KVM: PPC: Book3S HV: XIVE: Add a control to sync the sources

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Cédric Le Goater <clg@kaod.org>
commit 7b46b6169ab80f8f415a0ca2ea4aa7f1afdcc4f3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/7b46b616.failed

This control will be used by the H_INT_SYNC hcall from QEMU to flush
event notifications on the XIVE IC owning the source.

	Signed-off-by: Cédric Le Goater <clg@kaod.org>
	Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
	Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
(cherry picked from commit 7b46b6169ab80f8f415a0ca2ea4aa7f1afdcc4f3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/virtual/kvm/devices/xive.txt
#	arch/powerpc/include/uapi/asm/kvm.h
#	arch/powerpc/kvm/book3s_xive_native.c
diff --cc Documentation/virtual/kvm/devices/xive.txt
index fdbd2ff92a88,1e7f19d7594b..000000000000
--- a/Documentation/virtual/kvm/devices/xive.txt
+++ b/Documentation/virtual/kvm/devices/xive.txt
@@@ -17,3 -17,86 +17,89 @@@ the legacy interrupt mode, referred as 
  
    1. KVM_DEV_XIVE_GRP_CTRL
    Provides global controls on the device
++<<<<<<< HEAD
++=======
+   Attributes:
+     1.1 KVM_DEV_XIVE_RESET (write only)
+     Resets the interrupt controller configuration for sources and event
+     queues. To be used by kexec and kdump.
+     Errors: none
+ 
+   2. KVM_DEV_XIVE_GRP_SOURCE (write only)
+   Initializes a new source in the XIVE device and mask it.
+   Attributes:
+     Interrupt source number  (64-bit)
+   The kvm_device_attr.addr points to a __u64 value:
+   bits:     | 63   ....  2 |   1   |   0
+   values:   |    unused    | level | type
+   - type:  0:MSI 1:LSI
+   - level: assertion level in case of an LSI.
+   Errors:
+     -E2BIG:  Interrupt source number is out of range
+     -ENOMEM: Could not create a new source block
+     -EFAULT: Invalid user pointer for attr->addr.
+     -ENXIO:  Could not allocate underlying HW interrupt
+ 
+   3. KVM_DEV_XIVE_GRP_SOURCE_CONFIG (write only)
+   Configures source targeting
+   Attributes:
+     Interrupt source number  (64-bit)
+   The kvm_device_attr.addr points to a __u64 value:
+   bits:     | 63   ....  33 |  32  | 31 .. 3 |  2 .. 0
+   values:   |    eisn       | mask |  server | priority
+   - priority: 0-7 interrupt priority level
+   - server: CPU number chosen to handle the interrupt
+   - mask: mask flag (unused)
+   - eisn: Effective Interrupt Source Number
+   Errors:
+     -ENOENT: Unknown source number
+     -EINVAL: Not initialized source number
+     -EINVAL: Invalid priority
+     -EINVAL: Invalid CPU number.
+     -EFAULT: Invalid user pointer for attr->addr.
+     -ENXIO:  CPU event queues not configured or configuration of the
+              underlying HW interrupt failed
+     -EBUSY:  No CPU available to serve interrupt
+ 
+   4. KVM_DEV_XIVE_GRP_EQ_CONFIG (read-write)
+   Configures an event queue of a CPU
+   Attributes:
+     EQ descriptor identifier (64-bit)
+   The EQ descriptor identifier is a tuple (server, priority) :
+   bits:     | 63   ....  32 | 31 .. 3 |  2 .. 0
+   values:   |    unused     |  server | priority
+   The kvm_device_attr.addr points to :
+     struct kvm_ppc_xive_eq {
+ 	__u32 flags;
+ 	__u32 qshift;
+ 	__u64 qaddr;
+ 	__u32 qtoggle;
+ 	__u32 qindex;
+ 	__u8  pad[40];
+     };
+   - flags: queue flags
+     KVM_XIVE_EQ_ALWAYS_NOTIFY (required)
+ 	forces notification without using the coalescing mechanism
+ 	provided by the XIVE END ESBs.
+   - qshift: queue size (power of 2)
+   - qaddr: real address of queue
+   - qtoggle: current queue toggle bit
+   - qindex: current queue index
+   - pad: reserved for future use
+   Errors:
+     -ENOENT: Invalid CPU number
+     -EINVAL: Invalid priority
+     -EINVAL: Invalid flags
+     -EINVAL: Invalid queue size
+     -EINVAL: Invalid queue address
+     -EFAULT: Invalid user pointer for attr->addr.
+     -EIO:    Configuration of the underlying HW failed
+ 
+   5. KVM_DEV_XIVE_GRP_SOURCE_SYNC (write only)
+   Synchronize the source to flush event notifications
+   Attributes:
+     Interrupt source number  (64-bit)
+   Errors:
+     -ENOENT: Unknown source number
+     -EINVAL: Not initialized source number
++>>>>>>> 7b46b6169ab8 (KVM: PPC: Book3S HV: XIVE: Add a control to sync the sources)
diff --cc arch/powerpc/include/uapi/asm/kvm.h
index be0ce1f17625,e4abe30f6fc6..000000000000
--- a/arch/powerpc/include/uapi/asm/kvm.h
+++ b/arch/powerpc/include/uapi/asm/kvm.h
@@@ -679,5 -679,42 +679,45 @@@ struct kvm_ppc_cpu_char 
  
  /* POWER9 XIVE Native Interrupt Controller */
  #define KVM_DEV_XIVE_GRP_CTRL		1
++<<<<<<< HEAD
++=======
+ #define   KVM_DEV_XIVE_RESET		1
+ #define KVM_DEV_XIVE_GRP_SOURCE		2	/* 64-bit source identifier */
+ #define KVM_DEV_XIVE_GRP_SOURCE_CONFIG	3	/* 64-bit source identifier */
+ #define KVM_DEV_XIVE_GRP_EQ_CONFIG	4	/* 64-bit EQ identifier */
+ #define KVM_DEV_XIVE_GRP_SOURCE_SYNC	5       /* 64-bit source identifier */
+ 
+ /* Layout of 64-bit XIVE source attribute values */
+ #define KVM_XIVE_LEVEL_SENSITIVE	(1ULL << 0)
+ #define KVM_XIVE_LEVEL_ASSERTED		(1ULL << 1)
+ 
+ /* Layout of 64-bit XIVE source configuration attribute values */
+ #define KVM_XIVE_SOURCE_PRIORITY_SHIFT	0
+ #define KVM_XIVE_SOURCE_PRIORITY_MASK	0x7
+ #define KVM_XIVE_SOURCE_SERVER_SHIFT	3
+ #define KVM_XIVE_SOURCE_SERVER_MASK	0xfffffff8ULL
+ #define KVM_XIVE_SOURCE_MASKED_SHIFT	32
+ #define KVM_XIVE_SOURCE_MASKED_MASK	0x100000000ULL
+ #define KVM_XIVE_SOURCE_EISN_SHIFT	33
+ #define KVM_XIVE_SOURCE_EISN_MASK	0xfffffffe00000000ULL
+ 
+ /* Layout of 64-bit EQ identifier */
+ #define KVM_XIVE_EQ_PRIORITY_SHIFT	0
+ #define KVM_XIVE_EQ_PRIORITY_MASK	0x7
+ #define KVM_XIVE_EQ_SERVER_SHIFT	3
+ #define KVM_XIVE_EQ_SERVER_MASK		0xfffffff8ULL
+ 
+ /* Layout of EQ configuration values (64 bytes) */
+ struct kvm_ppc_xive_eq {
+ 	__u32 flags;
+ 	__u32 qshift;
+ 	__u64 qaddr;
+ 	__u32 qtoggle;
+ 	__u32 qindex;
+ 	__u8  pad[40];
+ };
+ 
+ #define KVM_XIVE_EQ_ALWAYS_NOTIFY	0x00000001
++>>>>>>> 7b46b6169ab8 (KVM: PPC: Book3S HV: XIVE: Add a control to sync the sources)
  
  #endif /* __LINUX_KVM_POWERPC_H */
diff --cc arch/powerpc/kvm/book3s_xive_native.c
index 751259394150,65380416d101..000000000000
--- a/arch/powerpc/kvm/book3s_xive_native.c
+++ b/arch/powerpc/kvm/book3s_xive_native.c
@@@ -26,12 -26,685 +26,685 @@@
  
  #include "book3s_xive.h"
  
++<<<<<<< HEAD
++=======
+ static u8 xive_vm_esb_load(struct xive_irq_data *xd, u32 offset)
+ {
+ 	u64 val;
+ 
+ 	if (xd->flags & XIVE_IRQ_FLAG_SHIFT_BUG)
+ 		offset |= offset << 4;
+ 
+ 	val = in_be64(xd->eoi_mmio + offset);
+ 	return (u8)val;
+ }
+ 
+ static void kvmppc_xive_native_cleanup_queue(struct kvm_vcpu *vcpu, int prio)
+ {
+ 	struct kvmppc_xive_vcpu *xc = vcpu->arch.xive_vcpu;
+ 	struct xive_q *q = &xc->queues[prio];
+ 
+ 	xive_native_disable_queue(xc->vp_id, q, prio);
+ 	if (q->qpage) {
+ 		put_page(virt_to_page(q->qpage));
+ 		q->qpage = NULL;
+ 	}
+ }
+ 
+ void kvmppc_xive_native_cleanup_vcpu(struct kvm_vcpu *vcpu)
+ {
+ 	struct kvmppc_xive_vcpu *xc = vcpu->arch.xive_vcpu;
+ 	int i;
+ 
+ 	if (!kvmppc_xive_enabled(vcpu))
+ 		return;
+ 
+ 	if (!xc)
+ 		return;
+ 
+ 	pr_devel("native_cleanup_vcpu(cpu=%d)\n", xc->server_num);
+ 
+ 	/* Ensure no interrupt is still routed to that VP */
+ 	xc->valid = false;
+ 	kvmppc_xive_disable_vcpu_interrupts(vcpu);
+ 
+ 	/* Disable the VP */
+ 	xive_native_disable_vp(xc->vp_id);
+ 
+ 	/* Free the queues & associated interrupts */
+ 	for (i = 0; i < KVMPPC_XIVE_Q_COUNT; i++) {
+ 		/* Free the escalation irq */
+ 		if (xc->esc_virq[i]) {
+ 			free_irq(xc->esc_virq[i], vcpu);
+ 			irq_dispose_mapping(xc->esc_virq[i]);
+ 			kfree(xc->esc_virq_names[i]);
+ 			xc->esc_virq[i] = 0;
+ 		}
+ 
+ 		/* Free the queue */
+ 		kvmppc_xive_native_cleanup_queue(vcpu, i);
+ 	}
+ 
+ 	/* Free the VP */
+ 	kfree(xc);
+ 
+ 	/* Cleanup the vcpu */
+ 	vcpu->arch.irq_type = KVMPPC_IRQ_DEFAULT;
+ 	vcpu->arch.xive_vcpu = NULL;
+ }
+ 
+ int kvmppc_xive_native_connect_vcpu(struct kvm_device *dev,
+ 				    struct kvm_vcpu *vcpu, u32 server_num)
+ {
+ 	struct kvmppc_xive *xive = dev->private;
+ 	struct kvmppc_xive_vcpu *xc = NULL;
+ 	int rc;
+ 
+ 	pr_devel("native_connect_vcpu(server=%d)\n", server_num);
+ 
+ 	if (dev->ops != &kvm_xive_native_ops) {
+ 		pr_devel("Wrong ops !\n");
+ 		return -EPERM;
+ 	}
+ 	if (xive->kvm != vcpu->kvm)
+ 		return -EPERM;
+ 	if (vcpu->arch.irq_type != KVMPPC_IRQ_DEFAULT)
+ 		return -EBUSY;
+ 	if (server_num >= KVM_MAX_VCPUS) {
+ 		pr_devel("Out of bounds !\n");
+ 		return -EINVAL;
+ 	}
+ 
+ 	mutex_lock(&vcpu->kvm->lock);
+ 
+ 	if (kvmppc_xive_find_server(vcpu->kvm, server_num)) {
+ 		pr_devel("Duplicate !\n");
+ 		rc = -EEXIST;
+ 		goto bail;
+ 	}
+ 
+ 	xc = kzalloc(sizeof(*xc), GFP_KERNEL);
+ 	if (!xc) {
+ 		rc = -ENOMEM;
+ 		goto bail;
+ 	}
+ 
+ 	vcpu->arch.xive_vcpu = xc;
+ 	xc->xive = xive;
+ 	xc->vcpu = vcpu;
+ 	xc->server_num = server_num;
+ 
+ 	xc->vp_id = kvmppc_xive_vp(xive, server_num);
+ 	xc->valid = true;
+ 	vcpu->arch.irq_type = KVMPPC_IRQ_XIVE;
+ 
+ 	rc = xive_native_get_vp_info(xc->vp_id, &xc->vp_cam, &xc->vp_chip_id);
+ 	if (rc) {
+ 		pr_err("Failed to get VP info from OPAL: %d\n", rc);
+ 		goto bail;
+ 	}
+ 
+ 	/*
+ 	 * Enable the VP first as the single escalation mode will
+ 	 * affect escalation interrupts numbering
+ 	 */
+ 	rc = xive_native_enable_vp(xc->vp_id, xive->single_escalation);
+ 	if (rc) {
+ 		pr_err("Failed to enable VP in OPAL: %d\n", rc);
+ 		goto bail;
+ 	}
+ 
+ 	/* Configure VCPU fields for use by assembly push/pull */
+ 	vcpu->arch.xive_saved_state.w01 = cpu_to_be64(0xff000000);
+ 	vcpu->arch.xive_cam_word = cpu_to_be32(xc->vp_cam | TM_QW1W2_VO);
+ 
+ 	/* TODO: reset all queues to a clean state ? */
+ bail:
+ 	mutex_unlock(&vcpu->kvm->lock);
+ 	if (rc)
+ 		kvmppc_xive_native_cleanup_vcpu(vcpu);
+ 
+ 	return rc;
+ }
+ 
+ static int kvmppc_xive_native_set_source(struct kvmppc_xive *xive, long irq,
+ 					 u64 addr)
+ {
+ 	struct kvmppc_xive_src_block *sb;
+ 	struct kvmppc_xive_irq_state *state;
+ 	u64 __user *ubufp = (u64 __user *) addr;
+ 	u64 val;
+ 	u16 idx;
+ 	int rc;
+ 
+ 	pr_devel("%s irq=0x%lx\n", __func__, irq);
+ 
+ 	if (irq < KVMPPC_XIVE_FIRST_IRQ || irq >= KVMPPC_XIVE_NR_IRQS)
+ 		return -E2BIG;
+ 
+ 	sb = kvmppc_xive_find_source(xive, irq, &idx);
+ 	if (!sb) {
+ 		pr_debug("No source, creating source block...\n");
+ 		sb = kvmppc_xive_create_src_block(xive, irq);
+ 		if (!sb) {
+ 			pr_err("Failed to create block...\n");
+ 			return -ENOMEM;
+ 		}
+ 	}
+ 	state = &sb->irq_state[idx];
+ 
+ 	if (get_user(val, ubufp)) {
+ 		pr_err("fault getting user info !\n");
+ 		return -EFAULT;
+ 	}
+ 
+ 	arch_spin_lock(&sb->lock);
+ 
+ 	/*
+ 	 * If the source doesn't already have an IPI, allocate
+ 	 * one and get the corresponding data
+ 	 */
+ 	if (!state->ipi_number) {
+ 		state->ipi_number = xive_native_alloc_irq();
+ 		if (state->ipi_number == 0) {
+ 			pr_err("Failed to allocate IRQ !\n");
+ 			rc = -ENXIO;
+ 			goto unlock;
+ 		}
+ 		xive_native_populate_irq_data(state->ipi_number,
+ 					      &state->ipi_data);
+ 		pr_debug("%s allocated hw_irq=0x%x for irq=0x%lx\n", __func__,
+ 			 state->ipi_number, irq);
+ 	}
+ 
+ 	/* Restore LSI state */
+ 	if (val & KVM_XIVE_LEVEL_SENSITIVE) {
+ 		state->lsi = true;
+ 		if (val & KVM_XIVE_LEVEL_ASSERTED)
+ 			state->asserted = true;
+ 		pr_devel("  LSI ! Asserted=%d\n", state->asserted);
+ 	}
+ 
+ 	/* Mask IRQ to start with */
+ 	state->act_server = 0;
+ 	state->act_priority = MASKED;
+ 	xive_vm_esb_load(&state->ipi_data, XIVE_ESB_SET_PQ_01);
+ 	xive_native_configure_irq(state->ipi_number, 0, MASKED, 0);
+ 
+ 	/* Increment the number of valid sources and mark this one valid */
+ 	if (!state->valid)
+ 		xive->src_count++;
+ 	state->valid = true;
+ 
+ 	rc = 0;
+ 
+ unlock:
+ 	arch_spin_unlock(&sb->lock);
+ 
+ 	return rc;
+ }
+ 
+ static int kvmppc_xive_native_update_source_config(struct kvmppc_xive *xive,
+ 					struct kvmppc_xive_src_block *sb,
+ 					struct kvmppc_xive_irq_state *state,
+ 					u32 server, u8 priority, bool masked,
+ 					u32 eisn)
+ {
+ 	struct kvm *kvm = xive->kvm;
+ 	u32 hw_num;
+ 	int rc = 0;
+ 
+ 	arch_spin_lock(&sb->lock);
+ 
+ 	if (state->act_server == server && state->act_priority == priority &&
+ 	    state->eisn == eisn)
+ 		goto unlock;
+ 
+ 	pr_devel("new_act_prio=%d new_act_server=%d mask=%d act_server=%d act_prio=%d\n",
+ 		 priority, server, masked, state->act_server,
+ 		 state->act_priority);
+ 
+ 	kvmppc_xive_select_irq(state, &hw_num, NULL);
+ 
+ 	if (priority != MASKED && !masked) {
+ 		rc = kvmppc_xive_select_target(kvm, &server, priority);
+ 		if (rc)
+ 			goto unlock;
+ 
+ 		state->act_priority = priority;
+ 		state->act_server = server;
+ 		state->eisn = eisn;
+ 
+ 		rc = xive_native_configure_irq(hw_num,
+ 					       kvmppc_xive_vp(xive, server),
+ 					       priority, eisn);
+ 	} else {
+ 		state->act_priority = MASKED;
+ 		state->act_server = 0;
+ 		state->eisn = 0;
+ 
+ 		rc = xive_native_configure_irq(hw_num, 0, MASKED, 0);
+ 	}
+ 
+ unlock:
+ 	arch_spin_unlock(&sb->lock);
+ 	return rc;
+ }
+ 
+ static int kvmppc_xive_native_set_source_config(struct kvmppc_xive *xive,
+ 						long irq, u64 addr)
+ {
+ 	struct kvmppc_xive_src_block *sb;
+ 	struct kvmppc_xive_irq_state *state;
+ 	u64 __user *ubufp = (u64 __user *) addr;
+ 	u16 src;
+ 	u64 kvm_cfg;
+ 	u32 server;
+ 	u8 priority;
+ 	bool masked;
+ 	u32 eisn;
+ 
+ 	sb = kvmppc_xive_find_source(xive, irq, &src);
+ 	if (!sb)
+ 		return -ENOENT;
+ 
+ 	state = &sb->irq_state[src];
+ 
+ 	if (!state->valid)
+ 		return -EINVAL;
+ 
+ 	if (get_user(kvm_cfg, ubufp))
+ 		return -EFAULT;
+ 
+ 	pr_devel("%s irq=0x%lx cfg=%016llx\n", __func__, irq, kvm_cfg);
+ 
+ 	priority = (kvm_cfg & KVM_XIVE_SOURCE_PRIORITY_MASK) >>
+ 		KVM_XIVE_SOURCE_PRIORITY_SHIFT;
+ 	server = (kvm_cfg & KVM_XIVE_SOURCE_SERVER_MASK) >>
+ 		KVM_XIVE_SOURCE_SERVER_SHIFT;
+ 	masked = (kvm_cfg & KVM_XIVE_SOURCE_MASKED_MASK) >>
+ 		KVM_XIVE_SOURCE_MASKED_SHIFT;
+ 	eisn = (kvm_cfg & KVM_XIVE_SOURCE_EISN_MASK) >>
+ 		KVM_XIVE_SOURCE_EISN_SHIFT;
+ 
+ 	if (priority != xive_prio_from_guest(priority)) {
+ 		pr_err("invalid priority for queue %d for VCPU %d\n",
+ 		       priority, server);
+ 		return -EINVAL;
+ 	}
+ 
+ 	return kvmppc_xive_native_update_source_config(xive, sb, state, server,
+ 						       priority, masked, eisn);
+ }
+ 
+ static int kvmppc_xive_native_sync_source(struct kvmppc_xive *xive,
+ 					  long irq, u64 addr)
+ {
+ 	struct kvmppc_xive_src_block *sb;
+ 	struct kvmppc_xive_irq_state *state;
+ 	struct xive_irq_data *xd;
+ 	u32 hw_num;
+ 	u16 src;
+ 	int rc = 0;
+ 
+ 	pr_devel("%s irq=0x%lx", __func__, irq);
+ 
+ 	sb = kvmppc_xive_find_source(xive, irq, &src);
+ 	if (!sb)
+ 		return -ENOENT;
+ 
+ 	state = &sb->irq_state[src];
+ 
+ 	rc = -EINVAL;
+ 
+ 	arch_spin_lock(&sb->lock);
+ 
+ 	if (state->valid) {
+ 		kvmppc_xive_select_irq(state, &hw_num, &xd);
+ 		xive_native_sync_source(hw_num);
+ 		rc = 0;
+ 	}
+ 
+ 	arch_spin_unlock(&sb->lock);
+ 	return rc;
+ }
+ 
+ static int xive_native_validate_queue_size(u32 qshift)
+ {
+ 	/*
+ 	 * We only support 64K pages for the moment. This is also
+ 	 * advertised in the DT property "ibm,xive-eq-sizes"
+ 	 */
+ 	switch (qshift) {
+ 	case 0: /* EQ reset */
+ 	case 16:
+ 		return 0;
+ 	case 12:
+ 	case 21:
+ 	case 24:
+ 	default:
+ 		return -EINVAL;
+ 	}
+ }
+ 
+ static int kvmppc_xive_native_set_queue_config(struct kvmppc_xive *xive,
+ 					       long eq_idx, u64 addr)
+ {
+ 	struct kvm *kvm = xive->kvm;
+ 	struct kvm_vcpu *vcpu;
+ 	struct kvmppc_xive_vcpu *xc;
+ 	void __user *ubufp = (void __user *) addr;
+ 	u32 server;
+ 	u8 priority;
+ 	struct kvm_ppc_xive_eq kvm_eq;
+ 	int rc;
+ 	__be32 *qaddr = 0;
+ 	struct page *page;
+ 	struct xive_q *q;
+ 	gfn_t gfn;
+ 	unsigned long page_size;
+ 
+ 	/*
+ 	 * Demangle priority/server tuple from the EQ identifier
+ 	 */
+ 	priority = (eq_idx & KVM_XIVE_EQ_PRIORITY_MASK) >>
+ 		KVM_XIVE_EQ_PRIORITY_SHIFT;
+ 	server = (eq_idx & KVM_XIVE_EQ_SERVER_MASK) >>
+ 		KVM_XIVE_EQ_SERVER_SHIFT;
+ 
+ 	if (copy_from_user(&kvm_eq, ubufp, sizeof(kvm_eq)))
+ 		return -EFAULT;
+ 
+ 	vcpu = kvmppc_xive_find_server(kvm, server);
+ 	if (!vcpu) {
+ 		pr_err("Can't find server %d\n", server);
+ 		return -ENOENT;
+ 	}
+ 	xc = vcpu->arch.xive_vcpu;
+ 
+ 	if (priority != xive_prio_from_guest(priority)) {
+ 		pr_err("Trying to restore invalid queue %d for VCPU %d\n",
+ 		       priority, server);
+ 		return -EINVAL;
+ 	}
+ 	q = &xc->queues[priority];
+ 
+ 	pr_devel("%s VCPU %d priority %d fl:%x shift:%d addr:%llx g:%d idx:%d\n",
+ 		 __func__, server, priority, kvm_eq.flags,
+ 		 kvm_eq.qshift, kvm_eq.qaddr, kvm_eq.qtoggle, kvm_eq.qindex);
+ 
+ 	/*
+ 	 * sPAPR specifies a "Unconditional Notify (n) flag" for the
+ 	 * H_INT_SET_QUEUE_CONFIG hcall which forces notification
+ 	 * without using the coalescing mechanisms provided by the
+ 	 * XIVE END ESBs. This is required on KVM as notification
+ 	 * using the END ESBs is not supported.
+ 	 */
+ 	if (kvm_eq.flags != KVM_XIVE_EQ_ALWAYS_NOTIFY) {
+ 		pr_err("invalid flags %d\n", kvm_eq.flags);
+ 		return -EINVAL;
+ 	}
+ 
+ 	rc = xive_native_validate_queue_size(kvm_eq.qshift);
+ 	if (rc) {
+ 		pr_err("invalid queue size %d\n", kvm_eq.qshift);
+ 		return rc;
+ 	}
+ 
+ 	/* reset queue and disable queueing */
+ 	if (!kvm_eq.qshift) {
+ 		q->guest_qaddr  = 0;
+ 		q->guest_qshift = 0;
+ 
+ 		rc = xive_native_configure_queue(xc->vp_id, q, priority,
+ 						 NULL, 0, true);
+ 		if (rc) {
+ 			pr_err("Failed to reset queue %d for VCPU %d: %d\n",
+ 			       priority, xc->server_num, rc);
+ 			return rc;
+ 		}
+ 
+ 		if (q->qpage) {
+ 			put_page(virt_to_page(q->qpage));
+ 			q->qpage = NULL;
+ 		}
+ 
+ 		return 0;
+ 	}
+ 
+ 	if (kvm_eq.qaddr & ((1ull << kvm_eq.qshift) - 1)) {
+ 		pr_err("queue page is not aligned %llx/%llx\n", kvm_eq.qaddr,
+ 		       1ull << kvm_eq.qshift);
+ 		return -EINVAL;
+ 	}
+ 
+ 	gfn = gpa_to_gfn(kvm_eq.qaddr);
+ 	page = gfn_to_page(kvm, gfn);
+ 	if (is_error_page(page)) {
+ 		pr_err("Couldn't get queue page %llx!\n", kvm_eq.qaddr);
+ 		return -EINVAL;
+ 	}
+ 
+ 	page_size = kvm_host_page_size(kvm, gfn);
+ 	if (1ull << kvm_eq.qshift > page_size) {
+ 		pr_warn("Incompatible host page size %lx!\n", page_size);
+ 		return -EINVAL;
+ 	}
+ 
+ 	qaddr = page_to_virt(page) + (kvm_eq.qaddr & ~PAGE_MASK);
+ 
+ 	/*
+ 	 * Backup the queue page guest address to the mark EQ page
+ 	 * dirty for migration.
+ 	 */
+ 	q->guest_qaddr  = kvm_eq.qaddr;
+ 	q->guest_qshift = kvm_eq.qshift;
+ 
+ 	 /*
+ 	  * Unconditional Notification is forced by default at the
+ 	  * OPAL level because the use of END ESBs is not supported by
+ 	  * Linux.
+ 	  */
+ 	rc = xive_native_configure_queue(xc->vp_id, q, priority,
+ 					 (__be32 *) qaddr, kvm_eq.qshift, true);
+ 	if (rc) {
+ 		pr_err("Failed to configure queue %d for VCPU %d: %d\n",
+ 		       priority, xc->server_num, rc);
+ 		put_page(page);
+ 		return rc;
+ 	}
+ 
+ 	/*
+ 	 * Only restore the queue state when needed. When doing the
+ 	 * H_INT_SET_SOURCE_CONFIG hcall, it should not.
+ 	 */
+ 	if (kvm_eq.qtoggle != 1 || kvm_eq.qindex != 0) {
+ 		rc = xive_native_set_queue_state(xc->vp_id, priority,
+ 						 kvm_eq.qtoggle,
+ 						 kvm_eq.qindex);
+ 		if (rc)
+ 			goto error;
+ 	}
+ 
+ 	rc = kvmppc_xive_attach_escalation(vcpu, priority,
+ 					   xive->single_escalation);
+ error:
+ 	if (rc)
+ 		kvmppc_xive_native_cleanup_queue(vcpu, priority);
+ 	return rc;
+ }
+ 
+ static int kvmppc_xive_native_get_queue_config(struct kvmppc_xive *xive,
+ 					       long eq_idx, u64 addr)
+ {
+ 	struct kvm *kvm = xive->kvm;
+ 	struct kvm_vcpu *vcpu;
+ 	struct kvmppc_xive_vcpu *xc;
+ 	struct xive_q *q;
+ 	void __user *ubufp = (u64 __user *) addr;
+ 	u32 server;
+ 	u8 priority;
+ 	struct kvm_ppc_xive_eq kvm_eq;
+ 	u64 qaddr;
+ 	u64 qshift;
+ 	u64 qeoi_page;
+ 	u32 escalate_irq;
+ 	u64 qflags;
+ 	int rc;
+ 
+ 	/*
+ 	 * Demangle priority/server tuple from the EQ identifier
+ 	 */
+ 	priority = (eq_idx & KVM_XIVE_EQ_PRIORITY_MASK) >>
+ 		KVM_XIVE_EQ_PRIORITY_SHIFT;
+ 	server = (eq_idx & KVM_XIVE_EQ_SERVER_MASK) >>
+ 		KVM_XIVE_EQ_SERVER_SHIFT;
+ 
+ 	vcpu = kvmppc_xive_find_server(kvm, server);
+ 	if (!vcpu) {
+ 		pr_err("Can't find server %d\n", server);
+ 		return -ENOENT;
+ 	}
+ 	xc = vcpu->arch.xive_vcpu;
+ 
+ 	if (priority != xive_prio_from_guest(priority)) {
+ 		pr_err("invalid priority for queue %d for VCPU %d\n",
+ 		       priority, server);
+ 		return -EINVAL;
+ 	}
+ 	q = &xc->queues[priority];
+ 
+ 	memset(&kvm_eq, 0, sizeof(kvm_eq));
+ 
+ 	if (!q->qpage)
+ 		return 0;
+ 
+ 	rc = xive_native_get_queue_info(xc->vp_id, priority, &qaddr, &qshift,
+ 					&qeoi_page, &escalate_irq, &qflags);
+ 	if (rc)
+ 		return rc;
+ 
+ 	kvm_eq.flags = 0;
+ 	if (qflags & OPAL_XIVE_EQ_ALWAYS_NOTIFY)
+ 		kvm_eq.flags |= KVM_XIVE_EQ_ALWAYS_NOTIFY;
+ 
+ 	kvm_eq.qshift = q->guest_qshift;
+ 	kvm_eq.qaddr  = q->guest_qaddr;
+ 
+ 	rc = xive_native_get_queue_state(xc->vp_id, priority, &kvm_eq.qtoggle,
+ 					 &kvm_eq.qindex);
+ 	if (rc)
+ 		return rc;
+ 
+ 	pr_devel("%s VCPU %d priority %d fl:%x shift:%d addr:%llx g:%d idx:%d\n",
+ 		 __func__, server, priority, kvm_eq.flags,
+ 		 kvm_eq.qshift, kvm_eq.qaddr, kvm_eq.qtoggle, kvm_eq.qindex);
+ 
+ 	if (copy_to_user(ubufp, &kvm_eq, sizeof(kvm_eq)))
+ 		return -EFAULT;
+ 
+ 	return 0;
+ }
+ 
+ static void kvmppc_xive_reset_sources(struct kvmppc_xive_src_block *sb)
+ {
+ 	int i;
+ 
+ 	for (i = 0; i < KVMPPC_XICS_IRQ_PER_ICS; i++) {
+ 		struct kvmppc_xive_irq_state *state = &sb->irq_state[i];
+ 
+ 		if (!state->valid)
+ 			continue;
+ 
+ 		if (state->act_priority == MASKED)
+ 			continue;
+ 
+ 		state->eisn = 0;
+ 		state->act_server = 0;
+ 		state->act_priority = MASKED;
+ 		xive_vm_esb_load(&state->ipi_data, XIVE_ESB_SET_PQ_01);
+ 		xive_native_configure_irq(state->ipi_number, 0, MASKED, 0);
+ 		if (state->pt_number) {
+ 			xive_vm_esb_load(state->pt_data, XIVE_ESB_SET_PQ_01);
+ 			xive_native_configure_irq(state->pt_number,
+ 						  0, MASKED, 0);
+ 		}
+ 	}
+ }
+ 
+ static int kvmppc_xive_reset(struct kvmppc_xive *xive)
+ {
+ 	struct kvm *kvm = xive->kvm;
+ 	struct kvm_vcpu *vcpu;
+ 	unsigned int i;
+ 
+ 	pr_devel("%s\n", __func__);
+ 
+ 	mutex_lock(&kvm->lock);
+ 
+ 	kvm_for_each_vcpu(i, vcpu, kvm) {
+ 		struct kvmppc_xive_vcpu *xc = vcpu->arch.xive_vcpu;
+ 		unsigned int prio;
+ 
+ 		if (!xc)
+ 			continue;
+ 
+ 		kvmppc_xive_disable_vcpu_interrupts(vcpu);
+ 
+ 		for (prio = 0; prio < KVMPPC_XIVE_Q_COUNT; prio++) {
+ 
+ 			/* Single escalation, no queue 7 */
+ 			if (prio == 7 && xive->single_escalation)
+ 				break;
+ 
+ 			if (xc->esc_virq[prio]) {
+ 				free_irq(xc->esc_virq[prio], vcpu);
+ 				irq_dispose_mapping(xc->esc_virq[prio]);
+ 				kfree(xc->esc_virq_names[prio]);
+ 				xc->esc_virq[prio] = 0;
+ 			}
+ 
+ 			kvmppc_xive_native_cleanup_queue(vcpu, prio);
+ 		}
+ 	}
+ 
+ 	for (i = 0; i <= xive->max_sbid; i++) {
+ 		struct kvmppc_xive_src_block *sb = xive->src_blocks[i];
+ 
+ 		if (sb) {
+ 			arch_spin_lock(&sb->lock);
+ 			kvmppc_xive_reset_sources(sb);
+ 			arch_spin_unlock(&sb->lock);
+ 		}
+ 	}
+ 
+ 	mutex_unlock(&kvm->lock);
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 7b46b6169ab8 (KVM: PPC: Book3S HV: XIVE: Add a control to sync the sources)
  static int kvmppc_xive_native_set_attr(struct kvm_device *dev,
  				       struct kvm_device_attr *attr)
  {
 -	struct kvmppc_xive *xive = dev->private;
 -
  	switch (attr->group) {
  	case KVM_DEV_XIVE_GRP_CTRL:
 -		switch (attr->attr) {
 -		case KVM_DEV_XIVE_RESET:
 -			return kvmppc_xive_reset(xive);
 -		}
  		break;
++<<<<<<< HEAD
++=======
+ 	case KVM_DEV_XIVE_GRP_SOURCE:
+ 		return kvmppc_xive_native_set_source(xive, attr->attr,
+ 						     attr->addr);
+ 	case KVM_DEV_XIVE_GRP_SOURCE_CONFIG:
+ 		return kvmppc_xive_native_set_source_config(xive, attr->attr,
+ 							    attr->addr);
+ 	case KVM_DEV_XIVE_GRP_EQ_CONFIG:
+ 		return kvmppc_xive_native_set_queue_config(xive, attr->attr,
+ 							   attr->addr);
+ 	case KVM_DEV_XIVE_GRP_SOURCE_SYNC:
+ 		return kvmppc_xive_native_sync_source(xive, attr->attr,
+ 						      attr->addr);
++>>>>>>> 7b46b6169ab8 (KVM: PPC: Book3S HV: XIVE: Add a control to sync the sources)
  	}
  	return -ENXIO;
  }
@@@ -47,7 -727,20 +720,19 @@@ static int kvmppc_xive_native_has_attr(
  {
  	switch (attr->group) {
  	case KVM_DEV_XIVE_GRP_CTRL:
 -		switch (attr->attr) {
 -		case KVM_DEV_XIVE_RESET:
 -			return 0;
 -		}
  		break;
++<<<<<<< HEAD
++=======
+ 	case KVM_DEV_XIVE_GRP_SOURCE:
+ 	case KVM_DEV_XIVE_GRP_SOURCE_CONFIG:
+ 	case KVM_DEV_XIVE_GRP_SOURCE_SYNC:
+ 		if (attr->attr >= KVMPPC_XIVE_FIRST_IRQ &&
+ 		    attr->attr < KVMPPC_XIVE_NR_IRQS)
+ 			return 0;
+ 		break;
+ 	case KVM_DEV_XIVE_GRP_EQ_CONFIG:
+ 		return 0;
++>>>>>>> 7b46b6169ab8 (KVM: PPC: Book3S HV: XIVE: Add a control to sync the sources)
  	}
  	return -ENXIO;
  }
* Unmerged path Documentation/virtual/kvm/devices/xive.txt
* Unmerged path arch/powerpc/include/uapi/asm/kvm.h
* Unmerged path arch/powerpc/kvm/book3s_xive_native.c
