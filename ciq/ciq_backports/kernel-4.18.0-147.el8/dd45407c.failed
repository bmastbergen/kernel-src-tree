x86/intel_rdt: Use perf infrastructure for measurements

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Reinette Chatre <reinette.chatre@intel.com>
commit dd45407c0b2445bc2aa0ecfea744d5af3a146577
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/dd45407c.failed

The success of a cache pseudo-locked region is measured using
performance monitoring events that are programmed directly at the time
the user requests a measurement.

Modifying the performance event registers directly is not appropriate
since it circumvents the in-kernel perf infrastructure that exists to
manage these resources and provide resource arbitration to the
performance monitoring hardware.

The cache pseudo-locking measurements are modified to use the in-kernel
perf infrastructure. Performance events are created and validated with
the appropriate perf API. The performance counters are still read as
directly as possible to avoid the additional cache hits. This is
done safely by first ensuring with the perf API that the counters have
been programmed correctly and only accessing the counters in an
interrupt disabled section where they are not able to be moved.

As part of the transition to the in-kernel perf infrastructure the L2
and L3 measurements are split into two separate measurements that can
be triggered independently. This separation prevents additional cache
misses incurred during the extra testing code used to decide if a
L2 and/or L3 measurement should be made.

	Signed-off-by: Reinette Chatre <reinette.chatre@intel.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: fenghua.yu@intel.com
	Cc: tony.luck@intel.com
	Cc: peterz@infradead.org
	Cc: acme@kernel.org
	Cc: gavin.hindman@intel.com
	Cc: jithu.joseph@intel.com
	Cc: dave.hansen@intel.com
	Cc: hpa@zytor.com
Link: https://lkml.kernel.org/r/fc24e728b446404f42c78573c506e98cd0599873.1537468643.git.reinette.chatre@intel.com

(cherry picked from commit dd45407c0b2445bc2aa0ecfea744d5af3a146577)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/x86/intel_rdt_ui.txt
#	arch/x86/kernel/cpu/intel_rdt_pseudo_lock.c
diff --cc Documentation/x86/intel_rdt_ui.txt
index e67f3d836f65,52b10945ff75..000000000000
--- a/Documentation/x86/intel_rdt_ui.txt
+++ b/Documentation/x86/intel_rdt_ui.txt
@@@ -382,6 -424,176 +382,179 @@@ L3CODE:0=fffff;1=fffff;2=fffff;3=ffff
  L3DATA:0=fffff;1=fffff;2=3c0;3=fffff
  L3CODE:0=fffff;1=fffff;2=fffff;3=fffff
  
++<<<<<<< HEAD
++=======
+ Cache Pseudo-Locking
+ --------------------
+ CAT enables a user to specify the amount of cache space that an
+ application can fill. Cache pseudo-locking builds on the fact that a
+ CPU can still read and write data pre-allocated outside its current
+ allocated area on a cache hit. With cache pseudo-locking, data can be
+ preloaded into a reserved portion of cache that no application can
+ fill, and from that point on will only serve cache hits. The cache
+ pseudo-locked memory is made accessible to user space where an
+ application can map it into its virtual address space and thus have
+ a region of memory with reduced average read latency.
+ 
+ The creation of a cache pseudo-locked region is triggered by a request
+ from the user to do so that is accompanied by a schemata of the region
+ to be pseudo-locked. The cache pseudo-locked region is created as follows:
+ - Create a CAT allocation CLOSNEW with a CBM matching the schemata
+   from the user of the cache region that will contain the pseudo-locked
+   memory. This region must not overlap with any current CAT allocation/CLOS
+   on the system and no future overlap with this cache region is allowed
+   while the pseudo-locked region exists.
+ - Create a contiguous region of memory of the same size as the cache
+   region.
+ - Flush the cache, disable hardware prefetchers, disable preemption.
+ - Make CLOSNEW the active CLOS and touch the allocated memory to load
+   it into the cache.
+ - Set the previous CLOS as active.
+ - At this point the closid CLOSNEW can be released - the cache
+   pseudo-locked region is protected as long as its CBM does not appear in
+   any CAT allocation. Even though the cache pseudo-locked region will from
+   this point on not appear in any CBM of any CLOS an application running with
+   any CLOS will be able to access the memory in the pseudo-locked region since
+   the region continues to serve cache hits.
+ - The contiguous region of memory loaded into the cache is exposed to
+   user-space as a character device.
+ 
+ Cache pseudo-locking increases the probability that data will remain
+ in the cache via carefully configuring the CAT feature and controlling
+ application behavior. There is no guarantee that data is placed in
+ cache. Instructions like INVD, WBINVD, CLFLUSH, etc. can still evict
+ “locked” data from cache. Power management C-states may shrink or
+ power off cache. Deeper C-states will automatically be restricted on
+ pseudo-locked region creation.
+ 
+ It is required that an application using a pseudo-locked region runs
+ with affinity to the cores (or a subset of the cores) associated
+ with the cache on which the pseudo-locked region resides. A sanity check
+ within the code will not allow an application to map pseudo-locked memory
+ unless it runs with affinity to cores associated with the cache on which the
+ pseudo-locked region resides. The sanity check is only done during the
+ initial mmap() handling, there is no enforcement afterwards and the
+ application self needs to ensure it remains affine to the correct cores.
+ 
+ Pseudo-locking is accomplished in two stages:
+ 1) During the first stage the system administrator allocates a portion
+    of cache that should be dedicated to pseudo-locking. At this time an
+    equivalent portion of memory is allocated, loaded into allocated
+    cache portion, and exposed as a character device.
+ 2) During the second stage a user-space application maps (mmap()) the
+    pseudo-locked memory into its address space.
+ 
+ Cache Pseudo-Locking Interface
+ ------------------------------
+ A pseudo-locked region is created using the resctrl interface as follows:
+ 
+ 1) Create a new resource group by creating a new directory in /sys/fs/resctrl.
+ 2) Change the new resource group's mode to "pseudo-locksetup" by writing
+    "pseudo-locksetup" to the "mode" file.
+ 3) Write the schemata of the pseudo-locked region to the "schemata" file. All
+    bits within the schemata should be "unused" according to the "bit_usage"
+    file.
+ 
+ On successful pseudo-locked region creation the "mode" file will contain
+ "pseudo-locked" and a new character device with the same name as the resource
+ group will exist in /dev/pseudo_lock. This character device can be mmap()'ed
+ by user space in order to obtain access to the pseudo-locked memory region.
+ 
+ An example of cache pseudo-locked region creation and usage can be found below.
+ 
+ Cache Pseudo-Locking Debugging Interface
+ ---------------------------------------
+ The pseudo-locking debugging interface is enabled by default (if
+ CONFIG_DEBUG_FS is enabled) and can be found in /sys/kernel/debug/resctrl.
+ 
+ There is no explicit way for the kernel to test if a provided memory
+ location is present in the cache. The pseudo-locking debugging interface uses
+ the tracing infrastructure to provide two ways to measure cache residency of
+ the pseudo-locked region:
+ 1) Memory access latency using the pseudo_lock_mem_latency tracepoint. Data
+    from these measurements are best visualized using a hist trigger (see
+    example below). In this test the pseudo-locked region is traversed at
+    a stride of 32 bytes while hardware prefetchers and preemption
+    are disabled. This also provides a substitute visualization of cache
+    hits and misses.
+ 2) Cache hit and miss measurements using model specific precision counters if
+    available. Depending on the levels of cache on the system the pseudo_lock_l2
+    and pseudo_lock_l3 tracepoints are available.
+ 
+ When a pseudo-locked region is created a new debugfs directory is created for
+ it in debugfs as /sys/kernel/debug/resctrl/<newdir>. A single
+ write-only file, pseudo_lock_measure, is present in this directory. The
+ measurement of the pseudo-locked region depends on the number written to this
+ debugfs file:
+ 1 -  writing "1" to the pseudo_lock_measure file will trigger the latency
+      measurement captured in the pseudo_lock_mem_latency tracepoint. See
+      example below.
+ 2 -  writing "2" to the pseudo_lock_measure file will trigger the L2 cache
+      residency (cache hits and misses) measurement captured in the
+      pseudo_lock_l2 tracepoint. See example below.
+ 3 -  writing "3" to the pseudo_lock_measure file will trigger the L3 cache
+      residency (cache hits and misses) measurement captured in the
+      pseudo_lock_l3 tracepoint.
+ 
+ All measurements are recorded with the tracing infrastructure. This requires
+ the relevant tracepoints to be enabled before the measurement is triggered.
+ 
+ Example of latency debugging interface:
+ In this example a pseudo-locked region named "newlock" was created. Here is
+ how we can measure the latency in cycles of reading from this region and
+ visualize this data with a histogram that is available if CONFIG_HIST_TRIGGERS
+ is set:
+ # :> /sys/kernel/debug/tracing/trace
+ # echo 'hist:keys=latency' > /sys/kernel/debug/tracing/events/resctrl/pseudo_lock_mem_latency/trigger
+ # echo 1 > /sys/kernel/debug/tracing/events/resctrl/pseudo_lock_mem_latency/enable
+ # echo 1 > /sys/kernel/debug/resctrl/newlock/pseudo_lock_measure
+ # echo 0 > /sys/kernel/debug/tracing/events/resctrl/pseudo_lock_mem_latency/enable
+ # cat /sys/kernel/debug/tracing/events/resctrl/pseudo_lock_mem_latency/hist
+ 
+ # event histogram
+ #
+ # trigger info: hist:keys=latency:vals=hitcount:sort=hitcount:size=2048 [active]
+ #
+ 
+ { latency:        456 } hitcount:          1
+ { latency:         50 } hitcount:         83
+ { latency:         36 } hitcount:         96
+ { latency:         44 } hitcount:        174
+ { latency:         48 } hitcount:        195
+ { latency:         46 } hitcount:        262
+ { latency:         42 } hitcount:        693
+ { latency:         40 } hitcount:       3204
+ { latency:         38 } hitcount:       3484
+ 
+ Totals:
+     Hits: 8192
+     Entries: 9
+    Dropped: 0
+ 
+ Example of cache hits/misses debugging:
+ In this example a pseudo-locked region named "newlock" was created on the L2
+ cache of a platform. Here is how we can obtain details of the cache hits
+ and misses using the platform's precision counters.
+ 
+ # :> /sys/kernel/debug/tracing/trace
+ # echo 1 > /sys/kernel/debug/tracing/events/resctrl/pseudo_lock_l2/enable
+ # echo 2 > /sys/kernel/debug/resctrl/newlock/pseudo_lock_measure
+ # echo 0 > /sys/kernel/debug/tracing/events/resctrl/pseudo_lock_l2/enable
+ # cat /sys/kernel/debug/tracing/trace
+ 
+ # tracer: nop
+ #
+ #                              _-----=> irqs-off
+ #                             / _----=> need-resched
+ #                            | / _---=> hardirq/softirq
+ #                            || / _--=> preempt-depth
+ #                            ||| /     delay
+ #           TASK-PID   CPU#  ||||    TIMESTAMP  FUNCTION
+ #              | |       |   ||||       |         |
+  pseudo_lock_mea-1672  [002] ....  3132.860500: pseudo_lock_l2: hits=4097 miss=0
+ 
+ 
++>>>>>>> dd45407c0b24 (x86/intel_rdt: Use perf infrastructure for measurements)
  Examples for RDT allocation usage:
  
  Example 1
diff --cc arch/x86/kernel/cpu/intel_rdt_pseudo_lock.c
index 71a18ef21947,d68836139cf9..000000000000
--- a/arch/x86/kernel/cpu/intel_rdt_pseudo_lock.c
+++ b/arch/x86/kernel/cpu/intel_rdt_pseudo_lock.c
@@@ -843,13 -907,44 +834,48 @@@ static int measure_cycles_lat_fn(void *
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int measure_cycles_perf_fn(void *_plr)
++=======
+ /*
+  * Create a perf_event_attr for the hit and miss perf events that will
+  * be used during the performance measurement. A perf_event maintains
+  * a pointer to its perf_event_attr so a unique attribute structure is
+  * created for each perf_event.
+  *
+  * The actual configuration of the event is set right before use in order
+  * to use the X86_CONFIG macro.
+  */
+ static struct perf_event_attr perf_miss_attr = {
+ 	.type		= PERF_TYPE_RAW,
+ 	.size		= sizeof(struct perf_event_attr),
+ 	.pinned		= 1,
+ 	.disabled	= 0,
+ 	.exclude_user	= 1,
+ };
+ 
+ static struct perf_event_attr perf_hit_attr = {
+ 	.type		= PERF_TYPE_RAW,
+ 	.size		= sizeof(struct perf_event_attr),
+ 	.pinned		= 1,
+ 	.disabled	= 0,
+ 	.exclude_user	= 1,
+ };
+ 
+ struct residency_counts {
+ 	u64 miss_before, hits_before;
+ 	u64 miss_after,  hits_after;
+ };
+ 
+ static int measure_residency_fn(struct perf_event_attr *miss_attr,
+ 				struct perf_event_attr *hit_attr,
+ 				struct pseudo_lock_region *plr,
+ 				struct residency_counts *counts)
++>>>>>>> dd45407c0b24 (x86/intel_rdt: Use perf infrastructure for measurements)
  {
- 	unsigned long long l3_hits = 0, l3_miss = 0;
- 	u64 l3_hit_bits = 0, l3_miss_bits = 0;
- 	struct pseudo_lock_region *plr = _plr;
- 	unsigned long long l2_hits, l2_miss;
- 	u64 l2_hit_bits, l2_miss_bits;
+ 	u64 hits_before = 0, hits_after = 0, miss_before = 0, miss_after = 0;
+ 	struct perf_event *miss_event, *hit_event;
+ 	int hit_pmcnum, miss_pmcnum;
  	unsigned int line_size;
  	unsigned int size;
  	unsigned long i;
* Unmerged path Documentation/x86/intel_rdt_ui.txt
* Unmerged path arch/x86/kernel/cpu/intel_rdt_pseudo_lock.c
