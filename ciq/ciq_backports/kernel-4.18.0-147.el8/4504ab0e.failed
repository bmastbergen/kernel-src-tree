net/tls: Inform user space about send buffer availability

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Vakul Garg <vakul.garg@nxp.com>
commit 4504ab0e6eb801555368cbb3011ab0530f659d4b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/4504ab0e.failed

A previous fix ("tls: Fix write space handling") assumed that
user space application gets informed about the socket send buffer
availability when tls_push_sg() gets called. Inside tls_push_sg(), in
case do_tcp_sendpages() returns 0, the function returns without calling
ctx->sk_write_space. Further, the new function tls_sw_write_space()
did not invoke ctx->sk_write_space. This leads to situation that user
space application encounters a lockup always waiting for socket send
buffer to become available.

Rather than call ctx->sk_write_space from tls_push_sg(), it should be
called from tls_write_space. So whenever tcp stack invokes
sk->sk_write_space after freeing socket send buffer, we always declare
the same to user space by the way of invoking ctx->sk_write_space.

Fixes: 7463d3a2db0ef ("tls: Fix write space handling")
	Signed-off-by: Vakul Garg <vakul.garg@nxp.com>
	Reviewed-by: Boris Pismenny <borisp@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 4504ab0e6eb801555368cbb3011ab0530f659d4b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/tls/tls_device.c
#	net/tls/tls_main.c
diff --cc net/tls/tls_device.c
index be826fc2113a,135a7ee9db03..000000000000
--- a/net/tls/tls_device.c
+++ b/net/tls/tls_device.c
@@@ -542,6 -546,20 +542,23 @@@ static int tls_device_push_pending_reco
  	return tls_push_data(sk, &msg_iter, 0, flags, TLS_RECORD_TYPE_DATA);
  }
  
++<<<<<<< HEAD
++=======
+ void tls_device_write_space(struct sock *sk, struct tls_context *ctx)
+ {
+ 	int rc = 0;
+ 
+ 	if (!sk->sk_write_pending && tls_is_partially_sent_record(ctx)) {
+ 		gfp_t sk_allocation = sk->sk_allocation;
+ 
+ 		sk->sk_allocation = GFP_ATOMIC;
+ 		rc = tls_push_partial_record(sk, ctx,
+ 					     MSG_DONTWAIT | MSG_NOSIGNAL);
+ 		sk->sk_allocation = sk_allocation;
+ 	}
+ }
+ 
++>>>>>>> 4504ab0e6eb8 (net/tls: Inform user space about send buffer availability)
  void handle_device_resync(struct sock *sk, u32 seq, u64 rcd_sn)
  {
  	struct tls_context *tls_ctx = tls_get_ctx(sk);
diff --cc net/tls/tls_main.c
index a0dcca82c8b9,df921a2904b9..000000000000
--- a/net/tls/tls_main.c
+++ b/net/tls/tls_main.c
@@@ -232,12 -221,12 +231,21 @@@ static void tls_write_space(struct soc
  		return;
  	}
  
++<<<<<<< HEAD
 +	/* Schedule the transmission if tx list is ready */
 +	if (is_tx_ready(tx_ctx) && !sk->sk_write_pending) {
 +		/* Schedule the transmission */
 +		if (!test_and_set_bit(BIT_TX_SCHEDULED, &tx_ctx->tx_bitmask))
 +			schedule_delayed_work(&tx_ctx->tx_work.work, 0);
 +	}
++=======
+ #ifdef CONFIG_TLS_DEVICE
+ 	if (ctx->tx_conf == TLS_HW)
+ 		tls_device_write_space(sk, ctx);
+ 	else
+ #endif
+ 		tls_sw_write_space(sk, ctx);
++>>>>>>> 4504ab0e6eb8 (net/tls: Inform user space about send buffer availability)
  
  	ctx->sk_write_space(sk);
  }
* Unmerged path net/tls/tls_device.c
* Unmerged path net/tls/tls_main.c
