vhost_net: fix possible infinite loop

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Jason Wang <jasowang@redhat.com>
commit e2412c07f8f3040593dfb88207865a3cd58680c0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/e2412c07.failed

When the rx buffer is too small for a packet, we will discard the vq
descriptor and retry it for the next packet:

while ((sock_len = vhost_net_rx_peek_head_len(net, sock->sk,
					      &busyloop_intr))) {
...
	/* On overrun, truncate and discard */
	if (unlikely(headcount > UIO_MAXIOV)) {
		iov_iter_init(&msg.msg_iter, READ, vq->iov, 1, 1);
		err = sock->ops->recvmsg(sock, &msg,
					 1, MSG_DONTWAIT | MSG_TRUNC);
		pr_debug("Discarded rx packet: len %zd\n", sock_len);
		continue;
	}
...
}

This makes it possible to trigger a infinite while..continue loop
through the co-opreation of two VMs like:

1) Malicious VM1 allocate 1 byte rx buffer and try to slow down the
   vhost process as much as possible e.g using indirect descriptors or
   other.
2) Malicious VM2 generate packets to VM1 as fast as possible

Fixing this by checking against weight at the end of RX and TX
loop. This also eliminate other similar cases when:

- userspace is consuming the packets in the meanwhile
- theoretical TOCTOU attack if guest moving avail index back and forth
  to hit the continue after vhost find guest just add new buffers

This addresses CVE-2019-3900.

Fixes: d8316f3991d20 ("vhost: fix total length when packets are too short")
Fixes: 3a4d5c94e9593 ("vhost_net: a kernel-level virtio server")
	Signed-off-by: Jason Wang <jasowang@redhat.com>
	Reviewed-by: Stefan Hajnoczi <stefanha@redhat.com>
	Signed-off-by: Michael S. Tsirkin <mst@redhat.com>
(cherry picked from commit e2412c07f8f3040593dfb88207865a3cd58680c0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/vhost/net.c
diff --cc drivers/vhost/net.c
index 30184f9971bd,2d9df786a9d3..000000000000
--- a/drivers/vhost/net.c
+++ b/drivers/vhost/net.c
@@@ -845,11 -839,7 +845,15 @@@ done
  		vq->heads[nvq->done_idx].id = cpu_to_vhost32(vq, head);
  		vq->heads[nvq->done_idx].len = 0;
  		++nvq->done_idx;
++<<<<<<< HEAD
 +		if (vhost_exceeds_weight(++sent_pkts, total_len)) {
 +			vhost_poll_queue(&vq->poll);
 +			break;
 +		}
 +	}
++=======
+ 	} while (likely(!vhost_exceeds_weight(vq, ++sent_pkts, total_len)));
++>>>>>>> e2412c07f8f3 (vhost_net: fix possible infinite loop)
  
  	vhost_tx_batch(net, nvq, sock, &msg);
  }
@@@ -951,11 -941,7 +955,15 @@@ static void handle_tx_zerocopy(struct v
  		else
  			vhost_zerocopy_signal_used(net, vq);
  		vhost_net_tx_packet(net);
++<<<<<<< HEAD
 +		if (unlikely(vhost_exceeds_weight(++sent_pkts, total_len))) {
 +			vhost_poll_queue(&vq->poll);
 +			break;
 +		}
 +	}
++=======
+ 	} while (likely(!vhost_exceeds_weight(vq, ++sent_pkts, total_len)));
++>>>>>>> e2412c07f8f3 (vhost_net: fix possible infinite loop)
  }
  
  /* Expects to be always run from workqueue - which acts as
@@@ -1239,14 -1228,11 +1250,19 @@@ static void handle_rx(struct vhost_net 
  			vhost_log_write(vq, vq_log, log, vhost_len,
  					vq->iov, in);
  		total_len += vhost_len;
++<<<<<<< HEAD
 +		if (unlikely(vhost_exceeds_weight(++recv_pkts, total_len))) {
 +			vhost_poll_queue(&vq->poll);
 +			goto out;
 +		}
 +	}
++=======
+ 	} while (likely(!vhost_exceeds_weight(vq, ++recv_pkts, total_len)));
+ 
++>>>>>>> e2412c07f8f3 (vhost_net: fix possible infinite loop)
  	if (unlikely(busyloop_intr))
  		vhost_poll_queue(&vq->poll);
- 	else
+ 	else if (!sock_len)
  		vhost_net_enable_vq(net, vq);
  out:
  	vhost_net_signal_used(nvq);
@@@ -1338,7 -1324,8 +1354,12 @@@ static int vhost_net_open(struct inode 
  		vhost_net_buf_init(&n->vqs[i].rxq);
  	}
  	vhost_dev_init(dev, vqs, VHOST_NET_VQ_MAX,
++<<<<<<< HEAD
 +		       UIO_MAXIOV + VHOST_RX_BATCH);
++=======
+ 		       UIO_MAXIOV + VHOST_NET_BATCH,
+ 		       VHOST_NET_PKT_WEIGHT, VHOST_NET_WEIGHT);
++>>>>>>> e2412c07f8f3 (vhost_net: fix possible infinite loop)
  
  	vhost_poll_init(n->poll + VHOST_NET_VQ_TX, handle_tx_net, EPOLLOUT, dev);
  	vhost_poll_init(n->poll + VHOST_NET_VQ_RX, handle_rx_net, EPOLLIN, dev);
* Unmerged path drivers/vhost/net.c
