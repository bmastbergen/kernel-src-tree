net/tls: handle errors from padding_length()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
Rebuild_CHGLOG: - [net] tls: handle errors from padding_length() (Sabrina Dubroca) [1711821]
Rebuild_FUZZ: 95.24%
commit-author Jakub Kicinski <jakub.kicinski@netronome.com>
commit b53f4976fb1f738573b5b76e21d3c2652fffb46b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/b53f4976.failed

At the time padding_length() is called the record header
is still part of the message.  If malicious TLS 1.3 peer
sends an all-zero record padding_length() will stop at
the record header, and return full length of the data
including the tail_size.

Subsequent subtraction of prot->overhead_size from rxm->full_len
will cause rxm->full_len to turn negative.  skb accessors,
however, will always catch resulting out-of-bounds operation,
so in practice this fix comes down to returning the correct
error code.  It also fixes a set but not used warning.

This code was added by commit 130b392c6cd6 ("net: tls: Add tls 1.3 support").

CC: Dave Watson <davejwatson@fb.com>
	Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
	Reviewed-by: Dirk van der Merwe <dirk.vandermerwe@netronome.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit b53f4976fb1f738573b5b76e21d3c2652fffb46b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/tls/tls_sw.c
diff --cc net/tls/tls_sw.c
index 3f443983a6b3,d93f83f77864..000000000000
--- a/net/tls/tls_sw.c
+++ b/net/tls/tls_sw.c
@@@ -119,6 -118,36 +119,39 @@@ static int skb_nsg(struct sk_buff *skb
          return __skb_nsg(skb, offset, len, 0);
  }
  
++<<<<<<< HEAD
++=======
+ static int padding_length(struct tls_sw_context_rx *ctx,
+ 			  struct tls_prot_info *prot, struct sk_buff *skb)
+ {
+ 	struct strp_msg *rxm = strp_msg(skb);
+ 	int sub = 0;
+ 
+ 	/* Determine zero-padding length */
+ 	if (prot->version == TLS_1_3_VERSION) {
+ 		char content_type = 0;
+ 		int err;
+ 		int back = 17;
+ 
+ 		while (content_type == 0) {
+ 			if (back > rxm->full_len - prot->prepend_size)
+ 				return -EBADMSG;
+ 			err = skb_copy_bits(skb,
+ 					    rxm->offset + rxm->full_len - back,
+ 					    &content_type, 1);
+ 			if (err)
+ 				return err;
+ 			if (content_type)
+ 				break;
+ 			sub++;
+ 			back++;
+ 		}
+ 		ctx->control = content_type;
+ 	}
+ 	return sub;
+ }
+ 
++>>>>>>> b53f4976fb1f (net/tls: handle errors from padding_length())
  static void tls_decrypt_done(struct crypto_async_request *req, int err)
  {
  	struct aead_request *aead_req = (struct aead_request *)req;
@@@ -139,6 -170,19 +172,22 @@@
  	if (err) {
  		ctx->async_wait.err = err;
  		tls_err_abort(skb->sk, err);
++<<<<<<< HEAD
++=======
+ 	} else {
+ 		struct strp_msg *rxm = strp_msg(skb);
+ 		int pad;
+ 
+ 		pad = padding_length(ctx, prot, skb);
+ 		if (pad < 0) {
+ 			ctx->async_wait.err = pad;
+ 			tls_err_abort(skb->sk, pad);
+ 		} else {
+ 			rxm->full_len -= pad;
+ 			rxm->offset += prot->prepend_size;
+ 			rxm->full_len -= prot->overhead_size;
+ 		}
++>>>>>>> b53f4976fb1f (net/tls: handle errors from padding_length())
  	}
  
  	/* After using skb->sk to propagate sk through crypto async callback
@@@ -1226,22 -1485,42 +1275,36 @@@ static int decrypt_skb_update(struct so
  {
  	struct tls_context *tls_ctx = tls_get_ctx(sk);
  	struct tls_sw_context_rx *ctx = tls_sw_ctx_rx(tls_ctx);
 -	struct tls_prot_info *prot = &tls_ctx->prot_info;
 -	int version = prot->version;
  	struct strp_msg *rxm = strp_msg(skb);
- 	int err = 0;
+ 	int pad, err = 0;
  
 -	if (!ctx->decrypted) {
  #ifdef CONFIG_TLS_DEVICE
 -		err = tls_device_decrypted(sk, skb);
 -		if (err < 0)
 -			return err;
 +	err = tls_device_decrypted(sk, skb);
 +	if (err < 0)
 +		return err;
  #endif
 -		/* Still not decrypted after tls_device */
 -		if (!ctx->decrypted) {
 -			err = decrypt_internal(sk, skb, dest, NULL, chunk, zc,
 -					       async);
 -			if (err < 0) {
 -				if (err == -EINPROGRESS)
 -					tls_advance_record_sn(sk, &tls_ctx->rx,
 -							      version);
 +	if (!ctx->decrypted) {
 +		err = decrypt_internal(sk, skb, dest, NULL, chunk, zc);
 +		if (err < 0) {
 +			if (err == -EINPROGRESS)
 +				tls_advance_record_sn(sk, &tls_ctx->rx);
  
 -				return err;
 -			}
 -		} else {
 -			*zc = false;
 +			return err;
  		}
++<<<<<<< HEAD
++=======
+ 
+ 		pad = padding_length(ctx, prot, skb);
+ 		if (pad < 0)
+ 			return pad;
+ 
+ 		rxm->full_len -= pad;
+ 		rxm->offset += prot->prepend_size;
+ 		rxm->full_len -= prot->overhead_size;
+ 		tls_advance_record_sn(sk, &tls_ctx->rx, version);
+ 		ctx->decrypted = true;
+ 		ctx->saved_data_ready(sk);
++>>>>>>> b53f4976fb1f (net/tls: handle errors from padding_length())
  	} else {
  		*zc = false;
  	}
* Unmerged path net/tls/tls_sw.c
