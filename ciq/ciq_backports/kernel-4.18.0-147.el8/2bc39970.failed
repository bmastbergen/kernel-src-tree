x86/kvm/hyper-v: Introduce KVM_GET_SUPPORTED_HV_CPUID

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Vitaly Kuznetsov <vkuznets@redhat.com>
commit 2bc39970e9327ceb06cb210f86ba35f81d00e350
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/2bc39970.failed

With every new Hyper-V Enlightenment we implement we're forced to add a
KVM_CAP_HYPERV_* capability. While this approach works it is fairly
inconvenient: the majority of the enlightenments we do have corresponding
CPUID feature bit(s) and userspace has to know this anyways to be able to
expose the feature to the guest.

Add KVM_GET_SUPPORTED_HV_CPUID ioctl (backed by KVM_CAP_HYPERV_CPUID, "one
cap to rule them all!") returning all Hyper-V CPUID feature leaves.

Using the existing KVM_GET_SUPPORTED_CPUID doesn't seem to be possible:
Hyper-V CPUID feature leaves intersect with KVM's (e.g. 0x40000000,
0x40000001) and we would probably confuse userspace in case we decide to
return these twice.

KVM_CAP_HYPERV_CPUID's number is interim: we're intended to drop
KVM_CAP_HYPERV_STIMER_DIRECT and use its number instead.

	Suggested-by: Paolo Bonzini <pbonzini@redhat.com>
	Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 2bc39970e9327ceb06cb210f86ba35f81d00e350)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/virtual/kvm/api.txt
#	arch/x86/kvm/x86.c
#	include/uapi/linux/kvm.h
diff --cc Documentation/virtual/kvm/api.txt
index 0ca352cf876c,356156f5c52d..000000000000
--- a/Documentation/virtual/kvm/api.txt
+++ b/Documentation/virtual/kvm/api.txt
@@@ -3727,8 -3755,107 +3727,112 @@@ Coalesced mmio is used if one or more w
  register can be deferred until a read or a write to another hardware
  register on the same device.  This last access will cause a vmexit and
  userspace will process accesses from the ring buffer before emulating
++<<<<<<< HEAD
 +it. That will avoid exiting to userspace on repeated writes to the
 +first register.
++=======
+ it. That will avoid exiting to userspace on repeated writes.
+ 
+ Coalesced pio is based on coalesced mmio. There is little difference
+ between coalesced mmio and pio except that coalesced pio records accesses
+ to I/O ports.
+ 
+ 4.117 KVM_CLEAR_DIRTY_LOG (vm ioctl)
+ 
+ Capability: KVM_CAP_MANUAL_DIRTY_LOG_PROTECT
+ Architectures: x86
+ Type: vm ioctl
+ Parameters: struct kvm_dirty_log (in)
+ Returns: 0 on success, -1 on error
+ 
+ /* for KVM_CLEAR_DIRTY_LOG */
+ struct kvm_clear_dirty_log {
+ 	__u32 slot;
+ 	__u32 num_pages;
+ 	__u64 first_page;
+ 	union {
+ 		void __user *dirty_bitmap; /* one bit per page */
+ 		__u64 padding;
+ 	};
+ };
+ 
+ The ioctl clears the dirty status of pages in a memory slot, according to
+ the bitmap that is passed in struct kvm_clear_dirty_log's dirty_bitmap
+ field.  Bit 0 of the bitmap corresponds to page "first_page" in the
+ memory slot, and num_pages is the size in bits of the input bitmap.
+ Both first_page and num_pages must be a multiple of 64.  For each bit
+ that is set in the input bitmap, the corresponding page is marked "clean"
+ in KVM's dirty bitmap, and dirty tracking is re-enabled for that page
+ (for example via write-protection, or by clearing the dirty bit in
+ a page table entry).
+ 
+ If KVM_CAP_MULTI_ADDRESS_SPACE is available, bits 16-31 specifies
+ the address space for which you want to return the dirty bitmap.
+ They must be less than the value that KVM_CHECK_EXTENSION returns for
+ the KVM_CAP_MULTI_ADDRESS_SPACE capability.
+ 
+ This ioctl is mostly useful when KVM_CAP_MANUAL_DIRTY_LOG_PROTECT
+ is enabled; for more information, see the description of the capability.
+ However, it can always be used as long as KVM_CHECK_EXTENSION confirms
+ that KVM_CAP_MANUAL_DIRTY_LOG_PROTECT is present.
+ 
+ 4.118 KVM_GET_SUPPORTED_HV_CPUID
+ 
+ Capability: KVM_CAP_HYPERV_CPUID
+ Architectures: x86
+ Type: vcpu ioctl
+ Parameters: struct kvm_cpuid2 (in/out)
+ Returns: 0 on success, -1 on error
+ 
+ struct kvm_cpuid2 {
+ 	__u32 nent;
+ 	__u32 padding;
+ 	struct kvm_cpuid_entry2 entries[0];
+ };
+ 
+ struct kvm_cpuid_entry2 {
+ 	__u32 function;
+ 	__u32 index;
+ 	__u32 flags;
+ 	__u32 eax;
+ 	__u32 ebx;
+ 	__u32 ecx;
+ 	__u32 edx;
+ 	__u32 padding[3];
+ };
+ 
+ This ioctl returns x86 cpuid features leaves related to Hyper-V emulation in
+ KVM.  Userspace can use the information returned by this ioctl to construct
+ cpuid information presented to guests consuming Hyper-V enlightenments (e.g.
+ Windows or Hyper-V guests).
+ 
+ CPUID feature leaves returned by this ioctl are defined by Hyper-V Top Level
+ Functional Specification (TLFS). These leaves can't be obtained with
+ KVM_GET_SUPPORTED_CPUID ioctl because some of them intersect with KVM feature
+ leaves (0x40000000, 0x40000001).
+ 
+ Currently, the following list of CPUID leaves are returned:
+  HYPERV_CPUID_VENDOR_AND_MAX_FUNCTIONS
+  HYPERV_CPUID_INTERFACE
+  HYPERV_CPUID_VERSION
+  HYPERV_CPUID_FEATURES
+  HYPERV_CPUID_ENLIGHTMENT_INFO
+  HYPERV_CPUID_IMPLEMENT_LIMITS
+  HYPERV_CPUID_NESTED_FEATURES
+ 
+ HYPERV_CPUID_NESTED_FEATURES leaf is only exposed when Enlightened VMCS was
+ enabled on the corresponding vCPU (KVM_CAP_HYPERV_ENLIGHTENED_VMCS).
+ 
+ Userspace invokes KVM_GET_SUPPORTED_CPUID by passing a kvm_cpuid2 structure
+ with the 'nent' field indicating the number of entries in the variable-size
+ array 'entries'.  If the number of entries is too low to describe all Hyper-V
+ feature leaves, an error (E2BIG) is returned. If the number is more or equal
+ to the number of Hyper-V feature leaves, the 'nent' field is adjusted to the
+ number of valid entries in the 'entries' array, which is then filled.
+ 
+ 'index' and 'flags' fields in 'struct kvm_cpuid_entry2' are currently reserved,
+ userspace should not expect to get any particular value there.
++>>>>>>> 2bc39970e932 (x86/kvm/hyper-v: Introduce KVM_GET_SUPPORTED_HV_CPUID)
  
  5. The kvm_run structure
  ------------------------
diff --cc arch/x86/kvm/x86.c
index 52729928548f,18b7817af2bc..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -2997,6 -2995,9 +2997,12 @@@ int kvm_vm_ioctl_check_extension(struc
  	case KVM_CAP_HYPERV_VP_INDEX:
  	case KVM_CAP_HYPERV_EVENTFD:
  	case KVM_CAP_HYPERV_TLBFLUSH:
++<<<<<<< HEAD
++=======
+ 	case KVM_CAP_HYPERV_SEND_IPI:
+ 	case KVM_CAP_HYPERV_ENLIGHTENED_VMCS:
+ 	case KVM_CAP_HYPERV_CPUID:
++>>>>>>> 2bc39970e932 (x86/kvm/hyper-v: Introduce KVM_GET_SUPPORTED_HV_CPUID)
  	case KVM_CAP_PCI_SEGMENT:
  	case KVM_CAP_DEBUGREGS:
  	case KVM_CAP_X86_ROBUST_SINGLESTEP:
diff --cc include/uapi/linux/kvm.h
index a76a9addaa2b,6d4ea4b6c922..000000000000
--- a/include/uapi/linux/kvm.h
+++ b/include/uapi/linux/kvm.h
@@@ -964,7 -981,13 +964,12 @@@ struct kvm_ppc_resize_hpt 
  #define KVM_CAP_ARM_INJECT_SERROR_ESR 158
  #define KVM_CAP_MSR_PLATFORM_INFO 159
  #define KVM_CAP_PPC_NESTED_HV 160
 -#define KVM_CAP_HYPERV_SEND_IPI 161
 -#define KVM_CAP_COALESCED_PIO 162
 -#define KVM_CAP_HYPERV_ENLIGHTENED_VMCS 163
 -#define KVM_CAP_EXCEPTION_PAYLOAD 164
  #define KVM_CAP_ARM_VM_IPA_SIZE 165
++<<<<<<< HEAD
++=======
+ #define KVM_CAP_MANUAL_DIRTY_LOG_PROTECT 166
+ #define KVM_CAP_HYPERV_CPUID 167
++>>>>>>> 2bc39970e932 (x86/kvm/hyper-v: Introduce KVM_GET_SUPPORTED_HV_CPUID)
  
  #ifdef KVM_CAP_IRQ_ROUTING
  
@@@ -1411,6 -1434,12 +1416,15 @@@ struct kvm_enc_region 
  #define KVM_GET_NESTED_STATE         _IOWR(KVMIO, 0xbe, struct kvm_nested_state)
  #define KVM_SET_NESTED_STATE         _IOW(KVMIO,  0xbf, struct kvm_nested_state)
  
++<<<<<<< HEAD
++=======
+ /* Available with KVM_CAP_MANUAL_DIRTY_LOG_PROTECT */
+ #define KVM_CLEAR_DIRTY_LOG          _IOWR(KVMIO, 0xc0, struct kvm_clear_dirty_log)
+ 
+ /* Available with KVM_CAP_HYPERV_CPUID */
+ #define KVM_GET_SUPPORTED_HV_CPUID _IOWR(KVMIO, 0xc1, struct kvm_cpuid2)
+ 
++>>>>>>> 2bc39970e932 (x86/kvm/hyper-v: Introduce KVM_GET_SUPPORTED_HV_CPUID)
  /* Secure Encrypted Virtualization command */
  enum sev_cmd_id {
  	/* Guest initialization commands */
* Unmerged path Documentation/virtual/kvm/api.txt
diff --git a/arch/x86/kvm/hyperv.c b/arch/x86/kvm/hyperv.c
index a9b4eb3be2e4..09b11291c393 100644
--- a/arch/x86/kvm/hyperv.c
+++ b/arch/x86/kvm/hyperv.c
@@ -1668,3 +1668,124 @@ int kvm_vm_ioctl_hv_eventfd(struct kvm *kvm, struct kvm_hyperv_eventfd *args)
 		return kvm_hv_eventfd_deassign(kvm, args->conn_id);
 	return kvm_hv_eventfd_assign(kvm, args->conn_id, args->fd);
 }
+
+int kvm_vcpu_ioctl_get_hv_cpuid(struct kvm_vcpu *vcpu, struct kvm_cpuid2 *cpuid,
+				struct kvm_cpuid_entry2 __user *entries)
+{
+	uint16_t evmcs_ver = kvm_x86_ops->nested_get_evmcs_version(vcpu);
+	struct kvm_cpuid_entry2 cpuid_entries[] = {
+		{ .function = HYPERV_CPUID_VENDOR_AND_MAX_FUNCTIONS },
+		{ .function = HYPERV_CPUID_INTERFACE },
+		{ .function = HYPERV_CPUID_VERSION },
+		{ .function = HYPERV_CPUID_FEATURES },
+		{ .function = HYPERV_CPUID_ENLIGHTMENT_INFO },
+		{ .function = HYPERV_CPUID_IMPLEMENT_LIMITS },
+		{ .function = HYPERV_CPUID_NESTED_FEATURES },
+	};
+	int i, nent = ARRAY_SIZE(cpuid_entries);
+
+	/* Skip NESTED_FEATURES if eVMCS is not supported */
+	if (!evmcs_ver)
+		--nent;
+
+	if (cpuid->nent < nent)
+		return -E2BIG;
+
+	if (cpuid->nent > nent)
+		cpuid->nent = nent;
+
+	for (i = 0; i < nent; i++) {
+		struct kvm_cpuid_entry2 *ent = &cpuid_entries[i];
+		u32 signature[3];
+
+		switch (ent->function) {
+		case HYPERV_CPUID_VENDOR_AND_MAX_FUNCTIONS:
+			memcpy(signature, "Linux KVM Hv", 12);
+
+			ent->eax = HYPERV_CPUID_NESTED_FEATURES;
+			ent->ebx = signature[0];
+			ent->ecx = signature[1];
+			ent->edx = signature[2];
+			break;
+
+		case HYPERV_CPUID_INTERFACE:
+			memcpy(signature, "Hv#1\0\0\0\0\0\0\0\0", 12);
+			ent->eax = signature[0];
+			break;
+
+		case HYPERV_CPUID_VERSION:
+			/*
+			 * We implement some Hyper-V 2016 functions so let's use
+			 * this version.
+			 */
+			ent->eax = 0x00003839;
+			ent->ebx = 0x000A0000;
+			break;
+
+		case HYPERV_CPUID_FEATURES:
+			ent->eax |= HV_X64_MSR_VP_RUNTIME_AVAILABLE;
+			ent->eax |= HV_MSR_TIME_REF_COUNT_AVAILABLE;
+			ent->eax |= HV_X64_MSR_SYNIC_AVAILABLE;
+			ent->eax |= HV_MSR_SYNTIMER_AVAILABLE;
+			ent->eax |= HV_X64_MSR_APIC_ACCESS_AVAILABLE;
+			ent->eax |= HV_X64_MSR_HYPERCALL_AVAILABLE;
+			ent->eax |= HV_X64_MSR_VP_INDEX_AVAILABLE;
+			ent->eax |= HV_X64_MSR_RESET_AVAILABLE;
+			ent->eax |= HV_MSR_REFERENCE_TSC_AVAILABLE;
+			ent->eax |= HV_X64_MSR_GUEST_IDLE_AVAILABLE;
+			ent->eax |= HV_X64_ACCESS_FREQUENCY_MSRS;
+			ent->eax |= HV_X64_ACCESS_REENLIGHTENMENT;
+
+			ent->ebx |= HV_X64_POST_MESSAGES;
+			ent->ebx |= HV_X64_SIGNAL_EVENTS;
+
+			ent->edx |= HV_FEATURE_FREQUENCY_MSRS_AVAILABLE;
+			ent->edx |= HV_FEATURE_GUEST_CRASH_MSR_AVAILABLE;
+			ent->edx |= HV_STIMER_DIRECT_MODE_AVAILABLE;
+
+			break;
+
+		case HYPERV_CPUID_ENLIGHTMENT_INFO:
+			ent->eax |= HV_X64_REMOTE_TLB_FLUSH_RECOMMENDED;
+			ent->eax |= HV_X64_APIC_ACCESS_RECOMMENDED;
+			ent->eax |= HV_X64_SYSTEM_RESET_RECOMMENDED;
+			ent->eax |= HV_X64_RELAXED_TIMING_RECOMMENDED;
+			ent->eax |= HV_X64_CLUSTER_IPI_RECOMMENDED;
+			ent->eax |= HV_X64_EX_PROCESSOR_MASKS_RECOMMENDED;
+			ent->eax |= HV_X64_ENLIGHTENED_VMCS_RECOMMENDED;
+
+			/*
+			 * Default number of spinlock retry attempts, matches
+			 * HyperV 2016.
+			 */
+			ent->ebx = 0x00000FFF;
+
+			break;
+
+		case HYPERV_CPUID_IMPLEMENT_LIMITS:
+			/* Maximum number of virtual processors */
+			ent->eax = KVM_MAX_VCPUS;
+			/*
+			 * Maximum number of logical processors, matches
+			 * HyperV 2016.
+			 */
+			ent->ebx = 64;
+
+			break;
+
+		case HYPERV_CPUID_NESTED_FEATURES:
+			ent->eax = evmcs_ver;
+
+			break;
+
+		default:
+			break;
+		}
+	}
+
+	if (copy_to_user(entries, cpuid_entries,
+			 nent * sizeof(struct kvm_cpuid_entry2)))
+		return -EFAULT;
+
+	return 0;
+}
diff --git a/arch/x86/kvm/hyperv.h b/arch/x86/kvm/hyperv.h
index 9c21c3479899..fd7cf13a2144 100644
--- a/arch/x86/kvm/hyperv.h
+++ b/arch/x86/kvm/hyperv.h
@@ -97,5 +97,7 @@ void kvm_hv_setup_tsc_page(struct kvm *kvm,
 void kvm_hv_init_vm(struct kvm *kvm);
 void kvm_hv_destroy_vm(struct kvm *kvm);
 int kvm_vm_ioctl_hv_eventfd(struct kvm *kvm, struct kvm_hyperv_eventfd *args);
+int kvm_vcpu_ioctl_get_hv_cpuid(struct kvm_vcpu *vcpu, struct kvm_cpuid2 *cpuid,
+				struct kvm_cpuid_entry2 __user *entries);
 
 #endif
* Unmerged path arch/x86/kvm/x86.c
* Unmerged path include/uapi/linux/kvm.h
