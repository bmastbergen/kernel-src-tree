bpf: sk_msg program helper bpf_msg_push_data

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author John Fastabend <john.fastabend@gmail.com>
commit 6fff607e2f14bd7c63c06c464a6f93b8efbabe28
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/6fff607e.failed

This allows user to push data into a msg using sk_msg program types.
The format is as follows,

	bpf_msg_push_data(msg, offset, len, flags)

this will insert 'len' bytes at offset 'offset'. For example to
prepend 10 bytes at the front of the message the user can,

	bpf_msg_push_data(msg, 0, 10, 0);

This will invalidate data bounds so BPF user will have to then recheck
data bounds after calling this. After this the msg size will have been
updated and the user is free to write into the added bytes. We allow
any offset/len as long as it is within the (data, data_end) range.
However, a copy will be required if the ring is full and its possible
for the helper to fail with ENOMEM or EINVAL errors which need to be
handled by the BPF program.

This can be used similar to XDP metadata to pass data between sk_msg
layer and lower layers.

	Signed-off-by: John Fastabend <john.fastabend@gmail.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
(cherry picked from commit 6fff607e2f14bd7c63c06c464a6f93b8efbabe28)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/skmsg.h
#	include/uapi/linux/bpf.h
diff --cc include/uapi/linux/bpf.h
index 11269f3807ea,852dc17ab47a..000000000000
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@@ -2118,6 -2161,102 +2118,105 @@@ union bpf_attr 
   *		the shared data.
   *	Return
   *		Pointer to the local storage area.
++<<<<<<< HEAD
++=======
+  *
+  * int bpf_sk_select_reuseport(struct sk_reuseport_md *reuse, struct bpf_map *map, void *key, u64 flags)
+  *	Description
+  *		Select a SO_REUSEPORT sk from a	BPF_MAP_TYPE_REUSEPORT_ARRAY map
+  *		It checks the selected sk is matching the incoming
+  *		request in the skb.
+  *	Return
+  *		0 on success, or a negative error in case of failure.
+  *
+  * struct bpf_sock *bpf_sk_lookup_tcp(void *ctx, struct bpf_sock_tuple *tuple, u32 tuple_size, u32 netns, u64 flags)
+  *	Description
+  *		Look for TCP socket matching *tuple*, optionally in a child
+  *		network namespace *netns*. The return value must be checked,
+  *		and if non-NULL, released via **bpf_sk_release**\ ().
+  *
+  *		The *ctx* should point to the context of the program, such as
+  *		the skb or socket (depending on the hook in use). This is used
+  *		to determine the base network namespace for the lookup.
+  *
+  *		*tuple_size* must be one of:
+  *
+  *		**sizeof**\ (*tuple*\ **->ipv4**)
+  *			Look for an IPv4 socket.
+  *		**sizeof**\ (*tuple*\ **->ipv6**)
+  *			Look for an IPv6 socket.
+  *
+  *		If the *netns* is zero, then the socket lookup table in the
+  *		netns associated with the *ctx* will be used. For the TC hooks,
+  *		this in the netns of the device in the skb. For socket hooks,
+  *		this in the netns of the socket. If *netns* is non-zero, then
+  *		it specifies the ID of the netns relative to the netns
+  *		associated with the *ctx*.
+  *
+  *		All values for *flags* are reserved for future usage, and must
+  *		be left at zero.
+  *
+  *		This helper is available only if the kernel was compiled with
+  *		**CONFIG_NET** configuration option.
+  *	Return
+  *		Pointer to *struct bpf_sock*, or NULL in case of failure.
+  *
+  * struct bpf_sock *bpf_sk_lookup_udp(void *ctx, struct bpf_sock_tuple *tuple, u32 tuple_size, u32 netns, u64 flags)
+  *	Description
+  *		Look for UDP socket matching *tuple*, optionally in a child
+  *		network namespace *netns*. The return value must be checked,
+  *		and if non-NULL, released via **bpf_sk_release**\ ().
+  *
+  *		The *ctx* should point to the context of the program, such as
+  *		the skb or socket (depending on the hook in use). This is used
+  *		to determine the base network namespace for the lookup.
+  *
+  *		*tuple_size* must be one of:
+  *
+  *		**sizeof**\ (*tuple*\ **->ipv4**)
+  *			Look for an IPv4 socket.
+  *		**sizeof**\ (*tuple*\ **->ipv6**)
+  *			Look for an IPv6 socket.
+  *
+  *		If the *netns* is zero, then the socket lookup table in the
+  *		netns associated with the *ctx* will be used. For the TC hooks,
+  *		this in the netns of the device in the skb. For socket hooks,
+  *		this in the netns of the socket. If *netns* is non-zero, then
+  *		it specifies the ID of the netns relative to the netns
+  *		associated with the *ctx*.
+  *
+  *		All values for *flags* are reserved for future usage, and must
+  *		be left at zero.
+  *
+  *		This helper is available only if the kernel was compiled with
+  *		**CONFIG_NET** configuration option.
+  *	Return
+  *		Pointer to *struct bpf_sock*, or NULL in case of failure.
+  *
+  * int bpf_sk_release(struct bpf_sock *sk)
+  *	Description
+  *		Release the reference held by *sock*. *sock* must be a non-NULL
+  *		pointer that was returned from bpf_sk_lookup_xxx\ ().
+  *	Return
+  *		0 on success, or a negative error in case of failure.
+  *
+  * int bpf_msg_push_data(struct sk_buff *skb, u32 start, u32 len, u64 flags)
+  *	Description
+  *		For socket policies, insert *len* bytes into msg at offset
+  *		*start*.
+  *
+  *		If a program of type **BPF_PROG_TYPE_SK_MSG** is run on a
+  *		*msg* it may want to insert metadata or options into the msg.
+  *		This can later be read and used by any of the lower layer BPF
+  *		hooks.
+  *
+  *		This helper may fail if under memory pressure (a malloc
+  *		fails) in these cases BPF programs will get an appropriate
+  *		error and BPF programs will need to handle them.
+  *
+  *	Return
+  *		0 on success, or a negative error in case of failure.
++>>>>>>> 6fff607e2f14 (bpf: sk_msg program helper bpf_msg_push_data)
   */
  #define __BPF_FUNC_MAPPER(FN)		\
  	FN(unspec),			\
@@@ -2201,7 -2340,16 +2300,20 @@@
  	FN(rc_keydown),			\
  	FN(skb_cgroup_id),		\
  	FN(get_current_cgroup_id),	\
++<<<<<<< HEAD
 +	FN(get_local_storage),
++=======
+ 	FN(get_local_storage),		\
+ 	FN(sk_select_reuseport),	\
+ 	FN(skb_ancestor_cgroup_id),	\
+ 	FN(sk_lookup_tcp),		\
+ 	FN(sk_lookup_udp),		\
+ 	FN(sk_release),			\
+ 	FN(map_push_elem),		\
+ 	FN(map_pop_elem),		\
+ 	FN(map_peek_elem),		\
+ 	FN(msg_push_data),
++>>>>>>> 6fff607e2f14 (bpf: sk_msg program helper bpf_msg_push_data)
  
  /* integer value in 'imm' field of BPF_CALL instruction selects which helper
   * function eBPF program intends to call
* Unmerged path include/linux/skmsg.h
* Unmerged path include/linux/skmsg.h
* Unmerged path include/uapi/linux/bpf.h
diff --git a/net/core/filter.c b/net/core/filter.c
index ed8de8b22015..6853c274fdfa 100644
--- a/net/core/filter.c
+++ b/net/core/filter.c
@@ -2407,6 +2407,137 @@ static const struct bpf_func_proto bpf_msg_pull_data_proto = {
 	.arg4_type	= ARG_ANYTHING,
 };
 
+BPF_CALL_4(bpf_msg_push_data, struct sk_msg *, msg, u32, start,
+	   u32, len, u64, flags)
+{
+	struct scatterlist sge, nsge, nnsge, rsge = {0}, *psge;
+	u32 new, i = 0, l, space, copy = 0, offset = 0;
+	u8 *raw, *to, *from;
+	struct page *page;
+
+	if (unlikely(flags))
+		return -EINVAL;
+
+	/* First find the starting scatterlist element */
+	i = msg->sg.start;
+	do {
+		l = sk_msg_elem(msg, i)->length;
+
+		if (start < offset + l)
+			break;
+		offset += l;
+		sk_msg_iter_var_next(i);
+	} while (i != msg->sg.end);
+
+	if (start >= offset + l)
+		return -EINVAL;
+
+	space = MAX_MSG_FRAGS - sk_msg_elem_used(msg);
+
+	/* If no space available will fallback to copy, we need at
+	 * least one scatterlist elem available to push data into
+	 * when start aligns to the beginning of an element or two
+	 * when it falls inside an element. We handle the start equals
+	 * offset case because its the common case for inserting a
+	 * header.
+	 */
+	if (!space || (space == 1 && start != offset))
+		copy = msg->sg.data[i].length;
+
+	page = alloc_pages(__GFP_NOWARN | GFP_ATOMIC | __GFP_COMP,
+			   get_order(copy + len));
+	if (unlikely(!page))
+		return -ENOMEM;
+
+	if (copy) {
+		int front, back;
+
+		raw = page_address(page);
+
+		psge = sk_msg_elem(msg, i);
+		front = start - offset;
+		back = psge->length - front;
+		from = sg_virt(psge);
+
+		if (front)
+			memcpy(raw, from, front);
+
+		if (back) {
+			from += front;
+			to = raw + front + len;
+
+			memcpy(to, from, back);
+		}
+
+		put_page(sg_page(psge));
+	} else if (start - offset) {
+		psge = sk_msg_elem(msg, i);
+		rsge = sk_msg_elem_cpy(msg, i);
+
+		psge->length = start - offset;
+		rsge.length -= psge->length;
+		rsge.offset += start;
+
+		sk_msg_iter_var_next(i);
+		sg_unmark_end(psge);
+		sk_msg_iter_next(msg, end);
+	}
+
+	/* Slot(s) to place newly allocated data */
+	new = i;
+
+	/* Shift one or two slots as needed */
+	if (!copy) {
+		sge = sk_msg_elem_cpy(msg, i);
+
+		sk_msg_iter_var_next(i);
+		sg_unmark_end(&sge);
+		sk_msg_iter_next(msg, end);
+
+		nsge = sk_msg_elem_cpy(msg, i);
+		if (rsge.length) {
+			sk_msg_iter_var_next(i);
+			nnsge = sk_msg_elem_cpy(msg, i);
+		}
+
+		while (i != msg->sg.end) {
+			msg->sg.data[i] = sge;
+			sge = nsge;
+			sk_msg_iter_var_next(i);
+			if (rsge.length) {
+				nsge = nnsge;
+				nnsge = sk_msg_elem_cpy(msg, i);
+			} else {
+				nsge = sk_msg_elem_cpy(msg, i);
+			}
+		}
+	}
+
+	/* Place newly allocated data buffer */
+	sk_mem_charge(msg->sk, len);
+	msg->sg.size += len;
+	msg->sg.copy[new] = false;
+	sg_set_page(&msg->sg.data[new], page, len + copy, 0);
+	if (rsge.length) {
+		get_page(sg_page(&rsge));
+		sk_msg_iter_var_next(new);
+		msg->sg.data[new] = rsge;
+	}
+
+	sk_msg_compute_data_pointers(msg);
+	return 0;
+}
+
+static const struct bpf_func_proto bpf_msg_push_data_proto = {
+	.func		= bpf_msg_push_data,
+	.gpl_only	= false,
+	.ret_type	= RET_INTEGER,
+	.arg1_type	= ARG_PTR_TO_CTX,
+	.arg2_type	= ARG_ANYTHING,
+	.arg3_type	= ARG_ANYTHING,
+	.arg4_type	= ARG_ANYTHING,
+};
+
 BPF_CALL_1(bpf_get_cgroup_classid, const struct sk_buff *, skb)
 {
 	return task_get_classid(skb);
@@ -4776,6 +4907,7 @@ bool bpf_helper_changes_pkt_data(void *func)
 	    func == bpf_xdp_adjust_head ||
 	    func == bpf_xdp_adjust_meta ||
 	    func == bpf_msg_pull_data ||
+	    func == bpf_msg_push_data ||
 	    func == bpf_xdp_adjust_tail ||
 #if IS_ENABLED(CONFIG_IPV6_SEG6_BPF)
 	    func == bpf_lwt_seg6_store_bytes ||
@@ -5031,6 +5163,8 @@ sk_msg_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)
 		return &bpf_msg_cork_bytes_proto;
 	case BPF_FUNC_msg_pull_data:
 		return &bpf_msg_pull_data_proto;
+	case BPF_FUNC_msg_push_data:
+		return &bpf_msg_push_data_proto;
 	case BPF_FUNC_get_local_storage:
 		return &bpf_get_local_storage_proto;
 	default:
