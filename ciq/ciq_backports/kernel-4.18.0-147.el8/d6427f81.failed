xarray: Move multiorder account test in-kernel

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Matthew Wilcox <willy@infradead.org>
commit d6427f8179b5dd65eb468c61fc8cc24657c336c9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/d6427f81.failed

Move this test to the in-kernel test suite, and enhance it to test
several different orders.

	Signed-off-by: Matthew Wilcox <willy@infradead.org>
(cherry picked from commit d6427f8179b5dd65eb468c61fc8cc24657c336c9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	lib/test_xarray.c
#	tools/testing/radix-tree/multiorder.c
diff --cc tools/testing/radix-tree/multiorder.c
index 7bf405638b0b,dc27a3da210a..000000000000
--- a/tools/testing/radix-tree/multiorder.c
+++ b/tools/testing/radix-tree/multiorder.c
@@@ -357,274 -356,6 +357,277 @@@ void multiorder_tagged_iteration(void
  	item_kill_tree(&tree);
  }
  
++<<<<<<< HEAD
 +/*
 + * Basic join checks: make sure we can't find an entry in the tree after
 + * a larger entry has replaced it
 + */
 +static void multiorder_join1(unsigned long index,
 +				unsigned order1, unsigned order2)
 +{
 +	unsigned long loc;
 +	void *item, *item2 = item_create(index + 1, order1);
 +	RADIX_TREE(tree, GFP_KERNEL);
 +
 +	item_insert_order(&tree, index, order2);
 +	item = radix_tree_lookup(&tree, index);
 +	radix_tree_join(&tree, index + 1, order1, item2);
 +	loc = find_item(&tree, item);
 +	if (loc == -1)
 +		free(item);
 +	item = radix_tree_lookup(&tree, index + 1);
 +	assert(item == item2);
 +	item_kill_tree(&tree);
 +}
 +
 +/*
 + * Check that the accounting of exceptional entries is handled correctly
 + * by joining an exceptional entry to a normal pointer.
 + */
 +static void multiorder_join2(unsigned order1, unsigned order2)
 +{
 +	RADIX_TREE(tree, GFP_KERNEL);
 +	struct radix_tree_node *node;
 +	void *item1 = item_create(0, order1);
 +	void *item2;
 +
 +	item_insert_order(&tree, 0, order2);
 +	radix_tree_insert(&tree, 1 << order2, (void *)0x12UL);
 +	item2 = __radix_tree_lookup(&tree, 1 << order2, &node, NULL);
 +	assert(item2 == (void *)0x12UL);
 +	assert(node->exceptional == 1);
 +
 +	item2 = radix_tree_lookup(&tree, 0);
 +	free(item2);
 +
 +	radix_tree_join(&tree, 0, order1, item1);
 +	item2 = __radix_tree_lookup(&tree, 1 << order2, &node, NULL);
 +	assert(item2 == item1);
 +	assert(node->exceptional == 0);
 +	item_kill_tree(&tree);
 +}
 +
 +/*
 + * This test revealed an accounting bug for exceptional entries at one point.
 + * Nodes were being freed back into the pool with an elevated exception count
 + * by radix_tree_join() and then radix_tree_split() was failing to zero the
 + * count of exceptional entries.
 + */
 +static void multiorder_join3(unsigned int order)
 +{
 +	RADIX_TREE(tree, GFP_KERNEL);
 +	struct radix_tree_node *node;
 +	void **slot;
 +	struct radix_tree_iter iter;
 +	unsigned long i;
 +
 +	for (i = 0; i < (1 << order); i++) {
 +		radix_tree_insert(&tree, i, (void *)0x12UL);
 +	}
 +
 +	radix_tree_join(&tree, 0, order, (void *)0x16UL);
 +	rcu_barrier();
 +
 +	radix_tree_split(&tree, 0, 0);
 +
 +	radix_tree_for_each_slot(slot, &tree, &iter, 0) {
 +		radix_tree_iter_replace(&tree, &iter, slot, (void *)0x12UL);
 +	}
 +
 +	__radix_tree_lookup(&tree, 0, &node, NULL);
 +	assert(node->exceptional == node->count);
 +
 +	item_kill_tree(&tree);
 +}
 +
 +static void multiorder_join(void)
 +{
 +	int i, j, idx;
 +
 +	for (idx = 0; idx < 1024; idx = idx * 2 + 3) {
 +		for (i = 1; i < 15; i++) {
 +			for (j = 0; j < i; j++) {
 +				multiorder_join1(idx, i, j);
 +			}
 +		}
 +	}
 +
 +	for (i = 1; i < 15; i++) {
 +		for (j = 0; j < i; j++) {
 +			multiorder_join2(i, j);
 +		}
 +	}
 +
 +	for (i = 3; i < 10; i++) {
 +		multiorder_join3(i);
 +	}
 +}
 +
 +static void check_mem(unsigned old_order, unsigned new_order, unsigned alloc)
 +{
 +	struct radix_tree_preload *rtp = &radix_tree_preloads;
 +	if (rtp->nr != 0)
 +		printv(2, "split(%u %u) remaining %u\n", old_order, new_order,
 +							rtp->nr);
 +	/*
 +	 * Can't check for equality here as some nodes may have been
 +	 * RCU-freed while we ran.  But we should never finish with more
 +	 * nodes allocated since they should have all been preloaded.
 +	 */
 +	if (nr_allocated > alloc)
 +		printv(2, "split(%u %u) allocated %u %u\n", old_order, new_order,
 +							alloc, nr_allocated);
 +}
 +
 +static void __multiorder_split(int old_order, int new_order)
 +{
 +	RADIX_TREE(tree, GFP_ATOMIC);
 +	void **slot;
 +	struct radix_tree_iter iter;
 +	unsigned alloc;
 +	struct item *item;
 +
 +	radix_tree_preload(GFP_KERNEL);
 +	assert(item_insert_order(&tree, 0, old_order) == 0);
 +	radix_tree_preload_end();
 +
 +	/* Wipe out the preloaded cache or it'll confuse check_mem() */
 +	radix_tree_cpu_dead(0);
 +
 +	item = radix_tree_tag_set(&tree, 0, 2);
 +
 +	radix_tree_split_preload(old_order, new_order, GFP_KERNEL);
 +	alloc = nr_allocated;
 +	radix_tree_split(&tree, 0, new_order);
 +	check_mem(old_order, new_order, alloc);
 +	radix_tree_for_each_slot(slot, &tree, &iter, 0) {
 +		radix_tree_iter_replace(&tree, &iter, slot,
 +					item_create(iter.index, new_order));
 +	}
 +	radix_tree_preload_end();
 +
 +	item_kill_tree(&tree);
 +	free(item);
 +}
 +
 +static void __multiorder_split2(int old_order, int new_order)
 +{
 +	RADIX_TREE(tree, GFP_KERNEL);
 +	void **slot;
 +	struct radix_tree_iter iter;
 +	struct radix_tree_node *node;
 +	void *item;
 +
 +	__radix_tree_insert(&tree, 0, old_order, (void *)0x12);
 +
 +	item = __radix_tree_lookup(&tree, 0, &node, NULL);
 +	assert(item == (void *)0x12);
 +	assert(node->exceptional > 0);
 +
 +	radix_tree_split(&tree, 0, new_order);
 +	radix_tree_for_each_slot(slot, &tree, &iter, 0) {
 +		radix_tree_iter_replace(&tree, &iter, slot,
 +					item_create(iter.index, new_order));
 +	}
 +
 +	item = __radix_tree_lookup(&tree, 0, &node, NULL);
 +	assert(item != (void *)0x12);
 +	assert(node->exceptional == 0);
 +
 +	item_kill_tree(&tree);
 +}
 +
 +static void __multiorder_split3(int old_order, int new_order)
 +{
 +	RADIX_TREE(tree, GFP_KERNEL);
 +	void **slot;
 +	struct radix_tree_iter iter;
 +	struct radix_tree_node *node;
 +	void *item;
 +
 +	__radix_tree_insert(&tree, 0, old_order, (void *)0x12);
 +
 +	item = __radix_tree_lookup(&tree, 0, &node, NULL);
 +	assert(item == (void *)0x12);
 +	assert(node->exceptional > 0);
 +
 +	radix_tree_split(&tree, 0, new_order);
 +	radix_tree_for_each_slot(slot, &tree, &iter, 0) {
 +		radix_tree_iter_replace(&tree, &iter, slot, (void *)0x16);
 +	}
 +
 +	item = __radix_tree_lookup(&tree, 0, &node, NULL);
 +	assert(item == (void *)0x16);
 +	assert(node->exceptional > 0);
 +
 +	item_kill_tree(&tree);
 +
 +	__radix_tree_insert(&tree, 0, old_order, (void *)0x12);
 +
 +	item = __radix_tree_lookup(&tree, 0, &node, NULL);
 +	assert(item == (void *)0x12);
 +	assert(node->exceptional > 0);
 +
 +	radix_tree_split(&tree, 0, new_order);
 +	radix_tree_for_each_slot(slot, &tree, &iter, 0) {
 +		if (iter.index == (1 << new_order))
 +			radix_tree_iter_replace(&tree, &iter, slot,
 +						(void *)0x16);
 +		else
 +			radix_tree_iter_replace(&tree, &iter, slot, NULL);
 +	}
 +
 +	item = __radix_tree_lookup(&tree, 1 << new_order, &node, NULL);
 +	assert(item == (void *)0x16);
 +	assert(node->count == node->exceptional);
 +	do {
 +		node = node->parent;
 +		if (!node)
 +			break;
 +		assert(node->count == 1);
 +		assert(node->exceptional == 0);
 +	} while (1);
 +
 +	item_kill_tree(&tree);
 +}
 +
 +static void multiorder_split(void)
 +{
 +	int i, j;
 +
 +	for (i = 3; i < 11; i++)
 +		for (j = 0; j < i; j++) {
 +			__multiorder_split(i, j);
 +			__multiorder_split2(i, j);
 +			__multiorder_split3(i, j);
 +		}
 +}
 +
 +static void multiorder_account(void)
 +{
 +	RADIX_TREE(tree, GFP_KERNEL);
 +	struct radix_tree_node *node;
 +	void **slot;
 +
 +	item_insert_order(&tree, 0, 5);
 +
 +	__radix_tree_insert(&tree, 1 << 5, 5, (void *)0x12);
 +	__radix_tree_lookup(&tree, 0, &node, NULL);
 +	assert(node->count == node->exceptional * 2);
 +	radix_tree_delete(&tree, 1 << 5);
 +	assert(node->exceptional == 0);
 +
 +	__radix_tree_insert(&tree, 1 << 5, 5, (void *)0x12);
 +	__radix_tree_lookup(&tree, 1 << 5, &node, &slot);
 +	assert(node->count == node->exceptional * 2);
 +	__radix_tree_replace(&tree, node, slot, NULL, NULL);
 +	assert(node->exceptional == 0);
 +
 +	item_kill_tree(&tree);
 +}
 +
++=======
++>>>>>>> d6427f8179b5 (xarray: Move multiorder account test in-kernel)
  bool stop_iteration = false;
  
  static void *creator_func(void *ptr)
@@@ -703,9 -434,6 +706,12 @@@ void multiorder_checks(void
  	multiorder_tag_tests();
  	multiorder_iteration();
  	multiorder_tagged_iteration();
++<<<<<<< HEAD
 +	multiorder_join();
 +	multiorder_split();
 +	multiorder_account();
++=======
++>>>>>>> d6427f8179b5 (xarray: Move multiorder account test in-kernel)
  	multiorder_iteration_race();
  
  	radix_tree_cpu_dead(0);
* Unmerged path lib/test_xarray.c
* Unmerged path lib/test_xarray.c
* Unmerged path tools/testing/radix-tree/multiorder.c
