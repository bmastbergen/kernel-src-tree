IB/mlx5: Manage device uid for DEVX white list commands

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Yishai Hadas <yishaih@mellanox.com>
commit 76dc5a8406bffabf3f466e331a3e9515ddf93954
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/76dc5a84.failed

Manage device uid for DEVX white list commands.  The created device uid
will be used on white list commands if the user didn't supply its own uid.

This will enable the firmware to filter out non privileged functionality
as of the recognition of the uid.

	Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 76dc5a8406bffabf3f466e331a3e9515ddf93954)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/main.c
#	drivers/infiniband/hw/mlx5/mlx5_ib.h
diff --cc drivers/infiniband/hw/mlx5/main.c
index f0ec543ce522,10e59923e95b..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -1728,14 -1762,20 +1728,21 @@@ static struct ib_ucontext *mlx5_ib_allo
  		/* Block DEVX on Infiniband as of SELinux */
  		if (mlx5_ib_port_link_layer(ibdev, 1) != IB_LINK_LAYER_ETHERNET) {
  			err = -EPERM;
 -			goto out_uars;
 +			goto out_td;
  		}
  
++<<<<<<< HEAD
 +		err = mlx5_ib_devx_create(dev, context);
 +		if (err)
 +			goto out_td;
++=======
+ 		err = mlx5_ib_devx_create(dev);
+ 		if (err < 0)
+ 			goto out_uars;
+ 		context->devx_uid = err;
++>>>>>>> 76dc5a8406bf (IB/mlx5: Manage device uid for DEVX white list commands)
  	}
  
 -	err = mlx5_ib_alloc_transport_domain(dev, &context->tdn,
 -					     context->devx_uid);
 -	if (err)
 -		goto out_devx;
 -
  	if (MLX5_CAP_GEN(dev->mdev, dump_fill_mkey)) {
  		err = mlx5_cmd_dump_fill_mkey(dev->mdev, &dump_fill_mkey);
  		if (err)
@@@ -1828,10 -1868,10 +1835,14 @@@
  	return &context->ibucontext;
  
  out_mdev:
 -	mlx5_ib_dealloc_transport_domain(dev, context->tdn, context->devx_uid);
 -out_devx:
  	if (req.flags & MLX5_IB_ALLOC_UCTX_DEVX)
++<<<<<<< HEAD
 +		mlx5_ib_devx_destroy(dev, context);
 +out_td:
 +	mlx5_ib_dealloc_transport_domain(dev, context->tdn);
++=======
+ 		mlx5_ib_devx_destroy(dev, context->devx_uid);
++>>>>>>> 76dc5a8406bf (IB/mlx5: Manage device uid for DEVX white list commands)
  
  out_uars:
  	deallocate_uars(dev, context);
@@@ -1854,12 -1894,19 +1865,12 @@@ static int mlx5_ib_dealloc_ucontext(str
  	struct mlx5_ib_dev *dev = to_mdev(ibcontext->device);
  	struct mlx5_bfreg_info *bfregi;
  
 -#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
 -	/* All umem's must be destroyed before destroying the ucontext. */
 -	mutex_lock(&ibcontext->per_mm_list_lock);
 -	WARN_ON(!list_empty(&ibcontext->per_mm_list));
 -	mutex_unlock(&ibcontext->per_mm_list_lock);
 -#endif
 -
 -	bfregi = &context->bfregi;
 -	mlx5_ib_dealloc_transport_domain(dev, context->tdn, context->devx_uid);
 -
  	if (context->devx_uid)
- 		mlx5_ib_devx_destroy(dev, context);
+ 		mlx5_ib_devx_destroy(dev, context->devx_uid);
  
 +	bfregi = &context->bfregi;
 +	mlx5_ib_dealloc_transport_domain(dev, context->tdn);
 +
  	deallocate_uars(dev, context);
  	kfree(bfregi->sys_pages);
  	kfree(bfregi->count);
diff --cc drivers/infiniband/hw/mlx5/mlx5_ib.h
index 896390e65822,e5ec3fdaa4d5..000000000000
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@@ -1211,16 -1250,37 +1212,50 @@@ void mlx5_ib_put_native_port_mdev(struc
  				  u8 port_num);
  
  #if IS_ENABLED(CONFIG_INFINIBAND_USER_ACCESS)
++<<<<<<< HEAD
 +int mlx5_ib_devx_create(struct mlx5_ib_dev *dev,
 +			struct mlx5_ib_ucontext *context);
 +void mlx5_ib_devx_destroy(struct mlx5_ib_dev *dev,
 +			  struct mlx5_ib_ucontext *context);
 +#else
 +static inline int
 +mlx5_ib_devx_create(struct mlx5_ib_dev *dev,
 +		    struct mlx5_ib_ucontext *context) { return -EOPNOTSUPP; };
 +static inline void mlx5_ib_devx_destroy(struct mlx5_ib_dev *dev,
 +					struct mlx5_ib_ucontext *context) {}
++=======
+ int mlx5_ib_devx_create(struct mlx5_ib_dev *dev);
+ void mlx5_ib_devx_destroy(struct mlx5_ib_dev *dev, u16 uid);
+ const struct uverbs_object_tree_def *mlx5_ib_get_devx_tree(void);
+ struct mlx5_ib_flow_handler *mlx5_ib_raw_fs_rule_add(
+ 	struct mlx5_ib_dev *dev, struct mlx5_ib_flow_matcher *fs_matcher,
+ 	struct mlx5_flow_act *flow_act, void *cmd_in, int inlen,
+ 	int dest_id, int dest_type);
+ bool mlx5_ib_devx_is_flow_dest(void *obj, int *dest_id, int *dest_type);
+ int mlx5_ib_get_flow_trees(const struct uverbs_object_tree_def **root);
+ void mlx5_ib_destroy_flow_action_raw(struct mlx5_ib_flow_action *maction);
+ #else
+ static inline int
+ mlx5_ib_devx_create(struct mlx5_ib_dev *dev) { return -EOPNOTSUPP; };
+ static inline void mlx5_ib_devx_destroy(struct mlx5_ib_dev *dev, u16 uid) {}
+ static inline const struct uverbs_object_tree_def *
+ mlx5_ib_get_devx_tree(void) { return NULL; }
+ static inline bool mlx5_ib_devx_is_flow_dest(void *obj, int *dest_id,
+ 					     int *dest_type)
+ {
+ 	return false;
+ }
+ static inline int
+ mlx5_ib_get_flow_trees(const struct uverbs_object_tree_def **root)
+ {
+ 	return 0;
+ }
+ static inline void
+ mlx5_ib_destroy_flow_action_raw(struct mlx5_ib_flow_action *maction)
+ {
+ 	return;
+ };
++>>>>>>> 76dc5a8406bf (IB/mlx5: Manage device uid for DEVX white list commands)
  #endif
  static inline void init_query_mad(struct ib_smp *mad)
  {
diff --git a/drivers/infiniband/hw/mlx5/devx.c b/drivers/infiniband/hw/mlx5/devx.c
index c7f8859c08ee..02af34161e62 100644
--- a/drivers/infiniband/hw/mlx5/devx.c
+++ b/drivers/infiniband/hw/mlx5/devx.c
@@ -29,13 +29,14 @@ static struct mlx5_ib_ucontext *devx_ufile2uctx(struct ib_uverbs_file *file)
 	return to_mucontext(ib_uverbs_get_ucontext(file));
 }
 
-int mlx5_ib_devx_create(struct mlx5_ib_dev *dev, struct mlx5_ib_ucontext *context)
+int mlx5_ib_devx_create(struct mlx5_ib_dev *dev)
 {
 	u32 in[MLX5_ST_SZ_DW(create_uctx_in)] = {0};
 	u32 out[MLX5_ST_SZ_DW(general_obj_out_cmd_hdr)] = {0};
 	u64 general_obj_types;
 	void *hdr;
 	int err;
+	u16 uid;
 
 	hdr = MLX5_ADDR_OF(create_uctx_in, in, hdr);
 
@@ -54,19 +55,18 @@ int mlx5_ib_devx_create(struct mlx5_ib_dev *dev, struct mlx5_ib_ucontext *contex
 	if (err)
 		return err;
 
-	context->devx_uid = MLX5_GET(general_obj_out_cmd_hdr, out, obj_id);
-	return 0;
+	uid = MLX5_GET(general_obj_out_cmd_hdr, out, obj_id);
+	return uid;
 }
 
-void mlx5_ib_devx_destroy(struct mlx5_ib_dev *dev,
-			  struct mlx5_ib_ucontext *context)
+void mlx5_ib_devx_destroy(struct mlx5_ib_dev *dev, u16 uid)
 {
 	u32 in[MLX5_ST_SZ_DW(general_obj_in_cmd_hdr)] = {0};
 	u32 out[MLX5_ST_SZ_DW(general_obj_out_cmd_hdr)] = {0};
 
 	MLX5_SET(general_obj_in_cmd_hdr, in, opcode, MLX5_CMD_OP_DESTROY_GENERAL_OBJECT);
 	MLX5_SET(general_obj_in_cmd_hdr, in, obj_type, MLX5_OBJ_TYPE_UCTX);
-	MLX5_SET(general_obj_in_cmd_hdr, in, obj_id, context->devx_uid);
+	MLX5_SET(general_obj_in_cmd_hdr, in, obj_id, uid);
 
 	mlx5_cmd_exec(dev->mdev, in, sizeof(in), out, sizeof(out));
 }
* Unmerged path drivers/infiniband/hw/mlx5/main.c
* Unmerged path drivers/infiniband/hw/mlx5/mlx5_ib.h
