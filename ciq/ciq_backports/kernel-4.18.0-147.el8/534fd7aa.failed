IB/mlx5: Manage indirection mkey upon DEVX flow for ODP

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Yishai Hadas <yishaih@mellanox.com>
commit 534fd7aac56a7994d16032f32123def9923e339f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/534fd7aa.failed

Manage indirection mkey upon DEVX flow to support ODP.

To support a page fault event on the indirection mkey it needs to be part
of the device mkey radix tree.

Both the creation and the deletion flows for a DEVX object which is
indirection mkey were adapted to handle that.

	Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
	Reviewed-by: Artemy Kovalyov <artemyko@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 534fd7aac56a7994d16032f32123def9923e339f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/devx.c
#	drivers/infiniband/hw/mlx5/main.c
diff --cc drivers/infiniband/hw/mlx5/devx.c
index c7f8859c08ee,bbf9a26d8fa6..000000000000
--- a/drivers/infiniband/hw/mlx5/devx.c
+++ b/drivers/infiniband/hw/mlx5/devx.c
@@@ -19,17 -24,36 +23,19 @@@ enum devx_obj_flags 
  #define MLX5_MAX_DESTROY_INBOX_SIZE_DW MLX5_ST_SZ_DW(delete_fte_in)
  struct devx_obj {
  	struct mlx5_core_dev	*mdev;
 -	u64			obj_id;
 +	u32			obj_id;
  	u32			dinlen; /* destroy inbox length */
  	u32			dinbox[MLX5_MAX_DESTROY_INBOX_SIZE_DW];
+ 	u32			flags;
+ 	struct mlx5_ib_devx_mr	devx_mr;
  };
  
 -struct devx_umem {
 -	struct mlx5_core_dev		*mdev;
 -	struct ib_umem			*umem;
 -	u32				page_offset;
 -	int				page_shift;
 -	int				ncont;
 -	u32				dinlen;
 -	u32				dinbox[MLX5_ST_SZ_DW(general_obj_in_cmd_hdr)];
 -};
 -
 -struct devx_umem_reg_cmd {
 -	void				*in;
 -	u32				inlen;
 -	u32				out[MLX5_ST_SZ_DW(general_obj_out_cmd_hdr)];
 -};
 -
 -static struct mlx5_ib_ucontext *
 -devx_ufile2uctx(const struct uverbs_attr_bundle *attrs)
 +static struct mlx5_ib_ucontext *devx_ufile2uctx(struct ib_uverbs_file *file)
  {
 -	return to_mucontext(ib_uverbs_get_ucontext(attrs));
 +	return to_mucontext(ib_uverbs_get_ucontext(file));
  }
  
 -int mlx5_ib_devx_create(struct mlx5_ib_dev *dev, bool is_user)
 +int mlx5_ib_devx_create(struct mlx5_ib_dev *dev, struct mlx5_ib_ucontext *context)
  {
  	u32 in[MLX5_ST_SZ_DW(create_uctx_in)] = {0};
  	u32 out[MLX5_ST_SZ_DW(general_obj_out_cmd_hdr)] = {0};
@@@ -349,6 -1017,94 +355,97 @@@ static void devx_obj_build_destroy_cmd(
  	}
  }
  
++<<<<<<< HEAD
++=======
+ static int devx_handle_mkey_indirect(struct devx_obj *obj,
+ 				     struct mlx5_ib_dev *dev,
+ 				     void *in, void *out)
+ {
+ 	struct mlx5_mkey_table *table = &dev->mdev->priv.mkey_table;
+ 	struct mlx5_ib_devx_mr *devx_mr = &obj->devx_mr;
+ 	unsigned long flags;
+ 	struct mlx5_core_mkey *mkey;
+ 	void *mkc;
+ 	u8 key;
+ 	int err;
+ 
+ 	mkey = &devx_mr->mmkey;
+ 	mkc = MLX5_ADDR_OF(create_mkey_in, in, memory_key_mkey_entry);
+ 	key = MLX5_GET(mkc, mkc, mkey_7_0);
+ 	mkey->key = mlx5_idx_to_mkey(
+ 			MLX5_GET(create_mkey_out, out, mkey_index)) | key;
+ 	mkey->type = MLX5_MKEY_INDIRECT_DEVX;
+ 	mkey->iova = MLX5_GET64(mkc, mkc, start_addr);
+ 	mkey->size = MLX5_GET64(mkc, mkc, len);
+ 	mkey->pd = MLX5_GET(mkc, mkc, pd);
+ 	devx_mr->ndescs = MLX5_GET(mkc, mkc, translations_octword_size);
+ 
+ 	write_lock_irqsave(&table->lock, flags);
+ 	err = radix_tree_insert(&table->tree, mlx5_base_mkey(mkey->key),
+ 				mkey);
+ 	write_unlock_irqrestore(&table->lock, flags);
+ 	return err;
+ }
+ 
+ static int devx_handle_mkey_create(struct mlx5_ib_dev *dev,
+ 				   struct devx_obj *obj,
+ 				   void *in, int in_len)
+ {
+ 	int min_len = MLX5_BYTE_OFF(create_mkey_in, memory_key_mkey_entry) +
+ 			MLX5_FLD_SZ_BYTES(create_mkey_in,
+ 			memory_key_mkey_entry);
+ 	void *mkc;
+ 	u8 access_mode;
+ 
+ 	if (in_len < min_len)
+ 		return -EINVAL;
+ 
+ 	mkc = MLX5_ADDR_OF(create_mkey_in, in, memory_key_mkey_entry);
+ 
+ 	access_mode = MLX5_GET(mkc, mkc, access_mode_1_0);
+ 	access_mode |= MLX5_GET(mkc, mkc, access_mode_4_2) << 2;
+ 
+ 	if (access_mode == MLX5_MKC_ACCESS_MODE_KLMS ||
+ 		access_mode == MLX5_MKC_ACCESS_MODE_KSM) {
+ 		if (IS_ENABLED(CONFIG_INFINIBAND_ON_DEMAND_PAGING))
+ 			obj->flags |= DEVX_OBJ_FLAGS_INDIRECT_MKEY;
+ 		return 0;
+ 	}
+ 
+ 	MLX5_SET(create_mkey_in, in, mkey_umem_valid, 1);
+ 	return 0;
+ }
+ 
+ static void devx_free_indirect_mkey(struct rcu_head *rcu)
+ {
+ 	kfree(container_of(rcu, struct devx_obj, devx_mr.rcu));
+ }
+ 
+ /* This function to delete from the radix tree needs to be called before
+  * destroying the underlying mkey. Otherwise a race might occur in case that
+  * other thread will get the same mkey before this one will be deleted,
+  * in that case it will fail via inserting to the tree its own data.
+  *
+  * Note:
+  * An error in the destroy is not expected unless there is some other indirect
+  * mkey which points to this one. In a kernel cleanup flow it will be just
+  * destroyed in the iterative destruction call. In a user flow, in case
+  * the application didn't close in the expected order it's its own problem,
+  * the mkey won't be part of the tree, in both cases the kernel is safe.
+  */
+ static void devx_cleanup_mkey(struct devx_obj *obj)
+ {
+ 	struct mlx5_mkey_table *table = &obj->mdev->priv.mkey_table;
+ 	struct mlx5_core_mkey *del_mkey;
+ 	unsigned long flags;
+ 
+ 	write_lock_irqsave(&table->lock, flags);
+ 	del_mkey = radix_tree_delete(&table->tree,
+ 				     mlx5_base_mkey(obj->devx_mr.mmkey.key));
+ 	write_unlock_irqrestore(&table->lock, flags);
+ }
+ 
++>>>>>>> 534fd7aac56a (IB/mlx5: Manage indirection mkey upon DEVX flow for ODP)
  static int devx_obj_cleanup(struct ib_uobject *uobject,
  			    enum rdma_remove_reason why)
  {
@@@ -356,10 -1112,21 +453,21 @@@
  	struct devx_obj *obj = uobject->object;
  	int ret;
  
+ 	if (obj->flags & DEVX_OBJ_FLAGS_INDIRECT_MKEY)
+ 		devx_cleanup_mkey(obj);
+ 
  	ret = mlx5_cmd_exec(obj->mdev, obj->dinbox, obj->dinlen, out, sizeof(out));
 -	if (ib_is_destroy_retryable(ret, why, uobject))
 +	if (ret && why == RDMA_REMOVE_DESTROY)
  		return ret;
  
+ 	if (obj->flags & DEVX_OBJ_FLAGS_INDIRECT_MKEY) {
+ 		struct mlx5_ib_dev *dev = to_mdev(uobject->context->device);
+ 
+ 		call_srcu(&dev->mr_srcu, &obj->devx_mr.rcu,
+ 			  devx_free_indirect_mkey);
+ 		return ret;
+ 	}
+ 
  	kfree(obj);
  	return ret;
  }
@@@ -395,34 -1166,44 +503,47 @@@ static int UVERBS_HANDLER(MLX5_IB_METHO
  	if (!obj)
  		return -ENOMEM;
  
 -	MLX5_SET(general_obj_in_cmd_hdr, cmd_in, uid, uid);
 -	if (opcode == MLX5_CMD_OP_CREATE_MKEY) {
 -		err = devx_handle_mkey_create(dev, obj, cmd_in, cmd_in_len);
 -		if (err)
 -			goto obj_free;
 -	} else {
 -		devx_set_umem_valid(cmd_in);
 +	cmd_out = kvzalloc(cmd_out_len, GFP_KERNEL);
 +	if (!cmd_out) {
 +		err = -ENOMEM;
 +		goto obj_free;
  	}
  
 +	MLX5_SET(general_obj_in_cmd_hdr, cmd_in, uid, c->devx_uid);
  	err = mlx5_cmd_exec(dev->mdev, cmd_in,
 -			    cmd_in_len,
 +			    uverbs_attr_get_len(attrs, MLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_IN),
  			    cmd_out, cmd_out_len);
  	if (err)
 -		goto obj_free;
 +		goto cmd_free;
  
 +	uobj = uverbs_attr_get_uobject(attrs, MLX5_IB_ATTR_DEVX_OBJ_CREATE_HANDLE);
  	uobj->object = obj;
  	obj->mdev = dev->mdev;
 -	devx_obj_build_destroy_cmd(cmd_in, cmd_out, obj->dinbox, &obj->dinlen,
 -				   &obj_id);
 +	devx_obj_build_destroy_cmd(cmd_in, cmd_out, obj->dinbox, &obj->dinlen, &obj->obj_id);
  	WARN_ON(obj->dinlen > MLX5_MAX_DESTROY_INBOX_SIZE_DW * sizeof(u32));
  
+ 	if (obj->flags & DEVX_OBJ_FLAGS_INDIRECT_MKEY) {
+ 		err = devx_handle_mkey_indirect(obj, dev, cmd_in, cmd_out);
+ 		if (err)
+ 			goto obj_destroy;
+ 	}
+ 
  	err = uverbs_copy_to(attrs, MLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_OUT, cmd_out, cmd_out_len);
  	if (err)
 -		goto obj_destroy;
 +		goto cmd_free;
  
 -	obj->obj_id = get_enc_obj_id(opcode, obj_id);
 +	kvfree(cmd_out);
  	return 0;
  
++<<<<<<< HEAD
 +cmd_free:
 +	kvfree(cmd_out);
++=======
+ obj_destroy:
+ 	if (obj->flags & DEVX_OBJ_FLAGS_INDIRECT_MKEY)
+ 		devx_cleanup_mkey(obj);
+ 	mlx5_cmd_exec(obj->mdev, obj->dinbox, obj->dinlen, out, sizeof(out));
++>>>>>>> 534fd7aac56a (IB/mlx5: Manage indirection mkey upon DEVX flow for ODP)
  obj_free:
  	kfree(obj);
  	return err;
diff --cc drivers/infiniband/hw/mlx5/main.c
index 9f7060c02bfd,ae00f994673b..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -5459,9 -5723,12 +5459,18 @@@ static struct ib_counters *mlx5_ib_crea
  void mlx5_ib_stage_init_cleanup(struct mlx5_ib_dev *dev)
  {
  	mlx5_ib_cleanup_multiport_master(dev);
++<<<<<<< HEAD
 +#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
 +	cleanup_srcu_struct(&dev->mr_srcu);
 +#endif
++=======
+ 	if (IS_ENABLED(CONFIG_INFINIBAND_ON_DEMAND_PAGING)) {
+ 		srcu_barrier(&dev->mr_srcu);
+ 		cleanup_srcu_struct(&dev->mr_srcu);
+ 		drain_workqueue(dev->advise_mr_wq);
+ 		destroy_workqueue(dev->advise_mr_wq);
+ 	}
++>>>>>>> 534fd7aac56a (IB/mlx5: Manage indirection mkey upon DEVX flow for ODP)
  	kfree(dev->port);
  }
  
* Unmerged path drivers/infiniband/hw/mlx5/devx.c
* Unmerged path drivers/infiniband/hw/mlx5/main.c
diff --git a/drivers/infiniband/hw/mlx5/mlx5_ib.h b/drivers/infiniband/hw/mlx5/mlx5_ib.h
index 2c8fea140d3d..a02182df2f6f 100644
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -574,6 +574,12 @@ struct mlx5_ib_mw {
 	int			ndescs;
 };
 
+struct mlx5_ib_devx_mr {
+	struct mlx5_core_mkey	mmkey;
+	int			ndescs;
+	struct rcu_head		rcu;
+};
+
 struct mlx5_ib_umr_context {
 	struct ib_cqe		cqe;
 	enum ib_wc_status	status;
diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 9173a00d2ab4..d092de8e80f9 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -429,6 +429,7 @@ struct mlx5_core_sig_ctx {
 enum {
 	MLX5_MKEY_MR = 1,
 	MLX5_MKEY_MW,
+	MLX5_MKEY_INDIRECT_DEVX,
 };
 
 struct mlx5_core_mkey {
