RDMA: Clean structures from CONFIG_INFINIBAND_ON_DEMAND_PAGING

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Leon Romanovsky <leon@kernel.org>
commit 96f87ee1811306d0c8cf94b8c37b0e4f725b01d1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/96f87ee1.failed

CONFIG_INFINIBAND_ON_DEMAND_PAGING is used in general structures to
micro-optimize the memory footprint. Remove it, so it will allow us to
simplify various ODP device flows.

	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 96f87ee1811306d0c8cf94b8c37b0e4f725b01d1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/mlx5_ib.h
#	include/rdma/ib_verbs.h
diff --cc drivers/infiniband/hw/mlx5/mlx5_ib.h
index 2c8fea140d3d,93c288a4de2b..000000000000
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@@ -865,16 -911,17 +865,19 @@@ struct mlx5_ib_dev 
  	/* Prevents soft lock on massive reg MRs */
  	struct mutex			slow_path_mutex;
  	int				fill_delay;
- #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
  	struct ib_odp_caps	odp_caps;
  	u64			odp_max_size;
 -	struct mlx5_ib_pf_eq	odp_pf_eq;
 -
  	/*
  	 * Sleepable RCU that prevents destruction of MRs while they are still
  	 * being used by a page fault handler.
  	 */
  	struct srcu_struct      mr_srcu;
  	u32			null_mkey;
++<<<<<<< HEAD
 +#endif
++=======
+ 	struct workqueue_struct *advise_mr_wq;
++>>>>>>> 96f87ee18113 (RDMA: Clean structures from CONFIG_INFINIBAND_ON_DEMAND_PAGING)
  	struct mlx5_ib_flow_db	*flow_db;
  	/* protect resources needed as part of reset flow */
  	spinlock_t		reset_flow_resource_lock;
diff --cc include/rdma/ib_verbs.h
index 7d63f1ad4c1e,3ddd199ba602..000000000000
--- a/include/rdma/ib_verbs.h
+++ b/include/rdma/ib_verbs.h
@@@ -1492,32 -1495,19 +1492,39 @@@ struct ib_rdmacg_object 
  struct ib_ucontext {
  	struct ib_device       *device;
  	struct ib_uverbs_file  *ufile;
 +	int			closing;
 +
 +	/* locking the uobjects_list */
 +	struct mutex		uobjects_lock;
 +	struct list_head	uobjects;
 +	/* protects cleanup process from other actions */
 +	struct rw_semaphore	cleanup_rwsem;
 +	enum rdma_remove_reason cleanup_reason;
 +
++<<<<<<< HEAD
 +	struct pid             *tgid;
 +#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
 +	struct rb_root_cached   umem_tree;
  	/*
 -	 * 'closing' can be read by the driver only during a destroy callback,
 -	 * it is set when we are closing the file descriptor and indicates
 -	 * that mm_sem may be locked.
 +	 * Protects .umem_rbroot and tree, as well as odp_mrs_count and
 +	 * mmu notifiers registration.
  	 */
 -	bool closing;
 -
 -	bool cleanup_retryable;
 +	struct rw_semaphore	umem_rwsem;
 +	void (*invalidate_range)(struct ib_umem_odp *umem_odp,
 +				 unsigned long start, unsigned long end);
  
 +	struct mmu_notifier	mn;
 +	atomic_t		notifier_count;
 +	/* A list of umems that don't have private mmu notifier counters yet. */
 +	struct list_head	no_private_counters;
 +	int                     odp_mrs_count;
 +#endif
++=======
+ 	void (*invalidate_range)(struct ib_umem_odp *umem_odp,
+ 				 unsigned long start, unsigned long end);
+ 	struct mutex per_mm_list_lock;
+ 	struct list_head per_mm_list;
++>>>>>>> 96f87ee18113 (RDMA: Clean structures from CONFIG_INFINIBAND_ON_DEMAND_PAGING)
  
  	struct ib_rdmacg_object	cg_obj;
  	/*
* Unmerged path drivers/infiniband/hw/mlx5/mlx5_ib.h
* Unmerged path include/rdma/ib_verbs.h
