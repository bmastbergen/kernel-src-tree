scsi: core: avoid preallocating big SGL for protection information

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
Rebuild_CHGLOG: - [scsi] scsi: core: avoid pre-allocating big SGL for protection information (Ewan Milne) [1698297]
Rebuild_FUZZ: 99.25%
commit-author Ming Lei <ming.lei@redhat.com>
commit 92524fa12312d1f082a473e14c590c48b4ef3fe5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/92524fa1.failed

scsi_mq_setup_tags() currently preallocates a big buffer for protection
SGL entries. scsi_mq_sgl_size() is used to determine the size for both data
and protection information scatterlists but the protection buffer is
usually much smaller. For example, one 512-byte sector needs 8 bytes of
protection information. Given that the maximum number of sectors for one
request is 2560 (BLK_DEF_MAX_SECTORS) sectors, the max protection
information buffer size is just 20K.

The protection information segment count generally matches the number of
bios in the request. As a result, the typical actual number of segments
won't be very big. And should the need arise, allocating a bigger SGL from
slab is fast enough.

Pre-allocate only one SGL entry for protection information and switch to
runtime allocation in case that the protection information segment number
is bigger than 1. This reduces memory tied up by static command
allocations. For example, 500+ MB is saved on single lpfc HBA.

[mkp: attempted to clarify commit desc]

	Cc: Christoph Hellwig <hch@lst.de>
	Cc: Bart Van Assche <bvanassche@acm.org>
	Cc: Ewan D. Milne <emilne@redhat.com>
	Cc: Hannes Reinecke <hare@suse.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Ming Lei <ming.lei@redhat.com>
	Reviewed-by: Bart Van Assche <bvanassche@acm.org>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit 92524fa12312d1f082a473e14c590c48b4ef3fe5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/scsi_lib.c
diff --cc drivers/scsi/scsi_lib.c
index 5528cb747bda,c115458c835e..000000000000
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@@ -556,17 -546,11 +562,22 @@@ static void scsi_uninit_cmd(struct scsi
  
  static void scsi_mq_free_sgtables(struct scsi_cmnd *cmd)
  {
 +	struct scsi_data_buffer *sdb;
 +
  	if (cmd->sdb.table.nents)
 -		sg_free_table_chained(&cmd->sdb.table, SG_CHUNK_SIZE);
 +		sg_free_table_chained(&cmd->sdb.table, true);
 +	if (cmd->request->next_rq) {
 +		sdb = cmd->request->next_rq->special;
 +		if (sdb)
 +			sg_free_table_chained(&sdb->table, true);
 +	}
  	if (scsi_prot_sg_count(cmd))
++<<<<<<< HEAD
 +		sg_free_table_chained(&cmd->prot_sdb->table, true);
++=======
+ 		sg_free_table_chained(&cmd->prot_sdb->table,
+ 				SCSI_INLINE_PROT_SG_CNT);
++>>>>>>> 92524fa12312 (scsi: core: avoid preallocating big SGL for protection information)
  }
  
  static void scsi_mq_uninit_cmd(struct scsi_cmnd *cmd)
@@@ -1083,7 -1038,8 +1094,12 @@@ blk_status_t scsi_init_io(struct scsi_c
  		ivecs = blk_rq_count_integrity_sg(rq->q, rq->bio);
  
  		if (sg_alloc_table_chained(&prot_sdb->table, ivecs,
++<<<<<<< HEAD
 +				prot_sdb->table.sgl)) {
++=======
+ 				prot_sdb->table.sgl,
+ 				SCSI_INLINE_PROT_SG_CNT)) {
++>>>>>>> 92524fa12312 (scsi: core: avoid preallocating big SGL for protection information)
  			ret = BLK_STS_RESOURCE;
  			goto out_free_sgtables;
  		}
* Unmerged path drivers/scsi/scsi_lib.c
