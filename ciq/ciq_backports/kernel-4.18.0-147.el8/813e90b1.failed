IB/mlx5: Add advise_mr() support

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Moni Shoua <monis@mellanox.com>
commit 813e90b1aeaa550641332625174d57edb15bc8bd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/813e90b1.failed

The verb advise_mr() is used to give advice to the kernel about an address
range that belongs to a MR.  Implement the verb and register it on the
device. The current implementation supports the only known advice to date,
prefetch.

	Signed-off-by: Moni Shoua <monis@mellanox.com>
	Reviewed-by: Guy Levi <guyle@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 813e90b1aeaa550641332625174d57edb15bc8bd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/odp.c
diff --cc drivers/infiniband/hw/mlx5/odp.c
index 4e6f586dbb7c,80fa2438db8f..000000000000
--- a/drivers/infiniband/hw/mlx5/odp.c
+++ b/drivers/infiniband/hw/mlx5/odp.c
@@@ -495,17 -549,24 +495,26 @@@ void mlx5_ib_free_implicit_mr(struct ml
  	wait_event(imr->q_leaf_free, !atomic_read(&imr->num_leaf_free));
  }
  
+ #define MLX5_PF_FLAGS_PREFETCH  BIT(0)
+ #define MLX5_PF_FLAGS_DOWNGRADE BIT(1)
  static int pagefault_mr(struct mlx5_ib_dev *dev, struct mlx5_ib_mr *mr,
- 			u64 io_virt, size_t bcnt, u32 *bytes_mapped)
+ 			u64 io_virt, size_t bcnt, u32 *bytes_mapped,
+ 			u32 flags)
  {
++<<<<<<< HEAD
 +	int npages = 0, current_seq, page_shift, ret, np;
 +	bool implicit = false;
++=======
+ 	struct ib_umem_odp *odp_mr = to_ib_umem_odp(mr->umem);
+ 	bool downgrade = flags & MLX5_PF_FLAGS_DOWNGRADE;
+ 	bool prefetch = flags & MLX5_PF_FLAGS_PREFETCH;
++>>>>>>> 813e90b1aeaa (IB/mlx5: Add advise_mr() support)
  	u64 access_mask = ODP_READ_ALLOWED_BIT;
 -	int npages = 0, page_shift, np;
  	u64 start_idx, page_mask;
  	struct ib_umem_odp *odp;
 -	int current_seq;
  	size_t size;
 -	int ret;
  
 -	if (!odp_mr->page_list) {
 +	if (!mr->umem->odp_data->page_list) {
  		odp = implicit_mr_get_data(mr, io_virt, bcnt);
  
  		if (IS_ERR(odp))
@@@ -664,7 -740,12 +688,16 @@@ next_mr
  			goto srcu_unlock;
  		}
  
++<<<<<<< HEAD
 +		if (!mr->umem->odp_data) {
++=======
+ 		if (prefetch && !mr->umem->is_odp) {
+ 			ret = -EINVAL;
+ 			goto srcu_unlock;
+ 		}
+ 
+ 		if (!mr->umem->is_odp) {
++>>>>>>> 813e90b1aeaa (IB/mlx5: Add advise_mr() support)
  			mlx5_ib_dbg(dev, "skipping non ODP MR (lkey=0x%06x) in page fault handler.\n",
  				    key);
  			if (bytes_mapped)
@@@ -1242,10 -1520,17 +1277,17 @@@ void mlx5_odp_init_mr_cache_entry(struc
  	}
  }
  
+ static const struct ib_device_ops mlx5_ib_dev_odp_ops = {
+ 	.advise_mr = mlx5_ib_advise_mr,
+ };
+ 
  int mlx5_ib_odp_init_one(struct mlx5_ib_dev *dev)
  {
 -	int ret = 0;
 +	int ret;
  
+ 	if (dev->odp_caps.general_caps & IB_ODP_SUPPORT)
+ 		ib_set_device_ops(&dev->ib_dev, &mlx5_ib_dev_odp_ops);
+ 
  	if (dev->odp_caps.general_caps & IB_ODP_SUPPORT_IMPLICIT) {
  		ret = mlx5_cmd_null_mkey(dev->mdev, &dev->null_mkey);
  		if (ret) {
@@@ -1265,3 -1563,75 +1307,78 @@@ int mlx5_ib_odp_init(void
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ struct prefetch_mr_work {
+ 	struct work_struct work;
+ 	struct mlx5_ib_dev *dev;
+ 	u32 pf_flags;
+ 	u32 num_sge;
+ 	struct ib_sge sg_list[0];
+ };
+ 
+ static int mlx5_ib_prefetch_sg_list(struct mlx5_ib_dev *dev, u32 pf_flags,
+ 				    struct ib_sge *sg_list, u32 num_sge)
+ {
+ 	int i;
+ 
+ 	for (i = 0; i < num_sge; ++i) {
+ 		struct ib_sge *sg = &sg_list[i];
+ 		int bytes_committed = 0;
+ 		int ret;
+ 
+ 		ret = pagefault_single_data_segment(dev, sg->lkey, sg->addr,
+ 						    sg->length,
+ 						    &bytes_committed, NULL,
+ 						    pf_flags);
+ 		if (ret < 0)
+ 			return ret;
+ 	}
+ 	return 0;
+ }
+ 
+ static void mlx5_ib_prefetch_mr_work(struct work_struct *work)
+ {
+ 	struct prefetch_mr_work *w =
+ 		container_of(work, struct prefetch_mr_work, work);
+ 
+ 	if (w->dev->ib_dev.reg_state == IB_DEV_REGISTERED)
+ 		mlx5_ib_prefetch_sg_list(w->dev, w->pf_flags, w->sg_list,
+ 					 w->num_sge);
+ 
+ 	kfree(w);
+ }
+ 
+ int mlx5_ib_advise_mr_prefetch(struct ib_pd *pd,
+ 			       enum ib_uverbs_advise_mr_advice advice,
+ 			       u32 flags, struct ib_sge *sg_list, u32 num_sge)
+ {
+ 	struct mlx5_ib_dev *dev = to_mdev(pd->device);
+ 	u32 pf_flags = MLX5_PF_FLAGS_PREFETCH;
+ 	struct prefetch_mr_work *work;
+ 
+ 	if (advice == IB_UVERBS_ADVISE_MR_ADVICE_PREFETCH)
+ 		pf_flags |= MLX5_PF_FLAGS_DOWNGRADE;
+ 
+ 	if (flags & IB_UVERBS_ADVISE_MR_FLAG_FLUSH)
+ 		return mlx5_ib_prefetch_sg_list(dev, pf_flags, sg_list,
+ 						num_sge);
+ 
+ 	if (dev->ib_dev.reg_state != IB_DEV_REGISTERED)
+ 		return -ENODEV;
+ 
+ 	work = kvzalloc(struct_size(work, sg_list, num_sge), GFP_KERNEL);
+ 	if (!work)
+ 		return -ENOMEM;
+ 
+ 	memcpy(work->sg_list, sg_list, num_sge * sizeof(struct ib_sge));
+ 
+ 	work->dev = dev;
+ 	work->pf_flags = pf_flags;
+ 	work->num_sge = num_sge;
+ 
+ 	INIT_WORK(&work->work, mlx5_ib_prefetch_mr_work);
+ 	schedule_work(&work->work);
+ 	return 0;
+ }
++>>>>>>> 813e90b1aeaa (IB/mlx5: Add advise_mr() support)
diff --git a/drivers/infiniband/hw/mlx5/main.c b/drivers/infiniband/hw/mlx5/main.c
index 12a75511c956..afc73d85d52b 100644
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@ -5386,6 +5386,8 @@ void mlx5_ib_stage_init_cleanup(struct mlx5_ib_dev *dev)
 	mlx5_ib_cleanup_multiport_master(dev);
 #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
 	cleanup_srcu_struct(&dev->mr_srcu);
+	drain_workqueue(dev->advise_mr_wq);
+	destroy_workqueue(dev->advise_mr_wq);
 #endif
 	kfree(dev->port);
 }
@@ -5448,6 +5450,12 @@ int mlx5_ib_stage_init_init(struct mlx5_ib_dev *dev)
 	dev->memic.dev = mdev;
 
 #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+	dev->advise_mr_wq = alloc_ordered_workqueue("mlx5_ib_advise_mr_wq", 0);
+	if (!dev->advise_mr_wq) {
+		err = -ENOMEM;
+		goto err_free_port;
+	}
+
 	err = init_srcu_struct(&dev->mr_srcu);
 	if (err)
 		goto err_free_port;
diff --git a/drivers/infiniband/hw/mlx5/mlx5_ib.h b/drivers/infiniband/hw/mlx5/mlx5_ib.h
index 2c8fea140d3d..b72059579dd4 100644
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -874,6 +874,7 @@ struct mlx5_ib_dev {
 	 */
 	struct srcu_struct      mr_srcu;
 	u32			null_mkey;
+	struct workqueue_struct *advise_mr_wq;
 #endif
 	struct mlx5_ib_flow_db	*flow_db;
 	/* protect resources needed as part of reset flow */
@@ -1033,6 +1034,12 @@ struct ib_mr *mlx5_ib_get_dma_mr(struct ib_pd *pd, int acc);
 struct ib_mr *mlx5_ib_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,
 				  u64 virt_addr, int access_flags,
 				  struct ib_udata *udata);
+int mlx5_ib_advise_mr(struct ib_pd *pd,
+		      enum ib_uverbs_advise_mr_advice advice,
+		      u32 flags,
+		      struct ib_sge *sg_list,
+		      u32 num_sge,
+		      struct uverbs_attr_bundle *attrs);
 struct ib_mw *mlx5_ib_alloc_mw(struct ib_pd *pd, enum ib_mw_type type,
 			       struct ib_udata *udata);
 int mlx5_ib_dealloc_mw(struct ib_mw *mw);
@@ -1131,6 +1138,10 @@ void mlx5_ib_invalidate_range(struct ib_umem_odp *umem_odp, unsigned long start,
 void mlx5_odp_init_mr_cache_entry(struct mlx5_cache_ent *ent);
 void mlx5_odp_populate_klm(struct mlx5_klm *pklm, size_t offset,
 			   size_t nentries, struct mlx5_ib_mr *mr, int flags);
+
+int mlx5_ib_advise_mr_prefetch(struct ib_pd *pd,
+			       enum ib_uverbs_advise_mr_advice advice,
+			       u32 flags, struct ib_sge *sg_list, u32 num_sge);
 #else /* CONFIG_INFINIBAND_ON_DEMAND_PAGING */
 static inline void mlx5_ib_internal_fill_odp_caps(struct mlx5_ib_dev *dev)
 {
@@ -1145,6 +1156,13 @@ static inline void mlx5_odp_populate_klm(struct mlx5_klm *pklm, size_t offset,
 					 size_t nentries, struct mlx5_ib_mr *mr,
 					 int flags) {}
 
+static int mlx5_ib_advise_mr_prefetch(struct ib_pd *pd,
+				      enum ib_uverbs_advise_mr_advice advice,
+				      u32 flags, struct ib_sge *sg_list,
+				      u32 num_sge)
+{
+	return -EOPNOTSUPP;
+}
 #endif /* CONFIG_INFINIBAND_ON_DEMAND_PAGING */
 
 /* Needed for rep profile */
diff --git a/drivers/infiniband/hw/mlx5/mr.c b/drivers/infiniband/hw/mlx5/mr.c
index 7aa0bfa996ba..0ee850bdddf8 100644
--- a/drivers/infiniband/hw/mlx5/mr.c
+++ b/drivers/infiniband/hw/mlx5/mr.c
@@ -1280,6 +1280,21 @@ static struct ib_mr *mlx5_ib_get_memic_mr(struct ib_pd *pd, u64 memic_addr,
 	return ERR_PTR(err);
 }
 
+int mlx5_ib_advise_mr(struct ib_pd *pd,
+		      enum ib_uverbs_advise_mr_advice advice,
+		      u32 flags,
+		      struct ib_sge *sg_list,
+		      u32 num_sge,
+		      struct uverbs_attr_bundle *attrs)
+{
+	if (advice != IB_UVERBS_ADVISE_MR_ADVICE_PREFETCH &&
+	    advice != IB_UVERBS_ADVISE_MR_ADVICE_PREFETCH_WRITE)
+		return -EOPNOTSUPP;
+
+	return mlx5_ib_advise_mr_prefetch(pd, advice, flags,
+					 sg_list, num_sge);
+}
+
 struct ib_mr *mlx5_ib_reg_dm_mr(struct ib_pd *pd, struct ib_dm *dm,
 				struct ib_dm_mr_attr *attr,
 				struct uverbs_attr_bundle *attrs)
* Unmerged path drivers/infiniband/hw/mlx5/odp.c
