IB/uverbs: Clarify and revise uverbs_close_fd

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Jason Gunthorpe <jgg@ziepe.ca>
commit e6d5d5ddd0869cf44a554289cd213007ccc0afde
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/e6d5d5dd.failed

The locking requirements here have changed slightly now that we can rely
on the ib_uverbs_file always existing and containing all the necessary
locking infrastructure.

That means we can get rid of the cleanup_mutex usage (this was protecting
the check on !uboj->context).

Otherwise, follow the same pattern that IDR uses for destroy, acquire
exclusive write access, then call destroy and the undo the 'lookup'.

	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit e6d5d5ddd0869cf44a554289cd213007ccc0afde)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/rdma_core.c
diff --cc drivers/infiniband/core/rdma_core.c
index 7abca5514e4d,a55646cbf9b1..000000000000
--- a/drivers/infiniband/core/rdma_core.c
+++ b/drivers/infiniband/core/rdma_core.c
@@@ -634,102 -648,125 +634,142 @@@ const struct uverbs_obj_type_class uver
  };
  EXPORT_SYMBOL(uverbs_idr_class);
  
 -static void _uverbs_close_fd(struct ib_uobject *uobj)
 +static void _uverbs_close_fd(struct ib_uobject_file *uobj_file)
  {
++<<<<<<< HEAD
 +	struct ib_ucontext *ucontext;
 +	struct ib_uverbs_file *ufile = uobj_file->ufile;
 +	int ret;
 +
 +	mutex_lock(&uobj_file->ufile->cleanup_mutex);
 +
 +	/* uobject was either already cleaned up or is cleaned up right now anyway */
 +	if (!uobj_file->uobj.context ||
 +	    !down_read_trylock(&uobj_file->uobj.context->cleanup_rwsem))
 +		goto unlock;
 +
 +	ucontext = uobj_file->uobj.context;
 +	ret = _rdma_remove_commit_uobject(&uobj_file->uobj, RDMA_REMOVE_CLOSE);
 +	up_read(&ucontext->cleanup_rwsem);
++=======
+ 	int ret;
+ 
+ 	/*
+ 	 * uobject was already cleaned up, remove_commit_fd_uobject
+ 	 * sets this
+ 	 */
+ 	if (!uobj->context)
+ 		return;
+ 
+ 	/*
+ 	 * lookup_get_fd_uobject holds the kref on the struct file any time a
+ 	 * FD uobj is locked, which prevents this release method from being
+ 	 * invoked. Meaning we can always get the write lock here, or we have
+ 	 * a kernel bug. If so dangle the pointers and bail.
+ 	 */
+ 	ret = uverbs_try_lock_object(uobj, true);
+ 	if (WARN(ret, "uverbs_close_fd() racing with lookup_get_fd_uobject()"))
+ 		return;
+ 
+ 	ret = _rdma_remove_commit_uobject(uobj, RDMA_REMOVE_CLOSE);
++>>>>>>> e6d5d5ddd086 (IB/uverbs: Clarify and revise uverbs_close_fd)
  	if (ret)
- 		pr_warn("uverbs: unable to clean up uobject file in uverbs_close_fd.\n");
- unlock:
- 	mutex_unlock(&ufile->cleanup_mutex);
+ 		pr_warn("Unable to clean up uobject file in %s\n", __func__);
+ 
+ 	atomic_set(&uobj->usecnt, 0);
  }
  
  void uverbs_close_fd(struct file *f)
  {
++<<<<<<< HEAD
 +	struct ib_uobject_file *uobj_file = f->private_data;
 +	struct kref *uverbs_file_ref = &uobj_file->ufile->ref;
 +
 +	_uverbs_close_fd(uobj_file);
 +	uverbs_uobject_put(&uobj_file->uobj);
 +	kref_put(uverbs_file_ref, ib_uverbs_release_file);
++=======
+ 	struct ib_uobject *uobj = f->private_data;
+ 	struct ib_uverbs_file *ufile = uobj->ufile;
+ 
+ 	if (down_read_trylock(&ufile->cleanup_rwsem)) {
+ 		_uverbs_close_fd(uobj);
+ 		up_read(&ufile->cleanup_rwsem);
+ 	}
+ 
+ 	uobj->object = NULL;
+ 	/* Matches the get in alloc_begin_fd_uobject */
+ 	kref_put(&ufile->ref, ib_uverbs_release_file);
+ 
+ 	/* Pairs with filp->private_data in alloc_begin_fd_uobject */
+ 	uverbs_uobject_put(uobj);
++>>>>>>> e6d5d5ddd086 (IB/uverbs: Clarify and revise uverbs_close_fd)
  }
  
 -static int __uverbs_cleanup_ufile(struct ib_uverbs_file *ufile,
 -				  enum rdma_remove_reason reason)
 +void uverbs_cleanup_ucontext(struct ib_ucontext *ucontext, bool device_removed)
  {
 -	struct ib_uobject *obj, *next_obj;
 -	int ret = -EINVAL;
 -	int err = 0;
 +	enum rdma_remove_reason reason = device_removed ?
 +		RDMA_REMOVE_DRIVER_REMOVE : RDMA_REMOVE_CLOSE;
 +	unsigned int cur_order = 0;
  
 +	ucontext->cleanup_reason = reason;
  	/*
 -	 * This shouldn't run while executing other commands on this
 -	 * context. Thus, the only thing we should take care of is
 -	 * releasing a FD while traversing this list. The FD could be
 -	 * closed and released from the _release fop of this FD.
 -	 * In order to mitigate this, we add a lock.
 -	 * We take and release the lock per traversal in order to let
 -	 * other threads (which might still use the FDs) chance to run.
 +	 * Waits for all remove_commit and alloc_commit to finish. Logically, We
 +	 * want to hold this forever as the context is going to be destroyed,
 +	 * but we'll release it since it causes a "held lock freed" BUG message.
  	 */
 -	mutex_lock(&ufile->uobjects_lock);
 -	ufile->cleanup_reason = reason;
 -	list_for_each_entry_safe(obj, next_obj, &ufile->uobjects, list) {
 +	down_write(&ucontext->cleanup_rwsem);
 +
 +	while (!list_empty(&ucontext->uobjects)) {
 +		struct ib_uobject *obj, *next_obj;
 +		unsigned int next_order = UINT_MAX;
 +
  		/*
 -		 * if we hit this WARN_ON, that means we are
 -		 * racing with a lookup_get.
 +		 * This shouldn't run while executing other commands on this
 +		 * context. Thus, the only thing we should take care of is
 +		 * releasing a FD while traversing this list. The FD could be
 +		 * closed and released from the _release fop of this FD.
 +		 * In order to mitigate this, we add a lock.
 +		 * We take and release the lock per order traversal in order
 +		 * to let other threads (which might still use the FDs) chance
 +		 * to run.
  		 */
 -		WARN_ON(uverbs_try_lock_object(obj, true));
 -		err = obj->type->type_class->remove_commit(obj, reason);
 -
 -		if (ib_is_destroy_retryable(err, reason, obj)) {
 -			pr_debug("ib_uverbs: failed to remove uobject id %d err %d\n",
 -				 obj->id, err);
 -			atomic_set(&obj->usecnt, 0);
 -			continue;
 +		mutex_lock(&ucontext->uobjects_lock);
 +		list_for_each_entry_safe(obj, next_obj, &ucontext->uobjects,
 +					 list) {
 +			if (obj->type->destroy_order == cur_order) {
 +				int ret;
 +
 +				/*
 +				 * if we hit this WARN_ON, that means we are
 +				 * racing with a lookup_get.
 +				 */
 +				WARN_ON(uverbs_try_lock_object(obj, true));
 +				ret = obj->type->type_class->remove_commit(obj,
 +									   reason);
 +				list_del(&obj->list);
 +				if (ret)
 +					pr_warn("ib_uverbs: failed to remove uobject id %d order %u\n",
 +						obj->id, cur_order);
 +				/* put the ref we took when we created the object */
 +				uverbs_uobject_put(obj);
 +			} else {
 +				next_order = min(next_order,
 +						 obj->type->destroy_order);
 +			}
  		}
 -
 -		if (err)
 -			pr_err("ib_uverbs: unable to remove uobject id %d err %d\n",
 -				obj->id, err);
 -
 -		list_del(&obj->list);
 -		/* Pairs with the get in rdma_alloc_commit_uobject() */
 -		uverbs_uobject_put(obj);
 -		ret = 0;
 +		mutex_unlock(&ucontext->uobjects_lock);
 +		cur_order = next_order;
  	}
 -	mutex_unlock(&ufile->uobjects_lock);
 -	return ret;
 +	up_write(&ucontext->cleanup_rwsem);
  }
  
 -void uverbs_cleanup_ufile(struct ib_uverbs_file *ufile, bool device_removed)
 +void uverbs_initialize_ucontext(struct ib_ucontext *ucontext)
  {
 -	enum rdma_remove_reason reason = device_removed ?
 -					RDMA_REMOVE_DRIVER_REMOVE :
 -					RDMA_REMOVE_CLOSE;
 -
 -	/*
 -	 * Waits for all remove_commit and alloc_commit to finish. Logically, We
 -	 * want to hold this forever as the context is going to be destroyed,
 -	 * but we'll release it since it causes a "held lock freed" BUG message.
 -	 */
 -	down_write(&ufile->cleanup_rwsem);
 -	ufile->ucontext->cleanup_retryable = true;
 -	while (!list_empty(&ufile->uobjects))
 -		if (__uverbs_cleanup_ufile(ufile, reason)) {
 -			/*
 -			 * No entry was cleaned-up successfully during this
 -			 * iteration
 -			 */
 -			break;
 -		}
 -
 -	ufile->ucontext->cleanup_retryable = false;
 -	if (!list_empty(&ufile->uobjects))
 -		__uverbs_cleanup_ufile(ufile, reason);
 -
 -	up_write(&ufile->cleanup_rwsem);
 +	ucontext->cleanup_reason = 0;
 +	mutex_init(&ucontext->uobjects_lock);
 +	INIT_LIST_HEAD(&ucontext->uobjects);
 +	init_rwsem(&ucontext->cleanup_rwsem);
  }
  
  const struct uverbs_obj_type_class uverbs_fd_class = {
* Unmerged path drivers/infiniband/core/rdma_core.c
