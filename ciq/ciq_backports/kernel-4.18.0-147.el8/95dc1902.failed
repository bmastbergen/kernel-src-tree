net/mlx5e: Don't inherit flow flags on peer flow creation

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Roi Dayan <roid@mellanox.com>
commit 95dc1902c3739a1a44397ea23b52b81375b711b3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/95dc1902.failed

Currently the peer flow inherits the flags from the original flow
after we've set it. At this time the flags are set according to
the flow state, e.g marked as going to slow path and such.

Even if not getting us to real bugs now, this opens the door to
get us to troubles later. Future proof the code and avoid the
inheritance, use the peer flags as were set on input when we
started adding the original flow.

	Signed-off-by: Roi Dayan <roid@mellanox.com>
	Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 95dc1902c3739a1a44397ea23b52b81375b711b3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index 06543506a2d4,c2df3863e82c..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -2805,47 -2729,282 +2805,141 @@@ int mlx5e_configure_flower(struct mlx5e
  	flow->flags = flow_flags;
  	flow->priv = priv;
  
 -	*__flow = flow;
 -	*__parse_attr = parse_attr;
 -
 -	return 0;
 -
 -err_free:
 -	kfree(flow);
 -	kvfree(parse_attr);
 -	return err;
 -}
 -
 -static void
 -mlx5e_flow_esw_attr_init(struct mlx5_esw_flow_attr *esw_attr,
 -			 struct mlx5e_priv *priv,
 -			 struct mlx5e_tc_flow_parse_attr *parse_attr,
 -			 struct tc_cls_flower_offload *f,
 -			 struct mlx5_eswitch_rep *in_rep,
 -			 struct mlx5_core_dev *in_mdev)
 -{
 -	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 -
 -	esw_attr->parse_attr = parse_attr;
 -	esw_attr->chain = f->common.chain_index;
 -	esw_attr->prio = TC_H_MAJ(f->common.prio) >> 16;
 -
 -	esw_attr->in_rep = in_rep;
 -	esw_attr->in_mdev = in_mdev;
 -
 -	if (MLX5_CAP_ESW(esw->dev, counter_eswitch_affinity) ==
 -	    MLX5_COUNTER_SOURCE_ESWITCH)
 -		esw_attr->counter_dev = in_mdev;
 -	else
 -		esw_attr->counter_dev = priv->mdev;
 -}
 -
 -static struct mlx5e_tc_flow *
 -__mlx5e_add_fdb_flow(struct mlx5e_priv *priv,
 -		     struct tc_cls_flower_offload *f,
 -		     u16 flow_flags,
 -		     struct net_device *filter_dev,
 -		     struct mlx5_eswitch_rep *in_rep,
 -		     struct mlx5_core_dev *in_mdev)
 -{
 -	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(f);
 -	struct netlink_ext_ack *extack = f->common.extack;
 -	struct mlx5e_tc_flow_parse_attr *parse_attr;
 -	struct mlx5e_tc_flow *flow;
 -	int attr_size, err;
 -
 -	flow_flags |= MLX5E_TC_FLOW_ESWITCH;
 -	attr_size  = sizeof(struct mlx5_esw_flow_attr);
 -	err = mlx5e_alloc_flow(priv, attr_size, f, flow_flags,
 -			       &parse_attr, &flow);
 -	if (err)
 -		goto out;
 -
 -	parse_attr->filter_dev = filter_dev;
 -	mlx5e_flow_esw_attr_init(flow->esw_attr,
 -				 priv, parse_attr,
 -				 f, in_rep, in_mdev);
 -
 -	err = parse_cls_flower(flow->priv, flow, &parse_attr->spec,
 -			       f, filter_dev);
 -	if (err)
 +	err = parse_cls_flower(priv, flow, &parse_attr->spec, f);
 +	if (err < 0)
  		goto err_free;
  
++<<<<<<< HEAD
 +	if (flow->flags & MLX5E_TC_FLOW_ESWITCH) {
 +		err = parse_tc_fdb_actions(priv, f->exts, parse_attr, flow);
 +		if (err < 0)
 +			goto err_free;
 +		flow->rule[0] = mlx5e_tc_add_fdb_flow(priv, parse_attr, flow);
 +	} else {
 +		err = parse_tc_nic_actions(priv, f->exts, parse_attr, flow);
 +		if (err < 0)
 +			goto err_free;
 +		flow->rule[0] = mlx5e_tc_add_nic_flow(priv, parse_attr, flow);
 +	}
 +
 +	if (IS_ERR(flow->rule[0])) {
 +		err = PTR_ERR(flow->rule[0]);
 +		if (err != -EAGAIN)
 +			goto err_free;
++=======
+ 	err = parse_tc_fdb_actions(priv, &rule->action, parse_attr, flow, extack);
+ 	if (err)
+ 		goto err_free;
+ 
+ 	err = mlx5e_tc_add_fdb_flow(priv, flow, extack);
+ 	if (err)
+ 		goto err_free;
+ 
+ 	return flow;
+ 
+ err_free:
+ 	kfree(flow);
+ 	kvfree(parse_attr);
+ out:
+ 	return ERR_PTR(err);
+ }
+ 
+ static int mlx5e_tc_add_fdb_peer_flow(struct tc_cls_flower_offload *f,
+ 				      struct mlx5e_tc_flow *flow,
+ 				      u16 flow_flags)
+ {
+ 	struct mlx5e_priv *priv = flow->priv, *peer_priv;
+ 	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch, *peer_esw;
+ 	struct mlx5_devcom *devcom = priv->mdev->priv.devcom;
+ 	struct mlx5e_tc_flow_parse_attr *parse_attr;
+ 	struct mlx5e_rep_priv *peer_urpriv;
+ 	struct mlx5e_tc_flow *peer_flow;
+ 	struct mlx5_core_dev *in_mdev;
+ 	int err = 0;
+ 
+ 	peer_esw = mlx5_devcom_get_peer_data(devcom, MLX5_DEVCOM_ESW_OFFLOADS);
+ 	if (!peer_esw)
+ 		return -ENODEV;
+ 
+ 	peer_urpriv = mlx5_eswitch_get_uplink_priv(peer_esw, REP_ETH);
+ 	peer_priv = netdev_priv(peer_urpriv->netdev);
+ 
+ 	/* in_mdev is assigned of which the packet originated from.
+ 	 * So packets redirected to uplink use the same mdev of the
+ 	 * original flow and packets redirected from uplink use the
+ 	 * peer mdev.
+ 	 */
+ 	if (flow->esw_attr->in_rep->vport == MLX5_VPORT_UPLINK)
+ 		in_mdev = peer_priv->mdev;
+ 	else
+ 		in_mdev = priv->mdev;
+ 
+ 	parse_attr = flow->esw_attr->parse_attr;
+ 	peer_flow = __mlx5e_add_fdb_flow(peer_priv, f, flow_flags,
+ 					 parse_attr->filter_dev,
+ 					 flow->esw_attr->in_rep, in_mdev);
+ 	if (IS_ERR(peer_flow)) {
+ 		err = PTR_ERR(peer_flow);
+ 		goto out;
+ 	}
+ 
+ 	flow->peer_flow = peer_flow;
+ 	flow->flags |= MLX5E_TC_FLOW_DUP;
+ 	mutex_lock(&esw->offloads.peer_mutex);
+ 	list_add_tail(&flow->peer, &esw->offloads.peer_flows);
+ 	mutex_unlock(&esw->offloads.peer_mutex);
+ 
+ out:
+ 	mlx5_devcom_release_peer_data(devcom, MLX5_DEVCOM_ESW_OFFLOADS);
+ 	return err;
+ }
+ 
+ static int
+ mlx5e_add_fdb_flow(struct mlx5e_priv *priv,
+ 		   struct tc_cls_flower_offload *f,
+ 		   u16 flow_flags,
+ 		   struct net_device *filter_dev,
+ 		   struct mlx5e_tc_flow **__flow)
+ {
+ 	struct mlx5e_rep_priv *rpriv = priv->ppriv;
+ 	struct mlx5_eswitch_rep *in_rep = rpriv->rep;
+ 	struct mlx5_core_dev *in_mdev = priv->mdev;
+ 	struct mlx5e_tc_flow *flow;
+ 	int err;
+ 
+ 	flow = __mlx5e_add_fdb_flow(priv, f, flow_flags, filter_dev, in_rep,
+ 				    in_mdev);
+ 	if (IS_ERR(flow))
+ 		return PTR_ERR(flow);
+ 
+ 	if (is_peer_flow_needed(flow)) {
+ 		err = mlx5e_tc_add_fdb_peer_flow(f, flow, flow_flags);
+ 		if (err) {
+ 			mlx5e_tc_del_fdb_flow(priv, flow);
+ 			goto out;
+ 		}
++>>>>>>> 95dc1902c373 (net/mlx5e: Don't inherit flow flags on peer flow creation)
  	}
  
 -	*__flow = flow;
 +	if (err != -EAGAIN)
 +		flow->flags |= MLX5E_TC_FLOW_OFFLOADED;
  
 -	return 0;
 -
 -out:
 -	return err;
 -}
 -
 -static int
 -mlx5e_add_nic_flow(struct mlx5e_priv *priv,
 -		   struct tc_cls_flower_offload *f,
 -		   u16 flow_flags,
 -		   struct net_device *filter_dev,
 -		   struct mlx5e_tc_flow **__flow)
 -{
 -	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(f);
 -	struct netlink_ext_ack *extack = f->common.extack;
 -	struct mlx5e_tc_flow_parse_attr *parse_attr;
 -	struct mlx5e_tc_flow *flow;
 -	int attr_size, err;
 -
 -	/* multi-chain not supported for NIC rules */
 -	if (!tc_cls_can_offload_and_chain0(priv->netdev, &f->common))
 -		return -EOPNOTSUPP;
 -
 -	flow_flags |= MLX5E_TC_FLOW_NIC;
 -	attr_size  = sizeof(struct mlx5_nic_flow_attr);
 -	err = mlx5e_alloc_flow(priv, attr_size, f, flow_flags,
 -			       &parse_attr, &flow);
 -	if (err)
 -		goto out;
 -
 -	parse_attr->filter_dev = filter_dev;
 -	err = parse_cls_flower(flow->priv, flow, &parse_attr->spec,
 -			       f, filter_dev);
 -	if (err)
 -		goto err_free;
 -
 -	err = parse_tc_nic_actions(priv, &rule->action, parse_attr, flow, extack);
 -	if (err)
 -		goto err_free;
 -
 -	err = mlx5e_tc_add_nic_flow(priv, parse_attr, flow, extack);
 -	if (err)
 -		goto err_free;
 -
 -	flow->flags |= MLX5E_TC_FLOW_OFFLOADED;
 -	kvfree(parse_attr);
 -	*__flow = flow;
 -
 -	return 0;
 -
 -err_free:
 -	kfree(flow);
 -	kvfree(parse_attr);
 -out:
 -	return err;
 -}
 -
 -static int
 -mlx5e_tc_add_flow(struct mlx5e_priv *priv,
 -		  struct tc_cls_flower_offload *f,
 -		  int flags,
 -		  struct net_device *filter_dev,
 -		  struct mlx5e_tc_flow **flow)
 -{
 -	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 -	u16 flow_flags;
 -	int err;
 -
 -	get_flags(flags, &flow_flags);
 -
 -	if (!tc_can_offload_extack(priv->netdev, f->common.extack))
 -		return -EOPNOTSUPP;
 -
 -	if (esw && esw->mode == SRIOV_OFFLOADS)
 -		err = mlx5e_add_fdb_flow(priv, f, flow_flags,
 -					 filter_dev, flow);
 -	else
 -		err = mlx5e_add_nic_flow(priv, f, flow_flags,
 -					 filter_dev, flow);
 -
 -	return err;
 -}
 -
 -int mlx5e_configure_flower(struct net_device *dev, struct mlx5e_priv *priv,
 -			   struct tc_cls_flower_offload *f, int flags)
 -{
 -	struct netlink_ext_ack *extack = f->common.extack;
 -	struct rhashtable *tc_ht = get_tc_ht(priv, flags);
 -	struct mlx5e_tc_flow *flow;
 -	int err = 0;
 -
 -	flow = rhashtable_lookup_fast(tc_ht, &f->cookie, tc_ht_params);
 -	if (flow) {
 -		NL_SET_ERR_MSG_MOD(extack,
 -				   "flow cookie already exists, ignoring");
 -		netdev_warn_once(priv->netdev,
 -				 "flow cookie %lx already exists, ignoring\n",
 -				 f->cookie);
 -		goto out;
 -	}
 -
 -	err = mlx5e_tc_add_flow(priv, f, flags, dev, &flow);
 -	if (err)
 -		goto out;
 +	if (!(flow->flags & MLX5E_TC_FLOW_ESWITCH) ||
 +	    !(flow->esw_attr->action &
 +	      MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT))
 +		kvfree(parse_attr);
  
  	err = rhashtable_insert_fast(tc_ht, &flow->node, tc_ht_params);
 -	if (err)
 -		goto err_free;
 +	if (err) {
 +		mlx5e_tc_del_flow(priv, flow);
 +		kfree(flow);
 +	}
  
 -	return 0;
 +	return err;
  
  err_free:
 -	mlx5e_tc_del_flow(priv, flow);
 +	kvfree(parse_attr);
  	kfree(flow);
 -out:
  	return err;
  }
  
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
