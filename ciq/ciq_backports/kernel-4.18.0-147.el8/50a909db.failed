nvmet: use IOCB_NOWAIT for file-ns buffered I/O

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
commit 50a909db36f244bcfec6e02598d31c0b0a468175
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/50a909db.failed

This patch optimizes read command behavior when file-ns configured
with buffered I/O. Instead of offloading the buffered I/O read operations
to the worker threads, we first issue the read operation with IOCB_NOWAIT
and try and access the data from the cache. Here we only offload the
request to the worker thread and complete the request in the worker
thread context when IOCB_NOWAIT request fails.

	Signed-off-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 50a909db36f244bcfec6e02598d31c0b0a468175)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/target/io-cmd-file.c
diff --cc drivers/nvme/target/io-cmd-file.c
index 1500690046b1,12eaa8ddc248..000000000000
--- a/drivers/nvme/target/io-cmd-file.c
+++ b/drivers/nvme/target/io-cmd-file.c
@@@ -100,14 -104,9 +99,9 @@@ static ssize_t nvmet_file_submit_bvec(s
  
  	iocb->ki_pos = pos;
  	iocb->ki_filp = req->ns->file;
 -	iocb->ki_flags = ki_flags | iocb_flags(req->ns->file);
 +	iocb->ki_flags = IOCB_DIRECT | ki_flags;
  
- 	ret = call_iter(iocb, &iter);
- 
- 	if (ret != -EIOCBQUEUED && iocb->ki_complete)
- 		iocb->ki_complete(iocb, ret, 0);
- 
- 	return ret;
+ 	return call_iter(iocb, &iter);
  }
  
  static void nvmet_file_io_done(struct kiocb *iocb, long ret, long ret2)
@@@ -182,17 -166,99 +161,102 @@@ static bool nvmet_file_execute_io(struc
  		nr_bvec--;
  	}
  
- 	if (WARN_ON_ONCE(total_len != req->data_len))
+ 	if (WARN_ON_ONCE(total_len != req->data_len)) {
  		ret = -EIO;
- out:
- 	if (unlikely(is_sync || ret)) {
- 		nvmet_file_io_done(&req->f.iocb, ret < 0 ? ret : total_len, 0);
+ 		goto complete;
+ 	}
+ 
+ 	if (unlikely(is_sync)) {
+ 		ret = total_len;
+ 		goto complete;
+ 	}
+ 
+ 	/*
+ 	 * A NULL ki_complete ask for synchronous execution, which we want
+ 	 * for the IOCB_NOWAIT case.
+ 	 */
+ 	if (!(ki_flags & IOCB_NOWAIT))
+ 		req->f.iocb.ki_complete = nvmet_file_io_done;
+ 
+ 	ret = nvmet_file_submit_bvec(req, pos, bv_cnt, total_len, ki_flags);
+ 
+ 	switch (ret) {
+ 	case -EIOCBQUEUED:
+ 		return true;
+ 	case -EAGAIN:
+ 		if (WARN_ON_ONCE(!(ki_flags & IOCB_NOWAIT)))
+ 			goto complete;
+ 		return false;
+ 	case -EOPNOTSUPP:
+ 		/*
+ 		 * For file systems returning error -EOPNOTSUPP, handle
+ 		 * IOCB_NOWAIT error case separately and retry without
+ 		 * IOCB_NOWAIT.
+ 		 */
+ 		if ((ki_flags & IOCB_NOWAIT))
+ 			return false;
+ 		break;
+ 	}
+ 
+ complete:
+ 	nvmet_file_io_done(&req->f.iocb, ret, 0);
+ 	return true;
+ }
+ 
++<<<<<<< HEAD
++=======
+ static void nvmet_file_buffered_io_work(struct work_struct *w)
+ {
+ 	struct nvmet_req *req = container_of(w, struct nvmet_req, f.work);
+ 
+ 	nvmet_file_execute_io(req, 0);
+ }
+ 
+ static void nvmet_file_submit_buffered_io(struct nvmet_req *req)
+ {
+ 	INIT_WORK(&req->f.work, nvmet_file_buffered_io_work);
+ 	queue_work(buffered_io_wq, &req->f.work);
+ }
+ 
+ static void nvmet_file_execute_rw(struct nvmet_req *req)
+ {
+ 	ssize_t nr_bvec = DIV_ROUND_UP(req->data_len, PAGE_SIZE);
+ 
+ 	if (!req->sg_cnt || !nr_bvec) {
+ 		nvmet_req_complete(req, 0);
  		return;
  	}
- 	req->f.iocb.ki_complete = nvmet_file_io_done;
- 	nvmet_file_submit_bvec(req, pos, bv_cnt, total_len);
+ 
+ 	if (nr_bvec > NVMET_MAX_INLINE_BIOVEC)
+ 		req->f.bvec = kmalloc_array(nr_bvec, sizeof(struct bio_vec),
+ 				GFP_KERNEL);
+ 	else
+ 		req->f.bvec = req->inline_bvec;
+ 
+ 	if (unlikely(!req->f.bvec)) {
+ 		/* fallback under memory pressure */
+ 		req->f.bvec = mempool_alloc(req->ns->bvec_pool, GFP_KERNEL);
+ 		req->f.mpool_alloc = true;
+ 	} else
+ 		req->f.mpool_alloc = false;
+ 
+ 	if (req->ns->buffered_io) {
+ 		if (likely(!req->f.mpool_alloc) &&
+ 				nvmet_file_execute_io(req, IOCB_NOWAIT))
+ 			return;
+ 		nvmet_file_submit_buffered_io(req);
+ 	} else
+ 		nvmet_file_execute_io(req, 0);
+ }
+ 
+ u16 nvmet_file_flush(struct nvmet_req *req)
+ {
+ 	if (vfs_fsync(req->ns->file, 1) < 0)
+ 		return NVME_SC_INTERNAL | NVME_SC_DNR;
+ 	return 0;
  }
  
++>>>>>>> 50a909db36f2 (nvmet: use IOCB_NOWAIT for file-ns buffered I/O)
  static void nvmet_file_flush_work(struct work_struct *w)
  {
  	struct nvmet_req *req = container_of(w, struct nvmet_req, f.work);
* Unmerged path drivers/nvme/target/io-cmd-file.c
