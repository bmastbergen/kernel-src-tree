RDMA/mlx5: Use the uapi disablement APIs instead of code

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Jason Gunthorpe <jgg@ziepe.ca>
commit 36e235c8829935a59d4652c878cffb08229205c2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/36e235c8.failed

Rely on UAPI_DEF_IS_OBJ_SUPPORTED instead of manipulating the contents of
the driver's definition list.

	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
(cherry picked from commit 36e235c8829935a59d4652c878cffb08229205c2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/devx.c
#	drivers/infiniband/hw/mlx5/main.c
diff --cc drivers/infiniband/hw/mlx5/devx.c
index c7f8859c08ee,ee8db8d9e919..000000000000
--- a/drivers/infiniband/hw/mlx5/devx.c
+++ b/drivers/infiniband/hw/mlx5/devx.c
@@@ -428,47 -969,377 +428,396 @@@ obj_free
  	return err;
  }
  
 -static int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_OBJ_MODIFY)(
 -	struct ib_uverbs_file *file, struct uverbs_attr_bundle *attrs)
 -{
 -	void *cmd_in = uverbs_attr_get_alloced_ptr(attrs, MLX5_IB_ATTR_DEVX_OBJ_MODIFY_CMD_IN);
 -	int cmd_out_len = uverbs_attr_get_len(attrs,
 -					MLX5_IB_ATTR_DEVX_OBJ_MODIFY_CMD_OUT);
 -	struct ib_uobject *uobj = uverbs_attr_get_uobject(attrs,
 -							  MLX5_IB_ATTR_DEVX_OBJ_MODIFY_HANDLE);
 -	struct mlx5_ib_ucontext *c = to_mucontext(uobj->context);
 -	struct devx_obj *obj = uobj->object;
 -	void *cmd_out;
 -	int err;
 -	int uid;
 -
 -	uid = devx_get_uid(c, cmd_in);
 -	if (uid < 0)
 -		return uid;
 -
 -	if (!devx_is_obj_modify_cmd(cmd_in))
 -		return -EINVAL;
 -
 -	if (!devx_is_valid_obj_id(obj, cmd_in))
 -		return -EINVAL;
 -
 -	cmd_out = uverbs_zalloc(attrs, cmd_out_len);
 -	if (IS_ERR(cmd_out))
 -		return PTR_ERR(cmd_out);
 -
 +static DECLARE_UVERBS_NAMED_METHOD(MLX5_IB_METHOD_DEVX_OTHER,
 +	&UVERBS_ATTR_PTR_IN_SZ(MLX5_IB_ATTR_DEVX_OTHER_CMD_IN,
 +			       UVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_in_cmd_hdr)),
 +			       UA_FLAGS(UVERBS_ATTR_SPEC_F_MANDATORY |
 +					UVERBS_ATTR_SPEC_F_MIN_SZ_OR_ZERO |
 +					UVERBS_ATTR_SPEC_F_ALLOC_AND_COPY)),
 +	&UVERBS_ATTR_PTR_OUT_SZ(MLX5_IB_ATTR_DEVX_OTHER_CMD_OUT,
 +				UVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_out_cmd_hdr)),
 +				UA_FLAGS(UVERBS_ATTR_SPEC_F_MANDATORY |
 +					 UVERBS_ATTR_SPEC_F_MIN_SZ_OR_ZERO))
 +);
 +
 +static DECLARE_UVERBS_NAMED_METHOD(MLX5_IB_METHOD_DEVX_OBJ_CREATE,
 +	&UVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_OBJ_CREATE_HANDLE,
 +			 MLX5_IB_OBJECT_DEVX_OBJ,
 +			 UVERBS_ACCESS_NEW,
 +			 UA_FLAGS(UVERBS_ATTR_SPEC_F_MANDATORY)),
 +	&UVERBS_ATTR_PTR_IN_SZ(MLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_IN,
 +			       UVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_in_cmd_hdr)),
 +			       UA_FLAGS(UVERBS_ATTR_SPEC_F_MANDATORY |
 +					UVERBS_ATTR_SPEC_F_MIN_SZ_OR_ZERO |
 +					UVERBS_ATTR_SPEC_F_ALLOC_AND_COPY)),
 +	&UVERBS_ATTR_PTR_OUT_SZ(MLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_OUT,
 +				UVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_out_cmd_hdr)),
 +				UA_FLAGS(UVERBS_ATTR_SPEC_F_MANDATORY |
 +					 UVERBS_ATTR_SPEC_F_MIN_SZ_OR_ZERO)));
 +
 +static DECLARE_UVERBS_NAMED_METHOD(MLX5_IB_METHOD_DEVX_OBJ_DESTROY,
 +	&UVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_OBJ_DESTROY_HANDLE,
 +			 MLX5_IB_OBJECT_DEVX_OBJ,
 +			 UVERBS_ACCESS_DESTROY,
 +			 UA_FLAGS(UVERBS_ATTR_SPEC_F_MANDATORY)));
 +
 +static DECLARE_UVERBS_GLOBAL_METHODS(MLX5_IB_OBJECT_DEVX,
 +	&UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OTHER));
 +
 +static DECLARE_UVERBS_NAMED_OBJECT(MLX5_IB_OBJECT_DEVX_OBJ,
 +	&UVERBS_TYPE_ALLOC_IDR(0, devx_obj_cleanup),
 +		&UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OBJ_CREATE),
 +		&UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OBJ_DESTROY));
 +
++<<<<<<< HEAD
 +static DECLARE_UVERBS_OBJECT_TREE(devx_objects,
 +	&UVERBS_OBJECT(MLX5_IB_OBJECT_DEVX),
 +	&UVERBS_OBJECT(MLX5_IB_OBJECT_DEVX_OBJ));
++=======
+ 	MLX5_SET(general_obj_in_cmd_hdr, cmd_in, uid, uid);
+ 	devx_set_umem_valid(cmd_in);
+ 
+ 	err = mlx5_cmd_exec(obj->mdev, cmd_in,
+ 			    uverbs_attr_get_len(attrs, MLX5_IB_ATTR_DEVX_OBJ_MODIFY_CMD_IN),
+ 			    cmd_out, cmd_out_len);
+ 	if (err)
+ 		return err;
+ 
+ 	return uverbs_copy_to(attrs, MLX5_IB_ATTR_DEVX_OBJ_MODIFY_CMD_OUT,
+ 			      cmd_out, cmd_out_len);
+ }
+ 
+ static int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_OBJ_QUERY)(
+ 	struct ib_uverbs_file *file, struct uverbs_attr_bundle *attrs)
+ {
+ 	void *cmd_in = uverbs_attr_get_alloced_ptr(attrs, MLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_IN);
+ 	int cmd_out_len = uverbs_attr_get_len(attrs,
+ 					      MLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_OUT);
+ 	struct ib_uobject *uobj = uverbs_attr_get_uobject(attrs,
+ 							  MLX5_IB_ATTR_DEVX_OBJ_QUERY_HANDLE);
+ 	struct mlx5_ib_ucontext *c = to_mucontext(uobj->context);
+ 	struct devx_obj *obj = uobj->object;
+ 	void *cmd_out;
+ 	int err;
+ 	int uid;
+ 
+ 	uid = devx_get_uid(c, cmd_in);
+ 	if (uid < 0)
+ 		return uid;
+ 
+ 	if (!devx_is_obj_query_cmd(cmd_in))
+ 		return -EINVAL;
+ 
+ 	if (!devx_is_valid_obj_id(obj, cmd_in))
+ 		return -EINVAL;
+ 
+ 	cmd_out = uverbs_zalloc(attrs, cmd_out_len);
+ 	if (IS_ERR(cmd_out))
+ 		return PTR_ERR(cmd_out);
+ 
+ 	MLX5_SET(general_obj_in_cmd_hdr, cmd_in, uid, uid);
+ 	err = mlx5_cmd_exec(obj->mdev, cmd_in,
+ 			    uverbs_attr_get_len(attrs, MLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_IN),
+ 			    cmd_out, cmd_out_len);
+ 	if (err)
+ 		return err;
+ 
+ 	return uverbs_copy_to(attrs, MLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_OUT,
+ 			      cmd_out, cmd_out_len);
+ }
+ 
+ static int devx_umem_get(struct mlx5_ib_dev *dev, struct ib_ucontext *ucontext,
+ 			 struct uverbs_attr_bundle *attrs,
+ 			 struct devx_umem *obj)
+ {
+ 	u64 addr;
+ 	size_t size;
+ 	u32 access;
+ 	int npages;
+ 	int err;
+ 	u32 page_mask;
+ 
+ 	if (uverbs_copy_from(&addr, attrs, MLX5_IB_ATTR_DEVX_UMEM_REG_ADDR) ||
+ 	    uverbs_copy_from(&size, attrs, MLX5_IB_ATTR_DEVX_UMEM_REG_LEN))
+ 		return -EFAULT;
+ 
+ 	err = uverbs_get_flags32(&access, attrs,
+ 				 MLX5_IB_ATTR_DEVX_UMEM_REG_ACCESS,
+ 				 IB_ACCESS_SUPPORTED);
+ 	if (err)
+ 		return err;
+ 
+ 	err = ib_check_mr_access(access);
+ 	if (err)
+ 		return err;
+ 
+ 	obj->umem = ib_umem_get(ucontext, addr, size, access, 0);
+ 	if (IS_ERR(obj->umem))
+ 		return PTR_ERR(obj->umem);
+ 
+ 	mlx5_ib_cont_pages(obj->umem, obj->umem->address,
+ 			   MLX5_MKEY_PAGE_SHIFT_MASK, &npages,
+ 			   &obj->page_shift, &obj->ncont, NULL);
+ 
+ 	if (!npages) {
+ 		ib_umem_release(obj->umem);
+ 		return -EINVAL;
+ 	}
+ 
+ 	page_mask = (1 << obj->page_shift) - 1;
+ 	obj->page_offset = obj->umem->address & page_mask;
+ 
+ 	return 0;
+ }
+ 
+ static int devx_umem_reg_cmd_alloc(struct uverbs_attr_bundle *attrs,
+ 				   struct devx_umem *obj,
+ 				   struct devx_umem_reg_cmd *cmd)
+ {
+ 	cmd->inlen = MLX5_ST_SZ_BYTES(create_umem_in) +
+ 		    (MLX5_ST_SZ_BYTES(mtt) * obj->ncont);
+ 	cmd->in = uverbs_zalloc(attrs, cmd->inlen);
+ 	return PTR_ERR_OR_ZERO(cmd->in);
+ }
+ 
+ static void devx_umem_reg_cmd_build(struct mlx5_ib_dev *dev,
+ 				    struct devx_umem *obj,
+ 				    struct devx_umem_reg_cmd *cmd)
+ {
+ 	void *umem;
+ 	__be64 *mtt;
+ 
+ 	umem = MLX5_ADDR_OF(create_umem_in, cmd->in, umem);
+ 	mtt = (__be64 *)MLX5_ADDR_OF(umem, umem, mtt);
+ 
+ 	MLX5_SET(general_obj_in_cmd_hdr, cmd->in, opcode, MLX5_CMD_OP_CREATE_GENERAL_OBJECT);
+ 	MLX5_SET(general_obj_in_cmd_hdr, cmd->in, obj_type, MLX5_OBJ_TYPE_UMEM);
+ 	MLX5_SET64(umem, umem, num_of_mtt, obj->ncont);
+ 	MLX5_SET(umem, umem, log_page_size, obj->page_shift -
+ 					    MLX5_ADAPTER_PAGE_SHIFT);
+ 	MLX5_SET(umem, umem, page_offset, obj->page_offset);
+ 	mlx5_ib_populate_pas(dev, obj->umem, obj->page_shift, mtt,
+ 			     (obj->umem->writable ? MLX5_IB_MTT_WRITE : 0) |
+ 			     MLX5_IB_MTT_READ);
+ }
+ 
+ static int UVERBS_HANDLER(MLX5_IB_METHOD_DEVX_UMEM_REG)(
+ 	struct ib_uverbs_file *file, struct uverbs_attr_bundle *attrs)
+ {
+ 	struct devx_umem_reg_cmd cmd;
+ 	struct devx_umem *obj;
+ 	struct ib_uobject *uobj = uverbs_attr_get_uobject(
+ 		attrs, MLX5_IB_ATTR_DEVX_UMEM_REG_HANDLE);
+ 	u32 obj_id;
+ 	struct mlx5_ib_ucontext *c = to_mucontext(uobj->context);
+ 	struct mlx5_ib_dev *dev = to_mdev(c->ibucontext.device);
+ 	int err;
+ 
+ 	if (!c->devx_uid)
+ 		return -EINVAL;
+ 
+ 	if (!capable(CAP_NET_RAW))
+ 		return -EPERM;
+ 
+ 	obj = kzalloc(sizeof(struct devx_umem), GFP_KERNEL);
+ 	if (!obj)
+ 		return -ENOMEM;
+ 
+ 	err = devx_umem_get(dev, &c->ibucontext, attrs, obj);
+ 	if (err)
+ 		goto err_obj_free;
+ 
+ 	err = devx_umem_reg_cmd_alloc(attrs, obj, &cmd);
+ 	if (err)
+ 		goto err_umem_release;
+ 
+ 	devx_umem_reg_cmd_build(dev, obj, &cmd);
+ 
+ 	MLX5_SET(general_obj_in_cmd_hdr, cmd.in, uid, c->devx_uid);
+ 	err = mlx5_cmd_exec(dev->mdev, cmd.in, cmd.inlen, cmd.out,
+ 			    sizeof(cmd.out));
+ 	if (err)
+ 		goto err_umem_release;
+ 
+ 	obj->mdev = dev->mdev;
+ 	uobj->object = obj;
+ 	devx_obj_build_destroy_cmd(cmd.in, cmd.out, obj->dinbox, &obj->dinlen, &obj_id);
+ 	err = uverbs_copy_to(attrs, MLX5_IB_ATTR_DEVX_UMEM_REG_OUT_ID, &obj_id, sizeof(obj_id));
+ 	if (err)
+ 		goto err_umem_destroy;
+ 
+ 	return 0;
+ 
+ err_umem_destroy:
+ 	mlx5_cmd_exec(obj->mdev, obj->dinbox, obj->dinlen, cmd.out, sizeof(cmd.out));
+ err_umem_release:
+ 	ib_umem_release(obj->umem);
+ err_obj_free:
+ 	kfree(obj);
+ 	return err;
+ }
+ 
+ static int devx_umem_cleanup(struct ib_uobject *uobject,
+ 			     enum rdma_remove_reason why)
+ {
+ 	struct devx_umem *obj = uobject->object;
+ 	u32 out[MLX5_ST_SZ_DW(general_obj_out_cmd_hdr)];
+ 	int err;
+ 
+ 	err = mlx5_cmd_exec(obj->mdev, obj->dinbox, obj->dinlen, out, sizeof(out));
+ 	if (ib_is_destroy_retryable(err, why, uobject))
+ 		return err;
+ 
+ 	ib_umem_release(obj->umem);
+ 	kfree(obj);
+ 	return 0;
+ }
+ 
+ DECLARE_UVERBS_NAMED_METHOD(
+ 	MLX5_IB_METHOD_DEVX_UMEM_REG,
+ 	UVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_UMEM_REG_HANDLE,
+ 			MLX5_IB_OBJECT_DEVX_UMEM,
+ 			UVERBS_ACCESS_NEW,
+ 			UA_MANDATORY),
+ 	UVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_DEVX_UMEM_REG_ADDR,
+ 			   UVERBS_ATTR_TYPE(u64),
+ 			   UA_MANDATORY),
+ 	UVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_DEVX_UMEM_REG_LEN,
+ 			   UVERBS_ATTR_TYPE(u64),
+ 			   UA_MANDATORY),
+ 	UVERBS_ATTR_FLAGS_IN(MLX5_IB_ATTR_DEVX_UMEM_REG_ACCESS,
+ 			     enum ib_access_flags),
+ 	UVERBS_ATTR_PTR_OUT(MLX5_IB_ATTR_DEVX_UMEM_REG_OUT_ID,
+ 			    UVERBS_ATTR_TYPE(u32),
+ 			    UA_MANDATORY));
+ 
+ DECLARE_UVERBS_NAMED_METHOD_DESTROY(
+ 	MLX5_IB_METHOD_DEVX_UMEM_DEREG,
+ 	UVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_UMEM_DEREG_HANDLE,
+ 			MLX5_IB_OBJECT_DEVX_UMEM,
+ 			UVERBS_ACCESS_DESTROY,
+ 			UA_MANDATORY));
+ 
+ DECLARE_UVERBS_NAMED_METHOD(
+ 	MLX5_IB_METHOD_DEVX_QUERY_EQN,
+ 	UVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_DEVX_QUERY_EQN_USER_VEC,
+ 			   UVERBS_ATTR_TYPE(u32),
+ 			   UA_MANDATORY),
+ 	UVERBS_ATTR_PTR_OUT(MLX5_IB_ATTR_DEVX_QUERY_EQN_DEV_EQN,
+ 			    UVERBS_ATTR_TYPE(u32),
+ 			    UA_MANDATORY));
+ 
+ DECLARE_UVERBS_NAMED_METHOD(
+ 	MLX5_IB_METHOD_DEVX_QUERY_UAR,
+ 	UVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_DEVX_QUERY_UAR_USER_IDX,
+ 			   UVERBS_ATTR_TYPE(u32),
+ 			   UA_MANDATORY),
+ 	UVERBS_ATTR_PTR_OUT(MLX5_IB_ATTR_DEVX_QUERY_UAR_DEV_IDX,
+ 			    UVERBS_ATTR_TYPE(u32),
+ 			    UA_MANDATORY));
+ 
+ DECLARE_UVERBS_NAMED_METHOD(
+ 	MLX5_IB_METHOD_DEVX_OTHER,
+ 	UVERBS_ATTR_PTR_IN(
+ 		MLX5_IB_ATTR_DEVX_OTHER_CMD_IN,
+ 		UVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_in_cmd_hdr)),
+ 		UA_MANDATORY,
+ 		UA_ALLOC_AND_COPY),
+ 	UVERBS_ATTR_PTR_OUT(
+ 		MLX5_IB_ATTR_DEVX_OTHER_CMD_OUT,
+ 		UVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_out_cmd_hdr)),
+ 		UA_MANDATORY));
+ 
+ DECLARE_UVERBS_NAMED_METHOD(
+ 	MLX5_IB_METHOD_DEVX_OBJ_CREATE,
+ 	UVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_OBJ_CREATE_HANDLE,
+ 			MLX5_IB_OBJECT_DEVX_OBJ,
+ 			UVERBS_ACCESS_NEW,
+ 			UA_MANDATORY),
+ 	UVERBS_ATTR_PTR_IN(
+ 		MLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_IN,
+ 		UVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_in_cmd_hdr)),
+ 		UA_MANDATORY,
+ 		UA_ALLOC_AND_COPY),
+ 	UVERBS_ATTR_PTR_OUT(
+ 		MLX5_IB_ATTR_DEVX_OBJ_CREATE_CMD_OUT,
+ 		UVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_out_cmd_hdr)),
+ 		UA_MANDATORY));
+ 
+ DECLARE_UVERBS_NAMED_METHOD_DESTROY(
+ 	MLX5_IB_METHOD_DEVX_OBJ_DESTROY,
+ 	UVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_OBJ_DESTROY_HANDLE,
+ 			MLX5_IB_OBJECT_DEVX_OBJ,
+ 			UVERBS_ACCESS_DESTROY,
+ 			UA_MANDATORY));
+ 
+ DECLARE_UVERBS_NAMED_METHOD(
+ 	MLX5_IB_METHOD_DEVX_OBJ_MODIFY,
+ 	UVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_OBJ_MODIFY_HANDLE,
+ 			MLX5_IB_OBJECT_DEVX_OBJ,
+ 			UVERBS_ACCESS_WRITE,
+ 			UA_MANDATORY),
+ 	UVERBS_ATTR_PTR_IN(
+ 		MLX5_IB_ATTR_DEVX_OBJ_MODIFY_CMD_IN,
+ 		UVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_in_cmd_hdr)),
+ 		UA_MANDATORY,
+ 		UA_ALLOC_AND_COPY),
+ 	UVERBS_ATTR_PTR_OUT(
+ 		MLX5_IB_ATTR_DEVX_OBJ_MODIFY_CMD_OUT,
+ 		UVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_out_cmd_hdr)),
+ 		UA_MANDATORY));
+ 
+ DECLARE_UVERBS_NAMED_METHOD(
+ 	MLX5_IB_METHOD_DEVX_OBJ_QUERY,
+ 	UVERBS_ATTR_IDR(MLX5_IB_ATTR_DEVX_OBJ_QUERY_HANDLE,
+ 			MLX5_IB_OBJECT_DEVX_OBJ,
+ 			UVERBS_ACCESS_READ,
+ 			UA_MANDATORY),
+ 	UVERBS_ATTR_PTR_IN(
+ 		MLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_IN,
+ 		UVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_in_cmd_hdr)),
+ 		UA_MANDATORY,
+ 		UA_ALLOC_AND_COPY),
+ 	UVERBS_ATTR_PTR_OUT(
+ 		MLX5_IB_ATTR_DEVX_OBJ_QUERY_CMD_OUT,
+ 		UVERBS_ATTR_MIN_SIZE(MLX5_ST_SZ_BYTES(general_obj_out_cmd_hdr)),
+ 		UA_MANDATORY));
+ 
+ DECLARE_UVERBS_GLOBAL_METHODS(MLX5_IB_OBJECT_DEVX,
+ 			      &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OTHER),
+ 			      &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_QUERY_UAR),
+ 			      &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_QUERY_EQN));
+ 
+ DECLARE_UVERBS_NAMED_OBJECT(MLX5_IB_OBJECT_DEVX_OBJ,
+ 			    UVERBS_TYPE_ALLOC_IDR(devx_obj_cleanup),
+ 			    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OBJ_CREATE),
+ 			    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OBJ_DESTROY),
+ 			    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OBJ_MODIFY),
+ 			    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_OBJ_QUERY));
+ 
+ DECLARE_UVERBS_NAMED_OBJECT(MLX5_IB_OBJECT_DEVX_UMEM,
+ 			    UVERBS_TYPE_ALLOC_IDR(devx_umem_cleanup),
+ 			    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_UMEM_REG),
+ 			    &UVERBS_METHOD(MLX5_IB_METHOD_DEVX_UMEM_DEREG));
+ 
+ static bool devx_is_supported(struct ib_device *device)
+ {
+ 	struct mlx5_ib_dev *dev = to_mdev(device);
+ 
+ 	return !dev->rep && MLX5_CAP_GEN_64(dev->mdev, general_obj_types) &
+ 				    MLX5_GENERAL_OBJ_TYPES_CAP_UCTX;
+ }
+ 
+ const struct uapi_definition mlx5_ib_devx_defs[] = {
+ 	UAPI_DEF_CHAIN_OBJ_TREE_NAMED(
+ 		MLX5_IB_OBJECT_DEVX,
+ 		UAPI_DEF_IS_OBJ_SUPPORTED(devx_is_supported)),
+ 	UAPI_DEF_CHAIN_OBJ_TREE_NAMED(
+ 		MLX5_IB_OBJECT_DEVX_OBJ,
+ 		UAPI_DEF_IS_OBJ_SUPPORTED(devx_is_supported)),
+ 	UAPI_DEF_CHAIN_OBJ_TREE_NAMED(
+ 		MLX5_IB_OBJECT_DEVX_UMEM,
+ 		UAPI_DEF_IS_OBJ_SUPPORTED(devx_is_supported)),
+ 	{},
+ };
++>>>>>>> 36e235c88299 (RDMA/mlx5: Use the uapi disablement APIs instead of code)
diff --cc drivers/infiniband/hw/mlx5/main.c
index 72ce00f38f1d,0707ede7dcdd..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -5262,47 -5532,36 +5262,69 @@@ static void mlx5_ib_cleanup_multiport_m
  	mlx5_nic_vport_disable_roce(dev->mdev);
  }
  
 -ADD_UVERBS_ATTRIBUTES_SIMPLE(
 -	mlx5_ib_dm,
 -	UVERBS_OBJECT_DM,
 -	UVERBS_METHOD_DM_ALLOC,
 -	UVERBS_ATTR_PTR_OUT(MLX5_IB_ATTR_ALLOC_DM_RESP_START_OFFSET,
 -			    UVERBS_ATTR_TYPE(u64),
 -			    UA_MANDATORY),
 -	UVERBS_ATTR_PTR_OUT(MLX5_IB_ATTR_ALLOC_DM_RESP_PAGE_INDEX,
 -			    UVERBS_ATTR_TYPE(u16),
 -			    UA_MANDATORY));
 +ADD_UVERBS_ATTRIBUTES_SIMPLE(mlx5_ib_dm, UVERBS_OBJECT_DM,
 +			     UVERBS_METHOD_DM_ALLOC,
 +			     &UVERBS_ATTR_PTR_OUT(MLX5_IB_ATTR_ALLOC_DM_RESP_START_OFFSET,
 +						  UVERBS_ATTR_TYPE(u64),
 +						  UA_FLAGS(UVERBS_ATTR_SPEC_F_MANDATORY)),
 +			     &UVERBS_ATTR_PTR_OUT(MLX5_IB_ATTR_ALLOC_DM_RESP_PAGE_INDEX,
 +						  UVERBS_ATTR_TYPE(u16),
 +						  UA_FLAGS(UVERBS_ATTR_SPEC_F_MANDATORY)));
 +
++<<<<<<< HEAD
 +ADD_UVERBS_ATTRIBUTES_SIMPLE(mlx5_ib_flow_action, UVERBS_OBJECT_FLOW_ACTION,
 +			     UVERBS_METHOD_FLOW_ACTION_ESP_CREATE,
 +			     &UVERBS_ATTR_PTR_IN(MLX5_IB_ATTR_CREATE_FLOW_ACTION_FLAGS,
 +						 UVERBS_ATTR_TYPE(u64),
 +						 UA_FLAGS(UVERBS_ATTR_SPEC_F_MANDATORY)));
 +
 +#define NUM_TREES	2
 +static int populate_specs_root(struct mlx5_ib_dev *dev)
 +{
 +	const struct uverbs_object_tree_def *default_root[NUM_TREES + 1] = {
 +		uverbs_default_get_objects()};
 +	size_t num_trees = 1;
 +
 +	if (mlx5_accel_ipsec_device_caps(dev->mdev) & MLX5_ACCEL_IPSEC_CAP_DEVICE &&
 +	    !WARN_ON(num_trees >= ARRAY_SIZE(default_root)))
 +		default_root[num_trees++] = &mlx5_ib_flow_action;
 +
 +	if (MLX5_CAP_DEV_MEM(dev->mdev, memic) &&
 +	    !WARN_ON(num_trees >= ARRAY_SIZE(default_root)))
 +		default_root[num_trees++] = &mlx5_ib_dm;
 +
 +	dev->ib_dev.specs_root =
 +		uverbs_alloc_spec_tree(num_trees, default_root);
 +
 +	return PTR_ERR_OR_ZERO(dev->ib_dev.specs_root);
 +}
 +
 +static void depopulate_specs_root(struct mlx5_ib_dev *dev)
 +{
 +	uverbs_free_spec_tree(dev->ib_dev.specs_root);
 +}
  
++=======
+ ADD_UVERBS_ATTRIBUTES_SIMPLE(
+ 	mlx5_ib_flow_action,
+ 	UVERBS_OBJECT_FLOW_ACTION,
+ 	UVERBS_METHOD_FLOW_ACTION_ESP_CREATE,
+ 	UVERBS_ATTR_FLAGS_IN(MLX5_IB_ATTR_CREATE_FLOW_ACTION_FLAGS,
+ 			     enum mlx5_ib_uapi_flow_action_flags));
+ 
+ static const struct uapi_definition mlx5_ib_defs[] = {
+ #if IS_ENABLED(CONFIG_INFINIBAND_USER_ACCESS)
+ 	UAPI_DEF_CHAIN(mlx5_ib_devx_defs),
+ 	UAPI_DEF_CHAIN(mlx5_ib_flow_defs),
+ #endif
+ 
+ 	UAPI_DEF_CHAIN_OBJ_TREE(UVERBS_OBJECT_FLOW_ACTION,
+ 				&mlx5_ib_flow_action),
+ 	UAPI_DEF_CHAIN_OBJ_TREE(UVERBS_OBJECT_DM, &mlx5_ib_dm),
+ 	{}
+ };
+ 
++>>>>>>> 36e235c88299 (RDMA/mlx5: Use the uapi disablement APIs instead of code)
  static int mlx5_ib_read_counters(struct ib_counters *counters,
  				 struct ib_counters_read_attr *read_attr,
  				 struct uverbs_attr_bundle *attrs)
@@@ -5828,19 -6093,16 +5853,14 @@@ void mlx5_ib_stage_bfrag_cleanup(struc
  	mlx5_free_bfreg(dev->mdev, &dev->bfreg);
  }
  
- static int mlx5_ib_stage_populate_specs(struct mlx5_ib_dev *dev)
- {
- 	return populate_specs_root(dev);
- }
- 
  int mlx5_ib_stage_ib_reg_init(struct mlx5_ib_dev *dev)
  {
 -	const char *name;
 +	return ib_register_device(&dev->ib_dev, NULL);
 +}
  
 -	rdma_set_device_sysfs_group(&dev->ib_dev, &mlx5_attr_group);
 -	if (!mlx5_lag_is_active(dev->mdev))
 -		name = "mlx5_%d";
 -	else
 -		name = "mlx5_bond_%d";
 -	return ib_register_device(&dev->ib_dev, name, NULL);
 +static void mlx5_ib_stage_depopulate_specs(struct mlx5_ib_dev *dev)
 +{
 +	depopulate_specs_root(dev);
  }
  
  void mlx5_ib_stage_pre_ib_reg_umr_cleanup(struct mlx5_ib_dev *dev)
@@@ -5973,9 -6227,6 +5993,12 @@@ static const struct mlx5_ib_profile pf_
  	STAGE_CREATE(MLX5_IB_STAGE_PRE_IB_REG_UMR,
  		     NULL,
  		     mlx5_ib_stage_pre_ib_reg_umr_cleanup),
++<<<<<<< HEAD
 +	STAGE_CREATE(MLX5_IB_STAGE_SPECS,
 +		     mlx5_ib_stage_populate_specs,
 +		     mlx5_ib_stage_depopulate_specs),
++=======
++>>>>>>> 36e235c88299 (RDMA/mlx5: Use the uapi disablement APIs instead of code)
  	STAGE_CREATE(MLX5_IB_STAGE_IB_REG,
  		     mlx5_ib_stage_ib_reg_init,
  		     mlx5_ib_stage_ib_reg_cleanup),
@@@ -6021,9 -6269,6 +6044,12 @@@ static const struct mlx5_ib_profile nic
  	STAGE_CREATE(MLX5_IB_STAGE_PRE_IB_REG_UMR,
  		     NULL,
  		     mlx5_ib_stage_pre_ib_reg_umr_cleanup),
++<<<<<<< HEAD
 +	STAGE_CREATE(MLX5_IB_STAGE_SPECS,
 +		     mlx5_ib_stage_populate_specs,
 +		     mlx5_ib_stage_depopulate_specs),
++=======
++>>>>>>> 36e235c88299 (RDMA/mlx5: Use the uapi disablement APIs instead of code)
  	STAGE_CREATE(MLX5_IB_STAGE_IB_REG,
  		     mlx5_ib_stage_ib_reg_init,
  		     mlx5_ib_stage_ib_reg_cleanup),
* Unmerged path drivers/infiniband/hw/mlx5/devx.c
* Unmerged path drivers/infiniband/hw/mlx5/main.c
diff --git a/drivers/infiniband/hw/mlx5/mlx5_ib.h b/drivers/infiniband/hw/mlx5/mlx5_ib.h
index bc0aa5141161..168b561169f1 100644
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -759,7 +759,6 @@ enum mlx5_ib_stages {
 	MLX5_IB_STAGE_UAR,
 	MLX5_IB_STAGE_BFREG,
 	MLX5_IB_STAGE_PRE_IB_REG_UMR,
-	MLX5_IB_STAGE_SPECS,
 	MLX5_IB_STAGE_IB_REG,
 	MLX5_IB_STAGE_POST_IB_REG_UMR,
 	MLX5_IB_STAGE_DELAY_DROP,
