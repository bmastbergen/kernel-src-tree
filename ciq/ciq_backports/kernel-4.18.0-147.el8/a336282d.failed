x86/kvm/nVMX: introduce source data cache for kvm_init_shadow_ept_mmu()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Vitaly Kuznetsov <vkuznets@redhat.com>
commit a336282d7753a92ced7b8e52ff959929f6e550ff
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/a336282d.failed

MMU re-initialization is expensive, in particular,
update_permission_bitmask() and update_pkru_bitmask() are.

Cache the data used to setup shadow EPT MMU and avoid full re-init when
it is unchanged.

	Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
Sean Christopherson <sean.j.christopherson@intel.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit a336282d7753a92ced7b8e52ff959929f6e550ff)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu.c
diff --cc arch/x86/kvm/mmu.c
index 62eff69e3039,9d400a06c5f2..000000000000
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@@ -4821,16 -4844,23 +4835,27 @@@ void kvm_init_shadow_mmu(struct kvm_vcp
  }
  EXPORT_SYMBOL_GPL(kvm_init_shadow_mmu);
  
- static union kvm_mmu_page_role
- kvm_calc_shadow_ept_root_page_role(struct kvm_vcpu *vcpu, bool accessed_dirty)
+ static union kvm_mmu_role
+ kvm_calc_shadow_ept_root_page_role(struct kvm_vcpu *vcpu, bool accessed_dirty,
+ 				   bool execonly)
  {
++<<<<<<< HEAD
 +	union kvm_mmu_page_role role = vcpu->arch.mmu->base_role;
++=======
+ 	union kvm_mmu_role role;
  
- 	role.level = PT64_ROOT_4LEVEL;
- 	role.direct = false;
- 	role.ad_disabled = !accessed_dirty;
- 	role.guest_mode = true;
- 	role.access = ACC_ALL;
+ 	/* Base role is inherited from root_mmu */
+ 	role.base.word = vcpu->arch.root_mmu.mmu_role.base.word;
+ 	role.ext = kvm_calc_mmu_role_ext(vcpu);
++>>>>>>> a336282d7753 (x86/kvm/nVMX: introduce source data cache for kvm_init_shadow_ept_mmu())
+ 
+ 	role.base.level = PT64_ROOT_4LEVEL;
+ 	role.base.direct = false;
+ 	role.base.ad_disabled = !accessed_dirty;
+ 	role.base.guest_mode = true;
+ 	role.base.access = ACC_ALL;
+ 
+ 	role.ext.execonly = execonly;
  
  	return role;
  }
diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index 7d68598fed64..203fe0f3f5e4 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -283,7 +283,21 @@ union kvm_mmu_page_role {
 };
 
 union kvm_mmu_extended_role {
+/*
+ * This structure complements kvm_mmu_page_role caching everything needed for
+ * MMU configuration. If nothing in both these structures changed, MMU
+ * re-configuration can be skipped. @valid bit is set on first usage so we don't
+ * treat all-zero structure as valid data.
+ */
 	u32 word;
+	struct {
+		unsigned int valid:1;
+		unsigned int execonly:1;
+		unsigned int cr4_pse:1;
+		unsigned int cr4_pke:1;
+		unsigned int cr4_smap:1;
+		unsigned int cr4_smep:1;
+	};
 };
 
 union kvm_mmu_role {
* Unmerged path arch/x86/kvm/mmu.c
