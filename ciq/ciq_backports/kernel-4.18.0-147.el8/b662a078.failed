nvmet: enable Discovery Controller AENs

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Jay Sternberg <jay.e.sternberg@intel.com>
commit b662a078576e7d6e235b4e1b94863f0474cd8555
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/b662a078.failed

Add functions to find connections requesting Discovery Change events
and send a notification to hosts that maintain an explicit persistent
connection and have and active Asynchronous Event Request pending.
Only Hosts that have access to the Subsystem effected by the change
will receive notifications of Discovery Change event.

Call these functions each time there is a configfs change that effects
the Discover Log Pages.

Set the OAES field in the Identify Controller response to advertise the
support for Asynchronous Event Notifications.

	Signed-off-by: Jay Sternberg <jay.e.sternberg@intel.com>
	Reviewed-by: Phil Cayton <phil.cayton@intel.com>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit b662a078576e7d6e235b4e1b94863f0474cd8555)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/target/configfs.c
#	drivers/nvme/target/nvmet.h
diff --cc drivers/nvme/target/configfs.c
index 18ed8b8501b1,d37fd7713bbc..000000000000
--- a/drivers/nvme/target/configfs.c
+++ b/drivers/nvme/target/configfs.c
@@@ -949,6 -1149,9 +961,12 @@@ static void nvmet_port_release(struct c
  {
  	struct nvmet_port *port = to_nvmet_port(item);
  
++<<<<<<< HEAD
++=======
+ 	list_del(&port->global_entry);
+ 
+ 	kfree(port->ana_state);
++>>>>>>> b662a078576e (nvmet: enable Discovery Controller AENs)
  	kfree(port);
  }
  
@@@ -985,6 -1189,22 +1003,25 @@@ static struct config_group *nvmet_ports
  	if (!port)
  		return ERR_PTR(-ENOMEM);
  
++<<<<<<< HEAD
++=======
+ 	port->ana_state = kcalloc(NVMET_MAX_ANAGRPS + 1,
+ 			sizeof(*port->ana_state), GFP_KERNEL);
+ 	if (!port->ana_state) {
+ 		kfree(port);
+ 		return ERR_PTR(-ENOMEM);
+ 	}
+ 
+ 	for (i = 1; i <= NVMET_MAX_ANAGRPS; i++) {
+ 		if (i == NVMET_DEFAULT_ANA_GRPID)
+ 			port->ana_state[1] = NVME_ANA_OPTIMIZED;
+ 		else
+ 			port->ana_state[i] = NVME_ANA_INACCESSIBLE;
+ 	}
+ 
+ 	list_add(&port->global_entry, &nvmet_ports_list);
+ 
++>>>>>>> b662a078576e (nvmet: enable Discovery Controller AENs)
  	INIT_LIST_HEAD(&port->entry);
  	INIT_LIST_HEAD(&port->subsystems);
  	INIT_LIST_HEAD(&port->referrals);
diff --cc drivers/nvme/target/nvmet.h
index 71edbd0ba324,31474940e373..000000000000
--- a/drivers/nvme/target/nvmet.h
+++ b/drivers/nvme/target/nvmet.h
@@@ -123,6 -139,10 +123,13 @@@ struct nvmet_port 
  	struct list_head		subsystems;
  	struct config_group		referrals_group;
  	struct list_head		referrals;
++<<<<<<< HEAD
++=======
+ 	struct list_head		global_entry;
+ 	struct config_group		ana_groups_group;
+ 	struct nvmet_ana_group		ana_default_group;
+ 	enum nvme_ana_state		*ana_state;
++>>>>>>> b662a078576e (nvmet: enable Discovery Controller AENs)
  	void				*priv;
  	bool				enabled;
  	int				inline_data_size;
* Unmerged path drivers/nvme/target/configfs.c
diff --git a/drivers/nvme/target/core.c b/drivers/nvme/target/core.c
index f78277df01ea..2cddeb2fb214 100644
--- a/drivers/nvme/target/core.c
+++ b/drivers/nvme/target/core.c
@@ -125,7 +125,7 @@ static void nvmet_async_event_work(struct work_struct *work)
 	}
 }
 
-static void nvmet_add_async_event(struct nvmet_ctrl *ctrl, u8 event_type,
+void nvmet_add_async_event(struct nvmet_ctrl *ctrl, u8 event_type,
 		u8 event_info, u8 log_page)
 {
 	struct nvmet_async_event *aen;
diff --git a/drivers/nvme/target/discovery.c b/drivers/nvme/target/discovery.c
index 60a4baacdfd3..14cc2a1666af 100644
--- a/drivers/nvme/target/discovery.c
+++ b/drivers/nvme/target/discovery.c
@@ -20,24 +20,82 @@ struct nvmet_subsys *nvmet_disc_subsys;
 
 static u64 nvmet_genctr;
 
+static void __nvmet_disc_changed(struct nvmet_port *port,
+				 struct nvmet_ctrl *ctrl)
+{
+	if (ctrl->port != port)
+		return;
+
+	if (nvmet_aen_bit_disabled(ctrl, NVME_AEN_BIT_DISC_CHANGE))
+		return;
+
+	nvmet_add_async_event(ctrl, NVME_AER_TYPE_NOTICE,
+			      NVME_AER_NOTICE_DISC_CHANGED, NVME_LOG_DISC);
+}
+
+void nvmet_port_disc_changed(struct nvmet_port *port,
+			     struct nvmet_subsys *subsys)
+{
+	struct nvmet_ctrl *ctrl;
+
+	nvmet_genctr++;
+
+	list_for_each_entry(ctrl, &nvmet_disc_subsys->ctrls, subsys_entry) {
+		if (subsys && !nvmet_host_allowed(subsys, ctrl->hostnqn))
+			continue;
+
+		__nvmet_disc_changed(port, ctrl);
+	}
+}
+
+static void __nvmet_subsys_disc_changed(struct nvmet_port *port,
+					struct nvmet_subsys *subsys,
+					struct nvmet_host *host)
+{
+	struct nvmet_ctrl *ctrl;
+
+	list_for_each_entry(ctrl, &nvmet_disc_subsys->ctrls, subsys_entry) {
+		if (host && strcmp(nvmet_host_name(host), ctrl->hostnqn))
+			continue;
+
+		__nvmet_disc_changed(port, ctrl);
+	}
+}
+
+void nvmet_subsys_disc_changed(struct nvmet_subsys *subsys,
+			       struct nvmet_host *host)
+{
+	struct nvmet_port *port;
+	struct nvmet_subsys_link *s;
+
+	nvmet_genctr++;
+
+	list_for_each_entry(port, nvmet_ports, global_entry)
+		list_for_each_entry(s, &port->subsystems, entry) {
+			if (s->subsys != subsys)
+				continue;
+			__nvmet_subsys_disc_changed(port, subsys, host);
+		}
+}
+
 void nvmet_referral_enable(struct nvmet_port *parent, struct nvmet_port *port)
 {
 	down_write(&nvmet_config_sem);
 	if (list_empty(&port->entry)) {
 		list_add_tail(&port->entry, &parent->referrals);
 		port->enabled = true;
-		nvmet_genctr++;
+		nvmet_port_disc_changed(parent, NULL);
 	}
 	up_write(&nvmet_config_sem);
 }
 
-void nvmet_referral_disable(struct nvmet_port *port)
+void nvmet_referral_disable(struct nvmet_port *parent, struct nvmet_port *port)
 {
 	down_write(&nvmet_config_sem);
 	if (!list_empty(&port->entry)) {
 		port->enabled = false;
 		list_del_init(&port->entry);
-		nvmet_genctr++;
+		nvmet_port_disc_changed(parent, NULL);
 	}
 	up_write(&nvmet_config_sem);
 }
@@ -136,6 +194,8 @@ static void nvmet_execute_get_disc_log_page(struct nvmet_req *req)
 	hdr->numrec = cpu_to_le64(numrec);
 	hdr->recfmt = cpu_to_le16(0);
 
+	nvmet_clear_aen_bit(req, NVME_AEN_BIT_DISC_CHANGE);
+
 	up_read(&nvmet_config_sem);
 
 	status = nvmet_copy_to_sgl(req, 0, hdr, data_len);
@@ -174,6 +234,8 @@ static void nvmet_execute_identify_disc_ctrl(struct nvmet_req *req)
 	if (req->port->inline_data_size)
 		id->sgls |= cpu_to_le32(1 << 20);
 
+	id->oaes = cpu_to_le32(NVMET_DISC_AEN_CFG_OPTIONAL);
+
 	strlcpy(id->subnqn, ctrl->subsys->subsysnqn, sizeof(id->subnqn));
 
 	status = nvmet_copy_to_sgl(req, 0, id, sizeof(*id));
* Unmerged path drivers/nvme/target/nvmet.h
