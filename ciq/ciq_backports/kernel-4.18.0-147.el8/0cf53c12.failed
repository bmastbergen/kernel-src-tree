net/mlx5: FWPage, Use async events chain

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Saeed Mahameed <saeedm@mellanox.com>
commit 0cf53c1247565b339a23d82a1853a0c41e9a2a34
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/0cf53c12.failed

Remove the explicit call to mlx5_core_req_pages_handler on
MLX5_EVENT_TYPE_PAGE_REQUEST and let FW page logic  to register its own
handler when its ready.

	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 0cf53c1247565b339a23d82a1853a0c41e9a2a34)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eq.c
#	drivers/net/ethernet/mellanox/mlx5/core/main.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eq.c
index a997f6ba7cac,7f6a644700eb..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eq.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
@@@ -532,21 -398,6 +532,24 @@@ static irqreturn_t mlx5_eq_int(int irq
  			mlx5_eq_cq_event(eq, cqn, eqe->type);
  			break;
  
++<<<<<<< HEAD
 +		case MLX5_EVENT_TYPE_PAGE_REQUEST:
 +			{
 +				u16 func_id = be16_to_cpu(eqe->data.req_pages.func_id);
 +				s32 npages = be32_to_cpu(eqe->data.req_pages.num_pages);
 +
 +				mlx5_core_dbg(dev, "page request for func 0x%x, npages %d\n",
 +					      func_id, npages);
 +				mlx5_core_req_pages_handler(dev, func_id, npages);
 +			}
 +			break;
 +
 +		case MLX5_EVENT_TYPE_NIC_VPORT_CHANGE:
 +			mlx5_eswitch_vport_event(dev->priv.eswitch, eqe);
 +			break;
 +
++=======
++>>>>>>> 0cf53c124756 (net/mlx5: FWPage, Use async events chain)
  		case MLX5_EVENT_TYPE_PORT_MODULE_EVENT:
  			mlx5_port_module_event(dev, eqe);
  			break;
diff --cc drivers/net/ethernet/mellanox/mlx5/core/main.c
index cfdc2f0b35a2,9e4cd2757ea8..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/main.c
@@@ -1158,25 -944,21 +1152,31 @@@ static int mlx5_load_one(struct mlx5_co
  	if (IS_ERR(dev->priv.uar)) {
  		dev_err(&pdev->dev, "Failed allocating uar, aborting\n");
  		err = PTR_ERR(dev->priv.uar);
 -		goto err_get_uars;
 +		goto err_disable_msix;
  	}
  
++<<<<<<< HEAD
 +	err = mlx5_start_eqs(dev);
++=======
+ 	mlx5_pagealloc_start(dev);
+ 
+ 	err = mlx5_eq_table_create(dev);
++>>>>>>> 0cf53c124756 (net/mlx5: FWPage, Use async events chain)
 +	if (err) {
 +		dev_err(&pdev->dev, "Failed to start pages and async EQs\n");
 +		goto err_put_uars;
 +	}
 +
 +	err = alloc_comp_eqs(dev);
  	if (err) {
 -		dev_err(&pdev->dev, "Failed to create EQs\n");
 -		goto err_eq_table;
 +		dev_err(&pdev->dev, "Failed to alloc completion EQs\n");
 +		goto err_stop_eqs;
  	}
  
 -	err = mlx5_fw_tracer_init(dev->tracer);
 +	err = mlx5_irq_set_affinity_hints(dev);
  	if (err) {
 -		dev_err(&pdev->dev, "Failed to init FW tracer\n");
 -		goto err_fw_tracer;
 +		dev_err(&pdev->dev, "Failed to alloc affinity hint cpumask\n");
 +		goto err_affinity_hints;
  	}
  
  	err = mlx5_fpga_device_start(dev);
@@@ -1247,21 -1029,16 +1247,26 @@@ err_ipsec_start
  	mlx5_fpga_device_stop(dev);
  
  err_fpga_start:
 -	mlx5_fw_tracer_cleanup(dev->tracer);
 +	mlx5_irq_clear_affinity_hints(dev);
  
 -err_fw_tracer:
 -	mlx5_eq_table_destroy(dev);
 +err_affinity_hints:
 +	free_comp_eqs(dev);
  
++<<<<<<< HEAD
 +err_stop_eqs:
 +	mlx5_stop_eqs(dev);
 +
 +err_put_uars:
++=======
+ err_eq_table:
+ 	mlx5_pagealloc_stop(dev);
++>>>>>>> 0cf53c124756 (net/mlx5: FWPage, Use async events chain)
  	mlx5_put_uars_page(dev, priv->uar);
  
 -err_get_uars:
 +err_disable_msix:
 +	mlx5_free_irq_vectors(dev);
 +
 +err_cleanup_once:
  	if (boot)
  		mlx5_cleanup_once(dev);
  
@@@ -1318,11 -1092,11 +1320,19 @@@ static int mlx5_unload_one(struct mlx5_
  	mlx5_accel_ipsec_cleanup(dev);
  	mlx5_accel_tls_cleanup(dev);
  	mlx5_fpga_device_stop(dev);
++<<<<<<< HEAD
 +	mlx5_irq_clear_affinity_hints(dev);
 +	free_comp_eqs(dev);
 +	mlx5_stop_eqs(dev);
 +	mlx5_put_uars_page(dev, priv->uar);
 +	mlx5_free_irq_vectors(dev);
++=======
+ 	mlx5_fw_tracer_cleanup(dev->tracer);
+ 	mlx5_eq_table_destroy(dev);
+ 	mlx5_pagealloc_stop(dev);
+ 	mlx5_put_uars_page(dev, priv->uar);
+ 
++>>>>>>> 0cf53c124756 (net/mlx5: FWPage, Use async events chain)
  	if (cleanup)
  		mlx5_cleanup_once(dev);
  	mlx5_stop_health_poll(dev, cleanup);
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eq.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/main.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c b/drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c
index e36d3e3675f9..a83b517b0714 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c
@@ -37,6 +37,7 @@
 #include <linux/mlx5/driver.h>
 #include <linux/mlx5/cmd.h>
 #include "mlx5_core.h"
+#include "lib/eq.h"
 
 enum {
 	MLX5_PAGES_CANT_GIVE	= 0,
@@ -433,15 +434,28 @@ static void pages_work_handler(struct work_struct *work)
 	kfree(req);
 }
 
-void mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,
-				 s32 npages)
+static int req_pages_handler(struct notifier_block *nb,
+			     unsigned long type, void *data)
 {
 	struct mlx5_pages_req *req;
-
+	struct mlx5_core_dev *dev;
+	struct mlx5_priv *priv;
+	struct mlx5_eqe *eqe;
+	u16 func_id;
+	s32 npages;
+
+	priv = mlx5_nb_cof(nb, struct mlx5_priv, pg_nb);
+	dev  = container_of(priv, struct mlx5_core_dev, priv);
+	eqe  = data;
+
+	func_id = be16_to_cpu(eqe->data.req_pages.func_id);
+	npages  = be32_to_cpu(eqe->data.req_pages.num_pages);
+	mlx5_core_dbg(dev, "page request for func 0x%x, npages %d\n",
+		      func_id, npages);
 	req = kzalloc(sizeof(*req), GFP_ATOMIC);
 	if (!req) {
 		mlx5_core_warn(dev, "failed to allocate pages request\n");
-		return;
+		return NOTIFY_DONE;
 	}
 
 	req->dev = dev;
@@ -449,6 +463,7 @@ void mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,
 	req->npages = npages;
 	INIT_WORK(&req->work, pages_work_handler);
 	queue_work(dev->priv.pg_wq, &req->work);
+	return NOTIFY_OK;
 }
 
 int mlx5_satisfy_startup_pages(struct mlx5_core_dev *dev, int boot)
@@ -524,29 +539,32 @@ int mlx5_reclaim_startup_pages(struct mlx5_core_dev *dev)
 	return 0;
 }
 
-void mlx5_pagealloc_init(struct mlx5_core_dev *dev)
+int mlx5_pagealloc_init(struct mlx5_core_dev *dev)
 {
 	dev->priv.page_root = RB_ROOT;
 	INIT_LIST_HEAD(&dev->priv.free_list);
+	dev->priv.pg_wq = create_singlethread_workqueue("mlx5_page_allocator");
+	if (!dev->priv.pg_wq)
+		return -ENOMEM;
+
+	return 0;
 }
 
 void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev)
 {
-	/* nothing */
+	destroy_workqueue(dev->priv.pg_wq);
 }
 
-int mlx5_pagealloc_start(struct mlx5_core_dev *dev)
+void mlx5_pagealloc_start(struct mlx5_core_dev *dev)
 {
-	dev->priv.pg_wq = create_singlethread_workqueue("mlx5_page_allocator");
-	if (!dev->priv.pg_wq)
-		return -ENOMEM;
-
-	return 0;
+	MLX5_NB_INIT(&dev->priv.pg_nb, req_pages_handler, PAGE_REQUEST);
+	mlx5_eq_notifier_register(dev, &dev->priv.pg_nb);
 }
 
 void mlx5_pagealloc_stop(struct mlx5_core_dev *dev)
 {
-	destroy_workqueue(dev->priv.pg_wq);
+	mlx5_eq_notifier_unregister(dev, &dev->priv.pg_nb);
+	flush_workqueue(dev->priv.pg_wq);
 }
 
 int mlx5_wait_for_vf_pages(struct mlx5_core_dev *dev)
diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2b6e906af6bb..8ef4d1193bba 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -639,6 +639,7 @@ struct mlx5_priv {
 	struct mlx5_irq_info	*irq_info;
 
 	/* pages stuff */
+	struct mlx5_nb          pg_nb;
 	struct workqueue_struct *pg_wq;
 	struct rb_root		page_root;
 	int			fw_pages;
@@ -1083,9 +1084,9 @@ int mlx5_core_alloc_pd(struct mlx5_core_dev *dev, u32 *pdn);
 int mlx5_core_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn);
 int mlx5_core_mad_ifc(struct mlx5_core_dev *dev, const void *inb, void *outb,
 		      u16 opmod, u8 port);
-void mlx5_pagealloc_init(struct mlx5_core_dev *dev);
+int mlx5_pagealloc_init(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_cleanup(struct mlx5_core_dev *dev);
-int mlx5_pagealloc_start(struct mlx5_core_dev *dev);
+void mlx5_pagealloc_start(struct mlx5_core_dev *dev);
 void mlx5_pagealloc_stop(struct mlx5_core_dev *dev);
 void mlx5_core_req_pages_handler(struct mlx5_core_dev *dev, u16 func_id,
 				 s32 npages);
