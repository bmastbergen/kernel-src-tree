RDMA/device: Call ib_cache_release_one() only from ib_device_release()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Jason Gunthorpe <jgg@ziepe.ca>
commit d45f89d59bcd42d6b8575d0af69d7a3a98e73bb6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/d45f89d5.failed

Instead of complicated logic about when this memory is freed, always free
it during device release(). All the cache pointers start out as NULL, so
it is safe to call this before the cache is initialized.

This makes for a simpler error unwind flow, and a simpler understanding of
the lifetime of the memory allocations inside the struct ib_device.

	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit d45f89d59bcd42d6b8575d0af69d7a3a98e73bb6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/device.c
diff --cc drivers/infiniband/core/device.c
index 47f3eaabe6fa,872662a84b16..000000000000
--- a/drivers/infiniband/core/device.c
+++ b/drivers/infiniband/core/device.c
@@@ -223,15 -244,10 +223,22 @@@ static void ib_device_release(struct de
  	struct ib_device *dev = container_of(device, struct ib_device, dev);
  
  	WARN_ON(dev->reg_state == IB_DEV_REGISTERED);
++<<<<<<< HEAD
 +	if (dev->reg_state == IB_DEV_UNREGISTERED) {
 +		/*
 +		 * In IB_DEV_UNINITIALIZED state, cache or port table
 +		 * is not even created. Free cache and port table only when
 +		 * device reaches UNREGISTERED state.
 +		 */
 +		ib_cache_release_one(dev);
 +		kfree(dev->port_immutable);
 +	}
++=======
+ 	ib_cache_release_one(dev);
+ 	ib_security_release_port_pkey_list(dev);
+ 	kfree(dev->port_pkey_list);
+ 	kfree(dev->port_immutable);
++>>>>>>> d45f89d59bcd (RDMA/device: Call ib_cache_release_one() only from ib_device_release())
  	kfree(dev);
  }
  
@@@ -509,38 -511,84 +516,112 @@@ int ib_register_device(struct ib_devic
  		WARN_ON_ONCE(!parent);
  		device->dma_device = parent;
  	}
 -}
  
++<<<<<<< HEAD
 +	mutex_lock(&device_mutex);
 +
 +	if (strchr(device->name, '%')) {
 +		ret = alloc_name(device->name);
 +		if (ret)
 +			goto out;
 +	}
++=======
+ static int setup_device(struct ib_device *device)
+ {
+ 	struct ib_udata uhw = {.outlen = 0, .inlen = 0};
+ 	int ret;
++>>>>>>> d45f89d59bcd (RDMA/device: Call ib_cache_release_one() only from ib_device_release())
  
 -	ret = ib_device_check_mandatory(device);
 -	if (ret)
 -		return ret;
 +	if (ib_device_check_mandatory(device)) {
 +		ret = -EINVAL;
 +		goto out;
 +	}
  
  	ret = read_port_immutable(device);
  	if (ret) {
++<<<<<<< HEAD
 +		pr_warn("Couldn't create per port immutable data %s\n",
 +			device->name);
 +		goto out;
++=======
+ 		dev_warn(&device->dev,
+ 			 "Couldn't create per port immutable data\n");
+ 		return ret;
+ 	}
+ 
+ 	memset(&device->attrs, 0, sizeof(device->attrs));
+ 	ret = device->ops.query_device(device, &device->attrs, &uhw);
+ 	if (ret) {
+ 		dev_warn(&device->dev,
+ 			 "Couldn't query the device attributes\n");
+ 		return ret;
++>>>>>>> d45f89d59bcd (RDMA/device: Call ib_cache_release_one() only from ib_device_release())
  	}
  
  	ret = setup_port_pkey_list(device);
  	if (ret) {
++<<<<<<< HEAD
 +		pr_warn("Couldn't create per port_pkey_list\n");
 +		goto port_cleanup;
 +	}
 +
 +	ret = ib_cache_setup_one(device);
 +	if (ret) {
 +		pr_warn("Couldn't set up InfiniBand P_Key/GID cache\n");
 +		goto pkey_cleanup;
 +	}
++=======
+ 		dev_warn(&device->dev, "Couldn't create per port_pkey_list\n");
+ 		return ret;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ /**
+  * ib_register_device - Register an IB device with IB core
+  * @device:Device to register
+  *
+  * Low-level drivers use ib_register_device() to register their
+  * devices with the IB core.  All registered clients will receive a
+  * callback for each device that is added. @device must be allocated
+  * with ib_alloc_device().
+  */
+ int ib_register_device(struct ib_device *device, const char *name)
+ {
+ 	int ret;
+ 	struct ib_client *client;
+ 
+ 	setup_dma_device(device);
+ 
+ 	mutex_lock(&device_mutex);
+ 
+ 	if (strchr(name, '%')) {
+ 		ret = alloc_name(device, name);
+ 		if (ret)
+ 			goto out;
+ 	} else {
+ 		ret = dev_set_name(&device->dev, name);
+ 		if (ret)
+ 			goto out;
+ 	}
+ 	if (__ib_device_get_by_name(dev_name(&device->dev))) {
+ 		ret = -ENFILE;
+ 		goto out;
+ 	}
+ 	strlcpy(device->name, dev_name(&device->dev), IB_DEVICE_NAME_MAX);
+ 
+ 	ret = setup_device(device);
+ 	if (ret)
+ 		goto out;
++>>>>>>> d45f89d59bcd (RDMA/device: Call ib_cache_release_one() only from ib_device_release())
+ 
+ 	ret = ib_cache_setup_one(device);
+ 	if (ret) {
+ 		dev_warn(&device->dev,
+ 			 "Couldn't set up InfiniBand P_Key/GID cache\n");
+ 		goto out;
+ 	}
  
  	device->index = __dev_new_index();
  
@@@ -579,13 -616,7 +660,17 @@@
  
  cg_cleanup:
  	ib_device_unregister_rdmacg(device);
++<<<<<<< HEAD
 +cache_cleanup:
 +	ib_cache_cleanup_one(device);
 +	ib_cache_release_one(device);
 +pkey_cleanup:
 +	kfree(device->port_pkey_list);
 +port_cleanup:
 +	kfree(device->port_immutable);
++=======
+ 	ib_cache_cleanup_one(device);
++>>>>>>> d45f89d59bcd (RDMA/device: Call ib_cache_release_one() only from ib_device_release())
  out:
  	mutex_unlock(&device_mutex);
  	return ret;
diff --git a/drivers/infiniband/core/cache.c b/drivers/infiniband/core/cache.c
index 3d9a628cdaa5..8d20e6fd30b4 100644
--- a/drivers/infiniband/core/cache.c
+++ b/drivers/infiniband/core/cache.c
@@ -1462,6 +1462,9 @@ void ib_cache_release_one(struct ib_device *device)
 {
 	int p;
 
+	if (!device->cache.ports)
+		return;
+
 	/*
 	 * The release function frees all the cache elements.
 	 * This function should be called as part of freeing
* Unmerged path drivers/infiniband/core/device.c
