powerpc/powernv/npu: Move OPAL calls away from context manipulation

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Alexey Kardashevskiy <aik@ozlabs.ru>
commit 0e759bd75285e96fbb4013d1303b08fdb8ba58e1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/0e759bd7.failed

When introduced, the NPU context init/destroy helpers called OPAL which
enabled/disabled PID (a userspace memory context ID) filtering in an NPU
per a GPU; this was a requirement for P9 DD1.0. However newer chip
revision added a PID wildcard support so there is no more need to
call OPAL every time a new context is initialized. Also, since the PID
wildcard support was added, skiboot does not clear wildcard entries
in the NPU so these remain in the hardware till the system reboot.

This moves LPID and wildcard programming to the PE setup code which
executes once during the booting process so NPU2 context init/destroy
won't need to do additional configuration.

This replaces the check for FW_FEATURE_OPAL with a check for npu!=NULL as
this is the way to tell if the NPU support is present and configured.

This moves pnv_npu2_init() declaration as pseries should be able to use it.
This keeps pnv_npu2_map_lpar() in powernv as pseries is not allowed to
call that. This exports pnv_npu2_map_lpar_dev() as following patches
will use it from the VFIO driver.

While at it, replace redundant list_for_each_entry_safe() with
a simpler list_for_each_entry().

	Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
(cherry picked from commit 0e759bd75285e96fbb4013d1303b08fdb8ba58e1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/platforms/powernv/npu-dma.c
#	arch/powerpc/platforms/powernv/pci-ioda.c
diff --cc arch/powerpc/platforms/powernv/npu-dma.c
index 6f60e0931922,abcce06d2a6f..000000000000
--- a/arch/powerpc/platforms/powernv/npu-dma.c
+++ b/arch/powerpc/platforms/powernv/npu-dma.c
@@@ -561,8 -510,10 +561,15 @@@ static void acquire_atsd_reg(struct npu
  			if (!npdev)
  				continue;
  
++<<<<<<< HEAD
 +			nphb = pci_bus_to_host(npdev->bus)->private_data;
 +			npu = &nphb->npu;
++=======
+ 			npu = pci_bus_to_host(npdev->bus)->npu;
+ 			if (!npu)
+ 				continue;
+ 
++>>>>>>> 0e759bd75285 (powerpc/powernv/npu: Move OPAL calls away from context manipulation)
  			mmio_atsd_reg[i].npu = npu;
  			mmio_atsd_reg[i].reg = get_mmio_atsd_reg(npu);
  			while (mmio_atsd_reg[i].reg < 0) {
@@@ -727,9 -678,9 +734,8 @@@ struct npu_context *pnv_npu2_init_conte
  	u32 nvlink_index;
  	struct device_node *nvlink_dn;
  	struct mm_struct *mm = current->mm;
- 	struct pnv_phb *nphb;
  	struct npu *npu;
  	struct npu_context *npu_context;
 -	struct pci_controller *hose;
  
  	/*
  	 * At present we don't support GPUs connected to multiple NPUs and I'm
@@@ -757,20 -709,10 +764,27 @@@
  		return ERR_PTR(-EINVAL);
  	}
  
++<<<<<<< HEAD
 +	nphb = pci_bus_to_host(npdev->bus)->private_data;
 +	npu = &nphb->npu;
 +
 +	/*
 +	 * Setup the NPU context table for a particular GPU. These need to be
 +	 * per-GPU as we need the tables to filter ATSDs when there are no
 +	 * active contexts on a particular GPU. It is safe for these to be
 +	 * called concurrently with destroy as the OPAL call takes appropriate
 +	 * locks and refcounts on init/destroy.
 +	 */
 +	rc = opal_npu_init_context(nphb->opal_id, mm->context.id, flags,
 +				PCI_DEVID(gpdev->bus->number, gpdev->devfn));
 +	if (rc < 0)
 +		return ERR_PTR(-ENOSPC);
++=======
+ 	hose = pci_bus_to_host(npdev->bus);
+ 	npu = hose->npu;
+ 	if (!npu)
+ 		return ERR_PTR(-ENODEV);
++>>>>>>> 0e759bd75285 (powerpc/powernv/npu: Move OPAL calls away from context manipulation)
  
  	/*
  	 * We store the npu pci device so we can more easily get at the
@@@ -874,11 -810,10 +881,18 @@@ void pnv_npu2_destroy_context(struct np
  	if (WARN_ON(!npdev))
  		return;
  
++<<<<<<< HEAD
 +	if (!firmware_has_feature(FW_FEATURE_OPAL))
 +		return;
 +
 +	nphb = pci_bus_to_host(npdev->bus)->private_data;
 +	npu = &nphb->npu;
++=======
+ 	hose = pci_bus_to_host(npdev->bus);
+ 	npu = hose->npu;
+ 	if (!npu)
+ 		return;
++>>>>>>> 0e759bd75285 (powerpc/powernv/npu: Move OPAL calls away from context manipulation)
  	nvlink_dn = of_parse_phandle(npdev->dev.of_node, "ibm,nvlink", 0);
  	if (WARN_ON(of_property_read_u32(nvlink_dn, "ibm,npu-link-index",
  							&nvlink_index)))
@@@ -952,38 -882,88 +961,96 @@@ int pnv_npu2_init(struct pci_controlle
  {
  	unsigned int i;
  	u64 mmio_atsd;
- 	struct device_node *dn;
- 	struct pci_dev *gpdev;
  	static int npu_index;
++<<<<<<< HEAD
 +	uint64_t rc = 0;
 +
 +	phb->npu.nmmu_flush =
 +		of_property_read_bool(phb->hose->dn, "ibm,nmmu-flush");
 +	for_each_child_of_node(phb->hose->dn, dn) {
 +		gpdev = pnv_pci_get_gpu_dev(get_pci_dev(dn));
 +		if (gpdev) {
 +			rc = opal_npu_map_lpar(phb->opal_id,
 +				PCI_DEVID(gpdev->bus->number, gpdev->devfn),
 +				0, 0);
 +			if (rc)
 +				dev_err(&gpdev->dev,
 +					"Error %lld mapping device to LPAR\n",
 +					rc);
 +		}
 +	}
++=======
+ 	struct npu *npu;
+ 	int ret;
+ 
+ 	npu = kzalloc(sizeof(*npu), GFP_KERNEL);
+ 	if (!npu)
+ 		return -ENOMEM;
+ 
+ 	npu->nmmu_flush = of_property_read_bool(hose->dn, "ibm,nmmu-flush");
++>>>>>>> 0e759bd75285 (powerpc/powernv/npu: Move OPAL calls away from context manipulation)
  
 -	for (i = 0; !of_property_read_u64_index(hose->dn, "ibm,mmio-atsd",
 +	for (i = 0; !of_property_read_u64_index(phb->hose->dn, "ibm,mmio-atsd",
  							i, &mmio_atsd); i++)
 -		npu->mmio_atsd_regs[i] = ioremap(mmio_atsd, 32);
 +		phb->npu.mmio_atsd_regs[i] = ioremap(mmio_atsd, 32);
  
 -	pr_info("NPU%d: Found %d MMIO ATSD registers", hose->global_number, i);
 -	npu->mmio_atsd_count = i;
 -	npu->mmio_atsd_usage = 0;
 +	pr_info("NPU%lld: Found %d MMIO ATSD registers", phb->opal_id, i);
 +	phb->npu.mmio_atsd_count = i;
 +	phb->npu.mmio_atsd_usage = 0;
  	npu_index++;
 -	if (WARN_ON(npu_index >= NV_MAX_NPUS)) {
 -		ret = -ENOSPC;
 -		goto fail_exit;
 -	}
 +	if (WARN_ON(npu_index >= NV_MAX_NPUS))
 +		return -ENOSPC;
  	max_npu2_index = npu_index;
 -	npu->index = npu_index;
 -	hose->npu = npu;
 +	phb->npu.index = npu_index;
  
  	return 0;
 -
 -fail_exit:
 -	for (i = 0; i < npu->mmio_atsd_count; ++i)
 -		iounmap(npu->mmio_atsd_regs[i]);
 -
 -	kfree(npu);
 -
 -	return ret;
  }
+ 
+ int pnv_npu2_map_lpar_dev(struct pci_dev *gpdev, unsigned int lparid,
+ 		unsigned long msr)
+ {
+ 	int ret;
+ 	struct pci_dev *npdev = pnv_pci_get_npu_dev(gpdev, 0);
+ 	struct pci_controller *hose;
+ 	struct pnv_phb *nphb;
+ 
+ 	if (!npdev)
+ 		return -ENODEV;
+ 
+ 	hose = pci_bus_to_host(npdev->bus);
+ 	nphb = hose->private_data;
+ 
+ 	dev_dbg(&gpdev->dev, "Map LPAR opalid=%llu lparid=%u\n",
+ 			nphb->opal_id, lparid);
+ 	/*
+ 	 * Currently we only support radix and non-zero LPCR only makes sense
+ 	 * for hash tables so skiboot expects the LPCR parameter to be a zero.
+ 	 */
+ 	ret = opal_npu_map_lpar(nphb->opal_id,
+ 			PCI_DEVID(gpdev->bus->number, gpdev->devfn), lparid,
+ 			0 /* LPCR bits */);
+ 	if (ret) {
+ 		dev_err(&gpdev->dev, "Error %d mapping device to LPAR\n", ret);
+ 		return ret;
+ 	}
+ 
+ 	dev_dbg(&gpdev->dev, "init context opalid=%llu msr=%lx\n",
+ 			nphb->opal_id, msr);
+ 	ret = opal_npu_init_context(nphb->opal_id, 0/*__unused*/, msr,
+ 			PCI_DEVID(gpdev->bus->number, gpdev->devfn));
+ 	if (ret < 0)
+ 		dev_err(&gpdev->dev, "Failed to init context: %d\n", ret);
+ 	else
+ 		ret = 0;
+ 
+ 	return 0;
+ }
+ EXPORT_SYMBOL_GPL(pnv_npu2_map_lpar_dev);
+ 
+ void pnv_npu2_map_lpar(struct pnv_ioda_pe *gpe, unsigned long msr)
+ {
+ 	struct pci_dev *gpdev;
+ 
+ 	list_for_each_entry(gpdev, &gpe->pbus->devices, bus_list)
+ 		pnv_npu2_map_lpar_dev(gpdev, 0, msr);
+ }
diff --cc arch/powerpc/platforms/powernv/pci-ioda.c
index 3f41331e99e8,1b821290f6a2..000000000000
--- a/arch/powerpc/platforms/powernv/pci-ioda.c
+++ b/arch/powerpc/platforms/powernv/pci-ioda.c
@@@ -1286,7 -1279,7 +1287,11 @@@ static void pnv_pci_ioda_setup_PEs(void
  			pnv_ioda_reserve_pe(phb, 0);
  			pnv_ioda_setup_npu_PEs(hose->bus);
  			if (phb->model == PNV_PHB_MODEL_NPU2)
++<<<<<<< HEAD
 +				pnv_npu2_init(phb);
++=======
+ 				WARN_ON_ONCE(pnv_npu2_init(hose));
++>>>>>>> 0e759bd75285 (powerpc/powernv/npu: Move OPAL calls away from context manipulation)
  		}
  		if (phb->type == PNV_PHB_NPU_OCAPI) {
  			bus = hose->bus;
diff --git a/arch/powerpc/include/asm/pci.h b/arch/powerpc/include/asm/pci.h
index 2af9ded80540..baf2886d4d6e 100644
--- a/arch/powerpc/include/asm/pci.h
+++ b/arch/powerpc/include/asm/pci.h
@@ -129,5 +129,8 @@ extern void pcibios_scan_phb(struct pci_controller *hose);
 
 extern struct pci_dev *pnv_pci_get_gpu_dev(struct pci_dev *npdev);
 extern struct pci_dev *pnv_pci_get_npu_dev(struct pci_dev *gpdev, int index);
+extern int pnv_npu2_init(struct pci_controller *hose);
+extern int pnv_npu2_map_lpar_dev(struct pci_dev *gpdev, unsigned int lparid,
+		unsigned long msr);
 
 #endif /* __ASM_POWERPC_PCI_H */
* Unmerged path arch/powerpc/platforms/powernv/npu-dma.c
* Unmerged path arch/powerpc/platforms/powernv/pci-ioda.c
diff --git a/arch/powerpc/platforms/powernv/pci.h b/arch/powerpc/platforms/powernv/pci.h
index 0020937fc694..59c41827dc84 100644
--- a/arch/powerpc/platforms/powernv/pci.h
+++ b/arch/powerpc/platforms/powernv/pci.h
@@ -214,6 +214,7 @@ extern void pnv_pci_init_ioda_hub(struct device_node *np);
 extern void pnv_pci_init_ioda2_phb(struct device_node *np);
 extern void pnv_pci_init_npu_phb(struct device_node *np);
 extern void pnv_pci_init_npu2_opencapi_phb(struct device_node *np);
+extern void pnv_npu2_map_lpar(struct pnv_ioda_pe *gpe, unsigned long msr);
 extern void pnv_pci_reset_secondary_bus(struct pci_dev *dev);
 extern int pnv_eeh_phb_reset(struct pci_controller *hose, int option);
 
@@ -245,7 +246,6 @@ extern long pnv_npu_set_window(struct pnv_ioda_pe *npe, int num,
 extern long pnv_npu_unset_window(struct pnv_ioda_pe *npe, int num);
 extern void pnv_npu_take_ownership(struct pnv_ioda_pe *npe);
 extern void pnv_npu_release_ownership(struct pnv_ioda_pe *npe);
-extern int pnv_npu2_init(struct pnv_phb *phb);
 
 /* cxl functions */
 extern bool pnv_cxl_enable_device_hook(struct pci_dev *dev);
