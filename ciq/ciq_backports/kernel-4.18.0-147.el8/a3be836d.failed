KVM: arm/arm64: Demote kvm_arm_init_arch_resources() to just set up SVE

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Dave Martin <Dave.Martin@arm.com>
commit a3be836df7cb777fa8ecbfd662224bfe0394f771
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/a3be836d.failed

The introduction of kvm_arm_init_arch_resources() looks like
premature factoring, since nothing else uses this hook yet and it
is not clear what will use it in the future.

For now, let's not pretend that this is a general thing:

This patch simply renames the function to kvm_arm_init_sve(),
retaining the arm stub version under the new name.

	Suggested-by: Andrew Jones <drjones@redhat.com>
	Signed-off-by: Dave Martin <Dave.Martin@arm.com>
	Reviewed-by: Andrew Jones <drjones@redhat.com>
	Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
(cherry picked from commit a3be836df7cb777fa8ecbfd662224bfe0394f771)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/kvm_host.h
#	arch/arm64/kvm/reset.c
diff --cc arch/arm64/include/asm/kvm_host.h
index 7eeddb2d82c2,6adf08ba9277..000000000000
--- a/arch/arm64/include/asm/kvm_host.h
+++ b/arch/arm64/include/asm/kvm_host.h
@@@ -51,7 -57,9 +51,12 @@@
  
  DECLARE_STATIC_KEY_FALSE(userspace_irqchip_in_use);
  
++<<<<<<< HEAD
 +static inline int kvm_arm_init_arch_resources(void) { return 0; }
++=======
+ extern unsigned int kvm_sve_max_vl;
+ int kvm_arm_init_sve(void);
++>>>>>>> a3be836df7cb (KVM: arm/arm64: Demote kvm_arm_init_arch_resources() to just set up SVE)
  
  int __attribute_const__ kvm_target_cpu(void);
  int kvm_reset_vcpu(struct kvm_vcpu *vcpu);
diff --cc arch/arm64/kvm/reset.c
index 9b8e8bd8b60b,8847f389f56d..000000000000
--- a/arch/arm64/kvm/reset.c
+++ b/arch/arm64/kvm/reset.c
@@@ -95,6 -108,119 +95,122 @@@ int kvm_arch_vm_ioctl_check_extension(s
  	return r;
  }
  
++<<<<<<< HEAD
++=======
+ unsigned int kvm_sve_max_vl;
+ 
+ int kvm_arm_init_sve(void)
+ {
+ 	if (system_supports_sve()) {
+ 		kvm_sve_max_vl = sve_max_virtualisable_vl;
+ 
+ 		/*
+ 		 * The get_sve_reg()/set_sve_reg() ioctl interface will need
+ 		 * to be extended with multiple register slice support in
+ 		 * order to support vector lengths greater than
+ 		 * SVE_VL_ARCH_MAX:
+ 		 */
+ 		if (WARN_ON(kvm_sve_max_vl > SVE_VL_ARCH_MAX))
+ 			kvm_sve_max_vl = SVE_VL_ARCH_MAX;
+ 
+ 		/*
+ 		 * Don't even try to make use of vector lengths that
+ 		 * aren't available on all CPUs, for now:
+ 		 */
+ 		if (kvm_sve_max_vl < sve_max_vl)
+ 			pr_warn("KVM: SVE vector length for guests limited to %u bytes\n",
+ 				kvm_sve_max_vl);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int kvm_vcpu_enable_sve(struct kvm_vcpu *vcpu)
+ {
+ 	if (!system_supports_sve())
+ 		return -EINVAL;
+ 
+ 	/* Verify that KVM startup enforced this when SVE was detected: */
+ 	if (WARN_ON(!has_vhe()))
+ 		return -EINVAL;
+ 
+ 	vcpu->arch.sve_max_vl = kvm_sve_max_vl;
+ 
+ 	/*
+ 	 * Userspace can still customize the vector lengths by writing
+ 	 * KVM_REG_ARM64_SVE_VLS.  Allocation is deferred until
+ 	 * kvm_arm_vcpu_finalize(), which freezes the configuration.
+ 	 */
+ 	vcpu->arch.flags |= KVM_ARM64_GUEST_HAS_SVE;
+ 
+ 	return 0;
+ }
+ 
+ /*
+  * Finalize vcpu's maximum SVE vector length, allocating
+  * vcpu->arch.sve_state as necessary.
+  */
+ static int kvm_vcpu_finalize_sve(struct kvm_vcpu *vcpu)
+ {
+ 	void *buf;
+ 	unsigned int vl;
+ 
+ 	vl = vcpu->arch.sve_max_vl;
+ 
+ 	/*
+ 	 * Resposibility for these properties is shared between
+ 	 * kvm_arm_init_arch_resources(), kvm_vcpu_enable_sve() and
+ 	 * set_sve_vls().  Double-check here just to be sure:
+ 	 */
+ 	if (WARN_ON(!sve_vl_valid(vl) || vl > sve_max_virtualisable_vl ||
+ 		    vl > SVE_VL_ARCH_MAX))
+ 		return -EIO;
+ 
+ 	buf = kzalloc(SVE_SIG_REGS_SIZE(sve_vq_from_vl(vl)), GFP_KERNEL);
+ 	if (!buf)
+ 		return -ENOMEM;
+ 
+ 	vcpu->arch.sve_state = buf;
+ 	vcpu->arch.flags |= KVM_ARM64_VCPU_SVE_FINALIZED;
+ 	return 0;
+ }
+ 
+ int kvm_arm_vcpu_finalize(struct kvm_vcpu *vcpu, int what)
+ {
+ 	switch (what) {
+ 	case KVM_ARM_VCPU_SVE:
+ 		if (!vcpu_has_sve(vcpu))
+ 			return -EINVAL;
+ 
+ 		if (kvm_arm_vcpu_sve_finalized(vcpu))
+ 			return -EPERM;
+ 
+ 		return kvm_vcpu_finalize_sve(vcpu);
+ 	}
+ 
+ 	return -EINVAL;
+ }
+ 
+ bool kvm_arm_vcpu_is_finalized(struct kvm_vcpu *vcpu)
+ {
+ 	if (vcpu_has_sve(vcpu) && !kvm_arm_vcpu_sve_finalized(vcpu))
+ 		return false;
+ 
+ 	return true;
+ }
+ 
+ void kvm_arch_vcpu_uninit(struct kvm_vcpu *vcpu)
+ {
+ 	kfree(vcpu->arch.sve_state);
+ }
+ 
+ static void kvm_vcpu_reset_sve(struct kvm_vcpu *vcpu)
+ {
+ 	if (vcpu_has_sve(vcpu))
+ 		memset(vcpu->arch.sve_state, 0, vcpu_sve_state_size(vcpu));
+ }
+ 
++>>>>>>> a3be836df7cb (KVM: arm/arm64: Demote kvm_arm_init_arch_resources() to just set up SVE)
  /**
   * kvm_reset_vcpu - sets core registers and sys_regs to reset value
   * @vcpu: The VCPU pointer
diff --git a/arch/arm/include/asm/kvm_host.h b/arch/arm/include/asm/kvm_host.h
index 4d0897ce0a24..871ee8886921 100644
--- a/arch/arm/include/asm/kvm_host.h
+++ b/arch/arm/include/asm/kvm_host.h
@@ -51,7 +51,7 @@
 
 DECLARE_STATIC_KEY_FALSE(userspace_irqchip_in_use);
 
-static inline int kvm_arm_init_arch_resources(void) { return 0; }
+static inline int kvm_arm_init_sve(void) { return 0; }
 
 u32 *kvm_vcpu_reg(struct kvm_vcpu *vcpu, u8 reg_num, u32 mode);
 int __attribute_const__ kvm_target_cpu(void);
* Unmerged path arch/arm64/include/asm/kvm_host.h
* Unmerged path arch/arm64/kvm/reset.c
diff --git a/virt/kvm/arm/arm.c b/virt/kvm/arm/arm.c
index 8f118ce084d3..79a634a2bd7d 100644
--- a/virt/kvm/arm/arm.c
+++ b/virt/kvm/arm/arm.c
@@ -1663,7 +1663,7 @@ int kvm_arch_init(void *opaque)
 	if (err)
 		return err;
 
-	err = kvm_arm_init_arch_resources();
+	err = kvm_arm_init_sve();
 	if (err)
 		return err;
 
