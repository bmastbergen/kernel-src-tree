nvme: call nvme_complete_rq when nvmf_check_ready fails for mpath I/O

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author James Smart <jsmart2021@gmail.com>
commit 783f4a4408e1251d17f333ad56abac24dde988b9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/783f4a44.failed

When an io is rejected by nvmf_check_ready() due to validation of the
controller state, the nvmf_fail_nonready_command() will normally return
BLK_STS_RESOURCE to requeue and retry.  However, if the controller is
dying or the I/O is marked for NVMe multipath, the I/O is failed so that
the controller can terminate or so that the io can be issued on a
different path.  Unfortunately, as this reject point is before the
transport has accepted the command, blk-mq ends up completing the I/O
and never calls nvme_complete_rq(), which is where multipath may preserve
or re-route the I/O. The end result is, the device user ends up seeing an
EIO error.

Example: single path connectivity, controller is under load, and a reset
is induced.  An I/O is received:

  a) while the reset state has been set but the queues have yet to be
     stopped; or
  b) after queues are started (at end of reset) but before the reconnect
     has completed.

The I/O finishes with an EIO status.

This patch makes the following changes:

  - Adds the HOST_PATH_ERROR pathing status from TP4028
  - Modifies the reject point such that it appears to queue successfully,
    but actually completes the io with the new pathing status and calls
    nvme_complete_rq().
  - nvme_complete_rq() recognizes the new status, avoids resetting the
    controller (likely was already done in order to get this new status),
    and calls the multipather to clear the current path that errored.
    This allows the next command (retry or new command) to select a new
    path if there is one.

	Signed-off-by: James Smart <jsmart2021@gmail.com>
	Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
(cherry picked from commit 783f4a4408e1251d17f333ad56abac24dde988b9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/multipath.c
diff --cc drivers/nvme/host/multipath.c
index 1b128a2a399e,ac16093a7928..000000000000
--- a/drivers/nvme/host/multipath.c
+++ b/drivers/nvme/host/multipath.c
@@@ -52,7 -58,41 +52,45 @@@ void nvme_failover_req(struct request *
  	spin_unlock_irqrestore(&ns->head->requeue_lock, flags);
  	blk_mq_end_request(req, 0);
  
++<<<<<<< HEAD
 +	nvme_reset_ctrl(ns->ctrl);
++=======
+ 	switch (status & 0x7ff) {
+ 	case NVME_SC_ANA_TRANSITION:
+ 	case NVME_SC_ANA_INACCESSIBLE:
+ 	case NVME_SC_ANA_PERSISTENT_LOSS:
+ 		/*
+ 		 * If we got back an ANA error we know the controller is alive,
+ 		 * but not ready to serve this namespaces.  The spec suggests
+ 		 * we should update our general state here, but due to the fact
+ 		 * that the admin and I/O queues are not serialized that is
+ 		 * fundamentally racy.  So instead just clear the current path,
+ 		 * mark the the path as pending and kick of a re-read of the ANA
+ 		 * log page ASAP.
+ 		 */
+ 		nvme_mpath_clear_current_path(ns);
+ 		if (ns->ctrl->ana_log_buf) {
+ 			set_bit(NVME_NS_ANA_PENDING, &ns->flags);
+ 			queue_work(nvme_wq, &ns->ctrl->ana_work);
+ 		}
+ 		break;
+ 	case NVME_SC_HOST_PATH_ERROR:
+ 		/*
+ 		 * Temporary transport disruption in talking to the controller.
+ 		 * Try to send on a new path.
+ 		 */
+ 		nvme_mpath_clear_current_path(ns);
+ 		break;
+ 	default:
+ 		/*
+ 		 * Reset the controller for any non-ANA error as we don't know
+ 		 * what caused the error.
+ 		 */
+ 		nvme_reset_ctrl(ns->ctrl);
+ 		break;
+ 	}
+ 
++>>>>>>> 783f4a4408e1 (nvme: call nvme_complete_rq when nvmf_check_ready fails for mpath I/O)
  	kblockd_schedule_work(&ns->head->requeue_work);
  }
  
diff --git a/drivers/nvme/host/fabrics.c b/drivers/nvme/host/fabrics.c
index 272dac80967d..1e9aa534df5b 100644
--- a/drivers/nvme/host/fabrics.c
+++ b/drivers/nvme/host/fabrics.c
@@ -544,8 +544,11 @@ blk_status_t nvmf_fail_nonready_command(struct nvme_ctrl *ctrl,
 	    ctrl->state != NVME_CTRL_DEAD &&
 	    !blk_noretry_request(rq) && !(rq->cmd_flags & REQ_NVME_MPATH))
 		return BLK_STS_RESOURCE;
-	nvme_req(rq)->status = NVME_SC_ABORT_REQ;
-	return BLK_STS_IOERR;
+
+	nvme_req(rq)->status = NVME_SC_HOST_PATH_ERROR;
+	blk_mq_start_request(rq);
+	nvme_complete_rq(rq);
+	return BLK_STS_OK;
 }
 EXPORT_SYMBOL_GPL(nvmf_fail_nonready_command);
 
* Unmerged path drivers/nvme/host/multipath.c
diff --git a/include/linux/nvme.h b/include/linux/nvme.h
index 27beeed277ef..5a5e8093f98a 100644
--- a/include/linux/nvme.h
+++ b/include/linux/nvme.h
@@ -1223,6 +1223,7 @@ enum {
 	NVME_SC_ANA_PERSISTENT_LOSS	= 0x301,
 	NVME_SC_ANA_INACCESSIBLE	= 0x302,
 	NVME_SC_ANA_TRANSITION		= 0x303,
+	NVME_SC_HOST_PATH_ERROR		= 0x370,
 
 	NVME_SC_DNR			= 0x4000,
 };
