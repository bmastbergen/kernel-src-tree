bpf: add bpf_jit_limit knob to restrict unpriv allocations

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Daniel Borkmann <daniel@iogearbox.net>
commit ede95a63b5e84ddeea6b0c473b36ab8bfd8c6ce3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/ede95a63.failed

Rick reported that the BPF JIT could potentially fill the entire module
space with BPF programs from unprivileged users which would prevent later
attempts to load normal kernel modules or privileged BPF programs, for
example. If JIT was enabled but unsuccessful to generate the image, then
before commit 290af86629b2 ("bpf: introduce BPF_JIT_ALWAYS_ON config")
we would always fall back to the BPF interpreter. Nowadays in the case
where the CONFIG_BPF_JIT_ALWAYS_ON could be set, then the load will abort
with a failure since the BPF interpreter was compiled out.

Add a global limit and enforce it for unprivileged users such that in case
of BPF interpreter compiled out we fail once the limit has been reached
or we fall back to BPF interpreter earlier w/o using module mem if latter
was compiled in. In a next step, fair share among unprivileged users can
be resolved in particular for the case where we would fail hard once limit
is reached.

Fixes: 290af86629b2 ("bpf: introduce BPF_JIT_ALWAYS_ON config")
Fixes: 0a14842f5a3c ("net: filter: Just In Time compiler for x86-64")
Co-Developed-by: Rick Edgecombe <rick.p.edgecombe@intel.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Acked-by: Alexei Starovoitov <ast@kernel.org>
	Cc: Eric Dumazet <eric.dumazet@gmail.com>
	Cc: Jann Horn <jannh@google.com>
	Cc: Kees Cook <keescook@chromium.org>
	Cc: LKML <linux-kernel@vger.kernel.org>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
(cherry picked from commit ede95a63b5e84ddeea6b0c473b36ab8bfd8c6ce3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/core.c
diff --cc kernel/bpf/core.c
index 03fd11bf8b73,6377225b2082..000000000000
--- a/kernel/bpf/core.c
+++ b/kernel/bpf/core.c
@@@ -365,12 -365,13 +365,20 @@@ void bpf_prog_kallsyms_del_all(struct b
  }
  
  #ifdef CONFIG_BPF_JIT
+ # define BPF_JIT_LIMIT_DEFAULT	(PAGE_SIZE * 40000)
+ 
  /* All BPF JIT sysctl knobs here. */
  int bpf_jit_enable   __read_mostly = IS_BUILTIN(CONFIG_BPF_JIT_ALWAYS_ON);
++<<<<<<< HEAD
 +/* RHEL-only: set it to 1 by default */
 +int bpf_jit_harden   __read_mostly = 1;
 +/* RHEL-only: set it to 1 by default */
 +int bpf_jit_kallsyms __read_mostly = 1;
++=======
+ int bpf_jit_harden   __read_mostly;
+ int bpf_jit_kallsyms __read_mostly;
+ int bpf_jit_limit    __read_mostly = BPF_JIT_LIMIT_DEFAULT;
++>>>>>>> ede95a63b5e8 (bpf: add bpf_jit_limit knob to restrict unpriv allocations)
  
  static __always_inline void
  bpf_get_prog_addr_region(const struct bpf_prog *prog,
diff --git a/Documentation/sysctl/net.txt b/Documentation/sysctl/net.txt
index 9ecde517728c..2793d4eac55f 100644
--- a/Documentation/sysctl/net.txt
+++ b/Documentation/sysctl/net.txt
@@ -92,6 +92,14 @@ Values :
 	0 - disable JIT kallsyms export (default value)
 	1 - enable JIT kallsyms export for privileged users only
 
+bpf_jit_limit
+-------------
+
+This enforces a global limit for memory allocations to the BPF JIT
+compiler in order to reject unprivileged JIT requests once it has
+been surpassed. bpf_jit_limit contains the value of the global limit
+in bytes.
+
 dev_weight
 --------------
 
diff --git a/include/linux/filter.h b/include/linux/filter.h
index f0c7e315bc41..2a3bb5d7dd40 100644
--- a/include/linux/filter.h
+++ b/include/linux/filter.h
@@ -859,6 +859,7 @@ struct sock *do_msg_redirect_map(struct sk_msg_buff *md);
 extern int bpf_jit_enable;
 extern int bpf_jit_harden;
 extern int bpf_jit_kallsyms;
+extern int bpf_jit_limit;
 
 typedef void (*bpf_jit_fill_hole_t)(void *area, unsigned int size);
 
* Unmerged path kernel/bpf/core.c
diff --git a/net/core/sysctl_net_core.c b/net/core/sysctl_net_core.c
index b1a2c5e38530..37b4667128a3 100644
--- a/net/core/sysctl_net_core.c
+++ b/net/core/sysctl_net_core.c
@@ -279,7 +279,6 @@ static int proc_dointvec_minmax_bpf_enable(struct ctl_table *table, int write,
 	return ret;
 }
 
-# ifdef CONFIG_HAVE_EBPF_JIT
 static int
 proc_dointvec_minmax_bpf_restricted(struct ctl_table *table, int write,
 				    void __user *buffer, size_t *lenp,
@@ -290,7 +289,6 @@ proc_dointvec_minmax_bpf_restricted(struct ctl_table *table, int write,
 
 	return proc_dointvec_minmax(table, write, buffer, lenp, ppos);
 }
-# endif
 #endif
 
 static struct ctl_table net_core_table[] = {
@@ -397,6 +395,14 @@ static struct ctl_table net_core_table[] = {
 		.extra2		= &one,
 	},
 # endif
+	{
+		.procname	= "bpf_jit_limit",
+		.data		= &bpf_jit_limit,
+		.maxlen		= sizeof(int),
+		.mode		= 0600,
+		.proc_handler	= proc_dointvec_minmax_bpf_restricted,
+		.extra1		= &one,
+	},
 #endif
 	{
 		.procname	= "netdev_tstamp_prequeue",
