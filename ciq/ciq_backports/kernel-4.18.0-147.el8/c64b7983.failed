bpf: Add PTR_TO_SOCKET verifier type

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Joe Stringer <joe@wand.net.nz>
commit c64b7983288e636356f7f5f652de4813e1cfedac
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/c64b7983.failed

Teach the verifier a little bit about a new type of pointer, a
PTR_TO_SOCKET. This pointer type is accessed from BPF through the
'struct bpf_sock' structure.

	Signed-off-by: Joe Stringer <joe@wand.net.nz>
	Acked-by: Alexei Starovoitov <ast@kernel.org>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
(cherry picked from commit c64b7983288e636356f7f5f652de4813e1cfedac)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
#	kernel/bpf/verifier.c
diff --cc include/linux/bpf.h
index 2fcb759fa815,027697b6a22f..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -212,6 -214,9 +214,12 @@@ enum bpf_reg_type 
  	PTR_TO_PACKET_META,	 /* skb->data - meta_len */
  	PTR_TO_PACKET,		 /* reg points to skb->data */
  	PTR_TO_PACKET_END,	 /* skb->data + headlen */
++<<<<<<< HEAD
++=======
+ 	PTR_TO_FLOW_KEYS,	 /* reg points to bpf_flow_keys */
+ 	PTR_TO_SOCKET,		 /* reg points to struct bpf_sock */
+ 	PTR_TO_SOCKET_OR_NULL,	 /* reg points to struct bpf_sock or NULL */
++>>>>>>> c64b7983288e (bpf: Add PTR_TO_SOCKET verifier type)
  };
  
  /* The information passed from prog-specific *_is_valid_access
diff --cc kernel/bpf/verifier.c
index e7cef8978269,f86386c9affd..000000000000
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@@ -266,6 -266,9 +266,12 @@@ static const char * const reg_type_str[
  	[PTR_TO_PACKET]		= "pkt",
  	[PTR_TO_PACKET_META]	= "pkt_meta",
  	[PTR_TO_PACKET_END]	= "pkt_end",
++<<<<<<< HEAD
++=======
+ 	[PTR_TO_FLOW_KEYS]	= "flow_keys",
+ 	[PTR_TO_SOCKET]		= "sock",
+ 	[PTR_TO_SOCKET_OR_NULL] = "sock_or_null",
++>>>>>>> c64b7983288e (bpf: Add PTR_TO_SOCKET verifier type)
  };
  
  static char slot_type_char[] = {
@@@ -973,7 -973,10 +979,9 @@@ static bool is_spillable_regtype(enum b
  	case PTR_TO_PACKET:
  	case PTR_TO_PACKET_META:
  	case PTR_TO_PACKET_END:
 -	case PTR_TO_FLOW_KEYS:
  	case CONST_PTR_TO_MAP:
+ 	case PTR_TO_SOCKET:
+ 	case PTR_TO_SOCKET_OR_NULL:
  		return true;
  	default:
  		return false;
@@@ -1328,6 -1333,40 +1336,43 @@@ static int check_ctx_access(struct bpf_
  	return -EACCES;
  }
  
++<<<<<<< HEAD
++=======
+ static int check_flow_keys_access(struct bpf_verifier_env *env, int off,
+ 				  int size)
+ {
+ 	if (size < 0 || off < 0 ||
+ 	    (u64)off + size > sizeof(struct bpf_flow_keys)) {
+ 		verbose(env, "invalid access to flow keys off=%d size=%d\n",
+ 			off, size);
+ 		return -EACCES;
+ 	}
+ 	return 0;
+ }
+ 
+ static int check_sock_access(struct bpf_verifier_env *env, u32 regno, int off,
+ 			     int size, enum bpf_access_type t)
+ {
+ 	struct bpf_reg_state *regs = cur_regs(env);
+ 	struct bpf_reg_state *reg = &regs[regno];
+ 	struct bpf_insn_access_aux info;
+ 
+ 	if (reg->smin_value < 0) {
+ 		verbose(env, "R%d min value is negative, either use unsigned index or do a if (index >=0) check.\n",
+ 			regno);
+ 		return -EACCES;
+ 	}
+ 
+ 	if (!bpf_sock_is_valid_access(off, size, t, &info)) {
+ 		verbose(env, "invalid bpf_sock access off=%d size=%d\n",
+ 			off, size);
+ 		return -EACCES;
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> c64b7983288e (bpf: Add PTR_TO_SOCKET verifier type)
  static bool __is_pointer_value(bool allow_ptr_leaks,
  			       const struct bpf_reg_state *reg)
  {
@@@ -1699,6 -1744,25 +1747,28 @@@ static int check_mem_access(struct bpf_
  		err = check_packet_access(env, regno, off, size, false);
  		if (!err && t == BPF_READ && value_regno >= 0)
  			mark_reg_unknown(env, regs, value_regno);
++<<<<<<< HEAD
++=======
+ 	} else if (reg->type == PTR_TO_FLOW_KEYS) {
+ 		if (t == BPF_WRITE && value_regno >= 0 &&
+ 		    is_pointer_value(env, value_regno)) {
+ 			verbose(env, "R%d leaks addr into flow keys\n",
+ 				value_regno);
+ 			return -EACCES;
+ 		}
+ 
+ 		err = check_flow_keys_access(env, off, size);
+ 		if (!err && t == BPF_READ && value_regno >= 0)
+ 			mark_reg_unknown(env, regs, value_regno);
+ 	} else if (reg->type == PTR_TO_SOCKET) {
+ 		if (t == BPF_WRITE) {
+ 			verbose(env, "cannot write into socket\n");
+ 			return -EACCES;
+ 		}
+ 		err = check_sock_access(env, regno, off, size, t);
+ 		if (!err && value_regno >= 0)
+ 			mark_reg_unknown(env, regs, value_regno);
++>>>>>>> c64b7983288e (bpf: Add PTR_TO_SOCKET verifier type)
  	} else {
  		verbose(env, "R%d invalid mem access '%s'\n", regno,
  			reg_type_str[reg->type]);
@@@ -4524,6 -4450,9 +4606,12 @@@ static bool regsafe(struct bpf_reg_stat
  	case PTR_TO_CTX:
  	case CONST_PTR_TO_MAP:
  	case PTR_TO_PACKET_END:
++<<<<<<< HEAD
++=======
+ 	case PTR_TO_FLOW_KEYS:
+ 	case PTR_TO_SOCKET:
+ 	case PTR_TO_SOCKET_OR_NULL:
++>>>>>>> c64b7983288e (bpf: Add PTR_TO_SOCKET verifier type)
  		/* Only valid matches are exact, which memcmp() above
  		 * would have accepted
  		 */
* Unmerged path include/linux/bpf.h
diff --git a/include/linux/bpf_verifier.h b/include/linux/bpf_verifier.h
index 60fc755117b1..c7e7995ba04d 100644
--- a/include/linux/bpf_verifier.h
+++ b/include/linux/bpf_verifier.h
@@ -61,6 +61,8 @@ struct bpf_reg_state {
 	 * offset, so they can share range knowledge.
 	 * For PTR_TO_MAP_VALUE_OR_NULL this is used to share which map value we
 	 * came from, when one is tested for != NULL.
+	 * For PTR_TO_SOCKET this is used to share which pointers retain the
+	 * same reference to the socket, to determine proper reference freeing.
 	 */
 	u32 id;
 	/* For scalar types (SCALAR_VALUE), this represents our knowledge of
* Unmerged path kernel/bpf/verifier.c
diff --git a/net/core/filter.c b/net/core/filter.c
index 9215221d9011..d97ac4cbbdad 100644
--- a/net/core/filter.c
+++ b/net/core/filter.c
@@ -5298,23 +5298,29 @@ static bool __sock_filter_check_size(int off, int size,
 	return size == size_default;
 }
 
-static bool sock_filter_is_valid_access(int off, int size,
-					enum bpf_access_type type,
-					const struct bpf_prog *prog,
-					struct bpf_insn_access_aux *info)
+bool bpf_sock_is_valid_access(int off, int size, enum bpf_access_type type,
+			      struct bpf_insn_access_aux *info)
 {
 	if (off < 0 || off >= sizeof(struct bpf_sock))
 		return false;
 	if (off % size != 0)
 		return false;
-	if (!__sock_filter_check_attach_type(off, type,
-					     prog->expected_attach_type))
-		return false;
 	if (!__sock_filter_check_size(off, size, info))
 		return false;
 	return true;
 }
 
+static bool sock_filter_is_valid_access(int off, int size,
+					enum bpf_access_type type,
+					const struct bpf_prog *prog,
+					struct bpf_insn_access_aux *info)
+{
+	if (!bpf_sock_is_valid_access(off, size, type, info))
+		return false;
+	return __sock_filter_check_attach_type(off, type,
+					       prog->expected_attach_type);
+}
+
 static int bpf_unclone_prologue(struct bpf_insn *insn_buf, bool direct_write,
 				const struct bpf_prog *prog, int drop_verdict)
 {
@@ -5982,10 +5988,10 @@ static u32 bpf_convert_ctx_access(enum bpf_access_type type,
 	return insn - insn_buf;
 }
 
-static u32 sock_filter_convert_ctx_access(enum bpf_access_type type,
-					  const struct bpf_insn *si,
-					  struct bpf_insn *insn_buf,
-					  struct bpf_prog *prog, u32 *target_size)
+u32 bpf_sock_convert_ctx_access(enum bpf_access_type type,
+				const struct bpf_insn *si,
+				struct bpf_insn *insn_buf,
+				struct bpf_prog *prog, u32 *target_size)
 {
 	struct bpf_insn *insn = insn_buf;
 	int off;
@@ -6897,7 +6903,7 @@ const struct bpf_prog_ops lwt_seg6local_prog_ops = {
 const struct bpf_verifier_ops cg_sock_verifier_ops = {
 	.get_func_proto		= sock_filter_func_proto,
 	.is_valid_access	= sock_filter_is_valid_access,
-	.convert_ctx_access	= sock_filter_convert_ctx_access,
+	.convert_ctx_access	= bpf_sock_convert_ctx_access,
 };
 
 const struct bpf_prog_ops cg_sock_prog_ops = {
