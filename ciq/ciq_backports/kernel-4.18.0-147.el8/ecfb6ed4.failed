KVM: arm64/sve: Explain validity checks in set_sve_vls()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Dave Martin <Dave.Martin@arm.com>
commit ecfb6ed4f66e68129c3ab675c68cb6578c28ef9b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/ecfb6ed4.failed

Correct virtualization of SVE relies for correctness on code in
set_sve_vls() that verifies consistency between the set of vector
lengths requested by userspace and the set of vector lengths
available on the host.

However, the purpose of this code is not obvious, and not likely to
be apparent at all to people who do not have detailed knowledge of
the SVE system-level architecture.

This patch adds a suitable comment to explain what these checks are
for.

No functional change.

	Suggested-by: Andrew Jones <drjones@redhat.com>
	Signed-off-by: Dave Martin <Dave.Martin@arm.com>
	Reviewed-by: Andrew Jones <drjones@redhat.com>
	Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
(cherry picked from commit ecfb6ed4f66e68129c3ab675c68cb6578c28ef9b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/kvm/guest.c
diff --cc arch/arm64/kvm/guest.c
index 988c23a37725,3ae2f82fca46..000000000000
--- a/arch/arm64/kvm/guest.c
+++ b/arch/arm64/kvm/guest.c
@@@ -206,6 -205,86 +206,89 @@@ out
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ #define vq_word(vq) (((vq) - SVE_VQ_MIN) / 64)
+ #define vq_mask(vq) ((u64)1 << ((vq) - SVE_VQ_MIN) % 64)
+ 
+ static bool vq_present(
+ 	const u64 (*const vqs)[KVM_ARM64_SVE_VLS_WORDS],
+ 	unsigned int vq)
+ {
+ 	return (*vqs)[vq_word(vq)] & vq_mask(vq);
+ }
+ 
+ static int get_sve_vls(struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
+ {
+ 	unsigned int max_vq, vq;
+ 	u64 vqs[KVM_ARM64_SVE_VLS_WORDS];
+ 
+ 	if (!vcpu_has_sve(vcpu))
+ 		return -ENOENT;
+ 
+ 	if (WARN_ON(!sve_vl_valid(vcpu->arch.sve_max_vl)))
+ 		return -EINVAL;
+ 
+ 	memset(vqs, 0, sizeof(vqs));
+ 
+ 	max_vq = sve_vq_from_vl(vcpu->arch.sve_max_vl);
+ 	for (vq = SVE_VQ_MIN; vq <= max_vq; ++vq)
+ 		if (sve_vq_available(vq))
+ 			vqs[vq_word(vq)] |= vq_mask(vq);
+ 
+ 	if (copy_to_user((void __user *)reg->addr, vqs, sizeof(vqs)))
+ 		return -EFAULT;
+ 
+ 	return 0;
+ }
+ 
+ static int set_sve_vls(struct kvm_vcpu *vcpu, const struct kvm_one_reg *reg)
+ {
+ 	unsigned int max_vq, vq;
+ 	u64 vqs[KVM_ARM64_SVE_VLS_WORDS];
+ 
+ 	if (!vcpu_has_sve(vcpu))
+ 		return -ENOENT;
+ 
+ 	if (kvm_arm_vcpu_sve_finalized(vcpu))
+ 		return -EPERM; /* too late! */
+ 
+ 	if (WARN_ON(vcpu->arch.sve_state))
+ 		return -EINVAL;
+ 
+ 	if (copy_from_user(vqs, (const void __user *)reg->addr, sizeof(vqs)))
+ 		return -EFAULT;
+ 
+ 	max_vq = 0;
+ 	for (vq = SVE_VQ_MIN; vq <= SVE_VQ_MAX; ++vq)
+ 		if (vq_present(&vqs, vq))
+ 			max_vq = vq;
+ 
+ 	if (max_vq > sve_vq_from_vl(kvm_sve_max_vl))
+ 		return -EINVAL;
+ 
+ 	/*
+ 	 * Vector lengths supported by the host can't currently be
+ 	 * hidden from the guest individually: instead we can only set a
+ 	 * maxmium via ZCR_EL2.LEN.  So, make sure the available vector
+ 	 * lengths match the set requested exactly up to the requested
+ 	 * maximum:
+ 	 */
+ 	for (vq = SVE_VQ_MIN; vq <= max_vq; ++vq)
+ 		if (vq_present(&vqs, vq) != sve_vq_available(vq))
+ 			return -EINVAL;
+ 
+ 	/* Can't run with no vector lengths at all: */
+ 	if (max_vq < SVE_VQ_MIN)
+ 		return -EINVAL;
+ 
+ 	/* vcpu->arch.sve_state will be alloc'd by kvm_vcpu_finalize_sve() */
+ 	vcpu->arch.sve_max_vl = sve_vl_from_vq(max_vq);
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> ecfb6ed4f66e (KVM: arm64/sve: Explain validity checks in set_sve_vls())
  #define SVE_REG_SLICE_SHIFT	0
  #define SVE_REG_SLICE_BITS	5
  #define SVE_REG_ID_SHIFT	(SVE_REG_SLICE_SHIFT + SVE_REG_SLICE_BITS)
* Unmerged path arch/arm64/kvm/guest.c
