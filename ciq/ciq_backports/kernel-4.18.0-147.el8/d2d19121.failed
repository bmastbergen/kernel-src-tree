IB/mlx5: Set uid as part of TD commands

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Yishai Hadas <yishaih@mellanox.com>
commit d2d19121ae2f4bc4e818dd770c1746deadf14093
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/d2d19121.failed

Set uid as part of TD commands so that the firmware can
manage the TD object in a secured way.

	Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit d2d19121ae2f4bc4e818dd770c1746deadf14093)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/cmd.c
#	drivers/infiniband/hw/mlx5/cmd.h
#	drivers/infiniband/hw/mlx5/main.c
diff --cc drivers/infiniband/hw/mlx5/cmd.c
index 64e48e303392,ca060a2e2b36..000000000000
--- a/drivers/infiniband/hw/mlx5/cmd.c
+++ b/drivers/infiniband/hw/mlx5/cmd.c
@@@ -198,6 -198,69 +198,72 @@@ int mlx5_cmd_query_ext_ppcnt_counters(s
  				     0, 0);
  }
  
++<<<<<<< HEAD
++=======
+ void mlx5_cmd_destroy_tir(struct mlx5_core_dev *dev, u32 tirn, u16 uid)
+ {
+ 	u32 in[MLX5_ST_SZ_DW(destroy_tir_in)]   = {};
+ 	u32 out[MLX5_ST_SZ_DW(destroy_tir_out)] = {};
+ 
+ 	MLX5_SET(destroy_tir_in, in, opcode, MLX5_CMD_OP_DESTROY_TIR);
+ 	MLX5_SET(destroy_tir_in, in, tirn, tirn);
+ 	MLX5_SET(destroy_tir_in, in, uid, uid);
+ 	mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));
+ }
+ 
+ void mlx5_cmd_destroy_tis(struct mlx5_core_dev *dev, u32 tisn, u16 uid)
+ {
+ 	u32 in[MLX5_ST_SZ_DW(destroy_tis_in)]   = {0};
+ 	u32 out[MLX5_ST_SZ_DW(destroy_tis_out)] = {0};
+ 
+ 	MLX5_SET(destroy_tis_in, in, opcode, MLX5_CMD_OP_DESTROY_TIS);
+ 	MLX5_SET(destroy_tis_in, in, tisn, tisn);
+ 	MLX5_SET(destroy_tis_in, in, uid, uid);
+ 	mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));
+ }
+ 
+ void mlx5_cmd_destroy_rqt(struct mlx5_core_dev *dev, u32 rqtn, u16 uid)
+ {
+ 	u32 in[MLX5_ST_SZ_DW(destroy_rqt_in)]   = {};
+ 	u32 out[MLX5_ST_SZ_DW(destroy_rqt_out)] = {};
+ 
+ 	MLX5_SET(destroy_rqt_in, in, opcode, MLX5_CMD_OP_DESTROY_RQT);
+ 	MLX5_SET(destroy_rqt_in, in, rqtn, rqtn);
+ 	MLX5_SET(destroy_rqt_in, in, uid, uid);
+ 	mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));
+ }
+ 
+ int mlx5_cmd_alloc_transport_domain(struct mlx5_core_dev *dev, u32 *tdn,
+ 				    u16 uid)
+ {
+ 	u32 in[MLX5_ST_SZ_DW(alloc_transport_domain_in)]   = {0};
+ 	u32 out[MLX5_ST_SZ_DW(alloc_transport_domain_out)] = {0};
+ 	int err;
+ 
+ 	MLX5_SET(alloc_transport_domain_in, in, opcode,
+ 		 MLX5_CMD_OP_ALLOC_TRANSPORT_DOMAIN);
+ 
+ 	err = mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));
+ 	if (!err)
+ 		*tdn = MLX5_GET(alloc_transport_domain_out, out,
+ 				transport_domain);
+ 
+ 	return err;
+ }
+ 
+ void mlx5_cmd_dealloc_transport_domain(struct mlx5_core_dev *dev, u32 tdn,
+ 				       u16 uid)
+ {
+ 	u32 in[MLX5_ST_SZ_DW(dealloc_transport_domain_in)]   = {0};
+ 	u32 out[MLX5_ST_SZ_DW(dealloc_transport_domain_out)] = {0};
+ 
+ 	MLX5_SET(dealloc_transport_domain_in, in, opcode,
+ 		 MLX5_CMD_OP_DEALLOC_TRANSPORT_DOMAIN);
+ 	MLX5_SET(dealloc_transport_domain_in, in, transport_domain, tdn);
+ 	mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));
+ }
+ 
++>>>>>>> d2d19121ae2f (IB/mlx5: Set uid as part of TD commands)
  void mlx5_cmd_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn, u16 uid)
  {
  	u32 out[MLX5_ST_SZ_DW(dealloc_pd_out)] = {};
diff --cc drivers/infiniband/hw/mlx5/cmd.h
index d1cb191fcd8c,c03c56455534..000000000000
--- a/drivers/infiniband/hw/mlx5/cmd.h
+++ b/drivers/infiniband/hw/mlx5/cmd.h
@@@ -48,6 -48,13 +48,16 @@@ int mlx5_cmd_alloc_memic(struct mlx5_me
  			 u64 length, u32 alignment);
  int mlx5_cmd_dealloc_memic(struct mlx5_memic *memic, u64 addr, u64 length);
  void mlx5_cmd_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn, u16 uid);
++<<<<<<< HEAD
++=======
+ void mlx5_cmd_destroy_tir(struct mlx5_core_dev *dev, u32 tirn, u16 uid);
+ void mlx5_cmd_destroy_tis(struct mlx5_core_dev *dev, u32 tisn, u16 uid);
+ void mlx5_cmd_destroy_rqt(struct mlx5_core_dev *dev, u32 rqtn, u16 uid);
+ int mlx5_cmd_alloc_transport_domain(struct mlx5_core_dev *dev, u32 *tdn,
+ 				    u16 uid);
+ void mlx5_cmd_dealloc_transport_domain(struct mlx5_core_dev *dev, u32 tdn,
+ 				       u16 uid);
++>>>>>>> d2d19121ae2f (IB/mlx5: Set uid as part of TD commands)
  int mlx5_cmd_attach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid,
  			u32 qpn, u16 uid);
  int mlx5_cmd_detach_mcg(struct mlx5_core_dev *dev, union ib_gid *mgid,
diff --cc drivers/infiniband/hw/mlx5/main.c
index f0ec543ce522,91693e1a3731..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -1564,7 -1571,50 +1564,54 @@@ static void deallocate_uars(struct mlx5
  			mlx5_cmd_free_uar(dev->mdev, bfregi->sys_pages[i]);
  }
  
++<<<<<<< HEAD
 +static int mlx5_ib_alloc_transport_domain(struct mlx5_ib_dev *dev, u32 *tdn)
++=======
+ int mlx5_ib_enable_lb(struct mlx5_ib_dev *dev, bool td, bool qp)
+ {
+ 	int err = 0;
+ 
+ 	mutex_lock(&dev->lb.mutex);
+ 	if (td)
+ 		dev->lb.user_td++;
+ 	if (qp)
+ 		dev->lb.qps++;
+ 
+ 	if (dev->lb.user_td == 2 ||
+ 	    dev->lb.qps == 1) {
+ 		if (!dev->lb.enabled) {
+ 			err = mlx5_nic_vport_update_local_lb(dev->mdev, true);
+ 			dev->lb.enabled = true;
+ 		}
+ 	}
+ 
+ 	mutex_unlock(&dev->lb.mutex);
+ 
+ 	return err;
+ }
+ 
+ void mlx5_ib_disable_lb(struct mlx5_ib_dev *dev, bool td, bool qp)
+ {
+ 	mutex_lock(&dev->lb.mutex);
+ 	if (td)
+ 		dev->lb.user_td--;
+ 	if (qp)
+ 		dev->lb.qps--;
+ 
+ 	if (dev->lb.user_td == 1 &&
+ 	    dev->lb.qps == 0) {
+ 		if (dev->lb.enabled) {
+ 			mlx5_nic_vport_update_local_lb(dev->mdev, false);
+ 			dev->lb.enabled = false;
+ 		}
+ 	}
+ 
+ 	mutex_unlock(&dev->lb.mutex);
+ }
+ 
+ static int mlx5_ib_alloc_transport_domain(struct mlx5_ib_dev *dev, u32 *tdn,
+ 					  u16 uid)
++>>>>>>> d2d19121ae2f (IB/mlx5: Set uid as part of TD commands)
  {
  	int err;
  
@@@ -1580,17 -1630,11 +1627,18 @@@
  	     !MLX5_CAP_GEN(dev->mdev, disable_local_lb_mc)))
  		return err;
  
 -	return mlx5_ib_enable_lb(dev, true, false);
 +	mutex_lock(&dev->lb_mutex);
 +	dev->user_td++;
 +
 +	if (dev->user_td == 2)
 +		err = mlx5_nic_vport_update_local_lb(dev->mdev, true);
 +
 +	mutex_unlock(&dev->lb_mutex);
 +	return err;
  }
  
- static void mlx5_ib_dealloc_transport_domain(struct mlx5_ib_dev *dev, u32 tdn)
+ static void mlx5_ib_dealloc_transport_domain(struct mlx5_ib_dev *dev, u32 tdn,
+ 					     u16 uid)
  {
  	if (!MLX5_CAP_GEN(dev->mdev, log_max_transport_domain))
  		return;
@@@ -1854,11 -1893,18 +1903,21 @@@ static int mlx5_ib_dealloc_ucontext(str
  	struct mlx5_ib_dev *dev = to_mdev(ibcontext->device);
  	struct mlx5_bfreg_info *bfregi;
  
- 	if (context->devx_uid)
- 		mlx5_ib_devx_destroy(dev, context);
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+ 	/* All umem's must be destroyed before destroying the ucontext. */
+ 	mutex_lock(&ibcontext->per_mm_list_lock);
+ 	WARN_ON(!list_empty(&ibcontext->per_mm_list));
+ 	mutex_unlock(&ibcontext->per_mm_list_lock);
+ #endif
  
  	bfregi = &context->bfregi;
- 	mlx5_ib_dealloc_transport_domain(dev, context->tdn);
+ 	mlx5_ib_dealloc_transport_domain(dev, context->tdn, context->devx_uid);
+ 
++>>>>>>> d2d19121ae2f (IB/mlx5: Set uid as part of TD commands)
+ 	if (context->devx_uid)
+ 		mlx5_ib_devx_destroy(dev, context);
  
  	deallocate_uars(dev, context);
  	kfree(bfregi->sys_pages);
* Unmerged path drivers/infiniband/hw/mlx5/cmd.c
* Unmerged path drivers/infiniband/hw/mlx5/cmd.h
* Unmerged path drivers/infiniband/hw/mlx5/main.c
