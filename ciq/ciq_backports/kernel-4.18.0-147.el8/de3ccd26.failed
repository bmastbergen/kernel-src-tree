KVM: MMU: record maximum physical address width in kvm_mmu_extended_role

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Yu Zhang <yu.c.zhang@linux.intel.com>
commit de3ccd26fafc707b09792d9b633c8b5b48865315
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/de3ccd26.failed

Previously, commit 7dcd57552008 ("x86/kvm/mmu: check if tdp/shadow
MMU reconfiguration is needed") offered some optimization to avoid
the unnecessary reconfiguration. Yet one scenario is broken - when
cpuid changes VM's maximum physical address width, reconfiguration
is needed to reset the reserved bits.  Also, the TDP may need to
reset its shadow_root_level when this value is changed.

To fix this, a new field, maxphyaddr, is introduced in the extended
role structure to keep track of the configured guest physical address
width.

	Signed-off-by: Yu Zhang <yu.c.zhang@linux.intel.com>
	Cc: stable@vger.kernel.org
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit de3ccd26fafc707b09792d9b633c8b5b48865315)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/kvm_host.h
#	arch/x86/kvm/mmu.c
diff --cc arch/x86/include/asm/kvm_host.h
index 4f4095c7b53d,180373360e34..000000000000
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@@ -284,7 -283,24 +284,21 @@@ union kvm_mmu_page_role 
  };
  
  union kvm_mmu_extended_role {
 -/*
 - * This structure complements kvm_mmu_page_role caching everything needed for
 - * MMU configuration. If nothing in both these structures changed, MMU
 - * re-configuration can be skipped. @valid bit is set on first usage so we don't
 - * treat all-zero structure as valid data.
 - */
  	u32 word;
++<<<<<<< HEAD
++=======
+ 	struct {
+ 		unsigned int valid:1;
+ 		unsigned int execonly:1;
+ 		unsigned int cr0_pg:1;
+ 		unsigned int cr4_pse:1;
+ 		unsigned int cr4_pke:1;
+ 		unsigned int cr4_smap:1;
+ 		unsigned int cr4_smep:1;
+ 		unsigned int cr4_la57:1;
+ 		unsigned int maxphyaddr:6;
+ 	};
++>>>>>>> de3ccd26fafc (KVM: MMU: record maximum physical address width in kvm_mmu_extended_role)
  };
  
  union kvm_mmu_role {
diff --cc arch/x86/kvm/mmu.c
index 55a047693562,f2d1d230d5b8..000000000000
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@@ -4763,17 -4767,51 +4763,61 @@@ static void paging32E_init_context(stru
  	paging64_init_context_common(vcpu, context, PT32E_ROOT_LEVEL);
  }
  
 -static union kvm_mmu_extended_role kvm_calc_mmu_role_ext(struct kvm_vcpu *vcpu)
 -{
 -	union kvm_mmu_extended_role ext = {0};
 -
 +static union kvm_mmu_page_role
 +kvm_calc_tdp_mmu_root_page_role(struct kvm_vcpu *vcpu)
 +{
 +	union kvm_mmu_page_role role = {0};
 +
++<<<<<<< HEAD
 +	role.guest_mode = is_guest_mode(vcpu);
 +	role.smm = is_smm(vcpu);
 +	role.ad_disabled = (shadow_accessed_mask == 0);
 +	role.level = kvm_x86_ops->get_tdp_level(vcpu);
 +	role.direct = true;
 +	role.access = ACC_ALL;
++=======
+ 	ext.cr0_pg = !!is_paging(vcpu);
+ 	ext.cr4_smep = !!kvm_read_cr4_bits(vcpu, X86_CR4_SMEP);
+ 	ext.cr4_smap = !!kvm_read_cr4_bits(vcpu, X86_CR4_SMAP);
+ 	ext.cr4_pse = !!is_pse(vcpu);
+ 	ext.cr4_pke = !!kvm_read_cr4_bits(vcpu, X86_CR4_PKE);
+ 	ext.cr4_la57 = !!kvm_read_cr4_bits(vcpu, X86_CR4_LA57);
+ 	ext.maxphyaddr = cpuid_maxphyaddr(vcpu);
+ 
+ 	ext.valid = 1;
+ 
+ 	return ext;
+ }
+ 
+ static union kvm_mmu_role kvm_calc_mmu_role_common(struct kvm_vcpu *vcpu,
+ 						   bool base_only)
+ {
+ 	union kvm_mmu_role role = {0};
+ 
+ 	role.base.access = ACC_ALL;
+ 	role.base.nxe = !!is_nx(vcpu);
+ 	role.base.cr4_pae = !!is_pae(vcpu);
+ 	role.base.cr0_wp = is_write_protection(vcpu);
+ 	role.base.smm = is_smm(vcpu);
+ 	role.base.guest_mode = is_guest_mode(vcpu);
+ 
+ 	if (base_only)
+ 		return role;
+ 
+ 	role.ext = kvm_calc_mmu_role_ext(vcpu);
+ 
+ 	return role;
+ }
+ 
+ static union kvm_mmu_role
+ kvm_calc_tdp_mmu_root_page_role(struct kvm_vcpu *vcpu, bool base_only)
+ {
+ 	union kvm_mmu_role role = kvm_calc_mmu_role_common(vcpu, base_only);
+ 
+ 	role.base.ad_disabled = (shadow_accessed_mask == 0);
+ 	role.base.level = kvm_x86_ops->get_tdp_level(vcpu);
+ 	role.base.direct = true;
++>>>>>>> de3ccd26fafc (KVM: MMU: record maximum physical address width in kvm_mmu_extended_role)
  
  	return role;
  }
* Unmerged path arch/x86/include/asm/kvm_host.h
* Unmerged path arch/x86/kvm/mmu.c
