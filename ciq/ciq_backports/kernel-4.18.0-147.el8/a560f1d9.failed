RDMA/mlx5: Refactor transport domain bookkeeping logic

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Mark Bloch <markb@mellanox.com>
commit a560f1d9af4be84ee91d1a47382cacf620eb4a79
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/a560f1d9.failed

In preparation to enable loopback on a single user context move the logic
that enables/disables loopback to separate functions and group variables
under a single struct.

	Signed-off-by: Mark Bloch <markb@mellanox.com>
	Reviewed-by: Yishai Hadas <yishaih@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit a560f1d9af4be84ee91d1a47382cacf620eb4a79)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/mlx5_ib.h
diff --cc drivers/infiniband/hw/mlx5/mlx5_ib.h
index d9607eed8056,fde5a867a7d3..000000000000
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@@ -839,11 -858,15 +839,20 @@@ to_mcounters(struct ib_counters *ibcntr
  	return container_of(ibcntrs, struct mlx5_ib_mcounters, ibcntrs);
  }
  
++<<<<<<< HEAD
 +int parse_flow_flow_action(struct mlx5_ib_flow_action *maction,
 +			   bool is_egress,
 +			   struct mlx5_flow_act *action);
++=======
+ struct mlx5_ib_lb_state {
+ 	/* protect the user_td */
+ 	struct mutex		mutex;
+ 	u32			user_td;
+ };
+ 
++>>>>>>> a560f1d9af4b (RDMA/mlx5: Refactor transport domain bookkeeping logic)
  struct mlx5_ib_dev {
  	struct ib_device		ib_dev;
 -	const struct uverbs_object_tree_def *driver_trees[6];
  	struct mlx5_core_dev		*mdev;
  	struct mlx5_roce		roce[MLX5_MAX_PORTS];
  	int				num_ports;
diff --git a/drivers/infiniband/hw/mlx5/main.c b/drivers/infiniband/hw/mlx5/main.c
index 5400c743211c..3df71b0157e7 100644
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@ -1564,6 +1564,32 @@ static void deallocate_uars(struct mlx5_ib_dev *dev,
 			mlx5_cmd_free_uar(dev->mdev, bfregi->sys_pages[i]);
 }
 
+static int mlx5_ib_enable_lb(struct mlx5_ib_dev *dev)
+{
+	int err = 0;
+
+	mutex_lock(&dev->lb.mutex);
+	dev->lb.user_td++;
+
+	if (dev->lb.user_td == 2)
+		err = mlx5_nic_vport_update_local_lb(dev->mdev, true);
+
+	mutex_unlock(&dev->lb.mutex);
+
+	return err;
+}
+
+static void mlx5_ib_disable_lb(struct mlx5_ib_dev *dev)
+{
+	mutex_lock(&dev->lb.mutex);
+	dev->lb.user_td--;
+
+	if (dev->lb.user_td < 2)
+		mlx5_nic_vport_update_local_lb(dev->mdev, false);
+
+	mutex_unlock(&dev->lb.mutex);
+}
+
 static int mlx5_ib_alloc_transport_domain(struct mlx5_ib_dev *dev, u32 *tdn)
 {
 	int err;
@@ -1580,14 +1606,7 @@ static int mlx5_ib_alloc_transport_domain(struct mlx5_ib_dev *dev, u32 *tdn)
 	     !MLX5_CAP_GEN(dev->mdev, disable_local_lb_mc)))
 		return err;
 
-	mutex_lock(&dev->lb_mutex);
-	dev->user_td++;
-
-	if (dev->user_td == 2)
-		err = mlx5_nic_vport_update_local_lb(dev->mdev, true);
-
-	mutex_unlock(&dev->lb_mutex);
-	return err;
+	return mlx5_ib_enable_lb(dev);
 }
 
 static void mlx5_ib_dealloc_transport_domain(struct mlx5_ib_dev *dev, u32 tdn)
@@ -1602,13 +1621,7 @@ static void mlx5_ib_dealloc_transport_domain(struct mlx5_ib_dev *dev, u32 tdn)
 	     !MLX5_CAP_GEN(dev->mdev, disable_local_lb_mc)))
 		return;
 
-	mutex_lock(&dev->lb_mutex);
-	dev->user_td--;
-
-	if (dev->user_td < 2)
-		mlx5_nic_vport_update_local_lb(dev->mdev, false);
-
-	mutex_unlock(&dev->lb_mutex);
+	mlx5_ib_disable_lb(dev);
 }
 
 static struct ib_ucontext *mlx5_ib_alloc_ucontext(struct ib_device *ibdev,
@@ -5609,7 +5622,7 @@ int mlx5_ib_stage_caps_init(struct mlx5_ib_dev *dev)
 	if ((MLX5_CAP_GEN(dev->mdev, port_type) == MLX5_CAP_PORT_TYPE_ETH) &&
 	    (MLX5_CAP_GEN(dev->mdev, disable_local_lb_uc) ||
 	     MLX5_CAP_GEN(dev->mdev, disable_local_lb_mc)))
-		mutex_init(&dev->lb_mutex);
+		mutex_init(&dev->lb.mutex);
 
 	return 0;
 }
* Unmerged path drivers/infiniband/hw/mlx5/mlx5_ib.h
