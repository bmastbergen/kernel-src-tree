bpf: add __weak hook for allocating executable memory

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Ard Biesheuvel <ard.biesheuvel@linaro.org>
commit dc002bb62f10c5905420f8b8a7d5ec0da567fc82
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/dc002bb6.failed

By default, BPF uses module_alloc() to allocate executable memory,
but this is not necessary on all arches and potentially undesirable
on some of them.

So break out the module_alloc() and module_memfree() calls into __weak
functions to allow them to be overridden in arch code.

	Signed-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
(cherry picked from commit dc002bb62f10c5905420f8b8a7d5ec0da567fc82)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/core.c
diff --cc kernel/bpf/core.c
index b3f0a11b622a,86817ab204e8..000000000000
--- a/kernel/bpf/core.c
+++ b/kernel/bpf/core.c
@@@ -577,6 -592,47 +577,50 @@@ int bpf_get_kallsym(unsigned int symnum
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ static atomic_long_t bpf_jit_current;
+ 
+ #if defined(MODULES_VADDR)
+ static int __init bpf_jit_charge_init(void)
+ {
+ 	/* Only used as heuristic here to derive limit. */
+ 	bpf_jit_limit = min_t(u64, round_up((MODULES_END - MODULES_VADDR) >> 2,
+ 					    PAGE_SIZE), INT_MAX);
+ 	return 0;
+ }
+ pure_initcall(bpf_jit_charge_init);
+ #endif
+ 
+ static int bpf_jit_charge_modmem(u32 pages)
+ {
+ 	if (atomic_long_add_return(pages, &bpf_jit_current) >
+ 	    (bpf_jit_limit >> PAGE_SHIFT)) {
+ 		if (!capable(CAP_SYS_ADMIN)) {
+ 			atomic_long_sub(pages, &bpf_jit_current);
+ 			return -EPERM;
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void bpf_jit_uncharge_modmem(u32 pages)
+ {
+ 	atomic_long_sub(pages, &bpf_jit_current);
+ }
+ 
+ void *__weak bpf_jit_alloc_exec(unsigned long size)
+ {
+ 	return module_alloc(size);
+ }
+ 
+ void __weak bpf_jit_free_exec(void *addr)
+ {
+ 	module_memfree(addr);
+ }
+ 
++>>>>>>> dc002bb62f10 (bpf: add __weak hook for allocating executable memory)
  struct bpf_binary_header *
  bpf_jit_binary_alloc(unsigned int proglen, u8 **image_ptr,
  		     unsigned int alignment,
@@@ -590,9 -646,15 +634,19 @@@
  	 * random section of illegal instructions.
  	 */
  	size = round_up(proglen + sizeof(*hdr) + 128, PAGE_SIZE);
++<<<<<<< HEAD
 +	hdr = module_alloc(size);
 +	if (hdr == NULL)
++=======
+ 	pages = size / PAGE_SIZE;
+ 
+ 	if (bpf_jit_charge_modmem(pages))
+ 		return NULL;
+ 	hdr = bpf_jit_alloc_exec(size);
+ 	if (!hdr) {
+ 		bpf_jit_uncharge_modmem(pages);
++>>>>>>> dc002bb62f10 (bpf: add __weak hook for allocating executable memory)
  		return NULL;
 -	}
  
  	/* Fill space with illegal/arch-dep instructions. */
  	bpf_fill_ill_insns(hdr, size);
@@@ -610,7 -672,10 +664,14 @@@
  
  void bpf_jit_binary_free(struct bpf_binary_header *hdr)
  {
++<<<<<<< HEAD
 +	module_memfree(hdr);
++=======
+ 	u32 pages = hdr->pages;
+ 
+ 	bpf_jit_free_exec(hdr);
+ 	bpf_jit_uncharge_modmem(pages);
++>>>>>>> dc002bb62f10 (bpf: add __weak hook for allocating executable memory)
  }
  
  /* This symbol is only overridden by archs that have different
* Unmerged path kernel/bpf/core.c
