drm/i915/icl: Default to Thread Group preemption for compute workloads

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-147.el8
commit-author Michał Winiarski <michal.winiarski@intel.com>
commit d846325ad0e5cd06f441299cdbec6ab8ba3a3c45
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-147.el8/d846325a.failed

We assumed that the default preemption granularity is fine for ICL.
Unfortunately, it turns out that some drivers don't support mid-thread
preemption for compute workloads.
If a workload that doesn't support mid-thread preemption gets mid-thread
preempted, we're going to observe a GPU hang.
While I'm here, let's also update the "workaround" naming.

	Signed-off-by: Michał Winiarski <michal.winiarski@intel.com>
	Cc: Anuj Phogat <anuj.phogat@intel.com>
	Cc: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
	Cc: Matt Roper <matthew.d.roper@intel.com>
	Cc: Rafael Antognolli <rafael.antognolli@intel.com>
	Tested-by: Anuj Phogat <anuj.phogat@intel.com>
	Reviewed-by: Rodrigo Vivi <rodrigo.vivi@intel.com>
	Acked-by: Rafael Antognolli <rafael.antognolli@intel.com>
	Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
Link: https://patchwork.freedesktop.org/patch/msgid/20190305124827.23446-1-michal.winiarski@intel.com
(cherry picked from commit d846325ad0e5cd06f441299cdbec6ab8ba3a3c45)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/i915/intel_workarounds.c
diff --cc drivers/gpu/drm/i915/intel_workarounds.c
index 2df3538ceba5,283e9a4ef3ca..000000000000
--- a/drivers/gpu/drm/i915/intel_workarounds.c
+++ b/drivers/gpu/drm/i915/intel_workarounds.c
@@@ -463,52 -534,76 +463,81 @@@ static int icl_ctx_workarounds_init(str
  	 */
  	WA_SET_BIT_MASKED(ICL_HDC_MODE, HDC_FORCE_NON_COHERENT);
  
++<<<<<<< HEAD
 +	return 0;
++=======
+ 	/* Wa_2006611047:icl (pre-prod)
+ 	 * Formerly known as WaDisableImprovedTdlClkGating
+ 	 */
+ 	if (IS_ICL_REVID(i915, ICL_REVID_A0, ICL_REVID_A0))
+ 		WA_SET_BIT_MASKED(GEN7_ROW_CHICKEN2,
+ 				  GEN11_TDL_CLOCK_GATING_FIX_DISABLE);
+ 
+ 	/* WaEnableStateCacheRedirectToCS:icl */
+ 	WA_SET_BIT_MASKED(GEN9_SLICE_COMMON_ECO_CHICKEN1,
+ 			  GEN11_STATE_CACHE_REDIRECT_TO_CS);
+ 
+ 	/* Wa_2006665173:icl (pre-prod) */
+ 	if (IS_ICL_REVID(i915, ICL_REVID_A0, ICL_REVID_A0))
+ 		WA_SET_BIT_MASKED(GEN11_COMMON_SLICE_CHICKEN3,
+ 				  GEN11_BLEND_EMB_FIX_DISABLE_IN_RCC);
+ 
+ 	/* WaEnableFloatBlendOptimization:icl */
+ 	wa_write_masked_or(wal,
+ 			   GEN10_CACHE_MODE_SS,
+ 			   0, /* write-only, so skip validation */
+ 			   _MASKED_BIT_ENABLE(FLOAT_BLEND_OPTIMIZATION_ENABLE));
+ 
+ 	/* WaDisableGPGPUMidThreadPreemption:icl */
+ 	WA_SET_FIELD_MASKED(GEN8_CS_CHICKEN1,
+ 			    GEN9_PREEMPT_GPGPU_LEVEL_MASK,
+ 			    GEN9_PREEMPT_GPGPU_THREAD_GROUP_LEVEL);
++>>>>>>> d846325ad0e5 (drm/i915/icl: Default to Thread Group preemption for compute workloads)
  }
  
 -void intel_engine_init_ctx_wa(struct intel_engine_cs *engine)
 +int intel_ctx_workarounds_init(struct drm_i915_private *dev_priv)
  {
 -	struct drm_i915_private *i915 = engine->i915;
 -	struct i915_wa_list *wal = &engine->ctx_wa_list;
 -
 -	wa_init_start(wal, "context");
 -
 -	if (IS_ICELAKE(i915))
 -		icl_ctx_workarounds_init(engine);
 -	else if (IS_CANNONLAKE(i915))
 -		cnl_ctx_workarounds_init(engine);
 -	else if (IS_COFFEELAKE(i915))
 -		cfl_ctx_workarounds_init(engine);
 -	else if (IS_GEMINILAKE(i915))
 -		glk_ctx_workarounds_init(engine);
 -	else if (IS_KABYLAKE(i915))
 -		kbl_ctx_workarounds_init(engine);
 -	else if (IS_BROXTON(i915))
 -		bxt_ctx_workarounds_init(engine);
 -	else if (IS_SKYLAKE(i915))
 -		skl_ctx_workarounds_init(engine);
 -	else if (IS_CHERRYVIEW(i915))
 -		chv_ctx_workarounds_init(engine);
 -	else if (IS_BROADWELL(i915))
 -		bdw_ctx_workarounds_init(engine);
 -	else if (INTEL_GEN(i915) < 8)
 -		return;
 +	int err = 0;
 +
 +	dev_priv->workarounds.count = 0;
 +
 +	if (INTEL_GEN(dev_priv) < 8)
 +		err = 0;
 +	else if (IS_BROADWELL(dev_priv))
 +		err = bdw_ctx_workarounds_init(dev_priv);
 +	else if (IS_CHERRYVIEW(dev_priv))
 +		err = chv_ctx_workarounds_init(dev_priv);
 +	else if (IS_SKYLAKE(dev_priv))
 +		err = skl_ctx_workarounds_init(dev_priv);
 +	else if (IS_BROXTON(dev_priv))
 +		err = bxt_ctx_workarounds_init(dev_priv);
 +	else if (IS_KABYLAKE(dev_priv))
 +		err = kbl_ctx_workarounds_init(dev_priv);
 +	else if (IS_GEMINILAKE(dev_priv))
 +		err = glk_ctx_workarounds_init(dev_priv);
 +	else if (IS_COFFEELAKE(dev_priv))
 +		err = cfl_ctx_workarounds_init(dev_priv);
 +	else if (IS_CANNONLAKE(dev_priv))
 +		err = cnl_ctx_workarounds_init(dev_priv);
 +	else if (IS_ICELAKE(dev_priv))
 +		err = icl_ctx_workarounds_init(dev_priv);
  	else
 -		MISSING_CASE(INTEL_GEN(i915));
 +		MISSING_CASE(INTEL_GEN(dev_priv));
 +	if (err)
 +		return err;
  
 -	wa_init_finish(wal);
 +	DRM_DEBUG_DRIVER("Number of context specific w/a: %d\n",
 +			 dev_priv->workarounds.count);
 +	return 0;
  }
  
 -int intel_engine_emit_ctx_wa(struct i915_request *rq)
 +int intel_ctx_workarounds_emit(struct i915_request *rq)
  {
 -	struct i915_wa_list *wal = &rq->engine->ctx_wa_list;
 -	struct i915_wa *wa;
 -	unsigned int i;
 +	struct i915_workarounds *w = &rq->i915->workarounds;
  	u32 *cs;
 -	int ret;
 +	int ret, i;
  
 -	if (wal->count == 0)
 +	if (w->count == 0)
  		return 0;
  
  	ret = rq->engine->emit_flush(rq, EMIT_BARRIER);
@@@ -932,16 -1103,157 +961,161 @@@ static void whitelist_apply(struct inte
  
  	/* And clear the rest just in case of garbage */
  	for (; i < RING_MAX_NONPRIV_SLOTS; i++)
 -		I915_WRITE(RING_FORCE_TO_NONPRIV(base, i),
 -			   i915_mmio_reg_offset(RING_NOPID(base)));
 +		I915_WRITE_FW(RING_FORCE_TO_NONPRIV(base, i), w->nopid);
 +
 +	intel_uncore_forcewake_put(engine->i915, FORCEWAKE_ALL);
  }
  
 -static void
 -rcs_engine_wa_init(struct intel_engine_cs *engine, struct i915_wa_list *wal)
 +void intel_whitelist_workarounds_apply(struct intel_engine_cs *engine)
  {
 -	struct drm_i915_private *i915 = engine->i915;
 +	struct whitelist w;
  
++<<<<<<< HEAD
 +	whitelist_apply(engine, whitelist_build(engine, &w));
++=======
+ 	if (IS_ICELAKE(i915)) {
+ 		/* This is not an Wa. Enable for better image quality */
+ 		wa_masked_en(wal,
+ 			     _3D_CHICKEN3,
+ 			     _3D_CHICKEN3_AA_LINE_QUALITY_FIX_ENABLE);
+ 
+ 		/* WaPipelineFlushCoherentLines:icl */
+ 		wa_write_or(wal,
+ 			    GEN8_L3SQCREG4,
+ 			    GEN8_LQSC_FLUSH_COHERENT_LINES);
+ 
+ 		/*
+ 		 * Wa_1405543622:icl
+ 		 * Formerly known as WaGAPZPriorityScheme
+ 		 */
+ 		wa_write_or(wal,
+ 			    GEN8_GARBCNTL,
+ 			    GEN11_ARBITRATION_PRIO_ORDER_MASK);
+ 
+ 		/*
+ 		 * Wa_1604223664:icl
+ 		 * Formerly known as WaL3BankAddressHashing
+ 		 */
+ 		wa_write_masked_or(wal,
+ 				   GEN8_GARBCNTL,
+ 				   GEN11_HASH_CTRL_EXCL_MASK,
+ 				   GEN11_HASH_CTRL_EXCL_BIT0);
+ 		wa_write_masked_or(wal,
+ 				   GEN11_GLBLINVL,
+ 				   GEN11_BANK_HASH_ADDR_EXCL_MASK,
+ 				   GEN11_BANK_HASH_ADDR_EXCL_BIT0);
+ 
+ 		/*
+ 		 * Wa_1405733216:icl
+ 		 * Formerly known as WaDisableCleanEvicts
+ 		 */
+ 		wa_write_or(wal,
+ 			    GEN8_L3SQCREG4,
+ 			    GEN11_LQSC_CLEAN_EVICT_DISABLE);
+ 
+ 		/* WaForwardProgressSoftReset:icl */
+ 		wa_write_or(wal,
+ 			    GEN10_SCRATCH_LNCF2,
+ 			    PMFLUSHDONE_LNICRSDROP |
+ 			    PMFLUSH_GAPL3UNBLOCK |
+ 			    PMFLUSHDONE_LNEBLK);
+ 
+ 		/* Wa_1406609255:icl (pre-prod) */
+ 		if (IS_ICL_REVID(i915, ICL_REVID_A0, ICL_REVID_B0))
+ 			wa_write_or(wal,
+ 				    GEN7_SARCHKMD,
+ 				    GEN7_DISABLE_DEMAND_PREFETCH |
+ 				    GEN7_DISABLE_SAMPLER_PREFETCH);
+ 	}
+ 
+ 	if (IS_GEN_RANGE(i915, 9, 11)) {
+ 		/* FtrPerCtxtPreemptionGranularityControl:skl,bxt,kbl,cfl,cnl,icl */
+ 		wa_masked_en(wal,
+ 			     GEN7_FF_SLICE_CS_CHICKEN1,
+ 			     GEN9_FFSC_PERCTX_PREEMPT_CTRL);
+ 	}
+ 
+ 	if (IS_SKYLAKE(i915) || IS_KABYLAKE(i915) || IS_COFFEELAKE(i915)) {
+ 		/* WaEnableGapsTsvCreditFix:skl,kbl,cfl */
+ 		wa_write_or(wal,
+ 			    GEN8_GARBCNTL,
+ 			    GEN9_GAPS_TSV_CREDIT_DISABLE);
+ 	}
+ 
+ 	if (IS_BROXTON(i915)) {
+ 		/* WaDisablePooledEuLoadBalancingFix:bxt */
+ 		wa_masked_en(wal,
+ 			     FF_SLICE_CS_CHICKEN2,
+ 			     GEN9_POOLED_EU_LOAD_BALANCING_FIX_DISABLE);
+ 	}
+ 
+ 	if (IS_GEN(i915, 9)) {
+ 		/* WaContextSwitchWithConcurrentTLBInvalidate:skl,bxt,kbl,glk,cfl */
+ 		wa_masked_en(wal,
+ 			     GEN9_CSFE_CHICKEN1_RCS,
+ 			     GEN9_PREEMPT_GPGPU_SYNC_SWITCH_DISABLE);
+ 
+ 		/* WaEnableLbsSlaRetryTimerDecrement:skl,bxt,kbl,glk,cfl */
+ 		wa_write_or(wal,
+ 			    BDW_SCRATCH1,
+ 			    GEN9_LBS_SLA_RETRY_TIMER_DECREMENT_ENABLE);
+ 
+ 		/* WaProgramL3SqcReg1DefaultForPerf:bxt,glk */
+ 		if (IS_GEN9_LP(i915))
+ 			wa_write_masked_or(wal,
+ 					   GEN8_L3SQCREG1,
+ 					   L3_PRIO_CREDITS_MASK,
+ 					   L3_GENERAL_PRIO_CREDITS(62) |
+ 					   L3_HIGH_PRIO_CREDITS(2));
+ 
+ 		/* WaOCLCoherentLineFlush:skl,bxt,kbl,cfl */
+ 		wa_write_or(wal,
+ 			    GEN8_L3SQCREG4,
+ 			    GEN8_LQSC_FLUSH_COHERENT_LINES);
+ 	}
+ }
+ 
+ static void
+ xcs_engine_wa_init(struct intel_engine_cs *engine, struct i915_wa_list *wal)
+ {
+ 	struct drm_i915_private *i915 = engine->i915;
+ 
+ 	/* WaKBLVECSSemaphoreWaitPoll:kbl */
+ 	if (IS_KBL_REVID(i915, KBL_REVID_A0, KBL_REVID_E0)) {
+ 		wa_write(wal,
+ 			 RING_SEMA_WAIT_POLL(engine->mmio_base),
+ 			 1);
+ 	}
+ }
+ 
+ static void
+ engine_init_workarounds(struct intel_engine_cs *engine, struct i915_wa_list *wal)
+ {
+ 	if (I915_SELFTEST_ONLY(INTEL_GEN(engine->i915) < 8))
+ 		return;
+ 
+ 	if (engine->id == RCS0)
+ 		rcs_engine_wa_init(engine, wal);
+ 	else
+ 		xcs_engine_wa_init(engine, wal);
+ }
+ 
+ void intel_engine_init_workarounds(struct intel_engine_cs *engine)
+ {
+ 	struct i915_wa_list *wal = &engine->wa_list;
+ 
+ 	if (GEM_WARN_ON(INTEL_GEN(engine->i915) < 8))
+ 		return;
+ 
+ 	wa_init_start(wal, engine->name);
+ 	engine_init_workarounds(engine, wal);
+ 	wa_init_finish(wal);
+ }
+ 
+ void intel_engine_apply_workarounds(struct intel_engine_cs *engine)
+ {
+ 	wa_list_apply(engine->i915, &engine->wa_list);
++>>>>>>> d846325ad0e5 (drm/i915/icl: Default to Thread Group preemption for compute workloads)
  }
  
  #if IS_ENABLED(CONFIG_DRM_I915_SELFTEST)
* Unmerged path drivers/gpu/drm/i915/intel_workarounds.c
