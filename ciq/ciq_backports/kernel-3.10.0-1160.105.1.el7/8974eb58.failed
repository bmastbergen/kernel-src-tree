x86/speculation: Add Gather Data Sampling mitigation

jira LE-1907
cve CVE-2022-40982
Rebuild_History Non-Buildable kernel-3.10.0-1160.105.1.el7
commit-author Daniel Sneddon <daniel.sneddon@linux.intel.com>
commit 8974eb588283b7d44a7c91fa09fcbaf380339f3a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.105.1.el7/8974eb58.failed

Gather Data Sampling (GDS) is a hardware vulnerability which allows
unprivileged speculative access to data which was previously stored in
vector registers.

Intel processors that support AVX2 and AVX512 have gather instructions
that fetch non-contiguous data elements from memory. On vulnerable
hardware, when a gather instruction is transiently executed and
encounters a fault, stale data from architectural or internal vector
registers may get transiently stored to the destination vector
register allowing an attacker to infer the stale data using typical
side channel techniques like cache timing attacks.

This mitigation is different from many earlier ones for two reasons.
First, it is enabled by default and a bit must be set to *DISABLE* it.
This is the opposite of normal mitigation polarity. This means GDS can
be mitigated simply by updating microcode and leaving the new control
bit alone.

Second, GDS has a "lock" bit. This lock bit is there because the
mitigation affects the hardware security features KeyLocker and SGX.
It needs to be enabled and *STAY* enabled for these features to be
mitigated against GDS.

The mitigation is enabled in the microcode by default. Disable it by
setting gather_data_sampling=off or by disabling all mitigations with
mitigations=off. The mitigation status can be checked by reading:

    /sys/devices/system/cpu/vulnerabilities/gather_data_sampling

	Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
	Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
	Acked-by: Josh Poimboeuf <jpoimboe@kernel.org>
(cherry picked from commit 8974eb588283b7d44a7c91fa09fcbaf380339f3a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/ABI/testing/sysfs-devices-system-cpu
#	Documentation/admin-guide/hw-vuln/index.rst
#	Documentation/admin-guide/kernel-parameters.txt
#	arch/x86/include/asm/cpufeatures.h
#	arch/x86/include/asm/msr-index.h
#	arch/x86/kernel/cpu/bugs.c
#	arch/x86/kernel/cpu/common.c
#	drivers/base/cpu.c
diff --cc Documentation/ABI/testing/sysfs-devices-system-cpu
index 43347f9d1455,77942eedf4f6..000000000000
--- a/Documentation/ABI/testing/sysfs-devices-system-cpu
+++ b/Documentation/ABI/testing/sysfs-devices-system-cpu
@@@ -270,17 -484,47 +270,24 @@@ Description:	POWERNV CPUFreq driver's f
  		the /sys/devices/system/cpu/cpuX/cpufreq/throttle_stats directory and
  		attributes which give the frequency throttle information of the chip.
  
 -What:		/sys/devices/system/cpu/cpuX/regs/
 -		/sys/devices/system/cpu/cpuX/regs/identification/
 -		/sys/devices/system/cpu/cpuX/regs/identification/midr_el1
 -		/sys/devices/system/cpu/cpuX/regs/identification/revidr_el1
 -		/sys/devices/system/cpu/cpuX/regs/identification/smidr_el1
 -Date:		June 2016
 -Contact:	Linux ARM Kernel Mailing list <linux-arm-kernel@lists.infradead.org>
 -Description:	AArch64 CPU registers
 -
 -		'identification' directory exposes the CPU ID registers for
 -		identifying model and revision of the CPU and SMCU.
 -
 -What:		/sys/devices/system/cpu/aarch32_el0
 -Date:		May 2021
 -Contact:	Linux ARM Kernel Mailing list <linux-arm-kernel@lists.infradead.org>
 -Description:	Identifies the subset of CPUs in the system that can execute
 -		AArch32 (32-bit ARM) applications. If present, the same format as
 -		/sys/devices/system/cpu/{offline,online,possible,present} is used.
 -		If absent, then all or none of the CPUs can execute AArch32
 -		applications and execve() will behave accordingly.
 -
 -What:		/sys/devices/system/cpu/cpuX/cpu_capacity
 -Date:		December 2016
 -Contact:	Linux kernel mailing list <linux-kernel@vger.kernel.org>
 -Description:	information about CPUs heterogeneity.
 -
 -		cpu_capacity: capacity of cpuX.
 -
  What:		/sys/devices/system/cpu/vulnerabilities
- 		/sys/devices/system/cpu/vulnerabilities/meltdown
- 		/sys/devices/system/cpu/vulnerabilities/spectre_v1
- 		/sys/devices/system/cpu/vulnerabilities/spectre_v2
- 		/sys/devices/system/cpu/vulnerabilities/spec_store_bypass
+ 		/sys/devices/system/cpu/vulnerabilities/gather_data_sampling
+ 		/sys/devices/system/cpu/vulnerabilities/itlb_multihit
  		/sys/devices/system/cpu/vulnerabilities/l1tf
  		/sys/devices/system/cpu/vulnerabilities/mds
++<<<<<<< HEAD
 +		/sys/devices/system/cpu/vulnerabilities/srbds
 +		/sys/devices/system/cpu/vulnerabilities/tsx_async_abort
++=======
+ 		/sys/devices/system/cpu/vulnerabilities/meltdown
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
  		/sys/devices/system/cpu/vulnerabilities/mmio_stale_data
  		/sys/devices/system/cpu/vulnerabilities/retbleed
+ 		/sys/devices/system/cpu/vulnerabilities/spec_store_bypass
+ 		/sys/devices/system/cpu/vulnerabilities/spectre_v1
+ 		/sys/devices/system/cpu/vulnerabilities/spectre_v2
+ 		/sys/devices/system/cpu/vulnerabilities/srbds
+ 		/sys/devices/system/cpu/vulnerabilities/tsx_async_abort
  Date:		January 2018
  Contact:	Linux kernel mailing list <linux-kernel@vger.kernel.org>
  Description:	Information about CPU vulnerabilities
diff --cc Documentation/admin-guide/hw-vuln/index.rst
index 2adec1e6520a,436fac0bd9c3..000000000000
--- a/Documentation/admin-guide/hw-vuln/index.rst
+++ b/Documentation/admin-guide/hw-vuln/index.rst
@@@ -15,4 -15,8 +15,9 @@@ are configurable at compile, boot or ru
     tsx_async_abort
     multihit.rst
     special-register-buffer-data-sampling.rst
 -   core-scheduling.rst
 -   l1d_flush.rst
     processor_mmio_stale_data.rst
++<<<<<<< HEAD
++=======
+    cross-thread-rsb.rst
+    gather_data_sampling.rst
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
diff --cc arch/x86/include/asm/cpufeatures.h
index b7d733af58f4,8d6b34726033..000000000000
--- a/arch/x86/include/asm/cpufeatures.h
+++ b/arch/x86/include/asm/cpufeatures.h
@@@ -378,6 -479,10 +378,14 @@@
  #define X86_BUG_ITLB_MULTIHIT		X86_BUG(23) /* CPU may incur MCE during certain page attribute changes */
  #define X86_BUG_SRBDS			X86_BUG(24) /* CPU may leak RNG bits if not mitigated */
  #define X86_BUG_MMIO_STALE_DATA		X86_BUG(25) /* CPU is affected by Processor MMIO Stale Data vulnerabilities */
++<<<<<<< HEAD
 +#define X86_BUG_RETBLEED		X86_BUG(26) /* CPU is affected by RETBleed */
++=======
+ #define X86_BUG_MMIO_UNKNOWN		X86_BUG(26) /* CPU is too old and its MMIO Stale Data status is unknown */
+ #define X86_BUG_RETBLEED		X86_BUG(27) /* CPU is affected by RETBleed */
+ #define X86_BUG_EIBRS_PBRSB		X86_BUG(28) /* EIBRS is vulnerable to Post Barrier RSB Predictions */
+ #define X86_BUG_SMT_RSB			X86_BUG(29) /* CPU is vulnerable to Cross-Thread Return Address Predictions */
+ #define X86_BUG_GDS			X86_BUG(30) /* CPU is affected by Gather Data Sampling */
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
  
  #endif /* _ASM_X86_CPUFEATURES_H */
diff --cc arch/x86/include/asm/msr-index.h
index 7b8e27a3789e,348f3da8b0f6..000000000000
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@@ -130,6 -151,24 +130,27 @@@
  						 * are restricted to targets in
  						 * kernel.
  						 */
++<<<<<<< HEAD
++=======
+ #define ARCH_CAP_PBRSB_NO		BIT(24)	/*
+ 						 * Not susceptible to Post-Barrier
+ 						 * Return Stack Buffer Predictions.
+ 						 */
+ #define ARCH_CAP_GDS_CTRL		BIT(25)	/*
+ 						 * CPU is vulnerable to Gather
+ 						 * Data Sampling (GDS) and
+ 						 * has controls for mitigation.
+ 						 */
+ #define ARCH_CAP_GDS_NO			BIT(26)	/*
+ 						 * CPU is not vulnerable to Gather
+ 						 * Data Sampling (GDS).
+ 						 */
+ 
+ #define ARCH_CAP_XAPIC_DISABLE		BIT(21)	/*
+ 						 * IA32_XAPIC_DISABLE_STATUS MSR
+ 						 * supported
+ 						 */
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
  
  #define MSR_IA32_FLUSH_CMD		0x0000010b
  #define L1D_FLUSH			BIT(0)	/*
@@@ -144,10 -183,12 +165,18 @@@
  #define TSX_CTRL_RTM_DISABLE		BIT(0)	/* Disable RTM feature */
  #define TSX_CTRL_CPUID_CLEAR		BIT(1)	/* Disable TSX enumeration */
  
 +/* SRBDS support */
  #define MSR_IA32_MCU_OPT_CTRL		0x00000123
++<<<<<<< HEAD
 +#define RNGDS_MITG_DIS			BIT(0)
 +#define FB_CLEAR_DIS			BIT(3)  /* CPU Fill buffer clear disable */
++=======
+ #define RNGDS_MITG_DIS			BIT(0)	/* SRBDS support */
+ #define RTM_ALLOW			BIT(1)	/* TSX development mode */
+ #define FB_CLEAR_DIS			BIT(3)	/* CPU Fill buffer clear disable */
+ #define GDS_MITG_DIS			BIT(4)	/* Disable GDS mitigation */
+ #define GDS_MITG_LOCKED			BIT(5)	/* GDS mitigation locked */
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
  
  #define MSR_IA32_SYSENTER_CS		0x00000174
  #define MSR_IA32_SYSENTER_ESP		0x00000175
diff --cc arch/x86/kernel/cpu/bugs.c
index 7d3e938e7b6b,7824b101ddfe..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -43,8 -46,16 +43,13 @@@ static void __init md_clear_select_miti
  static void __init taa_select_mitigation(void);
  static void __init mmio_select_mitigation(void);
  static void __init srbds_select_mitigation(void);
++<<<<<<< HEAD
++=======
+ static void __init l1d_flush_select_mitigation(void);
+ static void __init gds_select_mitigation(void);
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
  
 -/* The base value of the SPEC_CTRL MSR without task-specific bits set */
 -u64 x86_spec_ctrl_base;
 -EXPORT_SYMBOL_GPL(x86_spec_ctrl_base);
 -
 -/* The current value of the SPEC_CTRL MSR with task-specific bits set */
 -DEFINE_PER_CPU(u64, x86_spec_ctrl_current);
 -EXPORT_SYMBOL_GPL(x86_spec_ctrl_current);
 +extern void spec_ctrl_save_msr(void);
  
  static DEFINE_MUTEX(spec_ctrl_mutex);
  
@@@ -94,46 -160,53 +99,52 @@@ void __init check_bugs(void
  	l1tf_select_mitigation();
  	md_clear_select_mitigation();
  	srbds_select_mitigation();
++<<<<<<< HEAD
++=======
+ 	l1d_flush_select_mitigation();
+ 	gds_select_mitigation();
+ }
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
  
 -/*
 - * NOTE: This function is *only* called for SVM, since Intel uses
 - * MSR_IA32_SPEC_CTRL for SSBD.
 - */
 -void
 -x86_virt_spec_ctrl(u64 guest_virt_spec_ctrl, bool setguest)
 -{
 -	u64 guestval, hostval;
 -	struct thread_info *ti = current_thread_info();
 +	arch_smt_update();
  
 +#ifdef CONFIG_X86_32
  	/*
 -	 * If SSBD is not handled in MSR_SPEC_CTRL on AMD, update
 -	 * MSR_AMD64_L2_CFG or MSR_VIRT_SPEC_CTRL if supported.
 +	 * Check whether we are able to run this kernel safely on SMP.
 +	 *
 +	 * - i386 is no longer supported.
 +	 * - In order to run on anything without a TSC, we need to be
 +	 *   compiled for a i486.
  	 */
 -	if (!static_cpu_has(X86_FEATURE_LS_CFG_SSBD) &&
 -	    !static_cpu_has(X86_FEATURE_VIRT_SSBD))
 -		return;
 +	if (boot_cpu_data.x86 < 4)
 +		panic("Kernel requires i486+ for 'invlpg' and other features");
 +
 +	init_utsname()->machine[1] =
 +		'0' + (boot_cpu_data.x86 > 6 ? 6 : boot_cpu_data.x86);
 +	alternative_instructions();
  
  	/*
 -	 * If the host has SSBD mitigation enabled, force it in the host's
 -	 * virtual MSR value. If its not permanently enabled, evaluate
 -	 * current's TIF_SSBD thread flag.
 +	 * kernel_fpu_begin/end() in check_fpu() relies on the patched
 +	 * alternative instructions.
  	 */
 -	if (static_cpu_has(X86_FEATURE_SPEC_STORE_BYPASS_DISABLE))
 -		hostval = SPEC_CTRL_SSBD;
 -	else
 -		hostval = ssbd_tif_to_spec_ctrl(ti->flags);
 +	check_fpu();
 +#else /* CONFIG_X86_64 */
 +	alternative_instructions();
  
 -	/* Sanitize the guest value */
 -	guestval = guest_virt_spec_ctrl & SPEC_CTRL_SSBD;
 -
 -	if (hostval != guestval) {
 -		unsigned long tif;
 -
 -		tif = setguest ? ssbd_spec_ctrl_to_tif(guestval) :
 -				 ssbd_spec_ctrl_to_tif(hostval);
 -
 -		speculation_ctrl_update(tif);
 -	}
 +	/*
 +	 * Make sure the first 2MB area is not mapped by huge pages
 +	 * There are typically fixed size MTRRs in there and overlapping
 +	 * MTRRs into large pages causes slow downs.
 +	 *
 +	 * Right now we don't do that with gbpages because there seems
 +	 * very little benefit for that case.
 +	 */
 +	if (!direct_gbpages)
 +		set_memory_4k((unsigned long)__va(0), 1);
 +#endif
  }
 -EXPORT_SYMBOL_GPL(x86_virt_spec_ctrl);
  
 -static void x86_amd_ssb_disable(void)
 +void x86_amd_ssbd_enable(void)
  {
  	u64 msrval = x86_amd_ls_cfg_base | x86_amd_ls_cfg_ssbd_mask;
  
@@@ -567,6 -620,148 +578,151 @@@ static int __init srbds_parse_cmdline(c
  early_param("srbds", srbds_parse_cmdline);
  
  #undef pr_fmt
++<<<<<<< HEAD
++=======
+ #define pr_fmt(fmt)     "L1D Flush : " fmt
+ 
+ enum l1d_flush_mitigations {
+ 	L1D_FLUSH_OFF = 0,
+ 	L1D_FLUSH_ON,
+ };
+ 
+ static enum l1d_flush_mitigations l1d_flush_mitigation __initdata = L1D_FLUSH_OFF;
+ 
+ static void __init l1d_flush_select_mitigation(void)
+ {
+ 	if (!l1d_flush_mitigation || !boot_cpu_has(X86_FEATURE_FLUSH_L1D))
+ 		return;
+ 
+ 	static_branch_enable(&switch_mm_cond_l1d_flush);
+ 	pr_info("Conditional flush on switch_mm() enabled\n");
+ }
+ 
+ static int __init l1d_flush_parse_cmdline(char *str)
+ {
+ 	if (!strcmp(str, "on"))
+ 		l1d_flush_mitigation = L1D_FLUSH_ON;
+ 
+ 	return 0;
+ }
+ early_param("l1d_flush", l1d_flush_parse_cmdline);
+ 
+ #undef pr_fmt
+ #define pr_fmt(fmt)	"GDS: " fmt
+ 
+ enum gds_mitigations {
+ 	GDS_MITIGATION_OFF,
+ 	GDS_MITIGATION_UCODE_NEEDED,
+ 	GDS_MITIGATION_FULL,
+ 	GDS_MITIGATION_FULL_LOCKED,
+ 	GDS_MITIGATION_HYPERVISOR,
+ };
+ 
+ static enum gds_mitigations gds_mitigation __ro_after_init = GDS_MITIGATION_FULL;
+ 
+ static const char * const gds_strings[] = {
+ 	[GDS_MITIGATION_OFF]		= "Vulnerable",
+ 	[GDS_MITIGATION_UCODE_NEEDED]	= "Vulnerable: No microcode",
+ 	[GDS_MITIGATION_FULL]		= "Mitigation: Microcode",
+ 	[GDS_MITIGATION_FULL_LOCKED]	= "Mitigation: Microcode (locked)",
+ 	[GDS_MITIGATION_HYPERVISOR]	= "Unknown: Dependent on hypervisor status",
+ };
+ 
+ void update_gds_msr(void)
+ {
+ 	u64 mcu_ctrl_after;
+ 	u64 mcu_ctrl;
+ 
+ 	switch (gds_mitigation) {
+ 	case GDS_MITIGATION_OFF:
+ 		rdmsrl(MSR_IA32_MCU_OPT_CTRL, mcu_ctrl);
+ 		mcu_ctrl |= GDS_MITG_DIS;
+ 		break;
+ 	case GDS_MITIGATION_FULL_LOCKED:
+ 		/*
+ 		 * The LOCKED state comes from the boot CPU. APs might not have
+ 		 * the same state. Make sure the mitigation is enabled on all
+ 		 * CPUs.
+ 		 */
+ 	case GDS_MITIGATION_FULL:
+ 		rdmsrl(MSR_IA32_MCU_OPT_CTRL, mcu_ctrl);
+ 		mcu_ctrl &= ~GDS_MITG_DIS;
+ 		break;
+ 	case GDS_MITIGATION_UCODE_NEEDED:
+ 	case GDS_MITIGATION_HYPERVISOR:
+ 		return;
+ 	};
+ 
+ 	wrmsrl(MSR_IA32_MCU_OPT_CTRL, mcu_ctrl);
+ 
+ 	/*
+ 	 * Check to make sure that the WRMSR value was not ignored. Writes to
+ 	 * GDS_MITG_DIS will be ignored if this processor is locked but the boot
+ 	 * processor was not.
+ 	 */
+ 	rdmsrl(MSR_IA32_MCU_OPT_CTRL, mcu_ctrl_after);
+ 	WARN_ON_ONCE(mcu_ctrl != mcu_ctrl_after);
+ }
+ 
+ static void __init gds_select_mitigation(void)
+ {
+ 	u64 mcu_ctrl;
+ 
+ 	if (!boot_cpu_has_bug(X86_BUG_GDS))
+ 		return;
+ 
+ 	if (boot_cpu_has(X86_FEATURE_HYPERVISOR)) {
+ 		gds_mitigation = GDS_MITIGATION_HYPERVISOR;
+ 		goto out;
+ 	}
+ 
+ 	if (cpu_mitigations_off())
+ 		gds_mitigation = GDS_MITIGATION_OFF;
+ 	/* Will verify below that mitigation _can_ be disabled */
+ 
+ 	/* No microcode */
+ 	if (!(x86_read_arch_cap_msr() & ARCH_CAP_GDS_CTRL)) {
+ 		gds_mitigation = GDS_MITIGATION_UCODE_NEEDED;
+ 		goto out;
+ 	}
+ 
+ 	rdmsrl(MSR_IA32_MCU_OPT_CTRL, mcu_ctrl);
+ 	if (mcu_ctrl & GDS_MITG_LOCKED) {
+ 		if (gds_mitigation == GDS_MITIGATION_OFF)
+ 			pr_warn("Mitigation locked. Disable failed.\n");
+ 
+ 		/*
+ 		 * The mitigation is selected from the boot CPU. All other CPUs
+ 		 * _should_ have the same state. If the boot CPU isn't locked
+ 		 * but others are then update_gds_msr() will WARN() of the state
+ 		 * mismatch. If the boot CPU is locked update_gds_msr() will
+ 		 * ensure the other CPUs have the mitigation enabled.
+ 		 */
+ 		gds_mitigation = GDS_MITIGATION_FULL_LOCKED;
+ 	}
+ 
+ 	update_gds_msr();
+ out:
+ 	pr_info("%s\n", gds_strings[gds_mitigation]);
+ }
+ 
+ static int __init gds_parse_cmdline(char *str)
+ {
+ 	if (!str)
+ 		return -EINVAL;
+ 
+ 	if (!boot_cpu_has_bug(X86_BUG_GDS))
+ 		return 0;
+ 
+ 	if (!strcmp(str, "off"))
+ 		gds_mitigation = GDS_MITIGATION_OFF;
+ 
+ 	return 0;
+ }
+ early_param("gather_data_sampling", gds_parse_cmdline);
+ 
+ #undef pr_fmt
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
  #define pr_fmt(fmt)     "Spectre V1 : " fmt
  
  enum spectre_v1_mitigation {
@@@ -1658,25 -2482,32 +1814,30 @@@ static ssize_t srbds_show_state(char *b
  
  static ssize_t retbleed_show_state(char *buf)
  {
 -	if (retbleed_mitigation == RETBLEED_MITIGATION_UNRET ||
 -	    retbleed_mitigation == RETBLEED_MITIGATION_IBPB) {
 -		if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD &&
 -		    boot_cpu_data.x86_vendor != X86_VENDOR_HYGON)
 -			return sysfs_emit(buf, "Vulnerable: untrained return thunk / IBPB on non-AMD based uarch\n");
 -
 -		return sysfs_emit(buf, "%s; SMT %s\n", retbleed_strings[retbleed_mitigation],
 -				  !sched_smt_active() ? "disabled" :
 -				  spectre_v2_user_stibp == SPECTRE_V2_USER_STRICT ||
 -				  spectre_v2_user_stibp == SPECTRE_V2_USER_STRICT_PREFERRED ?
 -				  "enabled with STIBP protection" : "vulnerable");
 +	if (retbleed_mitigation == RETBLEED_MITIGATION_UNRET) {
 +	    if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD)
 +		    return sprintf(buf, "Vulnerable: untrained return thunk on non-Zen uarch\n");
 +
 +	    return sprintf(buf, "%s; SMT %s\n",
 +			   retbleed_strings[retbleed_mitigation],
 +			   !sched_smt_active() ? "disabled" :
 +			   (x86_spec_ctrl_base & SPEC_CTRL_STIBP) ?
 +			   "enabled with STIBP protection" : "vulnerable");
  	}
  
 -	return sysfs_emit(buf, "%s\n", retbleed_strings[retbleed_mitigation]);
 +	return sprintf(buf, "%s\n", retbleed_strings[retbleed_mitigation]);
  }
  
+ static ssize_t gds_show_state(char *buf)
+ {
+ 	return sysfs_emit(buf, "%s\n", gds_strings[gds_mitigation]);
+ }
+ 
  static ssize_t cpu_show_common(struct device *dev, struct device_attribute *attr,
 -			       char *buf, unsigned int bug)
 +			char *buf, unsigned int bug)
  {
  	if (!boot_cpu_has_bug(bug))
 -		return sysfs_emit(buf, "Not affected\n");
 +		return sprintf(buf, "Not affected\n");
  
  	switch (bug) {
  	case X86_BUG_CPU_MELTDOWN:
diff --cc arch/x86/kernel/cpu/common.c
index b3f97ecffd56,53224fe3ca6f..000000000000
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@@ -1036,27 -1248,40 +1036,57 @@@ static const __initconst struct x86_cpu
  #define MMIO_SBDS	BIT(2)
  /* CPU is affected by RETbleed, speculating where you would not expect it */
  #define RETBLEED	BIT(3)
++<<<<<<< HEAD
++=======
+ /* CPU is affected by SMT (cross-thread) return predictions */
+ #define SMT_RSB		BIT(4)
+ /* CPU is affected by GDS */
+ #define GDS		BIT(5)
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
  
  static const struct x86_cpu_id cpu_vuln_blacklist[] __initconst = {
  	VULNBL_INTEL_STEPPINGS(IVYBRIDGE,	X86_STEPPING_ANY,		SRBDS),
 -	VULNBL_INTEL_STEPPINGS(HASWELL,		X86_STEPPING_ANY,		SRBDS),
 -	VULNBL_INTEL_STEPPINGS(HASWELL_L,	X86_STEPPING_ANY,		SRBDS),
 -	VULNBL_INTEL_STEPPINGS(HASWELL_G,	X86_STEPPING_ANY,		SRBDS),
 +	VULNBL_INTEL_STEPPINGS(HASWELL_CORE,	X86_STEPPING_ANY,		SRBDS),
 +	VULNBL_INTEL_STEPPINGS(HASWELL_ULT,	X86_STEPPING_ANY,		SRBDS),
 +	VULNBL_INTEL_STEPPINGS(HASWELL_GT3E,	X86_STEPPING_ANY,		SRBDS),
  	VULNBL_INTEL_STEPPINGS(HASWELL_X,	X86_STEPPING_ANY,		MMIO),
 -	VULNBL_INTEL_STEPPINGS(BROADWELL_D,	X86_STEPPING_ANY,		MMIO),
 -	VULNBL_INTEL_STEPPINGS(BROADWELL_G,	X86_STEPPING_ANY,		SRBDS),
 +	VULNBL_INTEL_STEPPINGS(BROADWELL_XEON_D, X86_STEPPING_ANY,		MMIO),
 +	VULNBL_INTEL_STEPPINGS(BROADWELL_GT3E,	X86_STEPPING_ANY,		SRBDS),
  	VULNBL_INTEL_STEPPINGS(BROADWELL_X,	X86_STEPPING_ANY,		MMIO),
++<<<<<<< HEAD
 +	VULNBL_INTEL_STEPPINGS(BROADWELL_CORE,	X86_STEPPING_ANY,		SRBDS),
 +	VULNBL_INTEL_STEPPINGS(SKYLAKE_MOBILE,	X86_STEPPING_ANY,		SRBDS | MMIO | RETBLEED),
 +	VULNBL_INTEL_STEPPINGS(SKYLAKE_X,	X86_STEPPING_ANY,		MMIO | RETBLEED),
 +	VULNBL_INTEL_STEPPINGS(SKYLAKE_DESKTOP, X86_STEPPING_ANY,		SRBDS | MMIO | RETBLEED),
 +	VULNBL_INTEL_STEPPINGS(KABYLAKE_MOBILE, X86_STEPPING_ANY,		SRBDS | MMIO | RETBLEED),
 +	VULNBL_INTEL_STEPPINGS(KABYLAKE_DESKTOP, X86_STEPPING_ANY,		SRBDS | MMIO | RETBLEED),
 +	VULNBL_INTEL_STEPPINGS(CANNONLAKE_MOBILE, X86_STEPPING_ANY,		RETBLEED),
 +	VULNBL_INTEL_STEPPINGS(ICELAKE_MOBILE,	X86_STEPPING_ANY,		MMIO | MMIO_SBDS | RETBLEED),
 +	VULNBL_INTEL_STEPPINGS(ICELAKE_DESKTOP,	X86_STEPPING_ANY,		MMIO),
 +	VULNBL_INTEL_STEPPINGS(ICELAKE_X,	X86_STEPPING_ANY,		MMIO),
 +	VULNBL_INTEL_STEPPINGS(ATOM_TREMONT_X,	X86_STEPPING_ANY,		MMIO),
++=======
+ 	VULNBL_INTEL_STEPPINGS(BROADWELL,	X86_STEPPING_ANY,		SRBDS),
+ 	VULNBL_INTEL_STEPPINGS(SKYLAKE_L,	X86_STEPPING_ANY,		SRBDS | MMIO | RETBLEED),
+ 	VULNBL_INTEL_STEPPINGS(SKYLAKE_X,	X86_STEPPING_ANY,		MMIO | RETBLEED | GDS),
+ 	VULNBL_INTEL_STEPPINGS(SKYLAKE,		X86_STEPPING_ANY,		SRBDS | MMIO | RETBLEED),
+ 	VULNBL_INTEL_STEPPINGS(KABYLAKE_L,	X86_STEPPING_ANY,		SRBDS | MMIO | RETBLEED | GDS),
+ 	VULNBL_INTEL_STEPPINGS(KABYLAKE,	X86_STEPPING_ANY,		SRBDS | MMIO | RETBLEED | GDS),
+ 	VULNBL_INTEL_STEPPINGS(CANNONLAKE_L,	X86_STEPPING_ANY,		RETBLEED),
+ 	VULNBL_INTEL_STEPPINGS(ICELAKE_L,	X86_STEPPING_ANY,		MMIO | MMIO_SBDS | RETBLEED | GDS),
+ 	VULNBL_INTEL_STEPPINGS(ICELAKE_D,	X86_STEPPING_ANY,		MMIO | GDS),
+ 	VULNBL_INTEL_STEPPINGS(ICELAKE_X,	X86_STEPPING_ANY,		MMIO | GDS),
+ 	VULNBL_INTEL_STEPPINGS(COMETLAKE,	X86_STEPPING_ANY,		MMIO | MMIO_SBDS | RETBLEED | GDS),
+ 	VULNBL_INTEL_STEPPINGS(COMETLAKE_L,	X86_STEPPINGS(0x0, 0x0),	MMIO | RETBLEED),
+ 	VULNBL_INTEL_STEPPINGS(COMETLAKE_L,	X86_STEPPING_ANY,		MMIO | MMIO_SBDS | RETBLEED | GDS),
+ 	VULNBL_INTEL_STEPPINGS(TIGERLAKE_L,	X86_STEPPING_ANY,		GDS),
+ 	VULNBL_INTEL_STEPPINGS(TIGERLAKE,	X86_STEPPING_ANY,		GDS),
+ 	VULNBL_INTEL_STEPPINGS(LAKEFIELD,	X86_STEPPING_ANY,		MMIO | MMIO_SBDS | RETBLEED),
+ 	VULNBL_INTEL_STEPPINGS(ROCKETLAKE,	X86_STEPPING_ANY,		MMIO | RETBLEED | GDS),
+ 	VULNBL_INTEL_STEPPINGS(ATOM_TREMONT,	X86_STEPPING_ANY,		MMIO | MMIO_SBDS),
+ 	VULNBL_INTEL_STEPPINGS(ATOM_TREMONT_D,	X86_STEPPING_ANY,		MMIO),
+ 	VULNBL_INTEL_STEPPINGS(ATOM_TREMONT_L,	X86_STEPPING_ANY,		MMIO | MMIO_SBDS),
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
  
  	VULNBL_AMD(0x15, RETBLEED),
  	VULNBL_AMD(0x16, RETBLEED),
@@@ -1166,6 -1407,19 +1196,22 @@@ static void __init cpu_set_bug_bits(str
  			setup_force_cpu_bug(X86_BUG_RETBLEED);
  	}
  
++<<<<<<< HEAD
++=======
+ 	if (cpu_matches(cpu_vuln_blacklist, SMT_RSB))
+ 		setup_force_cpu_bug(X86_BUG_SMT_RSB);
+ 
+ 	/*
+ 	 * Check if CPU is vulnerable to GDS. If running in a virtual machine on
+ 	 * an affected processor, the VMM may have disabled the use of GATHER by
+ 	 * disabling AVX2. The only way to do this in HW is to clear XCR0[2],
+ 	 * which means that AVX will be disabled.
+ 	 */
+ 	if (cpu_matches(cpu_vuln_blacklist, GDS) && !(ia32_cap & ARCH_CAP_GDS_NO) &&
+ 	    boot_cpu_has(X86_FEATURE_AVX))
+ 		setup_force_cpu_bug(X86_BUG_GDS);
+ 
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
  	if (cpu_matches(cpu_vuln_whitelist, NO_MELTDOWN))
  		return;
  
@@@ -1526,63 -1973,14 +1572,70 @@@ void identify_secondary_cpu(struct cpui
  #ifdef CONFIG_X86_32
  	enable_sep_cpu();
  #endif
 +	mtrr_ap_init();
  	validate_apic_and_package_id(c);
 -	x86_spec_ctrl_setup_ap();
  	update_srbds_msr();
++<<<<<<< HEAD
++=======
+ 	if (boot_cpu_has_bug(X86_BUG_GDS))
+ 		update_gds_msr();
+ 
+ 	tsx_ap_init();
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
 +}
 +
 +struct msr_range {
 +	unsigned	min;
 +	unsigned	max;
 +};
 +
 +static const struct msr_range msr_range_array[] = {
 +	{ 0x00000000, 0x00000418},
 +	{ 0xc0000000, 0xc000040b},
 +	{ 0xc0010000, 0xc0010142},
 +	{ 0xc0011000, 0xc001103b},
 +};
 +
 +static void __print_cpu_msr(void)
 +{
 +	unsigned index_min, index_max;
 +	unsigned index;
 +	u64 val;
 +	int i;
 +
 +	for (i = 0; i < ARRAY_SIZE(msr_range_array); i++) {
 +		index_min = msr_range_array[i].min;
 +		index_max = msr_range_array[i].max;
 +
 +		for (index = index_min; index < index_max; index++) {
 +			if (rdmsrl_safe(index, &val))
 +				continue;
 +			printk(KERN_INFO " MSR%08x: %016llx\n", index, val);
 +		}
 +	}
 +}
 +
 +static int show_msr;
 +
 +static __init int setup_show_msr(char *arg)
 +{
 +	int num;
 +
 +	get_option(&arg, &num);
 +
 +	if (num > 0)
 +		show_msr = num;
 +	return 1;
  }
 +__setup("show_msr=", setup_show_msr);
 +
 +static __init int setup_noclflush(char *arg)
 +{
 +	setup_clear_cpu_cap(X86_FEATURE_CLFLUSH);
 +	setup_clear_cpu_cap(X86_FEATURE_CLFLUSHOPT);
 +	return 1;
 +}
 +__setup("noclflush", setup_noclflush);
  
  void print_cpu_info(struct cpuinfo_x86 *c)
  {
diff --cc drivers/base/cpu.c
index 96f519275438,0469c09e8a8c..000000000000
--- a/drivers/base/cpu.c
+++ b/drivers/base/cpu.c
@@@ -460,20 -574,27 +460,41 @@@ ssize_t __weak cpu_show_mmio_stale_data
  ssize_t __weak cpu_show_retbleed(struct device *dev,
  				 struct device_attribute *attr, char *buf)
  {
 -	return sysfs_emit(buf, "Not affected\n");
 -}
 -
 +	return sprintf(buf, "Not affected\n");
 +}
 +
++<<<<<<< HEAD
 +static DEVICE_ATTR(meltdown, 0400, cpu_show_meltdown, NULL);
 +static DEVICE_ATTR(spectre_v1, 0400, cpu_show_spectre_v1, NULL);
 +static DEVICE_ATTR(spectre_v2, 0400, cpu_show_spectre_v2, NULL);
 +static DEVICE_ATTR(spec_store_bypass, 0400, cpu_show_spec_store_bypass, NULL);
 +static DEVICE_ATTR(l1tf, 0400, cpu_show_l1tf, NULL);
 +static DEVICE_ATTR(mds, 0400, cpu_show_mds, NULL);
 +static DEVICE_ATTR(tsx_async_abort, 0400, cpu_show_tsx_async_abort, NULL);
 +static DEVICE_ATTR(itlb_multihit, 0400, cpu_show_itlb_multihit, NULL);
 +static DEVICE_ATTR(srbds, 0400, cpu_show_srbds, NULL);
 +static DEVICE_ATTR(mmio_stale_data, 0400, cpu_show_mmio_stale_data, NULL);
 +static DEVICE_ATTR(retbleed, 0400, cpu_show_retbleed, NULL);
++=======
+ ssize_t __weak cpu_show_gds(struct device *dev,
+ 			    struct device_attribute *attr, char *buf)
+ {
+ 	return sysfs_emit(buf, "Not affected\n");
+ }
+ 
+ static DEVICE_ATTR(meltdown, 0444, cpu_show_meltdown, NULL);
+ static DEVICE_ATTR(spectre_v1, 0444, cpu_show_spectre_v1, NULL);
+ static DEVICE_ATTR(spectre_v2, 0444, cpu_show_spectre_v2, NULL);
+ static DEVICE_ATTR(spec_store_bypass, 0444, cpu_show_spec_store_bypass, NULL);
+ static DEVICE_ATTR(l1tf, 0444, cpu_show_l1tf, NULL);
+ static DEVICE_ATTR(mds, 0444, cpu_show_mds, NULL);
+ static DEVICE_ATTR(tsx_async_abort, 0444, cpu_show_tsx_async_abort, NULL);
+ static DEVICE_ATTR(itlb_multihit, 0444, cpu_show_itlb_multihit, NULL);
+ static DEVICE_ATTR(srbds, 0444, cpu_show_srbds, NULL);
+ static DEVICE_ATTR(mmio_stale_data, 0444, cpu_show_mmio_stale_data, NULL);
+ static DEVICE_ATTR(retbleed, 0444, cpu_show_retbleed, NULL);
+ static DEVICE_ATTR(gather_data_sampling, 0444, cpu_show_gds, NULL);
++>>>>>>> 8974eb588283 (x86/speculation: Add Gather Data Sampling mitigation)
  
  static struct attribute *cpu_root_vulnerabilities_attrs[] = {
  	&dev_attr_meltdown.attr,
* Unmerged path Documentation/admin-guide/kernel-parameters.txt
* Unmerged path Documentation/ABI/testing/sysfs-devices-system-cpu
diff --git a/Documentation/admin-guide/hw-vuln/gather_data_sampling.rst b/Documentation/admin-guide/hw-vuln/gather_data_sampling.rst
new file mode 100644
index 000000000000..74dab6af7fe1
--- /dev/null
+++ b/Documentation/admin-guide/hw-vuln/gather_data_sampling.rst
@@ -0,0 +1,99 @@
+.. SPDX-License-Identifier: GPL-2.0
+
+GDS - Gather Data Sampling
+==========================
+
+Gather Data Sampling is a hardware vulnerability which allows unprivileged
+speculative access to data which was previously stored in vector registers.
+
+Problem
+-------
+When a gather instruction performs loads from memory, different data elements
+are merged into the destination vector register. However, when a gather
+instruction that is transiently executed encounters a fault, stale data from
+architectural or internal vector registers may get transiently forwarded to the
+destination vector register instead. This will allow a malicious attacker to
+infer stale data using typical side channel techniques like cache timing
+attacks. GDS is a purely sampling-based attack.
+
+The attacker uses gather instructions to infer the stale vector register data.
+The victim does not need to do anything special other than use the vector
+registers. The victim does not need to use gather instructions to be
+vulnerable.
+
+Because the buffers are shared between Hyper-Threads cross Hyper-Thread attacks
+are possible.
+
+Attack scenarios
+----------------
+Without mitigation, GDS can infer stale data across virtually all
+permission boundaries:
+
+	Non-enclaves can infer SGX enclave data
+	Userspace can infer kernel data
+	Guests can infer data from hosts
+	Guest can infer guest from other guests
+	Users can infer data from other users
+
+Because of this, it is important to ensure that the mitigation stays enabled in
+lower-privilege contexts like guests and when running outside SGX enclaves.
+
+The hardware enforces the mitigation for SGX. Likewise, VMMs should  ensure
+that guests are not allowed to disable the GDS mitigation. If a host erred and
+allowed this, a guest could theoretically disable GDS mitigation, mount an
+attack, and re-enable it.
+
+Mitigation mechanism
+--------------------
+This issue is mitigated in microcode. The microcode defines the following new
+bits:
+
+ ================================   ===   ============================
+ IA32_ARCH_CAPABILITIES[GDS_CTRL]   R/O   Enumerates GDS vulnerability
+                                          and mitigation support.
+ IA32_ARCH_CAPABILITIES[GDS_NO]     R/O   Processor is not vulnerable.
+ IA32_MCU_OPT_CTRL[GDS_MITG_DIS]    R/W   Disables the mitigation
+                                          0 by default.
+ IA32_MCU_OPT_CTRL[GDS_MITG_LOCK]   R/W   Locks GDS_MITG_DIS=0. Writes
+                                          to GDS_MITG_DIS are ignored
+                                          Can't be cleared once set.
+ ================================   ===   ============================
+
+GDS can also be mitigated on systems that don't have updated microcode by
+disabling AVX. This can be done by setting "clearcpuid=avx" on the kernel
+command-line.
+
+Mitigation control on the kernel command line
+---------------------------------------------
+The mitigation can be disabled by setting "gather_data_sampling=off" or
+"mitigations=off" on the kernel command line. Not specifying either will
+default to the mitigation being enabled.
+
+GDS System Information
+------------------------
+The kernel provides vulnerability status information through sysfs. For
+GDS this can be accessed by the following sysfs file:
+
+/sys/devices/system/cpu/vulnerabilities/gather_data_sampling
+
+The possible values contained in this file are:
+
+ ============================== =============================================
+ Not affected                   Processor not vulnerable.
+ Vulnerable                     Processor vulnerable and mitigation disabled.
+ Vulnerable: No microcode       Processor vulnerable and microcode is missing
+                                mitigation.
+ Mitigation: Microcode          Processor is vulnerable and mitigation is in
+                                effect.
+ Mitigation: Microcode (locked) Processor is vulnerable and mitigation is in
+                                effect and cannot be disabled.
+ Unknown: Dependent on
+ hypervisor status              Running on a virtual guest processor that is
+                                affected but with no way to know if host
+                                processor is mitigated or vulnerable.
+ ============================== =============================================
+
+GDS Default mitigation
+----------------------
+The updated microcode will enable the mitigation by default. The kernel's
+default action is to leave the mitigation enabled.
* Unmerged path Documentation/admin-guide/hw-vuln/index.rst
* Unmerged path Documentation/admin-guide/kernel-parameters.txt
* Unmerged path arch/x86/include/asm/cpufeatures.h
* Unmerged path arch/x86/include/asm/msr-index.h
* Unmerged path arch/x86/kernel/cpu/bugs.c
* Unmerged path arch/x86/kernel/cpu/common.c
diff --git a/arch/x86/kernel/cpu/cpu.h b/arch/x86/kernel/cpu/cpu.h
index 920081d4dfc9..9d5713a93592 100644
--- a/arch/x86/kernel/cpu/cpu.h
+++ b/arch/x86/kernel/cpu/cpu.h
@@ -63,6 +63,7 @@ extern int detect_extended_topology_early(struct cpuinfo_x86 *c);
 extern int detect_ht_early(struct cpuinfo_x86 *c);
 
 extern void update_srbds_msr(void);
+extern void update_gds_msr(void);
 
 extern u64 x86_read_arch_cap_msr(void);
 #endif /* ARCH_X86_CPU_H */
* Unmerged path drivers/base/cpu.c
