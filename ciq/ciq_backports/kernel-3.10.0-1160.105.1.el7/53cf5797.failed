x86/speculation: Add Kconfig option for GDS

jira LE-1907
cve CVE-2022-40982
Rebuild_History Non-Buildable kernel-3.10.0-1160.105.1.el7
commit-author Daniel Sneddon <daniel.sneddon@linux.intel.com>
commit 53cf5797f114ba2bd86d23a862302119848eff19
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.105.1.el7/53cf5797.failed

Gather Data Sampling (GDS) is mitigated in microcode. However, on
systems that haven't received the updated microcode, disabling AVX
can act as a mitigation. Add a Kconfig option that uses the microcode
mitigation if available and disables AVX otherwise. Setting this
option has no effect on systems not affected by GDS. This is the
equivalent of setting gather_data_sampling=force.

	Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
	Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
	Acked-by: Josh Poimboeuf <jpoimboe@kernel.org>
(cherry picked from commit 53cf5797f114ba2bd86d23a862302119848eff19)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/Kconfig
#	arch/x86/kernel/cpu/bugs.c
diff --cc arch/x86/Kconfig
index f3698f265557,36d3f61c4ed9..000000000000
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@@ -2249,29 -2449,187 +2249,207 @@@ source "kernel/livepatch/Kconfig
  
  endmenu
  
++<<<<<<< HEAD
++=======
+ config CC_HAS_SLS
+ 	def_bool $(cc-option,-mharden-sls=all)
+ 
+ config CC_HAS_RETURN_THUNK
+ 	def_bool $(cc-option,-mfunction-return=thunk-extern)
+ 
+ config CC_HAS_ENTRY_PADDING
+ 	def_bool $(cc-option,-fpatchable-function-entry=16,16)
+ 
+ config FUNCTION_PADDING_CFI
+ 	int
+ 	default 59 if FUNCTION_ALIGNMENT_64B
+ 	default 27 if FUNCTION_ALIGNMENT_32B
+ 	default 11 if FUNCTION_ALIGNMENT_16B
+ 	default  3 if FUNCTION_ALIGNMENT_8B
+ 	default  0
+ 
+ # Basically: FUNCTION_ALIGNMENT - 5*CFI_CLANG
+ # except Kconfig can't do arithmetic :/
+ config FUNCTION_PADDING_BYTES
+ 	int
+ 	default FUNCTION_PADDING_CFI if CFI_CLANG
+ 	default FUNCTION_ALIGNMENT
+ 
+ config CALL_PADDING
+ 	def_bool n
+ 	depends on CC_HAS_ENTRY_PADDING && OBJTOOL
+ 	select FUNCTION_ALIGNMENT_16B
+ 
+ config FINEIBT
+ 	def_bool y
+ 	depends on X86_KERNEL_IBT && CFI_CLANG && RETPOLINE
+ 	select CALL_PADDING
+ 
+ config HAVE_CALL_THUNKS
+ 	def_bool y
+ 	depends on CC_HAS_ENTRY_PADDING && RETHUNK && OBJTOOL
+ 
+ config CALL_THUNKS
+ 	def_bool n
+ 	select CALL_PADDING
+ 
+ config PREFIX_SYMBOLS
+ 	def_bool y
+ 	depends on CALL_PADDING && !CFI_CLANG
+ 
+ menuconfig SPECULATION_MITIGATIONS
+ 	bool "Mitigations for speculative execution vulnerabilities"
+ 	default y
+ 	help
+ 	  Say Y here to enable options which enable mitigations for
+ 	  speculative execution hardware vulnerabilities.
+ 
+ 	  If you say N, all mitigations will be disabled. You really
+ 	  should know what you are doing to say so.
+ 
+ if SPECULATION_MITIGATIONS
+ 
+ config PAGE_TABLE_ISOLATION
+ 	bool "Remove the kernel mapping in user mode"
+ 	default y
+ 	depends on (X86_64 || X86_PAE)
+ 	help
+ 	  This feature reduces the number of hardware side channels by
+ 	  ensuring that the majority of kernel addresses are not mapped
+ 	  into userspace.
+ 
+ 	  See Documentation/arch/x86/pti.rst for more details.
+ 
+ config RETPOLINE
+ 	bool "Avoid speculative indirect branches in kernel"
+ 	select OBJTOOL if HAVE_OBJTOOL
+ 	default y
+ 	help
+ 	  Compile kernel with the retpoline compiler options to guard against
+ 	  kernel-to-user data leaks by avoiding speculative indirect
+ 	  branches. Requires a compiler with -mindirect-branch=thunk-extern
+ 	  support for full protection. The kernel may run slower.
+ 
+ config RETHUNK
+ 	bool "Enable return-thunks"
+ 	depends on RETPOLINE && CC_HAS_RETURN_THUNK
+ 	select OBJTOOL if HAVE_OBJTOOL
+ 	default y if X86_64
+ 	help
+ 	  Compile the kernel with the return-thunks compiler option to guard
+ 	  against kernel-to-user data leaks by avoiding return speculation.
+ 	  Requires a compiler with -mfunction-return=thunk-extern
+ 	  support for full protection. The kernel may run slower.
+ 
+ config CPU_UNRET_ENTRY
+ 	bool "Enable UNRET on kernel entry"
+ 	depends on CPU_SUP_AMD && RETHUNK && X86_64
+ 	default y
+ 	help
+ 	  Compile the kernel with support for the retbleed=unret mitigation.
+ 
+ config CALL_DEPTH_TRACKING
+ 	bool "Mitigate RSB underflow with call depth tracking"
+ 	depends on CPU_SUP_INTEL && HAVE_CALL_THUNKS
+ 	select HAVE_DYNAMIC_FTRACE_NO_PATCHABLE
+ 	select CALL_THUNKS
+ 	default y
+ 	help
+ 	  Compile the kernel with call depth tracking to mitigate the Intel
+ 	  SKL Return-Speculation-Buffer (RSB) underflow issue. The
+ 	  mitigation is off by default and needs to be enabled on the
+ 	  kernel command line via the retbleed=stuff option. For
+ 	  non-affected systems the overhead of this option is marginal as
+ 	  the call depth tracking is using run-time generated call thunks
+ 	  in a compiler generated padding area and call patching. This
+ 	  increases text size by ~5%. For non affected systems this space
+ 	  is unused. On affected SKL systems this results in a significant
+ 	  performance gain over the IBRS mitigation.
+ 
+ config CALL_THUNKS_DEBUG
+ 	bool "Enable call thunks and call depth tracking debugging"
+ 	depends on CALL_DEPTH_TRACKING
+ 	select FUNCTION_ALIGNMENT_32B
+ 	default n
+ 	help
+ 	  Enable call/ret counters for imbalance detection and build in
+ 	  a noisy dmesg about callthunks generation and call patching for
+ 	  trouble shooting. The debug prints need to be enabled on the
+ 	  kernel command line with 'debug-callthunks'.
+ 	  Only enable this when you are debugging call thunks as this
+ 	  creates a noticeable runtime overhead. If unsure say N.
+ 
+ config CPU_IBPB_ENTRY
+ 	bool "Enable IBPB on kernel entry"
+ 	depends on CPU_SUP_AMD && X86_64
+ 	default y
+ 	help
+ 	  Compile the kernel with support for the retbleed=ibpb mitigation.
+ 
+ config CPU_IBRS_ENTRY
+ 	bool "Enable IBRS on kernel entry"
+ 	depends on CPU_SUP_INTEL && X86_64
+ 	default y
+ 	help
+ 	  Compile the kernel with support for the spectre_v2=ibrs mitigation.
+ 	  This mitigates both spectre_v2 and retbleed at great cost to
+ 	  performance.
+ 
+ config SLS
+ 	bool "Mitigate Straight-Line-Speculation"
+ 	depends on CC_HAS_SLS && X86_64
+ 	select OBJTOOL if HAVE_OBJTOOL
+ 	default n
+ 	help
+ 	  Compile the kernel with straight-line-speculation options to guard
+ 	  against straight line speculation. The kernel image might be slightly
+ 	  larger.
+ 
+ config GDS_FORCE_MITIGATION
+ 	bool "Force GDS Mitigation"
+ 	depends on CPU_SUP_INTEL
+ 	default n
+ 	help
+ 	  Gather Data Sampling (GDS) is a hardware vulnerability which allows
+ 	  unprivileged speculative access to data which was previously stored in
+ 	  vector registers.
+ 
+ 	  This option is equivalent to setting gather_data_sampling=force on the
+ 	  command line. The microcode mitigation is used if present, otherwise
+ 	  AVX is disabled as a mitigation. On affected systems that are missing
+ 	  the microcode any userspace code that unconditionally uses AVX will
+ 	  break with this option set.
+ 
+ 	  Setting this option on systems not vulnerable to GDS has no effect.
+ 
+ 	  If in doubt, say N.
+ 
+ endif
+ 
++>>>>>>> 53cf5797f114 (x86/speculation: Add Kconfig option for GDS)
  config ARCH_HAS_ADD_PAGES
  	def_bool y
 -	depends on ARCH_ENABLE_MEMORY_HOTPLUG
 +	depends on X86_64 && ARCH_ENABLE_MEMORY_HOTPLUG
 +
 +config ARCH_ENABLE_MEMORY_HOTPLUG
 +	def_bool y
 +	depends on X86_64 || (X86_32 && HIGHMEM)
 +
 +config ARCH_ENABLE_MEMORY_HOTREMOVE
 +	def_bool y
 +	depends on MEMORY_HOTPLUG
 +
 +config USE_PERCPU_NUMA_NODE_ID
 +	def_bool y
 +	depends on NUMA
  
 -config ARCH_MHP_MEMMAP_ON_MEMORY_ENABLE
 +config ARCH_ENABLE_SPLIT_PMD_PTLOCK
  	def_bool y
 +	depends on X86_64 || X86_PAE
 +
 +config ARCH_ENABLE_HUGEPAGE_MIGRATION
 +	def_bool y
 +	depends on X86_64 && HUGETLB_PAGE && MIGRATION
  
  menu "Power management and ACPI options"
  
diff --cc arch/x86/kernel/cpu/bugs.c
index 7d3e938e7b6b,41821a4551a2..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -567,6 -620,170 +567,173 @@@ static int __init srbds_parse_cmdline(c
  early_param("srbds", srbds_parse_cmdline);
  
  #undef pr_fmt
++<<<<<<< HEAD
++=======
+ #define pr_fmt(fmt)     "L1D Flush : " fmt
+ 
+ enum l1d_flush_mitigations {
+ 	L1D_FLUSH_OFF = 0,
+ 	L1D_FLUSH_ON,
+ };
+ 
+ static enum l1d_flush_mitigations l1d_flush_mitigation __initdata = L1D_FLUSH_OFF;
+ 
+ static void __init l1d_flush_select_mitigation(void)
+ {
+ 	if (!l1d_flush_mitigation || !boot_cpu_has(X86_FEATURE_FLUSH_L1D))
+ 		return;
+ 
+ 	static_branch_enable(&switch_mm_cond_l1d_flush);
+ 	pr_info("Conditional flush on switch_mm() enabled\n");
+ }
+ 
+ static int __init l1d_flush_parse_cmdline(char *str)
+ {
+ 	if (!strcmp(str, "on"))
+ 		l1d_flush_mitigation = L1D_FLUSH_ON;
+ 
+ 	return 0;
+ }
+ early_param("l1d_flush", l1d_flush_parse_cmdline);
+ 
+ #undef pr_fmt
+ #define pr_fmt(fmt)	"GDS: " fmt
+ 
+ enum gds_mitigations {
+ 	GDS_MITIGATION_OFF,
+ 	GDS_MITIGATION_UCODE_NEEDED,
+ 	GDS_MITIGATION_FORCE,
+ 	GDS_MITIGATION_FULL,
+ 	GDS_MITIGATION_FULL_LOCKED,
+ 	GDS_MITIGATION_HYPERVISOR,
+ };
+ 
+ #if IS_ENABLED(CONFIG_GDS_FORCE_MITIGATION)
+ static enum gds_mitigations gds_mitigation __ro_after_init = GDS_MITIGATION_FORCE;
+ #else
+ static enum gds_mitigations gds_mitigation __ro_after_init = GDS_MITIGATION_FULL;
+ #endif
+ 
+ static const char * const gds_strings[] = {
+ 	[GDS_MITIGATION_OFF]		= "Vulnerable",
+ 	[GDS_MITIGATION_UCODE_NEEDED]	= "Vulnerable: No microcode",
+ 	[GDS_MITIGATION_FORCE]		= "Mitigation: AVX disabled, no microcode",
+ 	[GDS_MITIGATION_FULL]		= "Mitigation: Microcode",
+ 	[GDS_MITIGATION_FULL_LOCKED]	= "Mitigation: Microcode (locked)",
+ 	[GDS_MITIGATION_HYPERVISOR]	= "Unknown: Dependent on hypervisor status",
+ };
+ 
+ void update_gds_msr(void)
+ {
+ 	u64 mcu_ctrl_after;
+ 	u64 mcu_ctrl;
+ 
+ 	switch (gds_mitigation) {
+ 	case GDS_MITIGATION_OFF:
+ 		rdmsrl(MSR_IA32_MCU_OPT_CTRL, mcu_ctrl);
+ 		mcu_ctrl |= GDS_MITG_DIS;
+ 		break;
+ 	case GDS_MITIGATION_FULL_LOCKED:
+ 		/*
+ 		 * The LOCKED state comes from the boot CPU. APs might not have
+ 		 * the same state. Make sure the mitigation is enabled on all
+ 		 * CPUs.
+ 		 */
+ 	case GDS_MITIGATION_FULL:
+ 		rdmsrl(MSR_IA32_MCU_OPT_CTRL, mcu_ctrl);
+ 		mcu_ctrl &= ~GDS_MITG_DIS;
+ 		break;
+ 	case GDS_MITIGATION_FORCE:
+ 	case GDS_MITIGATION_UCODE_NEEDED:
+ 	case GDS_MITIGATION_HYPERVISOR:
+ 		return;
+ 	};
+ 
+ 	wrmsrl(MSR_IA32_MCU_OPT_CTRL, mcu_ctrl);
+ 
+ 	/*
+ 	 * Check to make sure that the WRMSR value was not ignored. Writes to
+ 	 * GDS_MITG_DIS will be ignored if this processor is locked but the boot
+ 	 * processor was not.
+ 	 */
+ 	rdmsrl(MSR_IA32_MCU_OPT_CTRL, mcu_ctrl_after);
+ 	WARN_ON_ONCE(mcu_ctrl != mcu_ctrl_after);
+ }
+ 
+ static void __init gds_select_mitigation(void)
+ {
+ 	u64 mcu_ctrl;
+ 
+ 	if (!boot_cpu_has_bug(X86_BUG_GDS))
+ 		return;
+ 
+ 	if (boot_cpu_has(X86_FEATURE_HYPERVISOR)) {
+ 		gds_mitigation = GDS_MITIGATION_HYPERVISOR;
+ 		goto out;
+ 	}
+ 
+ 	if (cpu_mitigations_off())
+ 		gds_mitigation = GDS_MITIGATION_OFF;
+ 	/* Will verify below that mitigation _can_ be disabled */
+ 
+ 	/* No microcode */
+ 	if (!(x86_read_arch_cap_msr() & ARCH_CAP_GDS_CTRL)) {
+ 		if (gds_mitigation == GDS_MITIGATION_FORCE) {
+ 			/*
+ 			 * This only needs to be done on the boot CPU so do it
+ 			 * here rather than in update_gds_msr()
+ 			 */
+ 			setup_clear_cpu_cap(X86_FEATURE_AVX);
+ 			pr_warn("Microcode update needed! Disabling AVX as mitigation.\n");
+ 		} else {
+ 			gds_mitigation = GDS_MITIGATION_UCODE_NEEDED;
+ 		}
+ 		goto out;
+ 	}
+ 
+ 	/* Microcode has mitigation, use it */
+ 	if (gds_mitigation == GDS_MITIGATION_FORCE)
+ 		gds_mitigation = GDS_MITIGATION_FULL;
+ 
+ 	rdmsrl(MSR_IA32_MCU_OPT_CTRL, mcu_ctrl);
+ 	if (mcu_ctrl & GDS_MITG_LOCKED) {
+ 		if (gds_mitigation == GDS_MITIGATION_OFF)
+ 			pr_warn("Mitigation locked. Disable failed.\n");
+ 
+ 		/*
+ 		 * The mitigation is selected from the boot CPU. All other CPUs
+ 		 * _should_ have the same state. If the boot CPU isn't locked
+ 		 * but others are then update_gds_msr() will WARN() of the state
+ 		 * mismatch. If the boot CPU is locked update_gds_msr() will
+ 		 * ensure the other CPUs have the mitigation enabled.
+ 		 */
+ 		gds_mitigation = GDS_MITIGATION_FULL_LOCKED;
+ 	}
+ 
+ 	update_gds_msr();
+ out:
+ 	pr_info("%s\n", gds_strings[gds_mitigation]);
+ }
+ 
+ static int __init gds_parse_cmdline(char *str)
+ {
+ 	if (!str)
+ 		return -EINVAL;
+ 
+ 	if (!boot_cpu_has_bug(X86_BUG_GDS))
+ 		return 0;
+ 
+ 	if (!strcmp(str, "off"))
+ 		gds_mitigation = GDS_MITIGATION_OFF;
+ 	else if (!strcmp(str, "force"))
+ 		gds_mitigation = GDS_MITIGATION_FORCE;
+ 
+ 	return 0;
+ }
+ early_param("gather_data_sampling", gds_parse_cmdline);
+ 
+ #undef pr_fmt
++>>>>>>> 53cf5797f114 (x86/speculation: Add Kconfig option for GDS)
  #define pr_fmt(fmt)     "Spectre V1 : " fmt
  
  enum spectre_v1_mitigation {
* Unmerged path arch/x86/Kconfig
* Unmerged path arch/x86/kernel/cpu/bugs.c
