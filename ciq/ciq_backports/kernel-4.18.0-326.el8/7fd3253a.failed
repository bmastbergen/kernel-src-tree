net: Introduce preferred busy-polling

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Björn Töpel <bjorn.topel@intel.com>
commit 7fd3253a7de6a317a0683f83739479fb880bffc8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/7fd3253a.failed

The existing busy-polling mode, enabled by the SO_BUSY_POLL socket
option or system-wide using the /proc/sys/net/core/busy_read knob, is
an opportunistic. That means that if the NAPI context is not
scheduled, it will poll it. If, after busy-polling, the budget is
exceeded the busy-polling logic will schedule the NAPI onto the
regular softirq handling.

One implication of the behavior above is that a busy/heavy loaded NAPI
context will never enter/allow for busy-polling. Some applications
prefer that most NAPI processing would be done by busy-polling.

This series adds a new socket option, SO_PREFER_BUSY_POLL, that works
in concert with the napi_defer_hard_irqs and gro_flush_timeout
knobs. The napi_defer_hard_irqs and gro_flush_timeout knobs were
introduced in commit 6f8b12d661d0 ("net: napi: add hard irqs deferral
feature"), and allows for a user to defer interrupts to be enabled and
instead schedule the NAPI context from a watchdog timer. When a user
enables the SO_PREFER_BUSY_POLL, again with the other knobs enabled,
and the NAPI context is being processed by a softirq, the softirq NAPI
processing will exit early to allow the busy-polling to be performed.

If the application stops performing busy-polling via a system call,
the watchdog timer defined by gro_flush_timeout will timeout, and
regular softirq handling will resume.

In summary; Heavy traffic applications that prefer busy-polling over
softirq processing should use this option.

Example usage:

  $ echo 2 | sudo tee /sys/class/net/ens785f1/napi_defer_hard_irqs
  $ echo 200000 | sudo tee /sys/class/net/ens785f1/gro_flush_timeout

Note that the timeout should be larger than the userspace processing
window, otherwise the watchdog will timeout and fall back to regular
softirq processing.

Enable the SO_BUSY_POLL/SO_PREFER_BUSY_POLL options on your socket.

	Signed-off-by: Björn Töpel <bjorn.topel@intel.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Reviewed-by: Jakub Kicinski <kuba@kernel.org>
Link: https://lore.kernel.org/bpf/20201130185205.196029-2-bjorn.topel@gmail.com
(cherry picked from commit 7fd3253a7de6a317a0683f83739479fb880bffc8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/alpha/include/uapi/asm/socket.h
#	arch/mips/include/uapi/asm/socket.h
#	arch/parisc/include/uapi/asm/socket.h
#	arch/sparc/include/uapi/asm/socket.h
#	include/uapi/asm-generic/socket.h
#	net/core/dev.c
diff --cc arch/alpha/include/uapi/asm/socket.h
index 065fb372e355,538359642554..000000000000
--- a/arch/alpha/include/uapi/asm/socket.h
+++ b/arch/alpha/include/uapi/asm/socket.h
@@@ -115,4 -109,45 +115,48 @@@
  #define SO_TXTIME		61
  #define SCM_TXTIME		SO_TXTIME
  
++<<<<<<< HEAD
++=======
+ #define SO_BINDTOIFINDEX	62
+ 
+ #define SO_TIMESTAMP_OLD        29
+ #define SO_TIMESTAMPNS_OLD      35
+ #define SO_TIMESTAMPING_OLD     37
+ 
+ #define SO_TIMESTAMP_NEW        63
+ #define SO_TIMESTAMPNS_NEW      64
+ #define SO_TIMESTAMPING_NEW     65
+ 
+ #define SO_RCVTIMEO_NEW         66
+ #define SO_SNDTIMEO_NEW         67
+ 
+ #define SO_DETACH_REUSEPORT_BPF 68
+ 
+ #define SO_PREFER_BUSY_POLL	69
+ 
+ #if !defined(__KERNEL__)
+ 
+ #if __BITS_PER_LONG == 64
+ #define SO_TIMESTAMP		SO_TIMESTAMP_OLD
+ #define SO_TIMESTAMPNS		SO_TIMESTAMPNS_OLD
+ #define SO_TIMESTAMPING         SO_TIMESTAMPING_OLD
+ 
+ #define SO_RCVTIMEO		SO_RCVTIMEO_OLD
+ #define SO_SNDTIMEO		SO_SNDTIMEO_OLD
+ #else
+ #define SO_TIMESTAMP (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMP_OLD : SO_TIMESTAMP_NEW)
+ #define SO_TIMESTAMPNS (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMPNS_OLD : SO_TIMESTAMPNS_NEW)
+ #define SO_TIMESTAMPING (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMPING_OLD : SO_TIMESTAMPING_NEW)
+ 
+ #define SO_RCVTIMEO (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_RCVTIMEO_OLD : SO_RCVTIMEO_NEW)
+ #define SO_SNDTIMEO (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_SNDTIMEO_OLD : SO_SNDTIMEO_NEW)
+ #endif
+ 
+ #define SCM_TIMESTAMP           SO_TIMESTAMP
+ #define SCM_TIMESTAMPNS         SO_TIMESTAMPNS
+ #define SCM_TIMESTAMPING        SO_TIMESTAMPING
+ 
+ #endif
+ 
++>>>>>>> 7fd3253a7de6 (net: Introduce preferred busy-polling)
  #endif /* _UAPI_ASM_SOCKET_H */
diff --cc arch/mips/include/uapi/asm/socket.h
index 71370fb3ceef,e406e73b5e6e..000000000000
--- a/arch/mips/include/uapi/asm/socket.h
+++ b/arch/mips/include/uapi/asm/socket.h
@@@ -126,4 -120,45 +126,48 @@@
  #define SO_TXTIME		61
  #define SCM_TXTIME		SO_TXTIME
  
++<<<<<<< HEAD
++=======
+ #define SO_BINDTOIFINDEX	62
+ 
+ #define SO_TIMESTAMP_OLD        29
+ #define SO_TIMESTAMPNS_OLD      35
+ #define SO_TIMESTAMPING_OLD     37
+ 
+ #define SO_TIMESTAMP_NEW        63
+ #define SO_TIMESTAMPNS_NEW      64
+ #define SO_TIMESTAMPING_NEW     65
+ 
+ #define SO_RCVTIMEO_NEW         66
+ #define SO_SNDTIMEO_NEW         67
+ 
+ #define SO_DETACH_REUSEPORT_BPF 68
+ 
+ #define SO_PREFER_BUSY_POLL	69
+ 
+ #if !defined(__KERNEL__)
+ 
+ #if __BITS_PER_LONG == 64
+ #define SO_TIMESTAMP		SO_TIMESTAMP_OLD
+ #define SO_TIMESTAMPNS		SO_TIMESTAMPNS_OLD
+ #define SO_TIMESTAMPING		SO_TIMESTAMPING_OLD
+ 
+ #define SO_RCVTIMEO             SO_RCVTIMEO_OLD
+ #define SO_SNDTIMEO             SO_SNDTIMEO_OLD
+ #else
+ #define SO_TIMESTAMP (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMP_OLD : SO_TIMESTAMP_NEW)
+ #define SO_TIMESTAMPNS (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMPNS_OLD : SO_TIMESTAMPNS_NEW)
+ #define SO_TIMESTAMPING (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMPING_OLD : SO_TIMESTAMPING_NEW)
+ 
+ #define SO_RCVTIMEO (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_RCVTIMEO_OLD : SO_RCVTIMEO_NEW)
+ #define SO_SNDTIMEO (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_SNDTIMEO_OLD : SO_SNDTIMEO_NEW)
+ #endif
+ 
+ #define SCM_TIMESTAMP           SO_TIMESTAMP
+ #define SCM_TIMESTAMPNS         SO_TIMESTAMPNS
+ #define SCM_TIMESTAMPING        SO_TIMESTAMPING
+ 
+ #endif
+ 
++>>>>>>> 7fd3253a7de6 (net: Introduce preferred busy-polling)
  #endif /* _UAPI_ASM_SOCKET_H */
diff --cc arch/parisc/include/uapi/asm/socket.h
index 061b9cf2a779,1bc46200889d..000000000000
--- a/arch/parisc/include/uapi/asm/socket.h
+++ b/arch/parisc/include/uapi/asm/socket.h
@@@ -107,4 -101,44 +107,47 @@@
  #define SO_TXTIME		0x4036
  #define SCM_TXTIME		SO_TXTIME
  
++<<<<<<< HEAD
++=======
+ #define SO_BINDTOIFINDEX	0x4037
+ 
+ #define SO_TIMESTAMP_OLD        0x4012
+ #define SO_TIMESTAMPNS_OLD      0x4013
+ #define SO_TIMESTAMPING_OLD     0x4020
+ 
+ #define SO_TIMESTAMP_NEW        0x4038
+ #define SO_TIMESTAMPNS_NEW      0x4039
+ #define SO_TIMESTAMPING_NEW     0x403A
+ 
+ #define SO_RCVTIMEO_NEW         0x4040
+ #define SO_SNDTIMEO_NEW         0x4041
+ 
+ #define SO_DETACH_REUSEPORT_BPF 0x4042
+ 
+ #define SO_PREFER_BUSY_POLL	0x4043
+ 
+ #if !defined(__KERNEL__)
+ 
+ #if __BITS_PER_LONG == 64
+ #define SO_TIMESTAMP		SO_TIMESTAMP_OLD
+ #define SO_TIMESTAMPNS		SO_TIMESTAMPNS_OLD
+ #define SO_TIMESTAMPING         SO_TIMESTAMPING_OLD
+ #define SO_RCVTIMEO		SO_RCVTIMEO_OLD
+ #define SO_SNDTIMEO		SO_SNDTIMEO_OLD
+ #else
+ #define SO_TIMESTAMP (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMP_OLD : SO_TIMESTAMP_NEW)
+ #define SO_TIMESTAMPNS (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMPNS_OLD : SO_TIMESTAMPNS_NEW)
+ #define SO_TIMESTAMPING (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMPING_OLD : SO_TIMESTAMPING_NEW)
+ 
+ #define SO_RCVTIMEO (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_RCVTIMEO_OLD : SO_RCVTIMEO_NEW)
+ #define SO_SNDTIMEO (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_SNDTIMEO_OLD : SO_SNDTIMEO_NEW)
+ #endif
+ 
+ #define SCM_TIMESTAMP           SO_TIMESTAMP
+ #define SCM_TIMESTAMPNS         SO_TIMESTAMPNS
+ #define SCM_TIMESTAMPING        SO_TIMESTAMPING
+ 
+ #endif
+ 
++>>>>>>> 7fd3253a7de6 (net: Introduce preferred busy-polling)
  #endif /* _UAPI_ASM_SOCKET_H */
diff --cc arch/sparc/include/uapi/asm/socket.h
index 7ea35e5601b6,99688cf673a4..000000000000
--- a/arch/sparc/include/uapi/asm/socket.h
+++ b/arch/sparc/include/uapi/asm/socket.h
@@@ -109,4 -104,44 +109,47 @@@
  #define SO_SECURITY_ENCRYPTION_TRANSPORT	0x5002
  #define SO_SECURITY_ENCRYPTION_NETWORK		0x5004
  
++<<<<<<< HEAD
++=======
+ #define SO_TIMESTAMP_OLD         0x001d
+ #define SO_TIMESTAMPNS_OLD       0x0021
+ #define SO_TIMESTAMPING_OLD      0x0023
+ 
+ #define SO_TIMESTAMP_NEW         0x0046
+ #define SO_TIMESTAMPNS_NEW       0x0042
+ #define SO_TIMESTAMPING_NEW      0x0043
+ 
+ #define SO_RCVTIMEO_NEW          0x0044
+ #define SO_SNDTIMEO_NEW          0x0045
+ 
+ #define SO_DETACH_REUSEPORT_BPF  0x0047
+ 
+ #define SO_PREFER_BUSY_POLL	 0x0048
+ 
+ #if !defined(__KERNEL__)
+ 
+ 
+ #if __BITS_PER_LONG == 64
+ #define SO_TIMESTAMP		SO_TIMESTAMP_OLD
+ #define SO_TIMESTAMPNS		SO_TIMESTAMPNS_OLD
+ #define SO_TIMESTAMPING		SO_TIMESTAMPING_OLD
+ 
+ #define SO_RCVTIMEO		SO_RCVTIMEO_OLD
+ #define SO_SNDTIMEO		SO_SNDTIMEO_OLD
+ #else
+ #define SO_TIMESTAMP (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMP_OLD : SO_TIMESTAMP_NEW)
+ #define SO_TIMESTAMPNS (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMPNS_OLD : SO_TIMESTAMPNS_NEW)
+ #define SO_TIMESTAMPING (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMPING_OLD : SO_TIMESTAMPING_NEW)
+ 
+ #define SO_RCVTIMEO (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_RCVTIMEO_OLD : SO_RCVTIMEO_NEW)
+ #define SO_SNDTIMEO (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_SNDTIMEO_OLD : SO_SNDTIMEO_NEW)
+ #endif
+ 
+ #define SCM_TIMESTAMP          SO_TIMESTAMP
+ #define SCM_TIMESTAMPNS        SO_TIMESTAMPNS
+ #define SCM_TIMESTAMPING       SO_TIMESTAMPING
+ 
+ #endif
+ 
++>>>>>>> 7fd3253a7de6 (net: Introduce preferred busy-polling)
  #endif /* _ASM_SOCKET_H */
diff --cc include/uapi/asm-generic/socket.h
index 044b8966c2ce,7dd02408b7ce..000000000000
--- a/include/uapi/asm-generic/socket.h
+++ b/include/uapi/asm-generic/socket.h
@@@ -112,6 -106,44 +112,36 @@@
  
  #define SO_BINDTOIFINDEX	62
  
 -#define SO_TIMESTAMP_OLD        29
 -#define SO_TIMESTAMPNS_OLD      35
 -#define SO_TIMESTAMPING_OLD     37
 -
 -#define SO_TIMESTAMP_NEW        63
 -#define SO_TIMESTAMPNS_NEW      64
 -#define SO_TIMESTAMPING_NEW     65
 -
 -#define SO_RCVTIMEO_NEW         66
 -#define SO_SNDTIMEO_NEW         67
 -
  #define SO_DETACH_REUSEPORT_BPF 68
  
++<<<<<<< HEAD
++=======
+ #define SO_PREFER_BUSY_POLL	69
+ 
+ #if !defined(__KERNEL__)
+ 
+ #if __BITS_PER_LONG == 64 || (defined(__x86_64__) && defined(__ILP32__))
+ /* on 64-bit and x32, avoid the ?: operator */
+ #define SO_TIMESTAMP		SO_TIMESTAMP_OLD
+ #define SO_TIMESTAMPNS		SO_TIMESTAMPNS_OLD
+ #define SO_TIMESTAMPING		SO_TIMESTAMPING_OLD
+ 
+ #define SO_RCVTIMEO		SO_RCVTIMEO_OLD
+ #define SO_SNDTIMEO		SO_SNDTIMEO_OLD
+ #else
+ #define SO_TIMESTAMP (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMP_OLD : SO_TIMESTAMP_NEW)
+ #define SO_TIMESTAMPNS (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMPNS_OLD : SO_TIMESTAMPNS_NEW)
+ #define SO_TIMESTAMPING (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_TIMESTAMPING_OLD : SO_TIMESTAMPING_NEW)
+ 
+ #define SO_RCVTIMEO (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_RCVTIMEO_OLD : SO_RCVTIMEO_NEW)
+ #define SO_SNDTIMEO (sizeof(time_t) == sizeof(__kernel_long_t) ? SO_SNDTIMEO_OLD : SO_SNDTIMEO_NEW)
+ #endif
+ 
+ #define SCM_TIMESTAMP           SO_TIMESTAMP
+ #define SCM_TIMESTAMPNS         SO_TIMESTAMPNS
+ #define SCM_TIMESTAMPING        SO_TIMESTAMPING
+ 
+ #endif
+ 
++>>>>>>> 7fd3253a7de6 (net: Introduce preferred busy-polling)
  #endif /* __ASM_GENERIC_SOCKET_H */
diff --cc net/core/dev.c
index 1e7b7a3fd02e,6f8d2cffb7c5..000000000000
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@@ -6153,7 -6553,11 +6184,11 @@@ static void busy_poll_stop(struct napi_
  	trace_napi_poll(napi, rc, BUSY_POLL_BUDGET);
  	netpoll_poll_unlock(have_poll_lock);
  	if (rc == BUSY_POLL_BUDGET)
++<<<<<<< HEAD
 +		__napi_schedule(napi);
++=======
+ 		__busy_poll_stop(napi, skip_schedule);
++>>>>>>> 7fd3253a7de6 (net: Introduce preferred busy-polling)
  	local_bh_enable();
  }
  
@@@ -6270,9 -6681,11 +6311,16 @@@ static enum hrtimer_restart napi_watchd
  	/* Note : we use a relaxed variant of napi_schedule_prep() not setting
  	 * NAPI_STATE_MISSED, since we do not react to a device IRQ.
  	 */
++<<<<<<< HEAD
 +	if (!list_empty(&napi->gro_list) && !napi_disable_pending(napi) &&
 +	    !test_and_set_bit(NAPI_STATE_SCHED, &napi->state))
++=======
+ 	if (!napi_disable_pending(napi) &&
+ 	    !test_and_set_bit(NAPI_STATE_SCHED, &napi->state)) {
+ 		clear_bit(NAPI_STATE_PREFER_BUSY_POLL, &napi->state);
++>>>>>>> 7fd3253a7de6 (net: Introduce preferred busy-polling)
  		__napi_schedule_irqoff(napi);
+ 	}
  
  	return HRTIMER_NORESTART;
  }
@@@ -6389,7 -6816,20 +6438,24 @@@ static int napi_poll(struct napi_struc
  		goto out_unlock;
  	}
  
++<<<<<<< HEAD
 +	if (!list_empty(&n->gro_list)) {
++=======
+ 	/* The NAPI context has more processing work, but busy-polling
+ 	 * is preferred. Exit early.
+ 	 */
+ 	if (napi_prefer_busy_poll(n)) {
+ 		if (napi_complete_done(n, work)) {
+ 			/* If timeout is not set, we need to make sure
+ 			 * that the NAPI is re-scheduled.
+ 			 */
+ 			napi_schedule(n);
+ 		}
+ 		goto out_unlock;
+ 	}
+ 
+ 	if (n->gro_bitmask) {
++>>>>>>> 7fd3253a7de6 (net: Introduce preferred busy-polling)
  		/* flush too old packets
  		 * If HZ < 1000, flush all packets.
  		 */
* Unmerged path arch/alpha/include/uapi/asm/socket.h
* Unmerged path arch/mips/include/uapi/asm/socket.h
* Unmerged path arch/parisc/include/uapi/asm/socket.h
* Unmerged path arch/sparc/include/uapi/asm/socket.h
diff --git a/fs/eventpoll.c b/fs/eventpoll.c
index 6b2959020043..06cb64352b29 100644
--- a/fs/eventpoll.c
+++ b/fs/eventpoll.c
@@ -398,7 +398,7 @@ static void ep_busy_loop(struct eventpoll *ep, int nonblock)
 	unsigned int napi_id = READ_ONCE(ep->napi_id);
 
 	if ((napi_id >= MIN_NAPI_ID) && net_busy_loop_on())
-		napi_busy_loop(napi_id, nonblock ? NULL : ep_busy_loop_end, ep);
+		napi_busy_loop(napi_id, nonblock ? NULL : ep_busy_loop_end, ep, false);
 }
 
 static inline void ep_reset_busy_poll_napi_id(struct eventpoll *ep)
diff --git a/include/linux/netdevice.h b/include/linux/netdevice.h
index 23ab5b9a2e64..bd22621960d1 100644
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@ -354,23 +354,25 @@ struct napi_struct {
 };
 
 enum {
-	NAPI_STATE_SCHED,	/* Poll is scheduled */
-	NAPI_STATE_MISSED,	/* reschedule a napi */
-	NAPI_STATE_DISABLE,	/* Disable pending */
-	NAPI_STATE_NPSVC,	/* Netpoll - don't dequeue from poll_list */
-	NAPI_STATE_LISTED,	/* NAPI added to system lists */
-	NAPI_STATE_NO_BUSY_POLL,/* Do not add in napi_hash, no busy polling */
-	NAPI_STATE_IN_BUSY_POLL,/* sk_busy_loop() owns this NAPI */
+	NAPI_STATE_SCHED,		/* Poll is scheduled */
+	NAPI_STATE_MISSED,		/* reschedule a napi */
+	NAPI_STATE_DISABLE,		/* Disable pending */
+	NAPI_STATE_NPSVC,		/* Netpoll - don't dequeue from poll_list */
+	NAPI_STATE_LISTED,		/* NAPI added to system lists */
+	NAPI_STATE_NO_BUSY_POLL,	/* Do not add in napi_hash, no busy polling */
+	NAPI_STATE_IN_BUSY_POLL,	/* sk_busy_loop() owns this NAPI */
+	NAPI_STATE_PREFER_BUSY_POLL,	/* prefer busy-polling over softirq processing*/
 };
 
 enum {
-	NAPIF_STATE_SCHED	 = BIT(NAPI_STATE_SCHED),
-	NAPIF_STATE_MISSED	 = BIT(NAPI_STATE_MISSED),
-	NAPIF_STATE_DISABLE	 = BIT(NAPI_STATE_DISABLE),
-	NAPIF_STATE_NPSVC	 = BIT(NAPI_STATE_NPSVC),
-	NAPIF_STATE_LISTED	 = BIT(NAPI_STATE_LISTED),
-	NAPIF_STATE_NO_BUSY_POLL = BIT(NAPI_STATE_NO_BUSY_POLL),
-	NAPIF_STATE_IN_BUSY_POLL = BIT(NAPI_STATE_IN_BUSY_POLL),
+	NAPIF_STATE_SCHED		= BIT(NAPI_STATE_SCHED),
+	NAPIF_STATE_MISSED		= BIT(NAPI_STATE_MISSED),
+	NAPIF_STATE_DISABLE		= BIT(NAPI_STATE_DISABLE),
+	NAPIF_STATE_NPSVC		= BIT(NAPI_STATE_NPSVC),
+	NAPIF_STATE_LISTED		= BIT(NAPI_STATE_LISTED),
+	NAPIF_STATE_NO_BUSY_POLL	= BIT(NAPI_STATE_NO_BUSY_POLL),
+	NAPIF_STATE_IN_BUSY_POLL	= BIT(NAPI_STATE_IN_BUSY_POLL),
+	NAPIF_STATE_PREFER_BUSY_POLL	= BIT(NAPI_STATE_PREFER_BUSY_POLL),
 };
 
 enum gro_result {
@@ -441,6 +443,11 @@ static inline bool napi_disable_pending(struct napi_struct *n)
 	return test_bit(NAPI_STATE_DISABLE, &n->state);
 }
 
+static inline bool napi_prefer_busy_poll(struct napi_struct *n)
+{
+	return test_bit(NAPI_STATE_PREFER_BUSY_POLL, &n->state);
+}
+
 bool napi_schedule_prep(struct napi_struct *n);
 
 /**
diff --git a/include/net/busy_poll.h b/include/net/busy_poll.h
index 60f8490ed317..afd8198d46da 100644
--- a/include/net/busy_poll.h
+++ b/include/net/busy_poll.h
@@ -55,7 +55,7 @@ bool sk_busy_loop_end(void *p, unsigned long start_time);
 
 void napi_busy_loop(unsigned int napi_id,
 		    bool (*loop_end)(void *, unsigned long),
-		    void *loop_end_arg);
+		    void *loop_end_arg, bool prefer_busy_poll);
 
 #else /* CONFIG_NET_RX_BUSY_POLL */
 static inline unsigned long net_busy_loop_on(void)
@@ -117,7 +117,8 @@ static inline void sk_busy_loop(struct sock *sk, int nonblock)
 	unsigned int napi_id = READ_ONCE(sk->sk_napi_id);
 
 	if (napi_id >= MIN_NAPI_ID)
-		napi_busy_loop(napi_id, nonblock ? NULL : sk_busy_loop_end, sk);
+		napi_busy_loop(napi_id, nonblock ? NULL : sk_busy_loop_end, sk,
+			       READ_ONCE(sk->sk_prefer_busy_poll));
 #endif
 }
 
diff --git a/include/net/sock.h b/include/net/sock.h
index af8e0faa1fb6..e868dfa300a8 100644
--- a/include/net/sock.h
+++ b/include/net/sock.h
@@ -290,6 +290,7 @@ struct bpf_local_storage;
   *	@sk_ack_backlog: current listen backlog
   *	@sk_max_ack_backlog: listen backlog set in listen()
   *	@sk_uid: user id of owner
+  *	@sk_prefer_busy_poll: prefer busypolling over softirq processing
   *	@sk_priority: %SO_PRIORITY setting
   *	@sk_type: socket type (%SOCK_STREAM, etc)
   *	@sk_protocol: which protocol this socket belongs in this network family
@@ -474,6 +475,9 @@ struct sock {
 	u32			sk_ack_backlog;
 	u32			sk_max_ack_backlog;
 	kuid_t			sk_uid;
+#ifdef CONFIG_NET_RX_BUSY_POLL
+	u8			sk_prefer_busy_poll;
+#endif
 	struct pid		*sk_peer_pid;
 	const struct cred	*sk_peer_cred;
 	long			sk_rcvtimeo;
* Unmerged path include/uapi/asm-generic/socket.h
* Unmerged path net/core/dev.c
diff --git a/net/core/sock.c b/net/core/sock.c
index 72337c8d4eb6..3035b2b735f3 100644
--- a/net/core/sock.c
+++ b/net/core/sock.c
@@ -1147,6 +1147,12 @@ int sock_setsockopt(struct socket *sock, int level, int optname,
 				sk->sk_ll_usec = val;
 		}
 		break;
+	case SO_PREFER_BUSY_POLL:
+		if (valbool && !capable(CAP_NET_ADMIN))
+			ret = -EPERM;
+		else
+			WRITE_ONCE(sk->sk_prefer_busy_poll, valbool);
+		break;
 #endif
 
 	case SO_MAX_PACING_RATE:
@@ -1480,6 +1486,9 @@ int sock_getsockopt(struct socket *sock, int level, int optname,
 	case SO_BUSY_POLL:
 		v.val = sk->sk_ll_usec;
 		break;
+	case SO_PREFER_BUSY_POLL:
+		v.val = READ_ONCE(sk->sk_prefer_busy_poll);
+		break;
 #endif
 
 	case SO_MAX_PACING_RATE:
