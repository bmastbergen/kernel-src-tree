xfs: xfs_iflock is no longer a completion

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Dave Chinner <dchinner@redhat.com>
commit 718ecc50359ec7a45c3195305ab998a46db491dc
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/718ecc50.failed

With the recent rework of the inode cluster flushing, we no longer
ever wait on the the inode flush "lock". It was never a lock in the
first place, just a completion to allow callers to wait for inode IO
to complete. We now never wait for flush completion as all inode
flushing is non-blocking. Hence we can get rid of all the iflock
infrastructure and instead just set and check a state flag.

Rename the XFS_IFLOCK flag to XFS_IFLUSHING, convert all the
xfs_iflock_nowait() test-and-set operations on that flag, and
replace all the xfs_ifunlock() calls to clear operations.

	Signed-off-by: Dave Chinner <dchinner@redhat.com>
	Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
	Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
(cherry picked from commit 718ecc50359ec7a45c3195305ab998a46db491dc)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/xfs_inode.c
#	fs/xfs/xfs_inode_item.c
diff --cc fs/xfs/xfs_inode.c
index 7a257c128813,2072bd25989a..000000000000
--- a/fs/xfs/xfs_inode.c
+++ b/fs/xfs/xfs_inode.c
@@@ -3690,10 -3432,10 +3679,17 @@@ xfs_iflush_int
  	int			error;
  
  	ASSERT(xfs_isilocked(ip, XFS_ILOCK_EXCL|XFS_ILOCK_SHARED));
++<<<<<<< HEAD
 +	ASSERT(xfs_isiflocked(ip));
 +	ASSERT(ip->i_d.di_format != XFS_DINODE_FMT_BTREE ||
 +	       ip->i_d.di_nextents > XFS_IFORK_MAXEXT(ip, XFS_DATA_FORK));
 +	ASSERT(iip != NULL && iip->ili_fields != 0);
++=======
+ 	ASSERT(xfs_iflags_test(ip, XFS_IFLUSHING));
+ 	ASSERT(ip->i_df.if_format != XFS_DINODE_FMT_BTREE ||
+ 	       ip->i_df.if_nextents > XFS_IFORK_MAXEXT(ip, XFS_DATA_FORK));
+ 	ASSERT(iip->ili_item.li_buf == bp);
++>>>>>>> 718ecc50359e (xfs: xfs_iflock is no longer a completion)
  
  	dip = xfs_buf_offset(bp, ip->i_imap.im_boffset);
  
@@@ -3825,6 -3567,121 +3821,124 @@@ flush_out
  	return error;
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * Non-blocking flush of dirty inode metadata into the backing buffer.
+  *
+  * The caller must have a reference to the inode and hold the cluster buffer
+  * locked. The function will walk across all the inodes on the cluster buffer it
+  * can find and lock without blocking, and flush them to the cluster buffer.
+  *
+  * On successful flushing of at least one inode, the caller must write out the
+  * buffer and release it. If no inodes are flushed, -EAGAIN will be returned and
+  * the caller needs to release the buffer. On failure, the filesystem will be
+  * shut down, the buffer will have been unlocked and released, and EFSCORRUPTED
+  * will be returned.
+  */
+ int
+ xfs_iflush_cluster(
+ 	struct xfs_buf		*bp)
+ {
+ 	struct xfs_mount	*mp = bp->b_mount;
+ 	struct xfs_log_item	*lip, *n;
+ 	struct xfs_inode	*ip;
+ 	struct xfs_inode_log_item *iip;
+ 	int			clcount = 0;
+ 	int			error = 0;
+ 
+ 	/*
+ 	 * We must use the safe variant here as on shutdown xfs_iflush_abort()
+ 	 * can remove itself from the list.
+ 	 */
+ 	list_for_each_entry_safe(lip, n, &bp->b_li_list, li_bio_list) {
+ 		iip = (struct xfs_inode_log_item *)lip;
+ 		ip = iip->ili_inode;
+ 
+ 		/*
+ 		 * Quick and dirty check to avoid locks if possible.
+ 		 */
+ 		if (__xfs_iflags_test(ip, XFS_IRECLAIM | XFS_IFLUSHING))
+ 			continue;
+ 		if (xfs_ipincount(ip))
+ 			continue;
+ 
+ 		/*
+ 		 * The inode is still attached to the buffer, which means it is
+ 		 * dirty but reclaim might try to grab it. Check carefully for
+ 		 * that, and grab the ilock while still holding the i_flags_lock
+ 		 * to guarantee reclaim will not be able to reclaim this inode
+ 		 * once we drop the i_flags_lock.
+ 		 */
+ 		spin_lock(&ip->i_flags_lock);
+ 		ASSERT(!__xfs_iflags_test(ip, XFS_ISTALE));
+ 		if (__xfs_iflags_test(ip, XFS_IRECLAIM | XFS_IFLUSHING)) {
+ 			spin_unlock(&ip->i_flags_lock);
+ 			continue;
+ 		}
+ 
+ 		/*
+ 		 * ILOCK will pin the inode against reclaim and prevent
+ 		 * concurrent transactions modifying the inode while we are
+ 		 * flushing the inode. If we get the lock, set the flushing
+ 		 * state before we drop the i_flags_lock.
+ 		 */
+ 		if (!xfs_ilock_nowait(ip, XFS_ILOCK_SHARED)) {
+ 			spin_unlock(&ip->i_flags_lock);
+ 			continue;
+ 		}
+ 		__xfs_iflags_set(ip, XFS_IFLUSHING);
+ 		spin_unlock(&ip->i_flags_lock);
+ 
+ 		/*
+ 		 * Abort flushing this inode if we are shut down because the
+ 		 * inode may not currently be in the AIL. This can occur when
+ 		 * log I/O failure unpins the inode without inserting into the
+ 		 * AIL, leaving a dirty/unpinned inode attached to the buffer
+ 		 * that otherwise looks like it should be flushed.
+ 		 */
+ 		if (XFS_FORCED_SHUTDOWN(mp)) {
+ 			xfs_iunpin_wait(ip);
+ 			xfs_iflush_abort(ip);
+ 			xfs_iunlock(ip, XFS_ILOCK_SHARED);
+ 			error = -EIO;
+ 			continue;
+ 		}
+ 
+ 		/* don't block waiting on a log force to unpin dirty inodes */
+ 		if (xfs_ipincount(ip)) {
+ 			xfs_iflags_clear(ip, XFS_IFLUSHING);
+ 			xfs_iunlock(ip, XFS_ILOCK_SHARED);
+ 			continue;
+ 		}
+ 
+ 		if (!xfs_inode_clean(ip))
+ 			error = xfs_iflush(ip, bp);
+ 		else
+ 			xfs_iflags_clear(ip, XFS_IFLUSHING);
+ 		xfs_iunlock(ip, XFS_ILOCK_SHARED);
+ 		if (error)
+ 			break;
+ 		clcount++;
+ 	}
+ 
+ 	if (error) {
+ 		bp->b_flags |= XBF_ASYNC;
+ 		xfs_buf_ioend_fail(bp);
+ 		xfs_force_shutdown(mp, SHUTDOWN_CORRUPT_INCORE);
+ 		return error;
+ 	}
+ 
+ 	if (!clcount)
+ 		return -EAGAIN;
+ 
+ 	XFS_STATS_INC(mp, xs_icluster_flushcnt);
+ 	XFS_STATS_ADD(mp, xs_icluster_flushinode, clcount);
+ 	return 0;
+ 
+ }
+ 
++>>>>>>> 718ecc50359e (xfs: xfs_iflock is no longer a completion)
  /* Release an inode. */
  void
  xfs_irele(
diff --cc fs/xfs/xfs_inode_item.c
index 6c92fac59bcc,099ae8ee7908..000000000000
--- a/fs/xfs/xfs_inode_item.c
+++ b/fs/xfs/xfs_inode_item.c
@@@ -485,43 -485,28 +485,50 @@@ xfs_inode_item_push
  	uint			rval = XFS_ITEM_SUCCESS;
  	int			error;
  
 -	ASSERT(iip->ili_item.li_buf);
 -
 -	if (xfs_ipincount(ip) > 0 || xfs_buf_ispinned(bp) ||
 -	    (ip->i_flags & XFS_ISTALE))
 +	if (xfs_ipincount(ip) > 0)
  		return XFS_ITEM_PINNED;
  
++<<<<<<< HEAD
 +	if (!xfs_ilock_nowait(ip, XFS_ILOCK_SHARED))
++=======
+ 	if (xfs_iflags_test(ip, XFS_IFLUSHING))
+ 		return XFS_ITEM_FLUSHING;
+ 
+ 	if (!xfs_buf_trylock(bp))
++>>>>>>> 718ecc50359e (xfs: xfs_iflock is no longer a completion)
  		return XFS_ITEM_LOCKED;
  
 -	spin_unlock(&lip->li_ailp->ail_lock);
 +	/*
 +	 * Re-check the pincount now that we stabilized the value by
 +	 * taking the ilock.
 +	 */
 +	if (xfs_ipincount(ip) > 0) {
 +		rval = XFS_ITEM_PINNED;
 +		goto out_unlock;
 +	}
  
  	/*
 -	 * We need to hold a reference for flushing the cluster buffer as it may
 -	 * fail the buffer without IO submission. In which case, we better get a
 -	 * reference for that completion because otherwise we don't get a
 -	 * reference for IO until we queue the buffer for delwri submission.
 +	 * Stale inode items should force out the iclog.
  	 */
 -	xfs_buf_hold(bp);
 -	error = xfs_iflush_cluster(bp);
 +	if (ip->i_flags & XFS_ISTALE) {
 +		rval = XFS_ITEM_PINNED;
 +		goto out_unlock;
 +	}
 +
 +	/*
 +	 * Someone else is already flushing the inode.  Nothing we can do
 +	 * here but wait for the flush to finish and remove the item from
 +	 * the AIL.
 +	 */
 +	if (!xfs_iflock_nowait(ip)) {
 +		rval = XFS_ITEM_FLUSHING;
 +		goto out_unlock;
 +	}
 +
 +	ASSERT(iip->ili_fields != 0 || XFS_FORCED_SHUTDOWN(ip->i_mount));
 +	spin_unlock(&lip->li_ailp->ail_lock);
 +
 +	error = xfs_iflush(ip, &bp);
  	if (!error) {
  		if (!xfs_buf_delwri_queue(bp, buffer_list))
  			rval = XFS_ITEM_FLUSHING;
diff --git a/fs/xfs/xfs_icache.c b/fs/xfs/xfs_icache.c
index 7716259fef5b..3ea661fd1dcc 100644
--- a/fs/xfs/xfs_icache.c
+++ b/fs/xfs/xfs_icache.c
@@ -52,7 +52,6 @@ xfs_inode_alloc(
 
 	XFS_STATS_INC(mp, vn_active);
 	ASSERT(atomic_read(&ip->i_pincount) == 0);
-	ASSERT(!xfs_isiflocked(ip));
 	ASSERT(ip->i_ino == 0);
 
 	/* initialise the xfs inode */
@@ -122,7 +121,7 @@ void
 xfs_inode_free(
 	struct xfs_inode	*ip)
 {
-	ASSERT(!xfs_isiflocked(ip));
+	ASSERT(!xfs_iflags_test(ip, XFS_IFLUSHING));
 
 	/*
 	 * Because we use RCU freeing we need to ensure the inode always
@@ -1034,23 +1033,21 @@ xfs_reclaim_inode(
 
 	if (!xfs_ilock_nowait(ip, XFS_ILOCK_EXCL))
 		goto out;
-	if (!xfs_iflock_nowait(ip))
+	if (xfs_iflags_test_and_set(ip, XFS_IFLUSHING))
 		goto out_iunlock;
 
 	if (XFS_FORCED_SHUTDOWN(ip->i_mount)) {
 		xfs_iunpin_wait(ip);
-		/* xfs_iflush_abort() drops the flush lock */
 		xfs_iflush_abort(ip);
 		goto reclaim;
 	}
 	if (xfs_ipincount(ip))
-		goto out_ifunlock;
+		goto out_clear_flush;
 	if (!xfs_inode_clean(ip))
-		goto out_ifunlock;
+		goto out_clear_flush;
 
-	xfs_ifunlock(ip);
+	xfs_iflags_clear(ip, XFS_IFLUSHING);
 reclaim:
-	ASSERT(!xfs_isiflocked(ip));
 
 	/*
 	 * Because we use RCU freeing we need to ensure the inode always appears
@@ -1100,8 +1097,8 @@ xfs_reclaim_inode(
 	__xfs_inode_free(ip);
 	return;
 
-out_ifunlock:
-	xfs_ifunlock(ip);
+out_clear_flush:
+	xfs_iflags_clear(ip, XFS_IFLUSHING);
 out_iunlock:
 	xfs_iunlock(ip, XFS_ILOCK_EXCL);
 out:
* Unmerged path fs/xfs/xfs_inode.c
diff --git a/fs/xfs/xfs_inode.h b/fs/xfs/xfs_inode.h
index f9a8b26c3625..52eb5a0b8da5 100644
--- a/fs/xfs/xfs_inode.h
+++ b/fs/xfs/xfs_inode.h
@@ -214,8 +214,7 @@ static inline bool xfs_inode_has_cow_data(struct xfs_inode *ip)
 #define XFS_INEW		(1 << __XFS_INEW_BIT)
 #define XFS_ITRUNCATED		(1 << 5) /* truncated down so flush-on-close */
 #define XFS_IDIRTY_RELEASE	(1 << 6) /* dirty release already seen */
-#define __XFS_IFLOCK_BIT	7	 /* inode is being flushed right now */
-#define XFS_IFLOCK		(1 << __XFS_IFLOCK_BIT)
+#define XFS_IFLUSHING		(1 << 7) /* inode is being flushed */
 #define __XFS_IPINNED_BIT	8	 /* wakeup key for zero pin count */
 #define XFS_IPINNED		(1 << __XFS_IPINNED_BIT)
 #define XFS_IEOFBLOCKS		(1 << 9) /* has the preallocblocks tag set */
@@ -236,36 +235,6 @@ static inline bool xfs_inode_has_cow_data(struct xfs_inode *ip)
 	(XFS_IRECLAIMABLE | XFS_IRECLAIM | \
 	 XFS_IDIRTY_RELEASE | XFS_ITRUNCATED)
 
-/*
- * Synchronize processes attempting to flush the in-core inode back to disk.
- */
-
-static inline int xfs_isiflocked(struct xfs_inode *ip)
-{
-	return xfs_iflags_test(ip, XFS_IFLOCK);
-}
-
-extern void __xfs_iflock(struct xfs_inode *ip);
-
-static inline int xfs_iflock_nowait(struct xfs_inode *ip)
-{
-	return !xfs_iflags_test_and_set(ip, XFS_IFLOCK);
-}
-
-static inline void xfs_iflock(struct xfs_inode *ip)
-{
-	if (!xfs_iflock_nowait(ip))
-		__xfs_iflock(ip);
-}
-
-static inline void xfs_ifunlock(struct xfs_inode *ip)
-{
-	ASSERT(xfs_isiflocked(ip));
-	xfs_iflags_clear(ip, XFS_IFLOCK);
-	smp_mb();
-	wake_up_bit(&ip->i_flags, __XFS_IFLOCK_BIT);
-}
-
 /*
  * Flags for inode locking.
  * Bit ranges:	1<<1  - 1<<16-1 -- iolock/ilock modes (bitfield)
* Unmerged path fs/xfs/xfs_inode_item.c
diff --git a/fs/xfs/xfs_inode_item.h b/fs/xfs/xfs_inode_item.h
index 048b5e7dee90..23a7b4928727 100644
--- a/fs/xfs/xfs_inode_item.h
+++ b/fs/xfs/xfs_inode_item.h
@@ -25,8 +25,8 @@ struct xfs_inode_log_item {
 	 *
 	 * We need atomic changes between inode dirtying, inode flushing and
 	 * inode completion, but these all hold different combinations of
-	 * ILOCK and iflock and hence we need some other method of serialising
-	 * updates to the flush state.
+	 * ILOCK and IFLUSHING and hence we need some other method of
+	 * serialising updates to the flush state.
 	 */
 	spinlock_t		ili_lock;	   /* flush state lock */
 	unsigned int		ili_last_fields;   /* fields when flushed */
diff --git a/fs/xfs/xfs_mount.c b/fs/xfs/xfs_mount.c
index ee57975a76f2..e7647131d263 100644
--- a/fs/xfs/xfs_mount.c
+++ b/fs/xfs/xfs_mount.c
@@ -1059,11 +1059,12 @@ xfs_unmountfs(
 	 * We can potentially deadlock here if we have an inode cluster
 	 * that has been freed has its buffer still pinned in memory because
 	 * the transaction is still sitting in a iclog. The stale inodes
-	 * on that buffer will have their flush locks held until the
-	 * transaction hits the disk and the callbacks run. the inode
-	 * flush takes the flush lock unconditionally and with nothing to
-	 * push out the iclog we will never get that unlocked. hence we
-	 * need to force the log first.
+	 * on that buffer will be pinned to the buffer until the
+	 * transaction hits the disk and the callbacks run. Pushing the AIL will
+	 * skip the stale inodes and may never see the pinned buffer, so
+	 * nothing will push out the iclog and unpin the buffer. Hence we
+	 * need to force the log here to ensure all items are flushed into the
+	 * AIL before we go any further.
 	 */
 	xfs_log_force(mp, XFS_LOG_SYNC);
 
diff --git a/fs/xfs/xfs_super.c b/fs/xfs/xfs_super.c
index 60a2ea26e8ac..a1e1cc389e4a 100644
--- a/fs/xfs/xfs_super.c
+++ b/fs/xfs/xfs_super.c
@@ -655,11 +655,11 @@ xfs_fs_destroy_inode(
 	ASSERT_ALWAYS(!xfs_iflags_test(ip, XFS_IRECLAIM));
 
 	/*
-	 * We always use background reclaim here because even if the
-	 * inode is clean, it still may be under IO and hence we have
-	 * to take the flush lock. The background reclaim path handles
-	 * this more efficiently than we can here, so simply let background
-	 * reclaim tear down all inodes.
+	 * We always use background reclaim here because even if the inode is
+	 * clean, it still may be under IO and hence we have wait for IO
+	 * completion to occur before we can reclaim the inode. The background
+	 * reclaim path handles this more efficiently than we can here, so
+	 * simply let background reclaim tear down all inodes.
 	 */
 	xfs_inode_set_reclaim_tag(ip);
 }
