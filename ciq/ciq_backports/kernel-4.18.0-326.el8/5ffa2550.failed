bpf: Add instructions for atomic_[cmp]xchg

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Brendan Jackman <jackmanb@google.com>
commit 5ffa25502b5ab3d639829a2d1e316cff7f59a41e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/5ffa2550.failed

This adds two atomic opcodes, both of which include the BPF_FETCH
flag. XCHG without the BPF_FETCH flag would naturally encode
atomic_set. This is not supported because it would be of limited
value to userspace (it doesn't imply any barriers). CMPXCHG without
BPF_FETCH woulud be an atomic compare-and-write. We don't have such
an operation in the kernel so it isn't provided to BPF either.

There are two significant design decisions made for the CMPXCHG
instruction:

 - To solve the issue that this operation fundamentally has 3
   operands, but we only have two register fields. Therefore the
   operand we compare against (the kernel's API calls it 'old') is
   hard-coded to be R0. x86 has similar design (and A64 doesn't
   have this problem).

   A potential alternative might be to encode the other operand's
   register number in the immediate field.

 - The kernel's atomic_cmpxchg returns the old value, while the C11
   userspace APIs return a boolean indicating the comparison
   result. Which should BPF do? A64 returns the old value. x86 returns
   the old value in the hard-coded register (and also sets a
   flag). That means return-old-value is easier to JIT, so that's
   what we use.

	Signed-off-by: Brendan Jackman <jackmanb@google.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Yonghong Song <yhs@fb.com>
Link: https://lore.kernel.org/bpf/20210114181751.768687-8-jackmanb@google.com
(cherry picked from commit 5ffa25502b5ab3d639829a2d1e316cff7f59a41e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/net/bpf_jit_comp.c
#	include/linux/filter.h
#	include/uapi/linux/bpf.h
#	kernel/bpf/core.c
#	kernel/bpf/disasm.c
#	kernel/bpf/verifier.c
#	tools/include/linux/filter.h
#	tools/include/uapi/linux/bpf.h
diff --cc arch/x86/net/bpf_jit_comp.c
index dd4d8265af59,308241187582..000000000000
--- a/arch/x86/net/bpf_jit_comp.c
+++ b/arch/x86/net/bpf_jit_comp.c
@@@ -799,6 -795,45 +799,48 @@@ static void emit_stx(u8 **pprog, u32 si
  	*pprog = prog;
  }
  
++<<<<<<< HEAD
++=======
+ static int emit_atomic(u8 **pprog, u8 atomic_op,
+ 		       u32 dst_reg, u32 src_reg, s16 off, u8 bpf_size)
+ {
+ 	u8 *prog = *pprog;
+ 	int cnt = 0;
+ 
+ 	EMIT1(0xF0); /* lock prefix */
+ 
+ 	maybe_emit_mod(&prog, dst_reg, src_reg, bpf_size == BPF_DW);
+ 
+ 	/* emit opcode */
+ 	switch (atomic_op) {
+ 	case BPF_ADD:
+ 		/* lock *(u32/u64*)(dst_reg + off) <op>= src_reg */
+ 		EMIT1(simple_alu_opcodes[atomic_op]);
+ 		break;
+ 	case BPF_ADD | BPF_FETCH:
+ 		/* src_reg = atomic_fetch_add(dst_reg + off, src_reg); */
+ 		EMIT2(0x0F, 0xC1);
+ 		break;
+ 	case BPF_XCHG:
+ 		/* src_reg = atomic_xchg(dst_reg + off, src_reg); */
+ 		EMIT1(0x87);
+ 		break;
+ 	case BPF_CMPXCHG:
+ 		/* r0 = atomic_cmpxchg(dst_reg + off, r0, src_reg); */
+ 		EMIT2(0x0F, 0xB1);
+ 		break;
+ 	default:
+ 		pr_err("bpf_jit: unknown atomic opcode %02x\n", atomic_op);
+ 		return -EFAULT;
+ 	}
+ 
+ 	emit_insn_suffix(&prog, dst_reg, src_reg, off);
+ 
+ 	*pprog = prog;
+ 	return 0;
+ }
+ 
++>>>>>>> 5ffa25502b5a (bpf: Add instructions for atomic_[cmp]xchg)
  static bool ex_handler_bpf(const struct exception_table_entry *x,
  			   struct pt_regs *regs, int trapnr,
  			   unsigned long error_code, unsigned long fault_addr)
diff --cc include/linux/filter.h
index 3267b6630b89,d563820f197d..000000000000
--- a/include/linux/filter.h
+++ b/include/linux/filter.h
@@@ -259,11 -259,19 +259,24 @@@ static inline bool insn_is_zext(const s
  		.off   = OFF,					\
  		.imm   = 0 })
  
 +/* Atomic memory add, *(uint *)(dst_reg + off16) += src_reg */
  
++<<<<<<< HEAD
 +#define BPF_STX_XADD(SIZE, DST, SRC, OFF)			\
++=======
+ /*
+  * Atomic operations:
+  *
+  *   BPF_ADD                  *(uint *) (dst_reg + off16) += src_reg
+  *   BPF_ADD | BPF_FETCH      src_reg = atomic_fetch_add(dst_reg + off16, src_reg);
+  *   BPF_XCHG                 src_reg = atomic_xchg(dst_reg + off16, src_reg)
+  *   BPF_CMPXCHG              r0 = atomic_cmpxchg(dst_reg + off16, r0, src_reg)
+  */
+ 
+ #define BPF_ATOMIC_OP(SIZE, OP, DST, SRC, OFF)			\
++>>>>>>> 5ffa25502b5a (bpf: Add instructions for atomic_[cmp]xchg)
  	((struct bpf_insn) {					\
 -		.code  = BPF_STX | BPF_SIZE(SIZE) | BPF_ATOMIC,	\
 +		.code  = BPF_STX | BPF_SIZE(SIZE) | BPF_XADD,	\
  		.dst_reg = DST,					\
  		.src_reg = SRC,					\
  		.off   = OFF,					\
diff --cc include/uapi/linux/bpf.h
index a19a1e1a1ca1,c001766adcbc..000000000000
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@@ -43,6 -44,11 +43,14 @@@
  #define BPF_CALL	0x80	/* function call */
  #define BPF_EXIT	0x90	/* function return */
  
++<<<<<<< HEAD
++=======
+ /* atomic op type fields (stored in immediate) */
+ #define BPF_FETCH	0x01	/* not an opcode on its own, used to build others */
+ #define BPF_XCHG	(0xe0 | BPF_FETCH)	/* atomic exchange */
+ #define BPF_CMPXCHG	(0xf0 | BPF_FETCH)	/* atomic compare-and-write */
+ 
++>>>>>>> 5ffa25502b5a (bpf: Add instructions for atomic_[cmp]xchg)
  /* Register numbers */
  enum {
  	BPF_REG_0 = 0,
diff --cc kernel/bpf/core.c
index a915516dd706,4df6daba43ef..000000000000
--- a/kernel/bpf/core.c
+++ b/kernel/bpf/core.c
@@@ -1631,13 -1618,58 +1631,68 @@@ out
  	LDX_PROBE(DW, 8)
  #undef LDX_PROBE
  
++<<<<<<< HEAD
 +	STX_XADD_W: /* lock xadd *(u32 *)(dst_reg + off16) += src_reg */
 +		atomic_add((u32) SRC, (atomic_t *)(unsigned long)
 +			   (DST + insn->off));
 +		CONT;
 +	STX_XADD_DW: /* lock xadd *(u64 *)(dst_reg + off16) += src_reg */
 +		atomic64_add((u64) SRC, (atomic64_t *)(unsigned long)
 +			     (DST + insn->off));
++=======
+ 	STX_ATOMIC_W:
+ 		switch (IMM) {
+ 		case BPF_ADD:
+ 			/* lock xadd *(u32 *)(dst_reg + off16) += src_reg */
+ 			atomic_add((u32) SRC, (atomic_t *)(unsigned long)
+ 				   (DST + insn->off));
+ 			break;
+ 		case BPF_ADD | BPF_FETCH:
+ 			SRC = (u32) atomic_fetch_add(
+ 				(u32) SRC,
+ 				(atomic_t *)(unsigned long) (DST + insn->off));
+ 			break;
+ 		case BPF_XCHG:
+ 			SRC = (u32) atomic_xchg(
+ 				(atomic_t *)(unsigned long) (DST + insn->off),
+ 				(u32) SRC);
+ 			break;
+ 		case BPF_CMPXCHG:
+ 			BPF_R0 = (u32) atomic_cmpxchg(
+ 				(atomic_t *)(unsigned long) (DST + insn->off),
+ 				(u32) BPF_R0, (u32) SRC);
+ 			break;
+ 		default:
+ 			goto default_label;
+ 		}
+ 		CONT;
+ 
+ 	STX_ATOMIC_DW:
+ 		switch (IMM) {
+ 		case BPF_ADD:
+ 			/* lock xadd *(u64 *)(dst_reg + off16) += src_reg */
+ 			atomic64_add((u64) SRC, (atomic64_t *)(unsigned long)
+ 				     (DST + insn->off));
+ 			break;
+ 		case BPF_ADD | BPF_FETCH:
+ 			SRC = (u64) atomic64_fetch_add(
+ 				(u64) SRC,
+ 				(atomic64_t *)(unsigned long) (DST + insn->off));
+ 			break;
+ 		case BPF_XCHG:
+ 			SRC = (u64) atomic64_xchg(
+ 				(atomic64_t *)(unsigned long) (DST + insn->off),
+ 				(u64) SRC);
+ 			break;
+ 		case BPF_CMPXCHG:
+ 			BPF_R0 = (u64) atomic64_cmpxchg(
+ 				(atomic64_t *)(unsigned long) (DST + insn->off),
+ 				(u64) BPF_R0, (u64) SRC);
+ 			break;
+ 		default:
+ 			goto default_label;
+ 		}
++>>>>>>> 5ffa25502b5a (bpf: Add instructions for atomic_[cmp]xchg)
  		CONT;
  
  	default_label:
diff --cc kernel/bpf/disasm.c
index d9ce383c0f9c,ee8d1132767b..000000000000
--- a/kernel/bpf/disasm.c
+++ b/kernel/bpf/disasm.c
@@@ -167,8 -160,31 +167,34 @@@ void print_bpf_insn(const struct bpf_in
  				bpf_ldst_string[BPF_SIZE(insn->code) >> 3],
  				insn->dst_reg, insn->off,
  				insn->src_reg);
++<<<<<<< HEAD
 +		else
++=======
+ 		} else if (BPF_MODE(insn->code) == BPF_ATOMIC &&
+ 			   insn->imm == (BPF_ADD | BPF_FETCH)) {
+ 			verbose(cbs->private_data, "(%02x) r%d = atomic%s_fetch_add((%s *)(r%d %+d), r%d)\n",
+ 				insn->code, insn->src_reg,
+ 				BPF_SIZE(insn->code) == BPF_DW ? "64" : "",
+ 				bpf_ldst_string[BPF_SIZE(insn->code) >> 3],
+ 				insn->dst_reg, insn->off, insn->src_reg);
+ 		} else if (BPF_MODE(insn->code) == BPF_ATOMIC &&
+ 			   insn->imm == BPF_CMPXCHG) {
+ 			verbose(cbs->private_data, "(%02x) r0 = atomic%s_cmpxchg((%s *)(r%d %+d), r0, r%d)\n",
+ 				insn->code,
+ 				BPF_SIZE(insn->code) == BPF_DW ? "64" : "",
+ 				bpf_ldst_string[BPF_SIZE(insn->code) >> 3],
+ 				insn->dst_reg, insn->off,
+ 				insn->src_reg);
+ 		} else if (BPF_MODE(insn->code) == BPF_ATOMIC &&
+ 			   insn->imm == BPF_XCHG) {
+ 			verbose(cbs->private_data, "(%02x) r%d = atomic%s_xchg((%s *)(r%d %+d), r%d)\n",
+ 				insn->code, insn->src_reg,
+ 				BPF_SIZE(insn->code) == BPF_DW ? "64" : "",
+ 				bpf_ldst_string[BPF_SIZE(insn->code) >> 3],
+ 				insn->dst_reg, insn->off, insn->src_reg);
+ 		} else {
++>>>>>>> 5ffa25502b5a (bpf: Add instructions for atomic_[cmp]xchg)
  			verbose(cbs->private_data, "BUG_%02x\n", insn->code);
 -		}
  	} else if (class == BPF_ST) {
  		if (BPF_MODE(insn->code) != BPF_MEM) {
  			verbose(cbs->private_data, "BUG_st_%02x\n", insn->code);
diff --cc kernel/bpf/verifier.c
index 628ac51f9efd,89a4d154ab37..000000000000
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@@ -3602,13 -3604,24 +3602,30 @@@ static int check_mem_access(struct bpf_
  	return err;
  }
  
 -static int check_atomic(struct bpf_verifier_env *env, int insn_idx, struct bpf_insn *insn)
 +static int check_xadd(struct bpf_verifier_env *env, int insn_idx, struct bpf_insn *insn)
  {
+ 	int load_reg;
  	int err;
  
++<<<<<<< HEAD
 +	if ((BPF_SIZE(insn->code) != BPF_W && BPF_SIZE(insn->code) != BPF_DW) ||
 +	    insn->imm != 0) {
 +		verbose(env, "BPF_XADD uses reserved fields\n");
++=======
+ 	switch (insn->imm) {
+ 	case BPF_ADD:
+ 	case BPF_ADD | BPF_FETCH:
+ 	case BPF_XCHG:
+ 	case BPF_CMPXCHG:
+ 		break;
+ 	default:
+ 		verbose(env, "BPF_ATOMIC uses invalid atomic opcode %02x\n", insn->imm);
+ 		return -EINVAL;
+ 	}
+ 
+ 	if (BPF_SIZE(insn->code) != BPF_W && BPF_SIZE(insn->code) != BPF_DW) {
+ 		verbose(env, "invalid atomic operand size\n");
++>>>>>>> 5ffa25502b5a (bpf: Add instructions for atomic_[cmp]xchg)
  		return -EINVAL;
  	}
  
@@@ -3643,9 -3663,26 +3667,32 @@@
  	if (err)
  		return err;
  
++<<<<<<< HEAD
 +	/* check whether atomic_add can write into the same memory */
 +	return check_mem_access(env, insn_idx, insn->dst_reg, insn->off,
 +				BPF_SIZE(insn->code), BPF_WRITE, -1, true);
++=======
+ 	/* check whether we can write into the same memory */
+ 	err = check_mem_access(env, insn_idx, insn->dst_reg, insn->off,
+ 			       BPF_SIZE(insn->code), BPF_WRITE, -1, true);
+ 	if (err)
+ 		return err;
+ 
+ 	if (!(insn->imm & BPF_FETCH))
+ 		return 0;
+ 
+ 	if (insn->imm == BPF_CMPXCHG)
+ 		load_reg = BPF_REG_0;
+ 	else
+ 		load_reg = insn->src_reg;
+ 
+ 	/* check and record load of old value */
+ 	err = check_reg_arg(env, load_reg, DST_OP);
+ 	if (err)
+ 		return err;
+ 
+ 	return 0;
++>>>>>>> 5ffa25502b5a (bpf: Add instructions for atomic_[cmp]xchg)
  }
  
  static int __check_stack_boundary(struct bpf_verifier_env *env, u32 regno,
diff --cc tools/include/linux/filter.h
index ca28b6ab8db7,d75998b0d5ac..000000000000
--- a/tools/include/linux/filter.h
+++ b/tools/include/linux/filter.h
@@@ -169,11 -169,18 +169,22 @@@
  		.off   = OFF,					\
  		.imm   = 0 })
  
++<<<<<<< HEAD
 +/* Atomic memory add, *(uint *)(dst_reg + off16) += src_reg */
++=======
+ /*
+  * Atomic operations:
+  *
+  *   BPF_ADD                  *(uint *) (dst_reg + off16) += src_reg
+  *   BPF_ADD | BPF_FETCH      src_reg = atomic_fetch_add(dst_reg + off16, src_reg);
+  *   BPF_XCHG                 src_reg = atomic_xchg(dst_reg + off16, src_reg)
+  *   BPF_CMPXCHG              r0 = atomic_cmpxchg(dst_reg + off16, r0, src_reg)
+  */
++>>>>>>> 5ffa25502b5a (bpf: Add instructions for atomic_[cmp]xchg)
  
 -#define BPF_ATOMIC_OP(SIZE, OP, DST, SRC, OFF)			\
 +#define BPF_STX_XADD(SIZE, DST, SRC, OFF)			\
  	((struct bpf_insn) {					\
 -		.code  = BPF_STX | BPF_SIZE(SIZE) | BPF_ATOMIC,	\
 +		.code  = BPF_STX | BPF_SIZE(SIZE) | BPF_XADD,	\
  		.dst_reg = DST,					\
  		.src_reg = SRC,					\
  		.off   = OFF,					\
diff --cc tools/include/uapi/linux/bpf.h
index 8c3a5948ff2a,c001766adcbc..000000000000
--- a/tools/include/uapi/linux/bpf.h
+++ b/tools/include/uapi/linux/bpf.h
@@@ -43,6 -44,11 +43,14 @@@
  #define BPF_CALL	0x80	/* function call */
  #define BPF_EXIT	0x90	/* function return */
  
++<<<<<<< HEAD
++=======
+ /* atomic op type fields (stored in immediate) */
+ #define BPF_FETCH	0x01	/* not an opcode on its own, used to build others */
+ #define BPF_XCHG	(0xe0 | BPF_FETCH)	/* atomic exchange */
+ #define BPF_CMPXCHG	(0xf0 | BPF_FETCH)	/* atomic compare-and-write */
+ 
++>>>>>>> 5ffa25502b5a (bpf: Add instructions for atomic_[cmp]xchg)
  /* Register numbers */
  enum {
  	BPF_REG_0 = 0,
* Unmerged path arch/x86/net/bpf_jit_comp.c
* Unmerged path include/linux/filter.h
* Unmerged path include/uapi/linux/bpf.h
* Unmerged path kernel/bpf/core.c
* Unmerged path kernel/bpf/disasm.c
* Unmerged path kernel/bpf/verifier.c
* Unmerged path tools/include/linux/filter.h
* Unmerged path tools/include/uapi/linux/bpf.h
