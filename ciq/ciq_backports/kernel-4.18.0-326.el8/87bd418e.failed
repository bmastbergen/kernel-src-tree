net/mlx5: E-Switch, Consider SF ports of host PF

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Parav Pandit <parav@nvidia.com>
commit 87bd418ea7515d904a3dc69de2479396f5cbd7a4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/87bd418e.failed

Query SF vports count and base id of host PF from the firmware.

Account these ports in the total port calculation whenever it is non
zero.

	Signed-off-by: Parav Pandit <parav@nvidia.com>
	Reviewed-by: Roi Dayan <roid@nvidia.com>
	Reviewed-by: Vu Pham <vuhuong@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit 87bd418ea7515d904a3dc69de2479396f5cbd7a4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
index 6f56131481bc,570f2280823c..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@@ -1741,6 -1566,153 +1741,156 @@@ void mlx5_eswitch_disable(struct mlx5_e
  	up_write(&esw->mode_lock);
  }
  
++<<<<<<< HEAD
++=======
+ static int mlx5_query_hca_cap_host_pf(struct mlx5_core_dev *dev, void *out)
+ {
+ 	u16 opmod = (MLX5_CAP_GENERAL << 1) | (HCA_CAP_OPMOD_GET_MAX & 0x01);
+ 	u8 in[MLX5_ST_SZ_BYTES(query_hca_cap_in)] = {};
+ 
+ 	MLX5_SET(query_hca_cap_in, in, opcode, MLX5_CMD_OP_QUERY_HCA_CAP);
+ 	MLX5_SET(query_hca_cap_in, in, op_mod, opmod);
+ 	MLX5_SET(query_hca_cap_in, in, function_id, MLX5_VPORT_PF);
+ 	MLX5_SET(query_hca_cap_in, in, other_function, true);
+ 	return mlx5_cmd_exec_inout(dev, query_hca_cap, in, out);
+ }
+ 
+ int mlx5_esw_sf_max_hpf_functions(struct mlx5_core_dev *dev, u16 *max_sfs, u16 *sf_base_id)
+ 
+ {
+ 	int query_out_sz = MLX5_ST_SZ_BYTES(query_hca_cap_out);
+ 	void *query_ctx;
+ 	void *hca_caps;
+ 	int err;
+ 
+ 	if (!mlx5_core_is_ecpf(dev)) {
+ 		*max_sfs = 0;
+ 		return 0;
+ 	}
+ 
+ 	query_ctx = kzalloc(query_out_sz, GFP_KERNEL);
+ 	if (!query_ctx)
+ 		return -ENOMEM;
+ 
+ 	err = mlx5_query_hca_cap_host_pf(dev, query_ctx);
+ 	if (err)
+ 		goto out_free;
+ 
+ 	hca_caps = MLX5_ADDR_OF(query_hca_cap_out, query_ctx, capability);
+ 	*max_sfs = MLX5_GET(cmd_hca_cap, hca_caps, max_num_sf);
+ 	*sf_base_id = MLX5_GET(cmd_hca_cap, hca_caps, sf_base_id);
+ 
+ out_free:
+ 	kfree(query_ctx);
+ 	return err;
+ }
+ 
+ static int mlx5_esw_vport_alloc(struct mlx5_eswitch *esw, struct mlx5_core_dev *dev,
+ 				int index, u16 vport_num)
+ {
+ 	struct mlx5_vport *vport;
+ 	int err;
+ 
+ 	vport = kzalloc(sizeof(*vport), GFP_KERNEL);
+ 	if (!vport)
+ 		return -ENOMEM;
+ 
+ 	vport->dev = esw->dev;
+ 	vport->vport = vport_num;
+ 	vport->index = index;
+ 	vport->info.link_state = MLX5_VPORT_ADMIN_STATE_AUTO;
+ 	INIT_WORK(&vport->vport_change_handler, esw_vport_change_handler);
+ 	err = xa_insert(&esw->vports, vport_num, vport, GFP_KERNEL);
+ 	if (err)
+ 		goto insert_err;
+ 
+ 	esw->total_vports++;
+ 	return 0;
+ 
+ insert_err:
+ 	kfree(vport);
+ 	return err;
+ }
+ 
+ static void mlx5_esw_vport_free(struct mlx5_eswitch *esw, struct mlx5_vport *vport)
+ {
+ 	xa_erase(&esw->vports, vport->vport);
+ 	kfree(vport);
+ }
+ 
+ static void mlx5_esw_vports_cleanup(struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_vport *vport;
+ 	unsigned long i;
+ 
+ 	mlx5_esw_for_each_vport(esw, i, vport)
+ 		mlx5_esw_vport_free(esw, vport);
+ 	xa_destroy(&esw->vports);
+ }
+ 
+ static int mlx5_esw_vports_init(struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_core_dev *dev = esw->dev;
+ 	u16 max_host_pf_sfs;
+ 	u16 base_sf_num;
+ 	int idx = 0;
+ 	int err;
+ 	int i;
+ 
+ 	xa_init(&esw->vports);
+ 
+ 	err = mlx5_esw_vport_alloc(esw, dev, idx, MLX5_VPORT_PF);
+ 	if (err)
+ 		goto err;
+ 	if (esw->first_host_vport == MLX5_VPORT_PF)
+ 		xa_set_mark(&esw->vports, idx, MLX5_ESW_VPT_HOST_FN);
+ 	idx++;
+ 
+ 	for (i = 0; i < mlx5_core_max_vfs(dev); i++) {
+ 		err = mlx5_esw_vport_alloc(esw, dev, idx, idx);
+ 		if (err)
+ 			goto err;
+ 		xa_set_mark(&esw->vports, idx, MLX5_ESW_VPT_VF);
+ 		xa_set_mark(&esw->vports, idx, MLX5_ESW_VPT_HOST_FN);
+ 		idx++;
+ 	}
+ 	base_sf_num = mlx5_sf_start_function_id(dev);
+ 	for (i = 0; i < mlx5_sf_max_functions(dev); i++) {
+ 		err = mlx5_esw_vport_alloc(esw, dev, idx, base_sf_num + i);
+ 		if (err)
+ 			goto err;
+ 		xa_set_mark(&esw->vports, base_sf_num + i, MLX5_ESW_VPT_SF);
+ 		idx++;
+ 	}
+ 
+ 	err = mlx5_esw_sf_max_hpf_functions(dev, &max_host_pf_sfs, &base_sf_num);
+ 	if (err)
+ 		goto err;
+ 	for (i = 0; i < max_host_pf_sfs; i++) {
+ 		err = mlx5_esw_vport_alloc(esw, dev, idx, base_sf_num + i);
+ 		if (err)
+ 			goto err;
+ 		xa_set_mark(&esw->vports, base_sf_num + i, MLX5_ESW_VPT_SF);
+ 		idx++;
+ 	}
+ 
+ 	if (mlx5_ecpf_vport_exists(dev)) {
+ 		err = mlx5_esw_vport_alloc(esw, dev, idx, MLX5_VPORT_ECPF);
+ 		if (err)
+ 			goto err;
+ 		idx++;
+ 	}
+ 	err = mlx5_esw_vport_alloc(esw, dev, idx, MLX5_VPORT_UPLINK);
+ 	if (err)
+ 		goto err;
+ 	return 0;
+ 
+ err:
+ 	mlx5_esw_vports_cleanup(esw);
+ 	return err;
+ }
+ 
++>>>>>>> 87bd418ea751 (net/mlx5: E-Switch, Consider SF ports of host PF)
  int mlx5_eswitch_init(struct mlx5_core_dev *dev)
  {
  	struct mlx5_eswitch *esw;
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index f8d344738e70..596734aa8fae 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@ -745,6 +745,7 @@ void mlx5_esw_devlink_sf_port_unregister(struct mlx5_eswitch *esw, u16 vport_num
 int mlx5_esw_offloads_sf_vport_enable(struct mlx5_eswitch *esw, struct devlink_port *dl_port,
 				      u16 vport_num, u32 sfnum);
 void mlx5_esw_offloads_sf_vport_disable(struct mlx5_eswitch *esw, u16 vport_num);
+int mlx5_esw_sf_max_hpf_functions(struct mlx5_core_dev *dev, u16 *max_sfs, u16 *sf_base_id);
 
 #else  /* CONFIG_MLX5_ESWITCH */
 /* eswitch API stubs */
