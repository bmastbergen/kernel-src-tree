net/mlx5e: RX, Add a prefetch command for small L1_CACHE_BYTES

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Tariq Toukan <tariqt@mellanox.com>
commit e20f0dbf204fe2a518ad289f2b39644c69dff531
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/e20f0dbf.failed

A single cacheline might not contain the packet header for
small L1_CACHE_BYTES values.
Use net_prefetch() as it issues an additional prefetch
in this case.

	Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
	Reviewed-by: Saeed Mahameed <saeedm@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit e20f0dbf204fe2a518ad289f2b39644c69dff531)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
#	drivers/net/ethernet/mellanox/mlx5/core/en/xsk/rx.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
index 781e71d9a1f8,4bcb73a5522f..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
@@@ -194,22 -194,18 +194,30 @@@ static u16 mlx5e_xdpsq_get_next_pi(stru
  
  static void mlx5e_xdp_mpwqe_session_start(struct mlx5e_xdpsq *sq)
  {
 -	struct mlx5e_xdp_mpwqe *session = &sq->mpwqe;
 +	struct mlx5e_tx_mpwqe *session = &sq->mpwqe;
  	struct mlx5e_xdpsq_stats *stats = sq->stats;
 +	struct mlx5e_tx_wqe *wqe;
  	u16 pi;
  
 -	pi = mlx5e_xdpsq_get_next_pi(sq, MLX5_SEND_WQE_MAX_WQEBBS);
 -	session->wqe = MLX5E_TX_FETCH_WQE(sq, pi);
 -
 +	pi = mlx5e_xdpsq_get_next_pi(sq, MLX5E_TX_MPW_MAX_WQEBBS);
 +	wqe = MLX5E_TX_FETCH_WQE(sq, pi);
 +	prefetchw(wqe->data);
 +
++<<<<<<< HEAD
 +	*session = (struct mlx5e_tx_mpwqe) {
 +		.wqe = wqe,
 +		.bytes_count = 0,
 +		.ds_count = MLX5E_TX_WQE_EMPTY_DS_COUNT,
 +		.pkt_count = 0,
 +		.inline_on = mlx5e_xdp_get_inline_state(sq, session->inline_on),
 +	};
++=======
+ 	net_prefetchw(session->wqe->data);
+ 	session->ds_count  = MLX5E_XDP_TX_EMPTY_DS_COUNT;
+ 	session->pkt_count = 0;
+ 
+ 	mlx5e_xdp_update_inline_state(sq);
++>>>>>>> e20f0dbf204f (net/mlx5e: RX, Add a prefetch command for small L1_CACHE_BYTES)
  
  	stats->mpwqe++;
  }
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/xsk/rx.c
index 44007ef59b48,786fedf52436..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/xsk/rx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/xsk/rx.c
@@@ -47,8 -48,12 +47,13 @@@ struct sk_buff *mlx5e_xsk_skb_from_cqe_
  
  	xdp->data_end = xdp->data + cqe_bcnt32;
  	xdp_set_data_meta_invalid(xdp);
++<<<<<<< HEAD
 +	xsk_buff_dma_sync_for_cpu(xdp, rq->xsk_pool);
 +	prefetch(xdp->data);
++=======
+ 	xsk_buff_dma_sync_for_cpu(xdp);
+ 	net_prefetch(xdp->data);
 -
 -	rcu_read_lock();
 -	consumed = mlx5e_xdp_handle(rq, NULL, &cqe_bcnt32, xdp);
 -	rcu_read_unlock();
++>>>>>>> e20f0dbf204f (net/mlx5e: RX, Add a prefetch command for small L1_CACHE_BYTES)
  
  	/* Possible flows:
  	 * - XDP_REDIRECT to XSKMAP:
@@@ -93,8 -99,8 +98,13 @@@ struct sk_buff *mlx5e_xsk_skb_from_cqe_
  
  	xdp->data_end = xdp->data + cqe_bcnt;
  	xdp_set_data_meta_invalid(xdp);
++<<<<<<< HEAD
 +	xsk_buff_dma_sync_for_cpu(xdp, rq->xsk_pool);
 +	prefetch(xdp->data);
++=======
+ 	xsk_buff_dma_sync_for_cpu(xdp);
+ 	net_prefetch(xdp->data);
++>>>>>>> e20f0dbf204f (net/mlx5e: RX, Add a prefetch command for small L1_CACHE_BYTES)
  
  	if (unlikely(get_cqe_opcode(cqe) != MLX5_CQE_RESP_SEND)) {
  		rq->stats->wqe_err++;
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/xsk/rx.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
index 56c048644fa9..9b4629534784 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
@@ -30,7 +30,6 @@
  * SOFTWARE.
  */
 
-#include <linux/prefetch.h>
 #include <linux/ip.h>
 #include <linux/ipv6.h>
 #include <linux/tcp.h>
@@ -1140,8 +1139,8 @@ mlx5e_skb_from_cqe_linear(struct mlx5e_rq *rq, struct mlx5_cqe64 *cqe,
 
 	dma_sync_single_range_for_cpu(rq->pdev, di->addr, wi->offset,
 				      frag_size, DMA_FROM_DEVICE);
-	prefetchw(va); /* xdp_frame data area */
-	prefetch(data);
+	net_prefetchw(va); /* xdp_frame data area */
+	net_prefetch(data);
 
 	mlx5e_fill_xdp_buff(rq, va, rx_headroom, cqe_bcnt, &xdp);
 	if (mlx5e_xdp_handle(rq, di, &cqe_bcnt, &xdp))
@@ -1180,7 +1179,7 @@ mlx5e_skb_from_cqe_nonlinear(struct mlx5e_rq *rq, struct mlx5_cqe64 *cqe,
 		return NULL;
 	}
 
-	prefetchw(skb->data);
+	net_prefetchw(skb->data);
 
 	while (byte_cnt) {
 		u16 frag_consumed_bytes =
@@ -1399,7 +1398,7 @@ mlx5e_skb_from_cqe_mpwrq_nonlinear(struct mlx5e_rq *rq, struct mlx5e_mpw_info *w
 		return NULL;
 	}
 
-	prefetchw(skb->data);
+	net_prefetchw(skb->data);
 
 	if (unlikely(frag_offset >= PAGE_SIZE)) {
 		di++;
@@ -1451,8 +1450,8 @@ mlx5e_skb_from_cqe_mpwrq_linear(struct mlx5e_rq *rq, struct mlx5e_mpw_info *wi,
 
 	dma_sync_single_range_for_cpu(rq->pdev, di->addr, head_offset,
 				      frag_size, DMA_FROM_DEVICE);
-	prefetchw(va); /* xdp_frame data area */
-	prefetch(data);
+	net_prefetchw(va); /* xdp_frame data area */
+	net_prefetch(data);
 
 	mlx5e_fill_xdp_buff(rq, va, rx_headroom, cqe_bcnt32, &xdp);
 	if (mlx5e_xdp_handle(rq, di, &cqe_bcnt32, &xdp)) {
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_selftest.c b/drivers/net/ethernet/mellanox/mlx5/core/en_selftest.c
index 46790216ce86..ce8ab1f01876 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_selftest.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_selftest.c
@@ -30,7 +30,6 @@
  * SOFTWARE.
  */
 
-#include <linux/prefetch.h>
 #include <linux/ip.h>
 #include <linux/udp.h>
 #include <net/udp.h>
@@ -115,7 +114,7 @@ static struct sk_buff *mlx5e_test_get_udp_skb(struct mlx5e_priv *priv)
 		return NULL;
 	}
 
-	prefetchw(skb->data);
+	net_prefetchw(skb->data);
 	skb_reserve(skb, NET_IP_ALIGN);
 
 	/*  Reserve for ethernet and IP header  */
