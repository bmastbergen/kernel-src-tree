bpf: Support BPF ksym variables in kernel modules

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Andrii Nakryiko <andrii@kernel.org>
commit 541c3bad8dc51b253ba8686d0cd7628e6b9b5f4c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/541c3bad.failed

Add support for directly accessing kernel module variables from BPF programs
using special ldimm64 instructions. This functionality builds upon vmlinux
ksym support, but extends ldimm64 with src_reg=BPF_PSEUDO_BTF_ID to allow
specifying kernel module BTF's FD in insn[1].imm field.

During BPF program load time, verifier will resolve FD to BTF object and will
take reference on BTF object itself and, for module BTFs, corresponding module
as well, to make sure it won't be unloaded from under running BPF program. The
mechanism used is similar to how bpf_prog keeps track of used bpf_maps.

One interesting change is also in how per-CPU variable is determined. The
logic is to find .data..percpu data section in provided BTF, but both vmlinux
and module each have their own .data..percpu entries in BTF. So for module's
case, the search for DATASEC record needs to look at only module's added BTF
types. This is implemented with custom search function.

	Signed-off-by: Andrii Nakryiko <andrii@kernel.org>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Yonghong Song <yhs@fb.com>
	Acked-by: Hao Luo <haoluo@google.com>
Link: https://lore.kernel.org/bpf/20210112075520.4103414-6-andrii@kernel.org
(cherry picked from commit 541c3bad8dc51b253ba8686d0cd7628e6b9b5f4c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
#	include/linux/btf.h
#	kernel/bpf/btf.c
#	kernel/bpf/verifier.c
diff --cc include/linux/bpf.h
index e31890dda3c2,1aac2af12fed..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -767,13 -761,18 +767,19 @@@ struct bpf_ctx_arg_aux 
  	u32 btf_id;
  };
  
+ struct btf_mod_pair {
+ 	struct btf *btf;
+ 	struct module *module;
+ };
+ 
  struct bpf_prog_aux {
 -	atomic64_t refcnt;
 +	RH_KABI_BROKEN_REPLACE(atomic_t refcnt, atomic64_t refcnt)
  	u32 used_map_cnt;
+ 	u32 used_btf_cnt;
  	u32 max_ctx_offset;
 -	u32 max_pkt_offset;
 -	u32 max_tp_access;
 +	/* not protected by KABI, safe to extend in the middle */
 +	RH_KABI_BROKEN_INSERT(u32 max_pkt_offset)
 +	RH_KABI_BROKEN_INSERT(u32 max_tp_access)
  	u32 stack_depth;
  	u32 id;
  	u32 func_cnt; /* used by non-func prog as the number of func progs */
@@@ -789,29 -788,27 +795,34 @@@
  	struct bpf_trampoline *dst_trampoline;
  	enum bpf_prog_type saved_dst_prog_type;
  	enum bpf_attach_type saved_dst_attach_type;
 -	bool verifier_zext; /* Zero extensions has been inserted by verifier. */
 +	) /* RH_KABI_BROKEN_INSERT_BLOCK */
 +	RH_KABI_BROKEN_INSERT(bool verifier_zext) /* Zero extensions has been inserted by verifier. */
  	bool offload_requested;
 -	bool attach_btf_trace; /* true if attaching to BTF-enabled raw tp */
 -	bool func_proto_unreliable;
 -	bool sleepable;
 -	bool tail_call_reachable;
 -	enum bpf_tramp_prog_type trampoline_prog_type;
 -	struct hlist_node tramp_hlist;
 +	RH_KABI_BROKEN_INSERT(bool attach_btf_trace) /* true if attaching to BTF-enabled raw tp */
 +	RH_KABI_BROKEN_INSERT(bool func_proto_unreliable)
 +	RH_KABI_BROKEN_INSERT(bool sleepable)
 +	RH_KABI_BROKEN_INSERT(bool tail_call_reachable)
 +	RH_KABI_BROKEN_INSERT(enum bpf_tramp_prog_type trampoline_prog_type)
 +	RH_KABI_BROKEN_INSERT(struct hlist_node tramp_hlist)
  	/* BTF_KIND_FUNC_PROTO for valid attach_btf_id */
 -	const struct btf_type *attach_func_proto;
 +	RH_KABI_BROKEN_INSERT(const struct btf_type *attach_func_proto)
  	/* function name for valid attach_btf_id */
 -	const char *attach_func_name;
 +	RH_KABI_BROKEN_INSERT(const char *attach_func_name)
  	struct bpf_prog **func;
  	void *jit_data; /* JIT specific data. arch dependent */
 -	struct bpf_jit_poke_descriptor *poke_tab;
 -	u32 size_poke_tab;
 -	struct bpf_ksym ksym;
 +	RH_KABI_BROKEN_INSERT(struct bpf_jit_poke_descriptor *poke_tab)
 +	RH_KABI_BROKEN_INSERT(u32 size_poke_tab)
 +	RH_KABI_BROKEN_REMOVE(struct latch_tree_node ksym_tnode)
 +	RH_KABI_BROKEN_REMOVE(struct list_head ksym_lnode)
 +	RH_KABI_BROKEN_INSERT(struct bpf_ksym ksym)
  	const struct bpf_prog_ops *ops;
  	struct bpf_map **used_maps;
++<<<<<<< HEAD
 +	RH_KABI_BROKEN_INSERT(struct mutex used_maps_mutex) /* mutex for used_maps and used_map_cnt */
++=======
+ 	struct mutex used_maps_mutex; /* mutex for used_maps and used_map_cnt */
+ 	struct btf_mod_pair *used_btfs;
++>>>>>>> 541c3bad8dc5 (bpf: Support BPF ksym variables in kernel modules)
  	struct bpf_prog *prog;
  	struct user_struct *user;
  	u64 load_time; /* ns since boottime */
diff --cc include/linux/btf.h
index 2bf641829664,7fabf1428093..000000000000
--- a/include/linux/btf.h
+++ b/include/linux/btf.h
@@@ -88,7 -89,11 +88,15 @@@ int btf_type_snprintf_show(const struc
  			   char *buf, int len, u64 flags);
  
  int btf_get_fd_by_id(u32 id);
++<<<<<<< HEAD
 +u32 btf_id(const struct btf *btf);
++=======
+ u32 btf_obj_id(const struct btf *btf);
+ bool btf_is_kernel(const struct btf *btf);
+ bool btf_is_module(const struct btf *btf);
+ struct module *btf_try_get_module(const struct btf *btf);
+ u32 btf_nr_types(const struct btf *btf);
++>>>>>>> 541c3bad8dc5 (bpf: Support BPF ksym variables in kernel modules)
  bool btf_member_is_reg_int(const struct btf *btf, const struct btf_type *s,
  			   const struct btf_member *m,
  			   u32 expected_offset, u32 expected_size);
diff --cc kernel/bpf/btf.c
index b89fc7b7da7f,7ccc0133723a..000000000000
--- a/kernel/bpf/btf.c
+++ b/kernel/bpf/btf.c
@@@ -5641,6 -5738,16 +5641,19 @@@ u32 btf_id(const struct btf *btf
  	return btf->id;
  }
  
++<<<<<<< HEAD
++=======
+ bool btf_is_kernel(const struct btf *btf)
+ {
+ 	return btf->kernel_btf;
+ }
+ 
+ bool btf_is_module(const struct btf *btf)
+ {
+ 	return btf->kernel_btf && strcmp(btf->name, "vmlinux") != 0;
+ }
+ 
++>>>>>>> 541c3bad8dc5 (bpf: Support BPF ksym variables in kernel modules)
  static int btf_id_cmp_func(const void *a, const void *b)
  {
  	const int *pa = a, *pb = b;
@@@ -5652,3 -5759,148 +5665,151 @@@ bool btf_id_set_contains(const struct b
  {
  	return bsearch(&id, set->ids, set->cnt, sizeof(u32), btf_id_cmp_func) != NULL;
  }
++<<<<<<< HEAD
++=======
+ 
+ #ifdef CONFIG_DEBUG_INFO_BTF_MODULES
+ struct btf_module {
+ 	struct list_head list;
+ 	struct module *module;
+ 	struct btf *btf;
+ 	struct bin_attribute *sysfs_attr;
+ };
+ 
+ static LIST_HEAD(btf_modules);
+ static DEFINE_MUTEX(btf_module_mutex);
+ 
+ static ssize_t
+ btf_module_read(struct file *file, struct kobject *kobj,
+ 		struct bin_attribute *bin_attr,
+ 		char *buf, loff_t off, size_t len)
+ {
+ 	const struct btf *btf = bin_attr->private;
+ 
+ 	memcpy(buf, btf->data + off, len);
+ 	return len;
+ }
+ 
+ static int btf_module_notify(struct notifier_block *nb, unsigned long op,
+ 			     void *module)
+ {
+ 	struct btf_module *btf_mod, *tmp;
+ 	struct module *mod = module;
+ 	struct btf *btf;
+ 	int err = 0;
+ 
+ 	if (mod->btf_data_size == 0 ||
+ 	    (op != MODULE_STATE_COMING && op != MODULE_STATE_GOING))
+ 		goto out;
+ 
+ 	switch (op) {
+ 	case MODULE_STATE_COMING:
+ 		btf_mod = kzalloc(sizeof(*btf_mod), GFP_KERNEL);
+ 		if (!btf_mod) {
+ 			err = -ENOMEM;
+ 			goto out;
+ 		}
+ 		btf = btf_parse_module(mod->name, mod->btf_data, mod->btf_data_size);
+ 		if (IS_ERR(btf)) {
+ 			pr_warn("failed to validate module [%s] BTF: %ld\n",
+ 				mod->name, PTR_ERR(btf));
+ 			kfree(btf_mod);
+ 			err = PTR_ERR(btf);
+ 			goto out;
+ 		}
+ 		err = btf_alloc_id(btf);
+ 		if (err) {
+ 			btf_free(btf);
+ 			kfree(btf_mod);
+ 			goto out;
+ 		}
+ 
+ 		mutex_lock(&btf_module_mutex);
+ 		btf_mod->module = module;
+ 		btf_mod->btf = btf;
+ 		list_add(&btf_mod->list, &btf_modules);
+ 		mutex_unlock(&btf_module_mutex);
+ 
+ 		if (IS_ENABLED(CONFIG_SYSFS)) {
+ 			struct bin_attribute *attr;
+ 
+ 			attr = kzalloc(sizeof(*attr), GFP_KERNEL);
+ 			if (!attr)
+ 				goto out;
+ 
+ 			sysfs_bin_attr_init(attr);
+ 			attr->attr.name = btf->name;
+ 			attr->attr.mode = 0444;
+ 			attr->size = btf->data_size;
+ 			attr->private = btf;
+ 			attr->read = btf_module_read;
+ 
+ 			err = sysfs_create_bin_file(btf_kobj, attr);
+ 			if (err) {
+ 				pr_warn("failed to register module [%s] BTF in sysfs: %d\n",
+ 					mod->name, err);
+ 				kfree(attr);
+ 				err = 0;
+ 				goto out;
+ 			}
+ 
+ 			btf_mod->sysfs_attr = attr;
+ 		}
+ 
+ 		break;
+ 	case MODULE_STATE_GOING:
+ 		mutex_lock(&btf_module_mutex);
+ 		list_for_each_entry_safe(btf_mod, tmp, &btf_modules, list) {
+ 			if (btf_mod->module != module)
+ 				continue;
+ 
+ 			list_del(&btf_mod->list);
+ 			if (btf_mod->sysfs_attr)
+ 				sysfs_remove_bin_file(btf_kobj, btf_mod->sysfs_attr);
+ 			btf_put(btf_mod->btf);
+ 			kfree(btf_mod->sysfs_attr);
+ 			kfree(btf_mod);
+ 			break;
+ 		}
+ 		mutex_unlock(&btf_module_mutex);
+ 		break;
+ 	}
+ out:
+ 	return notifier_from_errno(err);
+ }
+ 
+ static struct notifier_block btf_module_nb = {
+ 	.notifier_call = btf_module_notify,
+ };
+ 
+ static int __init btf_module_init(void)
+ {
+ 	register_module_notifier(&btf_module_nb);
+ 	return 0;
+ }
+ 
+ fs_initcall(btf_module_init);
+ #endif /* CONFIG_DEBUG_INFO_BTF_MODULES */
+ 
+ struct module *btf_try_get_module(const struct btf *btf)
+ {
+ 	struct module *res = NULL;
+ #ifdef CONFIG_DEBUG_INFO_BTF_MODULES
+ 	struct btf_module *btf_mod, *tmp;
+ 
+ 	mutex_lock(&btf_module_mutex);
+ 	list_for_each_entry_safe(btf_mod, tmp, &btf_modules, list) {
+ 		if (btf_mod->btf != btf)
+ 			continue;
+ 
+ 		if (try_module_get(btf_mod->module))
+ 			res = btf_mod->module;
+ 
+ 		break;
+ 	}
+ 	mutex_unlock(&btf_module_mutex);
+ #endif
+ 
+ 	return res;
+ }
++>>>>>>> 541c3bad8dc5 (bpf: Support BPF ksym variables in kernel modules)
diff --cc kernel/bpf/verifier.c
index 628ac51f9efd,ae2aee48cf82..000000000000
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@@ -9743,9 -9803,10 +9782,13 @@@ static int check_pseudo_btf_id(struct b
  	insn[1].imm = addr >> 32;
  
  	type = t->type;
- 	t = btf_type_skip_modifiers(btf_vmlinux, type, NULL);
+ 	t = btf_type_skip_modifiers(btf, type, NULL);
  	if (percpu) {
  		aux->btf_var.reg_type = PTR_TO_PERCPU_BTF_ID;
++<<<<<<< HEAD
++=======
+ 		aux->btf_var.btf = btf;
++>>>>>>> 541c3bad8dc5 (bpf: Support BPF ksym variables in kernel modules)
  		aux->btf_var.btf_id = type;
  	} else if (!btf_type_is_struct(t)) {
  		const struct btf_type *ret;
@@@ -9764,9 -9826,42 +9808,45 @@@
  		aux->btf_var.mem_size = tsize;
  	} else {
  		aux->btf_var.reg_type = PTR_TO_BTF_ID;
++<<<<<<< HEAD
++=======
+ 		aux->btf_var.btf = btf;
++>>>>>>> 541c3bad8dc5 (bpf: Support BPF ksym variables in kernel modules)
  		aux->btf_var.btf_id = type;
  	}
+ 
+ 	/* check whether we recorded this BTF (and maybe module) already */
+ 	for (i = 0; i < env->used_btf_cnt; i++) {
+ 		if (env->used_btfs[i].btf == btf) {
+ 			btf_put(btf);
+ 			return 0;
+ 		}
+ 	}
+ 
+ 	if (env->used_btf_cnt >= MAX_USED_BTFS) {
+ 		err = -E2BIG;
+ 		goto err_put;
+ 	}
+ 
+ 	btf_mod = &env->used_btfs[env->used_btf_cnt];
+ 	btf_mod->btf = btf;
+ 	btf_mod->module = NULL;
+ 
+ 	/* if we reference variables from kernel module, bump its refcount */
+ 	if (btf_is_module(btf)) {
+ 		btf_mod->module = btf_try_get_module(btf);
+ 		if (!btf_mod->module) {
+ 			err = -ENXIO;
+ 			goto err_put;
+ 		}
+ 	}
+ 
+ 	env->used_btf_cnt++;
+ 
  	return 0;
+ err_put:
+ 	btf_put(btf);
+ 	return err;
  }
  
  static int check_map_prealloc(struct bpf_map *map)
* Unmerged path include/linux/bpf.h
diff --git a/include/linux/bpf_verifier.h b/include/linux/bpf_verifier.h
index 306869d4743b..b530970845c0 100644
--- a/include/linux/bpf_verifier.h
+++ b/include/linux/bpf_verifier.h
@@ -329,6 +329,7 @@ struct bpf_insn_aux_data {
 };
 
 #define MAX_USED_MAPS 64 /* max number of maps accessed by one eBPF program */
+#define MAX_USED_BTFS 64 /* max number of BTFs accessed by one BPF program */
 
 #define BPF_VERIFIER_TMP_LOG_SIZE	1024
 
@@ -387,7 +388,9 @@ struct bpf_verifier_env {
 	struct bpf_verifier_state_list **explored_states; /* search pruning optimization */
 	struct bpf_verifier_state_list *free_list;
 	struct bpf_map *used_maps[MAX_USED_MAPS]; /* array of map's used by eBPF program */
+	struct btf_mod_pair used_btfs[MAX_USED_BTFS]; /* array of BTF's used by BPF program */
 	u32 used_map_cnt;		/* number of used maps */
+	u32 used_btf_cnt;		/* number of used BTF objects */
 	u32 id_gen;			/* used to generate unique reg IDs */
 	bool allow_ptr_leaks;
 	bool allow_ptr_to_map_access;
* Unmerged path include/linux/btf.h
* Unmerged path kernel/bpf/btf.c
diff --git a/kernel/bpf/core.c b/kernel/bpf/core.c
index a915516dd706..726376900c1e 100644
--- a/kernel/bpf/core.c
+++ b/kernel/bpf/core.c
@@ -2132,6 +2132,28 @@ static void bpf_free_used_maps(struct bpf_prog_aux *aux)
 	kfree(aux->used_maps);
 }
 
+void __bpf_free_used_btfs(struct bpf_prog_aux *aux,
+			  struct btf_mod_pair *used_btfs, u32 len)
+{
+#ifdef CONFIG_BPF_SYSCALL
+	struct btf_mod_pair *btf_mod;
+	u32 i;
+
+	for (i = 0; i < len; i++) {
+		btf_mod = &used_btfs[i];
+		if (btf_mod->module)
+			module_put(btf_mod->module);
+		btf_put(btf_mod->btf);
+	}
+#endif
+}
+
+static void bpf_free_used_btfs(struct bpf_prog_aux *aux)
+{
+	__bpf_free_used_btfs(aux, aux->used_btfs, aux->used_btf_cnt);
+	kfree(aux->used_btfs);
+}
+
 static void bpf_prog_free_deferred(struct work_struct *work)
 {
 	struct bpf_prog_aux *aux;
@@ -2139,6 +2161,7 @@ static void bpf_prog_free_deferred(struct work_struct *work)
 
 	aux = container_of(work, struct bpf_prog_aux, work);
 	bpf_free_used_maps(aux);
+	bpf_free_used_btfs(aux);
 	if (bpf_prog_is_dev_bound(aux))
 		bpf_prog_offload_destroy(aux->prog);
 #ifdef CONFIG_PERF_EVENTS
* Unmerged path kernel/bpf/verifier.c
