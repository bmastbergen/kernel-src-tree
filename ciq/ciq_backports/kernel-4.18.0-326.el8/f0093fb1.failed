RDMA/mlx5: Move mlx5_ib_cont_pages() to the creation of the mlx5_ib_mr

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Jason Gunthorpe <jgg@nvidia.com>
commit f0093fb1a7cbff4bbfa47c1499a9e76f75359dbe
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/f0093fb1.failed

For the user MR path, instead of calling this after getting the umem, call
it as part of creating the struct mlx5_ib_mr and distill its output to a
single page_shift stored inside the mr.

This avoids passing around the tuple of its output. Based on the umem and
page_shift, the output arguments can be computed using:

  count == ib_umem_num_pages(mr->umem)
  shift == mr->page_shift
  ncont == ib_umem_num_dma_blocks(mr->umem, 1 << mr->page_shift)
  order == order_base_2(ncont)

And since mr->page_shift == umem_odp->page_shift then ncont ==
ib_umem_num_dma_blocks() == ib_umem_odp_num_pages() for ODP umems.

Link: https://lore.kernel.org/r/20201026131936.1335664-5-leon@kernel.org
	Signed-off-by: Leon Romanovsky <leonro@nvidia.com>
	Signed-off-by: Jason Gunthorpe <jgg@nvidia.com>
(cherry picked from commit f0093fb1a7cbff4bbfa47c1499a9e76f75359dbe)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/mr.c
diff --cc drivers/infiniband/hw/mlx5/mr.c
index 52d81032598e,3a373e1eef2b..000000000000
--- a/drivers/infiniband/hw/mlx5/mr.c
+++ b/drivers/infiniband/hw/mlx5/mr.c
@@@ -868,10 -868,8 +868,15 @@@ static int mr_cache_max_order(struct ml
  	return MLX5_MAX_UMR_SHIFT;
  }
  
++<<<<<<< HEAD
 +static int mr_umem_get(struct mlx5_ib_dev *dev, struct ib_udata *udata,
 +		       u64 start, u64 length, int access_flags,
 +		       struct ib_umem **umem, int *npages, int *page_shift,
 +		       int *ncont, int *order)
++=======
+ static struct ib_umem *mr_umem_get(struct mlx5_ib_dev *dev, u64 start,
+ 				   u64 length, int access_flags)
++>>>>>>> f0093fb1a7cb (RDMA/mlx5: Move mlx5_ib_cont_pages() to the creation of the mlx5_ib_mr)
  {
  	struct ib_umem *u;
  
@@@ -884,39 -881,17 +887,37 @@@
  		if (IS_ERR(odp)) {
  			mlx5_ib_dbg(dev, "umem get failed (%ld)\n",
  				    PTR_ERR(odp));
- 			return PTR_ERR(odp);
+ 			return ERR_CAST(odp);
  		}
++<<<<<<< HEAD
 +
 +		u = &odp->umem;
 +
 +		*page_shift = odp->page_shift;
 +		*ncont = ib_umem_odp_num_pages(odp);
 +		*npages = *ncont << (*page_shift - PAGE_SHIFT);
 +		if (order)
 +			*order = ilog2(roundup_pow_of_two(*ncont));
 +	} else {
 +		u = ib_umem_get(udata, start, length, access_flags);
 +		if (IS_ERR(u)) {
 +			mlx5_ib_dbg(dev, "umem get failed (%ld)\n", PTR_ERR(u));
 +			return PTR_ERR(u);
 +		}
 +
 +		mlx5_ib_cont_pages(u, start, MLX5_MKEY_PAGE_SHIFT_MASK, npages,
 +				   page_shift, ncont, order);
++=======
+ 		return &odp->umem;
++>>>>>>> f0093fb1a7cb (RDMA/mlx5: Move mlx5_ib_cont_pages() to the creation of the mlx5_ib_mr)
  	}
  
- 	if (!*npages) {
- 		mlx5_ib_warn(dev, "avoid zero region\n");
- 		ib_umem_release(u);
- 		return -EINVAL;
+ 	u = ib_umem_get(&dev->ib_dev, start, length, access_flags);
+ 	if (IS_ERR(u)) {
+ 		mlx5_ib_dbg(dev, "umem get failed (%ld)\n", PTR_ERR(u));
+ 		return u;
  	}
- 
- 	*umem = u;
- 
- 	mlx5_ib_dbg(dev, "npages %d, ncont %d, order %d, page_shift %d\n",
- 		    *npages, *ncont, *order, *page_shift);
- 
- 	return 0;
+ 	return u;
  }
  
  static void mlx5_ib_umr_done(struct ib_cq *cq, struct ib_wc *wc)
@@@ -1388,15 -1372,12 +1397,20 @@@ struct ib_mr *mlx5_ib_reg_user_mr(struc
  		return &mr->ibmr;
  	}
  
++<<<<<<< HEAD
 +	err = mr_umem_get(dev, udata, start, length, access_flags, &umem,
 +			  &npages, &page_shift, &ncont, &order);
 +
 +	if (err < 0)
 +		return ERR_PTR(err);
++=======
+ 	umem = mr_umem_get(dev, start, length, access_flags);
+ 	if (IS_ERR(umem))
+ 		return ERR_CAST(umem);
++>>>>>>> f0093fb1a7cb (RDMA/mlx5: Move mlx5_ib_cont_pages() to the creation of the mlx5_ib_mr)
  
  	if (xlt_with_umr) {
- 		mr = alloc_mr_from_cache(pd, umem, virt_addr, length, ncont,
- 					 page_shift, order, access_flags);
+ 		mr = alloc_mr_from_cache(pd, umem, virt_addr, access_flags);
  		if (IS_ERR(mr))
  			mr = NULL;
  	}
@@@ -1427,11 -1408,10 +1441,18 @@@
  		 */
  		int update_xlt_flags = MLX5_IB_UPD_XLT_ENABLE;
  
++<<<<<<< HEAD
 +		if (access_flags & IB_ACCESS_ON_DEMAND)
 +			update_xlt_flags |= MLX5_IB_UPD_XLT_ZAP;
 +
 +		err = mlx5_ib_update_xlt(mr, 0, ncont, page_shift,
 +					 update_xlt_flags);
++=======
+ 		err = mlx5_ib_update_xlt(
+ 			mr, 0,
+ 			ib_umem_num_dma_blocks(umem, 1UL << mr->page_shift),
+ 			mr->page_shift, update_xlt_flags);
++>>>>>>> f0093fb1a7cb (RDMA/mlx5: Move mlx5_ib_cont_pages() to the creation of the mlx5_ib_mr)
  		if (err) {
  			dereg_mr(dev, mr);
  			return ERR_PTR(err);
@@@ -1550,13 -1531,12 +1567,21 @@@ struct ib_mr *mlx5_ib_rereg_user_mr(str
  		atomic_sub(ib_umem_num_pages(mr->umem),
  			   &dev->mdev->priv.reg_pages);
  		ib_umem_release(mr->umem);
++<<<<<<< HEAD
 +		mr->umem = NULL;
 +
 +		err = mr_umem_get(dev, udata, addr, len, access_flags,
 +				  &mr->umem, &npages, &page_shift, &ncont,
 +				  &order);
 +		if (err)
++=======
+ 		mr->umem = mr_umem_get(dev, addr, len, access_flags);
+ 		if (IS_ERR(mr->umem)) {
+ 			err = PTR_ERR(mr->umem);
+ 			mr->umem = NULL;
++>>>>>>> f0093fb1a7cb (RDMA/mlx5: Move mlx5_ib_cont_pages() to the creation of the mlx5_ib_mr)
  			goto err;
+ 		}
  		atomic_add(ib_umem_num_pages(mr->umem),
  			   &dev->mdev->priv.reg_pages);
  	}
diff --git a/drivers/infiniband/hw/mlx5/mem.c b/drivers/infiniband/hw/mlx5/mem.c
index 13de3d2edd34..e63af1b05c0b 100644
--- a/drivers/infiniband/hw/mlx5/mem.c
+++ b/drivers/infiniband/hw/mlx5/mem.c
@@ -57,6 +57,17 @@ void mlx5_ib_cont_pages(struct ib_umem *umem, u64 addr,
 	struct scatterlist *sg;
 	int entry;
 
+	if (umem->is_odp) {
+		struct ib_umem_odp *odp = to_ib_umem_odp(umem);
+
+		*shift = odp->page_shift;
+		*ncont = ib_umem_odp_num_pages(odp);
+		*count = *ncont << (*shift - PAGE_SHIFT);
+		if (order)
+			*order = ilog2(roundup_pow_of_two(*count));
+		return;
+	}
+
 	addr = addr >> PAGE_SHIFT;
 	tmp = (unsigned long)addr;
 	m = find_first_bit(&tmp, BITS_PER_LONG);
diff --git a/drivers/infiniband/hw/mlx5/mlx5_ib.h b/drivers/infiniband/hw/mlx5/mlx5_ib.h
index 5e47304abc75..2cb1381a3185 100644
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -597,6 +597,7 @@ struct mlx5_ib_mr {
 	int			max_descs;
 	int			desc_size;
 	int			access_mode;
+	unsigned int		page_shift;
 	struct mlx5_core_mkey	mmkey;
 	struct ib_umem	       *umem;
 	struct mlx5_shared_mr_info	*smr_info;
* Unmerged path drivers/infiniband/hw/mlx5/mr.c
