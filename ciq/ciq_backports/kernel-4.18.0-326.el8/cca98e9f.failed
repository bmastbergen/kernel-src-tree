mm: enforce that vmap can't map pages executable

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Christoph Hellwig <hch@lst.de>
commit cca98e9f8b5ebcd9640846a675172578249b11a0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/cca98e9f.failed

To help enforcing the W^X protection don't allow remapping existing pages
as executable.

x86 bits from Peter Zijlstra, arm64 bits from Mark Rutland.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Mark Rutland <mark.rutland@arm.com>.
	Cc: Christian Borntraeger <borntraeger@de.ibm.com>
	Cc: Christophe Leroy <christophe.leroy@c-s.fr>
	Cc: Daniel Vetter <daniel.vetter@ffwll.ch>
	Cc: David Airlie <airlied@linux.ie>
	Cc: Gao Xiang <xiang@kernel.org>
	Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
	Cc: Haiyang Zhang <haiyangz@microsoft.com>
	Cc: Johannes Weiner <hannes@cmpxchg.org>
	Cc: "K. Y. Srinivasan" <kys@microsoft.com>
	Cc: Laura Abbott <labbott@redhat.com>
	Cc: Michael Kelley <mikelley@microsoft.com>
	Cc: Minchan Kim <minchan@kernel.org>
	Cc: Nitin Gupta <ngupta@vflare.org>
	Cc: Robin Murphy <robin.murphy@arm.com>
	Cc: Sakari Ailus <sakari.ailus@linux.intel.com>
	Cc: Stephen Hemminger <sthemmin@microsoft.com>
	Cc: Sumit Semwal <sumit.semwal@linaro.org>
	Cc: Wei Liu <wei.liu@kernel.org>
	Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
	Cc: Paul Mackerras <paulus@ozlabs.org>
	Cc: Vasily Gorbik <gor@linux.ibm.com>
	Cc: Will Deacon <will@kernel.org>
Link: http://lkml.kernel.org/r/20200414131348.444715-20-hch@lst.de
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit cca98e9f8b5ebcd9640846a675172578249b11a0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/pgtable_types.h
diff --cc arch/x86/include/asm/pgtable_types.h
index 763e7c46d403,2e7c442cc618..000000000000
--- a/arch/x86/include/asm/pgtable_types.h
+++ b/arch/x86/include/asm/pgtable_types.h
@@@ -284,9 -282,38 +284,41 @@@ typedef struct pgprot { pgprotval_t pgp
  
  typedef struct { pgdval_t pgd; } pgd_t;
  
++<<<<<<< HEAD
++=======
+ static inline pgprot_t pgprot_nx(pgprot_t prot)
+ {
+ 	return __pgprot(pgprot_val(prot) | _PAGE_NX);
+ }
+ #define pgprot_nx pgprot_nx
+ 
+ #ifdef CONFIG_X86_PAE
+ 
+ /*
+  * PHYSICAL_PAGE_MASK might be non-constant when SME is compiled in, so we can't
+  * use it here.
+  */
+ 
+ #define PGD_PAE_PAGE_MASK	((signed long)PAGE_MASK)
+ #define PGD_PAE_PHYS_MASK	(((1ULL << __PHYSICAL_MASK_SHIFT)-1) & PGD_PAE_PAGE_MASK)
+ 
+ /*
+  * PAE allows Base Address, P, PWT, PCD and AVL bits to be set in PGD entries.
+  * All other bits are Reserved MBZ
+  */
+ #define PGD_ALLOWED_BITS	(PGD_PAE_PHYS_MASK | _PAGE_PRESENT | \
+ 				 _PAGE_PWT | _PAGE_PCD | \
+ 				 _PAGE_SOFTW1 | _PAGE_SOFTW2 | _PAGE_SOFTW3)
+ 
+ #else
+ /* No need to mask any bits for !PAE */
+ #define PGD_ALLOWED_BITS	(~0ULL)
+ #endif
+ 
++>>>>>>> cca98e9f8b5e (mm: enforce that vmap can't map pages executable)
  static inline pgd_t native_make_pgd(pgdval_t val)
  {
 -	return (pgd_t) { val & PGD_ALLOWED_BITS };
 +	return (pgd_t) { val };
  }
  
  static inline pgdval_t native_pgd_val(pgd_t pgd)
diff --git a/arch/arm64/include/asm/pgtable.h b/arch/arm64/include/asm/pgtable.h
index 944b75b79d2a..12bf5921121f 100644
--- a/arch/arm64/include/asm/pgtable.h
+++ b/arch/arm64/include/asm/pgtable.h
@@ -409,6 +409,9 @@ static inline int pmd_protnone(pmd_t pmd)
 #define __pgprot_modify(prot,mask,bits) \
 	__pgprot((pgprot_val(prot) & ~(mask)) | (bits))
 
+#define pgprot_nx(prot) \
+	__pgprot_modify(prot, 0, PTE_PXN)
+
 /*
  * Mark the prot value as uncacheable and unbufferable.
  */
* Unmerged path arch/x86/include/asm/pgtable_types.h
diff --git a/include/asm-generic/pgtable.h b/include/asm-generic/pgtable.h
index 28cf42afd028..7f8e3fa789f3 100644
--- a/include/asm-generic/pgtable.h
+++ b/include/asm-generic/pgtable.h
@@ -491,6 +491,10 @@ static inline int arch_unmap_one(struct mm_struct *mm,
 #define flush_tlb_fix_spurious_fault(vma, address) flush_tlb_page(vma, address)
 #endif
 
+#ifndef pgprot_nx
+#define pgprot_nx(prot)	(prot)
+#endif
+
 #ifndef pgprot_noncached
 #define pgprot_noncached(prot)	(prot)
 #endif
diff --git a/mm/vmalloc.c b/mm/vmalloc.c
index f96cc57dc6f0..28018b3470ac 100644
--- a/mm/vmalloc.c
+++ b/mm/vmalloc.c
@@ -2353,7 +2353,7 @@ void *vmap(struct page **pages, unsigned int count,
 	if (!area)
 		return NULL;
 
-	if (map_kernel_range((unsigned long)area->addr, size, prot,
+	if (map_kernel_range((unsigned long)area->addr, size, pgprot_nx(prot),
 			pages) < 0) {
 		vunmap(area->addr);
 		return NULL;
