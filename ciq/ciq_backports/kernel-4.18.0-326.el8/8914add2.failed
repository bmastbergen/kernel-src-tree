net/mlx5e: Handle FIB events to update tunnel endpoint device

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Vlad Buslov <vladbu@nvidia.com>
commit 8914add2c9e5518f6a864936658bba5752510b39
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/8914add2.failed

Process FIB route update events to dynamically update the stack device
rules when tunnel routing changes. Use rtnl lock to prevent FIB event
handler from running concurrently with neigh update and neigh stats
workqueue tasks. Use encap_tbl_lock mutex to synchronize with TC rule
update path that doesn't use rtnl lock.

FIB event workflow for encap flows:

- Unoffload all flows attached to route encaps from slow or fast path
depending on encap destination endpoint neigh state.

- Update encap IP header according to new route dev.

- Update flows mod_hdr action that is responsible for overwriting reg_c0
source port bits to source port of new underlying VF of new route dev. This
step requires changing flow create/delete code to save flow parse attribute
mod_hdr_acts structure for whole flow lifetime instead of deallocating it
after flow creation. Refactor mod_hdr code to allow saving id of individual
mod_hdr actions and updating them with dedicated helper.

- Offload all flows to either slow or fast path depending on encap
destination endpoint neigh state.

FIB event workflow for decap flows:

- Unoffload all route flows from hardware. When last route flow is deleted
all indirect table rules for the route dev will also be deleted.

- Update flow attr decap_vport and destination MAC according to underlying
VF of new rote dev.

- Offload all route flows back to hardware creating new indirect table
rules according to updated flow attribute data.

Extract some neigh update code to helper functions to be used by both neigh
update and route update infrastructure.

	Signed-off-by: Vlad Buslov <vladbu@nvidia.com>
	Signed-off-by: Dmytro Linkin <dlinkin@nvidia.com>
	Reviewed-by: Roi Dayan <roid@nvidia.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit 8914add2c9e5518f6a864936658bba5752510b39)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en/tc_priv.h
#	drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c
#	drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.h
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index 00c2a6fd4471,db142ee96510..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -1282,9 -1305,16 +1283,19 @@@ mlx5e_tc_add_fdb_flow(struct mlx5e_pri
  	if (attr->prio > max_prio) {
  		NL_SET_ERR_MSG_MOD(extack,
  				   "Requested priority is out of supported range");
- 		return -EOPNOTSUPP;
+ 		err = -EOPNOTSUPP;
+ 		goto err_out;
+ 	}
+ 
++<<<<<<< HEAD
++=======
+ 	if (flow_flag_test(flow, TUN_RX)) {
+ 		err = mlx5e_attach_decap_route(priv, flow);
+ 		if (err)
+ 			goto err_out;
  	}
  
++>>>>>>> 8914add2c9e5 (net/mlx5e: Handle FIB events to update tunnel endpoint device)
  	if (flow_flag_test(flow, L3_TO_L2_DECAP)) {
  		err = mlx5e_attach_decap(priv, flow, extack);
  		if (err)
@@@ -1320,10 -1353,15 +1334,22 @@@
  
  	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR &&
  	    !(attr->ct_attr.ct_action & TCA_CT_ACT_CLEAR)) {
++<<<<<<< HEAD
 +		err = mlx5e_attach_mod_hdr(priv, flow, parse_attr);
 +		dealloc_mod_hdr_actions(&parse_attr->mod_hdr_acts);
 +		if (err)
 +			return err;
++=======
+ 		if (vf_tun) {
+ 			err = mlx5e_tc_add_flow_mod_hdr(priv, parse_attr, flow);
+ 			if (err)
+ 				goto err_out;
+ 		} else {
+ 			err = mlx5e_attach_mod_hdr(priv, flow, parse_attr);
+ 			if (err)
+ 				goto err_out;
+ 		}
++>>>>>>> 8914add2c9e5 (net/mlx5e: Handle FIB events to update tunnel endpoint device)
  	}
  
  	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_COUNT) {
@@@ -1369,8 -1414,11 +1402,13 @@@ static void mlx5e_tc_del_fdb_flow(struc
  {
  	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
  	struct mlx5_flow_attr *attr = flow->attr;
++<<<<<<< HEAD
++=======
+ 	struct mlx5_esw_flow_attr *esw_attr;
+ 	bool vf_tun = false;
++>>>>>>> 8914add2c9e5 (net/mlx5e: Handle FIB events to update tunnel endpoint device)
  	int out_index;
  
 -	esw_attr = attr->esw_attr;
  	mlx5e_put_flow_tunnel_id(flow);
  
  	if (flow_flag_test(flow, NOT_READY))
@@@ -1388,20 -1436,33 +1426,47 @@@
  
  	mlx5_eswitch_del_vlan_action(esw, attr);
  
++<<<<<<< HEAD
 +	for (out_index = 0; out_index < MLX5_MAX_FLOW_FWD_VPORTS; out_index++)
 +		if (attr->esw_attr->dests[out_index].flags & MLX5_ESW_DEST_ENCAP) {
 +			mlx5e_detach_encap(priv, flow, out_index);
 +			kfree(attr->parse_attr->tun_info[out_index]);
 +		}
 +	kvfree(attr->parse_attr);
++=======
+ 	if (flow->decap_route)
+ 		mlx5e_detach_decap_route(priv, flow);
+ 
+ 	for (out_index = 0; out_index < MLX5_MAX_FLOW_FWD_VPORTS; out_index++) {
+ 		if (esw_attr->dests[out_index].flags &
+ 		    MLX5_ESW_DEST_CHAIN_WITH_SRC_PORT_CHANGE)
+ 			vf_tun = true;
+ 		if (esw_attr->dests[out_index].flags & MLX5_ESW_DEST_ENCAP) {
+ 			mlx5e_detach_encap(priv, flow, out_index);
+ 			kfree(attr->parse_attr->tun_info[out_index]);
+ 		}
+ 	}
++>>>>>>> 8914add2c9e5 (net/mlx5e: Handle FIB events to update tunnel endpoint device)
  
 -	mlx5_tc_ct_match_del(get_ct_priv(priv), &flow->attr->ct_attr);
 +	mlx5_tc_ct_match_del(priv, &flow->attr->ct_attr);
  
++<<<<<<< HEAD
 +	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR)
 +		mlx5e_detach_mod_hdr(priv, flow);
++=======
+ 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR) {
+ 		dealloc_mod_hdr_actions(&attr->parse_attr->mod_hdr_acts);
+ 		if (vf_tun && attr->modify_hdr)
+ 			mlx5_modify_header_dealloc(priv->mdev, attr->modify_hdr);
+ 		else
+ 			mlx5e_detach_mod_hdr(priv, flow);
+ 	}
+ 	kvfree(attr->parse_attr);
+ 	kvfree(attr->esw_attr->rx_tun_attr);
++>>>>>>> 8914add2c9e5 (net/mlx5e: Handle FIB events to update tunnel endpoint device)
  
  	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_COUNT)
 -		mlx5_fc_destroy(esw_attr->counter_dev, attr->counter);
 +		mlx5_fc_destroy(attr->esw_attr->counter_dev, attr->counter);
  
  	if (flow_flag_test(flow, L3_TO_L2_DECAP))
  		mlx5e_detach_decap(priv, flow);
@@@ -4759,9 -4213,9 +4823,10 @@@ mlx5e_add_nic_flow(struct mlx5e_priv *p
  	return 0;
  
  err_free:
+ 	flow_flag_set(flow, FAILED);
  	dealloc_mod_hdr_actions(&parse_attr->mod_hdr_acts);
  	mlx5e_flow_put(priv, flow);
 +	kvfree(parse_attr);
  out:
  	return err;
  }
@@@ -5299,9 -4773,11 +5370,14 @@@ void mlx5e_tc_esw_cleanup(struct rhasht
  {
  	struct mlx5_rep_uplink_priv *uplink_priv;
  
+ 	uplink_priv = container_of(tc_ht, struct mlx5_rep_uplink_priv, tc_ht);
++<<<<<<< HEAD
++=======
+ 
  	rhashtable_free_and_destroy(tc_ht, _mlx5e_tc_del_flow, NULL);
+ 	mlx5e_tc_tun_cleanup(uplink_priv->encap);
  
- 	uplink_priv = container_of(tc_ht, struct mlx5_rep_uplink_priv, tc_ht);
++>>>>>>> 8914add2c9e5 (net/mlx5e: Handle FIB events to update tunnel endpoint device)
  	mapping_destroy(uplink_priv->tunnel_enc_opts_mapping);
  	mapping_destroy(uplink_priv->tunnel_mapping);
  
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
index d7bf5ced61fa,aba17835465b..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@@ -1794,11 -1827,12 +1794,15 @@@ int mlx5_eswitch_init(struct mlx5_core_
  
  	mutex_init(&esw->offloads.encap_tbl_lock);
  	hash_init(esw->offloads.encap_tbl);
 +	mlx5e_mod_hdr_tbl_init(&esw->offloads.mod_hdr);
  	mutex_init(&esw->offloads.decap_tbl_lock);
  	hash_init(esw->offloads.decap_tbl);
++<<<<<<< HEAD
++=======
+ 	mlx5e_mod_hdr_tbl_init(&esw->offloads.mod_hdr);
++>>>>>>> 8914add2c9e5 (net/mlx5e: Handle FIB events to update tunnel endpoint device)
  	atomic64_set(&esw->offloads.num_flows, 0);
  	ida_init(&esw->offloads.vport_metadata_ida);
 -	xa_init_flags(&esw->offloads.vhca_map, XA_FLAGS_ALLOC);
  	mutex_init(&esw->state_lock);
  	mutex_init(&esw->mode_lock);
  
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_priv.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_priv.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_encap.h
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.h b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
index 988195ab1c54..ee154fbab595 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
@@ -59,6 +59,8 @@ struct mlx5e_neigh_update_table {
 
 struct mlx5_tc_ct_priv;
 struct mlx5e_rep_bond;
+struct mlx5e_tc_tun_encap;
+
 struct mlx5_rep_uplink_priv {
 	/* Filters DB - instantiated by the uplink representor and shared by
 	 * the uplink's VFs
@@ -90,6 +92,9 @@ struct mlx5_rep_uplink_priv {
 
 	/* support eswitch vports bonding */
 	struct mlx5e_rep_bond *bond;
+
+	/* tc tunneling encapsulation private data */
+	struct mlx5e_tc_tun_encap *encap;
 };
 
 struct mlx5e_rep_priv {
@@ -153,6 +158,7 @@ enum {
 	/* set when the encap entry is successfully offloaded into HW */
 	MLX5_ENCAP_ENTRY_VALID     = BIT(0),
 	MLX5_REFORMAT_DECAP        = BIT(1),
+	MLX5_ENCAP_ENTRY_NO_ROUTE  = BIT(2),
 };
 
 struct mlx5e_decap_key {
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index a877326fe8ec..7e0d9b7781a5 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@ -416,6 +416,7 @@ struct mlx5_esw_flow_attr {
 		struct mlx5_pkt_reformat *pkt_reformat;
 		struct mlx5_core_dev *mdev;
 		struct mlx5_termtbl_handle *termtbl;
+		int src_port_rewrite_act_id;
 	} dests[MLX5_MAX_FLOW_FWD_VPORTS];
 	struct mlx5_rx_tun_attr *rx_tun_attr;
 	struct mlx5_pkt_reformat *decap_pkt_reformat;
