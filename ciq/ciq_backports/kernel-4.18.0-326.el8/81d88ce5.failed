dma-mapping: remove the {alloc,free}_noncoherent methods

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 81d88ce55092edf1a1f928efb373f289c6b90efd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/81d88ce5.failed

It turns out allowing non-contigous allocations here was a rather bad
idea, as we'll now need to define ways to get the pages for mmaping
or dma_buf sharing.  Revert this change and stick to the original
concept.  A different API for the use case of non-contigous allocations
will be added back later.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Tomasz Figa <tfiga@chromium.org>
	Tested-by: Ricardo Ribalda <ribalda@chromium.org>:wq
(cherry picked from commit 81d88ce55092edf1a1f928efb373f289c6b90efd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/dma-iommu.c
#	include/linux/dma-map-ops.h
#	include/linux/dma-mapping.h
#	kernel/dma/mapping.c
diff --cc drivers/iommu/dma-iommu.c
index fe135a263f73,255533faf905..000000000000
--- a/drivers/iommu/dma-iommu.c
+++ b/drivers/iommu/dma-iommu.c
@@@ -1236,6 -1258,15 +1236,11 @@@ static int iommu_dma_get_sgtable(struc
  static const struct dma_map_ops iommu_dma_ops = {
  	.alloc			= iommu_dma_alloc,
  	.free			= iommu_dma_free,
++<<<<<<< HEAD
++=======
+ 	.alloc_pages		= dma_common_alloc_pages,
+ 	.free_pages		= dma_common_free_pages,
++>>>>>>> 81d88ce55092 (dma-mapping: remove the {alloc,free}_noncoherent methods)
  	.mmap			= iommu_dma_mmap,
  	.get_sgtable		= iommu_dma_get_sgtable,
  	.map_page		= iommu_dma_map_page,
diff --cc include/linux/dma-mapping.h
index ba0c1c793dd8,fbfa3f5abd94..000000000000
--- a/include/linux/dma-mapping.h
+++ b/include/linux/dma-mapping.h
@@@ -392,16 -259,22 +392,35 @@@ static inline unsigned long dma_get_mer
  }
  #endif /* CONFIG_HAS_DMA */
  
++<<<<<<< HEAD
 +static inline void *dma_alloc_noncoherent(struct device *dev, size_t size,
 +		dma_addr_t *dma_handle, enum dma_data_direction dir, gfp_t gfp)
 +{
 +	return dma_alloc_attrs(dev, size, dma_handle, gfp,
 +			DMA_ATTR_NON_CONSISTENT);
 +}
 +static inline void dma_free_noncoherent(struct device *dev, size_t size,
 +		void *vaddr, dma_addr_t dma_handle, enum dma_data_direction dir)
 +{
 +	dma_free_attrs(dev, size, vaddr, dma_handle, DMA_ATTR_NON_CONSISTENT);
++=======
+ struct page *dma_alloc_pages(struct device *dev, size_t size,
+ 		dma_addr_t *dma_handle, enum dma_data_direction dir, gfp_t gfp);
+ void dma_free_pages(struct device *dev, size_t size, struct page *page,
+ 		dma_addr_t dma_handle, enum dma_data_direction dir);
+ 
+ static inline void *dma_alloc_noncoherent(struct device *dev, size_t size,
+ 		dma_addr_t *dma_handle, enum dma_data_direction dir, gfp_t gfp)
+ {
+ 	struct page *page = dma_alloc_pages(dev, size, dma_handle, dir, gfp);
+ 	return page ? page_address(page) : NULL;
+ }
+ 
+ static inline void dma_free_noncoherent(struct device *dev, size_t size,
+ 		void *vaddr, dma_addr_t dma_handle, enum dma_data_direction dir)
+ {
+ 	dma_free_pages(dev, size, virt_to_page(vaddr), dma_handle, dir);
++>>>>>>> 81d88ce55092 (dma-mapping: remove the {alloc,free}_noncoherent methods)
  }
  
  static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,
diff --cc kernel/dma/mapping.c
index 0597cdaee492,68992e35c8c3..000000000000
--- a/kernel/dma/mapping.c
+++ b/kernel/dma/mapping.c
@@@ -528,6 -475,46 +528,49 @@@ void dma_free_attrs(struct device *dev
  }
  EXPORT_SYMBOL(dma_free_attrs);
  
++<<<<<<< HEAD
++=======
+ struct page *dma_alloc_pages(struct device *dev, size_t size,
+ 		dma_addr_t *dma_handle, enum dma_data_direction dir, gfp_t gfp)
+ {
+ 	const struct dma_map_ops *ops = get_dma_ops(dev);
+ 	struct page *page;
+ 
+ 	if (WARN_ON_ONCE(!dev->coherent_dma_mask))
+ 		return NULL;
+ 	if (WARN_ON_ONCE(gfp & (__GFP_DMA | __GFP_DMA32 | __GFP_HIGHMEM)))
+ 		return NULL;
+ 
+ 	size = PAGE_ALIGN(size);
+ 	if (dma_alloc_direct(dev, ops))
+ 		page = dma_direct_alloc_pages(dev, size, dma_handle, dir, gfp);
+ 	else if (ops->alloc_pages)
+ 		page = ops->alloc_pages(dev, size, dma_handle, dir, gfp);
+ 	else
+ 		return NULL;
+ 
+ 	debug_dma_map_page(dev, page, 0, size, dir, *dma_handle);
+ 
+ 	return page;
+ }
+ EXPORT_SYMBOL_GPL(dma_alloc_pages);
+ 
+ void dma_free_pages(struct device *dev, size_t size, struct page *page,
+ 		dma_addr_t dma_handle, enum dma_data_direction dir)
+ {
+ 	const struct dma_map_ops *ops = get_dma_ops(dev);
+ 
+ 	size = PAGE_ALIGN(size);
+ 	debug_dma_unmap_page(dev, dma_handle, size, dir);
+ 
+ 	if (dma_alloc_direct(dev, ops))
+ 		dma_direct_free_pages(dev, size, page, dma_handle, dir);
+ 	else if (ops->free_pages)
+ 		ops->free_pages(dev, size, page, dma_handle, dir);
+ }
+ EXPORT_SYMBOL_GPL(dma_free_pages);
+ 
++>>>>>>> 81d88ce55092 (dma-mapping: remove the {alloc,free}_noncoherent methods)
  int dma_supported(struct device *dev, u64 mask)
  {
  	const struct dma_map_ops *ops = get_dma_ops(dev);
* Unmerged path include/linux/dma-map-ops.h
diff --git a/Documentation/core-api/dma-api.rst b/Documentation/core-api/dma-api.rst
index f7c065be590b..cf4808aa6ed2 100644
--- a/Documentation/core-api/dma-api.rst
+++ b/Documentation/core-api/dma-api.rst
@@ -528,16 +528,14 @@ an I/O device, you should not be using this part of the API.
 
 ::
 
-	void *
-	dma_alloc_noncoherent(struct device *dev, size_t size,
-			dma_addr_t *dma_handle, enum dma_data_direction dir,
-			gfp_t gfp)
+	struct page *
+	dma_alloc_pages(struct device *dev, size_t size, dma_addr_t *dma_handle,
+			enum dma_data_direction dir, gfp_t gfp)
 
-This routine allocates a region of <size> bytes of consistent memory.  It
-returns a pointer to the allocated region (in the processor's virtual address
-space) or NULL if the allocation failed.  The returned memory may or may not
-be in the kernel direct mapping.  Drivers must not call virt_to_page on
-the returned memory region.
+This routine allocates a region of <size> bytes of non-coherent memory.  It
+returns a pointer to first struct page for the region, or NULL if the
+allocation failed. The resulting struct page can be used for everything a
+struct page is suitable for.
 
 It also returns a <dma_handle> which may be cast to an unsigned integer the
 same width as the bus and given to the device as the DMA address base of
@@ -558,51 +556,33 @@ reused.
 ::
 
 	void
-	dma_free_noncoherent(struct device *dev, size_t size, void *cpu_addr,
+	dma_free_pages(struct device *dev, size_t size, struct page *page,
 			dma_addr_t dma_handle, enum dma_data_direction dir)
 
-Free a region of memory previously allocated using dma_alloc_noncoherent().
-dev, size and dma_handle and dir must all be the same as those passed into
-dma_alloc_noncoherent().  cpu_addr must be the virtual address returned by
-dma_alloc_noncoherent().
+Free a region of memory previously allocated using dma_alloc_pages().
+dev, size, dma_handle and dir must all be the same as those passed into
+dma_alloc_pages().  page must be the pointer returned by dma_alloc_pages().
 
 ::
 
-	struct page *
-	dma_alloc_pages(struct device *dev, size_t size, dma_addr_t *dma_handle,
-			enum dma_data_direction dir, gfp_t gfp)
-
-This routine allocates a region of <size> bytes of non-coherent memory.  It
-returns a pointer to first struct page for the region, or NULL if the
-allocation failed. The resulting struct page can be used for everything a
-struct page is suitable for.
-
-It also returns a <dma_handle> which may be cast to an unsigned integer the
-same width as the bus and given to the device as the DMA address base of
-the region.
-
-The dir parameter specified if data is read and/or written by the device,
-see dma_map_single() for details.
-
-The gfp parameter allows the caller to specify the ``GFP_`` flags (see
-kmalloc()) for the allocation, but rejects flags used to specify a memory
-zone such as GFP_DMA or GFP_HIGHMEM.
+	void *
+	dma_alloc_noncoherent(struct device *dev, size_t size,
+			dma_addr_t *dma_handle, enum dma_data_direction dir,
+			gfp_t gfp)
 
-Before giving the memory to the device, dma_sync_single_for_device() needs
-to be called, and before reading memory written by the device,
-dma_sync_single_for_cpu(), just like for streaming DMA mappings that are
-reused.
+This routine is a convenient wrapper around dma_alloc_pages that returns the
+kernel virtual address for the allocated memory instead of the page structure.
 
 ::
 
 	void
-	dma_free_pages(struct device *dev, size_t size, struct page *page,
+	dma_free_noncoherent(struct device *dev, size_t size, void *cpu_addr,
 			dma_addr_t dma_handle, enum dma_data_direction dir)
 
-Free a region of memory previously allocated using dma_alloc_pages().
-dev, size and dma_handle and dir must all be the same as those passed into
-dma_alloc_noncoherent().  page must be the pointer returned by
-dma_alloc_pages().
+Free a region of memory previously allocated using dma_alloc_noncoherent().
+dev, size, dma_handle and dir must all be the same as those passed into
+dma_alloc_noncoherent().  cpu_addr must be the virtual address returned by
+dma_alloc_noncoherent().
 
 ::
 
* Unmerged path drivers/iommu/dma-iommu.c
* Unmerged path include/linux/dma-map-ops.h
* Unmerged path include/linux/dma-mapping.h
* Unmerged path kernel/dma/mapping.c
