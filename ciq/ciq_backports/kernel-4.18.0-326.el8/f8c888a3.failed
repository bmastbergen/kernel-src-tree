mm/hmm: don't handle the non-fault case in hmm_vma_walk_hole_()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Christoph Hellwig <hch@lst.de>
commit f8c888a304e12074d941428b4aa1b13f04dd54ee
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/f8c888a3.failed

Setting a pfns entry to NONE before returning -EBUSY is a bug that will
cause corruption of the input flags on the next loop.

There is just a single caller using hmm_vma_walk_hole_() for the non-fault
case.  Use hmm_pfns_fill() to fill the whole pfn array with zeroes in the
only caller for the non-fault case and remove the non-fault path from
hmm_vma_walk_hole_(). This avoids setting NONE before returning -EBUSY.

Also rename the function to hmm_vma_fault() to better describe what it
does.

Fixes: 2aee09d8c116 ("mm/hmm: change hmm_vma_fault() to allow write fault on page basis")
Link: https://lore.kernel.org/r/20200316135310.899364-5-hch@lst.de
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Jason Gunthorpe <jgg@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit f8c888a304e12074d941428b4aa1b13f04dd54ee)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/hmm.c
diff --cc mm/hmm.c
index 0031a5d7b75b,b15bf4041803..000000000000
--- a/mm/hmm.c
+++ b/mm/hmm.c
@@@ -360,25 -91,23 +360,37 @@@ static int hmm_vma_fault(unsigned long 
  	struct hmm_vma_walk *hmm_vma_walk = walk->private;
  	struct hmm_range *range = hmm_vma_walk->range;
  	uint64_t *pfns = range->pfns;
++<<<<<<< HEAD
 +	unsigned long i, page_size;
++=======
+ 	unsigned long i = (addr - range->start) >> PAGE_SHIFT;
++>>>>>>> f8c888a304e1 (mm/hmm: don't handle the non-fault case in hmm_vma_walk_hole_())
  
+ 	WARN_ON_ONCE(!fault && !write_fault);
  	hmm_vma_walk->last = addr;
++<<<<<<< HEAD
 +	page_size = hmm_range_page_size(range);
 +	i = (addr - range->start) >> range->page_shift;
 +
 +	for (; addr < end; addr += page_size, i++) {
 +		pfns[i] = range->values[HMM_PFN_NONE];
 +		if (fault || write_fault) {
 +			int ret;
++=======
  
- 			ret = hmm_vma_do_fault(walk, addr, write_fault,
- 					       &pfns[i]);
- 			if (ret != -EBUSY)
- 				return ret;
- 		}
+ 	if (write_fault && walk->vma && !(walk->vma->vm_flags & VM_WRITE))
+ 		return -EPERM;
+ 
+ 	for (; addr < end; addr += PAGE_SIZE, i++) {
+ 		int ret;
++>>>>>>> f8c888a304e1 (mm/hmm: don't handle the non-fault case in hmm_vma_walk_hole_())
+ 
+ 		ret = hmm_vma_do_fault(walk, addr, write_fault, &pfns[i]);
+ 		if (ret != -EBUSY)
+ 			return ret;
  	}
  
- 	return (fault || write_fault) ? -EBUSY : 0;
+ 	return -EBUSY;
  }
  
  static inline void hmm_pte_need_fault(const struct hmm_vma_walk *hmm_vma_walk,
@@@ -850,12 -570,12 +865,17 @@@ static int hmm_vma_walk_hugetlb_entry(p
  	hmm_pte_need_fault(hmm_vma_walk, orig_pfn, cpu_flags,
  			   &fault, &write_fault);
  	if (fault || write_fault) {
++<<<<<<< HEAD
 +		ret = -ENOENT;
 +		goto unlock;
++=======
+ 		spin_unlock(ptl);
+ 		return hmm_vma_fault(addr, end, fault, write_fault, walk);
++>>>>>>> f8c888a304e1 (mm/hmm: don't handle the non-fault case in hmm_vma_walk_hole_())
  	}
  
 -	pfn = pte_pfn(entry) + ((start & ~hmask) >> PAGE_SHIFT);
 -	for (; addr < end; addr += PAGE_SIZE, i++, pfn++)
 +	pfn = pte_pfn(entry) + ((start & mask) >> range->page_shift);
 +	for (; addr < end; addr += size, i++, pfn += pfn_inc)
  		range->pfns[i] = hmm_device_entry_from_pfn(range, pfn) |
  				 cpu_flags;
  	hmm_vma_walk->last = end;
* Unmerged path mm/hmm.c
