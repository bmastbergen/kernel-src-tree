mm/hmm: hmm_range_fault() infinite loop

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Ralph Campbell <rcampbell@nvidia.com>
commit c18ce674d548c00faa6b7e760bacbaf1f39315f3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/c18ce674.failed

Normally, callers to handle_mm_fault() are supposed to check the
vma->vm_flags first. hmm_range_fault() checks for VM_READ but doesn't
check for VM_WRITE if the caller requests a page to be faulted in with
write permission (via the hmm_range.pfns[] value).  If the vma is write
protected, this can result in an infinite loop:

  hmm_range_fault()
    walk_page_range()
      ...
      hmm_vma_walk_hole()
        hmm_vma_walk_hole_()
          hmm_vma_do_fault()
            handle_mm_fault(FAULT_FLAG_WRITE)
            /* returns VM_FAULT_WRITE */
          /* returns -EBUSY */
        /* returns -EBUSY */
      /* returns -EBUSY */
    /* loops on -EBUSY and range->valid */

Prevent this by checking for vma->vm_flags & VM_WRITE before calling
handle_mm_fault().

Link: https://lore.kernel.org/r/20190823221753.2514-3-rcampbell@nvidia.com
	Signed-off-by: Ralph Campbell <rcampbell@nvidia.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Jason Gunthorpe <jgg@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit c18ce674d548c00faa6b7e760bacbaf1f39315f3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/hmm.c
diff --cc mm/hmm.c
index e19a0812813a,4882b83aeccb..000000000000
--- a/mm/hmm.c
+++ b/mm/hmm.c
@@@ -360,13 -287,15 +360,20 @@@ static int hmm_vma_walk_hole_(unsigned 
  	struct hmm_vma_walk *hmm_vma_walk = walk->private;
  	struct hmm_range *range = hmm_vma_walk->range;
  	uint64_t *pfns = range->pfns;
 -	unsigned long i;
 +	unsigned long i, page_size;
  
  	hmm_vma_walk->last = addr;
 -	i = (addr - range->start) >> PAGE_SHIFT;
 +	page_size = hmm_range_page_size(range);
 +	i = (addr - range->start) >> range->page_shift;
  
++<<<<<<< HEAD
 +	for (; addr < end; addr += page_size, i++) {
++=======
+ 	if (write_fault && walk->vma && !(walk->vma->vm_flags & VM_WRITE))
+ 		return -EPERM;
+ 
+ 	for (; addr < end; addr += PAGE_SIZE, i++) {
++>>>>>>> c18ce674d548 (mm/hmm: hmm_range_fault() infinite loop)
  		pfns[i] = range->values[HMM_PFN_NONE];
  		if (fault || write_fault) {
  			int ret;
* Unmerged path mm/hmm.c
