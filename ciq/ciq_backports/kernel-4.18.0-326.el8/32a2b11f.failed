xfs: Remove kmem_zone_zalloc() usage

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Carlos Maiolino <cmaiolino@redhat.com>
commit 32a2b11f467642ea700bc0b01f4693e52ec0fabd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/32a2b11f.failed

Use kmem_cache_zalloc() directly.

With the exception of xlog_ticket_alloc() which will be dealt on the
next patch for readability.

	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Carlos Maiolino <cmaiolino@redhat.com>
	Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
	Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
	Reviewed-by: Dave Chinner <dchinner@redhat.com>
(cherry picked from commit 32a2b11f467642ea700bc0b01f4693e52ec0fabd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/libxfs/xfs_alloc_btree.c
#	fs/xfs/libxfs/xfs_bmap.c
#	fs/xfs/libxfs/xfs_ialloc_btree.c
#	fs/xfs/libxfs/xfs_inode_fork.c
#	fs/xfs/libxfs/xfs_refcount_btree.c
#	fs/xfs/libxfs/xfs_rmap_btree.c
diff --cc fs/xfs/libxfs/xfs_alloc_btree.c
index 422a822a9957,8e01231b308e..000000000000
--- a/fs/xfs/libxfs/xfs_alloc_btree.c
+++ b/fs/xfs/libxfs/xfs_alloc_btree.c
@@@ -473,6 -468,43 +473,46 @@@ static const struct xfs_btree_ops xfs_c
  	.recs_inorder		= xfs_cntbt_recs_inorder,
  };
  
++<<<<<<< HEAD
++=======
+ /* Allocate most of a new allocation btree cursor. */
+ STATIC struct xfs_btree_cur *
+ xfs_allocbt_init_common(
+ 	struct xfs_mount	*mp,
+ 	struct xfs_trans	*tp,
+ 	xfs_agnumber_t		agno,
+ 	xfs_btnum_t		btnum)
+ {
+ 	struct xfs_btree_cur	*cur;
+ 
+ 	ASSERT(btnum == XFS_BTNUM_BNO || btnum == XFS_BTNUM_CNT);
+ 
+ 	cur = kmem_cache_zalloc(xfs_btree_cur_zone, GFP_NOFS | __GFP_NOFAIL);
+ 
+ 	cur->bc_tp = tp;
+ 	cur->bc_mp = mp;
+ 	cur->bc_btnum = btnum;
+ 	cur->bc_blocklog = mp->m_sb.sb_blocklog;
+ 
+ 	if (btnum == XFS_BTNUM_CNT) {
+ 		cur->bc_ops = &xfs_cntbt_ops;
+ 		cur->bc_statoff = XFS_STATS_CALC_INDEX(xs_abtc_2);
+ 		cur->bc_flags = XFS_BTREE_LASTREC_UPDATE;
+ 	} else {
+ 		cur->bc_ops = &xfs_bnobt_ops;
+ 		cur->bc_statoff = XFS_STATS_CALC_INDEX(xs_abtb_2);
+ 	}
+ 
+ 	cur->bc_ag.agno = agno;
+ 	cur->bc_ag.abt.active = false;
+ 
+ 	if (xfs_sb_version_hascrc(&mp->m_sb))
+ 		cur->bc_flags |= XFS_BTREE_CRC_BLOCKS;
+ 
+ 	return cur;
+ }
+ 
++>>>>>>> 32a2b11f4676 (xfs: Remove kmem_zone_zalloc() usage)
  /*
   * Allocate a new allocation btree cursor.
   */
diff --cc fs/xfs/libxfs/xfs_bmap.c
index 2f491dff3658,9c40d5971035..000000000000
--- a/fs/xfs/libxfs/xfs_bmap.c
+++ b/fs/xfs/libxfs/xfs_bmap.c
@@@ -1110,10 -1099,14 +1110,18 @@@ xfs_bmap_add_attrfork
  	if (error)
  		goto trans_cancel;
  	ASSERT(ip->i_afp == NULL);
++<<<<<<< HEAD
 +	ip->i_afp = kmem_zone_zalloc(xfs_ifork_zone, 0);
++=======
+ 
+ 	ip->i_afp = kmem_cache_zalloc(xfs_ifork_zone,
+ 				      GFP_KERNEL | __GFP_NOFAIL);
+ 
+ 	ip->i_afp->if_format = XFS_DINODE_FMT_EXTENTS;
++>>>>>>> 32a2b11f4676 (xfs: Remove kmem_zone_zalloc() usage)
  	ip->i_afp->if_flags = XFS_IFEXTENTS;
  	logflags = 0;
 -	switch (ip->i_df.if_format) {
 +	switch (ip->i_d.di_format) {
  	case XFS_DINODE_FMT_LOCAL:
  		error = xfs_bmap_add_attrfork_local(tp, ip, &logflags);
  		break;
diff --cc fs/xfs/libxfs/xfs_ialloc_btree.c
index 6903820f1c4b,3c8aebc36e64..000000000000
--- a/fs/xfs/libxfs/xfs_ialloc_btree.c
+++ b/fs/xfs/libxfs/xfs_ialloc_btree.c
@@@ -410,11 -409,9 +410,15 @@@ xfs_inobt_init_cursor
  	xfs_agnumber_t		agno,		/* allocation group number */
  	xfs_btnum_t		btnum)		/* ialloc or free ino btree */
  {
 +	struct xfs_agi		*agi = agbp->b_addr;
  	struct xfs_btree_cur	*cur;
  
++<<<<<<< HEAD
 +	cur = kmem_zone_zalloc(xfs_btree_cur_zone, KM_NOFS);
 +
++=======
+ 	cur = kmem_cache_zalloc(xfs_btree_cur_zone, GFP_NOFS | __GFP_NOFAIL);
++>>>>>>> 32a2b11f4676 (xfs: Remove kmem_zone_zalloc() usage)
  	cur->bc_tp = tp;
  	cur->bc_mp = mp;
  	cur->bc_btnum = btnum;
diff --cc fs/xfs/libxfs/xfs_inode_fork.c
index 6c24c27f5f44,0cf853d42d62..000000000000
--- a/fs/xfs/libxfs/xfs_inode_fork.c
+++ b/fs/xfs/libxfs/xfs_inode_fork.c
@@@ -281,8 -287,17 +281,22 @@@ xfs_iformat_attr_fork
  {
  	int			error = 0;
  
++<<<<<<< HEAD
 +	ip->i_afp = kmem_zone_zalloc(xfs_ifork_zone, KM_NOFS);
 +	switch (dip->di_aformat) {
++=======
+ 	/*
+ 	 * Initialize the extent count early, as the per-format routines may
+ 	 * depend on it.
+ 	 */
+ 	ip->i_afp = kmem_cache_zalloc(xfs_ifork_zone, GFP_NOFS | __GFP_NOFAIL);
+ 	ip->i_afp->if_format = dip->di_aformat;
+ 	if (unlikely(ip->i_afp->if_format == 0)) /* pre IRIX 6.2 file system */
+ 		ip->i_afp->if_format = XFS_DINODE_FMT_EXTENTS;
+ 	ip->i_afp->if_nextents = be16_to_cpu(dip->di_anextents);
+ 
+ 	switch (ip->i_afp->if_format) {
++>>>>>>> 32a2b11f4676 (xfs: Remove kmem_zone_zalloc() usage)
  	case XFS_DINODE_FMT_LOCAL:
  		error = xfs_iformat_local(ip, dip, XFS_ATTR_FORK,
  				xfs_dfork_attr_shortform_size(dip));
@@@ -672,11 -673,10 +686,11 @@@ xfs_ifork_init_cow
  	if (ip->i_cowfp)
  		return;
  
- 	ip->i_cowfp = kmem_zone_zalloc(xfs_ifork_zone,
- 				       KM_NOFS);
+ 	ip->i_cowfp = kmem_cache_zalloc(xfs_ifork_zone,
+ 				       GFP_NOFS | __GFP_NOFAIL);
  	ip->i_cowfp->if_flags = XFS_IFEXTENTS;
 -	ip->i_cowfp->if_format = XFS_DINODE_FMT_EXTENTS;
 +	ip->i_cformat = XFS_DINODE_FMT_EXTENTS;
 +	ip->i_cnextents = 0;
  }
  
  /* Verify the inline contents of the data fork of an inode. */
diff --cc fs/xfs/libxfs/xfs_refcount_btree.c
index a76997740e45,a6ac60ae9421..000000000000
--- a/fs/xfs/libxfs/xfs_refcount_btree.c
+++ b/fs/xfs/libxfs/xfs_refcount_btree.c
@@@ -311,8 -310,36 +311,39 @@@ static const struct xfs_btree_ops xfs_r
  };
  
  /*
 - * Initialize a new refcount btree cursor.
 + * Allocate a new refcount btree cursor.
   */
++<<<<<<< HEAD
++=======
+ static struct xfs_btree_cur *
+ xfs_refcountbt_init_common(
+ 	struct xfs_mount	*mp,
+ 	struct xfs_trans	*tp,
+ 	xfs_agnumber_t		agno)
+ {
+ 	struct xfs_btree_cur	*cur;
+ 
+ 	ASSERT(agno != NULLAGNUMBER);
+ 	ASSERT(agno < mp->m_sb.sb_agcount);
+ 
+ 	cur = kmem_cache_zalloc(xfs_btree_cur_zone, GFP_NOFS | __GFP_NOFAIL);
+ 	cur->bc_tp = tp;
+ 	cur->bc_mp = mp;
+ 	cur->bc_btnum = XFS_BTNUM_REFC;
+ 	cur->bc_blocklog = mp->m_sb.sb_blocklog;
+ 	cur->bc_statoff = XFS_STATS_CALC_INDEX(xs_refcbt_2);
+ 
+ 	cur->bc_ag.agno = agno;
+ 	cur->bc_flags |= XFS_BTREE_CRC_BLOCKS;
+ 
+ 	cur->bc_ag.refc.nr_ops = 0;
+ 	cur->bc_ag.refc.shape_changes = 0;
+ 	cur->bc_ops = &xfs_refcountbt_ops;
+ 	return cur;
+ }
+ 
+ /* Create a btree cursor. */
++>>>>>>> 32a2b11f4676 (xfs: Remove kmem_zone_zalloc() usage)
  struct xfs_btree_cur *
  xfs_refcountbt_init_cursor(
  	struct xfs_mount	*mp,
diff --cc fs/xfs/libxfs/xfs_rmap_btree.c
index 725cb892f157,beb81c84a937..000000000000
--- a/fs/xfs/libxfs/xfs_rmap_btree.c
+++ b/fs/xfs/libxfs/xfs_rmap_btree.c
@@@ -448,9 -448,29 +448,35 @@@ static const struct xfs_btree_ops xfs_r
  	.recs_inorder		= xfs_rmapbt_recs_inorder,
  };
  
++<<<<<<< HEAD
 +/*
 + * Allocate a new allocation btree cursor.
 + */
++=======
+ static struct xfs_btree_cur *
+ xfs_rmapbt_init_common(
+ 	struct xfs_mount	*mp,
+ 	struct xfs_trans	*tp,
+ 	xfs_agnumber_t		agno)
+ {
+ 	struct xfs_btree_cur	*cur;
+ 
+ 	cur = kmem_cache_zalloc(xfs_btree_cur_zone, GFP_NOFS | __GFP_NOFAIL);
+ 	cur->bc_tp = tp;
+ 	cur->bc_mp = mp;
+ 	/* Overlapping btree; 2 keys per pointer. */
+ 	cur->bc_btnum = XFS_BTNUM_RMAP;
+ 	cur->bc_flags = XFS_BTREE_CRC_BLOCKS | XFS_BTREE_OVERLAPPING;
+ 	cur->bc_blocklog = mp->m_sb.sb_blocklog;
+ 	cur->bc_statoff = XFS_STATS_CALC_INDEX(xs_rmap_2);
+ 	cur->bc_ag.agno = agno;
+ 	cur->bc_ops = &xfs_rmapbt_ops;
+ 
+ 	return cur;
+ }
+ 
+ /* Create a new reverse mapping btree cursor. */
++>>>>>>> 32a2b11f4676 (xfs: Remove kmem_zone_zalloc() usage)
  struct xfs_btree_cur *
  xfs_rmapbt_init_cursor(
  	struct xfs_mount	*mp,
* Unmerged path fs/xfs/libxfs/xfs_alloc_btree.c
* Unmerged path fs/xfs/libxfs/xfs_bmap.c
diff --git a/fs/xfs/libxfs/xfs_bmap_btree.c b/fs/xfs/libxfs/xfs_bmap_btree.c
index ffe608d2a2d9..77fe4ae671e5 100644
--- a/fs/xfs/libxfs/xfs_bmap_btree.c
+++ b/fs/xfs/libxfs/xfs_bmap_btree.c
@@ -552,7 +552,7 @@ xfs_bmbt_init_cursor(
 	struct xfs_btree_cur	*cur;
 	ASSERT(whichfork != XFS_COW_FORK);
 
-	cur = kmem_zone_zalloc(xfs_btree_cur_zone, KM_NOFS);
+	cur = kmem_cache_zalloc(xfs_btree_cur_zone, GFP_NOFS | __GFP_NOFAIL);
 
 	cur->bc_tp = tp;
 	cur->bc_mp = mp;
diff --git a/fs/xfs/libxfs/xfs_da_btree.c b/fs/xfs/libxfs/xfs_da_btree.c
index 897749c41f36..a4e1f01daf3d 100644
--- a/fs/xfs/libxfs/xfs_da_btree.c
+++ b/fs/xfs/libxfs/xfs_da_btree.c
@@ -81,7 +81,7 @@ kmem_zone_t *xfs_da_state_zone;	/* anchor for state struct zone */
 xfs_da_state_t *
 xfs_da_state_alloc(void)
 {
-	return kmem_zone_zalloc(xfs_da_state_zone, KM_NOFS);
+	return kmem_cache_zalloc(xfs_da_state_zone, GFP_NOFS | __GFP_NOFAIL);
 }
 
 /*
* Unmerged path fs/xfs/libxfs/xfs_ialloc_btree.c
* Unmerged path fs/xfs/libxfs/xfs_inode_fork.c
* Unmerged path fs/xfs/libxfs/xfs_refcount_btree.c
* Unmerged path fs/xfs/libxfs/xfs_rmap_btree.c
diff --git a/fs/xfs/xfs_bmap_item.c b/fs/xfs/xfs_bmap_item.c
index 6736c5ab188f..ec3691372e7c 100644
--- a/fs/xfs/xfs_bmap_item.c
+++ b/fs/xfs/xfs_bmap_item.c
@@ -138,7 +138,7 @@ xfs_bui_init(
 {
 	struct xfs_bui_log_item		*buip;
 
-	buip = kmem_zone_zalloc(xfs_bui_zone, 0);
+	buip = kmem_cache_zalloc(xfs_bui_zone, GFP_KERNEL | __GFP_NOFAIL);
 
 	xfs_log_item_init(mp, &buip->bui_item, XFS_LI_BUI, &xfs_bui_item_ops);
 	buip->bui_format.bui_nextents = XFS_BUI_MAX_FAST_EXTENTS;
@@ -215,7 +215,7 @@ xfs_trans_get_bud(
 {
 	struct xfs_bud_log_item		*budp;
 
-	budp = kmem_zone_zalloc(xfs_bud_zone, 0);
+	budp = kmem_cache_zalloc(xfs_bud_zone, GFP_KERNEL | __GFP_NOFAIL);
 	xfs_log_item_init(tp->t_mountp, &budp->bud_item, XFS_LI_BUD,
 			  &xfs_bud_item_ops);
 	budp->bud_buip = buip;
diff --git a/fs/xfs/xfs_buf.c b/fs/xfs/xfs_buf.c
index a1019f219a28..cd00691a5f12 100644
--- a/fs/xfs/xfs_buf.c
+++ b/fs/xfs/xfs_buf.c
@@ -214,9 +214,7 @@ _xfs_buf_alloc(
 	int			i;
 
 	*bpp = NULL;
-	bp = kmem_zone_zalloc(xfs_buf_zone, KM_NOFS);
-	if (unlikely(!bp))
-		return -ENOMEM;
+	bp = kmem_cache_zalloc(xfs_buf_zone, GFP_NOFS | __GFP_NOFAIL);
 
 	/*
 	 * We don't want certain flags to appear in b_flags unless they are
diff --git a/fs/xfs/xfs_buf_item.c b/fs/xfs/xfs_buf_item.c
index ed1bf1d99483..5bb6f22cc11a 100644
--- a/fs/xfs/xfs_buf_item.c
+++ b/fs/xfs/xfs_buf_item.c
@@ -738,7 +738,7 @@ xfs_buf_item_init(
 		return 0;
 	}
 
-	bip = kmem_zone_zalloc(xfs_buf_item_zone, 0);
+	bip = kmem_cache_zalloc(xfs_buf_item_zone, GFP_KERNEL | __GFP_NOFAIL);
 	xfs_log_item_init(mp, &bip->bli_item, XFS_LI_BUF, &xfs_buf_item_ops);
 	bip->bli_buf = bp;
 
diff --git a/fs/xfs/xfs_dquot.c b/fs/xfs/xfs_dquot.c
index 767bb09a6ae3..c76c587e41be 100644
--- a/fs/xfs/xfs_dquot.c
+++ b/fs/xfs/xfs_dquot.c
@@ -466,7 +466,7 @@ xfs_dquot_alloc(
 {
 	struct xfs_dquot	*dqp;
 
-	dqp = kmem_zone_zalloc(xfs_qm_dqzone, 0);
+	dqp = kmem_cache_zalloc(xfs_qm_dqzone, GFP_KERNEL | __GFP_NOFAIL);
 
 	dqp->dq_flags = type;
 	dqp->q_id = id;
diff --git a/fs/xfs/xfs_extfree_item.c b/fs/xfs/xfs_extfree_item.c
index b9c333bae0a1..6cb8cd11072a 100644
--- a/fs/xfs/xfs_extfree_item.c
+++ b/fs/xfs/xfs_extfree_item.c
@@ -161,7 +161,8 @@ xfs_efi_init(
 			((nextents - 1) * sizeof(xfs_extent_t)));
 		efip = kmem_zalloc(size, 0);
 	} else {
-		efip = kmem_zone_zalloc(xfs_efi_zone, 0);
+		efip = kmem_cache_zalloc(xfs_efi_zone,
+					 GFP_KERNEL | __GFP_NOFAIL);
 	}
 
 	xfs_log_item_init(mp, &efip->efi_item, XFS_LI_EFI, &xfs_efi_item_ops);
@@ -332,7 +333,8 @@ xfs_trans_get_efd(
 				(nextents - 1) * sizeof(struct xfs_extent),
 				0);
 	} else {
-		efdp = kmem_zone_zalloc(xfs_efd_zone, 0);
+		efdp = kmem_cache_zalloc(xfs_efd_zone,
+					GFP_KERNEL | __GFP_NOFAIL);
 	}
 
 	xfs_log_item_init(tp->t_mountp, &efdp->efd_item, XFS_LI_EFD,
diff --git a/fs/xfs/xfs_icreate_item.c b/fs/xfs/xfs_icreate_item.c
index 287a9e5c7d75..9b3994b9c716 100644
--- a/fs/xfs/xfs_icreate_item.c
+++ b/fs/xfs/xfs_icreate_item.c
@@ -97,7 +97,7 @@ xfs_icreate_log(
 {
 	struct xfs_icreate_item	*icp;
 
-	icp = kmem_zone_zalloc(xfs_icreate_zone, 0);
+	icp = kmem_cache_zalloc(xfs_icreate_zone, GFP_KERNEL | __GFP_NOFAIL);
 
 	xfs_log_item_init(tp->t_mountp, &icp->ic_item, XFS_LI_ICREATE,
 			  &xfs_icreate_item_ops);
diff --git a/fs/xfs/xfs_inode_item.c b/fs/xfs/xfs_inode_item.c
index f00ba80464df..92cd620be8a5 100644
--- a/fs/xfs/xfs_inode_item.c
+++ b/fs/xfs/xfs_inode_item.c
@@ -624,7 +624,8 @@ xfs_inode_item_init(
 	struct xfs_inode_log_item *iip;
 
 	ASSERT(ip->i_itemp == NULL);
-	iip = ip->i_itemp = kmem_zone_zalloc(xfs_ili_zone, 0);
+	iip = ip->i_itemp = kmem_cache_zalloc(xfs_ili_zone,
+					      GFP_KERNEL | __GFP_NOFAIL);
 
 	iip->ili_inode = ip;
 	spin_lock_init(&iip->ili_lock);
diff --git a/fs/xfs/xfs_refcount_item.c b/fs/xfs/xfs_refcount_item.c
index c81639891e29..7b2c72bc2858 100644
--- a/fs/xfs/xfs_refcount_item.c
+++ b/fs/xfs/xfs_refcount_item.c
@@ -143,7 +143,8 @@ xfs_cui_init(
 		cuip = kmem_zalloc(xfs_cui_log_item_sizeof(nextents),
 				0);
 	else
-		cuip = kmem_zone_zalloc(xfs_cui_zone, 0);
+		cuip = kmem_cache_zalloc(xfs_cui_zone,
+					 GFP_KERNEL | __GFP_NOFAIL);
 
 	xfs_log_item_init(mp, &cuip->cui_item, XFS_LI_CUI, &xfs_cui_item_ops);
 	cuip->cui_format.cui_nextents = nextents;
@@ -220,7 +221,7 @@ xfs_trans_get_cud(
 {
 	struct xfs_cud_log_item		*cudp;
 
-	cudp = kmem_zone_zalloc(xfs_cud_zone, 0);
+	cudp = kmem_cache_zalloc(xfs_cud_zone, GFP_KERNEL | __GFP_NOFAIL);
 	xfs_log_item_init(tp->t_mountp, &cudp->cud_item, XFS_LI_CUD,
 			  &xfs_cud_item_ops);
 	cudp->cud_cuip = cuip;
diff --git a/fs/xfs/xfs_rmap_item.c b/fs/xfs/xfs_rmap_item.c
index a86599db20a6..dc5b0753cd51 100644
--- a/fs/xfs/xfs_rmap_item.c
+++ b/fs/xfs/xfs_rmap_item.c
@@ -141,7 +141,8 @@ xfs_rui_init(
 	if (nextents > XFS_RUI_MAX_FAST_EXTENTS)
 		ruip = kmem_zalloc(xfs_rui_log_item_sizeof(nextents), 0);
 	else
-		ruip = kmem_zone_zalloc(xfs_rui_zone, 0);
+		ruip = kmem_cache_zalloc(xfs_rui_zone,
+					 GFP_KERNEL | __GFP_NOFAIL);
 
 	xfs_log_item_init(mp, &ruip->rui_item, XFS_LI_RUI, &xfs_rui_item_ops);
 	ruip->rui_format.rui_nextents = nextents;
@@ -243,7 +244,7 @@ xfs_trans_get_rud(
 {
 	struct xfs_rud_log_item		*rudp;
 
-	rudp = kmem_zone_zalloc(xfs_rud_zone, 0);
+	rudp = kmem_cache_zalloc(xfs_rud_zone, GFP_KERNEL | __GFP_NOFAIL);
 	xfs_log_item_init(tp->t_mountp, &rudp->rud_item, XFS_LI_RUD,
 			  &xfs_rud_item_ops);
 	rudp->rud_ruip = ruip;
diff --git a/fs/xfs/xfs_trans.c b/fs/xfs/xfs_trans.c
index f42bd3b823d1..440d13157242 100644
--- a/fs/xfs/xfs_trans.c
+++ b/fs/xfs/xfs_trans.c
@@ -91,7 +91,7 @@ xfs_trans_dup(
 
 	trace_xfs_trans_dup(tp, _RET_IP_);
 
-	ntp = kmem_zone_zalloc(xfs_trans_zone, 0);
+	ntp = kmem_cache_zalloc(xfs_trans_zone, GFP_KERNEL | __GFP_NOFAIL);
 
 	/*
 	 * Initialize the new transaction structure.
@@ -266,7 +266,7 @@ xfs_trans_alloc(
 	 * GFP_NOFS allocation context so that we avoid lockdep false positives
 	 * by doing GFP_KERNEL allocations inside sb_start_intwrite().
 	 */
-	tp = kmem_zone_zalloc(xfs_trans_zone, 0);
+	tp = kmem_cache_zalloc(xfs_trans_zone, GFP_KERNEL | __GFP_NOFAIL);
 	if (!(flags & XFS_TRANS_NO_WRITECOUNT))
 		sb_start_intwrite(mp->m_super);
 
diff --git a/fs/xfs/xfs_trans_dquot.c b/fs/xfs/xfs_trans_dquot.c
index ce487518738a..7a4cbaae6ea9 100644
--- a/fs/xfs/xfs_trans_dquot.c
+++ b/fs/xfs/xfs_trans_dquot.c
@@ -851,7 +851,8 @@ STATIC void
 xfs_trans_alloc_dqinfo(
 	xfs_trans_t	*tp)
 {
-	tp->t_dqinfo = kmem_zone_zalloc(xfs_qm_dqtrxzone, 0);
+	tp->t_dqinfo = kmem_cache_zalloc(xfs_qm_dqtrxzone,
+					 GFP_KERNEL | __GFP_NOFAIL);
 }
 
 void
