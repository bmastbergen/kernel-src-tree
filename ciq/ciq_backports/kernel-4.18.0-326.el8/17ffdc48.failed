mm: simplify device private page handling in hmm_range_fault

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 17ffdc482982af92bddb59692af1c5e1de23d184
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/17ffdc48.failed

Remove the HMM_PFN_DEVICE_PRIVATE flag, no driver has ever set this flag
on input, and the only place that uses it on output can be trivially
changed to use is_device_private_page().

This removes the ability to request that device_private pages are faulted
back into system memory.

Link: https://lore.kernel.org/r/20200316193216.920734-4-hch@lst.de
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Jason Gunthorpe <jgg@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 17ffdc482982af92bddb59692af1c5e1de23d184)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c
#	drivers/gpu/drm/nouveau/nouveau_dmem.c
#	drivers/gpu/drm/nouveau/nouveau_svm.c
diff --cc drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c
index b7fd0cdffce0,90821ce5e6ca..000000000000
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c
@@@ -885,6 -772,18 +885,21 @@@ struct amdgpu_ttm_tt 
  };
  
  #ifdef CONFIG_DRM_AMDGPU_USERPTR
++<<<<<<< HEAD
++=======
+ /* flags used by HMM internal, not related to CPU/GPU PTE flags */
+ static const uint64_t hmm_range_flags[HMM_PFN_FLAG_MAX] = {
+ 	(1 << 0), /* HMM_PFN_VALID */
+ 	(1 << 1), /* HMM_PFN_WRITE */
+ };
+ 
+ static const uint64_t hmm_range_values[HMM_PFN_VALUE_MAX] = {
+ 	0xfffffffffffffffeUL, /* HMM_PFN_ERROR */
+ 	0, /* HMM_PFN_NONE */
+ 	0xfffffffffffffffcUL /* HMM_PFN_SPECIAL */
+ };
+ 
++>>>>>>> 17ffdc482982 (mm: simplify device private page handling in hmm_range_fault)
  /**
   * amdgpu_ttm_tt_get_user_pages - get device accessible pages that back user
   * memory and start HMM tracking CPU page table update
diff --cc drivers/gpu/drm/nouveau/nouveau_dmem.c
index 4e8112fde3e6,edfd0805fba4..000000000000
--- a/drivers/gpu/drm/nouveau/nouveau_dmem.c
+++ b/drivers/gpu/drm/nouveau/nouveau_dmem.c
@@@ -29,7 -28,6 +29,10 @@@
  
  #include <nvif/class.h>
  #include <nvif/object.h>
++<<<<<<< HEAD
 +#include <nvif/push906f.h>
++=======
++>>>>>>> 17ffdc482982 (mm: simplify device private page handling in hmm_range_fault)
  #include <nvif/if000c.h>
  #include <nvif/if500b.h>
  #include <nvif/if900b.h>
@@@ -701,3 -671,40 +704,43 @@@ out_free_src
  out:
  	return ret;
  }
++<<<<<<< HEAD
++=======
+ 
+ static inline bool
+ nouveau_dmem_page(struct nouveau_drm *drm, struct page *page)
+ {
+ 	return is_device_private_page(page) && drm->dmem == page_to_dmem(page);
+ }
+ 
+ void
+ nouveau_dmem_convert_pfn(struct nouveau_drm *drm,
+ 			 struct hmm_range *range)
+ {
+ 	unsigned long i, npages;
+ 
+ 	npages = (range->end - range->start) >> PAGE_SHIFT;
+ 	for (i = 0; i < npages; ++i) {
+ 		struct page *page;
+ 		uint64_t addr;
+ 
+ 		page = hmm_device_entry_to_page(range, range->pfns[i]);
+ 		if (page == NULL)
+ 			continue;
+ 
+ 		if (!is_device_private_page(page))
+ 			continue;
+ 
+ 		if (!nouveau_dmem_page(drm, page)) {
+ 			WARN(1, "Some unknown device memory !\n");
+ 			range->pfns[i] = 0;
+ 			continue;
+ 		}
+ 
+ 		addr = nouveau_dmem_page_addr(page);
+ 		range->pfns[i] &= ((1UL << range->pfn_shift) - 1);
+ 		range->pfns[i] |= (addr >> PAGE_SHIFT) << range->pfn_shift;
+ 		range->pfns[i] |= NVIF_VMM_PFNMAP_V0_VRAM;
+ 	}
+ }
++>>>>>>> 17ffdc482982 (mm: simplify device private page handling in hmm_range_fault)
diff --cc drivers/gpu/drm/nouveau/nouveau_svm.c
index 4f69e4c3dafd,39c731a99937..000000000000
--- a/drivers/gpu/drm/nouveau/nouveau_svm.c
+++ b/drivers/gpu/drm/nouveau/nouveau_svm.c
@@@ -366,6 -363,19 +366,22 @@@ out_free
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ static const u64
+ nouveau_svm_pfn_flags[HMM_PFN_FLAG_MAX] = {
+ 	[HMM_PFN_VALID         ] = NVIF_VMM_PFNMAP_V0_V,
+ 	[HMM_PFN_WRITE         ] = NVIF_VMM_PFNMAP_V0_W,
+ };
+ 
+ static const u64
+ nouveau_svm_pfn_values[HMM_PFN_VALUE_MAX] = {
+ 	[HMM_PFN_ERROR  ] = ~NVIF_VMM_PFNMAP_V0_V,
+ 	[HMM_PFN_NONE   ] =  NVIF_VMM_PFNMAP_V0_NONE,
+ 	[HMM_PFN_SPECIAL] = ~NVIF_VMM_PFNMAP_V0_V,
+ };
+ 
++>>>>>>> 17ffdc482982 (mm: simplify device private page handling in hmm_range_fault)
  /* Issue fault replay for GPU to retry accesses that faulted previously. */
  static void
  nouveau_svm_fault_replay(struct nouveau_svm *svm)
* Unmerged path drivers/gpu/drm/amd/amdgpu/amdgpu_ttm.c
* Unmerged path drivers/gpu/drm/nouveau/nouveau_dmem.c
* Unmerged path drivers/gpu/drm/nouveau/nouveau_svm.c
diff --git a/include/linux/hmm.h b/include/linux/hmm.h
index 6a8157d67186..f76d055936c2 100644
--- a/include/linux/hmm.h
+++ b/include/linux/hmm.h
@@ -120,7 +120,6 @@ struct hmm {
  * Flags:
  * HMM_PFN_VALID: pfn is valid. It has, at least, read permission.
  * HMM_PFN_WRITE: CPU page table has write permission set
- * HMM_PFN_DEVICE_PRIVATE: private device memory (ZONE_DEVICE)
  *
  * The driver provides a flags array for mapping page protections to device
  * PTE bits. If the driver valid bit for an entry is bit 3,
@@ -132,7 +131,6 @@ struct hmm {
 enum hmm_pfn_flag_e {
 	HMM_PFN_VALID = 0,
 	HMM_PFN_WRITE,
-	HMM_PFN_DEVICE_PRIVATE,
 	HMM_PFN_FLAG_MAX
 };
 
diff --git a/mm/hmm.c b/mm/hmm.c
index 0031a5d7b75b..4f51d29edb4f 100644
--- a/mm/hmm.c
+++ b/mm/hmm.c
@@ -405,15 +405,6 @@ static inline void hmm_pte_need_fault(const struct hmm_vma_walk *hmm_vma_walk,
 	/* We aren't ask to do anything ... */
 	if (!(pfns & range->flags[HMM_PFN_VALID]))
 		return;
-	/* If this is device memory then only fault if explicitly requested */
-	if ((cpu_flags & range->flags[HMM_PFN_DEVICE_PRIVATE])) {
-		/* Do we fault on device memory ? */
-		if (pfns & range->flags[HMM_PFN_DEVICE_PRIVATE]) {
-			*write_fault = pfns & range->flags[HMM_PFN_WRITE];
-			*fault = true;
-		}
-		return;
-	}
 
 	/* If CPU page table is not valid then we need to fault */
 	*fault = !(cpu_flags & range->flags[HMM_PFN_VALID]);
@@ -548,21 +539,15 @@ static int hmm_vma_handle_pte(struct mm_walk *walk, unsigned long addr,
 		swp_entry_t entry = pte_to_swp_entry(pte);
 
 		/*
-		 * This is a special swap entry, ignore migration, use
-		 * device and report anything else as error.
+		 * Never fault in device private pages pages, but just report
+		 * the PFN even if not present.
 		 */
 		if (is_device_private_entry(entry)) {
-			cpu_flags = range->flags[HMM_PFN_VALID] |
-				range->flags[HMM_PFN_DEVICE_PRIVATE];
-			cpu_flags |= is_write_device_private_entry(entry) ?
-				range->flags[HMM_PFN_WRITE] : 0;
-			hmm_pte_need_fault(hmm_vma_walk, orig_pfn, cpu_flags,
-					   &fault, &write_fault);
-			if (fault || write_fault)
-				goto fault;
 			*pfn = hmm_device_entry_from_pfn(range,
 					    swp_offset(entry));
-			*pfn |= cpu_flags;
+			*pfn |= range->flags[HMM_PFN_VALID];
+			if (is_write_device_private_entry(entry))
+				*pfn |= range->flags[HMM_PFN_WRITE];
 			return 0;
 		}
 
