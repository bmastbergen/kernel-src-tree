mm/gup.c: fix comments of __get_user_pages() and get_user_pages_remote()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Liu Xiang <liuxiang_1999@126.com>
commit d2dfbe47fa0e9753f560b75cfcd4654e40ab903b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/d2dfbe47.failed

Fix comments of __get_user_pages() and get_user_pages_remote(), make
them more clear.

Link: http://lkml.kernel.org/r/1572443533-3118-1-git-send-email-liuxiang_1999@126.com
	Signed-off-by: Liu Xiang <liuxiang_1999@126.com>
	Suggested-by: John Hubbard <jhubbard@nvidia.com>
	Reviewed-by: David Hildenbrand <david@redhat.com>
	Reviewed-by: John Hubbard <jhubbard@nvidia.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit d2dfbe47fa0e9753f560b75cfcd4654e40ab903b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/gup.c
diff --cc mm/gup.c
index 22ac8220f407,7646bf993b25..000000000000
--- a/mm/gup.c
+++ b/mm/gup.c
@@@ -936,13 -732,19 +936,19 @@@ static int check_vma_flags(struct vm_ar
   *		only intends to ensure the pages are faulted in.
   * @vmas:	array of pointers to vmas corresponding to each page.
   *		Or NULL if the caller does not require them.
 - * @nonblocking: whether waiting for disk IO or mmap_sem contention
 + * @locked:     whether we're still with the mmap_sem held
   *
-  * Returns number of pages pinned. This may be fewer than the number
-  * requested. If nr_pages is 0 or negative, returns 0. If no pages
-  * were pinned, returns -errno. Each page returned must be released
-  * with a put_page() call when it is finished with. vmas will only
-  * remain valid while mmap_sem is held.
+  * Returns either number of pages pinned (which may be less than the
+  * number requested), or an error. Details about the return value:
+  *
+  * -- If nr_pages is 0, returns 0.
+  * -- If nr_pages is >0, but no pages were pinned, returns -errno.
+  * -- If nr_pages is >0, and some pages were pinned, returns the number of
+  *    pages pinned. Again, this may be less than nr_pages.
+  *
+  * The caller is responsible for releasing returned @pages, via put_page().
+  *
+  * @vmas are valid only as long as mmap_sem is held.
   *
   * Must be called with mmap_sem held.  It may be released.  See below.
   *
@@@ -1340,6 -1096,88 +1346,91 @@@ retry
  	return pages_done;
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * get_user_pages_remote() - pin user pages in memory
+  * @tsk:	the task_struct to use for page fault accounting, or
+  *		NULL if faults are not to be recorded.
+  * @mm:		mm_struct of target mm
+  * @start:	starting user address
+  * @nr_pages:	number of pages from start to pin
+  * @gup_flags:	flags modifying lookup behaviour
+  * @pages:	array that receives pointers to the pages pinned.
+  *		Should be at least nr_pages long. Or NULL, if caller
+  *		only intends to ensure the pages are faulted in.
+  * @vmas:	array of pointers to vmas corresponding to each page.
+  *		Or NULL if the caller does not require them.
+  * @locked:	pointer to lock flag indicating whether lock is held and
+  *		subsequently whether VM_FAULT_RETRY functionality can be
+  *		utilised. Lock must initially be held.
+  *
+  * Returns either number of pages pinned (which may be less than the
+  * number requested), or an error. Details about the return value:
+  *
+  * -- If nr_pages is 0, returns 0.
+  * -- If nr_pages is >0, but no pages were pinned, returns -errno.
+  * -- If nr_pages is >0, and some pages were pinned, returns the number of
+  *    pages pinned. Again, this may be less than nr_pages.
+  *
+  * The caller is responsible for releasing returned @pages, via put_page().
+  *
+  * @vmas are valid only as long as mmap_sem is held.
+  *
+  * Must be called with mmap_sem held for read or write.
+  *
+  * get_user_pages walks a process's page tables and takes a reference to
+  * each struct page that each user address corresponds to at a given
+  * instant. That is, it takes the page that would be accessed if a user
+  * thread accesses the given user virtual address at that instant.
+  *
+  * This does not guarantee that the page exists in the user mappings when
+  * get_user_pages returns, and there may even be a completely different
+  * page there in some cases (eg. if mmapped pagecache has been invalidated
+  * and subsequently re faulted). However it does guarantee that the page
+  * won't be freed completely. And mostly callers simply care that the page
+  * contains data that was valid *at some point in time*. Typically, an IO
+  * or similar operation cannot guarantee anything stronger anyway because
+  * locks can't be held over the syscall boundary.
+  *
+  * If gup_flags & FOLL_WRITE == 0, the page must not be written to. If the page
+  * is written to, set_page_dirty (or set_page_dirty_lock, as appropriate) must
+  * be called after the page is finished with, and before put_page is called.
+  *
+  * get_user_pages is typically used for fewer-copy IO operations, to get a
+  * handle on the memory by some means other than accesses via the user virtual
+  * addresses. The pages may be submitted for DMA to devices or accessed via
+  * their kernel linear mapping (via the kmap APIs). Care should be taken to
+  * use the correct cache flushing APIs.
+  *
+  * See also get_user_pages_fast, for performance critical applications.
+  *
+  * get_user_pages should be phased out in favor of
+  * get_user_pages_locked|unlocked or get_user_pages_fast. Nothing
+  * should use get_user_pages because it cannot pass
+  * FAULT_FLAG_ALLOW_RETRY to handle_mm_fault.
+  */
+ long get_user_pages_remote(struct task_struct *tsk, struct mm_struct *mm,
+ 		unsigned long start, unsigned long nr_pages,
+ 		unsigned int gup_flags, struct page **pages,
+ 		struct vm_area_struct **vmas, int *locked)
+ {
+ 	/*
+ 	 * FIXME: Current FOLL_LONGTERM behavior is incompatible with
+ 	 * FAULT_FLAG_ALLOW_RETRY because of the FS DAX check requirement on
+ 	 * vmas.  As there are no users of this flag in this call we simply
+ 	 * disallow this option for now.
+ 	 */
+ 	if (WARN_ON_ONCE(gup_flags & FOLL_LONGTERM))
+ 		return -EINVAL;
+ 
+ 	return __get_user_pages_locked(tsk, mm, start, nr_pages, pages, vmas,
+ 				       locked,
+ 				       gup_flags | FOLL_TOUCH | FOLL_REMOTE);
+ }
+ EXPORT_SYMBOL(get_user_pages_remote);
+ 
++>>>>>>> d2dfbe47fa0e (mm/gup.c: fix comments of __get_user_pages() and get_user_pages_remote())
  /**
   * populate_vma_page_range() -  populate a range of pages in the vma.
   * @vma:   target vma
* Unmerged path mm/gup.c
