mm: allow a NULL fn callback in apply_to_page_range

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-326.el8
commit-author Christoph Hellwig <hch@lst.de>
commit eeb4a05fcef39a720d24846356cf65a07e71d7a1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-326.el8/eeb4a05f.failed

Besides calling the callback on each page, apply_to_page_range also has
the effect of pre-faulting all PTEs for the range.  To support callers
that only need the pre-faulting, make the callback optional.

Based on a patch from Minchan Kim <minchan@kernel.org>.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Cc: Boris Ostrovsky <boris.ostrovsky@oracle.com>
	Cc: Chris Wilson <chris@chris-wilson.co.uk>
	Cc: Jani Nikula <jani.nikula@linux.intel.com>
	Cc: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
	Cc: Juergen Gross <jgross@suse.com>
	Cc: Matthew Auld <matthew.auld@intel.com>
	Cc: "Matthew Wilcox (Oracle)" <willy@infradead.org>
	Cc: Nitin Gupta <ngupta@vflare.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Rodrigo Vivi <rodrigo.vivi@intel.com>
	Cc: Stefano Stabellini <sstabellini@kernel.org>
	Cc: Tvrtko Ursulin <tvrtko.ursulin@intel.com>
	Cc: Uladzislau Rezki (Sony) <urezki@gmail.com>
Link: https://lkml.kernel.org/r/20201002122204.1534411-5-hch@lst.de
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit eeb4a05fcef39a720d24846356cf65a07e71d7a1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/memory.c
diff --cc mm/memory.c
index e5ee306b93fa,c48f8df6e502..000000000000
--- a/mm/memory.c
+++ b/mm/memory.c
@@@ -2083,13 -2391,16 +2083,26 @@@ static int apply_to_pte_range(struct mm
  
  	arch_enter_lazy_mmu_mode();
  
++<<<<<<< HEAD
 +	do {
 +		if (create || !pte_none(*pte)) {
 +			err = fn(pte++, addr, data);
 +			if (err)
 +				break;
 +		}
 +	} while (addr += PAGE_SIZE, addr != end);
++=======
+ 	if (fn) {
+ 		do {
+ 			if (create || !pte_none(*pte)) {
+ 				err = fn(pte++, addr, data);
+ 				if (err)
+ 					break;
+ 			}
+ 		} while (addr += PAGE_SIZE, addr != end);
+ 	}
+ 	*mask |= PGTBL_PTE_MODIFIED;
++>>>>>>> eeb4a05fcef3 (mm: allow a NULL fn callback in apply_to_page_range)
  
  	arch_leave_lazy_mmu_mode();
  
* Unmerged path mm/memory.c
