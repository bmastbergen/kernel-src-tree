mnt: Protect the mountpoint hashtable with mount_lock

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Eric W. Biederman <ebiederm@xmission.com>
commit 3895dbf8985f656675b5bde610723a29cbce3fa7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/3895dbf8.failed

Protecting the mountpoint hashtable with namespace_sem was sufficient
until a call to umount_mnt was added to mntput_no_expire.  At which
point it became possible for multiple calls of put_mountpoint on
the same hash chain to happen on the same time.

Kristen Johansen <kjlx@templeofstupid.com> reported:
> This can cause a panic when simultaneous callers of put_mountpoint
> attempt to free the same mountpoint.  This occurs because some callers
> hold the mount_hash_lock, while others hold the namespace lock.  Some
> even hold both.
>
> In this submitter's case, the panic manifested itself as a GP fault in
> put_mountpoint() when it called hlist_del() and attempted to dereference
> a m_hash.pprev that had been poisioned by another thread.

Al Viro observed that the simple fix is to switch from using the namespace_sem
to the mount_lock to protect the mountpoint hash table.

I have taken Al's suggested patch moved put_mountpoint in pivot_root
(instead of taking mount_lock an additional time), and have replaced
new_mountpoint with get_mountpoint a function that does the hash table
lookup and addition under the mount_lock.   The introduction of get_mounptoint
ensures that only the mount_lock is needed to manipulate the mountpoint
hashtable.

d_set_mounted is modified to only set DCACHE_MOUNTED if it is not
already set.  This allows get_mountpoint to use the setting of
DCACHE_MOUNTED to ensure adding a struct mountpoint for a dentry
happens exactly once.

	Cc: stable@vger.kernel.org
Fixes: ce07d891a089 ("mnt: Honor MNT_LOCKED when detaching mounts")
	Reported-by: Krister Johansen <kjlx@templeofstupid.com>
	Suggested-by: Al Viro <viro@ZenIV.linux.org.uk>
	Acked-by: Al Viro <viro@ZenIV.linux.org.uk>
	Signed-off-by: "Eric W. Biederman" <ebiederm@xmission.com>
(cherry picked from commit 3895dbf8985f656675b5bde610723a29cbce3fa7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/namespace.c
diff --cc fs/namespace.c
index 5bfed5a73a95,487ba30bb5c6..000000000000
--- a/fs/namespace.c
+++ b/fs/namespace.c
@@@ -657,25 -742,50 +657,56 @@@ static struct mountpoint *lookup_mountp
  	return NULL;
  }
  
- static struct mountpoint *new_mountpoint(struct dentry *dentry)
+ static struct mountpoint *get_mountpoint(struct dentry *dentry)
  {
- 	struct hlist_head *chain = mp_hash(dentry);
- 	struct mountpoint *mp;
+ 	struct mountpoint *mp, *new = NULL;
  	int ret;
  
- 	mp = kmalloc(sizeof(struct mountpoint), GFP_KERNEL);
- 	if (!mp)
- 		return ERR_PTR(-ENOMEM);
- 
- 	ret = d_set_mounted(dentry);
- 	if (ret) {
- 		kfree(mp);
- 		return ERR_PTR(ret);
+ 	if (d_mountpoint(dentry)) {
+ mountpoint:
+ 		read_seqlock_excl(&mount_lock);
+ 		mp = lookup_mountpoint(dentry);
+ 		read_sequnlock_excl(&mount_lock);
+ 		if (mp)
+ 			goto done;
  	}
  
++<<<<<<< HEAD
 +	mp->m_dentry = dentry;
 +	mp->m_count = 1;
 +	list_add(&mp->m_hash, chain);
++=======
+ 	if (!new)
+ 		new = kmalloc(sizeof(struct mountpoint), GFP_KERNEL);
+ 	if (!new)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 
+ 	/* Exactly one processes may set d_mounted */
+ 	ret = d_set_mounted(dentry);
+ 
+ 	/* Someone else set d_mounted? */
+ 	if (ret == -EBUSY)
+ 		goto mountpoint;
+ 
+ 	/* The dentry is not available as a mountpoint? */
+ 	mp = ERR_PTR(ret);
+ 	if (ret)
+ 		goto done;
+ 
+ 	/* Add the new mountpoint to the hash table */
+ 	read_seqlock_excl(&mount_lock);
+ 	new->m_dentry = dentry;
+ 	new->m_count = 1;
+ 	hlist_add_head(&new->m_hash, mp_hash(dentry));
+ 	INIT_HLIST_HEAD(&new->m_list);
+ 	read_sequnlock_excl(&mount_lock);
+ 
+ 	mp = new;
+ 	new = NULL;
+ done:
+ 	kfree(new);
++>>>>>>> 3895dbf8985f (mnt: Protect the mountpoint hashtable with mount_lock)
  	return mp;
  }
  
@@@ -1331,6 -1603,42 +1362,45 @@@ static int do_umount(struct mount *mnt
  	return retval;
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * __detach_mounts - lazily unmount all mounts on the specified dentry
+  *
+  * During unlink, rmdir, and d_drop it is possible to loose the path
+  * to an existing mountpoint, and wind up leaking the mount.
+  * detach_mounts allows lazily unmounting those mounts instead of
+  * leaking them.
+  *
+  * The caller may hold dentry->d_inode->i_mutex.
+  */
+ void __detach_mounts(struct dentry *dentry)
+ {
+ 	struct mountpoint *mp;
+ 	struct mount *mnt;
+ 
+ 	namespace_lock();
+ 	lock_mount_hash();
+ 	mp = lookup_mountpoint(dentry);
+ 	if (IS_ERR_OR_NULL(mp))
+ 		goto out_unlock;
+ 
+ 	event++;
+ 	while (!hlist_empty(&mp->m_list)) {
+ 		mnt = hlist_entry(mp->m_list.first, struct mount, mnt_mp_list);
+ 		if (mnt->mnt.mnt_flags & MNT_UMOUNT) {
+ 			hlist_add_head(&mnt->mnt_umount.s_list, &unmounted);
+ 			umount_mnt(mnt);
+ 		}
+ 		else umount_tree(mnt, UMOUNT_CONNECTED);
+ 	}
+ 	put_mountpoint(mp);
+ out_unlock:
+ 	unlock_mount_hash();
+ 	namespace_unlock();
+ }
+ 
++>>>>>>> 3895dbf8985f (mnt: Protect the mountpoint hashtable with mount_lock)
  /* 
   * Is the caller allowed to modify his namespace?
   */
@@@ -1703,12 -2062,10 +1773,10 @@@ retry
  	namespace_lock();
  	mnt = lookup_mnt(path);
  	if (likely(!mnt)) {
- 		struct mountpoint *mp = lookup_mountpoint(dentry);
- 		if (!mp)
- 			mp = new_mountpoint(dentry);
+ 		struct mountpoint *mp = get_mountpoint(dentry);
  		if (IS_ERR(mp)) {
  			namespace_unlock();
 -			inode_unlock(dentry->d_inode);
 +			mutex_unlock(&dentry->d_inode->i_mutex);
  			return mp;
  		}
  		return mp;
@@@ -1724,9 -2081,13 +1792,13 @@@
  static void unlock_mount(struct mountpoint *where)
  {
  	struct dentry *dentry = where->m_dentry;
+ 
+ 	read_seqlock_excl(&mount_lock);
  	put_mountpoint(where);
+ 	read_sequnlock_excl(&mount_lock);
+ 
  	namespace_unlock();
 -	inode_unlock(dentry->d_inode);
 +	mutex_unlock(&dentry->d_inode->i_mutex);
  }
  
  static int graft_tree(struct mount *mnt, struct mount *p, struct mountpoint *mp)
@@@ -2782,9 -3159,11 +2854,15 @@@ SYSCALL_DEFINE2(pivot_root, const char 
  	/* mount new_root on / */
  	attach_mnt(new_mnt, real_mount(root_parent.mnt), root_mp);
  	touch_mnt_namespace(current->nsproxy->mnt_ns);
++<<<<<<< HEAD
 +	br_write_unlock(&vfsmount_lock);
- 	chroot_fs_refs(&root, &new);
++=======
+ 	/* A moved mount should not expire automatically */
+ 	list_del_init(&new_mnt->mnt_expire);
  	put_mountpoint(root_mp);
+ 	unlock_mount_hash();
++>>>>>>> 3895dbf8985f (mnt: Protect the mountpoint hashtable with mount_lock)
+ 	chroot_fs_refs(&root, &new);
  	error = 0;
  out4:
  	unlock_mount(old_mp);
diff --git a/fs/dcache.c b/fs/dcache.c
index 396c17a096b6..b1d125f09fdb 100644
--- a/fs/dcache.c
+++ b/fs/dcache.c
@@ -1166,8 +1166,11 @@ int d_set_mounted(struct dentry *dentry)
 	}
 	spin_lock(&dentry->d_lock);
 	if (!d_unlinked(dentry)) {
-		dentry->d_flags |= DCACHE_MOUNTED;
-		ret = 0;
+		ret = -EBUSY;
+		if (!d_mountpoint(dentry)) {
+			dentry->d_flags |= DCACHE_MOUNTED;
+			ret = 0;
+		}
 	}
  	spin_unlock(&dentry->d_lock);
 out:
* Unmerged path fs/namespace.c
