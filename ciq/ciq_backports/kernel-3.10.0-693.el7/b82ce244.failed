crypto: sha1-ssse3 - Disable avx2

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Herbert Xu <herbert@gondor.apana.org.au>
commit b82ce24426a4071da9529d726057e4e642948667
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/b82ce244.failed

It has been reported that sha1-avx2 can cause page faults by reading
beyond the end of the input.  This patch disables it until it can be
fixed.

	Cc: <stable@vger.kernel.org>
Fixes: 7c1da8d0d046 ("crypto: sha - SHA1 transform x86_64 AVX2")
	Reported-by: Jan Stancek <jstancek@redhat.com>
	Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
(cherry picked from commit b82ce24426a4071da9529d726057e4e642948667)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/crypto/sha1_ssse3_glue.c
diff --cc arch/x86/crypto/sha1_ssse3_glue.c
index 6a70f9407a1b,f960a043cdeb..000000000000
--- a/arch/x86/crypto/sha1_ssse3_glue.c
+++ b/arch/x86/crypto/sha1_ssse3_glue.c
@@@ -95,7 -93,122 +95,126 @@@ static int sha1_ssse3_final(struct shas
  	return sha1_ssse3_finup(desc, NULL, 0, out);
  }
  
++<<<<<<< HEAD
 +#ifdef CONFIG_AS_AVX2
++=======
+ static struct shash_alg sha1_ssse3_alg = {
+ 	.digestsize	=	SHA1_DIGEST_SIZE,
+ 	.init		=	sha1_base_init,
+ 	.update		=	sha1_ssse3_update,
+ 	.final		=	sha1_ssse3_final,
+ 	.finup		=	sha1_ssse3_finup,
+ 	.descsize	=	sizeof(struct sha1_state),
+ 	.base		=	{
+ 		.cra_name	=	"sha1",
+ 		.cra_driver_name =	"sha1-ssse3",
+ 		.cra_priority	=	150,
+ 		.cra_flags	=	CRYPTO_ALG_TYPE_SHASH,
+ 		.cra_blocksize	=	SHA1_BLOCK_SIZE,
+ 		.cra_module	=	THIS_MODULE,
+ 	}
+ };
+ 
+ static int register_sha1_ssse3(void)
+ {
+ 	if (boot_cpu_has(X86_FEATURE_SSSE3))
+ 		return crypto_register_shash(&sha1_ssse3_alg);
+ 	return 0;
+ }
+ 
+ static void unregister_sha1_ssse3(void)
+ {
+ 	if (boot_cpu_has(X86_FEATURE_SSSE3))
+ 		crypto_unregister_shash(&sha1_ssse3_alg);
+ }
+ 
+ #ifdef CONFIG_AS_AVX
+ asmlinkage void sha1_transform_avx(u32 *digest, const char *data,
+ 				   unsigned int rounds);
+ 
+ static int sha1_avx_update(struct shash_desc *desc, const u8 *data,
+ 			     unsigned int len)
+ {
+ 	return sha1_update(desc, data, len,
+ 			(sha1_transform_fn *) sha1_transform_avx);
+ }
+ 
+ static int sha1_avx_finup(struct shash_desc *desc, const u8 *data,
+ 			      unsigned int len, u8 *out)
+ {
+ 	return sha1_finup(desc, data, len, out,
+ 			(sha1_transform_fn *) sha1_transform_avx);
+ }
+ 
+ static int sha1_avx_final(struct shash_desc *desc, u8 *out)
+ {
+ 	return sha1_avx_finup(desc, NULL, 0, out);
+ }
+ 
+ static struct shash_alg sha1_avx_alg = {
+ 	.digestsize	=	SHA1_DIGEST_SIZE,
+ 	.init		=	sha1_base_init,
+ 	.update		=	sha1_avx_update,
+ 	.final		=	sha1_avx_final,
+ 	.finup		=	sha1_avx_finup,
+ 	.descsize	=	sizeof(struct sha1_state),
+ 	.base		=	{
+ 		.cra_name	=	"sha1",
+ 		.cra_driver_name =	"sha1-avx",
+ 		.cra_priority	=	160,
+ 		.cra_flags	=	CRYPTO_ALG_TYPE_SHASH,
+ 		.cra_blocksize	=	SHA1_BLOCK_SIZE,
+ 		.cra_module	=	THIS_MODULE,
+ 	}
+ };
+ 
+ static bool avx_usable(void)
+ {
+ 	if (!cpu_has_xfeatures(XFEATURE_MASK_SSE | XFEATURE_MASK_YMM, NULL)) {
+ 		if (boot_cpu_has(X86_FEATURE_AVX))
+ 			pr_info("AVX detected but unusable.\n");
+ 		return false;
+ 	}
+ 
+ 	return true;
+ }
+ 
+ static int register_sha1_avx(void)
+ {
+ 	if (avx_usable())
+ 		return crypto_register_shash(&sha1_avx_alg);
+ 	return 0;
+ }
+ 
+ static void unregister_sha1_avx(void)
+ {
+ 	if (avx_usable())
+ 		crypto_unregister_shash(&sha1_avx_alg);
+ }
+ 
+ #else  /* CONFIG_AS_AVX */
+ static inline int register_sha1_avx(void) { return 0; }
+ static inline void unregister_sha1_avx(void) { }
+ #endif /* CONFIG_AS_AVX */
+ 
+ 
+ #if defined(CONFIG_AS_AVX2) && (CONFIG_AS_AVX)
+ #define SHA1_AVX2_BLOCK_OPTSIZE	4	/* optimal 4*64 bytes of SHA1 blocks */
+ 
+ asmlinkage void sha1_transform_avx2(u32 *digest, const char *data,
+ 				    unsigned int rounds);
+ 
+ static bool avx2_usable(void)
+ {
+ 	if (false && avx_usable() && boot_cpu_has(X86_FEATURE_AVX2)
+ 		&& boot_cpu_has(X86_FEATURE_BMI1)
+ 		&& boot_cpu_has(X86_FEATURE_BMI2))
+ 		return true;
+ 
+ 	return false;
+ }
+ 
++>>>>>>> b82ce24426a4 (crypto: sha1-ssse3 - Disable avx2)
  static void sha1_apply_transform_avx2(u32 *digest, const char *data,
  				unsigned int rounds)
  {
* Unmerged path arch/x86/crypto/sha1_ssse3_glue.c
