scsi: qla2xxx: Add multiple queue pair functionality.

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [scsi] qla2xxx: Add multiple queue pair functionality (Chad Dupuis) [1414957]
Rebuild_FUZZ: 92.93%
commit-author Michael Hernandez <michael.hernandez@cavium.com>
commit d74595278f4ab192af66d9e60a9087464638beee
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/d7459527.failed

Replaced existing multiple queue functionality with framework
that allows for the creation of pairs of request and response queues,
either at start of day or dynamically.

Queue pair creation depend on module parameter "ql2xmqsupport",
which need to be enabled to create queue pair.

	Signed-off-by: Sawan Chandak <sawan.chandak@cavium.com>
	Signed-off-by: Michael Hernandez <michael.hernandez@cavium.com>
	Signed-off-by: Himanshu Madhani <himanshu.madhani@cavium.com>
	Acked-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit d74595278f4ab192af66d9e60a9087464638beee)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/qla2xxx/qla_dbg.c
#	drivers/scsi/qla2xxx/qla_def.h
#	drivers/scsi/qla2xxx/qla_gbl.h
#	drivers/scsi/qla2xxx/qla_isr.c
#	drivers/scsi/qla2xxx/qla_mid.c
#	drivers/scsi/qla2xxx/qla_os.c
diff --cc drivers/scsi/qla2xxx/qla_dbg.c
index 53a86c55945d,21d9fb7fc887..000000000000
--- a/drivers/scsi/qla2xxx/qla_dbg.c
+++ b/drivers/scsi/qla2xxx/qla_dbg.c
@@@ -11,16 -11,14 +11,24 @@@
   * ----------------------------------------------------------------------
   * |             Level            |   Last Value Used  |     Holes	|
   * ----------------------------------------------------------------------
++<<<<<<< HEAD
 + * | Module Init and Probe        |       0x018f       | 0x0146         |
 + * | Mailbox commands             |       0x1181       | 0x111a-0x111b  |
 + * |                              |                    | 0x1155-0x1158  |
 + * |                              |                    | 0x1018-0x1019  |
 + * |                              |                    | 0x1115-0x1116  |
 + * |                              |                    | 0x10ca         |
 + * | Device Discovery             |       0x2095       | 0x2020-0x2022, |
++=======
+  * | Module Init and Probe        |       0x0193       | 0x0146         |
+  * |                              |                    | 0x015b-0x0160	|
+  * |                              |                    | 0x016e		|
+  * | Mailbox commands             |       0x1199       | 0x1193		|
+  * | Device Discovery             |       0x2004       | 0x2016		|
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
   * |                              |                    | 0x2011-0x2012, |
   * |                              |                    | 0x2099-0x20a4  |
 - * | Queue Command and IO tracing |       0x3074       | 0x300b         |
 + * | Queue Command and IO tracing |       0x3075       | 0x300b         |
   * |                              |                    | 0x3027-0x3028  |
   * |                              |                    | 0x303d-0x3041  |
   * |                              |                    | 0x302d,0x3033  |
@@@ -60,18 -58,14 +68,23 @@@
   * |                              |                    | 0xb13a,0xb142  |
   * |                              |                    | 0xb13c-0xb140  |
   * |                              |                    | 0xb149		|
++<<<<<<< HEAD
 + * | MultiQ                       |       0xc00c       |		|
 + * | Misc                         |       0xd300       | 0xd016-0xd017	|
 + * |                              |                    | 0xd021,0xd024	|
 + * |                              |                    | 0xd025,0xd029	|
 + * |                              |                    | 0xd02a,0xd02e	|
 + * |                              |                    | 0xd031-0xd0ff	|
++=======
+  * | MultiQ                       |       0xc010       |		|
+  * | Misc                         |       0xd301       | 0xd031-0xd0ff	|
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
   * |                              |                    | 0xd101-0xd1fe	|
 - * |                              |                    | 0xd214-0xd2fe	|
 - * | Target Mode		  |	  0xe080       |		|
 - * | Target Mode Management	  |	  0xf09b       | 0xf002		|
 + * |                              |                    | 0xd213-0xd2fe	|
 + * | Target Mode		  |	  0xe070       | 0xe021		|
 + * | Target Mode Management	  |	  0xf072       | 0xf002-0xf003	|
   * |                              |                    | 0xf046-0xf049  |
 - * | Target Mode Task Management  |	  0x1000d      |		|
 + * | Target Mode Task Management  |	  0x1000b      |		|
   * ----------------------------------------------------------------------
   */
  
diff --cc drivers/scsi/qla2xxx/qla_def.h
index 3968a8462b15,d60cd1737ee6..000000000000
--- a/drivers/scsi/qla2xxx/qla_def.h
+++ b/drivers/scsi/qla2xxx/qla_def.h
@@@ -390,9 -401,10 +390,10 @@@ typedef struct srb 
  	uint16_t type;
  	char *name;
  	int iocbs;
+ 	struct qla_qpair *qpair;
  	union {
  		struct srb_iocb iocb_cmd;
 -		struct bsg_job *bsg_job;
 +		struct fc_bsg_job *bsg_job;
  		struct srb_cmd scmd;
  	} u;
  	void (*done)(void *, void *, int);
@@@ -2717,11 -2743,18 +2720,19 @@@ struct isp_operations 
  
  struct scsi_qla_host;
  
 -
 -#define QLA83XX_RSPQ_MSIX_ENTRY_NUMBER 1 /* refer to qla83xx_msix_entries */
 -
  struct qla_msix_entry {
  	int have_irq;
+ 	int in_use;
  	uint32_t vector;
  	uint16_t entry;
++<<<<<<< HEAD
 +	struct rsp_que *rsp;
++=======
+ 	char name[30];
+ 	void *handle;
+ 	struct irq_affinity_notify irq_notify;
+ 	int cpuid;
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
  };
  
  #define	WATCH_INTERVAL		1       /* number of seconds */
@@@ -3598,6 -3732,22 +3646,25 @@@ typedef struct scsi_qla_host 
  	uint16_t	fcoe_fcf_idx;
  	uint8_t		fcoe_vn_port_mac[6];
  
++<<<<<<< HEAD
++=======
+ 	/* list of commands waiting on workqueue */
+ 	struct list_head	qla_cmd_list;
+ 	struct list_head	qla_sess_op_cmd_list;
+ 	spinlock_t		cmd_list_lock;
+ 
+ 	/* Counter to detect races between ELS and RSCN events */
+ 	atomic_t		generation_tick;
+ 	/* Time when global fcport update has been scheduled */
+ 	int			total_fcport_update_gen;
+ 	/* List of pending LOGOs, protected by tgt_mutex */
+ 	struct list_head	logo_list;
+ 	/* List of pending PLOGI acks, protected by hw lock */
+ 	struct list_head	plogi_ack_list;
+ 
+ 	struct list_head	qp_list;
+ 
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
  	uint32_t	vp_abort_cnt;
  
  	struct fc_vport	*fc_vport;	/* holds fc_vport * for each vport */
diff --cc drivers/scsi/qla2xxx/qla_gbl.h
index 5390445f16ac,afa0116a163b..000000000000
--- a/drivers/scsi/qla2xxx/qla_gbl.h
+++ b/drivers/scsi/qla2xxx/qla_gbl.h
@@@ -222,6 -241,16 +232,19 @@@ extern unsigned long qla2x00_get_async_
  
  extern void *qla2x00_alloc_iocbs(scsi_qla_host_t *, srb_t *);
  extern int qla2x00_issue_marker(scsi_qla_host_t *, int);
++<<<<<<< HEAD
++=======
+ extern int qla24xx_walk_and_build_sglist_no_difb(struct qla_hw_data *, srb_t *,
+ 	uint32_t *, uint16_t, struct qla_tgt_cmd *);
+ extern int qla24xx_walk_and_build_sglist(struct qla_hw_data *, srb_t *,
+ 	uint32_t *, uint16_t, struct qla_tgt_cmd *);
+ extern int qla24xx_walk_and_build_prot_sglist(struct qla_hw_data *, srb_t *,
+ 	uint32_t *, uint16_t, struct qla_tgt_cmd *);
+ extern int qla24xx_get_one_block_sg(uint32_t, struct qla2_sgx *, uint32_t *);
+ extern int qla24xx_configure_prot_mode(srb_t *, uint16_t *);
+ extern int qla24xx_build_scsi_crc_2_iocbs(srb_t *,
+ 	struct cmd_type_crc_2 *, uint16_t, uint16_t, uint16_t);
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
  
  /*
   * Global Function Prototypes in qla_mbx.c source file.
diff --cc drivers/scsi/qla2xxx/qla_isr.c
index 816b38009f31,d27019b3ed74..000000000000
--- a/drivers/scsi/qla2xxx/qla_isr.c
+++ b/drivers/scsi/qla2xxx/qla_isr.c
@@@ -3001,19 -3028,8 +2995,24 @@@ qla24xx_enable_msix(struct qla_hw_data 
  	struct qla_msix_entry *qentry;
  	scsi_qla_host_t *vha = pci_get_drvdata(ha->pdev);
  
++<<<<<<< HEAD
 +	entries = kzalloc(sizeof(struct msix_entry) * ha->msix_count,
 +			GFP_KERNEL);
 +	if (!entries) {
 +		ql_log(ql_log_warn, vha, 0x00bc,
 +		    "Failed to allocate memory for msix_entry.\n");
 +		return -ENOMEM;
 +	}
 +
 +	for (i = 0; i < ha->msix_count; i++)
 +		entries[i].entry = i;
 +
 +	ret = pci_enable_msix_range(ha->pdev,
 +				    entries, MIN_MSIX_COUNT, ha->msix_count);
++=======
+ 	ret = pci_alloc_irq_vectors(ha->pdev, MIN_MSIX_COUNT, ha->msix_count,
+ 				    PCI_IRQ_MSIX | PCI_IRQ_AFFINITY);
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
  	if (ret < 0) {
  		ql_log(ql_log_fatal, vha, 0x00c7,
  		    "MSI-X: Failed to enable support, "
@@@ -3023,11 -3039,24 +3022,31 @@@
  	} else if (ret < ha->msix_count) {
  		ql_log(ql_log_warn, vha, 0x00c6,
  		    "MSI-X: Failed to enable support "
++<<<<<<< HEAD
 +		    "-- %d/%d\n Retry with %d vectors.\n",
 +		    ha->msix_count, ret, ret);
++=======
+ 		     "with %d vectors, using %d vectors.\n",
+ 		    ha->msix_count, ret);
+ 		ha->msix_count = ret;
+ 		/* Recalculate queue values */
+ 		if (ha->mqiobase && ql2xmqsupport) {
+ 			ha->max_req_queues = ha->msix_count - 1;
+ 
+ 			/* ATIOQ needs 1 vector. That's 1 less QPair */
+ 			if (QLA_TGT_MODE_ENABLED())
+ 				ha->max_req_queues--;
+ 
+ 			ha->max_rsp_queues = ha->max_req_queues;
+ 
+ 			ha->max_qpairs = ha->max_req_queues - 1;
+ 			ql_dbg_pci(ql_dbg_init, ha->pdev, 0x0190,
+ 			    "Adjusted Max no of queues pairs: %d.\n", ha->max_qpairs);
+ 		}
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
  	}
 +	ha->msix_count = ret;
 +	ha->max_rsp_queues = ha->msix_count - 1;
  	ha->msix_entries = kzalloc(sizeof(struct qla_msix_entry) *
  				ha->msix_count, GFP_KERNEL);
  	if (!ha->msix_entries) {
@@@ -3040,15 -3069,23 +3059,30 @@@
  
  	for (i = 0; i < ha->msix_count; i++) {
  		qentry = &ha->msix_entries[i];
 -		qentry->vector = pci_irq_vector(ha->pdev, i);
 -		qentry->entry = i;
 +		qentry->vector = entries[i].vector;
 +		qentry->entry = entries[i].entry;
  		qentry->have_irq = 0;
++<<<<<<< HEAD
 +		qentry->rsp = NULL;
++=======
+ 		qentry->in_use = 0;
+ 		qentry->handle = NULL;
+ 		qentry->irq_notify.notify  = qla_irq_affinity_notify;
+ 		qentry->irq_notify.release = qla_irq_affinity_release;
+ 		qentry->cpuid = -1;
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
  	}
  
  	/* Enable MSI-X vectors for the base queue */
  	for (i = 0; i < 2; i++) {
  		qentry = &ha->msix_entries[i];
++<<<<<<< HEAD
++=======
+ 		qentry->handle = rsp;
+ 		rsp->msix = qentry;
+ 		scnprintf(qentry->name, sizeof(qentry->name),
+ 		    msix_entries[i].name);
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
  		if (IS_P3P_TYPE(ha))
  			ret = request_irq(qentry->vector,
  				qla82xx_msix_entries[i].handler,
@@@ -3070,6 -3117,10 +3104,13 @@@
  	 */
  	if (QLA_TGT_MODE_ENABLED() && IS_ATIO_MSIX_CAPABLE(ha)) {
  		qentry = &ha->msix_entries[ATIO_VECTOR];
++<<<<<<< HEAD
++=======
+ 		rsp->msix = qentry;
+ 		qentry->handle = rsp;
+ 		scnprintf(qentry->name, sizeof(qentry->name),
+ 		    qla83xx_msix_entries[ATIO_VECTOR].name);
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
  		ret = request_irq(qentry->vector,
  			qla83xx_msix_entries[ATIO_VECTOR].handler,
  			0, qla83xx_msix_entries[ATIO_VECTOR].name, rsp);
@@@ -3212,21 -3264,30 +3255,19 @@@ qla2x00_free_irqs(scsi_qla_host_t *vha
  		return;
  	rsp = ha->rsp_q_map[0];
  
 -	if (ha->flags.msix_enabled) {
 -		for (i = 0; i < ha->msix_count; i++) {
 -			qentry = &ha->msix_entries[i];
 -			if (qentry->have_irq) {
 -				irq_set_affinity_notifier(qentry->vector, NULL);
 -				free_irq(pci_irq_vector(ha->pdev, i), qentry->handle);
 -			}
 -		}
 -		kfree(ha->msix_entries);
 -		ha->msix_entries = NULL;
 -		ha->flags.msix_enabled = 0;
 -		ql_dbg(ql_dbg_init, vha, 0x0042,
 -			"Disabled MSI-X.\n");
 -	} else {
 -		free_irq(pci_irq_vector(ha->pdev, 0), rsp);
 -	}
 -
 -	pci_free_irq_vectors(ha->pdev);
 +	if (ha->flags.msix_enabled)
 +		qla24xx_disable_msix(ha);
 +	else if (ha->flags.msi_enabled) {
 +		free_irq(ha->pdev->irq, rsp);
 +		pci_disable_msi(ha->pdev);
 +	} else
 +		free_irq(ha->pdev->irq, rsp);
  }
  
- 
- int qla25xx_request_irq(struct rsp_que *rsp)
+ int qla25xx_request_irq(struct qla_hw_data *ha, struct qla_qpair *qpair,
+ 	struct qla_msix_entry *msix, int vector_type)
  {
- 	struct qla_hw_data *ha = rsp->hw;
- 	struct qla_init_msix_entry *intr = &msix_entries[2];
- 	struct qla_msix_entry *msix = rsp->msix;
+ 	struct qla_init_msix_entry *intr = &msix_entries[vector_type];
  	scsi_qla_host_t *vha = pci_get_drvdata(ha->pdev);
  	int ret;
  
@@@ -3238,6 -3301,52 +3281,58 @@@
  		return ret;
  	}
  	msix->have_irq = 1;
++<<<<<<< HEAD
 +	msix->rsp = rsp;
 +	return ret;
 +}
++=======
+ 	msix->handle = qpair;
+ 	return ret;
+ }
+ 
+ 
+ /* irq_set_affinity/irqbalance will trigger notification of cpu mask update */
+ static void qla_irq_affinity_notify(struct irq_affinity_notify *notify,
+ 	const cpumask_t *mask)
+ {
+ 	struct qla_msix_entry *e =
+ 		container_of(notify, struct qla_msix_entry, irq_notify);
+ 	struct qla_hw_data *ha;
+ 	struct scsi_qla_host *base_vha;
+ 	struct rsp_que *rsp = e->handle;
+ 
+ 	/* user is recommended to set mask to just 1 cpu */
+ 	e->cpuid = cpumask_first(mask);
+ 
+ 	ha = rsp->hw;
+ 	base_vha = pci_get_drvdata(ha->pdev);
+ 
+ 	ql_dbg(ql_dbg_init, base_vha, 0xffff,
+ 	    "%s: host %ld : vector %d cpu %d \n", __func__,
+ 	    base_vha->host_no, e->vector, e->cpuid);
+ 
+ 	if (e->have_irq) {
+ 		if ((IS_QLA83XX(ha) || IS_QLA27XX(ha)) &&
+ 		    (e->entry == QLA83XX_RSPQ_MSIX_ENTRY_NUMBER)) {
+ 			ha->tgt.rspq_vector_cpuid = e->cpuid;
+ 			ql_dbg(ql_dbg_init, base_vha, 0xffff,
+ 			    "%s: host%ld: rspq vector %d cpu %d  runtime change\n",
+ 			    __func__, base_vha->host_no, e->vector, e->cpuid);
+ 		}
+ 	}
+ }
+ 
+ static void qla_irq_affinity_release(struct kref *ref)
+ {
+ 	struct irq_affinity_notify *notify =
+ 		container_of(ref, struct irq_affinity_notify, kref);
+ 	struct qla_msix_entry *e =
+ 		container_of(notify, struct qla_msix_entry, irq_notify);
+ 	struct rsp_que *rsp = e->handle;
+ 	struct scsi_qla_host *base_vha = pci_get_drvdata(rsp->hw->pdev);
+ 
+ 	ql_dbg(ql_dbg_init, base_vha, 0xffff,
+ 		"%s: host%ld: vector %d cpu %d\n", __func__,
+ 	    base_vha->host_no, e->vector, e->cpuid);
+ }
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
diff --cc drivers/scsi/qla2xxx/qla_mid.c
index c5dd594f6c31,c6d6f0d912ff..000000000000
--- a/drivers/scsi/qla2xxx/qla_mid.c
+++ b/drivers/scsi/qla2xxx/qla_mid.c
@@@ -540,9 -540,10 +540,14 @@@ qla25xx_free_rsp_que(struct scsi_qla_ho
  	uint16_t que_id = rsp->id;
  
  	if (rsp->msix && rsp->msix->have_irq) {
- 		free_irq(rsp->msix->vector, rsp);
+ 		free_irq(rsp->msix->vector, rsp->msix->handle);
  		rsp->msix->have_irq = 0;
++<<<<<<< HEAD
 +		rsp->msix->rsp = NULL;
++=======
+ 		rsp->msix->in_use = 0;
+ 		rsp->msix->handle = NULL;
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
  	}
  	dma_free_coherent(&ha->pdev->dev, (rsp->length + 1) *
  		sizeof(response_t), rsp->ring, rsp->dma);
@@@ -596,34 -597,42 +601,71 @@@ qla25xx_delete_queues(struct scsi_qla_h
  	struct req_que *req = NULL;
  	struct rsp_que *rsp = NULL;
  	struct qla_hw_data *ha = vha->hw;
+ 	struct qla_qpair *qpair, *tqpair;
  
++<<<<<<< HEAD
 +	/* Delete request queues */
 +	for (cnt = 1; cnt < ha->max_req_queues; cnt++) {
 +		req = ha->req_q_map[cnt];
 +		if (req) {
 +			ret = qla25xx_delete_req_que(vha, req);
 +			if (ret != QLA_SUCCESS) {
 +				ql_log(ql_log_warn, vha, 0x00ea,
 +				    "Couldn't delete req que %d.\n",
 +				    req->id);
 +				return ret;
++=======
+ 	if (ql2xmqsupport) {
+ 		list_for_each_entry_safe(qpair, tqpair, &vha->qp_list,
+ 		    qp_list_elem)
+ 			qla2xxx_delete_qpair(vha, qpair);
+ 	} else {
+ 		/* Delete request queues */
+ 		for (cnt = 1; cnt < ha->max_req_queues; cnt++) {
+ 			req = ha->req_q_map[cnt];
+ 			if (req && test_bit(cnt, ha->req_qid_map)) {
+ 				ret = qla25xx_delete_req_que(vha, req);
+ 				if (ret != QLA_SUCCESS) {
+ 					ql_log(ql_log_warn, vha, 0x00ea,
+ 					    "Couldn't delete req que %d.\n",
+ 					    req->id);
+ 					return ret;
+ 				}
+ 			}
+ 		}
+ 
+ 		/* Delete response queues */
+ 		for (cnt = 1; cnt < ha->max_rsp_queues; cnt++) {
+ 			rsp = ha->rsp_q_map[cnt];
+ 			if (rsp && test_bit(cnt, ha->rsp_qid_map)) {
+ 				ret = qla25xx_delete_rsp_que(vha, rsp);
+ 				if (ret != QLA_SUCCESS) {
+ 					ql_log(ql_log_warn, vha, 0x00eb,
+ 					    "Couldn't delete rsp que %d.\n",
+ 					    rsp->id);
+ 					return ret;
+ 				}
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
  			}
  		}
  	}
  
++<<<<<<< HEAD
 +	/* Delete response queues */
 +	for (cnt = 1; cnt < ha->max_rsp_queues; cnt++) {
 +		rsp = ha->rsp_q_map[cnt];
 +		if (rsp) {
 +			ret = qla25xx_delete_rsp_que(vha, rsp);
 +			if (ret != QLA_SUCCESS) {
 +				ql_log(ql_log_warn, vha, 0x00eb,
 +				    "Couldn't delete rsp que %d.\n",
 +				    rsp->id);
 +				return ret;
 +			}
 +		}
 +	}
++=======
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
  	return ret;
  }
  
diff --cc drivers/scsi/qla2xxx/qla_os.c
index f1f989d1fce1,6ef32c932826..000000000000
--- a/drivers/scsi/qla2xxx/qla_os.c
+++ b/drivers/scsi/qla2xxx/qla_os.c
@@@ -3874,8 -4148,14 +3992,16 @@@ struct scsi_qla_host *qla2x00_create_ho
  	INIT_LIST_HEAD(&vha->vp_fcports);
  	INIT_LIST_HEAD(&vha->work_list);
  	INIT_LIST_HEAD(&vha->list);
++<<<<<<< HEAD
++=======
+ 	INIT_LIST_HEAD(&vha->qla_cmd_list);
+ 	INIT_LIST_HEAD(&vha->qla_sess_op_cmd_list);
+ 	INIT_LIST_HEAD(&vha->logo_list);
+ 	INIT_LIST_HEAD(&vha->plogi_ack_list);
+ 	INIT_LIST_HEAD(&vha->qp_list);
++>>>>>>> d74595278f4a (scsi: qla2xxx: Add multiple queue pair functionality.)
  
  	spin_lock_init(&vha->work_lock);
 -	spin_lock_init(&vha->cmd_list_lock);
  
  	sprintf(vha->host_str, "%s_%ld", QLA2XXX_DRIVER_NAME, vha->host_no);
  	ql_dbg(ql_dbg_init, vha, 0x0041,
diff --git a/drivers/scsi/qla2xxx/qla_attr.c b/drivers/scsi/qla2xxx/qla_attr.c
index 8d2f18f7324e..881ec2422189 100644
--- a/drivers/scsi/qla2xxx/qla_attr.c
+++ b/drivers/scsi/qla2xxx/qla_attr.c
@@ -2046,9 +2046,9 @@ qla24xx_vport_create(struct fc_vport *fc_vport, bool disable)
 	scsi_qla_host_t *base_vha = shost_priv(fc_vport->shost);
 	scsi_qla_host_t *vha = NULL;
 	struct qla_hw_data *ha = base_vha->hw;
-	uint16_t options = 0;
 	int	cnt;
 	struct req_que *req = ha->req_q_map[0];
+	struct qla_qpair *qpair;
 
 	ret = qla24xx_vport_create_req_sanity_check(fc_vport);
 	if (ret) {
@@ -2133,15 +2133,9 @@ qla24xx_vport_create(struct fc_vport *fc_vport, bool disable)
 	qlt_vport_create(vha, ha);
 	qla24xx_vport_disable(fc_vport, disable);
 
-	if (ha->flags.cpu_affinity_enabled) {
-		req = ha->req_q_map[1];
-		ql_dbg(ql_dbg_multiq, vha, 0xc000,
-		    "Request queue %p attached with "
-		    "VP[%d], cpu affinity =%d\n",
-		    req, vha->vp_idx, ha->flags.cpu_affinity_enabled);
-		goto vport_queue;
-	} else if (ql2xmaxqueues == 1 || !ha->npiv_info)
+	if (!ql2xmqsupport || !ha->npiv_info)
 		goto vport_queue;
+
 	/* Create a request queue in QoS mode for the vport */
 	for (cnt = 0; cnt < ha->nvram_npiv_size; cnt++) {
 		if (memcmp(ha->npiv_info[cnt].port_name, vha->port_name, 8) == 0
@@ -2153,20 +2147,20 @@ qla24xx_vport_create(struct fc_vport *fc_vport, bool disable)
 	}
 
 	if (qos) {
-		ret = qla25xx_create_req_que(ha, options, vha->vp_idx, 0, 0,
-			qos);
-		if (!ret)
+		qpair = qla2xxx_create_qpair(vha, qos, vha->vp_idx);
+		if (!qpair)
 			ql_log(ql_log_warn, vha, 0x7084,
-			    "Can't create request queue for VP[%d]\n",
+			    "Can't create qpair for VP[%d]\n",
 			    vha->vp_idx);
 		else {
 			ql_dbg(ql_dbg_multiq, vha, 0xc001,
-			    "Request Que:%d Q0s: %d) created for VP[%d]\n",
-			    ret, qos, vha->vp_idx);
+			    "Queue pair: %d Qos: %d) created for VP[%d]\n",
+			    qpair->id, qos, vha->vp_idx);
 			ql_dbg(ql_dbg_user, vha, 0x7085,
-			    "Request Que:%d Q0s: %d) created for VP[%d]\n",
-			    ret, qos, vha->vp_idx);
-			req = ha->req_q_map[ret];
+			    "Queue Pair: %d Qos: %d) created for VP[%d]\n",
+			    qpair->id, qos, vha->vp_idx);
+			req = qpair->req;
+			vha->qpair = qpair;
 		}
 	}
 
@@ -2218,10 +2212,10 @@ qla24xx_vport_delete(struct fc_vport *fc_vport)
 	clear_bit(vha->vp_idx, ha->vp_idx_map);
 	mutex_unlock(&ha->vport_lock);
 
-	if (vha->req->id && !ha->flags.cpu_affinity_enabled) {
-		if (qla25xx_delete_req_que(vha, vha->req) != QLA_SUCCESS)
+	if (vha->qpair->vp_idx == vha->vp_idx) {
+		if (qla2xxx_delete_qpair(vha, vha->qpair) != QLA_SUCCESS)
 			ql_log(ql_log_warn, vha, 0x7087,
-			    "Queue delete failed.\n");
+			    "Queue Pair delete failed.\n");
 	}
 
 	ql_log(ql_log_info, vha, 0x7088, "VP[%d] deleted.\n", id);
* Unmerged path drivers/scsi/qla2xxx/qla_dbg.c
* Unmerged path drivers/scsi/qla2xxx/qla_def.h
* Unmerged path drivers/scsi/qla2xxx/qla_gbl.h
diff --git a/drivers/scsi/qla2xxx/qla_init.c b/drivers/scsi/qla2xxx/qla_init.c
index c64ee86b3feb..65df18d2952c 100644
--- a/drivers/scsi/qla2xxx/qla_init.c
+++ b/drivers/scsi/qla2xxx/qla_init.c
@@ -1761,8 +1761,7 @@ qla2x00_alloc_outstanding_cmds(struct qla_hw_data *ha, struct req_que *req)
 	if (req->outstanding_cmds)
 		return QLA_SUCCESS;
 
-	if (!IS_FWI2_CAPABLE(ha) || (ha->mqiobase &&
-	    (ql2xmultique_tag || ql2xmaxqueues > 1)))
+	if (!IS_FWI2_CAPABLE(ha))
 		req->num_outstanding_cmds = DEFAULT_OUTSTANDING_COMMANDS;
 	else {
 		if (ha->fw_xcb_count <= ha->fw_iocb_count)
@@ -4111,10 +4110,7 @@ qla2x00_loop_resync(scsi_qla_host_t *vha)
 	struct req_que *req;
 	struct rsp_que *rsp;
 
-	if (vha->hw->flags.cpu_affinity_enabled)
-		req = vha->hw->req_q_map[0];
-	else
-		req = vha->req;
+	req = vha->req;
 	rsp = req->rsp;
 
 	clear_bit(ISP_ABORT_RETRY, &vha->dpc_flags);
@@ -5903,10 +5899,10 @@ qla24xx_configure_vhba(scsi_qla_host_t *vha)
 		return -EINVAL;
 
 	rval = qla2x00_fw_ready(base_vha);
-	if (ha->flags.cpu_affinity_enabled)
-		req = ha->req_q_map[0];
+	if (vha->qpair)
+		req = vha->qpair->req;
 	else
-		req = vha->req;
+		req = ha->req_q_map[0];
 	rsp = req->rsp;
 
 	if (rval == QLA_SUCCESS) {
@@ -6588,3 +6584,162 @@ qla24xx_update_all_fcp_prio(scsi_qla_host_t *vha)
 
 	return ret;
 }
+
+struct qla_qpair *qla2xxx_create_qpair(struct scsi_qla_host *vha, int qos, int vp_idx)
+{
+	int rsp_id = 0;
+	int  req_id = 0;
+	int i;
+	struct qla_hw_data *ha = vha->hw;
+	uint16_t qpair_id = 0;
+	struct qla_qpair *qpair = NULL;
+	struct qla_msix_entry *msix;
+
+	if (!(ha->fw_attributes & BIT_6) || !ha->flags.msix_enabled) {
+		ql_log(ql_log_warn, vha, 0x00181,
+		    "FW/Driver is not multi-queue capable.\n");
+		return NULL;
+	}
+
+	if (ql2xmqsupport) {
+		qpair = kzalloc(sizeof(struct qla_qpair), GFP_KERNEL);
+		if (qpair == NULL) {
+			ql_log(ql_log_warn, vha, 0x0182,
+			    "Failed to allocate memory for queue pair.\n");
+			return NULL;
+		}
+		memset(qpair, 0, sizeof(struct qla_qpair));
+
+		qpair->hw = vha->hw;
+
+		/* Assign available que pair id */
+		mutex_lock(&ha->mq_lock);
+		qpair_id = find_first_zero_bit(ha->qpair_qid_map, ha->max_qpairs);
+		if (qpair_id >= ha->max_qpairs) {
+			mutex_unlock(&ha->mq_lock);
+			ql_log(ql_log_warn, vha, 0x0183,
+			    "No resources to create additional q pair.\n");
+			goto fail_qid_map;
+		}
+		set_bit(qpair_id, ha->qpair_qid_map);
+		ha->queue_pair_map[qpair_id] = qpair;
+		qpair->id = qpair_id;
+		qpair->vp_idx = vp_idx;
+
+		for (i = 0; i < ha->msix_count; i++) {
+			msix = &ha->msix_entries[i + 2];
+			if (msix->in_use)
+				continue;
+			qpair->msix = msix;
+			ql_log(ql_dbg_multiq, vha, 0xc00f,
+			    "Vector %x selected for qpair\n", msix->vector);
+			break;
+		}
+		if (!qpair->msix) {
+			ql_log(ql_log_warn, vha, 0x0184,
+			    "Out of MSI-X vectors!.\n");
+			goto fail_msix;
+		}
+
+		qpair->msix->in_use = 1;
+		list_add_tail(&qpair->qp_list_elem, &vha->qp_list);
+
+		mutex_unlock(&ha->mq_lock);
+
+		/* Create response queue first */
+		rsp_id = qla25xx_create_rsp_que(ha, 0, 0, 0, qpair);
+		if (!rsp_id) {
+			ql_log(ql_log_warn, vha, 0x0185,
+			    "Failed to create response queue.\n");
+			goto fail_rsp;
+		}
+
+		qpair->rsp = ha->rsp_q_map[rsp_id];
+
+		/* Create request queue */
+		req_id = qla25xx_create_req_que(ha, 0, vp_idx, 0, rsp_id, qos);
+		if (!req_id) {
+			ql_log(ql_log_warn, vha, 0x0186,
+			    "Failed to create request queue.\n");
+			goto fail_req;
+		}
+
+		qpair->req = ha->req_q_map[req_id];
+		qpair->rsp->req = qpair->req;
+
+		if (IS_T10_PI_CAPABLE(ha) && ql2xenabledif) {
+			if (ha->fw_attributes & BIT_4)
+				qpair->difdix_supported = 1;
+		}
+
+		qpair->srb_mempool = mempool_create_slab_pool(SRB_MIN_REQ, srb_cachep);
+		if (!qpair->srb_mempool) {
+			ql_log(ql_log_warn, vha, 0x0191,
+			    "Failed to create srb mempool for qpair %d\n",
+			    qpair->id);
+			goto fail_mempool;
+		}
+
+		/* Mark as online */
+		qpair->online = 1;
+
+		if (!vha->flags.qpairs_available)
+			vha->flags.qpairs_available = 1;
+
+		ql_dbg(ql_dbg_multiq, vha, 0xc00d,
+		    "Request/Response queue pair created, id %d\n",
+		    qpair->id);
+		ql_dbg(ql_dbg_init, vha, 0x0187,
+		    "Request/Response queue pair created, id %d\n",
+		    qpair->id);
+	}
+	return qpair;
+
+fail_mempool:
+fail_req:
+	qla25xx_delete_rsp_que(vha, qpair->rsp);
+fail_rsp:
+	mutex_lock(&ha->mq_lock);
+	qpair->msix->in_use = 0;
+	list_del(&qpair->qp_list_elem);
+	if (list_empty(&vha->qp_list))
+		vha->flags.qpairs_available = 0;
+fail_msix:
+	ha->queue_pair_map[qpair_id] = NULL;
+	clear_bit(qpair_id, ha->qpair_qid_map);
+	mutex_unlock(&ha->mq_lock);
+fail_qid_map:
+	kfree(qpair);
+	return NULL;
+}
+
+int qla2xxx_delete_qpair(struct scsi_qla_host *vha, struct qla_qpair *qpair)
+{
+	int ret;
+	struct qla_hw_data *ha = qpair->hw;
+
+	qpair->delete_in_progress = 1;
+	while (atomic_read(&qpair->ref_count))
+		msleep(500);
+
+	ret = qla25xx_delete_req_que(vha, qpair->req);
+	if (ret != QLA_SUCCESS)
+		goto fail;
+	ret = qla25xx_delete_rsp_que(vha, qpair->rsp);
+	if (ret != QLA_SUCCESS)
+		goto fail;
+
+	mutex_lock(&ha->mq_lock);
+	ha->queue_pair_map[qpair->id] = NULL;
+	clear_bit(qpair->id, ha->qpair_qid_map);
+	list_del(&qpair->qp_list_elem);
+	if (list_empty(&vha->qp_list))
+		vha->flags.qpairs_available = 0;
+	mempool_destroy(qpair->srb_mempool);
+	kfree(qpair);
+	mutex_unlock(&ha->mq_lock);
+
+	return QLA_SUCCESS;
+fail:
+	return ret;
+}
diff --git a/drivers/scsi/qla2xxx/qla_inline.h b/drivers/scsi/qla2xxx/qla_inline.h
index fcaf4ecdc777..0ac13772fc47 100644
--- a/drivers/scsi/qla2xxx/qla_inline.h
+++ b/drivers/scsi/qla2xxx/qla_inline.h
@@ -206,6 +206,36 @@ qla2x00_reset_active(scsi_qla_host_t *vha)
 	    test_bit(ABORT_ISP_ACTIVE, &vha->dpc_flags);
 }
 
+static inline srb_t *
+qla2xxx_get_qpair_sp(struct qla_qpair *qpair, fc_port_t *fcport, gfp_t flag)
+{
+	srb_t *sp = NULL;
+	uint8_t bail;
+
+	QLA_QPAIR_MARK_BUSY(qpair, bail);
+	if (unlikely(bail))
+		return NULL;
+
+	sp = mempool_alloc(qpair->srb_mempool, flag);
+	if (!sp)
+		goto done;
+
+	memset(sp, 0, sizeof(*sp));
+	sp->fcport = fcport;
+	sp->iocbs = 1;
+done:
+	if (!sp)
+		QLA_QPAIR_MARK_NOT_BUSY(qpair);
+	return sp;
+}
+
+static inline void
+qla2xxx_rel_qpair_sp(struct qla_qpair *qpair, srb_t *sp)
+{
+	mempool_free(sp, qpair->srb_mempool);
+	QLA_QPAIR_MARK_NOT_BUSY(qpair);
+}
+
 static inline srb_t *
 qla2x00_get_sp(scsi_qla_host_t *vha, fc_port_t *fcport, gfp_t flag)
 {
diff --git a/drivers/scsi/qla2xxx/qla_iocb.c b/drivers/scsi/qla2xxx/qla_iocb.c
index 16c8700d7d5f..2aea13d9d71e 100644
--- a/drivers/scsi/qla2xxx/qla_iocb.c
+++ b/drivers/scsi/qla2xxx/qla_iocb.c
@@ -12,7 +12,6 @@
 
 #include <scsi/scsi_tcq.h>
 
-static void qla25xx_set_que(srb_t *, struct rsp_que **);
 /**
  * qla2x00_get_cmd_direction() - Determine control_flag data direction.
  * @cmd: SCSI command
@@ -143,7 +142,7 @@ qla2x00_prep_cont_type1_iocb(scsi_qla_host_t *vha, struct req_que *req)
 	return (cont_pkt);
 }
 
-static inline int
+inline int
 qla24xx_configure_prot_mode(srb_t *sp, uint16_t *fw_prot_opts)
 {
 	struct scsi_cmnd *cmd = GET_CMD_SP(sp);
@@ -694,10 +693,11 @@ qla24xx_calc_dsd_lists(uint16_t dsds)
  * @sp: SRB command to process
  * @cmd_pkt: Command type 3 IOCB
  * @tot_dsds: Total number of segments to transfer
+ * @req: pointer to request queue
  */
-static inline void
+inline void
 qla24xx_build_scsi_iocbs(srb_t *sp, struct cmd_type_7 *cmd_pkt,
-    uint16_t tot_dsds)
+	uint16_t tot_dsds, struct req_que *req)
 {
 	uint16_t	avail_dsds;
 	uint32_t	*cur_dsd;
@@ -746,7 +746,7 @@ qla24xx_build_scsi_iocbs(srb_t *sp, struct cmd_type_7 *cmd_pkt,
 			 * Five DSDs are available in the Continuation
 			 * Type 1 IOCB.
 			 */
-			cont_pkt = qla2x00_prep_cont_type1_iocb(vha, vha->req);
+			cont_pkt = qla2x00_prep_cont_type1_iocb(vha, req);
 			cur_dsd = (uint32_t *)cont_pkt->dseg_0_address;
 			avail_dsds = 5;
 		}
@@ -846,24 +846,7 @@ qla24xx_set_t10dif_tags(srb_t *sp, struct fw_dif_context *pkt,
 	}
 }
 
-struct qla2_sgx {
-	dma_addr_t		dma_addr;	/* OUT */
-	uint32_t		dma_len;	/* OUT */
-
-	uint32_t		tot_bytes;	/* IN */
-	struct scatterlist	*cur_sg;	/* IN */
-
-	/* for book keeping, bzero on initial invocation */
-	uint32_t		bytes_consumed;
-	uint32_t		num_bytes;
-	uint32_t		tot_partial;
-
-	/* for debugging */
-	uint32_t		num_sg;
-	srb_t			*sp;
-};
-
-static int
+int
 qla24xx_get_one_block_sg(uint32_t blk_sz, struct qla2_sgx *sgx,
 	uint32_t *partial)
 {
@@ -1150,7 +1133,7 @@ qla24xx_walk_and_build_prot_sglist(struct qla_hw_data *ha, srb_t *sp,
  * @cmd_pkt: Command type 3 IOCB
  * @tot_dsds: Total number of segments to transfer
  */
-static inline int
+inline int
 qla24xx_build_scsi_crc_2_iocbs(srb_t *sp, struct cmd_type_crc_2 *cmd_pkt,
     uint16_t tot_dsds, uint16_t tot_prot_dsds, uint16_t fw_prot_opts)
 {
@@ -1399,8 +1382,8 @@ qla24xx_start_scsi(srb_t *sp)
 	char		tag[2];
 
 	/* Setup device pointers. */
-	qla25xx_set_que(sp, &rsp);
 	req = vha->req;
+	rsp = req->rsp;
 
 	/* So we know we haven't pci_map'ed anything yet */
 	tot_dsds = 0;
@@ -1501,12 +1484,10 @@ qla24xx_start_scsi(srb_t *sp)
 	cmd_pkt->byte_count = cpu_to_le32((uint32_t)scsi_bufflen(cmd));
 
 	/* Build IOCB segments */
-	qla24xx_build_scsi_iocbs(sp, cmd_pkt, tot_dsds);
+	qla24xx_build_scsi_iocbs(sp, cmd_pkt, tot_dsds, req);
 
 	/* Set total data segment count. */
 	cmd_pkt->entry_count = (uint8_t)req_cnt;
-	/* Specify response queue number where completion should happen */
-	cmd_pkt->entry_status = (uint8_t) rsp->id;
 	wmb();
 	/* Adjust ring index. */
 	req->ring_index++;
@@ -1575,9 +1556,8 @@ qla24xx_dif_start_scsi(srb_t *sp)
 	}
 
 	/* Setup device pointers. */
-
-	qla25xx_set_que(sp, &rsp);
 	req = vha->req;
+	rsp = req->rsp;
 
 	/* So we know we haven't pci_map'ed anything yet */
 	tot_dsds = 0;
@@ -1742,18 +1722,365 @@ queuing_error:
 	return QLA_FUNCTION_FAILED;
 }
 
-
-static void qla25xx_set_que(srb_t *sp, struct rsp_que **rsp)
+/**
+ * qla2xxx_start_scsi_mq() - Send a SCSI command to the ISP
+ * @sp: command to send to the ISP
+ *
+ * Returns non-zero if a failure occurred, else zero.
+ */
+static int
+qla2xxx_start_scsi_mq(srb_t *sp)
 {
+	int		nseg;
+	unsigned long   flags;
+	uint32_t	*clr_ptr;
+	uint32_t        index;
+	uint32_t	handle;
+	struct cmd_type_7 *cmd_pkt;
+	uint16_t	cnt;
+	uint16_t	req_cnt;
+	uint16_t	tot_dsds;
+	struct req_que *req = NULL;
+	struct rsp_que *rsp = NULL;
 	struct scsi_cmnd *cmd = GET_CMD_SP(sp);
-	struct qla_hw_data *ha = sp->fcport->vha->hw;
-	int affinity = cmd->request->cpu;
+	struct scsi_qla_host *vha = sp->fcport->vha;
+	struct qla_hw_data *ha = vha->hw;
+	struct qla_qpair *qpair = sp->qpair;
+
+	/* Setup qpair pointers */
+	rsp = qpair->rsp;
+	req = qpair->req;
+
+	/* So we know we haven't pci_map'ed anything yet */
+	tot_dsds = 0;
+
+	/* Send marker if required */
+	if (vha->marker_needed != 0) {
+		if (qla2x00_marker(vha, req, rsp, 0, 0, MK_SYNC_ALL) !=
+		    QLA_SUCCESS)
+			return QLA_FUNCTION_FAILED;
+		vha->marker_needed = 0;
+	}
+
+	/* Acquire qpair specific lock */
+	spin_lock_irqsave(&qpair->qp_lock, flags);
+
+	/* Check for room in outstanding command list. */
+	handle = req->current_outstanding_cmd;
+	for (index = 1; index < req->num_outstanding_cmds; index++) {
+		handle++;
+		if (handle == req->num_outstanding_cmds)
+			handle = 1;
+		if (!req->outstanding_cmds[handle])
+			break;
+	}
+	if (index == req->num_outstanding_cmds)
+		goto queuing_error;
+
+	/* Map the sg table so we have an accurate count of sg entries needed */
+	if (scsi_sg_count(cmd)) {
+		nseg = dma_map_sg(&ha->pdev->dev, scsi_sglist(cmd),
+		    scsi_sg_count(cmd), cmd->sc_data_direction);
+		if (unlikely(!nseg))
+			goto queuing_error;
+	} else
+		nseg = 0;
+
+	tot_dsds = nseg;
+	req_cnt = qla24xx_calc_iocbs(vha, tot_dsds);
+	if (req->cnt < (req_cnt + 2)) {
+		cnt = IS_SHADOW_REG_CAPABLE(ha) ? *req->out_ptr :
+		    RD_REG_DWORD_RELAXED(req->req_q_out);
+		if (req->ring_index < cnt)
+			req->cnt = cnt - req->ring_index;
+		else
+			req->cnt = req->length -
+				(req->ring_index - cnt);
+		if (req->cnt < (req_cnt + 2))
+			goto queuing_error;
+	}
+
+	/* Build command packet. */
+	req->current_outstanding_cmd = handle;
+	req->outstanding_cmds[handle] = sp;
+	sp->handle = handle;
+	cmd->host_scribble = (unsigned char *)(unsigned long)handle;
+	req->cnt -= req_cnt;
+
+	cmd_pkt = (struct cmd_type_7 *)req->ring_ptr;
+	cmd_pkt->handle = MAKE_HANDLE(req->id, handle);
+
+	/* Zero out remaining portion of packet. */
+	/*    tagged queuing modifier -- default is TSK_SIMPLE (0). */
+	clr_ptr = (uint32_t *)cmd_pkt + 2;
+	memset(clr_ptr, 0, REQUEST_ENTRY_SIZE - 8);
+	cmd_pkt->dseg_count = cpu_to_le16(tot_dsds);
+
+	/* Set NPORT-ID and LUN number*/
+	cmd_pkt->nport_handle = cpu_to_le16(sp->fcport->loop_id);
+	cmd_pkt->port_id[0] = sp->fcport->d_id.b.al_pa;
+	cmd_pkt->port_id[1] = sp->fcport->d_id.b.area;
+	cmd_pkt->port_id[2] = sp->fcport->d_id.b.domain;
+	cmd_pkt->vp_index = sp->fcport->vha->vp_idx;
+
+	int_to_scsilun(cmd->device->lun, &cmd_pkt->lun);
+	host_to_fcp_swap((uint8_t *)&cmd_pkt->lun, sizeof(cmd_pkt->lun));
+
+	cmd_pkt->task = TSK_SIMPLE;
+
+	/* Load SCSI command packet. */
+	memcpy(cmd_pkt->fcp_cdb, cmd->cmnd, cmd->cmd_len);
+	host_to_fcp_swap(cmd_pkt->fcp_cdb, sizeof(cmd_pkt->fcp_cdb));
+
+	cmd_pkt->byte_count = cpu_to_le32((uint32_t)scsi_bufflen(cmd));
+
+	/* Build IOCB segments */
+	qla24xx_build_scsi_iocbs(sp, cmd_pkt, tot_dsds, req);
+
+	/* Set total data segment count. */
+	cmd_pkt->entry_count = (uint8_t)req_cnt;
+	wmb();
+	/* Adjust ring index. */
+	req->ring_index++;
+	if (req->ring_index == req->length) {
+		req->ring_index = 0;
+		req->ring_ptr = req->ring;
+	} else
+		req->ring_ptr++;
+
+	sp->flags |= SRB_DMA_VALID;
+
+	/* Set chip new ring index. */
+	WRT_REG_DWORD(req->req_q_in, req->ring_index);
+
+	/* Manage unprocessed RIO/ZIO commands in response queue. */
+	if (vha->flags.process_response_queue &&
+		rsp->ring_ptr->signature != RESPONSE_PROCESSED)
+		qla24xx_process_response_queue(vha, rsp);
+
+	spin_unlock_irqrestore(&qpair->qp_lock, flags);
+	return QLA_SUCCESS;
+
+queuing_error:
+	if (tot_dsds)
+		scsi_dma_unmap(cmd);
+
+	spin_unlock_irqrestore(&qpair->qp_lock, flags);
+
+	return QLA_FUNCTION_FAILED;
+}
+
 
-	if (ha->flags.cpu_affinity_enabled && affinity >= 0 &&
-		affinity < ha->max_rsp_queues - 1)
-		*rsp = ha->rsp_q_map[affinity + 1];
-	 else
-		*rsp = ha->rsp_q_map[0];
+/**
+ * qla2xxx_dif_start_scsi_mq() - Send a SCSI command to the ISP
+ * @sp: command to send to the ISP
+ *
+ * Returns non-zero if a failure occurred, else zero.
+ */
+int
+qla2xxx_dif_start_scsi_mq(srb_t *sp)
+{
+	int			nseg;
+	unsigned long		flags;
+	uint32_t		*clr_ptr;
+	uint32_t		index;
+	uint32_t		handle;
+	uint16_t		cnt;
+	uint16_t		req_cnt = 0;
+	uint16_t		tot_dsds;
+	uint16_t		tot_prot_dsds;
+	uint16_t		fw_prot_opts = 0;
+	struct req_que		*req = NULL;
+	struct rsp_que		*rsp = NULL;
+	struct scsi_cmnd	*cmd = GET_CMD_SP(sp);
+	struct scsi_qla_host	*vha = sp->fcport->vha;
+	struct qla_hw_data	*ha = vha->hw;
+	struct cmd_type_crc_2	*cmd_pkt;
+	uint32_t		status = 0;
+	struct qla_qpair	*qpair = sp->qpair;
+
+#define QDSS_GOT_Q_SPACE	BIT_0
+
+	/* Check for host side state */
+	if (!qpair->online) {
+		cmd->result = DID_NO_CONNECT << 16;
+		return QLA_INTERFACE_ERROR;
+	}
+
+	if (!qpair->difdix_supported &&
+		scsi_get_prot_op(cmd) != SCSI_PROT_NORMAL) {
+		cmd->result = DID_NO_CONNECT << 16;
+		return QLA_INTERFACE_ERROR;
+	}
+
+	/* Only process protection or >16 cdb in this routine */
+	if (scsi_get_prot_op(cmd) == SCSI_PROT_NORMAL) {
+		if (cmd->cmd_len <= 16)
+			return qla2xxx_start_scsi_mq(sp);
+	}
+
+	/* Setup qpair pointers */
+	rsp = qpair->rsp;
+	req = qpair->req;
+
+	/* So we know we haven't pci_map'ed anything yet */
+	tot_dsds = 0;
+
+	/* Send marker if required */
+	if (vha->marker_needed != 0) {
+		if (qla2x00_marker(vha, req, rsp, 0, 0, MK_SYNC_ALL) !=
+		    QLA_SUCCESS)
+			return QLA_FUNCTION_FAILED;
+		vha->marker_needed = 0;
+	}
+
+	/* Acquire ring specific lock */
+	spin_lock_irqsave(&qpair->qp_lock, flags);
+
+	/* Check for room in outstanding command list. */
+	handle = req->current_outstanding_cmd;
+	for (index = 1; index < req->num_outstanding_cmds; index++) {
+		handle++;
+		if (handle == req->num_outstanding_cmds)
+			handle = 1;
+		if (!req->outstanding_cmds[handle])
+			break;
+	}
+
+	if (index == req->num_outstanding_cmds)
+		goto queuing_error;
+
+	/* Compute number of required data segments */
+	/* Map the sg table so we have an accurate count of sg entries needed */
+	if (scsi_sg_count(cmd)) {
+		nseg = dma_map_sg(&ha->pdev->dev, scsi_sglist(cmd),
+		    scsi_sg_count(cmd), cmd->sc_data_direction);
+		if (unlikely(!nseg))
+			goto queuing_error;
+		else
+			sp->flags |= SRB_DMA_VALID;
+
+		if ((scsi_get_prot_op(cmd) == SCSI_PROT_READ_INSERT) ||
+		    (scsi_get_prot_op(cmd) == SCSI_PROT_WRITE_STRIP)) {
+			struct qla2_sgx sgx;
+			uint32_t	partial;
+
+			memset(&sgx, 0, sizeof(struct qla2_sgx));
+			sgx.tot_bytes = scsi_bufflen(cmd);
+			sgx.cur_sg = scsi_sglist(cmd);
+			sgx.sp = sp;
+
+			nseg = 0;
+			while (qla24xx_get_one_block_sg(
+			    cmd->device->sector_size, &sgx, &partial))
+				nseg++;
+		}
+	} else
+		nseg = 0;
+
+	/* number of required data segments */
+	tot_dsds = nseg;
+
+	/* Compute number of required protection segments */
+	if (qla24xx_configure_prot_mode(sp, &fw_prot_opts)) {
+		nseg = dma_map_sg(&ha->pdev->dev, scsi_prot_sglist(cmd),
+		    scsi_prot_sg_count(cmd), cmd->sc_data_direction);
+		if (unlikely(!nseg))
+			goto queuing_error;
+		else
+			sp->flags |= SRB_CRC_PROT_DMA_VALID;
+
+		if ((scsi_get_prot_op(cmd) == SCSI_PROT_READ_INSERT) ||
+		    (scsi_get_prot_op(cmd) == SCSI_PROT_WRITE_STRIP)) {
+			nseg = scsi_bufflen(cmd) / cmd->device->sector_size;
+		}
+	} else {
+		nseg = 0;
+	}
+
+	req_cnt = 1;
+	/* Total Data and protection sg segment(s) */
+	tot_prot_dsds = nseg;
+	tot_dsds += nseg;
+	if (req->cnt < (req_cnt + 2)) {
+		cnt = IS_SHADOW_REG_CAPABLE(ha) ? *req->out_ptr :
+		    RD_REG_DWORD_RELAXED(req->req_q_out);
+		if (req->ring_index < cnt)
+			req->cnt = cnt - req->ring_index;
+		else
+			req->cnt = req->length -
+				(req->ring_index - cnt);
+		if (req->cnt < (req_cnt + 2))
+			goto queuing_error;
+	}
+
+	status |= QDSS_GOT_Q_SPACE;
+
+	/* Build header part of command packet (excluding the OPCODE). */
+	req->current_outstanding_cmd = handle;
+	req->outstanding_cmds[handle] = sp;
+	sp->handle = handle;
+	cmd->host_scribble = (unsigned char *)(unsigned long)handle;
+	req->cnt -= req_cnt;
+
+	/* Fill-in common area */
+	cmd_pkt = (struct cmd_type_crc_2 *)req->ring_ptr;
+	cmd_pkt->handle = MAKE_HANDLE(req->id, handle);
+
+	clr_ptr = (uint32_t *)cmd_pkt + 2;
+	memset(clr_ptr, 0, REQUEST_ENTRY_SIZE - 8);
+
+	/* Set NPORT-ID and LUN number*/
+	cmd_pkt->nport_handle = cpu_to_le16(sp->fcport->loop_id);
+	cmd_pkt->port_id[0] = sp->fcport->d_id.b.al_pa;
+	cmd_pkt->port_id[1] = sp->fcport->d_id.b.area;
+	cmd_pkt->port_id[2] = sp->fcport->d_id.b.domain;
+
+	int_to_scsilun(cmd->device->lun, &cmd_pkt->lun);
+	host_to_fcp_swap((uint8_t *)&cmd_pkt->lun, sizeof(cmd_pkt->lun));
+
+	/* Total Data and protection segment(s) */
+	cmd_pkt->dseg_count = cpu_to_le16(tot_dsds);
+
+	/* Build IOCB segments and adjust for data protection segments */
+	if (qla24xx_build_scsi_crc_2_iocbs(sp, (struct cmd_type_crc_2 *)
+	    req->ring_ptr, tot_dsds, tot_prot_dsds, fw_prot_opts) !=
+		QLA_SUCCESS)
+		goto queuing_error;
+
+	cmd_pkt->entry_count = (uint8_t)req_cnt;
+	cmd_pkt->timeout = cpu_to_le16(0);
+	wmb();
+
+	/* Adjust ring index. */
+	req->ring_index++;
+	if (req->ring_index == req->length) {
+		req->ring_index = 0;
+		req->ring_ptr = req->ring;
+	} else
+		req->ring_ptr++;
+
+	/* Set chip new ring index. */
+	WRT_REG_DWORD(req->req_q_in, req->ring_index);
+
+	/* Manage unprocessed RIO/ZIO commands in response queue. */
+	if (vha->flags.process_response_queue &&
+	    rsp->ring_ptr->signature != RESPONSE_PROCESSED)
+		qla24xx_process_response_queue(vha, rsp);
+
+	spin_unlock_irqrestore(&qpair->qp_lock, flags);
+
+	return QLA_SUCCESS;
+
+queuing_error:
+	if (status & QDSS_GOT_Q_SPACE) {
+		req->outstanding_cmds[handle] = NULL;
+		req->cnt += req_cnt;
+	}
+	/* Cleanup will be performed by the caller (queuecommand) */
+
+	spin_unlock_irqrestore(&qpair->qp_lock, flags);
+	return QLA_FUNCTION_FAILED;
 }
 
 /* Generic Control-SRB manipulation functions. */
@@ -2473,7 +2800,7 @@ sufficient_dsds:
 		cmd_pkt->byte_count = cpu_to_le32((uint32_t)scsi_bufflen(cmd));
 
 		/* Build IOCB segments */
-		qla24xx_build_scsi_iocbs(sp, cmd_pkt, tot_dsds);
+		qla24xx_build_scsi_iocbs(sp, cmd_pkt, tot_dsds, req);
 
 		/* Set total data segment count. */
 		cmd_pkt->entry_count = (uint8_t)req_cnt;
* Unmerged path drivers/scsi/qla2xxx/qla_isr.c
diff --git a/drivers/scsi/qla2xxx/qla_mbx.c b/drivers/scsi/qla2xxx/qla_mbx.c
index fbe27de90b21..577f109c434c 100644
--- a/drivers/scsi/qla2xxx/qla_mbx.c
+++ b/drivers/scsi/qla2xxx/qla_mbx.c
@@ -932,12 +932,17 @@ qla2x00_abort_command(srb_t *sp)
 	fc_port_t	*fcport = sp->fcport;
 	scsi_qla_host_t *vha = fcport->vha;
 	struct qla_hw_data *ha = vha->hw;
-	struct req_que *req = vha->req;
+	struct req_que *req;
 	struct scsi_cmnd *cmd = GET_CMD_SP(sp);
 
 	ql_dbg(ql_dbg_mbx + ql_dbg_verbose, vha, 0x103b,
 	    "Entered %s.\n", __func__);
 
+	if (vha->flags.qpairs_available && sp->qpair)
+		req = sp->qpair->req;
+	else
+		req = vha->req;
+
 	spin_lock_irqsave(&ha->hardware_lock, flags);
 	for (handle = 1; handle < req->num_outstanding_cmds; handle++) {
 		if (req->outstanding_cmds[handle] == sp)
@@ -1890,10 +1895,10 @@ qla24xx_login_fabric(scsi_qla_host_t *vha, uint16_t loop_id, uint8_t domain,
 	ql_dbg(ql_dbg_mbx + ql_dbg_verbose, vha, 0x1061,
 	    "Entered %s.\n", __func__);
 
-	if (ha->flags.cpu_affinity_enabled)
-		req = ha->req_q_map[0];
+	if (vha->vp_idx && vha->qpair)
+		req = vha->qpair->req;
 	else
-		req = vha->req;
+		req = ha->req_q_map[0];
 
 	lg = dma_pool_alloc(ha->s_dma_pool, GFP_KERNEL, &lg_dma);
 	if (lg == NULL) {
@@ -2173,10 +2178,7 @@ qla24xx_fabric_logout(scsi_qla_host_t *vha, uint16_t loop_id, uint8_t domain,
 	}
 	memset(lg, 0, sizeof(struct logio_entry_24xx));
 
-	if (ql2xmaxqueues > 1)
-		req = ha->req_q_map[0];
-	else
-		req = vha->req;
+	req = vha->req;
 	lg->entry_type = LOGINOUT_PORT_IOCB_TYPE;
 	lg->entry_count = 1;
 	lg->handle = MAKE_HANDLE(req->id, lg->handle);
@@ -2645,6 +2647,9 @@ qla24xx_abort_command(srb_t *sp)
 	ql_dbg(ql_dbg_mbx + ql_dbg_verbose, vha, 0x108c,
 	    "Entered %s.\n", __func__);
 
+	if (vha->flags.qpairs_available && sp->qpair)
+		req = sp->qpair->req;
+
 	if (ql2xasynctmfenable)
 		return qla24xx_async_abort_command(sp);
 
@@ -2725,6 +2730,7 @@ __qla24xx_issue_tmf(char *name, uint32_t type, struct fc_port *fcport,
 	struct qla_hw_data *ha;
 	struct req_que *req;
 	struct rsp_que *rsp;
+	struct qla_qpair *qpair;
 
 	vha = fcport->vha;
 	ha = vha->hw;
@@ -2733,10 +2739,15 @@ __qla24xx_issue_tmf(char *name, uint32_t type, struct fc_port *fcport,
 	ql_dbg(ql_dbg_mbx + ql_dbg_verbose, vha, 0x1092,
 	    "Entered %s.\n", __func__);
 
-	if (ha->flags.cpu_affinity_enabled)
-		rsp = ha->rsp_q_map[tag + 1];
-	else
+	if (vha->vp_idx && vha->qpair) {
+		/* NPIV port */
+		qpair = vha->qpair;
+		rsp = qpair->rsp;
+		req = qpair->req;
+	} else {
 		rsp = req->rsp;
+	}
+
 	tsk = dma_pool_alloc(ha->s_dma_pool, GFP_KERNEL, &tsk_dma);
 	if (tsk == NULL) {
 		ql_log(ql_log_warn, vha, 0x1093,
* Unmerged path drivers/scsi/qla2xxx/qla_mid.c
* Unmerged path drivers/scsi/qla2xxx/qla_os.c
