alx: prepare resource allocation for multi queue support

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Tobias Regnery <tobias.regnery@gmail.com>
commit a4076d347f9a27cdd85186bef2f4207b6187c35e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/a4076d34.failed

Allocate, initialise and free alx_tx_queue structs based on the number of
alx_napi structures. Also increase the size of the descriptor memory based
on the number of tx queues in use.

Based on the downstream driver at github.com/qca/alx

	Signed-off-by: Tobias Regnery <tobias.regnery@gmail.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit a4076d347f9a27cdd85186bef2f4207b6187c35e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/atheros/alx/main.c
diff --cc drivers/net/ethernet/atheros/alx/main.c
index b165b9e58ad3,c5f09d2616a4..000000000000
--- a/drivers/net/ethernet/atheros/alx/main.c
+++ b/drivers/net/ethernet/atheros/alx/main.c
@@@ -445,23 -438,36 +450,56 @@@ static void alx_init_ring_ptrs(struct a
  {
  	struct alx_hw *hw = &alx->hw;
  	u32 addr_hi = ((u64)alx->descmem.dma) >> 32;
++<<<<<<< HEAD
 +
 +	alx->rxq.read_idx = 0;
 +	alx->rxq.write_idx = 0;
 +	alx->rxq.rrd_read_idx = 0;
 +	alx_write_mem32(hw, ALX_RX_BASE_ADDR_HI, addr_hi);
 +	alx_write_mem32(hw, ALX_RRD_ADDR_LO, alx->rxq.rrd_dma);
 +	alx_write_mem32(hw, ALX_RRD_RING_SZ, alx->rx_ringsz);
 +	alx_write_mem32(hw, ALX_RFD_ADDR_LO, alx->rxq.rfd_dma);
 +	alx_write_mem32(hw, ALX_RFD_RING_SZ, alx->rx_ringsz);
 +	alx_write_mem32(hw, ALX_RFD_BUF_SZ, alx->rxbuf_size);
 +
 +	alx->txq.read_idx = 0;
 +	alx->txq.write_idx = 0;
 +	alx_write_mem32(hw, ALX_TX_BASE_ADDR_HI, addr_hi);
 +	alx_write_mem32(hw, ALX_TPD_PRI0_ADDR_LO, alx->txq.tpd_dma);
 +	alx_write_mem32(hw, ALX_TPD_RING_SZ, alx->tx_ringsz);
 +
++=======
+ 	struct alx_napi *np;
+ 	int i;
+ 
+ 	for (i = 0; i < alx->num_napi; i++) {
+ 		np = alx->qnapi[i];
+ 		if (np->txq) {
+ 			np->txq->read_idx = 0;
+ 			np->txq->write_idx = 0;
+ 			alx_write_mem32(hw,
+ 					txring_header_reg[np->txq->queue_idx],
+ 					np->txq->tpd_dma);
+ 		}
+ 
+ 		if (np->rxq) {
+ 			np->rxq->read_idx = 0;
+ 			np->rxq->write_idx = 0;
+ 			np->rxq->rrd_read_idx = 0;
+ 			alx_write_mem32(hw, ALX_RRD_ADDR_LO, np->rxq->rrd_dma);
+ 			alx_write_mem32(hw, ALX_RFD_ADDR_LO, np->rxq->rfd_dma);
+ 		}
+ 	}
+ 
+ 	alx_write_mem32(hw, ALX_TX_BASE_ADDR_HI, addr_hi);
+ 	alx_write_mem32(hw, ALX_TPD_RING_SZ, alx->tx_ringsz);
+ 
+ 	alx_write_mem32(hw, ALX_RX_BASE_ADDR_HI, addr_hi);
+ 	alx_write_mem32(hw, ALX_RRD_RING_SZ, alx->rx_ringsz);
+ 	alx_write_mem32(hw, ALX_RFD_RING_SZ, alx->rx_ringsz);
+ 	alx_write_mem32(hw, ALX_RFD_BUF_SZ, alx->rxbuf_size);
+ 
++>>>>>>> a4076d347f9a (alx: prepare resource allocation for multi queue support)
  	/* load these pointers into the chip */
  	alx_write_mem32(hw, ALX_SRAM9, ALX_SRAM_LOAD_PTR);
  }
@@@ -491,13 -495,13 +529,13 @@@ static void alx_free_rxring_buf(struct 
  	struct alx_buffer *cur_buf;
  	u16 i;
  
- 	if (rxq == NULL)
+ 	if (!rxq->bufs)
  		return;
  
 -	for (i = 0; i < rxq->count; i++) {
 +	for (i = 0; i < alx->rx_ringsz; i++) {
  		cur_buf = rxq->bufs + i;
  		if (cur_buf->skb) {
 -			dma_unmap_single(rxq->dev,
 +			dma_unmap_single(&alx->hw.pdev->dev,
  					 dma_unmap_addr(cur_buf, dma),
  					 dma_unmap_len(cur_buf, size),
  					 DMA_FROM_DEVICE);
@@@ -515,8 -519,14 +553,19 @@@
  
  static void alx_free_buffers(struct alx_priv *alx)
  {
++<<<<<<< HEAD
 +	alx_free_txring_buf(alx);
 +	alx_free_rxring_buf(alx);
++=======
+ 	int i;
+ 
+ 	for (i = 0; i < alx->num_txq; i++)
+ 		if (alx->qnapi[i] && alx->qnapi[i]->txq)
+ 			alx_free_txring_buf(alx->qnapi[i]->txq);
+ 
+ 	if (alx->qnapi[0] && alx->qnapi[0]->rxq)
+ 		alx_free_rxring_buf(alx->qnapi[0]->rxq);
++>>>>>>> a4076d347f9a (alx: prepare resource allocation for multi queue support)
  }
  
  static int alx_reinit_rings(struct alx_priv *alx)
@@@ -646,23 -657,20 +696,32 @@@ static int alx_alloc_rings(struct alx_p
  	BUILD_BUG_ON(sizeof(struct alx_txd) % 8);
  	BUILD_BUG_ON(sizeof(struct alx_rrd) % 8);
  
++<<<<<<< HEAD
 +	offset = alx_alloc_tx_ring(alx, &alx->txq, offset);
 +	if (offset < 0) {
 +		netdev_err(alx->dev, "Allocation of tx buffer failed!\n");
 +		goto out_free;
++=======
+ 	for (i = 0; i < alx->num_txq; i++) {
+ 		offset = alx_alloc_tx_ring(alx, alx->qnapi[i]->txq, offset);
+ 		if (offset < 0) {
+ 			netdev_err(alx->dev, "Allocation of tx buffer failed!\n");
+ 			return -ENOMEM;
+ 		}
++>>>>>>> a4076d347f9a (alx: prepare resource allocation for multi queue support)
  	}
  
 -	offset = alx_alloc_rx_ring(alx, alx->qnapi[0]->rxq, offset);
 +	offset = alx_alloc_rx_ring(alx, &alx->rxq, offset);
  	if (offset < 0) {
  		netdev_err(alx->dev, "Allocation of rx buffer failed!\n");
 -		return -ENOMEM;
 +		goto out_free;
  	}
  
 +	alx->int_mask &= ~ALX_ISR_ALL_QUEUES;
 +	alx->int_mask |= ALX_ISR_TX_Q0 | ALX_ISR_RX_Q0;
 +
 +	netif_napi_add(alx->dev, &alx->napi, alx_poll, 64);
 +
  	alx_reinit_rings(alx);
  
  	return 0;
@@@ -678,23 -678,115 +737,130 @@@ out_free
  
  static void alx_free_rings(struct alx_priv *alx)
  {
++<<<<<<< HEAD
 +	netif_napi_del(&alx->napi);
 +	alx_free_buffers(alx);
 +
 +	kfree(alx->txq.bufs);
 +	kfree(alx->rxq.bufs);
++=======
+ 	int i;
+ 
+ 	alx_free_buffers(alx);
+ 
+ 	for (i = 0; i < alx->num_txq; i++)
+ 		if (alx->qnapi[i] && alx->qnapi[i]->txq)
+ 			kfree(alx->qnapi[i]->txq->bufs);
+ 
+ 	if (alx->qnapi[0] && alx->qnapi[0]->rxq)
+ 		kfree(alx->qnapi[0]->rxq->bufs);
++>>>>>>> a4076d347f9a (alx: prepare resource allocation for multi queue support)
  
 -	if (!alx->descmem.virt)
 -		dma_free_coherent(&alx->hw.pdev->dev,
 -				  alx->descmem.size,
 -				  alx->descmem.virt,
 -				  alx->descmem.dma);
 +	if (alx->rx_page) {
 +		put_page(alx->rx_page);
 +		alx->rx_page = NULL;
 +	}
 +
 +	dma_free_coherent(&alx->hw.pdev->dev,
 +			  alx->descmem.size,
 +			  alx->descmem.virt,
 +			  alx->descmem.dma);
  }
  
++<<<<<<< HEAD
++=======
+ static void alx_free_napis(struct alx_priv *alx)
+ {
+ 	struct alx_napi *np;
+ 	int i;
+ 
+ 	for (i = 0; i < alx->num_napi; i++) {
+ 		np = alx->qnapi[i];
+ 		if (!np)
+ 			continue;
+ 
+ 		netif_napi_del(&np->napi);
+ 		kfree(np->txq);
+ 		kfree(np->rxq);
+ 		kfree(np);
+ 		alx->qnapi[i] = NULL;
+ 	}
+ }
+ 
+ static const u32 tx_vect_mask[] = {ALX_ISR_TX_Q0, ALX_ISR_TX_Q1,
+ 				   ALX_ISR_TX_Q2, ALX_ISR_TX_Q3};
+ static const u32 rx_vect_mask[] = {ALX_ISR_RX_Q0, ALX_ISR_RX_Q1,
+ 				   ALX_ISR_RX_Q2, ALX_ISR_RX_Q3,
+ 				   ALX_ISR_RX_Q4, ALX_ISR_RX_Q5,
+ 				   ALX_ISR_RX_Q6, ALX_ISR_RX_Q7};
+ 
+ static int alx_alloc_napis(struct alx_priv *alx)
+ {
+ 	struct alx_napi *np;
+ 	struct alx_rx_queue *rxq;
+ 	struct alx_tx_queue *txq;
+ 	int i;
+ 
+ 	alx->int_mask &= ~ALX_ISR_ALL_QUEUES;
+ 
+ 	/* allocate alx_napi structures */
+ 	for (i = 0; i < alx->num_napi; i++) {
+ 		np = kzalloc(sizeof(struct alx_napi), GFP_KERNEL);
+ 		if (!np)
+ 			goto err_out;
+ 
+ 		np->alx = alx;
+ 		netif_napi_add(alx->dev, &np->napi, alx_poll, 64);
+ 		alx->qnapi[i] = np;
+ 	}
+ 
+ 	/* allocate tx queues */
+ 	for (i = 0; i < alx->num_txq; i++) {
+ 		np = alx->qnapi[i];
+ 		txq = kzalloc(sizeof(*txq), GFP_KERNEL);
+ 		if (!txq)
+ 			goto err_out;
+ 
+ 		np->txq = txq;
+ 		txq->queue_idx = i;
+ 		txq->count = alx->tx_ringsz;
+ 		txq->netdev = alx->dev;
+ 		txq->dev = &alx->hw.pdev->dev;
+ 		np->vec_mask |= tx_vect_mask[i];
+ 		alx->int_mask |= tx_vect_mask[i];
+ 	}
+ 
+ 	/* allocate rx queues */
+ 	np = alx->qnapi[0];
+ 	rxq = kzalloc(sizeof(*rxq), GFP_KERNEL);
+ 	if (!rxq)
+ 		goto err_out;
+ 
+ 	np->rxq = rxq;
+ 	rxq->np = alx->qnapi[0];
+ 	rxq->queue_idx = 0;
+ 	rxq->count = alx->rx_ringsz;
+ 	rxq->netdev = alx->dev;
+ 	rxq->dev = &alx->hw.pdev->dev;
+ 	np->vec_mask |= rx_vect_mask[0];
+ 	alx->int_mask |= rx_vect_mask[0];
+ 
+ 	return 0;
+ 
+ err_out:
+ 	netdev_err(alx->dev, "error allocating internal structures\n");
+ 	alx_free_napis(alx);
+ 	return -ENOMEM;
+ }
+ 
+ static const int txq_vec_mapping_shift[] = {
+ 	0, ALX_MSI_MAP_TBL1_TXQ0_SHIFT,
+ 	0, ALX_MSI_MAP_TBL1_TXQ1_SHIFT,
+ 	1, ALX_MSI_MAP_TBL2_TXQ2_SHIFT,
+ 	1, ALX_MSI_MAP_TBL2_TXQ3_SHIFT,
+ };
+ 
++>>>>>>> a4076d347f9a (alx: prepare resource allocation for multi queue support)
  static void alx_config_vector_mapping(struct alx_priv *alx)
  {
  	struct alx_hw *hw = &alx->hw;
@@@ -970,11 -1114,14 +1136,22 @@@ static netdev_features_t alx_fix_featur
  
  static void alx_netif_stop(struct alx_priv *alx)
  {
++<<<<<<< HEAD
 +	alx->dev->trans_start = jiffies;
 +	if (netif_carrier_ok(alx->dev)) {
 +		netif_carrier_off(alx->dev);
 +		netif_tx_disable(alx->dev);
 +		napi_disable(&alx->napi);
++=======
+ 	int i;
+ 
+ 	netif_trans_update(alx->dev);
+ 	if (netif_carrier_ok(alx->dev)) {
+ 		netif_carrier_off(alx->dev);
+ 		netif_tx_disable(alx->dev);
+ 		for (i = 0; i < alx->num_napi; i++)
+ 			napi_disable(&alx->qnapi[i]->napi);
++>>>>>>> a4076d347f9a (alx: prepare resource allocation for multi queue support)
  	}
  }
  
@@@ -1054,8 -1190,11 +1231,15 @@@ static int alx_change_mtu(struct net_de
  
  static void alx_netif_start(struct alx_priv *alx)
  {
+ 	int i;
+ 
  	netif_tx_wake_all_queues(alx->dev);
++<<<<<<< HEAD
 +	napi_enable(&alx->napi);
++=======
+ 	for (i = 0; i < alx->num_napi; i++)
+ 		napi_enable(&alx->qnapi[i]->napi);
++>>>>>>> a4076d347f9a (alx: prepare resource allocation for multi queue support)
  	netif_carrier_on(alx->dev);
  }
  
* Unmerged path drivers/net/ethernet/atheros/alx/main.c
