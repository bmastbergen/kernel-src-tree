Drivers: hv: vmbus: finally fix hv_need_to_signal_on_read()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [hv] vmbus: finally fix hv_need_to_signal_on_read() (Vitaly Kuznetsov) [1406404 1418889]
Rebuild_FUZZ: 87.62%
commit-author Dexuan Cui <decui@microsoft.com>
commit 433e19cf33d34bb6751c874a9c00980552fe508c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/433e19cf.failed

Commit a389fcfd2cb5 ("Drivers: hv: vmbus: Fix signaling logic in
hv_need_to_signal_on_read()")
added the proper mb(), but removed the test "prev_write_sz < pending_sz"
when making the signal decision.

As a result, the guest can signal the host unnecessarily,
and then the host can throttle the guest because the host
thinks the guest is buggy or malicious; finally the user
running stress test can perceive intermittent freeze of
the guest.

This patch brings back the test, and properly handles the
in-place consumption APIs used by NetVSC (see get_next_pkt_raw(),
put_pkt_raw() and commit_rd_index()).

Fixes: a389fcfd2cb5 ("Drivers: hv: vmbus: Fix signaling logic in
hv_need_to_signal_on_read()")

	Signed-off-by: Dexuan Cui <decui@microsoft.com>
	Reported-by: Rolf Neugebauer <rolf.neugebauer@docker.com>
	Tested-by: Rolf Neugebauer <rolf.neugebauer@docker.com>
	Cc: "K. Y. Srinivasan" <kys@microsoft.com>
	Cc: Haiyang Zhang <haiyangz@microsoft.com>
	Cc: Stephen Hemminger <sthemmin@microsoft.com>
	Cc: <stable@vger.kernel.org>
	Signed-off-by: K. Y. Srinivasan <kys@microsoft.com>
	Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
(cherry picked from commit 433e19cf33d34bb6751c874a9c00980552fe508c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/hyperv.h
diff --cc include/linux/hyperv.h
index cecfec703dfb,183efde54269..000000000000
--- a/include/linux/hyperv.h
+++ b/include/linux/hyperv.h
@@@ -126,6 -126,9 +126,12 @@@ struct hv_ring_buffer_info 
  
  	u32 ring_datasize;		/* < ring_size */
  	u32 ring_data_startoffset;
++<<<<<<< HEAD
++=======
+ 	u32 priv_write_index;
+ 	u32 priv_read_index;
+ 	u32 cached_read_index;
++>>>>>>> 433e19cf33d3 (Drivers: hv: vmbus: finally fix hv_need_to_signal_on_read())
  };
  
  /*
@@@ -1436,4 -1477,146 +1455,149 @@@ extern __u32 vmbus_proto_version
  int vmbus_send_tl_connect_request(const uuid_le *shv_guest_servie_id,
  				  const uuid_le *shv_host_servie_id);
  void vmbus_set_event(struct vmbus_channel *channel);
++<<<<<<< HEAD
++=======
+ 
+ /* Get the start of the ring buffer. */
+ static inline void *
+ hv_get_ring_buffer(struct hv_ring_buffer_info *ring_info)
+ {
+ 	return (void *)ring_info->ring_buffer->buffer;
+ }
+ 
+ /*
+  * To optimize the flow management on the send-side,
+  * when the sender is blocked because of lack of
+  * sufficient space in the ring buffer, potential the
+  * consumer of the ring buffer can signal the producer.
+  * This is controlled by the following parameters:
+  *
+  * 1. pending_send_sz: This is the size in bytes that the
+  *    producer is trying to send.
+  * 2. The feature bit feat_pending_send_sz set to indicate if
+  *    the consumer of the ring will signal when the ring
+  *    state transitions from being full to a state where
+  *    there is room for the producer to send the pending packet.
+  */
+ 
+ static inline  void hv_signal_on_read(struct vmbus_channel *channel)
+ {
+ 	u32 cur_write_sz, cached_write_sz;
+ 	u32 pending_sz;
+ 	struct hv_ring_buffer_info *rbi = &channel->inbound;
+ 
+ 	/*
+ 	 * Issue a full memory barrier before making the signaling decision.
+ 	 * Here is the reason for having this barrier:
+ 	 * If the reading of the pend_sz (in this function)
+ 	 * were to be reordered and read before we commit the new read
+ 	 * index (in the calling function)  we could
+ 	 * have a problem. If the host were to set the pending_sz after we
+ 	 * have sampled pending_sz and go to sleep before we commit the
+ 	 * read index, we could miss sending the interrupt. Issue a full
+ 	 * memory barrier to address this.
+ 	 */
+ 	virt_mb();
+ 
+ 	pending_sz = READ_ONCE(rbi->ring_buffer->pending_send_sz);
+ 	/* If the other end is not blocked on write don't bother. */
+ 	if (pending_sz == 0)
+ 		return;
+ 
+ 	cur_write_sz = hv_get_bytes_to_write(rbi);
+ 
+ 	if (cur_write_sz < pending_sz)
+ 		return;
+ 
+ 	cached_write_sz = hv_get_cached_bytes_to_write(rbi);
+ 	if (cached_write_sz < pending_sz)
+ 		vmbus_setevent(channel);
+ 
+ 	return;
+ }
+ 
+ static inline void
+ init_cached_read_index(struct vmbus_channel *channel)
+ {
+ 	struct hv_ring_buffer_info *rbi = &channel->inbound;
+ 
+ 	rbi->cached_read_index = rbi->ring_buffer->read_index;
+ }
+ 
+ /*
+  * An API to support in-place processing of incoming VMBUS packets.
+  */
+ #define VMBUS_PKT_TRAILER	8
+ 
+ static inline struct vmpacket_descriptor *
+ get_next_pkt_raw(struct vmbus_channel *channel)
+ {
+ 	struct hv_ring_buffer_info *ring_info = &channel->inbound;
+ 	u32 priv_read_loc = ring_info->priv_read_index;
+ 	void *ring_buffer = hv_get_ring_buffer(ring_info);
+ 	u32 dsize = ring_info->ring_datasize;
+ 	/*
+ 	 * delta is the difference between what is available to read and
+ 	 * what was already consumed in place. We commit read index after
+ 	 * the whole batch is processed.
+ 	 */
+ 	u32 delta = priv_read_loc >= ring_info->ring_buffer->read_index ?
+ 		priv_read_loc - ring_info->ring_buffer->read_index :
+ 		(dsize - ring_info->ring_buffer->read_index) + priv_read_loc;
+ 	u32 bytes_avail_toread = (hv_get_bytes_to_read(ring_info) - delta);
+ 
+ 	if (bytes_avail_toread < sizeof(struct vmpacket_descriptor))
+ 		return NULL;
+ 
+ 	return ring_buffer + priv_read_loc;
+ }
+ 
+ /*
+  * A helper function to step through packets "in-place"
+  * This API is to be called after each successful call
+  * get_next_pkt_raw().
+  */
+ static inline void put_pkt_raw(struct vmbus_channel *channel,
+ 				struct vmpacket_descriptor *desc)
+ {
+ 	struct hv_ring_buffer_info *ring_info = &channel->inbound;
+ 	u32 packetlen = desc->len8 << 3;
+ 	u32 dsize = ring_info->ring_datasize;
+ 
+ 	/*
+ 	 * Include the packet trailer.
+ 	 */
+ 	ring_info->priv_read_index += packetlen + VMBUS_PKT_TRAILER;
+ 	ring_info->priv_read_index %= dsize;
+ }
+ 
+ /*
+  * This call commits the read index and potentially signals the host.
+  * Here is the pattern for using the "in-place" consumption APIs:
+  *
+  * init_cached_read_index();
+  *
+  * while (get_next_pkt_raw() {
+  *	process the packet "in-place";
+  *	put_pkt_raw();
+  * }
+  * if (packets processed in place)
+  *	commit_rd_index();
+  */
+ static inline void commit_rd_index(struct vmbus_channel *channel)
+ {
+ 	struct hv_ring_buffer_info *ring_info = &channel->inbound;
+ 	/*
+ 	 * Make sure all reads are done before we update the read index since
+ 	 * the writer may start writing to the read area once the read index
+ 	 * is updated.
+ 	 */
+ 	virt_rmb();
+ 	ring_info->ring_buffer->read_index = ring_info->priv_read_index;
+ 
+ 	hv_signal_on_read(channel);
+ }
+ 
+ 
++>>>>>>> 433e19cf33d3 (Drivers: hv: vmbus: finally fix hv_need_to_signal_on_read())
  #endif /* _HYPERV_H */
diff --git a/drivers/hv/ring_buffer.c b/drivers/hv/ring_buffer.c
index d27dcebfaf0f..facfe58cc334 100644
--- a/drivers/hv/ring_buffer.c
+++ b/drivers/hv/ring_buffer.c
@@ -397,6 +397,7 @@ int hv_ringbuffer_read(struct hv_ring_buffer_info *inring_info,
 		return ret;
 	}
 
+	init_cached_read_index(channel);
 	next_read_location = hv_get_next_read_location(inring_info);
 	next_read_location = hv_copyfrom_ringbuffer(inring_info, &desc,
 						    sizeof(desc),
diff --git a/drivers/net/hyperv/netvsc.c b/drivers/net/hyperv/netvsc.c
index eb42acc1a4d7..4de88db19df2 100644
--- a/drivers/net/hyperv/netvsc.c
+++ b/drivers/net/hyperv/netvsc.c
@@ -1266,6 +1266,9 @@ void netvsc_channel_cb(void *context)
 	net_device_ctx = netdev_priv(ndev);
 	buffer = get_per_channel_state(channel);
 
+	/* commit_rd_index() -> hv_signal_on_read() needs this. */
+	init_cached_read_index(channel);
+
 	do {
 		ret = vmbus_recvpacket_raw(channel, buffer, bufferlen,
 					   &bytes_recvd, &request_id);
@@ -1323,6 +1326,9 @@ void netvsc_channel_cb(void *context)
 
 			bufferlen = bytes_recvd;
 		}
+
+		init_cached_read_index(channel);
+
 	} while (1);
 
 	if (bufferlen > NETVSC_PACKET_SIZE)
* Unmerged path include/linux/hyperv.h
