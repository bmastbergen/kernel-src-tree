mm/hugetlb: introduce hugetlb_bad_size()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [mm] hugetlb: introduce hugetlb_bad_size() (Andrea Arcangeli) [1430172]
Rebuild_FUZZ: 96.10%
commit-author Vaishali Thakkar <vaishali.thakkar@oracle.com>
commit 9fee021d15ddd884d40d1540913474e8112313fe
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/9fee021d.failed

When any unsupported hugepage size is specified, 'hugepagesz=' and
'hugepages=' should be ignored during command line parsing until any
supported hugepage size is found.  But currently incorrect number of
hugepages are allocated when unsupported size is specified as it fails
to ignore the 'hugepages=' command.

Test case:

Note that this is specific to x86 architecture.

Boot the kernel with command line option 'hugepagesz=256M hugepages=X'.
After boot, dmesg output shows that X number of hugepages of the size 2M
is pre-allocated instead of 0.

So, to handle such command line options, introduce new routine
hugetlb_bad_size.  The routine hugetlb_bad_size sets the global variable
parsed_valid_hugepagesz.  We are using parsed_valid_hugepagesz to save
the state when unsupported hugepagesize is found so that we can ignore
the 'hugepages=' parameters after that and then reset the variable when
supported hugepage size is found.

The routine hugetlb_bad_size can be called while setting 'hugepagesz='
parameter in an architecture specific code.

	Signed-off-by: Vaishali Thakkar <vaishali.thakkar@oracle.com>
	Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
	Reviewed-by: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
	Acked-by: Michal Hocko <mhocko@suse.com>
	Cc: Hillf Danton <hillf.zj@alibaba-inc.com>
	Cc: Yaowei Bai <baiyaowei@cmss.chinamobile.com>
	Cc: Dominik Dingel <dingel@linux.vnet.ibm.com>
	Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
	Cc: Paul Gortmaker <paul.gortmaker@windriver.com>
	Cc: Dave Hansen <dave.hansen@linux.intel.com>
	Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
	Cc: James Hogan <james.hogan@imgtec.com>
	Cc: Ingo Molnar <mingo@elte.hu>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 9fee021d15ddd884d40d1540913474e8112313fe)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/hugetlb.c
diff --cc mm/hugetlb.c
index 3015ba754f26,0adb74d0a4e1..000000000000
--- a/mm/hugetlb.c
+++ b/mm/hugetlb.c
@@@ -2384,18 -2649,23 +2385,27 @@@ static int __init hugetlb_init(void
  #else
  	num_fault_mutexes = 1;
  #endif
 -	hugetlb_fault_mutex_table =
 +	htlb_fault_mutex_table =
  		kmalloc(sizeof(struct mutex) * num_fault_mutexes, GFP_KERNEL);
 -	BUG_ON(!hugetlb_fault_mutex_table);
 +	BUG_ON(!htlb_fault_mutex_table);
  
  	for (i = 0; i < num_fault_mutexes; i++)
 -		mutex_init(&hugetlb_fault_mutex_table[i]);
 +		mutex_init(&htlb_fault_mutex_table[i]);
  	return 0;
  }
 -subsys_initcall(hugetlb_init);
 +module_init(hugetlb_init);
  
  /* Should be called on processing a hugepagesz=... option */
++<<<<<<< HEAD
 +void __init hugetlb_add_hstate(unsigned order)
++=======
+ void __init hugetlb_bad_size(void)
+ {
+ 	parsed_valid_hugepagesz = false;
+ }
+ 
+ void __init hugetlb_add_hstate(unsigned int order)
++>>>>>>> 9fee021d15dd (mm/hugetlb: introduce hugetlb_bad_size())
  {
  	struct hstate *h;
  	unsigned long i;
diff --git a/include/linux/hugetlb.h b/include/linux/hugetlb.h
index 8b5d86309d4f..483d833f9ec2 100644
--- a/include/linux/hugetlb.h
+++ b/include/linux/hugetlb.h
@@ -298,6 +298,7 @@ int huge_add_to_page_cache(struct page *page, struct address_space *mapping,
 /* arch callback */
 int __init alloc_bootmem_huge_page(struct hstate *h);
 
+void __init hugetlb_bad_size(void);
 void __init hugetlb_add_hstate(unsigned order);
 struct hstate *size_to_hstate(unsigned long size);
 
* Unmerged path mm/hugetlb.c
