flow_dissector: Use 'const' where possible.

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author David S. Miller <davem@davemloft.net>
commit 20a17bf6c04e3eca8824c930ecc55ab832558e3b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/20a17bf6.failed

	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 20a17bf6c04e3eca8824c930ecc55ab832558e3b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/skbuff.h
#	include/net/flow.h
#	net/core/flow_dissector.c
diff --cc include/linux/skbuff.h
index dcb8575fa615,2738d355cdf9..000000000000
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@@ -1001,6 -950,120 +1001,123 @@@ static inline void skb_clear_hash_if_no
  		skb_clear_hash(skb);
  }
  
++<<<<<<< HEAD
++=======
+ static inline void
+ __skb_set_hash(struct sk_buff *skb, __u32 hash, bool is_sw, bool is_l4)
+ {
+ 	skb->l4_hash = is_l4;
+ 	skb->sw_hash = is_sw;
+ 	skb->hash = hash;
+ }
+ 
+ static inline void
+ skb_set_hash(struct sk_buff *skb, __u32 hash, enum pkt_hash_types type)
+ {
+ 	/* Used by drivers to set hash from HW */
+ 	__skb_set_hash(skb, hash, false, type == PKT_HASH_TYPE_L4);
+ }
+ 
+ static inline void
+ __skb_set_sw_hash(struct sk_buff *skb, __u32 hash, bool is_l4)
+ {
+ 	__skb_set_hash(skb, hash, true, is_l4);
+ }
+ 
+ void __skb_get_hash(struct sk_buff *skb);
+ u32 skb_get_poff(const struct sk_buff *skb);
+ u32 __skb_get_poff(const struct sk_buff *skb, void *data,
+ 		   const struct flow_keys *keys, int hlen);
+ __be32 __skb_flow_get_ports(const struct sk_buff *skb, int thoff, u8 ip_proto,
+ 			    void *data, int hlen_proto);
+ 
+ static inline __be32 skb_flow_get_ports(const struct sk_buff *skb,
+ 					int thoff, u8 ip_proto)
+ {
+ 	return __skb_flow_get_ports(skb, thoff, ip_proto, NULL, 0);
+ }
+ 
+ void skb_flow_dissector_init(struct flow_dissector *flow_dissector,
+ 			     const struct flow_dissector_key *key,
+ 			     unsigned int key_count);
+ 
+ bool __skb_flow_dissect(const struct sk_buff *skb,
+ 			struct flow_dissector *flow_dissector,
+ 			void *target_container,
+ 			void *data, __be16 proto, int nhoff, int hlen,
+ 			unsigned int flags);
+ 
+ static inline bool skb_flow_dissect(const struct sk_buff *skb,
+ 				    struct flow_dissector *flow_dissector,
+ 				    void *target_container, unsigned int flags)
+ {
+ 	return __skb_flow_dissect(skb, flow_dissector, target_container,
+ 				  NULL, 0, 0, 0, flags);
+ }
+ 
+ static inline bool skb_flow_dissect_flow_keys(const struct sk_buff *skb,
+ 					      struct flow_keys *flow,
+ 					      unsigned int flags)
+ {
+ 	memset(flow, 0, sizeof(*flow));
+ 	return __skb_flow_dissect(skb, &flow_keys_dissector, flow,
+ 				  NULL, 0, 0, 0, flags);
+ }
+ 
+ static inline bool skb_flow_dissect_flow_keys_buf(struct flow_keys *flow,
+ 						  void *data, __be16 proto,
+ 						  int nhoff, int hlen,
+ 						  unsigned int flags)
+ {
+ 	memset(flow, 0, sizeof(*flow));
+ 	return __skb_flow_dissect(NULL, &flow_keys_buf_dissector, flow,
+ 				  data, proto, nhoff, hlen, flags);
+ }
+ 
+ static inline __u32 skb_get_hash(struct sk_buff *skb)
+ {
+ 	if (!skb->l4_hash && !skb->sw_hash)
+ 		__skb_get_hash(skb);
+ 
+ 	return skb->hash;
+ }
+ 
+ __u32 __skb_get_hash_flowi6(struct sk_buff *skb, const struct flowi6 *fl6);
+ 
+ static inline __u32 skb_get_hash_flowi6(struct sk_buff *skb, const struct flowi6 *fl6)
+ {
+ 	if (!skb->l4_hash && !skb->sw_hash) {
+ 		struct flow_keys keys;
+ 		__u32 hash = __get_hash_from_flowi6(fl6, &keys);
+ 
+ 		__skb_set_sw_hash(skb, hash, flow_keys_have_l4(&keys));
+ 	}
+ 
+ 	return skb->hash;
+ }
+ 
+ __u32 __skb_get_hash_flowi4(struct sk_buff *skb, const struct flowi4 *fl);
+ 
+ static inline __u32 skb_get_hash_flowi4(struct sk_buff *skb, const struct flowi4 *fl4)
+ {
+ 	if (!skb->l4_hash && !skb->sw_hash) {
+ 		struct flow_keys keys;
+ 		__u32 hash = __get_hash_from_flowi4(fl4, &keys);
+ 
+ 		__skb_set_sw_hash(skb, hash, flow_keys_have_l4(&keys));
+ 	}
+ 
+ 	return skb->hash;
+ }
+ 
+ __u32 skb_get_hash_perturb(const struct sk_buff *skb, u32 perturb);
+ 
+ static inline __u32 skb_get_hash_raw(const struct sk_buff *skb)
+ {
+ 	return skb->hash;
+ }
+ 
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  static inline void skb_copy_hash(struct sk_buff *to, const struct sk_buff *from)
  {
  	to->hash = from->hash;
diff --cc include/net/flow.h
index 484b9b9a822a,acd6a096250e..000000000000
--- a/include/net/flow.h
+++ b/include/net/flow.h
@@@ -269,4 -244,22 +269,25 @@@ void flow_cache_flush(struct net *net)
  void flow_cache_flush_deferred(struct net *net);
  extern atomic_t flow_cache_genid;
  
++<<<<<<< HEAD
++=======
+ __u32 __get_hash_from_flowi6(const struct flowi6 *fl6, struct flow_keys *keys);
+ 
+ static inline __u32 get_hash_from_flowi6(const struct flowi6 *fl6)
+ {
+ 	struct flow_keys keys;
+ 
+ 	return __get_hash_from_flowi6(fl6, &keys);
+ }
+ 
+ __u32 __get_hash_from_flowi4(const struct flowi4 *fl4, struct flow_keys *keys);
+ 
+ static inline __u32 get_hash_from_flowi4(const struct flowi4 *fl4)
+ {
+ 	struct flow_keys keys;
+ 
+ 	return __get_hash_from_flowi4(fl4, &keys);
+ }
+ 
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  #endif
diff --cc net/core/flow_dissector.c
index dae6e57d80c3,d79699c9d1b9..000000000000
--- a/net/core/flow_dissector.c
+++ b/net/core/flow_dissector.c
@@@ -13,11 -13,14 +13,11 @@@
  #include <linux/if_tunnel.h>
  #include <linux/if_pppox.h>
  #include <linux/ppp_defs.h>
 -#include <linux/stddef.h>
 -#include <linux/if_ether.h>
 -#include <linux/mpls.h>
 -#include <net/flow_dissector.h>
 +#include <net/flow_keys.h>
  #include <scsi/fc/fc_fcoe.h>
  
- static bool skb_flow_dissector_uses_key(struct flow_dissector *flow_dissector,
- 					enum flow_dissector_key_id key_id)
+ static bool dissector_uses_key(const struct flow_dissector *flow_dissector,
+ 			       enum flow_dissector_key_id key_id)
  {
  	return flow_dissector->used_keys & (1 << key_id);
  }
@@@ -55,11 -58,13 +55,18 @@@ void skb_flow_dissector_init(struct flo
  		flow_dissector->offset[key->key_id] = key->offset;
  	}
  
 -	/* Ensure that the dissector always includes control and basic key.
 -	 * That way we are able to avoid handling lack of these in fast path.
 +	/* Ensure that the dissector always includes basic key. That way
 +	 * we are able to avoid handling lack of it in fast path.
  	 */
++<<<<<<< HEAD
 +	BUG_ON(!skb_flow_dissector_uses_key(flow_dissector,
 +					    FLOW_DISSECTOR_KEY_BASIC));
++=======
+ 	BUG_ON(!dissector_uses_key(flow_dissector,
+ 				   FLOW_DISSECTOR_KEY_CONTROL));
+ 	BUG_ON(!dissector_uses_key(flow_dissector,
+ 				   FLOW_DISSECTOR_KEY_BASIC));
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  }
  EXPORT_SYMBOL(skb_flow_dissector_init);
  
@@@ -131,7 -140,30 +138,34 @@@ bool __skb_flow_dissect(const struct sk
  		hlen = skb_headlen(skb);
  	}
  
++<<<<<<< HEAD
 +	memset(flow, 0, sizeof(*flow));
++=======
+ 	/* It is ensured by skb_flow_dissector_init() that control key will
+ 	 * be always present.
+ 	 */
+ 	key_control = skb_flow_dissector_target(flow_dissector,
+ 						FLOW_DISSECTOR_KEY_CONTROL,
+ 						target_container);
+ 
+ 	/* It is ensured by skb_flow_dissector_init() that basic key will
+ 	 * be always present.
+ 	 */
+ 	key_basic = skb_flow_dissector_target(flow_dissector,
+ 					      FLOW_DISSECTOR_KEY_BASIC,
+ 					      target_container);
+ 
+ 	if (dissector_uses_key(flow_dissector,
+ 			       FLOW_DISSECTOR_KEY_ETH_ADDRS)) {
+ 		struct ethhdr *eth = eth_hdr(skb);
+ 		struct flow_dissector_key_eth_addrs *key_eth_addrs;
+ 
+ 		key_eth_addrs = skb_flow_dissector_target(flow_dissector,
+ 							  FLOW_DISSECTOR_KEY_ETH_ADDRS,
+ 							  target_container);
+ 		memcpy(key_eth_addrs, &eth->h_dest, sizeof(*key_eth_addrs));
+ 	}
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  
  again:
  	switch (proto) {
@@@ -145,31 -177,74 +179,89 @@@ ip
  		nhoff += iph->ihl * 4;
  
  		ip_proto = iph->protocol;
 +		if (ip_is_fragment(iph))
 +			ip_proto = 0;
  
++<<<<<<< HEAD
 +		iph_to_flow_copy_addrs(flow, iph);
++=======
+ 		if (!dissector_uses_key(flow_dissector,
+ 					FLOW_DISSECTOR_KEY_IPV4_ADDRS))
+ 			break;
+ 
+ 		key_addrs = skb_flow_dissector_target(flow_dissector,
+ 			      FLOW_DISSECTOR_KEY_IPV4_ADDRS, target_container);
+ 		memcpy(&key_addrs->v4addrs, &iph->saddr,
+ 		       sizeof(key_addrs->v4addrs));
+ 		key_control->addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;
+ 
+ 		if (ip_is_fragment(iph)) {
+ 			key_control->flags |= FLOW_DIS_IS_FRAGMENT;
+ 
+ 			if (iph->frag_off & htons(IP_OFFSET)) {
+ 				goto out_good;
+ 			} else {
+ 				key_control->flags |= FLOW_DIS_FIRST_FRAG;
+ 				if (!(flags & FLOW_DISSECTOR_F_PARSE_1ST_FRAG))
+ 					goto out_good;
+ 			}
+ 		}
+ 
+ 		if (flags & FLOW_DISSECTOR_F_STOP_AT_L3)
+ 			goto out_good;
+ 
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  		break;
  	}
 -	case htons(ETH_P_IPV6): {
 +	case __constant_htons(ETH_P_IPV6): {
  		const struct ipv6hdr *iph;
  		struct ipv6hdr _iph;
 -		__be32 flow_label;
 -
  ipv6:
  		iph = __skb_header_pointer(skb, nhoff, sizeof(_iph), data, hlen, &_iph);
  		if (!iph)
 -			goto out_bad;
 +			return false;
  
  		ip_proto = iph->nexthdr;
 +		flow->src = (__force __be32)ipv6_addr_hash(&iph->saddr);
 +		flow->dst = (__force __be32)ipv6_addr_hash(&iph->daddr);
  		nhoff += sizeof(struct ipv6hdr);
  
++<<<<<<< HEAD
 +		/* skip the flow label processing if skb is NULL.  The
 +		 * assumption here is that if there is no skb we are not
 +		 * looking for flow info as much as we are length.
 +		 */
 +		if (!skb)
 +			break;
++=======
+ 		if (dissector_uses_key(flow_dissector,
+ 				       FLOW_DISSECTOR_KEY_IPV6_ADDRS)) {
+ 			struct flow_dissector_key_ipv6_addrs *key_ipv6_addrs;
+ 
+ 			key_ipv6_addrs = skb_flow_dissector_target(flow_dissector,
+ 								   FLOW_DISSECTOR_KEY_IPV6_ADDRS,
+ 								   target_container);
+ 
+ 			memcpy(key_ipv6_addrs, &iph->saddr, sizeof(*key_ipv6_addrs));
+ 			key_control->addr_type = FLOW_DISSECTOR_KEY_IPV6_ADDRS;
+ 		}
+ 
+ 		flow_label = ip6_flowlabel(iph);
+ 		if (flow_label) {
+ 			if (dissector_uses_key(flow_dissector,
+ 					       FLOW_DISSECTOR_KEY_FLOW_LABEL)) {
+ 				key_tags = skb_flow_dissector_target(flow_dissector,
+ 								     FLOW_DISSECTOR_KEY_FLOW_LABEL,
+ 								     target_container);
+ 				key_tags->flow_label = ntohl(flow_label);
+ 			}
+ 			if (flags & FLOW_DISSECTOR_F_STOP_AT_FLOW_LABEL)
+ 				goto out_good;
+ 		}
+ 
+ 		if (flags & FLOW_DISSECTOR_F_STOP_AT_L3)
+ 			goto out_good;
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  
  		break;
  	}
@@@ -180,7 -255,16 +272,20 @@@
  
  		vlan = __skb_header_pointer(skb, nhoff, sizeof(_vlan), data, hlen, &_vlan);
  		if (!vlan)
++<<<<<<< HEAD
 +			return false;
++=======
+ 			goto out_bad;
+ 
+ 		if (dissector_uses_key(flow_dissector,
+ 				       FLOW_DISSECTOR_KEY_VLANID)) {
+ 			key_tags = skb_flow_dissector_target(flow_dissector,
+ 							     FLOW_DISSECTOR_KEY_VLANID,
+ 							     target_container);
+ 
+ 			key_tags->vlan_id = skb_vlan_tag_get_id(skb);
+ 		}
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  
  		proto = vlan->h_vlan_encapsulated_proto;
  		nhoff += sizeof(*vlan);
@@@ -212,18 -296,50 +317,60 @@@
  		} *hdr, _hdr;
  		hdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data, hlen, &_hdr);
  		if (!hdr)
++<<<<<<< HEAD
 +			return false;
 +		flow->src = hdr->srcnode;
 +		flow->dst = 0;
 +		flow->n_proto = proto;
 +		flow->thoff = (u16)nhoff;
 +		return true;
 +	}
++=======
+ 			goto out_bad;
+ 
+ 		if (dissector_uses_key(flow_dissector,
+ 				       FLOW_DISSECTOR_KEY_TIPC_ADDRS)) {
+ 			key_addrs = skb_flow_dissector_target(flow_dissector,
+ 							      FLOW_DISSECTOR_KEY_TIPC_ADDRS,
+ 							      target_container);
+ 			key_addrs->tipcaddrs.srcnode = hdr->srcnode;
+ 			key_control->addr_type = FLOW_DISSECTOR_KEY_TIPC_ADDRS;
+ 		}
+ 		goto out_good;
+ 	}
+ 
+ 	case htons(ETH_P_MPLS_UC):
+ 	case htons(ETH_P_MPLS_MC): {
+ 		struct mpls_label *hdr, _hdr[2];
+ mpls:
+ 		hdr = __skb_header_pointer(skb, nhoff, sizeof(_hdr), data,
+ 					   hlen, &_hdr);
+ 		if (!hdr)
+ 			goto out_bad;
+ 
+ 		if ((ntohl(hdr[0].entry) & MPLS_LS_LABEL_MASK) >>
+ 		     MPLS_LS_LABEL_SHIFT == MPLS_LABEL_ENTROPY) {
+ 			if (dissector_uses_key(flow_dissector,
+ 					       FLOW_DISSECTOR_KEY_MPLS_ENTROPY)) {
+ 				key_keyid = skb_flow_dissector_target(flow_dissector,
+ 								      FLOW_DISSECTOR_KEY_MPLS_ENTROPY,
+ 								      target_container);
+ 				key_keyid->keyid = hdr[1].entry &
+ 					htonl(MPLS_LS_LABEL_MASK);
+ 			}
+ 
+ 			goto out_good;
+ 		}
+ 
+ 		goto out_good;
+ 	}
+ 
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  	case htons(ETH_P_FCOE):
 -		key_control->thoff = (u16)(nhoff + FCOE_HEADER_LEN);
 +		flow->thoff = (u16)(nhoff + FCOE_HEADER_LEN);
  		/* fall through */
  	default:
 -		goto out_bad;
 +		return false;
  	}
  
  ip_proto_again:
@@@ -241,30 -357,52 +388,45 @@@
  		 * Only look inside GRE if version zero and no
  		 * routing
  		 */
 -		if (hdr->flags & (GRE_VERSION | GRE_ROUTING))
 -			break;
 -
 -		proto = hdr->proto;
 -		nhoff += 4;
 -		if (hdr->flags & GRE_CSUM)
 +		if (!(hdr->flags & (GRE_VERSION|GRE_ROUTING))) {
 +			proto = hdr->proto;
  			nhoff += 4;
 -		if (hdr->flags & GRE_KEY) {
 -			const __be32 *keyid;
 -			__be32 _keyid;
 -
 +			if (hdr->flags & GRE_CSUM)
 +				nhoff += 4;
 +			if (hdr->flags & GRE_KEY)
 +				nhoff += 4;
 +			if (hdr->flags & GRE_SEQ)
 +				nhoff += 4;
 +			if (proto == htons(ETH_P_TEB)) {
 +				const struct ethhdr *eth;
 +				struct ethhdr _eth;
 +
++<<<<<<< HEAD
 +				eth = __skb_header_pointer(skb, nhoff,
 +							   sizeof(_eth),
 +							   data, hlen, &_eth);
 +				if (!eth)
 +					return false;
 +				proto = eth->h_proto;
 +				nhoff += sizeof(*eth);
++=======
+ 			keyid = __skb_header_pointer(skb, nhoff, sizeof(_keyid),
+ 						     data, hlen, &_keyid);
+ 
+ 			if (!keyid)
+ 				goto out_bad;
+ 
+ 			if (dissector_uses_key(flow_dissector,
+ 					       FLOW_DISSECTOR_KEY_GRE_KEYID)) {
+ 				key_keyid = skb_flow_dissector_target(flow_dissector,
+ 								      FLOW_DISSECTOR_KEY_GRE_KEYID,
+ 								      target_container);
+ 				key_keyid->keyid = *keyid;
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  			}
 -			nhoff += 4;
 -		}
 -		if (hdr->flags & GRE_SEQ)
 -			nhoff += 4;
 -		if (proto == htons(ETH_P_TEB)) {
 -			const struct ethhdr *eth;
 -			struct ethhdr _eth;
 -
 -			eth = __skb_header_pointer(skb, nhoff,
 -						   sizeof(_eth),
 -						   data, hlen, &_eth);
 -			if (!eth)
 -				goto out_bad;
 -			proto = eth->h_proto;
 -			nhoff += sizeof(*eth);
 +			goto again;
  		}
 -
 -		key_control->flags |= FLOW_DIS_ENCAPSULATION;
 -		if (flags & FLOW_DISSECTOR_F_STOP_AT_ENCAP)
 -			goto out_good;
 -
 -		goto again;
 +		break;
  	}
  	case NEXTHDR_HOP:
  	case NEXTHDR_ROUTING:
@@@ -319,12 -470,24 +481,23 @@@
  		break;
  	}
  
++<<<<<<< HEAD
 +	flow->n_proto = proto;
 +	flow->ip_proto = ip_proto;
 +	flow->ports = __skb_flow_get_ports(skb, nhoff, ip_proto, data, hlen);
 +	flow->thoff = (u16) nhoff;
++=======
+ 	if (dissector_uses_key(flow_dissector,
+ 			       FLOW_DISSECTOR_KEY_PORTS)) {
+ 		key_ports = skb_flow_dissector_target(flow_dissector,
+ 						      FLOW_DISSECTOR_KEY_PORTS,
+ 						      target_container);
+ 		key_ports->ports = __skb_flow_get_ports(skb, nhoff, ip_proto,
+ 							data, hlen);
+ 	}
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  
 -out_good:
 -	ret = true;
 -
 -out_bad:
 -	key_basic->n_proto = proto;
 -	key_basic->ip_proto = ip_proto;
 -	key_control->thoff = (u16)nhoff;
 -
 -	return ret;
 +	return true;
  }
  EXPORT_SYMBOL(__skb_flow_dissect);
  
@@@ -334,27 -497,112 +507,133 @@@ static __always_inline void __flow_hash
  	net_get_random_once(&hashrnd, sizeof(hashrnd));
  }
  
++<<<<<<< HEAD
 +static __always_inline u32 __flow_hash_3words(u32 a, u32 b, u32 c)
++=======
+ static __always_inline u32 __flow_hash_words(const u32 *words, u32 length,
+ 					     u32 keyval)
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  {
 -	return jhash2(words, length, keyval);
 +	__flow_hash_secret_init();
 +	return jhash_3words(a, b, c, hashrnd);
  }
  
++<<<<<<< HEAD
 +static inline u32 __flow_hash_from_keys(struct flow_keys *keys)
++=======
+ static inline const u32 *flow_keys_hash_start(const struct flow_keys *flow)
+ {
+ 	const void *p = flow;
+ 
+ 	BUILD_BUG_ON(FLOW_KEYS_HASH_OFFSET % sizeof(u32));
+ 	return (const u32 *)(p + FLOW_KEYS_HASH_OFFSET);
+ }
+ 
+ static inline size_t flow_keys_hash_length(const struct flow_keys *flow)
+ {
+ 	size_t diff = FLOW_KEYS_HASH_OFFSET + sizeof(flow->addrs);
+ 	BUILD_BUG_ON((sizeof(*flow) - FLOW_KEYS_HASH_OFFSET) % sizeof(u32));
+ 	BUILD_BUG_ON(offsetof(typeof(*flow), addrs) !=
+ 		     sizeof(*flow) - sizeof(flow->addrs));
+ 
+ 	switch (flow->control.addr_type) {
+ 	case FLOW_DISSECTOR_KEY_IPV4_ADDRS:
+ 		diff -= sizeof(flow->addrs.v4addrs);
+ 		break;
+ 	case FLOW_DISSECTOR_KEY_IPV6_ADDRS:
+ 		diff -= sizeof(flow->addrs.v6addrs);
+ 		break;
+ 	case FLOW_DISSECTOR_KEY_TIPC_ADDRS:
+ 		diff -= sizeof(flow->addrs.tipcaddrs);
+ 		break;
+ 	}
+ 	return (sizeof(*flow) - diff) / sizeof(u32);
+ }
+ 
+ __be32 flow_get_u32_src(const struct flow_keys *flow)
+ {
+ 	switch (flow->control.addr_type) {
+ 	case FLOW_DISSECTOR_KEY_IPV4_ADDRS:
+ 		return flow->addrs.v4addrs.src;
+ 	case FLOW_DISSECTOR_KEY_IPV6_ADDRS:
+ 		return (__force __be32)ipv6_addr_hash(
+ 			&flow->addrs.v6addrs.src);
+ 	case FLOW_DISSECTOR_KEY_TIPC_ADDRS:
+ 		return flow->addrs.tipcaddrs.srcnode;
+ 	default:
+ 		return 0;
+ 	}
+ }
+ EXPORT_SYMBOL(flow_get_u32_src);
+ 
+ __be32 flow_get_u32_dst(const struct flow_keys *flow)
+ {
+ 	switch (flow->control.addr_type) {
+ 	case FLOW_DISSECTOR_KEY_IPV4_ADDRS:
+ 		return flow->addrs.v4addrs.dst;
+ 	case FLOW_DISSECTOR_KEY_IPV6_ADDRS:
+ 		return (__force __be32)ipv6_addr_hash(
+ 			&flow->addrs.v6addrs.dst);
+ 	default:
+ 		return 0;
+ 	}
+ }
+ EXPORT_SYMBOL(flow_get_u32_dst);
+ 
+ static inline void __flow_hash_consistentify(struct flow_keys *keys)
+ {
+ 	int addr_diff, i;
+ 
+ 	switch (keys->control.addr_type) {
+ 	case FLOW_DISSECTOR_KEY_IPV4_ADDRS:
+ 		addr_diff = (__force u32)keys->addrs.v4addrs.dst -
+ 			    (__force u32)keys->addrs.v4addrs.src;
+ 		if ((addr_diff < 0) ||
+ 		    (addr_diff == 0 &&
+ 		     ((__force u16)keys->ports.dst <
+ 		      (__force u16)keys->ports.src))) {
+ 			swap(keys->addrs.v4addrs.src, keys->addrs.v4addrs.dst);
+ 			swap(keys->ports.src, keys->ports.dst);
+ 		}
+ 		break;
+ 	case FLOW_DISSECTOR_KEY_IPV6_ADDRS:
+ 		addr_diff = memcmp(&keys->addrs.v6addrs.dst,
+ 				   &keys->addrs.v6addrs.src,
+ 				   sizeof(keys->addrs.v6addrs.dst));
+ 		if ((addr_diff < 0) ||
+ 		    (addr_diff == 0 &&
+ 		     ((__force u16)keys->ports.dst <
+ 		      (__force u16)keys->ports.src))) {
+ 			for (i = 0; i < 4; i++)
+ 				swap(keys->addrs.v6addrs.src.s6_addr32[i],
+ 				     keys->addrs.v6addrs.dst.s6_addr32[i]);
+ 			swap(keys->ports.src, keys->ports.dst);
+ 		}
+ 		break;
+ 	}
+ }
+ 
+ static inline u32 __flow_hash_from_keys(struct flow_keys *keys, u32 keyval)
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  {
  	u32 hash;
  
 -	__flow_hash_consistentify(keys);
 +	/* get a consistent hash (same value on both flow directions) */
 +	if (((__force u32)keys->dst < (__force u32)keys->src) ||
 +	    (((__force u32)keys->dst == (__force u32)keys->src) &&
 +	     ((__force u16)keys->port16[1] < (__force u16)keys->port16[0]))) {
 +		swap(keys->dst, keys->src);
 +		swap(keys->port16[0], keys->port16[1]);
 +	}
  
++<<<<<<< HEAD
 +	hash = __flow_hash_3words((__force u32)keys->dst,
 +				  (__force u32)keys->src,
 +				  (__force u32)keys->ports);
++=======
+ 	hash = __flow_hash_words(flow_keys_hash_start(keys),
+ 				 flow_keys_hash_length(keys), keyval);
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  	if (!hash)
  		hash = 1;
  
@@@ -387,33 -672,58 +666,82 @@@ void __skb_get_hash(struct sk_buff *skb
  }
  EXPORT_SYMBOL(__skb_get_hash);
  
 -__u32 skb_get_hash_perturb(const struct sk_buff *skb, u32 perturb)
 +/*
 + * Returns a Tx hash based on the given packet descriptor a Tx queues' number
 + * to be used as a distribution range.
 + */
 +u16 __skb_tx_hash(const struct net_device *dev, struct sk_buff *skb,
 +		  unsigned int num_tx_queues)
  {
 -	struct flow_keys keys;
 +	u32 hash;
 +	u16 qoffset = 0;
 +	u16 qcount = num_tx_queues;
 +
 +	if (skb_rx_queue_recorded(skb)) {
 +		hash = skb_get_rx_queue(skb);
 +		while (unlikely(hash >= num_tx_queues))
 +			hash -= num_tx_queues;
 +		return hash;
 +	}
 +
 +	if (dev->num_tc) {
 +		u8 tc = netdev_get_prio_tc_map(dev, skb->priority);
 +		qoffset = dev->tc_to_txq[tc].offset;
 +		qcount = dev->tc_to_txq[tc].count;
 +	}
  
 -	return ___skb_get_hash(skb, &keys, perturb);
 +	return (u16) reciprocal_scale(skb_get_hash(skb), qcount) + qoffset;
  }
++<<<<<<< HEAD
 +EXPORT_SYMBOL(__skb_tx_hash);
++=======
+ EXPORT_SYMBOL(skb_get_hash_perturb);
+ 
+ __u32 __skb_get_hash_flowi6(struct sk_buff *skb, const struct flowi6 *fl6)
+ {
+ 	struct flow_keys keys;
+ 
+ 	memset(&keys, 0, sizeof(keys));
+ 
+ 	memcpy(&keys.addrs.v6addrs.src, &fl6->saddr,
+ 	       sizeof(keys.addrs.v6addrs.src));
+ 	memcpy(&keys.addrs.v6addrs.dst, &fl6->daddr,
+ 	       sizeof(keys.addrs.v6addrs.dst));
+ 	keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV6_ADDRS;
+ 	keys.ports.src = fl6->fl6_sport;
+ 	keys.ports.dst = fl6->fl6_dport;
+ 	keys.keyid.keyid = fl6->fl6_gre_key;
+ 	keys.tags.flow_label = (__force u32)fl6->flowlabel;
+ 	keys.basic.ip_proto = fl6->flowi6_proto;
+ 
+ 	__skb_set_sw_hash(skb, flow_hash_from_keys(&keys),
+ 			  flow_keys_have_l4(&keys));
+ 
+ 	return skb->hash;
+ }
+ EXPORT_SYMBOL(__skb_get_hash_flowi6);
+ 
+ __u32 __skb_get_hash_flowi4(struct sk_buff *skb, const struct flowi4 *fl4)
+ {
+ 	struct flow_keys keys;
+ 
+ 	memset(&keys, 0, sizeof(keys));
+ 
+ 	keys.addrs.v4addrs.src = fl4->saddr;
+ 	keys.addrs.v4addrs.dst = fl4->daddr;
+ 	keys.control.addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;
+ 	keys.ports.src = fl4->fl4_sport;
+ 	keys.ports.dst = fl4->fl4_dport;
+ 	keys.keyid.keyid = fl4->fl4_gre_key;
+ 	keys.basic.ip_proto = fl4->flowi4_proto;
+ 
+ 	__skb_set_sw_hash(skb, flow_hash_from_keys(&keys),
+ 			  flow_keys_have_l4(&keys));
+ 
+ 	return skb->hash;
+ }
+ EXPORT_SYMBOL(__skb_get_hash_flowi4);
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
  
  u32 __skb_get_poff(const struct sk_buff *skb, void *data,
  		   const struct flow_keys *keys, int hlen)
@@@ -478,3 -789,106 +806,109 @@@ u32 skb_get_poff(const struct sk_buff *
  
  	return __skb_get_poff(skb, skb->data, &keys, skb_headlen(skb));
  }
++<<<<<<< HEAD
++=======
+ 
+ __u32 __get_hash_from_flowi6(const struct flowi6 *fl6, struct flow_keys *keys)
+ {
+ 	memset(keys, 0, sizeof(*keys));
+ 
+ 	memcpy(&keys->addrs.v6addrs.src, &fl6->saddr,
+ 	    sizeof(keys->addrs.v6addrs.src));
+ 	memcpy(&keys->addrs.v6addrs.dst, &fl6->daddr,
+ 	    sizeof(keys->addrs.v6addrs.dst));
+ 	keys->control.addr_type = FLOW_DISSECTOR_KEY_IPV6_ADDRS;
+ 	keys->ports.src = fl6->fl6_sport;
+ 	keys->ports.dst = fl6->fl6_dport;
+ 	keys->keyid.keyid = fl6->fl6_gre_key;
+ 	keys->tags.flow_label = (__force u32)fl6->flowlabel;
+ 	keys->basic.ip_proto = fl6->flowi6_proto;
+ 
+ 	return flow_hash_from_keys(keys);
+ }
+ EXPORT_SYMBOL(__get_hash_from_flowi6);
+ 
+ __u32 __get_hash_from_flowi4(const struct flowi4 *fl4, struct flow_keys *keys)
+ {
+ 	memset(keys, 0, sizeof(*keys));
+ 
+ 	keys->addrs.v4addrs.src = fl4->saddr;
+ 	keys->addrs.v4addrs.dst = fl4->daddr;
+ 	keys->control.addr_type = FLOW_DISSECTOR_KEY_IPV4_ADDRS;
+ 	keys->ports.src = fl4->fl4_sport;
+ 	keys->ports.dst = fl4->fl4_dport;
+ 	keys->keyid.keyid = fl4->fl4_gre_key;
+ 	keys->basic.ip_proto = fl4->flowi4_proto;
+ 
+ 	return flow_hash_from_keys(keys);
+ }
+ EXPORT_SYMBOL(__get_hash_from_flowi4);
+ 
+ static const struct flow_dissector_key flow_keys_dissector_keys[] = {
+ 	{
+ 		.key_id = FLOW_DISSECTOR_KEY_CONTROL,
+ 		.offset = offsetof(struct flow_keys, control),
+ 	},
+ 	{
+ 		.key_id = FLOW_DISSECTOR_KEY_BASIC,
+ 		.offset = offsetof(struct flow_keys, basic),
+ 	},
+ 	{
+ 		.key_id = FLOW_DISSECTOR_KEY_IPV4_ADDRS,
+ 		.offset = offsetof(struct flow_keys, addrs.v4addrs),
+ 	},
+ 	{
+ 		.key_id = FLOW_DISSECTOR_KEY_IPV6_ADDRS,
+ 		.offset = offsetof(struct flow_keys, addrs.v6addrs),
+ 	},
+ 	{
+ 		.key_id = FLOW_DISSECTOR_KEY_TIPC_ADDRS,
+ 		.offset = offsetof(struct flow_keys, addrs.tipcaddrs),
+ 	},
+ 	{
+ 		.key_id = FLOW_DISSECTOR_KEY_PORTS,
+ 		.offset = offsetof(struct flow_keys, ports),
+ 	},
+ 	{
+ 		.key_id = FLOW_DISSECTOR_KEY_VLANID,
+ 		.offset = offsetof(struct flow_keys, tags),
+ 	},
+ 	{
+ 		.key_id = FLOW_DISSECTOR_KEY_FLOW_LABEL,
+ 		.offset = offsetof(struct flow_keys, tags),
+ 	},
+ 	{
+ 		.key_id = FLOW_DISSECTOR_KEY_GRE_KEYID,
+ 		.offset = offsetof(struct flow_keys, keyid),
+ 	},
+ };
+ 
+ static const struct flow_dissector_key flow_keys_buf_dissector_keys[] = {
+ 	{
+ 		.key_id = FLOW_DISSECTOR_KEY_CONTROL,
+ 		.offset = offsetof(struct flow_keys, control),
+ 	},
+ 	{
+ 		.key_id = FLOW_DISSECTOR_KEY_BASIC,
+ 		.offset = offsetof(struct flow_keys, basic),
+ 	},
+ };
+ 
+ struct flow_dissector flow_keys_dissector __read_mostly;
+ EXPORT_SYMBOL(flow_keys_dissector);
+ 
+ struct flow_dissector flow_keys_buf_dissector __read_mostly;
+ 
+ static int __init init_default_flow_dissectors(void)
+ {
+ 	skb_flow_dissector_init(&flow_keys_dissector,
+ 				flow_keys_dissector_keys,
+ 				ARRAY_SIZE(flow_keys_dissector_keys));
+ 	skb_flow_dissector_init(&flow_keys_buf_dissector,
+ 				flow_keys_buf_dissector_keys,
+ 				ARRAY_SIZE(flow_keys_buf_dissector_keys));
+ 	return 0;
+ }
+ 
+ late_initcall_sync(init_default_flow_dissectors);
++>>>>>>> 20a17bf6c04e (flow_dissector: Use 'const' where possible.)
* Unmerged path include/linux/skbuff.h
* Unmerged path include/net/flow.h
* Unmerged path net/core/flow_dissector.c
