udplite: fix NULL pointer dereference

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Paolo Abeni <pabeni@redhat.com>
commit c915fe13cbaae5c7aa7b44f367d05addd60c9008
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/c915fe13.failed

The commit 850cbaddb52d ("udp: use it's own memory accounting schema")
assumes that the socket proto has memory accounting enabled,
but this is not the case for UDPLITE.
Fix it enabling memory accounting for UDPLITE and performing
fwd allocated memory reclaiming on socket shutdown.
UDP and UDPLITE share now the same memory accounting limits.
Also drop the backlog receive operation, since is no more needed.

Fixes: 850cbaddb52d ("udp: use it's own memory accounting schema")
	Reported-by: Andrei Vagin <avagin@gmail.com>
	Suggested-by: Eric Dumazet <eric.dumazet@gmail.com>
	Signed-off-by: Paolo Abeni <pabeni@redhat.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit c915fe13cbaae5c7aa7b44f367d05addd60c9008)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/udp.h
#	net/ipv4/udp.c
diff --cc include/net/udp.h
index 2c87c23321fa,1661791e8ca1..000000000000
--- a/include/net/udp.h
+++ b/include/net/udp.h
@@@ -227,42 -246,65 +227,64 @@@ static inline __be16 udp_flow_src_port(
  }
  
  /* net/ipv4/udp.c */
++<<<<<<< HEAD
++=======
+ void udp_destruct_sock(struct sock *sk);
+ void skb_consume_udp(struct sock *sk, struct sk_buff *skb, int len);
+ int __udp_enqueue_schedule_skb(struct sock *sk, struct sk_buff *skb);
+ void udp_skb_destructor(struct sock *sk, struct sk_buff *skb);
+ static inline struct sk_buff *
+ __skb_recv_udp(struct sock *sk, unsigned int flags, int noblock, int *peeked,
+ 	       int *off, int *err)
+ {
+ 	return __skb_recv_datagram(sk, flags | (noblock ? MSG_DONTWAIT : 0),
+ 				   udp_skb_destructor, peeked, off, err);
+ }
+ static inline struct sk_buff *skb_recv_udp(struct sock *sk, unsigned int flags,
+ 					   int noblock, int *err)
+ {
+ 	int peeked, off = 0;
+ 
+ 	return __skb_recv_udp(sk, flags, noblock, &peeked, &off, err);
+ }
+ 
++>>>>>>> c915fe13cbaa (udplite: fix NULL pointer dereference)
  void udp_v4_early_demux(struct sk_buff *skb);
 -int udp_get_port(struct sock *sk, unsigned short snum,
 -		 int (*saddr_cmp)(const struct sock *,
 -				  const struct sock *));
 -void udp_err(struct sk_buff *, u32);
 -int udp_abort(struct sock *sk, int err);
 -int udp_sendmsg(struct sock *sk, struct msghdr *msg, size_t len);
 -int udp_push_pending_frames(struct sock *sk);
 -void udp_flush_pending_frames(struct sock *sk);
 -void udp4_hwcsum(struct sk_buff *skb, __be32 src, __be32 dst);
 -int udp_rcv(struct sk_buff *skb);
 -int udp_ioctl(struct sock *sk, int cmd, unsigned long arg);
 -int udp_init_sock(struct sock *sk);
 -int __udp_disconnect(struct sock *sk, int flags);
 -int udp_disconnect(struct sock *sk, int flags);
 -unsigned int udp_poll(struct file *file, struct socket *sock, poll_table *wait);
 -struct sk_buff *skb_udp_tunnel_segment(struct sk_buff *skb,
 -				       netdev_features_t features,
 -				       bool is_ipv6);
 -int udp_lib_getsockopt(struct sock *sk, int level, int optname,
 -		       char __user *optval, int __user *optlen);
 -int udp_lib_setsockopt(struct sock *sk, int level, int optname,
 -		       char __user *optval, unsigned int optlen,
 -		       int (*push_pending_frames)(struct sock *));
 -struct sock *udp4_lib_lookup(struct net *net, __be32 saddr, __be16 sport,
 -			     __be32 daddr, __be16 dport, int dif);
 -struct sock *__udp4_lib_lookup(struct net *net, __be32 saddr, __be16 sport,
 -			       __be32 daddr, __be16 dport, int dif,
 -			       struct udp_table *tbl, struct sk_buff *skb);
 +extern int udp_get_port(struct sock *sk, unsigned short snum,
 +			int (*saddr_cmp)(const struct sock *,
 +					 const struct sock *));
 +extern void udp_err(struct sk_buff *, u32);
 +extern int udp_sendmsg(struct kiocb *iocb, struct sock *sk,
 +			    struct msghdr *msg, size_t len);
 +extern int udp_push_pending_frames(struct sock *sk);
 +extern void udp_flush_pending_frames(struct sock *sk);
 +extern int udp_rcv(struct sk_buff *skb);
 +extern int udp_ioctl(struct sock *sk, int cmd, unsigned long arg);
 +extern int udp_disconnect(struct sock *sk, int flags);
 +extern unsigned int udp_poll(struct file *file, struct socket *sock,
 +			     poll_table *wait);
 +extern struct sk_buff *skb_udp_tunnel_segment(struct sk_buff *skb,
 +					      netdev_features_t features,
 +					      bool is_ipv6);
 +extern int udp_lib_getsockopt(struct sock *sk, int level, int optname,
 +			      char __user *optval, int __user *optlen);
 +extern int udp_lib_setsockopt(struct sock *sk, int level, int optname,
 +			      char __user *optval, unsigned int optlen,
 +			      int (*push_pending_frames)(struct sock *));
 +extern struct sock *udp4_lib_lookup(struct net *net, __be32 saddr, __be16 sport,
 +				    __be32 daddr, __be16 dport,
 +				    int dif);
 +extern struct sock *__udp4_lib_lookup(struct net *net, __be32 saddr, __be16 sport,
 +				    __be32 daddr, __be16 dport,
 +				    int dif, struct udp_table *tbl);
  struct sock *udp4_lib_lookup_skb(struct sk_buff *skb,
  				 __be16 sport, __be16 dport);
 -struct sock *udp6_lib_lookup(struct net *net,
 -			     const struct in6_addr *saddr, __be16 sport,
 -			     const struct in6_addr *daddr, __be16 dport,
 -			     int dif);
 -struct sock *__udp6_lib_lookup(struct net *net,
 -			       const struct in6_addr *saddr, __be16 sport,
 -			       const struct in6_addr *daddr, __be16 dport,
 -			       int dif, struct udp_table *tbl,
 -			       struct sk_buff *skb);
 +extern struct sock *udp6_lib_lookup(struct net *net, const struct in6_addr *saddr, __be16 sport,
 +				    const struct in6_addr *daddr, __be16 dport,
 +				    int dif);
 +extern struct sock *__udp6_lib_lookup(struct net *net, const struct in6_addr *saddr, __be16 sport,
 +				    const struct in6_addr *daddr, __be16 dport,
 +				    int dif, struct udp_table *tbl);
  struct sock *udp6_lib_lookup_skb(struct sk_buff *skb,
  				 __be16 sport, __be16 dport);
  
diff --cc net/ipv4/udp.c
index a02b20ab0f64,9ae7c63a8b13..000000000000
--- a/net/ipv4/udp.c
+++ b/net/ipv4/udp.c
@@@ -1153,6 -1174,119 +1153,122 @@@ out
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ /* fully reclaim rmem/fwd memory allocated for skb */
+ static void udp_rmem_release(struct sock *sk, int size, int partial)
+ {
+ 	int amt;
+ 
+ 	atomic_sub(size, &sk->sk_rmem_alloc);
+ 	sk->sk_forward_alloc += size;
+ 	amt = (sk->sk_forward_alloc - partial) & ~(SK_MEM_QUANTUM - 1);
+ 	sk->sk_forward_alloc -= amt;
+ 
+ 	if (amt)
+ 		__sk_mem_reduce_allocated(sk, amt >> SK_MEM_QUANTUM_SHIFT);
+ }
+ 
+ /* Note: called with sk_receive_queue.lock held */
+ void udp_skb_destructor(struct sock *sk, struct sk_buff *skb)
+ {
+ 	udp_rmem_release(sk, skb->truesize, 1);
+ }
+ EXPORT_SYMBOL(udp_skb_destructor);
+ 
+ int __udp_enqueue_schedule_skb(struct sock *sk, struct sk_buff *skb)
+ {
+ 	struct sk_buff_head *list = &sk->sk_receive_queue;
+ 	int rmem, delta, amt, err = -ENOMEM;
+ 	int size = skb->truesize;
+ 
+ 	/* try to avoid the costly atomic add/sub pair when the receive
+ 	 * queue is full; always allow at least a packet
+ 	 */
+ 	rmem = atomic_read(&sk->sk_rmem_alloc);
+ 	if (rmem && (rmem + size > sk->sk_rcvbuf))
+ 		goto drop;
+ 
+ 	/* we drop only if the receive buf is full and the receive
+ 	 * queue contains some other skb
+ 	 */
+ 	rmem = atomic_add_return(size, &sk->sk_rmem_alloc);
+ 	if ((rmem > sk->sk_rcvbuf) && (rmem > size))
+ 		goto uncharge_drop;
+ 
+ 	spin_lock(&list->lock);
+ 	if (size >= sk->sk_forward_alloc) {
+ 		amt = sk_mem_pages(size);
+ 		delta = amt << SK_MEM_QUANTUM_SHIFT;
+ 		if (!__sk_mem_raise_allocated(sk, delta, amt, SK_MEM_RECV)) {
+ 			err = -ENOBUFS;
+ 			spin_unlock(&list->lock);
+ 			goto uncharge_drop;
+ 		}
+ 
+ 		sk->sk_forward_alloc += delta;
+ 	}
+ 
+ 	sk->sk_forward_alloc -= size;
+ 
+ 	/* no need to setup a destructor, we will explicitly release the
+ 	 * forward allocated memory on dequeue
+ 	 */
+ 	skb->dev = NULL;
+ 	sock_skb_set_dropcount(sk, skb);
+ 
+ 	__skb_queue_tail(list, skb);
+ 	spin_unlock(&list->lock);
+ 
+ 	if (!sock_flag(sk, SOCK_DEAD))
+ 		sk->sk_data_ready(sk);
+ 
+ 	return 0;
+ 
+ uncharge_drop:
+ 	atomic_sub(skb->truesize, &sk->sk_rmem_alloc);
+ 
+ drop:
+ 	atomic_inc(&sk->sk_drops);
+ 	return err;
+ }
+ EXPORT_SYMBOL_GPL(__udp_enqueue_schedule_skb);
+ 
+ void udp_destruct_sock(struct sock *sk)
+ {
+ 	/* reclaim completely the forward allocated memory */
+ 	unsigned int total = 0;
+ 	struct sk_buff *skb;
+ 
+ 	while ((skb = __skb_dequeue(&sk->sk_receive_queue)) != NULL) {
+ 		total += skb->truesize;
+ 		kfree_skb(skb);
+ 	}
+ 	udp_rmem_release(sk, total, 0);
+ 
+ 	inet_sock_destruct(sk);
+ }
+ EXPORT_SYMBOL_GPL(udp_destruct_sock);
+ 
+ int udp_init_sock(struct sock *sk)
+ {
+ 	sk->sk_destruct = udp_destruct_sock;
+ 	return 0;
+ }
+ EXPORT_SYMBOL_GPL(udp_init_sock);
+ 
+ void skb_consume_udp(struct sock *sk, struct sk_buff *skb, int len)
+ {
+ 	if (unlikely(READ_ONCE(sk->sk_peek_off) >= 0)) {
+ 		bool slow = lock_sock_fast(sk);
+ 
+ 		sk_peek_offset_bwd(sk, len);
+ 		unlock_sock_fast(sk, slow);
+ 	}
+ 	consume_skb(skb);
+ }
+ EXPORT_SYMBOL_GPL(skb_consume_udp);
++>>>>>>> c915fe13cbaa (udplite: fix NULL pointer dereference)
  
  /**
   *	first_packet_length	- return length of first packet in receive queue
* Unmerged path include/net/udp.h
diff --git a/include/net/udplite.h b/include/net/udplite.h
index 71375459a884..30eb82ae8326 100644
--- a/include/net/udplite.h
+++ b/include/net/udplite.h
@@ -26,6 +26,7 @@ static __inline__ int udplite_getfrag(void *from, char *to, int  offset,
 static inline int udplite_sk_init(struct sock *sk)
 {
 	udp_sk(sk)->pcflag = UDPLITE_BIT;
+	sk->sk_destruct = udp_destruct_sock;
 	return 0;
 }
 
* Unmerged path net/ipv4/udp.c
diff --git a/net/ipv4/udplite.c b/net/ipv4/udplite.c
index 3b3efbda48e1..ab4b90b50429 100644
--- a/net/ipv4/udplite.c
+++ b/net/ipv4/udplite.c
@@ -50,10 +50,11 @@ struct proto 	udplite_prot = {
 	.sendmsg	   = udp_sendmsg,
 	.recvmsg	   = udp_recvmsg,
 	.sendpage	   = udp_sendpage,
-	.backlog_rcv	   = udp_queue_rcv_skb,
 	.hash		   = udp_lib_hash,
 	.unhash		   = udp_lib_unhash,
 	.get_port	   = udp_v4_get_port,
+	.memory_allocated  = &udp_memory_allocated,
+	.sysctl_mem	   = sysctl_udp_mem,
 	.obj_size	   = sizeof(struct udp_sock),
 	.slab_flags	   = SLAB_DESTROY_BY_RCU,
 	.h.udp_table	   = &udplite_table,
diff --git a/net/ipv6/udplite.c b/net/ipv6/udplite.c
index 9cf097e206e9..02f2f15f0ffb 100644
--- a/net/ipv6/udplite.c
+++ b/net/ipv6/udplite.c
@@ -45,10 +45,11 @@ struct proto udplitev6_prot = {
 	.getsockopt	   = udpv6_getsockopt,
 	.sendmsg	   = udpv6_sendmsg,
 	.recvmsg	   = udpv6_recvmsg,
-	.backlog_rcv	   = udpv6_queue_rcv_skb,
 	.hash		   = udp_lib_hash,
 	.unhash		   = udp_lib_unhash,
 	.get_port	   = udp_v6_get_port,
+	.memory_allocated  = &udp_memory_allocated,
+	.sysctl_mem	   = sysctl_udp_mem,
 	.obj_size	   = sizeof(struct udp6_sock),
 	.slab_flags	   = SLAB_DESTROY_BY_RCU,
 	.h.udp_table	   = &udplite_table,
