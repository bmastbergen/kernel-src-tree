net: bridge: add support for IGMP/MLD stats and export them via netlink

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [net] bridge: add support for IGMP/MLD stats and export them via netlink (Ivan Vecera) [1352289]
Rebuild_FUZZ: 96.35%
commit-author Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
commit 1080ab95e3c7bdd77870e209aff83c763fdcf439
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/1080ab95.failed

This patch adds stats support for the currently used IGMP/MLD types by the
bridge. The stats are per-port (plus one stat per-bridge) and per-direction
(RX/TX). The stats are exported via netlink via the new linkxstats API
(RTM_GETSTATS). In order to minimize the performance impact, a new option
is used to enable/disable the stats - multicast_stats_enabled, similar to
the recent vlan stats. Also in order to avoid multiple IGMP/MLD type
lookups and checks, we make use of the current "igmp" member of the bridge
private skb->cb region to record the type on Rx (both host-generated and
external packets pass by multicast_rcv()). We can do that since the igmp
member was used as a boolean and all the valid IGMP/MLD types are positive
values. The normal bridge fast-path is not affected at all, the only
affected paths are the flooding ones and since we make use of the IGMP/MLD
type, we can quickly determine if the packet should be counted using
cache-hot data (cb's igmp member). We add counters for:
* IGMP Queries
* IGMP Leaves
* IGMP v1/v2/v3 reports

* MLD Queries
* MLD Leaves
* MLD v1/v2 reports

These are invaluable when monitoring or debugging complex multicast setups
with bridges.

	Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 1080ab95e3c7bdd77870e209aff83c763fdcf439)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/uapi/linux/if_bridge.h
#	include/uapi/linux/if_link.h
#	net/bridge/br_multicast.c
#	net/bridge/br_netlink.c
#	net/bridge/br_private.h
#	net/bridge/br_sysfs_br.c
diff --cc include/uapi/linux/if_bridge.h
index 15a865acafe9,8304fe6f0561..000000000000
--- a/include/uapi/linux/if_bridge.h
+++ b/include/uapi/linux/if_bridge.h
@@@ -209,4 -243,38 +209,41 @@@ enum 
  };
  #define MDBA_SET_ENTRY_MAX (__MDBA_SET_ENTRY_MAX - 1)
  
++<<<<<<< HEAD
++=======
+ /* Embedded inside LINK_XSTATS_TYPE_BRIDGE */
+ enum {
+ 	BRIDGE_XSTATS_UNSPEC,
+ 	BRIDGE_XSTATS_VLAN,
+ 	BRIDGE_XSTATS_MCAST,
+ 	BRIDGE_XSTATS_PAD,
+ 	__BRIDGE_XSTATS_MAX
+ };
+ #define BRIDGE_XSTATS_MAX (__BRIDGE_XSTATS_MAX - 1)
+ 
+ enum {
+ 	BR_MCAST_DIR_RX,
+ 	BR_MCAST_DIR_TX,
+ 	BR_MCAST_DIR_SIZE
+ };
+ 
+ /* IGMP/MLD statistics */
+ struct br_mcast_stats {
+ 	__u64 igmp_queries[BR_MCAST_DIR_SIZE];
+ 	__u64 igmp_leaves[BR_MCAST_DIR_SIZE];
+ 	__u64 igmp_v1reports[BR_MCAST_DIR_SIZE];
+ 	__u64 igmp_v2reports[BR_MCAST_DIR_SIZE];
+ 	__u64 igmp_v3reports[BR_MCAST_DIR_SIZE];
+ 	__u64 igmp_parse_errors;
+ 
+ 	__u64 mld_queries[BR_MCAST_DIR_SIZE];
+ 	__u64 mld_leaves[BR_MCAST_DIR_SIZE];
+ 	__u64 mld_v1reports[BR_MCAST_DIR_SIZE];
+ 	__u64 mld_v2reports[BR_MCAST_DIR_SIZE];
+ 	__u64 mld_parse_errors;
+ 
+ 	__u64 mcast_bytes[BR_MCAST_DIR_SIZE];
+ 	__u64 mcast_packets[BR_MCAST_DIR_SIZE];
+ };
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
  #endif /* _UAPI_LINUX_IF_BRIDGE_H */
diff --cc include/uapi/linux/if_link.h
index 1b43f8aab560,4285ac31e865..000000000000
--- a/include/uapi/linux/if_link.h
+++ b/include/uapi/linux/if_link.h
@@@ -232,6 -235,45 +232,48 @@@ enum 
  	IFLA_BR_FORWARD_DELAY,
  	IFLA_BR_HELLO_TIME,
  	IFLA_BR_MAX_AGE,
++<<<<<<< HEAD
++=======
+ 	IFLA_BR_AGEING_TIME,
+ 	IFLA_BR_STP_STATE,
+ 	IFLA_BR_PRIORITY,
+ 	IFLA_BR_VLAN_FILTERING,
+ 	IFLA_BR_VLAN_PROTOCOL,
+ 	IFLA_BR_GROUP_FWD_MASK,
+ 	IFLA_BR_ROOT_ID,
+ 	IFLA_BR_BRIDGE_ID,
+ 	IFLA_BR_ROOT_PORT,
+ 	IFLA_BR_ROOT_PATH_COST,
+ 	IFLA_BR_TOPOLOGY_CHANGE,
+ 	IFLA_BR_TOPOLOGY_CHANGE_DETECTED,
+ 	IFLA_BR_HELLO_TIMER,
+ 	IFLA_BR_TCN_TIMER,
+ 	IFLA_BR_TOPOLOGY_CHANGE_TIMER,
+ 	IFLA_BR_GC_TIMER,
+ 	IFLA_BR_GROUP_ADDR,
+ 	IFLA_BR_FDB_FLUSH,
+ 	IFLA_BR_MCAST_ROUTER,
+ 	IFLA_BR_MCAST_SNOOPING,
+ 	IFLA_BR_MCAST_QUERY_USE_IFADDR,
+ 	IFLA_BR_MCAST_QUERIER,
+ 	IFLA_BR_MCAST_HASH_ELASTICITY,
+ 	IFLA_BR_MCAST_HASH_MAX,
+ 	IFLA_BR_MCAST_LAST_MEMBER_CNT,
+ 	IFLA_BR_MCAST_STARTUP_QUERY_CNT,
+ 	IFLA_BR_MCAST_LAST_MEMBER_INTVL,
+ 	IFLA_BR_MCAST_MEMBERSHIP_INTVL,
+ 	IFLA_BR_MCAST_QUERIER_INTVL,
+ 	IFLA_BR_MCAST_QUERY_INTVL,
+ 	IFLA_BR_MCAST_QUERY_RESPONSE_INTVL,
+ 	IFLA_BR_MCAST_STARTUP_QUERY_INTVL,
+ 	IFLA_BR_NF_CALL_IPTABLES,
+ 	IFLA_BR_NF_CALL_IP6TABLES,
+ 	IFLA_BR_NF_CALL_ARPTABLES,
+ 	IFLA_BR_VLAN_DEFAULT_PVID,
+ 	IFLA_BR_PAD,
+ 	IFLA_BR_VLAN_STATS_ENABLED,
+ 	IFLA_BR_MCAST_STATS_ENABLED,
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
  	__IFLA_BR_MAX,
  };
  
diff --cc net/bridge/br_multicast.c
index 5d8caeb30a05,e405eef0ae2e..000000000000
--- a/net/bridge/br_multicast.c
+++ b/net/bridge/br_multicast.c
@@@ -819,11 -843,17 +826,23 @@@ static void __br_multicast_send_query(s
  
  	if (port) {
  		skb->dev = port->dev;
++<<<<<<< HEAD
 +		NF_HOOK(NFPROTO_BRIDGE, NF_BR_LOCAL_OUT, NULL, skb,
 +			NULL, skb->dev,
 +			br_dev_queue_push_xmit);
 +	} else
++=======
+ 		br_multicast_count(br, port, skb->protocol, igmp_type,
+ 				   BR_MCAST_DIR_TX);
+ 		NF_HOOK(NFPROTO_BRIDGE, NF_BR_LOCAL_OUT,
+ 			dev_net(port->dev), NULL, skb, NULL, skb->dev,
+ 			br_dev_queue_push_xmit);
+ 	} else {
+ 		br_multicast_select_own_querier(br, ip, skb);
+ 		br_multicast_count(br, port, skb->protocol, igmp_type,
+ 				   BR_MCAST_DIR_RX);
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
  		netif_rx(skb);
 -	}
  }
  
  static void br_multicast_send_query(struct net_bridge *br,
@@@ -899,9 -929,9 +918,9 @@@ static void br_ip6_multicast_port_query
  }
  #endif
  
- void br_multicast_add_port(struct net_bridge_port *port)
+ int br_multicast_add_port(struct net_bridge_port *port)
  {
 -	port->multicast_router = MDB_RTR_TYPE_TEMP_QUERY;
 +	port->multicast_router = 1;
  
  	setup_timer(&port->multicast_router_timer, br_multicast_router_expired,
  		    (unsigned long)port);
@@@ -1514,66 -1638,23 +1572,76 @@@ static int br_multicast_ipv4_rcv(struc
  				 struct sk_buff *skb,
  				 u16 vid)
  {
 -	struct sk_buff *skb_trimmed = NULL;
 +	struct sk_buff *skb2 = skb;
 +	const struct iphdr *iph;
  	struct igmphdr *ih;
 +	unsigned int len;
 +	unsigned int offset;
  	int err;
  
 -	err = ip_mc_check_igmp(skb, &skb_trimmed);
 +	/* We treat OOM as packet loss for now. */
 +	if (!pskb_may_pull(skb, sizeof(*iph)))
 +		return -EINVAL;
 +
 +	iph = ip_hdr(skb);
 +
 +	if (iph->ihl < 5 || iph->version != 4)
 +		return -EINVAL;
 +
 +	if (!pskb_may_pull(skb, ip_hdrlen(skb)))
 +		return -EINVAL;
 +
 +	iph = ip_hdr(skb);
  
 -	if (err == -ENOMSG) {
 -		if (!ipv4_is_local_multicast(ip_hdr(skb)->daddr))
 +	if (unlikely(ip_fast_csum((u8 *)iph, iph->ihl)))
 +		return -EINVAL;
 +
 +	if (iph->protocol != IPPROTO_IGMP) {
 +		if (!ipv4_is_local_multicast(iph->daddr))
  			BR_INPUT_SKB_CB(skb)->mrouters_only = 1;
  		return 0;
++<<<<<<< HEAD
 +	}
 +
 +	len = ntohs(iph->tot_len);
 +	if (skb->len < len || len < ip_hdrlen(skb))
 +		return -EINVAL;
 +
 +	if (skb->len > len) {
 +		skb2 = skb_clone(skb, GFP_ATOMIC);
 +		if (!skb2)
 +			return -ENOMEM;
 +
 +		err = pskb_trim_rcsum(skb2, len);
 +		if (err)
 +			goto err_out;
 +	}
 +
 +	len -= ip_hdrlen(skb2);
 +	offset = skb_network_offset(skb2) + ip_hdrlen(skb2);
 +	__skb_pull(skb2, offset);
 +	skb_reset_transport_header(skb2);
 +
 +	err = -EINVAL;
 +	if (!pskb_may_pull(skb2, sizeof(*ih)))
 +		goto out;
 +
 +	if (skb_checksum_simple_validate(skb2))
 +		goto out;
 +
 +	err = 0;
 +
 +	BR_INPUT_SKB_CB(skb)->igmp = 1;
 +	ih = igmp_hdr(skb2);
++=======
+ 	} else if (err < 0) {
+ 		br_multicast_err_count(br, port, skb->protocol);
+ 		return err;
+ 	}
+ 
+ 	ih = igmp_hdr(skb);
+ 	BR_INPUT_SKB_CB(skb)->igmp = ih->type;
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
  
  	switch (ih->type) {
  	case IGMP_HOST_MEMBERSHIP_REPORT:
@@@ -1592,11 -1673,12 +1660,20 @@@
  		break;
  	}
  
++<<<<<<< HEAD
 +out:
 +	__skb_push(skb2, offset);
 +err_out:
 +	if (skb2 != skb)
 +		kfree_skb(skb2);
++=======
+ 	if (skb_trimmed && skb_trimmed != skb)
+ 		kfree_skb(skb_trimmed);
+ 
+ 	br_multicast_count(br, port, skb->protocol, BR_INPUT_SKB_CB(skb)->igmp,
+ 			   BR_MCAST_DIR_RX);
+ 
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
  	return err;
  }
  
@@@ -1606,126 -1688,46 +1683,145 @@@ static int br_multicast_ipv6_rcv(struc
  				 struct sk_buff *skb,
  				 u16 vid)
  {
 -	struct sk_buff *skb_trimmed = NULL;
 -	struct mld_msg *mld;
 +	struct sk_buff *skb2;
 +	const struct ipv6hdr *ip6h;
 +	u8 icmp6_type;
 +	u8 nexthdr;
 +	__be16 frag_off;
 +	unsigned int len;
 +	int offset;
  	int err;
  
 -	err = ipv6_mc_check_mld(skb, &skb_trimmed);
 +	if (!pskb_may_pull(skb, sizeof(*ip6h)))
 +		return -EINVAL;
 +
 +	ip6h = ipv6_hdr(skb);
  
 -	if (err == -ENOMSG) {
 -		if (!ipv6_addr_is_ll_all_nodes(&ipv6_hdr(skb)->daddr))
 -			BR_INPUT_SKB_CB(skb)->mrouters_only = 1;
 +	/*
 +	 * We're interested in MLD messages only.
 +	 *  - Version is 6
 +	 *  - MLD has always Router Alert hop-by-hop option
 +	 *  - But we do not support jumbrograms.
 +	 */
 +	if (ip6h->version != 6)
  		return 0;
++<<<<<<< HEAD
 +
 +	/* Prevent flooding this packet if there is no listener present */
 +	if (!ipv6_addr_is_ll_all_nodes(&ip6h->daddr))
 +		BR_INPUT_SKB_CB(skb)->mrouters_only = 1;
 +
 +	if (ip6h->nexthdr != IPPROTO_HOPOPTS ||
 +	    ip6h->payload_len == 0)
 +		return 0;
 +
 +	len = ntohs(ip6h->payload_len) + sizeof(*ip6h);
 +	if (skb->len < len)
 +		return -EINVAL;
 +
 +	nexthdr = ip6h->nexthdr;
 +	offset = ipv6_skip_exthdr(skb, sizeof(*ip6h), &nexthdr, &frag_off);
 +
 +	if (offset < 0 || nexthdr != IPPROTO_ICMPV6)
 +		return 0;
 +
 +	/* Okay, we found ICMPv6 header */
 +	skb2 = skb_clone(skb, GFP_ATOMIC);
 +	if (!skb2)
 +		return -ENOMEM;
 +
 +	err = -EINVAL;
 +	if (!pskb_may_pull(skb2, offset + sizeof(struct icmp6hdr)))
 +		goto out;
 +
 +	len -= offset - skb_network_offset(skb2);
 +
 +	__skb_pull(skb2, offset);
 +	skb_reset_transport_header(skb2);
 +	skb_postpull_rcsum(skb2, skb_network_header(skb2),
 +			   skb_network_header_len(skb2));
 +
 +	icmp6_type = icmp6_hdr(skb2)->icmp6_type;
 +
 +	switch (icmp6_type) {
 +	case ICMPV6_MGM_QUERY:
 +	case ICMPV6_MGM_REPORT:
 +	case ICMPV6_MGM_REDUCTION:
 +	case ICMPV6_MLD2_REPORT:
 +		break;
 +	default:
 +		err = 0;
 +		goto out;
 +	}
 +
 +	/* Okay, we found MLD message. Check further. */
 +	if (skb2->len > len) {
 +		err = pskb_trim_rcsum(skb2, len);
 +		if (err)
 +			goto out;
 +		err = -EINVAL;
 +	}
++=======
+ 	} else if (err < 0) {
+ 		br_multicast_err_count(br, port, skb->protocol);
+ 		return err;
+ 	}
+ 
+ 	mld = (struct mld_msg *)skb_transport_header(skb);
+ 	BR_INPUT_SKB_CB(skb)->igmp = mld->mld_type;
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
 +
 +	ip6h = ipv6_hdr(skb2);
 +
 +	if (skb_checksum_validate(skb2, IPPROTO_ICMPV6, ip6_compute_pseudo))
 +		goto out;
  
 -	switch (mld->mld_type) {
 +	err = 0;
 +
 +	BR_INPUT_SKB_CB(skb)->igmp = 1;
 +
 +	switch (icmp6_type) {
  	case ICMPV6_MGM_REPORT:
 +	    {
 +		struct mld_msg *mld;
 +		if (!pskb_may_pull(skb2, sizeof(*mld))) {
 +			err = -EINVAL;
 +			goto out;
 +		}
 +		mld = (struct mld_msg *)skb_transport_header(skb2);
  		BR_INPUT_SKB_CB(skb)->mrouters_only = 1;
  		err = br_ip6_multicast_add_group(br, port, &mld->mld_mca, vid);
  		break;
 +	    }
  	case ICMPV6_MLD2_REPORT:
 -		err = br_ip6_multicast_mld2_report(br, port, skb_trimmed, vid);
 +		err = br_ip6_multicast_mld2_report(br, port, skb2, vid);
  		break;
  	case ICMPV6_MGM_QUERY:
 -		err = br_ip6_multicast_query(br, port, skb_trimmed, vid);
 +		err = br_ip6_multicast_query(br, port, skb2, vid);
  		break;
  	case ICMPV6_MGM_REDUCTION:
 +	    {
 +		struct mld_msg *mld;
 +		if (!pskb_may_pull(skb2, sizeof(*mld))) {
 +			err = -EINVAL;
 +			goto out;
 +		}
 +		mld = (struct mld_msg *)skb_transport_header(skb2);
  		br_ip6_multicast_leave_group(br, port, &mld->mld_mca, vid);
 -		break;
 +	    }
  	}
  
++<<<<<<< HEAD
 +out:
 +	kfree_skb(skb2);
++=======
+ 	if (skb_trimmed && skb_trimmed != skb)
+ 		kfree_skb(skb_trimmed);
+ 
+ 	br_multicast_count(br, port, skb->protocol, BR_INPUT_SKB_CB(skb)->igmp,
+ 			   BR_MCAST_DIR_RX);
+ 
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
  	return err;
  }
  #endif
@@@ -2140,4 -2163,214 +2242,142 @@@ unlock
  	return count;
  }
  EXPORT_SYMBOL_GPL(br_multicast_list_adjacent);
 -
 -/**
 - * br_multicast_has_querier_anywhere - Checks for a querier on a bridge
 - * @dev: The bridge port providing the bridge on which to check for a querier
 - * @proto: The protocol family to check for: IGMP -> ETH_P_IP, MLD -> ETH_P_IPV6
 - *
 - * Checks whether the given interface has a bridge on top and if so returns
 - * true if a valid querier exists anywhere on the bridged link layer.
 - * Otherwise returns false.
 - */
 -bool br_multicast_has_querier_anywhere(struct net_device *dev, int proto)
 -{
 -	struct net_bridge *br;
 -	struct net_bridge_port *port;
 -	struct ethhdr eth;
 -	bool ret = false;
 -
 -	rcu_read_lock();
 -	if (!br_port_exists(dev))
 -		goto unlock;
 -
 -	port = br_port_get_rcu(dev);
 -	if (!port || !port->br)
 -		goto unlock;
 -
 -	br = port->br;
 -
 -	memset(&eth, 0, sizeof(eth));
 -	eth.h_proto = htons(proto);
 -
 -	ret = br_multicast_querier_exists(br, &eth);
 -
 -unlock:
 -	rcu_read_unlock();
 -	return ret;
 -}
 -EXPORT_SYMBOL_GPL(br_multicast_has_querier_anywhere);
 -
 -/**
 - * br_multicast_has_querier_adjacent - Checks for a querier behind a bridge port
 - * @dev: The bridge port adjacent to which to check for a querier
 - * @proto: The protocol family to check for: IGMP -> ETH_P_IP, MLD -> ETH_P_IPV6
 - *
 - * Checks whether the given interface has a bridge on top and if so returns
 - * true if a selected querier is behind one of the other ports of this
 - * bridge. Otherwise returns false.
 - */
 -bool br_multicast_has_querier_adjacent(struct net_device *dev, int proto)
 -{
 -	struct net_bridge *br;
 -	struct net_bridge_port *port;
 -	bool ret = false;
 -
 -	rcu_read_lock();
 -	if (!br_port_exists(dev))
 -		goto unlock;
 -
 -	port = br_port_get_rcu(dev);
 -	if (!port || !port->br)
 -		goto unlock;
 -
 -	br = port->br;
 -
 -	switch (proto) {
 -	case ETH_P_IP:
 -		if (!timer_pending(&br->ip4_other_query.timer) ||
 -		    rcu_dereference(br->ip4_querier.port) == port)
 -			goto unlock;
 -		break;
 -#if IS_ENABLED(CONFIG_IPV6)
 -	case ETH_P_IPV6:
 -		if (!timer_pending(&br->ip6_other_query.timer) ||
 -		    rcu_dereference(br->ip6_querier.port) == port)
 -			goto unlock;
 -		break;
  #endif
++<<<<<<< HEAD
++=======
+ 	default:
+ 		goto unlock;
+ 	}
+ 
+ 	ret = true;
+ unlock:
+ 	rcu_read_unlock();
+ 	return ret;
+ }
+ EXPORT_SYMBOL_GPL(br_multicast_has_querier_adjacent);
+ 
+ static void br_mcast_stats_add(struct bridge_mcast_stats __percpu *stats,
+ 			       __be16 proto, u8 type, u8 dir)
+ {
+ 	struct bridge_mcast_stats *pstats = this_cpu_ptr(stats);
+ 
+ 	u64_stats_update_begin(&pstats->syncp);
+ 	switch (proto) {
+ 	case htons(ETH_P_IP):
+ 		switch (type) {
+ 		case IGMP_HOST_MEMBERSHIP_REPORT:
+ 			pstats->mstats.igmp_v1reports[dir]++;
+ 			break;
+ 		case IGMPV2_HOST_MEMBERSHIP_REPORT:
+ 			pstats->mstats.igmp_v2reports[dir]++;
+ 			break;
+ 		case IGMPV3_HOST_MEMBERSHIP_REPORT:
+ 			pstats->mstats.igmp_v3reports[dir]++;
+ 			break;
+ 		case IGMP_HOST_MEMBERSHIP_QUERY:
+ 			pstats->mstats.igmp_queries[dir]++;
+ 			break;
+ 		case IGMP_HOST_LEAVE_MESSAGE:
+ 			pstats->mstats.igmp_leaves[dir]++;
+ 			break;
+ 		}
+ 		break;
+ #if IS_ENABLED(CONFIG_IPV6)
+ 	case htons(ETH_P_IPV6):
+ 		switch (type) {
+ 		case ICMPV6_MGM_REPORT:
+ 			pstats->mstats.mld_v1reports[dir]++;
+ 			break;
+ 		case ICMPV6_MLD2_REPORT:
+ 			pstats->mstats.mld_v2reports[dir]++;
+ 			break;
+ 		case ICMPV6_MGM_QUERY:
+ 			pstats->mstats.mld_queries[dir]++;
+ 			break;
+ 		case ICMPV6_MGM_REDUCTION:
+ 			pstats->mstats.mld_leaves[dir]++;
+ 			break;
+ 		}
+ 		break;
+ #endif /* CONFIG_IPV6 */
+ 	}
+ 	u64_stats_update_end(&pstats->syncp);
+ }
+ 
+ void br_multicast_count(struct net_bridge *br, const struct net_bridge_port *p,
+ 			__be16 proto, u8 type, u8 dir)
+ {
+ 	struct bridge_mcast_stats __percpu *stats;
+ 
+ 	/* if multicast_disabled is true then igmp type can't be set */
+ 	if (!type || !br->multicast_stats_enabled)
+ 		return;
+ 
+ 	if (p)
+ 		stats = p->mcast_stats;
+ 	else
+ 		stats = br->mcast_stats;
+ 	if (WARN_ON(!stats))
+ 		return;
+ 
+ 	br_mcast_stats_add(stats, proto, type, dir);
+ }
+ 
+ int br_multicast_init_stats(struct net_bridge *br)
+ {
+ 	br->mcast_stats = netdev_alloc_pcpu_stats(struct bridge_mcast_stats);
+ 	if (!br->mcast_stats)
+ 		return -ENOMEM;
+ 
+ 	return 0;
+ }
+ 
+ static void mcast_stats_add_dir(u64 *dst, u64 *src)
+ {
+ 	dst[BR_MCAST_DIR_RX] += src[BR_MCAST_DIR_RX];
+ 	dst[BR_MCAST_DIR_TX] += src[BR_MCAST_DIR_TX];
+ }
+ 
+ void br_multicast_get_stats(const struct net_bridge *br,
+ 			    const struct net_bridge_port *p,
+ 			    struct br_mcast_stats *dest)
+ {
+ 	struct bridge_mcast_stats __percpu *stats;
+ 	struct br_mcast_stats tdst;
+ 	int i;
+ 
+ 	memset(dest, 0, sizeof(*dest));
+ 	if (p)
+ 		stats = p->mcast_stats;
+ 	else
+ 		stats = br->mcast_stats;
+ 	if (WARN_ON(!stats))
+ 		return;
+ 
+ 	memset(&tdst, 0, sizeof(tdst));
+ 	for_each_possible_cpu(i) {
+ 		struct bridge_mcast_stats *cpu_stats = per_cpu_ptr(stats, i);
+ 		struct br_mcast_stats temp;
+ 		unsigned int start;
+ 
+ 		do {
+ 			start = u64_stats_fetch_begin_irq(&cpu_stats->syncp);
+ 			memcpy(&temp, &cpu_stats->mstats, sizeof(temp));
+ 		} while (u64_stats_fetch_retry_irq(&cpu_stats->syncp, start));
+ 
+ 		mcast_stats_add_dir(tdst.igmp_queries, temp.igmp_queries);
+ 		mcast_stats_add_dir(tdst.igmp_leaves, temp.igmp_leaves);
+ 		mcast_stats_add_dir(tdst.igmp_v1reports, temp.igmp_v1reports);
+ 		mcast_stats_add_dir(tdst.igmp_v2reports, temp.igmp_v2reports);
+ 		mcast_stats_add_dir(tdst.igmp_v3reports, temp.igmp_v3reports);
+ 		tdst.igmp_parse_errors += temp.igmp_parse_errors;
+ 
+ 		mcast_stats_add_dir(tdst.mld_queries, temp.mld_queries);
+ 		mcast_stats_add_dir(tdst.mld_leaves, temp.mld_leaves);
+ 		mcast_stats_add_dir(tdst.mld_v1reports, temp.mld_v1reports);
+ 		mcast_stats_add_dir(tdst.mld_v2reports, temp.mld_v2reports);
+ 		tdst.mld_parse_errors += temp.mld_parse_errors;
+ 	}
+ 	memcpy(dest, &tdst, sizeof(*dest));
+ }
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
diff --cc net/bridge/br_netlink.c
index 2f4d900feeb1,f2a29e467e78..000000000000
--- a/net/bridge/br_netlink.c
+++ b/net/bridge/br_netlink.c
@@@ -648,27 -789,610 +648,621 @@@ static int br_dev_newlink(struct net *s
  	return register_netdevice(dev);
  }
  
 -static int br_port_slave_changelink(struct net_device *brdev,
 -				    struct net_device *dev,
 -				    struct nlattr *tb[],
 -				    struct nlattr *data[])
 +static size_t br_get_link_af_size(const struct net_device *dev)
  {
 -	struct net_bridge *br = netdev_priv(brdev);
 -	int ret;
 +	struct net_port_vlans *pv;
  
 -	if (!data)
 +	if (br_port_exists(dev))
 +		pv = nbp_get_vlan_info(br_port_get_rtnl(dev));
 +	else if (dev->priv_flags & IFF_EBRIDGE)
 +		pv = br_get_vlan_info((struct net_bridge *)netdev_priv(dev));
 +	else
  		return 0;
  
++<<<<<<< HEAD
 +	if (!pv)
 +		return 0;
 +
 +	/* Each VLAN is returned in bridge_vlan_info along with flags */
 +	return pv->num_vlans * nla_total_size(sizeof(struct bridge_vlan_info));
 +}
 +
 +static struct rtnl_af_ops br_af_ops = {
++=======
+ 	spin_lock_bh(&br->lock);
+ 	ret = br_setport(br_port_get_rtnl(dev), data);
+ 	spin_unlock_bh(&br->lock);
+ 
+ 	return ret;
+ }
+ 
+ static int br_port_fill_slave_info(struct sk_buff *skb,
+ 				   const struct net_device *brdev,
+ 				   const struct net_device *dev)
+ {
+ 	return br_port_fill_attrs(skb, br_port_get_rtnl(dev));
+ }
+ 
+ static size_t br_port_get_slave_size(const struct net_device *brdev,
+ 				     const struct net_device *dev)
+ {
+ 	return br_port_info_size();
+ }
+ 
+ static const struct nla_policy br_policy[IFLA_BR_MAX + 1] = {
+ 	[IFLA_BR_FORWARD_DELAY]	= { .type = NLA_U32 },
+ 	[IFLA_BR_HELLO_TIME]	= { .type = NLA_U32 },
+ 	[IFLA_BR_MAX_AGE]	= { .type = NLA_U32 },
+ 	[IFLA_BR_AGEING_TIME] = { .type = NLA_U32 },
+ 	[IFLA_BR_STP_STATE] = { .type = NLA_U32 },
+ 	[IFLA_BR_PRIORITY] = { .type = NLA_U16 },
+ 	[IFLA_BR_VLAN_FILTERING] = { .type = NLA_U8 },
+ 	[IFLA_BR_VLAN_PROTOCOL] = { .type = NLA_U16 },
+ 	[IFLA_BR_GROUP_FWD_MASK] = { .type = NLA_U16 },
+ 	[IFLA_BR_GROUP_ADDR] = { .type = NLA_BINARY,
+ 				 .len  = ETH_ALEN },
+ 	[IFLA_BR_MCAST_ROUTER] = { .type = NLA_U8 },
+ 	[IFLA_BR_MCAST_SNOOPING] = { .type = NLA_U8 },
+ 	[IFLA_BR_MCAST_QUERY_USE_IFADDR] = { .type = NLA_U8 },
+ 	[IFLA_BR_MCAST_QUERIER] = { .type = NLA_U8 },
+ 	[IFLA_BR_MCAST_HASH_ELASTICITY] = { .type = NLA_U32 },
+ 	[IFLA_BR_MCAST_HASH_MAX] = { .type = NLA_U32 },
+ 	[IFLA_BR_MCAST_LAST_MEMBER_CNT] = { .type = NLA_U32 },
+ 	[IFLA_BR_MCAST_STARTUP_QUERY_CNT] = { .type = NLA_U32 },
+ 	[IFLA_BR_MCAST_LAST_MEMBER_INTVL] = { .type = NLA_U64 },
+ 	[IFLA_BR_MCAST_MEMBERSHIP_INTVL] = { .type = NLA_U64 },
+ 	[IFLA_BR_MCAST_QUERIER_INTVL] = { .type = NLA_U64 },
+ 	[IFLA_BR_MCAST_QUERY_INTVL] = { .type = NLA_U64 },
+ 	[IFLA_BR_MCAST_QUERY_RESPONSE_INTVL] = { .type = NLA_U64 },
+ 	[IFLA_BR_MCAST_STARTUP_QUERY_INTVL] = { .type = NLA_U64 },
+ 	[IFLA_BR_NF_CALL_IPTABLES] = { .type = NLA_U8 },
+ 	[IFLA_BR_NF_CALL_IP6TABLES] = { .type = NLA_U8 },
+ 	[IFLA_BR_NF_CALL_ARPTABLES] = { .type = NLA_U8 },
+ 	[IFLA_BR_VLAN_DEFAULT_PVID] = { .type = NLA_U16 },
+ 	[IFLA_BR_VLAN_STATS_ENABLED] = { .type = NLA_U8 },
+ 	[IFLA_BR_MCAST_STATS_ENABLED] = { .type = NLA_U8 },
+ };
+ 
+ static int br_changelink(struct net_device *brdev, struct nlattr *tb[],
+ 			 struct nlattr *data[])
+ {
+ 	struct net_bridge *br = netdev_priv(brdev);
+ 	int err;
+ 
+ 	if (!data)
+ 		return 0;
+ 
+ 	if (data[IFLA_BR_FORWARD_DELAY]) {
+ 		err = br_set_forward_delay(br, nla_get_u32(data[IFLA_BR_FORWARD_DELAY]));
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_HELLO_TIME]) {
+ 		err = br_set_hello_time(br, nla_get_u32(data[IFLA_BR_HELLO_TIME]));
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_MAX_AGE]) {
+ 		err = br_set_max_age(br, nla_get_u32(data[IFLA_BR_MAX_AGE]));
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_AGEING_TIME]) {
+ 		err = br_set_ageing_time(br, nla_get_u32(data[IFLA_BR_AGEING_TIME]));
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_STP_STATE]) {
+ 		u32 stp_enabled = nla_get_u32(data[IFLA_BR_STP_STATE]);
+ 
+ 		br_stp_set_enabled(br, stp_enabled);
+ 	}
+ 
+ 	if (data[IFLA_BR_PRIORITY]) {
+ 		u32 priority = nla_get_u16(data[IFLA_BR_PRIORITY]);
+ 
+ 		br_stp_set_bridge_priority(br, priority);
+ 	}
+ 
+ 	if (data[IFLA_BR_VLAN_FILTERING]) {
+ 		u8 vlan_filter = nla_get_u8(data[IFLA_BR_VLAN_FILTERING]);
+ 
+ 		err = __br_vlan_filter_toggle(br, vlan_filter);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ #ifdef CONFIG_BRIDGE_VLAN_FILTERING
+ 	if (data[IFLA_BR_VLAN_PROTOCOL]) {
+ 		__be16 vlan_proto = nla_get_be16(data[IFLA_BR_VLAN_PROTOCOL]);
+ 
+ 		err = __br_vlan_set_proto(br, vlan_proto);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_VLAN_DEFAULT_PVID]) {
+ 		__u16 defpvid = nla_get_u16(data[IFLA_BR_VLAN_DEFAULT_PVID]);
+ 
+ 		err = __br_vlan_set_default_pvid(br, defpvid);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_VLAN_STATS_ENABLED]) {
+ 		__u8 vlan_stats = nla_get_u8(data[IFLA_BR_VLAN_STATS_ENABLED]);
+ 
+ 		err = br_vlan_set_stats(br, vlan_stats);
+ 		if (err)
+ 			return err;
+ 	}
+ #endif
+ 
+ 	if (data[IFLA_BR_GROUP_FWD_MASK]) {
+ 		u16 fwd_mask = nla_get_u16(data[IFLA_BR_GROUP_FWD_MASK]);
+ 
+ 		if (fwd_mask & BR_GROUPFWD_RESTRICTED)
+ 			return -EINVAL;
+ 		br->group_fwd_mask = fwd_mask;
+ 	}
+ 
+ 	if (data[IFLA_BR_GROUP_ADDR]) {
+ 		u8 new_addr[ETH_ALEN];
+ 
+ 		if (nla_len(data[IFLA_BR_GROUP_ADDR]) != ETH_ALEN)
+ 			return -EINVAL;
+ 		memcpy(new_addr, nla_data(data[IFLA_BR_GROUP_ADDR]), ETH_ALEN);
+ 		if (!is_link_local_ether_addr(new_addr))
+ 			return -EINVAL;
+ 		if (new_addr[5] == 1 ||		/* 802.3x Pause address */
+ 		    new_addr[5] == 2 ||		/* 802.3ad Slow protocols */
+ 		    new_addr[5] == 3)		/* 802.1X PAE address */
+ 			return -EINVAL;
+ 		spin_lock_bh(&br->lock);
+ 		memcpy(br->group_addr, new_addr, sizeof(br->group_addr));
+ 		spin_unlock_bh(&br->lock);
+ 		br->group_addr_set = true;
+ 		br_recalculate_fwd_mask(br);
+ 	}
+ 
+ 	if (data[IFLA_BR_FDB_FLUSH])
+ 		br_fdb_flush(br);
+ 
+ #ifdef CONFIG_BRIDGE_IGMP_SNOOPING
+ 	if (data[IFLA_BR_MCAST_ROUTER]) {
+ 		u8 multicast_router = nla_get_u8(data[IFLA_BR_MCAST_ROUTER]);
+ 
+ 		err = br_multicast_set_router(br, multicast_router);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_SNOOPING]) {
+ 		u8 mcast_snooping = nla_get_u8(data[IFLA_BR_MCAST_SNOOPING]);
+ 
+ 		err = br_multicast_toggle(br, mcast_snooping);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_QUERY_USE_IFADDR]) {
+ 		u8 val;
+ 
+ 		val = nla_get_u8(data[IFLA_BR_MCAST_QUERY_USE_IFADDR]);
+ 		br->multicast_query_use_ifaddr = !!val;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_QUERIER]) {
+ 		u8 mcast_querier = nla_get_u8(data[IFLA_BR_MCAST_QUERIER]);
+ 
+ 		err = br_multicast_set_querier(br, mcast_querier);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_HASH_ELASTICITY]) {
+ 		u32 val = nla_get_u32(data[IFLA_BR_MCAST_HASH_ELASTICITY]);
+ 
+ 		br->hash_elasticity = val;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_HASH_MAX]) {
+ 		u32 hash_max = nla_get_u32(data[IFLA_BR_MCAST_HASH_MAX]);
+ 
+ 		err = br_multicast_set_hash_max(br, hash_max);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_LAST_MEMBER_CNT]) {
+ 		u32 val = nla_get_u32(data[IFLA_BR_MCAST_LAST_MEMBER_CNT]);
+ 
+ 		br->multicast_last_member_count = val;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_STARTUP_QUERY_CNT]) {
+ 		u32 val = nla_get_u32(data[IFLA_BR_MCAST_STARTUP_QUERY_CNT]);
+ 
+ 		br->multicast_startup_query_count = val;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_LAST_MEMBER_INTVL]) {
+ 		u64 val = nla_get_u64(data[IFLA_BR_MCAST_LAST_MEMBER_INTVL]);
+ 
+ 		br->multicast_last_member_interval = clock_t_to_jiffies(val);
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_MEMBERSHIP_INTVL]) {
+ 		u64 val = nla_get_u64(data[IFLA_BR_MCAST_MEMBERSHIP_INTVL]);
+ 
+ 		br->multicast_membership_interval = clock_t_to_jiffies(val);
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_QUERIER_INTVL]) {
+ 		u64 val = nla_get_u64(data[IFLA_BR_MCAST_QUERIER_INTVL]);
+ 
+ 		br->multicast_querier_interval = clock_t_to_jiffies(val);
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_QUERY_INTVL]) {
+ 		u64 val = nla_get_u64(data[IFLA_BR_MCAST_QUERY_INTVL]);
+ 
+ 		br->multicast_query_interval = clock_t_to_jiffies(val);
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_QUERY_RESPONSE_INTVL]) {
+ 		u64 val = nla_get_u64(data[IFLA_BR_MCAST_QUERY_RESPONSE_INTVL]);
+ 
+ 		br->multicast_query_response_interval = clock_t_to_jiffies(val);
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_STARTUP_QUERY_INTVL]) {
+ 		u64 val = nla_get_u64(data[IFLA_BR_MCAST_STARTUP_QUERY_INTVL]);
+ 
+ 		br->multicast_startup_query_interval = clock_t_to_jiffies(val);
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_STATS_ENABLED]) {
+ 		__u8 mcast_stats;
+ 
+ 		mcast_stats = nla_get_u8(data[IFLA_BR_MCAST_STATS_ENABLED]);
+ 		br->multicast_stats_enabled = !!mcast_stats;
+ 	}
+ #endif
+ #if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)
+ 	if (data[IFLA_BR_NF_CALL_IPTABLES]) {
+ 		u8 val = nla_get_u8(data[IFLA_BR_NF_CALL_IPTABLES]);
+ 
+ 		br->nf_call_iptables = val ? true : false;
+ 	}
+ 
+ 	if (data[IFLA_BR_NF_CALL_IP6TABLES]) {
+ 		u8 val = nla_get_u8(data[IFLA_BR_NF_CALL_IP6TABLES]);
+ 
+ 		br->nf_call_ip6tables = val ? true : false;
+ 	}
+ 
+ 	if (data[IFLA_BR_NF_CALL_ARPTABLES]) {
+ 		u8 val = nla_get_u8(data[IFLA_BR_NF_CALL_ARPTABLES]);
+ 
+ 		br->nf_call_arptables = val ? true : false;
+ 	}
+ #endif
+ 
+ 	return 0;
+ }
+ 
+ static size_t br_get_size(const struct net_device *brdev)
+ {
+ 	return nla_total_size(sizeof(u32)) +	/* IFLA_BR_FORWARD_DELAY  */
+ 	       nla_total_size(sizeof(u32)) +	/* IFLA_BR_HELLO_TIME */
+ 	       nla_total_size(sizeof(u32)) +	/* IFLA_BR_MAX_AGE */
+ 	       nla_total_size(sizeof(u32)) +    /* IFLA_BR_AGEING_TIME */
+ 	       nla_total_size(sizeof(u32)) +    /* IFLA_BR_STP_STATE */
+ 	       nla_total_size(sizeof(u16)) +    /* IFLA_BR_PRIORITY */
+ 	       nla_total_size(sizeof(u8)) +     /* IFLA_BR_VLAN_FILTERING */
+ #ifdef CONFIG_BRIDGE_VLAN_FILTERING
+ 	       nla_total_size(sizeof(__be16)) +	/* IFLA_BR_VLAN_PROTOCOL */
+ 	       nla_total_size(sizeof(u16)) +    /* IFLA_BR_VLAN_DEFAULT_PVID */
+ 	       nla_total_size(sizeof(u8)) +     /* IFLA_BR_VLAN_STATS_ENABLED */
+ #endif
+ 	       nla_total_size(sizeof(u16)) +    /* IFLA_BR_GROUP_FWD_MASK */
+ 	       nla_total_size(sizeof(struct ifla_bridge_id)) +   /* IFLA_BR_ROOT_ID */
+ 	       nla_total_size(sizeof(struct ifla_bridge_id)) +   /* IFLA_BR_BRIDGE_ID */
+ 	       nla_total_size(sizeof(u16)) +    /* IFLA_BR_ROOT_PORT */
+ 	       nla_total_size(sizeof(u32)) +    /* IFLA_BR_ROOT_PATH_COST */
+ 	       nla_total_size(sizeof(u8)) +     /* IFLA_BR_TOPOLOGY_CHANGE */
+ 	       nla_total_size(sizeof(u8)) +     /* IFLA_BR_TOPOLOGY_CHANGE_DETECTED */
+ 	       nla_total_size_64bit(sizeof(u64)) + /* IFLA_BR_HELLO_TIMER */
+ 	       nla_total_size_64bit(sizeof(u64)) + /* IFLA_BR_TCN_TIMER */
+ 	       nla_total_size_64bit(sizeof(u64)) + /* IFLA_BR_TOPOLOGY_CHANGE_TIMER */
+ 	       nla_total_size_64bit(sizeof(u64)) + /* IFLA_BR_GC_TIMER */
+ 	       nla_total_size(ETH_ALEN) +       /* IFLA_BR_GROUP_ADDR */
+ #ifdef CONFIG_BRIDGE_IGMP_SNOOPING
+ 	       nla_total_size(sizeof(u8)) +     /* IFLA_BR_MCAST_ROUTER */
+ 	       nla_total_size(sizeof(u8)) +     /* IFLA_BR_MCAST_SNOOPING */
+ 	       nla_total_size(sizeof(u8)) +     /* IFLA_BR_MCAST_QUERY_USE_IFADDR */
+ 	       nla_total_size(sizeof(u8)) +     /* IFLA_BR_MCAST_QUERIER */
+ 	       nla_total_size(sizeof(u8)) +     /* IFLA_BR_MCAST_STATS_ENABLED */
+ 	       nla_total_size(sizeof(u32)) +    /* IFLA_BR_MCAST_HASH_ELASTICITY */
+ 	       nla_total_size(sizeof(u32)) +    /* IFLA_BR_MCAST_HASH_MAX */
+ 	       nla_total_size(sizeof(u32)) +    /* IFLA_BR_MCAST_LAST_MEMBER_CNT */
+ 	       nla_total_size(sizeof(u32)) +    /* IFLA_BR_MCAST_STARTUP_QUERY_CNT */
+ 	       nla_total_size_64bit(sizeof(u64)) + /* IFLA_BR_MCAST_LAST_MEMBER_INTVL */
+ 	       nla_total_size_64bit(sizeof(u64)) + /* IFLA_BR_MCAST_MEMBERSHIP_INTVL */
+ 	       nla_total_size_64bit(sizeof(u64)) + /* IFLA_BR_MCAST_QUERIER_INTVL */
+ 	       nla_total_size_64bit(sizeof(u64)) + /* IFLA_BR_MCAST_QUERY_INTVL */
+ 	       nla_total_size_64bit(sizeof(u64)) + /* IFLA_BR_MCAST_QUERY_RESPONSE_INTVL */
+ 	       nla_total_size_64bit(sizeof(u64)) + /* IFLA_BR_MCAST_STARTUP_QUERY_INTVL */
+ #endif
+ #if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)
+ 	       nla_total_size(sizeof(u8)) +     /* IFLA_BR_NF_CALL_IPTABLES */
+ 	       nla_total_size(sizeof(u8)) +     /* IFLA_BR_NF_CALL_IP6TABLES */
+ 	       nla_total_size(sizeof(u8)) +     /* IFLA_BR_NF_CALL_ARPTABLES */
+ #endif
+ 	       0;
+ }
+ 
+ static int br_fill_info(struct sk_buff *skb, const struct net_device *brdev)
+ {
+ 	struct net_bridge *br = netdev_priv(brdev);
+ 	u32 forward_delay = jiffies_to_clock_t(br->forward_delay);
+ 	u32 hello_time = jiffies_to_clock_t(br->hello_time);
+ 	u32 age_time = jiffies_to_clock_t(br->max_age);
+ 	u32 ageing_time = jiffies_to_clock_t(br->ageing_time);
+ 	u32 stp_enabled = br->stp_enabled;
+ 	u16 priority = (br->bridge_id.prio[0] << 8) | br->bridge_id.prio[1];
+ 	u8 vlan_enabled = br_vlan_enabled(br);
+ 	u64 clockval;
+ 
+ 	clockval = br_timer_value(&br->hello_timer);
+ 	if (nla_put_u64_64bit(skb, IFLA_BR_HELLO_TIMER, clockval, IFLA_BR_PAD))
+ 		return -EMSGSIZE;
+ 	clockval = br_timer_value(&br->tcn_timer);
+ 	if (nla_put_u64_64bit(skb, IFLA_BR_TCN_TIMER, clockval, IFLA_BR_PAD))
+ 		return -EMSGSIZE;
+ 	clockval = br_timer_value(&br->topology_change_timer);
+ 	if (nla_put_u64_64bit(skb, IFLA_BR_TOPOLOGY_CHANGE_TIMER, clockval,
+ 			      IFLA_BR_PAD))
+ 		return -EMSGSIZE;
+ 	clockval = br_timer_value(&br->gc_timer);
+ 	if (nla_put_u64_64bit(skb, IFLA_BR_GC_TIMER, clockval, IFLA_BR_PAD))
+ 		return -EMSGSIZE;
+ 
+ 	if (nla_put_u32(skb, IFLA_BR_FORWARD_DELAY, forward_delay) ||
+ 	    nla_put_u32(skb, IFLA_BR_HELLO_TIME, hello_time) ||
+ 	    nla_put_u32(skb, IFLA_BR_MAX_AGE, age_time) ||
+ 	    nla_put_u32(skb, IFLA_BR_AGEING_TIME, ageing_time) ||
+ 	    nla_put_u32(skb, IFLA_BR_STP_STATE, stp_enabled) ||
+ 	    nla_put_u16(skb, IFLA_BR_PRIORITY, priority) ||
+ 	    nla_put_u8(skb, IFLA_BR_VLAN_FILTERING, vlan_enabled) ||
+ 	    nla_put_u16(skb, IFLA_BR_GROUP_FWD_MASK, br->group_fwd_mask) ||
+ 	    nla_put(skb, IFLA_BR_BRIDGE_ID, sizeof(struct ifla_bridge_id),
+ 		    &br->bridge_id) ||
+ 	    nla_put(skb, IFLA_BR_ROOT_ID, sizeof(struct ifla_bridge_id),
+ 		    &br->designated_root) ||
+ 	    nla_put_u16(skb, IFLA_BR_ROOT_PORT, br->root_port) ||
+ 	    nla_put_u32(skb, IFLA_BR_ROOT_PATH_COST, br->root_path_cost) ||
+ 	    nla_put_u8(skb, IFLA_BR_TOPOLOGY_CHANGE, br->topology_change) ||
+ 	    nla_put_u8(skb, IFLA_BR_TOPOLOGY_CHANGE_DETECTED,
+ 		       br->topology_change_detected) ||
+ 	    nla_put(skb, IFLA_BR_GROUP_ADDR, ETH_ALEN, br->group_addr))
+ 		return -EMSGSIZE;
+ 
+ #ifdef CONFIG_BRIDGE_VLAN_FILTERING
+ 	if (nla_put_be16(skb, IFLA_BR_VLAN_PROTOCOL, br->vlan_proto) ||
+ 	    nla_put_u16(skb, IFLA_BR_VLAN_DEFAULT_PVID, br->default_pvid) ||
+ 	    nla_put_u8(skb, IFLA_BR_VLAN_STATS_ENABLED, br->vlan_stats_enabled))
+ 		return -EMSGSIZE;
+ #endif
+ #ifdef CONFIG_BRIDGE_IGMP_SNOOPING
+ 	if (nla_put_u8(skb, IFLA_BR_MCAST_ROUTER, br->multicast_router) ||
+ 	    nla_put_u8(skb, IFLA_BR_MCAST_SNOOPING, !br->multicast_disabled) ||
+ 	    nla_put_u8(skb, IFLA_BR_MCAST_QUERY_USE_IFADDR,
+ 		       br->multicast_query_use_ifaddr) ||
+ 	    nla_put_u8(skb, IFLA_BR_MCAST_QUERIER, br->multicast_querier) ||
+ 	    nla_put_u8(skb, IFLA_BR_MCAST_STATS_ENABLED,
+ 		       br->multicast_stats_enabled) ||
+ 	    nla_put_u32(skb, IFLA_BR_MCAST_HASH_ELASTICITY,
+ 			br->hash_elasticity) ||
+ 	    nla_put_u32(skb, IFLA_BR_MCAST_HASH_MAX, br->hash_max) ||
+ 	    nla_put_u32(skb, IFLA_BR_MCAST_LAST_MEMBER_CNT,
+ 			br->multicast_last_member_count) ||
+ 	    nla_put_u32(skb, IFLA_BR_MCAST_STARTUP_QUERY_CNT,
+ 			br->multicast_startup_query_count))
+ 		return -EMSGSIZE;
+ 
+ 	clockval = jiffies_to_clock_t(br->multicast_last_member_interval);
+ 	if (nla_put_u64_64bit(skb, IFLA_BR_MCAST_LAST_MEMBER_INTVL, clockval,
+ 			      IFLA_BR_PAD))
+ 		return -EMSGSIZE;
+ 	clockval = jiffies_to_clock_t(br->multicast_membership_interval);
+ 	if (nla_put_u64_64bit(skb, IFLA_BR_MCAST_MEMBERSHIP_INTVL, clockval,
+ 			      IFLA_BR_PAD))
+ 		return -EMSGSIZE;
+ 	clockval = jiffies_to_clock_t(br->multicast_querier_interval);
+ 	if (nla_put_u64_64bit(skb, IFLA_BR_MCAST_QUERIER_INTVL, clockval,
+ 			      IFLA_BR_PAD))
+ 		return -EMSGSIZE;
+ 	clockval = jiffies_to_clock_t(br->multicast_query_interval);
+ 	if (nla_put_u64_64bit(skb, IFLA_BR_MCAST_QUERY_INTVL, clockval,
+ 			      IFLA_BR_PAD))
+ 		return -EMSGSIZE;
+ 	clockval = jiffies_to_clock_t(br->multicast_query_response_interval);
+ 	if (nla_put_u64_64bit(skb, IFLA_BR_MCAST_QUERY_RESPONSE_INTVL, clockval,
+ 			      IFLA_BR_PAD))
+ 		return -EMSGSIZE;
+ 	clockval = jiffies_to_clock_t(br->multicast_startup_query_interval);
+ 	if (nla_put_u64_64bit(skb, IFLA_BR_MCAST_STARTUP_QUERY_INTVL, clockval,
+ 			      IFLA_BR_PAD))
+ 		return -EMSGSIZE;
+ #endif
+ #if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)
+ 	if (nla_put_u8(skb, IFLA_BR_NF_CALL_IPTABLES,
+ 		       br->nf_call_iptables ? 1 : 0) ||
+ 	    nla_put_u8(skb, IFLA_BR_NF_CALL_IP6TABLES,
+ 		       br->nf_call_ip6tables ? 1 : 0) ||
+ 	    nla_put_u8(skb, IFLA_BR_NF_CALL_ARPTABLES,
+ 		       br->nf_call_arptables ? 1 : 0))
+ 		return -EMSGSIZE;
+ #endif
+ 
+ 	return 0;
+ }
+ 
+ static size_t bridge_get_linkxstats_size(const struct net_device *dev)
+ {
+ 	struct net_bridge *br = netdev_priv(dev);
+ 	struct net_bridge_vlan_group *vg;
+ 	struct net_bridge_vlan *v;
+ 	int numvls = 0;
+ 
+ 	vg = br_vlan_group(br);
+ 	if (vg) {
+ 		/* we need to count all, even placeholder entries */
+ 		list_for_each_entry(v, &vg->vlan_list, vlist)
+ 			numvls++;
+ 	}
+ 
+ 	return numvls * nla_total_size(sizeof(struct bridge_vlan_xstats)) +
+ 	       nla_total_size(sizeof(struct br_mcast_stats)) +
+ 	       nla_total_size(0);
+ }
+ 
+ static size_t brport_get_linkxstats_size(const struct net_device *dev)
+ {
+ 	return nla_total_size(sizeof(struct br_mcast_stats)) +
+ 	       nla_total_size(0);
+ }
+ 
+ static size_t br_get_linkxstats_size(const struct net_device *dev, int attr)
+ {
+ 	size_t retsize = 0;
+ 
+ 	switch (attr) {
+ 	case IFLA_STATS_LINK_XSTATS:
+ 		retsize = bridge_get_linkxstats_size(dev);
+ 		break;
+ 	case IFLA_STATS_LINK_XSTATS_SLAVE:
+ 		retsize = brport_get_linkxstats_size(dev);
+ 		break;
+ 	}
+ 
+ 	return retsize;
+ }
+ 
+ static int bridge_fill_linkxstats(struct sk_buff *skb,
+ 				  const struct net_device *dev,
+ 				  int *prividx)
+ {
+ 	struct net_bridge *br = netdev_priv(dev);
+ 	struct nlattr *nla __maybe_unused;
+ 	struct net_bridge_vlan_group *vg;
+ 	struct net_bridge_vlan *v;
+ 	struct nlattr *nest;
+ 	int vl_idx = 0;
+ 
+ 	nest = nla_nest_start(skb, LINK_XSTATS_TYPE_BRIDGE);
+ 	if (!nest)
+ 		return -EMSGSIZE;
+ 
+ 	vg = br_vlan_group(br);
+ 	if (vg) {
+ 		list_for_each_entry(v, &vg->vlan_list, vlist) {
+ 			struct bridge_vlan_xstats vxi;
+ 			struct br_vlan_stats stats;
+ 
+ 			if (++vl_idx < *prividx)
+ 				continue;
+ 			memset(&vxi, 0, sizeof(vxi));
+ 			vxi.vid = v->vid;
+ 			br_vlan_get_stats(v, &stats);
+ 			vxi.rx_bytes = stats.rx_bytes;
+ 			vxi.rx_packets = stats.rx_packets;
+ 			vxi.tx_bytes = stats.tx_bytes;
+ 			vxi.tx_packets = stats.tx_packets;
+ 
+ 			if (nla_put(skb, BRIDGE_XSTATS_VLAN, sizeof(vxi), &vxi))
+ 				goto nla_put_failure;
+ 		}
+ 	}
+ 
+ #ifdef CONFIG_BRIDGE_IGMP_SNOOPING
+ 	if (++vl_idx >= *prividx) {
+ 		nla = nla_reserve_64bit(skb, BRIDGE_XSTATS_MCAST,
+ 					sizeof(struct br_mcast_stats),
+ 					BRIDGE_XSTATS_PAD);
+ 		if (!nla)
+ 			goto nla_put_failure;
+ 		br_multicast_get_stats(br, NULL, nla_data(nla));
+ 	}
+ #endif
+ 	nla_nest_end(skb, nest);
+ 	*prividx = 0;
+ 
+ 	return 0;
+ 
+ nla_put_failure:
+ 	nla_nest_end(skb, nest);
+ 	*prividx = vl_idx;
+ 
+ 	return -EMSGSIZE;
+ }
+ 
+ static int brport_fill_linkxstats(struct sk_buff *skb,
+ 				  const struct net_device *dev,
+ 				  int *prividx)
+ {
+ 	struct net_bridge_port *p = br_port_get_rtnl(dev);
+ 	struct nlattr *nla __maybe_unused;
+ 	struct nlattr *nest;
+ 
+ 	if (!p)
+ 		return 0;
+ 
+ 	nest = nla_nest_start(skb, LINK_XSTATS_TYPE_BRIDGE);
+ 	if (!nest)
+ 		return -EMSGSIZE;
+ #ifdef CONFIG_BRIDGE_IGMP_SNOOPING
+ 	nla = nla_reserve_64bit(skb, BRIDGE_XSTATS_MCAST,
+ 				sizeof(struct br_mcast_stats),
+ 				BRIDGE_XSTATS_PAD);
+ 	if (!nla) {
+ 		nla_nest_end(skb, nest);
+ 		return -EMSGSIZE;
+ 	}
+ 	br_multicast_get_stats(p->br, p, nla_data(nla));
+ #endif
+ 	nla_nest_end(skb, nest);
+ 
+ 	return 0;
+ }
+ 
+ static int br_fill_linkxstats(struct sk_buff *skb, const struct net_device *dev,
+ 			      int *prividx, int attr)
+ {
+ 	int ret = -EINVAL;
+ 
+ 	switch (attr) {
+ 	case IFLA_STATS_LINK_XSTATS:
+ 		ret = bridge_fill_linkxstats(skb, dev, prividx);
+ 		break;
+ 	case IFLA_STATS_LINK_XSTATS_SLAVE:
+ 		ret = brport_fill_linkxstats(skb, dev, prividx);
+ 		break;
+ 	}
+ 
+ 	return ret;
+ }
+ 
+ static struct rtnl_af_ops br_af_ops __read_mostly = {
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
  	.family			= AF_BRIDGE,
 -	.get_link_af_size	= br_get_link_af_size_filtered,
 +	.get_link_af_size	= br_get_link_af_size,
  };
  
  struct rtnl_link_ops br_link_ops __read_mostly = {
diff --cc net/bridge/br_private.h
index 1e1daa30e106,4dc851166ad1..000000000000
--- a/net/bridge/br_private.h
+++ b/net/bridge/br_private.h
@@@ -69,19 -69,85 +69,34 @@@ struct bridge_mcast_other_query 
  	struct timer_list		timer;
  	unsigned long			delay_time;
  };
++<<<<<<< HEAD
++=======
+ 
+ /* selected querier */
+ struct bridge_mcast_querier {
+ 	struct br_ip addr;
+ 	struct net_bridge_port __rcu	*port;
+ };
+ 
+ /* IGMP/MLD statistics */
+ struct bridge_mcast_stats {
+ 	struct br_mcast_stats mstats;
+ 	struct u64_stats_sync syncp;
+ };
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
  #endif
  
 -struct br_vlan_stats {
 -	u64 rx_bytes;
 -	u64 rx_packets;
 -	u64 tx_bytes;
 -	u64 tx_packets;
 -	struct u64_stats_sync syncp;
 -};
 -
 -/**
 - * struct net_bridge_vlan - per-vlan entry
 - *
 - * @vnode: rhashtable member
 - * @vid: VLAN id
 - * @flags: bridge vlan flags
 - * @stats: per-cpu VLAN statistics
 - * @br: if MASTER flag set, this points to a bridge struct
 - * @port: if MASTER flag unset, this points to a port struct
 - * @refcnt: if MASTER flag set, this is bumped for each port referencing it
 - * @brvlan: if MASTER flag unset, this points to the global per-VLAN context
 - *          for this VLAN entry
 - * @vlist: sorted list of VLAN entries
 - * @rcu: used for entry destruction
 - *
 - * This structure is shared between the global per-VLAN entries contained in
 - * the bridge rhashtable and the local per-port per-VLAN entries contained in
 - * the port's rhashtable. The union entries should be interpreted depending on
 - * the entry flags that are set.
 - */
 -struct net_bridge_vlan {
 -	struct rhash_head		vnode;
 -	u16				vid;
 -	u16				flags;
 -	struct br_vlan_stats __percpu	*stats;
 -	union {
 -		struct net_bridge	*br;
 -		struct net_bridge_port	*port;
 -	};
 +struct net_port_vlans {
 +	u16				port_idx;
 +	u16				pvid;
  	union {
 -		atomic_t		refcnt;
 -		struct net_bridge_vlan	*brvlan;
 -	};
 -	struct list_head		vlist;
 -
 +		struct net_bridge_port		*port;
 +		struct net_bridge		*br;
 +	}				parent;
  	struct rcu_head			rcu;
 -};
 -
 -/**
 - * struct net_bridge_vlan_group
 - *
 - * @vlan_hash: VLAN entry rhashtable
 - * @vlan_list: sorted VLAN entry list
 - * @num_vlans: number of total VLAN entries
 - * @pvid: PVID VLAN id
 - *
 - * IMPORTANT: Be careful when checking if there're VLAN entries using list
 - *            primitives because the bridge can have entries in its list which
 - *            are just for global context but not for filtering, i.e. they have
 - *            the master flag set but not the brentry flag. If you have to check
 - *            if there're "real" entries in the bridge please test @num_vlans
 - */
 -struct net_bridge_vlan_group {
 -	struct rhashtable		vlan_hash;
 -	struct list_head		vlan_list;
 +	unsigned long			vlan_bitmap[BR_VLAN_BITMAP_LEN];
 +	unsigned long			untagged_bitmap[BR_VLAN_BITMAP_LEN];
  	u16				num_vlans;
 -	u16				pvid;
  };
  
  struct net_bridge_fdb_entry
@@@ -271,6 -344,8 +288,11 @@@ struct net_bridg
  	struct timer_list		multicast_router_timer;
  	struct bridge_mcast_other_query	ip4_other_query;
  	struct bridge_mcast_own_query	ip4_own_query;
++<<<<<<< HEAD
++=======
+ 	struct bridge_mcast_querier	ip4_querier;
+ 	struct bridge_mcast_stats	__percpu *mcast_stats;
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
  #if IS_ENABLED(CONFIG_IPV6)
  	struct bridge_mcast_other_query	ip6_other_query;
  	struct bridge_mcast_own_query	ip6_own_query;
@@@ -444,8 -551,8 +466,13 @@@ extern unsigned int br_mdb_rehash_seq
  int br_multicast_rcv(struct net_bridge *br, struct net_bridge_port *port,
  		     struct sk_buff *skb, u16 vid);
  struct net_bridge_mdb_entry *br_mdb_get(struct net_bridge *br,
++<<<<<<< HEAD
 +				        struct sk_buff *skb, u16 vid);
 +void br_multicast_add_port(struct net_bridge_port *port);
++=======
+ 					struct sk_buff *skb, u16 vid);
+ int br_multicast_add_port(struct net_bridge_port *port);
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
  void br_multicast_del_port(struct net_bridge_port *port);
  void br_multicast_enable_port(struct net_bridge_port *port);
  void br_multicast_disable_port(struct net_bridge_port *port);
@@@ -475,7 -582,15 +502,19 @@@ br_multicast_new_port_group(struct net_
  void br_mdb_init(void);
  void br_mdb_uninit(void);
  void br_mdb_notify(struct net_device *dev, struct net_bridge_port *port,
++<<<<<<< HEAD
 +		   struct br_ip *group, int type);
++=======
+ 		   struct br_ip *group, int type, u8 flags);
+ void br_rtr_notify(struct net_device *dev, struct net_bridge_port *port,
+ 		   int type);
+ void br_multicast_count(struct net_bridge *br, const struct net_bridge_port *p,
+ 			__be16 proto, u8 type, u8 dir);
+ int br_multicast_init_stats(struct net_bridge *br);
+ void br_multicast_get_stats(const struct net_bridge *br,
+ 			    const struct net_bridge_port *p,
+ 			    struct br_mcast_stats *dest);
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
  
  #define mlock_dereference(X, br) \
  	rcu_dereference_protected(X, lockdep_is_held(&br->multicast_lock))
diff --cc net/bridge/br_sysfs_br.c
index 05548fb105c9,e120307c6e36..000000000000
--- a/net/bridge/br_sysfs_br.c
+++ b/net/bridge/br_sysfs_br.c
@@@ -637,12 -617,34 +637,40 @@@ static ssize_t store_multicast_startup_
  {
  	return store_bridge_parm(d, buf, len, set_startup_query_interval);
  }
++<<<<<<< HEAD
 +static DEVICE_ATTR(multicast_startup_query_interval, S_IRUGO | S_IWUSR,
 +		   show_multicast_startup_query_interval,
 +		   store_multicast_startup_query_interval);
++=======
+ static DEVICE_ATTR_RW(multicast_startup_query_interval);
+ 
+ static ssize_t multicast_stats_enabled_show(struct device *d,
+ 					    struct device_attribute *attr,
+ 					    char *buf)
+ {
+ 	struct net_bridge *br = to_bridge(d);
+ 
+ 	return sprintf(buf, "%u\n", br->multicast_stats_enabled);
+ }
+ 
+ static int set_stats_enabled(struct net_bridge *br, unsigned long val)
+ {
+ 	br->multicast_stats_enabled = !!val;
+ 	return 0;
+ }
+ 
+ static ssize_t multicast_stats_enabled_store(struct device *d,
+ 					     struct device_attribute *attr,
+ 					     const char *buf,
+ 					     size_t len)
+ {
+ 	return store_bridge_parm(d, buf, len, set_stats_enabled);
+ }
+ static DEVICE_ATTR_RW(multicast_stats_enabled);
++>>>>>>> 1080ab95e3c7 (net: bridge: add support for IGMP/MLD stats and export them via netlink)
  #endif
  #if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)
 -static ssize_t nf_call_iptables_show(
 +static ssize_t show_nf_call_iptables(
  	struct device *d, struct device_attribute *attr, char *buf)
  {
  	struct net_bridge *br = to_bridge(d);
* Unmerged path include/uapi/linux/if_bridge.h
* Unmerged path include/uapi/linux/if_link.h
diff --git a/net/bridge/br_device.c b/net/bridge/br_device.c
index 59112a1972e0..cc059d8085e7 100644
--- a/net/bridge/br_device.c
+++ b/net/bridge/br_device.c
@@ -104,8 +104,16 @@ static int br_dev_init(struct net_device *dev)
 		return -ENOMEM;
 
 	err = br_vlan_init(br);
-	if (err)
+	if (err) {
 		free_percpu(br->stats);
+		return err;
+	}
+
+	err = br_multicast_init_stats(br);
+	if (err) {
+		free_percpu(br->stats);
+		br_vlan_flush(br);
+	}
 	br_set_lockdep_class(dev);
 
 	return err;
diff --git a/net/bridge/br_forward.c b/net/bridge/br_forward.c
index 20c11b41fe6a..77b66ef19e32 100644
--- a/net/bridge/br_forward.c
+++ b/net/bridge/br_forward.c
@@ -196,8 +196,10 @@ static void br_flood(struct net_bridge *br, struct sk_buff *skb,
 					   struct sk_buff *skb),
 		     bool unicast)
 {
-	struct net_bridge_port *p;
+	u8 igmp_type = br_multicast_igmp_type(skb);
+	__be16 proto = skb->protocol;
 	struct net_bridge_port *prev;
+	struct net_bridge_port *p;
 
 	prev = NULL;
 
@@ -208,6 +210,9 @@ static void br_flood(struct net_bridge *br, struct sk_buff *skb,
 		prev = maybe_deliver(prev, p, skb, __packet_hook);
 		if (IS_ERR(prev))
 			goto out;
+		if (prev == p)
+			br_multicast_count(p->br, p, proto, igmp_type,
+					   BR_MCAST_DIR_TX);
 	}
 
 	if (!prev)
@@ -247,9 +252,12 @@ static void br_multicast_flood(struct net_bridge_mdb_entry *mdst,
 					struct sk_buff *skb))
 {
 	struct net_device *dev = BR_INPUT_SKB_CB(skb)->brdev;
+	u8 igmp_type = br_multicast_igmp_type(skb);
 	struct net_bridge *br = netdev_priv(dev);
 	struct net_bridge_port *prev = NULL;
 	struct net_bridge_port_group *p;
+	__be16 proto = skb->protocol;
+
 	struct hlist_node *rp;
 
 	rp = rcu_dereference(hlist_first_rcu(&br->router_list));
@@ -267,6 +275,9 @@ static void br_multicast_flood(struct net_bridge_mdb_entry *mdst,
 		prev = maybe_deliver(prev, port, skb, __packet_hook);
 		if (IS_ERR(prev))
 			goto out;
+		if (prev == port)
+			br_multicast_count(port->br, port, proto, igmp_type,
+					   BR_MCAST_DIR_TX);
 
 		if ((unsigned long)lport >= (unsigned long)port)
 			p = rcu_dereference(p->next);
diff --git a/net/bridge/br_if.c b/net/bridge/br_if.c
index 9445aee8bbee..5375d883fe0b 100644
--- a/net/bridge/br_if.c
+++ b/net/bridge/br_if.c
@@ -342,8 +342,8 @@ static int find_portno(struct net_bridge *br)
 static struct net_bridge_port *new_nbp(struct net_bridge *br,
 				       struct net_device *dev)
 {
-	int index;
 	struct net_bridge_port *p;
+	int index, err;
 
 	index = find_portno(br);
 	if (index < 0)
@@ -363,7 +363,12 @@ static struct net_bridge_port *new_nbp(struct net_bridge *br,
 	br_init_port(p);
 	br_set_state(p, BR_STATE_DISABLED);
 	br_stp_port_timer_init(p);
-	br_multicast_add_port(p);
+	err = br_multicast_add_port(p);
+	if (err) {
+		dev_put(dev);
+		kfree(p);
+		p = ERR_PTR(err);
+	}
 
 	return p;
 }
diff --git a/net/bridge/br_input.c b/net/bridge/br_input.c
index ddc6cbe6269c..4b7c8f0ad295 100644
--- a/net/bridge/br_input.c
+++ b/net/bridge/br_input.c
@@ -52,6 +52,9 @@ static int br_pass_frame_up(struct sk_buff *skb)
 	skb = br_handle_vlan(br, pv, skb);
 	if (!skb)
 		return NET_RX_DROP;
+	/* update the multicast stats if the packet is IGMP/MLD */
+	br_multicast_count(br, NULL, skb->protocol, br_multicast_igmp_type(skb),
+			   BR_MCAST_DIR_TX);
 
 	return NF_HOOK(NFPROTO_BRIDGE, NF_BR_LOCAL_IN, NULL, skb,
 		       indev, NULL,
* Unmerged path net/bridge/br_multicast.c
* Unmerged path net/bridge/br_netlink.c
* Unmerged path net/bridge/br_private.h
* Unmerged path net/bridge/br_sysfs_br.c
