random: make /dev/urandom scalable for silly userspace programs

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Theodore Ts'o <tytso@mit.edu>
commit 1e7f583af67be4ff091d0aeb863c649efd7a9112
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/1e7f583a.failed

On a system with a 4 socket (NUMA) system where a large number of
application threads were all trying to read from /dev/urandom, this
can result in the system spending 80% of its time contending on the
global urandom spinlock.  The application should have used its own
PRNG, but let's try to help it from running, lemming-like, straight
over the locking cliff.

	Reported-by: Andi Kleen <ak@linux.intel.com>
	Signed-off-by: Theodore Ts'o <tytso@mit.edu>
(cherry picked from commit 1e7f583af67be4ff091d0aeb863c649efd7a9112)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/char/random.c
diff --cc drivers/char/random.c
index 9e6776a12d13,2a30d9718a1b..000000000000
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@@ -406,18 -408,38 +406,50 @@@ static struct poolinfo 
   */
  static DECLARE_WAIT_QUEUE_HEAD(random_read_wait);
  static DECLARE_WAIT_QUEUE_HEAD(random_write_wait);
 -static DECLARE_WAIT_QUEUE_HEAD(urandom_init_wait);
  static struct fasync_struct *fasync;
  
++<<<<<<< HEAD
 +static bool debug;
 +module_param(debug, bool, 0644);
 +#define DEBUG_ENT(fmt, arg...) do { \
 +	if (debug) \
 +		printk(KERN_DEBUG "random %04d %04d %04d: " \
 +		fmt,\
 +		input_pool.entropy_count,\
 +		blocking_pool.entropy_count,\
 +		nonblocking_pool.entropy_count,\
 +		## arg); } while (0)
++=======
+ static DEFINE_SPINLOCK(random_ready_list_lock);
+ static LIST_HEAD(random_ready_list);
+ 
+ struct crng_state {
+ 	__u32		state[16];
+ 	unsigned long	init_time;
+ 	spinlock_t	lock;
+ };
+ 
+ struct crng_state primary_crng = {
+ 	.lock = __SPIN_LOCK_UNLOCKED(primary_crng.lock),
+ };
+ 
+ /*
+  * crng_init =  0 --> Uninitialized
+  *		1 --> Initialized
+  *		2 --> Initialized from input_pool
+  *
+  * crng_init is protected by primary_crng->lock, and only increases
+  * its value (from 0->1->2).
+  */
+ static int crng_init = 0;
+ #define crng_ready() (likely(crng_init > 0))
+ static int crng_init_cnt = 0;
+ #define CRNG_INIT_CNT_THRESH (2*CHACHA20_KEY_SIZE)
+ static void _extract_crng(struct crng_state *crng,
+ 			  __u8 out[CHACHA20_BLOCK_SIZE]);
+ static void extract_crng(__u8 out[CHACHA20_BLOCK_SIZE]);
+ static void process_random_ready_list(void);
++>>>>>>> 1e7f583af67b (random: make /dev/urandom scalable for silly userspace programs)
  
  /**********************************************************************
   *
@@@ -695,6 -750,182 +727,185 @@@ static void credit_entropy_bits_safe(st
  
  /*********************************************************************
   *
++<<<<<<< HEAD
++=======
+  * CRNG using CHACHA20
+  *
+  *********************************************************************/
+ 
+ #define CRNG_RESEED_INTERVAL (300*HZ)
+ 
+ static DECLARE_WAIT_QUEUE_HEAD(crng_init_wait);
+ 
+ #ifdef CONFIG_NUMA
+ /*
+  * Hack to deal with crazy userspace progams when they are all trying
+  * to access /dev/urandom in parallel.  The programs are almost
+  * certainly doing something terribly wrong, but we'll work around
+  * their brain damage.
+  */
+ static struct crng_state **crng_node_pool __read_mostly;
+ #endif
+ 
+ static void crng_initialize(struct crng_state *crng)
+ {
+ 	int		i;
+ 	unsigned long	rv;
+ 
+ 	memcpy(&crng->state[0], "expand 32-byte k", 16);
+ 	if (crng == &primary_crng)
+ 		_extract_entropy(&input_pool, &crng->state[4],
+ 				 sizeof(__u32) * 12, 0);
+ 	else
+ 		get_random_bytes(&crng->state[4], sizeof(__u32) * 12);
+ 	for (i = 4; i < 16; i++) {
+ 		if (!arch_get_random_seed_long(&rv) &&
+ 		    !arch_get_random_long(&rv))
+ 			rv = random_get_entropy();
+ 		crng->state[i] ^= rv;
+ 	}
+ 	crng->init_time = jiffies - CRNG_RESEED_INTERVAL - 1;
+ }
+ 
+ static int crng_fast_load(const char *cp, size_t len)
+ {
+ 	unsigned long flags;
+ 	char *p;
+ 
+ 	if (!spin_trylock_irqsave(&primary_crng.lock, flags))
+ 		return 0;
+ 	if (crng_ready()) {
+ 		spin_unlock_irqrestore(&primary_crng.lock, flags);
+ 		return 0;
+ 	}
+ 	p = (unsigned char *) &primary_crng.state[4];
+ 	while (len > 0 && crng_init_cnt < CRNG_INIT_CNT_THRESH) {
+ 		p[crng_init_cnt % CHACHA20_KEY_SIZE] ^= *cp;
+ 		cp++; crng_init_cnt++; len--;
+ 	}
+ 	if (crng_init_cnt >= CRNG_INIT_CNT_THRESH) {
+ 		crng_init = 1;
+ 		wake_up_interruptible(&crng_init_wait);
+ 		pr_notice("random: fast init done\n");
+ 	}
+ 	spin_unlock_irqrestore(&primary_crng.lock, flags);
+ 	return 1;
+ }
+ 
+ static void crng_reseed(struct crng_state *crng, struct entropy_store *r)
+ {
+ 	unsigned long	flags;
+ 	int		i, num;
+ 	union {
+ 		__u8	block[CHACHA20_BLOCK_SIZE];
+ 		__u32	key[8];
+ 	} buf;
+ 
+ 	if (r) {
+ 		num = extract_entropy(r, &buf, 32, 16, 0);
+ 		if (num == 0)
+ 			return;
+ 	} else
+ 		_extract_crng(&primary_crng, buf.block);
+ 	spin_lock_irqsave(&primary_crng.lock, flags);
+ 	for (i = 0; i < 8; i++) {
+ 		unsigned long	rv;
+ 		if (!arch_get_random_seed_long(&rv) &&
+ 		    !arch_get_random_long(&rv))
+ 			rv = random_get_entropy();
+ 		crng->state[i+4] ^= buf.key[i] ^ rv;
+ 	}
+ 	memzero_explicit(&buf, sizeof(buf));
+ 	crng->init_time = jiffies;
+ 	if (crng == &primary_crng && crng_init < 2) {
+ 		crng_init = 2;
+ 		process_random_ready_list();
+ 		wake_up_interruptible(&crng_init_wait);
+ 		pr_notice("random: crng init done\n");
+ 	}
+ 	spin_unlock_irqrestore(&primary_crng.lock, flags);
+ }
+ 
+ static inline void maybe_reseed_primary_crng(void)
+ {
+ 	if (crng_init > 2 &&
+ 	    time_after(jiffies, primary_crng.init_time + CRNG_RESEED_INTERVAL))
+ 		crng_reseed(&primary_crng, &input_pool);
+ }
+ 
+ static inline void crng_wait_ready(void)
+ {
+ 	wait_event_interruptible(crng_init_wait, crng_ready());
+ }
+ 
+ static void _extract_crng(struct crng_state *crng,
+ 			  __u8 out[CHACHA20_BLOCK_SIZE])
+ {
+ 	unsigned long v, flags;
+ 
+ 	if (crng_init > 1 &&
+ 	    time_after(jiffies, crng->init_time + CRNG_RESEED_INTERVAL))
+ 		crng_reseed(crng, crng == &primary_crng ? &input_pool : NULL);
+ 	spin_lock_irqsave(&crng->lock, flags);
+ 	if (arch_get_random_long(&v))
+ 		crng->state[14] ^= v;
+ 	chacha20_block(&crng->state[0], out);
+ 	if (crng->state[12] == 0)
+ 		crng->state[13]++;
+ 	spin_unlock_irqrestore(&crng->lock, flags);
+ }
+ 
+ static void extract_crng(__u8 out[CHACHA20_BLOCK_SIZE])
+ {
+ 	struct crng_state *crng = NULL;
+ 
+ #ifdef CONFIG_NUMA
+ 	if (crng_node_pool)
+ 		crng = crng_node_pool[numa_node_id()];
+ 	if (crng == NULL)
+ #endif
+ 		crng = &primary_crng;
+ 	_extract_crng(crng, out);
+ }
+ 
+ static ssize_t extract_crng_user(void __user *buf, size_t nbytes)
+ {
+ 	ssize_t ret = 0, i;
+ 	__u8 tmp[CHACHA20_BLOCK_SIZE];
+ 	int large_request = (nbytes > 256);
+ 
+ 	while (nbytes) {
+ 		if (large_request && need_resched()) {
+ 			if (signal_pending(current)) {
+ 				if (ret == 0)
+ 					ret = -ERESTARTSYS;
+ 				break;
+ 			}
+ 			schedule();
+ 		}
+ 
+ 		extract_crng(tmp);
+ 		i = min_t(int, nbytes, CHACHA20_BLOCK_SIZE);
+ 		if (copy_to_user(buf, tmp, i)) {
+ 			ret = -EFAULT;
+ 			break;
+ 		}
+ 
+ 		nbytes -= i;
+ 		buf += i;
+ 		ret += i;
+ 	}
+ 
+ 	/* Wipe data just written to memory */
+ 	memzero_explicit(tmp, sizeof(tmp));
+ 
+ 	return ret;
+ }
+ 
+ 
+ /*********************************************************************
+  *
++>>>>>>> 1e7f583af67b (random: make /dev/urandom scalable for silly userspace programs)
   * Entropy input management
   *
   *********************************************************************/
@@@ -1284,9 -1607,31 +1495,35 @@@ static void init_std_data(struct entrop
   */
  static int rand_initialize(void)
  {
+ #ifdef CONFIG_NUMA
+ 	int i;
+ 	int num_nodes = num_possible_nodes();
+ 	struct crng_state *crng;
+ 	struct crng_state **pool;
+ #endif
+ 
  	init_std_data(&input_pool);
  	init_std_data(&blocking_pool);
++<<<<<<< HEAD
 +	init_std_data(&nonblocking_pool);
++=======
+ 	crng_initialize(&primary_crng);
+ 
+ #ifdef CONFIG_NUMA
+ 	pool = kmalloc(num_nodes * sizeof(void *),
+ 		       GFP_KERNEL|__GFP_NOFAIL|__GFP_ZERO);
+ 	for (i=0; i < num_nodes; i++) {
+ 		crng = kmalloc_node(sizeof(struct crng_state),
+ 				    GFP_KERNEL | __GFP_NOFAIL, i);
+ 		spin_lock_init(&crng->lock);
+ 		crng_initialize(crng);
+ 		pool[i] = crng;
+ 
+ 	}
+ 	mb();
+ 	crng_node_pool = pool;
+ #endif
++>>>>>>> 1e7f583af67b (random: make /dev/urandom scalable for silly userspace programs)
  	return 0;
  }
  early_initcall(rand_initialize);
* Unmerged path drivers/char/random.c
