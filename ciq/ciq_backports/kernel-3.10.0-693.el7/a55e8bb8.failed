xen-netfront: refactor making Tx requests

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author David Vrabel <david.vrabel@citrix.com>
commit a55e8bb8fb89c90b33791861e59859a39e57ba30
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/a55e8bb8.failed

Eliminate all the duplicate code for making Tx requests by
consolidating them into a single xennet_make_one_txreq() function.

xennet_make_one_txreq() and xennet_make_txreqs() work with pages and
offsets so it will be easier to make netfront handle highmem frags in
the future.

	Signed-off-by: David Vrabel <david.vrabel@citrix.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit a55e8bb8fb89c90b33791861e59859a39e57ba30)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/xen-netfront.c
diff --cc drivers/net/xen-netfront.c
index 8896052a2ee0,01a4350eb313..000000000000
--- a/drivers/net/xen-netfront.c
+++ b/drivers/net/xen-netfront.c
@@@ -412,108 -413,64 +412,152 @@@ static void xennet_tx_buf_gc(struct net
  		 * data is outstanding: in such cases notification from Xen is
  		 * likely to be the only kick that we'll get.
  		 */
 -		queue->tx.sring->rsp_event =
 -			prod + ((queue->tx.sring->req_prod - prod) >> 1) + 1;
 +		np->tx.sring->rsp_event =
 +			prod + ((np->tx.sring->req_prod - prod) >> 1) + 1;
  		mb();		/* update shared area */
 -	} while ((cons == prod) && (prod != queue->tx.sring->rsp_prod));
 +	} while ((cons == prod) && (prod != np->tx.sring->rsp_prod));
  
 -	xennet_maybe_wake_tx(queue);
 +	xennet_maybe_wake_tx(dev);
  }
  
++<<<<<<< HEAD
 +static void xennet_make_frags(struct sk_buff *skb, struct net_device *dev,
 +			      struct xen_netif_tx_request *tx)
 +{
 +	struct netfront_info *np = netdev_priv(dev);
 +	char *data = skb->data;
 +	unsigned long mfn;
 +	RING_IDX prod = np->tx.req_prod_pvt;
 +	int frags = skb_shinfo(skb)->nr_frags;
 +	unsigned int offset = offset_in_page(data);
 +	unsigned int len = skb_headlen(skb);
++=======
+ static struct xen_netif_tx_request *xennet_make_one_txreq(
+ 	struct netfront_queue *queue, struct sk_buff *skb,
+ 	struct page *page, unsigned int offset, unsigned int len)
+ {
++>>>>>>> a55e8bb8fb89 (xen-netfront: refactor making Tx requests)
  	unsigned int id;
+ 	struct xen_netif_tx_request *tx;
  	grant_ref_t ref;
- 	int i;
  
- 	/* While the header overlaps a page boundary (including being
- 	   larger than a page), split it it into page-sized chunks. */
- 	while (len > PAGE_SIZE - offset) {
- 		tx->size = PAGE_SIZE - offset;
+ 	len = min_t(unsigned int, PAGE_SIZE - offset, len);
+ 
+ 	id = get_id_from_freelist(&queue->tx_skb_freelist, queue->tx_skbs);
+ 	tx = RING_GET_REQUEST(&queue->tx, queue->tx.req_prod_pvt++);
+ 	ref = gnttab_claim_grant_reference(&queue->gref_tx_head);
+ 	BUG_ON((signed short)ref < 0);
+ 
+ 	gnttab_grant_foreign_access_ref(ref, queue->info->xbdev->otherend_id,
+ 					page_to_mfn(page), GNTMAP_readonly);
+ 
+ 	queue->tx_skbs[id].skb = skb;
+ 	queue->grant_tx_page[id] = page;
+ 	queue->grant_tx_ref[id] = ref;
+ 
+ 	tx->id = id;
+ 	tx->gref = ref;
+ 	tx->offset = offset;
+ 	tx->size = len;
+ 	tx->flags = 0;
+ 
+ 	return tx;
+ }
+ 
+ static struct xen_netif_tx_request *xennet_make_txreqs(
+ 	struct netfront_queue *queue, struct xen_netif_tx_request *tx,
+ 	struct sk_buff *skb, struct page *page,
+ 	unsigned int offset, unsigned int len)
+ {
+ 	/* Skip unused frames from start of page */
+ 	page += offset >> PAGE_SHIFT;
+ 	offset &= ~PAGE_MASK;
+ 
+ 	while (len) {
  		tx->flags |= XEN_NETTXF_more_data;
- 		len -= tx->size;
- 		data += tx->size;
+ 		tx = xennet_make_one_txreq(queue, skb_get(skb),
+ 					   page, offset, len);
+ 		page++;
  		offset = 0;
++<<<<<<< HEAD
 +
 +		id = get_id_from_freelist(&np->tx_skb_freelist, np->tx_skbs);
 +		np->tx_skbs[id].skb = skb_get(skb);
 +		tx = RING_GET_REQUEST(&np->tx, prod++);
 +		tx->id = id;
 +		ref = gnttab_claim_grant_reference(&np->gref_tx_head);
 +		BUG_ON((signed short)ref < 0);
 +
 +		mfn = virt_to_mfn(data);
 +		gnttab_grant_foreign_access_ref(ref, np->xbdev->otherend_id,
 +						mfn, GNTMAP_readonly);
 +
 +		np->grant_tx_page[id] = virt_to_page(data);
 +		tx->gref = np->grant_tx_ref[id] = ref;
 +		tx->offset = offset;
 +		tx->size = len;
 +		tx->flags = 0;
 +	}
 +
 +	/* Grant backend access to each skb fragment page. */
 +	for (i = 0; i < frags; i++) {
 +		skb_frag_t *frag = skb_shinfo(skb)->frags + i;
 +		struct page *page = skb_frag_page(frag);
 +
 +		len = skb_frag_size(frag);
 +		offset = frag->page_offset;
 +
 +		/* Skip unused frames from start of page */
 +		page += offset >> PAGE_SHIFT;
 +		offset &= ~PAGE_MASK;
 +
 +		while (len > 0) {
 +			unsigned long bytes;
 +
 +			bytes = PAGE_SIZE - offset;
 +			if (bytes > len)
 +				bytes = len;
 +
 +			tx->flags |= XEN_NETTXF_more_data;
 +
 +			id = get_id_from_freelist(&np->tx_skb_freelist,
 +						  np->tx_skbs);
 +			np->tx_skbs[id].skb = skb_get(skb);
 +			tx = RING_GET_REQUEST(&np->tx, prod++);
 +			tx->id = id;
 +			ref = gnttab_claim_grant_reference(&np->gref_tx_head);
 +			BUG_ON((signed short)ref < 0);
 +
 +			mfn = pfn_to_mfn(page_to_pfn(page));
 +			gnttab_grant_foreign_access_ref(ref,
 +							np->xbdev->otherend_id,
 +							mfn, GNTMAP_readonly);
 +
 +			np->grant_tx_page[id] = page;
 +			tx->gref = np->grant_tx_ref[id] = ref;
 +			tx->offset = offset;
 +			tx->size = bytes;
 +			tx->flags = 0;
 +
 +			offset += bytes;
 +			len -= bytes;
 +
 +			/* Next frame */
 +			if (offset == PAGE_SIZE && len) {
 +				BUG_ON(!PageCompound(page));
 +				page++;
 +				offset = 0;
 +			}
 +		}
 +	}
 +
 +	np->tx.req_prod_pvt = prod;
++=======
+ 		len -= tx->size;
+ 	}
+ 
+ 	return tx;
++>>>>>>> a55e8bb8fb89 (xen-netfront: refactor making Tx requests)
  }
  
  /*
@@@ -541,21 -498,46 +585,18 @@@ static int xennet_count_skb_slots(struc
  	return pages;
  }
  
 -static u16 xennet_select_queue(struct net_device *dev, struct sk_buff *skb,
 -			       void *accel_priv, select_queue_fallback_t fallback)
 -{
 -	unsigned int num_queues = dev->real_num_tx_queues;
 -	u32 hash;
 -	u16 queue_idx;
 -
 -	/* First, check if there is only one queue */
 -	if (num_queues == 1) {
 -		queue_idx = 0;
 -	} else {
 -		hash = skb_get_hash(skb);
 -		queue_idx = hash % num_queues;
 -	}
 -
 -	return queue_idx;
 -}
 -
  static int xennet_start_xmit(struct sk_buff *skb, struct net_device *dev)
  {
- 	unsigned short id;
  	struct netfront_info *np = netdev_priv(dev);
  	struct netfront_stats *stats = this_cpu_ptr(np->stats);
- 	struct xen_netif_tx_request *tx;
- 	char *data = skb->data;
- 	RING_IDX i;
- 	grant_ref_t ref;
- 	unsigned long mfn;
+ 	struct xen_netif_tx_request *tx, *first_tx;
+ 	unsigned int i;
  	int notify;
  	int slots;
- 	unsigned int offset = offset_in_page(data);
- 	unsigned int len = skb_headlen(skb);
+ 	struct page *page;
+ 	unsigned int offset;
+ 	unsigned int len;
  	unsigned long flags;
 -	struct netfront_queue *queue = NULL;
 -	unsigned int num_queues = dev->real_num_tx_queues;
 -	u16 queue_index;
 -
 -	/* Drop the packet if no queues are set up */
 -	if (num_queues < 1)
 -		goto drop;
 -	/* Determine which queue to transmit this SKB on */
 -	queue_index = skb_get_queue_mapping(skb);
 -	queue = &np->queues[queue_index];
  
  	/* If skb->len is too big for wire format, drop skb and alert
  	 * user about misconfiguration.
@@@ -573,12 -555,13 +614,17 @@@
  				    slots, skb->len);
  		if (skb_linearize(skb))
  			goto drop;
- 		data = skb->data;
- 		offset = offset_in_page(data);
- 		len = skb_headlen(skb);
  	}
  
++<<<<<<< HEAD
 +	spin_lock_irqsave(&np->tx_lock, flags);
++=======
+ 	page = virt_to_page(skb->data);
+ 	offset = offset_in_page(skb->data);
+ 	len = skb_headlen(skb);
+ 
+ 	spin_lock_irqsave(&queue->tx_lock, flags);
++>>>>>>> a55e8bb8fb89 (xen-netfront: refactor making Tx requests)
  
  	if (unlikely(!netif_carrier_ok(dev) ||
  		     (slots > 1 && !xennet_can_sg(dev)) ||
@@@ -587,25 -570,13 +633,35 @@@
  		goto drop;
  	}
  
++<<<<<<< HEAD
 +	i = np->tx.req_prod_pvt;
 +
 +	id = get_id_from_freelist(&np->tx_skb_freelist, np->tx_skbs);
 +	np->tx_skbs[id].skb = skb;
 +
 +	tx = RING_GET_REQUEST(&np->tx, i);
 +
 +	tx->id   = id;
 +	ref = gnttab_claim_grant_reference(&np->gref_tx_head);
 +	BUG_ON((signed short)ref < 0);
 +	mfn = virt_to_mfn(data);
 +	gnttab_grant_foreign_access_ref(
 +		ref, np->xbdev->otherend_id, mfn, GNTMAP_readonly);
 +	np->grant_tx_page[id] = virt_to_page(data);
 +	tx->gref = np->grant_tx_ref[id] = ref;
 +	tx->offset = offset;
 +	tx->size = len;
 +
 +	tx->flags = 0;
++=======
+ 	/* First request for the linear area. */
+ 	first_tx = tx = xennet_make_one_txreq(queue, skb,
+ 					      page, offset, len);
+ 	page++;
+ 	offset = 0;
+ 	len -= tx->size;
+ 
++>>>>>>> a55e8bb8fb89 (xen-netfront: refactor making Tx requests)
  	if (skb->ip_summed == CHECKSUM_PARTIAL)
  		/* local packet? */
  		tx->flags |= XEN_NETTXF_csum_blank | XEN_NETTXF_data_validated;
@@@ -617,7 -589,7 +674,11 @@@
  		struct xen_netif_extra_info *gso;
  
  		gso = (struct xen_netif_extra_info *)
++<<<<<<< HEAD
 +			RING_GET_REQUEST(&np->tx, ++i);
++=======
+ 			RING_GET_REQUEST(&queue->tx, queue->tx.req_prod_pvt++);
++>>>>>>> a55e8bb8fb89 (xen-netfront: refactor making Tx requests)
  
  		tx->flags |= XEN_NETTXF_extra_info;
  
@@@ -630,14 -604,23 +691,30 @@@
  		gso->flags = 0;
  	}
  
++<<<<<<< HEAD
 +	np->tx.req_prod_pvt = i + 1;
 +
 +	xennet_make_frags(skb, dev, tx);
 +	tx->size = skb->len;
++=======
+ 	/* Requests for the rest of the linear area. */
+ 	tx = xennet_make_txreqs(queue, tx, skb, page, offset, len);
+ 
+ 	/* Requests for all the frags. */
+ 	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
+ 		skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
+ 		tx = xennet_make_txreqs(queue, tx, skb,
+ 					skb_frag_page(frag), frag->page_offset,
+ 					skb_frag_size(frag));
+ 	}
+ 
+ 	/* First request has the packet length. */
+ 	first_tx->size = skb->len;
++>>>>>>> a55e8bb8fb89 (xen-netfront: refactor making Tx requests)
  
 -	RING_PUSH_REQUESTS_AND_CHECK_NOTIFY(&queue->tx, notify);
 +	RING_PUSH_REQUESTS_AND_CHECK_NOTIFY(&np->tx, notify);
  	if (notify)
 -		notify_remote_via_irq(queue->tx_irq);
 +		notify_remote_via_irq(np->tx_irq);
  
  	u64_stats_update_begin(&stats->syncp);
  	stats->tx_bytes += skb->len;
* Unmerged path drivers/net/xen-netfront.c
