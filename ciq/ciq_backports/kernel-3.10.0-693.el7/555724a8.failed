kernfs, sysfs, cgroup: restrict extra perm check on open to sysfs

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Tejun Heo <tj@kernel.org>
commit 555724a831b4a146e7bdf16ecc989cda032b076d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/555724a8.failed

The kernfs open method - kernfs_fop_open() - inherited extra
permission checks from sysfs.  While the vfs layer allows ignoring the
read/write permissions checks if the issuer has CAP_DAC_OVERRIDE,
sysfs explicitly denied open regardless of the cap if the file doesn't
have any of the UGO perms of the requested access or doesn't implement
the requested operation.  It can be debated whether this was a good
idea or not but the behavior is too subtle and dangerous to change at
this point.

After cgroup got converted to kernfs, this extra perm check also got
applied to cgroup breaking libcgroup which opens write-only files with
O_RDWR as root.  This patch gates the extra open permission check with
a new flag KERNFS_ROOT_EXTRA_OPEN_PERM_CHECK and enables it for sysfs.
For sysfs, nothing changes.  For cgroup, root now can perform any
operation regardless of the permissions as it was before kernfs
conversion.  Note that kernfs still fails unimplemented operations
with -EINVAL.

While at it, add comments explaining KERNFS_ROOT flags.

	Signed-off-by: Tejun Heo <tj@kernel.org>
	Reported-by: Andrey Wagin <avagin@gmail.com>
	Tested-by: Andrey Wagin <avagin@gmail.com>
	Cc: Li Zefan <lizefan@huawei.com>
References: http://lkml.kernel.org/g/CANaxB-xUm3rJ-Cbp72q-rQJO5mZe1qK6qXsQM=vh0U8upJ44+A@mail.gmail.com
Fixes: 2bd59d48ebfb ("cgroup: convert to kernfs")
	Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
(cherry picked from commit 555724a831b4a146e7bdf16ecc989cda032b076d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/kernfs/file.c
#	fs/sysfs/mount.c
#	include/linux/kernfs.h
diff --cc fs/kernfs/file.c
index 90b1e88dad44,5e9a80cfc3d8..000000000000
--- a/fs/kernfs/file.c
+++ b/fs/kernfs/file.c
@@@ -7,3 -7,876 +7,879 @@@
   *
   * This file is released under the GPLv2.
   */
++<<<<<<< HEAD
++=======
+ 
+ #include <linux/fs.h>
+ #include <linux/seq_file.h>
+ #include <linux/slab.h>
+ #include <linux/poll.h>
+ #include <linux/pagemap.h>
+ #include <linux/sched.h>
+ 
+ #include "kernfs-internal.h"
+ 
+ /*
+  * There's one kernfs_open_file for each open file and one kernfs_open_node
+  * for each kernfs_node with one or more open files.
+  *
+  * kernfs_node->attr.open points to kernfs_open_node.  attr.open is
+  * protected by kernfs_open_node_lock.
+  *
+  * filp->private_data points to seq_file whose ->private points to
+  * kernfs_open_file.  kernfs_open_files are chained at
+  * kernfs_open_node->files, which is protected by kernfs_open_file_mutex.
+  */
+ static DEFINE_SPINLOCK(kernfs_open_node_lock);
+ static DEFINE_MUTEX(kernfs_open_file_mutex);
+ 
+ struct kernfs_open_node {
+ 	atomic_t		refcnt;
+ 	atomic_t		event;
+ 	wait_queue_head_t	poll;
+ 	struct list_head	files; /* goes through kernfs_open_file.list */
+ };
+ 
+ static struct kernfs_open_file *kernfs_of(struct file *file)
+ {
+ 	return ((struct seq_file *)file->private_data)->private;
+ }
+ 
+ /*
+  * Determine the kernfs_ops for the given kernfs_node.  This function must
+  * be called while holding an active reference.
+  */
+ static const struct kernfs_ops *kernfs_ops(struct kernfs_node *kn)
+ {
+ 	if (kn->flags & KERNFS_LOCKDEP)
+ 		lockdep_assert_held(kn);
+ 	return kn->attr.ops;
+ }
+ 
+ /*
+  * As kernfs_seq_stop() is also called after kernfs_seq_start() or
+  * kernfs_seq_next() failure, it needs to distinguish whether it's stopping
+  * a seq_file iteration which is fully initialized with an active reference
+  * or an aborted kernfs_seq_start() due to get_active failure.  The
+  * position pointer is the only context for each seq_file iteration and
+  * thus the stop condition should be encoded in it.  As the return value is
+  * directly visible to userland, ERR_PTR(-ENODEV) is the only acceptable
+  * choice to indicate get_active failure.
+  *
+  * Unfortunately, this is complicated due to the optional custom seq_file
+  * operations which may return ERR_PTR(-ENODEV) too.  kernfs_seq_stop()
+  * can't distinguish whether ERR_PTR(-ENODEV) is from get_active failure or
+  * custom seq_file operations and thus can't decide whether put_active
+  * should be performed or not only on ERR_PTR(-ENODEV).
+  *
+  * This is worked around by factoring out the custom seq_stop() and
+  * put_active part into kernfs_seq_stop_active(), skipping it from
+  * kernfs_seq_stop() if ERR_PTR(-ENODEV) while invoking it directly after
+  * custom seq_file operations fail with ERR_PTR(-ENODEV) - this ensures
+  * that kernfs_seq_stop_active() is skipped only after get_active failure.
+  */
+ static void kernfs_seq_stop_active(struct seq_file *sf, void *v)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 	const struct kernfs_ops *ops = kernfs_ops(of->kn);
+ 
+ 	if (ops->seq_stop)
+ 		ops->seq_stop(sf, v);
+ 	kernfs_put_active(of->kn);
+ }
+ 
+ static void *kernfs_seq_start(struct seq_file *sf, loff_t *ppos)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 	const struct kernfs_ops *ops;
+ 
+ 	/*
+ 	 * @of->mutex nests outside active ref and is just to ensure that
+ 	 * the ops aren't called concurrently for the same open file.
+ 	 */
+ 	mutex_lock(&of->mutex);
+ 	if (!kernfs_get_active(of->kn))
+ 		return ERR_PTR(-ENODEV);
+ 
+ 	ops = kernfs_ops(of->kn);
+ 	if (ops->seq_start) {
+ 		void *next = ops->seq_start(sf, ppos);
+ 		/* see the comment above kernfs_seq_stop_active() */
+ 		if (next == ERR_PTR(-ENODEV))
+ 			kernfs_seq_stop_active(sf, next);
+ 		return next;
+ 	} else {
+ 		/*
+ 		 * The same behavior and code as single_open().  Returns
+ 		 * !NULL if pos is at the beginning; otherwise, NULL.
+ 		 */
+ 		return NULL + !*ppos;
+ 	}
+ }
+ 
+ static void *kernfs_seq_next(struct seq_file *sf, void *v, loff_t *ppos)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 	const struct kernfs_ops *ops = kernfs_ops(of->kn);
+ 
+ 	if (ops->seq_next) {
+ 		void *next = ops->seq_next(sf, v, ppos);
+ 		/* see the comment above kernfs_seq_stop_active() */
+ 		if (next == ERR_PTR(-ENODEV))
+ 			kernfs_seq_stop_active(sf, next);
+ 		return next;
+ 	} else {
+ 		/*
+ 		 * The same behavior and code as single_open(), always
+ 		 * terminate after the initial read.
+ 		 */
+ 		++*ppos;
+ 		return NULL;
+ 	}
+ }
+ 
+ static void kernfs_seq_stop(struct seq_file *sf, void *v)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 
+ 	if (v != ERR_PTR(-ENODEV))
+ 		kernfs_seq_stop_active(sf, v);
+ 	mutex_unlock(&of->mutex);
+ }
+ 
+ static int kernfs_seq_show(struct seq_file *sf, void *v)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 
+ 	of->event = atomic_read(&of->kn->attr.open->event);
+ 
+ 	return of->kn->attr.ops->seq_show(sf, v);
+ }
+ 
+ static const struct seq_operations kernfs_seq_ops = {
+ 	.start = kernfs_seq_start,
+ 	.next = kernfs_seq_next,
+ 	.stop = kernfs_seq_stop,
+ 	.show = kernfs_seq_show,
+ };
+ 
+ /*
+  * As reading a bin file can have side-effects, the exact offset and bytes
+  * specified in read(2) call should be passed to the read callback making
+  * it difficult to use seq_file.  Implement simplistic custom buffering for
+  * bin files.
+  */
+ static ssize_t kernfs_file_direct_read(struct kernfs_open_file *of,
+ 				       char __user *user_buf, size_t count,
+ 				       loff_t *ppos)
+ {
+ 	ssize_t len = min_t(size_t, count, PAGE_SIZE);
+ 	const struct kernfs_ops *ops;
+ 	char *buf;
+ 
+ 	buf = kmalloc(len, GFP_KERNEL);
+ 	if (!buf)
+ 		return -ENOMEM;
+ 
+ 	/*
+ 	 * @of->mutex nests outside active ref and is just to ensure that
+ 	 * the ops aren't called concurrently for the same open file.
+ 	 */
+ 	mutex_lock(&of->mutex);
+ 	if (!kernfs_get_active(of->kn)) {
+ 		len = -ENODEV;
+ 		mutex_unlock(&of->mutex);
+ 		goto out_free;
+ 	}
+ 
+ 	ops = kernfs_ops(of->kn);
+ 	if (ops->read)
+ 		len = ops->read(of, buf, len, *ppos);
+ 	else
+ 		len = -EINVAL;
+ 
+ 	kernfs_put_active(of->kn);
+ 	mutex_unlock(&of->mutex);
+ 
+ 	if (len < 0)
+ 		goto out_free;
+ 
+ 	if (copy_to_user(user_buf, buf, len)) {
+ 		len = -EFAULT;
+ 		goto out_free;
+ 	}
+ 
+ 	*ppos += len;
+ 
+  out_free:
+ 	kfree(buf);
+ 	return len;
+ }
+ 
+ /**
+  * kernfs_fop_read - kernfs vfs read callback
+  * @file: file pointer
+  * @user_buf: data to write
+  * @count: number of bytes
+  * @ppos: starting offset
+  */
+ static ssize_t kernfs_fop_read(struct file *file, char __user *user_buf,
+ 			       size_t count, loff_t *ppos)
+ {
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 
+ 	if (of->kn->flags & KERNFS_HAS_SEQ_SHOW)
+ 		return seq_read(file, user_buf, count, ppos);
+ 	else
+ 		return kernfs_file_direct_read(of, user_buf, count, ppos);
+ }
+ 
+ /**
+  * kernfs_fop_write - kernfs vfs write callback
+  * @file: file pointer
+  * @user_buf: data to write
+  * @count: number of bytes
+  * @ppos: starting offset
+  *
+  * Copy data in from userland and pass it to the matching kernfs write
+  * operation.
+  *
+  * There is no easy way for us to know if userspace is only doing a partial
+  * write, so we don't support them. We expect the entire buffer to come on
+  * the first write.  Hint: if you're writing a value, first read the file,
+  * modify only the the value you're changing, then write entire buffer
+  * back.
+  */
+ static ssize_t kernfs_fop_write(struct file *file, const char __user *user_buf,
+ 				size_t count, loff_t *ppos)
+ {
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	const struct kernfs_ops *ops;
+ 	size_t len;
+ 	char *buf;
+ 
+ 	if (of->atomic_write_len) {
+ 		len = count;
+ 		if (len > of->atomic_write_len)
+ 			return -E2BIG;
+ 	} else {
+ 		len = min_t(size_t, count, PAGE_SIZE);
+ 	}
+ 
+ 	buf = kmalloc(len + 1, GFP_KERNEL);
+ 	if (!buf)
+ 		return -ENOMEM;
+ 
+ 	if (copy_from_user(buf, user_buf, len)) {
+ 		len = -EFAULT;
+ 		goto out_free;
+ 	}
+ 	buf[len] = '\0';	/* guarantee string termination */
+ 
+ 	/*
+ 	 * @of->mutex nests outside active ref and is just to ensure that
+ 	 * the ops aren't called concurrently for the same open file.
+ 	 */
+ 	mutex_lock(&of->mutex);
+ 	if (!kernfs_get_active(of->kn)) {
+ 		mutex_unlock(&of->mutex);
+ 		len = -ENODEV;
+ 		goto out_free;
+ 	}
+ 
+ 	ops = kernfs_ops(of->kn);
+ 	if (ops->write)
+ 		len = ops->write(of, buf, len, *ppos);
+ 	else
+ 		len = -EINVAL;
+ 
+ 	kernfs_put_active(of->kn);
+ 	mutex_unlock(&of->mutex);
+ 
+ 	if (len > 0)
+ 		*ppos += len;
+ out_free:
+ 	kfree(buf);
+ 	return len;
+ }
+ 
+ static void kernfs_vma_open(struct vm_area_struct *vma)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 
+ 	if (!of->vm_ops)
+ 		return;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return;
+ 
+ 	if (of->vm_ops->open)
+ 		of->vm_ops->open(vma);
+ 
+ 	kernfs_put_active(of->kn);
+ }
+ 
+ static int kernfs_vma_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return VM_FAULT_SIGBUS;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return VM_FAULT_SIGBUS;
+ 
+ 	ret = VM_FAULT_SIGBUS;
+ 	if (of->vm_ops->fault)
+ 		ret = of->vm_ops->fault(vma, vmf);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ 
+ static int kernfs_vma_page_mkwrite(struct vm_area_struct *vma,
+ 				   struct vm_fault *vmf)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return VM_FAULT_SIGBUS;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return VM_FAULT_SIGBUS;
+ 
+ 	ret = 0;
+ 	if (of->vm_ops->page_mkwrite)
+ 		ret = of->vm_ops->page_mkwrite(vma, vmf);
+ 	else
+ 		file_update_time(file);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ 
+ static int kernfs_vma_access(struct vm_area_struct *vma, unsigned long addr,
+ 			     void *buf, int len, int write)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return -EINVAL;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return -EINVAL;
+ 
+ 	ret = -EINVAL;
+ 	if (of->vm_ops->access)
+ 		ret = of->vm_ops->access(vma, addr, buf, len, write);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ 
+ #ifdef CONFIG_NUMA
+ static int kernfs_vma_set_policy(struct vm_area_struct *vma,
+ 				 struct mempolicy *new)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return 0;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return -EINVAL;
+ 
+ 	ret = 0;
+ 	if (of->vm_ops->set_policy)
+ 		ret = of->vm_ops->set_policy(vma, new);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ 
+ static struct mempolicy *kernfs_vma_get_policy(struct vm_area_struct *vma,
+ 					       unsigned long addr)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	struct mempolicy *pol;
+ 
+ 	if (!of->vm_ops)
+ 		return vma->vm_policy;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return vma->vm_policy;
+ 
+ 	pol = vma->vm_policy;
+ 	if (of->vm_ops->get_policy)
+ 		pol = of->vm_ops->get_policy(vma, addr);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return pol;
+ }
+ 
+ static int kernfs_vma_migrate(struct vm_area_struct *vma,
+ 			      const nodemask_t *from, const nodemask_t *to,
+ 			      unsigned long flags)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return 0;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return 0;
+ 
+ 	ret = 0;
+ 	if (of->vm_ops->migrate)
+ 		ret = of->vm_ops->migrate(vma, from, to, flags);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ #endif
+ 
+ static const struct vm_operations_struct kernfs_vm_ops = {
+ 	.open		= kernfs_vma_open,
+ 	.fault		= kernfs_vma_fault,
+ 	.page_mkwrite	= kernfs_vma_page_mkwrite,
+ 	.access		= kernfs_vma_access,
+ #ifdef CONFIG_NUMA
+ 	.set_policy	= kernfs_vma_set_policy,
+ 	.get_policy	= kernfs_vma_get_policy,
+ 	.migrate	= kernfs_vma_migrate,
+ #endif
+ };
+ 
+ static int kernfs_fop_mmap(struct file *file, struct vm_area_struct *vma)
+ {
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	const struct kernfs_ops *ops;
+ 	int rc;
+ 
+ 	/*
+ 	 * mmap path and of->mutex are prone to triggering spurious lockdep
+ 	 * warnings and we don't want to add spurious locking dependency
+ 	 * between the two.  Check whether mmap is actually implemented
+ 	 * without grabbing @of->mutex by testing HAS_MMAP flag.  See the
+ 	 * comment in kernfs_file_open() for more details.
+ 	 */
+ 	if (!(of->kn->flags & KERNFS_HAS_MMAP))
+ 		return -ENODEV;
+ 
+ 	mutex_lock(&of->mutex);
+ 
+ 	rc = -ENODEV;
+ 	if (!kernfs_get_active(of->kn))
+ 		goto out_unlock;
+ 
+ 	ops = kernfs_ops(of->kn);
+ 	rc = ops->mmap(of, vma);
+ 	if (rc)
+ 		goto out_put;
+ 
+ 	/*
+ 	 * PowerPC's pci_mmap of legacy_mem uses shmem_zero_setup()
+ 	 * to satisfy versions of X which crash if the mmap fails: that
+ 	 * substitutes a new vm_file, and we don't then want bin_vm_ops.
+ 	 */
+ 	if (vma->vm_file != file)
+ 		goto out_put;
+ 
+ 	rc = -EINVAL;
+ 	if (of->mmapped && of->vm_ops != vma->vm_ops)
+ 		goto out_put;
+ 
+ 	/*
+ 	 * It is not possible to successfully wrap close.
+ 	 * So error if someone is trying to use close.
+ 	 */
+ 	rc = -EINVAL;
+ 	if (vma->vm_ops && vma->vm_ops->close)
+ 		goto out_put;
+ 
+ 	rc = 0;
+ 	of->mmapped = 1;
+ 	of->vm_ops = vma->vm_ops;
+ 	vma->vm_ops = &kernfs_vm_ops;
+ out_put:
+ 	kernfs_put_active(of->kn);
+ out_unlock:
+ 	mutex_unlock(&of->mutex);
+ 
+ 	return rc;
+ }
+ 
+ /**
+  *	kernfs_get_open_node - get or create kernfs_open_node
+  *	@kn: target kernfs_node
+  *	@of: kernfs_open_file for this instance of open
+  *
+  *	If @kn->attr.open exists, increment its reference count; otherwise,
+  *	create one.  @of is chained to the files list.
+  *
+  *	LOCKING:
+  *	Kernel thread context (may sleep).
+  *
+  *	RETURNS:
+  *	0 on success, -errno on failure.
+  */
+ static int kernfs_get_open_node(struct kernfs_node *kn,
+ 				struct kernfs_open_file *of)
+ {
+ 	struct kernfs_open_node *on, *new_on = NULL;
+ 
+  retry:
+ 	mutex_lock(&kernfs_open_file_mutex);
+ 	spin_lock_irq(&kernfs_open_node_lock);
+ 
+ 	if (!kn->attr.open && new_on) {
+ 		kn->attr.open = new_on;
+ 		new_on = NULL;
+ 	}
+ 
+ 	on = kn->attr.open;
+ 	if (on) {
+ 		atomic_inc(&on->refcnt);
+ 		list_add_tail(&of->list, &on->files);
+ 	}
+ 
+ 	spin_unlock_irq(&kernfs_open_node_lock);
+ 	mutex_unlock(&kernfs_open_file_mutex);
+ 
+ 	if (on) {
+ 		kfree(new_on);
+ 		return 0;
+ 	}
+ 
+ 	/* not there, initialize a new one and retry */
+ 	new_on = kmalloc(sizeof(*new_on), GFP_KERNEL);
+ 	if (!new_on)
+ 		return -ENOMEM;
+ 
+ 	atomic_set(&new_on->refcnt, 0);
+ 	atomic_set(&new_on->event, 1);
+ 	init_waitqueue_head(&new_on->poll);
+ 	INIT_LIST_HEAD(&new_on->files);
+ 	goto retry;
+ }
+ 
+ /**
+  *	kernfs_put_open_node - put kernfs_open_node
+  *	@kn: target kernfs_nodet
+  *	@of: associated kernfs_open_file
+  *
+  *	Put @kn->attr.open and unlink @of from the files list.  If
+  *	reference count reaches zero, disassociate and free it.
+  *
+  *	LOCKING:
+  *	None.
+  */
+ static void kernfs_put_open_node(struct kernfs_node *kn,
+ 				 struct kernfs_open_file *of)
+ {
+ 	struct kernfs_open_node *on = kn->attr.open;
+ 	unsigned long flags;
+ 
+ 	mutex_lock(&kernfs_open_file_mutex);
+ 	spin_lock_irqsave(&kernfs_open_node_lock, flags);
+ 
+ 	if (of)
+ 		list_del(&of->list);
+ 
+ 	if (atomic_dec_and_test(&on->refcnt))
+ 		kn->attr.open = NULL;
+ 	else
+ 		on = NULL;
+ 
+ 	spin_unlock_irqrestore(&kernfs_open_node_lock, flags);
+ 	mutex_unlock(&kernfs_open_file_mutex);
+ 
+ 	kfree(on);
+ }
+ 
+ static int kernfs_fop_open(struct inode *inode, struct file *file)
+ {
+ 	struct kernfs_node *kn = file->f_path.dentry->d_fsdata;
+ 	struct kernfs_root *root = kernfs_root(kn);
+ 	const struct kernfs_ops *ops;
+ 	struct kernfs_open_file *of;
+ 	bool has_read, has_write, has_mmap;
+ 	int error = -EACCES;
+ 
+ 	if (!kernfs_get_active(kn))
+ 		return -ENODEV;
+ 
+ 	ops = kernfs_ops(kn);
+ 
+ 	has_read = ops->seq_show || ops->read || ops->mmap;
+ 	has_write = ops->write || ops->mmap;
+ 	has_mmap = ops->mmap;
+ 
+ 	/* see the flag definition for details */
+ 	if (root->flags & KERNFS_ROOT_EXTRA_OPEN_PERM_CHECK) {
+ 		if ((file->f_mode & FMODE_WRITE) &&
+ 		    (!(inode->i_mode & S_IWUGO) || !has_write))
+ 			goto err_out;
+ 
+ 		if ((file->f_mode & FMODE_READ) &&
+ 		    (!(inode->i_mode & S_IRUGO) || !has_read))
+ 			goto err_out;
+ 	}
+ 
+ 	/* allocate a kernfs_open_file for the file */
+ 	error = -ENOMEM;
+ 	of = kzalloc(sizeof(struct kernfs_open_file), GFP_KERNEL);
+ 	if (!of)
+ 		goto err_out;
+ 
+ 	/*
+ 	 * The following is done to give a different lockdep key to
+ 	 * @of->mutex for files which implement mmap.  This is a rather
+ 	 * crude way to avoid false positive lockdep warning around
+ 	 * mm->mmap_sem - mmap nests @of->mutex under mm->mmap_sem and
+ 	 * reading /sys/block/sda/trace/act_mask grabs sr_mutex, under
+ 	 * which mm->mmap_sem nests, while holding @of->mutex.  As each
+ 	 * open file has a separate mutex, it's okay as long as those don't
+ 	 * happen on the same file.  At this point, we can't easily give
+ 	 * each file a separate locking class.  Let's differentiate on
+ 	 * whether the file has mmap or not for now.
+ 	 *
+ 	 * Both paths of the branch look the same.  They're supposed to
+ 	 * look that way and give @of->mutex different static lockdep keys.
+ 	 */
+ 	if (has_mmap)
+ 		mutex_init(&of->mutex);
+ 	else
+ 		mutex_init(&of->mutex);
+ 
+ 	of->kn = kn;
+ 	of->file = file;
+ 
+ 	/*
+ 	 * Write path needs to atomic_write_len outside active reference.
+ 	 * Cache it in open_file.  See kernfs_fop_write() for details.
+ 	 */
+ 	of->atomic_write_len = ops->atomic_write_len;
+ 
+ 	/*
+ 	 * Always instantiate seq_file even if read access doesn't use
+ 	 * seq_file or is not requested.  This unifies private data access
+ 	 * and readable regular files are the vast majority anyway.
+ 	 */
+ 	if (ops->seq_show)
+ 		error = seq_open(file, &kernfs_seq_ops);
+ 	else
+ 		error = seq_open(file, NULL);
+ 	if (error)
+ 		goto err_free;
+ 
+ 	((struct seq_file *)file->private_data)->private = of;
+ 
+ 	/* seq_file clears PWRITE unconditionally, restore it if WRITE */
+ 	if (file->f_mode & FMODE_WRITE)
+ 		file->f_mode |= FMODE_PWRITE;
+ 
+ 	/* make sure we have open node struct */
+ 	error = kernfs_get_open_node(kn, of);
+ 	if (error)
+ 		goto err_close;
+ 
+ 	/* open succeeded, put active references */
+ 	kernfs_put_active(kn);
+ 	return 0;
+ 
+ err_close:
+ 	seq_release(inode, file);
+ err_free:
+ 	kfree(of);
+ err_out:
+ 	kernfs_put_active(kn);
+ 	return error;
+ }
+ 
+ static int kernfs_fop_release(struct inode *inode, struct file *filp)
+ {
+ 	struct kernfs_node *kn = filp->f_path.dentry->d_fsdata;
+ 	struct kernfs_open_file *of = kernfs_of(filp);
+ 
+ 	kernfs_put_open_node(kn, of);
+ 	seq_release(inode, filp);
+ 	kfree(of);
+ 
+ 	return 0;
+ }
+ 
+ void kernfs_unmap_bin_file(struct kernfs_node *kn)
+ {
+ 	struct kernfs_open_node *on;
+ 	struct kernfs_open_file *of;
+ 
+ 	if (!(kn->flags & KERNFS_HAS_MMAP))
+ 		return;
+ 
+ 	spin_lock_irq(&kernfs_open_node_lock);
+ 	on = kn->attr.open;
+ 	if (on)
+ 		atomic_inc(&on->refcnt);
+ 	spin_unlock_irq(&kernfs_open_node_lock);
+ 	if (!on)
+ 		return;
+ 
+ 	mutex_lock(&kernfs_open_file_mutex);
+ 	list_for_each_entry(of, &on->files, list) {
+ 		struct inode *inode = file_inode(of->file);
+ 		unmap_mapping_range(inode->i_mapping, 0, 0, 1);
+ 	}
+ 	mutex_unlock(&kernfs_open_file_mutex);
+ 
+ 	kernfs_put_open_node(kn, NULL);
+ }
+ 
+ /*
+  * Kernfs attribute files are pollable.  The idea is that you read
+  * the content and then you use 'poll' or 'select' to wait for
+  * the content to change.  When the content changes (assuming the
+  * manager for the kobject supports notification), poll will
+  * return POLLERR|POLLPRI, and select will return the fd whether
+  * it is waiting for read, write, or exceptions.
+  * Once poll/select indicates that the value has changed, you
+  * need to close and re-open the file, or seek to 0 and read again.
+  * Reminder: this only works for attributes which actively support
+  * it, and it is not possible to test an attribute from userspace
+  * to see if it supports poll (Neither 'poll' nor 'select' return
+  * an appropriate error code).  When in doubt, set a suitable timeout value.
+  */
+ static unsigned int kernfs_fop_poll(struct file *filp, poll_table *wait)
+ {
+ 	struct kernfs_open_file *of = kernfs_of(filp);
+ 	struct kernfs_node *kn = filp->f_path.dentry->d_fsdata;
+ 	struct kernfs_open_node *on = kn->attr.open;
+ 
+ 	/* need parent for the kobj, grab both */
+ 	if (!kernfs_get_active(kn))
+ 		goto trigger;
+ 
+ 	poll_wait(filp, &on->poll, wait);
+ 
+ 	kernfs_put_active(kn);
+ 
+ 	if (of->event != atomic_read(&on->event))
+ 		goto trigger;
+ 
+ 	return DEFAULT_POLLMASK;
+ 
+  trigger:
+ 	return DEFAULT_POLLMASK|POLLERR|POLLPRI;
+ }
+ 
+ /**
+  * kernfs_notify - notify a kernfs file
+  * @kn: file to notify
+  *
+  * Notify @kn such that poll(2) on @kn wakes up.
+  */
+ void kernfs_notify(struct kernfs_node *kn)
+ {
+ 	struct kernfs_open_node *on;
+ 	unsigned long flags;
+ 
+ 	spin_lock_irqsave(&kernfs_open_node_lock, flags);
+ 
+ 	if (!WARN_ON(kernfs_type(kn) != KERNFS_FILE)) {
+ 		on = kn->attr.open;
+ 		if (on) {
+ 			atomic_inc(&on->event);
+ 			wake_up_interruptible(&on->poll);
+ 		}
+ 	}
+ 
+ 	spin_unlock_irqrestore(&kernfs_open_node_lock, flags);
+ }
+ EXPORT_SYMBOL_GPL(kernfs_notify);
+ 
+ const struct file_operations kernfs_file_fops = {
+ 	.read		= kernfs_fop_read,
+ 	.write		= kernfs_fop_write,
+ 	.llseek		= generic_file_llseek,
+ 	.mmap		= kernfs_fop_mmap,
+ 	.open		= kernfs_fop_open,
+ 	.release	= kernfs_fop_release,
+ 	.poll		= kernfs_fop_poll,
+ };
+ 
+ /**
+  * __kernfs_create_file - kernfs internal function to create a file
+  * @parent: directory to create the file in
+  * @name: name of the file
+  * @mode: mode of the file
+  * @size: size of the file
+  * @ops: kernfs operations for the file
+  * @priv: private data for the file
+  * @ns: optional namespace tag of the file
+  * @static_name: don't copy file name
+  * @key: lockdep key for the file's active_ref, %NULL to disable lockdep
+  *
+  * Returns the created node on success, ERR_PTR() value on error.
+  */
+ struct kernfs_node *__kernfs_create_file(struct kernfs_node *parent,
+ 					 const char *name,
+ 					 umode_t mode, loff_t size,
+ 					 const struct kernfs_ops *ops,
+ 					 void *priv, const void *ns,
+ 					 bool name_is_static,
+ 					 struct lock_class_key *key)
+ {
+ 	struct kernfs_node *kn;
+ 	unsigned flags;
+ 	int rc;
+ 
+ 	flags = KERNFS_FILE;
+ 	if (name_is_static)
+ 		flags |= KERNFS_STATIC_NAME;
+ 
+ 	kn = kernfs_new_node(parent, name, (mode & S_IALLUGO) | S_IFREG, flags);
+ 	if (!kn)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	kn->attr.ops = ops;
+ 	kn->attr.size = size;
+ 	kn->ns = ns;
+ 	kn->priv = priv;
+ 
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	if (key) {
+ 		lockdep_init_map(&kn->dep_map, "s_active", key, 0);
+ 		kn->flags |= KERNFS_LOCKDEP;
+ 	}
+ #endif
+ 
+ 	/*
+ 	 * kn->attr.ops is accesible only while holding active ref.  We
+ 	 * need to know whether some ops are implemented outside active
+ 	 * ref.  Cache their existence in flags.
+ 	 */
+ 	if (ops->seq_show)
+ 		kn->flags |= KERNFS_HAS_SEQ_SHOW;
+ 	if (ops->mmap)
+ 		kn->flags |= KERNFS_HAS_MMAP;
+ 
+ 	rc = kernfs_add_one(kn);
+ 	if (rc) {
+ 		kernfs_put(kn);
+ 		return ERR_PTR(rc);
+ 	}
+ 	return kn;
+ }
++>>>>>>> 555724a831b4 (kernfs, sysfs, cgroup: restrict extra perm check on open to sysfs)
diff --cc fs/sysfs/mount.c
index afd83273e6ce,8794423f7efb..000000000000
--- a/fs/sysfs/mount.c
+++ b/fs/sysfs/mount.c
@@@ -158,48 -61,20 +158,55 @@@ static struct file_system_type sysfs_fs
  
  int __init sysfs_init(void)
  {
 -	int err;
 -
 +	int err = -ENOMEM;
 +
++<<<<<<< HEAD
 +	sysfs_dir_cachep = kmem_cache_create("sysfs_dir_cache",
 +					      sizeof(struct sysfs_dirent),
 +					      0, 0, NULL);
 +	if (!sysfs_dir_cachep)
 +		goto out;
++=======
+ 	sysfs_root = kernfs_create_root(NULL, KERNFS_ROOT_EXTRA_OPEN_PERM_CHECK,
+ 					NULL);
+ 	if (IS_ERR(sysfs_root))
+ 		return PTR_ERR(sysfs_root);
++>>>>>>> 555724a831b4 (kernfs, sysfs, cgroup: restrict extra perm check on open to sysfs)
  
 -	sysfs_root_kn = sysfs_root->kn;
 +	err = sysfs_inode_init();
 +	if (err)
 +		goto out_err;
  
  	err = register_filesystem(&sysfs_fs_type);
 -	if (err) {
 -		kernfs_destroy_root(sysfs_root);
 -		return err;
 -	}
 +	if (!err) {
 +		sysfs_mnt = kern_mount(&sysfs_fs_type);
 +		if (IS_ERR(sysfs_mnt)) {
 +			printk(KERN_ERR "sysfs: could not mount!\n");
 +			err = PTR_ERR(sysfs_mnt);
 +			sysfs_mnt = NULL;
 +			unregister_filesystem(&sysfs_fs_type);
 +			goto out_err;
 +		}
 +	} else
 +		goto out_err;
 +out:
 +	return err;
 +out_err:
 +	kmem_cache_destroy(sysfs_dir_cachep);
 +	sysfs_dir_cachep = NULL;
 +	goto out;
 +}
  
 -	return 0;
 +#undef sysfs_get
 +struct sysfs_dirent *sysfs_get(struct sysfs_dirent *sd)
 +{
 +	return __sysfs_get(sd);
 +}
 +EXPORT_SYMBOL_GPL(sysfs_get);
 +
 +#undef sysfs_put
 +void sysfs_put(struct sysfs_dirent *sd)
 +{
 +	__sysfs_put(sd);
  }
 +EXPORT_SYMBOL_GPL(sysfs_put);
diff --cc include/linux/kernfs.h
index 254b9e872b09,ca1be5c9136c..000000000000
--- a/include/linux/kernfs.h
+++ b/include/linux/kernfs.h
@@@ -7,6 -7,451 +7,455 @@@
  #ifndef __LINUX_KERNFS_H
  #define __LINUX_KERNFS_H
  
++<<<<<<< HEAD
 +struct sysfs_dirent;
++=======
+ #include <linux/kernel.h>
+ #include <linux/err.h>
+ #include <linux/list.h>
+ #include <linux/mutex.h>
+ #include <linux/idr.h>
+ #include <linux/lockdep.h>
+ #include <linux/rbtree.h>
+ #include <linux/atomic.h>
+ #include <linux/wait.h>
+ 
+ struct file;
+ struct dentry;
+ struct iattr;
+ struct seq_file;
+ struct vm_area_struct;
+ struct super_block;
+ struct file_system_type;
+ 
+ struct kernfs_open_node;
+ struct kernfs_iattrs;
+ 
+ enum kernfs_node_type {
+ 	KERNFS_DIR		= 0x0001,
+ 	KERNFS_FILE		= 0x0002,
+ 	KERNFS_LINK		= 0x0004,
+ };
+ 
+ #define KERNFS_TYPE_MASK	0x000f
+ #define KERNFS_FLAG_MASK	~KERNFS_TYPE_MASK
+ 
+ enum kernfs_node_flag {
+ 	KERNFS_ACTIVATED	= 0x0010,
+ 	KERNFS_NS		= 0x0020,
+ 	KERNFS_HAS_SEQ_SHOW	= 0x0040,
+ 	KERNFS_HAS_MMAP		= 0x0080,
+ 	KERNFS_LOCKDEP		= 0x0100,
+ 	KERNFS_STATIC_NAME	= 0x0200,
+ 	KERNFS_SUICIDAL		= 0x0400,
+ 	KERNFS_SUICIDED		= 0x0800,
+ };
+ 
+ /* @flags for kernfs_create_root() */
+ enum kernfs_root_flag {
+ 	/*
+ 	 * kernfs_nodes are created in the deactivated state and invisible.
+ 	 * They require explicit kernfs_activate() to become visible.  This
+ 	 * can be used to make related nodes become visible atomically
+ 	 * after all nodes are created successfully.
+ 	 */
+ 	KERNFS_ROOT_CREATE_DEACTIVATED		= 0x0001,
+ 
+ 	/*
+ 	 * For regular flies, if the opener has CAP_DAC_OVERRIDE, open(2)
+ 	 * succeeds regardless of the RW permissions.  sysfs had an extra
+ 	 * layer of enforcement where open(2) fails with -EACCES regardless
+ 	 * of CAP_DAC_OVERRIDE if the permission doesn't have the
+ 	 * respective read or write access at all (none of S_IRUGO or
+ 	 * S_IWUGO) or the respective operation isn't implemented.  The
+ 	 * following flag enables that behavior.
+ 	 */
+ 	KERNFS_ROOT_EXTRA_OPEN_PERM_CHECK	= 0x0002,
+ };
+ 
+ /* type-specific structures for kernfs_node union members */
+ struct kernfs_elem_dir {
+ 	unsigned long		subdirs;
+ 	/* children rbtree starts here and goes through kn->rb */
+ 	struct rb_root		children;
+ 
+ 	/*
+ 	 * The kernfs hierarchy this directory belongs to.  This fits
+ 	 * better directly in kernfs_node but is here to save space.
+ 	 */
+ 	struct kernfs_root	*root;
+ };
+ 
+ struct kernfs_elem_symlink {
+ 	struct kernfs_node	*target_kn;
+ };
+ 
+ struct kernfs_elem_attr {
+ 	const struct kernfs_ops	*ops;
+ 	struct kernfs_open_node	*open;
+ 	loff_t			size;
+ };
+ 
+ /*
+  * kernfs_node - the building block of kernfs hierarchy.  Each and every
+  * kernfs node is represented by single kernfs_node.  Most fields are
+  * private to kernfs and shouldn't be accessed directly by kernfs users.
+  *
+  * As long as s_count reference is held, the kernfs_node itself is
+  * accessible.  Dereferencing elem or any other outer entity requires
+  * active reference.
+  */
+ struct kernfs_node {
+ 	atomic_t		count;
+ 	atomic_t		active;
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	struct lockdep_map	dep_map;
+ #endif
+ 	/*
+ 	 * Use kernfs_get_parent() and kernfs_name/path() instead of
+ 	 * accessing the following two fields directly.  If the node is
+ 	 * never moved to a different parent, it is safe to access the
+ 	 * parent directly.
+ 	 */
+ 	struct kernfs_node	*parent;
+ 	const char		*name;
+ 
+ 	struct rb_node		rb;
+ 
+ 	const void		*ns;	/* namespace tag */
+ 	unsigned int		hash;	/* ns + name hash */
+ 	union {
+ 		struct kernfs_elem_dir		dir;
+ 		struct kernfs_elem_symlink	symlink;
+ 		struct kernfs_elem_attr		attr;
+ 	};
+ 
+ 	void			*priv;
+ 
+ 	unsigned short		flags;
+ 	umode_t			mode;
+ 	unsigned int		ino;
+ 	struct kernfs_iattrs	*iattr;
+ };
+ 
+ /*
+  * kernfs_syscall_ops may be specified on kernfs_create_root() to support
+  * syscalls.  These optional callbacks are invoked on the matching syscalls
+  * and can perform any kernfs operations which don't necessarily have to be
+  * the exact operation requested.  An active reference is held for each
+  * kernfs_node parameter.
+  */
+ struct kernfs_syscall_ops {
+ 	int (*remount_fs)(struct kernfs_root *root, int *flags, char *data);
+ 	int (*show_options)(struct seq_file *sf, struct kernfs_root *root);
+ 
+ 	int (*mkdir)(struct kernfs_node *parent, const char *name,
+ 		     umode_t mode);
+ 	int (*rmdir)(struct kernfs_node *kn);
+ 	int (*rename)(struct kernfs_node *kn, struct kernfs_node *new_parent,
+ 		      const char *new_name);
+ };
+ 
+ struct kernfs_root {
+ 	/* published fields */
+ 	struct kernfs_node	*kn;
+ 	unsigned int		flags;	/* KERNFS_ROOT_* flags */
+ 
+ 	/* private fields, do not use outside kernfs proper */
+ 	struct ida		ino_ida;
+ 	struct kernfs_syscall_ops *syscall_ops;
+ 	wait_queue_head_t	deactivate_waitq;
+ };
+ 
+ struct kernfs_open_file {
+ 	/* published fields */
+ 	struct kernfs_node	*kn;
+ 	struct file		*file;
+ 	void			*priv;
+ 
+ 	/* private fields, do not use outside kernfs proper */
+ 	struct mutex		mutex;
+ 	int			event;
+ 	struct list_head	list;
+ 
+ 	size_t			atomic_write_len;
+ 	bool			mmapped;
+ 	const struct vm_operations_struct *vm_ops;
+ };
+ 
+ struct kernfs_ops {
+ 	/*
+ 	 * Read is handled by either seq_file or raw_read().
+ 	 *
+ 	 * If seq_show() is present, seq_file path is active.  Other seq
+ 	 * operations are optional and if not implemented, the behavior is
+ 	 * equivalent to single_open().  @sf->private points to the
+ 	 * associated kernfs_open_file.
+ 	 *
+ 	 * read() is bounced through kernel buffer and a read larger than
+ 	 * PAGE_SIZE results in partial operation of PAGE_SIZE.
+ 	 */
+ 	int (*seq_show)(struct seq_file *sf, void *v);
+ 
+ 	void *(*seq_start)(struct seq_file *sf, loff_t *ppos);
+ 	void *(*seq_next)(struct seq_file *sf, void *v, loff_t *ppos);
+ 	void (*seq_stop)(struct seq_file *sf, void *v);
+ 
+ 	ssize_t (*read)(struct kernfs_open_file *of, char *buf, size_t bytes,
+ 			loff_t off);
+ 
+ 	/*
+ 	 * write() is bounced through kernel buffer.  If atomic_write_len
+ 	 * is not set, a write larger than PAGE_SIZE results in partial
+ 	 * operations of PAGE_SIZE chunks.  If atomic_write_len is set,
+ 	 * writes upto the specified size are executed atomically but
+ 	 * larger ones are rejected with -E2BIG.
+ 	 */
+ 	size_t atomic_write_len;
+ 	ssize_t (*write)(struct kernfs_open_file *of, char *buf, size_t bytes,
+ 			 loff_t off);
+ 
+ 	int (*mmap)(struct kernfs_open_file *of, struct vm_area_struct *vma);
+ 
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	struct lock_class_key	lockdep_key;
+ #endif
+ };
+ 
+ #ifdef CONFIG_KERNFS
+ 
+ static inline enum kernfs_node_type kernfs_type(struct kernfs_node *kn)
+ {
+ 	return kn->flags & KERNFS_TYPE_MASK;
+ }
+ 
+ /**
+  * kernfs_enable_ns - enable namespace under a directory
+  * @kn: directory of interest, should be empty
+  *
+  * This is to be called right after @kn is created to enable namespace
+  * under it.  All children of @kn must have non-NULL namespace tags and
+  * only the ones which match the super_block's tag will be visible.
+  */
+ static inline void kernfs_enable_ns(struct kernfs_node *kn)
+ {
+ 	WARN_ON_ONCE(kernfs_type(kn) != KERNFS_DIR);
+ 	WARN_ON_ONCE(!RB_EMPTY_ROOT(&kn->dir.children));
+ 	kn->flags |= KERNFS_NS;
+ }
+ 
+ /**
+  * kernfs_ns_enabled - test whether namespace is enabled
+  * @kn: the node to test
+  *
+  * Test whether namespace filtering is enabled for the children of @ns.
+  */
+ static inline bool kernfs_ns_enabled(struct kernfs_node *kn)
+ {
+ 	return kn->flags & KERNFS_NS;
+ }
+ 
+ int kernfs_name(struct kernfs_node *kn, char *buf, size_t buflen);
+ char * __must_check kernfs_path(struct kernfs_node *kn, char *buf,
+ 				size_t buflen);
+ void pr_cont_kernfs_name(struct kernfs_node *kn);
+ void pr_cont_kernfs_path(struct kernfs_node *kn);
+ struct kernfs_node *kernfs_get_parent(struct kernfs_node *kn);
+ struct kernfs_node *kernfs_find_and_get_ns(struct kernfs_node *parent,
+ 					   const char *name, const void *ns);
+ void kernfs_get(struct kernfs_node *kn);
+ void kernfs_put(struct kernfs_node *kn);
+ 
+ struct kernfs_node *kernfs_node_from_dentry(struct dentry *dentry);
+ struct kernfs_root *kernfs_root_from_sb(struct super_block *sb);
+ 
+ struct kernfs_root *kernfs_create_root(struct kernfs_syscall_ops *scops,
+ 				       unsigned int flags, void *priv);
+ void kernfs_destroy_root(struct kernfs_root *root);
+ 
+ struct kernfs_node *kernfs_create_dir_ns(struct kernfs_node *parent,
+ 					 const char *name, umode_t mode,
+ 					 void *priv, const void *ns);
+ struct kernfs_node *__kernfs_create_file(struct kernfs_node *parent,
+ 					 const char *name,
+ 					 umode_t mode, loff_t size,
+ 					 const struct kernfs_ops *ops,
+ 					 void *priv, const void *ns,
+ 					 bool name_is_static,
+ 					 struct lock_class_key *key);
+ struct kernfs_node *kernfs_create_link(struct kernfs_node *parent,
+ 				       const char *name,
+ 				       struct kernfs_node *target);
+ void kernfs_activate(struct kernfs_node *kn);
+ void kernfs_remove(struct kernfs_node *kn);
+ void kernfs_break_active_protection(struct kernfs_node *kn);
+ void kernfs_unbreak_active_protection(struct kernfs_node *kn);
+ bool kernfs_remove_self(struct kernfs_node *kn);
+ int kernfs_remove_by_name_ns(struct kernfs_node *parent, const char *name,
+ 			     const void *ns);
+ int kernfs_rename_ns(struct kernfs_node *kn, struct kernfs_node *new_parent,
+ 		     const char *new_name, const void *new_ns);
+ int kernfs_setattr(struct kernfs_node *kn, const struct iattr *iattr);
+ void kernfs_notify(struct kernfs_node *kn);
+ 
+ const void *kernfs_super_ns(struct super_block *sb);
+ struct dentry *kernfs_mount_ns(struct file_system_type *fs_type, int flags,
+ 			       struct kernfs_root *root, bool *new_sb_created,
+ 			       const void *ns);
+ void kernfs_kill_sb(struct super_block *sb);
+ 
+ void kernfs_init(void);
+ 
+ #else	/* CONFIG_KERNFS */
+ 
+ static inline enum kernfs_node_type kernfs_type(struct kernfs_node *kn)
+ { return 0; }	/* whatever */
+ 
+ static inline void kernfs_enable_ns(struct kernfs_node *kn) { }
+ 
+ static inline bool kernfs_ns_enabled(struct kernfs_node *kn)
+ { return false; }
+ 
+ static inline int kernfs_name(struct kernfs_node *kn, char *buf, size_t buflen)
+ { return -ENOSYS; }
+ 
+ static inline char * __must_check kernfs_path(struct kernfs_node *kn, char *buf,
+ 					      size_t buflen)
+ { return NULL; }
+ 
+ static inline void pr_cont_kernfs_name(struct kernfs_node *kn) { }
+ static inline void pr_cont_kernfs_path(struct kernfs_node *kn) { }
+ 
+ static inline struct kernfs_node *kernfs_get_parent(struct kernfs_node *kn)
+ { return NULL; }
+ 
+ static inline struct kernfs_node *
+ kernfs_find_and_get_ns(struct kernfs_node *parent, const char *name,
+ 		       const void *ns)
+ { return NULL; }
+ 
+ static inline void kernfs_get(struct kernfs_node *kn) { }
+ static inline void kernfs_put(struct kernfs_node *kn) { }
+ 
+ static inline struct kernfs_node *kernfs_node_from_dentry(struct dentry *dentry)
+ { return NULL; }
+ 
+ static inline struct kernfs_root *kernfs_root_from_sb(struct super_block *sb)
+ { return NULL; }
+ 
+ static inline struct kernfs_root *
+ kernfs_create_root(struct kernfs_syscall_ops *scops, unsigned int flags,
+ 		   void *priv)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline void kernfs_destroy_root(struct kernfs_root *root) { }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_dir_ns(struct kernfs_node *parent, const char *name,
+ 		     umode_t mode, void *priv, const void *ns)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline struct kernfs_node *
+ __kernfs_create_file(struct kernfs_node *parent, const char *name,
+ 		     umode_t mode, loff_t size, const struct kernfs_ops *ops,
+ 		     void *priv, const void *ns, bool name_is_static,
+ 		     struct lock_class_key *key)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_link(struct kernfs_node *parent, const char *name,
+ 		   struct kernfs_node *target)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline void kernfs_activate(struct kernfs_node *kn) { }
+ 
+ static inline void kernfs_remove(struct kernfs_node *kn) { }
+ 
+ static inline bool kernfs_remove_self(struct kernfs_node *kn)
+ { return false; }
+ 
+ static inline int kernfs_remove_by_name_ns(struct kernfs_node *kn,
+ 					   const char *name, const void *ns)
+ { return -ENOSYS; }
+ 
+ static inline int kernfs_rename_ns(struct kernfs_node *kn,
+ 				   struct kernfs_node *new_parent,
+ 				   const char *new_name, const void *new_ns)
+ { return -ENOSYS; }
+ 
+ static inline int kernfs_setattr(struct kernfs_node *kn,
+ 				 const struct iattr *iattr)
+ { return -ENOSYS; }
+ 
+ static inline void kernfs_notify(struct kernfs_node *kn) { }
+ 
+ static inline const void *kernfs_super_ns(struct super_block *sb)
+ { return NULL; }
+ 
+ static inline struct dentry *
+ kernfs_mount_ns(struct file_system_type *fs_type, int flags,
+ 		struct kernfs_root *root, bool *new_sb_created, const void *ns)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline void kernfs_kill_sb(struct super_block *sb) { }
+ 
+ static inline void kernfs_init(void) { }
+ 
+ #endif	/* CONFIG_KERNFS */
+ 
+ static inline struct kernfs_node *
+ kernfs_find_and_get(struct kernfs_node *kn, const char *name)
+ {
+ 	return kernfs_find_and_get_ns(kn, name, NULL);
+ }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_dir(struct kernfs_node *parent, const char *name, umode_t mode,
+ 		  void *priv)
+ {
+ 	return kernfs_create_dir_ns(parent, name, mode, priv, NULL);
+ }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_file_ns(struct kernfs_node *parent, const char *name,
+ 		      umode_t mode, loff_t size, const struct kernfs_ops *ops,
+ 		      void *priv, const void *ns)
+ {
+ 	struct lock_class_key *key = NULL;
+ 
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	key = (struct lock_class_key *)&ops->lockdep_key;
+ #endif
+ 	return __kernfs_create_file(parent, name, mode, size, ops, priv, ns,
+ 				    false, key);
+ }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_file(struct kernfs_node *parent, const char *name, umode_t mode,
+ 		   loff_t size, const struct kernfs_ops *ops, void *priv)
+ {
+ 	return kernfs_create_file_ns(parent, name, mode, size, ops, priv, NULL);
+ }
+ 
+ static inline int kernfs_remove_by_name(struct kernfs_node *parent,
+ 					const char *name)
+ {
+ 	return kernfs_remove_by_name_ns(parent, name, NULL);
+ }
+ 
+ static inline int kernfs_rename(struct kernfs_node *kn,
+ 				struct kernfs_node *new_parent,
+ 				const char *new_name)
+ {
+ 	return kernfs_rename_ns(kn, new_parent, new_name, NULL);
+ }
+ 
+ static inline struct dentry *
+ kernfs_mount(struct file_system_type *fs_type, int flags,
+ 	     struct kernfs_root *root, bool *new_sb_created)
+ {
+ 	return kernfs_mount_ns(fs_type, flags, root, new_sb_created, NULL);
+ }
++>>>>>>> 555724a831b4 (kernfs, sysfs, cgroup: restrict extra perm check on open to sysfs)
  
  #endif	/* __LINUX_KERNFS_H */
* Unmerged path fs/kernfs/file.c
* Unmerged path fs/sysfs/mount.c
* Unmerged path include/linux/kernfs.h
