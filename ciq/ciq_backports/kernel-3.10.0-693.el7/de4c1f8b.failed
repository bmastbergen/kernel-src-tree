flow_dissector: Fix function argument ordering dependency

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Tom Herbert <tom@herbertland.com>
commit de4c1f8ba302ccf4f2b3b17dc614b0a0b14d351a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/de4c1f8b.failed

Commit c6cc1ca7f4d70c ("flowi: Abstract out functions to get flow hash
based on flowi") introduced a bug in __skb_set_sw_hash where we
require a dependency on evaluating arguments in a function in order.
There is no such ordering enforced in C, so this incorrect. This
patch fixes that by splitting out the arguments. This bug was
found via a compiler warning that keys may be uninitialized.

	Signed-off-by: Tom Herbert <tom@herbertland.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit de4c1f8ba302ccf4f2b3b17dc614b0a0b14d351a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/skbuff.h
diff --cc include/linux/skbuff.h
index dcb8575fa615,eabfb810bc62..000000000000
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@@ -1001,6 -950,120 +1001,123 @@@ static inline void skb_clear_hash_if_no
  		skb_clear_hash(skb);
  }
  
++<<<<<<< HEAD
++=======
+ static inline void
+ __skb_set_hash(struct sk_buff *skb, __u32 hash, bool is_sw, bool is_l4)
+ {
+ 	skb->l4_hash = is_l4;
+ 	skb->sw_hash = is_sw;
+ 	skb->hash = hash;
+ }
+ 
+ static inline void
+ skb_set_hash(struct sk_buff *skb, __u32 hash, enum pkt_hash_types type)
+ {
+ 	/* Used by drivers to set hash from HW */
+ 	__skb_set_hash(skb, hash, false, type == PKT_HASH_TYPE_L4);
+ }
+ 
+ static inline void
+ __skb_set_sw_hash(struct sk_buff *skb, __u32 hash, bool is_l4)
+ {
+ 	__skb_set_hash(skb, hash, true, is_l4);
+ }
+ 
+ void __skb_get_hash(struct sk_buff *skb);
+ u32 skb_get_poff(const struct sk_buff *skb);
+ u32 __skb_get_poff(const struct sk_buff *skb, void *data,
+ 		   const struct flow_keys *keys, int hlen);
+ __be32 __skb_flow_get_ports(const struct sk_buff *skb, int thoff, u8 ip_proto,
+ 			    void *data, int hlen_proto);
+ 
+ static inline __be32 skb_flow_get_ports(const struct sk_buff *skb,
+ 					int thoff, u8 ip_proto)
+ {
+ 	return __skb_flow_get_ports(skb, thoff, ip_proto, NULL, 0);
+ }
+ 
+ void skb_flow_dissector_init(struct flow_dissector *flow_dissector,
+ 			     const struct flow_dissector_key *key,
+ 			     unsigned int key_count);
+ 
+ bool __skb_flow_dissect(const struct sk_buff *skb,
+ 			struct flow_dissector *flow_dissector,
+ 			void *target_container,
+ 			void *data, __be16 proto, int nhoff, int hlen,
+ 			unsigned int flags);
+ 
+ static inline bool skb_flow_dissect(const struct sk_buff *skb,
+ 				    struct flow_dissector *flow_dissector,
+ 				    void *target_container, unsigned int flags)
+ {
+ 	return __skb_flow_dissect(skb, flow_dissector, target_container,
+ 				  NULL, 0, 0, 0, flags);
+ }
+ 
+ static inline bool skb_flow_dissect_flow_keys(const struct sk_buff *skb,
+ 					      struct flow_keys *flow,
+ 					      unsigned int flags)
+ {
+ 	memset(flow, 0, sizeof(*flow));
+ 	return __skb_flow_dissect(skb, &flow_keys_dissector, flow,
+ 				  NULL, 0, 0, 0, flags);
+ }
+ 
+ static inline bool skb_flow_dissect_flow_keys_buf(struct flow_keys *flow,
+ 						  void *data, __be16 proto,
+ 						  int nhoff, int hlen,
+ 						  unsigned int flags)
+ {
+ 	memset(flow, 0, sizeof(*flow));
+ 	return __skb_flow_dissect(NULL, &flow_keys_buf_dissector, flow,
+ 				  data, proto, nhoff, hlen, flags);
+ }
+ 
+ static inline __u32 skb_get_hash(struct sk_buff *skb)
+ {
+ 	if (!skb->l4_hash && !skb->sw_hash)
+ 		__skb_get_hash(skb);
+ 
+ 	return skb->hash;
+ }
+ 
+ __u32 __skb_get_hash_flowi6(struct sk_buff *skb, struct flowi6 *fl6);
+ 
+ static inline __u32 skb_get_hash_flowi6(struct sk_buff *skb, struct flowi6 *fl6)
+ {
+ 	if (!skb->l4_hash && !skb->sw_hash) {
+ 		struct flow_keys keys;
+ 		__u32 hash = __get_hash_from_flowi6(fl6, &keys);
+ 
+ 		__skb_set_sw_hash(skb, hash, flow_keys_have_l4(&keys));
+ 	}
+ 
+ 	return skb->hash;
+ }
+ 
+ __u32 __skb_get_hash_flowi4(struct sk_buff *skb, struct flowi4 *fl);
+ 
+ static inline __u32 skb_get_hash_flowi4(struct sk_buff *skb, struct flowi4 *fl4)
+ {
+ 	if (!skb->l4_hash && !skb->sw_hash) {
+ 		struct flow_keys keys;
+ 		__u32 hash = __get_hash_from_flowi4(fl4, &keys);
+ 
+ 		__skb_set_sw_hash(skb, hash, flow_keys_have_l4(&keys));
+ 	}
+ 
+ 	return skb->hash;
+ }
+ 
+ __u32 skb_get_hash_perturb(const struct sk_buff *skb, u32 perturb);
+ 
+ static inline __u32 skb_get_hash_raw(const struct sk_buff *skb)
+ {
+ 	return skb->hash;
+ }
+ 
++>>>>>>> de4c1f8ba302 (flow_dissector: Fix function argument ordering dependency)
  static inline void skb_copy_hash(struct sk_buff *to, const struct sk_buff *from)
  {
  	to->hash = from->hash;
* Unmerged path include/linux/skbuff.h
