blk-mq: Introduce blk_mq_hctx_stopped()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Bart Van Assche <bart.vanassche@sandisk.com>
commit 5d1b25c1ecabb37f8eb58c8e9dd74f77f703e5d9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/5d1b25c1.failed

Multiple functions test the BLK_MQ_S_STOPPED bit so introduce
a helper function that performs this test.

	Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
	Reviewed-by: Ming Lei <tom.leiming@gmail.com>
	Reviewed-by: Hannes Reinecke <hare@suse.com>
	Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
	Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 5d1b25c1ecabb37f8eb58c8e9dd74f77f703e5d9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq.c
diff --cc block/blk-mq.c
index 5a93dd7c2ec2,2864e191cc86..000000000000
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@@ -878,11 -910,11 +878,11 @@@ static int blk_mq_hctx_next_cpu(struct 
  
  void blk_mq_run_hw_queue(struct blk_mq_hw_ctx *hctx, bool async)
  {
- 	if (unlikely(test_bit(BLK_MQ_S_STOPPED, &hctx->state) ||
- 	    !blk_mq_hw_queue_mapped(hctx)))
+ 	if (unlikely(blk_mq_hctx_stopped(hctx) ||
+ 		     !blk_mq_hw_queue_mapped(hctx)))
  		return;
  
 -	if (!async && !(hctx->flags & BLK_MQ_F_BLOCKING)) {
 +	if (!async) {
  		int cpu = get_cpu();
  		if (cpumask_test_cpu(cpu, hctx->cpumask)) {
  			__blk_mq_run_hw_queue(hctx);
@@@ -1308,11 -1316,11 +1308,19 @@@ static void blk_mq_make_request(struct 
  			old_rq = rq;
  		blk_mq_put_ctx(data.ctx);
  		if (!old_rq)
++<<<<<<< HEAD
 +			return;
 +		if (!blk_mq_direct_issue_request(old_rq))
 +			return;
 +		blk_mq_insert_request(old_rq, false, true, true);
 +		return;
++=======
+ 			goto done;
+ 		if (blk_mq_hctx_stopped(data.hctx) ||
+ 		    blk_mq_direct_issue_request(old_rq, &cookie) != 0)
+ 			blk_mq_insert_request(old_rq, false, true, true);
+ 		goto done;
++>>>>>>> 5d1b25c1ecab (blk-mq: Introduce blk_mq_hctx_stopped())
  	}
  
  	if (!blk_mq_merge_queue_io(data.hctx, data.ctx, rq, bio)) {
* Unmerged path block/blk-mq.c
diff --git a/block/blk-mq.h b/block/blk-mq.h
index 5da28965c4af..624133fd5b91 100644
--- a/block/blk-mq.h
+++ b/block/blk-mq.h
@@ -120,6 +120,11 @@ static inline void blk_mq_set_alloc_data(struct blk_mq_alloc_data *data,
 	data->hctx = hctx;
 }
 
+static inline bool blk_mq_hctx_stopped(struct blk_mq_hw_ctx *hctx)
+{
+	return test_bit(BLK_MQ_S_STOPPED, &hctx->state);
+}
+
 static inline bool blk_mq_hw_queue_mapped(struct blk_mq_hw_ctx *hctx)
 {
 	return hctx->nr_ctx && hctx->tags;
