amd-xgbe: Add support for MDIO attached PHYs

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Lendacky, Thomas <Thomas.Lendacky@amd.com>
commit 732f2ab7afb975755dcfbdcbe6eafe42e8cdc1d4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/732f2ab7.failed

Use the phylib support in the kernel to communicate with and control an
MDIO attached PHY. Use the hardware's MDIO communication mechanism to
communicate with the PHY.

	Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 732f2ab7afb975755dcfbdcbe6eafe42e8cdc1d4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/amd/xgbe/xgbe-common.h
#	drivers/net/ethernet/amd/xgbe/xgbe-dev.c
#	drivers/net/ethernet/amd/xgbe/xgbe-drv.c
#	drivers/net/ethernet/amd/xgbe/xgbe-main.c
#	drivers/net/ethernet/amd/xgbe/xgbe-phy-v2.c
#	drivers/net/ethernet/amd/xgbe/xgbe.h
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-common.h
index 3373e9ef2003,ecd4f4dce572..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-common.h
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-common.h
@@@ -385,10 -416,38 +390,39 @@@
  #define MAC_ISR_MMCTXIS_WIDTH		1
  #define MAC_ISR_PMTIS_INDEX		4
  #define MAC_ISR_PMTIS_WIDTH		1
++<<<<<<< HEAD
++=======
+ #define MAC_ISR_SMI_INDEX		1
+ #define MAC_ISR_SMI_WIDTH		1
+ #define MAC_ISR_TSIS_INDEX		12
+ #define MAC_ISR_TSIS_WIDTH		1
++>>>>>>> 732f2ab7afb9 (amd-xgbe: Add support for MDIO attached PHYs)
  #define MAC_MACA1HR_AE_INDEX		31
  #define MAC_MACA1HR_AE_WIDTH		1
+ #define MAC_MDIOIER_SNGLCOMPIE_INDEX	12
+ #define MAC_MDIOIER_SNGLCOMPIE_WIDTH	1
+ #define MAC_MDIOISR_SNGLCOMPINT_INDEX	12
+ #define MAC_MDIOISR_SNGLCOMPINT_WIDTH	1
+ #define MAC_MDIOSCAR_DA_INDEX		21
+ #define MAC_MDIOSCAR_DA_WIDTH		5
+ #define MAC_MDIOSCAR_PA_INDEX		16
+ #define MAC_MDIOSCAR_PA_WIDTH		5
+ #define MAC_MDIOSCAR_RA_INDEX		0
+ #define MAC_MDIOSCAR_RA_WIDTH		16
+ #define MAC_MDIOSCAR_REG_INDEX		0
+ #define MAC_MDIOSCAR_REG_WIDTH		21
+ #define MAC_MDIOSCCDR_BUSY_INDEX	22
+ #define MAC_MDIOSCCDR_BUSY_WIDTH	1
+ #define MAC_MDIOSCCDR_CMD_INDEX		16
+ #define MAC_MDIOSCCDR_CMD_WIDTH		2
+ #define MAC_MDIOSCCDR_CR_INDEX		19
+ #define MAC_MDIOSCCDR_CR_WIDTH		3
+ #define MAC_MDIOSCCDR_DATA_INDEX	0
+ #define MAC_MDIOSCCDR_DATA_WIDTH	16
+ #define MAC_MDIOSCCDR_SADDR_INDEX	18
+ #define MAC_MDIOSCCDR_SADDR_WIDTH	1
  #define MAC_PFR_HMC_INDEX		2
  #define MAC_PFR_HMC_WIDTH		1
 -#define MAC_PFR_HPF_INDEX		10
 -#define MAC_PFR_HPF_WIDTH		1
  #define MAC_PFR_HUC_INDEX		1
  #define MAC_PFR_HUC_WIDTH		1
  #define MAC_PFR_PM_INDEX		4
@@@ -743,16 -887,240 +777,242 @@@
  #define MTL_TSA_SP			0x00
  #define MTL_TSA_ETS			0x02
  
 -/* PCS register offsets */
 -#define PCS_V1_WINDOW_SELECT		0x03fc
 -#define PCS_V2_WINDOW_DEF		0x9060
 -#define PCS_V2_WINDOW_SELECT		0x9064
  
 -/* PCS register entry bit positions and sizes */
 -#define PCS_V2_WINDOW_DEF_OFFSET_INDEX	6
 -#define PCS_V2_WINDOW_DEF_OFFSET_WIDTH	14
 -#define PCS_V2_WINDOW_DEF_SIZE_INDEX	2
 -#define PCS_V2_WINDOW_DEF_SIZE_WIDTH	4
 +/* PCS MMD select register offset
 + *  The MMD select register is used for accessing PCS registers
 + *  when the underlying APB3 interface is using indirect addressing.
 + *  Indirect addressing requires accessing registers in two phases,
 + *  an address phase and a data phase.  The address phases requires
 + *  writing an address selection value to the MMD select regiesters.
 + */
 +#define PCS_MMD_SELECT			0xff
  
++<<<<<<< HEAD
++=======
+ /* SerDes integration register offsets */
+ #define SIR0_KR_RT_1			0x002c
+ #define SIR0_STATUS			0x0040
+ #define SIR1_SPEED			0x0000
+ 
+ /* SerDes integration register entry bit positions and sizes */
+ #define SIR0_KR_RT_1_RESET_INDEX	11
+ #define SIR0_KR_RT_1_RESET_WIDTH	1
+ #define SIR0_STATUS_RX_READY_INDEX	0
+ #define SIR0_STATUS_RX_READY_WIDTH	1
+ #define SIR0_STATUS_TX_READY_INDEX	8
+ #define SIR0_STATUS_TX_READY_WIDTH	1
+ #define SIR1_SPEED_CDR_RATE_INDEX	12
+ #define SIR1_SPEED_CDR_RATE_WIDTH	4
+ #define SIR1_SPEED_DATARATE_INDEX	4
+ #define SIR1_SPEED_DATARATE_WIDTH	2
+ #define SIR1_SPEED_PLLSEL_INDEX		3
+ #define SIR1_SPEED_PLLSEL_WIDTH		1
+ #define SIR1_SPEED_RATECHANGE_INDEX	6
+ #define SIR1_SPEED_RATECHANGE_WIDTH	1
+ #define SIR1_SPEED_TXAMP_INDEX		8
+ #define SIR1_SPEED_TXAMP_WIDTH		4
+ #define SIR1_SPEED_WORDMODE_INDEX	0
+ #define SIR1_SPEED_WORDMODE_WIDTH	3
+ 
+ /* SerDes RxTx register offsets */
+ #define RXTX_REG6			0x0018
+ #define RXTX_REG20			0x0050
+ #define RXTX_REG22			0x0058
+ #define RXTX_REG114			0x01c8
+ #define RXTX_REG129			0x0204
+ 
+ /* SerDes RxTx register entry bit positions and sizes */
+ #define RXTX_REG6_RESETB_RXD_INDEX	8
+ #define RXTX_REG6_RESETB_RXD_WIDTH	1
+ #define RXTX_REG20_BLWC_ENA_INDEX	2
+ #define RXTX_REG20_BLWC_ENA_WIDTH	1
+ #define RXTX_REG114_PQ_REG_INDEX	9
+ #define RXTX_REG114_PQ_REG_WIDTH	7
+ #define RXTX_REG129_RXDFE_CONFIG_INDEX	14
+ #define RXTX_REG129_RXDFE_CONFIG_WIDTH	2
+ 
+ /* MAC Control register offsets */
+ #define XP_PROP_0			0x0000
+ #define XP_PROP_1			0x0004
+ #define XP_PROP_2			0x0008
+ #define XP_PROP_3			0x000c
+ #define XP_PROP_4			0x0010
+ #define XP_PROP_5			0x0014
+ #define XP_MAC_ADDR_LO			0x0020
+ #define XP_MAC_ADDR_HI			0x0024
+ #define XP_ECC_ISR			0x0030
+ #define XP_ECC_IER			0x0034
+ #define XP_ECC_CNT0			0x003c
+ #define XP_ECC_CNT1			0x0040
+ #define XP_DRIVER_INT_REQ		0x0060
+ #define XP_DRIVER_INT_RO		0x0064
+ #define XP_DRIVER_SCRATCH_0		0x0068
+ #define XP_DRIVER_SCRATCH_1		0x006c
+ #define XP_INT_EN			0x0078
+ #define XP_I2C_MUTEX			0x0080
+ #define XP_MDIO_MUTEX			0x0084
+ 
+ /* MAC Control register entry bit positions and sizes */
+ #define XP_DRIVER_INT_REQ_REQUEST_INDEX		0
+ #define XP_DRIVER_INT_REQ_REQUEST_WIDTH		1
+ #define XP_DRIVER_INT_RO_STATUS_INDEX		0
+ #define XP_DRIVER_INT_RO_STATUS_WIDTH		1
+ #define XP_DRIVER_SCRATCH_0_COMMAND_INDEX	0
+ #define XP_DRIVER_SCRATCH_0_COMMAND_WIDTH	8
+ #define XP_DRIVER_SCRATCH_0_SUB_COMMAND_INDEX	8
+ #define XP_DRIVER_SCRATCH_0_SUB_COMMAND_WIDTH	8
+ #define XP_ECC_CNT0_RX_DED_INDEX		24
+ #define XP_ECC_CNT0_RX_DED_WIDTH		8
+ #define XP_ECC_CNT0_RX_SEC_INDEX		16
+ #define XP_ECC_CNT0_RX_SEC_WIDTH		8
+ #define XP_ECC_CNT0_TX_DED_INDEX		8
+ #define XP_ECC_CNT0_TX_DED_WIDTH		8
+ #define XP_ECC_CNT0_TX_SEC_INDEX		0
+ #define XP_ECC_CNT0_TX_SEC_WIDTH		8
+ #define XP_ECC_CNT1_DESC_DED_INDEX		8
+ #define XP_ECC_CNT1_DESC_DED_WIDTH		8
+ #define XP_ECC_CNT1_DESC_SEC_INDEX		0
+ #define XP_ECC_CNT1_DESC_SEC_WIDTH		8
+ #define XP_ECC_IER_DESC_DED_INDEX		0
+ #define XP_ECC_IER_DESC_DED_WIDTH		1
+ #define XP_ECC_IER_DESC_SEC_INDEX		1
+ #define XP_ECC_IER_DESC_SEC_WIDTH		1
+ #define XP_ECC_IER_RX_DED_INDEX			2
+ #define XP_ECC_IER_RX_DED_WIDTH			1
+ #define XP_ECC_IER_RX_SEC_INDEX			3
+ #define XP_ECC_IER_RX_SEC_WIDTH			1
+ #define XP_ECC_IER_TX_DED_INDEX			4
+ #define XP_ECC_IER_TX_DED_WIDTH			1
+ #define XP_ECC_IER_TX_SEC_INDEX			5
+ #define XP_ECC_IER_TX_SEC_WIDTH			1
+ #define XP_ECC_ISR_DESC_DED_INDEX		0
+ #define XP_ECC_ISR_DESC_DED_WIDTH		1
+ #define XP_ECC_ISR_DESC_SEC_INDEX		1
+ #define XP_ECC_ISR_DESC_SEC_WIDTH		1
+ #define XP_ECC_ISR_RX_DED_INDEX			2
+ #define XP_ECC_ISR_RX_DED_WIDTH			1
+ #define XP_ECC_ISR_RX_SEC_INDEX			3
+ #define XP_ECC_ISR_RX_SEC_WIDTH			1
+ #define XP_ECC_ISR_TX_DED_INDEX			4
+ #define XP_ECC_ISR_TX_DED_WIDTH			1
+ #define XP_ECC_ISR_TX_SEC_INDEX			5
+ #define XP_ECC_ISR_TX_SEC_WIDTH			1
+ #define XP_I2C_MUTEX_BUSY_INDEX			31
+ #define XP_I2C_MUTEX_BUSY_WIDTH			1
+ #define XP_I2C_MUTEX_ID_INDEX			29
+ #define XP_I2C_MUTEX_ID_WIDTH			2
+ #define XP_I2C_MUTEX_ACTIVE_INDEX		0
+ #define XP_I2C_MUTEX_ACTIVE_WIDTH		1
+ #define XP_MAC_ADDR_HI_VALID_INDEX		31
+ #define XP_MAC_ADDR_HI_VALID_WIDTH		1
+ #define XP_PROP_0_CONN_TYPE_INDEX		28
+ #define XP_PROP_0_CONN_TYPE_WIDTH		3
+ #define XP_PROP_0_MDIO_ADDR_INDEX		16
+ #define XP_PROP_0_MDIO_ADDR_WIDTH		5
+ #define XP_PROP_0_PORT_ID_INDEX			0
+ #define XP_PROP_0_PORT_ID_WIDTH			8
+ #define XP_PROP_0_PORT_MODE_INDEX		8
+ #define XP_PROP_0_PORT_MODE_WIDTH		4
+ #define XP_PROP_0_PORT_SPEEDS_INDEX		23
+ #define XP_PROP_0_PORT_SPEEDS_WIDTH		4
+ #define XP_PROP_1_MAX_RX_DMA_INDEX		24
+ #define XP_PROP_1_MAX_RX_DMA_WIDTH		5
+ #define XP_PROP_1_MAX_RX_QUEUES_INDEX		8
+ #define XP_PROP_1_MAX_RX_QUEUES_WIDTH		5
+ #define XP_PROP_1_MAX_TX_DMA_INDEX		16
+ #define XP_PROP_1_MAX_TX_DMA_WIDTH		5
+ #define XP_PROP_1_MAX_TX_QUEUES_INDEX		0
+ #define XP_PROP_1_MAX_TX_QUEUES_WIDTH		5
+ #define XP_PROP_2_RX_FIFO_SIZE_INDEX		16
+ #define XP_PROP_2_RX_FIFO_SIZE_WIDTH		16
+ #define XP_PROP_2_TX_FIFO_SIZE_INDEX		0
+ #define XP_PROP_2_TX_FIFO_SIZE_WIDTH		16
+ #define XP_PROP_3_GPIO_MASK_INDEX		28
+ #define XP_PROP_3_GPIO_MASK_WIDTH		4
+ #define XP_PROP_3_GPIO_MOD_ABS_INDEX		20
+ #define XP_PROP_3_GPIO_MOD_ABS_WIDTH		4
+ #define XP_PROP_3_GPIO_RATE_SELECT_INDEX	16
+ #define XP_PROP_3_GPIO_RATE_SELECT_WIDTH	4
+ #define XP_PROP_3_GPIO_RX_LOS_INDEX		24
+ #define XP_PROP_3_GPIO_RX_LOS_WIDTH		4
+ #define XP_PROP_3_GPIO_TX_FAULT_INDEX		12
+ #define XP_PROP_3_GPIO_TX_FAULT_WIDTH		4
+ #define XP_PROP_3_GPIO_ADDR_INDEX		8
+ #define XP_PROP_3_GPIO_ADDR_WIDTH		3
+ #define XP_PROP_3_MDIO_RESET_INDEX		0
+ #define XP_PROP_3_MDIO_RESET_WIDTH		2
+ #define XP_PROP_3_MDIO_RESET_I2C_ADDR_INDEX	8
+ #define XP_PROP_3_MDIO_RESET_I2C_ADDR_WIDTH	3
+ #define XP_PROP_3_MDIO_RESET_I2C_GPIO_INDEX	12
+ #define XP_PROP_3_MDIO_RESET_I2C_GPIO_WIDTH	4
+ #define XP_PROP_3_MDIO_RESET_INT_GPIO_INDEX	4
+ #define XP_PROP_3_MDIO_RESET_INT_GPIO_WIDTH	2
+ #define XP_PROP_4_MUX_ADDR_HI_INDEX		8
+ #define XP_PROP_4_MUX_ADDR_HI_WIDTH		5
+ #define XP_PROP_4_MUX_ADDR_LO_INDEX		0
+ #define XP_PROP_4_MUX_ADDR_LO_WIDTH		3
+ #define XP_PROP_4_MUX_CHAN_INDEX		4
+ #define XP_PROP_4_MUX_CHAN_WIDTH		3
+ 
+ /* I2C Control register offsets */
+ #define IC_CON					0x0000
+ #define IC_TAR					0x0004
+ #define IC_DATA_CMD				0x0010
+ #define IC_INTR_STAT				0x002c
+ #define IC_INTR_MASK				0x0030
+ #define IC_RAW_INTR_STAT			0x0034
+ #define IC_CLR_INTR				0x0040
+ #define IC_CLR_TX_ABRT				0x0054
+ #define IC_CLR_STOP_DET				0x0060
+ #define IC_ENABLE				0x006c
+ #define IC_TXFLR				0x0074
+ #define IC_RXFLR				0x0078
+ #define IC_TX_ABRT_SOURCE			0x0080
+ #define IC_ENABLE_STATUS			0x009c
+ #define IC_COMP_PARAM_1				0x00f4
+ 
+ /* I2C Control register entry bit positions and sizes */
+ #define IC_COMP_PARAM_1_MAX_SPEED_MODE_INDEX	2
+ #define IC_COMP_PARAM_1_MAX_SPEED_MODE_WIDTH	2
+ #define IC_COMP_PARAM_1_RX_BUFFER_DEPTH_INDEX	8
+ #define IC_COMP_PARAM_1_RX_BUFFER_DEPTH_WIDTH	8
+ #define IC_COMP_PARAM_1_TX_BUFFER_DEPTH_INDEX	16
+ #define IC_COMP_PARAM_1_TX_BUFFER_DEPTH_WIDTH	8
+ #define IC_CON_MASTER_MODE_INDEX		0
+ #define IC_CON_MASTER_MODE_WIDTH		1
+ #define IC_CON_RESTART_EN_INDEX			5
+ #define IC_CON_RESTART_EN_WIDTH			1
+ #define IC_CON_RX_FIFO_FULL_HOLD_INDEX		9
+ #define IC_CON_RX_FIFO_FULL_HOLD_WIDTH		1
+ #define IC_CON_SLAVE_DISABLE_INDEX		6
+ #define IC_CON_SLAVE_DISABLE_WIDTH		1
+ #define IC_CON_SPEED_INDEX			1
+ #define IC_CON_SPEED_WIDTH			2
+ #define IC_DATA_CMD_CMD_INDEX			8
+ #define IC_DATA_CMD_CMD_WIDTH			1
+ #define IC_DATA_CMD_STOP_INDEX			9
+ #define IC_DATA_CMD_STOP_WIDTH			1
+ #define IC_ENABLE_ABORT_INDEX			1
+ #define IC_ENABLE_ABORT_WIDTH			1
+ #define IC_ENABLE_EN_INDEX			0
+ #define IC_ENABLE_EN_WIDTH			1
+ #define IC_ENABLE_STATUS_EN_INDEX		0
+ #define IC_ENABLE_STATUS_EN_WIDTH		1
+ #define IC_INTR_MASK_TX_EMPTY_INDEX		4
+ #define IC_INTR_MASK_TX_EMPTY_WIDTH		1
+ #define IC_RAW_INTR_STAT_RX_FULL_INDEX		2
+ #define IC_RAW_INTR_STAT_RX_FULL_WIDTH		1
+ #define IC_RAW_INTR_STAT_STOP_DET_INDEX		9
+ #define IC_RAW_INTR_STAT_STOP_DET_WIDTH		1
+ #define IC_RAW_INTR_STAT_TX_ABRT_INDEX		6
+ #define IC_RAW_INTR_STAT_TX_ABRT_WIDTH		1
+ #define IC_RAW_INTR_STAT_TX_EMPTY_INDEX		4
+ #define IC_RAW_INTR_STAT_TX_EMPTY_WIDTH		1
+ 
+ /* I2C Control register value */
+ #define IC_TX_ABRT_7B_ADDR_NOACK		0x0001
+ #define IC_TX_ABRT_ARB_LOST			0x1000
++>>>>>>> 732f2ab7afb9 (amd-xgbe: Add support for MDIO attached PHYs)
  
  /* Descriptor/Packet entry bit positions and sizes */
  #define RX_PACKET_ERRORS_CRC_INDEX		2
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-dev.c
index de7b81d8b4ee,30056e24e1fc..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
@@@ -497,243 -722,90 +497,246 @@@ static void xgbe_enable_mac_interrupts(
  	/* Enable all counter interrupts */
  	XGMAC_IOWRITE_BITS(pdata, MMC_RIER, ALL_INTERRUPTS, 0xffffffff);
  	XGMAC_IOWRITE_BITS(pdata, MMC_TIER, ALL_INTERRUPTS, 0xffffffff);
+ 
+ 	/* Enable MDIO single command completion interrupt */
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_MDIOIER, SNGLCOMPIE, 1);
  }
  
 -static void xgbe_enable_ecc_interrupts(struct xgbe_prv_data *pdata)
 +static int xgbe_set_gmii_speed(struct xgbe_prv_data *pdata)
  {
 -	unsigned int ecc_isr, ecc_ier = 0;
 +	if (XGMAC_IOREAD_BITS(pdata, MAC_TCR, SS) == 0x3)
 +		return 0;
  
 -	if (!pdata->vdata->ecc_support)
 -		return;
 +	XGMAC_IOWRITE_BITS(pdata, MAC_TCR, SS, 0x3);
  
 -	/* Clear all the interrupts which are set */
 -	ecc_isr = XP_IOREAD(pdata, XP_ECC_ISR);
 -	XP_IOWRITE(pdata, XP_ECC_ISR, ecc_isr);
 +	return 0;
 +}
 +
 +static int xgbe_set_gmii_2500_speed(struct xgbe_prv_data *pdata)
 +{
 +	if (XGMAC_IOREAD_BITS(pdata, MAC_TCR, SS) == 0x2)
 +		return 0;
  
 -	/* Enable ECC interrupts */
 -	XP_SET_BITS(ecc_ier, XP_ECC_IER, TX_DED, 1);
 -	XP_SET_BITS(ecc_ier, XP_ECC_IER, TX_SEC, 1);
 -	XP_SET_BITS(ecc_ier, XP_ECC_IER, RX_DED, 1);
 -	XP_SET_BITS(ecc_ier, XP_ECC_IER, RX_SEC, 1);
 -	XP_SET_BITS(ecc_ier, XP_ECC_IER, DESC_DED, 1);
 -	XP_SET_BITS(ecc_ier, XP_ECC_IER, DESC_SEC, 1);
 +	XGMAC_IOWRITE_BITS(pdata, MAC_TCR, SS, 0x2);
  
 -	XP_IOWRITE(pdata, XP_ECC_IER, ecc_ier);
 +	return 0;
  }
  
 -static void xgbe_disable_ecc_ded(struct xgbe_prv_data *pdata)
 +static int xgbe_set_xgmii_speed(struct xgbe_prv_data *pdata)
  {
 -	unsigned int ecc_ier;
 +	if (XGMAC_IOREAD_BITS(pdata, MAC_TCR, SS) == 0)
 +		return 0;
  
 -	ecc_ier = XP_IOREAD(pdata, XP_ECC_IER);
 +	XGMAC_IOWRITE_BITS(pdata, MAC_TCR, SS, 0);
  
 -	/* Disable ECC DED interrupts */
 -	XP_SET_BITS(ecc_ier, XP_ECC_IER, TX_DED, 0);
 -	XP_SET_BITS(ecc_ier, XP_ECC_IER, RX_DED, 0);
 -	XP_SET_BITS(ecc_ier, XP_ECC_IER, DESC_DED, 0);
 +	return 0;
 +}
  
 -	XP_IOWRITE(pdata, XP_ECC_IER, ecc_ier);
 +static int xgbe_set_promiscuous_mode(struct xgbe_prv_data *pdata,
 +				     unsigned int enable)
 +{
 +	unsigned int val = enable ? 1 : 0;
 +
 +	if (XGMAC_IOREAD_BITS(pdata, MAC_PFR, PR) == val)
 +		return 0;
 +
 +	DBGPR("  %s promiscuous mode\n", enable ? "entering" : "leaving");
 +	XGMAC_IOWRITE_BITS(pdata, MAC_PFR, PR, val);
 +
 +	return 0;
  }
  
 -static void xgbe_disable_ecc_sec(struct xgbe_prv_data *pdata,
 -				 enum xgbe_ecc_sec sec)
 +static int xgbe_set_all_multicast_mode(struct xgbe_prv_data *pdata,
 +				       unsigned int enable)
  {
 -	unsigned int ecc_ier;
 +	unsigned int val = enable ? 1 : 0;
 +
 +	if (XGMAC_IOREAD_BITS(pdata, MAC_PFR, PM) == val)
 +		return 0;
  
 -	ecc_ier = XP_IOREAD(pdata, XP_ECC_IER);
 +	DBGPR("  %s allmulti mode\n", enable ? "entering" : "leaving");
 +	XGMAC_IOWRITE_BITS(pdata, MAC_PFR, PM, val);
  
 -	/* Disable ECC SEC interrupt */
 -	switch (sec) {
 -	case XGBE_ECC_SEC_TX:
 -	XP_SET_BITS(ecc_ier, XP_ECC_IER, TX_SEC, 0);
 -		break;
 -	case XGBE_ECC_SEC_RX:
 -	XP_SET_BITS(ecc_ier, XP_ECC_IER, RX_SEC, 0);
 -		break;
 -	case XGBE_ECC_SEC_DESC:
 -	XP_SET_BITS(ecc_ier, XP_ECC_IER, DESC_SEC, 0);
 -		break;
 +	return 0;
 +}
 +
 +static int xgbe_set_addn_mac_addrs(struct xgbe_prv_data *pdata,
 +				   unsigned int am_mode)
 +{
 +	struct netdev_hw_addr *ha;
 +	unsigned int mac_reg;
 +	unsigned int mac_addr_hi, mac_addr_lo;
 +	u8 *mac_addr;
 +	unsigned int i;
 +
 +	XGMAC_IOWRITE_BITS(pdata, MAC_PFR, HUC, 0);
 +	XGMAC_IOWRITE_BITS(pdata, MAC_PFR, HMC, 0);
 +
 +	i = 0;
 +	mac_reg = MAC_MACA1HR;
 +
 +	netdev_for_each_uc_addr(ha, pdata->netdev) {
 +		mac_addr_lo = 0;
 +		mac_addr_hi = 0;
 +		mac_addr = (u8 *)&mac_addr_lo;
 +		mac_addr[0] = ha->addr[0];
 +		mac_addr[1] = ha->addr[1];
 +		mac_addr[2] = ha->addr[2];
 +		mac_addr[3] = ha->addr[3];
 +		mac_addr = (u8 *)&mac_addr_hi;
 +		mac_addr[0] = ha->addr[4];
 +		mac_addr[1] = ha->addr[5];
 +
 +		DBGPR("  adding unicast address %pM at 0x%04x\n",
 +		      ha->addr, mac_reg);
 +
 +		XGMAC_SET_BITS(mac_addr_hi, MAC_MACA1HR, AE, 1);
 +
 +		XGMAC_IOWRITE(pdata, mac_reg, mac_addr_hi);
 +		mac_reg += MAC_MACA_INC;
 +		XGMAC_IOWRITE(pdata, mac_reg, mac_addr_lo);
 +		mac_reg += MAC_MACA_INC;
 +
 +		i++;
 +	}
 +
 +	if (!am_mode) {
 +		netdev_for_each_mc_addr(ha, pdata->netdev) {
 +			mac_addr_lo = 0;
 +			mac_addr_hi = 0;
 +			mac_addr = (u8 *)&mac_addr_lo;
 +			mac_addr[0] = ha->addr[0];
 +			mac_addr[1] = ha->addr[1];
 +			mac_addr[2] = ha->addr[2];
 +			mac_addr[3] = ha->addr[3];
 +			mac_addr = (u8 *)&mac_addr_hi;
 +			mac_addr[0] = ha->addr[4];
 +			mac_addr[1] = ha->addr[5];
 +
 +			DBGPR("  adding multicast address %pM at 0x%04x\n",
 +			      ha->addr, mac_reg);
 +
 +			XGMAC_SET_BITS(mac_addr_hi, MAC_MACA1HR, AE, 1);
 +
 +			XGMAC_IOWRITE(pdata, mac_reg, mac_addr_hi);
 +			mac_reg += MAC_MACA_INC;
 +			XGMAC_IOWRITE(pdata, mac_reg, mac_addr_lo);
 +			mac_reg += MAC_MACA_INC;
 +
 +			i++;
 +		}
 +	}
 +
 +	/* Clear remaining additional MAC address entries */
 +	for (; i < pdata->hw_feat.addn_mac; i++) {
 +		XGMAC_IOWRITE(pdata, mac_reg, 0);
 +		mac_reg += MAC_MACA_INC;
 +		XGMAC_IOWRITE(pdata, mac_reg, 0);
 +		mac_reg += MAC_MACA_INC;
  	}
  
 -	XP_IOWRITE(pdata, XP_ECC_IER, ecc_ier);
 +	return 0;
  }
  
 -static int xgbe_set_speed(struct xgbe_prv_data *pdata, int speed)
 +static int xgbe_set_mac_address(struct xgbe_prv_data *pdata, u8 *addr)
  {
 -	unsigned int ss;
 +	unsigned int mac_addr_hi, mac_addr_lo;
  
 -	switch (speed) {
 -	case SPEED_1000:
 -		ss = 0x03;
 -		break;
 -	case SPEED_2500:
 -		ss = 0x02;
 -		break;
 -	case SPEED_10000:
 -		ss = 0x00;
 -		break;
 -	default:
 -		return -EINVAL;
 +	mac_addr_hi = (addr[5] <<  8) | (addr[4] <<  0);
 +	mac_addr_lo = (addr[3] << 24) | (addr[2] << 16) |
 +		      (addr[1] <<  8) | (addr[0] <<  0);
 +
 +	XGMAC_IOWRITE(pdata, MAC_MACA0HR, mac_addr_hi);
 +	XGMAC_IOWRITE(pdata, MAC_MACA0LR, mac_addr_lo);
 +
 +	return 0;
 +}
 +
 +static int xgbe_read_mmd_regs(struct xgbe_prv_data *pdata, int prtad,
 +			      int mmd_reg)
 +{
 +	unsigned int mmd_address;
 +	int mmd_data;
 +
 +	if (mmd_reg & MII_ADDR_C45)
 +		mmd_address = mmd_reg & ~MII_ADDR_C45;
 +	else
 +		mmd_address = (pdata->mdio_mmd << 16) | (mmd_reg & 0xffff);
 +
 +	/* The PCS registers are accessed using mmio. The underlying APB3
 +	 * management interface uses indirect addressing to access the MMD
 +	 * register sets. This requires accessing of the PCS register in two
 +	 * phases, an address phase and a data phase.
 +	 *
 +	 * The mmio interface is based on 32-bit offsets and values. All
 +	 * register offsets must therefore be adjusted by left shifting the
 +	 * offset 2 bits and reading 32 bits of data.
 +	 */
 +	mutex_lock(&pdata->xpcs_mutex);
 +	XPCS_IOWRITE(pdata, PCS_MMD_SELECT << 2, mmd_address >> 8);
 +	mmd_data = XPCS_IOREAD(pdata, (mmd_address & 0xff) << 2);
 +	mutex_unlock(&pdata->xpcs_mutex);
 +
 +	return mmd_data;
 +}
 +
 +static void xgbe_write_mmd_regs(struct xgbe_prv_data *pdata, int prtad,
 +				int mmd_reg, int mmd_data)
 +{
 +	unsigned int mmd_address;
 +
 +	if (mmd_reg & MII_ADDR_C45)
 +		mmd_address = mmd_reg & ~MII_ADDR_C45;
 +	else
 +		mmd_address = (pdata->mdio_mmd << 16) | (mmd_reg & 0xffff);
 +
 +	/* If the PCS is changing modes, match the MAC speed to it */
 +	if (((mmd_address >> 16) == MDIO_MMD_PCS) &&
 +	    ((mmd_address & 0xffff) == MDIO_CTRL2)) {
 +		struct phy_device *phydev = pdata->phydev;
 +
 +		if (mmd_data & MDIO_PCS_CTRL2_TYPE) {
 +			/* KX mode */
 +			if (phydev->supported & SUPPORTED_1000baseKX_Full)
 +				xgbe_set_gmii_speed(pdata);
 +			else
 +				xgbe_set_gmii_2500_speed(pdata);
 +		} else {
 +			/* KR mode */
 +			xgbe_set_xgmii_speed(pdata);
 +		}
  	}
  
 -	if (XGMAC_IOREAD_BITS(pdata, MAC_TCR, SS) != ss)
 -		XGMAC_IOWRITE_BITS(pdata, MAC_TCR, SS, ss);
 +	/* The PCS registers are accessed using mmio. The underlying APB3
 +	 * management interface uses indirect addressing to access the MMD
 +	 * register sets. This requires accessing of the PCS register in two
 +	 * phases, an address phase and a data phase.
 +	 *
 +	 * The mmio interface is based on 32-bit offsets and values. All
 +	 * register offsets must therefore be adjusted by left shifting the
 +	 * offset 2 bits and reading 32 bits of data.
 +	 */
 +	mutex_lock(&pdata->xpcs_mutex);
 +	XPCS_IOWRITE(pdata, PCS_MMD_SELECT << 2, mmd_address >> 8);
 +	XPCS_IOWRITE(pdata, (mmd_address & 0xff) << 2, mmd_data);
 +	mutex_unlock(&pdata->xpcs_mutex);
 +}
 +
 +static int xgbe_tx_complete(struct xgbe_ring_desc *rdesc)
 +{
 +	return !XGMAC_GET_BITS_LE(rdesc->desc3, TX_NORMAL_DESC3, OWN);
 +}
 +
 +static int xgbe_disable_rx_csum(struct xgbe_prv_data *pdata)
 +{
 +	XGMAC_IOWRITE_BITS(pdata, MAC_RCR, IPC, 0);
 +
 +	return 0;
 +}
 +
 +static int xgbe_enable_rx_csum(struct xgbe_prv_data *pdata)
 +{
 +	XGMAC_IOWRITE_BITS(pdata, MAC_RCR, IPC, 1);
  
  	return 0;
  }
@@@ -765,6 -837,530 +768,533 @@@ static int xgbe_disable_rx_vlan_strippi
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static int xgbe_enable_rx_vlan_filtering(struct xgbe_prv_data *pdata)
+ {
+ 	/* Enable VLAN filtering */
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_PFR, VTFE, 1);
+ 
+ 	/* Enable VLAN Hash Table filtering */
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_VLANTR, VTHM, 1);
+ 
+ 	/* Disable VLAN tag inverse matching */
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_VLANTR, VTIM, 0);
+ 
+ 	/* Only filter on the lower 12-bits of the VLAN tag */
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_VLANTR, ETV, 1);
+ 
+ 	/* In order for the VLAN Hash Table filtering to be effective,
+ 	 * the VLAN tag identifier in the VLAN Tag Register must not
+ 	 * be zero.  Set the VLAN tag identifier to "1" to enable the
+ 	 * VLAN Hash Table filtering.  This implies that a VLAN tag of
+ 	 * 1 will always pass filtering.
+ 	 */
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_VLANTR, VL, 1);
+ 
+ 	return 0;
+ }
+ 
+ static int xgbe_disable_rx_vlan_filtering(struct xgbe_prv_data *pdata)
+ {
+ 	/* Disable VLAN filtering */
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_PFR, VTFE, 0);
+ 
+ 	return 0;
+ }
+ 
+ static u32 xgbe_vid_crc32_le(__le16 vid_le)
+ {
+ 	u32 poly = 0xedb88320;	/* CRCPOLY_LE */
+ 	u32 crc = ~0;
+ 	u32 temp = 0;
+ 	unsigned char *data = (unsigned char *)&vid_le;
+ 	unsigned char data_byte = 0;
+ 	int i, bits;
+ 
+ 	bits = get_bitmask_order(VLAN_VID_MASK);
+ 	for (i = 0; i < bits; i++) {
+ 		if ((i % 8) == 0)
+ 			data_byte = data[i / 8];
+ 
+ 		temp = ((crc & 1) ^ data_byte) & 1;
+ 		crc >>= 1;
+ 		data_byte >>= 1;
+ 
+ 		if (temp)
+ 			crc ^= poly;
+ 	}
+ 
+ 	return crc;
+ }
+ 
+ static int xgbe_update_vlan_hash_table(struct xgbe_prv_data *pdata)
+ {
+ 	u32 crc;
+ 	u16 vid;
+ 	__le16 vid_le;
+ 	u16 vlan_hash_table = 0;
+ 
+ 	/* Generate the VLAN Hash Table value */
+ 	for_each_set_bit(vid, pdata->active_vlans, VLAN_N_VID) {
+ 		/* Get the CRC32 value of the VLAN ID */
+ 		vid_le = cpu_to_le16(vid);
+ 		crc = bitrev32(~xgbe_vid_crc32_le(vid_le)) >> 28;
+ 
+ 		vlan_hash_table |= (1 << crc);
+ 	}
+ 
+ 	/* Set the VLAN Hash Table filtering register */
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_VLANHTR, VLHT, vlan_hash_table);
+ 
+ 	return 0;
+ }
+ 
+ static int xgbe_set_promiscuous_mode(struct xgbe_prv_data *pdata,
+ 				     unsigned int enable)
+ {
+ 	unsigned int val = enable ? 1 : 0;
+ 
+ 	if (XGMAC_IOREAD_BITS(pdata, MAC_PFR, PR) == val)
+ 		return 0;
+ 
+ 	netif_dbg(pdata, drv, pdata->netdev, "%s promiscuous mode\n",
+ 		  enable ? "entering" : "leaving");
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_PFR, PR, val);
+ 
+ 	/* Hardware will still perform VLAN filtering in promiscuous mode */
+ 	if (enable) {
+ 		xgbe_disable_rx_vlan_filtering(pdata);
+ 	} else {
+ 		if (pdata->netdev->features & NETIF_F_HW_VLAN_CTAG_FILTER)
+ 			xgbe_enable_rx_vlan_filtering(pdata);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int xgbe_set_all_multicast_mode(struct xgbe_prv_data *pdata,
+ 				       unsigned int enable)
+ {
+ 	unsigned int val = enable ? 1 : 0;
+ 
+ 	if (XGMAC_IOREAD_BITS(pdata, MAC_PFR, PM) == val)
+ 		return 0;
+ 
+ 	netif_dbg(pdata, drv, pdata->netdev, "%s allmulti mode\n",
+ 		  enable ? "entering" : "leaving");
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_PFR, PM, val);
+ 
+ 	return 0;
+ }
+ 
+ static void xgbe_set_mac_reg(struct xgbe_prv_data *pdata,
+ 			     struct netdev_hw_addr *ha, unsigned int *mac_reg)
+ {
+ 	unsigned int mac_addr_hi, mac_addr_lo;
+ 	u8 *mac_addr;
+ 
+ 	mac_addr_lo = 0;
+ 	mac_addr_hi = 0;
+ 
+ 	if (ha) {
+ 		mac_addr = (u8 *)&mac_addr_lo;
+ 		mac_addr[0] = ha->addr[0];
+ 		mac_addr[1] = ha->addr[1];
+ 		mac_addr[2] = ha->addr[2];
+ 		mac_addr[3] = ha->addr[3];
+ 		mac_addr = (u8 *)&mac_addr_hi;
+ 		mac_addr[0] = ha->addr[4];
+ 		mac_addr[1] = ha->addr[5];
+ 
+ 		netif_dbg(pdata, drv, pdata->netdev,
+ 			  "adding mac address %pM at %#x\n",
+ 			  ha->addr, *mac_reg);
+ 
+ 		XGMAC_SET_BITS(mac_addr_hi, MAC_MACA1HR, AE, 1);
+ 	}
+ 
+ 	XGMAC_IOWRITE(pdata, *mac_reg, mac_addr_hi);
+ 	*mac_reg += MAC_MACA_INC;
+ 	XGMAC_IOWRITE(pdata, *mac_reg, mac_addr_lo);
+ 	*mac_reg += MAC_MACA_INC;
+ }
+ 
+ static void xgbe_set_mac_addn_addrs(struct xgbe_prv_data *pdata)
+ {
+ 	struct net_device *netdev = pdata->netdev;
+ 	struct netdev_hw_addr *ha;
+ 	unsigned int mac_reg;
+ 	unsigned int addn_macs;
+ 
+ 	mac_reg = MAC_MACA1HR;
+ 	addn_macs = pdata->hw_feat.addn_mac;
+ 
+ 	if (netdev_uc_count(netdev) > addn_macs) {
+ 		xgbe_set_promiscuous_mode(pdata, 1);
+ 	} else {
+ 		netdev_for_each_uc_addr(ha, netdev) {
+ 			xgbe_set_mac_reg(pdata, ha, &mac_reg);
+ 			addn_macs--;
+ 		}
+ 
+ 		if (netdev_mc_count(netdev) > addn_macs) {
+ 			xgbe_set_all_multicast_mode(pdata, 1);
+ 		} else {
+ 			netdev_for_each_mc_addr(ha, netdev) {
+ 				xgbe_set_mac_reg(pdata, ha, &mac_reg);
+ 				addn_macs--;
+ 			}
+ 		}
+ 	}
+ 
+ 	/* Clear remaining additional MAC address entries */
+ 	while (addn_macs--)
+ 		xgbe_set_mac_reg(pdata, NULL, &mac_reg);
+ }
+ 
+ static void xgbe_set_mac_hash_table(struct xgbe_prv_data *pdata)
+ {
+ 	struct net_device *netdev = pdata->netdev;
+ 	struct netdev_hw_addr *ha;
+ 	unsigned int hash_reg;
+ 	unsigned int hash_table_shift, hash_table_count;
+ 	u32 hash_table[XGBE_MAC_HASH_TABLE_SIZE];
+ 	u32 crc;
+ 	unsigned int i;
+ 
+ 	hash_table_shift = 26 - (pdata->hw_feat.hash_table_size >> 7);
+ 	hash_table_count = pdata->hw_feat.hash_table_size / 32;
+ 	memset(hash_table, 0, sizeof(hash_table));
+ 
+ 	/* Build the MAC Hash Table register values */
+ 	netdev_for_each_uc_addr(ha, netdev) {
+ 		crc = bitrev32(~crc32_le(~0, ha->addr, ETH_ALEN));
+ 		crc >>= hash_table_shift;
+ 		hash_table[crc >> 5] |= (1 << (crc & 0x1f));
+ 	}
+ 
+ 	netdev_for_each_mc_addr(ha, netdev) {
+ 		crc = bitrev32(~crc32_le(~0, ha->addr, ETH_ALEN));
+ 		crc >>= hash_table_shift;
+ 		hash_table[crc >> 5] |= (1 << (crc & 0x1f));
+ 	}
+ 
+ 	/* Set the MAC Hash Table registers */
+ 	hash_reg = MAC_HTR0;
+ 	for (i = 0; i < hash_table_count; i++) {
+ 		XGMAC_IOWRITE(pdata, hash_reg, hash_table[i]);
+ 		hash_reg += MAC_HTR_INC;
+ 	}
+ }
+ 
+ static int xgbe_add_mac_addresses(struct xgbe_prv_data *pdata)
+ {
+ 	if (pdata->hw_feat.hash_table_size)
+ 		xgbe_set_mac_hash_table(pdata);
+ 	else
+ 		xgbe_set_mac_addn_addrs(pdata);
+ 
+ 	return 0;
+ }
+ 
+ static int xgbe_set_mac_address(struct xgbe_prv_data *pdata, u8 *addr)
+ {
+ 	unsigned int mac_addr_hi, mac_addr_lo;
+ 
+ 	mac_addr_hi = (addr[5] <<  8) | (addr[4] <<  0);
+ 	mac_addr_lo = (addr[3] << 24) | (addr[2] << 16) |
+ 		      (addr[1] <<  8) | (addr[0] <<  0);
+ 
+ 	XGMAC_IOWRITE(pdata, MAC_MACA0HR, mac_addr_hi);
+ 	XGMAC_IOWRITE(pdata, MAC_MACA0LR, mac_addr_lo);
+ 
+ 	return 0;
+ }
+ 
+ static int xgbe_config_rx_mode(struct xgbe_prv_data *pdata)
+ {
+ 	struct net_device *netdev = pdata->netdev;
+ 	unsigned int pr_mode, am_mode;
+ 
+ 	pr_mode = ((netdev->flags & IFF_PROMISC) != 0);
+ 	am_mode = ((netdev->flags & IFF_ALLMULTI) != 0);
+ 
+ 	xgbe_set_promiscuous_mode(pdata, pr_mode);
+ 	xgbe_set_all_multicast_mode(pdata, am_mode);
+ 
+ 	xgbe_add_mac_addresses(pdata);
+ 
+ 	return 0;
+ }
+ 
+ static int xgbe_clr_gpio(struct xgbe_prv_data *pdata, unsigned int gpio)
+ {
+ 	unsigned int reg;
+ 
+ 	if (gpio > 16)
+ 		return -EINVAL;
+ 
+ 	reg = XGMAC_IOREAD(pdata, MAC_GPIOSR);
+ 
+ 	reg &= ~(1 << (gpio + 16));
+ 	XGMAC_IOWRITE(pdata, MAC_GPIOSR, reg);
+ 
+ 	return 0;
+ }
+ 
+ static int xgbe_set_gpio(struct xgbe_prv_data *pdata, unsigned int gpio)
+ {
+ 	unsigned int reg;
+ 
+ 	if (gpio > 16)
+ 		return -EINVAL;
+ 
+ 	reg = XGMAC_IOREAD(pdata, MAC_GPIOSR);
+ 
+ 	reg |= (1 << (gpio + 16));
+ 	XGMAC_IOWRITE(pdata, MAC_GPIOSR, reg);
+ 
+ 	return 0;
+ }
+ 
+ static int xgbe_read_mmd_regs_v2(struct xgbe_prv_data *pdata, int prtad,
+ 				 int mmd_reg)
+ {
+ 	unsigned long flags;
+ 	unsigned int mmd_address, index, offset;
+ 	int mmd_data;
+ 
+ 	if (mmd_reg & MII_ADDR_C45)
+ 		mmd_address = mmd_reg & ~MII_ADDR_C45;
+ 	else
+ 		mmd_address = (pdata->mdio_mmd << 16) | (mmd_reg & 0xffff);
+ 
+ 	/* The PCS registers are accessed using mmio. The underlying
+ 	 * management interface uses indirect addressing to access the MMD
+ 	 * register sets. This requires accessing of the PCS register in two
+ 	 * phases, an address phase and a data phase.
+ 	 *
+ 	 * The mmio interface is based on 16-bit offsets and values. All
+ 	 * register offsets must therefore be adjusted by left shifting the
+ 	 * offset 1 bit and reading 16 bits of data.
+ 	 */
+ 	mmd_address <<= 1;
+ 	index = mmd_address & ~pdata->xpcs_window_mask;
+ 	offset = pdata->xpcs_window + (mmd_address & pdata->xpcs_window_mask);
+ 
+ 	spin_lock_irqsave(&pdata->xpcs_lock, flags);
+ 	XPCS32_IOWRITE(pdata, PCS_V2_WINDOW_SELECT, index);
+ 	mmd_data = XPCS16_IOREAD(pdata, offset);
+ 	spin_unlock_irqrestore(&pdata->xpcs_lock, flags);
+ 
+ 	return mmd_data;
+ }
+ 
+ static void xgbe_write_mmd_regs_v2(struct xgbe_prv_data *pdata, int prtad,
+ 				   int mmd_reg, int mmd_data)
+ {
+ 	unsigned long flags;
+ 	unsigned int mmd_address, index, offset;
+ 
+ 	if (mmd_reg & MII_ADDR_C45)
+ 		mmd_address = mmd_reg & ~MII_ADDR_C45;
+ 	else
+ 		mmd_address = (pdata->mdio_mmd << 16) | (mmd_reg & 0xffff);
+ 
+ 	/* The PCS registers are accessed using mmio. The underlying
+ 	 * management interface uses indirect addressing to access the MMD
+ 	 * register sets. This requires accessing of the PCS register in two
+ 	 * phases, an address phase and a data phase.
+ 	 *
+ 	 * The mmio interface is based on 16-bit offsets and values. All
+ 	 * register offsets must therefore be adjusted by left shifting the
+ 	 * offset 1 bit and writing 16 bits of data.
+ 	 */
+ 	mmd_address <<= 1;
+ 	index = mmd_address & ~pdata->xpcs_window_mask;
+ 	offset = pdata->xpcs_window + (mmd_address & pdata->xpcs_window_mask);
+ 
+ 	spin_lock_irqsave(&pdata->xpcs_lock, flags);
+ 	XPCS32_IOWRITE(pdata, PCS_V2_WINDOW_SELECT, index);
+ 	XPCS16_IOWRITE(pdata, offset, mmd_data);
+ 	spin_unlock_irqrestore(&pdata->xpcs_lock, flags);
+ }
+ 
+ static int xgbe_read_mmd_regs_v1(struct xgbe_prv_data *pdata, int prtad,
+ 				 int mmd_reg)
+ {
+ 	unsigned long flags;
+ 	unsigned int mmd_address;
+ 	int mmd_data;
+ 
+ 	if (mmd_reg & MII_ADDR_C45)
+ 		mmd_address = mmd_reg & ~MII_ADDR_C45;
+ 	else
+ 		mmd_address = (pdata->mdio_mmd << 16) | (mmd_reg & 0xffff);
+ 
+ 	/* The PCS registers are accessed using mmio. The underlying APB3
+ 	 * management interface uses indirect addressing to access the MMD
+ 	 * register sets. This requires accessing of the PCS register in two
+ 	 * phases, an address phase and a data phase.
+ 	 *
+ 	 * The mmio interface is based on 32-bit offsets and values. All
+ 	 * register offsets must therefore be adjusted by left shifting the
+ 	 * offset 2 bits and reading 32 bits of data.
+ 	 */
+ 	spin_lock_irqsave(&pdata->xpcs_lock, flags);
+ 	XPCS32_IOWRITE(pdata, PCS_V1_WINDOW_SELECT, mmd_address >> 8);
+ 	mmd_data = XPCS32_IOREAD(pdata, (mmd_address & 0xff) << 2);
+ 	spin_unlock_irqrestore(&pdata->xpcs_lock, flags);
+ 
+ 	return mmd_data;
+ }
+ 
+ static void xgbe_write_mmd_regs_v1(struct xgbe_prv_data *pdata, int prtad,
+ 				   int mmd_reg, int mmd_data)
+ {
+ 	unsigned int mmd_address;
+ 	unsigned long flags;
+ 
+ 	if (mmd_reg & MII_ADDR_C45)
+ 		mmd_address = mmd_reg & ~MII_ADDR_C45;
+ 	else
+ 		mmd_address = (pdata->mdio_mmd << 16) | (mmd_reg & 0xffff);
+ 
+ 	/* The PCS registers are accessed using mmio. The underlying APB3
+ 	 * management interface uses indirect addressing to access the MMD
+ 	 * register sets. This requires accessing of the PCS register in two
+ 	 * phases, an address phase and a data phase.
+ 	 *
+ 	 * The mmio interface is based on 32-bit offsets and values. All
+ 	 * register offsets must therefore be adjusted by left shifting the
+ 	 * offset 2 bits and writing 32 bits of data.
+ 	 */
+ 	spin_lock_irqsave(&pdata->xpcs_lock, flags);
+ 	XPCS32_IOWRITE(pdata, PCS_V1_WINDOW_SELECT, mmd_address >> 8);
+ 	XPCS32_IOWRITE(pdata, (mmd_address & 0xff) << 2, mmd_data);
+ 	spin_unlock_irqrestore(&pdata->xpcs_lock, flags);
+ }
+ 
+ static int xgbe_read_mmd_regs(struct xgbe_prv_data *pdata, int prtad,
+ 			      int mmd_reg)
+ {
+ 	switch (pdata->vdata->xpcs_access) {
+ 	case XGBE_XPCS_ACCESS_V1:
+ 		return xgbe_read_mmd_regs_v1(pdata, prtad, mmd_reg);
+ 
+ 	case XGBE_XPCS_ACCESS_V2:
+ 	default:
+ 		return xgbe_read_mmd_regs_v2(pdata, prtad, mmd_reg);
+ 	}
+ }
+ 
+ static void xgbe_write_mmd_regs(struct xgbe_prv_data *pdata, int prtad,
+ 				int mmd_reg, int mmd_data)
+ {
+ 	switch (pdata->vdata->xpcs_access) {
+ 	case XGBE_XPCS_ACCESS_V1:
+ 		return xgbe_write_mmd_regs_v1(pdata, prtad, mmd_reg, mmd_data);
+ 
+ 	case XGBE_XPCS_ACCESS_V2:
+ 	default:
+ 		return xgbe_write_mmd_regs_v2(pdata, prtad, mmd_reg, mmd_data);
+ 	}
+ }
+ 
+ static int xgbe_write_ext_mii_regs(struct xgbe_prv_data *pdata, int addr,
+ 				   int reg, u16 val)
+ {
+ 	unsigned int mdio_sca, mdio_sccd;
+ 
+ 	reinit_completion(&pdata->mdio_complete);
+ 
+ 	mdio_sca = 0;
+ 	XGMAC_SET_BITS(mdio_sca, MAC_MDIOSCAR, REG, reg);
+ 	XGMAC_SET_BITS(mdio_sca, MAC_MDIOSCAR, DA, addr);
+ 	XGMAC_IOWRITE(pdata, MAC_MDIOSCAR, mdio_sca);
+ 
+ 	mdio_sccd = 0;
+ 	XGMAC_SET_BITS(mdio_sccd, MAC_MDIOSCCDR, DATA, val);
+ 	XGMAC_SET_BITS(mdio_sccd, MAC_MDIOSCCDR, CMD, 1);
+ 	XGMAC_SET_BITS(mdio_sccd, MAC_MDIOSCCDR, BUSY, 1);
+ 	XGMAC_IOWRITE(pdata, MAC_MDIOSCCDR, mdio_sccd);
+ 
+ 	if (!wait_for_completion_timeout(&pdata->mdio_complete, HZ)) {
+ 		netdev_err(pdata->netdev, "mdio write operation timed out\n");
+ 		return -ETIMEDOUT;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int xgbe_read_ext_mii_regs(struct xgbe_prv_data *pdata, int addr,
+ 				  int reg)
+ {
+ 	unsigned int mdio_sca, mdio_sccd;
+ 
+ 	reinit_completion(&pdata->mdio_complete);
+ 
+ 	mdio_sca = 0;
+ 	XGMAC_SET_BITS(mdio_sca, MAC_MDIOSCAR, REG, reg);
+ 	XGMAC_SET_BITS(mdio_sca, MAC_MDIOSCAR, DA, addr);
+ 	XGMAC_IOWRITE(pdata, MAC_MDIOSCAR, mdio_sca);
+ 
+ 	mdio_sccd = 0;
+ 	XGMAC_SET_BITS(mdio_sccd, MAC_MDIOSCCDR, CMD, 3);
+ 	XGMAC_SET_BITS(mdio_sccd, MAC_MDIOSCCDR, BUSY, 1);
+ 	XGMAC_IOWRITE(pdata, MAC_MDIOSCCDR, mdio_sccd);
+ 
+ 	if (!wait_for_completion_timeout(&pdata->mdio_complete, HZ)) {
+ 		netdev_err(pdata->netdev, "mdio read operation timed out\n");
+ 		return -ETIMEDOUT;
+ 	}
+ 
+ 	return XGMAC_IOREAD_BITS(pdata, MAC_MDIOSCCDR, DATA);
+ }
+ 
+ static int xgbe_set_ext_mii_mode(struct xgbe_prv_data *pdata, unsigned int port,
+ 				 enum xgbe_mdio_mode mode)
+ {
+ 	unsigned int reg_val = 0;
+ 
+ 	switch (mode) {
+ 	case XGBE_MDIO_MODE_CL22:
+ 		if (port > XGMAC_MAX_C22_PORT)
+ 			return -EINVAL;
+ 		reg_val |= (1 << port);
+ 		break;
+ 	case XGBE_MDIO_MODE_CL45:
+ 		break;
+ 	default:
+ 		return -EINVAL;
+ 	}
+ 
+ 	XGMAC_IOWRITE(pdata, MAC_MDIOCL22R, reg_val);
+ 
+ 	return 0;
+ }
+ 
+ static int xgbe_tx_complete(struct xgbe_ring_desc *rdesc)
+ {
+ 	return !XGMAC_GET_BITS_LE(rdesc->desc3, TX_NORMAL_DESC3, OWN);
+ }
+ 
+ static int xgbe_disable_rx_csum(struct xgbe_prv_data *pdata)
+ {
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_RCR, IPC, 0);
+ 
+ 	return 0;
+ }
+ 
+ static int xgbe_enable_rx_csum(struct xgbe_prv_data *pdata)
+ {
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_RCR, IPC, 1);
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 732f2ab7afb9 (amd-xgbe: Add support for MDIO attached PHYs)
  static void xgbe_tx_desc_reset(struct xgbe_ring_data *rdata)
  {
  	struct xgbe_ring_desc *rdesc = rdata->rdesc;
@@@ -2210,10 -3490,15 +2740,17 @@@ void xgbe_init_function_ptrs_dev(struc
  	hw_if->read_mmd_regs = xgbe_read_mmd_regs;
  	hw_if->write_mmd_regs = xgbe_write_mmd_regs;
  
 -	hw_if->set_speed = xgbe_set_speed;
 +	hw_if->set_gmii_speed = xgbe_set_gmii_speed;
 +	hw_if->set_gmii_2500_speed = xgbe_set_gmii_2500_speed;
 +	hw_if->set_xgmii_speed = xgbe_set_xgmii_speed;
  
+ 	hw_if->set_ext_mii_mode = xgbe_set_ext_mii_mode;
+ 	hw_if->read_ext_mii_regs = xgbe_read_ext_mii_regs;
+ 	hw_if->write_ext_mii_regs = xgbe_write_ext_mii_regs;
+ 
+ 	hw_if->set_gpio = xgbe_set_gpio;
+ 	hw_if->clr_gpio = xgbe_clr_gpio;
+ 
  	hw_if->enable_tx = xgbe_enable_tx;
  	hw_if->disable_tx = xgbe_disable_tx;
  	hw_if->enable_rx = xgbe_enable_rx;
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-drv.c
index d58e85811bc9,155190db682d..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
@@@ -201,7 -443,7 +201,11 @@@ static irqreturn_t xgbe_isr(int irq, vo
  	struct xgbe_hw_if *hw_if = &pdata->hw_if;
  	struct xgbe_channel *channel;
  	unsigned int dma_isr, dma_ch_isr;
++<<<<<<< HEAD
 +	unsigned int mac_isr;
++=======
+ 	unsigned int mac_isr, mac_tssr, mac_mdioisr;
++>>>>>>> 732f2ab7afb9 (amd-xgbe: Add support for MDIO attached PHYs)
  	unsigned int i;
  
  	/* The DMA interrupt status register also reports MAC and MTL
@@@ -254,11 -511,45 +261,40 @@@
  
  		if (XGMAC_GET_BITS(mac_isr, MAC_ISR, MMCRXIS))
  			hw_if->rx_mmc_int(pdata);
++<<<<<<< HEAD
++=======
+ 
+ 		if (XGMAC_GET_BITS(mac_isr, MAC_ISR, TSIS)) {
+ 			mac_tssr = XGMAC_IOREAD(pdata, MAC_TSSR);
+ 
+ 			netif_dbg(pdata, intr, pdata->netdev,
+ 				  "MAC_TSSR=%#010x\n", mac_tssr);
+ 
+ 			if (XGMAC_GET_BITS(mac_tssr, MAC_TSSR, TXTSC)) {
+ 				/* Read Tx Timestamp to clear interrupt */
+ 				pdata->tx_tstamp =
+ 					hw_if->get_tx_tstamp(pdata);
+ 				queue_work(pdata->dev_workqueue,
+ 					   &pdata->tx_tstamp_work);
+ 			}
+ 		}
+ 
+ 		if (XGMAC_GET_BITS(mac_isr, MAC_ISR, SMI)) {
+ 			mac_mdioisr = XGMAC_IOREAD(pdata, MAC_MDIOISR);
+ 
+ 			netif_dbg(pdata, intr, pdata->netdev,
+ 				  "MAC_MDIOISR=%#010x\n", mac_mdioisr);
+ 
+ 			if (XGMAC_GET_BITS(mac_mdioisr, MAC_MDIOISR,
+ 					   SNGLCOMPINT))
+ 				complete(&pdata->mdio_complete);
+ 		}
++>>>>>>> 732f2ab7afb9 (amd-xgbe: Add support for MDIO attached PHYs)
  	}
  
 -	/* If there is not a separate AN irq, handle it here */
 -	if (pdata->dev_irq == pdata->an_irq)
 -		pdata->phy_if.an_isr(irq, pdata);
 -
 -	/* If there is not a separate ECC irq, handle it here */
 -	if (pdata->vdata->ecc_support && (pdata->dev_irq == pdata->ecc_irq))
 -		xgbe_ecc_isr(irq, pdata);
 +	DBGPR("  DMA_ISR = %08x\n", XGMAC_IOREAD(pdata, DMA_ISR));
  
 -	/* If there is not a separate I2C irq, handle it here */
 -	if (pdata->vdata->i2c_support && (pdata->dev_irq == pdata->i2c_irq))
 -		pdata->i2c_if.i2c_isr(irq, pdata);
 +	DBGPR("<--xgbe_isr\n");
  
  isr_done:
  	return IRQ_HANDLED;
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-main.c
index e79ba9088346,b87a89988ffd..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-main.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-main.c
@@@ -240,12 -181,120 +240,126 @@@ static int xgbe_probe(struct platform_d
  	SET_NETDEV_DEV(netdev, dev);
  	pdata = netdev_priv(netdev);
  	pdata->netdev = netdev;
 +	pdata->pdev = pdev;
  	pdata->dev = dev;
 +	platform_set_drvdata(pdev, netdev);
  
  	spin_lock_init(&pdata->lock);
++<<<<<<< HEAD
 +	mutex_init(&pdata->xpcs_mutex);
++=======
+ 	spin_lock_init(&pdata->xpcs_lock);
+ 	mutex_init(&pdata->rss_mutex);
+ 	spin_lock_init(&pdata->tstamp_lock);
+ 	mutex_init(&pdata->i2c_mutex);
+ 	init_completion(&pdata->i2c_complete);
+ 	init_completion(&pdata->mdio_complete);
+ 
+ 	pdata->msg_enable = netif_msg_init(debug, default_msg_level);
+ 
+ 	set_bit(XGBE_DOWN, &pdata->dev_state);
+ 	set_bit(XGBE_STOPPED, &pdata->dev_state);
+ 
+ 	return pdata;
+ }
+ 
+ void xgbe_free_pdata(struct xgbe_prv_data *pdata)
+ {
+ 	struct net_device *netdev = pdata->netdev;
+ 
+ 	free_netdev(netdev);
+ }
+ 
+ void xgbe_set_counts(struct xgbe_prv_data *pdata)
+ {
+ 	/* Set all the function pointers */
+ 	xgbe_init_all_fptrs(pdata);
+ 
+ 	/* Populate the hardware features */
+ 	xgbe_get_all_hw_features(pdata);
+ 
+ 	/* Set default max values if not provided */
+ 	if (!pdata->tx_max_channel_count)
+ 		pdata->tx_max_channel_count = pdata->hw_feat.tx_ch_cnt;
+ 	if (!pdata->rx_max_channel_count)
+ 		pdata->rx_max_channel_count = pdata->hw_feat.rx_ch_cnt;
+ 
+ 	if (!pdata->tx_max_q_count)
+ 		pdata->tx_max_q_count = pdata->hw_feat.tx_q_cnt;
+ 	if (!pdata->rx_max_q_count)
+ 		pdata->rx_max_q_count = pdata->hw_feat.rx_q_cnt;
+ 
+ 	/* Calculate the number of Tx and Rx rings to be created
+ 	 *  -Tx (DMA) Channels map 1-to-1 to Tx Queues so set
+ 	 *   the number of Tx queues to the number of Tx channels
+ 	 *   enabled
+ 	 *  -Rx (DMA) Channels do not map 1-to-1 so use the actual
+ 	 *   number of Rx queues or maximum allowed
+ 	 */
+ 	pdata->tx_ring_count = min_t(unsigned int, num_online_cpus(),
+ 				     pdata->hw_feat.tx_ch_cnt);
+ 	pdata->tx_ring_count = min_t(unsigned int, pdata->tx_ring_count,
+ 				     pdata->tx_max_channel_count);
+ 	pdata->tx_ring_count = min_t(unsigned int, pdata->tx_ring_count,
+ 				     pdata->tx_max_q_count);
+ 
+ 	pdata->tx_q_count = pdata->tx_ring_count;
+ 
+ 	pdata->rx_ring_count = min_t(unsigned int, num_online_cpus(),
+ 				     pdata->hw_feat.rx_ch_cnt);
+ 	pdata->rx_ring_count = min_t(unsigned int, pdata->rx_ring_count,
+ 				     pdata->rx_max_channel_count);
+ 
+ 	pdata->rx_q_count = min_t(unsigned int, pdata->hw_feat.rx_q_cnt,
+ 				  pdata->rx_max_q_count);
+ 
+ 	if (netif_msg_probe(pdata)) {
+ 		dev_dbg(pdata->dev, "TX/RX DMA channel count = %u/%u\n",
+ 			pdata->tx_ring_count, pdata->rx_ring_count);
+ 		dev_dbg(pdata->dev, "TX/RX hardware queue count = %u/%u\n",
+ 			pdata->tx_q_count, pdata->rx_q_count);
+ 	}
+ }
+ 
+ int xgbe_config_netdev(struct xgbe_prv_data *pdata)
+ {
+ 	struct net_device *netdev = pdata->netdev;
+ 	struct device *dev = pdata->dev;
+ 	unsigned int i;
+ 	int ret;
+ 
+ 	netdev->irq = pdata->dev_irq;
+ 	netdev->base_addr = (unsigned long)pdata->xgmac_regs;
+ 	memcpy(netdev->dev_addr, pdata->mac_addr, netdev->addr_len);
+ 
+ 	/* Initialize ECC timestamps */
+ 	pdata->tx_sec_period = jiffies;
+ 	pdata->tx_ded_period = jiffies;
+ 	pdata->rx_sec_period = jiffies;
+ 	pdata->rx_ded_period = jiffies;
+ 	pdata->desc_sec_period = jiffies;
+ 	pdata->desc_ded_period = jiffies;
+ 
+ 	/* Issue software reset to device */
+ 	pdata->hw_if.exit(pdata);
+ 
+ 	/* Set default configuration data */
+ 	xgbe_default_config(pdata);
+ 
+ 	/* Set the DMA mask */
+ 	ret = dma_set_mask_and_coherent(dev,
+ 					DMA_BIT_MASK(pdata->hw_feat.dma_width));
+ 	if (ret) {
+ 		dev_err(dev, "dma_set_mask_and_coherent failed\n");
+ 		return ret;
+ 	}
+ 
+ 	/* Set default max values if not provided */
+ 	if (!pdata->tx_max_fifo_size)
+ 		pdata->tx_max_fifo_size = pdata->hw_feat.tx_fifo_size;
+ 	if (!pdata->rx_max_fifo_size)
+ 		pdata->rx_max_fifo_size = pdata->hw_feat.rx_fifo_size;
++>>>>>>> 732f2ab7afb9 (amd-xgbe: Add support for MDIO attached PHYs)
  
  	/* Set and validate the number of descriptors for a ring */
  	BUILD_BUG_ON_NOT_POWER_OF_2(XGBE_TX_DESC_CNT);
diff --cc drivers/net/ethernet/amd/xgbe/xgbe.h
index 1903f878545a,34db47094c61..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe.h
+++ b/drivers/net/ethernet/amd/xgbe/xgbe.h
@@@ -194,7 -259,39 +194,10 @@@
  /* Flow control queue count */
  #define XGMAC_MAX_FLOW_CONTROL_QUEUES	8
  
 -/* Flow control threshold units */
 -#define XGMAC_FLOW_CONTROL_UNIT		512
 -#define XGMAC_FLOW_CONTROL_ALIGN(_x)				\
 -	(((_x) + XGMAC_FLOW_CONTROL_UNIT - 1) & ~(XGMAC_FLOW_CONTROL_UNIT - 1))
 -#define XGMAC_FLOW_CONTROL_VALUE(_x)				\
 -	(((_x) < 1024) ? 0 : ((_x) / XGMAC_FLOW_CONTROL_UNIT) - 2)
 -#define XGMAC_FLOW_CONTROL_MAX		33280
 -
 -/* Maximum MAC address hash table size (256 bits = 8 bytes) */
 -#define XGBE_MAC_HASH_TABLE_SIZE	8
 -
 -/* Receive Side Scaling */
 -#define XGBE_RSS_HASH_KEY_SIZE		40
 -#define XGBE_RSS_MAX_TABLE_SIZE		256
 -#define XGBE_RSS_LOOKUP_TABLE_TYPE	0
 -#define XGBE_RSS_HASH_KEY_TYPE		1
 -
 -/* Auto-negotiation */
 -#define XGBE_AN_MS_TIMEOUT		500
 -#define XGBE_LINK_TIMEOUT		5
 -
 -#define XGBE_SGMII_AN_LINK_STATUS	BIT(1)
 -#define XGBE_SGMII_AN_LINK_SPEED	(BIT(2) | BIT(3))
 -#define XGBE_SGMII_AN_LINK_SPEED_100	0x04
 -#define XGBE_SGMII_AN_LINK_SPEED_1000	0x08
 -#define XGBE_SGMII_AN_LINK_DUPLEX	BIT(4)
 -
 -/* ECC correctable error notification window (seconds) */
 -#define XGBE_ECC_LIMIT			60
  
+ /* MDIO port types */
+ #define XGMAC_MAX_C22_PORT		3
+ 
  struct xgbe_prv_data;
  
  struct xgbe_packet_data {
@@@ -401,10 -673,19 +404,18 @@@ struct xgbe_hw_if 
  
  	int (*read_mmd_regs)(struct xgbe_prv_data *, int, int);
  	void (*write_mmd_regs)(struct xgbe_prv_data *, int, int, int);
 -	int (*set_speed)(struct xgbe_prv_data *, int);
 +	int (*set_gmii_speed)(struct xgbe_prv_data *);
 +	int (*set_gmii_2500_speed)(struct xgbe_prv_data *);
 +	int (*set_xgmii_speed)(struct xgbe_prv_data *);
  
+ 	int (*set_ext_mii_mode)(struct xgbe_prv_data *, unsigned int,
+ 				enum xgbe_mdio_mode);
+ 	int (*read_ext_mii_regs)(struct xgbe_prv_data *, int, int);
+ 	int (*write_ext_mii_regs)(struct xgbe_prv_data *, int, int, u16);
+ 
+ 	int (*set_gpio)(struct xgbe_prv_data *, unsigned int);
+ 	int (*clr_gpio)(struct xgbe_prv_data *, unsigned int);
+ 
  	void (*enable_tx)(struct xgbe_prv_data *);
  	void (*disable_tx)(struct xgbe_prv_data *);
  	void (*enable_rx)(struct xgbe_prv_data *);
@@@ -591,25 -1115,43 +602,35 @@@ struct xgbe_prv_data 
  	phy_interface_t phy_mode;
  	int phy_link;
  	int phy_speed;
 +	unsigned int phy_tx_pause;
 +	unsigned int phy_rx_pause;
  
++<<<<<<< HEAD
 +	/* Netdev related settings */
 +	netdev_features_t netdev_features;
 +	struct napi_struct napi;
 +	struct xgbe_mmc_stats mmc_stats;
++=======
+ 	/* MDIO/PHY related settings */
+ 	unsigned int phy_started;
+ 	void *phy_data;
+ 	struct xgbe_phy phy;
+ 	int mdio_mmd;
+ 	unsigned long link_check;
+ 	struct completion mdio_complete;
++>>>>>>> 732f2ab7afb9 (amd-xgbe: Add support for MDIO attached PHYs)
 +
 +	/* System clock value used for Rx watchdog */
 +	struct clk *sysclock;
  
 -	char an_name[IFNAMSIZ + 32];
 -	struct workqueue_struct *an_workqueue;
 -
 -	int an_irq;
 -	struct work_struct an_irq_work;
 -
 -	/* Auto-negotiation state machine support */
 -	unsigned int an_int;
 -	unsigned int an_status;
 -	struct mutex an_mutex;
 -	enum xgbe_an an_result;
 -	enum xgbe_an an_state;
 -	enum xgbe_rx kr_state;
 -	enum xgbe_rx kx_state;
 -	struct work_struct an_work;
 -	unsigned int an_supported;
 -	unsigned int parallel_detect;
 -	unsigned int fec_ability;
 -	unsigned long an_start;
 -	enum xgbe_an_mode an_mode;
 -
 -	/* I2C support */
 -	struct xgbe_i2c i2c;
 -	struct mutex i2c_mutex;
 -	struct completion i2c_complete;
 -	char i2c_name[IFNAMSIZ + 32];
 -
 -	unsigned int lpm_ctrl;		/* CTRL1 for resume */
 +	/* Hardware features of the device */
 +	struct xgbe_hw_features hw_feat;
 +
 +	/* Device restart work structure */
 +	struct work_struct restart_work;
 +
 +	/* Keeps track of power mode */
 +	unsigned int power_down;
  
  #ifdef CONFIG_DEBUG_FS
  	struct dentry *xgbe_debugfs;
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-phy-v2.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-common.h
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-dev.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-drv.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-main.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-phy-v2.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe.h
