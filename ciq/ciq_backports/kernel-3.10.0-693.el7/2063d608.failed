kernfs: mark static names with KERNFS_STATIC_NAME

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Tejun Heo <tj@kernel.org>
commit 2063d608f5110d120db60e896ec2c70c95bb7978
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/2063d608.failed

Because sysfs used struct attribute which are supposed to stay
constant, sysfs didn't copy names when creating regular files.  The
specified string for name was supposed to stay constant.  Such
distinction isn't inherent for kernfs.  kernfs_create_file[_ns]()
should be able to take the same @name as kernfs_create_dir[_ns]()

As there can be huge number of sysfs attributes, we still want to be
able to use static names for sysfs attributes.  This patch renames
kernfs_create_file_ns_key() to __kernfs_create_file() and adds
@name_is_static parameter so that the caller can explicitly indicate
that @name can be used without copying.  kernfs is updated to use
KERNFS_STATIC_NAME to distinguish static and copied names.

This patch doesn't introduce any behavior changes.

	Signed-off-by: Tejun Heo <tj@kernel.org>
	Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
(cherry picked from commit 2063d608f5110d120db60e896ec2c70c95bb7978)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/kernfs/dir.c
#	fs/kernfs/file.c
#	fs/kernfs/kernfs-internal.h
#	fs/sysfs/file.c
#	include/linux/kernfs.h
diff --cc fs/kernfs/dir.c
index 1061602ce81a,e1681775abd5..000000000000
--- a/fs/kernfs/dir.c
+++ b/fs/kernfs/dir.c
@@@ -7,3 -7,1020 +7,1023 @@@
   *
   * This file is released under the GPLv2.
   */
++<<<<<<< HEAD
++=======
+ 
+ #include <linux/fs.h>
+ #include <linux/namei.h>
+ #include <linux/idr.h>
+ #include <linux/slab.h>
+ #include <linux/security.h>
+ #include <linux/hash.h>
+ 
+ #include "kernfs-internal.h"
+ 
+ DEFINE_MUTEX(kernfs_mutex);
+ 
+ #define rb_to_kn(X) rb_entry((X), struct kernfs_node, rb)
+ 
+ /**
+  *	kernfs_name_hash
+  *	@name: Null terminated string to hash
+  *	@ns:   Namespace tag to hash
+  *
+  *	Returns 31 bit hash of ns + name (so it fits in an off_t )
+  */
+ static unsigned int kernfs_name_hash(const char *name, const void *ns)
+ {
+ 	unsigned long hash = init_name_hash();
+ 	unsigned int len = strlen(name);
+ 	while (len--)
+ 		hash = partial_name_hash(*name++, hash);
+ 	hash = (end_name_hash(hash) ^ hash_ptr((void *)ns, 31));
+ 	hash &= 0x7fffffffU;
+ 	/* Reserve hash numbers 0, 1 and INT_MAX for magic directory entries */
+ 	if (hash < 1)
+ 		hash += 2;
+ 	if (hash >= INT_MAX)
+ 		hash = INT_MAX - 1;
+ 	return hash;
+ }
+ 
+ static int kernfs_name_compare(unsigned int hash, const char *name,
+ 			       const void *ns, const struct kernfs_node *kn)
+ {
+ 	if (hash != kn->hash)
+ 		return hash - kn->hash;
+ 	if (ns != kn->ns)
+ 		return ns - kn->ns;
+ 	return strcmp(name, kn->name);
+ }
+ 
+ static int kernfs_sd_compare(const struct kernfs_node *left,
+ 			     const struct kernfs_node *right)
+ {
+ 	return kernfs_name_compare(left->hash, left->name, left->ns, right);
+ }
+ 
+ /**
+  *	kernfs_link_sibling - link kernfs_node into sibling rbtree
+  *	@kn: kernfs_node of interest
+  *
+  *	Link @kn into its sibling rbtree which starts from
+  *	@kn->parent->dir.children.
+  *
+  *	Locking:
+  *	mutex_lock(kernfs_mutex)
+  *
+  *	RETURNS:
+  *	0 on susccess -EEXIST on failure.
+  */
+ static int kernfs_link_sibling(struct kernfs_node *kn)
+ {
+ 	struct rb_node **node = &kn->parent->dir.children.rb_node;
+ 	struct rb_node *parent = NULL;
+ 
+ 	if (kernfs_type(kn) == KERNFS_DIR)
+ 		kn->parent->dir.subdirs++;
+ 
+ 	while (*node) {
+ 		struct kernfs_node *pos;
+ 		int result;
+ 
+ 		pos = rb_to_kn(*node);
+ 		parent = *node;
+ 		result = kernfs_sd_compare(kn, pos);
+ 		if (result < 0)
+ 			node = &pos->rb.rb_left;
+ 		else if (result > 0)
+ 			node = &pos->rb.rb_right;
+ 		else
+ 			return -EEXIST;
+ 	}
+ 	/* add new node and rebalance the tree */
+ 	rb_link_node(&kn->rb, parent, node);
+ 	rb_insert_color(&kn->rb, &kn->parent->dir.children);
+ 	return 0;
+ }
+ 
+ /**
+  *	kernfs_unlink_sibling - unlink kernfs_node from sibling rbtree
+  *	@kn: kernfs_node of interest
+  *
+  *	Unlink @kn from its sibling rbtree which starts from
+  *	kn->parent->dir.children.
+  *
+  *	Locking:
+  *	mutex_lock(kernfs_mutex)
+  */
+ static void kernfs_unlink_sibling(struct kernfs_node *kn)
+ {
+ 	if (kernfs_type(kn) == KERNFS_DIR)
+ 		kn->parent->dir.subdirs--;
+ 
+ 	rb_erase(&kn->rb, &kn->parent->dir.children);
+ }
+ 
+ /**
+  *	kernfs_get_active - get an active reference to kernfs_node
+  *	@kn: kernfs_node to get an active reference to
+  *
+  *	Get an active reference of @kn.  This function is noop if @kn
+  *	is NULL.
+  *
+  *	RETURNS:
+  *	Pointer to @kn on success, NULL on failure.
+  */
+ struct kernfs_node *kernfs_get_active(struct kernfs_node *kn)
+ {
+ 	if (unlikely(!kn))
+ 		return NULL;
+ 
+ 	if (!atomic_inc_unless_negative(&kn->active))
+ 		return NULL;
+ 
+ 	if (kn->flags & KERNFS_LOCKDEP)
+ 		rwsem_acquire_read(&kn->dep_map, 0, 1, _RET_IP_);
+ 	return kn;
+ }
+ 
+ /**
+  *	kernfs_put_active - put an active reference to kernfs_node
+  *	@kn: kernfs_node to put an active reference to
+  *
+  *	Put an active reference to @kn.  This function is noop if @kn
+  *	is NULL.
+  */
+ void kernfs_put_active(struct kernfs_node *kn)
+ {
+ 	int v;
+ 
+ 	if (unlikely(!kn))
+ 		return;
+ 
+ 	if (kn->flags & KERNFS_LOCKDEP)
+ 		rwsem_release(&kn->dep_map, 1, _RET_IP_);
+ 	v = atomic_dec_return(&kn->active);
+ 	if (likely(v != KN_DEACTIVATED_BIAS))
+ 		return;
+ 
+ 	/*
+ 	 * atomic_dec_return() is a mb(), we'll always see the updated
+ 	 * kn->u.completion.
+ 	 */
+ 	complete(kn->u.completion);
+ }
+ 
+ /**
+  *	kernfs_deactivate - deactivate kernfs_node
+  *	@kn: kernfs_node to deactivate
+  *
+  *	Deny new active references and drain existing ones.
+  */
+ static void kernfs_deactivate(struct kernfs_node *kn)
+ {
+ 	DECLARE_COMPLETION_ONSTACK(wait);
+ 	int v;
+ 
+ 	BUG_ON(!(kn->flags & KERNFS_REMOVED));
+ 
+ 	if (!(kernfs_type(kn) & KERNFS_ACTIVE_REF))
+ 		return;
+ 
+ 	kn->u.completion = (void *)&wait;
+ 
+ 	rwsem_acquire(&kn->dep_map, 0, 0, _RET_IP_);
+ 	/* atomic_add_return() is a mb(), put_active() will always see
+ 	 * the updated kn->u.completion.
+ 	 */
+ 	v = atomic_add_return(KN_DEACTIVATED_BIAS, &kn->active);
+ 
+ 	if (v != KN_DEACTIVATED_BIAS) {
+ 		lock_contended(&kn->dep_map, _RET_IP_);
+ 		wait_for_completion(&wait);
+ 	}
+ 
+ 	lock_acquired(&kn->dep_map, _RET_IP_);
+ 	rwsem_release(&kn->dep_map, 1, _RET_IP_);
+ }
+ 
+ /**
+  * kernfs_get - get a reference count on a kernfs_node
+  * @kn: the target kernfs_node
+  */
+ void kernfs_get(struct kernfs_node *kn)
+ {
+ 	if (kn) {
+ 		WARN_ON(!atomic_read(&kn->count));
+ 		atomic_inc(&kn->count);
+ 	}
+ }
+ EXPORT_SYMBOL_GPL(kernfs_get);
+ 
+ /**
+  * kernfs_put - put a reference count on a kernfs_node
+  * @kn: the target kernfs_node
+  *
+  * Put a reference count of @kn and destroy it if it reached zero.
+  */
+ void kernfs_put(struct kernfs_node *kn)
+ {
+ 	struct kernfs_node *parent;
+ 	struct kernfs_root *root;
+ 
+ 	if (!kn || !atomic_dec_and_test(&kn->count))
+ 		return;
+ 	root = kernfs_root(kn);
+  repeat:
+ 	/* Moving/renaming is always done while holding reference.
+ 	 * kn->parent won't change beneath us.
+ 	 */
+ 	parent = kn->parent;
+ 
+ 	WARN(!(kn->flags & KERNFS_REMOVED), "kernfs: free using entry: %s/%s\n",
+ 	     parent ? parent->name : "", kn->name);
+ 
+ 	if (kernfs_type(kn) == KERNFS_LINK)
+ 		kernfs_put(kn->symlink.target_kn);
+ 	if (!(kn->flags & KERNFS_STATIC_NAME))
+ 		kfree(kn->name);
+ 	if (kn->iattr) {
+ 		if (kn->iattr->ia_secdata)
+ 			security_release_secctx(kn->iattr->ia_secdata,
+ 						kn->iattr->ia_secdata_len);
+ 		simple_xattrs_free(&kn->iattr->xattrs);
+ 	}
+ 	kfree(kn->iattr);
+ 	ida_simple_remove(&root->ino_ida, kn->ino);
+ 	kmem_cache_free(kernfs_node_cache, kn);
+ 
+ 	kn = parent;
+ 	if (kn) {
+ 		if (atomic_dec_and_test(&kn->count))
+ 			goto repeat;
+ 	} else {
+ 		/* just released the root kn, free @root too */
+ 		ida_destroy(&root->ino_ida);
+ 		kfree(root);
+ 	}
+ }
+ EXPORT_SYMBOL_GPL(kernfs_put);
+ 
+ static int kernfs_dop_delete(const struct dentry *dentry)
+ {
+ 	struct kernfs_node *kn = dentry->d_fsdata;
+ 	return !(kn && !(kn->flags & KERNFS_REMOVED));
+ }
+ 
+ static int kernfs_dop_revalidate(struct dentry *dentry, unsigned int flags)
+ {
+ 	struct kernfs_node *kn;
+ 
+ 	if (flags & LOOKUP_RCU)
+ 		return -ECHILD;
+ 
+ 	kn = dentry->d_fsdata;
+ 	mutex_lock(&kernfs_mutex);
+ 
+ 	/* The kernfs node has been deleted */
+ 	if (kn->flags & KERNFS_REMOVED)
+ 		goto out_bad;
+ 
+ 	/* The kernfs node has been moved? */
+ 	if (dentry->d_parent->d_fsdata != kn->parent)
+ 		goto out_bad;
+ 
+ 	/* The kernfs node has been renamed */
+ 	if (strcmp(dentry->d_name.name, kn->name) != 0)
+ 		goto out_bad;
+ 
+ 	/* The kernfs node has been moved to a different namespace */
+ 	if (kn->parent && kernfs_ns_enabled(kn->parent) &&
+ 	    kernfs_info(dentry->d_sb)->ns != kn->ns)
+ 		goto out_bad;
+ 
+ 	mutex_unlock(&kernfs_mutex);
+ out_valid:
+ 	return 1;
+ out_bad:
+ 	/*
+ 	 * Remove the dentry from the dcache hashes.
+ 	 * If this is a deleted dentry we use d_drop instead of d_delete
+ 	 * so kernfs doesn't need to cope with negative dentries.
+ 	 *
+ 	 * If this is a dentry that has simply been renamed we
+ 	 * use d_drop to remove it from the dcache lookup on its
+ 	 * old parent.  If this dentry persists later when a lookup
+ 	 * is performed at its new name the dentry will be readded
+ 	 * to the dcache hashes.
+ 	 */
+ 	mutex_unlock(&kernfs_mutex);
+ 
+ 	/* If we have submounts we must allow the vfs caches
+ 	 * to lie about the state of the filesystem to prevent
+ 	 * leaks and other nasty things.
+ 	 */
+ 	if (check_submounts_and_drop(dentry) != 0)
+ 		goto out_valid;
+ 
+ 	return 0;
+ }
+ 
+ static void kernfs_dop_release(struct dentry *dentry)
+ {
+ 	kernfs_put(dentry->d_fsdata);
+ }
+ 
+ const struct dentry_operations kernfs_dops = {
+ 	.d_revalidate	= kernfs_dop_revalidate,
+ 	.d_delete	= kernfs_dop_delete,
+ 	.d_release	= kernfs_dop_release,
+ };
+ 
+ struct kernfs_node *kernfs_new_node(struct kernfs_root *root, const char *name,
+ 				    umode_t mode, unsigned flags)
+ {
+ 	char *dup_name = NULL;
+ 	struct kernfs_node *kn;
+ 	int ret;
+ 
+ 	if (!(flags & KERNFS_STATIC_NAME)) {
+ 		name = dup_name = kstrdup(name, GFP_KERNEL);
+ 		if (!name)
+ 			return NULL;
+ 	}
+ 
+ 	kn = kmem_cache_zalloc(kernfs_node_cache, GFP_KERNEL);
+ 	if (!kn)
+ 		goto err_out1;
+ 
+ 	ret = ida_simple_get(&root->ino_ida, 1, 0, GFP_KERNEL);
+ 	if (ret < 0)
+ 		goto err_out2;
+ 	kn->ino = ret;
+ 
+ 	atomic_set(&kn->count, 1);
+ 	atomic_set(&kn->active, 0);
+ 
+ 	kn->name = name;
+ 	kn->mode = mode;
+ 	kn->flags = flags | KERNFS_REMOVED;
+ 
+ 	return kn;
+ 
+  err_out2:
+ 	kmem_cache_free(kernfs_node_cache, kn);
+  err_out1:
+ 	kfree(dup_name);
+ 	return NULL;
+ }
+ 
+ /**
+  *	kernfs_addrm_start - prepare for kernfs_node add/remove
+  *	@acxt: pointer to kernfs_addrm_cxt to be used
+  *
+  *	This function is called when the caller is about to add or remove
+  *	kernfs_node.  This function acquires kernfs_mutex.  @acxt is used
+  *	to keep and pass context to other addrm functions.
+  *
+  *	LOCKING:
+  *	Kernel thread context (may sleep).  kernfs_mutex is locked on
+  *	return.
+  */
+ void kernfs_addrm_start(struct kernfs_addrm_cxt *acxt)
+ 	__acquires(kernfs_mutex)
+ {
+ 	memset(acxt, 0, sizeof(*acxt));
+ 
+ 	mutex_lock(&kernfs_mutex);
+ }
+ 
+ /**
+  *	kernfs_add_one - add kernfs_node to parent without warning
+  *	@acxt: addrm context to use
+  *	@kn: kernfs_node to be added
+  *	@parent: the parent kernfs_node to add @kn to
+  *
+  *	Get @parent and set @kn->parent to it and increment nlink of the
+  *	parent inode if @kn is a directory and link into the children list
+  *	of the parent.
+  *
+  *	This function should be called between calls to
+  *	kernfs_addrm_start() and kernfs_addrm_finish() and should be passed
+  *	the same @acxt as passed to kernfs_addrm_start().
+  *
+  *	LOCKING:
+  *	Determined by kernfs_addrm_start().
+  *
+  *	RETURNS:
+  *	0 on success, -EEXIST if entry with the given name already
+  *	exists.
+  */
+ int kernfs_add_one(struct kernfs_addrm_cxt *acxt, struct kernfs_node *kn,
+ 		  struct kernfs_node *parent)
+ {
+ 	bool has_ns = kernfs_ns_enabled(parent);
+ 	struct kernfs_iattrs *ps_iattr;
+ 	int ret;
+ 
+ 	if (has_ns != (bool)kn->ns) {
+ 		WARN(1, KERN_WARNING "kernfs: ns %s in '%s' for '%s'\n",
+ 		     has_ns ? "required" : "invalid", parent->name, kn->name);
+ 		return -EINVAL;
+ 	}
+ 
+ 	if (kernfs_type(parent) != KERNFS_DIR)
+ 		return -EINVAL;
+ 
+ 	if (parent->flags & KERNFS_REMOVED)
+ 		return -ENOENT;
+ 
+ 	kn->hash = kernfs_name_hash(kn->name, kn->ns);
+ 	kn->parent = parent;
+ 	kernfs_get(parent);
+ 
+ 	ret = kernfs_link_sibling(kn);
+ 	if (ret)
+ 		return ret;
+ 
+ 	/* Update timestamps on the parent */
+ 	ps_iattr = parent->iattr;
+ 	if (ps_iattr) {
+ 		struct iattr *ps_iattrs = &ps_iattr->ia_iattr;
+ 		ps_iattrs->ia_ctime = ps_iattrs->ia_mtime = CURRENT_TIME;
+ 	}
+ 
+ 	/* Mark the entry added into directory tree */
+ 	kn->flags &= ~KERNFS_REMOVED;
+ 
+ 	return 0;
+ }
+ 
+ /**
+  *	kernfs_remove_one - remove kernfs_node from parent
+  *	@acxt: addrm context to use
+  *	@kn: kernfs_node to be removed
+  *
+  *	Mark @kn removed and drop nlink of parent inode if @kn is a
+  *	directory.  @kn is unlinked from the children list.
+  *
+  *	This function should be called between calls to
+  *	kernfs_addrm_start() and kernfs_addrm_finish() and should be
+  *	passed the same @acxt as passed to kernfs_addrm_start().
+  *
+  *	LOCKING:
+  *	Determined by kernfs_addrm_start().
+  */
+ static void kernfs_remove_one(struct kernfs_addrm_cxt *acxt,
+ 			      struct kernfs_node *kn)
+ {
+ 	struct kernfs_iattrs *ps_iattr;
+ 
+ 	/*
+ 	 * Removal can be called multiple times on the same node.  Only the
+ 	 * first invocation is effective and puts the base ref.
+ 	 */
+ 	if (kn->flags & KERNFS_REMOVED)
+ 		return;
+ 
+ 	if (kn->parent) {
+ 		kernfs_unlink_sibling(kn);
+ 
+ 		/* Update timestamps on the parent */
+ 		ps_iattr = kn->parent->iattr;
+ 		if (ps_iattr) {
+ 			ps_iattr->ia_iattr.ia_ctime = CURRENT_TIME;
+ 			ps_iattr->ia_iattr.ia_mtime = CURRENT_TIME;
+ 		}
+ 	}
+ 
+ 	kn->flags |= KERNFS_REMOVED;
+ 	kn->u.removed_list = acxt->removed;
+ 	acxt->removed = kn;
+ }
+ 
+ /**
+  *	kernfs_addrm_finish - finish up kernfs_node add/remove
+  *	@acxt: addrm context to finish up
+  *
+  *	Finish up kernfs_node add/remove.  Resources acquired by
+  *	kernfs_addrm_start() are released and removed kernfs_nodes are
+  *	cleaned up.
+  *
+  *	LOCKING:
+  *	kernfs_mutex is released.
+  */
+ void kernfs_addrm_finish(struct kernfs_addrm_cxt *acxt)
+ 	__releases(kernfs_mutex)
+ {
+ 	/* release resources acquired by kernfs_addrm_start() */
+ 	mutex_unlock(&kernfs_mutex);
+ 
+ 	/* kill removed kernfs_nodes */
+ 	while (acxt->removed) {
+ 		struct kernfs_node *kn = acxt->removed;
+ 
+ 		acxt->removed = kn->u.removed_list;
+ 
+ 		kernfs_deactivate(kn);
+ 		kernfs_unmap_bin_file(kn);
+ 		kernfs_put(kn);
+ 	}
+ }
+ 
+ /**
+  * kernfs_find_ns - find kernfs_node with the given name
+  * @parent: kernfs_node to search under
+  * @name: name to look for
+  * @ns: the namespace tag to use
+  *
+  * Look for kernfs_node with name @name under @parent.  Returns pointer to
+  * the found kernfs_node on success, %NULL on failure.
+  */
+ static struct kernfs_node *kernfs_find_ns(struct kernfs_node *parent,
+ 					  const unsigned char *name,
+ 					  const void *ns)
+ {
+ 	struct rb_node *node = parent->dir.children.rb_node;
+ 	bool has_ns = kernfs_ns_enabled(parent);
+ 	unsigned int hash;
+ 
+ 	lockdep_assert_held(&kernfs_mutex);
+ 
+ 	if (has_ns != (bool)ns) {
+ 		WARN(1, KERN_WARNING "kernfs: ns %s in '%s' for '%s'\n",
+ 		     has_ns ? "required" : "invalid", parent->name, name);
+ 		return NULL;
+ 	}
+ 
+ 	hash = kernfs_name_hash(name, ns);
+ 	while (node) {
+ 		struct kernfs_node *kn;
+ 		int result;
+ 
+ 		kn = rb_to_kn(node);
+ 		result = kernfs_name_compare(hash, name, ns, kn);
+ 		if (result < 0)
+ 			node = node->rb_left;
+ 		else if (result > 0)
+ 			node = node->rb_right;
+ 		else
+ 			return kn;
+ 	}
+ 	return NULL;
+ }
+ 
+ /**
+  * kernfs_find_and_get_ns - find and get kernfs_node with the given name
+  * @parent: kernfs_node to search under
+  * @name: name to look for
+  * @ns: the namespace tag to use
+  *
+  * Look for kernfs_node with name @name under @parent and get a reference
+  * if found.  This function may sleep and returns pointer to the found
+  * kernfs_node on success, %NULL on failure.
+  */
+ struct kernfs_node *kernfs_find_and_get_ns(struct kernfs_node *parent,
+ 					   const char *name, const void *ns)
+ {
+ 	struct kernfs_node *kn;
+ 
+ 	mutex_lock(&kernfs_mutex);
+ 	kn = kernfs_find_ns(parent, name, ns);
+ 	kernfs_get(kn);
+ 	mutex_unlock(&kernfs_mutex);
+ 
+ 	return kn;
+ }
+ EXPORT_SYMBOL_GPL(kernfs_find_and_get_ns);
+ 
+ /**
+  * kernfs_create_root - create a new kernfs hierarchy
+  * @priv: opaque data associated with the new directory
+  *
+  * Returns the root of the new hierarchy on success, ERR_PTR() value on
+  * failure.
+  */
+ struct kernfs_root *kernfs_create_root(void *priv)
+ {
+ 	struct kernfs_root *root;
+ 	struct kernfs_node *kn;
+ 
+ 	root = kzalloc(sizeof(*root), GFP_KERNEL);
+ 	if (!root)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	ida_init(&root->ino_ida);
+ 
+ 	kn = kernfs_new_node(root, "", S_IFDIR | S_IRUGO | S_IXUGO, KERNFS_DIR);
+ 	if (!kn) {
+ 		ida_destroy(&root->ino_ida);
+ 		kfree(root);
+ 		return ERR_PTR(-ENOMEM);
+ 	}
+ 
+ 	kn->flags &= ~KERNFS_REMOVED;
+ 	kn->priv = priv;
+ 	kn->dir.root = root;
+ 
+ 	root->kn = kn;
+ 
+ 	return root;
+ }
+ 
+ /**
+  * kernfs_destroy_root - destroy a kernfs hierarchy
+  * @root: root of the hierarchy to destroy
+  *
+  * Destroy the hierarchy anchored at @root by removing all existing
+  * directories and destroying @root.
+  */
+ void kernfs_destroy_root(struct kernfs_root *root)
+ {
+ 	kernfs_remove(root->kn);	/* will also free @root */
+ }
+ 
+ /**
+  * kernfs_create_dir_ns - create a directory
+  * @parent: parent in which to create a new directory
+  * @name: name of the new directory
+  * @mode: mode of the new directory
+  * @priv: opaque data associated with the new directory
+  * @ns: optional namespace tag of the directory
+  *
+  * Returns the created node on success, ERR_PTR() value on failure.
+  */
+ struct kernfs_node *kernfs_create_dir_ns(struct kernfs_node *parent,
+ 					 const char *name, umode_t mode,
+ 					 void *priv, const void *ns)
+ {
+ 	struct kernfs_addrm_cxt acxt;
+ 	struct kernfs_node *kn;
+ 	int rc;
+ 
+ 	/* allocate */
+ 	kn = kernfs_new_node(kernfs_root(parent), name, mode | S_IFDIR,
+ 			     KERNFS_DIR);
+ 	if (!kn)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	kn->dir.root = parent->dir.root;
+ 	kn->ns = ns;
+ 	kn->priv = priv;
+ 
+ 	/* link in */
+ 	kernfs_addrm_start(&acxt);
+ 	rc = kernfs_add_one(&acxt, kn, parent);
+ 	kernfs_addrm_finish(&acxt);
+ 
+ 	if (!rc)
+ 		return kn;
+ 
+ 	kernfs_put(kn);
+ 	return ERR_PTR(rc);
+ }
+ 
+ static struct dentry *kernfs_iop_lookup(struct inode *dir,
+ 					struct dentry *dentry,
+ 					unsigned int flags)
+ {
+ 	struct dentry *ret = NULL;
+ 	struct kernfs_node *parent = dentry->d_parent->d_fsdata;
+ 	struct kernfs_node *kn;
+ 	struct inode *inode;
+ 	const void *ns = NULL;
+ 
+ 	mutex_lock(&kernfs_mutex);
+ 
+ 	if (kernfs_ns_enabled(parent))
+ 		ns = kernfs_info(dir->i_sb)->ns;
+ 
+ 	kn = kernfs_find_ns(parent, dentry->d_name.name, ns);
+ 
+ 	/* no such entry */
+ 	if (!kn) {
+ 		ret = ERR_PTR(-ENOENT);
+ 		goto out_unlock;
+ 	}
+ 	kernfs_get(kn);
+ 	dentry->d_fsdata = kn;
+ 
+ 	/* attach dentry and inode */
+ 	inode = kernfs_get_inode(dir->i_sb, kn);
+ 	if (!inode) {
+ 		ret = ERR_PTR(-ENOMEM);
+ 		goto out_unlock;
+ 	}
+ 
+ 	/* instantiate and hash dentry */
+ 	ret = d_materialise_unique(dentry, inode);
+  out_unlock:
+ 	mutex_unlock(&kernfs_mutex);
+ 	return ret;
+ }
+ 
+ const struct inode_operations kernfs_dir_iops = {
+ 	.lookup		= kernfs_iop_lookup,
+ 	.permission	= kernfs_iop_permission,
+ 	.setattr	= kernfs_iop_setattr,
+ 	.getattr	= kernfs_iop_getattr,
+ 	.setxattr	= kernfs_iop_setxattr,
+ 	.removexattr	= kernfs_iop_removexattr,
+ 	.getxattr	= kernfs_iop_getxattr,
+ 	.listxattr	= kernfs_iop_listxattr,
+ };
+ 
+ static struct kernfs_node *kernfs_leftmost_descendant(struct kernfs_node *pos)
+ {
+ 	struct kernfs_node *last;
+ 
+ 	while (true) {
+ 		struct rb_node *rbn;
+ 
+ 		last = pos;
+ 
+ 		if (kernfs_type(pos) != KERNFS_DIR)
+ 			break;
+ 
+ 		rbn = rb_first(&pos->dir.children);
+ 		if (!rbn)
+ 			break;
+ 
+ 		pos = rb_to_kn(rbn);
+ 	}
+ 
+ 	return last;
+ }
+ 
+ /**
+  * kernfs_next_descendant_post - find the next descendant for post-order walk
+  * @pos: the current position (%NULL to initiate traversal)
+  * @root: kernfs_node whose descendants to walk
+  *
+  * Find the next descendant to visit for post-order traversal of @root's
+  * descendants.  @root is included in the iteration and the last node to be
+  * visited.
+  */
+ static struct kernfs_node *kernfs_next_descendant_post(struct kernfs_node *pos,
+ 						       struct kernfs_node *root)
+ {
+ 	struct rb_node *rbn;
+ 
+ 	lockdep_assert_held(&kernfs_mutex);
+ 
+ 	/* if first iteration, visit leftmost descendant which may be root */
+ 	if (!pos)
+ 		return kernfs_leftmost_descendant(root);
+ 
+ 	/* if we visited @root, we're done */
+ 	if (pos == root)
+ 		return NULL;
+ 
+ 	/* if there's an unvisited sibling, visit its leftmost descendant */
+ 	rbn = rb_next(&pos->rb);
+ 	if (rbn)
+ 		return kernfs_leftmost_descendant(rb_to_kn(rbn));
+ 
+ 	/* no sibling left, visit parent */
+ 	return pos->parent;
+ }
+ 
+ static void __kernfs_remove(struct kernfs_addrm_cxt *acxt,
+ 			    struct kernfs_node *kn)
+ {
+ 	struct kernfs_node *pos, *next;
+ 
+ 	if (!kn)
+ 		return;
+ 
+ 	pr_debug("kernfs %s: removing\n", kn->name);
+ 
+ 	next = NULL;
+ 	do {
+ 		pos = next;
+ 		next = kernfs_next_descendant_post(pos, kn);
+ 		if (pos)
+ 			kernfs_remove_one(acxt, pos);
+ 	} while (next);
+ }
+ 
+ /**
+  * kernfs_remove - remove a kernfs_node recursively
+  * @kn: the kernfs_node to remove
+  *
+  * Remove @kn along with all its subdirectories and files.
+  */
+ void kernfs_remove(struct kernfs_node *kn)
+ {
+ 	struct kernfs_addrm_cxt acxt;
+ 
+ 	kernfs_addrm_start(&acxt);
+ 	__kernfs_remove(&acxt, kn);
+ 	kernfs_addrm_finish(&acxt);
+ }
+ 
+ /**
+  * kernfs_remove_by_name_ns - find a kernfs_node by name and remove it
+  * @parent: parent of the target
+  * @name: name of the kernfs_node to remove
+  * @ns: namespace tag of the kernfs_node to remove
+  *
+  * Look for the kernfs_node with @name and @ns under @parent and remove it.
+  * Returns 0 on success, -ENOENT if such entry doesn't exist.
+  */
+ int kernfs_remove_by_name_ns(struct kernfs_node *parent, const char *name,
+ 			     const void *ns)
+ {
+ 	struct kernfs_addrm_cxt acxt;
+ 	struct kernfs_node *kn;
+ 
+ 	if (!parent) {
+ 		WARN(1, KERN_WARNING "kernfs: can not remove '%s', no directory\n",
+ 			name);
+ 		return -ENOENT;
+ 	}
+ 
+ 	kernfs_addrm_start(&acxt);
+ 
+ 	kn = kernfs_find_ns(parent, name, ns);
+ 	if (kn)
+ 		__kernfs_remove(&acxt, kn);
+ 
+ 	kernfs_addrm_finish(&acxt);
+ 
+ 	if (kn)
+ 		return 0;
+ 	else
+ 		return -ENOENT;
+ }
+ 
+ /**
+  * kernfs_rename_ns - move and rename a kernfs_node
+  * @kn: target node
+  * @new_parent: new parent to put @sd under
+  * @new_name: new name
+  * @new_ns: new namespace tag
+  */
+ int kernfs_rename_ns(struct kernfs_node *kn, struct kernfs_node *new_parent,
+ 		     const char *new_name, const void *new_ns)
+ {
+ 	int error;
+ 
+ 	mutex_lock(&kernfs_mutex);
+ 
+ 	error = -ENOENT;
+ 	if ((kn->flags | new_parent->flags) & KERNFS_REMOVED)
+ 		goto out;
+ 
+ 	error = 0;
+ 	if ((kn->parent == new_parent) && (kn->ns == new_ns) &&
+ 	    (strcmp(kn->name, new_name) == 0))
+ 		goto out;	/* nothing to rename */
+ 
+ 	error = -EEXIST;
+ 	if (kernfs_find_ns(new_parent, new_name, new_ns))
+ 		goto out;
+ 
+ 	/* rename kernfs_node */
+ 	if (strcmp(kn->name, new_name) != 0) {
+ 		error = -ENOMEM;
+ 		new_name = kstrdup(new_name, GFP_KERNEL);
+ 		if (!new_name)
+ 			goto out;
+ 
+ 		kfree(kn->name);
+ 		kn->name = new_name;
+ 	}
+ 
+ 	/*
+ 	 * Move to the appropriate place in the appropriate directories rbtree.
+ 	 */
+ 	kernfs_unlink_sibling(kn);
+ 	kernfs_get(new_parent);
+ 	kernfs_put(kn->parent);
+ 	kn->ns = new_ns;
+ 	kn->hash = kernfs_name_hash(kn->name, kn->ns);
+ 	kn->parent = new_parent;
+ 	kernfs_link_sibling(kn);
+ 
+ 	error = 0;
+  out:
+ 	mutex_unlock(&kernfs_mutex);
+ 	return error;
+ }
+ 
+ /* Relationship between s_mode and the DT_xxx types */
+ static inline unsigned char dt_type(struct kernfs_node *kn)
+ {
+ 	return (kn->mode >> 12) & 15;
+ }
+ 
+ static int kernfs_dir_fop_release(struct inode *inode, struct file *filp)
+ {
+ 	kernfs_put(filp->private_data);
+ 	return 0;
+ }
+ 
+ static struct kernfs_node *kernfs_dir_pos(const void *ns,
+ 	struct kernfs_node *parent, loff_t hash, struct kernfs_node *pos)
+ {
+ 	if (pos) {
+ 		int valid = !(pos->flags & KERNFS_REMOVED) &&
+ 			pos->parent == parent && hash == pos->hash;
+ 		kernfs_put(pos);
+ 		if (!valid)
+ 			pos = NULL;
+ 	}
+ 	if (!pos && (hash > 1) && (hash < INT_MAX)) {
+ 		struct rb_node *node = parent->dir.children.rb_node;
+ 		while (node) {
+ 			pos = rb_to_kn(node);
+ 
+ 			if (hash < pos->hash)
+ 				node = node->rb_left;
+ 			else if (hash > pos->hash)
+ 				node = node->rb_right;
+ 			else
+ 				break;
+ 		}
+ 	}
+ 	/* Skip over entries in the wrong namespace */
+ 	while (pos && pos->ns != ns) {
+ 		struct rb_node *node = rb_next(&pos->rb);
+ 		if (!node)
+ 			pos = NULL;
+ 		else
+ 			pos = rb_to_kn(node);
+ 	}
+ 	return pos;
+ }
+ 
+ static struct kernfs_node *kernfs_dir_next_pos(const void *ns,
+ 	struct kernfs_node *parent, ino_t ino, struct kernfs_node *pos)
+ {
+ 	pos = kernfs_dir_pos(ns, parent, ino, pos);
+ 	if (pos)
+ 		do {
+ 			struct rb_node *node = rb_next(&pos->rb);
+ 			if (!node)
+ 				pos = NULL;
+ 			else
+ 				pos = rb_to_kn(node);
+ 		} while (pos && pos->ns != ns);
+ 	return pos;
+ }
+ 
+ static int kernfs_fop_readdir(struct file *file, struct dir_context *ctx)
+ {
+ 	struct dentry *dentry = file->f_path.dentry;
+ 	struct kernfs_node *parent = dentry->d_fsdata;
+ 	struct kernfs_node *pos = file->private_data;
+ 	const void *ns = NULL;
+ 
+ 	if (!dir_emit_dots(file, ctx))
+ 		return 0;
+ 	mutex_lock(&kernfs_mutex);
+ 
+ 	if (kernfs_ns_enabled(parent))
+ 		ns = kernfs_info(dentry->d_sb)->ns;
+ 
+ 	for (pos = kernfs_dir_pos(ns, parent, ctx->pos, pos);
+ 	     pos;
+ 	     pos = kernfs_dir_next_pos(ns, parent, ctx->pos, pos)) {
+ 		const char *name = pos->name;
+ 		unsigned int type = dt_type(pos);
+ 		int len = strlen(name);
+ 		ino_t ino = pos->ino;
+ 
+ 		ctx->pos = pos->hash;
+ 		file->private_data = pos;
+ 		kernfs_get(pos);
+ 
+ 		mutex_unlock(&kernfs_mutex);
+ 		if (!dir_emit(ctx, name, len, ino, type))
+ 			return 0;
+ 		mutex_lock(&kernfs_mutex);
+ 	}
+ 	mutex_unlock(&kernfs_mutex);
+ 	file->private_data = NULL;
+ 	ctx->pos = INT_MAX;
+ 	return 0;
+ }
+ 
+ static loff_t kernfs_dir_fop_llseek(struct file *file, loff_t offset,
+ 				    int whence)
+ {
+ 	struct inode *inode = file_inode(file);
+ 	loff_t ret;
+ 
+ 	mutex_lock(&inode->i_mutex);
+ 	ret = generic_file_llseek(file, offset, whence);
+ 	mutex_unlock(&inode->i_mutex);
+ 
+ 	return ret;
+ }
+ 
+ const struct file_operations kernfs_dir_fops = {
+ 	.read		= generic_read_dir,
+ 	.iterate	= kernfs_fop_readdir,
+ 	.release	= kernfs_dir_fop_release,
+ 	.llseek		= kernfs_dir_fop_llseek,
+ };
++>>>>>>> 2063d608f511 (kernfs: mark static names with KERNFS_STATIC_NAME)
diff --cc fs/kernfs/file.c
index 90b1e88dad44,316604cc3a1c..000000000000
--- a/fs/kernfs/file.c
+++ b/fs/kernfs/file.c
@@@ -7,3 -7,825 +7,828 @@@
   *
   * This file is released under the GPLv2.
   */
++<<<<<<< HEAD
++=======
+ 
+ #include <linux/fs.h>
+ #include <linux/seq_file.h>
+ #include <linux/slab.h>
+ #include <linux/poll.h>
+ #include <linux/pagemap.h>
+ #include <linux/sched.h>
+ 
+ #include "kernfs-internal.h"
+ 
+ /*
+  * There's one kernfs_open_file for each open file and one kernfs_open_node
+  * for each kernfs_node with one or more open files.
+  *
+  * kernfs_node->attr.open points to kernfs_open_node.  attr.open is
+  * protected by kernfs_open_node_lock.
+  *
+  * filp->private_data points to seq_file whose ->private points to
+  * kernfs_open_file.  kernfs_open_files are chained at
+  * kernfs_open_node->files, which is protected by kernfs_open_file_mutex.
+  */
+ static DEFINE_SPINLOCK(kernfs_open_node_lock);
+ static DEFINE_MUTEX(kernfs_open_file_mutex);
+ 
+ struct kernfs_open_node {
+ 	atomic_t		refcnt;
+ 	atomic_t		event;
+ 	wait_queue_head_t	poll;
+ 	struct list_head	files; /* goes through kernfs_open_file.list */
+ };
+ 
+ static struct kernfs_open_file *kernfs_of(struct file *file)
+ {
+ 	return ((struct seq_file *)file->private_data)->private;
+ }
+ 
+ /*
+  * Determine the kernfs_ops for the given kernfs_node.  This function must
+  * be called while holding an active reference.
+  */
+ static const struct kernfs_ops *kernfs_ops(struct kernfs_node *kn)
+ {
+ 	if (kn->flags & KERNFS_LOCKDEP)
+ 		lockdep_assert_held(kn);
+ 	return kn->attr.ops;
+ }
+ 
+ static void *kernfs_seq_start(struct seq_file *sf, loff_t *ppos)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 	const struct kernfs_ops *ops;
+ 
+ 	/*
+ 	 * @of->mutex nests outside active ref and is just to ensure that
+ 	 * the ops aren't called concurrently for the same open file.
+ 	 */
+ 	mutex_lock(&of->mutex);
+ 	if (!kernfs_get_active(of->kn))
+ 		return ERR_PTR(-ENODEV);
+ 
+ 	ops = kernfs_ops(of->kn);
+ 	if (ops->seq_start) {
+ 		return ops->seq_start(sf, ppos);
+ 	} else {
+ 		/*
+ 		 * The same behavior and code as single_open().  Returns
+ 		 * !NULL if pos is at the beginning; otherwise, NULL.
+ 		 */
+ 		return NULL + !*ppos;
+ 	}
+ }
+ 
+ static void *kernfs_seq_next(struct seq_file *sf, void *v, loff_t *ppos)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 	const struct kernfs_ops *ops = kernfs_ops(of->kn);
+ 
+ 	if (ops->seq_next) {
+ 		return ops->seq_next(sf, v, ppos);
+ 	} else {
+ 		/*
+ 		 * The same behavior and code as single_open(), always
+ 		 * terminate after the initial read.
+ 		 */
+ 		++*ppos;
+ 		return NULL;
+ 	}
+ }
+ 
+ static void kernfs_seq_stop(struct seq_file *sf, void *v)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 	const struct kernfs_ops *ops = kernfs_ops(of->kn);
+ 
+ 	if (ops->seq_stop)
+ 		ops->seq_stop(sf, v);
+ 
+ 	kernfs_put_active(of->kn);
+ 	mutex_unlock(&of->mutex);
+ }
+ 
+ static int kernfs_seq_show(struct seq_file *sf, void *v)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 
+ 	of->event = atomic_read(&of->kn->attr.open->event);
+ 
+ 	return of->kn->attr.ops->seq_show(sf, v);
+ }
+ 
+ static const struct seq_operations kernfs_seq_ops = {
+ 	.start = kernfs_seq_start,
+ 	.next = kernfs_seq_next,
+ 	.stop = kernfs_seq_stop,
+ 	.show = kernfs_seq_show,
+ };
+ 
+ /*
+  * As reading a bin file can have side-effects, the exact offset and bytes
+  * specified in read(2) call should be passed to the read callback making
+  * it difficult to use seq_file.  Implement simplistic custom buffering for
+  * bin files.
+  */
+ static ssize_t kernfs_file_direct_read(struct kernfs_open_file *of,
+ 				       char __user *user_buf, size_t count,
+ 				       loff_t *ppos)
+ {
+ 	ssize_t len = min_t(size_t, count, PAGE_SIZE);
+ 	const struct kernfs_ops *ops;
+ 	char *buf;
+ 
+ 	buf = kmalloc(len, GFP_KERNEL);
+ 	if (!buf)
+ 		return -ENOMEM;
+ 
+ 	/*
+ 	 * @of->mutex nests outside active ref and is just to ensure that
+ 	 * the ops aren't called concurrently for the same open file.
+ 	 */
+ 	mutex_lock(&of->mutex);
+ 	if (!kernfs_get_active(of->kn)) {
+ 		len = -ENODEV;
+ 		mutex_unlock(&of->mutex);
+ 		goto out_free;
+ 	}
+ 
+ 	ops = kernfs_ops(of->kn);
+ 	if (ops->read)
+ 		len = ops->read(of, buf, len, *ppos);
+ 	else
+ 		len = -EINVAL;
+ 
+ 	kernfs_put_active(of->kn);
+ 	mutex_unlock(&of->mutex);
+ 
+ 	if (len < 0)
+ 		goto out_free;
+ 
+ 	if (copy_to_user(user_buf, buf, len)) {
+ 		len = -EFAULT;
+ 		goto out_free;
+ 	}
+ 
+ 	*ppos += len;
+ 
+  out_free:
+ 	kfree(buf);
+ 	return len;
+ }
+ 
+ /**
+  * kernfs_fop_read - kernfs vfs read callback
+  * @file: file pointer
+  * @user_buf: data to write
+  * @count: number of bytes
+  * @ppos: starting offset
+  */
+ static ssize_t kernfs_fop_read(struct file *file, char __user *user_buf,
+ 			       size_t count, loff_t *ppos)
+ {
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 
+ 	if (of->kn->flags & KERNFS_HAS_SEQ_SHOW)
+ 		return seq_read(file, user_buf, count, ppos);
+ 	else
+ 		return kernfs_file_direct_read(of, user_buf, count, ppos);
+ }
+ 
+ /**
+  * kernfs_fop_write - kernfs vfs write callback
+  * @file: file pointer
+  * @user_buf: data to write
+  * @count: number of bytes
+  * @ppos: starting offset
+  *
+  * Copy data in from userland and pass it to the matching kernfs write
+  * operation.
+  *
+  * There is no easy way for us to know if userspace is only doing a partial
+  * write, so we don't support them. We expect the entire buffer to come on
+  * the first write.  Hint: if you're writing a value, first read the file,
+  * modify only the the value you're changing, then write entire buffer
+  * back.
+  */
+ static ssize_t kernfs_fop_write(struct file *file, const char __user *user_buf,
+ 				size_t count, loff_t *ppos)
+ {
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	ssize_t len = min_t(size_t, count, PAGE_SIZE);
+ 	const struct kernfs_ops *ops;
+ 	char *buf;
+ 
+ 	buf = kmalloc(len + 1, GFP_KERNEL);
+ 	if (!buf)
+ 		return -ENOMEM;
+ 
+ 	if (copy_from_user(buf, user_buf, len)) {
+ 		len = -EFAULT;
+ 		goto out_free;
+ 	}
+ 	buf[len] = '\0';	/* guarantee string termination */
+ 
+ 	/*
+ 	 * @of->mutex nests outside active ref and is just to ensure that
+ 	 * the ops aren't called concurrently for the same open file.
+ 	 */
+ 	mutex_lock(&of->mutex);
+ 	if (!kernfs_get_active(of->kn)) {
+ 		mutex_unlock(&of->mutex);
+ 		len = -ENODEV;
+ 		goto out_free;
+ 	}
+ 
+ 	ops = kernfs_ops(of->kn);
+ 	if (ops->write)
+ 		len = ops->write(of, buf, len, *ppos);
+ 	else
+ 		len = -EINVAL;
+ 
+ 	kernfs_put_active(of->kn);
+ 	mutex_unlock(&of->mutex);
+ 
+ 	if (len > 0)
+ 		*ppos += len;
+ out_free:
+ 	kfree(buf);
+ 	return len;
+ }
+ 
+ static void kernfs_vma_open(struct vm_area_struct *vma)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 
+ 	if (!of->vm_ops)
+ 		return;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return;
+ 
+ 	if (of->vm_ops->open)
+ 		of->vm_ops->open(vma);
+ 
+ 	kernfs_put_active(of->kn);
+ }
+ 
+ static int kernfs_vma_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return VM_FAULT_SIGBUS;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return VM_FAULT_SIGBUS;
+ 
+ 	ret = VM_FAULT_SIGBUS;
+ 	if (of->vm_ops->fault)
+ 		ret = of->vm_ops->fault(vma, vmf);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ 
+ static int kernfs_vma_page_mkwrite(struct vm_area_struct *vma,
+ 				   struct vm_fault *vmf)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return VM_FAULT_SIGBUS;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return VM_FAULT_SIGBUS;
+ 
+ 	ret = 0;
+ 	if (of->vm_ops->page_mkwrite)
+ 		ret = of->vm_ops->page_mkwrite(vma, vmf);
+ 	else
+ 		file_update_time(file);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ 
+ static int kernfs_vma_access(struct vm_area_struct *vma, unsigned long addr,
+ 			     void *buf, int len, int write)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return -EINVAL;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return -EINVAL;
+ 
+ 	ret = -EINVAL;
+ 	if (of->vm_ops->access)
+ 		ret = of->vm_ops->access(vma, addr, buf, len, write);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ 
+ #ifdef CONFIG_NUMA
+ static int kernfs_vma_set_policy(struct vm_area_struct *vma,
+ 				 struct mempolicy *new)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return 0;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return -EINVAL;
+ 
+ 	ret = 0;
+ 	if (of->vm_ops->set_policy)
+ 		ret = of->vm_ops->set_policy(vma, new);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ 
+ static struct mempolicy *kernfs_vma_get_policy(struct vm_area_struct *vma,
+ 					       unsigned long addr)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	struct mempolicy *pol;
+ 
+ 	if (!of->vm_ops)
+ 		return vma->vm_policy;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return vma->vm_policy;
+ 
+ 	pol = vma->vm_policy;
+ 	if (of->vm_ops->get_policy)
+ 		pol = of->vm_ops->get_policy(vma, addr);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return pol;
+ }
+ 
+ static int kernfs_vma_migrate(struct vm_area_struct *vma,
+ 			      const nodemask_t *from, const nodemask_t *to,
+ 			      unsigned long flags)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return 0;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return 0;
+ 
+ 	ret = 0;
+ 	if (of->vm_ops->migrate)
+ 		ret = of->vm_ops->migrate(vma, from, to, flags);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ #endif
+ 
+ static const struct vm_operations_struct kernfs_vm_ops = {
+ 	.open		= kernfs_vma_open,
+ 	.fault		= kernfs_vma_fault,
+ 	.page_mkwrite	= kernfs_vma_page_mkwrite,
+ 	.access		= kernfs_vma_access,
+ #ifdef CONFIG_NUMA
+ 	.set_policy	= kernfs_vma_set_policy,
+ 	.get_policy	= kernfs_vma_get_policy,
+ 	.migrate	= kernfs_vma_migrate,
+ #endif
+ };
+ 
+ static int kernfs_fop_mmap(struct file *file, struct vm_area_struct *vma)
+ {
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	const struct kernfs_ops *ops;
+ 	int rc;
+ 
+ 	/*
+ 	 * mmap path and of->mutex are prone to triggering spurious lockdep
+ 	 * warnings and we don't want to add spurious locking dependency
+ 	 * between the two.  Check whether mmap is actually implemented
+ 	 * without grabbing @of->mutex by testing HAS_MMAP flag.  See the
+ 	 * comment in kernfs_file_open() for more details.
+ 	 */
+ 	if (!(of->kn->flags & KERNFS_HAS_MMAP))
+ 		return -ENODEV;
+ 
+ 	mutex_lock(&of->mutex);
+ 
+ 	rc = -ENODEV;
+ 	if (!kernfs_get_active(of->kn))
+ 		goto out_unlock;
+ 
+ 	ops = kernfs_ops(of->kn);
+ 	rc = ops->mmap(of, vma);
+ 
+ 	/*
+ 	 * PowerPC's pci_mmap of legacy_mem uses shmem_zero_setup()
+ 	 * to satisfy versions of X which crash if the mmap fails: that
+ 	 * substitutes a new vm_file, and we don't then want bin_vm_ops.
+ 	 */
+ 	if (vma->vm_file != file)
+ 		goto out_put;
+ 
+ 	rc = -EINVAL;
+ 	if (of->mmapped && of->vm_ops != vma->vm_ops)
+ 		goto out_put;
+ 
+ 	/*
+ 	 * It is not possible to successfully wrap close.
+ 	 * So error if someone is trying to use close.
+ 	 */
+ 	rc = -EINVAL;
+ 	if (vma->vm_ops && vma->vm_ops->close)
+ 		goto out_put;
+ 
+ 	rc = 0;
+ 	of->mmapped = 1;
+ 	of->vm_ops = vma->vm_ops;
+ 	vma->vm_ops = &kernfs_vm_ops;
+ out_put:
+ 	kernfs_put_active(of->kn);
+ out_unlock:
+ 	mutex_unlock(&of->mutex);
+ 
+ 	return rc;
+ }
+ 
+ /**
+  *	kernfs_get_open_node - get or create kernfs_open_node
+  *	@kn: target kernfs_node
+  *	@of: kernfs_open_file for this instance of open
+  *
+  *	If @kn->attr.open exists, increment its reference count; otherwise,
+  *	create one.  @of is chained to the files list.
+  *
+  *	LOCKING:
+  *	Kernel thread context (may sleep).
+  *
+  *	RETURNS:
+  *	0 on success, -errno on failure.
+  */
+ static int kernfs_get_open_node(struct kernfs_node *kn,
+ 				struct kernfs_open_file *of)
+ {
+ 	struct kernfs_open_node *on, *new_on = NULL;
+ 
+  retry:
+ 	mutex_lock(&kernfs_open_file_mutex);
+ 	spin_lock_irq(&kernfs_open_node_lock);
+ 
+ 	if (!kn->attr.open && new_on) {
+ 		kn->attr.open = new_on;
+ 		new_on = NULL;
+ 	}
+ 
+ 	on = kn->attr.open;
+ 	if (on) {
+ 		atomic_inc(&on->refcnt);
+ 		list_add_tail(&of->list, &on->files);
+ 	}
+ 
+ 	spin_unlock_irq(&kernfs_open_node_lock);
+ 	mutex_unlock(&kernfs_open_file_mutex);
+ 
+ 	if (on) {
+ 		kfree(new_on);
+ 		return 0;
+ 	}
+ 
+ 	/* not there, initialize a new one and retry */
+ 	new_on = kmalloc(sizeof(*new_on), GFP_KERNEL);
+ 	if (!new_on)
+ 		return -ENOMEM;
+ 
+ 	atomic_set(&new_on->refcnt, 0);
+ 	atomic_set(&new_on->event, 1);
+ 	init_waitqueue_head(&new_on->poll);
+ 	INIT_LIST_HEAD(&new_on->files);
+ 	goto retry;
+ }
+ 
+ /**
+  *	kernfs_put_open_node - put kernfs_open_node
+  *	@kn: target kernfs_nodet
+  *	@of: associated kernfs_open_file
+  *
+  *	Put @kn->attr.open and unlink @of from the files list.  If
+  *	reference count reaches zero, disassociate and free it.
+  *
+  *	LOCKING:
+  *	None.
+  */
+ static void kernfs_put_open_node(struct kernfs_node *kn,
+ 				 struct kernfs_open_file *of)
+ {
+ 	struct kernfs_open_node *on = kn->attr.open;
+ 	unsigned long flags;
+ 
+ 	mutex_lock(&kernfs_open_file_mutex);
+ 	spin_lock_irqsave(&kernfs_open_node_lock, flags);
+ 
+ 	if (of)
+ 		list_del(&of->list);
+ 
+ 	if (atomic_dec_and_test(&on->refcnt))
+ 		kn->attr.open = NULL;
+ 	else
+ 		on = NULL;
+ 
+ 	spin_unlock_irqrestore(&kernfs_open_node_lock, flags);
+ 	mutex_unlock(&kernfs_open_file_mutex);
+ 
+ 	kfree(on);
+ }
+ 
+ static int kernfs_fop_open(struct inode *inode, struct file *file)
+ {
+ 	struct kernfs_node *kn = file->f_path.dentry->d_fsdata;
+ 	const struct kernfs_ops *ops;
+ 	struct kernfs_open_file *of;
+ 	bool has_read, has_write, has_mmap;
+ 	int error = -EACCES;
+ 
+ 	if (!kernfs_get_active(kn))
+ 		return -ENODEV;
+ 
+ 	ops = kernfs_ops(kn);
+ 
+ 	has_read = ops->seq_show || ops->read || ops->mmap;
+ 	has_write = ops->write || ops->mmap;
+ 	has_mmap = ops->mmap;
+ 
+ 	/* check perms and supported operations */
+ 	if ((file->f_mode & FMODE_WRITE) &&
+ 	    (!(inode->i_mode & S_IWUGO) || !has_write))
+ 		goto err_out;
+ 
+ 	if ((file->f_mode & FMODE_READ) &&
+ 	    (!(inode->i_mode & S_IRUGO) || !has_read))
+ 		goto err_out;
+ 
+ 	/* allocate a kernfs_open_file for the file */
+ 	error = -ENOMEM;
+ 	of = kzalloc(sizeof(struct kernfs_open_file), GFP_KERNEL);
+ 	if (!of)
+ 		goto err_out;
+ 
+ 	/*
+ 	 * The following is done to give a different lockdep key to
+ 	 * @of->mutex for files which implement mmap.  This is a rather
+ 	 * crude way to avoid false positive lockdep warning around
+ 	 * mm->mmap_sem - mmap nests @of->mutex under mm->mmap_sem and
+ 	 * reading /sys/block/sda/trace/act_mask grabs sr_mutex, under
+ 	 * which mm->mmap_sem nests, while holding @of->mutex.  As each
+ 	 * open file has a separate mutex, it's okay as long as those don't
+ 	 * happen on the same file.  At this point, we can't easily give
+ 	 * each file a separate locking class.  Let's differentiate on
+ 	 * whether the file has mmap or not for now.
+ 	 *
+ 	 * Both paths of the branch look the same.  They're supposed to
+ 	 * look that way and give @of->mutex different static lockdep keys.
+ 	 */
+ 	if (has_mmap)
+ 		mutex_init(&of->mutex);
+ 	else
+ 		mutex_init(&of->mutex);
+ 
+ 	of->kn = kn;
+ 	of->file = file;
+ 
+ 	/*
+ 	 * Always instantiate seq_file even if read access doesn't use
+ 	 * seq_file or is not requested.  This unifies private data access
+ 	 * and readable regular files are the vast majority anyway.
+ 	 */
+ 	if (ops->seq_show)
+ 		error = seq_open(file, &kernfs_seq_ops);
+ 	else
+ 		error = seq_open(file, NULL);
+ 	if (error)
+ 		goto err_free;
+ 
+ 	((struct seq_file *)file->private_data)->private = of;
+ 
+ 	/* seq_file clears PWRITE unconditionally, restore it if WRITE */
+ 	if (file->f_mode & FMODE_WRITE)
+ 		file->f_mode |= FMODE_PWRITE;
+ 
+ 	/* make sure we have open node struct */
+ 	error = kernfs_get_open_node(kn, of);
+ 	if (error)
+ 		goto err_close;
+ 
+ 	/* open succeeded, put active references */
+ 	kernfs_put_active(kn);
+ 	return 0;
+ 
+ err_close:
+ 	seq_release(inode, file);
+ err_free:
+ 	kfree(of);
+ err_out:
+ 	kernfs_put_active(kn);
+ 	return error;
+ }
+ 
+ static int kernfs_fop_release(struct inode *inode, struct file *filp)
+ {
+ 	struct kernfs_node *kn = filp->f_path.dentry->d_fsdata;
+ 	struct kernfs_open_file *of = kernfs_of(filp);
+ 
+ 	kernfs_put_open_node(kn, of);
+ 	seq_release(inode, filp);
+ 	kfree(of);
+ 
+ 	return 0;
+ }
+ 
+ void kernfs_unmap_bin_file(struct kernfs_node *kn)
+ {
+ 	struct kernfs_open_node *on;
+ 	struct kernfs_open_file *of;
+ 
+ 	if (!(kn->flags & KERNFS_HAS_MMAP))
+ 		return;
+ 
+ 	spin_lock_irq(&kernfs_open_node_lock);
+ 	on = kn->attr.open;
+ 	if (on)
+ 		atomic_inc(&on->refcnt);
+ 	spin_unlock_irq(&kernfs_open_node_lock);
+ 	if (!on)
+ 		return;
+ 
+ 	mutex_lock(&kernfs_open_file_mutex);
+ 	list_for_each_entry(of, &on->files, list) {
+ 		struct inode *inode = file_inode(of->file);
+ 		unmap_mapping_range(inode->i_mapping, 0, 0, 1);
+ 	}
+ 	mutex_unlock(&kernfs_open_file_mutex);
+ 
+ 	kernfs_put_open_node(kn, NULL);
+ }
+ 
+ /*
+  * Kernfs attribute files are pollable.  The idea is that you read
+  * the content and then you use 'poll' or 'select' to wait for
+  * the content to change.  When the content changes (assuming the
+  * manager for the kobject supports notification), poll will
+  * return POLLERR|POLLPRI, and select will return the fd whether
+  * it is waiting for read, write, or exceptions.
+  * Once poll/select indicates that the value has changed, you
+  * need to close and re-open the file, or seek to 0 and read again.
+  * Reminder: this only works for attributes which actively support
+  * it, and it is not possible to test an attribute from userspace
+  * to see if it supports poll (Neither 'poll' nor 'select' return
+  * an appropriate error code).  When in doubt, set a suitable timeout value.
+  */
+ static unsigned int kernfs_fop_poll(struct file *filp, poll_table *wait)
+ {
+ 	struct kernfs_open_file *of = kernfs_of(filp);
+ 	struct kernfs_node *kn = filp->f_path.dentry->d_fsdata;
+ 	struct kernfs_open_node *on = kn->attr.open;
+ 
+ 	/* need parent for the kobj, grab both */
+ 	if (!kernfs_get_active(kn))
+ 		goto trigger;
+ 
+ 	poll_wait(filp, &on->poll, wait);
+ 
+ 	kernfs_put_active(kn);
+ 
+ 	if (of->event != atomic_read(&on->event))
+ 		goto trigger;
+ 
+ 	return DEFAULT_POLLMASK;
+ 
+  trigger:
+ 	return DEFAULT_POLLMASK|POLLERR|POLLPRI;
+ }
+ 
+ /**
+  * kernfs_notify - notify a kernfs file
+  * @kn: file to notify
+  *
+  * Notify @kn such that poll(2) on @kn wakes up.
+  */
+ void kernfs_notify(struct kernfs_node *kn)
+ {
+ 	struct kernfs_open_node *on;
+ 	unsigned long flags;
+ 
+ 	spin_lock_irqsave(&kernfs_open_node_lock, flags);
+ 
+ 	if (!WARN_ON(kernfs_type(kn) != KERNFS_FILE)) {
+ 		on = kn->attr.open;
+ 		if (on) {
+ 			atomic_inc(&on->event);
+ 			wake_up_interruptible(&on->poll);
+ 		}
+ 	}
+ 
+ 	spin_unlock_irqrestore(&kernfs_open_node_lock, flags);
+ }
+ EXPORT_SYMBOL_GPL(kernfs_notify);
+ 
+ const struct file_operations kernfs_file_fops = {
+ 	.read		= kernfs_fop_read,
+ 	.write		= kernfs_fop_write,
+ 	.llseek		= generic_file_llseek,
+ 	.mmap		= kernfs_fop_mmap,
+ 	.open		= kernfs_fop_open,
+ 	.release	= kernfs_fop_release,
+ 	.poll		= kernfs_fop_poll,
+ };
+ 
+ /**
+  * __kernfs_create_file - kernfs internal function to create a file
+  * @parent: directory to create the file in
+  * @name: name of the file
+  * @mode: mode of the file
+  * @size: size of the file
+  * @ops: kernfs operations for the file
+  * @priv: private data for the file
+  * @ns: optional namespace tag of the file
+  * @static_name: don't copy file name
+  * @key: lockdep key for the file's active_ref, %NULL to disable lockdep
+  *
+  * Returns the created node on success, ERR_PTR() value on error.
+  */
+ struct kernfs_node *__kernfs_create_file(struct kernfs_node *parent,
+ 					 const char *name,
+ 					 umode_t mode, loff_t size,
+ 					 const struct kernfs_ops *ops,
+ 					 void *priv, const void *ns,
+ 					 bool name_is_static,
+ 					 struct lock_class_key *key)
+ {
+ 	struct kernfs_addrm_cxt acxt;
+ 	struct kernfs_node *kn;
+ 	unsigned flags;
+ 	int rc;
+ 
+ 	flags = KERNFS_FILE;
+ 	if (name_is_static)
+ 		flags |= KERNFS_STATIC_NAME;
+ 
+ 	kn = kernfs_new_node(kernfs_root(parent), name,
+ 			     (mode & S_IALLUGO) | S_IFREG, flags);
+ 	if (!kn)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	kn->attr.ops = ops;
+ 	kn->attr.size = size;
+ 	kn->ns = ns;
+ 	kn->priv = priv;
+ 
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	if (key) {
+ 		lockdep_init_map(&kn->dep_map, "s_active", key, 0);
+ 		kn->flags |= KERNFS_LOCKDEP;
+ 	}
+ #endif
+ 
+ 	/*
+ 	 * kn->attr.ops is accesible only while holding active ref.  We
+ 	 * need to know whether some ops are implemented outside active
+ 	 * ref.  Cache their existence in flags.
+ 	 */
+ 	if (ops->seq_show)
+ 		kn->flags |= KERNFS_HAS_SEQ_SHOW;
+ 	if (ops->mmap)
+ 		kn->flags |= KERNFS_HAS_MMAP;
+ 
+ 	kernfs_addrm_start(&acxt);
+ 	rc = kernfs_add_one(&acxt, kn, parent);
+ 	kernfs_addrm_finish(&acxt);
+ 
+ 	if (rc) {
+ 		kernfs_put(kn);
+ 		return ERR_PTR(rc);
+ 	}
+ 	return kn;
+ }
++>>>>>>> 2063d608f511 (kernfs: mark static names with KERNFS_STATIC_NAME)
diff --cc fs/sysfs/file.c
index 602f56db0442,810cf6e613e5..000000000000
--- a/fs/sysfs/file.c
+++ b/fs/sysfs/file.c
@@@ -96,479 -74,208 +96,501 @@@ static int fill_read_buffer(struct dent
  		/* Try to struggle along */
  		count = PAGE_SIZE - 1;
  	}
 -	seq_commit(sf, count);
 +	if (count >= 0) {
 +		buffer->needs_read_fill = 0;
 +		buffer->count = count;
 +	} else {
 +		ret = count;
 +	}
++<<<<<<< HEAD
 +	return ret;
++=======
++
++#ifdef CONFIG_DEBUG_LOCK_ALLOC
++	if (!attr->ignore_lockdep)
++		key = attr->key ?: (struct lock_class_key *)&attr->skey;
++#endif
++	kn = __kernfs_create_file(parent, attr->name, mode, size, ops,
++				  (void *)attr, ns, true, key);
++	if (IS_ERR(kn)) {
++		if (PTR_ERR(kn) == -EEXIST)
++			sysfs_warn_dup(parent, attr->name);
++		return PTR_ERR(kn);
++	}
+ 	return 0;
+ }
+ 
 -static ssize_t sysfs_kf_bin_read(struct kernfs_open_file *of, char *buf,
 -				 size_t count, loff_t pos)
++int sysfs_add_file(struct kernfs_node *parent, const struct attribute *attr,
++		   bool is_bin)
+ {
 -	struct bin_attribute *battr = of->kn->priv;
 -	struct kobject *kobj = of->kn->parent->priv;
 -	loff_t size = file_inode(of->file)->i_size;
++	return sysfs_add_file_mode_ns(parent, attr, is_bin, attr->mode, NULL);
++>>>>>>> 2063d608f511 (kernfs: mark static names with KERNFS_STATIC_NAME)
 +}
  
 -	if (!count)
 -		return 0;
 +/**
 + *	sysfs_read_file - read an attribute. 
 + *	@file:	file pointer.
 + *	@buf:	buffer to fill.
 + *	@count:	number of bytes to read.
 + *	@ppos:	starting offset in file.
 + *
 + *	Userspace wants to read an attribute file. The attribute descriptor
 + *	is in the file's ->d_fsdata. The target object is in the directory's
 + *	->d_fsdata.
 + *
 + *	We call fill_read_buffer() to allocate and fill the buffer from the
 + *	object's show() method exactly once (if the read is happening from
 + *	the beginning of the file). That should fill the entire buffer with
 + *	all the data the object has to offer for that attribute.
 + *	We then call flush_read_buffer() to copy the buffer to userspace
 + *	in the increments specified.
 + */
  
 -	if (size) {
 -		if (pos > size)
 -			return 0;
 -		if (pos + count > size)
 -			count = size - pos;
 +static ssize_t
 +sysfs_read_file(struct file *file, char __user *buf, size_t count, loff_t *ppos)
 +{
 +	struct sysfs_buffer * buffer = file->private_data;
 +	ssize_t retval = 0;
 +
 +	mutex_lock(&buffer->mutex);
 +	if (buffer->needs_read_fill || *ppos == 0) {
 +		retval = fill_read_buffer(file->f_path.dentry,buffer);
 +		if (retval)
 +			goto out;
  	}
 +	pr_debug("%s: count = %zd, ppos = %lld, buf = %s\n",
 +		 __func__, count, *ppos, buffer->page);
 +	retval = simple_read_from_buffer(buf, count, ppos, buffer->page,
 +					 buffer->count);
 +out:
 +	mutex_unlock(&buffer->mutex);
 +	return retval;
 +}
 +
 +/**
 + *	fill_write_buffer - copy buffer from userspace.
 + *	@buffer:	data buffer for file.
 + *	@buf:		data from user.
 + *	@count:		number of bytes in @userbuf.
 + *
 + *	Allocate @buffer->page if it hasn't been already, then
 + *	copy the user-supplied buffer into it.
 + */
 +
 +static int 
 +fill_write_buffer(struct sysfs_buffer * buffer, const char __user * buf, size_t count)
 +{
 +	int error;
  
 -	if (!battr->read)
 -		return -EIO;
 +	if (!buffer->page)
 +		buffer->page = (char *)get_zeroed_page(GFP_KERNEL);
 +	if (!buffer->page)
 +		return -ENOMEM;
  
 -	return battr->read(of->file, kobj, battr, buf, pos, count);
 +	if (count >= PAGE_SIZE)
 +		count = PAGE_SIZE - 1;
 +	error = copy_from_user(buffer->page,buf,count);
 +	buffer->needs_read_fill = 1;
 +	/* if buf is assumed to contain a string, terminate it by \0,
 +	   so e.g. sscanf() can scan the string easily */
 +	buffer->page[count] = 0;
 +	return error ? -EFAULT : count;
  }
  
 -/* kernfs write callback for regular sysfs files */
 -static ssize_t sysfs_kf_write(struct kernfs_open_file *of, char *buf,
 -			      size_t count, loff_t pos)
 +
 +/**
 + *	flush_write_buffer - push buffer to kobject.
 + *	@dentry:	dentry to the attribute
 + *	@buffer:	data buffer for file.
 + *	@count:		number of bytes
 + *
 + *	Get the correct pointers for the kobject and the attribute we're
 + *	dealing with, then call the store() method for the attribute, 
 + *	passing the buffer that we acquired in fill_write_buffer().
 + */
 +
 +static int
 +flush_write_buffer(struct dentry * dentry, struct sysfs_buffer * buffer, size_t count)
  {
 -	const struct sysfs_ops *ops = sysfs_file_ops(of->kn);
 -	struct kobject *kobj = of->kn->parent->priv;
 +	struct sysfs_dirent *attr_sd = dentry->d_fsdata;
 +	struct kobject *kobj = attr_sd->s_parent->s_dir.kobj;
 +	const struct sysfs_ops * ops = buffer->ops;
 +	int rc;
  
 -	if (!count)
 -		return 0;
 +	/* need attr_sd for attr and ops, its parent for kobj */
 +	if (!sysfs_get_active(attr_sd))
 +		return -ENODEV;
 +
 +	rc = ops->store(kobj, attr_sd->s_attr.attr, buffer->page, count);
  
 -	return ops->store(kobj, of->kn->priv, buf, count);
 +	sysfs_put_active(attr_sd);
 +
 +	return rc;
  }
  
 -/* kernfs write callback for bin sysfs files */
 -static ssize_t sysfs_kf_bin_write(struct kernfs_open_file *of, char *buf,
 -				  size_t count, loff_t pos)
 +
 +/**
 + *	sysfs_write_file - write an attribute.
 + *	@file:	file pointer
 + *	@buf:	data to write
 + *	@count:	number of bytes
 + *	@ppos:	starting offset
 + *
 + *	Similar to sysfs_read_file(), though working in the opposite direction.
 + *	We allocate and fill the data from the user in fill_write_buffer(),
 + *	then push it to the kobject in flush_write_buffer().
 + *	There is no easy way for us to know if userspace is only doing a partial
 + *	write, so we don't support them. We expect the entire buffer to come
 + *	on the first write. 
 + *	Hint: if you're writing a value, first read the file, modify only the
 + *	the value you're changing, then write entire buffer back. 
 + */
 +
 +static ssize_t
 +sysfs_write_file(struct file *file, const char __user *buf, size_t count, loff_t *ppos)
 +{
 +	struct sysfs_buffer * buffer = file->private_data;
 +	ssize_t len;
 +
 +	mutex_lock(&buffer->mutex);
 +	len = fill_write_buffer(buffer, buf, count);
 +	if (len > 0)
 +		len = flush_write_buffer(file->f_path.dentry, buffer, len);
 +	if (len > 0)
 +		*ppos += len;
 +	mutex_unlock(&buffer->mutex);
 +	return len;
 +}
 +
 +/**
 + *	sysfs_get_open_dirent - get or create sysfs_open_dirent
 + *	@sd: target sysfs_dirent
 + *	@buffer: sysfs_buffer for this instance of open
 + *
 + *	If @sd->s_attr.open exists, increment its reference count;
 + *	otherwise, create one.  @buffer is chained to the buffers
 + *	list.
 + *
 + *	LOCKING:
 + *	Kernel thread context (may sleep).
 + *
 + *	RETURNS:
 + *	0 on success, -errno on failure.
 + */
 +static int sysfs_get_open_dirent(struct sysfs_dirent *sd,
 +				 struct sysfs_buffer *buffer)
  {
 -	struct bin_attribute *battr = of->kn->priv;
 -	struct kobject *kobj = of->kn->parent->priv;
 -	loff_t size = file_inode(of->file)->i_size;
 -
 -	if (size) {
 -		if (size <= pos)
 -			return 0;
 -		count = min_t(ssize_t, count, size - pos);
 +	struct sysfs_open_dirent *od, *new_od = NULL;
 +
 + retry:
 +	spin_lock_irq(&sysfs_open_dirent_lock);
 +
 +	if (!sd->s_attr.open && new_od) {
 +		sd->s_attr.open = new_od;
 +		new_od = NULL;
 +	}
 +
 +	od = sd->s_attr.open;
 +	if (od) {
 +		atomic_inc(&od->refcnt);
 +		list_add_tail(&buffer->list, &od->buffers);
  	}
 -	if (!count)
 +
 +	spin_unlock_irq(&sysfs_open_dirent_lock);
 +
 +	if (od) {
 +		kfree(new_od);
  		return 0;
 +	}
  
 -	if (!battr->write)
 -		return -EIO;
 +	/* not there, initialize a new one and retry */
 +	new_od = kmalloc(sizeof(*new_od), GFP_KERNEL);
 +	if (!new_od)
 +		return -ENOMEM;
  
 -	return battr->write(of->file, kobj, battr, buf, pos, count);
 +	atomic_set(&new_od->refcnt, 0);
 +	atomic_set(&new_od->event, 1);
 +	init_waitqueue_head(&new_od->poll);
 +	INIT_LIST_HEAD(&new_od->buffers);
 +	goto retry;
  }
  
 -static int sysfs_kf_bin_mmap(struct kernfs_open_file *of,
 -			     struct vm_area_struct *vma)
 +/**
 + *	sysfs_put_open_dirent - put sysfs_open_dirent
 + *	@sd: target sysfs_dirent
 + *	@buffer: associated sysfs_buffer
 + *
 + *	Put @sd->s_attr.open and unlink @buffer from the buffers list.
 + *	If reference count reaches zero, disassociate and free it.
 + *
 + *	LOCKING:
 + *	None.
 + */
 +static void sysfs_put_open_dirent(struct sysfs_dirent *sd,
 +				  struct sysfs_buffer *buffer)
  {
 -	struct bin_attribute *battr = of->kn->priv;
 -	struct kobject *kobj = of->kn->parent->priv;
 +	struct sysfs_open_dirent *od = sd->s_attr.open;
 +	unsigned long flags;
 +
 +	spin_lock_irqsave(&sysfs_open_dirent_lock, flags);
  
 -	return battr->mmap(of->file, kobj, battr, vma);
 +	list_del(&buffer->list);
 +	if (atomic_dec_and_test(&od->refcnt))
 +		sd->s_attr.open = NULL;
 +	else
 +		od = NULL;
 +
 +	spin_unlock_irqrestore(&sysfs_open_dirent_lock, flags);
 +
 +	kfree(od);
  }
  
 -void sysfs_notify(struct kobject *kobj, const char *dir, const char *attr)
 +static int sysfs_open_file(struct inode *inode, struct file *file)
  {
 -	struct kernfs_node *kn = kobj->sd, *tmp;
 +	struct sysfs_dirent *attr_sd = file->f_path.dentry->d_fsdata;
 +	struct kobject *kobj = attr_sd->s_parent->s_dir.kobj;
 +	struct sysfs_buffer *buffer;
 +	const struct sysfs_ops *ops;
 +	int error = -EACCES;
 +
 +	/* need attr_sd for attr and ops, its parent for kobj */
 +	if (!sysfs_get_active(attr_sd))
 +		return -ENODEV;
  
 -	if (kn && dir)
 -		kn = kernfs_find_and_get(kn, dir);
 -	else
 -		kernfs_get(kn);
 +	/* every kobject with an attribute needs a ktype assigned */
 +	if (kobj->ktype && kobj->ktype->sysfs_ops)
 +		ops = kobj->ktype->sysfs_ops;
 +	else {
 +		WARN(1, KERN_ERR "missing sysfs attribute operations for "
 +		       "kobject: %s\n", kobject_name(kobj));
 +		goto err_out;
 +	}
  
 -	if (kn && attr) {
 -		tmp = kernfs_find_and_get(kn, attr);
 -		kernfs_put(kn);
 -		kn = tmp;
 +	/* File needs write support.
 +	 * The inode's perms must say it's ok, 
 +	 * and we must have a store method.
 +	 */
 +	if (file->f_mode & FMODE_WRITE) {
 +		if (!(inode->i_mode & S_IWUGO) || !ops->store)
 +			goto err_out;
  	}
  
 -	if (kn) {
 -		kernfs_notify(kn);
 -		kernfs_put(kn);
 +	/* File needs read support.
 +	 * The inode's perms must say it's ok, and we there
 +	 * must be a show method for it.
 +	 */
 +	if (file->f_mode & FMODE_READ) {
 +		if (!(inode->i_mode & S_IRUGO) || !ops->show)
 +			goto err_out;
  	}
 +
 +	/* No error? Great, allocate a buffer for the file, and store it
 +	 * it in file->private_data for easy access.
 +	 */
 +	error = -ENOMEM;
 +	buffer = kzalloc(sizeof(struct sysfs_buffer), GFP_KERNEL);
 +	if (!buffer)
 +		goto err_out;
 +
 +	mutex_init(&buffer->mutex);
 +	buffer->needs_read_fill = 1;
 +	buffer->ops = ops;
 +	file->private_data = buffer;
 +
 +	/* make sure we have open dirent struct */
 +	error = sysfs_get_open_dirent(attr_sd, buffer);
 +	if (error)
 +		goto err_free;
 +
 +	/* open succeeded, put active references */
 +	sysfs_put_active(attr_sd);
 +	return 0;
 +
 + err_free:
 +	kfree(buffer);
 + err_out:
 +	sysfs_put_active(attr_sd);
 +	return error;
  }
 -EXPORT_SYMBOL_GPL(sysfs_notify);
  
 -static const struct kernfs_ops sysfs_file_kfops_empty = {
 -};
 +static int sysfs_release(struct inode *inode, struct file *filp)
 +{
 +	struct sysfs_dirent *sd = filp->f_path.dentry->d_fsdata;
 +	struct sysfs_buffer *buffer = filp->private_data;
  
 -static const struct kernfs_ops sysfs_file_kfops_ro = {
 -	.seq_show	= sysfs_kf_seq_show,
 -};
 +	sysfs_put_open_dirent(sd, buffer);
  
 -static const struct kernfs_ops sysfs_file_kfops_wo = {
 -	.write		= sysfs_kf_write,
 -};
 +	if (buffer->page)
 +		free_page((unsigned long)buffer->page);
 +	kfree(buffer);
  
 -static const struct kernfs_ops sysfs_file_kfops_rw = {
 -	.seq_show	= sysfs_kf_seq_show,
 -	.write		= sysfs_kf_write,
 -};
 +	return 0;
 +}
  
 -static const struct kernfs_ops sysfs_bin_kfops_ro = {
 -	.read		= sysfs_kf_bin_read,
 -};
 +/* Sysfs attribute files are pollable.  The idea is that you read
 + * the content and then you use 'poll' or 'select' to wait for
 + * the content to change.  When the content changes (assuming the
 + * manager for the kobject supports notification), poll will
 + * return POLLERR|POLLPRI, and select will return the fd whether
 + * it is waiting for read, write, or exceptions.
 + * Once poll/select indicates that the value has changed, you
 + * need to close and re-open the file, or seek to 0 and read again.
 + * Reminder: this only works for attributes which actively support
 + * it, and it is not possible to test an attribute from userspace
 + * to see if it supports poll (Neither 'poll' nor 'select' return
 + * an appropriate error code).  When in doubt, set a suitable timeout value.
 + */
 +static unsigned int sysfs_poll(struct file *filp, poll_table *wait)
 +{
 +	struct sysfs_buffer * buffer = filp->private_data;
 +	struct sysfs_dirent *attr_sd = filp->f_path.dentry->d_fsdata;
 +	struct sysfs_open_dirent *od = attr_sd->s_attr.open;
  
 -static const struct kernfs_ops sysfs_bin_kfops_wo = {
 -	.write		= sysfs_kf_bin_write,
 -};
 +	/* need parent for the kobj, grab both */
 +	if (!sysfs_get_active(attr_sd))
 +		goto trigger;
  
 -static const struct kernfs_ops sysfs_bin_kfops_rw = {
 -	.read		= sysfs_kf_bin_read,
 -	.write		= sysfs_kf_bin_write,
 -};
 +	poll_wait(filp, &od->poll, wait);
 +
 +	sysfs_put_active(attr_sd);
 +
 +	if (buffer->event != atomic_read(&od->event))
 +		goto trigger;
 +
 +	return DEFAULT_POLLMASK;
 +
 + trigger:
 +	buffer->needs_read_fill = 1;
 +	return DEFAULT_POLLMASK|POLLERR|POLLPRI;
 +}
 +
 +void sysfs_notify_dirent(struct sysfs_dirent *sd)
 +{
 +	struct sysfs_open_dirent *od;
 +	unsigned long flags;
 +
 +	spin_lock_irqsave(&sysfs_open_dirent_lock, flags);
 +
 +	od = sd->s_attr.open;
 +	if (od) {
 +		atomic_inc(&od->event);
 +		wake_up_interruptible(&od->poll);
 +	}
 +
 +	spin_unlock_irqrestore(&sysfs_open_dirent_lock, flags);
 +}
 +EXPORT_SYMBOL_GPL(sysfs_notify_dirent);
  
 -static const struct kernfs_ops sysfs_bin_kfops_mmap = {
 -	.read		= sysfs_kf_bin_read,
 -	.write		= sysfs_kf_bin_write,
 -	.mmap		= sysfs_kf_bin_mmap,
 +void sysfs_notify(struct kobject *k, const char *dir, const char *attr)
 +{
 +	struct sysfs_dirent *sd = k->sd;
 +
 +	mutex_lock(&sysfs_mutex);
 +
 +	if (sd && dir)
 +		sd = sysfs_find_dirent(sd, NULL, dir);
 +	if (sd && attr)
 +		sd = sysfs_find_dirent(sd, NULL, attr);
 +	if (sd)
 +		sysfs_notify_dirent(sd);
 +
 +	mutex_unlock(&sysfs_mutex);
 +}
 +EXPORT_SYMBOL_GPL(sysfs_notify);
 +
 +const struct file_operations sysfs_file_operations = {
 +	.read		= sysfs_read_file,
 +	.write		= sysfs_write_file,
 +	.llseek		= generic_file_llseek,
 +	.open		= sysfs_open_file,
 +	.release	= sysfs_release,
 +	.poll		= sysfs_poll,
  };
  
 -int sysfs_add_file_mode_ns(struct kernfs_node *parent,
 -			   const struct attribute *attr, bool is_bin,
 -			   umode_t mode, const void *ns)
 +static int sysfs_attr_ns(struct kobject *kobj, const struct attribute *attr,
 +			 const void **pns)
  {
 -	struct lock_class_key *key = NULL;
 -	const struct kernfs_ops *ops;
 -	struct kernfs_node *kn;
 -	loff_t size;
 -
 -	if (!is_bin) {
 -		struct kobject *kobj = parent->priv;
 -		const struct sysfs_ops *sysfs_ops = kobj->ktype->sysfs_ops;
 -
 -		/* every kobject with an attribute needs a ktype assigned */
 -		if (WARN(!sysfs_ops, KERN_ERR
 -			 "missing sysfs attribute operations for kobject: %s\n",
 -			 kobject_name(kobj)))
 -			return -EINVAL;
 -
 -		if (sysfs_ops->show && sysfs_ops->store)
 -			ops = &sysfs_file_kfops_rw;
 -		else if (sysfs_ops->show)
 -			ops = &sysfs_file_kfops_ro;
 -		else if (sysfs_ops->store)
 -			ops = &sysfs_file_kfops_wo;
 -		else
 -			ops = &sysfs_file_kfops_empty;
 -
 -		size = PAGE_SIZE;
 -	} else {
 -		struct bin_attribute *battr = (void *)attr;
 -
 -		if (battr->mmap)
 -			ops = &sysfs_bin_kfops_mmap;
 -		else if (battr->read && battr->write)
 -			ops = &sysfs_bin_kfops_rw;
 -		else if (battr->read)
 -			ops = &sysfs_bin_kfops_ro;
 -		else if (battr->write)
 -			ops = &sysfs_bin_kfops_wo;
 -		else
 -			ops = &sysfs_file_kfops_empty;
 -
 -		size = battr->size;
 +	struct sysfs_dirent *dir_sd = kobj->sd;
 +	const struct sysfs_ops *ops;
 +	const void *ns = NULL;
 +	int err;
 +
 +	if (!dir_sd) {
 +		WARN(1, KERN_ERR "sysfs: kobject %s without dirent\n",
 +			kobject_name(kobj));
 +		return -ENOENT;
  	}
  
 -#ifdef CONFIG_DEBUG_LOCK_ALLOC
 -	if (!attr->ignore_lockdep)
 -		key = attr->key ?: (struct lock_class_key *)&attr->skey;
 -#endif
 -	kn = __kernfs_create_file(parent, attr->name, mode, size, ops,
 -				  (void *)attr, ns, true, key);
 -	if (IS_ERR(kn)) {
 -		if (PTR_ERR(kn) == -EEXIST)
 -			sysfs_warn_dup(parent, attr->name);
 -		return PTR_ERR(kn);
 +	err = 0;
 +	if (!sysfs_ns_type(dir_sd))
 +		goto out;
 +
 +	err = -EINVAL;
 +	if (!kobj->ktype)
 +		goto out;
 +	ops = kobj->ktype->sysfs_ops;
 +	if (!ops)
 +		goto out;
 +	if (!ops->namespace)
 +		goto out;
 +
 +	err = 0;
 +	ns = ops->namespace(kobj, attr);
 +out:
 +	if (err) {
 +		WARN(1, KERN_ERR "missing sysfs namespace attribute operation for "
 +		     "kobject: %s\n", kobject_name(kobj));
  	}
 -	return 0;
 +	*pns = ns;
 +	return err;
  }
  
 -int sysfs_add_file(struct kernfs_node *parent, const struct attribute *attr,
 -		   bool is_bin)
 +int sysfs_add_file_mode(struct sysfs_dirent *dir_sd,
 +			const struct attribute *attr, int type, umode_t amode)
  {
 -	return sysfs_add_file_mode_ns(parent, attr, is_bin, attr->mode, NULL);
 +	umode_t mode = (amode & S_IALLUGO) | S_IFREG;
 +	struct sysfs_addrm_cxt acxt;
 +	struct sysfs_dirent *sd;
 +	const void *ns;
 +	int rc;
 +
 +	rc = sysfs_attr_ns(dir_sd->s_dir.kobj, attr, &ns);
 +	if (rc)
 +		return rc;
 +
 +	sd = sysfs_new_dirent(attr->name, mode, type);
 +	if (!sd)
 +		return -ENOMEM;
 +
 +	sd->s_ns = ns;
 +	sd->s_attr.attr = (void *)attr;
 +	sysfs_dirent_init_lockdep(sd);
 +
 +	sysfs_addrm_start(&acxt, dir_sd);
 +	rc = sysfs_add_one(&acxt, sd);
 +	sysfs_addrm_finish(&acxt);
 +
 +	if (rc)
 +		sysfs_put(sd);
 +
 +	return rc;
 +}
 +
 +
 +int sysfs_add_file(struct sysfs_dirent *dir_sd, const struct attribute *attr,
 +		   int type)
 +{
 +	return sysfs_add_file_mode(dir_sd, attr, type, attr->mode);
  }
  
 +
  /**
 - * sysfs_create_file_ns - create an attribute file for an object with custom ns
 - * @kobj: object we're creating for
 - * @attr: attribute descriptor
 - * @ns: namespace the new file should belong to
 + *	sysfs_create_file - create an attribute file for an object.
 + *	@kobj:	object we're creating for. 
 + *	@attr:	attribute descriptor.
   */
 -int sysfs_create_file_ns(struct kobject *kobj, const struct attribute *attr,
 -			 const void *ns)
 +
 +int sysfs_create_file(struct kobject * kobj, const struct attribute * attr)
  {
  	BUG_ON(!kobj || !kobj->sd || !attr);
  
diff --cc include/linux/kernfs.h
index 254b9e872b09,321ed84ad4ce..000000000000
--- a/include/linux/kernfs.h
+++ b/include/linux/kernfs.h
@@@ -7,6 -7,352 +7,356 @@@
  #ifndef __LINUX_KERNFS_H
  #define __LINUX_KERNFS_H
  
++<<<<<<< HEAD
 +struct sysfs_dirent;
++=======
+ #include <linux/kernel.h>
+ #include <linux/err.h>
+ #include <linux/list.h>
+ #include <linux/mutex.h>
+ #include <linux/idr.h>
+ #include <linux/lockdep.h>
+ #include <linux/rbtree.h>
+ #include <linux/atomic.h>
+ #include <linux/completion.h>
+ 
+ struct file;
+ struct iattr;
+ struct seq_file;
+ struct vm_area_struct;
+ struct super_block;
+ struct file_system_type;
+ 
+ struct kernfs_open_node;
+ struct kernfs_iattrs;
+ 
+ enum kernfs_node_type {
+ 	KERNFS_DIR		= 0x0001,
+ 	KERNFS_FILE		= 0x0002,
+ 	KERNFS_LINK		= 0x0004,
+ };
+ 
+ #define KERNFS_TYPE_MASK	0x000f
+ #define KERNFS_ACTIVE_REF	KERNFS_FILE
+ #define KERNFS_FLAG_MASK	~KERNFS_TYPE_MASK
+ 
+ enum kernfs_node_flag {
+ 	KERNFS_REMOVED		= 0x0010,
+ 	KERNFS_NS		= 0x0020,
+ 	KERNFS_HAS_SEQ_SHOW	= 0x0040,
+ 	KERNFS_HAS_MMAP		= 0x0080,
+ 	KERNFS_LOCKDEP		= 0x0100,
+ 	KERNFS_STATIC_NAME	= 0x0200,
+ };
+ 
+ /* type-specific structures for kernfs_node union members */
+ struct kernfs_elem_dir {
+ 	unsigned long		subdirs;
+ 	/* children rbtree starts here and goes through kn->rb */
+ 	struct rb_root		children;
+ 
+ 	/*
+ 	 * The kernfs hierarchy this directory belongs to.  This fits
+ 	 * better directly in kernfs_node but is here to save space.
+ 	 */
+ 	struct kernfs_root	*root;
+ };
+ 
+ struct kernfs_elem_symlink {
+ 	struct kernfs_node	*target_kn;
+ };
+ 
+ struct kernfs_elem_attr {
+ 	const struct kernfs_ops	*ops;
+ 	struct kernfs_open_node	*open;
+ 	loff_t			size;
+ };
+ 
+ /*
+  * kernfs_node - the building block of kernfs hierarchy.  Each and every
+  * kernfs node is represented by single kernfs_node.  Most fields are
+  * private to kernfs and shouldn't be accessed directly by kernfs users.
+  *
+  * As long as s_count reference is held, the kernfs_node itself is
+  * accessible.  Dereferencing elem or any other outer entity requires
+  * active reference.
+  */
+ struct kernfs_node {
+ 	atomic_t		count;
+ 	atomic_t		active;
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	struct lockdep_map	dep_map;
+ #endif
+ 	/* the following two fields are published */
+ 	struct kernfs_node	*parent;
+ 	const char		*name;
+ 
+ 	struct rb_node		rb;
+ 
+ 	union {
+ 		struct completion	*completion;
+ 		struct kernfs_node	*removed_list;
+ 	} u;
+ 
+ 	const void		*ns;	/* namespace tag */
+ 	unsigned int		hash;	/* ns + name hash */
+ 	union {
+ 		struct kernfs_elem_dir		dir;
+ 		struct kernfs_elem_symlink	symlink;
+ 		struct kernfs_elem_attr		attr;
+ 	};
+ 
+ 	void			*priv;
+ 
+ 	unsigned short		flags;
+ 	umode_t			mode;
+ 	unsigned int		ino;
+ 	struct kernfs_iattrs	*iattr;
+ };
+ 
+ struct kernfs_root {
+ 	/* published fields */
+ 	struct kernfs_node	*kn;
+ 
+ 	/* private fields, do not use outside kernfs proper */
+ 	struct ida		ino_ida;
+ };
+ 
+ struct kernfs_open_file {
+ 	/* published fields */
+ 	struct kernfs_node	*kn;
+ 	struct file		*file;
+ 
+ 	/* private fields, do not use outside kernfs proper */
+ 	struct mutex		mutex;
+ 	int			event;
+ 	struct list_head	list;
+ 
+ 	bool			mmapped;
+ 	const struct vm_operations_struct *vm_ops;
+ };
+ 
+ struct kernfs_ops {
+ 	/*
+ 	 * Read is handled by either seq_file or raw_read().
+ 	 *
+ 	 * If seq_show() is present, seq_file path is active.  Other seq
+ 	 * operations are optional and if not implemented, the behavior is
+ 	 * equivalent to single_open().  @sf->private points to the
+ 	 * associated kernfs_open_file.
+ 	 *
+ 	 * read() is bounced through kernel buffer and a read larger than
+ 	 * PAGE_SIZE results in partial operation of PAGE_SIZE.
+ 	 */
+ 	int (*seq_show)(struct seq_file *sf, void *v);
+ 
+ 	void *(*seq_start)(struct seq_file *sf, loff_t *ppos);
+ 	void *(*seq_next)(struct seq_file *sf, void *v, loff_t *ppos);
+ 	void (*seq_stop)(struct seq_file *sf, void *v);
+ 
+ 	ssize_t (*read)(struct kernfs_open_file *of, char *buf, size_t bytes,
+ 			loff_t off);
+ 
+ 	/*
+ 	 * write() is bounced through kernel buffer and a write larger than
+ 	 * PAGE_SIZE results in partial operation of PAGE_SIZE.
+ 	 */
+ 	ssize_t (*write)(struct kernfs_open_file *of, char *buf, size_t bytes,
+ 			 loff_t off);
+ 
+ 	int (*mmap)(struct kernfs_open_file *of, struct vm_area_struct *vma);
+ 
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	struct lock_class_key	lockdep_key;
+ #endif
+ };
+ 
+ #ifdef CONFIG_SYSFS
+ 
+ static inline enum kernfs_node_type kernfs_type(struct kernfs_node *kn)
+ {
+ 	return kn->flags & KERNFS_TYPE_MASK;
+ }
+ 
+ /**
+  * kernfs_enable_ns - enable namespace under a directory
+  * @kn: directory of interest, should be empty
+  *
+  * This is to be called right after @kn is created to enable namespace
+  * under it.  All children of @kn must have non-NULL namespace tags and
+  * only the ones which match the super_block's tag will be visible.
+  */
+ static inline void kernfs_enable_ns(struct kernfs_node *kn)
+ {
+ 	WARN_ON_ONCE(kernfs_type(kn) != KERNFS_DIR);
+ 	WARN_ON_ONCE(!RB_EMPTY_ROOT(&kn->dir.children));
+ 	kn->flags |= KERNFS_NS;
+ }
+ 
+ /**
+  * kernfs_ns_enabled - test whether namespace is enabled
+  * @kn: the node to test
+  *
+  * Test whether namespace filtering is enabled for the children of @ns.
+  */
+ static inline bool kernfs_ns_enabled(struct kernfs_node *kn)
+ {
+ 	return kn->flags & KERNFS_NS;
+ }
+ 
+ struct kernfs_node *kernfs_find_and_get_ns(struct kernfs_node *parent,
+ 					   const char *name, const void *ns);
+ void kernfs_get(struct kernfs_node *kn);
+ void kernfs_put(struct kernfs_node *kn);
+ 
+ struct kernfs_root *kernfs_create_root(void *priv);
+ void kernfs_destroy_root(struct kernfs_root *root);
+ 
+ struct kernfs_node *kernfs_create_dir_ns(struct kernfs_node *parent,
+ 					 const char *name, umode_t mode,
+ 					 void *priv, const void *ns);
+ struct kernfs_node *__kernfs_create_file(struct kernfs_node *parent,
+ 					 const char *name,
+ 					 umode_t mode, loff_t size,
+ 					 const struct kernfs_ops *ops,
+ 					 void *priv, const void *ns,
+ 					 bool name_is_static,
+ 					 struct lock_class_key *key);
+ struct kernfs_node *kernfs_create_link(struct kernfs_node *parent,
+ 				       const char *name,
+ 				       struct kernfs_node *target);
+ void kernfs_remove(struct kernfs_node *kn);
+ int kernfs_remove_by_name_ns(struct kernfs_node *parent, const char *name,
+ 			     const void *ns);
+ int kernfs_rename_ns(struct kernfs_node *kn, struct kernfs_node *new_parent,
+ 		     const char *new_name, const void *new_ns);
+ int kernfs_setattr(struct kernfs_node *kn, const struct iattr *iattr);
+ void kernfs_notify(struct kernfs_node *kn);
+ 
+ const void *kernfs_super_ns(struct super_block *sb);
+ struct dentry *kernfs_mount_ns(struct file_system_type *fs_type, int flags,
+ 			       struct kernfs_root *root, const void *ns);
+ void kernfs_kill_sb(struct super_block *sb);
+ 
+ void kernfs_init(void);
+ 
+ #else	/* CONFIG_SYSFS */
+ 
+ static inline enum kernfs_node_type kernfs_type(struct kernfs_node *kn)
+ { return 0; }	/* whatever */
+ 
+ static inline void kernfs_enable_ns(struct kernfs_node *kn) { }
+ 
+ static inline bool kernfs_ns_enabled(struct kernfs_node *kn)
+ { return false; }
+ 
+ static inline struct kernfs_node *
+ kernfs_find_and_get_ns(struct kernfs_node *parent, const char *name,
+ 		       const void *ns)
+ { return NULL; }
+ 
+ static inline void kernfs_get(struct kernfs_node *kn) { }
+ static inline void kernfs_put(struct kernfs_node *kn) { }
+ 
+ static inline struct kernfs_root *kernfs_create_root(void *priv)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline void kernfs_destroy_root(struct kernfs_root *root) { }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_dir_ns(struct kernfs_node *parent, const char *name,
+ 		     umode_t mode, void *priv, const void *ns)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline struct kernfs_node *
+ __kernfs_create_file(struct kernfs_node *parent, const char *name,
+ 		     umode_t mode, loff_t size, const struct kernfs_ops *ops,
+ 		     void *priv, const void *ns, bool name_is_static,
+ 		     struct lock_class_key *key)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_link(struct kernfs_node *parent, const char *name,
+ 		   struct kernfs_node *target)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline void kernfs_remove(struct kernfs_node *kn) { }
+ 
+ static inline int kernfs_remove_by_name_ns(struct kernfs_node *kn,
+ 					   const char *name, const void *ns)
+ { return -ENOSYS; }
+ 
+ static inline int kernfs_rename_ns(struct kernfs_node *kn,
+ 				   struct kernfs_node *new_parent,
+ 				   const char *new_name, const void *new_ns)
+ { return -ENOSYS; }
+ 
+ static inline int kernfs_setattr(struct kernfs_node *kn,
+ 				 const struct iattr *iattr)
+ { return -ENOSYS; }
+ 
+ static inline void kernfs_notify(struct kernfs_node *kn) { }
+ 
+ static inline const void *kernfs_super_ns(struct super_block *sb)
+ { return NULL; }
+ 
+ static inline struct dentry *
+ kernfs_mount_ns(struct file_system_type *fs_type, int flags,
+ 		struct kernfs_root *root, const void *ns)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline void kernfs_kill_sb(struct super_block *sb) { }
+ 
+ static inline void kernfs_init(void) { }
+ 
+ #endif	/* CONFIG_SYSFS */
+ 
+ static inline struct kernfs_node *
+ kernfs_find_and_get(struct kernfs_node *kn, const char *name)
+ {
+ 	return kernfs_find_and_get_ns(kn, name, NULL);
+ }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_dir(struct kernfs_node *parent, const char *name, umode_t mode,
+ 		  void *priv)
+ {
+ 	return kernfs_create_dir_ns(parent, name, mode, priv, NULL);
+ }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_file_ns(struct kernfs_node *parent, const char *name,
+ 		      umode_t mode, loff_t size, const struct kernfs_ops *ops,
+ 		      void *priv, const void *ns)
+ {
+ 	struct lock_class_key *key = NULL;
+ 
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	key = (struct lock_class_key *)&ops->lockdep_key;
+ #endif
+ 	return __kernfs_create_file(parent, name, mode, size, ops, priv, ns,
+ 				    false, key);
+ }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_file(struct kernfs_node *parent, const char *name, umode_t mode,
+ 		   loff_t size, const struct kernfs_ops *ops, void *priv)
+ {
+ 	return kernfs_create_file_ns(parent, name, mode, size, ops, priv, NULL);
+ }
+ 
+ static inline int kernfs_remove_by_name(struct kernfs_node *parent,
+ 					const char *name)
+ {
+ 	return kernfs_remove_by_name_ns(parent, name, NULL);
+ }
+ 
+ static inline struct dentry *
+ kernfs_mount(struct file_system_type *fs_type, int flags,
+ 	     struct kernfs_root *root)
+ {
+ 	return kernfs_mount_ns(fs_type, flags, root, NULL);
+ }
++>>>>>>> 2063d608f511 (kernfs: mark static names with KERNFS_STATIC_NAME)
  
  #endif	/* __LINUX_KERNFS_H */
* Unmerged path fs/kernfs/kernfs-internal.h
* Unmerged path fs/kernfs/dir.c
* Unmerged path fs/kernfs/file.c
* Unmerged path fs/kernfs/kernfs-internal.h
* Unmerged path fs/sysfs/file.c
* Unmerged path include/linux/kernfs.h
