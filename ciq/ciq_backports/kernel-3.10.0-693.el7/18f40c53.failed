svm: Add VMEXIT handlers for AVIC

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Suravee Suthikulpanit <suravee.suthikulpanit@amd.com>
commit 18f40c53e10f8d1267dc47cce4487664eececd6d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/18f40c53.failed

This patch introduces VMEXIT handlers, avic_incomplete_ipi_interception()
and avic_unaccelerated_access_interception() along with two trace points
(trace_kvm_avic_incomplete_ipi and trace_kvm_avic_unaccelerated_access).

	Signed-off-by: Suravee Suthikulpanit <suravee.suthikulpanit@amd.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 18f40c53e10f8d1267dc47cce4487664eececd6d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/kvm_host.h
#	arch/x86/kvm/svm.c
#	arch/x86/kvm/trace.h
diff --cc arch/x86/include/asm/kvm_host.h
index e9b71b8ce24b,7aaa10891e2c..000000000000
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@@ -677,8 -774,10 +677,15 @@@ struct kvm_arch 
  
  	bool disabled_lapic_found;
  
++<<<<<<< HEAD
 +	bool x2apic_format;
 +	bool x2apic_broadcast_quirk_disabled;
++=======
+ 	/* Struct members for AVIC */
+ 	u32 ldr_mode;
+ 	struct page *avic_logical_id_table_page;
+ 	struct page *avic_physical_id_table_page;
++>>>>>>> 18f40c53e10f (svm: Add VMEXIT handlers for AVIC)
  };
  
  struct kvm_vm_stat {
diff --cc arch/x86/kvm/svm.c
index b645837920e7,db2c140ed079..000000000000
--- a/arch/x86/kvm/svm.c
+++ b/arch/x86/kvm/svm.c
@@@ -78,6 -83,18 +78,21 @@@ MODULE_DEVICE_TABLE(x86cpu, svm_cpu_id)
  #define TSC_RATIO_MIN		0x0000000000000001ULL
  #define TSC_RATIO_MAX		0x000000ffffffffffULL
  
++<<<<<<< HEAD
++=======
+ #define AVIC_HPA_MASK	~((0xFFFULL << 52) || 0xFFF)
+ 
+ /*
+  * 0xff is broadcast, so the max index allowed for physical APIC ID
+  * table is 0xfe.  APIC IDs above 0xff are reserved.
+  */
+ #define AVIC_MAX_PHYSICAL_ID_COUNT	255
+ 
+ #define AVIC_UNACCEL_ACCESS_WRITE_MASK		1
+ #define AVIC_UNACCEL_ACCESS_OFFSET_MASK		0xFF0
+ #define AVIC_UNACCEL_ACCESS_VECTOR_MASK		0xFFFFFFFF
+ 
++>>>>>>> 18f40c53e10f (svm: Add VMEXIT handlers for AVIC)
  static bool erratum_383_found __read_mostly;
  
  static const u32 host_save_user_msrs[] = {
@@@ -160,8 -179,20 +175,15 @@@ struct vcpu_svm 
  
  	/* cached guest cpuid flags for faster access */
  	bool nrips_enabled	: 1;
++<<<<<<< HEAD
++=======
+ 
+ 	u32 ldr_reg;
+ 	struct page *avic_backing_page;
+ 	u64 *avic_physical_id_cache;
++>>>>>>> 18f40c53e10f (svm: Add VMEXIT handlers for AVIC)
  };
  
 -#define AVIC_LOGICAL_ID_ENTRY_GUEST_PHYSICAL_ID_MASK	(0xFF)
 -#define AVIC_LOGICAL_ID_ENTRY_VALID_MASK		(1 << 31)
 -
 -#define AVIC_PHYSICAL_ID_ENTRY_HOST_PHYSICAL_ID_MASK	(0xFFULL)
 -#define AVIC_PHYSICAL_ID_ENTRY_BACKING_PAGE_MASK	(0xFFFFFFFFFFULL << 12)
 -#define AVIC_PHYSICAL_ID_ENTRY_IS_RUNNING_MASK		(1ULL << 62)
 -#define AVIC_PHYSICAL_ID_ENTRY_VALID_MASK		(1ULL << 63)
 -
  static DEFINE_PER_CPU(u64, current_tsc_ratio);
  #define TSC_RATIO_DEFAULT	0x0100000000ULL
  
diff --cc arch/x86/kvm/trace.h
index dd60ae85fb3e,39f264cbda71..000000000000
--- a/arch/x86/kvm/trace.h
+++ b/arch/x86/kvm/trace.h
@@@ -1029,6 -1029,326 +1029,329 @@@ TRACE_EVENT(kvm_pi_irte_update
  		  __entry->pi_desc_addr)
  );
  
++<<<<<<< HEAD
++=======
+ /*
+  * Tracepoint for kvm_hv_notify_acked_sint.
+  */
+ TRACE_EVENT(kvm_hv_notify_acked_sint,
+ 	TP_PROTO(int vcpu_id, u32 sint),
+ 	TP_ARGS(vcpu_id, sint),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(int, vcpu_id)
+ 		__field(u32, sint)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu_id = vcpu_id;
+ 		__entry->sint = sint;
+ 	),
+ 
+ 	TP_printk("vcpu_id %d sint %u", __entry->vcpu_id, __entry->sint)
+ );
+ 
+ /*
+  * Tracepoint for synic_set_irq.
+  */
+ TRACE_EVENT(kvm_hv_synic_set_irq,
+ 	TP_PROTO(int vcpu_id, u32 sint, int vector, int ret),
+ 	TP_ARGS(vcpu_id, sint, vector, ret),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(int, vcpu_id)
+ 		__field(u32, sint)
+ 		__field(int, vector)
+ 		__field(int, ret)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu_id = vcpu_id;
+ 		__entry->sint = sint;
+ 		__entry->vector = vector;
+ 		__entry->ret = ret;
+ 	),
+ 
+ 	TP_printk("vcpu_id %d sint %u vector %d ret %d",
+ 		  __entry->vcpu_id, __entry->sint, __entry->vector,
+ 		  __entry->ret)
+ );
+ 
+ /*
+  * Tracepoint for kvm_hv_synic_send_eoi.
+  */
+ TRACE_EVENT(kvm_hv_synic_send_eoi,
+ 	TP_PROTO(int vcpu_id, int vector),
+ 	TP_ARGS(vcpu_id, vector),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(int, vcpu_id)
+ 		__field(u32, sint)
+ 		__field(int, vector)
+ 		__field(int, ret)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu_id = vcpu_id;
+ 		__entry->vector	= vector;
+ 	),
+ 
+ 	TP_printk("vcpu_id %d vector %d", __entry->vcpu_id, __entry->vector)
+ );
+ 
+ /*
+  * Tracepoint for synic_set_msr.
+  */
+ TRACE_EVENT(kvm_hv_synic_set_msr,
+ 	TP_PROTO(int vcpu_id, u32 msr, u64 data, bool host),
+ 	TP_ARGS(vcpu_id, msr, data, host),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(int, vcpu_id)
+ 		__field(u32, msr)
+ 		__field(u64, data)
+ 		__field(bool, host)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu_id = vcpu_id;
+ 		__entry->msr = msr;
+ 		__entry->data = data;
+ 		__entry->host = host
+ 	),
+ 
+ 	TP_printk("vcpu_id %d msr 0x%x data 0x%llx host %d",
+ 		  __entry->vcpu_id, __entry->msr, __entry->data, __entry->host)
+ );
+ 
+ /*
+  * Tracepoint for stimer_set_config.
+  */
+ TRACE_EVENT(kvm_hv_stimer_set_config,
+ 	TP_PROTO(int vcpu_id, int timer_index, u64 config, bool host),
+ 	TP_ARGS(vcpu_id, timer_index, config, host),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(int, vcpu_id)
+ 		__field(int, timer_index)
+ 		__field(u64, config)
+ 		__field(bool, host)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu_id = vcpu_id;
+ 		__entry->timer_index = timer_index;
+ 		__entry->config = config;
+ 		__entry->host = host;
+ 	),
+ 
+ 	TP_printk("vcpu_id %d timer %d config 0x%llx host %d",
+ 		  __entry->vcpu_id, __entry->timer_index, __entry->config,
+ 		  __entry->host)
+ );
+ 
+ /*
+  * Tracepoint for stimer_set_count.
+  */
+ TRACE_EVENT(kvm_hv_stimer_set_count,
+ 	TP_PROTO(int vcpu_id, int timer_index, u64 count, bool host),
+ 	TP_ARGS(vcpu_id, timer_index, count, host),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(int, vcpu_id)
+ 		__field(int, timer_index)
+ 		__field(u64, count)
+ 		__field(bool, host)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu_id = vcpu_id;
+ 		__entry->timer_index = timer_index;
+ 		__entry->count = count;
+ 		__entry->host = host;
+ 	),
+ 
+ 	TP_printk("vcpu_id %d timer %d count %llu host %d",
+ 		  __entry->vcpu_id, __entry->timer_index, __entry->count,
+ 		  __entry->host)
+ );
+ 
+ /*
+  * Tracepoint for stimer_start(periodic timer case).
+  */
+ TRACE_EVENT(kvm_hv_stimer_start_periodic,
+ 	TP_PROTO(int vcpu_id, int timer_index, u64 time_now, u64 exp_time),
+ 	TP_ARGS(vcpu_id, timer_index, time_now, exp_time),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(int, vcpu_id)
+ 		__field(int, timer_index)
+ 		__field(u64, time_now)
+ 		__field(u64, exp_time)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu_id = vcpu_id;
+ 		__entry->timer_index = timer_index;
+ 		__entry->time_now = time_now;
+ 		__entry->exp_time = exp_time;
+ 	),
+ 
+ 	TP_printk("vcpu_id %d timer %d time_now %llu exp_time %llu",
+ 		  __entry->vcpu_id, __entry->timer_index, __entry->time_now,
+ 		  __entry->exp_time)
+ );
+ 
+ /*
+  * Tracepoint for stimer_start(one-shot timer case).
+  */
+ TRACE_EVENT(kvm_hv_stimer_start_one_shot,
+ 	TP_PROTO(int vcpu_id, int timer_index, u64 time_now, u64 count),
+ 	TP_ARGS(vcpu_id, timer_index, time_now, count),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(int, vcpu_id)
+ 		__field(int, timer_index)
+ 		__field(u64, time_now)
+ 		__field(u64, count)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu_id = vcpu_id;
+ 		__entry->timer_index = timer_index;
+ 		__entry->time_now = time_now;
+ 		__entry->count = count;
+ 	),
+ 
+ 	TP_printk("vcpu_id %d timer %d time_now %llu count %llu",
+ 		  __entry->vcpu_id, __entry->timer_index, __entry->time_now,
+ 		  __entry->count)
+ );
+ 
+ /*
+  * Tracepoint for stimer_timer_callback.
+  */
+ TRACE_EVENT(kvm_hv_stimer_callback,
+ 	TP_PROTO(int vcpu_id, int timer_index),
+ 	TP_ARGS(vcpu_id, timer_index),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(int, vcpu_id)
+ 		__field(int, timer_index)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu_id = vcpu_id;
+ 		__entry->timer_index = timer_index;
+ 	),
+ 
+ 	TP_printk("vcpu_id %d timer %d",
+ 		  __entry->vcpu_id, __entry->timer_index)
+ );
+ 
+ /*
+  * Tracepoint for stimer_expiration.
+  */
+ TRACE_EVENT(kvm_hv_stimer_expiration,
+ 	TP_PROTO(int vcpu_id, int timer_index, int msg_send_result),
+ 	TP_ARGS(vcpu_id, timer_index, msg_send_result),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(int, vcpu_id)
+ 		__field(int, timer_index)
+ 		__field(int, msg_send_result)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu_id = vcpu_id;
+ 		__entry->timer_index = timer_index;
+ 		__entry->msg_send_result = msg_send_result;
+ 	),
+ 
+ 	TP_printk("vcpu_id %d timer %d msg send result %d",
+ 		  __entry->vcpu_id, __entry->timer_index,
+ 		  __entry->msg_send_result)
+ );
+ 
+ /*
+  * Tracepoint for stimer_cleanup.
+  */
+ TRACE_EVENT(kvm_hv_stimer_cleanup,
+ 	TP_PROTO(int vcpu_id, int timer_index),
+ 	TP_ARGS(vcpu_id, timer_index),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(int, vcpu_id)
+ 		__field(int, timer_index)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu_id = vcpu_id;
+ 		__entry->timer_index = timer_index;
+ 	),
+ 
+ 	TP_printk("vcpu_id %d timer %d",
+ 		  __entry->vcpu_id, __entry->timer_index)
+ );
+ 
+ /*
+  * Tracepoint for AMD AVIC
+  */
+ TRACE_EVENT(kvm_avic_incomplete_ipi,
+ 	    TP_PROTO(u32 vcpu, u32 icrh, u32 icrl, u32 id, u32 index),
+ 	    TP_ARGS(vcpu, icrh, icrl, id, index),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(u32, vcpu)
+ 		__field(u32, icrh)
+ 		__field(u32, icrl)
+ 		__field(u32, id)
+ 		__field(u32, index)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu = vcpu;
+ 		__entry->icrh = icrh;
+ 		__entry->icrl = icrl;
+ 		__entry->id = id;
+ 		__entry->index = index;
+ 	),
+ 
+ 	TP_printk("vcpu=%u, icrh:icrl=%#010x:%08x, id=%u, index=%u\n",
+ 		  __entry->vcpu, __entry->icrh, __entry->icrl,
+ 		  __entry->id, __entry->index)
+ );
+ 
+ TRACE_EVENT(kvm_avic_unaccelerated_access,
+ 	    TP_PROTO(u32 vcpu, u32 offset, bool ft, bool rw, u32 vec),
+ 	    TP_ARGS(vcpu, offset, ft, rw, vec),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(u32, vcpu)
+ 		__field(u32, offset)
+ 		__field(bool, ft)
+ 		__field(bool, rw)
+ 		__field(u32, vec)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->vcpu = vcpu;
+ 		__entry->offset = offset;
+ 		__entry->ft = ft;
+ 		__entry->rw = rw;
+ 		__entry->vec = vec;
+ 	),
+ 
+ 	TP_printk("vcpu=%u, offset=%#x(%s), %s, %s, vec=%#x\n",
+ 		  __entry->vcpu,
+ 		  __entry->offset,
+ 		  __print_symbolic(__entry->offset, kvm_trace_symbol_apic),
+ 		  __entry->ft ? "trap" : "fault",
+ 		  __entry->rw ? "write" : "read",
+ 		  __entry->vec)
+ );
+ 
++>>>>>>> 18f40c53e10f (svm: Add VMEXIT handlers for AVIC)
  #endif /* _TRACE_KVM_H */
  
  #undef TRACE_INCLUDE_PATH
* Unmerged path arch/x86/include/asm/kvm_host.h
diff --git a/arch/x86/include/uapi/asm/svm.h b/arch/x86/include/uapi/asm/svm.h
index b5d7640abc5d..8482cae2c779 100644
--- a/arch/x86/include/uapi/asm/svm.h
+++ b/arch/x86/include/uapi/asm/svm.h
@@ -73,6 +73,8 @@
 #define SVM_EXIT_MWAIT_COND    0x08c
 #define SVM_EXIT_XSETBV        0x08d
 #define SVM_EXIT_NPF           0x400
+#define SVM_EXIT_AVIC_INCOMPLETE_IPI		0x401
+#define SVM_EXIT_AVIC_UNACCELERATED_ACCESS	0x402
 
 #define SVM_EXIT_ERR           -1
 
@@ -106,8 +108,10 @@
 	{ SVM_EXIT_SMI,         "smi" }, \
 	{ SVM_EXIT_INIT,        "init" }, \
 	{ SVM_EXIT_VINTR,       "vintr" }, \
+	{ SVM_EXIT_CR0_SEL_WRITE, "cr0_sel_write" }, \
 	{ SVM_EXIT_CPUID,       "cpuid" }, \
 	{ SVM_EXIT_INVD,        "invd" }, \
+	{ SVM_EXIT_PAUSE,       "pause" }, \
 	{ SVM_EXIT_HLT,         "hlt" }, \
 	{ SVM_EXIT_INVLPG,      "invlpg" }, \
 	{ SVM_EXIT_INVLPGA,     "invlpga" }, \
@@ -126,7 +130,10 @@
 	{ SVM_EXIT_MONITOR,     "monitor" }, \
 	{ SVM_EXIT_MWAIT,       "mwait" }, \
 	{ SVM_EXIT_XSETBV,      "xsetbv" }, \
-	{ SVM_EXIT_NPF,         "npf" }
+	{ SVM_EXIT_NPF,         "npf" }, \
+	{ SVM_EXIT_RSM,         "rsm" }, \
+	{ SVM_EXIT_AVIC_INCOMPLETE_IPI,		"avic_incomplete_ipi" }, \
+	{ SVM_EXIT_AVIC_UNACCELERATED_ACCESS,   "avic_unaccelerated_access" }
 
 
 #endif /* _UAPI__SVM_H */
diff --git a/arch/x86/kvm/lapic.h b/arch/x86/kvm/lapic.h
index 639882f11237..b16a99437938 100644
--- a/arch/x86/kvm/lapic.h
+++ b/arch/x86/kvm/lapic.h
@@ -8,6 +8,9 @@
 #define KVM_APIC_INIT		0
 #define KVM_APIC_SIPI		1
 
+#define KVM_APIC_SHORT_MASK	0xc0000
+#define KVM_APIC_DEST_MASK	0x800
+
 struct kvm_timer {
 	struct hrtimer timer;
 	s64 period; 				/* unit: ns */
* Unmerged path arch/x86/kvm/svm.c
* Unmerged path arch/x86/kvm/trace.h
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index ae62c46b426c..9fbb42c5c80f 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -8556,3 +8556,5 @@ EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_write_tsc_offset);
 EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_ple_window);
 EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_pml_full);
 EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_pi_irte_update);
+EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_avic_unaccelerated_access);
+EXPORT_TRACEPOINT_SYMBOL_GPL(kvm_avic_incomplete_ipi);
