userfaultfd: non-cooperative: rollback userfaultfd_exit

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Andrea Arcangeli <aarcange@redhat.com>
commit dd0db88d8094a6d9d4d1fc5fcd56ab619f54ccf8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/dd0db88d.failed

Patch series "userfaultfd non-cooperative further update for 4.11 merge
window".

Unfortunately I noticed one relevant bug in userfaultfd_exit while doing
more testing.  I've been doing testing before and this was also tested
by kbuild bot and exercised by the selftest, but this bug never
reproduced before.

I dropped userfaultfd_exit as result.  I dropped it because of
implementation difficulty in receiving signals in __mmput and because I
think -ENOSPC as result from the background UFFDIO_COPY should be enough
already.

Before I decided to remove userfaultfd_exit, I noticed userfaultfd_exit
wasn't exercised by the selftest and when I tried to exercise it, after
moving it to a more correct place in __mmput where it would make more
sense and where the vma list is stable, it resulted in the
event_wait_completion in D state.  So then I added the second patch to
be sure even if we call userfaultfd_event_wait_completion too late
during task exit(), we won't risk to generate tasks in D state.  The
same check exists in handle_userfault() for the same reason, except it
makes a difference there, while here is just a robustness check and it's
run under WARN_ON_ONCE.

While looking at the userfaultfd_event_wait_completion() function I
looked back at its callers too while at it and I think it's not ok to
stop executing dup_fctx on the fcs list because we relay on
userfaultfd_event_wait_completion to execute
userfaultfd_ctx_put(fctx->orig) which is paired against
userfaultfd_ctx_get(fctx->orig) in dup_userfault just before
list_add(fcs).  This change only takes care of fctx->orig but this area
also needs further review looking for similar problems in fctx->new.

The only patch that is urgent is the first because it's an use after
free during a SMP race condition that affects all processes if
CONFIG_USERFAULTFD=y.  Very hard to reproduce though and probably
impossible without SLUB poisoning enabled.

This patch (of 3):

I once reproduced this oops with the userfaultfd selftest, it's not
easily reproducible and it requires SLUB poisoning to reproduce.

    general protection fault: 0000 [#1] SMP
    Modules linked in:
    CPU: 2 PID: 18421 Comm: userfaultfd Tainted: G               ------------ T 3.10.0+ #15
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.10.1-0-g8891697-prebuilt.qemu-project.org 04/01/2014
    task: ffff8801f83b9440 ti: ffff8801f833c000 task.ti: ffff8801f833c000
    RIP: 0010:[<ffffffff81451299>]  [<ffffffff81451299>] userfaultfd_exit+0x29/0xa0
    RSP: 0018:ffff8801f833fe80  EFLAGS: 00010202
    RAX: ffff8801f833ffd8 RBX: 6b6b6b6b6b6b6b6b RCX: ffff8801f83b9440
    RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffff8800baf18600
    RBP: ffff8801f833fee8 R08: 0000000000000000 R09: 0000000000000001
    R10: 0000000000000000 R11: ffffffff8127ceb3 R12: 0000000000000000
    R13: ffff8800baf186b0 R14: ffff8801f83b99f8 R15: 00007faed746c700
    FS:  0000000000000000(0000) GS:ffff88023fc80000(0000) knlGS:0000000000000000
    CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b
    CR2: 00007faf0966f028 CR3: 0000000001bc6000 CR4: 00000000000006e0
    DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000
    DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400
    Call Trace:
      do_exit+0x297/0xd10
      SyS_exit+0x17/0x20
      tracesys+0xdd/0xe2
    Code: 00 00 66 66 66 66 90 55 48 89 e5 41 54 53 48 83 ec 58 48 8b 1f 48 85 db 75 11 eb 73 66 0f 1f 44 00 00 48 8b 5b 10 48 85 db 74 64 <4c> 8b a3 b8 00 00 00 4d 85 e4 74 eb 41 f6 84 24 2c 01 00 00 80
    RIP  [<ffffffff81451299>] userfaultfd_exit+0x29/0xa0
     RSP <ffff8801f833fe80>
    ---[ end trace 9fecd6dcb442846a ]---

In the debugger I located the "mm" pointer in the stack and walking
mm->mmap->vm_next through the end shows the vma->vm_next list is fully
consistent and it is null terminated list as expected.  So this has to
be an SMP race condition where userfaultfd_exit was running while the
vma list was being modified by another CPU.

When userfaultfd_exit() run one of the ->vm_next pointers pointed to
SLAB_POISON (RBX is the vma pointer and is 0x6b6b..).

The reason is that it's not running in __mmput but while there are still
other threads running and it's not holding the mmap_sem (it can't as it
has to wait the even to be received by the manager).  So this is an use
after free that was happening for all processes.

One more implementation problem aside from the race condition:
userfaultfd_exit has really to check a flag in mm->flags before walking
the vma or it's going to slowdown the exit() path for regular tasks.

One more implementation problem: at that point signals can't be
delivered so it would also create a task in D state if the manager
doesn't read the event.

The major design issue: it overall looks superfluous as the manager can
check for -ENOSPC in the background transfer:

	if (mmget_not_zero(ctx->mm)) {
[..]
	} else {
		return -ENOSPC;
	}

It's safer to roll it back and re-introduce it later if at all.

[rppt@linux.vnet.ibm.com: documentation fixup after removal of UFFD_EVENT_EXIT]
  Link: http://lkml.kernel.org/r/1488345437-4364-1-git-send-email-rppt@linux.vnet.ibm.com
Link: http://lkml.kernel.org/r/20170224181957.19736-2-aarcange@redhat.com
	Signed-off-by: Andrea Arcangeli <aarcange@redhat.com>
	Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
	Acked-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
	Cc: "Dr. David Alan Gilbert" <dgilbert@redhat.com>
	Cc: Mike Kravetz <mike.kravetz@oracle.com>
	Cc: Pavel Emelyanov <xemul@parallels.com>
	Cc: Hillf Danton <hillf.zj@alibaba-inc.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit dd0db88d8094a6d9d4d1fc5fcd56ab619f54ccf8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/vm/userfaultfd.txt
#	fs/userfaultfd.c
#	include/linux/userfaultfd_k.h
#	include/uapi/linux/userfaultfd.h
diff --cc Documentation/vm/userfaultfd.txt
index 70a3c94d1941,bb2f945f87ab..000000000000
--- a/Documentation/vm/userfaultfd.txt
+++ b/Documentation/vm/userfaultfd.txt
@@@ -142,3 -162,68 +142,71 @@@ course the bitmap is updated accordingl
  sending the same page twice (in case the userfault is read by the
  postcopy thread just before UFFDIO_COPY|ZEROPAGE runs in the migration
  thread).
++<<<<<<< HEAD
++=======
+ 
+ == Non-cooperative userfaultfd ==
+ 
+ When the userfaultfd is monitored by an external manager, the manager
+ must be able to track changes in the process virtual memory
+ layout. Userfaultfd can notify the manager about such changes using
+ the same read(2) protocol as for the page fault notifications. The
+ manager has to explicitly enable these events by setting appropriate
+ bits in uffdio_api.features passed to UFFDIO_API ioctl:
+ 
+ UFFD_FEATURE_EVENT_FORK - enable userfaultfd hooks for fork(). When
+ this feature is enabled, the userfaultfd context of the parent process
+ is duplicated into the newly created process. The manager receives
+ UFFD_EVENT_FORK with file descriptor of the new userfaultfd context in
+ the uffd_msg.fork.
+ 
+ UFFD_FEATURE_EVENT_REMAP - enable notifications about mremap()
+ calls. When the non-cooperative process moves a virtual memory area to
+ a different location, the manager will receive UFFD_EVENT_REMAP. The
+ uffd_msg.remap will contain the old and new addresses of the area and
+ its original length.
+ 
+ UFFD_FEATURE_EVENT_REMOVE - enable notifications about
+ madvise(MADV_REMOVE) and madvise(MADV_DONTNEED) calls. The event
+ UFFD_EVENT_REMOVE will be generated upon these calls to madvise. The
+ uffd_msg.remove will contain start and end addresses of the removed
+ area.
+ 
+ UFFD_FEATURE_EVENT_UNMAP - enable notifications about memory
+ unmapping. The manager will get UFFD_EVENT_UNMAP with uffd_msg.remove
+ containing start and end addresses of the unmapped area.
+ 
+ Although the UFFD_FEATURE_EVENT_REMOVE and UFFD_FEATURE_EVENT_UNMAP
+ are pretty similar, they quite differ in the action expected from the
+ userfaultfd manager. In the former case, the virtual memory is
+ removed, but the area is not, the area remains monitored by the
+ userfaultfd, and if a page fault occurs in that area it will be
+ delivered to the manager. The proper resolution for such page fault is
+ to zeromap the faulting address. However, in the latter case, when an
+ area is unmapped, either explicitly (with munmap() system call), or
+ implicitly (e.g. during mremap()), the area is removed and in turn the
+ userfaultfd context for such area disappears too and the manager will
+ not get further userland page faults from the removed area. Still, the
+ notification is required in order to prevent manager from using
+ UFFDIO_COPY on the unmapped area.
+ 
+ Unlike userland page faults which have to be synchronous and require
+ explicit or implicit wakeup, all the events are delivered
+ asynchronously and the non-cooperative process resumes execution as
+ soon as manager executes read(). The userfaultfd manager should
+ carefully synchronize calls to UFFDIO_COPY with the events
+ processing. To aid the synchronization, the UFFDIO_COPY ioctl will
+ return -ENOSPC when the monitored process exits at the time of
+ UFFDIO_COPY, and -ENOENT, when the non-cooperative process has changed
+ its virtual memory layout simultaneously with outstanding UFFDIO_COPY
+ operation.
+ 
+ The current asynchronous model of the event delivery is optimal for
+ single threaded non-cooperative userfaultfd manager implementations. A
+ synchronous event delivery model can be added later as a new
+ userfaultfd feature to facilitate multithreading enhancements of the
+ non cooperative manager, for example to allow UFFDIO_COPY ioctls to
+ run in parallel to the event reception. Single threaded
+ implementations should continue to use the current async event
+ delivery model instead.
++>>>>>>> dd0db88d8094 (userfaultfd: non-cooperative: rollback userfaultfd_exit)
diff --cc fs/userfaultfd.c
index d7afc1f69ed4,16d0cc600fa9..000000000000
--- a/fs/userfaultfd.c
+++ b/fs/userfaultfd.c
@@@ -517,6 -579,202 +517,205 @@@ static void userfaultfd_event_complete(
  	__remove_wait_queue(&ctx->event_wqh, &ewq->wq);
  }
  
++<<<<<<< HEAD
++=======
+ int dup_userfaultfd(struct vm_area_struct *vma, struct list_head *fcs)
+ {
+ 	struct userfaultfd_ctx *ctx = NULL, *octx;
+ 	struct userfaultfd_fork_ctx *fctx;
+ 
+ 	octx = vma->vm_userfaultfd_ctx.ctx;
+ 	if (!octx || !(octx->features & UFFD_FEATURE_EVENT_FORK)) {
+ 		vma->vm_userfaultfd_ctx = NULL_VM_UFFD_CTX;
+ 		vma->vm_flags &= ~(VM_UFFD_WP | VM_UFFD_MISSING);
+ 		return 0;
+ 	}
+ 
+ 	list_for_each_entry(fctx, fcs, list)
+ 		if (fctx->orig == octx) {
+ 			ctx = fctx->new;
+ 			break;
+ 		}
+ 
+ 	if (!ctx) {
+ 		fctx = kmalloc(sizeof(*fctx), GFP_KERNEL);
+ 		if (!fctx)
+ 			return -ENOMEM;
+ 
+ 		ctx = kmem_cache_alloc(userfaultfd_ctx_cachep, GFP_KERNEL);
+ 		if (!ctx) {
+ 			kfree(fctx);
+ 			return -ENOMEM;
+ 		}
+ 
+ 		atomic_set(&ctx->refcount, 1);
+ 		ctx->flags = octx->flags;
+ 		ctx->state = UFFD_STATE_RUNNING;
+ 		ctx->features = octx->features;
+ 		ctx->released = false;
+ 		ctx->mm = vma->vm_mm;
+ 		atomic_inc(&ctx->mm->mm_count);
+ 
+ 		userfaultfd_ctx_get(octx);
+ 		fctx->orig = octx;
+ 		fctx->new = ctx;
+ 		list_add_tail(&fctx->list, fcs);
+ 	}
+ 
+ 	vma->vm_userfaultfd_ctx.ctx = ctx;
+ 	return 0;
+ }
+ 
+ static int dup_fctx(struct userfaultfd_fork_ctx *fctx)
+ {
+ 	struct userfaultfd_ctx *ctx = fctx->orig;
+ 	struct userfaultfd_wait_queue ewq;
+ 
+ 	msg_init(&ewq.msg);
+ 
+ 	ewq.msg.event = UFFD_EVENT_FORK;
+ 	ewq.msg.arg.reserved.reserved1 = (unsigned long)fctx->new;
+ 
+ 	return userfaultfd_event_wait_completion(ctx, &ewq);
+ }
+ 
+ void dup_userfaultfd_complete(struct list_head *fcs)
+ {
+ 	int ret = 0;
+ 	struct userfaultfd_fork_ctx *fctx, *n;
+ 
+ 	list_for_each_entry_safe(fctx, n, fcs, list) {
+ 		if (!ret)
+ 			ret = dup_fctx(fctx);
+ 		list_del(&fctx->list);
+ 		kfree(fctx);
+ 	}
+ }
+ 
+ void mremap_userfaultfd_prep(struct vm_area_struct *vma,
+ 			     struct vm_userfaultfd_ctx *vm_ctx)
+ {
+ 	struct userfaultfd_ctx *ctx;
+ 
+ 	ctx = vma->vm_userfaultfd_ctx.ctx;
+ 	if (ctx && (ctx->features & UFFD_FEATURE_EVENT_REMAP)) {
+ 		vm_ctx->ctx = ctx;
+ 		userfaultfd_ctx_get(ctx);
+ 	}
+ }
+ 
+ void mremap_userfaultfd_complete(struct vm_userfaultfd_ctx *vm_ctx,
+ 				 unsigned long from, unsigned long to,
+ 				 unsigned long len)
+ {
+ 	struct userfaultfd_ctx *ctx = vm_ctx->ctx;
+ 	struct userfaultfd_wait_queue ewq;
+ 
+ 	if (!ctx)
+ 		return;
+ 
+ 	if (to & ~PAGE_MASK) {
+ 		userfaultfd_ctx_put(ctx);
+ 		return;
+ 	}
+ 
+ 	msg_init(&ewq.msg);
+ 
+ 	ewq.msg.event = UFFD_EVENT_REMAP;
+ 	ewq.msg.arg.remap.from = from;
+ 	ewq.msg.arg.remap.to = to;
+ 	ewq.msg.arg.remap.len = len;
+ 
+ 	userfaultfd_event_wait_completion(ctx, &ewq);
+ }
+ 
+ void userfaultfd_remove(struct vm_area_struct *vma,
+ 			struct vm_area_struct **prev,
+ 			unsigned long start, unsigned long end)
+ {
+ 	struct mm_struct *mm = vma->vm_mm;
+ 	struct userfaultfd_ctx *ctx;
+ 	struct userfaultfd_wait_queue ewq;
+ 
+ 	ctx = vma->vm_userfaultfd_ctx.ctx;
+ 	if (!ctx || !(ctx->features & UFFD_FEATURE_EVENT_REMOVE))
+ 		return;
+ 
+ 	userfaultfd_ctx_get(ctx);
+ 	up_read(&mm->mmap_sem);
+ 
+ 	*prev = NULL; /* We wait for ACK w/o the mmap semaphore */
+ 
+ 	msg_init(&ewq.msg);
+ 
+ 	ewq.msg.event = UFFD_EVENT_REMOVE;
+ 	ewq.msg.arg.remove.start = start;
+ 	ewq.msg.arg.remove.end = end;
+ 
+ 	userfaultfd_event_wait_completion(ctx, &ewq);
+ 
+ 	down_read(&mm->mmap_sem);
+ }
+ 
+ static bool has_unmap_ctx(struct userfaultfd_ctx *ctx, struct list_head *unmaps,
+ 			  unsigned long start, unsigned long end)
+ {
+ 	struct userfaultfd_unmap_ctx *unmap_ctx;
+ 
+ 	list_for_each_entry(unmap_ctx, unmaps, list)
+ 		if (unmap_ctx->ctx == ctx && unmap_ctx->start == start &&
+ 		    unmap_ctx->end == end)
+ 			return true;
+ 
+ 	return false;
+ }
+ 
+ int userfaultfd_unmap_prep(struct vm_area_struct *vma,
+ 			   unsigned long start, unsigned long end,
+ 			   struct list_head *unmaps)
+ {
+ 	for ( ; vma && vma->vm_start < end; vma = vma->vm_next) {
+ 		struct userfaultfd_unmap_ctx *unmap_ctx;
+ 		struct userfaultfd_ctx *ctx = vma->vm_userfaultfd_ctx.ctx;
+ 
+ 		if (!ctx || !(ctx->features & UFFD_FEATURE_EVENT_UNMAP) ||
+ 		    has_unmap_ctx(ctx, unmaps, start, end))
+ 			continue;
+ 
+ 		unmap_ctx = kzalloc(sizeof(*unmap_ctx), GFP_KERNEL);
+ 		if (!unmap_ctx)
+ 			return -ENOMEM;
+ 
+ 		userfaultfd_ctx_get(ctx);
+ 		unmap_ctx->ctx = ctx;
+ 		unmap_ctx->start = start;
+ 		unmap_ctx->end = end;
+ 		list_add_tail(&unmap_ctx->list, unmaps);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ void userfaultfd_unmap_complete(struct mm_struct *mm, struct list_head *uf)
+ {
+ 	struct userfaultfd_unmap_ctx *ctx, *n;
+ 	struct userfaultfd_wait_queue ewq;
+ 
+ 	list_for_each_entry_safe(ctx, n, uf, list) {
+ 		msg_init(&ewq.msg);
+ 
+ 		ewq.msg.event = UFFD_EVENT_UNMAP;
+ 		ewq.msg.arg.remove.start = ctx->start;
+ 		ewq.msg.arg.remove.end = ctx->end;
+ 
+ 		userfaultfd_event_wait_completion(ctx->ctx, &ewq);
+ 
+ 		list_del(&ctx->list);
+ 		kfree(ctx);
+ 	}
+ }
+ 
++>>>>>>> dd0db88d8094 (userfaultfd: non-cooperative: rollback userfaultfd_exit)
  static int userfaultfd_release(struct inode *inode, struct file *file)
  {
  	struct userfaultfd_ctx *ctx = file->private_data;
diff --cc include/linux/userfaultfd_k.h
index 587480ad41b7,f2b79bf4c895..000000000000
--- a/include/linux/userfaultfd_k.h
+++ b/include/linux/userfaultfd_k.h
@@@ -53,6 -52,26 +53,29 @@@ static inline bool userfaultfd_armed(st
  	return vma->vm_flags & (VM_UFFD_MISSING | VM_UFFD_WP);
  }
  
++<<<<<<< HEAD
++=======
+ extern int dup_userfaultfd(struct vm_area_struct *, struct list_head *);
+ extern void dup_userfaultfd_complete(struct list_head *);
+ 
+ extern void mremap_userfaultfd_prep(struct vm_area_struct *,
+ 				    struct vm_userfaultfd_ctx *);
+ extern void mremap_userfaultfd_complete(struct vm_userfaultfd_ctx *,
+ 					unsigned long from, unsigned long to,
+ 					unsigned long len);
+ 
+ extern void userfaultfd_remove(struct vm_area_struct *vma,
+ 			       struct vm_area_struct **prev,
+ 			       unsigned long start,
+ 			       unsigned long end);
+ 
+ extern int userfaultfd_unmap_prep(struct vm_area_struct *vma,
+ 				  unsigned long start, unsigned long end,
+ 				  struct list_head *uf);
+ extern void userfaultfd_unmap_complete(struct mm_struct *mm,
+ 				       struct list_head *uf);
+ 
++>>>>>>> dd0db88d8094 (userfaultfd: non-cooperative: rollback userfaultfd_exit)
  #else /* CONFIG_USERFAULTFD */
  
  /* mm helpers */
@@@ -80,6 -96,47 +103,50 @@@ static inline bool userfaultfd_armed(st
  	return false;
  }
  
++<<<<<<< HEAD
++=======
+ static inline int dup_userfaultfd(struct vm_area_struct *vma,
+ 				  struct list_head *l)
+ {
+ 	return 0;
+ }
+ 
+ static inline void dup_userfaultfd_complete(struct list_head *l)
+ {
+ }
+ 
+ static inline void mremap_userfaultfd_prep(struct vm_area_struct *vma,
+ 					   struct vm_userfaultfd_ctx *ctx)
+ {
+ }
+ 
+ static inline void mremap_userfaultfd_complete(struct vm_userfaultfd_ctx *ctx,
+ 					       unsigned long from,
+ 					       unsigned long to,
+ 					       unsigned long len)
+ {
+ }
+ 
+ static inline void userfaultfd_remove(struct vm_area_struct *vma,
+ 				      struct vm_area_struct **prev,
+ 				      unsigned long start,
+ 				      unsigned long end)
+ {
+ }
+ 
+ static inline int userfaultfd_unmap_prep(struct vm_area_struct *vma,
+ 					 unsigned long start, unsigned long end,
+ 					 struct list_head *uf)
+ {
+ 	return 0;
+ }
+ 
+ static inline void userfaultfd_unmap_complete(struct mm_struct *mm,
+ 					      struct list_head *uf)
+ {
+ }
+ 
++>>>>>>> dd0db88d8094 (userfaultfd: non-cooperative: rollback userfaultfd_exit)
  #endif /* CONFIG_USERFAULTFD */
  
  #endif /* _LINUX_USERFAULTFD_K_H */
diff --cc include/uapi/linux/userfaultfd.h
index abfce32281cc,3b059530dac9..000000000000
--- a/include/uapi/linux/userfaultfd.h
+++ b/include/uapi/linux/userfaultfd.h
@@@ -18,12 -18,12 +18,21 @@@
   * means the userland is reading).
   */
  #define UFFD_API ((__u64)0xAA)
++<<<<<<< HEAD
 +/*
 + * After implementing the respective features it will become:
 + * #define UFFD_API_FEATURES (UFFD_FEATURE_PAGEFAULT_FLAG_WP | \
 + *			      UFFD_FEATURE_EVENT_FORK)
 + */
 +#define UFFD_API_FEATURES (0)
++=======
+ #define UFFD_API_FEATURES (UFFD_FEATURE_EVENT_FORK |		\
+ 			   UFFD_FEATURE_EVENT_REMAP |		\
+ 			   UFFD_FEATURE_EVENT_REMOVE |	\
+ 			   UFFD_FEATURE_EVENT_UNMAP |		\
+ 			   UFFD_FEATURE_MISSING_HUGETLBFS |	\
+ 			   UFFD_FEATURE_MISSING_SHMEM)
++>>>>>>> dd0db88d8094 (userfaultfd: non-cooperative: rollback userfaultfd_exit)
  #define UFFD_API_IOCTLS				\
  	((__u64)1 << _UFFDIO_REGISTER |		\
  	 (__u64)1 << _UFFDIO_UNREGISTER |	\
@@@ -93,9 -108,10 +102,15 @@@ struct uffd_msg 
   * Start at 0x12 and not at 0 to be more strict against bugs.
   */
  #define UFFD_EVENT_PAGEFAULT	0x12
 +#if 0 /* not available yet */
  #define UFFD_EVENT_FORK		0x13
++<<<<<<< HEAD
 +#endif
++=======
+ #define UFFD_EVENT_REMAP	0x14
+ #define UFFD_EVENT_REMOVE	0x15
+ #define UFFD_EVENT_UNMAP	0x16
++>>>>>>> dd0db88d8094 (userfaultfd: non-cooperative: rollback userfaultfd_exit)
  
  /* flags for UFFD_EVENT_PAGEFAULT */
  #define UFFD_PAGEFAULT_FLAG_WRITE	(1<<0)	/* If this was a write fault */
@@@ -113,11 -129,38 +128,19 @@@ struct uffdio_api 
  	 * Note: UFFD_EVENT_PAGEFAULT and UFFD_PAGEFAULT_FLAG_WRITE
  	 * are to be considered implicitly always enabled in all kernels as
  	 * long as the uffdio_api.api requested matches UFFD_API.
 -	 *
 -	 * UFFD_FEATURE_MISSING_HUGETLBFS means an UFFDIO_REGISTER
 -	 * with UFFDIO_REGISTER_MODE_MISSING mode will succeed on
 -	 * hugetlbfs virtual memory ranges. Adding or not adding
 -	 * UFFD_FEATURE_MISSING_HUGETLBFS to uffdio_api.features has
 -	 * no real functional effect after UFFDIO_API returns, but
 -	 * it's only useful for an initial feature set probe at
 -	 * UFFDIO_API time. There are two ways to use it:
 -	 *
 -	 * 1) by adding UFFD_FEATURE_MISSING_HUGETLBFS to the
 -	 *    uffdio_api.features before calling UFFDIO_API, an error
 -	 *    will be returned by UFFDIO_API on a kernel without
 -	 *    hugetlbfs missing support
 -	 *
 -	 * 2) the UFFD_FEATURE_MISSING_HUGETLBFS can not be added in
 -	 *    uffdio_api.features and instead it will be set by the
 -	 *    kernel in the uffdio_api.features if the kernel supports
 -	 *    it, so userland can later check if the feature flag is
 -	 *    present in uffdio_api.features after UFFDIO_API
 -	 *    succeeded.
 -	 *
 -	 * UFFD_FEATURE_MISSING_SHMEM works the same as
 -	 * UFFD_FEATURE_MISSING_HUGETLBFS, but it applies to shmem
 -	 * (i.e. tmpfs and other shmem based APIs).
  	 */
 +#if 0 /* not available yet */
  #define UFFD_FEATURE_PAGEFAULT_FLAG_WP		(1<<0)
  #define UFFD_FEATURE_EVENT_FORK			(1<<1)
++<<<<<<< HEAD
 +#endif
++=======
+ #define UFFD_FEATURE_EVENT_REMAP		(1<<2)
+ #define UFFD_FEATURE_EVENT_REMOVE		(1<<3)
+ #define UFFD_FEATURE_MISSING_HUGETLBFS		(1<<4)
+ #define UFFD_FEATURE_MISSING_SHMEM		(1<<5)
+ #define UFFD_FEATURE_EVENT_UNMAP		(1<<6)
++>>>>>>> dd0db88d8094 (userfaultfd: non-cooperative: rollback userfaultfd_exit)
  	__u64 features;
  
  	__u64 ioctls;
* Unmerged path Documentation/vm/userfaultfd.txt
* Unmerged path fs/userfaultfd.c
* Unmerged path include/linux/userfaultfd_k.h
* Unmerged path include/uapi/linux/userfaultfd.h
