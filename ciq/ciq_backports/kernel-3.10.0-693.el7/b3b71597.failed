amd-xgbe: Do traffic class setup when called through dcbnl

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Lendacky, Thomas <Thomas.Lendacky@amd.com>
commit b3b715974bfe69f626d6a633b8c96590de1b7338
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/b3b71597.failed

Currently the netdev traffic class setup is only performed when invoked
through the ndo_setup_tc interface. However, the same setup should be
performed when the dcbnl interface (ieee_setets) is invoked. Rework the
netdev traffic class setup to be invokable through either interface and
also provide the priority to traffic class mapping if available.

	Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit b3b715974bfe69f626d6a633b8c96590de1b7338)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/amd/xgbe/xgbe-dcb.c
#	drivers/net/ethernet/amd/xgbe/xgbe-dev.c
#	drivers/net/ethernet/amd/xgbe/xgbe-drv.c
#	drivers/net/ethernet/amd/xgbe/xgbe.h
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-dev.c
index a748fd8a1c58,43273c9823aa..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
@@@ -923,7 -1224,233 +923,237 @@@ static void xgbe_rx_desc_init(struct xg
  	DBGPR("<--rx_desc_init\n");
  }
  
++<<<<<<< HEAD
 +static void xgbe_pre_xmit(struct xgbe_channel *channel)
++=======
+ static void xgbe_update_tstamp_addend(struct xgbe_prv_data *pdata,
+ 				      unsigned int addend)
+ {
+ 	/* Set the addend register value and tell the device */
+ 	XGMAC_IOWRITE(pdata, MAC_TSAR, addend);
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_TSCR, TSADDREG, 1);
+ 
+ 	/* Wait for addend update to complete */
+ 	while (XGMAC_IOREAD_BITS(pdata, MAC_TSCR, TSADDREG))
+ 		udelay(5);
+ }
+ 
+ static void xgbe_set_tstamp_time(struct xgbe_prv_data *pdata, unsigned int sec,
+ 				 unsigned int nsec)
+ {
+ 	/* Set the time values and tell the device */
+ 	XGMAC_IOWRITE(pdata, MAC_STSUR, sec);
+ 	XGMAC_IOWRITE(pdata, MAC_STNUR, nsec);
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_TSCR, TSINIT, 1);
+ 
+ 	/* Wait for time update to complete */
+ 	while (XGMAC_IOREAD_BITS(pdata, MAC_TSCR, TSINIT))
+ 		udelay(5);
+ }
+ 
+ static u64 xgbe_get_tstamp_time(struct xgbe_prv_data *pdata)
+ {
+ 	u64 nsec;
+ 
+ 	nsec = XGMAC_IOREAD(pdata, MAC_STSR);
+ 	nsec *= NSEC_PER_SEC;
+ 	nsec += XGMAC_IOREAD(pdata, MAC_STNR);
+ 
+ 	return nsec;
+ }
+ 
+ static u64 xgbe_get_tx_tstamp(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int tx_snr;
+ 	u64 nsec;
+ 
+ 	tx_snr = XGMAC_IOREAD(pdata, MAC_TXSNR);
+ 	if (XGMAC_GET_BITS(tx_snr, MAC_TXSNR, TXTSSTSMIS))
+ 		return 0;
+ 
+ 	nsec = XGMAC_IOREAD(pdata, MAC_TXSSR);
+ 	nsec *= NSEC_PER_SEC;
+ 	nsec += tx_snr;
+ 
+ 	return nsec;
+ }
+ 
+ static void xgbe_get_rx_tstamp(struct xgbe_packet_data *packet,
+ 			       struct xgbe_ring_desc *rdesc)
+ {
+ 	u64 nsec;
+ 
+ 	if (XGMAC_GET_BITS_LE(rdesc->desc3, RX_CONTEXT_DESC3, TSA) &&
+ 	    !XGMAC_GET_BITS_LE(rdesc->desc3, RX_CONTEXT_DESC3, TSD)) {
+ 		nsec = le32_to_cpu(rdesc->desc1);
+ 		nsec <<= 32;
+ 		nsec |= le32_to_cpu(rdesc->desc0);
+ 		if (nsec != 0xffffffffffffffffULL) {
+ 			packet->rx_tstamp = nsec;
+ 			XGMAC_SET_BITS(packet->attributes, RX_PACKET_ATTRIBUTES,
+ 				       RX_TSTAMP, 1);
+ 		}
+ 	}
+ }
+ 
+ static int xgbe_config_tstamp(struct xgbe_prv_data *pdata,
+ 			      unsigned int mac_tscr)
+ {
+ 	/* Set one nano-second accuracy */
+ 	XGMAC_SET_BITS(mac_tscr, MAC_TSCR, TSCTRLSSR, 1);
+ 
+ 	/* Set fine timestamp update */
+ 	XGMAC_SET_BITS(mac_tscr, MAC_TSCR, TSCFUPDT, 1);
+ 
+ 	/* Overwrite earlier timestamps */
+ 	XGMAC_SET_BITS(mac_tscr, MAC_TSCR, TXTSSTSM, 1);
+ 
+ 	XGMAC_IOWRITE(pdata, MAC_TSCR, mac_tscr);
+ 
+ 	/* Exit if timestamping is not enabled */
+ 	if (!XGMAC_GET_BITS(mac_tscr, MAC_TSCR, TSENA))
+ 		return 0;
+ 
+ 	/* Initialize time registers */
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_SSIR, SSINC, XGBE_TSTAMP_SSINC);
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_SSIR, SNSINC, XGBE_TSTAMP_SNSINC);
+ 	xgbe_update_tstamp_addend(pdata, pdata->tstamp_addend);
+ 	xgbe_set_tstamp_time(pdata, 0, 0);
+ 
+ 	/* Initialize the timecounter */
+ 	timecounter_init(&pdata->tstamp_tc, &pdata->tstamp_cc,
+ 			 ktime_to_ns(ktime_get_real()));
+ 
+ 	return 0;
+ }
+ 
+ static void xgbe_config_tc(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int offset, queue, prio;
+ 	u8 i;
+ 
+ 	netdev_reset_tc(pdata->netdev);
+ 	if (!pdata->num_tcs)
+ 		return;
+ 
+ 	netdev_set_num_tc(pdata->netdev, pdata->num_tcs);
+ 
+ 	for (i = 0, queue = 0, offset = 0; i < pdata->num_tcs; i++) {
+ 		while ((queue < pdata->tx_q_count) &&
+ 		       (pdata->q2tc_map[queue] == i))
+ 			queue++;
+ 
+ 		netif_dbg(pdata, drv, pdata->netdev, "TC%u using TXq%u-%u\n",
+ 			  i, offset, queue - 1);
+ 		netdev_set_tc_queue(pdata->netdev, i, queue - offset, offset);
+ 		offset = queue;
+ 	}
+ 
+ 	if (!pdata->ets)
+ 		return;
+ 
+ 	for (prio = 0; prio < IEEE_8021QAZ_MAX_TCS; prio++)
+ 		netdev_set_prio_tc_map(pdata->netdev, prio,
+ 				       pdata->ets->prio_tc[prio]);
+ }
+ 
+ static void xgbe_config_dcb_tc(struct xgbe_prv_data *pdata)
+ {
+ 	struct ieee_ets *ets = pdata->ets;
+ 	unsigned int total_weight, min_weight, weight;
+ 	unsigned int mask, reg, reg_val;
+ 	unsigned int i, prio;
+ 
+ 	if (!ets)
+ 		return;
+ 
+ 	/* Set Tx to deficit weighted round robin scheduling algorithm (when
+ 	 * traffic class is using ETS algorithm)
+ 	 */
+ 	XGMAC_IOWRITE_BITS(pdata, MTL_OMR, ETSALG, MTL_ETSALG_DWRR);
+ 
+ 	/* Set Traffic Class algorithms */
+ 	total_weight = pdata->netdev->mtu * pdata->hw_feat.tc_cnt;
+ 	min_weight = total_weight / 100;
+ 	if (!min_weight)
+ 		min_weight = 1;
+ 
+ 	for (i = 0; i < pdata->hw_feat.tc_cnt; i++) {
+ 		/* Map the priorities to the traffic class */
+ 		mask = 0;
+ 		for (prio = 0; prio < IEEE_8021QAZ_MAX_TCS; prio++) {
+ 			if (ets->prio_tc[prio] == i)
+ 				mask |= (1 << prio);
+ 		}
+ 		mask &= 0xff;
+ 
+ 		netif_dbg(pdata, drv, pdata->netdev, "TC%u PRIO mask=%#x\n",
+ 			  i, mask);
+ 		reg = MTL_TCPM0R + (MTL_TCPM_INC * (i / MTL_TCPM_TC_PER_REG));
+ 		reg_val = XGMAC_IOREAD(pdata, reg);
+ 
+ 		reg_val &= ~(0xff << ((i % MTL_TCPM_TC_PER_REG) << 3));
+ 		reg_val |= (mask << ((i % MTL_TCPM_TC_PER_REG) << 3));
+ 
+ 		XGMAC_IOWRITE(pdata, reg, reg_val);
+ 
+ 		/* Set the traffic class algorithm */
+ 		switch (ets->tc_tsa[i]) {
+ 		case IEEE_8021QAZ_TSA_STRICT:
+ 			netif_dbg(pdata, drv, pdata->netdev,
+ 				  "TC%u using SP\n", i);
+ 			XGMAC_MTL_IOWRITE_BITS(pdata, i, MTL_TC_ETSCR, TSA,
+ 					       MTL_TSA_SP);
+ 			break;
+ 		case IEEE_8021QAZ_TSA_ETS:
+ 			weight = total_weight * ets->tc_tx_bw[i] / 100;
+ 			weight = clamp(weight, min_weight, total_weight);
+ 
+ 			netif_dbg(pdata, drv, pdata->netdev,
+ 				  "TC%u using DWRR (weight %u)\n", i, weight);
+ 			XGMAC_MTL_IOWRITE_BITS(pdata, i, MTL_TC_ETSCR, TSA,
+ 					       MTL_TSA_ETS);
+ 			XGMAC_MTL_IOWRITE_BITS(pdata, i, MTL_TC_QWR, QW,
+ 					       weight);
+ 			break;
+ 		}
+ 	}
+ 
+ 	xgbe_config_tc(pdata);
+ }
+ 
+ static void xgbe_config_dcb_pfc(struct xgbe_prv_data *pdata)
+ {
+ 	xgbe_config_flow_control(pdata);
+ }
+ 
+ static void xgbe_tx_start_xmit(struct xgbe_channel *channel,
+ 			       struct xgbe_ring *ring)
+ {
+ 	struct xgbe_prv_data *pdata = channel->pdata;
+ 	struct xgbe_ring_data *rdata;
+ 
+ 	/* Make sure everything is written before the register write */
+ 	wmb();
+ 
+ 	/* Issue a poll command to Tx DMA by writing address
+ 	 * of next immediate free descriptor */
+ 	rdata = XGBE_GET_DESC_DATA(ring, ring->cur);
+ 	XGMAC_DMA_IOWRITE(channel, DMA_CH_TDTR_LO,
+ 			  lower_32_bits(rdata->rdesc_dma));
+ 
+ 	/* Start the Tx timer */
+ 	if (pdata->tx_usecs && !channel->tx_timer_active) {
+ 		channel->tx_timer_active = 1;
+ 		mod_timer(&channel->tx_timer,
+ 			  jiffies + usecs_to_jiffies(pdata->tx_usecs));
+ 	}
+ 
+ 	ring->tx.xmit_more = 0;
+ }
+ 
+ static void xgbe_dev_xmit(struct xgbe_channel *channel)
++>>>>>>> b3b715974bfe (amd-xgbe: Do traffic class setup when called through dcbnl)
  {
  	struct xgbe_prv_data *pdata = channel->pdata;
  	struct xgbe_ring *ring = channel->tx_ring;
@@@ -2258,5 -2934,23 +2488,26 @@@ void xgbe_init_function_ptrs_dev(struc
  	hw_if->rx_mmc_int = xgbe_rx_mmc_int;
  	hw_if->read_mmc_stats = xgbe_read_mmc_stats;
  
++<<<<<<< HEAD
++=======
+ 	/* For PTP config */
+ 	hw_if->config_tstamp = xgbe_config_tstamp;
+ 	hw_if->update_tstamp_addend = xgbe_update_tstamp_addend;
+ 	hw_if->set_tstamp_time = xgbe_set_tstamp_time;
+ 	hw_if->get_tstamp_time = xgbe_get_tstamp_time;
+ 	hw_if->get_tx_tstamp = xgbe_get_tx_tstamp;
+ 
+ 	/* For Data Center Bridging config */
+ 	hw_if->config_tc = xgbe_config_tc;
+ 	hw_if->config_dcb_tc = xgbe_config_dcb_tc;
+ 	hw_if->config_dcb_pfc = xgbe_config_dcb_pfc;
+ 
+ 	/* For Receive Side Scaling */
+ 	hw_if->enable_rss = xgbe_enable_rss;
+ 	hw_if->disable_rss = xgbe_disable_rss;
+ 	hw_if->set_rss_hash_key = xgbe_set_rss_hash_key;
+ 	hw_if->set_rss_lookup_table = xgbe_set_rss_lookup_table;
+ 
++>>>>>>> b3b715974bfe (amd-xgbe: Do traffic class setup when called through dcbnl)
  	DBGPR("<--xgbe_init_function_ptrs\n");
  }
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-drv.c
index d58e85811bc9,33606840ae15..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
@@@ -1029,6 -1626,26 +1029,29 @@@ static void xgbe_poll_controller(struc
  }
  #endif /* End CONFIG_NET_POLL_CONTROLLER */
  
++<<<<<<< HEAD
++=======
+ static int xgbe_setup_tc(struct net_device *netdev, u32 handle, __be16 proto,
+ 			 struct tc_to_netdev *tc_to_netdev)
+ {
+ 	struct xgbe_prv_data *pdata = netdev_priv(netdev);
+ 	u8 tc;
+ 
+ 	if (handle != TC_H_ROOT || tc_to_netdev->type != TC_SETUP_MQPRIO)
+ 		return -EINVAL;
+ 
+ 	tc = tc_to_netdev->tc;
+ 
+ 	if (tc > pdata->hw_feat.tc_cnt)
+ 		return -EINVAL;
+ 
+ 	pdata->num_tcs = tc;
+ 	pdata->hw_if.config_tc(pdata);
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> b3b715974bfe (amd-xgbe: Do traffic class setup when called through dcbnl)
  static int xgbe_set_features(struct net_device *netdev,
  			     netdev_features_t features)
  {
diff --cc drivers/net/ethernet/amd/xgbe/xgbe.h
index 1903f878545a,ca2835485450..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe.h
+++ b/drivers/net/ethernet/amd/xgbe/xgbe.h
@@@ -461,6 -663,39 +461,42 @@@ struct xgbe_hw_if 
  	void (*rx_mmc_int)(struct xgbe_prv_data *);
  	void (*tx_mmc_int)(struct xgbe_prv_data *);
  	void (*read_mmc_stats)(struct xgbe_prv_data *);
++<<<<<<< HEAD
++=======
+ 
+ 	/* For Timestamp config */
+ 	int (*config_tstamp)(struct xgbe_prv_data *, unsigned int);
+ 	void (*update_tstamp_addend)(struct xgbe_prv_data *, unsigned int);
+ 	void (*set_tstamp_time)(struct xgbe_prv_data *, unsigned int sec,
+ 				unsigned int nsec);
+ 	u64 (*get_tstamp_time)(struct xgbe_prv_data *);
+ 	u64 (*get_tx_tstamp)(struct xgbe_prv_data *);
+ 
+ 	/* For Data Center Bridging config */
+ 	void (*config_tc)(struct xgbe_prv_data *);
+ 	void (*config_dcb_tc)(struct xgbe_prv_data *);
+ 	void (*config_dcb_pfc)(struct xgbe_prv_data *);
+ 
+ 	/* For Receive Side Scaling */
+ 	int (*enable_rss)(struct xgbe_prv_data *);
+ 	int (*disable_rss)(struct xgbe_prv_data *);
+ 	int (*set_rss_hash_key)(struct xgbe_prv_data *, const u8 *);
+ 	int (*set_rss_lookup_table)(struct xgbe_prv_data *, const u32 *);
+ };
+ 
+ struct xgbe_phy_if {
+ 	/* For initial PHY setup */
+ 	void (*phy_init)(struct xgbe_prv_data *);
+ 
+ 	/* For PHY support when setting device up/down */
+ 	int (*phy_reset)(struct xgbe_prv_data *);
+ 	int (*phy_start)(struct xgbe_prv_data *);
+ 	void (*phy_stop)(struct xgbe_prv_data *);
+ 
+ 	/* For PHY support while device is up */
+ 	void (*phy_status)(struct xgbe_prv_data *);
+ 	int (*phy_config_aneg)(struct xgbe_prv_data *);
++>>>>>>> b3b715974bfe (amd-xgbe: Do traffic class setup when called through dcbnl)
  };
  
  struct xgbe_desc_if {
@@@ -598,9 -852,36 +634,39 @@@ struct xgbe_prv_data 
  	netdev_features_t netdev_features;
  	struct napi_struct napi;
  	struct xgbe_mmc_stats mmc_stats;
 -	struct xgbe_ext_stats ext_stats;
  
++<<<<<<< HEAD
 +	/* System clock value used for Rx watchdog */
 +	struct clk *sysclock;
++=======
+ 	/* Filtering support */
+ 	unsigned long active_vlans[BITS_TO_LONGS(VLAN_N_VID)];
+ 
+ 	/* Device clocks */
+ 	struct clk *sysclk;
+ 	unsigned long sysclk_rate;
+ 	struct clk *ptpclk;
+ 	unsigned long ptpclk_rate;
+ 
+ 	/* Timestamp support */
+ 	spinlock_t tstamp_lock;
+ 	struct ptp_clock_info ptp_clock_info;
+ 	struct ptp_clock *ptp_clock;
+ 	struct hwtstamp_config tstamp_config;
+ 	struct cyclecounter tstamp_cc;
+ 	struct timecounter tstamp_tc;
+ 	unsigned int tstamp_addend;
+ 	struct work_struct tx_tstamp_work;
+ 	struct sk_buff *tx_tstamp_skb;
+ 	u64 tx_tstamp;
+ 
+ 	/* DCB support */
+ 	struct ieee_ets *ets;
+ 	struct ieee_pfc *pfc;
+ 	unsigned int q2tc_map[XGBE_MAX_QUEUES];
+ 	unsigned int prio2q_map[IEEE_8021QAZ_MAX_TCS];
+ 	u8 num_tcs;
++>>>>>>> b3b715974bfe (amd-xgbe: Do traffic class setup when called through dcbnl)
  
  	/* Hardware features of the device */
  	struct xgbe_hw_features hw_feat;
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-dcb.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-dcb.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-dev.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-drv.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe.h
