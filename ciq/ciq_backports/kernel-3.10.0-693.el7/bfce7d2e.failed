xfs: factor mapping out of xfs_do_writepage

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Dave Chinner <dchinner@redhat.com>
commit bfce7d2e2d5ee05e9d465888905c66a70a9c243c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/bfce7d2e.failed

Separate out the bufferhead based mapping from the writepage code so
that we have a clear separation of the page operations and the
bufferhead state.

	Signed-off-by: Dave Chinner <dchinner@redhat.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Dave Chinner <david@fromorbit.com>

(cherry picked from commit bfce7d2e2d5ee05e9d465888905c66a70a9c243c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/xfs_aops.c
diff --cc fs/xfs/xfs_aops.c
index acf6c4a54883,6f5c95f94add..000000000000
--- a/fs/xfs/xfs_aops.c
+++ b/fs/xfs/xfs_aops.c
@@@ -932,21 -877,16 +1053,28 @@@ out_error
   * For any other dirty buffer heads on the page we should flush them.
   */
  STATIC int
 -xfs_do_writepage(
 +xfs_vm_writepage(
  	struct page		*page,
 -	struct writeback_control *wbc,
 -	void			*data)
 +	struct writeback_control *wbc)
  {
 -	struct xfs_writepage_ctx *wpc = data;
  	struct inode		*inode = page->mapping->host;
++<<<<<<< HEAD
 +	struct buffer_head	*bh, *head;
 +	struct xfs_bmbt_irec	imap;
 +	xfs_ioend_t		*ioend = NULL, *iohead = NULL;
++=======
++>>>>>>> bfce7d2e2d5e (xfs: factor mapping out of xfs_do_writepage)
  	loff_t			offset;
 +	unsigned int		type;
  	__uint64_t              end_offset;
++<<<<<<< HEAD
 +	pgoff_t                 end_index, last_index;
 +	ssize_t			len;
 +	int			err, imap_valid = 0, uptodate = 1;
 +	int			count = 0;
++=======
+ 	pgoff_t                 end_index;
++>>>>>>> bfce7d2e2d5e (xfs: factor mapping out of xfs_do_writepage)
  
  	trace_xfs_writepage(inode, page, 0, 0);
  
@@@ -1040,154 -979,7 +1168,158 @@@
  		end_offset = offset;
  	}
  
++<<<<<<< HEAD
 +	len = 1 << inode->i_blkbits;
 +
 +	bh = head = page_buffers(page);
 +	offset = page_offset(page);
 +	type = XFS_IO_OVERWRITE;
 +
 +	do {
 +		int new_ioend = 0;
 +
 +		if (offset >= end_offset)
 +			break;
 +		if (!buffer_uptodate(bh))
 +			uptodate = 0;
 +
 +		/*
 +		 * set_page_dirty dirties all buffers in a page, independent
 +		 * of their state.  The dirty state however is entirely
 +		 * meaningless for holes (!mapped && uptodate), so skip
 +		 * buffers covering holes here.
 +		 */
 +		if (!buffer_mapped(bh) && buffer_uptodate(bh)) {
 +			imap_valid = 0;
 +			continue;
 +		}
 +
 +		if (buffer_unwritten(bh)) {
 +			if (type != XFS_IO_UNWRITTEN) {
 +				type = XFS_IO_UNWRITTEN;
 +				imap_valid = 0;
 +			}
 +		} else if (buffer_delay(bh)) {
 +			if (type != XFS_IO_DELALLOC) {
 +				type = XFS_IO_DELALLOC;
 +				imap_valid = 0;
 +			}
 +		} else if (buffer_uptodate(bh)) {
 +			if (type != XFS_IO_OVERWRITE) {
 +				type = XFS_IO_OVERWRITE;
 +				imap_valid = 0;
 +			}
 +		} else {
 +			if (PageUptodate(page))
 +				ASSERT(buffer_mapped(bh));
 +			/*
 +			 * This buffer is not uptodate and will not be
 +			 * written to disk.  Ensure that we will put any
 +			 * subsequent writeable buffers into a new
 +			 * ioend.
 +			 */
 +			imap_valid = 0;
 +			continue;
 +		}
 +
 +		if (imap_valid)
 +			imap_valid = xfs_imap_valid(inode, &imap, offset);
 +		if (!imap_valid) {
 +			/*
 +			 * If we didn't have a valid mapping then we need to
 +			 * put the new mapping into a separate ioend structure.
 +			 * This ensures non-contiguous extents always have
 +			 * separate ioends, which is particularly important
 +			 * for unwritten extent conversion at I/O completion
 +			 * time.
 +			 */
 +			new_ioend = 1;
 +			err = xfs_map_blocks(inode, offset, &imap, type);
 +			if (err)
 +				goto error;
 +			imap_valid = xfs_imap_valid(inode, &imap, offset);
 +		}
 +		if (imap_valid) {
 +			lock_buffer(bh);
 +			if (type != XFS_IO_OVERWRITE)
 +				xfs_map_at_offset(inode, bh, &imap, offset);
 +			xfs_add_to_ioend(inode, bh, offset, type, &ioend,
 +					 new_ioend);
 +			count++;
 +		}
 +
 +		if (!iohead)
 +			iohead = ioend;
 +
 +	} while (offset += len, ((bh = bh->b_this_page) != head));
 +
 +	if (uptodate && bh == head)
 +		SetPageUptodate(page);
 +
 +	xfs_start_page_writeback(page, 1, count);
 +
 +	/* if there is no IO to be submitted for this page, we are done */
 +	if (!ioend)
 +		return 0;
 +
 +	ASSERT(iohead);
 +	ASSERT(err == 0);
 +
 +	/*
 +	 * Any errors from this point onwards need tobe reported through the IO
 +	 * completion path as we have marked the initial page as under writeback
 +	 * and unlocked it.
 +	 */
 +	if (imap_valid) {
 +		xfs_off_t		end_index;
 +
 +		end_index = imap.br_startoff + imap.br_blockcount;
 +
 +		/* to bytes */
 +		end_index <<= inode->i_blkbits;
 +
 +		/* to pages */
 +		end_index = (end_index - 1) >> PAGE_CACHE_SHIFT;
 +
 +		/* check against file size */
 +		if (end_index > last_index)
 +			end_index = last_index;
 +
 +		xfs_cluster_write(inode, page->index + 1, &imap, &ioend,
 +				  wbc, end_index);
 +	}
 +
 +	return xfs_writepage_submit(ioend, iohead, wbc, 0);
 +
 +error:
 +	/*
 +	 * On error, we have to fail the iohead here because we buffers locked
 +	 * in the ioend chain. If we don't do this, we'll deadlock invalidating
 +	 * the page as that tries to lock the buffers on the page. Also, because
 +	 * we may have set pages under writeback, we have to run IO completion to
 +	 * mark the error state of the IO appropriately, so we can't cancel the
 +	 * ioend directly here. That means we have to mark this page as under
 +	 * writeback if we included any buffers from it in the ioend chain.
 +	 */
 +	if (count)
 +		xfs_start_page_writeback(page, 0, count);
 +	xfs_writepage_submit(ioend, iohead, wbc, err);
 +
 +	/*
 +	 * We can only discard the page we had the IO error on if we haven't
 +	 * included it in the ioend above. If it has already been errored out,
 +	 * the it is unlocked and we can't touch it here.
 +	 */
 +	if (!count) {
 +		xfs_aops_discard_page(page);
 +		ClearPageUptodate(page);
 +		unlock_page(page);
 +	}
 +	mapping_set_error(page->mapping, err);
 +	return err;
++=======
+ 	return xfs_writepage_map(wpc, inode, page, offset, end_offset);
++>>>>>>> bfce7d2e2d5e (xfs: factor mapping out of xfs_do_writepage)
  
  redirty:
  	redirty_page_for_writepage(wbc, page);
* Unmerged path fs/xfs/xfs_aops.c
