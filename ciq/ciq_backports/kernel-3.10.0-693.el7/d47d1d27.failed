pmem: return EIO on read_pmem() failure

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Stefan Hajnoczi <stefanha@redhat.com>
commit d47d1d27fd6206c18806440f6ebddf51a806be4f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/d47d1d27.failed

The read_pmem() function uses memcpy_mcsafe() on x86 where an EFAULT
error code indicates a failed read.  Block I/O should use EIO to
indicate failure.  Other pmem code paths (like bad blocks) already use
EIO so let's be consistent.

This fixes compatibility with consumers like btrfs that try to parse the
specific error code rather than treat all errors the same.

	Reviewed-by: Jeff Moyer <jmoyer@redhat.com>
	Signed-off-by: Stefan Hajnoczi <stefanha@redhat.com>
	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
(cherry picked from commit d47d1d27fd6206c18806440f6ebddf51a806be4f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvdimm/pmem.c
diff --cc drivers/nvdimm/pmem.c
index 26fd9ba8de78,5b536be5a12e..000000000000
--- a/drivers/nvdimm/pmem.c
+++ b/drivers/nvdimm/pmem.c
@@@ -51,18 -51,48 +51,45 @@@ static void pmem_clear_poison(struct pm
  		unsigned int len)
  {
  	struct device *dev = to_dev(pmem);
 -	sector_t sector;
 -	long cleared;
 -	int rc = 0;
 +	sector_t sector, cleared;
  
  	sector = (offset - pmem->data_offset) / 512;
 +	cleared = nvdimm_clear_poison(dev, pmem->phys_addr + offset, len) / 512;
  
 -	cleared = nvdimm_clear_poison(dev, pmem->phys_addr + offset, len);
 -	if (cleared < len)
 -		rc = -EIO;
 -	if (cleared > 0 && cleared / 512) {
 -		cleared /= 512;
 -		dev_dbg(dev, "%s: %#llx clear %ld sector%s\n", __func__,
 -				(unsigned long long) sector, cleared,
 -				cleared > 1 ? "s" : "");
 +	if (cleared) {
 +		dev_dbg(dev, "%s: %#llx clear %ld sector%s\n",
 +				__func__, (unsigned long long) sector,
 +				cleared, cleared > 1 ? "s" : "");
  		badblocks_clear(&pmem->bb, sector, cleared);
  	}
 -
  	invalidate_pmem(pmem->virt_addr + offset, len);
++<<<<<<< HEAD
++=======
+ 
+ 	return rc;
+ }
+ 
+ static void write_pmem(void *pmem_addr, struct page *page,
+ 		unsigned int off, unsigned int len)
+ {
+ 	void *mem = kmap_atomic(page);
+ 
+ 	memcpy_to_pmem(pmem_addr, mem + off, len);
+ 	kunmap_atomic(mem);
+ }
+ 
+ static int read_pmem(struct page *page, unsigned int off,
+ 		void *pmem_addr, unsigned int len)
+ {
+ 	int rc;
+ 	void *mem = kmap_atomic(page);
+ 
+ 	rc = memcpy_from_pmem(mem + off, pmem_addr, len);
+ 	kunmap_atomic(mem);
+ 	if (rc)
+ 		return -EIO;
+ 	return 0;
++>>>>>>> d47d1d27fd62 (pmem: return EIO on read_pmem() failure)
  }
  
  static int pmem_do_bvec(struct pmem_device *pmem, struct page *page,
* Unmerged path drivers/nvdimm/pmem.c
