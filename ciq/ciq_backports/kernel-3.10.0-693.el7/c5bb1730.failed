net/mlx5: Refactor mlx5_add_flow_rule

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [netdrv] mlx5: Refactor mlx5_add_flow_rule (Don Dutile) [1383601 1417284]
Rebuild_FUZZ: 94.29%
commit-author Maor Gottlieb <maorg@mellanox.com>
commit c5bb17302e734967822be559cf661704b707b4ed
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/c5bb1730.failed

Reduce the set of arguments passed to mlx5_add_flow_rule
by introducing flow_spec structure.

	Signed-off-by: Maor Gottlieb <maorg@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit c5bb17302e734967822be559cf661704b707b4ed)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_arfs.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
index 4df49e660587,2e1e86316fe7..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
@@@ -512,33 -156,34 +512,45 @@@ enum mlx5e_vlan_rule_type 
  
  static int __mlx5e_add_vlan_rule(struct mlx5e_priv *priv,
  				 enum mlx5e_vlan_rule_type rule_type,
- 				 u16 vid, u32 *mc, u32 *mv)
+ 				 u16 vid, struct mlx5_flow_spec *spec)
  {
 -	struct mlx5_flow_table *ft = priv->fs.vlan.ft.t;
 +	struct mlx5_flow_table *ft = priv->fts.vlan.t;
  	struct mlx5_flow_destination dest;
- 	u8 match_criteria_enable = 0;
  	struct mlx5_flow_rule **rule_p;
  	int err = 0;
  
  	dest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
 -	dest.ft = priv->fs.l2.ft.t;
 +	dest.ft = priv->fts.main.t;
  
- 	match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
- 	MLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.vlan_tag);
+ 	spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 	MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.vlan_tag);
  
  	switch (rule_type) {
  	case MLX5E_VLAN_RULE_TYPE_UNTAGGED:
 -		rule_p = &priv->fs.vlan.untagged_rule;
 +		rule_p = &priv->vlan.untagged_rule;
  		break;
  	case MLX5E_VLAN_RULE_TYPE_ANY_VID:
++<<<<<<< HEAD
 +		rule_p = &priv->vlan.any_vlan_rule;
 +		MLX5_SET(fte_match_param, mv, outer_headers.vlan_tag, 1);
 +		break;
 +	default: /* MLX5E_VLAN_RULE_TYPE_MATCH_VID */
 +		rule_p = &priv->vlan.active_vlans_rule[vid];
 +		MLX5_SET(fte_match_param, mv, outer_headers.vlan_tag, 1);
 +		MLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.first_vid);
 +		MLX5_SET(fte_match_param, mv, outer_headers.first_vid, vid);
++=======
+ 		rule_p = &priv->fs.vlan.any_vlan_rule;
+ 		MLX5_SET(fte_match_param, spec->match_value, outer_headers.vlan_tag, 1);
+ 		break;
+ 	default: /* MLX5E_VLAN_RULE_TYPE_MATCH_VID */
+ 		rule_p = &priv->fs.vlan.active_vlans_rule[vid];
+ 		MLX5_SET(fte_match_param, spec->match_value, outer_headers.vlan_tag, 1);
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria,
+ 				 outer_headers.first_vid);
+ 		MLX5_SET(fte_match_param, spec->match_value, outer_headers.first_vid,
+ 			 vid);
++>>>>>>> c5bb17302e73 (net/mlx5: Refactor mlx5_add_flow_rule)
  		break;
  	}
  
@@@ -1077,9 -524,418 +1083,422 @@@ static void mlx5e_destroy_flow_table(st
  	ft->t = NULL;
  }
  
 -static void mlx5e_cleanup_ttc_rules(struct mlx5e_ttc_table *ttc)
 +static void mlx5e_destroy_main_flow_table(struct mlx5e_priv *priv)
  {
++<<<<<<< HEAD
 +	mlx5e_destroy_flow_table(&priv->fts.main);
++=======
+ 	int i;
+ 
+ 	for (i = 0; i < MLX5E_NUM_TT; i++) {
+ 		if (!IS_ERR_OR_NULL(ttc->rules[i])) {
+ 			mlx5_del_flow_rule(ttc->rules[i]);
+ 			ttc->rules[i] = NULL;
+ 		}
+ 	}
+ }
+ 
+ static struct {
+ 	u16 etype;
+ 	u8 proto;
+ } ttc_rules[] = {
+ 	[MLX5E_TT_IPV4_TCP] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = IPPROTO_TCP,
+ 	},
+ 	[MLX5E_TT_IPV6_TCP] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = IPPROTO_TCP,
+ 	},
+ 	[MLX5E_TT_IPV4_UDP] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = IPPROTO_UDP,
+ 	},
+ 	[MLX5E_TT_IPV6_UDP] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = IPPROTO_UDP,
+ 	},
+ 	[MLX5E_TT_IPV4_IPSEC_AH] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = IPPROTO_AH,
+ 	},
+ 	[MLX5E_TT_IPV6_IPSEC_AH] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = IPPROTO_AH,
+ 	},
+ 	[MLX5E_TT_IPV4_IPSEC_ESP] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = IPPROTO_ESP,
+ 	},
+ 	[MLX5E_TT_IPV6_IPSEC_ESP] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = IPPROTO_ESP,
+ 	},
+ 	[MLX5E_TT_IPV4] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = 0,
+ 	},
+ 	[MLX5E_TT_IPV6] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = 0,
+ 	},
+ 	[MLX5E_TT_ANY] = {
+ 		.etype = 0,
+ 		.proto = 0,
+ 	},
+ };
+ 
+ static struct mlx5_flow_rule *mlx5e_generate_ttc_rule(struct mlx5e_priv *priv,
+ 						      struct mlx5_flow_table *ft,
+ 						      struct mlx5_flow_destination *dest,
+ 						      u16 etype,
+ 						      u8 proto)
+ {
+ 	struct mlx5_flow_rule *rule;
+ 	struct mlx5_flow_spec *spec;
+ 	int err = 0;
+ 
+ 	spec = mlx5_vzalloc(sizeof(*spec));
+ 	if (!spec) {
+ 		netdev_err(priv->netdev, "%s: alloc failed\n", __func__);
+ 		return ERR_PTR(-ENOMEM);
+ 	}
+ 
+ 	if (proto) {
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.ip_protocol);
+ 		MLX5_SET(fte_match_param, spec->match_value, outer_headers.ip_protocol, proto);
+ 	}
+ 	if (etype) {
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.ethertype);
+ 		MLX5_SET(fte_match_param, spec->match_value, outer_headers.ethertype, etype);
+ 	}
+ 
+ 	rule = mlx5_add_flow_rule(ft, spec,
+ 				  MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 				  MLX5_FS_DEFAULT_FLOW_TAG,
+ 				  dest);
+ 	if (IS_ERR(rule)) {
+ 		err = PTR_ERR(rule);
+ 		netdev_err(priv->netdev, "%s: add rule failed\n", __func__);
+ 	}
+ 
+ 	kvfree(spec);
+ 	return err ? ERR_PTR(err) : rule;
+ }
+ 
+ static int mlx5e_generate_ttc_table_rules(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5_flow_destination dest;
+ 	struct mlx5e_ttc_table *ttc;
+ 	struct mlx5_flow_rule **rules;
+ 	struct mlx5_flow_table *ft;
+ 	int tt;
+ 	int err;
+ 
+ 	ttc = &priv->fs.ttc;
+ 	ft = ttc->ft.t;
+ 	rules = ttc->rules;
+ 
+ 	dest.type = MLX5_FLOW_DESTINATION_TYPE_TIR;
+ 	for (tt = 0; tt < MLX5E_NUM_TT; tt++) {
+ 		if (tt == MLX5E_TT_ANY)
+ 			dest.tir_num = priv->direct_tir[0].tirn;
+ 		else
+ 			dest.tir_num = priv->indir_tir[tt].tirn;
+ 		rules[tt] = mlx5e_generate_ttc_rule(priv, ft, &dest,
+ 						    ttc_rules[tt].etype,
+ 						    ttc_rules[tt].proto);
+ 		if (IS_ERR(rules[tt]))
+ 			goto del_rules;
+ 	}
+ 
+ 	return 0;
+ 
+ del_rules:
+ 	err = PTR_ERR(rules[tt]);
+ 	rules[tt] = NULL;
+ 	mlx5e_cleanup_ttc_rules(ttc);
+ 	return err;
+ }
+ 
+ #define MLX5E_TTC_NUM_GROUPS	3
+ #define MLX5E_TTC_GROUP1_SIZE	BIT(3)
+ #define MLX5E_TTC_GROUP2_SIZE	BIT(1)
+ #define MLX5E_TTC_GROUP3_SIZE	BIT(0)
+ #define MLX5E_TTC_TABLE_SIZE	(MLX5E_TTC_GROUP1_SIZE +\
+ 				 MLX5E_TTC_GROUP2_SIZE +\
+ 				 MLX5E_TTC_GROUP3_SIZE)
+ static int mlx5e_create_ttc_table_groups(struct mlx5e_ttc_table *ttc)
+ {
+ 	int inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);
+ 	struct mlx5e_flow_table *ft = &ttc->ft;
+ 	int ix = 0;
+ 	u32 *in;
+ 	int err;
+ 	u8 *mc;
+ 
+ 	ft->g = kcalloc(MLX5E_TTC_NUM_GROUPS,
+ 			sizeof(*ft->g), GFP_KERNEL);
+ 	if (!ft->g)
+ 		return -ENOMEM;
+ 	in = mlx5_vzalloc(inlen);
+ 	if (!in) {
+ 		kfree(ft->g);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	/* L4 Group */
+ 	mc = MLX5_ADDR_OF(create_flow_group_in, in, match_criteria);
+ 	MLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.ip_protocol);
+ 	MLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.ethertype);
+ 	MLX5_SET_CFG(in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_TTC_GROUP1_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err;
+ 	ft->num_groups++;
+ 
+ 	/* L3 Group */
+ 	MLX5_SET(fte_match_param, mc, outer_headers.ip_protocol, 0);
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_TTC_GROUP2_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err;
+ 	ft->num_groups++;
+ 
+ 	/* Any Group */
+ 	memset(in, 0, inlen);
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_TTC_GROUP3_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err;
+ 	ft->num_groups++;
+ 
+ 	kvfree(in);
+ 	return 0;
+ 
+ err:
+ 	err = PTR_ERR(ft->g[ft->num_groups]);
+ 	ft->g[ft->num_groups] = NULL;
+ 	kvfree(in);
+ 
+ 	return err;
+ }
+ 
+ static void mlx5e_destroy_ttc_table(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_ttc_table *ttc = &priv->fs.ttc;
+ 
+ 	mlx5e_cleanup_ttc_rules(ttc);
+ 	mlx5e_destroy_flow_table(&ttc->ft);
+ }
+ 
+ static int mlx5e_create_ttc_table(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_ttc_table *ttc = &priv->fs.ttc;
+ 	struct mlx5e_flow_table *ft = &ttc->ft;
+ 	int err;
+ 
+ 	ft->t = mlx5_create_flow_table(priv->fs.ns, MLX5E_NIC_PRIO,
+ 				       MLX5E_TTC_TABLE_SIZE, MLX5E_TTC_FT_LEVEL);
+ 	if (IS_ERR(ft->t)) {
+ 		err = PTR_ERR(ft->t);
+ 		ft->t = NULL;
+ 		return err;
+ 	}
+ 
+ 	err = mlx5e_create_ttc_table_groups(ttc);
+ 	if (err)
+ 		goto err;
+ 
+ 	err = mlx5e_generate_ttc_table_rules(priv);
+ 	if (err)
+ 		goto err;
+ 
+ 	return 0;
+ err:
+ 	mlx5e_destroy_flow_table(ft);
+ 	return err;
+ }
+ 
+ static void mlx5e_del_l2_flow_rule(struct mlx5e_priv *priv,
+ 				   struct mlx5e_l2_rule *ai)
+ {
+ 	if (!IS_ERR_OR_NULL(ai->rule)) {
+ 		mlx5_del_flow_rule(ai->rule);
+ 		ai->rule = NULL;
+ 	}
+ }
+ 
+ static int mlx5e_add_l2_flow_rule(struct mlx5e_priv *priv,
+ 				  struct mlx5e_l2_rule *ai, int type)
+ {
+ 	struct mlx5_flow_table *ft = priv->fs.l2.ft.t;
+ 	struct mlx5_flow_destination dest;
+ 	struct mlx5_flow_spec *spec;
+ 	int err = 0;
+ 	u8 *mc_dmac;
+ 	u8 *mv_dmac;
+ 
+ 	spec = mlx5_vzalloc(sizeof(*spec));
+ 	if (!spec) {
+ 		netdev_err(priv->netdev, "%s: alloc failed\n", __func__);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	mc_dmac = MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
+ 			       outer_headers.dmac_47_16);
+ 	mv_dmac = MLX5_ADDR_OF(fte_match_param, spec->match_value,
+ 			       outer_headers.dmac_47_16);
+ 
+ 	dest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
+ 	dest.ft = priv->fs.ttc.ft.t;
+ 
+ 	switch (type) {
+ 	case MLX5E_FULLMATCH:
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 		eth_broadcast_addr(mc_dmac);
+ 		ether_addr_copy(mv_dmac, ai->addr);
+ 		break;
+ 
+ 	case MLX5E_ALLMULTI:
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 		mc_dmac[0] = 0x01;
+ 		mv_dmac[0] = 0x01;
+ 		break;
+ 
+ 	case MLX5E_PROMISC:
+ 		break;
+ 	}
+ 
+ 	ai->rule = mlx5_add_flow_rule(ft, spec,
+ 				      MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 				      MLX5_FS_DEFAULT_FLOW_TAG, &dest);
+ 	if (IS_ERR(ai->rule)) {
+ 		netdev_err(priv->netdev, "%s: add l2 rule(mac:%pM) failed\n",
+ 			   __func__, mv_dmac);
+ 		err = PTR_ERR(ai->rule);
+ 		ai->rule = NULL;
+ 	}
+ 
+ 	kvfree(spec);
+ 
+ 	return err;
+ }
+ 
+ #define MLX5E_NUM_L2_GROUPS	   3
+ #define MLX5E_L2_GROUP1_SIZE	   BIT(0)
+ #define MLX5E_L2_GROUP2_SIZE	   BIT(15)
+ #define MLX5E_L2_GROUP3_SIZE	   BIT(0)
+ #define MLX5E_L2_TABLE_SIZE	   (MLX5E_L2_GROUP1_SIZE +\
+ 				    MLX5E_L2_GROUP2_SIZE +\
+ 				    MLX5E_L2_GROUP3_SIZE)
+ static int mlx5e_create_l2_table_groups(struct mlx5e_l2_table *l2_table)
+ {
+ 	int inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);
+ 	struct mlx5e_flow_table *ft = &l2_table->ft;
+ 	int ix = 0;
+ 	u8 *mc_dmac;
+ 	u32 *in;
+ 	int err;
+ 	u8 *mc;
+ 
+ 	ft->g = kcalloc(MLX5E_NUM_L2_GROUPS, sizeof(*ft->g), GFP_KERNEL);
+ 	if (!ft->g)
+ 		return -ENOMEM;
+ 	in = mlx5_vzalloc(inlen);
+ 	if (!in) {
+ 		kfree(ft->g);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	mc = MLX5_ADDR_OF(create_flow_group_in, in, match_criteria);
+ 	mc_dmac = MLX5_ADDR_OF(fte_match_param, mc,
+ 			       outer_headers.dmac_47_16);
+ 	/* Flow Group for promiscuous */
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_L2_GROUP1_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err_destroy_groups;
+ 	ft->num_groups++;
+ 
+ 	/* Flow Group for full match */
+ 	eth_broadcast_addr(mc_dmac);
+ 	MLX5_SET_CFG(in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_L2_GROUP2_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err_destroy_groups;
+ 	ft->num_groups++;
+ 
+ 	/* Flow Group for allmulti */
+ 	eth_zero_addr(mc_dmac);
+ 	mc_dmac[0] = 0x01;
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_L2_GROUP3_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err_destroy_groups;
+ 	ft->num_groups++;
+ 
+ 	kvfree(in);
+ 	return 0;
+ 
+ err_destroy_groups:
+ 	err = PTR_ERR(ft->g[ft->num_groups]);
+ 	ft->g[ft->num_groups] = NULL;
+ 	mlx5e_destroy_groups(ft);
+ 	kvfree(in);
+ 
+ 	return err;
+ }
+ 
+ static void mlx5e_destroy_l2_table(struct mlx5e_priv *priv)
+ {
+ 	mlx5e_destroy_flow_table(&priv->fs.l2.ft);
+ }
+ 
+ static int mlx5e_create_l2_table(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_l2_table *l2_table = &priv->fs.l2;
+ 	struct mlx5e_flow_table *ft = &l2_table->ft;
+ 	int err;
+ 
+ 	ft->num_groups = 0;
+ 	ft->t = mlx5_create_flow_table(priv->fs.ns, MLX5E_NIC_PRIO,
+ 				       MLX5E_L2_TABLE_SIZE, MLX5E_L2_FT_LEVEL);
+ 
+ 	if (IS_ERR(ft->t)) {
+ 		err = PTR_ERR(ft->t);
+ 		ft->t = NULL;
+ 		return err;
+ 	}
+ 
+ 	err = mlx5e_create_l2_table_groups(l2_table);
+ 	if (err)
+ 		goto err_destroy_flow_table;
+ 
+ 	return 0;
+ 
+ err_destroy_flow_table:
+ 	mlx5_destroy_flow_table(ft->t);
+ 	ft->t = NULL;
+ 
+ 	return err;
++>>>>>>> c5bb17302e73 (net/mlx5: Refactor mlx5_add_flow_rule)
  }
  
  #define MLX5E_NUM_VLAN_GROUPS	2
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
index 6c7352099dd6,f6d667797ee1..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@@ -330,42 -329,51 +330,66 @@@ __esw_fdb_set_vport_rule(struct mlx5_es
  			    MLX5_MATCH_OUTER_HEADERS);
  	struct mlx5_flow_rule *flow_rule = NULL;
  	struct mlx5_flow_destination dest;
++<<<<<<< HEAD
++=======
+ 	struct mlx5_flow_spec *spec;
+ 	void *mv_misc = NULL;
+ 	void *mc_misc = NULL;
++>>>>>>> c5bb17302e73 (net/mlx5: Refactor mlx5_add_flow_rule)
  	u8 *dmac_v = NULL;
  	u8 *dmac_c = NULL;
- 	u32 *match_v;
- 	u32 *match_c;
  
++<<<<<<< HEAD
 +	match_v = kzalloc(MLX5_ST_SZ_BYTES(fte_match_param), GFP_KERNEL);
 +	match_c = kzalloc(MLX5_ST_SZ_BYTES(fte_match_param), GFP_KERNEL);
 +	if (!match_v || !match_c) {
 +		pr_warn("FDB: Failed to alloc match parameters\n");
 +		goto out;
 +	}
++=======
+ 	if (rx_rule)
+ 		match_header |= MLX5_MATCH_MISC_PARAMETERS;
++>>>>>>> c5bb17302e73 (net/mlx5: Refactor mlx5_add_flow_rule)
  
- 	dmac_v = MLX5_ADDR_OF(fte_match_param, match_v,
+ 	spec = mlx5_vzalloc(sizeof(*spec));
+ 	if (!spec) {
+ 		pr_warn("FDB: Failed to alloc match parameters\n");
+ 		return NULL;
+ 	}
+ 	dmac_v = MLX5_ADDR_OF(fte_match_param, spec->match_value,
  			      outer_headers.dmac_47_16);
- 	dmac_c = MLX5_ADDR_OF(fte_match_param, match_c,
+ 	dmac_c = MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
  			      outer_headers.dmac_47_16);
  
 -	if (match_header & MLX5_MATCH_OUTER_HEADERS) {
 +	if (match_header == MLX5_MATCH_OUTER_HEADERS) {
  		ether_addr_copy(dmac_v, mac_v);
  		ether_addr_copy(dmac_c, mac_c);
  	}
  
++<<<<<<< HEAD
++=======
+ 	if (match_header & MLX5_MATCH_MISC_PARAMETERS) {
+ 		mv_misc  = MLX5_ADDR_OF(fte_match_param, spec->match_value,
+ 					misc_parameters);
+ 		mc_misc  = MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
+ 					misc_parameters);
+ 		MLX5_SET(fte_match_set_misc, mv_misc, source_port, UPLINK_VPORT);
+ 		MLX5_SET_TO_ONES(fte_match_set_misc, mc_misc, source_port);
+ 	}
+ 
++>>>>>>> c5bb17302e73 (net/mlx5: Refactor mlx5_add_flow_rule)
  	dest.type = MLX5_FLOW_DESTINATION_TYPE_VPORT;
  	dest.vport_num = vport;
  
  	esw_debug(esw->dev,
  		  "\tFDB add rule dmac_v(%pM) dmac_c(%pM) -> vport(%d)\n",
  		  dmac_v, dmac_c, vport);
+ 	spec->match_criteria_enable = match_header;
  	flow_rule =
- 		mlx5_add_flow_rule(esw->fdb_table.fdb,
- 				   match_header,
- 				   match_c,
- 				   match_v,
+ 		mlx5_add_flow_rule(esw->fdb_table.fdb, spec,
  				   MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
  				   0, &dest);
 -	if (IS_ERR(flow_rule)) {
 +	if (IS_ERR_OR_NULL(flow_rule)) {
  		pr_warn(
  			"FDB: Failed to add flow rule: dmac_v(%pM) dmac_c(%pM) -> vport(%d), err(%ld)\n",
  			 dmac_v, dmac_c, vport, PTR_ERR(flow_rule));
@@@ -1044,15 -1290,26 +1067,20 @@@ static void esw_vport_disable_ingress_a
  static int esw_vport_ingress_config(struct mlx5_eswitch *esw,
  				    struct mlx5_vport *vport)
  {
++<<<<<<< HEAD
 +	u32 *match_v;
 +	u32 *match_c;
++=======
+ 	struct mlx5_flow_spec *spec;
+ 	u8 smac[ETH_ALEN];
++>>>>>>> c5bb17302e73 (net/mlx5: Refactor mlx5_add_flow_rule)
  	int err = 0;
 -	u8 *smac_v;
  
 -	if (vport->spoofchk) {
 -		err = mlx5_query_nic_vport_mac_address(esw->dev, vport->vport, smac);
 -		if (err) {
 -			esw_warn(esw->dev,
 -				 "vport[%d] configure ingress rules failed, query smac failed, err(%d)\n",
 -				 vport->vport, err);
 -			return err;
 -		}
 -
 -		if (!is_valid_ether_addr(smac)) {
 -			mlx5_core_warn(esw->dev,
 -				       "vport[%d] configure ingress rules failed, illegal mac with spoofchk\n",
 -				       vport->vport);
 -			return -EPERM;
 -		}
 +	if (IS_ERR_OR_NULL(vport->ingress.acl)) {
 +		esw_warn(esw->dev,
 +			 "vport[%d] configure ingress rules failed, ingress acl is not initialized!\n",
 +			 vport->vport);
 +		return -EPERM;
  	}
  
  	esw_vport_cleanup_ingress_rules(esw, vport);
@@@ -1072,45 -1332,66 +1099,81 @@@
  			 vport->vport, err);
  		goto out;
  	}
 +	MLX5_SET_TO_ONES(fte_match_param, match_c, outer_headers.vlan_tag);
 +	MLX5_SET_TO_ONES(fte_match_param, match_v, outer_headers.vlan_tag);
  
++<<<<<<< HEAD
 +	vport->ingress.drop_rule =
 +		mlx5_add_flow_rule(vport->ingress.acl,
 +				   MLX5_MATCH_OUTER_HEADERS,
 +				   match_c,
 +				   match_v,
++=======
+ 	if (vport->vlan || vport->qos)
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.vlan_tag);
+ 
+ 	if (vport->spoofchk) {
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.smac_47_16);
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.smac_15_0);
+ 		smac_v = MLX5_ADDR_OF(fte_match_param,
+ 				      spec->match_value,
+ 				      outer_headers.smac_47_16);
+ 		ether_addr_copy(smac_v, smac);
+ 	}
+ 
+ 	spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 	vport->ingress.allow_rule =
+ 		mlx5_add_flow_rule(vport->ingress.acl, spec,
+ 				   MLX5_FLOW_CONTEXT_ACTION_ALLOW,
+ 				   0, NULL);
+ 	if (IS_ERR(vport->ingress.allow_rule)) {
+ 		err = PTR_ERR(vport->ingress.allow_rule);
+ 		pr_warn("vport[%d] configure ingress allow rule, err(%d)\n",
+ 			vport->vport, err);
+ 		vport->ingress.allow_rule = NULL;
+ 		goto out;
+ 	}
+ 
+ 	memset(spec, 0, sizeof(*spec));
+ 	vport->ingress.drop_rule =
+ 		mlx5_add_flow_rule(vport->ingress.acl, spec,
++>>>>>>> c5bb17302e73 (net/mlx5: Refactor mlx5_add_flow_rule)
  				   MLX5_FLOW_CONTEXT_ACTION_DROP,
  				   0, NULL);
 -	if (IS_ERR(vport->ingress.drop_rule)) {
 +	if (IS_ERR_OR_NULL(vport->ingress.drop_rule)) {
  		err = PTR_ERR(vport->ingress.drop_rule);
 -		pr_warn("vport[%d] configure ingress drop rule, err(%d)\n",
 +		pr_warn("vport[%d] configure ingress rules, err(%d)\n",
  			vport->vport, err);
  		vport->ingress.drop_rule = NULL;
 -		goto out;
  	}
 -
  out:
++<<<<<<< HEAD
 +	kfree(match_v);
 +	kfree(match_c);
++=======
+ 	if (err)
+ 		esw_vport_cleanup_ingress_rules(esw, vport);
+ 	kvfree(spec);
++>>>>>>> c5bb17302e73 (net/mlx5: Refactor mlx5_add_flow_rule)
  	return err;
  }
  
  static int esw_vport_egress_config(struct mlx5_eswitch *esw,
  				   struct mlx5_vport *vport)
  {
- 	u32 *match_v;
- 	u32 *match_c;
+ 	struct mlx5_flow_spec *spec;
  	int err = 0;
  
 +	if (IS_ERR_OR_NULL(vport->egress.acl)) {
 +		esw_warn(esw->dev, "vport[%d] configure rgress rules failed, egress acl is not initialized!\n",
 +			 vport->vport);
 +		return -EPERM;
 +	}
 +
  	esw_vport_cleanup_egress_rules(esw, vport);
  
 -	if (!vport->vlan && !vport->qos) {
 -		esw_vport_disable_egress_acl(esw, vport);
 +	if (!vport->vlan && !vport->qos)
  		return 0;
 -	}
 -
 -	esw_vport_enable_egress_acl(esw, vport);
  
  	esw_debug(esw->dev,
  		  "vport[%d] configure egress rules, vlan(%d) qos(%d)\n",
@@@ -1126,19 -1406,17 +1188,17 @@@
  	}
  
  	/* Allowed vlan rule */
- 	MLX5_SET_TO_ONES(fte_match_param, match_c, outer_headers.vlan_tag);
- 	MLX5_SET_TO_ONES(fte_match_param, match_v, outer_headers.vlan_tag);
- 	MLX5_SET_TO_ONES(fte_match_param, match_c, outer_headers.first_vid);
- 	MLX5_SET(fte_match_param, match_v, outer_headers.first_vid, vport->vlan);
+ 	MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.vlan_tag);
+ 	MLX5_SET_TO_ONES(fte_match_param, spec->match_value, outer_headers.vlan_tag);
+ 	MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.first_vid);
+ 	MLX5_SET(fte_match_param, spec->match_value, outer_headers.first_vid, vport->vlan);
  
+ 	spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
  	vport->egress.allowed_vlan =
- 		mlx5_add_flow_rule(vport->egress.acl,
- 				   MLX5_MATCH_OUTER_HEADERS,
- 				   match_c,
- 				   match_v,
+ 		mlx5_add_flow_rule(vport->egress.acl, spec,
  				   MLX5_FLOW_CONTEXT_ACTION_ALLOW,
  				   0, NULL);
 -	if (IS_ERR(vport->egress.allowed_vlan)) {
 +	if (IS_ERR_OR_NULL(vport->egress.allowed_vlan)) {
  		err = PTR_ERR(vport->egress.allowed_vlan);
  		pr_warn("vport[%d] configure egress allowed vlan rule failed, err(%d)\n",
  			vport->vport, err);
@@@ -1147,16 -1425,12 +1207,12 @@@
  	}
  
  	/* Drop others rule (star rule) */
- 	memset(match_c, 0, MLX5_ST_SZ_BYTES(fte_match_param));
- 	memset(match_v, 0, MLX5_ST_SZ_BYTES(fte_match_param));
+ 	memset(spec, 0, sizeof(*spec));
  	vport->egress.drop_rule =
- 		mlx5_add_flow_rule(vport->egress.acl,
- 				   0,
- 				   match_c,
- 				   match_v,
+ 		mlx5_add_flow_rule(vport->egress.acl, spec,
  				   MLX5_FLOW_CONTEXT_ACTION_DROP,
  				   0, NULL);
 -	if (IS_ERR(vport->egress.drop_rule)) {
 +	if (IS_ERR_OR_NULL(vport->egress.drop_rule)) {
  		err = PTR_ERR(vport->egress.drop_rule);
  		pr_warn("vport[%d] configure egress drop rule failed, err(%d)\n",
  			vport->vport, err);
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_arfs.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --git a/drivers/infiniband/hw/mlx5/main.c b/drivers/infiniband/hw/mlx5/main.c
index c59be3674778..48c9e4f43002 100644
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@ -1860,21 +1860,18 @@ static struct mlx5_ib_flow_handler *create_flow_rule(struct mlx5_ib_dev *dev,
 {
 	struct mlx5_flow_table	*ft = ft_prio->flow_table;
 	struct mlx5_ib_flow_handler *handler;
+	struct mlx5_flow_spec *spec;
 	void *ib_flow = flow_attr + 1;
-	u8 match_criteria_enable = 0;
 	unsigned int spec_index;
-	u32 *match_c;
-	u32 *match_v;
 	u32 action;
 	int err = 0;
 
 	if (!is_valid_attr(flow_attr))
 		return ERR_PTR(-EINVAL);
 
-	match_c = kzalloc(MLX5_ST_SZ_BYTES(fte_match_param), GFP_KERNEL);
-	match_v = kzalloc(MLX5_ST_SZ_BYTES(fte_match_param), GFP_KERNEL);
+	spec = mlx5_vzalloc(sizeof(*spec));
 	handler = kzalloc(sizeof(*handler), GFP_KERNEL);
-	if (!handler || !match_c || !match_v) {
+	if (!handler || !spec) {
 		err = -ENOMEM;
 		goto free;
 	}
@@ -1882,7 +1879,8 @@ static struct mlx5_ib_flow_handler *create_flow_rule(struct mlx5_ib_dev *dev,
 	INIT_LIST_HEAD(&handler->list);
 
 	for (spec_index = 0; spec_index < flow_attr->num_of_specs; spec_index++) {
-		err = parse_flow_attr(match_c, match_v, ib_flow);
+		err = parse_flow_attr(spec->match_criteria,
+				      spec->match_value, ib_flow);
 		if (err < 0)
 			goto free;
 
@@ -1890,11 +1888,11 @@ static struct mlx5_ib_flow_handler *create_flow_rule(struct mlx5_ib_dev *dev,
 	}
 
 	/* Outer header support only */
-	match_criteria_enable = (!outer_header_zero(match_c)) << 0;
+	spec->match_criteria_enable = (!outer_header_zero(spec->match_criteria))
+		<< 0;
 	action = dst ? MLX5_FLOW_CONTEXT_ACTION_FWD_DEST :
 		MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO;
-	handler->rule = mlx5_add_flow_rule(ft, match_criteria_enable,
-					   match_c, match_v,
+	handler->rule = mlx5_add_flow_rule(ft, spec,
 					   action,
 					   MLX5_FS_DEFAULT_FLOW_TAG,
 					   dst);
@@ -1911,8 +1909,7 @@ static struct mlx5_ib_flow_handler *create_flow_rule(struct mlx5_ib_dev *dev,
 free:
 	if (err)
 		kfree(handler);
-	kfree(match_c);
-	kfree(match_v);
+	kvfree(spec);
 	return err ? ERR_PTR(err) : handler;
 }
 
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_arfs.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
index de1cde8dc012..72b71de2a794 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
@@ -1106,9 +1106,7 @@ unlock_fg:
 
 static struct mlx5_flow_rule *
 _mlx5_add_flow_rule(struct mlx5_flow_table *ft,
-		    u8 match_criteria_enable,
-		    u32 *match_criteria,
-		    u32 *match_value,
+		   struct mlx5_flow_spec *spec,
 		    u32 action,
 		    u32 flow_tag,
 		    struct mlx5_flow_destination *dest)
@@ -1122,22 +1120,23 @@ _mlx5_add_flow_rule(struct mlx5_flow_table *ft,
 	nested_lock_ref_node(&ft->node, FS_MUTEX_GRANDPARENT);
 	fs_for_each_fg(g, ft)
 		if (compare_match_criteria(g->mask.match_criteria_enable,
-					   match_criteria_enable,
+					   spec->match_criteria_enable,
 					   g->mask.match_criteria,
-					   match_criteria)) {
-			rule = add_rule_fg(g, match_value,
+					   spec->match_criteria)) {
+			rule = add_rule_fg(g, spec->match_value,
 					   action, flow_tag, dest);
 			if (!IS_ERR(rule) || PTR_ERR(rule) != -ENOSPC)
 				goto unlock;
 		}
 
-	g = create_autogroup(ft, match_criteria_enable, match_criteria);
+	g = create_autogroup(ft, spec->match_criteria_enable,
+			     spec->match_criteria);
 	if (IS_ERR(g)) {
 		rule = (void *)g;
 		goto unlock;
 	}
 
-	rule = add_rule_fg(g, match_value,
+	rule = add_rule_fg(g, spec->match_value,
 			   action, flow_tag, dest);
 	if (IS_ERR(rule)) {
 		/* Remove assumes refcount > 0 and autogroup creates a group
@@ -1161,9 +1160,7 @@ static bool fwd_next_prio_supported(struct mlx5_flow_table *ft)
 
 struct mlx5_flow_rule *
 mlx5_add_flow_rule(struct mlx5_flow_table *ft,
-		   u8 match_criteria_enable,
-		   u32 *match_criteria,
-		   u32 *match_value,
+		   struct mlx5_flow_spec *spec,
 		   u32 action,
 		   u32 flow_tag,
 		   struct mlx5_flow_destination *dest)
@@ -1194,8 +1191,7 @@ mlx5_add_flow_rule(struct mlx5_flow_table *ft,
 		}
 	}
 
-	rule =	_mlx5_add_flow_rule(ft, match_criteria_enable, match_criteria,
-				    match_value, action, flow_tag, dest);
+	rule = _mlx5_add_flow_rule(ft, spec, action, flow_tag, dest);
 
 	if (sw_action == MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO) {
 		if (!IS_ERR_OR_NULL(rule) &&
diff --git a/include/linux/mlx5/fs.h b/include/linux/mlx5/fs.h
index 3f3444d24756..8a3834ea32f2 100644
--- a/include/linux/mlx5/fs.h
+++ b/include/linux/mlx5/fs.h
@@ -66,6 +66,12 @@ struct mlx5_flow_group;
 struct mlx5_flow_rule;
 struct mlx5_flow_namespace;
 
+struct mlx5_flow_spec {
+	u8   match_criteria_enable;
+	u32  match_criteria[MLX5_ST_SZ_DW(fte_match_param)];
+	u32  match_value[MLX5_ST_SZ_DW(fte_match_param)];
+};
+
 struct mlx5_flow_destination {
 	enum mlx5_flow_destination_type	type;
 	union {
@@ -106,9 +112,7 @@ void mlx5_destroy_flow_group(struct mlx5_flow_group *fg);
  */
 struct mlx5_flow_rule *
 mlx5_add_flow_rule(struct mlx5_flow_table *ft,
-		   u8 match_criteria_enable,
-		   u32 *match_criteria,
-		   u32 *match_value,
+		   struct mlx5_flow_spec *spec,
 		   u32 action,
 		   u32 flow_tag,
 		   struct mlx5_flow_destination *dest);
