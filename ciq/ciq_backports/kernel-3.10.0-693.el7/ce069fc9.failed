locking/rwsem: Reduce the size of struct rw_semaphore

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Jason Low <jason.low2@hp.com>
commit ce069fc920e5734558b3d9cbef1ab06cf01ee793
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/ce069fc9.failed

Recent optimistic spinning additions to rwsem provide significant performance
benefits on many workloads on large machines. The cost of it was increasing
the size of the rwsem structure by up to 128 bits.

However, now that the previous patches in this series bring the overhead of
struct optimistic_spin_queue to 32 bits, this patch reorders some fields in
struct rw_semaphore such that we can reduce the overhead of the rwsem structure
by 64 bits (on 64 bit systems).

The extra overhead required for rwsem optimistic spinning would now be up
to 8 additional bytes instead of up to 16 bytes. Additionally, the size of
rwsem would now be more in line with mutexes.

	Signed-off-by: Jason Low <jason.low2@hp.com>
	Signed-off-by: Peter Zijlstra <peterz@infradead.org>
	Cc: Scott Norton <scott.norton@hp.com>
	Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
	Cc: Dave Chinner <david@fromorbit.com>
	Cc: Waiman Long <waiman.long@hp.com>
	Cc: Davidlohr Bueso <davidlohr@hp.com>
	Cc: Rik van Riel <riel@redhat.com>
	Cc: Andrew Morton <akpm@linux-foundation.org>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Steven Rostedt <rostedt@goodmis.org>
	Cc: Tim Chen <tim.c.chen@linux.intel.com>
	Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
	Cc: Aswin Chandramouleeswaran <aswin@hp.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Chris Mason <clm@fb.com>
	Cc: Josef Bacik <jbacik@fusionio.com>
Link: http://lkml.kernel.org/r/1405358872-3732-6-git-send-email-jason.low2@hp.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit ce069fc920e5734558b3d9cbef1ab06cf01ee793)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/rwsem.h
diff --cc include/linux/rwsem.h
index 8d79708146aa,716807f0eb2d..000000000000
--- a/include/linux/rwsem.h
+++ b/include/linux/rwsem.h
@@@ -33,7 -33,6 +34,10 @@@ struct rw_semaphore 
  	 * if the owner is running on the cpu.
  	 */
  	struct task_struct *owner;
++<<<<<<< HEAD
 +	struct optimistic_spin_queue *osq; /* spinner MCS lock */
++=======
++>>>>>>> ce069fc920e5 (locking/rwsem: Reduce the size of struct rw_semaphore)
  #endif
  #ifdef CONFIG_DEBUG_LOCK_ALLOC
  	struct lockdep_map	dep_map;
@@@ -65,21 -64,18 +69,28 @@@ static inline int rwsem_is_locked(struc
  #endif
  
  #if defined(CONFIG_SMP) && !defined(CONFIG_RWSEM_GENERIC_SPINLOCK)
++<<<<<<< HEAD
 +#define __RWSEM_INITIALIZER(name)			\
 +	{ RWSEM_UNLOCKED_VALUE,				\
 +	  __RAW_SPIN_LOCK_UNLOCKED(name.wait_lock),	\
 +	  LIST_HEAD_INIT((name).wait_list),		\
 +	  NULL, /* owner */				\
 +	  NULL /* mcs lock */                           \
 +	  __RWSEM_DEP_MAP_INIT(name) }
++=======
+ #define __RWSEM_OPT_INIT(lockname) , .osq = OSQ_LOCK_UNLOCKED, .owner = NULL
++>>>>>>> ce069fc920e5 (locking/rwsem: Reduce the size of struct rw_semaphore)
  #else
- #define __RWSEM_INITIALIZER(name)			\
- 	{ RWSEM_UNLOCKED_VALUE,				\
- 	  __RAW_SPIN_LOCK_UNLOCKED(name.wait_lock),	\
- 	  LIST_HEAD_INIT((name).wait_list)		\
- 	  __RWSEM_DEP_MAP_INIT(name) }
+ #define __RWSEM_OPT_INIT(lockname)
  #endif
  
+ #define __RWSEM_INITIALIZER(name)				\
+ 	{ .count = RWSEM_UNLOCKED_VALUE,			\
+ 	  .wait_list = LIST_HEAD_INIT((name).wait_list),	\
+ 	  .wait_lock = __RAW_SPIN_LOCK_UNLOCKED(name.wait_lock)	\
+ 	  __RWSEM_OPT_INIT(name)				\
+ 	  __RWSEM_DEP_MAP_INIT(name) }
+ 
  #define DECLARE_RWSEM(name) \
  	struct rw_semaphore name = __RWSEM_INITIALIZER(name)
  
* Unmerged path include/linux/rwsem.h
