md/raid5-cache: do not need to set STRIPE_PREREAD_ACTIVE repeatedly

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [md] raid5-cache: do not need to set STRIPE_PREREAD_ACTIVE repeatedly (Jes Sorensen) [1380016]
Rebuild_FUZZ: 97.71%
commit-author JackieLiu <liuyun01@kylinos.cn>
commit 1a0ec5c30c37d29e4435a45e75c896f91af970bd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/1a0ec5c3.failed

R5c_make_stripe_write_out has set this flag, do not need to set again.

	Signed-off-by: JackieLiu <liuyun01@kylinos.cn>
	Signed-off-by: Shaohua Li <shli@fb.com>
(cherry picked from commit 1a0ec5c30c37d29e4435a45e75c896f91af970bd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/raid5-cache.c
diff --cc drivers/md/raid5-cache.c
index c6ed6dc6889f,e786d4e555cc..000000000000
--- a/drivers/md/raid5-cache.c
+++ b/drivers/md/raid5-cache.c
@@@ -744,6 -1221,132 +744,135 @@@ static void r5l_write_super_and_discard
  	}
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * r5c_flush_stripe moves stripe from cached list to handle_list. When called,
+  * the stripe must be on r5c_cached_full_stripes or r5c_cached_partial_stripes.
+  *
+  * must hold conf->device_lock
+  */
+ static void r5c_flush_stripe(struct r5conf *conf, struct stripe_head *sh)
+ {
+ 	BUG_ON(list_empty(&sh->lru));
+ 	BUG_ON(!test_bit(STRIPE_R5C_CACHING, &sh->state));
+ 	BUG_ON(test_bit(STRIPE_HANDLE, &sh->state));
+ 
+ 	/*
+ 	 * The stripe is not ON_RELEASE_LIST, so it is safe to call
+ 	 * raid5_release_stripe() while holding conf->device_lock
+ 	 */
+ 	BUG_ON(test_bit(STRIPE_ON_RELEASE_LIST, &sh->state));
+ 	assert_spin_locked(&conf->device_lock);
+ 
+ 	list_del_init(&sh->lru);
+ 	atomic_inc(&sh->count);
+ 
+ 	set_bit(STRIPE_HANDLE, &sh->state);
+ 	atomic_inc(&conf->active_stripes);
+ 	r5c_make_stripe_write_out(sh);
+ 
+ 	raid5_release_stripe(sh);
+ }
+ 
+ /*
+  * if num == 0, flush all full stripes
+  * if num > 0, flush all full stripes. If less than num full stripes are
+  *             flushed, flush some partial stripes until totally num stripes are
+  *             flushed or there is no more cached stripes.
+  */
+ void r5c_flush_cache(struct r5conf *conf, int num)
+ {
+ 	int count;
+ 	struct stripe_head *sh, *next;
+ 
+ 	assert_spin_locked(&conf->device_lock);
+ 	if (!conf->log)
+ 		return;
+ 
+ 	count = 0;
+ 	list_for_each_entry_safe(sh, next, &conf->r5c_full_stripe_list, lru) {
+ 		r5c_flush_stripe(conf, sh);
+ 		count++;
+ 	}
+ 
+ 	if (count >= num)
+ 		return;
+ 	list_for_each_entry_safe(sh, next,
+ 				 &conf->r5c_partial_stripe_list, lru) {
+ 		r5c_flush_stripe(conf, sh);
+ 		if (++count >= num)
+ 			break;
+ 	}
+ }
+ 
+ static void r5c_do_reclaim(struct r5conf *conf)
+ {
+ 	struct r5l_log *log = conf->log;
+ 	struct stripe_head *sh;
+ 	int count = 0;
+ 	unsigned long flags;
+ 	int total_cached;
+ 	int stripes_to_flush;
+ 
+ 	if (!r5c_is_writeback(log))
+ 		return;
+ 
+ 	total_cached = atomic_read(&conf->r5c_cached_partial_stripes) +
+ 		atomic_read(&conf->r5c_cached_full_stripes);
+ 
+ 	if (total_cached > conf->min_nr_stripes * 3 / 4 ||
+ 	    atomic_read(&conf->empty_inactive_list_nr) > 0)
+ 		/*
+ 		 * if stripe cache pressure high, flush all full stripes and
+ 		 * some partial stripes
+ 		 */
+ 		stripes_to_flush = R5C_RECLAIM_STRIPE_GROUP;
+ 	else if (total_cached > conf->min_nr_stripes * 1 / 2 ||
+ 		 atomic_read(&conf->r5c_cached_full_stripes) >
+ 		 R5C_FULL_STRIPE_FLUSH_BATCH)
+ 		/*
+ 		 * if stripe cache pressure moderate, or if there is many full
+ 		 * stripes,flush all full stripes
+ 		 */
+ 		stripes_to_flush = 0;
+ 	else
+ 		/* no need to flush */
+ 		stripes_to_flush = -1;
+ 
+ 	if (stripes_to_flush >= 0) {
+ 		spin_lock_irqsave(&conf->device_lock, flags);
+ 		r5c_flush_cache(conf, stripes_to_flush);
+ 		spin_unlock_irqrestore(&conf->device_lock, flags);
+ 	}
+ 
+ 	/* if log space is tight, flush stripes on stripe_in_journal_list */
+ 	if (test_bit(R5C_LOG_TIGHT, &conf->cache_state)) {
+ 		spin_lock_irqsave(&log->stripe_in_journal_lock, flags);
+ 		spin_lock(&conf->device_lock);
+ 		list_for_each_entry(sh, &log->stripe_in_journal_list, r5c) {
+ 			/*
+ 			 * stripes on stripe_in_journal_list could be in any
+ 			 * state of the stripe_cache state machine. In this
+ 			 * case, we only want to flush stripe on
+ 			 * r5c_cached_full/partial_stripes. The following
+ 			 * condition makes sure the stripe is on one of the
+ 			 * two lists.
+ 			 */
+ 			if (!list_empty(&sh->lru) &&
+ 			    !test_bit(STRIPE_HANDLE, &sh->state) &&
+ 			    atomic_read(&sh->count) == 0) {
+ 				r5c_flush_stripe(conf, sh);
+ 			}
+ 			if (count++ >= R5C_RECLAIM_STRIPE_GROUP)
+ 				break;
+ 		}
+ 		spin_unlock(&conf->device_lock);
+ 		spin_unlock_irqrestore(&log->stripe_in_journal_lock, flags);
+ 	}
+ 	md_wakeup_thread(conf->mddev->thread);
+ }
++>>>>>>> 1a0ec5c30c37 (md/raid5-cache: do not need to set STRIPE_PREREAD_ACTIVE repeatedly)
  
  static void r5l_do_reclaim(struct r5l_log *log)
  {
* Unmerged path drivers/md/raid5-cache.c
