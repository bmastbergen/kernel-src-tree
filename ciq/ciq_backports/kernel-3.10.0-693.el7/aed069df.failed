ip_tunnel_core: iptunnel_handle_offloads returns int and doesn't free skb

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Alexander Duyck <aduyck@mirantis.com>
commit aed069df099cd1a27900acb56bb892ec24c66ac4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/aed069df.failed

This patch updates the IP tunnel core function iptunnel_handle_offloads so
that we return an int and do not free the skb inside the function.  This
actually allows us to clean up several paths in several tunnels so that we
can free the skb at one point in the path without having to have a
secondary path if we are supporting tunnel offloads.

In addition it should resolve some double-free issues I have found in the
tunnels paths as I believe it is possible for us to end up triggering such
an event in the case of fou or gue.

	Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit aed069df099cd1a27900acb56bb892ec24c66ac4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/vxlan.c
#	include/net/ip_tunnels.h
#	net/ipv4/fou.c
#	net/ipv4/ip_tunnel_core.c
#	net/ipv4/ipip.c
#	net/ipv6/sit.c
#	net/netfilter/ipvs/ip_vs_xmit.c
diff --cc drivers/net/vxlan.c
index 8f88cba29f1a,c2e22c2532a1..000000000000
--- a/drivers/net/vxlan.c
+++ b/drivers/net/vxlan.c
@@@ -1800,9 -1797,9 +1800,15 @@@ static int vxlan_build_skb(struct sk_bu
  	if (WARN_ON(!skb))
  		return -ENOMEM;
  
++<<<<<<< HEAD
 +	skb = iptunnel_handle_offloads(skb, false, type);
 +	if (IS_ERR(skb))
 +		return PTR_ERR(skb);
++=======
+ 	err = iptunnel_handle_offloads(skb, type);
+ 	if (err)
+ 		goto out_free;
++>>>>>>> aed069df099c (ip_tunnel_core: iptunnel_handle_offloads returns int and doesn't free skb)
  
  	vxh = (struct vxlanhdr *) __skb_push(skb, sizeof(*vxh));
  	vxh->vx_flags = VXLAN_HF_VNI;
diff --cc include/net/ip_tunnels.h
index c62b45515469,6d790910ebdf..000000000000
--- a/include/net/ip_tunnels.h
+++ b/include/net/ip_tunnels.h
@@@ -314,8 -309,7 +314,12 @@@ void iptunnel_xmit(struct sock *sk, str
  struct metadata_dst *iptunnel_metadata_reply(struct metadata_dst *md,
  					     gfp_t flags);
  
++<<<<<<< HEAD
 +struct sk_buff *iptunnel_handle_offloads(struct sk_buff *skb, bool gre_csum,
 +					 int gso_type_mask);
++=======
+ int iptunnel_handle_offloads(struct sk_buff *skb, int gso_type_mask);
++>>>>>>> aed069df099c (ip_tunnel_core: iptunnel_handle_offloads returns int and doesn't free skb)
  
  static inline int iptunnel_pull_offloads(struct sk_buff *skb)
  {
diff --cc net/ipv4/fou.c
index f471d6929968,7ac5ec87b004..000000000000
--- a/net/ipv4/fou.c
+++ b/net/ipv4/fou.c
@@@ -679,14 -799,14 +679,21 @@@ static void fou_build_udp(struct sk_buf
  int fou_build_header(struct sk_buff *skb, struct ip_tunnel_encap *e,
  		     u8 *protocol, struct flowi4 *fl4)
  {
 -	int type = e->flags & TUNNEL_ENCAP_FLAG_CSUM ? SKB_GSO_UDP_TUNNEL_CSUM :
 -						       SKB_GSO_UDP_TUNNEL;
 +	bool csum = !!(e->flags & TUNNEL_ENCAP_FLAG_CSUM);
 +	int type = csum ? SKB_GSO_UDP_TUNNEL_CSUM : SKB_GSO_UDP_TUNNEL;
  	__be16 sport;
+ 	int err;
  
++<<<<<<< HEAD
 +	skb = iptunnel_handle_offloads(skb, csum, type);
 +
 +	if (IS_ERR(skb))
 +		return PTR_ERR(skb);
++=======
+ 	err = iptunnel_handle_offloads(skb, type);
+ 	if (err)
+ 		return err;
++>>>>>>> aed069df099c (ip_tunnel_core: iptunnel_handle_offloads returns int and doesn't free skb)
  
  	sport = e->sport ? : udp_flow_src_port(dev_net(skb->dev),
  					       skb, 0, 0, false);
@@@ -717,10 -837,9 +725,16 @@@ int gue_build_header(struct sk_buff *sk
  
  	optlen += need_priv ? GUE_LEN_PRIV : 0;
  
++<<<<<<< HEAD
 +	skb = iptunnel_handle_offloads(skb, csum, type);
 +
 +	if (IS_ERR(skb))
 +		return PTR_ERR(skb);
++=======
+ 	err = iptunnel_handle_offloads(skb, type);
+ 	if (err)
+ 		return err;
++>>>>>>> aed069df099c (ip_tunnel_core: iptunnel_handle_offloads returns int and doesn't free skb)
  
  	/* Get source port (based on flow hash) before skb_push */
  	sport = e->sport ? : udp_flow_src_port(dev_net(skb->dev),
diff --cc net/ipv4/ip_tunnel_core.c
index 709e729b47bf,f46c5c873831..000000000000
--- a/net/ipv4/ip_tunnel_core.c
+++ b/net/ipv4/ip_tunnel_core.c
@@@ -147,9 -146,8 +147,14 @@@ struct metadata_dst *iptunnel_metadata_
  }
  EXPORT_SYMBOL_GPL(iptunnel_metadata_reply);
  
++<<<<<<< HEAD
 +struct sk_buff *iptunnel_handle_offloads(struct sk_buff *skb,
 +					 bool csum_help,
 +					 int gso_type_mask)
++=======
+ int iptunnel_handle_offloads(struct sk_buff *skb,
+ 			     int gso_type_mask)
++>>>>>>> aed069df099c (ip_tunnel_core: iptunnel_handle_offloads returns int and doesn't free skb)
  {
  	int err;
  
@@@ -159,25 -157,20 +164,25 @@@
  	}
  
  	if (skb_is_gso(skb)) {
 -		err = skb_unclone(skb, GFP_ATOMIC);
 +		err = skb_header_unclone(skb, GFP_ATOMIC);
  		if (unlikely(err))
- 			goto error;
+ 			return err;
  		skb_shinfo(skb)->gso_type |= gso_type_mask;
- 		return skb;
+ 		return 0;
  	}
  
 -	if (skb->ip_summed != CHECKSUM_PARTIAL) {
 +	/* If packet is not gso and we are not offloading inner checksum,
 +	 * clear encapsulation flag. This allows setting CHECKSUM_PARTIAL
 +	 * on the outer header without confusing devices that implement
 +	 * NETIF_F_IP_CSUM with encapsulation.
 +	 */
 +	if (skb->ip_summed == CHECKSUM_PARTIAL && csum_help) {
 +		skb->encapsulation = 0;
 +		err = skb_checksum_help(skb);
 +		if (unlikely(err))
 +			goto error;
 +	} else if (skb->ip_summed != CHECKSUM_PARTIAL) {
  		skb->ip_summed = CHECKSUM_NONE;
 -		/* We clear encapsulation here to prevent badly-written
 -		 * drivers potentially deciding to offload an inner checksum
 -		 * if we set CHECKSUM_PARTIAL on the outer header.
 -		 * This should go away when the drivers are all fixed.
 -		 */
  		skb->encapsulation = 0;
  	}
  
diff --cc net/ipv4/ipip.c
index 8a09cef5a5aa,92827483ee3d..000000000000
--- a/net/ipv4/ipip.c
+++ b/net/ipv4/ipip.c
@@@ -220,9 -219,8 +220,14 @@@ static netdev_tx_t ipip_tunnel_xmit(str
  	if (unlikely(skb->protocol != htons(ETH_P_IP)))
  		goto tx_error;
  
++<<<<<<< HEAD
 +	skb = iptunnel_handle_offloads(skb, false, SKB_GSO_IPIP);
 +	if (IS_ERR(skb))
 +		goto out;
++=======
+ 	if (iptunnel_handle_offloads(skb, SKB_GSO_IPIP))
+ 		goto tx_error;
++>>>>>>> aed069df099c (ip_tunnel_core: iptunnel_handle_offloads returns int and doesn't free skb)
  
  	skb_set_inner_ipproto(skb, IPPROTO_IPIP);
  
diff --cc net/ipv6/sit.c
index 06e147737499,a13d8c114ccb..000000000000
--- a/net/ipv6/sit.c
+++ b/net/ipv6/sit.c
@@@ -824,10 -913,9 +824,14 @@@ static netdev_tx_t ipip6_tunnel_xmit(st
  		goto tx_error;
  	}
  
++<<<<<<< HEAD
 +	skb = iptunnel_handle_offloads(skb, false, SKB_GSO_SIT);
 +	if (IS_ERR(skb)) {
++=======
+ 	if (iptunnel_handle_offloads(skb, SKB_GSO_SIT)) {
++>>>>>>> aed069df099c (ip_tunnel_core: iptunnel_handle_offloads returns int and doesn't free skb)
  		ip_rt_put(rt);
- 		goto out;
+ 		goto tx_error;
  	}
  
  	if (df) {
@@@ -902,8 -990,7 +906,12 @@@
  tx_error_icmp:
  	dst_link_failure(skb);
  tx_error:
++<<<<<<< HEAD
 +	dev_kfree_skb(skb);
 +out:
++=======
+ 	kfree_skb(skb);
++>>>>>>> aed069df099c (ip_tunnel_core: iptunnel_handle_offloads returns int and doesn't free skb)
  	dev->stats.tx_errors++;
  	return NETDEV_TX_OK;
  }
@@@ -913,9 -1000,8 +921,14 @@@ static netdev_tx_t ipip_tunnel_xmit(str
  	struct ip_tunnel *tunnel = netdev_priv(dev);
  	const struct iphdr  *tiph = &tunnel->parms.iph;
  
++<<<<<<< HEAD
 +	skb = iptunnel_handle_offloads(skb, false, SKB_GSO_IPIP);
 +	if (IS_ERR(skb))
 +		goto out;
++=======
+ 	if (iptunnel_handle_offloads(skb, SKB_GSO_IPIP))
+ 		goto tx_error;
++>>>>>>> aed069df099c (ip_tunnel_core: iptunnel_handle_offloads returns int and doesn't free skb)
  
  	skb_set_inner_ipproto(skb, IPPROTO_IPIP);
  
diff --cc net/netfilter/ipvs/ip_vs_xmit.c
index 4fbf1730c473,6d19d2eeaa60..000000000000
--- a/net/netfilter/ipvs/ip_vs_xmit.c
+++ b/net/netfilter/ipvs/ip_vs_xmit.c
@@@ -857,16 -1005,16 +857,21 @@@ ip_vs_tunnel_xmit(struct sk_buff *skb, 
  	 */
  	max_headroom = LL_RESERVED_SPACE(tdev) + sizeof(struct iphdr);
  
 -	/* We only care about the df field if sysctl_pmtu_disc(ipvs) is set */
 -	dfp = sysctl_pmtu_disc(ipvs) ? &df : NULL;
 -	skb = ip_vs_prepare_tunneled_skb(skb, cp->af, max_headroom,
 -					 &next_protocol, NULL, &dsfield,
 -					 &ttl, dfp);
 -	if (IS_ERR(skb))
 -		goto tx_error;
 +	if (skb_headroom(skb) < max_headroom || skb_cloned(skb)) {
 +		struct sk_buff *new_skb =
 +			skb_realloc_headroom(skb, max_headroom);
  
++<<<<<<< HEAD
 +		if (!new_skb)
 +			goto tx_error;
 +		consume_skb(skb);
 +		skb = new_skb;
 +		old_iph = ip_hdr(skb);
 +	}
++=======
+ 	if (iptunnel_handle_offloads(skb, __tun_gso_type_mask(AF_INET, cp->af)))
+ 		goto tx_error;
++>>>>>>> aed069df099c (ip_tunnel_core: iptunnel_handle_offloads returns int and doesn't free skb)
  
  	skb->transport_header = skb->network_header;
  
@@@ -948,16 -1098,14 +953,21 @@@ ip_vs_tunnel_xmit_v6(struct sk_buff *sk
  	 */
  	max_headroom = LL_RESERVED_SPACE(tdev) + sizeof(struct ipv6hdr);
  
 -	skb = ip_vs_prepare_tunneled_skb(skb, cp->af, max_headroom,
 -					 &next_protocol, &payload_len,
 -					 &dsfield, &ttl, NULL);
 -	if (IS_ERR(skb))
 -		goto tx_error;
 +	if (skb_headroom(skb) < max_headroom || skb_cloned(skb)) {
 +		struct sk_buff *new_skb =
 +			skb_realloc_headroom(skb, max_headroom);
  
++<<<<<<< HEAD
 +		if (!new_skb)
 +			goto tx_error;
 +		consume_skb(skb);
 +		skb = new_skb;
 +		old_iph = ipv6_hdr(skb);
 +	}
++=======
+ 	if (iptunnel_handle_offloads(skb, __tun_gso_type_mask(AF_INET6, cp->af)))
+ 		goto tx_error;
++>>>>>>> aed069df099c (ip_tunnel_core: iptunnel_handle_offloads returns int and doesn't free skb)
  
  	skb->transport_header = skb->network_header;
  
diff --git a/drivers/net/geneve.c b/drivers/net/geneve.c
index cd018ae81338..ad9db9283fbb 100644
--- a/drivers/net/geneve.c
+++ b/drivers/net/geneve.c
@@ -693,16 +693,12 @@ static int geneve_build_skb(struct rtable *rt, struct sk_buff *skb,
 	min_headroom = LL_RESERVED_SPACE(rt->dst.dev) + rt->dst.header_len
 			+ GENEVE_BASE_HLEN + opt_len + sizeof(struct iphdr);
 	err = skb_cow_head(skb, min_headroom);
-	if (unlikely(err)) {
-		kfree_skb(skb);
+	if (unlikely(err))
 		goto free_rt;
-	}
 
-	skb = udp_tunnel_handle_offloads(skb, udp_sum);
-	if (IS_ERR(skb)) {
-		err = PTR_ERR(skb);
+	err = udp_tunnel_handle_offloads(skb, udp_sum);
+	if (err)
 		goto free_rt;
-	}
 
 	gnvh = (struct genevehdr *)__skb_push(skb, sizeof(*gnvh) + opt_len);
 	geneve_build_header(gnvh, tun_flags, vni, opt_len, opt);
@@ -730,16 +726,12 @@ static int geneve6_build_skb(struct dst_entry *dst, struct sk_buff *skb,
 	min_headroom = LL_RESERVED_SPACE(dst->dev) + dst->header_len
 			+ GENEVE_BASE_HLEN + opt_len + sizeof(struct ipv6hdr);
 	err = skb_cow_head(skb, min_headroom);
-	if (unlikely(err)) {
-		kfree_skb(skb);
+	if (unlikely(err))
 		goto free_dst;
-	}
 
-	skb = udp_tunnel_handle_offloads(skb, udp_sum);
-	if (IS_ERR(skb)) {
-		err = PTR_ERR(skb);
+	err = udp_tunnel_handle_offloads(skb, udp_sum);
+	if (IS_ERR(skb))
 		goto free_dst;
-	}
 
 	gnvh = (struct genevehdr *)__skb_push(skb, sizeof(*gnvh) + opt_len);
 	geneve_build_header(gnvh, tun_flags, vni, opt_len, opt);
@@ -934,7 +926,7 @@ static netdev_tx_t geneve_xmit_skb(struct sk_buff *skb, struct net_device *dev,
 		err = geneve_build_skb(rt, skb, key->tun_flags, vni,
 				       info->options_len, opts, flags, xnet);
 		if (unlikely(err))
-			goto err;
+			goto tx_error;
 
 		tos = ip_tunnel_ecn_encap(key->tos, iip, skb);
 		ttl = key->ttl;
@@ -943,7 +935,7 @@ static netdev_tx_t geneve_xmit_skb(struct sk_buff *skb, struct net_device *dev,
 		err = geneve_build_skb(rt, skb, 0, geneve->vni,
 				       0, NULL, flags, xnet);
 		if (unlikely(err))
-			goto err;
+			goto tx_error;
 
 		tos = ip_tunnel_ecn_encap(fl4.flowi4_tos, iip, skb);
 		ttl = geneve->ttl;
@@ -961,7 +953,7 @@ static netdev_tx_t geneve_xmit_skb(struct sk_buff *skb, struct net_device *dev,
 
 tx_error:
 	dev_kfree_skb(skb);
-err:
+
 	if (err == -ELOOP)
 		dev->stats.collisions++;
 	else if (err == -ENETUNREACH)
@@ -1023,7 +1015,7 @@ static netdev_tx_t geneve6_xmit_skb(struct sk_buff *skb, struct net_device *dev,
 					info->options_len, opts,
 					flags, xnet);
 		if (unlikely(err))
-			goto err;
+			goto tx_error;
 
 		prio = ip_tunnel_ecn_encap(key->tos, iip, skb);
 		ttl = key->ttl;
@@ -1032,7 +1024,7 @@ static netdev_tx_t geneve6_xmit_skb(struct sk_buff *skb, struct net_device *dev,
 		err = geneve6_build_skb(dst, skb, 0, geneve->vni,
 					0, NULL, flags, xnet);
 		if (unlikely(err))
-			goto err;
+			goto tx_error;
 
 		prio = ip_tunnel_ecn_encap(ip6_tclass(fl6.flowlabel),
 					   iip, skb);
@@ -1051,7 +1043,7 @@ static netdev_tx_t geneve6_xmit_skb(struct sk_buff *skb, struct net_device *dev,
 
 tx_error:
 	dev_kfree_skb(skb);
-err:
+
 	if (err == -ELOOP)
 		dev->stats.collisions++;
 	else if (err == -ENETUNREACH)
* Unmerged path drivers/net/vxlan.c
* Unmerged path include/net/ip_tunnels.h
diff --git a/include/net/udp_tunnel.h b/include/net/udp_tunnel.h
index fdc50733c4fe..6e82b13a7f7d 100644
--- a/include/net/udp_tunnel.h
+++ b/include/net/udp_tunnel.h
@@ -105,8 +105,7 @@ struct metadata_dst *udp_tun_rx_dst(struct sk_buff *skb, unsigned short family,
 				    __be16 flags, __be64 tunnel_id,
 				    int md_size);
 
-static inline struct sk_buff *udp_tunnel_handle_offloads(struct sk_buff *skb,
-							 bool udp_csum)
+static inline int udp_tunnel_handle_offloads(struct sk_buff *skb, bool udp_csum)
 {
 	int type = udp_csum ? SKB_GSO_UDP_TUNNEL_CSUM : SKB_GSO_UDP_TUNNEL;
 
* Unmerged path net/ipv4/fou.c
diff --git a/net/ipv4/ip_gre.c b/net/ipv4/ip_gre.c
index 685bbcd70289..f988fb3ed45a 100644
--- a/net/ipv4/ip_gre.c
+++ b/net/ipv4/ip_gre.c
@@ -501,8 +501,7 @@ static void __gre_xmit(struct sk_buff *skb, struct net_device *dev,
 	ip_tunnel_xmit(skb, dev, tnl_params, tnl_params->protocol);
 }
 
-static struct sk_buff *gre_handle_offloads(struct sk_buff *skb,
-					   bool csum)
+static int gre_handle_offloads(struct sk_buff *skb, bool csum)
 {
 	return iptunnel_handle_offloads(skb, false,
 					csum ? SKB_GSO_GRE_CSUM : SKB_GSO_GRE);
@@ -571,11 +570,8 @@ static void gre_fb_xmit(struct sk_buff *skb, struct net_device *dev,
 	}
 
 	/* Push Tunnel header. */
-	skb = gre_handle_offloads(skb, !!(tun_info->key.tun_flags & TUNNEL_CSUM));
-	if (IS_ERR(skb)) {
-		skb = NULL;
+	if (gre_handle_offloads(skb, !!(tun_info->key.tun_flags & TUNNEL_CSUM)))
 		goto err_free_rt;
-	}
 
 	flags = tun_info->key.tun_flags & (TUNNEL_CSUM | TUNNEL_KEY);
 	build_header(skb, tunnel_hlen, flags, proto,
@@ -643,16 +639,14 @@ static netdev_tx_t ipgre_xmit(struct sk_buff *skb,
 		tnl_params = &tunnel->parms.iph;
 	}
 
-	skb = gre_handle_offloads(skb, !!(tunnel->parms.o_flags&TUNNEL_CSUM));
-	if (IS_ERR(skb))
-		goto out;
+	if (gre_handle_offloads(skb, !!(tunnel->parms.o_flags & TUNNEL_CSUM)))
+		goto free_skb;
 
 	__gre_xmit(skb, dev, tnl_params, skb->protocol);
 	return NETDEV_TX_OK;
 
 free_skb:
 	kfree_skb(skb);
-out:
 	dev->stats.tx_dropped++;
 	return NETDEV_TX_OK;
 }
@@ -667,9 +661,8 @@ static netdev_tx_t gre_tap_xmit(struct sk_buff *skb,
 		return NETDEV_TX_OK;
 	}
 
-	skb = gre_handle_offloads(skb, !!(tunnel->parms.o_flags&TUNNEL_CSUM));
-	if (IS_ERR(skb))
-		goto out;
+	if (gre_handle_offloads(skb, !!(tunnel->parms.o_flags & TUNNEL_CSUM)))
+		goto free_skb;
 
 	if (skb_cow_head(skb, dev->needed_headroom))
 		goto free_skb;
@@ -679,7 +672,6 @@ static netdev_tx_t gre_tap_xmit(struct sk_buff *skb,
 
 free_skb:
 	kfree_skb(skb);
-out:
 	dev->stats.tx_dropped++;
 	return NETDEV_TX_OK;
 }
* Unmerged path net/ipv4/ip_tunnel_core.c
* Unmerged path net/ipv4/ipip.c
* Unmerged path net/ipv6/sit.c
* Unmerged path net/netfilter/ipvs/ip_vs_xmit.c
