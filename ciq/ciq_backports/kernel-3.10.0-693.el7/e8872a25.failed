net: rtnetlink: allow rtnl_fill_statsinfo to save private state counter

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [net] rtnetlink: allow rtnl_fill_statsinfo to save private state counter (Ivan Vecera) [1352289]
Rebuild_FUZZ: 96.35%
commit-author Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
commit e8872a25a05efcf0a133ca7ed6511fe9f908dc41
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/e8872a25.failed

The new prividx argument allows the current dumping device to save a
private state counter which would enable it to continue dumping from
where it left off. And the idxattr is used to save the current idx user
so multiple prividx using attributes can be requested at the same time
as suggested by Roopa Prabhu.

	Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit e8872a25a05efcf0a133ca7ed6511fe9f908dc41)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/core/rtnetlink.c
diff --cc net/core/rtnetlink.c
index 8209decfe5a9,de529a20cd18..000000000000
--- a/net/core/rtnetlink.c
+++ b/net/core/rtnetlink.c
@@@ -3213,6 -3444,172 +3213,175 @@@ out
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ static bool stats_attr_valid(unsigned int mask, int attrid, int idxattr)
+ {
+ 	return (mask & IFLA_STATS_FILTER_BIT(attrid)) &&
+ 	       (!idxattr || idxattr == attrid);
+ }
+ 
+ static int rtnl_fill_statsinfo(struct sk_buff *skb, struct net_device *dev,
+ 			       int type, u32 pid, u32 seq, u32 change,
+ 			       unsigned int flags, unsigned int filter_mask,
+ 			       int *idxattr, int *prividx)
+ {
+ 	struct if_stats_msg *ifsm;
+ 	struct nlmsghdr *nlh;
+ 	struct nlattr *attr;
+ 	int s_prividx = *prividx;
+ 
+ 	ASSERT_RTNL();
+ 
+ 	nlh = nlmsg_put(skb, pid, seq, type, sizeof(*ifsm), flags);
+ 	if (!nlh)
+ 		return -EMSGSIZE;
+ 
+ 	ifsm = nlmsg_data(nlh);
+ 	ifsm->ifindex = dev->ifindex;
+ 	ifsm->filter_mask = filter_mask;
+ 
+ 	if (stats_attr_valid(filter_mask, IFLA_STATS_LINK_64, *idxattr)) {
+ 		struct rtnl_link_stats64 *sp;
+ 
+ 		attr = nla_reserve_64bit(skb, IFLA_STATS_LINK_64,
+ 					 sizeof(struct rtnl_link_stats64),
+ 					 IFLA_STATS_UNSPEC);
+ 		if (!attr)
+ 			goto nla_put_failure;
+ 
+ 		sp = nla_data(attr);
+ 		dev_get_stats(dev, sp);
+ 	}
+ 
+ 	nlmsg_end(skb, nlh);
+ 
+ 	return 0;
+ 
+ nla_put_failure:
+ 	/* not a multi message or no progress mean a real error */
+ 	if (!(flags & NLM_F_MULTI) || s_prividx == *prividx)
+ 		nlmsg_cancel(skb, nlh);
+ 	else
+ 		nlmsg_end(skb, nlh);
+ 
+ 	return -EMSGSIZE;
+ }
+ 
+ static const struct nla_policy ifla_stats_policy[IFLA_STATS_MAX + 1] = {
+ 	[IFLA_STATS_LINK_64]	= { .len = sizeof(struct rtnl_link_stats64) },
+ };
+ 
+ static size_t if_nlmsg_stats_size(const struct net_device *dev,
+ 				  u32 filter_mask)
+ {
+ 	size_t size = 0;
+ 
+ 	if (stats_attr_valid(filter_mask, IFLA_STATS_LINK_64, 0))
+ 		size += nla_total_size_64bit(sizeof(struct rtnl_link_stats64));
+ 
+ 	return size;
+ }
+ 
+ static int rtnl_stats_get(struct sk_buff *skb, struct nlmsghdr *nlh)
+ {
+ 	struct net *net = sock_net(skb->sk);
+ 	struct net_device *dev = NULL;
+ 	int idxattr = 0, prividx = 0;
+ 	struct if_stats_msg *ifsm;
+ 	struct sk_buff *nskb;
+ 	u32 filter_mask;
+ 	int err;
+ 
+ 	ifsm = nlmsg_data(nlh);
+ 	if (ifsm->ifindex > 0)
+ 		dev = __dev_get_by_index(net, ifsm->ifindex);
+ 	else
+ 		return -EINVAL;
+ 
+ 	if (!dev)
+ 		return -ENODEV;
+ 
+ 	filter_mask = ifsm->filter_mask;
+ 	if (!filter_mask)
+ 		return -EINVAL;
+ 
+ 	nskb = nlmsg_new(if_nlmsg_stats_size(dev, filter_mask), GFP_KERNEL);
+ 	if (!nskb)
+ 		return -ENOBUFS;
+ 
+ 	err = rtnl_fill_statsinfo(nskb, dev, RTM_NEWSTATS,
+ 				  NETLINK_CB(skb).portid, nlh->nlmsg_seq, 0,
+ 				  0, filter_mask, &idxattr, &prividx);
+ 	if (err < 0) {
+ 		/* -EMSGSIZE implies BUG in if_nlmsg_stats_size */
+ 		WARN_ON(err == -EMSGSIZE);
+ 		kfree_skb(nskb);
+ 	} else {
+ 		err = rtnl_unicast(nskb, net, NETLINK_CB(skb).portid);
+ 	}
+ 
+ 	return err;
+ }
+ 
+ static int rtnl_stats_dump(struct sk_buff *skb, struct netlink_callback *cb)
+ {
+ 	int h, s_h, err, s_idx, s_idxattr, s_prividx;
+ 	struct net *net = sock_net(skb->sk);
+ 	unsigned int flags = NLM_F_MULTI;
+ 	struct if_stats_msg *ifsm;
+ 	struct hlist_head *head;
+ 	struct net_device *dev;
+ 	u32 filter_mask = 0;
+ 	int idx = 0;
+ 
+ 	s_h = cb->args[0];
+ 	s_idx = cb->args[1];
+ 	s_idxattr = cb->args[2];
+ 	s_prividx = cb->args[3];
+ 
+ 	cb->seq = net->dev_base_seq;
+ 
+ 	ifsm = nlmsg_data(cb->nlh);
+ 	filter_mask = ifsm->filter_mask;
+ 	if (!filter_mask)
+ 		return -EINVAL;
+ 
+ 	for (h = s_h; h < NETDEV_HASHENTRIES; h++, s_idx = 0) {
+ 		idx = 0;
+ 		head = &net->dev_index_head[h];
+ 		hlist_for_each_entry(dev, head, index_hlist) {
+ 			if (idx < s_idx)
+ 				goto cont;
+ 			err = rtnl_fill_statsinfo(skb, dev, RTM_NEWSTATS,
+ 						  NETLINK_CB(cb->skb).portid,
+ 						  cb->nlh->nlmsg_seq, 0,
+ 						  flags, filter_mask,
+ 						  &s_idxattr, &s_prividx);
+ 			/* If we ran out of room on the first message,
+ 			 * we're in trouble
+ 			 */
+ 			WARN_ON((err == -EMSGSIZE) && (skb->len == 0));
+ 
+ 			if (err < 0)
+ 				goto out;
+ 			s_prividx = 0;
+ 			s_idxattr = 0;
+ 			nl_dump_check_consistent(cb, nlmsg_hdr(skb));
+ cont:
+ 			idx++;
+ 		}
+ 	}
+ out:
+ 	cb->args[3] = s_prividx;
+ 	cb->args[2] = s_idxattr;
+ 	cb->args[1] = idx;
+ 	cb->args[0] = h;
+ 
+ 	return skb->len;
+ }
+ 
++>>>>>>> e8872a25a05e (net: rtnetlink: allow rtnl_fill_statsinfo to save private state counter)
  /* Process one rtnetlink message. */
  
  static int rtnetlink_rcv_msg(struct sk_buff *skb, struct nlmsghdr *nlh)
* Unmerged path net/core/rtnetlink.c
