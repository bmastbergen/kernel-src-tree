net/mlx5e: Choose best nearest LRO timeout

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [netdrv] mlx5e: Choose best nearest LRO timeout (Don Dutile) [1385330 1417285]
Rebuild_FUZZ: 95.00%
commit-author Saeed Mahameed <saeedm@mellanox.com>
commit 2b029556667a7fc1aea731c5828e501656f87653
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/2b029556.failed

Instead of predicting the index of the wanted LRO timeout value from
hardware capabilities, look for the nearest LRO timeout value.

Fixes: 5c50368f3831 ('net/mlx5e: Light-weight netdev open/stop')
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
	Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 2b029556667a7fc1aea731c5828e501656f87653)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en.h
#	drivers/net/ethernet/mellanox/mlx5/core/en_main.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en.h
index b01f5bb32ed7,7a43502a89cc..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en.h
@@@ -190,6 -223,8 +193,11 @@@ struct mlx5e_params 
  #ifdef CONFIG_MLX5_CORE_EN_DCB
  	struct ieee_ets ets;
  #endif
++<<<<<<< HEAD
++=======
+ 	bool rx_am_enabled;
+ 	u32 lro_timeout;
++>>>>>>> 2b029556667a (net/mlx5e: Choose best nearest LRO timeout)
  };
  
  struct mlx5e_tstamp {
@@@ -645,6 -827,71 +653,48 @@@ extern const struct dcbnl_rtnl_ops mlx5
  int mlx5e_dcbnl_ieee_setets_core(struct mlx5e_priv *priv, struct ieee_ets *ets);
  #endif
  
 -#ifndef CONFIG_RFS_ACCEL
 -static inline int mlx5e_arfs_create_tables(struct mlx5e_priv *priv)
 -{
 -	return 0;
 -}
 -
 -static inline void mlx5e_arfs_destroy_tables(struct mlx5e_priv *priv) {}
 -
 -static inline int mlx5e_arfs_enable(struct mlx5e_priv *priv)
 -{
 -	return -ENOTSUPP;
 -}
 -
 -static inline int mlx5e_arfs_disable(struct mlx5e_priv *priv)
 -{
 -	return -ENOTSUPP;
 -}
 -#else
 -int mlx5e_arfs_create_tables(struct mlx5e_priv *priv);
 -void mlx5e_arfs_destroy_tables(struct mlx5e_priv *priv);
 -int mlx5e_arfs_enable(struct mlx5e_priv *priv);
 -int mlx5e_arfs_disable(struct mlx5e_priv *priv);
 -int mlx5e_rx_flow_steer(struct net_device *dev, const struct sk_buff *skb,
 -			u16 rxq_index, u32 flow_id);
 -#endif
 -
  u16 mlx5e_get_max_inline_cap(struct mlx5_core_dev *mdev);
++<<<<<<< HEAD
++=======
+ int mlx5e_create_tir(struct mlx5_core_dev *mdev,
+ 		     struct mlx5e_tir *tir, u32 *in, int inlen);
+ void mlx5e_destroy_tir(struct mlx5_core_dev *mdev,
+ 		       struct mlx5e_tir *tir);
+ int mlx5e_create_mdev_resources(struct mlx5_core_dev *mdev);
+ void mlx5e_destroy_mdev_resources(struct mlx5_core_dev *mdev);
+ int mlx5e_refresh_tirs_self_loopback_enable(struct mlx5_core_dev *mdev);
+ 
+ struct mlx5_eswitch_rep;
+ int mlx5e_vport_rep_load(struct mlx5_eswitch *esw,
+ 			 struct mlx5_eswitch_rep *rep);
+ void mlx5e_vport_rep_unload(struct mlx5_eswitch *esw,
+ 			    struct mlx5_eswitch_rep *rep);
+ int mlx5e_nic_rep_load(struct mlx5_eswitch *esw, struct mlx5_eswitch_rep *rep);
+ void mlx5e_nic_rep_unload(struct mlx5_eswitch *esw,
+ 			  struct mlx5_eswitch_rep *rep);
+ int mlx5e_add_sqs_fwd_rules(struct mlx5e_priv *priv);
+ void mlx5e_remove_sqs_fwd_rules(struct mlx5e_priv *priv);
+ int mlx5e_attr_get(struct net_device *dev, struct switchdev_attr *attr);
+ void mlx5e_handle_rx_cqe_rep(struct mlx5e_rq *rq, struct mlx5_cqe64 *cqe);
+ 
+ int mlx5e_create_direct_rqts(struct mlx5e_priv *priv);
+ void mlx5e_destroy_rqt(struct mlx5e_priv *priv, struct mlx5e_rqt *rqt);
+ int mlx5e_create_direct_tirs(struct mlx5e_priv *priv);
+ void mlx5e_destroy_direct_tirs(struct mlx5e_priv *priv);
+ int mlx5e_create_tises(struct mlx5e_priv *priv);
+ void mlx5e_cleanup_nic_tx(struct mlx5e_priv *priv);
+ int mlx5e_close(struct net_device *netdev);
+ int mlx5e_open(struct net_device *netdev);
+ void mlx5e_update_stats_work(struct work_struct *work);
+ struct net_device *mlx5e_create_netdev(struct mlx5_core_dev *mdev,
+ 				       const struct mlx5e_profile *profile,
+ 				       void *ppriv);
+ void mlx5e_destroy_netdev(struct mlx5_core_dev *mdev, struct mlx5e_priv *priv);
+ int mlx5e_attach_netdev(struct mlx5_core_dev *mdev, struct net_device *netdev);
+ void mlx5e_detach_netdev(struct mlx5_core_dev *mdev, struct net_device *netdev);
+ struct rtnl_link_stats64 *
+ mlx5e_get_stats(struct net_device *dev, struct rtnl_link_stats64 *stats);
+ u32 mlx5e_choose_lro_timeout(struct mlx5_core_dev *mdev, u32 wanted_timeout);
++>>>>>>> 2b029556667a (net/mlx5e: Choose best nearest LRO timeout)
  
  #endif /* __MLX5_EN_H__ */
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index 98d2ea9b4528,5c8ab3eabe9c..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@@ -2747,19 -3382,57 +2745,68 @@@ void mlx5e_set_rx_cq_mode_params(struc
  			MLX5E_PARAMS_DEFAULT_RX_CQ_MODERATION_USEC_FROM_CQE;
  }
  
++<<<<<<< HEAD
 +static void mlx5e_build_netdev_priv(struct mlx5_core_dev *mdev,
 +				    struct net_device *netdev,
 +				    int num_channels)
++=======
+ static void mlx5e_query_min_inline(struct mlx5_core_dev *mdev,
+ 				   u8 *min_inline_mode)
+ {
+ 	switch (MLX5_CAP_ETH(mdev, wqe_inline_mode)) {
+ 	case MLX5E_INLINE_MODE_L2:
+ 		*min_inline_mode = MLX5_INLINE_MODE_L2;
+ 		break;
+ 	case MLX5E_INLINE_MODE_VPORT_CONTEXT:
+ 		mlx5_query_nic_vport_min_inline(mdev,
+ 						min_inline_mode);
+ 		break;
+ 	case MLX5_INLINE_MODE_NOT_REQUIRED:
+ 		*min_inline_mode = MLX5_INLINE_MODE_NONE;
+ 		break;
+ 	}
+ }
+ 
+ u32 mlx5e_choose_lro_timeout(struct mlx5_core_dev *mdev, u32 wanted_timeout)
+ {
+ 	int i;
+ 
+ 	/* The supported periods are organized in ascending order */
+ 	for (i = 0; i < MLX5E_LRO_TIMEOUT_ARR_SIZE - 1; i++)
+ 		if (MLX5_CAP_ETH(mdev, lro_timer_supported_periods[i]) >= wanted_timeout)
+ 			break;
+ 
+ 	return MLX5_CAP_ETH(mdev, lro_timer_supported_periods[i]);
+ }
+ 
+ static void mlx5e_build_nic_netdev_priv(struct mlx5_core_dev *mdev,
+ 					struct net_device *netdev,
+ 					const struct mlx5e_profile *profile,
+ 					void *ppriv)
++>>>>>>> 2b029556667a (net/mlx5e: Choose best nearest LRO timeout)
  {
  	struct mlx5e_priv *priv = netdev_priv(netdev);
  	u32 link_speed = 0;
  	u32 pci_bw = 0;
 -	u8 cq_period_mode = MLX5_CAP_GEN(mdev, cq_period_start_from_cqe) ?
 -					 MLX5_CQ_PERIOD_MODE_START_FROM_CQE :
 -					 MLX5_CQ_PERIOD_MODE_START_FROM_EQE;
  
++<<<<<<< HEAD
 +	priv->params.log_sq_size           =
 +		MLX5E_PARAMS_DEFAULT_LOG_SQ_SIZE;
 +	priv->params.rq_wq_type = mlx5e_check_fragmented_striding_rq_cap(mdev) ?
 +		MLX5_WQ_TYPE_LINKED_LIST_STRIDING_RQ :
 +		MLX5_WQ_TYPE_LINKED_LIST;
++=======
+ 	priv->mdev                         = mdev;
+ 	priv->netdev                       = netdev;
+ 	priv->params.num_channels          = profile->max_nch(mdev);
+ 	priv->profile                      = profile;
+ 	priv->ppriv                        = ppriv;
+ 
+ 	priv->params.lro_timeout =
+ 		mlx5e_choose_lro_timeout(mdev, MLX5E_DEFAULT_LRO_TIMEOUT);
+ 
+ 	priv->params.log_sq_size = MLX5E_PARAMS_DEFAULT_LOG_SQ_SIZE;
++>>>>>>> 2b029556667a (net/mlx5e: Choose best nearest LRO timeout)
  
  	/* set CQE compression */
  	priv->params.rx_cqe_compress_admin = false;
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_main.c
