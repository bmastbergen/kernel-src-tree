blk-mq: introduce blk_mq_delay_kick_requeue_list()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Mike Snitzer <snitzer@redhat.com>
commit 2849450ad39d2e699fda2d5c6f41e05d87fd7004
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/2849450a.failed

blk_mq_delay_kick_requeue_list() provides the ability to kick the
q->requeue_list after a specified time.  To do this the request_queue's
'requeue_work' member was changed to a delayed_work.

blk_mq_delay_kick_requeue_list() allows DM to defer processing requeued
requests while it doesn't make sense to immediately requeue them
(e.g. when all paths in a DM multipath have failed).

	Signed-off-by: Mike Snitzer <snitzer@redhat.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 2849450ad39d2e699fda2d5c6f41e05d87fd7004)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/blkdev.h
diff --cc include/linux/blkdev.h
index 04d39eb837bf,c47c358ba052..000000000000
--- a/include/linux/blkdev.h
+++ b/include/linux/blkdev.h
@@@ -488,16 -445,11 +488,24 @@@ struct request_queue 
  	/*
  	 * for flush operations
  	 */
++<<<<<<< HEAD
 +	unsigned int		flush_flags;
 +	unsigned int		flush_not_queueable:1;
 +	RH_KABI_DEPRECATE(unsigned int,            flush_queue_delayed:1)
 +	RH_KABI_DEPRECATE(unsigned int,            flush_pending_idx:1)
 +	RH_KABI_DEPRECATE(unsigned int,            flush_running_idx:1)
 +	RH_KABI_DEPRECATE(unsigned long,           flush_pending_since)
 +	RH_KABI_DEPRECATE(struct list_head,        flush_queue[2])
 +	RH_KABI_DEPRECATE(struct list_head,        flush_data_in_flight)
 +	RH_KABI_DEPRECATE(struct request *,        flush_rq)
 +	RH_KABI_DEPRECATE(spinlock_t,              mq_flush_lock)
++=======
+ 	struct blk_flush_queue	*fq;
+ 
+ 	struct list_head	requeue_list;
+ 	spinlock_t		requeue_lock;
+ 	struct delayed_work	requeue_work;
++>>>>>>> 2849450ad39d (blk-mq: introduce blk_mq_delay_kick_requeue_list())
  
  	struct mutex		sysfs_lock;
  
diff --git a/block/blk-mq.c b/block/blk-mq.c
index 5a93dd7c2ec2..987b6a5e3e6c 100644
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@ -458,7 +458,7 @@ EXPORT_SYMBOL(blk_mq_requeue_request);
 static void blk_mq_requeue_work(struct work_struct *work)
 {
 	struct request_queue *q =
-		container_of(work, struct request_queue, requeue_work);
+		container_of(work, struct request_queue, requeue_work.work);
 	LIST_HEAD(rq_list);
 	struct request *rq, *next;
 	unsigned long flags;
@@ -513,16 +513,24 @@ EXPORT_SYMBOL(blk_mq_add_to_requeue_list);
 
 void blk_mq_cancel_requeue_work(struct request_queue *q)
 {
-	cancel_work_sync(&q->requeue_work);
+	cancel_delayed_work_sync(&q->requeue_work);
 }
 EXPORT_SYMBOL_GPL(blk_mq_cancel_requeue_work);
 
 void blk_mq_kick_requeue_list(struct request_queue *q)
 {
-	kblockd_schedule_work(&q->requeue_work);
+	kblockd_schedule_delayed_work(&q->requeue_work, 0);
 }
 EXPORT_SYMBOL(blk_mq_kick_requeue_list);
 
+void blk_mq_delay_kick_requeue_list(struct request_queue *q,
+				    unsigned long msecs)
+{
+	kblockd_schedule_delayed_work(&q->requeue_work,
+				      msecs_to_jiffies(msecs));
+}
+EXPORT_SYMBOL(blk_mq_delay_kick_requeue_list);
+
 void blk_mq_abort_requeue_list(struct request_queue *q)
 {
 	unsigned long flags;
@@ -2002,7 +2010,7 @@ struct request_queue *blk_mq_init_allocated_queue(struct blk_mq_tag_set *set,
 
 	q->sg_reserved_size = INT_MAX;
 
-	INIT_WORK(&q->requeue_work, blk_mq_requeue_work);
+	INIT_DELAYED_WORK(&q->requeue_work, blk_mq_requeue_work);
 	INIT_LIST_HEAD(&q->requeue_list);
 	spin_lock_init(&q->requeue_lock);
 
diff --git a/include/linux/blk-mq.h b/include/linux/blk-mq.h
index 81b624be8424..ee624b2ea645 100644
--- a/include/linux/blk-mq.h
+++ b/include/linux/blk-mq.h
@@ -255,6 +255,7 @@ void blk_mq_requeue_request(struct request *rq);
 void blk_mq_add_to_requeue_list(struct request *rq, bool at_head);
 void blk_mq_cancel_requeue_work(struct request_queue *q);
 void blk_mq_kick_requeue_list(struct request_queue *q);
+void blk_mq_delay_kick_requeue_list(struct request_queue *q, unsigned long msecs);
 void blk_mq_abort_requeue_list(struct request_queue *q);
 void blk_mq_complete_request(struct request *rq, int error);
 
* Unmerged path include/linux/blkdev.h
