xen-netfront: don't nest queue locks in xennet_connect()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author David Vrabel <david.vrabel@citrix.com>
commit f50b407653f64e76d1c9abda61d0d85cde3ca9ca
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/f50b4076.failed

The nesting of the per-queue rx_lock and tx_lock in xennet_connect()
is confusing to both humans and lockdep.  The locking is safe because
this is the only place where the locks are nested in this way but
lockdep still warns.

Instead of adding the missing lockdep annotations, refactor the
locking to avoid the confusing nesting.  This is still safe, because
the xenbus connection state changes are all serialized by the xenwatch
thread.

	Signed-off-by: David Vrabel <david.vrabel@citrix.com>
	Reported-by: Sander Eikelenboom <linux@eikelenboom.it>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit f50b407653f64e76d1c9abda61d0d85cde3ca9ca)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/xen-netfront.c
diff --cc drivers/net/xen-netfront.c
index 6c33c68dceb8,6a37d62de40b..000000000000
--- a/drivers/net/xen-netfront.c
+++ b/drivers/net/xen-netfront.c
@@@ -1757,37 -2043,45 +1757,66 @@@ static int xennet_connect(struct net_de
  	netdev_update_features(dev);
  	rtnl_unlock();
  
++<<<<<<< HEAD
 +	spin_lock_bh(&np->rx_lock);
 +	spin_lock_irq(&np->tx_lock);
 +
 +	/* Step 1: Discard all pending TX packet fragments. */
 +	xennet_release_tx_bufs(np);
 +
 +	/* Step 2: Rebuild the RX buffer freelist and the RX ring itself. */
 +	for (requeue_idx = 0, i = 0; i < NET_RX_RING_SIZE; i++) {
 +		skb_frag_t *frag;
 +		const struct page *page;
 +		if (!np->rx_skbs[i])
 +			continue;
++=======
+ 	/* By now, the queue structures have been set up */
+ 	for (j = 0; j < num_queues; ++j) {
+ 		queue = &np->queues[j];
+ 
+ 		/* Step 1: Discard all pending TX packet fragments. */
+ 		spin_lock_irq(&queue->tx_lock);
+ 		xennet_release_tx_bufs(queue);
+ 		spin_unlock_irq(&queue->tx_lock);
+ 
+ 		/* Step 2: Rebuild the RX buffer freelist and the RX ring itself. */
+ 		spin_lock_bh(&queue->rx_lock);
+ 
+ 		for (requeue_idx = 0, i = 0; i < NET_RX_RING_SIZE; i++) {
+ 			skb_frag_t *frag;
+ 			const struct page *page;
+ 			if (!queue->rx_skbs[i])
+ 				continue;
++>>>>>>> f50b407653f6 (xen-netfront: don't nest queue locks in xennet_connect())
 +
 +		skb = np->rx_skbs[requeue_idx] = xennet_get_rx_skb(np, i);
 +		ref = np->grant_rx_ref[requeue_idx] = xennet_get_rx_ref(np, i);
 +		req = RING_GET_REQUEST(&np->rx, requeue_idx);
 +
 +		frag = &skb_shinfo(skb)->frags[0];
 +		page = skb_frag_page(frag);
 +		gnttab_grant_foreign_access_ref(
 +			ref, np->xbdev->otherend_id,
 +			pfn_to_mfn(page_to_pfn(page)),
 +			0);
 +		req->gref = ref;
 +		req->id   = requeue_idx;
  
 -			skb = queue->rx_skbs[requeue_idx] = xennet_get_rx_skb(queue, i);
 -			ref = queue->grant_rx_ref[requeue_idx] = xennet_get_rx_ref(queue, i);
 -			req = RING_GET_REQUEST(&queue->rx, requeue_idx);
 -
 -			frag = &skb_shinfo(skb)->frags[0];
 -			page = skb_frag_page(frag);
 -			gnttab_grant_foreign_access_ref(
 -				ref, queue->info->xbdev->otherend_id,
 -				pfn_to_mfn(page_to_pfn(page)),
 -				0);
 -			req->gref = ref;
 -			req->id   = requeue_idx;
 -
++<<<<<<< HEAD
 +		requeue_idx++;
++=======
+ 			requeue_idx++;
+ 		}
+ 
+ 		queue->rx.req_prod_pvt = requeue_idx;
+ 
+ 		spin_unlock_bh(&queue->rx_lock);
++>>>>>>> f50b407653f6 (xen-netfront: don't nest queue locks in xennet_connect())
  	}
  
 +	np->rx.req_prod_pvt = requeue_idx;
 +
  	/*
  	 * Step 3: All public and private state should now be sane.  Get
  	 * ready to start sending and receiving packets and give the driver
@@@ -1795,14 -2089,21 +1824,32 @@@
  	 * packets.
  	 */
  	netif_carrier_on(np->netdev);
++<<<<<<< HEAD
 +	notify_remote_via_irq(np->tx_irq);
 +	if (np->tx_irq != np->rx_irq)
 +		notify_remote_via_irq(np->rx_irq);
 +	xennet_tx_buf_gc(dev);
 +	xennet_alloc_rx_buffers(dev);
 +
 +	spin_unlock_irq(&np->tx_lock);
 +	spin_unlock_bh(&np->rx_lock);
++=======
+ 	for (j = 0; j < num_queues; ++j) {
+ 		queue = &np->queues[j];
+ 
+ 		notify_remote_via_irq(queue->tx_irq);
+ 		if (queue->tx_irq != queue->rx_irq)
+ 			notify_remote_via_irq(queue->rx_irq);
+ 
+ 		spin_lock_irq(&queue->tx_lock);
+ 		xennet_tx_buf_gc(queue);
+ 		spin_unlock_irq(&queue->tx_lock);
+ 
+ 		spin_lock_bh(&queue->rx_lock);
+ 		xennet_alloc_rx_buffers(queue);
+ 		spin_unlock_bh(&queue->rx_lock);
+ 	}
++>>>>>>> f50b407653f6 (xen-netfront: don't nest queue locks in xennet_connect())
  
  	return 0;
  }
* Unmerged path drivers/net/xen-netfront.c
