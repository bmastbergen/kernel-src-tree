net/mlx5e: Introduce SRIOV VF representors

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [netdrv] mlx5e: Introduce SRIOV VF representors (Don Dutile) [1383788 1417284]
Rebuild_FUZZ: 95.00%
commit-author Hadar Hen Zion <hadarh@mellanox.com>
commit cb67b832921cfa20ad79bafdc51f1745339d0557
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/cb67b832.failed

Implement the relevant profile functions to create mlx5e driver instance
serving as VF representor. When SRIOV offloads mode is enabled, each VF
will have a representor netdevice instance on the host.

To do that, we also export set of shared service functions from en_main.c,
such that they can be used by both NIC and repsresentors netdevs.

The newly created representor netdevice has a basic set of net_device_ops
which are the same ndo functions as the NIC netdevice and an ndo of it's
own for phys port name.

The profiling infrastructure allow sharing code between the NIC and the
vport representor even though the representor has only a subset of the
NIC functionality.

The VF reps and the PF which is used in that mode to represent the uplink,
expose switchdev ops. Currently the only op supposed is attr get for the
port parent ID which here serves to identify net-devices belonging to the
same HW E-Switch. Other than that, no offloading is implemented and hence
switching functionality is achieved if one sets SW switching rules, e.g
using tc, bridge or ovs.

Port phys name (ndo_get_phys_port_name) is implemented to allow exporting
to user-space the VF vport number and along with the switchdev port parent
id (phys_switch_id) enable a udev base consistent naming scheme:

SUBSYSTEM=="net", ACTION=="add", ATTR{phys_switch_id}=="<phys_switch_id>", \
        ATTR{phys_port_name}!="", NAME="$PF_NIC$attr{phys_port_name}"

where phys_switch_id is exposed by the PF (and VF reps) and $PF_NIC is
the name of the PF netdevice.

	Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
	Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit cb67b832921cfa20ad79bafdc51f1745339d0557)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/Makefile
#	drivers/net/ethernet/mellanox/mlx5/core/en.h
#	drivers/net/ethernet/mellanox/mlx5/core/en_main.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/Makefile
index 3784a00cd751,a574deabdda8..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/Makefile
+++ b/drivers/net/ethernet/mellanox/mlx5/core/Makefile
@@@ -1,12 -1,13 +1,19 @@@
  obj-$(CONFIG_MLX5_CORE)		+= mlx5_core.o
  
  mlx5_core-y :=	main.o cmd.o debugfs.o fw.o eq.o uar.o pagealloc.o \
 -		health.o mcg.o cq.o srq.o alloc.o qp.o port.o mr.o pd.o \
 -		mad.o transobj.o vport.o sriov.o fs_cmd.o fs_core.o \
 -		fs_counters.o rl.o
 +		health.o mcg.o cq.o srq.o alloc.o qp.o port.o mr.o pd.o   \
 +		mad.o transobj.o vport.o sriov.o fs_cmd.o fs_core.o
  
++<<<<<<< HEAD
 +mlx5_core-$(CONFIG_MLX5_CORE_EN) += wq.o eswitch.o \
 +		en_main.o en_fs.o en_ethtool.o en_tx.o en_rx.o \
 +		en_txrx.o en_clock.o
++=======
+ mlx5_core-$(CONFIG_MLX5_CORE_EN) += wq.o eswitch.o eswitch_offloads.o \
+ 		en_main.o en_common.o en_fs.o en_ethtool.o en_tx.o \
+ 		en_rx.o en_rx_am.o en_txrx.o en_clock.o vxlan.o \
+ 		en_tc.o en_arfs.o en_rep.o
++>>>>>>> cb67b832921c (net/mlx5e: Introduce SRIOV VF representors)
  
 +mlx5_core-$(CONFIG_MLX5_CORE_EN_VXLAN) += vxlan.o
  mlx5_core-$(CONFIG_MLX5_CORE_EN_DCB) +=  en_dcbnl.o
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en.h
index 5eea7e35421a,00643a116492..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en.h
@@@ -43,6 -43,8 +43,11 @@@
  #include <linux/mlx5/port.h>
  #include <linux/mlx5/vport.h>
  #include <linux/mlx5/transobj.h>
++<<<<<<< HEAD
++=======
+ #include <linux/rhashtable.h>
+ #include <net/switchdev.h>
++>>>>>>> cb67b832921c (net/mlx5e: Introduce SRIOV VF representors)
  #include "wq.h"
  #include "mlx5_core.h"
  #include "en_stats.h"
@@@ -678,6 -782,66 +683,33 @@@ extern const struct dcbnl_rtnl_ops mlx5
  int mlx5e_dcbnl_ieee_setets_core(struct mlx5e_priv *priv, struct ieee_ets *ets);
  #endif
  
 -#ifndef CONFIG_RFS_ACCEL
 -static inline int mlx5e_arfs_create_tables(struct mlx5e_priv *priv)
 -{
 -	return 0;
 -}
 -
 -static inline void mlx5e_arfs_destroy_tables(struct mlx5e_priv *priv) {}
 -
 -static inline int mlx5e_arfs_enable(struct mlx5e_priv *priv)
 -{
 -	return -ENOTSUPP;
 -}
 -
 -static inline int mlx5e_arfs_disable(struct mlx5e_priv *priv)
 -{
 -	return -ENOTSUPP;
 -}
 -#else
 -int mlx5e_arfs_create_tables(struct mlx5e_priv *priv);
 -void mlx5e_arfs_destroy_tables(struct mlx5e_priv *priv);
 -int mlx5e_arfs_enable(struct mlx5e_priv *priv);
 -int mlx5e_arfs_disable(struct mlx5e_priv *priv);
 -int mlx5e_rx_flow_steer(struct net_device *dev, const struct sk_buff *skb,
 -			u16 rxq_index, u32 flow_id);
 -#endif
 -
  u16 mlx5e_get_max_inline_cap(struct mlx5_core_dev *mdev);
 -int mlx5e_create_tir(struct mlx5_core_dev *mdev,
 -		     struct mlx5e_tir *tir, u32 *in, int inlen);
 -void mlx5e_destroy_tir(struct mlx5_core_dev *mdev,
 -		       struct mlx5e_tir *tir);
 -int mlx5e_create_mdev_resources(struct mlx5_core_dev *mdev);
 -void mlx5e_destroy_mdev_resources(struct mlx5_core_dev *mdev);
 -int mlx5e_refresh_tirs_self_loopback_enable(struct mlx5_core_dev *mdev);
  
+ struct mlx5_eswitch_rep;
+ int mlx5e_vport_rep_load(struct mlx5_eswitch *esw,
+ 			 struct mlx5_eswitch_rep *rep);
+ void mlx5e_vport_rep_unload(struct mlx5_eswitch *esw,
+ 			    struct mlx5_eswitch_rep *rep);
+ int mlx5e_nic_rep_load(struct mlx5_eswitch *esw, struct mlx5_eswitch_rep *rep);
+ void mlx5e_nic_rep_unload(struct mlx5_eswitch *esw,
+ 			  struct mlx5_eswitch_rep *rep);
+ int mlx5e_add_sqs_fwd_rules(struct mlx5e_priv *priv);
+ void mlx5e_remove_sqs_fwd_rules(struct mlx5e_priv *priv);
+ int mlx5e_attr_get(struct net_device *dev, struct switchdev_attr *attr);
+ 
+ int mlx5e_create_direct_rqts(struct mlx5e_priv *priv);
+ void mlx5e_destroy_rqt(struct mlx5e_priv *priv, struct mlx5e_rqt *rqt);
+ int mlx5e_create_direct_tirs(struct mlx5e_priv *priv);
+ void mlx5e_destroy_direct_tirs(struct mlx5e_priv *priv);
+ int mlx5e_create_tises(struct mlx5e_priv *priv);
+ void mlx5e_cleanup_nic_tx(struct mlx5e_priv *priv);
+ int mlx5e_close(struct net_device *netdev);
+ int mlx5e_open(struct net_device *netdev);
+ void mlx5e_update_stats_work(struct work_struct *work);
+ void *mlx5e_create_netdev(struct mlx5_core_dev *mdev,
+ 			  const struct mlx5e_profile *profile, void *ppriv);
+ void mlx5e_destroy_netdev(struct mlx5_core_dev *mdev, struct mlx5e_priv *priv);
+ struct rtnl_link_stats64 *
+ mlx5e_get_stats(struct net_device *dev, struct rtnl_link_stats64 *stats);
+ 
  #endif /* __MLX5_EN_H__ */
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index 0c9d38242297,96ec53a6a595..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@@ -1444,15 -1518,22 +1444,30 @@@ static int mlx5e_create_rqt(struct mlx5
  	return err;
  }
  
++<<<<<<< HEAD
 +static void mlx5e_destroy_rqt(struct mlx5e_priv *priv, u32 rqtn)
++=======
+ void mlx5e_destroy_rqt(struct mlx5e_priv *priv, struct mlx5e_rqt *rqt)
++>>>>>>> cb67b832921c (net/mlx5e: Introduce SRIOV VF representors)
  {
 -	rqt->enabled = false;
 -	mlx5_core_destroy_rqt(priv->mdev, rqt->rqtn);
 +	mlx5_core_destroy_rqt(priv->mdev, rqtn);
  }
  
 -static int mlx5e_create_indirect_rqts(struct mlx5e_priv *priv)
 +static int mlx5e_create_rqts(struct mlx5e_priv *priv)
  {
++<<<<<<< HEAD
 +	int nch = mlx5e_get_max_num_channels(priv->mdev);
 +	u32 *rqtn;
++=======
+ 	struct mlx5e_rqt *rqt = &priv->indir_rqt;
+ 
+ 	return mlx5e_create_rqt(priv, MLX5E_INDIR_RQT_SIZE, 0, rqt);
+ }
+ 
+ int mlx5e_create_direct_rqts(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_rqt *rqt;
++>>>>>>> cb67b832921c (net/mlx5e: Introduce SRIOV VF representors)
  	int err;
  	int ix;
  
@@@ -1948,7 -1987,7 +1973,11 @@@ err_close_tises
  	return err;
  }
  
++<<<<<<< HEAD
 +static void mlx5e_destroy_tises(struct mlx5e_priv *priv)
++=======
+ void mlx5e_cleanup_nic_tx(struct mlx5e_priv *priv)
++>>>>>>> cb67b832921c (net/mlx5e: Introduce SRIOV VF representors)
  {
  	int tc;
  
@@@ -2104,14 -2140,41 +2133,45 @@@ static int mlx5e_create_tirs(struct mlx
  			goto err_destroy_tirs;
  	}
  
++<<<<<<< HEAD
 +	/* direct tirs */
++=======
+ 	kvfree(in);
+ 
+ 	return 0;
+ 
+ err_destroy_tirs:
+ 	for (tt--; tt >= 0; tt--)
+ 		mlx5e_destroy_tir(priv->mdev, &priv->indir_tir[tt]);
+ 
+ 	kvfree(in);
+ 
+ 	return err;
+ }
+ 
+ int mlx5e_create_direct_tirs(struct mlx5e_priv *priv)
+ {
+ 	int nch = priv->profile->max_nch(priv->mdev);
+ 	struct mlx5e_tir *tir;
+ 	void *tirc;
+ 	int inlen;
+ 	int err;
+ 	u32 *in;
+ 	int ix;
+ 
+ 	inlen = MLX5_ST_SZ_BYTES(create_tir_in);
+ 	in = mlx5_vzalloc(inlen);
+ 	if (!in)
+ 		return -ENOMEM;
+ 
++>>>>>>> cb67b832921c (net/mlx5e: Introduce SRIOV VF representors)
  	for (ix = 0; ix < nch; ix++) {
  		memset(in, 0, inlen);
 -		tir = &priv->direct_tir[ix];
 +		tirn = &priv->direct_tir[ix].tirn;
  		tirc = MLX5_ADDR_OF(create_tir_in, in, ctx);
  		mlx5e_build_direct_tir_ctx(priv, tirc,
 -					   priv->direct_tir[ix].rqt.rqtn);
 -		err = mlx5e_create_tir(priv->mdev, tir, in, inlen);
 +					   priv->direct_tir[ix].rqtn);
 +		err = mlx5_core_create_tir(priv->mdev, in, inlen, tirn);
  		if (err)
  			goto err_destroy_ch_tirs;
  	}
@@@ -2133,9 -2192,17 +2193,21 @@@ err_destroy_tirs
  	return err;
  }
  
 -static void mlx5e_destroy_indirect_tirs(struct mlx5e_priv *priv)
 +static void mlx5e_destroy_tirs(struct mlx5e_priv *priv)
  {
++<<<<<<< HEAD
 +	int nch = mlx5e_get_max_num_channels(priv->mdev);
++=======
+ 	int i;
+ 
+ 	for (i = 0; i < MLX5E_NUM_INDIR_TIRS; i++)
+ 		mlx5e_destroy_tir(priv->mdev, &priv->indir_tir[i]);
+ }
+ 
+ void mlx5e_destroy_direct_tirs(struct mlx5e_priv *priv)
+ {
+ 	int nch = priv->profile->max_nch(priv->mdev);
++>>>>>>> cb67b832921c (net/mlx5e: Introduce SRIOV VF representors)
  	int i;
  
  	for (i = 0; i < nch; i++)
@@@ -2847,7 -2998,11 +2919,15 @@@ static void mlx5e_set_netdev_dev_addr(s
  	}
  }
  
++<<<<<<< HEAD
 +static void mlx5e_build_netdev(struct net_device *netdev)
++=======
+ static const struct switchdev_ops mlx5e_switchdev_ops = {
+ 	.switchdev_port_attr_get	= mlx5e_attr_get,
+ };
+ 
+ static void mlx5e_build_nic_netdev(struct net_device *netdev)
++>>>>>>> cb67b832921c (net/mlx5e: Introduce SRIOV VF representors)
  {
  	struct mlx5e_priv *priv = netdev_priv(netdev);
  	struct mlx5_core_dev *mdev = priv->mdev;
@@@ -2917,33 -3083,13 +2997,38 @@@
  	netdev->priv_flags       |= IFF_UNICAST_FLT;
  
  	mlx5e_set_netdev_dev_addr(netdev);
+ 
+ #ifdef CONFIG_NET_SWITCHDEV
+ 	if (MLX5_CAP_GEN(mdev, vport_group_manager))
+ 		netdev->switchdev_ops = &mlx5e_switchdev_ops;
+ #endif
  }
  
 +static int mlx5e_create_mkey(struct mlx5e_priv *priv, u32 pdn,
 +			     struct mlx5_core_mkey *mkey)
 +{
 +	struct mlx5_core_dev *mdev = priv->mdev;
 +	struct mlx5_create_mkey_mbox_in *in;
 +	int err;
 +
 +	in = mlx5_vzalloc(sizeof(*in));
 +	if (!in)
 +		return -ENOMEM;
 +
 +	in->seg.flags = MLX5_PERM_LOCAL_WRITE |
 +			MLX5_PERM_LOCAL_READ  |
 +			MLX5_ACCESS_MODE_PA;
 +	in->seg.flags_pd = cpu_to_be32(pdn | MLX5_MKEY_LEN64);
 +	in->seg.qpn_mkey7_0 = cpu_to_be32(0xffffff << 8);
 +
 +	err = mlx5_core_create_mkey(mdev, mkey, in, sizeof(*in), NULL, NULL,
 +				    NULL);
 +
 +	kvfree(in);
 +
 +	return err;
 +}
 +
  static void mlx5e_create_q_counter(struct mlx5e_priv *priv)
  {
  	struct mlx5_core_dev *mdev = priv->mdev;
@@@ -2999,7 -3145,161 +3084,165 @@@ static int mlx5e_create_umr_mkey(struc
  	return err;
  }
  
++<<<<<<< HEAD
 +static void *mlx5e_create_netdev(struct mlx5_core_dev *mdev)
++=======
+ static void mlx5e_nic_init(struct mlx5_core_dev *mdev,
+ 			   struct net_device *netdev,
+ 			   const struct mlx5e_profile *profile,
+ 			   void *ppriv)
+ {
+ 	struct mlx5e_priv *priv = netdev_priv(netdev);
+ 
+ 	mlx5e_build_nic_netdev_priv(mdev, netdev, profile, ppriv);
+ 	mlx5e_build_nic_netdev(netdev);
+ 	mlx5e_vxlan_init(priv);
+ }
+ 
+ static void mlx5e_nic_cleanup(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5_core_dev *mdev = priv->mdev;
+ 	struct mlx5_eswitch *esw = mdev->priv.eswitch;
+ 
+ 	mlx5e_vxlan_cleanup(priv);
+ 
+ 	if (MLX5_CAP_GEN(mdev, vport_group_manager))
+ 		mlx5_eswitch_unregister_vport_rep(esw, 0);
+ }
+ 
+ static int mlx5e_init_nic_rx(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5_core_dev *mdev = priv->mdev;
+ 	int err;
+ 	int i;
+ 
+ 	err = mlx5e_create_indirect_rqts(priv);
+ 	if (err) {
+ 		mlx5_core_warn(mdev, "create indirect rqts failed, %d\n", err);
+ 		return err;
+ 	}
+ 
+ 	err = mlx5e_create_direct_rqts(priv);
+ 	if (err) {
+ 		mlx5_core_warn(mdev, "create direct rqts failed, %d\n", err);
+ 		goto err_destroy_indirect_rqts;
+ 	}
+ 
+ 	err = mlx5e_create_indirect_tirs(priv);
+ 	if (err) {
+ 		mlx5_core_warn(mdev, "create indirect tirs failed, %d\n", err);
+ 		goto err_destroy_direct_rqts;
+ 	}
+ 
+ 	err = mlx5e_create_direct_tirs(priv);
+ 	if (err) {
+ 		mlx5_core_warn(mdev, "create direct tirs failed, %d\n", err);
+ 		goto err_destroy_indirect_tirs;
+ 	}
+ 
+ 	err = mlx5e_create_flow_steering(priv);
+ 	if (err) {
+ 		mlx5_core_warn(mdev, "create flow steering failed, %d\n", err);
+ 		goto err_destroy_direct_tirs;
+ 	}
+ 
+ 	err = mlx5e_tc_init(priv);
+ 	if (err)
+ 		goto err_destroy_flow_steering;
+ 
+ 	return 0;
+ 
+ err_destroy_flow_steering:
+ 	mlx5e_destroy_flow_steering(priv);
+ err_destroy_direct_tirs:
+ 	mlx5e_destroy_direct_tirs(priv);
+ err_destroy_indirect_tirs:
+ 	mlx5e_destroy_indirect_tirs(priv);
+ err_destroy_direct_rqts:
+ 	for (i = 0; i < priv->profile->max_nch(mdev); i++)
+ 		mlx5e_destroy_rqt(priv, &priv->direct_tir[i].rqt);
+ err_destroy_indirect_rqts:
+ 	mlx5e_destroy_rqt(priv, &priv->indir_rqt);
+ 	return err;
+ }
+ 
+ static void mlx5e_cleanup_nic_rx(struct mlx5e_priv *priv)
+ {
+ 	int i;
+ 
+ 	mlx5e_tc_cleanup(priv);
+ 	mlx5e_destroy_flow_steering(priv);
+ 	mlx5e_destroy_direct_tirs(priv);
+ 	mlx5e_destroy_indirect_tirs(priv);
+ 	for (i = 0; i < priv->profile->max_nch(priv->mdev); i++)
+ 		mlx5e_destroy_rqt(priv, &priv->direct_tir[i].rqt);
+ 	mlx5e_destroy_rqt(priv, &priv->indir_rqt);
+ }
+ 
+ static int mlx5e_init_nic_tx(struct mlx5e_priv *priv)
+ {
+ 	int err;
+ 
+ 	err = mlx5e_create_tises(priv);
+ 	if (err) {
+ 		mlx5_core_warn(priv->mdev, "create tises failed, %d\n", err);
+ 		return err;
+ 	}
+ 
+ #ifdef CONFIG_MLX5_CORE_EN_DCB
+ 	mlx5e_dcbnl_ieee_setets_core(priv, &priv->params.ets);
+ #endif
+ 	return 0;
+ }
+ 
+ static void mlx5e_nic_enable(struct mlx5e_priv *priv)
+ {
+ 	struct net_device *netdev = priv->netdev;
+ 	struct mlx5_core_dev *mdev = priv->mdev;
+ 	struct mlx5_eswitch *esw = mdev->priv.eswitch;
+ 	struct mlx5_eswitch_rep rep;
+ 
+ 	if (mlx5e_vxlan_allowed(mdev)) {
+ 		rtnl_lock();
+ 		udp_tunnel_get_rx_info(netdev);
+ 		rtnl_unlock();
+ 	}
+ 
+ 	mlx5e_enable_async_events(priv);
+ 	queue_work(priv->wq, &priv->set_rx_mode_work);
+ 
+ 	if (MLX5_CAP_GEN(mdev, vport_group_manager)) {
+ 		rep.load = mlx5e_nic_rep_load;
+ 		rep.unload = mlx5e_nic_rep_unload;
+ 		rep.vport = 0;
+ 		rep.priv_data = priv;
+ 		mlx5_eswitch_register_vport_rep(esw, &rep);
+ 	}
+ }
+ 
+ static void mlx5e_nic_disable(struct mlx5e_priv *priv)
+ {
+ 	queue_work(priv->wq, &priv->set_rx_mode_work);
+ 	mlx5e_disable_async_events(priv);
+ }
+ 
+ static const struct mlx5e_profile mlx5e_nic_profile = {
+ 	.init		   = mlx5e_nic_init,
+ 	.cleanup	   = mlx5e_nic_cleanup,
+ 	.init_rx	   = mlx5e_init_nic_rx,
+ 	.cleanup_rx	   = mlx5e_cleanup_nic_rx,
+ 	.init_tx	   = mlx5e_init_nic_tx,
+ 	.cleanup_tx	   = mlx5e_cleanup_nic_tx,
+ 	.enable		   = mlx5e_nic_enable,
+ 	.disable	   = mlx5e_nic_disable,
+ 	.update_stats	   = mlx5e_update_stats,
+ 	.max_nch	   = mlx5e_get_max_num_channels,
+ 	.max_tc		   = MLX5E_MAX_NUM_TC,
+ };
+ 
+ void *mlx5e_create_netdev(struct mlx5_core_dev *mdev,
+ 			  const struct mlx5e_profile *profile, void *ppriv)
++>>>>>>> cb67b832921c (net/mlx5e: Introduce SRIOV VF representors)
  {
  	struct net_device *netdev;
  	struct mlx5e_priv *priv;
@@@ -3156,9 -3381,53 +3399,57 @@@ err_free_netdev
  	return NULL;
  }
  
 -static void mlx5e_register_vport_rep(struct mlx5_core_dev *mdev)
 +static void mlx5e_destroy_netdev(struct mlx5_core_dev *mdev, void *vpriv)
  {
++<<<<<<< HEAD
 +	struct mlx5e_priv *priv = vpriv;
++=======
+ 	struct mlx5_eswitch *esw = mdev->priv.eswitch;
+ 	int total_vfs = MLX5_TOTAL_VPORTS(mdev);
+ 	int vport;
+ 
+ 	if (!MLX5_CAP_GEN(mdev, vport_group_manager))
+ 		return;
+ 
+ 	for (vport = 1; vport < total_vfs; vport++) {
+ 		struct mlx5_eswitch_rep rep;
+ 
+ 		rep.load = mlx5e_vport_rep_load;
+ 		rep.unload = mlx5e_vport_rep_unload;
+ 		rep.vport = vport;
+ 		mlx5_eswitch_register_vport_rep(esw, &rep);
+ 	}
+ }
+ 
+ static void *mlx5e_add(struct mlx5_core_dev *mdev)
+ {
+ 	struct mlx5_eswitch *esw = mdev->priv.eswitch;
+ 	void *ppriv = NULL;
+ 	void *ret;
+ 
+ 	if (mlx5e_check_required_hca_cap(mdev))
+ 		return NULL;
+ 
+ 	if (mlx5e_create_mdev_resources(mdev))
+ 		return NULL;
+ 
+ 	mlx5e_register_vport_rep(mdev);
+ 
+ 	if (MLX5_CAP_GEN(mdev, vport_group_manager))
+ 		ppriv = &esw->offloads.vport_reps[0];
+ 
+ 	ret = mlx5e_create_netdev(mdev, &mlx5e_nic_profile, ppriv);
+ 	if (!ret) {
+ 		mlx5e_destroy_mdev_resources(mdev);
+ 		return NULL;
+ 	}
+ 	return ret;
+ }
+ 
+ void mlx5e_destroy_netdev(struct mlx5_core_dev *mdev, struct mlx5e_priv *priv)
+ {
+ 	const struct mlx5e_profile *profile = priv->profile;
++>>>>>>> cb67b832921c (net/mlx5e: Introduce SRIOV VF representors)
  	struct net_device *netdev = priv->netdev;
  
  	set_bit(MLX5E_STATE_DESTROYING, &priv->state);
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index 6f9da7b7d506,7b45e6a6efb8..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@@ -130,9 -137,48 +132,54 @@@ struct mlx5_l2_table 
  
  struct mlx5_eswitch_fdb {
  	void *fdb;
++<<<<<<< HEAD
 +	struct mlx5_flow_group *addr_grp;
 +	struct mlx5_flow_group *allmulti_grp;
 +	struct mlx5_flow_group *promisc_grp;
++=======
+ 	union {
+ 		struct legacy_fdb {
+ 			struct mlx5_flow_group *addr_grp;
+ 			struct mlx5_flow_group *allmulti_grp;
+ 			struct mlx5_flow_group *promisc_grp;
+ 		} legacy;
+ 
+ 		struct offloads_fdb {
+ 			struct mlx5_flow_group *send_to_vport_grp;
+ 			struct mlx5_flow_group *miss_grp;
+ 			struct mlx5_flow_rule  *miss_rule;
+ 		} offloads;
+ 	};
+ };
+ 
+ enum {
+ 	SRIOV_NONE,
+ 	SRIOV_LEGACY,
+ 	SRIOV_OFFLOADS
+ };
+ 
+ struct mlx5_esw_sq {
+ 	struct mlx5_flow_rule	*send_to_vport_rule;
+ 	struct list_head	 list;
+ };
+ 
+ struct mlx5_eswitch_rep {
+ 	int		       (*load)(struct mlx5_eswitch *esw,
+ 				       struct mlx5_eswitch_rep *rep);
+ 	void		       (*unload)(struct mlx5_eswitch *esw,
+ 					 struct mlx5_eswitch_rep *rep);
+ 	u16		       vport;
+ 	struct mlx5_flow_rule *vport_rx_rule;
+ 	void		      *priv_data;
+ 	struct list_head       vport_sqs_list;
+ 	bool		       valid;
+ };
+ 
+ struct mlx5_esw_offload {
+ 	struct mlx5_flow_table *ft_offloads;
+ 	struct mlx5_flow_group *vport_rx_group;
+ 	struct mlx5_eswitch_rep *vport_reps;
++>>>>>>> cb67b832921c (net/mlx5e: Introduce SRIOV VF representors)
  };
  
  struct mlx5_eswitch {
@@@ -168,4 -221,30 +215,33 @@@ int mlx5_eswitch_get_vport_stats(struc
  				 int vport,
  				 struct ifla_vf_stats *vf_stats);
  
++<<<<<<< HEAD
++=======
+ struct mlx5_flow_rule *
+ mlx5_eswitch_create_vport_rx_rule(struct mlx5_eswitch *esw, int vport, u32 tirn);
+ 
+ int mlx5_eswitch_sqs2vport_start(struct mlx5_eswitch *esw,
+ 				 struct mlx5_eswitch_rep *rep,
+ 				 u16 *sqns_array, int sqns_num);
+ void mlx5_eswitch_sqs2vport_stop(struct mlx5_eswitch *esw,
+ 				 struct mlx5_eswitch_rep *rep);
+ 
+ int mlx5_devlink_eswitch_mode_set(struct devlink *devlink, u16 mode);
+ int mlx5_devlink_eswitch_mode_get(struct devlink *devlink, u16 *mode);
+ void mlx5_eswitch_register_vport_rep(struct mlx5_eswitch *esw,
+ 				     struct mlx5_eswitch_rep *rep);
+ void mlx5_eswitch_unregister_vport_rep(struct mlx5_eswitch *esw,
+ 				       int vport);
+ 
+ #define MLX5_DEBUG_ESWITCH_MASK BIT(3)
+ 
+ #define esw_info(dev, format, ...)				\
+ 	pr_info("(%s): E-Switch: " format, (dev)->priv.name, ##__VA_ARGS__)
+ 
+ #define esw_warn(dev, format, ...)				\
+ 	pr_warn("(%s): E-Switch: " format, (dev)->priv.name, ##__VA_ARGS__)
+ 
+ #define esw_debug(dev, format, ...)				\
+ 	mlx5_core_dbg_mask(dev, MLX5_DEBUG_ESWITCH_MASK, format, ##__VA_ARGS__)
++>>>>>>> cb67b832921c (net/mlx5e: Introduce SRIOV VF representors)
  #endif /* __MLX5_ESWITCH_H__ */
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/Makefile
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_main.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
new file mode 100644
index 000000000000..5ef02f02a1d5
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
@@ -0,0 +1,394 @@
+/*
+ * Copyright (c) 2016, Mellanox Technologies. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include <generated/utsrelease.h>
+#include <linux/mlx5/fs.h>
+#include <net/switchdev.h>
+
+#include "eswitch.h"
+#include "en.h"
+
+static const char mlx5e_rep_driver_name[] = "mlx5e_rep";
+
+static void mlx5e_rep_get_drvinfo(struct net_device *dev,
+				  struct ethtool_drvinfo *drvinfo)
+{
+	strlcpy(drvinfo->driver, mlx5e_rep_driver_name,
+		sizeof(drvinfo->driver));
+	strlcpy(drvinfo->version, UTS_RELEASE, sizeof(drvinfo->version));
+}
+
+static const struct counter_desc sw_rep_stats_desc[] = {
+	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_packets) },
+	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_bytes) },
+	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_packets) },
+	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_bytes) },
+};
+
+#define NUM_VPORT_REP_COUNTERS	ARRAY_SIZE(sw_rep_stats_desc)
+
+static void mlx5e_rep_get_strings(struct net_device *dev,
+				  u32 stringset, uint8_t *data)
+{
+	int i;
+
+	switch (stringset) {
+	case ETH_SS_STATS:
+		for (i = 0; i < NUM_VPORT_REP_COUNTERS; i++)
+			strcpy(data + (i * ETH_GSTRING_LEN),
+			       sw_rep_stats_desc[i].format);
+		break;
+	}
+}
+
+static void mlx5e_update_sw_rep_counters(struct mlx5e_priv *priv)
+{
+	struct mlx5e_sw_stats *s = &priv->stats.sw;
+	struct mlx5e_rq_stats *rq_stats;
+	struct mlx5e_sq_stats *sq_stats;
+	int i, j;
+
+	memset(s, 0, sizeof(*s));
+	for (i = 0; i < priv->params.num_channels; i++) {
+		rq_stats = &priv->channel[i]->rq.stats;
+
+		s->rx_packets	+= rq_stats->packets;
+		s->rx_bytes	+= rq_stats->bytes;
+
+		for (j = 0; j < priv->params.num_tc; j++) {
+			sq_stats = &priv->channel[i]->sq[j].stats;
+
+			s->tx_packets		+= sq_stats->packets;
+			s->tx_bytes		+= sq_stats->bytes;
+		}
+	}
+}
+
+static void mlx5e_rep_get_ethtool_stats(struct net_device *dev,
+					struct ethtool_stats *stats, u64 *data)
+{
+	struct mlx5e_priv *priv = netdev_priv(dev);
+	int i;
+
+	if (!data)
+		return;
+
+	mutex_lock(&priv->state_lock);
+	if (test_bit(MLX5E_STATE_OPENED, &priv->state))
+		mlx5e_update_sw_rep_counters(priv);
+	mutex_unlock(&priv->state_lock);
+
+	for (i = 0; i < NUM_VPORT_REP_COUNTERS; i++)
+		data[i] = MLX5E_READ_CTR64_CPU(&priv->stats.sw,
+					       sw_rep_stats_desc, i);
+}
+
+static int mlx5e_rep_get_sset_count(struct net_device *dev, int sset)
+{
+	switch (sset) {
+	case ETH_SS_STATS:
+		return NUM_VPORT_REP_COUNTERS;
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+static const struct ethtool_ops mlx5e_rep_ethtool_ops = {
+	.get_drvinfo	   = mlx5e_rep_get_drvinfo,
+	.get_link	   = ethtool_op_get_link,
+	.get_strings       = mlx5e_rep_get_strings,
+	.get_sset_count    = mlx5e_rep_get_sset_count,
+	.get_ethtool_stats = mlx5e_rep_get_ethtool_stats,
+};
+
+int mlx5e_attr_get(struct net_device *dev, struct switchdev_attr *attr)
+{
+	struct mlx5e_priv *priv = netdev_priv(dev);
+	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+	u8 mac[ETH_ALEN];
+
+	if (esw->mode == SRIOV_NONE)
+		return -EOPNOTSUPP;
+
+	switch (attr->id) {
+	case SWITCHDEV_ATTR_ID_PORT_PARENT_ID:
+		mlx5_query_nic_vport_mac_address(priv->mdev, 0, mac);
+		attr->u.ppid.id_len = ETH_ALEN;
+		memcpy(&attr->u.ppid.id, &mac, ETH_ALEN);
+		break;
+	default:
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
+int mlx5e_add_sqs_fwd_rules(struct mlx5e_priv *priv)
+
+{
+	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+	struct mlx5_eswitch_rep *rep = priv->ppriv;
+	struct mlx5e_channel *c;
+	int n, tc, err, num_sqs = 0;
+	u16 *sqs;
+
+	sqs = kcalloc(priv->params.num_channels * priv->params.num_tc, sizeof(u16), GFP_KERNEL);
+	if (!sqs)
+		return -ENOMEM;
+
+	for (n = 0; n < priv->params.num_channels; n++) {
+		c = priv->channel[n];
+		for (tc = 0; tc < c->num_tc; tc++)
+			sqs[num_sqs++] = c->sq[tc].sqn;
+	}
+
+	err = mlx5_eswitch_sqs2vport_start(esw, rep, sqs, num_sqs);
+
+	kfree(sqs);
+	return err;
+}
+
+int mlx5e_nic_rep_load(struct mlx5_eswitch *esw, struct mlx5_eswitch_rep *rep)
+{
+	struct mlx5e_priv *priv = rep->priv_data;
+
+	if (test_bit(MLX5E_STATE_OPENED, &priv->state))
+		return mlx5e_add_sqs_fwd_rules(priv);
+	return 0;
+}
+
+void mlx5e_remove_sqs_fwd_rules(struct mlx5e_priv *priv)
+{
+	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+	struct mlx5_eswitch_rep *rep = priv->ppriv;
+
+	mlx5_eswitch_sqs2vport_stop(esw, rep);
+}
+
+void mlx5e_nic_rep_unload(struct mlx5_eswitch *esw,
+			  struct mlx5_eswitch_rep *rep)
+{
+	struct mlx5e_priv *priv = rep->priv_data;
+
+	if (test_bit(MLX5E_STATE_OPENED, &priv->state))
+		mlx5e_remove_sqs_fwd_rules(priv);
+}
+
+static int mlx5e_rep_get_phys_port_name(struct net_device *dev,
+					char *buf, size_t len)
+{
+	struct mlx5e_priv *priv = netdev_priv(dev);
+	struct mlx5_eswitch_rep *rep = priv->ppriv;
+	int ret;
+
+	ret = snprintf(buf, len, "%d", rep->vport - 1);
+	if (ret >= len)
+		return -EOPNOTSUPP;
+
+	return 0;
+}
+
+static const struct switchdev_ops mlx5e_rep_switchdev_ops = {
+	.switchdev_port_attr_get	= mlx5e_attr_get,
+};
+
+static const struct net_device_ops mlx5e_netdev_ops_rep = {
+	.ndo_open                = mlx5e_open,
+	.ndo_stop                = mlx5e_close,
+	.ndo_start_xmit          = mlx5e_xmit,
+	.ndo_get_phys_port_name  = mlx5e_rep_get_phys_port_name,
+	.ndo_get_stats64         = mlx5e_get_stats,
+};
+
+static void mlx5e_build_rep_netdev_priv(struct mlx5_core_dev *mdev,
+					struct net_device *netdev,
+					const struct mlx5e_profile *profile,
+					void *ppriv)
+{
+	struct mlx5e_priv *priv = netdev_priv(netdev);
+	u8 cq_period_mode = MLX5_CAP_GEN(mdev, cq_period_start_from_cqe) ?
+					 MLX5_CQ_PERIOD_MODE_START_FROM_CQE :
+					 MLX5_CQ_PERIOD_MODE_START_FROM_EQE;
+
+	priv->params.log_sq_size           =
+		MLX5E_PARAMS_MINIMUM_LOG_SQ_SIZE;
+	priv->params.rq_wq_type = MLX5_WQ_TYPE_LINKED_LIST;
+	priv->params.log_rq_size = MLX5E_PARAMS_MINIMUM_LOG_RQ_SIZE;
+
+	priv->params.min_rx_wqes = mlx5_min_rx_wqes(priv->params.rq_wq_type,
+					    BIT(priv->params.log_rq_size));
+
+	priv->params.rx_am_enabled = MLX5_CAP_GEN(mdev, cq_moderation);
+	mlx5e_set_rx_cq_mode_params(&priv->params, cq_period_mode);
+
+	priv->params.tx_max_inline         = mlx5e_get_max_inline_cap(mdev);
+	priv->params.num_tc                = 1;
+
+	priv->params.lro_wqe_sz            =
+		MLX5E_PARAMS_DEFAULT_LRO_WQE_SZ;
+
+	priv->mdev                         = mdev;
+	priv->netdev                       = netdev;
+	priv->params.num_channels          = profile->max_nch(mdev);
+	priv->profile                      = profile;
+	priv->ppriv                        = ppriv;
+
+	mutex_init(&priv->state_lock);
+
+	INIT_DELAYED_WORK(&priv->update_stats_work, mlx5e_update_stats_work);
+}
+
+static void mlx5e_build_rep_netdev(struct net_device *netdev)
+{
+	netdev->netdev_ops = &mlx5e_netdev_ops_rep;
+
+	netdev->watchdog_timeo    = 15 * HZ;
+
+	netdev->ethtool_ops	  = &mlx5e_rep_ethtool_ops;
+
+#ifdef CONFIG_NET_SWITCHDEV
+	netdev->switchdev_ops = &mlx5e_rep_switchdev_ops;
+#endif
+
+	netdev->features	 |= NETIF_F_VLAN_CHALLENGED;
+
+	eth_hw_addr_random(netdev);
+}
+
+static void mlx5e_init_rep(struct mlx5_core_dev *mdev,
+			   struct net_device *netdev,
+			   const struct mlx5e_profile *profile,
+			   void *ppriv)
+{
+	mlx5e_build_rep_netdev_priv(mdev, netdev, profile, ppriv);
+	mlx5e_build_rep_netdev(netdev);
+}
+
+static int mlx5e_init_rep_rx(struct mlx5e_priv *priv)
+{
+	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+	struct mlx5_eswitch_rep *rep = priv->ppriv;
+	struct mlx5_core_dev *mdev = priv->mdev;
+	struct mlx5_flow_rule *flow_rule;
+	int err;
+	int i;
+
+	err = mlx5e_create_direct_rqts(priv);
+	if (err) {
+		mlx5_core_warn(mdev, "create direct rqts failed, %d\n", err);
+		return err;
+	}
+
+	err = mlx5e_create_direct_tirs(priv);
+	if (err) {
+		mlx5_core_warn(mdev, "create direct tirs failed, %d\n", err);
+		goto err_destroy_direct_rqts;
+	}
+
+	flow_rule = mlx5_eswitch_create_vport_rx_rule(esw,
+						      rep->vport,
+						      priv->direct_tir[0].tirn);
+	if (IS_ERR(flow_rule)) {
+		err = PTR_ERR(flow_rule);
+		goto err_destroy_direct_tirs;
+	}
+	rep->vport_rx_rule = flow_rule;
+
+	return 0;
+
+err_destroy_direct_tirs:
+	mlx5e_destroy_direct_tirs(priv);
+err_destroy_direct_rqts:
+	for (i = 0; i < priv->params.num_channels; i++)
+		mlx5e_destroy_rqt(priv, &priv->direct_tir[i].rqt);
+	return err;
+}
+
+static void mlx5e_cleanup_rep_rx(struct mlx5e_priv *priv)
+{
+	struct mlx5_eswitch_rep *rep = priv->ppriv;
+	int i;
+
+	mlx5_del_flow_rule(rep->vport_rx_rule);
+	mlx5e_destroy_direct_tirs(priv);
+	for (i = 0; i < priv->params.num_channels; i++)
+		mlx5e_destroy_rqt(priv, &priv->direct_tir[i].rqt);
+}
+
+static int mlx5e_init_rep_tx(struct mlx5e_priv *priv)
+{
+	int err;
+
+	err = mlx5e_create_tises(priv);
+	if (err) {
+		mlx5_core_warn(priv->mdev, "create tises failed, %d\n", err);
+		return err;
+	}
+	return 0;
+}
+
+static int mlx5e_get_rep_max_num_channels(struct mlx5_core_dev *mdev)
+{
+#define	MLX5E_PORT_REPRESENTOR_NCH 1
+	return MLX5E_PORT_REPRESENTOR_NCH;
+}
+
+static struct mlx5e_profile mlx5e_rep_profile = {
+	.init			= mlx5e_init_rep,
+	.init_rx		= mlx5e_init_rep_rx,
+	.cleanup_rx		= mlx5e_cleanup_rep_rx,
+	.init_tx		= mlx5e_init_rep_tx,
+	.cleanup_tx		= mlx5e_cleanup_nic_tx,
+	.update_stats           = mlx5e_update_sw_rep_counters,
+	.max_nch		= mlx5e_get_rep_max_num_channels,
+	.max_tc			= 1,
+};
+
+int mlx5e_vport_rep_load(struct mlx5_eswitch *esw,
+			 struct mlx5_eswitch_rep *rep)
+{
+	rep->priv_data = mlx5e_create_netdev(esw->dev, &mlx5e_rep_profile, rep);
+	if (!rep->priv_data) {
+		pr_warn("Failed to create representor for vport %d\n",
+			rep->vport);
+		return -EINVAL;
+	}
+	return 0;
+}
+
+void mlx5e_vport_rep_unload(struct mlx5_eswitch *esw,
+			    struct mlx5_eswitch_rep *rep)
+{
+	struct mlx5e_priv *priv = rep->priv_data;
+
+	mlx5e_destroy_netdev(esw->dev, priv);
+}
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
