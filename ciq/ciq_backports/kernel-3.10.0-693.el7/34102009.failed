x86/mce/AMD: Log Deferred Errors using SMCA MCA_DE{STAT,ADDR} registers

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [x86] mce/amd: Log Deferred Errors using SMCA MCA_DE{STAT, ADDR} registers (David Arcari) [1389383]
Rebuild_FUZZ: 96.40%
commit-author Yazen Ghannam <Yazen.Ghannam@amd.com>
commit 34102009580a047c02b21f089f7fc7f65e605887
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/34102009.failed

Scalable MCA provides new registers for all banks for logging deferred
errors: MCA_DESTAT and MCA_DEADDR. Deferred errors are always logged to
these registers.

Update the AMD deferred error handler to use these registers, if
available.

	Signed-off-by: Yazen Ghannam <Yazen.Ghannam@amd.com>
[ Sanity-check __log_error() args, massage a bit. ]
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Cc: Andy Lutomirski <luto@amacapital.net>
	Cc: Aravind Gopalakrishnan <aravindksg.lkml@gmail.com>
	Cc: Borislav Petkov <bp@alien8.de>
	Cc: Brian Gerst <brgerst@gmail.com>
	Cc: Denys Vlasenko <dvlasenk@redhat.com>
	Cc: H. Peter Anvin <hpa@zytor.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Tony Luck <tony.luck@intel.com>
	Cc: linux-edac <linux-edac@vger.kernel.org>
Link: http://lkml.kernel.org/r/1462971509-3856-2-git-send-email-bp@alien8.de
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 34102009580a047c02b21f089f7fc7f65e605887)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/mce.h
#	arch/x86/kernel/cpu/mcheck/mce_amd.c
diff --cc arch/x86/include/asm/mce.h
index cb08d9d92582,8bf766ef0e18..000000000000
--- a/arch/x86/include/asm/mce.h
+++ b/arch/x86/include/asm/mce.h
@@@ -92,8 -104,24 +92,24 @@@
  #define MCE_LOG_SIGNATURE	"MACHINECHECK"
  
  /* AMD Scalable MCA */
 -#define MSR_AMD64_SMCA_MC0_CTL		0xc0002000
 -#define MSR_AMD64_SMCA_MC0_STATUS	0xc0002001
 -#define MSR_AMD64_SMCA_MC0_ADDR		0xc0002002
 -#define MSR_AMD64_SMCA_MC0_MISC0	0xc0002003
  #define MSR_AMD64_SMCA_MC0_CONFIG	0xc0002004
++<<<<<<< HEAD
 +#define MSR_AMD64_SMCA_MCx_CONFIG(x)	(MSR_AMD64_SMCA_MC0_CONFIG + 0x10*(x))
++=======
+ #define MSR_AMD64_SMCA_MC0_IPID		0xc0002005
+ #define MSR_AMD64_SMCA_MC0_DESTAT	0xc0002008
+ #define MSR_AMD64_SMCA_MC0_DEADDR	0xc0002009
+ #define MSR_AMD64_SMCA_MC0_MISC1	0xc000200a
+ #define MSR_AMD64_SMCA_MCx_CTL(x)	(MSR_AMD64_SMCA_MC0_CTL + 0x10*(x))
+ #define MSR_AMD64_SMCA_MCx_STATUS(x)	(MSR_AMD64_SMCA_MC0_STATUS + 0x10*(x))
+ #define MSR_AMD64_SMCA_MCx_ADDR(x)	(MSR_AMD64_SMCA_MC0_ADDR + 0x10*(x))
+ #define MSR_AMD64_SMCA_MCx_MISC(x)	(MSR_AMD64_SMCA_MC0_MISC0 + 0x10*(x))
+ #define MSR_AMD64_SMCA_MCx_CONFIG(x)	(MSR_AMD64_SMCA_MC0_CONFIG + 0x10*(x))
+ #define MSR_AMD64_SMCA_MCx_IPID(x)	(MSR_AMD64_SMCA_MC0_IPID + 0x10*(x))
+ #define MSR_AMD64_SMCA_MCx_DESTAT(x)	(MSR_AMD64_SMCA_MC0_DESTAT + 0x10*(x))
+ #define MSR_AMD64_SMCA_MCx_DEADDR(x)	(MSR_AMD64_SMCA_MC0_DEADDR + 0x10*(x))
+ #define MSR_AMD64_SMCA_MCx_MISCy(x, y)	((MSR_AMD64_SMCA_MC0_MISC1 + y) + (0x10*(x)))
++>>>>>>> 34102009580a (x86/mce/AMD: Log Deferred Errors using SMCA MCA_DE{STAT,ADDR} registers)
  
  /*
   * This structure contains all data related to the MCE log.  Also
diff --cc arch/x86/kernel/cpu/mcheck/mce_amd.c
index f6a10e3f36cb,d1b1e62f7cb9..000000000000
--- a/arch/x86/kernel/cpu/mcheck/mce_amd.c
+++ b/arch/x86/kernel/cpu/mcheck/mce_amd.c
@@@ -368,7 -438,15 +371,19 @@@ __log_error(unsigned int bank, bool def
  	struct mce m;
  	u64 status;
  
++<<<<<<< HEAD
 +	rdmsrl(MSR_IA32_MCx_STATUS(bank), status);
++=======
+ 	WARN_ON_ONCE(deferred_err && threshold_err);
+ 
+ 	if (deferred_err && mce_flags.smca) {
+ 		msr_status = MSR_AMD64_SMCA_MCx_DESTAT(bank);
+ 		msr_addr = MSR_AMD64_SMCA_MCx_DEADDR(bank);
+ 	}
+ 
+ 	rdmsrl(msr_status, status);
+ 
++>>>>>>> 34102009580a (x86/mce/AMD: Log Deferred Errors using SMCA MCA_DE{STAT,ADDR} registers)
  	if (!(status & MCI_STATUS_VAL))
  		return;
  
@@@ -381,10 -459,11 +396,18 @@@
  		m.misc = misc;
  
  	if (m.status & MCI_STATUS_ADDRV)
++<<<<<<< HEAD
 +		rdmsrl(MSR_IA32_MCx_ADDR(bank), m.addr);
 +
 +	mce_log(&m);
 +	wrmsrl(MSR_IA32_MCx_STATUS(bank), 0);
++=======
+ 		rdmsrl(msr_addr, m.addr);
+ 
+ 	mce_log(&m);
+ 
+ 	wrmsrl(msr_status, 0);
++>>>>>>> 34102009580a (x86/mce/AMD: Log Deferred Errors using SMCA MCA_DE{STAT,ADDR} registers)
  }
  
  static inline void __smp_deferred_error_interrupt(void)
@@@ -412,11 -491,15 +435,19 @@@ asmlinkage __visible void smp_trace_def
  /* APIC interrupt handler for deferred errors */
  static void amd_deferred_error_interrupt(void)
  {
- 	u64 status;
  	unsigned int bank;
+ 	u32 msr_status;
+ 	u64 status;
  
  	for (bank = 0; bank < mca_cfg.banks; ++bank) {
++<<<<<<< HEAD
 +		rdmsrl(MSR_IA32_MCx_STATUS(bank), status);
++=======
+ 		msr_status = (mce_flags.smca) ? MSR_AMD64_SMCA_MCx_DESTAT(bank)
+ 					      : msr_ops.status(bank);
+ 
+ 		rdmsrl(msr_status, status);
++>>>>>>> 34102009580a (x86/mce/AMD: Log Deferred Errors using SMCA MCA_DE{STAT,ADDR} registers)
  
  		if (!(status & MCI_STATUS_VAL) ||
  		    !(status & MCI_STATUS_DEFERRED))
* Unmerged path arch/x86/include/asm/mce.h
* Unmerged path arch/x86/kernel/cpu/mcheck/mce_amd.c
