net: sched: restrict use of qstats qlen

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [net] sched: restrict use of qstats qlen (Ivan Vecera) [1428588]
Rebuild_FUZZ: 93.15%
commit-author John Fastabend <john.fastabend@gmail.com>
commit 6401585366326fc0ecbc372ec60d1a15cd8be2f5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/64015853.failed

This removes the use of qstats->qlen variable from the classifiers
and makes it an explicit argument to gnet_stats_copy_queue().

The qlen represents the qdisc queue length and is packed into
the qstats at the last moment before passnig to user space. By
handling it explicitely we avoid, in the percpu stats case, having
to figure out which per_cpu variable to put it in.

It would probably be best to remove it from qstats completely
but qstats is a user space ABI and can't be broken. A future
patch could make an internal only qstats structure that would
avoid having to allocate an additional u32 variable on the
Qdisc struct. This would make the qstats struct 128bits instead
of 128+32.

	Signed-off-by: John Fastabend <john.r.fastabend@intel.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 6401585366326fc0ecbc372ec60d1a15cd8be2f5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sched/sch_atm.c
#	net/sched/sch_mq.c
#	net/sched/sch_mqprio.c
#	net/sched/sch_multiq.c
#	net/sched/sch_prio.c
diff --cc net/sched/sch_atm.c
index a5c6ce48ef31,c145eb6279cc..000000000000
--- a/net/sched/sch_atm.c
+++ b/net/sched/sch_atm.c
@@@ -635,10 -637,8 +635,15 @@@ atm_tc_dump_class_stats(struct Qdisc *s
  {
  	struct atm_flow_data *flow = (struct atm_flow_data *)arg;
  
++<<<<<<< HEAD
 +	flow->qstats.qlen = flow->q->q.qlen;
 +
 +	if (gnet_stats_copy_basic(d, &flow->bstats) < 0 ||
 +	    gnet_stats_copy_queue(d, &flow->qstats) < 0)
++=======
+ 	if (gnet_stats_copy_basic(d, NULL, &flow->bstats) < 0 ||
+ 	    gnet_stats_copy_queue(d, &flow->qstats, flow->q->q.qlen) < 0)
++>>>>>>> 640158536632 (net: sched: restrict use of qstats qlen)
  		return -1;
  
  	return 0;
diff --cc net/sched/sch_mq.c
index a8b2864a696b,6416a6942062..000000000000
--- a/net/sched/sch_mq.c
+++ b/net/sched/sch_mq.c
@@@ -200,9 -199,8 +199,14 @@@ static int mq_dump_class_stats(struct Q
  	struct netdev_queue *dev_queue = mq_queue_get(sch, cl);
  
  	sch = dev_queue->qdisc_sleeping;
++<<<<<<< HEAD
 +	sch->qstats.qlen = sch->q.qlen;
 +	if (gnet_stats_copy_basic(d, &sch->bstats) < 0 ||
 +	    gnet_stats_copy_queue(d, &sch->qstats) < 0)
++=======
+ 	if (gnet_stats_copy_basic(d, NULL, &sch->bstats) < 0 ||
+ 	    gnet_stats_copy_queue(d, &sch->qstats, sch->q.qlen) < 0)
++>>>>>>> 640158536632 (net: sched: restrict use of qstats qlen)
  		return -1;
  	return 0;
  }
diff --cc net/sched/sch_mqprio.c
index 15d8c87be2b6,03dbeb5e8181..000000000000
--- a/net/sched/sch_mqprio.c
+++ b/net/sched/sch_mqprio.c
@@@ -368,16 -355,15 +368,26 @@@ static int mqprio_dump_class_stats(stru
  		}
  		/* Reclaim root sleeping lock before completing stats */
  		spin_lock_bh(d->lock);
++<<<<<<< HEAD
 +		if (gnet_stats_copy_basic(d, &bstats) < 0 ||
 +		    gnet_stats_copy_queue(d, &qstats) < 0)
++=======
+ 		if (gnet_stats_copy_basic(d, NULL, &bstats) < 0 ||
+ 		    gnet_stats_copy_queue(d, &qstats, qlen) < 0)
++>>>>>>> 640158536632 (net: sched: restrict use of qstats qlen)
  			return -1;
  	} else {
  		struct netdev_queue *dev_queue = mqprio_queue_get(sch, cl);
  
  		sch = dev_queue->qdisc_sleeping;
++<<<<<<< HEAD
 +		sch->qstats.qlen = sch->q.qlen;
 +		if (gnet_stats_copy_basic(d, &sch->bstats) < 0 ||
 +		    gnet_stats_copy_queue(d, &sch->qstats) < 0)
++=======
+ 		if (gnet_stats_copy_basic(d, NULL, &sch->bstats) < 0 ||
+ 		    gnet_stats_copy_queue(d, &sch->qstats, sch->q.qlen) < 0)
++>>>>>>> 640158536632 (net: sched: restrict use of qstats qlen)
  			return -1;
  	}
  	return 0;
diff --cc net/sched/sch_multiq.c
index c433de581b93,53357b368bff..000000000000
--- a/net/sched/sch_multiq.c
+++ b/net/sched/sch_multiq.c
@@@ -354,9 -360,8 +354,14 @@@ static int multiq_dump_class_stats(stru
  	struct Qdisc *cl_q;
  
  	cl_q = q->queues[cl - 1];
++<<<<<<< HEAD
 +	cl_q->qstats.qlen = cl_q->q.qlen;
 +	if (gnet_stats_copy_basic(d, &cl_q->bstats) < 0 ||
 +	    gnet_stats_copy_queue(d, &cl_q->qstats) < 0)
++=======
+ 	if (gnet_stats_copy_basic(d, NULL, &cl_q->bstats) < 0 ||
+ 	    gnet_stats_copy_queue(d, &cl_q->qstats, cl_q->q.qlen) < 0)
++>>>>>>> 640158536632 (net: sched: restrict use of qstats qlen)
  		return -1;
  
  	return 0;
diff --cc net/sched/sch_prio.c
index 0b904a19248a,4644f55242d2..000000000000
--- a/net/sched/sch_prio.c
+++ b/net/sched/sch_prio.c
@@@ -320,9 -324,8 +320,14 @@@ static int prio_dump_class_stats(struc
  	struct Qdisc *cl_q;
  
  	cl_q = q->queues[cl - 1];
++<<<<<<< HEAD
 +	cl_q->qstats.qlen = cl_q->q.qlen;
 +	if (gnet_stats_copy_basic(d, &cl_q->bstats) < 0 ||
 +	    gnet_stats_copy_queue(d, &cl_q->qstats) < 0)
++=======
+ 	if (gnet_stats_copy_basic(d, NULL, &cl_q->bstats) < 0 ||
+ 	    gnet_stats_copy_queue(d, &cl_q->qstats, cl_q->q.qlen) < 0)
++>>>>>>> 640158536632 (net: sched: restrict use of qstats qlen)
  		return -1;
  
  	return 0;
diff --git a/include/net/gen_stats.h b/include/net/gen_stats.h
index ea4271dceff0..f308f799d40a 100644
--- a/include/net/gen_stats.h
+++ b/include/net/gen_stats.h
@@ -31,7 +31,8 @@ int gnet_stats_copy_basic(struct gnet_dump *d,
 int gnet_stats_copy_rate_est(struct gnet_dump *d,
 			     const struct gnet_stats_basic_packed *b,
 			     struct gnet_stats_rate_est64 *r);
-int gnet_stats_copy_queue(struct gnet_dump *d, struct gnet_stats_queue *q);
+int gnet_stats_copy_queue(struct gnet_dump *d,
+			  struct gnet_stats_queue *q, __u32 len);
 int gnet_stats_copy_app(struct gnet_dump *d, void *st, int len);
 
 int gnet_stats_finish_copy(struct gnet_dump *d);
diff --git a/net/core/gen_stats.c b/net/core/gen_stats.c
index 9d3d9e78397b..0ed83167a0d3 100644
--- a/net/core/gen_stats.c
+++ b/net/core/gen_stats.c
@@ -176,6 +176,7 @@ EXPORT_SYMBOL(gnet_stats_copy_rate_est);
  * gnet_stats_copy_queue - copy queue statistics into statistics TLV
  * @d: dumping handle
  * @q: queue statistics
+ * @qlen: queue length statistics
  *
  * Appends the queue statistics to the top level TLV created by
  * gnet_stats_start_copy().
@@ -184,8 +185,11 @@ EXPORT_SYMBOL(gnet_stats_copy_rate_est);
  * if the room in the socket buffer was not sufficient.
  */
 int
-gnet_stats_copy_queue(struct gnet_dump *d, struct gnet_stats_queue *q)
+gnet_stats_copy_queue(struct gnet_dump *d,
+		      struct gnet_stats_queue *q, __u32 qlen)
 {
+	q->qlen = qlen;
+
 	if (d->compat_tc_stats) {
 		d->tc_stats.drops = q->drops;
 		d->tc_stats.qlen = q->qlen;
diff --git a/net/sched/act_api.c b/net/sched/act_api.c
index 71f2bdf1efd8..ea150dd0938a 100644
--- a/net/sched/act_api.c
+++ b/net/sched/act_api.c
@@ -588,7 +588,9 @@ int tcf_action_copy_stats(struct sk_buff *skb, struct tc_action *a,
 	if (gnet_stats_copy_basic(&d, &p->tcfc_bstats) < 0 ||
 	    gnet_stats_copy_rate_est(&d, &p->tcfc_bstats,
 				     &p->tcfc_rate_est) < 0 ||
-	    gnet_stats_copy_queue(&d, &p->tcfc_qstats) < 0)
+	    gnet_stats_copy_queue(&d,
+				  &p->tcfc_qstats,
+				  p->tcfc_qstats.qlen) < 0)
 		goto errout;
 
 	if (gnet_stats_finish_copy(&d) < 0)
diff --git a/net/sched/sch_api.c b/net/sched/sch_api.c
index 41f2533fbfbd..e8123cb204cd 100644
--- a/net/sched/sch_api.c
+++ b/net/sched/sch_api.c
@@ -1306,6 +1306,7 @@ static int tc_fill_qdisc(struct sk_buff *skb, struct Qdisc *q, u32 clid,
 	unsigned char *b = skb_tail_pointer(skb);
 	struct gnet_dump d;
 	struct qdisc_size_table *stab;
+	__u32 qlen;
 
 	cond_resched();
 	nlh = nlmsg_put(skb, portid, seq, event, sizeof(*tcm), flags);
@@ -1323,7 +1324,7 @@ static int tc_fill_qdisc(struct sk_buff *skb, struct Qdisc *q, u32 clid,
 		goto nla_put_failure;
 	if (q->ops->dump && q->ops->dump(q, skb) < 0)
 		goto nla_put_failure;
-	q->qstats.qlen = q->q.qlen;
+	qlen = q->q.qlen;
 
 	stab = rtnl_dereference(q->stab);
 	if (stab && qdisc_dump_stab(skb, stab) < 0)
@@ -1338,7 +1339,7 @@ static int tc_fill_qdisc(struct sk_buff *skb, struct Qdisc *q, u32 clid,
 
 	if (gnet_stats_copy_basic(&d, &q->bstats) < 0 ||
 	    gnet_stats_copy_rate_est(&d, &q->bstats, &q->rate_est) < 0 ||
-	    gnet_stats_copy_queue(&d, &q->qstats) < 0)
+	    gnet_stats_copy_queue(&d, &q->qstats, qlen) < 0)
 		goto nla_put_failure;
 
 	if (gnet_stats_finish_copy(&d) < 0)
* Unmerged path net/sched/sch_atm.c
diff --git a/net/sched/sch_cbq.c b/net/sched/sch_cbq.c
index 3389351a8374..de7733a15a03 100644
--- a/net/sched/sch_cbq.c
+++ b/net/sched/sch_cbq.c
@@ -1611,7 +1611,6 @@ cbq_dump_class_stats(struct Qdisc *sch, unsigned long arg,
 	struct cbq_sched_data *q = qdisc_priv(sch);
 	struct cbq_class *cl = (struct cbq_class *)arg;
 
-	cl->qstats.qlen = cl->q->q.qlen;
 	cl->xstats.avgidle = cl->avgidle;
 	cl->xstats.undertime = 0;
 
@@ -1620,7 +1619,7 @@ cbq_dump_class_stats(struct Qdisc *sch, unsigned long arg,
 
 	if (gnet_stats_copy_basic(d, &cl->bstats) < 0 ||
 	    gnet_stats_copy_rate_est(d, &cl->bstats, &cl->rate_est) < 0 ||
-	    gnet_stats_copy_queue(d, &cl->qstats) < 0)
+	    gnet_stats_copy_queue(d, &cl->qstats, cl->q->q.qlen) < 0)
 		return -1;
 
 	return gnet_stats_copy_app(d, &cl->xstats, sizeof(cl->xstats));
diff --git a/net/sched/sch_drr.c b/net/sched/sch_drr.c
index 4c26ee692ff8..76a36e59a27f 100644
--- a/net/sched/sch_drr.c
+++ b/net/sched/sch_drr.c
@@ -269,17 +269,16 @@ static int drr_dump_class_stats(struct Qdisc *sch, unsigned long arg,
 				struct gnet_dump *d)
 {
 	struct drr_class *cl = (struct drr_class *)arg;
+	__u32 qlen = cl->qdisc->q.qlen;
 	struct tc_drr_stats xstats;
 
 	memset(&xstats, 0, sizeof(xstats));
-	if (cl->qdisc->q.qlen) {
+	if (qlen)
 		xstats.deficit = cl->deficit;
-		cl->qdisc->qstats.qlen = cl->qdisc->q.qlen;
-	}
 
 	if (gnet_stats_copy_basic(d, &cl->bstats) < 0 ||
 	    gnet_stats_copy_rate_est(d, &cl->bstats, &cl->rate_est) < 0 ||
-	    gnet_stats_copy_queue(d, &cl->qdisc->qstats) < 0)
+	    gnet_stats_copy_queue(d, &cl->qdisc->qstats, qlen) < 0)
 		return -1;
 
 	return gnet_stats_copy_app(d, &xstats, sizeof(xstats));
diff --git a/net/sched/sch_fq_codel.c b/net/sched/sch_fq_codel.c
index 325552fe3cde..4b0a77d5637f 100644
--- a/net/sched/sch_fq_codel.c
+++ b/net/sched/sch_fq_codel.c
@@ -579,7 +579,7 @@ static int fq_codel_dump_class_stats(struct Qdisc *sch, unsigned long cl,
 		qs.backlog = q->backlogs[idx];
 		qs.drops = flow->dropped;
 	}
-	if (gnet_stats_copy_queue(d, &qs) < 0)
+	if (gnet_stats_copy_queue(d, &qs, 0) < 0)
 		return -1;
 	if (idx < q->flows_cnt)
 		return gnet_stats_copy_app(d, &xstats, sizeof(xstats));
diff --git a/net/sched/sch_hfsc.c b/net/sched/sch_hfsc.c
index 747f88e3d5d1..cb6ef2af7c81 100644
--- a/net/sched/sch_hfsc.c
+++ b/net/sched/sch_hfsc.c
@@ -1363,7 +1363,6 @@ hfsc_dump_class_stats(struct Qdisc *sch, unsigned long arg,
 	struct hfsc_class *cl = (struct hfsc_class *)arg;
 	struct tc_hfsc_stats xstats;
 
-	cl->qstats.qlen = cl->qdisc->q.qlen;
 	cl->qstats.backlog = cl->qdisc->qstats.backlog;
 	xstats.level   = cl->level;
 	xstats.period  = cl->cl_vtperiod;
@@ -1372,7 +1371,7 @@ hfsc_dump_class_stats(struct Qdisc *sch, unsigned long arg,
 
 	if (gnet_stats_copy_basic(d, &cl->bstats) < 0 ||
 	    gnet_stats_copy_rate_est(d, &cl->bstats, &cl->rate_est) < 0 ||
-	    gnet_stats_copy_queue(d, &cl->qstats) < 0)
+	    gnet_stats_copy_queue(d, &cl->qstats, cl->qdisc->q.qlen) < 0)
 		return -1;
 
 	return gnet_stats_copy_app(d, &xstats, sizeof(xstats));
diff --git a/net/sched/sch_htb.c b/net/sched/sch_htb.c
index 38195029b441..504489f22dcc 100644
--- a/net/sched/sch_htb.c
+++ b/net/sched/sch_htb.c
@@ -1141,15 +1141,16 @@ static int
 htb_dump_class_stats(struct Qdisc *sch, unsigned long arg, struct gnet_dump *d)
 {
 	struct htb_class *cl = (struct htb_class *)arg;
+	__u32 qlen = 0;
 
 	if (!cl->level && cl->un.leaf.q)
-		cl->qstats.qlen = cl->un.leaf.q->q.qlen;
+		qlen = cl->un.leaf.q->q.qlen;
 	cl->xstats.tokens = PSCHED_NS2TICKS(cl->tokens);
 	cl->xstats.ctokens = PSCHED_NS2TICKS(cl->ctokens);
 
 	if (gnet_stats_copy_basic(d, &cl->bstats) < 0 ||
 	    gnet_stats_copy_rate_est(d, NULL, &cl->rate_est) < 0 ||
-	    gnet_stats_copy_queue(d, &cl->qstats) < 0)
+	    gnet_stats_copy_queue(d, &cl->qstats, qlen) < 0)
 		return -1;
 
 	return gnet_stats_copy_app(d, &cl->xstats, sizeof(cl->xstats));
* Unmerged path net/sched/sch_mq.c
* Unmerged path net/sched/sch_mqprio.c
* Unmerged path net/sched/sch_multiq.c
* Unmerged path net/sched/sch_prio.c
diff --git a/net/sched/sch_qfq.c b/net/sched/sch_qfq.c
index 2b0a5cfb2004..9ad1bf87d4cb 100644
--- a/net/sched/sch_qfq.c
+++ b/net/sched/sch_qfq.c
@@ -657,14 +657,13 @@ static int qfq_dump_class_stats(struct Qdisc *sch, unsigned long arg,
 	struct tc_qfq_stats xstats;
 
 	memset(&xstats, 0, sizeof(xstats));
-	cl->qdisc->qstats.qlen = cl->qdisc->q.qlen;
 
 	xstats.weight = cl->agg->class_weight;
 	xstats.lmax = cl->agg->lmax;
 
 	if (gnet_stats_copy_basic(d, &cl->bstats) < 0 ||
 	    gnet_stats_copy_rate_est(d, &cl->bstats, &cl->rate_est) < 0 ||
-	    gnet_stats_copy_queue(d, &cl->qdisc->qstats) < 0)
+	    gnet_stats_copy_queue(d, &cl->qdisc->qstats, cl->qdisc->q.qlen) < 0)
 		return -1;
 
 	return gnet_stats_copy_app(d, &xstats, sizeof(xstats));
diff --git a/net/sched/sch_sfq.c b/net/sched/sch_sfq.c
index 26d6814c8b15..d5489bfb91c1 100644
--- a/net/sched/sch_sfq.c
+++ b/net/sched/sch_sfq.c
@@ -876,7 +876,7 @@ static int sfq_dump_class_stats(struct Qdisc *sch, unsigned long cl,
 		qs.qlen = slot->qlen;
 		qs.backlog = slot->backlog;
 	}
-	if (gnet_stats_copy_queue(d, &qs) < 0)
+	if (gnet_stats_copy_queue(d, &qs, qs.qlen) < 0)
 		return -1;
 	return gnet_stats_copy_app(d, &xstats, sizeof(xstats));
 }
