net/socket: factor out helpers for memory and queue manipulation

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [net] sock: factor out helpers for memory and queue manipulation (Paolo Abeni) [1388467]
Rebuild_FUZZ: 95.08%
commit-author Paolo Abeni <pabeni@redhat.com>
commit f8c3bf00d440df2bc2c3f669d460868d9ba67226
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/f8c3bf00.failed

Basic sock operations that udp code can use with its own
memory accounting schema. No functional change is introduced
in the existing APIs.

v4 -> v5:
  - avoid whitespace changes

v2 -> v4:
  - avoid exporting __sock_enqueue_skb

v1 -> v2:
  - avoid export sock_rmem_free

	Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
	Signed-off-by: Paolo Abeni <pabeni@redhat.com>
	Acked-by: Eric Dumazet <edumazet@google.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit f8c3bf00d440df2bc2c3f669d460868d9ba67226)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/sock.h
#	net/core/sock.c
diff --cc include/net/sock.h
index 58c7b9c999a7,276489553338..000000000000
--- a/include/net/sock.h
+++ b/include/net/sock.h
@@@ -1432,7 -1274,9 +1432,13 @@@ static inline struct inode *SOCK_INODE(
  /*
   * Functions for memory accounting
   */
++<<<<<<< HEAD
 +extern int __sk_mem_schedule(struct sock *sk, int size, int kind);
++=======
+ int __sk_mem_raise_allocated(struct sock *sk, int size, int amt, int kind);
+ int __sk_mem_schedule(struct sock *sk, int size, int kind);
+ void __sk_mem_reduce_allocated(struct sock *sk, int amount);
++>>>>>>> f8c3bf00d440 (net/socket: factor out helpers for memory and queue manipulation)
  void __sk_mem_reclaim(struct sock *sk, int amount);
  
  #define SK_MEM_QUANTUM ((int)PAGE_SIZE)
@@@ -2114,14 -1947,18 +2120,21 @@@ static inline void skb_set_owner_r(stru
  	sk_mem_charge(sk, skb->truesize);
  }
  
 -void sk_reset_timer(struct sock *sk, struct timer_list *timer,
 -		    unsigned long expires);
 +extern void sk_reset_timer(struct sock *sk, struct timer_list *timer,
 +			   unsigned long expires);
  
 -void sk_stop_timer(struct sock *sk, struct timer_list *timer);
 +extern void sk_stop_timer(struct sock *sk, struct timer_list *timer);
  
++<<<<<<< HEAD
 +extern int sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb);
++=======
+ int __sk_queue_drop_skb(struct sock *sk, struct sk_buff *skb,
+ 			unsigned int flags);
+ int __sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb);
+ int sock_queue_rcv_skb(struct sock *sk, struct sk_buff *skb);
++>>>>>>> f8c3bf00d440 (net/socket: factor out helpers for memory and queue manipulation)
  
 -int sock_queue_err_skb(struct sock *sk, struct sk_buff *skb);
 -struct sk_buff *sock_dequeue_err_skb(struct sock *sk);
 +extern int sock_queue_err_skb(struct sock *sk, struct sk_buff *skb);
  
  /*
   *	Recover an error report and clear atomically
diff --cc net/core/sock.c
index 960b698f3aa7,d8e4532e89e7..000000000000
--- a/net/core/sock.c
+++ b/net/core/sock.c
@@@ -2002,29 -2091,25 +2002,36 @@@ int sk_wait_data(struct sock *sk, long 
  EXPORT_SYMBOL(sk_wait_data);
  
  /**
-  *	__sk_mem_schedule - increase sk_forward_alloc and memory_allocated
+  *	__sk_mem_raise_allocated - increase memory_allocated
   *	@sk: socket
   *	@size: memory size to allocate
+  *	@amt: pages to allocate
   *	@kind: allocation type
   *
-  *	If kind is SK_MEM_SEND, it means wmem allocation. Otherwise it means
-  *	rmem allocation. This function assumes that protocols which have
-  *	memory_pressure use sk_wmem_queued as write buffer accounting.
+  *	Similar to __sk_mem_schedule(), but does not update sk_forward_alloc
   */
- int __sk_mem_schedule(struct sock *sk, int size, int kind)
+ int __sk_mem_raise_allocated(struct sock *sk, int size, int amt, int kind)
  {
  	struct proto *prot = sk->sk_prot;
++<<<<<<< HEAD
 +	int amt = sk_mem_pages(size);
 +	long allocated;
 +	int parent_status = UNDER_LIMIT;
 +
 +	sk->sk_forward_alloc += amt * SK_MEM_QUANTUM;
 +
 +	allocated = sk_memory_allocated_add(sk, amt, &parent_status);
++=======
+ 	long allocated = sk_memory_allocated_add(sk, amt);
+ 
+ 	if (mem_cgroup_sockets_enabled && sk->sk_memcg &&
+ 	    !mem_cgroup_charge_skmem(sk->sk_memcg, amt))
+ 		goto suppress_allocation;
++>>>>>>> f8c3bf00d440 (net/socket: factor out helpers for memory and queue manipulation)
  
  	/* Under limit. */
 -	if (allocated <= sk_prot_mem_limits(sk, 0)) {
 +	if (parent_status == UNDER_LIMIT &&
 +			allocated <= sk_prot_mem_limits(sk, 0)) {
  		sk_leave_memory_pressure(sk);
  		return 1;
  	}
@@@ -2080,32 -2163,79 +2087,68 @@@ suppress_allocation
  
  	trace_sock_exceed_buf_limit(sk, prot, allocated);
  
- 	/* Alas. Undo changes. */
- 	sk->sk_forward_alloc -= amt * SK_MEM_QUANTUM;
- 
  	sk_memory_allocated_sub(sk, amt);
  
 -	if (mem_cgroup_sockets_enabled && sk->sk_memcg)
 -		mem_cgroup_uncharge_skmem(sk->sk_memcg, amt);
 -
  	return 0;
  }
+ EXPORT_SYMBOL(__sk_mem_raise_allocated);
+ 
+ /**
+  *	__sk_mem_schedule - increase sk_forward_alloc and memory_allocated
+  *	@sk: socket
+  *	@size: memory size to allocate
+  *	@kind: allocation type
+  *
+  *	If kind is SK_MEM_SEND, it means wmem allocation. Otherwise it means
+  *	rmem allocation. This function assumes that protocols which have
+  *	memory_pressure use sk_wmem_queued as write buffer accounting.
+  */
+ int __sk_mem_schedule(struct sock *sk, int size, int kind)
+ {
+ 	int ret, amt = sk_mem_pages(size);
+ 
+ 	sk->sk_forward_alloc += amt << SK_MEM_QUANTUM_SHIFT;
+ 	ret = __sk_mem_raise_allocated(sk, size, amt, kind);
+ 	if (!ret)
+ 		sk->sk_forward_alloc -= amt << SK_MEM_QUANTUM_SHIFT;
+ 	return ret;
+ }
  EXPORT_SYMBOL(__sk_mem_schedule);
  
  /**
++<<<<<<< HEAD
 + *	__sk_reclaim - reclaim memory_allocated
++=======
+  *	__sk_mem_reduce_allocated - reclaim memory_allocated
++>>>>>>> f8c3bf00d440 (net/socket: factor out helpers for memory and queue manipulation)
   *	@sk: socket
-  *	@amount: number of bytes (rounded down to a SK_MEM_QUANTUM multiple)
+  *	@amount: number of quanta
+  *
+  *	Similar to __sk_mem_reclaim(), but does not update sk_forward_alloc
   */
- void __sk_mem_reclaim(struct sock *sk, int amount)
+ void __sk_mem_reduce_allocated(struct sock *sk, int amount)
  {
- 	amount >>= SK_MEM_QUANTUM_SHIFT;
  	sk_memory_allocated_sub(sk, amount);
- 	sk->sk_forward_alloc -= amount << SK_MEM_QUANTUM_SHIFT;
  
 -	if (mem_cgroup_sockets_enabled && sk->sk_memcg)
 -		mem_cgroup_uncharge_skmem(sk->sk_memcg, amount);
 -
  	if (sk_under_memory_pressure(sk) &&
  	    (sk_memory_allocated(sk) < sk_prot_mem_limits(sk, 0)))
  		sk_leave_memory_pressure(sk);
  }
+ EXPORT_SYMBOL(__sk_mem_reduce_allocated);
+ 
+ /**
+  *	__sk_mem_reclaim - reclaim sk_forward_alloc and memory_allocated
+  *	@sk: socket
+  *	@amount: number of bytes (rounded down to a SK_MEM_QUANTUM multiple)
+  */
+ void __sk_mem_reclaim(struct sock *sk, int amount)
+ {
+ 	amount >>= SK_MEM_QUANTUM_SHIFT;
+ 	sk->sk_forward_alloc -= amount << SK_MEM_QUANTUM_SHIFT;
+ 	__sk_mem_reduce_allocated(sk, amount);
+ }
  EXPORT_SYMBOL(__sk_mem_reclaim);
  
 -int sk_set_peek_off(struct sock *sk, int val)
 -{
 -	if (val < 0)
 -		return -EINVAL;
 -
 -	sk->sk_peek_off = val;
 -	return 0;
 -}
 -EXPORT_SYMBOL_GPL(sk_set_peek_off);
  
  /*
   * Set of default routines for initialising struct proto_ops when
* Unmerged path include/net/sock.h
diff --git a/net/core/datagram.c b/net/core/datagram.c
index 4f0a43b26c79..62107caff018 100644
--- a/net/core/datagram.c
+++ b/net/core/datagram.c
@@ -318,6 +318,27 @@ void skb_free_datagram_locked(struct sock *sk, struct sk_buff *skb)
 }
 EXPORT_SYMBOL(skb_free_datagram_locked);
 
+int __sk_queue_drop_skb(struct sock *sk, struct sk_buff *skb,
+			unsigned int flags)
+{
+	int err = 0;
+
+	if (flags & MSG_PEEK) {
+		err = -ENOENT;
+		spin_lock_bh(&sk->sk_receive_queue.lock);
+		if (skb == skb_peek(&sk->sk_receive_queue)) {
+			__skb_unlink(skb, &sk->sk_receive_queue);
+			atomic_dec(&skb->users);
+			err = 0;
+		}
+		spin_unlock_bh(&sk->sk_receive_queue.lock);
+	}
+
+	atomic_inc(&sk->sk_drops);
+	return err;
+}
+EXPORT_SYMBOL(__sk_queue_drop_skb);
+
 /**
  *	skb_kill_datagram - Free a datagram skbuff forcibly
  *	@sk: socket
@@ -341,23 +362,10 @@ EXPORT_SYMBOL(skb_free_datagram_locked);
 
 int skb_kill_datagram(struct sock *sk, struct sk_buff *skb, unsigned int flags)
 {
-	int err = 0;
-
-	if (flags & MSG_PEEK) {
-		err = -ENOENT;
-		spin_lock_bh(&sk->sk_receive_queue.lock);
-		if (skb == skb_peek(&sk->sk_receive_queue)) {
-			__skb_unlink(skb, &sk->sk_receive_queue);
-			atomic_dec(&skb->users);
-			err = 0;
-		}
-		spin_unlock_bh(&sk->sk_receive_queue.lock);
-	}
+	int err = __sk_queue_drop_skb(sk, skb, flags);
 
 	kfree_skb(skb);
-	atomic_inc(&sk->sk_drops);
 	sk_mem_reclaim_partial(sk);
-
 	return err;
 }
 EXPORT_SYMBOL(skb_kill_datagram);
* Unmerged path net/core/sock.c
