Btrfs: add a flags field to btrfs_fs_info

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Josef Bacik <jbacik@fb.com>
commit afcdd129e05a9210a5d19d4aa6e0afa475fc49e2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/afcdd129.failed

We have a lot of random ints in btrfs_fs_info that can be put into flags.  This
is mostly equivalent with the exception of how we deal with quota going on or
off, now instead we set a flag when we are turning it on or off and deal with
that appropriately, rather than just having a pending state that the current
quota_enabled gets set to.  Thanks,

	Signed-off-by: Josef Bacik <jbacik@fb.com>
	Signed-off-by: David Sterba <dsterba@suse.com>
(cherry picked from commit afcdd129e05a9210a5d19d4aa6e0afa475fc49e2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/btrfs/ctree.h
#	fs/btrfs/extent-tree.c
#	fs/btrfs/free-space-tree.c
#	fs/btrfs/qgroup.c
diff --cc fs/btrfs/ctree.h
index 48f38b765f55,2b7041ed4cb8..000000000000
--- a/fs/btrfs/ctree.h
+++ b/fs/btrfs/ctree.h
@@@ -1046,6 -1080,9 +1046,12 @@@ struct btrfs_fs_info 
  	 * and will be latter freed. Protected by fs_info->chunk_mutex.
  	 */
  	struct list_head pinned_chunks;
++<<<<<<< HEAD
++=======
+ 
+ 	/* Used to record internally whether fs has been frozen */
+ 	int fs_frozen;
++>>>>>>> afcdd129e05a (Btrfs: add a flags field to btrfs_fs_info)
  };
  
  struct btrfs_subvolume_writers {
diff --cc fs/btrfs/extent-tree.c
index 074941dda16d,3e360132a2b7..000000000000
--- a/fs/btrfs/extent-tree.c
+++ b/fs/btrfs/extent-tree.c
@@@ -2928,6 -2940,9 +2928,12 @@@ int btrfs_run_delayed_refs(struct btrfs
  	if (trans->aborted)
  		return 0;
  
++<<<<<<< HEAD
++=======
+ 	if (test_bit(BTRFS_FS_CREATING_FREE_SPACE_TREE, &root->fs_info->flags))
+ 		return 0;
+ 
++>>>>>>> afcdd129e05a (Btrfs: add a flags field to btrfs_fs_info)
  	if (root == root->fs_info->extent_root)
  		root = root->fs_info->tree_root;
  
@@@ -4919,6 -5030,203 +4925,206 @@@ void btrfs_init_async_reclaim_work(stru
  	INIT_WORK(work, btrfs_async_reclaim_metadata_space);
  }
  
++<<<<<<< HEAD
++=======
+ static void priority_reclaim_metadata_space(struct btrfs_fs_info *fs_info,
+ 					    struct btrfs_space_info *space_info,
+ 					    struct reserve_ticket *ticket)
+ {
+ 	u64 to_reclaim;
+ 	int flush_state = FLUSH_DELAYED_ITEMS_NR;
+ 
+ 	spin_lock(&space_info->lock);
+ 	to_reclaim = btrfs_calc_reclaim_metadata_size(fs_info->fs_root,
+ 						      space_info);
+ 	if (!to_reclaim) {
+ 		spin_unlock(&space_info->lock);
+ 		return;
+ 	}
+ 	spin_unlock(&space_info->lock);
+ 
+ 	do {
+ 		flush_space(fs_info->fs_root, space_info, to_reclaim,
+ 			    to_reclaim, flush_state);
+ 		flush_state++;
+ 		spin_lock(&space_info->lock);
+ 		if (ticket->bytes == 0) {
+ 			spin_unlock(&space_info->lock);
+ 			return;
+ 		}
+ 		spin_unlock(&space_info->lock);
+ 
+ 		/*
+ 		 * Priority flushers can't wait on delalloc without
+ 		 * deadlocking.
+ 		 */
+ 		if (flush_state == FLUSH_DELALLOC ||
+ 		    flush_state == FLUSH_DELALLOC_WAIT)
+ 			flush_state = ALLOC_CHUNK;
+ 	} while (flush_state < COMMIT_TRANS);
+ }
+ 
+ static int wait_reserve_ticket(struct btrfs_fs_info *fs_info,
+ 			       struct btrfs_space_info *space_info,
+ 			       struct reserve_ticket *ticket, u64 orig_bytes)
+ 
+ {
+ 	DEFINE_WAIT(wait);
+ 	int ret = 0;
+ 
+ 	spin_lock(&space_info->lock);
+ 	while (ticket->bytes > 0 && ticket->error == 0) {
+ 		ret = prepare_to_wait_event(&ticket->wait, &wait, TASK_KILLABLE);
+ 		if (ret) {
+ 			ret = -EINTR;
+ 			break;
+ 		}
+ 		spin_unlock(&space_info->lock);
+ 
+ 		schedule();
+ 
+ 		finish_wait(&ticket->wait, &wait);
+ 		spin_lock(&space_info->lock);
+ 	}
+ 	if (!ret)
+ 		ret = ticket->error;
+ 	if (!list_empty(&ticket->list))
+ 		list_del_init(&ticket->list);
+ 	if (ticket->bytes && ticket->bytes < orig_bytes) {
+ 		u64 num_bytes = orig_bytes - ticket->bytes;
+ 		space_info->bytes_may_use -= num_bytes;
+ 		trace_btrfs_space_reservation(fs_info, "space_info",
+ 					      space_info->flags, num_bytes, 0);
+ 	}
+ 	spin_unlock(&space_info->lock);
+ 
+ 	return ret;
+ }
+ 
+ /**
+  * reserve_metadata_bytes - try to reserve bytes from the block_rsv's space
+  * @root - the root we're allocating for
+  * @space_info - the space info we want to allocate from
+  * @orig_bytes - the number of bytes we want
+  * @flush - whether or not we can flush to make our reservation
+  *
+  * This will reserve orig_bytes number of bytes from the space info associated
+  * with the block_rsv.  If there is not enough space it will make an attempt to
+  * flush out space to make room.  It will do this by flushing delalloc if
+  * possible or committing the transaction.  If flush is 0 then no attempts to
+  * regain reservations will be made and this will fail if there is not enough
+  * space already.
+  */
+ static int __reserve_metadata_bytes(struct btrfs_root *root,
+ 				    struct btrfs_space_info *space_info,
+ 				    u64 orig_bytes,
+ 				    enum btrfs_reserve_flush_enum flush)
+ {
+ 	struct reserve_ticket ticket;
+ 	u64 used;
+ 	int ret = 0;
+ 
+ 	ASSERT(orig_bytes);
+ 	ASSERT(!current->journal_info || flush != BTRFS_RESERVE_FLUSH_ALL);
+ 
+ 	spin_lock(&space_info->lock);
+ 	ret = -ENOSPC;
+ 	used = space_info->bytes_used + space_info->bytes_reserved +
+ 		space_info->bytes_pinned + space_info->bytes_readonly +
+ 		space_info->bytes_may_use;
+ 
+ 	/*
+ 	 * If we have enough space then hooray, make our reservation and carry
+ 	 * on.  If not see if we can overcommit, and if we can, hooray carry on.
+ 	 * If not things get more complicated.
+ 	 */
+ 	if (used + orig_bytes <= space_info->total_bytes) {
+ 		space_info->bytes_may_use += orig_bytes;
+ 		trace_btrfs_space_reservation(root->fs_info, "space_info",
+ 					      space_info->flags, orig_bytes,
+ 					      1);
+ 		ret = 0;
+ 	} else if (can_overcommit(root, space_info, orig_bytes, flush)) {
+ 		space_info->bytes_may_use += orig_bytes;
+ 		trace_btrfs_space_reservation(root->fs_info, "space_info",
+ 					      space_info->flags, orig_bytes,
+ 					      1);
+ 		ret = 0;
+ 	}
+ 
+ 	/*
+ 	 * If we couldn't make a reservation then setup our reservation ticket
+ 	 * and kick the async worker if it's not already running.
+ 	 *
+ 	 * If we are a priority flusher then we just need to add our ticket to
+ 	 * the list and we will do our own flushing further down.
+ 	 */
+ 	if (ret && flush != BTRFS_RESERVE_NO_FLUSH) {
+ 		ticket.bytes = orig_bytes;
+ 		ticket.error = 0;
+ 		init_waitqueue_head(&ticket.wait);
+ 		if (flush == BTRFS_RESERVE_FLUSH_ALL) {
+ 			list_add_tail(&ticket.list, &space_info->tickets);
+ 			if (!space_info->flush) {
+ 				space_info->flush = 1;
+ 				trace_btrfs_trigger_flush(root->fs_info,
+ 							  space_info->flags,
+ 							  orig_bytes, flush,
+ 							  "enospc");
+ 				queue_work(system_unbound_wq,
+ 					   &root->fs_info->async_reclaim_work);
+ 			}
+ 		} else {
+ 			list_add_tail(&ticket.list,
+ 				      &space_info->priority_tickets);
+ 		}
+ 	} else if (!ret && space_info->flags & BTRFS_BLOCK_GROUP_METADATA) {
+ 		used += orig_bytes;
+ 		/*
+ 		 * We will do the space reservation dance during log replay,
+ 		 * which means we won't have fs_info->fs_root set, so don't do
+ 		 * the async reclaim as we will panic.
+ 		 */
+ 		if (!test_bit(BTRFS_FS_LOG_RECOVERING, &root->fs_info->flags) &&
+ 		    need_do_async_reclaim(space_info, root, used) &&
+ 		    !work_busy(&root->fs_info->async_reclaim_work)) {
+ 			trace_btrfs_trigger_flush(root->fs_info,
+ 						  space_info->flags,
+ 						  orig_bytes, flush,
+ 						  "preempt");
+ 			queue_work(system_unbound_wq,
+ 				   &root->fs_info->async_reclaim_work);
+ 		}
+ 	}
+ 	spin_unlock(&space_info->lock);
+ 	if (!ret || flush == BTRFS_RESERVE_NO_FLUSH)
+ 		return ret;
+ 
+ 	if (flush == BTRFS_RESERVE_FLUSH_ALL)
+ 		return wait_reserve_ticket(root->fs_info, space_info, &ticket,
+ 					   orig_bytes);
+ 
+ 	ret = 0;
+ 	priority_reclaim_metadata_space(root->fs_info, space_info, &ticket);
+ 	spin_lock(&space_info->lock);
+ 	if (ticket.bytes) {
+ 		if (ticket.bytes < orig_bytes) {
+ 			u64 num_bytes = orig_bytes - ticket.bytes;
+ 			space_info->bytes_may_use -= num_bytes;
+ 			trace_btrfs_space_reservation(root->fs_info,
+ 					"space_info", space_info->flags,
+ 					num_bytes, 0);
+ 
+ 		}
+ 		list_del_init(&ticket.list);
+ 		ret = -ENOSPC;
+ 	}
+ 	spin_unlock(&space_info->lock);
+ 	ASSERT(list_empty(&ticket.list));
+ 	return ret;
+ }
+ 
++>>>>>>> afcdd129e05a (Btrfs: add a flags field to btrfs_fs_info)
  /**
   * reserve_metadata_bytes - try to reserve bytes from the block_rsv's space
   * @root - the root we're allocating for
diff --cc fs/btrfs/free-space-tree.c
index 6da7e246ea6b,83ee63bdca96..000000000000
--- a/fs/btrfs/free-space-tree.c
+++ b/fs/btrfs/free-space-tree.c
@@@ -1159,6 -1163,7 +1159,10 @@@ int btrfs_create_free_space_tree(struc
  	if (IS_ERR(trans))
  		return PTR_ERR(trans);
  
++<<<<<<< HEAD
++=======
+ 	set_bit(BTRFS_FS_CREATING_FREE_SPACE_TREE, &fs_info->flags);
++>>>>>>> afcdd129e05a (Btrfs: add a flags field to btrfs_fs_info)
  	free_space_root = btrfs_create_tree(trans, fs_info,
  					    BTRFS_FREE_SPACE_TREE_OBJECTID);
  	if (IS_ERR(free_space_root)) {
@@@ -1178,6 -1183,7 +1182,10 @@@
  	}
  
  	btrfs_set_fs_compat_ro(fs_info, FREE_SPACE_TREE);
++<<<<<<< HEAD
++=======
+ 	clear_bit(BTRFS_FS_CREATING_FREE_SPACE_TREE, &fs_info->flags);
++>>>>>>> afcdd129e05a (Btrfs: add a flags field to btrfs_fs_info)
  
  	ret = btrfs_commit_transaction(trans, tree_root);
  	if (ret)
@@@ -1186,7 -1192,8 +1194,12 @@@
  	return 0;
  
  abort:
++<<<<<<< HEAD
 +	btrfs_abort_transaction(trans, tree_root, ret);
++=======
+ 	clear_bit(BTRFS_FS_CREATING_FREE_SPACE_TREE, &fs_info->flags);
+ 	btrfs_abort_transaction(trans, ret);
++>>>>>>> afcdd129e05a (Btrfs: add a flags field to btrfs_fs_info)
  	btrfs_end_transaction(trans, tree_root);
  	return ret;
  }
diff --cc fs/btrfs/qgroup.c
index 70c263934517,13c2dc79501b..000000000000
--- a/fs/btrfs/qgroup.c
+++ b/fs/btrfs/qgroup.c
@@@ -1479,7 -1477,38 +1477,42 @@@ struct btrfs_qgroup_extent_recor
  
  	rb_link_node(&record->node, parent_node, p);
  	rb_insert_color(&record->node, &delayed_refs->dirty_extent_root);
++<<<<<<< HEAD
 +	return NULL;
++=======
+ 	return 0;
+ }
+ 
+ int btrfs_qgroup_insert_dirty_extent(struct btrfs_trans_handle *trans,
+ 		struct btrfs_fs_info *fs_info, u64 bytenr, u64 num_bytes,
+ 		gfp_t gfp_flag)
+ {
+ 	struct btrfs_qgroup_extent_record *record;
+ 	struct btrfs_delayed_ref_root *delayed_refs;
+ 	int ret;
+ 
+ 	if (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags)
+ 	    || bytenr == 0 || num_bytes == 0)
+ 		return 0;
+ 	if (WARN_ON(trans == NULL))
+ 		return -EINVAL;
+ 	record = kmalloc(sizeof(*record), gfp_flag);
+ 	if (!record)
+ 		return -ENOMEM;
+ 
+ 	delayed_refs = &trans->transaction->delayed_refs;
+ 	record->bytenr = bytenr;
+ 	record->num_bytes = num_bytes;
+ 	record->old_roots = NULL;
+ 
+ 	spin_lock(&delayed_refs->lock);
+ 	ret = btrfs_qgroup_insert_dirty_extent_nolock(fs_info, delayed_refs,
+ 						      record);
+ 	spin_unlock(&delayed_refs->lock);
+ 	if (ret > 0)
+ 		kfree(record);
+ 	return 0;
++>>>>>>> afcdd129e05a (Btrfs: add a flags field to btrfs_fs_info)
  }
  
  #define UPDATE_NEW	0
diff --git a/fs/btrfs/btrfs_inode.h b/fs/btrfs/btrfs_inode.h
index eacde644fee6..a9563fac3050 100644
--- a/fs/btrfs/btrfs_inode.h
+++ b/fs/btrfs/btrfs_inode.h
@@ -44,17 +44,6 @@
 #define BTRFS_INODE_IN_DELALLOC_LIST		9
 #define BTRFS_INODE_READDIO_NEED_LOCK		10
 #define BTRFS_INODE_HAS_PROPS		        11
-/*
- * The following 3 bits are meant only for the btree inode.
- * When any of them is set, it means an error happened while writing an
- * extent buffer belonging to:
- * 1) a non-log btree
- * 2) a log btree and first log sub-transaction
- * 3) a log btree and second log sub-transaction
- */
-#define BTRFS_INODE_BTREE_ERR		        12
-#define BTRFS_INODE_BTREE_LOG1_ERR		13
-#define BTRFS_INODE_BTREE_LOG2_ERR		14
 
 /* in memory btrfs inode */
 struct btrfs_inode {
* Unmerged path fs/btrfs/ctree.h
diff --git a/fs/btrfs/delayed-inode.c b/fs/btrfs/delayed-inode.c
index be7759976c4d..5d8120572085 100644
--- a/fs/btrfs/delayed-inode.c
+++ b/fs/btrfs/delayed-inode.c
@@ -1858,7 +1858,8 @@ int btrfs_delayed_delete_inode_ref(struct inode *inode)
 	 * leads to enospc problems.  This means we also can't do
 	 * delayed inode refs
 	 */
-	if (BTRFS_I(inode)->root->fs_info->log_root_recovering)
+	if (test_bit(BTRFS_FS_LOG_RECOVERING,
+		     &BTRFS_I(inode)->root->fs_info->flags))
 		return -EAGAIN;
 
 	delayed_node = btrfs_get_or_create_delayed_node(inode);
diff --git a/fs/btrfs/delayed-ref.c b/fs/btrfs/delayed-ref.c
index 6c4a18010682..c5b22bb18c65 100644
--- a/fs/btrfs/delayed-ref.c
+++ b/fs/btrfs/delayed-ref.c
@@ -772,7 +772,8 @@ int btrfs_add_delayed_tree_ref(struct btrfs_fs_info *fs_info,
 	if (!head_ref)
 		goto free_ref;
 
-	if (fs_info->quota_enabled && is_fstree(ref_root)) {
+	if (test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags) &&
+	    is_fstree(ref_root)) {
 		record = kmalloc(sizeof(*record), GFP_NOFS);
 		if (!record)
 			goto free_head_ref;
@@ -830,7 +831,8 @@ int btrfs_add_delayed_data_ref(struct btrfs_fs_info *fs_info,
 		return -ENOMEM;
 	}
 
-	if (fs_info->quota_enabled && is_fstree(ref_root)) {
+	if (test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags) &&
+	    is_fstree(ref_root)) {
 		record = kmalloc(sizeof(*record), GFP_NOFS);
 		if (!record) {
 			kmem_cache_free(btrfs_delayed_data_ref_cachep, ref);
diff --git a/fs/btrfs/disk-io.c b/fs/btrfs/disk-io.c
index 7b22912f55ab..94bca3636344 100644
--- a/fs/btrfs/disk-io.c
+++ b/fs/btrfs/disk-io.c
@@ -1828,7 +1828,7 @@ static int cleaner_kthread(void *arg)
 		 * Do not do anything if we might cause open_ctree() to block
 		 * before we have finished mounting the filesystem.
 		 */
-		if (!root->fs_info->open)
+		if (!test_bit(BTRFS_FS_OPEN, &root->fs_info->flags))
 			goto sleep;
 
 		if (!mutex_trylock(&root->fs_info->cleaner_mutex))
@@ -2321,8 +2321,6 @@ static void btrfs_init_qgroup(struct btrfs_fs_info *fs_info)
 	fs_info->qgroup_op_tree = RB_ROOT;
 	INIT_LIST_HEAD(&fs_info->dirty_qgroups);
 	fs_info->qgroup_seq = 1;
-	fs_info->quota_enabled = 0;
-	fs_info->pending_quota_state = 0;
 	fs_info->qgroup_ulist = NULL;
 	fs_info->qgroup_rescan_running = false;
 	mutex_init(&fs_info->qgroup_rescan_lock);
@@ -2498,8 +2496,7 @@ static int btrfs_read_roots(struct btrfs_fs_info *fs_info,
 	root = btrfs_read_tree_root(tree_root, &location);
 	if (!IS_ERR(root)) {
 		set_bit(BTRFS_ROOT_TRACK_DIRTY, &root->state);
-		fs_info->quota_enabled = 1;
-		fs_info->pending_quota_state = 1;
+		set_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags);
 		fs_info->quota_root = root;
 	}
 
@@ -2680,8 +2677,7 @@ int open_ctree(struct super_block *sb,
 	extent_io_tree_init(&fs_info->freed_extents[1],
 			     fs_info->btree_inode->i_mapping);
 	fs_info->pinned_extents = &fs_info->freed_extents[0];
-	fs_info->do_barriers = 1;
-
+	set_bit(BTRFS_FS_BARRIER, &fs_info->flags);
 
 	mutex_init(&fs_info->ordered_operations_mutex);
 	mutex_init(&fs_info->tree_log_mutex);
@@ -3146,10 +3142,9 @@ retry_root_backup:
 			return ret;
 		}
 	} else {
-		fs_info->update_uuid_tree_gen = 1;
+		set_bit(BTRFS_FS_UPDATE_UUID_TREE_GEN, &fs_info->flags);
 	}
-
-	fs_info->open = 1;
+	set_bit(BTRFS_FS_OPEN, &fs_info->flags);
 
 	return 0;
 
@@ -3842,8 +3837,7 @@ void close_ctree(struct btrfs_root *root)
 	struct btrfs_fs_info *fs_info = root->fs_info;
 	int ret;
 
-	fs_info->closing = 1;
-	smp_mb();
+	set_bit(BTRFS_FS_CLOSING_START, &fs_info->flags);
 
 	/* wait for the qgroup rescan worker to stop */
 	btrfs_qgroup_wait_for_completion(fs_info, false);
@@ -3888,8 +3882,7 @@ void close_ctree(struct btrfs_root *root)
 	kthread_stop(fs_info->transaction_kthread);
 	kthread_stop(fs_info->cleaner_kthread);
 
-	fs_info->closing = 2;
-	smp_mb();
+	set_bit(BTRFS_FS_CLOSING_DONE, &fs_info->flags);
 
 	btrfs_free_qgroup_config(fs_info);
 
@@ -3914,7 +3907,7 @@ void close_ctree(struct btrfs_root *root)
 	invalidate_inode_pages2(fs_info->btree_inode->i_mapping);
 	btrfs_stop_all_workers(fs_info);
 
-	fs_info->open = 0;
+	clear_bit(BTRFS_FS_OPEN, &fs_info->flags);
 	free_root_pointers(fs_info, 1);
 
 	iput(fs_info->btree_inode);
* Unmerged path fs/btrfs/extent-tree.c
diff --git a/fs/btrfs/extent_io.c b/fs/btrfs/extent_io.c
index 07d85929b65a..856b2f2d1aaf 100644
--- a/fs/btrfs/extent_io.c
+++ b/fs/btrfs/extent_io.c
@@ -3649,7 +3649,6 @@ static void end_extent_buffer_writeback(struct extent_buffer *eb)
 static void set_btree_ioerr(struct page *page)
 {
 	struct extent_buffer *eb = (struct extent_buffer *)page->private;
-	struct btrfs_inode *btree_ino = BTRFS_I(eb->fs_info->btree_inode);
 
 	SetPageError(page);
 	if (test_and_set_bit(EXTENT_BUFFER_WRITE_ERR, &eb->bflags))
@@ -3695,13 +3694,13 @@ static void set_btree_ioerr(struct page *page)
 	 */
 	switch (eb->log_index) {
 	case -1:
-		set_bit(BTRFS_INODE_BTREE_ERR, &btree_ino->runtime_flags);
+		set_bit(BTRFS_FS_BTREE_ERR, &eb->fs_info->flags);
 		break;
 	case 0:
-		set_bit(BTRFS_INODE_BTREE_LOG1_ERR, &btree_ino->runtime_flags);
+		set_bit(BTRFS_FS_LOG1_ERR, &eb->fs_info->flags);
 		break;
 	case 1:
-		set_bit(BTRFS_INODE_BTREE_LOG2_ERR, &btree_ino->runtime_flags);
+		set_bit(BTRFS_FS_LOG2_ERR, &eb->fs_info->flags);
 		break;
 	default:
 		BUG(); /* unexpected, logic error */
* Unmerged path fs/btrfs/free-space-tree.c
diff --git a/fs/btrfs/inode.c b/fs/btrfs/inode.c
index 3fafb48a6ff7..d288f72a7b39 100644
--- a/fs/btrfs/inode.c
+++ b/fs/btrfs/inode.c
@@ -3910,7 +3910,7 @@ noinline int btrfs_update_inode(struct btrfs_trans_handle *trans,
 	 */
 	if (!btrfs_is_free_space_inode(inode)
 	    && root->root_key.objectid != BTRFS_DATA_RELOC_TREE_OBJECTID
-	    && !root->fs_info->log_root_recovering) {
+	    && !test_bit(BTRFS_FS_LOG_RECOVERING, &root->fs_info->flags)) {
 		btrfs_update_root_times(trans, root);
 
 		ret = btrfs_delayed_update_inode(trans, root, inode);
@@ -5195,7 +5195,7 @@ void btrfs_evict_inode(struct inode *inode)
 
 	btrfs_free_io_failure_record(inode, 0, (u64)-1);
 
-	if (root->fs_info->log_root_recovering) {
+	if (test_bit(BTRFS_FS_LOG_RECOVERING, &root->fs_info->flags)) {
 		BUG_ON(test_bit(BTRFS_INODE_HAS_ORPHAN_ITEM,
 				 &BTRFS_I(inode)->runtime_flags));
 		goto no_delete;
* Unmerged path fs/btrfs/qgroup.c
diff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c
index 3fd1af30f508..931a941fc2aa 100644
--- a/fs/btrfs/relocation.c
+++ b/fs/btrfs/relocation.c
@@ -3942,7 +3942,7 @@ static int qgroup_fix_relocated_data_extents(struct btrfs_trans_handle *trans,
 	struct btrfs_key key;
 	int ret = 0;
 
-	if (!fs_info->quota_enabled)
+	if (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags))
 		return 0;
 
 	/*
diff --git a/fs/btrfs/super.c b/fs/btrfs/super.c
index 92d06671fd90..7a5f96da282c 100644
--- a/fs/btrfs/super.c
+++ b/fs/btrfs/super.c
@@ -1768,7 +1768,7 @@ static int btrfs_remount(struct super_block *sb, int *flags, char *data)
 		}
 		sb->s_flags &= ~MS_RDONLY;
 
-		fs_info->open = 1;
+		set_bit(BTRFS_FS_OPEN, &fs_info->flags);
 	}
 out:
 	wake_up_process(fs_info->transaction_kthread);
diff --git a/fs/btrfs/tests/qgroup-tests.c b/fs/btrfs/tests/qgroup-tests.c
index 846d277b1901..54137240cb1b 100644
--- a/fs/btrfs/tests/qgroup-tests.c
+++ b/fs/btrfs/tests/qgroup-tests.c
@@ -470,7 +470,7 @@ int btrfs_test_qgroups(void)
 	 */
 	root->fs_info->tree_root = root;
 	root->fs_info->quota_root = root;
-	root->fs_info->quota_enabled = 1;
+	set_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags);
 
 	/*
 	 * Can't use bytenr 0, some things freak out
diff --git a/fs/btrfs/transaction.c b/fs/btrfs/transaction.c
index 8287524e73a2..d19fba697412 100644
--- a/fs/btrfs/transaction.c
+++ b/fs/btrfs/transaction.c
@@ -441,7 +441,7 @@ static void wait_current_trans(struct btrfs_root *root)
 
 static int may_wait_transaction(struct btrfs_root *root, int type)
 {
-	if (root->fs_info->log_root_recovering)
+	if (test_bit(BTRFS_FS_LOG_RECOVERING, &root->fs_info->flags))
 		return 0;
 
 	if (type == TRANS_USERSPACE)
@@ -992,7 +992,6 @@ int btrfs_wait_marked_extents(struct btrfs_root *root,
 	struct extent_state *cached_state = NULL;
 	u64 start = 0;
 	u64 end;
-	struct btrfs_inode *btree_ino = BTRFS_I(root->fs_info->btree_inode);
 	bool errors = false;
 
 	while (!find_first_extent_bit(dirty_pages, start, &start, &end,
@@ -1024,17 +1023,17 @@ int btrfs_wait_marked_extents(struct btrfs_root *root,
 
 	if (root->root_key.objectid == BTRFS_TREE_LOG_OBJECTID) {
 		if ((mark & EXTENT_DIRTY) &&
-		    test_and_clear_bit(BTRFS_INODE_BTREE_LOG1_ERR,
-				       &btree_ino->runtime_flags))
+		    test_and_clear_bit(BTRFS_FS_LOG1_ERR,
+				       &root->fs_info->flags))
 			errors = true;
 
 		if ((mark & EXTENT_NEW) &&
-		    test_and_clear_bit(BTRFS_INODE_BTREE_LOG2_ERR,
-				       &btree_ino->runtime_flags))
+		    test_and_clear_bit(BTRFS_FS_LOG2_ERR,
+				       &root->fs_info->flags))
 			errors = true;
 	} else {
-		if (test_and_clear_bit(BTRFS_INODE_BTREE_ERR,
-				       &btree_ino->runtime_flags))
+		if (test_and_clear_bit(BTRFS_FS_BTREE_ERR,
+				       &root->fs_info->flags))
 			errors = true;
 	}
 
@@ -1334,7 +1333,7 @@ static int qgroup_account_snapshot(struct btrfs_trans_handle *trans,
 	 * kick in anyway.
 	 */
 	mutex_lock(&fs_info->qgroup_ioctl_lock);
-	if (!fs_info->quota_enabled) {
+	if (!test_bit(BTRFS_FS_QUOTA_ENABLED, &fs_info->flags)) {
 		mutex_unlock(&fs_info->qgroup_ioctl_lock);
 		return 0;
 	}
@@ -1708,7 +1707,7 @@ static void update_super_roots(struct btrfs_root *root)
 	super->root_level = root_item->level;
 	if (btrfs_test_opt(root, SPACE_CACHE))
 		super->cache_generation = root_item->generation;
-	if (root->fs_info->update_uuid_tree_gen)
+	if (test_bit(BTRFS_FS_UPDATE_UUID_TREE_GEN, &root->fs_info->flags))
 		super->uuid_tree_generation = root_item->generation;
 }
 
@@ -1919,7 +1918,6 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
 {
 	struct btrfs_transaction *cur_trans = trans->transaction;
 	struct btrfs_transaction *prev_trans = NULL;
-	struct btrfs_inode *btree_ino = BTRFS_I(root->fs_info->btree_inode);
 	int ret;
 
 	/* Stop the commit early if ->aborted is set */
@@ -2213,8 +2211,8 @@ int btrfs_commit_transaction(struct btrfs_trans_handle *trans,
 	btrfs_update_commit_device_size(root->fs_info);
 	btrfs_update_commit_device_bytes_used(root, cur_trans);
 
-	clear_bit(BTRFS_INODE_BTREE_LOG1_ERR, &btree_ino->runtime_flags);
-	clear_bit(BTRFS_INODE_BTREE_LOG2_ERR, &btree_ino->runtime_flags);
+	clear_bit(BTRFS_FS_LOG1_ERR, &root->fs_info->flags);
+	clear_bit(BTRFS_FS_LOG2_ERR, &root->fs_info->flags);
 
 	btrfs_trans_release_chunk_metadata(trans);
 
diff --git a/fs/btrfs/tree-log.c b/fs/btrfs/tree-log.c
index e9ec22a26cf6..559dbe5d4440 100644
--- a/fs/btrfs/tree-log.c
+++ b/fs/btrfs/tree-log.c
@@ -5602,7 +5602,7 @@ int btrfs_recover_log_trees(struct btrfs_root *log_root_tree)
 	if (!path)
 		return -ENOMEM;
 
-	fs_info->log_root_recovering = 1;
+	set_bit(BTRFS_FS_LOG_RECOVERING, &fs_info->flags);
 
 	trans = btrfs_start_transaction(fs_info->tree_root, 0);
 	if (IS_ERR(trans)) {
@@ -5712,7 +5712,7 @@ again:
 
 	free_extent_buffer(log_root_tree->node);
 	log_root_tree->log_root = NULL;
-	fs_info->log_root_recovering = 0;
+	clear_bit(BTRFS_FS_LOG_RECOVERING, &fs_info->flags);
 	kfree(log_root_tree);
 
 	return 0;
diff --git a/fs/btrfs/volumes.c b/fs/btrfs/volumes.c
index 54ce73cb639f..6216a689bcba 100644
--- a/fs/btrfs/volumes.c
+++ b/fs/btrfs/volumes.c
@@ -4201,7 +4201,7 @@ out:
 	if (ret)
 		btrfs_warn(fs_info, "btrfs_uuid_scan_kthread failed %d", ret);
 	else
-		fs_info->update_uuid_tree_gen = 1;
+		set_bit(BTRFS_FS_UPDATE_UUID_TREE_GEN, &fs_info->flags);
 	up(&fs_info->uuid_tree_rescan_sem);
 	return 0;
 }
