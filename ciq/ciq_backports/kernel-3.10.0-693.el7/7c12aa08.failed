amd-xgbe: Move the PHY support into amd-xgbe

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Lendacky, Thomas <Thomas.Lendacky@amd.com>
commit 7c12aa08779cfa8e0a64943bd6d823c5c110766b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/7c12aa08.failed

The AMD XGBE device is intended to work with a specific integrated PHY
and that PHY is not meant to be a standalone PHY for use by other
devices. As such this patch removes the phylib driver and implements
the PHY support in the amd-xgbe driver (the majority of the logic from
the phylib driver is moved into the amd-xgbe driver).

Update the driver version to 1.0.1.

	Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 7c12aa08779cfa8e0a64943bd6d823c5c110766b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/devicetree/bindings/net/amd-xgbe.txt
#	drivers/net/ethernet/amd/Kconfig
#	drivers/net/ethernet/amd/xgbe/xgbe-common.h
#	drivers/net/ethernet/amd/xgbe/xgbe-drv.c
#	drivers/net/ethernet/amd/xgbe/xgbe-main.c
#	drivers/net/ethernet/amd/xgbe/xgbe-mdio.c
#	drivers/net/ethernet/amd/xgbe/xgbe.h
#	drivers/net/phy/Makefile
#	drivers/net/phy/amd-xgbe-phy.c
diff --cc Documentation/devicetree/bindings/net/amd-xgbe.txt
index f6db1ba87a3f,5dbc55a2db90..000000000000
--- a/Documentation/devicetree/bindings/net/amd-xgbe.txt
+++ b/Documentation/devicetree/bindings/net/amd-xgbe.txt
@@@ -19,17 -26,51 +19,55 @@@ Optional properties (ethernet device)
  - mac-address: mac address to be assigned to the device. Can be overridden
    by UEFI.
  - dma-coherent: Present if dma operations are coherent
 -- amd,per-channel-interrupt: Indicates that Rx and Tx complete will generate
 -  a unique interrupt for each DMA channel - this requires an additional
 -  interrupt be configured for each DMA channel
  
+ Required properties (phy device):
+ - compatible: Should be "amd,xgbe-phy-seattle-v1a"
+ - reg: Address and length of the register sets for the device
+    - SerDes Rx/Tx registers
+    - SerDes integration registers (1/2)
+    - SerDes integration registers (2/2)
+ - interrupt-parent: Should be the phandle for the interrupt controller
+   that services interrupts for this device
+ - interrupts: Should contain the amd-xgbe-phy interrupt.
+ 
+ Optional properties (phy device):
+ - amd,speed-set: Speed capabilities of the device
+     0 - 1GbE and 10GbE (default)
+     1 - 2.5GbE and 10GbE
+ 
+ The following optional properties are represented by an array with each
+ value corresponding to a particular speed. The first array value represents
+ the setting for the 1GbE speed, the second value for the 2.5GbE speed and
+ the third value for the 10GbE speed.  All three values are required if the
+ property is used.
+ - amd,serdes-blwc: Baseline wandering correction enablement
+     0 - Off
+     1 - On
+ - amd,serdes-cdr-rate: CDR rate speed selection
+ - amd,serdes-pq-skew: PQ (data sampling) skew
+ - amd,serdes-tx-amp: TX amplitude boost
+ - amd,serdes-dfe-tap-config: DFE taps available to run
+ - amd,serdes-dfe-tap-enable: DFE taps to enable
+ 
  Example:
  	xgbe@e0700000 {
  		compatible = "amd,xgbe-seattle-v1a";
  		reg = <0 0xe0700000 0 0x80000>,
  		      <0 0xe0780000 0 0x80000>;
  		interrupt-parent = <&gic>;
++<<<<<<< HEAD
 +		interrupts = <0 325 4>;
 +		clocks = <&xgbe_clk>;
 +		clock-names = "dma_clk";
 +		phy-handle = <&phy>;
++=======
+ 		interrupts = <0 325 4>,
+ 			     <0 326 1>, <0 327 1>, <0 328 1>, <0 329 1>;
+ 		amd,per-channel-interrupt;
+ 		clocks = <&xgbe_dma_clk>, <&xgbe_ptp_clk>;
+ 		clock-names = "dma_clk", "ptp_clk";
+ 		phy-handle = <&xgbe_phy>;
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  		phy-mode = "xgmii";
  		mac-address = [ 02 a1 a2 a3 a4 a5 ];
  	};
diff --cc drivers/net/ethernet/amd/Kconfig
index 13d74aa4033d,acd53173fcc0..000000000000
--- a/drivers/net/ethernet/amd/Kconfig
+++ b/drivers/net/ethernet/amd/Kconfig
@@@ -179,4 -177,28 +179,31 @@@ config SUNLANC
  	  To compile this driver as a module, choose M here: the module
  	  will be called sunlance.
  
++<<<<<<< HEAD
++=======
+ config AMD_XGBE
+ 	tristate "AMD 10GbE Ethernet driver"
+ 	depends on ((OF_NET && OF_ADDRESS) || ACPI) && HAS_IOMEM && HAS_DMA
+ 	depends on ARM64 || COMPILE_TEST
+ 	select BITREVERSE
+ 	select CRC32
+ 	select PTP_1588_CLOCK
+ 	---help---
+ 	  This driver supports the AMD 10GbE Ethernet device found on an
+ 	  AMD SoC.
+ 
+ 	  To compile this driver as a module, choose M here: the module
+ 	  will be called amd-xgbe.
+ 
+ config AMD_XGBE_DCB
+ 	bool "Data Center Bridging (DCB) support"
+ 	default n
+ 	depends on AMD_XGBE && DCB
+ 	---help---
+ 	  Say Y here to enable Data Center Bridging (DCB) support in the
+ 	  driver.
+ 
+ 	  If unsure, say N.
+ 
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  endif # NET_VENDOR_AMD
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-common.h
index 3373e9ef2003,b6fa89102526..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-common.h
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-common.h
@@@ -753,6 -857,47 +753,50 @@@
   */
  #define PCS_MMD_SELECT			0xff
  
++<<<<<<< HEAD
++=======
+ /* SerDes integration register offsets */
+ #define SIR0_KR_RT_1			0x002c
+ #define SIR0_STATUS			0x0040
+ #define SIR1_SPEED			0x0000
+ 
+ /* SerDes integration register entry bit positions and sizes */
+ #define SIR0_KR_RT_1_RESET_INDEX	11
+ #define SIR0_KR_RT_1_RESET_WIDTH	1
+ #define SIR0_STATUS_RX_READY_INDEX	0
+ #define SIR0_STATUS_RX_READY_WIDTH	1
+ #define SIR0_STATUS_TX_READY_INDEX	8
+ #define SIR0_STATUS_TX_READY_WIDTH	1
+ #define SIR1_SPEED_CDR_RATE_INDEX	12
+ #define SIR1_SPEED_CDR_RATE_WIDTH	4
+ #define SIR1_SPEED_DATARATE_INDEX	4
+ #define SIR1_SPEED_DATARATE_WIDTH	2
+ #define SIR1_SPEED_PLLSEL_INDEX		3
+ #define SIR1_SPEED_PLLSEL_WIDTH		1
+ #define SIR1_SPEED_RATECHANGE_INDEX	6
+ #define SIR1_SPEED_RATECHANGE_WIDTH	1
+ #define SIR1_SPEED_TXAMP_INDEX		8
+ #define SIR1_SPEED_TXAMP_WIDTH		4
+ #define SIR1_SPEED_WORDMODE_INDEX	0
+ #define SIR1_SPEED_WORDMODE_WIDTH	3
+ 
+ /* SerDes RxTx register offsets */
+ #define RXTX_REG6			0x0018
+ #define RXTX_REG20			0x0050
+ #define RXTX_REG22			0x0058
+ #define RXTX_REG114			0x01c8
+ #define RXTX_REG129			0x0204
+ 
+ /* SerDes RxTx register entry bit positions and sizes */
+ #define RXTX_REG6_RESETB_RXD_INDEX	8
+ #define RXTX_REG6_RESETB_RXD_WIDTH	1
+ #define RXTX_REG20_BLWC_ENA_INDEX	2
+ #define RXTX_REG20_BLWC_ENA_WIDTH	1
+ #define RXTX_REG114_PQ_REG_INDEX	9
+ #define RXTX_REG114_PQ_REG_WIDTH	7
+ #define RXTX_REG129_RXDFE_CONFIG_INDEX	14
+ #define RXTX_REG129_RXDFE_CONFIG_WIDTH	2
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  
  /* Descriptor/Packet entry bit positions and sizes */
  #define RX_PACKET_ERRORS_CRC_INDEX		2
@@@ -838,6 -1035,26 +898,29 @@@
  #define MDIO_AN_COMP_STAT		0x0030
  #endif
  
++<<<<<<< HEAD
++=======
+ #ifndef MDIO_AN_INTMASK
+ #define MDIO_AN_INTMASK			0x8001
+ #endif
+ 
+ #ifndef MDIO_AN_INT
+ #define MDIO_AN_INT			0x8002
+ #endif
+ 
+ #ifndef MDIO_CTRL1_SPEED1G
+ #define MDIO_CTRL1_SPEED1G		(MDIO_CTRL1_SPEED10G & ~BMCR_SPEED100)
+ #endif
+ 
+ /* MDIO mask values */
+ #define XGBE_XNP_MCF_NULL_MESSAGE	0x001
+ #define XGBE_XNP_ACK_PROCESSED		BIT(12)
+ #define XGBE_XNP_MP_FORMATTED		BIT(13)
+ #define XGBE_XNP_NP_EXCHANGE		BIT(15)
+ 
+ #define XGBE_KR_TRAINING_START		BIT(0)
+ #define XGBE_KR_TRAINING_ENABLE		BIT(1)
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  
  /* Bit setting and getting macros
   *  The get macro will extract the current bit field value from within
@@@ -985,7 -1197,82 +1068,83 @@@ do {									
  #define XPCS_IOREAD(_pdata, _off)					\
  	ioread32((_pdata)->xpcs_regs + (_off))
  
 +
+ /* Macros for building, reading or writing register values or bits
+  * within the register values of SerDes integration registers.
+  */
+ #define XSIR_GET_BITS(_var, _prefix, _field)                            \
+ 	GET_BITS((_var),                                                \
+ 		 _prefix##_##_field##_INDEX,                            \
+ 		 _prefix##_##_field##_WIDTH)
+ 
+ #define XSIR_SET_BITS(_var, _prefix, _field, _val)                      \
+ 	SET_BITS((_var),                                                \
+ 		 _prefix##_##_field##_INDEX,                            \
+ 		 _prefix##_##_field##_WIDTH, (_val))
+ 
+ #define XSIR0_IOREAD(_pdata, _reg)					\
+ 	ioread16((_pdata)->sir0_regs + _reg)
+ 
+ #define XSIR0_IOREAD_BITS(_pdata, _reg, _field)				\
+ 	GET_BITS(XSIR0_IOREAD((_pdata), _reg),				\
+ 		 _reg##_##_field##_INDEX,				\
+ 		 _reg##_##_field##_WIDTH)
+ 
+ #define XSIR0_IOWRITE(_pdata, _reg, _val)				\
+ 	iowrite16((_val), (_pdata)->sir0_regs + _reg)
+ 
+ #define XSIR0_IOWRITE_BITS(_pdata, _reg, _field, _val)			\
+ do {									\
+ 	u16 reg_val = XSIR0_IOREAD((_pdata), _reg);			\
+ 	SET_BITS(reg_val,						\
+ 		 _reg##_##_field##_INDEX,				\
+ 		 _reg##_##_field##_WIDTH, (_val));			\
+ 	XSIR0_IOWRITE((_pdata), _reg, reg_val);				\
+ } while (0)
+ 
+ #define XSIR1_IOREAD(_pdata, _reg)					\
+ 	ioread16((_pdata)->sir1_regs + _reg)
+ 
+ #define XSIR1_IOREAD_BITS(_pdata, _reg, _field)				\
+ 	GET_BITS(XSIR1_IOREAD((_pdata), _reg),				\
+ 		 _reg##_##_field##_INDEX,				\
+ 		 _reg##_##_field##_WIDTH)
+ 
+ #define XSIR1_IOWRITE(_pdata, _reg, _val)				\
+ 	iowrite16((_val), (_pdata)->sir1_regs + _reg)
+ 
+ #define XSIR1_IOWRITE_BITS(_pdata, _reg, _field, _val)			\
+ do {									\
+ 	u16 reg_val = XSIR1_IOREAD((_pdata), _reg);			\
+ 	SET_BITS(reg_val,						\
+ 		 _reg##_##_field##_INDEX,				\
+ 		 _reg##_##_field##_WIDTH, (_val));			\
+ 	XSIR1_IOWRITE((_pdata), _reg, reg_val);				\
+ } while (0)
+ 
+ /* Macros for building, reading or writing register values or bits
+  * within the register values of SerDes RxTx registers.
+  */
+ #define XRXTX_IOREAD(_pdata, _reg)					\
+ 	ioread16((_pdata)->rxtx_regs + _reg)
+ 
+ #define XRXTX_IOREAD_BITS(_pdata, _reg, _field)				\
+ 	GET_BITS(XRXTX_IOREAD((_pdata), _reg),				\
+ 		 _reg##_##_field##_INDEX,				\
+ 		 _reg##_##_field##_WIDTH)
+ 
+ #define XRXTX_IOWRITE(_pdata, _reg, _val)				\
+ 	iowrite16((_val), (_pdata)->rxtx_regs + _reg)
+ 
+ #define XRXTX_IOWRITE_BITS(_pdata, _reg, _field, _val)			\
+ do {									\
+ 	u16 reg_val = XRXTX_IOREAD((_pdata), _reg);			\
+ 	SET_BITS(reg_val,						\
+ 		 _reg##_##_field##_INDEX,				\
+ 		 _reg##_##_field##_WIDTH, (_val));			\
+ 	XRXTX_IOWRITE((_pdata), _reg, reg_val);				\
+ } while (0)
+ 
  /* Macros for building, reading or writing register values or bits
   * using MDIO.  Different from above because of the use of standardized
   * Linux include values.  No shifting is performed with the bit
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-drv.c
index d58e85811bc9,401703fc7b4f..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
@@@ -287,14 -434,28 +287,32 @@@ static enum hrtimer_restart xgbe_tx_tim
  
  	channel->tx_timer_active = 0;
  
 +	spin_unlock_irqrestore(&ring->lock, flags);
 +
  	DBGPR("<--xgbe_tx_timer\n");
 +
 +	return HRTIMER_NORESTART;
  }
  
- static void xgbe_init_tx_timers(struct xgbe_prv_data *pdata)
+ static void xgbe_service(struct work_struct *work)
+ {
+ 	struct xgbe_prv_data *pdata = container_of(work,
+ 						   struct xgbe_prv_data,
+ 						   service_work);
+ 
+ 	pdata->phy_if.phy_status(pdata);
+ }
+ 
+ static void xgbe_service_timer(unsigned long data)
+ {
+ 	struct xgbe_prv_data *pdata = (struct xgbe_prv_data *)data;
+ 
+ 	schedule_work(&pdata->service_work);
+ 
+ 	mod_timer(&pdata->service_timer, jiffies + HZ);
+ }
+ 
+ static void xgbe_init_timers(struct xgbe_prv_data *pdata)
  {
  	struct xgbe_channel *channel;
  	unsigned int i;
@@@ -306,16 -468,17 +325,19 @@@
  		if (!channel->tx_ring)
  			break;
  
 -		setup_timer(&channel->tx_timer, xgbe_tx_timer,
 -			    (unsigned long)channel);
 +		DBGPR("  %s adding tx timer\n", channel->name);
 +		hrtimer_init(&channel->tx_timer, CLOCK_MONOTONIC,
 +			     HRTIMER_MODE_REL);
 +		channel->tx_timer.function = xgbe_tx_timer;
  	}
+ }
  
- 	DBGPR("<--xgbe_init_tx_timers\n");
+ static void xgbe_start_timers(struct xgbe_prv_data *pdata)
+ {
+ 	mod_timer(&pdata->service_timer, jiffies + HZ);
  }
  
- static void xgbe_stop_tx_timers(struct xgbe_prv_data *pdata)
+ static void xgbe_stop_timers(struct xgbe_prv_data *pdata)
  {
  	struct xgbe_channel *channel;
  	unsigned int i;
@@@ -327,12 -490,8 +349,10 @@@
  		if (!channel->tx_ring)
  			break;
  
 -		del_timer_sync(&channel->tx_timer);
 +		DBGPR("  %s deleting tx timer\n", channel->name);
 +		channel->tx_timer_active = 0;
 +		hrtimer_cancel(&channel->tx_timer);
  	}
- 
- 	DBGPR("<--xgbe_stop_tx_timers\n");
  }
  
  void xgbe_get_all_hw_features(struct xgbe_prv_data *pdata)
@@@ -490,7 -775,17 +510,21 @@@ static void xgbe_free_rx_skbuff(struct 
  		}
  	}
  
++<<<<<<< HEAD
 +	DBGPR("<--xgbe_free_rx_skbuff\n");
++=======
+ 	DBGPR("<--xgbe_free_rx_data\n");
+ }
+ 
+ static int xgbe_phy_init(struct xgbe_prv_data *pdata)
+ {
+ 	pdata->phy_link = -1;
+ 	pdata->phy_speed = SPEED_UNKNOWN;
+ 	pdata->phy_tx_pause = pdata->tx_pause;
+ 	pdata->phy_rx_pause = pdata->rx_pause;
+ 
+ 	return pdata->phy_if.phy_reset(pdata);
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  }
  
  int xgbe_powerdown(struct net_device *netdev, unsigned int caller)
@@@ -516,12 -809,15 +550,24 @@@
  		netif_device_detach(netdev);
  
  	netif_tx_stop_all_queues(netdev);
++<<<<<<< HEAD
 +	xgbe_napi_disable(pdata, 0);
 +
 +	/* Powerdown Tx/Rx */
 +	hw_if->powerdown_tx(pdata);
 +	hw_if->powerdown_rx(pdata);
 +
++=======
+ 
+ 	xgbe_stop_timers(pdata);
+ 	flush_workqueue(pdata->dev_workqueue);
+ 
+ 	hw_if->powerdown_tx(pdata);
+ 	hw_if->powerdown_rx(pdata);
+ 
+ 	xgbe_napi_disable(pdata, 0);
+ 
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  	pdata->power_down = 1;
  
  	spin_unlock_irqrestore(&pdata->lock, flags);
@@@ -550,18 -846,18 +596,25 @@@ int xgbe_powerup(struct net_device *net
  
  	pdata->power_down = 0;
  
++<<<<<<< HEAD
 +	phy_start(pdata->phydev);
 +
 +	/* Enable Tx/Rx */
++=======
+ 	xgbe_napi_enable(pdata, 0);
+ 
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  	hw_if->powerup_tx(pdata);
  	hw_if->powerup_rx(pdata);
  
  	if (caller == XGMAC_DRIVER_CONTEXT)
  		netif_device_attach(netdev);
  
 +	xgbe_napi_enable(pdata, 0);
  	netif_tx_start_all_queues(netdev);
  
+ 	xgbe_start_timers(pdata);
+ 
  	spin_unlock_irqrestore(&pdata->lock, flags);
  
  	DBGPR("<--xgbe_powerup\n");
@@@ -572,46 -868,83 +625,94 @@@
  static int xgbe_start(struct xgbe_prv_data *pdata)
  {
  	struct xgbe_hw_if *hw_if = &pdata->hw_if;
+ 	struct xgbe_phy_if *phy_if = &pdata->phy_if;
  	struct net_device *netdev = pdata->netdev;
 -	int ret;
  
  	DBGPR("-->xgbe_start\n");
  
 +	xgbe_set_rx_mode(netdev);
 +
  	hw_if->init(pdata);
  
- 	phy_start(pdata->phydev);
+ 	ret = phy_if->phy_start(pdata);
+ 	if (ret)
+ 		goto err_phy;
  
 -	xgbe_napi_enable(pdata, 1);
 -
 -	ret = xgbe_request_irqs(pdata);
 -	if (ret)
 -		goto err_napi;
 -
  	hw_if->enable_tx(pdata);
  	hw_if->enable_rx(pdata);
  
++<<<<<<< HEAD
 +	xgbe_init_tx_timers(pdata);
 +
 +	xgbe_napi_enable(pdata, 1);
++=======
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  	netif_tx_start_all_queues(netdev);
  
+ 	xgbe_start_timers(pdata);
+ 	schedule_work(&pdata->service_work);
+ 
  	DBGPR("<--xgbe_start\n");
  
  	return 0;
++<<<<<<< HEAD
++=======
+ 
+ err_napi:
+ 	xgbe_napi_disable(pdata, 1);
+ 
+ 	phy_if->phy_stop(pdata);
+ 
+ err_phy:
+ 	hw_if->exit(pdata);
+ 
+ 	return ret;
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  }
  
  static void xgbe_stop(struct xgbe_prv_data *pdata)
  {
  	struct xgbe_hw_if *hw_if = &pdata->hw_if;
++<<<<<<< HEAD
++=======
+ 	struct xgbe_phy_if *phy_if = &pdata->phy_if;
+ 	struct xgbe_channel *channel;
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  	struct net_device *netdev = pdata->netdev;
 -	struct netdev_queue *txq;
 -	unsigned int i;
  
  	DBGPR("-->xgbe_stop\n");
  
 +	phy_stop(pdata->phydev);
 +
  	netif_tx_stop_all_queues(netdev);
 +	xgbe_napi_disable(pdata, 1);
  
- 	xgbe_stop_tx_timers(pdata);
+ 	xgbe_stop_timers(pdata);
+ 	flush_workqueue(pdata->dev_workqueue);
  
  	hw_if->disable_tx(pdata);
  	hw_if->disable_rx(pdata);
  
++<<<<<<< HEAD
++=======
+ 	xgbe_free_irqs(pdata);
+ 
+ 	xgbe_napi_disable(pdata, 1);
+ 
+ 	phy_if->phy_stop(pdata);
+ 
+ 	hw_if->exit(pdata);
+ 
+ 	channel = pdata->channel;
+ 	for (i = 0; i < pdata->channel_count; i++, channel++) {
+ 		if (!channel->tx_ring)
+ 			continue;
+ 
+ 		txq = netdev_get_tx_queue(netdev, channel->queue_index);
+ 		netdev_tx_reset_queue(txq);
+ 	}
+ 
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  	DBGPR("<--xgbe_stop\n");
  }
  
@@@ -760,11 -1294,22 +861,26 @@@ static int xgbe_open(struct net_device 
  
  	DBGPR("-->xgbe_open\n");
  
 -	/* Initialize the phy */
 -	ret = xgbe_phy_init(pdata);
 -	if (ret)
 +	/* Enable the clock */
 +	ret = clk_prepare_enable(pdata->sysclock);
 +	if (ret) {
 +		netdev_alert(netdev, "clk_prepare_enable failed\n");
  		return ret;
++<<<<<<< HEAD
++=======
+ 
+ 	/* Enable the clocks */
+ 	ret = clk_prepare_enable(pdata->sysclk);
+ 	if (ret) {
+ 		netdev_alert(netdev, "dma clk_prepare_enable failed\n");
+ 		return ret;
+ 	}
+ 
+ 	ret = clk_prepare_enable(pdata->ptpclk);
+ 	if (ret) {
+ 		netdev_alert(netdev, "ptp clk_prepare_enable failed\n");
+ 		goto err_sysclk;
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  	}
  
  	/* Calculate the Rx buffer size before allocating rings */
@@@ -776,40 -1321,39 +892,60 @@@
  	/* Allocate the ring descriptors and buffers */
  	ret = desc_if->alloc_ring_resources(pdata);
  	if (ret)
 -		goto err_channels;
 +		goto err_clk;
 +
++<<<<<<< HEAD
 +	/* Initialize the device restart work struct */
 +	INIT_WORK(&pdata->restart_work, xgbe_restart);
  
 +	/* Request interrupts */
 +	ret = devm_request_irq(pdata->dev, netdev->irq, xgbe_isr, 0,
 +			       netdev->name, pdata);
 +	if (ret) {
 +		netdev_alert(netdev, "error requesting irq %d\n",
 +			     pdata->irq_number);
 +		goto err_irq;
 +	}
 +	pdata->irq_number = netdev->irq;
++=======
+ 	INIT_WORK(&pdata->service_work, xgbe_service);
+ 	INIT_WORK(&pdata->restart_work, xgbe_restart);
+ 	INIT_WORK(&pdata->tx_tstamp_work, xgbe_tx_tstamp);
+ 	xgbe_init_timers(pdata);
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  
  	ret = xgbe_start(pdata);
  	if (ret)
 -		goto err_rings;
 +		goto err_start;
  
+ 	clear_bit(XGBE_DOWN, &pdata->dev_state);
+ 
  	DBGPR("<--xgbe_open\n");
  
  	return 0;
  
 -err_rings:
 +err_start:
 +	hw_if->exit(pdata);
 +
 +	devm_free_irq(pdata->dev, pdata->irq_number, pdata);
 +	pdata->irq_number = 0;
 +
 +err_irq:
  	desc_if->free_ring_resources(pdata);
  
++<<<<<<< HEAD
 +err_clk:
 +	clk_disable_unprepare(pdata->sysclock);
++=======
+ err_channels:
+ 	xgbe_free_channels(pdata);
+ 
+ err_ptpclk:
+ 	clk_disable_unprepare(pdata->ptpclk);
+ 
+ err_sysclk:
+ 	clk_disable_unprepare(pdata->sysclk);
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  
  	return ret;
  }
@@@ -825,20 -1368,17 +961,28 @@@ static int xgbe_close(struct net_devic
  	/* Stop the device */
  	xgbe_stop(pdata);
  
 -	/* Free the ring descriptors and buffers */
 +	/* Issue software reset to device */
 +	hw_if->exit(pdata);
 +
 +	/* Free all the ring data */
  	desc_if->free_ring_resources(pdata);
  
 -	/* Free the channel and ring structures */
 -	xgbe_free_channels(pdata);
 +	/* Release the interrupt */
 +	if (pdata->irq_number != 0) {
 +		devm_free_irq(pdata->dev, pdata->irq_number, pdata);
 +		pdata->irq_number = 0;
 +	}
  
++<<<<<<< HEAD
 +	/* Disable the clock */
 +	clk_disable_unprepare(pdata->sysclock);
++=======
+ 	/* Disable the clocks */
+ 	clk_disable_unprepare(pdata->ptpclk);
+ 	clk_disable_unprepare(pdata->sysclk);
+ 
+ 	set_bit(XGBE_DOWN, &pdata->dev_state);
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  
  	DBGPR("<--xgbe_close\n");
  
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-main.c
index 51cdca78ec38,0c219b30c129..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-main.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-main.c
@@@ -123,7 -123,12 +123,16 @@@
  #include <linux/io.h>
  #include <linux/of.h>
  #include <linux/of_net.h>
++<<<<<<< HEAD
 +#include <linux/clk.h>
++=======
+ #include <linux/of_address.h>
+ #include <linux/of_platform.h>
+ #include <linux/clk.h>
+ #include <linux/property.h>
+ #include <linux/acpi.h>
+ #include <linux/mdio.h>
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  
  #include "xgbe.h"
  #include "xgbe-common.h"
@@@ -134,60 -138,49 +143,96 @@@ MODULE_LICENSE("Dual BSD/GPL")
  MODULE_VERSION(XGBE_DRV_VERSION);
  MODULE_DESCRIPTION(XGBE_DRV_DESC);
  
 -static int debug = -1;
 -module_param(debug, int, S_IWUSR | S_IRUGO);
 -MODULE_PARM_DESC(debug, " Network interface message level setting");
 +static struct xgbe_channel *xgbe_alloc_rings(struct xgbe_prv_data *pdata)
 +{
 +	struct xgbe_channel *channel_mem, *channel;
 +	struct xgbe_ring *tx_ring, *rx_ring;
 +	unsigned int count, i;
 +
 +	DBGPR("-->xgbe_alloc_rings\n");
 +
 +	count = max_t(unsigned int, pdata->tx_ring_count, pdata->rx_ring_count);
 +
 +	channel_mem = devm_kcalloc(pdata->dev, count,
 +				   sizeof(struct xgbe_channel), GFP_KERNEL);
 +	if (!channel_mem)
 +		return NULL;
 +
 +	tx_ring = devm_kcalloc(pdata->dev, pdata->tx_ring_count,
 +			       sizeof(struct xgbe_ring), GFP_KERNEL);
 +	if (!tx_ring)
 +		return NULL;
 +
 +	rx_ring = devm_kcalloc(pdata->dev, pdata->rx_ring_count,
 +			       sizeof(struct xgbe_ring), GFP_KERNEL);
 +	if (!rx_ring)
 +		return NULL;
 +
 +	for (i = 0, channel = channel_mem; i < count; i++, channel++) {
 +		snprintf(channel->name, sizeof(channel->name), "channel-%d", i);
 +		channel->pdata = pdata;
 +		channel->queue_index = i;
 +		channel->dma_regs = pdata->xgmac_regs + DMA_CH_BASE +
 +				    (DMA_CH_INC * i);
 +
 +		if (i < pdata->tx_ring_count) {
 +			spin_lock_init(&tx_ring->lock);
 +			channel->tx_ring = tx_ring++;
 +		}
 +
 +		if (i < pdata->rx_ring_count) {
 +			spin_lock_init(&rx_ring->lock);
 +			channel->rx_ring = rx_ring++;
 +		}
 +
 +		DBGPR("  %s - queue_index=%u, dma_regs=%p, tx=%p, rx=%p\n",
 +		      channel->name, channel->queue_index, channel->dma_regs,
 +		      channel->tx_ring, channel->rx_ring);
 +	}
  
 -static const u32 default_msg_level = (NETIF_MSG_LINK | NETIF_MSG_IFDOWN |
 -				      NETIF_MSG_IFUP);
 +	pdata->channel_count = count;
 +
 +	DBGPR("<--xgbe_alloc_rings\n");
 +
 +	return channel_mem;
 +}
  
+ static const u32 xgbe_serdes_blwc[] = {
+ 	XGBE_SPEED_1000_BLWC,
+ 	XGBE_SPEED_2500_BLWC,
+ 	XGBE_SPEED_10000_BLWC,
+ };
+ 
+ static const u32 xgbe_serdes_cdr_rate[] = {
+ 	XGBE_SPEED_1000_CDR,
+ 	XGBE_SPEED_2500_CDR,
+ 	XGBE_SPEED_10000_CDR,
+ };
+ 
+ static const u32 xgbe_serdes_pq_skew[] = {
+ 	XGBE_SPEED_1000_PQ,
+ 	XGBE_SPEED_2500_PQ,
+ 	XGBE_SPEED_10000_PQ,
+ };
+ 
+ static const u32 xgbe_serdes_tx_amp[] = {
+ 	XGBE_SPEED_1000_TXAMP,
+ 	XGBE_SPEED_2500_TXAMP,
+ 	XGBE_SPEED_10000_TXAMP,
+ };
+ 
+ static const u32 xgbe_serdes_dfe_tap_cfg[] = {
+ 	XGBE_SPEED_1000_DFE_TAP_CONFIG,
+ 	XGBE_SPEED_2500_DFE_TAP_CONFIG,
+ 	XGBE_SPEED_10000_DFE_TAP_CONFIG,
+ };
+ 
+ static const u32 xgbe_serdes_dfe_tap_ena[] = {
+ 	XGBE_SPEED_1000_DFE_TAP_ENABLE,
+ 	XGBE_SPEED_2500_DFE_TAP_ENABLE,
+ 	XGBE_SPEED_10000_DFE_TAP_ENABLE,
+ };
+ 
  static void xgbe_default_config(struct xgbe_prv_data *pdata)
  {
  	DBGPR("-->xgbe_default_config\n");
@@@ -217,15 -209,158 +261,165 @@@ static void xgbe_init_all_fptrs(struct 
  	xgbe_init_function_ptrs_desc(&pdata->desc_if);
  }
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_ACPI
+ static int xgbe_acpi_support(struct xgbe_prv_data *pdata)
+ {
+ 	struct acpi_device *adev = pdata->adev;
+ 	struct device *dev = pdata->dev;
+ 	u32 property;
+ 	acpi_handle handle;
+ 	acpi_status status;
+ 	unsigned long long data;
+ 	int cca;
+ 	int ret;
+ 
+ 	/* Obtain the system clock setting */
+ 	ret = device_property_read_u32(dev, XGBE_ACPI_DMA_FREQ, &property);
+ 	if (ret) {
+ 		dev_err(dev, "unable to obtain %s property\n",
+ 			XGBE_ACPI_DMA_FREQ);
+ 		return ret;
+ 	}
+ 	pdata->sysclk_rate = property;
+ 
+ 	/* Obtain the PTP clock setting */
+ 	ret = device_property_read_u32(dev, XGBE_ACPI_PTP_FREQ, &property);
+ 	if (ret) {
+ 		dev_err(dev, "unable to obtain %s property\n",
+ 			XGBE_ACPI_PTP_FREQ);
+ 		return ret;
+ 	}
+ 	pdata->ptpclk_rate = property;
+ 
+ 	/* Retrieve the device cache coherency value */
+ 	handle = adev->handle;
+ 	do {
+ 		status = acpi_evaluate_integer(handle, "_CCA", NULL, &data);
+ 		if (!ACPI_FAILURE(status)) {
+ 			cca = data;
+ 			break;
+ 		}
+ 
+ 		status = acpi_get_parent(handle, &handle);
+ 	} while (!ACPI_FAILURE(status));
+ 
+ 	if (ACPI_FAILURE(status)) {
+ 		dev_err(dev, "error obtaining acpi coherency value\n");
+ 		return -EINVAL;
+ 	}
+ 	pdata->coherent = !!cca;
+ 
+ 	return 0;
+ }
+ #else   /* CONFIG_ACPI */
+ static int xgbe_acpi_support(struct xgbe_prv_data *pdata)
+ {
+ 	return -EINVAL;
+ }
+ #endif  /* CONFIG_ACPI */
+ 
+ #ifdef CONFIG_OF
+ static int xgbe_of_support(struct xgbe_prv_data *pdata)
+ {
+ 	struct device *dev = pdata->dev;
+ 
+ 	/* Obtain the system clock setting */
+ 	pdata->sysclk = devm_clk_get(dev, XGBE_DMA_CLOCK);
+ 	if (IS_ERR(pdata->sysclk)) {
+ 		dev_err(dev, "dma devm_clk_get failed\n");
+ 		return PTR_ERR(pdata->sysclk);
+ 	}
+ 	pdata->sysclk_rate = clk_get_rate(pdata->sysclk);
+ 
+ 	/* Obtain the PTP clock setting */
+ 	pdata->ptpclk = devm_clk_get(dev, XGBE_PTP_CLOCK);
+ 	if (IS_ERR(pdata->ptpclk)) {
+ 		dev_err(dev, "ptp devm_clk_get failed\n");
+ 		return PTR_ERR(pdata->ptpclk);
+ 	}
+ 	pdata->ptpclk_rate = clk_get_rate(pdata->ptpclk);
+ 
+ 	/* Retrieve the device cache coherency value */
+ 	pdata->coherent = of_dma_is_coherent(dev->of_node);
+ 
+ 	return 0;
+ }
+ 
+ static struct platform_device *xgbe_of_get_phy_pdev(struct xgbe_prv_data *pdata)
+ {
+ 	struct device *dev = pdata->dev;
+ 	struct device_node *phy_node;
+ 	struct platform_device *phy_pdev;
+ 
+ 	phy_node = of_parse_phandle(dev->of_node, "phy-handle", 0);
+ 	if (!phy_node) {
+ 		dev_err(dev, "unable to locate phy device\n");
+ 		return NULL;
+ 	}
+ 
+ 	phy_pdev = of_find_device_by_node(phy_node);
+ 	of_node_put(phy_node);
+ 
+ 	return phy_pdev;
+ }
+ #else   /* CONFIG_OF */
+ static int xgbe_of_support(struct xgbe_prv_data *pdata)
+ {
+ 	return -EINVAL;
+ }
+ 
+ static struct platform_device *xgbe_of_get_phy_pdev(struct xgbe_prv_data *pdata)
+ {
+ 	return NULL;
+ }
+ #endif  /* CONFIG_OF */
+ 
+ static unsigned int xgbe_resource_count(struct platform_device *pdev,
+ 					unsigned int type)
+ {
+ 	unsigned int count;
+ 	int i;
+ 
+ 	for (i = 0, count = 0; i < pdev->num_resources; i++) {
+ 		struct resource *res = &pdev->resource[i];
+ 
+ 		if (type == resource_type(res))
+ 			count++;
+ 	}
+ 
+ 	return count;
+ }
+ 
+ static struct platform_device *xgbe_get_phy_pdev(struct xgbe_prv_data *pdata)
+ {
+ 	struct platform_device *phy_pdev;
+ 
+ 	if (pdata->use_acpi) {
+ 		get_device(pdata->dev);
+ 		phy_pdev = pdata->pdev;
+ 	} else {
+ 		phy_pdev = xgbe_of_get_phy_pdev(pdata);
+ 	}
+ 
+ 	return phy_pdev;
+ }
+ 
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  static int xgbe_probe(struct platform_device *pdev)
  {
  	struct xgbe_prv_data *pdata;
- 	struct xgbe_hw_if *hw_if;
- 	struct xgbe_desc_if *desc_if;
  	struct net_device *netdev;
- 	struct device *dev = &pdev->dev;
+ 	struct device *dev = &pdev->dev, *phy_dev;
+ 	struct platform_device *phy_pdev;
  	struct resource *res;
++<<<<<<< HEAD
 +	const u8 *mac_addr;
++=======
+ 	const char *phy_mode;
+ 	unsigned int i, phy_memnum, phy_irqnum;
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  	int ret;
  
  	DBGPR("--> xgbe_probe\n");
@@@ -246,6 -382,38 +440,41 @@@
  
  	spin_lock_init(&pdata->lock);
  	mutex_init(&pdata->xpcs_mutex);
++<<<<<<< HEAD
++=======
+ 	mutex_init(&pdata->rss_mutex);
+ 	spin_lock_init(&pdata->tstamp_lock);
+ 
+ 	pdata->msg_enable = netif_msg_init(debug, default_msg_level);
+ 
+ 	set_bit(XGBE_DOWN, &pdata->dev_state);
+ 
+ 	/* Check if we should use ACPI or DT */
+ 	pdata->use_acpi = (!pdata->adev || acpi_disabled) ? 0 : 1;
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
+ 
+ 	phy_pdev = xgbe_get_phy_pdev(pdata);
+ 	if (!phy_pdev) {
+ 		dev_err(dev, "unable to obtain phy device\n");
+ 		ret = -EINVAL;
+ 		goto err_phydev;
+ 	}
+ 	phy_dev = &phy_pdev->dev;
+ 
+ 	if (pdev == phy_pdev) {
+ 		/* ACPI:
+ 		 *   The XGBE and PHY resources are grouped together with
+ 		 *   the PHY resources listed last
+ 		 */
+ 		phy_memnum = xgbe_resource_count(pdev, IORESOURCE_MEM) - 3;
+ 		phy_irqnum = xgbe_resource_count(pdev, IORESOURCE_IRQ) - 1;
+ 	} else {
+ 		/* Device tree:
+ 		 *   The XGBE and PHY resources are separate
+ 		 */
+ 		phy_memnum = 0;
+ 		phy_irqnum = 0;
+ 	}
  
  	/* Set and validate the number of descriptors for a ring */
  	BUILD_BUG_ON_NOT_POWER_OF_2(XGBE_TX_DESC_CNT);
@@@ -290,18 -451,184 +519,196 @@@
  		ret = PTR_ERR(pdata->xpcs_regs);
  		goto err_io;
  	}
 -	if (netif_msg_probe(pdata))
 -		dev_dbg(dev, "xpcs_regs  = %p\n", pdata->xpcs_regs);
 +	DBGPR("  xpcs_regs  = %p\n", pdata->xpcs_regs);
 +
++<<<<<<< HEAD
 +	/* Set the DMA mask */
 +	if (!dev->dma_mask)
 +		dev->dma_mask = &dev->coherent_dma_mask;
 +	ret = dma_set_mask_and_coherent(dev, DMA_BIT_MASK(40));
 +	if (ret) {
 +		dev_err(dev, "dma_set_mask_and_coherent failed\n");
 +		goto err_io;
 +	}
  
 +	if (of_property_read_bool(dev->of_node, "dma-coherent")) {
++=======
+ 	res = platform_get_resource(phy_pdev, IORESOURCE_MEM, phy_memnum++);
+ 	pdata->rxtx_regs = devm_ioremap_resource(dev, res);
+ 	if (IS_ERR(pdata->rxtx_regs)) {
+ 		dev_err(dev, "rxtx ioremap failed\n");
+ 		ret = PTR_ERR(pdata->rxtx_regs);
+ 		goto err_io;
+ 	}
+ 	if (netif_msg_probe(pdata))
+ 		dev_dbg(dev, "rxtx_regs  = %p\n", pdata->rxtx_regs);
+ 
+ 	res = platform_get_resource(phy_pdev, IORESOURCE_MEM, phy_memnum++);
+ 	pdata->sir0_regs = devm_ioremap_resource(dev, res);
+ 	if (IS_ERR(pdata->sir0_regs)) {
+ 		dev_err(dev, "sir0 ioremap failed\n");
+ 		ret = PTR_ERR(pdata->sir0_regs);
+ 		goto err_io;
+ 	}
+ 	if (netif_msg_probe(pdata))
+ 		dev_dbg(dev, "sir0_regs  = %p\n", pdata->sir0_regs);
+ 
+ 	res = platform_get_resource(phy_pdev, IORESOURCE_MEM, phy_memnum++);
+ 	pdata->sir1_regs = devm_ioremap_resource(dev, res);
+ 	if (IS_ERR(pdata->sir1_regs)) {
+ 		dev_err(dev, "sir1 ioremap failed\n");
+ 		ret = PTR_ERR(pdata->sir1_regs);
+ 		goto err_io;
+ 	}
+ 	if (netif_msg_probe(pdata))
+ 		dev_dbg(dev, "sir1_regs  = %p\n", pdata->sir1_regs);
+ 
+ 	/* Retrieve the MAC address */
+ 	ret = device_property_read_u8_array(dev, XGBE_MAC_ADDR_PROPERTY,
+ 					    pdata->mac_addr,
+ 					    sizeof(pdata->mac_addr));
+ 	if (ret || !is_valid_ether_addr(pdata->mac_addr)) {
+ 		dev_err(dev, "invalid %s property\n", XGBE_MAC_ADDR_PROPERTY);
+ 		if (!ret)
+ 			ret = -EINVAL;
+ 		goto err_io;
+ 	}
+ 
+ 	/* Retrieve the PHY mode - it must be "xgmii" */
+ 	ret = device_property_read_string(dev, XGBE_PHY_MODE_PROPERTY,
+ 					  &phy_mode);
+ 	if (ret || strcmp(phy_mode, phy_modes(PHY_INTERFACE_MODE_XGMII))) {
+ 		dev_err(dev, "invalid %s property\n", XGBE_PHY_MODE_PROPERTY);
+ 		if (!ret)
+ 			ret = -EINVAL;
+ 		goto err_io;
+ 	}
+ 	pdata->phy_mode = PHY_INTERFACE_MODE_XGMII;
+ 
+ 	/* Check for per channel interrupt support */
+ 	if (device_property_present(dev, XGBE_DMA_IRQS_PROPERTY))
+ 		pdata->per_channel_irq = 1;
+ 
+ 	/* Retrieve the PHY speedset */
+ 	ret = device_property_read_u32(phy_dev, XGBE_SPEEDSET_PROPERTY,
+ 				       &pdata->speed_set);
+ 	if (ret) {
+ 		dev_err(dev, "invalid %s property\n", XGBE_SPEEDSET_PROPERTY);
+ 		goto err_io;
+ 	}
+ 
+ 	switch (pdata->speed_set) {
+ 	case XGBE_SPEEDSET_1000_10000:
+ 	case XGBE_SPEEDSET_2500_10000:
+ 		break;
+ 	default:
+ 		dev_err(dev, "invalid %s property\n", XGBE_SPEEDSET_PROPERTY);
+ 		ret = -EINVAL;
+ 		goto err_io;
+ 	}
+ 
+ 	/* Retrieve the PHY configuration properties */
+ 	if (device_property_present(phy_dev, XGBE_BLWC_PROPERTY)) {
+ 		ret = device_property_read_u32_array(phy_dev,
+ 						     XGBE_BLWC_PROPERTY,
+ 						     pdata->serdes_blwc,
+ 						     XGBE_SPEEDS);
+ 		if (ret) {
+ 			dev_err(dev, "invalid %s property\n",
+ 				XGBE_BLWC_PROPERTY);
+ 			goto err_io;
+ 		}
+ 	} else {
+ 		memcpy(pdata->serdes_blwc, xgbe_serdes_blwc,
+ 		       sizeof(pdata->serdes_blwc));
+ 	}
+ 
+ 	if (device_property_present(phy_dev, XGBE_CDR_RATE_PROPERTY)) {
+ 		ret = device_property_read_u32_array(phy_dev,
+ 						     XGBE_CDR_RATE_PROPERTY,
+ 						     pdata->serdes_cdr_rate,
+ 						     XGBE_SPEEDS);
+ 		if (ret) {
+ 			dev_err(dev, "invalid %s property\n",
+ 				XGBE_CDR_RATE_PROPERTY);
+ 			goto err_io;
+ 		}
+ 	} else {
+ 		memcpy(pdata->serdes_cdr_rate, xgbe_serdes_cdr_rate,
+ 		       sizeof(pdata->serdes_cdr_rate));
+ 	}
+ 
+ 	if (device_property_present(phy_dev, XGBE_PQ_SKEW_PROPERTY)) {
+ 		ret = device_property_read_u32_array(phy_dev,
+ 						     XGBE_PQ_SKEW_PROPERTY,
+ 						     pdata->serdes_pq_skew,
+ 						     XGBE_SPEEDS);
+ 		if (ret) {
+ 			dev_err(dev, "invalid %s property\n",
+ 				XGBE_PQ_SKEW_PROPERTY);
+ 			goto err_io;
+ 		}
+ 	} else {
+ 		memcpy(pdata->serdes_pq_skew, xgbe_serdes_pq_skew,
+ 		       sizeof(pdata->serdes_pq_skew));
+ 	}
+ 
+ 	if (device_property_present(phy_dev, XGBE_TX_AMP_PROPERTY)) {
+ 		ret = device_property_read_u32_array(phy_dev,
+ 						     XGBE_TX_AMP_PROPERTY,
+ 						     pdata->serdes_tx_amp,
+ 						     XGBE_SPEEDS);
+ 		if (ret) {
+ 			dev_err(dev, "invalid %s property\n",
+ 				XGBE_TX_AMP_PROPERTY);
+ 			goto err_io;
+ 		}
+ 	} else {
+ 		memcpy(pdata->serdes_tx_amp, xgbe_serdes_tx_amp,
+ 		       sizeof(pdata->serdes_tx_amp));
+ 	}
+ 
+ 	if (device_property_present(phy_dev, XGBE_DFE_CFG_PROPERTY)) {
+ 		ret = device_property_read_u32_array(phy_dev,
+ 						     XGBE_DFE_CFG_PROPERTY,
+ 						     pdata->serdes_dfe_tap_cfg,
+ 						     XGBE_SPEEDS);
+ 		if (ret) {
+ 			dev_err(dev, "invalid %s property\n",
+ 				XGBE_DFE_CFG_PROPERTY);
+ 			goto err_io;
+ 		}
+ 	} else {
+ 		memcpy(pdata->serdes_dfe_tap_cfg, xgbe_serdes_dfe_tap_cfg,
+ 		       sizeof(pdata->serdes_dfe_tap_cfg));
+ 	}
+ 
+ 	if (device_property_present(phy_dev, XGBE_DFE_ENA_PROPERTY)) {
+ 		ret = device_property_read_u32_array(phy_dev,
+ 						     XGBE_DFE_ENA_PROPERTY,
+ 						     pdata->serdes_dfe_tap_ena,
+ 						     XGBE_SPEEDS);
+ 		if (ret) {
+ 			dev_err(dev, "invalid %s property\n",
+ 				XGBE_DFE_ENA_PROPERTY);
+ 			goto err_io;
+ 		}
+ 	} else {
+ 		memcpy(pdata->serdes_dfe_tap_ena, xgbe_serdes_dfe_tap_ena,
+ 		       sizeof(pdata->serdes_dfe_tap_ena));
+ 	}
+ 
+ 	/* Obtain device settings unique to ACPI/OF */
+ 	if (pdata->use_acpi)
+ 		ret = xgbe_acpi_support(pdata);
+ 	else
+ 		ret = xgbe_of_support(pdata);
+ 	if (ret)
+ 		goto err_io;
+ 
+ 	/* Set the DMA coherency values */
+ 	if (pdata->coherent) {
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  		pdata->axdomain = XGBE_DMA_OS_AXDOMAIN;
  		pdata->arcache = XGBE_DMA_OS_ARCACHE;
  		pdata->awcache = XGBE_DMA_OS_AWCACHE;
@@@ -311,13 -638,25 +718,27 @@@
  		pdata->awcache = XGBE_DMA_SYS_AWCACHE;
  	}
  
 -	/* Get the device interrupt */
  	ret = platform_get_irq(pdev, 0);
  	if (ret < 0) {
 -		dev_err(dev, "platform_get_irq 0 failed\n");
 +		dev_err(dev, "platform_get_irq failed\n");
  		goto err_io;
  	}
++<<<<<<< HEAD
 +	netdev->irq = ret;
++=======
+ 	pdata->dev_irq = ret;
+ 
+ 	/* Get the auto-negotiation interrupt */
+ 	ret = platform_get_irq(phy_pdev, phy_irqnum++);
+ 	if (ret < 0) {
+ 		dev_err(dev, "platform_get_irq phy 0 failed\n");
+ 		goto err_io;
+ 	}
+ 	pdata->an_irq = ret;
+ 
+ 	netdev->irq = pdata->dev_irq;
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  	netdev->base_addr = (unsigned long)pdata->xgmac_regs;
 -	memcpy(netdev->dev_addr, pdata->mac_addr, netdev->addr_len);
  
  	/* Set all the function pointers */
  	xgbe_init_all_fptrs(pdata);
@@@ -367,28 -706,26 +786,20 @@@
  		goto err_io;
  	}
  
 -	/* Initialize RSS hash key and lookup table */
 -	netdev_rss_key_fill(pdata->rss_key, sizeof(pdata->rss_key));
 -
 -	for (i = 0; i < XGBE_RSS_MAX_TABLE_SIZE; i++)
 -		XGMAC_SET_BITS(pdata->rss_table[i], MAC_RSSDR, DMCH,
 -			       i % pdata->rx_ring_count);
 -
 -	XGMAC_SET_BITS(pdata->rss_options, MAC_RSSCR, IP2TE, 1);
 -	XGMAC_SET_BITS(pdata->rss_options, MAC_RSSCR, TCP4TE, 1);
 -	XGMAC_SET_BITS(pdata->rss_options, MAC_RSSCR, UDP4TE, 1);
 +	/* Allocate the rings for the DMA channels */
 +	pdata->channel = xgbe_alloc_rings(pdata);
 +	if (!pdata->channel) {
 +		dev_err(dev, "ring allocation failed\n");
 +		ret = -ENOMEM;
 +		goto err_io;
 +	}
  
- 	/* Prepare to regsiter with MDIO */
- 	pdata->mii_bus_id = kasprintf(GFP_KERNEL, "%s", pdev->name);
- 	if (!pdata->mii_bus_id) {
- 		dev_err(dev, "failed to allocate mii bus id\n");
- 		ret = -ENOMEM;
- 		goto err_io;
- 	}
- 	ret = xgbe_mdio_register(pdata);
- 	if (ret)
- 		goto err_bus_id;
+ 	/* Call MDIO/PHY initialization routine */
+ 	pdata->phy_if.phy_init(pdata);
  
 -	/* Set device operations */
 +	/* Set network and ethtool operations */
  	netdev->netdev_ops = xgbe_get_netdev_ops();
  	netdev->ethtool_ops = xgbe_get_ethtool_ops();
 -#ifdef CONFIG_AMD_XGBE_DCB
 -	netdev->dcbnl_ops = xgbe_get_dcbnl_ops();
 -#endif
  
  	/* Set device features */
  	netdev->hw_features = NETIF_F_SG |
@@@ -417,11 -763,36 +828,34 @@@
  	ret = register_netdev(netdev);
  	if (ret) {
  		dev_err(dev, "net device registration failed\n");
- 		goto err_reg_netdev;
+ 		goto err_io;
+ 	}
+ 
+ 	/* Create the PHY/ANEG name based on netdev name */
+ 	snprintf(pdata->an_name, sizeof(pdata->an_name) - 1, "%s-pcs",
+ 		 netdev_name(netdev));
+ 
+ 	/* Create workqueues */
+ 	pdata->dev_workqueue =
+ 		create_singlethread_workqueue(netdev_name(netdev));
+ 	if (!pdata->dev_workqueue) {
+ 		netdev_err(netdev, "device workqueue creation failed\n");
+ 		ret = -ENOMEM;
+ 		goto err_netdev;
+ 	}
+ 
+ 	pdata->an_workqueue =
+ 		create_singlethread_workqueue(pdata->an_name);
+ 	if (!pdata->an_workqueue) {
+ 		netdev_err(netdev, "phy workqueue creation failed\n");
+ 		ret = -ENOMEM;
+ 		goto err_wq;
  	}
  
 -	xgbe_ptp_register(pdata);
 -
  	xgbe_debugfs_init(pdata);
  
+ 	platform_device_put(phy_pdev);
+ 
  	netdev_notice(netdev, "net device enabled\n");
  
  	DBGPR("<-- xgbe_probe\n");
@@@ -452,11 -826,15 +889,18 @@@ static int xgbe_remove(struct platform_
  
  	xgbe_debugfs_exit(pdata);
  
- 	unregister_netdev(netdev);
++<<<<<<< HEAD
++=======
+ 	xgbe_ptp_unregister(pdata);
  
- 	xgbe_mdio_unregister(pdata);
+ 	flush_workqueue(pdata->an_workqueue);
+ 	destroy_workqueue(pdata->an_workqueue);
  
- 	kfree(pdata->mii_bus_id);
+ 	flush_workqueue(pdata->dev_workqueue);
+ 	destroy_workqueue(pdata->dev_workqueue);
+ 
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
+ 	unregister_netdev(netdev);
  
  	free_netdev(netdev);
  
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-mdio.c
index 8514b5841ecd,1ae4bfbd13d3..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-mdio.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-mdio.c
@@@ -124,305 -125,1116 +126,1345 @@@
  #include "xgbe.h"
  #include "xgbe-common.h"
  
++<<<<<<< HEAD
 +
 +static int xgbe_mdio_read(struct mii_bus *mii, int prtad, int mmd_reg)
++=======
+ static void xgbe_an_enable_kr_training(struct xgbe_prv_data *pdata)
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  {
- 	struct xgbe_prv_data *pdata = mii->priv;
- 	struct xgbe_hw_if *hw_if = &pdata->hw_if;
- 	int mmd_data;
+ 	unsigned int reg;
+ 
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PMAPMD, MDIO_PMA_10GBR_PMD_CTRL);
  
- 	DBGPR_MDIO("-->xgbe_mdio_read: prtad=%#x mmd_reg=%#x\n",
- 		   prtad, mmd_reg);
+ 	reg |= XGBE_KR_TRAINING_ENABLE;
+ 	XMDIO_WRITE(pdata, MDIO_MMD_PMAPMD, MDIO_PMA_10GBR_PMD_CTRL, reg);
+ }
  
- 	mmd_data = hw_if->read_mmd_regs(pdata, prtad, mmd_reg);
+ static void xgbe_an_disable_kr_training(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int reg;
  
- 	DBGPR_MDIO("<--xgbe_mdio_read: mmd_data=%#x\n", mmd_data);
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PMAPMD, MDIO_PMA_10GBR_PMD_CTRL);
  
- 	return mmd_data;
+ 	reg &= ~XGBE_KR_TRAINING_ENABLE;
+ 	XMDIO_WRITE(pdata, MDIO_MMD_PMAPMD, MDIO_PMA_10GBR_PMD_CTRL, reg);
  }
  
- static int xgbe_mdio_write(struct mii_bus *mii, int prtad, int mmd_reg,
- 			   u16 mmd_val)
+ static void xgbe_pcs_power_cycle(struct xgbe_prv_data *pdata)
  {
- 	struct xgbe_prv_data *pdata = mii->priv;
- 	struct xgbe_hw_if *hw_if = &pdata->hw_if;
- 	int mmd_data = mmd_val;
+ 	unsigned int reg;
+ 
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL1);
+ 
+ 	reg |= MDIO_CTRL1_LPOWER;
+ 	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL1, reg);
+ 
+ 	usleep_range(75, 100);
+ 
+ 	reg &= ~MDIO_CTRL1_LPOWER;
+ 	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL1, reg);
+ }
+ 
+ static void xgbe_serdes_start_ratechange(struct xgbe_prv_data *pdata)
+ {
+ 	/* Assert Rx and Tx ratechange */
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, RATECHANGE, 1);
+ }
+ 
+ static void xgbe_serdes_complete_ratechange(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int wait;
+ 	u16 status;
+ 
+ 	/* Release Rx and Tx ratechange */
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, RATECHANGE, 0);
+ 
+ 	/* Wait for Rx and Tx ready */
+ 	wait = XGBE_RATECHANGE_COUNT;
+ 	while (wait--) {
+ 		usleep_range(50, 75);
+ 
+ 		status = XSIR0_IOREAD(pdata, SIR0_STATUS);
+ 		if (XSIR_GET_BITS(status, SIR0_STATUS, RX_READY) &&
+ 		    XSIR_GET_BITS(status, SIR0_STATUS, TX_READY))
+ 			goto rx_reset;
+ 	}
+ 
+ 	netdev_dbg(pdata->netdev, "SerDes rx/tx not ready (%#hx)\n",
+ 		   status);
+ 
+ rx_reset:
+ 	/* Perform Rx reset for the DFE changes */
+ 	XRXTX_IOWRITE_BITS(pdata, RXTX_REG6, RESETB_RXD, 0);
+ 	XRXTX_IOWRITE_BITS(pdata, RXTX_REG6, RESETB_RXD, 1);
+ }
+ 
+ static void xgbe_xgmii_mode(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int reg;
+ 
+ 	/* Enable KR training */
+ 	xgbe_an_enable_kr_training(pdata);
+ 
+ 	/* Set MAC to 10G speed */
+ 	pdata->hw_if.set_xgmii_speed(pdata);
+ 
+ 	/* Set PCS to KR/10G speed */
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL2);
+ 	reg &= ~MDIO_PCS_CTRL2_TYPE;
+ 	reg |= MDIO_PCS_CTRL2_10GBR;
+ 	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL2, reg);
+ 
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL1);
+ 	reg &= ~MDIO_CTRL1_SPEEDSEL;
+ 	reg |= MDIO_CTRL1_SPEED10G;
+ 	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL1, reg);
+ 
+ 	xgbe_pcs_power_cycle(pdata);
+ 
+ 	/* Set SerDes to 10G speed */
+ 	xgbe_serdes_start_ratechange(pdata);
+ 
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, DATARATE, XGBE_SPEED_10000_RATE);
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, WORDMODE, XGBE_SPEED_10000_WORD);
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, PLLSEL, XGBE_SPEED_10000_PLL);
+ 
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, CDR_RATE,
+ 			   pdata->serdes_cdr_rate[XGBE_SPEED_10000]);
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, TXAMP,
+ 			   pdata->serdes_tx_amp[XGBE_SPEED_10000]);
+ 	XRXTX_IOWRITE_BITS(pdata, RXTX_REG20, BLWC_ENA,
+ 			   pdata->serdes_blwc[XGBE_SPEED_10000]);
+ 	XRXTX_IOWRITE_BITS(pdata, RXTX_REG114, PQ_REG,
+ 			   pdata->serdes_pq_skew[XGBE_SPEED_10000]);
+ 	XRXTX_IOWRITE_BITS(pdata, RXTX_REG129, RXDFE_CONFIG,
+ 			   pdata->serdes_dfe_tap_cfg[XGBE_SPEED_10000]);
+ 	XRXTX_IOWRITE(pdata, RXTX_REG22,
+ 		      pdata->serdes_dfe_tap_ena[XGBE_SPEED_10000]);
+ 
+ 	xgbe_serdes_complete_ratechange(pdata);
+ }
+ 
+ static void xgbe_gmii_2500_mode(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int reg;
+ 
+ 	/* Disable KR training */
+ 	xgbe_an_disable_kr_training(pdata);
+ 
+ 	/* Set MAC to 2.5G speed */
+ 	pdata->hw_if.set_gmii_2500_speed(pdata);
+ 
+ 	/* Set PCS to KX/1G speed */
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL2);
+ 	reg &= ~MDIO_PCS_CTRL2_TYPE;
+ 	reg |= MDIO_PCS_CTRL2_10GBX;
+ 	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL2, reg);
+ 
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL1);
+ 	reg &= ~MDIO_CTRL1_SPEEDSEL;
+ 	reg |= MDIO_CTRL1_SPEED1G;
+ 	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL1, reg);
+ 
+ 	xgbe_pcs_power_cycle(pdata);
+ 
+ 	/* Set SerDes to 2.5G speed */
+ 	xgbe_serdes_start_ratechange(pdata);
+ 
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, DATARATE, XGBE_SPEED_2500_RATE);
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, WORDMODE, XGBE_SPEED_2500_WORD);
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, PLLSEL, XGBE_SPEED_2500_PLL);
+ 
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, CDR_RATE,
+ 			   pdata->serdes_cdr_rate[XGBE_SPEED_2500]);
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, TXAMP,
+ 			   pdata->serdes_tx_amp[XGBE_SPEED_2500]);
+ 	XRXTX_IOWRITE_BITS(pdata, RXTX_REG20, BLWC_ENA,
+ 			   pdata->serdes_blwc[XGBE_SPEED_2500]);
+ 	XRXTX_IOWRITE_BITS(pdata, RXTX_REG114, PQ_REG,
+ 			   pdata->serdes_pq_skew[XGBE_SPEED_2500]);
+ 	XRXTX_IOWRITE_BITS(pdata, RXTX_REG129, RXDFE_CONFIG,
+ 			   pdata->serdes_dfe_tap_cfg[XGBE_SPEED_2500]);
+ 	XRXTX_IOWRITE(pdata, RXTX_REG22,
+ 		      pdata->serdes_dfe_tap_ena[XGBE_SPEED_2500]);
+ 
+ 	xgbe_serdes_complete_ratechange(pdata);
+ }
+ 
+ static void xgbe_gmii_mode(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int reg;
+ 
+ 	/* Disable KR training */
+ 	xgbe_an_disable_kr_training(pdata);
+ 
+ 	/* Set MAC to 1G speed */
+ 	pdata->hw_if.set_gmii_speed(pdata);
+ 
+ 	/* Set PCS to KX/1G speed */
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL2);
+ 	reg &= ~MDIO_PCS_CTRL2_TYPE;
+ 	reg |= MDIO_PCS_CTRL2_10GBX;
+ 	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL2, reg);
+ 
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL1);
+ 	reg &= ~MDIO_CTRL1_SPEEDSEL;
+ 	reg |= MDIO_CTRL1_SPEED1G;
+ 	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL1, reg);
+ 
+ 	xgbe_pcs_power_cycle(pdata);
+ 
+ 	/* Set SerDes to 1G speed */
+ 	xgbe_serdes_start_ratechange(pdata);
+ 
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, DATARATE, XGBE_SPEED_1000_RATE);
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, WORDMODE, XGBE_SPEED_1000_WORD);
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, PLLSEL, XGBE_SPEED_1000_PLL);
+ 
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, CDR_RATE,
+ 			   pdata->serdes_cdr_rate[XGBE_SPEED_1000]);
+ 	XSIR1_IOWRITE_BITS(pdata, SIR1_SPEED, TXAMP,
+ 			   pdata->serdes_tx_amp[XGBE_SPEED_1000]);
+ 	XRXTX_IOWRITE_BITS(pdata, RXTX_REG20, BLWC_ENA,
+ 			   pdata->serdes_blwc[XGBE_SPEED_1000]);
+ 	XRXTX_IOWRITE_BITS(pdata, RXTX_REG114, PQ_REG,
+ 			   pdata->serdes_pq_skew[XGBE_SPEED_1000]);
+ 	XRXTX_IOWRITE_BITS(pdata, RXTX_REG129, RXDFE_CONFIG,
+ 			   pdata->serdes_dfe_tap_cfg[XGBE_SPEED_1000]);
+ 	XRXTX_IOWRITE(pdata, RXTX_REG22,
+ 		      pdata->serdes_dfe_tap_ena[XGBE_SPEED_1000]);
+ 
+ 	xgbe_serdes_complete_ratechange(pdata);
+ }
+ 
+ static void xgbe_cur_mode(struct xgbe_prv_data *pdata,
+ 			  enum xgbe_mode *mode)
+ {
+ 	unsigned int reg;
+ 
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL2);
+ 	if ((reg & MDIO_PCS_CTRL2_TYPE) == MDIO_PCS_CTRL2_10GBR)
+ 		*mode = XGBE_MODE_KR;
+ 	else
+ 		*mode = XGBE_MODE_KX;
+ }
+ 
+ static bool xgbe_in_kr_mode(struct xgbe_prv_data *pdata)
+ {
+ 	enum xgbe_mode mode;
+ 
+ 	xgbe_cur_mode(pdata, &mode);
+ 
+ 	return (mode == XGBE_MODE_KR);
+ }
+ 
+ static void xgbe_switch_mode(struct xgbe_prv_data *pdata)
+ {
+ 	/* If we are in KR switch to KX, and vice-versa */
+ 	if (xgbe_in_kr_mode(pdata)) {
+ 		if (pdata->speed_set == XGBE_SPEEDSET_1000_10000)
+ 			xgbe_gmii_mode(pdata);
+ 		else
+ 			xgbe_gmii_2500_mode(pdata);
+ 	} else {
+ 		xgbe_xgmii_mode(pdata);
+ 	}
+ }
+ 
+ static void xgbe_set_mode(struct xgbe_prv_data *pdata,
+ 			  enum xgbe_mode mode)
+ {
+ 	enum xgbe_mode cur_mode;
+ 
+ 	xgbe_cur_mode(pdata, &cur_mode);
+ 	if (mode != cur_mode)
+ 		xgbe_switch_mode(pdata);
+ }
+ 
+ static void xgbe_set_an(struct xgbe_prv_data *pdata, bool enable, bool restart)
+ {
+ 	unsigned int reg;
+ 
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_CTRL1);
+ 	reg &= ~MDIO_AN_CTRL1_ENABLE;
+ 
+ 	if (enable)
+ 		reg |= MDIO_AN_CTRL1_ENABLE;
+ 
+ 	if (restart)
+ 		reg |= MDIO_AN_CTRL1_RESTART;
+ 
+ 	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_CTRL1, reg);
+ }
+ 
+ static void xgbe_restart_an(struct xgbe_prv_data *pdata)
+ {
+ 	xgbe_set_an(pdata, true, true);
+ }
+ 
+ static void xgbe_disable_an(struct xgbe_prv_data *pdata)
+ {
+ 	xgbe_set_an(pdata, false, false);
+ }
+ 
+ static enum xgbe_an xgbe_an_tx_training(struct xgbe_prv_data *pdata,
+ 					enum xgbe_rx *state)
+ {
+ 	unsigned int ad_reg, lp_reg, reg;
+ 
+ 	*state = XGBE_RX_COMPLETE;
+ 
+ 	/* If we're not in KR mode then we're done */
+ 	if (!xgbe_in_kr_mode(pdata))
+ 		return XGBE_AN_PAGE_RECEIVED;
+ 
+ 	/* Enable/Disable FEC */
+ 	ad_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE + 2);
+ 	lp_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_LPA + 2);
+ 
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PMAPMD, MDIO_PMA_10GBR_FECCTRL);
+ 	reg &= ~(MDIO_PMA_10GBR_FECABLE_ABLE | MDIO_PMA_10GBR_FECABLE_ERRABLE);
+ 	if ((ad_reg & 0xc000) && (lp_reg & 0xc000))
+ 		reg |= pdata->fec_ability;
+ 
+ 	XMDIO_WRITE(pdata, MDIO_MMD_PMAPMD, MDIO_PMA_10GBR_FECCTRL, reg);
+ 
+ 	/* Start KR training */
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PMAPMD, MDIO_PMA_10GBR_PMD_CTRL);
+ 	if (reg & XGBE_KR_TRAINING_ENABLE) {
+ 		XSIR0_IOWRITE_BITS(pdata, SIR0_KR_RT_1, RESET, 1);
+ 
+ 		reg |= XGBE_KR_TRAINING_START;
+ 		XMDIO_WRITE(pdata, MDIO_MMD_PMAPMD, MDIO_PMA_10GBR_PMD_CTRL,
+ 			    reg);
+ 
+ 		XSIR0_IOWRITE_BITS(pdata, SIR0_KR_RT_1, RESET, 0);
+ 	}
+ 
+ 	return XGBE_AN_PAGE_RECEIVED;
+ }
+ 
+ static enum xgbe_an xgbe_an_tx_xnp(struct xgbe_prv_data *pdata,
+ 				   enum xgbe_rx *state)
+ {
+ 	u16 msg;
+ 
+ 	*state = XGBE_RX_XNP;
+ 
+ 	msg = XGBE_XNP_MCF_NULL_MESSAGE;
+ 	msg |= XGBE_XNP_MP_FORMATTED;
+ 
+ 	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_XNP + 2, 0);
+ 	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_XNP + 1, 0);
+ 	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_XNP, msg);
+ 
+ 	return XGBE_AN_PAGE_RECEIVED;
+ }
+ 
+ static enum xgbe_an xgbe_an_rx_bpa(struct xgbe_prv_data *pdata,
+ 				   enum xgbe_rx *state)
+ {
+ 	unsigned int link_support;
+ 	unsigned int reg, ad_reg, lp_reg;
+ 
+ 	/* Read Base Ability register 2 first */
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_LPA + 1);
+ 
+ 	/* Check for a supported mode, otherwise restart in a different one */
+ 	link_support = xgbe_in_kr_mode(pdata) ? 0x80 : 0x20;
+ 	if (!(reg & link_support))
+ 		return XGBE_AN_INCOMPAT_LINK;
+ 
+ 	/* Check Extended Next Page support */
+ 	ad_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE);
+ 	lp_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_LPA);
+ 
+ 	return ((ad_reg & XGBE_XNP_NP_EXCHANGE) ||
+ 		(lp_reg & XGBE_XNP_NP_EXCHANGE))
+ 	       ? xgbe_an_tx_xnp(pdata, state)
+ 	       : xgbe_an_tx_training(pdata, state);
+ }
+ 
+ static enum xgbe_an xgbe_an_rx_xnp(struct xgbe_prv_data *pdata,
+ 				   enum xgbe_rx *state)
+ {
+ 	unsigned int ad_reg, lp_reg;
+ 
+ 	/* Check Extended Next Page support */
+ 	ad_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_XNP);
+ 	lp_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_LPX);
+ 
+ 	return ((ad_reg & XGBE_XNP_NP_EXCHANGE) ||
+ 		(lp_reg & XGBE_XNP_NP_EXCHANGE))
+ 	       ? xgbe_an_tx_xnp(pdata, state)
+ 	       : xgbe_an_tx_training(pdata, state);
+ }
+ 
+ static enum xgbe_an xgbe_an_page_received(struct xgbe_prv_data *pdata)
+ {
+ 	enum xgbe_rx *state;
+ 	unsigned long an_timeout;
+ 	enum xgbe_an ret;
+ 
+ 	if (!pdata->an_start) {
+ 		pdata->an_start = jiffies;
+ 	} else {
+ 		an_timeout = pdata->an_start +
+ 			     msecs_to_jiffies(XGBE_AN_MS_TIMEOUT);
+ 		if (time_after(jiffies, an_timeout)) {
+ 			/* Auto-negotiation timed out, reset state */
+ 			pdata->kr_state = XGBE_RX_BPA;
+ 			pdata->kx_state = XGBE_RX_BPA;
+ 
+ 			pdata->an_start = jiffies;
+ 		}
+ 	}
+ 
+ 	state = xgbe_in_kr_mode(pdata) ? &pdata->kr_state
+ 					   : &pdata->kx_state;
+ 
+ 	switch (*state) {
+ 	case XGBE_RX_BPA:
+ 		ret = xgbe_an_rx_bpa(pdata, state);
+ 		break;
+ 
+ 	case XGBE_RX_XNP:
+ 		ret = xgbe_an_rx_xnp(pdata, state);
+ 		break;
+ 
+ 	default:
+ 		ret = XGBE_AN_ERROR;
+ 	}
+ 
+ 	return ret;
+ }
+ 
+ static enum xgbe_an xgbe_an_incompat_link(struct xgbe_prv_data *pdata)
+ {
+ 	/* Be sure we aren't looping trying to negotiate */
+ 	if (xgbe_in_kr_mode(pdata)) {
+ 		pdata->kr_state = XGBE_RX_ERROR;
+ 
+ 		if (!(pdata->phy.advertising & ADVERTISED_1000baseKX_Full) &&
+ 		    !(pdata->phy.advertising & ADVERTISED_2500baseX_Full))
+ 			return XGBE_AN_NO_LINK;
+ 
+ 		if (pdata->kx_state != XGBE_RX_BPA)
+ 			return XGBE_AN_NO_LINK;
+ 	} else {
+ 		pdata->kx_state = XGBE_RX_ERROR;
+ 
+ 		if (!(pdata->phy.advertising & ADVERTISED_10000baseKR_Full))
+ 			return XGBE_AN_NO_LINK;
+ 
+ 		if (pdata->kr_state != XGBE_RX_BPA)
+ 			return XGBE_AN_NO_LINK;
+ 	}
+ 
+ 	xgbe_disable_an(pdata);
+ 
+ 	xgbe_switch_mode(pdata);
+ 
+ 	xgbe_restart_an(pdata);
+ 
+ 	return XGBE_AN_INCOMPAT_LINK;
+ }
+ 
+ static irqreturn_t xgbe_an_isr(int irq, void *data)
+ {
+ 	struct xgbe_prv_data *pdata = (struct xgbe_prv_data *)data;
+ 
+ 	/* Interrupt reason must be read and cleared outside of IRQ context */
+ 	disable_irq_nosync(pdata->an_irq);
+ 
+ 	queue_work(pdata->an_workqueue, &pdata->an_irq_work);
+ 
+ 	return IRQ_HANDLED;
+ }
+ 
+ static void xgbe_an_irq_work(struct work_struct *work)
+ {
+ 	struct xgbe_prv_data *pdata = container_of(work,
+ 						   struct xgbe_prv_data,
+ 						   an_irq_work);
+ 
+ 	/* Avoid a race between enabling the IRQ and exiting the work by
+ 	 * waiting for the work to finish and then queueing it
+ 	 */
+ 	flush_work(&pdata->an_work);
+ 	queue_work(pdata->an_workqueue, &pdata->an_work);
+ }
+ 
+ static void xgbe_an_state_machine(struct work_struct *work)
+ {
+ 	struct xgbe_prv_data *pdata = container_of(work,
+ 						   struct xgbe_prv_data,
+ 						   an_work);
+ 	enum xgbe_an cur_state = pdata->an_state;
+ 	unsigned int int_reg, int_mask;
+ 
+ 	mutex_lock(&pdata->an_mutex);
+ 
+ 	/* Read the interrupt */
+ 	int_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_INT);
+ 	if (!int_reg)
+ 		goto out;
+ 
+ next_int:
+ 	if (int_reg & XGBE_AN_PG_RCV) {
+ 		pdata->an_state = XGBE_AN_PAGE_RECEIVED;
+ 		int_mask = XGBE_AN_PG_RCV;
+ 	} else if (int_reg & XGBE_AN_INC_LINK) {
+ 		pdata->an_state = XGBE_AN_INCOMPAT_LINK;
+ 		int_mask = XGBE_AN_INC_LINK;
+ 	} else if (int_reg & XGBE_AN_INT_CMPLT) {
+ 		pdata->an_state = XGBE_AN_COMPLETE;
+ 		int_mask = XGBE_AN_INT_CMPLT;
+ 	} else {
+ 		pdata->an_state = XGBE_AN_ERROR;
+ 		int_mask = 0;
+ 	}
+ 
+ 	/* Clear the interrupt to be processed */
+ 	int_reg &= ~int_mask;
+ 	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_INT, int_reg);
+ 
+ 	pdata->an_result = pdata->an_state;
+ 
+ again:
+ 	cur_state = pdata->an_state;
+ 
+ 	switch (pdata->an_state) {
+ 	case XGBE_AN_READY:
+ 		pdata->an_supported = 0;
+ 		break;
+ 
+ 	case XGBE_AN_PAGE_RECEIVED:
+ 		pdata->an_state = xgbe_an_page_received(pdata);
+ 		pdata->an_supported++;
+ 		break;
+ 
+ 	case XGBE_AN_INCOMPAT_LINK:
+ 		pdata->an_supported = 0;
+ 		pdata->parallel_detect = 0;
+ 		pdata->an_state = xgbe_an_incompat_link(pdata);
+ 		break;
+ 
+ 	case XGBE_AN_COMPLETE:
+ 		pdata->parallel_detect = pdata->an_supported ? 0 : 1;
+ 		netdev_dbg(pdata->netdev, "%s successful\n",
+ 			   pdata->an_supported ? "Auto negotiation"
+ 					       : "Parallel detection");
+ 		break;
+ 
+ 	case XGBE_AN_NO_LINK:
+ 		break;
+ 
+ 	default:
+ 		pdata->an_state = XGBE_AN_ERROR;
+ 	}
+ 
+ 	if (pdata->an_state == XGBE_AN_NO_LINK) {
+ 		int_reg = 0;
+ 		XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_INT, 0);
+ 	} else if (pdata->an_state == XGBE_AN_ERROR) {
+ 		netdev_err(pdata->netdev,
+ 			   "error during auto-negotiation, state=%u\n",
+ 			   cur_state);
+ 
+ 		int_reg = 0;
+ 		XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_INT, 0);
+ 	}
+ 
+ 	if (pdata->an_state >= XGBE_AN_COMPLETE) {
+ 		pdata->an_result = pdata->an_state;
+ 		pdata->an_state = XGBE_AN_READY;
+ 		pdata->kr_state = XGBE_RX_BPA;
+ 		pdata->kx_state = XGBE_RX_BPA;
+ 		pdata->an_start = 0;
+ 	}
+ 
+ 	if (cur_state != pdata->an_state)
+ 		goto again;
+ 
+ 	if (int_reg)
+ 		goto next_int;
+ 
+ out:
+ 	enable_irq(pdata->an_irq);
+ 
+ 	mutex_unlock(&pdata->an_mutex);
+ }
+ 
+ static void xgbe_an_init(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int reg;
+ 
+ 	/* Set up Advertisement register 3 first */
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE + 2);
+ 	if (pdata->phy.advertising & ADVERTISED_10000baseR_FEC)
+ 		reg |= 0xc000;
+ 	else
+ 		reg &= ~0xc000;
+ 
+ 	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE + 2, reg);
+ 
+ 	/* Set up Advertisement register 2 next */
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE + 1);
+ 	if (pdata->phy.advertising & ADVERTISED_10000baseKR_Full)
+ 		reg |= 0x80;
+ 	else
+ 		reg &= ~0x80;
+ 
+ 	if ((pdata->phy.advertising & ADVERTISED_1000baseKX_Full) ||
+ 	    (pdata->phy.advertising & ADVERTISED_2500baseX_Full))
+ 		reg |= 0x20;
+ 	else
+ 		reg &= ~0x20;
+ 
+ 	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE + 1, reg);
+ 
+ 	/* Set up Advertisement register 1 last */
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE);
+ 	if (pdata->phy.advertising & ADVERTISED_Pause)
+ 		reg |= 0x400;
+ 	else
+ 		reg &= ~0x400;
+ 
+ 	if (pdata->phy.advertising & ADVERTISED_Asym_Pause)
+ 		reg |= 0x800;
+ 	else
+ 		reg &= ~0x800;
+ 
+ 	/* We don't intend to perform XNP */
+ 	reg &= ~XGBE_XNP_NP_EXCHANGE;
+ 
+ 	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE, reg);
+ }
+ 
+ static const char *xgbe_phy_speed_string(int speed)
+ {
+ 	switch (speed) {
+ 	case SPEED_1000:
+ 		return "1Gbps";
+ 	case SPEED_2500:
+ 		return "2.5Gbps";
+ 	case SPEED_10000:
+ 		return "10Gbps";
+ 	case SPEED_UNKNOWN:
+ 		return "Unknown";
+ 	default:
+ 		return "Unsupported";
+ 	}
+ }
+ 
+ static void xgbe_phy_print_status(struct xgbe_prv_data *pdata)
+ {
+ 	if (pdata->phy.link)
+ 		netdev_info(pdata->netdev,
+ 			    "Link is Up - %s/%s - flow control %s\n",
+ 			    xgbe_phy_speed_string(pdata->phy.speed),
+ 			    pdata->phy.duplex == DUPLEX_FULL ? "Full" : "Half",
+ 			    pdata->phy.pause ? "rx/tx" : "off");
+ 	else
+ 		netdev_info(pdata->netdev, "Link is Down\n");
+ }
+ 
+ static void xgbe_phy_adjust_link(struct xgbe_prv_data *pdata)
+ {
+ 	int new_state = 0;
  
- 	DBGPR_MDIO("-->xgbe_mdio_write: prtad=%#x mmd_reg=%#x mmd_data=%#x\n",
- 		   prtad, mmd_reg, mmd_data);
+ 	if (pdata->phy.link) {
+ 		/* Flow control support */
+ 		if (pdata->pause_autoneg) {
+ 			if (pdata->phy.pause || pdata->phy.asym_pause) {
+ 				pdata->tx_pause = 1;
+ 				pdata->rx_pause = 1;
+ 			} else {
+ 				pdata->tx_pause = 0;
+ 				pdata->rx_pause = 0;
+ 			}
+ 		}
  
- 	hw_if->write_mmd_regs(pdata, prtad, mmd_reg, mmd_data);
+ 		if (pdata->tx_pause != pdata->phy_tx_pause) {
+ 			pdata->hw_if.config_tx_flow_control(pdata);
+ 			pdata->phy_tx_pause = pdata->tx_pause;
+ 		}
  
- 	DBGPR_MDIO("<--xgbe_mdio_write\n");
+ 		if (pdata->rx_pause != pdata->phy_rx_pause) {
+ 			pdata->hw_if.config_rx_flow_control(pdata);
+ 			pdata->phy_rx_pause = pdata->rx_pause;
+ 		}
+ 
+ 		/* Speed support */
+ 		if (pdata->phy_speed != pdata->phy.speed) {
+ 			new_state = 1;
+ 			pdata->phy_speed = pdata->phy.speed;
+ 		}
+ 
+ 		if (pdata->phy_link != pdata->phy.link) {
+ 			new_state = 1;
+ 			pdata->phy_link = pdata->phy.link;
+ 		}
+ 	} else if (pdata->phy_link) {
+ 		new_state = 1;
+ 		pdata->phy_link = 0;
+ 		pdata->phy_speed = SPEED_UNKNOWN;
+ 	}
+ 
+ 	if (new_state && netif_msg_link(pdata))
+ 		xgbe_phy_print_status(pdata);
+ }
+ 
+ static int xgbe_phy_config_fixed(struct xgbe_prv_data *pdata)
+ {
+ 	/* Disable auto-negotiation */
+ 	xgbe_disable_an(pdata);
+ 
+ 	/* Validate/Set specified speed */
+ 	switch (pdata->phy.speed) {
+ 	case SPEED_10000:
+ 		xgbe_set_mode(pdata, XGBE_MODE_KR);
+ 		break;
+ 
+ 	case SPEED_2500:
+ 	case SPEED_1000:
+ 		xgbe_set_mode(pdata, XGBE_MODE_KX);
+ 		break;
+ 
+ 	default:
+ 		return -EINVAL;
+ 	}
+ 
+ 	/* Validate duplex mode */
+ 	if (pdata->phy.duplex != DUPLEX_FULL)
+ 		return -EINVAL;
+ 
+ 	pdata->phy.pause = 0;
+ 	pdata->phy.asym_pause = 0;
  
  	return 0;
  }
  
++<<<<<<< HEAD
 +static void xgbe_adjust_link(struct net_device *netdev)
 +{
 +	struct xgbe_prv_data *pdata = netdev_priv(netdev);
 +	struct xgbe_hw_if *hw_if = &pdata->hw_if;
 +	struct phy_device *phydev = pdata->phydev;
 +	int new_state = 0;
 +
 +	if (phydev == NULL)
 +		return;
 +
 +	DBGPR_MDIO("-->xgbe_adjust_link: address=%d, newlink=%d, curlink=%d\n",
 +		   phydev->addr, phydev->link, pdata->phy_link);
 +
 +	if (phydev->link) {
 +		/* Flow control support */
 +		if (pdata->pause_autoneg) {
 +			if (phydev->pause || phydev->asym_pause) {
 +				pdata->tx_pause = 1;
 +				pdata->rx_pause = 1;
 +			} else {
 +				pdata->tx_pause = 0;
 +				pdata->rx_pause = 0;
 +			}
 +		}
 +
 +		if (pdata->tx_pause != pdata->phy_tx_pause) {
 +			hw_if->config_tx_flow_control(pdata);
 +			pdata->phy_tx_pause = pdata->tx_pause;
 +		}
 +
 +		if (pdata->rx_pause != pdata->phy_rx_pause) {
 +			hw_if->config_rx_flow_control(pdata);
 +			pdata->phy_rx_pause = pdata->rx_pause;
 +		}
 +
 +		/* Speed support */
 +		if (phydev->speed != pdata->phy_speed) {
 +			new_state = 1;
 +
 +			switch (phydev->speed) {
 +			case SPEED_10000:
 +				hw_if->set_xgmii_speed(pdata);
 +				break;
 +
 +			case SPEED_2500:
 +				hw_if->set_gmii_2500_speed(pdata);
 +				break;
 +
 +			case SPEED_1000:
 +				hw_if->set_gmii_speed(pdata);
 +				break;
 +			}
 +			pdata->phy_speed = phydev->speed;
 +		}
 +
 +		if (phydev->link != pdata->phy_link) {
 +			new_state = 1;
 +			pdata->phy_link = 1;
 +		}
 +	} else if (pdata->phy_link) {
 +		new_state = 1;
 +		pdata->phy_link = 0;
 +		pdata->phy_speed = SPEED_UNKNOWN;
 +	}
 +
 +	if (new_state)
 +		phy_print_status(phydev);
 +
 +	DBGPR_MDIO("<--xgbe_adjust_link\n");
 +}
 +
 +void xgbe_dump_phy_registers(struct xgbe_prv_data *pdata)
 +{
 +	struct device *dev = pdata->dev;
 +	struct phy_device *phydev = pdata->mii->phy_map[XGBE_PRTAD];
 +	int i;
++=======
+ static int __xgbe_phy_config_aneg(struct xgbe_prv_data *pdata)
+ {
+ 	set_bit(XGBE_LINK_INIT, &pdata->dev_state);
+ 	pdata->link_check = jiffies;
+ 
+ 	if (pdata->phy.autoneg != AUTONEG_ENABLE)
+ 		return xgbe_phy_config_fixed(pdata);
+ 
+ 	/* Disable auto-negotiation interrupt */
+ 	disable_irq(pdata->an_irq);
+ 
+ 	/* Start auto-negotiation in a supported mode */
+ 	if (pdata->phy.advertising & ADVERTISED_10000baseKR_Full) {
+ 		xgbe_set_mode(pdata, XGBE_MODE_KR);
+ 	} else if ((pdata->phy.advertising & ADVERTISED_1000baseKX_Full) ||
+ 		   (pdata->phy.advertising & ADVERTISED_2500baseX_Full)) {
+ 		xgbe_set_mode(pdata, XGBE_MODE_KX);
+ 	} else {
+ 		enable_irq(pdata->an_irq);
+ 		return -EINVAL;
+ 	}
+ 
+ 	/* Disable and stop any in progress auto-negotiation */
+ 	xgbe_disable_an(pdata);
+ 
+ 	/* Clear any auto-negotitation interrupts */
+ 	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_INT, 0);
+ 
+ 	pdata->an_result = XGBE_AN_READY;
+ 	pdata->an_state = XGBE_AN_READY;
+ 	pdata->kr_state = XGBE_RX_BPA;
+ 	pdata->kx_state = XGBE_RX_BPA;
+ 
+ 	/* Re-enable auto-negotiation interrupt */
+ 	enable_irq(pdata->an_irq);
+ 
+ 	/* Set up advertisement registers based on current settings */
+ 	xgbe_an_init(pdata);
+ 
+ 	/* Enable and start auto-negotiation */
+ 	xgbe_restart_an(pdata);
+ 
+ 	return 0;
+ }
+ 
+ static int xgbe_phy_config_aneg(struct xgbe_prv_data *pdata)
+ {
+ 	int ret;
+ 
+ 	mutex_lock(&pdata->an_mutex);
+ 
+ 	ret = __xgbe_phy_config_aneg(pdata);
+ 	if (ret)
+ 		set_bit(XGBE_LINK_ERR, &pdata->dev_state);
+ 	else
+ 		clear_bit(XGBE_LINK_ERR, &pdata->dev_state);
+ 
+ 	mutex_unlock(&pdata->an_mutex);
+ 
+ 	return ret;
+ }
+ 
+ static bool xgbe_phy_aneg_done(struct xgbe_prv_data *pdata)
+ {
+ 	return (pdata->an_result == XGBE_AN_COMPLETE);
+ }
+ 
+ static void xgbe_check_link_timeout(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned long link_timeout;
+ 
+ 	link_timeout = pdata->link_check + (XGBE_LINK_TIMEOUT * HZ);
+ 	if (time_after(jiffies, link_timeout))
+ 		xgbe_phy_config_aneg(pdata);
+ }
+ 
+ static void xgbe_phy_status_force(struct xgbe_prv_data *pdata)
+ {
+ 	if (xgbe_in_kr_mode(pdata)) {
+ 		pdata->phy.speed = SPEED_10000;
+ 	} else {
+ 		switch (pdata->speed_set) {
+ 		case XGBE_SPEEDSET_1000_10000:
+ 			pdata->phy.speed = SPEED_1000;
+ 			break;
+ 
+ 		case XGBE_SPEEDSET_2500_10000:
+ 			pdata->phy.speed = SPEED_2500;
+ 			break;
+ 		}
+ 	}
+ 	pdata->phy.duplex = DUPLEX_FULL;
+ 	pdata->phy.pause = 0;
+ 	pdata->phy.asym_pause = 0;
+ }
+ 
+ static void xgbe_phy_status_aneg(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int ad_reg, lp_reg;
+ 
+ 	pdata->phy.lp_advertising = 0;
+ 
+ 	if ((pdata->phy.autoneg != AUTONEG_ENABLE) || pdata->parallel_detect)
+ 		return xgbe_phy_status_force(pdata);
+ 
+ 	pdata->phy.lp_advertising |= ADVERTISED_Autoneg;
+ 	pdata->phy.lp_advertising |= ADVERTISED_Backplane;
+ 
+ 	/* Compare Advertisement and Link Partner register 1 */
+ 	ad_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE);
+ 	lp_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_LPA);
+ 	if (lp_reg & 0x400)
+ 		pdata->phy.lp_advertising |= ADVERTISED_Pause;
+ 	if (lp_reg & 0x800)
+ 		pdata->phy.lp_advertising |= ADVERTISED_Asym_Pause;
+ 
+ 	ad_reg &= lp_reg;
+ 	pdata->phy.pause = (ad_reg & 0x400) ? 1 : 0;
+ 	pdata->phy.asym_pause = (ad_reg & 0x800) ? 1 : 0;
+ 
+ 	/* Compare Advertisement and Link Partner register 2 */
+ 	ad_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE + 1);
+ 	lp_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_LPA + 1);
+ 	if (lp_reg & 0x80)
+ 		pdata->phy.lp_advertising |= ADVERTISED_10000baseKR_Full;
+ 	if (lp_reg & 0x20) {
+ 		switch (pdata->speed_set) {
+ 		case XGBE_SPEEDSET_1000_10000:
+ 			pdata->phy.lp_advertising |= ADVERTISED_1000baseKX_Full;
+ 			break;
+ 		case XGBE_SPEEDSET_2500_10000:
+ 			pdata->phy.lp_advertising |= ADVERTISED_2500baseX_Full;
+ 			break;
+ 		}
+ 	}
+ 
+ 	ad_reg &= lp_reg;
+ 	if (ad_reg & 0x80) {
+ 		pdata->phy.speed = SPEED_10000;
+ 		xgbe_set_mode(pdata, XGBE_MODE_KR);
+ 	} else if (ad_reg & 0x20) {
+ 		switch (pdata->speed_set) {
+ 		case XGBE_SPEEDSET_1000_10000:
+ 			pdata->phy.speed = SPEED_1000;
+ 			break;
+ 
+ 		case XGBE_SPEEDSET_2500_10000:
+ 			pdata->phy.speed = SPEED_2500;
+ 			break;
+ 		}
+ 
+ 		xgbe_set_mode(pdata, XGBE_MODE_KX);
+ 	} else {
+ 		pdata->phy.speed = SPEED_UNKNOWN;
+ 	}
+ 
+ 	/* Compare Advertisement and Link Partner register 3 */
+ 	ad_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE + 2);
+ 	lp_reg = XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_LPA + 2);
+ 	if (lp_reg & 0xc000)
+ 		pdata->phy.lp_advertising |= ADVERTISED_10000baseR_FEC;
+ 
+ 	pdata->phy.duplex = DUPLEX_FULL;
+ }
+ 
+ static void xgbe_phy_status(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int reg, link_aneg;
+ 
+ 	if (test_bit(XGBE_LINK_ERR, &pdata->dev_state)) {
+ 		if (test_and_clear_bit(XGBE_LINK, &pdata->dev_state))
+ 			netif_carrier_off(pdata->netdev);
+ 
+ 		pdata->phy.link = 0;
+ 		goto adjust_link;
+ 	}
+ 
+ 	link_aneg = (pdata->phy.autoneg == AUTONEG_ENABLE);
+ 
+ 	/* Get the link status. Link status is latched low, so read
+ 	 * once to clear and then read again to get current state
+ 	 */
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_STAT1);
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_STAT1);
+ 	pdata->phy.link = (reg & MDIO_STAT1_LSTATUS) ? 1 : 0;
+ 
+ 	if (pdata->phy.link) {
+ 		if (link_aneg && !xgbe_phy_aneg_done(pdata)) {
+ 			xgbe_check_link_timeout(pdata);
+ 			return;
+ 		}
+ 
+ 		xgbe_phy_status_aneg(pdata);
+ 
+ 		if (test_bit(XGBE_LINK_INIT, &pdata->dev_state))
+ 			clear_bit(XGBE_LINK_INIT, &pdata->dev_state);
+ 
+ 		if (!test_bit(XGBE_LINK, &pdata->dev_state)) {
+ 			set_bit(XGBE_LINK, &pdata->dev_state);
+ 			netif_carrier_on(pdata->netdev);
+ 		}
+ 	} else {
+ 		if (test_bit(XGBE_LINK_INIT, &pdata->dev_state)) {
+ 			xgbe_check_link_timeout(pdata);
+ 
+ 			if (link_aneg)
+ 				return;
+ 		}
+ 
+ 		xgbe_phy_status_aneg(pdata);
+ 
+ 		if (test_bit(XGBE_LINK, &pdata->dev_state)) {
+ 			clear_bit(XGBE_LINK, &pdata->dev_state);
+ 			netif_carrier_off(pdata->netdev);
+ 		}
+ 	}
+ 
+ adjust_link:
+ 	xgbe_phy_adjust_link(pdata);
+ }
+ 
+ static void xgbe_phy_stop(struct xgbe_prv_data *pdata)
+ {
+ 	/* Disable auto-negotiation */
+ 	xgbe_disable_an(pdata);
+ 
+ 	/* Disable auto-negotiation interrupts */
+ 	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_INTMASK, 0);
+ 
+ 	devm_free_irq(pdata->dev, pdata->an_irq, pdata);
+ 
+ 	pdata->phy.link = 0;
+ 	if (test_and_clear_bit(XGBE_LINK, &pdata->dev_state))
+ 		netif_carrier_off(pdata->netdev);
+ 
+ 	xgbe_phy_adjust_link(pdata);
+ }
+ 
+ static int xgbe_phy_start(struct xgbe_prv_data *pdata)
+ {
+ 	struct net_device *netdev = pdata->netdev;
+ 	int ret;
+ 
+ 	ret = devm_request_irq(pdata->dev, pdata->an_irq,
+ 			       xgbe_an_isr, 0, pdata->an_name,
+ 			       pdata);
+ 	if (ret) {
+ 		netdev_err(netdev, "phy irq request failed\n");
+ 		return ret;
+ 	}
+ 
+ 	/* Set initial mode - call the mode setting routines
+ 	 * directly to insure we are properly configured
+ 	 */
+ 	if (pdata->phy.advertising & ADVERTISED_10000baseKR_Full) {
+ 		xgbe_xgmii_mode(pdata);
+ 	} else if (pdata->phy.advertising & ADVERTISED_1000baseKX_Full) {
+ 		xgbe_gmii_mode(pdata);
+ 	} else if (pdata->phy.advertising & ADVERTISED_2500baseX_Full) {
+ 		xgbe_gmii_2500_mode(pdata);
+ 	} else {
+ 		ret = -EINVAL;
+ 		goto err_irq;
+ 	}
+ 
+ 	/* Set up advertisement registers based on current settings */
+ 	xgbe_an_init(pdata);
+ 
+ 	/* Enable auto-negotiation interrupts */
+ 	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_INTMASK, 0x07);
+ 
+ 	return xgbe_phy_config_aneg(pdata);
+ 
+ err_irq:
+ 	devm_free_irq(pdata->dev, pdata->an_irq, pdata);
+ 
+ 	return ret;
+ }
+ 
+ static int xgbe_phy_reset(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int count, reg;
+ 
+ 	reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL1);
+ 	reg |= MDIO_CTRL1_RESET;
+ 	XMDIO_WRITE(pdata, MDIO_MMD_PCS, MDIO_CTRL1, reg);
+ 
+ 	count = 50;
+ 	do {
+ 		msleep(20);
+ 		reg = XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL1);
+ 	} while ((reg & MDIO_CTRL1_RESET) && --count);
+ 
+ 	if (reg & MDIO_CTRL1_RESET)
+ 		return -ETIMEDOUT;
+ 
+ 	/* Disable auto-negotiation for now */
+ 	xgbe_disable_an(pdata);
+ 
+ 	/* Clear auto-negotiation interrupts */
+ 	XMDIO_WRITE(pdata, MDIO_MMD_AN, MDIO_AN_INT, 0);
+ 
+ 	return 0;
+ }
+ 
+ static void xgbe_dump_phy_registers(struct xgbe_prv_data *pdata)
+ {
+ 	struct device *dev = pdata->dev;
 -
 -	dev_dbg(dev, "\n************* PHY Reg dump **********************\n");
 -
 -	dev_dbg(dev, "PCS Control Reg (%#04x) = %#04x\n", MDIO_CTRL1,
 -		XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL1));
 -	dev_dbg(dev, "PCS Status Reg (%#04x) = %#04x\n", MDIO_STAT1,
 -		XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_STAT1));
 -	dev_dbg(dev, "Phy Id (PHYS ID 1 %#04x)= %#04x\n", MDIO_DEVID1,
 -		XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_DEVID1));
 -	dev_dbg(dev, "Phy Id (PHYS ID 2 %#04x)= %#04x\n", MDIO_DEVID2,
 -		XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_DEVID2));
 -	dev_dbg(dev, "Devices in Package (%#04x)= %#04x\n", MDIO_DEVS1,
 -		XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_DEVS1));
 -	dev_dbg(dev, "Devices in Package (%#04x)= %#04x\n", MDIO_DEVS2,
 -		XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_DEVS2));
 -
 -	dev_dbg(dev, "Auto-Neg Control Reg (%#04x) = %#04x\n", MDIO_CTRL1,
 -		XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_CTRL1));
 -	dev_dbg(dev, "Auto-Neg Status Reg (%#04x) = %#04x\n", MDIO_STAT1,
 -		XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_STAT1));
 -	dev_dbg(dev, "Auto-Neg Ad Reg 1 (%#04x) = %#04x\n",
 -		MDIO_AN_ADVERTISE,
 -		XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE));
 -	dev_dbg(dev, "Auto-Neg Ad Reg 2 (%#04x) = %#04x\n",
 -		MDIO_AN_ADVERTISE + 1,
 -		XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE + 1));
 -	dev_dbg(dev, "Auto-Neg Ad Reg 3 (%#04x) = %#04x\n",
 -		MDIO_AN_ADVERTISE + 2,
 -		XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE + 2));
 -	dev_dbg(dev, "Auto-Neg Completion Reg (%#04x) = %#04x\n",
 -		MDIO_AN_COMP_STAT,
 -		XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_COMP_STAT));
 -
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
 +
 +	dev_alert(dev, "\n************* PHY Reg dump **********************\n");
 +
 +	dev_alert(dev, "PCS Control Reg (%#04x) = %#04x\n", MDIO_CTRL1,
 +		  XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_CTRL1));
 +	dev_alert(dev, "PCS Status Reg (%#04x) = %#04x\n", MDIO_STAT1,
 +		  XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_STAT1));
 +	dev_alert(dev, "Phy Id (PHYS ID 1 %#04x)= %#04x\n", MDIO_DEVID1,
 +		  XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_DEVID1));
 +	dev_alert(dev, "Phy Id (PHYS ID 2 %#04x)= %#04x\n", MDIO_DEVID2,
 +		  XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_DEVID2));
 +	dev_alert(dev, "Devices in Package (%#04x)= %#04x\n", MDIO_DEVS1,
 +		  XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_DEVS1));
 +	dev_alert(dev, "Devices in Package (%#04x)= %#04x\n", MDIO_DEVS2,
 +		  XMDIO_READ(pdata, MDIO_MMD_PCS, MDIO_DEVS2));
 +
 +	dev_alert(dev, "Auto-Neg Control Reg (%#04x) = %#04x\n", MDIO_CTRL1,
 +		  XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_CTRL1));
 +	dev_alert(dev, "Auto-Neg Status Reg (%#04x) = %#04x\n", MDIO_STAT1,
 +		  XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_STAT1));
 +	dev_alert(dev, "Auto-Neg Ad Reg 1 (%#04x) = %#04x\n",
 +		  MDIO_AN_ADVERTISE,
 +		  XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE));
 +	dev_alert(dev, "Auto-Neg Ad Reg 2 (%#04x) = %#04x\n",
 +		  MDIO_AN_ADVERTISE + 1,
 +		  XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE + 1));
 +	dev_alert(dev, "Auto-Neg Ad Reg 3 (%#04x) = %#04x\n",
 +		  MDIO_AN_ADVERTISE + 2,
 +		  XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_ADVERTISE + 2));
 +	dev_alert(dev, "Auto-Neg Completion Reg (%#04x) = %#04x\n",
 +		  MDIO_AN_COMP_STAT,
 +		  XMDIO_READ(pdata, MDIO_MMD_AN, MDIO_AN_COMP_STAT));
 +
++<<<<<<< HEAD
 +	dev_alert(dev, "MMD Device Mask = %#x\n",
 +		  phydev->c45_ids.devices_in_package);
 +	for (i = 0; i < ARRAY_SIZE(phydev->c45_ids.device_ids); i++)
 +		dev_alert(dev, "  MMD %d: ID = %#08x\n", i,
 +			  phydev->c45_ids.device_ids[i]);
 +
 +	dev_alert(dev, "\n*************************************************\n");
++=======
+ 	dev_dbg(dev, "\n*************************************************\n");
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  }
  
- int xgbe_mdio_register(struct xgbe_prv_data *pdata)
+ static void xgbe_phy_init(struct xgbe_prv_data *pdata)
  {
++<<<<<<< HEAD
 +	struct net_device *netdev = pdata->netdev;
 +	struct device_node *phy_node;
 +	struct mii_bus *mii;
 +	struct phy_device *phydev;
 +	int ret = 0;
 +
 +	DBGPR("-->xgbe_mdio_register\n");
 +
 +	/* Retrieve the phy-handle */
 +	phy_node = of_parse_phandle(pdata->dev->of_node, "phy-handle", 0);
 +	if (!phy_node) {
 +		dev_err(pdata->dev, "unable to parse phy-handle\n");
 +		return -EINVAL;
 +	}
 +
 +	/* Register with the MDIO bus */
 +	mii = mdiobus_alloc();
 +	if (mii == NULL) {
 +		dev_err(pdata->dev, "mdiobus_alloc failed\n");
 +		ret = -ENOMEM;
 +		goto err_node_get;
 +	}
 +
 +	/* Register on the MDIO bus (don't probe any PHYs) */
 +	mii->name = XGBE_PHY_NAME;
 +	mii->read = xgbe_mdio_read;
 +	mii->write = xgbe_mdio_write;
 +	snprintf(mii->id, sizeof(mii->id), "%s", pdata->mii_bus_id);
 +	mii->priv = pdata;
 +	mii->phy_mask = ~0;
 +	mii->parent = pdata->dev;
 +	ret = mdiobus_register(mii);
 +	if (ret) {
 +		dev_err(pdata->dev, "mdiobus_register failed\n");
 +		goto err_mdiobus_alloc;
 +	}
 +	DBGPR("  mdiobus_register succeeded for %s\n", pdata->mii_bus_id);
 +
 +	/* Probe the PCS using Clause 45 */
 +	phydev = get_phy_device(mii, XGBE_PRTAD, true);
 +	if (IS_ERR(phydev) || !phydev ||
 +	    !phydev->c45_ids.device_ids[MDIO_MMD_PCS]) {
 +		dev_err(pdata->dev, "get_phy_device failed\n");
 +		ret = phydev ? PTR_ERR(phydev) : -ENOLINK;
 +		goto err_mdiobus_register;
 +	}
 +	request_module(MDIO_MODULE_PREFIX MDIO_ID_FMT,
 +		       MDIO_ID_ARGS(phydev->c45_ids.device_ids[MDIO_MMD_PCS]));
 +
 +	of_node_get(phy_node);
 +	phydev->dev.of_node = phy_node;
 +	ret = phy_device_register(phydev);
 +	if (ret) {
 +		dev_err(pdata->dev, "phy_device_register failed\n");
 +		of_node_put(phy_node);
 +		goto err_phy_device;
 +	}
 +	if (!phydev->dev.driver) {
 +		dev_err(pdata->dev, "phy driver probe failed\n");
 +		ret = -EIO;
 +		goto err_phy_device;
 +	}
 +
 +	/* Add a reference to the PHY driver so it can't be unloaded */
 +	pdata->phy_module = phydev->dev.driver->owner;
 +	if (!try_module_get(pdata->phy_module)) {
 +		dev_err(pdata->dev, "try_module_get failed\n");
 +		ret = -EIO;
 +		goto err_phy_device;
 +	}
 +
 +	pdata->mii = mii;
 +	pdata->mdio_mmd = MDIO_MMD_PCS;
 +
 +	pdata->phy_link = -1;
 +	pdata->phy_speed = SPEED_UNKNOWN;
 +	pdata->phy_tx_pause = pdata->tx_pause;
 +	pdata->phy_rx_pause = pdata->rx_pause;
 +
 +	ret = phy_connect_direct(netdev, phydev, &xgbe_adjust_link,
 +				 pdata->phy_mode);
 +	if (ret) {
 +		netdev_err(netdev, "phy_connect_direct failed\n");
 +		goto err_phy_device;
 +	}
 +
 +	if (!phydev->drv || (phydev->drv->phy_id == 0)) {
 +		netdev_err(netdev, "phy_id not valid\n");
 +		ret = -ENODEV;
 +		goto err_phy_connect;
 +	}
 +	DBGPR("  phy_connect_direct succeeded for PHY %s, link=%d\n",
 +	      dev_name(&phydev->dev), phydev->link);
 +
 +	phydev->autoneg = pdata->default_autoneg;
 +	if (phydev->autoneg == AUTONEG_DISABLE) {
 +		phydev->speed = pdata->default_speed;
 +		phydev->duplex = DUPLEX_FULL;
 +
 +		phydev->advertising &= ~ADVERTISED_Autoneg;
++=======
+ 	mutex_init(&pdata->an_mutex);
+ 	INIT_WORK(&pdata->an_irq_work, xgbe_an_irq_work);
+ 	INIT_WORK(&pdata->an_work, xgbe_an_state_machine);
+ 	pdata->mdio_mmd = MDIO_MMD_PCS;
+ 
+ 	/* Initialize supported features */
+ 	pdata->phy.supported = SUPPORTED_Autoneg;
+ 	pdata->phy.supported |= SUPPORTED_Pause | SUPPORTED_Asym_Pause;
+ 	pdata->phy.supported |= SUPPORTED_Backplane;
+ 	pdata->phy.supported |= SUPPORTED_10000baseKR_Full;
+ 	switch (pdata->speed_set) {
+ 	case XGBE_SPEEDSET_1000_10000:
+ 		pdata->phy.supported |= SUPPORTED_1000baseKX_Full;
+ 		break;
+ 	case XGBE_SPEEDSET_2500_10000:
+ 		pdata->phy.supported |= SUPPORTED_2500baseX_Full;
+ 		break;
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  	}
  
- 	pdata->phydev = phydev;
+ 	pdata->fec_ability = XMDIO_READ(pdata, MDIO_MMD_PMAPMD,
+ 					MDIO_PMA_10GBR_FECABLE);
+ 	pdata->fec_ability &= (MDIO_PMA_10GBR_FECABLE_ABLE |
+ 			       MDIO_PMA_10GBR_FECABLE_ERRABLE);
+ 	if (pdata->fec_ability & MDIO_PMA_10GBR_FECABLE_ABLE)
+ 		pdata->phy.supported |= SUPPORTED_10000baseR_FEC;
+ 
+ 	pdata->phy.advertising = pdata->phy.supported;
+ 
+ 	pdata->phy.address = 0;
  
+ 	pdata->phy.autoneg = AUTONEG_ENABLE;
+ 	pdata->phy.speed = SPEED_UNKNOWN;
+ 	pdata->phy.duplex = DUPLEX_UNKNOWN;
+ 
+ 	pdata->phy.link = 0;
+ 
++<<<<<<< HEAD
 +	of_node_put(phy_node);
 +
 +	DBGPHY_REGS(pdata);
 +
 +	DBGPR("<--xgbe_mdio_register\n");
 +
 +	return 0;
 +
 +err_phy_connect:
 +	phy_disconnect(phydev);
 +
 +err_phy_device:
 +	phy_device_free(phydev);
 +
 +err_mdiobus_register:
 +	mdiobus_unregister(mii);
 +
 +err_mdiobus_alloc:
 +	mdiobus_free(mii);
 +
 +err_node_get:
 +	of_node_put(phy_node);
 +
 +	return ret;
++=======
+ 	if (netif_msg_drv(pdata))
+ 		xgbe_dump_phy_registers(pdata);
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  }
  
- void xgbe_mdio_unregister(struct xgbe_prv_data *pdata)
+ void xgbe_init_function_ptrs_phy(struct xgbe_phy_if *phy_if)
  {
- 	DBGPR("-->xgbe_mdio_unregister\n");
+ 	phy_if->phy_init        = xgbe_phy_init;
  
++<<<<<<< HEAD
 +	phy_disconnect(pdata->phydev);
 +	pdata->phydev = NULL;
++=======
+ 	phy_if->phy_reset       = xgbe_phy_reset;
+ 	phy_if->phy_start       = xgbe_phy_start;
+ 	phy_if->phy_stop        = xgbe_phy_stop;
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  
- 	module_put(pdata->phy_module);
- 	pdata->phy_module = NULL;
- 
- 	mdiobus_unregister(pdata->mii);
- 	pdata->mii->priv = NULL;
- 
- 	mdiobus_free(pdata->mii);
- 	pdata->mii = NULL;
- 
- 	DBGPR("<--xgbe_mdio_unregister\n");
+ 	phy_if->phy_status      = xgbe_phy_status;
+ 	phy_if->phy_config_aneg = xgbe_phy_config_aneg;
  }
diff --cc drivers/net/ethernet/amd/xgbe/xgbe.h
index 1903f878545a,b6aecc95e63f..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe.h
+++ b/drivers/net/ethernet/amd/xgbe/xgbe.h
@@@ -121,10 -121,15 +121,10 @@@
  #include <linux/netdevice.h>
  #include <linux/workqueue.h>
  #include <linux/phy.h>
 -#include <linux/if_vlan.h>
 -#include <linux/bitops.h>
 -#include <linux/ptp_clock_kernel.h>
 -#include <linux/timecounter.h>
 -#include <linux/net_tstamp.h>
 -#include <net/dcbnl.h>
 +
  
  #define XGBE_DRV_NAME		"amd-xgbe"
- #define XGBE_DRV_VERSION	"1.0.0-a"
+ #define XGBE_DRV_VERSION	"1.0.1"
  #define XGBE_DRV_DESC		"AMD 10 Gigabit Ethernet Driver"
  
  /* Descriptor related defines */
@@@ -158,9 -178,31 +158,37 @@@
  #define XGMAC_JUMBO_PACKET_MTU	9000
  #define XGMAC_MAX_JUMBO_PACKET	9018
  
++<<<<<<< HEAD
 +/* MDIO bus phy name */
 +#define XGBE_PHY_NAME		"amd_xgbe_phy"
 +#define XGBE_PRTAD		0
++=======
+ /* Common property names */
+ #define XGBE_MAC_ADDR_PROPERTY	"mac-address"
+ #define XGBE_PHY_MODE_PROPERTY	"phy-mode"
+ #define XGBE_DMA_IRQS_PROPERTY	"amd,per-channel-interrupt"
+ #define XGBE_SPEEDSET_PROPERTY	"amd,speed-set"
+ #define XGBE_BLWC_PROPERTY	"amd,serdes-blwc"
+ #define XGBE_CDR_RATE_PROPERTY	"amd,serdes-cdr-rate"
+ #define XGBE_PQ_SKEW_PROPERTY	"amd,serdes-pq-skew"
+ #define XGBE_TX_AMP_PROPERTY	"amd,serdes-tx-amp"
+ #define XGBE_DFE_CFG_PROPERTY	"amd,serdes-dfe-tap-config"
+ #define XGBE_DFE_ENA_PROPERTY	"amd,serdes-dfe-tap-enable"
+ 
+ /* Device-tree clock names */
+ #define XGBE_DMA_CLOCK		"dma_clk"
+ #define XGBE_PTP_CLOCK		"ptp_clk"
+ 
+ /* ACPI property names */
+ #define XGBE_ACPI_DMA_FREQ	"amd,dma-freq"
+ #define XGBE_ACPI_PTP_FREQ	"amd,ptp-freq"
+ 
+ /* Timestamp support - values based on 50MHz PTP clock
+  *   50MHz => 20 nsec
+  */
+ #define XGBE_TSTAMP_SSINC	20
+ #define XGBE_TSTAMP_SNSINC	0
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  
  /* Driver PMT macros */
  #define XGMAC_DRIVER_CONTEXT	1
@@@ -194,7 -235,58 +222,50 @@@
  /* Flow control queue count */
  #define XGMAC_MAX_FLOW_CONTROL_QUEUES	8
  
 -/* Maximum MAC address hash table size (256 bits = 8 bytes) */
 -#define XGBE_MAC_HASH_TABLE_SIZE	8
 -
 -/* Receive Side Scaling */
 -#define XGBE_RSS_HASH_KEY_SIZE		40
 -#define XGBE_RSS_MAX_TABLE_SIZE		256
 -#define XGBE_RSS_LOOKUP_TABLE_TYPE	0
 -#define XGBE_RSS_HASH_KEY_TYPE		1
  
+ /* Auto-negotiation */
+ #define XGBE_AN_MS_TIMEOUT		500
+ #define XGBE_LINK_TIMEOUT		10
+ 
+ #define XGBE_AN_INT_CMPLT		0x01
+ #define XGBE_AN_INC_LINK		0x02
+ #define XGBE_AN_PG_RCV			0x04
+ #define XGBE_AN_INT_MASK		0x07
+ 
+ /* Rate-change complete wait/retry count */
+ #define XGBE_RATECHANGE_COUNT		500
+ 
+ /* Default SerDes settings */
+ #define XGBE_SPEED_10000_BLWC		0
+ #define XGBE_SPEED_10000_CDR		0x7
+ #define XGBE_SPEED_10000_PLL		0x1
+ #define XGBE_SPEED_10000_PQ		0x12
+ #define XGBE_SPEED_10000_RATE		0x0
+ #define XGBE_SPEED_10000_TXAMP		0xa
+ #define XGBE_SPEED_10000_WORD		0x7
+ #define XGBE_SPEED_10000_DFE_TAP_CONFIG	0x1
+ #define XGBE_SPEED_10000_DFE_TAP_ENABLE	0x7f
+ 
+ #define XGBE_SPEED_2500_BLWC		1
+ #define XGBE_SPEED_2500_CDR		0x2
+ #define XGBE_SPEED_2500_PLL		0x0
+ #define XGBE_SPEED_2500_PQ		0xa
+ #define XGBE_SPEED_2500_RATE		0x1
+ #define XGBE_SPEED_2500_TXAMP		0xf
+ #define XGBE_SPEED_2500_WORD		0x1
+ #define XGBE_SPEED_2500_DFE_TAP_CONFIG	0x3
+ #define XGBE_SPEED_2500_DFE_TAP_ENABLE	0x0
+ 
+ #define XGBE_SPEED_1000_BLWC		1
+ #define XGBE_SPEED_1000_CDR		0x2
+ #define XGBE_SPEED_1000_PLL		0x0
+ #define XGBE_SPEED_1000_PQ		0xa
+ #define XGBE_SPEED_1000_RATE		0x3
+ #define XGBE_SPEED_1000_TXAMP		0xf
+ #define XGBE_SPEED_1000_WORD		0x1
+ #define XGBE_SPEED_1000_DFE_TAP_CONFIG	0x3
+ #define XGBE_SPEED_1000_DFE_TAP_ENABLE	0x0
+ 
  struct xgbe_prv_data;
  
  struct xgbe_packet_data {
@@@ -461,8 -676,40 +588,22 @@@ struct xgbe_hw_if 
  	void (*rx_mmc_int)(struct xgbe_prv_data *);
  	void (*tx_mmc_int)(struct xgbe_prv_data *);
  	void (*read_mmc_stats)(struct xgbe_prv_data *);
 -
 -	/* For Timestamp config */
 -	int (*config_tstamp)(struct xgbe_prv_data *, unsigned int);
 -	void (*update_tstamp_addend)(struct xgbe_prv_data *, unsigned int);
 -	void (*set_tstamp_time)(struct xgbe_prv_data *, unsigned int sec,
 -				unsigned int nsec);
 -	u64 (*get_tstamp_time)(struct xgbe_prv_data *);
 -	u64 (*get_tx_tstamp)(struct xgbe_prv_data *);
 -
 -	/* For Data Center Bridging config */
 -	void (*config_dcb_tc)(struct xgbe_prv_data *);
 -	void (*config_dcb_pfc)(struct xgbe_prv_data *);
 -
 -	/* For Receive Side Scaling */
 -	int (*enable_rss)(struct xgbe_prv_data *);
 -	int (*disable_rss)(struct xgbe_prv_data *);
 -	int (*set_rss_hash_key)(struct xgbe_prv_data *, const u8 *);
 -	int (*set_rss_lookup_table)(struct xgbe_prv_data *, const u32 *);
  };
  
+ struct xgbe_phy_if {
+ 	/* For initial PHY setup */
+ 	void (*phy_init)(struct xgbe_prv_data *);
+ 
+ 	/* For PHY support when setting device up/down */
+ 	int (*phy_reset)(struct xgbe_prv_data *);
+ 	int (*phy_start)(struct xgbe_prv_data *);
+ 	void (*phy_stop)(struct xgbe_prv_data *);
+ 
+ 	/* For PHY support while device is up */
+ 	void (*phy_status)(struct xgbe_prv_data *);
+ 	int (*phy_config_aneg)(struct xgbe_prv_data *);
+ };
+ 
  struct xgbe_desc_if {
  	int (*alloc_ring_resources)(struct xgbe_prv_data *);
  	void (*free_ring_resources)(struct xgbe_prv_data *);
@@@ -529,9 -789,17 +673,21 @@@ struct xgbe_prv_data 
  	/* XPCS indirect addressing mutex */
  	struct mutex xpcs_mutex;
  
++<<<<<<< HEAD
 +	int irq_number;
++=======
+ 	/* RSS addressing mutex */
+ 	struct mutex rss_mutex;
+ 
+ 	/* Flags representing xgbe_state */
+ 	unsigned long dev_state;
+ 
+ 	int dev_irq;
+ 	unsigned int per_channel_irq;
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  
  	struct xgbe_hw_if hw_if;
+ 	struct xgbe_phy_if phy_if;
  	struct xgbe_desc_if desc_if;
  
  	/* AXI DMA settings */
@@@ -578,23 -855,13 +739,30 @@@
  	unsigned int tx_pause;
  	unsigned int rx_pause;
  
++<<<<<<< HEAD
 +	/* MDIO settings */
 +	struct module *phy_module;
 +	char *mii_bus_id;
 +	struct mii_bus *mii;
 +	int mdio_mmd;
 +	struct phy_device *phydev;
 +	int default_autoneg;
 +	int default_speed;
 +
 +	/* Current PHY settings */
 +	phy_interface_t phy_mode;
 +	int phy_link;
 +	int phy_speed;
 +	unsigned int phy_tx_pause;
 +	unsigned int phy_rx_pause;
++=======
+ 	/* Receive Side Scaling settings */
+ 	u8 rss_key[XGBE_RSS_HASH_KEY_SIZE];
+ 	u32 rss_table[XGBE_RSS_MAX_TABLE_SIZE];
+ 	u32 rss_options;
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  
  	/* Netdev related settings */
 -	unsigned char mac_addr[ETH_ALEN];
  	netdev_features_t netdev_features;
  	struct napi_struct napi;
  	struct xgbe_mmc_stats mmc_stats;
@@@ -611,6 -903,56 +779,59 @@@
  	/* Keeps track of power mode */
  	unsigned int power_down;
  
++<<<<<<< HEAD
++=======
+ 	/* Network interface message level setting */
+ 	u32 msg_enable;
+ 
+ 	/* Current PHY settings */
+ 	phy_interface_t phy_mode;
+ 	int phy_link;
+ 	int phy_speed;
+ 	unsigned int phy_tx_pause;
+ 	unsigned int phy_rx_pause;
+ 
+ 	/* MDIO/PHY related settings */
+ 	struct xgbe_phy phy;
+ 	int mdio_mmd;
+ 	unsigned long link_check;
+ 
+ 	char an_name[IFNAMSIZ + 32];
+ 	struct workqueue_struct *an_workqueue;
+ 
+ 	int an_irq;
+ 	struct work_struct an_irq_work;
+ 
+ 	unsigned int speed_set;
+ 
+ 	/* SerDes UEFI configurable settings.
+ 	 *   Switching between modes/speeds requires new values for some
+ 	 *   SerDes settings.  The values can be supplied as device
+ 	 *   properties in array format.  The first array entry is for
+ 	 *   1GbE, second for 2.5GbE and third for 10GbE
+ 	 */
+ 	u32 serdes_blwc[XGBE_SPEEDS];
+ 	u32 serdes_cdr_rate[XGBE_SPEEDS];
+ 	u32 serdes_pq_skew[XGBE_SPEEDS];
+ 	u32 serdes_tx_amp[XGBE_SPEEDS];
+ 	u32 serdes_dfe_tap_cfg[XGBE_SPEEDS];
+ 	u32 serdes_dfe_tap_ena[XGBE_SPEEDS];
+ 
+ 	/* Auto-negotiation state machine support */
+ 	struct mutex an_mutex;
+ 	enum xgbe_an an_result;
+ 	enum xgbe_an an_state;
+ 	enum xgbe_rx kr_state;
+ 	enum xgbe_rx kx_state;
+ 	struct work_struct an_work;
+ 	unsigned int an_supported;
+ 	unsigned int parallel_detect;
+ 	unsigned int fec_ability;
+ 	unsigned long an_start;
+ 
+ 	unsigned int lpm_ctrl;		/* CTRL1 for resume */
+ 
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  #ifdef CONFIG_DEBUG_FS
  	struct dentry *xgbe_debugfs;
  
@@@ -627,13 -970,15 +849,21 @@@ void xgbe_init_function_ptrs_phy(struc
  void xgbe_init_function_ptrs_desc(struct xgbe_desc_if *);
  struct net_device_ops *xgbe_get_netdev_ops(void);
  struct ethtool_ops *xgbe_get_ethtool_ops(void);
 -#ifdef CONFIG_AMD_XGBE_DCB
 -const struct dcbnl_rtnl_ops *xgbe_get_dcbnl_ops(void);
 -#endif
  
++<<<<<<< HEAD
 +int xgbe_mdio_register(struct xgbe_prv_data *);
 +void xgbe_mdio_unregister(struct xgbe_prv_data *);
 +void xgbe_dump_phy_registers(struct xgbe_prv_data *);
 +void xgbe_dump_tx_desc(struct xgbe_ring *, unsigned int, unsigned int,
 +		       unsigned int);
 +void xgbe_dump_rx_desc(struct xgbe_ring *, struct xgbe_ring_desc *,
++=======
+ void xgbe_ptp_register(struct xgbe_prv_data *);
+ void xgbe_ptp_unregister(struct xgbe_prv_data *);
+ void xgbe_dump_tx_desc(struct xgbe_prv_data *, struct xgbe_ring *,
+ 		       unsigned int, unsigned int, unsigned int);
+ void xgbe_dump_rx_desc(struct xgbe_prv_data *, struct xgbe_ring *,
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
  		       unsigned int);
  void xgbe_print_pkt(struct net_device *, struct sk_buff *, bool);
  void xgbe_get_all_hw_features(struct xgbe_prv_data *);
diff --cc drivers/net/phy/Makefile
index a2bb4785c03f,e97e7f921862..000000000000
--- a/drivers/net/phy/Makefile
+++ b/drivers/net/phy/Makefile
@@@ -30,3 -31,6 +30,9 @@@ obj-$(CONFIG_AMD_PHY)		+= amd.
  obj-$(CONFIG_MDIO_BUS_MUX)	+= mdio-mux.o
  obj-$(CONFIG_MDIO_BUS_MUX_GPIO)	+= mdio-mux-gpio.o
  obj-$(CONFIG_MDIO_BUS_MUX_MMIOREG) += mdio-mux-mmioreg.o
++<<<<<<< HEAD
++=======
+ obj-$(CONFIG_MDIO_SUN4I)	+= mdio-sun4i.o
+ obj-$(CONFIG_MDIO_MOXART)	+= mdio-moxart.o
+ obj-$(CONFIG_MDIO_BCM_UNIMAC)	+= mdio-bcm-unimac.o
++>>>>>>> 7c12aa08779c (amd-xgbe: Move the PHY support into amd-xgbe)
* Unmerged path drivers/net/phy/amd-xgbe-phy.c
diff --git a/Documentation/devicetree/bindings/net/amd-xgbe-phy.txt b/Documentation/devicetree/bindings/net/amd-xgbe-phy.txt
deleted file mode 100644
index 8db32384a486..000000000000
--- a/Documentation/devicetree/bindings/net/amd-xgbe-phy.txt
+++ /dev/null
@@ -1,48 +0,0 @@
-* AMD 10GbE PHY driver (amd-xgbe-phy)
-
-Required properties:
-- compatible: Should be "amd,xgbe-phy-seattle-v1a" and
-  "ethernet-phy-ieee802.3-c45"
-- reg: Address and length of the register sets for the device
-   - SerDes Rx/Tx registers
-   - SerDes integration registers (1/2)
-   - SerDes integration registers (2/2)
-- interrupt-parent: Should be the phandle for the interrupt controller
-  that services interrupts for this device
-- interrupts: Should contain the amd-xgbe-phy interrupt.
-
-Optional properties:
-- amd,speed-set: Speed capabilities of the device
-    0 - 1GbE and 10GbE (default)
-    1 - 2.5GbE and 10GbE
-
-The following optional properties are represented by an array with each
-value corresponding to a particular speed. The first array value represents
-the setting for the 1GbE speed, the second value for the 2.5GbE speed and
-the third value for the 10GbE speed.  All three values are required if the
-property is used.
-- amd,serdes-blwc: Baseline wandering correction enablement
-    0 - Off
-    1 - On
-- amd,serdes-cdr-rate: CDR rate speed selection
-- amd,serdes-pq-skew: PQ (data sampling) skew
-- amd,serdes-tx-amp: TX amplitude boost
-- amd,serdes-dfe-tap-config: DFE taps available to run
-- amd,serdes-dfe-tap-enable: DFE taps to enable
-
-Example:
-	xgbe_phy@e1240800 {
-		compatible = "amd,xgbe-phy-seattle-v1a", "ethernet-phy-ieee802.3-c45";
-		reg = <0 0xe1240800 0 0x00400>,
-		      <0 0xe1250000 0 0x00060>,
-		      <0 0xe1250080 0 0x00004>;
-		interrupt-parent = <&gic>;
-		interrupts = <0 323 4>;
-		amd,speed-set = <0>;
-		amd,serdes-blwc = <1>, <1>, <0>;
-		amd,serdes-cdr-rate = <2>, <2>, <7>;
-		amd,serdes-pq-skew = <10>, <10>, <30>;
-		amd,serdes-tx-amp = <15>, <15>, <10>;
-		amd,serdes-dfe-tap-config = <3>, <3>, <1>;
-		amd,serdes-dfe-tap-enable = <0>, <0>, <127>;
-	};
* Unmerged path Documentation/devicetree/bindings/net/amd-xgbe.txt
diff --git a/MAINTAINERS b/MAINTAINERS
index 34330c037ee5..9e6b2d2fbd4e 100644
--- a/MAINTAINERS
+++ b/MAINTAINERS
@@ -562,7 +562,6 @@ M:	Tom Lendacky <thomas.lendacky@amd.com>
 L:	netdev@vger.kernel.org
 S:	Supported
 F:	drivers/net/ethernet/amd/xgbe/
-F:	drivers/net/phy/amd-xgbe-phy.c
 
 AMS (Apple Motion Sensor) DRIVER
 M:	Michael Hanselmann <linux-kernel@hansmi.ch>
* Unmerged path drivers/net/ethernet/amd/Kconfig
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-common.h
diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-dev.c b/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
index ec5481f846ee..269c3b3f6e4d 100644
--- a/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
@@ -687,23 +687,6 @@ static void xgbe_write_mmd_regs(struct xgbe_prv_data *pdata, int prtad,
 	else
 		mmd_address = (pdata->mdio_mmd << 16) | (mmd_reg & 0xffff);
 
-	/* If the PCS is changing modes, match the MAC speed to it */
-	if (((mmd_address >> 16) == MDIO_MMD_PCS) &&
-	    ((mmd_address & 0xffff) == MDIO_CTRL2)) {
-		struct phy_device *phydev = pdata->phydev;
-
-		if (mmd_data & MDIO_PCS_CTRL2_TYPE) {
-			/* KX mode */
-			if (phydev->supported & SUPPORTED_1000baseKX_Full)
-				xgbe_set_gmii_speed(pdata);
-			else
-				xgbe_set_gmii_2500_speed(pdata);
-		} else {
-			/* KR mode */
-			xgbe_set_xgmii_speed(pdata);
-		}
-	}
-
 	/* The PCS registers are accessed using mmio. The underlying APB3
 	 * management interface uses indirect addressing to access the MMD
 	 * register sets. This requires accessing of the PCS register in two
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-drv.c
diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-ethtool.c b/drivers/net/ethernet/amd/xgbe/xgbe-ethtool.c
index 6e5a90e8e36c..22a706b6abe4 100644
--- a/drivers/net/ethernet/amd/xgbe/xgbe-ethtool.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-ethtool.c
@@ -249,7 +249,6 @@ static int xgbe_set_pauseparam(struct net_device *netdev,
 			       struct ethtool_pauseparam *pause)
 {
 	struct xgbe_prv_data *pdata = netdev_priv(netdev);
-	struct phy_device *phydev = pdata->phydev;
 	int ret = 0;
 
 	DBGPR("-->xgbe_set_pauseparam\n");
@@ -259,19 +258,19 @@ static int xgbe_set_pauseparam(struct net_device *netdev,
 
 	pdata->pause_autoneg = pause->autoneg;
 	if (pause->autoneg) {
-		phydev->advertising |= ADVERTISED_Pause;
-		phydev->advertising |= ADVERTISED_Asym_Pause;
+		pdata->phy.advertising |= ADVERTISED_Pause;
+		pdata->phy.advertising |= ADVERTISED_Asym_Pause;
 
 	} else {
-		phydev->advertising &= ~ADVERTISED_Pause;
-		phydev->advertising &= ~ADVERTISED_Asym_Pause;
+		pdata->phy.advertising &= ~ADVERTISED_Pause;
+		pdata->phy.advertising &= ~ADVERTISED_Asym_Pause;
 
 		pdata->tx_pause = pause->tx_pause;
 		pdata->rx_pause = pause->rx_pause;
 	}
 
 	if (netif_running(netdev))
-		ret = phy_start_aneg(phydev);
+		ret = pdata->phy_if.phy_config_aneg(pdata);
 
 	DBGPR("<--xgbe_set_pauseparam\n");
 
@@ -282,36 +281,39 @@ static int xgbe_get_settings(struct net_device *netdev,
 			     struct ethtool_cmd *cmd)
 {
 	struct xgbe_prv_data *pdata = netdev_priv(netdev);
-	int ret;
 
 	DBGPR("-->xgbe_get_settings\n");
 
-	if (!pdata->phydev)
-		return -ENODEV;
+	cmd->phy_address = pdata->phy.address;
+
+	cmd->supported = pdata->phy.supported;
+	cmd->advertising = pdata->phy.advertising;
+	cmd->lp_advertising = pdata->phy.lp_advertising;
+
+	cmd->autoneg = pdata->phy.autoneg;
+	ethtool_cmd_speed_set(cmd, pdata->phy.speed);
+	cmd->duplex = pdata->phy.duplex;
 
-	ret = phy_ethtool_gset(pdata->phydev, cmd);
+	cmd->port = PORT_NONE;
+	cmd->transceiver = XCVR_INTERNAL;
 
 	DBGPR("<--xgbe_get_settings\n");
 
-	return ret;
+	return 0;
 }
 
 static int xgbe_set_settings(struct net_device *netdev,
 			     struct ethtool_cmd *cmd)
 {
 	struct xgbe_prv_data *pdata = netdev_priv(netdev);
-	struct phy_device *phydev = pdata->phydev;
 	u32 speed;
 	int ret;
 
 	DBGPR("-->xgbe_set_settings\n");
 
-	if (!pdata->phydev)
-		return -ENODEV;
-
 	speed = ethtool_cmd_speed(cmd);
 
-	if (cmd->phy_address != phydev->addr)
+	if (cmd->phy_address != pdata->phy.address)
 		return -EINVAL;
 
 	if ((cmd->autoneg != AUTONEG_ENABLE) &&
@@ -332,23 +334,23 @@ static int xgbe_set_settings(struct net_device *netdev,
 			return -EINVAL;
 	}
 
-	cmd->advertising &= phydev->supported;
+	cmd->advertising &= pdata->phy.supported;
 	if ((cmd->autoneg == AUTONEG_ENABLE) && !cmd->advertising)
 		return -EINVAL;
 
 	ret = 0;
-	phydev->autoneg = cmd->autoneg;
-	phydev->speed = speed;
-	phydev->duplex = cmd->duplex;
-	phydev->advertising = cmd->advertising;
+	pdata->phy.autoneg = cmd->autoneg;
+	pdata->phy.speed = speed;
+	pdata->phy.duplex = cmd->duplex;
+	pdata->phy.advertising = cmd->advertising;
 
 	if (cmd->autoneg == AUTONEG_ENABLE)
-		phydev->advertising |= ADVERTISED_Autoneg;
+		pdata->phy.advertising |= ADVERTISED_Autoneg;
 	else
-		phydev->advertising &= ~ADVERTISED_Autoneg;
+		pdata->phy.advertising &= ~ADVERTISED_Autoneg;
 
 	if (netif_running(netdev))
-		ret = phy_start_aneg(phydev);
+		ret = pdata->phy_if.phy_config_aneg(pdata);
 
 	DBGPR("<--xgbe_set_settings\n");
 
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-main.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-mdio.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe.h
* Unmerged path drivers/net/phy/Makefile
* Unmerged path drivers/net/phy/amd-xgbe-phy.c
