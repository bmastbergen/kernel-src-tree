nvme: Pass pointers, not dma addresses, to nvme_get/set_features()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [nvme] Pass pointers, not dma addresses, to nvme_get/set_features() (David Milburn) [1384526 1389755 1366753 1374291 1383834]
Rebuild_FUZZ: 95.24%
commit-author Andy Lutomirski <luto@kernel.org>
commit 1a6fe74dfd1bb10afb41cbbbdc14890604be42a6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/1a6fe74d.failed

Any user I can imagine that needs a buffer at all will want to pass
a pointer directly.  There are no currently callers that use
buffers, so this change is painless, and it will make it much easier
to start using features that use buffers (e.g. APST).

	Signed-off-by: Andy Lutomirski <luto@kernel.org>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Acked-by: Jay Freyensee <james_p_freyensee@linux.intel.com>
	Tested-by: Jay Freyensee <james_p_freyensee@linux.intel.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 1a6fe74dfd1bb10afb41cbbbdc14890604be42a6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/core.c
diff --cc drivers/nvme/host/core.c
index 63f6b5f40b5c,4669c052239e..000000000000
--- a/drivers/nvme/host/core.c
+++ b/drivers/nvme/host/core.c
@@@ -316,31 -599,41 +316,52 @@@ int nvme_identify_ns(struct nvme_ctrl *
  }
  
  int nvme_get_features(struct nvme_ctrl *dev, unsigned fid, unsigned nsid,
- 					dma_addr_t dma_addr, u32 *result)
+ 		      void *buffer, size_t buflen, u32 *result)
  {
  	struct nvme_command c;
 -	struct nvme_completion cqe;
 -	int ret;
  
  	memset(&c, 0, sizeof(c));
  	c.features.opcode = nvme_admin_get_features;
  	c.features.nsid = cpu_to_le32(nsid);
++<<<<<<< HEAD
 +	c.features.prp1 = cpu_to_le64(dma_addr);
 +	c.features.fid = cpu_to_le32(fid);
 +
 +	return __nvme_submit_sync_cmd(dev->admin_q, &c, NULL, 0, result, 0);
++=======
+ 	c.features.fid = cpu_to_le32(fid);
+ 
+ 	ret = __nvme_submit_sync_cmd(dev->admin_q, &c, &cqe, buffer, buflen, 0,
+ 			NVME_QID_ANY, 0, 0);
+ 	if (ret >= 0 && result)
+ 		*result = le32_to_cpu(cqe.result);
+ 	return ret;
++>>>>>>> 1a6fe74dfd1b (nvme: Pass pointers, not dma addresses, to nvme_get/set_features())
  }
  
  int nvme_set_features(struct nvme_ctrl *dev, unsigned fid, unsigned dword11,
- 					dma_addr_t dma_addr, u32 *result)
+ 		      void *buffer, size_t buflen, u32 *result)
  {
  	struct nvme_command c;
 -	struct nvme_completion cqe;
 -	int ret;
  
  	memset(&c, 0, sizeof(c));
  	c.features.opcode = nvme_admin_set_features;
++<<<<<<< HEAD
 +	c.features.prp1 = cpu_to_le64(dma_addr);
 +	c.features.fid = cpu_to_le32(fid);
 +	c.features.dword11 = cpu_to_le32(dword11);
 +
 +	return __nvme_submit_sync_cmd(dev->admin_q, &c, NULL, 0, result, 0);
++=======
+ 	c.features.fid = cpu_to_le32(fid);
+ 	c.features.dword11 = cpu_to_le32(dword11);
+ 
+ 	ret = __nvme_submit_sync_cmd(dev->admin_q, &c, &cqe,
+ 			buffer, buflen, 0, NVME_QID_ANY, 0, 0);
+ 	if (ret >= 0 && result)
+ 		*result = le32_to_cpu(cqe.result);
+ 	return ret;
++>>>>>>> 1a6fe74dfd1b (nvme: Pass pointers, not dma addresses, to nvme_get/set_features())
  }
  
  int nvme_get_log_page(struct nvme_ctrl *dev, struct nvme_smart_log **log)
@@@ -371,15 -664,27 +392,15 @@@ int nvme_set_queue_count(struct nvme_ct
  	u32 result;
  	int status, nr_io_queues;
  
- 	status = nvme_set_features(ctrl, NVME_FEAT_NUM_QUEUES, q_count, 0,
+ 	status = nvme_set_features(ctrl, NVME_FEAT_NUM_QUEUES, q_count, NULL, 0,
  			&result);
 -	if (status < 0)
 +	if (status)
  		return status;
  
 -	/*
 -	 * Degraded controllers might return an error when setting the queue
 -	 * count.  We still want to be able to bring them online and offer
 -	 * access to the admin queue, as that might be only way to fix them up.
 -	 */
 -	if (status > 0) {
 -		dev_err(ctrl->dev, "Could not set queue count (%d)\n", status);
 -		*count = 0;
 -	} else {
 -		nr_io_queues = min(result & 0xffff, result >> 16) + 1;
 -		*count = min(*count, nr_io_queues);
 -	}
 -
 +	nr_io_queues = min(result & 0xffff, result >> 16) + 1;
 +	*count = min(*count, nr_io_queues);
  	return 0;
  }
 -EXPORT_SYMBOL_GPL(nvme_set_queue_count);
  
  static int nvme_submit_io(struct nvme_ns *ns, struct nvme_user_io __user *uio)
  {
* Unmerged path drivers/nvme/host/core.c
diff --git a/drivers/nvme/host/nvme.h b/drivers/nvme/host/nvme.h
index ddd7fc3f3881..c548682c44f4 100644
--- a/drivers/nvme/host/nvme.h
+++ b/drivers/nvme/host/nvme.h
@@ -264,9 +264,9 @@ int nvme_identify_ns(struct nvme_ctrl *dev, unsigned nsid,
 		struct nvme_id_ns **id);
 int nvme_get_log_page(struct nvme_ctrl *dev, struct nvme_smart_log **log);
 int nvme_get_features(struct nvme_ctrl *dev, unsigned fid, unsigned nsid,
-			dma_addr_t dma_addr, u32 *result);
+		      void *buffer, size_t buflen, u32 *result);
 int nvme_set_features(struct nvme_ctrl *dev, unsigned fid, unsigned dword11,
-			dma_addr_t dma_addr, u32 *result);
+		      void *buffer, size_t buflen, u32 *result);
 int nvme_set_queue_count(struct nvme_ctrl *ctrl, int *count);
 
 extern spinlock_t dev_list_lock;
diff --git a/drivers/nvme/host/scsi.c b/drivers/nvme/host/scsi.c
index 44009105f8c8..c2a0a1c7d05d 100644
--- a/drivers/nvme/host/scsi.c
+++ b/drivers/nvme/host/scsi.c
@@ -906,7 +906,7 @@ static int nvme_trans_log_temperature(struct nvme_ns *ns, struct sg_io_hdr *hdr,
 	kfree(smart_log);
 
 	/* Get Features for Temp Threshold */
-	res = nvme_get_features(ns->ctrl, NVME_FEAT_TEMP_THRESH, 0, 0,
+	res = nvme_get_features(ns->ctrl, NVME_FEAT_TEMP_THRESH, 0, NULL, 0,
 								&feature_resp);
 	if (res != NVME_SC_SUCCESS)
 		temp_c_thresh = LOG_TEMP_UNKNOWN;
@@ -1039,7 +1039,7 @@ static int nvme_trans_fill_caching_page(struct nvme_ns *ns,
 	if (len < MODE_PAGE_CACHING_LEN)
 		return -EINVAL;
 
-	nvme_sc = nvme_get_features(ns->ctrl, NVME_FEAT_VOLATILE_WC, 0, 0,
+	nvme_sc = nvme_get_features(ns->ctrl, NVME_FEAT_VOLATILE_WC, 0, NULL, 0,
 								&feature_resp);
 	res = nvme_trans_status_code(hdr, nvme_sc);
 	if (res)
@@ -1328,7 +1328,7 @@ static int nvme_trans_modesel_get_mp(struct nvme_ns *ns, struct sg_io_hdr *hdr,
 	case MODE_PAGE_CACHING:
 		dword11 = ((mode_page[2] & CACHING_MODE_PAGE_WCE_MASK) ? 1 : 0);
 		nvme_sc = nvme_set_features(ns->ctrl, NVME_FEAT_VOLATILE_WC,
-					    dword11, 0, NULL);
+					    dword11, NULL, 0, NULL);
 		res = nvme_trans_status_code(hdr, nvme_sc);
 		break;
 	case MODE_PAGE_CONTROL:
