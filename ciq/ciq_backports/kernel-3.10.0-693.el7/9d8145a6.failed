IB/hfi1: Avoid credit return allocation for cpu-less NUMA nodes

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Harish Chegondi <harish.chegondi@intel.com>
commit 9d8145a604937780898c0e4bdb124a57988fc2ed
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/9d8145a6.failed

Do not allocate credit return base and DMA memory for
NUMA nodes without CPUs.

	Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
	Signed-off-by: Harish Chegondi <harish.chegondi@intel.com>
	Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 9d8145a604937780898c0e4bdb124a57988fc2ed)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/hfi1/affinity.c
#	drivers/infiniband/hw/hfi1/affinity.h
diff --cc drivers/infiniband/hw/hfi1/affinity.c
index 1ca2154de24c,4962b6ef1f34..000000000000
--- a/drivers/infiniband/hw/hfi1/affinity.c
+++ b/drivers/infiniband/hw/hfi1/affinity.c
@@@ -102,11 -106,53 +102,59 @@@ int init_real_cpu_mask(struct hfi1_devd
  	 * skip any gaps.
  	 */
  	for (; i < possible; i++) {
++<<<<<<< HEAD
 +		cpumask_clear_cpu(curr_cpu, &info->real_cpu_mask);
 +		curr_cpu = cpumask_next(curr_cpu, &info->real_cpu_mask);
++=======
+ 		cpumask_clear_cpu(curr_cpu, &node_affinity.real_cpu_mask);
+ 		curr_cpu = cpumask_next(curr_cpu, &node_affinity.real_cpu_mask);
+ 	}
+ }
+ 
+ int node_affinity_init(void)
+ {
+ 	int node;
+ 	struct pci_dev *dev = NULL;
+ 	const struct pci_device_id *ids = hfi1_pci_tbl;
+ 
+ 	cpumask_clear(&node_affinity.proc.used);
+ 	cpumask_copy(&node_affinity.proc.mask, cpu_online_mask);
+ 
+ 	node_affinity.proc.gen = 0;
+ 	node_affinity.num_core_siblings =
+ 				cpumask_weight(topology_sibling_cpumask(
+ 					cpumask_first(&node_affinity.proc.mask)
+ 					));
+ 	node_affinity.num_possible_nodes = num_possible_nodes();
+ 	node_affinity.num_online_nodes = num_online_nodes();
+ 	node_affinity.num_online_cpus = num_online_cpus();
+ 
+ 	/*
+ 	 * The real cpu mask is part of the affinity struct but it has to be
+ 	 * initialized early. It is needed to calculate the number of user
+ 	 * contexts in set_up_context_variables().
+ 	 */
+ 	init_real_cpu_mask();
+ 
+ 	hfi1_per_node_cntr = kcalloc(node_affinity.num_possible_nodes,
+ 				     sizeof(*hfi1_per_node_cntr), GFP_KERNEL);
+ 	if (!hfi1_per_node_cntr)
+ 		return -ENOMEM;
+ 
+ 	while (ids->vendor) {
+ 		dev = NULL;
+ 		while ((dev = pci_get_device(ids->vendor, ids->device, dev))) {
+ 			node = pcibus_to_node(dev->bus);
+ 			if (node < 0)
+ 				node = numa_node_id();
+ 
+ 			hfi1_per_node_cntr[node]++;
+ 		}
+ 		ids++;
++>>>>>>> 9d8145a60493 (IB/hfi1: Avoid credit return allocation for cpu-less NUMA nodes)
  	}
  
 +	dd->affinity = info;
  	return 0;
  }
  
diff --cc drivers/infiniband/hw/hfi1/affinity.h
index 20f52fe74091,c9453b3d47b4..000000000000
--- a/drivers/infiniband/hw/hfi1/affinity.h
+++ b/drivers/infiniband/hw/hfi1/affinity.h
@@@ -101,8 -90,35 +101,39 @@@ void hfi1_put_irq_affinity(struct hfi1_
   * Determine a CPU affinity for a user process, if the process does not
   * have an affinity set yet.
   */
 -int hfi1_get_proc_affinity(int);
 +int hfi1_get_proc_affinity(struct hfi1_devdata *, int);
  /* Release a CPU used by a user process. */
++<<<<<<< HEAD
 +void hfi1_put_proc_affinity(struct hfi1_devdata *, int);
++=======
+ void hfi1_put_proc_affinity(int);
+ 
+ int hfi1_get_sdma_affinity(struct hfi1_devdata *dd, char *buf);
+ int hfi1_set_sdma_affinity(struct hfi1_devdata *dd, const char *buf,
+ 			   size_t count);
+ 
+ struct hfi1_affinity_node {
+ 	int node;
+ 	struct cpu_mask_set def_intr;
+ 	struct cpu_mask_set rcv_intr;
+ 	struct cpumask general_intr_mask;
+ 	struct list_head list;
+ };
+ 
+ struct hfi1_affinity_node_list {
+ 	struct list_head list;
+ 	struct cpumask real_cpu_mask;
+ 	struct cpu_mask_set proc;
+ 	int num_core_siblings;
+ 	int num_possible_nodes;
+ 	int num_online_nodes;
+ 	int num_online_cpus;
+ 	struct mutex lock; /* protects affinity nodes */
+ };
+ 
+ int node_affinity_init(void);
+ void node_affinity_destroy(void);
+ extern struct hfi1_affinity_node_list node_affinity;
++>>>>>>> 9d8145a60493 (IB/hfi1: Avoid credit return allocation for cpu-less NUMA nodes)
  
  #endif /* _HFI1_AFFINITY_H */
* Unmerged path drivers/infiniband/hw/hfi1/affinity.c
* Unmerged path drivers/infiniband/hw/hfi1/affinity.h
diff --git a/drivers/infiniband/hw/hfi1/pio.c b/drivers/infiniband/hw/hfi1/pio.c
index aa8b3fb463e5..615be68e40b3 100644
--- a/drivers/infiniband/hw/hfi1/pio.c
+++ b/drivers/infiniband/hw/hfi1/pio.c
@@ -2029,28 +2029,17 @@ freesc15:
 int init_credit_return(struct hfi1_devdata *dd)
 {
 	int ret;
-	int num_numa;
 	int i;
 
-	num_numa = num_online_nodes();
-	/* enforce the expectation that the numas are compact */
-	for (i = 0; i < num_numa; i++) {
-		if (!node_online(i)) {
-			dd_dev_err(dd, "NUMA nodes are not compact\n");
-			ret = -EINVAL;
-			goto done;
-		}
-	}
-
 	dd->cr_base = kcalloc(
-		num_numa,
+		node_affinity.num_possible_nodes,
 		sizeof(struct credit_return_base),
 		GFP_KERNEL);
 	if (!dd->cr_base) {
 		ret = -ENOMEM;
 		goto done;
 	}
-	for (i = 0; i < num_numa; i++) {
+	for_each_node_with_cpus(i) {
 		int bytes = TXE_NUM_CONTEXTS * sizeof(struct credit_return);
 
 		set_dev_node(&dd->pcidev->dev, i);
@@ -2077,14 +2066,11 @@ done:
 
 void free_credit_return(struct hfi1_devdata *dd)
 {
-	int num_numa;
 	int i;
 
 	if (!dd->cr_base)
 		return;
-
-	num_numa = num_online_nodes();
-	for (i = 0; i < num_numa; i++) {
+	for (i = 0; i < node_affinity.num_possible_nodes; i++) {
 		if (dd->cr_base[i].va) {
 			dma_free_coherent(&dd->pcidev->dev,
 					  TXE_NUM_CONTEXTS *
