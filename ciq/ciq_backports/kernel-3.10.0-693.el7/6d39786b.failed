IB/core: Introduce Receive Work Queue indirection table

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Yishai Hadas <yishaih@mellanox.com>
commit 6d39786bf116e476d75eca91f7cfa22586a32e5f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/6d39786b.failed

Introduce Receive Work Queue (WQ) indirection table.
This object can be used to spread incoming traffic to different
receive Work Queues.

A Receive WQ indirection table points to variable size of WQs.
This table is given to a QP in downstream patches.

	Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
	Signed-off-by: Matan Barak <matanb@mellanox.com>
	Reviewed-by: Sagi Grimberg <sagi@grimerg.me>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 6d39786bf116e476d75eca91f7cfa22586a32e5f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/verbs.c
#	include/rdma/ib_verbs.h
diff --cc drivers/infiniband/core/verbs.c
index 6298f54b4137,6b548d7f8753..000000000000
--- a/drivers/infiniband/core/verbs.c
+++ b/drivers/infiniband/core/verbs.c
@@@ -1558,6 -1554,150 +1558,153 @@@ int ib_dealloc_xrcd(struct ib_xrcd *xrc
  }
  EXPORT_SYMBOL(ib_dealloc_xrcd);
  
++<<<<<<< HEAD
++=======
+ /**
+  * ib_create_wq - Creates a WQ associated with the specified protection
+  * domain.
+  * @pd: The protection domain associated with the WQ.
+  * @wq_init_attr: A list of initial attributes required to create the
+  * WQ. If WQ creation succeeds, then the attributes are updated to
+  * the actual capabilities of the created WQ.
+  *
+  * wq_init_attr->max_wr and wq_init_attr->max_sge determine
+  * the requested size of the WQ, and set to the actual values allocated
+  * on return.
+  * If ib_create_wq() succeeds, then max_wr and max_sge will always be
+  * at least as large as the requested values.
+  */
+ struct ib_wq *ib_create_wq(struct ib_pd *pd,
+ 			   struct ib_wq_init_attr *wq_attr)
+ {
+ 	struct ib_wq *wq;
+ 
+ 	if (!pd->device->create_wq)
+ 		return ERR_PTR(-ENOSYS);
+ 
+ 	wq = pd->device->create_wq(pd, wq_attr, NULL);
+ 	if (!IS_ERR(wq)) {
+ 		wq->event_handler = wq_attr->event_handler;
+ 		wq->wq_context = wq_attr->wq_context;
+ 		wq->wq_type = wq_attr->wq_type;
+ 		wq->cq = wq_attr->cq;
+ 		wq->device = pd->device;
+ 		wq->pd = pd;
+ 		wq->uobject = NULL;
+ 		atomic_inc(&pd->usecnt);
+ 		atomic_inc(&wq_attr->cq->usecnt);
+ 		atomic_set(&wq->usecnt, 0);
+ 	}
+ 	return wq;
+ }
+ EXPORT_SYMBOL(ib_create_wq);
+ 
+ /**
+  * ib_destroy_wq - Destroys the specified WQ.
+  * @wq: The WQ to destroy.
+  */
+ int ib_destroy_wq(struct ib_wq *wq)
+ {
+ 	int err;
+ 	struct ib_cq *cq = wq->cq;
+ 	struct ib_pd *pd = wq->pd;
+ 
+ 	if (atomic_read(&wq->usecnt))
+ 		return -EBUSY;
+ 
+ 	err = wq->device->destroy_wq(wq);
+ 	if (!err) {
+ 		atomic_dec(&pd->usecnt);
+ 		atomic_dec(&cq->usecnt);
+ 	}
+ 	return err;
+ }
+ EXPORT_SYMBOL(ib_destroy_wq);
+ 
+ /**
+  * ib_modify_wq - Modifies the specified WQ.
+  * @wq: The WQ to modify.
+  * @wq_attr: On input, specifies the WQ attributes to modify.
+  * @wq_attr_mask: A bit-mask used to specify which attributes of the WQ
+  *   are being modified.
+  * On output, the current values of selected WQ attributes are returned.
+  */
+ int ib_modify_wq(struct ib_wq *wq, struct ib_wq_attr *wq_attr,
+ 		 u32 wq_attr_mask)
+ {
+ 	int err;
+ 
+ 	if (!wq->device->modify_wq)
+ 		return -ENOSYS;
+ 
+ 	err = wq->device->modify_wq(wq, wq_attr, wq_attr_mask, NULL);
+ 	return err;
+ }
+ EXPORT_SYMBOL(ib_modify_wq);
+ 
+ /*
+  * ib_create_rwq_ind_table - Creates a RQ Indirection Table.
+  * @device: The device on which to create the rwq indirection table.
+  * @ib_rwq_ind_table_init_attr: A list of initial attributes required to
+  * create the Indirection Table.
+  *
+  * Note: The life time of ib_rwq_ind_table_init_attr->ind_tbl is not less
+  *	than the created ib_rwq_ind_table object and the caller is responsible
+  *	for its memory allocation/free.
+  */
+ struct ib_rwq_ind_table *ib_create_rwq_ind_table(struct ib_device *device,
+ 						 struct ib_rwq_ind_table_init_attr *init_attr)
+ {
+ 	struct ib_rwq_ind_table *rwq_ind_table;
+ 	int i;
+ 	u32 table_size;
+ 
+ 	if (!device->create_rwq_ind_table)
+ 		return ERR_PTR(-ENOSYS);
+ 
+ 	table_size = (1 << init_attr->log_ind_tbl_size);
+ 	rwq_ind_table = device->create_rwq_ind_table(device,
+ 				init_attr, NULL);
+ 	if (IS_ERR(rwq_ind_table))
+ 		return rwq_ind_table;
+ 
+ 	rwq_ind_table->ind_tbl = init_attr->ind_tbl;
+ 	rwq_ind_table->log_ind_tbl_size = init_attr->log_ind_tbl_size;
+ 	rwq_ind_table->device = device;
+ 	rwq_ind_table->uobject = NULL;
+ 	atomic_set(&rwq_ind_table->usecnt, 0);
+ 
+ 	for (i = 0; i < table_size; i++)
+ 		atomic_inc(&rwq_ind_table->ind_tbl[i]->usecnt);
+ 
+ 	return rwq_ind_table;
+ }
+ EXPORT_SYMBOL(ib_create_rwq_ind_table);
+ 
+ /*
+  * ib_destroy_rwq_ind_table - Destroys the specified Indirection Table.
+  * @wq_ind_table: The Indirection Table to destroy.
+ */
+ int ib_destroy_rwq_ind_table(struct ib_rwq_ind_table *rwq_ind_table)
+ {
+ 	int err, i;
+ 	u32 table_size = (1 << rwq_ind_table->log_ind_tbl_size);
+ 	struct ib_wq **ind_tbl = rwq_ind_table->ind_tbl;
+ 
+ 	if (atomic_read(&rwq_ind_table->usecnt))
+ 		return -EBUSY;
+ 
+ 	err = rwq_ind_table->device->destroy_rwq_ind_table(rwq_ind_table);
+ 	if (!err) {
+ 		for (i = 0; i < table_size; i++)
+ 			atomic_dec(&ind_tbl[i]->usecnt);
+ 	}
+ 
+ 	return err;
+ }
+ EXPORT_SYMBOL(ib_destroy_rwq_ind_table);
+ 
++>>>>>>> 6d39786bf116 (IB/core: Introduce Receive Work Queue indirection table)
  struct ib_flow *ib_create_flow(struct ib_qp *qp,
  			       struct ib_flow_attr *flow_attr,
  			       int domain)
diff --cc include/rdma/ib_verbs.h
index 0650081e3bce,fa2e0184dcc5..000000000000
--- a/include/rdma/ib_verbs.h
+++ b/include/rdma/ib_verbs.h
@@@ -1431,6 -1431,63 +1431,66 @@@ struct ib_srq 
  	} ext;
  };
  
++<<<<<<< HEAD
++=======
+ enum ib_wq_type {
+ 	IB_WQT_RQ
+ };
+ 
+ enum ib_wq_state {
+ 	IB_WQS_RESET,
+ 	IB_WQS_RDY,
+ 	IB_WQS_ERR
+ };
+ 
+ struct ib_wq {
+ 	struct ib_device       *device;
+ 	struct ib_uobject      *uobject;
+ 	void		    *wq_context;
+ 	void		    (*event_handler)(struct ib_event *, void *);
+ 	struct ib_pd	       *pd;
+ 	struct ib_cq	       *cq;
+ 	u32		wq_num;
+ 	enum ib_wq_state       state;
+ 	enum ib_wq_type	wq_type;
+ 	atomic_t		usecnt;
+ };
+ 
+ struct ib_wq_init_attr {
+ 	void		       *wq_context;
+ 	enum ib_wq_type	wq_type;
+ 	u32		max_wr;
+ 	u32		max_sge;
+ 	struct	ib_cq	       *cq;
+ 	void		    (*event_handler)(struct ib_event *, void *);
+ };
+ 
+ enum ib_wq_attr_mask {
+ 	IB_WQ_STATE	= 1 << 0,
+ 	IB_WQ_CUR_STATE	= 1 << 1,
+ };
+ 
+ struct ib_wq_attr {
+ 	enum	ib_wq_state	wq_state;
+ 	enum	ib_wq_state	curr_wq_state;
+ };
+ 
+ struct ib_rwq_ind_table {
+ 	struct ib_device	*device;
+ 	struct ib_uobject      *uobject;
+ 	atomic_t		usecnt;
+ 	u32		ind_tbl_num;
+ 	u32		log_ind_tbl_size;
+ 	struct ib_wq	**ind_tbl;
+ };
+ 
+ struct ib_rwq_ind_table_init_attr {
+ 	u32		log_ind_tbl_size;
+ 	/* Each entry is a pointer to Receive Work Queue */
+ 	struct ib_wq	**ind_tbl;
+ };
+ 
++>>>>>>> 6d39786bf116 (IB/core: Introduce Receive Work Queue indirection table)
  struct ib_qp {
  	struct ib_device       *device;
  	struct ib_pd	       *pd;
@@@ -1922,9 -1981,18 +1982,24 @@@ struct ib_device 
  						   struct ifla_vf_stats *stats);
  	int			   (*set_vf_guid)(struct ib_device *device, int vf, u8 port, u64 guid,
  						  int type);
++<<<<<<< HEAD
 +	void			   (*drain_rq)(struct ib_qp *qp);
 +	void			   (*drain_sq)(struct ib_qp *qp);
 +
++=======
+ 	struct ib_wq *		   (*create_wq)(struct ib_pd *pd,
+ 						struct ib_wq_init_attr *init_attr,
+ 						struct ib_udata *udata);
+ 	int			   (*destroy_wq)(struct ib_wq *wq);
+ 	int			   (*modify_wq)(struct ib_wq *wq,
+ 						struct ib_wq_attr *attr,
+ 						u32 wq_attr_mask,
+ 						struct ib_udata *udata);
+ 	struct ib_rwq_ind_table *  (*create_rwq_ind_table)(struct ib_device *device,
+ 							   struct ib_rwq_ind_table_init_attr *init_attr,
+ 							   struct ib_udata *udata);
+ 	int                        (*destroy_rwq_ind_table)(struct ib_rwq_ind_table *wq_ind_table);
++>>>>>>> 6d39786bf116 (IB/core: Introduce Receive Work Queue indirection table)
  	struct ib_dma_mapping_ops   *dma_ops;
  
  	struct module               *owner;
@@@ -3170,6 -3238,15 +3245,18 @@@ int ib_check_mr_status(struct ib_mr *mr
  struct net_device *ib_get_net_dev_by_params(struct ib_device *dev, u8 port,
  					    u16 pkey, const union ib_gid *gid,
  					    const struct sockaddr *addr);
++<<<<<<< HEAD
++=======
+ struct ib_wq *ib_create_wq(struct ib_pd *pd,
+ 			   struct ib_wq_init_attr *init_attr);
+ int ib_destroy_wq(struct ib_wq *wq);
+ int ib_modify_wq(struct ib_wq *wq, struct ib_wq_attr *attr,
+ 		 u32 wq_attr_mask);
+ struct ib_rwq_ind_table *ib_create_rwq_ind_table(struct ib_device *device,
+ 						 struct ib_rwq_ind_table_init_attr*
+ 						 wq_ind_table_init_attr);
+ int ib_destroy_rwq_ind_table(struct ib_rwq_ind_table *wq_ind_table);
++>>>>>>> 6d39786bf116 (IB/core: Introduce Receive Work Queue indirection table)
  
  int ib_map_mr_sg(struct ib_mr *mr, struct scatterlist *sg, int sg_nents,
  		 unsigned int *sg_offset, unsigned int page_size);
* Unmerged path drivers/infiniband/core/verbs.c
* Unmerged path include/rdma/ib_verbs.h
