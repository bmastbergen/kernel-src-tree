locking,arch: Use ACCESS_ONCE() instead of cast to volatile in atomic_read()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [asm-generic] locking, arch: Use ACCESS_ONCE() instead of cast to volatile in atomic_read() (Rob Clark) [1406119]
Rebuild_FUZZ: 99.35%
commit-author Pranith Kumar <bobby.prani@gmail.com>
commit 2291059c852706c6f5ffb400366042b7625066cd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/2291059c.failed

Use the much more reader friendly ACCESS_ONCE() instead of the cast to volatile.
This is purely a stylistic change.

	Signed-off-by: Pranith Kumar <bobby.prani@gmail.com>
	Acked-by: Jesper Nilsson <jesper.nilsson@axis.com>
	Acked-by: Hans-Christian Egtvedt <egtvedt@samfundet.no>
	Acked-by: Max Filippov <jcmvbkbc@gmail.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: linux-arch@vger.kernel.org
Link: http://lkml.kernel.org/r/1411482607-20948-1-git-send-email-bobby.prani@gmail.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 2291059c852706c6f5ffb400366042b7625066cd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/atomic.h
diff --cc arch/arm64/include/asm/atomic.h
index 836364468571,7047051ded40..000000000000
--- a/arch/arm64/include/asm/atomic.h
+++ b/arch/arm64/include/asm/atomic.h
@@@ -173,72 -139,53 +173,76 @@@ static inline int __atomic_add_unless(a
   */
  #define ATOMIC64_INIT(i) { (i) }
  
++<<<<<<< HEAD
 +#define atomic64_read(v)	(*(volatile long long *)&(v)->counter)
++=======
+ #define atomic64_read(v)	ACCESS_ONCE((v)->counter)
++>>>>>>> 2291059c8527 (locking,arch: Use ACCESS_ONCE() instead of cast to volatile in atomic_read())
  #define atomic64_set(v,i)	(((v)->counter) = (i))
  
 -#define ATOMIC64_OP(op, asm_op)						\
 -static inline void atomic64_##op(long i, atomic64_t *v)			\
 -{									\
 -	long result;							\
 -	unsigned long tmp;						\
 -									\
 -	asm volatile("// atomic64_" #op "\n"				\
 -"1:	ldxr	%0, %2\n"						\
 -"	" #asm_op "	%0, %0, %3\n"					\
 -"	stxr	%w1, %0, %2\n"						\
 -"	cbnz	%w1, 1b"						\
 -	: "=&r" (result), "=&r" (tmp), "+Q" (v->counter)		\
 -	: "Ir" (i));							\
 -}									\
 -
 -#define ATOMIC64_OP_RETURN(op, asm_op)					\
 -static inline long atomic64_##op##_return(long i, atomic64_t *v)	\
 -{									\
 -	long result;							\
 -	unsigned long tmp;						\
 -									\
 -	asm volatile("// atomic64_" #op "_return\n"			\
 -"1:	ldxr	%0, %2\n"						\
 -"	" #asm_op "	%0, %0, %3\n"					\
 -"	stlxr	%w1, %0, %2\n"						\
 -"	cbnz	%w1, 1b"						\
 -	: "=&r" (result), "=&r" (tmp), "+Q" (v->counter)		\
 -	: "Ir" (i)							\
 -	: "memory");							\
 -									\
 -	smp_mb();							\
 -	return result;							\
 +static inline void atomic64_add(u64 i, atomic64_t *v)
 +{
 +	long result;
 +	unsigned long tmp;
 +
 +	asm volatile("// atomic64_add\n"
 +"1:	ldxr	%0, %2\n"
 +"	add	%0, %0, %3\n"
 +"	stxr	%w1, %0, %2\n"
 +"	cbnz	%w1, 1b"
 +	: "=&r" (result), "=&r" (tmp), "+Q" (v->counter)
 +	: "Ir" (i)
 +	: "cc");
  }
  
 -#define ATOMIC64_OPS(op, asm_op)					\
 -	ATOMIC64_OP(op, asm_op)						\
 -	ATOMIC64_OP_RETURN(op, asm_op)
 +static inline long atomic64_add_return(long i, atomic64_t *v)
 +{
 +	long result;
 +	unsigned long tmp;
  
 -ATOMIC64_OPS(add, add)
 -ATOMIC64_OPS(sub, sub)
 +	asm volatile("// atomic64_add_return\n"
 +"1:	ldaxr	%0, %2\n"
 +"	add	%0, %0, %3\n"
 +"	stlxr	%w1, %0, %2\n"
 +"	cbnz	%w1, 1b"
 +	: "=&r" (result), "=&r" (tmp), "+Q" (v->counter)
 +	: "Ir" (i)
 +	: "cc", "memory");
  
 -#undef ATOMIC64_OPS
 -#undef ATOMIC64_OP_RETURN
 -#undef ATOMIC64_OP
 +	return result;
 +}
 +
 +static inline void atomic64_sub(u64 i, atomic64_t *v)
 +{
 +	long result;
 +	unsigned long tmp;
 +
 +	asm volatile("// atomic64_sub\n"
 +"1:	ldxr	%0, %2\n"
 +"	sub	%0, %0, %3\n"
 +"	stxr	%w1, %0, %2\n"
 +"	cbnz	%w1, 1b"
 +	: "=&r" (result), "=&r" (tmp), "+Q" (v->counter)
 +	: "Ir" (i)
 +	: "cc");
 +}
 +
 +static inline long atomic64_sub_return(long i, atomic64_t *v)
 +{
 +	long result;
 +	unsigned long tmp;
 +
 +	asm volatile("// atomic64_sub_return\n"
 +"1:	ldaxr	%0, %2\n"
 +"	sub	%0, %0, %3\n"
 +"	stlxr	%w1, %0, %2\n"
 +"	cbnz	%w1, 1b"
 +	: "=&r" (result), "=&r" (tmp), "+Q" (v->counter)
 +	: "Ir" (i)
 +	: "cc", "memory");
 +
 +	return result;
 +}
  
  static inline long atomic64_cmpxchg(atomic64_t *ptr, long old, long new)
  {
diff --git a/arch/alpha/include/asm/atomic.h b/arch/alpha/include/asm/atomic.h
index c2cbe4fc391c..cdc41cd76eea 100644
--- a/arch/alpha/include/asm/atomic.h
+++ b/arch/alpha/include/asm/atomic.h
@@ -17,8 +17,8 @@
 #define ATOMIC_INIT(i)		{ (i) }
 #define ATOMIC64_INIT(i)	{ (i) }
 
-#define atomic_read(v)		(*(volatile int *)&(v)->counter)
-#define atomic64_read(v)	(*(volatile long *)&(v)->counter)
+#define atomic_read(v)		ACCESS_ONCE((v)->counter)
+#define atomic64_read(v)	ACCESS_ONCE((v)->counter)
 
 #define atomic_set(v,i)		((v)->counter = (i))
 #define atomic64_set(v,i)	((v)->counter = (i))
diff --git a/arch/arm/include/asm/atomic.h b/arch/arm/include/asm/atomic.h
index da1c77d39327..8c6cb8c071da 100644
--- a/arch/arm/include/asm/atomic.h
+++ b/arch/arm/include/asm/atomic.h
@@ -26,7 +26,7 @@
  * strex/ldrex monitor on some implementations. The reason we can use it for
  * atomic_set() is the clrex or dummy strex done on every exception return.
  */
-#define atomic_read(v)	(*(volatile int *)&(v)->counter)
+#define atomic_read(v)	ACCESS_ONCE((v)->counter)
 #define atomic_set(v,i)	(((v)->counter) = (i))
 
 #if __LINUX_ARM_ARCH__ >= 6
* Unmerged path arch/arm64/include/asm/atomic.h
diff --git a/arch/avr32/include/asm/atomic.h b/arch/avr32/include/asm/atomic.h
index 61407279208a..afc783362926 100644
--- a/arch/avr32/include/asm/atomic.h
+++ b/arch/avr32/include/asm/atomic.h
@@ -19,7 +19,7 @@
 
 #define ATOMIC_INIT(i)  { (i) }
 
-#define atomic_read(v)		(*(volatile int *)&(v)->counter)
+#define atomic_read(v)		ACCESS_ONCE((v)->counter)
 #define atomic_set(v, i)	(((v)->counter) = i)
 
 /*
diff --git a/arch/cris/include/asm/atomic.h b/arch/cris/include/asm/atomic.h
index 1056a5dfe04f..63f4cb7a7e9f 100644
--- a/arch/cris/include/asm/atomic.h
+++ b/arch/cris/include/asm/atomic.h
@@ -15,7 +15,7 @@
 
 #define ATOMIC_INIT(i)  { (i) }
 
-#define atomic_read(v) (*(volatile int *)&(v)->counter)
+#define atomic_read(v) ACCESS_ONCE((v)->counter)
 #define atomic_set(v,i) (((v)->counter) = (i))
 
 /* These should be written in asm but we do it in C for now. */
diff --git a/arch/frv/include/asm/atomic.h b/arch/frv/include/asm/atomic.h
index b86329d0e316..a1e565fda20e 100644
--- a/arch/frv/include/asm/atomic.h
+++ b/arch/frv/include/asm/atomic.h
@@ -36,7 +36,7 @@
 #define smp_mb__after_atomic_inc()	barrier()
 
 #define ATOMIC_INIT(i)		{ (i) }
-#define atomic_read(v)		(*(volatile int *)&(v)->counter)
+#define atomic_read(v)		ACCESS_ONCE((v)->counter)
 #define atomic_set(v, i)	(((v)->counter) = (i))
 
 #ifndef CONFIG_FRV_OUTOFLINE_ATOMIC_OPS
diff --git a/arch/ia64/include/asm/atomic.h b/arch/ia64/include/asm/atomic.h
index 6e6fe1839f5d..13b3bfa54d49 100644
--- a/arch/ia64/include/asm/atomic.h
+++ b/arch/ia64/include/asm/atomic.h
@@ -20,8 +20,8 @@
 #define ATOMIC_INIT(i)		{ (i) }
 #define ATOMIC64_INIT(i)	{ (i) }
 
-#define atomic_read(v)		(*(volatile int *)&(v)->counter)
-#define atomic64_read(v)	(*(volatile long *)&(v)->counter)
+#define atomic_read(v)		ACCESS_ONCE((v)->counter)
+#define atomic64_read(v)	ACCESS_ONCE((v)->counter)
 
 #define atomic_set(v,i)		(((v)->counter) = (i))
 #define atomic64_set(v,i)	(((v)->counter) = (i))
diff --git a/arch/m32r/include/asm/atomic.h b/arch/m32r/include/asm/atomic.h
index 0d81697c326c..a3b22aaa2f02 100644
--- a/arch/m32r/include/asm/atomic.h
+++ b/arch/m32r/include/asm/atomic.h
@@ -27,7 +27,7 @@
  *
  * Atomically reads the value of @v.
  */
-#define atomic_read(v)	(*(volatile int *)&(v)->counter)
+#define atomic_read(v)	ACCESS_ONCE((v)->counter)
 
 /**
  * atomic_set - set atomic variable
diff --git a/arch/m68k/include/asm/atomic.h b/arch/m68k/include/asm/atomic.h
index f4e32de263a7..a7cd4d1a58c2 100644
--- a/arch/m68k/include/asm/atomic.h
+++ b/arch/m68k/include/asm/atomic.h
@@ -16,7 +16,7 @@
 
 #define ATOMIC_INIT(i)	{ (i) }
 
-#define atomic_read(v)		(*(volatile int *)&(v)->counter)
+#define atomic_read(v)		ACCESS_ONCE((v)->counter)
 #define atomic_set(v, i)	(((v)->counter) = i)
 
 /*
diff --git a/arch/mips/include/asm/atomic.h b/arch/mips/include/asm/atomic.h
index 08b607969a16..c6488ba4fc64 100644
--- a/arch/mips/include/asm/atomic.h
+++ b/arch/mips/include/asm/atomic.h
@@ -29,7 +29,7 @@
  *
  * Atomically reads the value of @v.
  */
-#define atomic_read(v)		(*(volatile int *)&(v)->counter)
+#define atomic_read(v)		ACCESS_ONCE((v)->counter)
 
 /*
  * atomic_set - set atomic variable
@@ -398,7 +398,7 @@ static __inline__ int __atomic_add_unless(atomic_t *v, int a, int u)
  * @v: pointer of type atomic64_t
  *
  */
-#define atomic64_read(v)	(*(volatile long *)&(v)->counter)
+#define atomic64_read(v)	ACCESS_ONCE((v)->counter)
 
 /*
  * atomic64_set - set atomic variable
diff --git a/arch/parisc/include/asm/atomic.h b/arch/parisc/include/asm/atomic.h
index 472886ceab1d..f3ab59092740 100644
--- a/arch/parisc/include/asm/atomic.h
+++ b/arch/parisc/include/asm/atomic.h
@@ -83,7 +83,7 @@ static __inline__ void atomic_set(atomic_t *v, int i)
 
 static __inline__ int atomic_read(const atomic_t *v)
 {
-	return (*(volatile int *)&(v)->counter);
+	return ACCESS_ONCE((v)->counter);
 }
 
 /* exported interface */
@@ -179,7 +179,7 @@ atomic64_set(atomic64_t *v, s64 i)
 static __inline__ s64
 atomic64_read(const atomic64_t *v)
 {
-	return (*(volatile long *)&(v)->counter);
+	return ACCESS_ONCE((v)->counter);
 }
 
 #define atomic64_add(i,v)	((void)(__atomic64_add_return( ((s64)(i)),(v))))
diff --git a/arch/sh/include/asm/atomic.h b/arch/sh/include/asm/atomic.h
index f4c1c20bcdf6..abf583f4d9ee 100644
--- a/arch/sh/include/asm/atomic.h
+++ b/arch/sh/include/asm/atomic.h
@@ -13,7 +13,7 @@
 
 #define ATOMIC_INIT(i)	{ (i) }
 
-#define atomic_read(v)		(*(volatile int *)&(v)->counter)
+#define atomic_read(v)		ACCESS_ONCE((v)->counter)
 #define atomic_set(v,i)		((v)->counter = (i))
 
 #if defined(CONFIG_GUSA_RB)
diff --git a/arch/sparc/include/asm/atomic_32.h b/arch/sparc/include/asm/atomic_32.h
index 905832aa9e9e..5a59d0f5fb41 100644
--- a/arch/sparc/include/asm/atomic_32.h
+++ b/arch/sparc/include/asm/atomic_32.h
@@ -25,7 +25,7 @@ extern int atomic_cmpxchg(atomic_t *, int, int);
 extern int __atomic_add_unless(atomic_t *, int, int);
 extern void atomic_set(atomic_t *, int);
 
-#define atomic_read(v)          (*(volatile int *)&(v)->counter)
+#define atomic_read(v)          ACCESS_ONCE((v)->counter)
 
 #define atomic_add(i, v)	((void)__atomic_add_return( (int)(i), (v)))
 #define atomic_sub(i, v)	((void)__atomic_add_return(-(int)(i), (v)))
diff --git a/arch/sparc/include/asm/atomic_64.h b/arch/sparc/include/asm/atomic_64.h
index be56a244c9cf..9a0dcac92cb8 100644
--- a/arch/sparc/include/asm/atomic_64.h
+++ b/arch/sparc/include/asm/atomic_64.h
@@ -13,8 +13,8 @@
 #define ATOMIC_INIT(i)		{ (i) }
 #define ATOMIC64_INIT(i)	{ (i) }
 
-#define atomic_read(v)		(*(volatile int *)&(v)->counter)
-#define atomic64_read(v)	(*(volatile long *)&(v)->counter)
+#define atomic_read(v)		ACCESS_ONCE((v)->counter)
+#define atomic64_read(v)	ACCESS_ONCE((v)->counter)
 
 #define atomic_set(v, i)	(((v)->counter) = i)
 #define atomic64_set(v, i)	(((v)->counter) = i)
diff --git a/arch/x86/include/asm/atomic.h b/arch/x86/include/asm/atomic.h
index 241d95f4269b..a5129926bd2d 100644
--- a/arch/x86/include/asm/atomic.h
+++ b/arch/x86/include/asm/atomic.h
@@ -23,7 +23,7 @@
  */
 static inline int atomic_read(const atomic_t *v)
 {
-	return (*(volatile int *)&(v)->counter);
+	return ACCESS_ONCE((v)->counter);
 }
 
 /**
diff --git a/arch/x86/include/asm/atomic64_64.h b/arch/x86/include/asm/atomic64_64.h
index 0e1cbfc8ee06..80dac9bb473a 100644
--- a/arch/x86/include/asm/atomic64_64.h
+++ b/arch/x86/include/asm/atomic64_64.h
@@ -18,7 +18,7 @@
  */
 static inline long atomic64_read(const atomic64_t *v)
 {
-	return (*(volatile long *)&(v)->counter);
+	return ACCESS_ONCE((v)->counter);
 }
 
 /**
diff --git a/arch/xtensa/include/asm/atomic.h b/arch/xtensa/include/asm/atomic.h
index e7fb447bce8e..316d0bc276aa 100644
--- a/arch/xtensa/include/asm/atomic.h
+++ b/arch/xtensa/include/asm/atomic.h
@@ -46,7 +46,7 @@
  *
  * Atomically reads the value of @v.
  */
-#define atomic_read(v)		(*(volatile int *)&(v)->counter)
+#define atomic_read(v)		ACCESS_ONCE((v)->counter)
 
 /**
  * atomic_set - set atomic variable
diff --git a/include/asm-generic/atomic.h b/include/asm-generic/atomic.h
index 9c79e7603459..c916ecc0963f 100644
--- a/include/asm-generic/atomic.h
+++ b/include/asm-generic/atomic.h
@@ -42,7 +42,7 @@
  * Atomically reads the value of @v.
  */
 #ifndef atomic_read
-#define atomic_read(v)	(*(volatile int *)&(v)->counter)
+#define atomic_read(v)	ACCESS_ONCE((v)->counter)
 #endif
 
 /**
