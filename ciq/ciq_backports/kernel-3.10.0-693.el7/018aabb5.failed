KVM: x86: MMU: Encapsulate the type of rmap-chain head in a new struct

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Takuya Yoshikawa <yoshikawa_takuya_b1@lab.ntt.co.jp>
commit 018aabb56d6109c8f12397c24e59f67c58870ac1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/018aabb5.failed

New struct kvm_rmap_head makes the code type-safe to some extent.

	Signed-off-by: Takuya Yoshikawa <yoshikawa_takuya_b1@lab.ntt.co.jp>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 018aabb56d6109c8f12397c24e59f67c58870ac1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu.c
diff --cc arch/x86/kvm/mmu.c
index f0b28ccbb086,d9a6801457aa..000000000000
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@@ -1564,26 -1572,16 +1565,31 @@@ static int kvm_age_rmapp(struct kvm *kv
  	struct rmap_iterator uninitialized_var(iter);
  	int young = 0;
  
 -	BUG_ON(!shadow_accessed_mask);
 +	/*
 +	 * In case of absence of EPT Access and Dirty Bits supports,
 +	 * emulate the accessed bit for EPT, by checking if this page has
 +	 * an EPT mapping, and clearing it if it does. On the next access,
 +	 * a new EPT mapping will be established.
 +	 * This has some overhead, but not as much as the cost of swapping
 +	 * out actively used pages or breaking up actively used hugepages.
 +	 */
 +	if (!shadow_accessed_mask) {
 +		young = kvm_unmap_rmapp(kvm, rmapp, slot, gfn, level, data);
 +		goto out;
 +	}
  
- 	for_each_rmap_spte(rmapp, &iter, sptep)
+ 	for_each_rmap_spte(rmap_head, &iter, sptep) {
  		if (*sptep & shadow_accessed_mask) {
  			young = 1;
  			clear_bit((ffs(shadow_accessed_mask) - 1),
  				 (unsigned long *)sptep);
  		}
++<<<<<<< HEAD
 +out:
++=======
+ 	}
+ 
++>>>>>>> 018aabb56d61 (KVM: x86: MMU: Encapsulate the type of rmap-chain head in a new struct)
  	trace_kvm_age_page(gfn, level, slot, young);
  	return young;
  }
diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index 38430109c621..da0958cde03a 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -214,6 +214,10 @@ union kvm_mmu_page_role {
 	};
 };
 
+struct kvm_rmap_head {
+	unsigned long val;
+};
+
 struct kvm_mmu_page {
 	struct list_head link;
 	struct hlist_node hash_link;
@@ -231,7 +235,7 @@ struct kvm_mmu_page {
 	bool unsync;
 	int root_count;          /* Currently serving as active root */
 	unsigned int unsync_children;
-	unsigned long parent_ptes;	/* Reverse mapping for parent_pte */
+	struct kvm_rmap_head parent_ptes; /* rmap pointers to parent sptes */
 
 	/* The page is obsolete if mmu_valid_gen != kvm->arch.mmu_valid_gen.  */
 	unsigned long mmu_valid_gen;
@@ -569,7 +573,7 @@ struct kvm_lpage_info {
 };
 
 struct kvm_arch_memory_slot {
-	unsigned long *rmap[KVM_NR_PAGE_SIZES];
+	struct kvm_rmap_head *rmap[KVM_NR_PAGE_SIZES];
 	struct kvm_lpage_info *lpage_info[KVM_NR_PAGE_SIZES - 1];
 };
 
* Unmerged path arch/x86/kvm/mmu.c
diff --git a/arch/x86/kvm/mmu_audit.c b/arch/x86/kvm/mmu_audit.c
index fa2f2982157c..e28ef59dc34e 100644
--- a/arch/x86/kvm/mmu_audit.c
+++ b/arch/x86/kvm/mmu_audit.c
@@ -129,7 +129,7 @@ static void audit_mappings(struct kvm_vcpu *vcpu, u64 *sptep, int level)
 static void inspect_spte_has_rmap(struct kvm *kvm, u64 *sptep)
 {
 	static DEFINE_RATELIMIT_STATE(ratelimit_state, 5 * HZ, 10);
-	unsigned long *rmapp;
+	struct kvm_rmap_head *rmap_head;
 	struct kvm_mmu_page *rev_sp;
 	struct kvm_memslots *slots;
 	struct kvm_memory_slot *slot;
@@ -150,8 +150,8 @@ static void inspect_spte_has_rmap(struct kvm *kvm, u64 *sptep)
 		return;
 	}
 
-	rmapp = __gfn_to_rmap(gfn, rev_sp->role.level, slot);
-	if (!*rmapp) {
+	rmap_head = __gfn_to_rmap(gfn, rev_sp->role.level, slot);
+	if (!rmap_head->val) {
 		if (!__ratelimit(&ratelimit_state))
 			return;
 		audit_printk(kvm, "no rmap for writable spte %llx\n",
@@ -192,7 +192,7 @@ static void check_mappings_rmap(struct kvm *kvm, struct kvm_mmu_page *sp)
 
 static void audit_write_protection(struct kvm *kvm, struct kvm_mmu_page *sp)
 {
-	unsigned long *rmapp;
+	struct kvm_rmap_head *rmap_head;
 	u64 *sptep;
 	struct rmap_iterator iter;
 	struct kvm_memslots *slots;
@@ -203,13 +203,14 @@ static void audit_write_protection(struct kvm *kvm, struct kvm_mmu_page *sp)
 
 	slots = kvm_memslots_for_spte_role(kvm, sp->role);
 	slot = __gfn_to_memslot(slots, sp->gfn);
-	rmapp = __gfn_to_rmap(sp->gfn, PT_PAGE_TABLE_LEVEL, slot);
+	rmap_head = __gfn_to_rmap(sp->gfn, PT_PAGE_TABLE_LEVEL, slot);
 
-	for_each_rmap_spte(rmapp, &iter, sptep)
+	for_each_rmap_spte(rmap_head, &iter, sptep) {
 		if (is_writable_pte(*sptep))
 			audit_printk(kvm, "shadow page has writable "
 				     "mappings: gfn %llx role %x\n",
 				     sp->gfn, sp->role.word);
+	}
 }
 
 static void audit_sp(struct kvm *kvm, struct kvm_mmu_page *sp)
