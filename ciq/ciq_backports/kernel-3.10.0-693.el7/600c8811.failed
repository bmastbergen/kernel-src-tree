amd-xgbe: Clarify output message about queues

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Lendacky, Thomas <Thomas.Lendacky@amd.com>
commit 600c8811d3f608d28a6a79bfbcca08bb7962f301
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/600c8811.failed

Clarify that the queues referred to in a message when the device is
brought up are hardware queues and not necessarily related to the
Linux network queues.

	Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 600c8811d3f608d28a6a79bfbcca08bb7962f301)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/amd/xgbe/xgbe-dev.c
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-dev.c
index ec5481f846ee,29137c9e2200..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
@@@ -1491,13 -1999,14 +1491,19 @@@ static void xgbe_config_tx_fifo_size(st
  	unsigned int i;
  
  	fifo_size = xgbe_calculate_per_queue_fifo(pdata->hw_feat.tx_fifo_size,
 -						  pdata->tx_q_count);
 +						  pdata->hw_feat.tx_q_cnt);
  
 -	for (i = 0; i < pdata->tx_q_count; i++)
 +	for (i = 0; i < pdata->hw_feat.tx_q_cnt; i++)
  		XGMAC_MTL_IOWRITE_BITS(pdata, i, MTL_Q_TQOMR, TQS, fifo_size);
  
++<<<<<<< HEAD
 +	netdev_notice(pdata->netdev, "%d Tx queues, %d byte fifo per queue\n",
 +		      pdata->hw_feat.tx_q_cnt, ((fifo_size + 1) * 256));
++=======
+ 	netdev_notice(pdata->netdev,
+ 		      "%d Tx hardware queues, %d byte fifo per queue\n",
+ 		      pdata->tx_q_count, ((fifo_size + 1) * 256));
++>>>>>>> 600c8811d3f6 (amd-xgbe: Clarify output message about queues)
  }
  
  static void xgbe_config_rx_fifo_size(struct xgbe_prv_data *pdata)
@@@ -1506,19 -2015,77 +1512,25 @@@
  	unsigned int i;
  
  	fifo_size = xgbe_calculate_per_queue_fifo(pdata->hw_feat.rx_fifo_size,
 -						  pdata->rx_q_count);
 +						  pdata->hw_feat.rx_q_cnt);
  
 -	for (i = 0; i < pdata->rx_q_count; i++)
 +	for (i = 0; i < pdata->hw_feat.rx_q_cnt; i++)
  		XGMAC_MTL_IOWRITE_BITS(pdata, i, MTL_Q_RQOMR, RQS, fifo_size);
  
++<<<<<<< HEAD
 +	netdev_notice(pdata->netdev, "%d Rx queues, %d byte fifo per queue\n",
 +		      pdata->hw_feat.rx_q_cnt, ((fifo_size + 1) * 256));
++=======
+ 	netdev_notice(pdata->netdev,
+ 		      "%d Rx hardware queues, %d byte fifo per queue\n",
+ 		      pdata->rx_q_count, ((fifo_size + 1) * 256));
++>>>>>>> 600c8811d3f6 (amd-xgbe: Clarify output message about queues)
  }
  
 -static void xgbe_config_queue_mapping(struct xgbe_prv_data *pdata)
 +static void xgbe_config_rx_queue_mapping(struct xgbe_prv_data *pdata)
  {
 -	unsigned int qptc, qptc_extra, queue;
 -	unsigned int prio_queues;
 -	unsigned int ppq, ppq_extra, prio;
 -	unsigned int mask;
 -	unsigned int i, j, reg, reg_val;
 -
 -	/* Map the MTL Tx Queues to Traffic Classes
 -	 *   Note: Tx Queues >= Traffic Classes
 -	 */
 -	qptc = pdata->tx_q_count / pdata->hw_feat.tc_cnt;
 -	qptc_extra = pdata->tx_q_count % pdata->hw_feat.tc_cnt;
 -
 -	for (i = 0, queue = 0; i < pdata->hw_feat.tc_cnt; i++) {
 -		for (j = 0; j < qptc; j++) {
 -			DBGPR("  TXq%u mapped to TC%u\n", queue, i);
 -			XGMAC_MTL_IOWRITE_BITS(pdata, queue, MTL_Q_TQOMR,
 -					       Q2TCMAP, i);
 -			pdata->q2tc_map[queue++] = i;
 -		}
 -
 -		if (i < qptc_extra) {
 -			DBGPR("  TXq%u mapped to TC%u\n", queue, i);
 -			XGMAC_MTL_IOWRITE_BITS(pdata, queue, MTL_Q_TQOMR,
 -					       Q2TCMAP, i);
 -			pdata->q2tc_map[queue++] = i;
 -		}
 -	}
 -
 -	/* Map the 8 VLAN priority values to available MTL Rx queues */
 -	prio_queues = min_t(unsigned int, IEEE_8021QAZ_MAX_TCS,
 -			    pdata->rx_q_count);
 -	ppq = IEEE_8021QAZ_MAX_TCS / prio_queues;
 -	ppq_extra = IEEE_8021QAZ_MAX_TCS % prio_queues;
 -
 -	reg = MAC_RQC2R;
 -	reg_val = 0;
 -	for (i = 0, prio = 0; i < prio_queues;) {
 -		mask = 0;
 -		for (j = 0; j < ppq; j++) {
 -			DBGPR("  PRIO%u mapped to RXq%u\n", prio, i);
 -			mask |= (1 << prio);
 -			pdata->prio2q_map[prio++] = i;
 -		}
 -
 -		if (i < ppq_extra) {
 -			DBGPR("  PRIO%u mapped to RXq%u\n", prio, i);
 -			mask |= (1 << prio);
 -			pdata->prio2q_map[prio++] = i;
 -		}
 -
 -		reg_val |= (mask << ((i++ % MAC_RQC2_Q_PER_REG) << 3));
 -
 -		if ((i % MAC_RQC2_Q_PER_REG) && (i != prio_queues))
 -			continue;
 -
 -		XGMAC_IOWRITE(pdata, reg, reg_val);
 -		reg += MAC_RQC2_INC;
 -		reg_val = 0;
 -	}
 +	unsigned int i, reg, reg_val;
 +	unsigned int q_count = pdata->hw_feat.rx_q_cnt;
  
  	/* Select dynamic mapping of MTL Rx queue to DMA Rx channel */
  	reg = MTL_RQDCM0R;
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-dev.c
