bridge: netlink: register netdevice before executing changelink

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Ido Schimmel <idosch@mellanox.com>
commit 5b8d5429daa05bebef6ffd3297df3b502cc6f184
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/5b8d5429.failed

Peter reported a kernel oops when executing the following command:

$ ip link add name test type bridge vlan_default_pvid 1

[13634.939408] BUG: unable to handle kernel NULL pointer dereference at
0000000000000190
[13634.939436] IP: __vlan_add+0x73/0x5f0
[...]
[13634.939783] Call Trace:
[13634.939791]  ? pcpu_next_unpop+0x3b/0x50
[13634.939801]  ? pcpu_alloc+0x3d2/0x680
[13634.939810]  ? br_vlan_add+0x135/0x1b0
[13634.939820]  ? __br_vlan_set_default_pvid.part.28+0x204/0x2b0
[13634.939834]  ? br_changelink+0x120/0x4e0
[13634.939844]  ? br_dev_newlink+0x50/0x70
[13634.939854]  ? rtnl_newlink+0x5f5/0x8a0
[13634.939864]  ? rtnl_newlink+0x176/0x8a0
[13634.939874]  ? mem_cgroup_commit_charge+0x7c/0x4e0
[13634.939886]  ? rtnetlink_rcv_msg+0xe1/0x220
[13634.939896]  ? lookup_fast+0x52/0x370
[13634.939905]  ? rtnl_newlink+0x8a0/0x8a0
[13634.939915]  ? netlink_rcv_skb+0xa1/0xc0
[13634.939925]  ? rtnetlink_rcv+0x24/0x30
[13634.939934]  ? netlink_unicast+0x177/0x220
[13634.939944]  ? netlink_sendmsg+0x2fe/0x3b0
[13634.939954]  ? _copy_from_user+0x39/0x40
[13634.939964]  ? sock_sendmsg+0x30/0x40
[13634.940159]  ? ___sys_sendmsg+0x29d/0x2b0
[13634.940326]  ? __alloc_pages_nodemask+0xdf/0x230
[13634.940478]  ? mem_cgroup_commit_charge+0x7c/0x4e0
[13634.940592]  ? mem_cgroup_try_charge+0x76/0x1a0
[13634.940701]  ? __handle_mm_fault+0xdb9/0x10b0
[13634.940809]  ? __sys_sendmsg+0x51/0x90
[13634.940917]  ? entry_SYSCALL_64_fastpath+0x1e/0xad

The problem is that the bridge's VLAN group is created after setting the
default PVID, when registering the netdevice and executing its
ndo_init().

Fix this by changing the order of both operations, so that
br_changelink() is only processed after the netdevice is registered,
when the VLAN group is already initialized.

Fixes: b6677449dff6 ("bridge: netlink: call br_changelink() during br_dev_newlink()")
	Signed-off-by: Nikolay Aleksandrov <nikolay@cumulusnetworks.com>
	Signed-off-by: Ido Schimmel <idosch@mellanox.com>
	Reported-by: Peter V. Saveliev <peter@svinota.eu>
	Tested-by: Peter V. Saveliev <peter@svinota.eu>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 5b8d5429daa05bebef6ffd3297df3b502cc6f184)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/bridge/br_netlink.c
diff --cc net/bridge/br_netlink.c
index 2f4d900feeb1,225ef7d53701..000000000000
--- a/net/bridge/br_netlink.c
+++ b/net/bridge/br_netlink.c
@@@ -611,6 -818,363 +611,351 @@@ static int br_validate(struct nlattr *t
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static int br_port_slave_changelink(struct net_device *brdev,
+ 				    struct net_device *dev,
+ 				    struct nlattr *tb[],
+ 				    struct nlattr *data[])
+ {
+ 	struct net_bridge *br = netdev_priv(brdev);
+ 	int ret;
+ 
+ 	if (!data)
+ 		return 0;
+ 
+ 	spin_lock_bh(&br->lock);
+ 	ret = br_setport(br_port_get_rtnl(dev), data);
+ 	spin_unlock_bh(&br->lock);
+ 
+ 	return ret;
+ }
+ 
+ static int br_port_fill_slave_info(struct sk_buff *skb,
+ 				   const struct net_device *brdev,
+ 				   const struct net_device *dev)
+ {
+ 	return br_port_fill_attrs(skb, br_port_get_rtnl(dev));
+ }
+ 
+ static size_t br_port_get_slave_size(const struct net_device *brdev,
+ 				     const struct net_device *dev)
+ {
+ 	return br_port_info_size();
+ }
+ 
+ static const struct nla_policy br_policy[IFLA_BR_MAX + 1] = {
+ 	[IFLA_BR_FORWARD_DELAY]	= { .type = NLA_U32 },
+ 	[IFLA_BR_HELLO_TIME]	= { .type = NLA_U32 },
+ 	[IFLA_BR_MAX_AGE]	= { .type = NLA_U32 },
+ 	[IFLA_BR_AGEING_TIME] = { .type = NLA_U32 },
+ 	[IFLA_BR_STP_STATE] = { .type = NLA_U32 },
+ 	[IFLA_BR_PRIORITY] = { .type = NLA_U16 },
+ 	[IFLA_BR_VLAN_FILTERING] = { .type = NLA_U8 },
+ 	[IFLA_BR_VLAN_PROTOCOL] = { .type = NLA_U16 },
+ 	[IFLA_BR_GROUP_FWD_MASK] = { .type = NLA_U16 },
+ 	[IFLA_BR_GROUP_ADDR] = { .type = NLA_BINARY,
+ 				 .len  = ETH_ALEN },
+ 	[IFLA_BR_MCAST_ROUTER] = { .type = NLA_U8 },
+ 	[IFLA_BR_MCAST_SNOOPING] = { .type = NLA_U8 },
+ 	[IFLA_BR_MCAST_QUERY_USE_IFADDR] = { .type = NLA_U8 },
+ 	[IFLA_BR_MCAST_QUERIER] = { .type = NLA_U8 },
+ 	[IFLA_BR_MCAST_HASH_ELASTICITY] = { .type = NLA_U32 },
+ 	[IFLA_BR_MCAST_HASH_MAX] = { .type = NLA_U32 },
+ 	[IFLA_BR_MCAST_LAST_MEMBER_CNT] = { .type = NLA_U32 },
+ 	[IFLA_BR_MCAST_STARTUP_QUERY_CNT] = { .type = NLA_U32 },
+ 	[IFLA_BR_MCAST_LAST_MEMBER_INTVL] = { .type = NLA_U64 },
+ 	[IFLA_BR_MCAST_MEMBERSHIP_INTVL] = { .type = NLA_U64 },
+ 	[IFLA_BR_MCAST_QUERIER_INTVL] = { .type = NLA_U64 },
+ 	[IFLA_BR_MCAST_QUERY_INTVL] = { .type = NLA_U64 },
+ 	[IFLA_BR_MCAST_QUERY_RESPONSE_INTVL] = { .type = NLA_U64 },
+ 	[IFLA_BR_MCAST_STARTUP_QUERY_INTVL] = { .type = NLA_U64 },
+ 	[IFLA_BR_NF_CALL_IPTABLES] = { .type = NLA_U8 },
+ 	[IFLA_BR_NF_CALL_IP6TABLES] = { .type = NLA_U8 },
+ 	[IFLA_BR_NF_CALL_ARPTABLES] = { .type = NLA_U8 },
+ 	[IFLA_BR_VLAN_DEFAULT_PVID] = { .type = NLA_U16 },
+ 	[IFLA_BR_VLAN_STATS_ENABLED] = { .type = NLA_U8 },
+ 	[IFLA_BR_MCAST_STATS_ENABLED] = { .type = NLA_U8 },
+ 	[IFLA_BR_MCAST_IGMP_VERSION] = { .type = NLA_U8 },
+ 	[IFLA_BR_MCAST_MLD_VERSION] = { .type = NLA_U8 },
+ };
+ 
+ static int br_changelink(struct net_device *brdev, struct nlattr *tb[],
+ 			 struct nlattr *data[])
+ {
+ 	struct net_bridge *br = netdev_priv(brdev);
+ 	int err;
+ 
+ 	if (!data)
+ 		return 0;
+ 
+ 	if (data[IFLA_BR_FORWARD_DELAY]) {
+ 		err = br_set_forward_delay(br, nla_get_u32(data[IFLA_BR_FORWARD_DELAY]));
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_HELLO_TIME]) {
+ 		err = br_set_hello_time(br, nla_get_u32(data[IFLA_BR_HELLO_TIME]));
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_MAX_AGE]) {
+ 		err = br_set_max_age(br, nla_get_u32(data[IFLA_BR_MAX_AGE]));
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_AGEING_TIME]) {
+ 		err = br_set_ageing_time(br, nla_get_u32(data[IFLA_BR_AGEING_TIME]));
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_STP_STATE]) {
+ 		u32 stp_enabled = nla_get_u32(data[IFLA_BR_STP_STATE]);
+ 
+ 		br_stp_set_enabled(br, stp_enabled);
+ 	}
+ 
+ 	if (data[IFLA_BR_PRIORITY]) {
+ 		u32 priority = nla_get_u16(data[IFLA_BR_PRIORITY]);
+ 
+ 		br_stp_set_bridge_priority(br, priority);
+ 	}
+ 
+ 	if (data[IFLA_BR_VLAN_FILTERING]) {
+ 		u8 vlan_filter = nla_get_u8(data[IFLA_BR_VLAN_FILTERING]);
+ 
+ 		err = __br_vlan_filter_toggle(br, vlan_filter);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ #ifdef CONFIG_BRIDGE_VLAN_FILTERING
+ 	if (data[IFLA_BR_VLAN_PROTOCOL]) {
+ 		__be16 vlan_proto = nla_get_be16(data[IFLA_BR_VLAN_PROTOCOL]);
+ 
+ 		err = __br_vlan_set_proto(br, vlan_proto);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_VLAN_DEFAULT_PVID]) {
+ 		__u16 defpvid = nla_get_u16(data[IFLA_BR_VLAN_DEFAULT_PVID]);
+ 
+ 		err = __br_vlan_set_default_pvid(br, defpvid);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_VLAN_STATS_ENABLED]) {
+ 		__u8 vlan_stats = nla_get_u8(data[IFLA_BR_VLAN_STATS_ENABLED]);
+ 
+ 		err = br_vlan_set_stats(br, vlan_stats);
+ 		if (err)
+ 			return err;
+ 	}
+ #endif
+ 
+ 	if (data[IFLA_BR_GROUP_FWD_MASK]) {
+ 		u16 fwd_mask = nla_get_u16(data[IFLA_BR_GROUP_FWD_MASK]);
+ 
+ 		if (fwd_mask & BR_GROUPFWD_RESTRICTED)
+ 			return -EINVAL;
+ 		br->group_fwd_mask = fwd_mask;
+ 	}
+ 
+ 	if (data[IFLA_BR_GROUP_ADDR]) {
+ 		u8 new_addr[ETH_ALEN];
+ 
+ 		if (nla_len(data[IFLA_BR_GROUP_ADDR]) != ETH_ALEN)
+ 			return -EINVAL;
+ 		memcpy(new_addr, nla_data(data[IFLA_BR_GROUP_ADDR]), ETH_ALEN);
+ 		if (!is_link_local_ether_addr(new_addr))
+ 			return -EINVAL;
+ 		if (new_addr[5] == 1 ||		/* 802.3x Pause address */
+ 		    new_addr[5] == 2 ||		/* 802.3ad Slow protocols */
+ 		    new_addr[5] == 3)		/* 802.1X PAE address */
+ 			return -EINVAL;
+ 		spin_lock_bh(&br->lock);
+ 		memcpy(br->group_addr, new_addr, sizeof(br->group_addr));
+ 		spin_unlock_bh(&br->lock);
+ 		br->group_addr_set = true;
+ 		br_recalculate_fwd_mask(br);
+ 	}
+ 
+ 	if (data[IFLA_BR_FDB_FLUSH])
+ 		br_fdb_flush(br);
+ 
+ #ifdef CONFIG_BRIDGE_IGMP_SNOOPING
+ 	if (data[IFLA_BR_MCAST_ROUTER]) {
+ 		u8 multicast_router = nla_get_u8(data[IFLA_BR_MCAST_ROUTER]);
+ 
+ 		err = br_multicast_set_router(br, multicast_router);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_SNOOPING]) {
+ 		u8 mcast_snooping = nla_get_u8(data[IFLA_BR_MCAST_SNOOPING]);
+ 
+ 		err = br_multicast_toggle(br, mcast_snooping);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_QUERY_USE_IFADDR]) {
+ 		u8 val;
+ 
+ 		val = nla_get_u8(data[IFLA_BR_MCAST_QUERY_USE_IFADDR]);
+ 		br->multicast_query_use_ifaddr = !!val;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_QUERIER]) {
+ 		u8 mcast_querier = nla_get_u8(data[IFLA_BR_MCAST_QUERIER]);
+ 
+ 		err = br_multicast_set_querier(br, mcast_querier);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_HASH_ELASTICITY]) {
+ 		u32 val = nla_get_u32(data[IFLA_BR_MCAST_HASH_ELASTICITY]);
+ 
+ 		br->hash_elasticity = val;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_HASH_MAX]) {
+ 		u32 hash_max = nla_get_u32(data[IFLA_BR_MCAST_HASH_MAX]);
+ 
+ 		err = br_multicast_set_hash_max(br, hash_max);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_LAST_MEMBER_CNT]) {
+ 		u32 val = nla_get_u32(data[IFLA_BR_MCAST_LAST_MEMBER_CNT]);
+ 
+ 		br->multicast_last_member_count = val;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_STARTUP_QUERY_CNT]) {
+ 		u32 val = nla_get_u32(data[IFLA_BR_MCAST_STARTUP_QUERY_CNT]);
+ 
+ 		br->multicast_startup_query_count = val;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_LAST_MEMBER_INTVL]) {
+ 		u64 val = nla_get_u64(data[IFLA_BR_MCAST_LAST_MEMBER_INTVL]);
+ 
+ 		br->multicast_last_member_interval = clock_t_to_jiffies(val);
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_MEMBERSHIP_INTVL]) {
+ 		u64 val = nla_get_u64(data[IFLA_BR_MCAST_MEMBERSHIP_INTVL]);
+ 
+ 		br->multicast_membership_interval = clock_t_to_jiffies(val);
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_QUERIER_INTVL]) {
+ 		u64 val = nla_get_u64(data[IFLA_BR_MCAST_QUERIER_INTVL]);
+ 
+ 		br->multicast_querier_interval = clock_t_to_jiffies(val);
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_QUERY_INTVL]) {
+ 		u64 val = nla_get_u64(data[IFLA_BR_MCAST_QUERY_INTVL]);
+ 
+ 		br->multicast_query_interval = clock_t_to_jiffies(val);
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_QUERY_RESPONSE_INTVL]) {
+ 		u64 val = nla_get_u64(data[IFLA_BR_MCAST_QUERY_RESPONSE_INTVL]);
+ 
+ 		br->multicast_query_response_interval = clock_t_to_jiffies(val);
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_STARTUP_QUERY_INTVL]) {
+ 		u64 val = nla_get_u64(data[IFLA_BR_MCAST_STARTUP_QUERY_INTVL]);
+ 
+ 		br->multicast_startup_query_interval = clock_t_to_jiffies(val);
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_STATS_ENABLED]) {
+ 		__u8 mcast_stats;
+ 
+ 		mcast_stats = nla_get_u8(data[IFLA_BR_MCAST_STATS_ENABLED]);
+ 		br->multicast_stats_enabled = !!mcast_stats;
+ 	}
+ 
+ 	if (data[IFLA_BR_MCAST_IGMP_VERSION]) {
+ 		__u8 igmp_version;
+ 
+ 		igmp_version = nla_get_u8(data[IFLA_BR_MCAST_IGMP_VERSION]);
+ 		err = br_multicast_set_igmp_version(br, igmp_version);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ #if IS_ENABLED(CONFIG_IPV6)
+ 	if (data[IFLA_BR_MCAST_MLD_VERSION]) {
+ 		__u8 mld_version;
+ 
+ 		mld_version = nla_get_u8(data[IFLA_BR_MCAST_MLD_VERSION]);
+ 		err = br_multicast_set_mld_version(br, mld_version);
+ 		if (err)
+ 			return err;
+ 	}
+ #endif
+ #endif
+ #if IS_ENABLED(CONFIG_BRIDGE_NETFILTER)
+ 	if (data[IFLA_BR_NF_CALL_IPTABLES]) {
+ 		u8 val = nla_get_u8(data[IFLA_BR_NF_CALL_IPTABLES]);
+ 
+ 		br->nf_call_iptables = val ? true : false;
+ 	}
+ 
+ 	if (data[IFLA_BR_NF_CALL_IP6TABLES]) {
+ 		u8 val = nla_get_u8(data[IFLA_BR_NF_CALL_IP6TABLES]);
+ 
+ 		br->nf_call_ip6tables = val ? true : false;
+ 	}
+ 
+ 	if (data[IFLA_BR_NF_CALL_ARPTABLES]) {
+ 		u8 val = nla_get_u8(data[IFLA_BR_NF_CALL_ARPTABLES]);
+ 
+ 		br->nf_call_arptables = val ? true : false;
+ 	}
+ #endif
+ 
+ 	return 0;
+ }
+ 
+ static int br_dev_newlink(struct net *src_net, struct net_device *dev,
+ 			  struct nlattr *tb[], struct nlattr *data[])
+ {
+ 	struct net_bridge *br = netdev_priv(dev);
+ 	int err;
+ 
+ 	if (tb[IFLA_ADDRESS]) {
+ 		spin_lock_bh(&br->lock);
+ 		br_stp_change_bridge_id(br, nla_data(tb[IFLA_ADDRESS]));
+ 		spin_unlock_bh(&br->lock);
+ 	}
+ 
+ 	err = register_netdevice(dev);
+ 	if (err)
+ 		return err;
+ 
+ 	err = br_changelink(dev, tb, data);
+ 	if (err)
+ 		unregister_netdevice(dev);
+ 	return err;
+ }
+ 
++>>>>>>> 5b8d5429daa0 (bridge: netlink: register netdevice before executing changelink)
  static size_t br_get_size(const struct net_device *brdev)
  {
  	return nla_total_size(sizeof(u32)) +	/* IFLA_BR_FORWARD_DELAY  */
* Unmerged path net/bridge/br_netlink.c
