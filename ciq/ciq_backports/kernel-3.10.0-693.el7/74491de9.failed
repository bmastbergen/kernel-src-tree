net/mlx5: Add multi dest support

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [kernel] mlx5: Add multi dest support (Don Dutile) [1385330 1417286]
Rebuild_FUZZ: 93.33%
commit-author Mark Bloch <markb@mellanox.com>
commit 74491de937125d0c98c9b9c9208b4105717a3caa
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/74491de9.failed

Currently when calling mlx5_add_flow_rule we accept
only one flow destination, this commit allows to pass
multiple destinations.

This change forces us to change the return structure to a more
flexible one. We introduce a flow handle (struct mlx5_flow_handle),
it holds internally the number for rules created and holds an array
where each cell points the to a flow rule.

From the consumers (of mlx5_add_flow_rule) point of view this
change is only cosmetic and requires only to change the type
of the returned value they store.

From the core point of view, we now need to use a loop when
allocating and deleting rules (e.g given to us a flow handler).

	Signed-off-by: Mark Bloch <markb@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
	Signed-off-by: Leon Romanovsky <leon@kernel.org>
(cherry picked from commit 74491de937125d0c98c9b9c9208b4105717a3caa)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/main.c
#	drivers/net/ethernet/mellanox/mlx5/core/en.h
#	drivers/net/ethernet/mellanox/mlx5/core/en_arfs.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
#	drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
#	include/linux/mlx5/fs.h
diff --cc drivers/infiniband/hw/mlx5/main.c
index c59be3674778,8e0dbd51944e..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -1889,15 -1904,13 +1889,19 @@@ static struct mlx5_ib_flow_handler *cre
  		ib_flow += ((union ib_flow_spec *)ib_flow)->size;
  	}
  
 -	spec->match_criteria_enable = get_match_criteria_enable(spec->match_criteria);
 +	/* Outer header support only */
 +	match_criteria_enable = (!outer_header_zero(match_c)) << 0;
  	action = dst ? MLX5_FLOW_CONTEXT_ACTION_FWD_DEST :
  		MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO;
++<<<<<<< HEAD
 +	handler->rule = mlx5_add_flow_rule(ft, match_criteria_enable,
 +					   match_c, match_v,
++=======
+ 	handler->rule = mlx5_add_flow_rules(ft, spec,
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  					   action,
  					   MLX5_FS_DEFAULT_FLOW_TAG,
- 					   dst);
+ 					   dst, 1);
  
  	if (IS_ERR(handler->rule)) {
  		err = PTR_ERR(handler->rule);
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en.h
index f49539a1ae6e,47ee8ffe987f..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en.h
@@@ -449,34 -513,146 +449,79 @@@ enum 
  	MLX5E_STATE_DESTROYING,
  };
  
++<<<<<<< HEAD
 +struct mlx5e_vlan_db {
++=======
+ struct mlx5e_vxlan_db {
+ 	spinlock_t			lock; /* protect vxlan table */
+ 	struct radix_tree_root		tree;
+ };
+ 
+ struct mlx5e_l2_rule {
+ 	u8  addr[ETH_ALEN + 2];
+ 	struct mlx5_flow_handle *rule;
+ };
+ 
+ struct mlx5e_flow_table {
+ 	int num_groups;
+ 	struct mlx5_flow_table *t;
+ 	struct mlx5_flow_group **g;
+ };
+ 
+ #define MLX5E_L2_ADDR_HASH_SIZE BIT(BITS_PER_BYTE)
+ 
+ struct mlx5e_tc_table {
+ 	struct mlx5_flow_table		*t;
+ 
+ 	struct rhashtable_params        ht_params;
+ 	struct rhashtable               ht;
+ };
+ 
+ struct mlx5e_vlan_table {
+ 	struct mlx5e_flow_table		ft;
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  	unsigned long active_vlans[BITS_TO_LONGS(VLAN_N_VID)];
- 	struct mlx5_flow_rule	*active_vlans_rule[VLAN_N_VID];
- 	struct mlx5_flow_rule	*untagged_rule;
- 	struct mlx5_flow_rule	*any_vlan_rule;
- 	bool          filter_disabled;
+ 	struct mlx5_flow_handle	*active_vlans_rule[VLAN_N_VID];
+ 	struct mlx5_flow_handle	*untagged_rule;
+ 	struct mlx5_flow_handle	*any_vlan_rule;
+ 	bool		filter_disabled;
  };
  
 -struct mlx5e_l2_table {
 -	struct mlx5e_flow_table    ft;
 -	struct hlist_head          netdev_uc[MLX5E_L2_ADDR_HASH_SIZE];
 -	struct hlist_head          netdev_mc[MLX5E_L2_ADDR_HASH_SIZE];
 -	struct mlx5e_l2_rule	   broadcast;
 -	struct mlx5e_l2_rule	   allmulti;
 -	struct mlx5e_l2_rule	   promisc;
 -	bool                       broadcast_enabled;
 -	bool                       allmulti_enabled;
 -	bool                       promisc_enabled;
 +struct mlx5e_vxlan_db {
 +	spinlock_t			lock; /* protect vxlan table */
 +	struct radix_tree_root		tree;
  };
  
++<<<<<<< HEAD
 +struct mlx5e_flow_table {
 +	int num_groups;
 +	struct mlx5_flow_table		*t;
 +	struct mlx5_flow_group		**g;
 +};
 +
 +struct mlx5e_flow_tables {
 +	struct mlx5_flow_namespace	*ns;
 +	struct mlx5e_flow_table		vlan;
 +	struct mlx5e_flow_table		main;
++=======
+ /* L3/L4 traffic type classifier */
+ struct mlx5e_ttc_table {
+ 	struct mlx5e_flow_table  ft;
+ 	struct mlx5_flow_handle	 *rules[MLX5E_NUM_TT];
+ };
+ 
+ #define ARFS_HASH_SHIFT BITS_PER_BYTE
+ #define ARFS_HASH_SIZE BIT(BITS_PER_BYTE)
+ struct arfs_table {
+ 	struct mlx5e_flow_table  ft;
+ 	struct mlx5_flow_handle	 *default_rule;
+ 	struct hlist_head	 rules_hash[ARFS_HASH_SIZE];
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  };
  
 -enum  arfs_type {
 -	ARFS_IPV4_TCP,
 -	ARFS_IPV6_TCP,
 -	ARFS_IPV4_UDP,
 -	ARFS_IPV6_UDP,
 -	ARFS_NUM_TYPES,
 -};
 -
 -struct mlx5e_arfs_tables {
 -	struct arfs_table arfs_tables[ARFS_NUM_TYPES];
 -	/* Protect aRFS rules list */
 -	spinlock_t                     arfs_lock;
 -	struct list_head               rules;
 -	int                            last_filter_id;
 -	struct workqueue_struct        *wq;
 -};
 -
 -/* NIC prio FTS */
 -enum {
 -	MLX5E_VLAN_FT_LEVEL = 0,
 -	MLX5E_L2_FT_LEVEL,
 -	MLX5E_TTC_FT_LEVEL,
 -	MLX5E_ARFS_FT_LEVEL
 -};
 -
 -struct mlx5e_ethtool_table {
 -	struct mlx5_flow_table *ft;
 -	int                    num_rules;
 -};
 -
 -#define ETHTOOL_NUM_L3_L4_FTS 7
 -#define ETHTOOL_NUM_L2_FTS 4
 -
 -struct mlx5e_ethtool_steering {
 -	struct mlx5e_ethtool_table      l3_l4_ft[ETHTOOL_NUM_L3_L4_FTS];
 -	struct mlx5e_ethtool_table      l2_ft[ETHTOOL_NUM_L2_FTS];
 -	struct list_head                rules;
 -	int                             tot_num_rules;
 -};
 -
 -struct mlx5e_flow_steering {
 -	struct mlx5_flow_namespace      *ns;
 -	struct mlx5e_ethtool_steering   ethtool;
 -	struct mlx5e_tc_table           tc;
 -	struct mlx5e_vlan_table         vlan;
 -	struct mlx5e_l2_table           l2;
 -	struct mlx5e_ttc_table          ttc;
 -	struct mlx5e_arfs_tables        arfs;
 -};
 -
 -struct mlx5e_rqt {
 +struct mlx5e_direct_tir {
 +	u32              tirn;
  	u32              rqtn;
 -	bool		 enabled;
 -};
 -
 -struct mlx5e_tir {
 -	u32		  tirn;
 -	struct mlx5e_rqt  rqt;
 -	struct list_head  list;
 -};
 -
 -enum {
 -	MLX5E_TC_PRIO = 0,
 -	MLX5E_NIC_PRIO
 -};
 -
 -struct mlx5e_profile {
 -	void	(*init)(struct mlx5_core_dev *mdev,
 -			struct net_device *netdev,
 -			const struct mlx5e_profile *profile, void *ppriv);
 -	void	(*cleanup)(struct mlx5e_priv *priv);
 -	int	(*init_rx)(struct mlx5e_priv *priv);
 -	void	(*cleanup_rx)(struct mlx5e_priv *priv);
 -	int	(*init_tx)(struct mlx5e_priv *priv);
 -	void	(*cleanup_tx)(struct mlx5e_priv *priv);
 -	void	(*enable)(struct mlx5e_priv *priv);
 -	void	(*disable)(struct mlx5e_priv *priv);
 -	void	(*update_stats)(struct mlx5e_priv *priv);
 -	int	(*max_nch)(struct mlx5_core_dev *mdev);
 -	int	max_tc;
  };
  
  struct mlx5e_priv {
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
index 4df49e660587,bed544d47ba1..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
@@@ -512,12 -156,11 +512,16 @@@ enum mlx5e_vlan_rule_type 
  
  static int __mlx5e_add_vlan_rule(struct mlx5e_priv *priv,
  				 enum mlx5e_vlan_rule_type rule_type,
 -				 u16 vid, struct mlx5_flow_spec *spec)
 +				 u16 vid, u32 *mc, u32 *mv)
  {
 -	struct mlx5_flow_table *ft = priv->fs.vlan.ft.t;
 +	struct mlx5_flow_table *ft = priv->fts.vlan.t;
  	struct mlx5_flow_destination dest;
++<<<<<<< HEAD
 +	u8 match_criteria_enable = 0;
 +	struct mlx5_flow_rule **rule_p;
++=======
+ 	struct mlx5_flow_handle **rule_p;
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  	int err = 0;
  
  	dest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
@@@ -542,10 -187,10 +546,17 @@@
  		break;
  	}
  
++<<<<<<< HEAD
 +	*rule_p = mlx5_add_flow_rule(ft, match_criteria_enable, mc, mv,
 +				     MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
 +				     MLX5_FS_DEFAULT_FLOW_TAG,
 +				     &dest);
++=======
+ 	*rule_p = mlx5_add_flow_rules(ft, spec,
+ 				      MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 				      MLX5_FS_DEFAULT_FLOW_TAG,
+ 				      &dest, 1);
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  
  	if (IS_ERR(*rule_p)) {
  		err = PTR_ERR(*rule_p);
@@@ -589,22 -228,22 +600,40 @@@ static void mlx5e_del_vlan_rule(struct 
  {
  	switch (rule_type) {
  	case MLX5E_VLAN_RULE_TYPE_UNTAGGED:
++<<<<<<< HEAD
 +		if (priv->vlan.untagged_rule) {
 +			mlx5_del_flow_rule(priv->vlan.untagged_rule);
 +			priv->vlan.untagged_rule = NULL;
 +		}
 +		break;
 +	case MLX5E_VLAN_RULE_TYPE_ANY_VID:
 +		if (priv->vlan.any_vlan_rule) {
 +			mlx5_del_flow_rule(priv->vlan.any_vlan_rule);
 +			priv->vlan.any_vlan_rule = NULL;
++=======
+ 		if (priv->fs.vlan.untagged_rule) {
+ 			mlx5_del_flow_rules(priv->fs.vlan.untagged_rule);
+ 			priv->fs.vlan.untagged_rule = NULL;
+ 		}
+ 		break;
+ 	case MLX5E_VLAN_RULE_TYPE_ANY_VID:
+ 		if (priv->fs.vlan.any_vlan_rule) {
+ 			mlx5_del_flow_rules(priv->fs.vlan.any_vlan_rule);
+ 			priv->fs.vlan.any_vlan_rule = NULL;
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  		}
  		break;
  	case MLX5E_VLAN_RULE_TYPE_MATCH_VID:
  		mlx5e_vport_context_update_vlans(priv);
++<<<<<<< HEAD
 +		if (priv->vlan.active_vlans_rule[vid]) {
 +			mlx5_del_flow_rule(priv->vlan.active_vlans_rule[vid]);
 +			priv->vlan.active_vlans_rule[vid] = NULL;
++=======
+ 		if (priv->fs.vlan.active_vlans_rule[vid]) {
+ 			mlx5_del_flow_rules(priv->fs.vlan.active_vlans_rule[vid]);
+ 			priv->fs.vlan.active_vlans_rule[vid] = NULL;
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  		}
  		mlx5e_vport_context_update_vlans(priv);
  		break;
@@@ -1077,9 -554,419 +1106,423 @@@ static void mlx5e_destroy_flow_table(st
  	ft->t = NULL;
  }
  
 -static void mlx5e_cleanup_ttc_rules(struct mlx5e_ttc_table *ttc)
 +static void mlx5e_destroy_main_flow_table(struct mlx5e_priv *priv)
  {
++<<<<<<< HEAD
 +	mlx5e_destroy_flow_table(&priv->fts.main);
++=======
+ 	int i;
+ 
+ 	for (i = 0; i < MLX5E_NUM_TT; i++) {
+ 		if (!IS_ERR_OR_NULL(ttc->rules[i])) {
+ 			mlx5_del_flow_rules(ttc->rules[i]);
+ 			ttc->rules[i] = NULL;
+ 		}
+ 	}
+ }
+ 
+ static struct {
+ 	u16 etype;
+ 	u8 proto;
+ } ttc_rules[] = {
+ 	[MLX5E_TT_IPV4_TCP] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = IPPROTO_TCP,
+ 	},
+ 	[MLX5E_TT_IPV6_TCP] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = IPPROTO_TCP,
+ 	},
+ 	[MLX5E_TT_IPV4_UDP] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = IPPROTO_UDP,
+ 	},
+ 	[MLX5E_TT_IPV6_UDP] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = IPPROTO_UDP,
+ 	},
+ 	[MLX5E_TT_IPV4_IPSEC_AH] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = IPPROTO_AH,
+ 	},
+ 	[MLX5E_TT_IPV6_IPSEC_AH] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = IPPROTO_AH,
+ 	},
+ 	[MLX5E_TT_IPV4_IPSEC_ESP] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = IPPROTO_ESP,
+ 	},
+ 	[MLX5E_TT_IPV6_IPSEC_ESP] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = IPPROTO_ESP,
+ 	},
+ 	[MLX5E_TT_IPV4] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = 0,
+ 	},
+ 	[MLX5E_TT_IPV6] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = 0,
+ 	},
+ 	[MLX5E_TT_ANY] = {
+ 		.etype = 0,
+ 		.proto = 0,
+ 	},
+ };
+ 
+ static struct mlx5_flow_handle *
+ mlx5e_generate_ttc_rule(struct mlx5e_priv *priv,
+ 			struct mlx5_flow_table *ft,
+ 			struct mlx5_flow_destination *dest,
+ 			u16 etype,
+ 			u8 proto)
+ {
+ 	struct mlx5_flow_handle *rule;
+ 	struct mlx5_flow_spec *spec;
+ 	int err = 0;
+ 
+ 	spec = mlx5_vzalloc(sizeof(*spec));
+ 	if (!spec) {
+ 		netdev_err(priv->netdev, "%s: alloc failed\n", __func__);
+ 		return ERR_PTR(-ENOMEM);
+ 	}
+ 
+ 	if (proto) {
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.ip_protocol);
+ 		MLX5_SET(fte_match_param, spec->match_value, outer_headers.ip_protocol, proto);
+ 	}
+ 	if (etype) {
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.ethertype);
+ 		MLX5_SET(fte_match_param, spec->match_value, outer_headers.ethertype, etype);
+ 	}
+ 
+ 	rule = mlx5_add_flow_rules(ft, spec,
+ 				   MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 				   MLX5_FS_DEFAULT_FLOW_TAG,
+ 				   dest, 1);
+ 	if (IS_ERR(rule)) {
+ 		err = PTR_ERR(rule);
+ 		netdev_err(priv->netdev, "%s: add rule failed\n", __func__);
+ 	}
+ 
+ 	kvfree(spec);
+ 	return err ? ERR_PTR(err) : rule;
+ }
+ 
+ static int mlx5e_generate_ttc_table_rules(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5_flow_destination dest;
+ 	struct mlx5e_ttc_table *ttc;
+ 	struct mlx5_flow_handle **rules;
+ 	struct mlx5_flow_table *ft;
+ 	int tt;
+ 	int err;
+ 
+ 	ttc = &priv->fs.ttc;
+ 	ft = ttc->ft.t;
+ 	rules = ttc->rules;
+ 
+ 	dest.type = MLX5_FLOW_DESTINATION_TYPE_TIR;
+ 	for (tt = 0; tt < MLX5E_NUM_TT; tt++) {
+ 		if (tt == MLX5E_TT_ANY)
+ 			dest.tir_num = priv->direct_tir[0].tirn;
+ 		else
+ 			dest.tir_num = priv->indir_tir[tt].tirn;
+ 		rules[tt] = mlx5e_generate_ttc_rule(priv, ft, &dest,
+ 						    ttc_rules[tt].etype,
+ 						    ttc_rules[tt].proto);
+ 		if (IS_ERR(rules[tt]))
+ 			goto del_rules;
+ 	}
+ 
+ 	return 0;
+ 
+ del_rules:
+ 	err = PTR_ERR(rules[tt]);
+ 	rules[tt] = NULL;
+ 	mlx5e_cleanup_ttc_rules(ttc);
+ 	return err;
+ }
+ 
+ #define MLX5E_TTC_NUM_GROUPS	3
+ #define MLX5E_TTC_GROUP1_SIZE	BIT(3)
+ #define MLX5E_TTC_GROUP2_SIZE	BIT(1)
+ #define MLX5E_TTC_GROUP3_SIZE	BIT(0)
+ #define MLX5E_TTC_TABLE_SIZE	(MLX5E_TTC_GROUP1_SIZE +\
+ 				 MLX5E_TTC_GROUP2_SIZE +\
+ 				 MLX5E_TTC_GROUP3_SIZE)
+ static int mlx5e_create_ttc_table_groups(struct mlx5e_ttc_table *ttc)
+ {
+ 	int inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);
+ 	struct mlx5e_flow_table *ft = &ttc->ft;
+ 	int ix = 0;
+ 	u32 *in;
+ 	int err;
+ 	u8 *mc;
+ 
+ 	ft->g = kcalloc(MLX5E_TTC_NUM_GROUPS,
+ 			sizeof(*ft->g), GFP_KERNEL);
+ 	if (!ft->g)
+ 		return -ENOMEM;
+ 	in = mlx5_vzalloc(inlen);
+ 	if (!in) {
+ 		kfree(ft->g);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	/* L4 Group */
+ 	mc = MLX5_ADDR_OF(create_flow_group_in, in, match_criteria);
+ 	MLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.ip_protocol);
+ 	MLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.ethertype);
+ 	MLX5_SET_CFG(in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_TTC_GROUP1_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err;
+ 	ft->num_groups++;
+ 
+ 	/* L3 Group */
+ 	MLX5_SET(fte_match_param, mc, outer_headers.ip_protocol, 0);
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_TTC_GROUP2_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err;
+ 	ft->num_groups++;
+ 
+ 	/* Any Group */
+ 	memset(in, 0, inlen);
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_TTC_GROUP3_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err;
+ 	ft->num_groups++;
+ 
+ 	kvfree(in);
+ 	return 0;
+ 
+ err:
+ 	err = PTR_ERR(ft->g[ft->num_groups]);
+ 	ft->g[ft->num_groups] = NULL;
+ 	kvfree(in);
+ 
+ 	return err;
+ }
+ 
+ static void mlx5e_destroy_ttc_table(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_ttc_table *ttc = &priv->fs.ttc;
+ 
+ 	mlx5e_cleanup_ttc_rules(ttc);
+ 	mlx5e_destroy_flow_table(&ttc->ft);
+ }
+ 
+ static int mlx5e_create_ttc_table(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_ttc_table *ttc = &priv->fs.ttc;
+ 	struct mlx5e_flow_table *ft = &ttc->ft;
+ 	int err;
+ 
+ 	ft->t = mlx5_create_flow_table(priv->fs.ns, MLX5E_NIC_PRIO,
+ 				       MLX5E_TTC_TABLE_SIZE, MLX5E_TTC_FT_LEVEL);
+ 	if (IS_ERR(ft->t)) {
+ 		err = PTR_ERR(ft->t);
+ 		ft->t = NULL;
+ 		return err;
+ 	}
+ 
+ 	err = mlx5e_create_ttc_table_groups(ttc);
+ 	if (err)
+ 		goto err;
+ 
+ 	err = mlx5e_generate_ttc_table_rules(priv);
+ 	if (err)
+ 		goto err;
+ 
+ 	return 0;
+ err:
+ 	mlx5e_destroy_flow_table(ft);
+ 	return err;
+ }
+ 
+ static void mlx5e_del_l2_flow_rule(struct mlx5e_priv *priv,
+ 				   struct mlx5e_l2_rule *ai)
+ {
+ 	if (!IS_ERR_OR_NULL(ai->rule)) {
+ 		mlx5_del_flow_rules(ai->rule);
+ 		ai->rule = NULL;
+ 	}
+ }
+ 
+ static int mlx5e_add_l2_flow_rule(struct mlx5e_priv *priv,
+ 				  struct mlx5e_l2_rule *ai, int type)
+ {
+ 	struct mlx5_flow_table *ft = priv->fs.l2.ft.t;
+ 	struct mlx5_flow_destination dest;
+ 	struct mlx5_flow_spec *spec;
+ 	int err = 0;
+ 	u8 *mc_dmac;
+ 	u8 *mv_dmac;
+ 
+ 	spec = mlx5_vzalloc(sizeof(*spec));
+ 	if (!spec) {
+ 		netdev_err(priv->netdev, "%s: alloc failed\n", __func__);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	mc_dmac = MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
+ 			       outer_headers.dmac_47_16);
+ 	mv_dmac = MLX5_ADDR_OF(fte_match_param, spec->match_value,
+ 			       outer_headers.dmac_47_16);
+ 
+ 	dest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
+ 	dest.ft = priv->fs.ttc.ft.t;
+ 
+ 	switch (type) {
+ 	case MLX5E_FULLMATCH:
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 		eth_broadcast_addr(mc_dmac);
+ 		ether_addr_copy(mv_dmac, ai->addr);
+ 		break;
+ 
+ 	case MLX5E_ALLMULTI:
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 		mc_dmac[0] = 0x01;
+ 		mv_dmac[0] = 0x01;
+ 		break;
+ 
+ 	case MLX5E_PROMISC:
+ 		break;
+ 	}
+ 
+ 	ai->rule = mlx5_add_flow_rules(ft, spec,
+ 				       MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 				       MLX5_FS_DEFAULT_FLOW_TAG, &dest, 1);
+ 	if (IS_ERR(ai->rule)) {
+ 		netdev_err(priv->netdev, "%s: add l2 rule(mac:%pM) failed\n",
+ 			   __func__, mv_dmac);
+ 		err = PTR_ERR(ai->rule);
+ 		ai->rule = NULL;
+ 	}
+ 
+ 	kvfree(spec);
+ 
+ 	return err;
+ }
+ 
+ #define MLX5E_NUM_L2_GROUPS	   3
+ #define MLX5E_L2_GROUP1_SIZE	   BIT(0)
+ #define MLX5E_L2_GROUP2_SIZE	   BIT(15)
+ #define MLX5E_L2_GROUP3_SIZE	   BIT(0)
+ #define MLX5E_L2_TABLE_SIZE	   (MLX5E_L2_GROUP1_SIZE +\
+ 				    MLX5E_L2_GROUP2_SIZE +\
+ 				    MLX5E_L2_GROUP3_SIZE)
+ static int mlx5e_create_l2_table_groups(struct mlx5e_l2_table *l2_table)
+ {
+ 	int inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);
+ 	struct mlx5e_flow_table *ft = &l2_table->ft;
+ 	int ix = 0;
+ 	u8 *mc_dmac;
+ 	u32 *in;
+ 	int err;
+ 	u8 *mc;
+ 
+ 	ft->g = kcalloc(MLX5E_NUM_L2_GROUPS, sizeof(*ft->g), GFP_KERNEL);
+ 	if (!ft->g)
+ 		return -ENOMEM;
+ 	in = mlx5_vzalloc(inlen);
+ 	if (!in) {
+ 		kfree(ft->g);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	mc = MLX5_ADDR_OF(create_flow_group_in, in, match_criteria);
+ 	mc_dmac = MLX5_ADDR_OF(fte_match_param, mc,
+ 			       outer_headers.dmac_47_16);
+ 	/* Flow Group for promiscuous */
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_L2_GROUP1_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err_destroy_groups;
+ 	ft->num_groups++;
+ 
+ 	/* Flow Group for full match */
+ 	eth_broadcast_addr(mc_dmac);
+ 	MLX5_SET_CFG(in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_L2_GROUP2_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err_destroy_groups;
+ 	ft->num_groups++;
+ 
+ 	/* Flow Group for allmulti */
+ 	eth_zero_addr(mc_dmac);
+ 	mc_dmac[0] = 0x01;
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_L2_GROUP3_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err_destroy_groups;
+ 	ft->num_groups++;
+ 
+ 	kvfree(in);
+ 	return 0;
+ 
+ err_destroy_groups:
+ 	err = PTR_ERR(ft->g[ft->num_groups]);
+ 	ft->g[ft->num_groups] = NULL;
+ 	mlx5e_destroy_groups(ft);
+ 	kvfree(in);
+ 
+ 	return err;
+ }
+ 
+ static void mlx5e_destroy_l2_table(struct mlx5e_priv *priv)
+ {
+ 	mlx5e_destroy_flow_table(&priv->fs.l2.ft);
+ }
+ 
+ static int mlx5e_create_l2_table(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_l2_table *l2_table = &priv->fs.l2;
+ 	struct mlx5e_flow_table *ft = &l2_table->ft;
+ 	int err;
+ 
+ 	ft->num_groups = 0;
+ 	ft->t = mlx5_create_flow_table(priv->fs.ns, MLX5E_NIC_PRIO,
+ 				       MLX5E_L2_TABLE_SIZE, MLX5E_L2_FT_LEVEL);
+ 
+ 	if (IS_ERR(ft->t)) {
+ 		err = PTR_ERR(ft->t);
+ 		ft->t = NULL;
+ 		return err;
+ 	}
+ 
+ 	err = mlx5e_create_l2_table_groups(l2_table);
+ 	if (err)
+ 		goto err_destroy_flow_table;
+ 
+ 	return 0;
+ 
+ err_destroy_flow_table:
+ 	mlx5_destroy_flow_table(ft->t);
+ 	ft->t = NULL;
+ 
+ 	return err;
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  }
  
  #define MLX5E_NUM_VLAN_GROUPS	2
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
index 6c7352099dd6,fcd8b15f6625..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@@ -76,7 -65,9 +76,13 @@@ struct vport_addr 
  	struct l2addr_node     node;
  	u8                     action;
  	u32                    vport;
++<<<<<<< HEAD
 +	struct mlx5_flow_rule *flow_rule; /* SRIOV only */
++=======
+ 	struct mlx5_flow_handle *flow_rule; /* SRIOV only */
+ 	/* A flag indicating that mac was added due to mc promiscuous vport */
+ 	bool mc_promisc;
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  };
  
  enum {
@@@ -322,32 -237,34 +328,37 @@@ static void del_l2_table_entry(struct m
  }
  
  /* E-Switch FDB */
++<<<<<<< HEAD
 +static struct mlx5_flow_rule *
 +__esw_fdb_set_vport_rule(struct mlx5_eswitch *esw, u32 vport,
++=======
+ static struct mlx5_flow_handle *
+ __esw_fdb_set_vport_rule(struct mlx5_eswitch *esw, u32 vport, bool rx_rule,
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  			 u8 mac_c[ETH_ALEN], u8 mac_v[ETH_ALEN])
  {
  	int match_header = (is_zero_ether_addr(mac_c) ? 0 :
  			    MLX5_MATCH_OUTER_HEADERS);
- 	struct mlx5_flow_rule *flow_rule = NULL;
+ 	struct mlx5_flow_handle *flow_rule = NULL;
  	struct mlx5_flow_destination dest;
 -	struct mlx5_flow_spec *spec;
 -	void *mv_misc = NULL;
 -	void *mc_misc = NULL;
  	u8 *dmac_v = NULL;
  	u8 *dmac_c = NULL;
 +	u32 *match_v;
 +	u32 *match_c;
  
 -	if (rx_rule)
 -		match_header |= MLX5_MATCH_MISC_PARAMETERS;
 -
 -	spec = mlx5_vzalloc(sizeof(*spec));
 -	if (!spec) {
 -		esw_warn(esw->dev, "FDB: Failed to alloc match parameters\n");
 -		return NULL;
 +	match_v = kzalloc(MLX5_ST_SZ_BYTES(fte_match_param), GFP_KERNEL);
 +	match_c = kzalloc(MLX5_ST_SZ_BYTES(fte_match_param), GFP_KERNEL);
 +	if (!match_v || !match_c) {
 +		pr_warn("FDB: Failed to alloc match parameters\n");
 +		goto out;
  	}
 -	dmac_v = MLX5_ADDR_OF(fte_match_param, spec->match_value,
 +
 +	dmac_v = MLX5_ADDR_OF(fte_match_param, match_v,
  			      outer_headers.dmac_47_16);
 -	dmac_c = MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 +	dmac_c = MLX5_ADDR_OF(fte_match_param, match_c,
  			      outer_headers.dmac_47_16);
  
 -	if (match_header & MLX5_MATCH_OUTER_HEADERS) {
 +	if (match_header == MLX5_MATCH_OUTER_HEADERS) {
  		ether_addr_copy(dmac_v, mac_v);
  		ether_addr_copy(dmac_c, mac_c);
  	}
@@@ -358,16 -284,14 +369,25 @@@
  	esw_debug(esw->dev,
  		  "\tFDB add rule dmac_v(%pM) dmac_c(%pM) -> vport(%d)\n",
  		  dmac_v, dmac_c, vport);
 -	spec->match_criteria_enable = match_header;
  	flow_rule =
++<<<<<<< HEAD
 +		mlx5_add_flow_rule(esw->fdb_table.fdb,
 +				   match_header,
 +				   match_c,
 +				   match_v,
 +				   MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
 +				   0, &dest);
 +	if (IS_ERR_OR_NULL(flow_rule)) {
 +		pr_warn(
 +			"FDB: Failed to add flow rule: dmac_v(%pM) dmac_c(%pM) -> vport(%d), err(%ld)\n",
++=======
+ 		mlx5_add_flow_rules(esw->fdb_table.fdb, spec,
+ 				    MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 				    0, &dest, 1);
+ 	if (IS_ERR(flow_rule)) {
+ 		esw_warn(esw->dev,
+ 			 "FDB: Failed to add flow rule: dmac_v(%pM) dmac_c(%pM) -> vport(%d), err(%ld)\n",
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  			 dmac_v, dmac_c, vport, PTR_ERR(flow_rule));
  		flow_rule = NULL;
  	}
@@@ -383,10 -306,34 +403,38 @@@ esw_fdb_set_vport_rule(struct mlx5_eswi
  	u8 mac_c[ETH_ALEN];
  
  	eth_broadcast_addr(mac_c);
 -	return __esw_fdb_set_vport_rule(esw, vport, false, mac_c, mac);
 +	return __esw_fdb_set_vport_rule(esw, vport, mac_c, mac);
  }
  
++<<<<<<< HEAD
 +static int esw_create_fdb_table(struct mlx5_eswitch *esw, int nvports)
++=======
+ static struct mlx5_flow_handle *
+ esw_fdb_set_vport_allmulti_rule(struct mlx5_eswitch *esw, u32 vport)
+ {
+ 	u8 mac_c[ETH_ALEN];
+ 	u8 mac_v[ETH_ALEN];
+ 
+ 	eth_zero_addr(mac_c);
+ 	eth_zero_addr(mac_v);
+ 	mac_c[0] = 0x01;
+ 	mac_v[0] = 0x01;
+ 	return __esw_fdb_set_vport_rule(esw, vport, false, mac_c, mac_v);
+ }
+ 
+ static struct mlx5_flow_handle *
+ esw_fdb_set_vport_promisc_rule(struct mlx5_eswitch *esw, u32 vport)
+ {
+ 	u8 mac_c[ETH_ALEN];
+ 	u8 mac_v[ETH_ALEN];
+ 
+ 	eth_zero_addr(mac_c);
+ 	eth_zero_addr(mac_v);
+ 	return __esw_fdb_set_vport_rule(esw, vport, true, mac_c, mac_v);
+ }
+ 
+ static int esw_create_legacy_fdb_table(struct mlx5_eswitch *esw, int nvports)
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  {
  	int inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);
  	struct mlx5_core_dev *dev = esw->dev;
@@@ -574,6 -522,53 +622,56 @@@ static int esw_del_uc_addr(struct mlx5_
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static void update_allmulti_vports(struct mlx5_eswitch *esw,
+ 				   struct vport_addr *vaddr,
+ 				   struct esw_mc_addr *esw_mc)
+ {
+ 	u8 *mac = vaddr->node.addr;
+ 	u32 vport_idx = 0;
+ 
+ 	for (vport_idx = 0; vport_idx < esw->total_vports; vport_idx++) {
+ 		struct mlx5_vport *vport = &esw->vports[vport_idx];
+ 		struct hlist_head *vport_hash = vport->mc_list;
+ 		struct vport_addr *iter_vaddr =
+ 					l2addr_hash_find(vport_hash,
+ 							 mac,
+ 							 struct vport_addr);
+ 		if (IS_ERR_OR_NULL(vport->allmulti_rule) ||
+ 		    vaddr->vport == vport_idx)
+ 			continue;
+ 		switch (vaddr->action) {
+ 		case MLX5_ACTION_ADD:
+ 			if (iter_vaddr)
+ 				continue;
+ 			iter_vaddr = l2addr_hash_add(vport_hash, mac,
+ 						     struct vport_addr,
+ 						     GFP_KERNEL);
+ 			if (!iter_vaddr) {
+ 				esw_warn(esw->dev,
+ 					 "ALL-MULTI: Failed to add MAC(%pM) to vport[%d] DB\n",
+ 					 mac, vport_idx);
+ 				continue;
+ 			}
+ 			iter_vaddr->vport = vport_idx;
+ 			iter_vaddr->flow_rule =
+ 					esw_fdb_set_vport_rule(esw,
+ 							       mac,
+ 							       vport_idx);
+ 			iter_vaddr->mc_promisc = true;
+ 			break;
+ 		case MLX5_ACTION_DEL:
+ 			if (!iter_vaddr)
+ 				continue;
+ 			mlx5_del_flow_rules(iter_vaddr->flow_rule);
+ 			l2addr_hash_del(iter_vaddr);
+ 			break;
+ 		}
+ 	}
+ }
+ 
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  static int esw_add_mc_addr(struct mlx5_eswitch *esw, struct vport_addr *vaddr)
  {
  	struct hlist_head *hash = esw->mc_table;
@@@ -628,14 -632,20 +726,14 @@@ static int esw_del_mc_addr(struct mlx5_
  		  esw_mc->uplink_rule);
  
  	if (vaddr->flow_rule)
- 		mlx5_del_flow_rule(vaddr->flow_rule);
+ 		mlx5_del_flow_rules(vaddr->flow_rule);
  	vaddr->flow_rule = NULL;
  
 -	/* If the multicast mac is added as a result of mc promiscuous vport,
 -	 * don't decrement the multicast ref count.
 -	 */
 -	if (vaddr->mc_promisc || (--esw_mc->refcnt > 0))
 +	if (--esw_mc->refcnt)
  		return 0;
  
 -	/* Remove this multicast mac from all the mc promiscuous vports */
 -	update_allmulti_vports(esw, vaddr, esw_mc);
 -
  	if (esw_mc->uplink_rule)
- 		mlx5_del_flow_rule(esw_mc->uplink_rule);
+ 		mlx5_del_flow_rules(esw_mc->uplink_rule);
  
  	l2addr_hash_del(esw_mc);
  	return 0;
@@@ -744,10 -772,117 +842,123 @@@ out
  	kfree(mac_list);
  }
  
++<<<<<<< HEAD
 +static void esw_vport_change_handler(struct work_struct *work)
++=======
+ /* Sync vport UC/MC list from vport context
+  * Must be called after esw_update_vport_addr_list
+  */
+ static void esw_update_vport_mc_promisc(struct mlx5_eswitch *esw, u32 vport_num)
+ {
+ 	struct mlx5_vport *vport = &esw->vports[vport_num];
+ 	struct l2addr_node *node;
+ 	struct vport_addr *addr;
+ 	struct hlist_head *hash;
+ 	struct hlist_node *tmp;
+ 	int hi;
+ 
+ 	hash = vport->mc_list;
+ 
+ 	for_each_l2hash_node(node, tmp, esw->mc_table, hi) {
+ 		u8 *mac = node->addr;
+ 
+ 		addr = l2addr_hash_find(hash, mac, struct vport_addr);
+ 		if (addr) {
+ 			if (addr->action == MLX5_ACTION_DEL)
+ 				addr->action = MLX5_ACTION_NONE;
+ 			continue;
+ 		}
+ 		addr = l2addr_hash_add(hash, mac, struct vport_addr,
+ 				       GFP_KERNEL);
+ 		if (!addr) {
+ 			esw_warn(esw->dev,
+ 				 "Failed to add allmulti MAC(%pM) to vport[%d] DB\n",
+ 				 mac, vport_num);
+ 			continue;
+ 		}
+ 		addr->vport = vport_num;
+ 		addr->action = MLX5_ACTION_ADD;
+ 		addr->mc_promisc = true;
+ 	}
+ }
+ 
+ /* Apply vport rx mode to HW FDB table */
+ static void esw_apply_vport_rx_mode(struct mlx5_eswitch *esw, u32 vport_num,
+ 				    bool promisc, bool mc_promisc)
+ {
+ 	struct esw_mc_addr *allmulti_addr = esw->mc_promisc;
+ 	struct mlx5_vport *vport = &esw->vports[vport_num];
+ 
+ 	if (IS_ERR_OR_NULL(vport->allmulti_rule) != mc_promisc)
+ 		goto promisc;
+ 
+ 	if (mc_promisc) {
+ 		vport->allmulti_rule =
+ 				esw_fdb_set_vport_allmulti_rule(esw, vport_num);
+ 		if (!allmulti_addr->uplink_rule)
+ 			allmulti_addr->uplink_rule =
+ 				esw_fdb_set_vport_allmulti_rule(esw,
+ 								UPLINK_VPORT);
+ 		allmulti_addr->refcnt++;
+ 	} else if (vport->allmulti_rule) {
+ 		mlx5_del_flow_rules(vport->allmulti_rule);
+ 		vport->allmulti_rule = NULL;
+ 
+ 		if (--allmulti_addr->refcnt > 0)
+ 			goto promisc;
+ 
+ 		if (allmulti_addr->uplink_rule)
+ 			mlx5_del_flow_rules(allmulti_addr->uplink_rule);
+ 		allmulti_addr->uplink_rule = NULL;
+ 	}
+ 
+ promisc:
+ 	if (IS_ERR_OR_NULL(vport->promisc_rule) != promisc)
+ 		return;
+ 
+ 	if (promisc) {
+ 		vport->promisc_rule = esw_fdb_set_vport_promisc_rule(esw,
+ 								     vport_num);
+ 	} else if (vport->promisc_rule) {
+ 		mlx5_del_flow_rules(vport->promisc_rule);
+ 		vport->promisc_rule = NULL;
+ 	}
+ }
+ 
+ /* Sync vport rx mode from vport context */
+ static void esw_update_vport_rx_mode(struct mlx5_eswitch *esw, u32 vport_num)
+ {
+ 	struct mlx5_vport *vport = &esw->vports[vport_num];
+ 	int promisc_all = 0;
+ 	int promisc_uc = 0;
+ 	int promisc_mc = 0;
+ 	int err;
+ 
+ 	err = mlx5_query_nic_vport_promisc(esw->dev,
+ 					   vport_num,
+ 					   &promisc_uc,
+ 					   &promisc_mc,
+ 					   &promisc_all);
+ 	if (err)
+ 		return;
+ 	esw_debug(esw->dev, "vport[%d] context update rx mode promisc_all=%d, all_multi=%d\n",
+ 		  vport_num, promisc_all, promisc_mc);
+ 
+ 	if (!vport->info.trusted || !vport->enabled) {
+ 		promisc_uc = 0;
+ 		promisc_mc = 0;
+ 		promisc_all = 0;
+ 	}
+ 
+ 	esw_apply_vport_rx_mode(esw, vport_num, promisc_all,
+ 				(promisc_all || promisc_mc));
+ }
+ 
+ static void esw_vport_change_handle_locked(struct mlx5_vport *vport)
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  {
 +	struct mlx5_vport *vport =
 +		container_of(work, struct mlx5_vport, vport_change_handler);
  	struct mlx5_core_dev *dev = vport->dev;
  	struct mlx5_eswitch *esw = dev->priv.eswitch;
  	u8 mac[ETH_ALEN];
@@@ -1016,8 -1173,13 +1227,16 @@@ static void esw_vport_cleanup_ingress_r
  					    struct mlx5_vport *vport)
  {
  	if (!IS_ERR_OR_NULL(vport->ingress.drop_rule))
++<<<<<<< HEAD
 +		mlx5_del_flow_rule(vport->ingress.drop_rule);
++=======
+ 		mlx5_del_flow_rules(vport->ingress.drop_rule);
+ 
+ 	if (!IS_ERR_OR_NULL(vport->ingress.allow_rule))
+ 		mlx5_del_flow_rules(vport->ingress.allow_rule);
+ 
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  	vport->ingress.drop_rule = NULL;
 -	vport->ingress.allow_rule = NULL;
  }
  
  static void esw_vport_disable_ingress_acl(struct mlx5_eswitch *esw,
@@@ -1072,25 -1238,51 +1291,60 @@@ static int esw_vport_ingress_config(str
  			 vport->vport, err);
  		goto out;
  	}
 +	MLX5_SET_TO_ONES(fte_match_param, match_c, outer_headers.vlan_tag);
 +	MLX5_SET_TO_ONES(fte_match_param, match_v, outer_headers.vlan_tag);
  
++<<<<<<< HEAD
 +	vport->ingress.drop_rule =
 +		mlx5_add_flow_rule(vport->ingress.acl,
 +				   MLX5_MATCH_OUTER_HEADERS,
 +				   match_c,
 +				   match_v,
 +				   MLX5_FLOW_CONTEXT_ACTION_DROP,
 +				   0, NULL);
 +	if (IS_ERR_OR_NULL(vport->ingress.drop_rule)) {
++=======
+ 	if (vport->info.vlan || vport->info.qos)
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.vlan_tag);
+ 
+ 	if (vport->info.spoofchk) {
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.smac_47_16);
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.smac_15_0);
+ 		smac_v = MLX5_ADDR_OF(fte_match_param,
+ 				      spec->match_value,
+ 				      outer_headers.smac_47_16);
+ 		ether_addr_copy(smac_v, vport->info.mac);
+ 	}
+ 
+ 	spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 	vport->ingress.allow_rule =
+ 		mlx5_add_flow_rules(vport->ingress.acl, spec,
+ 				    MLX5_FLOW_CONTEXT_ACTION_ALLOW,
+ 				    0, NULL, 0);
+ 	if (IS_ERR(vport->ingress.allow_rule)) {
+ 		err = PTR_ERR(vport->ingress.allow_rule);
+ 		esw_warn(esw->dev,
+ 			 "vport[%d] configure ingress allow rule, err(%d)\n",
+ 			 vport->vport, err);
+ 		vport->ingress.allow_rule = NULL;
+ 		goto out;
+ 	}
+ 
+ 	memset(spec, 0, sizeof(*spec));
+ 	vport->ingress.drop_rule =
+ 		mlx5_add_flow_rules(vport->ingress.acl, spec,
+ 				    MLX5_FLOW_CONTEXT_ACTION_DROP,
+ 				    0, NULL, 0);
+ 	if (IS_ERR(vport->ingress.drop_rule)) {
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  		err = PTR_ERR(vport->ingress.drop_rule);
 -		esw_warn(esw->dev,
 -			 "vport[%d] configure ingress drop rule, err(%d)\n",
 -			 vport->vport, err);
 +		pr_warn("vport[%d] configure ingress rules, err(%d)\n",
 +			vport->vport, err);
  		vport->ingress.drop_rule = NULL;
 -		goto out;
  	}
 -
  out:
 -	if (err)
 -		esw_vport_cleanup_ingress_rules(esw, vport);
 -	kvfree(spec);
 +	kfree(match_v);
 +	kfree(match_c);
  	return err;
  }
  
@@@ -1126,40 -1314,36 +1380,54 @@@ static int esw_vport_egress_config(stru
  	}
  
  	/* Allowed vlan rule */
 -	MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.vlan_tag);
 -	MLX5_SET_TO_ONES(fte_match_param, spec->match_value, outer_headers.vlan_tag);
 -	MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.first_vid);
 -	MLX5_SET(fte_match_param, spec->match_value, outer_headers.first_vid, vport->info.vlan);
 +	MLX5_SET_TO_ONES(fte_match_param, match_c, outer_headers.vlan_tag);
 +	MLX5_SET_TO_ONES(fte_match_param, match_v, outer_headers.vlan_tag);
 +	MLX5_SET_TO_ONES(fte_match_param, match_c, outer_headers.first_vid);
 +	MLX5_SET(fte_match_param, match_v, outer_headers.first_vid, vport->vlan);
  
 -	spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
  	vport->egress.allowed_vlan =
++<<<<<<< HEAD
 +		mlx5_add_flow_rule(vport->egress.acl,
 +				   MLX5_MATCH_OUTER_HEADERS,
 +				   match_c,
 +				   match_v,
 +				   MLX5_FLOW_CONTEXT_ACTION_ALLOW,
 +				   0, NULL);
 +	if (IS_ERR_OR_NULL(vport->egress.allowed_vlan)) {
++=======
+ 		mlx5_add_flow_rules(vport->egress.acl, spec,
+ 				    MLX5_FLOW_CONTEXT_ACTION_ALLOW,
+ 				    0, NULL, 0);
+ 	if (IS_ERR(vport->egress.allowed_vlan)) {
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  		err = PTR_ERR(vport->egress.allowed_vlan);
 -		esw_warn(esw->dev,
 -			 "vport[%d] configure egress allowed vlan rule failed, err(%d)\n",
 -			 vport->vport, err);
 +		pr_warn("vport[%d] configure egress allowed vlan rule failed, err(%d)\n",
 +			vport->vport, err);
  		vport->egress.allowed_vlan = NULL;
  		goto out;
  	}
  
  	/* Drop others rule (star rule) */
 -	memset(spec, 0, sizeof(*spec));
 +	memset(match_c, 0, MLX5_ST_SZ_BYTES(fte_match_param));
 +	memset(match_v, 0, MLX5_ST_SZ_BYTES(fte_match_param));
  	vport->egress.drop_rule =
++<<<<<<< HEAD
 +		mlx5_add_flow_rule(vport->egress.acl,
 +				   0,
 +				   match_c,
 +				   match_v,
 +				   MLX5_FLOW_CONTEXT_ACTION_DROP,
 +				   0, NULL);
 +	if (IS_ERR_OR_NULL(vport->egress.drop_rule)) {
++=======
+ 		mlx5_add_flow_rules(vport->egress.acl, spec,
+ 				    MLX5_FLOW_CONTEXT_ACTION_DROP,
+ 				    0, NULL, 0);
+ 	if (IS_ERR(vport->egress.drop_rule)) {
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  		err = PTR_ERR(vport->egress.drop_rule);
 -		esw_warn(esw->dev,
 -			 "vport[%d] configure egress drop rule failed, err(%d)\n",
 -			 vport->vport, err);
 +		pr_warn("vport[%d] configure egress drop rule failed, err(%d)\n",
 +			vport->vport, err);
  		vport->egress.drop_rule = NULL;
  	}
  out:
@@@ -1296,8 -1666,17 +1564,13 @@@ void mlx5_eswitch_disable_sriov(struct 
  	for (i = 0; i < esw->total_vports; i++)
  		esw_disable_vport(esw, i);
  
++<<<<<<< HEAD
 +	esw_destroy_fdb_table(esw);
++=======
+ 	if (mc_promisc && mc_promisc->uplink_rule)
+ 		mlx5_del_flow_rules(mc_promisc->uplink_rule);
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  
 -	esw_destroy_tsar(esw);
 -
 -	if (esw->mode == SRIOV_LEGACY)
 -		esw_destroy_legacy_fdb_table(esw);
 -	else if (esw->mode == SRIOV_OFFLOADS)
 -		esw_offloads_cleanup(esw, nvports);
 -
 -	esw->mode = SRIOV_NONE;
  	/* VPORT 0 (PF) must be enabled back with non-sriov configuration */
  	esw_enable_vport(esw, 0, UC_ADDR_CHANGE);
  }
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index 7b5e70f8cc22,6d414cb1b75f..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@@ -102,15 -105,28 +102,20 @@@ struct vport_egress 
  	struct mlx5_flow_table *acl;
  	struct mlx5_flow_group *allowed_vlans_grp;
  	struct mlx5_flow_group *drop_grp;
- 	struct mlx5_flow_rule  *allowed_vlan;
- 	struct mlx5_flow_rule  *drop_rule;
+ 	struct mlx5_flow_handle  *allowed_vlan;
+ 	struct mlx5_flow_handle  *drop_rule;
  };
  
 -struct mlx5_vport_info {
 -	u8                      mac[ETH_ALEN];
 -	u16                     vlan;
 -	u8                      qos;
 -	u64                     node_guid;
 -	int                     link_state;
 -	u32                     max_rate;
 -	bool                    spoofchk;
 -	bool                    trusted;
 -};
 -
  struct mlx5_vport {
  	struct mlx5_core_dev    *dev;
  	int                     vport;
  	struct hlist_head       uc_list[MLX5_L2_ADDR_HASH_SIZE];
  	struct hlist_head       mc_list[MLX5_L2_ADDR_HASH_SIZE];
++<<<<<<< HEAD
++=======
+ 	struct mlx5_flow_handle *promisc_rule;
+ 	struct mlx5_flow_handle *allmulti_rule;
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  	struct work_struct      vport_change_handler;
  
  	struct vport_ingress    ingress;
@@@ -130,9 -151,54 +135,60 @@@ struct mlx5_l2_table 
  
  struct mlx5_eswitch_fdb {
  	void *fdb;
++<<<<<<< HEAD
 +	struct mlx5_flow_group *addr_grp;
 +	struct mlx5_flow_group *allmulti_grp;
 +	struct mlx5_flow_group *promisc_grp;
++=======
+ 	union {
+ 		struct legacy_fdb {
+ 			struct mlx5_flow_group *addr_grp;
+ 			struct mlx5_flow_group *allmulti_grp;
+ 			struct mlx5_flow_group *promisc_grp;
+ 		} legacy;
+ 
+ 		struct offloads_fdb {
+ 			struct mlx5_flow_table *fdb;
+ 			struct mlx5_flow_group *send_to_vport_grp;
+ 			struct mlx5_flow_group *miss_grp;
+ 			struct mlx5_flow_handle *miss_rule;
+ 			int vlan_push_pop_refcount;
+ 		} offloads;
+ 	};
+ };
+ 
+ enum {
+ 	SRIOV_NONE,
+ 	SRIOV_LEGACY,
+ 	SRIOV_OFFLOADS
+ };
+ 
+ struct mlx5_esw_sq {
+ 	struct mlx5_flow_handle	*send_to_vport_rule;
+ 	struct list_head	 list;
+ };
+ 
+ struct mlx5_eswitch_rep {
+ 	int		       (*load)(struct mlx5_eswitch *esw,
+ 				       struct mlx5_eswitch_rep *rep);
+ 	void		       (*unload)(struct mlx5_eswitch *esw,
+ 					 struct mlx5_eswitch_rep *rep);
+ 	u16		       vport;
+ 	u8		       hw_id[ETH_ALEN];
+ 	void		      *priv_data;
+ 
+ 	struct mlx5_flow_handle *vport_rx_rule;
+ 	struct list_head       vport_sqs_list;
+ 	u16		       vlan;
+ 	u32		       vlan_refcount;
+ 	bool		       valid;
+ };
+ 
+ struct mlx5_esw_offload {
+ 	struct mlx5_flow_table *ft_offloads;
+ 	struct mlx5_flow_group *vport_rx_group;
+ 	struct mlx5_eswitch_rep *vport_reps;
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  };
  
  struct mlx5_eswitch {
@@@ -170,4 -254,62 +226,65 @@@ int mlx5_eswitch_get_vport_stats(struc
  				 int vport,
  				 struct ifla_vf_stats *vf_stats);
  
++<<<<<<< HEAD
++=======
+ struct mlx5_flow_spec;
+ struct mlx5_esw_flow_attr;
+ 
+ struct mlx5_flow_handle *
+ mlx5_eswitch_add_offloaded_rule(struct mlx5_eswitch *esw,
+ 				struct mlx5_flow_spec *spec,
+ 				struct mlx5_esw_flow_attr *attr);
+ struct mlx5_flow_handle *
+ mlx5_eswitch_create_vport_rx_rule(struct mlx5_eswitch *esw, int vport, u32 tirn);
+ 
+ enum {
+ 	SET_VLAN_STRIP	= BIT(0),
+ 	SET_VLAN_INSERT	= BIT(1)
+ };
+ 
+ #define MLX5_FLOW_CONTEXT_ACTION_VLAN_POP  0x40
+ #define MLX5_FLOW_CONTEXT_ACTION_VLAN_PUSH 0x80
+ 
+ struct mlx5_esw_flow_attr {
+ 	struct mlx5_eswitch_rep *in_rep;
+ 	struct mlx5_eswitch_rep *out_rep;
+ 
+ 	int	action;
+ 	u16	vlan;
+ 	bool	vlan_handled;
+ };
+ 
+ int mlx5_eswitch_sqs2vport_start(struct mlx5_eswitch *esw,
+ 				 struct mlx5_eswitch_rep *rep,
+ 				 u16 *sqns_array, int sqns_num);
+ void mlx5_eswitch_sqs2vport_stop(struct mlx5_eswitch *esw,
+ 				 struct mlx5_eswitch_rep *rep);
+ 
+ int mlx5_devlink_eswitch_mode_set(struct devlink *devlink, u16 mode);
+ int mlx5_devlink_eswitch_mode_get(struct devlink *devlink, u16 *mode);
+ void mlx5_eswitch_register_vport_rep(struct mlx5_eswitch *esw,
+ 				     int vport_index,
+ 				     struct mlx5_eswitch_rep *rep);
+ void mlx5_eswitch_unregister_vport_rep(struct mlx5_eswitch *esw,
+ 				       int vport_index);
+ 
+ int mlx5_eswitch_add_vlan_action(struct mlx5_eswitch *esw,
+ 				 struct mlx5_esw_flow_attr *attr);
+ int mlx5_eswitch_del_vlan_action(struct mlx5_eswitch *esw,
+ 				 struct mlx5_esw_flow_attr *attr);
+ int __mlx5_eswitch_set_vport_vlan(struct mlx5_eswitch *esw,
+ 				  int vport, u16 vlan, u8 qos, u8 set_flags);
+ 
+ #define MLX5_DEBUG_ESWITCH_MASK BIT(3)
+ 
+ #define esw_info(dev, format, ...)				\
+ 	pr_info("(%s): E-Switch: " format, (dev)->priv.name, ##__VA_ARGS__)
+ 
+ #define esw_warn(dev, format, ...)				\
+ 	pr_warn("(%s): E-Switch: " format, (dev)->priv.name, ##__VA_ARGS__)
+ 
+ #define esw_debug(dev, format, ...)				\
+ 	mlx5_core_dbg_mask(dev, MLX5_DEBUG_ESWITCH_MASK, format, ##__VA_ARGS__)
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  #endif /* __MLX5_ESWITCH_H__ */
diff --cc drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
index de1cde8dc012,6732287a98c8..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
@@@ -861,42 -942,125 +886,143 @@@ static struct mlx5_flow_rule *alloc_rul
  	return rule;
  }
  
+ static struct mlx5_flow_handle *alloc_handle(int num_rules)
+ {
+ 	struct mlx5_flow_handle *handle;
+ 
+ 	handle = kzalloc(sizeof(*handle) + sizeof(handle->rule[0]) *
+ 			  num_rules, GFP_KERNEL);
+ 	if (!handle)
+ 		return NULL;
+ 
+ 	handle->num_rules = num_rules;
+ 
+ 	return handle;
+ }
+ 
+ static void destroy_flow_handle(struct fs_fte *fte,
+ 				struct mlx5_flow_handle *handle,
+ 				struct mlx5_flow_destination *dest,
+ 				int i)
+ {
+ 	for (; --i >= 0;) {
+ 		if (atomic_dec_and_test(&handle->rule[i]->node.refcount)) {
+ 			fte->dests_size--;
+ 			list_del(&handle->rule[i]->node.list);
+ 			kfree(handle->rule[i]);
+ 		}
+ 	}
+ 	kfree(handle);
+ }
+ 
+ static struct mlx5_flow_handle *
+ create_flow_handle(struct fs_fte *fte,
+ 		   struct mlx5_flow_destination *dest,
+ 		   int dest_num,
+ 		   int *modify_mask,
+ 		   bool *new_rule)
+ {
+ 	struct mlx5_flow_handle *handle;
+ 	struct mlx5_flow_rule *rule = NULL;
+ 	static int count = BIT(MLX5_SET_FTE_MODIFY_ENABLE_MASK_FLOW_COUNTERS);
+ 	static int dst = BIT(MLX5_SET_FTE_MODIFY_ENABLE_MASK_DESTINATION_LIST);
+ 	int type;
+ 	int i = 0;
+ 
+ 	handle = alloc_handle((dest_num) ? dest_num : 1);
+ 	if (!handle)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	do {
+ 		if (dest) {
+ 			rule = find_flow_rule(fte, dest + i);
+ 			if (rule) {
+ 				atomic_inc(&rule->node.refcount);
+ 				goto rule_found;
+ 			}
+ 		}
+ 
+ 		*new_rule = true;
+ 		rule = alloc_rule(dest + i);
+ 		if (!rule)
+ 			goto free_rules;
+ 
+ 		/* Add dest to dests list- we need flow tables to be in the
+ 		 * end of the list for forward to next prio rules.
+ 		 */
+ 		tree_init_node(&rule->node, 1, del_rule);
+ 		if (dest &&
+ 		    dest[i].type != MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE)
+ 			list_add(&rule->node.list, &fte->node.children);
+ 		else
+ 			list_add_tail(&rule->node.list, &fte->node.children);
+ 		if (dest) {
+ 			fte->dests_size++;
+ 
+ 			type = dest[i].type ==
+ 				MLX5_FLOW_DESTINATION_TYPE_COUNTER;
+ 			*modify_mask |= type ? count : dst;
+ 		}
+ rule_found:
+ 		handle->rule[i] = rule;
+ 	} while (++i < dest_num);
+ 
+ 	return handle;
+ 
+ free_rules:
+ 	destroy_flow_handle(fte, handle, dest, i);
+ 	return ERR_PTR(-ENOMEM);
+ }
+ 
  /* fte should not be deleted while calling this function */
- static struct mlx5_flow_rule *add_rule_fte(struct fs_fte *fte,
- 					   struct mlx5_flow_group *fg,
- 					   struct mlx5_flow_destination *dest,
- 					   bool update_action)
+ static struct mlx5_flow_handle *
+ add_rule_fte(struct fs_fte *fte,
+ 	     struct mlx5_flow_group *fg,
+ 	     struct mlx5_flow_destination *dest,
+ 	     int dest_num,
+ 	     bool update_action)
  {
+ 	struct mlx5_flow_handle *handle;
  	struct mlx5_flow_table *ft;
++<<<<<<< HEAD
 +	struct mlx5_flow_rule *rule;
++=======
+ 	int modify_mask = 0;
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  	int err;
+ 	bool new_rule = false;
  
- 	rule = alloc_rule(dest);
- 	if (!rule)
- 		return ERR_PTR(-ENOMEM);
+ 	handle = create_flow_handle(fte, dest, dest_num, &modify_mask,
+ 				    &new_rule);
+ 	if (IS_ERR(handle) || !new_rule)
+ 		goto out;
  
  	if (update_action)
  		modify_mask |= BIT(MLX5_SET_FTE_MODIFY_ENABLE_MASK_ACTION);
  
  	fs_get_obj(ft, fg->node.parent);
++<<<<<<< HEAD
 +	/* Add dest to dests list- we need flow tables to be in the
 +	 * end of the list for forward to next prio rules.
 +	 */
 +	tree_init_node(&rule->node, 1, del_rule);
 +	if (dest && dest->type != MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE)
 +		list_add(&rule->node.list, &fte->node.children);
 +	else
 +		list_add_tail(&rule->node.list, &fte->node.children);
 +	if (dest)
 +		fte->dests_size++;
 +	if (fte->dests_size == 1 || !dest)
++=======
+ 	if (!(fte->status & FS_FTE_STATUS_EXISTING))
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  		err = mlx5_cmd_create_fte(get_dev(&ft->node),
  					  ft, fg->id, fte);
  	else
  		err = mlx5_cmd_update_fte(get_dev(&ft->node),
 -					  ft, fg->id, modify_mask, fte);
 +					  ft, fg->id, fte);
  	if (err)
- 		goto free_rule;
+ 		goto free_handle;
  
  	fte->status |= FS_FTE_STATUS_EXISTING;
  
@@@ -1101,32 -1261,78 +1223,100 @@@ unlock_fte
  	unlock_ref_node(&fte->node);
  unlock_fg:
  	unlock_ref_node(&fg->node);
- 	return rule;
+ 	return handle;
  }
  
++<<<<<<< HEAD
 +static struct mlx5_flow_rule *
 +_mlx5_add_flow_rule(struct mlx5_flow_table *ft,
 +		    u8 match_criteria_enable,
 +		    u32 *match_criteria,
 +		    u32 *match_value,
 +		    u32 action,
 +		    u32 flow_tag,
 +		    struct mlx5_flow_destination *dest)
++=======
+ struct mlx5_fc *mlx5_flow_rule_counter(struct mlx5_flow_handle *handle)
+ {
+ 	struct mlx5_flow_rule *dst;
+ 	struct fs_fte *fte;
+ 
+ 	fs_get_obj(fte, handle->rule[0]->node.parent);
+ 
+ 	fs_for_each_dst(dst, fte) {
+ 		if (dst->dest_attr.type == MLX5_FLOW_DESTINATION_TYPE_COUNTER)
+ 			return dst->dest_attr.counter;
+ 	}
+ 
+ 	return NULL;
+ }
+ 
+ static bool counter_is_valid(struct mlx5_fc *counter, u32 action)
+ {
+ 	if (!(action & MLX5_FLOW_CONTEXT_ACTION_COUNT))
+ 		return !counter;
+ 
+ 	if (!counter)
+ 		return false;
+ 
+ 	/* Hardware support counter for a drop action only */
+ 	return action == (MLX5_FLOW_CONTEXT_ACTION_DROP | MLX5_FLOW_CONTEXT_ACTION_COUNT);
+ }
+ 
+ static bool dest_is_valid(struct mlx5_flow_destination *dest,
+ 			  u32 action,
+ 			  struct mlx5_flow_table *ft)
+ {
+ 	if (dest && (dest->type == MLX5_FLOW_DESTINATION_TYPE_COUNTER))
+ 		return counter_is_valid(dest->counter, action);
+ 
+ 	if (!(action & MLX5_FLOW_CONTEXT_ACTION_FWD_DEST))
+ 		return true;
+ 
+ 	if (!dest || ((dest->type ==
+ 	    MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE) &&
+ 	    (dest->ft->level <= ft->level)))
+ 		return false;
+ 	return true;
+ }
+ 
+ static struct mlx5_flow_handle *
+ _mlx5_add_flow_rules(struct mlx5_flow_table *ft,
+ 		     struct mlx5_flow_spec *spec,
+ 		     u32 action,
+ 		     u32 flow_tag,
+ 		     struct mlx5_flow_destination *dest,
+ 		     int dest_num)
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  {
  	struct mlx5_flow_group *g;
- 	struct mlx5_flow_rule *rule;
+ 	struct mlx5_flow_handle *rule;
+ 	int i;
  
++<<<<<<< HEAD
 +	if ((action & MLX5_FLOW_CONTEXT_ACTION_FWD_DEST) && !dest)
 +		return ERR_PTR(-EINVAL);
++=======
+ 	for (i = 0; i < dest_num; i++) {
+ 		if (!dest_is_valid(&dest[i], action, ft))
+ 			return ERR_PTR(-EINVAL);
+ 	}
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  
  	nested_lock_ref_node(&ft->node, FS_MUTEX_GRANDPARENT);
  	fs_for_each_fg(g, ft)
  		if (compare_match_criteria(g->mask.match_criteria_enable,
 -					   spec->match_criteria_enable,
 +					   match_criteria_enable,
  					   g->mask.match_criteria,
++<<<<<<< HEAD
 +					   match_criteria)) {
 +			rule = add_rule_fg(g, match_value,
 +					   action, flow_tag, dest);
++=======
+ 					   spec->match_criteria)) {
+ 			rule = add_rule_fg(g, spec->match_value,
+ 					   action, flow_tag, dest, dest_num);
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  			if (!IS_ERR(rule) || PTR_ERR(rule) != -ENOSPC)
  				goto unlock;
  		}
@@@ -1137,8 -1344,8 +1327,13 @@@
  		goto unlock;
  	}
  
++<<<<<<< HEAD
 +	rule = add_rule_fg(g, match_value,
 +			   action, flow_tag, dest);
++=======
+ 	rule = add_rule_fg(g, spec->match_value,
+ 			   action, flow_tag, dest, dest_num);
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  	if (IS_ERR(rule)) {
  		/* Remove assumes refcount > 0 and autogroup creates a group
  		 * with a refcount = 0.
@@@ -1159,14 -1366,13 +1354,24 @@@ static bool fwd_next_prio_supported(str
  		(MLX5_CAP_FLOWTABLE(get_dev(&ft->node), nic_rx_multi_path_tirs)));
  }
  
++<<<<<<< HEAD
 +struct mlx5_flow_rule *
 +mlx5_add_flow_rule(struct mlx5_flow_table *ft,
 +		   u8 match_criteria_enable,
 +		   u32 *match_criteria,
 +		   u32 *match_value,
 +		   u32 action,
 +		   u32 flow_tag,
 +		   struct mlx5_flow_destination *dest)
++=======
+ struct mlx5_flow_handle *
+ mlx5_add_flow_rules(struct mlx5_flow_table *ft,
+ 		    struct mlx5_flow_spec *spec,
+ 		    u32 action,
+ 		    u32 flow_tag,
+ 		    struct mlx5_flow_destination *dest,
+ 		    int dest_num)
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  {
  	struct mlx5_flow_root_namespace *root = find_root(&ft->node);
  	struct mlx5_flow_destination gen_dest;
@@@ -1194,16 -1401,17 +1400,22 @@@
  		}
  	}
  
++<<<<<<< HEAD
 +	rule =	_mlx5_add_flow_rule(ft, match_criteria_enable, match_criteria,
 +				    match_value, action, flow_tag, dest);
++=======
+ 	handle = _mlx5_add_flow_rules(ft, spec, action, flow_tag, dest,
+ 				      dest_num);
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  
  	if (sw_action == MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO) {
- 		if (!IS_ERR_OR_NULL(rule) &&
- 		    (list_empty(&rule->next_ft))) {
+ 		if (!IS_ERR_OR_NULL(handle) &&
+ 		    (list_empty(&handle->rule[0]->next_ft))) {
  			mutex_lock(&next_ft->lock);
- 			list_add(&rule->next_ft, &next_ft->fwd_rules);
+ 			list_add(&handle->rule[0]->next_ft,
+ 				 &next_ft->fwd_rules);
  			mutex_unlock(&next_ft->lock);
- 			rule->sw_action = MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO;
+ 			handle->rule[0]->sw_action = MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO;
  		}
  		mutex_unlock(&root->chain_lock);
  	}
diff --cc include/linux/mlx5/fs.h
index 3f3444d24756,0dcd287f4bd0..000000000000
--- a/include/linux/mlx5/fs.h
+++ b/include/linux/mlx5/fs.h
@@@ -63,9 -69,15 +63,9 @@@ enum mlx5_flow_namespace_type 
  
  struct mlx5_flow_table;
  struct mlx5_flow_group;
- struct mlx5_flow_rule;
  struct mlx5_flow_namespace;
+ struct mlx5_flow_handle;
  
 -struct mlx5_flow_spec {
 -	u8   match_criteria_enable;
 -	u32  match_criteria[MLX5_ST_SZ_DW(fte_match_param)];
 -	u32  match_value[MLX5_ST_SZ_DW(fte_match_param)];
 -};
 -
  struct mlx5_flow_destination {
  	enum mlx5_flow_destination_type	type;
  	union {
@@@ -104,17 -127,23 +104,38 @@@ void mlx5_destroy_flow_group(struct mlx
  /* Single destination per rule.
   * Group ID is implied by the match criteria.
   */
++<<<<<<< HEAD
 +struct mlx5_flow_rule *
 +mlx5_add_flow_rule(struct mlx5_flow_table *ft,
 +		   u8 match_criteria_enable,
 +		   u32 *match_criteria,
 +		   u32 *match_value,
 +		   u32 action,
 +		   u32 flow_tag,
 +		   struct mlx5_flow_destination *dest);
 +void mlx5_del_flow_rule(struct mlx5_flow_rule *fr);
++=======
+ struct mlx5_flow_handle *
+ mlx5_add_flow_rules(struct mlx5_flow_table *ft,
+ 		    struct mlx5_flow_spec *spec,
+ 		    u32 action,
+ 		    u32 flow_tag,
+ 		    struct mlx5_flow_destination *dest,
+ 		    int dest_num);
+ void mlx5_del_flow_rules(struct mlx5_flow_handle *fr);
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  
- int mlx5_modify_rule_destination(struct mlx5_flow_rule *rule,
- 				 struct mlx5_flow_destination *dest);
+ int mlx5_modify_rule_destination(struct mlx5_flow_handle *handler,
+ 				 struct mlx5_flow_destination *new_dest,
+ 				 struct mlx5_flow_destination *old_dest);
  
++<<<<<<< HEAD
++=======
+ struct mlx5_fc *mlx5_flow_rule_counter(struct mlx5_flow_handle *handler);
+ struct mlx5_fc *mlx5_fc_create(struct mlx5_core_dev *dev, bool aging);
+ void mlx5_fc_destroy(struct mlx5_core_dev *dev, struct mlx5_fc *counter);
+ void mlx5_fc_query_cached(struct mlx5_fc *counter,
+ 			  u64 *bytes, u64 *packets, u64 *lastuse);
+ 
++>>>>>>> 74491de93712 (net/mlx5: Add multi dest support)
  #endif
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_arfs.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
* Unmerged path drivers/infiniband/hw/mlx5/main.c
diff --git a/drivers/infiniband/hw/mlx5/mlx5_ib.h b/drivers/infiniband/hw/mlx5/mlx5_ib.h
index ca9e5580572f..c47867157e66 100644
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -154,7 +154,7 @@ struct mlx5_ib_flow_handler {
 	struct list_head		list;
 	struct ib_flow			ibflow;
 	struct mlx5_ib_flow_prio	*prio;
-	struct mlx5_flow_rule	*rule;
+	struct mlx5_flow_handle		*rule;
 };
 
 struct mlx5_ib_flow_db {
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_arfs.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.h b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.h
index d607e564f454..17ad7896f144 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.h
@@ -75,6 +75,11 @@ struct mlx5_flow_rule {
 	u32					sw_action;
 };
 
+struct mlx5_flow_handle {
+	int num_rules;
+	struct mlx5_flow_rule *rule[];
+};
+
 /* Type of children is mlx5_flow_group */
 struct mlx5_flow_table {
 	struct fs_node			node;
* Unmerged path include/linux/mlx5/fs.h
