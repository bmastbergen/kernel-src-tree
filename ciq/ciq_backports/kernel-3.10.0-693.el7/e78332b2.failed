amd-xgbe: Add ECC status support for the device memory

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Lendacky, Thomas <Thomas.Lendacky@amd.com>
commit e78332b2285d9fe631a093fc8ca2b604c48c33e6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/e78332b2.failed

Some versions of the amd-xgbe device are capable of reporting ECC error
information back to the driver. Add support to process, track and report
on this information.

	Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit e78332b2285d9fe631a093fc8ca2b604c48c33e6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/amd/Kconfig
#	drivers/net/ethernet/amd/xgbe/xgbe-common.h
#	drivers/net/ethernet/amd/xgbe/xgbe-dev.c
#	drivers/net/ethernet/amd/xgbe/xgbe-drv.c
#	drivers/net/ethernet/amd/xgbe/xgbe-main.c
#	drivers/net/ethernet/amd/xgbe/xgbe-pci.c
#	drivers/net/ethernet/amd/xgbe/xgbe.h
diff --cc drivers/net/ethernet/amd/Kconfig
index 13d74aa4033d,930636c65e54..000000000000
--- a/drivers/net/ethernet/amd/Kconfig
+++ b/drivers/net/ethernet/amd/Kconfig
@@@ -179,4 -171,33 +179,36 @@@ config SUNLANC
  	  To compile this driver as a module, choose M here: the module
  	  will be called sunlance.
  
++<<<<<<< HEAD
++=======
+ config AMD_XGBE
+ 	tristate "AMD 10GbE Ethernet driver"
+ 	depends on ((OF_NET && OF_ADDRESS) || ACPI || PCI) && HAS_IOMEM && HAS_DMA
+ 	depends on X86 || ARM64 || COMPILE_TEST
+ 	select BITREVERSE
+ 	select CRC32
+ 	select PTP_1588_CLOCK
+ 	select AMD_XGBE_HAVE_ECC if X86
+ 	---help---
+ 	  This driver supports the AMD 10GbE Ethernet device found on an
+ 	  AMD SoC.
+ 
+ 	  To compile this driver as a module, choose M here: the module
+ 	  will be called amd-xgbe.
+ 
+ config AMD_XGBE_DCB
+ 	bool "Data Center Bridging (DCB) support"
+ 	default n
+ 	depends on AMD_XGBE && DCB
+ 	---help---
+ 	  Say Y here to enable Data Center Bridging (DCB) support in the
+ 	  driver.
+ 
+ 	  If unsure, say N.
+ 
+ config AMD_XGBE_HAVE_ECC
+ 	bool
+ 	default n
+ 
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  endif # NET_VENDOR_AMD
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-common.h
index 3373e9ef2003,f7527cddb0f3..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-common.h
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-common.h
@@@ -743,16 -858,147 +743,149 @@@
  #define MTL_TSA_SP			0x00
  #define MTL_TSA_ETS			0x02
  
 -/* PCS register offsets */
 -#define PCS_V1_WINDOW_SELECT		0x03fc
 -#define PCS_V2_WINDOW_DEF		0x9060
 -#define PCS_V2_WINDOW_SELECT		0x9064
  
 -/* PCS register entry bit positions and sizes */
 -#define PCS_V2_WINDOW_DEF_OFFSET_INDEX	6
 -#define PCS_V2_WINDOW_DEF_OFFSET_WIDTH	14
 -#define PCS_V2_WINDOW_DEF_SIZE_INDEX	2
 -#define PCS_V2_WINDOW_DEF_SIZE_WIDTH	4
 +/* PCS MMD select register offset
 + *  The MMD select register is used for accessing PCS registers
 + *  when the underlying APB3 interface is using indirect addressing.
 + *  Indirect addressing requires accessing registers in two phases,
 + *  an address phase and a data phase.  The address phases requires
 + *  writing an address selection value to the MMD select regiesters.
 + */
 +#define PCS_MMD_SELECT			0xff
  
++<<<<<<< HEAD
++=======
+ /* SerDes integration register offsets */
+ #define SIR0_KR_RT_1			0x002c
+ #define SIR0_STATUS			0x0040
+ #define SIR1_SPEED			0x0000
+ 
+ /* SerDes integration register entry bit positions and sizes */
+ #define SIR0_KR_RT_1_RESET_INDEX	11
+ #define SIR0_KR_RT_1_RESET_WIDTH	1
+ #define SIR0_STATUS_RX_READY_INDEX	0
+ #define SIR0_STATUS_RX_READY_WIDTH	1
+ #define SIR0_STATUS_TX_READY_INDEX	8
+ #define SIR0_STATUS_TX_READY_WIDTH	1
+ #define SIR1_SPEED_CDR_RATE_INDEX	12
+ #define SIR1_SPEED_CDR_RATE_WIDTH	4
+ #define SIR1_SPEED_DATARATE_INDEX	4
+ #define SIR1_SPEED_DATARATE_WIDTH	2
+ #define SIR1_SPEED_PLLSEL_INDEX		3
+ #define SIR1_SPEED_PLLSEL_WIDTH		1
+ #define SIR1_SPEED_RATECHANGE_INDEX	6
+ #define SIR1_SPEED_RATECHANGE_WIDTH	1
+ #define SIR1_SPEED_TXAMP_INDEX		8
+ #define SIR1_SPEED_TXAMP_WIDTH		4
+ #define SIR1_SPEED_WORDMODE_INDEX	0
+ #define SIR1_SPEED_WORDMODE_WIDTH	3
+ 
+ /* SerDes RxTx register offsets */
+ #define RXTX_REG6			0x0018
+ #define RXTX_REG20			0x0050
+ #define RXTX_REG22			0x0058
+ #define RXTX_REG114			0x01c8
+ #define RXTX_REG129			0x0204
+ 
+ /* SerDes RxTx register entry bit positions and sizes */
+ #define RXTX_REG6_RESETB_RXD_INDEX	8
+ #define RXTX_REG6_RESETB_RXD_WIDTH	1
+ #define RXTX_REG20_BLWC_ENA_INDEX	2
+ #define RXTX_REG20_BLWC_ENA_WIDTH	1
+ #define RXTX_REG114_PQ_REG_INDEX	9
+ #define RXTX_REG114_PQ_REG_WIDTH	7
+ #define RXTX_REG129_RXDFE_CONFIG_INDEX	14
+ #define RXTX_REG129_RXDFE_CONFIG_WIDTH	2
+ 
+ /* MAC Control register offsets */
+ #define XP_PROP_0			0x0000
+ #define XP_PROP_1			0x0004
+ #define XP_PROP_2			0x0008
+ #define XP_PROP_3			0x000c
+ #define XP_PROP_4			0x0010
+ #define XP_PROP_5			0x0014
+ #define XP_MAC_ADDR_LO			0x0020
+ #define XP_MAC_ADDR_HI			0x0024
+ #define XP_ECC_ISR			0x0030
+ #define XP_ECC_IER			0x0034
+ #define XP_ECC_CNT0			0x003c
+ #define XP_ECC_CNT1			0x0040
+ #define XP_DRIVER_INT_REQ		0x0060
+ #define XP_DRIVER_INT_RO		0x0064
+ #define XP_DRIVER_SCRATCH_0		0x0068
+ #define XP_DRIVER_SCRATCH_1		0x006c
+ #define XP_INT_EN			0x0078
+ 
+ /* MAC Control register entry bit positions and sizes */
+ #define XP_DRIVER_INT_REQ_REQUEST_INDEX		0
+ #define XP_DRIVER_INT_REQ_REQUEST_WIDTH		1
+ #define XP_DRIVER_INT_RO_STATUS_INDEX		0
+ #define XP_DRIVER_INT_RO_STATUS_WIDTH		1
+ #define XP_DRIVER_SCRATCH_0_COMMAND_INDEX	0
+ #define XP_DRIVER_SCRATCH_0_COMMAND_WIDTH	8
+ #define XP_DRIVER_SCRATCH_0_SUB_COMMAND_INDEX	8
+ #define XP_DRIVER_SCRATCH_0_SUB_COMMAND_WIDTH	8
+ #define XP_ECC_CNT0_RX_DED_INDEX		24
+ #define XP_ECC_CNT0_RX_DED_WIDTH		8
+ #define XP_ECC_CNT0_RX_SEC_INDEX		16
+ #define XP_ECC_CNT0_RX_SEC_WIDTH		8
+ #define XP_ECC_CNT0_TX_DED_INDEX		8
+ #define XP_ECC_CNT0_TX_DED_WIDTH		8
+ #define XP_ECC_CNT0_TX_SEC_INDEX		0
+ #define XP_ECC_CNT0_TX_SEC_WIDTH		8
+ #define XP_ECC_CNT1_DESC_DED_INDEX		8
+ #define XP_ECC_CNT1_DESC_DED_WIDTH		8
+ #define XP_ECC_CNT1_DESC_SEC_INDEX		0
+ #define XP_ECC_CNT1_DESC_SEC_WIDTH		8
+ #define XP_ECC_IER_DESC_DED_INDEX		0
+ #define XP_ECC_IER_DESC_DED_WIDTH		1
+ #define XP_ECC_IER_DESC_SEC_INDEX		1
+ #define XP_ECC_IER_DESC_SEC_WIDTH		1
+ #define XP_ECC_IER_RX_DED_INDEX			2
+ #define XP_ECC_IER_RX_DED_WIDTH			1
+ #define XP_ECC_IER_RX_SEC_INDEX			3
+ #define XP_ECC_IER_RX_SEC_WIDTH			1
+ #define XP_ECC_IER_TX_DED_INDEX			4
+ #define XP_ECC_IER_TX_DED_WIDTH			1
+ #define XP_ECC_IER_TX_SEC_INDEX			5
+ #define XP_ECC_IER_TX_SEC_WIDTH			1
+ #define XP_ECC_ISR_DESC_DED_INDEX		0
+ #define XP_ECC_ISR_DESC_DED_WIDTH		1
+ #define XP_ECC_ISR_DESC_SEC_INDEX		1
+ #define XP_ECC_ISR_DESC_SEC_WIDTH		1
+ #define XP_ECC_ISR_RX_DED_INDEX			2
+ #define XP_ECC_ISR_RX_DED_WIDTH			1
+ #define XP_ECC_ISR_RX_SEC_INDEX			3
+ #define XP_ECC_ISR_RX_SEC_WIDTH			1
+ #define XP_ECC_ISR_TX_DED_INDEX			4
+ #define XP_ECC_ISR_TX_DED_WIDTH			1
+ #define XP_ECC_ISR_TX_SEC_INDEX			5
+ #define XP_ECC_ISR_TX_SEC_WIDTH			1
+ #define XP_MAC_ADDR_HI_VALID_INDEX		31
+ #define XP_MAC_ADDR_HI_VALID_WIDTH		1
+ #define XP_PROP_0_CONN_TYPE_INDEX		28
+ #define XP_PROP_0_CONN_TYPE_WIDTH		3
+ #define XP_PROP_0_MDIO_ADDR_INDEX		16
+ #define XP_PROP_0_MDIO_ADDR_WIDTH		5
+ #define XP_PROP_0_PORT_ID_INDEX			0
+ #define XP_PROP_0_PORT_ID_WIDTH			8
+ #define XP_PROP_0_PORT_MODE_INDEX		8
+ #define XP_PROP_0_PORT_MODE_WIDTH		4
+ #define XP_PROP_0_PORT_SPEEDS_INDEX		23
+ #define XP_PROP_0_PORT_SPEEDS_WIDTH		4
+ #define XP_PROP_1_MAX_RX_DMA_INDEX		24
+ #define XP_PROP_1_MAX_RX_DMA_WIDTH		5
+ #define XP_PROP_1_MAX_RX_QUEUES_INDEX		8
+ #define XP_PROP_1_MAX_RX_QUEUES_WIDTH		5
+ #define XP_PROP_1_MAX_TX_DMA_INDEX		16
+ #define XP_PROP_1_MAX_TX_DMA_WIDTH		5
+ #define XP_PROP_1_MAX_TX_QUEUES_INDEX		0
+ #define XP_PROP_1_MAX_TX_QUEUES_WIDTH		5
+ #define XP_PROP_2_RX_FIFO_SIZE_INDEX		16
+ #define XP_PROP_2_RX_FIFO_SIZE_WIDTH		16
+ #define XP_PROP_2_TX_FIFO_SIZE_INDEX		0
+ #define XP_PROP_2_TX_FIFO_SIZE_WIDTH		16
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  
  /* Descriptor/Packet entry bit positions and sizes */
  #define RX_PACKET_ERRORS_CRC_INDEX		2
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-dev.c
index de7b81d8b4ee,78a2063029da..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
@@@ -499,12 -724,112 +499,75 @@@ static void xgbe_enable_mac_interrupts(
  	XGMAC_IOWRITE_BITS(pdata, MMC_TIER, ALL_INTERRUPTS, 0xffffffff);
  }
  
++<<<<<<< HEAD
 +static int xgbe_set_gmii_speed(struct xgbe_prv_data *pdata)
++=======
+ static void xgbe_enable_ecc_interrupts(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int ecc_isr, ecc_ier = 0;
+ 
+ 	if (!pdata->vdata->ecc_support)
+ 		return;
+ 
+ 	/* Clear all the interrupts which are set */
+ 	ecc_isr = XP_IOREAD(pdata, XP_ECC_ISR);
+ 	XP_IOWRITE(pdata, XP_ECC_ISR, ecc_isr);
+ 
+ 	/* Enable ECC interrupts */
+ 	XP_SET_BITS(ecc_ier, XP_ECC_IER, TX_DED, 1);
+ 	XP_SET_BITS(ecc_ier, XP_ECC_IER, TX_SEC, 1);
+ 	XP_SET_BITS(ecc_ier, XP_ECC_IER, RX_DED, 1);
+ 	XP_SET_BITS(ecc_ier, XP_ECC_IER, RX_SEC, 1);
+ 	XP_SET_BITS(ecc_ier, XP_ECC_IER, DESC_DED, 1);
+ 	XP_SET_BITS(ecc_ier, XP_ECC_IER, DESC_SEC, 1);
+ 
+ 	XP_IOWRITE(pdata, XP_ECC_IER, ecc_ier);
+ }
+ 
+ static void xgbe_disable_ecc_ded(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int ecc_ier;
+ 
+ 	ecc_ier = XP_IOREAD(pdata, XP_ECC_IER);
+ 
+ 	/* Disable ECC DED interrupts */
+ 	XP_SET_BITS(ecc_ier, XP_ECC_IER, TX_DED, 0);
+ 	XP_SET_BITS(ecc_ier, XP_ECC_IER, RX_DED, 0);
+ 	XP_SET_BITS(ecc_ier, XP_ECC_IER, DESC_DED, 0);
+ 
+ 	XP_IOWRITE(pdata, XP_ECC_IER, ecc_ier);
+ }
+ 
+ static void xgbe_disable_ecc_sec(struct xgbe_prv_data *pdata,
+ 				 enum xgbe_ecc_sec sec)
+ {
+ 	unsigned int ecc_ier;
+ 
+ 	ecc_ier = XP_IOREAD(pdata, XP_ECC_IER);
+ 
+ 	/* Disable ECC SEC interrupt */
+ 	switch (sec) {
+ 	case XGBE_ECC_SEC_TX:
+ 	XP_SET_BITS(ecc_ier, XP_ECC_IER, TX_SEC, 0);
+ 		break;
+ 	case XGBE_ECC_SEC_RX:
+ 	XP_SET_BITS(ecc_ier, XP_ECC_IER, RX_SEC, 0);
+ 		break;
+ 	case XGBE_ECC_SEC_DESC:
+ 	XP_SET_BITS(ecc_ier, XP_ECC_IER, DESC_SEC, 0);
+ 		break;
+ 	}
+ 
+ 	XP_IOWRITE(pdata, XP_ECC_IER, ecc_ier);
+ }
+ 
+ static int xgbe_set_speed(struct xgbe_prv_data *pdata, int speed)
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  {
 -	unsigned int ss;
 -
 -	switch (speed) {
 -	case SPEED_1000:
 -		ss = 0x03;
 -		break;
 -	case SPEED_2500:
 -		ss = 0x02;
 -		break;
 -	case SPEED_10000:
 -		ss = 0x00;
 -		break;
 -	default:
 -		return -EINVAL;
 -	}
 -
 -	if (XGMAC_IOREAD_BITS(pdata, MAC_TCR, SS) != ss)
 -		XGMAC_IOWRITE_BITS(pdata, MAC_TCR, SS, ss);
 -
 -	return 0;
 -}
 -
 -static int xgbe_enable_rx_vlan_stripping(struct xgbe_prv_data *pdata)
 -{
 -	/* Put the VLAN tag in the Rx descriptor */
 -	XGMAC_IOWRITE_BITS(pdata, MAC_VLANTR, EVLRXS, 1);
 -
 -	/* Don't check the VLAN type */
 -	XGMAC_IOWRITE_BITS(pdata, MAC_VLANTR, DOVLTC, 1);
 -
 -	/* Check only C-TAG (0x8100) packets */
 -	XGMAC_IOWRITE_BITS(pdata, MAC_VLANTR, ERSVLM, 0);
 -
 -	/* Don't consider an S-TAG (0x88A8) packet as a VLAN packet */
 -	XGMAC_IOWRITE_BITS(pdata, MAC_VLANTR, ESVL, 0);
 -
 -	/* Enable VLAN tag stripping */
 -	XGMAC_IOWRITE_BITS(pdata, MAC_VLANTR, EVLS, 0x3);
 -
 -	return 0;
 -}
 +	if (XGMAC_IOREAD_BITS(pdata, MAC_TCR, SS) == 0x3)
 +		return 0;
  
 -static int xgbe_disable_rx_vlan_stripping(struct xgbe_prv_data *pdata)
 -{
 -	XGMAC_IOWRITE_BITS(pdata, MAC_VLANTR, EVLS, 0);
 +	XGMAC_IOWRITE_BITS(pdata, MAC_TCR, SS, 0x3);
  
  	return 0;
  }
@@@ -2272,5 -3445,27 +2340,30 @@@ void xgbe_init_function_ptrs_dev(struc
  	hw_if->rx_mmc_int = xgbe_rx_mmc_int;
  	hw_if->read_mmc_stats = xgbe_read_mmc_stats;
  
++<<<<<<< HEAD
++=======
+ 	/* For PTP config */
+ 	hw_if->config_tstamp = xgbe_config_tstamp;
+ 	hw_if->update_tstamp_addend = xgbe_update_tstamp_addend;
+ 	hw_if->set_tstamp_time = xgbe_set_tstamp_time;
+ 	hw_if->get_tstamp_time = xgbe_get_tstamp_time;
+ 	hw_if->get_tx_tstamp = xgbe_get_tx_tstamp;
+ 
+ 	/* For Data Center Bridging config */
+ 	hw_if->config_tc = xgbe_config_tc;
+ 	hw_if->config_dcb_tc = xgbe_config_dcb_tc;
+ 	hw_if->config_dcb_pfc = xgbe_config_dcb_pfc;
+ 
+ 	/* For Receive Side Scaling */
+ 	hw_if->enable_rss = xgbe_enable_rss;
+ 	hw_if->disable_rss = xgbe_disable_rss;
+ 	hw_if->set_rss_hash_key = xgbe_set_rss_hash_key;
+ 	hw_if->set_rss_lookup_table = xgbe_set_rss_lookup_table;
+ 
+ 	/* For ECC */
+ 	hw_if->disable_ecc_ded = xgbe_disable_ecc_ded;
+ 	hw_if->disable_ecc_sec = xgbe_disable_ecc_sec;
+ 
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  	DBGPR("<--xgbe_init_function_ptrs\n");
  }
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-drv.c
index d58e85811bc9,fc3b703eb583..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
@@@ -124,9 -127,112 +125,41 @@@
  #include "xgbe.h"
  #include "xgbe-common.h"
  
++<<<<<<< HEAD
++=======
+ static unsigned int ecc_sec_info_threshold = 10;
+ static unsigned int ecc_sec_warn_threshold = 10000;
+ static unsigned int ecc_sec_period = 600;
+ static unsigned int ecc_ded_threshold = 2;
+ static unsigned int ecc_ded_period = 600;
+ 
+ #ifdef CONFIG_AMD_XGBE_HAVE_ECC
+ /* Only expose the ECC parameters if supported */
+ module_param(ecc_sec_info_threshold, uint, S_IWUSR | S_IRUGO);
+ MODULE_PARM_DESC(ecc_sec_info_threshold,
+ 		 " ECC corrected error informational threshold setting");
+ 
+ module_param(ecc_sec_warn_threshold, uint, S_IWUSR | S_IRUGO);
+ MODULE_PARM_DESC(ecc_sec_warn_threshold,
+ 		 " ECC corrected error warning threshold setting");
+ 
+ module_param(ecc_sec_period, uint, S_IWUSR | S_IRUGO);
+ MODULE_PARM_DESC(ecc_sec_period, " ECC corrected error period (in seconds)");
+ 
+ module_param(ecc_ded_threshold, uint, S_IWUSR | S_IRUGO);
+ MODULE_PARM_DESC(ecc_ded_threshold, " ECC detected error threshold setting");
+ 
+ module_param(ecc_ded_period, uint, S_IWUSR | S_IRUGO);
+ MODULE_PARM_DESC(ecc_ded_period, " ECC detected error period (in seconds)");
+ #endif
+ 
+ static int xgbe_one_poll(struct napi_struct *, int);
+ static int xgbe_all_poll(struct napi_struct *, int);
+ static void xgbe_stop(struct xgbe_prv_data *);
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  
 -static int xgbe_alloc_channels(struct xgbe_prv_data *pdata)
 -{
 -	struct xgbe_channel *channel_mem, *channel;
 -	struct xgbe_ring *tx_ring, *rx_ring;
 -	unsigned int count, i;
 -	int ret = -ENOMEM;
 -
 -	count = max_t(unsigned int, pdata->tx_ring_count, pdata->rx_ring_count);
 -
 -	channel_mem = kcalloc(count, sizeof(struct xgbe_channel), GFP_KERNEL);
 -	if (!channel_mem)
 -		goto err_channel;
 -
 -	tx_ring = kcalloc(pdata->tx_ring_count, sizeof(struct xgbe_ring),
 -			  GFP_KERNEL);
 -	if (!tx_ring)
 -		goto err_tx_ring;
 -
 -	rx_ring = kcalloc(pdata->rx_ring_count, sizeof(struct xgbe_ring),
 -			  GFP_KERNEL);
 -	if (!rx_ring)
 -		goto err_rx_ring;
 -
 -	for (i = 0, channel = channel_mem; i < count; i++, channel++) {
 -		snprintf(channel->name, sizeof(channel->name), "channel-%u", i);
 -		channel->pdata = pdata;
 -		channel->queue_index = i;
 -		channel->dma_regs = pdata->xgmac_regs + DMA_CH_BASE +
 -				    (DMA_CH_INC * i);
 -
 -		if (pdata->per_channel_irq)
 -			channel->dma_irq = pdata->channel_irq[i];
 -
 -		if (i < pdata->tx_ring_count) {
 -			spin_lock_init(&tx_ring->lock);
 -			channel->tx_ring = tx_ring++;
 -		}
 -
 -		if (i < pdata->rx_ring_count) {
 -			spin_lock_init(&rx_ring->lock);
 -			channel->rx_ring = rx_ring++;
 -		}
 -
 -		netif_dbg(pdata, drv, pdata->netdev,
 -			  "%s: dma_regs=%p, dma_irq=%d, tx=%p, rx=%p\n",
 -			  channel->name, channel->dma_regs, channel->dma_irq,
 -			  channel->tx_ring, channel->rx_ring);
 -	}
 -
 -	pdata->channel = channel_mem;
 -	pdata->channel_count = count;
 -
 -	return 0;
 -
 -err_rx_ring:
 -	kfree(tx_ring);
 -
 -err_tx_ring:
 -	kfree(channel_mem);
 -
 -err_channel:
 -	return ret;
 -}
 -
 -static void xgbe_free_channels(struct xgbe_prv_data *pdata)
 -{
 -	if (!pdata->channel)
 -		return;
 -
 -	kfree(pdata->channel->rx_ring);
 -	kfree(pdata->channel->tx_ring);
 -	kfree(pdata->channel);
 -
 -	pdata->channel = NULL;
 -	pdata->channel_count = 0;
 -}
 +static int xgbe_poll(struct napi_struct *, int);
 +static void xgbe_set_rx_mode(struct net_device *);
  
  static inline unsigned int xgbe_tx_avail_desc(struct xgbe_ring *ring)
  {
@@@ -181,20 -332,111 +214,121 @@@ static void xgbe_disable_rx_tx_ints(str
  	unsigned int i;
  
  	channel = pdata->channel;
 -	for (i = 0; i < pdata->channel_count; i++, channel++)
 -		xgbe_disable_rx_tx_int(pdata, channel);
 +	for (i = 0; i < pdata->channel_count; i++, channel++) {
 +		if (channel->tx_ring && channel->rx_ring)
 +			int_id = XGMAC_INT_DMA_CH_SR_TI_RI;
 +		else if (channel->tx_ring)
 +			int_id = XGMAC_INT_DMA_CH_SR_TI;
 +		else if (channel->rx_ring)
 +			int_id = XGMAC_INT_DMA_CH_SR_RI;
 +		else
 +			continue;
 +
 +		hw_if->disable_int(channel, int_id);
 +	}
  }
  
+ static bool xgbe_ecc_sec(struct xgbe_prv_data *pdata, unsigned long *period,
+ 			 unsigned int *count, const char *area)
+ {
+ 	if (time_before(jiffies, *period)) {
+ 		(*count)++;
+ 	} else {
+ 		*period = jiffies + (ecc_sec_period * HZ);
+ 		*count = 1;
+ 	}
+ 
+ 	if (*count > ecc_sec_info_threshold)
+ 		dev_warn_once(pdata->dev,
+ 			      "%s ECC corrected errors exceed informational threshold\n",
+ 			      area);
+ 
+ 	if (*count > ecc_sec_warn_threshold) {
+ 		dev_warn_once(pdata->dev,
+ 			      "%s ECC corrected errors exceed warning threshold\n",
+ 			      area);
+ 		return true;
+ 	}
+ 
+ 	return false;
+ }
+ 
+ static bool xgbe_ecc_ded(struct xgbe_prv_data *pdata, unsigned long *period,
+ 			 unsigned int *count, const char *area)
+ {
+ 	if (time_before(jiffies, *period)) {
+ 		(*count)++;
+ 	} else {
+ 		*period = jiffies + (ecc_ded_period * HZ);
+ 		*count = 1;
+ 	}
+ 
+ 	if (*count > ecc_ded_threshold) {
+ 		netdev_alert(pdata->netdev,
+ 			     "%s ECC detected errors exceed threshold\n",
+ 			     area);
+ 		return true;
+ 	}
+ 
+ 	return false;
+ }
+ 
+ static irqreturn_t xgbe_ecc_isr(int irq, void *data)
+ {
+ 	struct xgbe_prv_data *pdata = data;
+ 	unsigned int ecc_isr;
+ 	bool stop = false;
+ 
+ 	/* Mask status with only the interrupts we care about */
+ 	ecc_isr = XP_IOREAD(pdata, XP_ECC_ISR);
+ 	ecc_isr &= XP_IOREAD(pdata, XP_ECC_IER);
+ 	netif_dbg(pdata, intr, pdata->netdev, "ECC_ISR=%#010x\n", ecc_isr);
+ 
+ 	if (XP_GET_BITS(ecc_isr, XP_ECC_ISR, TX_DED)) {
+ 		stop |= xgbe_ecc_ded(pdata, &pdata->tx_ded_period,
+ 				     &pdata->tx_ded_count, "TX fifo");
+ 	}
+ 
+ 	if (XP_GET_BITS(ecc_isr, XP_ECC_ISR, RX_DED)) {
+ 		stop |= xgbe_ecc_ded(pdata, &pdata->rx_ded_period,
+ 				     &pdata->rx_ded_count, "RX fifo");
+ 	}
+ 
+ 	if (XP_GET_BITS(ecc_isr, XP_ECC_ISR, DESC_DED)) {
+ 		stop |= xgbe_ecc_ded(pdata, &pdata->desc_ded_period,
+ 				     &pdata->desc_ded_count,
+ 				     "descriptor cache");
+ 	}
+ 
+ 	if (stop) {
+ 		pdata->hw_if.disable_ecc_ded(pdata);
+ 		schedule_work(&pdata->stopdev_work);
+ 		goto out;
+ 	}
+ 
+ 	if (XP_GET_BITS(ecc_isr, XP_ECC_ISR, TX_SEC)) {
+ 		if (xgbe_ecc_sec(pdata, &pdata->tx_sec_period,
+ 				 &pdata->tx_sec_count, "TX fifo"))
+ 			pdata->hw_if.disable_ecc_sec(pdata, XGBE_ECC_SEC_TX);
+ 	}
+ 
+ 	if (XP_GET_BITS(ecc_isr, XP_ECC_ISR, RX_SEC))
+ 		if (xgbe_ecc_sec(pdata, &pdata->rx_sec_period,
+ 				 &pdata->rx_sec_count, "RX fifo"))
+ 			pdata->hw_if.disable_ecc_sec(pdata, XGBE_ECC_SEC_RX);
+ 
+ 	if (XP_GET_BITS(ecc_isr, XP_ECC_ISR, DESC_SEC))
+ 		if (xgbe_ecc_sec(pdata, &pdata->desc_sec_period,
+ 				 &pdata->desc_sec_count, "descriptor cache"))
+ 			pdata->hw_if.disable_ecc_sec(pdata, XGBE_ECC_SEC_DESC);
+ 
+ out:
+ 	/* Clear all ECC interrupts */
+ 	XP_IOWRITE(pdata, XP_ECC_ISR, ecc_isr);
+ 
+ 	return IRQ_HANDLED;
+ }
+ 
  static irqreturn_t xgbe_isr(int irq, void *data)
  {
  	struct xgbe_prv_data *pdata = data;
@@@ -254,12 -508,28 +388,16 @@@
  
  		if (XGMAC_GET_BITS(mac_isr, MAC_ISR, MMCRXIS))
  			hw_if->rx_mmc_int(pdata);
 -
 -		if (XGMAC_GET_BITS(mac_isr, MAC_ISR, TSIS)) {
 -			mac_tssr = XGMAC_IOREAD(pdata, MAC_TSSR);
 -
 -			if (XGMAC_GET_BITS(mac_tssr, MAC_TSSR, TXTSC)) {
 -				/* Read Tx Timestamp to clear interrupt */
 -				pdata->tx_tstamp =
 -					hw_if->get_tx_tstamp(pdata);
 -				queue_work(pdata->dev_workqueue,
 -					   &pdata->tx_tstamp_work);
 -			}
 -		}
  	}
  
 -	/* If there is not a separate AN irq, handle it here */
 -	if (pdata->dev_irq == pdata->an_irq)
 -		pdata->phy_if.an_isr(irq, pdata);
 +	DBGPR("  DMA_ISR = %08x\n", XGMAC_IOREAD(pdata, DMA_ISR));
 +
 +	DBGPR("<--xgbe_isr\n");
  
+ 	/* If there is not a separate ECC irq, handle it here */
+ 	if (pdata->vdata->ecc_support && (pdata->dev_irq == pdata->ecc_irq))
+ 		xgbe_ecc_isr(irq, pdata);
+ 
  isr_done:
  	return IRQ_HANDLED;
  }
@@@ -408,10 -778,102 +546,106 @@@ static void xgbe_napi_enable(struct xgb
  
  static void xgbe_napi_disable(struct xgbe_prv_data *pdata, unsigned int del)
  {
 -	struct xgbe_channel *channel;
 -	unsigned int i;
 +	napi_disable(&pdata->napi);
  
++<<<<<<< HEAD
 +	if (del)
 +		netif_napi_del(&pdata->napi);
++=======
+ 	if (pdata->per_channel_irq) {
+ 		channel = pdata->channel;
+ 		for (i = 0; i < pdata->channel_count; i++, channel++) {
+ 			napi_disable(&channel->napi);
+ 
+ 			if (del)
+ 				netif_napi_del(&channel->napi);
+ 		}
+ 	} else {
+ 		napi_disable(&pdata->napi);
+ 
+ 		if (del)
+ 			netif_napi_del(&pdata->napi);
+ 	}
+ }
+ 
+ static int xgbe_request_irqs(struct xgbe_prv_data *pdata)
+ {
+ 	struct xgbe_channel *channel;
+ 	struct net_device *netdev = pdata->netdev;
+ 	unsigned int i;
+ 	int ret;
+ 
+ 	ret = devm_request_irq(pdata->dev, pdata->dev_irq, xgbe_isr, 0,
+ 			       netdev->name, pdata);
+ 	if (ret) {
+ 		netdev_alert(netdev, "error requesting irq %d\n",
+ 			     pdata->dev_irq);
+ 		return ret;
+ 	}
+ 
+ 	if (pdata->vdata->ecc_support && (pdata->dev_irq != pdata->ecc_irq)) {
+ 		ret = devm_request_irq(pdata->dev, pdata->ecc_irq, xgbe_ecc_isr,
+ 				       0, pdata->ecc_name, pdata);
+ 		if (ret) {
+ 			netdev_alert(netdev, "error requesting ecc irq %d\n",
+ 				     pdata->ecc_irq);
+ 			goto err_dev_irq;
+ 		}
+ 	}
+ 
+ 	if (!pdata->per_channel_irq)
+ 		return 0;
+ 
+ 	channel = pdata->channel;
+ 	for (i = 0; i < pdata->channel_count; i++, channel++) {
+ 		snprintf(channel->dma_irq_name,
+ 			 sizeof(channel->dma_irq_name) - 1,
+ 			 "%s-TxRx-%u", netdev_name(netdev),
+ 			 channel->queue_index);
+ 
+ 		ret = devm_request_irq(pdata->dev, channel->dma_irq,
+ 				       xgbe_dma_isr, 0,
+ 				       channel->dma_irq_name, channel);
+ 		if (ret) {
+ 			netdev_alert(netdev, "error requesting irq %d\n",
+ 				     channel->dma_irq);
+ 			goto err_dma_irq;
+ 		}
+ 	}
+ 
+ 	return 0;
+ 
+ err_dma_irq:
+ 	/* Using an unsigned int, 'i' will go to UINT_MAX and exit */
+ 	for (i--, channel--; i < pdata->channel_count; i--, channel--)
+ 		devm_free_irq(pdata->dev, channel->dma_irq, channel);
+ 
+ 	if (pdata->vdata->ecc_support && (pdata->dev_irq != pdata->ecc_irq))
+ 		devm_free_irq(pdata->dev, pdata->ecc_irq, pdata);
+ 
+ err_dev_irq:
+ 	devm_free_irq(pdata->dev, pdata->dev_irq, pdata);
+ 
+ 	return ret;
+ }
+ 
+ static void xgbe_free_irqs(struct xgbe_prv_data *pdata)
+ {
+ 	struct xgbe_channel *channel;
+ 	unsigned int i;
+ 
+ 	devm_free_irq(pdata->dev, pdata->dev_irq, pdata);
+ 
+ 	if (pdata->vdata->ecc_support && (pdata->dev_irq != pdata->ecc_irq))
+ 		devm_free_irq(pdata->dev, pdata->ecc_irq, pdata);
+ 
+ 	if (!pdata->per_channel_irq)
+ 		return;
+ 
+ 	channel = pdata->channel;
+ 	for (i = 0; i < pdata->channel_count; i++, channel++)
+ 		devm_free_irq(pdata->dev, channel->dma_irq, channel);
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  }
  
  void xgbe_init_tx_coalesce(struct xgbe_prv_data *pdata)
@@@ -585,11 -1064,13 +819,13 @@@ static int xgbe_start(struct xgbe_prv_d
  	hw_if->enable_tx(pdata);
  	hw_if->enable_rx(pdata);
  
 -	netif_tx_start_all_queues(netdev);
 +	xgbe_init_tx_timers(pdata);
  
 -	xgbe_start_timers(pdata);
 -	queue_work(pdata->dev_workqueue, &pdata->service_work);
 +	xgbe_napi_enable(pdata, 1);
 +	netif_tx_start_all_queues(netdev);
  
+ 	clear_bit(XGBE_STOPPED, &pdata->dev_state);
+ 
  	DBGPR("<--xgbe_start\n");
  
  	return 0;
@@@ -602,23 -1095,61 +838,70 @@@ static void xgbe_stop(struct xgbe_prv_d
  
  	DBGPR("-->xgbe_stop\n");
  
++<<<<<<< HEAD
 +	phy_stop(pdata->phydev);
++=======
+ 	if (test_bit(XGBE_STOPPED, &pdata->dev_state))
+ 		return;
+ 
+ 	netif_tx_stop_all_queues(netdev);
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
 +
 +	netif_tx_stop_all_queues(netdev);
 +	xgbe_napi_disable(pdata, 1);
  
 -	xgbe_stop_timers(pdata);
 -	flush_workqueue(pdata->dev_workqueue);
 +	xgbe_stop_tx_timers(pdata);
  
  	hw_if->disable_tx(pdata);
  	hw_if->disable_rx(pdata);
  
++<<<<<<< HEAD
++=======
+ 	xgbe_free_irqs(pdata);
+ 
+ 	xgbe_napi_disable(pdata, 1);
+ 
+ 	phy_if->phy_stop(pdata);
+ 
+ 	hw_if->exit(pdata);
+ 
+ 	channel = pdata->channel;
+ 	for (i = 0; i < pdata->channel_count; i++, channel++) {
+ 		if (!channel->tx_ring)
+ 			continue;
+ 
+ 		txq = netdev_get_tx_queue(netdev, channel->queue_index);
+ 		netdev_tx_reset_queue(txq);
+ 	}
+ 
+ 	set_bit(XGBE_STOPPED, &pdata->dev_state);
+ 
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  	DBGPR("<--xgbe_stop\n");
  }
  
+ static void xgbe_stopdev(struct work_struct *work)
+ {
+ 	struct xgbe_prv_data *pdata = container_of(work,
+ 						   struct xgbe_prv_data,
+ 						   stopdev_work);
+ 
+ 	rtnl_lock();
+ 
+ 	xgbe_stop(pdata);
+ 
+ 	xgbe_free_tx_data(pdata);
+ 	xgbe_free_rx_data(pdata);
+ 
+ 	rtnl_unlock();
+ 
+ 	netdev_alert(pdata->netdev, "device stopped\n");
+ }
+ 
  static void xgbe_restart_dev(struct xgbe_prv_data *pdata)
  {
 +	struct xgbe_hw_if *hw_if = &pdata->hw_if;
 +
  	DBGPR("-->xgbe_restart_dev\n");
  
  	/* If not running, "restart" will happen on open */
@@@ -776,20 -1521,18 +1059,26 @@@ static int xgbe_open(struct net_device 
  	/* Allocate the ring descriptors and buffers */
  	ret = desc_if->alloc_ring_resources(pdata);
  	if (ret)
 -		goto err_channels;
 +		goto err_clk;
  
 -	INIT_WORK(&pdata->service_work, xgbe_service);
 +	/* Initialize the device restart work struct */
  	INIT_WORK(&pdata->restart_work, xgbe_restart);
++<<<<<<< HEAD
 +
 +	/* Request interrupts */
 +	ret = devm_request_irq(pdata->dev, netdev->irq, xgbe_isr, 0,
 +			       netdev->name, pdata);
 +	if (ret) {
 +		netdev_alert(netdev, "error requesting irq %d\n",
 +			     pdata->irq_number);
 +		goto err_irq;
 +	}
 +	pdata->irq_number = netdev->irq;
++=======
+ 	INIT_WORK(&pdata->stopdev_work, xgbe_stopdev);
+ 	INIT_WORK(&pdata->tx_tstamp_work, xgbe_tx_tstamp);
+ 	xgbe_init_timers(pdata);
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  
  	ret = xgbe_start(pdata);
  	if (ret)
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-main.c
index e79ba9088346,b16b7b62dee0..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-main.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-main.c
@@@ -240,12 -180,117 +240,123 @@@ static int xgbe_probe(struct platform_d
  	SET_NETDEV_DEV(netdev, dev);
  	pdata = netdev_priv(netdev);
  	pdata->netdev = netdev;
 +	pdata->pdev = pdev;
  	pdata->dev = dev;
 +	platform_set_drvdata(pdev, netdev);
  
  	spin_lock_init(&pdata->lock);
++<<<<<<< HEAD
 +	mutex_init(&pdata->xpcs_mutex);
++=======
+ 	spin_lock_init(&pdata->xpcs_lock);
+ 	mutex_init(&pdata->rss_mutex);
+ 	spin_lock_init(&pdata->tstamp_lock);
+ 
+ 	pdata->msg_enable = netif_msg_init(debug, default_msg_level);
+ 
+ 	set_bit(XGBE_DOWN, &pdata->dev_state);
+ 	set_bit(XGBE_STOPPED, &pdata->dev_state);
+ 
+ 	return pdata;
+ }
+ 
+ void xgbe_free_pdata(struct xgbe_prv_data *pdata)
+ {
+ 	struct net_device *netdev = pdata->netdev;
+ 
+ 	free_netdev(netdev);
+ }
+ 
+ void xgbe_set_counts(struct xgbe_prv_data *pdata)
+ {
+ 	/* Set all the function pointers */
+ 	xgbe_init_all_fptrs(pdata);
+ 
+ 	/* Populate the hardware features */
+ 	xgbe_get_all_hw_features(pdata);
+ 
+ 	/* Set default max values if not provided */
+ 	if (!pdata->tx_max_channel_count)
+ 		pdata->tx_max_channel_count = pdata->hw_feat.tx_ch_cnt;
+ 	if (!pdata->rx_max_channel_count)
+ 		pdata->rx_max_channel_count = pdata->hw_feat.rx_ch_cnt;
+ 
+ 	if (!pdata->tx_max_q_count)
+ 		pdata->tx_max_q_count = pdata->hw_feat.tx_q_cnt;
+ 	if (!pdata->rx_max_q_count)
+ 		pdata->rx_max_q_count = pdata->hw_feat.rx_q_cnt;
+ 
+ 	/* Calculate the number of Tx and Rx rings to be created
+ 	 *  -Tx (DMA) Channels map 1-to-1 to Tx Queues so set
+ 	 *   the number of Tx queues to the number of Tx channels
+ 	 *   enabled
+ 	 *  -Rx (DMA) Channels do not map 1-to-1 so use the actual
+ 	 *   number of Rx queues or maximum allowed
+ 	 */
+ 	pdata->tx_ring_count = min_t(unsigned int, num_online_cpus(),
+ 				     pdata->hw_feat.tx_ch_cnt);
+ 	pdata->tx_ring_count = min_t(unsigned int, pdata->tx_ring_count,
+ 				     pdata->tx_max_channel_count);
+ 	pdata->tx_ring_count = min_t(unsigned int, pdata->tx_ring_count,
+ 				     pdata->tx_max_q_count);
+ 
+ 	pdata->tx_q_count = pdata->tx_ring_count;
+ 
+ 	pdata->rx_ring_count = min_t(unsigned int, num_online_cpus(),
+ 				     pdata->hw_feat.rx_ch_cnt);
+ 	pdata->rx_ring_count = min_t(unsigned int, pdata->rx_ring_count,
+ 				     pdata->rx_max_channel_count);
+ 
+ 	pdata->rx_q_count = min_t(unsigned int, pdata->hw_feat.rx_q_cnt,
+ 				  pdata->rx_max_q_count);
+ 
+ 	if (netif_msg_probe(pdata)) {
+ 		dev_dbg(pdata->dev, "TX/RX DMA channel count = %u/%u\n",
+ 			pdata->tx_ring_count, pdata->rx_ring_count);
+ 		dev_dbg(pdata->dev, "TX/RX hardware queue count = %u/%u\n",
+ 			pdata->tx_q_count, pdata->rx_q_count);
+ 	}
+ }
+ 
+ int xgbe_config_netdev(struct xgbe_prv_data *pdata)
+ {
+ 	struct net_device *netdev = pdata->netdev;
+ 	struct device *dev = pdata->dev;
+ 	unsigned int i;
+ 	int ret;
+ 
+ 	netdev->irq = pdata->dev_irq;
+ 	netdev->base_addr = (unsigned long)pdata->xgmac_regs;
+ 	memcpy(netdev->dev_addr, pdata->mac_addr, netdev->addr_len);
+ 
+ 	/* Initialize ECC timestamps */
+ 	pdata->tx_sec_period = jiffies;
+ 	pdata->tx_ded_period = jiffies;
+ 	pdata->rx_sec_period = jiffies;
+ 	pdata->rx_ded_period = jiffies;
+ 	pdata->desc_sec_period = jiffies;
+ 	pdata->desc_ded_period = jiffies;
+ 
+ 	/* Issue software reset to device */
+ 	pdata->hw_if.exit(pdata);
+ 
+ 	/* Set default configuration data */
+ 	xgbe_default_config(pdata);
+ 
+ 	/* Set the DMA mask */
+ 	ret = dma_set_mask_and_coherent(dev,
+ 					DMA_BIT_MASK(pdata->hw_feat.dma_width));
+ 	if (ret) {
+ 		dev_err(dev, "dma_set_mask_and_coherent failed\n");
+ 		return ret;
+ 	}
+ 
+ 	/* Set default max values if not provided */
+ 	if (!pdata->tx_max_fifo_size)
+ 		pdata->tx_max_fifo_size = pdata->hw_feat.tx_fifo_size;
+ 	if (!pdata->rx_max_fifo_size)
+ 		pdata->rx_max_fifo_size = pdata->hw_feat.rx_fifo_size;
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  
  	/* Set and validate the number of descriptors for a ring */
  	BUILD_BUG_ON_NOT_POWER_OF_2(XGBE_TX_DESC_CNT);
@@@ -418,14 -386,42 +529,44 @@@
  	ret = register_netdev(netdev);
  	if (ret) {
  		dev_err(dev, "net device registration failed\n");
 -		return ret;
 +		goto err_reg_netdev;
  	}
  
++<<<<<<< HEAD
++=======
+ 	/* Create the PHY/ANEG name based on netdev name */
+ 	snprintf(pdata->an_name, sizeof(pdata->an_name) - 1, "%s-pcs",
+ 		 netdev_name(netdev));
+ 
+ 	/* Create the ECC name based on netdev name */
+ 	snprintf(pdata->ecc_name, sizeof(pdata->ecc_name) - 1, "%s-ecc",
+ 		 netdev_name(netdev));
+ 
+ 	/* Create workqueues */
+ 	pdata->dev_workqueue =
+ 		create_singlethread_workqueue(netdev_name(netdev));
+ 	if (!pdata->dev_workqueue) {
+ 		netdev_err(netdev, "device workqueue creation failed\n");
+ 		ret = -ENOMEM;
+ 		goto err_netdev;
+ 	}
+ 
+ 	pdata->an_workqueue =
+ 		create_singlethread_workqueue(pdata->an_name);
+ 	if (!pdata->an_workqueue) {
+ 		netdev_err(netdev, "phy workqueue creation failed\n");
+ 		ret = -ENOMEM;
+ 		goto err_wq;
+ 	}
+ 
+ 	xgbe_ptp_register(pdata);
+ 
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  	xgbe_debugfs_init(pdata);
  
 -	netif_dbg(pdata, drv, pdata->netdev, "%u Tx software queues\n",
 -		  pdata->tx_ring_count);
 -	netif_dbg(pdata, drv, pdata->netdev, "%u Rx software queues\n",
 -		  pdata->rx_ring_count);
 +	netdev_notice(netdev, "net device enabled\n");
 +
 +	DBGPR("<-- xgbe_probe\n");
  
  	return 0;
  
diff --cc drivers/net/ethernet/amd/xgbe/xgbe.h
index 1903f878545a,2f0b0b4c611d..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe.h
+++ b/drivers/net/ethernet/amd/xgbe/xgbe.h
@@@ -194,7 -258,36 +194,10 @@@
  /* Flow control queue count */
  #define XGMAC_MAX_FLOW_CONTROL_QUEUES	8
  
 -/* Flow control threshold units */
 -#define XGMAC_FLOW_CONTROL_UNIT		512
 -#define XGMAC_FLOW_CONTROL_ALIGN(_x)				\
 -	(((_x) + XGMAC_FLOW_CONTROL_UNIT - 1) & ~(XGMAC_FLOW_CONTROL_UNIT - 1))
 -#define XGMAC_FLOW_CONTROL_VALUE(_x)				\
 -	(((_x) < 1024) ? 0 : ((_x) / XGMAC_FLOW_CONTROL_UNIT) - 2)
 -#define XGMAC_FLOW_CONTROL_MAX		33280
 -
 -/* Maximum MAC address hash table size (256 bits = 8 bytes) */
 -#define XGBE_MAC_HASH_TABLE_SIZE	8
 -
 -/* Receive Side Scaling */
 -#define XGBE_RSS_HASH_KEY_SIZE		40
 -#define XGBE_RSS_MAX_TABLE_SIZE		256
 -#define XGBE_RSS_LOOKUP_TABLE_TYPE	0
 -#define XGBE_RSS_HASH_KEY_TYPE		1
 -
 -/* Auto-negotiation */
 -#define XGBE_AN_MS_TIMEOUT		500
 -#define XGBE_LINK_TIMEOUT		5
 -
 -#define XGBE_SGMII_AN_LINK_STATUS	BIT(1)
 -#define XGBE_SGMII_AN_LINK_SPEED	(BIT(2) | BIT(3))
 -#define XGBE_SGMII_AN_LINK_SPEED_100	0x04
 -#define XGBE_SGMII_AN_LINK_SPEED_1000	0x08
 -#define XGBE_SGMII_AN_LINK_DUPLEX	BIT(4)
  
+ /* ECC correctable error notification window (seconds) */
+ #define XGBE_ECC_LIMIT			60
+ 
  struct xgbe_prv_data;
  
  struct xgbe_packet_data {
@@@ -307,6 -460,13 +310,16 @@@ struct xgbe_channel 
  	struct xgbe_ring *rx_ring;
  } ____cacheline_aligned;
  
++<<<<<<< HEAD
++=======
+ enum xgbe_state {
+ 	XGBE_DOWN,
+ 	XGBE_LINK_INIT,
+ 	XGBE_LINK_ERR,
+ 	XGBE_STOPPED,
+ };
+ 
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  enum xgbe_int {
  	XGMAC_INT_DMA_CH_SR_TI,
  	XGMAC_INT_DMA_CH_SR_TPS,
@@@ -324,18 -484,75 +337,90 @@@ enum xgbe_int_state 
  	XGMAC_INT_STATE_RESTORE,
  };
  
++<<<<<<< HEAD
 +enum xgbe_mtl_fifo_size {
 +	XGMAC_MTL_FIFO_SIZE_256  = 0x00,
 +	XGMAC_MTL_FIFO_SIZE_512  = 0x01,
 +	XGMAC_MTL_FIFO_SIZE_1K   = 0x03,
 +	XGMAC_MTL_FIFO_SIZE_2K   = 0x07,
 +	XGMAC_MTL_FIFO_SIZE_4K   = 0x0f,
 +	XGMAC_MTL_FIFO_SIZE_8K   = 0x1f,
 +	XGMAC_MTL_FIFO_SIZE_16K  = 0x3f,
 +	XGMAC_MTL_FIFO_SIZE_32K  = 0x7f,
 +	XGMAC_MTL_FIFO_SIZE_64K  = 0xff,
 +	XGMAC_MTL_FIFO_SIZE_128K = 0x1ff,
 +	XGMAC_MTL_FIFO_SIZE_256K = 0x3ff,
++=======
+ enum xgbe_ecc_sec {
+ 	XGBE_ECC_SEC_TX,
+ 	XGBE_ECC_SEC_RX,
+ 	XGBE_ECC_SEC_DESC,
+ };
+ 
+ enum xgbe_speed {
+ 	XGBE_SPEED_1000 = 0,
+ 	XGBE_SPEED_2500,
+ 	XGBE_SPEED_10000,
+ 	XGBE_SPEEDS,
+ };
+ 
+ enum xgbe_xpcs_access {
+ 	XGBE_XPCS_ACCESS_V1 = 0,
+ 	XGBE_XPCS_ACCESS_V2,
+ };
+ 
+ enum xgbe_an_mode {
+ 	XGBE_AN_MODE_CL73 = 0,
+ 	XGBE_AN_MODE_CL37,
+ 	XGBE_AN_MODE_CL37_SGMII,
+ 	XGBE_AN_MODE_NONE,
+ };
+ 
+ enum xgbe_an {
+ 	XGBE_AN_READY = 0,
+ 	XGBE_AN_PAGE_RECEIVED,
+ 	XGBE_AN_INCOMPAT_LINK,
+ 	XGBE_AN_COMPLETE,
+ 	XGBE_AN_NO_LINK,
+ 	XGBE_AN_ERROR,
+ };
+ 
+ enum xgbe_rx {
+ 	XGBE_RX_BPA = 0,
+ 	XGBE_RX_XNP,
+ 	XGBE_RX_COMPLETE,
+ 	XGBE_RX_ERROR,
+ };
+ 
+ enum xgbe_mode {
+ 	XGBE_MODE_KX_1000 = 0,
+ 	XGBE_MODE_KX_2500,
+ 	XGBE_MODE_KR,
+ 	XGBE_MODE_UNKNOWN,
+ };
+ 
+ enum xgbe_speedset {
+ 	XGBE_SPEEDSET_1000_10000 = 0,
+ 	XGBE_SPEEDSET_2500_10000,
+ };
+ 
+ struct xgbe_phy {
+ 	u32 supported;
+ 	u32 advertising;
+ 	u32 lp_advertising;
+ 
+ 	int address;
+ 
+ 	int autoneg;
+ 	int speed;
+ 	int duplex;
+ 
+ 	int link;
+ 
+ 	int pause_autoneg;
+ 	int tx_pause;
+ 	int rx_pause;
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  };
  
  struct xgbe_mmc_stats {
@@@ -461,6 -685,96 +546,99 @@@ struct xgbe_hw_if 
  	void (*rx_mmc_int)(struct xgbe_prv_data *);
  	void (*tx_mmc_int)(struct xgbe_prv_data *);
  	void (*read_mmc_stats)(struct xgbe_prv_data *);
++<<<<<<< HEAD
++=======
+ 
+ 	/* For Timestamp config */
+ 	int (*config_tstamp)(struct xgbe_prv_data *, unsigned int);
+ 	void (*update_tstamp_addend)(struct xgbe_prv_data *, unsigned int);
+ 	void (*set_tstamp_time)(struct xgbe_prv_data *, unsigned int sec,
+ 				unsigned int nsec);
+ 	u64 (*get_tstamp_time)(struct xgbe_prv_data *);
+ 	u64 (*get_tx_tstamp)(struct xgbe_prv_data *);
+ 
+ 	/* For Data Center Bridging config */
+ 	void (*config_tc)(struct xgbe_prv_data *);
+ 	void (*config_dcb_tc)(struct xgbe_prv_data *);
+ 	void (*config_dcb_pfc)(struct xgbe_prv_data *);
+ 
+ 	/* For Receive Side Scaling */
+ 	int (*enable_rss)(struct xgbe_prv_data *);
+ 	int (*disable_rss)(struct xgbe_prv_data *);
+ 	int (*set_rss_hash_key)(struct xgbe_prv_data *, const u8 *);
+ 	int (*set_rss_lookup_table)(struct xgbe_prv_data *, const u32 *);
+ 
+ 	/* For ECC */
+ 	void (*disable_ecc_ded)(struct xgbe_prv_data *);
+ 	void (*disable_ecc_sec)(struct xgbe_prv_data *, enum xgbe_ecc_sec);
+ };
+ 
+ /* This structure represents implementation specific routines for an
+  * implementation of a PHY. All routines are required unless noted below.
+  *   Optional routines:
+  *     kr_training_pre, kr_training_post
+  */
+ struct xgbe_phy_impl_if {
+ 	/* Perform Setup/teardown actions */
+ 	int (*init)(struct xgbe_prv_data *);
+ 	void (*exit)(struct xgbe_prv_data *);
+ 
+ 	/* Perform start/stop specific actions */
+ 	int (*reset)(struct xgbe_prv_data *);
+ 	int (*start)(struct xgbe_prv_data *);
+ 	void (*stop)(struct xgbe_prv_data *);
+ 
+ 	/* Return the link status */
+ 	int (*link_status)(struct xgbe_prv_data *);
+ 
+ 	/* Indicate if a particular speed is valid */
+ 	bool (*valid_speed)(struct xgbe_prv_data *, int);
+ 
+ 	/* Check if the specified mode can/should be used */
+ 	bool (*use_mode)(struct xgbe_prv_data *, enum xgbe_mode);
+ 	/* Switch the PHY into various modes */
+ 	void (*set_mode)(struct xgbe_prv_data *, enum xgbe_mode);
+ 	/* Retrieve mode needed for a specific speed */
+ 	enum xgbe_mode (*get_mode)(struct xgbe_prv_data *, int);
+ 	/* Retrieve new/next mode when trying to auto-negotiate */
+ 	enum xgbe_mode (*switch_mode)(struct xgbe_prv_data *);
+ 	/* Retrieve current mode */
+ 	enum xgbe_mode (*cur_mode)(struct xgbe_prv_data *);
+ 
+ 	/* Retrieve current auto-negotiation mode */
+ 	enum xgbe_an_mode (*an_mode)(struct xgbe_prv_data *);
+ 
+ 	/* Process results of auto-negotiation */
+ 	enum xgbe_mode (*an_outcome)(struct xgbe_prv_data *);
+ 
+ 	/* Pre/Post KR training enablement support */
+ 	void (*kr_training_pre)(struct xgbe_prv_data *);
+ 	void (*kr_training_post)(struct xgbe_prv_data *);
+ };
+ 
+ struct xgbe_phy_if {
+ 	/* For PHY setup/teardown */
+ 	int (*phy_init)(struct xgbe_prv_data *);
+ 	void (*phy_exit)(struct xgbe_prv_data *);
+ 
+ 	/* For PHY support when setting device up/down */
+ 	int (*phy_reset)(struct xgbe_prv_data *);
+ 	int (*phy_start)(struct xgbe_prv_data *);
+ 	void (*phy_stop)(struct xgbe_prv_data *);
+ 
+ 	/* For PHY support while device is up */
+ 	void (*phy_status)(struct xgbe_prv_data *);
+ 	int (*phy_config_aneg)(struct xgbe_prv_data *);
+ 
+ 	/* For PHY settings validation */
+ 	bool (*phy_valid_speed)(struct xgbe_prv_data *, int);
+ 
+ 	/* For single interrupt support */
+ 	irqreturn_t (*an_isr)(int, struct xgbe_prv_data *);
+ 
+ 	/* PHY implementation specific services */
+ 	struct xgbe_phy_impl_if phy_impl;
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  };
  
  struct xgbe_desc_if {
@@@ -514,10 -834,30 +692,23 @@@ struct xgbe_hw_features 
  	unsigned int aux_snap_num;	/* Number of Aux snapshot inputs */
  };
  
++<<<<<<< HEAD
++=======
+ struct xgbe_version_data {
+ 	void (*init_function_ptrs_phy_impl)(struct xgbe_phy_if *);
+ 	enum xgbe_xpcs_access xpcs_access;
+ 	unsigned int mmc_64bit;
+ 	unsigned int tx_max_fifo_size;
+ 	unsigned int rx_max_fifo_size;
+ 	unsigned int tx_tstamp_workaround;
+ 	unsigned int ecc_support;
+ };
+ 
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
  struct xgbe_prv_data {
  	struct net_device *netdev;
 -	struct pci_dev *pcidev;
 -	struct platform_device *platdev;
 -	struct acpi_device *adev;
 +	struct platform_device *pdev;
  	struct device *dev;
 -	struct platform_device *phy_platdev;
 -	struct device *phy_dev;
 -
 -	/* Version related data */
 -	struct xgbe_version_data *vdata;
 -
 -	/* ACPI or DT flag */
 -	unsigned int use_acpi;
  
  	/* XGMAC/XPCS related mmio registers */
  	void __iomem *xgmac_regs;	/* XGMAC CSRs */
@@@ -526,12 -871,49 +717,49 @@@
  	/* Overall device lock */
  	spinlock_t lock;
  
 -	/* XPCS indirect addressing lock */
 -	spinlock_t xpcs_lock;
 -	unsigned int xpcs_window;
 -	unsigned int xpcs_window_size;
 -	unsigned int xpcs_window_mask;
 +	/* XPCS indirect addressing mutex */
 +	struct mutex xpcs_mutex;
  
++<<<<<<< HEAD
 +	int irq_number;
++=======
+ 	/* RSS addressing mutex */
+ 	struct mutex rss_mutex;
+ 
+ 	/* Flags representing xgbe_state */
+ 	unsigned long dev_state;
+ 
+ 	/* ECC support */
+ 	unsigned long tx_sec_period;
+ 	unsigned long tx_ded_period;
+ 	unsigned long rx_sec_period;
+ 	unsigned long rx_ded_period;
+ 	unsigned long desc_sec_period;
+ 	unsigned long desc_ded_period;
+ 
+ 	unsigned int tx_sec_count;
+ 	unsigned int tx_ded_count;
+ 	unsigned int rx_sec_count;
+ 	unsigned int rx_ded_count;
+ 	unsigned int desc_ded_count;
+ 	unsigned int desc_sec_count;
+ 
+ 	struct msix_entry *msix_entries;
+ 	int dev_irq;
+ 	int ecc_irq;
+ 	int i2c_irq;
+ 	int channel_irq[XGBE_MAX_DMA_CHANNELS];
+ 
+ 	unsigned int per_channel_irq;
+ 	unsigned int irq_shared;
+ 	unsigned int irq_count;
+ 	unsigned int channel_irq_count;
+ 	unsigned int channel_irq_mode;
++>>>>>>> e78332b2285d (amd-xgbe: Add ECC status support for the device memory)
+ 
+ 	char ecc_name[IFNAMSIZ + 32];
  
  	struct xgbe_hw_if hw_if;
 -	struct xgbe_phy_if phy_if;
  	struct xgbe_desc_if desc_if;
  
  	/* AXI DMA settings */
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-pci.c
* Unmerged path drivers/net/ethernet/amd/Kconfig
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-common.h
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-dev.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-drv.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-main.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-pci.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe.h
