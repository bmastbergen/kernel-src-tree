hugetlbfs: add minimum size accounting to subpools

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Mike Kravetz <mike.kravetz@oracle.com>
commit 1c5ecae3a93fa1ab51a784d77e9c9ed54e67c65f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/1c5ecae3.failed

The same routines that perform subpool maximum size accounting
hugepage_subpool_get/put_pages() are modified to also perform minimum size
accounting.  When a delta value is passed to these routines, calculate how
global reservations must be adjusted to maintain the subpool minimum size.
 The routines now return this global reserve count adjustment.  This
global reserve count adjustment is then passed to the global accounting
routine hugetlb_acct_memory().

	Signed-off-by: Mike Kravetz <mike.kravetz@oracle.com>
	Cc: Davidlohr Bueso <dave@stgolabs.net>
	Cc: Aneesh Kumar <aneesh.kumar@linux.vnet.ibm.com>
	Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
	Cc: Andi Kleen <andi@firstfloor.org>
	Cc: David Rientjes <rientjes@google.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 1c5ecae3a93fa1ab51a784d77e9c9ed54e67c65f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/hugetlb.c
diff --cc mm/hugetlb.c
index 8b12a450c300,499cb72c74b1..000000000000
--- a/mm/hugetlb.c
+++ b/mm/hugetlb.c
@@@ -887,8 -926,15 +940,16 @@@ void free_huge_page(struct page *page
  	restore_reserve = PagePrivate(page);
  	ClearPagePrivate(page);
  
+ 	/*
+ 	 * A return code of zero implies that the subpool will be under its
+ 	 * minimum size if the reservation is not restored after page is free.
+ 	 * Therefore, force restore_reserve operation.
+ 	 */
+ 	if (hugepage_subpool_put_pages(spool, 1) == 0)
+ 		restore_reserve = true;
+ 
  	spin_lock(&hugetlb_lock);
 +	clear_page_huge_active(page);
  	hugetlb_cgroup_uncharge_page(hstate_index(h),
  				     pages_per_huge_page(h), page);
  	if (restore_reserve)
@@@ -2604,25 -2510,28 +2664,42 @@@ static void resv_map_put(struct vm_area
  static void hugetlb_vm_op_close(struct vm_area_struct *vma)
  {
  	struct hstate *h = hstate_vma(vma);
 -	struct resv_map *resv = vma_resv_map(vma);
 +	struct resv_map *reservations = vma_resv_map(vma);
  	struct hugepage_subpool *spool = subpool_vma(vma);
++<<<<<<< HEAD
 +	unsigned long reserve;
 +	unsigned long start;
 +	unsigned long end;
++=======
+ 	unsigned long reserve, start, end;
+ 	long gbl_reserve;
++>>>>>>> 1c5ecae3a93f (hugetlbfs: add minimum size accounting to subpools)
  
 -	if (!resv || !is_vma_resv_set(vma, HPAGE_RESV_OWNER))
 -		return;
 +	if (reservations) {
 +		start = vma_hugecache_offset(h, vma, vma->vm_start);
 +		end = vma_hugecache_offset(h, vma, vma->vm_end);
  
 -	start = vma_hugecache_offset(h, vma, vma->vm_start);
 -	end = vma_hugecache_offset(h, vma, vma->vm_end);
 +		reserve = (end - start) -
 +			region_count(reservations, start, end);
  
 -	reserve = (end - start) - region_count(resv, start, end);
 +		resv_map_put(vma);
  
++<<<<<<< HEAD
 +		if (reserve) {
 +			hugetlb_acct_memory(h, -reserve);
 +			hugepage_subpool_put_pages(spool, reserve);
 +		}
++=======
+ 	kref_put(&resv->refs, resv_map_release);
+ 
+ 	if (reserve) {
+ 		/*
+ 		 * Decrement reserve counts.  The global reserve count may be
+ 		 * adjusted if the subpool has a minimum size.
+ 		 */
+ 		gbl_reserve = hugepage_subpool_put_pages(spool, reserve);
+ 		hugetlb_acct_memory(h, -gbl_reserve);
++>>>>>>> 1c5ecae3a93f (hugetlbfs: add minimum size accounting to subpools)
  	}
  }
  
@@@ -3690,9 -3593,10 +3774,10 @@@ out_err
  void hugetlb_unreserve_pages(struct inode *inode, long offset, long freed)
  {
  	struct hstate *h = hstate_inode(inode);
 -	struct resv_map *resv_map = inode_resv_map(inode);
 +	struct resv_map *resv_map = inode->i_mapping->private_data;
  	long chg = 0;
  	struct hugepage_subpool *spool = subpool_inode(inode);
+ 	long gbl_reserve;
  
  	if (resv_map)
  		chg = region_truncate(resv_map, offset);
* Unmerged path mm/hugetlb.c
