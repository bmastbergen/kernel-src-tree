net/mlx5: Support encap id when setting new steering entry

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [kernel] mlx5: Support encap id when setting new steering entry (Don Dutile) [1385330 1417286]
Rebuild_FUZZ: 96.43%
commit-author Hadar Hen Zion <hadarh@mellanox.com>
commit 66958ed906b87816314c0517f05fe0b5766ec7fe
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/66958ed9.failed

In order to support steering rules which add encapsulation headers,
encap_id parameter is needed.

Add new mlx5_flow_act struct which holds action related parameter:
action, flow_tag and encap_id. Use mlx5_flow_act struct when adding a new
steering rule.
This patch doesn't change any functionality.

	Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 66958ed906b87816314c0517f05fe0b5766ec7fe)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/main.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_arfs.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
#	drivers/net/ethernet/mellanox/mlx5/core/fs_cmd.c
#	drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
#	include/linux/mlx5/fs.h
diff --cc drivers/infiniband/hw/mlx5/main.c
index c59be3674778,76ed57f1b678..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -1860,12 -1877,10 +1860,19 @@@ static struct mlx5_ib_flow_handler *cre
  {
  	struct mlx5_flow_table	*ft = ft_prio->flow_table;
  	struct mlx5_ib_flow_handler *handler;
++<<<<<<< HEAD
 +	void *ib_flow = flow_attr + 1;
 +	u8 match_criteria_enable = 0;
 +	unsigned int spec_index;
 +	u32 *match_c;
 +	u32 *match_v;
 +	u32 action;
++=======
+ 	struct mlx5_flow_act flow_act = {0};
+ 	struct mlx5_flow_spec *spec;
+ 	const void *ib_flow = (const void *)flow_attr + sizeof(*flow_attr);
+ 	unsigned int spec_index;
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  	int err = 0;
  
  	if (!is_valid_attr(flow_attr))
@@@ -1889,15 -1904,13 +1896,25 @@@
  		ib_flow += ((union ib_flow_spec *)ib_flow)->size;
  	}
  
++<<<<<<< HEAD
 +	/* Outer header support only */
 +	match_criteria_enable = (!outer_header_zero(match_c)) << 0;
 +	action = dst ? MLX5_FLOW_CONTEXT_ACTION_FWD_DEST :
 +		MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO;
 +	handler->rule = mlx5_add_flow_rule(ft, match_criteria_enable,
 +					   match_c, match_v,
 +					   action,
 +					   MLX5_FS_DEFAULT_FLOW_TAG,
 +					   dst);
++=======
+ 	spec->match_criteria_enable = get_match_criteria_enable(spec->match_criteria);
+ 	flow_act.action = dst ? MLX5_FLOW_CONTEXT_ACTION_FWD_DEST :
+ 		MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO;
+ 	flow_act.flow_tag = MLX5_FS_DEFAULT_FLOW_TAG;
+ 	handler->rule = mlx5_add_flow_rules(ft, spec,
+ 					    &flow_act,
+ 					    dst, 1);
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  
  	if (IS_ERR(handler->rule)) {
  		err = PTR_ERR(handler->rule);
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
index 4df49e660587,1fe80de5d68f..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
@@@ -512,12 -156,16 +512,21 @@@ enum mlx5e_vlan_rule_type 
  
  static int __mlx5e_add_vlan_rule(struct mlx5e_priv *priv,
  				 enum mlx5e_vlan_rule_type rule_type,
 -				 u16 vid, struct mlx5_flow_spec *spec)
 +				 u16 vid, u32 *mc, u32 *mv)
  {
++<<<<<<< HEAD
 +	struct mlx5_flow_table *ft = priv->fts.vlan.t;
++=======
+ 	struct mlx5_flow_act flow_act = {
+ 		.action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 		.flow_tag = MLX5_FS_DEFAULT_FLOW_TAG,
+ 		.encap_id = 0,
+ 	};
+ 	struct mlx5_flow_table *ft = priv->fs.vlan.ft.t;
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  	struct mlx5_flow_destination dest;
 -	struct mlx5_flow_handle **rule_p;
 +	u8 match_criteria_enable = 0;
 +	struct mlx5_flow_rule **rule_p;
  	int err = 0;
  
  	dest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
@@@ -542,10 -192,7 +551,14 @@@
  		break;
  	}
  
++<<<<<<< HEAD
 +	*rule_p = mlx5_add_flow_rule(ft, match_criteria_enable, mc, mv,
 +				     MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
 +				     MLX5_FS_DEFAULT_FLOW_TAG,
 +				     &dest);
++=======
+ 	*rule_p = mlx5_add_flow_rules(ft, spec, &flow_act, &dest, 1);
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  
  	if (IS_ERR(*rule_p)) {
  		err = PTR_ERR(*rule_p);
@@@ -1077,9 -556,424 +1090,428 @@@ static void mlx5e_destroy_flow_table(st
  	ft->t = NULL;
  }
  
 -static void mlx5e_cleanup_ttc_rules(struct mlx5e_ttc_table *ttc)
 +static void mlx5e_destroy_main_flow_table(struct mlx5e_priv *priv)
  {
++<<<<<<< HEAD
 +	mlx5e_destroy_flow_table(&priv->fts.main);
++=======
+ 	int i;
+ 
+ 	for (i = 0; i < MLX5E_NUM_TT; i++) {
+ 		if (!IS_ERR_OR_NULL(ttc->rules[i])) {
+ 			mlx5_del_flow_rules(ttc->rules[i]);
+ 			ttc->rules[i] = NULL;
+ 		}
+ 	}
+ }
+ 
+ static struct {
+ 	u16 etype;
+ 	u8 proto;
+ } ttc_rules[] = {
+ 	[MLX5E_TT_IPV4_TCP] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = IPPROTO_TCP,
+ 	},
+ 	[MLX5E_TT_IPV6_TCP] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = IPPROTO_TCP,
+ 	},
+ 	[MLX5E_TT_IPV4_UDP] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = IPPROTO_UDP,
+ 	},
+ 	[MLX5E_TT_IPV6_UDP] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = IPPROTO_UDP,
+ 	},
+ 	[MLX5E_TT_IPV4_IPSEC_AH] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = IPPROTO_AH,
+ 	},
+ 	[MLX5E_TT_IPV6_IPSEC_AH] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = IPPROTO_AH,
+ 	},
+ 	[MLX5E_TT_IPV4_IPSEC_ESP] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = IPPROTO_ESP,
+ 	},
+ 	[MLX5E_TT_IPV6_IPSEC_ESP] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = IPPROTO_ESP,
+ 	},
+ 	[MLX5E_TT_IPV4] = {
+ 		.etype = ETH_P_IP,
+ 		.proto = 0,
+ 	},
+ 	[MLX5E_TT_IPV6] = {
+ 		.etype = ETH_P_IPV6,
+ 		.proto = 0,
+ 	},
+ 	[MLX5E_TT_ANY] = {
+ 		.etype = 0,
+ 		.proto = 0,
+ 	},
+ };
+ 
+ static struct mlx5_flow_handle *
+ mlx5e_generate_ttc_rule(struct mlx5e_priv *priv,
+ 			struct mlx5_flow_table *ft,
+ 			struct mlx5_flow_destination *dest,
+ 			u16 etype,
+ 			u8 proto)
+ {
+ 	struct mlx5_flow_act flow_act = {
+ 		.action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 		.flow_tag = MLX5_FS_DEFAULT_FLOW_TAG,
+ 		.encap_id = 0,
+ 	};
+ 	struct mlx5_flow_handle *rule;
+ 	struct mlx5_flow_spec *spec;
+ 	int err = 0;
+ 
+ 	spec = mlx5_vzalloc(sizeof(*spec));
+ 	if (!spec) {
+ 		netdev_err(priv->netdev, "%s: alloc failed\n", __func__);
+ 		return ERR_PTR(-ENOMEM);
+ 	}
+ 
+ 	if (proto) {
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.ip_protocol);
+ 		MLX5_SET(fte_match_param, spec->match_value, outer_headers.ip_protocol, proto);
+ 	}
+ 	if (etype) {
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.ethertype);
+ 		MLX5_SET(fte_match_param, spec->match_value, outer_headers.ethertype, etype);
+ 	}
+ 
+ 	rule = mlx5_add_flow_rules(ft, spec, &flow_act, dest, 1);
+ 	if (IS_ERR(rule)) {
+ 		err = PTR_ERR(rule);
+ 		netdev_err(priv->netdev, "%s: add rule failed\n", __func__);
+ 	}
+ 
+ 	kvfree(spec);
+ 	return err ? ERR_PTR(err) : rule;
+ }
+ 
+ static int mlx5e_generate_ttc_table_rules(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5_flow_destination dest;
+ 	struct mlx5e_ttc_table *ttc;
+ 	struct mlx5_flow_handle **rules;
+ 	struct mlx5_flow_table *ft;
+ 	int tt;
+ 	int err;
+ 
+ 	ttc = &priv->fs.ttc;
+ 	ft = ttc->ft.t;
+ 	rules = ttc->rules;
+ 
+ 	dest.type = MLX5_FLOW_DESTINATION_TYPE_TIR;
+ 	for (tt = 0; tt < MLX5E_NUM_TT; tt++) {
+ 		if (tt == MLX5E_TT_ANY)
+ 			dest.tir_num = priv->direct_tir[0].tirn;
+ 		else
+ 			dest.tir_num = priv->indir_tir[tt].tirn;
+ 		rules[tt] = mlx5e_generate_ttc_rule(priv, ft, &dest,
+ 						    ttc_rules[tt].etype,
+ 						    ttc_rules[tt].proto);
+ 		if (IS_ERR(rules[tt]))
+ 			goto del_rules;
+ 	}
+ 
+ 	return 0;
+ 
+ del_rules:
+ 	err = PTR_ERR(rules[tt]);
+ 	rules[tt] = NULL;
+ 	mlx5e_cleanup_ttc_rules(ttc);
+ 	return err;
+ }
+ 
+ #define MLX5E_TTC_NUM_GROUPS	3
+ #define MLX5E_TTC_GROUP1_SIZE	BIT(3)
+ #define MLX5E_TTC_GROUP2_SIZE	BIT(1)
+ #define MLX5E_TTC_GROUP3_SIZE	BIT(0)
+ #define MLX5E_TTC_TABLE_SIZE	(MLX5E_TTC_GROUP1_SIZE +\
+ 				 MLX5E_TTC_GROUP2_SIZE +\
+ 				 MLX5E_TTC_GROUP3_SIZE)
+ static int mlx5e_create_ttc_table_groups(struct mlx5e_ttc_table *ttc)
+ {
+ 	int inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);
+ 	struct mlx5e_flow_table *ft = &ttc->ft;
+ 	int ix = 0;
+ 	u32 *in;
+ 	int err;
+ 	u8 *mc;
+ 
+ 	ft->g = kcalloc(MLX5E_TTC_NUM_GROUPS,
+ 			sizeof(*ft->g), GFP_KERNEL);
+ 	if (!ft->g)
+ 		return -ENOMEM;
+ 	in = mlx5_vzalloc(inlen);
+ 	if (!in) {
+ 		kfree(ft->g);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	/* L4 Group */
+ 	mc = MLX5_ADDR_OF(create_flow_group_in, in, match_criteria);
+ 	MLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.ip_protocol);
+ 	MLX5_SET_TO_ONES(fte_match_param, mc, outer_headers.ethertype);
+ 	MLX5_SET_CFG(in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_TTC_GROUP1_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err;
+ 	ft->num_groups++;
+ 
+ 	/* L3 Group */
+ 	MLX5_SET(fte_match_param, mc, outer_headers.ip_protocol, 0);
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_TTC_GROUP2_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err;
+ 	ft->num_groups++;
+ 
+ 	/* Any Group */
+ 	memset(in, 0, inlen);
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_TTC_GROUP3_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err;
+ 	ft->num_groups++;
+ 
+ 	kvfree(in);
+ 	return 0;
+ 
+ err:
+ 	err = PTR_ERR(ft->g[ft->num_groups]);
+ 	ft->g[ft->num_groups] = NULL;
+ 	kvfree(in);
+ 
+ 	return err;
+ }
+ 
+ static void mlx5e_destroy_ttc_table(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_ttc_table *ttc = &priv->fs.ttc;
+ 
+ 	mlx5e_cleanup_ttc_rules(ttc);
+ 	mlx5e_destroy_flow_table(&ttc->ft);
+ }
+ 
+ static int mlx5e_create_ttc_table(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_ttc_table *ttc = &priv->fs.ttc;
+ 	struct mlx5e_flow_table *ft = &ttc->ft;
+ 	int err;
+ 
+ 	ft->t = mlx5_create_flow_table(priv->fs.ns, MLX5E_NIC_PRIO,
+ 				       MLX5E_TTC_TABLE_SIZE, MLX5E_TTC_FT_LEVEL, 0);
+ 	if (IS_ERR(ft->t)) {
+ 		err = PTR_ERR(ft->t);
+ 		ft->t = NULL;
+ 		return err;
+ 	}
+ 
+ 	err = mlx5e_create_ttc_table_groups(ttc);
+ 	if (err)
+ 		goto err;
+ 
+ 	err = mlx5e_generate_ttc_table_rules(priv);
+ 	if (err)
+ 		goto err;
+ 
+ 	return 0;
+ err:
+ 	mlx5e_destroy_flow_table(ft);
+ 	return err;
+ }
+ 
+ static void mlx5e_del_l2_flow_rule(struct mlx5e_priv *priv,
+ 				   struct mlx5e_l2_rule *ai)
+ {
+ 	if (!IS_ERR_OR_NULL(ai->rule)) {
+ 		mlx5_del_flow_rules(ai->rule);
+ 		ai->rule = NULL;
+ 	}
+ }
+ 
+ static int mlx5e_add_l2_flow_rule(struct mlx5e_priv *priv,
+ 				  struct mlx5e_l2_rule *ai, int type)
+ {
+ 	struct mlx5_flow_act flow_act = {
+ 		.action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
+ 		.flow_tag = MLX5_FS_DEFAULT_FLOW_TAG,
+ 		.encap_id = 0,
+ 	};
+ 	struct mlx5_flow_table *ft = priv->fs.l2.ft.t;
+ 	struct mlx5_flow_destination dest;
+ 	struct mlx5_flow_spec *spec;
+ 	int err = 0;
+ 	u8 *mc_dmac;
+ 	u8 *mv_dmac;
+ 
+ 	spec = mlx5_vzalloc(sizeof(*spec));
+ 	if (!spec) {
+ 		netdev_err(priv->netdev, "%s: alloc failed\n", __func__);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	mc_dmac = MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
+ 			       outer_headers.dmac_47_16);
+ 	mv_dmac = MLX5_ADDR_OF(fte_match_param, spec->match_value,
+ 			       outer_headers.dmac_47_16);
+ 
+ 	dest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
+ 	dest.ft = priv->fs.ttc.ft.t;
+ 
+ 	switch (type) {
+ 	case MLX5E_FULLMATCH:
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 		eth_broadcast_addr(mc_dmac);
+ 		ether_addr_copy(mv_dmac, ai->addr);
+ 		break;
+ 
+ 	case MLX5E_ALLMULTI:
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 		mc_dmac[0] = 0x01;
+ 		mv_dmac[0] = 0x01;
+ 		break;
+ 
+ 	case MLX5E_PROMISC:
+ 		break;
+ 	}
+ 
+ 	ai->rule = mlx5_add_flow_rules(ft, spec, &flow_act, &dest, 1);
+ 	if (IS_ERR(ai->rule)) {
+ 		netdev_err(priv->netdev, "%s: add l2 rule(mac:%pM) failed\n",
+ 			   __func__, mv_dmac);
+ 		err = PTR_ERR(ai->rule);
+ 		ai->rule = NULL;
+ 	}
+ 
+ 	kvfree(spec);
+ 
+ 	return err;
+ }
+ 
+ #define MLX5E_NUM_L2_GROUPS	   3
+ #define MLX5E_L2_GROUP1_SIZE	   BIT(0)
+ #define MLX5E_L2_GROUP2_SIZE	   BIT(15)
+ #define MLX5E_L2_GROUP3_SIZE	   BIT(0)
+ #define MLX5E_L2_TABLE_SIZE	   (MLX5E_L2_GROUP1_SIZE +\
+ 				    MLX5E_L2_GROUP2_SIZE +\
+ 				    MLX5E_L2_GROUP3_SIZE)
+ static int mlx5e_create_l2_table_groups(struct mlx5e_l2_table *l2_table)
+ {
+ 	int inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);
+ 	struct mlx5e_flow_table *ft = &l2_table->ft;
+ 	int ix = 0;
+ 	u8 *mc_dmac;
+ 	u32 *in;
+ 	int err;
+ 	u8 *mc;
+ 
+ 	ft->g = kcalloc(MLX5E_NUM_L2_GROUPS, sizeof(*ft->g), GFP_KERNEL);
+ 	if (!ft->g)
+ 		return -ENOMEM;
+ 	in = mlx5_vzalloc(inlen);
+ 	if (!in) {
+ 		kfree(ft->g);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	mc = MLX5_ADDR_OF(create_flow_group_in, in, match_criteria);
+ 	mc_dmac = MLX5_ADDR_OF(fte_match_param, mc,
+ 			       outer_headers.dmac_47_16);
+ 	/* Flow Group for promiscuous */
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_L2_GROUP1_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err_destroy_groups;
+ 	ft->num_groups++;
+ 
+ 	/* Flow Group for full match */
+ 	eth_broadcast_addr(mc_dmac);
+ 	MLX5_SET_CFG(in, match_criteria_enable, MLX5_MATCH_OUTER_HEADERS);
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_L2_GROUP2_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err_destroy_groups;
+ 	ft->num_groups++;
+ 
+ 	/* Flow Group for allmulti */
+ 	eth_zero_addr(mc_dmac);
+ 	mc_dmac[0] = 0x01;
+ 	MLX5_SET_CFG(in, start_flow_index, ix);
+ 	ix += MLX5E_L2_GROUP3_SIZE;
+ 	MLX5_SET_CFG(in, end_flow_index, ix - 1);
+ 	ft->g[ft->num_groups] = mlx5_create_flow_group(ft->t, in);
+ 	if (IS_ERR(ft->g[ft->num_groups]))
+ 		goto err_destroy_groups;
+ 	ft->num_groups++;
+ 
+ 	kvfree(in);
+ 	return 0;
+ 
+ err_destroy_groups:
+ 	err = PTR_ERR(ft->g[ft->num_groups]);
+ 	ft->g[ft->num_groups] = NULL;
+ 	mlx5e_destroy_groups(ft);
+ 	kvfree(in);
+ 
+ 	return err;
+ }
+ 
+ static void mlx5e_destroy_l2_table(struct mlx5e_priv *priv)
+ {
+ 	mlx5e_destroy_flow_table(&priv->fs.l2.ft);
+ }
+ 
+ static int mlx5e_create_l2_table(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_l2_table *l2_table = &priv->fs.l2;
+ 	struct mlx5e_flow_table *ft = &l2_table->ft;
+ 	int err;
+ 
+ 	ft->num_groups = 0;
+ 	ft->t = mlx5_create_flow_table(priv->fs.ns, MLX5E_NIC_PRIO,
+ 				       MLX5E_L2_TABLE_SIZE, MLX5E_L2_FT_LEVEL, 0);
+ 
+ 	if (IS_ERR(ft->t)) {
+ 		err = PTR_ERR(ft->t);
+ 		ft->t = NULL;
+ 		return err;
+ 	}
+ 
+ 	err = mlx5e_create_l2_table_groups(l2_table);
+ 	if (err)
+ 		goto err_destroy_flow_table;
+ 
+ 	return 0;
+ 
+ err_destroy_flow_table:
+ 	mlx5_destroy_flow_table(ft->t);
+ 	ft->t = NULL;
+ 
+ 	return err;
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  }
  
  #define MLX5E_NUM_VLAN_GROUPS	2
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
index 6c7352099dd6,ae05d27832e4..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@@ -328,26 -243,29 +328,31 @@@ __esw_fdb_set_vport_rule(struct mlx5_es
  {
  	int match_header = (is_zero_ether_addr(mac_c) ? 0 :
  			    MLX5_MATCH_OUTER_HEADERS);
++<<<<<<< HEAD
 +	struct mlx5_flow_rule *flow_rule = NULL;
++=======
+ 	struct mlx5_flow_handle *flow_rule = NULL;
+ 	struct mlx5_flow_act flow_act = {0};
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  	struct mlx5_flow_destination dest;
 -	struct mlx5_flow_spec *spec;
 -	void *mv_misc = NULL;
 -	void *mc_misc = NULL;
  	u8 *dmac_v = NULL;
  	u8 *dmac_c = NULL;
 +	u32 *match_v;
 +	u32 *match_c;
  
 -	if (rx_rule)
 -		match_header |= MLX5_MATCH_MISC_PARAMETERS;
 -
 -	spec = mlx5_vzalloc(sizeof(*spec));
 -	if (!spec) {
 -		esw_warn(esw->dev, "FDB: Failed to alloc match parameters\n");
 -		return NULL;
 +	match_v = kzalloc(MLX5_ST_SZ_BYTES(fte_match_param), GFP_KERNEL);
 +	match_c = kzalloc(MLX5_ST_SZ_BYTES(fte_match_param), GFP_KERNEL);
 +	if (!match_v || !match_c) {
 +		pr_warn("FDB: Failed to alloc match parameters\n");
 +		goto out;
  	}
 -	dmac_v = MLX5_ADDR_OF(fte_match_param, spec->match_value,
 +
 +	dmac_v = MLX5_ADDR_OF(fte_match_param, match_v,
  			      outer_headers.dmac_47_16);
 -	dmac_c = MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 +	dmac_c = MLX5_ADDR_OF(fte_match_param, match_c,
  			      outer_headers.dmac_47_16);
  
 -	if (match_header & MLX5_MATCH_OUTER_HEADERS) {
 +	if (match_header == MLX5_MATCH_OUTER_HEADERS) {
  		ether_addr_copy(dmac_v, mac_v);
  		ether_addr_copy(dmac_c, mac_c);
  	}
@@@ -358,16 -285,14 +363,27 @@@
  	esw_debug(esw->dev,
  		  "\tFDB add rule dmac_v(%pM) dmac_c(%pM) -> vport(%d)\n",
  		  dmac_v, dmac_c, vport);
++<<<<<<< HEAD
 +	flow_rule =
 +		mlx5_add_flow_rule(esw->fdb_table.fdb,
 +				   match_header,
 +				   match_c,
 +				   match_v,
 +				   MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
 +				   0, &dest);
 +	if (IS_ERR_OR_NULL(flow_rule)) {
 +		pr_warn(
 +			"FDB: Failed to add flow rule: dmac_v(%pM) dmac_c(%pM) -> vport(%d), err(%ld)\n",
++=======
+ 	spec->match_criteria_enable = match_header;
+ 	flow_act.action =  MLX5_FLOW_CONTEXT_ACTION_FWD_DEST;
+ 	flow_rule =
+ 		mlx5_add_flow_rules(esw->fdb_table.fdb, spec,
+ 				    &flow_act, &dest, 1);
+ 	if (IS_ERR(flow_rule)) {
+ 		esw_warn(esw->dev,
+ 			 "FDB: Failed to add flow rule: dmac_v(%pM) dmac_c(%pM) -> vport(%d), err(%ld)\n",
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  			 dmac_v, dmac_c, vport, PTR_ERR(flow_rule));
  		flow_rule = NULL;
  	}
@@@ -1044,15 -1213,17 +1060,20 @@@ static void esw_vport_disable_ingress_a
  static int esw_vport_ingress_config(struct mlx5_eswitch *esw,
  				    struct mlx5_vport *vport)
  {
++<<<<<<< HEAD
 +	u32 *match_v;
 +	u32 *match_c;
++=======
+ 	struct mlx5_flow_act flow_act = {0};
+ 	struct mlx5_flow_spec *spec;
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  	int err = 0;
 -	u8 *smac_v;
  
 -	if (vport->info.spoofchk && !is_valid_ether_addr(vport->info.mac)) {
 -		mlx5_core_warn(esw->dev,
 -			       "vport[%d] configure ingress rules failed, illegal mac with spoofchk\n",
 -			       vport->vport);
 +	if (IS_ERR_OR_NULL(vport->ingress.acl)) {
 +		esw_warn(esw->dev,
 +			 "vport[%d] configure ingress rules failed, ingress acl is not initialized!\n",
 +			 vport->vport);
  		return -EPERM;
 -
  	}
  
  	esw_vport_cleanup_ingress_rules(esw, vport);
@@@ -1072,45 -1252,75 +1093,85 @@@
  			 vport->vport, err);
  		goto out;
  	}
 +	MLX5_SET_TO_ONES(fte_match_param, match_c, outer_headers.vlan_tag);
 +	MLX5_SET_TO_ONES(fte_match_param, match_v, outer_headers.vlan_tag);
  
++<<<<<<< HEAD
 +	vport->ingress.drop_rule =
 +		mlx5_add_flow_rule(vport->ingress.acl,
 +				   MLX5_MATCH_OUTER_HEADERS,
 +				   match_c,
 +				   match_v,
 +				   MLX5_FLOW_CONTEXT_ACTION_DROP,
 +				   0, NULL);
 +	if (IS_ERR_OR_NULL(vport->ingress.drop_rule)) {
++=======
+ 	if (vport->info.vlan || vport->info.qos)
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.vlan_tag);
+ 
+ 	if (vport->info.spoofchk) {
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.smac_47_16);
+ 		MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.smac_15_0);
+ 		smac_v = MLX5_ADDR_OF(fte_match_param,
+ 				      spec->match_value,
+ 				      outer_headers.smac_47_16);
+ 		ether_addr_copy(smac_v, vport->info.mac);
+ 	}
+ 
+ 	spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 	flow_act.action = MLX5_FLOW_CONTEXT_ACTION_ALLOW;
+ 	vport->ingress.allow_rule =
+ 		mlx5_add_flow_rules(vport->ingress.acl, spec,
+ 				    &flow_act, NULL, 0);
+ 	if (IS_ERR(vport->ingress.allow_rule)) {
+ 		err = PTR_ERR(vport->ingress.allow_rule);
+ 		esw_warn(esw->dev,
+ 			 "vport[%d] configure ingress allow rule, err(%d)\n",
+ 			 vport->vport, err);
+ 		vport->ingress.allow_rule = NULL;
+ 		goto out;
+ 	}
+ 
+ 	memset(spec, 0, sizeof(*spec));
+ 	flow_act.action = MLX5_FLOW_CONTEXT_ACTION_DROP;
+ 	vport->ingress.drop_rule =
+ 		mlx5_add_flow_rules(vport->ingress.acl, spec,
+ 				    &flow_act, NULL, 0);
+ 	if (IS_ERR(vport->ingress.drop_rule)) {
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  		err = PTR_ERR(vport->ingress.drop_rule);
 -		esw_warn(esw->dev,
 -			 "vport[%d] configure ingress drop rule, err(%d)\n",
 -			 vport->vport, err);
 +		pr_warn("vport[%d] configure ingress rules, err(%d)\n",
 +			vport->vport, err);
  		vport->ingress.drop_rule = NULL;
 -		goto out;
  	}
 -
  out:
 -	if (err)
 -		esw_vport_cleanup_ingress_rules(esw, vport);
 -	kvfree(spec);
 +	kfree(match_v);
 +	kfree(match_c);
  	return err;
  }
  
  static int esw_vport_egress_config(struct mlx5_eswitch *esw,
  				   struct mlx5_vport *vport)
  {
++<<<<<<< HEAD
 +	u32 *match_v;
 +	u32 *match_c;
++=======
+ 	struct mlx5_flow_act flow_act = {0};
+ 	struct mlx5_flow_spec *spec;
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  	int err = 0;
  
 +	if (IS_ERR_OR_NULL(vport->egress.acl)) {
 +		esw_warn(esw->dev, "vport[%d] configure rgress rules failed, egress acl is not initialized!\n",
 +			 vport->vport);
 +		return -EPERM;
 +	}
 +
  	esw_vport_cleanup_egress_rules(esw, vport);
  
 -	if (!vport->info.vlan && !vport->info.qos) {
 -		esw_vport_disable_egress_acl(esw, vport);
 +	if (!vport->vlan && !vport->qos)
  		return 0;
 -	}
 -
 -	err = esw_vport_enable_egress_acl(esw, vport);
 -	if (err) {
 -		mlx5_core_warn(esw->dev,
 -			       "failed to enable egress acl (%d) on vport[%d]\n",
 -			       err, vport->vport);
 -		return err;
 -	}
  
  	esw_debug(esw->dev,
  		  "vport[%d] configure egress rules, vlan(%d) qos(%d)\n",
@@@ -1126,40 -1335,36 +1187,58 @@@
  	}
  
  	/* Allowed vlan rule */
 -	MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.vlan_tag);
 -	MLX5_SET_TO_ONES(fte_match_param, spec->match_value, outer_headers.vlan_tag);
 -	MLX5_SET_TO_ONES(fte_match_param, spec->match_criteria, outer_headers.first_vid);
 -	MLX5_SET(fte_match_param, spec->match_value, outer_headers.first_vid, vport->info.vlan);
 +	MLX5_SET_TO_ONES(fte_match_param, match_c, outer_headers.vlan_tag);
 +	MLX5_SET_TO_ONES(fte_match_param, match_v, outer_headers.vlan_tag);
 +	MLX5_SET_TO_ONES(fte_match_param, match_c, outer_headers.first_vid);
 +	MLX5_SET(fte_match_param, match_v, outer_headers.first_vid, vport->vlan);
  
++<<<<<<< HEAD
 +	vport->egress.allowed_vlan =
 +		mlx5_add_flow_rule(vport->egress.acl,
 +				   MLX5_MATCH_OUTER_HEADERS,
 +				   match_c,
 +				   match_v,
 +				   MLX5_FLOW_CONTEXT_ACTION_ALLOW,
 +				   0, NULL);
 +	if (IS_ERR_OR_NULL(vport->egress.allowed_vlan)) {
++=======
+ 	spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS;
+ 	flow_act.action = MLX5_FLOW_CONTEXT_ACTION_ALLOW;
+ 	vport->egress.allowed_vlan =
+ 		mlx5_add_flow_rules(vport->egress.acl, spec,
+ 				    &flow_act, NULL, 0);
+ 	if (IS_ERR(vport->egress.allowed_vlan)) {
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  		err = PTR_ERR(vport->egress.allowed_vlan);
 -		esw_warn(esw->dev,
 -			 "vport[%d] configure egress allowed vlan rule failed, err(%d)\n",
 -			 vport->vport, err);
 +		pr_warn("vport[%d] configure egress allowed vlan rule failed, err(%d)\n",
 +			vport->vport, err);
  		vport->egress.allowed_vlan = NULL;
  		goto out;
  	}
  
  	/* Drop others rule (star rule) */
++<<<<<<< HEAD
 +	memset(match_c, 0, MLX5_ST_SZ_BYTES(fte_match_param));
 +	memset(match_v, 0, MLX5_ST_SZ_BYTES(fte_match_param));
 +	vport->egress.drop_rule =
 +		mlx5_add_flow_rule(vport->egress.acl,
 +				   0,
 +				   match_c,
 +				   match_v,
 +				   MLX5_FLOW_CONTEXT_ACTION_DROP,
 +				   0, NULL);
 +	if (IS_ERR_OR_NULL(vport->egress.drop_rule)) {
++=======
+ 	memset(spec, 0, sizeof(*spec));
+ 	flow_act.action = MLX5_FLOW_CONTEXT_ACTION_DROP;
+ 	vport->egress.drop_rule =
+ 		mlx5_add_flow_rules(vport->egress.acl, spec,
+ 				    &flow_act, NULL, 0);
+ 	if (IS_ERR(vport->egress.drop_rule)) {
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  		err = PTR_ERR(vport->egress.drop_rule);
 -		esw_warn(esw->dev,
 -			 "vport[%d] configure egress drop rule failed, err(%d)\n",
 -			 vport->vport, err);
 +		pr_warn("vport[%d] configure egress drop rule failed, err(%d)\n",
 +			vport->vport, err);
  		vport->egress.drop_rule = NULL;
  	}
  out:
diff --cc drivers/net/ethernet/mellanox/mlx5/core/fs_cmd.c
index 9255fb6f5d9d,c4478ecd8056..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_cmd.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_cmd.c
@@@ -212,8 -248,7 +212,12 @@@ static int mlx5_cmd_set_fte(struct mlx5
  	MLX5_SET(flow_context, in_flow_context, group_id, group_id);
  	MLX5_SET(flow_context, in_flow_context, flow_tag, fte->flow_tag);
  	MLX5_SET(flow_context, in_flow_context, action, fte->action);
++<<<<<<< HEAD
 +	MLX5_SET(flow_context, in_flow_context, destination_list_size,
 +		 fte->dests_size);
++=======
+ 	MLX5_SET(flow_context, in_flow_context, encap_id, fte->encap_id);
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  	in_match_value = MLX5_ADDR_OF(flow_context, in_flow_context,
  				      match_value);
  	memcpy(in_match_value, &fte->val, MLX5_ST_SZ_BYTES(fte_match_param));
diff --cc drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
index de1cde8dc012,9adc766c7a3f..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
@@@ -435,12 -456,11 +435,11 @@@ static void del_flow_group(struct fs_no
  		ft->autogroup.num_groups--;
  
  	if (mlx5_cmd_destroy_flow_group(dev, ft, fg->id))
 -		mlx5_core_warn(dev, "flow steering can't destroy fg %d of ft %d\n",
 -			       fg->id, ft->id);
 +		pr_warn("flow steering can't destroy fg %d of ft %d\n",
 +			fg->id, ft->id);
  }
  
- static struct fs_fte *alloc_fte(u8 action,
- 				u32 flow_tag,
+ static struct fs_fte *alloc_fte(struct mlx5_flow_act *flow_act,
  				u32 *match_value,
  				unsigned int index)
  {
@@@ -1035,35 -1216,30 +1034,51 @@@ static struct mlx5_flow_rule *find_flow
  	return NULL;
  }
  
++<<<<<<< HEAD
 +static struct mlx5_flow_rule *add_rule_fg(struct mlx5_flow_group *fg,
 +					  u32 *match_value,
 +					  u8 action,
 +					  u32 flow_tag,
 +					  struct mlx5_flow_destination *dest)
++=======
+ static struct mlx5_flow_handle *add_rule_fg(struct mlx5_flow_group *fg,
+ 					    u32 *match_value,
+ 					    struct mlx5_flow_act *flow_act,
+ 					    struct mlx5_flow_destination *dest,
+ 					    int dest_num)
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  {
 -	struct mlx5_flow_handle *handle;
 +	struct fs_fte *fte;
 +	struct mlx5_flow_rule *rule;
  	struct mlx5_flow_table *ft;
  	struct list_head *prev;
 -	struct fs_fte *fte;
 -	int i;
  
  	nested_lock_ref_node(&fg->node, FS_MUTEX_PARENT);
  	fs_for_each_fte(fte, fg) {
  		nested_lock_ref_node(&fte->node, FS_MUTEX_CHILD);
  		if (compare_match_value(&fg->mask, match_value, &fte->val) &&
- 		    (action & fte->action) && flow_tag == fte->flow_tag) {
+ 		    (flow_act->action & fte->action) &&
+ 		    flow_act->flow_tag == fte->flow_tag) {
  			int old_action = fte->action;
  
++<<<<<<< HEAD
 +			rule = find_flow_rule(fte, dest);
 +			if (rule) {
 +				atomic_inc(&rule->node.refcount);
 +				unlock_ref_node(&fte->node);
 +				unlock_ref_node(&fg->node);
 +				return rule;
 +			}
 +			fte->action |= action;
 +			rule = add_rule_fte(fte, fg, dest,
 +					    old_action != action);
 +			if (IS_ERR(rule)) {
++=======
+ 			fte->action |= flow_act->action;
+ 			handle = add_rule_fte(fte, fg, dest, dest_num,
+ 					      old_action != flow_act->action);
+ 			if (IS_ERR(handle)) {
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  				fte->action = old_action;
  				goto unlock_fte;
  			} else {
@@@ -1078,9 -1254,9 +1093,9 @@@
  		goto unlock_fg;
  	}
  
- 	fte = create_fte(fg, match_value, action, flow_tag, &prev);
+ 	fte = create_fte(fg, match_value, flow_act, &prev);
  	if (IS_ERR(fte)) {
 -		handle = (void *)fte;
 +		rule = (void *)fte;
  		goto unlock_fg;
  	}
  	tree_init_node(&fte->node, 0, del_fte);
@@@ -1101,32 -1280,79 +1116,100 @@@ unlock_fte
  	unlock_ref_node(&fte->node);
  unlock_fg:
  	unlock_ref_node(&fg->node);
 -	return handle;
 +	return rule;
  }
  
++<<<<<<< HEAD
 +static struct mlx5_flow_rule *
 +_mlx5_add_flow_rule(struct mlx5_flow_table *ft,
 +		    u8 match_criteria_enable,
 +		    u32 *match_criteria,
 +		    u32 *match_value,
 +		    u32 action,
 +		    u32 flow_tag,
 +		    struct mlx5_flow_destination *dest)
++=======
+ struct mlx5_fc *mlx5_flow_rule_counter(struct mlx5_flow_handle *handle)
+ {
+ 	struct mlx5_flow_rule *dst;
+ 	struct fs_fte *fte;
+ 
+ 	fs_get_obj(fte, handle->rule[0]->node.parent);
+ 
+ 	fs_for_each_dst(dst, fte) {
+ 		if (dst->dest_attr.type == MLX5_FLOW_DESTINATION_TYPE_COUNTER)
+ 			return dst->dest_attr.counter;
+ 	}
+ 
+ 	return NULL;
+ }
+ 
+ static bool counter_is_valid(struct mlx5_fc *counter, u32 action)
+ {
+ 	if (!(action & MLX5_FLOW_CONTEXT_ACTION_COUNT))
+ 		return !counter;
+ 
+ 	if (!counter)
+ 		return false;
+ 
+ 	return (action & (MLX5_FLOW_CONTEXT_ACTION_DROP |
+ 			  MLX5_FLOW_CONTEXT_ACTION_FWD_DEST)) &&
+ 		(action & MLX5_FLOW_CONTEXT_ACTION_COUNT);
+ }
+ 
+ static bool dest_is_valid(struct mlx5_flow_destination *dest,
+ 			  u32 action,
+ 			  struct mlx5_flow_table *ft)
+ {
+ 	if (dest && (dest->type == MLX5_FLOW_DESTINATION_TYPE_COUNTER))
+ 		return counter_is_valid(dest->counter, action);
+ 
+ 	if (!(action & MLX5_FLOW_CONTEXT_ACTION_FWD_DEST))
+ 		return true;
+ 
+ 	if (!dest || ((dest->type ==
+ 	    MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE) &&
+ 	    (dest->ft->level <= ft->level)))
+ 		return false;
+ 	return true;
+ }
+ 
+ static struct mlx5_flow_handle *
+ _mlx5_add_flow_rules(struct mlx5_flow_table *ft,
+ 		     struct mlx5_flow_spec *spec,
+ 		     struct mlx5_flow_act *flow_act,
+ 		     struct mlx5_flow_destination *dest,
+ 		     int dest_num)
+ 
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  {
  	struct mlx5_flow_group *g;
 -	struct mlx5_flow_handle *rule;
 -	int i;
 +	struct mlx5_flow_rule *rule;
  
++<<<<<<< HEAD
 +	if ((action & MLX5_FLOW_CONTEXT_ACTION_FWD_DEST) && !dest)
 +		return ERR_PTR(-EINVAL);
++=======
+ 	for (i = 0; i < dest_num; i++) {
+ 		if (!dest_is_valid(&dest[i], flow_act->action, ft))
+ 			return ERR_PTR(-EINVAL);
+ 	}
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  
  	nested_lock_ref_node(&ft->node, FS_MUTEX_GRANDPARENT);
  	fs_for_each_fg(g, ft)
  		if (compare_match_criteria(g->mask.match_criteria_enable,
 -					   spec->match_criteria_enable,
 +					   match_criteria_enable,
  					   g->mask.match_criteria,
++<<<<<<< HEAD
 +					   match_criteria)) {
 +			rule = add_rule_fg(g, match_value,
 +					   action, flow_tag, dest);
++=======
+ 					   spec->match_criteria)) {
+ 			rule = add_rule_fg(g, spec->match_value,
+ 					   flow_act, dest, dest_num);
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  			if (!IS_ERR(rule) || PTR_ERR(rule) != -ENOSPC)
  				goto unlock;
  		}
@@@ -1137,8 -1364,7 +1220,12 @@@
  		goto unlock;
  	}
  
++<<<<<<< HEAD
 +	rule = add_rule_fg(g, match_value,
 +			   action, flow_tag, dest);
++=======
+ 	rule = add_rule_fg(g, spec->match_value, flow_act, dest, dest_num);
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  	if (IS_ERR(rule)) {
  		/* Remove assumes refcount > 0 and autogroup creates a group
  		 * with a refcount = 0.
@@@ -1159,20 -1385,18 +1246,34 @@@ static bool fwd_next_prio_supported(str
  		(MLX5_CAP_FLOWTABLE(get_dev(&ft->node), nic_rx_multi_path_tirs)));
  }
  
++<<<<<<< HEAD
 +struct mlx5_flow_rule *
 +mlx5_add_flow_rule(struct mlx5_flow_table *ft,
 +		   u8 match_criteria_enable,
 +		   u32 *match_criteria,
 +		   u32 *match_value,
 +		   u32 action,
 +		   u32 flow_tag,
 +		   struct mlx5_flow_destination *dest)
++=======
+ struct mlx5_flow_handle *
+ mlx5_add_flow_rules(struct mlx5_flow_table *ft,
+ 		    struct mlx5_flow_spec *spec,
+ 		    struct mlx5_flow_act *flow_act,
+ 		    struct mlx5_flow_destination *dest,
+ 		    int dest_num)
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  {
  	struct mlx5_flow_root_namespace *root = find_root(&ft->node);
  	struct mlx5_flow_destination gen_dest;
  	struct mlx5_flow_table *next_ft = NULL;
++<<<<<<< HEAD
 +	struct mlx5_flow_rule *rule = NULL;
 +	u32 sw_action = action;
++=======
+ 	struct mlx5_flow_handle *handle = NULL;
+ 	u32 sw_action = flow_act->action;
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  	struct fs_prio *prio;
  
  	fs_get_obj(prio, ft->node.parent);
@@@ -1187,23 -1411,24 +1288,32 @@@
  			gen_dest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
  			gen_dest.ft = next_ft;
  			dest = &gen_dest;
++<<<<<<< HEAD
 +			action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST;
++=======
+ 			dest_num = 1;
+ 			flow_act->action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST;
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  		} else {
  			mutex_unlock(&root->chain_lock);
  			return ERR_PTR(-EOPNOTSUPP);
  		}
  	}
  
++<<<<<<< HEAD
 +	rule =	_mlx5_add_flow_rule(ft, match_criteria_enable, match_criteria,
 +				    match_value, action, flow_tag, dest);
++=======
+ 	handle = _mlx5_add_flow_rules(ft, spec, flow_act, dest, dest_num);
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  
  	if (sw_action == MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO) {
 -		if (!IS_ERR_OR_NULL(handle) &&
 -		    (list_empty(&handle->rule[0]->next_ft))) {
 +		if (!IS_ERR_OR_NULL(rule) &&
 +		    (list_empty(&rule->next_ft))) {
  			mutex_lock(&next_ft->lock);
 -			list_add(&handle->rule[0]->next_ft,
 -				 &next_ft->fwd_rules);
 +			list_add(&rule->next_ft, &next_ft->fwd_rules);
  			mutex_unlock(&next_ft->lock);
 -			handle->rule[0]->sw_action = MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO;
 +			rule->sw_action = MLX5_FLOW_CONTEXT_ACTION_FWD_NEXT_PRIO;
  		}
  		mutex_unlock(&root->chain_lock);
  	}
diff --cc include/linux/mlx5/fs.h
index 3f3444d24756,949b24b6c479..000000000000
--- a/include/linux/mlx5/fs.h
+++ b/include/linux/mlx5/fs.h
@@@ -104,17 -139,22 +110,27 @@@ struct mlx5_flow_act 
  /* Single destination per rule.
   * Group ID is implied by the match criteria.
   */
++<<<<<<< HEAD
 +struct mlx5_flow_rule *
 +mlx5_add_flow_rule(struct mlx5_flow_table *ft,
 +		   u8 match_criteria_enable,
 +		   u32 *match_criteria,
 +		   u32 *match_value,
 +		   u32 action,
 +		   u32 flow_tag,
 +		   struct mlx5_flow_destination *dest);
 +void mlx5_del_flow_rule(struct mlx5_flow_rule *fr);
++=======
+ struct mlx5_flow_handle *
+ mlx5_add_flow_rules(struct mlx5_flow_table *ft,
+ 		    struct mlx5_flow_spec *spec,
+ 		    struct mlx5_flow_act *flow_act,
+ 		    struct mlx5_flow_destination *dest,
+ 		    int dest_num);
+ void mlx5_del_flow_rules(struct mlx5_flow_handle *fr);
++>>>>>>> 66958ed906b8 (net/mlx5: Support encap id when setting new steering entry)
  
 -int mlx5_modify_rule_destination(struct mlx5_flow_handle *handler,
 -				 struct mlx5_flow_destination *new_dest,
 -				 struct mlx5_flow_destination *old_dest);
 -
 -struct mlx5_fc *mlx5_flow_rule_counter(struct mlx5_flow_handle *handler);
 -struct mlx5_fc *mlx5_fc_create(struct mlx5_core_dev *dev, bool aging);
 -void mlx5_fc_destroy(struct mlx5_core_dev *dev, struct mlx5_fc *counter);
 -void mlx5_fc_query_cached(struct mlx5_fc *counter,
 -			  u64 *bytes, u64 *packets, u64 *lastuse);
 +int mlx5_modify_rule_destination(struct mlx5_flow_rule *rule,
 +				 struct mlx5_flow_destination *dest);
  
  #endif
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_arfs.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
* Unmerged path drivers/infiniband/hw/mlx5/main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_arfs.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_fs.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_fs_ethtool.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/fs_cmd.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.h b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.h
index d607e564f454..f5fa207a49ed 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.h
@@ -101,6 +101,7 @@ struct fs_fte {
 	u32				flow_tag;
 	u32				index;
 	u32				action;
+	u32				encap_id;
 	enum fs_fte_status		status;
 };
 
* Unmerged path include/linux/mlx5/fs.h
