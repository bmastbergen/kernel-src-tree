net/mlx5: Introduce E-switch QoS management

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [netdrv] mlx5: Introduce E-switch QoS management (Don Dutile) [1386713 1385330 1417286]
Rebuild_FUZZ: 95.12%
commit-author Mohamad Haj Yahia <mohamad@mellanox.com>
commit 1bd27b11c1df33a1dc3277e2a0abbf6bd33cc817
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/1bd27b11.failed

Add TSAR to the eswitch which will act as the vports rate limiter.
Create/Destroy TSAR on Enable/Dsiable SRIOV.
Attach/Detach vport to eswitch TSAR on Enable/Disable vport.

	Signed-off-by: Mohamad Haj Yahia <mohamad@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
	Signed-off-by: Leon Romanovsky <leon@kernel.org>
(cherry picked from commit 1bd27b11c1df33a1dc3277e2a0abbf6bd33cc817)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
index 084178cfa483,2e11a94d8365..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@@ -1168,6 -1351,142 +1168,145 @@@ out
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ /* Vport QoS management */
+ static int esw_create_tsar(struct mlx5_eswitch *esw)
+ {
+ 	u32 tsar_ctx[MLX5_ST_SZ_DW(scheduling_context)] = {0};
+ 	struct mlx5_core_dev *dev = esw->dev;
+ 	int err;
+ 
+ 	if (!MLX5_CAP_GEN(dev, qos) || !MLX5_CAP_QOS(dev, esw_scheduling))
+ 		return 0;
+ 
+ 	if (esw->qos.enabled)
+ 		return -EEXIST;
+ 
+ 	err = mlx5_create_scheduling_element_cmd(dev,
+ 						 SCHEDULING_HIERARCHY_E_SWITCH,
+ 						 &tsar_ctx,
+ 						 &esw->qos.root_tsar_id);
+ 	if (err) {
+ 		esw_warn(esw->dev, "E-Switch create TSAR failed (%d)\n", err);
+ 		return err;
+ 	}
+ 
+ 	esw->qos.enabled = true;
+ 	return 0;
+ }
+ 
+ static void esw_destroy_tsar(struct mlx5_eswitch *esw)
+ {
+ 	int err;
+ 
+ 	if (!esw->qos.enabled)
+ 		return;
+ 
+ 	err = mlx5_destroy_scheduling_element_cmd(esw->dev,
+ 						  SCHEDULING_HIERARCHY_E_SWITCH,
+ 						  esw->qos.root_tsar_id);
+ 	if (err)
+ 		esw_warn(esw->dev, "E-Switch destroy TSAR failed (%d)\n", err);
+ 
+ 	esw->qos.enabled = false;
+ }
+ 
+ static int esw_vport_enable_qos(struct mlx5_eswitch *esw, int vport_num,
+ 				u32 initial_max_rate)
+ {
+ 	u32 sched_ctx[MLX5_ST_SZ_DW(scheduling_context)] = {0};
+ 	struct mlx5_vport *vport = &esw->vports[vport_num];
+ 	struct mlx5_core_dev *dev = esw->dev;
+ 	void *vport_elem;
+ 	int err = 0;
+ 
+ 	if (!esw->qos.enabled || !MLX5_CAP_GEN(dev, qos) ||
+ 	    !MLX5_CAP_QOS(dev, esw_scheduling))
+ 		return 0;
+ 
+ 	if (vport->qos.enabled)
+ 		return -EEXIST;
+ 
+ 	MLX5_SET(scheduling_context, &sched_ctx, element_type,
+ 		 SCHEDULING_CONTEXT_ELEMENT_TYPE_VPORT);
+ 	vport_elem = MLX5_ADDR_OF(scheduling_context, &sched_ctx,
+ 				  element_attributes);
+ 	MLX5_SET(vport_element, vport_elem, vport_number, vport_num);
+ 	MLX5_SET(scheduling_context, &sched_ctx, parent_element_id,
+ 		 esw->qos.root_tsar_id);
+ 	MLX5_SET(scheduling_context, &sched_ctx, max_average_bw,
+ 		 initial_max_rate);
+ 
+ 	err = mlx5_create_scheduling_element_cmd(dev,
+ 						 SCHEDULING_HIERARCHY_E_SWITCH,
+ 						 &sched_ctx,
+ 						 &vport->qos.esw_tsar_ix);
+ 	if (err) {
+ 		esw_warn(esw->dev, "E-Switch create TSAR vport element failed (vport=%d,err=%d)\n",
+ 			 vport_num, err);
+ 		return err;
+ 	}
+ 
+ 	vport->qos.enabled = true;
+ 	return 0;
+ }
+ 
+ static void esw_vport_disable_qos(struct mlx5_eswitch *esw, int vport_num)
+ {
+ 	struct mlx5_vport *vport = &esw->vports[vport_num];
+ 	int err = 0;
+ 
+ 	if (!vport->qos.enabled)
+ 		return;
+ 
+ 	err = mlx5_destroy_scheduling_element_cmd(esw->dev,
+ 						  SCHEDULING_HIERARCHY_E_SWITCH,
+ 						  vport->qos.esw_tsar_ix);
+ 	if (err)
+ 		esw_warn(esw->dev, "E-Switch destroy TSAR vport element failed (vport=%d,err=%d)\n",
+ 			 vport_num, err);
+ 
+ 	vport->qos.enabled = false;
+ }
+ 
+ static void node_guid_gen_from_mac(u64 *node_guid, u8 mac[ETH_ALEN])
+ {
+ 	((u8 *)node_guid)[7] = mac[0];
+ 	((u8 *)node_guid)[6] = mac[1];
+ 	((u8 *)node_guid)[5] = mac[2];
+ 	((u8 *)node_guid)[4] = 0xff;
+ 	((u8 *)node_guid)[3] = 0xfe;
+ 	((u8 *)node_guid)[2] = mac[3];
+ 	((u8 *)node_guid)[1] = mac[4];
+ 	((u8 *)node_guid)[0] = mac[5];
+ }
+ 
+ static void esw_apply_vport_conf(struct mlx5_eswitch *esw,
+ 				 struct mlx5_vport *vport)
+ {
+ 	int vport_num = vport->vport;
+ 
+ 	if (!vport_num)
+ 		return;
+ 
+ 	mlx5_modify_vport_admin_state(esw->dev,
+ 				      MLX5_QUERY_VPORT_STATE_IN_OP_MOD_ESW_VPORT,
+ 				      vport_num,
+ 				      vport->info.link_state);
+ 	mlx5_modify_nic_vport_mac_address(esw->dev, vport_num, vport->info.mac);
+ 	mlx5_modify_nic_vport_node_guid(esw->dev, vport_num, vport->info.node_guid);
+ 	modify_esw_vport_cvlan(esw->dev, vport_num, vport->info.vlan, vport->info.qos,
+ 			       (vport->info.vlan || vport->info.qos));
+ 
+ 	/* Only legacy mode needs ACLs */
+ 	if (esw->mode == SRIOV_LEGACY) {
+ 		esw_vport_ingress_config(esw, vport);
+ 		esw_vport_egress_config(esw, vport);
+ 	}
+ }
+ 
++>>>>>>> 1bd27b11c1df (net/mlx5: Introduce E-switch QoS management)
  static void esw_enable_vport(struct mlx5_eswitch *esw, int vport_num,
  			     int enable_events)
  {
@@@ -1178,25 -1497,22 +1317,29 @@@
  
  	esw_debug(esw->dev, "Enabling VPORT(%d)\n", vport_num);
  
 -	/* Restore old vport configuration */
 -	esw_apply_vport_conf(esw, vport);
 +	if (vport_num) { /* Only VFs need ACLs for VST and spoofchk filtering */
 +		esw_vport_enable_ingress_acl(esw, vport);
 +		esw_vport_enable_egress_acl(esw, vport);
 +		esw_vport_ingress_config(esw, vport);
 +		esw_vport_egress_config(esw, vport);
 +	}
 +
 +	mlx5_modify_vport_admin_state(esw->dev,
 +				      MLX5_QUERY_VPORT_STATE_IN_OP_MOD_ESW_VPORT,
 +				      vport_num,
 +				      MLX5_ESW_VPORT_ADMIN_STATE_AUTO);
  
+ 	/* Attach vport to the eswitch rate limiter */
+ 	if (esw_vport_enable_qos(esw, vport_num, vport->info.max_rate))
+ 		esw_warn(esw->dev, "Failed to attach vport %d to eswitch rate limiter", vport_num);
+ 
  	/* Sync with current vport context */
  	vport->enabled_events = enable_events;
 -	vport->enabled = true;
 +	esw_vport_change_handler(&vport->vport_change_handler);
  
 -	/* only PF is trusted by default */
 -	if (!vport_num)
 -		vport->info.trusted = true;
 +	vport->enabled = true;
  
 -	esw_vport_change_handle_locked(vport);
 +	arm_vport_context_events_cmd(esw->dev, vport_num, enable_events);
  
  	esw->enabled_vports++;
  	esw_debug(esw->dev, "Enabled VPORT(%d)\n", vport_num);
@@@ -1229,9 -1540,14 +1372,18 @@@ static void esw_disable_vport(struct ml
  	 * Calling vport change handler while vport is disabled will cleanup
  	 * the vport resources.
  	 */
 -	esw_vport_change_handle_locked(vport);
 +	esw_vport_change_handler(&vport->vport_change_handler);
  	vport->enabled_events = 0;
++<<<<<<< HEAD
 +	if (vport_num) {
++=======
+ 	esw_vport_disable_qos(esw, vport_num);
+ 	if (vport_num && esw->mode == SRIOV_LEGACY) {
+ 		mlx5_modify_vport_admin_state(esw->dev,
+ 					      MLX5_QUERY_VPORT_STATE_IN_OP_MOD_ESW_VPORT,
+ 					      vport_num,
+ 					      MLX5_ESW_VPORT_ADMIN_STATE_DOWN);
++>>>>>>> 1bd27b11c1df (net/mlx5: Introduce E-switch QoS management)
  		esw_vport_disable_egress_acl(esw, vport);
  		esw_vport_disable_ingress_acl(esw, vport);
  	}
@@@ -1269,8 -1588,13 +1421,16 @@@ int mlx5_eswitch_enable_sriov(struct ml
  	if (err)
  		goto abort;
  
++<<<<<<< HEAD
++=======
+ 	err = esw_create_tsar(esw);
+ 	if (err)
+ 		esw_warn(esw->dev, "Failed to create eswitch TSAR");
+ 
+ 	enabled_events = (mode == SRIOV_LEGACY) ? SRIOV_VPORT_EVENTS : UC_ADDR_CHANGE;
++>>>>>>> 1bd27b11c1df (net/mlx5: Introduce E-switch QoS management)
  	for (i = 0; i <= nvfs; i++)
 -		esw_enable_vport(esw, i, enabled_events);
 +		esw_enable_vport(esw, i, SRIOV_VPORT_EVENTS);
  
  	esw_info(esw->dev, "SRIOV enabled: active vports(%d)\n",
  		 esw->enabled_vports);
@@@ -1296,8 -1625,17 +1456,19 @@@ void mlx5_eswitch_disable_sriov(struct 
  	for (i = 0; i < esw->total_vports; i++)
  		esw_disable_vport(esw, i);
  
 -	if (mc_promisc && mc_promisc->uplink_rule)
 -		mlx5_del_flow_rule(mc_promisc->uplink_rule);
 +	esw_destroy_fdb_table(esw);
  
++<<<<<<< HEAD
++=======
+ 	esw_destroy_tsar(esw);
+ 
+ 	if (esw->mode == SRIOV_LEGACY)
+ 		esw_destroy_legacy_fdb_table(esw);
+ 	else if (esw->mode == SRIOV_OFFLOADS)
+ 		esw_offloads_cleanup(esw, nvports);
+ 
+ 	esw->mode = SRIOV_NONE;
++>>>>>>> 1bd27b11c1df (net/mlx5: Introduce E-switch QoS management)
  	/* VPORT 0 (PF) must be enabled back with non-sriov configuration */
  	esw_enable_vport(esw, 0, UC_ADDR_CHANGE);
  }
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index 7b5e70f8cc22,fb8de34b6baf..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@@ -106,6 -109,17 +106,20 @@@ struct vport_egress 
  	struct mlx5_flow_rule  *drop_rule;
  };
  
++<<<<<<< HEAD
++=======
+ struct mlx5_vport_info {
+ 	u8                      mac[ETH_ALEN];
+ 	u16                     vlan;
+ 	u8                      qos;
+ 	u64                     node_guid;
+ 	int                     link_state;
+ 	u32                     max_rate;
+ 	bool                    spoofchk;
+ 	bool                    trusted;
+ };
+ 
++>>>>>>> 1bd27b11c1df (net/mlx5: Introduce E-switch QoS management)
  struct mlx5_vport {
  	struct mlx5_core_dev    *dev;
  	int                     vport;
@@@ -116,8 -132,13 +130,18 @@@
  	struct vport_ingress    ingress;
  	struct vport_egress     egress;
  
++<<<<<<< HEAD
 +	u16                     vlan;
 +	u8                      qos;
++=======
+ 	struct mlx5_vport_info  info;
+ 
+ 	struct {
+ 		bool            enabled;
+ 		u32             esw_tsar_ix;
+ 	} qos;
+ 
++>>>>>>> 1bd27b11c1df (net/mlx5: Introduce E-switch QoS management)
  	bool                    enabled;
  	u16                     enabled_events;
  };
@@@ -148,8 -214,20 +172,20 @@@ struct mlx5_eswitch 
  	 * and async SRIOV admin state changes
  	 */
  	struct mutex            state_lock;
++<<<<<<< HEAD
++=======
+ 	struct esw_mc_addr      *mc_promisc;
+ 
+ 	struct {
+ 		bool            enabled;
+ 		u32             root_tsar_id;
+ 	} qos;
+ 
+ 	struct mlx5_esw_offload offloads;
+ 	int                     mode;
++>>>>>>> 1bd27b11c1df (net/mlx5: Introduce E-switch QoS management)
  };
  
 -void esw_offloads_cleanup(struct mlx5_eswitch *esw, int nvports);
 -int esw_offloads_init(struct mlx5_eswitch *esw, int nvports);
 -
  /* E-Switch API */
  int mlx5_eswitch_init(struct mlx5_core_dev *dev);
  void mlx5_eswitch_cleanup(struct mlx5_eswitch *esw);
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
