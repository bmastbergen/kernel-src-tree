dm cache policy smq: put newly promoted entries at the top of the multiqueue

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Joe Thornber <ejt@redhat.com>
commit 4d44ec5ab751be63c5d348f13294304d87baa8c3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/4d44ec5a.failed

This stops entries bouncing in and out of the cache quickly.

	Signed-off-by: Joe Thornber <ejt@redhat.com>
	Signed-off-by: Mike Snitzer <snitzer@redhat.com>
(cherry picked from commit 4d44ec5ab751be63c5d348f13294304d87baa8c3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/dm-cache-policy-smq.c
diff --cc drivers/md/dm-cache-policy-smq.c
index c33f4a6e1d7d,54421a846a0c..000000000000
--- a/drivers/md/dm-cache-policy-smq.c
+++ b/drivers/md/dm-cache-policy-smq.c
@@@ -1327,19 -1411,83 +1327,99 @@@ static int smq_lookup(struct dm_cache_p
  	return r;
  }
  
 +static void __smq_set_clear_dirty(struct smq_policy *mq, dm_oblock_t oblock, bool set)
 +{
 +	struct entry *e;
 +
 +	e = h_lookup(&mq->table, oblock);
 +	BUG_ON(!e);
 +
 +	del(mq, e);
 +	e->dirty = set;
 +	push(mq, e);
 +}
 +
++<<<<<<< HEAD
 +static void smq_set_dirty(struct dm_cache_policy *p, dm_oblock_t oblock)
++=======
+ static int smq_get_background_work(struct dm_cache_policy *p, bool idle,
+ 				   struct policy_work **result)
+ {
+ 	int r;
+ 	unsigned long flags;
+ 	struct smq_policy *mq = to_smq_policy(p);
+ 
+ 	spin_lock_irqsave(&mq->lock, flags);
+ 	r = btracker_issue(mq->bg_work, result);
+ 	if (r == -ENODATA) {
+ 		/* find some writeback work to do */
+ 		if (mq->migrations_allowed && !free_target_met(mq, idle))
+ 			queue_demotion(mq);
+ 
+ 		else if (!clean_target_met(mq, idle))
+ 			queue_writeback(mq);
+ 
+ 		r = btracker_issue(mq->bg_work, result);
+ 	}
+ 	spin_unlock_irqrestore(&mq->lock, flags);
+ 
+ 	return r;
+ }
+ 
+ /*
+  * We need to clear any pending work flags that have been set, and in the
+  * case of promotion free the entry for the destination cblock.
+  */
+ static void __complete_background_work(struct smq_policy *mq,
+ 				       struct policy_work *work,
+ 				       bool success)
+ {
+ 	struct entry *e = get_entry(&mq->cache_alloc,
+ 				    from_cblock(work->cblock));
+ 
+ 	switch (work->op) {
+ 	case POLICY_PROMOTE:
+ 		// !h, !q, a
+ 		clear_pending(mq, e);
+ 		if (success) {
+ 			e->oblock = work->oblock;
+ 			e->level = NR_CACHE_LEVELS - 1;
+ 			push(mq, e);
+ 			// h, q, a
+ 		} else {
+ 			free_entry(&mq->cache_alloc, e);
+ 			// !h, !q, !a
+ 		}
+ 		break;
+ 
+ 	case POLICY_DEMOTE:
+ 		// h, !q, a
+ 		if (success) {
+ 			h_remove(&mq->table, e);
+ 			free_entry(&mq->cache_alloc, e);
+ 			// !h, !q, !a
+ 		} else {
+ 			clear_pending(mq, e);
+ 			push_queue(mq, e);
+ 			// h, q, a
+ 		}
+ 		break;
+ 
+ 	case POLICY_WRITEBACK:
+ 		// h, !q, a
+ 		clear_pending(mq, e);
+ 		push_queue(mq, e);
+ 		// h, q, a
+ 		break;
+ 	}
+ 
+ 	btracker_complete(mq->bg_work, work);
+ }
+ 
+ static void smq_complete_background_work(struct dm_cache_policy *p,
+ 					 struct policy_work *work,
+ 					 bool success)
++>>>>>>> 4d44ec5ab751 (dm cache policy smq: put newly promoted entries at the top of the multiqueue)
  {
  	unsigned long flags;
  	struct smq_policy *mq = to_smq_policy(p);
* Unmerged path drivers/md/dm-cache-policy-smq.c
