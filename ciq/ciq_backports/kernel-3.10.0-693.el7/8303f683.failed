IB/hfi1: Allocate cpu mask on the heap to silence warning

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Tadeusz Struk <tadeusz.struk@intel.com>
commit 8303f683b161467b6595c153c8751b80f9df3508
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/8303f683.failed

If CONFIG_FRAME_WARN is small (1K) and CONFIG_NR_CPUS big
then a frame size warning is triggered during build.
Allocate the cpu mask dynamically to silence the warning.

	Reviewed-by: Sebastian Sanchez <sebastian.sanchez@intel.com>
	Signed-off-by: Tadeusz Struk <tadeusz.struk@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 8303f683b161467b6595c153c8751b80f9df3508)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/hfi1/affinity.c
diff --cc drivers/infiniband/hw/hfi1/affinity.c
index 1ca2154de24c,9bbb21459166..000000000000
--- a/drivers/infiniband/hw/hfi1/affinity.c
+++ b/drivers/infiniband/hw/hfi1/affinity.c
@@@ -423,6 -672,78 +423,81 @@@ void hfi1_put_proc_affinity(struct hfi1
  		set->gen--;
  		cpumask_copy(&set->used, &set->mask);
  	}
 -	spin_unlock(&affinity->lock);
 +	spin_unlock(&dd->affinity->lock);
  }
  
++<<<<<<< HEAD
++=======
+ /* Prevents concurrent reads and writes of the sdma_affinity attrib */
+ static DEFINE_MUTEX(sdma_affinity_mutex);
+ 
+ int hfi1_set_sdma_affinity(struct hfi1_devdata *dd, const char *buf,
+ 			   size_t count)
+ {
+ 	struct hfi1_affinity_node *entry;
+ 	cpumask_var_t mask;
+ 	int ret, i;
+ 
+ 	spin_lock(&node_affinity.lock);
+ 	entry = node_affinity_lookup(dd->node);
+ 	spin_unlock(&node_affinity.lock);
+ 
+ 	if (!entry)
+ 		return -EINVAL;
+ 
+ 	ret = zalloc_cpumask_var(&mask, GFP_KERNEL);
+ 	if (!ret)
+ 		return -ENOMEM;
+ 
+ 	ret = cpulist_parse(buf, mask);
+ 	if (ret)
+ 		goto out;
+ 
+ 	if (!cpumask_subset(mask, cpu_online_mask) || cpumask_empty(mask)) {
+ 		dd_dev_warn(dd, "Invalid CPU mask\n");
+ 		ret = -EINVAL;
+ 		goto out;
+ 	}
+ 
+ 	mutex_lock(&sdma_affinity_mutex);
+ 	/* reset the SDMA interrupt affinity details */
+ 	init_cpu_mask_set(&entry->def_intr);
+ 	cpumask_copy(&entry->def_intr.mask, mask);
+ 	/*
+ 	 * Reassign the affinity for each SDMA interrupt.
+ 	 */
+ 	for (i = 0; i < dd->num_msix_entries; i++) {
+ 		struct hfi1_msix_entry *msix;
+ 
+ 		msix = &dd->msix_entries[i];
+ 		if (msix->type != IRQ_SDMA)
+ 			continue;
+ 
+ 		ret = hfi1_get_irq_affinity(dd, msix);
+ 
+ 		if (ret)
+ 			break;
+ 	}
+ 	mutex_unlock(&sdma_affinity_mutex);
+ out:
+ 	free_cpumask_var(mask);
+ 	return ret ? ret : strnlen(buf, PAGE_SIZE);
+ }
+ 
+ int hfi1_get_sdma_affinity(struct hfi1_devdata *dd, char *buf)
+ {
+ 	struct hfi1_affinity_node *entry;
+ 
+ 	spin_lock(&node_affinity.lock);
+ 	entry = node_affinity_lookup(dd->node);
+ 	spin_unlock(&node_affinity.lock);
+ 
+ 	if (!entry)
+ 		return -EINVAL;
+ 
+ 	mutex_lock(&sdma_affinity_mutex);
+ 	cpumap_print_to_pagebuf(true, buf, &entry->def_intr.mask);
+ 	mutex_unlock(&sdma_affinity_mutex);
+ 	return strnlen(buf, PAGE_SIZE);
+ }
++>>>>>>> 8303f683b161 (IB/hfi1: Allocate cpu mask on the heap to silence warning)
* Unmerged path drivers/infiniband/hw/hfi1/affinity.c
