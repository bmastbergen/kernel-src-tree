net: use skb->csum_not_inet to identify packets needing crc32c

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [net] use skb->csum_not_inet to identify packets needing crc32c (Davide Caratti) [1072503]
Rebuild_FUZZ: 95.80%
commit-author Davide Caratti <dcaratti@redhat.com>
commit dba003067a43a9699bef0c4bdbe320ece5a109b8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/dba00306.failed

skb->csum_not_inet carries the indication on which algorithm is needed to
compute checksum on skb in the transmit path, when skb->ip_summed is equal
to CHECKSUM_PARTIAL. If skb carries a SCTP packet and crc32c hasn't been
yet written in L4 header, skb->csum_not_inet is assigned to 1; otherwise,
assume Internet Checksum is needed and thus set skb->csum_not_inet to 0.

	Suggested-by: Tom Herbert <tom@herbertland.com>
	Signed-off-by: Davide Caratti <dcaratti@redhat.com>
	Acked-by: Tom Herbert <tom@herbertland.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit dba003067a43a9699bef0c4bdbe320ece5a109b8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/skbuff.h
#	net/core/dev.c
#	net/sched/act_csum.c
#	net/sctp/output.c
diff --cc include/linux/skbuff.h
index 3d397b324356,a43d2086bb7f..000000000000
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@@ -186,11 -189,13 +186,21 @@@
   *
   *   NETIF_F_SCTP_CRC - This feature indicates that a device is capable of
   *     offloading the SCTP CRC in a packet. To perform this offload the stack
++<<<<<<< HEAD
 + *     will set ip_summed to CHECKSUM_PARTIAL and set csum_start and csum_offset
 + *     accordingly. Note the there is no indication in the skbuff that the
 + *     CHECKSUM_PARTIAL refers to an SCTP checksum, a driver that supports
 + *     both IP checksum offload and SCTP CRC offload must verify which offload
 + *     is configured for a packet presumably by inspecting packet headers.
++=======
+  *     will set set csum_start and csum_offset accordingly, set ip_summed to
+  *     CHECKSUM_PARTIAL and set csum_not_inet to 1, to provide an indication in
+  *     the skbuff that the CHECKSUM_PARTIAL refers to CRC32c.
+  *     A driver that supports both IP checksum offload and SCTP CRC32c offload
+  *     must verify which offload is configured for a packet by testing the
+  *     value of skb->csum_not_inet; skb_crc32c_csum_help is provided to resolve
+  *     CHECKSUM_PARTIAL on skbs where csum_not_inet is set to 1.
++>>>>>>> dba003067a43 (net: use skb->csum_not_inet to identify packets needing crc32c)
   *
   *   NETIF_F_FCOE_CRC - This feature indicates that a device is capable of
   *     offloading the FCOE CRC in a packet. To perform this offload the stack
@@@ -627,11 -557,12 +637,17 @@@ static inline u32 skb_mstamp_us_delta(c
   *	@wifi_acked_valid: wifi_acked was set
   *	@wifi_acked: whether frame was acked on wifi or not
   *	@no_fcs:  Request NIC to treat last 4 bytes as Ethernet FCS
++<<<<<<< HEAD
 + *	@xmit_more: More SKBs are pending for this queue
 + *	@napi_id: id of the NAPI struct this skb came from
++=======
+  *	@csum_not_inet: use CRC32c to resolve CHECKSUM_PARTIAL
+  *	@dst_pending_confirm: need to confirm neighbour
+   *	@napi_id: id of the NAPI struct this skb came from
++>>>>>>> dba003067a43 (net: use skb->csum_not_inet to identify packets needing crc32c)
   *	@secmark: security marking
   *	@mark: Generic packet mark
 + *	@dropcount: total number of sk_receive_queue overflows
   *	@vlan_proto: vlan encapsulation protocol
   *	@vlan_tci: vlan tag control information
   *	@inner_protocol: Protocol (encapsulation)
@@@ -680,6 -627,89 +696,92 @@@ struct sk_buff 
  				data_len;
  	__u16			mac_len,
  				hdr_len;
++<<<<<<< HEAD
++=======
+ 
+ 	/* Following fields are _not_ copied in __copy_skb_header()
+ 	 * Note that queue_mapping is here mostly to fill a hole.
+ 	 */
+ 	kmemcheck_bitfield_begin(flags1);
+ 	__u16			queue_mapping;
+ 
+ /* if you move cloned around you also must adapt those constants */
+ #ifdef __BIG_ENDIAN_BITFIELD
+ #define CLONED_MASK	(1 << 7)
+ #else
+ #define CLONED_MASK	1
+ #endif
+ #define CLONED_OFFSET()		offsetof(struct sk_buff, __cloned_offset)
+ 
+ 	__u8			__cloned_offset[0];
+ 	__u8			cloned:1,
+ 				nohdr:1,
+ 				fclone:2,
+ 				peeked:1,
+ 				head_frag:1,
+ 				xmit_more:1,
+ 				__unused:1; /* one bit hole */
+ 	kmemcheck_bitfield_end(flags1);
+ 
+ 	/* fields enclosed in headers_start/headers_end are copied
+ 	 * using a single memcpy() in __copy_skb_header()
+ 	 */
+ 	/* private: */
+ 	__u32			headers_start[0];
+ 	/* public: */
+ 
+ /* if you move pkt_type around you also must adapt those constants */
+ #ifdef __BIG_ENDIAN_BITFIELD
+ #define PKT_TYPE_MAX	(7 << 5)
+ #else
+ #define PKT_TYPE_MAX	7
+ #endif
+ #define PKT_TYPE_OFFSET()	offsetof(struct sk_buff, __pkt_type_offset)
+ 
+ 	__u8			__pkt_type_offset[0];
+ 	__u8			pkt_type:3;
+ 	__u8			pfmemalloc:1;
+ 	__u8			ignore_df:1;
+ 
+ 	__u8			nf_trace:1;
+ 	__u8			ip_summed:2;
+ 	__u8			ooo_okay:1;
+ 	__u8			l4_hash:1;
+ 	__u8			sw_hash:1;
+ 	__u8			wifi_acked_valid:1;
+ 	__u8			wifi_acked:1;
+ 
+ 	__u8			no_fcs:1;
+ 	/* Indicates the inner headers are valid in the skbuff. */
+ 	__u8			encapsulation:1;
+ 	__u8			encap_hdr_csum:1;
+ 	__u8			csum_valid:1;
+ 	__u8			csum_complete_sw:1;
+ 	__u8			csum_level:2;
+ 	__u8			csum_not_inet:1;
+ 
+ 	__u8			dst_pending_confirm:1;
+ #ifdef CONFIG_IPV6_NDISC_NODETYPE
+ 	__u8			ndisc_nodetype:2;
+ #endif
+ 	__u8			ipvs_property:1;
+ 	__u8			inner_protocol_type:1;
+ 	__u8			remcsum_offload:1;
+ #ifdef CONFIG_NET_SWITCHDEV
+ 	__u8			offload_fwd_mark:1;
+ #endif
+ #ifdef CONFIG_NET_CLS_ACT
+ 	__u8			tc_skip_classify:1;
+ 	__u8			tc_at_ingress:1;
+ 	__u8			tc_redirected:1;
+ 	__u8			tc_from_ingress:1;
+ #endif
+ 
+ #ifdef CONFIG_NET_SCHED
+ 	__u16			tc_index;	/* traffic control index */
+ #endif
+ 
++>>>>>>> dba003067a43 (net: use skb->csum_not_inet to identify packets needing crc32c)
  	union {
  		__wsum		csum;
  		struct {
diff --cc net/core/dev.c
index a6aab03373f7,71107d1f3051..000000000000
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@@ -2498,6 -2613,47 +2498,50 @@@ out
  }
  EXPORT_SYMBOL(skb_checksum_help);
  
++<<<<<<< HEAD
++=======
+ int skb_crc32c_csum_help(struct sk_buff *skb)
+ {
+ 	__le32 crc32c_csum;
+ 	int ret = 0, offset, start;
+ 
+ 	if (skb->ip_summed != CHECKSUM_PARTIAL)
+ 		goto out;
+ 
+ 	if (unlikely(skb_is_gso(skb)))
+ 		goto out;
+ 
+ 	/* Before computing a checksum, we should make sure no frag could
+ 	 * be modified by an external entity : checksum could be wrong.
+ 	 */
+ 	if (unlikely(skb_has_shared_frag(skb))) {
+ 		ret = __skb_linearize(skb);
+ 		if (ret)
+ 			goto out;
+ 	}
+ 	start = skb_checksum_start_offset(skb);
+ 	offset = start + offsetof(struct sctphdr, checksum);
+ 	if (WARN_ON_ONCE(offset >= skb_headlen(skb))) {
+ 		ret = -EINVAL;
+ 		goto out;
+ 	}
+ 	if (skb_cloned(skb) &&
+ 	    !skb_clone_writable(skb, offset + sizeof(__le32))) {
+ 		ret = pskb_expand_head(skb, 0, 0, GFP_ATOMIC);
+ 		if (ret)
+ 			goto out;
+ 	}
+ 	crc32c_csum = cpu_to_le32(~__skb_checksum(skb, start,
+ 						  skb->len - start, ~(__u32)0,
+ 						  crc32c_csum_stub));
+ 	*(__le32 *)(skb->data + offset) = crc32c_csum;
+ 	skb->ip_summed = CHECKSUM_NONE;
+ 	skb->csum_not_inet = 0;
+ out:
+ 	return ret;
+ }
+ 
++>>>>>>> dba003067a43 (net: use skb->csum_not_inet to identify packets needing crc32c)
  __be16 skb_network_protocol(struct sk_buff *skb, int *depth)
  {
  	__be16 type = skb->protocol;
diff --cc net/sched/act_csum.c
index 11fe1a416433,3317a2f579da..000000000000
--- a/net/sched/act_csum.c
+++ b/net/sched/act_csum.c
@@@ -336,6 -335,26 +336,29 @@@ ignore_obscure_skb
  	return 1;
  }
  
++<<<<<<< HEAD
++=======
+ static int tcf_csum_sctp(struct sk_buff *skb, unsigned int ihl,
+ 			 unsigned int ipl)
+ {
+ 	struct sctphdr *sctph;
+ 
+ 	if (skb_is_gso(skb) && skb_shinfo(skb)->gso_type & SKB_GSO_SCTP)
+ 		return 1;
+ 
+ 	sctph = tcf_csum_skb_nextlayer(skb, ihl, ipl, sizeof(*sctph));
+ 	if (!sctph)
+ 		return 0;
+ 
+ 	sctph->checksum = sctp_compute_cksum(skb,
+ 					     skb_network_offset(skb) + ihl);
+ 	skb->ip_summed = CHECKSUM_NONE;
+ 	skb->csum_not_inet = 0;
+ 
+ 	return 1;
+ }
+ 
++>>>>>>> dba003067a43 (net: use skb->csum_not_inet to identify packets needing crc32c)
  static int tcf_csum_ipv4(struct sk_buff *skb, u32 update_flags)
  {
  	const struct iphdr *iph;
diff --cc net/sctp/output.c
index 02b6a1b39273,e2edf2ebbade..000000000000
--- a/net/sctp/output.c
+++ b/net/sctp/output.c
@@@ -728,27 -523,123 +728,135 @@@ int sctp_packet_transmit(struct sctp_pa
  			sk_setup_caps(sk, tp->dst);
  		}
  		rcu_read_unlock();
++<<<<<<< HEAD
++=======
+ 		goto chksum;
+ 	}
+ 
+ 	if (sctp_checksum_disable)
+ 		return 1;
+ 
+ 	if (!(skb_dst(head)->dev->features & NETIF_F_SCTP_CRC) ||
+ 	    dst_xfrm(skb_dst(head)) || packet->ipfragok) {
+ 		struct sctphdr *sh =
+ 			(struct sctphdr *)skb_transport_header(head);
+ 
+ 		sh->checksum = sctp_compute_cksum(head, 0);
+ 	} else {
+ chksum:
+ 		head->ip_summed = CHECKSUM_PARTIAL;
+ 		head->csum_not_inet = 1;
+ 		head->csum_start = skb_transport_header(head) - head->head;
+ 		head->csum_offset = offsetof(struct sctphdr, checksum);
+ 	}
+ 
+ 	return pkt_count;
+ }
+ 
+ /* All packets are sent to the network through this function from
+  * sctp_outq_tail().
+  *
+  * The return value is always 0 for now.
+  */
+ int sctp_packet_transmit(struct sctp_packet *packet, gfp_t gfp)
+ {
+ 	struct sctp_transport *tp = packet->transport;
+ 	struct sctp_association *asoc = tp->asoc;
+ 	struct sctp_chunk *chunk, *tmp;
+ 	int pkt_count, gso = 0;
+ 	struct dst_entry *dst;
+ 	struct sk_buff *head;
+ 	struct sctphdr *sh;
+ 	struct sock *sk;
+ 
+ 	pr_debug("%s: packet:%p\n", __func__, packet);
+ 	if (list_empty(&packet->chunk_list))
+ 		return 0;
+ 	chunk = list_entry(packet->chunk_list.next, struct sctp_chunk, list);
+ 	sk = chunk->skb->sk;
+ 
+ 	/* check gso */
+ 	if (packet->size > tp->pathmtu && !packet->ipfragok) {
+ 		if (!sk_can_gso(sk)) {
+ 			pr_err_once("Trying to GSO but underlying device doesn't support it.");
+ 			goto out;
+ 		}
+ 		gso = 1;
+ 	}
+ 
+ 	/* alloc head skb */
+ 	head = alloc_skb((gso ? packet->overhead : packet->size) +
+ 			 MAX_HEADER, gfp);
+ 	if (!head)
+ 		goto out;
+ 	skb_reserve(head, packet->overhead + MAX_HEADER);
+ 	sctp_packet_set_owner_w(head, sk);
+ 
+ 	/* set sctp header */
+ 	sh = (struct sctphdr *)skb_push(head, sizeof(struct sctphdr));
+ 	skb_reset_transport_header(head);
+ 	sh->source = htons(packet->source_port);
+ 	sh->dest = htons(packet->destination_port);
+ 	sh->vtag = htonl(packet->vtag);
+ 	sh->checksum = 0;
+ 
+ 	/* drop packet if no dst */
+ 	dst = dst_clone(tp->dst);
+ 	if (!dst) {
+ 		IP_INC_STATS(sock_net(sk), IPSTATS_MIB_OUTNOROUTES);
+ 		kfree_skb(head);
+ 		goto out;
+ 	}
+ 	skb_dst_set(head, dst);
+ 
+ 	/* pack up chunks */
+ 	pkt_count = sctp_packet_pack(packet, head, gso, gfp);
+ 	if (!pkt_count) {
+ 		kfree_skb(head);
+ 		goto out;
+ 	}
+ 	pr_debug("***sctp_transmit_packet*** skb->len:%d\n", head->len);
+ 
+ 	/* start autoclose timer */
+ 	if (packet->has_data && sctp_state(asoc, ESTABLISHED) &&
+ 	    asoc->timeouts[SCTP_EVENT_TIMEOUT_AUTOCLOSE]) {
+ 		struct timer_list *timer =
+ 			&asoc->timers[SCTP_EVENT_TIMEOUT_AUTOCLOSE];
+ 		unsigned long timeout =
+ 			asoc->timeouts[SCTP_EVENT_TIMEOUT_AUTOCLOSE];
+ 
+ 		if (!mod_timer(timer, jiffies + timeout))
+ 			sctp_association_hold(asoc);
+ 	}
+ 
+ 	/* sctp xmit */
+ 	tp->af_specific->ecn_capable(sk);
+ 	if (asoc) {
+ 		asoc->stats.opackets += pkt_count;
+ 		if (asoc->peer.last_sent_to != tp)
+ 			asoc->peer.last_sent_to = tp;
++>>>>>>> dba003067a43 (net: use skb->csum_not_inet to identify packets needing crc32c)
  	}
  	head->ignore_df = packet->ipfragok;
 -	if (tp->dst_pending_confirm)
 -		skb_set_dst_pending_confirm(head, 1);
 -	/* neighbour should be confirmed on successful transmission or
 -	 * positive error
 +	tp->af_specific->sctp_xmit(head, tp);
 +	goto out;
 +
 +nomem:
 +	if (packet->auth && list_empty(&packet->auth->list))
 +		sctp_chunk_free(packet->auth);
 +
 +nodst:
 +	/* FIXME: Returning the 'err' will effect all the associations
 +	 * associated with a socket, although only one of the paths of the
 +	 * association is unreachable.
 +	 * The real failure of a transport or association can be passed on
 +	 * to the user via notifications. So setting this error may not be
 +	 * required.
  	 */
 -	if (tp->af_specific->sctp_xmit(head, tp) >= 0 &&
 -	    tp->dst_pending_confirm)
 -		tp->dst_pending_confirm = 0;
 +	 /* err = -EHOSTUNREACH; */
 +	kfree_skb(head);
  
 -out:
 +err:
  	list_for_each_entry_safe(chunk, tmp, &packet->chunk_list, list) {
  		list_del_init(&chunk->list);
  		if (!sctp_chunk_is_data(chunk))
* Unmerged path include/linux/skbuff.h
* Unmerged path net/core/dev.c
* Unmerged path net/sched/act_csum.c
diff --git a/net/sctp/offload.c b/net/sctp/offload.c
index b67198429db5..275925b93b29 100644
--- a/net/sctp/offload.c
+++ b/net/sctp/offload.c
@@ -35,6 +35,7 @@
 static __le32 sctp_gso_make_checksum(struct sk_buff *skb)
 {
 	skb->ip_summed = CHECKSUM_NONE;
+	skb->csum_not_inet = 0;
 	return sctp_compute_cksum(skb, skb_transport_offset(skb));
 }
 
* Unmerged path net/sctp/output.c
