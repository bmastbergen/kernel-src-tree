vfio/pci: Add infrastructure for additional device specific regions

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [vfio] pci: Add infrastructure for additional device specific regions (Tarun Gupta) [1116064]
Rebuild_FUZZ: 96.12%
commit-author Alex Williamson <alex.williamson@redhat.com>
commit 28541d41c9e04cb2ddbf93facd1e376dd5613360
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/28541d41.failed

Add support for additional regions with indexes started after the
already defined fixed regions.  Device specific code can register
these regions with the new vfio_pci_register_dev_region() function.
The ops structure per region currently only includes read/write
access and a release function, allowing automatic cleanup when the
device is closed.  mmap support is only missing here because it's
not needed by the first user queued for this support.

	Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
(cherry picked from commit 28541d41c9e04cb2ddbf93facd1e376dd5613360)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/vfio/pci/vfio_pci.c
diff --cc drivers/vfio/pci/vfio_pci.c
index 2a0043c78806,813a2e67aa0c..000000000000
--- a/drivers/vfio/pci/vfio_pci.c
+++ b/drivers/vfio/pci/vfio_pci.c
@@@ -446,6 -428,93 +453,96 @@@ static int vfio_pci_for_each_slot_or_bu
  	return walk.ret;
  }
  
++<<<<<<< HEAD
++=======
+ static int msix_sparse_mmap_cap(struct vfio_pci_device *vdev,
+ 				struct vfio_info_cap *caps)
+ {
+ 	struct vfio_info_cap_header *header;
+ 	struct vfio_region_info_cap_sparse_mmap *sparse;
+ 	size_t end, size;
+ 	int nr_areas = 2, i = 0;
+ 
+ 	end = pci_resource_len(vdev->pdev, vdev->msix_bar);
+ 
+ 	/* If MSI-X table is aligned to the start or end, only one area */
+ 	if (((vdev->msix_offset & PAGE_MASK) == 0) ||
+ 	    (PAGE_ALIGN(vdev->msix_offset + vdev->msix_size) >= end))
+ 		nr_areas = 1;
+ 
+ 	size = sizeof(*sparse) + (nr_areas * sizeof(*sparse->areas));
+ 
+ 	header = vfio_info_cap_add(caps, size,
+ 				   VFIO_REGION_INFO_CAP_SPARSE_MMAP, 1);
+ 	if (IS_ERR(header))
+ 		return PTR_ERR(header);
+ 
+ 	sparse = container_of(header,
+ 			      struct vfio_region_info_cap_sparse_mmap, header);
+ 	sparse->nr_areas = nr_areas;
+ 
+ 	if (vdev->msix_offset & PAGE_MASK) {
+ 		sparse->areas[i].offset = 0;
+ 		sparse->areas[i].size = vdev->msix_offset & PAGE_MASK;
+ 		i++;
+ 	}
+ 
+ 	if (PAGE_ALIGN(vdev->msix_offset + vdev->msix_size) < end) {
+ 		sparse->areas[i].offset = PAGE_ALIGN(vdev->msix_offset +
+ 						     vdev->msix_size);
+ 		sparse->areas[i].size = end - sparse->areas[i].offset;
+ 		i++;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int region_type_cap(struct vfio_pci_device *vdev,
+ 			   struct vfio_info_cap *caps,
+ 			   unsigned int type, unsigned int subtype)
+ {
+ 	struct vfio_info_cap_header *header;
+ 	struct vfio_region_info_cap_type *cap;
+ 
+ 	header = vfio_info_cap_add(caps, sizeof(*cap),
+ 				   VFIO_REGION_INFO_CAP_TYPE, 1);
+ 	if (IS_ERR(header))
+ 		return PTR_ERR(header);
+ 
+ 	cap = container_of(header, struct vfio_region_info_cap_type, header);
+ 	cap->type = type;
+ 	cap->subtype = subtype;
+ 
+ 	return 0;
+ }
+ 
+ int vfio_pci_register_dev_region(struct vfio_pci_device *vdev,
+ 				 unsigned int type, unsigned int subtype,
+ 				 const struct vfio_pci_regops *ops,
+ 				 size_t size, u32 flags, void *data)
+ {
+ 	struct vfio_pci_region *region;
+ 
+ 	region = krealloc(vdev->region,
+ 			  (vdev->num_regions + 1) * sizeof(*region),
+ 			  GFP_KERNEL);
+ 	if (!region)
+ 		return -ENOMEM;
+ 
+ 	vdev->region = region;
+ 	vdev->region[vdev->num_regions].type = type;
+ 	vdev->region[vdev->num_regions].subtype = subtype;
+ 	vdev->region[vdev->num_regions].ops = ops;
+ 	vdev->region[vdev->num_regions].size = size;
+ 	vdev->region[vdev->num_regions].flags = flags;
+ 	vdev->region[vdev->num_regions].data = data;
+ 
+ 	vdev->num_regions++;
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 28541d41c9e0 (vfio/pci: Add infrastructure for additional device specific regions)
  static long vfio_pci_ioctl(void *device_data,
  			   unsigned int cmd, unsigned long arg)
  {
@@@ -468,15 -537,16 +565,20 @@@
  		if (vdev->reset_works)
  			info.flags |= VFIO_DEVICE_FLAGS_RESET;
  
- 		info.num_regions = VFIO_PCI_NUM_REGIONS;
+ 		info.num_regions = VFIO_PCI_NUM_REGIONS + vdev->num_regions;
  		info.num_irqs = VFIO_PCI_NUM_IRQS;
  
 -		return copy_to_user((void __user *)arg, &info, minsz);
 +		return copy_to_user((void __user *)arg, &info, minsz) ?
 +			-EFAULT : 0;
  
  	} else if (cmd == VFIO_DEVICE_GET_REGION_INFO) {
  		struct pci_dev *pdev = vdev->pdev;
  		struct vfio_region_info info;
++<<<<<<< HEAD
++=======
+ 		struct vfio_info_cap caps = { .buf = NULL, .size = 0 };
+ 		int i, ret;
++>>>>>>> 28541d41c9e0 (vfio/pci: Add infrastructure for additional device specific regions)
  
  		minsz = offsetofend(struct vfio_region_info, offset);
  
@@@ -543,11 -620,44 +645,25 @@@
  
  			break;
  		default:
- 			return -EINVAL;
+ 			if (info.index >=
+ 			    VFIO_PCI_NUM_REGIONS + vdev->num_regions)
+ 				return -EINVAL;
+ 
+ 			i = info.index - VFIO_PCI_NUM_REGIONS;
+ 
+ 			info.offset = VFIO_PCI_INDEX_TO_OFFSET(info.index);
+ 			info.size = vdev->region[i].size;
+ 			info.flags = vdev->region[i].flags;
+ 
+ 			ret = region_type_cap(vdev, &caps,
+ 					      vdev->region[i].type,
+ 					      vdev->region[i].subtype);
+ 			if (ret)
+ 				return ret;
  		}
  
 -		if (caps.size) {
 -			info.flags |= VFIO_REGION_INFO_FLAG_CAPS;
 -			if (info.argsz < sizeof(info) + caps.size) {
 -				info.argsz = sizeof(info) + caps.size;
 -				info.cap_offset = 0;
 -			} else {
 -				vfio_info_cap_shift(&caps, sizeof(info));
 -				ret = copy_to_user((void __user *)arg +
 -						   sizeof(info), caps.buf,
 -						   caps.size);
 -				if (ret) {
 -					kfree(caps.buf);
 -					return ret;
 -				}
 -				info.cap_offset = sizeof(info);
 -			}
 -
 -			kfree(caps.buf);
 -		}
 -
 -		return copy_to_user((void __user *)arg, &info, minsz);
 +		return copy_to_user((void __user *)arg, &info, minsz) ?
 +			-EFAULT : 0;
  
  	} else if (cmd == VFIO_DEVICE_GET_IRQ_INFO) {
  		struct vfio_irq_info info;
* Unmerged path drivers/vfio/pci/vfio_pci.c
diff --git a/drivers/vfio/pci/vfio_pci_private.h b/drivers/vfio/pci/vfio_pci_private.h
index 7958f229de60..094d115d246d 100644
--- a/drivers/vfio/pci/vfio_pci_private.h
+++ b/drivers/vfio/pci/vfio_pci_private.h
@@ -14,6 +14,7 @@
 #include <linux/mutex.h>
 #include <linux/pci.h>
 #include <linux/irqbypass.h>
+#include <linux/types.h>
 
 #ifndef VFIO_PCI_PRIVATE_H
 #define VFIO_PCI_PRIVATE_H
@@ -33,6 +34,25 @@ struct vfio_pci_irq_ctx {
 	struct irq_bypass_producer	producer;
 };
 
+struct vfio_pci_device;
+struct vfio_pci_region;
+
+struct vfio_pci_regops {
+	size_t	(*rw)(struct vfio_pci_device *vdev, char __user *buf,
+		      size_t count, loff_t *ppos, bool iswrite);
+	void	(*release)(struct vfio_pci_device *vdev,
+			   struct vfio_pci_region *region);
+};
+
+struct vfio_pci_region {
+	u32				type;
+	u32				subtype;
+	const struct vfio_pci_regops	*ops;
+	void				*data;
+	size_t				size;
+	u32				flags;
+};
+
 struct vfio_pci_device {
 	struct pci_dev		*pdev;
 	void __iomem		*barmap[PCI_STD_RESOURCE_END + 1];
@@ -45,6 +65,8 @@ struct vfio_pci_device {
 	struct vfio_pci_irq_ctx	*ctx;
 	int			num_ctx;
 	int			irq_type;
+	int			num_regions;
+	struct vfio_pci_region	*region;
 	u8			msi_qmax;
 	u8			msix_bar;
 	u16			msix_size;
@@ -95,4 +117,9 @@ extern void vfio_pci_virqfd_exit(void);
 
 extern int vfio_config_init(struct vfio_pci_device *vdev);
 extern void vfio_config_free(struct vfio_pci_device *vdev);
+
+extern int vfio_pci_register_dev_region(struct vfio_pci_device *vdev,
+					unsigned int type, unsigned int subtype,
+					const struct vfio_pci_regops *ops,
+					size_t size, u32 flags, void *data);
 #endif /* VFIO_PCI_PRIVATE_H */
