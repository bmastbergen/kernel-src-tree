md/raid10: add failfast handling for writes.

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [md] raid10: add failfast handling for writes (Jes Sorensen) [1380016]
Rebuild_FUZZ: 95.24%
commit-author NeilBrown <neilb@suse.com>
commit 1919cbb23bf1b3e0fdb7b6edfb7369f920744087
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/1919cbb2.failed

When writing to a fastfail device, we use MD_FASTFAIL unless
it is the only device being written to.  For
resync/recovery, assume there was a working device to read
from so always use MD_FASTFAIL.

If a write for resync/recovery fails, we just fail the
device - there is not much else to do.

If a normal write fails, but the device cannot be marked
Faulty (must be only one left), we queue for write error
handling which calls narrow_write_error() to write the block
synchronously without any failfast flags.

	Signed-off-by: NeilBrown <neilb@suse.com>
	Signed-off-by: Shaohua Li <shli@fb.com>
(cherry picked from commit 1919cbb23bf1b3e0fdb7b6edfb7369f920744087)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/raid10.c
diff --cc drivers/md/raid10.c
index 9848c5d0edf0,525ca9923707..000000000000
--- a/drivers/md/raid10.c
+++ b/drivers/md/raid10.c
@@@ -447,6 -451,10 +448,13 @@@ static void raid10_end_write_request(st
  	struct r10conf *conf = r10_bio->mddev->private;
  	int slot, repl;
  	struct md_rdev *rdev = NULL;
++<<<<<<< HEAD
++=======
+ 	struct bio *to_put = NULL;
+ 	bool discard_error;
+ 
+ 	discard_error = bio->bi_error && bio_op(bio) == REQ_OP_DISCARD;
++>>>>>>> 1919cbb23bf1 (md/raid10: add failfast handling for writes.)
  
  	dev = find_bio_disk(conf, r10_bio, bio, &slot, &repl);
  
@@@ -1502,10 -1409,19 +1528,17 @@@ retry_write
  							      rdev));
  			mbio->bi_bdev = rdev->bdev;
  			mbio->bi_end_io	= raid10_end_write_request;
++<<<<<<< HEAD
 +			mbio->bi_rw =
 +				WRITE | do_sync | do_fua | do_discard | do_same;
++=======
+ 			bio_set_op_attrs(mbio, op, do_sync | do_fua);
+ 			if (test_bit(FailFast, &conf->mirrors[d].rdev->flags) &&
+ 			    enough(conf, d))
+ 				mbio->bi_opf |= MD_FAILFAST;
++>>>>>>> 1919cbb23bf1 (md/raid10: add failfast handling for writes.)
  			mbio->bi_private = r10_bio;
  
 -			if (conf->mddev->gendisk)
 -				trace_block_bio_remap(bdev_get_queue(mbio->bi_bdev),
 -						      mbio, disk_devt(conf->mddev->gendisk),
 -						      r10_bio->sector);
 -			/* flush_pending_writes() needs access to the rdev so...*/
 -			mbio->bi_bdev = (void*)rdev;
 -
  			atomic_inc(&r10_bio->remaining);
  
  			cb = blk_check_plugged(raid10_unplug, mddev,
@@@ -2134,7 -2075,9 +2167,13 @@@ static void sync_request_write(struct m
  		atomic_inc(&r10_bio->remaining);
  		md_sync_acct(conf->mirrors[d].rdev->bdev, bio_sectors(tbio));
  
++<<<<<<< HEAD
 +		tbio->bi_sector += conf->mirrors[d].rdev->data_offset;
++=======
+ 		if (test_bit(FailFast, &conf->mirrors[d].rdev->flags))
+ 			tbio->bi_opf |= MD_FAILFAST;
+ 		tbio->bi_iter.bi_sector += conf->mirrors[d].rdev->data_offset;
++>>>>>>> 1919cbb23bf1 (md/raid10: add failfast handling for writes.)
  		tbio->bi_bdev = conf->mirrors[d].rdev->bdev;
  		generic_make_request(tbio);
  	}
@@@ -3357,10 -3365,11 +3396,18 @@@ static sector_t raid10_sync_request(str
  			biolist = bio;
  			bio->bi_private = r10_bio;
  			bio->bi_end_io = end_sync_write;
++<<<<<<< HEAD
 +			bio->bi_rw = WRITE;
 +			bio->bi_sector = sector +
 +				conf->mirrors[d].replacement->data_offset;
 +			bio->bi_bdev = conf->mirrors[d].replacement->bdev;
++=======
+ 			bio_set_op_attrs(bio, REQ_OP_WRITE, 0);
+ 			if (test_bit(FailFast, &conf->mirrors[d].rdev->flags))
+ 				bio->bi_opf |= MD_FAILFAST;
+ 			bio->bi_iter.bi_sector = sector + rdev->data_offset;
+ 			bio->bi_bdev = rdev->bdev;
++>>>>>>> 1919cbb23bf1 (md/raid10: add failfast handling for writes.)
  			count++;
  		}
  
* Unmerged path drivers/md/raid10.c
