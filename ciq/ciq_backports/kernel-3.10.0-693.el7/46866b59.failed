perf/x86/intel/uncore: Add support for the Intel Skylake client uncore PMU

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Kan Liang <kan.liang@intel.com>
commit 46866b59dfbe9bf99bb1323ce1f3fd2073a81aa3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/46866b59.failed

This patch adds full support for Intel SKL client uncore PMU:

 - Add support for SKL client CPU uncore PMU, which is similar to the
   BDW client PMU driver. (There are some differences in CBOX numbering
   and uncore control MSR.)
 - Add new support for SkyLake Mobile uncore PMUs, for both CPU and PCI
   uncore functionality.

	Signed-off-by: Kan Liang <kan.liang@intel.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
	Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
	Cc: Jiri Olsa <jolsa@redhat.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Stephane Eranian <eranian@google.com>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Vince Weaver <vincent.weaver@maine.edu>
Link: http://lkml.kernel.org/r/1467208912-8179-1-git-send-email-kan.liang@intel.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 46866b59dfbe9bf99bb1323ce1f3fd2073a81aa3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/events/intel/uncore.c
diff --cc arch/x86/events/intel/uncore.c
index 53ff22fa4cd0,59b4974c697f..000000000000
--- a/arch/x86/events/intel/uncore.c
+++ b/arch/x86/events/intel/uncore.c
@@@ -1398,23 -1317,125 +1398,119 @@@ static int __init uncore_cpumask_init(b
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ #define X86_UNCORE_MODEL_MATCH(model, init)	\
+ 	{ X86_VENDOR_INTEL, 6, model, X86_FEATURE_ANY, (unsigned long)&init }
+ 
+ struct intel_uncore_init_fun {
+ 	void	(*cpu_init)(void);
+ 	int	(*pci_init)(void);
+ };
+ 
+ static const struct intel_uncore_init_fun nhm_uncore_init __initconst = {
+ 	.cpu_init = nhm_uncore_cpu_init,
+ };
+ 
+ static const struct intel_uncore_init_fun snb_uncore_init __initconst = {
+ 	.cpu_init = snb_uncore_cpu_init,
+ 	.pci_init = snb_uncore_pci_init,
+ };
+ 
+ static const struct intel_uncore_init_fun ivb_uncore_init __initconst = {
+ 	.cpu_init = snb_uncore_cpu_init,
+ 	.pci_init = ivb_uncore_pci_init,
+ };
+ 
+ static const struct intel_uncore_init_fun hsw_uncore_init __initconst = {
+ 	.cpu_init = snb_uncore_cpu_init,
+ 	.pci_init = hsw_uncore_pci_init,
+ };
+ 
+ static const struct intel_uncore_init_fun bdw_uncore_init __initconst = {
+ 	.cpu_init = snb_uncore_cpu_init,
+ 	.pci_init = bdw_uncore_pci_init,
+ };
+ 
+ static const struct intel_uncore_init_fun snbep_uncore_init __initconst = {
+ 	.cpu_init = snbep_uncore_cpu_init,
+ 	.pci_init = snbep_uncore_pci_init,
+ };
+ 
+ static const struct intel_uncore_init_fun nhmex_uncore_init __initconst = {
+ 	.cpu_init = nhmex_uncore_cpu_init,
+ };
+ 
+ static const struct intel_uncore_init_fun ivbep_uncore_init __initconst = {
+ 	.cpu_init = ivbep_uncore_cpu_init,
+ 	.pci_init = ivbep_uncore_pci_init,
+ };
+ 
+ static const struct intel_uncore_init_fun hswep_uncore_init __initconst = {
+ 	.cpu_init = hswep_uncore_cpu_init,
+ 	.pci_init = hswep_uncore_pci_init,
+ };
+ 
+ static const struct intel_uncore_init_fun bdx_uncore_init __initconst = {
+ 	.cpu_init = bdx_uncore_cpu_init,
+ 	.pci_init = bdx_uncore_pci_init,
+ };
+ 
+ static const struct intel_uncore_init_fun knl_uncore_init __initconst = {
+ 	.cpu_init = knl_uncore_cpu_init,
+ 	.pci_init = knl_uncore_pci_init,
+ };
+ 
+ static const struct intel_uncore_init_fun skl_uncore_init __initconst = {
+ 	.cpu_init = skl_uncore_cpu_init,
+ 	.pci_init = skl_uncore_pci_init,
+ };
+ 
+ static const struct x86_cpu_id intel_uncore_match[] __initconst = {
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_NEHALEM_EP,	  nhm_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_NEHALEM,	  nhm_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_WESTMERE,	  nhm_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_WESTMERE_EP,	  nhm_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_SANDYBRIDGE,	  snb_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_IVYBRIDGE,	  ivb_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_HASWELL_CORE,	  hsw_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_HASWELL_ULT,	  hsw_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_HASWELL_GT3E,	  hsw_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_BROADWELL_CORE, bdw_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_BROADWELL_GT3E, bdw_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_SANDYBRIDGE_X,  snbep_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_NEHALEM_EX,	  nhmex_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_WESTMERE_EX,	  nhmex_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_IVYBRIDGE_X,	  ivbep_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_HASWELL_X,	  hswep_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_BROADWELL_X,	  bdx_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_BROADWELL_XEON_D, bdx_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_XEON_PHI_KNL,	  knl_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_SKYLAKE_DESKTOP,skl_uncore_init),
+ 	X86_UNCORE_MODEL_MATCH(INTEL_FAM6_SKYLAKE_MOBILE, skl_uncore_init),
+ 	{},
+ };
+ 
+ MODULE_DEVICE_TABLE(x86cpu, intel_uncore_match);
+ 
++>>>>>>> 46866b59dfbe (perf/x86/intel/uncore: Add support for the Intel Skylake client uncore PMU)
  static int __init intel_uncore_init(void)
  {
 -	const struct x86_cpu_id *id;
 -	struct intel_uncore_init_fun *uncore_init;
 -	int pret = 0, cret = 0, ret;
 +	int pret, cret, ret;
  
 -	id = x86_match_cpu(intel_uncore_match);
 -	if (!id)
 +	if (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL)
  		return -ENODEV;
  
 -	if (boot_cpu_has(X86_FEATURE_HYPERVISOR))
 +	if (cpu_has_hypervisor)
  		return -ENODEV;
  
 -	max_packages = topology_max_packages();
 +	if (is_kdump_kernel())
 +		return -ENODEV;
  
 -	uncore_init = (struct intel_uncore_init_fun *)id->driver_data;
 -	if (uncore_init->pci_init) {
 -		pret = uncore_init->pci_init();
 -		if (!pret)
 -			pret = uncore_pci_init();
 -	}
 +	max_packages = topology_max_packages();
  
 -	if (uncore_init->cpu_init) {
 -		uncore_init->cpu_init();
 -		cret = uncore_cpu_init();
 -	}
 +	pret = uncore_pci_init();
 +	cret = uncore_cpu_init();
  
  	if (cret && pret)
  		return -ENODEV;
* Unmerged path arch/x86/events/intel/uncore.c
diff --git a/arch/x86/events/intel/uncore.h b/arch/x86/events/intel/uncore.h
index 66c3a3657a10..d6063e438158 100644
--- a/arch/x86/events/intel/uncore.h
+++ b/arch/x86/events/intel/uncore.h
@@ -364,6 +364,7 @@ int bdw_uncore_pci_init(void);
 int skl_uncore_pci_init(void);
 void snb_uncore_cpu_init(void);
 void nhm_uncore_cpu_init(void);
+void skl_uncore_cpu_init(void);
 int snb_pci2phy_map_init(int devid);
 
 /* perf_event_intel_uncore_snbep.c */
diff --git a/arch/x86/events/intel/uncore_snb.c b/arch/x86/events/intel/uncore_snb.c
index 99408ef660a0..c5032bdb3905 100644
--- a/arch/x86/events/intel/uncore_snb.c
+++ b/arch/x86/events/intel/uncore_snb.c
@@ -1,4 +1,4 @@
-/* Nehalem/SandBridge/Haswell uncore support */
+/* Nehalem/SandBridge/Haswell/Broadwell/Skylake uncore support */
 #include "uncore.h"
 
 /* Uncore IMC PCI IDs */
@@ -9,6 +9,7 @@
 #define PCI_DEVICE_ID_INTEL_HSW_U_IMC	0x0a04
 #define PCI_DEVICE_ID_INTEL_BDW_IMC	0x1604
 #define PCI_DEVICE_ID_INTEL_SKL_IMC	0x191f
+#define PCI_DEVICE_ID_INTEL_SKL_U_IMC	0x190c
 
 /* SNB event control */
 #define SNB_UNC_CTL_EV_SEL_MASK			0x000000ff
@@ -64,6 +65,10 @@
 #define NHM_UNC_PERFEVTSEL0                     0x3c0
 #define NHM_UNC_UNCORE_PMC0                     0x3b0
 
+/* SKL uncore global control */
+#define SKL_UNC_PERF_GLOBAL_CTL			0xe01
+#define SKL_UNC_GLOBAL_CTL_CORE_ALL		((1 << 5) - 1)
+
 DEFINE_UNCORE_FORMAT_ATTR(event, event, "config:0-7");
 DEFINE_UNCORE_FORMAT_ATTR(umask, umask, "config:8-15");
 DEFINE_UNCORE_FORMAT_ATTR(edge, edge, "config:18");
@@ -179,6 +184,60 @@ void snb_uncore_cpu_init(void)
 		snb_uncore_cbox.num_boxes = boot_cpu_data.x86_max_cores;
 }
 
+static void skl_uncore_msr_init_box(struct intel_uncore_box *box)
+{
+	if (box->pmu->pmu_idx == 0) {
+		wrmsrl(SKL_UNC_PERF_GLOBAL_CTL,
+			SNB_UNC_GLOBAL_CTL_EN | SKL_UNC_GLOBAL_CTL_CORE_ALL);
+	}
+}
+
+static void skl_uncore_msr_exit_box(struct intel_uncore_box *box)
+{
+	if (box->pmu->pmu_idx == 0)
+		wrmsrl(SKL_UNC_PERF_GLOBAL_CTL, 0);
+}
+
+static struct intel_uncore_ops skl_uncore_msr_ops = {
+	.init_box	= skl_uncore_msr_init_box,
+	.exit_box	= skl_uncore_msr_exit_box,
+	.disable_event	= snb_uncore_msr_disable_event,
+	.enable_event	= snb_uncore_msr_enable_event,
+	.read_counter	= uncore_msr_read_counter,
+};
+
+static struct intel_uncore_type skl_uncore_cbox = {
+	.name		= "cbox",
+	.num_counters   = 4,
+	.num_boxes	= 5,
+	.perf_ctr_bits	= 44,
+	.fixed_ctr_bits	= 48,
+	.perf_ctr	= SNB_UNC_CBO_0_PER_CTR0,
+	.event_ctl	= SNB_UNC_CBO_0_PERFEVTSEL0,
+	.fixed_ctr	= SNB_UNC_FIXED_CTR,
+	.fixed_ctl	= SNB_UNC_FIXED_CTR_CTRL,
+	.single_fixed	= 1,
+	.event_mask	= SNB_UNC_RAW_EVENT_MASK,
+	.msr_offset	= SNB_UNC_CBO_MSR_OFFSET,
+	.ops		= &skl_uncore_msr_ops,
+	.format_group	= &snb_uncore_format_group,
+	.event_descs	= snb_uncore_events,
+};
+
+static struct intel_uncore_type *skl_msr_uncores[] = {
+	&skl_uncore_cbox,
+	&snb_uncore_arb,
+	NULL,
+};
+
+void skl_uncore_cpu_init(void)
+{
+	uncore_msr_uncores = skl_msr_uncores;
+	if (skl_uncore_cbox.num_boxes > boot_cpu_data.x86_max_cores)
+		skl_uncore_cbox.num_boxes = boot_cpu_data.x86_max_cores;
+	snb_uncore_arb.ops = &skl_uncore_msr_ops;
+}
+
 enum {
 	SNB_PCI_UNCORE_IMC,
 };
@@ -544,6 +603,11 @@ static const struct pci_device_id skl_uncore_pci_ids[] = {
 		PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_SKL_IMC),
 		.driver_data = UNCORE_PCI_DEV_DATA(SNB_PCI_UNCORE_IMC, 0),
 	},
+	{ /* IMC */
+		PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_SKL_U_IMC),
+		.driver_data = UNCORE_PCI_DEV_DATA(SNB_PCI_UNCORE_IMC, 0),
+	},
+
 	{ /* end: all zeroes */ },
 };
 
@@ -587,6 +651,7 @@ static const struct imc_uncore_pci_dev desktop_imc_pci_ids[] = {
 	IMC_DEV(HSW_U_IMC, &hsw_uncore_pci_driver),  /* 4th Gen Core ULT Mobile Processor */
 	IMC_DEV(BDW_IMC, &bdw_uncore_pci_driver),    /* 5th Gen Core U */
 	IMC_DEV(SKL_IMC, &skl_uncore_pci_driver),    /* 6th Gen Core */
+	IMC_DEV(SKL_U_IMC, &skl_uncore_pci_driver),  /* 6th Gen Core U */
 	{  /* end marker */ }
 };
 
