xprtrmda: Report address of frmr, not mw

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Chuck Lever <chuck.lever@oracle.com>
commit eeb30613e1ef82236a058b02d645cad812b309ae
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/eeb30613.failed

Tie frwr debugging messages together by always reporting the address
of the frwr.

	Signed-off-by: Chuck Lever <chuck.lever@oracle.com>
	Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
(cherry picked from commit eeb30613e1ef82236a058b02d645cad812b309ae)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sunrpc/xprtrdma/frwr_ops.c
diff --cc net/sunrpc/xprtrdma/frwr_ops.c
index 0efe42a52a2b,ad70a873ea62..000000000000
--- a/net/sunrpc/xprtrdma/frwr_ops.c
+++ b/net/sunrpc/xprtrdma/frwr_ops.c
@@@ -181,11 -130,75 +181,77 @@@ __frwr_release(struct rpcrdma_mw *r
  {
  	int rc;
  
 -	/* Ensure MW is not on any rl_registered list */
 -	if (!list_empty(&r->mw_list))
 -		list_del(&r->mw_list);
 -
  	rc = ib_dereg_mr(r->frmr.fr_mr);
  	if (rc)
++<<<<<<< HEAD
 +		dprintk("RPC:       %s: ib_dereg_mr status %i\n",
 +			__func__, rc);
 +	kfree(r->frmr.sg);
++=======
+ 		pr_err("rpcrdma: final ib_dereg_mr for %p returned %i\n",
+ 		       r, rc);
+ 	kfree(r->mw_sg);
+ 	kfree(r);
+ }
+ 
+ static int
+ __frwr_reset_mr(struct rpcrdma_ia *ia, struct rpcrdma_mw *r)
+ {
+ 	struct rpcrdma_frmr *f = &r->frmr;
+ 	int rc;
+ 
+ 	rc = ib_dereg_mr(f->fr_mr);
+ 	if (rc) {
+ 		pr_warn("rpcrdma: ib_dereg_mr status %d, frwr %p orphaned\n",
+ 			rc, r);
+ 		return rc;
+ 	}
+ 
+ 	f->fr_mr = ib_alloc_mr(ia->ri_pd, IB_MR_TYPE_MEM_REG,
+ 			       ia->ri_max_frmr_depth);
+ 	if (IS_ERR(f->fr_mr)) {
+ 		pr_warn("rpcrdma: ib_alloc_mr status %ld, frwr %p orphaned\n",
+ 			PTR_ERR(f->fr_mr), r);
+ 		return PTR_ERR(f->fr_mr);
+ 	}
+ 
+ 	dprintk("RPC:       %s: recovered FRMR %p\n", __func__, f);
+ 	f->fr_state = FRMR_IS_INVALID;
+ 	return 0;
+ }
+ 
+ /* Reset of a single FRMR. Generate a fresh rkey by replacing the MR.
+  *
+  * There's no recovery if this fails. The FRMR is abandoned, but
+  * remains in rb_all. It will be cleaned up when the transport is
+  * destroyed.
+  */
+ static void
+ frwr_op_recover_mr(struct rpcrdma_mw *mw)
+ {
+ 	struct rpcrdma_xprt *r_xprt = mw->mw_xprt;
+ 	struct rpcrdma_ia *ia = &r_xprt->rx_ia;
+ 	int rc;
+ 
+ 	rc = __frwr_reset_mr(ia, mw);
+ 	ib_dma_unmap_sg(ia->ri_device, mw->mw_sg, mw->mw_nents, mw->mw_dir);
+ 	if (rc)
+ 		goto out_release;
+ 
+ 	rpcrdma_put_mw(r_xprt, mw);
+ 	r_xprt->rx_stats.mrs_recovered++;
+ 	return;
+ 
+ out_release:
+ 	pr_err("rpcrdma: FRMR reset failed %d, %p release\n", rc, mw);
+ 	r_xprt->rx_stats.mrs_orphaned++;
+ 
+ 	spin_lock(&r_xprt->rx_buf.rb_mwlock);
+ 	list_del(&mw->mw_all);
+ 	spin_unlock(&r_xprt->rx_buf.rb_mwlock);
+ 
+ 	frwr_op_release_mr(mw);
++>>>>>>> eeb30613e1ef (xprtrmda: Report address of frmr, not mw)
  }
  
  static int
@@@ -414,25 -382,22 +480,29 @@@ frwr_op_map(struct rpcrdma_xprt *r_xprt
  		    offset_in_page((seg-1)->mr_offset + (seg-1)->mr_len))
  			break;
  	}
 -	mw->mw_nents = i;
 -	mw->mw_dir = rpcrdma_data_dir(writing);
 -	if (i == 0)
 -		goto out_dmamap_err;
 +	frmr->sg_nents = i;
  
 -	dma_nents = ib_dma_map_sg(ia->ri_device,
 -				  mw->mw_sg, mw->mw_nents, mw->mw_dir);
 -	if (!dma_nents)
 -		goto out_dmamap_err;
 +	dma_nents = ib_dma_map_sg(device, frmr->sg, frmr->sg_nents, direction);
 +	if (!dma_nents) {
 +		pr_err("RPC:       %s: failed to dma map sg %p sg_nents %u\n",
 +		       __func__, frmr->sg, frmr->sg_nents);
 +		return -ENOMEM;
 +	}
  
 -	n = ib_map_mr_sg(mr, mw->mw_sg, mw->mw_nents, NULL, PAGE_SIZE);
 -	if (unlikely(n != mw->mw_nents))
 -		goto out_mapmr_err;
 +	n = ib_map_mr_sg(mr, frmr->sg, frmr->sg_nents, NULL, PAGE_SIZE);
 +	if (unlikely(n != frmr->sg_nents)) {
 +		pr_err("RPC:       %s: failed to map mr %p (%u/%u)\n",
 +		       __func__, frmr->fr_mr, n, frmr->sg_nents);
 +		rc = n < 0 ? n : -EINVAL;
 +		goto out_senderr;
 +	}
  
  	dprintk("RPC:       %s: Using frmr %p to map %u segments (%u bytes)\n",
++<<<<<<< HEAD
 +		__func__, mw, frmr->sg_nents, mr->length);
++=======
+ 		__func__, frmr, mw->mw_nents, mr->length);
++>>>>>>> eeb30613e1ef (xprtrmda: Report address of frmr, not mw)
  
  	key = (u8)(mr->rkey & 0x000000FF);
  	ib_update_fast_reg_key(mr, ++key);
@@@ -572,16 -533,31 +644,28 @@@ frwr_op_unmap_sync(struct rpcrdma_xprt 
  	 * them to the free MW list.
  	 */
  unmap:
++<<<<<<< HEAD
 +	for (i = 0, nchunks = req->rl_nchunks; nchunks; nchunks--) {
 +		seg = &req->rl_segments[i];
++=======
+ 	list_for_each_entry_safe(mw, tmp, &req->rl_registered, mw_list) {
+ 		dprintk("RPC:       %s: unmapping frmr %p\n",
+ 			__func__, &mw->frmr);
+ 		list_del_init(&mw->mw_list);
+ 		ib_dma_unmap_sg(ia->ri_device,
+ 				mw->mw_sg, mw->mw_nents, mw->mw_dir);
+ 		rpcrdma_put_mw(r_xprt, mw);
+ 	}
+ 	return;
++>>>>>>> eeb30613e1ef (xprtrmda: Report address of frmr, not mw)
  
 -reset_mrs:
 -	pr_err("rpcrdma: FRMR invalidate ib_post_send returned %i\n", rc);
 -	rdma_disconnect(ia->ri_id);
 +		__frwr_dma_unmap(r_xprt, seg, rc);
  
 -	/* Find and reset the MRs in the LOCAL_INV WRs that did not
 -	 * get posted. This is synchronous, and slow.
 -	 */
 -	list_for_each_entry(mw, &req->rl_registered, mw_list) {
 -		f = &mw->frmr;
 -		if (mw->frmr.fr_mr->rkey == bad_wr->ex.invalidate_rkey) {
 -			__frwr_reset_mr(ia, mw);
 -			bad_wr = bad_wr->next;
 -		}
 +		i += seg->mr_nsegs;
 +		seg->mr_nsegs = 0;
  	}
 -	goto unmap;
 +
 +	req->rl_nchunks = 0;
  }
  
  /* Use a slow, safe mechanism to invalidate all memory regions
* Unmerged path net/sunrpc/xprtrdma/frwr_ops.c
