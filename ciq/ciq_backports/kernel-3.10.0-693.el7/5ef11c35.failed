mm: ASLR: use get_random_long()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [mm] aslr: use get_random_long() (Bhupesh Sharma) [1412802]
Rebuild_FUZZ: 93.10%
commit-author Daniel Cashman <dcashman@android.com>
commit 5ef11c35ce86b94bfb878b684de4cdaf96f54b2f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/5ef11c35.failed

Replace calls to get_random_int() followed by a cast to (unsigned long)
with calls to get_random_long().  Also address shifting bug which, in
case of x86 removed entropy mask for mmap_rnd_bits values > 31 bits.

	Signed-off-by: Daniel Cashman <dcashman@android.com>
	Acked-by: Kees Cook <keescook@chromium.org>
	Cc: "Theodore Ts'o" <tytso@mit.edu>
	Cc: Arnd Bergmann <arnd@arndb.de>
	Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Will Deacon <will.deacon@arm.com>
	Cc: Ralf Baechle <ralf@linux-mips.org>
	Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
	Cc: Paul Mackerras <paulus@samba.org>
	Cc: Michael Ellerman <mpe@ellerman.id.au>
	Cc: David S. Miller <davem@davemloft.net>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: H. Peter Anvin <hpa@zytor.com>
	Cc: Al Viro <viro@zeniv.linux.org.uk>
	Cc: Nick Kralevich <nnk@google.com>
	Cc: Jeff Vander Stoep <jeffv@google.com>
	Cc: Mark Salyzyn <salyzyn@android.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 5ef11c35ce86b94bfb878b684de4cdaf96f54b2f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm/mm/mmap.c
#	arch/arm64/mm/mmap.c
#	arch/mips/mm/mmap.c
#	arch/powerpc/mm/mmap_64.c
#	arch/x86/mm/mmap.c
diff --cc arch/arm/mm/mmap.c
index f0ef2f7d4ad7,66353caa35b9..000000000000
--- a/arch/arm/mm/mmap.c
+++ b/arch/arm/mm/mmap.c
@@@ -169,6 -169,15 +169,18 @@@ arch_get_unmapped_area_topdown(struct f
  	return addr;
  }
  
++<<<<<<< HEAD
++=======
+ unsigned long arch_mmap_rnd(void)
+ {
+ 	unsigned long rnd;
+ 
+ 	rnd = get_random_long() & ((1UL << mmap_rnd_bits) - 1);
+ 
+ 	return rnd << PAGE_SHIFT;
+ }
+ 
++>>>>>>> 5ef11c35ce86 (mm: ASLR: use get_random_long())
  void arch_pick_mmap_layout(struct mm_struct *mm)
  {
  	unsigned long random_factor = 0UL;
diff --cc arch/arm64/mm/mmap.c
index 7c7be7855638,232f787a088a..000000000000
--- a/arch/arm64/mm/mmap.c
+++ b/arch/arm64/mm/mmap.c
@@@ -47,25 -47,20 +47,35 @@@ static int mmap_is_legacy(void
  	return sysctl_legacy_va_layout;
  }
  
 -unsigned long arch_mmap_rnd(void)
 +/*
 + * Since get_random_int() returns the same value within a 1 jiffy window, we
 + * will almost always get the same randomisation for the stack and mmap
 + * region. This will mean the relative distance between stack and mmap will be
 + * the same.
 + *
 + * To avoid this we can shift the randomness by 1 bit.
 + */
 +static unsigned long mmap_rnd(void)
  {
 -	unsigned long rnd;
 +	unsigned long rnd = 0;
 +
++<<<<<<< HEAD
 +	if (current->flags & PF_RANDOMIZE)
 +		rnd = (long)get_random_int() & (STACK_RND_MASK >> 1);
  
 +	return rnd << (PAGE_SHIFT + 1);
++=======
+ #ifdef CONFIG_COMPAT
+ 	if (test_thread_flag(TIF_32BIT))
+ 		rnd = get_random_long() & ((1UL << mmap_rnd_compat_bits) - 1);
+ 	else
+ #endif
+ 		rnd = get_random_long() & ((1UL << mmap_rnd_bits) - 1);
+ 	return rnd << PAGE_SHIFT;
++>>>>>>> 5ef11c35ce86 (mm: ASLR: use get_random_long())
  }
  
 -static unsigned long mmap_base(unsigned long rnd)
 +static unsigned long mmap_base(void)
  {
  	unsigned long gap = rlimit(RLIMIT_STACK);
  
diff --cc arch/mips/mm/mmap.c
index 7e5fe2790d8a,353037699512..000000000000
--- a/arch/mips/mm/mmap.c
+++ b/arch/mips/mm/mmap.c
@@@ -142,6 -142,20 +142,23 @@@ unsigned long arch_get_unmapped_area_to
  			addr0, len, pgoff, flags, DOWN);
  }
  
++<<<<<<< HEAD
++=======
+ unsigned long arch_mmap_rnd(void)
+ {
+ 	unsigned long rnd;
+ 
+ 	rnd = get_random_long();
+ 	rnd <<= PAGE_SHIFT;
+ 	if (TASK_IS_32BIT_ADDR)
+ 		rnd &= 0xfffffful;
+ 	else
+ 		rnd &= 0xffffffful;
+ 
+ 	return rnd;
+ }
+ 
++>>>>>>> 5ef11c35ce86 (mm: ASLR: use get_random_long())
  void arch_pick_mmap_layout(struct mm_struct *mm)
  {
  	unsigned long random_factor = 0UL;
diff --cc arch/powerpc/mm/mmap_64.c
index 67a42ed0d2fc,4087705ba90f..000000000000
--- a/arch/powerpc/mm/mmap_64.c
+++ b/arch/powerpc/mm/mmap_64.c
@@@ -53,17 -53,16 +53,27 @@@ static inline int mmap_is_legacy(void
  	return sysctl_legacy_va_layout;
  }
  
 -unsigned long arch_mmap_rnd(void)
 +static unsigned long mmap_rnd(void)
  {
++<<<<<<< HEAD:arch/powerpc/mm/mmap_64.c
 +	unsigned long rnd = 0;
++=======
+ 	unsigned long rnd;
+ 
+ 	/* 8MB for 32bit, 1GB for 64bit */
+ 	if (is_32bit_task())
+ 		rnd = get_random_long() % (1<<(23-PAGE_SHIFT));
+ 	else
+ 		rnd = get_random_long() % (1UL<<(30-PAGE_SHIFT));
++>>>>>>> 5ef11c35ce86 (mm: ASLR: use get_random_long()):arch/powerpc/mm/mmap.c
  
 +	if (current->flags & PF_RANDOMIZE) {
 +		/* 8MB for 32bit, 1GB for 64bit */
 +		if (is_32bit_task())
 +			rnd = (long)(get_random_int() % (1<<(23-PAGE_SHIFT)));
 +		else
 +			rnd = (long)(get_random_int() % (1<<(30-PAGE_SHIFT)));
 +	}
  	return rnd << PAGE_SHIFT;
  }
  
diff --cc arch/x86/mm/mmap.c
index 0e426764499a,72bb52f93c3d..000000000000
--- a/arch/x86/mm/mmap.c
+++ b/arch/x86/mm/mmap.c
@@@ -69,14 -69,14 +69,24 @@@ static unsigned long mmap_rnd(void
  {
  	unsigned long rnd;
  
 +	/*
 +	 *  8 bits of randomness in 32bit mmaps, 20 address space bits
 +	 * 28 bits of randomness in 64bit mmaps, 40 address space bits
 +	 */
  	if (mmap_is_ia32())
++<<<<<<< HEAD
 +		rnd = (unsigned long)get_random_int() % (1<<8);
 +	else
 +		rnd = (unsigned long)get_random_int() % (1<<28);
++=======
+ #ifdef CONFIG_COMPAT
+ 		rnd = get_random_long() & ((1UL << mmap_rnd_compat_bits) - 1);
+ #else
+ 		rnd = get_random_long() & ((1UL << mmap_rnd_bits) - 1);
+ #endif
+ 	else
+ 		rnd = get_random_long() & ((1UL << mmap_rnd_bits) - 1);
++>>>>>>> 5ef11c35ce86 (mm: ASLR: use get_random_long())
  
  	return rnd << PAGE_SHIFT;
  }
* Unmerged path arch/arm/mm/mmap.c
* Unmerged path arch/arm64/mm/mmap.c
* Unmerged path arch/mips/mm/mmap.c
diff --git a/arch/powerpc/kernel/process.c b/arch/powerpc/kernel/process.c
index 7f3a6ffc29aa..13e89d95565a 100644
--- a/arch/powerpc/kernel/process.c
+++ b/arch/powerpc/kernel/process.c
@@ -1626,9 +1626,9 @@ static inline unsigned long brk_rnd(void)
 
 	/* 8MB for 32bit, 1GB for 64bit */
 	if (is_32bit_task())
-		rnd = (long)(get_random_int() % (1<<(23-PAGE_SHIFT)));
+		rnd = (get_random_long() % (1UL<<(23-PAGE_SHIFT)));
 	else
-		rnd = (long)(get_random_int() % (1<<(30-PAGE_SHIFT)));
+		rnd = (get_random_long() % (1UL<<(30-PAGE_SHIFT)));
 
 	return rnd << PAGE_SHIFT;
 }
* Unmerged path arch/powerpc/mm/mmap_64.c
diff --git a/arch/sparc/kernel/sys_sparc_64.c b/arch/sparc/kernel/sys_sparc_64.c
index 2daaaa6eda23..1e9e320583c7 100644
--- a/arch/sparc/kernel/sys_sparc_64.c
+++ b/arch/sparc/kernel/sys_sparc_64.c
@@ -265,7 +265,7 @@ static unsigned long mmap_rnd(void)
 	unsigned long rnd = 0UL;
 
 	if (current->flags & PF_RANDOMIZE) {
-		unsigned long val = get_random_int();
+		unsigned long val = get_random_long();
 		if (test_thread_flag(TIF_32BIT))
 			rnd = (val % (1UL << (23UL-PAGE_SHIFT)));
 		else
* Unmerged path arch/x86/mm/mmap.c
diff --git a/fs/binfmt_elf.c b/fs/binfmt_elf.c
index 4b775dc44a97..a05a49602dac 100644
--- a/fs/binfmt_elf.c
+++ b/fs/binfmt_elf.c
@@ -557,7 +557,7 @@ static unsigned long randomize_stack_top(unsigned long stack_top)
 
 	if ((current->flags & PF_RANDOMIZE) &&
 		!(current->personality & ADDR_NO_RANDOMIZE)) {
-		random_variable = (unsigned long) get_random_int();
+		random_variable = get_random_long();
 		random_variable &= STACK_RND_MASK;
 		random_variable <<= PAGE_SHIFT;
 	}
