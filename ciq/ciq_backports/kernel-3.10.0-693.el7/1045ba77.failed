net sched actions: Add support for user cookies

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [net] sched: actions: Add support for user cookies (Ivan Vecera) [1447674]
Rebuild_FUZZ: 94.51%
commit-author Jamal Hadi Salim <jhs@mojatatu.com>
commit 1045ba77a5962a22bce7777678ef46714107ea63
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/1045ba77.failed

Introduce optional 128-bit action cookie.
Like all other cookie schemes in the networking world (eg in protocols
like http or existing kernel fib protocol field, etc) the idea is to save
user state that when retrieved serves as a correlator. The kernel
_should not_ intepret it.  The user can store whatever they wish in the
128 bits.

Sample exercise(showing variable length use of cookie)

.. create an accept action with cookie a1b2c3d4
sudo $TC actions add action ok index 1 cookie a1b2c3d4

.. dump all gact actions..
sudo $TC -s actions ls action gact

    action order 0: gact action pass
     random type none pass val 0
     index 1 ref 1 bind 0 installed 5 sec used 5 sec
    Action statistics:
    Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0)
    backlog 0b 0p requeues 0
    cookie a1b2c3d4

.. bind the accept action to a filter..
sudo $TC filter add dev lo parent ffff: protocol ip prio 1 \
u32 match ip dst 127.0.0.1/32 flowid 1:1 action gact index 1

... send some traffic..
$ ping 127.0.0.1 -c 3
PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.
64 bytes from 127.0.0.1: icmp_seq=1 ttl=64 time=0.020 ms
64 bytes from 127.0.0.1: icmp_seq=2 ttl=64 time=0.027 ms
64 bytes from 127.0.0.1: icmp_seq=3 ttl=64 time=0.038 ms

	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 1045ba77a5962a22bce7777678ef46714107ea63)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/act_api.h
#	include/net/pkt_cls.h
#	include/uapi/linux/pkt_cls.h
#	net/sched/act_api.c
diff --cc include/net/act_api.h
index 11aac9abd0ca,cfa2ae33da9a..000000000000
--- a/include/net/act_api.h
+++ b/include/net/act_api.h
@@@ -7,40 -7,55 +7,81 @@@
  
  #include <net/sch_generic.h>
  #include <net/pkt_sched.h>
 -#include <net/net_namespace.h>
 -#include <net/netns/generic.h>
  
 +struct tcf_common {
 +	struct tcf_common		*tcfc_next;
 +	u32				tcfc_index;
 +	int				tcfc_refcnt;
 +	int				tcfc_bindcnt;
 +	u32				tcfc_capab;
 +	int				tcfc_action;
 +	struct tcf_t			tcfc_tm;
 +	struct gnet_stats_basic_packed	tcfc_bstats;
 +	struct gnet_stats_queue		tcfc_qstats;
 +	struct gnet_stats_rate_est64	tcfc_rate_est;
 +	spinlock_t			tcfc_lock;
 +	struct rcu_head			tcfc_rcu;
 +};
 +#define tcf_next	common.tcfc_next
 +#define tcf_index	common.tcfc_index
 +#define tcf_refcnt	common.tcfc_refcnt
 +#define tcf_bindcnt	common.tcfc_bindcnt
 +#define tcf_capab	common.tcfc_capab
 +#define tcf_action	common.tcfc_action
 +#define tcf_tm		common.tcfc_tm
 +#define tcf_bstats	common.tcfc_bstats
 +#define tcf_qstats	common.tcfc_qstats
 +#define tcf_rate_est	common.tcfc_rate_est
 +#define tcf_lock	common.tcfc_lock
 +#define tcf_rcu		common.tcfc_rcu
  
  struct tcf_hashinfo {
 -	struct hlist_head	*htab;
 +	struct tcf_common	**htab;
  	unsigned int		hmask;
 -	spinlock_t		lock;
 -	u32			index;
 +	rwlock_t		*lock;
  };
  
++<<<<<<< HEAD
++=======
+ struct tc_action_ops;
+ 
+ struct tc_action {
+ 	const struct tc_action_ops	*ops;
+ 	__u32				type; /* for backward compat(TCA_OLD_COMPAT) */
+ 	__u32				order;
+ 	struct list_head		list;
+ 	struct tcf_hashinfo		*hinfo;
+ 
+ 	struct hlist_node		tcfa_head;
+ 	u32				tcfa_index;
+ 	int				tcfa_refcnt;
+ 	int				tcfa_bindcnt;
+ 	u32				tcfa_capab;
+ 	int				tcfa_action;
+ 	struct tcf_t			tcfa_tm;
+ 	struct gnet_stats_basic_packed	tcfa_bstats;
+ 	struct gnet_stats_queue		tcfa_qstats;
+ 	struct net_rate_estimator __rcu *tcfa_rate_est;
+ 	spinlock_t			tcfa_lock;
+ 	struct rcu_head			tcfa_rcu;
+ 	struct gnet_stats_basic_cpu __percpu *cpu_bstats;
+ 	struct gnet_stats_queue __percpu *cpu_qstats;
+ 	struct tc_cookie	*act_cookie;
+ };
+ #define tcf_head	common.tcfa_head
+ #define tcf_index	common.tcfa_index
+ #define tcf_refcnt	common.tcfa_refcnt
+ #define tcf_bindcnt	common.tcfa_bindcnt
+ #define tcf_capab	common.tcfa_capab
+ #define tcf_action	common.tcfa_action
+ #define tcf_tm		common.tcfa_tm
+ #define tcf_bstats	common.tcfa_bstats
+ #define tcf_qstats	common.tcfa_qstats
+ #define tcf_rate_est	common.tcfa_rate_est
+ #define tcf_lock	common.tcfa_lock
+ #define tcf_rcu		common.tcfa_rcu
+ 
++>>>>>>> 1045ba77a596 (net sched actions: Add support for user cookies)
  static inline unsigned int tcf_hash(u32 index, unsigned int hmask)
  {
  	return index & hmask;
diff --cc include/net/pkt_cls.h
index b606c03c3836,b43077e47d35..000000000000
--- a/include/net/pkt_cls.h
+++ b/include/net/pkt_cls.h
@@@ -392,9 -427,100 +392,92 @@@ struct tc_cls_u32_offload 
  	};
  };
  
 -static inline bool tc_can_offload(const struct net_device *dev,
 -				  const struct tcf_proto *tp)
 +static inline bool tc_should_offload(struct net_device *dev)
  {
 -	const struct Qdisc *sch = tp->q;
 -	const struct Qdisc_class_ops *cops = sch->ops->cl_ops;
 -
 -	if (!(dev->features & NETIF_F_HW_TC))
 -		return false;
 -	if (!dev->netdev_ops->ndo_setup_tc)
 -		return false;
 -	if (cops && cops->tcf_cl_offload)
 -		return cops->tcf_cl_offload(tp->classid);
 -
 -	return true;
 +	return dev->netdev_ops->ndo_setup_tc;
  }
  
++<<<<<<< HEAD
++=======
+ static inline bool tc_skip_hw(u32 flags)
+ {
+ 	return (flags & TCA_CLS_FLAGS_SKIP_HW) ? true : false;
+ }
+ 
+ static inline bool tc_should_offload(const struct net_device *dev,
+ 				     const struct tcf_proto *tp, u32 flags)
+ {
+ 	if (tc_skip_hw(flags))
+ 		return false;
+ 	return tc_can_offload(dev, tp);
+ }
+ 
+ static inline bool tc_skip_sw(u32 flags)
+ {
+ 	return (flags & TCA_CLS_FLAGS_SKIP_SW) ? true : false;
+ }
+ 
+ /* SKIP_HW and SKIP_SW are mutually exclusive flags. */
+ static inline bool tc_flags_valid(u32 flags)
+ {
+ 	if (flags & ~(TCA_CLS_FLAGS_SKIP_HW | TCA_CLS_FLAGS_SKIP_SW))
+ 		return false;
+ 
+ 	if (!(flags ^ (TCA_CLS_FLAGS_SKIP_HW | TCA_CLS_FLAGS_SKIP_SW)))
+ 		return false;
+ 
+ 	return true;
+ }
+ 
+ enum tc_fl_command {
+ 	TC_CLSFLOWER_REPLACE,
+ 	TC_CLSFLOWER_DESTROY,
+ 	TC_CLSFLOWER_STATS,
+ };
+ 
+ struct tc_cls_flower_offload {
+ 	enum tc_fl_command command;
+ 	unsigned long cookie;
+ 	struct flow_dissector *dissector;
+ 	struct fl_flow_key *mask;
+ 	struct fl_flow_key *key;
+ 	struct tcf_exts *exts;
+ };
+ 
+ enum tc_matchall_command {
+ 	TC_CLSMATCHALL_REPLACE,
+ 	TC_CLSMATCHALL_DESTROY,
+ };
+ 
+ struct tc_cls_matchall_offload {
+ 	enum tc_matchall_command command;
+ 	struct tcf_exts *exts;
+ 	unsigned long cookie;
+ };
+ 
+ enum tc_clsbpf_command {
+ 	TC_CLSBPF_ADD,
+ 	TC_CLSBPF_REPLACE,
+ 	TC_CLSBPF_DESTROY,
+ 	TC_CLSBPF_STATS,
+ };
+ 
+ struct tc_cls_bpf_offload {
+ 	enum tc_clsbpf_command command;
+ 	struct tcf_exts *exts;
+ 	struct bpf_prog *prog;
+ 	const char *name;
+ 	bool exts_integrated;
+ 	u32 gen_flags;
+ };
+ 
+ 
+ /* This structure holds cookie structure that is passed from user
+  * to the kernel for actions and classifiers
+  */
+ struct tc_cookie {
+ 	u8  *data;
+ 	u32 len;
+ };
++>>>>>>> 1045ba77a596 (net sched actions: Add support for user cookies)
  #endif
diff --cc include/uapi/linux/pkt_cls.h
index 3abfe7f00823,345551e71410..000000000000
--- a/include/uapi/linux/pkt_cls.h
+++ b/include/uapi/linux/pkt_cls.h
@@@ -4,80 -4,7 +4,84 @@@
  #include <linux/types.h>
  #include <linux/pkt_sched.h>
  
++<<<<<<< HEAD
 +/* I think i could have done better macros ; for now this is stolen from
 + * some arch/mips code - jhs
 +*/
 +#define _TC_MAKE32(x) ((x))
 +
 +#define _TC_MAKEMASK1(n) (_TC_MAKE32(1) << _TC_MAKE32(n))
 +#define _TC_MAKEMASK(v,n) (_TC_MAKE32((_TC_MAKE32(1)<<(v))-1) << _TC_MAKE32(n))
 +#define _TC_MAKEVALUE(v,n) (_TC_MAKE32(v) << _TC_MAKE32(n))
 +#define _TC_GETVALUE(v,n,m) ((_TC_MAKE32(v) & _TC_MAKE32(m)) >> _TC_MAKE32(n))
 +
 +/* verdict bit breakdown 
 + *
 +bit 0: when set -> this packet has been munged already
 +
 +bit 1: when set -> It is ok to munge this packet
 +
 +bit 2,3,4,5: Reclassify counter - sort of reverse TTL - if exceeded
 +assume loop
 +
 +bit 6,7: Where this packet was last seen 
 +0: Above the transmit example at the socket level
 +1: on the Ingress
 +2: on the Egress
 +
 +bit 8: when set --> Request not to classify on ingress. 
 +
 +bits 9,10,11: redirect counter -  redirect TTL. Loop avoidance
 +
 + *
 + * */
 +
 +#ifndef __KERNEL__
 +/* backwards compat for userspace only */
 +#define TC_MUNGED          _TC_MAKEMASK1(0)
 +#define SET_TC_MUNGED(v)   ( TC_MUNGED | (v & ~TC_MUNGED))
 +#define CLR_TC_MUNGED(v)   ( v & ~TC_MUNGED)
 +
 +#define TC_OK2MUNGE        _TC_MAKEMASK1(1)
 +#define SET_TC_OK2MUNGE(v)   ( TC_OK2MUNGE | (v & ~TC_OK2MUNGE))
 +#define CLR_TC_OK2MUNGE(v)   ( v & ~TC_OK2MUNGE)
 +
 +#define S_TC_VERD          _TC_MAKE32(2)
 +#define M_TC_VERD          _TC_MAKEMASK(4,S_TC_VERD)
 +#define G_TC_VERD(x)       _TC_GETVALUE(x,S_TC_VERD,M_TC_VERD)
 +#define V_TC_VERD(x)       _TC_MAKEVALUE(x,S_TC_VERD)
 +#define SET_TC_VERD(v,n)   ((V_TC_VERD(n)) | (v & ~M_TC_VERD))
 +#endif
 +
 +#define S_TC_FROM          _TC_MAKE32(6)
 +#define M_TC_FROM          _TC_MAKEMASK(2,S_TC_FROM)
 +#define G_TC_FROM(x)       _TC_GETVALUE(x,S_TC_FROM,M_TC_FROM)
 +#define V_TC_FROM(x)       _TC_MAKEVALUE(x,S_TC_FROM)
 +#define SET_TC_FROM(v,n)   ((V_TC_FROM(n)) | (v & ~M_TC_FROM))
 +#define AT_STACK	0x0
 +#define AT_INGRESS	0x1
 +#define AT_EGRESS	0x2
 +
 +#define TC_NCLS          _TC_MAKEMASK1(8)
 +#define SET_TC_NCLS(v)   ( TC_NCLS | (v & ~TC_NCLS))
 +#define CLR_TC_NCLS(v)   ( v & ~TC_NCLS)
 +
 +#ifndef __KERNEL__
 +#define S_TC_RTTL          _TC_MAKE32(9)
 +#define M_TC_RTTL          _TC_MAKEMASK(3,S_TC_RTTL)
 +#define G_TC_RTTL(x)       _TC_GETVALUE(x,S_TC_RTTL,M_TC_RTTL)
 +#define V_TC_RTTL(x)       _TC_MAKEVALUE(x,S_TC_RTTL)
 +#define SET_TC_RTTL(v,n)   ((V_TC_RTTL(n)) | (v & ~M_TC_RTTL))
 +#endif
 +
 +#define S_TC_AT          _TC_MAKE32(12)
 +#define M_TC_AT          _TC_MAKEMASK(2,S_TC_AT)
 +#define G_TC_AT(x)       _TC_GETVALUE(x,S_TC_AT,M_TC_AT)
 +#define V_TC_AT(x)       _TC_MAKEVALUE(x,S_TC_AT)
 +#define SET_TC_AT(v,n)   ((V_TC_AT(n)) | (v & ~M_TC_AT))
++=======
+ #define TC_COOKIE_MAX_SIZE 16
++>>>>>>> 1045ba77a596 (net sched actions: Add support for user cookies)
  
  /* Action attributes */
  enum {
@@@ -86,6 -13,8 +90,11 @@@
  	TCA_ACT_OPTIONS,
  	TCA_ACT_INDEX,
  	TCA_ACT_STATS,
++<<<<<<< HEAD
++=======
+ 	TCA_ACT_PAD,
+ 	TCA_ACT_COOKIE,
++>>>>>>> 1045ba77a596 (net sched actions: Add support for user cookies)
  	__TCA_ACT_MAX
  };
  
diff --cc net/sched/act_api.c
index 45d305cc522a,3c5e29ba6594..000000000000
--- a/net/sched/act_api.c
+++ b/net/sched/act_api.c
@@@ -27,32 -28,35 +28,44 @@@
  #include <net/act_api.h>
  #include <net/netlink.h>
  
 -static void free_tcf(struct rcu_head *head)
 +void tcf_hash_destroy(struct tcf_common *p, struct tcf_hashinfo *hinfo)
  {
 -	struct tc_action *p = container_of(head, struct tc_action, tcfa_rcu);
 -
 +	unsigned int h = tcf_hash(p->tcfc_index, hinfo->hmask);
 +	struct tcf_common **p1p;
 +
++<<<<<<< HEAD
 +	for (p1p = &hinfo->htab[h]; *p1p; p1p = &(*p1p)->tcfc_next) {
 +		if (*p1p == p) {
 +			write_lock_bh(hinfo->lock);
 +			*p1p = p->tcfc_next;
 +			write_unlock_bh(hinfo->lock);
 +			gen_kill_estimator(&p->tcfc_bstats,
 +					   &p->tcfc_rate_est);
 +			/*
 +			 * gen_estimator est_timer() might access p->tcfc_lock
 +			 * or bstats, wait a RCU grace period before freeing p
 +			 */
 +			kfree_rcu(p, tcfc_rcu);
 +			return;
 +		}
 +	}
 +	WARN_ON(1);
++=======
+ 	free_percpu(p->cpu_bstats);
+ 	free_percpu(p->cpu_qstats);
+ 
+ 	if (p->act_cookie) {
+ 		kfree(p->act_cookie->data);
+ 		kfree(p->act_cookie);
+ 	}
+ 
+ 	kfree(p);
++>>>>>>> 1045ba77a596 (net sched actions: Add support for user cookies)
  }
 +EXPORT_SYMBOL(tcf_hash_destroy);
  
 -static void tcf_hash_destroy(struct tcf_hashinfo *hinfo, struct tc_action *p)
 -{
 -	spin_lock_bh(&hinfo->lock);
 -	hlist_del(&p->tcfa_head);
 -	spin_unlock_bh(&hinfo->lock);
 -	gen_kill_estimator(&p->tcfa_rate_est);
 -	/*
 -	 * gen_estimator est_timer() might access p->tcfa_lock
 -	 * or bstats, wait a RCU grace period before freeing p
 -	 */
 -	call_rcu(&p->tcfa_rcu, free_tcf);
 -}
 -
 -int __tcf_hash_release(struct tc_action *p, bool bind, bool strict)
 +int tcf_hash_release(struct tcf_common *p, int bind,
 +		     struct tcf_hashinfo *hinfo)
  {
  	int ret = 0;
  
@@@ -493,20 -596,30 +528,36 @@@ struct tc_action *tcf_action_init_1(str
  		goto err_out;
  	}
  
 +	err = -ENOMEM;
 +	a = kzalloc(sizeof(*a), GFP_KERNEL);
 +	if (a == NULL)
 +		goto err_mod;
 +
 +	INIT_LIST_HEAD(&a->list);
  	/* backward compatibility for policer */
  	if (name == NULL)
 -		err = a_o->init(net, tb[TCA_ACT_OPTIONS], est, &a, ovr, bind);
 +		err = a_o->init(net, tb[TCA_ACT_OPTIONS], est, a, ovr, bind);
  	else
 -		err = a_o->init(net, nla, est, &a, ovr, bind);
 +		err = a_o->init(net, nla, est, a, ovr, bind);
  	if (err < 0)
 -		goto err_mod;
 +		goto err_free;
  
+ 	if (tb[TCA_ACT_COOKIE]) {
+ 		int cklen = nla_len(tb[TCA_ACT_COOKIE]);
+ 
+ 		if (cklen > TC_COOKIE_MAX_SIZE) {
+ 			err = -EINVAL;
+ 			tcf_hash_release(a, bind);
+ 			goto err_mod;
+ 		}
+ 
+ 		err = nla_memdup_cookie(a, tb);
+ 		if (err < 0) {
+ 			tcf_hash_release(a, bind);
+ 			goto err_mod;
+ 		}
+ 	}
+ 
  	/* module count goes up only when brand new policy is created
  	 * if it exists and is only bound to in a_o->init() then
  	 * ACT_P_CREATED is not returned (a zero is).
* Unmerged path include/net/act_api.h
* Unmerged path include/net/pkt_cls.h
* Unmerged path include/uapi/linux/pkt_cls.h
* Unmerged path net/sched/act_api.c
