dm cache: set/clear the cache core's dirty_bitset when loading mappings

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Joe Thornber <ejt@redhat.com>
commit 449b668ce0b9069fcaafa6344c7f10fa2ba9632e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/449b668c.failed

When loading metadata make sure to set/clear the dirty bits in the cache
core's dirty_bitset as well as the policy.

Otherwise the cache core is unaware that any blocks were dirty when the
cache was last shutdown.  A very serious side-effect being that the
cleaner policy would therefore never be tasked with writing back dirty
data from a cache that was in writeback mode (e.g. when switching from
smq policy to cleaner policy when decommissioning a writeback cache).

This fixes a serious data corruption bug associated with writeback mode.

	Signed-off-by: Joe Thornber <ejt@redhat.com>
	Signed-off-by: Mike Snitzer <snitzer@redhat.com>
(cherry picked from commit 449b668ce0b9069fcaafa6344c7f10fa2ba9632e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/dm-cache-target.c
diff --cc drivers/md/dm-cache-target.c
index e614b257365d,6e747fcbdf0f..000000000000
--- a/drivers/md/dm-cache-target.c
+++ b/drivers/md/dm-cache-target.c
@@@ -3283,7 -2960,13 +3283,17 @@@ static int load_mapping(void *context, 
  	int r;
  	struct cache *cache = context;
  
++<<<<<<< HEAD
 +	r = policy_load_mapping(cache->policy, oblock, cblock, hint, hint_valid);
++=======
+ 	if (dirty) {
+ 		set_bit(from_cblock(cblock), cache->dirty_bitset);
+ 		atomic_inc(&cache->nr_dirty);
+ 	} else
+ 		clear_bit(from_cblock(cblock), cache->dirty_bitset);
+ 
+ 	r = policy_load_mapping(cache->policy, oblock, cblock, dirty, hint, hint_valid);
++>>>>>>> 449b668ce0b9 (dm cache: set/clear the cache core's dirty_bitset when loading mappings)
  	if (r)
  		return r;
  
* Unmerged path drivers/md/dm-cache-target.c
