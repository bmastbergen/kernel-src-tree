qed: avoid possible stack overflow in qed_ll2_acquire_connection

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Arnd Bergmann <arnd@arndb.de>
commit 0629a330cf55454962168dd3ee46fad53a39323e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/0629a330.failed

struct qed_ll2_info is rather large, so putting it on the stack
can cause an overflow, as this warning tries to tell us:

drivers/net/ethernet/qlogic/qed/qed_ll2.c: In function 'qed_ll2_start':
drivers/net/ethernet/qlogic/qed/qed_ll2.c:2159:1: error: the frame size of 1056 bytes is larger than 1024 bytes [-Werror=frame-larger-than=]

qed_ll2_start_ooo() already uses a dynamic allocation for the structure
to work around that problem, and we could do the same in qed_ll2_start()
as well as qed_roce_ll2_start(), but since the structure is only
used to pass a couple of initialization values here, it seems nicer
to replace it with a different structure.

Lacking any idea for better naming, I'm adding 'struct qed_ll2_conn',
which now contains all the initialization data, and this now simply
gets copied into struct qed_ll2_info rather than assigning all members
one by one.

	Signed-off-by: Arnd Bergmann <arnd@arndb.de>
	Acked-by: Yuval Mintz <Yuval.Mintz@cavium.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 0629a330cf55454962168dd3ee46fad53a39323e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/qlogic/qed/qed_ll2.c
diff --cc drivers/net/ethernet/qlogic/qed/qed_ll2.c
index d7e3a49ff80d,873ce2cd76ba..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_ll2.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_ll2.c
@@@ -295,25 -297,34 +295,56 @@@ static void qed_ll2_txq_flush(struct qe
  		list_del(&p_pkt->list_entry);
  		b_last_packet = list_empty(&p_tx->active_descq);
  		list_add_tail(&p_pkt->list_entry, &p_tx->free_descq);
++<<<<<<< HEAD
 +		p_tx->cur_completing_packet = *p_pkt;
 +		p_tx->cur_completing_bd_idx = 1;
 +		b_last_frag = p_tx->cur_completing_bd_idx == p_pkt->bd_used;
 +		tx_frag = p_pkt->bds_set[0].tx_frag;
 +		if (p_ll2_conn->gsi_enable)
 +			qed_ll2b_release_tx_gsi_packet(p_hwfn,
 +						       p_ll2_conn->my_id,
 +						       p_pkt->cookie,
 +						       tx_frag,
 +						       b_last_frag,
 +						       b_last_packet);
 +		else
 +			qed_ll2b_complete_tx_packet(p_hwfn,
 +						    p_ll2_conn->my_id,
 +						    p_pkt->cookie,
 +						    tx_frag,
 +						    b_last_frag,
 +						    b_last_packet);
 +
++=======
+ 		if (p_ll2_conn->conn.conn_type == QED_LL2_TYPE_ISCSI_OOO) {
+ 			struct qed_ooo_buffer *p_buffer;
+ 
+ 			p_buffer = (struct qed_ooo_buffer *)p_pkt->cookie;
+ 			qed_ooo_put_free_buffer(p_hwfn, p_hwfn->p_ooo_info,
+ 						p_buffer);
+ 		} else {
+ 			p_tx->cur_completing_packet = *p_pkt;
+ 			p_tx->cur_completing_bd_idx = 1;
+ 			b_last_frag =
+ 				p_tx->cur_completing_bd_idx == p_pkt->bd_used;
+ 			tx_frag = p_pkt->bds_set[0].tx_frag;
+ 			if (p_ll2_conn->conn.gsi_enable)
+ 				qed_ll2b_release_tx_gsi_packet(p_hwfn,
+ 							       p_ll2_conn->
+ 							       my_id,
+ 							       p_pkt->cookie,
+ 							       tx_frag,
+ 							       b_last_frag,
+ 							       b_last_packet);
+ 			else
+ 				qed_ll2b_complete_tx_packet(p_hwfn,
+ 							    p_ll2_conn->my_id,
+ 							    p_pkt->cookie,
+ 							    tx_frag,
+ 							    b_last_frag,
+ 							    b_last_packet);
+ 		}
++>>>>>>> 0629a330cf55 (qed: avoid possible stack overflow in qed_ll2_acquire_connection)
  	}
  }
  
@@@ -539,13 -550,454 +570,454 @@@ static void qed_ll2_rxq_flush(struct qe
  
  		list_move_tail(&p_pkt->list_entry, &p_rx->free_descq);
  
++<<<<<<< HEAD
 +		rx_buf_addr = p_pkt->rx_buf_addr;
 +		cookie = p_pkt->cookie;
++=======
+ 		if (p_ll2_conn->conn.conn_type == QED_LL2_TYPE_ISCSI_OOO) {
+ 			struct qed_ooo_buffer *p_buffer;
++>>>>>>> 0629a330cf55 (qed: avoid possible stack overflow in qed_ll2_acquire_connection)
  
 -			p_buffer = (struct qed_ooo_buffer *)p_pkt->cookie;
 -			qed_ooo_put_free_buffer(p_hwfn, p_hwfn->p_ooo_info,
 -						p_buffer);
 -		} else {
 -			rx_buf_addr = p_pkt->rx_buf_addr;
 -			cookie = p_pkt->cookie;
 -
 -			b_last = list_empty(&p_rx->active_descq);
 -		}
 +		b_last = list_empty(&p_rx->active_descq);
  	}
  }
  
++<<<<<<< HEAD
++=======
+ #if IS_ENABLED(CONFIG_QED_ISCSI)
+ static u8 qed_ll2_convert_rx_parse_to_tx_flags(u16 parse_flags)
+ {
+ 	u8 bd_flags = 0;
+ 
+ 	if (GET_FIELD(parse_flags, PARSING_AND_ERR_FLAGS_TAG8021QEXIST))
+ 		SET_FIELD(bd_flags, CORE_TX_BD_FLAGS_VLAN_INSERTION, 1);
+ 
+ 	return bd_flags;
+ }
+ 
+ static int qed_ll2_lb_rxq_handler(struct qed_hwfn *p_hwfn,
+ 				  struct qed_ll2_info *p_ll2_conn)
+ {
+ 	struct qed_ll2_rx_queue *p_rx = &p_ll2_conn->rx_queue;
+ 	u16 packet_length = 0, parse_flags = 0, vlan = 0;
+ 	struct qed_ll2_rx_packet *p_pkt = NULL;
+ 	u32 num_ooo_add_to_peninsula = 0, cid;
+ 	union core_rx_cqe_union *cqe = NULL;
+ 	u16 cq_new_idx = 0, cq_old_idx = 0;
+ 	struct qed_ooo_buffer *p_buffer;
+ 	struct ooo_opaque *iscsi_ooo;
+ 	u8 placement_offset = 0;
+ 	u8 cqe_type;
+ 
+ 	cq_new_idx = le16_to_cpu(*p_rx->p_fw_cons);
+ 	cq_old_idx = qed_chain_get_cons_idx(&p_rx->rcq_chain);
+ 	if (cq_new_idx == cq_old_idx)
+ 		return 0;
+ 
+ 	while (cq_new_idx != cq_old_idx) {
+ 		struct core_rx_fast_path_cqe *p_cqe_fp;
+ 
+ 		cqe = qed_chain_consume(&p_rx->rcq_chain);
+ 		cq_old_idx = qed_chain_get_cons_idx(&p_rx->rcq_chain);
+ 		cqe_type = cqe->rx_cqe_sp.type;
+ 
+ 		if (cqe_type != CORE_RX_CQE_TYPE_REGULAR) {
+ 			DP_NOTICE(p_hwfn,
+ 				  "Got a non-regular LB LL2 completion [type 0x%02x]\n",
+ 				  cqe_type);
+ 			return -EINVAL;
+ 		}
+ 		p_cqe_fp = &cqe->rx_cqe_fp;
+ 
+ 		placement_offset = p_cqe_fp->placement_offset;
+ 		parse_flags = le16_to_cpu(p_cqe_fp->parse_flags.flags);
+ 		packet_length = le16_to_cpu(p_cqe_fp->packet_length);
+ 		vlan = le16_to_cpu(p_cqe_fp->vlan);
+ 		iscsi_ooo = (struct ooo_opaque *)&p_cqe_fp->opaque_data;
+ 		qed_ooo_save_history_entry(p_hwfn, p_hwfn->p_ooo_info,
+ 					   iscsi_ooo);
+ 		cid = le32_to_cpu(iscsi_ooo->cid);
+ 
+ 		/* Process delete isle first */
+ 		if (iscsi_ooo->drop_size)
+ 			qed_ooo_delete_isles(p_hwfn, p_hwfn->p_ooo_info, cid,
+ 					     iscsi_ooo->drop_isle,
+ 					     iscsi_ooo->drop_size);
+ 
+ 		if (iscsi_ooo->ooo_opcode == TCP_EVENT_NOP)
+ 			continue;
+ 
+ 		/* Now process create/add/join isles */
+ 		if (list_empty(&p_rx->active_descq)) {
+ 			DP_NOTICE(p_hwfn,
+ 				  "LL2 OOO RX chain has no submitted buffers\n"
+ 				  );
+ 			return -EIO;
+ 		}
+ 
+ 		p_pkt = list_first_entry(&p_rx->active_descq,
+ 					 struct qed_ll2_rx_packet, list_entry);
+ 
+ 		if ((iscsi_ooo->ooo_opcode == TCP_EVENT_ADD_NEW_ISLE) ||
+ 		    (iscsi_ooo->ooo_opcode == TCP_EVENT_ADD_ISLE_RIGHT) ||
+ 		    (iscsi_ooo->ooo_opcode == TCP_EVENT_ADD_ISLE_LEFT) ||
+ 		    (iscsi_ooo->ooo_opcode == TCP_EVENT_ADD_PEN) ||
+ 		    (iscsi_ooo->ooo_opcode == TCP_EVENT_JOIN)) {
+ 			if (!p_pkt) {
+ 				DP_NOTICE(p_hwfn,
+ 					  "LL2 OOO RX packet is not valid\n");
+ 				return -EIO;
+ 			}
+ 			list_del(&p_pkt->list_entry);
+ 			p_buffer = (struct qed_ooo_buffer *)p_pkt->cookie;
+ 			p_buffer->packet_length = packet_length;
+ 			p_buffer->parse_flags = parse_flags;
+ 			p_buffer->vlan = vlan;
+ 			p_buffer->placement_offset = placement_offset;
+ 			qed_chain_consume(&p_rx->rxq_chain);
+ 			list_add_tail(&p_pkt->list_entry, &p_rx->free_descq);
+ 
+ 			switch (iscsi_ooo->ooo_opcode) {
+ 			case TCP_EVENT_ADD_NEW_ISLE:
+ 				qed_ooo_add_new_isle(p_hwfn,
+ 						     p_hwfn->p_ooo_info,
+ 						     cid,
+ 						     iscsi_ooo->ooo_isle,
+ 						     p_buffer);
+ 				break;
+ 			case TCP_EVENT_ADD_ISLE_RIGHT:
+ 				qed_ooo_add_new_buffer(p_hwfn,
+ 						       p_hwfn->p_ooo_info,
+ 						       cid,
+ 						       iscsi_ooo->ooo_isle,
+ 						       p_buffer,
+ 						       QED_OOO_RIGHT_BUF);
+ 				break;
+ 			case TCP_EVENT_ADD_ISLE_LEFT:
+ 				qed_ooo_add_new_buffer(p_hwfn,
+ 						       p_hwfn->p_ooo_info,
+ 						       cid,
+ 						       iscsi_ooo->ooo_isle,
+ 						       p_buffer,
+ 						       QED_OOO_LEFT_BUF);
+ 				break;
+ 			case TCP_EVENT_JOIN:
+ 				qed_ooo_add_new_buffer(p_hwfn,
+ 						       p_hwfn->p_ooo_info,
+ 						       cid,
+ 						       iscsi_ooo->ooo_isle +
+ 						       1,
+ 						       p_buffer,
+ 						       QED_OOO_LEFT_BUF);
+ 				qed_ooo_join_isles(p_hwfn,
+ 						   p_hwfn->p_ooo_info,
+ 						   cid, iscsi_ooo->ooo_isle);
+ 				break;
+ 			case TCP_EVENT_ADD_PEN:
+ 				num_ooo_add_to_peninsula++;
+ 				qed_ooo_put_ready_buffer(p_hwfn,
+ 							 p_hwfn->p_ooo_info,
+ 							 p_buffer, true);
+ 				break;
+ 			}
+ 		} else {
+ 			DP_NOTICE(p_hwfn,
+ 				  "Unexpected event (%d) TX OOO completion\n",
+ 				  iscsi_ooo->ooo_opcode);
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void
+ qed_ooo_submit_tx_buffers(struct qed_hwfn *p_hwfn,
+ 			  struct qed_ll2_info *p_ll2_conn)
+ {
+ 	struct qed_ooo_buffer *p_buffer;
+ 	int rc;
+ 	u16 l4_hdr_offset_w;
+ 	dma_addr_t first_frag;
+ 	u16 parse_flags;
+ 	u8 bd_flags;
+ 
+ 	/* Submit Tx buffers here */
+ 	while ((p_buffer = qed_ooo_get_ready_buffer(p_hwfn,
+ 						    p_hwfn->p_ooo_info))) {
+ 		l4_hdr_offset_w = 0;
+ 		bd_flags = 0;
+ 
+ 		first_frag = p_buffer->rx_buffer_phys_addr +
+ 			     p_buffer->placement_offset;
+ 		parse_flags = p_buffer->parse_flags;
+ 		bd_flags = qed_ll2_convert_rx_parse_to_tx_flags(parse_flags);
+ 		SET_FIELD(bd_flags, CORE_TX_BD_FLAGS_FORCE_VLAN_MODE, 1);
+ 		SET_FIELD(bd_flags, CORE_TX_BD_FLAGS_L4_PROTOCOL, 1);
+ 
+ 		rc = qed_ll2_prepare_tx_packet(p_hwfn, p_ll2_conn->my_id, 1,
+ 					       p_buffer->vlan, bd_flags,
+ 					       l4_hdr_offset_w,
+ 					       p_ll2_conn->conn.tx_dest, 0,
+ 					       first_frag,
+ 					       p_buffer->packet_length,
+ 					       p_buffer, true);
+ 		if (rc) {
+ 			qed_ooo_put_ready_buffer(p_hwfn, p_hwfn->p_ooo_info,
+ 						 p_buffer, false);
+ 			break;
+ 		}
+ 	}
+ }
+ 
+ static void
+ qed_ooo_submit_rx_buffers(struct qed_hwfn *p_hwfn,
+ 			  struct qed_ll2_info *p_ll2_conn)
+ {
+ 	struct qed_ooo_buffer *p_buffer;
+ 	int rc;
+ 
+ 	while ((p_buffer = qed_ooo_get_free_buffer(p_hwfn,
+ 						   p_hwfn->p_ooo_info))) {
+ 		rc = qed_ll2_post_rx_buffer(p_hwfn,
+ 					    p_ll2_conn->my_id,
+ 					    p_buffer->rx_buffer_phys_addr,
+ 					    0, p_buffer, true);
+ 		if (rc) {
+ 			qed_ooo_put_free_buffer(p_hwfn,
+ 						p_hwfn->p_ooo_info, p_buffer);
+ 			break;
+ 		}
+ 	}
+ }
+ 
+ static int qed_ll2_lb_rxq_completion(struct qed_hwfn *p_hwfn, void *p_cookie)
+ {
+ 	struct qed_ll2_info *p_ll2_conn = (struct qed_ll2_info *)p_cookie;
+ 	int rc;
+ 
+ 	rc = qed_ll2_lb_rxq_handler(p_hwfn, p_ll2_conn);
+ 	if (rc)
+ 		return rc;
+ 
+ 	qed_ooo_submit_rx_buffers(p_hwfn, p_ll2_conn);
+ 	qed_ooo_submit_tx_buffers(p_hwfn, p_ll2_conn);
+ 
+ 	return 0;
+ }
+ 
+ static int qed_ll2_lb_txq_completion(struct qed_hwfn *p_hwfn, void *p_cookie)
+ {
+ 	struct qed_ll2_info *p_ll2_conn = (struct qed_ll2_info *)p_cookie;
+ 	struct qed_ll2_tx_queue *p_tx = &p_ll2_conn->tx_queue;
+ 	struct qed_ll2_tx_packet *p_pkt = NULL;
+ 	struct qed_ooo_buffer *p_buffer;
+ 	bool b_dont_submit_rx = false;
+ 	u16 new_idx = 0, num_bds = 0;
+ 	int rc;
+ 
+ 	new_idx = le16_to_cpu(*p_tx->p_fw_cons);
+ 	num_bds = ((s16)new_idx - (s16)p_tx->bds_idx);
+ 
+ 	if (!num_bds)
+ 		return 0;
+ 
+ 	while (num_bds) {
+ 		if (list_empty(&p_tx->active_descq))
+ 			return -EINVAL;
+ 
+ 		p_pkt = list_first_entry(&p_tx->active_descq,
+ 					 struct qed_ll2_tx_packet, list_entry);
+ 		if (!p_pkt)
+ 			return -EINVAL;
+ 
+ 		if (p_pkt->bd_used != 1) {
+ 			DP_NOTICE(p_hwfn,
+ 				  "Unexpectedly many BDs(%d) in TX OOO completion\n",
+ 				  p_pkt->bd_used);
+ 			return -EINVAL;
+ 		}
+ 
+ 		list_del(&p_pkt->list_entry);
+ 
+ 		num_bds--;
+ 		p_tx->bds_idx++;
+ 		qed_chain_consume(&p_tx->txq_chain);
+ 
+ 		p_buffer = (struct qed_ooo_buffer *)p_pkt->cookie;
+ 		list_add_tail(&p_pkt->list_entry, &p_tx->free_descq);
+ 
+ 		if (b_dont_submit_rx) {
+ 			qed_ooo_put_free_buffer(p_hwfn, p_hwfn->p_ooo_info,
+ 						p_buffer);
+ 			continue;
+ 		}
+ 
+ 		rc = qed_ll2_post_rx_buffer(p_hwfn, p_ll2_conn->my_id,
+ 					    p_buffer->rx_buffer_phys_addr, 0,
+ 					    p_buffer, true);
+ 		if (rc != 0) {
+ 			qed_ooo_put_free_buffer(p_hwfn,
+ 						p_hwfn->p_ooo_info, p_buffer);
+ 			b_dont_submit_rx = true;
+ 		}
+ 	}
+ 
+ 	qed_ooo_submit_tx_buffers(p_hwfn, p_ll2_conn);
+ 
+ 	return 0;
+ }
+ 
+ static int
+ qed_ll2_acquire_connection_ooo(struct qed_hwfn *p_hwfn,
+ 			       struct qed_ll2_info *p_ll2_info,
+ 			       u16 rx_num_ooo_buffers, u16 mtu)
+ {
+ 	struct qed_ooo_buffer *p_buf = NULL;
+ 	void *p_virt;
+ 	u16 buf_idx;
+ 	int rc = 0;
+ 
+ 	if (p_ll2_info->conn.conn_type != QED_LL2_TYPE_ISCSI_OOO)
+ 		return rc;
+ 
+ 	if (!rx_num_ooo_buffers)
+ 		return -EINVAL;
+ 
+ 	for (buf_idx = 0; buf_idx < rx_num_ooo_buffers; buf_idx++) {
+ 		p_buf = kzalloc(sizeof(*p_buf), GFP_KERNEL);
+ 		if (!p_buf) {
+ 			rc = -ENOMEM;
+ 			goto out;
+ 		}
+ 
+ 		p_buf->rx_buffer_size = mtu + 26 + ETH_CACHE_LINE_SIZE;
+ 		p_buf->rx_buffer_size = (p_buf->rx_buffer_size +
+ 					 ETH_CACHE_LINE_SIZE - 1) &
+ 					~(ETH_CACHE_LINE_SIZE - 1);
+ 		p_virt = dma_alloc_coherent(&p_hwfn->cdev->pdev->dev,
+ 					    p_buf->rx_buffer_size,
+ 					    &p_buf->rx_buffer_phys_addr,
+ 					    GFP_KERNEL);
+ 		if (!p_virt) {
+ 			kfree(p_buf);
+ 			rc = -ENOMEM;
+ 			goto out;
+ 		}
+ 
+ 		p_buf->rx_buffer_virt_addr = p_virt;
+ 		qed_ooo_put_free_buffer(p_hwfn, p_hwfn->p_ooo_info, p_buf);
+ 	}
+ 
+ 	DP_VERBOSE(p_hwfn, QED_MSG_LL2,
+ 		   "Allocated [%04x] LL2 OOO buffers [each of size 0x%08x]\n",
+ 		   rx_num_ooo_buffers, p_buf->rx_buffer_size);
+ 
+ out:
+ 	return rc;
+ }
+ 
+ static void
+ qed_ll2_establish_connection_ooo(struct qed_hwfn *p_hwfn,
+ 				 struct qed_ll2_info *p_ll2_conn)
+ {
+ 	if (p_ll2_conn->conn.conn_type != QED_LL2_TYPE_ISCSI_OOO)
+ 		return;
+ 
+ 	qed_ooo_release_all_isles(p_hwfn, p_hwfn->p_ooo_info);
+ 	qed_ooo_submit_rx_buffers(p_hwfn, p_ll2_conn);
+ }
+ 
+ static void qed_ll2_release_connection_ooo(struct qed_hwfn *p_hwfn,
+ 					   struct qed_ll2_info *p_ll2_conn)
+ {
+ 	struct qed_ooo_buffer *p_buffer;
+ 
+ 	if (p_ll2_conn->conn.conn_type != QED_LL2_TYPE_ISCSI_OOO)
+ 		return;
+ 
+ 	qed_ooo_release_all_isles(p_hwfn, p_hwfn->p_ooo_info);
+ 	while ((p_buffer = qed_ooo_get_free_buffer(p_hwfn,
+ 						   p_hwfn->p_ooo_info))) {
+ 		dma_free_coherent(&p_hwfn->cdev->pdev->dev,
+ 				  p_buffer->rx_buffer_size,
+ 				  p_buffer->rx_buffer_virt_addr,
+ 				  p_buffer->rx_buffer_phys_addr);
+ 		kfree(p_buffer);
+ 	}
+ }
+ 
+ static void qed_ll2_stop_ooo(struct qed_dev *cdev)
+ {
+ 	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
+ 	u8 *handle = &hwfn->pf_params.iscsi_pf_params.ll2_ooo_queue_id;
+ 
+ 	DP_VERBOSE(cdev, QED_MSG_STORAGE, "Stopping LL2 OOO queue [%02x]\n",
+ 		   *handle);
+ 
+ 	qed_ll2_terminate_connection(hwfn, *handle);
+ 	qed_ll2_release_connection(hwfn, *handle);
+ 	*handle = QED_LL2_UNUSED_HANDLE;
+ }
+ 
+ static int qed_ll2_start_ooo(struct qed_dev *cdev,
+ 			     struct qed_ll2_params *params)
+ {
+ 	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
+ 	u8 *handle = &hwfn->pf_params.iscsi_pf_params.ll2_ooo_queue_id;
+ 	struct qed_ll2_conn ll2_info;
+ 	int rc;
+ 
+ 	ll2_info.conn_type = QED_LL2_TYPE_ISCSI_OOO;
+ 	ll2_info.mtu = params->mtu;
+ 	ll2_info.rx_drop_ttl0_flg = params->drop_ttl0_packets;
+ 	ll2_info.rx_vlan_removal_en = params->rx_vlan_stripping;
+ 	ll2_info.tx_tc = OOO_LB_TC;
+ 	ll2_info.tx_dest = CORE_TX_DEST_LB;
+ 
+ 	rc = qed_ll2_acquire_connection(hwfn, &ll2_info,
+ 					QED_LL2_RX_SIZE, QED_LL2_TX_SIZE,
+ 					handle);
+ 	if (rc) {
+ 		DP_INFO(cdev, "Failed to acquire LL2 OOO connection\n");
+ 		goto out;
+ 	}
+ 
+ 	rc = qed_ll2_establish_connection(hwfn, *handle);
+ 	if (rc) {
+ 		DP_INFO(cdev, "Failed to establist LL2 OOO connection\n");
+ 		goto fail;
+ 	}
+ 
+ 	return 0;
+ 
+ fail:
+ 	qed_ll2_release_connection(hwfn, *handle);
+ out:
+ 	*handle = QED_LL2_UNUSED_HANDLE;
+ 	return rc;
+ }
+ #else /* IS_ENABLED(CONFIG_QED_ISCSI) */
+ static int qed_ll2_lb_rxq_completion(struct qed_hwfn *p_hwfn,
+ 				     void *p_cookie) { return -EINVAL; }
+ static int qed_ll2_lb_txq_completion(struct qed_hwfn *p_hwfn,
+ 				     void *p_cookie) { return -EINVAL; }
+ static inline int
+ qed_ll2_acquire_connection_ooo(struct qed_hwfn *p_hwfn,
+ 			       struct qed_ll2_info *p_ll2_info,
+ 			       u16 rx_num_ooo_buffers, u16 mtu) { return 0; }
+ static inline void
+ qed_ll2_establish_connection_ooo(struct qed_hwfn *p_hwfn,
+ 				 struct qed_ll2_info *p_ll2_conn) { return; }
+ static inline void
+ qed_ll2_release_connection_ooo(struct qed_hwfn *p_hwfn,
+ 			       struct qed_ll2_info *p_ll2_conn) { return; }
+ static inline void qed_ll2_stop_ooo(struct qed_dev *cdev) { return; }
+ static inline int qed_ll2_start_ooo(struct qed_dev *cdev,
+ 				    struct qed_ll2_params *params)
+ 				    { return -EINVAL; }
+ #endif /* IS_ENABLED(CONFIG_QED_ISCSI) */
+ 
++>>>>>>> 0629a330cf55 (qed: avoid possible stack overflow in qed_ll2_acquire_connection)
  static int qed_sp_ll2_rx_queue_start(struct qed_hwfn *p_hwfn,
  				     struct qed_ll2_info *p_ll2_conn,
  				     u8 action_on_error)
@@@ -584,10 -1036,11 +1056,10 @@@
  	DMA_REGPAIR_LE(p_ramrod->cqe_pbl_addr,
  		       qed_chain_get_pbl_phys(&p_rx->rcq_chain));
  
- 	p_ramrod->drop_ttl0_flg = p_ll2_conn->rx_drop_ttl0_flg;
- 	p_ramrod->inner_vlan_removal_en = p_ll2_conn->rx_vlan_removal_en;
+ 	p_ramrod->drop_ttl0_flg = p_ll2_conn->conn.rx_drop_ttl0_flg;
+ 	p_ramrod->inner_vlan_removal_en = p_ll2_conn->conn.rx_vlan_removal_en;
  	p_ramrod->queue_id = p_ll2_conn->queue_id;
 -	p_ramrod->main_func_queue = (conn_type == QED_LL2_TYPE_ISCSI_OOO) ? 0
 -									  : 1;
 +	p_ramrod->main_func_queue = 1;
  
  	if ((IS_MF_DEFAULT(p_hwfn) || IS_MF_SI(p_hwfn)) &&
  	    p_ramrod->main_func_queue && (conn_type != QED_LL2_TYPE_ROCE)) {
@@@ -618,6 -1071,11 +1090,14 @@@ static int qed_sp_ll2_tx_queue_start(st
  	if (!QED_LL2_TX_REGISTERED(p_ll2_conn))
  		return 0;
  
++<<<<<<< HEAD
++=======
+ 	if (p_ll2_conn->conn.conn_type == QED_LL2_TYPE_ISCSI_OOO)
+ 		p_ll2_conn->tx_stats_en = 0;
+ 	else
+ 		p_ll2_conn->tx_stats_en = 1;
+ 
++>>>>>>> 0629a330cf55 (qed: avoid possible stack overflow in qed_ll2_acquire_connection)
  	/* Get SPQ entry */
  	memset(&init_data, 0, sizeof(init_data));
  	init_data.cid = p_ll2_conn->cid;
@@@ -634,8 -1092,7 +1114,12 @@@
  
  	p_ramrod->sb_id = cpu_to_le16(qed_int_get_sp_sb_id(p_hwfn));
  	p_ramrod->sb_index = p_tx->tx_sb_index;
++<<<<<<< HEAD
 +	p_ramrod->mtu = cpu_to_le16(p_ll2_conn->mtu);
 +	p_ll2_conn->tx_stats_en = 1;
++=======
+ 	p_ramrod->mtu = cpu_to_le16(p_ll2_conn->conn.mtu);
++>>>>>>> 0629a330cf55 (qed: avoid possible stack overflow in qed_ll2_acquire_connection)
  	p_ramrod->stats_en = p_ll2_conn->tx_stats_en;
  	p_ramrod->stats_id = p_ll2_conn->tx_stats_id;
  
@@@ -1340,6 -1805,9 +1816,12 @@@ int qed_ll2_terminate_connection(struc
  		qed_ll2_rxq_flush(p_hwfn, connection_handle);
  	}
  
++<<<<<<< HEAD
++=======
+ 	if (p_ll2_conn->conn.conn_type == QED_LL2_TYPE_ISCSI_OOO)
+ 		qed_ooo_release_all_isles(p_hwfn, p_hwfn->p_ooo_info);
+ 
++>>>>>>> 0629a330cf55 (qed: avoid possible stack overflow in qed_ll2_acquire_connection)
  	return rc;
  }
  
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_ll2.c
diff --git a/drivers/net/ethernet/qlogic/qed/qed_ll2.h b/drivers/net/ethernet/qlogic/qed/qed_ll2.h
index 80a5dc2d652d..1bec01bd106a 100644
--- a/drivers/net/ethernet/qlogic/qed/qed_ll2.h
+++ b/drivers/net/ethernet/qlogic/qed/qed_ll2.h
@@ -106,15 +106,8 @@ struct qed_ll2_tx_queue {
 	bool b_completing_packet;
 };
 
-struct qed_ll2_info {
-	/* Lock protecting the state of LL2 */
-	struct mutex mutex;
+struct qed_ll2_conn {
 	enum qed_ll2_conn_type conn_type;
-	u32 cid;
-	u8 my_id;
-	u8 queue_id;
-	u8 tx_stats_id;
-	bool b_active;
 	u16 mtu;
 	u8 rx_drop_ttl0_flg;
 	u8 rx_vlan_removal_en;
@@ -122,10 +115,21 @@ struct qed_ll2_info {
 	enum core_tx_dest tx_dest;
 	enum core_error_handle ai_err_packet_too_big;
 	enum core_error_handle ai_err_no_buf;
+	u8 gsi_enable;
+};
+
+struct qed_ll2_info {
+	/* Lock protecting the state of LL2 */
+	struct mutex mutex;
+	struct qed_ll2_conn conn;
+	u32 cid;
+	u8 my_id;
+	u8 queue_id;
+	u8 tx_stats_id;
+	bool b_active;
 	u8 tx_stats_en;
 	struct qed_ll2_rx_queue rx_queue;
 	struct qed_ll2_tx_queue tx_queue;
-	u8 gsi_enable;
 };
 
 /**
@@ -143,7 +147,7 @@ struct qed_ll2_info {
  * @return 0 on success, failure otherwise
  */
 int qed_ll2_acquire_connection(struct qed_hwfn *p_hwfn,
-			       struct qed_ll2_info *p_params,
+			       struct qed_ll2_conn *p_params,
 			       u16 rx_num_desc,
 			       u16 tx_num_desc,
 			       u8 *p_connection_handle);
diff --git a/drivers/net/ethernet/qlogic/qed/qed_roce.c b/drivers/net/ethernet/qlogic/qed/qed_roce.c
index 98b49dbe5917..e8574bf60624 100644
--- a/drivers/net/ethernet/qlogic/qed/qed_roce.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_roce.c
@@ -2635,7 +2635,7 @@ static int qed_roce_ll2_start(struct qed_dev *cdev,
 {
 	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
 	struct qed_roce_ll2_info *roce_ll2;
-	struct qed_ll2_info ll2_params;
+	struct qed_ll2_conn ll2_params;
 	int rc;
 
 	if (!params) {
