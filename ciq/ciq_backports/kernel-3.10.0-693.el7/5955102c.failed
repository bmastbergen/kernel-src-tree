wrappers for ->i_mutex access

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Al Viro <viro@zeniv.linux.org.uk>
commit 5955102c9984fa081b2d570cfac75c97eecf8f3b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/5955102c.failed

parallel to mutex_{lock,unlock,trylock,is_locked,lock_nested},
inode_foo(inode) being mutex_foo(&inode->i_mutex).

Please, use those for access to ->i_mutex; over the coming cycle
->i_mutex will become rwsem, with ->lookup() done with it held
only shared.

	Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
(cherry picked from commit 5955102c9984fa081b2d570cfac75c97eecf8f3b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/platforms/cell/spufs/inode.c
#	arch/s390/hypfs/inode.c
#	block/ioctl.c
#	drivers/base/devtmpfs.c
#	drivers/block/drbd/drbd_debugfs.c
#	drivers/infiniband/hw/ipath/ipath_fs.c
#	drivers/infiniband/hw/qib/qib_fs.c
#	drivers/oprofile/oprofilefs.c
#	drivers/staging/lustre/lustre/llite/dir.c
#	drivers/staging/lustre/lustre/llite/file.c
#	drivers/staging/lustre/lustre/llite/llite_lib.c
#	drivers/staging/lustre/lustre/llite/llite_nfs.c
#	drivers/staging/lustre/lustre/llite/lloop.c
#	drivers/staging/lustre/lustre/llite/rw.c
#	drivers/staging/lustre/lustre/llite/rw26.c
#	drivers/staging/lustre/lustre/llite/vvp_io.c
#	drivers/staging/lustre/lustre/llite/vvp_page.c
#	drivers/video/fb_defio.c
#	fs/binfmt_misc.c
#	fs/block_dev.c
#	fs/btrfs/file.c
#	fs/btrfs/ioctl.c
#	fs/cachefiles/interface.c
#	fs/cachefiles/namei.c
#	fs/ceph/cache.c
#	fs/ceph/export.c
#	fs/ceph/file.c
#	fs/cifs/file.c
#	fs/coda/dir.c
#	fs/coda/file.c
#	fs/configfs/dir.c
#	fs/configfs/file.c
#	fs/configfs/inode.c
#	fs/dax.c
#	fs/debugfs/inode.c
#	fs/devpts/inode.c
#	fs/direct-io.c
#	fs/ecryptfs/inode.c
#	fs/exportfs/expfs.c
#	fs/ext4/extents.c
#	fs/ext4/file.c
#	fs/ext4/inode.c
#	fs/ext4/ioctl.c
#	fs/f2fs/data.c
#	fs/f2fs/file.c
#	fs/fat/dir.c
#	fs/fat/file.c
#	fs/fuse/dir.c
#	fs/fuse/file.c
#	fs/hugetlbfs/inode.c
#	fs/jfs/file.c
#	fs/kernfs/dir.c
#	fs/libfs.c
#	fs/locks.c
#	fs/namei.c
#	fs/nfs/direct.c
#	fs/nfsd/nfs4recover.c
#	fs/nfsd/nfsfh.h
#	fs/nfsd/vfs.c
#	fs/ntfs/file.c
#	fs/ocfs2/alloc.c
#	fs/ocfs2/file.c
#	fs/ocfs2/journal.c
#	fs/ocfs2/namei.c
#	fs/ocfs2/refcounttree.c
#	fs/ocfs2/suballoc.c
#	fs/overlayfs/dir.c
#	fs/overlayfs/inode.c
#	fs/overlayfs/super.c
#	fs/proc/thread_self.c
#	fs/pstore/inode.c
#	fs/quota/dquot.c
#	fs/reiserfs/ioctl.c
#	fs/reiserfs/xattr.c
#	fs/tracefs/inode.c
#	fs/ubifs/dir.c
#	fs/ubifs/xattr.c
#	fs/udf/file.c
#	fs/udf/inode.c
#	fs/xattr.c
#	include/linux/fs.h
#	ipc/mqueue.c
#	kernel/audit_watch.c
#	kernel/sched/core.c
#	mm/filemap.c
#	mm/swapfile.c
#	net/sunrpc/rpc_pipe.c
#	security/inode.c
#	security/integrity/ima/ima_main.c
diff --cc arch/powerpc/platforms/cell/spufs/inode.c
index 35f77a42bedf,dfa863876778..000000000000
--- a/arch/powerpc/platforms/cell/spufs/inode.c
+++ b/arch/powerpc/platforms/cell/spufs/inode.c
@@@ -163,10 -163,10 +163,15 @@@ static void spufs_prune_dir(struct dent
  {
  	struct dentry *dentry, *tmp;
  
++<<<<<<< HEAD
 +	mutex_lock(&dir->d_inode->i_mutex);
 +	list_for_each_entry_safe(dentry, tmp, &dir->d_subdirs, d_u.d_child) {
++=======
+ 	inode_lock(d_inode(dir));
+ 	list_for_each_entry_safe(dentry, tmp, &dir->d_subdirs, d_child) {
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		spin_lock(&dentry->d_lock);
 -		if (simple_positive(dentry)) {
 +		if (!(d_unhashed(dentry)) && dentry->d_inode) {
  			dget_dlock(dentry);
  			__d_drop(dentry);
  			spin_unlock(&dentry->d_lock);
@@@ -180,7 -180,7 +185,11 @@@
  		}
  	}
  	shrink_dcache_parent(dir);
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  }
  
  /* Caller must hold parent->i_mutex */
@@@ -222,12 -222,12 +231,12 @@@ static int spufs_dir_close(struct inod
  	int ret;
  
  	dir = file->f_path.dentry;
 -	parent = d_inode(dir->d_parent);
 -	ctx = SPUFS_I(d_inode(dir))->i_ctx;
 +	parent = dir->d_parent->d_inode;
 +	ctx = SPUFS_I(dir->d_inode)->i_ctx;
  
- 	mutex_lock_nested(&parent->i_mutex, I_MUTEX_PARENT);
+ 	inode_lock_nested(parent, I_MUTEX_PARENT);
  	ret = spufs_rmdir(parent, dir);
- 	mutex_unlock(&parent->i_mutex);
+ 	inode_unlock(parent);
  	WARN_ON(ret);
  
  	return dcache_dir_close(inode, file);
diff --cc arch/s390/hypfs/inode.c
index b9e6cfb925ab,0f3da2cb2bd6..000000000000
--- a/arch/s390/hypfs/inode.c
+++ b/arch/s390/hypfs/inode.c
@@@ -73,16 -67,16 +73,27 @@@ static void hypfs_remove(struct dentry 
  	struct dentry *parent;
  
  	parent = dentry->d_parent;
++<<<<<<< HEAD
 +	mutex_lock(&parent->d_inode->i_mutex);
 +	if (hypfs_positive(dentry)) {
 +		if (S_ISDIR(dentry->d_inode->i_mode))
 +			simple_rmdir(parent->d_inode, dentry);
++=======
+ 	inode_lock(d_inode(parent));
+ 	if (simple_positive(dentry)) {
+ 		if (d_is_dir(dentry))
+ 			simple_rmdir(d_inode(parent), dentry);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		else
 -			simple_unlink(d_inode(parent), dentry);
 +			simple_unlink(parent->d_inode, dentry);
  	}
  	d_delete(dentry);
  	dput(dentry);
++<<<<<<< HEAD
 +	mutex_unlock(&parent->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  }
  
  static void hypfs_delete_tree(struct dentry *root)
@@@ -341,7 -331,7 +352,11 @@@ static struct dentry *hypfs_create_file
  	struct dentry *dentry;
  	struct inode *inode;
  
++<<<<<<< HEAD
 +	mutex_lock(&parent->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dentry = lookup_one_len(name, parent, strlen(name));
  	if (IS_ERR(dentry)) {
  		dentry = ERR_PTR(-ENOMEM);
@@@ -369,7 -359,7 +384,11 @@@
  	d_instantiate(dentry, inode);
  	dget(dentry);
  fail:
++<<<<<<< HEAD
 +	mutex_unlock(&parent->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return dentry;
  }
  
diff --cc block/ioctl.c
index 4aa3b235d4f1,77f5d17779d6..000000000000
--- a/block/ioctl.c
+++ b/block/ioctl.c
@@@ -406,6 -407,71 +406,74 @@@ static inline int is_unrecognized_ioctl
  		ret == -ENOIOCTLCMD;
  }
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_FS_DAX
+ bool blkdev_dax_capable(struct block_device *bdev)
+ {
+ 	struct gendisk *disk = bdev->bd_disk;
+ 
+ 	if (!disk->fops->direct_access)
+ 		return false;
+ 
+ 	/*
+ 	 * If the partition is not aligned on a page boundary, we can't
+ 	 * do dax I/O to it.
+ 	 */
+ 	if ((bdev->bd_part->start_sect % (PAGE_SIZE / 512))
+ 			|| (bdev->bd_part->nr_sects % (PAGE_SIZE / 512)))
+ 		return false;
+ 
+ 	/*
+ 	 * If the device has known bad blocks, force all I/O through the
+ 	 * driver / page cache.
+ 	 *
+ 	 * TODO: support finer grained dax error handling
+ 	 */
+ 	if (disk->bb && disk->bb->count)
+ 		return false;
+ 
+ 	return true;
+ }
+ 
+ static int blkdev_daxset(struct block_device *bdev, unsigned long argp)
+ {
+ 	unsigned long arg;
+ 	int rc = 0;
+ 
+ 	if (!capable(CAP_SYS_ADMIN))
+ 		return -EACCES;
+ 
+ 	if (get_user(arg, (int __user *)(argp)))
+ 		return -EFAULT;
+ 	arg = !!arg;
+ 	if (arg == !!(bdev->bd_inode->i_flags & S_DAX))
+ 		return 0;
+ 
+ 	if (arg)
+ 		arg = S_DAX;
+ 
+ 	if (arg && !blkdev_dax_capable(bdev))
+ 		return -ENOTTY;
+ 
+ 	inode_lock(bdev->bd_inode);
+ 	if (bdev->bd_map_count == 0)
+ 		inode_set_flags(bdev->bd_inode, arg, S_DAX);
+ 	else
+ 		rc = -EBUSY;
+ 	inode_unlock(bdev->bd_inode);
+ 	return rc;
+ }
+ #else
+ static int blkdev_daxset(struct block_device *bdev, int arg)
+ {
+ 	if (arg)
+ 		return -ENOTTY;
+ 	return 0;
+ }
+ #endif
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  static int blkdev_flushbuf(struct block_device *bdev, fmode_t mode,
  		unsigned cmd, unsigned long arg)
  {
diff --cc drivers/base/devtmpfs.c
index 0f3820121e02,44a74cf1372c..000000000000
--- a/drivers/base/devtmpfs.c
+++ b/drivers/base/devtmpfs.c
@@@ -215,12 -215,12 +215,18 @@@ static int handle_create(const char *no
  		newattrs.ia_uid = uid;
  		newattrs.ia_gid = gid;
  		newattrs.ia_valid = ATTR_MODE|ATTR_UID|ATTR_GID;
++<<<<<<< HEAD
 +		mutex_lock(&dentry->d_inode->i_mutex);
 +		notify_change(dentry, &newattrs, NULL);
 +		mutex_unlock(&dentry->d_inode->i_mutex);
++=======
+ 		inode_lock(d_inode(dentry));
+ 		notify_change(dentry, &newattrs, NULL);
+ 		inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  		/* mark as kernel-created inode */
 -		d_inode(dentry)->i_private = &thread;
 +		dentry->d_inode->i_private = &thread;
  	}
  	done_path_create(&path, dentry);
  	return err;
@@@ -244,7 -244,7 +250,11 @@@ static int dev_rmdir(const char *name
  		err = -ENOENT;
  	}
  	dput(dentry);
++<<<<<<< HEAD
 +	mutex_unlock(&parent.dentry->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(parent.dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	path_put(&parent);
  	return err;
  }
@@@ -321,10 -321,10 +331,17 @@@ static int handle_remove(const char *no
  			newattrs.ia_mode = stat.mode & ~0777;
  			newattrs.ia_valid =
  				ATTR_UID|ATTR_GID|ATTR_MODE;
++<<<<<<< HEAD
 +			mutex_lock(&dentry->d_inode->i_mutex);
 +			notify_change(dentry, &newattrs, NULL);
 +			mutex_unlock(&dentry->d_inode->i_mutex);
 +			err = vfs_unlink(parent.dentry->d_inode, dentry, NULL);
++=======
+ 			inode_lock(d_inode(dentry));
+ 			notify_change(dentry, &newattrs, NULL);
+ 			inode_unlock(d_inode(dentry));
+ 			err = vfs_unlink(d_inode(parent.dentry), dentry, NULL);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  			if (!err || err == -ENOENT)
  				deleted = 1;
  		}
@@@ -332,7 -332,7 +349,11 @@@
  		err = -ENOENT;
  	}
  	dput(dentry);
++<<<<<<< HEAD
 +	mutex_unlock(&parent.dentry->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(parent.dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	path_put(&parent);
  	if (deleted && strchr(nodename, '/'))
diff --cc drivers/infiniband/hw/ipath/ipath_fs.c
index e545fff47b23,476fcdf05acb..000000000000
--- a/drivers/infiniband/hw/ipath/ipath_fs.c
+++ b/drivers/infiniband/hw/ipath/ipath_fs.c
@@@ -82,15 -82,14 +82,23 @@@ static int create_file(const char *name
  {
  	int error;
  
++<<<<<<< HEAD:drivers/infiniband/hw/ipath/ipath_fs.c
 +	*dentry = NULL;
 +	mutex_lock(&parent->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access):drivers/staging/rdma/ipath/ipath_fs.c
  	*dentry = lookup_one_len(name, parent, strlen(name));
  	if (!IS_ERR(*dentry))
 -		error = ipathfs_mknod(d_inode(parent), *dentry,
 +		error = ipathfs_mknod(parent->d_inode, *dentry,
  				      mode, fops, data);
  	else
  		error = PTR_ERR(*dentry);
++<<<<<<< HEAD:drivers/infiniband/hw/ipath/ipath_fs.c
 +	mutex_unlock(&parent->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access):drivers/staging/rdma/ipath/ipath_fs.c
  
  	return error;
  }
@@@ -296,7 -295,7 +304,11 @@@ static int remove_device_files(struct s
  	int ret;
  
  	root = dget(sb->s_root);
++<<<<<<< HEAD:drivers/infiniband/hw/ipath/ipath_fs.c
 +	mutex_lock(&root->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access):drivers/staging/rdma/ipath/ipath_fs.c
  	snprintf(unit, sizeof unit, "%02d", dd->ipath_unit);
  	dir = lookup_one_len(unit, root, strlen(unit));
  
@@@ -309,10 -308,10 +321,14 @@@
  	remove_file(dir, "flash");
  	remove_file(dir, "atomic_counters");
  	d_delete(dir);
 -	ret = simple_rmdir(d_inode(root), dir);
 +	ret = simple_rmdir(root->d_inode, dir);
  
  bail:
++<<<<<<< HEAD:drivers/infiniband/hw/ipath/ipath_fs.c
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access):drivers/staging/rdma/ipath/ipath_fs.c
  	dput(root);
  	return ret;
  }
diff --cc drivers/infiniband/hw/qib/qib_fs.c
index a6b52f8f8710,fcdf37913a26..000000000000
--- a/drivers/infiniband/hw/qib/qib_fs.c
+++ b/drivers/infiniband/hw/qib/qib_fs.c
@@@ -89,15 -89,14 +89,23 @@@ static int create_file(const char *name
  {
  	int error;
  
++<<<<<<< HEAD
 +	*dentry = NULL;
 +	mutex_lock(&parent->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	*dentry = lookup_one_len(name, parent, strlen(name));
  	if (!IS_ERR(*dentry))
 -		error = qibfs_mknod(d_inode(parent), *dentry,
 +		error = qibfs_mknod(parent->d_inode, *dentry,
  				    mode, fops, data);
  	else
  		error = PTR_ERR(*dentry);
++<<<<<<< HEAD
 +	mutex_unlock(&parent->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	return error;
  }
@@@ -466,7 -481,7 +474,11 @@@ static int remove_device_files(struct s
  	int ret, i;
  
  	root = dget(sb->s_root);
++<<<<<<< HEAD
 +	mutex_lock(&root->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	snprintf(unit, sizeof(unit), "%u", dd->unit);
  	dir = lookup_one_len(unit, root, strlen(unit));
  
@@@ -476,7 -491,7 +488,11 @@@
  		goto bail;
  	}
  
++<<<<<<< HEAD
 +	mutex_lock(&dir->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	remove_file(dir, "counters");
  	remove_file(dir, "counter_names");
  	remove_file(dir, "portcounter_names");
@@@ -491,13 -506,13 +507,22 @@@
  		}
  	}
  	remove_file(dir, "flash");
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
 +	ret = simple_rmdir(root->d_inode, dir);
++=======
+ 	inode_unlock(d_inode(dir));
+ 	ret = simple_rmdir(d_inode(root), dir);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	d_delete(dir);
  	dput(dir);
  
  bail:
++<<<<<<< HEAD
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dput(root);
  	return ret;
  }
diff --cc drivers/oprofile/oprofilefs.c
index 7c12d9c2b230,b48ac6300c79..000000000000
--- a/drivers/oprofile/oprofilefs.c
+++ b/drivers/oprofile/oprofilefs.c
@@@ -139,22 -138,22 +139,37 @@@ static int __oprofilefs_create_file(str
  	struct dentry *dentry;
  	struct inode *inode;
  
++<<<<<<< HEAD
 +	mutex_lock(&root->d_inode->i_mutex);
 +	dentry = d_alloc_name(root, name);
 +	if (!dentry) {
 +		mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(root));
+ 	dentry = d_alloc_name(root, name);
+ 	if (!dentry) {
+ 		inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		return -ENOMEM;
  	}
 -	inode = oprofilefs_get_inode(root->d_sb, S_IFREG | perm);
 +	inode = oprofilefs_get_inode(sb, S_IFREG | perm);
  	if (!inode) {
  		dput(dentry);
++<<<<<<< HEAD
 +		mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 		inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		return -ENOMEM;
  	}
  	inode->i_fop = fops;
  	inode->i_private = priv;
  	d_add(dentry, inode);
++<<<<<<< HEAD
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return 0;
  }
  
@@@ -217,22 -215,22 +232,37 @@@ struct dentry *oprofilefs_mkdir(struct 
  	struct dentry *dentry;
  	struct inode *inode;
  
++<<<<<<< HEAD
 +	mutex_lock(&root->d_inode->i_mutex);
 +	dentry = d_alloc_name(root, name);
 +	if (!dentry) {
 +		mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(parent));
+ 	dentry = d_alloc_name(parent, name);
+ 	if (!dentry) {
+ 		inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		return NULL;
  	}
 -	inode = oprofilefs_get_inode(parent->d_sb, S_IFDIR | 0755);
 +	inode = oprofilefs_get_inode(sb, S_IFDIR | 0755);
  	if (!inode) {
  		dput(dentry);
++<<<<<<< HEAD
 +		mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 		inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		return NULL;
  	}
  	inode->i_op = &simple_dir_inode_operations;
  	inode->i_fop = &simple_dir_operations;
  	d_add(dentry, inode);
++<<<<<<< HEAD
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return dentry;
  }
  
diff --cc drivers/video/fb_defio.c
index 900aa4ecd617,57721c73177f..000000000000
--- a/drivers/video/fb_defio.c
+++ b/drivers/video/fb_defio.c
@@@ -83,9 -83,10 +83,16 @@@ int fb_deferred_io_fsync(struct file *f
  	cancel_delayed_work_sync(&info->deferred_work);
  
  	/* Run it immediately */
++<<<<<<< HEAD:drivers/video/fb_defio.c
 +	err = schedule_delayed_work(&info->deferred_work, 0);
 +	mutex_unlock(&inode->i_mutex);
 +	return err;
++=======
+ 	schedule_delayed_work(&info->deferred_work, 0);
+ 	inode_unlock(inode);
+ 
+ 	return 0;
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access):drivers/video/fbdev/core/fb_defio.c
  }
  EXPORT_SYMBOL_GPL(fb_deferred_io_fsync);
  
diff --cc fs/binfmt_misc.c
index 1c740e152f38,3a3ced779fc7..000000000000
--- a/fs/binfmt_misc.c
+++ b/fs/binfmt_misc.c
@@@ -538,20 -627,28 +538,43 @@@ static ssize_t bm_entry_write(struct fi
  	int res = parse_command(buffer, count);
  
  	switch (res) {
++<<<<<<< HEAD
 +		case 1: clear_bit(Enabled, &e->flags);
 +			break;
 +		case 2: set_bit(Enabled, &e->flags);
 +			break;
 +		case 3: root = dget(file->f_path.dentry->d_sb->s_root);
 +			mutex_lock(&root->d_inode->i_mutex);
++=======
+ 	case 1:
+ 		/* Disable this handler. */
+ 		clear_bit(Enabled, &e->flags);
+ 		break;
+ 	case 2:
+ 		/* Enable this handler. */
+ 		set_bit(Enabled, &e->flags);
+ 		break;
+ 	case 3:
+ 		/* Delete this handler. */
+ 		root = dget(file->f_path.dentry->d_sb->s_root);
+ 		inode_lock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
 -		kill_node(e);
 +			kill_node(e);
  
++<<<<<<< HEAD
 +			mutex_unlock(&root->d_inode->i_mutex);
 +			dput(root);
 +			break;
 +		default: return res;
++=======
+ 		inode_unlock(d_inode(root));
+ 		dput(root);
+ 		break;
+ 	default:
+ 		return res;
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	}
 -
  	return count;
  }
  
@@@ -578,7 -675,7 +601,11 @@@ static ssize_t bm_register_write(struc
  		return PTR_ERR(e);
  
  	root = dget(sb->s_root);
++<<<<<<< HEAD
 +	mutex_lock(&root->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dentry = lookup_one_len(e->name, root, strlen(e->name));
  	err = PTR_ERR(dentry);
  	if (IS_ERR(dentry))
@@@ -614,7 -711,7 +641,11 @@@
  out2:
  	dput(dentry);
  out:
++<<<<<<< HEAD
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dput(root);
  
  	if (err) {
@@@ -646,18 -743,29 +677,41 @@@ static ssize_t bm_status_write(struct f
  	struct dentry *root;
  
  	switch (res) {
++<<<<<<< HEAD
 +		case 1: enabled = 0; break;
 +		case 2: enabled = 1; break;
 +		case 3: root = dget(file->f_path.dentry->d_sb->s_root);
 +			mutex_lock(&root->d_inode->i_mutex);
++=======
+ 	case 1:
+ 		/* Disable all handlers. */
+ 		enabled = 0;
+ 		break;
+ 	case 2:
+ 		/* Enable all handlers. */
+ 		enabled = 1;
+ 		break;
+ 	case 3:
+ 		/* Delete all handlers. */
+ 		root = dget(file->f_path.dentry->d_sb->s_root);
+ 		inode_lock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
 -		while (!list_empty(&entries))
 -			kill_node(list_entry(entries.next, Node, list));
 +			while (!list_empty(&entries))
 +				kill_node(list_entry(entries.next, Node, list));
  
++<<<<<<< HEAD
 +			mutex_unlock(&root->d_inode->i_mutex);
 +			dput(root);
 +		default: return res;
++=======
+ 		inode_unlock(d_inode(root));
+ 		dput(root);
+ 		break;
+ 	default:
+ 		return res;
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	}
 -
  	return count;
  }
  
diff --cc fs/block_dev.c
index 7d6ea6f10f58,2c3aeab17e20..000000000000
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@@ -404,32 -344,11 +404,38 @@@ EXPORT_SYMBOL_GPL(bdev_direct_access)
  static loff_t block_llseek(struct file *file, loff_t offset, int whence)
  {
  	struct inode *bd_inode = bdev_file_inode(file);
 +	loff_t size;
  	loff_t retval;
  
++<<<<<<< HEAD
 +	mutex_lock(&bd_inode->i_mutex);
 +	size = i_size_read(bd_inode);
 +
 +	retval = -EINVAL;
 +	switch (whence) {
 +		case SEEK_END:
 +			offset += size;
 +			break;
 +		case SEEK_CUR:
 +			offset += file->f_pos;
 +		case SEEK_SET:
 +			break;
 +		default:
 +			goto out;
 +	}
 +	if (offset >= 0 && offset <= size) {
 +		if (offset != file->f_pos) {
 +			file->f_pos = offset;
 +		}
 +		retval = offset;
 +	}
 +out:
 +	mutex_unlock(&bd_inode->i_mutex);
++=======
+ 	inode_lock(bd_inode);
+ 	retval = fixed_size_llseek(file, offset, whence, i_size_read(bd_inode));
+ 	inode_unlock(bd_inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return retval;
  }
  	
@@@ -1808,6 -1705,94 +1814,97 @@@ static const struct address_space_opera
  	.is_dirty_writeback = buffer_check_dirty_writeback,
  };
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_FS_DAX
+ /*
+  * In the raw block case we do not need to contend with truncation nor
+  * unwritten file extents.  Without those concerns there is no need for
+  * additional locking beyond the mmap_sem context that these routines
+  * are already executing under.
+  *
+  * Note, there is no protection if the block device is dynamically
+  * resized (partition grow/shrink) during a fault. A stable block device
+  * size is already not enforced in the blkdev_direct_IO path.
+  *
+  * For DAX, it is the responsibility of the block device driver to
+  * ensure the whole-disk device size is stable while requests are in
+  * flight.
+  *
+  * Finally, unlike the filemap_page_mkwrite() case there is no
+  * filesystem superblock to sync against freezing.  We still include a
+  * pfn_mkwrite callback for dax drivers to receive write fault
+  * notifications.
+  */
+ static int blkdev_dax_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
+ {
+ 	return __dax_fault(vma, vmf, blkdev_get_block, NULL);
+ }
+ 
+ static int blkdev_dax_pmd_fault(struct vm_area_struct *vma, unsigned long addr,
+ 		pmd_t *pmd, unsigned int flags)
+ {
+ 	return __dax_pmd_fault(vma, addr, pmd, flags, blkdev_get_block, NULL);
+ }
+ 
+ static void blkdev_vm_open(struct vm_area_struct *vma)
+ {
+ 	struct inode *bd_inode = bdev_file_inode(vma->vm_file);
+ 	struct block_device *bdev = I_BDEV(bd_inode);
+ 
+ 	inode_lock(bd_inode);
+ 	bdev->bd_map_count++;
+ 	inode_unlock(bd_inode);
+ }
+ 
+ static void blkdev_vm_close(struct vm_area_struct *vma)
+ {
+ 	struct inode *bd_inode = bdev_file_inode(vma->vm_file);
+ 	struct block_device *bdev = I_BDEV(bd_inode);
+ 
+ 	inode_lock(bd_inode);
+ 	bdev->bd_map_count--;
+ 	inode_unlock(bd_inode);
+ }
+ 
+ static const struct vm_operations_struct blkdev_dax_vm_ops = {
+ 	.open		= blkdev_vm_open,
+ 	.close		= blkdev_vm_close,
+ 	.fault		= blkdev_dax_fault,
+ 	.pmd_fault	= blkdev_dax_pmd_fault,
+ 	.pfn_mkwrite	= blkdev_dax_fault,
+ };
+ 
+ static const struct vm_operations_struct blkdev_default_vm_ops = {
+ 	.open		= blkdev_vm_open,
+ 	.close		= blkdev_vm_close,
+ 	.fault		= filemap_fault,
+ 	.map_pages	= filemap_map_pages,
+ };
+ 
+ static int blkdev_mmap(struct file *file, struct vm_area_struct *vma)
+ {
+ 	struct inode *bd_inode = bdev_file_inode(file);
+ 	struct block_device *bdev = I_BDEV(bd_inode);
+ 
+ 	file_accessed(file);
+ 	inode_lock(bd_inode);
+ 	bdev->bd_map_count++;
+ 	if (IS_DAX(bd_inode)) {
+ 		vma->vm_ops = &blkdev_dax_vm_ops;
+ 		vma->vm_flags |= VM_MIXEDMAP | VM_HUGEPAGE;
+ 	} else {
+ 		vma->vm_ops = &blkdev_default_vm_ops;
+ 	}
+ 	inode_unlock(bd_inode);
+ 
+ 	return 0;
+ }
+ #else
+ #define blkdev_mmap generic_file_mmap
+ #endif
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  const struct file_operations def_blk_fops = {
  	.open		= blkdev_open,
  	.release	= blkdev_close,
diff --cc fs/btrfs/file.c
index 8cf385cc7c91,098bb8f690c9..000000000000
--- a/fs/btrfs/file.c
+++ b/fs/btrfs/file.c
@@@ -1770,34 -1757,22 +1770,42 @@@ static ssize_t btrfs_file_aio_write(str
  	u64 start_pos;
  	u64 end_pos;
  	ssize_t num_written = 0;
 +	ssize_t err = 0;
 +	size_t count, ocount;
  	bool sync = (file->f_flags & O_DSYNC) || IS_SYNC(file->f_mapping->host);
 -	ssize_t err;
 -	loff_t pos;
 -	size_t count;
  
++<<<<<<< HEAD
 +	mutex_lock(&inode->i_mutex);
 +
 +	err = generic_segment_checks(iov, &nr_segs, &ocount, VERIFY_READ);
 +	if (err) {
 +		mutex_unlock(&inode->i_mutex);
 +		goto out;
 +	}
 +	count = ocount;
 +
 +	current->backing_dev_info = inode->i_mapping->backing_dev_info;
 +	err = generic_write_checks(file, &pos, &count, S_ISBLK(inode->i_mode));
 +	if (err) {
 +		mutex_unlock(&inode->i_mutex);
 +		goto out;
 +	}
 +
 +	if (count == 0) {
 +		mutex_unlock(&inode->i_mutex);
 +		goto out;
++=======
+ 	inode_lock(inode);
+ 	err = generic_write_checks(iocb, from);
+ 	if (err <= 0) {
+ 		inode_unlock(inode);
+ 		return err;
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	}
  
 -	current->backing_dev_info = inode_to_bdi(inode);
  	err = file_remove_privs(file);
  	if (err) {
- 		mutex_unlock(&inode->i_mutex);
+ 		inode_unlock(inode);
  		goto out;
  	}
  
@@@ -1835,20 -1812,15 +1843,20 @@@
  	if (sync)
  		atomic_inc(&BTRFS_I(inode)->sync_writers);
  
 -	if (iocb->ki_flags & IOCB_DIRECT) {
 -		num_written = __btrfs_direct_write(iocb, from, pos);
 +	if (file->f_flags & O_DIRECT) {
 +		num_written = __btrfs_direct_write(iocb, iov, nr_segs,
 +						   pos, ppos, count, ocount);
  	} else {
 -		num_written = __btrfs_buffered_write(file, from, pos);
 +		struct iov_iter i;
 +
 +		iov_iter_init(&i, iov, nr_segs, count, num_written);
 +
 +		num_written = __btrfs_buffered_write(file, &i, pos);
  		if (num_written > 0)
 -			iocb->ki_pos = pos + num_written;
 +			*ppos = pos + num_written;
  	}
  
- 	mutex_unlock(&inode->i_mutex);
+ 	inode_unlock(inode);
  
  	/*
  	 * We also have to set last_sub_trans to the current log transid,
diff --cc fs/btrfs/ioctl.c
index 4557a0834a64,952172ca7e45..000000000000
--- a/fs/btrfs/ioctl.c
+++ b/fs/btrfs/ioctl.c
@@@ -2537,9 -2543,9 +2537,9 @@@ out_unlock
  		spin_unlock(&dest->root_item_lock);
  	}
  out_unlock_inode:
- 	mutex_unlock(&inode->i_mutex);
+ 	inode_unlock(inode);
  	if (!err) {
 -		d_invalidate(dentry);
 +		shrink_dcache_sb(root->fs_info->sb);
  		btrfs_invalidate_inodes(dest);
  		d_delete(dentry);
  		ASSERT(dest->send_in_progress == 0);
@@@ -4001,11 -3820,7 +4001,15 @@@ out_unlock
  	if (!same_inode)
  		btrfs_double_inode_unlock(src, inode);
  	else
++<<<<<<< HEAD
 +		mutex_unlock(&src->i_mutex);
 +out_fput:
 +	fdput(src_file);
 +out_drop_write:
 +	mnt_drop_write_file(file);
++=======
+ 		inode_unlock(src);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return ret;
  }
  
diff --cc fs/cachefiles/interface.c
index eb46779fb089,675a3332d72f..000000000000
--- a/fs/cachefiles/interface.c
+++ b/fs/cachefiles/interface.c
@@@ -444,7 -446,7 +444,11 @@@ static int cachefiles_attr_changed(stru
  		return 0;
  
  	cachefiles_begin_secure(cache, &saved_cred);
++<<<<<<< HEAD
 +	mutex_lock(&object->backer->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(object->backer));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	/* if there's an extension to a partial page at the end of the backing
  	 * file, we need to discard the partial page so that we pick up new
@@@ -463,7 -465,7 +467,11 @@@
  	ret = notify_change(object->backer, &newattrs, NULL);
  
  truncate_failed:
++<<<<<<< HEAD
 +	mutex_unlock(&object->backer->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(object->backer));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	cachefiles_end_secure(cache, saved_cred);
  
  	if (ret == -EIO) {
diff --cc fs/cachefiles/namei.c
index 295429faa0d6,1c2334c163dd..000000000000
--- a/fs/cachefiles/namei.c
+++ b/fs/cachefiles/namei.c
@@@ -320,7 -295,7 +320,11 @@@ static int cachefiles_bury_object(struc
  				cachefiles_mark_object_buried(cache, rep, why);
  		}
  
++<<<<<<< HEAD
 +		mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 		inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  		if (ret == -EIO)
  			cachefiles_io_error(cache, "Unlink failed");
@@@ -331,7 -306,7 +335,11 @@@
  
  	/* directories have to be moved to the graveyard */
  	_debug("move stale object to graveyard");
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  try_again:
  	/* first step is to make up a grave dentry in the graveyard */
@@@ -448,13 -423,13 +456,21 @@@ int cachefiles_delete_object(struct cac
  
  	dir = dget_parent(object->dentry);
  
++<<<<<<< HEAD
 +	mutex_lock_nested(&dir->d_inode->i_mutex, I_MUTEX_PARENT);
++=======
+ 	inode_lock_nested(d_inode(dir), I_MUTEX_PARENT);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if (test_bit(FSCACHE_OBJECT_KILLED_BY_CACHE, &object->fscache.flags)) {
  		/* object allocation for the same key preemptively deleted this
  		 * object's file so that it could create its own file */
  		_debug("object preemptively buried");
++<<<<<<< HEAD
 +		mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 		inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		ret = 0;
  	} else {
  		/* we need to check that our parent is _still_ our parent - it
@@@ -467,7 -442,7 +483,11 @@@
  			/* it got moved, presumably by cachefilesd culling it,
  			 * so it's no longer in the key path and we can ignore
  			 * it */
++<<<<<<< HEAD
 +			mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 			inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  			ret = 0;
  		}
  	}
@@@ -526,7 -501,7 +546,11 @@@ lookup_again
  	/* search the current directory for the element name */
  	_debug("lookup '%s'", name);
  
++<<<<<<< HEAD
 +	mutex_lock_nested(&dir->d_inode->i_mutex, I_MUTEX_PARENT);
++=======
+ 	inode_lock_nested(d_inode(dir), I_MUTEX_PARENT);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	start = jiffies;
  	next = lookup_one_len(name, dir, nlen);
@@@ -610,7 -585,7 +634,11 @@@
  	/* process the next component */
  	if (key) {
  		_debug("advance");
++<<<<<<< HEAD
 +		mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 		inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		dput(dir);
  		dir = next;
  		next = NULL;
@@@ -649,7 -623,7 +677,11 @@@
  	/* note that we're now using this object */
  	ret = cachefiles_mark_object_active(cache, object);
  
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dput(dir);
  	dir = NULL;
  
@@@ -728,7 -705,7 +760,11 @@@ lookup_error
  		cachefiles_io_error(cache, "Lookup failed");
  	next = NULL;
  error:
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dput(next);
  error_out2:
  	dput(dir);
@@@ -752,7 -729,7 +788,11 @@@ struct dentry *cachefiles_get_directory
  	_enter(",,%s", dirname);
  
  	/* search the current directory for the element name */
++<<<<<<< HEAD
 +	mutex_lock(&dir->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	start = jiffies;
  	subdir = lookup_one_len(dirname, dir, strlen(dirname));
@@@ -787,16 -764,16 +827,20 @@@
  
  		_debug("mkdir -> %p{%p{ino=%lu}}",
  		       subdir,
 -		       d_backing_inode(subdir),
 -		       d_backing_inode(subdir)->i_ino);
 +		       subdir->d_inode,
 +		       subdir->d_inode->i_ino);
  	}
  
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	/* we need to make sure the subdir is a directory */
 -	ASSERT(d_backing_inode(subdir));
 +	ASSERT(subdir->d_inode);
  
 -	if (!d_can_lookup(subdir)) {
 +	if (!S_ISDIR(subdir->d_inode->i_mode)) {
  		pr_err("%s is not a directory\n", dirname);
  		ret = -EIO;
  		goto check_error;
@@@ -822,19 -800,19 +866,31 @@@ check_error
  	return ERR_PTR(ret);
  
  mkdir_error:
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dput(subdir);
  	pr_err("mkdir %s failed with error %d\n", dirname, ret);
  	return ERR_PTR(ret);
  
  lookup_error:
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	ret = PTR_ERR(subdir);
  	pr_err("Lookup %s failed with error %d\n", dirname, ret);
  	return ERR_PTR(ret);
  
  nomem_d_alloc:
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	_leave(" = -ENOMEM");
  	return ERR_PTR(-ENOMEM);
  }
@@@ -855,11 -833,11 +911,15 @@@ static struct dentry *cachefiles_check_
  	unsigned long start;
  	int ret;
  
 -	//_enter(",%pd/,%s",
 -	//       dir, filename);
 +	//_enter(",%*.*s/,%s",
 +	//       dir->d_name.len, dir->d_name.len, dir->d_name.name, filename);
  
  	/* look up the victim */
++<<<<<<< HEAD
 +	mutex_lock_nested(&dir->d_inode->i_mutex, I_MUTEX_PARENT);
++=======
+ 	inode_lock_nested(d_inode(dir), I_MUTEX_PARENT);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	start = jiffies;
  	victim = lookup_one_len(filename, dir, strlen(filename));
@@@ -873,8 -851,8 +933,13 @@@
  	/* if the object is no longer there then we probably retired the object
  	 * at the netfs's request whilst the cull was in progress
  	 */
++<<<<<<< HEAD
 +	if (!victim->d_inode) {
 +		mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	if (d_is_negative(victim)) {
+ 		inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		dput(victim);
  		_leave(" = -ENOENT [absent]");
  		return ERR_PTR(-ENOENT);
@@@ -903,13 -881,13 +968,21 @@@
  
  object_in_use:
  	read_unlock(&cache->active_lock);
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dput(victim);
  	//_leave(" = -EBUSY [in use]");
  	return ERR_PTR(-EBUSY);
  
  lookup_error:
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	ret = PTR_ERR(victim);
  	if (ret == -ENOENT) {
  		/* file or dir now absent - probably retired by netfs */
@@@ -970,7 -947,7 +1043,11 @@@ int cachefiles_cull(struct cachefiles_c
  	return 0;
  
  error_unlock:
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  error:
  	dput(victim);
  	if (ret == -ENOENT) {
@@@ -1005,7 -982,7 +1082,11 @@@ int cachefiles_check_in_use(struct cach
  	if (IS_ERR(victim))
  		return PTR_ERR(victim);
  
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dput(victim);
  	//_leave(" = 0");
  	return 0;
diff --cc fs/ceph/export.c
index fc5e552e7766,3b3172357326..000000000000
--- a/fs/ceph/export.c
+++ b/fs/ceph/export.c
@@@ -228,16 -215,16 +228,24 @@@ static int ceph_get_name(struct dentry 
  	if (IS_ERR(req))
  		return PTR_ERR(req);
  
++<<<<<<< HEAD
 +	mutex_lock(&parent->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
 -	req->r_inode = d_inode(child);
 -	ihold(d_inode(child));
 -	req->r_ino2 = ceph_vino(d_inode(parent));
 -	req->r_locked_dir = d_inode(parent);
 +	req->r_inode = child->d_inode;
 +	ihold(child->d_inode);
 +	req->r_ino2 = ceph_vino(parent->d_inode);
 +	req->r_locked_dir = parent->d_inode;
  	req->r_num_caps = 2;
  	err = ceph_mdsc_do_request(mdsc, NULL, req);
  
++<<<<<<< HEAD
 +	mutex_unlock(&parent->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if (!err) {
  		struct ceph_mds_reply_info_parsed *rinfo = &req->r_reply_info;
diff --cc fs/ceph/file.c
index 1d49d61253bc,10c5ae79696e..000000000000
--- a/fs/ceph/file.c
+++ b/fs/ceph/file.c
@@@ -1321,16 -1014,12 +1321,16 @@@ static ssize_t ceph_aio_write(struct ki
  	if (!prealloc_cf)
  		return -ENOMEM;
  
- 	mutex_lock(&inode->i_mutex);
+ 	inode_lock(inode);
  
 +	err = generic_segment_checks(iov, &nr_segs, &count, VERIFY_READ);
 +	if (err)
 +		goto out;
 +
  	/* We can write back this queue in page reclaim */
 -	current->backing_dev_info = inode_to_bdi(inode);
 +	current->backing_dev_info = file->f_mapping->backing_dev_info;
  
 -	if (iocb->ki_flags & IOCB_APPEND) {
 +	if (file->f_flags & O_APPEND) {
  		err = ceph_do_getattr(inode, CEPH_STAT_CAP_SIZE, false);
  		if (err < 0)
  			goto out;
@@@ -1379,10 -1067,10 +1379,15 @@@ retry_snap
  	     inode, ceph_vinop(inode), pos, count, ceph_cap_string(got));
  
  	if ((got & (CEPH_CAP_FILE_BUFFER|CEPH_CAP_FILE_LAZYIO)) == 0 ||
 -	    (iocb->ki_flags & IOCB_DIRECT) || (fi->flags & CEPH_F_SYNC)) {
 +	    (file->f_flags & O_DIRECT) || (fi->flags & CEPH_F_SYNC)) {
  		struct ceph_snap_context *snapc;
++<<<<<<< HEAD
 +		struct iov_iter i;
 +		mutex_unlock(&inode->i_mutex);
++=======
+ 		struct iov_iter data;
+ 		inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  		spin_lock(&ci->i_ceph_lock);
  		if (__ceph_have_pending_cap_snap(ci)) {
@@@ -1409,12 -1096,15 +1414,17 @@@
  			dout("aio_write %p %llx.%llx %llu~%u"
  				"got EOLDSNAPC, retrying\n",
  				inode, ceph_vinop(inode),
++<<<<<<< HEAD
 +				pos, (unsigned)iov->iov_len);
 +			mutex_lock(&inode->i_mutex);
++=======
+ 				pos, (unsigned)count);
+ 			inode_lock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  			goto retry_snap;
  		}
 -		if (written > 0)
 -			iov_iter_advance(from, written);
  		ceph_put_snap_context(snapc);
  	} else {
 -		loff_t old_size = inode->i_size;
  		/*
  		 * No need to acquire the i_truncate_mutex. Because
  		 * the MDS revokes Fwb caps before sending truncate
@@@ -1422,10 -1112,12 +1432,19 @@@
  		 * are pending vmtruncate. So write and vmtruncate
  		 * can not run at the same time
  		 */
++<<<<<<< HEAD
 +		written = generic_file_buffered_write(iocb, iov, nr_segs,
 +						      pos, &iocb->ki_pos,
 +						      count, 0);
 +		mutex_unlock(&inode->i_mutex);
++=======
+ 		written = generic_perform_write(file, from, pos);
+ 		if (likely(written >= 0))
+ 			iocb->ki_pos = pos + written;
+ 		if (inode->i_size > old_size)
+ 			ceph_fscache_update_objectsize(inode);
+ 		inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	}
  
  	if (written >= 0) {
@@@ -1468,10 -1160,9 +1487,10 @@@ out_unlocked
  static loff_t ceph_llseek(struct file *file, loff_t offset, int whence)
  {
  	struct inode *inode = file->f_mapping->host;
 +	loff_t i_size;
  	int ret;
  
- 	mutex_lock(&inode->i_mutex);
+ 	inode_lock(inode);
  
  	if (whence == SEEK_END || whence == SEEK_DATA || whence == SEEK_HOLE) {
  		ret = ceph_do_getattr(inode, CEPH_STAT_CAP_SIZE, false);
diff --cc fs/cifs/file.c
index c259c09ba911,ff882aeaccc6..000000000000
--- a/fs/cifs/file.c
+++ b/fs/cifs/file.c
@@@ -2692,25 -2672,25 +2692,42 @@@ cifs_writev(struct kiocb *iocb, const s
  	 * with a brlock that prevents writing.
  	 */
  	down_read(&cinode->lock_sem);
++<<<<<<< HEAD
 +	mutex_lock(&inode->i_mutex);
 +	if (file->f_flags & O_APPEND)
 +		lock_pos = i_size_read(inode);
 +	if (!cifs_find_lock_conflict(cfile, lock_pos, iov_length(iov, nr_segs),
 +				     server->vals->exclusive_lock_type, NULL,
 +				     CIFS_WRITE_OP)) {
 +		rc = __generic_file_aio_write(iocb, iov, nr_segs,
 +						&iocb->ki_pos);
 +		mutex_unlock(&inode->i_mutex);
++=======
+ 	inode_lock(inode);
+ 
+ 	rc = generic_write_checks(iocb, from);
+ 	if (rc <= 0)
+ 		goto out;
+ 
+ 	if (!cifs_find_lock_conflict(cfile, iocb->ki_pos, iov_iter_count(from),
+ 				     server->vals->exclusive_lock_type, NULL,
+ 				     CIFS_WRITE_OP))
+ 		rc = __generic_file_write_iter(iocb, from);
+ 	else
+ 		rc = -EACCES;
+ out:
+ 	inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
 -	if (rc > 0) {
 -		ssize_t err = generic_write_sync(file, iocb->ki_pos - rc, rc);
 -		if (err < 0)
 -			rc = err;
 +		if (rc > 0) {
 +			ssize_t err;
 +
 +			err = generic_write_sync(file, iocb->ki_pos - rc, rc);
 +			if (err < 0)
 +				rc = err;
 +		}
 +	} else {
 +		mutex_unlock(&inode->i_mutex);
  	}
  	up_read(&cinode->lock_sem);
  	return rc;
diff --cc fs/coda/dir.c
index c424e27b42f9,42e731b8c80a..000000000000
--- a/fs/coda/dir.c
+++ b/fs/coda/dir.c
@@@ -532,7 -410,34 +532,38 @@@ static int coda_venus_readdir(struct fi
  	}
  out:
  	kfree(vdir);
++<<<<<<< HEAD
 +	return result ? result : ret;
++=======
+ 	return 0;
+ }
+ 
+ /* file operations for directories */
+ static int coda_readdir(struct file *coda_file, struct dir_context *ctx)
+ {
+ 	struct coda_file_info *cfi;
+ 	struct file *host_file;
+ 	int ret;
+ 
+ 	cfi = CODA_FTOC(coda_file);
+ 	BUG_ON(!cfi || cfi->cfi_magic != CODA_MAGIC);
+ 	host_file = cfi->cfi_container;
+ 
+ 	if (host_file->f_op->iterate) {
+ 		struct inode *host_inode = file_inode(host_file);
+ 
+ 		inode_lock(host_inode);
+ 		ret = -ENOENT;
+ 		if (!IS_DEADDIR(host_inode)) {
+ 			ret = host_file->f_op->iterate(host_file, ctx);
+ 			file_accessed(host_file);
+ 		}
+ 		inode_unlock(host_inode);
+ 		return ret;
+ 	}
+ 	/* Venus: we must read Venus dirents from a file */
+ 	return coda_venus_readdir(coda_file, ctx);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  }
  
  /* called when a cache lookup succeeds */
diff --cc fs/coda/file.c
index 380b798f8443,f47c7483863b..000000000000
--- a/fs/coda/file.c
+++ b/fs/coda/file.c
@@@ -71,25 -67,17 +71,31 @@@ coda_file_write(struct file *coda_file
  	struct file *host_file;
  	ssize_t ret;
  
 +	cfi = CODA_FTOC(coda_file);
  	BUG_ON(!cfi || cfi->cfi_magic != CODA_MAGIC);
 -
  	host_file = cfi->cfi_container;
 +
 +	if (!host_file->f_op || !host_file->f_op->write)
 +		return -EINVAL;
 +
 +	host_inode = file_inode(host_file);
  	file_start_write(host_file);
++<<<<<<< HEAD
 +	mutex_lock(&coda_inode->i_mutex);
 +
 +	ret = host_file->f_op->write(host_file, buf, count, ppos);
 +
 +	coda_inode->i_size = host_inode->i_size;
++=======
+ 	inode_lock(coda_inode);
+ 	ret = vfs_iter_write(cfi->cfi_container, to, &iocb->ki_pos);
+ 	coda_inode->i_size = file_inode(host_file)->i_size;
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	coda_inode->i_blocks = (coda_inode->i_size + 511) >> 9;
  	coda_inode->i_mtime = coda_inode->i_ctime = CURRENT_TIME_SEC;
- 	mutex_unlock(&coda_inode->i_mutex);
+ 	inode_unlock(coda_inode);
  	file_end_write(host_file);
 +
  	return ret;
  }
  
diff --cc fs/configfs/dir.c
index 8e466317b895,f419519ec41f..000000000000
--- a/fs/configfs/dir.c
+++ b/fs/configfs/dir.c
@@@ -642,13 -640,13 +642,21 @@@ static void detach_groups(struct config
  
  		child = sd->s_dentry;
  
++<<<<<<< HEAD
 +		mutex_lock(&child->d_inode->i_mutex);
++=======
+ 		inode_lock(d_inode(child));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  		configfs_detach_group(sd->s_element);
 -		d_inode(child)->i_flags |= S_DEAD;
 +		child->d_inode->i_flags |= S_DEAD;
  		dont_mount(child);
  
++<<<<<<< HEAD
 +		mutex_unlock(&child->d_inode->i_mutex);
++=======
+ 		inode_unlock(d_inode(child));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  		d_delete(child);
  		dput(child);
@@@ -840,11 -834,11 +848,19 @@@ static int configfs_attach_item(struct 
  			 * the VFS may already have hit and used them. Thus,
  			 * we must lock them as rmdir() would.
  			 */
++<<<<<<< HEAD
 +			mutex_lock(&dentry->d_inode->i_mutex);
++=======
+ 			inode_lock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  			configfs_remove_dir(item);
 -			d_inode(dentry)->i_flags |= S_DEAD;
 +			dentry->d_inode->i_flags |= S_DEAD;
  			dont_mount(dentry);
++<<<<<<< HEAD
 +			mutex_unlock(&dentry->d_inode->i_mutex);
++=======
+ 			inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  			d_delete(dentry);
  		}
  	}
@@@ -880,7 -874,7 +896,11 @@@ static int configfs_attach_group(struc
  		 * We must also lock the inode to remove it safely in case of
  		 * error, as rmdir() would.
  		 */
++<<<<<<< HEAD
 +		mutex_lock_nested(&dentry->d_inode->i_mutex, I_MUTEX_CHILD);
++=======
+ 		inode_lock_nested(d_inode(dentry), I_MUTEX_CHILD);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		configfs_adjust_dir_dirent_depth_before_populate(sd);
  		ret = populate_groups(to_config_group(item));
  		if (ret) {
@@@ -889,7 -883,7 +909,11 @@@
  			dont_mount(dentry);
  		}
  		configfs_adjust_dir_dirent_depth_after_populate(sd);
++<<<<<<< HEAD
 +		mutex_unlock(&dentry->d_inode->i_mutex);
++=======
+ 		inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		if (ret)
  			d_delete(dentry);
  	}
@@@ -1097,43 -1135,19 +1121,51 @@@ int configfs_depend_item(struct configf
  	 * subsystem is really registered, and so we need to lock out
  	 * configfs_[un]register_subsystem().
  	 */
++<<<<<<< HEAD
 +	mutex_lock(&root->d_inode->i_mutex);
 +
 +	root_sd = root->d_fsdata;
 +
 +	list_for_each_entry(p, &root_sd->s_children, s_sibling) {
 +		if (p->s_type & CONFIGFS_DIR) {
 +			if (p->s_element == s_item) {
 +				subsys_sd = p;
 +				break;
 +			}
 +		}
 +	}
++=======
+ 	inode_lock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
 -	subsys_sd = configfs_find_subsys_dentry(root->d_fsdata, s_item);
  	if (!subsys_sd) {
  		ret = -ENOENT;
  		goto out_unlock_fs;
  	}
  
  	/* Ok, now we can trust subsys/s_item */
 -	ret = configfs_do_depend_item(subsys_sd->s_dentry, target);
  
 +	spin_lock(&configfs_dirent_lock);
 +	/* Scan the tree, return 0 if found */
 +	ret = configfs_depend_prep(subsys_sd->s_dentry, target);
 +	if (ret)
 +		goto out_unlock_dirent_lock;
 +
 +	/*
 +	 * We are sure that the item is not about to be removed by rmdir(), and
 +	 * not in the middle of attachment by mkdir().
 +	 */
 +	p = target->ci_dentry->d_fsdata;
 +	p->s_dependent_count += 1;
 +
 +out_unlock_dirent_lock:
 +	spin_unlock(&configfs_dirent_lock);
  out_unlock_fs:
++<<<<<<< HEAD
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	/*
  	 * If we succeeded, the fs is pinned via other methods.  If not,
@@@ -1174,6 -1187,79 +1206,82 @@@ void configfs_undepend_item(struct conf
  }
  EXPORT_SYMBOL(configfs_undepend_item);
  
++<<<<<<< HEAD
++=======
+ /*
+  * caller_subsys is a caller's subsystem not target's. This is used to
+  * determine if we should lock root and check subsys or not. When we are
+  * in the same subsystem as our target there is no need to do locking as
+  * we know that subsys is valid and is not unregistered during this function
+  * as we are called from callback of one of his children and VFS holds a lock
+  * on some inode. Otherwise we have to lock our root to  ensure that target's
+  * subsystem it is not unregistered during this function.
+  */
+ int configfs_depend_item_unlocked(struct configfs_subsystem *caller_subsys,
+ 				  struct config_item *target)
+ {
+ 	struct configfs_subsystem *target_subsys;
+ 	struct config_group *root, *parent;
+ 	struct configfs_dirent *subsys_sd;
+ 	int ret = -ENOENT;
+ 
+ 	/* Disallow this function for configfs root */
+ 	if (configfs_is_root(target))
+ 		return -EINVAL;
+ 
+ 	parent = target->ci_group;
+ 	/*
+ 	 * This may happen when someone is trying to depend root
+ 	 * directory of some subsystem
+ 	 */
+ 	if (configfs_is_root(&parent->cg_item)) {
+ 		target_subsys = to_configfs_subsystem(to_config_group(target));
+ 		root = parent;
+ 	} else {
+ 		target_subsys = parent->cg_subsys;
+ 		/* Find a cofnigfs root as we may need it for locking */
+ 		for (root = parent; !configfs_is_root(&root->cg_item);
+ 		     root = root->cg_item.ci_group)
+ 			;
+ 	}
+ 
+ 	if (target_subsys != caller_subsys) {
+ 		/*
+ 		 * We are in other configfs subsystem, so we have to do
+ 		 * additional locking to prevent other subsystem from being
+ 		 * unregistered
+ 		 */
+ 		inode_lock(d_inode(root->cg_item.ci_dentry));
+ 
+ 		/*
+ 		 * As we are trying to depend item from other subsystem
+ 		 * we have to check if this subsystem is still registered
+ 		 */
+ 		subsys_sd = configfs_find_subsys_dentry(
+ 				root->cg_item.ci_dentry->d_fsdata,
+ 				&target_subsys->su_group.cg_item);
+ 		if (!subsys_sd)
+ 			goto out_root_unlock;
+ 	} else {
+ 		subsys_sd = target_subsys->su_group.cg_item.ci_dentry->d_fsdata;
+ 	}
+ 
+ 	/* Now we can execute core of depend item */
+ 	ret = configfs_do_depend_item(subsys_sd->s_dentry, target);
+ 
+ 	if (target_subsys != caller_subsys)
+ out_root_unlock:
+ 		/*
+ 		 * We were called from subsystem other than our target so we
+ 		 * took some locks so now it's time to release them
+ 		 */
+ 		inode_unlock(d_inode(root->cg_item.ci_dentry));
+ 
+ 	return ret;
+ }
+ EXPORT_SYMBOL(configfs_depend_item_unlocked);
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  static int configfs_mkdir(struct inode *dir, struct dentry *dentry, umode_t mode)
  {
  	int ret = 0;
@@@ -1475,7 -1561,7 +1583,11 @@@ int configfs_rename_dir(struct config_i
  	down_write(&configfs_rename_sem);
  	parent = item->parent->dentry;
  
++<<<<<<< HEAD
 +	mutex_lock(&parent->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	new_dentry = lookup_one_len(new_name, parent, strlen(new_name));
  	if (!IS_ERR(new_dentry)) {
@@@ -1491,7 -1577,7 +1603,11 @@@
  			error = -EEXIST;
  		dput(new_dentry);
  	}
++<<<<<<< HEAD
 +	mutex_unlock(&parent->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	up_write(&configfs_rename_sem);
  
  	return error;
@@@ -1504,7 -1590,7 +1620,11 @@@ static int configfs_dir_open(struct ino
  	struct configfs_dirent * parent_sd = dentry->d_fsdata;
  	int err;
  
++<<<<<<< HEAD
 +	mutex_lock(&dentry->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	/*
  	 * Fake invisibility if dir belongs to a group/default groups hierarchy
  	 * being attached
@@@ -1517,7 -1603,7 +1637,11 @@@
  		else
  			err = 0;
  	}
++<<<<<<< HEAD
 +	mutex_unlock(&dentry->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	return err;
  }
@@@ -1527,11 -1613,11 +1651,19 @@@ static int configfs_dir_close(struct in
  	struct dentry * dentry = file->f_path.dentry;
  	struct configfs_dirent * cursor = file->private_data;
  
++<<<<<<< HEAD
 +	mutex_lock(&dentry->d_inode->i_mutex);
 +	spin_lock(&configfs_dirent_lock);
 +	list_del_init(&cursor->s_sibling);
 +	spin_unlock(&configfs_dirent_lock);
 +	mutex_unlock(&dentry->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(dentry));
+ 	spin_lock(&configfs_dirent_lock);
+ 	list_del_init(&cursor->s_sibling);
+ 	spin_unlock(&configfs_dirent_lock);
+ 	inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	release_configfs_dirent(cursor);
  
@@@ -1630,7 -1698,7 +1762,11 @@@ static loff_t configfs_dir_lseek(struc
  {
  	struct dentry * dentry = file->f_path.dentry;
  
++<<<<<<< HEAD
 +	mutex_lock(&dentry->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	switch (whence) {
  		case 1:
  			offset += file->f_pos;
@@@ -1638,7 -1706,7 +1774,11 @@@
  			if (offset >= 0)
  				break;
  		default:
++<<<<<<< HEAD
 +			mutex_unlock(&file_inode(file)->i_mutex);
++=======
+ 			inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  			return -EINVAL;
  	}
  	if (offset != file->f_pos) {
@@@ -1664,7 -1732,7 +1804,11 @@@
  			spin_unlock(&configfs_dirent_lock);
  		}
  	}
++<<<<<<< HEAD
 +	mutex_unlock(&dentry->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return offset;
  }
  
@@@ -1673,9 -1741,119 +1817,122 @@@ const struct file_operations configfs_d
  	.release	= configfs_dir_close,
  	.llseek		= configfs_dir_lseek,
  	.read		= generic_read_dir,
 -	.iterate	= configfs_readdir,
 +	.readdir	= configfs_readdir,
  };
  
++<<<<<<< HEAD
++=======
+ /**
+  * configfs_register_group - creates a parent-child relation between two groups
+  * @parent_group:	parent group
+  * @group:		child group
+  *
+  * link groups, creates dentry for the child and attaches it to the
+  * parent dentry.
+  *
+  * Return: 0 on success, negative errno code on error
+  */
+ int configfs_register_group(struct config_group *parent_group,
+ 			    struct config_group *group)
+ {
+ 	struct configfs_subsystem *subsys = parent_group->cg_subsys;
+ 	struct dentry *parent;
+ 	int ret;
+ 
+ 	mutex_lock(&subsys->su_mutex);
+ 	link_group(parent_group, group);
+ 	mutex_unlock(&subsys->su_mutex);
+ 
+ 	parent = parent_group->cg_item.ci_dentry;
+ 
+ 	inode_lock_nested(d_inode(parent), I_MUTEX_PARENT);
+ 	ret = create_default_group(parent_group, group);
+ 	if (!ret) {
+ 		spin_lock(&configfs_dirent_lock);
+ 		configfs_dir_set_ready(group->cg_item.ci_dentry->d_fsdata);
+ 		spin_unlock(&configfs_dirent_lock);
+ 	}
+ 	inode_unlock(d_inode(parent));
+ 	return ret;
+ }
+ EXPORT_SYMBOL(configfs_register_group);
+ 
+ /**
+  * configfs_unregister_group() - unregisters a child group from its parent
+  * @group: parent group to be unregistered
+  *
+  * Undoes configfs_register_group()
+  */
+ void configfs_unregister_group(struct config_group *group)
+ {
+ 	struct configfs_subsystem *subsys = group->cg_subsys;
+ 	struct dentry *dentry = group->cg_item.ci_dentry;
+ 	struct dentry *parent = group->cg_item.ci_parent->ci_dentry;
+ 
+ 	inode_lock_nested(d_inode(parent), I_MUTEX_PARENT);
+ 	spin_lock(&configfs_dirent_lock);
+ 	configfs_detach_prep(dentry, NULL);
+ 	spin_unlock(&configfs_dirent_lock);
+ 
+ 	configfs_detach_group(&group->cg_item);
+ 	d_inode(dentry)->i_flags |= S_DEAD;
+ 	dont_mount(dentry);
+ 	d_delete(dentry);
+ 	inode_unlock(d_inode(parent));
+ 
+ 	dput(dentry);
+ 
+ 	mutex_lock(&subsys->su_mutex);
+ 	unlink_group(group);
+ 	mutex_unlock(&subsys->su_mutex);
+ }
+ EXPORT_SYMBOL(configfs_unregister_group);
+ 
+ /**
+  * configfs_register_default_group() - allocates and registers a child group
+  * @parent_group:	parent group
+  * @name:		child group name
+  * @item_type:		child item type description
+  *
+  * boilerplate to allocate and register a child group with its parent. We need
+  * kzalloc'ed memory because child's default_group is initially empty.
+  *
+  * Return: allocated config group or ERR_PTR() on error
+  */
+ struct config_group *
+ configfs_register_default_group(struct config_group *parent_group,
+ 				const char *name,
+ 				struct config_item_type *item_type)
+ {
+ 	int ret;
+ 	struct config_group *group;
+ 
+ 	group = kzalloc(sizeof(*group), GFP_KERNEL);
+ 	if (!group)
+ 		return ERR_PTR(-ENOMEM);
+ 	config_group_init_type_name(group, name, item_type);
+ 
+ 	ret = configfs_register_group(parent_group, group);
+ 	if (ret) {
+ 		kfree(group);
+ 		return ERR_PTR(ret);
+ 	}
+ 	return group;
+ }
+ EXPORT_SYMBOL(configfs_register_default_group);
+ 
+ /**
+  * configfs_unregister_default_group() - unregisters and frees a child group
+  * @group:	the group to act on
+  */
+ void configfs_unregister_default_group(struct config_group *group)
+ {
+ 	configfs_unregister_group(group);
+ 	kfree(group);
+ }
+ EXPORT_SYMBOL(configfs_unregister_default_group);
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  int configfs_register_subsystem(struct configfs_subsystem *subsys)
  {
  	int err;
@@@ -1695,14 -1872,10 +1952,18 @@@
  	sd = root->d_fsdata;
  	link_group(to_config_group(sd->s_element), group);
  
++<<<<<<< HEAD
 +	mutex_lock_nested(&root->d_inode->i_mutex, I_MUTEX_PARENT);
 +
 +	name.name = group->cg_item.ci_name;
 +	name.len = strlen(name.name);
 +	name.hash = full_name_hash(name.name, name.len);
++=======
+ 	inode_lock_nested(d_inode(root), I_MUTEX_PARENT);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	err = -ENOMEM;
 -	dentry = d_alloc_name(root, group->cg_item.ci_name);
 +	dentry = d_alloc(root, &name);
  	if (dentry) {
  		d_add(dentry, NULL);
  
@@@ -1719,7 -1892,7 +1980,11 @@@
  		}
  	}
  
++<<<<<<< HEAD
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if (err) {
  		unlink_group(group);
@@@ -1740,9 -1913,9 +2005,15 @@@ void configfs_unregister_subsystem(stru
  		return;
  	}
  
++<<<<<<< HEAD
 +	mutex_lock_nested(&root->d_inode->i_mutex,
 +			  I_MUTEX_PARENT);
 +	mutex_lock_nested(&dentry->d_inode->i_mutex, I_MUTEX_CHILD);
++=======
+ 	inode_lock_nested(d_inode(root),
+ 			  I_MUTEX_PARENT);
+ 	inode_lock_nested(d_inode(dentry), I_MUTEX_CHILD);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	mutex_lock(&configfs_symlink_mutex);
  	spin_lock(&configfs_dirent_lock);
  	if (configfs_detach_prep(dentry, NULL)) {
@@@ -1751,13 -1924,13 +2022,21 @@@
  	spin_unlock(&configfs_dirent_lock);
  	mutex_unlock(&configfs_symlink_mutex);
  	configfs_detach_group(&group->cg_item);
 -	d_inode(dentry)->i_flags |= S_DEAD;
 +	dentry->d_inode->i_flags |= S_DEAD;
  	dont_mount(dentry);
++<<<<<<< HEAD
 +	mutex_unlock(&dentry->d_inode->i_mutex);
 +
 +	d_delete(dentry);
 +
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dentry));
+ 
+ 	d_delete(dentry);
+ 
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	dput(dentry);
  
diff --cc fs/configfs/file.c
index 8816d0561e5e,33b7ee34eda5..000000000000
--- a/fs/configfs/file.c
+++ b/fs/configfs/file.c
@@@ -343,9 -535,37 +343,41 @@@ int configfs_add_file(struct dentry * d
  
  int configfs_create_file(struct config_item * item, const struct configfs_attribute * attr)
  {
 -	struct dentry *dir = item->ci_dentry;
 -	struct configfs_dirent *parent_sd = dir->d_fsdata;
 -	umode_t mode = (attr->ca_mode & S_IALLUGO) | S_IFREG;
 -	int error = 0;
 +	BUG_ON(!item || !item->ci_dentry || !attr);
 +
++<<<<<<< HEAD
 +	return configfs_add_file(item->ci_dentry, attr,
 +				 CONFIGFS_ITEM_ATTR);
 +}
  
++=======
+ 	inode_lock_nested(d_inode(dir), I_MUTEX_NORMAL);
+ 	error = configfs_make_dirent(parent_sd, NULL, (void *) attr, mode,
+ 				     CONFIGFS_ITEM_ATTR);
+ 	inode_unlock(d_inode(dir));
+ 
+ 	return error;
+ }
+ 
+ /**
+  *	configfs_create_bin_file - create a binary attribute file for an item.
+  *	@item:	item we're creating for.
+  *	@attr:	atrribute descriptor.
+  */
+ 
+ int configfs_create_bin_file(struct config_item *item,
+ 		const struct configfs_bin_attribute *bin_attr)
+ {
+ 	struct dentry *dir = item->ci_dentry;
+ 	struct configfs_dirent *parent_sd = dir->d_fsdata;
+ 	umode_t mode = (bin_attr->cb_attr.ca_mode & S_IALLUGO) | S_IFREG;
+ 	int error = 0;
+ 
+ 	inode_lock_nested(dir->d_inode, I_MUTEX_NORMAL);
+ 	error = configfs_make_dirent(parent_sd, NULL, (void *) bin_attr, mode,
+ 				     CONFIGFS_ITEM_BIN_ATTR);
+ 	inode_unlock(dir->d_inode);
+ 
+ 	return error;
+ }
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
diff --cc fs/configfs/inode.c
index a9d35b0e06cf,cee087d8f7e0..000000000000
--- a/fs/configfs/inode.c
+++ b/fs/configfs/inode.c
@@@ -269,7 -255,7 +269,11 @@@ void configfs_hash_and_remove(struct de
  		/* no inode means this hasn't been made visible yet */
  		return;
  
++<<<<<<< HEAD
 +	mutex_lock(&dir->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	list_for_each_entry(sd, &parent_sd->s_children, s_sibling) {
  		if (!sd->s_element)
  			continue;
@@@ -282,15 -268,5 +286,19 @@@
  			break;
  		}
  	}
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
 +}
 +
 +int __init configfs_inode_init(void)
 +{
 +	return bdi_init(&configfs_backing_dev_info);
 +}
 +
 +void configfs_inode_exit(void)
 +{
 +	bdi_destroy(&configfs_backing_dev_info);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  }
diff --cc fs/dax.c
index 365b0662df80,55aa273145a8..000000000000
--- a/fs/dax.c
+++ b/fs/dax.c
@@@ -288,17 -242,16 +288,17 @@@ ssize_t dax_do_io(int rw, struct kiocb 
  {
  	struct buffer_head bh;
  	ssize_t retval = -EINVAL;
 -	loff_t end = pos + iov_iter_count(iter);
 +	loff_t end = pos + iov_length(iov, nr_segs);
  
  	memset(&bh, 0, sizeof(bh));
 +	bh.b_bdev = inode->i_sb->s_bdev;
  
 -	if ((flags & DIO_LOCKING) && iov_iter_rw(iter) == READ) {
 +	if ((flags & DIO_LOCKING) && (rw == READ)) {
  		struct address_space *mapping = inode->i_mapping;
- 		mutex_lock(&inode->i_mutex);
+ 		inode_lock(inode);
  		retval = filemap_write_and_wait_range(mapping, pos, end - 1);
  		if (retval) {
- 			mutex_unlock(&inode->i_mutex);
+ 			inode_unlock(inode);
  			goto out;
  		}
  	}
@@@ -307,13 -260,13 +307,18 @@@
  	if (!(flags & DIO_SKIP_DIO_COUNT))
  		inode_dio_begin(inode);
  
 -	retval = dax_io(inode, iter, pos, end, get_block, &bh);
 +	retval = dax_io(rw, inode, iov, pos, end, get_block, &bh);
  
++<<<<<<< HEAD
 +	if ((flags & DIO_LOCKING) && (rw == READ))
 +		mutex_unlock(&inode->i_mutex);
++=======
+ 	if ((flags & DIO_LOCKING) && iov_iter_rw(iter) == READ)
+ 		inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if ((retval > 0) && end_io)
 -		end_io(iocb, pos, retval, bh.b_private);
 +		end_io(iocb, pos, retval, bh.b_private, retval, false);
  
  	if (!(flags & DIO_SKIP_DIO_COUNT))
  		inode_dio_end(inode);
diff --cc fs/debugfs/inode.c
index c7c83ff0f752,bece948b363d..000000000000
--- a/fs/debugfs/inode.c
+++ b/fs/debugfs/inode.c
@@@ -323,33 -265,32 +323,59 @@@ static struct dentry *__create_file(con
  	if (!parent)
  		parent = debugfs_mount->mnt_root;
  
++<<<<<<< HEAD
 +	mutex_lock(&parent->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dentry = lookup_one_len(name, parent, strlen(name));
 -	if (!IS_ERR(dentry) && d_really_is_positive(dentry)) {
 +	if (!IS_ERR(dentry)) {
 +		switch (mode & S_IFMT) {
 +		case S_IFDIR:
 +			error = debugfs_mkdir(parent->d_inode, dentry, mode);
 +					      
 +			break;
 +		case S_IFLNK:
 +			error = debugfs_link(parent->d_inode, dentry, mode,
 +					     data);
 +			break;
 +		default:
 +			error = debugfs_create(parent->d_inode, dentry, mode,
 +					       data, fops);
 +			break;
 +		}
  		dput(dentry);
 -		dentry = ERR_PTR(-EEXIST);
 -	}
 +	} else
 +		error = PTR_ERR(dentry);
 +	mutex_unlock(&parent->d_inode->i_mutex);
  
++<<<<<<< HEAD
 +	if (error) {
 +		dentry = NULL;
 +		simple_release_fs(&debugfs_mount, &debugfs_mount_count);
 +	}
 +exit:
++=======
+ 	if (IS_ERR(dentry)) {
+ 		inode_unlock(d_inode(parent));
+ 		simple_release_fs(&debugfs_mount, &debugfs_mount_count);
+ 	}
+ 
+ 	return dentry;
+ }
+ 
+ static struct dentry *failed_creating(struct dentry *dentry)
+ {
+ 	inode_unlock(d_inode(dentry->d_parent));
+ 	dput(dentry);
+ 	simple_release_fs(&debugfs_mount, &debugfs_mount_count);
+ 	return NULL;
+ }
+ 
+ static struct dentry *end_creating(struct dentry *dentry)
+ {
+ 	inode_unlock(d_inode(dentry->d_parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return dentry;
  }
  
@@@ -508,12 -557,12 +534,18 @@@ void debugfs_remove(struct dentry *dent
  		return;
  
  	parent = dentry->d_parent;
 -	if (!parent || d_really_is_negative(parent))
 +	if (!parent || !parent->d_inode)
  		return;
  
++<<<<<<< HEAD
 +	mutex_lock(&parent->d_inode->i_mutex);
 +	ret = __debugfs_remove(dentry, parent);
 +	mutex_unlock(&parent->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(parent));
+ 	ret = __debugfs_remove(dentry, parent);
+ 	inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (!ret)
  		simple_release_fs(&debugfs_mount, &debugfs_mount_count);
  }
@@@ -544,36 -594,54 +576,65 @@@ void debugfs_remove_recursive(struct de
  
  	parent = dentry;
   down:
++<<<<<<< HEAD
 +	mutex_lock(&parent->d_inode->i_mutex);
 +	list_for_each_entry_safe(child, next, &parent->d_subdirs, d_u.d_child) {
 +		if (!debugfs_positive(child))
++=======
+ 	inode_lock(d_inode(parent));
+  loop:
+ 	/*
+ 	 * The parent->d_subdirs is protected by the d_lock. Outside that
+ 	 * lock, the child can be unlinked and set to be freed which can
+ 	 * use the d_u.d_child as the rcu head and corrupt this list.
+ 	 */
+ 	spin_lock(&parent->d_lock);
+ 	list_for_each_entry(child, &parent->d_subdirs, d_child) {
+ 		if (!simple_positive(child))
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  			continue;
  
  		/* perhaps simple_empty(child) makes more sense */
  		if (!list_empty(&child->d_subdirs)) {
++<<<<<<< HEAD
 +			mutex_unlock(&parent->d_inode->i_mutex);
++=======
+ 			spin_unlock(&parent->d_lock);
+ 			inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  			parent = child;
  			goto down;
  		}
 -
 -		spin_unlock(&parent->d_lock);
 -
 + up:
  		if (!__debugfs_remove(child, parent))
  			simple_release_fs(&debugfs_mount, &debugfs_mount_count);
 -
 -		/*
 -		 * The parent->d_lock protects agaist child from unlinking
 -		 * from d_subdirs. When releasing the parent->d_lock we can
 -		 * no longer trust that the next pointer is valid.
 -		 * Restart the loop. We'll skip this one with the
 -		 * simple_positive() check.
 -		 */
 -		goto loop;
  	}
 -	spin_unlock(&parent->d_lock);
  
++<<<<<<< HEAD
 +	mutex_unlock(&parent->d_inode->i_mutex);
 +	child = parent;
 +	parent = parent->d_parent;
 +	mutex_lock(&parent->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(parent));
+ 	child = parent;
+ 	parent = parent->d_parent;
+ 	inode_lock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
 -	if (child != dentry)
 -		/* go up */
 -		goto loop;
 +	if (child != dentry) {
 +		next = list_entry(child->d_u.d_child.next, struct dentry,
 +					d_u.d_child);
 +		goto up;
 +	}
  
  	if (!__debugfs_remove(child, parent))
  		simple_release_fs(&debugfs_mount, &debugfs_mount_count);
++<<<<<<< HEAD
 +	mutex_unlock(&parent->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  }
  EXPORT_SYMBOL_GPL(debugfs_remove_recursive);
  
diff --cc fs/devpts/inode.c
index cb79c4b4e67f,1f107fd51328..000000000000
--- a/fs/devpts/inode.c
+++ b/fs/devpts/inode.c
@@@ -253,7 -255,7 +253,11 @@@ static int mknod_ptmx(struct super_bloc
  	if (!uid_valid(root_uid) || !gid_valid(root_gid))
  		return -EINVAL;
  
++<<<<<<< HEAD
 +	mutex_lock(&root->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	/* If we have already created ptmx node, return */
  	if (fsi->ptmx_dentry) {
@@@ -290,7 -292,7 +294,11 @@@
  	fsi->ptmx_dentry = dentry;
  	rc = 0;
  out:
++<<<<<<< HEAD
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return rc;
  }
  
@@@ -630,7 -615,7 +638,11 @@@ struct inode *devpts_pty_new(struct ino
  
  	sprintf(s, "%d", index);
  
++<<<<<<< HEAD
 +	mutex_lock(&root->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	dentry = d_alloc_name(root, s);
  	if (dentry) {
@@@ -641,7 -626,7 +653,11 @@@
  		inode = ERR_PTR(-ENOMEM);
  	}
  
++<<<<<<< HEAD
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	return inode;
  }
@@@ -686,7 -671,7 +702,11 @@@ void devpts_pty_kill(struct inode *inod
  
  	BUG_ON(inode->i_rdev == MKDEV(TTYAUX_MAJOR, PTMX_MINOR));
  
++<<<<<<< HEAD
 +	mutex_lock(&root->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	dentry = d_find_alias(inode);
  
@@@ -695,7 -680,7 +715,11 @@@
  	dput(dentry);	/* d_alloc_name() in devpts_pty_new() */
  	dput(dentry);		/* d_find_alias above */
  
++<<<<<<< HEAD
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  }
  
  static int __init init_devpts_fs(void)
diff --cc fs/direct-io.c
index 9f15d96aa264,1b2f7ffc8b84..000000000000
--- a/fs/direct-io.c
+++ b/fs/direct-io.c
@@@ -1232,6 -1169,16 +1232,19 @@@ do_blockdev_direct_IO(int rw, struct ki
  		}
  	}
  
++<<<<<<< HEAD
++=======
+ 	/* Once we sampled i_size check for reads beyond EOF */
+ 	dio->i_size = i_size_read(inode);
+ 	if (iov_iter_rw(iter) == READ && offset >= dio->i_size) {
+ 		if (dio->flags & DIO_LOCKING)
+ 			inode_unlock(inode);
+ 		kmem_cache_free(dio_cache, dio);
+ 		retval = 0;
+ 		goto out;
+ 	}
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	/*
  	 * For file extending writes updating i_size before data writeouts
  	 * complete can expose uninitialized blocks in dumb filesystems.
@@@ -1378,8 -1294,8 +1391,13 @@@
  	 * we can let i_mutex go now that its achieved its purpose
  	 * of protecting us from looking up uninitialized blocks.
  	 */
++<<<<<<< HEAD
 +	if (rw == READ && (dio->flags & DIO_LOCKING))
 +		mutex_unlock(&dio->inode->i_mutex);
++=======
+ 	if (iov_iter_rw(iter) == READ && (dio->flags & DIO_LOCKING))
+ 		inode_unlock(dio->inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	/*
  	 * The only time we want to leave bios in flight is when a successful
diff --cc fs/ecryptfs/inode.c
index 1648908cf236,4e685ac1024d..000000000000
--- a/fs/ecryptfs/inode.c
+++ b/fs/ecryptfs/inode.c
@@@ -41,13 -41,13 +41,21 @@@ static struct dentry *lock_parent(struc
  	struct dentry *dir;
  
  	dir = dget_parent(dentry);
++<<<<<<< HEAD
 +	mutex_lock_nested(&(dir->d_inode->i_mutex), I_MUTEX_PARENT);
++=======
+ 	inode_lock_nested(d_inode(dir), I_MUTEX_PARENT);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return dir;
  }
  
  static void unlock_dir(struct dentry *dir)
  {
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dput(dir);
  }
  
@@@ -410,11 -397,11 +418,19 @@@ static struct dentry *ecryptfs_lookup(s
  	int rc = 0;
  
  	lower_dir_dentry = ecryptfs_dentry_to_lower(ecryptfs_dentry->d_parent);
++<<<<<<< HEAD
 +	mutex_lock(&lower_dir_dentry->d_inode->i_mutex);
 +	lower_dentry = lookup_one_len(ecryptfs_dentry->d_name.name,
 +				      lower_dir_dentry,
 +				      ecryptfs_dentry->d_name.len);
 +	mutex_unlock(&lower_dir_dentry->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(lower_dir_dentry));
+ 	lower_dentry = lookup_one_len(ecryptfs_dentry->d_name.name,
+ 				      lower_dir_dentry,
+ 				      ecryptfs_dentry->d_name.len);
+ 	inode_unlock(d_inode(lower_dir_dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (IS_ERR(lower_dentry)) {
  		rc = PTR_ERR(lower_dentry);
  		ecryptfs_printk(KERN_DEBUG, "%s: lookup_one_len() returned "
@@@ -439,11 -426,11 +455,19 @@@
  		       "filename; rc = [%d]\n", __func__, rc);
  		goto out;
  	}
++<<<<<<< HEAD
 +	mutex_lock(&lower_dir_dentry->d_inode->i_mutex);
 +	lower_dentry = lookup_one_len(encrypted_and_encoded_name,
 +				      lower_dir_dentry,
 +				      encrypted_and_encoded_name_size);
 +	mutex_unlock(&lower_dir_dentry->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(lower_dir_dentry));
+ 	lower_dentry = lookup_one_len(encrypted_and_encoded_name,
+ 				      lower_dir_dentry,
+ 				      encrypted_and_encoded_name_size);
+ 	inode_unlock(d_inode(lower_dir_dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (IS_ERR(lower_dentry)) {
  		rc = PTR_ERR(lower_dentry);
  		ecryptfs_printk(KERN_DEBUG, "%s: lookup_one_len() returned "
@@@ -881,9 -869,9 +905,15 @@@ int ecryptfs_truncate(struct dentry *de
  	if (!rc && lower_ia.ia_valid & ATTR_SIZE) {
  		struct dentry *lower_dentry = ecryptfs_dentry_to_lower(dentry);
  
++<<<<<<< HEAD
 +		mutex_lock(&lower_dentry->d_inode->i_mutex);
 +		rc = notify_change(lower_dentry, &lower_ia, NULL);
 +		mutex_unlock(&lower_dentry->d_inode->i_mutex);
++=======
+ 		inode_lock(d_inode(lower_dentry));
+ 		rc = notify_change(lower_dentry, &lower_ia, NULL);
+ 		inode_unlock(d_inode(lower_dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	}
  	return rc;
  }
@@@ -982,9 -970,9 +1012,15 @@@ static int ecryptfs_setattr(struct dent
  	if (lower_ia.ia_valid & (ATTR_KILL_SUID | ATTR_KILL_SGID))
  		lower_ia.ia_valid &= ~ATTR_MODE;
  
++<<<<<<< HEAD
 +	mutex_lock(&lower_dentry->d_inode->i_mutex);
 +	rc = notify_change(lower_dentry, &lower_ia, NULL);
 +	mutex_unlock(&lower_dentry->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(lower_dentry));
+ 	rc = notify_change(lower_dentry, &lower_ia, NULL);
+ 	inode_unlock(d_inode(lower_dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  out:
  	fsstack_copy_attr_all(inode, lower_inode);
  	return rc;
@@@ -1058,10 -1048,10 +1094,17 @@@ ecryptfs_getxattr_lower(struct dentry *
  		rc = -EOPNOTSUPP;
  		goto out;
  	}
++<<<<<<< HEAD
 +	mutex_lock(&lower_dentry->d_inode->i_mutex);
 +	rc = lower_dentry->d_inode->i_op->getxattr(lower_dentry, name, value,
 +						   size);
 +	mutex_unlock(&lower_dentry->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(lower_dentry));
+ 	rc = d_inode(lower_dentry)->i_op->getxattr(lower_dentry, name, value,
+ 						   size);
+ 	inode_unlock(d_inode(lower_dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  out:
  	return rc;
  }
@@@ -1085,9 -1075,9 +1128,15 @@@ ecryptfs_listxattr(struct dentry *dentr
  		rc = -EOPNOTSUPP;
  		goto out;
  	}
++<<<<<<< HEAD
 +	mutex_lock(&lower_dentry->d_inode->i_mutex);
 +	rc = lower_dentry->d_inode->i_op->listxattr(lower_dentry, list, size);
 +	mutex_unlock(&lower_dentry->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(lower_dentry));
+ 	rc = d_inode(lower_dentry)->i_op->listxattr(lower_dentry, list, size);
+ 	inode_unlock(d_inode(lower_dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  out:
  	return rc;
  }
@@@ -1102,9 -1092,9 +1151,15 @@@ static int ecryptfs_removexattr(struct 
  		rc = -EOPNOTSUPP;
  		goto out;
  	}
++<<<<<<< HEAD
 +	mutex_lock(&lower_dentry->d_inode->i_mutex);
 +	rc = lower_dentry->d_inode->i_op->removexattr(lower_dentry, name);
 +	mutex_unlock(&lower_dentry->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(lower_dentry));
+ 	rc = d_inode(lower_dentry)->i_op->removexattr(lower_dentry, name);
+ 	inode_unlock(d_inode(lower_dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  out:
  	return rc;
  }
diff --cc fs/exportfs/expfs.c
index 262fc9940982,c46f1a190b8d..000000000000
--- a/fs/exportfs/expfs.c
+++ b/fs/exportfs/expfs.c
@@@ -69,25 -69,119 +69,84 @@@ find_acceptable_alias(struct dentry *re
  	return NULL;
  }
  
 -static bool dentry_connected(struct dentry *dentry)
 +/*
 + * Find root of a disconnected subtree and return a reference to it.
 + */
 +static struct dentry *
 +find_disconnected_root(struct dentry *dentry)
  {
  	dget(dentry);
 -	while (dentry->d_flags & DCACHE_DISCONNECTED) {
 +	while (!IS_ROOT(dentry)) {
  		struct dentry *parent = dget_parent(dentry);
  
 -		dput(dentry);
 -		if (IS_ROOT(dentry)) {
++<<<<<<< HEAD
 +		if (!(parent->d_flags & DCACHE_DISCONNECTED)) {
  			dput(parent);
 -			return false;
 +			break;
  		}
 -		dentry = parent;
 -	}
 -	dput(dentry);
 -	return true;
 -}
 -
 -static void clear_disconnected(struct dentry *dentry)
 -{
 -	dget(dentry);
 -	while (dentry->d_flags & DCACHE_DISCONNECTED) {
 -		struct dentry *parent = dget_parent(dentry);
 -
 -		WARN_ON_ONCE(IS_ROOT(dentry));
 -
 -		spin_lock(&dentry->d_lock);
 -		dentry->d_flags &= ~DCACHE_DISCONNECTED;
 -		spin_unlock(&dentry->d_lock);
 -
 -		dput(dentry);
 -		dentry = parent;
 -	}
 -	dput(dentry);
 -}
 -
 -/*
 - * Reconnect a directory dentry with its parent.
 - *
 - * This can return a dentry, or NULL, or an error.
 - *
 - * In the first case the returned dentry is the parent of the given
 - * dentry, and may itself need to be reconnected to its parent.
 - *
 - * In the NULL case, a concurrent VFS operation has either renamed or
 - * removed this directory.  The concurrent operation has reconnected our
 - * dentry, so we no longer need to.
 - */
 -static struct dentry *reconnect_one(struct vfsmount *mnt,
 -		struct dentry *dentry, char *nbuf)
 -{
 -	struct dentry *parent;
 -	struct dentry *tmp;
 -	int err;
 -
++=======
+ 	parent = ERR_PTR(-EACCES);
+ 	inode_lock(dentry->d_inode);
+ 	if (mnt->mnt_sb->s_export_op->get_parent)
+ 		parent = mnt->mnt_sb->s_export_op->get_parent(dentry);
+ 	inode_unlock(dentry->d_inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
 -	if (IS_ERR(parent)) {
 -		dprintk("%s: get_parent of %ld failed, err %d\n",
 -			__func__, dentry->d_inode->i_ino, PTR_ERR(parent));
 -		return parent;
 +		dput(dentry);
 +		dentry = parent;
  	}
++<<<<<<< HEAD
 +	return dentry;
++=======
+ 
+ 	dprintk("%s: find name of %lu in %lu\n", __func__,
+ 		dentry->d_inode->i_ino, parent->d_inode->i_ino);
+ 	err = exportfs_get_name(mnt, parent, nbuf, dentry);
+ 	if (err == -ENOENT)
+ 		goto out_reconnected;
+ 	if (err)
+ 		goto out_err;
+ 	dprintk("%s: found name: %s\n", __func__, nbuf);
+ 	inode_lock(parent->d_inode);
+ 	tmp = lookup_one_len(nbuf, parent, strlen(nbuf));
+ 	inode_unlock(parent->d_inode);
+ 	if (IS_ERR(tmp)) {
+ 		dprintk("%s: lookup failed: %d\n", __func__, PTR_ERR(tmp));
+ 		goto out_err;
+ 	}
+ 	if (tmp != dentry) {
+ 		dput(tmp);
+ 		goto out_reconnected;
+ 	}
+ 	dput(tmp);
+ 	if (IS_ROOT(dentry)) {
+ 		err = -ESTALE;
+ 		goto out_err;
+ 	}
+ 	return parent;
+ 
+ out_err:
+ 	dput(parent);
+ 	return ERR_PTR(err);
+ out_reconnected:
+ 	dput(parent);
+ 	/*
+ 	 * Someone must have renamed our entry into another parent, in
+ 	 * which case it has been reconnected by the rename.
+ 	 *
+ 	 * Or someone removed it entirely, in which case filehandle
+ 	 * lookup will succeed but the directory is now IS_DEAD and
+ 	 * subsequent operations on it will fail.
+ 	 *
+ 	 * Alternatively, maybe there was no race at all, and the
+ 	 * filesystem is just corrupt and gave us a parent that doesn't
+ 	 * actually contain any entry pointing to this inode.  So,
+ 	 * double check that this worked and return -ESTALE if not:
+ 	 */
+ 	if (!dentry_connected(dentry))
+ 		return ERR_PTR(-ESTALE);
+ 	return NULL;
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  }
  
  /*
diff --cc fs/ext4/extents.c
index 3148c840b560,0ffabaf90aa5..000000000000
--- a/fs/ext4/extents.c
+++ b/fs/ext4/extents.c
@@@ -5427,13 -5492,7 +5427,17 @@@ int ext4_collapse_range(struct inode *i
  			return ret;
  	}
  
++<<<<<<< HEAD
 +	mutex_lock(&inode->i_mutex);
 +	/* It's not possible punch hole on append only file */
 +	if (IS_APPEND(inode) || IS_IMMUTABLE(inode)) {
 +		ret = -EPERM;
 +		goto out_mutex;
 +	}
 +
++=======
+ 	inode_lock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	/*
  	 * There is no need to overlap collapse range with EOF, in which case
  	 * it is effectively a truncate operation
@@@ -5528,6 -5587,372 +5532,375 @@@ out_mmap
  	up_write(&EXT4_I(inode)->i_mmap_sem);
  	ext4_inode_resume_unlocked_dio(inode);
  out_mutex:
- 	mutex_unlock(&inode->i_mutex);
+ 	inode_unlock(inode);
  	return ret;
  }
++<<<<<<< HEAD
++=======
+ 
+ /*
+  * ext4_insert_range:
+  * This function implements the FALLOC_FL_INSERT_RANGE flag of fallocate.
+  * The data blocks starting from @offset to the EOF are shifted by @len
+  * towards right to create a hole in the @inode. Inode size is increased
+  * by len bytes.
+  * Returns 0 on success, error otherwise.
+  */
+ int ext4_insert_range(struct inode *inode, loff_t offset, loff_t len)
+ {
+ 	struct super_block *sb = inode->i_sb;
+ 	handle_t *handle;
+ 	struct ext4_ext_path *path;
+ 	struct ext4_extent *extent;
+ 	ext4_lblk_t offset_lblk, len_lblk, ee_start_lblk = 0;
+ 	unsigned int credits, ee_len;
+ 	int ret = 0, depth, split_flag = 0;
+ 	loff_t ioffset;
+ 
+ 	/*
+ 	 * We need to test this early because xfstests assumes that an
+ 	 * insert range of (0, 1) will return EOPNOTSUPP if the file
+ 	 * system does not support insert range.
+ 	 */
+ 	if (!ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))
+ 		return -EOPNOTSUPP;
+ 
+ 	/* Insert range works only on fs block size aligned offsets. */
+ 	if (offset & (EXT4_CLUSTER_SIZE(sb) - 1) ||
+ 			len & (EXT4_CLUSTER_SIZE(sb) - 1))
+ 		return -EINVAL;
+ 
+ 	if (!S_ISREG(inode->i_mode))
+ 		return -EOPNOTSUPP;
+ 
+ 	trace_ext4_insert_range(inode, offset, len);
+ 
+ 	offset_lblk = offset >> EXT4_BLOCK_SIZE_BITS(sb);
+ 	len_lblk = len >> EXT4_BLOCK_SIZE_BITS(sb);
+ 
+ 	/* Call ext4_force_commit to flush all data in case of data=journal */
+ 	if (ext4_should_journal_data(inode)) {
+ 		ret = ext4_force_commit(inode->i_sb);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	inode_lock(inode);
+ 	/* Currently just for extent based files */
+ 	if (!ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)) {
+ 		ret = -EOPNOTSUPP;
+ 		goto out_mutex;
+ 	}
+ 
+ 	/* Check for wrap through zero */
+ 	if (inode->i_size + len > inode->i_sb->s_maxbytes) {
+ 		ret = -EFBIG;
+ 		goto out_mutex;
+ 	}
+ 
+ 	/* Offset should be less than i_size */
+ 	if (offset >= i_size_read(inode)) {
+ 		ret = -EINVAL;
+ 		goto out_mutex;
+ 	}
+ 
+ 	/* Wait for existing dio to complete */
+ 	ext4_inode_block_unlocked_dio(inode);
+ 	inode_dio_wait(inode);
+ 
+ 	/*
+ 	 * Prevent page faults from reinstantiating pages we have released from
+ 	 * page cache.
+ 	 */
+ 	down_write(&EXT4_I(inode)->i_mmap_sem);
+ 	/*
+ 	 * Need to round down to align start offset to page size boundary
+ 	 * for page size > block size.
+ 	 */
+ 	ioffset = round_down(offset, PAGE_SIZE);
+ 	/* Write out all dirty pages */
+ 	ret = filemap_write_and_wait_range(inode->i_mapping, ioffset,
+ 			LLONG_MAX);
+ 	if (ret)
+ 		goto out_mmap;
+ 	truncate_pagecache(inode, ioffset);
+ 
+ 	credits = ext4_writepage_trans_blocks(inode);
+ 	handle = ext4_journal_start(inode, EXT4_HT_TRUNCATE, credits);
+ 	if (IS_ERR(handle)) {
+ 		ret = PTR_ERR(handle);
+ 		goto out_mmap;
+ 	}
+ 
+ 	/* Expand file to avoid data loss if there is error while shifting */
+ 	inode->i_size += len;
+ 	EXT4_I(inode)->i_disksize += len;
+ 	inode->i_mtime = inode->i_ctime = ext4_current_time(inode);
+ 	ret = ext4_mark_inode_dirty(handle, inode);
+ 	if (ret)
+ 		goto out_stop;
+ 
+ 	down_write(&EXT4_I(inode)->i_data_sem);
+ 	ext4_discard_preallocations(inode);
+ 
+ 	path = ext4_find_extent(inode, offset_lblk, NULL, 0);
+ 	if (IS_ERR(path)) {
+ 		up_write(&EXT4_I(inode)->i_data_sem);
+ 		goto out_stop;
+ 	}
+ 
+ 	depth = ext_depth(inode);
+ 	extent = path[depth].p_ext;
+ 	if (extent) {
+ 		ee_start_lblk = le32_to_cpu(extent->ee_block);
+ 		ee_len = ext4_ext_get_actual_len(extent);
+ 
+ 		/*
+ 		 * If offset_lblk is not the starting block of extent, split
+ 		 * the extent @offset_lblk
+ 		 */
+ 		if ((offset_lblk > ee_start_lblk) &&
+ 				(offset_lblk < (ee_start_lblk + ee_len))) {
+ 			if (ext4_ext_is_unwritten(extent))
+ 				split_flag = EXT4_EXT_MARK_UNWRIT1 |
+ 					EXT4_EXT_MARK_UNWRIT2;
+ 			ret = ext4_split_extent_at(handle, inode, &path,
+ 					offset_lblk, split_flag,
+ 					EXT4_EX_NOCACHE |
+ 					EXT4_GET_BLOCKS_PRE_IO |
+ 					EXT4_GET_BLOCKS_METADATA_NOFAIL);
+ 		}
+ 
+ 		ext4_ext_drop_refs(path);
+ 		kfree(path);
+ 		if (ret < 0) {
+ 			up_write(&EXT4_I(inode)->i_data_sem);
+ 			goto out_stop;
+ 		}
+ 	}
+ 
+ 	ret = ext4_es_remove_extent(inode, offset_lblk,
+ 			EXT_MAX_BLOCKS - offset_lblk);
+ 	if (ret) {
+ 		up_write(&EXT4_I(inode)->i_data_sem);
+ 		goto out_stop;
+ 	}
+ 
+ 	/*
+ 	 * if offset_lblk lies in a hole which is at start of file, use
+ 	 * ee_start_lblk to shift extents
+ 	 */
+ 	ret = ext4_ext_shift_extents(inode, handle,
+ 		ee_start_lblk > offset_lblk ? ee_start_lblk : offset_lblk,
+ 		len_lblk, SHIFT_RIGHT);
+ 
+ 	up_write(&EXT4_I(inode)->i_data_sem);
+ 	if (IS_SYNC(inode))
+ 		ext4_handle_sync(handle);
+ 
+ out_stop:
+ 	ext4_journal_stop(handle);
+ out_mmap:
+ 	up_write(&EXT4_I(inode)->i_mmap_sem);
+ 	ext4_inode_resume_unlocked_dio(inode);
+ out_mutex:
+ 	inode_unlock(inode);
+ 	return ret;
+ }
+ 
+ /**
+  * ext4_swap_extents - Swap extents between two inodes
+  *
+  * @inode1:	First inode
+  * @inode2:	Second inode
+  * @lblk1:	Start block for first inode
+  * @lblk2:	Start block for second inode
+  * @count:	Number of blocks to swap
+  * @mark_unwritten: Mark second inode's extents as unwritten after swap
+  * @erp:	Pointer to save error value
+  *
+  * This helper routine does exactly what is promise "swap extents". All other
+  * stuff such as page-cache locking consistency, bh mapping consistency or
+  * extent's data copying must be performed by caller.
+  * Locking:
+  * 		i_mutex is held for both inodes
+  * 		i_data_sem is locked for write for both inodes
+  * Assumptions:
+  *		All pages from requested range are locked for both inodes
+  */
+ int
+ ext4_swap_extents(handle_t *handle, struct inode *inode1,
+ 		     struct inode *inode2, ext4_lblk_t lblk1, ext4_lblk_t lblk2,
+ 		  ext4_lblk_t count, int unwritten, int *erp)
+ {
+ 	struct ext4_ext_path *path1 = NULL;
+ 	struct ext4_ext_path *path2 = NULL;
+ 	int replaced_count = 0;
+ 
+ 	BUG_ON(!rwsem_is_locked(&EXT4_I(inode1)->i_data_sem));
+ 	BUG_ON(!rwsem_is_locked(&EXT4_I(inode2)->i_data_sem));
+ 	BUG_ON(!inode_is_locked(inode1));
+ 	BUG_ON(!inode_is_locked(inode2));
+ 
+ 	*erp = ext4_es_remove_extent(inode1, lblk1, count);
+ 	if (unlikely(*erp))
+ 		return 0;
+ 	*erp = ext4_es_remove_extent(inode2, lblk2, count);
+ 	if (unlikely(*erp))
+ 		return 0;
+ 
+ 	while (count) {
+ 		struct ext4_extent *ex1, *ex2, tmp_ex;
+ 		ext4_lblk_t e1_blk, e2_blk;
+ 		int e1_len, e2_len, len;
+ 		int split = 0;
+ 
+ 		path1 = ext4_find_extent(inode1, lblk1, NULL, EXT4_EX_NOCACHE);
+ 		if (IS_ERR(path1)) {
+ 			*erp = PTR_ERR(path1);
+ 			path1 = NULL;
+ 		finish:
+ 			count = 0;
+ 			goto repeat;
+ 		}
+ 		path2 = ext4_find_extent(inode2, lblk2, NULL, EXT4_EX_NOCACHE);
+ 		if (IS_ERR(path2)) {
+ 			*erp = PTR_ERR(path2);
+ 			path2 = NULL;
+ 			goto finish;
+ 		}
+ 		ex1 = path1[path1->p_depth].p_ext;
+ 		ex2 = path2[path2->p_depth].p_ext;
+ 		/* Do we have somthing to swap ? */
+ 		if (unlikely(!ex2 || !ex1))
+ 			goto finish;
+ 
+ 		e1_blk = le32_to_cpu(ex1->ee_block);
+ 		e2_blk = le32_to_cpu(ex2->ee_block);
+ 		e1_len = ext4_ext_get_actual_len(ex1);
+ 		e2_len = ext4_ext_get_actual_len(ex2);
+ 
+ 		/* Hole handling */
+ 		if (!in_range(lblk1, e1_blk, e1_len) ||
+ 		    !in_range(lblk2, e2_blk, e2_len)) {
+ 			ext4_lblk_t next1, next2;
+ 
+ 			/* if hole after extent, then go to next extent */
+ 			next1 = ext4_ext_next_allocated_block(path1);
+ 			next2 = ext4_ext_next_allocated_block(path2);
+ 			/* If hole before extent, then shift to that extent */
+ 			if (e1_blk > lblk1)
+ 				next1 = e1_blk;
+ 			if (e2_blk > lblk2)
+ 				next2 = e1_blk;
+ 			/* Do we have something to swap */
+ 			if (next1 == EXT_MAX_BLOCKS || next2 == EXT_MAX_BLOCKS)
+ 				goto finish;
+ 			/* Move to the rightest boundary */
+ 			len = next1 - lblk1;
+ 			if (len < next2 - lblk2)
+ 				len = next2 - lblk2;
+ 			if (len > count)
+ 				len = count;
+ 			lblk1 += len;
+ 			lblk2 += len;
+ 			count -= len;
+ 			goto repeat;
+ 		}
+ 
+ 		/* Prepare left boundary */
+ 		if (e1_blk < lblk1) {
+ 			split = 1;
+ 			*erp = ext4_force_split_extent_at(handle, inode1,
+ 						&path1, lblk1, 0);
+ 			if (unlikely(*erp))
+ 				goto finish;
+ 		}
+ 		if (e2_blk < lblk2) {
+ 			split = 1;
+ 			*erp = ext4_force_split_extent_at(handle, inode2,
+ 						&path2,  lblk2, 0);
+ 			if (unlikely(*erp))
+ 				goto finish;
+ 		}
+ 		/* ext4_split_extent_at() may result in leaf extent split,
+ 		 * path must to be revalidated. */
+ 		if (split)
+ 			goto repeat;
+ 
+ 		/* Prepare right boundary */
+ 		len = count;
+ 		if (len > e1_blk + e1_len - lblk1)
+ 			len = e1_blk + e1_len - lblk1;
+ 		if (len > e2_blk + e2_len - lblk2)
+ 			len = e2_blk + e2_len - lblk2;
+ 
+ 		if (len != e1_len) {
+ 			split = 1;
+ 			*erp = ext4_force_split_extent_at(handle, inode1,
+ 						&path1, lblk1 + len, 0);
+ 			if (unlikely(*erp))
+ 				goto finish;
+ 		}
+ 		if (len != e2_len) {
+ 			split = 1;
+ 			*erp = ext4_force_split_extent_at(handle, inode2,
+ 						&path2, lblk2 + len, 0);
+ 			if (*erp)
+ 				goto finish;
+ 		}
+ 		/* ext4_split_extent_at() may result in leaf extent split,
+ 		 * path must to be revalidated. */
+ 		if (split)
+ 			goto repeat;
+ 
+ 		BUG_ON(e2_len != e1_len);
+ 		*erp = ext4_ext_get_access(handle, inode1, path1 + path1->p_depth);
+ 		if (unlikely(*erp))
+ 			goto finish;
+ 		*erp = ext4_ext_get_access(handle, inode2, path2 + path2->p_depth);
+ 		if (unlikely(*erp))
+ 			goto finish;
+ 
+ 		/* Both extents are fully inside boundaries. Swap it now */
+ 		tmp_ex = *ex1;
+ 		ext4_ext_store_pblock(ex1, ext4_ext_pblock(ex2));
+ 		ext4_ext_store_pblock(ex2, ext4_ext_pblock(&tmp_ex));
+ 		ex1->ee_len = cpu_to_le16(e2_len);
+ 		ex2->ee_len = cpu_to_le16(e1_len);
+ 		if (unwritten)
+ 			ext4_ext_mark_unwritten(ex2);
+ 		if (ext4_ext_is_unwritten(&tmp_ex))
+ 			ext4_ext_mark_unwritten(ex1);
+ 
+ 		ext4_ext_try_to_merge(handle, inode2, path2, ex2);
+ 		ext4_ext_try_to_merge(handle, inode1, path1, ex1);
+ 		*erp = ext4_ext_dirty(handle, inode2, path2 +
+ 				      path2->p_depth);
+ 		if (unlikely(*erp))
+ 			goto finish;
+ 		*erp = ext4_ext_dirty(handle, inode1, path1 +
+ 				      path1->p_depth);
+ 		/*
+ 		 * Looks scarry ah..? second inode already points to new blocks,
+ 		 * and it was successfully dirtied. But luckily error may happen
+ 		 * only due to journal error, so full transaction will be
+ 		 * aborted anyway.
+ 		 */
+ 		if (unlikely(*erp))
+ 			goto finish;
+ 		lblk1 += len;
+ 		lblk2 += len;
+ 		replaced_count += len;
+ 		count -= len;
+ 
+ 	repeat:
+ 		ext4_ext_drop_refs(path1);
+ 		kfree(path1);
+ 		ext4_ext_drop_refs(path2);
+ 		kfree(path2);
+ 		path1 = path2 = NULL;
+ 	}
+ 	return replaced_count;
+ }
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
diff --cc fs/ext4/file.c
index de8914c0fbc1,8eb87e3e2752..000000000000
--- a/fs/ext4/file.c
+++ b/fs/ext4/file.c
@@@ -114,90 -113,82 +114,123 @@@ ext4_file_dio_write(struct kiocb *iocb
  		ext4_unwritten_wait(inode);
  	}
  
++<<<<<<< HEAD
 +	BUG_ON(iocb->ki_pos != pos);
 +
 +	mutex_lock(&inode->i_mutex);
 +	blk_start_plug(&plug);
++=======
+ 	inode_lock(inode);
+ 	ret = generic_write_checks(iocb, from);
+ 	if (ret <= 0)
+ 		goto out;
+ 
+ 	/*
+ 	 * If we have encountered a bitmap-format file, the size limit
+ 	 * is smaller than s_maxbytes, which is for extent-mapped files.
+ 	 */
+ 	if (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))) {
+ 		struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);
+ 
+ 		if (iocb->ki_pos >= sbi->s_bitmap_maxbytes) {
+ 			ret = -EFBIG;
+ 			goto out;
+ 		}
+ 		iov_iter_truncate(from, sbi->s_bitmap_maxbytes - iocb->ki_pos);
+ 	}
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	iocb->private = &overwrite;
 -	if (o_direct) {
 -		size_t length = iov_iter_count(from);
 -		loff_t pos = iocb->ki_pos;
 -		blk_start_plug(&plug);
 -
 -		/* check whether we do a DIO overwrite or not */
 -		if (ext4_should_dioread_nolock(inode) && !aio_mutex &&
 -		    !file->f_mapping->nrpages && pos + length <= i_size_read(inode)) {
 -			struct ext4_map_blocks map;
 -			unsigned int blkbits = inode->i_blkbits;
 -			int err, len;
 -
 -			map.m_lblk = pos >> blkbits;
 -			map.m_len = (EXT4_BLOCK_ALIGN(pos + length, blkbits) >> blkbits)
 -				- map.m_lblk;
 -			len = map.m_len;
 -
 -			err = ext4_map_blocks(NULL, inode, &map, 0);
 -			/*
 -			 * 'err==len' means that all of blocks has
 -			 * been preallocated no matter they are
 -			 * initialized or not.  For excluding
 -			 * unwritten extents, we need to check
 -			 * m_flags.  There are two conditions that
 -			 * indicate for initialized extents.  1) If we
 -			 * hit extent cache, EXT4_MAP_MAPPED flag is
 -			 * returned; 2) If we do a real lookup,
 -			 * non-flags are returned.  So we should check
 -			 * these two conditions.
 -			 */
 -			if (err == len && (map.m_flags & EXT4_MAP_MAPPED))
 -				overwrite = 1;
 -		}
 +
 +	/* check whether we do a DIO overwrite or not */
 +	if (ext4_should_dioread_nolock(inode) && !unaligned_aio &&
 +	    !file->f_mapping->nrpages && pos + length <= i_size_read(inode)) {
 +		struct ext4_map_blocks map;
 +		unsigned int blkbits = inode->i_blkbits;
 +		int err, len;
 +
 +		map.m_lblk = pos >> blkbits;
 +		map.m_len = (EXT4_BLOCK_ALIGN(pos + length, blkbits) >> blkbits)
 +			- map.m_lblk;
 +		len = map.m_len;
 +
 +		err = ext4_map_blocks(NULL, inode, &map, 0);
 +		/*
 +		 * 'err==len' means that all of blocks has been preallocated no
 +		 * matter they are initialized or not.  For excluding
 +		 * unwritten extents, we need to check m_flags.  There are
 +		 * two conditions that indicate for initialized extents.
 +		 * 1) If we hit extent cache, EXT4_MAP_MAPPED flag is returned;
 +		 * 2) If we do a real lookup, non-flags are returned.
 +		 * So we should check these two conditions.
 +		 */
 +		if (err == len && (map.m_flags & EXT4_MAP_MAPPED))
 +			overwrite = 1;
  	}
  
++<<<<<<< HEAD
 +	ret = __generic_file_aio_write(iocb, iov, nr_segs, &iocb->ki_pos);
 +	mutex_unlock(&inode->i_mutex);
++=======
+ 	ret = __generic_file_write_iter(iocb, from);
+ 	inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if (ret > 0) {
  		ssize_t err;
  
 -		err = generic_write_sync(file, iocb->ki_pos - ret, ret);
 -		if (err < 0)
 +		err = generic_write_sync(file, pos, ret);
 +		if (err < 0 && ret > 0)
  			ret = err;
  	}
 -	if (o_direct)
 -		blk_finish_plug(&plug);
 +	blk_finish_plug(&plug);
 +
 +	if (unaligned_aio)
 +		mutex_unlock(ext4_aio_mutex(inode));
  
 -	if (aio_mutex)
 -		mutex_unlock(aio_mutex);
  	return ret;
 +}
 +
 +static ssize_t
 +ext4_file_write(struct kiocb *iocb, const struct iovec *iov,
 +		unsigned long nr_segs, loff_t pos)
 +{
 +	struct inode *inode = file_inode(iocb->ki_filp);
 +	ssize_t ret;
 +	int overwrite = 0;
 +
 +	/*
 +	 * If we have encountered a bitmap-format file, the size limit
 +	 * is smaller than s_maxbytes, which is for extent-mapped files.
 +	 */
 +
 +	if (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS))) {
 +		struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);
 +		size_t length = iov_length(iov, nr_segs);
 +
 +		if ((pos > sbi->s_bitmap_maxbytes ||
 +		    (pos == sbi->s_bitmap_maxbytes && length > 0)))
 +			return -EFBIG;
  
 +		if (pos + length > sbi->s_bitmap_maxbytes) {
 +			nr_segs = iov_shorten((struct iovec *)iov, nr_segs,
 +					      sbi->s_bitmap_maxbytes - pos);
 +		}
 +	}
 +
 +	iocb->private = &overwrite; /* RHEL7 only - prevent DIO race */
 +	if (unlikely(io_is_direct(iocb->ki_filp)))
 +		ret = ext4_file_dio_write(iocb, iov, nr_segs, pos);
 +	else
 +		ret = generic_file_aio_write(iocb, iov, nr_segs, pos);
 +
++<<<<<<< HEAD
++=======
+ out:
+ 	inode_unlock(inode);
+ 	if (aio_mutex)
+ 		mutex_unlock(aio_mutex);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return ret;
  }
  
diff --cc fs/ext4/inode.c
index 46409f183977,83bc8bfb3bea..000000000000
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@@ -3606,12 -3707,7 +3606,16 @@@ int ext4_punch_hole(struct inode *inode
  			return ret;
  	}
  
++<<<<<<< HEAD
 +	mutex_lock(&inode->i_mutex);
 +	/* It's not possible punch hole on append only file */
 +	if (IS_APPEND(inode) || IS_IMMUTABLE(inode)) {
 +		ret = -EPERM;
 +		goto out_mutex;
 +	}
++=======
+ 	inode_lock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	/* No need to punch hole beyond i_size */
  	if (offset >= inode->i_size)
diff --cc fs/ext4/ioctl.c
index 70c66d3c5bee,0f6c36922c24..000000000000
--- a/fs/ext4/ioctl.c
+++ b/fs/ext4/ioctl.c
@@@ -198,6 -193,248 +198,251 @@@ journal_err_out
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ static int uuid_is_zero(__u8 u[16])
+ {
+ 	int	i;
+ 
+ 	for (i = 0; i < 16; i++)
+ 		if (u[i])
+ 			return 0;
+ 	return 1;
+ }
+ 
+ static int ext4_ioctl_setflags(struct inode *inode,
+ 			       unsigned int flags)
+ {
+ 	struct ext4_inode_info *ei = EXT4_I(inode);
+ 	handle_t *handle = NULL;
+ 	int err = EPERM, migrate = 0;
+ 	struct ext4_iloc iloc;
+ 	unsigned int oldflags, mask, i;
+ 	unsigned int jflag;
+ 
+ 	/* Is it quota file? Do not allow user to mess with it */
+ 	if (IS_NOQUOTA(inode))
+ 		goto flags_out;
+ 
+ 	oldflags = ei->i_flags;
+ 
+ 	/* The JOURNAL_DATA flag is modifiable only by root */
+ 	jflag = flags & EXT4_JOURNAL_DATA_FL;
+ 
+ 	/*
+ 	 * The IMMUTABLE and APPEND_ONLY flags can only be changed by
+ 	 * the relevant capability.
+ 	 *
+ 	 * This test looks nicer. Thanks to Pauline Middelink
+ 	 */
+ 	if ((flags ^ oldflags) & (EXT4_APPEND_FL | EXT4_IMMUTABLE_FL)) {
+ 		if (!capable(CAP_LINUX_IMMUTABLE))
+ 			goto flags_out;
+ 	}
+ 
+ 	/*
+ 	 * The JOURNAL_DATA flag can only be changed by
+ 	 * the relevant capability.
+ 	 */
+ 	if ((jflag ^ oldflags) & (EXT4_JOURNAL_DATA_FL)) {
+ 		if (!capable(CAP_SYS_RESOURCE))
+ 			goto flags_out;
+ 	}
+ 	if ((flags ^ oldflags) & EXT4_EXTENTS_FL)
+ 		migrate = 1;
+ 
+ 	if (flags & EXT4_EOFBLOCKS_FL) {
+ 		/* we don't support adding EOFBLOCKS flag */
+ 		if (!(oldflags & EXT4_EOFBLOCKS_FL)) {
+ 			err = -EOPNOTSUPP;
+ 			goto flags_out;
+ 		}
+ 	} else if (oldflags & EXT4_EOFBLOCKS_FL)
+ 		ext4_truncate(inode);
+ 
+ 	handle = ext4_journal_start(inode, EXT4_HT_INODE, 1);
+ 	if (IS_ERR(handle)) {
+ 		err = PTR_ERR(handle);
+ 		goto flags_out;
+ 	}
+ 	if (IS_SYNC(inode))
+ 		ext4_handle_sync(handle);
+ 	err = ext4_reserve_inode_write(handle, inode, &iloc);
+ 	if (err)
+ 		goto flags_err;
+ 
+ 	for (i = 0, mask = 1; i < 32; i++, mask <<= 1) {
+ 		if (!(mask & EXT4_FL_USER_MODIFIABLE))
+ 			continue;
+ 		if (mask & flags)
+ 			ext4_set_inode_flag(inode, i);
+ 		else
+ 			ext4_clear_inode_flag(inode, i);
+ 	}
+ 
+ 	ext4_set_inode_flags(inode);
+ 	inode->i_ctime = ext4_current_time(inode);
+ 
+ 	err = ext4_mark_iloc_dirty(handle, inode, &iloc);
+ flags_err:
+ 	ext4_journal_stop(handle);
+ 	if (err)
+ 		goto flags_out;
+ 
+ 	if ((jflag ^ oldflags) & (EXT4_JOURNAL_DATA_FL))
+ 		err = ext4_change_inode_journal_flag(inode, jflag);
+ 	if (err)
+ 		goto flags_out;
+ 	if (migrate) {
+ 		if (flags & EXT4_EXTENTS_FL)
+ 			err = ext4_ext_migrate(inode);
+ 		else
+ 			err = ext4_ind_migrate(inode);
+ 	}
+ 
+ flags_out:
+ 	return err;
+ }
+ 
+ #ifdef CONFIG_QUOTA
+ static int ext4_ioctl_setproject(struct file *filp, __u32 projid)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	struct super_block *sb = inode->i_sb;
+ 	struct ext4_inode_info *ei = EXT4_I(inode);
+ 	int err, rc;
+ 	handle_t *handle;
+ 	kprojid_t kprojid;
+ 	struct ext4_iloc iloc;
+ 	struct ext4_inode *raw_inode;
+ 
+ 	if (!EXT4_HAS_RO_COMPAT_FEATURE(sb,
+ 			EXT4_FEATURE_RO_COMPAT_PROJECT)) {
+ 		if (projid != EXT4_DEF_PROJID)
+ 			return -EOPNOTSUPP;
+ 		else
+ 			return 0;
+ 	}
+ 
+ 	if (EXT4_INODE_SIZE(sb) <= EXT4_GOOD_OLD_INODE_SIZE)
+ 		return -EOPNOTSUPP;
+ 
+ 	kprojid = make_kprojid(&init_user_ns, (projid_t)projid);
+ 
+ 	if (projid_eq(kprojid, EXT4_I(inode)->i_projid))
+ 		return 0;
+ 
+ 	err = mnt_want_write_file(filp);
+ 	if (err)
+ 		return err;
+ 
+ 	err = -EPERM;
+ 	inode_lock(inode);
+ 	/* Is it quota file? Do not allow user to mess with it */
+ 	if (IS_NOQUOTA(inode))
+ 		goto out_unlock;
+ 
+ 	err = ext4_get_inode_loc(inode, &iloc);
+ 	if (err)
+ 		goto out_unlock;
+ 
+ 	raw_inode = ext4_raw_inode(&iloc);
+ 	if (!EXT4_FITS_IN_INODE(raw_inode, ei, i_projid)) {
+ 		err = -EOVERFLOW;
+ 		brelse(iloc.bh);
+ 		goto out_unlock;
+ 	}
+ 	brelse(iloc.bh);
+ 
+ 	dquot_initialize(inode);
+ 
+ 	handle = ext4_journal_start(inode, EXT4_HT_QUOTA,
+ 		EXT4_QUOTA_INIT_BLOCKS(sb) +
+ 		EXT4_QUOTA_DEL_BLOCKS(sb) + 3);
+ 	if (IS_ERR(handle)) {
+ 		err = PTR_ERR(handle);
+ 		goto out_unlock;
+ 	}
+ 
+ 	err = ext4_reserve_inode_write(handle, inode, &iloc);
+ 	if (err)
+ 		goto out_stop;
+ 
+ 	if (sb_has_quota_limits_enabled(sb, PRJQUOTA)) {
+ 		struct dquot *transfer_to[MAXQUOTAS] = { };
+ 
+ 		transfer_to[PRJQUOTA] = dqget(sb, make_kqid_projid(kprojid));
+ 		if (transfer_to[PRJQUOTA]) {
+ 			err = __dquot_transfer(inode, transfer_to);
+ 			dqput(transfer_to[PRJQUOTA]);
+ 			if (err)
+ 				goto out_dirty;
+ 		}
+ 	}
+ 	EXT4_I(inode)->i_projid = kprojid;
+ 	inode->i_ctime = ext4_current_time(inode);
+ out_dirty:
+ 	rc = ext4_mark_iloc_dirty(handle, inode, &iloc);
+ 	if (!err)
+ 		err = rc;
+ out_stop:
+ 	ext4_journal_stop(handle);
+ out_unlock:
+ 	inode_unlock(inode);
+ 	mnt_drop_write_file(filp);
+ 	return err;
+ }
+ #else
+ static int ext4_ioctl_setproject(struct file *filp, __u32 projid)
+ {
+ 	if (projid != EXT4_DEF_PROJID)
+ 		return -EOPNOTSUPP;
+ 	return 0;
+ }
+ #endif
+ 
+ /* Transfer internal flags to xflags */
+ static inline __u32 ext4_iflags_to_xflags(unsigned long iflags)
+ {
+ 	__u32 xflags = 0;
+ 
+ 	if (iflags & EXT4_SYNC_FL)
+ 		xflags |= FS_XFLAG_SYNC;
+ 	if (iflags & EXT4_IMMUTABLE_FL)
+ 		xflags |= FS_XFLAG_IMMUTABLE;
+ 	if (iflags & EXT4_APPEND_FL)
+ 		xflags |= FS_XFLAG_APPEND;
+ 	if (iflags & EXT4_NODUMP_FL)
+ 		xflags |= FS_XFLAG_NODUMP;
+ 	if (iflags & EXT4_NOATIME_FL)
+ 		xflags |= FS_XFLAG_NOATIME;
+ 	if (iflags & EXT4_PROJINHERIT_FL)
+ 		xflags |= FS_XFLAG_PROJINHERIT;
+ 	return xflags;
+ }
+ 
+ /* Transfer xflags flags to internal */
+ static inline unsigned long ext4_xflags_to_iflags(__u32 xflags)
+ {
+ 	unsigned long iflags = 0;
+ 
+ 	if (xflags & FS_XFLAG_SYNC)
+ 		iflags |= EXT4_SYNC_FL;
+ 	if (xflags & FS_XFLAG_IMMUTABLE)
+ 		iflags |= EXT4_IMMUTABLE_FL;
+ 	if (xflags & FS_XFLAG_APPEND)
+ 		iflags |= EXT4_APPEND_FL;
+ 	if (xflags & FS_XFLAG_NODUMP)
+ 		iflags |= EXT4_NODUMP_FL;
+ 	if (xflags & FS_XFLAG_NOATIME)
+ 		iflags |= EXT4_NOATIME_FL;
+ 	if (xflags & FS_XFLAG_PROJINHERIT)
+ 		iflags |= EXT4_PROJINHERIT_FL;
+ 
+ 	return iflags;
+ }
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  long ext4_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
  {
  	struct inode *inode = file_inode(filp);
@@@ -231,90 -464,9 +476,96 @@@
  
  		flags = ext4_mask_flags(inode->i_mode, flags);
  
++<<<<<<< HEAD
 +		err = -EPERM;
 +		mutex_lock(&inode->i_mutex);
 +		/* Is it quota file? Do not allow user to mess with it */
 +		if (IS_NOQUOTA(inode))
 +			goto flags_out;
 +
 +		oldflags = ei->i_flags;
 +
 +		/* The JOURNAL_DATA flag is modifiable only by root */
 +		jflag = flags & EXT4_JOURNAL_DATA_FL;
 +
 +		/*
 +		 * The IMMUTABLE and APPEND_ONLY flags can only be changed by
 +		 * the relevant capability.
 +		 *
 +		 * This test looks nicer. Thanks to Pauline Middelink
 +		 */
 +		if ((flags ^ oldflags) & (EXT4_APPEND_FL | EXT4_IMMUTABLE_FL)) {
 +			if (!capable(CAP_LINUX_IMMUTABLE))
 +				goto flags_out;
 +		}
 +
 +		/*
 +		 * The JOURNAL_DATA flag can only be changed by
 +		 * the relevant capability.
 +		 */
 +		if ((jflag ^ oldflags) & (EXT4_JOURNAL_DATA_FL)) {
 +			if (!capable(CAP_SYS_RESOURCE))
 +				goto flags_out;
 +		}
 +		if ((flags ^ oldflags) & EXT4_EXTENTS_FL)
 +			migrate = 1;
 +
 +		if (flags & EXT4_EOFBLOCKS_FL) {
 +			/* we don't support adding EOFBLOCKS flag */
 +			if (!(oldflags & EXT4_EOFBLOCKS_FL)) {
 +				err = -EOPNOTSUPP;
 +				goto flags_out;
 +			}
 +		} else if (oldflags & EXT4_EOFBLOCKS_FL)
 +			ext4_truncate(inode);
 +
 +		handle = ext4_journal_start(inode, EXT4_HT_INODE, 1);
 +		if (IS_ERR(handle)) {
 +			err = PTR_ERR(handle);
 +			goto flags_out;
 +		}
 +		if (IS_SYNC(inode))
 +			ext4_handle_sync(handle);
 +		err = ext4_reserve_inode_write(handle, inode, &iloc);
 +		if (err)
 +			goto flags_err;
 +
 +		for (i = 0, mask = 1; i < 32; i++, mask <<= 1) {
 +			if (!(mask & EXT4_FL_USER_MODIFIABLE))
 +				continue;
 +			if (mask & flags)
 +				ext4_set_inode_flag(inode, i);
 +			else
 +				ext4_clear_inode_flag(inode, i);
 +		}
 +
 +		ext4_set_inode_flags(inode);
 +		inode->i_ctime = ext4_current_time(inode);
 +
 +		err = ext4_mark_iloc_dirty(handle, inode, &iloc);
 +flags_err:
 +		ext4_journal_stop(handle);
 +		if (err)
 +			goto flags_out;
 +
 +		if ((jflag ^ oldflags) & (EXT4_JOURNAL_DATA_FL))
 +			err = ext4_change_inode_journal_flag(inode, jflag);
 +		if (err)
 +			goto flags_out;
 +		if (migrate) {
 +			if (flags & EXT4_EXTENTS_FL)
 +				err = ext4_ext_migrate(inode);
 +			else
 +				err = ext4_ind_migrate(inode);
 +		}
 +
 +flags_out:
 +		mutex_unlock(&inode->i_mutex);
++=======
+ 		inode_lock(inode);
+ 		err = ext4_ioctl_setflags(inode, flags);
+ 		inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		mnt_drop_write_file(filp);
  		return err;
  	}
@@@ -622,7 -765,132 +873,131 @@@ resizefs_out
  	}
  	case EXT4_IOC_PRECACHE_EXTENTS:
  		return ext4_ext_precache(inode);
 -	case EXT4_IOC_SET_ENCRYPTION_POLICY: {
 -#ifdef CONFIG_EXT4_FS_ENCRYPTION
 -		struct ext4_encryption_policy policy;
 -		int err = 0;
  
++<<<<<<< HEAD
++=======
+ 		if (copy_from_user(&policy,
+ 				   (struct ext4_encryption_policy __user *)arg,
+ 				   sizeof(policy))) {
+ 			err = -EFAULT;
+ 			goto encryption_policy_out;
+ 		}
+ 
+ 		err = ext4_process_policy(&policy, inode);
+ encryption_policy_out:
+ 		return err;
+ #else
+ 		return -EOPNOTSUPP;
+ #endif
+ 	}
+ 	case EXT4_IOC_GET_ENCRYPTION_PWSALT: {
+ 		int err, err2;
+ 		struct ext4_sb_info *sbi = EXT4_SB(sb);
+ 		handle_t *handle;
+ 
+ 		if (!ext4_sb_has_crypto(sb))
+ 			return -EOPNOTSUPP;
+ 		if (uuid_is_zero(sbi->s_es->s_encrypt_pw_salt)) {
+ 			err = mnt_want_write_file(filp);
+ 			if (err)
+ 				return err;
+ 			handle = ext4_journal_start_sb(sb, EXT4_HT_MISC, 1);
+ 			if (IS_ERR(handle)) {
+ 				err = PTR_ERR(handle);
+ 				goto pwsalt_err_exit;
+ 			}
+ 			err = ext4_journal_get_write_access(handle, sbi->s_sbh);
+ 			if (err)
+ 				goto pwsalt_err_journal;
+ 			generate_random_uuid(sbi->s_es->s_encrypt_pw_salt);
+ 			err = ext4_handle_dirty_metadata(handle, NULL,
+ 							 sbi->s_sbh);
+ 		pwsalt_err_journal:
+ 			err2 = ext4_journal_stop(handle);
+ 			if (err2 && !err)
+ 				err = err2;
+ 		pwsalt_err_exit:
+ 			mnt_drop_write_file(filp);
+ 			if (err)
+ 				return err;
+ 		}
+ 		if (copy_to_user((void __user *) arg,
+ 				 sbi->s_es->s_encrypt_pw_salt, 16))
+ 			return -EFAULT;
+ 		return 0;
+ 	}
+ 	case EXT4_IOC_GET_ENCRYPTION_POLICY: {
+ #ifdef CONFIG_EXT4_FS_ENCRYPTION
+ 		struct ext4_encryption_policy policy;
+ 		int err = 0;
+ 
+ 		if (!ext4_encrypted_inode(inode))
+ 			return -ENOENT;
+ 		err = ext4_get_policy(inode, &policy);
+ 		if (err)
+ 			return err;
+ 		if (copy_to_user((void __user *)arg, &policy, sizeof(policy)))
+ 			return -EFAULT;
+ 		return 0;
+ #else
+ 		return -EOPNOTSUPP;
+ #endif
+ 	}
+ 	case EXT4_IOC_FSGETXATTR:
+ 	{
+ 		struct fsxattr fa;
+ 
+ 		memset(&fa, 0, sizeof(struct fsxattr));
+ 		ext4_get_inode_flags(ei);
+ 		fa.fsx_xflags = ext4_iflags_to_xflags(ei->i_flags & EXT4_FL_USER_VISIBLE);
+ 
+ 		if (EXT4_HAS_RO_COMPAT_FEATURE(inode->i_sb,
+ 				EXT4_FEATURE_RO_COMPAT_PROJECT)) {
+ 			fa.fsx_projid = (__u32)from_kprojid(&init_user_ns,
+ 				EXT4_I(inode)->i_projid);
+ 		}
+ 
+ 		if (copy_to_user((struct fsxattr __user *)arg,
+ 				 &fa, sizeof(fa)))
+ 			return -EFAULT;
+ 		return 0;
+ 	}
+ 	case EXT4_IOC_FSSETXATTR:
+ 	{
+ 		struct fsxattr fa;
+ 		int err;
+ 
+ 		if (copy_from_user(&fa, (struct fsxattr __user *)arg,
+ 				   sizeof(fa)))
+ 			return -EFAULT;
+ 
+ 		/* Make sure caller has proper permission */
+ 		if (!inode_owner_or_capable(inode))
+ 			return -EACCES;
+ 
+ 		err = mnt_want_write_file(filp);
+ 		if (err)
+ 			return err;
+ 
+ 		flags = ext4_xflags_to_iflags(fa.fsx_xflags);
+ 		flags = ext4_mask_flags(inode->i_mode, flags);
+ 
+ 		inode_lock(inode);
+ 		flags = (ei->i_flags & ~EXT4_FL_XFLAG_VISIBLE) |
+ 			 (flags & EXT4_FL_XFLAG_VISIBLE);
+ 		err = ext4_ioctl_setflags(inode, flags);
+ 		inode_unlock(inode);
+ 		mnt_drop_write_file(filp);
+ 		if (err)
+ 			return err;
+ 
+ 		err = ext4_ioctl_setproject(filp, fa.fsx_projid);
+ 		if (err)
+ 			return err;
+ 
+ 		return 0;
+ 	}
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	default:
  		return -ENOTTY;
  	}
diff --cc fs/f2fs/data.c
index f412cf901c1f,5c06db17e41f..000000000000
--- a/fs/f2fs/data.c
+++ b/fs/f2fs/data.c
@@@ -409,36 -600,412 +409,333 @@@ static int get_data_block_ro(struct ino
  
  	/* When reading holes, we need its node page */
  	set_new_dnode(&dn, inode, NULL, NULL, 0);
 -	err = get_dnode_of_data(&dn, pgofs, mode);
 +	err = get_dnode_of_data(&dn, pgofs, LOOKUP_NODE_RA);
  	if (err) {
 -		if (err == -ENOENT)
 -			err = 0;
 -		goto unlock_out;
 +		trace_f2fs_get_data_block(inode, iblock, bh_result, err);
 +		return (err == -ENOENT) ? 0 : err;
  	}
  
 -	if (dn.data_blkaddr == NEW_ADDR || dn.data_blkaddr == NULL_ADDR) {
 -		if (create) {
 -			if (unlikely(f2fs_cp_error(sbi))) {
 -				err = -EIO;
 -				goto put_out;
 -			}
 -			err = __allocate_data_block(&dn);
 -			if (err)
 -				goto put_out;
 -			allocated = true;
 -			map->m_flags = F2FS_MAP_NEW;
 -		} else {
 -			if (flag != F2FS_GET_BLOCK_FIEMAP ||
 -						dn.data_blkaddr != NEW_ADDR) {
 -				if (flag == F2FS_GET_BLOCK_BMAP)
 -					err = -ENOENT;
 -				goto put_out;
 -			}
 -
 -			/*
 -			 * preallocated unwritten block should be mapped
 -			 * for fiemap.
 -			 */
 -			if (dn.data_blkaddr == NEW_ADDR)
 -				map->m_flags = F2FS_MAP_UNWRITTEN;
 -		}
 -	}
 -
 -	map->m_flags |= F2FS_MAP_MAPPED;
 -	map->m_pblk = dn.data_blkaddr;
 -	map->m_len = 1;
 -
 -	end_offset = ADDRS_PER_PAGE(dn.node_page, F2FS_I(inode));
 -	dn.ofs_in_node++;
 -	pgofs++;
 -
 -get_next:
 -	if (map->m_len >= maxblocks)
 -		goto sync_out;
 -
 -	if (dn.ofs_in_node >= end_offset) {
 -		if (allocated)
 -			sync_inode_page(&dn);
 -		allocated = false;
 -		f2fs_put_dnode(&dn);
 +	/* It does not support data allocation */
 +	BUG_ON(create);
  
 -		if (create) {
 -			f2fs_unlock_op(sbi);
 -			f2fs_balance_fs(sbi, dn.node_changed);
 -			f2fs_lock_op(sbi);
 -		}
 +	if (dn.data_blkaddr != NEW_ADDR && dn.data_blkaddr != NULL_ADDR) {
 +		int i;
 +		unsigned int end_offset;
  
 -		set_new_dnode(&dn, inode, NULL, NULL, 0);
 -		err = get_dnode_of_data(&dn, pgofs, mode);
 -		if (err) {
 -			if (err == -ENOENT)
 -				err = 0;
 -			goto unlock_out;
 -		}
 +		end_offset = IS_INODE(dn.node_page) ?
 +				ADDRS_PER_INODE :
 +				ADDRS_PER_BLOCK;
  
 -		end_offset = ADDRS_PER_PAGE(dn.node_page, F2FS_I(inode));
 -	}
 +		clear_buffer_new(bh_result);
  
 -	blkaddr = datablock_addr(dn.node_page, dn.ofs_in_node);
 -
 -	if (blkaddr == NEW_ADDR || blkaddr == NULL_ADDR) {
 -		if (create) {
 -			if (unlikely(f2fs_cp_error(sbi))) {
 -				err = -EIO;
 -				goto sync_out;
 -			}
 -			err = __allocate_data_block(&dn);
 -			if (err)
 -				goto sync_out;
 -			allocated = true;
 -			map->m_flags |= F2FS_MAP_NEW;
 -			blkaddr = dn.data_blkaddr;
 -		} else {
 -			/*
 -			 * we only merge preallocated unwritten blocks
 -			 * for fiemap.
 -			 */
 -			if (flag != F2FS_GET_BLOCK_FIEMAP ||
 -					blkaddr != NEW_ADDR)
 -				goto sync_out;
 -		}
 -	}
 -
 -	/* Give more consecutive addresses for the readahead */
 -	if ((map->m_pblk != NEW_ADDR &&
 -			blkaddr == (map->m_pblk + ofs)) ||
 -			(map->m_pblk == NEW_ADDR &&
 -			blkaddr == NEW_ADDR)) {
 -		ofs++;
 -		dn.ofs_in_node++;
 -		pgofs++;
 -		map->m_len++;
 -		goto get_next;
 +		/* Give more consecutive addresses for the read ahead */
 +		for (i = 0; i < end_offset - dn.ofs_in_node; i++)
 +			if (((datablock_addr(dn.node_page,
 +							dn.ofs_in_node + i))
 +				!= (dn.data_blkaddr + i)) || maxblocks == i)
 +				break;
 +		map_bh(bh_result, inode->i_sb, dn.data_blkaddr);
 +		bh_result->b_size = (i << blkbits);
  	}
 -
 -sync_out:
 -	if (allocated)
 -		sync_inode_page(&dn);
 -put_out:
  	f2fs_put_dnode(&dn);
++<<<<<<< HEAD
 +	trace_f2fs_get_data_block(inode, iblock, bh_result, 0);
++=======
+ unlock_out:
+ 	if (create) {
+ 		f2fs_unlock_op(sbi);
+ 		f2fs_balance_fs(sbi, dn.node_changed);
+ 	}
+ out:
+ 	trace_f2fs_map_blocks(inode, map, err);
+ 	return err;
+ }
+ 
+ static int __get_data_block(struct inode *inode, sector_t iblock,
+ 			struct buffer_head *bh, int create, int flag)
+ {
+ 	struct f2fs_map_blocks map;
+ 	int ret;
+ 
+ 	map.m_lblk = iblock;
+ 	map.m_len = bh->b_size >> inode->i_blkbits;
+ 
+ 	ret = f2fs_map_blocks(inode, &map, create, flag);
+ 	if (!ret) {
+ 		map_bh(bh, inode->i_sb, map.m_pblk);
+ 		bh->b_state = (bh->b_state & ~F2FS_MAP_FLAGS) | map.m_flags;
+ 		bh->b_size = map.m_len << inode->i_blkbits;
+ 	}
+ 	return ret;
+ }
+ 
+ static int get_data_block(struct inode *inode, sector_t iblock,
+ 			struct buffer_head *bh_result, int create, int flag)
+ {
+ 	return __get_data_block(inode, iblock, bh_result, create, flag);
+ }
+ 
+ static int get_data_block_dio(struct inode *inode, sector_t iblock,
+ 			struct buffer_head *bh_result, int create)
+ {
+ 	return __get_data_block(inode, iblock, bh_result, create,
+ 						F2FS_GET_BLOCK_DIO);
+ }
+ 
+ static int get_data_block_bmap(struct inode *inode, sector_t iblock,
+ 			struct buffer_head *bh_result, int create)
+ {
+ 	/* Block number less than F2FS MAX BLOCKS */
+ 	if (unlikely(iblock >= F2FS_I_SB(inode)->max_file_blocks))
+ 		return -EFBIG;
+ 
+ 	return __get_data_block(inode, iblock, bh_result, create,
+ 						F2FS_GET_BLOCK_BMAP);
+ }
+ 
+ static inline sector_t logical_to_blk(struct inode *inode, loff_t offset)
+ {
+ 	return (offset >> inode->i_blkbits);
+ }
+ 
+ static inline loff_t blk_to_logical(struct inode *inode, sector_t blk)
+ {
+ 	return (blk << inode->i_blkbits);
+ }
+ 
+ int f2fs_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
+ 		u64 start, u64 len)
+ {
+ 	struct buffer_head map_bh;
+ 	sector_t start_blk, last_blk;
+ 	loff_t isize;
+ 	u64 logical = 0, phys = 0, size = 0;
+ 	u32 flags = 0;
+ 	int ret = 0;
+ 
+ 	ret = fiemap_check_flags(fieinfo, FIEMAP_FLAG_SYNC);
+ 	if (ret)
+ 		return ret;
+ 
+ 	if (f2fs_has_inline_data(inode)) {
+ 		ret = f2fs_inline_data_fiemap(inode, fieinfo, start, len);
+ 		if (ret != -EAGAIN)
+ 			return ret;
+ 	}
+ 
+ 	inode_lock(inode);
+ 
+ 	isize = i_size_read(inode);
+ 	if (start >= isize)
+ 		goto out;
+ 
+ 	if (start + len > isize)
+ 		len = isize - start;
+ 
+ 	if (logical_to_blk(inode, len) == 0)
+ 		len = blk_to_logical(inode, 1);
+ 
+ 	start_blk = logical_to_blk(inode, start);
+ 	last_blk = logical_to_blk(inode, start + len - 1);
+ 
+ next:
+ 	memset(&map_bh, 0, sizeof(struct buffer_head));
+ 	map_bh.b_size = len;
+ 
+ 	ret = get_data_block(inode, start_blk, &map_bh, 0,
+ 					F2FS_GET_BLOCK_FIEMAP);
+ 	if (ret)
+ 		goto out;
+ 
+ 	/* HOLE */
+ 	if (!buffer_mapped(&map_bh)) {
+ 		/* Go through holes util pass the EOF */
+ 		if (blk_to_logical(inode, start_blk++) < isize)
+ 			goto prep_next;
+ 		/* Found a hole beyond isize means no more extents.
+ 		 * Note that the premise is that filesystems don't
+ 		 * punch holes beyond isize and keep size unchanged.
+ 		 */
+ 		flags |= FIEMAP_EXTENT_LAST;
+ 	}
+ 
+ 	if (size) {
+ 		if (f2fs_encrypted_inode(inode))
+ 			flags |= FIEMAP_EXTENT_DATA_ENCRYPTED;
+ 
+ 		ret = fiemap_fill_next_extent(fieinfo, logical,
+ 				phys, size, flags);
+ 	}
+ 
+ 	if (start_blk > last_blk || ret)
+ 		goto out;
+ 
+ 	logical = blk_to_logical(inode, start_blk);
+ 	phys = blk_to_logical(inode, map_bh.b_blocknr);
+ 	size = map_bh.b_size;
+ 	flags = 0;
+ 	if (buffer_unwritten(&map_bh))
+ 		flags = FIEMAP_EXTENT_UNWRITTEN;
+ 
+ 	start_blk += logical_to_blk(inode, size);
+ 
+ prep_next:
+ 	cond_resched();
+ 	if (fatal_signal_pending(current))
+ 		ret = -EINTR;
+ 	else
+ 		goto next;
+ out:
+ 	if (ret == 1)
+ 		ret = 0;
+ 
+ 	inode_unlock(inode);
+ 	return ret;
+ }
+ 
+ /*
+  * This function was originally taken from fs/mpage.c, and customized for f2fs.
+  * Major change was from block_size == page_size in f2fs by default.
+  */
+ static int f2fs_mpage_readpages(struct address_space *mapping,
+ 			struct list_head *pages, struct page *page,
+ 			unsigned nr_pages)
+ {
+ 	struct bio *bio = NULL;
+ 	unsigned page_idx;
+ 	sector_t last_block_in_bio = 0;
+ 	struct inode *inode = mapping->host;
+ 	const unsigned blkbits = inode->i_blkbits;
+ 	const unsigned blocksize = 1 << blkbits;
+ 	sector_t block_in_file;
+ 	sector_t last_block;
+ 	sector_t last_block_in_file;
+ 	sector_t block_nr;
+ 	struct block_device *bdev = inode->i_sb->s_bdev;
+ 	struct f2fs_map_blocks map;
+ 
+ 	map.m_pblk = 0;
+ 	map.m_lblk = 0;
+ 	map.m_len = 0;
+ 	map.m_flags = 0;
+ 
+ 	for (page_idx = 0; nr_pages; page_idx++, nr_pages--) {
+ 
+ 		prefetchw(&page->flags);
+ 		if (pages) {
+ 			page = list_entry(pages->prev, struct page, lru);
+ 			list_del(&page->lru);
+ 			if (add_to_page_cache_lru(page, mapping,
+ 						  page->index, GFP_KERNEL))
+ 				goto next_page;
+ 		}
+ 
+ 		block_in_file = (sector_t)page->index;
+ 		last_block = block_in_file + nr_pages;
+ 		last_block_in_file = (i_size_read(inode) + blocksize - 1) >>
+ 								blkbits;
+ 		if (last_block > last_block_in_file)
+ 			last_block = last_block_in_file;
+ 
+ 		/*
+ 		 * Map blocks using the previous result first.
+ 		 */
+ 		if ((map.m_flags & F2FS_MAP_MAPPED) &&
+ 				block_in_file > map.m_lblk &&
+ 				block_in_file < (map.m_lblk + map.m_len))
+ 			goto got_it;
+ 
+ 		/*
+ 		 * Then do more f2fs_map_blocks() calls until we are
+ 		 * done with this page.
+ 		 */
+ 		map.m_flags = 0;
+ 
+ 		if (block_in_file < last_block) {
+ 			map.m_lblk = block_in_file;
+ 			map.m_len = last_block - block_in_file;
+ 
+ 			if (f2fs_map_blocks(inode, &map, 0,
+ 							F2FS_GET_BLOCK_READ))
+ 				goto set_error_page;
+ 		}
+ got_it:
+ 		if ((map.m_flags & F2FS_MAP_MAPPED)) {
+ 			block_nr = map.m_pblk + block_in_file - map.m_lblk;
+ 			SetPageMappedToDisk(page);
+ 
+ 			if (!PageUptodate(page) && !cleancache_get_page(page)) {
+ 				SetPageUptodate(page);
+ 				goto confused;
+ 			}
+ 		} else {
+ 			zero_user_segment(page, 0, PAGE_CACHE_SIZE);
+ 			SetPageUptodate(page);
+ 			unlock_page(page);
+ 			goto next_page;
+ 		}
+ 
+ 		/*
+ 		 * This page will go to BIO.  Do we need to send this
+ 		 * BIO off first?
+ 		 */
+ 		if (bio && (last_block_in_bio != block_nr - 1)) {
+ submit_and_realloc:
+ 			submit_bio(READ, bio);
+ 			bio = NULL;
+ 		}
+ 		if (bio == NULL) {
+ 			struct f2fs_crypto_ctx *ctx = NULL;
+ 
+ 			if (f2fs_encrypted_inode(inode) &&
+ 					S_ISREG(inode->i_mode)) {
+ 
+ 				ctx = f2fs_get_crypto_ctx(inode);
+ 				if (IS_ERR(ctx))
+ 					goto set_error_page;
+ 
+ 				/* wait the page to be moved by cleaning */
+ 				f2fs_wait_on_encrypted_page_writeback(
+ 						F2FS_I_SB(inode), block_nr);
+ 			}
+ 
+ 			bio = bio_alloc(GFP_KERNEL,
+ 				min_t(int, nr_pages, BIO_MAX_PAGES));
+ 			if (!bio) {
+ 				if (ctx)
+ 					f2fs_release_crypto_ctx(ctx);
+ 				goto set_error_page;
+ 			}
+ 			bio->bi_bdev = bdev;
+ 			bio->bi_iter.bi_sector = SECTOR_FROM_BLOCK(block_nr);
+ 			bio->bi_end_io = f2fs_read_end_io;
+ 			bio->bi_private = ctx;
+ 		}
+ 
+ 		if (bio_add_page(bio, page, blocksize, 0) < blocksize)
+ 			goto submit_and_realloc;
+ 
+ 		last_block_in_bio = block_nr;
+ 		goto next_page;
+ set_error_page:
+ 		SetPageError(page);
+ 		zero_user_segment(page, 0, PAGE_CACHE_SIZE);
+ 		unlock_page(page);
+ 		goto next_page;
+ confused:
+ 		if (bio) {
+ 			submit_bio(READ, bio);
+ 			bio = NULL;
+ 		}
+ 		unlock_page(page);
+ next_page:
+ 		if (pages)
+ 			page_cache_release(page);
+ 	}
+ 	BUG_ON(pages && !list_empty(pages));
+ 	if (bio)
+ 		submit_bio(READ, bio);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return 0;
  }
  
diff --cc fs/f2fs/file.c
index 1cae864f8dfc,ea272be62677..000000000000
--- a/fs/f2fs/file.c
+++ b/fs/f2fs/file.c
@@@ -161,8 -287,151 +161,139 @@@ out
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ static pgoff_t __get_first_dirty_index(struct address_space *mapping,
+ 						pgoff_t pgofs, int whence)
+ {
+ 	struct pagevec pvec;
+ 	int nr_pages;
+ 
+ 	if (whence != SEEK_DATA)
+ 		return 0;
+ 
+ 	/* find first dirty page index */
+ 	pagevec_init(&pvec, 0);
+ 	nr_pages = pagevec_lookup_tag(&pvec, mapping, &pgofs,
+ 					PAGECACHE_TAG_DIRTY, 1);
+ 	pgofs = nr_pages ? pvec.pages[0]->index : LONG_MAX;
+ 	pagevec_release(&pvec);
+ 	return pgofs;
+ }
+ 
+ static bool __found_offset(block_t blkaddr, pgoff_t dirty, pgoff_t pgofs,
+ 							int whence)
+ {
+ 	switch (whence) {
+ 	case SEEK_DATA:
+ 		if ((blkaddr == NEW_ADDR && dirty == pgofs) ||
+ 			(blkaddr != NEW_ADDR && blkaddr != NULL_ADDR))
+ 			return true;
+ 		break;
+ 	case SEEK_HOLE:
+ 		if (blkaddr == NULL_ADDR)
+ 			return true;
+ 		break;
+ 	}
+ 	return false;
+ }
+ 
+ static loff_t f2fs_seek_block(struct file *file, loff_t offset, int whence)
+ {
+ 	struct inode *inode = file->f_mapping->host;
+ 	loff_t maxbytes = inode->i_sb->s_maxbytes;
+ 	struct dnode_of_data dn;
+ 	pgoff_t pgofs, end_offset, dirty;
+ 	loff_t data_ofs = offset;
+ 	loff_t isize;
+ 	int err = 0;
+ 
+ 	inode_lock(inode);
+ 
+ 	isize = i_size_read(inode);
+ 	if (offset >= isize)
+ 		goto fail;
+ 
+ 	/* handle inline data case */
+ 	if (f2fs_has_inline_data(inode) || f2fs_has_inline_dentry(inode)) {
+ 		if (whence == SEEK_HOLE)
+ 			data_ofs = isize;
+ 		goto found;
+ 	}
+ 
+ 	pgofs = (pgoff_t)(offset >> PAGE_CACHE_SHIFT);
+ 
+ 	dirty = __get_first_dirty_index(inode->i_mapping, pgofs, whence);
+ 
+ 	for (; data_ofs < isize; data_ofs = (loff_t)pgofs << PAGE_CACHE_SHIFT) {
+ 		set_new_dnode(&dn, inode, NULL, NULL, 0);
+ 		err = get_dnode_of_data(&dn, pgofs, LOOKUP_NODE_RA);
+ 		if (err && err != -ENOENT) {
+ 			goto fail;
+ 		} else if (err == -ENOENT) {
+ 			/* direct node does not exists */
+ 			if (whence == SEEK_DATA) {
+ 				pgofs = PGOFS_OF_NEXT_DNODE(pgofs,
+ 							F2FS_I(inode));
+ 				continue;
+ 			} else {
+ 				goto found;
+ 			}
+ 		}
+ 
+ 		end_offset = ADDRS_PER_PAGE(dn.node_page, F2FS_I(inode));
+ 
+ 		/* find data/hole in dnode block */
+ 		for (; dn.ofs_in_node < end_offset;
+ 				dn.ofs_in_node++, pgofs++,
+ 				data_ofs = (loff_t)pgofs << PAGE_CACHE_SHIFT) {
+ 			block_t blkaddr;
+ 			blkaddr = datablock_addr(dn.node_page, dn.ofs_in_node);
+ 
+ 			if (__found_offset(blkaddr, dirty, pgofs, whence)) {
+ 				f2fs_put_dnode(&dn);
+ 				goto found;
+ 			}
+ 		}
+ 		f2fs_put_dnode(&dn);
+ 	}
+ 
+ 	if (whence == SEEK_DATA)
+ 		goto fail;
+ found:
+ 	if (whence == SEEK_HOLE && data_ofs > isize)
+ 		data_ofs = isize;
+ 	inode_unlock(inode);
+ 	return vfs_setpos(file, data_ofs, maxbytes);
+ fail:
+ 	inode_unlock(inode);
+ 	return -ENXIO;
+ }
+ 
+ static loff_t f2fs_llseek(struct file *file, loff_t offset, int whence)
+ {
+ 	struct inode *inode = file->f_mapping->host;
+ 	loff_t maxbytes = inode->i_sb->s_maxbytes;
+ 
+ 	switch (whence) {
+ 	case SEEK_SET:
+ 	case SEEK_CUR:
+ 	case SEEK_END:
+ 		return generic_file_llseek_size(file, offset, whence,
+ 						maxbytes, i_size_read(inode));
+ 	case SEEK_DATA:
+ 	case SEEK_HOLE:
+ 		if (offset < 0)
+ 			return -ENXIO;
+ 		return f2fs_seek_block(file, offset, whence);
+ 	}
+ 
+ 	return -EINVAL;
+ }
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  static int f2fs_file_mmap(struct file *file, struct vm_area_struct *vma)
  {
 -	struct inode *inode = file_inode(file);
 -	int err;
 -
 -	if (f2fs_encrypted_inode(inode)) {
 -		err = f2fs_get_encryption_info(inode);
 -		if (err)
 -			return 0;
 -	}
 -
 -	/* we don't need to use inline_data strictly */
 -	err = f2fs_convert_inline_inode(inode);
 -	if (err)
 -		return err;
 -
  	file_accessed(file);
  	vma->vm_ops = &f2fs_file_vm_ops;
  	return 0;
@@@ -536,20 -1204,47 +667,49 @@@ static long f2fs_fallocate(struct file 
  				loff_t offset, loff_t len)
  {
  	struct inode *inode = file_inode(file);
 -	long ret = 0;
 -
 -	/* f2fs only support ->fallocate for regular file */
 -	if (!S_ISREG(inode->i_mode))
 -		return -EINVAL;
 +	long ret;
  
 -	if (f2fs_encrypted_inode(inode) &&
 -		(mode & (FALLOC_FL_COLLAPSE_RANGE | FALLOC_FL_INSERT_RANGE)))
 +	if (mode & ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))
  		return -EOPNOTSUPP;
  
++<<<<<<< HEAD
 +	if (mode & FALLOC_FL_PUNCH_HOLE)
 +		ret = punch_hole(inode, offset, len, mode);
 +	else
++=======
+ 	if (mode & ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE |
+ 			FALLOC_FL_COLLAPSE_RANGE | FALLOC_FL_ZERO_RANGE |
+ 			FALLOC_FL_INSERT_RANGE))
+ 		return -EOPNOTSUPP;
+ 
+ 	inode_lock(inode);
+ 
+ 	if (mode & FALLOC_FL_PUNCH_HOLE) {
+ 		if (offset >= inode->i_size)
+ 			goto out;
+ 
+ 		ret = punch_hole(inode, offset, len);
+ 	} else if (mode & FALLOC_FL_COLLAPSE_RANGE) {
+ 		ret = f2fs_collapse_range(inode, offset, len);
+ 	} else if (mode & FALLOC_FL_ZERO_RANGE) {
+ 		ret = f2fs_zero_range(inode, offset, len, mode);
+ 	} else if (mode & FALLOC_FL_INSERT_RANGE) {
+ 		ret = f2fs_insert_range(inode, offset, len);
+ 	} else {
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		ret = expand_inode_data(inode, offset, len, mode);
 -	}
  
  	if (!ret) {
  		inode->i_mtime = inode->i_ctime = CURRENT_TIME;
  		mark_inode_dirty(inode);
 -		f2fs_update_time(F2FS_I_SB(inode), REQ_TIME);
  	}
++<<<<<<< HEAD
++=======
+ 
+ out:
+ 	inode_unlock(inode);
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	trace_f2fs_fallocate(inode, mode, offset, len, ret);
  	return ret;
  }
@@@ -567,64 -1275,613 +727,624 @@@ static inline __u32 f2fs_mask_flags(umo
  		return flags & F2FS_OTHER_FLMASK;
  }
  
++<<<<<<< HEAD
++=======
+ static int f2fs_ioc_getflags(struct file *filp, unsigned long arg)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	struct f2fs_inode_info *fi = F2FS_I(inode);
+ 	unsigned int flags = fi->i_flags & FS_FL_USER_VISIBLE;
+ 	return put_user(flags, (int __user *)arg);
+ }
+ 
+ static int f2fs_ioc_setflags(struct file *filp, unsigned long arg)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	struct f2fs_inode_info *fi = F2FS_I(inode);
+ 	unsigned int flags = fi->i_flags & FS_FL_USER_VISIBLE;
+ 	unsigned int oldflags;
+ 	int ret;
+ 
+ 	ret = mnt_want_write_file(filp);
+ 	if (ret)
+ 		return ret;
+ 
+ 	if (!inode_owner_or_capable(inode)) {
+ 		ret = -EACCES;
+ 		goto out;
+ 	}
+ 
+ 	if (get_user(flags, (int __user *)arg)) {
+ 		ret = -EFAULT;
+ 		goto out;
+ 	}
+ 
+ 	flags = f2fs_mask_flags(inode->i_mode, flags);
+ 
+ 	inode_lock(inode);
+ 
+ 	oldflags = fi->i_flags;
+ 
+ 	if ((flags ^ oldflags) & (FS_APPEND_FL | FS_IMMUTABLE_FL)) {
+ 		if (!capable(CAP_LINUX_IMMUTABLE)) {
+ 			inode_unlock(inode);
+ 			ret = -EPERM;
+ 			goto out;
+ 		}
+ 	}
+ 
+ 	flags = flags & FS_FL_USER_MODIFIABLE;
+ 	flags |= oldflags & ~FS_FL_USER_MODIFIABLE;
+ 	fi->i_flags = flags;
+ 	inode_unlock(inode);
+ 
+ 	f2fs_set_inode_flags(inode);
+ 	inode->i_ctime = CURRENT_TIME;
+ 	mark_inode_dirty(inode);
+ out:
+ 	mnt_drop_write_file(filp);
+ 	return ret;
+ }
+ 
+ static int f2fs_ioc_getversion(struct file *filp, unsigned long arg)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 
+ 	return put_user(inode->i_generation, (int __user *)arg);
+ }
+ 
+ static int f2fs_ioc_start_atomic_write(struct file *filp)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	int ret;
+ 
+ 	if (!inode_owner_or_capable(inode))
+ 		return -EACCES;
+ 
+ 	if (f2fs_is_atomic_file(inode))
+ 		return 0;
+ 
+ 	ret = f2fs_convert_inline_inode(inode);
+ 	if (ret)
+ 		return ret;
+ 
+ 	set_inode_flag(F2FS_I(inode), FI_ATOMIC_FILE);
+ 	f2fs_update_time(F2FS_I_SB(inode), REQ_TIME);
+ 
+ 	return 0;
+ }
+ 
+ static int f2fs_ioc_commit_atomic_write(struct file *filp)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	int ret;
+ 
+ 	if (!inode_owner_or_capable(inode))
+ 		return -EACCES;
+ 
+ 	if (f2fs_is_volatile_file(inode))
+ 		return 0;
+ 
+ 	ret = mnt_want_write_file(filp);
+ 	if (ret)
+ 		return ret;
+ 
+ 	if (f2fs_is_atomic_file(inode)) {
+ 		clear_inode_flag(F2FS_I(inode), FI_ATOMIC_FILE);
+ 		ret = commit_inmem_pages(inode, false);
+ 		if (ret) {
+ 			set_inode_flag(F2FS_I(inode), FI_ATOMIC_FILE);
+ 			goto err_out;
+ 		}
+ 	}
+ 
+ 	ret = f2fs_sync_file(filp, 0, LLONG_MAX, 0);
+ err_out:
+ 	mnt_drop_write_file(filp);
+ 	return ret;
+ }
+ 
+ static int f2fs_ioc_start_volatile_write(struct file *filp)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	int ret;
+ 
+ 	if (!inode_owner_or_capable(inode))
+ 		return -EACCES;
+ 
+ 	if (f2fs_is_volatile_file(inode))
+ 		return 0;
+ 
+ 	ret = f2fs_convert_inline_inode(inode);
+ 	if (ret)
+ 		return ret;
+ 
+ 	set_inode_flag(F2FS_I(inode), FI_VOLATILE_FILE);
+ 	f2fs_update_time(F2FS_I_SB(inode), REQ_TIME);
+ 	return 0;
+ }
+ 
+ static int f2fs_ioc_release_volatile_write(struct file *filp)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 
+ 	if (!inode_owner_or_capable(inode))
+ 		return -EACCES;
+ 
+ 	if (!f2fs_is_volatile_file(inode))
+ 		return 0;
+ 
+ 	if (!f2fs_is_first_block_written(inode))
+ 		return truncate_partial_data_page(inode, 0, true);
+ 
+ 	return punch_hole(inode, 0, F2FS_BLKSIZE);
+ }
+ 
+ static int f2fs_ioc_abort_volatile_write(struct file *filp)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	int ret;
+ 
+ 	if (!inode_owner_or_capable(inode))
+ 		return -EACCES;
+ 
+ 	ret = mnt_want_write_file(filp);
+ 	if (ret)
+ 		return ret;
+ 
+ 	if (f2fs_is_atomic_file(inode)) {
+ 		clear_inode_flag(F2FS_I(inode), FI_ATOMIC_FILE);
+ 		commit_inmem_pages(inode, true);
+ 	}
+ 	if (f2fs_is_volatile_file(inode)) {
+ 		clear_inode_flag(F2FS_I(inode), FI_VOLATILE_FILE);
+ 		ret = f2fs_sync_file(filp, 0, LLONG_MAX, 0);
+ 	}
+ 
+ 	mnt_drop_write_file(filp);
+ 	f2fs_update_time(F2FS_I_SB(inode), REQ_TIME);
+ 	return ret;
+ }
+ 
+ static int f2fs_ioc_shutdown(struct file *filp, unsigned long arg)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
+ 	struct super_block *sb = sbi->sb;
+ 	__u32 in;
+ 
+ 	if (!capable(CAP_SYS_ADMIN))
+ 		return -EPERM;
+ 
+ 	if (get_user(in, (__u32 __user *)arg))
+ 		return -EFAULT;
+ 
+ 	switch (in) {
+ 	case F2FS_GOING_DOWN_FULLSYNC:
+ 		sb = freeze_bdev(sb->s_bdev);
+ 		if (sb && !IS_ERR(sb)) {
+ 			f2fs_stop_checkpoint(sbi);
+ 			thaw_bdev(sb->s_bdev, sb);
+ 		}
+ 		break;
+ 	case F2FS_GOING_DOWN_METASYNC:
+ 		/* do checkpoint only */
+ 		f2fs_sync_fs(sb, 1);
+ 		f2fs_stop_checkpoint(sbi);
+ 		break;
+ 	case F2FS_GOING_DOWN_NOSYNC:
+ 		f2fs_stop_checkpoint(sbi);
+ 		break;
+ 	case F2FS_GOING_DOWN_METAFLUSH:
+ 		sync_meta_pages(sbi, META, LONG_MAX);
+ 		f2fs_stop_checkpoint(sbi);
+ 		break;
+ 	default:
+ 		return -EINVAL;
+ 	}
+ 	f2fs_update_time(sbi, REQ_TIME);
+ 	return 0;
+ }
+ 
+ static int f2fs_ioc_fitrim(struct file *filp, unsigned long arg)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	struct super_block *sb = inode->i_sb;
+ 	struct request_queue *q = bdev_get_queue(sb->s_bdev);
+ 	struct fstrim_range range;
+ 	int ret;
+ 
+ 	if (!capable(CAP_SYS_ADMIN))
+ 		return -EPERM;
+ 
+ 	if (!blk_queue_discard(q))
+ 		return -EOPNOTSUPP;
+ 
+ 	if (copy_from_user(&range, (struct fstrim_range __user *)arg,
+ 				sizeof(range)))
+ 		return -EFAULT;
+ 
+ 	range.minlen = max((unsigned int)range.minlen,
+ 				q->limits.discard_granularity);
+ 	ret = f2fs_trim_fs(F2FS_SB(sb), &range);
+ 	if (ret < 0)
+ 		return ret;
+ 
+ 	if (copy_to_user((struct fstrim_range __user *)arg, &range,
+ 				sizeof(range)))
+ 		return -EFAULT;
+ 	f2fs_update_time(F2FS_I_SB(inode), REQ_TIME);
+ 	return 0;
+ }
+ 
+ static bool uuid_is_nonzero(__u8 u[16])
+ {
+ 	int i;
+ 
+ 	for (i = 0; i < 16; i++)
+ 		if (u[i])
+ 			return true;
+ 	return false;
+ }
+ 
+ static int f2fs_ioc_set_encryption_policy(struct file *filp, unsigned long arg)
+ {
+ #ifdef CONFIG_F2FS_FS_ENCRYPTION
+ 	struct f2fs_encryption_policy policy;
+ 	struct inode *inode = file_inode(filp);
+ 
+ 	if (copy_from_user(&policy, (struct f2fs_encryption_policy __user *)arg,
+ 				sizeof(policy)))
+ 		return -EFAULT;
+ 
+ 	f2fs_update_time(F2FS_I_SB(inode), REQ_TIME);
+ 	return f2fs_process_policy(&policy, inode);
+ #else
+ 	return -EOPNOTSUPP;
+ #endif
+ }
+ 
+ static int f2fs_ioc_get_encryption_policy(struct file *filp, unsigned long arg)
+ {
+ #ifdef CONFIG_F2FS_FS_ENCRYPTION
+ 	struct f2fs_encryption_policy policy;
+ 	struct inode *inode = file_inode(filp);
+ 	int err;
+ 
+ 	err = f2fs_get_policy(inode, &policy);
+ 	if (err)
+ 		return err;
+ 
+ 	if (copy_to_user((struct f2fs_encryption_policy __user *)arg, &policy,
+ 							sizeof(policy)))
+ 		return -EFAULT;
+ 	return 0;
+ #else
+ 	return -EOPNOTSUPP;
+ #endif
+ }
+ 
+ static int f2fs_ioc_get_encryption_pwsalt(struct file *filp, unsigned long arg)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
+ 	int err;
+ 
+ 	if (!f2fs_sb_has_crypto(inode->i_sb))
+ 		return -EOPNOTSUPP;
+ 
+ 	if (uuid_is_nonzero(sbi->raw_super->encrypt_pw_salt))
+ 		goto got_it;
+ 
+ 	err = mnt_want_write_file(filp);
+ 	if (err)
+ 		return err;
+ 
+ 	/* update superblock with uuid */
+ 	generate_random_uuid(sbi->raw_super->encrypt_pw_salt);
+ 
+ 	err = f2fs_commit_super(sbi, false);
+ 	if (err) {
+ 		/* undo new data */
+ 		memset(sbi->raw_super->encrypt_pw_salt, 0, 16);
+ 		mnt_drop_write_file(filp);
+ 		return err;
+ 	}
+ 	mnt_drop_write_file(filp);
+ got_it:
+ 	if (copy_to_user((__u8 __user *)arg, sbi->raw_super->encrypt_pw_salt,
+ 									16))
+ 		return -EFAULT;
+ 	return 0;
+ }
+ 
+ static int f2fs_ioc_gc(struct file *filp, unsigned long arg)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
+ 	__u32 sync;
+ 
+ 	if (!capable(CAP_SYS_ADMIN))
+ 		return -EPERM;
+ 
+ 	if (get_user(sync, (__u32 __user *)arg))
+ 		return -EFAULT;
+ 
+ 	if (f2fs_readonly(sbi->sb))
+ 		return -EROFS;
+ 
+ 	if (!sync) {
+ 		if (!mutex_trylock(&sbi->gc_mutex))
+ 			return -EBUSY;
+ 	} else {
+ 		mutex_lock(&sbi->gc_mutex);
+ 	}
+ 
+ 	return f2fs_gc(sbi, sync);
+ }
+ 
+ static int f2fs_ioc_write_checkpoint(struct file *filp, unsigned long arg)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
+ 
+ 	if (!capable(CAP_SYS_ADMIN))
+ 		return -EPERM;
+ 
+ 	if (f2fs_readonly(sbi->sb))
+ 		return -EROFS;
+ 
+ 	return f2fs_sync_fs(sbi->sb, 1);
+ }
+ 
+ static int f2fs_defragment_range(struct f2fs_sb_info *sbi,
+ 					struct file *filp,
+ 					struct f2fs_defragment *range)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	struct f2fs_map_blocks map;
+ 	struct extent_info ei;
+ 	pgoff_t pg_start, pg_end;
+ 	unsigned int blk_per_seg = sbi->blocks_per_seg;
+ 	unsigned int total = 0, sec_num;
+ 	unsigned int pages_per_sec = sbi->segs_per_sec * blk_per_seg;
+ 	block_t blk_end = 0;
+ 	bool fragmented = false;
+ 	int err;
+ 
+ 	/* if in-place-update policy is enabled, don't waste time here */
+ 	if (need_inplace_update(inode))
+ 		return -EINVAL;
+ 
+ 	pg_start = range->start >> PAGE_CACHE_SHIFT;
+ 	pg_end = (range->start + range->len) >> PAGE_CACHE_SHIFT;
+ 
+ 	f2fs_balance_fs(sbi, true);
+ 
+ 	inode_lock(inode);
+ 
+ 	/* writeback all dirty pages in the range */
+ 	err = filemap_write_and_wait_range(inode->i_mapping, range->start,
+ 						range->start + range->len - 1);
+ 	if (err)
+ 		goto out;
+ 
+ 	/*
+ 	 * lookup mapping info in extent cache, skip defragmenting if physical
+ 	 * block addresses are continuous.
+ 	 */
+ 	if (f2fs_lookup_extent_cache(inode, pg_start, &ei)) {
+ 		if (ei.fofs + ei.len >= pg_end)
+ 			goto out;
+ 	}
+ 
+ 	map.m_lblk = pg_start;
+ 
+ 	/*
+ 	 * lookup mapping info in dnode page cache, skip defragmenting if all
+ 	 * physical block addresses are continuous even if there are hole(s)
+ 	 * in logical blocks.
+ 	 */
+ 	while (map.m_lblk < pg_end) {
+ 		map.m_len = pg_end - map.m_lblk;
+ 		err = f2fs_map_blocks(inode, &map, 0, F2FS_GET_BLOCK_READ);
+ 		if (err)
+ 			goto out;
+ 
+ 		if (!(map.m_flags & F2FS_MAP_FLAGS)) {
+ 			map.m_lblk++;
+ 			continue;
+ 		}
+ 
+ 		if (blk_end && blk_end != map.m_pblk) {
+ 			fragmented = true;
+ 			break;
+ 		}
+ 		blk_end = map.m_pblk + map.m_len;
+ 
+ 		map.m_lblk += map.m_len;
+ 	}
+ 
+ 	if (!fragmented)
+ 		goto out;
+ 
+ 	map.m_lblk = pg_start;
+ 	map.m_len = pg_end - pg_start;
+ 
+ 	sec_num = (map.m_len + pages_per_sec - 1) / pages_per_sec;
+ 
+ 	/*
+ 	 * make sure there are enough free section for LFS allocation, this can
+ 	 * avoid defragment running in SSR mode when free section are allocated
+ 	 * intensively
+ 	 */
+ 	if (has_not_enough_free_secs(sbi, sec_num)) {
+ 		err = -EAGAIN;
+ 		goto out;
+ 	}
+ 
+ 	while (map.m_lblk < pg_end) {
+ 		pgoff_t idx;
+ 		int cnt = 0;
+ 
+ do_map:
+ 		map.m_len = pg_end - map.m_lblk;
+ 		err = f2fs_map_blocks(inode, &map, 0, F2FS_GET_BLOCK_READ);
+ 		if (err)
+ 			goto clear_out;
+ 
+ 		if (!(map.m_flags & F2FS_MAP_FLAGS)) {
+ 			map.m_lblk++;
+ 			continue;
+ 		}
+ 
+ 		set_inode_flag(F2FS_I(inode), FI_DO_DEFRAG);
+ 
+ 		idx = map.m_lblk;
+ 		while (idx < map.m_lblk + map.m_len && cnt < blk_per_seg) {
+ 			struct page *page;
+ 
+ 			page = get_lock_data_page(inode, idx, true);
+ 			if (IS_ERR(page)) {
+ 				err = PTR_ERR(page);
+ 				goto clear_out;
+ 			}
+ 
+ 			set_page_dirty(page);
+ 			f2fs_put_page(page, 1);
+ 
+ 			idx++;
+ 			cnt++;
+ 			total++;
+ 		}
+ 
+ 		map.m_lblk = idx;
+ 
+ 		if (idx < pg_end && cnt < blk_per_seg)
+ 			goto do_map;
+ 
+ 		clear_inode_flag(F2FS_I(inode), FI_DO_DEFRAG);
+ 
+ 		err = filemap_fdatawrite(inode->i_mapping);
+ 		if (err)
+ 			goto out;
+ 	}
+ clear_out:
+ 	clear_inode_flag(F2FS_I(inode), FI_DO_DEFRAG);
+ out:
+ 	inode_unlock(inode);
+ 	if (!err)
+ 		range->len = (u64)total << PAGE_CACHE_SHIFT;
+ 	return err;
+ }
+ 
+ static int f2fs_ioc_defragment(struct file *filp, unsigned long arg)
+ {
+ 	struct inode *inode = file_inode(filp);
+ 	struct f2fs_sb_info *sbi = F2FS_I_SB(inode);
+ 	struct f2fs_defragment range;
+ 	int err;
+ 
+ 	if (!capable(CAP_SYS_ADMIN))
+ 		return -EPERM;
+ 
+ 	if (!S_ISREG(inode->i_mode))
+ 		return -EINVAL;
+ 
+ 	err = mnt_want_write_file(filp);
+ 	if (err)
+ 		return err;
+ 
+ 	if (f2fs_readonly(sbi->sb)) {
+ 		err = -EROFS;
+ 		goto out;
+ 	}
+ 
+ 	if (copy_from_user(&range, (struct f2fs_defragment __user *)arg,
+ 							sizeof(range))) {
+ 		err = -EFAULT;
+ 		goto out;
+ 	}
+ 
+ 	/* verify alignment of offset & size */
+ 	if (range.start & (F2FS_BLKSIZE - 1) ||
+ 		range.len & (F2FS_BLKSIZE - 1)) {
+ 		err = -EINVAL;
+ 		goto out;
+ 	}
+ 
+ 	err = f2fs_defragment_range(sbi, filp, &range);
+ 	f2fs_update_time(sbi, REQ_TIME);
+ 	if (err < 0)
+ 		goto out;
+ 
+ 	if (copy_to_user((struct f2fs_defragment __user *)arg, &range,
+ 							sizeof(range)))
+ 		err = -EFAULT;
+ out:
+ 	mnt_drop_write_file(filp);
+ 	return err;
+ }
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  long f2fs_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
  {
 +	struct inode *inode = file_inode(filp);
 +	struct f2fs_inode_info *fi = F2FS_I(inode);
 +	unsigned int flags;
 +	int ret;
 +
  	switch (cmd) {
 -	case F2FS_IOC_GETFLAGS:
 -		return f2fs_ioc_getflags(filp, arg);
 -	case F2FS_IOC_SETFLAGS:
 -		return f2fs_ioc_setflags(filp, arg);
 -	case F2FS_IOC_GETVERSION:
 -		return f2fs_ioc_getversion(filp, arg);
 -	case F2FS_IOC_START_ATOMIC_WRITE:
 -		return f2fs_ioc_start_atomic_write(filp);
 -	case F2FS_IOC_COMMIT_ATOMIC_WRITE:
 -		return f2fs_ioc_commit_atomic_write(filp);
 -	case F2FS_IOC_START_VOLATILE_WRITE:
 -		return f2fs_ioc_start_volatile_write(filp);
 -	case F2FS_IOC_RELEASE_VOLATILE_WRITE:
 -		return f2fs_ioc_release_volatile_write(filp);
 -	case F2FS_IOC_ABORT_VOLATILE_WRITE:
 -		return f2fs_ioc_abort_volatile_write(filp);
 -	case F2FS_IOC_SHUTDOWN:
 -		return f2fs_ioc_shutdown(filp, arg);
 -	case FITRIM:
 -		return f2fs_ioc_fitrim(filp, arg);
 -	case F2FS_IOC_SET_ENCRYPTION_POLICY:
 -		return f2fs_ioc_set_encryption_policy(filp, arg);
 -	case F2FS_IOC_GET_ENCRYPTION_POLICY:
 -		return f2fs_ioc_get_encryption_policy(filp, arg);
 -	case F2FS_IOC_GET_ENCRYPTION_PWSALT:
 -		return f2fs_ioc_get_encryption_pwsalt(filp, arg);
 -	case F2FS_IOC_GARBAGE_COLLECT:
 -		return f2fs_ioc_gc(filp, arg);
 -	case F2FS_IOC_WRITE_CHECKPOINT:
 -		return f2fs_ioc_write_checkpoint(filp, arg);
 -	case F2FS_IOC_DEFRAGMENT:
 -		return f2fs_ioc_defragment(filp, arg);
 -	default:
 -		return -ENOTTY;
 -	}
 -}
 +	case FS_IOC_GETFLAGS:
 +		flags = fi->i_flags & FS_FL_USER_VISIBLE;
 +		return put_user(flags, (int __user *) arg);
 +	case FS_IOC_SETFLAGS:
 +	{
 +		unsigned int oldflags;
 +
 +		ret = mnt_want_write_file(filp);
 +		if (ret)
 +			return ret;
  
 -static ssize_t f2fs_file_write_iter(struct kiocb *iocb, struct iov_iter *from)
 -{
 -	struct inode *inode = file_inode(iocb->ki_filp);
 +		if (!inode_owner_or_capable(inode)) {
 +			ret = -EACCES;
 +			goto out;
 +		}
  
 -	if (f2fs_encrypted_inode(inode) &&
 -				!f2fs_has_encryption_key(inode) &&
 -				f2fs_get_encryption_info(inode))
 -		return -EACCES;
 +		if (get_user(flags, (int __user *) arg)) {
 +			ret = -EFAULT;
 +			goto out;
 +		}
 +
 +		flags = f2fs_mask_flags(inode->i_mode, flags);
 +
 +		mutex_lock(&inode->i_mutex);
 +
 +		oldflags = fi->i_flags;
 +
 +		if ((flags ^ oldflags) & (FS_APPEND_FL | FS_IMMUTABLE_FL)) {
 +			if (!capable(CAP_LINUX_IMMUTABLE)) {
 +				mutex_unlock(&inode->i_mutex);
 +				ret = -EPERM;
 +				goto out;
 +			}
 +		}
  
 -	return generic_file_write_iter(iocb, from);
 +		flags = flags & FS_FL_USER_MODIFIABLE;
 +		flags |= oldflags & ~FS_FL_USER_MODIFIABLE;
 +		fi->i_flags = flags;
 +		mutex_unlock(&inode->i_mutex);
 +
 +		f2fs_set_inode_flags(inode);
 +		inode->i_ctime = CURRENT_TIME;
 +		mark_inode_dirty(inode);
 +out:
 +		mnt_drop_write_file(filp);
 +		return ret;
 +	}
 +	default:
 +		return -ENOTTY;
 +	}
  }
  
  #ifdef CONFIG_COMPAT
diff --cc fs/fat/dir.c
index 7a6f02caf286,d0b95c95079b..000000000000
--- a/fs/fat/dir.c
+++ b/fs/fat/dir.c
@@@ -764,13 -769,15 +764,18 @@@ static int fat_ioctl_readdir(struct ino
  
  	buf.dirent = dirent;
  	buf.result = 0;
++<<<<<<< HEAD
 +	mutex_lock(&inode->i_mutex);
++=======
+ 	inode_lock(inode);
+ 	buf.ctx.pos = file->f_pos;
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	ret = -ENOENT;
  	if (!IS_DEADDIR(inode)) {
 -		ret = __fat_readdir(inode, file, &buf.ctx,
 -				    short_only, both ? &buf : NULL);
 -		file->f_pos = buf.ctx.pos;
 +		ret = __fat_readdir(inode, filp, &buf, filldir,
 +				    short_only, both);
  	}
- 	mutex_unlock(&inode->i_mutex);
+ 	inode_unlock(inode);
  	if (ret >= 0)
  		ret = buf.result;
  	return ret;
diff --cc fs/fat/file.c
index b0b632e50ddb,f70185668832..000000000000
--- a/fs/fat/file.c
+++ b/fs/fat/file.c
@@@ -212,6 -220,62 +212,65 @@@ out
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * Preallocate space for a file. This implements fat's fallocate file
+  * operation, which gets called from sys_fallocate system call. User
+  * space requests len bytes at offset. If FALLOC_FL_KEEP_SIZE is set
+  * we just allocate clusters without zeroing them out. Otherwise we
+  * allocate and zero out clusters via an expanding truncate.
+  */
+ static long fat_fallocate(struct file *file, int mode,
+ 			  loff_t offset, loff_t len)
+ {
+ 	int nr_cluster; /* Number of clusters to be allocated */
+ 	loff_t mm_bytes; /* Number of bytes to be allocated for file */
+ 	loff_t ondisksize; /* block aligned on-disk size in bytes*/
+ 	struct inode *inode = file->f_mapping->host;
+ 	struct super_block *sb = inode->i_sb;
+ 	struct msdos_sb_info *sbi = MSDOS_SB(sb);
+ 	int err = 0;
+ 
+ 	/* No support for hole punch or other fallocate flags. */
+ 	if (mode & ~FALLOC_FL_KEEP_SIZE)
+ 		return -EOPNOTSUPP;
+ 
+ 	/* No support for dir */
+ 	if (!S_ISREG(inode->i_mode))
+ 		return -EOPNOTSUPP;
+ 
+ 	inode_lock(inode);
+ 	if (mode & FALLOC_FL_KEEP_SIZE) {
+ 		ondisksize = inode->i_blocks << 9;
+ 		if ((offset + len) <= ondisksize)
+ 			goto error;
+ 
+ 		/* First compute the number of clusters to be allocated */
+ 		mm_bytes = offset + len - ondisksize;
+ 		nr_cluster = (mm_bytes + (sbi->cluster_size - 1)) >>
+ 			sbi->cluster_bits;
+ 
+ 		/* Start the allocation.We are not zeroing out the clusters */
+ 		while (nr_cluster-- > 0) {
+ 			err = fat_add_cluster(inode);
+ 			if (err)
+ 				goto error;
+ 		}
+ 	} else {
+ 		if ((offset + len) <= i_size_read(inode))
+ 			goto error;
+ 
+ 		/* This is just an expanding truncate */
+ 		err = fat_cont_expand(inode, (offset + len));
+ 	}
+ 
+ error:
+ 	inode_unlock(inode);
+ 	return err;
+ }
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  /* Free all clusters after the skip'th cluster. */
  static int fat_free(struct inode *inode, int skip)
  {
diff --cc fs/fuse/dir.c
index 07254ac422e9,4b855b65d457..000000000000
--- a/fs/fuse/dir.c
+++ b/fs/fuse/dir.c
@@@ -1034,9 -961,9 +1034,15 @@@ int fuse_reverse_inval_entry(struct sup
  	fuse_invalidate_attr(parent);
  	fuse_invalidate_entry(entry);
  
++<<<<<<< HEAD
 +	if (child_nodeid != 0 && entry->d_inode) {
 +		mutex_lock(&entry->d_inode->i_mutex);
 +		if (get_node_id(entry->d_inode) != child_nodeid) {
++=======
+ 	if (child_nodeid != 0 && d_really_is_positive(entry)) {
+ 		inode_lock(d_inode(entry));
+ 		if (get_node_id(d_inode(entry)) != child_nodeid) {
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  			err = -ENOENT;
  			goto badentry;
  		}
@@@ -1050,13 -977,13 +1056,17 @@@
  				err = -ENOTEMPTY;
  				goto badentry;
  			}
 -			d_inode(entry)->i_flags |= S_DEAD;
 +			entry->d_inode->i_flags |= S_DEAD;
  		}
  		dont_mount(entry);
 -		clear_nlink(d_inode(entry));
 +		clear_nlink(entry->d_inode);
  		err = 0;
   badentry:
++<<<<<<< HEAD
 +		mutex_unlock(&entry->d_inode->i_mutex);
++=======
+ 		inode_unlock(d_inode(entry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		if (!err)
  			d_delete(entry);
  	} else {
diff --cc fs/fuse/file.c
index ed212b08f7f8,b03d253ece15..000000000000
--- a/fs/fuse/file.c
+++ b/fs/fuse/file.c
@@@ -202,13 -206,18 +202,26 @@@ int fuse_open_common(struct inode *inod
  	if (err)
  		return err;
  
++<<<<<<< HEAD
++=======
+ 	if (lock_inode)
+ 		inode_lock(inode);
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	err = fuse_do_open(fc, get_node_id(inode), file, isdir);
 +	if (err)
 +		return err;
  
 -	if (!err)
 -		fuse_finish_open(inode, file);
 +	fuse_finish_open(inode, file);
  
++<<<<<<< HEAD
 +	return 0;
++=======
+ 	if (lock_inode)
+ 		inode_unlock(inode);
+ 
+ 	return err;
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  }
  
  static void fuse_prepare_release(struct fuse_file *ff, int flags, int opcode)
@@@ -373,6 -409,14 +386,17 @@@ static int fuse_flush(struct file *file
  	if (fc->no_flush)
  		return 0;
  
++<<<<<<< HEAD
++=======
+ 	err = write_inode_now(inode, 1);
+ 	if (err)
+ 		return err;
+ 
+ 	inode_lock(inode);
+ 	fuse_sync_writes(inode);
+ 	inode_unlock(inode);
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	req = fuse_get_req_nofail_nopages(fc, file);
  	memset(&inarg, 0, sizeof(inarg));
  	inarg.fh = ff->fh;
@@@ -421,14 -450,7 +445,18 @@@ int fuse_fsync_common(struct file *file
  	if (is_bad_inode(inode))
  		return -EIO;
  
++<<<<<<< HEAD
 +	err = filemap_write_and_wait_range(inode->i_mapping, start, end);
 +	if (err)
 +		return err;
 +
 +	if ((!isdir && fc->no_fsync) || (isdir && fc->no_fsyncdir))
 +		return 0;
 +
 +	mutex_lock(&inode->i_mutex);
++=======
+ 	inode_lock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	/*
  	 * Start writeback against all dirty pages of the inode, then
@@@ -1096,27 -1149,24 +1124,31 @@@ static ssize_t fuse_file_aio_write(stru
  	ssize_t written_buffered = 0;
  	struct inode *inode = mapping->host;
  	ssize_t err;
 +	struct iov_iter i;
  	loff_t endbyte = 0;
  
 -	if (get_fuse_conn(inode)->writeback_cache) {
 -		/* Update size (EOF optimization) and mode (SUID clearing) */
 -		err = fuse_update_attributes(mapping->host, NULL, file, NULL);
 -		if (err)
 -			return err;
 +	WARN_ON(iocb->ki_pos != pos);
  
 -		return generic_file_write_iter(iocb, from);
 -	}
 +	ocount = 0;
 +	err = generic_segment_checks(iov, &nr_segs, &ocount, VERIFY_READ);
 +	if (err)
 +		return err;
  
++<<<<<<< HEAD
 +	count = ocount;
 +	mutex_lock(&inode->i_mutex);
++=======
+ 	inode_lock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	/* We can write back this queue in page reclaim */
 -	current->backing_dev_info = inode_to_bdi(inode);
 +	current->backing_dev_info = mapping->backing_dev_info;
 +
 +	err = generic_write_checks(file, &pos, &count, S_ISBLK(inode->i_mode));
 +	if (err)
 +		goto out;
  
 -	err = generic_write_checks(iocb, from);
 -	if (err <= 0)
 +	if (count == 0)
  		goto out;
  
  	err = file_remove_privs(file);
@@@ -1292,6 -1320,14 +1324,17 @@@ ssize_t fuse_direct_io(struct fuse_io_p
  	if (IS_ERR(req))
  		return PTR_ERR(req);
  
++<<<<<<< HEAD
++=======
+ 	if (!cuse && fuse_range_is_writeback(inode, idx_from, idx_to)) {
+ 		if (!write)
+ 			inode_lock(inode);
+ 		fuse_sync_writes(inode);
+ 		if (!write)
+ 			inode_unlock(inode);
+ 	}
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	while (count) {
  		size_t nres;
  		fl_owner_t owner = current->files;
@@@ -1399,11 -1413,14 +1442,22 @@@ static ssize_t fuse_direct_write(struc
  		return -EIO;
  
  	/* Don't allow parallel writes to the same file */
++<<<<<<< HEAD
 +	mutex_lock(&inode->i_mutex);
 +	res = __fuse_direct_write(&io, &iov, 1, ppos);
 +	if (res > 0)
 +		fuse_write_update_size(inode, *ppos);
 +	mutex_unlock(&inode->i_mutex);
++=======
+ 	inode_lock(inode);
+ 	res = generic_write_checks(iocb, from);
+ 	if (res > 0)
+ 		res = fuse_direct_io(&io, from, &iocb->ki_pos, FUSE_DIO_WRITE);
+ 	fuse_invalidate_attr(inode);
+ 	if (res > 0)
+ 		fuse_write_update_size(inode, iocb->ki_pos);
+ 	inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	return res;
  }
@@@ -1842,15 -2280,28 +1896,35 @@@ static loff_t fuse_file_llseek(struct f
  	loff_t retval;
  	struct inode *inode = file_inode(file);
  
 -	switch (whence) {
 -	case SEEK_SET:
 -	case SEEK_CUR:
 -		 /* No i_mutex protection necessary for SEEK_CUR and SEEK_SET */
 +	/* No i_mutex protection necessary for SEEK_CUR and SEEK_SET */
 +	if (whence == SEEK_CUR || whence == SEEK_SET)
 +		return generic_file_llseek(file, offset, whence);
 +
 +	mutex_lock(&inode->i_mutex);
 +	retval = fuse_update_attributes(inode, NULL, file, NULL);
 +	if (!retval)
  		retval = generic_file_llseek(file, offset, whence);
++<<<<<<< HEAD
 +	mutex_unlock(&inode->i_mutex);
++=======
+ 		break;
+ 	case SEEK_END:
+ 		inode_lock(inode);
+ 		retval = fuse_update_attributes(inode, NULL, file, NULL);
+ 		if (!retval)
+ 			retval = generic_file_llseek(file, offset, whence);
+ 		inode_unlock(inode);
+ 		break;
+ 	case SEEK_HOLE:
+ 	case SEEK_DATA:
+ 		inode_lock(inode);
+ 		retval = fuse_lseek(file, offset, whence);
+ 		inode_unlock(inode);
+ 		break;
+ 	default:
+ 		retval = -EINVAL;
+ 	}
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	return retval;
  }
diff --cc fs/hugetlbfs/inode.c
index 7b7a94a0485b,e1f465a389d5..000000000000
--- a/fs/hugetlbfs/inode.c
+++ b/fs/hugetlbfs/inode.c
@@@ -418,9 -514,158 +418,161 @@@ static int hugetlb_vmtruncate(struct in
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static long hugetlbfs_punch_hole(struct inode *inode, loff_t offset, loff_t len)
+ {
+ 	struct hstate *h = hstate_inode(inode);
+ 	loff_t hpage_size = huge_page_size(h);
+ 	loff_t hole_start, hole_end;
+ 
+ 	/*
+ 	 * For hole punch round up the beginning offset of the hole and
+ 	 * round down the end.
+ 	 */
+ 	hole_start = round_up(offset, hpage_size);
+ 	hole_end = round_down(offset + len, hpage_size);
+ 
+ 	if (hole_end > hole_start) {
+ 		struct address_space *mapping = inode->i_mapping;
+ 
+ 		inode_lock(inode);
+ 		i_mmap_lock_write(mapping);
+ 		if (!RB_EMPTY_ROOT(&mapping->i_mmap))
+ 			hugetlb_vmdelete_list(&mapping->i_mmap,
+ 						hole_start >> PAGE_SHIFT,
+ 						hole_end  >> PAGE_SHIFT);
+ 		i_mmap_unlock_write(mapping);
+ 		remove_inode_hugepages(inode, hole_start, hole_end);
+ 		inode_unlock(inode);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static long hugetlbfs_fallocate(struct file *file, int mode, loff_t offset,
+ 				loff_t len)
+ {
+ 	struct inode *inode = file_inode(file);
+ 	struct address_space *mapping = inode->i_mapping;
+ 	struct hstate *h = hstate_inode(inode);
+ 	struct vm_area_struct pseudo_vma;
+ 	struct mm_struct *mm = current->mm;
+ 	loff_t hpage_size = huge_page_size(h);
+ 	unsigned long hpage_shift = huge_page_shift(h);
+ 	pgoff_t start, index, end;
+ 	int error;
+ 	u32 hash;
+ 
+ 	if (mode & ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))
+ 		return -EOPNOTSUPP;
+ 
+ 	if (mode & FALLOC_FL_PUNCH_HOLE)
+ 		return hugetlbfs_punch_hole(inode, offset, len);
+ 
+ 	/*
+ 	 * Default preallocate case.
+ 	 * For this range, start is rounded down and end is rounded up
+ 	 * as well as being converted to page offsets.
+ 	 */
+ 	start = offset >> hpage_shift;
+ 	end = (offset + len + hpage_size - 1) >> hpage_shift;
+ 
+ 	inode_lock(inode);
+ 
+ 	/* We need to check rlimit even when FALLOC_FL_KEEP_SIZE */
+ 	error = inode_newsize_ok(inode, offset + len);
+ 	if (error)
+ 		goto out;
+ 
+ 	/*
+ 	 * Initialize a pseudo vma as this is required by the huge page
+ 	 * allocation routines.  If NUMA is configured, use page index
+ 	 * as input to create an allocation policy.
+ 	 */
+ 	memset(&pseudo_vma, 0, sizeof(struct vm_area_struct));
+ 	pseudo_vma.vm_flags = (VM_HUGETLB | VM_MAYSHARE | VM_SHARED);
+ 	pseudo_vma.vm_file = file;
+ 
+ 	for (index = start; index < end; index++) {
+ 		/*
+ 		 * This is supposed to be the vaddr where the page is being
+ 		 * faulted in, but we have no vaddr here.
+ 		 */
+ 		struct page *page;
+ 		unsigned long addr;
+ 		int avoid_reserve = 0;
+ 
+ 		cond_resched();
+ 
+ 		/*
+ 		 * fallocate(2) manpage permits EINTR; we may have been
+ 		 * interrupted because we are using up too much memory.
+ 		 */
+ 		if (signal_pending(current)) {
+ 			error = -EINTR;
+ 			break;
+ 		}
+ 
+ 		/* Set numa allocation policy based on index */
+ 		hugetlb_set_vma_policy(&pseudo_vma, inode, index);
+ 
+ 		/* addr is the offset within the file (zero based) */
+ 		addr = index * hpage_size;
+ 
+ 		/* mutex taken here, fault path and hole punch */
+ 		hash = hugetlb_fault_mutex_hash(h, mm, &pseudo_vma, mapping,
+ 						index, addr);
+ 		mutex_lock(&hugetlb_fault_mutex_table[hash]);
+ 
+ 		/* See if already present in mapping to avoid alloc/free */
+ 		page = find_get_page(mapping, index);
+ 		if (page) {
+ 			put_page(page);
+ 			mutex_unlock(&hugetlb_fault_mutex_table[hash]);
+ 			hugetlb_drop_vma_policy(&pseudo_vma);
+ 			continue;
+ 		}
+ 
+ 		/* Allocate page and add to page cache */
+ 		page = alloc_huge_page(&pseudo_vma, addr, avoid_reserve);
+ 		hugetlb_drop_vma_policy(&pseudo_vma);
+ 		if (IS_ERR(page)) {
+ 			mutex_unlock(&hugetlb_fault_mutex_table[hash]);
+ 			error = PTR_ERR(page);
+ 			goto out;
+ 		}
+ 		clear_huge_page(page, addr, pages_per_huge_page(h));
+ 		__SetPageUptodate(page);
+ 		error = huge_add_to_page_cache(page, mapping, index);
+ 		if (unlikely(error)) {
+ 			put_page(page);
+ 			mutex_unlock(&hugetlb_fault_mutex_table[hash]);
+ 			goto out;
+ 		}
+ 
+ 		mutex_unlock(&hugetlb_fault_mutex_table[hash]);
+ 
+ 		/*
+ 		 * page_put due to reference from alloc_huge_page()
+ 		 * unlock_page because locked by add_to_page_cache()
+ 		 */
+ 		put_page(page);
+ 		unlock_page(page);
+ 	}
+ 
+ 	if (!(mode & FALLOC_FL_KEEP_SIZE) && offset + len > inode->i_size)
+ 		i_size_write(inode, offset + len);
+ 	inode->i_ctime = CURRENT_TIME;
+ out:
+ 	inode_unlock(inode);
+ 	return error;
+ }
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  static int hugetlbfs_setattr(struct dentry *dentry, struct iattr *attr)
  {
 -	struct inode *inode = d_inode(dentry);
 +	struct inode *inode = dentry->d_inode;
  	struct hstate *h = hstate_inode(inode);
  	int error;
  	unsigned int ia_valid = attr->ia_valid;
diff --cc fs/jfs/file.c
index dd7442c58358,4ce7735dd042..000000000000
--- a/fs/jfs/file.c
+++ b/fs/jfs/file.c
@@@ -37,8 -38,8 +37,13 @@@ int jfs_fsync(struct file *file, loff_
  	if (rc)
  		return rc;
  
++<<<<<<< HEAD
 +	mutex_lock(&inode->i_mutex);
 +	if (!(inode->i_state & I_DIRTY) ||
++=======
+ 	inode_lock(inode);
+ 	if (!(inode->i_state & I_DIRTY_ALL) ||
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	    (datasync && !(inode->i_state & I_DIRTY_DATASYNC))) {
  		/* Make sure committed changes hit the disk */
  		jfs_flush_journal(JFS_SBI(inode->i_sb)->log, 1);
diff --cc fs/libfs.c
index 23fbb25d1c9f,0ca80b2af420..000000000000
--- a/fs/libfs.c
+++ b/fs/libfs.c
@@@ -91,7 -89,7 +91,11 @@@ EXPORT_SYMBOL(dcache_dir_close)
  loff_t dcache_dir_lseek(struct file *file, loff_t offset, int whence)
  {
  	struct dentry *dentry = file->f_path.dentry;
++<<<<<<< HEAD
 +	mutex_lock(&dentry->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	switch (whence) {
  		case 1:
  			offset += file->f_pos;
@@@ -99,7 -97,7 +103,11 @@@
  			if (offset >= 0)
  				break;
  		default:
++<<<<<<< HEAD
 +			mutex_unlock(&dentry->d_inode->i_mutex);
++=======
+ 			inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  			return -EINVAL;
  	}
  	if (offset != file->f_pos) {
@@@ -126,7 -124,7 +134,11 @@@
  			spin_unlock(&dentry->d_lock);
  		}
  	}
++<<<<<<< HEAD
 +	mutex_unlock(&dentry->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return offset;
  }
  EXPORT_SYMBOL(dcache_dir_lseek);
@@@ -960,9 -941,9 +972,9 @@@ int generic_file_fsync(struct file *fil
  	if (err)
  		return err;
  
- 	mutex_lock(&inode->i_mutex);
+ 	inode_lock(inode);
  	ret = sync_mapping_buffers(inode->i_mapping);
 -	if (!(inode->i_state & I_DIRTY_ALL))
 +	if (!(inode->i_state & I_DIRTY))
  		goto out;
  	if (datasync && !(inode->i_state & I_DIRTY_DATASYNC))
  		goto out;
@@@ -970,10 -951,34 +982,10 @@@
  	err = sync_inode_metadata(inode, 1);
  	if (ret == 0)
  		ret = err;
 -
  out:
- 	mutex_unlock(&inode->i_mutex);
+ 	inode_unlock(inode);
  	return ret;
  }
 -EXPORT_SYMBOL(__generic_file_fsync);
 -
 -/**
 - * generic_file_fsync - generic fsync implementation for simple filesystems
 - *			with flush
 - * @file:	file to synchronize
 - * @start:	start offset in bytes
 - * @end:	end offset in bytes (inclusive)
 - * @datasync:	only synchronize essential metadata if true
 - *
 - */
 -
 -int generic_file_fsync(struct file *file, loff_t start, loff_t end,
 -		       int datasync)
 -{
 -	struct inode *inode = file->f_mapping->host;
 -	int err;
 -
 -	err = __generic_file_fsync(file, start, end, datasync);
 -	if (err)
 -		return err;
 -	return blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL, NULL);
 -}
  EXPORT_SYMBOL(generic_file_fsync);
  
  /**
diff --cc fs/locks.c
index 1f99358bf86e,7c5f91be9b65..000000000000
--- a/fs/locks.c
+++ b/fs/locks.c
@@@ -1558,6 -1655,7 +1558,10 @@@ generic_add_lease(struct file *filp, lo
  
  	if (is_deleg && arg == F_WRLCK) {
  		/* Write delegations are not currently supported: */
++<<<<<<< HEAD
++=======
+ 		inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		WARN_ON_ONCE(1);
  		return -EINVAL;
  	}
@@@ -1620,15 -1720,22 +1624,21 @@@
  	 */
  	smp_mb();
  	error = check_conflicting_open(dentry, arg, lease->fl_flags);
 -	if (error) {
 -		locks_unlink_lock_ctx(lease);
 -		goto out;
 -	}
 -
 -out_setup:
 -	if (lease->fl_lmops->lm_setup)
 -		lease->fl_lmops->lm_setup(lease, priv);
 +	if (error)
 +		goto out_unlink;
  out:
 -	spin_unlock(&ctx->flc_lock);
 -	locks_dispose_list(&dispose);
  	if (is_deleg)
++<<<<<<< HEAD
 +		mutex_unlock(&inode->i_mutex);
++=======
+ 		inode_unlock(inode);
+ 	if (!error && !my_fl)
+ 		*flp = NULL;
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return error;
 +out_unlink:
 +	locks_unlink_lock(before);
 +	goto out;
  }
  
  static int generic_delete_lease(struct file *filp, void *owner)
diff --cc fs/namei.c
index 5ce79acbacb6,f624d132e01e..000000000000
--- a/fs/namei.c
+++ b/fs/namei.c
@@@ -2063,33 -2215,26 +2063,41 @@@ static int do_path_lookup(int dfd, cons
  /* does lookup, returns the object with parent locked */
  struct dentry *kern_path_locked(const char *name, struct path *path)
  {
 -	struct filename *filename;
 +	struct filename *filename = getname_kernel(name);
 +	struct nameidata nd;
  	struct dentry *d;
 -	struct qstr last;
 -	int type;
 +	int err;
  
 -	filename = filename_parentat(AT_FDCWD, getname_kernel(name), 0, path,
 -				    &last, &type);
  	if (IS_ERR(filename))
  		return ERR_CAST(filename);
 -	if (unlikely(type != LAST_NORM)) {
 -		path_put(path);
 -		putname(filename);
 -		return ERR_PTR(-EINVAL);
 +
 +	err = filename_lookup(AT_FDCWD, filename, LOOKUP_PARENT, &nd);
 +	if (err) {
 +		d = ERR_PTR(err);
 +		goto out;
  	}
++<<<<<<< HEAD
 +	if (nd.last_type != LAST_NORM) {
 +		path_put(&nd.path);
 +		d = ERR_PTR(-EINVAL);
 +		goto out;
 +	}
 +	mutex_lock_nested(&nd.path.dentry->d_inode->i_mutex, I_MUTEX_PARENT);
 +	d = __lookup_hash(&nd.last, nd.path.dentry, 0);
 +	if (IS_ERR(d)) {
 +		mutex_unlock(&nd.path.dentry->d_inode->i_mutex);
 +		path_put(&nd.path);
 +		goto out;
++=======
+ 	inode_lock_nested(path->dentry->d_inode, I_MUTEX_PARENT);
+ 	d = __lookup_hash(&last, path->dentry, 0);
+ 	if (IS_ERR(d)) {
+ 		inode_unlock(path->dentry->d_inode);
+ 		path_put(path);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	}
 +	*path = nd.path;
 +out:
  	putname(filename);
  	return d;
  }
@@@ -2401,35 -2473,33 +2409,45 @@@ mountpoint_last(struct nameidata *nd, s
  		 */
  		dentry = d_alloc(dir, &nd->last);
  		if (!dentry) {
++<<<<<<< HEAD
 +			error = -ENOMEM;
 +			mutex_unlock(&dir->d_inode->i_mutex);
 +			goto out;
++=======
+ 			inode_unlock(dir->d_inode);
+ 			return -ENOMEM;
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		}
  		dentry = lookup_real(dir->d_inode, dentry, nd->flags);
 +		error = PTR_ERR(dentry);
  		if (IS_ERR(dentry)) {
++<<<<<<< HEAD
 +			mutex_unlock(&dir->d_inode->i_mutex);
 +			goto out;
++=======
+ 			inode_unlock(dir->d_inode);
+ 			return PTR_ERR(dentry);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		}
  	}
- 	mutex_unlock(&dir->d_inode->i_mutex);
+ 	inode_unlock(dir->d_inode);
  
  done:
 -	if (d_is_negative(dentry)) {
 +	if (!dentry->d_inode || d_is_negative(dentry)) {
 +		error = -ENOENT;
  		dput(dentry);
 -		return -ENOENT;
 +		goto out;
  	}
 -	if (nd->depth)
 -		put_link(nd);
  	path->dentry = dentry;
  	path->mnt = nd->path.mnt;
 -	error = should_follow_link(nd, path, nd->flags & LOOKUP_FOLLOW,
 -				   d_backing_inode(dentry), 0);
 -	if (unlikely(error))
 -		return error;
 +	if (should_follow_link(dentry, nd->flags & LOOKUP_FOLLOW))
 +		return 1;
  	mntget(path->mnt);
  	follow_mount(path);
 -	return 0;
 +	error = 0;
 +out:
 +	terminate_walk(nd);
 +	return error;
  }
  
  /**
@@@ -2640,10 -2692,11 +2658,10 @@@ struct dentry *lock_rename(struct dentr
  		return p;
  	}
  
- 	mutex_lock_nested(&p1->d_inode->i_mutex, I_MUTEX_PARENT);
- 	mutex_lock_nested(&p2->d_inode->i_mutex, I_MUTEX_PARENT2);
+ 	inode_lock_nested(p1->d_inode, I_MUTEX_PARENT);
+ 	inode_lock_nested(p2->d_inode, I_MUTEX_PARENT2);
  	return NULL;
  }
 -EXPORT_SYMBOL(lock_rename);
  
  void unlock_rename(struct dentry *p1, struct dentry *p2)
  {
@@@ -3110,9 -3141,9 +3128,15 @@@ retry_lookup
  		 * dropping this one anyway.
  		 */
  	}
++<<<<<<< HEAD
 +	mutex_lock(&dir->d_inode->i_mutex);
 +	error = lookup_open(nd, path, file, op, got_write, opened);
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_lock(dir->d_inode);
+ 	error = lookup_open(nd, &path, file, op, got_write, opened);
+ 	inode_unlock(dir->d_inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if (error <= 0) {
  		if (error)
@@@ -3416,8 -3488,9 +3440,14 @@@ static struct dentry *filename_create(i
  	/*
  	 * Do the final lookup.
  	 */
++<<<<<<< HEAD
 +	mutex_lock_nested(&nd.path.dentry->d_inode->i_mutex, I_MUTEX_PARENT);
 +	dentry = lookup_hash_locked(&nd);
++=======
+ 	lookup_flags |= LOOKUP_CREATE | LOOKUP_EXCL;
+ 	inode_lock_nested(path->dentry->d_inode, I_MUTEX_PARENT);
+ 	dentry = __lookup_hash(&last, path->dentry, lookup_flags);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (IS_ERR(dentry))
  		goto unlock;
  
@@@ -3445,11 -3518,12 +3475,15 @@@ fail
  	dput(dentry);
  	dentry = ERR_PTR(error);
  unlock:
++<<<<<<< HEAD
 +	mutex_unlock(&nd.path.dentry->d_inode->i_mutex);
++=======
+ 	inode_unlock(path->dentry->d_inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (!err2)
 -		mnt_drop_write(path->mnt);
 +		mnt_drop_write(nd.path.mnt);
  out:
 -	path_put(path);
 -	putname(name);
 +	path_put(&nd.path);
  	return dentry;
  }
  
@@@ -3670,10 -3735,10 +3704,10 @@@ int vfs_rmdir(struct inode *dir, struc
  		return -EPERM;
  
  	dget(dentry);
- 	mutex_lock(&dentry->d_inode->i_mutex);
+ 	inode_lock(dentry->d_inode);
  
  	error = -EBUSY;
 -	if (is_local_mountpoint(dentry))
 +	if (d_mountpoint(dentry))
  		goto out;
  
  	error = security_inode_rmdir(dir, dentry);
@@@ -3687,9 -3752,10 +3721,9 @@@
  
  	dentry->d_inode->i_flags |= S_DEAD;
  	dont_mount(dentry);
 -	detach_mounts(dentry);
  
  out:
- 	mutex_unlock(&dentry->d_inode->i_mutex);
+ 	inode_unlock(dentry->d_inode);
  	dput(dentry);
  	if (!error)
  		d_delete(dentry);
@@@ -3725,8 -3794,8 +3759,13 @@@ retry
  	if (error)
  		goto exit1;
  
++<<<<<<< HEAD
 +	mutex_lock_nested(&nd.path.dentry->d_inode->i_mutex, I_MUTEX_PARENT);
 +	dentry = lookup_hash_locked(&nd);
++=======
+ 	inode_lock_nested(path.dentry->d_inode, I_MUTEX_PARENT);
+ 	dentry = __lookup_hash(&last, path.dentry, lookup_flags);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	error = PTR_ERR(dentry);
  	if (IS_ERR(dentry))
  		goto exit2;
@@@ -3741,10 -3810,10 +3780,15 @@@
  exit3:
  	dput(dentry);
  exit2:
++<<<<<<< HEAD
 +	mutex_unlock(&nd.path.dentry->d_inode->i_mutex);
 +	mnt_drop_write(nd.path.mnt);
++=======
+ 	inode_unlock(path.dentry->d_inode);
+ 	mnt_drop_write(path.mnt);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  exit1:
 -	path_put(&path);
 +	path_put(&nd.path);
  	putname(name);
  	if (retry_estale(error, lookup_flags)) {
  		lookup_flags |= LOOKUP_REVAL;
@@@ -3787,8 -3856,8 +3831,13 @@@ int vfs_unlink(struct inode *dir, struc
  	if (!dir->i_op->unlink)
  		return -EPERM;
  
++<<<<<<< HEAD
 +	mutex_lock(&target->i_mutex);
 +	if (d_mountpoint(dentry))
++=======
+ 	inode_lock(target);
+ 	if (is_local_mountpoint(dentry))
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		error = -EBUSY;
  	else {
  		error = security_inode_unlink(dir, dentry);
@@@ -3842,8 -3916,8 +3891,13 @@@ retry
  	if (error)
  		goto exit1;
  retry_deleg:
++<<<<<<< HEAD
 +	mutex_lock_nested(&nd.path.dentry->d_inode->i_mutex, I_MUTEX_PARENT);
 +	dentry = lookup_hash_locked(&nd);
++=======
+ 	inode_lock_nested(path.dentry->d_inode, I_MUTEX_PARENT);
+ 	dentry = __lookup_hash(&last, path.dentry, lookup_flags);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	error = PTR_ERR(dentry);
  	if (!IS_ERR(dentry)) {
  		/* Why not before? Because we want correct error value */
@@@ -3860,7 -3934,7 +3914,11 @@@
  exit2:
  		dput(dentry);
  	}
++<<<<<<< HEAD
 +	mutex_unlock(&nd.path.dentry->d_inode->i_mutex);
++=======
+ 	inode_unlock(path.dentry->d_inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (inode)
  		iput(inode);	/* truncate the inode here */
  	inode = NULL;
@@@ -4233,10 -4303,10 +4291,10 @@@ int vfs_rename(struct inode *old_dir, s
  	if (!is_dir || (flags & RENAME_EXCHANGE))
  		lock_two_nondirectories(source, target);
  	else if (target)
- 		mutex_lock(&target->i_mutex);
+ 		inode_lock(target);
  
  	error = -EBUSY;
 -	if (is_local_mountpoint(old_dentry) || is_local_mountpoint(new_dentry))
 +	if (d_mountpoint(old_dentry) || d_mountpoint(new_dentry))
  		goto out;
  
  	if (max_links && new_dir != old_dir) {
diff --cc fs/nfs/direct.c
index 07e5f6823c61,7a0cfd3266e5..000000000000
--- a/fs/nfs/direct.c
+++ b/fs/nfs/direct.c
@@@ -670,10 -605,10 +670,10 @@@ ssize_t nfs_file_direct_read(struct kio
  	if (!is_sync_kiocb(iocb))
  		dreq->iocb = iocb;
  
 -	NFS_I(inode)->read_io += count;
 -	result = nfs_direct_read_schedule_iovec(dreq, iter, pos);
 +	NFS_I(inode)->read_io += iov_length(iov, nr_segs);
 +	result = nfs_direct_read_schedule_iovec(dreq, iov, nr_segs, pos, uio);
  
- 	mutex_unlock(&inode->i_mutex);
+ 	inode_unlock(inode);
  
  	if (!result) {
  		result = nfs_direct_wait(dreq);
@@@ -1108,29 -994,18 +1108,29 @@@ ssize_t nfs_file_direct_write(struct ki
  	struct inode *inode = mapping->host;
  	struct nfs_direct_req *dreq;
  	struct nfs_lock_context *l_ctx;
 -	loff_t pos, end;
 +	loff_t end;
 +	size_t count;
 +
 +	count = iov_length(iov, nr_segs);
 +	end = (pos + count - 1) >> PAGE_CACHE_SHIFT;
 +
 +	nfs_add_stats(mapping->host, NFSIOS_DIRECTWRITTENBYTES, count);
  
  	dfprintk(FILE, "NFS: direct write(%pD2, %zd@%Ld)\n",
 -		file, iov_iter_count(iter), (long long) iocb->ki_pos);
 +		file, count, (long long) pos);
  
 -	nfs_add_stats(mapping->host, NFSIOS_DIRECTWRITTENBYTES,
 -		      iov_iter_count(iter));
 +	result = generic_write_checks(file, &pos, &count, 0);
 +	if (result)
 +		goto out;
  
 -	pos = iocb->ki_pos;
 -	end = (pos + iov_iter_count(iter) - 1) >> PAGE_CACHE_SHIFT;
 +	result = -EINVAL;
 +	if ((ssize_t) count < 0)
 +		goto out;
 +	result = 0;
 +	if (!count)
 +		goto out;
  
- 	mutex_lock(&inode->i_mutex);
+ 	inode_lock(inode);
  
  	result = nfs_sync_mapping(mapping);
  	if (result)
@@@ -1191,8 -1066,7 +1191,12 @@@
  out_release:
  	nfs_direct_req_release(dreq);
  out_unlock:
++<<<<<<< HEAD
 +	mutex_unlock(&inode->i_mutex);
 +out:
++=======
+ 	inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return result;
  }
  
diff --cc fs/nfsd/nfs4recover.c
index cdb8e1753ca6,dc8ebecf5618..000000000000
--- a/fs/nfsd/nfs4recover.c
+++ b/fs/nfsd/nfs4recover.c
@@@ -192,7 -192,7 +192,11 @@@ nfsd4_create_clid_dir(struct nfs4_clien
  
  	dir = nn->rec_file->f_path.dentry;
  	/* lock the parent */
++<<<<<<< HEAD
 +	mutex_lock(&dir->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	dentry = lookup_one_len(dname, dir, HEXDIR_LEN-1);
  	if (IS_ERR(dentry)) {
@@@ -213,7 -213,7 +217,11 @@@
  out_put:
  	dput(dentry);
  out_unlock:
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (status == 0) {
  		if (nn->in_grace) {
  			crp = nfs4_client_to_reclaim(dname, nn);
@@@ -276,9 -285,10 +284,16 @@@ nfsd4_list_rec_dir(recdir_func *f, stru
  		return status;
  	}
  
++<<<<<<< HEAD
 +	status = vfs_readdir(nn->rec_file, nfsd4_build_namelist, &names);
 +	mutex_lock_nested(&dir->d_inode->i_mutex, I_MUTEX_PARENT);
 +	list_for_each_entry_safe(entry, tmp, &names, list) {
++=======
+ 	status = iterate_dir(nn->rec_file, &ctx.ctx);
+ 	inode_lock_nested(d_inode(dir), I_MUTEX_PARENT);
+ 
+ 	list_for_each_entry_safe(entry, tmp, &ctx.names, list) {
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		if (!status) {
  			struct dentry *dentry;
  			dentry = lookup_one_len(entry->name, dir, HEXDIR_LEN-1);
@@@ -292,10 -302,10 +307,14 @@@
  		list_del(&entry->list);
  		kfree(entry);
  	}
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	nfs4_reset_creds(original_cred);
  
 -	list_for_each_entry_safe(entry, tmp, &ctx.names, list) {
 +	list_for_each_entry_safe(entry, tmp, &names, list) {
  		dprintk("NFSD: %s. Left entry %s\n", __func__, entry->name);
  		list_del(&entry->list);
  		kfree(entry);
@@@ -312,7 -322,7 +331,11 @@@ nfsd4_unlink_clid_dir(char *name, int n
  	dprintk("NFSD: nfsd4_unlink_clid_dir. name %.*s\n", namlen, name);
  
  	dir = nn->rec_file->f_path.dentry;
++<<<<<<< HEAD
 +	mutex_lock_nested(&dir->d_inode->i_mutex, I_MUTEX_PARENT);
++=======
+ 	inode_lock_nested(d_inode(dir), I_MUTEX_PARENT);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dentry = lookup_one_len(name, dir, namlen);
  	if (IS_ERR(dentry)) {
  		status = PTR_ERR(dentry);
@@@ -325,7 -335,7 +348,11 @@@
  out:
  	dput(dentry);
  out_unlock:
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return status;
  }
  
diff --cc fs/nfsd/nfsfh.h
index be650f8686be,f84fe6bf9aee..000000000000
--- a/fs/nfsd/nfsfh.h
+++ b/fs/nfsd/nfsfh.h
@@@ -287,8 -287,8 +287,13 @@@ fh_lock_nested(struct svc_fh *fhp, unsi
  		return;
  	}
  
++<<<<<<< HEAD
 +	inode = dentry->d_inode;
 +	mutex_lock_nested(&inode->i_mutex, subclass);
++=======
+ 	inode = d_inode(dentry);
+ 	inode_lock_nested(inode, subclass);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	fill_pre_wcc(fhp);
  	fhp->fh_locked = true;
  }
@@@ -307,7 -307,7 +312,11 @@@ fh_unlock(struct svc_fh *fhp
  {
  	if (fhp->fh_locked) {
  		fill_post_wcc(fhp);
++<<<<<<< HEAD
 +		mutex_unlock(&fhp->fh_dentry->d_inode->i_mutex);
++=======
+ 		inode_unlock(d_inode(fhp->fh_dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		fhp->fh_locked = false;
  	}
  }
diff --cc fs/nfsd/vfs.c
index c439a9b86cda,5d2a57e4c03a..000000000000
--- a/fs/nfsd/vfs.c
+++ b/fs/nfsd/vfs.c
@@@ -644,9 -493,9 +644,15 @@@ __be32 nfsd4_set_nfs4_label(struct svc_
  
  	dentry = fhp->fh_dentry;
  
++<<<<<<< HEAD
 +	mutex_lock(&dentry->d_inode->i_mutex);
 +	host_error = security_inode_setsecctx(dentry, label->data, label->len);
 +	mutex_unlock(&dentry->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(dentry));
+ 	host_error = security_inode_setsecctx(dentry, label->data, label->len);
+ 	inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return nfserrno(host_error);
  }
  #else
diff --cc fs/ntfs/file.c
index 81adff3fd865,bed4d427dfae..000000000000
--- a/fs/ntfs/file.c
+++ b/fs/ntfs/file.c
@@@ -2079,41 -1929,35 +2079,55 @@@ err_out
  }
  
  /**
 - * ntfs_file_write_iter - simple wrapper for ntfs_file_write_iter_nolock()
 - * @iocb:	IO state structure
 - * @from:	iov_iter with data to write
 - *
 - * Basically the same as generic_file_write_iter() except that it ends up
 - * up calling ntfs_perform_write() instead of generic_perform_write() and that
 - * O_DIRECT is not implemented.
 + * ntfs_file_aio_write_nolock -
   */
 -static ssize_t ntfs_file_write_iter(struct kiocb *iocb, struct iov_iter *from)
 +static ssize_t ntfs_file_aio_write_nolock(struct kiocb *iocb,
 +		const struct iovec *iov, unsigned long nr_segs, loff_t *ppos)
  {
  	struct file *file = iocb->ki_filp;
 -	struct inode *vi = file_inode(file);
 -	ssize_t written = 0;
 -	ssize_t err;
 +	struct address_space *mapping = file->f_mapping;
 +	struct inode *inode = mapping->host;
 +	loff_t pos;
 +	size_t count;		/* after file limit checks */
 +	ssize_t written, err;
  
++<<<<<<< HEAD
 +	count = 0;
 +	err = generic_segment_checks(iov, &nr_segs, &count, VERIFY_READ);
 +	if (err)
 +		return err;
 +	pos = *ppos;
++=======
+ 	inode_lock(vi);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	/* We can write back this queue in page reclaim. */
 -	current->backing_dev_info = inode_to_bdi(vi);
 -	err = ntfs_prepare_file_for_write(iocb, from);
 -	if (iov_iter_count(from) && !err)
 -		written = ntfs_perform_write(file, from, iocb->ki_pos);
 +	current->backing_dev_info = mapping->backing_dev_info;
 +	written = 0;
 +	err = generic_write_checks(file, &pos, &count, S_ISBLK(inode->i_mode));
 +	if (err)
 +		goto out;
 +	if (!count)
 +		goto out;
 +	err = file_remove_privs(file);
 +	if (err)
 +		goto out;
 +	err = file_update_time(file);
 +	if (err)
 +		goto out;
 +	written = ntfs_file_buffered_write(iocb, iov, nr_segs, pos, ppos,
 +			count);
 +out:
  	current->backing_dev_info = NULL;
++<<<<<<< HEAD
++=======
+ 	inode_unlock(vi);
+ 	if (likely(written > 0)) {
+ 		err = generic_write_sync(file, iocb->ki_pos, written);
+ 		if (err < 0)
+ 			written = 0;
+ 	}
+ 	iocb->ki_pos += written;
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return written ? written : err;
  }
  
diff --cc fs/ocfs2/alloc.c
index b8a9d87231b1,d002579c6f2b..000000000000
--- a/fs/ocfs2/alloc.c
+++ b/fs/ocfs2/alloc.c
@@@ -5674,10 -5716,10 +5674,10 @@@ int ocfs2_remove_btree_range(struct ino
  						 extra_blocks);
  	if (ret) {
  		mlog_errno(ret);
 -		goto bail;
 +		return ret;
  	}
  
- 	mutex_lock(&tl_inode->i_mutex);
+ 	inode_lock(tl_inode);
  
  	if (ocfs2_truncate_log_needs_flush(osb)) {
  		ret = __ocfs2_flush_truncate_log(osb);
@@@ -5733,8 -5776,8 +5733,13 @@@
  out_commit:
  	ocfs2_commit_trans(osb, handle);
  out:
++<<<<<<< HEAD
 +	mutex_unlock(&tl_inode->i_mutex);
 +
++=======
+ 	inode_unlock(tl_inode);
+ bail:
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (meta_ac)
  		ocfs2_free_alloc_context(meta_ac);
  
diff --cc fs/ocfs2/file.c
index 2bcf1677a59b,7cb38fdca229..000000000000
--- a/fs/ocfs2/file.c
+++ b/fs/ocfs2/file.c
@@@ -2243,26 -2291,17 +2243,26 @@@ static ssize_t ocfs2_file_aio_write(str
  		(unsigned long long)OCFS2_I(inode)->ip_blkno,
  		file->f_path.dentry->d_name.len,
  		file->f_path.dentry->d_name.name,
 -		(unsigned int)from->nr_segs);	/* GRRRRR */
 +		(unsigned int)nr_segs);
  
 -	if (count == 0)
 +	if (iocb->ki_left == 0)
  		return 0;
  
 -	appending = iocb->ki_flags & IOCB_APPEND ? 1 : 0;
 -	direct_io = iocb->ki_flags & IOCB_DIRECT ? 1 : 0;
 +	appending = file->f_flags & O_APPEND ? 1 : 0;
 +	direct_io = file->f_flags & O_DIRECT ? 1 : 0;
  
- 	mutex_lock(&inode->i_mutex);
+ 	inode_lock(inode);
  
 +	ocfs2_iocb_clear_sem_locked(iocb);
 +
  relock:
 +	/* to match setattr's i_mutex -> rw_lock ordering */
 +	if (direct_io) {
 +		have_alloc_sem = 1;
 +		/* communicate with ocfs2_dio_end_io */
 +		ocfs2_iocb_set_sem_locked(iocb);
 +	}
 +
  	/*
  	 * Concurrent O_DIRECT writes are allowed with
  	 * mount_option "coherency=buffered".
@@@ -2416,11 -2434,8 +2416,16 @@@ out
  	if (rw_level != -1)
  		ocfs2_rw_unlock(inode, rw_level);
  
++<<<<<<< HEAD
 +out_sems:
 +	if (have_alloc_sem)
 +		ocfs2_iocb_clear_sem_locked(iocb);
 +
 +	mutex_unlock(&inode->i_mutex);
++=======
+ out_mutex:
+ 	inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if (written)
  		ret = written;
diff --cc fs/ocfs2/journal.c
index 8eccfabcd12e,61b833b721d8..000000000000
--- a/fs/ocfs2/journal.c
+++ b/fs/ocfs2/journal.c
@@@ -2095,21 -2193,61 +2095,75 @@@ static int ocfs2_recover_orphans(struc
  					(unsigned long long)oi->ip_blkno);
  
  		iter = oi->ip_next_orphan;
 -		oi->ip_next_orphan = NULL;
  
++<<<<<<< HEAD
 +		spin_lock(&oi->ip_lock);
 +		/* The remote delete code may have set these on the
 +		 * assumption that the other node would wipe them
 +		 * successfully.  If they are still in the node's
 +		 * orphan dir, we need to reset that state. */
 +		oi->ip_flags &= ~(OCFS2_INODE_DELETED|OCFS2_INODE_SKIP_DELETE);
 +
 +		/* Set the proper information to get us going into
 +		 * ocfs2_delete_inode. */
 +		oi->ip_flags |= OCFS2_INODE_MAYBE_ORPHANED;
 +		spin_unlock(&oi->ip_lock);
++=======
+ 		if (oi->ip_flags & OCFS2_INODE_DIO_ORPHAN_ENTRY) {
+ 			inode_lock(inode);
+ 			ret = ocfs2_rw_lock(inode, 1);
+ 			if (ret < 0) {
+ 				mlog_errno(ret);
+ 				goto unlock_mutex;
+ 			}
+ 			/*
+ 			 * We need to take and drop the inode lock to
+ 			 * force read inode from disk.
+ 			 */
+ 			ret = ocfs2_inode_lock(inode, &di_bh, 1);
+ 			if (ret) {
+ 				mlog_errno(ret);
+ 				goto unlock_rw;
+ 			}
+ 
+ 			di = (struct ocfs2_dinode *)di_bh->b_data;
+ 
+ 			if (di->i_flags & cpu_to_le32(OCFS2_DIO_ORPHANED_FL)) {
+ 				ret = ocfs2_truncate_file(inode, di_bh,
+ 						i_size_read(inode));
+ 				if (ret < 0) {
+ 					if (ret != -ENOSPC)
+ 						mlog_errno(ret);
+ 					goto unlock_inode;
+ 				}
+ 
+ 				ret = ocfs2_del_inode_from_orphan(osb, inode,
+ 						di_bh, 0, 0);
+ 				if (ret)
+ 					mlog_errno(ret);
+ 			}
+ unlock_inode:
+ 			ocfs2_inode_unlock(inode, 1);
+ 			brelse(di_bh);
+ 			di_bh = NULL;
+ unlock_rw:
+ 			ocfs2_rw_unlock(inode, 1);
+ unlock_mutex:
+ 			inode_unlock(inode);
+ 
+ 			/* clear dio flag in ocfs2_inode_info */
+ 			oi->ip_flags &= ~OCFS2_INODE_DIO_ORPHAN_ENTRY;
+ 		} else {
+ 			spin_lock(&oi->ip_lock);
+ 			/* Set the proper information to get us going into
+ 			 * ocfs2_delete_inode. */
+ 			oi->ip_flags |= OCFS2_INODE_MAYBE_ORPHANED;
+ 			spin_unlock(&oi->ip_lock);
+ 		}
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  		iput(inode);
 +
  		inode = iter;
  	}
  
diff --cc fs/ocfs2/namei.c
index b4a5cdf9dbc5,6b3e87189a64..000000000000
--- a/fs/ocfs2/namei.c
+++ b/fs/ocfs2/namei.c
@@@ -2339,6 -2626,158 +2339,161 @@@ leave
  	return status;
  }
  
++<<<<<<< HEAD
++=======
+ int ocfs2_add_inode_to_orphan(struct ocfs2_super *osb,
+ 	struct inode *inode)
+ {
+ 	char orphan_name[OCFS2_DIO_ORPHAN_PREFIX_LEN + OCFS2_ORPHAN_NAMELEN + 1];
+ 	struct inode *orphan_dir_inode = NULL;
+ 	struct ocfs2_dir_lookup_result orphan_insert = { NULL, };
+ 	struct buffer_head *di_bh = NULL;
+ 	int status = 0;
+ 	handle_t *handle = NULL;
+ 	struct ocfs2_dinode *di = NULL;
+ 
+ 	status = ocfs2_inode_lock(inode, &di_bh, 1);
+ 	if (status < 0) {
+ 		mlog_errno(status);
+ 		goto bail;
+ 	}
+ 
+ 	di = (struct ocfs2_dinode *) di_bh->b_data;
+ 	/*
+ 	 * Another append dio crashed?
+ 	 * If so, manually recover it first.
+ 	 */
+ 	if (unlikely(di->i_flags & cpu_to_le32(OCFS2_DIO_ORPHANED_FL))) {
+ 		status = ocfs2_truncate_file(inode, di_bh, i_size_read(inode));
+ 		if (status < 0) {
+ 			if (status != -ENOSPC)
+ 				mlog_errno(status);
+ 			goto bail_unlock_inode;
+ 		}
+ 
+ 		status = ocfs2_del_inode_from_orphan(osb, inode, di_bh, 0, 0);
+ 		if (status < 0) {
+ 			mlog_errno(status);
+ 			goto bail_unlock_inode;
+ 		}
+ 	}
+ 
+ 	status = ocfs2_prepare_orphan_dir(osb, &orphan_dir_inode,
+ 			OCFS2_I(inode)->ip_blkno,
+ 			orphan_name,
+ 			&orphan_insert,
+ 			true);
+ 	if (status < 0) {
+ 		mlog_errno(status);
+ 		goto bail_unlock_inode;
+ 	}
+ 
+ 	handle = ocfs2_start_trans(osb,
+ 			OCFS2_INODE_ADD_TO_ORPHAN_CREDITS);
+ 	if (IS_ERR(handle)) {
+ 		status = PTR_ERR(handle);
+ 		goto bail_unlock_orphan;
+ 	}
+ 
+ 	status = ocfs2_orphan_add(osb, handle, inode, di_bh, orphan_name,
+ 			&orphan_insert, orphan_dir_inode, true);
+ 	if (status)
+ 		mlog_errno(status);
+ 
+ 	ocfs2_commit_trans(osb, handle);
+ 
+ bail_unlock_orphan:
+ 	ocfs2_inode_unlock(orphan_dir_inode, 1);
+ 	inode_unlock(orphan_dir_inode);
+ 	iput(orphan_dir_inode);
+ 
+ 	ocfs2_free_dir_lookup_result(&orphan_insert);
+ 
+ bail_unlock_inode:
+ 	ocfs2_inode_unlock(inode, 1);
+ 	brelse(di_bh);
+ 
+ bail:
+ 	return status;
+ }
+ 
+ int ocfs2_del_inode_from_orphan(struct ocfs2_super *osb,
+ 		struct inode *inode, struct buffer_head *di_bh,
+ 		int update_isize, loff_t end)
+ {
+ 	struct inode *orphan_dir_inode = NULL;
+ 	struct buffer_head *orphan_dir_bh = NULL;
+ 	struct ocfs2_dinode *di = (struct ocfs2_dinode *)di_bh->b_data;
+ 	handle_t *handle = NULL;
+ 	int status = 0;
+ 
+ 	orphan_dir_inode = ocfs2_get_system_file_inode(osb,
+ 			ORPHAN_DIR_SYSTEM_INODE,
+ 			le16_to_cpu(di->i_dio_orphaned_slot));
+ 	if (!orphan_dir_inode) {
+ 		status = -ENOENT;
+ 		mlog_errno(status);
+ 		goto bail;
+ 	}
+ 
+ 	inode_lock(orphan_dir_inode);
+ 	status = ocfs2_inode_lock(orphan_dir_inode, &orphan_dir_bh, 1);
+ 	if (status < 0) {
+ 		inode_unlock(orphan_dir_inode);
+ 		iput(orphan_dir_inode);
+ 		mlog_errno(status);
+ 		goto bail;
+ 	}
+ 
+ 	handle = ocfs2_start_trans(osb,
+ 			OCFS2_INODE_DEL_FROM_ORPHAN_CREDITS);
+ 	if (IS_ERR(handle)) {
+ 		status = PTR_ERR(handle);
+ 		goto bail_unlock_orphan;
+ 	}
+ 
+ 	BUG_ON(!(di->i_flags & cpu_to_le32(OCFS2_DIO_ORPHANED_FL)));
+ 
+ 	status = ocfs2_orphan_del(osb, handle, orphan_dir_inode,
+ 				inode, orphan_dir_bh, true);
+ 	if (status < 0) {
+ 		mlog_errno(status);
+ 		goto bail_commit;
+ 	}
+ 
+ 	status = ocfs2_journal_access_di(handle,
+ 			INODE_CACHE(inode),
+ 			di_bh,
+ 			OCFS2_JOURNAL_ACCESS_WRITE);
+ 	if (status < 0) {
+ 		mlog_errno(status);
+ 		goto bail_commit;
+ 	}
+ 
+ 	di->i_flags &= ~cpu_to_le32(OCFS2_DIO_ORPHANED_FL);
+ 	di->i_dio_orphaned_slot = 0;
+ 
+ 	if (update_isize) {
+ 		status = ocfs2_set_inode_size(handle, inode, di_bh, end);
+ 		if (status)
+ 			mlog_errno(status);
+ 	} else
+ 		ocfs2_journal_dirty(handle, di_bh);
+ 
+ bail_commit:
+ 	ocfs2_commit_trans(osb, handle);
+ 
+ bail_unlock_orphan:
+ 	ocfs2_inode_unlock(orphan_dir_inode, 1);
+ 	inode_unlock(orphan_dir_inode);
+ 	brelse(orphan_dir_bh);
+ 	iput(orphan_dir_inode);
+ 
+ bail:
+ 	return status;
+ }
+ 
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  int ocfs2_mv_orphaned_inode_to_new(struct inode *dir,
  				   struct inode *inode,
  				   struct dentry *dentry)
diff --cc fs/ocfs2/refcounttree.c
index 998b17eda09d,3eff031aaf26..000000000000
--- a/fs/ocfs2/refcounttree.c
+++ b/fs/ocfs2/refcounttree.c
@@@ -4424,10 -4402,11 +4424,18 @@@ static int ocfs2_vfs_reflink(struct den
  			return error;
  	}
  
++<<<<<<< HEAD
 +	mutex_lock(&inode->i_mutex);
 +	dquot_initialize(dir);
 +	error = ocfs2_reflink(old_dentry, dir, new_dentry, preserve);
 +	mutex_unlock(&inode->i_mutex);
++=======
+ 	inode_lock(inode);
+ 	error = dquot_initialize(dir);
+ 	if (!error)
+ 		error = ocfs2_reflink(old_dentry, dir, new_dentry, preserve);
+ 	inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (!error)
  		fsnotify_create(dir, new_dentry);
  	return error;
diff --cc fs/ocfs2/suballoc.c
index b7e74b580c0f,2f19aeec5482..000000000000
--- a/fs/ocfs2/suballoc.c
+++ b/fs/ocfs2/suballoc.c
@@@ -2881,10 -2875,11 +2881,15 @@@ int ocfs2_test_inode_bit(struct ocfs2_s
  		goto bail;
  	}
  
- 	mutex_lock(&inode_alloc_inode->i_mutex);
+ 	inode_lock(inode_alloc_inode);
  	status = ocfs2_inode_lock(inode_alloc_inode, &alloc_bh, 0);
  	if (status < 0) {
++<<<<<<< HEAD
 +		mutex_unlock(&inode_alloc_inode->i_mutex);
++=======
+ 		inode_unlock(inode_alloc_inode);
+ 		iput(inode_alloc_inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		mlog(ML_ERROR, "lock on alloc inode on slot %u failed %d\n",
  		     (u32)suballoc_slot, status);
  		goto bail;
diff --cc fs/overlayfs/dir.c
index 6bbc598eb773,ed95272d57a6..000000000000
--- a/fs/overlayfs/dir.c
+++ b/fs/overlayfs/dir.c
@@@ -191,10 -167,7 +191,14 @@@ static int ovl_create_upper(struct dent
  	struct dentry *newdentry;
  	int err;
  
++<<<<<<< HEAD
 +	if (!hardlink && !IS_POSIXACL(udir))
 +		stat->mode &= ~current_umask();
 +
 +	mutex_lock_nested(&udir->i_mutex, I_MUTEX_PARENT);
++=======
+ 	inode_lock_nested(udir, I_MUTEX_PARENT);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	newdentry = lookup_one_len(dentry->d_name.name, upperdir,
  				   dentry->d_name.len);
  	err = PTR_ERR(newdentry);
@@@ -717,18 -596,14 +721,22 @@@ static int ovl_remove_upper(struct dent
  {
  	struct dentry *upperdir = ovl_dentry_upper(dentry->d_parent);
  	struct inode *dir = upperdir->d_inode;
 -	struct dentry *upper = ovl_dentry_upper(dentry);
 +	struct dentry *upper;
  	int err;
  
++<<<<<<< HEAD
 +	mutex_lock_nested(&dir->i_mutex, I_MUTEX_PARENT);
 +	upper = lookup_one_len(dentry->d_name.name, upperdir,
 +			       dentry->d_name.len);
 +	err = PTR_ERR(upper);
 +	if (IS_ERR(upper))
 +		goto out_unlock;
 +
++=======
+ 	inode_lock_nested(dir, I_MUTEX_PARENT);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	err = -ESTALE;
 -	if (upper->d_parent == upperdir) {
 -		/* Don't let d_delete() think it can reset d_inode */
 -		dget(upper);
 +	if (upper == ovl_dentry_upper(dentry)) {
  		if (is_dir)
  			err = vfs_rmdir(dir, upper);
  		else
@@@ -743,10 -618,8 +751,15 @@@
  	 * sole user of this dentry.  Too tricky...  Just unhash for
  	 * now.
  	 */
++<<<<<<< HEAD
 +	if (!err)
 +		d_drop(dentry);
 +out_unlock:
 +	mutex_unlock(&dir->i_mutex);
++=======
+ 	d_drop(dentry);
+ 	inode_unlock(dir);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	return err;
  }
diff --cc fs/overlayfs/inode.c
index eb18c6cf9cfd,49e204560655..000000000000
--- a/fs/overlayfs/inode.c
+++ b/fs/overlayfs/inode.c
@@@ -64,42 -59,14 +64,48 @@@ int ovl_setattr(struct dentry *dentry, 
  	if (err)
  		goto out;
  
 +	if (attr->ia_valid & ATTR_SIZE) {
 +		struct inode *realinode = d_inode(ovl_dentry_real(dentry));
 +
 +		err = -ETXTBSY;
 +		if (atomic_read(&realinode->i_writecount) < 0)
 +			goto out_drop_write;
 +	}
 +
  	err = ovl_copy_up(dentry);
  	if (!err) {
 +		struct inode *winode = NULL;
 +
  		upperdentry = ovl_dentry_upper(dentry);
  
++<<<<<<< HEAD
 +		if (attr->ia_valid & ATTR_SIZE) {
 +			winode = d_inode(upperdentry);
 +			err = get_write_access(winode);
 +			if (err)
 +				goto out_drop_write;
 +		}
 +
 +		if (attr->ia_valid & (ATTR_KILL_SUID|ATTR_KILL_SGID))
 +			attr->ia_valid &= ~ATTR_MODE;
 +
 +		mutex_lock(&upperdentry->d_inode->i_mutex);
 +		old_cred = ovl_override_creds(dentry->d_sb);
 +		err = notify_change(upperdentry, attr, NULL);
 +		revert_creds(old_cred);
 +		if (!err)
 +			ovl_copyattr(upperdentry->d_inode, dentry->d_inode);
 +		mutex_unlock(&upperdentry->d_inode->i_mutex);
 +
 +		if (winode)
 +			put_write_access(winode);
++=======
+ 		inode_lock(upperdentry->d_inode);
+ 		err = notify_change(upperdentry, attr, NULL);
+ 		inode_unlock(upperdentry->d_inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	}
 +out_drop_write:
  	ovl_drop_write(dentry);
  out:
  	return err;
diff --cc fs/overlayfs/super.c
index c3d8b1ec4002,8d826bd56b26..000000000000
--- a/fs/overlayfs/super.c
+++ b/fs/overlayfs/super.c
@@@ -220,8 -229,9 +220,8 @@@ void ovl_dentry_update(struct dentry *d
  {
  	struct ovl_entry *oe = dentry->d_fsdata;
  
- 	WARN_ON(!mutex_is_locked(&upperdentry->d_parent->d_inode->i_mutex));
+ 	WARN_ON(!inode_is_locked(upperdentry->d_parent->d_inode));
  	WARN_ON(oe->__upperdentry);
 -	BUG_ON(!upperdentry->d_inode);
  	/*
  	 * Make sure upperdentry is consistent before making it visible to
  	 * ovl_upperdentry_dereference().
@@@ -427,16 -370,14 +427,22 @@@ static bool ovl_dentry_weird(struct den
  				  DCACHE_OP_COMPARE);
  }
  
 -static inline struct dentry *ovl_lookup_real(struct dentry *dir,
 -					     struct qstr *name)
 +static inline struct dentry *ovl_lookup_real(struct super_block *ovl_sb,
 +					     struct dentry *dir,
 +					     const struct qstr *name)
  {
 +	const struct cred *old_cred;
  	struct dentry *dentry;
  
++<<<<<<< HEAD
 +	old_cred = ovl_override_creds(ovl_sb);
 +	dentry = lookup_one_len_unlocked(name->name, dir, name->len);
 +	revert_creds(old_cred);
++=======
+ 	inode_lock(dir->d_inode);
+ 	dentry = lookup_one_len(name->name, dir, name->len);
+ 	inode_unlock(dir->d_inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if (IS_ERR(dentry)) {
  		if (PTR_ERR(dentry) == -ENOENT)
@@@ -841,37 -768,9 +847,37 @@@ retry
  		err = ovl_create_real(dir, work, &stat, NULL, NULL, true);
  		if (err)
  			goto out_dput;
 +
 +		/*
 +		 * Try to remove POSIX ACL xattrs from workdir.  We are good if:
 +		 *
 +		 * a) success (there was a POSIX ACL xattr and was removed)
 +		 * b) -ENODATA (there was no POSIX ACL xattr)
 +		 * c) -EOPNOTSUPP (POSIX ACL xattrs are not supported)
 +		 *
 +		 * There are various other error values that could effectively
 +		 * mean that the xattr doesn't exist (e.g. -ERANGE is returned
 +		 * if the xattr name is too long), but the set of filesystems
 +		 * allowed as upper are limited to "normal" ones, where checking
 +		 * for the above two errors is sufficient.
 +		 */
 +		err = vfs_removexattr(work, XATTR_NAME_POSIX_ACL_DEFAULT);
 +		if (err && err != -ENODATA && err != -EOPNOTSUPP)
 +			goto out_dput;
 +
 +		err = vfs_removexattr(work, XATTR_NAME_POSIX_ACL_ACCESS);
 +		if (err && err != -ENODATA && err != -EOPNOTSUPP)
 +			goto out_dput;
 +
 +		/* Clear any inherited mode bits */
 +		inode_lock(work->d_inode);
 +		err = notify_change(work, &attr, NULL);
 +		inode_unlock(work->d_inode);
 +		if (err)
 +			goto out_dput;
  	}
  out_unlock:
- 	mutex_unlock(&dir->i_mutex);
+ 	inode_unlock(dir);
  	mnt_drop_write(mnt);
  
  	return work;
diff --cc fs/pstore/inode.c
index 808c88d636e2,dc645b66cd79..000000000000
--- a/fs/pstore/inode.c
+++ b/fs/pstore/inode.c
@@@ -346,11 -377,10 +346,15 @@@ int pstore_mkfile(enum pstore_type_id t
  		break;
  	}
  
++<<<<<<< HEAD
 +	mutex_lock(&root->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
 +	rc = -ENOSPC;
  	dentry = d_alloc_name(root, name);
 -	if (!dentry)
 +	if (IS_ERR(dentry))
  		goto fail_lockedalloc;
  
  	memcpy(private->data, data, size);
@@@ -367,12 -397,12 +371,20 @@@
  	list_add(&private->list, &allpstore);
  	spin_unlock_irqrestore(&allpstore_lock, flags);
  
++<<<<<<< HEAD
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	return 0;
  
  fail_lockedalloc:
++<<<<<<< HEAD
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	kfree(private);
  fail_alloc:
  	iput(inode);
diff --cc fs/quota/dquot.c
index d7d5a0afc057,3c3b81bb6dfe..000000000000
--- a/fs/quota/dquot.c
+++ b/fs/quota/dquot.c
@@@ -2356,9 -2430,9 +2356,15 @@@ int dquot_quota_on_mount(struct super_b
  	struct dentry *dentry;
  	int error;
  
++<<<<<<< HEAD
 +	mutex_lock(&sb->s_root->d_inode->i_mutex);
 +	dentry = lookup_one_len(qf_name, sb->s_root, strlen(qf_name));
 +	mutex_unlock(&sb->s_root->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(sb->s_root));
+ 	dentry = lookup_one_len(qf_name, sb->s_root, strlen(qf_name));
+ 	inode_unlock(d_inode(sb->s_root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (IS_ERR(dentry))
  		return PTR_ERR(dentry);
  
diff --cc fs/reiserfs/ioctl.c
index 15cb5fe6b425,036a1fc0a8c3..000000000000
--- a/fs/reiserfs/ioctl.c
+++ b/fs/reiserfs/ioctl.c
@@@ -219,8 -223,8 +219,14 @@@ int reiserfs_unpack(struct inode *inode
  	unlock_page(page);
  	page_cache_release(page);
  
++<<<<<<< HEAD
 +      out:
 +	mutex_unlock(&inode->i_mutex);
 +	reiserfs_write_unlock_once(inode->i_sb, depth);
++=======
+ out:
+ 	inode_unlock(inode);
+ 	reiserfs_write_unlock(inode->i_sb);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return retval;
  }
diff --cc fs/reiserfs/xattr.c
index 821bcf70e467,57e0b2310532..000000000000
--- a/fs/reiserfs/xattr.c
+++ b/fs/reiserfs/xattr.c
@@@ -79,12 -84,12 +79,21 @@@ static int xattr_mkdir(struct inode *di
  static int xattr_unlink(struct inode *dir, struct dentry *dentry)
  {
  	int error;
++<<<<<<< HEAD
 +	BUG_ON(!mutex_is_locked(&dir->i_mutex));
 +
 +	reiserfs_mutex_lock_nested_safe(&dentry->d_inode->i_mutex,
 +					I_MUTEX_CHILD, dir->i_sb);
 +	error = dir->i_op->unlink(dir, dentry);
 +	mutex_unlock(&dentry->d_inode->i_mutex);
++=======
+ 
+ 	BUG_ON(!inode_is_locked(dir));
+ 
+ 	inode_lock_nested(d_inode(dentry), I_MUTEX_CHILD);
+ 	error = dir->i_op->unlink(dir, dentry);
+ 	inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if (!error)
  		d_delete(dentry);
@@@ -94,14 -99,14 +103,25 @@@
  static int xattr_rmdir(struct inode *dir, struct dentry *dentry)
  {
  	int error;
++<<<<<<< HEAD
 +	BUG_ON(!mutex_is_locked(&dir->i_mutex));
 +
 +	reiserfs_mutex_lock_nested_safe(&dentry->d_inode->i_mutex,
 +					I_MUTEX_CHILD, dir->i_sb);
 +	error = dir->i_op->rmdir(dir, dentry);
 +	if (!error)
 +		dentry->d_inode->i_flags |= S_DEAD;
 +	mutex_unlock(&dentry->d_inode->i_mutex);
++=======
+ 
+ 	BUG_ON(!inode_is_locked(dir));
+ 
+ 	inode_lock_nested(d_inode(dentry), I_MUTEX_CHILD);
+ 	error = dir->i_op->rmdir(dir, dentry);
+ 	if (!error)
+ 		d_inode(dentry)->i_flags |= S_DEAD;
+ 	inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (!error)
  		d_delete(dentry);
  
@@@ -114,10 -119,11 +134,14 @@@ static struct dentry *open_xa_root(stru
  {
  	struct dentry *privroot = REISERFS_SB(sb)->priv_root;
  	struct dentry *xaroot;
 -
 -	if (d_really_is_negative(privroot))
 +	if (!privroot->d_inode)
  		return ERR_PTR(-ENODATA);
  
++<<<<<<< HEAD
 +	mutex_lock_nested(&privroot->d_inode->i_mutex, I_MUTEX_XATTR);
++=======
+ 	inode_lock_nested(d_inode(privroot), I_MUTEX_XATTR);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	xaroot = dget(REISERFS_SB(sb)->xattr_root);
  	if (!xaroot)
@@@ -132,7 -139,7 +156,11 @@@
  		}
  	}
  
++<<<<<<< HEAD
 +	mutex_unlock(&privroot->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(privroot));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return xaroot;
  }
  
@@@ -149,20 -156,21 +177,28 @@@ static struct dentry *open_xa_dir(cons
  		 le32_to_cpu(INODE_PKEY(inode)->k_objectid),
  		 inode->i_generation);
  
++<<<<<<< HEAD
 +	mutex_lock_nested(&xaroot->d_inode->i_mutex, I_MUTEX_XATTR);
++=======
+ 	inode_lock_nested(d_inode(xaroot), I_MUTEX_XATTR);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	xadir = lookup_one_len(namebuf, xaroot, strlen(namebuf));
 -	if (!IS_ERR(xadir) && d_really_is_negative(xadir)) {
 +	if (!IS_ERR(xadir) && !xadir->d_inode) {
  		int err = -ENODATA;
 -
  		if (xattr_may_create(flags))
 -			err = xattr_mkdir(d_inode(xaroot), xadir, 0700);
 +			err = xattr_mkdir(xaroot->d_inode, xadir, 0700);
  		if (err) {
  			dput(xadir);
  			xadir = ERR_PTR(err);
  		}
  	}
  
++<<<<<<< HEAD
 +	mutex_unlock(&xaroot->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(xaroot));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dput(xaroot);
  	return xadir;
  }
@@@ -177,12 -188,14 +213,17 @@@ struct reiserfs_dentry_buf 
  };
  
  static int
 -fill_with_dentries(struct dir_context *ctx, const char *name, int namelen,
 -		   loff_t offset, u64 ino, unsigned int d_type)
 +fill_with_dentries(void *buf, const char *name, int namelen, loff_t offset,
 +		    u64 ino, unsigned int d_type)
  {
 -	struct reiserfs_dentry_buf *dbuf =
 -		container_of(ctx, struct reiserfs_dentry_buf, ctx);
 +	struct reiserfs_dentry_buf *dbuf = buf;
  	struct dentry *dentry;
++<<<<<<< HEAD
 +	WARN_ON_ONCE(!mutex_is_locked(&dbuf->xadir->d_inode->i_mutex));
++=======
+ 
+ 	WARN_ON_ONCE(!inode_is_locked(d_inode(dbuf->xadir)));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if (dbuf->count == ARRAY_SIZE(dbuf->dentries))
  		return -ENOSPC;
@@@ -244,34 -254,30 +285,42 @@@ static int reiserfs_for_each_xattr(stru
  		goto out_dir;
  	}
  
++<<<<<<< HEAD
 +	mutex_lock_nested(&dir->d_inode->i_mutex, I_MUTEX_XATTR);
 +
 +	reiserfs_write_lock(inode->i_sb);
++=======
+ 	inode_lock_nested(d_inode(dir), I_MUTEX_XATTR);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	buf.xadir = dir;
 -	while (1) {
 -		err = reiserfs_readdir_inode(d_inode(dir), &buf.ctx);
 -		if (err)
 -			break;
 -		if (!buf.count)
 -			break;
 -		for (i = 0; !err && i < buf.count && buf.dentries[i]; i++) {
 +	err = reiserfs_readdir_dentry(dir, &buf, fill_with_dentries, &pos);
 +	while ((err == 0 || err == -ENOSPC) && buf.count) {
 +		err = 0;
 +
 +		for (i = 0; i < buf.count && buf.dentries[i]; i++) {
 +			int lerr = 0;
  			struct dentry *dentry = buf.dentries[i];
  
 -			if (!d_is_dir(dentry))
 -				err = action(dentry, data);
 +			if (err == 0 && !S_ISDIR(dentry->d_inode->i_mode))
 +				lerr = action(dentry, data);
  
  			dput(dentry);
  			buf.dentries[i] = NULL;
 +			err = lerr ?: err;
  		}
 -		if (err)
 -			break;
  		buf.count = 0;
 +		if (!err)
 +			err = reiserfs_readdir_dentry(dir, &buf,
 +						      fill_with_dentries, &pos);
  	}
++<<<<<<< HEAD
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
 +	/* Clean up after a failed readdir */
  	cleanup_dentry_buf(&buf);
  
  	if (!err) {
@@@ -283,15 -291,20 +332,26 @@@
  		int blocks = JOURNAL_PER_BALANCE_CNT * 2 + 2 +
  			     4 * REISERFS_QUOTA_TRANS_BLOCKS(inode->i_sb);
  		struct reiserfs_transaction_handle th;
 -
 -		reiserfs_write_lock(inode->i_sb);
  		err = journal_begin(&th, inode->i_sb, blocks);
 -		reiserfs_write_unlock(inode->i_sb);
  		if (!err) {
  			int jerror;
++<<<<<<< HEAD
 +			reiserfs_mutex_lock_nested_safe(
 +					  &dir->d_parent->d_inode->i_mutex,
 +					  I_MUTEX_XATTR, inode->i_sb);
 +			err = action(dir, data);
 +			jerror = journal_end(&th, inode->i_sb, blocks);
 +			mutex_unlock(&dir->d_parent->d_inode->i_mutex);
++=======
+ 
+ 			inode_lock_nested(d_inode(dir->d_parent),
+ 					  I_MUTEX_XATTR);
+ 			err = action(dir, data);
+ 			reiserfs_write_lock(inode->i_sb);
+ 			jerror = journal_end(&th);
+ 			reiserfs_write_unlock(inode->i_sb);
+ 			inode_unlock(d_inode(dir->d_parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  			err = jerror ?: err;
  		}
  	}
@@@ -367,7 -384,7 +427,11 @@@ static struct dentry *xattr_lookup(stru
  	if (IS_ERR(xadir))
  		return ERR_CAST(xadir);
  
++<<<<<<< HEAD
 +	mutex_lock_nested(&xadir->d_inode->i_mutex, I_MUTEX_XATTR);
++=======
+ 	inode_lock_nested(d_inode(xadir), I_MUTEX_XATTR);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	xafile = lookup_one_len(name, xadir, strlen(name));
  	if (IS_ERR(xafile)) {
  		err = PTR_ERR(xafile);
@@@ -387,7 -404,7 +451,11 @@@
  	if (err)
  		dput(xafile);
  out:
++<<<<<<< HEAD
 +	mutex_unlock(&xadir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(xadir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dput(xadir);
  	if (err)
  		return ERR_PTR(err);
@@@ -449,7 -469,7 +517,11 @@@ static int lookup_and_delete_xattr(stru
  	if (IS_ERR(xadir))
  		return PTR_ERR(xadir);
  
++<<<<<<< HEAD
 +	mutex_lock_nested(&xadir->d_inode->i_mutex, I_MUTEX_XATTR);
++=======
+ 	inode_lock_nested(d_inode(xadir), I_MUTEX_XATTR);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dentry = lookup_one_len(name, xadir, strlen(name));
  	if (IS_ERR(dentry)) {
  		err = PTR_ERR(dentry);
@@@ -465,7 -483,7 +537,11 @@@
  
  	dput(dentry);
  out_dput:
++<<<<<<< HEAD
 +	mutex_unlock(&xadir->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(xadir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dput(xadir);
  	return err;
  }
@@@ -565,13 -580,11 +641,21 @@@ reiserfs_xattr_set_handle(struct reiser
  			.ia_valid = ATTR_SIZE | ATTR_CTIME,
  		};
  
++<<<<<<< HEAD
 +		reiserfs_write_unlock(inode->i_sb);
 +		mutex_lock_nested(&dentry->d_inode->i_mutex, I_MUTEX_XATTR);
 +		inode_dio_wait(dentry->d_inode);
 +		reiserfs_write_lock(inode->i_sb);
 +
 +		err = reiserfs_setattr(dentry, &newattrs);
 +		mutex_unlock(&dentry->d_inode->i_mutex);
++=======
+ 		inode_lock_nested(d_inode(dentry), I_MUTEX_XATTR);
+ 		inode_dio_wait(d_inode(dentry));
+ 
+ 		err = reiserfs_setattr(dentry, &newattrs);
+ 		inode_unlock(d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	} else
  		update_ctime(inode);
  out_unlock:
@@@ -867,9 -888,9 +951,15 @@@ ssize_t reiserfs_listxattr(struct dentr
  		goto out;
  	}
  
++<<<<<<< HEAD
 +	mutex_lock_nested(&dir->d_inode->i_mutex, I_MUTEX_XATTR);
 +	err = reiserfs_readdir_dentry(dir, &buf, listxattr_filler, &pos);
 +	mutex_unlock(&dir->d_inode->i_mutex);
++=======
+ 	inode_lock_nested(d_inode(dir), I_MUTEX_XATTR);
+ 	err = reiserfs_readdir_inode(d_inode(dir), &buf.ctx);
+ 	inode_unlock(d_inode(dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if (!err)
  		err = buf.pos;
@@@ -882,11 -903,12 +972,17 @@@ out
  static int create_privroot(struct dentry *dentry)
  {
  	int err;
++<<<<<<< HEAD
 +	struct inode *inode = dentry->d_parent->d_inode;
 +	WARN_ON_ONCE(!mutex_is_locked(&inode->i_mutex));
++=======
+ 	struct inode *inode = d_inode(dentry->d_parent);
+ 
+ 	WARN_ON_ONCE(!inode_is_locked(inode));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	err = xattr_mkdir(inode, dentry, 0700);
 -	if (err || d_really_is_negative(dentry)) {
 +	if (err || !dentry->d_inode) {
  		reiserfs_warning(dentry->d_sb, "jdm-20006",
  				 "xattrs/ACLs enabled and couldn't "
  				 "find/create .reiserfs_priv. "
@@@ -969,17 -995,17 +1065,25 @@@ int reiserfs_lookup_privroot(struct sup
  	int err = 0;
  
  	/* If we don't have the privroot located yet - go find it */
++<<<<<<< HEAD
 +	reiserfs_mutex_lock_safe(&s->s_root->d_inode->i_mutex, s);
++=======
+ 	inode_lock(d_inode(s->s_root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dentry = lookup_one_len(PRIVROOT_NAME, s->s_root,
  				strlen(PRIVROOT_NAME));
  	if (!IS_ERR(dentry)) {
  		REISERFS_SB(s)->priv_root = dentry;
  		d_set_d_op(dentry, &xattr_lookup_poison_ops);
 -		if (d_really_is_positive(dentry))
 -			d_inode(dentry)->i_flags |= S_PRIVATE;
 +		if (dentry->d_inode)
 +			dentry->d_inode->i_flags |= S_PRIVATE;
  	} else
  		err = PTR_ERR(dentry);
++<<<<<<< HEAD
 +	mutex_unlock(&s->s_root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(s->s_root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	return err;
  }
@@@ -996,17 -1024,18 +1100,28 @@@ int reiserfs_xattr_init(struct super_bl
  	if (err)
  		goto error;
  
++<<<<<<< HEAD
 +	if (!privroot->d_inode && !(mount_flags & MS_RDONLY)) {
 +		reiserfs_mutex_lock_safe(&s->s_root->d_inode->i_mutex, s);
 +		err = create_privroot(REISERFS_SB(s)->priv_root);
 +		mutex_unlock(&s->s_root->d_inode->i_mutex);
++=======
+ 	if (d_really_is_negative(privroot) && !(mount_flags & MS_RDONLY)) {
+ 		inode_lock(d_inode(s->s_root));
+ 		err = create_privroot(REISERFS_SB(s)->priv_root);
+ 		inode_unlock(d_inode(s->s_root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	}
  
 -	if (d_really_is_positive(privroot)) {
 +	if (privroot->d_inode) {
  		s->s_xattr = reiserfs_xattr_handlers;
++<<<<<<< HEAD
 +		reiserfs_mutex_lock_safe(&privroot->d_inode->i_mutex, s);
++=======
+ 		inode_lock(d_inode(privroot));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		if (!REISERFS_SB(s)->xattr_root) {
  			struct dentry *dentry;
 -
  			dentry = lookup_one_len(XAROOT_NAME, privroot,
  						strlen(XAROOT_NAME));
  			if (!IS_ERR(dentry))
@@@ -1014,7 -1043,7 +1129,11 @@@
  			else
  				err = PTR_ERR(dentry);
  		}
++<<<<<<< HEAD
 +		mutex_unlock(&privroot->d_inode->i_mutex);
++=======
+ 		inode_unlock(d_inode(privroot));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	}
  
  error:
diff --cc fs/ubifs/dir.c
index 605af512aec2,795992a8321e..000000000000
--- a/fs/ubifs/dir.c
+++ b/fs/ubifs/dir.c
@@@ -534,11 -512,11 +534,11 @@@ static int ubifs_link(struct dentry *ol
  	 * changing the parent inode.
  	 */
  
 -	dbg_gen("dent '%pd' to ino %lu (nlink %d) in dir ino %lu",
 -		dentry, inode->i_ino,
 +	dbg_gen("dent '%.*s' to ino %lu (nlink %d) in dir ino %lu",
 +		dentry->d_name.len, dentry->d_name.name, inode->i_ino,
  		inode->i_nlink, dir->i_ino);
- 	ubifs_assert(mutex_is_locked(&dir->i_mutex));
- 	ubifs_assert(mutex_is_locked(&inode->i_mutex));
+ 	ubifs_assert(inode_is_locked(dir));
+ 	ubifs_assert(inode_is_locked(inode));
  
  	err = dbg_check_synced_i_size(c, inode);
  	if (err)
@@@ -591,11 -569,11 +591,11 @@@ static int ubifs_unlink(struct inode *d
  	 * deletions.
  	 */
  
 -	dbg_gen("dent '%pd' from ino %lu (nlink %d) in dir ino %lu",
 -		dentry, inode->i_ino,
 +	dbg_gen("dent '%.*s' from ino %lu (nlink %d) in dir ino %lu",
 +		dentry->d_name.len, dentry->d_name.name, inode->i_ino,
  		inode->i_nlink, dir->i_ino);
- 	ubifs_assert(mutex_is_locked(&dir->i_mutex));
- 	ubifs_assert(mutex_is_locked(&inode->i_mutex));
+ 	ubifs_assert(inode_is_locked(dir));
+ 	ubifs_assert(inode_is_locked(inode));
  	err = dbg_check_synced_i_size(c, inode);
  	if (err)
  		return err;
@@@ -681,11 -659,11 +681,19 @@@ static int ubifs_rmdir(struct inode *di
  	 * because we have extra space reserved for deletions.
  	 */
  
++<<<<<<< HEAD
 +	dbg_gen("directory '%.*s', ino %lu in dir ino %lu", dentry->d_name.len,
 +		dentry->d_name.name, inode->i_ino, dir->i_ino);
 +	ubifs_assert(mutex_is_locked(&dir->i_mutex));
 +	ubifs_assert(mutex_is_locked(&inode->i_mutex));
 +	err = check_dir_empty(c, dentry->d_inode);
++=======
+ 	dbg_gen("directory '%pd', ino %lu in dir ino %lu", dentry,
+ 		inode->i_ino, dir->i_ino);
+ 	ubifs_assert(inode_is_locked(dir));
+ 	ubifs_assert(inode_is_locked(inode));
+ 	err = check_dir_empty(c, d_inode(dentry));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (err)
  		return err;
  
@@@ -1004,14 -993,13 +1012,22 @@@ static int ubifs_rename(struct inode *o
  	 * separately.
  	 */
  
++<<<<<<< HEAD
 +	dbg_gen("dent '%.*s' ino %lu in dir ino %lu to dent '%.*s' in dir ino %lu",
 +		old_dentry->d_name.len, old_dentry->d_name.name,
 +		old_inode->i_ino, old_dir->i_ino, new_dentry->d_name.len,
 +		new_dentry->d_name.name, new_dir->i_ino);
 +	ubifs_assert(mutex_is_locked(&old_dir->i_mutex));
 +	ubifs_assert(mutex_is_locked(&new_dir->i_mutex));
++=======
+ 	dbg_gen("dent '%pd' ino %lu in dir ino %lu to dent '%pd' in dir ino %lu",
+ 		old_dentry, old_inode->i_ino, old_dir->i_ino,
+ 		new_dentry, new_dir->i_ino);
+ 	ubifs_assert(inode_is_locked(old_dir));
+ 	ubifs_assert(inode_is_locked(new_dir));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (unlink)
- 		ubifs_assert(mutex_is_locked(&new_inode->i_mutex));
+ 		ubifs_assert(inode_is_locked(new_inode));
  
  
  	if (unlink && is_dir) {
diff --cc fs/ubifs/xattr.c
index 0f7139bdb2c2,c7f4d434d098..000000000000
--- a/fs/ubifs/xattr.c
+++ b/fs/ubifs/xattr.c
@@@ -303,9 -313,7 +303,13 @@@ int ubifs_setxattr(struct dentry *dentr
  	union ubifs_key key;
  	int err, type;
  
++<<<<<<< HEAD
 +	dbg_gen("xattr '%s', host ino %lu ('%.*s'), size %zd", name,
 +		host->i_ino, dentry->d_name.len, dentry->d_name.name, size);
 +	ubifs_assert(mutex_is_locked(&host->i_mutex));
++=======
+ 	ubifs_assert(inode_is_locked(host));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if (size > UBIFS_MAX_INO_DATA)
  		return -ERANGE;
@@@ -529,9 -548,9 +533,15 @@@ int ubifs_removexattr(struct dentry *de
  	union ubifs_key key;
  	int err;
  
++<<<<<<< HEAD
 +	dbg_gen("xattr '%s', ino %lu ('%.*s')", name,
 +		host->i_ino, dentry->d_name.len, dentry->d_name.name);
 +	ubifs_assert(mutex_is_locked(&host->i_mutex));
++=======
+ 	dbg_gen("xattr '%s', ino %lu ('%pd')", name,
+ 		host->i_ino, dentry);
+ 	ubifs_assert(inode_is_locked(host));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	err = check_namespace(&nm);
  	if (err < 0)
diff --cc fs/udf/file.c
index 29569dd08168,1af98963d860..000000000000
--- a/fs/udf/file.c
+++ b/fs/udf/file.c
@@@ -140,22 -119,24 +140,36 @@@ static ssize_t udf_file_aio_write(struc
  	ssize_t retval;
  	struct file *file = iocb->ki_filp;
  	struct inode *inode = file_inode(file);
 +	int err, pos;
 +	size_t count = iocb->ki_left;
  	struct udf_inode_info *iinfo = UDF_I(inode);
++<<<<<<< HEAD
++=======
+ 	int err;
+ 
+ 	inode_lock(inode);
+ 
+ 	retval = generic_write_checks(iocb, from);
+ 	if (retval <= 0)
+ 		goto out;
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	down_write(&iinfo->i_data_sem);
  	if (iinfo->i_alloc_type == ICBTAG_FLAG_AD_IN_ICB) {
 -		loff_t end = iocb->ki_pos + iov_iter_count(from);
 +		if (file->f_flags & O_APPEND)
 +			pos = inode->i_size;
 +		else
 +			pos = ppos;
  
  		if (inode->i_sb->s_blocksize <
 -				(udf_file_entry_alloc_offset(inode) + end)) {
 +				(udf_file_entry_alloc_offset(inode) +
 +						pos + count)) {
  			err = udf_expand_file_adinicb(inode);
  			if (err) {
++<<<<<<< HEAD
++=======
+ 				inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  				udf_debug("udf_expand_adinicb: err=%d\n", err);
  				return err;
  			}
@@@ -169,9 -147,16 +183,17 @@@
  	} else
  		up_write(&iinfo->i_data_sem);
  
++<<<<<<< HEAD
 +	retval = generic_file_aio_write(iocb, iov, nr_segs, ppos);
 +	if (retval > 0)
++=======
+ 	retval = __generic_file_write_iter(iocb, from);
+ out:
+ 	inode_unlock(inode);
+ 
+ 	if (retval > 0) {
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		mark_inode_dirty(inode);
 -		err = generic_write_sync(file, iocb->ki_pos - retval, retval);
 -		if (err < 0)
 -			retval = err;
 -	}
  
  	return retval;
  }
@@@ -232,11 -217,18 +254,25 @@@ out
  
  static int udf_release_file(struct inode *inode, struct file *filp)
  {
++<<<<<<< HEAD
 +	if (filp->f_mode & FMODE_WRITE) {
++=======
+ 	if (filp->f_mode & FMODE_WRITE &&
+ 	    atomic_read(&inode->i_writecount) == 1) {
+ 		/*
+ 		 * Grab i_mutex to avoid races with writes changing i_size
+ 		 * while we are running.
+ 		 */
+ 		inode_lock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		down_write(&UDF_I(inode)->i_data_sem);
  		udf_discard_prealloc(inode);
  		udf_truncate_tail_extent(inode);
  		up_write(&UDF_I(inode)->i_data_sem);
++<<<<<<< HEAD
++=======
+ 		inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	}
  	return 0;
  }
diff --cc fs/udf/inode.c
index b06be272b294,166d3ed32c39..000000000000
--- a/fs/udf/inode.c
+++ b/fs/udf/inode.c
@@@ -265,6 -262,7 +265,10 @@@ int udf_expand_file_adinicb(struct inod
  		.nr_to_write = 1,
  	};
  
++<<<<<<< HEAD
++=======
+ 	WARN_ON_ONCE(!inode_is_locked(inode));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (!iinfo->i_lenAlloc) {
  		if (UDF_QUERY_FLAG(inode->i_sb, UDF_FLAG_USE_SHORT_AD))
  			iinfo->i_alloc_type = ICBTAG_FLAG_AD_SHORT;
diff --cc fs/xattr.c
index 3377dff18404,07d0e47f6a7f..000000000000
--- a/fs/xattr.c
+++ b/fs/xattr.c
@@@ -296,20 -277,20 +296,26 @@@ vfs_removexattr(struct dentry *dentry, 
  	if (error)
  		return error;
  
- 	mutex_lock(&inode->i_mutex);
+ 	inode_lock(inode);
  	error = security_inode_removexattr(dentry, name);
 -	if (error)
 -		goto out;
 +	if (error) {
 +		mutex_unlock(&inode->i_mutex);
 +		return error;
 +	}
  
  	error = inode->i_op->removexattr(dentry, name);
 +	mutex_unlock(&inode->i_mutex);
  
  	if (!error) {
  		fsnotify_xattr(dentry);
  		evm_inode_post_removexattr(dentry, name);
  	}
++<<<<<<< HEAD
++=======
+ 
+ out:
+ 	inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return error;
  }
  EXPORT_SYMBOL_GPL(vfs_removexattr);
diff --cc include/linux/fs.h
index 98b7caca3399,2df6c033c3f5..000000000000
--- a/include/linux/fs.h
+++ b/include/linux/fs.h
@@@ -3119,29 -3035,49 +3144,63 @@@ static inline void inode_has_no_xattr(s
  		inode->i_flags |= S_NOSEC;
  }
  
 -static inline bool is_root_inode(struct inode *inode)
 +static inline const struct inode_operations_wrapper *get_iop_wrapper(struct inode *inode,
 +								     unsigned version)
  {
 -	return inode == inode->i_sb->s_root->d_inode;
 +	const struct inode_operations_wrapper *wrapper;
 +		
 +	if (!IS_IOPS_WRAPPER(inode))
 +		return NULL;
 +	wrapper = container_of(inode->i_op, const struct inode_operations_wrapper, ops);
 +	if (wrapper->version < version)
 +		return NULL;
 +	return wrapper;
  }
  
 -static inline bool dir_emit(struct dir_context *ctx,
 -			    const char *name, int namelen,
 -			    u64 ino, unsigned type)
 +static inline iop_rename2_t get_rename2_iop(struct inode *inode)
  {
++<<<<<<< HEAD
 +	const struct inode_operations_wrapper *wrapper = get_iop_wrapper(inode, 0);
 +	return wrapper ? wrapper->rename2 : NULL;
++=======
+ 	return ctx->actor(ctx, name, namelen, ctx->pos, ino, type) == 0;
+ }
+ static inline bool dir_emit_dot(struct file *file, struct dir_context *ctx)
+ {
+ 	return ctx->actor(ctx, ".", 1, ctx->pos,
+ 			  file->f_path.dentry->d_inode->i_ino, DT_DIR) == 0;
+ }
+ static inline bool dir_emit_dotdot(struct file *file, struct dir_context *ctx)
+ {
+ 	return ctx->actor(ctx, "..", 2, ctx->pos,
+ 			  parent_ino(file->f_path.dentry), DT_DIR) == 0;
+ }
+ static inline bool dir_emit_dots(struct file *file, struct dir_context *ctx)
+ {
+ 	if (ctx->pos == 0) {
+ 		if (!dir_emit_dot(file, ctx))
+ 			return false;
+ 		ctx->pos = 1;
+ 	}
+ 	if (ctx->pos == 1) {
+ 		if (!dir_emit_dotdot(file, ctx))
+ 			return false;
+ 		ctx->pos = 2;
+ 	}
+ 	return true;
+ }
+ static inline bool dir_relax(struct inode *inode)
+ {
+ 	inode_unlock(inode);
+ 	inode_lock(inode);
+ 	return !IS_DEADDIR(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  }
  
 -extern bool path_noexec(const struct path *path);
 -extern void inode_nohighmem(struct inode *inode);
 +static inline iop_dentry_open_t get_dentry_open_iop(struct inode *inode)
 +{
 +	const struct inode_operations_wrapper *wrapper = get_iop_wrapper(inode, 0);
 +	return wrapper ? wrapper->dentry_open : NULL;
 +}
  
  #endif /* _LINUX_FS_H */
diff --cc ipc/mqueue.c
index b8d4aed45b8c,781c1399c6a3..000000000000
--- a/ipc/mqueue.c
+++ b/ipc/mqueue.c
@@@ -802,7 -795,7 +802,11 @@@ SYSCALL_DEFINE4(mq_open, const char __u
  
  	ro = mnt_want_write(mnt);	/* we'll drop it in any case */
  	error = 0;
++<<<<<<< HEAD
 +	mutex_lock(&root->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	path.dentry = lookup_one_len(name->name, root, strlen(name->name));
  	if (IS_ERR(path.dentry)) {
  		error = PTR_ERR(path.dentry);
@@@ -848,7 -841,7 +852,11 @@@ out_putfd
  		put_unused_fd(fd);
  		fd = error;
  	}
++<<<<<<< HEAD
 +	mutex_unlock(&root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (!ro)
  		mnt_drop_write(mnt);
  out_putname:
@@@ -873,7 -866,7 +881,11 @@@ SYSCALL_DEFINE1(mq_unlink, const char _
  	err = mnt_want_write(mnt);
  	if (err)
  		goto out_name;
++<<<<<<< HEAD
 +	mutex_lock_nested(&mnt->mnt_root->d_inode->i_mutex, I_MUTEX_PARENT);
++=======
+ 	inode_lock_nested(d_inode(mnt->mnt_root), I_MUTEX_PARENT);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	dentry = lookup_one_len(name->name, mnt->mnt_root,
  				strlen(name->name));
  	if (IS_ERR(dentry)) {
@@@ -891,7 -884,7 +903,11 @@@
  	dput(dentry);
  
  out_unlock:
++<<<<<<< HEAD
 +	mutex_unlock(&mnt->mnt_root->d_inode->i_mutex);
++=======
+ 	inode_unlock(d_inode(mnt->mnt_root));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (inode)
  		iput(inode);
  	mnt_drop_write(mnt);
diff --cc kernel/audit_watch.c
index 4e6869e3e688,9f194aad0adc..000000000000
--- a/kernel/audit_watch.c
+++ b/kernel/audit_watch.c
@@@ -364,11 -364,11 +364,16 @@@ static int audit_get_nd(struct audit_wa
  	struct dentry *d = kern_path_locked(watch->path, parent);
  	if (IS_ERR(d))
  		return PTR_ERR(d);
++<<<<<<< HEAD
 +	mutex_unlock(&parent->dentry->d_inode->i_mutex);
 +	if (d->d_inode) {
++=======
+ 	inode_unlock(d_backing_inode(parent->dentry));
+ 	if (d_is_positive(d)) {
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  		/* update watch filter fields */
 -		watch->dev = d_backing_inode(d)->i_sb->s_dev;
 -		watch->ino = d_backing_inode(d)->i_ino;
 +		watch->dev = d->d_inode->i_sb->s_dev;
 +		watch->ino = d->d_inode->i_ino;
  	}
  	dput(d);
  	return 0;
diff --cc kernel/sched/core.c
index 8dcc6799195b,63d3a24e081a..000000000000
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@@ -244,7 -220,11 +244,15 @@@ sched_feat_write(struct file *filp, con
  	buf[cnt] = 0;
  	cmp = strstrip(buf);
  
++<<<<<<< HEAD
 +	i = sched_feat_set(cmp);
++=======
+ 	/* Ensure the static_key remains in a consistent state */
+ 	inode = file_inode(filp);
+ 	inode_lock(inode);
+ 	i = sched_feat_set(cmp);
+ 	inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (i == __SCHED_FEAT_NR)
  		return -EINVAL;
  
diff --cc mm/filemap.c
index c30a5bf58143,30ab120b33db..000000000000
--- a/mm/filemap.c
+++ b/mm/filemap.c
@@@ -3188,11 -2684,11 +3188,19 @@@ ssize_t generic_file_aio_write(struct k
  	struct inode *inode = file->f_mapping->host;
  	ssize_t ret;
  
++<<<<<<< HEAD
 +	BUG_ON(iocb->ki_pos != pos);
 +
 +	mutex_lock(&inode->i_mutex);
 +	ret = __generic_file_aio_write(iocb, iov, nr_segs, &iocb->ki_pos);
 +	mutex_unlock(&inode->i_mutex);
++=======
+ 	inode_lock(inode);
+ 	ret = generic_write_checks(iocb, from);
+ 	if (ret > 0)
+ 		ret = __generic_file_write_iter(iocb, from);
+ 	inode_unlock(inode);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  
  	if (ret > 0) {
  		ssize_t err;
diff --cc mm/swapfile.c
index 44c2eac6b890,d2c37365e2d6..000000000000
--- a/mm/swapfile.c
+++ b/mm/swapfile.c
@@@ -1700,14 -1953,24 +1700,14 @@@ SYSCALL_DEFINE1(swapoff, const char __u
  	inode = mapping->host;
  	if (S_ISBLK(inode->i_mode)) {
  		struct block_device *bdev = I_BDEV(inode);
 -		set_blocksize(bdev, old_block_size);
 +		set_blocksize(bdev, p->old_block_size);
  		blkdev_put(bdev, FMODE_READ | FMODE_WRITE | FMODE_EXCL);
  	} else {
- 		mutex_lock(&inode->i_mutex);
+ 		inode_lock(inode);
  		inode->i_flags &= ~S_SWAPFILE;
- 		mutex_unlock(&inode->i_mutex);
+ 		inode_unlock(inode);
  	}
  	filp_close(swap_file, NULL);
 -
 -	/*
 -	 * Clear the SWP_USED flag after all resources are freed so that swapon
 -	 * can reuse this swap_info in alloc_swap_info() safely.  It is ok to
 -	 * not hold p->lock after we cleared its SWP_WRITEOK.
 -	 */
 -	spin_lock(&swap_lock);
 -	p->flags = 0;
 -	spin_unlock(&swap_lock);
 -
  	err = 0;
  	atomic_inc(&proc_poll_event);
  	wake_up_interruptible(&proc_poll_wait);
@@@ -2099,20 -2414,9 +2099,24 @@@ SYSCALL_DEFINE2(swapon, const char __us
  
  	p->swap_file = swap_file;
  	mapping = swap_file->f_mapping;
 -	inode = mapping->host;
  
++<<<<<<< HEAD
 +	for (i = 0; i < nr_swapfiles; i++) {
 +		struct swap_info_struct *q = swap_info[i];
 +
 +		if (q == p || !q->swap_file)
 +			continue;
 +		if (mapping == q->swap_file->f_mapping) {
 +			error = -EBUSY;
 +			goto bad_swap;
 +		}
 +	}
 +
 +	inode = mapping->host;
 +	/* If S_ISREG(inode->i_mode) will do mutex_lock(&inode->i_mutex); */
++=======
+ 	/* If S_ISREG(inode->i_mode) will do inode_lock(inode); */
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	error = claim_swapfile(p, inode);
  	if (unlikely(error))
  		goto bad_swap;
@@@ -2233,9 -2558,10 +2237,9 @@@ bad_swap
  	p->flags = 0;
  	spin_unlock(&swap_lock);
  	vfree(swap_map);
 -	vfree(cluster_info);
  	if (swap_file) {
  		if (inode && S_ISREG(inode->i_mode)) {
- 			mutex_unlock(&inode->i_mutex);
+ 			inode_unlock(inode);
  			inode = NULL;
  		}
  		filp_close(swap_file, NULL);
diff --cc net/sunrpc/rpc_pipe.c
index 5f1269892c2e,31789ef3e614..000000000000
--- a/net/sunrpc/rpc_pipe.c
+++ b/net/sunrpc/rpc_pipe.c
@@@ -625,10 -616,10 +625,15 @@@ int rpc_rmdir(struct dentry *dentry
  	int error;
  
  	parent = dget_parent(dentry);
++<<<<<<< HEAD
 +	dir = parent->d_inode;
 +	mutex_lock_nested(&dir->i_mutex, I_MUTEX_PARENT);
++=======
+ 	dir = d_inode(parent);
+ 	inode_lock_nested(dir, I_MUTEX_PARENT);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	error = __rpc_rmdir(dir, dentry);
- 	mutex_unlock(&dir->i_mutex);
+ 	inode_unlock(dir);
  	dput(parent);
  	return error;
  }
@@@ -708,11 -699,11 +713,11 @@@ static void rpc_depopulate(struct dentr
  			   const struct rpc_filelist *files,
  			   int start, int eof)
  {
 -	struct inode *dir = d_inode(parent);
 +	struct inode *dir = parent->d_inode;
  
- 	mutex_lock_nested(&dir->i_mutex, I_MUTEX_CHILD);
+ 	inode_lock_nested(dir, I_MUTEX_CHILD);
  	__rpc_depopulate(parent, files, start, eof);
- 	mutex_unlock(&dir->i_mutex);
+ 	inode_unlock(dir);
  }
  
  static int rpc_populate(struct dentry *parent,
@@@ -752,9 -743,9 +757,15 @@@
  	return 0;
  out_bad:
  	__rpc_depopulate(parent, files, start, eof);
++<<<<<<< HEAD
 +	mutex_unlock(&dir->i_mutex);
 +	printk(KERN_WARNING "%s: %s failed to populate directory %s\n",
 +			__FILE__, __func__, parent->d_name.name);
++=======
+ 	inode_unlock(dir);
+ 	printk(KERN_WARNING "%s: %s failed to populate directory %pd\n",
+ 			__FILE__, __func__, parent);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	return err;
  }
  
@@@ -763,10 -754,10 +774,10 @@@ static struct dentry *rpc_mkdir_populat
  		int (*populate)(struct dentry *, void *), void *args_populate)
  {
  	struct dentry *dentry;
 -	struct inode *dir = d_inode(parent);
 +	struct inode *dir = parent->d_inode;
  	int error;
  
- 	mutex_lock_nested(&dir->i_mutex, I_MUTEX_PARENT);
+ 	inode_lock_nested(dir, I_MUTEX_PARENT);
  	dentry = __rpc_lookup_create_exclusive(parent, name);
  	if (IS_ERR(dentry))
  		goto out;
@@@ -796,8 -787,8 +807,13 @@@ static int rpc_rmdir_depopulate(struct 
  	int error;
  
  	parent = dget_parent(dentry);
++<<<<<<< HEAD
 +	dir = parent->d_inode;
 +	mutex_lock_nested(&dir->i_mutex, I_MUTEX_PARENT);
++=======
+ 	dir = d_inode(parent);
+ 	inode_lock_nested(dir, I_MUTEX_PARENT);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	if (depopulate != NULL)
  		depopulate(dentry);
  	error = __rpc_rmdir(dir, dentry);
@@@ -873,10 -864,10 +889,15 @@@ rpc_unlink(struct dentry *dentry
  	int error = 0;
  
  	parent = dget_parent(dentry);
++<<<<<<< HEAD
 +	dir = parent->d_inode;
 +	mutex_lock_nested(&dir->i_mutex, I_MUTEX_PARENT);
++=======
+ 	dir = d_inode(parent);
+ 	inode_lock_nested(dir, I_MUTEX_PARENT);
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	error = __rpc_rmpipe(dir, dentry);
- 	mutex_unlock(&dir->i_mutex);
+ 	inode_unlock(dir);
  	dput(parent);
  	return error;
  }
diff --cc security/inode.c
index 43ce6e19015f,28414b0207ce..000000000000
--- a/security/inode.c
+++ b/security/inode.c
@@@ -102,9 -97,9 +102,9 @@@ struct dentry *securityfs_create_file(c
  	if (!parent)
  		parent = mount->mnt_root;
  
 -	dir = d_inode(parent);
 +	dir = parent->d_inode;
  
- 	mutex_lock(&dir->i_mutex);
+ 	inode_lock(dir);
  	dentry = lookup_one_len(name, parent, strlen(name));
  	if (IS_ERR(dentry))
  		goto out;
@@@ -197,20 -192,18 +197,32 @@@ void securityfs_remove(struct dentry *d
  		return;
  
  	parent = dentry->d_parent;
 -	if (!parent || d_really_is_negative(parent))
 +	if (!parent || !parent->d_inode)
  		return;
  
++<<<<<<< HEAD
 +	mutex_lock(&parent->d_inode->i_mutex);
 +	if (positive(dentry)) {
 +		if (dentry->d_inode) {
 +			if (S_ISDIR(dentry->d_inode->i_mode))
 +				simple_rmdir(parent->d_inode, dentry);
 +			else
 +				simple_unlink(parent->d_inode, dentry);
 +			dput(dentry);
 +		}
 +	}
 +	mutex_unlock(&parent->d_inode->i_mutex);
++=======
+ 	inode_lock(d_inode(parent));
+ 	if (simple_positive(dentry)) {
+ 		if (d_is_dir(dentry))
+ 			simple_rmdir(d_inode(parent), dentry);
+ 		else
+ 			simple_unlink(d_inode(parent), dentry);
+ 		dput(dentry);
+ 	}
+ 	inode_unlock(d_inode(parent));
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	simple_release_fs(&mount, &mount_count);
  }
  EXPORT_SYMBOL_GPL(securityfs_remove);
diff --cc security/integrity/ima/ima_main.c
index ad4ea69cf057,9d96551d0196..000000000000
--- a/security/integrity/ima/ima_main.c
+++ b/security/integrity/ima/ima_main.c
@@@ -108,14 -121,16 +108,25 @@@ static void ima_check_last_writer(struc
  	if (!(mode & FMODE_WRITE))
  		return;
  
++<<<<<<< HEAD
 +	mutex_lock(&inode->i_mutex);
 +	if (atomic_read(&inode->i_writecount) == 1 &&
 +	    iint->version != inode->i_version) {
 +		iint->flags &= ~IMA_DONE_MASK;
 +		if (iint->flags & IMA_APPRAISE)
 +			ima_update_xattr(iint, file);
++=======
+ 	inode_lock(inode);
+ 	if (atomic_read(&inode->i_writecount) == 1) {
+ 		if ((iint->version != inode->i_version) ||
+ 		    (iint->flags & IMA_NEW_FILE)) {
+ 			iint->flags &= ~(IMA_DONE_MASK | IMA_NEW_FILE);
+ 			if (iint->flags & IMA_APPRAISE)
+ 				ima_update_xattr(iint, file);
+ 		}
++>>>>>>> 5955102c9984 (wrappers for ->i_mutex access)
  	}
- 	mutex_unlock(&inode->i_mutex);
+ 	inode_unlock(inode);
  }
  
  /**
@@@ -162,13 -183,25 +173,13 @@@ static int process_measurement(struct f
  	must_appraise = action & IMA_APPRAISE;
  
  	/*  Is the appraise rule hook specific?  */
 -	if (action & IMA_FILE_APPRAISE)
 -		function = FILE_CHECK;
 +	_func = (action & IMA_FILE_APPRAISE) ? FILE_CHECK : function;
  
- 	mutex_lock(&inode->i_mutex);
+ 	inode_lock(inode);
  
 -	if (action) {
 -		iint = integrity_inode_get(inode);
 -		if (!iint)
 -			goto out;
 -	}
 -
 -	if (violation_check) {
 -		ima_rdwr_violation_check(file, iint, action & IMA_MEASURE,
 -					 &pathbuf, &pathname);
 -		if (!action) {
 -			rc = 0;
 -			goto out_free;
 -		}
 -	}
 +	iint = integrity_inode_get(inode);
 +	if (!iint)
 +		goto out;
  
  	/* Determine if already appraised/measured based on bitmask
  	 * (IMA_MEASURE, IMA_MEASURED, IMA_XXXX_APPRAISE, IMA_XXXX_APPRAISED,
@@@ -203,8 -245,12 +214,8 @@@
  out_digsig:
  	if ((mask & MAY_WRITE) && (iint->flags & IMA_DIGSIG))
  		rc = -EACCES;
 -	kfree(xattr_value);
 -out_free:
 -	if (pathbuf)
 -		__putname(pathbuf);
  out:
- 	mutex_unlock(&inode->i_mutex);
+ 	inode_unlock(inode);
  	if ((rc && must_appraise) && (ima_appraise & IMA_APPRAISE_ENFORCE))
  		return -EACCES;
  	return 0;
* Unmerged path drivers/block/drbd/drbd_debugfs.c
* Unmerged path drivers/staging/lustre/lustre/llite/dir.c
* Unmerged path drivers/staging/lustre/lustre/llite/file.c
* Unmerged path drivers/staging/lustre/lustre/llite/llite_lib.c
* Unmerged path drivers/staging/lustre/lustre/llite/llite_nfs.c
* Unmerged path drivers/staging/lustre/lustre/llite/lloop.c
* Unmerged path drivers/staging/lustre/lustre/llite/rw.c
* Unmerged path drivers/staging/lustre/lustre/llite/rw26.c
* Unmerged path drivers/staging/lustre/lustre/llite/vvp_io.c
* Unmerged path drivers/staging/lustre/lustre/llite/vvp_page.c
* Unmerged path fs/ceph/cache.c
* Unmerged path fs/kernfs/dir.c
* Unmerged path fs/proc/thread_self.c
* Unmerged path fs/tracefs/inode.c
diff --git a/arch/powerpc/platforms/cell/spufs/file.c b/arch/powerpc/platforms/cell/spufs/file.c
index 90986923a53a..7083114f943e 100644
--- a/arch/powerpc/platforms/cell/spufs/file.c
+++ b/arch/powerpc/platforms/cell/spufs/file.c
@@ -1854,9 +1854,9 @@ static int spufs_mfc_fsync(struct file *file, loff_t start, loff_t end, int data
 	struct inode *inode = file_inode(file);
 	int err = filemap_write_and_wait_range(inode->i_mapping, start, end);
 	if (!err) {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		err = spufs_mfc_flush(file, NULL);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 	}
 	return err;
 }
* Unmerged path arch/powerpc/platforms/cell/spufs/inode.c
* Unmerged path arch/s390/hypfs/inode.c
* Unmerged path block/ioctl.c
* Unmerged path drivers/base/devtmpfs.c
diff --git a/drivers/block/aoe/aoecmd.c b/drivers/block/aoe/aoecmd.c
index e89f65ec5923..81e81aca36df 100644
--- a/drivers/block/aoe/aoecmd.c
+++ b/drivers/block/aoe/aoecmd.c
@@ -990,9 +990,9 @@ aoecmd_sleepwork(struct work_struct *work)
 		ssize = get_capacity(d->gd);
 		bd = bdget_disk(d->gd, 0);
 		if (bd) {
-			mutex_lock(&bd->bd_inode->i_mutex);
+			inode_lock(bd->bd_inode);
 			i_size_write(bd->bd_inode, (loff_t)ssize<<9);
-			mutex_unlock(&bd->bd_inode->i_mutex);
+			inode_unlock(bd->bd_inode);
 			bdput(bd);
 		}
 		spin_lock_irq(&d->lock);
* Unmerged path drivers/block/drbd/drbd_debugfs.c
diff --git a/drivers/char/mem.c b/drivers/char/mem.c
index a3653f746a08..cff5874e43f1 100644
--- a/drivers/char/mem.c
+++ b/drivers/char/mem.c
@@ -752,7 +752,7 @@ static loff_t memory_lseek(struct file *file, loff_t offset, int orig)
 {
 	loff_t ret;
 
-	mutex_lock(&file_inode(file)->i_mutex);
+	inode_lock(file_inode(file));
 	switch (orig) {
 	case SEEK_CUR:
 		offset += file->f_pos;
@@ -769,7 +769,7 @@ static loff_t memory_lseek(struct file *file, loff_t offset, int orig)
 	default:
 		ret = -EINVAL;
 	}
-	mutex_unlock(&file_inode(file)->i_mutex);
+	inode_unlock(file_inode(file));
 	return ret;
 }
 
diff --git a/drivers/char/ps3flash.c b/drivers/char/ps3flash.c
index 8cafa9ccd43f..0f5062e676bb 100644
--- a/drivers/char/ps3flash.c
+++ b/drivers/char/ps3flash.c
@@ -314,9 +314,9 @@ static int ps3flash_fsync(struct file *file, loff_t start, loff_t end, int datas
 {
 	struct inode *inode = file_inode(file);
 	int err;
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	err = ps3flash_writeback(ps3flash_dev);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return err;
 }
 
* Unmerged path drivers/infiniband/hw/ipath/ipath_fs.c
* Unmerged path drivers/infiniband/hw/qib/qib_fs.c
diff --git a/drivers/mtd/ubi/cdev.c b/drivers/mtd/ubi/cdev.c
index 4f02848bb2bc..f4dc429f0d2b 100644
--- a/drivers/mtd/ubi/cdev.c
+++ b/drivers/mtd/ubi/cdev.c
@@ -196,9 +196,9 @@ static int vol_cdev_fsync(struct file *file, loff_t start, loff_t end,
 	struct ubi_device *ubi = desc->vol->ubi;
 	struct inode *inode = file_inode(file);
 	int err;
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	err = ubi_sync(ubi->ubi_num);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return err;
 }
 
* Unmerged path drivers/oprofile/oprofilefs.c
* Unmerged path drivers/staging/lustre/lustre/llite/dir.c
* Unmerged path drivers/staging/lustre/lustre/llite/file.c
* Unmerged path drivers/staging/lustre/lustre/llite/llite_lib.c
* Unmerged path drivers/staging/lustre/lustre/llite/llite_nfs.c
* Unmerged path drivers/staging/lustre/lustre/llite/lloop.c
* Unmerged path drivers/staging/lustre/lustre/llite/rw.c
* Unmerged path drivers/staging/lustre/lustre/llite/rw26.c
* Unmerged path drivers/staging/lustre/lustre/llite/vvp_io.c
* Unmerged path drivers/staging/lustre/lustre/llite/vvp_page.c
diff --git a/drivers/usb/gadget/atmel_usba_udc.c b/drivers/usb/gadget/atmel_usba_udc.c
index 5a5128a226f7..5b7d81f0187d 100644
--- a/drivers/usb/gadget/atmel_usba_udc.c
+++ b/drivers/usb/gadget/atmel_usba_udc.c
@@ -93,7 +93,7 @@ static ssize_t queue_dbg_read(struct file *file, char __user *buf,
 	if (!access_ok(VERIFY_WRITE, buf, nbytes))
 		return -EFAULT;
 
-	mutex_lock(&file_inode(file)->i_mutex);
+	inode_lock(file_inode(file));
 	list_for_each_entry_safe(req, tmp_req, queue, queue) {
 		len = snprintf(tmpbuf, sizeof(tmpbuf),
 				"%8p %08x %c%c%c %5d %c%c%c\n",
@@ -120,7 +120,7 @@ static ssize_t queue_dbg_read(struct file *file, char __user *buf,
 		nbytes -= len;
 		buf += len;
 	}
-	mutex_unlock(&file_inode(file)->i_mutex);
+	inode_unlock(file_inode(file));
 
 	return actual;
 }
@@ -145,7 +145,7 @@ static int regs_dbg_open(struct inode *inode, struct file *file)
 	u32 *data;
 	int ret = -ENOMEM;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	udc = inode->i_private;
 	data = kmalloc(inode->i_size, GFP_KERNEL);
 	if (!data)
@@ -160,7 +160,7 @@ static int regs_dbg_open(struct inode *inode, struct file *file)
 	ret = 0;
 
 out:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	return ret;
 }
@@ -171,11 +171,11 @@ static ssize_t regs_dbg_read(struct file *file, char __user *buf,
 	struct inode *inode = file_inode(file);
 	int ret;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	ret = simple_read_from_buffer(buf, nbytes, ppos,
 			file->private_data,
 			file_inode(file)->i_size);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	return ret;
 }
diff --git a/drivers/usb/gadget/inode.c b/drivers/usb/gadget/inode.c
index 570c005062ab..009b962c60cb 100644
--- a/drivers/usb/gadget/inode.c
+++ b/drivers/usb/gadget/inode.c
@@ -1609,10 +1609,10 @@ static void destroy_ep_files (struct dev_data *dev)
 		spin_unlock_irq (&dev->lock);
 
 		/* break link to dcache */
-		mutex_lock (&parent->i_mutex);
+		inode_lock(parent);
 		d_delete (dentry);
 		dput (dentry);
-		mutex_unlock (&parent->i_mutex);
+		inode_unlock(parent);
 
 		spin_lock_irq (&dev->lock);
 	}
diff --git a/drivers/usb/gadget/printer.c b/drivers/usb/gadget/printer.c
index bf7a56b6d48a..d61c214a55ea 100644
--- a/drivers/usb/gadget/printer.c
+++ b/drivers/usb/gadget/printer.c
@@ -692,7 +692,7 @@ printer_fsync(struct file *fd, loff_t start, loff_t end, int datasync)
 	unsigned long		flags;
 	int			tx_list_empty;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	spin_lock_irqsave(&dev->lock, flags);
 	tx_list_empty = (likely(list_empty(&dev->tx_reqs)));
 	spin_unlock_irqrestore(&dev->lock, flags);
@@ -702,7 +702,7 @@ printer_fsync(struct file *fd, loff_t start, loff_t end, int datasync)
 		wait_event_interruptible(dev->tx_flush_wait,
 				(likely(list_empty(&dev->tx_reqs_active))));
 	}
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	return 0;
 }
* Unmerged path drivers/video/fb_defio.c
diff --git a/fs/9p/vfs_file.c b/fs/9p/vfs_file.c
index d384a8b77ee8..e64273222c1e 100644
--- a/fs/9p/vfs_file.c
+++ b/fs/9p/vfs_file.c
@@ -548,14 +548,14 @@ static int v9fs_file_fsync(struct file *filp, loff_t start, loff_t end,
 	if (retval)
 		return retval;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	p9_debug(P9_DEBUG_VFS, "filp %p datasync %x\n", filp, datasync);
 
 	fid = filp->private_data;
 	v9fs_blank_wstat(&wstat);
 
 	retval = p9_client_wstat(fid, &wstat);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	return retval;
 }
@@ -571,13 +571,13 @@ int v9fs_file_fsync_dotl(struct file *filp, loff_t start, loff_t end,
 	if (retval)
 		return retval;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	p9_debug(P9_DEBUG_VFS, "filp %p datasync %x\n", filp, datasync);
 
 	fid = filp->private_data;
 
 	retval = p9_client_fsync(fid, datasync);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	return retval;
 }
diff --git a/fs/affs/file.c b/fs/affs/file.c
index 1d5e51dda4f1..0347f8e4f595 100644
--- a/fs/affs/file.c
+++ b/fs/affs/file.c
@@ -58,11 +58,11 @@ affs_file_release(struct inode *inode, struct file *filp)
 		 inode->i_ino, atomic_read(&AFFS_I(inode)->i_opencnt));
 
 	if (atomic_dec_and_test(&AFFS_I(inode)->i_opencnt)) {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		if (inode->i_size != AFFS_I(inode)->mmu_private)
 			affs_truncate(inode);
 		affs_free_prealloc(inode);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 	}
 
 	return 0;
@@ -938,11 +938,11 @@ int affs_file_fsync(struct file *filp, loff_t start, loff_t end, int datasync)
 	if (err)
 		return err;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	ret = write_inode_now(inode, 0);
 	err = sync_blockdev(inode->i_sb->s_bdev);
 	if (!ret)
 		ret = err;
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return ret;
 }
diff --git a/fs/afs/flock.c b/fs/afs/flock.c
index a8cf2cff836c..53d4e8ff438d 100644
--- a/fs/afs/flock.c
+++ b/fs/afs/flock.c
@@ -483,7 +483,7 @@ static int afs_do_getlk(struct file *file, struct file_lock *fl)
 
 	fl->fl_type = F_UNLCK;
 
-	mutex_lock(&vnode->vfs_inode.i_mutex);
+	inode_lock(&vnode->vfs_inode);
 
 	/* check local lock records first */
 	ret = 0;
@@ -505,7 +505,7 @@ static int afs_do_getlk(struct file *file, struct file_lock *fl)
 	}
 
 error:
-	mutex_unlock(&vnode->vfs_inode.i_mutex);
+	inode_unlock(&vnode->vfs_inode);
 	_leave(" = %d [%hd]", ret, fl->fl_type);
 	return ret;
 }
diff --git a/fs/afs/write.c b/fs/afs/write.c
index a890db4b9898..2bba8ee72562 100644
--- a/fs/afs/write.c
+++ b/fs/afs/write.c
@@ -696,7 +696,7 @@ int afs_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 	ret = filemap_write_and_wait_range(inode->i_mapping, start, end);
 	if (ret)
 		return ret;
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	/* use a writeback record as a marker in the queue - when this reaches
 	 * the front of the queue, all the outstanding writes are either
@@ -738,7 +738,7 @@ int afs_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 	afs_put_writeback(wb);
 	_leave(" = %d", ret);
 out:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return ret;
 }
 
diff --git a/fs/attr.c b/fs/attr.c
index 7262f3beb8b5..1d846c5ba6db 100644
--- a/fs/attr.c
+++ b/fs/attr.c
@@ -195,7 +195,7 @@ int notify_change(struct dentry * dentry, struct iattr * attr, struct inode **de
 	struct timespec now;
 	unsigned int ia_valid = attr->ia_valid;
 
-	WARN_ON_ONCE(!mutex_is_locked(&inode->i_mutex));
+	WARN_ON_ONCE(!inode_is_locked(inode));
 
 	if (ia_valid & (ATTR_MODE | ATTR_UID | ATTR_GID | ATTR_TIMES_SET)) {
 		if (IS_IMMUTABLE(inode) || IS_APPEND(inode))
* Unmerged path fs/binfmt_misc.c
* Unmerged path fs/block_dev.c
* Unmerged path fs/btrfs/file.c
diff --git a/fs/btrfs/inode.c b/fs/btrfs/inode.c
index ded5036d1968..5e2b00cf031b 100644
--- a/fs/btrfs/inode.c
+++ b/fs/btrfs/inode.c
@@ -8476,7 +8476,7 @@ static ssize_t btrfs_direct_IO(int rw, struct kiocb *iocb,
 		 * not unlock the i_mutex at this case.
 		 */
 		if (offset + count <= inode->i_size) {
-			mutex_unlock(&inode->i_mutex);
+			inode_unlock(inode);
 			relock = true;
 		}
 		ret = btrfs_delalloc_reserve_space(inode, offset, count);
@@ -8518,7 +8518,7 @@ out:
 	if (wakeup)
 		inode_dio_end(inode);
 	if (relock)
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 
 	return ret;
 }
* Unmerged path fs/btrfs/ioctl.c
diff --git a/fs/btrfs/relocation.c b/fs/btrfs/relocation.c
index b4ca5454ef1a..53aad2f15115 100644
--- a/fs/btrfs/relocation.c
+++ b/fs/btrfs/relocation.c
@@ -3030,7 +3030,7 @@ int prealloc_file_extent_cluster(struct inode *inode,
 	int ret = 0;
 
 	BUG_ON(cluster->start != cluster->boundary[0]);
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	ret = btrfs_check_data_free_space(inode, cluster->start,
 					  cluster->end + 1 - cluster->start);
@@ -3057,7 +3057,7 @@ int prealloc_file_extent_cluster(struct inode *inode,
 	btrfs_free_reserved_data_space(inode, cluster->start,
 				       cluster->end + 1 - cluster->start);
 out:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return ret;
 }
 
diff --git a/fs/btrfs/scrub.c b/fs/btrfs/scrub.c
index 171130d3fefe..620d094bb93c 100644
--- a/fs/btrfs/scrub.c
+++ b/fs/btrfs/scrub.c
@@ -4295,7 +4295,7 @@ static int copy_nocow_pages_for_inode(u64 inum, u64 offset, u64 root,
 		return PTR_ERR(inode);
 
 	/* Avoid truncate/dio/punch hole.. */
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	inode_dio_wait(inode);
 
 	physical_for_dev_replace = nocow_ctx->physical_for_dev_replace;
@@ -4374,7 +4374,7 @@ next_page:
 	}
 	ret = COPY_COMPLETE;
 out:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	iput(inode);
 	return ret;
 }
diff --git a/fs/btrfs/xattr.c b/fs/btrfs/xattr.c
index 13f71dbda553..d385fe23dd4c 100644
--- a/fs/btrfs/xattr.c
+++ b/fs/btrfs/xattr.c
@@ -125,7 +125,7 @@ static int do_setxattr(struct btrfs_trans_handle *trans,
 	 * locks the inode's i_mutex before calling setxattr or removexattr.
 	 */
 	if (flags & XATTR_REPLACE) {
-		ASSERT(mutex_is_locked(&inode->i_mutex));
+		ASSERT(inode_is_locked(inode));
 		di = btrfs_lookup_xattr(NULL, root, path, btrfs_ino(inode),
 					name, name_len, 0);
 		if (!di)
* Unmerged path fs/cachefiles/interface.c
* Unmerged path fs/cachefiles/namei.c
* Unmerged path fs/ceph/cache.c
diff --git a/fs/ceph/caps.c b/fs/ceph/caps.c
index 6d4458adcf52..e6f85c08abab 100644
--- a/fs/ceph/caps.c
+++ b/fs/ceph/caps.c
@@ -2031,7 +2031,7 @@ int ceph_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 	if (datasync)
 		goto out;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	dirty = try_flush_caps(inode, &flush_tid);
 	dout("fsync dirty caps are %s\n", ceph_cap_string(dirty));
@@ -2047,7 +2047,7 @@ int ceph_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 		ret = wait_event_interruptible(ci->i_cap_wq,
 					caps_are_flushed(inode, flush_tid));
 	}
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 out:
 	dout("fsync %p%s result=%d\n", inode, datasync ? " datasync" : "", ret);
 	return ret;
diff --git a/fs/ceph/dir.c b/fs/ceph/dir.c
index 80058e8a3304..2b734c388f99 100644
--- a/fs/ceph/dir.c
+++ b/fs/ceph/dir.c
@@ -492,7 +492,7 @@ static loff_t ceph_dir_llseek(struct file *file, loff_t offset, int whence)
 	loff_t old_offset = ceph_make_fpos(fi->frag, fi->next_offset);
 	loff_t retval;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	retval = -EINVAL;
 	switch (whence) {
 	case SEEK_CUR:
@@ -527,7 +527,7 @@ static loff_t ceph_dir_llseek(struct file *file, loff_t offset, int whence)
 		}
 	}
 out:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return retval;
 }
 
* Unmerged path fs/ceph/export.c
* Unmerged path fs/ceph/file.c
diff --git a/fs/cifs/cifsfs.c b/fs/cifs/cifsfs.c
index 9f6ff2423731..9f0c6d185e8d 100644
--- a/fs/cifs/cifsfs.c
+++ b/fs/cifs/cifsfs.c
@@ -644,9 +644,9 @@ cifs_get_root(struct smb_vol *vol, struct super_block *sb)
 		while (*s && *s != sep)
 			s++;
 
-		mutex_lock(&dir->i_mutex);
+		inode_lock(dir);
 		child = lookup_one_len(p, dentry, s - p);
-		mutex_unlock(&dir->i_mutex);
+		inode_unlock(dir);
 		dput(dentry);
 		dentry = child;
 	} while (!IS_ERR(dentry));
* Unmerged path fs/cifs/file.c
* Unmerged path fs/coda/dir.c
* Unmerged path fs/coda/file.c
* Unmerged path fs/configfs/dir.c
* Unmerged path fs/configfs/file.c
* Unmerged path fs/configfs/inode.c
* Unmerged path fs/dax.c
diff --git a/fs/dcache.c b/fs/dcache.c
index 5dabe0ebb8a8..d274abab26f2 100644
--- a/fs/dcache.c
+++ b/fs/dcache.c
@@ -2294,7 +2294,7 @@ EXPORT_SYMBOL(d_rehash);
  */
 void dentry_update_name_case(struct dentry *dentry, struct qstr *name)
 {
-	BUG_ON(!mutex_is_locked(&dentry->d_parent->d_inode->i_mutex));
+	BUG_ON(!inode_is_locked(dentry->d_parent->d_inode));
 	BUG_ON(dentry->d_name.len != name->len); /* d_lookup gives this */
 
 	spin_lock(&dentry->d_lock);
@@ -2550,7 +2550,7 @@ static struct dentry *__d_unalias(struct inode *inode,
 	if (!mutex_trylock(&dentry->d_sb->s_vfs_rename_mutex))
 		goto out_err;
 	m1 = &dentry->d_sb->s_vfs_rename_mutex;
-	if (!mutex_trylock(&alias->d_parent->d_inode->i_mutex))
+	if (!inode_trylock(alias->d_parent->d_inode))
 		goto out_err;
 	m2 = &alias->d_parent->d_inode->i_mutex;
 out_unalias:
* Unmerged path fs/debugfs/inode.c
* Unmerged path fs/devpts/inode.c
* Unmerged path fs/direct-io.c
* Unmerged path fs/ecryptfs/inode.c
diff --git a/fs/ecryptfs/mmap.c b/fs/ecryptfs/mmap.c
index 564a1fa34b99..6699c7599311 100644
--- a/fs/ecryptfs/mmap.c
+++ b/fs/ecryptfs/mmap.c
@@ -436,7 +436,7 @@ static int ecryptfs_write_inode_size_to_xattr(struct inode *ecryptfs_inode)
 		rc = -ENOMEM;
 		goto out;
 	}
-	mutex_lock(&lower_inode->i_mutex);
+	inode_lock(lower_inode);
 	size = lower_inode->i_op->getxattr(lower_dentry, ECRYPTFS_XATTR_NAME,
 					   xattr_virt, PAGE_CACHE_SIZE);
 	if (size < 0)
@@ -444,7 +444,7 @@ static int ecryptfs_write_inode_size_to_xattr(struct inode *ecryptfs_inode)
 	put_unaligned_be64(i_size_read(ecryptfs_inode), xattr_virt);
 	rc = lower_inode->i_op->setxattr(lower_dentry, ECRYPTFS_XATTR_NAME,
 					 xattr_virt, size, 0);
-	mutex_unlock(&lower_inode->i_mutex);
+	inode_unlock(lower_inode);
 	if (rc)
 		printk(KERN_ERR "Error whilst attempting to write inode size "
 		       "to lower file xattr; rc = [%d]\n", rc);
diff --git a/fs/efivarfs/file.c b/fs/efivarfs/file.c
index 8dd524f32284..daf2e2753c56 100644
--- a/fs/efivarfs/file.c
+++ b/fs/efivarfs/file.c
@@ -55,9 +55,9 @@ static ssize_t efivarfs_file_write(struct file *file,
 		d_delete(file->f_dentry);
 		dput(file->f_dentry);
 	} else {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		i_size_write(inode, datasize + sizeof(attributes));
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 	}
 
 	bytes = count;
diff --git a/fs/efivarfs/super.c b/fs/efivarfs/super.c
index a8766b880c07..cde735cfc07d 100644
--- a/fs/efivarfs/super.c
+++ b/fs/efivarfs/super.c
@@ -169,10 +169,10 @@ static int efivarfs_callback(efi_char16_t *name16, efi_guid_t vendor,
 	efivar_entry_size(entry, &size);
 	efivar_entry_add(entry, &efivarfs_list);
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	inode->i_private = entry;
 	i_size_write(inode, size + sizeof(entry->var.Attributes));
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	d_add(dentry, inode);
 
 	return 0;
diff --git a/fs/exec.c b/fs/exec.c
index cc7185c3af70..cd064be38310 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -1258,13 +1258,13 @@ static void bprm_fill_uid(struct linux_binprm *bprm)
 		return;
 
 	/* Be careful if suid/sgid is set */
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	/* reload atomically mode/uid/gid now that lock held */
 	mode = inode->i_mode;
 	uid = inode->i_uid;
 	gid = inode->i_gid;
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	/* We ignore suid/sgid if there are no mappings for them in the ns */
 	if (!kuid_has_mapping(bprm->cred->user_ns, uid) ||
diff --git a/fs/exofs/file.c b/fs/exofs/file.c
index 491c6c078e7f..bedc9bab0560 100644
--- a/fs/exofs/file.c
+++ b/fs/exofs/file.c
@@ -52,9 +52,9 @@ static int exofs_file_fsync(struct file *filp, loff_t start, loff_t end,
 	if (ret)
 		return ret;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	ret = sync_inode_metadata(filp->f_mapping->host, 1);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return ret;
 }
 
* Unmerged path fs/exportfs/expfs.c
diff --git a/fs/ext2/ioctl.c b/fs/ext2/ioctl.c
index 5d46c09863f0..b386af2e45f4 100644
--- a/fs/ext2/ioctl.c
+++ b/fs/ext2/ioctl.c
@@ -51,10 +51,10 @@ long ext2_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 
 		flags = ext2_mask_flags(inode->i_mode, flags);
 
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		/* Is it quota file? Do not allow user to mess with it */
 		if (IS_NOQUOTA(inode)) {
-			mutex_unlock(&inode->i_mutex);
+			inode_unlock(inode);
 			ret = -EPERM;
 			goto setflags_out;
 		}
@@ -68,7 +68,7 @@ long ext2_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 		 */
 		if ((flags ^ oldflags) & (EXT2_APPEND_FL | EXT2_IMMUTABLE_FL)) {
 			if (!capable(CAP_LINUX_IMMUTABLE)) {
-				mutex_unlock(&inode->i_mutex);
+				inode_unlock(inode);
 				ret = -EPERM;
 				goto setflags_out;
 			}
@@ -80,7 +80,7 @@ long ext2_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 
 		ext2_set_inode_flags(inode);
 		inode->i_ctime = CURRENT_TIME_SEC;
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 
 		mark_inode_dirty(inode);
 setflags_out:
@@ -102,10 +102,10 @@ setflags_out:
 			goto setversion_out;
 		}
 
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		inode->i_ctime = CURRENT_TIME_SEC;
 		inode->i_generation = generation;
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 
 		mark_inode_dirty(inode);
 setversion_out:
diff --git a/fs/ext4/ext4.h b/fs/ext4/ext4.h
index 22282c061b41..1d5a0594035c 100644
--- a/fs/ext4/ext4.h
+++ b/fs/ext4/ext4.h
@@ -2527,7 +2527,7 @@ do {								\
 static inline void ext4_update_i_disksize(struct inode *inode, loff_t newsize)
 {
 	WARN_ON_ONCE(S_ISREG(inode->i_mode) &&
-		     !mutex_is_locked(&inode->i_mutex));
+		     !inode_is_locked(inode));
 	down_write(&EXT4_I(inode)->i_data_sem);
 	if (newsize > EXT4_I(inode)->i_disksize)
 		EXT4_I(inode)->i_disksize = newsize;
* Unmerged path fs/ext4/extents.c
* Unmerged path fs/ext4/file.c
* Unmerged path fs/ext4/inode.c
* Unmerged path fs/ext4/ioctl.c
diff --git a/fs/ext4/namei.c b/fs/ext4/namei.c
index 0738842d53b3..dbeadfd3a0d1 100644
--- a/fs/ext4/namei.c
+++ b/fs/ext4/namei.c
@@ -2532,7 +2532,7 @@ int ext4_orphan_add(handle_t *handle, struct inode *inode)
 		return 0;
 
 	WARN_ON_ONCE(!(inode->i_state & (I_NEW | I_FREEING)) &&
-		     !mutex_is_locked(&inode->i_mutex));
+		     !inode_is_locked(inode));
 	/*
 	 * Exit early if inode already is on orphan list. This is a big speedup
 	 * since we don't have to contend on the global s_orphan_lock.
@@ -2614,7 +2614,7 @@ int ext4_orphan_del(handle_t *handle, struct inode *inode)
 		return 0;
 
 	WARN_ON_ONCE(!(inode->i_state & (I_NEW | I_FREEING)) &&
-		     !mutex_is_locked(&inode->i_mutex));
+		     !inode_is_locked(inode));
 	/* Do this quick check before taking global s_orphan_lock. */
 	if (list_empty(&ei->i_orphan))
 		return 0;
diff --git a/fs/ext4/super.c b/fs/ext4/super.c
index 8a6f058f1768..85f605fe90e1 100644
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@ -2287,10 +2287,10 @@ static void ext4_orphan_cleanup(struct super_block *sb,
 					__func__, inode->i_ino, inode->i_size);
 			jbd_debug(2, "truncating inode %lu to %lld bytes\n",
 				  inode->i_ino, inode->i_size);
-			mutex_lock(&inode->i_mutex);
+			inode_lock(inode);
 			truncate_inode_pages(inode->i_mapping, inode->i_size);
 			ext4_truncate(inode);
-			mutex_unlock(&inode->i_mutex);
+			inode_unlock(inode);
 			nr_truncates++;
 		} else {
 			if (test_opt(sb, DEBUG))
* Unmerged path fs/f2fs/data.c
* Unmerged path fs/f2fs/file.c
* Unmerged path fs/fat/dir.c
* Unmerged path fs/fat/file.c
* Unmerged path fs/fuse/dir.c
* Unmerged path fs/fuse/file.c
diff --git a/fs/gfs2/file.c b/fs/gfs2/file.c
index af0d418da809..2ef146efcbbc 100644
--- a/fs/gfs2/file.c
+++ b/fs/gfs2/file.c
@@ -925,7 +925,7 @@ static long gfs2_fallocate(struct file *file, int mode, loff_t offset, loff_t le
 	if ((mode & ~FALLOC_FL_KEEP_SIZE) || gfs2_is_jdata(ip))
 		return -EOPNOTSUPP;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	gfs2_holder_init(ip->i_gl, LM_ST_EXCLUSIVE, 0, &gh);
 	ret = gfs2_glock_nq(&gh);
@@ -957,7 +957,7 @@ out_unlock:
 	gfs2_glock_dq(&gh);
 out_uninit:
 	gfs2_holder_uninit(&gh);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return ret;
 }
 
diff --git a/fs/gfs2/inode.c b/fs/gfs2/inode.c
index 82106f9575e9..e31d88b8b9f0 100644
--- a/fs/gfs2/inode.c
+++ b/fs/gfs2/inode.c
@@ -2011,7 +2011,7 @@ static int gfs2_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 	if (ret)
 		return ret;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	ret = gfs2_glock_nq_init(ip->i_gl, LM_ST_SHARED, 0, &gh);
 	if (ret)
@@ -2038,7 +2038,7 @@ static int gfs2_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 
 	gfs2_glock_dq_uninit(&gh);
 out:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return ret;
 }
 
diff --git a/fs/gfs2/quota.c b/fs/gfs2/quota.c
index e3f54b09777d..d0f2980db6c1 100644
--- a/fs/gfs2/quota.c
+++ b/fs/gfs2/quota.c
@@ -879,7 +879,7 @@ static int do_sync(unsigned int num_qd, struct gfs2_quota_data **qda)
 		return -ENOMEM;
 
 	sort(qda, num_qd, sizeof(struct gfs2_quota_data *), sort_qd, NULL);
-	mutex_lock(&ip->i_inode.i_mutex);
+	inode_lock(&ip->i_inode);
 	for (qx = 0; qx < num_qd; qx++) {
 		error = gfs2_glock_nq_init(qda[qx]->qd_gl, LM_ST_EXCLUSIVE,
 					   GL_NOCACHE, &ghs[qx]);
@@ -944,7 +944,7 @@ out_alloc:
 out:
 	while (qx--)
 		gfs2_glock_dq_uninit(&ghs[qx]);
-	mutex_unlock(&ip->i_inode.i_mutex);
+	inode_unlock(&ip->i_inode);
 	kfree(ghs);
 	gfs2_log_flush(ip->i_gl->gl_name.ln_sbd, ip->i_gl);
 	return error;
@@ -1676,7 +1676,7 @@ static int gfs2_set_dqblk(struct super_block *sb, struct kqid qid,
 	if (error)
 		goto out_put;
 
-	mutex_lock(&ip->i_inode.i_mutex);
+	inode_lock(&ip->i_inode);
 	error = gfs2_glock_nq_init(qd->qd_gl, LM_ST_EXCLUSIVE, 0, &q_gh);
 	if (error)
 		goto out_unlockput;
@@ -1741,7 +1741,7 @@ out_i:
 out_q:
 	gfs2_glock_dq_uninit(&q_gh);
 out_unlockput:
-	mutex_unlock(&ip->i_inode.i_mutex);
+	inode_unlock(&ip->i_inode);
 out_put:
 	qd_put(qd);
 	return error;
diff --git a/fs/hfs/dir.c b/fs/hfs/dir.c
index e0101b6fb0d7..e11666bf572f 100644
--- a/fs/hfs/dir.c
+++ b/fs/hfs/dir.c
@@ -176,9 +176,9 @@ static int hfs_dir_release(struct inode *inode, struct file *file)
 {
 	struct hfs_readdir_data *rd = file->private_data;
 	if (rd) {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		list_del(&rd->list);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 		kfree(rd);
 	}
 	return 0;
diff --git a/fs/hfs/inode.c b/fs/hfs/inode.c
index 9e2fecd62f62..93ad87747f57 100644
--- a/fs/hfs/inode.c
+++ b/fs/hfs/inode.c
@@ -570,13 +570,13 @@ static int hfs_file_release(struct inode *inode, struct file *file)
 	if (HFS_IS_RSRC(inode))
 		inode = HFS_I(inode)->rsrc_inode;
 	if (atomic_dec_and_test(&HFS_I(inode)->opencnt)) {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		hfs_file_truncate(inode);
 		//if (inode->i_flags & S_DEAD) {
 		//	hfs_delete_cat(inode->i_ino, HFSPLUS_SB(sb).hidden_dir, NULL);
 		//	hfs_delete_inode(inode);
 		//}
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 	}
 	return 0;
 }
@@ -656,7 +656,7 @@ static int hfs_file_fsync(struct file *filp, loff_t start, loff_t end,
 	ret = filemap_write_and_wait_range(inode->i_mapping, start, end);
 	if (ret)
 		return ret;
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	/* sync the inode to buffers */
 	ret = write_inode_now(inode, 0);
@@ -668,7 +668,7 @@ static int hfs_file_fsync(struct file *filp, loff_t start, loff_t end,
 	err = sync_blockdev(sb->s_bdev);
 	if (!ret)
 		ret = err;
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return ret;
 }
 
diff --git a/fs/hfsplus/dir.c b/fs/hfsplus/dir.c
index a37ac934732f..78828f8deb95 100644
--- a/fs/hfsplus/dir.c
+++ b/fs/hfsplus/dir.c
@@ -257,9 +257,9 @@ static int hfsplus_dir_release(struct inode *inode, struct file *file)
 {
 	struct hfsplus_readdir_data *rd = file->private_data;
 	if (rd) {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		list_del(&rd->list);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 		kfree(rd);
 	}
 	return 0;
diff --git a/fs/hfsplus/inode.c b/fs/hfsplus/inode.c
index 4b4ae8ccc6dc..1c151efc95bb 100644
--- a/fs/hfsplus/inode.c
+++ b/fs/hfsplus/inode.c
@@ -286,14 +286,14 @@ static int hfsplus_file_release(struct inode *inode, struct file *file)
 	if (HFSPLUS_IS_RSRC(inode))
 		inode = HFSPLUS_I(inode)->rsrc_inode;
 	if (atomic_dec_and_test(&HFSPLUS_I(inode)->opencnt)) {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		hfsplus_file_truncate(inode);
 		if (inode->i_flags & S_DEAD) {
 			hfsplus_delete_cat(inode->i_ino,
 					   HFSPLUS_SB(sb)->hidden_dir, NULL);
 			hfsplus_delete_inode(inode);
 		}
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 	}
 	return 0;
 }
@@ -330,7 +330,7 @@ int hfsplus_file_fsync(struct file *file, loff_t start, loff_t end,
 	error = filemap_write_and_wait_range(inode->i_mapping, start, end);
 	if (error)
 		return error;
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	/*
 	 * Sync inode metadata into the catalog and extent trees.
@@ -371,7 +371,7 @@ int hfsplus_file_fsync(struct file *file, loff_t start, loff_t end,
 	if (!test_bit(HFSPLUS_SB_NOBARRIER, &sbi->flags))
 		blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL, NULL);
 
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	return error;
 }
diff --git a/fs/hfsplus/ioctl.c b/fs/hfsplus/ioctl.c
index d3ff5cc317d7..4e36ce35d1ec 100644
--- a/fs/hfsplus/ioctl.c
+++ b/fs/hfsplus/ioctl.c
@@ -93,7 +93,7 @@ static int hfsplus_ioctl_setflags(struct file *file, int __user *user_flags)
 		goto out_drop_write;
 	}
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	if ((flags & (FS_IMMUTABLE_FL|FS_APPEND_FL)) ||
 	    inode->i_flags & (S_IMMUTABLE|S_APPEND)) {
@@ -128,7 +128,7 @@ static int hfsplus_ioctl_setflags(struct file *file, int __user *user_flags)
 	mark_inode_dirty(inode);
 
 out_unlock_inode:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 out_drop_write:
 	mnt_drop_write_file(file);
 out:
diff --git a/fs/hostfs/hostfs_kern.c b/fs/hostfs/hostfs_kern.c
index 208e6f79ce7a..368d4b40c88c 100644
--- a/fs/hostfs/hostfs_kern.c
+++ b/fs/hostfs/hostfs_kern.c
@@ -371,9 +371,9 @@ int hostfs_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 	if (ret)
 		return ret;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	ret = fsync_file(HOSTFS_I(inode)->fd, datasync);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	return ret;
 }
diff --git a/fs/hpfs/dir.c b/fs/hpfs/dir.c
index 834ac13c04b7..fbd5a5ebcb39 100644
--- a/fs/hpfs/dir.c
+++ b/fs/hpfs/dir.c
@@ -33,7 +33,7 @@ static loff_t hpfs_dir_lseek(struct file *filp, loff_t off, int whence)
 	if (whence == SEEK_DATA || whence == SEEK_HOLE)
 		return -EINVAL;
 
-	mutex_lock(&i->i_mutex);
+	inode_lock(i);
 	hpfs_lock(s);
 
 	/*printk("dir lseek\n");*/
@@ -48,12 +48,12 @@ static loff_t hpfs_dir_lseek(struct file *filp, loff_t off, int whence)
 ok:
 	filp->f_pos = new_off;
 	hpfs_unlock(s);
-	mutex_unlock(&i->i_mutex);
+	inode_unlock(i);
 	return new_off;
 fail:
 	/*printk("illegal lseek: %016llx\n", new_off);*/
 	hpfs_unlock(s);
-	mutex_unlock(&i->i_mutex);
+	inode_unlock(i);
 	return -ESPIPE;
 }
 
* Unmerged path fs/hugetlbfs/inode.c
diff --git a/fs/inode.c b/fs/inode.c
index 50ca9758e8ff..3fef256f1ef0 100644
--- a/fs/inode.c
+++ b/fs/inode.c
@@ -1006,9 +1006,9 @@ void lock_two_nondirectories(struct inode *inode1, struct inode *inode2)
 		swap(inode1, inode2);
 
 	if (inode1 && !S_ISDIR(inode1->i_mode))
-		mutex_lock(&inode1->i_mutex);
+		inode_lock(inode1);
 	if (inode2 && !S_ISDIR(inode2->i_mode) && inode2 != inode1)
-		mutex_lock_nested(&inode2->i_mutex, I_MUTEX_NONDIR2);
+		inode_lock_nested(inode2, I_MUTEX_NONDIR2);
 }
 EXPORT_SYMBOL(lock_two_nondirectories);
 
@@ -1020,9 +1020,9 @@ EXPORT_SYMBOL(lock_two_nondirectories);
 void unlock_two_nondirectories(struct inode *inode1, struct inode *inode2)
 {
 	if (inode1 && !S_ISDIR(inode1->i_mode))
-		mutex_unlock(&inode1->i_mutex);
+		inode_unlock(inode1);
 	if (inode2 && !S_ISDIR(inode2->i_mode) && inode2 != inode1)
-		mutex_unlock(&inode2->i_mutex);
+		inode_unlock(inode2);
 }
 EXPORT_SYMBOL(unlock_two_nondirectories);
 
diff --git a/fs/ioctl.c b/fs/ioctl.c
index dea5a20610a4..015080083d1d 100644
--- a/fs/ioctl.c
+++ b/fs/ioctl.c
@@ -406,9 +406,9 @@ int generic_block_fiemap(struct inode *inode,
 			 u64 len, get_block_t *get_block)
 {
 	int ret;
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	ret = __generic_block_fiemap(inode, fieinfo, start, len, get_block);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return ret;
 }
 EXPORT_SYMBOL(generic_block_fiemap);
diff --git a/fs/jffs2/file.c b/fs/jffs2/file.c
index 1506673c087e..256094422901 100644
--- a/fs/jffs2/file.c
+++ b/fs/jffs2/file.c
@@ -39,10 +39,10 @@ int jffs2_fsync(struct file *filp, loff_t start, loff_t end, int datasync)
 	if (ret)
 		return ret;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	/* Trigger GC to flush any pending writes for this inode */
 	jffs2_flush_wbuf_gc(c, inode->i_ino);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	return 0;
 }
* Unmerged path fs/jfs/file.c
diff --git a/fs/jfs/ioctl.c b/fs/jfs/ioctl.c
index 93a1232894f6..97ca997466fb 100644
--- a/fs/jfs/ioctl.c
+++ b/fs/jfs/ioctl.c
@@ -96,7 +96,7 @@ long jfs_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 		}
 
 		/* Lock against other parallel changes of flags */
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 
 		jfs_get_inode_flags(jfs_inode);
 		oldflags = jfs_inode->mode2;
@@ -109,7 +109,7 @@ long jfs_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 			((flags ^ oldflags) &
 			(JFS_APPEND_FL | JFS_IMMUTABLE_FL))) {
 			if (!capable(CAP_LINUX_IMMUTABLE)) {
-				mutex_unlock(&inode->i_mutex);
+				inode_unlock(inode);
 				err = -EPERM;
 				goto setflags_out;
 			}
@@ -120,7 +120,7 @@ long jfs_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
 		jfs_inode->mode2 = flags;
 
 		jfs_set_inode_flags(inode);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 		inode->i_ctime = CURRENT_TIME_SEC;
 		mark_inode_dirty(inode);
 setflags_out:
diff --git a/fs/jfs/super.c b/fs/jfs/super.c
index 788e0a9c1fb0..725d8ed202b9 100644
--- a/fs/jfs/super.c
+++ b/fs/jfs/super.c
@@ -777,7 +777,7 @@ static ssize_t jfs_quota_write(struct super_block *sb, int type,
 	struct buffer_head tmp_bh;
 	struct buffer_head *bh;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	while (towrite > 0) {
 		tocopy = sb->s_blocksize - offset < towrite ?
 				sb->s_blocksize - offset : towrite;
@@ -809,7 +809,7 @@ static ssize_t jfs_quota_write(struct super_block *sb, int type,
 	}
 out:
 	if (len == towrite) {
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 		return err;
 	}
 	if (inode->i_size < off+len-towrite)
@@ -817,7 +817,7 @@ out:
 	inode->i_version++;
 	inode->i_mtime = inode->i_ctime = CURRENT_TIME;
 	mark_inode_dirty(inode);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return len - towrite;
 }
 
* Unmerged path fs/kernfs/dir.c
* Unmerged path fs/libfs.c
* Unmerged path fs/locks.c
diff --git a/fs/logfs/file.c b/fs/logfs/file.c
index c2219a6dd3c8..3086d67fa61c 100644
--- a/fs/logfs/file.c
+++ b/fs/logfs/file.c
@@ -203,12 +203,12 @@ long logfs_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 		if (err)
 			return err;
 
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		oldflags = li->li_flags;
 		flags &= LOGFS_FL_USER_MODIFIABLE;
 		flags |= oldflags & ~LOGFS_FL_USER_MODIFIABLE;
 		li->li_flags = flags;
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 
 		inode->i_ctime = CURRENT_TIME;
 		mark_inode_dirty_sync(inode);
@@ -229,11 +229,11 @@ int logfs_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 	if (ret)
 		return ret;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	logfs_get_wblocks(sb, NULL, WF_LOCK);
 	logfs_write_anchor(sb);
 	logfs_put_wblocks(sb, NULL, WF_LOCK);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	return 0;
 }
* Unmerged path fs/namei.c
diff --git a/fs/namespace.c b/fs/namespace.c
index 9440b6a5a3d4..db54320cccdf 100644
--- a/fs/namespace.c
+++ b/fs/namespace.c
@@ -1667,9 +1667,9 @@ static struct mountpoint *lock_mount(struct path *path)
 	struct vfsmount *mnt;
 	struct dentry *dentry = path->dentry;
 retry:
-	mutex_lock(&dentry->d_inode->i_mutex);
+	inode_lock(dentry->d_inode);
 	if (unlikely(cant_mount(dentry))) {
-		mutex_unlock(&dentry->d_inode->i_mutex);
+		inode_unlock(dentry->d_inode);
 		return ERR_PTR(-ENOENT);
 	}
 	namespace_lock();
@@ -1678,13 +1678,13 @@ retry:
 		struct mountpoint *mp = new_mountpoint(dentry);
 		if (IS_ERR(mp)) {
 			namespace_unlock();
-			mutex_unlock(&dentry->d_inode->i_mutex);
+			inode_unlock(dentry->d_inode);
 			return mp;
 		}
 		return mp;
 	}
 	namespace_unlock();
-	mutex_unlock(&path->dentry->d_inode->i_mutex);
+	inode_unlock(path->dentry->d_inode);
 	path_put(path);
 	path->mnt = mnt;
 	dentry = path->dentry = dget(mnt->mnt_root);
@@ -1696,7 +1696,7 @@ static void unlock_mount(struct mountpoint *where)
 	struct dentry *dentry = where->m_dentry;
 	put_mountpoint(where);
 	namespace_unlock();
-	mutex_unlock(&dentry->d_inode->i_mutex);
+	inode_unlock(dentry->d_inode);
 }
 
 static int graft_tree(struct mount *mnt, struct mount *p, struct mountpoint *mp)
diff --git a/fs/ncpfs/dir.c b/fs/ncpfs/dir.c
index dd8190ae891c..859efe216fac 100644
--- a/fs/ncpfs/dir.c
+++ b/fs/ncpfs/dir.c
@@ -368,7 +368,7 @@ ncp_lookup_validate(struct dentry *dentry, unsigned int flags)
 	if (!res) {
 		struct inode *inode = dentry->d_inode;
 
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		if (finfo.i.dirEntNum == NCP_FINFO(inode)->dirEntNum) {
 			ncp_new_dentry(dentry);
 			val=1;
@@ -376,7 +376,7 @@ ncp_lookup_validate(struct dentry *dentry, unsigned int flags)
 			DDPRINTK("ncp_lookup_validate: found, but dirEntNum changed\n");
 
 		ncp_update_inode2(inode, &finfo);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 	}
 
 finished:
@@ -649,9 +649,9 @@ ncp_fill_cache(struct file *filp, void *dirent, filldir_t filldir,
 	} else {
 		struct inode *inode = newdent->d_inode;
 
-		mutex_lock_nested(&inode->i_mutex, I_MUTEX_CHILD);
+		inode_lock_nested(inode, I_MUTEX_CHILD);
 		ncp_update_inode2(inode, entry);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 	}
 
 	if (newdent->d_inode) {
diff --git a/fs/ncpfs/file.c b/fs/ncpfs/file.c
index 122e260247f5..47862b2339bf 100644
--- a/fs/ncpfs/file.c
+++ b/fs/ncpfs/file.c
@@ -259,10 +259,10 @@ ncp_file_write(struct file *file, const char __user *buf, size_t count, loff_t *
 	*ppos = pos;
 
 	if (pos > i_size_read(inode)) {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		if (pos > i_size_read(inode))
 			i_size_write(inode, pos);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 	}
 	DPRINTK("ncp_file_write: exit %s/%s\n",
 		dentry->d_parent->d_name.name, dentry->d_name.name);
diff --git a/fs/nfs/dir.c b/fs/nfs/dir.c
index 770fe7b74079..f3e23f978524 100644
--- a/fs/nfs/dir.c
+++ b/fs/nfs/dir.c
@@ -943,7 +943,7 @@ static loff_t nfs_llseek_dir(struct file *filp, loff_t offset, int whence)
 	dfprintk(FILE, "NFS: llseek dir(%pD2, %lld, %d)\n",
 			filp, offset, whence);
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	switch (whence) {
 		case 1:
 			offset += filp->f_pos;
@@ -960,7 +960,7 @@ static loff_t nfs_llseek_dir(struct file *filp, loff_t offset, int whence)
 		dir_ctx->duped = 0;
 	}
 out:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return offset;
 }
 
@@ -975,9 +975,9 @@ static int nfs_fsync_dir(struct file *filp, loff_t start, loff_t end,
 
 	dfprintk(FILE, "NFS: fsync dir(%pD2) datasync %d\n", filp, datasync);
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	nfs_inc_stats(inode, NFSIOS_VFSFSYNC);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return 0;
 }
 
* Unmerged path fs/nfs/direct.c
diff --git a/fs/nfs/file.c b/fs/nfs/file.c
index c497ac465f2a..1eec7d8030cb 100644
--- a/fs/nfs/file.c
+++ b/fs/nfs/file.c
@@ -280,9 +280,9 @@ nfs_file_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 		ret = filemap_write_and_wait_range(inode->i_mapping, start, end);
 		if (ret != 0)
 			break;
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		ret = nfs_file_fsync_commit(file, start, end, datasync);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 		/*
 		 * If nfs_file_fsync_commit detected a server reboot, then
 		 * resend all dirty pages that might have been covered by
diff --git a/fs/nfs/inode.c b/fs/nfs/inode.c
index f056e9789b3f..15b82e4ece10 100644
--- a/fs/nfs/inode.c
+++ b/fs/nfs/inode.c
@@ -656,9 +656,9 @@ int nfs_getattr(struct vfsmount *mnt, struct dentry *dentry, struct kstat *stat)
 	trace_nfs_getattr_enter(inode);
 	/* Flush out writes to the server in order to update c/mtime.  */
 	if (S_ISREG(inode->i_mode)) {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		err = nfs_sync_inode(inode);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 		if (err)
 			goto out;
 	}
@@ -1152,9 +1152,9 @@ static int __nfs_revalidate_mapping(struct inode *inode,
 	spin_unlock(&inode->i_lock);
 	trace_nfs_invalidate_mapping_enter(inode);
 	if (may_lock) {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		ret = nfs_invalidate_mapping(inode, mapping);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 	} else
 		ret = nfs_invalidate_mapping(inode, mapping);
 	trace_nfs_invalidate_mapping_exit(inode, ret);
diff --git a/fs/nfs/nfs42proc.c b/fs/nfs/nfs42proc.c
index 923864bebddf..192864ea549d 100644
--- a/fs/nfs/nfs42proc.c
+++ b/fs/nfs/nfs42proc.c
@@ -92,13 +92,13 @@ int nfs42_proc_allocate(struct file *filep, loff_t offset, loff_t len)
 	if (!nfs_server_capable(inode, NFS_CAP_ALLOCATE))
 		return -EOPNOTSUPP;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	err = nfs42_proc_fallocate(&msg, filep, offset, len);
 	if (err == -EOPNOTSUPP)
 		NFS_SERVER(inode)->caps &= ~NFS_CAP_ALLOCATE;
 
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return err;
 }
 
@@ -114,7 +114,7 @@ int nfs42_proc_deallocate(struct file *filep, loff_t offset, loff_t len)
 		return -EOPNOTSUPP;
 
 	nfs_wb_all(inode);
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	err = nfs42_proc_fallocate(&msg, filep, offset, len);
 	if (err == 0)
@@ -122,7 +122,7 @@ int nfs42_proc_deallocate(struct file *filep, loff_t offset, loff_t len)
 	if (err == -EOPNOTSUPP)
 		NFS_SERVER(inode)->caps &= ~NFS_CAP_DEALLOCATE;
 
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return err;
 }
 
diff --git a/fs/nfs/nfs4file.c b/fs/nfs/nfs4file.c
index ea8125acbd96..14e15e9d9b33 100644
--- a/fs/nfs/nfs4file.c
+++ b/fs/nfs/nfs4file.c
@@ -141,11 +141,11 @@ nfs4_file_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 		ret = filemap_write_and_wait_range(inode->i_mapping, start, end);
 		if (ret != 0)
 			break;
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		ret = nfs_file_fsync_commit(file, start, end, datasync);
 		if (!ret)
 			ret = pnfs_sync_inode(inode, !!datasync);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 		/*
 		 * If nfs_file_fsync_commit detected a server reboot, then
 		 * resend all dirty pages that might have been covered by
@@ -257,13 +257,13 @@ nfs42_ioctl_clone(struct file *dst_file, unsigned long srcfd,
 
 	/* XXX: do we lock at all? what if server needs CB_RECALL_LAYOUT? */
 	if (same_inode) {
-		mutex_lock(&src_inode->i_mutex);
+		inode_lock(src_inode);
 	} else if (dst_inode < src_inode) {
-		mutex_lock_nested(&dst_inode->i_mutex, I_MUTEX_PARENT);
-		mutex_lock_nested(&src_inode->i_mutex, I_MUTEX_CHILD);
+		inode_lock_nested(dst_inode, I_MUTEX_PARENT);
+		inode_lock_nested(src_inode, I_MUTEX_CHILD);
 	} else {
-		mutex_lock_nested(&src_inode->i_mutex, I_MUTEX_PARENT);
-		mutex_lock_nested(&dst_inode->i_mutex, I_MUTEX_CHILD);
+		inode_lock_nested(src_inode, I_MUTEX_PARENT);
+		inode_lock_nested(dst_inode, I_MUTEX_CHILD);
 	}
 
 	/* flush all pending writes on both src and dst so that server
@@ -284,13 +284,13 @@ nfs42_ioctl_clone(struct file *dst_file, unsigned long srcfd,
 
 out_unlock:
 	if (same_inode) {
-		mutex_unlock(&src_inode->i_mutex);
+		inode_unlock(src_inode);
 	} else if (dst_inode < src_inode) {
-		mutex_unlock(&src_inode->i_mutex);
-		mutex_unlock(&dst_inode->i_mutex);
+		inode_unlock(src_inode);
+		inode_unlock(dst_inode);
 	} else {
-		mutex_unlock(&dst_inode->i_mutex);
-		mutex_unlock(&src_inode->i_mutex);
+		inode_unlock(dst_inode);
+		inode_unlock(src_inode);
 	}
 out_fput:
 	fdput(src_file);
diff --git a/fs/nfsd/nfs4proc.c b/fs/nfsd/nfs4proc.c
index 355774c4c646..c09590d82f8b 100644
--- a/fs/nfsd/nfs4proc.c
+++ b/fs/nfsd/nfs4proc.c
@@ -54,10 +54,10 @@ nfsd4_security_inode_setsecctx(struct svc_fh *resfh, struct xdr_netobj *label, u
 	struct inode *inode = resfh->fh_dentry->d_inode;
 	int status;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	status = security_inode_setsecctx(resfh->fh_dentry,
 		label->data, label->len);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	if (status)
 		/*
* Unmerged path fs/nfsd/nfs4recover.c
* Unmerged path fs/nfsd/nfsfh.h
* Unmerged path fs/nfsd/vfs.c
diff --git a/fs/nilfs2/inode.c b/fs/nilfs2/inode.c
index 4fcb0d232962..9e233f829c26 100644
--- a/fs/nilfs2/inode.c
+++ b/fs/nilfs2/inode.c
@@ -998,7 +998,7 @@ int nilfs_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 	if (ret)
 		return ret;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	isize = i_size_read(inode);
 
@@ -1108,6 +1108,6 @@ int nilfs_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 	if (ret == 1)
 		ret = 0;
 
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return ret;
 }
diff --git a/fs/nilfs2/ioctl.c b/fs/nilfs2/ioctl.c
index b44bdb291b84..fbfe7c0ed99f 100644
--- a/fs/nilfs2/ioctl.c
+++ b/fs/nilfs2/ioctl.c
@@ -125,7 +125,7 @@ static int nilfs_ioctl_setflags(struct inode *inode, struct file *filp,
 
 	flags = nilfs_mask_flags(inode->i_mode, flags);
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	oldflags = NILFS_I(inode)->i_flags;
 
@@ -153,7 +153,7 @@ static int nilfs_ioctl_setflags(struct inode *inode, struct file *filp,
 	nilfs_mark_inode_dirty(inode);
 	ret = nilfs_transaction_commit(inode->i_sb);
 out:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	mnt_drop_write_file(filp);
 	return ret;
 }
diff --git a/fs/ntfs/dir.c b/fs/ntfs/dir.c
index aa411c3f20e9..0f0a4d92189a 100644
--- a/fs/ntfs/dir.c
+++ b/fs/ntfs/dir.c
@@ -1539,7 +1539,7 @@ static int ntfs_dir_fsync(struct file *filp, loff_t start, loff_t end,
 	err = filemap_write_and_wait_range(vi->i_mapping, start, end);
 	if (err)
 		return err;
-	mutex_lock(&vi->i_mutex);
+	inode_lock(vi);
 
 	BUG_ON(!S_ISDIR(vi->i_mode));
 	/* If the bitmap attribute inode is in memory sync it, too. */
@@ -1562,7 +1562,7 @@ static int ntfs_dir_fsync(struct file *filp, loff_t start, loff_t end,
 	else
 		ntfs_warning(vi->i_sb, "Failed to f%ssync inode 0x%lx.  Error "
 				"%u.", datasync ? "data" : "", vi->i_ino, -ret);
-	mutex_unlock(&vi->i_mutex);
+	inode_unlock(vi);
 	return ret;
 }
 
* Unmerged path fs/ntfs/file.c
diff --git a/fs/ntfs/quota.c b/fs/ntfs/quota.c
index d80e3315cab0..9793e68ba1dd 100644
--- a/fs/ntfs/quota.c
+++ b/fs/ntfs/quota.c
@@ -48,7 +48,7 @@ bool ntfs_mark_quotas_out_of_date(ntfs_volume *vol)
 		ntfs_error(vol->sb, "Quota inodes are not open.");
 		return false;
 	}
-	mutex_lock(&vol->quota_q_ino->i_mutex);
+	inode_lock(vol->quota_q_ino);
 	ictx = ntfs_index_ctx_get(NTFS_I(vol->quota_q_ino));
 	if (!ictx) {
 		ntfs_error(vol->sb, "Failed to get index context.");
@@ -98,7 +98,7 @@ bool ntfs_mark_quotas_out_of_date(ntfs_volume *vol)
 	ntfs_index_entry_mark_dirty(ictx);
 set_done:
 	ntfs_index_ctx_put(ictx);
-	mutex_unlock(&vol->quota_q_ino->i_mutex);
+	inode_unlock(vol->quota_q_ino);
 	/*
 	 * We set the flag so we do not try to mark the quotas out of date
 	 * again on remount.
@@ -110,7 +110,7 @@ done:
 err_out:
 	if (ictx)
 		ntfs_index_ctx_put(ictx);
-	mutex_unlock(&vol->quota_q_ino->i_mutex);
+	inode_unlock(vol->quota_q_ino);
 	return false;
 }
 
diff --git a/fs/ntfs/super.c b/fs/ntfs/super.c
index 82650d52d916..eb82969f1d48 100644
--- a/fs/ntfs/super.c
+++ b/fs/ntfs/super.c
@@ -1281,10 +1281,10 @@ static int check_windows_hibernation_status(ntfs_volume *vol)
 	 * Find the inode number for the hibernation file by looking up the
 	 * filename hiberfil.sys in the root directory.
 	 */
-	mutex_lock(&vol->root_ino->i_mutex);
+	inode_lock(vol->root_ino);
 	mref = ntfs_lookup_inode_by_name(NTFS_I(vol->root_ino), hiberfil, 12,
 			&name);
-	mutex_unlock(&vol->root_ino->i_mutex);
+	inode_unlock(vol->root_ino);
 	if (IS_ERR_MREF(mref)) {
 		ret = MREF_ERR(mref);
 		/* If the file does not exist, Windows is not hibernated. */
@@ -1374,10 +1374,10 @@ static bool load_and_init_quota(ntfs_volume *vol)
 	 * Find the inode number for the quota file by looking up the filename
 	 * $Quota in the extended system files directory $Extend.
 	 */
-	mutex_lock(&vol->extend_ino->i_mutex);
+	inode_lock(vol->extend_ino);
 	mref = ntfs_lookup_inode_by_name(NTFS_I(vol->extend_ino), Quota, 6,
 			&name);
-	mutex_unlock(&vol->extend_ino->i_mutex);
+	inode_unlock(vol->extend_ino);
 	if (IS_ERR_MREF(mref)) {
 		/*
 		 * If the file does not exist, quotas are disabled and have
@@ -1457,10 +1457,10 @@ static bool load_and_init_usnjrnl(ntfs_volume *vol)
 	 * Find the inode number for the transaction log file by looking up the
 	 * filename $UsnJrnl in the extended system files directory $Extend.
 	 */
-	mutex_lock(&vol->extend_ino->i_mutex);
+	inode_lock(vol->extend_ino);
 	mref = ntfs_lookup_inode_by_name(NTFS_I(vol->extend_ino), UsnJrnl, 8,
 			&name);
-	mutex_unlock(&vol->extend_ino->i_mutex);
+	inode_unlock(vol->extend_ino);
 	if (IS_ERR_MREF(mref)) {
 		/*
 		 * If the file does not exist, transaction logging is disabled,
* Unmerged path fs/ocfs2/alloc.c
diff --git a/fs/ocfs2/aops.c b/fs/ocfs2/aops.c
index 7fee7b2e1225..b826d3801110 100644
--- a/fs/ocfs2/aops.c
+++ b/fs/ocfs2/aops.c
@@ -1678,9 +1678,9 @@ static int ocfs2_try_to_free_truncate_log(struct ocfs2_super *osb,
 	int ret = 0;
 	unsigned int truncated_clusters;
 
-	mutex_lock(&osb->osb_tl_inode->i_mutex);
+	inode_lock(osb->osb_tl_inode);
 	truncated_clusters = osb->truncated_clusters;
-	mutex_unlock(&osb->osb_tl_inode->i_mutex);
+	inode_unlock(osb->osb_tl_inode);
 
 	/*
 	 * Check whether we can succeed in allocating if we free
diff --git a/fs/ocfs2/dir.c b/fs/ocfs2/dir.c
index f1e1aed8f638..6bf89af9e9ba 100644
--- a/fs/ocfs2/dir.c
+++ b/fs/ocfs2/dir.c
@@ -4427,7 +4427,7 @@ static int ocfs2_dx_dir_remove_index(struct inode *dir,
 		mlog_errno(ret);
 		goto out;
 	}
-	mutex_lock(&dx_alloc_inode->i_mutex);
+	inode_lock(dx_alloc_inode);
 
 	ret = ocfs2_inode_lock(dx_alloc_inode, &dx_alloc_bh, 1);
 	if (ret) {
@@ -4475,7 +4475,7 @@ out_unlock:
 	ocfs2_inode_unlock(dx_alloc_inode, 1);
 
 out_mutex:
-	mutex_unlock(&dx_alloc_inode->i_mutex);
+	inode_unlock(dx_alloc_inode);
 	brelse(dx_alloc_bh);
 out:
 	iput(dx_alloc_inode);
* Unmerged path fs/ocfs2/file.c
diff --git a/fs/ocfs2/inode.c b/fs/ocfs2/inode.c
index f1c46a7f9bc5..afc1cdfba5a8 100644
--- a/fs/ocfs2/inode.c
+++ b/fs/ocfs2/inode.c
@@ -613,10 +613,10 @@ static int ocfs2_remove_inode(struct inode *inode,
 		goto bail;
 	}
 
-	mutex_lock(&inode_alloc_inode->i_mutex);
+	inode_lock(inode_alloc_inode);
 	status = ocfs2_inode_lock(inode_alloc_inode, &inode_alloc_bh, 1);
 	if (status < 0) {
-		mutex_unlock(&inode_alloc_inode->i_mutex);
+		inode_unlock(inode_alloc_inode);
 
 		mlog_errno(status);
 		goto bail;
@@ -663,7 +663,7 @@ bail_commit:
 	ocfs2_commit_trans(osb, handle);
 bail_unlock:
 	ocfs2_inode_unlock(inode_alloc_inode, 1);
-	mutex_unlock(&inode_alloc_inode->i_mutex);
+	inode_unlock(inode_alloc_inode);
 	brelse(inode_alloc_bh);
 bail:
 	iput(inode_alloc_inode);
@@ -734,10 +734,10 @@ static int ocfs2_wipe_inode(struct inode *inode,
 		/* Lock the orphan dir. The lock will be held for the entire
 		 * delete_inode operation. We do this now to avoid races with
 		 * recovery completion on other nodes. */
-		mutex_lock(&orphan_dir_inode->i_mutex);
+		inode_lock(orphan_dir_inode);
 		status = ocfs2_inode_lock(orphan_dir_inode, &orphan_dir_bh, 1);
 		if (status < 0) {
-			mutex_unlock(&orphan_dir_inode->i_mutex);
+			inode_unlock(orphan_dir_inode);
 
 			mlog_errno(status);
 			goto bail;
@@ -786,7 +786,7 @@ bail_unlock_dir:
 		return status;
 
 	ocfs2_inode_unlock(orphan_dir_inode, 1);
-	mutex_unlock(&orphan_dir_inode->i_mutex);
+	inode_unlock(orphan_dir_inode);
 	brelse(orphan_dir_bh);
 bail:
 	iput(orphan_dir_inode);
diff --git a/fs/ocfs2/ioctl.c b/fs/ocfs2/ioctl.c
index 0c60ef2d8056..d0b85153d662 100644
--- a/fs/ocfs2/ioctl.c
+++ b/fs/ocfs2/ioctl.c
@@ -86,7 +86,7 @@ static int ocfs2_set_inode_attr(struct inode *inode, unsigned flags,
 	unsigned oldflags;
 	int status;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	status = ocfs2_inode_lock(inode, &bh, 1);
 	if (status < 0) {
@@ -135,7 +135,7 @@ static int ocfs2_set_inode_attr(struct inode *inode, unsigned flags,
 bail_unlock:
 	ocfs2_inode_unlock(inode, 1);
 bail:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	brelse(bh);
 
@@ -328,7 +328,7 @@ int ocfs2_info_scan_inode_alloc(struct ocfs2_super *osb,
 	struct ocfs2_dinode *dinode_alloc = NULL;
 
 	if (inode_alloc)
-		mutex_lock(&inode_alloc->i_mutex);
+		inode_lock(inode_alloc);
 
 	if (o2info_coherent(&fi->ifi_req)) {
 		status = ocfs2_inode_lock(inode_alloc, &bh, 0);
@@ -358,7 +358,7 @@ bail:
 		ocfs2_inode_unlock(inode_alloc, 0);
 
 	if (inode_alloc)
-		mutex_unlock(&inode_alloc->i_mutex);
+		inode_unlock(inode_alloc);
 
 	brelse(bh);
 
@@ -583,7 +583,7 @@ int ocfs2_info_freefrag_scan_bitmap(struct ocfs2_super *osb,
 	struct ocfs2_dinode *gb_dinode = NULL;
 
 	if (gb_inode)
-		mutex_lock(&gb_inode->i_mutex);
+		inode_lock(gb_inode);
 
 	if (o2info_coherent(&ffg->iff_req)) {
 		status = ocfs2_inode_lock(gb_inode, &bh, 0);
@@ -640,7 +640,7 @@ bail:
 		ocfs2_inode_unlock(gb_inode, 0);
 
 	if (gb_inode)
-		mutex_unlock(&gb_inode->i_mutex);
+		inode_unlock(gb_inode);
 
 	if (gb_inode)
 		iput(gb_inode);
* Unmerged path fs/ocfs2/journal.c
diff --git a/fs/ocfs2/localalloc.c b/fs/ocfs2/localalloc.c
index aebeacd807c3..685cedf11c58 100644
--- a/fs/ocfs2/localalloc.c
+++ b/fs/ocfs2/localalloc.c
@@ -415,7 +415,7 @@ void ocfs2_shutdown_local_alloc(struct ocfs2_super *osb)
 		goto out;
 	}
 
-	mutex_lock(&main_bm_inode->i_mutex);
+	inode_lock(main_bm_inode);
 
 	status = ocfs2_inode_lock(main_bm_inode, &main_bm_bh, 1);
 	if (status < 0) {
@@ -469,7 +469,7 @@ out_unlock:
 	ocfs2_inode_unlock(main_bm_inode, 1);
 
 out_mutex:
-	mutex_unlock(&main_bm_inode->i_mutex);
+	inode_unlock(main_bm_inode);
 	iput(main_bm_inode);
 
 out:
@@ -508,7 +508,7 @@ int ocfs2_begin_local_alloc_recovery(struct ocfs2_super *osb,
 		goto bail;
 	}
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	status = ocfs2_read_inode_block_full(inode, &alloc_bh,
 					     OCFS2_BH_IGNORE_CACHE);
@@ -541,7 +541,7 @@ bail:
 	brelse(alloc_bh);
 
 	if (inode) {
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 		iput(inode);
 	}
 
@@ -573,7 +573,7 @@ int ocfs2_complete_local_alloc_recovery(struct ocfs2_super *osb,
 		goto out;
 	}
 
-	mutex_lock(&main_bm_inode->i_mutex);
+	inode_lock(main_bm_inode);
 
 	status = ocfs2_inode_lock(main_bm_inode, &main_bm_bh, 1);
 	if (status < 0) {
@@ -603,7 +603,7 @@ out_unlock:
 	ocfs2_inode_unlock(main_bm_inode, 1);
 
 out_mutex:
-	mutex_unlock(&main_bm_inode->i_mutex);
+	inode_unlock(main_bm_inode);
 
 	brelse(main_bm_bh);
 
@@ -645,7 +645,7 @@ int ocfs2_reserve_local_alloc_bits(struct ocfs2_super *osb,
 		goto bail;
 	}
 
-	mutex_lock(&local_alloc_inode->i_mutex);
+	inode_lock(local_alloc_inode);
 
 	/*
 	 * We must double check state and allocator bits because
@@ -712,7 +712,7 @@ int ocfs2_reserve_local_alloc_bits(struct ocfs2_super *osb,
 	status = 0;
 bail:
 	if (status < 0 && local_alloc_inode) {
-		mutex_unlock(&local_alloc_inode->i_mutex);
+		inode_unlock(local_alloc_inode);
 		iput(local_alloc_inode);
 	}
 
diff --git a/fs/ocfs2/move_extents.c b/fs/ocfs2/move_extents.c
index f1fc172175b6..15838cf4907e 100644
--- a/fs/ocfs2/move_extents.c
+++ b/fs/ocfs2/move_extents.c
@@ -277,7 +277,7 @@ static int ocfs2_defrag_extent(struct ocfs2_move_extents_context *context,
 	 *	context->data_ac->ac_resv = &OCFS2_I(inode)->ip_la_data_resv;
 	 */
 
-	mutex_lock(&tl_inode->i_mutex);
+	inode_lock(tl_inode);
 
 	if (ocfs2_truncate_log_needs_flush(osb)) {
 		ret = __ocfs2_flush_truncate_log(osb);
@@ -339,7 +339,7 @@ out_commit:
 	ocfs2_commit_trans(osb, handle);
 
 out_unlock_mutex:
-	mutex_unlock(&tl_inode->i_mutex);
+	inode_unlock(tl_inode);
 
 	if (context->data_ac) {
 		ocfs2_free_alloc_context(context->data_ac);
@@ -710,7 +710,7 @@ static int ocfs2_move_extent(struct ocfs2_move_extents_context *context,
 		goto out;
 	}
 
-	mutex_lock(&gb_inode->i_mutex);
+	inode_lock(gb_inode);
 
 	ret = ocfs2_inode_lock(gb_inode, &gb_bh, 1);
 	if (ret) {
@@ -718,7 +718,7 @@ static int ocfs2_move_extent(struct ocfs2_move_extents_context *context,
 		goto out_unlock_gb_mutex;
 	}
 
-	mutex_lock(&tl_inode->i_mutex);
+	inode_lock(tl_inode);
 
 	handle = ocfs2_start_trans(osb, credits);
 	if (IS_ERR(handle)) {
@@ -783,11 +783,11 @@ out_commit:
 	brelse(gd_bh);
 
 out_unlock_tl_inode:
-	mutex_unlock(&tl_inode->i_mutex);
+	inode_unlock(tl_inode);
 
 	ocfs2_inode_unlock(gb_inode, 1);
 out_unlock_gb_mutex:
-	mutex_unlock(&gb_inode->i_mutex);
+	inode_unlock(gb_inode);
 	brelse(gb_bh);
 	iput(gb_inode);
 
@@ -983,7 +983,7 @@ static int ocfs2_move_extents(struct ocfs2_move_extents_context *context)
 	if (ocfs2_is_hard_readonly(osb) || ocfs2_is_soft_readonly(osb))
 		return -EROFS;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	/*
 	 * This prevents concurrent writes from other nodes
@@ -1046,7 +1046,7 @@ out_inode_unlock:
 out_rw_unlock:
 	ocfs2_rw_unlock(inode, 1);
 out:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	return status;
 }
* Unmerged path fs/ocfs2/namei.c
diff --git a/fs/ocfs2/quota_global.c b/fs/ocfs2/quota_global.c
index 332a281f217e..3f9c4ca425e9 100644
--- a/fs/ocfs2/quota_global.c
+++ b/fs/ocfs2/quota_global.c
@@ -307,7 +307,7 @@ int ocfs2_lock_global_qf(struct ocfs2_mem_dqinfo *oinfo, int ex)
 		WARN_ON(bh != oinfo->dqi_gqi_bh);
 	spin_unlock(&dq_data_lock);
 	if (ex) {
-		mutex_lock(&oinfo->dqi_gqinode->i_mutex);
+		inode_lock(oinfo->dqi_gqinode);
 		down_write(&OCFS2_I(oinfo->dqi_gqinode)->ip_alloc_sem);
 	} else {
 		down_read(&OCFS2_I(oinfo->dqi_gqinode)->ip_alloc_sem);
@@ -319,7 +319,7 @@ void ocfs2_unlock_global_qf(struct ocfs2_mem_dqinfo *oinfo, int ex)
 {
 	if (ex) {
 		up_write(&OCFS2_I(oinfo->dqi_gqinode)->ip_alloc_sem);
-		mutex_unlock(&oinfo->dqi_gqinode->i_mutex);
+		inode_unlock(oinfo->dqi_gqinode);
 	} else {
 		up_read(&OCFS2_I(oinfo->dqi_gqinode)->ip_alloc_sem);
 	}
* Unmerged path fs/ocfs2/refcounttree.c
diff --git a/fs/ocfs2/resize.c b/fs/ocfs2/resize.c
index ec55add7604a..0ae7ad9dadb8 100644
--- a/fs/ocfs2/resize.c
+++ b/fs/ocfs2/resize.c
@@ -298,7 +298,7 @@ int ocfs2_group_extend(struct inode * inode, int new_clusters)
 		goto out;
 	}
 
-	mutex_lock(&main_bm_inode->i_mutex);
+	inode_lock(main_bm_inode);
 
 	ret = ocfs2_inode_lock(main_bm_inode, &main_bm_bh, 1);
 	if (ret < 0) {
@@ -372,7 +372,7 @@ out_unlock:
 	ocfs2_inode_unlock(main_bm_inode, 1);
 
 out_mutex:
-	mutex_unlock(&main_bm_inode->i_mutex);
+	inode_unlock(main_bm_inode);
 	iput(main_bm_inode);
 
 out:
@@ -482,7 +482,7 @@ int ocfs2_group_add(struct inode *inode, struct ocfs2_new_group_input *input)
 		goto out;
 	}
 
-	mutex_lock(&main_bm_inode->i_mutex);
+	inode_lock(main_bm_inode);
 
 	ret = ocfs2_inode_lock(main_bm_inode, &main_bm_bh, 1);
 	if (ret < 0) {
@@ -581,7 +581,7 @@ out_unlock:
 	ocfs2_inode_unlock(main_bm_inode, 1);
 
 out_mutex:
-	mutex_unlock(&main_bm_inode->i_mutex);
+	inode_unlock(main_bm_inode);
 	iput(main_bm_inode);
 
 out:
* Unmerged path fs/ocfs2/suballoc.c
diff --git a/fs/ocfs2/xattr.c b/fs/ocfs2/xattr.c
index 5b8d94436105..ff875c548329 100644
--- a/fs/ocfs2/xattr.c
+++ b/fs/ocfs2/xattr.c
@@ -2499,7 +2499,7 @@ static int ocfs2_xattr_free_block(struct inode *inode,
 		mlog_errno(ret);
 		goto out;
 	}
-	mutex_lock(&xb_alloc_inode->i_mutex);
+	inode_lock(xb_alloc_inode);
 
 	ret = ocfs2_inode_lock(xb_alloc_inode, &xb_alloc_bh, 1);
 	if (ret < 0) {
@@ -2524,7 +2524,7 @@ out_unlock:
 	ocfs2_inode_unlock(xb_alloc_inode, 1);
 	brelse(xb_alloc_bh);
 out_mutex:
-	mutex_unlock(&xb_alloc_inode->i_mutex);
+	inode_unlock(xb_alloc_inode);
 	iput(xb_alloc_inode);
 out:
 	brelse(blk_bh);
@@ -3592,17 +3592,17 @@ int ocfs2_xattr_set(struct inode *inode,
 		}
 	}
 
-	mutex_lock(&tl_inode->i_mutex);
+	inode_lock(tl_inode);
 
 	if (ocfs2_truncate_log_needs_flush(osb)) {
 		ret = __ocfs2_flush_truncate_log(osb);
 		if (ret < 0) {
-			mutex_unlock(&tl_inode->i_mutex);
+			inode_unlock(tl_inode);
 			mlog_errno(ret);
 			goto cleanup;
 		}
 	}
-	mutex_unlock(&tl_inode->i_mutex);
+	inode_unlock(tl_inode);
 
 	ret = ocfs2_init_xattr_set_ctxt(inode, di, &xi, &xis,
 					&xbs, &ctxt, ref_meta, &credits);
@@ -5445,7 +5445,7 @@ static int ocfs2_rm_xattr_cluster(struct inode *inode,
 		return ret;
 	}
 
-	mutex_lock(&tl_inode->i_mutex);
+	inode_lock(tl_inode);
 
 	if (ocfs2_truncate_log_needs_flush(osb)) {
 		ret = __ocfs2_flush_truncate_log(osb);
@@ -5488,7 +5488,7 @@ out_commit:
 out:
 	ocfs2_schedule_truncate_log_flush(osb, 1);
 
-	mutex_unlock(&tl_inode->i_mutex);
+	inode_unlock(tl_inode);
 
 	if (meta_ac)
 		ocfs2_free_alloc_context(meta_ac);
diff --git a/fs/open.c b/fs/open.c
index f7eac9e9d550..13a09a1d96bd 100644
--- a/fs/open.c
+++ b/fs/open.c
@@ -58,10 +58,10 @@ int do_truncate(struct dentry *dentry, loff_t length, unsigned int time_attrs,
 	if (ret)
 		newattrs.ia_valid |= ret | ATTR_FORCE;
 
-	mutex_lock(&dentry->d_inode->i_mutex);
+	inode_lock(dentry->d_inode);
 	/* Note any delegations or leases have already been broken: */
 	ret = notify_change(dentry, &newattrs, NULL);
-	mutex_unlock(&dentry->d_inode->i_mutex);
+	inode_unlock(dentry->d_inode);
 	return ret;
 }
 
@@ -509,7 +509,7 @@ static int chmod_common(struct path *path, umode_t mode)
 	if (error)
 		return error;
 retry_deleg:
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	error = security_path_chmod(path, mode);
 	if (error)
 		goto out_unlock;
@@ -517,7 +517,7 @@ retry_deleg:
 	newattrs.ia_valid = ATTR_MODE | ATTR_CTIME;
 	error = notify_change(path->dentry, &newattrs, &delegated_inode);
 out_unlock:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	if (delegated_inode) {
 		error = break_deleg_wait(&delegated_inode);
 		if (!error)
@@ -593,11 +593,11 @@ retry_deleg:
 	if (!S_ISDIR(inode->i_mode))
 		newattrs.ia_valid |=
 			ATTR_KILL_SUID | ATTR_KILL_SGID | ATTR_KILL_PRIV;
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	error = security_path_chown(path, uid, gid);
 	if (!error)
 		error = notify_change(path->dentry, &newattrs, &delegated_inode);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	if (delegated_inode) {
 		error = break_deleg_wait(&delegated_inode);
 		if (!error)
diff --git a/fs/overlayfs/copy_up.c b/fs/overlayfs/copy_up.c
index 176e21bbad0e..b0f8d2f22061 100644
--- a/fs/overlayfs/copy_up.c
+++ b/fs/overlayfs/copy_up.c
@@ -283,9 +283,9 @@ static int ovl_copy_up_locked(struct dentry *workdir, struct dentry *upperdir,
 	if (err)
 		goto out_cleanup;
 
-	mutex_lock(&newdentry->d_inode->i_mutex);
+	inode_lock(newdentry->d_inode);
 	err = ovl_set_attr(newdentry, stat);
-	mutex_unlock(&newdentry->d_inode->i_mutex);
+	inode_unlock(newdentry->d_inode);
 	if (err)
 		goto out_cleanup;
 
* Unmerged path fs/overlayfs/dir.c
* Unmerged path fs/overlayfs/inode.c
diff --git a/fs/overlayfs/readdir.c b/fs/overlayfs/readdir.c
index 2010cf9bd904..5897898d384e 100644
--- a/fs/overlayfs/readdir.c
+++ b/fs/overlayfs/readdir.c
@@ -226,7 +226,7 @@ static int ovl_check_whiteouts(struct dentry *dir, struct ovl_readdir_data *rdd)
 				dput(dentry);
 			}
 		}
-		mutex_unlock(&dir->d_inode->i_mutex);
+		inode_unlock(dir->d_inode);
 	}
 	revert_creds(old_cred);
 
@@ -402,7 +402,7 @@ static loff_t ovl_dir_llseek(struct file *file, loff_t offset, int origin)
 	loff_t res;
 	struct ovl_dir_file *od = file->private_data;
 
-	mutex_lock(&file_inode(file)->i_mutex);
+	inode_lock(file_inode(file));
 	if (!file->f_pos)
 		ovl_dir_reset(file);
 
@@ -432,7 +432,7 @@ static loff_t ovl_dir_llseek(struct file *file, loff_t offset, int origin)
 		res = offset;
 	}
 out_unlock:
-	mutex_unlock(&file_inode(file)->i_mutex);
+	inode_unlock(file_inode(file));
 
 	return res;
 }
@@ -457,10 +457,10 @@ static int ovl_dir_fsync(struct file *file, loff_t start, loff_t end,
 			ovl_path_upper(dentry, &upperpath);
 			realfile = ovl_path_open(&upperpath, O_RDONLY);
 			smp_mb__before_spinlock();
-			mutex_lock(&inode->i_mutex);
+			inode_lock(inode);
 			if (!od->upperfile) {
 				if (IS_ERR(realfile)) {
-					mutex_unlock(&inode->i_mutex);
+					inode_unlock(inode);
 					return PTR_ERR(realfile);
 				}
 				od->upperfile = realfile;
@@ -470,7 +470,7 @@ static int ovl_dir_fsync(struct file *file, loff_t start, loff_t end,
 					fput(realfile);
 				realfile = od->upperfile;
 			}
-			mutex_unlock(&inode->i_mutex);
+			inode_unlock(inode);
 		}
 	}
 
@@ -482,9 +482,9 @@ static int ovl_dir_release(struct inode *inode, struct file *file)
 	struct ovl_dir_file *od = file->private_data;
 
 	if (od->cache) {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		ovl_cache_put(od, file->f_path.dentry);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 	}
 	fput(od->realfile);
 	if (od->upperfile)
@@ -560,7 +560,7 @@ void ovl_cleanup_whiteouts(struct dentry *upper, struct list_head *list)
 {
 	struct ovl_cache_entry *p;
 
-	mutex_lock_nested(&upper->d_inode->i_mutex, I_MUTEX_CHILD);
+	inode_lock_nested(upper->d_inode, I_MUTEX_CHILD);
 	list_for_each_entry(p, list, l_node) {
 		struct dentry *dentry;
 
@@ -578,7 +578,7 @@ void ovl_cleanup_whiteouts(struct dentry *upper, struct list_head *list)
 			ovl_cleanup(upper->d_inode, dentry);
 		dput(dentry);
 	}
-	mutex_unlock(&upper->d_inode->i_mutex);
+	inode_unlock(upper->d_inode);
 }
 
 static int ovl_check_d_type(void *buf, const char *name,
* Unmerged path fs/overlayfs/super.c
diff --git a/fs/proc/kcore.c b/fs/proc/kcore.c
index 0a22194e5d58..02f8b67a418e 100644
--- a/fs/proc/kcore.c
+++ b/fs/proc/kcore.c
@@ -553,9 +553,9 @@ static int open_kcore(struct inode *inode, struct file *filp)
 	if (kcore_need_update)
 		kcore_update_ram();
 	if (i_size_read(inode) != proc_root_kcore->size) {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		i_size_write(inode, proc_root_kcore->size);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 	}
 	return 0;
 }
diff --git a/fs/proc/self.c b/fs/proc/self.c
index ffeb202ec942..fe27f0e0dd98 100644
--- a/fs/proc/self.c
+++ b/fs/proc/self.c
@@ -50,7 +50,7 @@ int proc_setup_self(struct super_block *s)
 	struct pid_namespace *ns = s->s_fs_info;
 	struct dentry *self;
 	
-	mutex_lock(&root_inode->i_mutex);
+	inode_lock(root_inode);
 	self = d_alloc_name(s->s_root, "self");
 	if (self) {
 		struct inode *inode = new_inode_pseudo(s);
@@ -69,7 +69,7 @@ int proc_setup_self(struct super_block *s)
 	} else {
 		self = ERR_PTR(-ENOMEM);
 	}
-	mutex_unlock(&root_inode->i_mutex);
+	inode_unlock(root_inode);
 	if (IS_ERR(self)) {
 		pr_err("proc_fill_super: can't allocate /proc/self\n");
 		return PTR_ERR(self);
* Unmerged path fs/proc/thread_self.c
* Unmerged path fs/pstore/inode.c
* Unmerged path fs/quota/dquot.c
diff --git a/fs/read_write.c b/fs/read_write.c
index b7e6d43449bd..b2ee1500c39d 100644
--- a/fs/read_write.c
+++ b/fs/read_write.c
@@ -241,7 +241,7 @@ loff_t default_llseek(struct file *file, loff_t offset, int whence)
 	struct inode *inode = file_inode(file);
 	loff_t retval;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	switch (whence) {
 		case SEEK_END:
 			offset += i_size_read(inode);
@@ -286,7 +286,7 @@ loff_t default_llseek(struct file *file, loff_t offset, int whence)
 		retval = offset;
 	}
 out:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return retval;
 }
 EXPORT_SYMBOL(default_llseek);
diff --git a/fs/readdir.c b/fs/readdir.c
index fee38e04fae4..50bf71e2a040 100644
--- a/fs/readdir.c
+++ b/fs/readdir.c
@@ -40,7 +40,7 @@ int vfs_readdir(struct file *file, filldir_t filler, void *buf)
 		res = file->f_op->readdir(file, buf, filler);
 		file_accessed(file);
 	}
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 out:
 	return res;
 }
diff --git a/fs/reiserfs/dir.c b/fs/reiserfs/dir.c
index 6c2d136561cb..bb27e71238fa 100644
--- a/fs/reiserfs/dir.c
+++ b/fs/reiserfs/dir.c
@@ -38,11 +38,11 @@ static int reiserfs_dir_fsync(struct file *filp, loff_t start, loff_t end,
 	if (err)
 		return err;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	reiserfs_write_lock(inode->i_sb);
 	err = reiserfs_commit_for_inode(inode);
 	reiserfs_write_unlock(inode->i_sb);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	if (err < 0)
 		return err;
 	return 0;
diff --git a/fs/reiserfs/file.c b/fs/reiserfs/file.c
index dcaafcfc23b0..1b557c59f31c 100644
--- a/fs/reiserfs/file.c
+++ b/fs/reiserfs/file.c
@@ -151,7 +151,7 @@ static int reiserfs_sync_file(struct file *filp, loff_t start, loff_t end,
 	if (err)
 		return err;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	BUG_ON(!S_ISREG(inode->i_mode));
 	err = sync_mapping_buffers(inode->i_mapping);
 	reiserfs_write_lock(inode->i_sb);
@@ -159,7 +159,7 @@ static int reiserfs_sync_file(struct file *filp, loff_t start, loff_t end,
 	reiserfs_write_unlock(inode->i_sb);
 	if (barrier_done != 1 && reiserfs_barrier_flush(inode->i_sb))
 		blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL, NULL);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	if (barrier_done < 0)
 		return barrier_done;
 	return (err < 0) ? -EIO : 0;
* Unmerged path fs/reiserfs/ioctl.c
* Unmerged path fs/reiserfs/xattr.c
* Unmerged path fs/tracefs/inode.c
* Unmerged path fs/ubifs/dir.c
diff --git a/fs/ubifs/file.c b/fs/ubifs/file.c
index 14374530784c..1454a296d5ec 100644
--- a/fs/ubifs/file.c
+++ b/fs/ubifs/file.c
@@ -1323,7 +1323,7 @@ int ubifs_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 	err = filemap_write_and_wait_range(inode->i_mapping, start, end);
 	if (err)
 		return err;
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	/* Synchronize the inode unless this is a 'datasync()' call. */
 	if (!datasync || (inode->i_state & I_DIRTY_DATASYNC)) {
@@ -1338,7 +1338,7 @@ int ubifs_fsync(struct file *file, loff_t start, loff_t end, int datasync)
 	 */
 	err = ubifs_sync_wbufs_by_inode(c, inode);
 out:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return err;
 }
 
* Unmerged path fs/ubifs/xattr.c
* Unmerged path fs/udf/file.c
* Unmerged path fs/udf/inode.c
diff --git a/fs/utimes.c b/fs/utimes.c
index aa138d64560a..85c40f4f373d 100644
--- a/fs/utimes.c
+++ b/fs/utimes.c
@@ -103,9 +103,9 @@ static int utimes_common(struct path *path, struct timespec *times)
 		}
 	}
 retry_deleg:
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	error = notify_change(path->dentry, &newattrs, &delegated_inode);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	if (delegated_inode) {
 		error = break_deleg_wait(&delegated_inode);
 		if (!error)
* Unmerged path fs/xattr.c
diff --git a/fs/xfs/xfs_file.c b/fs/xfs/xfs_file.c
index 815d8f3721f9..7db487ca1434 100644
--- a/fs/xfs/xfs_file.c
+++ b/fs/xfs/xfs_file.c
@@ -56,7 +56,7 @@ xfs_rw_ilock(
 	int			type)
 {
 	if (type & XFS_IOLOCK_EXCL)
-		mutex_lock(&VFS_I(ip)->i_mutex);
+		inode_lock(VFS_I(ip));
 	xfs_ilock(ip, type);
 }
 
@@ -67,7 +67,7 @@ xfs_rw_iunlock(
 {
 	xfs_iunlock(ip, type);
 	if (type & XFS_IOLOCK_EXCL)
-		mutex_unlock(&VFS_I(ip)->i_mutex);
+		inode_unlock(VFS_I(ip));
 }
 
 static inline void
@@ -77,7 +77,7 @@ xfs_rw_ilock_demote(
 {
 	xfs_ilock_demote(ip, type);
 	if (type & XFS_IOLOCK_EXCL)
-		mutex_unlock(&VFS_I(ip)->i_mutex);
+		inode_unlock(VFS_I(ip));
 }
 
 /*
diff --git a/fs/xfs/xfs_pnfs.c b/fs/xfs/xfs_pnfs.c
index dc6221942b85..ade236e90bb3 100644
--- a/fs/xfs/xfs_pnfs.c
+++ b/fs/xfs/xfs_pnfs.c
@@ -42,11 +42,11 @@ xfs_break_layouts(
 	while ((error = break_layout(inode, false) == -EWOULDBLOCK)) {
 		xfs_iunlock(ip, *iolock);
 		if (with_imutex && (*iolock & XFS_IOLOCK_EXCL))
-			mutex_unlock(&inode->i_mutex);
+			inode_unlock(inode);
 		error = break_layout(inode, true);
 		*iolock = XFS_IOLOCK_EXCL;
 		if (with_imutex)
-			mutex_lock(&inode->i_mutex);
+			inode_lock(inode);
 		xfs_ilock(ip, *iolock);
 	}
 
* Unmerged path include/linux/fs.h
* Unmerged path ipc/mqueue.c
diff --git a/kernel/audit_fsnotify.c b/kernel/audit_fsnotify.c
index ef79983a9139..f75154889aa9 100644
--- a/kernel/audit_fsnotify.c
+++ b/kernel/audit_fsnotify.c
@@ -95,7 +95,7 @@ struct audit_fsnotify_mark *audit_alloc_mark(struct audit_krule *krule, char *pa
 	if (IS_ERR(dentry))
 		return (void *)dentry; /* returning an error */
 	inode = path.dentry->d_inode;
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	audit_mark = kzalloc(sizeof(*audit_mark), GFP_KERNEL);
 	if (unlikely(!audit_mark)) {
* Unmerged path kernel/audit_watch.c
diff --git a/kernel/events/core.c b/kernel/events/core.c
index 11d74ee5dbf9..fd72d9b6ce8c 100644
--- a/kernel/events/core.c
+++ b/kernel/events/core.c
@@ -5030,9 +5030,9 @@ static int perf_fasync(int fd, struct file *filp, int on)
 	struct perf_event *event = filp->private_data;
 	int retval;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	retval = fasync_helper(fd, filp, on, &event->fasync);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 
 	if (retval < 0)
 		return retval;
diff --git a/kernel/relay.c b/kernel/relay.c
index 5001c9887db1..3a35c0b34081 100644
--- a/kernel/relay.c
+++ b/kernel/relay.c
@@ -1136,7 +1136,7 @@ static ssize_t relay_file_read_subbufs(struct file *filp, loff_t *ppos,
 	if (!desc->count)
 		return 0;
 
-	mutex_lock(&file_inode(filp)->i_mutex);
+	inode_lock(file_inode(filp));
 	do {
 		if (!relay_file_read_avail(buf, *ppos))
 			break;
@@ -1156,7 +1156,7 @@ static ssize_t relay_file_read_subbufs(struct file *filp, loff_t *ppos,
 			*ppos = relay_file_read_end_pos(buf, read_start, ret);
 		}
 	} while (desc->count && ret);
-	mutex_unlock(&file_inode(filp)->i_mutex);
+	inode_unlock(file_inode(filp));
 
 	return desc->written;
 }
* Unmerged path kernel/sched/core.c
* Unmerged path mm/filemap.c
diff --git a/mm/shmem.c b/mm/shmem.c
index 021ba8dffccb..d97f786d046f 100644
--- a/mm/shmem.c
+++ b/mm/shmem.c
@@ -1884,7 +1884,7 @@ static loff_t shmem_file_llseek(struct file *file, loff_t offset, int whence)
 	if (whence != SEEK_DATA && whence != SEEK_HOLE)
 		return generic_file_llseek_size(file, offset, whence,
 					MAX_LFS_FILESIZE, i_size_read(inode));
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	/* We're holding i_mutex so we can access i_size directly */
 
 	if (offset < 0)
@@ -1908,7 +1908,7 @@ static loff_t shmem_file_llseek(struct file *file, loff_t offset, int whence)
 
 	if (offset >= 0)
 		offset = vfs_setpos(file, offset, MAX_LFS_FILESIZE);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return offset;
 }
 
@@ -2073,7 +2073,7 @@ int shmem_add_seals(struct file *file, unsigned int seals)
 	if (seals & ~(unsigned int)F_ALL_SEALS)
 		return -EINVAL;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	if (info->seals & F_SEAL_SEAL) {
 		error = -EPERM;
@@ -2096,7 +2096,7 @@ int shmem_add_seals(struct file *file, unsigned int seals)
 	error = 0;
 
 unlock:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return error;
 }
 EXPORT_SYMBOL_GPL(shmem_add_seals);
@@ -2146,7 +2146,7 @@ static long shmem_fallocate(struct file *file, int mode, loff_t offset,
 	if (mode & ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))
 		return -EOPNOTSUPP;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 
 	if (mode & FALLOC_FL_PUNCH_HOLE) {
 		struct address_space *mapping = file->f_mapping;
@@ -2259,7 +2259,7 @@ undone:
 	inode->i_private = NULL;
 	spin_unlock(&inode->i_lock);
 out:
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return error;
 }
 
* Unmerged path mm/swapfile.c
diff --git a/net/sunrpc/cache.c b/net/sunrpc/cache.c
index abb7d5a578cf..2afe49690c5f 100644
--- a/net/sunrpc/cache.c
+++ b/net/sunrpc/cache.c
@@ -775,7 +775,7 @@ static ssize_t cache_read(struct file *filp, char __user *buf, size_t count,
 	if (count == 0)
 		return 0;
 
-	mutex_lock(&inode->i_mutex); /* protect against multiple concurrent
+	inode_lock(inode); /* protect against multiple concurrent
 			      * readers on this file */
  again:
 	spin_lock(&queue_lock);
@@ -788,7 +788,7 @@ static ssize_t cache_read(struct file *filp, char __user *buf, size_t count,
 	}
 	if (rp->q.list.next == &cd->queue) {
 		spin_unlock(&queue_lock);
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 		WARN_ON_ONCE(rp->offset);
 		return 0;
 	}
@@ -842,7 +842,7 @@ static ssize_t cache_read(struct file *filp, char __user *buf, size_t count,
 	}
 	if (err == -EAGAIN)
 		goto again;
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 	return err ? err :  count;
 }
 
@@ -913,9 +913,9 @@ static ssize_t cache_write(struct file *filp, const char __user *buf,
 	if (!cd->cache_parse)
 		goto out;
 
-	mutex_lock(&inode->i_mutex);
+	inode_lock(inode);
 	ret = cache_downcall(mapping, buf, count, cd);
-	mutex_unlock(&inode->i_mutex);
+	inode_unlock(inode);
 out:
 	return ret;
 }
* Unmerged path net/sunrpc/rpc_pipe.c
* Unmerged path security/inode.c
* Unmerged path security/integrity/ima/ima_main.c
diff --git a/security/selinux/selinuxfs.c b/security/selinux/selinuxfs.c
index ff427733c290..3031375cf2b8 100644
--- a/security/selinux/selinuxfs.c
+++ b/security/selinux/selinuxfs.c
@@ -391,9 +391,9 @@ static int sel_open_policy(struct inode *inode, struct file *filp)
 		goto err;
 
 	if (i_size_read(inode) != security_policydb_len()) {
-		mutex_lock(&inode->i_mutex);
+		inode_lock(inode);
 		i_size_write(inode, security_policydb_len());
-		mutex_unlock(&inode->i_mutex);
+		inode_unlock(inode);
 	}
 
 	rc = security_read_policy(&plm->data, &plm->len);
