shmem: avoid maybe-uninitialized warning

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [pinctrl] amd: avoid maybe-uninitalized warning (Suravee Suthikulpanit) [1329005]
Rebuild_FUZZ: 90.91%
commit-author Arnd Bergmann <arnd@arndb.de>
commit 23f919d4ad0eb325595f10f55be4301b2965d6d6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/23f919d4.failed

After enabling -Wmaybe-uninitialized warnings, we get a false-postive
warning for shmem:

  mm/shmem.c: In function `shmem_getpage_gfp':
  include/linux/spinlock.h:332:21: error: `info' may be used uninitialized in this function [-Werror=maybe-uninitialized]

This can be easily avoided, since the correct 'info' pointer is known at
the time we first enter the function, so we can simply move the
initialization up.  Moving it before the first label avoids the warning
and lets us remove two later initializations.

Note that the function is so hard to read that it not only confuses the
compiler, but also most readers and without this patch it could\ easily
break if one of the 'goto's changed.

Link: https://www.spinics.net/lists/kernel/msg2368133.html
Link: http://lkml.kernel.org/r/20161024205725.786455-1-arnd@arndb.de
	Signed-off-by: Arnd Bergmann <arnd@arndb.de>
	Acked-by: Michal Hocko <mhocko@suse.com>
	Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
	Acked-by: Vlastimil Babka <vbabka@suse.cz>
	Cc: Hugh Dickins <hughd@google.com>
	Cc: Andreas Gruenbacher <agruenba@redhat.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 23f919d4ad0eb325595f10f55be4301b2965d6d6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/shmem.c
diff --cc mm/shmem.c
index 021ba8dffccb,ba0d7644ee20..000000000000
--- a/mm/shmem.c
+++ b/mm/shmem.c
@@@ -1097,16 -1529,24 +1097,16 @@@ static int shmem_replace_page(struct pa
   *
   * If we allocate a new one we do not mark it dirty. That's up to the
   * vm. If we swap it in we mark it dirty since we also free the swap
 - * entry since a page cannot live in both the swap and page cache.
 - *
 - * fault_mm and fault_type are only supplied by shmem_fault:
 - * otherwise they are NULL.
 + * entry since a page cannot live in both the swap and page cache
   */
  static int shmem_getpage_gfp(struct inode *inode, pgoff_t index,
 -	struct page **pagep, enum sgp_type sgp, gfp_t gfp,
 -	struct mm_struct *fault_mm, int *fault_type)
 +	struct page **pagep, enum sgp_type sgp, gfp_t gfp, int *fault_type)
  {
  	struct address_space *mapping = inode->i_mapping;
- 	struct shmem_inode_info *info;
+ 	struct shmem_inode_info *info = SHMEM_I(inode);
  	struct shmem_sb_info *sbinfo;
 -	struct mm_struct *charge_mm;
 -	struct mem_cgroup *memcg;
  	struct page *page;
  	swp_entry_t swap;
 -	enum sgp_type sgp_huge = sgp;
 -	pgoff_t hindex = index;
  	int error;
  	int once = 0;
  	int alloced = 0;
@@@ -1144,8 -1589,8 +1144,7 @@@ repeat
  	 * Fast cache lookup did not find it:
  	 * bring it back from swap or allocate.
  	 */
- 	info = SHMEM_I(inode);
  	sbinfo = SHMEM_SB(inode->i_sb);
 -	charge_mm = fault_mm ? : current->mm;
  
  	if (swap.val) {
  		/* Look it up and read it in.. */
@@@ -1313,13 -1833,12 +1312,17 @@@ failed
  unlock:
  	if (page) {
  		unlock_page(page);
 -		put_page(page);
 +		page_cache_release(page);
  	}
  	if (error == -ENOSPC && !once++) {
++<<<<<<< HEAD
 +		info = SHMEM_I(inode);
 +		spin_lock(&info->lock);
++=======
+ 		spin_lock_irq(&info->lock);
++>>>>>>> 23f919d4ad0e (shmem: avoid maybe-uninitialized warning)
  		shmem_recalc_inode(inode);
 -		spin_unlock_irq(&info->lock);
 +		spin_unlock(&info->lock);
  		goto repeat;
  	}
  	if (error == -EEXIST)	/* from above or from radix_tree_insert */
* Unmerged path mm/shmem.c
