kernfs: remove KERNFS_REMOVED

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Tejun Heo <tj@kernel.org>
commit ae34372eb8408b3d07e870f1939f99007a730d28
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/ae34372e.failed

KERNFS_REMOVED is used to mark half-initialized and dying nodes so
that they don't show up in lookups and deny adding new nodes under or
renaming it; however, its role overlaps those of deactivation and
removal from rbtree.

It's necessary to deny addition of new children while removal is in
progress; however, this role considerably intersects with deactivation
- KERNFS_REMOVED prevents new children while deactivation prevents new
file operations.  There's no reason to have them separate making
things more complex than necessary.

KERNFS_REMOVED is also used to decide whether a node is still visible
to vfs layer, which is rather redundant as equivalent determination
can be made by testing whether the node is on its parent's children
rbtree or not.

This patch removes KERNFS_REMOVED.

* Instead of KERNFS_REMOVED, each node now starts its life
  deactivated.  This means that we now use both atomic_add() and
  atomic_sub() on KN_DEACTIVATED_BIAS, which is INT_MIN.  The compiler
  generates an overflow warnings when negating INT_MIN as the negation
  can't be represented as a positive number.  Nothing is actually
  broken but let's bump BIAS by one to avoid the warnings for archs
  which negates the subtrahend..

* KERNFS_REMOVED tests in add and rename paths are replaced with
  kernfs_get/put_active() of the target nodes.  Due to the way the add
  path is structured now, active ref handling is done in the callers
  of kernfs_add_one().  This will be consolidated up later.

* kernfs_remove_one() is updated to deactivate instead of setting
  KERNFS_REMOVED.  This removes deactivation from kernfs_deactivate(),
  which is now renamed to kernfs_drain().

* kernfs_dop_revalidate() now tests RB_EMPTY_NODE(&kn->rb) instead of
  KERNFS_REMOVED and KERNFS_REMOVED test in kernfs_dir_pos() is
  dropped.  A node which is removed from the children rbtree is not
  included in the iteration in the first place.  This means that a
  node may be visible through vfs a bit longer - it's now also visible
  after deactivation until the actual removal.  This slightly enlarged
  window difference doesn't make any difference to the userland.

* Sanity check on KERNFS_REMOVED in kernfs_put() is replaced with
  checks on the active ref.

* Some comment style updates in the affected area.

v2: Reordered before removal path restructuring.  kernfs_active()
    dropped and kernfs_get/put_active() used instead.  RB_EMPTY_NODE()
    used in the lookup paths.

	Signed-off-by: Tejun Heo <tj@kernel.org>
	Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
(cherry picked from commit ae34372eb8408b3d07e870f1939f99007a730d28)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/kernfs/dir.c
#	fs/kernfs/file.c
#	fs/kernfs/kernfs-internal.h
#	fs/kernfs/symlink.c
#	include/linux/kernfs.h
diff --cc fs/kernfs/dir.c
index 1061602ce81a,7f8afc1d08f1..000000000000
--- a/fs/kernfs/dir.c
+++ b/fs/kernfs/dir.c
@@@ -7,3 -7,1068 +7,1071 @@@
   *
   * This file is released under the GPLv2.
   */
++<<<<<<< HEAD
++=======
+ 
+ #include <linux/sched.h>
+ #include <linux/fs.h>
+ #include <linux/namei.h>
+ #include <linux/idr.h>
+ #include <linux/slab.h>
+ #include <linux/security.h>
+ #include <linux/hash.h>
+ 
+ #include "kernfs-internal.h"
+ 
+ DEFINE_MUTEX(kernfs_mutex);
+ 
+ #define rb_to_kn(X) rb_entry((X), struct kernfs_node, rb)
+ 
+ static bool kernfs_lockdep(struct kernfs_node *kn)
+ {
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	return kn->flags & KERNFS_LOCKDEP;
+ #else
+ 	return false;
+ #endif
+ }
+ 
+ /**
+  *	kernfs_name_hash
+  *	@name: Null terminated string to hash
+  *	@ns:   Namespace tag to hash
+  *
+  *	Returns 31 bit hash of ns + name (so it fits in an off_t )
+  */
+ static unsigned int kernfs_name_hash(const char *name, const void *ns)
+ {
+ 	unsigned long hash = init_name_hash();
+ 	unsigned int len = strlen(name);
+ 	while (len--)
+ 		hash = partial_name_hash(*name++, hash);
+ 	hash = (end_name_hash(hash) ^ hash_ptr((void *)ns, 31));
+ 	hash &= 0x7fffffffU;
+ 	/* Reserve hash numbers 0, 1 and INT_MAX for magic directory entries */
+ 	if (hash < 1)
+ 		hash += 2;
+ 	if (hash >= INT_MAX)
+ 		hash = INT_MAX - 1;
+ 	return hash;
+ }
+ 
+ static int kernfs_name_compare(unsigned int hash, const char *name,
+ 			       const void *ns, const struct kernfs_node *kn)
+ {
+ 	if (hash != kn->hash)
+ 		return hash - kn->hash;
+ 	if (ns != kn->ns)
+ 		return ns - kn->ns;
+ 	return strcmp(name, kn->name);
+ }
+ 
+ static int kernfs_sd_compare(const struct kernfs_node *left,
+ 			     const struct kernfs_node *right)
+ {
+ 	return kernfs_name_compare(left->hash, left->name, left->ns, right);
+ }
+ 
+ /**
+  *	kernfs_link_sibling - link kernfs_node into sibling rbtree
+  *	@kn: kernfs_node of interest
+  *
+  *	Link @kn into its sibling rbtree which starts from
+  *	@kn->parent->dir.children.
+  *
+  *	Locking:
+  *	mutex_lock(kernfs_mutex)
+  *
+  *	RETURNS:
+  *	0 on susccess -EEXIST on failure.
+  */
+ static int kernfs_link_sibling(struct kernfs_node *kn)
+ {
+ 	struct rb_node **node = &kn->parent->dir.children.rb_node;
+ 	struct rb_node *parent = NULL;
+ 
+ 	if (kernfs_type(kn) == KERNFS_DIR)
+ 		kn->parent->dir.subdirs++;
+ 
+ 	while (*node) {
+ 		struct kernfs_node *pos;
+ 		int result;
+ 
+ 		pos = rb_to_kn(*node);
+ 		parent = *node;
+ 		result = kernfs_sd_compare(kn, pos);
+ 		if (result < 0)
+ 			node = &pos->rb.rb_left;
+ 		else if (result > 0)
+ 			node = &pos->rb.rb_right;
+ 		else
+ 			return -EEXIST;
+ 	}
+ 	/* add new node and rebalance the tree */
+ 	rb_link_node(&kn->rb, parent, node);
+ 	rb_insert_color(&kn->rb, &kn->parent->dir.children);
+ 	return 0;
+ }
+ 
+ /**
+  *	kernfs_unlink_sibling - unlink kernfs_node from sibling rbtree
+  *	@kn: kernfs_node of interest
+  *
+  *	Unlink @kn from its sibling rbtree which starts from
+  *	kn->parent->dir.children.
+  *
+  *	Locking:
+  *	mutex_lock(kernfs_mutex)
+  */
+ static void kernfs_unlink_sibling(struct kernfs_node *kn)
+ {
+ 	if (kernfs_type(kn) == KERNFS_DIR)
+ 		kn->parent->dir.subdirs--;
+ 
+ 	rb_erase(&kn->rb, &kn->parent->dir.children);
+ 	RB_CLEAR_NODE(&kn->rb);
+ }
+ 
+ /**
+  *	kernfs_get_active - get an active reference to kernfs_node
+  *	@kn: kernfs_node to get an active reference to
+  *
+  *	Get an active reference of @kn.  This function is noop if @kn
+  *	is NULL.
+  *
+  *	RETURNS:
+  *	Pointer to @kn on success, NULL on failure.
+  */
+ struct kernfs_node *kernfs_get_active(struct kernfs_node *kn)
+ {
+ 	if (unlikely(!kn))
+ 		return NULL;
+ 
+ 	if (!atomic_inc_unless_negative(&kn->active))
+ 		return NULL;
+ 
+ 	if (kernfs_lockdep(kn))
+ 		rwsem_acquire_read(&kn->dep_map, 0, 1, _RET_IP_);
+ 	return kn;
+ }
+ 
+ /**
+  *	kernfs_put_active - put an active reference to kernfs_node
+  *	@kn: kernfs_node to put an active reference to
+  *
+  *	Put an active reference to @kn.  This function is noop if @kn
+  *	is NULL.
+  */
+ void kernfs_put_active(struct kernfs_node *kn)
+ {
+ 	struct kernfs_root *root = kernfs_root(kn);
+ 	int v;
+ 
+ 	if (unlikely(!kn))
+ 		return;
+ 
+ 	if (kernfs_lockdep(kn))
+ 		rwsem_release(&kn->dep_map, 1, _RET_IP_);
+ 	v = atomic_dec_return(&kn->active);
+ 	if (likely(v != KN_DEACTIVATED_BIAS))
+ 		return;
+ 
+ 	wake_up_all(&root->deactivate_waitq);
+ }
+ 
+ /**
+  * kernfs_drain - drain kernfs_node
+  * @kn: kernfs_node to drain
+  *
+  * Drain existing usages.
+  */
+ static void kernfs_drain(struct kernfs_node *kn)
+ {
+ 	struct kernfs_root *root = kernfs_root(kn);
+ 
+ 	WARN_ON_ONCE(atomic_read(&kn->active) >= 0);
+ 
+ 	if (kernfs_lockdep(kn)) {
+ 		rwsem_acquire(&kn->dep_map, 0, 0, _RET_IP_);
+ 		if (atomic_read(&kn->active) != KN_DEACTIVATED_BIAS)
+ 			lock_contended(&kn->dep_map, _RET_IP_);
+ 	}
+ 
+ 	wait_event(root->deactivate_waitq,
+ 		   atomic_read(&kn->active) == KN_DEACTIVATED_BIAS);
+ 
+ 	if (kernfs_lockdep(kn)) {
+ 		lock_acquired(&kn->dep_map, _RET_IP_);
+ 		rwsem_release(&kn->dep_map, 1, _RET_IP_);
+ 	}
+ }
+ 
+ /**
+  * kernfs_get - get a reference count on a kernfs_node
+  * @kn: the target kernfs_node
+  */
+ void kernfs_get(struct kernfs_node *kn)
+ {
+ 	if (kn) {
+ 		WARN_ON(!atomic_read(&kn->count));
+ 		atomic_inc(&kn->count);
+ 	}
+ }
+ EXPORT_SYMBOL_GPL(kernfs_get);
+ 
+ /**
+  * kernfs_put - put a reference count on a kernfs_node
+  * @kn: the target kernfs_node
+  *
+  * Put a reference count of @kn and destroy it if it reached zero.
+  */
+ void kernfs_put(struct kernfs_node *kn)
+ {
+ 	struct kernfs_node *parent;
+ 	struct kernfs_root *root;
+ 
+ 	if (!kn || !atomic_dec_and_test(&kn->count))
+ 		return;
+ 	root = kernfs_root(kn);
+  repeat:
+ 	/*
+ 	 * Moving/renaming is always done while holding reference.
+ 	 * kn->parent won't change beneath us.
+ 	 */
+ 	parent = kn->parent;
+ 
+ 	WARN_ONCE(atomic_read(&kn->active) != KN_DEACTIVATED_BIAS,
+ 		  "kernfs_put: %s/%s: released with incorrect active_ref %d\n",
+ 		  parent ? parent->name : "", kn->name, atomic_read(&kn->active));
+ 
+ 	if (kernfs_type(kn) == KERNFS_LINK)
+ 		kernfs_put(kn->symlink.target_kn);
+ 	if (!(kn->flags & KERNFS_STATIC_NAME))
+ 		kfree(kn->name);
+ 	if (kn->iattr) {
+ 		if (kn->iattr->ia_secdata)
+ 			security_release_secctx(kn->iattr->ia_secdata,
+ 						kn->iattr->ia_secdata_len);
+ 		simple_xattrs_free(&kn->iattr->xattrs);
+ 	}
+ 	kfree(kn->iattr);
+ 	ida_simple_remove(&root->ino_ida, kn->ino);
+ 	kmem_cache_free(kernfs_node_cache, kn);
+ 
+ 	kn = parent;
+ 	if (kn) {
+ 		if (atomic_dec_and_test(&kn->count))
+ 			goto repeat;
+ 	} else {
+ 		/* just released the root kn, free @root too */
+ 		ida_destroy(&root->ino_ida);
+ 		kfree(root);
+ 	}
+ }
+ EXPORT_SYMBOL_GPL(kernfs_put);
+ 
+ static int kernfs_dop_revalidate(struct dentry *dentry, unsigned int flags)
+ {
+ 	struct kernfs_node *kn;
+ 
+ 	if (flags & LOOKUP_RCU)
+ 		return -ECHILD;
+ 
+ 	/* Always perform fresh lookup for negatives */
+ 	if (!dentry->d_inode)
+ 		goto out_bad_unlocked;
+ 
+ 	kn = dentry->d_fsdata;
+ 	mutex_lock(&kernfs_mutex);
+ 
+ 	/* Force fresh lookup if removed */
+ 	if (kn->parent && RB_EMPTY_NODE(&kn->rb))
+ 		goto out_bad;
+ 
+ 	/* The kernfs node has been moved? */
+ 	if (dentry->d_parent->d_fsdata != kn->parent)
+ 		goto out_bad;
+ 
+ 	/* The kernfs node has been renamed */
+ 	if (strcmp(dentry->d_name.name, kn->name) != 0)
+ 		goto out_bad;
+ 
+ 	/* The kernfs node has been moved to a different namespace */
+ 	if (kn->parent && kernfs_ns_enabled(kn->parent) &&
+ 	    kernfs_info(dentry->d_sb)->ns != kn->ns)
+ 		goto out_bad;
+ 
+ 	mutex_unlock(&kernfs_mutex);
+ out_valid:
+ 	return 1;
+ out_bad:
+ 	mutex_unlock(&kernfs_mutex);
+ out_bad_unlocked:
+ 	/*
+ 	 * @dentry doesn't match the underlying kernfs node, drop the
+ 	 * dentry and force lookup.  If we have submounts we must allow the
+ 	 * vfs caches to lie about the state of the filesystem to prevent
+ 	 * leaks and other nasty things, so use check_submounts_and_drop()
+ 	 * instead of d_drop().
+ 	 */
+ 	if (check_submounts_and_drop(dentry) != 0)
+ 		goto out_valid;
+ 
+ 	return 0;
+ }
+ 
+ static void kernfs_dop_release(struct dentry *dentry)
+ {
+ 	kernfs_put(dentry->d_fsdata);
+ }
+ 
+ const struct dentry_operations kernfs_dops = {
+ 	.d_revalidate	= kernfs_dop_revalidate,
+ 	.d_release	= kernfs_dop_release,
+ };
+ 
+ struct kernfs_node *kernfs_new_node(struct kernfs_root *root, const char *name,
+ 				    umode_t mode, unsigned flags)
+ {
+ 	char *dup_name = NULL;
+ 	struct kernfs_node *kn;
+ 	int ret;
+ 
+ 	if (!(flags & KERNFS_STATIC_NAME)) {
+ 		name = dup_name = kstrdup(name, GFP_KERNEL);
+ 		if (!name)
+ 			return NULL;
+ 	}
+ 
+ 	kn = kmem_cache_zalloc(kernfs_node_cache, GFP_KERNEL);
+ 	if (!kn)
+ 		goto err_out1;
+ 
+ 	ret = ida_simple_get(&root->ino_ida, 1, 0, GFP_KERNEL);
+ 	if (ret < 0)
+ 		goto err_out2;
+ 	kn->ino = ret;
+ 
+ 	atomic_set(&kn->count, 1);
+ 	atomic_set(&kn->active, KN_DEACTIVATED_BIAS);
+ 	RB_CLEAR_NODE(&kn->rb);
+ 
+ 	kn->name = name;
+ 	kn->mode = mode;
+ 	kn->flags = flags;
+ 
+ 	return kn;
+ 
+  err_out2:
+ 	kmem_cache_free(kernfs_node_cache, kn);
+  err_out1:
+ 	kfree(dup_name);
+ 	return NULL;
+ }
+ 
+ /**
+  *	kernfs_addrm_start - prepare for kernfs_node add/remove
+  *	@acxt: pointer to kernfs_addrm_cxt to be used
+  *
+  *	This function is called when the caller is about to add or remove
+  *	kernfs_node.  This function acquires kernfs_mutex.  @acxt is used
+  *	to keep and pass context to other addrm functions.
+  *
+  *	LOCKING:
+  *	Kernel thread context (may sleep).  kernfs_mutex is locked on
+  *	return.
+  */
+ void kernfs_addrm_start(struct kernfs_addrm_cxt *acxt)
+ 	__acquires(kernfs_mutex)
+ {
+ 	memset(acxt, 0, sizeof(*acxt));
+ 
+ 	mutex_lock(&kernfs_mutex);
+ }
+ 
+ /**
+  *	kernfs_add_one - add kernfs_node to parent without warning
+  *	@acxt: addrm context to use
+  *	@kn: kernfs_node to be added
+  *	@parent: the parent kernfs_node to add @kn to
+  *
+  *	Get @parent and set @kn->parent to it and increment nlink of the
+  *	parent inode if @kn is a directory and link into the children list
+  *	of the parent.
+  *
+  *	This function should be called between calls to
+  *	kernfs_addrm_start() and kernfs_addrm_finish() and should be passed
+  *	the same @acxt as passed to kernfs_addrm_start().
+  *
+  *	LOCKING:
+  *	Determined by kernfs_addrm_start().
+  *
+  *	RETURNS:
+  *	0 on success, -EEXIST if entry with the given name already
+  *	exists.
+  */
+ int kernfs_add_one(struct kernfs_addrm_cxt *acxt, struct kernfs_node *kn,
+ 		  struct kernfs_node *parent)
+ {
+ 	bool has_ns = kernfs_ns_enabled(parent);
+ 	struct kernfs_iattrs *ps_iattr;
+ 	int ret;
+ 
+ 	WARN_ON_ONCE(atomic_read(&parent->active) < 0);
+ 
+ 	if (has_ns != (bool)kn->ns) {
+ 		WARN(1, KERN_WARNING "kernfs: ns %s in '%s' for '%s'\n",
+ 		     has_ns ? "required" : "invalid", parent->name, kn->name);
+ 		return -EINVAL;
+ 	}
+ 
+ 	if (kernfs_type(parent) != KERNFS_DIR)
+ 		return -EINVAL;
+ 
+ 	kn->hash = kernfs_name_hash(kn->name, kn->ns);
+ 	kn->parent = parent;
+ 	kernfs_get(parent);
+ 
+ 	ret = kernfs_link_sibling(kn);
+ 	if (ret)
+ 		return ret;
+ 
+ 	/* Update timestamps on the parent */
+ 	ps_iattr = parent->iattr;
+ 	if (ps_iattr) {
+ 		struct iattr *ps_iattrs = &ps_iattr->ia_iattr;
+ 		ps_iattrs->ia_ctime = ps_iattrs->ia_mtime = CURRENT_TIME;
+ 	}
+ 
+ 	/* Mark the entry added into directory tree */
+ 	atomic_sub(KN_DEACTIVATED_BIAS, &kn->active);
+ 	return 0;
+ }
+ 
+ /**
+  *	kernfs_remove_one - remove kernfs_node from parent
+  *	@acxt: addrm context to use
+  *	@kn: kernfs_node to be removed
+  *
+  *	Mark @kn removed and drop nlink of parent inode if @kn is a
+  *	directory.  @kn is unlinked from the children list.
+  *
+  *	This function should be called between calls to
+  *	kernfs_addrm_start() and kernfs_addrm_finish() and should be
+  *	passed the same @acxt as passed to kernfs_addrm_start().
+  *
+  *	LOCKING:
+  *	Determined by kernfs_addrm_start().
+  */
+ static void kernfs_remove_one(struct kernfs_addrm_cxt *acxt,
+ 			      struct kernfs_node *kn)
+ {
+ 	struct kernfs_iattrs *ps_iattr;
+ 
+ 	/*
+ 	 * Removal can be called multiple times on the same node.  Only the
+ 	 * first invocation is effective and puts the base ref.
+ 	 */
+ 	if (atomic_read(&kn->active) < 0)
+ 		return;
+ 
+ 	if (kn->parent) {
+ 		kernfs_unlink_sibling(kn);
+ 
+ 		/* Update timestamps on the parent */
+ 		ps_iattr = kn->parent->iattr;
+ 		if (ps_iattr) {
+ 			ps_iattr->ia_iattr.ia_ctime = CURRENT_TIME;
+ 			ps_iattr->ia_iattr.ia_mtime = CURRENT_TIME;
+ 		}
+ 	}
+ 
+ 	atomic_add(KN_DEACTIVATED_BIAS, &kn->active);
+ 	kn->u.removed_list = acxt->removed;
+ 	acxt->removed = kn;
+ }
+ 
+ /**
+  *	kernfs_addrm_finish - finish up kernfs_node add/remove
+  *	@acxt: addrm context to finish up
+  *
+  *	Finish up kernfs_node add/remove.  Resources acquired by
+  *	kernfs_addrm_start() are released and removed kernfs_nodes are
+  *	cleaned up.
+  *
+  *	LOCKING:
+  *	kernfs_mutex is released.
+  */
+ void kernfs_addrm_finish(struct kernfs_addrm_cxt *acxt)
+ 	__releases(kernfs_mutex)
+ {
+ 	/* release resources acquired by kernfs_addrm_start() */
+ 	mutex_unlock(&kernfs_mutex);
+ 
+ 	/* kill removed kernfs_nodes */
+ 	while (acxt->removed) {
+ 		struct kernfs_node *kn = acxt->removed;
+ 
+ 		acxt->removed = kn->u.removed_list;
+ 
+ 		kernfs_drain(kn);
+ 		kernfs_unmap_bin_file(kn);
+ 		kernfs_put(kn);
+ 	}
+ }
+ 
+ /**
+  * kernfs_find_ns - find kernfs_node with the given name
+  * @parent: kernfs_node to search under
+  * @name: name to look for
+  * @ns: the namespace tag to use
+  *
+  * Look for kernfs_node with name @name under @parent.  Returns pointer to
+  * the found kernfs_node on success, %NULL on failure.
+  */
+ static struct kernfs_node *kernfs_find_ns(struct kernfs_node *parent,
+ 					  const unsigned char *name,
+ 					  const void *ns)
+ {
+ 	struct rb_node *node = parent->dir.children.rb_node;
+ 	bool has_ns = kernfs_ns_enabled(parent);
+ 	unsigned int hash;
+ 
+ 	lockdep_assert_held(&kernfs_mutex);
+ 
+ 	if (has_ns != (bool)ns) {
+ 		WARN(1, KERN_WARNING "kernfs: ns %s in '%s' for '%s'\n",
+ 		     has_ns ? "required" : "invalid", parent->name, name);
+ 		return NULL;
+ 	}
+ 
+ 	hash = kernfs_name_hash(name, ns);
+ 	while (node) {
+ 		struct kernfs_node *kn;
+ 		int result;
+ 
+ 		kn = rb_to_kn(node);
+ 		result = kernfs_name_compare(hash, name, ns, kn);
+ 		if (result < 0)
+ 			node = node->rb_left;
+ 		else if (result > 0)
+ 			node = node->rb_right;
+ 		else
+ 			return kn;
+ 	}
+ 	return NULL;
+ }
+ 
+ /**
+  * kernfs_find_and_get_ns - find and get kernfs_node with the given name
+  * @parent: kernfs_node to search under
+  * @name: name to look for
+  * @ns: the namespace tag to use
+  *
+  * Look for kernfs_node with name @name under @parent and get a reference
+  * if found.  This function may sleep and returns pointer to the found
+  * kernfs_node on success, %NULL on failure.
+  */
+ struct kernfs_node *kernfs_find_and_get_ns(struct kernfs_node *parent,
+ 					   const char *name, const void *ns)
+ {
+ 	struct kernfs_node *kn;
+ 
+ 	mutex_lock(&kernfs_mutex);
+ 	kn = kernfs_find_ns(parent, name, ns);
+ 	kernfs_get(kn);
+ 	mutex_unlock(&kernfs_mutex);
+ 
+ 	return kn;
+ }
+ EXPORT_SYMBOL_GPL(kernfs_find_and_get_ns);
+ 
+ /**
+  * kernfs_create_root - create a new kernfs hierarchy
+  * @kdops: optional directory syscall operations for the hierarchy
+  * @priv: opaque data associated with the new directory
+  *
+  * Returns the root of the new hierarchy on success, ERR_PTR() value on
+  * failure.
+  */
+ struct kernfs_root *kernfs_create_root(struct kernfs_dir_ops *kdops, void *priv)
+ {
+ 	struct kernfs_root *root;
+ 	struct kernfs_node *kn;
+ 
+ 	root = kzalloc(sizeof(*root), GFP_KERNEL);
+ 	if (!root)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	ida_init(&root->ino_ida);
+ 
+ 	kn = kernfs_new_node(root, "", S_IFDIR | S_IRUGO | S_IXUGO, KERNFS_DIR);
+ 	if (!kn) {
+ 		ida_destroy(&root->ino_ida);
+ 		kfree(root);
+ 		return ERR_PTR(-ENOMEM);
+ 	}
+ 
+ 	atomic_sub(KN_DEACTIVATED_BIAS, &kn->active);
+ 	kn->priv = priv;
+ 	kn->dir.root = root;
+ 
+ 	root->dir_ops = kdops;
+ 	root->kn = kn;
+ 	init_waitqueue_head(&root->deactivate_waitq);
+ 
+ 	return root;
+ }
+ 
+ /**
+  * kernfs_destroy_root - destroy a kernfs hierarchy
+  * @root: root of the hierarchy to destroy
+  *
+  * Destroy the hierarchy anchored at @root by removing all existing
+  * directories and destroying @root.
+  */
+ void kernfs_destroy_root(struct kernfs_root *root)
+ {
+ 	kernfs_remove(root->kn);	/* will also free @root */
+ }
+ 
+ /**
+  * kernfs_create_dir_ns - create a directory
+  * @parent: parent in which to create a new directory
+  * @name: name of the new directory
+  * @mode: mode of the new directory
+  * @priv: opaque data associated with the new directory
+  * @ns: optional namespace tag of the directory
+  *
+  * Returns the created node on success, ERR_PTR() value on failure.
+  */
+ struct kernfs_node *kernfs_create_dir_ns(struct kernfs_node *parent,
+ 					 const char *name, umode_t mode,
+ 					 void *priv, const void *ns)
+ {
+ 	struct kernfs_addrm_cxt acxt;
+ 	struct kernfs_node *kn;
+ 	int rc;
+ 
+ 	/* allocate */
+ 	kn = kernfs_new_node(kernfs_root(parent), name, mode | S_IFDIR,
+ 			     KERNFS_DIR);
+ 	if (!kn)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	kn->dir.root = parent->dir.root;
+ 	kn->ns = ns;
+ 	kn->priv = priv;
+ 
+ 	/* link in */
+ 	rc = -ENOENT;
+ 	if (kernfs_get_active(parent)) {
+ 		kernfs_addrm_start(&acxt);
+ 		rc = kernfs_add_one(&acxt, kn, parent);
+ 		kernfs_addrm_finish(&acxt);
+ 		kernfs_put_active(parent);
+ 	}
+ 
+ 	if (!rc)
+ 		return kn;
+ 
+ 	kernfs_put(kn);
+ 	return ERR_PTR(rc);
+ }
+ 
+ static struct dentry *kernfs_iop_lookup(struct inode *dir,
+ 					struct dentry *dentry,
+ 					unsigned int flags)
+ {
+ 	struct dentry *ret;
+ 	struct kernfs_node *parent = dentry->d_parent->d_fsdata;
+ 	struct kernfs_node *kn;
+ 	struct inode *inode;
+ 	const void *ns = NULL;
+ 
+ 	mutex_lock(&kernfs_mutex);
+ 
+ 	if (kernfs_ns_enabled(parent))
+ 		ns = kernfs_info(dir->i_sb)->ns;
+ 
+ 	kn = kernfs_find_ns(parent, dentry->d_name.name, ns);
+ 
+ 	/* no such entry */
+ 	if (!kn) {
+ 		ret = NULL;
+ 		goto out_unlock;
+ 	}
+ 	kernfs_get(kn);
+ 	dentry->d_fsdata = kn;
+ 
+ 	/* attach dentry and inode */
+ 	inode = kernfs_get_inode(dir->i_sb, kn);
+ 	if (!inode) {
+ 		ret = ERR_PTR(-ENOMEM);
+ 		goto out_unlock;
+ 	}
+ 
+ 	/* instantiate and hash dentry */
+ 	ret = d_materialise_unique(dentry, inode);
+  out_unlock:
+ 	mutex_unlock(&kernfs_mutex);
+ 	return ret;
+ }
+ 
+ static int kernfs_iop_mkdir(struct inode *dir, struct dentry *dentry,
+ 			    umode_t mode)
+ {
+ 	struct kernfs_node *parent = dir->i_private;
+ 	struct kernfs_dir_ops *kdops = kernfs_root(parent)->dir_ops;
+ 
+ 	if (!kdops || !kdops->mkdir)
+ 		return -EPERM;
+ 
+ 	return kdops->mkdir(parent, dentry->d_name.name, mode);
+ }
+ 
+ static int kernfs_iop_rmdir(struct inode *dir, struct dentry *dentry)
+ {
+ 	struct kernfs_node *kn  = dentry->d_fsdata;
+ 	struct kernfs_dir_ops *kdops = kernfs_root(kn)->dir_ops;
+ 
+ 	if (!kdops || !kdops->rmdir)
+ 		return -EPERM;
+ 
+ 	return kdops->rmdir(kn);
+ }
+ 
+ static int kernfs_iop_rename(struct inode *old_dir, struct dentry *old_dentry,
+ 			     struct inode *new_dir, struct dentry *new_dentry)
+ {
+ 	struct kernfs_node *kn  = old_dentry->d_fsdata;
+ 	struct kernfs_node *new_parent = new_dir->i_private;
+ 	struct kernfs_dir_ops *kdops = kernfs_root(kn)->dir_ops;
+ 
+ 	if (!kdops || !kdops->rename)
+ 		return -EPERM;
+ 
+ 	return kdops->rename(kn, new_parent, new_dentry->d_name.name);
+ }
+ 
+ const struct inode_operations kernfs_dir_iops = {
+ 	.lookup		= kernfs_iop_lookup,
+ 	.permission	= kernfs_iop_permission,
+ 	.setattr	= kernfs_iop_setattr,
+ 	.getattr	= kernfs_iop_getattr,
+ 	.setxattr	= kernfs_iop_setxattr,
+ 	.removexattr	= kernfs_iop_removexattr,
+ 	.getxattr	= kernfs_iop_getxattr,
+ 	.listxattr	= kernfs_iop_listxattr,
+ 
+ 	.mkdir		= kernfs_iop_mkdir,
+ 	.rmdir		= kernfs_iop_rmdir,
+ 	.rename		= kernfs_iop_rename,
+ };
+ 
+ static struct kernfs_node *kernfs_leftmost_descendant(struct kernfs_node *pos)
+ {
+ 	struct kernfs_node *last;
+ 
+ 	while (true) {
+ 		struct rb_node *rbn;
+ 
+ 		last = pos;
+ 
+ 		if (kernfs_type(pos) != KERNFS_DIR)
+ 			break;
+ 
+ 		rbn = rb_first(&pos->dir.children);
+ 		if (!rbn)
+ 			break;
+ 
+ 		pos = rb_to_kn(rbn);
+ 	}
+ 
+ 	return last;
+ }
+ 
+ /**
+  * kernfs_next_descendant_post - find the next descendant for post-order walk
+  * @pos: the current position (%NULL to initiate traversal)
+  * @root: kernfs_node whose descendants to walk
+  *
+  * Find the next descendant to visit for post-order traversal of @root's
+  * descendants.  @root is included in the iteration and the last node to be
+  * visited.
+  */
+ static struct kernfs_node *kernfs_next_descendant_post(struct kernfs_node *pos,
+ 						       struct kernfs_node *root)
+ {
+ 	struct rb_node *rbn;
+ 
+ 	lockdep_assert_held(&kernfs_mutex);
+ 
+ 	/* if first iteration, visit leftmost descendant which may be root */
+ 	if (!pos)
+ 		return kernfs_leftmost_descendant(root);
+ 
+ 	/* if we visited @root, we're done */
+ 	if (pos == root)
+ 		return NULL;
+ 
+ 	/* if there's an unvisited sibling, visit its leftmost descendant */
+ 	rbn = rb_next(&pos->rb);
+ 	if (rbn)
+ 		return kernfs_leftmost_descendant(rb_to_kn(rbn));
+ 
+ 	/* no sibling left, visit parent */
+ 	return pos->parent;
+ }
+ 
+ static void __kernfs_remove(struct kernfs_addrm_cxt *acxt,
+ 			    struct kernfs_node *kn)
+ {
+ 	struct kernfs_node *pos, *next;
+ 
+ 	if (!kn)
+ 		return;
+ 
+ 	pr_debug("kernfs %s: removing\n", kn->name);
+ 
+ 	next = NULL;
+ 	do {
+ 		pos = next;
+ 		next = kernfs_next_descendant_post(pos, kn);
+ 		if (pos)
+ 			kernfs_remove_one(acxt, pos);
+ 	} while (next);
+ }
+ 
+ /**
+  * kernfs_remove - remove a kernfs_node recursively
+  * @kn: the kernfs_node to remove
+  *
+  * Remove @kn along with all its subdirectories and files.
+  */
+ void kernfs_remove(struct kernfs_node *kn)
+ {
+ 	struct kernfs_addrm_cxt acxt;
+ 
+ 	kernfs_addrm_start(&acxt);
+ 	__kernfs_remove(&acxt, kn);
+ 	kernfs_addrm_finish(&acxt);
+ }
+ 
+ /**
+  * kernfs_remove_by_name_ns - find a kernfs_node by name and remove it
+  * @parent: parent of the target
+  * @name: name of the kernfs_node to remove
+  * @ns: namespace tag of the kernfs_node to remove
+  *
+  * Look for the kernfs_node with @name and @ns under @parent and remove it.
+  * Returns 0 on success, -ENOENT if such entry doesn't exist.
+  */
+ int kernfs_remove_by_name_ns(struct kernfs_node *parent, const char *name,
+ 			     const void *ns)
+ {
+ 	struct kernfs_addrm_cxt acxt;
+ 	struct kernfs_node *kn;
+ 
+ 	if (!parent) {
+ 		WARN(1, KERN_WARNING "kernfs: can not remove '%s', no directory\n",
+ 			name);
+ 		return -ENOENT;
+ 	}
+ 
+ 	kernfs_addrm_start(&acxt);
+ 
+ 	kn = kernfs_find_ns(parent, name, ns);
+ 	if (kn)
+ 		__kernfs_remove(&acxt, kn);
+ 
+ 	kernfs_addrm_finish(&acxt);
+ 
+ 	if (kn)
+ 		return 0;
+ 	else
+ 		return -ENOENT;
+ }
+ 
+ /**
+  * kernfs_rename_ns - move and rename a kernfs_node
+  * @kn: target node
+  * @new_parent: new parent to put @sd under
+  * @new_name: new name
+  * @new_ns: new namespace tag
+  */
+ int kernfs_rename_ns(struct kernfs_node *kn, struct kernfs_node *new_parent,
+ 		     const char *new_name, const void *new_ns)
+ {
+ 	int error;
+ 
+ 	error = -ENOENT;
+ 	if (!kernfs_get_active(new_parent))
+ 		goto out;
+ 	if (!kernfs_get_active(kn))
+ 		goto out_put_new_parent;
+ 
+ 	mutex_lock(&kernfs_mutex);
+ 
+ 	error = 0;
+ 	if ((kn->parent == new_parent) && (kn->ns == new_ns) &&
+ 	    (strcmp(kn->name, new_name) == 0))
+ 		goto out_unlock;	/* nothing to rename */
+ 
+ 	error = -EEXIST;
+ 	if (kernfs_find_ns(new_parent, new_name, new_ns))
+ 		goto out_unlock;
+ 
+ 	/* rename kernfs_node */
+ 	if (strcmp(kn->name, new_name) != 0) {
+ 		error = -ENOMEM;
+ 		new_name = kstrdup(new_name, GFP_KERNEL);
+ 		if (!new_name)
+ 			goto out_unlock;
+ 
+ 		if (kn->flags & KERNFS_STATIC_NAME)
+ 			kn->flags &= ~KERNFS_STATIC_NAME;
+ 		else
+ 			kfree(kn->name);
+ 
+ 		kn->name = new_name;
+ 	}
+ 
+ 	/*
+ 	 * Move to the appropriate place in the appropriate directories rbtree.
+ 	 */
+ 	kernfs_unlink_sibling(kn);
+ 	kernfs_get(new_parent);
+ 	kernfs_put(kn->parent);
+ 	kn->ns = new_ns;
+ 	kn->hash = kernfs_name_hash(kn->name, kn->ns);
+ 	kn->parent = new_parent;
+ 	kernfs_link_sibling(kn);
+ 
+ 	error = 0;
+ out_unlock:
+ 	mutex_unlock(&kernfs_mutex);
+ 	kernfs_put_active(kn);
+ out_put_new_parent:
+ 	kernfs_put_active(new_parent);
+ out:
+ 	return error;
+ }
+ 
+ /* Relationship between s_mode and the DT_xxx types */
+ static inline unsigned char dt_type(struct kernfs_node *kn)
+ {
+ 	return (kn->mode >> 12) & 15;
+ }
+ 
+ static int kernfs_dir_fop_release(struct inode *inode, struct file *filp)
+ {
+ 	kernfs_put(filp->private_data);
+ 	return 0;
+ }
+ 
+ static struct kernfs_node *kernfs_dir_pos(const void *ns,
+ 	struct kernfs_node *parent, loff_t hash, struct kernfs_node *pos)
+ {
+ 	if (pos) {
+ 		int valid = pos->parent == parent && hash == pos->hash;
+ 		kernfs_put(pos);
+ 		if (!valid)
+ 			pos = NULL;
+ 	}
+ 	if (!pos && (hash > 1) && (hash < INT_MAX)) {
+ 		struct rb_node *node = parent->dir.children.rb_node;
+ 		while (node) {
+ 			pos = rb_to_kn(node);
+ 
+ 			if (hash < pos->hash)
+ 				node = node->rb_left;
+ 			else if (hash > pos->hash)
+ 				node = node->rb_right;
+ 			else
+ 				break;
+ 		}
+ 	}
+ 	/* Skip over entries in the wrong namespace */
+ 	while (pos && pos->ns != ns) {
+ 		struct rb_node *node = rb_next(&pos->rb);
+ 		if (!node)
+ 			pos = NULL;
+ 		else
+ 			pos = rb_to_kn(node);
+ 	}
+ 	return pos;
+ }
+ 
+ static struct kernfs_node *kernfs_dir_next_pos(const void *ns,
+ 	struct kernfs_node *parent, ino_t ino, struct kernfs_node *pos)
+ {
+ 	pos = kernfs_dir_pos(ns, parent, ino, pos);
+ 	if (pos)
+ 		do {
+ 			struct rb_node *node = rb_next(&pos->rb);
+ 			if (!node)
+ 				pos = NULL;
+ 			else
+ 				pos = rb_to_kn(node);
+ 		} while (pos && pos->ns != ns);
+ 	return pos;
+ }
+ 
+ static int kernfs_fop_readdir(struct file *file, struct dir_context *ctx)
+ {
+ 	struct dentry *dentry = file->f_path.dentry;
+ 	struct kernfs_node *parent = dentry->d_fsdata;
+ 	struct kernfs_node *pos = file->private_data;
+ 	const void *ns = NULL;
+ 
+ 	if (!dir_emit_dots(file, ctx))
+ 		return 0;
+ 	mutex_lock(&kernfs_mutex);
+ 
+ 	if (kernfs_ns_enabled(parent))
+ 		ns = kernfs_info(dentry->d_sb)->ns;
+ 
+ 	for (pos = kernfs_dir_pos(ns, parent, ctx->pos, pos);
+ 	     pos;
+ 	     pos = kernfs_dir_next_pos(ns, parent, ctx->pos, pos)) {
+ 		const char *name = pos->name;
+ 		unsigned int type = dt_type(pos);
+ 		int len = strlen(name);
+ 		ino_t ino = pos->ino;
+ 
+ 		ctx->pos = pos->hash;
+ 		file->private_data = pos;
+ 		kernfs_get(pos);
+ 
+ 		mutex_unlock(&kernfs_mutex);
+ 		if (!dir_emit(ctx, name, len, ino, type))
+ 			return 0;
+ 		mutex_lock(&kernfs_mutex);
+ 	}
+ 	mutex_unlock(&kernfs_mutex);
+ 	file->private_data = NULL;
+ 	ctx->pos = INT_MAX;
+ 	return 0;
+ }
+ 
+ static loff_t kernfs_dir_fop_llseek(struct file *file, loff_t offset,
+ 				    int whence)
+ {
+ 	struct inode *inode = file_inode(file);
+ 	loff_t ret;
+ 
+ 	mutex_lock(&inode->i_mutex);
+ 	ret = generic_file_llseek(file, offset, whence);
+ 	mutex_unlock(&inode->i_mutex);
+ 
+ 	return ret;
+ }
+ 
+ const struct file_operations kernfs_dir_fops = {
+ 	.read		= generic_read_dir,
+ 	.iterate	= kernfs_fop_readdir,
+ 	.release	= kernfs_dir_fop_release,
+ 	.llseek		= kernfs_dir_fop_llseek,
+ };
++>>>>>>> ae34372eb840 (kernfs: remove KERNFS_REMOVED)
diff --cc fs/kernfs/file.c
index 90b1e88dad44,231a171f48b6..000000000000
--- a/fs/kernfs/file.c
+++ b/fs/kernfs/file.c
@@@ -7,3 -7,866 +7,869 @@@
   *
   * This file is released under the GPLv2.
   */
++<<<<<<< HEAD
++=======
+ 
+ #include <linux/fs.h>
+ #include <linux/seq_file.h>
+ #include <linux/slab.h>
+ #include <linux/poll.h>
+ #include <linux/pagemap.h>
+ #include <linux/sched.h>
+ 
+ #include "kernfs-internal.h"
+ 
+ /*
+  * There's one kernfs_open_file for each open file and one kernfs_open_node
+  * for each kernfs_node with one or more open files.
+  *
+  * kernfs_node->attr.open points to kernfs_open_node.  attr.open is
+  * protected by kernfs_open_node_lock.
+  *
+  * filp->private_data points to seq_file whose ->private points to
+  * kernfs_open_file.  kernfs_open_files are chained at
+  * kernfs_open_node->files, which is protected by kernfs_open_file_mutex.
+  */
+ static DEFINE_SPINLOCK(kernfs_open_node_lock);
+ static DEFINE_MUTEX(kernfs_open_file_mutex);
+ 
+ struct kernfs_open_node {
+ 	atomic_t		refcnt;
+ 	atomic_t		event;
+ 	wait_queue_head_t	poll;
+ 	struct list_head	files; /* goes through kernfs_open_file.list */
+ };
+ 
+ static struct kernfs_open_file *kernfs_of(struct file *file)
+ {
+ 	return ((struct seq_file *)file->private_data)->private;
+ }
+ 
+ /*
+  * Determine the kernfs_ops for the given kernfs_node.  This function must
+  * be called while holding an active reference.
+  */
+ static const struct kernfs_ops *kernfs_ops(struct kernfs_node *kn)
+ {
+ 	if (kn->flags & KERNFS_LOCKDEP)
+ 		lockdep_assert_held(kn);
+ 	return kn->attr.ops;
+ }
+ 
+ /*
+  * As kernfs_seq_stop() is also called after kernfs_seq_start() or
+  * kernfs_seq_next() failure, it needs to distinguish whether it's stopping
+  * a seq_file iteration which is fully initialized with an active reference
+  * or an aborted kernfs_seq_start() due to get_active failure.  The
+  * position pointer is the only context for each seq_file iteration and
+  * thus the stop condition should be encoded in it.  As the return value is
+  * directly visible to userland, ERR_PTR(-ENODEV) is the only acceptable
+  * choice to indicate get_active failure.
+  *
+  * Unfortunately, this is complicated due to the optional custom seq_file
+  * operations which may return ERR_PTR(-ENODEV) too.  kernfs_seq_stop()
+  * can't distinguish whether ERR_PTR(-ENODEV) is from get_active failure or
+  * custom seq_file operations and thus can't decide whether put_active
+  * should be performed or not only on ERR_PTR(-ENODEV).
+  *
+  * This is worked around by factoring out the custom seq_stop() and
+  * put_active part into kernfs_seq_stop_active(), skipping it from
+  * kernfs_seq_stop() if ERR_PTR(-ENODEV) while invoking it directly after
+  * custom seq_file operations fail with ERR_PTR(-ENODEV) - this ensures
+  * that kernfs_seq_stop_active() is skipped only after get_active failure.
+  */
+ static void kernfs_seq_stop_active(struct seq_file *sf, void *v)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 	const struct kernfs_ops *ops = kernfs_ops(of->kn);
+ 
+ 	if (ops->seq_stop)
+ 		ops->seq_stop(sf, v);
+ 	kernfs_put_active(of->kn);
+ }
+ 
+ static void *kernfs_seq_start(struct seq_file *sf, loff_t *ppos)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 	const struct kernfs_ops *ops;
+ 
+ 	/*
+ 	 * @of->mutex nests outside active ref and is just to ensure that
+ 	 * the ops aren't called concurrently for the same open file.
+ 	 */
+ 	mutex_lock(&of->mutex);
+ 	if (!kernfs_get_active(of->kn))
+ 		return ERR_PTR(-ENODEV);
+ 
+ 	ops = kernfs_ops(of->kn);
+ 	if (ops->seq_start) {
+ 		void *next = ops->seq_start(sf, ppos);
+ 		/* see the comment above kernfs_seq_stop_active() */
+ 		if (next == ERR_PTR(-ENODEV))
+ 			kernfs_seq_stop_active(sf, next);
+ 		return next;
+ 	} else {
+ 		/*
+ 		 * The same behavior and code as single_open().  Returns
+ 		 * !NULL if pos is at the beginning; otherwise, NULL.
+ 		 */
+ 		return NULL + !*ppos;
+ 	}
+ }
+ 
+ static void *kernfs_seq_next(struct seq_file *sf, void *v, loff_t *ppos)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 	const struct kernfs_ops *ops = kernfs_ops(of->kn);
+ 
+ 	if (ops->seq_next) {
+ 		void *next = ops->seq_next(sf, v, ppos);
+ 		/* see the comment above kernfs_seq_stop_active() */
+ 		if (next == ERR_PTR(-ENODEV))
+ 			kernfs_seq_stop_active(sf, next);
+ 		return next;
+ 	} else {
+ 		/*
+ 		 * The same behavior and code as single_open(), always
+ 		 * terminate after the initial read.
+ 		 */
+ 		++*ppos;
+ 		return NULL;
+ 	}
+ }
+ 
+ static void kernfs_seq_stop(struct seq_file *sf, void *v)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 
+ 	if (v != ERR_PTR(-ENODEV))
+ 		kernfs_seq_stop_active(sf, v);
+ 	mutex_unlock(&of->mutex);
+ }
+ 
+ static int kernfs_seq_show(struct seq_file *sf, void *v)
+ {
+ 	struct kernfs_open_file *of = sf->private;
+ 
+ 	of->event = atomic_read(&of->kn->attr.open->event);
+ 
+ 	return of->kn->attr.ops->seq_show(sf, v);
+ }
+ 
+ static const struct seq_operations kernfs_seq_ops = {
+ 	.start = kernfs_seq_start,
+ 	.next = kernfs_seq_next,
+ 	.stop = kernfs_seq_stop,
+ 	.show = kernfs_seq_show,
+ };
+ 
+ /*
+  * As reading a bin file can have side-effects, the exact offset and bytes
+  * specified in read(2) call should be passed to the read callback making
+  * it difficult to use seq_file.  Implement simplistic custom buffering for
+  * bin files.
+  */
+ static ssize_t kernfs_file_direct_read(struct kernfs_open_file *of,
+ 				       char __user *user_buf, size_t count,
+ 				       loff_t *ppos)
+ {
+ 	ssize_t len = min_t(size_t, count, PAGE_SIZE);
+ 	const struct kernfs_ops *ops;
+ 	char *buf;
+ 
+ 	buf = kmalloc(len, GFP_KERNEL);
+ 	if (!buf)
+ 		return -ENOMEM;
+ 
+ 	/*
+ 	 * @of->mutex nests outside active ref and is just to ensure that
+ 	 * the ops aren't called concurrently for the same open file.
+ 	 */
+ 	mutex_lock(&of->mutex);
+ 	if (!kernfs_get_active(of->kn)) {
+ 		len = -ENODEV;
+ 		mutex_unlock(&of->mutex);
+ 		goto out_free;
+ 	}
+ 
+ 	ops = kernfs_ops(of->kn);
+ 	if (ops->read)
+ 		len = ops->read(of, buf, len, *ppos);
+ 	else
+ 		len = -EINVAL;
+ 
+ 	kernfs_put_active(of->kn);
+ 	mutex_unlock(&of->mutex);
+ 
+ 	if (len < 0)
+ 		goto out_free;
+ 
+ 	if (copy_to_user(user_buf, buf, len)) {
+ 		len = -EFAULT;
+ 		goto out_free;
+ 	}
+ 
+ 	*ppos += len;
+ 
+  out_free:
+ 	kfree(buf);
+ 	return len;
+ }
+ 
+ /**
+  * kernfs_fop_read - kernfs vfs read callback
+  * @file: file pointer
+  * @user_buf: data to write
+  * @count: number of bytes
+  * @ppos: starting offset
+  */
+ static ssize_t kernfs_fop_read(struct file *file, char __user *user_buf,
+ 			       size_t count, loff_t *ppos)
+ {
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 
+ 	if (of->kn->flags & KERNFS_HAS_SEQ_SHOW)
+ 		return seq_read(file, user_buf, count, ppos);
+ 	else
+ 		return kernfs_file_direct_read(of, user_buf, count, ppos);
+ }
+ 
+ /**
+  * kernfs_fop_write - kernfs vfs write callback
+  * @file: file pointer
+  * @user_buf: data to write
+  * @count: number of bytes
+  * @ppos: starting offset
+  *
+  * Copy data in from userland and pass it to the matching kernfs write
+  * operation.
+  *
+  * There is no easy way for us to know if userspace is only doing a partial
+  * write, so we don't support them. We expect the entire buffer to come on
+  * the first write.  Hint: if you're writing a value, first read the file,
+  * modify only the the value you're changing, then write entire buffer
+  * back.
+  */
+ static ssize_t kernfs_fop_write(struct file *file, const char __user *user_buf,
+ 				size_t count, loff_t *ppos)
+ {
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	ssize_t len = min_t(size_t, count, PAGE_SIZE);
+ 	const struct kernfs_ops *ops;
+ 	char *buf;
+ 
+ 	buf = kmalloc(len + 1, GFP_KERNEL);
+ 	if (!buf)
+ 		return -ENOMEM;
+ 
+ 	if (copy_from_user(buf, user_buf, len)) {
+ 		len = -EFAULT;
+ 		goto out_free;
+ 	}
+ 	buf[len] = '\0';	/* guarantee string termination */
+ 
+ 	/*
+ 	 * @of->mutex nests outside active ref and is just to ensure that
+ 	 * the ops aren't called concurrently for the same open file.
+ 	 */
+ 	mutex_lock(&of->mutex);
+ 	if (!kernfs_get_active(of->kn)) {
+ 		mutex_unlock(&of->mutex);
+ 		len = -ENODEV;
+ 		goto out_free;
+ 	}
+ 
+ 	ops = kernfs_ops(of->kn);
+ 	if (ops->write)
+ 		len = ops->write(of, buf, len, *ppos);
+ 	else
+ 		len = -EINVAL;
+ 
+ 	kernfs_put_active(of->kn);
+ 	mutex_unlock(&of->mutex);
+ 
+ 	if (len > 0)
+ 		*ppos += len;
+ out_free:
+ 	kfree(buf);
+ 	return len;
+ }
+ 
+ static void kernfs_vma_open(struct vm_area_struct *vma)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 
+ 	if (!of->vm_ops)
+ 		return;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return;
+ 
+ 	if (of->vm_ops->open)
+ 		of->vm_ops->open(vma);
+ 
+ 	kernfs_put_active(of->kn);
+ }
+ 
+ static int kernfs_vma_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return VM_FAULT_SIGBUS;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return VM_FAULT_SIGBUS;
+ 
+ 	ret = VM_FAULT_SIGBUS;
+ 	if (of->vm_ops->fault)
+ 		ret = of->vm_ops->fault(vma, vmf);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ 
+ static int kernfs_vma_page_mkwrite(struct vm_area_struct *vma,
+ 				   struct vm_fault *vmf)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return VM_FAULT_SIGBUS;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return VM_FAULT_SIGBUS;
+ 
+ 	ret = 0;
+ 	if (of->vm_ops->page_mkwrite)
+ 		ret = of->vm_ops->page_mkwrite(vma, vmf);
+ 	else
+ 		file_update_time(file);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ 
+ static int kernfs_vma_access(struct vm_area_struct *vma, unsigned long addr,
+ 			     void *buf, int len, int write)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return -EINVAL;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return -EINVAL;
+ 
+ 	ret = -EINVAL;
+ 	if (of->vm_ops->access)
+ 		ret = of->vm_ops->access(vma, addr, buf, len, write);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ 
+ #ifdef CONFIG_NUMA
+ static int kernfs_vma_set_policy(struct vm_area_struct *vma,
+ 				 struct mempolicy *new)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return 0;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return -EINVAL;
+ 
+ 	ret = 0;
+ 	if (of->vm_ops->set_policy)
+ 		ret = of->vm_ops->set_policy(vma, new);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ 
+ static struct mempolicy *kernfs_vma_get_policy(struct vm_area_struct *vma,
+ 					       unsigned long addr)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	struct mempolicy *pol;
+ 
+ 	if (!of->vm_ops)
+ 		return vma->vm_policy;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return vma->vm_policy;
+ 
+ 	pol = vma->vm_policy;
+ 	if (of->vm_ops->get_policy)
+ 		pol = of->vm_ops->get_policy(vma, addr);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return pol;
+ }
+ 
+ static int kernfs_vma_migrate(struct vm_area_struct *vma,
+ 			      const nodemask_t *from, const nodemask_t *to,
+ 			      unsigned long flags)
+ {
+ 	struct file *file = vma->vm_file;
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	int ret;
+ 
+ 	if (!of->vm_ops)
+ 		return 0;
+ 
+ 	if (!kernfs_get_active(of->kn))
+ 		return 0;
+ 
+ 	ret = 0;
+ 	if (of->vm_ops->migrate)
+ 		ret = of->vm_ops->migrate(vma, from, to, flags);
+ 
+ 	kernfs_put_active(of->kn);
+ 	return ret;
+ }
+ #endif
+ 
+ static const struct vm_operations_struct kernfs_vm_ops = {
+ 	.open		= kernfs_vma_open,
+ 	.fault		= kernfs_vma_fault,
+ 	.page_mkwrite	= kernfs_vma_page_mkwrite,
+ 	.access		= kernfs_vma_access,
+ #ifdef CONFIG_NUMA
+ 	.set_policy	= kernfs_vma_set_policy,
+ 	.get_policy	= kernfs_vma_get_policy,
+ 	.migrate	= kernfs_vma_migrate,
+ #endif
+ };
+ 
+ static int kernfs_fop_mmap(struct file *file, struct vm_area_struct *vma)
+ {
+ 	struct kernfs_open_file *of = kernfs_of(file);
+ 	const struct kernfs_ops *ops;
+ 	int rc;
+ 
+ 	/*
+ 	 * mmap path and of->mutex are prone to triggering spurious lockdep
+ 	 * warnings and we don't want to add spurious locking dependency
+ 	 * between the two.  Check whether mmap is actually implemented
+ 	 * without grabbing @of->mutex by testing HAS_MMAP flag.  See the
+ 	 * comment in kernfs_file_open() for more details.
+ 	 */
+ 	if (!(of->kn->flags & KERNFS_HAS_MMAP))
+ 		return -ENODEV;
+ 
+ 	mutex_lock(&of->mutex);
+ 
+ 	rc = -ENODEV;
+ 	if (!kernfs_get_active(of->kn))
+ 		goto out_unlock;
+ 
+ 	ops = kernfs_ops(of->kn);
+ 	rc = ops->mmap(of, vma);
+ 
+ 	/*
+ 	 * PowerPC's pci_mmap of legacy_mem uses shmem_zero_setup()
+ 	 * to satisfy versions of X which crash if the mmap fails: that
+ 	 * substitutes a new vm_file, and we don't then want bin_vm_ops.
+ 	 */
+ 	if (vma->vm_file != file)
+ 		goto out_put;
+ 
+ 	rc = -EINVAL;
+ 	if (of->mmapped && of->vm_ops != vma->vm_ops)
+ 		goto out_put;
+ 
+ 	/*
+ 	 * It is not possible to successfully wrap close.
+ 	 * So error if someone is trying to use close.
+ 	 */
+ 	rc = -EINVAL;
+ 	if (vma->vm_ops && vma->vm_ops->close)
+ 		goto out_put;
+ 
+ 	rc = 0;
+ 	of->mmapped = 1;
+ 	of->vm_ops = vma->vm_ops;
+ 	vma->vm_ops = &kernfs_vm_ops;
+ out_put:
+ 	kernfs_put_active(of->kn);
+ out_unlock:
+ 	mutex_unlock(&of->mutex);
+ 
+ 	return rc;
+ }
+ 
+ /**
+  *	kernfs_get_open_node - get or create kernfs_open_node
+  *	@kn: target kernfs_node
+  *	@of: kernfs_open_file for this instance of open
+  *
+  *	If @kn->attr.open exists, increment its reference count; otherwise,
+  *	create one.  @of is chained to the files list.
+  *
+  *	LOCKING:
+  *	Kernel thread context (may sleep).
+  *
+  *	RETURNS:
+  *	0 on success, -errno on failure.
+  */
+ static int kernfs_get_open_node(struct kernfs_node *kn,
+ 				struct kernfs_open_file *of)
+ {
+ 	struct kernfs_open_node *on, *new_on = NULL;
+ 
+  retry:
+ 	mutex_lock(&kernfs_open_file_mutex);
+ 	spin_lock_irq(&kernfs_open_node_lock);
+ 
+ 	if (!kn->attr.open && new_on) {
+ 		kn->attr.open = new_on;
+ 		new_on = NULL;
+ 	}
+ 
+ 	on = kn->attr.open;
+ 	if (on) {
+ 		atomic_inc(&on->refcnt);
+ 		list_add_tail(&of->list, &on->files);
+ 	}
+ 
+ 	spin_unlock_irq(&kernfs_open_node_lock);
+ 	mutex_unlock(&kernfs_open_file_mutex);
+ 
+ 	if (on) {
+ 		kfree(new_on);
+ 		return 0;
+ 	}
+ 
+ 	/* not there, initialize a new one and retry */
+ 	new_on = kmalloc(sizeof(*new_on), GFP_KERNEL);
+ 	if (!new_on)
+ 		return -ENOMEM;
+ 
+ 	atomic_set(&new_on->refcnt, 0);
+ 	atomic_set(&new_on->event, 1);
+ 	init_waitqueue_head(&new_on->poll);
+ 	INIT_LIST_HEAD(&new_on->files);
+ 	goto retry;
+ }
+ 
+ /**
+  *	kernfs_put_open_node - put kernfs_open_node
+  *	@kn: target kernfs_nodet
+  *	@of: associated kernfs_open_file
+  *
+  *	Put @kn->attr.open and unlink @of from the files list.  If
+  *	reference count reaches zero, disassociate and free it.
+  *
+  *	LOCKING:
+  *	None.
+  */
+ static void kernfs_put_open_node(struct kernfs_node *kn,
+ 				 struct kernfs_open_file *of)
+ {
+ 	struct kernfs_open_node *on = kn->attr.open;
+ 	unsigned long flags;
+ 
+ 	mutex_lock(&kernfs_open_file_mutex);
+ 	spin_lock_irqsave(&kernfs_open_node_lock, flags);
+ 
+ 	if (of)
+ 		list_del(&of->list);
+ 
+ 	if (atomic_dec_and_test(&on->refcnt))
+ 		kn->attr.open = NULL;
+ 	else
+ 		on = NULL;
+ 
+ 	spin_unlock_irqrestore(&kernfs_open_node_lock, flags);
+ 	mutex_unlock(&kernfs_open_file_mutex);
+ 
+ 	kfree(on);
+ }
+ 
+ static int kernfs_fop_open(struct inode *inode, struct file *file)
+ {
+ 	struct kernfs_node *kn = file->f_path.dentry->d_fsdata;
+ 	const struct kernfs_ops *ops;
+ 	struct kernfs_open_file *of;
+ 	bool has_read, has_write, has_mmap;
+ 	int error = -EACCES;
+ 
+ 	if (!kernfs_get_active(kn))
+ 		return -ENODEV;
+ 
+ 	ops = kernfs_ops(kn);
+ 
+ 	has_read = ops->seq_show || ops->read || ops->mmap;
+ 	has_write = ops->write || ops->mmap;
+ 	has_mmap = ops->mmap;
+ 
+ 	/* check perms and supported operations */
+ 	if ((file->f_mode & FMODE_WRITE) &&
+ 	    (!(inode->i_mode & S_IWUGO) || !has_write))
+ 		goto err_out;
+ 
+ 	if ((file->f_mode & FMODE_READ) &&
+ 	    (!(inode->i_mode & S_IRUGO) || !has_read))
+ 		goto err_out;
+ 
+ 	/* allocate a kernfs_open_file for the file */
+ 	error = -ENOMEM;
+ 	of = kzalloc(sizeof(struct kernfs_open_file), GFP_KERNEL);
+ 	if (!of)
+ 		goto err_out;
+ 
+ 	/*
+ 	 * The following is done to give a different lockdep key to
+ 	 * @of->mutex for files which implement mmap.  This is a rather
+ 	 * crude way to avoid false positive lockdep warning around
+ 	 * mm->mmap_sem - mmap nests @of->mutex under mm->mmap_sem and
+ 	 * reading /sys/block/sda/trace/act_mask grabs sr_mutex, under
+ 	 * which mm->mmap_sem nests, while holding @of->mutex.  As each
+ 	 * open file has a separate mutex, it's okay as long as those don't
+ 	 * happen on the same file.  At this point, we can't easily give
+ 	 * each file a separate locking class.  Let's differentiate on
+ 	 * whether the file has mmap or not for now.
+ 	 *
+ 	 * Both paths of the branch look the same.  They're supposed to
+ 	 * look that way and give @of->mutex different static lockdep keys.
+ 	 */
+ 	if (has_mmap)
+ 		mutex_init(&of->mutex);
+ 	else
+ 		mutex_init(&of->mutex);
+ 
+ 	of->kn = kn;
+ 	of->file = file;
+ 
+ 	/*
+ 	 * Always instantiate seq_file even if read access doesn't use
+ 	 * seq_file or is not requested.  This unifies private data access
+ 	 * and readable regular files are the vast majority anyway.
+ 	 */
+ 	if (ops->seq_show)
+ 		error = seq_open(file, &kernfs_seq_ops);
+ 	else
+ 		error = seq_open(file, NULL);
+ 	if (error)
+ 		goto err_free;
+ 
+ 	((struct seq_file *)file->private_data)->private = of;
+ 
+ 	/* seq_file clears PWRITE unconditionally, restore it if WRITE */
+ 	if (file->f_mode & FMODE_WRITE)
+ 		file->f_mode |= FMODE_PWRITE;
+ 
+ 	/* make sure we have open node struct */
+ 	error = kernfs_get_open_node(kn, of);
+ 	if (error)
+ 		goto err_close;
+ 
+ 	/* open succeeded, put active references */
+ 	kernfs_put_active(kn);
+ 	return 0;
+ 
+ err_close:
+ 	seq_release(inode, file);
+ err_free:
+ 	kfree(of);
+ err_out:
+ 	kernfs_put_active(kn);
+ 	return error;
+ }
+ 
+ static int kernfs_fop_release(struct inode *inode, struct file *filp)
+ {
+ 	struct kernfs_node *kn = filp->f_path.dentry->d_fsdata;
+ 	struct kernfs_open_file *of = kernfs_of(filp);
+ 
+ 	kernfs_put_open_node(kn, of);
+ 	seq_release(inode, filp);
+ 	kfree(of);
+ 
+ 	return 0;
+ }
+ 
+ void kernfs_unmap_bin_file(struct kernfs_node *kn)
+ {
+ 	struct kernfs_open_node *on;
+ 	struct kernfs_open_file *of;
+ 
+ 	if (!(kn->flags & KERNFS_HAS_MMAP))
+ 		return;
+ 
+ 	spin_lock_irq(&kernfs_open_node_lock);
+ 	on = kn->attr.open;
+ 	if (on)
+ 		atomic_inc(&on->refcnt);
+ 	spin_unlock_irq(&kernfs_open_node_lock);
+ 	if (!on)
+ 		return;
+ 
+ 	mutex_lock(&kernfs_open_file_mutex);
+ 	list_for_each_entry(of, &on->files, list) {
+ 		struct inode *inode = file_inode(of->file);
+ 		unmap_mapping_range(inode->i_mapping, 0, 0, 1);
+ 	}
+ 	mutex_unlock(&kernfs_open_file_mutex);
+ 
+ 	kernfs_put_open_node(kn, NULL);
+ }
+ 
+ /*
+  * Kernfs attribute files are pollable.  The idea is that you read
+  * the content and then you use 'poll' or 'select' to wait for
+  * the content to change.  When the content changes (assuming the
+  * manager for the kobject supports notification), poll will
+  * return POLLERR|POLLPRI, and select will return the fd whether
+  * it is waiting for read, write, or exceptions.
+  * Once poll/select indicates that the value has changed, you
+  * need to close and re-open the file, or seek to 0 and read again.
+  * Reminder: this only works for attributes which actively support
+  * it, and it is not possible to test an attribute from userspace
+  * to see if it supports poll (Neither 'poll' nor 'select' return
+  * an appropriate error code).  When in doubt, set a suitable timeout value.
+  */
+ static unsigned int kernfs_fop_poll(struct file *filp, poll_table *wait)
+ {
+ 	struct kernfs_open_file *of = kernfs_of(filp);
+ 	struct kernfs_node *kn = filp->f_path.dentry->d_fsdata;
+ 	struct kernfs_open_node *on = kn->attr.open;
+ 
+ 	/* need parent for the kobj, grab both */
+ 	if (!kernfs_get_active(kn))
+ 		goto trigger;
+ 
+ 	poll_wait(filp, &on->poll, wait);
+ 
+ 	kernfs_put_active(kn);
+ 
+ 	if (of->event != atomic_read(&on->event))
+ 		goto trigger;
+ 
+ 	return DEFAULT_POLLMASK;
+ 
+  trigger:
+ 	return DEFAULT_POLLMASK|POLLERR|POLLPRI;
+ }
+ 
+ /**
+  * kernfs_notify - notify a kernfs file
+  * @kn: file to notify
+  *
+  * Notify @kn such that poll(2) on @kn wakes up.
+  */
+ void kernfs_notify(struct kernfs_node *kn)
+ {
+ 	struct kernfs_open_node *on;
+ 	unsigned long flags;
+ 
+ 	spin_lock_irqsave(&kernfs_open_node_lock, flags);
+ 
+ 	if (!WARN_ON(kernfs_type(kn) != KERNFS_FILE)) {
+ 		on = kn->attr.open;
+ 		if (on) {
+ 			atomic_inc(&on->event);
+ 			wake_up_interruptible(&on->poll);
+ 		}
+ 	}
+ 
+ 	spin_unlock_irqrestore(&kernfs_open_node_lock, flags);
+ }
+ EXPORT_SYMBOL_GPL(kernfs_notify);
+ 
+ const struct file_operations kernfs_file_fops = {
+ 	.read		= kernfs_fop_read,
+ 	.write		= kernfs_fop_write,
+ 	.llseek		= generic_file_llseek,
+ 	.mmap		= kernfs_fop_mmap,
+ 	.open		= kernfs_fop_open,
+ 	.release	= kernfs_fop_release,
+ 	.poll		= kernfs_fop_poll,
+ };
+ 
+ /**
+  * __kernfs_create_file - kernfs internal function to create a file
+  * @parent: directory to create the file in
+  * @name: name of the file
+  * @mode: mode of the file
+  * @size: size of the file
+  * @ops: kernfs operations for the file
+  * @priv: private data for the file
+  * @ns: optional namespace tag of the file
+  * @static_name: don't copy file name
+  * @key: lockdep key for the file's active_ref, %NULL to disable lockdep
+  *
+  * Returns the created node on success, ERR_PTR() value on error.
+  */
+ struct kernfs_node *__kernfs_create_file(struct kernfs_node *parent,
+ 					 const char *name,
+ 					 umode_t mode, loff_t size,
+ 					 const struct kernfs_ops *ops,
+ 					 void *priv, const void *ns,
+ 					 bool name_is_static,
+ 					 struct lock_class_key *key)
+ {
+ 	struct kernfs_addrm_cxt acxt;
+ 	struct kernfs_node *kn;
+ 	unsigned flags;
+ 	int rc;
+ 
+ 	flags = KERNFS_FILE;
+ 	if (name_is_static)
+ 		flags |= KERNFS_STATIC_NAME;
+ 
+ 	kn = kernfs_new_node(kernfs_root(parent), name,
+ 			     (mode & S_IALLUGO) | S_IFREG, flags);
+ 	if (!kn)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	kn->attr.ops = ops;
+ 	kn->attr.size = size;
+ 	kn->ns = ns;
+ 	kn->priv = priv;
+ 
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	if (key) {
+ 		lockdep_init_map(&kn->dep_map, "s_active", key, 0);
+ 		kn->flags |= KERNFS_LOCKDEP;
+ 	}
+ #endif
+ 
+ 	/*
+ 	 * kn->attr.ops is accesible only while holding active ref.  We
+ 	 * need to know whether some ops are implemented outside active
+ 	 * ref.  Cache their existence in flags.
+ 	 */
+ 	if (ops->seq_show)
+ 		kn->flags |= KERNFS_HAS_SEQ_SHOW;
+ 	if (ops->mmap)
+ 		kn->flags |= KERNFS_HAS_MMAP;
+ 
+ 	rc = -ENOENT;
+ 	if (kernfs_get_active(parent)) {
+ 		kernfs_addrm_start(&acxt);
+ 		rc = kernfs_add_one(&acxt, kn, parent);
+ 		kernfs_addrm_finish(&acxt);
+ 		kernfs_put_active(parent);
+ 	}
+ 
+ 	if (rc) {
+ 		kernfs_put(kn);
+ 		return ERR_PTR(rc);
+ 	}
+ 	return kn;
+ }
++>>>>>>> ae34372eb840 (kernfs: remove KERNFS_REMOVED)
diff --cc fs/kernfs/symlink.c
index 2578715baf0e,b2c106ca3434..000000000000
--- a/fs/kernfs/symlink.c
+++ b/fs/kernfs/symlink.c
@@@ -7,3 -7,150 +7,153 @@@
   *
   * This file is released under the GPLv2.
   */
++<<<<<<< HEAD
++=======
+ 
+ #include <linux/fs.h>
+ #include <linux/gfp.h>
+ #include <linux/namei.h>
+ 
+ #include "kernfs-internal.h"
+ 
+ /**
+  * kernfs_create_link - create a symlink
+  * @parent: directory to create the symlink in
+  * @name: name of the symlink
+  * @target: target node for the symlink to point to
+  *
+  * Returns the created node on success, ERR_PTR() value on error.
+  */
+ struct kernfs_node *kernfs_create_link(struct kernfs_node *parent,
+ 				       const char *name,
+ 				       struct kernfs_node *target)
+ {
+ 	struct kernfs_node *kn;
+ 	struct kernfs_addrm_cxt acxt;
+ 	int error;
+ 
+ 	kn = kernfs_new_node(kernfs_root(parent), name, S_IFLNK|S_IRWXUGO,
+ 			     KERNFS_LINK);
+ 	if (!kn)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	if (kernfs_ns_enabled(parent))
+ 		kn->ns = target->ns;
+ 	kn->symlink.target_kn = target;
+ 	kernfs_get(target);	/* ref owned by symlink */
+ 
+ 	error = -ENOENT;
+ 	if (kernfs_get_active(parent)) {
+ 		kernfs_addrm_start(&acxt);
+ 		error = kernfs_add_one(&acxt, kn, parent);
+ 		kernfs_addrm_finish(&acxt);
+ 		kernfs_put_active(parent);
+ 	}
+ 
+ 	if (!error)
+ 		return kn;
+ 
+ 	kernfs_put(kn);
+ 	return ERR_PTR(error);
+ }
+ 
+ static int kernfs_get_target_path(struct kernfs_node *parent,
+ 				  struct kernfs_node *target, char *path)
+ {
+ 	struct kernfs_node *base, *kn;
+ 	char *s = path;
+ 	int len = 0;
+ 
+ 	/* go up to the root, stop at the base */
+ 	base = parent;
+ 	while (base->parent) {
+ 		kn = target->parent;
+ 		while (kn->parent && base != kn)
+ 			kn = kn->parent;
+ 
+ 		if (base == kn)
+ 			break;
+ 
+ 		strcpy(s, "../");
+ 		s += 3;
+ 		base = base->parent;
+ 	}
+ 
+ 	/* determine end of target string for reverse fillup */
+ 	kn = target;
+ 	while (kn->parent && kn != base) {
+ 		len += strlen(kn->name) + 1;
+ 		kn = kn->parent;
+ 	}
+ 
+ 	/* check limits */
+ 	if (len < 2)
+ 		return -EINVAL;
+ 	len--;
+ 	if ((s - path) + len > PATH_MAX)
+ 		return -ENAMETOOLONG;
+ 
+ 	/* reverse fillup of target string from target to base */
+ 	kn = target;
+ 	while (kn->parent && kn != base) {
+ 		int slen = strlen(kn->name);
+ 
+ 		len -= slen;
+ 		strncpy(s + len, kn->name, slen);
+ 		if (len)
+ 			s[--len] = '/';
+ 
+ 		kn = kn->parent;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int kernfs_getlink(struct dentry *dentry, char *path)
+ {
+ 	struct kernfs_node *kn = dentry->d_fsdata;
+ 	struct kernfs_node *parent = kn->parent;
+ 	struct kernfs_node *target = kn->symlink.target_kn;
+ 	int error;
+ 
+ 	mutex_lock(&kernfs_mutex);
+ 	error = kernfs_get_target_path(parent, target, path);
+ 	mutex_unlock(&kernfs_mutex);
+ 
+ 	return error;
+ }
+ 
+ static void *kernfs_iop_follow_link(struct dentry *dentry, struct nameidata *nd)
+ {
+ 	int error = -ENOMEM;
+ 	unsigned long page = get_zeroed_page(GFP_KERNEL);
+ 	if (page) {
+ 		error = kernfs_getlink(dentry, (char *) page);
+ 		if (error < 0)
+ 			free_page((unsigned long)page);
+ 	}
+ 	nd_set_link(nd, error ? ERR_PTR(error) : (char *)page);
+ 	return NULL;
+ }
+ 
+ static void kernfs_iop_put_link(struct dentry *dentry, struct nameidata *nd,
+ 				void *cookie)
+ {
+ 	char *page = nd_get_link(nd);
+ 	if (!IS_ERR(page))
+ 		free_page((unsigned long)page);
+ }
+ 
+ const struct inode_operations kernfs_symlink_iops = {
+ 	.setxattr	= kernfs_iop_setxattr,
+ 	.removexattr	= kernfs_iop_removexattr,
+ 	.getxattr	= kernfs_iop_getxattr,
+ 	.listxattr	= kernfs_iop_listxattr,
+ 	.readlink	= generic_readlink,
+ 	.follow_link	= kernfs_iop_follow_link,
+ 	.put_link	= kernfs_iop_put_link,
+ 	.setattr	= kernfs_iop_setattr,
+ 	.getattr	= kernfs_iop_getattr,
+ 	.permission	= kernfs_iop_permission,
+ };
++>>>>>>> ae34372eb840 (kernfs: remove KERNFS_REMOVED)
diff --cc include/linux/kernfs.h
index 254b9e872b09,289d4f639ade..000000000000
--- a/include/linux/kernfs.h
+++ b/include/linux/kernfs.h
@@@ -7,6 -7,367 +7,371 @@@
  #ifndef __LINUX_KERNFS_H
  #define __LINUX_KERNFS_H
  
++<<<<<<< HEAD
 +struct sysfs_dirent;
++=======
+ #include <linux/kernel.h>
+ #include <linux/err.h>
+ #include <linux/list.h>
+ #include <linux/mutex.h>
+ #include <linux/idr.h>
+ #include <linux/lockdep.h>
+ #include <linux/rbtree.h>
+ #include <linux/atomic.h>
+ #include <linux/wait.h>
+ 
+ struct file;
+ struct iattr;
+ struct seq_file;
+ struct vm_area_struct;
+ struct super_block;
+ struct file_system_type;
+ 
+ struct kernfs_open_node;
+ struct kernfs_iattrs;
+ 
+ enum kernfs_node_type {
+ 	KERNFS_DIR		= 0x0001,
+ 	KERNFS_FILE		= 0x0002,
+ 	KERNFS_LINK		= 0x0004,
+ };
+ 
+ #define KERNFS_TYPE_MASK	0x000f
+ #define KERNFS_FLAG_MASK	~KERNFS_TYPE_MASK
+ 
+ enum kernfs_node_flag {
+ 	KERNFS_NS		= 0x0020,
+ 	KERNFS_HAS_SEQ_SHOW	= 0x0040,
+ 	KERNFS_HAS_MMAP		= 0x0080,
+ 	KERNFS_LOCKDEP		= 0x0100,
+ 	KERNFS_STATIC_NAME	= 0x0200,
+ };
+ 
+ /* type-specific structures for kernfs_node union members */
+ struct kernfs_elem_dir {
+ 	unsigned long		subdirs;
+ 	/* children rbtree starts here and goes through kn->rb */
+ 	struct rb_root		children;
+ 
+ 	/*
+ 	 * The kernfs hierarchy this directory belongs to.  This fits
+ 	 * better directly in kernfs_node but is here to save space.
+ 	 */
+ 	struct kernfs_root	*root;
+ };
+ 
+ struct kernfs_elem_symlink {
+ 	struct kernfs_node	*target_kn;
+ };
+ 
+ struct kernfs_elem_attr {
+ 	const struct kernfs_ops	*ops;
+ 	struct kernfs_open_node	*open;
+ 	loff_t			size;
+ };
+ 
+ /*
+  * kernfs_node - the building block of kernfs hierarchy.  Each and every
+  * kernfs node is represented by single kernfs_node.  Most fields are
+  * private to kernfs and shouldn't be accessed directly by kernfs users.
+  *
+  * As long as s_count reference is held, the kernfs_node itself is
+  * accessible.  Dereferencing elem or any other outer entity requires
+  * active reference.
+  */
+ struct kernfs_node {
+ 	atomic_t		count;
+ 	atomic_t		active;
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	struct lockdep_map	dep_map;
+ #endif
+ 	/* the following two fields are published */
+ 	struct kernfs_node	*parent;
+ 	const char		*name;
+ 
+ 	struct rb_node		rb;
+ 
+ 	union {
+ 		struct kernfs_node	*removed_list;
+ 	} u;
+ 
+ 	const void		*ns;	/* namespace tag */
+ 	unsigned int		hash;	/* ns + name hash */
+ 	union {
+ 		struct kernfs_elem_dir		dir;
+ 		struct kernfs_elem_symlink	symlink;
+ 		struct kernfs_elem_attr		attr;
+ 	};
+ 
+ 	void			*priv;
+ 
+ 	unsigned short		flags;
+ 	umode_t			mode;
+ 	unsigned int		ino;
+ 	struct kernfs_iattrs	*iattr;
+ };
+ 
+ /*
+  * kernfs_dir_ops may be specified on kernfs_create_root() to support
+  * directory manipulation syscalls.  These optional callbacks are invoked
+  * on the matching syscalls and can perform any kernfs operations which
+  * don't necessarily have to be the exact operation requested.
+  */
+ struct kernfs_dir_ops {
+ 	int (*mkdir)(struct kernfs_node *parent, const char *name,
+ 		     umode_t mode);
+ 	int (*rmdir)(struct kernfs_node *kn);
+ 	int (*rename)(struct kernfs_node *kn, struct kernfs_node *new_parent,
+ 		      const char *new_name);
+ };
+ 
+ struct kernfs_root {
+ 	/* published fields */
+ 	struct kernfs_node	*kn;
+ 
+ 	/* private fields, do not use outside kernfs proper */
+ 	struct ida		ino_ida;
+ 	struct kernfs_dir_ops	*dir_ops;
+ 	wait_queue_head_t	deactivate_waitq;
+ };
+ 
+ struct kernfs_open_file {
+ 	/* published fields */
+ 	struct kernfs_node	*kn;
+ 	struct file		*file;
+ 
+ 	/* private fields, do not use outside kernfs proper */
+ 	struct mutex		mutex;
+ 	int			event;
+ 	struct list_head	list;
+ 
+ 	bool			mmapped;
+ 	const struct vm_operations_struct *vm_ops;
+ };
+ 
+ struct kernfs_ops {
+ 	/*
+ 	 * Read is handled by either seq_file or raw_read().
+ 	 *
+ 	 * If seq_show() is present, seq_file path is active.  Other seq
+ 	 * operations are optional and if not implemented, the behavior is
+ 	 * equivalent to single_open().  @sf->private points to the
+ 	 * associated kernfs_open_file.
+ 	 *
+ 	 * read() is bounced through kernel buffer and a read larger than
+ 	 * PAGE_SIZE results in partial operation of PAGE_SIZE.
+ 	 */
+ 	int (*seq_show)(struct seq_file *sf, void *v);
+ 
+ 	void *(*seq_start)(struct seq_file *sf, loff_t *ppos);
+ 	void *(*seq_next)(struct seq_file *sf, void *v, loff_t *ppos);
+ 	void (*seq_stop)(struct seq_file *sf, void *v);
+ 
+ 	ssize_t (*read)(struct kernfs_open_file *of, char *buf, size_t bytes,
+ 			loff_t off);
+ 
+ 	/*
+ 	 * write() is bounced through kernel buffer and a write larger than
+ 	 * PAGE_SIZE results in partial operation of PAGE_SIZE.
+ 	 */
+ 	ssize_t (*write)(struct kernfs_open_file *of, char *buf, size_t bytes,
+ 			 loff_t off);
+ 
+ 	int (*mmap)(struct kernfs_open_file *of, struct vm_area_struct *vma);
+ 
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	struct lock_class_key	lockdep_key;
+ #endif
+ };
+ 
+ #ifdef CONFIG_SYSFS
+ 
+ static inline enum kernfs_node_type kernfs_type(struct kernfs_node *kn)
+ {
+ 	return kn->flags & KERNFS_TYPE_MASK;
+ }
+ 
+ /**
+  * kernfs_enable_ns - enable namespace under a directory
+  * @kn: directory of interest, should be empty
+  *
+  * This is to be called right after @kn is created to enable namespace
+  * under it.  All children of @kn must have non-NULL namespace tags and
+  * only the ones which match the super_block's tag will be visible.
+  */
+ static inline void kernfs_enable_ns(struct kernfs_node *kn)
+ {
+ 	WARN_ON_ONCE(kernfs_type(kn) != KERNFS_DIR);
+ 	WARN_ON_ONCE(!RB_EMPTY_ROOT(&kn->dir.children));
+ 	kn->flags |= KERNFS_NS;
+ }
+ 
+ /**
+  * kernfs_ns_enabled - test whether namespace is enabled
+  * @kn: the node to test
+  *
+  * Test whether namespace filtering is enabled for the children of @ns.
+  */
+ static inline bool kernfs_ns_enabled(struct kernfs_node *kn)
+ {
+ 	return kn->flags & KERNFS_NS;
+ }
+ 
+ struct kernfs_node *kernfs_find_and_get_ns(struct kernfs_node *parent,
+ 					   const char *name, const void *ns);
+ void kernfs_get(struct kernfs_node *kn);
+ void kernfs_put(struct kernfs_node *kn);
+ 
+ struct kernfs_root *kernfs_create_root(struct kernfs_dir_ops *kdops,
+ 				       void *priv);
+ void kernfs_destroy_root(struct kernfs_root *root);
+ 
+ struct kernfs_node *kernfs_create_dir_ns(struct kernfs_node *parent,
+ 					 const char *name, umode_t mode,
+ 					 void *priv, const void *ns);
+ struct kernfs_node *__kernfs_create_file(struct kernfs_node *parent,
+ 					 const char *name,
+ 					 umode_t mode, loff_t size,
+ 					 const struct kernfs_ops *ops,
+ 					 void *priv, const void *ns,
+ 					 bool name_is_static,
+ 					 struct lock_class_key *key);
+ struct kernfs_node *kernfs_create_link(struct kernfs_node *parent,
+ 				       const char *name,
+ 				       struct kernfs_node *target);
+ void kernfs_remove(struct kernfs_node *kn);
+ int kernfs_remove_by_name_ns(struct kernfs_node *parent, const char *name,
+ 			     const void *ns);
+ int kernfs_rename_ns(struct kernfs_node *kn, struct kernfs_node *new_parent,
+ 		     const char *new_name, const void *new_ns);
+ int kernfs_setattr(struct kernfs_node *kn, const struct iattr *iattr);
+ void kernfs_notify(struct kernfs_node *kn);
+ 
+ const void *kernfs_super_ns(struct super_block *sb);
+ struct dentry *kernfs_mount_ns(struct file_system_type *fs_type, int flags,
+ 			       struct kernfs_root *root, const void *ns);
+ void kernfs_kill_sb(struct super_block *sb);
+ 
+ void kernfs_init(void);
+ 
+ #else	/* CONFIG_SYSFS */
+ 
+ static inline enum kernfs_node_type kernfs_type(struct kernfs_node *kn)
+ { return 0; }	/* whatever */
+ 
+ static inline void kernfs_enable_ns(struct kernfs_node *kn) { }
+ 
+ static inline bool kernfs_ns_enabled(struct kernfs_node *kn)
+ { return false; }
+ 
+ static inline struct kernfs_node *
+ kernfs_find_and_get_ns(struct kernfs_node *parent, const char *name,
+ 		       const void *ns)
+ { return NULL; }
+ 
+ static inline void kernfs_get(struct kernfs_node *kn) { }
+ static inline void kernfs_put(struct kernfs_node *kn) { }
+ 
+ static inline struct kernfs_root *
+ kernfs_create_root(struct kernfs_dir_ops *kdops, void *priv)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline void kernfs_destroy_root(struct kernfs_root *root) { }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_dir_ns(struct kernfs_node *parent, const char *name,
+ 		     umode_t mode, void *priv, const void *ns)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline struct kernfs_node *
+ __kernfs_create_file(struct kernfs_node *parent, const char *name,
+ 		     umode_t mode, loff_t size, const struct kernfs_ops *ops,
+ 		     void *priv, const void *ns, bool name_is_static,
+ 		     struct lock_class_key *key)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_link(struct kernfs_node *parent, const char *name,
+ 		   struct kernfs_node *target)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline void kernfs_remove(struct kernfs_node *kn) { }
+ 
+ static inline int kernfs_remove_by_name_ns(struct kernfs_node *kn,
+ 					   const char *name, const void *ns)
+ { return -ENOSYS; }
+ 
+ static inline int kernfs_rename_ns(struct kernfs_node *kn,
+ 				   struct kernfs_node *new_parent,
+ 				   const char *new_name, const void *new_ns)
+ { return -ENOSYS; }
+ 
+ static inline int kernfs_setattr(struct kernfs_node *kn,
+ 				 const struct iattr *iattr)
+ { return -ENOSYS; }
+ 
+ static inline void kernfs_notify(struct kernfs_node *kn) { }
+ 
+ static inline const void *kernfs_super_ns(struct super_block *sb)
+ { return NULL; }
+ 
+ static inline struct dentry *
+ kernfs_mount_ns(struct file_system_type *fs_type, int flags,
+ 		struct kernfs_root *root, const void *ns)
+ { return ERR_PTR(-ENOSYS); }
+ 
+ static inline void kernfs_kill_sb(struct super_block *sb) { }
+ 
+ static inline void kernfs_init(void) { }
+ 
+ #endif	/* CONFIG_SYSFS */
+ 
+ static inline struct kernfs_node *
+ kernfs_find_and_get(struct kernfs_node *kn, const char *name)
+ {
+ 	return kernfs_find_and_get_ns(kn, name, NULL);
+ }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_dir(struct kernfs_node *parent, const char *name, umode_t mode,
+ 		  void *priv)
+ {
+ 	return kernfs_create_dir_ns(parent, name, mode, priv, NULL);
+ }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_file_ns(struct kernfs_node *parent, const char *name,
+ 		      umode_t mode, loff_t size, const struct kernfs_ops *ops,
+ 		      void *priv, const void *ns)
+ {
+ 	struct lock_class_key *key = NULL;
+ 
+ #ifdef CONFIG_DEBUG_LOCK_ALLOC
+ 	key = (struct lock_class_key *)&ops->lockdep_key;
+ #endif
+ 	return __kernfs_create_file(parent, name, mode, size, ops, priv, ns,
+ 				    false, key);
+ }
+ 
+ static inline struct kernfs_node *
+ kernfs_create_file(struct kernfs_node *parent, const char *name, umode_t mode,
+ 		   loff_t size, const struct kernfs_ops *ops, void *priv)
+ {
+ 	return kernfs_create_file_ns(parent, name, mode, size, ops, priv, NULL);
+ }
+ 
+ static inline int kernfs_remove_by_name(struct kernfs_node *parent,
+ 					const char *name)
+ {
+ 	return kernfs_remove_by_name_ns(parent, name, NULL);
+ }
+ 
+ static inline struct dentry *
+ kernfs_mount(struct file_system_type *fs_type, int flags,
+ 	     struct kernfs_root *root)
+ {
+ 	return kernfs_mount_ns(fs_type, flags, root, NULL);
+ }
++>>>>>>> ae34372eb840 (kernfs: remove KERNFS_REMOVED)
  
  #endif	/* __LINUX_KERNFS_H */
* Unmerged path fs/kernfs/kernfs-internal.h
* Unmerged path fs/kernfs/dir.c
* Unmerged path fs/kernfs/file.c
* Unmerged path fs/kernfs/kernfs-internal.h
* Unmerged path fs/kernfs/symlink.c
* Unmerged path include/linux/kernfs.h
