locking/mcs: Better differentiate between MCS variants

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Davidlohr Bueso <dave@stgolabs.net>
commit d84b6728c54dcf73bcef3e3f7cf6767e2d224e39
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/d84b6728.failed

We have two flavors of the MCS spinlock: standard and cancelable (OSQ).
While each one is independent of the other, we currently mix and match
them. This patch:

  - Moves the OSQ code out of mcs_spinlock.h (which only deals with the traditional
    version) into include/linux/osq_lock.h. No unnecessary code is added to the
    more global header file, anything locks that make use of OSQ must include
    it anyway.

  - Renames mcs_spinlock.c to osq_lock.c. This file only contains osq code.

  - Introduces a CONFIG_LOCK_SPIN_ON_OWNER in order to only build osq_lock
    if there is support for it.

	Signed-off-by: Davidlohr Bueso <dbueso@suse.de>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: "Paul E. McKenney" <paulmck@linux.vnet.ibm.com>
	Cc: Jason Low <jason.low2@hp.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Mikulas Patocka <mpatocka@redhat.com>
	Cc: Waiman Long <Waiman.Long@hp.com>
Link: http://lkml.kernel.org/r/1420573509-24774-5-git-send-email-dave@stgolabs.net
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit d84b6728c54dcf73bcef3e3f7cf6767e2d224e39)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/osq_lock.h
#	kernel/Kconfig.locks
#	kernel/locking/Makefile
#	kernel/locking/mcs_spinlock.c
#	kernel/mcs_spinlock.c
#	kernel/mcs_spinlock.h
#	kernel/osq_lock.c
diff --cc kernel/Kconfig.locks
index 44511d100eaa,08561f1acd13..000000000000
--- a/kernel/Kconfig.locks
+++ b/kernel/Kconfig.locks
@@@ -220,6 -220,24 +220,25 @@@ config INLINE_WRITE_UNLOCK_IRQRESTOR
  
  endif
  
 -config ARCH_SUPPORTS_ATOMIC_RMW
 -	bool
 -
  config MUTEX_SPIN_ON_OWNER
  	def_bool y
++<<<<<<< HEAD
 +	depends on SMP && !DEBUG_MUTEXES
++=======
+ 	depends on SMP && !DEBUG_MUTEXES && ARCH_SUPPORTS_ATOMIC_RMW
+ 
+ config RWSEM_SPIN_ON_OWNER
+        def_bool y
+        depends on SMP && RWSEM_XCHGADD_ALGORITHM && ARCH_SUPPORTS_ATOMIC_RMW
+ 
+ config LOCK_SPIN_ON_OWNER
+        def_bool y
+        depends on MUTEX_SPIN_ON_OWNER || RWSEM_SPIN_ON_OWNER
+ 
+ config ARCH_USE_QUEUE_RWLOCK
+ 	bool
+ 
+ config QUEUE_RWLOCK
+ 	def_bool y if ARCH_USE_QUEUE_RWLOCK
+ 	depends on SMP
++>>>>>>> d84b6728c54d (locking/mcs: Better differentiate between MCS variants)
diff --cc kernel/mcs_spinlock.h
index 074c62536f83,d1fe2ba5bac9..000000000000
--- a/kernel/mcs_spinlock.h
+++ b/kernel/mcs_spinlock.h
@@@ -108,19 -107,5 +108,22 @@@ void mcs_spin_unlock(struct mcs_spinloc
  	/* Pass lock to next waiter. */
  	arch_mcs_spin_unlock_contended(&next->locked);
  }
++<<<<<<< HEAD:kernel/mcs_spinlock.h
 +/*
 + * Cancellable version of the MCS lock above.
 + *
 + * Intended for adaptive spinning of sleeping locks:
 + * mutex_lock()/rwsem_down_{read,write}() etc.
 + */
 +
 +struct optimistic_spin_queue {
 +	struct optimistic_spin_queue *next, *prev;
 +	int locked; /* 1 if lock acquired */
 +};
 +
 +extern bool osq_lock(struct optimistic_spin_queue **lock);
 +extern void osq_unlock(struct optimistic_spin_queue **lock);
++=======
++>>>>>>> d84b6728c54d (locking/mcs: Better differentiate between MCS variants):kernel/locking/mcs_spinlock.h
  
  #endif /* __LINUX_MCS_SPINLOCK_H */
* Unmerged path include/linux/osq_lock.h
* Unmerged path kernel/locking/Makefile
* Unmerged path kernel/locking/mcs_spinlock.c
* Unmerged path kernel/mcs_spinlock.c
* Unmerged path kernel/osq_lock.c
* Unmerged path include/linux/osq_lock.h
* Unmerged path kernel/Kconfig.locks
* Unmerged path kernel/locking/Makefile
* Unmerged path kernel/locking/mcs_spinlock.c
* Unmerged path kernel/mcs_spinlock.c
* Unmerged path kernel/mcs_spinlock.h
* Unmerged path kernel/osq_lock.c
