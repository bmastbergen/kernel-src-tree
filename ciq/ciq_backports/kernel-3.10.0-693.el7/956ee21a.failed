crypto: ccp - Refactoring: symbol cleanup

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [crypto] ccp - refactoring: symbol cleanup (Suravee Suthikulpanit) [1390820]
Rebuild_FUZZ: 89.19%
commit-author Gary R Hook <gary.hook@amd.com>
commit 956ee21a6df08afd9c1c64e0f394a9a1b65e897d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/956ee21a.failed

Form and use of the local storage block in the CCP is
particular to the device version. Much of the code that
accesses the storage block can treat it as a virtual
resource, and will under go some renaming. Device-specific
access to the memory will be moved into device file.
Service functions will be added to the actions
structure.

	Signed-off-by: Gary R Hook <gary.hook@amd.com>
	Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
(cherry picked from commit 956ee21a6df08afd9c1c64e0f394a9a1b65e897d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/crypto/ccp/ccp-dev-v3.c
#	drivers/crypto/ccp/ccp-dev.h
#	drivers/crypto/ccp/ccp-ops.c
diff --cc drivers/crypto/ccp/ccp-dev.h
index 72bf1536b653,1e30568d7c04..000000000000
--- a/drivers/crypto/ccp/ccp-dev.h
+++ b/drivers/crypto/ccp/ccp-dev.h
@@@ -139,6 -144,32 +138,35 @@@
  #define CCP_ECC_RESULT_OFFSET		60
  #define CCP_ECC_RESULT_SUCCESS		0x0001
  
++<<<<<<< HEAD
++=======
+ #define CCP_SB_BYTES			32
+ 
+ struct ccp_op;
+ 
+ /* Structure for computation functions that are device-specific */
+ struct ccp_actions {
+ 	int (*aes)(struct ccp_op *);
+ 	int (*xts_aes)(struct ccp_op *);
+ 	int (*sha)(struct ccp_op *);
+ 	int (*rsa)(struct ccp_op *);
+ 	int (*passthru)(struct ccp_op *);
+ 	int (*ecc)(struct ccp_op *);
+ 	int (*init)(struct ccp_device *);
+ 	void (*destroy)(struct ccp_device *);
+ 	irqreturn_t (*irqhandler)(int, void *);
+ };
+ 
+ /* Structure to hold CCP version-specific values */
+ struct ccp_vdata {
+ 	unsigned int version;
+ 	const struct ccp_actions *perform;
+ 	const unsigned int bar;
+ 	const unsigned int offset;
+ };
+ 
+ extern struct ccp_vdata ccpv3;
++>>>>>>> 956ee21a6df0 (crypto: ccp - Refactoring: symbol cleanup)
  
  struct ccp_device;
  struct ccp_cmd;
@@@ -253,8 -324,124 +281,124 @@@ struct ccp_device 
  	/* Suspend support */
  	unsigned int suspending;
  	wait_queue_head_t suspend_queue;
 -
 -	/* DMA caching attribute support */
 -	unsigned int axcache;
  };
  
++<<<<<<< HEAD
++=======
+ enum ccp_memtype {
+ 	CCP_MEMTYPE_SYSTEM = 0,
+ 	CCP_MEMTYPE_SB,
+ 	CCP_MEMTYPE_LOCAL,
+ 	CCP_MEMTYPE__LAST,
+ };
+ 
+ struct ccp_dma_info {
+ 	dma_addr_t address;
+ 	unsigned int offset;
+ 	unsigned int length;
+ 	enum dma_data_direction dir;
+ };
+ 
+ struct ccp_dm_workarea {
+ 	struct device *dev;
+ 	struct dma_pool *dma_pool;
+ 	unsigned int length;
+ 
+ 	u8 *address;
+ 	struct ccp_dma_info dma;
+ };
+ 
+ struct ccp_sg_workarea {
+ 	struct scatterlist *sg;
+ 	int nents;
+ 
+ 	struct scatterlist *dma_sg;
+ 	struct device *dma_dev;
+ 	unsigned int dma_count;
+ 	enum dma_data_direction dma_dir;
+ 
+ 	unsigned int sg_used;
+ 
+ 	u64 bytes_left;
+ };
+ 
+ struct ccp_data {
+ 	struct ccp_sg_workarea sg_wa;
+ 	struct ccp_dm_workarea dm_wa;
+ };
+ 
+ struct ccp_mem {
+ 	enum ccp_memtype type;
+ 	union {
+ 		struct ccp_dma_info dma;
+ 		u32 sb;
+ 	} u;
+ };
+ 
+ struct ccp_aes_op {
+ 	enum ccp_aes_type type;
+ 	enum ccp_aes_mode mode;
+ 	enum ccp_aes_action action;
+ };
+ 
+ struct ccp_xts_aes_op {
+ 	enum ccp_aes_action action;
+ 	enum ccp_xts_aes_unit_size unit_size;
+ };
+ 
+ struct ccp_sha_op {
+ 	enum ccp_sha_type type;
+ 	u64 msg_bits;
+ };
+ 
+ struct ccp_rsa_op {
+ 	u32 mod_size;
+ 	u32 input_len;
+ };
+ 
+ struct ccp_passthru_op {
+ 	enum ccp_passthru_bitwise bit_mod;
+ 	enum ccp_passthru_byteswap byte_swap;
+ };
+ 
+ struct ccp_ecc_op {
+ 	enum ccp_ecc_function function;
+ };
+ 
+ struct ccp_op {
+ 	struct ccp_cmd_queue *cmd_q;
+ 
+ 	u32 jobid;
+ 	u32 ioc;
+ 	u32 soc;
+ 	u32 sb_key;
+ 	u32 sb_ctx;
+ 	u32 init;
+ 	u32 eom;
+ 
+ 	struct ccp_mem src;
+ 	struct ccp_mem dst;
+ 
+ 	union {
+ 		struct ccp_aes_op aes;
+ 		struct ccp_xts_aes_op xts;
+ 		struct ccp_sha_op sha;
+ 		struct ccp_rsa_op rsa;
+ 		struct ccp_passthru_op passthru;
+ 		struct ccp_ecc_op ecc;
+ 	} u;
+ };
+ 
+ static inline u32 ccp_addr_lo(struct ccp_dma_info *info)
+ {
+ 	return lower_32_bits(info->address + info->offset);
+ }
+ 
+ static inline u32 ccp_addr_hi(struct ccp_dma_info *info)
+ {
+ 	return upper_32_bits(info->address + info->offset) & 0x0000ffff;
+ }
++>>>>>>> 956ee21a6df0 (crypto: ccp - Refactoring: symbol cleanup)
  
  int ccp_pci_init(void);
  void ccp_pci_exit(void);
diff --cc drivers/crypto/ccp/ccp-ops.c
index 23dbb41465d1,2c2890a4c2e2..000000000000
--- a/drivers/crypto/ccp/ccp-ops.c
+++ b/drivers/crypto/ccp/ccp-ops.c
@@@ -591,15 -227,16 +591,15 @@@ static void ccp_get_dm_area(struct ccp_
  				 1);
  }
  
 -static int ccp_reverse_set_dm_area(struct ccp_dm_workarea *wa,
 -				   struct scatterlist *sg,
 -				   unsigned int len, unsigned int se_len,
 -				   bool sign_extend)
 +static void ccp_reverse_set_dm_area(struct ccp_dm_workarea *wa,
 +				    struct scatterlist *sg,
 +				    unsigned int len, unsigned int se_len,
 +				    bool sign_extend)
  {
- 	unsigned int nbytes, sg_offset, dm_offset, ksb_len, i;
+ 	unsigned int nbytes, sg_offset, dm_offset, sb_len, i;
  	u8 buffer[CCP_REVERSE_BUF_SIZE];
  
 -	if (WARN_ON(se_len > sizeof(buffer)))
 -		return -EINVAL;
 +	BUG_ON(se_len > sizeof(buffer));
  
  	sg_offset = len;
  	dm_offset = 0;
@@@ -619,9 -256,11 +619,9 @@@
  			/* Must sign-extend to nearest sign-extend length */
  			if (wa->address[dm_offset - 1] & 0x80)
  				memset(wa->address + dm_offset, 0xff,
- 				       se_len - ksb_len);
+ 				       se_len - sb_len);
  		}
  	}
 -
 -	return 0;
  }
  
  static void ccp_reverse_get_dm_area(struct ccp_dm_workarea *wa,
@@@ -835,21 -479,21 +835,21 @@@ static int ccp_copy_to_from_sb(struct c
  
  	op.u.passthru.byte_swap = byte_swap;
  
 -	return cmd_q->ccp->vdata->perform->passthru(&op);
 +	return ccp_perform_passthru(&op);
  }
  
- static int ccp_copy_to_ksb(struct ccp_cmd_queue *cmd_q,
- 			   struct ccp_dm_workarea *wa, u32 jobid, u32 ksb,
- 			   u32 byte_swap)
+ static int ccp_copy_to_sb(struct ccp_cmd_queue *cmd_q,
+ 			  struct ccp_dm_workarea *wa, u32 jobid, u32 sb,
+ 			  u32 byte_swap)
  {
- 	return ccp_copy_to_from_ksb(cmd_q, wa, jobid, ksb, byte_swap, false);
+ 	return ccp_copy_to_from_sb(cmd_q, wa, jobid, sb, byte_swap, false);
  }
  
- static int ccp_copy_from_ksb(struct ccp_cmd_queue *cmd_q,
- 			     struct ccp_dm_workarea *wa, u32 jobid, u32 ksb,
- 			     u32 byte_swap)
+ static int ccp_copy_from_sb(struct ccp_cmd_queue *cmd_q,
+ 			    struct ccp_dm_workarea *wa, u32 jobid, u32 sb,
+ 			    u32 byte_swap)
  {
- 	return ccp_copy_to_from_ksb(cmd_q, wa, jobid, ksb, byte_swap, true);
+ 	return ccp_copy_to_from_sb(cmd_q, wa, jobid, sb, byte_swap, true);
  }
  
  static int ccp_run_aes_cmac_cmd(struct ccp_cmd_queue *cmd_q,
@@@ -1408,9 -1055,30 +1408,36 @@@ static int ccp_run_sha_cmd(struct ccp_c
  	if (ret)
  		return ret;
  
++<<<<<<< HEAD
 +	ccp_set_dm_area(&ctx, 0, sha->ctx, 0, sha->ctx_len);
 +	ret = ccp_copy_to_ksb(cmd_q, &ctx, op.jobid, op.ksb_ctx,
 +			      CCP_PASSTHRU_BYTESWAP_256BIT);
++=======
+ 	if (sha->first) {
+ 		const __be32 *init;
+ 
+ 		switch (sha->type) {
+ 		case CCP_SHA_TYPE_1:
+ 			init = ccp_sha1_init;
+ 			break;
+ 		case CCP_SHA_TYPE_224:
+ 			init = ccp_sha224_init;
+ 			break;
+ 		case CCP_SHA_TYPE_256:
+ 			init = ccp_sha256_init;
+ 			break;
+ 		default:
+ 			ret = -EINVAL;
+ 			goto e_ctx;
+ 		}
+ 		memcpy(ctx.address, init, CCP_SHA_CTXSIZE);
+ 	} else {
+ 		ccp_set_dm_area(&ctx, 0, sha->ctx, 0, sha->ctx_len);
+ 	}
+ 
+ 	ret = ccp_copy_to_sb(cmd_q, &ctx, op.jobid, op.sb_ctx,
+ 			     CCP_PASSTHRU_BYTESWAP_256BIT);
++>>>>>>> 956ee21a6df0 (crypto: ccp - Refactoring: symbol cleanup)
  	if (ret) {
  		cmd->engine_error = cmd_q->cmd_error;
  		goto e_ctx;
@@@ -1498,12 -1226,14 +1525,21 @@@ static int ccp_run_rsa_cmd(struct ccp_c
  	 */
  	ret = ccp_init_dm_workarea(&exp, cmd_q, o_len, DMA_TO_DEVICE);
  	if (ret)
- 		goto e_ksb;
+ 		goto e_sb;
  
++<<<<<<< HEAD
 +	ccp_reverse_set_dm_area(&exp, rsa->exp, rsa->exp_len, CCP_KSB_BYTES,
 +				false);
 +	ret = ccp_copy_to_ksb(cmd_q, &exp, op.jobid, op.ksb_key,
 +			      CCP_PASSTHRU_BYTESWAP_NOOP);
++=======
+ 	ret = ccp_reverse_set_dm_area(&exp, rsa->exp, rsa->exp_len,
+ 				      CCP_SB_BYTES, false);
+ 	if (ret)
+ 		goto e_exp;
+ 	ret = ccp_copy_to_sb(cmd_q, &exp, op.jobid, op.sb_key,
+ 			     CCP_PASSTHRU_BYTESWAP_NOOP);
++>>>>>>> 956ee21a6df0 (crypto: ccp - Refactoring: symbol cleanup)
  	if (ret) {
  		cmd->engine_error = cmd_q->cmd_error;
  		goto e_exp;
@@@ -1517,11 -1247,15 +1553,23 @@@
  	if (ret)
  		goto e_exp;
  
++<<<<<<< HEAD
 +	ccp_reverse_set_dm_area(&src, rsa->mod, rsa->mod_len, CCP_KSB_BYTES,
 +				false);
 +	src.address += o_len;	/* Adjust the address for the copy operation */
 +	ccp_reverse_set_dm_area(&src, rsa->src, rsa->src_len, CCP_KSB_BYTES,
 +				false);
++=======
+ 	ret = ccp_reverse_set_dm_area(&src, rsa->mod, rsa->mod_len,
+ 				      CCP_SB_BYTES, false);
+ 	if (ret)
+ 		goto e_src;
+ 	src.address += o_len;	/* Adjust the address for the copy operation */
+ 	ret = ccp_reverse_set_dm_area(&src, rsa->src, rsa->src_len,
+ 				      CCP_SB_BYTES, false);
+ 	if (ret)
+ 		goto e_src;
++>>>>>>> 956ee21a6df0 (crypto: ccp - Refactoring: symbol cleanup)
  	src.address -= o_len;	/* Reset the address to original value */
  
  	/* Prepare the output area for the operation */
@@@ -1694,6 -1428,70 +1742,73 @@@ e_mask
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ static int ccp_run_passthru_nomap_cmd(struct ccp_cmd_queue *cmd_q,
+ 				      struct ccp_cmd *cmd)
+ {
+ 	struct ccp_passthru_nomap_engine *pt = &cmd->u.passthru_nomap;
+ 	struct ccp_dm_workarea mask;
+ 	struct ccp_op op;
+ 	int ret;
+ 
+ 	if (!pt->final && (pt->src_len & (CCP_PASSTHRU_BLOCKSIZE - 1)))
+ 		return -EINVAL;
+ 
+ 	if (!pt->src_dma || !pt->dst_dma)
+ 		return -EINVAL;
+ 
+ 	if (pt->bit_mod != CCP_PASSTHRU_BITWISE_NOOP) {
+ 		if (pt->mask_len != CCP_PASSTHRU_MASKSIZE)
+ 			return -EINVAL;
+ 		if (!pt->mask)
+ 			return -EINVAL;
+ 	}
+ 
+ 	BUILD_BUG_ON(CCP_PASSTHRU_SB_COUNT != 1);
+ 
+ 	memset(&op, 0, sizeof(op));
+ 	op.cmd_q = cmd_q;
+ 	op.jobid = ccp_gen_jobid(cmd_q->ccp);
+ 
+ 	if (pt->bit_mod != CCP_PASSTHRU_BITWISE_NOOP) {
+ 		/* Load the mask */
+ 		op.sb_key = cmd_q->sb_key;
+ 
+ 		mask.length = pt->mask_len;
+ 		mask.dma.address = pt->mask;
+ 		mask.dma.length = pt->mask_len;
+ 
+ 		ret = ccp_copy_to_sb(cmd_q, &mask, op.jobid, op.sb_key,
+ 				     CCP_PASSTHRU_BYTESWAP_NOOP);
+ 		if (ret) {
+ 			cmd->engine_error = cmd_q->cmd_error;
+ 			return ret;
+ 		}
+ 	}
+ 
+ 	/* Send data to the CCP Passthru engine */
+ 	op.eom = 1;
+ 	op.soc = 1;
+ 
+ 	op.src.type = CCP_MEMTYPE_SYSTEM;
+ 	op.src.u.dma.address = pt->src_dma;
+ 	op.src.u.dma.offset = 0;
+ 	op.src.u.dma.length = pt->src_len;
+ 
+ 	op.dst.type = CCP_MEMTYPE_SYSTEM;
+ 	op.dst.u.dma.address = pt->dst_dma;
+ 	op.dst.u.dma.offset = 0;
+ 	op.dst.u.dma.length = pt->src_len;
+ 
+ 	ret = cmd_q->ccp->vdata->perform->passthru(&op);
+ 	if (ret)
+ 		cmd->engine_error = cmd_q->cmd_error;
+ 
+ 	return ret;
+ }
+ 
++>>>>>>> 956ee21a6df0 (crypto: ccp - Refactoring: symbol cleanup)
  static int ccp_run_ecc_mm_cmd(struct ccp_cmd_queue *cmd_q, struct ccp_cmd *cmd)
  {
  	struct ccp_ecc_engine *ecc = &cmd->u.ecc;
* Unmerged path drivers/crypto/ccp/ccp-dev-v3.c
* Unmerged path drivers/crypto/ccp/ccp-dev-v3.c
diff --git a/drivers/crypto/ccp/ccp-dev.c b/drivers/crypto/ccp/ccp-dev.c
index 2777dc97b570..7ff24fdcc79c 100644
--- a/drivers/crypto/ccp/ccp-dev.c
+++ b/drivers/crypto/ccp/ccp-dev.c
@@ -4,6 +4,7 @@
  * Copyright (C) 2013 Advanced Micro Devices, Inc.
  *
  * Author: Tom Lendacky <thomas.lendacky@amd.com>
+ * Author: Gary R Hook <gary.hook@amd.com>
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
@@ -292,9 +293,9 @@ struct ccp_device *ccp_alloc_struct(struct device *dev)
 
 	spin_lock_init(&ccp->cmd_lock);
 	mutex_init(&ccp->req_mutex);
-	mutex_init(&ccp->ksb_mutex);
-	ccp->ksb_count = KSB_COUNT;
-	ccp->ksb_start = 0;
+	mutex_init(&ccp->sb_mutex);
+	ccp->sb_count = KSB_COUNT;
+	ccp->sb_start = 0;
 
 	return ccp;
 }
* Unmerged path drivers/crypto/ccp/ccp-dev.h
* Unmerged path drivers/crypto/ccp/ccp-ops.c
