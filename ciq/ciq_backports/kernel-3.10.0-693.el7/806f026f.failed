nvme: use blk_mq_start_hw_queues() in nvme_kill_queues()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
Rebuild_CHGLOG: - [nvme] use blk_mq_start_hw_queues() in nvme_kill_queues() (Ming Lei) [1445595]
Rebuild_FUZZ: 94.34%
commit-author Ming Lei <ming.lei@redhat.com>
commit 806f026f9b901eaf1a6baeb48b5da18d6a4f818e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/806f026f.failed

Inside nvme_kill_queues(), we have to start hw queues for
draining requests in sw queues, .dispatch list and requeue list,
so use blk_mq_start_hw_queues() instead of blk_mq_start_stopped_hw_queues()
which only run queues if queues are stopped, but the queues may have
been started already, for example nvme_start_queues() is called in reset work
function.

blk_mq_start_hw_queues() run hw queues in current context, instead
of running asynchronously like before. Given nvme_kill_queues() is
run from either remove context or reset worker context, both are fine
to run hw queue directly. And the mutex of namespaces_mutex isn't a
problem too becasue nvme_start_freeze() runs hw queue in this way
already.

	Cc: stable@vger.kernel.org
	Reported-by: Zhang Yi <yizhan@redhat.com>
	Reviewed-by: Keith Busch <keith.busch@intel.com>
	Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
	Signed-off-by: Ming Lei <ming.lei@redhat.com>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
(cherry picked from commit 806f026f9b901eaf1a6baeb48b5da18d6a4f818e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/core.c
diff --cc drivers/nvme/host/core.c
index 0588703d149f,40d5e4a9e8d7..000000000000
--- a/drivers/nvme/host/core.c
+++ b/drivers/nvme/host/core.c
@@@ -1517,19 -2432,24 +1517,29 @@@ void nvme_kill_queues(struct nvme_ctrl 
  		 * Revalidating a dead namespace sets capacity to 0. This will
  		 * end buffered writers dirtying pages that can't be synced.
  		 */
 -		if (!ns->disk || test_and_set_bit(NVME_NS_DEAD, &ns->flags))
 -			continue;
 -		revalidate_disk(ns->disk);
 +		if (!test_and_set_bit(NVME_NS_DEAD, &ns->flags))
 +			revalidate_disk(ns->disk);
 +
  		blk_set_queue_dying(ns->queue);
  		blk_mq_abort_requeue_list(ns->queue);
++<<<<<<< HEAD
 +		blk_mq_start_stopped_hw_queues(ns->queue, true);
 +
 +		nvme_put_ns(ns);
++=======
+ 
+ 		/*
+ 		 * Forcibly start all queues to avoid having stuck requests.
+ 		 * Note that we must ensure the queues are not stopped
+ 		 * when the final removal happens.
+ 		 */
+ 		blk_mq_start_hw_queues(ns->queue);
++>>>>>>> 806f026f9b90 (nvme: use blk_mq_start_hw_queues() in nvme_kill_queues())
  	}
 -	mutex_unlock(&ctrl->namespaces_mutex);
 +	rcu_read_unlock();
  }
 -EXPORT_SYMBOL_GPL(nvme_kill_queues);
  
 -void nvme_unfreeze(struct nvme_ctrl *ctrl)
 +void nvme_stop_queues(struct nvme_ctrl *ctrl)
  {
  	struct nvme_ns *ns;
  
* Unmerged path drivers/nvme/host/core.c
