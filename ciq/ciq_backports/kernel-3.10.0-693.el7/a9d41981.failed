amd-xgbe: Rename pre_xmit function to dev_xmit

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-693.el7
commit-author Lendacky, Thomas <Thomas.Lendacky@amd.com>
commit a9d41981e95651143125352f0233138efc17378a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-693.el7/a9d41981.failed

The pre_xmit function name implies that it performs operations prior
to transmitting the packet when in fact it is responsible for setting
up the descriptors and initiating the transmit.  Rename this to
function from pre_xmit to dev_xmit, which is consistent with the name
used during receive processing - dev_read.

	Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit a9d41981e95651143125352f0233138efc17378a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/amd/xgbe/xgbe-dev.c
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-dev.c
index 2da3691ffcd6,7b97d3852091..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-dev.c
@@@ -896,7 -1024,181 +896,185 @@@ static void xgbe_rx_desc_init(struct xg
  	DBGPR("<--rx_desc_init\n");
  }
  
++<<<<<<< HEAD
 +static void xgbe_pre_xmit(struct xgbe_channel *channel)
++=======
+ static void xgbe_update_tstamp_addend(struct xgbe_prv_data *pdata,
+ 				      unsigned int addend)
+ {
+ 	/* Set the addend register value and tell the device */
+ 	XGMAC_IOWRITE(pdata, MAC_TSAR, addend);
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_TSCR, TSADDREG, 1);
+ 
+ 	/* Wait for addend update to complete */
+ 	while (XGMAC_IOREAD_BITS(pdata, MAC_TSCR, TSADDREG))
+ 		udelay(5);
+ }
+ 
+ static void xgbe_set_tstamp_time(struct xgbe_prv_data *pdata, unsigned int sec,
+ 				 unsigned int nsec)
+ {
+ 	/* Set the time values and tell the device */
+ 	XGMAC_IOWRITE(pdata, MAC_STSUR, sec);
+ 	XGMAC_IOWRITE(pdata, MAC_STNUR, nsec);
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_TSCR, TSINIT, 1);
+ 
+ 	/* Wait for time update to complete */
+ 	while (XGMAC_IOREAD_BITS(pdata, MAC_TSCR, TSINIT))
+ 		udelay(5);
+ }
+ 
+ static u64 xgbe_get_tstamp_time(struct xgbe_prv_data *pdata)
+ {
+ 	u64 nsec;
+ 
+ 	nsec = XGMAC_IOREAD(pdata, MAC_STSR);
+ 	nsec *= NSEC_PER_SEC;
+ 	nsec += XGMAC_IOREAD(pdata, MAC_STNR);
+ 
+ 	return nsec;
+ }
+ 
+ static u64 xgbe_get_tx_tstamp(struct xgbe_prv_data *pdata)
+ {
+ 	unsigned int tx_snr;
+ 	u64 nsec;
+ 
+ 	tx_snr = XGMAC_IOREAD(pdata, MAC_TXSNR);
+ 	if (XGMAC_GET_BITS(tx_snr, MAC_TXSNR, TXTSSTSMIS))
+ 		return 0;
+ 
+ 	nsec = XGMAC_IOREAD(pdata, MAC_TXSSR);
+ 	nsec *= NSEC_PER_SEC;
+ 	nsec += tx_snr;
+ 
+ 	return nsec;
+ }
+ 
+ static void xgbe_get_rx_tstamp(struct xgbe_packet_data *packet,
+ 			       struct xgbe_ring_desc *rdesc)
+ {
+ 	u64 nsec;
+ 
+ 	if (XGMAC_GET_BITS_LE(rdesc->desc3, RX_CONTEXT_DESC3, TSA) &&
+ 	    !XGMAC_GET_BITS_LE(rdesc->desc3, RX_CONTEXT_DESC3, TSD)) {
+ 		nsec = le32_to_cpu(rdesc->desc1);
+ 		nsec <<= 32;
+ 		nsec |= le32_to_cpu(rdesc->desc0);
+ 		if (nsec != 0xffffffffffffffffULL) {
+ 			packet->rx_tstamp = nsec;
+ 			XGMAC_SET_BITS(packet->attributes, RX_PACKET_ATTRIBUTES,
+ 				       RX_TSTAMP, 1);
+ 		}
+ 	}
+ }
+ 
+ static int xgbe_config_tstamp(struct xgbe_prv_data *pdata,
+ 			      unsigned int mac_tscr)
+ {
+ 	/* Set one nano-second accuracy */
+ 	XGMAC_SET_BITS(mac_tscr, MAC_TSCR, TSCTRLSSR, 1);
+ 
+ 	/* Set fine timestamp update */
+ 	XGMAC_SET_BITS(mac_tscr, MAC_TSCR, TSCFUPDT, 1);
+ 
+ 	/* Overwrite earlier timestamps */
+ 	XGMAC_SET_BITS(mac_tscr, MAC_TSCR, TXTSSTSM, 1);
+ 
+ 	XGMAC_IOWRITE(pdata, MAC_TSCR, mac_tscr);
+ 
+ 	/* Exit if timestamping is not enabled */
+ 	if (!XGMAC_GET_BITS(mac_tscr, MAC_TSCR, TSENA))
+ 		return 0;
+ 
+ 	/* Initialize time registers */
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_SSIR, SSINC, XGBE_TSTAMP_SSINC);
+ 	XGMAC_IOWRITE_BITS(pdata, MAC_SSIR, SNSINC, XGBE_TSTAMP_SNSINC);
+ 	xgbe_update_tstamp_addend(pdata, pdata->tstamp_addend);
+ 	xgbe_set_tstamp_time(pdata, 0, 0);
+ 
+ 	/* Initialize the timecounter */
+ 	timecounter_init(&pdata->tstamp_tc, &pdata->tstamp_cc,
+ 			 ktime_to_ns(ktime_get_real()));
+ 
+ 	return 0;
+ }
+ 
+ static void xgbe_config_dcb_tc(struct xgbe_prv_data *pdata)
+ {
+ 	struct ieee_ets *ets = pdata->ets;
+ 	unsigned int total_weight, min_weight, weight;
+ 	unsigned int i;
+ 
+ 	if (!ets)
+ 		return;
+ 
+ 	/* Set Tx to deficit weighted round robin scheduling algorithm (when
+ 	 * traffic class is using ETS algorithm)
+ 	 */
+ 	XGMAC_IOWRITE_BITS(pdata, MTL_OMR, ETSALG, MTL_ETSALG_DWRR);
+ 
+ 	/* Set Traffic Class algorithms */
+ 	total_weight = pdata->netdev->mtu * pdata->hw_feat.tc_cnt;
+ 	min_weight = total_weight / 100;
+ 	if (!min_weight)
+ 		min_weight = 1;
+ 
+ 	for (i = 0; i < pdata->hw_feat.tc_cnt; i++) {
+ 		switch (ets->tc_tsa[i]) {
+ 		case IEEE_8021QAZ_TSA_STRICT:
+ 			DBGPR("  TC%u using SP\n", i);
+ 			XGMAC_MTL_IOWRITE_BITS(pdata, i, MTL_TC_ETSCR, TSA,
+ 					       MTL_TSA_SP);
+ 			break;
+ 		case IEEE_8021QAZ_TSA_ETS:
+ 			weight = total_weight * ets->tc_tx_bw[i] / 100;
+ 			weight = clamp(weight, min_weight, total_weight);
+ 
+ 			DBGPR("  TC%u using DWRR (weight %u)\n", i, weight);
+ 			XGMAC_MTL_IOWRITE_BITS(pdata, i, MTL_TC_ETSCR, TSA,
+ 					       MTL_TSA_ETS);
+ 			XGMAC_MTL_IOWRITE_BITS(pdata, i, MTL_TC_QWR, QW,
+ 					       weight);
+ 			break;
+ 		}
+ 	}
+ }
+ 
+ static void xgbe_config_dcb_pfc(struct xgbe_prv_data *pdata)
+ {
+ 	struct ieee_pfc *pfc = pdata->pfc;
+ 	struct ieee_ets *ets = pdata->ets;
+ 	unsigned int mask, reg, reg_val;
+ 	unsigned int tc, prio;
+ 
+ 	if (!pfc || !ets)
+ 		return;
+ 
+ 	for (tc = 0; tc < pdata->hw_feat.tc_cnt; tc++) {
+ 		mask = 0;
+ 		for (prio = 0; prio < IEEE_8021QAZ_MAX_TCS; prio++) {
+ 			if ((pfc->pfc_en & (1 << prio)) &&
+ 			    (ets->prio_tc[prio] == tc))
+ 				mask |= (1 << prio);
+ 		}
+ 		mask &= 0xff;
+ 
+ 		DBGPR("  TC%u PFC mask=%#x\n", tc, mask);
+ 		reg = MTL_TCPM0R + (MTL_TCPM_INC * (tc / MTL_TCPM_TC_PER_REG));
+ 		reg_val = XGMAC_IOREAD(pdata, reg);
+ 
+ 		reg_val &= ~(0xff << ((tc % MTL_TCPM_TC_PER_REG) << 3));
+ 		reg_val |= (mask << ((tc % MTL_TCPM_TC_PER_REG) << 3));
+ 
+ 		XGMAC_IOWRITE(pdata, reg, reg_val);
+ 	}
+ 
+ 	xgbe_config_flow_control(pdata);
+ }
+ 
+ static void xgbe_dev_xmit(struct xgbe_channel *channel)
++>>>>>>> a9d41981e956 (amd-xgbe: Rename pre_xmit function to dev_xmit)
  {
  	struct xgbe_prv_data *pdata = channel->pdata;
  	struct xgbe_ring *ring = channel->tx_ring;
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-dev.c
diff --git a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
index 6baf601c4282..a96140111078 100644
--- a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
@@ -899,7 +899,7 @@ static int xgbe_xmit(struct sk_buff *skb, struct net_device *netdev)
 	}
 
 	/* Configure required descriptor fields for transmission */
-	hw_if->pre_xmit(channel);
+	hw_if->dev_xmit(channel);
 
 #ifdef XGMAC_ENABLE_TX_PKT_DUMP
 	xgbe_print_pkt(netdev, skb, true);
diff --git a/drivers/net/ethernet/amd/xgbe/xgbe.h b/drivers/net/ethernet/amd/xgbe/xgbe.h
index 03f298feb832..ca49a8230cbe 100644
--- a/drivers/net/ethernet/amd/xgbe/xgbe.h
+++ b/drivers/net/ethernet/amd/xgbe/xgbe.h
@@ -420,7 +420,7 @@ struct xgbe_hw_if {
 
 	int (*enable_int)(struct xgbe_channel *, enum xgbe_int);
 	int (*disable_int)(struct xgbe_channel *, enum xgbe_int);
-	void (*pre_xmit)(struct xgbe_channel *);
+	void (*dev_xmit)(struct xgbe_channel *);
 	int (*dev_read)(struct xgbe_channel *);
 	void (*tx_desc_init)(struct xgbe_channel *);
 	void (*rx_desc_init)(struct xgbe_channel *);
