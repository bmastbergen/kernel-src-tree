futex: Handle faults correctly for PI futexes

jira LE-1907
cve CVE-2021-3347
Rebuild_History Non-Buildable kernel-3.10.0-1160.31.1.el7
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 34b1a1ce1458f50ef27c54e28eb9b1947012907a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.31.1.el7/34b1a1ce.failed

fixup_pi_state_owner() tries to ensure that the state of the rtmutex,
pi_state and the user space value related to the PI futex are consistent
before returning to user space. In case that the user space value update
faults and the fault cannot be resolved by faulting the page in via
fault_in_user_writeable() the function returns with -EFAULT and leaves
the rtmutex and pi_state owner state inconsistent.

A subsequent futex_unlock_pi() operates on the inconsistent pi_state and
releases the rtmutex despite not owning it which can corrupt the RB tree of
the rtmutex and cause a subsequent kernel stack use after free.

It was suggested to loop forever in fixup_pi_state_owner() if the fault
cannot be resolved, but that results in runaway tasks which is especially
undesired when the problem happens due to a programming error and not due
to malice.

As the user space value cannot be fixed up, the proper solution is to make
the rtmutex and the pi_state consistent so both have the same owner. This
leaves the user space value out of sync. Any subsequent operation on the
futex will fail because the 10th rule of PI futexes (pi_state owner and
user space value are consistent) has been violated.

As a consequence this removes the inept attempts of 'fixing' the situation
in case that the current task owns the rtmutex when returning with an
unresolvable fault by unlocking the rtmutex which left pi_state::owner and
rtmutex::owner out of sync in a different and only slightly less dangerous
way.

Fixes: 1b7558e457ed ("futexes: fix fault handling in futex_lock_pi")
	Reported-by: gzobqq@gmail.com
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: stable@vger.kernel.org
(cherry picked from commit 34b1a1ce1458f50ef27c54e28eb9b1947012907a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/futex.c
diff --cc kernel/futex.c
index 877831775d7a,45a13eb8894e..000000000000
--- a/kernel/futex.c
+++ b/kernel/futex.c
@@@ -791,129 -958,133 +791,167 @@@ void exit_pi_state_list(struct task_str
   *	FUTEX_OWNER_DIED bit. See [4]
   *
   * [10] There is no transient state which leaves owner and user space
++<<<<<<< HEAD
 + *	TID out of sync.
++=======
+  *	TID out of sync. Except one error case where the kernel is denied
+  *	write access to the user address, see fixup_pi_state_owner().
+  *
+  *
+  * Serialization and lifetime rules:
+  *
+  * hb->lock:
+  *
+  *	hb -> futex_q, relation
+  *	futex_q -> pi_state, relation
+  *
+  *	(cannot be raw because hb can contain arbitrary amount
+  *	 of futex_q's)
+  *
+  * pi_mutex->wait_lock:
+  *
+  *	{uval, pi_state}
+  *
+  *	(and pi_mutex 'obviously')
+  *
+  * p->pi_lock:
+  *
+  *	p->pi_state_list -> pi_state->list, relation
+  *
+  * pi_state->refcount:
+  *
+  *	pi_state lifetime
+  *
+  *
+  * Lock order:
+  *
+  *   hb->lock
+  *     pi_mutex->wait_lock
+  *       p->pi_lock
+  *
++>>>>>>> 34b1a1ce1458 (futex: Handle faults correctly for PI futexes)
   */
 -
 -/*
 - * Validate that the existing waiter has a pi_state and sanity check
 - * the pi_state against the user space value. If correct, attach to
 - * it.
 - */
 -static int attach_to_pi_state(u32 __user *uaddr, u32 uval,
 -			      struct futex_pi_state *pi_state,
 -			      struct futex_pi_state **ps)
 +static int
 +lookup_pi_state(u32 uval, struct futex_hash_bucket *hb,
 +		union futex_key *key, struct futex_pi_state **ps,
 +		struct task_struct *task)
  {
 +	struct futex_pi_state *pi_state = NULL;
 +	struct futex_q *this, *next;
 +	struct task_struct *p;
  	pid_t pid = uval & FUTEX_TID_MASK;
 -	u32 uval2;
 -	int ret;
  
 -	/*
 -	 * Userspace might have messed up non-PI and PI futexes [3]
 -	 */
 -	if (unlikely(!pi_state))
 -		return -EINVAL;
 +	plist_for_each_entry_safe(this, next, &hb->chain, list) {
 +		if (match_futex(&this->key, key)) {
 +			/*
 +			 * Sanity check the waiter before increasing
 +			 * the refcount and attaching to it.
 +			 */
 +			pi_state = this->pi_state;
 +			/*
 +			 * Userspace might have messed up non-PI and
 +			 * PI futexes [3]
 +			 */
 +			if (unlikely(!pi_state))
 +				return -EINVAL;
  
 -	/*
 -	 * We get here with hb->lock held, and having found a
 -	 * futex_top_waiter(). This means that futex_lock_pi() of said futex_q
 -	 * has dropped the hb->lock in between queue_me() and unqueue_me_pi(),
 -	 * which in turn means that futex_lock_pi() still has a reference on
 -	 * our pi_state.
 -	 *
 -	 * The waiter holding a reference on @pi_state also protects against
 -	 * the unlocked put_pi_state() in futex_unlock_pi(), futex_lock_pi()
 -	 * and futex_wait_requeue_pi() as it cannot go to 0 and consequently
 -	 * free pi_state before we can take a reference ourselves.
 -	 */
 -	WARN_ON(!refcount_read(&pi_state->refcount));
 +			WARN_ON(!atomic_read(&pi_state->refcount));
  
 -	/*
 -	 * Now that we have a pi_state, we can acquire wait_lock
 -	 * and do the state validation.
 -	 */
 -	raw_spin_lock_irq(&pi_state->pi_mutex.wait_lock);
 +			/*
 +			 * Handle the owner died case:
 +			 */
 +			if (uval & FUTEX_OWNER_DIED) {
 +				/*
 +				 * exit_pi_state_list sets owner to NULL and
 +				 * wakes the topmost waiter. The task which
 +				 * acquires the pi_state->rt_mutex will fixup
 +				 * owner.
 +				 */
 +				if (!pi_state->owner) {
 +					/*
 +					 * No pi state owner, but the user
 +					 * space TID is not 0. Inconsistent
 +					 * state. [5]
 +					 */
 +					if (pid)
 +						return -EINVAL;
 +					/*
 +					 * Take a ref on the state and
 +					 * return. [4]
 +					 */
 +					goto out_state;
 +				}
 +
 +				/*
 +				 * If TID is 0, then either the dying owner
 +				 * has not yet executed exit_pi_state_list()
 +				 * or some waiter acquired the rtmutex in the
 +				 * pi state, but did not yet fixup the TID in
 +				 * user space.
 +				 *
 +				 * Take a ref on the state and return. [6]
 +				 */
 +				if (!pid)
 +					goto out_state;
 +			} else {
 +				/*
 +				 * If the owner died bit is not set,
 +				 * then the pi_state must have an
 +				 * owner. [7]
 +				 */
 +				if (!pi_state->owner)
 +					return -EINVAL;
 +			}
 +
 +			/*
 +			 * Bail out if user space manipulated the
 +			 * futex value. If pi state exists then the
 +			 * owner TID must be the same as the user
 +			 * space TID. [9/10]
 +			 */
 +			if (pid != task_pid_vnr(pi_state->owner))
 +				return -EINVAL;
 +
 +		out_state:
 +			atomic_inc(&pi_state->refcount);
 +			*ps = pi_state;
 +			return 0;
 +		}
 +	}
  
  	/*
 -	 * Since {uval, pi_state} is serialized by wait_lock, and our current
 -	 * uval was read without holding it, it can have changed. Verify it
 -	 * still is what we expect it to be, otherwise retry the entire
 -	 * operation.
 +	 * We are the first waiter - try to look up the real owner and attach
 +	 * the new pi_state to it, but bail out when TID = 0 [1]
  	 */
 -	if (get_futex_value_locked(&uval2, uaddr))
 -		goto out_efault;
 +	if (!pid)
 +		return -ESRCH;
 +	p = futex_find_get_task(pid);
 +	if (!p)
 +		return -ESRCH;
  
 -	if (uval != uval2)
 -		goto out_eagain;
 +	if (!p->mm) {
 +		put_task_struct(p);
 +		return -EPERM;
 +	}
  
  	/*
 -	 * Handle the owner died case:
 +	 * We need to look at the task state flags to figure out,
 +	 * whether the task is exiting. To protect against the do_exit
 +	 * change of the task flags, we do this protected by
 +	 * p->pi_lock:
  	 */
 -	if (uval & FUTEX_OWNER_DIED) {
 +	raw_spin_lock_irq(&p->pi_lock);
 +	if (unlikely(p->flags & PF_EXITING)) {
  		/*
 -		 * exit_pi_state_list sets owner to NULL and wakes the
 -		 * topmost waiter. The task which acquires the
 -		 * pi_state->rt_mutex will fixup owner.
 +		 * The task is on the way out. When PF_EXITPIDONE is
 +		 * set, we know that the task has finished the
 +		 * cleanup:
  		 */
 -		if (!pi_state->owner) {
 -			/*
 -			 * No pi state owner, but the user space TID
 -			 * is not 0. Inconsistent state. [5]
 -			 */
 -			if (pid)
 -				goto out_einval;
 -			/*
 -			 * Take a ref on the state and return success. [4]
 -			 */
 -			goto out_attach;
 -		}
 +		int ret = (p->flags & PF_EXITPIDONE) ? -ESRCH : -EAGAIN;
  
 -		/*
 -		 * If TID is 0, then either the dying owner has not
 -		 * yet executed exit_pi_state_list() or some waiter
 -		 * acquired the rtmutex in the pi state, but did not
 -		 * yet fixup the TID in user space.
 -		 *
 -		 * Take a ref on the state and return success. [6]
 -		 */
 -		if (!pid)
 -			goto out_attach;
 -	} else {
 -		/*
 -		 * If the owner died bit is not set, then the pi_state
 -		 * must have an owner. [7]
 -		 */
 -		if (!pi_state->owner)
 -			goto out_einval;
 +		raw_spin_unlock_irq(&p->pi_lock);
 +		put_task_struct(p);
 +		return ret;
  	}
  
  	/*
@@@ -1989,12 -2475,45 +2027,48 @@@ handle_fault
  	 * Check if someone else fixed it for us:
  	 */
  	if (pi_state->owner != oldowner)
 -		return argowner == current;
 +		return 0;
  
 -	/* Retry if err was -EAGAIN or the fault in succeeded */
 -	if (!err)
 -		goto retry;
 +	if (ret)
 +		return ret;
  
++<<<<<<< HEAD
 +	goto retry;
++=======
+ 	/*
+ 	 * fault_in_user_writeable() failed so user state is immutable. At
+ 	 * best we can make the kernel state consistent but user state will
+ 	 * be most likely hosed and any subsequent unlock operation will be
+ 	 * rejected due to PI futex rule [10].
+ 	 *
+ 	 * Ensure that the rtmutex owner is also the pi_state owner despite
+ 	 * the user space value claiming something different. There is no
+ 	 * point in unlocking the rtmutex if current is the owner as it
+ 	 * would need to wait until the next waiter has taken the rtmutex
+ 	 * to guarantee consistent state. Keep it simple. Userspace asked
+ 	 * for this wreckaged state.
+ 	 *
+ 	 * The rtmutex has an owner - either current or some other
+ 	 * task. See the EAGAIN loop above.
+ 	 */
+ 	pi_state_update_owner(pi_state, rt_mutex_owner(&pi_state->pi_mutex));
+ 
+ 	return err;
+ }
+ 
+ static int fixup_pi_state_owner(u32 __user *uaddr, struct futex_q *q,
+ 				struct task_struct *argowner)
+ {
+ 	struct futex_pi_state *pi_state = q->pi_state;
+ 	int ret;
+ 
+ 	lockdep_assert_held(q->lock_ptr);
+ 
+ 	raw_spin_lock_irq(&pi_state->pi_mutex.wait_lock);
+ 	ret = __fixup_pi_state_owner(uaddr, q, argowner);
+ 	raw_spin_unlock_irq(&pi_state->pi_mutex.wait_lock);
+ 	return ret;
++>>>>>>> 34b1a1ce1458 (futex: Handle faults correctly for PI futexes)
  }
  
  static long futex_wait_restart(struct restart_block *restart);
@@@ -2280,13 -2765,18 +2354,19 @@@ static long futex_wait_restart(struct r
  /*
   * Userspace tried a 0 -> TID atomic transition of the futex value
   * and failed. The kernel side here does the whole locking operation:
 - * if there are waiters then it will block as a consequence of relying
 - * on rt-mutexes, it does PI, etc. (Due to races the kernel might see
 - * a 0 value of the futex too.).
 - *
 - * Also serves as futex trylock_pi()'ing, and due semantics.
 + * if there are waiters then it will block, it does PI, etc. (Due to
 + * races the kernel might see a 0 value of the futex too.)
   */
 -static int futex_lock_pi(u32 __user *uaddr, unsigned int flags,
 +static int futex_lock_pi(u32 __user *uaddr, unsigned int flags, int detect,
  			 ktime_t *time, int trylock)
  {
++<<<<<<< HEAD
 +	struct hrtimer_sleeper timeout, *to = NULL;
++=======
+ 	struct hrtimer_sleeper timeout, *to;
+ 	struct task_struct *exiting = NULL;
+ 	struct rt_mutex_waiter rt_waiter;
++>>>>>>> 34b1a1ce1458 (futex: Handle faults correctly for PI futexes)
  	struct futex_hash_bucket *hb;
  	struct futex_q q = futex_q_init;
  	int res, ret;
@@@ -2363,17 -2910,9 +2443,23 @@@ retry_private
  	if (res)
  		ret = (res < 0) ? res : 0;
  
++<<<<<<< HEAD
 +	/*
 +	 * If fixup_owner() faulted and was unable to handle the fault, unlock
 +	 * it and return the fault to userspace.
 +	 */
 +	if (ret && (rt_mutex_owner(&q.pi_state->pi_mutex) == current))
 +		rt_mutex_unlock(&q.pi_state->pi_mutex);
 +
 +	/* Unqueue and drop the lock */
 +	unqueue_me_pi(&q);
 +
 +	goto out_put_key;
++=======
+ 	/* Unqueue and drop the lock */
+ 	unqueue_me_pi(&q);
+ 	goto out;
++>>>>>>> 34b1a1ce1458 (futex: Handle faults correctly for PI futexes)
  
  out_unlock_put_key:
  	queue_unlock(hb);
@@@ -2579,9 -3170,8 +2665,13 @@@ static int futex_wait_requeue_pi(u32 __
  				 u32 val, ktime_t *abs_time, u32 bitset,
  				 u32 __user *uaddr2)
  {
++<<<<<<< HEAD
 +	struct hrtimer_sleeper timeout, *to = NULL;
++=======
+ 	struct hrtimer_sleeper timeout, *to;
++>>>>>>> 34b1a1ce1458 (futex: Handle faults correctly for PI futexes)
  	struct rt_mutex_waiter rt_waiter;
 +	struct rt_mutex *pi_mutex = NULL;
  	struct futex_hash_bucket *hb;
  	union futex_key key2 = FUTEX_KEY_INIT;
  	struct futex_q q = futex_q_init;
@@@ -2665,9 -3248,21 +2755,17 @@@
  		if (q.pi_state && (q.pi_state->owner != current)) {
  			spin_lock(q.lock_ptr);
  			ret = fixup_pi_state_owner(uaddr2, &q, current);
++<<<<<<< HEAD
++=======
+ 			/*
+ 			 * Drop the reference to the pi state which
+ 			 * the requeue_pi() code acquired for us.
+ 			 */
+ 			put_pi_state(q.pi_state);
++>>>>>>> 34b1a1ce1458 (futex: Handle faults correctly for PI futexes)
  			spin_unlock(q.lock_ptr);
 -			/*
 -			 * Adjust the return value. It's either -EFAULT or
 -			 * success (1) but the caller expects 0 for success.
 -			 */
 -			ret = ret < 0 ? ret : 0;
  		}
  	} else {
 -		struct rt_mutex *pi_mutex;
 -
  		/*
  		 * We have been woken up by futex_unlock_pi(), a timeout, or a
  		 * signal.  futex_unlock_pi() will not destroy the lock_ptr nor
@@@ -2695,14 -3293,7 +2793,18 @@@
  		unqueue_me_pi(&q);
  	}
  
++<<<<<<< HEAD
 +	/*
 +	 * If fixup_pi_state_owner() faulted and was unable to handle the
 +	 * fault, unlock the rt_mutex and return the fault to userspace.
 +	 */
 +	if (ret == -EFAULT) {
 +		if (pi_mutex && rt_mutex_owner(pi_mutex) == current)
 +			rt_mutex_unlock(pi_mutex);
 +	} else if (ret == -EINTR) {
++=======
+ 	if (ret == -EINTR) {
++>>>>>>> 34b1a1ce1458 (futex: Handle faults correctly for PI futexes)
  		/*
  		 * We've already been requeued, but cannot restart by calling
  		 * futex_lock_pi() directly. We could restart this syscall, but
* Unmerged path kernel/futex.c
