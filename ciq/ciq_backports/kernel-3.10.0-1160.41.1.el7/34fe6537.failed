mm/vmalloc.c:__vmalloc_area_node(): avoid 32-bit overflow

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1160.41.1.el7
Rebuild_CHGLOG: - mm/vmalloc: __vmalloc_area_node(): avoid 32-bit overflow (Rafael Aquini) [1896794]
Rebuild_FUZZ: 97.35%
commit-author Andrew Morton <akpm@linux-foundation.org>
commit 34fe653716b0d340bc26dd4823d2dbe00c57f849
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.41.1.el7/34fe6537.failed

With a machine with 3 TB (more than 2 TB memory).  If you use vmalloc to
allocate > 2 TB memory, the array_size below will be overflowed.

The array_size is an unsigned int and can only be used to allocate less
than 2 TB memory.  If you pass 2*1028*1028*1024*1024 = 2 * 2^40 in the
argument of vmalloc.  The array_size will become 2*2^31 = 2^32.  The 2^32
cannot be store with a 32 bit integer.

The fix is to change the type of array_size to unsigned long.

[akpm@linux-foundation.org: rework for current mainline]

Link: https://bugzilla.kernel.org/show_bug.cgi?id=210023
	Reported-by: <hsinhuiwu@gmail.com>
	Cc: Matthew Wilcox <willy@infradead.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 34fe653716b0d340bc26dd4823d2dbe00c57f849)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/vmalloc.c
diff --cc mm/vmalloc.c
index 164d5c83caaf,8a2dc571bc8d..000000000000
--- a/mm/vmalloc.c
+++ b/mm/vmalloc.c
@@@ -1598,23 -2411,69 +1598,37 @@@ void *vmap(struct page **pages, unsigne
  }
  EXPORT_SYMBOL(vmap);
  
 -#ifdef CONFIG_VMAP_PFN
 -struct vmap_pfn_data {
 -	unsigned long	*pfns;
 -	pgprot_t	prot;
 -	unsigned int	idx;
 -};
 -
 -static int vmap_pfn_apply(pte_t *pte, unsigned long addr, void *private)
 -{
 -	struct vmap_pfn_data *data = private;
 -
 -	if (WARN_ON_ONCE(pfn_valid(data->pfns[data->idx])))
 -		return -EINVAL;
 -	*pte = pte_mkspecial(pfn_pte(data->pfns[data->idx++], data->prot));
 -	return 0;
 -}
 -
 -/**
 - * vmap_pfn - map an array of PFNs into virtually contiguous space
 - * @pfns: array of PFNs
 - * @count: number of pages to map
 - * @prot: page protection for the mapping
 - *
 - * Maps @count PFNs from @pfns into contiguous kernel virtual space and returns
 - * the start address of the mapping.
 - */
 -void *vmap_pfn(unsigned long *pfns, unsigned int count, pgprot_t prot)
 -{
 -	struct vmap_pfn_data data = { .pfns = pfns, .prot = pgprot_nx(prot) };
 -	struct vm_struct *area;
 -
 -	area = get_vm_area_caller(count * PAGE_SIZE, VM_IOREMAP,
 -			__builtin_return_address(0));
 -	if (!area)
 -		return NULL;
 -	if (apply_to_page_range(&init_mm, (unsigned long)area->addr,
 -			count * PAGE_SIZE, vmap_pfn_apply, &data)) {
 -		free_vm_area(area);
 -		return NULL;
 -	}
 -	return area->addr;
 -}
 -EXPORT_SYMBOL_GPL(vmap_pfn);
 -#endif /* CONFIG_VMAP_PFN */
 -
  static void *__vmalloc_area_node(struct vm_struct *area, gfp_t gfp_mask,
 -				 pgprot_t prot, int node)
 +				 pgprot_t prot, int node, const void *caller)
  {
++<<<<<<< HEAD
 +	const int order = 0;
++=======
+ 	const gfp_t nested_gfp = (gfp_mask & GFP_RECLAIM_MASK) | __GFP_ZERO;
+ 	unsigned int nr_pages = get_vm_area_size(area) >> PAGE_SHIFT;
+ 	unsigned long array_size;
+ 	unsigned int i;
++>>>>>>> 34fe653716b0 (mm/vmalloc.c:__vmalloc_area_node(): avoid 32-bit overflow)
  	struct page **pages;
 +	unsigned int nr_pages, array_size, i;
 +	gfp_t nested_gfp = (gfp_mask & GFP_RECLAIM_MASK) | __GFP_ZERO;
  
++<<<<<<< HEAD
 +	nr_pages = (area->size - PAGE_SIZE) >> PAGE_SHIFT;
 +	array_size = (nr_pages * sizeof(struct page *));
++=======
+ 	array_size = (unsigned long)nr_pages * sizeof(struct page *);
+ 	gfp_mask |= __GFP_NOWARN;
+ 	if (!(gfp_mask & (GFP_DMA | GFP_DMA32)))
+ 		gfp_mask |= __GFP_HIGHMEM;
++>>>>>>> 34fe653716b0 (mm/vmalloc.c:__vmalloc_area_node(): avoid 32-bit overflow)
  
 +	area->nr_pages = nr_pages;
  	/* Please note that the recursion is strictly bounded. */
  	if (array_size > PAGE_SIZE) {
 -		pages = __vmalloc_node(array_size, 1, nested_gfp, node,
 -					area->caller);
 +		pages = __vmalloc_node(array_size, 1, nested_gfp|__GFP_HIGHMEM,
 +				PAGE_KERNEL, node, caller);
 +		area->flags |= VM_VPAGES;
  	} else {
  		pages = kmalloc_node(array_size, nested_gfp, node);
  	}
* Unmerged path mm/vmalloc.c
