x86, mm: introduce _PAGE_DEVMAP

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [x86] mm: introduce _PAGE_DEVMAP (Jeff Moyer) [1346083 1346084 1346445 1346449 1346472 1347091 1359806]
Rebuild_FUZZ: 91.23%
commit-author Dan Williams <dan.j.williams@intel.com>
commit 69660fd797c3e52f7f20478a27687f293d1a41be
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/69660fd7.failed

_PAGE_DEVMAP is a hardware-unused pte bit that will later be used in the
get_user_pages() path to identify pfns backed by the dynamic allocation
established by devm_memremap_pages.  Upon seeing that bit the gup path
will lookup and pin the allocation while the pages are in use.

Since the _PAGE_DEVMAP bit is > 32 it must be cast to u64 instead of a
pteval_t to allow pmd_flags() usage in the realmode boot code to build.

	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 69660fd797c3e52f7f20478a27687f293d1a41be)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/pgtable_types.h
diff --cc arch/x86/include/asm/pgtable_types.h
index 6fdbf77a317c,04c27a013165..000000000000
--- a/arch/x86/include/asm/pgtable_types.h
+++ b/arch/x86/include/asm/pgtable_types.h
@@@ -16,15 -16,17 +16,25 @@@
  #define _PAGE_BIT_PSE		7	/* 4 MB (or 2MB) page */
  #define _PAGE_BIT_PAT		7	/* on 4KB pages */
  #define _PAGE_BIT_GLOBAL	8	/* Global TLB entry PPro+ */
 -#define _PAGE_BIT_SOFTW1	9	/* available for programmer */
 -#define _PAGE_BIT_SOFTW2	10	/* " */
 -#define _PAGE_BIT_SOFTW3	11	/* " */
 +#define _PAGE_BIT_UNUSED1	9	/* available for programmer */
 +#define _PAGE_BIT_IOMAP		10	/* flag used to indicate IO mapping */
 +#define _PAGE_BIT_HIDDEN	11	/* hidden by kmemcheck */
  #define _PAGE_BIT_PAT_LARGE	12	/* On 2MB or 1GB pages */
++<<<<<<< HEAD
 +#define _PAGE_BIT_SPECIAL	_PAGE_BIT_UNUSED1
 +#define _PAGE_BIT_CPA_TEST	_PAGE_BIT_UNUSED1
 +#define _PAGE_BIT_SPLITTING	_PAGE_BIT_UNUSED1 /* only valid on a PSE pmd */
 +#define _PAGE_BIT_SOFTDIRTY	_PAGE_BIT_HIDDEN
 +#define _PAGE_BIT_NX           63       /* No execute: only valid after cpuid check */
++=======
+ #define _PAGE_BIT_SPECIAL	_PAGE_BIT_SOFTW1
+ #define _PAGE_BIT_CPA_TEST	_PAGE_BIT_SOFTW1
+ #define _PAGE_BIT_HIDDEN	_PAGE_BIT_SOFTW3 /* hidden by kmemcheck */
+ #define _PAGE_BIT_SOFT_DIRTY	_PAGE_BIT_SOFTW3 /* software dirty tracking */
+ #define _PAGE_BIT_SOFTW4	58	/* available for programmer */
+ #define _PAGE_BIT_DEVMAP		_PAGE_BIT_SOFTW4
+ #define _PAGE_BIT_NX		63	/* No execute: only valid after cpuid check */
++>>>>>>> 69660fd797c3 (x86, mm: introduce _PAGE_DEVMAP)
  
  /* If _PAGE_BIT_PRESENT is clear, we use these: */
  /* - if the user mapped it with PROT_NONE; pte_present gives true */
@@@ -57,35 -55,45 +67,38 @@@
  #define _PAGE_HIDDEN	(_AT(pteval_t, 0))
  #endif
  
 -/*
 - * The same hidden bit is used by kmemcheck, but since kmemcheck
 - * works on kernel pages while soft-dirty engine on user space,
 - * they do not conflict with each other.
 - */
 -
 -#ifdef CONFIG_MEM_SOFT_DIRTY
 -#define _PAGE_SOFT_DIRTY	(_AT(pteval_t, 1) << _PAGE_BIT_SOFT_DIRTY)
 -#else
 -#define _PAGE_SOFT_DIRTY	(_AT(pteval_t, 0))
 -#endif
 -
 -/*
 - * Tracking soft dirty bit when a page goes to a swap is tricky.
 - * We need a bit which can be stored in pte _and_ not conflict
 - * with swap entry format. On x86 bits 6 and 7 are *not* involved
 - * into swap entry computation, but bit 6 is used for nonlinear
 - * file mapping, so we borrow bit 7 for soft dirty tracking.
 - *
 - * Please note that this bit must be treated as swap dirty page
 - * mark if and only if the PTE has present bit clear!
 - */
 -#ifdef CONFIG_MEM_SOFT_DIRTY
 -#define _PAGE_SWP_SOFT_DIRTY	_PAGE_PSE
 -#else
 -#define _PAGE_SWP_SOFT_DIRTY	(_AT(pteval_t, 0))
 -#endif
 -
  #if defined(CONFIG_X86_64) || defined(CONFIG_X86_PAE)
  #define _PAGE_NX	(_AT(pteval_t, 1) << _PAGE_BIT_NX)
+ #define _PAGE_DEVMAP	(_AT(u64, 1) << _PAGE_BIT_DEVMAP)
+ #define __HAVE_ARCH_PTE_DEVMAP
  #else
  #define _PAGE_NX	(_AT(pteval_t, 0))
+ #define _PAGE_DEVMAP	(_AT(pteval_t, 0))
  #endif
  
 +#define _PAGE_FILE	(_AT(pteval_t, 1) << _PAGE_BIT_FILE)
  #define _PAGE_PROTNONE	(_AT(pteval_t, 1) << _PAGE_BIT_PROTNONE)
  
 +/*
 + * _PAGE_NUMA indicates that this page will trigger a numa hinting
 + * minor page fault to gather numa placement statistics (see
 + * pte_numa()). The bit picked (8) is within the range between
 + * _PAGE_FILE (6) and _PAGE_PROTNONE (8) bits. Therefore, it doesn't
 + * require changes to the swp entry format because that bit is always
 + * zero when the pte is not present.
 + *
 + * The bit picked must be always zero when the pmd is present and not
 + * present, so that we don't lose information when we set it while
 + * atomically clearing the present bit.
 + *
 + * Because we shared the same bit (8) with _PAGE_PROTNONE this can be
 + * interpreted as _PAGE_NUMA only in places that _PAGE_PROTNONE
 + * couldn't reach, like handle_mm_fault() (see access_error in
 + * arch/x86/mm/fault.c, the vma protection must not be PROT_NONE for
 + * handle_mm_fault() to be invoked).
 + */
 +#define _PAGE_NUMA	_PAGE_PROTNONE
 +
  #define _PAGE_TABLE	(_PAGE_PRESENT | _PAGE_RW | _PAGE_USER |	\
  			 _PAGE_ACCESSED | _PAGE_DIRTY)
  #define _KERNPG_TABLE	(_PAGE_PRESENT | _PAGE_RW | _PAGE_ACCESSED |	\
* Unmerged path arch/x86/include/asm/pgtable_types.h
