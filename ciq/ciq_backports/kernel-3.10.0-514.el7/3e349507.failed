perf: Fix perf_enable_on_exec() event scheduling

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Peter Zijlstra <peterz@infradead.org>
commit 3e349507d12de93b08b0aa814fc2aa0dee91c5ba
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/3e349507.failed

There are two problems with the current perf_enable_on_exec() event
scheduling:

  - the newly enabled events will be immediately scheduled
    irrespective of their ctx event list order.

  - there's a hole in the ctx->lock between scheduling the events
    out and putting them back on.

Esp. the latter issue is a real problem because a hole in event
scheduling leaves the thing in an observable inconsistent state,
confusing things.

Fix both issues by first doing the enable iteration and at the end,
when there are newly enabled events, reschedule the ctx in one go.

	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
	Cc: David Ahern <dsahern@gmail.com>
	Cc: Jiri Olsa <jolsa@redhat.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Namhyung Kim <namhyung@kernel.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Stephane Eranian <eranian@google.com>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Vince Weaver <vincent.weaver@maine.edu>
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 3e349507d12de93b08b0aa814fc2aa0dee91c5ba)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/events/core.c
diff --cc kernel/events/core.c
index 1f4ad251e896,0679e73f5f63..000000000000
--- a/kernel/events/core.c
+++ b/kernel/events/core.c
@@@ -3059,36 -3117,20 +3070,49 @@@ static void perf_event_enable_on_exec(i
  	if (!ctx || !ctx->nr_events)
  		goto out;
  
++<<<<<<< HEAD
 +	/*
 +	 * We must ctxsw out cgroup events to avoid conflict
 +	 * when invoking perf_task_event_sched_in() later on
 +	 * in this function. Otherwise we end up trying to
 +	 * ctxswin cgroup events which are already scheduled
 +	 * in.
 +	 */
 +	perf_cgroup_sched_out(current, NULL);
 +
 +	raw_spin_lock(&ctx->lock);
 +	task_ctx_sched_out(ctx);
 +
 +	list_for_each_entry(event, &ctx->event_list, event_entry) {
 +		ret = event_enable_on_exec(event, ctx);
 +		if (ret)
 +			enabled = 1;
 +	}
++=======
+ 	cpuctx = __get_cpu_context(ctx);
+ 	perf_ctx_lock(cpuctx, ctx);
+ 	list_for_each_entry(event, &ctx->event_list, event_entry)
+ 		enabled |= event_enable_on_exec(event, ctx);
++>>>>>>> 3e349507d12d (perf: Fix perf_enable_on_exec() event scheduling)
  
  	/*
- 	 * Unclone this context if we enabled any event.
+ 	 * Unclone and reschedule this context if we enabled any event.
  	 */
- 	if (enabled)
+ 	if (enabled) {
  		clone_ctx = unclone_ctx(ctx);
+ 		ctx_resched(cpuctx, ctx);
+ 	}
+ 	perf_ctx_unlock(cpuctx, ctx);
  
++<<<<<<< HEAD
 +	raw_spin_unlock(&ctx->lock);
 +
 +	/*
 +	 * Also calls ctxswin for cgroup events, if any:
 +	 */
 +	perf_event_context_sched_in(ctx, ctx->task);
++=======
++>>>>>>> 3e349507d12d (perf: Fix perf_enable_on_exec() event scheduling)
  out:
  	local_irq_restore(flags);
  
* Unmerged path kernel/events/core.c
