IB/qib: Remove create qp and create qp table functionality

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Harish Chegondi <harish.chegondi@intel.com>
commit 47c7ea6d8e70510c3b3e311cfc20943cd3fe786a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/47c7ea6d.failed

Rely on rdmavt functions for creation of qp and qp table.  Function to
allocate a qpn is still being provided by qib as the algorithm to allocate
a qpn in qib is different from that of the algorithm in rdmavt.

	Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
	Reviewed-by: Ira Weiny <ira.weiny@intel.com>
	Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
	Signed-off-by: Harish Chegondi <harish.chegondi@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 47c7ea6d8e70510c3b3e311cfc20943cd3fe786a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/qib/qib.h
#	drivers/infiniband/hw/qib/qib_qp.c
#	drivers/infiniband/hw/qib/qib_verbs.c
#	drivers/infiniband/hw/qib/qib_verbs.h
diff --cc drivers/infiniband/hw/qib/qib.h
index 2c9672d7da79,29cbe67f39d9..000000000000
--- a/drivers/infiniband/hw/qib/qib.h
+++ b/drivers/infiniband/hw/qib/qib.h
@@@ -1136,9 -1136,9 +1136,14 @@@ extern spinlock_t qib_devs_lock
  extern struct qib_devdata *qib_lookup(int unit);
  extern u32 qib_cpulist_count;
  extern unsigned long *qib_cpulist;
++<<<<<<< HEAD
 +
 +extern unsigned qib_wc_pat;
++=======
+ extern u16 qpt_mask;
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  extern unsigned qib_cc_table_size;
+ 
  int qib_init(struct qib_devdata *, int);
  int init_chip_wc_pat(struct qib_devdata *dd, u32);
  int qib_enable_wc(struct qib_devdata *dd);
diff --cc drivers/infiniband/hw/qib/qib_qp.c
index cf1dd6e9d434,83dec693845e..000000000000
--- a/drivers/infiniband/hw/qib/qib_qp.c
+++ b/drivers/infiniband/hw/qib/qib_qp.c
@@@ -42,25 -42,31 +42,35 @@@
  
  #include "qib.h"
  
++<<<<<<< HEAD
 +#define BITS_PER_PAGE           (PAGE_SIZE*BITS_PER_BYTE)
 +#define BITS_PER_PAGE_MASK      (BITS_PER_PAGE-1)
++=======
+ /*
+  * mask field which was present in now deleted qib_qpn_table
+  * is not present in rvt_qpn_table. Defining the same field
+  * as qpt_mask here instead of adding the mask field to
+  * rvt_qpn_table.
+  */
+ u16 qpt_mask;
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  
 -static inline unsigned mk_qpn(struct rvt_qpn_table *qpt,
 -			      struct rvt_qpn_map *map, unsigned off)
 +static inline unsigned mk_qpn(struct qib_qpn_table *qpt,
 +			      struct qpn_map *map, unsigned off)
  {
 -	return (map - qpt->map) * RVT_BITS_PER_PAGE + off;
 +	return (map - qpt->map) * BITS_PER_PAGE + off;
  }
  
 -static inline unsigned find_next_offset(struct rvt_qpn_table *qpt,
 -					struct rvt_qpn_map *map, unsigned off,
 +static inline unsigned find_next_offset(struct qib_qpn_table *qpt,
 +					struct qpn_map *map, unsigned off,
  					unsigned n)
  {
 -	if (qpt_mask) {
 +	if (qpt->mask) {
  		off++;
 -		if (((off & qpt_mask) >> 1) >= n)
 -			off = (off | qpt_mask) + 2;
 -	} else {
 -		off = find_next_zero_bit(map->page, RVT_BITS_PER_PAGE, off);
 -	}
 +		if (((off & qpt->mask) >> 1) >= n)
 +			off = (off | qpt->mask) + 2;
 +	} else
 +		off = find_next_zero_bit(map->page, BITS_PER_PAGE, off);
  	return off;
  }
  
@@@ -122,12 -128,15 +132,20 @@@ static void get_map_page(struct qib_qpn
   * Allocate the next available QPN or
   * zero/one for QP type IB_QPT_SMI/IB_QPT_GSI.
   */
++<<<<<<< HEAD
 +static int alloc_qpn(struct qib_devdata *dd, struct qib_qpn_table *qpt,
 +		     enum ib_qp_type type, u8 port, gfp_t gfp)
++=======
+ int alloc_qpn(struct rvt_dev_info *rdi, struct rvt_qpn_table *qpt,
+ 	      enum ib_qp_type type, u8 port, gfp_t gfp)
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  {
  	u32 i, offset, max_scan, qpn;
 -	struct rvt_qpn_map *map;
 +	struct qpn_map *map;
  	u32 ret;
+ 	struct qib_ibdev *verbs_dev = container_of(rdi, struct qib_ibdev, rdi);
+ 	struct qib_devdata *dd = container_of(verbs_dev, struct qib_devdata,
+ 					      verbs_dev);
  
  	if (type == IB_QPT_SMI || type == IB_QPT_GSI) {
  		unsigned n;
@@@ -288,16 -299,12 +306,18 @@@ static void remove_qp(struct qib_ibdev 
  
  /**
   * qib_free_all_qps - check for QPs still in use
-  * @qpt: the QP table to empty
-  *
-  * There should not be any QPs still in use.
-  * Free memory for table.
   */
- unsigned qib_free_all_qps(struct qib_devdata *dd)
+ unsigned qib_free_all_qps(struct rvt_dev_info *rdi)
  {
++<<<<<<< HEAD
 +	struct qib_ibdev *dev = &dd->verbs_dev;
 +	unsigned long flags;
 +	struct qib_qp *qp;
++=======
+ 	struct qib_ibdev *verbs_dev = container_of(rdi, struct qib_ibdev, rdi);
+ 	struct qib_devdata *dd = container_of(verbs_dev, struct qib_devdata,
+ 					      verbs_dev);
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  	unsigned n, qp_inuse = 0;
  
  	for (n = 0; n < dd->num_pports; n++) {
@@@ -312,20 -319,6 +332,23 @@@
  			qp_inuse++;
  		rcu_read_unlock();
  	}
++<<<<<<< HEAD
 +
 +	spin_lock_irqsave(&dev->qpt_lock, flags);
 +	for (n = 0; n < dev->qp_table_size; n++) {
 +		qp = rcu_dereference_protected(dev->qp_table[n],
 +			lockdep_is_held(&dev->qpt_lock));
 +		rcu_assign_pointer(dev->qp_table[n], NULL);
 +
 +		for (; qp; qp = rcu_dereference_protected(qp->next,
 +					lockdep_is_held(&dev->qpt_lock)))
 +			qp_inuse++;
 +	}
 +	spin_unlock_irqrestore(&dev->qpt_lock, flags);
 +	synchronize_rcu();
 +
++=======
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  	return qp_inuse;
  }
  
@@@ -364,60 -357,14 +387,65 @@@ struct qib_qp *qib_lookup_qpn(struct qi
  	return qp;
  }
  
++<<<<<<< HEAD
 +/**
 + * qib_reset_qp - initialize the QP state to the reset state
 + * @qp: the QP to reset
 + * @type: the QP type
 + */
 +static void qib_reset_qp(struct qib_qp *qp, enum ib_qp_type type)
++=======
+ void notify_qp_reset(struct rvt_qp *qp)
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  {
  	struct qib_qp_priv *priv = qp->priv;
- 	qp->remote_qpn = 0;
- 	qp->qkey = 0;
- 	qp->qp_access_flags = 0;
+ 
  	atomic_set(&priv->s_dma_busy, 0);
++<<<<<<< HEAD
 +	qp->s_flags &= QIB_S_SIGNAL_REQ_WR;
 +	qp->s_hdrwords = 0;
 +	qp->s_wqe = NULL;
 +	qp->s_draining = 0;
 +	qp->s_next_psn = 0;
 +	qp->s_last_psn = 0;
 +	qp->s_sending_psn = 0;
 +	qp->s_sending_hpsn = 0;
 +	qp->s_psn = 0;
 +	qp->r_psn = 0;
 +	qp->r_msn = 0;
 +	if (type == IB_QPT_RC) {
 +		qp->s_state = IB_OPCODE_RC_SEND_LAST;
 +		qp->r_state = IB_OPCODE_RC_SEND_LAST;
 +	} else {
 +		qp->s_state = IB_OPCODE_UC_SEND_LAST;
 +		qp->r_state = IB_OPCODE_UC_SEND_LAST;
 +	}
 +	qp->s_ack_state = IB_OPCODE_RC_ACKNOWLEDGE;
 +	qp->r_nak_state = 0;
 +	qp->r_aflags = 0;
 +	qp->r_flags = 0;
 +	qp->s_head = 0;
 +	qp->s_tail = 0;
 +	qp->s_cur = 0;
 +	qp->s_acked = 0;
 +	qp->s_last = 0;
 +	qp->s_ssn = 1;
 +	qp->s_lsn = 0;
 +	qp->s_mig_state = IB_MIG_MIGRATED;
 +	memset(qp->s_ack_queue, 0, sizeof(qp->s_ack_queue));
 +	qp->r_head_ack_queue = 0;
 +	qp->s_tail_ack_queue = 0;
 +	qp->s_num_rd_atomic = 0;
 +	if (qp->r_rq.wq) {
 +		qp->r_rq.wq->head = 0;
 +		qp->r_rq.wq->tail = 0;
 +	}
 +	qp->r_sge.num_sge = 0;
++=======
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  }
  
 -static void clear_mr_refs(struct rvt_qp *qp, int clr_sends)
 +static void clear_mr_refs(struct qib_qp *qp, int clr_sends)
  {
  	unsigned n;
  
@@@ -967,246 -916,33 +995,226 @@@ __be32 qib_compute_aeth(struct qib_qp *
  	return cpu_to_be32(aeth);
  }
  
- /**
-  * qib_create_qp - create a queue pair for a device
-  * @ibpd: the protection domain who's device we create the queue pair for
-  * @init_attr: the attributes of the queue pair
-  * @udata: user data for libibverbs.so
-  *
-  * Returns the queue pair on success, otherwise returns an errno.
-  *
-  * Called by the ib_create_qp() core verbs function.
-  */
- struct ib_qp *qib_create_qp(struct ib_pd *ibpd,
- 			    struct ib_qp_init_attr *init_attr,
- 			    struct ib_udata *udata)
+ void *qp_priv_alloc(struct rvt_dev_info *rdi, struct rvt_qp *qp, gfp_t gfp)
  {
++<<<<<<< HEAD
 +	struct qib_qp *qp;
 +	int err;
 +	struct qib_swqe *swq = NULL;
 +	struct qib_ibdev *dev;
 +	struct qib_devdata *dd;
 +	size_t sz;
 +	size_t sg_list_sz;
 +	struct ib_qp *ret;
 +	gfp_t gfp;
++=======
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  	struct qib_qp_priv *priv;
  
- 	if (init_attr->cap.max_send_sge > ib_qib_max_sges ||
- 	    init_attr->cap.max_send_wr > ib_qib_max_qp_wrs ||
- 	    init_attr->create_flags & ~(IB_QP_CREATE_USE_GFP_NOIO))
- 		return ERR_PTR(-EINVAL);
- 
- 	/* GFP_NOIO is applicable in RC QPs only */
- 	if (init_attr->create_flags & IB_QP_CREATE_USE_GFP_NOIO &&
- 	    init_attr->qp_type != IB_QPT_RC)
- 		return ERR_PTR(-EINVAL);
+ 	priv = kzalloc(sizeof(*priv), gfp);
+ 	if (!priv)
+ 		return ERR_PTR(-ENOMEM);
+ 	priv->owner = qp;
  
- 	gfp = init_attr->create_flags & IB_QP_CREATE_USE_GFP_NOIO ?
- 			GFP_NOIO : GFP_KERNEL;
- 
- 	/* Check receive queue parameters if no SRQ is specified. */
- 	if (!init_attr->srq) {
- 		if (init_attr->cap.max_recv_sge > ib_qib_max_sges ||
- 		    init_attr->cap.max_recv_wr > ib_qib_max_qp_wrs) {
- 			ret = ERR_PTR(-EINVAL);
- 			goto bail;
- 		}
- 		if (init_attr->cap.max_send_sge +
- 		    init_attr->cap.max_send_wr +
- 		    init_attr->cap.max_recv_sge +
- 		    init_attr->cap.max_recv_wr == 0) {
- 			ret = ERR_PTR(-EINVAL);
- 			goto bail;
- 		}
+ 	priv->s_hdr = kzalloc(sizeof(*priv->s_hdr), gfp);
+ 	if (!priv->s_hdr) {
+ 		kfree(priv);
+ 		return ERR_PTR(-ENOMEM);
  	}
+ 	init_waitqueue_head(&priv->wait_dma);
+ 	INIT_WORK(&priv->s_work, qib_do_send);
+ 	INIT_LIST_HEAD(&priv->iowait);
  
++<<<<<<< HEAD
 +	switch (init_attr->qp_type) {
 +	case IB_QPT_SMI:
 +	case IB_QPT_GSI:
 +		if (init_attr->port_num == 0 ||
 +		    init_attr->port_num > ibpd->device->phys_port_cnt) {
 +			ret = ERR_PTR(-EINVAL);
 +			goto bail;
 +		}
 +	case IB_QPT_UC:
 +	case IB_QPT_RC:
 +	case IB_QPT_UD:
 +		sz = sizeof(struct qib_sge) *
 +			init_attr->cap.max_send_sge +
 +			sizeof(struct qib_swqe);
 +		swq = __vmalloc((init_attr->cap.max_send_wr + 1) * sz,
 +				gfp, PAGE_KERNEL);
 +		if (swq == NULL) {
 +			ret = ERR_PTR(-ENOMEM);
 +			goto bail;
 +		}
 +		sz = sizeof(*qp);
 +		sg_list_sz = 0;
 +		if (init_attr->srq) {
 +			struct qib_srq *srq = to_isrq(init_attr->srq);
 +
 +			if (srq->rq.max_sge > 1)
 +				sg_list_sz = sizeof(*qp->r_sg_list) *
 +					(srq->rq.max_sge - 1);
 +		} else if (init_attr->cap.max_recv_sge > 1)
 +			sg_list_sz = sizeof(*qp->r_sg_list) *
 +				(init_attr->cap.max_recv_sge - 1);
 +		qp = kzalloc(sz + sg_list_sz, gfp);
 +		if (!qp) {
 +			ret = ERR_PTR(-ENOMEM);
 +			goto bail_swq;
 +		}
 +		RCU_INIT_POINTER(qp->next, NULL);
 +		priv = kzalloc(sizeof(*priv), gfp);
 +		if (!priv) {
 +			ret = ERR_PTR(-ENOMEM);
 +			goto bail_qp_hdr;
 +		}
 +		priv->owner = qp;
 +		priv->s_hdr = kzalloc(sizeof(*priv->s_hdr), gfp);
 +		if (!priv->s_hdr) {
 +			ret = ERR_PTR(-ENOMEM);
 +			goto bail_qp;
 +		}
 +		qp->priv = priv;
 +		qp->timeout_jiffies =
 +			usecs_to_jiffies((4096UL * (1UL << qp->timeout)) /
 +				1000UL);
 +		if (init_attr->srq)
 +			sz = 0;
 +		else {
 +			qp->r_rq.size = init_attr->cap.max_recv_wr + 1;
 +			qp->r_rq.max_sge = init_attr->cap.max_recv_sge;
 +			sz = (sizeof(struct ib_sge) * qp->r_rq.max_sge) +
 +				sizeof(struct qib_rwqe);
 +			if (gfp != GFP_NOIO)
 +				qp->r_rq.wq = vmalloc_user(
 +						sizeof(struct qib_rwq) +
 +						qp->r_rq.size * sz);
 +			else
 +				qp->r_rq.wq = __vmalloc(
 +						sizeof(struct qib_rwq) +
 +						qp->r_rq.size * sz,
 +						gfp, PAGE_KERNEL);
 +
 +			if (!qp->r_rq.wq) {
 +				ret = ERR_PTR(-ENOMEM);
 +				goto bail_qp;
 +			}
 +		}
 +
 +		/*
 +		 * ib_create_qp() will initialize qp->ibqp
 +		 * except for qp->ibqp.qp_num.
 +		 */
 +		spin_lock_init(&qp->r_lock);
 +		spin_lock_init(&qp->s_lock);
 +		spin_lock_init(&qp->r_rq.lock);
 +		atomic_set(&qp->refcount, 0);
 +		init_waitqueue_head(&qp->wait);
 +		init_waitqueue_head(&priv->wait_dma);
 +		init_timer(&qp->s_timer);
 +		qp->s_timer.data = (unsigned long)qp;
 +		INIT_WORK(&priv->s_work, qib_do_send);
 +		INIT_LIST_HEAD(&priv->iowait);
 +		INIT_LIST_HEAD(&qp->rspwait);
 +		qp->state = IB_QPS_RESET;
 +		qp->s_wq = swq;
 +		qp->s_size = init_attr->cap.max_send_wr + 1;
 +		qp->s_max_sge = init_attr->cap.max_send_sge;
 +		if (init_attr->sq_sig_type == IB_SIGNAL_REQ_WR)
 +			qp->s_flags = QIB_S_SIGNAL_REQ_WR;
 +		dev = to_idev(ibpd->device);
 +		dd = dd_from_dev(dev);
 +		err = alloc_qpn(dd, &dev->qpn_table, init_attr->qp_type,
 +				init_attr->port_num, gfp);
 +		if (err < 0) {
 +			ret = ERR_PTR(err);
 +			vfree(qp->r_rq.wq);
 +			goto bail_qp;
 +		}
 +		qp->ibqp.qp_num = err;
 +		qp->port_num = init_attr->port_num;
 +		qib_reset_qp(qp, init_attr->qp_type);
 +		break;
 +
 +	default:
 +		/* Don't support raw QPs */
 +		ret = ERR_PTR(-ENOSYS);
 +		goto bail;
 +	}
 +
 +	init_attr->cap.max_inline_data = 0;
 +
 +	/*
 +	 * Return the address of the RWQ as the offset to mmap.
 +	 * See qib_mmap() for details.
 +	 */
 +	if (udata && udata->outlen >= sizeof(__u64)) {
 +		if (!qp->r_rq.wq) {
 +			__u64 offset = 0;
 +
 +			err = ib_copy_to_udata(udata, &offset,
 +					       sizeof(offset));
 +			if (err) {
 +				ret = ERR_PTR(err);
 +				goto bail_ip;
 +			}
 +		} else {
 +			u32 s = sizeof(struct qib_rwq) + qp->r_rq.size * sz;
 +
 +			qp->ip = qib_create_mmap_info(dev, s,
 +						      ibpd->uobject->context,
 +						      qp->r_rq.wq);
 +			if (!qp->ip) {
 +				ret = ERR_PTR(-ENOMEM);
 +				goto bail_ip;
 +			}
 +
 +			err = ib_copy_to_udata(udata, &(qp->ip->offset),
 +					       sizeof(qp->ip->offset));
 +			if (err) {
 +				ret = ERR_PTR(err);
 +				goto bail_ip;
 +			}
 +		}
 +	}
 +
 +	spin_lock(&dev->n_qps_lock);
 +	if (dev->n_qps_allocated == ib_qib_max_qps) {
 +		spin_unlock(&dev->n_qps_lock);
 +		ret = ERR_PTR(-ENOMEM);
 +		goto bail_ip;
 +	}
 +
 +	dev->n_qps_allocated++;
 +	spin_unlock(&dev->n_qps_lock);
 +
 +	if (qp->ip) {
 +		spin_lock_irq(&dev->pending_lock);
 +		list_add(&qp->ip->pending_mmaps, &dev->pending_mmaps);
 +		spin_unlock_irq(&dev->pending_lock);
 +	}
 +
 +	ret = &qp->ibqp;
 +	goto bail;
 +
 +bail_ip:
 +	if (qp->ip)
 +		kref_put(&qp->ip->ref, qib_release_mmap_info);
 +	else
 +		vfree(qp->r_rq.wq);
 +	free_qpn(&dev->qpn_table, qp->ibqp.qp_num);
 +bail_qp:
++=======
+ 	return priv;
+ }
+ 
+ void qp_priv_free(struct rvt_dev_info *rdi, struct rvt_qp *qp)
+ {
+ 	struct qib_qp_priv *priv = qp->priv;
+ 
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  	kfree(priv->s_hdr);
  	kfree(priv);
- bail_qp_hdr:
- 	kfree(qp);
- bail_swq:
- 	vfree(swq);
- bail:
- 	return ret;
  }
  
  /**
@@@ -1265,31 -1001,6 +1273,34 @@@ int qib_destroy_qp(struct ib_qp *ibqp
  }
  
  /**
++<<<<<<< HEAD
 + * qib_init_qpn_table - initialize the QP number table for a device
 + * @qpt: the QPN table
 + */
 +void qib_init_qpn_table(struct qib_devdata *dd, struct qib_qpn_table *qpt)
 +{
 +	spin_lock_init(&qpt->lock);
 +	qpt->last = 1;          /* start with QPN 2 */
 +	qpt->nmaps = 1;
 +	qpt->mask = dd->qpn_mask;
 +}
 +
 +/**
 + * qib_free_qpn_table - free the QP number table for a device
 + * @qpt: the QPN table
 + */
 +void qib_free_qpn_table(struct qib_qpn_table *qpt)
 +{
 +	int i;
 +
 +	for (i = 0; i < ARRAY_SIZE(qpt->map); i++)
 +		if (qpt->map[i].page)
 +			free_page((unsigned long) qpt->map[i].page);
 +}
 +
 +/**
++=======
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
   * qib_get_credit - flush the send work queue of a QP
   * @qp: the qp who's send work queue to flush
   * @aeth: the Acknowledge Extended Transport Header
diff --cc drivers/infiniband/hw/qib/qib_verbs.c
index c4417a1f33be,6b85153ee917..000000000000
--- a/drivers/infiniband/hw/qib/qib_verbs.c
+++ b/drivers/infiniband/hw/qib/qib_verbs.c
@@@ -2089,29 -1901,14 +2089,36 @@@ int qib_register_ib_device(struct qib_d
  	struct qib_ibdev *dev = &dd->verbs_dev;
  	struct ib_device *ibdev = &dev->rdi.ibdev;
  	struct qib_pportdata *ppd = dd->pport;
 -	unsigned i, ctxt;
 +	unsigned i, lk_tab_size;
  	int ret;
  
++<<<<<<< HEAD
 +	dev->qp_table_size = ib_qib_qp_table_size;
 +	get_random_bytes(&dev->qp_rnd, sizeof(dev->qp_rnd));
 +	dev->qp_table = kmalloc_array(
 +				dev->qp_table_size,
 +				sizeof(*dev->qp_table),
 +				GFP_KERNEL);
 +	if (!dev->qp_table) {
 +		ret = -ENOMEM;
 +		goto err_qpt;
 +	}
 +	for (i = 0; i < dev->qp_table_size; i++)
 +		RCU_INIT_POINTER(dev->qp_table[i], NULL);
 +
++=======
+ 	get_random_bytes(&dev->qp_rnd, sizeof(dev->qp_rnd));
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  	for (i = 0; i < dd->num_pports; i++)
  		init_ibport(ppd + i);
  
  	/* Only need to initialize non-zero fields. */
++<<<<<<< HEAD
 +	spin_lock_init(&dev->qpt_lock);
 +	spin_lock_init(&dev->n_pds_lock);
 +	spin_lock_init(&dev->n_ahs_lock);
++=======
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  	spin_lock_init(&dev->n_cqs_lock);
  	spin_lock_init(&dev->n_qps_lock);
  	spin_lock_init(&dev->n_srqs_lock);
@@@ -2120,35 -1917,8 +2127,39 @@@
  	dev->mem_timer.function = mem_timer;
  	dev->mem_timer.data = (unsigned long) dev;
  
++<<<<<<< HEAD
 +	qib_init_qpn_table(dd, &dev->qpn_table);
++=======
+ 	qpt_mask = dd->qpn_mask;
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  
 +	/*
 +	 * The top ib_qib_lkey_table_size bits are used to index the
 +	 * table.  The lower 8 bits can be owned by the user (copied from
 +	 * the LKEY).  The remaining bits act as a generation number or tag.
 +	 */
 +	spin_lock_init(&dev->lk_table.lock);
 +	/* insure generation is at least 4 bits see keys.c */
 +	if (ib_qib_lkey_table_size > MAX_LKEY_TABLE_BITS) {
 +		qib_dev_warn(dd, "lkey bits %u too large, reduced to %u\n",
 +			ib_qib_lkey_table_size, MAX_LKEY_TABLE_BITS);
 +		ib_qib_lkey_table_size = MAX_LKEY_TABLE_BITS;
 +	}
 +	dev->lk_table.max = 1 << ib_qib_lkey_table_size;
 +	lk_tab_size = dev->lk_table.max * sizeof(*dev->lk_table.table);
 +	dev->lk_table.table = (struct qib_mregion __rcu **)
 +		vmalloc(lk_tab_size);
 +	if (dev->lk_table.table == NULL) {
 +		ret = -ENOMEM;
 +		goto err_lk;
 +	}
 +	RCU_INIT_POINTER(dev->dma_mr, NULL);
 +	for (i = 0; i < dev->lk_table.max; i++)
 +		RCU_INIT_POINTER(dev->lk_table.table[i], NULL);
 +	INIT_LIST_HEAD(&dev->pending_mmaps);
 +	spin_lock_init(&dev->pending_lock);
 +	dev->mmap_offset = PAGE_SIZE;
 +	spin_lock_init(&dev->mmap_offset_lock);
  	INIT_LIST_HEAD(&dev->piowait);
  	INIT_LIST_HEAD(&dev->dmawait);
  	INIT_LIST_HEAD(&dev->txwait);
@@@ -2283,11 -2051,36 +2294,33 @@@
  	dd->verbs_dev.rdi.driver_f.port_callback = qib_create_port_files;
  	dd->verbs_dev.rdi.driver_f.get_card_name = qib_get_card_name;
  	dd->verbs_dev.rdi.driver_f.get_pci_dev = qib_get_pci_dev;
++<<<<<<< HEAD
 +	dd->verbs_dev.rdi.dparms.props.max_pd = ib_qib_max_pds;
 +	dd->verbs_dev.rdi.flags = (RVT_FLAG_MR_INIT_DRIVER |
 +				   RVT_FLAG_QP_INIT_DRIVER |
 +				   RVT_FLAG_CQ_INIT_DRIVER);
++=======
+ 	dd->verbs_dev.rdi.driver_f.check_ah = qib_check_ah;
+ 	dd->verbs_dev.rdi.driver_f.notify_new_ah = qib_notify_new_ah;
+ 	dd->verbs_dev.rdi.driver_f.alloc_qpn = alloc_qpn;
+ 	dd->verbs_dev.rdi.driver_f.qp_priv_alloc = qp_priv_alloc;
+ 	dd->verbs_dev.rdi.driver_f.qp_priv_free = qp_priv_free;
+ 	dd->verbs_dev.rdi.driver_f.free_all_qps = qib_free_all_qps;
+ 	dd->verbs_dev.rdi.driver_f.notify_qp_reset = notify_qp_reset;
+ 
+ 	dd->verbs_dev.rdi.flags = RVT_FLAG_CQ_INIT_DRIVER;
+ 
+ 	dd->verbs_dev.rdi.dparms.lkey_table_size = qib_lkey_table_size;
+ 	dd->verbs_dev.rdi.dparms.qp_table_size = ib_qib_qp_table_size;
+ 	dd->verbs_dev.rdi.dparms.qpn_start = 1;
+ 	dd->verbs_dev.rdi.dparms.qpn_res_start = QIB_KD_QP;
+ 	dd->verbs_dev.rdi.dparms.qpn_res_end = QIB_KD_QP; /* Reserve one QP */
+ 	dd->verbs_dev.rdi.dparms.qpn_inc = 1;
+ 	dd->verbs_dev.rdi.dparms.qos_shift = 1;
+ 	dd->verbs_dev.rdi.dparms.nports = dd->num_pports;
+ 	dd->verbs_dev.rdi.dparms.npkeys = qib_get_npkeys(dd);
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  
 -	qib_fill_device_attr(dd);
 -
 -	ppd = dd->pport;
 -	for (i = 0; i < dd->num_pports; i++, ppd++) {
 -		ctxt = ppd->hw_pidx;
 -		rvt_init_port(&dd->verbs_dev.rdi,
 -			      &ppd->ibport_data.rvp,
 -			      i,
 -			      dd->rcd[ctxt]->pkeys);
 -	}
  
  	ret = rvt_register_device(&dd->verbs_dev.rdi);
  	if (ret)
@@@ -2323,10 -2116,6 +2356,13 @@@ err_tx
  					sizeof(struct qib_pio_header),
  				  dev->pio_hdrs, dev->pio_hdrs_phys);
  err_hdrs:
++<<<<<<< HEAD
 +	vfree(dev->lk_table.table);
 +err_lk:
 +	kfree(dev->qp_table);
 +err_qpt:
++=======
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  	qib_dev_err(dd, "cannot register verbs: %d!\n", -ret);
  bail:
  	return ret;
@@@ -2335,8 -2124,6 +2371,11 @@@
  void qib_unregister_ib_device(struct qib_devdata *dd)
  {
  	struct qib_ibdev *dev = &dd->verbs_dev;
++<<<<<<< HEAD
 +	u32 qps_inuse;
 +	unsigned lk_tab_size;
++=======
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  
  	qib_verbs_unregister_sysfs(dd);
  
@@@ -2352,16 -2139,8 +2391,14 @@@
  		qib_dev_err(dd, "txwait list not empty!\n");
  	if (!list_empty(&dev->memwait))
  		qib_dev_err(dd, "memwait list not empty!\n");
 +	if (dev->dma_mr)
 +		qib_dev_err(dd, "DMA MR not NULL!\n");
  
- 	qps_inuse = qib_free_all_qps(dd);
- 	if (qps_inuse)
- 		qib_dev_err(dd, "QP memory leak! %u still in use\n",
- 			    qps_inuse);
- 
  	del_timer_sync(&dev->mem_timer);
++<<<<<<< HEAD
 +	qib_free_qpn_table(&dev->qpn_table);
++=======
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  	while (!list_empty(&dev->txreq_free)) {
  		struct list_head *l = dev->txreq_free.next;
  		struct qib_verbs_txreq *tx;
@@@ -2375,9 -2154,6 +2412,12 @@@
  				  dd->pport->sdma_descq_cnt *
  					sizeof(struct qib_pio_header),
  				  dev->pio_hdrs, dev->pio_hdrs_phys);
++<<<<<<< HEAD
 +	lk_tab_size = dev->lk_table.max * sizeof(*dev->lk_table.table);
 +	vfree(dev->lk_table.table);
 +	kfree(dev->qp_table);
++=======
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  }
  
  /*
diff --cc drivers/infiniband/hw/qib/qib_verbs.h
index ca366073af4f,bcc627181298..000000000000
--- a/drivers/infiniband/hw/qib/qib_verbs.h
+++ b/drivers/infiniband/hw/qib/qib_verbs.h
@@@ -919,29 -460,28 +919,37 @@@ int qib_multicast_detach(struct ib_qp *
  
  int qib_mcast_tree_empty(struct qib_ibport *ibp);
  
 -__be32 qib_compute_aeth(struct rvt_qp *qp);
 +__be32 qib_compute_aeth(struct qib_qp *qp);
  
 -struct rvt_qp *qib_lookup_qpn(struct qib_ibport *ibp, u32 qpn);
 +struct qib_qp *qib_lookup_qpn(struct qib_ibport *ibp, u32 qpn);
  
- struct ib_qp *qib_create_qp(struct ib_pd *ibpd,
- 			    struct ib_qp_init_attr *init_attr,
- 			    struct ib_udata *udata);
- 
  int qib_destroy_qp(struct ib_qp *ibqp);
  
 -int qib_error_qp(struct rvt_qp *qp, enum ib_wc_status err);
 +int qib_error_qp(struct qib_qp *qp, enum ib_wc_status err);
  
  int qib_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
  		  int attr_mask, struct ib_udata *udata);
  
  int qib_query_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
  		 int attr_mask, struct ib_qp_init_attr *init_attr);
++<<<<<<< HEAD
 +
 +unsigned qib_free_all_qps(struct qib_devdata *dd);
 +
 +void qib_init_qpn_table(struct qib_devdata *dd, struct qib_qpn_table *qpt);
 +
 +void qib_free_qpn_table(struct qib_qpn_table *qpt);
++=======
+ /*
+  * Functions provided by qib driver for rdmavt to use
+  */
+ unsigned qib_free_all_qps(struct rvt_dev_info *rdi);
+ void *qp_priv_alloc(struct rvt_dev_info *rdi, struct rvt_qp *qp, gfp_t gfp);
+ void qp_priv_free(struct rvt_dev_info *rdi, struct rvt_qp *qp);
+ void notify_qp_reset(struct rvt_qp *qp);
+ int alloc_qpn(struct rvt_dev_info *rdi, struct rvt_qpn_table *qpt,
+ 	      enum ib_qp_type type, u8 port, gfp_t gfp);
++>>>>>>> 47c7ea6d8e70 (IB/qib: Remove create qp and create qp table functionality)
  
  #ifdef CONFIG_DEBUG_FS
  
* Unmerged path drivers/infiniband/hw/qib/qib.h
* Unmerged path drivers/infiniband/hw/qib/qib_qp.c
* Unmerged path drivers/infiniband/hw/qib/qib_verbs.c
* Unmerged path drivers/infiniband/hw/qib/qib_verbs.h
