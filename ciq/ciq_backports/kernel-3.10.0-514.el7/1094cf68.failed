be2iscsi: Fix IOPOLL implementation

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Jitendra Bhivare <jitendra.bhivare@avagotech.com>
commit 1094cf68e801cdde7b65dc91fb8e9276af736176
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/1094cf68.failed

OS not responding when running 2 port traffic on 72 CPUs system.

be2iscsi IRQs gets affined to CPU0 when irqbalancer is disabled.
be_iopoll processing completions in BLOCK_IOPOLL_SOFTIRQ hogged CPU0.

1. Use budget to exit the polling loop. beiscsi_process_cq didn't honour
   it.
2. Rearming of EQ is done only after iopoll completes.

[mkp: Fixed up blk_iopoll -> irq_poll transition]

	Signed-off-by: Jitendra Bhivare <jitendra.bhivare@avagotech.com>
	Reviewed-by: Hannes Reinecke <hare@suse.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit 1094cf68e801cdde7b65dc91fb8e9276af736176)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/be2iscsi/be_iscsi.c
#	drivers/scsi/be2iscsi/be_main.c
diff --cc drivers/scsi/be2iscsi/be_iscsi.c
index 1f1ae87225b9,8bf7379b06ad..000000000000
--- a/drivers/scsi/be2iscsi/be_iscsi.c
+++ b/drivers/scsi/be2iscsi/be_iscsi.c
@@@ -1299,9 -1297,9 +1299,15 @@@ static void beiscsi_flush_cq(struct bei
  
  	for (i = 0; i < phba->num_cpus; i++) {
  		pbe_eq = &phwi_context->be_eq[i];
++<<<<<<< HEAD
 +		blk_iopoll_disable(&pbe_eq->iopoll);
 +		beiscsi_process_cq(pbe_eq);
 +		blk_iopoll_enable(&pbe_eq->iopoll);
++=======
+ 		irq_poll_disable(&pbe_eq->iopoll);
+ 		beiscsi_process_cq(pbe_eq, BE2_MAX_NUM_CQ_PROC);
+ 		irq_poll_enable(&pbe_eq->iopoll);
++>>>>>>> 1094cf68e801 (be2iscsi: Fix IOPOLL implementation)
  	}
  }
  
diff --cc drivers/scsi/be2iscsi/be_main.c
index abdc14b473a0,9c3a7b2421c8..000000000000
--- a/drivers/scsi/be2iscsi/be_main.c
+++ b/drivers/scsi/be2iscsi/be_main.c
@@@ -896,49 -896,17 +897,51 @@@ static irqreturn_t be_isr_mcc(int irq, 
  static irqreturn_t be_isr_msix(int irq, void *dev_id)
  {
  	struct beiscsi_hba *phba;
- 	struct be_eq_entry *eqe = NULL;
  	struct be_queue_info *eq;
- 	struct be_queue_info *cq;
- 	unsigned int num_eq_processed;
  	struct be_eq_obj *pbe_eq;
 +	unsigned long flags;
  
  	pbe_eq = dev_id;
  	eq = &pbe_eq->q;
- 	cq = pbe_eq->cq;
- 	eqe = queue_tail_node(eq);
  
  	phba = pbe_eq->phba;
++<<<<<<< HEAD
 +	num_eq_processed = 0;
 +	if (blk_iopoll_enabled) {
 +		while (eqe->dw[offsetof(struct amap_eq_entry, valid) / 32]
 +					& EQE_VALID_MASK) {
 +			if (!blk_iopoll_sched_prep(&pbe_eq->iopoll))
 +				blk_iopoll_sched(&pbe_eq->iopoll);
 +
 +			AMAP_SET_BITS(struct amap_eq_entry, valid, eqe, 0);
 +			queue_tail_inc(eq);
 +			eqe = queue_tail_node(eq);
 +			num_eq_processed++;
 +		}
 +	} else {
 +		while (eqe->dw[offsetof(struct amap_eq_entry, valid) / 32]
 +						& EQE_VALID_MASK) {
 +			spin_lock_irqsave(&phba->isr_lock, flags);
 +			pbe_eq->todo_cq = true;
 +			spin_unlock_irqrestore(&phba->isr_lock, flags);
 +			AMAP_SET_BITS(struct amap_eq_entry, valid, eqe, 0);
 +			queue_tail_inc(eq);
 +			eqe = queue_tail_node(eq);
 +			num_eq_processed++;
 +		}
 +
 +		if (pbe_eq->todo_cq)
 +			queue_work(phba->wq, &pbe_eq->work_cqs);
 +	}
 +
 +	if (num_eq_processed)
 +		hwi_ring_eq_db(phba, eq->id, 1,	num_eq_processed, 0, 1);
++=======
+ 
+ 	/* disable interrupt till iopoll completes */
+ 	hwi_ring_eq_db(phba, eq->id, 1,	0, 0, 1);
+ 	irq_poll_sched(&pbe_eq->iopoll);
++>>>>>>> 1094cf68e801 (be2iscsi: Fix IOPOLL implementation)
  
  	return IRQ_HANDLED;
  }
@@@ -981,74 -948,42 +984,75 @@@ static irqreturn_t be_isr(int irq, voi
  
  	num_ioeq_processed = 0;
  	num_mcceq_processed = 0;
 -	while (eqe->dw[offsetof(struct amap_eq_entry, valid) / 32]
 -				& EQE_VALID_MASK) {
 -		if (((eqe->dw[offsetof(struct amap_eq_entry,
 -		     resource_id) / 32] &
 -		     EQE_RESID_MASK) >> 16) == mcc->id) {
 -			spin_lock_irqsave(&phba->isr_lock, flags);
 -			pbe_eq->todo_mcc_cq = true;
 -			spin_unlock_irqrestore(&phba->isr_lock, flags);
 -			num_mcceq_processed++;
 -		} else {
 -			irq_poll_sched(&pbe_eq->iopoll);
 +	if (blk_iopoll_enabled) {
 +		while (eqe->dw[offsetof(struct amap_eq_entry, valid) / 32]
 +					& EQE_VALID_MASK) {
 +			if (((eqe->dw[offsetof(struct amap_eq_entry,
 +			     resource_id) / 32] &
 +			     EQE_RESID_MASK) >> 16) == mcc->id) {
 +				spin_lock_irqsave(&phba->isr_lock, flags);
 +				pbe_eq->todo_mcc_cq = true;
 +				spin_unlock_irqrestore(&phba->isr_lock, flags);
 +				num_mcceq_processed++;
 +			} else {
 +				if (!blk_iopoll_sched_prep(&pbe_eq->iopoll))
 +					blk_iopoll_sched(&pbe_eq->iopoll);
 +				num_ioeq_processed++;
 +			}
 +			AMAP_SET_BITS(struct amap_eq_entry, valid, eqe, 0);
 +			queue_tail_inc(eq);
 +			eqe = queue_tail_node(eq);
 +		}
 +		if (num_ioeq_processed || num_mcceq_processed) {
 +			if (pbe_eq->todo_mcc_cq)
 +				queue_work(phba->wq, &pbe_eq->work_cqs);
 +
 +			if ((num_mcceq_processed) && (!num_ioeq_processed))
 +				hwi_ring_eq_db(phba, eq->id, 0,
 +					      (num_ioeq_processed +
 +					       num_mcceq_processed) , 1, 1);
 +			else
 +				hwi_ring_eq_db(phba, eq->id, 0,
 +					       (num_ioeq_processed +
 +						num_mcceq_processed), 0, 1);
 +
 +			return IRQ_HANDLED;
 +		} else
 +			return IRQ_NONE;
 +	} else {
 +		cq = &phwi_context->be_cq[0];
 +		while (eqe->dw[offsetof(struct amap_eq_entry, valid) / 32]
 +						& EQE_VALID_MASK) {
 +
 +			if (((eqe->dw[offsetof(struct amap_eq_entry,
 +			     resource_id) / 32] &
 +			     EQE_RESID_MASK) >> 16) != cq->id) {
 +				spin_lock_irqsave(&phba->isr_lock, flags);
 +				pbe_eq->todo_mcc_cq = true;
 +				spin_unlock_irqrestore(&phba->isr_lock, flags);
 +			} else {
 +				spin_lock_irqsave(&phba->isr_lock, flags);
 +				pbe_eq->todo_cq = true;
 +				spin_unlock_irqrestore(&phba->isr_lock, flags);
 +			}
 +			AMAP_SET_BITS(struct amap_eq_entry, valid, eqe, 0);
 +			queue_tail_inc(eq);
 +			eqe = queue_tail_node(eq);
  			num_ioeq_processed++;
  		}
 -		AMAP_SET_BITS(struct amap_eq_entry, valid, eqe, 0);
 -		queue_tail_inc(eq);
 -		eqe = queue_tail_node(eq);
 -	}
 -	if (num_ioeq_processed || num_mcceq_processed) {
 -		if (pbe_eq->todo_mcc_cq)
 +		if (pbe_eq->todo_cq || pbe_eq->todo_mcc_cq)
  			queue_work(phba->wq, &pbe_eq->work_cqs);
  
 -		if ((num_mcceq_processed) && (!num_ioeq_processed))
 +		if (num_ioeq_processed) {
  			hwi_ring_eq_db(phba, eq->id, 0,
 -				      (num_ioeq_processed +
 -				       num_mcceq_processed) , 1, 1);
 -		else
 -			hwi_ring_eq_db(phba, eq->id, 0,
 -				       (num_ioeq_processed +
 -					num_mcceq_processed), 0, 1);
 -
 -		return IRQ_HANDLED;
 -	} else
 -		return IRQ_NONE;
 +				       num_ioeq_processed, 1, 1);
 +			return IRQ_HANDLED;
 +		} else
 +			return IRQ_NONE;
 +	}
  }
  
+ 
  static int beiscsi_init_irqs(struct beiscsi_hba *phba)
  {
  	struct pci_dev *pcidev = phba->pcidev;
@@@ -2346,22 -2272,38 +2355,43 @@@ void beiscsi_process_all_cqs(struct wor
  	hwi_ring_eq_db(phba, pbe_eq->q.id, 0, 0, 1, 1);
  }
  
 -static int be_iopoll(struct irq_poll *iop, int budget)
 +static int be_iopoll(struct blk_iopoll *iop, int budget)
  {
- 	unsigned int ret;
+ 	unsigned int ret, num_eq_processed;
  	struct beiscsi_hba *phba;
  	struct be_eq_obj *pbe_eq;
+ 	struct be_eq_entry *eqe = NULL;
+ 	struct be_queue_info *eq;
  
+ 	num_eq_processed = 0;
  	pbe_eq = container_of(iop, struct be_eq_obj, iopoll);
- 	ret = beiscsi_process_cq(pbe_eq);
+ 	phba = pbe_eq->phba;
+ 	eq = &pbe_eq->q;
+ 	eqe = queue_tail_node(eq);
+ 
+ 	while (eqe->dw[offsetof(struct amap_eq_entry, valid) / 32] &
+ 			EQE_VALID_MASK) {
+ 		AMAP_SET_BITS(struct amap_eq_entry, valid, eqe, 0);
+ 		queue_tail_inc(eq);
+ 		eqe = queue_tail_node(eq);
+ 		num_eq_processed++;
+ 	}
+ 
+ 	hwi_ring_eq_db(phba, eq->id, 1, num_eq_processed, 0, 1);
+ 
+ 	ret = beiscsi_process_cq(pbe_eq, budget);
  	pbe_eq->cq_count += ret;
  	if (ret < budget) {
++<<<<<<< HEAD
 +		phba = pbe_eq->phba;
 +		blk_iopoll_complete(iop);
++=======
+ 		irq_poll_complete(iop);
++>>>>>>> 1094cf68e801 (be2iscsi: Fix IOPOLL implementation)
  		beiscsi_log(phba, KERN_INFO,
  			    BEISCSI_LOG_CONFIG | BEISCSI_LOG_IO,
- 			    "BM_%d : rearm pbe_eq->q.id =%d\n",
- 			    pbe_eq->q.id);
+ 			    "BM_%d : rearm pbe_eq->q.id =%d ret %d\n",
+ 			    pbe_eq->q.id, ret);
  		hwi_ring_eq_db(phba, pbe_eq->q.id, 0, 0, 1, 1);
  	}
  	return ret;
diff --git a/drivers/scsi/be2iscsi/be_cmds.c b/drivers/scsi/be2iscsi/be_cmds.c
index 3a78e054ddea..73de0f8ed988 100644
--- a/drivers/scsi/be2iscsi/be_cmds.c
+++ b/drivers/scsi/be2iscsi/be_cmds.c
@@ -507,7 +507,7 @@ int beiscsi_process_mcc(struct beiscsi_hba *phba)
 	}
 
 	if (num)
-		hwi_ring_cq_db(phba, phba->ctrl.mcc_obj.cq.id, num, 1, 0);
+		hwi_ring_cq_db(phba, phba->ctrl.mcc_obj.cq.id, num, 1);
 
 	spin_unlock_bh(&phba->ctrl.mcc_cq_lock);
 	return status;
* Unmerged path drivers/scsi/be2iscsi/be_iscsi.c
* Unmerged path drivers/scsi/be2iscsi/be_main.c
diff --git a/drivers/scsi/be2iscsi/be_main.h b/drivers/scsi/be2iscsi/be_main.h
index 7c1871cc0ca5..5a62ce6ed058 100644
--- a/drivers/scsi/be2iscsi/be_main.h
+++ b/drivers/scsi/be2iscsi/be_main.h
@@ -63,6 +63,7 @@
 #define BE2_SGE			32
 #define BE2_DEFPDU_HDR_SZ	64
 #define BE2_DEFPDU_DATA_SZ	8192
+#define BE2_MAX_NUM_CQ_PROC	512
 
 #define MAX_CPUS		64
 #define BEISCSI_MAX_NUM_CPUS	7
@@ -844,9 +845,9 @@ void beiscsi_free_mgmt_task_handles(struct beiscsi_conn *beiscsi_conn,
 
 void hwi_ring_cq_db(struct beiscsi_hba *phba,
 		     unsigned int id, unsigned int num_processed,
-		     unsigned char rearm, unsigned char event);
+		     unsigned char rearm);
 
-unsigned int beiscsi_process_cq(struct be_eq_obj *pbe_eq);
+unsigned int beiscsi_process_cq(struct be_eq_obj *pbe_eq, int budget);
 
 static inline bool beiscsi_error(struct beiscsi_hba *phba)
 {
