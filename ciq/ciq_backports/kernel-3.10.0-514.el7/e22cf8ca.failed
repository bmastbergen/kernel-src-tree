s390/cpumf: rework program parameter setting to detect guest samples

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [s390] cpumf: rework program parameter setting to detect guest samples (Hendrik Brueckner) [1339534]
Rebuild_FUZZ: 96.18%
commit-author Christian Borntraeger <borntraeger@de.ibm.com>
commit e22cf8ca6f75a6c4fccf2d6ee818bdb1205f32e6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/e22cf8ca.failed

The program parameter can be used to mark hardware samples with
some token.  Previously, it was used to mark guest samples only.

Improve the program parameter doubleword by combining two parts,
the leftmost LPP part and the rightmost PID part.  Set the PID
part for processes by using the task PID.
To distinguish host and guest samples for the kernel (PID part
is zero), the guest must always set the program paramater to a
non-zero value.  Use the leftmost bit in the LPP part of the
program parameter to be able to detect guest kernel samples.

[brueckner@linux.vnet.ibm.com]: Split __LC_CURRENT and introduced
__LC_LPP. Corrected __LC_CURRENT users and adjusted assembler parts.
And updated the commit message accordingly.

	Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
	Signed-off-by: Hendrik Brueckner <brueckner@linux.vnet.ibm.com>
	Reviewed-by: Heiko Carstens <heiko.carstens@de.ibm.com>
	Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
(cherry picked from commit e22cf8ca6f75a6c4fccf2d6ee818bdb1205f32e6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/s390/kernel/asm-offsets.c
#	arch/s390/kernel/entry.S
#	arch/s390/kernel/perf_cpum_sf.c
#	arch/s390/mm/fault.c
diff --cc arch/s390/kernel/asm-offsets.c
index 809fed72a8da,9cd248f637c7..000000000000
--- a/arch/s390/kernel/asm-offsets.c
+++ b/arch/s390/kernel/asm-offsets.c
@@@ -71,102 -84,112 +71,195 @@@ int main(void
  	/* constants used by the vdso */
  	DEFINE(__CLOCK_REALTIME, CLOCK_REALTIME);
  	DEFINE(__CLOCK_MONOTONIC, CLOCK_MONOTONIC);
 -	DEFINE(__CLOCK_REALTIME_COARSE, CLOCK_REALTIME_COARSE);
 -	DEFINE(__CLOCK_MONOTONIC_COARSE, CLOCK_MONOTONIC_COARSE);
  	DEFINE(__CLOCK_THREAD_CPUTIME_ID, CLOCK_THREAD_CPUTIME_ID);
  	DEFINE(__CLOCK_REALTIME_RES, MONOTONIC_RES_NSEC);
 -	DEFINE(__CLOCK_COARSE_RES, LOW_RES_NSEC);
  	BLANK();
  	/* idle data offsets */
 -	OFFSET(__CLOCK_IDLE_ENTER, s390_idle_data, clock_idle_enter);
 -	OFFSET(__CLOCK_IDLE_EXIT, s390_idle_data, clock_idle_exit);
 -	OFFSET(__TIMER_IDLE_ENTER, s390_idle_data, timer_idle_enter);
 -	OFFSET(__TIMER_IDLE_EXIT, s390_idle_data, timer_idle_exit);
 +	DEFINE(__CLOCK_IDLE_ENTER, offsetof(struct s390_idle_data, clock_idle_enter));
 +	DEFINE(__CLOCK_IDLE_EXIT, offsetof(struct s390_idle_data, clock_idle_exit));
 +	DEFINE(__TIMER_IDLE_ENTER, offsetof(struct s390_idle_data, timer_idle_enter));
 +	DEFINE(__TIMER_IDLE_EXIT, offsetof(struct s390_idle_data, timer_idle_exit));
 +	/* lowcore offsets */
 +	DEFINE(__LC_EXT_PARAMS, offsetof(struct _lowcore, ext_params));
 +	DEFINE(__LC_EXT_CPU_ADDR, offsetof(struct _lowcore, ext_cpu_addr));
 +	DEFINE(__LC_EXT_INT_CODE, offsetof(struct _lowcore, ext_int_code));
 +	DEFINE(__LC_SVC_ILC, offsetof(struct _lowcore, svc_ilc));
 +	DEFINE(__LC_SVC_INT_CODE, offsetof(struct _lowcore, svc_code));
 +	DEFINE(__LC_PGM_ILC, offsetof(struct _lowcore, pgm_ilc));
 +	DEFINE(__LC_PGM_INT_CODE, offsetof(struct _lowcore, pgm_code));
 +	DEFINE(__LC_TRANS_EXC_CODE, offsetof(struct _lowcore, trans_exc_code));
 +	DEFINE(__LC_PER_CAUSE, offsetof(struct _lowcore, per_perc_atmid));
 +	DEFINE(__LC_PER_ADDRESS, offsetof(struct _lowcore, per_address));
 +	DEFINE(__LC_PER_PAID, offsetof(struct _lowcore, per_access_id));
 +	DEFINE(__LC_AR_MODE_ID, offsetof(struct _lowcore, ar_access_id));
 +	DEFINE(__LC_SUBCHANNEL_ID, offsetof(struct _lowcore, subchannel_id));
 +	DEFINE(__LC_SUBCHANNEL_NR, offsetof(struct _lowcore, subchannel_nr));
 +	DEFINE(__LC_IO_INT_PARM, offsetof(struct _lowcore, io_int_parm));
 +	DEFINE(__LC_IO_INT_WORD, offsetof(struct _lowcore, io_int_word));
 +	DEFINE(__LC_STFL_FAC_LIST, offsetof(struct _lowcore, stfl_fac_list));
 +	DEFINE(__LC_MCCK_CODE, offsetof(struct _lowcore, mcck_interruption_code));
 +	DEFINE(__LC_RST_OLD_PSW, offsetof(struct _lowcore, restart_old_psw));
 +	DEFINE(__LC_EXT_OLD_PSW, offsetof(struct _lowcore, external_old_psw));
 +	DEFINE(__LC_SVC_OLD_PSW, offsetof(struct _lowcore, svc_old_psw));
 +	DEFINE(__LC_PGM_OLD_PSW, offsetof(struct _lowcore, program_old_psw));
 +	DEFINE(__LC_MCK_OLD_PSW, offsetof(struct _lowcore, mcck_old_psw));
 +	DEFINE(__LC_IO_OLD_PSW, offsetof(struct _lowcore, io_old_psw));
 +	DEFINE(__LC_RST_NEW_PSW, offsetof(struct _lowcore, restart_psw));
 +	DEFINE(__LC_EXT_NEW_PSW, offsetof(struct _lowcore, external_new_psw));
 +	DEFINE(__LC_SVC_NEW_PSW, offsetof(struct _lowcore, svc_new_psw));
 +	DEFINE(__LC_PGM_NEW_PSW, offsetof(struct _lowcore, program_new_psw));
 +	DEFINE(__LC_MCK_NEW_PSW, offsetof(struct _lowcore, mcck_new_psw));
 +	DEFINE(__LC_IO_NEW_PSW, offsetof(struct _lowcore, io_new_psw));
  	BLANK();
++<<<<<<< HEAD
 +	DEFINE(__LC_SAVE_AREA_SYNC, offsetof(struct _lowcore, save_area_sync));
 +	DEFINE(__LC_SAVE_AREA_ASYNC, offsetof(struct _lowcore, save_area_async));
 +	DEFINE(__LC_SAVE_AREA_RESTART, offsetof(struct _lowcore, save_area_restart));
 +	DEFINE(__LC_RETURN_PSW, offsetof(struct _lowcore, return_psw));
 +	DEFINE(__LC_RETURN_MCCK_PSW, offsetof(struct _lowcore, return_mcck_psw));
 +	DEFINE(__LC_SYNC_ENTER_TIMER, offsetof(struct _lowcore, sync_enter_timer));
 +	DEFINE(__LC_ASYNC_ENTER_TIMER, offsetof(struct _lowcore, async_enter_timer));
 +	DEFINE(__LC_MCCK_ENTER_TIMER, offsetof(struct _lowcore, mcck_enter_timer));
 +	DEFINE(__LC_EXIT_TIMER, offsetof(struct _lowcore, exit_timer));
 +	DEFINE(__LC_USER_TIMER, offsetof(struct _lowcore, user_timer));
 +	DEFINE(__LC_SYSTEM_TIMER, offsetof(struct _lowcore, system_timer));
 +	DEFINE(__LC_STEAL_TIMER, offsetof(struct _lowcore, steal_timer));
 +	DEFINE(__LC_LAST_UPDATE_TIMER, offsetof(struct _lowcore, last_update_timer));
 +	DEFINE(__LC_LAST_UPDATE_CLOCK, offsetof(struct _lowcore, last_update_clock));
 +	DEFINE(__LC_CURRENT, offsetof(struct _lowcore, current_task));
 +	DEFINE(__LC_CURRENT_PID, offsetof(struct _lowcore, current_pid));
 +	DEFINE(__LC_THREAD_INFO, offsetof(struct _lowcore, thread_info));
 +	DEFINE(__LC_KERNEL_STACK, offsetof(struct _lowcore, kernel_stack));
 +	DEFINE(__LC_ASYNC_STACK, offsetof(struct _lowcore, async_stack));
 +	DEFINE(__LC_PANIC_STACK, offsetof(struct _lowcore, panic_stack));
 +	DEFINE(__LC_RESTART_STACK, offsetof(struct _lowcore, restart_stack));
 +	DEFINE(__LC_RESTART_FN, offsetof(struct _lowcore, restart_fn));
 +	DEFINE(__LC_RESTART_DATA, offsetof(struct _lowcore, restart_data));
 +	DEFINE(__LC_RESTART_SOURCE, offsetof(struct _lowcore, restart_source));
 +	DEFINE(__LC_KERNEL_ASCE, offsetof(struct _lowcore, kernel_asce));
 +	DEFINE(__LC_USER_ASCE, offsetof(struct _lowcore, user_asce));
 +	DEFINE(__LC_INT_CLOCK, offsetof(struct _lowcore, int_clock));
 +	DEFINE(__LC_MCCK_CLOCK, offsetof(struct _lowcore, mcck_clock));
 +	DEFINE(__LC_MACHINE_FLAGS, offsetof(struct _lowcore, machine_flags));
 +	DEFINE(__LC_FTRACE_FUNC, offsetof(struct _lowcore, ftrace_func));
 +	DEFINE(__LC_IRB, offsetof(struct _lowcore, irb));
 +	DEFINE(__LC_DUMP_REIPL, offsetof(struct _lowcore, ipib));
++=======
+ 	/* hardware defined lowcore locations 0x000 - 0x1ff */
+ 	OFFSET(__LC_EXT_PARAMS, _lowcore, ext_params);
+ 	OFFSET(__LC_EXT_CPU_ADDR, _lowcore, ext_cpu_addr);
+ 	OFFSET(__LC_EXT_INT_CODE, _lowcore, ext_int_code);
+ 	OFFSET(__LC_SVC_ILC, _lowcore, svc_ilc);
+ 	OFFSET(__LC_SVC_INT_CODE, _lowcore, svc_code);
+ 	OFFSET(__LC_PGM_ILC, _lowcore, pgm_ilc);
+ 	OFFSET(__LC_PGM_INT_CODE, _lowcore, pgm_code);
+ 	OFFSET(__LC_DATA_EXC_CODE, _lowcore, data_exc_code);
+ 	OFFSET(__LC_MON_CLASS_NR, _lowcore, mon_class_num);
+ 	OFFSET(__LC_PER_CODE, _lowcore, per_code);
+ 	OFFSET(__LC_PER_ATMID, _lowcore, per_atmid);
+ 	OFFSET(__LC_PER_ADDRESS, _lowcore, per_address);
+ 	OFFSET(__LC_EXC_ACCESS_ID, _lowcore, exc_access_id);
+ 	OFFSET(__LC_PER_ACCESS_ID, _lowcore, per_access_id);
+ 	OFFSET(__LC_OP_ACCESS_ID, _lowcore, op_access_id);
+ 	OFFSET(__LC_AR_MODE_ID, _lowcore, ar_mode_id);
+ 	OFFSET(__LC_TRANS_EXC_CODE, _lowcore, trans_exc_code);
+ 	OFFSET(__LC_MON_CODE, _lowcore, monitor_code);
+ 	OFFSET(__LC_SUBCHANNEL_ID, _lowcore, subchannel_id);
+ 	OFFSET(__LC_SUBCHANNEL_NR, _lowcore, subchannel_nr);
+ 	OFFSET(__LC_IO_INT_PARM, _lowcore, io_int_parm);
+ 	OFFSET(__LC_IO_INT_WORD, _lowcore, io_int_word);
+ 	OFFSET(__LC_STFL_FAC_LIST, _lowcore, stfl_fac_list);
+ 	OFFSET(__LC_MCCK_CODE, _lowcore, mcck_interruption_code);
+ 	OFFSET(__LC_MCCK_FAIL_STOR_ADDR, _lowcore, failing_storage_address);
+ 	OFFSET(__LC_LAST_BREAK, _lowcore, breaking_event_addr);
+ 	OFFSET(__LC_RST_OLD_PSW, _lowcore, restart_old_psw);
+ 	OFFSET(__LC_EXT_OLD_PSW, _lowcore, external_old_psw);
+ 	OFFSET(__LC_SVC_OLD_PSW, _lowcore, svc_old_psw);
+ 	OFFSET(__LC_PGM_OLD_PSW, _lowcore, program_old_psw);
+ 	OFFSET(__LC_MCK_OLD_PSW, _lowcore, mcck_old_psw);
+ 	OFFSET(__LC_IO_OLD_PSW, _lowcore, io_old_psw);
+ 	OFFSET(__LC_RST_NEW_PSW, _lowcore, restart_psw);
+ 	OFFSET(__LC_EXT_NEW_PSW, _lowcore, external_new_psw);
+ 	OFFSET(__LC_SVC_NEW_PSW, _lowcore, svc_new_psw);
+ 	OFFSET(__LC_PGM_NEW_PSW, _lowcore, program_new_psw);
+ 	OFFSET(__LC_MCK_NEW_PSW, _lowcore, mcck_new_psw);
+ 	OFFSET(__LC_IO_NEW_PSW, _lowcore, io_new_psw);
+ 	/* software defined lowcore locations 0x200 - 0xdff*/
+ 	OFFSET(__LC_SAVE_AREA_SYNC, _lowcore, save_area_sync);
+ 	OFFSET(__LC_SAVE_AREA_ASYNC, _lowcore, save_area_async);
+ 	OFFSET(__LC_SAVE_AREA_RESTART, _lowcore, save_area_restart);
+ 	OFFSET(__LC_CPU_FLAGS, _lowcore, cpu_flags);
+ 	OFFSET(__LC_RETURN_PSW, _lowcore, return_psw);
+ 	OFFSET(__LC_RETURN_MCCK_PSW, _lowcore, return_mcck_psw);
+ 	OFFSET(__LC_SYNC_ENTER_TIMER, _lowcore, sync_enter_timer);
+ 	OFFSET(__LC_ASYNC_ENTER_TIMER, _lowcore, async_enter_timer);
+ 	OFFSET(__LC_MCCK_ENTER_TIMER, _lowcore, mcck_enter_timer);
+ 	OFFSET(__LC_EXIT_TIMER, _lowcore, exit_timer);
+ 	OFFSET(__LC_USER_TIMER, _lowcore, user_timer);
+ 	OFFSET(__LC_SYSTEM_TIMER, _lowcore, system_timer);
+ 	OFFSET(__LC_STEAL_TIMER, _lowcore, steal_timer);
+ 	OFFSET(__LC_LAST_UPDATE_TIMER, _lowcore, last_update_timer);
+ 	OFFSET(__LC_LAST_UPDATE_CLOCK, _lowcore, last_update_clock);
+ 	OFFSET(__LC_INT_CLOCK, _lowcore, int_clock);
+ 	OFFSET(__LC_MCCK_CLOCK, _lowcore, mcck_clock);
+ 	OFFSET(__LC_CURRENT, _lowcore, current_task);
+ 	OFFSET(__LC_THREAD_INFO, _lowcore, thread_info);
+ 	OFFSET(__LC_KERNEL_STACK, _lowcore, kernel_stack);
+ 	OFFSET(__LC_ASYNC_STACK, _lowcore, async_stack);
+ 	OFFSET(__LC_PANIC_STACK, _lowcore, panic_stack);
+ 	OFFSET(__LC_RESTART_STACK, _lowcore, restart_stack);
+ 	OFFSET(__LC_RESTART_FN, _lowcore, restart_fn);
+ 	OFFSET(__LC_RESTART_DATA, _lowcore, restart_data);
+ 	OFFSET(__LC_RESTART_SOURCE, _lowcore, restart_source);
+ 	OFFSET(__LC_USER_ASCE, _lowcore, user_asce);
+ 	OFFSET(__LC_LPP, _lowcore, lpp);
+ 	OFFSET(__LC_CURRENT_PID, _lowcore, current_pid);
+ 	OFFSET(__LC_PERCPU_OFFSET, _lowcore, percpu_offset);
+ 	OFFSET(__LC_VDSO_PER_CPU, _lowcore, vdso_per_cpu_data);
+ 	OFFSET(__LC_MACHINE_FLAGS, _lowcore, machine_flags);
+ 	OFFSET(__LC_GMAP, _lowcore, gmap);
+ 	OFFSET(__LC_PASTE, _lowcore, paste);
+ 	/* software defined ABI-relevant lowcore locations 0xe00 - 0xe20 */
+ 	OFFSET(__LC_DUMP_REIPL, _lowcore, ipib);
+ 	/* hardware defined lowcore locations 0x1000 - 0x18ff */
+ 	OFFSET(__LC_VX_SAVE_AREA_ADDR, _lowcore, vector_save_area_addr);
+ 	OFFSET(__LC_EXT_PARAMS2, _lowcore, ext_params2);
+ 	OFFSET(SAVE_AREA_BASE, _lowcore, floating_pt_save_area);
+ 	OFFSET(__LC_FPREGS_SAVE_AREA, _lowcore, floating_pt_save_area);
+ 	OFFSET(__LC_GPREGS_SAVE_AREA, _lowcore, gpregs_save_area);
+ 	OFFSET(__LC_PSW_SAVE_AREA, _lowcore, psw_save_area);
+ 	OFFSET(__LC_PREFIX_SAVE_AREA, _lowcore, prefixreg_save_area);
+ 	OFFSET(__LC_FP_CREG_SAVE_AREA, _lowcore, fpt_creg_save_area);
+ 	OFFSET(__LC_CPU_TIMER_SAVE_AREA, _lowcore, cpu_timer_save_area);
+ 	OFFSET(__LC_CLOCK_COMP_SAVE_AREA, _lowcore, clock_comp_save_area);
+ 	OFFSET(__LC_AREGS_SAVE_AREA, _lowcore, access_regs_save_area);
+ 	OFFSET(__LC_CREGS_SAVE_AREA, _lowcore, cregs_save_area);
+ 	OFFSET(__LC_PGM_TDB, _lowcore, pgm_tdb);
++>>>>>>> e22cf8ca6f75 (s390/cpumf: rework program parameter setting to detect guest samples)
  	BLANK();
 -	/* gmap/sie offsets */
 -	OFFSET(__GMAP_ASCE, gmap, asce);
 -	OFFSET(__SIE_PROG0C, kvm_s390_sie_block, prog0c);
 -	OFFSET(__SIE_PROG20, kvm_s390_sie_block, prog20);
 +	DEFINE(__LC_CPU_TIMER_SAVE_AREA, offsetof(struct _lowcore, cpu_timer_save_area));
 +	DEFINE(__LC_CLOCK_COMP_SAVE_AREA, offsetof(struct _lowcore, clock_comp_save_area));
 +	DEFINE(__LC_PSW_SAVE_AREA, offsetof(struct _lowcore, psw_save_area));
 +	DEFINE(__LC_PREFIX_SAVE_AREA, offsetof(struct _lowcore, prefixreg_save_area));
 +	DEFINE(__LC_AREGS_SAVE_AREA, offsetof(struct _lowcore, access_regs_save_area));
 +	DEFINE(__LC_FPREGS_SAVE_AREA, offsetof(struct _lowcore, floating_pt_save_area));
 +	DEFINE(__LC_GPREGS_SAVE_AREA, offsetof(struct _lowcore, gpregs_save_area));
 +	DEFINE(__LC_CREGS_SAVE_AREA, offsetof(struct _lowcore, cregs_save_area));
 +#ifdef CONFIG_32BIT
 +	DEFINE(SAVE_AREA_BASE, offsetof(struct _lowcore, extended_save_area_addr));
 +#else /* CONFIG_32BIT */
 +	DEFINE(__LC_EXT_PARAMS2, offsetof(struct _lowcore, ext_params2));
 +	DEFINE(SAVE_AREA_BASE, offsetof(struct _lowcore, floating_pt_save_area));
 +	DEFINE(__LC_PASTE, offsetof(struct _lowcore, paste));
 +	DEFINE(__LC_FP_CREG_SAVE_AREA, offsetof(struct _lowcore, fpt_creg_save_area));
 +	DEFINE(__LC_LAST_BREAK, offsetof(struct _lowcore, breaking_event_addr));
 +	DEFINE(__LC_VDSO_PER_CPU, offsetof(struct _lowcore, vdso_per_cpu_data));
 +	DEFINE(__LC_GMAP, offsetof(struct _lowcore, gmap));
 +	DEFINE(__LC_PGM_TDB, offsetof(struct _lowcore, pgm_tdb));
 +	DEFINE(__THREAD_trap_tdb, offsetof(struct task_struct, thread.trap_tdb));
 +	DEFINE(__GMAP_ASCE, offsetof(struct gmap, asce));
 +	DEFINE(__SIE_PROG0C, offsetof(struct kvm_s390_sie_block, prog0c));
 +	DEFINE(__SIE_PROG20, offsetof(struct kvm_s390_sie_block, prog20));
 +#endif /* CONFIG_32BIT */
  	return 0;
  }
diff --cc arch/s390/kernel/entry.S
index 9fd2c1f12630,d653a87d66b5..000000000000
--- a/arch/s390/kernel/entry.S
+++ b/arch/s390/kernel/entry.S
@@@ -146,26 -172,85 +146,93 @@@ STACK_INIT  = STACK_SIZE - STACK_FRAME_
   *  gpr2 = prev
   */
  ENTRY(__switch_to)
 -	stmg	%r6,%r15,__SF_GPRS(%r15)	# store gprs of prev task
 -	lgr	%r1,%r2
 -	aghi	%r1,__TASK_thread		# thread_struct of prev task
 -	lg	%r4,__TASK_thread_info(%r2)	# get thread_info of prev
 -	lg	%r5,__TASK_thread_info(%r3)	# get thread_info of next
 -	stg	%r15,__THREAD_ksp(%r1)		# store kernel stack of prev
 -	lgr	%r1,%r3
 -	aghi	%r1,__TASK_thread		# thread_struct of next task
 -	lgr	%r15,%r5
 -	aghi	%r15,STACK_INIT			# end of kernel stack of next
 -	stg	%r3,__LC_CURRENT		# store task struct of next
 -	stg	%r5,__LC_THREAD_INFO		# store thread info of next
 -	stg	%r15,__LC_KERNEL_STACK		# store end of kernel stack
 -	lg	%r15,__THREAD_ksp(%r1)		# load kernel stack of next
 +	stm	%r6,%r15,__SF_GPRS(%r15)	# store gprs of prev task
 +	st	%r15,__THREAD_ksp(%r2)		# store kernel stack of prev
 +	l	%r4,__THREAD_info(%r2)		# get thread_info of prev
 +	l	%r5,__THREAD_info(%r3)		# get thread_info of next
 +	lr	%r15,%r5
 +	ahi	%r15,STACK_INIT			# end of kernel stack of next
 +	st	%r3,__LC_CURRENT		# store task struct of next
 +	st	%r5,__LC_THREAD_INFO		# store thread info of next
 +	st	%r15,__LC_KERNEL_STACK		# store end of kernel stack
  	lctl	%c4,%c4,__TASK_pid(%r3)		# load pid to control reg. 4
++<<<<<<< HEAD
 +	mvc	__LC_CURRENT_PID(4,%r0),__TASK_pid(%r3)	# store pid of next
 +	l	%r15,__THREAD_ksp(%r3)		# load kernel stack of next
 +	tm	__TI_flags+3(%r4),_TIF_MCCK_PENDING # machine check pending?
 +	jz	0f
 +	ni	__TI_flags+3(%r4),255-_TIF_MCCK_PENDING	# clear flag in prev
 +	oi	__TI_flags+3(%r5),_TIF_MCCK_PENDING	# set it in next
 +0:	lm	%r6,%r15,__SF_GPRS(%r15)	# load gprs of next task
 +	br	%r14
 +
 +__critical_start:
++=======
+ 	mvc	__LC_CURRENT_PID(4,%r0),__TASK_pid(%r3) # store pid of next
+ 	lmg	%r6,%r15,__SF_GPRS(%r15)	# load gprs of next task
+ 	TSTMSK	__LC_MACHINE_FLAGS,MACHINE_FLAG_LPP
+ 	bzr	%r14
+ 	.insn	s,0xb2800000,__LC_LPP		# set program parameter
+ 	br	%r14
+ 
+ .L__critical_start:
+ 
+ #if IS_ENABLED(CONFIG_KVM)
+ /*
+  * sie64a calling convention:
+  * %r2 pointer to sie control block
+  * %r3 guest register save area
+  */
+ ENTRY(sie64a)
+ 	stmg	%r6,%r14,__SF_GPRS(%r15)	# save kernel registers
+ 	stg	%r2,__SF_EMPTY(%r15)		# save control block pointer
+ 	stg	%r3,__SF_EMPTY+8(%r15)		# save guest register save area
+ 	xc	__SF_EMPTY+16(8,%r15),__SF_EMPTY+16(%r15) # reason code = 0
+ 	TSTMSK	__LC_CPU_FLAGS,_CIF_FPU		# load guest fp/vx registers ?
+ 	jno	.Lsie_load_guest_gprs
+ 	brasl	%r14,load_fpu_regs		# load guest fp/vx regs
+ .Lsie_load_guest_gprs:
+ 	lmg	%r0,%r13,0(%r3)			# load guest gprs 0-13
+ 	lg	%r14,__LC_GMAP			# get gmap pointer
+ 	ltgr	%r14,%r14
+ 	jz	.Lsie_gmap
+ 	lctlg	%c1,%c1,__GMAP_ASCE(%r14)	# load primary asce
+ .Lsie_gmap:
+ 	lg	%r14,__SF_EMPTY(%r15)		# get control block pointer
+ 	oi	__SIE_PROG0C+3(%r14),1		# we are going into SIE now
+ 	tm	__SIE_PROG20+3(%r14),3		# last exit...
+ 	jnz	.Lsie_skip
+ 	TSTMSK	__LC_CPU_FLAGS,_CIF_FPU
+ 	jo	.Lsie_skip			# exit if fp/vx regs changed
+ 	sie	0(%r14)
+ .Lsie_skip:
+ 	ni	__SIE_PROG0C+3(%r14),0xfe	# no longer in SIE
+ 	lctlg	%c1,%c1,__LC_USER_ASCE		# load primary asce
+ .Lsie_done:
+ # some program checks are suppressing. C code (e.g. do_protection_exception)
+ # will rewind the PSW by the ILC, which is 4 bytes in case of SIE. Other
+ # instructions between sie64a and .Lsie_done should not cause program
+ # interrupts. So lets use a nop (47 00 00 00) as a landing pad.
+ # See also .Lcleanup_sie
+ .Lrewind_pad:
+ 	nop	0
+ 	.globl sie_exit
+ sie_exit:
+ 	lg	%r14,__SF_EMPTY+8(%r15)		# load guest register save area
+ 	stmg	%r0,%r13,0(%r14)		# save guest gprs 0-13
+ 	lmg	%r6,%r14,__SF_GPRS(%r15)	# restore kernel registers
+ 	lg	%r2,__SF_EMPTY+16(%r15)		# return exit reason code
+ 	br	%r14
+ .Lsie_fault:
+ 	lghi	%r14,-EFAULT
+ 	stg	%r14,__SF_EMPTY+16(%r15)	# set exit reason code
+ 	j	sie_exit
+ 
+ 	EX_TABLE(.Lrewind_pad,.Lsie_fault)
+ 	EX_TABLE(sie_exit,.Lsie_fault)
+ #endif
+ 
++>>>>>>> e22cf8ca6f75 (s390/cpumf: rework program parameter setting to detect guest samples)
  /*
   * SVC interrupt handler routine. System calls are synchronous events and
   * are executed with interrupts enabled.
@@@ -701,19 -934,22 +768,28 @@@ mcck_panic
  # PSW restart interrupt handler
  #
  ENTRY(restart_int_handler)
++<<<<<<< HEAD
 +	st	%r15,__LC_SAVE_AREA_RESTART
 +	l	%r15,__LC_RESTART_STACK
 +	ahi	%r15,-__PT_SIZE			# create pt_regs on stack
++=======
+ 	TSTMSK	__LC_MACHINE_FLAGS,MACHINE_FLAG_LPP
+ 	jz	0f
+ 	.insn	s,0xb2800000,__LC_LPP
+ 0:	stg	%r15,__LC_SAVE_AREA_RESTART
+ 	lg	%r15,__LC_RESTART_STACK
+ 	aghi	%r15,-__PT_SIZE			# create pt_regs on stack
++>>>>>>> e22cf8ca6f75 (s390/cpumf: rework program parameter setting to detect guest samples)
  	xc	0(__PT_SIZE,%r15),0(%r15)
 -	stmg	%r0,%r14,__PT_R0(%r15)
 -	mvc	__PT_R15(8,%r15),__LC_SAVE_AREA_RESTART
 -	mvc	__PT_PSW(16,%r15),__LC_RST_OLD_PSW # store restart old psw
 -	aghi	%r15,-STACK_FRAME_OVERHEAD	# create stack frame on stack
 +	stm	%r0,%r14,__PT_R0(%r15)
 +	mvc	__PT_R15(4,%r15),__LC_SAVE_AREA_RESTART
 +	mvc	__PT_PSW(8,%r15),__LC_RST_OLD_PSW # store restart old psw
 +	ahi	%r15,-STACK_FRAME_OVERHEAD	# create stack frame on stack
  	xc	0(STACK_FRAME_OVERHEAD,%r15),0(%r15)
 -	lg	%r1,__LC_RESTART_FN		# load fn, parm & source cpu
 -	lg	%r2,__LC_RESTART_DATA
 -	lg	%r3,__LC_RESTART_SOURCE
 -	ltgr	%r3,%r3				# test source cpu address
 +	l	%r1,__LC_RESTART_FN		# load fn, parm & source cpu
 +	l	%r2,__LC_RESTART_DATA
 +	l	%r3,__LC_RESTART_SOURCE
 +	ltr	%r3,%r3				# test source cpu address
  	jm	1f				# negative -> skip source stop
  0:	sigp	%r4,%r3,SIGP_SENSE		# sigp sense to source cpu
  	brc	10,0b				# wait for status stored
@@@ -733,141 -969,179 +809,175 @@@
   * Setup a pt_regs so that show_trace can provide a good call trace.
   */
  stack_overflow:
 -	lg	%r15,__LC_PANIC_STACK	# change to panic stack
 +	l	%r15,__LC_PANIC_STACK	# change to panic stack
  	la	%r11,STACK_FRAME_OVERHEAD(%r15)
 -	stmg	%r0,%r7,__PT_R0(%r11)
 -	stmg	%r8,%r9,__PT_PSW(%r11)
 -	mvc	__PT_R8(64,%r11),0(%r14)
 -	stg	%r10,__PT_ORIG_GPR2(%r11) # store last break to orig_gpr2
 -	xc	__SF_BACKCHAIN(8,%r15),__SF_BACKCHAIN(%r15)
 -	lgr	%r2,%r11		# pass pointer to pt_regs
 -	jg	kernel_stack_overflow
 +	stm	%r0,%r7,__PT_R0(%r11)
 +	stm	%r8,%r9,__PT_PSW(%r11)
 +	mvc	__PT_R8(32,%r11),0(%r14)
 +	l	%r1,BASED(1f)
 +	xc	__SF_BACKCHAIN(4,%r15),__SF_BACKCHAIN(%r15)
 +	lr	%r2,%r11		# pass pointer to pt_regs
 +	br	%r1			# branch to kernel_stack_overflow
 +1:	.long	kernel_stack_overflow
  #endif
  
 +cleanup_table:
 +	.long	system_call + 0x80000000
 +	.long	sysc_do_svc + 0x80000000
 +	.long	sysc_tif + 0x80000000
 +	.long	sysc_restore + 0x80000000
 +	.long	sysc_done + 0x80000000
 +	.long	io_tif + 0x80000000
 +	.long	io_restore + 0x80000000
 +	.long	io_done + 0x80000000
 +	.long	psw_idle + 0x80000000
 +	.long	psw_idle_end + 0x80000000
 +
  cleanup_critical:
 -#if IS_ENABLED(CONFIG_KVM)
 -	clg	%r9,BASED(.Lcleanup_table_sie)	# .Lsie_gmap
 +	cl	%r9,BASED(cleanup_table)	# system_call
  	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table_sie+8)# .Lsie_done
 -	jl	.Lcleanup_sie
 -#endif
 -	clg	%r9,BASED(.Lcleanup_table)	# system_call
 -	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table+8)	# .Lsysc_do_svc
 -	jl	.Lcleanup_system_call
 -	clg	%r9,BASED(.Lcleanup_table+16)	# .Lsysc_tif
 -	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table+24)	# .Lsysc_restore
 -	jl	.Lcleanup_sysc_tif
 -	clg	%r9,BASED(.Lcleanup_table+32)	# .Lsysc_done
 -	jl	.Lcleanup_sysc_restore
 -	clg	%r9,BASED(.Lcleanup_table+40)	# .Lio_tif
 +	cl	%r9,BASED(cleanup_table+4)	# sysc_do_svc
 +	jl	cleanup_system_call
 +	cl	%r9,BASED(cleanup_table+8)	# sysc_tif
  	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table+48)	# .Lio_restore
 -	jl	.Lcleanup_io_tif
 -	clg	%r9,BASED(.Lcleanup_table+56)	# .Lio_done
 -	jl	.Lcleanup_io_restore
 -	clg	%r9,BASED(.Lcleanup_table+64)	# psw_idle
 +	cl	%r9,BASED(cleanup_table+12)	# sysc_restore
 +	jl	cleanup_sysc_tif
 +	cl	%r9,BASED(cleanup_table+16)	# sysc_done
 +	jl	cleanup_sysc_restore
 +	cl	%r9,BASED(cleanup_table+20)	# io_tif
  	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table+72)	# .Lpsw_idle_end
 -	jl	.Lcleanup_idle
 -	clg	%r9,BASED(.Lcleanup_table+80)	# save_fpu_regs
 +	cl	%r9,BASED(cleanup_table+24)	# io_restore
 +	jl	cleanup_io_tif
 +	cl	%r9,BASED(cleanup_table+28)	# io_done
 +	jl	cleanup_io_restore
 +	cl	%r9,BASED(cleanup_table+32)	# psw_idle
  	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table+88)	# .Lsave_fpu_regs_end
 -	jl	.Lcleanup_save_fpu_regs
 -	clg	%r9,BASED(.Lcleanup_table+96)	# load_fpu_regs
 -	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table+104)	# .Lload_fpu_regs_end
 -	jl	.Lcleanup_load_fpu_regs
 +	cl	%r9,BASED(cleanup_table+36)	# psw_idle_end
 +	jl	cleanup_idle
  0:	br	%r14
  
++<<<<<<< HEAD
 +cleanup_system_call:
++=======
+ 	.align	8
+ .Lcleanup_table:
+ 	.quad	system_call
+ 	.quad	.Lsysc_do_svc
+ 	.quad	.Lsysc_tif
+ 	.quad	.Lsysc_restore
+ 	.quad	.Lsysc_done
+ 	.quad	.Lio_tif
+ 	.quad	.Lio_restore
+ 	.quad	.Lio_done
+ 	.quad	psw_idle
+ 	.quad	.Lpsw_idle_end
+ 	.quad	save_fpu_regs
+ 	.quad	.Lsave_fpu_regs_end
+ 	.quad	load_fpu_regs
+ 	.quad	.Lload_fpu_regs_end
+ 
+ #if IS_ENABLED(CONFIG_KVM)
+ .Lcleanup_table_sie:
+ 	.quad	.Lsie_gmap
+ 	.quad	.Lsie_done
+ 
+ .Lcleanup_sie:
+ 	lg	%r9,__SF_EMPTY(%r15)		# get control block pointer
+ 	ni	__SIE_PROG0C+3(%r9),0xfe	# no longer in SIE
+ 	lctlg	%c1,%c1,__LC_USER_ASCE		# load primary asce
+ 	larl	%r9,sie_exit			# skip forward to sie_exit
+ 	br	%r14
+ #endif
+ 
+ .Lcleanup_system_call:
++>>>>>>> e22cf8ca6f75 (s390/cpumf: rework program parameter setting to detect guest samples)
  	# check if stpt has been executed
 -	clg	%r9,BASED(.Lcleanup_system_call_insn)
 +	cl	%r9,BASED(cleanup_system_call_insn)
  	jh	0f
  	mvc	__LC_SYNC_ENTER_TIMER(8),__LC_ASYNC_ENTER_TIMER
 -	cghi	%r11,__LC_SAVE_AREA_ASYNC
 +	chi	%r11,__LC_SAVE_AREA_ASYNC
  	je	0f
  	mvc	__LC_SYNC_ENTER_TIMER(8),__LC_MCCK_ENTER_TIMER
 -0:	# check if stmg has been executed
 -	clg	%r9,BASED(.Lcleanup_system_call_insn+8)
 +0:	# check if stm has been executed
 +	cl	%r9,BASED(cleanup_system_call_insn+4)
  	jh	0f
 -	mvc	__LC_SAVE_AREA_SYNC(64),0(%r11)
 -0:	# check if base register setup + TIF bit load has been done
 -	clg	%r9,BASED(.Lcleanup_system_call_insn+16)
 -	jhe	0f
 -	# set up saved registers r10 and r12
 -	stg	%r10,16(%r11)		# r10 last break
 -	stg	%r12,32(%r11)		# r12 thread-info pointer
 -0:	# check if the user time update has been done
 -	clg	%r9,BASED(.Lcleanup_system_call_insn+24)
 +	mvc	__LC_SAVE_AREA_SYNC(32),0(%r11)
 +0:	# set up saved registers r12, and r13
 +	st	%r12,16(%r11)		# r12 thread-info pointer
 +	st	%r13,20(%r11)		# r13 literal-pool pointer
 +	# check if the user time calculation has been done
 +	cl	%r9,BASED(cleanup_system_call_insn+8)
  	jh	0f
 -	lg	%r15,__LC_EXIT_TIMER
 -	slg	%r15,__LC_SYNC_ENTER_TIMER
 -	alg	%r15,__LC_USER_TIMER
 -	stg	%r15,__LC_USER_TIMER
 -0:	# check if the system time update has been done
 -	clg	%r9,BASED(.Lcleanup_system_call_insn+32)
 +	l	%r10,__LC_EXIT_TIMER
 +	l	%r15,__LC_EXIT_TIMER+4
 +	SUB64	%r10,%r15,__LC_SYNC_ENTER_TIMER
 +	ADD64	%r10,%r15,__LC_USER_TIMER
 +	st	%r10,__LC_USER_TIMER
 +	st	%r15,__LC_USER_TIMER+4
 +0:	# check if the system time calculation has been done
 +	cl	%r9,BASED(cleanup_system_call_insn+12)
  	jh	0f
 -	lg	%r15,__LC_LAST_UPDATE_TIMER
 -	slg	%r15,__LC_EXIT_TIMER
 -	alg	%r15,__LC_SYSTEM_TIMER
 -	stg	%r15,__LC_SYSTEM_TIMER
 +	l	%r10,__LC_LAST_UPDATE_TIMER
 +	l	%r15,__LC_LAST_UPDATE_TIMER+4
 +	SUB64	%r10,%r15,__LC_EXIT_TIMER
 +	ADD64	%r10,%r15,__LC_SYSTEM_TIMER
 +	st	%r10,__LC_SYSTEM_TIMER
 +	st	%r15,__LC_SYSTEM_TIMER+4
  0:	# update accounting time stamp
  	mvc	__LC_LAST_UPDATE_TIMER(8),__LC_SYNC_ENTER_TIMER
 -	# do LAST_BREAK
 -	lg	%r9,16(%r11)
 -	srag	%r9,%r9,23
 -	jz	0f
 -	mvc	__TI_last_break(8,%r12),16(%r11)
 -0:	# set up saved register r11
 -	lg	%r15,__LC_KERNEL_STACK
 +	# set up saved register 11
 +	l	%r15,__LC_KERNEL_STACK
  	la	%r9,STACK_FRAME_OVERHEAD(%r15)
 -	stg	%r9,24(%r11)		# r11 pt_regs pointer
 +	st	%r9,12(%r11)		# r11 pt_regs pointer
  	# fill pt_regs
 -	mvc	__PT_R8(64,%r9),__LC_SAVE_AREA_SYNC
 -	stmg	%r0,%r7,__PT_R0(%r9)
 -	mvc	__PT_PSW(16,%r9),__LC_SVC_OLD_PSW
 +	mvc	__PT_R8(32,%r9),__LC_SAVE_AREA_SYNC
 +	stm	%r0,%r7,__PT_R0(%r9)
 +	mvc	__PT_PSW(8,%r9),__LC_SVC_OLD_PSW
  	mvc	__PT_INT_CODE(4,%r9),__LC_SVC_ILC
 -	xc	__PT_FLAGS(8,%r9),__PT_FLAGS(%r9)
 -	mvi	__PT_FLAGS+7(%r9),_PIF_SYSCALL
 -	# setup saved register r15
 -	stg	%r15,56(%r11)		# r15 stack pointer
 +	# setup saved register 15
 +	st	%r15,28(%r11)		# r15 stack pointer
  	# set new psw address and exit
 -	larl	%r9,.Lsysc_do_svc
 +	l	%r9,BASED(cleanup_table+4)	# sysc_do_svc + 0x80000000
  	br	%r14
 -.Lcleanup_system_call_insn:
 -	.quad	system_call
 -	.quad	.Lsysc_stmg
 -	.quad	.Lsysc_per
 -	.quad	.Lsysc_vtime+36
 -	.quad	.Lsysc_vtime+42
 -
 -.Lcleanup_sysc_tif:
 -	larl	%r9,.Lsysc_tif
 +cleanup_system_call_insn:
 +	.long	system_call + 0x80000000
 +	.long	sysc_stm + 0x80000000
 +	.long	sysc_vtime + 0x80000000 + 36
 +	.long	sysc_vtime + 0x80000000 + 76
 +
 +cleanup_sysc_tif:
 +	l	%r9,BASED(cleanup_table+8)	# sysc_tif + 0x80000000
  	br	%r14
  
 -.Lcleanup_sysc_restore:
 -	clg	%r9,BASED(.Lcleanup_sysc_restore_insn)
 -	je	0f
 -	lg	%r9,24(%r11)		# get saved pointer to pt_regs
 -	mvc	__LC_RETURN_PSW(16),__PT_PSW(%r9)
 -	mvc	0(64,%r11),__PT_R8(%r9)
 -	lmg	%r0,%r7,__PT_R0(%r9)
 -0:	lmg	%r8,%r9,__LC_RETURN_PSW
 +cleanup_sysc_restore:
 +	cl	%r9,BASED(cleanup_sysc_restore_insn)
 +	jhe	0f
 +	l	%r9,12(%r11)		# get saved pointer to pt_regs
 +	mvc	__LC_RETURN_PSW(8),__PT_PSW(%r9)
 +	mvc	0(32,%r11),__PT_R8(%r9)
 +	lm	%r0,%r7,__PT_R0(%r9)
 +0:	lm	%r8,%r9,__LC_RETURN_PSW
  	br	%r14
 -.Lcleanup_sysc_restore_insn:
 -	.quad	.Lsysc_done - 4
 +cleanup_sysc_restore_insn:
 +	.long	sysc_done - 4 + 0x80000000
  
 -.Lcleanup_io_tif:
 -	larl	%r9,.Lio_tif
 +cleanup_io_tif:
 +	l	%r9,BASED(cleanup_table+20)	# io_tif + 0x80000000
  	br	%r14
  
 -.Lcleanup_io_restore:
 -	clg	%r9,BASED(.Lcleanup_io_restore_insn)
 -	je	0f
 -	lg	%r9,24(%r11)		# get saved r11 pointer to pt_regs
 -	mvc	__LC_RETURN_PSW(16),__PT_PSW(%r9)
 -	mvc	0(64,%r11),__PT_R8(%r9)
 -	lmg	%r0,%r7,__PT_R0(%r9)
 -0:	lmg	%r8,%r9,__LC_RETURN_PSW
 +cleanup_io_restore:
 +	cl	%r9,BASED(cleanup_io_restore_insn)
 +	jhe	0f
 +	l	%r9,12(%r11)		# get saved r11 pointer to pt_regs
 +	mvc	__LC_RETURN_PSW(8),__PT_PSW(%r9)
 +	mvc	0(32,%r11),__PT_R8(%r9)
 +	lm	%r0,%r7,__PT_R0(%r9)
 +0:	lm	%r8,%r9,__LC_RETURN_PSW
  	br	%r14
 -.Lcleanup_io_restore_insn:
 -	.quad	.Lio_done - 4
 +cleanup_io_restore_insn:
 +	.long	io_done - 4 + 0x80000000
  
 -.Lcleanup_idle:
 +cleanup_idle:
  	# copy interrupt clock & cpu timer
  	mvc	__CLOCK_IDLE_EXIT(8,%r2),__LC_INT_CLOCK
  	mvc	__TIMER_IDLE_EXIT(8,%r2),__LC_ASYNC_ENTER_TIMER
diff --cc arch/s390/kernel/perf_cpum_sf.c
index 3e71ee872319,3d8da1e742c2..000000000000
--- a/arch/s390/kernel/perf_cpum_sf.c
+++ b/arch/s390/kernel/perf_cpum_sf.c
@@@ -1021,14 -1019,13 +1021,22 @@@ static int perf_push_sample(struct perf
  		break;
  	}
  
++<<<<<<< HEAD
 +	/* The host-program-parameter (hpp) contains the sie control
 +	 * block that is set by sie64a() in entry64.S.	Check if hpp
 +	 * refers to a valid control block and set sde_regs flags
 +	 * accordingly.  This would allow to use hpp values for other
 +	 * purposes too.
 +	 * For now, simply use a non-zero value as guest indicator.
++=======
+ 	/*
+ 	 * A non-zero guest program parameter indicates a guest
+ 	 * sample.
+ 	 * Note that some early samples might be misaccounted to
+ 	 * the host.
++>>>>>>> e22cf8ca6f75 (s390/cpumf: rework program parameter setting to detect guest samples)
  	 */
- 	if (sfr->basic.hpp)
+ 	if (sfr->basic.gpp)
  		sde_regs->in_guest = 1;
  
  	overflow = 0;
diff --cc arch/s390/mm/fault.c
index f93e6c2d4ba5,ec1a30d0d11a..000000000000
--- a/arch/s390/mm/fault.c
+++ b/arch/s390/mm/fault.c
@@@ -515,7 -649,7 +515,11 @@@ static void pfault_interrupt(struct ext
  		return;
  	inc_irq_stat(IRQEXT_PFL);
  	/* Get the token (= pid of the affected task). */
++<<<<<<< HEAD
 +	pid = sizeof(void *) == 4 ? param32 : param64;
++=======
+ 	pid = param64 & LPP_PFAULT_PID_MASK;
++>>>>>>> e22cf8ca6f75 (s390/cpumf: rework program parameter setting to detect guest samples)
  	rcu_read_lock();
  	tsk = find_task_by_pid_ns(pid, &init_pid_ns);
  	if (tsk)
diff --git a/arch/s390/include/asm/lowcore.h b/arch/s390/include/asm/lowcore.h
index 8ff54ce7864b..46d885094acd 100644
--- a/arch/s390/include/asm/lowcore.h
+++ b/arch/s390/include/asm/lowcore.h
@@ -286,7 +286,14 @@ struct _lowcore {
 	/* Address space pointer. */
 	__u64	kernel_asce;			/* 0x0358 */
 	__u64	user_asce;			/* 0x0360 */
-	__u64	current_pid;			/* 0x0368 */
+
+	/*
+	 * The lpp and current_pid fields form a
+	 * 64-bit value that is set as program
+	 * parameter with the LPP instruction.
+	 */
+	__u32	lpp;				/* 0x0368 */
+	__u32	current_pid;			/* 0x036c */
 
 	/* SMP info area */
 	__u32	cpu_nr;				/* 0x0370 */
diff --git a/arch/s390/include/asm/setup.h b/arch/s390/include/asm/setup.h
index 8fd5fb472082..d2f2186ab488 100644
--- a/arch/s390/include/asm/setup.h
+++ b/arch/s390/include/asm/setup.h
@@ -11,6 +11,9 @@
 #define PARMAREA		0x10400
 #define MEMORY_CHUNKS		256
 
+#define LPP_MAGIC		_BITUL(31)
+#define LPP_PFAULT_PID_MASK	_AC(0xffffffff, UL)
+
 #ifndef __ASSEMBLY__
 
 #include <asm/lowcore.h>
* Unmerged path arch/s390/kernel/asm-offsets.c
* Unmerged path arch/s390/kernel/entry.S
diff --git a/arch/s390/kernel/head64.S b/arch/s390/kernel/head64.S
index d7c00507568a..58b719fa8067 100644
--- a/arch/s390/kernel/head64.S
+++ b/arch/s390/kernel/head64.S
@@ -16,7 +16,12 @@
 
 __HEAD
 ENTRY(startup_continue)
-	larl	%r1,sched_clock_base_cc
+	tm	__LC_STFL_FAC_LIST+6,0x80	# LPP available ?
+	jz	0f
+	xc	__LC_LPP+1(7,0),__LC_LPP+1	# clear lpp and current_pid
+	mvi	__LC_LPP,0x80			#   and set LPP_MAGIC
+	.insn	s,0xb2800000,__LC_LPP		# load program parameter
+0:	larl	%r1,sched_clock_base_cc
 	mvc	0(8,%r1),__LC_LAST_UPDATE_CLOCK
 	larl	%r13,.LPG1		# get base
 	lctlg	%c0,%c15,.Lctl-.LPG1(%r13)	# load control registers
* Unmerged path arch/s390/kernel/perf_cpum_sf.c
diff --git a/arch/s390/kernel/smp.c b/arch/s390/kernel/smp.c
index e56ebcc4023c..c7ff1e24e257 100644
--- a/arch/s390/kernel/smp.c
+++ b/arch/s390/kernel/smp.c
@@ -287,6 +287,8 @@ static void pcpu_attach_task(struct pcpu *pcpu, struct task_struct *tsk)
 		+ THREAD_SIZE - STACK_FRAME_OVERHEAD - sizeof(struct pt_regs);
 	lc->thread_info = (unsigned long) task_thread_info(tsk);
 	lc->current_task = (unsigned long) tsk;
+	lc->lpp = LPP_MAGIC;
+	lc->current_pid = tsk->pid;
 	lc->user_timer = ti->user_timer;
 	lc->system_timer = ti->system_timer;
 	lc->steal_timer = 0;
* Unmerged path arch/s390/mm/fault.c
