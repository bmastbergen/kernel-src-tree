drm/i915: Move CRTC updating in atomic_commit into it's own hook

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [drm] i915: Move CRTC updating in atomic_commit into it's own hook (Lyude Paul) [1341633 1355776]
Rebuild_FUZZ: 96.77%
commit-author Lyude <cpaul@redhat.com>
commit 896e5bb022bce64e29ce2e1b2fc2a7476d311a15
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/896e5bb0.failed

Since we have to write ddb allocations at the same time as we do other
plane updates, we're going to need to be able to control the order in
which we execute modesets on each pipe. The easiest way to do this is to
just factor this section of intel_atomic_commit_tail()
(intel_atomic_commit() for stable branches) into it's own function, and
add an appropriate display function hook for it.

Based off of Matt Rope's suggestions

Changes since v1:
 - Drop pipe_config->base.active check in intel_update_crtcs() since we
   check that before calling the function

	Signed-off-by: Lyude <cpaul@redhat.com>
	Reviewed-by: Matt Roper <matthew.d.roper@intel.com>
[omitting CC for stable, since this patch will need to be changed for
such backports first]
	Cc: Ville Syrjälä <ville.syrjala@linux.intel.com>
	Cc: Daniel Vetter <daniel.vetter@intel.com>
	Cc: Radhakrishna Sripada <radhakrishna.sripada@intel.com>
	Cc: Hans de Goede <hdegoede@redhat.com>

	Signed-off-by: Lyude <cpaul@redhat.com>
	Signed-off-by: Maarten Lankhorst <maarten.lankhorst@linux.intel.com>
Link: http://patchwork.freedesktop.org/patch/msgid/1471961565-28540-1-git-send-email-cpaul@redhat.com
(cherry picked from commit 896e5bb022bce64e29ce2e1b2fc2a7476d311a15)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/i915/i915_drv.h
#	drivers/gpu/drm/i915/intel_display.c
diff --cc drivers/gpu/drm/i915/i915_drv.h
index f691be6f9546,04b4fd6c32e4..000000000000
--- a/drivers/gpu/drm/i915/i915_drv.h
+++ b/drivers/gpu/drm/i915/i915_drv.h
@@@ -407,6 -481,234 +407,237 @@@ struct sdvo_device_mapping 
  	u8 ddc_pin;
  };
  
++<<<<<<< HEAD
++=======
+ struct intel_connector;
+ struct intel_encoder;
+ struct intel_crtc_state;
+ struct intel_initial_plane_config;
+ struct intel_crtc;
+ struct intel_limit;
+ struct dpll;
+ 
+ struct drm_i915_display_funcs {
+ 	int (*get_display_clock_speed)(struct drm_device *dev);
+ 	int (*get_fifo_size)(struct drm_device *dev, int plane);
+ 	int (*compute_pipe_wm)(struct intel_crtc_state *cstate);
+ 	int (*compute_intermediate_wm)(struct drm_device *dev,
+ 				       struct intel_crtc *intel_crtc,
+ 				       struct intel_crtc_state *newstate);
+ 	void (*initial_watermarks)(struct intel_crtc_state *cstate);
+ 	void (*optimize_watermarks)(struct intel_crtc_state *cstate);
+ 	int (*compute_global_watermarks)(struct drm_atomic_state *state);
+ 	void (*update_wm)(struct drm_crtc *crtc);
+ 	int (*modeset_calc_cdclk)(struct drm_atomic_state *state);
+ 	void (*modeset_commit_cdclk)(struct drm_atomic_state *state);
+ 	/* Returns the active state of the crtc, and if the crtc is active,
+ 	 * fills out the pipe-config with the hw state. */
+ 	bool (*get_pipe_config)(struct intel_crtc *,
+ 				struct intel_crtc_state *);
+ 	void (*get_initial_plane_config)(struct intel_crtc *,
+ 					 struct intel_initial_plane_config *);
+ 	int (*crtc_compute_clock)(struct intel_crtc *crtc,
+ 				  struct intel_crtc_state *crtc_state);
+ 	void (*crtc_enable)(struct intel_crtc_state *pipe_config,
+ 			    struct drm_atomic_state *old_state);
+ 	void (*crtc_disable)(struct intel_crtc_state *old_crtc_state,
+ 			     struct drm_atomic_state *old_state);
+ 	void (*update_crtcs)(struct drm_atomic_state *state,
+ 			     unsigned int *crtc_vblank_mask);
+ 	void (*audio_codec_enable)(struct drm_connector *connector,
+ 				   struct intel_encoder *encoder,
+ 				   const struct drm_display_mode *adjusted_mode);
+ 	void (*audio_codec_disable)(struct intel_encoder *encoder);
+ 	void (*fdi_link_train)(struct drm_crtc *crtc);
+ 	void (*init_clock_gating)(struct drm_device *dev);
+ 	int (*queue_flip)(struct drm_device *dev, struct drm_crtc *crtc,
+ 			  struct drm_framebuffer *fb,
+ 			  struct drm_i915_gem_object *obj,
+ 			  struct drm_i915_gem_request *req,
+ 			  uint32_t flags);
+ 	void (*hpd_irq_setup)(struct drm_i915_private *dev_priv);
+ 	/* clock updates for mode set */
+ 	/* cursor updates */
+ 	/* render clock increase/decrease */
+ 	/* display clock increase/decrease */
+ 	/* pll clock increase/decrease */
+ 
+ 	void (*load_csc_matrix)(struct drm_crtc_state *crtc_state);
+ 	void (*load_luts)(struct drm_crtc_state *crtc_state);
+ };
+ 
+ enum forcewake_domain_id {
+ 	FW_DOMAIN_ID_RENDER = 0,
+ 	FW_DOMAIN_ID_BLITTER,
+ 	FW_DOMAIN_ID_MEDIA,
+ 
+ 	FW_DOMAIN_ID_COUNT
+ };
+ 
+ enum forcewake_domains {
+ 	FORCEWAKE_RENDER = (1 << FW_DOMAIN_ID_RENDER),
+ 	FORCEWAKE_BLITTER = (1 << FW_DOMAIN_ID_BLITTER),
+ 	FORCEWAKE_MEDIA	= (1 << FW_DOMAIN_ID_MEDIA),
+ 	FORCEWAKE_ALL = (FORCEWAKE_RENDER |
+ 			 FORCEWAKE_BLITTER |
+ 			 FORCEWAKE_MEDIA)
+ };
+ 
+ #define FW_REG_READ  (1)
+ #define FW_REG_WRITE (2)
+ 
+ enum forcewake_domains
+ intel_uncore_forcewake_for_reg(struct drm_i915_private *dev_priv,
+ 			       i915_reg_t reg, unsigned int op);
+ 
+ struct intel_uncore_funcs {
+ 	void (*force_wake_get)(struct drm_i915_private *dev_priv,
+ 							enum forcewake_domains domains);
+ 	void (*force_wake_put)(struct drm_i915_private *dev_priv,
+ 							enum forcewake_domains domains);
+ 
+ 	uint8_t  (*mmio_readb)(struct drm_i915_private *dev_priv, i915_reg_t r, bool trace);
+ 	uint16_t (*mmio_readw)(struct drm_i915_private *dev_priv, i915_reg_t r, bool trace);
+ 	uint32_t (*mmio_readl)(struct drm_i915_private *dev_priv, i915_reg_t r, bool trace);
+ 	uint64_t (*mmio_readq)(struct drm_i915_private *dev_priv, i915_reg_t r, bool trace);
+ 
+ 	void (*mmio_writeb)(struct drm_i915_private *dev_priv, i915_reg_t r,
+ 				uint8_t val, bool trace);
+ 	void (*mmio_writew)(struct drm_i915_private *dev_priv, i915_reg_t r,
+ 				uint16_t val, bool trace);
+ 	void (*mmio_writel)(struct drm_i915_private *dev_priv, i915_reg_t r,
+ 				uint32_t val, bool trace);
+ 	void (*mmio_writeq)(struct drm_i915_private *dev_priv, i915_reg_t r,
+ 				uint64_t val, bool trace);
+ };
+ 
+ struct intel_uncore {
+ 	spinlock_t lock; /** lock is also taken in irq contexts. */
+ 
+ 	struct intel_uncore_funcs funcs;
+ 
+ 	unsigned fifo_count;
+ 	enum forcewake_domains fw_domains;
+ 
+ 	struct intel_uncore_forcewake_domain {
+ 		struct drm_i915_private *i915;
+ 		enum forcewake_domain_id id;
+ 		enum forcewake_domains mask;
+ 		unsigned wake_count;
+ 		struct hrtimer timer;
+ 		i915_reg_t reg_set;
+ 		u32 val_set;
+ 		u32 val_clear;
+ 		i915_reg_t reg_ack;
+ 		i915_reg_t reg_post;
+ 		u32 val_reset;
+ 	} fw_domain[FW_DOMAIN_ID_COUNT];
+ 
+ 	int unclaimed_mmio_check;
+ };
+ 
+ /* Iterate over initialised fw domains */
+ #define for_each_fw_domain_masked(domain__, mask__, dev_priv__) \
+ 	for ((domain__) = &(dev_priv__)->uncore.fw_domain[0]; \
+ 	     (domain__) < &(dev_priv__)->uncore.fw_domain[FW_DOMAIN_ID_COUNT]; \
+ 	     (domain__)++) \
+ 		for_each_if ((mask__) & (domain__)->mask)
+ 
+ #define for_each_fw_domain(domain__, dev_priv__) \
+ 	for_each_fw_domain_masked(domain__, FORCEWAKE_ALL, dev_priv__)
+ 
+ #define CSR_VERSION(major, minor)	((major) << 16 | (minor))
+ #define CSR_VERSION_MAJOR(version)	((version) >> 16)
+ #define CSR_VERSION_MINOR(version)	((version) & 0xffff)
+ 
+ struct intel_csr {
+ 	struct work_struct work;
+ 	const char *fw_path;
+ 	uint32_t *dmc_payload;
+ 	uint32_t dmc_fw_size;
+ 	uint32_t version;
+ 	uint32_t mmio_count;
+ 	i915_reg_t mmioaddr[8];
+ 	uint32_t mmiodata[8];
+ 	uint32_t dc_state;
+ 	uint32_t allowed_dc_mask;
+ };
+ 
+ #define DEV_INFO_FOR_EACH_FLAG(func, sep) \
+ 	func(is_mobile) sep \
+ 	func(is_i85x) sep \
+ 	func(is_i915g) sep \
+ 	func(is_i945gm) sep \
+ 	func(is_g33) sep \
+ 	func(need_gfx_hws) sep \
+ 	func(is_g4x) sep \
+ 	func(is_pineview) sep \
+ 	func(is_broadwater) sep \
+ 	func(is_crestline) sep \
+ 	func(is_ivybridge) sep \
+ 	func(is_valleyview) sep \
+ 	func(is_cherryview) sep \
+ 	func(is_haswell) sep \
+ 	func(is_broadwell) sep \
+ 	func(is_skylake) sep \
+ 	func(is_broxton) sep \
+ 	func(is_kabylake) sep \
+ 	func(is_preliminary) sep \
+ 	func(has_fbc) sep \
+ 	func(has_pipe_cxsr) sep \
+ 	func(has_hotplug) sep \
+ 	func(cursor_needs_physical) sep \
+ 	func(has_overlay) sep \
+ 	func(overlay_needs_physical) sep \
+ 	func(supports_tv) sep \
+ 	func(has_llc) sep \
+ 	func(has_snoop) sep \
+ 	func(has_ddi) sep \
+ 	func(has_fpga_dbg) sep \
+ 	func(has_pooled_eu)
+ 
+ #define DEFINE_FLAG(name) u8 name:1
+ #define SEP_SEMICOLON ;
+ 
+ struct intel_device_info {
+ 	u32 display_mmio_offset;
+ 	u16 device_id;
+ 	u8 num_pipes;
+ 	u8 num_sprites[I915_MAX_PIPES];
+ 	u8 gen;
+ 	u16 gen_mask;
+ 	u8 ring_mask; /* Rings supported by the HW */
+ 	u8 num_rings;
+ 	DEV_INFO_FOR_EACH_FLAG(DEFINE_FLAG, SEP_SEMICOLON);
+ 	/* Register offsets for the various display pipes and transcoders */
+ 	int pipe_offsets[I915_MAX_TRANSCODERS];
+ 	int trans_offsets[I915_MAX_TRANSCODERS];
+ 	int palette_offsets[I915_MAX_PIPES];
+ 	int cursor_offsets[I915_MAX_PIPES];
+ 
+ 	/* Slice/subslice/EU info */
+ 	u8 slice_total;
+ 	u8 subslice_total;
+ 	u8 subslice_per_slice;
+ 	u8 eu_total;
+ 	u8 eu_per_subslice;
+ 	u8 min_eu_in_pool;
+ 	/* For each slice, which subslice(s) has(have) 7 EUs (bitfield)? */
+ 	u8 subslice_7eu[3];
+ 	u8 has_slice_pg:1;
+ 	u8 has_subslice_pg:1;
+ 	u8 has_eu_pg:1;
+ 
+ 	struct color_luts {
+ 		u16 degamma_lut_size;
+ 		u16 gamma_lut_size;
+ 	} color;
+ };
+ 
+ #undef DEFINE_FLAG
+ #undef SEP_SEMICOLON
+ 
++>>>>>>> 896e5bb022bc (drm/i915: Move CRTC updating in atomic_commit into it's own hook)
  struct intel_display_error_state;
  
  struct drm_i915_error_state {
diff --cc drivers/gpu/drm/i915/intel_display.c
index 0caacf8c3858,30372f9fcf66..000000000000
--- a/drivers/gpu/drm/i915/intel_display.c
+++ b/drivers/gpu/drm/i915/intel_display.c
@@@ -11614,860 -14095,478 +11614,1070 @@@ static int __intel_set_mode_setup_plls(
  		}
  	}
  
 -	return ret;
 -}
 -
 -u32 intel_crtc_get_vblank_counter(struct intel_crtc *crtc)
 -{
 -	struct drm_device *dev = crtc->base.dev;
 -
 -	if (!dev->max_vblank_count)
 -		return drm_accurate_vblank_count(&crtc->base);
 -
 -	return dev->driver->get_vblank_counter(dev, crtc->pipe);
 +done:
 +	return ret;
  }
  
 -static void intel_atomic_wait_for_vblanks(struct drm_device *dev,
 -					  struct drm_i915_private *dev_priv,
 -					  unsigned crtc_mask)
 +static int __intel_set_mode(struct drm_crtc *crtc,
 +			    struct drm_display_mode *mode,
 +			    int x, int y, struct drm_framebuffer *fb,
 +			    struct intel_crtc_state *pipe_config,
 +			    unsigned modeset_pipes,
 +			    unsigned prepare_pipes,
 +			    unsigned disable_pipes)
  {
 -	unsigned last_vblank_count[I915_MAX_PIPES];
 -	enum pipe pipe;
 -	int ret;
 -
 -	if (!crtc_mask)
 -		return;
 -
 -	for_each_pipe(dev_priv, pipe) {
 -		struct drm_crtc *crtc = dev_priv->pipe_to_crtc_mapping[pipe];
 -
 -		if (!((1 << pipe) & crtc_mask))
 -			continue;
 +	struct drm_device *dev = crtc->dev;
 +	struct drm_i915_private *dev_priv = dev->dev_private;
 +	struct drm_display_mode *saved_mode;
 +	struct intel_crtc_state *crtc_state_copy = NULL;
 +	struct intel_crtc *intel_crtc;
 +	int ret = 0;
  
 -		ret = drm_crtc_vblank_get(crtc);
 -		if (WARN_ON(ret != 0)) {
 -			crtc_mask &= ~(1 << pipe);
 -			continue;
 -		}
 +	saved_mode = kmalloc(sizeof(*saved_mode), GFP_KERNEL);
 +	if (!saved_mode)
 +		return -ENOMEM;
  
 -		last_vblank_count[pipe] = drm_crtc_vblank_count(crtc);
 +	crtc_state_copy = kmalloc(sizeof(*crtc_state_copy), GFP_KERNEL);
 +	if (!crtc_state_copy) {
 +		ret = -ENOMEM;
 +		goto done;
  	}
  
 -	for_each_pipe(dev_priv, pipe) {
 -		struct drm_crtc *crtc = dev_priv->pipe_to_crtc_mapping[pipe];
 -		long lret;
 -
 -		if (!((1 << pipe) & crtc_mask))
 -			continue;
 +	*saved_mode = crtc->mode;
  
 -		lret = wait_event_timeout(dev->vblank[pipe].queue,
 -				last_vblank_count[pipe] !=
 -					drm_crtc_vblank_count(crtc),
 -				msecs_to_jiffies(50));
 +	if (modeset_pipes)
 +		to_intel_crtc(crtc)->new_config = pipe_config;
  
 -		WARN(!lret, "pipe %c vblank wait timed out\n", pipe_name(pipe));
 +	/*
 +	 * See if the config requires any additional preparation, e.g.
 +	 * to adjust global state with pipes off.  We need to do this
 +	 * here so we can get the modeset_pipe updated config for the new
 +	 * mode set on this crtc.  For other crtcs we need to use the
 +	 * adjusted_mode bits in the crtc directly.
 +	 */
 +	if (IS_VALLEYVIEW(dev)) {
 +		valleyview_modeset_global_pipes(dev, &prepare_pipes);
  
 -		drm_crtc_vblank_put(crtc);
 +		/* may have added more to prepare_pipes than we should */
 +		prepare_pipes &= ~disable_pipes;
  	}
 -}
  
 -static bool needs_vblank_wait(struct intel_crtc_state *crtc_state)
 -{
 -	/* fb updated, need to unpin old fb */
 -	if (crtc_state->fb_changed)
 -		return true;
 +	ret = __intel_set_mode_setup_plls(dev, modeset_pipes, disable_pipes);
 +	if (ret)
 +		goto done;
  
 -	/* wm changes, need vblank before final wm's */
 -	if (crtc_state->update_wm_post)
 -		return true;
 +	for_each_intel_crtc_masked(dev, disable_pipes, intel_crtc)
 +		intel_crtc_disable(&intel_crtc->base);
  
 -	/*
 -	 * cxsr is re-enabled after vblank.
 -	 * This is already handled by crtc_state->update_wm_post,
 -	 * but added for clarity.
 +	for_each_intel_crtc_masked(dev, prepare_pipes, intel_crtc) {
 +		if (intel_crtc->base.state->enable)
 +			dev_priv->display.crtc_disable(&intel_crtc->base);
 +	}
 +
 +	/* crtc->mode is already used by the ->mode_set callbacks, hence we need
 +	 * to set it here already despite that we pass it down the callchain.
 +	 *
 +	 * Note we'll need to fix this up when we start tracking multiple
 +	 * pipes; here we assume a single modeset_pipe and only track the
 +	 * single crtc and mode.
  	 */
 -	if (crtc_state->disable_cxsr)
 -		return true;
 +	if (modeset_pipes) {
 +		crtc->mode = *mode;
 +		/* mode_set/enable/disable functions rely on a correct pipe
 +		 * config. */
 +		intel_crtc_set_state(to_intel_crtc(crtc), pipe_config);
  
++<<<<<<< HEAD
 +		/*
 +		 * Calculate and store various constants which
 +		 * are later needed by vblank and swap-completion
 +		 * timestamping. They are derived from true hwmode.
 +		 */
 +		drm_calc_timestamping_constants(crtc,
 +						&pipe_config->base.adjusted_mode);
++=======
+ 	return false;
+ }
+ 
+ static void intel_update_crtc(struct drm_crtc *crtc,
+ 			      struct drm_atomic_state *state,
+ 			      struct drm_crtc_state *old_crtc_state,
+ 			      unsigned int *crtc_vblank_mask)
+ {
+ 	struct drm_device *dev = crtc->dev;
+ 	struct drm_i915_private *dev_priv = to_i915(dev);
+ 	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
+ 	struct intel_crtc_state *pipe_config = to_intel_crtc_state(crtc->state);
+ 	bool modeset = needs_modeset(crtc->state);
+ 
+ 	if (modeset) {
+ 		update_scanline_offset(intel_crtc);
+ 		dev_priv->display.crtc_enable(pipe_config, state);
+ 	} else {
+ 		intel_pre_plane_update(to_intel_crtc_state(old_crtc_state));
+ 	}
+ 
+ 	if (drm_atomic_get_existing_plane_state(state, crtc->primary)) {
+ 		intel_fbc_enable(
+ 		    intel_crtc, pipe_config,
+ 		    to_intel_plane_state(crtc->primary->state));
+ 	}
+ 
+ 	drm_atomic_helper_commit_planes_on_crtc(old_crtc_state);
+ 
+ 	if (needs_vblank_wait(pipe_config))
+ 		*crtc_vblank_mask |= drm_crtc_mask(crtc);
+ }
+ 
+ static void intel_update_crtcs(struct drm_atomic_state *state,
+ 			       unsigned int *crtc_vblank_mask)
+ {
+ 	struct drm_crtc *crtc;
+ 	struct drm_crtc_state *old_crtc_state;
+ 	int i;
+ 
+ 	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
+ 		if (!crtc->state->active)
+ 			continue;
+ 
+ 		intel_update_crtc(crtc, state, old_crtc_state,
+ 				  crtc_vblank_mask);
+ 	}
+ }
+ 
+ static void intel_atomic_commit_tail(struct drm_atomic_state *state)
+ {
+ 	struct drm_device *dev = state->dev;
+ 	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
+ 	struct drm_i915_private *dev_priv = to_i915(dev);
+ 	struct drm_crtc_state *old_crtc_state;
+ 	struct drm_crtc *crtc;
+ 	struct intel_crtc_state *intel_cstate;
+ 	struct drm_plane *plane;
+ 	struct drm_plane_state *plane_state;
+ 	bool hw_check = intel_state->modeset;
+ 	unsigned long put_domains[I915_MAX_PIPES] = {};
+ 	unsigned crtc_vblank_mask = 0;
+ 	int i, ret;
+ 
+ 	for_each_plane_in_state(state, plane, plane_state, i) {
+ 		struct intel_plane_state *intel_plane_state =
+ 			to_intel_plane_state(plane_state);
+ 
+ 		if (!intel_plane_state->wait_req)
+ 			continue;
+ 
+ 		ret = i915_wait_request(intel_plane_state->wait_req,
+ 					true, NULL, NULL);
+ 		/* EIO should be eaten, and we can't get interrupted in the
+ 		 * worker, and blocking commits have waited already. */
+ 		WARN_ON(ret);
+ 	}
+ 
+ 	drm_atomic_helper_wait_for_dependencies(state);
+ 
+ 	if (intel_state->modeset) {
+ 		memcpy(dev_priv->min_pixclk, intel_state->min_pixclk,
+ 		       sizeof(intel_state->min_pixclk));
+ 		dev_priv->active_crtcs = intel_state->active_crtcs;
+ 		dev_priv->atomic_cdclk_freq = intel_state->cdclk;
+ 
+ 		intel_display_power_get(dev_priv, POWER_DOMAIN_MODESET);
+ 	}
+ 
+ 	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
+ 		struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
+ 
+ 		if (needs_modeset(crtc->state) ||
+ 		    to_intel_crtc_state(crtc->state)->update_pipe) {
+ 			hw_check = true;
+ 
+ 			put_domains[to_intel_crtc(crtc)->pipe] =
+ 				modeset_get_crtc_power_domains(crtc,
+ 					to_intel_crtc_state(crtc->state));
+ 		}
+ 
+ 		if (!needs_modeset(crtc->state))
+ 			continue;
+ 
+ 		intel_pre_plane_update(to_intel_crtc_state(old_crtc_state));
+ 
+ 		if (old_crtc_state->active) {
+ 			intel_crtc_disable_planes(crtc, old_crtc_state->plane_mask);
+ 			dev_priv->display.crtc_disable(to_intel_crtc_state(old_crtc_state), state);
+ 			intel_crtc->active = false;
+ 			intel_fbc_disable(intel_crtc);
+ 			intel_disable_shared_dpll(intel_crtc);
+ 
+ 			/*
+ 			 * Underruns don't always raise
+ 			 * interrupts, so check manually.
+ 			 */
+ 			intel_check_cpu_fifo_underruns(dev_priv);
+ 			intel_check_pch_fifo_underruns(dev_priv);
+ 
+ 			if (!crtc->state->active)
+ 				intel_update_watermarks(crtc);
+ 		}
++>>>>>>> 896e5bb022bc (drm/i915: Move CRTC updating in atomic_commit into it's own hook)
  	}
  
  	/* Only after disabling all output pipelines that will be changed can we
  	 * update the the output configuration. */
 -	intel_modeset_update_crtc_state(state);
 +	intel_modeset_update_state(dev, prepare_pipes);
  
 -	if (intel_state->modeset) {
 -		drm_atomic_helper_update_legacy_modeset_state(state->dev, state);
 +	modeset_update_crtc_power_domains(pipe_config->base.state);
  
 -		if (dev_priv->display.modeset_commit_cdclk &&
 -		    (intel_state->dev_cdclk != dev_priv->cdclk_freq ||
 -		     intel_state->cdclk_pll_vco != dev_priv->cdclk_pll.vco))
 -			dev_priv->display.modeset_commit_cdclk(state);
 +	/* Set up the DPLL and any encoders state that needs to adjust or depend
 +	 * on the DPLL.
 +	 */
 +	for_each_intel_crtc_masked(dev, modeset_pipes, intel_crtc) {
 +		struct drm_plane *primary = intel_crtc->base.primary;
 +		int vdisplay, hdisplay;
  
 -		/*
 -		 * SKL workaround: bspec recommends we disable the SAGV when we
 -		 * have more then one pipe enabled
 -		 */
 -		if (IS_SKYLAKE(dev_priv) && !skl_can_enable_sagv(state))
 -			skl_disable_sagv(dev_priv);
 +		drm_crtc_get_hv_timing(mode, &hdisplay, &vdisplay);
 +		ret = primary->funcs->update_plane(primary, &intel_crtc->base,
 +						   fb, 0, 0,
 +						   hdisplay, vdisplay,
 +						   x << 16, y << 16,
 +						   hdisplay << 16, vdisplay << 16);
 +	}
 +
++<<<<<<< HEAD
 +	/* Now enable the clocks, plane, pipe, and connectors that we set up. */
 +	for_each_intel_crtc_masked(dev, prepare_pipes, intel_crtc) {
 +		update_scanline_offset(intel_crtc);
  
 -		intel_modeset_verify_disabled(dev);
 +		dev_priv->display.crtc_enable(&intel_crtc->base);
  	}
  
 +	/* FIXME: add subpixel order */
 +done:
 +	if (ret && crtc->state->enable)
 +		crtc->mode = *saved_mode;
 +
 +	if (ret == 0 && pipe_config) {
 +		struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 +
 +		/* The pipe_config will be freed with the atomic state, so
 +		 * make a copy. */
 +		memcpy(crtc_state_copy, intel_crtc->config,
 +		       sizeof *crtc_state_copy);
 +		intel_crtc->config = crtc_state_copy;
 +		intel_crtc->base.state = &crtc_state_copy->base;
 +
 +		if (modeset_pipes)
 +			intel_crtc->new_config = intel_crtc->config;
 +	} else {
 +		kfree(crtc_state_copy);
 +	}
 +
 +	kfree(saved_mode);
 +	return ret;
++=======
+ 	/* Complete the events for pipes that have now been disabled */
+ 	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
+ 		bool modeset = needs_modeset(crtc->state);
+ 
+ 		/* Complete events for now disable pipes here. */
+ 		if (modeset && !crtc->state->active && crtc->state->event) {
+ 			spin_lock_irq(&dev->event_lock);
+ 			drm_crtc_send_vblank_event(crtc, crtc->state->event);
+ 			spin_unlock_irq(&dev->event_lock);
+ 
+ 			crtc->state->event = NULL;
+ 		}
+ 	}
+ 
+ 	/* Now enable the clocks, plane, pipe, and connectors that we set up. */
+ 	dev_priv->display.update_crtcs(state, &crtc_vblank_mask);
+ 
+ 	/* FIXME: We should call drm_atomic_helper_commit_hw_done() here
+ 	 * already, but still need the state for the delayed optimization. To
+ 	 * fix this:
+ 	 * - wrap the optimization/post_plane_update stuff into a per-crtc work.
+ 	 * - schedule that vblank worker _before_ calling hw_done
+ 	 * - at the start of commit_tail, cancel it _synchrously
+ 	 * - switch over to the vblank wait helper in the core after that since
+ 	 *   we don't need out special handling any more.
+ 	 */
+ 	if (!state->legacy_cursor_update)
+ 		intel_atomic_wait_for_vblanks(dev, dev_priv, crtc_vblank_mask);
+ 
+ 	/*
+ 	 * Now that the vblank has passed, we can go ahead and program the
+ 	 * optimal watermarks on platforms that need two-step watermark
+ 	 * programming.
+ 	 *
+ 	 * TODO: Move this (and other cleanup) to an async worker eventually.
+ 	 */
+ 	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
+ 		intel_cstate = to_intel_crtc_state(crtc->state);
+ 
+ 		if (dev_priv->display.optimize_watermarks)
+ 			dev_priv->display.optimize_watermarks(intel_cstate);
+ 	}
+ 
+ 	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
+ 		intel_post_plane_update(to_intel_crtc_state(old_crtc_state));
+ 
+ 		if (put_domains[i])
+ 			modeset_put_power_domains(dev_priv, put_domains[i]);
+ 
+ 		intel_modeset_verify_crtc(crtc, old_crtc_state, crtc->state);
+ 	}
+ 
+ 	if (IS_SKYLAKE(dev_priv) && intel_state->modeset &&
+ 	    skl_can_enable_sagv(state))
+ 		skl_enable_sagv(dev_priv);
+ 
+ 	drm_atomic_helper_commit_hw_done(state);
+ 
+ 	if (intel_state->modeset)
+ 		intel_display_power_put(dev_priv, POWER_DOMAIN_MODESET);
+ 
+ 	mutex_lock(&dev->struct_mutex);
+ 	drm_atomic_helper_cleanup_planes(dev, state);
+ 	mutex_unlock(&dev->struct_mutex);
+ 
+ 	drm_atomic_helper_commit_cleanup_done(state);
+ 
+ 	drm_atomic_state_free(state);
+ 
+ 	/* As one of the primary mmio accessors, KMS has a high likelihood
+ 	 * of triggering bugs in unclaimed access. After we finish
+ 	 * modesetting, see if an error has been flagged, and if so
+ 	 * enable debugging for the next modeset - and hope we catch
+ 	 * the culprit.
+ 	 *
+ 	 * XXX note that we assume display power is on at this point.
+ 	 * This might hold true now but we need to add pm helper to check
+ 	 * unclaimed only when the hardware is on, as atomic commits
+ 	 * can happen also when the device is completely off.
+ 	 */
+ 	intel_uncore_arm_unclaimed_mmio_detection(dev_priv);
++>>>>>>> 896e5bb022bc (drm/i915: Move CRTC updating in atomic_commit into it's own hook)
 +}
 +
 +static int intel_set_mode_pipes(struct drm_crtc *crtc,
 +				struct drm_display_mode *mode,
 +				int x, int y, struct drm_framebuffer *fb,
 +				struct intel_crtc_state *pipe_config,
 +				unsigned modeset_pipes,
 +				unsigned prepare_pipes,
 +				unsigned disable_pipes)
 +{
 +	int ret;
 +
 +	ret = __intel_set_mode(crtc, mode, x, y, fb, pipe_config, modeset_pipes,
 +			       prepare_pipes, disable_pipes);
 +
 +	if (ret == 0)
 +		intel_modeset_check_state(crtc->dev);
 +
 +	return ret;
 +}
 +
 +static int intel_set_mode(struct drm_crtc *crtc,
 +			  struct drm_display_mode *mode,
 +			  int x, int y, struct drm_framebuffer *fb,
 +			  struct drm_atomic_state *state)
 +{
 +	struct intel_crtc_state *pipe_config;
 +	unsigned modeset_pipes, prepare_pipes, disable_pipes;
 +	int ret = 0;
 +
 +	pipe_config = intel_modeset_compute_config(crtc, mode, fb, state,
 +						   &modeset_pipes,
 +						   &prepare_pipes,
 +						   &disable_pipes);
 +
 +	if (IS_ERR(pipe_config)) {
 +		ret = PTR_ERR(pipe_config);
 +		goto out;
 +	}
 +
 +	ret = intel_set_mode_pipes(crtc, mode, x, y, fb, pipe_config,
 +				   modeset_pipes, prepare_pipes,
 +				   disable_pipes);
 +	if (ret)
 +		goto out;
 +
 +out:
 +	return ret;
 +}
 +
 +void intel_crtc_restore_mode(struct drm_crtc *crtc)
 +{
 +	struct drm_device *dev = crtc->dev;
 +	struct drm_atomic_state *state;
 +	struct intel_encoder *encoder;
 +	struct intel_connector *connector;
 +	struct drm_connector_state *connector_state;
 +
 +	state = drm_atomic_state_alloc(dev);
 +	if (!state) {
 +		DRM_DEBUG_KMS("[CRTC:%d] mode restore failed, out of memory",
 +			      crtc->base.id);
 +		return;
 +	}
 +
 +	state->acquire_ctx = dev->mode_config.acquire_ctx;
 +
 +	/* The force restore path in the HW readout code relies on the staged
 +	 * config still keeping the user requested config while the actual
 +	 * state has been overwritten by the configuration read from HW. We
 +	 * need to copy the staged config to the atomic state, otherwise the
 +	 * mode set will just reapply the state the HW is already in. */
 +	for_each_intel_encoder(dev, encoder) {
 +		if (&encoder->new_crtc->base != crtc)
 +			continue;
 +
 +		for_each_intel_connector(dev, connector) {
 +			if (connector->new_encoder != encoder)
 +				continue;
 +
 +			connector_state = drm_atomic_get_connector_state(state, &connector->base);
 +			if (IS_ERR(connector_state)) {
 +				DRM_DEBUG_KMS("Failed to add [CONNECTOR:%d:%s] to state: %ld\n",
 +					      connector->base.base.id,
 +					      connector->base.name,
 +					      PTR_ERR(connector_state));
 +				continue;
 +			}
 +
 +			connector_state->crtc = crtc;
 +			connector_state->best_encoder = &encoder->base;
 +		}
 +	}
 +
 +	intel_set_mode(crtc, &crtc->mode, crtc->x, crtc->y, crtc->primary->fb,
 +		       state);
 +
 +	drm_atomic_state_free(state);
 +}
 +
 +#undef for_each_intel_crtc_masked
 +
 +static void intel_set_config_free(struct intel_set_config *config)
 +{
 +	if (!config)
 +		return;
 +
 +	kfree(config->save_connector_encoders);
 +	kfree(config->save_encoder_crtcs);
 +	kfree(config->save_crtc_enabled);
 +	kfree(config);
 +}
 +
 +static int intel_set_config_save_state(struct drm_device *dev,
 +				       struct intel_set_config *config)
 +{
 +	struct drm_crtc *crtc;
 +	struct drm_encoder *encoder;
 +	struct drm_connector *connector;
 +	int count;
 +
 +	config->save_crtc_enabled =
 +		kcalloc(dev->mode_config.num_crtc,
 +			sizeof(bool), GFP_KERNEL);
 +	if (!config->save_crtc_enabled)
 +		return -ENOMEM;
 +
 +	config->save_encoder_crtcs =
 +		kcalloc(dev->mode_config.num_encoder,
 +			sizeof(struct drm_crtc *), GFP_KERNEL);
 +	if (!config->save_encoder_crtcs)
 +		return -ENOMEM;
 +
 +	config->save_connector_encoders =
 +		kcalloc(dev->mode_config.num_connector,
 +			sizeof(struct drm_encoder *), GFP_KERNEL);
 +	if (!config->save_connector_encoders)
 +		return -ENOMEM;
 +
 +	/* Copy data. Note that driver private data is not affected.
 +	 * Should anything bad happen only the expected state is
 +	 * restored, not the drivers personal bookkeeping.
 +	 */
 +	count = 0;
 +	for_each_crtc(dev, crtc) {
 +		config->save_crtc_enabled[count++] = crtc->state->enable;
 +	}
 +
 +	count = 0;
 +	list_for_each_entry(encoder, &dev->mode_config.encoder_list, head) {
 +		config->save_encoder_crtcs[count++] = encoder->crtc;
 +	}
 +
 +	count = 0;
 +	list_for_each_entry(connector, &dev->mode_config.connector_list, head) {
 +		config->save_connector_encoders[count++] = connector->encoder;
 +	}
 +
 +	return 0;
 +}
 +
 +static void intel_set_config_restore_state(struct drm_device *dev,
 +					   struct intel_set_config *config)
 +{
 +	struct intel_crtc *crtc;
 +	struct intel_encoder *encoder;
 +	struct intel_connector *connector;
 +	int count;
 +
 +	count = 0;
 +	for_each_intel_crtc(dev, crtc) {
 +		crtc->new_enabled = config->save_crtc_enabled[count++];
 +
 +		if (crtc->new_enabled)
 +			crtc->new_config = crtc->config;
 +		else
 +			crtc->new_config = NULL;
 +	}
 +
 +	count = 0;
 +	for_each_intel_encoder(dev, encoder) {
 +		encoder->new_crtc =
 +			to_intel_crtc(config->save_encoder_crtcs[count++]);
 +	}
 +
 +	count = 0;
 +	for_each_intel_connector(dev, connector) {
 +		connector->new_encoder =
 +			to_intel_encoder(config->save_connector_encoders[count++]);
 +	}
 +}
 +
 +static bool
 +is_crtc_connector_off(struct drm_mode_set *set)
 +{
 +	int i;
 +
 +	if (set->num_connectors == 0)
 +		return false;
 +
 +	if (WARN_ON(set->connectors == NULL))
 +		return false;
 +
 +	for (i = 0; i < set->num_connectors; i++)
 +		if (set->connectors[i]->encoder &&
 +		    set->connectors[i]->encoder->crtc == set->crtc &&
 +		    set->connectors[i]->dpms != DRM_MODE_DPMS_ON)
 +			return true;
 +
 +	return false;
 +}
 +
 +static void
 +intel_set_config_compute_mode_changes(struct drm_mode_set *set,
 +				      struct intel_set_config *config)
 +{
 +
 +	/* We should be able to check here if the fb has the same properties
 +	 * and then just flip_or_move it */
 +	if (is_crtc_connector_off(set)) {
 +		config->mode_changed = true;
 +	} else if (set->crtc->primary->fb != set->fb) {
 +		/*
 +		 * If we have no fb, we can only flip as long as the crtc is
 +		 * active, otherwise we need a full mode set.  The crtc may
 +		 * be active if we've only disabled the primary plane, or
 +		 * in fastboot situations.
 +		 */
 +		if (set->crtc->primary->fb == NULL) {
 +			struct intel_crtc *intel_crtc =
 +				to_intel_crtc(set->crtc);
 +
 +			if (intel_crtc->active) {
 +				DRM_DEBUG_KMS("crtc has no fb, will flip\n");
 +				config->fb_changed = true;
 +			} else {
 +				DRM_DEBUG_KMS("inactive crtc, full mode set\n");
 +				config->mode_changed = true;
 +			}
 +		} else if (set->fb == NULL) {
 +			config->mode_changed = true;
 +		} else if (set->fb->pixel_format !=
 +			   set->crtc->primary->fb->pixel_format) {
 +			config->mode_changed = true;
 +		} else {
 +			config->fb_changed = true;
 +		}
 +	}
 +
 +	if (set->fb && (set->x != set->crtc->x || set->y != set->crtc->y))
 +		config->fb_changed = true;
 +
 +	if (set->mode && !drm_mode_equal(set->mode, &set->crtc->mode)) {
 +		DRM_DEBUG_KMS("modes are different, full mode set\n");
 +		drm_mode_debug_printmodeline(&set->crtc->mode);
 +		drm_mode_debug_printmodeline(set->mode);
 +		config->mode_changed = true;
 +	}
 +
 +	DRM_DEBUG_KMS("computed changes for [CRTC:%d], mode_changed=%d, fb_changed=%d\n",
 +			set->crtc->base.id, config->mode_changed, config->fb_changed);
 +}
 +
 +static int
 +intel_modeset_stage_output_state(struct drm_device *dev,
 +				 struct drm_mode_set *set,
 +				 struct intel_set_config *config,
 +				 struct drm_atomic_state *state)
 +{
 +	struct intel_connector *connector;
 +	struct drm_connector_state *connector_state;
 +	struct intel_encoder *encoder;
 +	struct intel_crtc *crtc;
 +	int ro;
 +
 +	/* The upper layers ensure that we either disable a crtc or have a list
 +	 * of connectors. For paranoia, double-check this. */
 +	WARN_ON(!set->fb && (set->num_connectors != 0));
 +	WARN_ON(set->fb && (set->num_connectors == 0));
 +
 +	for_each_intel_connector(dev, connector) {
 +		/* Otherwise traverse passed in connector list and get encoders
 +		 * for them. */
 +		for (ro = 0; ro < set->num_connectors; ro++) {
 +			if (set->connectors[ro] == &connector->base) {
 +				connector->new_encoder = intel_find_encoder(connector, to_intel_crtc(set->crtc)->pipe);
 +				break;
 +			}
 +		}
 +
 +		/* If we disable the crtc, disable all its connectors. Also, if
 +		 * the connector is on the changing crtc but not on the new
 +		 * connector list, disable it. */
 +		if ((!set->fb || ro == set->num_connectors) &&
 +		    connector->base.encoder &&
 +		    connector->base.encoder->crtc == set->crtc) {
 +			connector->new_encoder = NULL;
 +
 +			DRM_DEBUG_KMS("[CONNECTOR:%d:%s] to [NOCRTC]\n",
 +				connector->base.base.id,
 +				connector->base.name);
 +		}
 +
 +
 +		if (&connector->new_encoder->base != connector->base.encoder) {
 +			DRM_DEBUG_KMS("[CONNECTOR:%d:%s] encoder changed, full mode switch\n",
 +				      connector->base.base.id,
 +				      connector->base.name);
 +			config->mode_changed = true;
 +		}
 +	}
 +	/* connector->new_encoder is now updated for all connectors. */
 +
 +	/* Update crtc of enabled connectors. */
 +	for_each_intel_connector(dev, connector) {
 +		struct drm_crtc *new_crtc;
 +
 +		if (!connector->new_encoder)
 +			continue;
 +
 +		new_crtc = connector->new_encoder->base.crtc;
 +
 +		for (ro = 0; ro < set->num_connectors; ro++) {
 +			if (set->connectors[ro] == &connector->base)
 +				new_crtc = set->crtc;
 +		}
 +
 +		/* Make sure the new CRTC will work with the encoder */
 +		if (!drm_encoder_crtc_ok(&connector->new_encoder->base,
 +					 new_crtc)) {
 +			return -EINVAL;
 +		}
 +		connector->new_encoder->new_crtc = to_intel_crtc(new_crtc);
 +
 +		connector_state =
 +			drm_atomic_get_connector_state(state, &connector->base);
 +		if (IS_ERR(connector_state))
 +			return PTR_ERR(connector_state);
 +
 +		connector_state->crtc = new_crtc;
 +		connector_state->best_encoder = &connector->new_encoder->base;
 +
 +		DRM_DEBUG_KMS("[CONNECTOR:%d:%s] to [CRTC:%d]\n",
 +			connector->base.base.id,
 +			connector->base.name,
 +			new_crtc->base.id);
 +	}
 +
 +	/* Check for any encoders that needs to be disabled. */
 +	for_each_intel_encoder(dev, encoder) {
 +		int num_connectors = 0;
 +		for_each_intel_connector(dev, connector) {
 +			if (connector->new_encoder == encoder) {
 +				WARN_ON(!connector->new_encoder->new_crtc);
 +				num_connectors++;
 +			}
 +		}
 +
 +		if (num_connectors == 0)
 +			encoder->new_crtc = NULL;
 +		else if (num_connectors > 1)
 +			return -EINVAL;
 +
 +		/* Only now check for crtc changes so we don't miss encoders
 +		 * that will be disabled. */
 +		if (&encoder->new_crtc->base != encoder->base.crtc) {
 +			DRM_DEBUG_KMS("[ENCODER:%d:%s] crtc changed, full mode switch\n",
 +				      encoder->base.base.id,
 +				      encoder->base.name);
 +			config->mode_changed = true;
 +		}
 +	}
 +	/* Now we've also updated encoder->new_crtc for all encoders. */
 +	for_each_intel_connector(dev, connector) {
 +		connector_state =
 +			drm_atomic_get_connector_state(state, &connector->base);
 +		if (IS_ERR(connector_state))
 +			return PTR_ERR(connector_state);
 +
 +		if (connector->new_encoder) {
 +			if (connector->new_encoder != connector->encoder)
 +				connector->encoder = connector->new_encoder;
 +		} else {
 +			connector_state->crtc = NULL;
 +		}
 +	}
 +	for_each_intel_crtc(dev, crtc) {
 +		crtc->new_enabled = false;
 +
 +		for_each_intel_encoder(dev, encoder) {
 +			if (encoder->new_crtc == crtc) {
 +				crtc->new_enabled = true;
 +				break;
 +			}
 +		}
 +
 +		if (crtc->new_enabled != crtc->base.state->enable) {
 +			DRM_DEBUG_KMS("[CRTC:%d] %sabled, full mode switch\n",
 +				      crtc->base.base.id,
 +				      crtc->new_enabled ? "en" : "dis");
 +			config->mode_changed = true;
 +		}
 +
 +		if (crtc->new_enabled)
 +			crtc->new_config = crtc->config;
 +		else
 +			crtc->new_config = NULL;
 +	}
 +
 +	return 0;
  }
  
 -static void intel_atomic_commit_work(struct work_struct *work)
 -{
 -	struct drm_atomic_state *state = container_of(work,
 -						      struct drm_atomic_state,
 -						      commit_work);
 -	intel_atomic_commit_tail(state);
 +static void disable_crtc_nofb(struct intel_crtc *crtc)
 +{
 +	struct drm_device *dev = crtc->base.dev;
 +	struct intel_encoder *encoder;
 +	struct intel_connector *connector;
 +
 +	DRM_DEBUG_KMS("Trying to restore without FB -> disabling pipe %c\n",
 +		      pipe_name(crtc->pipe));
 +
 +	for_each_intel_connector(dev, connector) {
 +		if (connector->new_encoder &&
 +		    connector->new_encoder->new_crtc == crtc)
 +			connector->new_encoder = NULL;
 +	}
 +
 +	for_each_intel_encoder(dev, encoder) {
 +		if (encoder->new_crtc == crtc)
 +			encoder->new_crtc = NULL;
 +	}
 +
 +	crtc->new_enabled = false;
 +	crtc->new_config = NULL;
  }
  
 -static void intel_atomic_track_fbs(struct drm_atomic_state *state)
 +static int intel_crtc_set_config(struct drm_mode_set *set)
  {
 -	struct drm_plane_state *old_plane_state;
 -	struct drm_plane *plane;
 -	int i;
 +	struct drm_device *dev;
 +	struct drm_mode_set save_set;
 +	struct drm_atomic_state *state = NULL;
 +	struct intel_set_config *config;
 +	struct intel_crtc_state *pipe_config;
 +	unsigned modeset_pipes, prepare_pipes, disable_pipes;
 +	int ret;
  
 -	for_each_plane_in_state(state, plane, old_plane_state, i)
 -		i915_gem_track_fb(intel_fb_obj(old_plane_state->fb),
 -				  intel_fb_obj(plane->state->fb),
 -				  to_intel_plane(plane)->frontbuffer_bit);
 -}
 +	BUG_ON(!set);
 +	BUG_ON(!set->crtc);
 +	BUG_ON(!set->crtc->helper_private);
  
 -/**
 - * intel_atomic_commit - commit validated state object
 - * @dev: DRM device
 - * @state: the top-level driver state object
 - * @nonblock: nonblocking commit
 - *
 - * This function commits a top-level state object that has been validated
 - * with drm_atomic_helper_check().
 - *
 - * FIXME:  Atomic modeset support for i915 is not yet complete.  At the moment
 - * nonblocking commits are only safe for pure plane updates. Everything else
 - * should work though.
 - *
 - * RETURNS
 - * Zero for success or -errno.
 - */
 -static int intel_atomic_commit(struct drm_device *dev,
 -			       struct drm_atomic_state *state,
 -			       bool nonblock)
 -{
 -	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
 -	struct drm_i915_private *dev_priv = to_i915(dev);
 -	int ret = 0;
 +	/* Enforce sane interface api - has been abused by the fb helper. */
 +	BUG_ON(!set->mode && set->fb);
 +	BUG_ON(set->fb && set->num_connectors == 0);
  
 -	if (intel_state->modeset && nonblock) {
 -		DRM_DEBUG_KMS("nonblocking commit for modeset not yet implemented.\n");
 -		return -EINVAL;
 +	if (set->fb) {
 +		DRM_DEBUG_KMS("[CRTC:%d] [FB:%d] #connectors=%d (x y) (%i %i)\n",
 +				set->crtc->base.id, set->fb->base.id,
 +				(int)set->num_connectors, set->x, set->y);
 +	} else {
 +		DRM_DEBUG_KMS("[CRTC:%d] [NOFB]\n", set->crtc->base.id);
  	}
  
 -	ret = drm_atomic_helper_setup_commit(state, nonblock);
 +	dev = set->crtc->dev;
 +
 +	ret = -ENOMEM;
 +	config = kzalloc(sizeof(*config), GFP_KERNEL);
 +	if (!config)
 +		goto out_config;
 +
 +	ret = intel_set_config_save_state(dev, config);
  	if (ret)
 -		return ret;
 +		goto out_config;
  
 -	INIT_WORK(&state->commit_work, intel_atomic_commit_work);
 +	save_set.crtc = set->crtc;
 +	save_set.mode = &set->crtc->mode;
 +	save_set.x = set->crtc->x;
 +	save_set.y = set->crtc->y;
 +	save_set.fb = set->crtc->primary->fb;
  
 -	ret = intel_atomic_prepare_commit(dev, state, nonblock);
 -	if (ret) {
 -		DRM_DEBUG_ATOMIC("Preparing state failed with %i\n", ret);
 -		return ret;
 -	}
 +	/* Compute whether we need a full modeset, only an fb base update or no
 +	 * change at all. In the future we might also check whether only the
 +	 * mode changed, e.g. for LVDS where we only change the panel fitter in
 +	 * such cases. */
 +	intel_set_config_compute_mode_changes(set, config);
  
 -	drm_atomic_helper_swap_state(state, true);
 -	dev_priv->wm.distrust_bios_wm = false;
 -	dev_priv->wm.skl_results = intel_state->wm_results;
 -	intel_shared_dpll_commit(state);
 -	intel_atomic_track_fbs(state);
 +	state = drm_atomic_state_alloc(dev);
 +	if (!state) {
 +		ret = -ENOMEM;
 +		goto out_config;
 +	}
  
 -	if (nonblock)
 -		queue_work(system_unbound_wq, &state->commit_work);
 -	else
 -		intel_atomic_commit_tail(state);
 +	state->acquire_ctx = dev->mode_config.acquire_ctx;
  
 -	return 0;
 -}
 +	ret = intel_modeset_stage_output_state(dev, set, config, state);
 +	if (ret)
 +		goto fail;
  
 -void intel_crtc_restore_mode(struct drm_crtc *crtc)
 -{
 -	struct drm_device *dev = crtc->dev;
 -	struct drm_atomic_state *state;
 -	struct drm_crtc_state *crtc_state;
 -	int ret;
 +	pipe_config = intel_modeset_compute_config(set->crtc, set->mode,
 +						   set->fb, state,
 +						   &modeset_pipes,
 +						   &prepare_pipes,
 +						   &disable_pipes);
 +	if (IS_ERR(pipe_config)) {
 +		ret = PTR_ERR(pipe_config);
 +		goto fail;
 +	} else if (pipe_config) {
 +		if (pipe_config->has_audio !=
 +		    to_intel_crtc(set->crtc)->config->has_audio)
 +			config->mode_changed = true;
  
 -	state = drm_atomic_state_alloc(dev);
 -	if (!state) {
 -		DRM_DEBUG_KMS("[CRTC:%d:%s] crtc restore failed, out of memory",
 -			      crtc->base.id, crtc->name);
 -		return;
 +		/*
 +		 * Note we have an issue here with infoframes: current code
 +		 * only updates them on the full mode set path per hw
 +		 * requirements.  So here we should be checking for any
 +		 * required changes and forcing a mode set.
 +		 */
  	}
  
 -	state->acquire_ctx = drm_modeset_legacy_acquire_ctx(crtc);
 +	intel_update_pipe_size(to_intel_crtc(set->crtc));
  
 -retry:
 -	crtc_state = drm_atomic_get_crtc_state(state, crtc);
 -	ret = PTR_ERR_OR_ZERO(crtc_state);
 -	if (!ret) {
 -		if (!crtc_state->active)
 -			goto out;
 +	if (config->mode_changed) {
 +		ret = intel_set_mode_pipes(set->crtc, set->mode,
 +					   set->x, set->y, set->fb, pipe_config,
 +					   modeset_pipes, prepare_pipes,
 +					   disable_pipes);
 +	} else if (config->fb_changed) {
 +		struct intel_crtc *intel_crtc = to_intel_crtc(set->crtc);
 +		struct drm_plane *primary = set->crtc->primary;
 +		int vdisplay, hdisplay;
 +
 +		drm_crtc_get_hv_timing(set->mode, &hdisplay, &vdisplay);
 +		ret = primary->funcs->update_plane(primary, set->crtc, set->fb,
 +						   0, 0, hdisplay, vdisplay,
 +						   set->x << 16, set->y << 16,
 +						   hdisplay << 16, vdisplay << 16);
  
 -		crtc_state->mode_changed = true;
 -		ret = drm_atomic_commit(state);
 +		/*
 +		 * We need to make sure the primary plane is re-enabled if it
 +		 * has previously been turned off.
 +		 */
 +		if (!intel_crtc->primary_enabled && ret == 0) {
 +			WARN_ON(!intel_crtc->active);
 +			intel_enable_primary_hw_plane(set->crtc->primary, set->crtc);
 +		}
 +
 +		/*
 +		 * In the fastboot case this may be our only check of the
 +		 * state after boot.  It would be better to only do it on
 +		 * the first update, but we don't have a nice way of doing that
 +		 * (and really, set_config isn't used much for high freq page
 +		 * flipping, so increasing its cost here shouldn't be a big
 +		 * deal).
 +		 */
 +		if (i915.fastboot && ret == 0)
 +			intel_modeset_check_state(set->crtc->dev);
  	}
  
 -	if (ret == -EDEADLK) {
 +	if (ret) {
 +		DRM_DEBUG_KMS("failed to set mode on [CRTC:%d], err = %d\n",
 +			      set->crtc->base.id, ret);
 +fail:
 +		intel_set_config_restore_state(dev, config);
 +
  		drm_atomic_state_clear(state);
 -		drm_modeset_backoff(state->acquire_ctx);
 -		goto retry;
 +
 +		/*
 +		 * HACK: if the pipe was on, but we didn't have a framebuffer,
 +		 * force the pipe off to avoid oopsing in the modeset code
 +		 * due to fb==NULL. This should only happen during boot since
 +		 * we don't yet reconstruct the FB from the hardware state.
 +		 */
 +		if (to_intel_crtc(save_set.crtc)->new_enabled && !save_set.fb)
 +			disable_crtc_nofb(to_intel_crtc(save_set.crtc));
 +
 +		/* Try to restore the config */
 +		if (config->mode_changed &&
 +		    intel_set_mode(save_set.crtc, save_set.mode,
 +				   save_set.x, save_set.y, save_set.fb,
 +				   state))
 +			DRM_ERROR("failed to restore config after modeset failure\n");
  	}
  
 -	if (ret)
 -out:
 +out_config:
 +	if (state)
  		drm_atomic_state_free(state);
 +
 +	intel_set_config_free(config);
 +	return ret;
  }
  
 -#undef for_each_intel_crtc_masked
 +static const struct drm_crtc_funcs intel_crtc_funcs = {
 +	.gamma_set = intel_crtc_gamma_set,
 +	.set_config = intel_crtc_set_config,
 +	.destroy = intel_crtc_destroy,
 +	.page_flip = intel_crtc_page_flip,
 +	.atomic_duplicate_state = intel_crtc_duplicate_state,
 +	.atomic_destroy_state = intel_crtc_destroy_state,
 +};
  
 -/*
 - * FIXME: Remove this once i915 is fully DRIVER_ATOMIC by calling
 - *        drm_atomic_helper_legacy_gamma_set() directly.
 - */
 -static int intel_atomic_legacy_gamma_set(struct drm_crtc *crtc,
 -					 u16 *red, u16 *green, u16 *blue,
 -					 uint32_t size)
 +static bool ibx_pch_dpll_get_hw_state(struct drm_i915_private *dev_priv,
 +				      struct intel_shared_dpll *pll,
 +				      struct intel_dpll_hw_state *hw_state)
  {
 -	struct drm_device *dev = crtc->dev;
 -	struct drm_mode_config *config = &dev->mode_config;
 -	struct drm_crtc_state *state;
 -	int ret;
 +	uint32_t val;
  
 -	ret = drm_atomic_helper_legacy_gamma_set(crtc, red, green, blue, size);
 -	if (ret)
 -		return ret;
 +	if (!intel_display_power_is_enabled(dev_priv, POWER_DOMAIN_PLLS))
 +		return false;
  
 -	/*
 -	 * Make sure we update the legacy properties so this works when
 -	 * atomic is not enabled.
 -	 */
 +	val = I915_READ(PCH_DPLL(pll->id));
 +	hw_state->dpll = val;
 +	hw_state->fp0 = I915_READ(PCH_FP0(pll->id));
 +	hw_state->fp1 = I915_READ(PCH_FP1(pll->id));
 +
 +	return val & DPLL_VCO_ENABLE;
 +}
  
 -	state = crtc->state;
 +static void ibx_pch_dpll_mode_set(struct drm_i915_private *dev_priv,
 +				  struct intel_shared_dpll *pll)
 +{
 +	I915_WRITE(PCH_FP0(pll->id), pll->config.hw_state.fp0);
 +	I915_WRITE(PCH_FP1(pll->id), pll->config.hw_state.fp1);
 +}
  
 -	drm_object_property_set_value(&crtc->base,
 -				      config->degamma_lut_property,
 -				      (state->degamma_lut) ?
 -				      state->degamma_lut->base.id : 0);
 +static void ibx_pch_dpll_enable(struct drm_i915_private *dev_priv,
 +				struct intel_shared_dpll *pll)
 +{
 +	/* PCH refclock must be enabled first */
 +	ibx_assert_pch_refclk_enabled(dev_priv);
  
 -	drm_object_property_set_value(&crtc->base,
 -				      config->ctm_property,
 -				      (state->ctm) ?
 -				      state->ctm->base.id : 0);
 +	I915_WRITE(PCH_DPLL(pll->id), pll->config.hw_state.dpll);
  
 -	drm_object_property_set_value(&crtc->base,
 -				      config->gamma_lut_property,
 -				      (state->gamma_lut) ?
 -				      state->gamma_lut->base.id : 0);
 +	/* Wait for the clocks to stabilize. */
 +	POSTING_READ(PCH_DPLL(pll->id));
 +	udelay(150);
  
 -	return 0;
 +	/* The pixel multiplier can only be updated once the
 +	 * DPLL is enabled and the clocks are stable.
 +	 *
 +	 * So write it again.
 +	 */
 +	I915_WRITE(PCH_DPLL(pll->id), pll->config.hw_state.dpll);
 +	POSTING_READ(PCH_DPLL(pll->id));
 +	udelay(200);
  }
  
 -static const struct drm_crtc_funcs intel_crtc_funcs = {
 -	.gamma_set = intel_atomic_legacy_gamma_set,
 -	.set_config = drm_atomic_helper_set_config,
 -	.set_property = drm_atomic_helper_crtc_set_property,
 -	.destroy = intel_crtc_destroy,
 -	.page_flip = intel_crtc_page_flip,
 -	.atomic_duplicate_state = intel_crtc_duplicate_state,
 -	.atomic_destroy_state = intel_crtc_destroy_state,
 +static void ibx_pch_dpll_disable(struct drm_i915_private *dev_priv,
 +				 struct intel_shared_dpll *pll)
 +{
 +	struct drm_device *dev = dev_priv->dev;
 +	struct intel_crtc *crtc;
 +
 +	/* Make sure no transcoder isn't still depending on us. */
 +	for_each_intel_crtc(dev, crtc) {
 +		if (intel_crtc_to_shared_dpll(crtc) == pll)
 +			assert_pch_transcoder_disabled(dev_priv, crtc->pipe);
 +	}
 +
 +	I915_WRITE(PCH_DPLL(pll->id), 0);
 +	POSTING_READ(PCH_DPLL(pll->id));
 +	udelay(200);
 +}
 +
 +static char *ibx_pch_dpll_names[] = {
 +	"PCH DPLL A",
 +	"PCH DPLL B",
  };
  
 +static void ibx_pch_dpll_init(struct drm_device *dev)
 +{
 +	struct drm_i915_private *dev_priv = dev->dev_private;
 +	int i;
 +
 +	dev_priv->num_shared_dpll = 2;
 +
 +	for (i = 0; i < dev_priv->num_shared_dpll; i++) {
 +		dev_priv->shared_dplls[i].id = i;
 +		dev_priv->shared_dplls[i].name = ibx_pch_dpll_names[i];
 +		dev_priv->shared_dplls[i].mode_set = ibx_pch_dpll_mode_set;
 +		dev_priv->shared_dplls[i].enable = ibx_pch_dpll_enable;
 +		dev_priv->shared_dplls[i].disable = ibx_pch_dpll_disable;
 +		dev_priv->shared_dplls[i].get_hw_state =
 +			ibx_pch_dpll_get_hw_state;
 +	}
 +}
 +
 +static void intel_shared_dpll_init(struct drm_device *dev)
 +{
 +	struct drm_i915_private *dev_priv = dev->dev_private;
 +
 +	if (HAS_DDI(dev))
 +		intel_ddi_pll_init(dev);
 +	else if (HAS_PCH_IBX(dev) || HAS_PCH_CPT(dev))
 +		ibx_pch_dpll_init(dev);
 +	else
 +		dev_priv->num_shared_dpll = 0;
 +
 +	BUG_ON(dev_priv->num_shared_dpll > I915_NUM_PLLS);
 +}
 +
 +/**
 + * intel_wm_need_update - Check whether watermarks need updating
 + * @plane: drm plane
 + * @state: new plane state
 + *
 + * Check current plane state versus the new one to determine whether
 + * watermarks need to be recalculated.
 + *
 + * Returns true or false.
 + */
 +bool intel_wm_need_update(struct drm_plane *plane,
 +			  struct drm_plane_state *state)
 +{
 +	/* Update watermarks on tiling changes. */
 +	if (!plane->state->fb || !state->fb ||
 +	    plane->state->fb->modifier[0] != state->fb->modifier[0] ||
 +	    plane->state->rotation != state->rotation)
 +		return true;
 +
 +	return false;
 +}
 +
  /**
   * intel_prepare_plane_fb - Prepare fb for usage on plane
   * @plane: drm plane to prepare for
@@@ -13588,67 -15846,103 +13798,69 @@@ static void intel_init_display(struct d
  		dev_priv->display.get_pipe_config = i9xx_get_pipe_config;
  		dev_priv->display.get_initial_plane_config =
  			i9xx_get_initial_plane_config;
 -		dev_priv->display.crtc_compute_clock = i8xx_crtc_compute_clock;
 +		dev_priv->display.crtc_compute_clock = i9xx_crtc_compute_clock;
  		dev_priv->display.crtc_enable = i9xx_crtc_enable;
  		dev_priv->display.crtc_disable = i9xx_crtc_disable;
 +		dev_priv->display.off = i9xx_crtc_off;
 +		dev_priv->display.update_primary_plane =
 +			i9xx_update_primary_plane;
  	}
  
+ 	dev_priv->display.update_crtcs = intel_update_crtcs;
+ 
  	/* Returns the core display clock speed */
 -	if (IS_SKYLAKE(dev_priv) || IS_KABYLAKE(dev_priv))
 +	if (IS_SKYLAKE(dev))
  		dev_priv->display.get_display_clock_speed =
  			skylake_get_display_clock_speed;
 -	else if (IS_BROXTON(dev_priv))
 -		dev_priv->display.get_display_clock_speed =
 -			broxton_get_display_clock_speed;
 -	else if (IS_BROADWELL(dev_priv))
 +	else if (IS_BROADWELL(dev))
  		dev_priv->display.get_display_clock_speed =
  			broadwell_get_display_clock_speed;
 -	else if (IS_HASWELL(dev_priv))
 +	else if (IS_HASWELL(dev))
  		dev_priv->display.get_display_clock_speed =
  			haswell_get_display_clock_speed;
 -	else if (IS_VALLEYVIEW(dev_priv) || IS_CHERRYVIEW(dev_priv))
 +	else if (IS_VALLEYVIEW(dev))
  		dev_priv->display.get_display_clock_speed =
  			valleyview_get_display_clock_speed;
 -	else if (IS_GEN5(dev_priv))
 -		dev_priv->display.get_display_clock_speed =
 -			ilk_get_display_clock_speed;
 -	else if (IS_I945G(dev_priv) || IS_BROADWATER(dev_priv) ||
 -		 IS_GEN6(dev_priv) || IS_IVYBRIDGE(dev_priv))
 +	else if (IS_I945G(dev) || (IS_G33(dev) && !IS_PINEVIEW_M(dev)))
  		dev_priv->display.get_display_clock_speed =
  			i945_get_display_clock_speed;
 -	else if (IS_GM45(dev_priv))
 -		dev_priv->display.get_display_clock_speed =
 -			gm45_get_display_clock_speed;
 -	else if (IS_CRESTLINE(dev_priv))
 -		dev_priv->display.get_display_clock_speed =
 -			i965gm_get_display_clock_speed;
 -	else if (IS_PINEVIEW(dev_priv))
 -		dev_priv->display.get_display_clock_speed =
 -			pnv_get_display_clock_speed;
 -	else if (IS_G33(dev_priv) || IS_G4X(dev_priv))
 -		dev_priv->display.get_display_clock_speed =
 -			g33_get_display_clock_speed;
 -	else if (IS_I915G(dev_priv))
 +	else if (IS_I915G(dev))
  		dev_priv->display.get_display_clock_speed =
  			i915_get_display_clock_speed;
 -	else if (IS_I945GM(dev_priv) || IS_845G(dev_priv))
 +	else if (IS_I945GM(dev) || IS_845G(dev))
  		dev_priv->display.get_display_clock_speed =
  			i9xx_misc_get_display_clock_speed;
 -	else if (IS_I915GM(dev_priv))
 +	else if (IS_PINEVIEW(dev))
 +		dev_priv->display.get_display_clock_speed =
 +			pnv_get_display_clock_speed;
 +	else if (IS_I915GM(dev))
  		dev_priv->display.get_display_clock_speed =
  			i915gm_get_display_clock_speed;
 -	else if (IS_I865G(dev_priv))
 +	else if (IS_I865G(dev))
  		dev_priv->display.get_display_clock_speed =
  			i865_get_display_clock_speed;
 -	else if (IS_I85X(dev_priv))
 +	else if (IS_I85X(dev))
  		dev_priv->display.get_display_clock_speed =
 -			i85x_get_display_clock_speed;
 -	else { /* 830 */
 -		WARN(!IS_I830(dev_priv), "Unknown platform. Assuming 133 MHz CDCLK\n");
 +			i855_get_display_clock_speed;
 +	else /* 852, 830 */
  		dev_priv->display.get_display_clock_speed =
  			i830_get_display_clock_speed;
 -	}
  
 -	if (IS_GEN5(dev_priv)) {
 +	if (IS_GEN5(dev)) {
  		dev_priv->display.fdi_link_train = ironlake_fdi_link_train;
 -	} else if (IS_GEN6(dev_priv)) {
 +	} else if (IS_GEN6(dev)) {
  		dev_priv->display.fdi_link_train = gen6_fdi_link_train;
 -	} else if (IS_IVYBRIDGE(dev_priv)) {
 +	} else if (IS_IVYBRIDGE(dev)) {
  		/* FIXME: detect B0+ stepping and use auto training */
  		dev_priv->display.fdi_link_train = ivb_manual_fdi_link_train;
 -	} else if (IS_HASWELL(dev_priv) || IS_BROADWELL(dev_priv)) {
 +	} else if (IS_HASWELL(dev) || IS_BROADWELL(dev)) {
  		dev_priv->display.fdi_link_train = hsw_fdi_link_train;
 +	} else if (IS_VALLEYVIEW(dev)) {
 +		dev_priv->display.modeset_global_resources =
 +			valleyview_modeset_global_resources;
  	}
  
 -	if (IS_BROADWELL(dev_priv)) {
 -		dev_priv->display.modeset_commit_cdclk =
 -			broadwell_modeset_commit_cdclk;
 -		dev_priv->display.modeset_calc_cdclk =
 -			broadwell_modeset_calc_cdclk;
 -	} else if (IS_VALLEYVIEW(dev_priv) || IS_CHERRYVIEW(dev_priv)) {
 -		dev_priv->display.modeset_commit_cdclk =
 -			valleyview_modeset_commit_cdclk;
 -		dev_priv->display.modeset_calc_cdclk =
 -			valleyview_modeset_calc_cdclk;
 -	} else if (IS_BROXTON(dev_priv)) {
 -		dev_priv->display.modeset_commit_cdclk =
 -			bxt_modeset_commit_cdclk;
 -		dev_priv->display.modeset_calc_cdclk =
 -			bxt_modeset_calc_cdclk;
 -	} else if (IS_SKYLAKE(dev_priv) || IS_KABYLAKE(dev_priv)) {
 -		dev_priv->display.modeset_commit_cdclk =
 -			skl_modeset_commit_cdclk;
 -		dev_priv->display.modeset_calc_cdclk =
 -			skl_modeset_calc_cdclk;
 -	}
 -
 -	switch (INTEL_INFO(dev_priv)->gen) {
 +	switch (INTEL_INFO(dev)->gen) {
  	case 2:
  		dev_priv->display.queue_flip = intel_gen2_queue_flip;
  		break;
* Unmerged path drivers/gpu/drm/i915/i915_drv.h
* Unmerged path drivers/gpu/drm/i915/intel_display.c
