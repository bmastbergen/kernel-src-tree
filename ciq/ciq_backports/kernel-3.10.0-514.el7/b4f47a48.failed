ixgbe: use BIT() macro

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Jacob Keller <jacob.e.keller@intel.com>
commit b4f47a483045a6e6b31be8ade76cdfef7091f18b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/b4f47a48.failed

Several areas of ixgbe were written before widespread usage of the
BIT(n) macro. With the impending release of GCC 6 and its associated new
warnings, some usages such as (1 << 31) have been noted within the ixgbe
driver source. Fix these wholesale and prevent future issues by simply
using BIT macro instead of hand coded bit shifts.

Also fix a few shifts that are shifting values into place by using the
'u' prefix to indicate unsigned. It doesn't strictly matter in these
cases because we're not shifting by too large a value, but these are all
unsigned values and should be indicated as such.

	Signed-off-by: Jacob Keller <jacob.e.keller@intel.com>
	Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
	Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
(cherry picked from commit b4f47a483045a6e6b31be8ade76cdfef7091f18b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/ixgbe/ixgbe.h
#	drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
#	drivers/net/ethernet/intel/ixgbe/ixgbe_ptp.c
#	drivers/net/ethernet/intel/ixgbe/ixgbe_type.h
diff --cc drivers/net/ethernet/intel/ixgbe/ixgbe.h
index 7d4bc9ac4e00,781c8787ab66..000000000000
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe.h
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe.h
@@@ -638,41 -620,46 +638,84 @@@ struct ixgbe_adapter 
  	 * thus the additional *_CAPABLE flags.
  	 */
  	u32 flags;
++<<<<<<< HEAD
 +#define IXGBE_FLAG_MSI_ENABLED                  (u32)(1 << 1)
 +#define IXGBE_FLAG_MSIX_ENABLED                 (u32)(1 << 3)
 +#define IXGBE_FLAG_RX_1BUF_CAPABLE              (u32)(1 << 4)
 +#define IXGBE_FLAG_RX_PS_CAPABLE                (u32)(1 << 5)
 +#define IXGBE_FLAG_RX_PS_ENABLED                (u32)(1 << 6)
 +#define IXGBE_FLAG_DCA_ENABLED                  (u32)(1 << 8)
 +#define IXGBE_FLAG_DCA_CAPABLE                  (u32)(1 << 9)
 +#define IXGBE_FLAG_IMIR_ENABLED                 (u32)(1 << 10)
 +#define IXGBE_FLAG_MQ_CAPABLE                   (u32)(1 << 11)
 +#define IXGBE_FLAG_DCB_ENABLED                  (u32)(1 << 12)
 +#define IXGBE_FLAG_VMDQ_CAPABLE                 (u32)(1 << 13)
 +#define IXGBE_FLAG_VMDQ_ENABLED                 (u32)(1 << 14)
 +#define IXGBE_FLAG_FAN_FAIL_CAPABLE             (u32)(1 << 15)
 +#define IXGBE_FLAG_NEED_LINK_UPDATE             (u32)(1 << 16)
 +#define IXGBE_FLAG_NEED_LINK_CONFIG             (u32)(1 << 17)
 +#define IXGBE_FLAG_FDIR_HASH_CAPABLE            (u32)(1 << 18)
 +#define IXGBE_FLAG_FDIR_PERFECT_CAPABLE         (u32)(1 << 19)
 +#define IXGBE_FLAG_FCOE_CAPABLE                 (u32)(1 << 20)
 +#define IXGBE_FLAG_FCOE_ENABLED                 (u32)(1 << 21)
 +#define IXGBE_FLAG_SRIOV_CAPABLE                (u32)(1 << 22)
 +#define IXGBE_FLAG_SRIOV_ENABLED                (u32)(1 << 23)
 +
 +	u32 flags2;
 +#define IXGBE_FLAG2_RSC_CAPABLE                 (u32)(1 << 0)
 +#define IXGBE_FLAG2_RSC_ENABLED                 (u32)(1 << 1)
 +#define IXGBE_FLAG2_TEMP_SENSOR_CAPABLE         (u32)(1 << 2)
 +#define IXGBE_FLAG2_TEMP_SENSOR_EVENT           (u32)(1 << 3)
 +#define IXGBE_FLAG2_SEARCH_FOR_SFP              (u32)(1 << 4)
 +#define IXGBE_FLAG2_SFP_NEEDS_RESET             (u32)(1 << 5)
 +#define IXGBE_FLAG2_RESET_REQUESTED             (u32)(1 << 6)
 +#define IXGBE_FLAG2_FDIR_REQUIRES_REINIT        (u32)(1 << 7)
 +#define IXGBE_FLAG2_RSS_FIELD_IPV4_UDP		(u32)(1 << 8)
 +#define IXGBE_FLAG2_RSS_FIELD_IPV6_UDP		(u32)(1 << 9)
 +#define IXGBE_FLAG2_PTP_PPS_ENABLED		(u32)(1 << 10)
 +#define IXGBE_FLAG2_PHY_INTERRUPT		(u32)(1 << 11)
++=======
+ #define IXGBE_FLAG_MSI_ENABLED			BIT(1)
+ #define IXGBE_FLAG_MSIX_ENABLED			BIT(3)
+ #define IXGBE_FLAG_RX_1BUF_CAPABLE		BIT(4)
+ #define IXGBE_FLAG_RX_PS_CAPABLE		BIT(5)
+ #define IXGBE_FLAG_RX_PS_ENABLED		BIT(6)
+ #define IXGBE_FLAG_DCA_ENABLED			BIT(8)
+ #define IXGBE_FLAG_DCA_CAPABLE			BIT(9)
+ #define IXGBE_FLAG_IMIR_ENABLED			BIT(10)
+ #define IXGBE_FLAG_MQ_CAPABLE			BIT(11)
+ #define IXGBE_FLAG_DCB_ENABLED			BIT(12)
+ #define IXGBE_FLAG_VMDQ_CAPABLE			BIT(13)
+ #define IXGBE_FLAG_VMDQ_ENABLED			BIT(14)
+ #define IXGBE_FLAG_FAN_FAIL_CAPABLE		BIT(15)
+ #define IXGBE_FLAG_NEED_LINK_UPDATE		BIT(16)
+ #define IXGBE_FLAG_NEED_LINK_CONFIG		BIT(17)
+ #define IXGBE_FLAG_FDIR_HASH_CAPABLE		BIT(18)
+ #define IXGBE_FLAG_FDIR_PERFECT_CAPABLE		BIT(19)
+ #define IXGBE_FLAG_FCOE_CAPABLE			BIT(20)
+ #define IXGBE_FLAG_FCOE_ENABLED			BIT(21)
+ #define IXGBE_FLAG_SRIOV_CAPABLE		BIT(22)
+ #define IXGBE_FLAG_SRIOV_ENABLED		BIT(23)
+ #define IXGBE_FLAG_VXLAN_OFFLOAD_CAPABLE	BIT(24)
+ #define IXGBE_FLAG_RX_HWTSTAMP_ENABLED		BIT(25)
+ #define IXGBE_FLAG_RX_HWTSTAMP_IN_REGISTER	BIT(26)
+ 
+ 	u32 flags2;
+ #define IXGBE_FLAG2_RSC_CAPABLE			BIT(0)
+ #define IXGBE_FLAG2_RSC_ENABLED			BIT(1)
+ #define IXGBE_FLAG2_TEMP_SENSOR_CAPABLE		BIT(2)
+ #define IXGBE_FLAG2_TEMP_SENSOR_EVENT		BIT(3)
+ #define IXGBE_FLAG2_SEARCH_FOR_SFP		BIT(4)
+ #define IXGBE_FLAG2_SFP_NEEDS_RESET		BIT(5)
+ #define IXGBE_FLAG2_RESET_REQUESTED		BIT(6)
+ #define IXGBE_FLAG2_FDIR_REQUIRES_REINIT	BIT(7)
+ #define IXGBE_FLAG2_RSS_FIELD_IPV4_UDP		BIT(8)
+ #define IXGBE_FLAG2_RSS_FIELD_IPV6_UDP		BIT(9)
+ #define IXGBE_FLAG2_PTP_PPS_ENABLED		BIT(10)
+ #define IXGBE_FLAG2_PHY_INTERRUPT		BIT(11)
+ #define IXGBE_FLAG2_VXLAN_REREG_NEEDED		BIT(12)
+ #define IXGBE_FLAG2_VLAN_PROMISC		BIT(13)
++>>>>>>> b4f47a483045 (ixgbe: use BIT() macro)
  
  	/* Tx fast path data */
  	int num_tx_queues;
diff --cc drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
index 7c4d1735a08a,b41a26fe57de..000000000000
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
@@@ -3648,13 -3737,12 +3648,13 @@@ static void ixgbe_setup_psrtype(struct 
  		return;
  
  	if (rss_i > 3)
- 		psrtype |= 2 << 29;
+ 		psrtype |= 2u << 29;
  	else if (rss_i > 1)
- 		psrtype |= 1 << 29;
+ 		psrtype |= 1u << 29;
  
 -	for_each_set_bit(pool, &adapter->fwd_bitmask, 32)
 -		IXGBE_WRITE_REG(hw, IXGBE_PSRTYPE(VMDQ_P(pool)), psrtype);
 +	for (p = 0; p < adapter->num_rx_pools; p++)
 +		IXGBE_WRITE_REG(hw, IXGBE_PSRTYPE(VMDQ_P(p)),
 +				psrtype);
  }
  
  static void ixgbe_configure_virtualization(struct ixgbe_adapter *adapter)
@@@ -3985,6 -4094,131 +3985,134 @@@ static void ixgbe_vlan_strip_enable(str
  	}
  }
  
++<<<<<<< HEAD
++=======
+ static void ixgbe_vlan_promisc_enable(struct ixgbe_adapter *adapter)
+ {
+ 	struct ixgbe_hw *hw = &adapter->hw;
+ 	u32 vlnctrl, i;
+ 
+ 	switch (hw->mac.type) {
+ 	case ixgbe_mac_82599EB:
+ 	case ixgbe_mac_X540:
+ 	case ixgbe_mac_X550:
+ 	case ixgbe_mac_X550EM_x:
+ 	case ixgbe_mac_x550em_a:
+ 	default:
+ 		if (adapter->flags & IXGBE_FLAG_VMDQ_ENABLED)
+ 			break;
+ 		/* fall through */
+ 	case ixgbe_mac_82598EB:
+ 		/* legacy case, we can just disable VLAN filtering */
+ 		vlnctrl = IXGBE_READ_REG(hw, IXGBE_VLNCTRL);
+ 		vlnctrl &= ~(IXGBE_VLNCTRL_VFE | IXGBE_VLNCTRL_CFIEN);
+ 		IXGBE_WRITE_REG(hw, IXGBE_VLNCTRL, vlnctrl);
+ 		return;
+ 	}
+ 
+ 	/* We are already in VLAN promisc, nothing to do */
+ 	if (adapter->flags2 & IXGBE_FLAG2_VLAN_PROMISC)
+ 		return;
+ 
+ 	/* Set flag so we don't redo unnecessary work */
+ 	adapter->flags2 |= IXGBE_FLAG2_VLAN_PROMISC;
+ 
+ 	/* Add PF to all active pools */
+ 	for (i = IXGBE_VLVF_ENTRIES; --i;) {
+ 		u32 reg_offset = IXGBE_VLVFB(i * 2 + VMDQ_P(0) / 32);
+ 		u32 vlvfb = IXGBE_READ_REG(hw, reg_offset);
+ 
+ 		vlvfb |= BIT(VMDQ_P(0) % 32);
+ 		IXGBE_WRITE_REG(hw, reg_offset, vlvfb);
+ 	}
+ 
+ 	/* Set all bits in the VLAN filter table array */
+ 	for (i = hw->mac.vft_size; i--;)
+ 		IXGBE_WRITE_REG(hw, IXGBE_VFTA(i), ~0U);
+ }
+ 
+ #define VFTA_BLOCK_SIZE 8
+ static void ixgbe_scrub_vfta(struct ixgbe_adapter *adapter, u32 vfta_offset)
+ {
+ 	struct ixgbe_hw *hw = &adapter->hw;
+ 	u32 vfta[VFTA_BLOCK_SIZE] = { 0 };
+ 	u32 vid_start = vfta_offset * 32;
+ 	u32 vid_end = vid_start + (VFTA_BLOCK_SIZE * 32);
+ 	u32 i, vid, word, bits;
+ 
+ 	for (i = IXGBE_VLVF_ENTRIES; --i;) {
+ 		u32 vlvf = IXGBE_READ_REG(hw, IXGBE_VLVF(i));
+ 
+ 		/* pull VLAN ID from VLVF */
+ 		vid = vlvf & VLAN_VID_MASK;
+ 
+ 		/* only concern outselves with a certain range */
+ 		if (vid < vid_start || vid >= vid_end)
+ 			continue;
+ 
+ 		if (vlvf) {
+ 			/* record VLAN ID in VFTA */
+ 			vfta[(vid - vid_start) / 32] |= BIT(vid % 32);
+ 
+ 			/* if PF is part of this then continue */
+ 			if (test_bit(vid, adapter->active_vlans))
+ 				continue;
+ 		}
+ 
+ 		/* remove PF from the pool */
+ 		word = i * 2 + VMDQ_P(0) / 32;
+ 		bits = ~BIT(VMDQ_P(0) % 32);
+ 		bits &= IXGBE_READ_REG(hw, IXGBE_VLVFB(word));
+ 		IXGBE_WRITE_REG(hw, IXGBE_VLVFB(word), bits);
+ 	}
+ 
+ 	/* extract values from active_vlans and write back to VFTA */
+ 	for (i = VFTA_BLOCK_SIZE; i--;) {
+ 		vid = (vfta_offset + i) * 32;
+ 		word = vid / BITS_PER_LONG;
+ 		bits = vid % BITS_PER_LONG;
+ 
+ 		vfta[i] |= adapter->active_vlans[word] >> bits;
+ 
+ 		IXGBE_WRITE_REG(hw, IXGBE_VFTA(vfta_offset + i), vfta[i]);
+ 	}
+ }
+ 
+ static void ixgbe_vlan_promisc_disable(struct ixgbe_adapter *adapter)
+ {
+ 	struct ixgbe_hw *hw = &adapter->hw;
+ 	u32 vlnctrl, i;
+ 
+ 	switch (hw->mac.type) {
+ 	case ixgbe_mac_82599EB:
+ 	case ixgbe_mac_X540:
+ 	case ixgbe_mac_X550:
+ 	case ixgbe_mac_X550EM_x:
+ 	case ixgbe_mac_x550em_a:
+ 	default:
+ 		if (adapter->flags & IXGBE_FLAG_VMDQ_ENABLED)
+ 			break;
+ 		/* fall through */
+ 	case ixgbe_mac_82598EB:
+ 		vlnctrl = IXGBE_READ_REG(hw, IXGBE_VLNCTRL);
+ 		vlnctrl &= ~IXGBE_VLNCTRL_CFIEN;
+ 		vlnctrl |= IXGBE_VLNCTRL_VFE;
+ 		IXGBE_WRITE_REG(hw, IXGBE_VLNCTRL, vlnctrl);
+ 		return;
+ 	}
+ 
+ 	/* We are not in VLAN promisc, nothing to do */
+ 	if (!(adapter->flags2 & IXGBE_FLAG2_VLAN_PROMISC))
+ 		return;
+ 
+ 	/* Set flag so we don't redo unnecessary work */
+ 	adapter->flags2 &= ~IXGBE_FLAG2_VLAN_PROMISC;
+ 
+ 	for (i = 0; i < hw->mac.vft_size; i += VFTA_BLOCK_SIZE)
+ 		ixgbe_scrub_vfta(adapter, i);
+ }
+ 
++>>>>>>> b4f47a483045 (ixgbe: use BIT() macro)
  static void ixgbe_restore_vlan(struct ixgbe_adapter *adapter)
  {
  	u16 vid = 1;
@@@ -4586,6 -4823,215 +4714,218 @@@ static void ixgbe_fdir_filter_restore(s
  	spin_unlock(&adapter->fdir_perfect_lock);
  }
  
++<<<<<<< HEAD
++=======
+ static void ixgbe_macvlan_set_rx_mode(struct net_device *dev, unsigned int pool,
+ 				      struct ixgbe_adapter *adapter)
+ {
+ 	struct ixgbe_hw *hw = &adapter->hw;
+ 	u32 vmolr;
+ 
+ 	/* No unicast promiscuous support for VMDQ devices. */
+ 	vmolr = IXGBE_READ_REG(hw, IXGBE_VMOLR(pool));
+ 	vmolr |= (IXGBE_VMOLR_ROMPE | IXGBE_VMOLR_BAM | IXGBE_VMOLR_AUPE);
+ 
+ 	/* clear the affected bit */
+ 	vmolr &= ~IXGBE_VMOLR_MPE;
+ 
+ 	if (dev->flags & IFF_ALLMULTI) {
+ 		vmolr |= IXGBE_VMOLR_MPE;
+ 	} else {
+ 		vmolr |= IXGBE_VMOLR_ROMPE;
+ 		hw->mac.ops.update_mc_addr_list(hw, dev);
+ 	}
+ 	ixgbe_write_uc_addr_list(adapter->netdev, pool);
+ 	IXGBE_WRITE_REG(hw, IXGBE_VMOLR(pool), vmolr);
+ }
+ 
+ static void ixgbe_fwd_psrtype(struct ixgbe_fwd_adapter *vadapter)
+ {
+ 	struct ixgbe_adapter *adapter = vadapter->real_adapter;
+ 	int rss_i = adapter->num_rx_queues_per_pool;
+ 	struct ixgbe_hw *hw = &adapter->hw;
+ 	u16 pool = vadapter->pool;
+ 	u32 psrtype = IXGBE_PSRTYPE_TCPHDR |
+ 		      IXGBE_PSRTYPE_UDPHDR |
+ 		      IXGBE_PSRTYPE_IPV4HDR |
+ 		      IXGBE_PSRTYPE_L2HDR |
+ 		      IXGBE_PSRTYPE_IPV6HDR;
+ 
+ 	if (hw->mac.type == ixgbe_mac_82598EB)
+ 		return;
+ 
+ 	if (rss_i > 3)
+ 		psrtype |= 2u << 29;
+ 	else if (rss_i > 1)
+ 		psrtype |= 1u << 29;
+ 
+ 	IXGBE_WRITE_REG(hw, IXGBE_PSRTYPE(VMDQ_P(pool)), psrtype);
+ }
+ 
+ /**
+  * ixgbe_clean_rx_ring - Free Rx Buffers per Queue
+  * @rx_ring: ring to free buffers from
+  **/
+ static void ixgbe_clean_rx_ring(struct ixgbe_ring *rx_ring)
+ {
+ 	struct device *dev = rx_ring->dev;
+ 	unsigned long size;
+ 	u16 i;
+ 
+ 	/* ring already cleared, nothing to do */
+ 	if (!rx_ring->rx_buffer_info)
+ 		return;
+ 
+ 	/* Free all the Rx ring sk_buffs */
+ 	for (i = 0; i < rx_ring->count; i++) {
+ 		struct ixgbe_rx_buffer *rx_buffer = &rx_ring->rx_buffer_info[i];
+ 
+ 		if (rx_buffer->skb) {
+ 			struct sk_buff *skb = rx_buffer->skb;
+ 			if (IXGBE_CB(skb)->page_released)
+ 				dma_unmap_page(dev,
+ 					       IXGBE_CB(skb)->dma,
+ 					       ixgbe_rx_bufsz(rx_ring),
+ 					       DMA_FROM_DEVICE);
+ 			dev_kfree_skb(skb);
+ 			rx_buffer->skb = NULL;
+ 		}
+ 
+ 		if (!rx_buffer->page)
+ 			continue;
+ 
+ 		dma_unmap_page(dev, rx_buffer->dma,
+ 			       ixgbe_rx_pg_size(rx_ring), DMA_FROM_DEVICE);
+ 		__free_pages(rx_buffer->page, ixgbe_rx_pg_order(rx_ring));
+ 
+ 		rx_buffer->page = NULL;
+ 	}
+ 
+ 	size = sizeof(struct ixgbe_rx_buffer) * rx_ring->count;
+ 	memset(rx_ring->rx_buffer_info, 0, size);
+ 
+ 	/* Zero out the descriptor ring */
+ 	memset(rx_ring->desc, 0, rx_ring->size);
+ 
+ 	rx_ring->next_to_alloc = 0;
+ 	rx_ring->next_to_clean = 0;
+ 	rx_ring->next_to_use = 0;
+ }
+ 
+ static void ixgbe_disable_fwd_ring(struct ixgbe_fwd_adapter *vadapter,
+ 				   struct ixgbe_ring *rx_ring)
+ {
+ 	struct ixgbe_adapter *adapter = vadapter->real_adapter;
+ 	int index = rx_ring->queue_index + vadapter->rx_base_queue;
+ 
+ 	/* shutdown specific queue receive and wait for dma to settle */
+ 	ixgbe_disable_rx_queue(adapter, rx_ring);
+ 	usleep_range(10000, 20000);
+ 	ixgbe_irq_disable_queues(adapter, BIT_ULL(index));
+ 	ixgbe_clean_rx_ring(rx_ring);
+ 	rx_ring->l2_accel_priv = NULL;
+ }
+ 
+ static int ixgbe_fwd_ring_down(struct net_device *vdev,
+ 			       struct ixgbe_fwd_adapter *accel)
+ {
+ 	struct ixgbe_adapter *adapter = accel->real_adapter;
+ 	unsigned int rxbase = accel->rx_base_queue;
+ 	unsigned int txbase = accel->tx_base_queue;
+ 	int i;
+ 
+ 	netif_tx_stop_all_queues(vdev);
+ 
+ 	for (i = 0; i < adapter->num_rx_queues_per_pool; i++) {
+ 		ixgbe_disable_fwd_ring(accel, adapter->rx_ring[rxbase + i]);
+ 		adapter->rx_ring[rxbase + i]->netdev = adapter->netdev;
+ 	}
+ 
+ 	for (i = 0; i < adapter->num_rx_queues_per_pool; i++) {
+ 		adapter->tx_ring[txbase + i]->l2_accel_priv = NULL;
+ 		adapter->tx_ring[txbase + i]->netdev = adapter->netdev;
+ 	}
+ 
+ 
+ 	return 0;
+ }
+ 
+ static int ixgbe_fwd_ring_up(struct net_device *vdev,
+ 			     struct ixgbe_fwd_adapter *accel)
+ {
+ 	struct ixgbe_adapter *adapter = accel->real_adapter;
+ 	unsigned int rxbase, txbase, queues;
+ 	int i, baseq, err = 0;
+ 
+ 	if (!test_bit(accel->pool, &adapter->fwd_bitmask))
+ 		return 0;
+ 
+ 	baseq = accel->pool * adapter->num_rx_queues_per_pool;
+ 	netdev_dbg(vdev, "pool %i:%i queues %i:%i VSI bitmask %lx\n",
+ 		   accel->pool, adapter->num_rx_pools,
+ 		   baseq, baseq + adapter->num_rx_queues_per_pool,
+ 		   adapter->fwd_bitmask);
+ 
+ 	accel->netdev = vdev;
+ 	accel->rx_base_queue = rxbase = baseq;
+ 	accel->tx_base_queue = txbase = baseq;
+ 
+ 	for (i = 0; i < adapter->num_rx_queues_per_pool; i++)
+ 		ixgbe_disable_fwd_ring(accel, adapter->rx_ring[rxbase + i]);
+ 
+ 	for (i = 0; i < adapter->num_rx_queues_per_pool; i++) {
+ 		adapter->rx_ring[rxbase + i]->netdev = vdev;
+ 		adapter->rx_ring[rxbase + i]->l2_accel_priv = accel;
+ 		ixgbe_configure_rx_ring(adapter, adapter->rx_ring[rxbase + i]);
+ 	}
+ 
+ 	for (i = 0; i < adapter->num_rx_queues_per_pool; i++) {
+ 		adapter->tx_ring[txbase + i]->netdev = vdev;
+ 		adapter->tx_ring[txbase + i]->l2_accel_priv = accel;
+ 	}
+ 
+ 	queues = min_t(unsigned int,
+ 		       adapter->num_rx_queues_per_pool, vdev->num_tx_queues);
+ 	err = netif_set_real_num_tx_queues(vdev, queues);
+ 	if (err)
+ 		goto fwd_queue_err;
+ 
+ 	err = netif_set_real_num_rx_queues(vdev, queues);
+ 	if (err)
+ 		goto fwd_queue_err;
+ 
+ 	if (is_valid_ether_addr(vdev->dev_addr))
+ 		ixgbe_add_mac_filter(adapter, vdev->dev_addr, accel->pool);
+ 
+ 	ixgbe_fwd_psrtype(accel);
+ 	ixgbe_macvlan_set_rx_mode(vdev, accel->pool, adapter);
+ 	return err;
+ fwd_queue_err:
+ 	ixgbe_fwd_ring_down(vdev, accel);
+ 	return err;
+ }
+ 
+ static void ixgbe_configure_dfwd(struct ixgbe_adapter *adapter)
+ {
+ 	struct net_device *upper;
+ 	struct list_head *iter;
+ 	int err;
+ 
+ 	netdev_for_each_all_upper_dev_rcu(adapter->netdev, upper, iter) {
+ 		if (netif_is_macvlan(upper)) {
+ 			struct macvlan_dev *dfwd = netdev_priv(upper);
+ 			struct ixgbe_fwd_adapter *vadapter = dfwd->fwd_priv;
+ 
+ 			if (dfwd->fwd_priv) {
+ 				err = ixgbe_fwd_ring_up(upper, vadapter);
+ 				if (err)
+ 					continue;
+ 			}
+ 		}
+ 	}
+ }
+ 
++>>>>>>> b4f47a483045 (ixgbe: use BIT() macro)
  static void ixgbe_configure(struct ixgbe_adapter *adapter)
  {
  	struct ixgbe_hw *hw = &adapter->hw;
diff --cc drivers/net/ethernet/intel/ixgbe/ixgbe_ptp.c
index e5ba04025e2b,e5431bfe3339..000000000000
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_ptp.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_ptp.c
@@@ -235,12 -388,16 +235,17 @@@ static int ixgbe_ptp_adjfreq(struct ptp
  
  	switch (hw->mac.type) {
  	case ixgbe_mac_X540:
 -		if (incval > 0xFFFFFFFFULL)
 -			e_dev_warn("PTP ppb adjusted SYSTIME rate overflowed!\n");
 -		IXGBE_WRITE_REG(hw, IXGBE_TIMINCA, (u32)incval);
 +		IXGBE_WRITE_REG(hw, IXGBE_TIMINCA, incval);
  		break;
  	case ixgbe_mac_82599EB:
 -		if (incval > 0x00FFFFFFULL)
 -			e_dev_warn("PTP ppb adjusted SYSTIME rate overflowed!\n");
  		IXGBE_WRITE_REG(hw, IXGBE_TIMINCA,
++<<<<<<< HEAD
 +				(1 << IXGBE_INCPER_SHIFT_82599) |
 +				incval);
++=======
+ 				BIT(IXGBE_INCPER_SHIFT_82599) |
+ 				((u32)incval & 0x00FFFFFFUL));
++>>>>>>> b4f47a483045 (ixgbe: use BIT() macro)
  		break;
  	default:
  		break;
@@@ -770,11 -1105,16 +775,15 @@@ void ixgbe_ptp_start_cyclecounter(struc
  		IXGBE_WRITE_REG(hw, IXGBE_TIMINCA, incval);
  		break;
  	case ixgbe_mac_82599EB:
 -		cc.read = ixgbe_ptp_read_82599;
 -
 -		ixgbe_ptp_link_speed_adjust(adapter, &cc.shift, &incval);
  		incval >>= IXGBE_INCVAL_SHIFT_82599;
 -		cc.shift -= IXGBE_INCVAL_SHIFT_82599;
 +		shift -= IXGBE_INCVAL_SHIFT_82599;
  		IXGBE_WRITE_REG(hw, IXGBE_TIMINCA,
++<<<<<<< HEAD
 +				(1 << IXGBE_INCPER_SHIFT_82599) |
 +				incval);
++=======
+ 				BIT(IXGBE_INCPER_SHIFT_82599) | incval);
++>>>>>>> b4f47a483045 (ixgbe: use BIT() macro)
  		break;
  	default:
  		/* other devices aren't supported */
diff --cc drivers/net/ethernet/intel/ixgbe/ixgbe_type.h
index 0232cb641add,7af451460374..000000000000
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_type.h
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_type.h
@@@ -3534,46 -3597,54 +3534,74 @@@ struct ixgbe_info 
  #define IXGBE_KRM_TX_COEFF_CTRL_1(P)	((P) ? 0x9520 : 0x5520)
  #define IXGBE_KRM_RX_ANA_CTL(P)		((P) ? 0x9A00 : 0x5A00)
  
- #define IXGBE_KRM_PORT_CAR_GEN_CTRL_NELB_32B		(1 << 9)
- #define IXGBE_KRM_PORT_CAR_GEN_CTRL_NELB_KRPCS		(1 << 11)
+ #define IXGBE_KRM_PORT_CAR_GEN_CTRL_NELB_32B		BIT(9)
+ #define IXGBE_KRM_PORT_CAR_GEN_CTRL_NELB_KRPCS		BIT(11)
  
++<<<<<<< HEAD
 +#define IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_MASK	(0x7 << 8)
 +#define IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_1G	(2 << 8)
 +#define IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_10G	(4 << 8)
 +#define IXGBE_KRM_LINK_CTRL_1_TETH_AN_FEC_REQ		(1 << 14)
 +#define IXGBE_KRM_LINK_CTRL_1_TETH_AN_CAP_FEC		(1 << 15)
 +#define IXGBE_KRM_LINK_CTRL_1_TETH_AN_CAP_KX		(1 << 16)
 +#define IXGBE_KRM_LINK_CTRL_1_TETH_AN_CAP_KR		(1 << 18)
 +#define IXGBE_KRM_LINK_CTRL_1_TETH_EEE_CAP_KX		(1 << 24)
 +#define IXGBE_KRM_LINK_CTRL_1_TETH_EEE_CAP_KR		(1 << 26)
 +#define IXGBE_KRM_LINK_CTRL_1_TETH_AN_ENABLE		(1 << 29)
 +#define IXGBE_KRM_LINK_CTRL_1_TETH_AN_RESTART		(1 << 31)
- 
- #define IXGBE_KRM_AN_CNTL_1_SYM_PAUSE			(1 << 28)
- #define IXGBE_KRM_AN_CNTL_1_ASM_PAUSE			(1 << 29)
- 
++=======
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_MASK	(7u << 8)
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_1G	(2u << 8)
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_FORCE_SPEED_10G	(4u << 8)
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_SGMII_EN		BIT(12)
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_CLAUSE_37_EN	BIT(13)
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_FEC_REQ		BIT(14)
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_CAP_FEC		BIT(15)
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_CAP_KX		BIT(16)
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_CAP_KR		BIT(18)
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_EEE_CAP_KX		BIT(24)
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_EEE_CAP_KR		BIT(26)
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_ENABLE		BIT(29)
+ #define IXGBE_KRM_LINK_CTRL_1_TETH_AN_RESTART		BIT(31)
++>>>>>>> b4f47a483045 (ixgbe: use BIT() macro)
+ 
+ #define IXGBE_KRM_AN_CNTL_1_SYM_PAUSE			BIT(28)
+ #define IXGBE_KRM_AN_CNTL_1_ASM_PAUSE			BIT(29)
+ 
++<<<<<<< HEAD
 +#define IXGBE_KRM_DSP_TXFFE_STATE_C0_EN			(1 << 6)
 +#define IXGBE_KRM_DSP_TXFFE_STATE_CP1_CN1_EN		(1 << 15)
 +#define IXGBE_KRM_DSP_TXFFE_STATE_CO_ADAPT_EN		(1 << 16)
++=======
+ #define IXGBE_KRM_AN_CNTL_8_LINEAR			BIT(0)
+ #define IXGBE_KRM_AN_CNTL_8_LIMITING			BIT(1)
+ 
+ #define IXGBE_KRM_SGMII_CTRL_MAC_TAR_FORCE_100_D	BIT(12)
+ #define IXGBE_KRM_SGMII_CTRL_MAC_TAR_FORCE_10_D		BIT(19)
+ 
+ #define IXGBE_KRM_DSP_TXFFE_STATE_C0_EN			BIT(6)
+ #define IXGBE_KRM_DSP_TXFFE_STATE_CP1_CN1_EN		BIT(15)
+ #define IXGBE_KRM_DSP_TXFFE_STATE_CO_ADAPT_EN		BIT(16)
++>>>>>>> b4f47a483045 (ixgbe: use BIT() macro)
  
- #define IXGBE_KRM_RX_TRN_LINKUP_CTRL_CONV_WO_PROTOCOL	(1 << 4)
- #define IXGBE_KRM_RX_TRN_LINKUP_CTRL_PROTOCOL_BYPASS	(1 << 2)
+ #define IXGBE_KRM_RX_TRN_LINKUP_CTRL_CONV_WO_PROTOCOL	BIT(4)
+ #define IXGBE_KRM_RX_TRN_LINKUP_CTRL_PROTOCOL_BYPASS	BIT(2)
  
- #define IXGBE_KRM_PMD_DFX_BURNIN_TX_RX_KR_LB_MASK	(0x3 << 16)
+ #define IXGBE_KRM_PMD_DFX_BURNIN_TX_RX_KR_LB_MASK	(3u << 16)
  
- #define IXGBE_KRM_TX_COEFF_CTRL_1_CMINUS1_OVRRD_EN	(1 << 1)
- #define IXGBE_KRM_TX_COEFF_CTRL_1_CPLUS1_OVRRD_EN	(1 << 2)
- #define IXGBE_KRM_TX_COEFF_CTRL_1_CZERO_EN		(1 << 3)
- #define IXGBE_KRM_TX_COEFF_CTRL_1_OVRRD_EN		(1 << 31)
+ #define IXGBE_KRM_TX_COEFF_CTRL_1_CMINUS1_OVRRD_EN	BIT(1)
+ #define IXGBE_KRM_TX_COEFF_CTRL_1_CPLUS1_OVRRD_EN	BIT(2)
+ #define IXGBE_KRM_TX_COEFF_CTRL_1_CZERO_EN		BIT(3)
+ #define IXGBE_KRM_TX_COEFF_CTRL_1_OVRRD_EN		BIT(31)
  
  #define IXGBE_KX4_LINK_CNTL_1				0x4C
- #define IXGBE_KX4_LINK_CNTL_1_TETH_AN_CAP_KX		(1 << 16)
- #define IXGBE_KX4_LINK_CNTL_1_TETH_AN_CAP_KX4		(1 << 17)
- #define IXGBE_KX4_LINK_CNTL_1_TETH_EEE_CAP_KX		(1 << 24)
- #define IXGBE_KX4_LINK_CNTL_1_TETH_EEE_CAP_KX4		(1 << 25)
- #define IXGBE_KX4_LINK_CNTL_1_TETH_AN_ENABLE		(1 << 29)
- #define IXGBE_KX4_LINK_CNTL_1_TETH_FORCE_LINK_UP	(1 << 30)
- #define IXGBE_KX4_LINK_CNTL_1_TETH_AN_RESTART		(1 << 31)
+ #define IXGBE_KX4_LINK_CNTL_1_TETH_AN_CAP_KX		BIT(16)
+ #define IXGBE_KX4_LINK_CNTL_1_TETH_AN_CAP_KX4		BIT(17)
+ #define IXGBE_KX4_LINK_CNTL_1_TETH_EEE_CAP_KX		BIT(24)
+ #define IXGBE_KX4_LINK_CNTL_1_TETH_EEE_CAP_KX4		BIT(25)
+ #define IXGBE_KX4_LINK_CNTL_1_TETH_AN_ENABLE		BIT(29)
+ #define IXGBE_KX4_LINK_CNTL_1_TETH_FORCE_LINK_UP	BIT(30)
+ #define IXGBE_KX4_LINK_CNTL_1_TETH_AN_RESTART		BIT(31)
  
  #define IXGBE_SB_IOSF_INDIRECT_CTRL		0x00011144
  #define IXGBE_SB_IOSF_INDIRECT_DATA		0x00011148
* Unmerged path drivers/net/ethernet/intel/ixgbe/ixgbe.h
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c
index 028e11aeb7b8..485b8dd01d7d 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_82598.c
@@ -792,7 +792,7 @@ mac_reset_top:
 	}
 
 	gheccr = IXGBE_READ_REG(hw, IXGBE_GHECCR);
-	gheccr &= ~((1 << 21) | (1 << 18) | (1 << 9) | (1 << 6));
+	gheccr &= ~(BIT(21) | BIT(18) | BIT(9) | BIT(6));
 	IXGBE_WRITE_REG(hw, IXGBE_GHECCR, gheccr);
 
 	/*
@@ -914,10 +914,10 @@ static s32 ixgbe_set_vfta_82598(struct ixgbe_hw *hw, u32 vlan, u32 vind,
 	bits = IXGBE_READ_REG(hw, IXGBE_VFTA(regindex));
 	if (vlan_on)
 		/* Turn on this VLAN id */
-		bits |= (1 << bitindex);
+		bits |= BIT(bitindex);
 	else
 		/* Turn off this VLAN id */
-		bits &= ~(1 << bitindex);
+		bits &= ~BIT(bitindex);
 	IXGBE_WRITE_REG(hw, IXGBE_VFTA(regindex), bits);
 
 	return 0;
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_82599.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_82599.c
index 7724953735ff..4bc3dccd4959 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_82599.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_82599.c
@@ -1296,17 +1296,17 @@ s32 ixgbe_init_fdir_perfect_82599(struct ixgbe_hw *hw, u32 fdirctrl)
 #define IXGBE_COMPUTE_SIG_HASH_ITERATION(_n) \
 do { \
 	u32 n = (_n); \
-	if (IXGBE_ATR_COMMON_HASH_KEY & (0x01 << n)) \
+	if (IXGBE_ATR_COMMON_HASH_KEY & BIT(n)) \
 		common_hash ^= lo_hash_dword >> n; \
-	else if (IXGBE_ATR_BUCKET_HASH_KEY & (0x01 << n)) \
+	else if (IXGBE_ATR_BUCKET_HASH_KEY & BIT(n)) \
 		bucket_hash ^= lo_hash_dword >> n; \
-	else if (IXGBE_ATR_SIGNATURE_HASH_KEY & (0x01 << n)) \
+	else if (IXGBE_ATR_SIGNATURE_HASH_KEY & BIT(n)) \
 		sig_hash ^= lo_hash_dword << (16 - n); \
-	if (IXGBE_ATR_COMMON_HASH_KEY & (0x01 << (n + 16))) \
+	if (IXGBE_ATR_COMMON_HASH_KEY & BIT(n + 16)) \
 		common_hash ^= hi_hash_dword >> n; \
-	else if (IXGBE_ATR_BUCKET_HASH_KEY & (0x01 << (n + 16))) \
+	else if (IXGBE_ATR_BUCKET_HASH_KEY & BIT(n + 16)) \
 		bucket_hash ^= hi_hash_dword >> n; \
-	else if (IXGBE_ATR_SIGNATURE_HASH_KEY & (0x01 << (n + 16))) \
+	else if (IXGBE_ATR_SIGNATURE_HASH_KEY & BIT(n + 16)) \
 		sig_hash ^= hi_hash_dword << (16 - n); \
 } while (0)
 
@@ -1430,9 +1430,9 @@ s32 ixgbe_fdir_add_signature_filter_82599(struct ixgbe_hw *hw,
 #define IXGBE_COMPUTE_BKT_HASH_ITERATION(_n) \
 do { \
 	u32 n = (_n); \
-	if (IXGBE_ATR_BUCKET_HASH_KEY & (0x01 << n)) \
+	if (IXGBE_ATR_BUCKET_HASH_KEY & BIT(n)) \
 		bucket_hash ^= lo_hash_dword >> n; \
-	if (IXGBE_ATR_BUCKET_HASH_KEY & (0x01 << (n + 16))) \
+	if (IXGBE_ATR_BUCKET_HASH_KEY & BIT(n + 16)) \
 		bucket_hash ^= hi_hash_dword >> n; \
 } while (0)
 
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_common.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_common.c
index 04f6be073802..174cfeb1841f 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_common.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_common.c
@@ -825,8 +825,8 @@ s32 ixgbe_init_eeprom_params_generic(struct ixgbe_hw *hw)
 			 */
 			eeprom_size = (u16)((eec & IXGBE_EEC_SIZE) >>
 					    IXGBE_EEC_SIZE_SHIFT);
-			eeprom->word_size = 1 << (eeprom_size +
-						  IXGBE_EEPROM_WORD_SIZE_SHIFT);
+			eeprom->word_size = BIT(eeprom_size +
+						 IXGBE_EEPROM_WORD_SIZE_SHIFT);
 		}
 
 		if (eec & IXGBE_EEC_ADDR_SIZE)
@@ -1502,7 +1502,7 @@ static void ixgbe_shift_out_eeprom_bits(struct ixgbe_hw *hw, u16 data,
 	 * Mask is used to shift "count" bits of "data" out to the EEPROM
 	 * one bit at a time.  Determine the starting bit based on count
 	 */
-	mask = 0x01 << (count - 1);
+	mask = BIT(count - 1);
 
 	for (i = 0; i < count; i++) {
 		/*
@@ -1991,7 +1991,7 @@ static void ixgbe_set_mta(struct ixgbe_hw *hw, u8 *mc_addr)
 	 */
 	vector_reg = (vector >> 5) & 0x7F;
 	vector_bit = vector & 0x1F;
-	hw->mac.mta_shadow[vector_reg] |= (1 << vector_bit);
+	hw->mac.mta_shadow[vector_reg] |= BIT(vector_bit);
 }
 
 /**
@@ -2920,10 +2920,10 @@ s32 ixgbe_clear_vmdq_generic(struct ixgbe_hw *hw, u32 rar, u32 vmdq)
 			mpsar_hi = 0;
 		}
 	} else if (vmdq < 32) {
-		mpsar_lo &= ~(1 << vmdq);
+		mpsar_lo &= ~BIT(vmdq);
 		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_LO(rar), mpsar_lo);
 	} else {
-		mpsar_hi &= ~(1 << (vmdq - 32));
+		mpsar_hi &= ~BIT(vmdq - 32);
 		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_HI(rar), mpsar_hi);
 	}
 
@@ -2952,11 +2952,11 @@ s32 ixgbe_set_vmdq_generic(struct ixgbe_hw *hw, u32 rar, u32 vmdq)
 
 	if (vmdq < 32) {
 		mpsar = IXGBE_READ_REG(hw, IXGBE_MPSAR_LO(rar));
-		mpsar |= 1 << vmdq;
+		mpsar |= BIT(vmdq);
 		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_LO(rar), mpsar);
 	} else {
 		mpsar = IXGBE_READ_REG(hw, IXGBE_MPSAR_HI(rar));
-		mpsar |= 1 << (vmdq - 32);
+		mpsar |= BIT(vmdq - 32);
 		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_HI(rar), mpsar);
 	}
 	return 0;
@@ -2977,11 +2977,11 @@ s32 ixgbe_set_vmdq_san_mac_generic(struct ixgbe_hw *hw, u32 vmdq)
 	u32 rar = hw->mac.san_mac_rar_index;
 
 	if (vmdq < 32) {
-		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_LO(rar), 1 << vmdq);
+		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_LO(rar), BIT(vmdq));
 		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_HI(rar), 0);
 	} else {
 		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_LO(rar), 0);
-		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_HI(rar), 1 << (vmdq - 32));
+		IXGBE_WRITE_REG(hw, IXGBE_MPSAR_HI(rar), BIT(vmdq - 32));
 	}
 
 	return 0;
@@ -3081,7 +3081,7 @@ s32 ixgbe_set_vfta_generic(struct ixgbe_hw *hw, u32 vlan, u32 vind,
 	 *    bits[4-0]:  which bit in the register
 	 */
 	regidx = vlan / 32;
-	vfta_delta = 1 << (vlan % 32);
+	vfta_delta = BIT(vlan % 32);
 	vfta = IXGBE_READ_REG(hw, IXGBE_VFTA(regidx));
 
 	/* vfta_delta represents the difference between the current value
@@ -3112,12 +3112,12 @@ s32 ixgbe_set_vfta_generic(struct ixgbe_hw *hw, u32 vlan, u32 vind,
 	bits = IXGBE_READ_REG(hw, IXGBE_VLVFB(vlvf_index * 2 + vind / 32));
 
 	/* set the pool bit */
-	bits |= 1 << (vind % 32);
+	bits |= BIT(vind % 32);
 	if (vlan_on)
 		goto vlvf_update;
 
 	/* clear the pool bit */
-	bits ^= 1 << (vind % 32);
+	bits ^= BIT(vind % 32);
 
 	if (!bits &&
 	    !IXGBE_READ_REG(hw, IXGBE_VLVFB(vlvf_index * 2 + 1 - vind / 32))) {
@@ -3348,9 +3348,9 @@ void ixgbe_set_vlan_anti_spoofing(struct ixgbe_hw *hw, bool enable, int vf)
 
 	pfvfspoof = IXGBE_READ_REG(hw, IXGBE_PFVFSPOOF(vf_target_reg));
 	if (enable)
-		pfvfspoof |= (1 << vf_target_shift);
+		pfvfspoof |= BIT(vf_target_shift);
 	else
-		pfvfspoof &= ~(1 << vf_target_shift);
+		pfvfspoof &= ~BIT(vf_target_shift);
 	IXGBE_WRITE_REG(hw, IXGBE_PFVFSPOOF(vf_target_reg), pfvfspoof);
 }
 
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb.c
index 02c7333a9c83..b1411ebd50b5 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb.c
@@ -186,7 +186,7 @@ void ixgbe_dcb_unpack_pfc(struct ixgbe_dcb_config *cfg, u8 *pfc_en)
 
 	for (*pfc_en = 0, tc = 0; tc < MAX_TRAFFIC_CLASS; tc++) {
 		if (tc_config[tc].dcb_pfc != pfc_disabled)
-			*pfc_en |= 1 << tc;
+			*pfc_en |= BIT(tc);
 	}
 }
 
@@ -232,7 +232,7 @@ void ixgbe_dcb_unpack_prio(struct ixgbe_dcb_config *cfg, int direction,
 u8 ixgbe_dcb_get_tc_from_up(struct ixgbe_dcb_config *cfg, int direction, u8 up)
 {
 	struct tc_configuration *tc_config = &cfg->tc_config[0];
-	u8 prio_mask = 1 << up;
+	u8 prio_mask = BIT(up);
 	u8 tc = cfg->num_tcs.pg_tcs;
 
 	/* If tc is 0 then DCB is likely not enabled or supported */
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb_82598.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb_82598.c
index d3ba63f9ad37..b79e93a5b699 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb_82598.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb_82598.c
@@ -210,7 +210,7 @@ s32 ixgbe_dcb_config_pfc_82598(struct ixgbe_hw *hw, u8 pfc_en)
 
 	/* Configure PFC Tx thresholds per TC */
 	for (i = 0; i < MAX_TRAFFIC_CLASS; i++) {
-		if (!(pfc_en & (1 << i))) {
+		if (!(pfc_en & BIT(i))) {
 			IXGBE_WRITE_REG(hw, IXGBE_FCRTL(i), 0);
 			IXGBE_WRITE_REG(hw, IXGBE_FCRTH(i), 0);
 			continue;
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb_82599.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb_82599.c
index b5cc989a3d23..1011d644978f 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb_82599.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb_82599.c
@@ -248,7 +248,7 @@ s32 ixgbe_dcb_config_pfc_82599(struct ixgbe_hw *hw, u8 pfc_en, u8 *prio_tc)
 		int enabled = 0;
 
 		for (j = 0; j < MAX_USER_PRIORITY; j++) {
-			if ((prio_tc[j] == i) && (pfc_en & (1 << j))) {
+			if ((prio_tc[j] == i) && (pfc_en & BIT(j))) {
 				enabled = 1;
 				break;
 			}
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb_nl.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb_nl.c
index 44fc939b64fb..ce65f79ed796 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb_nl.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_dcb_nl.c
@@ -62,7 +62,7 @@ static int ixgbe_copy_dcb_cfg(struct ixgbe_adapter *adapter, int tc_max)
 			     };
 	u8 up = dcb_getapp(adapter->netdev, &app);
 
-	if (up && !(up & (1 << adapter->fcoe.up)))
+	if (up && !(up & BIT(adapter->fcoe.up)))
 		changes |= BIT_APP_UPCHG;
 #endif
 
@@ -657,7 +657,7 @@ static int ixgbe_dcbnl_ieee_setapp(struct net_device *dev,
 	    app->protocol == ETH_P_FCOE) {
 		u8 app_mask = dcb_ieee_getapp_mask(dev, app);
 
-		if (app_mask & (1 << adapter->fcoe.up))
+		if (app_mask & BIT(adapter->fcoe.up))
 			return 0;
 
 		adapter->fcoe.up = app->priority;
@@ -700,7 +700,7 @@ static int ixgbe_dcbnl_ieee_delapp(struct net_device *dev,
 	    app->protocol == ETH_P_FCOE) {
 		u8 app_mask = dcb_ieee_getapp_mask(dev, app);
 
-		if (app_mask & (1 << adapter->fcoe.up))
+		if (app_mask & BIT(adapter->fcoe.up))
 			return 0;
 
 		adapter->fcoe.up = app_mask ?
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_ethtool.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_ethtool.c
index 6f0c5798a192..b00a9b9a41d2 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_ethtool.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_ethtool.c
@@ -1591,7 +1591,7 @@ static int ixgbe_intr_test(struct ixgbe_adapter *adapter, u64 *data)
 	/* Test each interrupt */
 	for (; i < 10; i++) {
 		/* Interrupt to test */
-		mask = 1 << i;
+		mask = BIT(i);
 
 		if (!shared_int) {
 			/*
@@ -3010,14 +3010,14 @@ static int ixgbe_get_ts_info(struct net_device *dev,
 			info->phc_index = -1;
 
 		info->tx_types =
-			(1 << HWTSTAMP_TX_OFF) |
-			(1 << HWTSTAMP_TX_ON);
+			BIT(HWTSTAMP_TX_OFF) |
+			BIT(HWTSTAMP_TX_ON);
 
 		info->rx_filters =
-			(1 << HWTSTAMP_FILTER_NONE) |
-			(1 << HWTSTAMP_FILTER_PTP_V1_L4_SYNC) |
-			(1 << HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ) |
-			(1 << HWTSTAMP_FILTER_PTP_V2_EVENT);
+			BIT(HWTSTAMP_FILTER_NONE) |
+			BIT(HWTSTAMP_FILTER_PTP_V1_L4_SYNC) |
+			BIT(HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ) |
+			BIT(HWTSTAMP_FILTER_PTP_V2_EVENT);
 		break;
 	default:
 		return ethtool_op_get_ts_info(dev, info);
* Unmerged path drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_mbx.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_mbx.c
index 9993a471d668..5c346e2dbb96 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_mbx.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_mbx.c
@@ -313,8 +313,8 @@ static s32 ixgbe_check_for_rst_pf(struct ixgbe_hw *hw, u16 vf_number)
 		break;
 	}
 
-	if (vflre & (1 << vf_shift)) {
-		IXGBE_WRITE_REG(hw, IXGBE_VFLREC(reg_offset), (1 << vf_shift));
+	if (vflre & BIT(vf_shift)) {
+		IXGBE_WRITE_REG(hw, IXGBE_VFLREC(reg_offset), BIT(vf_shift));
 		hw->mbx.stats.rsts++;
 		return 0;
 	}
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_phy.h b/drivers/net/ethernet/intel/ixgbe/ixgbe_phy.h
index 61dc71563bf9..c28c352394d3 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_phy.h
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_phy.h
@@ -103,7 +103,7 @@
 #define IXGBE_PE				0xE0	/* Port expander addr */
 #define IXGBE_PE_OUTPUT				1	/* Output reg offset */
 #define IXGBE_PE_CONFIG				3	/* Config reg offset */
-#define IXGBE_PE_BIT1				(1 << 1)
+#define IXGBE_PE_BIT1				BIT(1)
 
 /* Flow control defines */
 #define IXGBE_TAF_SYM_PAUSE                  0x400
* Unmerged path drivers/net/ethernet/intel/ixgbe/ixgbe_ptp.c
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_sriov.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_sriov.c
index 18ea5da234d0..c3b6c283c09e 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_sriov.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_sriov.c
@@ -407,7 +407,7 @@ static int ixgbe_set_vf_multicasts(struct ixgbe_adapter *adapter,
 		vector_reg = (vfinfo->vf_mc_hashes[i] >> 5) & 0x7F;
 		vector_bit = vfinfo->vf_mc_hashes[i] & 0x1F;
 		mta_reg = IXGBE_READ_REG(hw, IXGBE_MTA(vector_reg));
-		mta_reg |= (1 << vector_bit);
+		mta_reg |= BIT(vector_bit);
 		IXGBE_WRITE_REG(hw, IXGBE_MTA(vector_reg), mta_reg);
 	}
 	vmolr |= IXGBE_VMOLR_ROMPE;
@@ -434,7 +434,7 @@ void ixgbe_restore_vf_multicasts(struct ixgbe_adapter *adapter)
 			vector_reg = (vfinfo->vf_mc_hashes[j] >> 5) & 0x7F;
 			vector_bit = vfinfo->vf_mc_hashes[j] & 0x1F;
 			mta_reg = IXGBE_READ_REG(hw, IXGBE_MTA(vector_reg));
-			mta_reg |= (1 << vector_bit);
+			mta_reg |= BIT(vector_bit);
 			IXGBE_WRITE_REG(hw, IXGBE_MTA(vector_reg), mta_reg);
 		}
 
@@ -537,9 +537,9 @@ static s32 ixgbe_set_vf_lpe(struct ixgbe_adapter *adapter, u32 *msgbuf, u32 vf)
 		/* enable or disable receive depending on error */
 		vfre = IXGBE_READ_REG(hw, IXGBE_VFRE(reg_offset));
 		if (err)
-			vfre &= ~(1 << vf_shift);
+			vfre &= ~BIT(vf_shift);
 		else
-			vfre |= 1 << vf_shift;
+			vfre |= BIT(vf_shift);
 		IXGBE_WRITE_REG(hw, IXGBE_VFRE(reg_offset), vfre);
 
 		if (err) {
@@ -593,8 +593,8 @@ static void ixgbe_clear_vf_vlans(struct ixgbe_adapter *adapter, u32 vf)
 	u32 vlvfb_mask, pool_mask, i;
 
 	/* create mask for VF and other pools */
-	pool_mask = ~(1 << (VMDQ_P(0) % 32));
-	vlvfb_mask = 1 << (vf % 32);
+	pool_mask = ~BIT(VMDQ_P(0) % 32);
+	vlvfb_mask = BIT(vf % 32);
 
 	/* post increment loop, covers VLVF_ENTRIES - 1 to 0 */
 	for (i = IXGBE_VLVF_ENTRIES; i--;) {
@@ -630,7 +630,7 @@ static void ixgbe_clear_vf_vlans(struct ixgbe_adapter *adapter, u32 vf)
 			goto update_vlvfb;
 
 		vid = vlvf & VLAN_VID_MASK;
-		mask = 1 << (vid % 32);
+		mask = BIT(vid % 32);
 
 		/* clear bit from VFTA */
 		vfta = IXGBE_READ_REG(hw, IXGBE_VFTA(vid / 32));
@@ -817,7 +817,7 @@ static int ixgbe_vf_reset_msg(struct ixgbe_adapter *adapter, u32 vf)
 
 	/* enable transmit for vf */
 	reg = IXGBE_READ_REG(hw, IXGBE_VFTE(reg_offset));
-	reg |= 1 << vf_shift;
+	reg |= BIT(vf_shift);
 	IXGBE_WRITE_REG(hw, IXGBE_VFTE(reg_offset), reg);
 
 	/* force drop enable for all VF Rx queues */
@@ -825,7 +825,7 @@ static int ixgbe_vf_reset_msg(struct ixgbe_adapter *adapter, u32 vf)
 
 	/* enable receive for vf */
 	reg = IXGBE_READ_REG(hw, IXGBE_VFRE(reg_offset));
-	reg |= 1 << vf_shift;
+	reg |= BIT(vf_shift);
 	/*
 	 * The 82599 cannot support a mix of jumbo and non-jumbo PF/VFs.
 	 * For more info take a look at ixgbe_set_vf_lpe
@@ -841,7 +841,7 @@ static int ixgbe_vf_reset_msg(struct ixgbe_adapter *adapter, u32 vf)
 
 #endif /* CONFIG_FCOE */
 		if (pf_max_frame > ETH_FRAME_LEN)
-			reg &= ~(1 << vf_shift);
+			reg &= ~BIT(vf_shift);
 	}
 	IXGBE_WRITE_REG(hw, IXGBE_VFRE(reg_offset), reg);
 
@@ -850,7 +850,7 @@ static int ixgbe_vf_reset_msg(struct ixgbe_adapter *adapter, u32 vf)
 
 	/* Enable counting of spoofed packets in the SSVPC register */
 	reg = IXGBE_READ_REG(hw, IXGBE_VMECM(reg_offset));
-	reg |= (1 << vf_shift);
+	reg |= BIT(vf_shift);
 	IXGBE_WRITE_REG(hw, IXGBE_VMECM(reg_offset), reg);
 
 	/*
* Unmerged path drivers/net/ethernet/intel/ixgbe/ixgbe_type.h
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_x540.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_x540.c
index fcfa2cc00d28..465d1a4c9c05 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_x540.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_x540.c
@@ -214,8 +214,8 @@ s32 ixgbe_init_eeprom_params_X540(struct ixgbe_hw *hw)
 		eec = IXGBE_READ_REG(hw, IXGBE_EEC(hw));
 		eeprom_size = (u16)((eec & IXGBE_EEC_SIZE) >>
 				    IXGBE_EEC_SIZE_SHIFT);
-		eeprom->word_size = 1 << (eeprom_size +
-					  IXGBE_EEPROM_WORD_SIZE_SHIFT);
+		eeprom->word_size = BIT(eeprom_size +
+					IXGBE_EEPROM_WORD_SIZE_SHIFT);
 
 		hw_dbg(hw, "Eeprom params: type = %d, size = %d\n",
 		       eeprom->type, eeprom->word_size);
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_x550.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_x550.c
index 98d6e51de236..b91e2d0fd9bd 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_x550.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_x550.c
@@ -325,8 +325,8 @@ static s32 ixgbe_init_eeprom_params_X550(struct ixgbe_hw *hw)
 		eec = IXGBE_READ_REG(hw, IXGBE_EEC(hw));
 		eeprom_size = (u16)((eec & IXGBE_EEC_SIZE) >>
 				    IXGBE_EEC_SIZE_SHIFT);
-		eeprom->word_size = 1 << (eeprom_size +
-					  IXGBE_EEPROM_WORD_SIZE_SHIFT);
+		eeprom->word_size = BIT(eeprom_size +
+					IXGBE_EEPROM_WORD_SIZE_SHIFT);
 
 		hw_dbg(hw, "Eeprom params: type = %d, size = %d\n",
 		       eeprom->type, eeprom->word_size);
@@ -2327,9 +2327,9 @@ static void ixgbe_set_ethertype_anti_spoofing_X550(struct ixgbe_hw *hw,
 
 	pfvfspoof = IXGBE_READ_REG(hw, IXGBE_PFVFSPOOF(vf_target_reg));
 	if (enable)
-		pfvfspoof |= (1 << vf_target_shift);
+		pfvfspoof |= BIT(vf_target_shift);
 	else
-		pfvfspoof &= ~(1 << vf_target_shift);
+		pfvfspoof &= ~BIT(vf_target_shift);
 
 	IXGBE_WRITE_REG(hw, IXGBE_PFVFSPOOF(vf_target_reg), pfvfspoof);
 }
