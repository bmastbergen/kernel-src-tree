vxlan: clean up extension handling on rx

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Jiri Benc <jbenc@redhat.com>
commit f14ecebb3a4e83eb6233e0167aa4ba675c99e514
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/f14ecebb.failed

Bring the extension handling to a single place and move the actual handling
logic out of vxlan_udp_encap_recv as much as possible.

	Signed-off-by: Jiri Benc <jbenc@redhat.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit f14ecebb3a4e83eb6233e0167aa4ba675c99e514)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/vxlan.c
diff --cc drivers/net/vxlan.c
index a2751f4f523c,ac688dc75c66..000000000000
--- a/drivers/net/vxlan.c
+++ b/drivers/net/vxlan.c
@@@ -1128,120 -1135,52 +1128,162 @@@ static int vxlan_igmp_leave(struct vxla
  	return ret;
  }
  
++<<<<<<< HEAD
 +static struct vxlanhdr *vxlan_remcsum(struct sk_buff *skb, struct vxlanhdr *vh,
 +				      size_t hdrlen, u32 data, bool nopartial)
 +{
 +	size_t start, offset, plen;
 +
 +	if (skb->remcsum_offload)
 +		return vh;
 +
 +	start = (data & VXLAN_RCO_MASK) << VXLAN_RCO_SHIFT;
 +	offset = start + ((data & VXLAN_RCO_UDP) ?
 +			  offsetof(struct udphdr, check) :
 +			  offsetof(struct tcphdr, check));
++=======
+ static bool vxlan_remcsum(struct vxlanhdr *unparsed,
+ 			  struct sk_buff *skb, u32 vxflags)
+ {
+ 	size_t start, offset, plen;
+ 
+ 	if (!(unparsed->vx_flags & VXLAN_HF_RCO) || skb->remcsum_offload)
+ 		goto out;
+ 
+ 	start = vxlan_rco_start(unparsed->vx_vni);
+ 	offset = start + vxlan_rco_offset(unparsed->vx_vni);
++>>>>>>> f14ecebb3a4e (vxlan: clean up extension handling on rx)
  
 -	plen = sizeof(struct vxlanhdr) + offset + sizeof(u16);
 +	plen = hdrlen + offset + sizeof(u16);
  
  	if (!pskb_may_pull(skb, plen))
 -		return false;
 +		return NULL;
 +
++<<<<<<< HEAD
 +	vh = (struct vxlanhdr *)(udp_hdr(skb) + 1);
 +
 +	skb_remcsum_process(skb, (void *)vh + hdrlen, start, offset,
 +			    nopartial);
  
 +	return vh;
 +}
 +
 +/* Callback from net/ipv4/udp.c to receive packets */
 +static int vxlan_udp_encap_recv(struct sock *sk, struct sk_buff *skb)
 +{
 +	struct vxlan_sock *vs;
 +	struct vxlanhdr *vxh;
 +	u32 flags, vni;
 +	struct vxlan_metadata md = {0};
 +
 +	/* Need Vxlan and inner Ethernet header to be present */
 +	if (!pskb_may_pull(skb, VXLAN_HLEN))
 +		goto error;
++=======
+ 	skb_remcsum_process(skb, (void *)(vxlan_hdr(skb) + 1), start, offset,
+ 			    !!(vxflags & VXLAN_F_REMCSUM_NOPARTIAL));
+ out:
+ 	unparsed->vx_flags &= ~VXLAN_HF_RCO;
+ 	unparsed->vx_vni &= VXLAN_VNI_MASK;
+ 	return true;
+ }
+ 
+ static void vxlan_parse_gbp_hdr(struct vxlanhdr *unparsed,
+ 				struct vxlan_metadata *md,
+ 				struct metadata_dst *tun_dst)
+ {
+ 	struct vxlanhdr_gbp *gbp = (struct vxlanhdr_gbp *)unparsed;
+ 
+ 	if (!(unparsed->vx_flags & VXLAN_HF_GBP))
+ 		goto out;
+ 
+ 	md->gbp = ntohs(gbp->policy_id);
++>>>>>>> f14ecebb3a4e (vxlan: clean up extension handling on rx)
  
 -	if (tun_dst)
 -		tun_dst->u.tun_info.key.tun_flags |= TUNNEL_VXLAN_OPT;
 +	vxh = (struct vxlanhdr *)(udp_hdr(skb) + 1);
 +	flags = ntohl(vxh->vx_flags);
 +	vni = ntohl(vxh->vx_vni);
 +
 +	if (flags & VXLAN_HF_VNI) {
 +		flags &= ~VXLAN_HF_VNI;
 +	} else {
 +		/* VNI flag always required to be set */
 +		goto bad_flags;
 +	}
  
 -	if (gbp->dont_learn)
 -		md->gbp |= VXLAN_GBP_DONT_LEARN;
++<<<<<<< HEAD
 +	if (iptunnel_pull_header(skb, VXLAN_HLEN, htons(ETH_P_TEB)))
 +		goto drop;
 +	vxh = (struct vxlanhdr *)(udp_hdr(skb) + 1);
 +
 +	vs = rcu_dereference_sk_user_data(sk);
 +	if (!vs)
 +		goto drop;
 +
 +	if ((flags & VXLAN_HF_RCO) && (vs->flags & VXLAN_F_REMCSUM_RX)) {
 +		vxh = vxlan_remcsum(skb, vxh, sizeof(struct vxlanhdr), vni,
 +				    !!(vs->flags & VXLAN_F_REMCSUM_NOPARTIAL));
 +		if (!vxh)
 +			goto drop;
 +
 +		flags &= ~VXLAN_HF_RCO;
 +		vni &= VXLAN_VNI_MASK;
 +	}
 +
 +	/* For backwards compatibility, only allow reserved fields to be
 +	 * used by VXLAN extensions if explicitly requested.
 +	 */
 +	if ((flags & VXLAN_HF_GBP) && (vs->flags & VXLAN_F_GBP)) {
 +		struct vxlanhdr_gbp *gbp;
 +
 +		gbp = (struct vxlanhdr_gbp *)vxh;
 +		md.gbp = ntohs(gbp->policy_id);
 +
 +		if (gbp->dont_learn)
 +			md.gbp |= VXLAN_GBP_DONT_LEARN;
 +
 +		if (gbp->policy_applied)
 +			md.gbp |= VXLAN_GBP_POLICY_APPLIED;
 +
 +		flags &= ~VXLAN_GBP_USED_BITS;
 +	}
 +
 +	if (flags || vni & ~VXLAN_VNI_MASK) {
 +		/* If there are any unprocessed flags remaining treat
 +		 * this as a malformed packet. This behavior diverges from
 +		 * VXLAN RFC (RFC7348) which stipulates that bits in reserved
 +		 * in reserved fields are to be ignored. The approach here
 +		 * maintains compatibility with previous stack code, and also
 +		 * is more robust and provides a little more security in
 +		 * adding extensions to VXLAN.
 +		 */
  
 +		goto bad_flags;
 +	}
 +
 +	md.vni = vxh->vx_vni;
 +	vs->rcv(vs, skb, &md);
 +	return 0;
 +
 +drop:
 +	/* Consume bad packet */
 +	kfree_skb(skb);
 +	return 0;
 +
 +bad_flags:
 +	netdev_dbg(skb->dev, "invalid vxlan flags=%#x vni=%#x\n",
 +		   ntohl(vxh->vx_flags), ntohl(vxh->vx_vni));
 +
 +error:
 +	/* Return non vxlan pkt */
 +	return 1;
++=======
+ 	if (gbp->policy_applied)
+ 		md->gbp |= VXLAN_GBP_POLICY_APPLIED;
+ 
+ out:
+ 	unparsed->vx_flags &= ~VXLAN_GBP_USED_BITS;
++>>>>>>> f14ecebb3a4e (vxlan: clean up extension handling on rx)
  }
  
  static void vxlan_rcv(struct vxlan_sock *vs, struct sk_buff *skb,
@@@ -1327,6 -1277,91 +1369,94 @@@ drop
  	kfree_skb(skb);
  }
  
++<<<<<<< HEAD
++=======
+ /* Callback from net/ipv4/udp.c to receive packets */
+ static int vxlan_udp_encap_recv(struct sock *sk, struct sk_buff *skb)
+ {
+ 	struct metadata_dst *tun_dst = NULL;
+ 	struct vxlan_sock *vs;
+ 	struct vxlanhdr unparsed;
+ 	struct vxlan_metadata _md;
+ 	struct vxlan_metadata *md = &_md;
+ 
+ 	/* Need Vxlan and inner Ethernet header to be present */
+ 	if (!pskb_may_pull(skb, VXLAN_HLEN))
+ 		goto error;
+ 
+ 	unparsed = *vxlan_hdr(skb);
+ 	if (unparsed.vx_flags & VXLAN_HF_VNI) {
+ 		unparsed.vx_flags &= ~VXLAN_HF_VNI;
+ 		unparsed.vx_vni &= ~VXLAN_VNI_MASK;
+ 	} else {
+ 		/* VNI flag always required to be set */
+ 		goto bad_flags;
+ 	}
+ 
+ 	if (iptunnel_pull_header(skb, VXLAN_HLEN, htons(ETH_P_TEB)))
+ 		goto drop;
+ 
+ 	vs = rcu_dereference_sk_user_data(sk);
+ 	if (!vs)
+ 		goto drop;
+ 
+ 	if (vxlan_collect_metadata(vs)) {
+ 		tun_dst = udp_tun_rx_dst(skb, vxlan_get_sk_family(vs), TUNNEL_KEY,
+ 					 vxlan_vni(vxlan_hdr(skb)->vx_vni),
+ 					 sizeof(*md));
+ 
+ 		if (!tun_dst)
+ 			goto drop;
+ 
+ 		md = ip_tunnel_info_opts(&tun_dst->u.tun_info);
+ 	} else {
+ 		memset(md, 0, sizeof(*md));
+ 	}
+ 
+ 	/* For backwards compatibility, only allow reserved fields to be
+ 	 * used by VXLAN extensions if explicitly requested.
+ 	 */
+ 	if (vs->flags & VXLAN_F_REMCSUM_RX)
+ 		if (!vxlan_remcsum(&unparsed, skb, vs->flags))
+ 			goto drop;
+ 	if (vs->flags & VXLAN_F_GBP)
+ 		vxlan_parse_gbp_hdr(&unparsed, md, tun_dst);
+ 
+ 	if (unparsed.vx_flags || unparsed.vx_vni) {
+ 		/* If there are any unprocessed flags remaining treat
+ 		 * this as a malformed packet. This behavior diverges from
+ 		 * VXLAN RFC (RFC7348) which stipulates that bits in reserved
+ 		 * in reserved fields are to be ignored. The approach here
+ 		 * maintains compatibility with previous stack code, and also
+ 		 * is more robust and provides a little more security in
+ 		 * adding extensions to VXLAN.
+ 		 */
+ 
+ 		goto bad_flags;
+ 	}
+ 
+ 	vxlan_rcv(vs, skb, md, vxlan_vni(vxlan_hdr(skb)->vx_vni), tun_dst);
+ 	return 0;
+ 
+ drop:
+ 	/* Consume bad packet */
+ 	kfree_skb(skb);
+ 	return 0;
+ 
+ bad_flags:
+ 	netdev_dbg(skb->dev, "invalid vxlan flags=%#x vni=%#x\n",
+ 		   ntohl(vxlan_hdr(skb)->vx_flags),
+ 		   ntohl(vxlan_hdr(skb)->vx_vni));
+ 
+ error:
+ 	if (tun_dst)
+ 		dst_release((struct dst_entry *)tun_dst);
+ 
+ 	/* Return non vxlan pkt */
+ 	return 1;
+ }
+ 
++>>>>>>> f14ecebb3a4e (vxlan: clean up extension handling on rx)
  static int arp_reduce(struct net_device *dev, struct sk_buff *skb)
  {
  	struct vxlan_dev *vxlan = netdev_priv(dev);
* Unmerged path drivers/net/vxlan.c
