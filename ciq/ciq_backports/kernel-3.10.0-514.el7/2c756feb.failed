time: Add history to cross timestamp interface supporting slower devices

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Christopher S. Hall <christopher.s.hall@intel.com>
commit 2c756feb18d9ec258dbb3a3d11c47e28820690d7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/2c756feb.failed

Another representative use case of time sync and the correlated
clocksource (in addition to PTP noted above) is PTP synchronized
audio.

In a streaming application, as an example, samples will be sent and/or
received by multiple devices with a presentation time that is in terms
of the PTP master clock. Synchronizing the audio output on these
devices requires correlating the audio clock with the PTP master
clock. The more precise this correlation is, the better the audio
quality (i.e. out of sync audio sounds bad).

From an application standpoint, to correlate the PTP master clock with
the audio device clock, the system clock is used as a intermediate
timebase. The transforms such an application would perform are:

    System Clock <-> Audio clock
    System Clock <-> Network Device Clock [<-> PTP Master Clock]

Modern Intel platforms can perform a more accurate cross timestamp in
hardware (ART,audio device clock).  The audio driver requires
ART->system time transforms -- the same as required for the network
driver. These platforms offload audio processing (including
cross-timestamps) to a DSP which to ensure uninterrupted audio
processing, communicates and response to the host only once every
millsecond. As a result is takes up to a millisecond for the DSP to
receive a request, the request is processed by the DSP, the audio
output hardware is polled for completion, the result is copied into
shared memory, and the host is notified. All of these operation occur
on a millisecond cadence.  This transaction requires about 2 ms, but
under heavier workloads it may take up to 4 ms.

Adding a history allows these slow devices the option of providing an
ART value outside of the current interval. In this case, the callback
provided is an accessor function for the previously obtained counter
value. If get_system_device_crosststamp() receives a counter value
previous to cycle_last, it consults the history provided as an
argument in history_ref and interpolates the realtime and monotonic
raw system time using the provided counter value. If there are any
clock discontinuities, e.g. from calling settimeofday(), the monotonic
raw time is interpolated in the usual way, but the realtime clock time
is adjusted by scaling the monotonic raw adjustment.

When an accessor function is used a history argument *must* be
provided. The history is initialized using ktime_get_snapshot() and
must be called before the counter values are read.

	Cc: Prarit Bhargava <prarit@redhat.com>
	Cc: Richard Cochran <richardcochran@gmail.com>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Ingo Molnar <mingo@kernel.org>
	Cc: Andy Lutomirski <luto@amacapital.net>
	Cc: kevin.b.stanton@intel.com
	Cc: kevin.j.clarke@intel.com
	Cc: hpa@zytor.com
	Cc: jeffrey.t.kirsher@intel.com
	Cc: netdev@vger.kernel.org
	Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
	Signed-off-by: Christopher S. Hall <christopher.s.hall@intel.com>
[jstultz: Fixed up cycles_t/cycle_t type confusion]
	Signed-off-by: John Stultz <john.stultz@linaro.org>
(cherry picked from commit 2c756feb18d9ec258dbb3a3d11c47e28820690d7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/timekeeper_internal.h
#	include/linux/timekeeping.h
#	kernel/time/timekeeping.c
diff --cc include/linux/timekeeper_internal.h
index a44b704da541,e88005459035..000000000000
--- a/include/linux/timekeeper_internal.h
+++ b/include/linux/timekeeper_internal.h
@@@ -10,68 -10,97 +10,158 @@@
  #include <linux/jiffies.h>
  #include <linux/time.h>
  
++<<<<<<< HEAD
 +/* Structure holding internal timekeeping values. */
 +struct timekeeper {
 +	/* Current clocksource used for timekeeping. */
 +	struct clocksource	*clock;
 +	/* NTP adjusted clock multiplier */
 +	u32			mult;
 +	/* The shift value of the current clocksource. */
 +	u32			shift;
 +	/* Number of clock cycles in one NTP interval. */
++=======
+ /**
+  * struct tk_read_base - base structure for timekeeping readout
+  * @clock:	Current clocksource used for timekeeping.
+  * @read:	Read function of @clock
+  * @mask:	Bitmask for two's complement subtraction of non 64bit clocks
+  * @cycle_last: @clock cycle value at last update
+  * @mult:	(NTP adjusted) multiplier for scaled math conversion
+  * @shift:	Shift value for scaled math conversion
+  * @xtime_nsec: Shifted (fractional) nano seconds offset for readout
+  * @base:	ktime_t (nanoseconds) base time for readout
+  *
+  * This struct has size 56 byte on 64 bit. Together with a seqcount it
+  * occupies a single 64byte cache line.
+  *
+  * The struct is separate from struct timekeeper as it is also used
+  * for a fast NMI safe accessors.
+  */
+ struct tk_read_base {
+ 	struct clocksource	*clock;
+ 	cycle_t			(*read)(struct clocksource *cs);
+ 	cycle_t			mask;
+ 	cycle_t			cycle_last;
+ 	u32			mult;
+ 	u32			shift;
+ 	u64			xtime_nsec;
+ 	ktime_t			base;
+ };
+ 
+ /**
+  * struct timekeeper - Structure holding internal timekeeping values.
+  * @tkr_mono:		The readout base structure for CLOCK_MONOTONIC
+  * @tkr_raw:		The readout base structure for CLOCK_MONOTONIC_RAW
+  * @xtime_sec:		Current CLOCK_REALTIME time in seconds
+  * @ktime_sec:		Current CLOCK_MONOTONIC time in seconds
+  * @wall_to_monotonic:	CLOCK_REALTIME to CLOCK_MONOTONIC offset
+  * @offs_real:		Offset clock monotonic -> clock realtime
+  * @offs_boot:		Offset clock monotonic -> clock boottime
+  * @offs_tai:		Offset clock monotonic -> clock tai
+  * @tai_offset:		The current UTC to TAI offset in seconds
+  * @clock_was_set_seq:	The sequence number of clock was set events
+  * @cs_was_changed_seq:	The sequence number of clocksource change events
+  * @next_leap_ktime:	CLOCK_MONOTONIC time value of a pending leap-second
+  * @raw_time:		Monotonic raw base time in timespec64 format
+  * @cycle_interval:	Number of clock cycles in one NTP interval
+  * @xtime_interval:	Number of clock shifted nano seconds in one NTP
+  *			interval.
+  * @xtime_remainder:	Shifted nano seconds left over when rounding
+  *			@cycle_interval
+  * @raw_interval:	Raw nano seconds accumulated per NTP interval.
+  * @ntp_error:		Difference between accumulated time and NTP time in ntp
+  *			shifted nano seconds.
+  * @ntp_error_shift:	Shift conversion between clock shifted nano seconds and
+  *			ntp shifted nano seconds.
+  * @last_warning:	Warning ratelimiter (DEBUG_TIMEKEEPING)
+  * @underflow_seen:	Underflow warning flag (DEBUG_TIMEKEEPING)
+  * @overflow_seen:	Overflow warning flag (DEBUG_TIMEKEEPING)
+  *
+  * Note: For timespec(64) based interfaces wall_to_monotonic is what
+  * we need to add to xtime (or xtime corrected for sub jiffie times)
+  * to get to monotonic time.  Monotonic is pegged at zero at system
+  * boot time, so wall_to_monotonic will be negative, however, we will
+  * ALWAYS keep the tv_nsec part positive so we can use the usual
+  * normalization.
+  *
+  * wall_to_monotonic is moved after resume from suspend for the
+  * monotonic time not to jump. We need to add total_sleep_time to
+  * wall_to_monotonic to get the real boot based time offset.
+  *
+  * wall_to_monotonic is no longer the boot time, getboottime must be
+  * used instead.
+  */
+ struct timekeeper {
+ 	struct tk_read_base	tkr_mono;
+ 	struct tk_read_base	tkr_raw;
+ 	u64			xtime_sec;
+ 	unsigned long		ktime_sec;
+ 	struct timespec64	wall_to_monotonic;
+ 	ktime_t			offs_real;
+ 	ktime_t			offs_boot;
+ 	ktime_t			offs_tai;
+ 	s32			tai_offset;
+ 	unsigned int		clock_was_set_seq;
+ 	u8			cs_was_changed_seq;
+ 	ktime_t			next_leap_ktime;
+ 	struct timespec64	raw_time;
+ 
+ 	/* The following members are for timekeeping internal use */
++>>>>>>> 2c756feb18d9 (time: Add history to cross timestamp interface supporting slower devices)
  	cycle_t			cycle_interval;
 +	/* Last cycle value (also stored in clock->cycle_last) */
 +	cycle_t			cycle_last;
 +	/* Number of clock shifted nano seconds in one NTP interval. */
  	u64			xtime_interval;
 +	/* shifted nano seconds left over when rounding cycle_interval */
  	s64			xtime_remainder;
 +	/* Raw nano seconds accumulated per NTP interval. */
  	u32			raw_interval;
 +
 +	/* Current CLOCK_REALTIME time in seconds */
 +	u64			xtime_sec;
 +	/* Clock shifted nano seconds */
 +	u64			xtime_nsec;
 +
 +	/* Monotonic base time */
 +	ktime_t                 base_mono;
 +
 +	/* Difference between accumulated time and NTP time in ntp
 +	 * shifted nano seconds. */
 +	s64			ntp_error;
 +	/* Shift conversion between clock shifted nano seconds and
 +	 * ntp shifted nano seconds. */
 +	u32			ntp_error_shift;
 +
 +	/*
 +	 * wall_to_monotonic is what we need to add to xtime (or xtime corrected
 +	 * for sub jiffie times) to get to monotonic time.  Monotonic is pegged
 +	 * at zero at system boot time, so wall_to_monotonic will be negative,
 +	 * however, we will ALWAYS keep the tv_nsec part positive so we can use
 +	 * the usual normalization.
 +	 *
 +	 * wall_to_monotonic is moved after resume from suspend for the
 +	 * monotonic time not to jump. We need to add total_sleep_time to
 +	 * wall_to_monotonic to get the real boot based time offset.
 +	 *
 +	 * - wall_to_monotonic is no longer the boot time, getboottime must be
 +	 * used instead.
 +	 */
 +	struct timespec64	wall_to_monotonic;
 +	/* Offset clock monotonic -> clock realtime */
 +	ktime_t			offs_real;
 +	/* time spent in suspend */
 +	struct timespec64	total_sleep_time;
 +	/* Offset clock monotonic -> clock boottime */
 +	ktime_t			offs_boot;
 +	/* The raw monotonic time for the CLOCK_MONOTONIC_RAW posix clock. */
 +	struct timespec64	raw_time;
 +	/* The current UTC to TAI offset in seconds */
 +	s32			tai_offset;
 +	/* Offset clock monotonic -> clock tai */
 +	ktime_t			offs_tai;
 +
  	/* The ntp_tick_length() value currently being used.
  	 * This cached copy ensures we consistently apply the tick
  	 * length for an entire tick, as ntp_tick_length may change
diff --cc kernel/time/timekeeping.c
index 7bb86335a3a9,931b0b1a71e9..000000000000
--- a/kernel/time/timekeeping.c
+++ b/kernel/time/timekeeping.c
@@@ -105,9 -233,17 +105,23 @@@ static void tk_setup_internals(struct t
  	u64 tmp, ntpinterval;
  	struct clocksource *old_clock;
  
++<<<<<<< HEAD
 +	old_clock = tk->clock;
 +	tk->clock = clock;
 +	tk->cycle_last = clock->cycle_last = clock->read(clock);
++=======
+ 	++tk->cs_was_changed_seq;
+ 	old_clock = tk->tkr_mono.clock;
+ 	tk->tkr_mono.clock = clock;
+ 	tk->tkr_mono.read = clock->read;
+ 	tk->tkr_mono.mask = clock->mask;
+ 	tk->tkr_mono.cycle_last = tk->tkr_mono.read(clock);
+ 
+ 	tk->tkr_raw.clock = clock;
+ 	tk->tkr_raw.read = clock->read;
+ 	tk->tkr_raw.mask = clock->mask;
+ 	tk->tkr_raw.cycle_last = tk->tkr_mono.cycle_last;
++>>>>>>> 2c756feb18d9 (time: Add history to cross timestamp interface supporting slower devices)
  
  	/* Do the ns -> cycle conversion first, using original mult */
  	tmp = NTP_INTERVAL_LENGTH;
@@@ -487,23 -892,245 +501,259 @@@ void getnstime_raw_and_real(struct time
  	WARN_ON_ONCE(timekeeping_suspended);
  
  	do {
 -		seq = read_seqcount_begin(&tk_core.seq);
 +		seq = read_seqcount_begin(&timekeeper_seq);
  
++<<<<<<< HEAD
 +		*ts_raw = timespec64_to_timespec(tk->raw_time);
 +		ts_real->tv_sec = tk->xtime_sec;
 +		ts_real->tv_nsec = 0;
++=======
+ 		now = tk->tkr_mono.read(tk->tkr_mono.clock);
+ 		systime_snapshot->cs_was_changed_seq = tk->cs_was_changed_seq;
+ 		systime_snapshot->clock_was_set_seq = tk->clock_was_set_seq;
+ 		base_real = ktime_add(tk->tkr_mono.base,
+ 				      tk_core.timekeeper.offs_real);
+ 		base_raw = tk->tkr_raw.base;
+ 		nsec_real = timekeeping_cycles_to_ns(&tk->tkr_mono, now);
+ 		nsec_raw  = timekeeping_cycles_to_ns(&tk->tkr_raw, now);
+ 	} while (read_seqcount_retry(&tk_core.seq, seq));
++>>>>>>> 2c756feb18d9 (time: Add history to cross timestamp interface supporting slower devices)
 +
 +		nsecs_raw = timekeeping_get_ns_raw(tk);
 +		nsecs_real = timekeeping_get_ns(tk);
  
 -	systime_snapshot->cycles = now;
 -	systime_snapshot->real = ktime_add_ns(base_real, nsec_real);
 -	systime_snapshot->raw = ktime_add_ns(base_raw, nsec_raw);
 +	} while (read_seqcount_retry(&timekeeper_seq, seq));
 +
 +	timespec_add_ns(ts_raw, nsecs_raw);
 +	timespec_add_ns(ts_real, nsecs_real);
  }
 -EXPORT_SYMBOL_GPL(ktime_get_snapshot);
 +EXPORT_SYMBOL(getnstime_raw_and_real);
  
++<<<<<<< HEAD
 +#endif /* CONFIG_NTP_PPS */
++=======
+ /* Scale base by mult/div checking for overflow */
+ static int scale64_check_overflow(u64 mult, u64 div, u64 *base)
+ {
+ 	u64 tmp, rem;
+ 
+ 	tmp = div64_u64_rem(*base, div, &rem);
+ 
+ 	if (((int)sizeof(u64)*8 - fls64(mult) < fls64(tmp)) ||
+ 	    ((int)sizeof(u64)*8 - fls64(mult) < fls64(rem)))
+ 		return -EOVERFLOW;
+ 	tmp *= mult;
+ 	rem *= mult;
+ 
+ 	do_div(rem, div);
+ 	*base = tmp + rem;
+ 	return 0;
+ }
+ 
+ /**
+  * adjust_historical_crosststamp - adjust crosstimestamp previous to current interval
+  * @history:			Snapshot representing start of history
+  * @partial_history_cycles:	Cycle offset into history (fractional part)
+  * @total_history_cycles:	Total history length in cycles
+  * @discontinuity:		True indicates clock was set on history period
+  * @ts:				Cross timestamp that should be adjusted using
+  *	partial/total ratio
+  *
+  * Helper function used by get_device_system_crosststamp() to correct the
+  * crosstimestamp corresponding to the start of the current interval to the
+  * system counter value (timestamp point) provided by the driver. The
+  * total_history_* quantities are the total history starting at the provided
+  * reference point and ending at the start of the current interval. The cycle
+  * count between the driver timestamp point and the start of the current
+  * interval is partial_history_cycles.
+  */
+ static int adjust_historical_crosststamp(struct system_time_snapshot *history,
+ 					 cycle_t partial_history_cycles,
+ 					 cycle_t total_history_cycles,
+ 					 bool discontinuity,
+ 					 struct system_device_crosststamp *ts)
+ {
+ 	struct timekeeper *tk = &tk_core.timekeeper;
+ 	u64 corr_raw, corr_real;
+ 	bool interp_forward;
+ 	int ret;
+ 
+ 	if (total_history_cycles == 0 || partial_history_cycles == 0)
+ 		return 0;
+ 
+ 	/* Interpolate shortest distance from beginning or end of history */
+ 	interp_forward = partial_history_cycles > total_history_cycles/2 ?
+ 		true : false;
+ 	partial_history_cycles = interp_forward ?
+ 		total_history_cycles - partial_history_cycles :
+ 		partial_history_cycles;
+ 
+ 	/*
+ 	 * Scale the monotonic raw time delta by:
+ 	 *	partial_history_cycles / total_history_cycles
+ 	 */
+ 	corr_raw = (u64)ktime_to_ns(
+ 		ktime_sub(ts->sys_monoraw, history->raw));
+ 	ret = scale64_check_overflow(partial_history_cycles,
+ 				     total_history_cycles, &corr_raw);
+ 	if (ret)
+ 		return ret;
+ 
+ 	/*
+ 	 * If there is a discontinuity in the history, scale monotonic raw
+ 	 *	correction by:
+ 	 *	mult(real)/mult(raw) yielding the realtime correction
+ 	 * Otherwise, calculate the realtime correction similar to monotonic
+ 	 *	raw calculation
+ 	 */
+ 	if (discontinuity) {
+ 		corr_real = mul_u64_u32_div
+ 			(corr_raw, tk->tkr_mono.mult, tk->tkr_raw.mult);
+ 	} else {
+ 		corr_real = (u64)ktime_to_ns(
+ 			ktime_sub(ts->sys_realtime, history->real));
+ 		ret = scale64_check_overflow(partial_history_cycles,
+ 					     total_history_cycles, &corr_real);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	/* Fixup monotonic raw and real time time values */
+ 	if (interp_forward) {
+ 		ts->sys_monoraw = ktime_add_ns(history->raw, corr_raw);
+ 		ts->sys_realtime = ktime_add_ns(history->real, corr_real);
+ 	} else {
+ 		ts->sys_monoraw = ktime_sub_ns(ts->sys_monoraw, corr_raw);
+ 		ts->sys_realtime = ktime_sub_ns(ts->sys_realtime, corr_real);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ /*
+  * cycle_between - true if test occurs chronologically between before and after
+  */
+ static bool cycle_between(cycle_t before, cycle_t test, cycle_t after)
+ {
+ 	if (test > before && test < after)
+ 		return true;
+ 	if (test < before && before > after)
+ 		return true;
+ 	return false;
+ }
+ 
+ /**
+  * get_device_system_crosststamp - Synchronously capture system/device timestamp
+  * @get_time_fn:	Callback to get simultaneous device time and
+  *	system counter from the device driver
+  * @ctx:		Context passed to get_time_fn()
+  * @history_begin:	Historical reference point used to interpolate system
+  *	time when counter provided by the driver is before the current interval
+  * @xtstamp:		Receives simultaneously captured system and device time
+  *
+  * Reads a timestamp from a device and correlates it to system time
+  */
+ int get_device_system_crosststamp(int (*get_time_fn)
+ 				  (ktime_t *device_time,
+ 				   struct system_counterval_t *sys_counterval,
+ 				   void *ctx),
+ 				  void *ctx,
+ 				  struct system_time_snapshot *history_begin,
+ 				  struct system_device_crosststamp *xtstamp)
+ {
+ 	struct system_counterval_t system_counterval;
+ 	struct timekeeper *tk = &tk_core.timekeeper;
+ 	cycle_t cycles, now, interval_start;
+ 	unsigned int clock_was_set_seq;
+ 	ktime_t base_real, base_raw;
+ 	s64 nsec_real, nsec_raw;
+ 	u8 cs_was_changed_seq;
+ 	unsigned long seq;
+ 	bool do_interp;
+ 	int ret;
+ 
+ 	do {
+ 		seq = read_seqcount_begin(&tk_core.seq);
+ 		/*
+ 		 * Try to synchronously capture device time and a system
+ 		 * counter value calling back into the device driver
+ 		 */
+ 		ret = get_time_fn(&xtstamp->device, &system_counterval, ctx);
+ 		if (ret)
+ 			return ret;
+ 
+ 		/*
+ 		 * Verify that the clocksource associated with the captured
+ 		 * system counter value is the same as the currently installed
+ 		 * timekeeper clocksource
+ 		 */
+ 		if (tk->tkr_mono.clock != system_counterval.cs)
+ 			return -ENODEV;
+ 		cycles = system_counterval.cycles;
+ 
+ 		/*
+ 		 * Check whether the system counter value provided by the
+ 		 * device driver is on the current timekeeping interval.
+ 		 */
+ 		now = tk->tkr_mono.read(tk->tkr_mono.clock);
+ 		interval_start = tk->tkr_mono.cycle_last;
+ 		if (!cycle_between(interval_start, cycles, now)) {
+ 			clock_was_set_seq = tk->clock_was_set_seq;
+ 			cs_was_changed_seq = tk->cs_was_changed_seq;
+ 			cycles = interval_start;
+ 			do_interp = true;
+ 		} else {
+ 			do_interp = false;
+ 		}
+ 
+ 		base_real = ktime_add(tk->tkr_mono.base,
+ 				      tk_core.timekeeper.offs_real);
+ 		base_raw = tk->tkr_raw.base;
+ 
+ 		nsec_real = timekeeping_cycles_to_ns(&tk->tkr_mono,
+ 						     system_counterval.cycles);
+ 		nsec_raw = timekeeping_cycles_to_ns(&tk->tkr_raw,
+ 						    system_counterval.cycles);
+ 	} while (read_seqcount_retry(&tk_core.seq, seq));
+ 
+ 	xtstamp->sys_realtime = ktime_add_ns(base_real, nsec_real);
+ 	xtstamp->sys_monoraw = ktime_add_ns(base_raw, nsec_raw);
+ 
+ 	/*
+ 	 * Interpolate if necessary, adjusting back from the start of the
+ 	 * current interval
+ 	 */
+ 	if (do_interp) {
+ 		cycle_t partial_history_cycles, total_history_cycles;
+ 		bool discontinuity;
+ 
+ 		/*
+ 		 * Check that the counter value occurs after the provided
+ 		 * history reference and that the history doesn't cross a
+ 		 * clocksource change
+ 		 */
+ 		if (!history_begin ||
+ 		    !cycle_between(history_begin->cycles,
+ 				   system_counterval.cycles, cycles) ||
+ 		    history_begin->cs_was_changed_seq != cs_was_changed_seq)
+ 			return -EINVAL;
+ 		partial_history_cycles = cycles - system_counterval.cycles;
+ 		total_history_cycles = cycles - history_begin->cycles;
+ 		discontinuity =
+ 			history_begin->clock_was_set_seq != clock_was_set_seq;
+ 
+ 		ret = adjust_historical_crosststamp(history_begin,
+ 						    partial_history_cycles,
+ 						    total_history_cycles,
+ 						    discontinuity, xtstamp);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	return 0;
+ }
+ EXPORT_SYMBOL_GPL(get_device_system_crosststamp);
++>>>>>>> 2c756feb18d9 (time: Add history to cross timestamp interface supporting slower devices)
  
  /**
   * do_gettimeofday - Returns the time of day in a timeval
* Unmerged path include/linux/timekeeping.h
* Unmerged path include/linux/timekeeper_internal.h
* Unmerged path include/linux/timekeeping.h
* Unmerged path kernel/time/timekeeping.c
