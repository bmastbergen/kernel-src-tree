sctp: Add GSO support

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
commit 90017accff61ae89283ad9a51f9ac46ca01633fb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/90017acc.failed

SCTP has this pecualiarity that its packets cannot be just segmented to
(P)MTU. Its chunks must be contained in IP segments, padding respected.
So we can't just generate a big skb, set gso_size to the fragmentation
point and deliver it to IP layer.

This patch takes a different approach. SCTP will now build a skb as it
would be if it was received using GRO. That is, there will be a cover
skb with protocol headers and children ones containing the actual
segments, already segmented to a way that respects SCTP RFCs.

With that, we can tell skb_segment() to just split based on frag_list,
trusting its sizes are already in accordance.

This way SCTP can benefit from GSO and instead of passing several
packets through the stack, it can pass a single large packet.

v2:
- Added support for receiving GSO frames, as requested by Dave Miller.
- Clear skb->cb if packet is GSO (otherwise it's not used by SCTP)
- Added heuristics similar to what we have in TCP for not generating
  single GSO packets that fills cwnd.
v3:
- consider sctphdr size in skb_gso_transport_seglen()
- rebased due to 5c7cdf339af5 ("gso: Remove arbitrary checks for
  unsupported GSO")

	Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
	Tested-by: Xin Long <lucien.xin@gmail.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 90017accff61ae89283ad9a51f9ac46ca01633fb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/netdev_features.h
#	include/linux/netdevice.h
#	include/linux/skbuff.h
#	net/core/ethtool.c
#	net/sctp/output.c
diff --cc include/linux/netdev_features.h
index 83724df4f707,9c6c8ef2e9e7..000000000000
--- a/include/linux/netdev_features.h
+++ b/include/linux/netdev_features.h
@@@ -42,15 -42,23 +42,27 @@@ enum 
  	NETIF_F_TSO6_BIT,		/* ... TCPv6 segmentation */
  	NETIF_F_FSO_BIT,		/* ... FCoE segmentation */
  	NETIF_F_GSO_GRE_BIT,		/* ... GRE with TSO */
 -	NETIF_F_GSO_GRE_CSUM_BIT,	/* ... GRE with csum with TSO */
 -	NETIF_F_GSO_IPXIP4_BIT,		/* ... IP4 or IP6 over IP4 with TSO */
 -	NETIF_F_GSO_IPXIP6_BIT,		/* ... IP4 or IP6 over IP6 with TSO */
 +	NETIF_F_GSO_IPIP_BIT,		/* ... IPIP tunnel with TSO */
 +	NETIF_F_GSO_SIT_BIT,		/* ... SIT tunnel with TSO */
  	NETIF_F_GSO_UDP_TUNNEL_BIT,	/* ... UDP TUNNEL with TSO */
++<<<<<<< HEAD
 +	NETIF_F_GSO_MPLS_BIT,		/* ... MPLS segmentation */
 +	/**/NETIF_F_GSO_LAST =		/* last bit, see GSO_MASK */
 +		NETIF_F_GSO_MPLS_BIT,
++=======
+ 	NETIF_F_GSO_UDP_TUNNEL_CSUM_BIT,/* ... UDP TUNNEL with TSO & CSUM */
+ 	NETIF_F_GSO_PARTIAL_BIT,	/* ... Only segment inner-most L4
+ 					 *     in hardware and all other
+ 					 *     headers in software.
+ 					 */
+ 	NETIF_F_GSO_TUNNEL_REMCSUM_BIT, /* ... TUNNEL with TSO & REMCSUM */
+ 	NETIF_F_GSO_SCTP_BIT,		/* ... SCTP fragmentation */
+ 	/**/NETIF_F_GSO_LAST =		/* last bit, see GSO_MASK */
+ 		NETIF_F_GSO_SCTP_BIT,
++>>>>>>> 90017accff61 (sctp: Add GSO support)
  
  	NETIF_F_FCOE_CRC_BIT,		/* FCoE CRC32 */
 -	NETIF_F_SCTP_CRC_BIT,		/* SCTP checksum offload */
 +	NETIF_F_SCTP_CSUM_BIT,		/* SCTP checksum offload */
  	NETIF_F_FCOE_MTU_BIT,		/* Supports max FCoE MTU, 2158 bytes*/
  	NETIF_F_NTUPLE_BIT,		/* N-tuple filters supported */
  	NETIF_F_RXHASH_BIT,		/* Receive hashing offload */
@@@ -116,12 -122,14 +128,13 @@@
  #define NETIF_F_RXALL		__NETIF_F(RXALL)
  #define NETIF_F_GSO_GRE		__NETIF_F(GSO_GRE)
  #define NETIF_F_GSO_GRE_CSUM	__NETIF_F(GSO_GRE_CSUM)
 -#define NETIF_F_GSO_IPXIP4	__NETIF_F(GSO_IPXIP4)
 -#define NETIF_F_GSO_IPXIP6	__NETIF_F(GSO_IPXIP6)
 +#define NETIF_F_GSO_IPIP	__NETIF_F(GSO_IPIP)
 +#define NETIF_F_GSO_SIT		__NETIF_F(GSO_SIT)
  #define NETIF_F_GSO_UDP_TUNNEL	__NETIF_F(GSO_UDP_TUNNEL)
  #define NETIF_F_GSO_UDP_TUNNEL_CSUM __NETIF_F(GSO_UDP_TUNNEL_CSUM)
 -#define NETIF_F_TSO_MANGLEID	__NETIF_F(TSO_MANGLEID)
 -#define NETIF_F_GSO_PARTIAL	 __NETIF_F(GSO_PARTIAL)
 +#define NETIF_F_GSO_MPLS	__NETIF_F(GSO_MPLS)
  #define NETIF_F_GSO_TUNNEL_REMCSUM __NETIF_F(GSO_TUNNEL_REMCSUM)
+ #define NETIF_F_GSO_SCTP	__NETIF_F(GSO_SCTP)
  #define NETIF_F_HW_VLAN_STAG_FILTER __NETIF_F(HW_VLAN_STAG_FILTER)
  #define NETIF_F_HW_VLAN_STAG_RX	__NETIF_F(HW_VLAN_STAG_RX)
  #define NETIF_F_HW_VLAN_STAG_TX	__NETIF_F(HW_VLAN_STAG_TX)
@@@ -168,6 -167,10 +181,13 @@@
  #define NETIF_F_ALL_FCOE	(NETIF_F_FCOE_CRC | NETIF_F_FCOE_MTU | \
  				 NETIF_F_FSO)
  
++<<<<<<< HEAD
++=======
+ /* List of features with software fallbacks. */
+ #define NETIF_F_GSO_SOFTWARE	(NETIF_F_ALL_TSO | NETIF_F_UFO | \
+ 				 NETIF_F_GSO_SCTP)
+ 
++>>>>>>> 90017accff61 (sctp: Add GSO support)
  /*
   * If one device supports one of these features, then enable them
   * for all in netdev_increment_features.
diff --cc include/linux/netdevice.h
index 95e53059b81a,fa6df2699532..000000000000
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@@ -3472,15 -4004,15 +3472,22 @@@ static inline bool net_gso_ok(netdev_fe
  	BUILD_BUG_ON(SKB_GSO_TCPV6   != (NETIF_F_TSO6 >> NETIF_F_GSO_SHIFT));
  	BUILD_BUG_ON(SKB_GSO_FCOE    != (NETIF_F_FSO >> NETIF_F_GSO_SHIFT));
  	BUILD_BUG_ON(SKB_GSO_GRE     != (NETIF_F_GSO_GRE >> NETIF_F_GSO_SHIFT));
 -	BUILD_BUG_ON(SKB_GSO_GRE_CSUM != (NETIF_F_GSO_GRE_CSUM >> NETIF_F_GSO_SHIFT));
 -	BUILD_BUG_ON(SKB_GSO_IPXIP4  != (NETIF_F_GSO_IPXIP4 >> NETIF_F_GSO_SHIFT));
 -	BUILD_BUG_ON(SKB_GSO_IPXIP6  != (NETIF_F_GSO_IPXIP6 >> NETIF_F_GSO_SHIFT));
 +	BUILD_BUG_ON(SKB_GSO_IPIP    != (NETIF_F_GSO_IPIP >> NETIF_F_GSO_SHIFT));
 +	BUILD_BUG_ON(SKB_GSO_SIT     != (NETIF_F_GSO_SIT >> NETIF_F_GSO_SHIFT));
  	BUILD_BUG_ON(SKB_GSO_UDP_TUNNEL != (NETIF_F_GSO_UDP_TUNNEL >> NETIF_F_GSO_SHIFT));
++<<<<<<< HEAD
 +	BUILD_BUG_ON(SKB_GSO_MPLS    != (NETIF_F_GSO_MPLS >> NETIF_F_GSO_SHIFT));
 +
 +	/* GSO2 flags, see netdev_features.h */
 +	BUILD_BUG_ON(SKB_GSO_GRE_CSUM != (NETIF_F_GSO_GRE_CSUM >> NETIF_F_GSO2_SHIFT));
 +	BUILD_BUG_ON(SKB_GSO_UDP_TUNNEL_CSUM != (NETIF_F_GSO_UDP_TUNNEL_CSUM >> NETIF_F_GSO2_SHIFT));
 +	BUILD_BUG_ON(SKB_GSO_TUNNEL_REMCSUM != (NETIF_F_GSO_TUNNEL_REMCSUM >> NETIF_F_GSO2_SHIFT));
++=======
+ 	BUILD_BUG_ON(SKB_GSO_UDP_TUNNEL_CSUM != (NETIF_F_GSO_UDP_TUNNEL_CSUM >> NETIF_F_GSO_SHIFT));
+ 	BUILD_BUG_ON(SKB_GSO_PARTIAL != (NETIF_F_GSO_PARTIAL >> NETIF_F_GSO_SHIFT));
+ 	BUILD_BUG_ON(SKB_GSO_TUNNEL_REMCSUM != (NETIF_F_GSO_TUNNEL_REMCSUM >> NETIF_F_GSO_SHIFT));
+ 	BUILD_BUG_ON(SKB_GSO_SCTP    != (NETIF_F_GSO_SCTP >> NETIF_F_GSO_SHIFT));
++>>>>>>> 90017accff61 (sctp: Add GSO support)
  
  	return (features & feature) == feature;
  }
diff --cc include/linux/skbuff.h
index 72292c04faa6,dc0fca747c5e..000000000000
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@@ -383,13 -484,13 +383,21 @@@ enum 
  
  	SKB_GSO_UDP_TUNNEL_CSUM = 1 << 12,
  
++<<<<<<< HEAD
 +	SKB_GSO_TUNNEL_REMCSUM = 1 << 13,
++=======
+ 	SKB_GSO_PARTIAL = 1 << 13,
+ 
+ 	SKB_GSO_TUNNEL_REMCSUM = 1 << 14,
+ 
+ 	SKB_GSO_SCTP = 1 << 15,
++>>>>>>> 90017accff61 (sctp: Add GSO support)
  };
  
 +/* NETIF_F_GSO flags are no longer part of a single range */
 +#define SKB_GSO1_MASK (SKB_GSO_GRE_CSUM - 1)
 +#define SKB_GSO2_MASK (SKB_GSO_GRE_CSUM|SKB_GSO_UDP_TUNNEL_CSUM)
 +
  #if BITS_PER_LONG > 32
  #define NET_SKBUFF_DATA_USES_OFFSET 1
  #endif
diff --cc net/core/ethtool.c
index 1ed11f1c82d9,977489820eb9..000000000000
--- a/net/core/ethtool.c
+++ b/net/core/ethtool.c
@@@ -82,13 -82,17 +82,19 @@@ static const char netdev_features_strin
  	[NETIF_F_TSO6_BIT] =             "tx-tcp6-segmentation",
  	[NETIF_F_FSO_BIT] =              "tx-fcoe-segmentation",
  	[NETIF_F_GSO_GRE_BIT] =		 "tx-gre-segmentation",
 -	[NETIF_F_GSO_GRE_CSUM_BIT] =	 "tx-gre-csum-segmentation",
 -	[NETIF_F_GSO_IPXIP4_BIT] =	 "tx-ipxip4-segmentation",
 -	[NETIF_F_GSO_IPXIP6_BIT] =	 "tx-ipxip6-segmentation",
 +	[NETIF_F_GSO_IPIP_BIT] =	 "tx-ipip-segmentation",
 +	[NETIF_F_GSO_SIT_BIT] =		 "tx-sit-segmentation",
  	[NETIF_F_GSO_UDP_TUNNEL_BIT] =	 "tx-udp_tnl-segmentation",
++<<<<<<< HEAD
 +	[NETIF_F_GSO_MPLS_BIT] =	 "tx-mpls-segmentation",
++=======
+ 	[NETIF_F_GSO_UDP_TUNNEL_CSUM_BIT] = "tx-udp_tnl-csum-segmentation",
+ 	[NETIF_F_GSO_PARTIAL_BIT] =	 "tx-gso-partial",
+ 	[NETIF_F_GSO_SCTP_BIT] =	 "tx-sctp-segmentation",
++>>>>>>> 90017accff61 (sctp: Add GSO support)
  
  	[NETIF_F_FCOE_CRC_BIT] =         "tx-checksum-fcoe-crc",
 -	[NETIF_F_SCTP_CRC_BIT] =        "tx-checksum-sctp",
 +	[NETIF_F_SCTP_CSUM_BIT] =        "tx-checksum-sctp",
  	[NETIF_F_FCOE_MTU_BIT] =         "fcoe-mtu",
  	[NETIF_F_NTUPLE_BIT] =           "rx-ntuple-filter",
  	[NETIF_F_RXHASH_BIT] =           "rx-hashing",
diff --cc net/sctp/output.c
index fed27c5c328a,60499a69179d..000000000000
--- a/net/sctp/output.c
+++ b/net/sctp/output.c
@@@ -91,10 -84,10 +91,11 @@@ static void sctp_packet_reset(struct sc
  struct sctp_packet *sctp_packet_config(struct sctp_packet *packet,
  				       __u32 vtag, int ecn_capable)
  {
- 	struct sctp_chunk *chunk = NULL;
+ 	struct sctp_transport *tp = packet->transport;
+ 	struct sctp_association *asoc = tp->asoc;
  
 -	pr_debug("%s: packet:%p vtag:0x%x\n", __func__, packet, vtag);
 +	SCTP_DEBUG_PRINTK("%s: packet:%p vtag:0x%x\n", __func__,
 +			  packet, vtag);
  
  	packet->vtag = vtag;
  
@@@ -452,91 -487,133 +498,178 @@@ int sctp_packet_transmit(struct sctp_pa
  	sh->vtag     = htonl(packet->vtag);
  	sh->checksum = 0;
  
++<<<<<<< HEAD
 +	/**
 +	 * 6.10 Bundling
 +	 *
 +	 *    An endpoint bundles chunks by simply including multiple
 +	 *    chunks in one outbound SCTP packet.  ...
 +	 */
 +
 +	/**
 +	 * 3.2  Chunk Field Descriptions
 +	 *
 +	 * The total length of a chunk (including Type, Length and
 +	 * Value fields) MUST be a multiple of 4 bytes.  If the length
 +	 * of the chunk is not a multiple of 4 bytes, the sender MUST
 +	 * pad the chunk with all zero bytes and this padding is not
 +	 * included in the chunk length field.  The sender should
 +	 * never pad with more than 3 bytes.
 +	 *
 +	 * [This whole comment explains WORD_ROUND() below.]
 +	 */
 +	SCTP_DEBUG_PRINTK("***sctp_transmit_packet***\n");
 +	list_for_each_entry_safe(chunk, tmp, &packet->chunk_list, list) {
 +		list_del_init(&chunk->list);
 +		if (sctp_chunk_is_data(chunk)) {
 +			/* 6.3.1 C4) When data is in flight and when allowed
 +			 * by rule C5, a new RTT measurement MUST be made each
 +			 * round trip.  Furthermore, new RTT measurements
 +			 * SHOULD be made no more than once per round-trip
 +			 * for a given destination transport address.
 +			 */
++=======
+ 	pr_debug("***sctp_transmit_packet***\n");
+ 
+ 	do {
+ 		/* Set up convenience variables... */
+ 		chunk = list_entry(packet->chunk_list.next, struct sctp_chunk, list);
+ 		pktcount++;
++>>>>>>> 90017accff61 (sctp: Add GSO support)
  
- 			if (!chunk->resent && !tp->rto_pending) {
- 				chunk->rtt_in_progress = 1;
- 				tp->rto_pending = 1;
+ 		/* Calculate packet size, so it fits in PMTU. Leave
+ 		 * other chunks for the next packets.
+ 		 */
+ 		if (gso) {
+ 			pkt_size = packet->overhead;
+ 			list_for_each_entry(chunk, &packet->chunk_list, list) {
+ 				int padded = WORD_ROUND(chunk->skb->len);
+ 
+ 				if (pkt_size + padded > tp->pathmtu)
+ 					break;
+ 				pkt_size += padded;
  			}
  
- 			has_data = 1;
- 		}
+ 			/* Allocate a new skb. */
+ 			nskb = alloc_skb(pkt_size + MAX_HEADER, gfp);
+ 			if (!nskb)
+ 				goto nomem;
  
- 		padding = WORD_ROUND(chunk->skb->len) - chunk->skb->len;
- 		if (padding)
- 			memset(skb_put(chunk->skb, padding), 0, padding);
+ 			/* Make sure the outbound skb has enough header
+ 			 * room reserved.
+ 			 */
+ 			skb_reserve(nskb, packet->overhead + MAX_HEADER);
+ 		} else {
+ 			nskb = head;
+ 		}
  
- 		/* if this is the auth chunk that we are adding,
- 		 * store pointer where it will be added and put
- 		 * the auth into the packet.
+ 		/**
+ 		 * 3.2  Chunk Field Descriptions
+ 		 *
+ 		 * The total length of a chunk (including Type, Length and
+ 		 * Value fields) MUST be a multiple of 4 bytes.  If the length
+ 		 * of the chunk is not a multiple of 4 bytes, the sender MUST
+ 		 * pad the chunk with all zero bytes and this padding is not
+ 		 * included in the chunk length field.  The sender should
+ 		 * never pad with more than 3 bytes.
+ 		 *
+ 		 * [This whole comment explains WORD_ROUND() below.]
  		 */
- 		if (chunk == packet->auth)
- 			auth = skb_tail_pointer(nskb);
  
- 		memcpy(skb_put(nskb, chunk->skb->len),
+ 		pkt_size -= packet->overhead;
+ 		list_for_each_entry_safe(chunk, tmp, &packet->chunk_list, list) {
+ 			list_del_init(&chunk->list);
+ 			if (sctp_chunk_is_data(chunk)) {
+ 				/* 6.3.1 C4) When data is in flight and when allowed
+ 				 * by rule C5, a new RTT measurement MUST be made each
+ 				 * round trip.  Furthermore, new RTT measurements
+ 				 * SHOULD be made no more than once per round-trip
+ 				 * for a given destination transport address.
+ 				 */
+ 
+ 				if (!chunk->resent && !tp->rto_pending) {
+ 					chunk->rtt_in_progress = 1;
+ 					tp->rto_pending = 1;
+ 				}
+ 
+ 				has_data = 1;
+ 			}
+ 
+ 			padding = WORD_ROUND(chunk->skb->len) - chunk->skb->len;
+ 			if (padding)
+ 				memset(skb_put(chunk->skb, padding), 0, padding);
+ 
+ 			/* if this is the auth chunk that we are adding,
+ 			 * store pointer where it will be added and put
+ 			 * the auth into the packet.
+ 			 */
+ 			if (chunk == packet->auth)
+ 				auth = skb_tail_pointer(nskb);
+ 
+ 			memcpy(skb_put(nskb, chunk->skb->len),
  			       chunk->skb->data, chunk->skb->len);
  
++<<<<<<< HEAD
 +		SCTP_DEBUG_PRINTK("%s %p[%s] %s 0x%x, %s %d, %s %d, %s %d\n",
 +				  "*** Chunk", chunk,
 +				  sctp_cname(SCTP_ST_CHUNK(
 +					  chunk->chunk_hdr->type)),
 +				  chunk->has_tsn ? "TSN" : "No TSN",
 +				  chunk->has_tsn ?
 +				  ntohl(chunk->subh.data_hdr->tsn) : 0,
 +				  "length", ntohs(chunk->chunk_hdr->length),
 +				  "chunk->skb->len", chunk->skb->len,
 +				  "rtt_in_progress", chunk->rtt_in_progress);
++=======
+ 			pr_debug("*** Chunk:%p[%s] %s 0x%x, length:%d, chunk->skb->len:%d, rtt_in_progress:%d\n",
+ 				 chunk,
+ 				 sctp_cname(SCTP_ST_CHUNK(chunk->chunk_hdr->type)),
+ 				 chunk->has_tsn ? "TSN" : "No TSN",
+ 				 chunk->has_tsn ? ntohl(chunk->subh.data_hdr->tsn) : 0,
+ 				 ntohs(chunk->chunk_hdr->length), chunk->skb->len,
+ 				 chunk->rtt_in_progress);
++>>>>>>> 90017accff61 (sctp: Add GSO support)
+ 
+ 			/* If this is a control chunk, this is our last
+ 			 * reference. Free data chunks after they've been
+ 			 * acknowledged or have failed.
+ 			 * Re-queue auth chunks if needed.
+ 			 */
+ 			pkt_size -= WORD_ROUND(chunk->skb->len);
  
- 		/*
- 		 * If this is a control chunk, this is our last
- 		 * reference. Free data chunks after they've been
- 		 * acknowledged or have failed.
- 		 */
- 		if (!sctp_chunk_is_data(chunk))
- 			sctp_chunk_free(chunk);
- 	}
+ 			if (chunk == packet->auth && !list_empty(&packet->chunk_list))
+ 				list_add(&chunk->list, &packet->chunk_list);
+ 			else if (!sctp_chunk_is_data(chunk))
+ 				sctp_chunk_free(chunk);
  
- 	/* SCTP-AUTH, Section 6.2
- 	 *    The sender MUST calculate the MAC as described in RFC2104 [2]
- 	 *    using the hash function H as described by the MAC Identifier and
- 	 *    the shared association key K based on the endpoint pair shared key
- 	 *    described by the shared key identifier.  The 'data' used for the
- 	 *    computation of the AUTH-chunk is given by the AUTH chunk with its
- 	 *    HMAC field set to zero (as shown in Figure 6) followed by all
- 	 *    chunks that are placed after the AUTH chunk in the SCTP packet.
- 	 */
- 	if (auth)
- 		sctp_auth_calculate_hmac(asoc, nskb,
- 					 (struct sctp_auth_chunk *)auth,
- 					 gfp);
+ 			if (!pkt_size)
+ 				break;
+ 		}
+ 
+ 		/* SCTP-AUTH, Section 6.2
+ 		 *    The sender MUST calculate the MAC as described in RFC2104 [2]
+ 		 *    using the hash function H as described by the MAC Identifier and
+ 		 *    the shared association key K based on the endpoint pair shared key
+ 		 *    described by the shared key identifier.  The 'data' used for the
+ 		 *    computation of the AUTH-chunk is given by the AUTH chunk with its
+ 		 *    HMAC field set to zero (as shown in Figure 6) followed by all
+ 		 *    chunks that are placed after the AUTH chunk in the SCTP packet.
+ 		 */
+ 		if (auth)
+ 			sctp_auth_calculate_hmac(asoc, nskb,
+ 						 (struct sctp_auth_chunk *)auth,
+ 						 gfp);
+ 
+ 		if (!gso)
+ 			break;
+ 
+ 		if (skb_gro_receive(&head, nskb))
+ 			goto nomem;
+ 		nskb = NULL;
+ 		if (WARN_ON_ONCE(skb_shinfo(head)->gso_segs >=
+ 				 sk->sk_gso_max_segs))
+ 			goto nomem;
+ 	} while (!list_empty(&packet->chunk_list));
  
  	/* 2) Calculate the Adler-32 checksum of the whole packet,
  	 *    including the SCTP common header and all the
@@@ -544,17 -621,18 +677,31 @@@
  	 *
  	 * Note: Adler-32 is no longer applicable, as has been replaced
  	 * by CRC32-C as described in <draft-ietf-tsvwg-sctpcsum-02.txt>.
+ 	 *
+ 	 * If it's a GSO packet, it's postponed to sctp_skb_segment.
  	 */
++<<<<<<< HEAD
 +	if (!sctp_checksum_disable) {
 +		if (!(dst->dev->features & NETIF_F_SCTP_CSUM) ||
 +		    (dst_xfrm(dst) != NULL) || packet->ipfragok) {
 +			sh->checksum = sctp_compute_cksum(nskb, 0);
 +		} else {
 +			/* no need to seed pseudo checksum for SCTP */
 +			nskb->ip_summed = CHECKSUM_PARTIAL;
 +			nskb->csum_start = (skb_transport_header(nskb) -
 +			                    nskb->head);
 +			nskb->csum_offset = offsetof(struct sctphdr, checksum);
++=======
+ 	if (!sctp_checksum_disable || gso) {
+ 		if (!gso && (!(dst->dev->features & NETIF_F_SCTP_CRC) ||
+ 			     dst_xfrm(dst) || packet->ipfragok)) {
+ 			sh->checksum = sctp_compute_cksum(head, 0);
+ 		} else {
+ 			/* no need to seed pseudo checksum for SCTP */
+ 			head->ip_summed = CHECKSUM_PARTIAL;
+ 			head->csum_start = skb_transport_header(head) - head->head;
+ 			head->csum_offset = offsetof(struct sctphdr, checksum);
++>>>>>>> 90017accff61 (sctp: Add GSO support)
  		}
  	}
  
@@@ -570,7 -648,7 +717,11 @@@
  	 * Note: The works for IPv6 layer checks this bit too later
  	 * in transmission.  See IP6_ECN_flow_xmit().
  	 */
++<<<<<<< HEAD
 +	(*tp->af_specific->ecn_capable)(nskb->sk);
++=======
+ 	tp->af_specific->ecn_capable(sk);
++>>>>>>> 90017accff61 (sctp: Add GSO support)
  
  	/* Set up the IP options.  */
  	/* BUG: not implemented
@@@ -601,18 -680,39 +752,52 @@@
  		}
  	}
  
++<<<<<<< HEAD
 +	SCTP_DEBUG_PRINTK("***sctp_transmit_packet*** skb len %d\n",
 +			  nskb->len);
 +
 +	nskb->ignore_df = packet->ipfragok;
 +	(*tp->af_specific->sctp_xmit)(nskb, tp);
++=======
+ 	pr_debug("***sctp_transmit_packet*** skb->len:%d\n", head->len);
+ 
+ 	if (gso) {
+ 		/* Cleanup our debris for IP stacks */
+ 		memset(head->cb, 0, max(sizeof(struct inet_skb_parm),
+ 					sizeof(struct inet6_skb_parm)));
+ 
+ 		skb_shinfo(head)->gso_segs = pktcount;
+ 		skb_shinfo(head)->gso_size = GSO_BY_FRAGS;
+ 
+ 		/* We have to refresh this in case we are xmiting to
+ 		 * more than one transport at a time
+ 		 */
+ 		rcu_read_lock();
+ 		if (__sk_dst_get(sk) != tp->dst) {
+ 			dst_hold(tp->dst);
+ 			sk_setup_caps(sk, tp->dst);
+ 		}
+ 		rcu_read_unlock();
+ 	}
+ 	head->ignore_df = packet->ipfragok;
+ 	tp->af_specific->sctp_xmit(head, tp);
++>>>>>>> 90017accff61 (sctp: Add GSO support)
  
  out:
  	sctp_packet_reset(packet);
  	return err;
  no_route:
++<<<<<<< HEAD
 +	kfree_skb(nskb);
 +	IP_INC_STATS_BH(sock_net(asoc->base.sk), IPSTATS_MIB_OUTNOROUTES);
++=======
+ 	kfree_skb(head);
+ 	if (nskb != head)
+ 		kfree_skb(nskb);
+ 
+ 	if (asoc)
+ 		IP_INC_STATS(sock_net(asoc->base.sk), IPSTATS_MIB_OUTNOROUTES);
++>>>>>>> 90017accff61 (sctp: Add GSO support)
  
  	/* FIXME: Returning the 'err' will effect all the associations
  	 * associated with a socket, although only one of the paths of the
* Unmerged path include/linux/netdev_features.h
* Unmerged path include/linux/netdevice.h
* Unmerged path include/linux/skbuff.h
diff --git a/include/net/sctp/sctp.h b/include/net/sctp/sctp.h
index dc59f95106d2..1b1217fb8f85 100644
--- a/include/net/sctp/sctp.h
+++ b/include/net/sctp/sctp.h
@@ -195,6 +195,10 @@ void sctp_assocs_proc_exit(struct net *net);
 int sctp_remaddr_proc_init(struct net *net);
 void sctp_remaddr_proc_exit(struct net *net);
 
+/*
+ * sctp/offload.c
+ */
+int sctp_offload_init(void);
 
 /*
  * Module global variables
diff --git a/include/net/sctp/structs.h b/include/net/sctp/structs.h
index f67eb807b1dd..3530aaf54e3f 100644
--- a/include/net/sctp/structs.h
+++ b/include/net/sctp/structs.h
@@ -576,6 +576,9 @@ struct sctp_chunk {
 	/* This points to the sk_buff containing the actual data.  */
 	struct sk_buff *skb;
 
+	/* In case of GSO packets, this will store the head one */
+	struct sk_buff *head_skb;
+
 	/* These are the SCTP headers by reverse order in a packet.
 	 * Note that some of these may happen more than once.  In that
 	 * case, we point at the "current" one, whatever that means
@@ -707,6 +710,8 @@ struct sctp_packet {
 	size_t overhead;
 	/* This is the total size of all chunks INCLUDING padding.  */
 	size_t size;
+	/* This is the maximum size this packet may have */
+	size_t max_size;
 
 	/* The packet is destined for this transport address.
 	 * The function we finally use to pass down to the next lower
* Unmerged path net/core/ethtool.c
diff --git a/net/core/skbuff.c b/net/core/skbuff.c
index a695cad46f55..6358333490df 100644
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -49,6 +49,7 @@
 #include <linux/slab.h>
 #include <linux/tcp.h>
 #include <linux/udp.h>
+#include <linux/sctp.h>
 #include <linux/netdevice.h>
 #ifdef CONFIG_NET_CLS_ACT
 #include <net/pkt_sched.h>
@@ -3876,6 +3877,8 @@ unsigned int skb_gso_transport_seglen(const struct sk_buff *skb)
 			thlen += inner_tcp_hdrlen(skb);
 	} else if (likely(shinfo->gso_type & (SKB_GSO_TCPV4 | SKB_GSO_TCPV6))) {
 		thlen = tcp_hdrlen(skb);
+	} else if (unlikely(shinfo->gso_type & SKB_GSO_SCTP)) {
+		thlen = sizeof(struct sctphdr);
 	}
 	/* UFO sets gso_size to the size of the fragmentation
 	 * payload, i.e. the size of the L4 (UDP) header is already
diff --git a/net/sctp/Makefile b/net/sctp/Makefile
index 4d00fde2acc6..f34e31df8dc9 100644
--- a/net/sctp/Makefile
+++ b/net/sctp/Makefile
@@ -11,7 +11,8 @@ sctp-y := sm_statetable.o sm_statefuns.o sm_sideeffect.o \
 	  transport.o chunk.o sm_make_chunk.o ulpevent.o \
 	  inqueue.o outqueue.o ulpqueue.o command.o \
 	  tsnmap.o bind_addr.o socket.o primitive.o \
-	  output.o input.o debug.o ssnmap.o auth.o
+	  output.o input.o debug.o ssnmap.o auth.o \
+	  offload.o
 
 sctp_probe-y := probe.o
 
diff --git a/net/sctp/input.c b/net/sctp/input.c
index c53999ec1d68..233f74f71616 100644
--- a/net/sctp/input.c
+++ b/net/sctp/input.c
@@ -146,7 +146,9 @@ int sctp_rcv(struct sk_buff *skb)
 	skb->csum_valid = 0; /* Previous value not applicable */
 	if (skb_csum_unnecessary(skb))
 		__skb_decr_checksum_unnecessary(skb);
-	else if (!sctp_checksum_disable && sctp_rcv_checksum(net, skb) < 0)
+	else if (!sctp_checksum_disable &&
+		 !(skb_shinfo(skb)->gso_type & SKB_GSO_SCTP) &&
+		 sctp_rcv_checksum(net, skb) < 0)
 		goto discard_it;
 	skb->csum_valid = 1;
 
@@ -1259,6 +1261,14 @@ static struct sctp_association *__sctp_rcv_lookup_harder(struct net *net,
 {
 	sctp_chunkhdr_t *ch;
 
+	/* We do not allow GSO frames here as we need to linearize and
+	 * then cannot guarantee frame boundaries. This shouldn't be an
+	 * issue as packets hitting this are mostly INIT or INIT-ACK and
+	 * those cannot be on GSO-style anyway.
+	 */
+	if ((skb_shinfo(skb)->gso_type & SKB_GSO_SCTP) == SKB_GSO_SCTP)
+		return NULL;
+
 	if (skb_linearize(skb))
 		return NULL;
 
diff --git a/net/sctp/inqueue.c b/net/sctp/inqueue.c
index f49b9cedb9f5..558eda2b41fd 100644
--- a/net/sctp/inqueue.c
+++ b/net/sctp/inqueue.c
@@ -143,6 +143,17 @@ struct sctp_chunk *sctp_inq_pop(struct sctp_inq *queue)
 		if (chunk->singleton ||
 		    chunk->end_of_packet ||
 		    chunk->pdiscard) {
+			if (chunk->head_skb == chunk->skb) {
+				chunk->skb = skb_shinfo(chunk->skb)->frag_list;
+				goto new_skb;
+			}
+			if (chunk->skb->next) {
+				chunk->skb = chunk->skb->next;
+				goto new_skb;
+			}
+
+			if (chunk->head_skb)
+				chunk->skb = chunk->head_skb;
 			sctp_chunk_free(chunk);
 			chunk = queue->in_progress = NULL;
 		} else {
@@ -160,15 +171,15 @@ struct sctp_chunk *sctp_inq_pop(struct sctp_inq *queue)
 
 next_chunk:
 		/* Is the queue empty?  */
-		if (list_empty(&queue->in_chunk_list))
+		entry = sctp_list_dequeue(&queue->in_chunk_list);
+		if (!entry)
 			return NULL;
 
-		entry = queue->in_chunk_list.next;
 		chunk = list_entry(entry, struct sctp_chunk, list);
-		list_del_init(entry);
 
 		/* Linearize if it's not GSO */
-		if (skb_is_nonlinear(chunk->skb)) {
+		if ((skb_shinfo(chunk->skb)->gso_type & SKB_GSO_SCTP) != SKB_GSO_SCTP &&
+		    skb_is_nonlinear(chunk->skb)) {
 			if (skb_linearize(chunk->skb)) {
 				__SCTP_INC_STATS(dev_net(chunk->skb->dev), SCTP_MIB_IN_PKT_DISCARDS);
 				sctp_chunk_free(chunk);
@@ -179,15 +190,39 @@ next_chunk:
 			chunk->sctp_hdr = sctp_hdr(chunk->skb);
 		}
 
+		if ((skb_shinfo(chunk->skb)->gso_type & SKB_GSO_SCTP) == SKB_GSO_SCTP) {
+			/* GSO-marked skbs but without frags, handle
+			 * them normally
+			 */
+			if (skb_shinfo(chunk->skb)->frag_list)
+				chunk->head_skb = chunk->skb;
+
+			/* skbs with "cover letter" */
+			if (chunk->head_skb && chunk->skb->data_len == chunk->skb->len)
+				chunk->skb = skb_shinfo(chunk->skb)->frag_list;
+
+			if (WARN_ON(!chunk->skb)) {
+				__SCTP_INC_STATS(dev_net(chunk->skb->dev), SCTP_MIB_IN_PKT_DISCARDS);
+				sctp_chunk_free(chunk);
+				goto next_chunk;
+			}
+		}
+
+		if (chunk->asoc)
+			sock_rps_save_rxhash(chunk->asoc->base.sk, chunk->skb);
+
 		queue->in_progress = chunk;
 
+new_skb:
 		/* This is the first chunk in the packet.  */
-		chunk->singleton = 1;
 		ch = (sctp_chunkhdr_t *) chunk->skb->data;
+		chunk->singleton = 1;
 		chunk->data_accepted = 0;
-
-		if (chunk->asoc)
-			sock_rps_save_rxhash(chunk->asoc->base.sk, chunk->skb);
+		chunk->pdiscard = 0;
+		chunk->auth = 0;
+		chunk->has_asconf = 0;
+		chunk->end_of_packet = 0;
+		chunk->ecn_ce_done = 0;
 	}
 
 	chunk->chunk_hdr = ch;
diff --git a/net/sctp/offload.c b/net/sctp/offload.c
new file mode 100644
index 000000000000..a37887b373a7
--- /dev/null
+++ b/net/sctp/offload.c
@@ -0,0 +1,98 @@
+/*
+ * sctp_offload - GRO/GSO Offloading for SCTP
+ *
+ * Copyright (C) 2015, Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
+#include <linux/kernel.h>
+#include <linux/kprobes.h>
+#include <linux/socket.h>
+#include <linux/sctp.h>
+#include <linux/proc_fs.h>
+#include <linux/vmalloc.h>
+#include <linux/module.h>
+#include <linux/kfifo.h>
+#include <linux/time.h>
+#include <net/net_namespace.h>
+
+#include <linux/skbuff.h>
+#include <net/sctp/sctp.h>
+#include <net/sctp/checksum.h>
+#include <net/protocol.h>
+
+static __le32 sctp_gso_make_checksum(struct sk_buff *skb)
+{
+	skb->ip_summed = CHECKSUM_NONE;
+	return sctp_compute_cksum(skb, skb_transport_offset(skb));
+}
+
+static struct sk_buff *sctp_gso_segment(struct sk_buff *skb,
+					netdev_features_t features)
+{
+	struct sk_buff *segs = ERR_PTR(-EINVAL);
+	struct sctphdr *sh;
+
+	sh = sctp_hdr(skb);
+	if (!pskb_may_pull(skb, sizeof(*sh)))
+		goto out;
+
+	__skb_pull(skb, sizeof(*sh));
+
+	if (skb_gso_ok(skb, features | NETIF_F_GSO_ROBUST)) {
+		/* Packet is from an untrusted source, reset gso_segs. */
+		struct skb_shared_info *pinfo = skb_shinfo(skb);
+		struct sk_buff *frag_iter;
+
+		pinfo->gso_segs = 0;
+		if (skb->len != skb->data_len) {
+			/* Means we have chunks in here too */
+			pinfo->gso_segs++;
+		}
+
+		skb_walk_frags(skb, frag_iter)
+			pinfo->gso_segs++;
+
+		segs = NULL;
+		goto out;
+	}
+
+	segs = skb_segment(skb, features | NETIF_F_HW_CSUM);
+	if (IS_ERR(segs))
+		goto out;
+
+	/* All that is left is update SCTP CRC if necessary */
+	if (!(features & NETIF_F_SCTP_CRC)) {
+		for (skb = segs; skb; skb = skb->next) {
+			if (skb->ip_summed == CHECKSUM_PARTIAL) {
+				sh = sctp_hdr(skb);
+				sh->checksum = sctp_gso_make_checksum(skb);
+			}
+		}
+	}
+
+out:
+	return segs;
+}
+
+static const struct net_offload sctp_offload = {
+	.callbacks = {
+		.gso_segment = sctp_gso_segment,
+	},
+};
+
+int __init sctp_offload_init(void)
+{
+	return inet_add_offload(&sctp_offload, IPPROTO_SCTP);
+}
* Unmerged path net/sctp/output.c
diff --git a/net/sctp/protocol.c b/net/sctp/protocol.c
index ce4856e5bfb8..a6917d842bd3 100644
--- a/net/sctp/protocol.c
+++ b/net/sctp/protocol.c
@@ -1502,6 +1502,9 @@ SCTP_STATIC __init int sctp_init(void)
 	if (status)
 		goto err_v6_add_protocol;
 
+	if (sctp_offload_init() < 0)
+		pr_crit("%s: Cannot add SCTP protocol offload\n", __func__);
+
 out:
 	return status;
 err_v6_add_protocol:
diff --git a/net/sctp/socket.c b/net/sctp/socket.c
index 034c1b60f4e3..cf170888104e 100644
--- a/net/sctp/socket.c
+++ b/net/sctp/socket.c
@@ -3903,6 +3903,8 @@ SCTP_STATIC int sctp_init_sock(struct sock *sk)
 		return -ESOCKTNOSUPPORT;
 	}
 
+	sk->sk_gso_type = SKB_GSO_SCTP;
+
 	/* Initialize default send parameters. These parameters can be
 	 * modified with the SCTP_DEFAULT_SEND_PARAM socket option.
 	 */
