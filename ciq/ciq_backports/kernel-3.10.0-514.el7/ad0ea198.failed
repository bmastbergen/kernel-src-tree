ipv4: fix broadcast packets reception

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Paolo Abeni <pabeni@redhat.com>
commit ad0ea1989cc4d5905941d0a9e62c63ad6d859cef
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/ad0ea198.failed

Currently, ingress ipv4 broadcast datagrams are dropped since,
in udp_v4_early_demux(), ip_check_mc_rcu() is invoked even on
bcast packets.

This patch addresses the issue, invoking ip_check_mc_rcu()
only for mcast packets.

Fixes: 6e5403093261 ("ipv4/udp: Verify multicast group is ours in upd_v4_early_demux()")
	Signed-off-by: Paolo Abeni <pabeni@redhat.com>
	Acked-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit ad0ea1989cc4d5905941d0a9e62c63ad6d859cef)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/ipv4/udp.c
diff --cc net/ipv4/udp.c
index 556580e2c4f8,08eed5e16df0..000000000000
--- a/net/ipv4/udp.c
+++ b/net/ipv4/udp.c
@@@ -1809,6 -1949,164 +1809,167 @@@ drop
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ /* We can only early demux multicast if there is a single matching socket.
+  * If more than one socket found returns NULL
+  */
+ static struct sock *__udp4_lib_mcast_demux_lookup(struct net *net,
+ 						  __be16 loc_port, __be32 loc_addr,
+ 						  __be16 rmt_port, __be32 rmt_addr,
+ 						  int dif)
+ {
+ 	struct sock *sk, *result;
+ 	struct hlist_nulls_node *node;
+ 	unsigned short hnum = ntohs(loc_port);
+ 	unsigned int count, slot = udp_hashfn(net, hnum, udp_table.mask);
+ 	struct udp_hslot *hslot = &udp_table.hash[slot];
+ 
+ 	/* Do not bother scanning a too big list */
+ 	if (hslot->count > 10)
+ 		return NULL;
+ 
+ 	rcu_read_lock();
+ begin:
+ 	count = 0;
+ 	result = NULL;
+ 	sk_nulls_for_each_rcu(sk, node, &hslot->head) {
+ 		if (__udp_is_mcast_sock(net, sk,
+ 					loc_port, loc_addr,
+ 					rmt_port, rmt_addr,
+ 					dif, hnum)) {
+ 			result = sk;
+ 			++count;
+ 		}
+ 	}
+ 	/*
+ 	 * if the nulls value we got at the end of this lookup is
+ 	 * not the expected one, we must restart lookup.
+ 	 * We probably met an item that was moved to another chain.
+ 	 */
+ 	if (get_nulls_value(node) != slot)
+ 		goto begin;
+ 
+ 	if (result) {
+ 		if (count != 1 ||
+ 		    unlikely(!atomic_inc_not_zero_hint(&result->sk_refcnt, 2)))
+ 			result = NULL;
+ 		else if (unlikely(!__udp_is_mcast_sock(net, result,
+ 						       loc_port, loc_addr,
+ 						       rmt_port, rmt_addr,
+ 						       dif, hnum))) {
+ 			sock_put(result);
+ 			result = NULL;
+ 		}
+ 	}
+ 	rcu_read_unlock();
+ 	return result;
+ }
+ 
+ /* For unicast we should only early demux connected sockets or we can
+  * break forwarding setups.  The chains here can be long so only check
+  * if the first socket is an exact match and if not move on.
+  */
+ static struct sock *__udp4_lib_demux_lookup(struct net *net,
+ 					    __be16 loc_port, __be32 loc_addr,
+ 					    __be16 rmt_port, __be32 rmt_addr,
+ 					    int dif)
+ {
+ 	struct sock *sk, *result;
+ 	struct hlist_nulls_node *node;
+ 	unsigned short hnum = ntohs(loc_port);
+ 	unsigned int hash2 = udp4_portaddr_hash(net, loc_addr, hnum);
+ 	unsigned int slot2 = hash2 & udp_table.mask;
+ 	struct udp_hslot *hslot2 = &udp_table.hash2[slot2];
+ 	INET_ADDR_COOKIE(acookie, rmt_addr, loc_addr);
+ 	const __portpair ports = INET_COMBINED_PORTS(rmt_port, hnum);
+ 
+ 	rcu_read_lock();
+ 	result = NULL;
+ 	udp_portaddr_for_each_entry_rcu(sk, node, &hslot2->head) {
+ 		if (INET_MATCH(sk, net, acookie,
+ 			       rmt_addr, loc_addr, ports, dif))
+ 			result = sk;
+ 		/* Only check first socket in chain */
+ 		break;
+ 	}
+ 
+ 	if (result) {
+ 		if (unlikely(!atomic_inc_not_zero_hint(&result->sk_refcnt, 2)))
+ 			result = NULL;
+ 		else if (unlikely(!INET_MATCH(sk, net, acookie,
+ 					      rmt_addr, loc_addr,
+ 					      ports, dif))) {
+ 			sock_put(result);
+ 			result = NULL;
+ 		}
+ 	}
+ 	rcu_read_unlock();
+ 	return result;
+ }
+ 
+ void udp_v4_early_demux(struct sk_buff *skb)
+ {
+ 	struct net *net = dev_net(skb->dev);
+ 	const struct iphdr *iph;
+ 	const struct udphdr *uh;
+ 	struct sock *sk;
+ 	struct dst_entry *dst;
+ 	int dif = skb->dev->ifindex;
+ 	int ours;
+ 
+ 	/* validate the packet */
+ 	if (!pskb_may_pull(skb, skb_transport_offset(skb) + sizeof(struct udphdr)))
+ 		return;
+ 
+ 	iph = ip_hdr(skb);
+ 	uh = udp_hdr(skb);
+ 
+ 	if (skb->pkt_type == PACKET_BROADCAST ||
+ 	    skb->pkt_type == PACKET_MULTICAST) {
+ 		struct in_device *in_dev = __in_dev_get_rcu(skb->dev);
+ 
+ 		if (!in_dev)
+ 			return;
+ 
+ 		/* we are supposed to accept bcast packets */
+ 		if (skb->pkt_type == PACKET_MULTICAST) {
+ 			ours = ip_check_mc_rcu(in_dev, iph->daddr, iph->saddr,
+ 					       iph->protocol);
+ 			if (!ours)
+ 				return;
+ 		}
+ 
+ 		sk = __udp4_lib_mcast_demux_lookup(net, uh->dest, iph->daddr,
+ 						   uh->source, iph->saddr, dif);
+ 	} else if (skb->pkt_type == PACKET_HOST) {
+ 		sk = __udp4_lib_demux_lookup(net, uh->dest, iph->daddr,
+ 					     uh->source, iph->saddr, dif);
+ 	} else {
+ 		return;
+ 	}
+ 
+ 	if (!sk)
+ 		return;
+ 
+ 	skb->sk = sk;
+ 	skb->destructor = sock_efree;
+ 	dst = READ_ONCE(sk->sk_rx_dst);
+ 
+ 	if (dst)
+ 		dst = dst_check(dst, 0);
+ 	if (dst) {
+ 		/* DST_NOCACHE can not be used without taking a reference */
+ 		if (dst->flags & DST_NOCACHE) {
+ 			if (likely(atomic_inc_not_zero(&dst->__refcnt)))
+ 				skb_dst_set(skb, dst);
+ 		} else {
+ 			skb_dst_set_noref(skb, dst);
+ 		}
+ 	}
+ }
+ 
++>>>>>>> ad0ea1989cc4 (ipv4: fix broadcast packets reception)
  int udp_rcv(struct sk_buff *skb)
  {
  	return __udp4_lib_rcv(skb, &udp_table, IPPROTO_UDP);
* Unmerged path net/ipv4/udp.c
