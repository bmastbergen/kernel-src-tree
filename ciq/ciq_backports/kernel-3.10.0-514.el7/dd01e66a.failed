IB/mlx5: Remove old FRWR API support

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Sagi Grimberg <sagig@mellanox.com>
commit dd01e66a6c532a8cd183cbc02ebaef99f186345f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/dd01e66a.failed

No ULP uses it anymore, go ahead and remove it.
Keep only the local invalidate part of the handlers.

	Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
	Acked-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit dd01e66a6c532a8cd183cbc02ebaef99f186345f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/qp.c
diff --cc drivers/infiniband/hw/mlx5/qp.c
index 0d61971fa13b,307bdbca8938..000000000000
--- a/drivers/infiniband/hw/mlx5/qp.c
+++ b/drivers/infiniband/hw/mlx5/qp.c
@@@ -1908,20 -1907,11 +1907,24 @@@ static void set_reg_umr_seg(struct mlx5
  	umr->mkey_mask = frwr_mkey_mask();
  }
  
- static void set_frwr_umr_segment(struct mlx5_wqe_umr_ctrl_seg *umr,
- 				 struct ib_send_wr *wr, int li)
+ static void set_linv_umr_seg(struct mlx5_wqe_umr_ctrl_seg *umr)
  {
  	memset(umr, 0, sizeof(*umr));
++<<<<<<< HEAD
 +
 +	if (li) {
 +		umr->mkey_mask = cpu_to_be64(MLX5_MKEY_MASK_FREE);
 +		umr->flags = 1 << 7;
 +		return;
 +	}
 +
 +	umr->flags = (1 << 5); /* fail if not free */
 +	umr->klm_octowords = get_klm_octo(wr->wr.fast_reg.page_list_len);
 +	umr->mkey_mask = frwr_mkey_mask();
++=======
+ 	umr->mkey_mask = cpu_to_be64(MLX5_MKEY_MASK_FREE);
+ 	umr->flags = 1 << 7;
++>>>>>>> dd01e66a6c53 (IB/mlx5: Remove old FRWR API support)
  }
  
  static __be64 get_umr_reg_mr_mask(void)
@@@ -2015,24 -2005,10 +2018,27 @@@ static void set_reg_mkey_seg(struct mlx
  	seg->log2_page_size = ilog2(mr->ibmr.page_size);
  }
  
- static void set_mkey_segment(struct mlx5_mkey_seg *seg, struct ib_send_wr *wr,
- 			     int li, int *writ)
+ static void set_linv_mkey_seg(struct mlx5_mkey_seg *seg)
  {
  	memset(seg, 0, sizeof(*seg));
++<<<<<<< HEAD
 +	if (li) {
 +		seg->status = MLX5_MKEY_STATUS_FREE;
 +		return;
 +	}
 +
 +	seg->flags = get_umr_flags(wr->wr.fast_reg.access_flags) |
 +		     MLX5_ACCESS_MODE_MTT;
 +	*writ = seg->flags & (MLX5_PERM_LOCAL_WRITE | IB_ACCESS_REMOTE_WRITE);
 +	seg->qpn_mkey7_0 = cpu_to_be32((wr->wr.fast_reg.rkey & 0xff) | 0xffffff00);
 +	seg->flags_pd = cpu_to_be32(MLX5_MKEY_REMOTE_INVAL);
 +	seg->start_addr = cpu_to_be64(wr->wr.fast_reg.iova_start);
 +	seg->len = cpu_to_be64(wr->wr.fast_reg.length);
 +	seg->xlt_oct_size = cpu_to_be32((wr->wr.fast_reg.page_list_len + 1) / 2);
 +	seg->log2_page_size = wr->wr.fast_reg.page_shift;
++=======
+ 	seg->status = MLX5_MKEY_STATUS_FREE;
++>>>>>>> dd01e66a6c53 (IB/mlx5: Remove old FRWR API support)
  }
  
  static void set_reg_mkey_segment(struct mlx5_mkey_seg *seg, struct ib_send_wr *wr)
@@@ -2067,24 -2043,6 +2073,27 @@@ static void set_reg_data_seg(struct mlx
  	dseg->lkey = cpu_to_be32(pd->ibpd.local_dma_lkey);
  }
  
++<<<<<<< HEAD
 +static void set_frwr_pages(struct mlx5_wqe_data_seg *dseg,
 +			   struct ib_send_wr *wr,
 +			   struct mlx5_core_dev *mdev,
 +			   struct mlx5_ib_pd *pd,
 +			   int writ)
 +{
 +	struct mlx5_ib_fast_reg_page_list *mfrpl = to_mfrpl(wr->wr.fast_reg.page_list);
 +	u64 *page_list = wr->wr.fast_reg.page_list->page_list;
 +	u64 perm = MLX5_EN_RD | (writ ? MLX5_EN_WR : 0);
 +	int i;
 +
 +	for (i = 0; i < wr->wr.fast_reg.page_list_len; i++)
 +		mfrpl->mapped_page_list[i] = cpu_to_be64(page_list[i] | perm);
 +	dseg->addr = cpu_to_be64(mfrpl->map);
 +	dseg->byte_count = cpu_to_be32(ALIGN(sizeof(u64) * wr->wr.fast_reg.page_list_len, 64));
 +	dseg->lkey = cpu_to_be32(pd->ibpd.local_dma_lkey);
 +}
 +
++=======
++>>>>>>> dd01e66a6c53 (IB/mlx5: Remove old FRWR API support)
  static __be32 send_ieth(struct ib_send_wr *wr)
  {
  	switch (wr->opcode) {
@@@ -2524,16 -2474,6 +2525,19 @@@ static void set_linv_wr(struct mlx5_ib_
  	*size += sizeof(struct mlx5_mkey_seg) / 16;
  	if (unlikely((*seg == qp->sq.qend)))
  		*seg = mlx5_get_send_wqe(qp, 0);
++<<<<<<< HEAD
 +	if (!li) {
 +		if (unlikely(wr->wr.fast_reg.page_list_len >
 +			     wr->wr.fast_reg.page_list->max_page_list_len))
 +			return	-ENOMEM;
 +
 +		set_frwr_pages(*seg, wr, mdev, pd, writ);
 +		*seg += sizeof(struct mlx5_wqe_data_seg);
 +		*size += (sizeof(struct mlx5_wqe_data_seg) / 16);
 +	}
 +	return 0;
++=======
++>>>>>>> dd01e66a6c53 (IB/mlx5: Remove old FRWR API support)
  }
  
  static void dump_wqe(struct mlx5_ib_qp *qp, int idx, int size_16)
@@@ -2725,25 -2663,7 +2728,29 @@@ int mlx5_ib_post_send(struct ib_qp *ibq
  				next_fence = MLX5_FENCE_MODE_INITIATOR_SMALL;
  				qp->sq.wr_data[idx] = IB_WR_LOCAL_INV;
  				ctrl->imm = cpu_to_be32(wr->ex.invalidate_rkey);
++<<<<<<< HEAD
 +				err = set_frwr_li_wr(&seg, wr, &size, mdev, to_mpd(ibqp->pd), qp);
 +				if (err) {
 +					mlx5_ib_warn(dev, "\n");
 +					*bad_wr = wr;
 +					goto out;
 +				}
 +				num_sge = 0;
 +				break;
 +
 +			case IB_WR_FAST_REG_MR:
 +				next_fence = MLX5_FENCE_MODE_INITIATOR_SMALL;
 +				qp->sq.wr_data[idx] = IB_WR_FAST_REG_MR;
 +				ctrl->imm = cpu_to_be32(wr->wr.fast_reg.rkey);
 +				err = set_frwr_li_wr(&seg, wr, &size, mdev, to_mpd(ibqp->pd), qp);
 +				if (err) {
 +					mlx5_ib_warn(dev, "\n");
 +					*bad_wr = wr;
 +					goto out;
 +				}
++=======
+ 				set_linv_wr(qp, &seg, &size);
++>>>>>>> dd01e66a6c53 (IB/mlx5: Remove old FRWR API support)
  				num_sge = 0;
  				break;
  
diff --git a/drivers/infiniband/hw/mlx5/cq.c b/drivers/infiniband/hw/mlx5/cq.c
index 206930096d56..3dfd287256d6 100644
--- a/drivers/infiniband/hw/mlx5/cq.c
+++ b/drivers/infiniband/hw/mlx5/cq.c
@@ -112,9 +112,6 @@ static enum ib_wc_opcode get_umr_comp(struct mlx5_ib_wq *wq, int idx)
 	case IB_WR_REG_MR:
 		return IB_WC_REG_MR;
 
-	case IB_WR_FAST_REG_MR:
-		return IB_WC_FAST_REG_MR;
-
 	default:
 		pr_warn("unknown completion status\n");
 		return 0;
diff --git a/drivers/infiniband/hw/mlx5/main.c b/drivers/infiniband/hw/mlx5/main.c
index e32b3a20b0ae..7e97cb55a6bf 100644
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@ -1426,8 +1426,6 @@ static void *mlx5_ib_add(struct mlx5_core_dev *mdev)
 	dev->ib_dev.process_mad		= mlx5_ib_process_mad;
 	dev->ib_dev.alloc_mr		= mlx5_ib_alloc_mr;
 	dev->ib_dev.map_mr_sg		= mlx5_ib_map_mr_sg;
-	dev->ib_dev.alloc_fast_reg_page_list = mlx5_ib_alloc_fast_reg_page_list;
-	dev->ib_dev.free_fast_reg_page_list  = mlx5_ib_free_fast_reg_page_list;
 	dev->ib_dev.check_mr_status	= mlx5_ib_check_mr_status;
 	dev->ib_dev.get_port_immutable  = mlx5_port_immutable;
 
diff --git a/drivers/infiniband/hw/mlx5/mlx5_ib.h b/drivers/infiniband/hw/mlx5/mlx5_ib.h
index a47447b2379a..16f8b80c6e1e 100644
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -332,12 +332,6 @@ struct mlx5_ib_mr {
 	void			*descs_alloc;
 };
 
-struct mlx5_ib_fast_reg_page_list {
-	struct ib_fast_reg_page_list	ibfrpl;
-	__be64			       *mapped_page_list;
-	dma_addr_t			map;
-};
-
 struct mlx5_ib_umr_context {
 	enum ib_wc_status	status;
 	struct completion	done;
@@ -488,11 +482,6 @@ static inline struct mlx5_ib_mr *to_mmr(struct ib_mr *ibmr)
 	return container_of(ibmr, struct mlx5_ib_mr, ibmr);
 }
 
-static inline struct mlx5_ib_fast_reg_page_list *to_mfrpl(struct ib_fast_reg_page_list *ibfrpl)
-{
-	return container_of(ibfrpl, struct mlx5_ib_fast_reg_page_list, ibfrpl);
-}
-
 struct mlx5_ib_ah {
 	struct ib_ah		ibah;
 	struct mlx5_av		av;
@@ -563,9 +552,6 @@ struct ib_mr *mlx5_ib_alloc_mr(struct ib_pd *pd,
 int mlx5_ib_map_mr_sg(struct ib_mr *ibmr,
 		      struct scatterlist *sg,
 		      int sg_nents);
-struct ib_fast_reg_page_list *mlx5_ib_alloc_fast_reg_page_list(struct ib_device *ibdev,
-							       int page_list_len);
-void mlx5_ib_free_fast_reg_page_list(struct ib_fast_reg_page_list *page_list);
 int mlx5_ib_process_mad(struct ib_device *ibdev, int mad_flags, u8 port_num,
 			const struct ib_wc *in_wc, const struct ib_grh *in_grh,
 			const struct ib_mad_hdr *in, size_t in_mad_size,
diff --git a/drivers/infiniband/hw/mlx5/mr.c b/drivers/infiniband/hw/mlx5/mr.c
index 32fa45112be6..6448f62d8e97 100644
--- a/drivers/infiniband/hw/mlx5/mr.c
+++ b/drivers/infiniband/hw/mlx5/mr.c
@@ -1381,48 +1381,6 @@ err_free:
 	return ERR_PTR(err);
 }
 
-struct ib_fast_reg_page_list *mlx5_ib_alloc_fast_reg_page_list(struct ib_device *ibdev,
-							       int page_list_len)
-{
-	struct mlx5_ib_fast_reg_page_list *mfrpl;
-	int size = page_list_len * sizeof(u64);
-
-	mfrpl = kmalloc(sizeof(*mfrpl), GFP_KERNEL);
-	if (!mfrpl)
-		return ERR_PTR(-ENOMEM);
-
-	mfrpl->ibfrpl.page_list = kmalloc(size, GFP_KERNEL);
-	if (!mfrpl->ibfrpl.page_list)
-		goto err_free;
-
-	mfrpl->mapped_page_list = dma_alloc_coherent(ibdev->dma_device,
-						     size, &mfrpl->map,
-						     GFP_KERNEL);
-	if (!mfrpl->mapped_page_list)
-		goto err_free;
-
-	WARN_ON(mfrpl->map & 0x3f);
-
-	return &mfrpl->ibfrpl;
-
-err_free:
-	kfree(mfrpl->ibfrpl.page_list);
-	kfree(mfrpl);
-	return ERR_PTR(-ENOMEM);
-}
-
-void mlx5_ib_free_fast_reg_page_list(struct ib_fast_reg_page_list *page_list)
-{
-	struct mlx5_ib_fast_reg_page_list *mfrpl = to_mfrpl(page_list);
-	struct mlx5_ib_dev *dev = to_mdev(page_list->device);
-	int size = page_list->max_page_list_len * sizeof(u64);
-
-	dma_free_coherent(&dev->mdev->pdev->dev, size, mfrpl->mapped_page_list,
-			  mfrpl->map);
-	kfree(mfrpl->ibfrpl.page_list);
-	kfree(mfrpl);
-}
-
 int mlx5_ib_check_mr_status(struct ib_mr *ibmr, u32 check_mask,
 			    struct ib_mr_status *mr_status)
 {
* Unmerged path drivers/infiniband/hw/mlx5/qp.c
