IB/iser: Port to new fast registration API

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Sagi Grimberg <sagig@mellanox.com>
commit 39405885005a8b01e3523d3351ea74ae3b965842
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/39405885.failed

Remove fastreg page list allocation as the page vector
is now private to the provider. Instead of constructing
the page list and fast_req work request, call ib_map_mr_sg
and construct ib_reg_wr.

	Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
	Acked-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 39405885005a8b01e3523d3351ea74ae3b965842)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/ulp/iser/iscsi_iser.h
#	drivers/infiniband/ulp/iser/iser_memory.c
diff --cc drivers/infiniband/ulp/iser/iscsi_iser.h
index b9dc02d4dd14,8a5998e6a407..000000000000
--- a/drivers/infiniband/ulp/iser/iscsi_iser.h
+++ b/drivers/infiniband/ulp/iser/iscsi_iser.h
@@@ -228,12 -230,10 +228,12 @@@ enum iser_data_dir 
   */
  struct iser_data_buf {
  	struct scatterlist *sg;
- 	unsigned int       size;
+ 	int                size;
  	unsigned long      data_len;
  	unsigned int       dma_nents;
 -};
 +	struct scatterlist *orig_sg;
 +	unsigned int       orig_size;
 +  };
  
  /* fwd declarations */
  struct iser_device;
@@@ -280,6 -294,15 +280,18 @@@ struct iser_tx_desc 
  	struct ib_sge		     tx_sg[2];
  	int                          num_sge;
  	bool			     mapped;
++<<<<<<< HEAD
++=======
+ 	u8                           wr_idx;
+ 	union iser_wr {
+ 		struct ib_send_wr		send;
+ 		struct ib_reg_wr		fast_reg;
+ 		struct ib_sig_handover_wr	sig;
+ 	} wrs[ISER_MAX_WRS];
+ 	struct iser_mem_reg          data_reg;
+ 	struct iser_mem_reg          prot_reg;
+ 	struct ib_sig_attrs          sig_attrs;
++>>>>>>> 39405885005a (IB/iser: Port to new fast registration API)
  };
  
  #define ISER_RX_PAD_SIZE	(256 - (ISER_RX_PAYLOAD_SIZE + \
diff --cc drivers/infiniband/ulp/iser/iser_memory.c
index b04a5e59e448,ea765fb9664d..000000000000
--- a/drivers/infiniband/ulp/iser/iser_memory.c
+++ b/drivers/infiniband/ulp/iser/iser_memory.c
@@@ -803,127 -484,112 +803,154 @@@ static int iser_fast_reg_mr(struct iscs
  			    struct iser_reg_resources *rsc,
  			    struct iser_mem_reg *reg)
  {
++<<<<<<< HEAD
 +	struct ib_conn *ib_conn = &iser_task->iser_conn->ib_conn;
 +	struct iser_device *device = ib_conn->device;
 +	struct ib_mr *mr;
 +	struct ib_fast_reg_page_list *frpl;
 +	struct ib_send_wr fastreg_wr, inv_wr;
 +	struct ib_send_wr *bad_wr, *wr = NULL;
 +	int ret, offset, size, plen;
 +
 +	/* if there a single dma entry, dma mr suffices */
 +	if (mem->dma_nents == 1)
 +		return iser_reg_dma(device, mem, reg);
 +
 +	mr = rsc->mr;
 +	frpl = rsc->frpl;
 +
 +	plen = iser_sg_to_page_vec(mem, device->ib_device, frpl->page_list,
 +				   &offset, &size);
 +	if (plen * SIZE_4K < size) {
 +		iser_err("fast reg page_list too short to hold this SG\n");
 +		return -EINVAL;
 +	}
++=======
+ 	struct iser_tx_desc *tx_desc = &iser_task->desc;
+ 	struct ib_mr *mr = rsc->mr;
+ 	struct ib_reg_wr *wr;
+ 	int n;
++>>>>>>> 39405885005a (IB/iser: Port to new fast registration API)
 +
 +	if (!rsc->mr_valid) {
 +		iser_inv_rkey(&inv_wr, mr);
 +		wr = &inv_wr;
 +	}
  
 -	if (!rsc->mr_valid)
 -		iser_inv_rkey(iser_tx_next_wr(tx_desc), mr);
++<<<<<<< HEAD
 +	/* Prepare FASTREG WR */
 +	memset(&fastreg_wr, 0, sizeof(fastreg_wr));
 +	fastreg_wr.wr_id = ISER_FASTREG_LI_WRID;
 +	fastreg_wr.opcode = IB_WR_FAST_REG_MR;
 +	fastreg_wr.wr.fast_reg.iova_start = frpl->page_list[0] + offset;
 +	fastreg_wr.wr.fast_reg.page_list = frpl;
 +	fastreg_wr.wr.fast_reg.page_list_len = plen;
 +	fastreg_wr.wr.fast_reg.page_shift = SHIFT_4K;
 +	fastreg_wr.wr.fast_reg.length = size;
 +	fastreg_wr.wr.fast_reg.rkey = mr->rkey;
 +	fastreg_wr.wr.fast_reg.access_flags = (IB_ACCESS_LOCAL_WRITE  |
 +					       IB_ACCESS_REMOTE_WRITE |
 +					       IB_ACCESS_REMOTE_READ);
 +
 +	if (!wr)
 +		wr = &fastreg_wr;
 +	else
 +		wr->next = &fastreg_wr;
  
 +	ret = ib_post_send(ib_conn->qp, wr, &bad_wr);
 +	if (ret) {
 +		iser_err("fast registration failed, ret:%d\n", ret);
 +		return ret;
 +	}
++=======
+ 	n = ib_map_mr_sg(mr, mem->sg, mem->size, SIZE_4K);
+ 	if (unlikely(n != mem->size)) {
+ 		iser_err("failed to map sg (%d/%d)\n",
+ 			 n, mem->size);
+ 		return n < 0 ? n : -EINVAL;
+ 	}
+ 
+ 	wr = reg_wr(iser_tx_next_wr(tx_desc));
+ 	wr->wr.opcode = IB_WR_REG_MR;
+ 	wr->wr.wr_id = ISER_FASTREG_LI_WRID;
+ 	wr->wr.send_flags = 0;
+ 	wr->wr.num_sge = 0;
+ 	wr->mr = mr;
+ 	wr->key = mr->rkey;
+ 	wr->access = IB_ACCESS_LOCAL_WRITE  |
+ 		     IB_ACCESS_REMOTE_WRITE |
+ 		     IB_ACCESS_REMOTE_READ;
+ 
++>>>>>>> 39405885005a (IB/iser: Port to new fast registration API)
  	rsc->mr_valid = 0;
  
  	reg->sge.lkey = mr->lkey;
  	reg->rkey = mr->rkey;
- 	reg->sge.addr = frpl->page_list[0] + offset;
- 	reg->sge.length = size;
+ 	reg->sge.addr = mr->iova;
+ 	reg->sge.length = mr->length;
  
- 	iser_dbg("fast reg: lkey=0x%x, rkey=0x%x, addr=0x%llx,"
- 		 " length=0x%x\n", reg->sge.lkey, reg->rkey,
- 		 reg->sge.addr, reg->sge.length);
+ 	iser_dbg("lkey=0x%x rkey=0x%x addr=0x%llx length=0x%x\n",
+ 		 reg->sge.lkey, reg->rkey, reg->sge.addr, reg->sge.length);
  
 -	return 0;
 -}
 -
 -static int
 -iser_reg_prot_sg(struct iscsi_iser_task *task,
 -		 struct iser_data_buf *mem,
 -		 struct iser_fr_desc *desc,
 -		 bool use_dma_key,
 -		 struct iser_mem_reg *reg)
 -{
 -	struct iser_device *device = task->iser_conn->ib_conn.device;
 -
 -	if (use_dma_key)
 -		return iser_reg_dma(device, mem, reg);
 -
 -	return device->reg_ops->reg_mem(task, mem, &desc->pi_ctx->rsc, reg);
 -}
 -
 -static int
 -iser_reg_data_sg(struct iscsi_iser_task *task,
 -		 struct iser_data_buf *mem,
 -		 struct iser_fr_desc *desc,
 -		 bool use_dma_key,
 -		 struct iser_mem_reg *reg)
 -{
 -	struct iser_device *device = task->iser_conn->ib_conn.device;
 -
 -	if (use_dma_key)
 -		return iser_reg_dma(device, mem, reg);
 -
 -	return device->reg_ops->reg_mem(task, mem, &desc->rsc, reg);
 +	return ret;
  }
  
 -int iser_reg_rdma_mem(struct iscsi_iser_task *task,
 -		      enum iser_data_dir dir)
 +/**
 + * iser_reg_rdma_mem_fastreg - Registers memory intended for RDMA,
 + * using Fast Registration WR (if possible) obtaining rkey and va
 + *
 + * returns 0 on success, errno code on failure
 + */
 +int iser_reg_rdma_mem_fastreg(struct iscsi_iser_task *iser_task,
 +			      enum iser_data_dir cmd_dir)
  {
 -	struct ib_conn *ib_conn = &task->iser_conn->ib_conn;
 +	struct ib_conn *ib_conn = &iser_task->iser_conn->ib_conn;
  	struct iser_device *device = ib_conn->device;
 -	struct iser_data_buf *mem = &task->data[dir];
 -	struct iser_mem_reg *reg = &task->rdma_reg[dir];
 -	struct iser_mem_reg *data_reg;
 +	struct ib_device *ibdev = device->ib_device;
 +	struct iser_data_buf *mem = &iser_task->data[cmd_dir];
 +	struct iser_mem_reg *mem_reg = &iser_task->rdma_reg[cmd_dir];
  	struct iser_fr_desc *desc = NULL;
 -	bool use_dma_key;
 -	int err;
 -
 -	use_dma_key = (mem->dma_nents == 1 && !iser_always_reg &&
 -		       scsi_get_prot_op(task->sc) == SCSI_PROT_NORMAL);
 +	int err, aligned_len;
 +
 +	aligned_len = iser_data_buf_aligned_len(mem, ibdev);
 +	if (aligned_len != mem->dma_nents) {
 +		err = fall_to_bounce_buf(iser_task, mem, cmd_dir);
 +		if (err) {
 +			iser_err("failed to allocate bounce buffer\n");
 +			return err;
 +		}
 +	}
  
 -	if (!use_dma_key) {
 +	if (mem->dma_nents != 1 ||
 +	    scsi_get_prot_op(iser_task->sc) != SCSI_PROT_NORMAL) {
  		desc = device->reg_ops->reg_desc_get(ib_conn);
 -		reg->mem_h = desc;
 +		mem_reg->mem_h = desc;
  	}
  
 -	if (scsi_get_prot_op(task->sc) == SCSI_PROT_NORMAL)
 -		data_reg = reg;
 -	else
 -		data_reg = &task->desc.data_reg;
 -
 -	err = iser_reg_data_sg(task, mem, desc, use_dma_key, data_reg);
 -	if (unlikely(err))
 +	err = iser_fast_reg_mr(iser_task, mem,
 +			       desc ? &desc->rsc : NULL, mem_reg);
 +	if (err)
  		goto err_reg;
  
 -	if (scsi_get_prot_op(task->sc) != SCSI_PROT_NORMAL) {
 -		struct iser_mem_reg *prot_reg = &task->desc.prot_reg;
 -
 -		if (scsi_prot_sg_count(task->sc)) {
 -			mem = &task->prot[dir];
 -			err = iser_reg_prot_sg(task, mem, desc,
 -					       use_dma_key, prot_reg);
 -			if (unlikely(err))
 +	if (scsi_get_prot_op(iser_task->sc) != SCSI_PROT_NORMAL) {
 +		struct iser_mem_reg prot_reg;
 +
 +		memset(&prot_reg, 0, sizeof(prot_reg));
 +		if (scsi_prot_sg_count(iser_task->sc)) {
 +			mem = &iser_task->prot[cmd_dir];
 +			aligned_len = iser_data_buf_aligned_len(mem, ibdev);
 +			if (aligned_len != mem->dma_nents) {
 +				err = fall_to_bounce_buf(iser_task, mem,
 +							 cmd_dir);
 +				if (err) {
 +					iser_err("failed to allocate bounce buffer\n");
 +					return err;
 +				}
 +			}
 +
 +			err = iser_fast_reg_mr(iser_task, mem,
 +					       &desc->pi_ctx->rsc, &prot_reg);
 +			if (err)
  				goto err_reg;
  		}
  
* Unmerged path drivers/infiniband/ulp/iser/iscsi_iser.h
* Unmerged path drivers/infiniband/ulp/iser/iser_memory.c
diff --git a/drivers/infiniband/ulp/iser/iser_verbs.c b/drivers/infiniband/ulp/iser/iser_verbs.c
index 3a0562552ca5..5db75dc21291 100644
--- a/drivers/infiniband/ulp/iser/iser_verbs.c
+++ b/drivers/infiniband/ulp/iser/iser_verbs.c
@@ -288,35 +288,21 @@ iser_alloc_reg_res(struct ib_device *ib_device,
 {
 	int ret;
 
-	res->frpl = ib_alloc_fast_reg_page_list(ib_device, size);
-	if (IS_ERR(res->frpl)) {
-		ret = PTR_ERR(res->frpl);
-		iser_err("Failed to allocate ib_fast_reg_page_list err=%d\n",
-			 ret);
-		return PTR_ERR(res->frpl);
-	}
-
 	res->mr = ib_alloc_mr(pd, IB_MR_TYPE_MEM_REG, size);
 	if (IS_ERR(res->mr)) {
 		ret = PTR_ERR(res->mr);
 		iser_err("Failed to allocate ib_fast_reg_mr err=%d\n", ret);
-		goto fast_reg_mr_failure;
+		return ret;
 	}
 	res->mr_valid = 1;
 
 	return 0;
-
-fast_reg_mr_failure:
-	ib_free_fast_reg_page_list(res->frpl);
-
-	return ret;
 }
 
 static void
 iser_free_reg_res(struct iser_reg_resources *rsc)
 {
 	ib_dereg_mr(rsc->mr);
-	ib_free_fast_reg_page_list(rsc->frpl);
 }
 
 static int
