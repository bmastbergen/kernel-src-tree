gre: Remove support for sharing GRE protocol hook.

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [net] gre: Remove support for sharing GRE protocol hook (Lance Richardson) [1283886]
Rebuild_FUZZ: 98.99%
commit-author Pravin B Shelar <pshelar@nicira.com>
commit 9f57c67c379d88a10e8ad676426fee5ae7341b14
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/9f57c67c.failed

Support for sharing GREPROTO_CISCO port was added so that
OVS gre port and kernel GRE devices can co-exist. After
flow-based tunneling patches OVS GRE protocol processing
is completely moved to ip_gre module. so there is no need
for GRE protocol hook. Following patch consolidates
GRE protocol related functions into ip_gre module.

	Signed-off-by: Pravin B Shelar <pshelar@nicira.com>
	Acked-by: Thomas Graf <tgraf@suug.ch>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 9f57c67c379d88a10e8ad676426fee5ae7341b14)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/gre.h
#	net/ipv4/gre_demux.c
#	net/ipv4/ip_gre.c
diff --cc include/net/gre.h
index b53182018743,97eafdc47eea..000000000000
--- a/include/net/gre.h
+++ b/include/net/gre.h
@@@ -17,88 -23,6 +23,87 @@@ struct gre_protocol 
  int gre_add_protocol(const struct gre_protocol *proto, u8 version);
  int gre_del_protocol(const struct gre_protocol *proto, u8 version);
  
++<<<<<<< HEAD
 +struct gre_cisco_protocol {
 +	int (*handler)(struct sk_buff *skb, const struct tnl_ptk_info *tpi);
 +	int (*err_handler)(struct sk_buff *skb, u32 info,
 +			   const struct tnl_ptk_info *tpi);
 +	u8 priority;
 +};
 +
 +int gre_cisco_register(struct gre_cisco_protocol *proto);
 +int gre_cisco_unregister(struct gre_cisco_protocol *proto);
 +
 +void gre_build_header(struct sk_buff *skb, const struct tnl_ptk_info *tpi,
 +		      int hdr_len);
 +
 +static inline struct sk_buff *gre_handle_offloads(struct sk_buff *skb,
 +						  bool csum)
 +{
 +	return iptunnel_handle_offloads(skb, csum,
 +					csum ? SKB_GSO_GRE_CSUM : SKB_GSO_GRE);
 +}
 +
 +
 +static inline int ip_gre_calc_hlen(__be16 o_flags)
 +{
 +	int addend = 4;
 +
 +	if (o_flags&TUNNEL_CSUM)
 +		addend += 4;
 +	if (o_flags&TUNNEL_KEY)
 +		addend += 4;
 +	if (o_flags&TUNNEL_SEQ)
 +		addend += 4;
 +	return addend;
 +}
 +
 +static inline __be16 gre_flags_to_tnl_flags(__be16 flags)
 +{
 +	__be16 tflags = 0;
 +
 +	if (flags & GRE_CSUM)
 +		tflags |= TUNNEL_CSUM;
 +	if (flags & GRE_ROUTING)
 +		tflags |= TUNNEL_ROUTING;
 +	if (flags & GRE_KEY)
 +		tflags |= TUNNEL_KEY;
 +	if (flags & GRE_SEQ)
 +		tflags |= TUNNEL_SEQ;
 +	if (flags & GRE_STRICT)
 +		tflags |= TUNNEL_STRICT;
 +	if (flags & GRE_REC)
 +		tflags |= TUNNEL_REC;
 +	if (flags & GRE_VERSION)
 +		tflags |= TUNNEL_VERSION;
 +
 +	return tflags;
 +}
 +
 +static inline __be16 tnl_flags_to_gre_flags(__be16 tflags)
 +{
 +	__be16 flags = 0;
 +
 +	if (tflags & TUNNEL_CSUM)
 +		flags |= GRE_CSUM;
 +	if (tflags & TUNNEL_ROUTING)
 +		flags |= GRE_ROUTING;
 +	if (tflags & TUNNEL_KEY)
 +		flags |= GRE_KEY;
 +	if (tflags & TUNNEL_SEQ)
 +		flags |= GRE_SEQ;
 +	if (tflags & TUNNEL_STRICT)
 +		flags |= GRE_STRICT;
 +	if (tflags & TUNNEL_REC)
 +		flags |= GRE_REC;
 +	if (tflags & TUNNEL_VERSION)
 +		flags |= GRE_VERSION;
 +
 +	return flags;
 +}
 +
++=======
+ struct net_device *gretap_fb_dev_create(struct net *net, const char *name,
+ 				       u8 name_assign_type);
++>>>>>>> 9f57c67c379d (gre: Remove support for sharing GRE protocol hook.)
  #endif
diff --cc net/ipv4/gre_demux.c
index 7e0756da8737,d9c552a721fc..000000000000
--- a/net/ipv4/gre_demux.c
+++ b/net/ipv4/gre_demux.c
@@@ -61,198 -60,6 +60,201 @@@ int gre_del_protocol(const struct gre_p
  }
  EXPORT_SYMBOL_GPL(gre_del_protocol);
  
++<<<<<<< HEAD
 +void gre_build_header(struct sk_buff *skb, const struct tnl_ptk_info *tpi,
 +		      int hdr_len)
 +{
 +	struct gre_base_hdr *greh;
 +
 +	skb_push(skb, hdr_len);
 +
 +	skb_reset_transport_header(skb);
 +	greh = (struct gre_base_hdr *)skb->data;
 +	greh->flags = tnl_flags_to_gre_flags(tpi->flags);
 +	greh->protocol = tpi->proto;
 +
 +	if (tpi->flags&(TUNNEL_KEY|TUNNEL_CSUM|TUNNEL_SEQ)) {
 +		__be32 *ptr = (__be32 *)(((u8 *)greh) + hdr_len - 4);
 +
 +		if (tpi->flags&TUNNEL_SEQ) {
 +			*ptr = tpi->seq;
 +			ptr--;
 +		}
 +		if (tpi->flags&TUNNEL_KEY) {
 +			*ptr = tpi->key;
 +			ptr--;
 +		}
 +		if (tpi->flags&TUNNEL_CSUM &&
 +		    !(skb_shinfo(skb)->gso_type &
 +		      (SKB_GSO_GRE|SKB_GSO_GRE_CSUM))) {
 +			*ptr = 0;
 +			*(__sum16 *)ptr = csum_fold(skb_checksum(skb, 0,
 +								 skb->len, 0));
 +		}
 +	}
 +}
 +EXPORT_SYMBOL_GPL(gre_build_header);
 +
 +static int parse_gre_header(struct sk_buff *skb, struct tnl_ptk_info *tpi,
 +			    bool *csum_err)
 +{
 +	unsigned int ip_hlen = ip_hdrlen(skb);
 +	const struct gre_base_hdr *greh;
 +	__be32 *options;
 +	int hdr_len;
 +
 +	if (unlikely(!pskb_may_pull(skb, sizeof(struct gre_base_hdr))))
 +		return -EINVAL;
 +
 +	greh = (struct gre_base_hdr *)(skb_network_header(skb) + ip_hlen);
 +	if (unlikely(greh->flags & (GRE_VERSION | GRE_ROUTING)))
 +		return -EINVAL;
 +
 +	tpi->flags = gre_flags_to_tnl_flags(greh->flags);
 +	hdr_len = ip_gre_calc_hlen(tpi->flags);
 +
 +	if (!pskb_may_pull(skb, hdr_len))
 +		return -EINVAL;
 +
 +	greh = (struct gre_base_hdr *)(skb_network_header(skb) + ip_hlen);
 +	tpi->proto = greh->protocol;
 +
 +	options = (__be32 *)(greh + 1);
 +	if (greh->flags & GRE_CSUM) {
 +		if (skb_checksum_simple_validate(skb)) {
 +			*csum_err = true;
 +			return -EINVAL;
 +		}
 +
 +		skb_checksum_try_convert(skb, IPPROTO_GRE, 0,
 +					 null_compute_pseudo);
 +
 +		options++;
 +	}
 +
 +	if (greh->flags & GRE_KEY) {
 +		tpi->key = *options;
 +		options++;
 +	} else
 +		tpi->key = 0;
 +
 +	if (unlikely(greh->flags & GRE_SEQ)) {
 +		tpi->seq = *options;
 +		options++;
 +	} else
 +		tpi->seq = 0;
 +
 +	/* WCCP version 1 and 2 protocol decoding.
 +	 * - Change protocol to IP
 +	 * - When dealing with WCCPv2, Skip extra 4 bytes in GRE header
 +	 */
 +	if (greh->flags == 0 && tpi->proto == htons(ETH_P_WCCP)) {
 +		tpi->proto = htons(ETH_P_IP);
 +		if ((*(u8 *)options & 0xF0) != 0x40) {
 +			hdr_len += 4;
 +			if (!pskb_may_pull(skb, hdr_len))
 +				return -EINVAL;
 +		}
 +	}
 +
 +	return iptunnel_pull_header(skb, hdr_len, tpi->proto);
 +}
 +
 +static int gre_cisco_rcv(struct sk_buff *skb)
 +{
 +	struct tnl_ptk_info tpi;
 +	int i;
 +	bool csum_err = false;
 +
 +#ifdef CONFIG_NET_IPGRE_BROADCAST
 +	if (ipv4_is_multicast(ip_hdr(skb)->daddr)) {
 +		/* Looped back packet, drop it! */
 +		if (rt_is_output_route(skb_rtable(skb)))
 +			goto drop;
 +	}
 +#endif
 +
 +	if (parse_gre_header(skb, &tpi, &csum_err) < 0)
 +		goto drop;
 +
 +	rcu_read_lock();
 +	for (i = 0; i < GRE_IP_PROTO_MAX; i++) {
 +		struct gre_cisco_protocol *proto;
 +		int ret;
 +
 +		proto = rcu_dereference(gre_cisco_proto_list[i]);
 +		if (!proto)
 +			continue;
 +		ret = proto->handler(skb, &tpi);
 +		if (ret == PACKET_RCVD) {
 +			rcu_read_unlock();
 +			return 0;
 +		}
 +	}
 +	rcu_read_unlock();
 +
 +	icmp_send(skb, ICMP_DEST_UNREACH, ICMP_PORT_UNREACH, 0);
 +drop:
 +	kfree_skb(skb);
 +	return 0;
 +}
 +
 +static void gre_cisco_err(struct sk_buff *skb, u32 info)
 +{
 +	/* All the routers (except for Linux) return only
 +	 * 8 bytes of packet payload. It means, that precise relaying of
 +	 * ICMP in the real Internet is absolutely infeasible.
 +	 *
 +	 * Moreover, Cisco "wise men" put GRE key to the third word
 +	 * in GRE header. It makes impossible maintaining even soft
 +	 * state for keyed
 +	 * GRE tunnels with enabled checksum. Tell them "thank you".
 +	 *
 +	 * Well, I wonder, rfc1812 was written by Cisco employee,
 +	 * what the hell these idiots break standards established
 +	 * by themselves???
 +	 */
 +
 +	const int type = icmp_hdr(skb)->type;
 +	const int code = icmp_hdr(skb)->code;
 +	struct tnl_ptk_info tpi;
 +	bool csum_err = false;
 +	int i;
 +
 +	if (parse_gre_header(skb, &tpi, &csum_err)) {
 +		if (!csum_err)		/* ignore csum errors. */
 +			return;
 +	}
 +
 +	if (type == ICMP_DEST_UNREACH && code == ICMP_FRAG_NEEDED) {
 +		ipv4_update_pmtu(skb, dev_net(skb->dev), info,
 +				skb->dev->ifindex, 0, IPPROTO_GRE, 0);
 +		return;
 +	}
 +	if (type == ICMP_REDIRECT) {
 +		ipv4_redirect(skb, dev_net(skb->dev), skb->dev->ifindex, 0,
 +				IPPROTO_GRE, 0);
 +		return;
 +	}
 +
 +	rcu_read_lock();
 +	for (i = 0; i < GRE_IP_PROTO_MAX; i++) {
 +		struct gre_cisco_protocol *proto;
 +
 +		proto = rcu_dereference(gre_cisco_proto_list[i]);
 +		if (!proto)
 +			continue;
 +
 +		if (proto->err_handler(skb, info, &tpi) == PACKET_RCVD)
 +			goto out;
 +
 +	}
 +out:
 +	rcu_read_unlock();
 +}
 +
++=======
++>>>>>>> 9f57c67c379d (gre: Remove support for sharing GRE protocol hook.)
  static int gre_rcv(struct sk_buff *skb)
  {
  	const struct gre_protocol *proto;
diff --cc net/ipv4/ip_gre.c
index afc4a83f7ee7,fb44d693796e..000000000000
--- a/net/ipv4/ip_gre.c
+++ b/net/ipv4/ip_gre.c
@@@ -182,8 -304,8 +302,13 @@@ static void ipgre_err(struct sk_buff *s
  	t = ip_tunnel_lookup(itn, skb->dev->ifindex, tpi->flags,
  			     iph->daddr, iph->saddr, tpi->key);
  
++<<<<<<< HEAD
 +	if (t == NULL)
 +		return PACKET_REJECT;
++=======
+ 	if (!t)
+ 		return;
++>>>>>>> 9f57c67c379d (gre: Remove support for sharing GRE protocol hook.)
  
  	if (t->parms.iph.daddr == 0 ||
  	    ipv4_is_multicast(t->parms.iph.daddr))
@@@ -197,9 -319,67 +322,48 @@@
  	else
  		t->err_count = 1;
  	t->err_time = jiffies;
- 	return PACKET_RCVD;
+ }
+ 
+ static void gre_err(struct sk_buff *skb, u32 info)
+ {
+ 	/* All the routers (except for Linux) return only
+ 	 * 8 bytes of packet payload. It means, that precise relaying of
+ 	 * ICMP in the real Internet is absolutely infeasible.
+ 	 *
+ 	 * Moreover, Cisco "wise men" put GRE key to the third word
+ 	 * in GRE header. It makes impossible maintaining even soft
+ 	 * state for keyed
+ 	 * GRE tunnels with enabled checksum. Tell them "thank you".
+ 	 *
+ 	 * Well, I wonder, rfc1812 was written by Cisco employee,
+ 	 * what the hell these idiots break standards established
+ 	 * by themselves???
+ 	 */
+ 
+ 	const int type = icmp_hdr(skb)->type;
+ 	const int code = icmp_hdr(skb)->code;
+ 	struct tnl_ptk_info tpi;
+ 	bool csum_err = false;
+ 
+ 	if (parse_gre_header(skb, &tpi, &csum_err)) {
+ 		if (!csum_err)		/* ignore csum errors. */
+ 			return;
+ 	}
+ 
+ 	if (type == ICMP_DEST_UNREACH && code == ICMP_FRAG_NEEDED) {
+ 		ipv4_update_pmtu(skb, dev_net(skb->dev), info,
+ 				 skb->dev->ifindex, 0, IPPROTO_GRE, 0);
+ 		return;
+ 	}
+ 	if (type == ICMP_REDIRECT) {
+ 		ipv4_redirect(skb, dev_net(skb->dev), skb->dev->ifindex, 0,
+ 			      IPPROTO_GRE, 0);
+ 		return;
+ 	}
+ 
+ 	ipgre_err(skb, info, &tpi);
  }
  
 -static __be64 key_to_tunnel_id(__be32 key)
 -{
 -#ifdef __BIG_ENDIAN
 -	return (__force __be64)((__force u32)key);
 -#else
 -	return (__force __be64)((__force u64)key << 32);
 -#endif
 -}
 -
 -/* Returns the least-significant 32 bits of a __be64. */
 -static __be32 tunnel_id_to_key(__be64 x)
 -{
 -#ifdef __BIG_ENDIAN
 -	return (__force __be32)x;
 -#else
 -	return (__force __be32)((__force u64)x >> 32);
 -#endif
 -}
 -
  static int ipgre_rcv(struct sk_buff *skb, const struct tnl_ptk_info *tpi)
  {
  	struct net *net = dev_net(skb->dev);
@@@ -224,6 -427,64 +388,67 @@@
  	return PACKET_REJECT;
  }
  
++<<<<<<< HEAD
++=======
+ static int gre_rcv(struct sk_buff *skb)
+ {
+ 	struct tnl_ptk_info tpi;
+ 	bool csum_err = false;
+ 
+ #ifdef CONFIG_NET_IPGRE_BROADCAST
+ 	if (ipv4_is_multicast(ip_hdr(skb)->daddr)) {
+ 		/* Looped back packet, drop it! */
+ 		if (rt_is_output_route(skb_rtable(skb)))
+ 			goto drop;
+ 	}
+ #endif
+ 
+ 	if (parse_gre_header(skb, &tpi, &csum_err) < 0)
+ 		goto drop;
+ 
+ 	if (ipgre_rcv(skb, &tpi) == PACKET_RCVD)
+ 		return 0;
+ 
+ 	icmp_send(skb, ICMP_DEST_UNREACH, ICMP_PORT_UNREACH, 0);
+ drop:
+ 	kfree_skb(skb);
+ 	return 0;
+ }
+ 
+ static void build_header(struct sk_buff *skb, int hdr_len, __be16 flags,
+ 			 __be16 proto, __be32 key, __be32 seq)
+ {
+ 	struct gre_base_hdr *greh;
+ 
+ 	skb_push(skb, hdr_len);
+ 
+ 	skb_reset_transport_header(skb);
+ 	greh = (struct gre_base_hdr *)skb->data;
+ 	greh->flags = tnl_flags_to_gre_flags(flags);
+ 	greh->protocol = proto;
+ 
+ 	if (flags & (TUNNEL_KEY | TUNNEL_CSUM | TUNNEL_SEQ)) {
+ 		__be32 *ptr = (__be32 *)(((u8 *)greh) + hdr_len - 4);
+ 
+ 		if (flags & TUNNEL_SEQ) {
+ 			*ptr = seq;
+ 			ptr--;
+ 		}
+ 		if (flags & TUNNEL_KEY) {
+ 			*ptr = key;
+ 			ptr--;
+ 		}
+ 		if (flags & TUNNEL_CSUM &&
+ 		    !(skb_shinfo(skb)->gso_type &
+ 		      (SKB_GSO_GRE | SKB_GSO_GRE_CSUM))) {
+ 			*ptr = 0;
+ 			*(__sum16 *)ptr = csum_fold(skb_checksum(skb, 0,
+ 								 skb->len, 0));
+ 		}
+ 	}
+ }
+ 
++>>>>>>> 9f57c67c379d (gre: Remove support for sharing GRE protocol hook.)
  static void __gre_xmit(struct sk_buff *skb, struct net_device *dev,
  		       const struct iphdr *tnl_params,
  		       __be16 proto)
* Unmerged path include/net/gre.h
* Unmerged path net/ipv4/gre_demux.c
* Unmerged path net/ipv4/ip_gre.c
