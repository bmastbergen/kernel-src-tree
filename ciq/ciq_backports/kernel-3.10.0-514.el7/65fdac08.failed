sched: Fix avg_load computation

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Vincent Guittot <vincent.guittot@linaro.org>
commit 65fdac08c264506ff95ee1e34ae066e308c9e6e3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/65fdac08.failed

The computation of avg_load and avg_load_per_task should only take into
account the number of CFS tasks. The non-CFS tasks are already taken into
account by decreasing the CPU's capacity and they will be tracked in the
CPU's utilization (group_utilization) of the next patches.

	Reviewed-by: Preeti U Murthy <preeti@linux.vnet.ibm.com>
	Signed-off-by: Vincent Guittot <vincent.guittot@linaro.org>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: riel@redhat.com
	Cc: Morten.Rasmussen@arm.com
	Cc: efault@gmx.de
	Cc: nicolas.pitre@linaro.org
	Cc: daniel.lezcano@linaro.org
	Cc: dietmar.eggemann@arm.com
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
Link: http://lkml.kernel.org/r/1409051215-16788-4-git-send-email-vincent.guittot@linaro.org
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 65fdac08c264506ff95ee1e34ae066e308c9e6e3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/fair.c
diff --cc kernel/sched/fair.c
index 961e580cbff7,eb87229ed4af..000000000000
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@@ -3943,10 -4095,11 +3943,15 @@@ static unsigned long power_of(int cpu
  static unsigned long cpu_avg_load_per_task(int cpu)
  {
  	struct rq *rq = cpu_rq(cpu);
++<<<<<<< HEAD
 +	unsigned long nr_running = ACCESS_ONCE(rq->nr_running);
++=======
+ 	unsigned long nr_running = ACCESS_ONCE(rq->cfs.h_nr_running);
+ 	unsigned long load_avg = rq->cfs.runnable_load_avg;
++>>>>>>> 65fdac08c264 (sched: Fix avg_load computation)
  
  	if (nr_running)
 -		return load_avg / nr_running;
 +		return rq->load.weight / nr_running;
  
  	return 0;
  }
@@@ -5674,7 -5985,7 +5679,11 @@@ static inline void update_sg_lb_stats(s
  			load = source_load(i, load_idx);
  
  		sgs->group_load += load;
++<<<<<<< HEAD
 +		sgs->sum_nr_running += nr_running;
++=======
+ 		sgs->sum_nr_running += rq->cfs.h_nr_running;
++>>>>>>> 65fdac08c264 (sched: Fix avg_load computation)
  
  		if (rq->nr_running > 1)
  			*overload = true;
* Unmerged path kernel/sched/fair.c
