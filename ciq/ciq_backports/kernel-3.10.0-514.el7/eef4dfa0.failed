x86/mce: Kill drain_mcelog_buffer()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [x86] mce: Kill drain_mcelog_buffer() (Prarit Bhargava) [1301710]
Rebuild_FUZZ: 93.94%
commit-author Borislav Petkov <bp@suse.de>
commit eef4dfa0cb83899c782935ac5345532f47073cea
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/eef4dfa0.failed

This used to flush out MCEs logged during early boot and which
were in the MCA registers from a previous system run. No need
for that now, since we've moved to a genpool.

	Suggested-by: Tony Luck <tony.luck@intel.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
Link: http://lkml.kernel.org/r/1439396985-12812-7-git-send-email-bp@alien8.de
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit eef4dfa0cb83899c782935ac5345532f47073cea)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/mcheck/mce.c
diff --cc arch/x86/kernel/cpu/mcheck/mce.c
index 53f7039f68c9,32b586ee006a..000000000000
--- a/arch/x86/kernel/cpu/mcheck/mce.c
+++ b/arch/x86/kernel/cpu/mcheck/mce.c
@@@ -194,48 -199,15 +194,55 @@@ void mce_log(struct mce *mce
  	set_bit(0, &mce_need_notify);
  }
  
++<<<<<<< HEAD
 +static void drain_mcelog_buffer(void)
 +{
 +	unsigned int next, i, prev = 0;
 +
 +	next = ACCESS_ONCE(mcelog.next);
 +
 +	do {
 +		struct mce *m;
 +
 +		/* drain what was logged during boot */
 +		for (i = prev; i < next; i++) {
 +			unsigned long start = jiffies;
 +			unsigned retries = 1;
 +
 +			m = &mcelog.entry[i];
 +
 +			while (!m->finished) {
 +				if (time_after_eq(jiffies, start + 2*retries))
 +					retries++;
 +
 +				cpu_relax();
 +
 +				if (!m->finished && retries >= 4) {
 +					pr_err("skipping error being logged currently!\n");
 +					break;
 +				}
 +			}
 +			smp_rmb();
 +			atomic_notifier_call_chain(&x86_mce_decoder_chain, 0, m);
 +		}
 +
 +		memset(mcelog.entry + prev, 0, (next - prev) * sizeof(*m));
 +		prev = next;
 +		next = cmpxchg(&mcelog.next, prev, 0);
 +	} while (next != prev);
 +}
 +
++=======
+ static struct notifier_block mce_srao_nb;
++>>>>>>> eef4dfa0cb83 (x86/mce: Kill drain_mcelog_buffer())
  
  void mce_register_decode_chain(struct notifier_block *nb)
  {
 -	/* Ensure SRAO notifier has the highest priority in the decode chain. */
 -	if (nb != &mce_srao_nb && nb->priority == INT_MAX)
 -		nb->priority -= 1;
 -
  	atomic_notifier_chain_register(&x86_mce_decoder_chain, nb);
++<<<<<<< HEAD
 +	drain_mcelog_buffer();
++=======
++>>>>>>> eef4dfa0cb83 (x86/mce: Kill drain_mcelog_buffer())
  }
  EXPORT_SYMBOL_GPL(mce_register_decode_chain);
  
@@@ -2053,8 -1988,12 +2060,12 @@@ __setup("mce", mcheck_enable)
  int __init mcheck_init(void)
  {
  	mcheck_intel_therm_init();
++<<<<<<< HEAD
++=======
+ 	mce_register_decode_chain(&mce_srao_nb);
++>>>>>>> eef4dfa0cb83 (x86/mce: Kill drain_mcelog_buffer())
  	mcheck_vendor_init_severity();
  
 -	INIT_WORK(&mce_work, mce_process_work);
 -	init_irq_work(&mce_irq_work, mce_irq_work_cb);
 -
  	return 0;
  }
  
* Unmerged path arch/x86/kernel/cpu/mcheck/mce.c
