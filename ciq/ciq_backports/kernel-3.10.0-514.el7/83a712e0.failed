sunrpc: add some tracepoints around enqueue and dequeue of svc_xprt

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Jeff Layton <jlayton@primarydata.com>
commit 83a712e0afefaf68555f816ea78ecd2862c6cf30
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/83a712e0.failed

These were useful when I was tracking down a race condition between
svc_xprt_do_enqueue and svc_get_next_xprt.

	Signed-off-by: Jeff Layton <jlayton@primarydata.com>
	Signed-off-by: J. Bruce Fields <bfields@redhat.com>
(cherry picked from commit 83a712e0afefaf68555f816ea78ecd2862c6cf30)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/trace/events/sunrpc.h
#	net/sunrpc/svc_xprt.c
diff --cc include/trace/events/sunrpc.h
index 6260f5134212,b9c1dc6c825a..000000000000
--- a/include/trace/events/sunrpc.h
+++ b/include/trace/events/sunrpc.h
@@@ -7,6 -7,8 +7,11 @@@
  #include <linux/sunrpc/sched.h>
  #include <linux/sunrpc/clnt.h>
  #include <linux/sunrpc/svc.h>
++<<<<<<< HEAD
++=======
+ #include <linux/sunrpc/xprtsock.h>
+ #include <linux/sunrpc/svc_xprt.h>
++>>>>>>> 83a712e0afef (sunrpc: add some tracepoints around enqueue and dequeue of svc_xprt)
  #include <net/tcp_states.h>
  #include <linux/net.h>
  #include <linux/tracepoint.h>
diff --cc net/sunrpc/svc_xprt.c
index 8398c7f679ec,73d40bd1839a..000000000000
--- a/net/sunrpc/svc_xprt.c
+++ b/net/sunrpc/svc_xprt.c
@@@ -356,11 -322,12 +356,11 @@@ static bool svc_xprt_has_something_to_d
  static void svc_xprt_do_enqueue(struct svc_xprt *xprt)
  {
  	struct svc_pool *pool;
- 	struct svc_rqst	*rqstp;
+ 	struct svc_rqst	*rqstp = NULL;
  	int cpu;
 -	bool queued = false;
  
  	if (!svc_xprt_has_something_to_do(xprt))
- 		return;
+ 		goto out;
  
  	/* Mark transport as busy. It will remain in this state until
  	 * the provider calls svc_xprt_received. We update XPT_BUSY
@@@ -379,34 -345,61 +379,56 @@@
  
  	atomic_long_inc(&pool->sp_stats.packets);
  
 -redo_search:
 -	/* find a thread for this xprt */
 -	rcu_read_lock();
 -	list_for_each_entry_rcu(rqstp, &pool->sp_all_threads, rq_all) {
 -		/* Do a lockless check first */
 -		if (test_bit(RQ_BUSY, &rqstp->rq_flags))
 -			continue;
 -
 -		/*
 -		 * Once the xprt has been queued, it can only be dequeued by
 -		 * the task that intends to service it. All we can do at that
 -		 * point is to try to wake this thread back up so that it can
 -		 * do so.
 +	if (!list_empty(&pool->sp_threads)) {
 +		rqstp = list_entry(pool->sp_threads.next,
 +				   struct svc_rqst,
 +				   rq_list);
 +		dprintk("svc: transport %p served by daemon %p\n",
 +			xprt, rqstp);
 +		svc_thread_dequeue(pool, rqstp);
 +		if (rqstp->rq_xprt)
 +			printk(KERN_ERR
 +				"svc_xprt_enqueue: server %p, rq_xprt=%p!\n",
 +				rqstp, rqstp->rq_xprt);
 +		/* Note the order of the following 3 lines:
 +		 * We want to assign xprt to rqstp->rq_xprt only _after_
 +		 * we've woken up the process, so that we don't race with
 +		 * the lockless check in svc_get_next_xprt().
  		 */
 -		if (!queued) {
 -			spin_lock_bh(&rqstp->rq_lock);
 -			if (test_and_set_bit(RQ_BUSY, &rqstp->rq_flags)) {
 -				/* already busy, move on... */
 -				spin_unlock_bh(&rqstp->rq_lock);
 -				continue;
 -			}
 -
 -			/* this one will do */
 -			rqstp->rq_xprt = xprt;
 -			svc_xprt_get(xprt);
 -			spin_unlock_bh(&rqstp->rq_lock);
 -		}
 -		rcu_read_unlock();
 -
 -		atomic_long_inc(&pool->sp_stats.threads_woken);
 +		svc_xprt_get(xprt);
  		wake_up_process(rqstp->rq_task);
++<<<<<<< HEAD
 +		rqstp->rq_xprt = xprt;
 +		atomic_long_inc(&pool->sp_stats.threads_woken);
 +	} else {
++=======
+ 		put_cpu();
+ 		goto out;
+ 	}
+ 	rcu_read_unlock();
+ 
+ 	/*
+ 	 * We didn't find an idle thread to use, so we need to queue the xprt.
+ 	 * Do so and then search again. If we find one, we can't hook this one
+ 	 * up to it directly but we can wake the thread up in the hopes that it
+ 	 * will pick it up once it searches for a xprt to service.
+ 	 */
+ 	if (!queued) {
+ 		queued = true;
++>>>>>>> 83a712e0afef (sunrpc: add some tracepoints around enqueue and dequeue of svc_xprt)
  		dprintk("svc: transport %p put into queue\n", xprt);
 -		spin_lock_bh(&pool->sp_lock);
  		list_add_tail(&xprt->xpt_ready, &pool->sp_sockets);
  		pool->sp_stats.sockets_queued++;
 -		spin_unlock_bh(&pool->sp_lock);
 -		goto redo_search;
  	}
++<<<<<<< HEAD
 +
 +	spin_unlock_bh(&pool->sp_lock);
++=======
+ 	rqstp = NULL;
++>>>>>>> 83a712e0afef (sunrpc: add some tracepoints around enqueue and dequeue of svc_xprt)
  	put_cpu();
+ out:
+ 	trace_svc_xprt_do_enqueue(xprt, rqstp);
  }
  
  /*
@@@ -427,18 -420,24 +449,27 @@@ EXPORT_SYMBOL_GPL(svc_xprt_enqueue)
   */
  static struct svc_xprt *svc_xprt_dequeue(struct svc_pool *pool)
  {
 -	struct svc_xprt	*xprt = NULL;
 +	struct svc_xprt	*xprt;
  
  	if (list_empty(&pool->sp_sockets))
- 		return NULL;
+ 		goto out;
  
 -	spin_lock_bh(&pool->sp_lock);
 -	if (likely(!list_empty(&pool->sp_sockets))) {
 -		xprt = list_first_entry(&pool->sp_sockets,
 -					struct svc_xprt, xpt_ready);
 -		list_del_init(&xprt->xpt_ready);
 -		svc_xprt_get(xprt);
 +	xprt = list_entry(pool->sp_sockets.next,
 +			  struct svc_xprt, xpt_ready);
 +	list_del_init(&xprt->xpt_ready);
  
++<<<<<<< HEAD
 +	dprintk("svc: transport %p dequeued, inuse=%d\n",
 +		xprt, atomic_read(&xprt->xpt_ref.refcount));
 +
++=======
+ 		dprintk("svc: transport %p dequeued, inuse=%d\n",
+ 			xprt, atomic_read(&xprt->xpt_ref.refcount));
+ 	}
+ 	spin_unlock_bh(&pool->sp_lock);
+ out:
+ 	trace_svc_xprt_dequeue(xprt);
++>>>>>>> 83a712e0afef (sunrpc: add some tracepoints around enqueue and dequeue of svc_xprt)
  	return xprt;
  }
  
@@@ -512,16 -511,23 +543,28 @@@ void svc_wake_up(struct svc_serv *serv
  
  	pool = &serv->sv_pools[0];
  
 -	rcu_read_lock();
 -	list_for_each_entry_rcu(rqstp, &pool->sp_all_threads, rq_all) {
 -		/* skip any that aren't queued */
 -		if (test_bit(RQ_BUSY, &rqstp->rq_flags))
 -			continue;
 -		rcu_read_unlock();
 +	spin_lock_bh(&pool->sp_lock);
 +	if (!list_empty(&pool->sp_threads)) {
 +		rqstp = list_entry(pool->sp_threads.next,
 +				   struct svc_rqst,
 +				   rq_list);
  		dprintk("svc: daemon %p woken up.\n", rqstp);
  		wake_up_process(rqstp->rq_task);
++<<<<<<< HEAD
 +	} else
 +		set_bit(SP_TASK_PENDING, &pool->sp_flags);
 +	spin_unlock_bh(&pool->sp_lock);
++=======
+ 		trace_svc_wake_up(rqstp->rq_task->pid);
+ 		return;
+ 	}
+ 	rcu_read_unlock();
+ 
+ 	/* No free entries available */
+ 	set_bit(SP_TASK_PENDING, &pool->sp_flags);
+ 	smp_wmb();
+ 	trace_svc_wake_up(0);
++>>>>>>> 83a712e0afef (sunrpc: add some tracepoints around enqueue and dequeue of svc_xprt)
  }
  EXPORT_SYMBOL_GPL(svc_wake_up);
  
* Unmerged path include/trace/events/sunrpc.h
* Unmerged path net/sunrpc/svc_xprt.c
