rhashtable: involve rhashtable_lookup_compare_insert routine

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Ying Xue <ying.xue@windriver.com>
commit 7a868d1e9ab3c534c5ad44e3e5dc46753a1e5636
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/7a868d1e.failed

Introduce a new function called rhashtable_lookup_compare_insert()
which is very similar to rhashtable_lookup_insert(). But the former
makes use of users' given compare function to look for an object,
and then inserts it into hash table if found. As the entire process
of search and insertion is under protection of per bucket lock, this
can help users to avoid the involvement of extra lock.

	Signed-off-by: Ying Xue <ying.xue@windriver.com>
	Cc: Thomas Graf <tgraf@suug.ch>
	Acked-by: Thomas Graf <tgraf@suug.ch>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 7a868d1e9ab3c534c5ad44e3e5dc46753a1e5636)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/rhashtable.h
#	lib/rhashtable.c
diff --cc include/linux/rhashtable.h
index 0839d7b8cd60,7b9bd77ed684..000000000000
--- a/include/linux/rhashtable.h
+++ b/include/linux/rhashtable.h
@@@ -109,11 -165,17 +109,20 @@@ bool rht_shrink_below_30(const struct r
  int rhashtable_expand(struct rhashtable *ht);
  int rhashtable_shrink(struct rhashtable *ht);
  
 -void *rhashtable_lookup(struct rhashtable *ht, const void *key);
 -void *rhashtable_lookup_compare(struct rhashtable *ht, const void *key,
 +void *rhashtable_lookup(const struct rhashtable *ht, const void *key);
 +void *rhashtable_lookup_compare(const struct rhashtable *ht, const void *key,
  				bool (*compare)(void *, void *), void *arg);
++<<<<<<< HEAD
++=======
+ 
+ bool rhashtable_lookup_insert(struct rhashtable *ht, struct rhash_head *obj);
+ bool rhashtable_lookup_compare_insert(struct rhashtable *ht,
+ 				      struct rhash_head *obj,
+ 				      bool (*compare)(void *, void *),
+ 				      void *arg);
++>>>>>>> 7a868d1e9ab3 (rhashtable: involve rhashtable_lookup_compare_insert routine)
  
 -void rhashtable_destroy(struct rhashtable *ht);
 +void rhashtable_destroy(const struct rhashtable *ht);
  
  #define rht_dereference(p, ht) \
  	rcu_dereference_protected(p, lockdep_rht_mutex_is_held(ht))
diff --cc lib/rhashtable.c
index be20e9720492,ed6ae1ad304c..000000000000
--- a/lib/rhashtable.c
+++ b/lib/rhashtable.c
@@@ -458,6 -705,104 +458,107 @@@ void *rhashtable_lookup_compare(const s
  }
  EXPORT_SYMBOL_GPL(rhashtable_lookup_compare);
  
++<<<<<<< HEAD
++=======
+ /**
+  * rhashtable_lookup_insert - lookup and insert object into hash table
+  * @ht:		hash table
+  * @obj:	pointer to hash head inside object
+  *
+  * Locks down the bucket chain in both the old and new table if a resize
+  * is in progress to ensure that writers can't remove from the old table
+  * and can't insert to the new table during the atomic operation of search
+  * and insertion. Searches for duplicates in both the old and new table if
+  * a resize is in progress.
+  *
+  * This lookup function may only be used for fixed key hash table (key_len
+  * parameter set). It will BUG() if used inappropriately.
+  *
+  * It is safe to call this function from atomic context.
+  *
+  * Will trigger an automatic deferred table resizing if the size grows
+  * beyond the watermark indicated by grow_decision() which can be passed
+  * to rhashtable_init().
+  */
+ bool rhashtable_lookup_insert(struct rhashtable *ht, struct rhash_head *obj)
+ {
+ 	struct rhashtable_compare_arg arg = {
+ 		.ht = ht,
+ 		.key = rht_obj(ht, obj) + ht->p.key_offset,
+ 	};
+ 
+ 	BUG_ON(!ht->p.key_len);
+ 
+ 	return rhashtable_lookup_compare_insert(ht, obj, &rhashtable_compare,
+ 						&arg);
+ }
+ EXPORT_SYMBOL_GPL(rhashtable_lookup_insert);
+ 
+ /**
+  * rhashtable_lookup_compare_insert - search and insert object to hash table
+  *                                    with compare function
+  * @ht:		hash table
+  * @obj:	pointer to hash head inside object
+  * @compare:	compare function, must return true on match
+  * @arg:	argument passed on to compare function
+  *
+  * Locks down the bucket chain in both the old and new table if a resize
+  * is in progress to ensure that writers can't remove from the old table
+  * and can't insert to the new table during the atomic operation of search
+  * and insertion. Searches for duplicates in both the old and new table if
+  * a resize is in progress.
+  *
+  * Lookups may occur in parallel with hashtable mutations and resizing.
+  *
+  * Will trigger an automatic deferred table resizing if the size grows
+  * beyond the watermark indicated by grow_decision() which can be passed
+  * to rhashtable_init().
+  */
+ bool rhashtable_lookup_compare_insert(struct rhashtable *ht,
+ 				      struct rhash_head *obj,
+ 				      bool (*compare)(void *, void *),
+ 				      void *arg)
+ {
+ 	struct bucket_table *new_tbl, *old_tbl;
+ 	spinlock_t *new_bucket_lock, *old_bucket_lock;
+ 	u32 new_hash, old_hash;
+ 	bool success = true;
+ 
+ 	BUG_ON(!ht->p.key_len);
+ 
+ 	rcu_read_lock();
+ 
+ 	old_tbl = rht_dereference_rcu(ht->tbl, ht);
+ 	old_hash = head_hashfn(ht, old_tbl, obj);
+ 	old_bucket_lock = bucket_lock(old_tbl, old_hash);
+ 	spin_lock_bh(old_bucket_lock);
+ 
+ 	new_tbl = rht_dereference_rcu(ht->future_tbl, ht);
+ 	new_hash = head_hashfn(ht, new_tbl, obj);
+ 	new_bucket_lock = bucket_lock(new_tbl, new_hash);
+ 	if (unlikely(old_tbl != new_tbl))
+ 		spin_lock_bh_nested(new_bucket_lock, RHT_LOCK_NESTED);
+ 
+ 	if (rhashtable_lookup_compare(ht, rht_obj(ht, obj) + ht->p.key_offset,
+ 				      compare, arg)) {
+ 		success = false;
+ 		goto exit;
+ 	}
+ 
+ 	__rhashtable_insert(ht, obj, new_tbl, new_hash);
+ 
+ exit:
+ 	if (unlikely(old_tbl != new_tbl))
+ 		spin_unlock_bh(new_bucket_lock);
+ 	spin_unlock_bh(old_bucket_lock);
+ 
+ 	rcu_read_unlock();
+ 
+ 	return success;
+ }
+ EXPORT_SYMBOL_GPL(rhashtable_lookup_compare_insert);
+ 
++>>>>>>> 7a868d1e9ab3 (rhashtable: involve rhashtable_lookup_compare_insert routine)
  static size_t rounded_hashtable_size(struct rhashtable_params *params)
  {
  	return max(roundup_pow_of_two(params->nelem_hint * 4 / 3),
* Unmerged path include/linux/rhashtable.h
* Unmerged path lib/rhashtable.c
