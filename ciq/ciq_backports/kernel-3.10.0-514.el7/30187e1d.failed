dm: rename target's per_bio_data_size to per_io_data_size

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Mike Snitzer <snitzer@redhat.com>
commit 30187e1d48a258e304af184c45c3140c8509d219
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/30187e1d.failed

Request-based DM will also make use of per_bio_data_size.

	Signed-off-by: Mike Snitzer <snitzer@redhat.com>
(cherry picked from commit 30187e1d48a258e304af184c45c3140c8509d219)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/dm-log-writes.c
#	drivers/md/dm-verity-fec.c
#	drivers/md/dm-verity-target.c
diff --cc drivers/md/dm-verity-target.c
index 0ec8b641792b,0aba34a7b3b3..000000000000
--- a/drivers/md/dm-verity-target.c
+++ b/drivers/md/dm-verity-target.c
@@@ -353,6 -344,57 +353,60 @@@ release_ret_r
  }
  
  /*
++<<<<<<< HEAD
++=======
+  * Calls function process for 1 << v->data_dev_block_bits bytes in the bio_vec
+  * starting from iter.
+  */
+ int verity_for_bv_block(struct dm_verity *v, struct dm_verity_io *io,
+ 			struct bvec_iter *iter,
+ 			int (*process)(struct dm_verity *v,
+ 				       struct dm_verity_io *io, u8 *data,
+ 				       size_t len))
+ {
+ 	unsigned todo = 1 << v->data_dev_block_bits;
+ 	struct bio *bio = dm_bio_from_per_bio_data(io, v->ti->per_io_data_size);
+ 
+ 	do {
+ 		int r;
+ 		u8 *page;
+ 		unsigned len;
+ 		struct bio_vec bv = bio_iter_iovec(bio, *iter);
+ 
+ 		page = kmap_atomic(bv.bv_page);
+ 		len = bv.bv_len;
+ 
+ 		if (likely(len >= todo))
+ 			len = todo;
+ 
+ 		r = process(v, io, page + bv.bv_offset, len);
+ 		kunmap_atomic(page);
+ 
+ 		if (r < 0)
+ 			return r;
+ 
+ 		bio_advance_iter(bio, iter, len);
+ 		todo -= len;
+ 	} while (todo);
+ 
+ 	return 0;
+ }
+ 
+ static int verity_bv_hash_update(struct dm_verity *v, struct dm_verity_io *io,
+ 				 u8 *data, size_t len)
+ {
+ 	return verity_hash_update(v, verity_io_hash_desc(v, io), data, len);
+ }
+ 
+ static int verity_bv_zero(struct dm_verity *v, struct dm_verity_io *io,
+ 			  u8 *data, size_t len)
+ {
+ 	memset(data, 0, len);
+ 	return 0;
+ }
+ 
+ /*
++>>>>>>> 30187e1d48a2 (dm: rename target's per_bio_data_size to per_io_data_size)
   * Verify one "dm_verity_io" structure.
   */
  static int verity_verify_io(struct dm_verity_io *io)
@@@ -468,15 -460,14 +522,15 @@@ test_block_hash
  static void verity_finish_io(struct dm_verity_io *io, int error)
  {
  	struct dm_verity *v = io->v;
- 	struct bio *bio = dm_bio_from_per_bio_data(io, v->ti->per_bio_data_size);
+ 	struct bio *bio = dm_bio_from_per_bio_data(io, v->ti->per_io_data_size);
  
  	bio->bi_end_io = io->orig_bi_end_io;
 -	bio->bi_error = error;
 +	bio->bi_private = io->orig_bi_private;
  
 -	verity_fec_finish_io(io);
 +	if (io->io_vec != io->io_vec_inline)
 +		mempool_free(io->io_vec, v->vec_mempool);
  
 -	bio_endio(bio);
 +	bio_endio(bio, error);
  }
  
  static void verity_work(struct work_struct *w)
@@@ -583,12 -574,11 +637,12 @@@ static int verity_map(struct dm_target 
  	if (bio_data_dir(bio) == WRITE)
  		return -EIO;
  
- 	io = dm_per_bio_data(bio, ti->per_bio_data_size);
+ 	io = dm_per_bio_data(bio, ti->per_io_data_size);
  	io->v = v;
  	io->orig_bi_end_io = bio->bi_end_io;
 -	io->block = bio->bi_iter.bi_sector >> (v->data_dev_block_bits - SECTOR_SHIFT);
 -	io->n_blocks = bio->bi_iter.bi_size >> v->data_dev_block_bits;
 +	io->orig_bi_private = bio->bi_private;
 +	io->block = bio->bi_sector >> (v->data_dev_block_bits - SECTOR_SHIFT);
 +	io->n_blocks = bio->bi_size >> v->data_dev_block_bits;
  
  	bio->bi_end_io = verity_end_io;
  	bio->bi_private = io;
@@@ -1014,6 -1036,16 +1068,19 @@@ static int verity_ctr(struct dm_target 
  		goto bad;
  	}
  
++<<<<<<< HEAD
++=======
+ 	ti->per_io_data_size = sizeof(struct dm_verity_io) +
+ 				v->shash_descsize + v->digest_size * 2;
+ 
+ 	r = verity_fec_ctr(v);
+ 	if (r)
+ 		goto bad;
+ 
+ 	ti->per_io_data_size = roundup(ti->per_io_data_size,
+ 				       __alignof__(struct dm_verity_io));
+ 
++>>>>>>> 30187e1d48a2 (dm: rename target's per_bio_data_size to per_io_data_size)
  	return 0;
  
  bad:
* Unmerged path drivers/md/dm-log-writes.c
* Unmerged path drivers/md/dm-verity-fec.c
diff --git a/drivers/md/dm-cache-target.c b/drivers/md/dm-cache-target.c
index fac969af4bbe..62eed49daeb0 100644
--- a/drivers/md/dm-cache-target.c
+++ b/drivers/md/dm-cache-target.c
@@ -2773,7 +2773,7 @@ static int cache_create(struct cache_args *ca, struct cache **result)
 	ti->split_discard_bios = false;
 
 	cache->features = ca->features;
-	ti->per_bio_data_size = get_per_bio_data_size(cache);
+	ti->per_io_data_size = get_per_bio_data_size(cache);
 
 	cache->callbacks.congested_fn = cache_is_congested;
 	dm_table_add_target_callbacks(ti->table, &cache->callbacks);
diff --git a/drivers/md/dm-crypt.c b/drivers/md/dm-crypt.c
index ecb3bd20b2be..9d79aff6327a 100644
--- a/drivers/md/dm-crypt.c
+++ b/drivers/md/dm-crypt.c
@@ -1790,7 +1790,7 @@ static int crypt_ctr(struct dm_target *ti, unsigned int argc, char **argv)
 		goto bad;
 	}
 
-	cc->per_bio_data_size = ti->per_bio_data_size =
+	cc->per_bio_data_size = ti->per_io_data_size =
 		ALIGN(sizeof(struct dm_crypt_io) + cc->dmreq_start +
 		      sizeof(struct dm_crypt_request) + iv_size_padding + cc->iv_size,
 		      ARCH_KMALLOC_MINALIGN);
diff --git a/drivers/md/dm-delay.c b/drivers/md/dm-delay.c
index 84104d5fc6c6..2801cce2600a 100644
--- a/drivers/md/dm-delay.c
+++ b/drivers/md/dm-delay.c
@@ -198,7 +198,7 @@ out:
 
 	ti->num_flush_bios = 1;
 	ti->num_discard_bios = 1;
-	ti->per_bio_data_size = sizeof(struct dm_delay_info);
+	ti->per_io_data_size = sizeof(struct dm_delay_info);
 	ti->private = dc;
 	return 0;
 
diff --git a/drivers/md/dm-flakey.c b/drivers/md/dm-flakey.c
index c80a0ec5f126..d5fb78876c65 100644
--- a/drivers/md/dm-flakey.c
+++ b/drivers/md/dm-flakey.c
@@ -218,7 +218,7 @@ static int flakey_ctr(struct dm_target *ti, unsigned int argc, char **argv)
 
 	ti->num_flush_bios = 1;
 	ti->num_discard_bios = 1;
-	ti->per_bio_data_size = sizeof(struct per_bio_data);
+	ti->per_io_data_size = sizeof(struct per_bio_data);
 	ti->private = fc;
 	return 0;
 
* Unmerged path drivers/md/dm-log-writes.c
diff --git a/drivers/md/dm-raid1.c b/drivers/md/dm-raid1.c
index 9610cbbbafa6..c941eb46b755 100644
--- a/drivers/md/dm-raid1.c
+++ b/drivers/md/dm-raid1.c
@@ -1086,7 +1086,7 @@ static int mirror_ctr(struct dm_target *ti, unsigned int argc, char **argv)
 
 	ti->num_flush_bios = 1;
 	ti->num_discard_bios = 1;
-	ti->per_bio_data_size = sizeof(struct dm_raid1_bio_record);
+	ti->per_io_data_size = sizeof(struct dm_raid1_bio_record);
 	ti->discard_zeroes_data_unsupported = true;
 
 	ms->kmirrord_wq = alloc_workqueue("kmirrord", WQ_MEM_RECLAIM, 0);
diff --git a/drivers/md/dm-snap.c b/drivers/md/dm-snap.c
index 273158e59a98..aa0e42529147 100644
--- a/drivers/md/dm-snap.c
+++ b/drivers/md/dm-snap.c
@@ -1209,7 +1209,7 @@ static int snapshot_ctr(struct dm_target *ti, unsigned int argc, char **argv)
 
 	ti->private = s;
 	ti->num_flush_bios = num_flush_bios;
-	ti->per_bio_data_size = sizeof(struct dm_snap_tracked_chunk);
+	ti->per_io_data_size = sizeof(struct dm_snap_tracked_chunk);
 
 	/* Add snapshot to the list of snapshots for this origin */
 	/* Exceptions aren't triggered till snapshot_resume() is called */
diff --git a/drivers/md/dm-table.c b/drivers/md/dm-table.c
index 38a87abfee3e..c8a5bd7b92bc 100644
--- a/drivers/md/dm-table.c
+++ b/drivers/md/dm-table.c
@@ -965,7 +965,7 @@ bool dm_table_mq_request_based(struct dm_table *t)
 static int dm_table_alloc_md_mempools(struct dm_table *t, struct mapped_device *md)
 {
 	unsigned type = dm_table_get_type(t);
-	unsigned per_bio_data_size = 0;
+	unsigned per_io_data_size = 0;
 	struct dm_target *tgt;
 	unsigned i;
 
@@ -977,10 +977,10 @@ static int dm_table_alloc_md_mempools(struct dm_table *t, struct mapped_device *
 	if (type == DM_TYPE_BIO_BASED)
 		for (i = 0; i < t->num_targets; i++) {
 			tgt = t->targets + i;
-			per_bio_data_size = max(per_bio_data_size, tgt->per_bio_data_size);
+			per_io_data_size = max(per_io_data_size, tgt->per_io_data_size);
 		}
 
-	t->mempools = dm_alloc_md_mempools(md, type, t->integrity_supported, per_bio_data_size);
+	t->mempools = dm_alloc_md_mempools(md, type, t->integrity_supported, per_io_data_size);
 	if (!t->mempools)
 		return -ENOMEM;
 
diff --git a/drivers/md/dm-thin.c b/drivers/md/dm-thin.c
index 1e40c68755b4..890d2712a78d 100644
--- a/drivers/md/dm-thin.c
+++ b/drivers/md/dm-thin.c
@@ -4104,7 +4104,7 @@ static int thin_ctr(struct dm_target *ti, unsigned argc, char **argv)
 
 	ti->num_flush_bios = 1;
 	ti->flush_supported = true;
-	ti->per_bio_data_size = sizeof(struct dm_thin_endio_hook);
+	ti->per_io_data_size = sizeof(struct dm_thin_endio_hook);
 
 	/* In case the pool supports discards, pass them on. */
 	ti->discard_zeroes_data_unsupported = true;
* Unmerged path drivers/md/dm-verity-fec.c
* Unmerged path drivers/md/dm-verity-target.c
diff --git a/drivers/md/dm.c b/drivers/md/dm.c
index 511a3a6992f6..0a256f01958d 100644
--- a/drivers/md/dm.c
+++ b/drivers/md/dm.c
@@ -3674,7 +3674,7 @@ int dm_noflush_suspending(struct dm_target *ti)
 EXPORT_SYMBOL_GPL(dm_noflush_suspending);
 
 struct dm_md_mempools *dm_alloc_md_mempools(struct mapped_device *md, unsigned type,
-					    unsigned integrity, unsigned per_bio_data_size)
+					    unsigned integrity, unsigned per_io_data_size)
 {
 	struct dm_md_mempools *pools = kzalloc(sizeof(*pools), GFP_KERNEL);
 	struct kmem_cache *cachep = NULL;
@@ -3690,7 +3690,7 @@ struct dm_md_mempools *dm_alloc_md_mempools(struct mapped_device *md, unsigned t
 	case DM_TYPE_BIO_BASED:
 		cachep = _io_cache;
 		pool_size = dm_get_reserved_bio_based_ios();
-		front_pad = roundup(per_bio_data_size, __alignof__(struct dm_target_io)) + offsetof(struct dm_target_io, clone);
+		front_pad = roundup(per_io_data_size, __alignof__(struct dm_target_io)) + offsetof(struct dm_target_io, clone);
 		break;
 	case DM_TYPE_REQUEST_BASED:
 		cachep = _rq_tio_cache;
@@ -3703,8 +3703,8 @@ struct dm_md_mempools *dm_alloc_md_mempools(struct mapped_device *md, unsigned t
 		if (!pool_size)
 			pool_size = dm_get_reserved_rq_based_ios();
 		front_pad = offsetof(struct dm_rq_clone_bio_info, clone);
-		/* per_bio_data_size is not used. See __bind_mempools(). */
-		WARN_ON(per_bio_data_size != 0);
+		/* per_io_data_size is not used. */
+		WARN_ON(per_io_data_size != 0);
 		break;
 	default:
 		BUG();
diff --git a/include/linux/device-mapper.h b/include/linux/device-mapper.h
index 8d9b7c216f51..d96978c71cea 100644
--- a/include/linux/device-mapper.h
+++ b/include/linux/device-mapper.h
@@ -242,10 +242,10 @@ struct dm_target {
 	unsigned num_write_same_bios;
 
 	/*
-	 * The minimum number of extra bytes allocated in each bio for the
-	 * target to use.  dm_per_bio_data returns the data location.
+	 * The minimum number of extra bytes allocated in each io for the
+	 * target to use.
 	 */
-	unsigned per_bio_data_size;
+	unsigned per_io_data_size;
 
 	/*
 	 * If defined, this function is called to find out how many
