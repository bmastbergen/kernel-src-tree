sched: Move SCHED_RESET_ON_FORK into attr::sched_flags

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Peter Zijlstra <peterz@infradead.org>
commit 7479f3c9cf67edf5e8a76b21ea3726757f35cf53
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/7479f3c9.failed

I noticed the new sched_{set,get}attr() calls didn't properly deal
with the SCHED_RESET_ON_FORK hack.

Instead of propagating the flags in high bits nonsense use the brand
spanking new attr::sched_flags field.

	Signed-off-by: Peter Zijlstra <peterz@infradead.org>
	Cc: Juri Lelli <juri.lelli@gmail.com>
	Cc: Dario Faggioli <raistlin@linux.it>
Link: http://lkml.kernel.org/r/20140115162242.GJ31570@twins.programming.kicks-ass.net
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 7479f3c9cf67edf5e8a76b21ea3726757f35cf53)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/uapi/linux/sched.h
#	kernel/sched/core.c
diff --cc include/uapi/linux/sched.h
index 5a0f945927ac,34f9d7387d13..000000000000
--- a/include/uapi/linux/sched.h
+++ b/include/uapi/linux/sched.h
@@@ -39,6 -39,8 +39,11 @@@
  #define SCHED_BATCH		3
  /* SCHED_ISO: reserved but not implemented yet */
  #define SCHED_IDLE		5
++<<<<<<< HEAD
++=======
+ #define SCHED_DEADLINE		6
+ 
++>>>>>>> 7479f3c9cf67 (sched: Move SCHED_RESET_ON_FORK into attr::sched_flags)
  /* Can be ORed in to make sure the process is reverted back to SCHED_NORMAL on fork */
  #define SCHED_RESET_ON_FORK     0x40000000
  
diff --cc kernel/sched/core.c
index 04c5c65570ca,93a2836b6220..000000000000
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@@ -4132,10 -3267,10 +4132,9 @@@ recheck
  		reset_on_fork = p->sched_reset_on_fork;
  		policy = oldpolicy = p->policy;
  	} else {
- 		reset_on_fork = !!(policy & SCHED_RESET_ON_FORK);
- 		policy &= ~SCHED_RESET_ON_FORK;
+ 		reset_on_fork = !!(attr->sched_flags & SCHED_FLAG_RESET_ON_FORK);
  
 -		if (policy != SCHED_DEADLINE &&
 -				policy != SCHED_FIFO && policy != SCHED_RR &&
 +		if (policy != SCHED_FIFO && policy != SCHED_RR &&
  				policy != SCHED_NORMAL && policy != SCHED_BATCH &&
  				policy != SCHED_IDLE)
  			return -EINVAL;
@@@ -4290,7 -3478,7 +4312,11 @@@ static int _sched_setscheduler(struct t
  int sched_setscheduler(struct task_struct *p, int policy,
  		       const struct sched_param *param)
  {
++<<<<<<< HEAD
 +	return __sched_setscheduler(p, policy, param, true);
++=======
+ 	return _sched_setscheduler(p, policy, param, true);
++>>>>>>> 7479f3c9cf67 (sched: Move SCHED_RESET_ON_FORK into attr::sched_flags)
  }
  EXPORT_SYMBOL_GPL(sched_setscheduler);
  
@@@ -4310,7 -3504,7 +4336,11 @@@
  int sched_setscheduler_nocheck(struct task_struct *p, int policy,
  			       const struct sched_param *param)
  {
++<<<<<<< HEAD
 +	return __sched_setscheduler(p, policy, param, false);
++=======
+ 	return _sched_setscheduler(p, policy, param, false);
++>>>>>>> 7479f3c9cf67 (sched: Move SCHED_RESET_ON_FORK into attr::sched_flags)
  }
  
  static int
@@@ -4435,6 -3733,96 +4465,99 @@@ out_unlock
  	return retval;
  }
  
++<<<<<<< HEAD
++=======
+ static int sched_read_attr(struct sched_attr __user *uattr,
+ 			   struct sched_attr *attr,
+ 			   unsigned int usize)
+ {
+ 	int ret;
+ 
+ 	if (!access_ok(VERIFY_WRITE, uattr, usize))
+ 		return -EFAULT;
+ 
+ 	/*
+ 	 * If we're handed a smaller struct than we know of,
+ 	 * ensure all the unknown bits are 0 - i.e. old
+ 	 * user-space does not get uncomplete information.
+ 	 */
+ 	if (usize < sizeof(*attr)) {
+ 		unsigned char *addr;
+ 		unsigned char *end;
+ 
+ 		addr = (void *)attr + usize;
+ 		end  = (void *)attr + sizeof(*attr);
+ 
+ 		for (; addr < end; addr++) {
+ 			if (*addr)
+ 				goto err_size;
+ 		}
+ 
+ 		attr->size = usize;
+ 	}
+ 
+ 	ret = copy_to_user(uattr, attr, usize);
+ 	if (ret)
+ 		return -EFAULT;
+ 
+ out:
+ 	return ret;
+ 
+ err_size:
+ 	ret = -E2BIG;
+ 	goto out;
+ }
+ 
+ /**
+  * sys_sched_getattr - similar to sched_getparam, but with sched_attr
+  * @pid: the pid in question.
+  * @uattr: structure containing the extended parameters.
+  * @size: sizeof(attr) for fwd/bwd comp.
+  */
+ SYSCALL_DEFINE3(sched_getattr, pid_t, pid, struct sched_attr __user *, uattr,
+ 		unsigned int, size)
+ {
+ 	struct sched_attr attr = {
+ 		.size = sizeof(struct sched_attr),
+ 	};
+ 	struct task_struct *p;
+ 	int retval;
+ 
+ 	if (!uattr || pid < 0 || size > PAGE_SIZE ||
+ 	    size < SCHED_ATTR_SIZE_VER0)
+ 		return -EINVAL;
+ 
+ 	rcu_read_lock();
+ 	p = find_process_by_pid(pid);
+ 	retval = -ESRCH;
+ 	if (!p)
+ 		goto out_unlock;
+ 
+ 	retval = security_task_getscheduler(p);
+ 	if (retval)
+ 		goto out_unlock;
+ 
+ 	attr.sched_policy = p->policy;
+ 	if (p->sched_reset_on_fork)
+ 		attr.sched_flags |= SCHED_FLAG_RESET_ON_FORK;
+ 	if (task_has_dl_policy(p))
+ 		__getparam_dl(p, &attr);
+ 	else if (task_has_rt_policy(p))
+ 		attr.sched_priority = p->rt_priority;
+ 	else
+ 		attr.sched_nice = TASK_NICE(p);
+ 
+ 	rcu_read_unlock();
+ 
+ 	retval = sched_read_attr(uattr, &attr, size);
+ 	return retval;
+ 
+ out_unlock:
+ 	rcu_read_unlock();
+ 	return retval;
+ }
+ 
++>>>>>>> 7479f3c9cf67 (sched: Move SCHED_RESET_ON_FORK into attr::sched_flags)
  long sched_setaffinity(pid_t pid, const struct cpumask *in_mask)
  {
  	cpumask_var_t cpus_allowed, new_mask;
* Unmerged path include/uapi/linux/sched.h
* Unmerged path kernel/sched/core.c
