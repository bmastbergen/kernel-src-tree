xprtrdma: Don't provide a reply chunk when expecting a short reply

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Chuck Lever <chuck.lever@oracle.com>
commit 33943b2974734ca5e5bef583d09ddd1eded6a77b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/33943b29.failed

Currently Linux always offers a reply chunk, even when the reply
can be sent inline (ie. is smaller than 1KB).

On the client, registering a memory region can be expensive. A
server may choose not to use the reply chunk, wasting the cost of
the registration.

This is a change only for RPC replies smaller than 1KB which the
server constructs in the RPC reply send buffer. Because the elements
of the reply must be XDR encoded, a copy-free data transfer has no
benefit in this case.

	Signed-off-by: Chuck Lever <chuck.lever@oracle.com>
	Reviewed-by: Sagi Grimberg <sagig@mellanox.com>
	Tested-by: Devesh Sharma <devesh.sharma@avagotech.com>
	Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
(cherry picked from commit 33943b2974734ca5e5bef583d09ddd1eded6a77b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sunrpc/xprtrdma/rpc_rdma.c
diff --cc net/sunrpc/xprtrdma/rpc_rdma.c
index 7cfb717728c2,62150ae2dc09..000000000000
--- a/net/sunrpc/xprtrdma/rpc_rdma.c
+++ b/net/sunrpc/xprtrdma/rpc_rdma.c
@@@ -482,43 -469,13 +482,51 @@@ rpcrdma_marshal_req(struct rpc_rqst *rq
  	 */
  	if (rtype == rpcrdma_noch) {
  
 -		rpcrdma_inline_pullup(rqst);
 -
 +		padlen = rpcrdma_inline_pullup(rqst,
 +						RPCRDMA_INLINE_PAD_VALUE(rqst));
 +
++<<<<<<< HEAD
 +		if (padlen) {
 +			headerp->rm_type = rdma_msgp;
 +			headerp->rm_body.rm_padded.rm_align =
 +				cpu_to_be32(RPCRDMA_INLINE_PAD_VALUE(rqst));
 +			headerp->rm_body.rm_padded.rm_thresh =
 +				cpu_to_be32(RPCRDMA_INLINE_PAD_THRESH);
 +			headerp->rm_body.rm_padded.rm_pempty[0] = xdr_zero;
 +			headerp->rm_body.rm_padded.rm_pempty[1] = xdr_zero;
 +			headerp->rm_body.rm_padded.rm_pempty[2] = xdr_zero;
 +			hdrlen += 2 * sizeof(u32); /* extra words in padhdr */
 +			if (wtype != rpcrdma_noch) {
 +				dprintk("RPC:       %s: invalid chunk list\n",
 +					__func__);
 +				return -EIO;
 +			}
 +		} else {
 +			headerp->rm_body.rm_nochunks.rm_empty[0] = xdr_zero;
 +			headerp->rm_body.rm_nochunks.rm_empty[1] = xdr_zero;
 +			headerp->rm_body.rm_nochunks.rm_empty[2] = xdr_zero;
 +			/* new length after pullup */
 +			rpclen = rqst->rq_svec[0].iov_len;
 +			/*
 +			 * Currently we try to not actually use read inline.
 +			 * Reply chunks have the desirable property that
 +			 * they land, packed, directly in the target buffers
 +			 * without headers, so they require no fixup. The
 +			 * additional RDMA Write op sends the same amount
 +			 * of data, streams on-the-wire and adds no overhead
 +			 * on receive. Therefore, we request a reply chunk
 +			 * for non-writes wherever feasible and efficient.
 +			 */
 +			if (wtype == rpcrdma_noch)
 +				wtype = rpcrdma_replych;
 +		}
++=======
+ 		headerp->rm_body.rm_nochunks.rm_empty[0] = xdr_zero;
+ 		headerp->rm_body.rm_nochunks.rm_empty[1] = xdr_zero;
+ 		headerp->rm_body.rm_nochunks.rm_empty[2] = xdr_zero;
+ 		/* new length after pullup */
+ 		rpclen = rqst->rq_svec[0].iov_len;
++>>>>>>> 33943b297473 (xprtrdma: Don't provide a reply chunk when expecting a short reply)
  	}
  
  	if (rtype != rpcrdma_noch) {
* Unmerged path net/sunrpc/xprtrdma/rpc_rdma.c
