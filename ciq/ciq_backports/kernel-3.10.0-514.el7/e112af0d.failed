nvme: don't overwrite req->cmd_flags on sync cmd

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Matias Bjørling <m@bjorling.me>
commit e112af0dc9f55099b948e55077504a44b4162c79
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/e112af0d.failed

In __nvme_submit_sync_cmd, the request direction is overwritten when
the REQ_FAILFAST_DRIVER flag is set.

	Signed-off-by: Matias Bjørling <m@bjorling.me>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
Fixes: 75619bfa904d0 ("NVMe: End sync requests immediately on failure")
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit e112af0dc9f55099b948e55077504a44b4162c79)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/block/nvme-core.c
diff --cc drivers/block/nvme-core.c
index d8687b59f02c,12d5b7b03f9b..000000000000
--- a/drivers/block/nvme-core.c
+++ b/drivers/block/nvme-core.c
@@@ -905,28 -1009,44 +905,36 @@@ static int __nvme_submit_sync_cmd(struc
  	if (IS_ERR(req))
  		return PTR_ERR(req);
  
++<<<<<<< HEAD
 +	cmdinfo.task = current;
 +	cmdinfo.status = -EINTR;
++=======
+ 	req->cmd_type = REQ_TYPE_DRV_PRIV;
+ 	req->cmd_flags |= REQ_FAILFAST_DRIVER;
+ 	req->__data_len = 0;
+ 	req->__sector = (sector_t) -1;
+ 	req->bio = req->biotail = NULL;
++>>>>>>> e112af0dc9f5 (nvme: don't overwrite req->cmd_flags on sync cmd)
  
 -	req->timeout = timeout ? timeout : ADMIN_TIMEOUT;
 +	cmd->common.command_id = req->tag;
  
 -	req->cmd = (unsigned char *)cmd;
 -	req->cmd_len = sizeof(struct nvme_command);
 -	req->special = (void *)0;
 +	cmd_rq = blk_mq_rq_to_pdu(req);
 +	nvme_set_info(cmd_rq, &cmdinfo, sync_completion);
  
 -	if (buffer && bufflen) {
 -		ret = blk_rq_map_kern(q, req, buffer, bufflen, __GFP_WAIT);
 -		if (ret)
 -			goto out;
 -	} else if (ubuffer && bufflen) {
 -		ret = blk_rq_map_user(q, req, NULL, ubuffer, bufflen, __GFP_WAIT);
 -		if (ret)
 -			goto out;
 -		bio = req->bio;
 -	}
 +	set_current_state(TASK_UNINTERRUPTIBLE);
 +	nvme_submit_cmd(cmd_rq->nvmeq, cmd);
 +	schedule();
  
 -	blk_execute_rq(req->q, NULL, req, 0);
 -	if (bio)
 -		blk_rq_unmap_user(bio);
  	if (result)
 -		*result = (u32)(uintptr_t)req->special;
 -	ret = req->errors;
 - out:
 +		*result = cmdinfo.result;
 +	res = cmdinfo.status;
  	blk_mq_free_request(req);
 -	return ret;
 +	return res;
  }
  
 -int nvme_submit_sync_cmd(struct request_queue *q, struct nvme_command *cmd,
 -		void *buffer, unsigned bufflen)
 +int nvme_submit_sync_cmd(struct request_queue *q, struct nvme_command *cmd)
  {
 -	return __nvme_submit_sync_cmd(q, cmd, buffer, NULL, bufflen, NULL, 0);
 +	return __nvme_submit_sync_cmd(q, cmd, NULL, 0);
  }
  
  static int nvme_submit_async_admin_req(struct nvme_dev *dev)
* Unmerged path drivers/block/nvme-core.c
