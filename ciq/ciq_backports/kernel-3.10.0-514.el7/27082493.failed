drm/i915/skl: Update DDB values atomically with wms/plane attrs

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [drm] i915/skl: Update DDB values atomically with wms/plane attrs (Lyude Paul) [1341633 1355776]
Rebuild_FUZZ: 96.72%
commit-author Lyude <cpaul@redhat.com>
commit 27082493e9c6371b05370a619ab9d2877c5f4726
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/27082493.failed

Now that we can hook into update_crtcs and control the order in which we
update CRTCs at each modeset, we can finish the final step of fixing
Skylake's watermark handling by performing DDB updates at the same time
as plane updates and watermark updates.

The first major change in this patch is skl_update_crtcs(), which
handles ensuring that we order each CRTC update in our atomic commits
properly so that they honor the DDB flush order.

The second major change in this patch is the order in which we flush the
pipes. While the previous order may have worked, it can't be used in
this approach since it no longer will do the right thing. For example,
using the old ddb flush order:

We have pipes A, B, and C enabled, and we're disabling C. Initial ddb
allocation looks like this:

|   A   |   B   |xxxxxxx|

Since we're performing the ddb updates after performing any CRTC
disablements in intel_atomic_commit_tail(), the space to the right of
pipe B is unallocated.

1. Flush pipes with new allocation contained into old space. None
   apply, so we skip this
2. Flush pipes having their allocation reduced, but overlapping with a
   previous allocation. None apply, so we also skip this
3. Flush pipes that got more space allocated. This applies to A and B,
   giving us the following update order: A, B

This is wrong, since updating pipe A first will cause it to overlap with
B and potentially burst into flames. Our new order (see the code
comments for details) would update the pipes in the proper order: B, A.

As well, we calculate the order for each DDB update during the check
phase, and reference it later in the commit phase when we hit
skl_update_crtcs().

This long overdue patch fixes the rest of the underruns on Skylake.

Changes since v1:
 - Add skl_ddb_entry_write() for cursor into skl_write_cursor_wm()
Changes since v2:
 - Use the method for updating CRTCs that Ville suggested
 - In skl_update_wm(), only copy the watermarks for the crtc that was
   passed to us
Changes since v3:
 - Small comment fix in skl_ddb_allocation_overlaps()
Changes since v4:
 - Remove the second loop in intel_update_crtcs() and use Ville's
   suggestion for updating the ddb allocations in the right order
 - Get rid of the second loop and just use the ddb state as it updates
   to determine what order to update everything in (thanks for the
   suggestion Ville)
 - Simplify skl_ddb_allocation_overlaps()
 - Split actual overlap checking into it's own helper

Fixes: 0e8fb7ba7ca5 ("drm/i915/skl: Flush the WM configuration")
Fixes: 8211bd5bdf5e ("drm/i915/skl: Program the DDB allocation")
[omitting CC for stable, since this patch will need to be changed for
such backports first]

Testcase: kms_cursor_legacy
Testcase: plane-all-modeset-transition
	Signed-off-by: Lyude <cpaul@redhat.com>
	Cc: Ville Syrjälä <ville.syrjala@linux.intel.com>
	Cc: Daniel Vetter <daniel.vetter@intel.com>
	Cc: Radhakrishna Sripada <radhakrishna.sripada@intel.com>
	Cc: Hans de Goede <hdegoede@redhat.com>
	Cc: Matt Roper <matthew.d.roper@intel.com>
	Signed-off-by: Maarten Lankhorst <maarten.lankhorst@linux.intel.com>
Link: http://patchwork.freedesktop.org/patch/msgid/1471961565-28540-2-git-send-email-cpaul@redhat.com
(cherry picked from commit 27082493e9c6371b05370a619ab9d2877c5f4726)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/i915/intel_display.c
#	drivers/gpu/drm/i915/intel_drv.h
#	drivers/gpu/drm/i915/intel_pm.c
diff --cc drivers/gpu/drm/i915/intel_display.c
index 0caacf8c3858,a388ed547f73..000000000000
--- a/drivers/gpu/drm/i915/intel_display.c
+++ b/drivers/gpu/drm/i915/intel_display.c
@@@ -11273,11 -13451,30 +11273,38 @@@ static void check_wm_state(struct drm_d
  		if (skl_ddb_entry_equal(hw_entry, sw_entry))
  			continue;
  
++<<<<<<< HEAD
 +		DRM_ERROR("mismatch in DDB state pipe %c cursor "
 +			  "(expected (%u,%u), found (%u,%u))\n",
 +			  pipe_name(pipe),
 +			  sw_entry->start, sw_entry->end,
 +			  hw_entry->start, hw_entry->end);
++=======
+ 		DRM_ERROR("mismatch in DDB state pipe %c plane %d "
+ 			  "(expected (%u,%u), found (%u,%u))\n",
+ 			  pipe_name(pipe), plane + 1,
+ 			  sw_entry->start, sw_entry->end,
+ 			  hw_entry->start, hw_entry->end);
+ 	}
+ 
+ 	/*
+ 	 * cursor
+ 	 * If the cursor plane isn't active, we may not have updated it's ddb
+ 	 * allocation. In that case since the ddb allocation will be updated
+ 	 * once the plane becomes visible, we can skip this check
+ 	 */
+ 	if (intel_crtc->cursor_addr) {
+ 		hw_entry = &hw_ddb.plane[pipe][PLANE_CURSOR];
+ 		sw_entry = &sw_ddb->plane[pipe][PLANE_CURSOR];
+ 
+ 		if (!skl_ddb_entry_equal(hw_entry, sw_entry)) {
+ 			DRM_ERROR("mismatch in DDB state pipe %c cursor "
+ 				  "(expected (%u,%u), found (%u,%u))\n",
+ 				  pipe_name(pipe),
+ 				  sw_entry->start, sw_entry->end,
+ 				  hw_entry->start, hw_entry->end);
+ 		}
++>>>>>>> 27082493e9c6 (drm/i915/skl: Update DDB values atomically with wms/plane attrs)
  	}
  }
  
@@@ -11655,819 -13919,720 +11682,1004 @@@ static int __intel_set_mode(struct drm_
  	 * mode set on this crtc.  For other crtcs we need to use the
  	 * adjusted_mode bits in the crtc directly.
  	 */
 -	if (dev_priv->display.modeset_calc_cdclk) {
 -		if (!intel_state->cdclk_pll_vco)
 -			intel_state->cdclk_pll_vco = dev_priv->cdclk_pll.vco;
 -		if (!intel_state->cdclk_pll_vco)
 -			intel_state->cdclk_pll_vco = dev_priv->skl_preferred_vco_freq;
 -
 -		ret = dev_priv->display.modeset_calc_cdclk(state);
 -		if (ret < 0)
 -			return ret;
 -
 -		if (intel_state->dev_cdclk != dev_priv->cdclk_freq ||
 -		    intel_state->cdclk_pll_vco != dev_priv->cdclk_pll.vco)
 -			ret = intel_modeset_all_pipes(state);
 -
 -		if (ret < 0)
 -			return ret;
 -
 -		DRM_DEBUG_KMS("New cdclk calculated to be atomic %u, actual %u\n",
 -			      intel_state->cdclk, intel_state->dev_cdclk);
 -	} else
 -		to_intel_atomic_state(state)->cdclk = dev_priv->atomic_cdclk_freq;
 -
 -	intel_modeset_clear_plls(state);
 -
 -	if (IS_HASWELL(dev_priv))
 -		return haswell_mode_set_planes_workaround(state);
 -
 -	return 0;
 -}
 -
 -/*
 - * Handle calculation of various watermark data at the end of the atomic check
 - * phase.  The code here should be run after the per-crtc and per-plane 'check'
 - * handlers to ensure that all derived state has been updated.
 - */
 -static int calc_watermark_data(struct drm_atomic_state *state)
 -{
 -	struct drm_device *dev = state->dev;
 -	struct drm_i915_private *dev_priv = to_i915(dev);
 -
 -	/* Is there platform-specific watermark information to calculate? */
 -	if (dev_priv->display.compute_global_watermarks)
 -		return dev_priv->display.compute_global_watermarks(state);
 -
 -	return 0;
 -}
 -
 -/**
 - * intel_atomic_check - validate state object
 - * @dev: drm device
 - * @state: state to validate
 - */
 -static int intel_atomic_check(struct drm_device *dev,
 -			      struct drm_atomic_state *state)
 -{
 -	struct drm_i915_private *dev_priv = to_i915(dev);
 -	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
 -	struct drm_crtc *crtc;
 -	struct drm_crtc_state *crtc_state;
 -	int ret, i;
 -	bool any_ms = false;
 -
 -	ret = drm_atomic_helper_check_modeset(dev, state);
 -	if (ret)
 -		return ret;
 -
 -	for_each_crtc_in_state(state, crtc, crtc_state, i) {
 -		struct intel_crtc_state *pipe_config =
 -			to_intel_crtc_state(crtc_state);
 -
 -		/* Catch I915_MODE_FLAG_INHERITED */
 -		if (crtc_state->mode.private_flags != crtc->state->mode.private_flags)
 -			crtc_state->mode_changed = true;
 -
 -		if (!needs_modeset(crtc_state))
 -			continue;
 -
 -		if (!crtc_state->enable) {
 -			any_ms = true;
 -			continue;
 -		}
 -
 -		/* FIXME: For only active_changed we shouldn't need to do any
 -		 * state recomputation at all. */
 -
 -		ret = drm_atomic_add_affected_connectors(state, crtc);
 -		if (ret)
 -			return ret;
 -
 -		ret = intel_modeset_pipe_config(crtc, pipe_config);
 -		if (ret) {
 -			intel_dump_pipe_config(to_intel_crtc(crtc),
 -					       pipe_config, "[failed]");
 -			return ret;
 -		}
 -
 -		if (i915.fastboot &&
 -		    intel_pipe_config_compare(dev,
 -					to_intel_crtc_state(crtc->state),
 -					pipe_config, true)) {
 -			crtc_state->mode_changed = false;
 -			to_intel_crtc_state(crtc_state)->update_pipe = true;
 -		}
 -
 -		if (needs_modeset(crtc_state))
 -			any_ms = true;
 -
 -		ret = drm_atomic_add_affected_planes(state, crtc);
 -		if (ret)
 -			return ret;
 -
 -		intel_dump_pipe_config(to_intel_crtc(crtc), pipe_config,
 -				       needs_modeset(crtc_state) ?
 -				       "[modeset]" : "[fastset]");
 -	}
 -
 -	if (any_ms) {
 -		ret = intel_modeset_checks(state);
 -
 -		if (ret)
 -			return ret;
 -	} else
 -		intel_state->cdclk = dev_priv->cdclk_freq;
 -
 -	ret = drm_atomic_helper_check_planes(dev, state);
 -	if (ret)
 -		return ret;
 -
 -	intel_fbc_choose_crtc(dev_priv, state);
 -	return calc_watermark_data(state);
 -}
 -
 -static int intel_atomic_prepare_commit(struct drm_device *dev,
 -				       struct drm_atomic_state *state,
 -				       bool nonblock)
 -{
 -	struct drm_i915_private *dev_priv = to_i915(dev);
 -	struct drm_plane_state *plane_state;
 -	struct drm_crtc_state *crtc_state;
 -	struct drm_plane *plane;
 -	struct drm_crtc *crtc;
 -	int i, ret;
 -
 -	for_each_crtc_in_state(state, crtc, crtc_state, i) {
 -		if (state->legacy_cursor_update)
 -			continue;
 -
 -		ret = intel_crtc_wait_for_pending_flips(crtc);
 -		if (ret)
 -			return ret;
 +	if (IS_VALLEYVIEW(dev)) {
 +		valleyview_modeset_global_pipes(dev, &prepare_pipes);
  
 -		if (atomic_read(&to_intel_crtc(crtc)->unpin_work_count) >= 2)
 -			flush_workqueue(dev_priv->wq);
 +		/* may have added more to prepare_pipes than we should */
 +		prepare_pipes &= ~disable_pipes;
  	}
  
 -	ret = mutex_lock_interruptible(&dev->struct_mutex);
 +	ret = __intel_set_mode_setup_plls(dev, modeset_pipes, disable_pipes);
  	if (ret)
 -		return ret;
 -
 -	ret = drm_atomic_helper_prepare_planes(dev, state);
 -	mutex_unlock(&dev->struct_mutex);
 -
 -	if (!ret && !nonblock) {
 -		for_each_plane_in_state(state, plane, plane_state, i) {
 -			struct intel_plane_state *intel_plane_state =
 -				to_intel_plane_state(plane_state);
 -
 -			if (!intel_plane_state->wait_req)
 -				continue;
 -
 -			ret = i915_wait_request(intel_plane_state->wait_req,
 -						true, NULL, NULL);
 -			if (ret) {
 -				/* Any hang should be swallowed by the wait */
 -				WARN_ON(ret == -EIO);
 -				mutex_lock(&dev->struct_mutex);
 -				drm_atomic_helper_cleanup_planes(dev, state);
 -				mutex_unlock(&dev->struct_mutex);
 -				break;
 -			}
 -		}
 -	}
 -
 -	return ret;
 -}
 -
 -u32 intel_crtc_get_vblank_counter(struct intel_crtc *crtc)
 -{
 -	struct drm_device *dev = crtc->base.dev;
 -
 -	if (!dev->max_vblank_count)
 -		return drm_accurate_vblank_count(&crtc->base);
 -
 -	return dev->driver->get_vblank_counter(dev, crtc->pipe);
 -}
 -
 -static void intel_atomic_wait_for_vblanks(struct drm_device *dev,
 -					  struct drm_i915_private *dev_priv,
 -					  unsigned crtc_mask)
 -{
 -	unsigned last_vblank_count[I915_MAX_PIPES];
 -	enum pipe pipe;
 -	int ret;
 -
 -	if (!crtc_mask)
 -		return;
 -
 -	for_each_pipe(dev_priv, pipe) {
 -		struct drm_crtc *crtc = dev_priv->pipe_to_crtc_mapping[pipe];
 -
 -		if (!((1 << pipe) & crtc_mask))
 -			continue;
 -
 -		ret = drm_crtc_vblank_get(crtc);
 -		if (WARN_ON(ret != 0)) {
 -			crtc_mask &= ~(1 << pipe);
 -			continue;
 -		}
 -
 -		last_vblank_count[pipe] = drm_crtc_vblank_count(crtc);
 -	}
 -
 -	for_each_pipe(dev_priv, pipe) {
 -		struct drm_crtc *crtc = dev_priv->pipe_to_crtc_mapping[pipe];
 -		long lret;
 -
 -		if (!((1 << pipe) & crtc_mask))
 -			continue;
 +		goto done;
  
 -		lret = wait_event_timeout(dev->vblank[pipe].queue,
 -				last_vblank_count[pipe] !=
 -					drm_crtc_vblank_count(crtc),
 -				msecs_to_jiffies(50));
 -
 -		WARN(!lret, "pipe %c vblank wait timed out\n", pipe_name(pipe));
 -
 -		drm_crtc_vblank_put(crtc);
 -	}
 -}
 -
 -static bool needs_vblank_wait(struct intel_crtc_state *crtc_state)
 -{
 -	/* fb updated, need to unpin old fb */
 -	if (crtc_state->fb_changed)
 -		return true;
 +	for_each_intel_crtc_masked(dev, disable_pipes, intel_crtc)
 +		intel_crtc_disable(&intel_crtc->base);
  
 -	/* wm changes, need vblank before final wm's */
 -	if (crtc_state->update_wm_post)
 -		return true;
 +	for_each_intel_crtc_masked(dev, prepare_pipes, intel_crtc) {
 +		if (intel_crtc->base.state->enable)
 +			dev_priv->display.crtc_disable(&intel_crtc->base);
 +	}
  
 -	/*
 -	 * cxsr is re-enabled after vblank.
 -	 * This is already handled by crtc_state->update_wm_post,
 -	 * but added for clarity.
 +	/* crtc->mode is already used by the ->mode_set callbacks, hence we need
 +	 * to set it here already despite that we pass it down the callchain.
 +	 *
 +	 * Note we'll need to fix this up when we start tracking multiple
 +	 * pipes; here we assume a single modeset_pipe and only track the
 +	 * single crtc and mode.
  	 */
 -	if (crtc_state->disable_cxsr)
 -		return true;
 +	if (modeset_pipes) {
 +		crtc->mode = *mode;
 +		/* mode_set/enable/disable functions rely on a correct pipe
 +		 * config. */
 +		intel_crtc_set_state(to_intel_crtc(crtc), pipe_config);
  
++<<<<<<< HEAD
 +		/*
 +		 * Calculate and store various constants which
 +		 * are later needed by vblank and swap-completion
 +		 * timestamping. They are derived from true hwmode.
 +		 */
 +		drm_calc_timestamping_constants(crtc,
 +						&pipe_config->base.adjusted_mode);
++=======
+ 	return false;
+ }
+ 
+ static void intel_update_crtc(struct drm_crtc *crtc,
+ 			      struct drm_atomic_state *state,
+ 			      struct drm_crtc_state *old_crtc_state,
+ 			      unsigned int *crtc_vblank_mask)
+ {
+ 	struct drm_device *dev = crtc->dev;
+ 	struct drm_i915_private *dev_priv = to_i915(dev);
+ 	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
+ 	struct intel_crtc_state *pipe_config = to_intel_crtc_state(crtc->state);
+ 	bool modeset = needs_modeset(crtc->state);
+ 
+ 	if (modeset) {
+ 		update_scanline_offset(intel_crtc);
+ 		dev_priv->display.crtc_enable(pipe_config, state);
+ 	} else {
+ 		intel_pre_plane_update(to_intel_crtc_state(old_crtc_state));
+ 	}
+ 
+ 	if (drm_atomic_get_existing_plane_state(state, crtc->primary)) {
+ 		intel_fbc_enable(
+ 		    intel_crtc, pipe_config,
+ 		    to_intel_plane_state(crtc->primary->state));
+ 	}
+ 
+ 	drm_atomic_helper_commit_planes_on_crtc(old_crtc_state);
+ 
+ 	if (needs_vblank_wait(pipe_config))
+ 		*crtc_vblank_mask |= drm_crtc_mask(crtc);
+ }
+ 
+ static void intel_update_crtcs(struct drm_atomic_state *state,
+ 			       unsigned int *crtc_vblank_mask)
+ {
+ 	struct drm_crtc *crtc;
+ 	struct drm_crtc_state *old_crtc_state;
+ 	int i;
+ 
+ 	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
+ 		if (!crtc->state->active)
+ 			continue;
+ 
+ 		intel_update_crtc(crtc, state, old_crtc_state,
+ 				  crtc_vblank_mask);
+ 	}
+ }
+ 
+ static void skl_update_crtcs(struct drm_atomic_state *state,
+ 			     unsigned int *crtc_vblank_mask)
+ {
+ 	struct drm_device *dev = state->dev;
+ 	struct drm_i915_private *dev_priv = to_i915(dev);
+ 	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
+ 	struct drm_crtc *crtc;
+ 	struct drm_crtc_state *old_crtc_state;
+ 	struct skl_ddb_allocation *new_ddb = &intel_state->wm_results.ddb;
+ 	struct skl_ddb_allocation *cur_ddb = &dev_priv->wm.skl_hw.ddb;
+ 	unsigned int updated = 0;
+ 	bool progress;
+ 	enum pipe pipe;
+ 
+ 	/*
+ 	 * Whenever the number of active pipes changes, we need to make sure we
+ 	 * update the pipes in the right order so that their ddb allocations
+ 	 * never overlap with eachother inbetween CRTC updates. Otherwise we'll
+ 	 * cause pipe underruns and other bad stuff.
+ 	 */
+ 	do {
+ 		int i;
+ 		progress = false;
+ 
+ 		for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
+ 			bool vbl_wait = false;
+ 			unsigned int cmask = drm_crtc_mask(crtc);
+ 			pipe = to_intel_crtc(crtc)->pipe;
+ 
+ 			if (updated & cmask || !crtc->state->active)
+ 				continue;
+ 			if (skl_ddb_allocation_overlaps(state, cur_ddb, new_ddb,
+ 							pipe))
+ 				continue;
+ 
+ 			updated |= cmask;
+ 
+ 			/*
+ 			 * If this is an already active pipe, it's DDB changed,
+ 			 * and this isn't the last pipe that needs updating
+ 			 * then we need to wait for a vblank to pass for the
+ 			 * new ddb allocation to take effect.
+ 			 */
+ 			if (!skl_ddb_allocation_equals(cur_ddb, new_ddb, pipe) &&
+ 			    !crtc->state->active_changed &&
+ 			    intel_state->wm_results.dirty_pipes != updated)
+ 				vbl_wait = true;
+ 
+ 			intel_update_crtc(crtc, state, old_crtc_state,
+ 					  crtc_vblank_mask);
+ 
+ 			if (vbl_wait)
+ 				intel_wait_for_vblank(dev, pipe);
+ 
+ 			progress = true;
+ 		}
+ 	} while (progress);
+ }
+ 
+ static void intel_atomic_commit_tail(struct drm_atomic_state *state)
+ {
+ 	struct drm_device *dev = state->dev;
+ 	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
+ 	struct drm_i915_private *dev_priv = to_i915(dev);
+ 	struct drm_crtc_state *old_crtc_state;
+ 	struct drm_crtc *crtc;
+ 	struct intel_crtc_state *intel_cstate;
+ 	struct drm_plane *plane;
+ 	struct drm_plane_state *plane_state;
+ 	bool hw_check = intel_state->modeset;
+ 	unsigned long put_domains[I915_MAX_PIPES] = {};
+ 	unsigned crtc_vblank_mask = 0;
+ 	int i, ret;
+ 
+ 	for_each_plane_in_state(state, plane, plane_state, i) {
+ 		struct intel_plane_state *intel_plane_state =
+ 			to_intel_plane_state(plane_state);
+ 
+ 		if (!intel_plane_state->wait_req)
+ 			continue;
+ 
+ 		ret = i915_wait_request(intel_plane_state->wait_req,
+ 					true, NULL, NULL);
+ 		/* EIO should be eaten, and we can't get interrupted in the
+ 		 * worker, and blocking commits have waited already. */
+ 		WARN_ON(ret);
+ 	}
+ 
+ 	drm_atomic_helper_wait_for_dependencies(state);
+ 
+ 	if (intel_state->modeset) {
+ 		memcpy(dev_priv->min_pixclk, intel_state->min_pixclk,
+ 		       sizeof(intel_state->min_pixclk));
+ 		dev_priv->active_crtcs = intel_state->active_crtcs;
+ 		dev_priv->atomic_cdclk_freq = intel_state->cdclk;
+ 
+ 		intel_display_power_get(dev_priv, POWER_DOMAIN_MODESET);
+ 	}
+ 
+ 	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
+ 		struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
+ 
+ 		if (needs_modeset(crtc->state) ||
+ 		    to_intel_crtc_state(crtc->state)->update_pipe) {
+ 			hw_check = true;
+ 
+ 			put_domains[to_intel_crtc(crtc)->pipe] =
+ 				modeset_get_crtc_power_domains(crtc,
+ 					to_intel_crtc_state(crtc->state));
+ 		}
+ 
+ 		if (!needs_modeset(crtc->state))
+ 			continue;
+ 
+ 		intel_pre_plane_update(to_intel_crtc_state(old_crtc_state));
+ 
+ 		if (old_crtc_state->active) {
+ 			intel_crtc_disable_planes(crtc, old_crtc_state->plane_mask);
+ 			dev_priv->display.crtc_disable(to_intel_crtc_state(old_crtc_state), state);
+ 			intel_crtc->active = false;
+ 			intel_fbc_disable(intel_crtc);
+ 			intel_disable_shared_dpll(intel_crtc);
+ 
+ 			/*
+ 			 * Underruns don't always raise
+ 			 * interrupts, so check manually.
+ 			 */
+ 			intel_check_cpu_fifo_underruns(dev_priv);
+ 			intel_check_pch_fifo_underruns(dev_priv);
+ 
+ 			if (!crtc->state->active)
+ 				intel_update_watermarks(crtc);
+ 		}
++>>>>>>> 27082493e9c6 (drm/i915/skl: Update DDB values atomically with wms/plane attrs)
 +	}
 +
 +	/* Only after disabling all output pipelines that will be changed can we
 +	 * update the the output configuration. */
 +	intel_modeset_update_state(dev, prepare_pipes);
 +
 +	modeset_update_crtc_power_domains(pipe_config->base.state);
 +
 +	/* Set up the DPLL and any encoders state that needs to adjust or depend
 +	 * on the DPLL.
 +	 */
 +	for_each_intel_crtc_masked(dev, modeset_pipes, intel_crtc) {
 +		struct drm_plane *primary = intel_crtc->base.primary;
 +		int vdisplay, hdisplay;
 +
 +		drm_crtc_get_hv_timing(mode, &hdisplay, &vdisplay);
 +		ret = primary->funcs->update_plane(primary, &intel_crtc->base,
 +						   fb, 0, 0,
 +						   hdisplay, vdisplay,
 +						   x << 16, y << 16,
 +						   hdisplay << 16, vdisplay << 16);
 +	}
 +
 +	/* Now enable the clocks, plane, pipe, and connectors that we set up. */
 +	for_each_intel_crtc_masked(dev, prepare_pipes, intel_crtc) {
 +		update_scanline_offset(intel_crtc);
 +
 +		dev_priv->display.crtc_enable(&intel_crtc->base);
 +	}
 +
 +	/* FIXME: add subpixel order */
 +done:
 +	if (ret && crtc->state->enable)
 +		crtc->mode = *saved_mode;
 +
 +	if (ret == 0 && pipe_config) {
 +		struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 +
 +		/* The pipe_config will be freed with the atomic state, so
 +		 * make a copy. */
 +		memcpy(crtc_state_copy, intel_crtc->config,
 +		       sizeof *crtc_state_copy);
 +		intel_crtc->config = crtc_state_copy;
 +		intel_crtc->base.state = &crtc_state_copy->base;
 +
 +		if (modeset_pipes)
 +			intel_crtc->new_config = intel_crtc->config;
 +	} else {
 +		kfree(crtc_state_copy);
 +	}
 +
 +	kfree(saved_mode);
 +	return ret;
 +}
 +
 +static int intel_set_mode_pipes(struct drm_crtc *crtc,
 +				struct drm_display_mode *mode,
 +				int x, int y, struct drm_framebuffer *fb,
 +				struct intel_crtc_state *pipe_config,
 +				unsigned modeset_pipes,
 +				unsigned prepare_pipes,
 +				unsigned disable_pipes)
 +{
 +	int ret;
 +
 +	ret = __intel_set_mode(crtc, mode, x, y, fb, pipe_config, modeset_pipes,
 +			       prepare_pipes, disable_pipes);
 +
 +	if (ret == 0)
 +		intel_modeset_check_state(crtc->dev);
 +
 +	return ret;
 +}
 +
 +static int intel_set_mode(struct drm_crtc *crtc,
 +			  struct drm_display_mode *mode,
 +			  int x, int y, struct drm_framebuffer *fb,
 +			  struct drm_atomic_state *state)
 +{
 +	struct intel_crtc_state *pipe_config;
 +	unsigned modeset_pipes, prepare_pipes, disable_pipes;
 +	int ret = 0;
 +
 +	pipe_config = intel_modeset_compute_config(crtc, mode, fb, state,
 +						   &modeset_pipes,
 +						   &prepare_pipes,
 +						   &disable_pipes);
 +
 +	if (IS_ERR(pipe_config)) {
 +		ret = PTR_ERR(pipe_config);
 +		goto out;
 +	}
 +
 +	ret = intel_set_mode_pipes(crtc, mode, x, y, fb, pipe_config,
 +				   modeset_pipes, prepare_pipes,
 +				   disable_pipes);
 +	if (ret)
 +		goto out;
 +
 +out:
 +	return ret;
 +}
 +
 +void intel_crtc_restore_mode(struct drm_crtc *crtc)
 +{
 +	struct drm_device *dev = crtc->dev;
 +	struct drm_atomic_state *state;
 +	struct intel_encoder *encoder;
 +	struct intel_connector *connector;
 +	struct drm_connector_state *connector_state;
 +
 +	state = drm_atomic_state_alloc(dev);
 +	if (!state) {
 +		DRM_DEBUG_KMS("[CRTC:%d] mode restore failed, out of memory",
 +			      crtc->base.id);
 +		return;
 +	}
 +
 +	state->acquire_ctx = dev->mode_config.acquire_ctx;
 +
 +	/* The force restore path in the HW readout code relies on the staged
 +	 * config still keeping the user requested config while the actual
 +	 * state has been overwritten by the configuration read from HW. We
 +	 * need to copy the staged config to the atomic state, otherwise the
 +	 * mode set will just reapply the state the HW is already in. */
 +	for_each_intel_encoder(dev, encoder) {
 +		if (&encoder->new_crtc->base != crtc)
 +			continue;
 +
 +		for_each_intel_connector(dev, connector) {
 +			if (connector->new_encoder != encoder)
 +				continue;
 +
 +			connector_state = drm_atomic_get_connector_state(state, &connector->base);
 +			if (IS_ERR(connector_state)) {
 +				DRM_DEBUG_KMS("Failed to add [CONNECTOR:%d:%s] to state: %ld\n",
 +					      connector->base.base.id,
 +					      connector->base.name,
 +					      PTR_ERR(connector_state));
 +				continue;
 +			}
 +
 +			connector_state->crtc = crtc;
 +			connector_state->best_encoder = &encoder->base;
 +		}
 +	}
 +
 +	intel_set_mode(crtc, &crtc->mode, crtc->x, crtc->y, crtc->primary->fb,
 +		       state);
 +
 +	drm_atomic_state_free(state);
 +}
 +
 +#undef for_each_intel_crtc_masked
 +
 +static void intel_set_config_free(struct intel_set_config *config)
 +{
 +	if (!config)
 +		return;
 +
 +	kfree(config->save_connector_encoders);
 +	kfree(config->save_encoder_crtcs);
 +	kfree(config->save_crtc_enabled);
 +	kfree(config);
 +}
 +
 +static int intel_set_config_save_state(struct drm_device *dev,
 +				       struct intel_set_config *config)
 +{
 +	struct drm_crtc *crtc;
 +	struct drm_encoder *encoder;
 +	struct drm_connector *connector;
 +	int count;
 +
 +	config->save_crtc_enabled =
 +		kcalloc(dev->mode_config.num_crtc,
 +			sizeof(bool), GFP_KERNEL);
 +	if (!config->save_crtc_enabled)
 +		return -ENOMEM;
 +
 +	config->save_encoder_crtcs =
 +		kcalloc(dev->mode_config.num_encoder,
 +			sizeof(struct drm_crtc *), GFP_KERNEL);
 +	if (!config->save_encoder_crtcs)
 +		return -ENOMEM;
 +
 +	config->save_connector_encoders =
 +		kcalloc(dev->mode_config.num_connector,
 +			sizeof(struct drm_encoder *), GFP_KERNEL);
 +	if (!config->save_connector_encoders)
 +		return -ENOMEM;
 +
 +	/* Copy data. Note that driver private data is not affected.
 +	 * Should anything bad happen only the expected state is
 +	 * restored, not the drivers personal bookkeeping.
 +	 */
 +	count = 0;
 +	for_each_crtc(dev, crtc) {
 +		config->save_crtc_enabled[count++] = crtc->state->enable;
 +	}
 +
 +	count = 0;
 +	list_for_each_entry(encoder, &dev->mode_config.encoder_list, head) {
 +		config->save_encoder_crtcs[count++] = encoder->crtc;
 +	}
 +
 +	count = 0;
 +	list_for_each_entry(connector, &dev->mode_config.connector_list, head) {
 +		config->save_connector_encoders[count++] = connector->encoder;
 +	}
 +
 +	return 0;
 +}
 +
 +static void intel_set_config_restore_state(struct drm_device *dev,
 +					   struct intel_set_config *config)
 +{
 +	struct intel_crtc *crtc;
 +	struct intel_encoder *encoder;
 +	struct intel_connector *connector;
 +	int count;
 +
 +	count = 0;
 +	for_each_intel_crtc(dev, crtc) {
 +		crtc->new_enabled = config->save_crtc_enabled[count++];
 +
 +		if (crtc->new_enabled)
 +			crtc->new_config = crtc->config;
 +		else
 +			crtc->new_config = NULL;
 +	}
 +
 +	count = 0;
 +	for_each_intel_encoder(dev, encoder) {
 +		encoder->new_crtc =
 +			to_intel_crtc(config->save_encoder_crtcs[count++]);
 +	}
 +
 +	count = 0;
 +	for_each_intel_connector(dev, connector) {
 +		connector->new_encoder =
 +			to_intel_encoder(config->save_connector_encoders[count++]);
 +	}
 +}
 +
 +static bool
 +is_crtc_connector_off(struct drm_mode_set *set)
 +{
 +	int i;
 +
 +	if (set->num_connectors == 0)
 +		return false;
 +
 +	if (WARN_ON(set->connectors == NULL))
 +		return false;
 +
 +	for (i = 0; i < set->num_connectors; i++)
 +		if (set->connectors[i]->encoder &&
 +		    set->connectors[i]->encoder->crtc == set->crtc &&
 +		    set->connectors[i]->dpms != DRM_MODE_DPMS_ON)
 +			return true;
 +
 +	return false;
 +}
 +
 +static void
 +intel_set_config_compute_mode_changes(struct drm_mode_set *set,
 +				      struct intel_set_config *config)
 +{
 +
 +	/* We should be able to check here if the fb has the same properties
 +	 * and then just flip_or_move it */
 +	if (is_crtc_connector_off(set)) {
 +		config->mode_changed = true;
 +	} else if (set->crtc->primary->fb != set->fb) {
 +		/*
 +		 * If we have no fb, we can only flip as long as the crtc is
 +		 * active, otherwise we need a full mode set.  The crtc may
 +		 * be active if we've only disabled the primary plane, or
 +		 * in fastboot situations.
 +		 */
 +		if (set->crtc->primary->fb == NULL) {
 +			struct intel_crtc *intel_crtc =
 +				to_intel_crtc(set->crtc);
 +
 +			if (intel_crtc->active) {
 +				DRM_DEBUG_KMS("crtc has no fb, will flip\n");
 +				config->fb_changed = true;
 +			} else {
 +				DRM_DEBUG_KMS("inactive crtc, full mode set\n");
 +				config->mode_changed = true;
 +			}
 +		} else if (set->fb == NULL) {
 +			config->mode_changed = true;
 +		} else if (set->fb->pixel_format !=
 +			   set->crtc->primary->fb->pixel_format) {
 +			config->mode_changed = true;
 +		} else {
 +			config->fb_changed = true;
 +		}
 +	}
 +
 +	if (set->fb && (set->x != set->crtc->x || set->y != set->crtc->y))
 +		config->fb_changed = true;
 +
 +	if (set->mode && !drm_mode_equal(set->mode, &set->crtc->mode)) {
 +		DRM_DEBUG_KMS("modes are different, full mode set\n");
 +		drm_mode_debug_printmodeline(&set->crtc->mode);
 +		drm_mode_debug_printmodeline(set->mode);
 +		config->mode_changed = true;
 +	}
 +
 +	DRM_DEBUG_KMS("computed changes for [CRTC:%d], mode_changed=%d, fb_changed=%d\n",
 +			set->crtc->base.id, config->mode_changed, config->fb_changed);
 +}
 +
 +static int
 +intel_modeset_stage_output_state(struct drm_device *dev,
 +				 struct drm_mode_set *set,
 +				 struct intel_set_config *config,
 +				 struct drm_atomic_state *state)
 +{
 +	struct intel_connector *connector;
 +	struct drm_connector_state *connector_state;
 +	struct intel_encoder *encoder;
 +	struct intel_crtc *crtc;
 +	int ro;
 +
 +	/* The upper layers ensure that we either disable a crtc or have a list
 +	 * of connectors. For paranoia, double-check this. */
 +	WARN_ON(!set->fb && (set->num_connectors != 0));
 +	WARN_ON(set->fb && (set->num_connectors == 0));
 +
 +	for_each_intel_connector(dev, connector) {
 +		/* Otherwise traverse passed in connector list and get encoders
 +		 * for them. */
 +		for (ro = 0; ro < set->num_connectors; ro++) {
 +			if (set->connectors[ro] == &connector->base) {
 +				connector->new_encoder = intel_find_encoder(connector, to_intel_crtc(set->crtc)->pipe);
 +				break;
 +			}
 +		}
 +
 +		/* If we disable the crtc, disable all its connectors. Also, if
 +		 * the connector is on the changing crtc but not on the new
 +		 * connector list, disable it. */
 +		if ((!set->fb || ro == set->num_connectors) &&
 +		    connector->base.encoder &&
 +		    connector->base.encoder->crtc == set->crtc) {
 +			connector->new_encoder = NULL;
 +
 +			DRM_DEBUG_KMS("[CONNECTOR:%d:%s] to [NOCRTC]\n",
 +				connector->base.base.id,
 +				connector->base.name);
 +		}
 +
 +
 +		if (&connector->new_encoder->base != connector->base.encoder) {
 +			DRM_DEBUG_KMS("[CONNECTOR:%d:%s] encoder changed, full mode switch\n",
 +				      connector->base.base.id,
 +				      connector->base.name);
 +			config->mode_changed = true;
 +		}
 +	}
 +	/* connector->new_encoder is now updated for all connectors. */
 +
 +	/* Update crtc of enabled connectors. */
 +	for_each_intel_connector(dev, connector) {
 +		struct drm_crtc *new_crtc;
 +
 +		if (!connector->new_encoder)
 +			continue;
 +
 +		new_crtc = connector->new_encoder->base.crtc;
 +
 +		for (ro = 0; ro < set->num_connectors; ro++) {
 +			if (set->connectors[ro] == &connector->base)
 +				new_crtc = set->crtc;
 +		}
 +
 +		/* Make sure the new CRTC will work with the encoder */
 +		if (!drm_encoder_crtc_ok(&connector->new_encoder->base,
 +					 new_crtc)) {
 +			return -EINVAL;
 +		}
 +		connector->new_encoder->new_crtc = to_intel_crtc(new_crtc);
 +
 +		connector_state =
 +			drm_atomic_get_connector_state(state, &connector->base);
 +		if (IS_ERR(connector_state))
 +			return PTR_ERR(connector_state);
 +
 +		connector_state->crtc = new_crtc;
 +		connector_state->best_encoder = &connector->new_encoder->base;
 +
 +		DRM_DEBUG_KMS("[CONNECTOR:%d:%s] to [CRTC:%d]\n",
 +			connector->base.base.id,
 +			connector->base.name,
 +			new_crtc->base.id);
 +	}
 +
 +	/* Check for any encoders that needs to be disabled. */
 +	for_each_intel_encoder(dev, encoder) {
 +		int num_connectors = 0;
 +		for_each_intel_connector(dev, connector) {
 +			if (connector->new_encoder == encoder) {
 +				WARN_ON(!connector->new_encoder->new_crtc);
 +				num_connectors++;
 +			}
 +		}
 +
 +		if (num_connectors == 0)
 +			encoder->new_crtc = NULL;
 +		else if (num_connectors > 1)
 +			return -EINVAL;
 +
 +		/* Only now check for crtc changes so we don't miss encoders
 +		 * that will be disabled. */
 +		if (&encoder->new_crtc->base != encoder->base.crtc) {
 +			DRM_DEBUG_KMS("[ENCODER:%d:%s] crtc changed, full mode switch\n",
 +				      encoder->base.base.id,
 +				      encoder->base.name);
 +			config->mode_changed = true;
 +		}
 +	}
 +	/* Now we've also updated encoder->new_crtc for all encoders. */
 +	for_each_intel_connector(dev, connector) {
 +		connector_state =
 +			drm_atomic_get_connector_state(state, &connector->base);
 +		if (IS_ERR(connector_state))
 +			return PTR_ERR(connector_state);
 +
 +		if (connector->new_encoder) {
 +			if (connector->new_encoder != connector->encoder)
 +				connector->encoder = connector->new_encoder;
 +		} else {
 +			connector_state->crtc = NULL;
 +		}
 +	}
 +	for_each_intel_crtc(dev, crtc) {
 +		crtc->new_enabled = false;
 +
 +		for_each_intel_encoder(dev, encoder) {
 +			if (encoder->new_crtc == crtc) {
 +				crtc->new_enabled = true;
 +				break;
 +			}
 +		}
 +
 +		if (crtc->new_enabled != crtc->base.state->enable) {
 +			DRM_DEBUG_KMS("[CRTC:%d] %sabled, full mode switch\n",
 +				      crtc->base.base.id,
 +				      crtc->new_enabled ? "en" : "dis");
 +			config->mode_changed = true;
 +		}
 +
 +		if (crtc->new_enabled)
 +			crtc->new_config = crtc->config;
 +		else
 +			crtc->new_config = NULL;
 +	}
 +
 +	return 0;
 +}
 +
 +static void disable_crtc_nofb(struct intel_crtc *crtc)
 +{
 +	struct drm_device *dev = crtc->base.dev;
 +	struct intel_encoder *encoder;
 +	struct intel_connector *connector;
 +
 +	DRM_DEBUG_KMS("Trying to restore without FB -> disabling pipe %c\n",
 +		      pipe_name(crtc->pipe));
 +
 +	for_each_intel_connector(dev, connector) {
 +		if (connector->new_encoder &&
 +		    connector->new_encoder->new_crtc == crtc)
 +			connector->new_encoder = NULL;
 +	}
 +
 +	for_each_intel_encoder(dev, encoder) {
 +		if (encoder->new_crtc == crtc)
 +			encoder->new_crtc = NULL;
 +	}
 +
 +	crtc->new_enabled = false;
 +	crtc->new_config = NULL;
 +}
 +
 +static int intel_crtc_set_config(struct drm_mode_set *set)
 +{
 +	struct drm_device *dev;
 +	struct drm_mode_set save_set;
 +	struct drm_atomic_state *state = NULL;
 +	struct intel_set_config *config;
 +	struct intel_crtc_state *pipe_config;
 +	unsigned modeset_pipes, prepare_pipes, disable_pipes;
 +	int ret;
 +
 +	BUG_ON(!set);
 +	BUG_ON(!set->crtc);
 +	BUG_ON(!set->crtc->helper_private);
 +
 +	/* Enforce sane interface api - has been abused by the fb helper. */
 +	BUG_ON(!set->mode && set->fb);
 +	BUG_ON(set->fb && set->num_connectors == 0);
 +
 +	if (set->fb) {
 +		DRM_DEBUG_KMS("[CRTC:%d] [FB:%d] #connectors=%d (x y) (%i %i)\n",
 +				set->crtc->base.id, set->fb->base.id,
 +				(int)set->num_connectors, set->x, set->y);
 +	} else {
 +		DRM_DEBUG_KMS("[CRTC:%d] [NOFB]\n", set->crtc->base.id);
 +	}
 +
 +	dev = set->crtc->dev;
 +
 +	ret = -ENOMEM;
 +	config = kzalloc(sizeof(*config), GFP_KERNEL);
 +	if (!config)
 +		goto out_config;
 +
 +	ret = intel_set_config_save_state(dev, config);
 +	if (ret)
 +		goto out_config;
 +
 +	save_set.crtc = set->crtc;
 +	save_set.mode = &set->crtc->mode;
 +	save_set.x = set->crtc->x;
 +	save_set.y = set->crtc->y;
 +	save_set.fb = set->crtc->primary->fb;
 +
 +	/* Compute whether we need a full modeset, only an fb base update or no
 +	 * change at all. In the future we might also check whether only the
 +	 * mode changed, e.g. for LVDS where we only change the panel fitter in
 +	 * such cases. */
 +	intel_set_config_compute_mode_changes(set, config);
 +
 +	state = drm_atomic_state_alloc(dev);
 +	if (!state) {
 +		ret = -ENOMEM;
 +		goto out_config;
  	}
  
 -	/* Only after disabling all output pipelines that will be changed can we
 -	 * update the the output configuration. */
 -	intel_modeset_update_crtc_state(state);
 +	state->acquire_ctx = dev->mode_config.acquire_ctx;
  
 -	if (intel_state->modeset) {
 -		drm_atomic_helper_update_legacy_modeset_state(state->dev, state);
 +	ret = intel_modeset_stage_output_state(dev, set, config, state);
 +	if (ret)
 +		goto fail;
  
 -		if (dev_priv->display.modeset_commit_cdclk &&
 -		    (intel_state->dev_cdclk != dev_priv->cdclk_freq ||
 -		     intel_state->cdclk_pll_vco != dev_priv->cdclk_pll.vco))
 -			dev_priv->display.modeset_commit_cdclk(state);
 +	pipe_config = intel_modeset_compute_config(set->crtc, set->mode,
 +						   set->fb, state,
 +						   &modeset_pipes,
 +						   &prepare_pipes,
 +						   &disable_pipes);
 +	if (IS_ERR(pipe_config)) {
 +		ret = PTR_ERR(pipe_config);
 +		goto fail;
 +	} else if (pipe_config) {
 +		if (pipe_config->has_audio !=
 +		    to_intel_crtc(set->crtc)->config->has_audio)
 +			config->mode_changed = true;
  
  		/*
 -		 * SKL workaround: bspec recommends we disable the SAGV when we
 -		 * have more then one pipe enabled
 +		 * Note we have an issue here with infoframes: current code
 +		 * only updates them on the full mode set path per hw
 +		 * requirements.  So here we should be checking for any
 +		 * required changes and forcing a mode set.
  		 */
 -		if (IS_SKYLAKE(dev_priv) && !skl_can_enable_sagv(state))
 -			skl_disable_sagv(dev_priv);
 -
 -		intel_modeset_verify_disabled(dev);
  	}
  
 -	/* Complete the events for pipes that have now been disabled */
 -	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
 -		bool modeset = needs_modeset(crtc->state);
 -
 -		/* Complete events for now disable pipes here. */
 -		if (modeset && !crtc->state->active && crtc->state->event) {
 -			spin_lock_irq(&dev->event_lock);
 -			drm_crtc_send_vblank_event(crtc, crtc->state->event);
 -			spin_unlock_irq(&dev->event_lock);
 +	intel_update_pipe_size(to_intel_crtc(set->crtc));
  
 -			crtc->state->event = NULL;
 -		}
 -	}
 +	if (config->mode_changed) {
 +		ret = intel_set_mode_pipes(set->crtc, set->mode,
 +					   set->x, set->y, set->fb, pipe_config,
 +					   modeset_pipes, prepare_pipes,
 +					   disable_pipes);
 +	} else if (config->fb_changed) {
 +		struct intel_crtc *intel_crtc = to_intel_crtc(set->crtc);
 +		struct drm_plane *primary = set->crtc->primary;
 +		int vdisplay, hdisplay;
  
 -	/* Now enable the clocks, plane, pipe, and connectors that we set up. */
 -	dev_priv->display.update_crtcs(state, &crtc_vblank_mask);
 -
 -	/* FIXME: We should call drm_atomic_helper_commit_hw_done() here
 -	 * already, but still need the state for the delayed optimization. To
 -	 * fix this:
 -	 * - wrap the optimization/post_plane_update stuff into a per-crtc work.
 -	 * - schedule that vblank worker _before_ calling hw_done
 -	 * - at the start of commit_tail, cancel it _synchrously
 -	 * - switch over to the vblank wait helper in the core after that since
 -	 *   we don't need out special handling any more.
 -	 */
 -	if (!state->legacy_cursor_update)
 -		intel_atomic_wait_for_vblanks(dev, dev_priv, crtc_vblank_mask);
 +		drm_crtc_get_hv_timing(set->mode, &hdisplay, &vdisplay);
 +		ret = primary->funcs->update_plane(primary, set->crtc, set->fb,
 +						   0, 0, hdisplay, vdisplay,
 +						   set->x << 16, set->y << 16,
 +						   hdisplay << 16, vdisplay << 16);
  
 -	/*
 -	 * Now that the vblank has passed, we can go ahead and program the
 -	 * optimal watermarks on platforms that need two-step watermark
 -	 * programming.
 -	 *
 -	 * TODO: Move this (and other cleanup) to an async worker eventually.
 -	 */
 -	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
 -		intel_cstate = to_intel_crtc_state(crtc->state);
 +		/*
 +		 * We need to make sure the primary plane is re-enabled if it
 +		 * has previously been turned off.
 +		 */
 +		if (!intel_crtc->primary_enabled && ret == 0) {
 +			WARN_ON(!intel_crtc->active);
 +			intel_enable_primary_hw_plane(set->crtc->primary, set->crtc);
 +		}
  
 -		if (dev_priv->display.optimize_watermarks)
 -			dev_priv->display.optimize_watermarks(intel_cstate);
 +		/*
 +		 * In the fastboot case this may be our only check of the
 +		 * state after boot.  It would be better to only do it on
 +		 * the first update, but we don't have a nice way of doing that
 +		 * (and really, set_config isn't used much for high freq page
 +		 * flipping, so increasing its cost here shouldn't be a big
 +		 * deal).
 +		 */
 +		if (i915.fastboot && ret == 0)
 +			intel_modeset_check_state(set->crtc->dev);
  	}
  
 -	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
 -		intel_post_plane_update(to_intel_crtc_state(old_crtc_state));
 +	if (ret) {
 +		DRM_DEBUG_KMS("failed to set mode on [CRTC:%d], err = %d\n",
 +			      set->crtc->base.id, ret);
 +fail:
 +		intel_set_config_restore_state(dev, config);
 +
 +		drm_atomic_state_clear(state);
  
 -		if (put_domains[i])
 -			modeset_put_power_domains(dev_priv, put_domains[i]);
 +		/*
 +		 * HACK: if the pipe was on, but we didn't have a framebuffer,
 +		 * force the pipe off to avoid oopsing in the modeset code
 +		 * due to fb==NULL. This should only happen during boot since
 +		 * we don't yet reconstruct the FB from the hardware state.
 +		 */
 +		if (to_intel_crtc(save_set.crtc)->new_enabled && !save_set.fb)
 +			disable_crtc_nofb(to_intel_crtc(save_set.crtc));
  
 -		intel_modeset_verify_crtc(crtc, old_crtc_state, crtc->state);
 +		/* Try to restore the config */
 +		if (config->mode_changed &&
 +		    intel_set_mode(save_set.crtc, save_set.mode,
 +				   save_set.x, save_set.y, save_set.fb,
 +				   state))
 +			DRM_ERROR("failed to restore config after modeset failure\n");
  	}
  
 -	if (IS_SKYLAKE(dev_priv) && intel_state->modeset &&
 -	    skl_can_enable_sagv(state))
 -		skl_enable_sagv(dev_priv);
 +out_config:
 +	if (state)
 +		drm_atomic_state_free(state);
  
 -	drm_atomic_helper_commit_hw_done(state);
 +	intel_set_config_free(config);
 +	return ret;
 +}
  
 -	if (intel_state->modeset)
 -		intel_display_power_put(dev_priv, POWER_DOMAIN_MODESET);
 +static const struct drm_crtc_funcs intel_crtc_funcs = {
 +	.gamma_set = intel_crtc_gamma_set,
 +	.set_config = intel_crtc_set_config,
 +	.destroy = intel_crtc_destroy,
 +	.page_flip = intel_crtc_page_flip,
 +	.atomic_duplicate_state = intel_crtc_duplicate_state,
 +	.atomic_destroy_state = intel_crtc_destroy_state,
 +};
  
 -	mutex_lock(&dev->struct_mutex);
 -	drm_atomic_helper_cleanup_planes(dev, state);
 -	mutex_unlock(&dev->struct_mutex);
 +static bool ibx_pch_dpll_get_hw_state(struct drm_i915_private *dev_priv,
 +				      struct intel_shared_dpll *pll,
 +				      struct intel_dpll_hw_state *hw_state)
 +{
 +	uint32_t val;
  
 -	drm_atomic_helper_commit_cleanup_done(state);
 +	if (!intel_display_power_is_enabled(dev_priv, POWER_DOMAIN_PLLS))
 +		return false;
  
 -	drm_atomic_state_free(state);
 +	val = I915_READ(PCH_DPLL(pll->id));
 +	hw_state->dpll = val;
 +	hw_state->fp0 = I915_READ(PCH_FP0(pll->id));
 +	hw_state->fp1 = I915_READ(PCH_FP1(pll->id));
  
 -	/* As one of the primary mmio accessors, KMS has a high likelihood
 -	 * of triggering bugs in unclaimed access. After we finish
 -	 * modesetting, see if an error has been flagged, and if so
 -	 * enable debugging for the next modeset - and hope we catch
 -	 * the culprit.
 -	 *
 -	 * XXX note that we assume display power is on at this point.
 -	 * This might hold true now but we need to add pm helper to check
 -	 * unclaimed only when the hardware is on, as atomic commits
 -	 * can happen also when the device is completely off.
 -	 */
 -	intel_uncore_arm_unclaimed_mmio_detection(dev_priv);
 +	return val & DPLL_VCO_ENABLE;
  }
  
 -static void intel_atomic_commit_work(struct work_struct *work)
 +static void ibx_pch_dpll_mode_set(struct drm_i915_private *dev_priv,
 +				  struct intel_shared_dpll *pll)
  {
 -	struct drm_atomic_state *state = container_of(work,
 -						      struct drm_atomic_state,
 -						      commit_work);
 -	intel_atomic_commit_tail(state);
 +	I915_WRITE(PCH_FP0(pll->id), pll->config.hw_state.fp0);
 +	I915_WRITE(PCH_FP1(pll->id), pll->config.hw_state.fp1);
  }
  
 -static void intel_atomic_track_fbs(struct drm_atomic_state *state)
 +static void ibx_pch_dpll_enable(struct drm_i915_private *dev_priv,
 +				struct intel_shared_dpll *pll)
  {
 -	struct drm_plane_state *old_plane_state;
 -	struct drm_plane *plane;
 -	int i;
 +	/* PCH refclock must be enabled first */
 +	ibx_assert_pch_refclk_enabled(dev_priv);
 +
 +	I915_WRITE(PCH_DPLL(pll->id), pll->config.hw_state.dpll);
  
 -	for_each_plane_in_state(state, plane, old_plane_state, i)
 -		i915_gem_track_fb(intel_fb_obj(old_plane_state->fb),
 -				  intel_fb_obj(plane->state->fb),
 -				  to_intel_plane(plane)->frontbuffer_bit);
 +	/* Wait for the clocks to stabilize. */
 +	POSTING_READ(PCH_DPLL(pll->id));
 +	udelay(150);
 +
 +	/* The pixel multiplier can only be updated once the
 +	 * DPLL is enabled and the clocks are stable.
 +	 *
 +	 * So write it again.
 +	 */
 +	I915_WRITE(PCH_DPLL(pll->id), pll->config.hw_state.dpll);
 +	POSTING_READ(PCH_DPLL(pll->id));
 +	udelay(200);
  }
  
 -/**
 - * intel_atomic_commit - commit validated state object
 - * @dev: DRM device
 - * @state: the top-level driver state object
 - * @nonblock: nonblocking commit
 - *
 - * This function commits a top-level state object that has been validated
 - * with drm_atomic_helper_check().
 - *
 - * FIXME:  Atomic modeset support for i915 is not yet complete.  At the moment
 - * nonblocking commits are only safe for pure plane updates. Everything else
 - * should work though.
 - *
 - * RETURNS
 - * Zero for success or -errno.
 - */
 -static int intel_atomic_commit(struct drm_device *dev,
 -			       struct drm_atomic_state *state,
 -			       bool nonblock)
 +static void ibx_pch_dpll_disable(struct drm_i915_private *dev_priv,
 +				 struct intel_shared_dpll *pll)
  {
 -	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
 -	struct drm_i915_private *dev_priv = to_i915(dev);
 -	int ret = 0;
 +	struct drm_device *dev = dev_priv->dev;
 +	struct intel_crtc *crtc;
  
 -	if (intel_state->modeset && nonblock) {
 -		DRM_DEBUG_KMS("nonblocking commit for modeset not yet implemented.\n");
 -		return -EINVAL;
 +	/* Make sure no transcoder isn't still depending on us. */
 +	for_each_intel_crtc(dev, crtc) {
 +		if (intel_crtc_to_shared_dpll(crtc) == pll)
 +			assert_pch_transcoder_disabled(dev_priv, crtc->pipe);
  	}
  
 -	ret = drm_atomic_helper_setup_commit(state, nonblock);
 -	if (ret)
 -		return ret;
 -
 -	INIT_WORK(&state->commit_work, intel_atomic_commit_work);
 +	I915_WRITE(PCH_DPLL(pll->id), 0);
 +	POSTING_READ(PCH_DPLL(pll->id));
 +	udelay(200);
 +}
  
 -	ret = intel_atomic_prepare_commit(dev, state, nonblock);
 -	if (ret) {
 -		DRM_DEBUG_ATOMIC("Preparing state failed with %i\n", ret);
 -		return ret;
 -	}
 +static char *ibx_pch_dpll_names[] = {
 +	"PCH DPLL A",
 +	"PCH DPLL B",
 +};
  
 -	drm_atomic_helper_swap_state(state, true);
 -	dev_priv->wm.distrust_bios_wm = false;
 -	dev_priv->wm.skl_results = intel_state->wm_results;
 -	intel_shared_dpll_commit(state);
 -	intel_atomic_track_fbs(state);
 +static void ibx_pch_dpll_init(struct drm_device *dev)
 +{
 +	struct drm_i915_private *dev_priv = dev->dev_private;
 +	int i;
  
 -	if (nonblock)
 -		queue_work(system_unbound_wq, &state->commit_work);
 -	else
 -		intel_atomic_commit_tail(state);
 +	dev_priv->num_shared_dpll = 2;
  
 -	return 0;
 +	for (i = 0; i < dev_priv->num_shared_dpll; i++) {
 +		dev_priv->shared_dplls[i].id = i;
 +		dev_priv->shared_dplls[i].name = ibx_pch_dpll_names[i];
 +		dev_priv->shared_dplls[i].mode_set = ibx_pch_dpll_mode_set;
 +		dev_priv->shared_dplls[i].enable = ibx_pch_dpll_enable;
 +		dev_priv->shared_dplls[i].disable = ibx_pch_dpll_disable;
 +		dev_priv->shared_dplls[i].get_hw_state =
 +			ibx_pch_dpll_get_hw_state;
 +	}
  }
  
 -void intel_crtc_restore_mode(struct drm_crtc *crtc)
 +static void intel_shared_dpll_init(struct drm_device *dev)
  {
 -	struct drm_device *dev = crtc->dev;
 -	struct drm_atomic_state *state;
 -	struct drm_crtc_state *crtc_state;
 -	int ret;
 -
 -	state = drm_atomic_state_alloc(dev);
 -	if (!state) {
 -		DRM_DEBUG_KMS("[CRTC:%d:%s] crtc restore failed, out of memory",
 -			      crtc->base.id, crtc->name);
 -		return;
 -	}
 -
 -	state->acquire_ctx = drm_modeset_legacy_acquire_ctx(crtc);
 -
 -retry:
 -	crtc_state = drm_atomic_get_crtc_state(state, crtc);
 -	ret = PTR_ERR_OR_ZERO(crtc_state);
 -	if (!ret) {
 -		if (!crtc_state->active)
 -			goto out;
 +	struct drm_i915_private *dev_priv = dev->dev_private;
  
 -		crtc_state->mode_changed = true;
 -		ret = drm_atomic_commit(state);
 -	}
 -
 -	if (ret == -EDEADLK) {
 -		drm_atomic_state_clear(state);
 -		drm_modeset_backoff(state->acquire_ctx);
 -		goto retry;
 -	}
 +	if (HAS_DDI(dev))
 +		intel_ddi_pll_init(dev);
 +	else if (HAS_PCH_IBX(dev) || HAS_PCH_CPT(dev))
 +		ibx_pch_dpll_init(dev);
 +	else
 +		dev_priv->num_shared_dpll = 0;
  
 -	if (ret)
 -out:
 -		drm_atomic_state_free(state);
 +	BUG_ON(dev_priv->num_shared_dpll > I915_NUM_PLLS);
  }
  
 -#undef for_each_intel_crtc_masked
 -
 -/*
 - * FIXME: Remove this once i915 is fully DRIVER_ATOMIC by calling
 - *        drm_atomic_helper_legacy_gamma_set() directly.
 +/**
 + * intel_wm_need_update - Check whether watermarks need updating
 + * @plane: drm plane
 + * @state: new plane state
 + *
 + * Check current plane state versus the new one to determine whether
 + * watermarks need to be recalculated.
 + *
 + * Returns true or false.
   */
 -static int intel_atomic_legacy_gamma_set(struct drm_crtc *crtc,
 -					 u16 *red, u16 *green, u16 *blue,
 -					 uint32_t size)
 +bool intel_wm_need_update(struct drm_plane *plane,
 +			  struct drm_plane_state *state)
  {
 -	struct drm_device *dev = crtc->dev;
 -	struct drm_mode_config *config = &dev->mode_config;
 -	struct drm_crtc_state *state;
 -	int ret;
 -
 -	ret = drm_atomic_helper_legacy_gamma_set(crtc, red, green, blue, size);
 -	if (ret)
 -		return ret;
 -
 -	/*
 -	 * Make sure we update the legacy properties so this works when
 -	 * atomic is not enabled.
 -	 */
 -
 -	state = crtc->state;
 -
 -	drm_object_property_set_value(&crtc->base,
 -				      config->degamma_lut_property,
 -				      (state->degamma_lut) ?
 -				      state->degamma_lut->base.id : 0);
 -
 -	drm_object_property_set_value(&crtc->base,
 -				      config->ctm_property,
 -				      (state->ctm) ?
 -				      state->ctm->base.id : 0);
 -
 -	drm_object_property_set_value(&crtc->base,
 -				      config->gamma_lut_property,
 -				      (state->gamma_lut) ?
 -				      state->gamma_lut->base.id : 0);
 +	/* Update watermarks on tiling changes. */
 +	if (!plane->state->fb || !state->fb ||
 +	    plane->state->fb->modifier[0] != state->fb->modifier[0] ||
 +	    plane->state->rotation != state->rotation)
 +		return true;
  
 -	return 0;
 +	return false;
  }
  
 -static const struct drm_crtc_funcs intel_crtc_funcs = {
 -	.gamma_set = intel_atomic_legacy_gamma_set,
 -	.set_config = drm_atomic_helper_set_config,
 -	.set_property = drm_atomic_helper_crtc_set_property,
 -	.destroy = intel_crtc_destroy,
 -	.page_flip = intel_crtc_page_flip,
 -	.atomic_duplicate_state = intel_crtc_duplicate_state,
 -	.atomic_destroy_state = intel_crtc_destroy_state,
 -};
 -
  /**
   * intel_prepare_plane_fb - Prepare fb for usage on plane
   * @plane: drm plane to prepare for
@@@ -13597,58 -15918,100 +13809,89 @@@ static void intel_init_display(struct d
  	}
  
  	/* Returns the core display clock speed */
 -	if (IS_SKYLAKE(dev_priv) || IS_KABYLAKE(dev_priv))
 +	if (IS_SKYLAKE(dev))
  		dev_priv->display.get_display_clock_speed =
  			skylake_get_display_clock_speed;
 -	else if (IS_BROXTON(dev_priv))
 -		dev_priv->display.get_display_clock_speed =
 -			broxton_get_display_clock_speed;
 -	else if (IS_BROADWELL(dev_priv))
 +	else if (IS_BROADWELL(dev))
  		dev_priv->display.get_display_clock_speed =
  			broadwell_get_display_clock_speed;
 -	else if (IS_HASWELL(dev_priv))
 +	else if (IS_HASWELL(dev))
  		dev_priv->display.get_display_clock_speed =
  			haswell_get_display_clock_speed;
 -	else if (IS_VALLEYVIEW(dev_priv) || IS_CHERRYVIEW(dev_priv))
 +	else if (IS_VALLEYVIEW(dev))
  		dev_priv->display.get_display_clock_speed =
  			valleyview_get_display_clock_speed;
 -	else if (IS_GEN5(dev_priv))
 -		dev_priv->display.get_display_clock_speed =
 -			ilk_get_display_clock_speed;
 -	else if (IS_I945G(dev_priv) || IS_BROADWATER(dev_priv) ||
 -		 IS_GEN6(dev_priv) || IS_IVYBRIDGE(dev_priv))
 +	else if (IS_I945G(dev) || (IS_G33(dev) && !IS_PINEVIEW_M(dev)))
  		dev_priv->display.get_display_clock_speed =
  			i945_get_display_clock_speed;
 -	else if (IS_GM45(dev_priv))
 -		dev_priv->display.get_display_clock_speed =
 -			gm45_get_display_clock_speed;
 -	else if (IS_CRESTLINE(dev_priv))
 -		dev_priv->display.get_display_clock_speed =
 -			i965gm_get_display_clock_speed;
 -	else if (IS_PINEVIEW(dev_priv))
 -		dev_priv->display.get_display_clock_speed =
 -			pnv_get_display_clock_speed;
 -	else if (IS_G33(dev_priv) || IS_G4X(dev_priv))
 -		dev_priv->display.get_display_clock_speed =
 -			g33_get_display_clock_speed;
 -	else if (IS_I915G(dev_priv))
 +	else if (IS_I915G(dev))
  		dev_priv->display.get_display_clock_speed =
  			i915_get_display_clock_speed;
 -	else if (IS_I945GM(dev_priv) || IS_845G(dev_priv))
 +	else if (IS_I945GM(dev) || IS_845G(dev))
  		dev_priv->display.get_display_clock_speed =
  			i9xx_misc_get_display_clock_speed;
 -	else if (IS_I915GM(dev_priv))
 +	else if (IS_PINEVIEW(dev))
 +		dev_priv->display.get_display_clock_speed =
 +			pnv_get_display_clock_speed;
 +	else if (IS_I915GM(dev))
  		dev_priv->display.get_display_clock_speed =
  			i915gm_get_display_clock_speed;
 -	else if (IS_I865G(dev_priv))
 +	else if (IS_I865G(dev))
  		dev_priv->display.get_display_clock_speed =
  			i865_get_display_clock_speed;
 -	else if (IS_I85X(dev_priv))
 +	else if (IS_I85X(dev))
  		dev_priv->display.get_display_clock_speed =
 -			i85x_get_display_clock_speed;
 -	else { /* 830 */
 -		WARN(!IS_I830(dev_priv), "Unknown platform. Assuming 133 MHz CDCLK\n");
 +			i855_get_display_clock_speed;
 +	else /* 852, 830 */
  		dev_priv->display.get_display_clock_speed =
  			i830_get_display_clock_speed;
 -	}
  
 -	if (IS_GEN5(dev_priv)) {
 +	if (IS_GEN5(dev)) {
  		dev_priv->display.fdi_link_train = ironlake_fdi_link_train;
 -	} else if (IS_GEN6(dev_priv)) {
 +	} else if (IS_GEN6(dev)) {
  		dev_priv->display.fdi_link_train = gen6_fdi_link_train;
 -	} else if (IS_IVYBRIDGE(dev_priv)) {
 +	} else if (IS_IVYBRIDGE(dev)) {
  		/* FIXME: detect B0+ stepping and use auto training */
  		dev_priv->display.fdi_link_train = ivb_manual_fdi_link_train;
 -	} else if (IS_HASWELL(dev_priv) || IS_BROADWELL(dev_priv)) {
 +	} else if (IS_HASWELL(dev) || IS_BROADWELL(dev)) {
  		dev_priv->display.fdi_link_train = hsw_fdi_link_train;
 +	} else if (IS_VALLEYVIEW(dev)) {
 +		dev_priv->display.modeset_global_resources =
 +			valleyview_modeset_global_resources;
  	}
  
++<<<<<<< HEAD
 +	switch (INTEL_INFO(dev)->gen) {
++=======
+ 	if (IS_BROADWELL(dev_priv)) {
+ 		dev_priv->display.modeset_commit_cdclk =
+ 			broadwell_modeset_commit_cdclk;
+ 		dev_priv->display.modeset_calc_cdclk =
+ 			broadwell_modeset_calc_cdclk;
+ 	} else if (IS_VALLEYVIEW(dev_priv) || IS_CHERRYVIEW(dev_priv)) {
+ 		dev_priv->display.modeset_commit_cdclk =
+ 			valleyview_modeset_commit_cdclk;
+ 		dev_priv->display.modeset_calc_cdclk =
+ 			valleyview_modeset_calc_cdclk;
+ 	} else if (IS_BROXTON(dev_priv)) {
+ 		dev_priv->display.modeset_commit_cdclk =
+ 			bxt_modeset_commit_cdclk;
+ 		dev_priv->display.modeset_calc_cdclk =
+ 			bxt_modeset_calc_cdclk;
+ 	} else if (IS_SKYLAKE(dev_priv) || IS_KABYLAKE(dev_priv)) {
+ 		dev_priv->display.modeset_commit_cdclk =
+ 			skl_modeset_commit_cdclk;
+ 		dev_priv->display.modeset_calc_cdclk =
+ 			skl_modeset_calc_cdclk;
+ 	}
+ 
+ 	if (dev_priv->info.gen >= 9)
+ 		dev_priv->display.update_crtcs = skl_update_crtcs;
+ 	else
+ 		dev_priv->display.update_crtcs = intel_update_crtcs;
+ 
+ 	switch (INTEL_INFO(dev_priv)->gen) {
++>>>>>>> 27082493e9c6 (drm/i915/skl: Update DDB values atomically with wms/plane attrs)
  	case 2:
  		dev_priv->display.queue_flip = intel_gen2_queue_flip;
  		break;
diff --cc drivers/gpu/drm/i915/intel_drv.h
index 640e923ced09,debbc1b5b0f9..000000000000
--- a/drivers/gpu/drm/i915/intel_drv.h
+++ b/drivers/gpu/drm/i915/intel_drv.h
@@@ -1268,10 -1742,32 +1268,35 @@@ void ilk_wm_get_hw_state(struct drm_dev
  void skl_wm_get_hw_state(struct drm_device *dev);
  void skl_ddb_get_hw_state(struct drm_i915_private *dev_priv,
  			  struct skl_ddb_allocation *ddb /* out */);
- 
++<<<<<<< HEAD
++
++=======
+ bool skl_can_enable_sagv(struct drm_atomic_state *state);
+ int skl_enable_sagv(struct drm_i915_private *dev_priv);
+ int skl_disable_sagv(struct drm_i915_private *dev_priv);
+ bool skl_ddb_allocation_equals(const struct skl_ddb_allocation *old,
+ 			       const struct skl_ddb_allocation *new,
+ 			       enum pipe pipe);
+ bool skl_ddb_allocation_overlaps(struct drm_atomic_state *state,
+ 				 const struct skl_ddb_allocation *old,
+ 				 const struct skl_ddb_allocation *new,
+ 				 enum pipe pipe);
+ void skl_write_cursor_wm(struct intel_crtc *intel_crtc,
+ 			 const struct skl_wm_values *wm);
+ void skl_write_plane_wm(struct intel_crtc *intel_crtc,
+ 			const struct skl_wm_values *wm,
+ 			int plane);
+ uint32_t ilk_pipe_pixel_rate(const struct intel_crtc_state *pipe_config);
+ bool ilk_disable_lp_wm(struct drm_device *dev);
+ int sanitize_rc6_option(struct drm_i915_private *dev_priv, int enable_rc6);
+ static inline int intel_enable_rc6(void)
+ {
+ 	return i915.enable_rc6;
+ }
++>>>>>>> 27082493e9c6 (drm/i915/skl: Update DDB values atomically with wms/plane attrs)
  
  /* intel_sdvo.c */
 -bool intel_sdvo_init(struct drm_device *dev,
 -		     i915_reg_t reg, enum port port);
 +bool intel_sdvo_init(struct drm_device *dev, uint32_t sdvo_reg, bool is_sdvob);
  
  
  /* intel_sprite.c */
diff --cc drivers/gpu/drm/i915/intel_pm.c
index 29a433e4d2d1,729d952174d8..000000000000
--- a/drivers/gpu/drm/i915/intel_pm.c
+++ b/drivers/gpu/drm/i915/intel_pm.c
@@@ -3081,321 -3836,338 +3081,320 @@@ static void skl_ddb_entry_write(struct 
  		I915_WRITE(reg, 0);
  }
  
++<<<<<<< HEAD
 +static void skl_write_wm_values(struct drm_i915_private *dev_priv,
 +				const struct skl_wm_values *new)
 +{
 +	struct drm_device *dev = dev_priv->dev;
 +	struct intel_crtc *crtc;
 +
 +	list_for_each_entry(crtc, &dev->mode_config.crtc_list, base.head) {
 +		int i, level, max_level = ilk_wm_max_level(dev);
 +		enum pipe pipe = crtc->pipe;
 +
 +		if (!new->dirty[pipe])
 +			continue;
 +
 +		I915_WRITE(PIPE_WM_LINETIME(pipe), new->wm_linetime[pipe]);
 +
 +		for (level = 0; level <= max_level; level++) {
 +			for (i = 0; i < intel_num_planes(crtc); i++)
 +				I915_WRITE(PLANE_WM(pipe, i, level),
 +					   new->plane[pipe][i][level]);
 +			I915_WRITE(CUR_WM(pipe, level),
 +				   new->cursor[pipe][level]);
 +		}
 +		for (i = 0; i < intel_num_planes(crtc); i++)
 +			I915_WRITE(PLANE_WM_TRANS(pipe, i),
 +				   new->plane_trans[pipe][i]);
 +		I915_WRITE(CUR_WM_TRANS(pipe), new->cursor_trans[pipe]);
 +
 +		for (i = 0; i < intel_num_planes(crtc); i++)
 +			skl_ddb_entry_write(dev_priv,
 +					    PLANE_BUF_CFG(pipe, i),
 +					    &new->ddb.plane[pipe][i]);
 +
 +		skl_ddb_entry_write(dev_priv, CUR_BUF_CFG(pipe),
 +				    &new->ddb.cursor[pipe]);
 +	}
- }
++=======
+ void skl_write_plane_wm(struct intel_crtc *intel_crtc,
+ 			const struct skl_wm_values *wm,
+ 			int plane)
+ {
+ 	struct drm_crtc *crtc = &intel_crtc->base;
+ 	struct drm_device *dev = crtc->dev;
+ 	struct drm_i915_private *dev_priv = to_i915(dev);
+ 	int level, max_level = ilk_wm_max_level(dev);
+ 	enum pipe pipe = intel_crtc->pipe;
  
- /*
-  * When setting up a new DDB allocation arrangement, we need to correctly
-  * sequence the times at which the new allocations for the pipes are taken into
-  * account or we'll have pipes fetching from space previously allocated to
-  * another pipe.
-  *
-  * Roughly the sequence looks like:
-  *  1. re-allocate the pipe(s) with the allocation being reduced and not
-  *     overlapping with a previous light-up pipe (another way to put it is:
-  *     pipes with their new allocation strickly included into their old ones).
-  *  2. re-allocate the other pipes that get their allocation reduced
-  *  3. allocate the pipes having their allocation increased
-  *
-  * Steps 1. and 2. are here to take care of the following case:
-  * - Initially DDB looks like this:
-  *     |   B    |   C    |
-  * - enable pipe A.
-  * - pipe B has a reduced DDB allocation that overlaps with the old pipe C
-  *   allocation
-  *     |  A  |  B  |  C  |
-  *
-  * We need to sequence the re-allocation: C, B, A (and not B, C, A).
-  */
+ 	for (level = 0; level <= max_level; level++) {
+ 		I915_WRITE(PLANE_WM(pipe, plane, level),
+ 			   wm->plane[pipe][plane][level]);
+ 	}
+ 	I915_WRITE(PLANE_WM_TRANS(pipe, plane), wm->plane_trans[pipe][plane]);
  
- static void
- skl_wm_flush_pipe(struct drm_i915_private *dev_priv, enum pipe pipe, int pass)
- {
- 	int plane;
+ 	skl_ddb_entry_write(dev_priv, PLANE_BUF_CFG(pipe, plane),
+ 			    &wm->ddb.plane[pipe][plane]);
+ 	skl_ddb_entry_write(dev_priv, PLANE_NV12_BUF_CFG(pipe, plane),
+ 			    &wm->ddb.y_plane[pipe][plane]);
+ }
  
- 	DRM_DEBUG_KMS("flush pipe %c (pass %d)\n", pipe_name(pipe), pass);
+ void skl_write_cursor_wm(struct intel_crtc *intel_crtc,
+ 			 const struct skl_wm_values *wm)
+ {
+ 	struct drm_crtc *crtc = &intel_crtc->base;
+ 	struct drm_device *dev = crtc->dev;
+ 	struct drm_i915_private *dev_priv = to_i915(dev);
+ 	int level, max_level = ilk_wm_max_level(dev);
+ 	enum pipe pipe = intel_crtc->pipe;
  
- 	for_each_plane(dev_priv, pipe, plane) {
- 		I915_WRITE(PLANE_SURF(pipe, plane),
- 			   I915_READ(PLANE_SURF(pipe, plane)));
+ 	for (level = 0; level <= max_level; level++) {
+ 		I915_WRITE(CUR_WM(pipe, level),
+ 			   wm->plane[pipe][PLANE_CURSOR][level]);
  	}
- 	I915_WRITE(CURBASE(pipe), I915_READ(CURBASE(pipe)));
+ 	I915_WRITE(CUR_WM_TRANS(pipe), wm->plane_trans[pipe][PLANE_CURSOR]);
+ 
+ 	skl_ddb_entry_write(dev_priv, CUR_BUF_CFG(pipe),
+ 			    &wm->ddb.plane[pipe][PLANE_CURSOR]);
+ }
+ 
+ bool skl_ddb_allocation_equals(const struct skl_ddb_allocation *old,
+ 			       const struct skl_ddb_allocation *new,
+ 			       enum pipe pipe)
+ {
+ 	return new->pipe[pipe].start == old->pipe[pipe].start &&
+ 	       new->pipe[pipe].end == old->pipe[pipe].end;
++>>>>>>> 27082493e9c6 (drm/i915/skl: Update DDB values atomically with wms/plane attrs)
  }
  
- static bool
- skl_ddb_allocation_included(const struct skl_ddb_allocation *old,
- 			    const struct skl_ddb_allocation *new,
- 			    enum pipe pipe)
+ static inline bool skl_ddb_entries_overlap(const struct skl_ddb_entry *a,
+ 					   const struct skl_ddb_entry *b)
  {
- 	uint16_t old_size, new_size;
+ 	return a->start < b->end && b->start < a->end;
+ }
  
- 	old_size = skl_ddb_entry_size(&old->pipe[pipe]);
- 	new_size = skl_ddb_entry_size(&new->pipe[pipe]);
+ bool skl_ddb_allocation_overlaps(struct drm_atomic_state *state,
+ 				 const struct skl_ddb_allocation *old,
+ 				 const struct skl_ddb_allocation *new,
+ 				 enum pipe pipe)
+ {
+ 	struct drm_device *dev = state->dev;
+ 	struct intel_crtc *intel_crtc;
+ 	enum pipe otherp;
  
+ 	for_each_intel_crtc(dev, intel_crtc) {
+ 		otherp = intel_crtc->pipe;
+ 
++<<<<<<< HEAD
 +	return old_size != new_size &&
 +	       new->pipe[pipe].start >= old->pipe[pipe].start &&
 +	       new->pipe[pipe].end <= old->pipe[pipe].end;
 +}
 +
 +static void skl_flush_wm_values(struct drm_i915_private *dev_priv,
 +				struct skl_wm_values *new_values)
 +{
 +	struct drm_device *dev = dev_priv->dev;
 +	struct skl_ddb_allocation *cur_ddb, *new_ddb;
 +	bool reallocated[I915_MAX_PIPES] = {false, false, false};
 +	struct intel_crtc *crtc;
 +	enum pipe pipe;
 +
 +	new_ddb = &new_values->ddb;
 +	cur_ddb = &dev_priv->wm.skl_hw.ddb;
 +
 +	/*
 +	 * First pass: flush the pipes with the new allocation contained into
 +	 * the old space.
 +	 *
 +	 * We'll wait for the vblank on those pipes to ensure we can safely
 +	 * re-allocate the freed space without this pipe fetching from it.
 +	 */
 +	for_each_intel_crtc(dev, crtc) {
 +		if (!crtc->active)
++=======
+ 		if (otherp == pipe)
++>>>>>>> 27082493e9c6 (drm/i915/skl: Update DDB values atomically with wms/plane attrs)
  			continue;
  
- 		pipe = crtc->pipe;
- 
- 		if (!skl_ddb_allocation_included(cur_ddb, new_ddb, pipe))
- 			continue;
- 
- 		skl_wm_flush_pipe(dev_priv, pipe, 1);
- 		intel_wait_for_vblank(dev, pipe);
- 
- 		reallocated[pipe] = true;
- 	}
- 
- 
- 	/*
- 	 * Second pass: flush the pipes that are having their allocation
- 	 * reduced, but overlapping with a previous allocation.
- 	 *
- 	 * Here as well we need to wait for the vblank to make sure the freed
- 	 * space is not used anymore.
- 	 */
- 	for_each_intel_crtc(dev, crtc) {
- 		if (!crtc->active)
- 			continue;
- 
- 		pipe = crtc->pipe;
- 
- 		if (reallocated[pipe])
- 			continue;
- 
- 		if (skl_ddb_entry_size(&new_ddb->pipe[pipe]) <
- 		    skl_ddb_entry_size(&cur_ddb->pipe[pipe])) {
- 			skl_wm_flush_pipe(dev_priv, pipe, 2);
- 			intel_wait_for_vblank(dev, pipe);
- 			reallocated[pipe] = true;
- 		}
+ 		if (skl_ddb_entries_overlap(&new->pipe[pipe],
+ 					    &old->pipe[otherp]))
+ 			return true;
  	}
  
- 	/*
- 	 * Third pass: flush the pipes that got more space allocated.
- 	 *
- 	 * We don't need to actively wait for the update here, next vblank
- 	 * will just get more DDB space with the correct WM values.
- 	 */
- 	for_each_intel_crtc(dev, crtc) {
- 		if (!crtc->active)
- 			continue;
- 
- 		pipe = crtc->pipe;
- 
- 		/*
- 		 * At this point, only the pipes more space than before are
- 		 * left to re-allocate.
- 		 */
- 		if (reallocated[pipe])
- 			continue;
- 
- 		skl_wm_flush_pipe(dev_priv, pipe, 3);
- 	}
+ 	return false;
  }
  
 -static int skl_update_pipe_wm(struct drm_crtc_state *cstate,
 -			      struct skl_ddb_allocation *ddb, /* out */
 -			      struct skl_pipe_wm *pipe_wm, /* out */
 -			      bool *changed /* out */)
 +static bool skl_update_pipe_wm(struct drm_crtc *crtc,
 +			       struct skl_pipe_wm_parameters *params,
 +			       struct intel_wm_config *config,
 +			       struct skl_ddb_allocation *ddb, /* out */
 +			       struct skl_pipe_wm *pipe_wm /* out */)
  {
 -	struct intel_crtc *intel_crtc = to_intel_crtc(cstate->crtc);
 -	struct intel_crtc_state *intel_cstate = to_intel_crtc_state(cstate);
 -	int ret;
 -
 -	ret = skl_build_pipe_wm(intel_cstate, ddb, pipe_wm);
 -	if (ret)
 -		return ret;
 -
 -	if (!memcmp(&intel_crtc->wm.active.skl, pipe_wm, sizeof(*pipe_wm)))
 -		*changed = false;
 -	else
 -		*changed = true;
 +	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
  
 -	return 0;
 -}
 +	skl_compute_wm_pipe_parameters(crtc, params);
 +	skl_allocate_pipe_ddb(crtc, config, params, ddb);
 +	skl_compute_pipe_wm(crtc, ddb, params, pipe_wm);
  
 -static uint32_t
 -pipes_modified(struct drm_atomic_state *state)
 -{
 -	struct drm_crtc *crtc;
 -	struct drm_crtc_state *cstate;
 -	uint32_t i, ret = 0;
 -
 -	for_each_crtc_in_state(state, crtc, cstate, i)
 -		ret |= drm_crtc_mask(crtc);
 +	if (!memcmp(&intel_crtc->wm.skl_active, pipe_wm, sizeof(*pipe_wm)))
 +		return false;
  
 -	return ret;
 +	intel_crtc->wm.skl_active = *pipe_wm;
 +	return true;
  }
  
 -static int
 -skl_compute_ddb(struct drm_atomic_state *state)
 +static void skl_update_other_pipe_wm(struct drm_device *dev,
 +				     struct drm_crtc *crtc,
 +				     struct intel_wm_config *config,
 +				     struct skl_wm_values *r)
  {
 -	struct drm_device *dev = state->dev;
 -	struct drm_i915_private *dev_priv = to_i915(dev);
 -	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
  	struct intel_crtc *intel_crtc;
 -	struct skl_ddb_allocation *ddb = &intel_state->wm_results.ddb;
 -	uint32_t realloc_pipes = pipes_modified(state);
 -	int ret;
 +	struct intel_crtc *this_crtc = to_intel_crtc(crtc);
  
  	/*
 -	 * If this is our first atomic update following hardware readout,
 -	 * we can't trust the DDB that the BIOS programmed for us.  Let's
 -	 * pretend that all pipes switched active status so that we'll
 -	 * ensure a full DDB recompute.
 +	 * If the WM update hasn't changed the allocation for this_crtc (the
 +	 * crtc we are currently computing the new WM values for), other
 +	 * enabled crtcs will keep the same allocation and we don't need to
 +	 * recompute anything for them.
  	 */
 -	if (dev_priv->wm.distrust_bios_wm) {
 -		ret = drm_modeset_lock(&dev->mode_config.connection_mutex,
 -				       state->acquire_ctx);
 -		if (ret)
 -			return ret;
 -
 -		intel_state->active_pipe_changes = ~0;
 -
 -		/*
 -		 * We usually only initialize intel_state->active_crtcs if we
 -		 * we're doing a modeset; make sure this field is always
 -		 * initialized during the sanitization process that happens
 -		 * on the first commit too.
 -		 */
 -		if (!intel_state->modeset)
 -			intel_state->active_crtcs = dev_priv->active_crtcs;
 -	}
 -
 -	/*
 -	 * If the modeset changes which CRTC's are active, we need to
 -	 * recompute the DDB allocation for *all* active pipes, even
 -	 * those that weren't otherwise being modified in any way by this
 -	 * atomic commit.  Due to the shrinking of the per-pipe allocations
 -	 * when new active CRTC's are added, it's possible for a pipe that
 -	 * we were already using and aren't changing at all here to suddenly
 -	 * become invalid if its DDB needs exceeds its new allocation.
 -	 *
 -	 * Note that if we wind up doing a full DDB recompute, we can't let
 -	 * any other display updates race with this transaction, so we need
 -	 * to grab the lock on *all* CRTC's.
 -	 */
 -	if (intel_state->active_pipe_changes) {
 -		realloc_pipes = ~0;
 -		intel_state->wm_results.dirty_pipes = ~0;
 -	}
 -
 -	for_each_intel_crtc_mask(dev, intel_crtc, realloc_pipes) {
 -		struct intel_crtc_state *cstate;
 -
 -		cstate = intel_atomic_get_crtc_state(state, intel_crtc);
 -		if (IS_ERR(cstate))
 -			return PTR_ERR(cstate);
 -
 -		ret = skl_allocate_pipe_ddb(cstate, ddb);
 -		if (ret)
 -			return ret;
 -
 -		ret = drm_atomic_add_affected_planes(state, &intel_crtc->base);
 -		if (ret)
 -			return ret;
 -	}
 -
 -	return 0;
 -}
 -
 -static void
 -skl_copy_wm_for_pipe(struct skl_wm_values *dst,
 -		     struct skl_wm_values *src,
 -		     enum pipe pipe)
 -{
 -	dst->wm_linetime[pipe] = src->wm_linetime[pipe];
 -	memcpy(dst->plane[pipe], src->plane[pipe],
 -	       sizeof(dst->plane[pipe]));
 -	memcpy(dst->plane_trans[pipe], src->plane_trans[pipe],
 -	       sizeof(dst->plane_trans[pipe]));
 -
 -	dst->ddb.pipe[pipe] = src->ddb.pipe[pipe];
 -	memcpy(dst->ddb.y_plane[pipe], src->ddb.y_plane[pipe],
 -	       sizeof(dst->ddb.y_plane[pipe]));
 -	memcpy(dst->ddb.plane[pipe], src->ddb.plane[pipe],
 -	       sizeof(dst->ddb.plane[pipe]));
 -}
 -
 -static int
 -skl_compute_wm(struct drm_atomic_state *state)
 -{
 -	struct drm_crtc *crtc;
 -	struct drm_crtc_state *cstate;
 -	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
 -	struct skl_wm_values *results = &intel_state->wm_results;
 -	struct skl_pipe_wm *pipe_wm;
 -	bool changed = false;
 -	int ret, i;
 +	if (!skl_ddb_allocation_changed(&r->ddb, this_crtc))
 +		return;
  
  	/*
 -	 * If this transaction isn't actually touching any CRTC's, don't
 -	 * bother with watermark calculation.  Note that if we pass this
 -	 * test, we're guaranteed to hold at least one CRTC state mutex,
 -	 * which means we can safely use values like dev_priv->active_crtcs
 -	 * since any racing commits that want to update them would need to
 -	 * hold _all_ CRTC state mutexes.
 +	 * Otherwise, because of this_crtc being freshly enabled/disabled, the
 +	 * other active pipes need new DDB allocation and WM values.
  	 */
 -	for_each_crtc_in_state(state, crtc, cstate, i)
 -		changed = true;
 -	if (!changed)
 -		return 0;
 +	list_for_each_entry(intel_crtc, &dev->mode_config.crtc_list,
 +				base.head) {
 +		struct skl_pipe_wm_parameters params = {};
 +		struct skl_pipe_wm pipe_wm = {};
 +		bool wm_changed;
  
 -	/* Clear all dirty flags */
 -	results->dirty_pipes = 0;
 -
 -	ret = skl_compute_ddb(state);
 -	if (ret)
 -		return ret;
 +		if (this_crtc->pipe == intel_crtc->pipe)
 +			continue;
  
 -	/*
 -	 * Calculate WM's for all pipes that are part of this transaction.
 -	 * Note that the DDB allocation above may have added more CRTC's that
 -	 * weren't otherwise being modified (and set bits in dirty_pipes) if
 -	 * pipe allocations had to change.
 -	 *
 -	 * FIXME:  Now that we're doing this in the atomic check phase, we
 -	 * should allow skl_update_pipe_wm() to return failure in cases where
 -	 * no suitable watermark values can be found.
 -	 */
 -	for_each_crtc_in_state(state, crtc, cstate, i) {
 -		struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 -		struct intel_crtc_state *intel_cstate =
 -			to_intel_crtc_state(cstate);
 -
 -		pipe_wm = &intel_cstate->wm.skl.optimal;
 -		ret = skl_update_pipe_wm(cstate, &results->ddb, pipe_wm,
 -					 &changed);
 -		if (ret)
 -			return ret;
 +		if (!intel_crtc->active)
 +			continue;
  
 -		if (changed)
 -			results->dirty_pipes |= drm_crtc_mask(crtc);
 +		wm_changed = skl_update_pipe_wm(&intel_crtc->base,
 +						&params, config,
 +						&r->ddb, &pipe_wm);
  
 -		if ((results->dirty_pipes & drm_crtc_mask(crtc)) == 0)
 -			/* This pipe's WM's did not change */
 -			continue;
 +		/*
 +		 * If we end up re-computing the other pipe WM values, it's
 +		 * because it was really needed, so we expect the WM values to
 +		 * be different.
 +		 */
 +		WARN_ON(!wm_changed);
  
 -		intel_cstate->update_wm_pre = true;
 -		skl_compute_wm_results(crtc->dev, pipe_wm, results, intel_crtc);
 +		skl_compute_wm_results(dev, &params, &pipe_wm, r, intel_crtc);
 +		r->dirty[intel_crtc->pipe] = true;
  	}
 -
 -	return 0;
  }
  
  static void skl_update_wm(struct drm_crtc *crtc)
  {
  	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
  	struct drm_device *dev = crtc->dev;
 -	struct drm_i915_private *dev_priv = to_i915(dev);
 +	struct drm_i915_private *dev_priv = dev->dev_private;
 +	struct skl_pipe_wm_parameters params = {};
  	struct skl_wm_values *results = &dev_priv->wm.skl_results;
++<<<<<<< HEAD
 +	struct skl_pipe_wm pipe_wm = {};
 +	struct intel_wm_config config = {};
++=======
+ 	struct skl_wm_values *hw_vals = &dev_priv->wm.skl_hw;
+ 	struct intel_crtc_state *cstate = to_intel_crtc_state(crtc->state);
+ 	struct skl_pipe_wm *pipe_wm = &cstate->wm.skl.optimal;
+ 	enum pipe pipe = intel_crtc->pipe;
++>>>>>>> 27082493e9c6 (drm/i915/skl: Update DDB values atomically with wms/plane attrs)
 +
 +	memset(results, 0, sizeof(*results));
 +
 +	skl_compute_wm_global_parameters(dev, &config);
  
 -	if ((results->dirty_pipes & drm_crtc_mask(crtc)) == 0)
 +	if (!skl_update_pipe_wm(crtc, &params, &config,
 +				&results->ddb, &pipe_wm))
  		return;
  
 -	intel_crtc->wm.active.skl = *pipe_wm;
 +	skl_compute_wm_results(dev, &params, &pipe_wm, results, intel_crtc);
 +	results->dirty[intel_crtc->pipe] = true;
  
 -	mutex_lock(&dev_priv->wm.wm_mutex);
++<<<<<<< HEAD
 +	skl_update_other_pipe_wm(dev, crtc, &config, results);
 +	skl_write_wm_values(dev_priv, results);
 +	skl_flush_wm_values(dev_priv, results);
 +
 +	/* store the new configuration */
 +	dev_priv->wm.skl_hw = *results;
 +}
  
 +static void
 +skl_update_sprite_wm(struct drm_plane *plane, struct drm_crtc *crtc,
 +		     uint32_t sprite_width, uint32_t sprite_height,
 +		     int pixel_size, bool enabled, bool scaled)
 +{
 +	struct intel_plane *intel_plane = to_intel_plane(plane);
 +	struct drm_framebuffer *fb = plane->state->fb;
 +
 +	intel_plane->wm.enabled = enabled;
 +	intel_plane->wm.scaled = scaled;
 +	intel_plane->wm.horiz_pixels = sprite_width;
 +	intel_plane->wm.vert_pixels = sprite_height;
 +	intel_plane->wm.bytes_per_pixel = pixel_size;
 +	intel_plane->wm.tiling = DRM_FORMAT_MOD_NONE;
 +	/*
 +	 * Framebuffer can be NULL on plane disable, but it does not
 +	 * matter for watermarks if we assume no tiling in that case.
 +	 */
 +	if (fb)
 +		intel_plane->wm.tiling = fb->modifier[0];
 +	intel_plane->wm.rotation = plane->state->rotation;
++=======
+ 	/*
+ 	 * If this pipe isn't active already, we're going to be enabling it
+ 	 * very soon. Since it's safe to update a pipe's ddb allocation while
+ 	 * the pipe's shut off, just do so here. Already active pipes will have
+ 	 * their watermarks updated once we update their planes.
+ 	 */
+ 	if (crtc->state->active_changed) {
+ 		int plane;
+ 
+ 		for (plane = 0; plane < intel_num_planes(intel_crtc); plane++)
+ 			skl_write_plane_wm(intel_crtc, results, plane);
+ 
+ 		skl_write_cursor_wm(intel_crtc, results);
+ 	}
+ 
+ 	skl_copy_wm_for_pipe(hw_vals, results, pipe);
++>>>>>>> 27082493e9c6 (drm/i915/skl: Update DDB values atomically with wms/plane attrs)
  
 -	mutex_unlock(&dev_priv->wm.wm_mutex);
 +	skl_update_wm(crtc);
  }
  
 -static void ilk_compute_wm_config(struct drm_device *dev,
 -				  struct intel_wm_config *config)
 +static void ilk_update_wm(struct drm_crtc *crtc)
  {
 -	struct intel_crtc *crtc;
 +	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 +	struct drm_device *dev = crtc->dev;
 +	struct drm_i915_private *dev_priv = dev->dev_private;
 +	struct ilk_wm_maximums max;
 +	struct ilk_pipe_wm_parameters params = {};
 +	struct ilk_wm_values results = {};
 +	enum intel_ddb_partitioning partitioning;
 +	struct intel_pipe_wm pipe_wm = {};
 +	struct intel_pipe_wm lp_wm_1_2 = {}, lp_wm_5_6 = {}, *best_lp_wm;
 +	struct intel_wm_config config = {};
  
 -	/* Compute the currently _active_ config */
 -	for_each_intel_crtc(dev, crtc) {
 -		const struct intel_pipe_wm *wm = &crtc->wm.active.ilk;
 +	ilk_compute_wm_parameters(crtc, &params);
  
 -		if (!wm->pipe_enabled)
 -			continue;
 +	intel_compute_pipe_wm(crtc, &params, &pipe_wm);
  
 -		config->sprites_enabled |= wm->sprites_enabled;
 -		config->sprites_scaled |= wm->sprites_scaled;
 -		config->num_pipes_active++;
 -	}
 -}
 +	if (!memcmp(&intel_crtc->wm.active, &pipe_wm, sizeof(pipe_wm)))
 +		return;
  
 -static void ilk_program_watermarks(struct drm_i915_private *dev_priv)
 -{
 -	struct drm_device *dev = &dev_priv->drm;
 -	struct intel_pipe_wm lp_wm_1_2 = {}, lp_wm_5_6 = {}, *best_lp_wm;
 -	struct ilk_wm_maximums max;
 -	struct intel_wm_config config = {};
 -	struct ilk_wm_values results = {};
 -	enum intel_ddb_partitioning partitioning;
 +	intel_crtc->wm.active = pipe_wm;
  
  	ilk_compute_wm_config(dev, &config);
  
* Unmerged path drivers/gpu/drm/i915/intel_display.c
* Unmerged path drivers/gpu/drm/i915/intel_drv.h
* Unmerged path drivers/gpu/drm/i915/intel_pm.c
