hugetlb: rename hugepage_migration_support() to ..._supported()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
commit 100873d7a777b67ad35197c5a998b5e778f8bf3f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/100873d7.failed

We already have a function named hugepages_supported(), and the similar
name hugepage_migration_support() is a bit unconfortable, so let's rename
it hugepage_migration_supported().

	Signed-off-by: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
	Acked-by: Hugh Dickins <hughd@google.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 100873d7a777b67ad35197c5a998b5e778f8bf3f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/hugetlb.h
#	mm/hugetlb.c
#	mm/migrate.c
diff --cc include/linux/hugetlb.h
index f71f104feba3,255cd5cc0754..000000000000
--- a/include/linux/hugetlb.h
+++ b/include/linux/hugetlb.h
@@@ -398,6 -395,17 +398,20 @@@ static inline pgoff_t basepage_index(st
  	return __basepage_index(page);
  }
  
++<<<<<<< HEAD
++=======
+ extern void dissolve_free_huge_pages(unsigned long start_pfn,
+ 				     unsigned long end_pfn);
+ static inline int hugepage_migration_supported(struct hstate *h)
+ {
+ #ifdef CONFIG_ARCH_ENABLE_HUGEPAGE_MIGRATION
+ 	return huge_page_shift(h) == PMD_SHIFT;
+ #else
+ 	return 0;
+ #endif
+ }
+ 
++>>>>>>> 100873d7a777 (hugetlb: rename hugepage_migration_support() to ..._supported())
  static inline spinlock_t *huge_pte_lockptr(struct hstate *h,
  					   struct mm_struct *mm, pte_t *pte)
  {
@@@ -444,6 -452,8 +458,11 @@@ static inline pgoff_t basepage_index(st
  {
  	return page->index;
  }
++<<<<<<< HEAD
++=======
+ #define dissolve_free_huge_pages(s, e)	do {} while (0)
+ #define hugepage_migration_supported(h)	0
++>>>>>>> 100873d7a777 (hugetlb: rename hugepage_migration_support() to ..._supported())
  
  static inline spinlock_t *huge_pte_lockptr(struct hstate *h,
  					   struct mm_struct *mm, pte_t *pte)
diff --cc mm/hugetlb.c
index 4a192c9e708d,226910cb7c9b..000000000000
--- a/mm/hugetlb.c
+++ b/mm/hugetlb.c
@@@ -523,6 -541,15 +523,18 @@@ static struct page *dequeue_huge_page_n
  	return page;
  }
  
++<<<<<<< HEAD
++=======
+ /* Movability of hugepages depends on migration support. */
+ static inline gfp_t htlb_alloc_mask(struct hstate *h)
+ {
+ 	if (hugepages_treat_as_movable || hugepage_migration_supported(h))
+ 		return GFP_HIGHUSER_MOVABLE;
+ 	else
+ 		return GFP_HIGHUSER;
+ }
+ 
++>>>>>>> 100873d7a777 (hugetlb: rename hugepage_migration_support() to ..._supported())
  static struct page *dequeue_huge_page_vma(struct hstate *h,
  				struct vm_area_struct *vma,
  				unsigned long address, int avoid_reserve,
diff --cc mm/migrate.c
index c1313d07c550,63f0cd559999..000000000000
--- a/mm/migrate.c
+++ b/mm/migrate.c
@@@ -1006,9 -1029,22 +1006,25 @@@ static int unmap_and_move_huge_page(new
  {
  	int rc = 0;
  	int *result = NULL;
 -	struct page *new_hpage;
 +	struct page *new_hpage = get_new_page(hpage, private, &result);
  	struct anon_vma *anon_vma = NULL;
  
++<<<<<<< HEAD
++=======
+ 	/*
+ 	 * Movability of hugepages depends on architectures and hugepage size.
+ 	 * This check is necessary because some callers of hugepage migration
+ 	 * like soft offline and memory hotremove don't walk through page
+ 	 * tables or check whether the hugepage is pmd-based or not before
+ 	 * kicking migration.
+ 	 */
+ 	if (!hugepage_migration_supported(page_hstate(hpage))) {
+ 		putback_active_hugepage(hpage);
+ 		return -ENOSYS;
+ 	}
+ 
+ 	new_hpage = get_new_page(hpage, private, &result);
++>>>>>>> 100873d7a777 (hugetlb: rename hugepage_migration_support() to ..._supported())
  	if (!new_hpage)
  		return -ENOMEM;
  
* Unmerged path include/linux/hugetlb.h
* Unmerged path mm/hugetlb.c
* Unmerged path mm/migrate.c
