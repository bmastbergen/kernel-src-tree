IB/qib: Remove mmap from qib

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Harish Chegondi <harish.chegondi@intel.com>
commit cd18201f5ec8b04a8eb9ef3f3b559cba55955598
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/cd18201f.failed

Since mmap functionality has been moved into rdmavt, its time for qib to
use that.

	Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
	Signed-off-by: Harish Chegondi <harish.chegondi@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit cd18201f5ec8b04a8eb9ef3f3b559cba55955598)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/qib/Makefile
#	drivers/infiniband/hw/qib/qib_mmap.c
#	drivers/infiniband/hw/qib/qib_verbs.c
#	drivers/infiniband/hw/qib/qib_verbs.h
diff --cc drivers/infiniband/hw/qib/Makefile
index 8a8f892de7df,45db4fc21c93..000000000000
--- a/drivers/infiniband/hw/qib/Makefile
+++ b/drivers/infiniband/hw/qib/Makefile
@@@ -1,8 -1,8 +1,13 @@@
  obj-$(CONFIG_INFINIBAND_QIB) += ib_qib.o
  
  ib_qib-y := qib_cq.o qib_diag.o qib_driver.o qib_eeprom.o \
++<<<<<<< HEAD
 +	qib_file_ops.o qib_fs.o qib_init.o qib_intr.o qib_keys.o \
 +	qib_mad.o qib_mmap.o qib_mr.o qib_pcie.o qib_pio_copy.o \
++=======
+ 	qib_file_ops.o qib_fs.o qib_init.o qib_intr.o \
+ 	qib_mad.o qib_pcie.o qib_pio_copy.o \
++>>>>>>> cd18201f5ec8 (IB/qib: Remove mmap from qib)
  	qib_qp.o qib_qsfp.o qib_rc.o qib_ruc.o qib_sdma.o qib_srq.o \
  	qib_sysfs.o qib_twsi.o qib_tx.o qib_uc.o qib_ud.o \
  	qib_user_pages.o qib_user_sdma.o qib_verbs_mcast.o qib_iba7220.o \
diff --cc drivers/infiniband/hw/qib/qib_verbs.c
index c4417a1f33be,893d00c05bd8..000000000000
--- a/drivers/infiniband/hw/qib/qib_verbs.c
+++ b/drivers/infiniband/hw/qib/qib_verbs.c
@@@ -2122,33 -1992,6 +2122,36 @@@ int qib_register_ib_device(struct qib_d
  
  	qib_init_qpn_table(dd, &dev->qpn_table);
  
++<<<<<<< HEAD
 +	/*
 +	 * The top ib_qib_lkey_table_size bits are used to index the
 +	 * table.  The lower 8 bits can be owned by the user (copied from
 +	 * the LKEY).  The remaining bits act as a generation number or tag.
 +	 */
 +	spin_lock_init(&dev->lk_table.lock);
 +	/* insure generation is at least 4 bits see keys.c */
 +	if (ib_qib_lkey_table_size > MAX_LKEY_TABLE_BITS) {
 +		qib_dev_warn(dd, "lkey bits %u too large, reduced to %u\n",
 +			ib_qib_lkey_table_size, MAX_LKEY_TABLE_BITS);
 +		ib_qib_lkey_table_size = MAX_LKEY_TABLE_BITS;
 +	}
 +	dev->lk_table.max = 1 << ib_qib_lkey_table_size;
 +	lk_tab_size = dev->lk_table.max * sizeof(*dev->lk_table.table);
 +	dev->lk_table.table = (struct qib_mregion __rcu **)
 +		vmalloc(lk_tab_size);
 +	if (dev->lk_table.table == NULL) {
 +		ret = -ENOMEM;
 +		goto err_lk;
 +	}
 +	RCU_INIT_POINTER(dev->dma_mr, NULL);
 +	for (i = 0; i < dev->lk_table.max; i++)
 +		RCU_INIT_POINTER(dev->lk_table.table[i], NULL);
 +	INIT_LIST_HEAD(&dev->pending_mmaps);
 +	spin_lock_init(&dev->pending_lock);
 +	dev->mmap_offset = PAGE_SIZE;
 +	spin_lock_init(&dev->mmap_offset_lock);
++=======
++>>>>>>> cd18201f5ec8 (IB/qib: Remove mmap from qib)
  	INIT_LIST_HEAD(&dev->piowait);
  	INIT_LIST_HEAD(&dev->dmawait);
  	INIT_LIST_HEAD(&dev->txwait);
diff --cc drivers/infiniband/hw/qib/qib_verbs.h
index ca366073af4f,eade66850640..000000000000
--- a/drivers/infiniband/hw/qib/qib_verbs.h
+++ b/drivers/infiniband/hw/qib/qib_verbs.h
@@@ -718,48 -423,11 +718,51 @@@ struct qib_ibport 
  	u32 z_local_link_integrity_errors;      /* starting count for PMA */
  	u32 z_excessive_buffer_overrun_errors;  /* starting count for PMA */
  	u32 z_vl15_dropped;                     /* starting count for PMA */
 +	u32 n_rc_resends;
 +	u32 n_rc_acks;
 +	u32 n_rc_qacks;
 +	u32 n_rc_delayed_comp;
 +	u32 n_seq_naks;
 +	u32 n_rdma_seq;
 +	u32 n_rnr_naks;
 +	u32 n_other_naks;
 +	u32 n_loop_pkts;
 +	u32 n_pkt_drops;
 +	u32 n_vl15_dropped;
 +	u32 n_rc_timeouts;
 +	u32 n_dmawait;
 +	u32 n_unaligned;
 +	u32 n_rc_dupreq;
 +	u32 n_rc_seqnak;
 +	u32 port_cap_flags;
 +	u32 pma_sample_start;
 +	u32 pma_sample_interval;
 +	__be16 pma_counter_select[5];
 +	u16 pma_tag;
 +	u16 pkey_violations;
 +	u16 qkey_violations;
 +	u16 mkey_violations;
 +	u16 mkey_lease_period;
 +	u16 sm_lid;
 +	u16 repress_traps;
 +	u8 sm_sl;
 +	u8 mkeyprot;
 +	u8 subnet_timeout;
 +	u8 vl_high_limit;
  	u8 sl_to_vl[16];
 +
  };
  
 +
  struct qib_ibdev {
  	struct rvt_dev_info rdi;
++<<<<<<< HEAD
 +	struct list_head pending_mmaps;
 +	spinlock_t mmap_offset_lock; /* protect mmap_offset */
 +	u32 mmap_offset;
 +	struct qib_mregion __rcu *dma_mr;
++=======
++>>>>>>> cd18201f5ec8 (IB/qib: Remove mmap from qib)
  
  	/* QP numbers are shared by all IB ports */
  	struct qib_qpn_table qpn_table;
@@@ -1091,24 -679,12 +1093,28 @@@ static inline void qib_put_ss(struct qi
  	}
  }
  
++<<<<<<< HEAD
 +
 +void qib_release_mmap_info(struct kref *ref);
 +
 +struct qib_mmap_info *qib_create_mmap_info(struct qib_ibdev *dev, u32 size,
 +					   struct ib_ucontext *context,
 +					   void *obj);
 +
 +void qib_update_mmap_info(struct qib_ibdev *dev, struct qib_mmap_info *ip,
 +			  u32 size, void *obj);
 +
 +int qib_mmap(struct ib_ucontext *context, struct vm_area_struct *vma);
 +
 +int qib_get_rwqe(struct qib_qp *qp, int wr_id_only);
++=======
+ int qib_get_rwqe(struct rvt_qp *qp, int wr_id_only);
++>>>>>>> cd18201f5ec8 (IB/qib: Remove mmap from qib)
  
 -void qib_migrate_qp(struct rvt_qp *qp);
 +void qib_migrate_qp(struct qib_qp *qp);
  
  int qib_ruc_check_hdr(struct qib_ibport *ibp, struct qib_ib_header *hdr,
 -		      int has_grh, struct rvt_qp *qp, u32 bth0);
 +		      int has_grh, struct qib_qp *qp, u32 bth0);
  
  u32 qib_make_grh(struct qib_ibport *ibp, struct ib_grh *hdr,
  		 struct ib_global_route *grh, u32 hwords, u32 nwords);
* Unmerged path drivers/infiniband/hw/qib/qib_mmap.c
* Unmerged path drivers/infiniband/hw/qib/Makefile
diff --git a/drivers/infiniband/hw/qib/qib_cq.c b/drivers/infiniband/hw/qib/qib_cq.c
index 2b45d0b02300..0373f9c3b3c1 100644
--- a/drivers/infiniband/hw/qib/qib_cq.c
+++ b/drivers/infiniband/hw/qib/qib_cq.c
@@ -264,7 +264,7 @@ struct ib_cq *qib_create_cq(struct ib_device *ibdev,
 	if (udata && udata->outlen >= sizeof(__u64)) {
 		int err;
 
-		cq->ip = qib_create_mmap_info(dev, sz, context, wc);
+		cq->ip = rvt_create_mmap_info(&dev->rdi, sz, context, wc);
 		if (!cq->ip) {
 			ret = ERR_PTR(-ENOMEM);
 			goto bail_wc;
@@ -290,9 +290,9 @@ struct ib_cq *qib_create_cq(struct ib_device *ibdev,
 	spin_unlock(&dev->n_cqs_lock);
 
 	if (cq->ip) {
-		spin_lock_irq(&dev->pending_lock);
-		list_add(&cq->ip->pending_mmaps, &dev->pending_mmaps);
-		spin_unlock_irq(&dev->pending_lock);
+		spin_lock_irq(&dev->rdi.pending_lock);
+		list_add(&cq->ip->pending_mmaps, &dev->rdi.pending_mmaps);
+		spin_unlock_irq(&dev->rdi.pending_lock);
 	}
 
 	/*
@@ -342,7 +342,7 @@ int qib_destroy_cq(struct ib_cq *ibcq)
 	dev->n_cqs_allocated--;
 	spin_unlock(&dev->n_cqs_lock);
 	if (cq->ip)
-		kref_put(&cq->ip->ref, qib_release_mmap_info);
+		kref_put(&cq->ip->ref, rvt_release_mmap_info);
 	else
 		vfree(cq->queue);
 	kfree(cq);
@@ -468,7 +468,7 @@ int qib_resize_cq(struct ib_cq *ibcq, int cqe, struct ib_udata *udata)
 		struct qib_ibdev *dev = to_idev(ibcq->device);
 		struct qib_mmap_info *ip = cq->ip;
 
-		qib_update_mmap_info(dev, ip, sz, wc);
+		rvt_update_mmap_info(&dev->rdi, ip, sz, wc);
 
 		/*
 		 * Return the offset to mmap.
@@ -481,10 +481,10 @@ int qib_resize_cq(struct ib_cq *ibcq, int cqe, struct ib_udata *udata)
 				goto bail;
 		}
 
-		spin_lock_irq(&dev->pending_lock);
+		spin_lock_irq(&dev->rdi.pending_lock);
 		if (list_empty(&ip->pending_mmaps))
-			list_add(&ip->pending_mmaps, &dev->pending_mmaps);
-		spin_unlock_irq(&dev->pending_lock);
+			list_add(&ip->pending_mmaps, &dev->rdi.pending_mmaps);
+		spin_unlock_irq(&dev->rdi.pending_lock);
 	}
 
 	ret = 0;
* Unmerged path drivers/infiniband/hw/qib/qib_mmap.c
diff --git a/drivers/infiniband/hw/qib/qib_qp.c b/drivers/infiniband/hw/qib/qib_qp.c
index cf1dd6e9d434..3c6e893fce15 100644
--- a/drivers/infiniband/hw/qib/qib_qp.c
+++ b/drivers/infiniband/hw/qib/qib_qp.c
@@ -493,12 +493,12 @@ int qib_error_qp(struct qib_qp *qp, enum ib_wc_status err)
 	if (qp->s_flags & QIB_S_ANY_WAIT_SEND)
 		qp->s_flags &= ~QIB_S_ANY_WAIT_SEND;
 
-	spin_lock(&dev->pending_lock);
+	spin_lock(&dev->rdi.pending_lock);
 	if (!list_empty(&priv->iowait) && !(qp->s_flags & QIB_S_BUSY)) {
 		qp->s_flags &= ~QIB_S_ANY_WAIT_IO;
 		list_del_init(&priv->iowait);
 	}
-	spin_unlock(&dev->pending_lock);
+	spin_unlock(&dev->rdi.pending_lock);
 
 	if (!(qp->s_flags & QIB_S_BUSY)) {
 		qp->s_hdrwords = 0;
@@ -700,10 +700,10 @@ int qib_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 	case IB_QPS_RESET:
 		if (qp->state != IB_QPS_RESET) {
 			qp->state = IB_QPS_RESET;
-			spin_lock(&dev->pending_lock);
+			spin_lock(&dev->rdi.pending_lock);
 			if (!list_empty(&priv->iowait))
 				list_del_init(&priv->iowait);
-			spin_unlock(&dev->pending_lock);
+			spin_unlock(&dev->rdi.pending_lock);
 			qp->s_flags &= ~(QIB_S_TIMER | QIB_S_ANY_WAIT);
 			spin_unlock(&qp->s_lock);
 			spin_unlock_irq(&qp->r_lock);
@@ -1156,7 +1156,7 @@ struct ib_qp *qib_create_qp(struct ib_pd *ibpd,
 		} else {
 			u32 s = sizeof(struct qib_rwq) + qp->r_rq.size * sz;
 
-			qp->ip = qib_create_mmap_info(dev, s,
+			qp->ip = rvt_create_mmap_info(&dev->rdi, s,
 						      ibpd->uobject->context,
 						      qp->r_rq.wq);
 			if (!qp->ip) {
@@ -1184,9 +1184,9 @@ struct ib_qp *qib_create_qp(struct ib_pd *ibpd,
 	spin_unlock(&dev->n_qps_lock);
 
 	if (qp->ip) {
-		spin_lock_irq(&dev->pending_lock);
-		list_add(&qp->ip->pending_mmaps, &dev->pending_mmaps);
-		spin_unlock_irq(&dev->pending_lock);
+		spin_lock_irq(&dev->rdi.pending_lock);
+		list_add(&qp->ip->pending_mmaps, &dev->rdi.pending_mmaps);
+		spin_unlock_irq(&dev->rdi.pending_lock);
 	}
 
 	ret = &qp->ibqp;
@@ -1194,7 +1194,7 @@ struct ib_qp *qib_create_qp(struct ib_pd *ibpd,
 
 bail_ip:
 	if (qp->ip)
-		kref_put(&qp->ip->ref, qib_release_mmap_info);
+		kref_put(&qp->ip->ref, rvt_release_mmap_info);
 	else
 		vfree(qp->r_rq.wq);
 	free_qpn(&dev->qpn_table, qp->ibqp.qp_num);
@@ -1228,10 +1228,10 @@ int qib_destroy_qp(struct ib_qp *ibqp)
 	spin_lock_irq(&qp->s_lock);
 	if (qp->state != IB_QPS_RESET) {
 		qp->state = IB_QPS_RESET;
-		spin_lock(&dev->pending_lock);
+		spin_lock(&dev->rdi.pending_lock);
 		if (!list_empty(&priv->iowait))
 			list_del_init(&priv->iowait);
-		spin_unlock(&dev->pending_lock);
+		spin_unlock(&dev->rdi.pending_lock);
 		qp->s_flags &= ~(QIB_S_TIMER | QIB_S_ANY_WAIT);
 		spin_unlock_irq(&qp->s_lock);
 		cancel_work_sync(&priv->s_work);
@@ -1254,7 +1254,7 @@ int qib_destroy_qp(struct ib_qp *ibqp)
 	spin_unlock(&dev->n_qps_lock);
 
 	if (qp->ip)
-		kref_put(&qp->ip->ref, qib_release_mmap_info);
+		kref_put(&qp->ip->ref, rvt_release_mmap_info);
 	else
 		vfree(qp->r_rq.wq);
 	vfree(qp->s_wq);
diff --git a/drivers/infiniband/hw/qib/qib_sdma.c b/drivers/infiniband/hw/qib/qib_sdma.c
index ac4fcad97505..d691db2b9fd1 100644
--- a/drivers/infiniband/hw/qib/qib_sdma.c
+++ b/drivers/infiniband/hw/qib/qib_sdma.c
@@ -697,7 +697,7 @@ busy:
 		tx->dwords = dwords;
 		priv->s_tx = tx;
 		dev = &ppd->dd->verbs_dev;
-		spin_lock(&dev->pending_lock);
+		spin_lock(&dev->rdi.pending_lock);
 		if (list_empty(&priv->iowait)) {
 			struct qib_ibport *ibp;
 
@@ -706,7 +706,7 @@ busy:
 			qp->s_flags |= QIB_S_WAIT_DMA_DESC;
 			list_add_tail(&priv->iowait, &dev->dmawait);
 		}
-		spin_unlock(&dev->pending_lock);
+		spin_unlock(&dev->rdi.pending_lock);
 		qp->s_flags &= ~QIB_S_BUSY;
 		spin_unlock(&qp->s_lock);
 		ret = -EBUSY;
diff --git a/drivers/infiniband/hw/qib/qib_srq.c b/drivers/infiniband/hw/qib/qib_srq.c
index d6235931a1ba..6504ce7976eb 100644
--- a/drivers/infiniband/hw/qib/qib_srq.c
+++ b/drivers/infiniband/hw/qib/qib_srq.c
@@ -148,7 +148,7 @@ struct ib_srq *qib_create_srq(struct ib_pd *ibpd,
 		u32 s = sizeof(struct qib_rwq) + srq->rq.size * sz;
 
 		srq->ip =
-		    qib_create_mmap_info(dev, s, ibpd->uobject->context,
+		    rvt_create_mmap_info(&dev->rdi, s, ibpd->uobject->context,
 					 srq->rq.wq);
 		if (!srq->ip) {
 			ret = ERR_PTR(-ENOMEM);
@@ -183,9 +183,9 @@ struct ib_srq *qib_create_srq(struct ib_pd *ibpd,
 	spin_unlock(&dev->n_srqs_lock);
 
 	if (srq->ip) {
-		spin_lock_irq(&dev->pending_lock);
-		list_add(&srq->ip->pending_mmaps, &dev->pending_mmaps);
-		spin_unlock_irq(&dev->pending_lock);
+		spin_lock_irq(&dev->rdi.pending_lock);
+		list_add(&srq->ip->pending_mmaps, &dev->rdi.pending_mmaps);
+		spin_unlock_irq(&dev->rdi.pending_lock);
 	}
 
 	ret = &srq->ibsrq;
@@ -307,7 +307,7 @@ int qib_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,
 			struct qib_ibdev *dev = to_idev(srq->ibsrq.device);
 			u32 s = sizeof(struct qib_rwq) + size * sz;
 
-			qib_update_mmap_info(dev, ip, s, wq);
+			rvt_update_mmap_info(&dev->rdi, ip, s, wq);
 
 			/*
 			 * Return the offset to mmap.
@@ -324,11 +324,11 @@ int qib_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,
 			 * Put user mapping info onto the pending list
 			 * unless it already is on the list.
 			 */
-			spin_lock_irq(&dev->pending_lock);
+			spin_lock_irq(&dev->rdi.pending_lock);
 			if (list_empty(&ip->pending_mmaps))
 				list_add(&ip->pending_mmaps,
-					 &dev->pending_mmaps);
-			spin_unlock_irq(&dev->pending_lock);
+					 &dev->rdi.pending_mmaps);
+			spin_unlock_irq(&dev->rdi.pending_lock);
 		}
 	} else if (attr_mask & IB_SRQ_LIMIT) {
 		spin_lock_irq(&srq->rq.lock);
@@ -371,7 +371,7 @@ int qib_destroy_srq(struct ib_srq *ibsrq)
 	dev->n_srqs_allocated--;
 	spin_unlock(&dev->n_srqs_lock);
 	if (srq->ip)
-		kref_put(&srq->ip->ref, qib_release_mmap_info);
+		kref_put(&srq->ip->ref, rvt_release_mmap_info);
 	else
 		vfree(srq->rq.wq);
 	kfree(srq);
* Unmerged path drivers/infiniband/hw/qib/qib_verbs.c
* Unmerged path drivers/infiniband/hw/qib/qib_verbs.h
