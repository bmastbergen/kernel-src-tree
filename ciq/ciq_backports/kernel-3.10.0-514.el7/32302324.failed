iommu/amd: Use swiotlb in passthrough mode

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [iommu] amd: Use swiotlb in passthrough mode (Myron Stowe) [1050021]
Rebuild_FUZZ: 92.31%
commit-author Joerg Roedel <jroedel@suse.de>
commit 323023245771589c53869396e3297c703d347852
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/32302324.failed

In passthrough mode (iommu=pt) all devices are identity
mapped. If a device does not support 64bit DMA it might
still need remapping. Make sure swiotlb is initialized to
provide this remapping.

	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit 323023245771589c53869396e3297c703d347852)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/amd_iommu.c
diff --cc drivers/iommu/amd_iommu.c
index 092461032458,e29baa6c64e3..000000000000
--- a/drivers/iommu/amd_iommu.c
+++ b/drivers/iommu/amd_iommu.c
@@@ -2377,44 -2247,55 +2377,66 @@@ static void detach_device(struct devic
  	dev_data->ats.enabled = false;
  }
  
 -static int amd_iommu_add_device(struct device *dev)
 +/*
 + * Find out the protection domain structure for a given PCI device. This
 + * will give us the pointer to the page table root for example.
 + */
 +static struct protection_domain *domain_for_device(struct device *dev)
  {
  	struct iommu_dev_data *dev_data;
 -	struct iommu_domain *domain;
 -	struct amd_iommu *iommu;
 -	u16 devid;
 -	int ret;
 +	struct protection_domain *dom = NULL;
 +	unsigned long flags;
  
 -	if (!check_device(dev) || get_dev_data(dev))
 -		return 0;
 +	dev_data   = get_dev_data(dev);
  
 -	devid = get_device_id(dev);
 -	iommu = amd_iommu_rlookup_table[devid];
 +	if (dev_data->domain)
 +		return dev_data->domain;
  
 -	ret = iommu_init_device(dev);
 -	if (ret) {
 -		if (ret != -ENOTSUPP)
 -			pr_err("Failed to initialize device %s - trying to proceed anyway\n",
 -				dev_name(dev));
 +	if (dev_data->alias_data != NULL) {
 +		struct iommu_dev_data *alias_data = dev_data->alias_data;
  
++<<<<<<< HEAD
 +		read_lock_irqsave(&amd_iommu_devtable_lock, flags);
 +		if (alias_data->domain != NULL) {
 +			__attach_device(dev_data, alias_data->domain);
 +			dom = alias_data->domain;
 +		}
 +		read_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
 +	}
++=======
+ 		iommu_ignore_device(dev);
+ 		dev->archdata.dma_ops = &nommu_dma_ops;
+ 		goto out;
+ 	}
+ 	init_iommu_group(dev);
+ 
+ 	dev_data = get_dev_data(dev);
+ 
+ 	BUG_ON(!dev_data);
+ 
+ 	if (iommu_pass_through || dev_data->iommu_v2)
+ 		iommu_request_dm_for_dev(dev);
+ 
+ 	/* Domains are initialized for this device - have a look what we ended up with */
+ 	domain = iommu_get_domain_for_dev(dev);
+ 	if (domain->type == IOMMU_DOMAIN_IDENTITY)
+ 		dev_data->passthrough = true;
+ 	else
+ 		dev->archdata.dma_ops = &amd_iommu_dma_ops;
++>>>>>>> 323023245771 (iommu/amd: Use swiotlb in passthrough mode)
  
 -out:
 -	iommu_completion_wait(iommu);
 -
 -	return 0;
 +	return dom;
  }
  
 -static void amd_iommu_remove_device(struct device *dev)
 +static int device_change_notifier(struct notifier_block *nb,
 +				  unsigned long action, void *data)
  {
 +	struct dma_ops_domain *dma_domain;
 +	struct protection_domain *domain;
 +	struct iommu_dev_data *dev_data;
 +	struct device *dev = data;
  	struct amd_iommu *iommu;
 +	unsigned long flags;
  	u16 devid;
  
  	if (!check_device(dev))
@@@ -3118,39 -2850,9 +3140,42 @@@ void __init amd_iommu_init_api(void
  
  int __init amd_iommu_init_dma_ops(void)
  {
++<<<<<<< HEAD
 +	struct amd_iommu *iommu;
 +	int ret, unhandled;
 +
 +	/*
 +	 * first allocate a default protection domain for every IOMMU we
 +	 * found in the system. Devices not assigned to any other
 +	 * protection domain will be assigned to the default one.
 +	 */
 +	for_each_iommu(iommu) {
 +		iommu->default_dom = dma_ops_domain_alloc();
 +		if (iommu->default_dom == NULL)
 +			return -ENOMEM;
 +		iommu->default_dom->domain.flags |= PD_DEFAULT_MASK;
 +		ret = iommu_init_unity_mappings(iommu);
 +		if (ret)
 +			goto free_domains;
 +	}
 +
 +	/*
 +	 * Pre-allocate the protection domains for each device.
 +	 */
 +	prealloc_protection_domains();
 +
++=======
+ 	swiotlb        = iommu_pass_through ? 1 : 0;
++>>>>>>> 323023245771 (iommu/amd: Use swiotlb in passthrough mode)
  	iommu_detected = 1;
- 	swiotlb = 0;
  
 +	/* Make the driver finally visible to the drivers */
 +	unhandled = device_dma_ops_init();
 +	if (unhandled && max_pfn > MAX_DMA32_PFN) {
 +		/* There are unhandled devices - initialize swiotlb for them */
 +		swiotlb = 1;
 +	}
 +
  	amd_iommu_stats_init();
  
  	if (amd_iommu_unmap_flush)
* Unmerged path drivers/iommu/amd_iommu.c
