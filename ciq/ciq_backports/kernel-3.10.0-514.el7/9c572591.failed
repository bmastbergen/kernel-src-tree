sched/debug: Fix /proc/sched_debug regression

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Josh Poimboeuf <jpoimboe@redhat.com>
commit 9c57259117b9c25472a3fa6d5a14d6bb3b647e87
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/9c572591.failed

Commit:

  cb2517653fcc ("sched/debug: Make schedstats a runtime tunable that is disabled by default")

... introduced a bug when CONFIG_SCHEDSTATS is enabled and the
runtime tunable is disabled (which is the default).

The wait-time, sum-exec, and sum-sleep fields are missing from the
/proc/sched_debug file in the runnable_tasks section.

Fix it with a new schedstat_val() macro which returns the field value
when schedstats is enabled and zero otherwise.  The macro works with
both SCHEDSTATS and !SCHEDSTATS.  I put the macro in stats.h since it
might end up being useful in other places.

	Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Acked-by: Mel Gorman <mgorman@techsingularity.net>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Matt Fleming <matt@codeblueprint.co.uk>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
	Cc: Thomas Gleixner <tglx@linutronix.de>
Fixes: cb2517653fcc ("sched/debug: Make schedstats a runtime tunable that is disabled by default")
Link: http://lkml.kernel.org/r/bcda7c2790cf2ccbe586a28c02dd7b6fe7749a2b.1464994423.git.jpoimboe@redhat.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 9c57259117b9c25472a3fa6d5a14d6bb3b647e87)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/debug.c
#	kernel/sched/stats.h
diff --cc kernel/sched/debug.c
index 850df63779ac,0368c393a336..000000000000
--- a/kernel/sched/debug.c
+++ b/kernel/sched/debug.c
@@@ -129,19 -427,14 +129,23 @@@ print_task(struct seq_file *m, struct r
  		SPLIT_NS(p->se.vruntime),
  		(long long)(p->nvcsw + p->nivcsw),
  		p->prio);
++<<<<<<< HEAD
 +#ifdef CONFIG_SCHEDSTATS
 +	SEQ_printf(m, "%9Ld.%06ld %9Ld.%06ld %9Ld.%06ld",
 +		SPLIT_NS(p->se.statistics.wait_sum),
 +		SPLIT_NS(p->se.sum_exec_runtime),
 +		SPLIT_NS(p->se.statistics.sum_sleep_runtime));
 +#else
++=======
+ 
++>>>>>>> 9c57259117b9 (sched/debug: Fix /proc/sched_debug regression)
  	SEQ_printf(m, "%9Ld.%06ld %9Ld.%06ld %9Ld.%06ld",
- 		0LL, 0L,
+ 		SPLIT_NS(schedstat_val(p, se.statistics.wait_sum)),
  		SPLIT_NS(p->se.sum_exec_runtime),
- 		0LL, 0L);
- #endif
+ 		SPLIT_NS(schedstat_val(p, se.statistics.sum_sleep_runtime)));
+ 
  #ifdef CONFIG_NUMA_BALANCING
 -	SEQ_printf(m, " %d %d", task_node(p), task_numa_group_id(p));
 +	SEQ_printf(m, " %d", cpu_to_node(task_cpu(p)));
  #endif
  #ifdef CONFIG_CGROUP_SCHED
  	SEQ_printf(m, " %s", task_group_path(task_group(p)));
diff --cc kernel/sched/stats.h
index 17d7065c3872,78955cbea31c..000000000000
--- a/kernel/sched/stats.h
+++ b/kernel/sched/stats.h
@@@ -29,9 -29,12 +29,18 @@@ rq_sched_info_dequeued(struct rq *rq, u
  	if (rq)
  		rq->rq_sched_info.run_delay += delta;
  }
++<<<<<<< HEAD
 +# define schedstat_inc(rq, field)	do { (rq)->field++; } while (0)
 +# define schedstat_add(rq, field, amt)	do { (rq)->field += (amt); } while (0)
 +# define schedstat_set(var, val)	do { var = (val); } while (0)
++=======
+ # define schedstat_enabled()		static_branch_unlikely(&sched_schedstats)
+ # define schedstat_inc(rq, field)	do { if (schedstat_enabled()) { (rq)->field++; } } while (0)
+ # define schedstat_add(rq, field, amt)	do { if (schedstat_enabled()) { (rq)->field += (amt); } } while (0)
+ # define schedstat_set(var, val)	do { if (schedstat_enabled()) { var = (val); } } while (0)
+ # define schedstat_val(rq, field)	((schedstat_enabled()) ? (rq)->field : 0)
+ 
++>>>>>>> 9c57259117b9 (sched/debug: Fix /proc/sched_debug regression)
  #else /* !CONFIG_SCHEDSTATS */
  static inline void
  rq_sched_info_arrive(struct rq *rq, unsigned long long delta)
@@@ -45,9 -48,11 +54,10 @@@ rq_sched_info_depart(struct rq *rq, uns
  # define schedstat_inc(rq, field)	do { } while (0)
  # define schedstat_add(rq, field, amt)	do { } while (0)
  # define schedstat_set(var, val)	do { } while (0)
+ # define schedstat_val(rq, field)	0
  #endif
  
 -#ifdef CONFIG_SCHED_INFO
 +#if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
  static inline void sched_info_reset_dequeued(struct task_struct *t)
  {
  	t->sched_info.last_queued = 0;
* Unmerged path kernel/sched/debug.c
* Unmerged path kernel/sched/stats.h
