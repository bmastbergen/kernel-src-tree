nvme: split a new struct nvme_ctrl out of struct nvme_dev

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Christoph Hellwig <hch@lst.de>
commit 1c63dc66580d4bbb6d2b75bf184b5aa105ba5bdb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/1c63dc66.failed

The new struct nvme_ctrl will be used by the common NVMe code that sits
on top of struct request_queue and the new nvme_ctrl_ops abstraction.
It only contains the bare minimum required, which consists of values
sampled during controller probe, the admin queue pointer and a second
struct device pointer at the moment, but more will follow later.  Only
values that are not used in the I/O fast path should be moved to
struct nvme_ctrl so that drivers can optimize their cache line usage
easily.  That's also the reason why we have two device pointers as
the struct device is used for DMA mapping purposes.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Acked-by: Keith Busch <keith.busch@intel.com>
	Signed-off-by: Keith Busch <keith.busch@intel.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 1c63dc66580d4bbb6d2b75bf184b5aa105ba5bdb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/block/nvme-core.c
#	drivers/block/nvme-scsi.c
#	drivers/nvme/host/core.c
#	drivers/nvme/host/nvme.h
diff --cc drivers/block/nvme-core.c
index 2a6eb55ad96c,8a564f4ecf99..000000000000
--- a/drivers/block/nvme-core.c
+++ b/drivers/block/nvme-core.c
@@@ -81,9 -87,13 +81,16 @@@ static wait_queue_head_t nvme_kthread_w
  
  static struct class *nvme_class;
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +static void nvme_reset_failed_dev(struct work_struct *ws);
++=======
+ struct nvme_dev;
+ struct nvme_queue;
+ 
+ static int __nvme_reset(struct nvme_dev *dev);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  static int nvme_reset(struct nvme_dev *dev);
 -static void nvme_process_cq(struct nvme_queue *nvmeq);
 -static void nvme_dead_ctrl(struct nvme_dev *dev);
 +static int nvme_process_cq(struct nvme_queue *nvmeq);
  
  struct async_cmd_info {
  	struct kthread_work work;
@@@ -943,7 -1097,8 +993,12 @@@ static int nvme_submit_async_admin_req(
  	struct nvme_cmd_info *cmd_info;
  	struct request *req;
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	req = blk_mq_alloc_request(dev->admin_q, WRITE, GFP_ATOMIC, true);
++=======
+ 	req = blk_mq_alloc_request(dev->ctrl.admin_q, WRITE,
+ 			BLK_MQ_REQ_NOWAIT | BLK_MQ_REQ_RESERVED);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  	if (IS_ERR(req))
  		return PTR_ERR(req);
  
@@@ -968,7 -1123,7 +1023,11 @@@ static int nvme_submit_admin_async_cmd(
  	struct request *req;
  	struct nvme_cmd_info *cmd_rq;
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	req = blk_mq_alloc_request(dev->admin_q, WRITE, GFP_KERNEL, false);
++=======
+ 	req = blk_mq_alloc_request(dev->ctrl.admin_q, WRITE, 0);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  	if (IS_ERR(req))
  		return PTR_ERR(req);
  
@@@ -992,7 -1147,7 +1051,11 @@@ static int adapter_delete_queue(struct 
  	c.delete_queue.opcode = opcode;
  	c.delete_queue.qid = cpu_to_le16(id);
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	return nvme_submit_sync_cmd(dev->admin_q, &c);
++=======
+ 	return nvme_submit_sync_cmd(dev->ctrl.admin_q, &c, NULL, 0);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  }
  
  static int adapter_alloc_cq(struct nvme_dev *dev, u16 qid,
@@@ -1009,7 -1168,7 +1072,11 @@@
  	c.create_cq.cq_flags = cpu_to_le16(flags);
  	c.create_cq.irq_vector = cpu_to_le16(nvmeq->cq_vector);
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	return nvme_submit_sync_cmd(dev->admin_q, &c);
++=======
+ 	return nvme_submit_sync_cmd(dev->ctrl.admin_q, &c, NULL, 0);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  }
  
  static int adapter_alloc_sq(struct nvme_dev *dev, u16 qid,
@@@ -1026,7 -1189,7 +1093,11 @@@
  	c.create_sq.sq_flags = cpu_to_le16(flags);
  	c.create_sq.cqid = cpu_to_le16(qid);
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	return nvme_submit_sync_cmd(dev->admin_q, &c);
++=======
+ 	return nvme_submit_sync_cmd(dev->ctrl.admin_q, &c, NULL, 0);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  }
  
  static int adapter_delete_cq(struct nvme_dev *dev, u16 cqid)
@@@ -1113,11 -1228,11 +1184,16 @@@ static void nvme_abort_req(struct reque
  		return;
  	}
  
- 	if (!dev->abort_limit)
+ 	if (!dev->ctrl.abort_limit)
  		return;
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	abort_req = blk_mq_alloc_request(dev->admin_q, WRITE, GFP_ATOMIC,
 +									false);
++=======
+ 	abort_req = blk_mq_alloc_request(dev->ctrl.admin_q, WRITE,
+ 			BLK_MQ_REQ_NOWAIT);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  	if (IS_ERR(abort_req))
  		return;
  
@@@ -1270,21 -1426,18 +1346,21 @@@ static struct nvme_queue *nvme_alloc_qu
  	if (!nvmeq)
  		return NULL;
  
 -	nvmeq->cqes = dma_zalloc_coherent(dev->dev, CQ_SIZE(depth),
 -					  &nvmeq->cq_dma_addr, GFP_KERNEL);
 +	nvmeq->cqes = dma_alloc_coherent(dmadev, CQ_SIZE(depth),
 +					&nvmeq->cq_dma_addr, GFP_KERNEL);
  	if (!nvmeq->cqes)
  		goto free_nvmeq;
 +	memset((void *)nvmeq->cqes, 0, CQ_SIZE(depth));
  
 -	if (nvme_alloc_sq_cmds(dev, nvmeq, qid, depth))
 +	nvmeq->sq_cmds = dma_alloc_coherent(dmadev, SQ_SIZE(depth),
 +					&nvmeq->sq_dma_addr, GFP_KERNEL);
 +	if (!nvmeq->sq_cmds)
  		goto free_cqdma;
  
 -	nvmeq->q_dmadev = dev->dev;
 +	nvmeq->q_dmadev = dmadev;
  	nvmeq->dev = dev;
  	snprintf(nvmeq->irqname, sizeof(nvmeq->irqname), "nvme%dq%d",
- 			dev->instance, qid);
+ 			dev->ctrl.instance, qid);
  	spin_lock_init(&nvmeq->q_lock);
  	nvmeq->cq_head = 0;
  	nvmeq->cq_phase = 1;
@@@ -1472,8 -1626,8 +1548,13 @@@ static int nvme_alloc_admin_tags(struc
  		if (blk_mq_alloc_tag_set(&dev->admin_tagset))
  			return -ENOMEM;
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +		dev->admin_q = blk_mq_init_queue(&dev->admin_tagset);
 +		if (!dev->admin_q) {
++=======
+ 		dev->ctrl.admin_q = blk_mq_init_queue(&dev->admin_tagset);
+ 		if (IS_ERR(dev->ctrl.admin_q)) {
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  			blk_mq_free_tag_set(&dev->admin_tagset);
  			return -ENOMEM;
  		}
@@@ -1562,88 -1714,16 +1643,88 @@@ static int nvme_configure_admin_queue(s
  	return result;
  }
  
 +struct nvme_iod *nvme_map_user_pages(struct nvme_dev *dev, int write,
 +				unsigned long addr, unsigned length)
 +{
 +	int i, err, count, nents, offset;
 +	struct scatterlist *sg;
 +	struct page **pages;
 +	struct nvme_iod *iod;
 +
 +	if (addr & 3)
 +		return ERR_PTR(-EINVAL);
 +	if (!length || length > INT_MAX - PAGE_SIZE)
 +		return ERR_PTR(-EINVAL);
 +
 +	offset = offset_in_page(addr);
 +	count = DIV_ROUND_UP(offset + length, PAGE_SIZE);
 +	pages = kcalloc(count, sizeof(*pages), GFP_KERNEL);
 +	if (!pages)
 +		return ERR_PTR(-ENOMEM);
 +
 +	err = get_user_pages_fast(addr, count, 1, pages);
 +	if (err < count) {
 +		count = err;
 +		err = -EFAULT;
 +		goto put_pages;
 +	}
 +
 +	err = -ENOMEM;
 +	iod = __nvme_alloc_iod(count, length, dev, 0, GFP_KERNEL);
 +	if (!iod)
 +		goto put_pages;
 +
 +	sg = iod->sg;
 +	sg_init_table(sg, count);
 +	for (i = 0; i < count; i++) {
 +		sg_set_page(&sg[i], pages[i],
 +			    min_t(unsigned, length, PAGE_SIZE - offset),
 +			    offset);
 +		length -= (PAGE_SIZE - offset);
 +		offset = 0;
 +	}
 +	sg_mark_end(&sg[i - 1]);
 +	iod->nents = count;
 +
 +	nents = dma_map_sg(&dev->pci_dev->dev, sg, count,
 +				write ? DMA_TO_DEVICE : DMA_FROM_DEVICE);
 +	if (!nents)
 +		goto free_iod;
 +
 +	kfree(pages);
 +	return iod;
 +
 + free_iod:
 +	kfree(iod);
 + put_pages:
 +	for (i = 0; i < count; i++)
 +		put_page(pages[i]);
 +	kfree(pages);
 +	return ERR_PTR(err);
 +}
 +
 +void nvme_unmap_user_pages(struct nvme_dev *dev, int write,
 +			struct nvme_iod *iod)
 +{
 +	int i;
 +
 +	dma_unmap_sg(&dev->pci_dev->dev, iod->sg, iod->nents,
 +				write ? DMA_TO_DEVICE : DMA_FROM_DEVICE);
 +
 +	for (i = 0; i < iod->nents; i++)
 +		put_page(sg_page(&iod->sg[i]));
 +}
 +
  static int nvme_submit_io(struct nvme_ns *ns, struct nvme_user_io __user *uio)
  {
- 	struct nvme_dev *dev = ns->dev;
+ 	struct nvme_dev *dev = to_nvme_dev(ns->ctrl);
  	struct nvme_user_io io;
  	struct nvme_command c;
 -	unsigned length, meta_len;
 +	unsigned length, meta_len, prp_len;
  	int status, write;
 +	struct nvme_iod *iod;
  	dma_addr_t meta_dma = 0;
  	void *meta = NULL;
 -	void __user *metadata;
  
  	if (copy_from_user(&io, uio, sizeof(io)))
  		return -EFAULT;
@@@ -1750,38 -1817,17 +1831,47 @@@ static int nvme_user_cmd(struct nvme_ct
  	c.common.cdw10[4] = cpu_to_le32(cmd.cdw14);
  	c.common.cdw10[5] = cpu_to_le32(cmd.cdw15);
  
 -	if (cmd.timeout_ms)
 -		timeout = msecs_to_jiffies(cmd.timeout_ms);
 +	length = cmd.data_len;
 +	if (cmd.data_len) {
 +		iod = nvme_map_user_pages(dev, cmd.opcode & 1, cmd.addr,
 +								length);
 +		if (IS_ERR(iod))
 +			return PTR_ERR(iod);
 +		length = nvme_setup_prps(dev, iod, length, GFP_KERNEL);
 +		c.common.prp1 = cpu_to_le64(sg_dma_address(iod->sg));
 +		c.common.prp2 = cpu_to_le64(iod->first_dma);
 +	}
 +
 +	timeout = cmd.timeout_ms ? msecs_to_jiffies(cmd.timeout_ms) :
 +								ADMIN_TIMEOUT;
  
 +	if (length != cmd.data_len) {
 +		status = -ENOMEM;
 +		goto out;
 +	}
 +
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	status = __nvme_submit_sync_cmd(ns ? ns->queue : dev->admin_q, &c,
 +					&cmd.result, timeout);
 +
 +out:
 +	if (cmd.data_len) {
 +		nvme_unmap_user_pages(dev, cmd.opcode & 1, iod);
 +		nvme_free_iod(dev, iod);
++=======
+ 	status = __nvme_submit_sync_cmd(ns ? ns->queue : ctrl->admin_q, &c,
+ 			NULL, (void __user *)(uintptr_t)cmd.addr, cmd.data_len,
+ 			&cmd.result, timeout);
+ 	if (status >= 0) {
+ 		if (put_user(cmd.result, &ucmd->result))
+ 			return -EFAULT;
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  	}
  
 +	if ((status >= 0) && copy_to_user(&ucmd->result, &cmd.result,
 +							sizeof(cmd.result)))
 +		status = -EFAULT;
 +
  	return status;
  }
  
@@@ -1836,7 -1882,11 +1926,8 @@@ static void nvme_free_dev(struct kref *
  static void nvme_free_ns(struct kref *kref)
  {
  	struct nvme_ns *ns = container_of(kref, struct nvme_ns, kref);
+ 	struct nvme_dev *dev = to_nvme_dev(ns->ctrl);
  
 -	if (ns->type == NVME_NS_LIGHTNVM)
 -		nvme_nvm_unregister(ns->queue, ns->disk->disk_name);
 -
  	spin_lock(&dev_list_lock);
  	ns->disk->private_data = NULL;
  	spin_unlock(&dev_list_lock);
@@@ -1890,31 -1940,30 +1981,42 @@@ static void nvme_config_discard(struct 
  static int nvme_revalidate_disk(struct gendisk *disk)
  {
  	struct nvme_ns *ns = disk->private_data;
- 	struct nvme_dev *dev = ns->dev;
+ 	struct nvme_dev *dev = to_nvme_dev(ns->ctrl);
  	struct nvme_id_ns *id;
 -	u8 lbaf, pi_type;
 +	dma_addr_t dma_addr;
 +	u8 lbaf;
  	u16 old_ms;
  	unsigned short bs;
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	id = dma_alloc_coherent(&dev->pci_dev->dev, 4096, &dma_addr,
 +								GFP_KERNEL);
 +	if (!id) {
 +		dev_warn(&dev->pci_dev->dev, "%s: Memory alocation failure\n",
 +								__func__);
 +		return 0;
++=======
+ 	if (nvme_identify_ns(&dev->ctrl, ns->ns_id, &id)) {
+ 		dev_warn(dev->dev, "%s: Identify failure nvme%dn%d\n", __func__,
+ 						dev->ctrl.instance, ns->ns_id);
+ 		return -ENODEV;
+ 	}
+ 	if (id->ncap == 0) {
+ 		kfree(id);
+ 		return -ENODEV;
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  	}
  
 -	if (nvme_nvm_ns_supported(ns, id) && ns->type != NVME_NS_LIGHTNVM) {
 -		if (nvme_nvm_register(ns->queue, disk->disk_name)) {
 -			dev_warn(dev->dev,
 -				"%s: LightNVM init failure\n", __func__);
 -			kfree(id);
 -			return -ENODEV;
 -		}
 -		ns->type = NVME_NS_LIGHTNVM;
 +	if (nvme_identify(dev, ns->ns_id, 0, dma_addr)) {
 +		dev_warn(&dev->pci_dev->dev,
 +			"identify failed ns:%d, setting capacity to 0\n",
 +			ns->ns_id);
 +		memset(id, 0, sizeof(*id));
 +	}
 +
 +	if (id->ncap == 0) {
 +		dma_free_coherent(&dev->pci_dev->dev, 4096, id, dma_addr);
 +		return -ENODEV;
  	}
  
  	old_ms = ns->ms;
@@@ -1950,10 -2004,11 +2052,10 @@@
  	else
  		set_capacity(disk, le64_to_cpup(&id->nsze) << (ns->lba_shift - 9));
  
- 	if (dev->oncs & NVME_CTRL_ONCS_DSM)
+ 	if (dev->ctrl.oncs & NVME_CTRL_ONCS_DSM)
  		nvme_config_discard(ns);
 -	blk_mq_unfreeze_queue(disk->queue);
  
 -	kfree(id);
 +	dma_free_coherent(&dev->pci_dev->dev, 4096, id, dma_addr);
  	return 0;
  }
  
@@@ -2120,8 -2171,7 +2222,12 @@@ static void nvme_alloc_ns(struct nvme_d
  		goto out_free_ns;
  	queue_flag_set_unlocked(QUEUE_FLAG_NOMERGES, ns->queue);
  	queue_flag_set_unlocked(QUEUE_FLAG_NONROT, ns->queue);
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	queue_flag_set_unlocked(QUEUE_FLAG_SG_GAPS, ns->queue);
 +	ns->dev = dev;
++=======
+ 	ns->ctrl = &dev->ctrl;
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  	ns->queue->queuedata = ns;
  
  	disk = alloc_disk_node(0, node);
@@@ -2142,8 -2192,9 +2248,8 @@@
  	}
  	if (dev->stripe_size)
  		blk_queue_chunk_sectors(ns->queue, dev->stripe_size >> 9);
- 	if (dev->vwc & NVME_CTRL_VWC_PRESENT)
+ 	if (dev->ctrl.vwc & NVME_CTRL_VWC_PRESENT)
  		blk_queue_flush(ns->queue, REQ_FLUSH | REQ_FUA);
 -	blk_queue_virt_boundary(ns->queue, dev->page_size - 1);
  
  	disk->major = nvme_major;
  	disk->first_minor = 0;
@@@ -2390,17 -2510,11 +2497,21 @@@ static void nvme_dev_scan(struct work_s
  
  	if (!dev->tagset.tags)
  		return;
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +
 +	mem = dma_alloc_coherent(&dev->pci_dev->dev, 4096, &dma_addr, GFP_KERNEL);
 +	if (!mem)
++=======
+ 	if (nvme_identify_ctrl(&dev->ctrl, &ctrl))
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
 +		return;
 +	if (nvme_identify(dev, 0, 1, dma_addr)) {
 +		dma_free_coherent(&dev->pci_dev->dev, 4096, mem, dma_addr);
  		return;
 +	}
 +	ctrl = mem;
  	nvme_scan_namespaces(dev, le32_to_cpup(&ctrl->nn));
 -	kfree(ctrl);
 -	nvme_set_irq_hints(dev);
 +	dma_free_coherent(&dev->pci_dev->dev, 4096, mem, dma_addr);
  }
  
  /*
@@@ -2411,33 -2525,23 +2522,46 @@@
   */
  static int nvme_dev_add(struct nvme_dev *dev)
  {
 -	struct pci_dev *pdev = to_pci_dev(dev->dev);
 +	struct pci_dev *pdev = dev->pci_dev;
  	int res;
 +	unsigned nn;
  	struct nvme_id_ctrl *ctrl;
 -	int shift = NVME_CAP_MPSMIN(lo_hi_readq(dev->bar + NVME_REG_CAP)) + 12;
 +	void *mem;
 +	dma_addr_t dma_addr;
 +	int shift = NVME_CAP_MPSMIN(readq(&dev->bar->cap)) + 12;
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	mem = dma_alloc_coherent(&pdev->dev, 4096, &dma_addr, GFP_KERNEL);
 +	if (!mem)
 +		return -ENOMEM;
 +
 +	res = nvme_identify(dev, 0, 1, dma_addr);
++=======
+ 	res = nvme_identify_ctrl(&dev->ctrl, &ctrl);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  	if (res) {
 -		dev_err(dev->dev, "Identify Controller failed (%d)\n", res);
 +		dev_err(&pdev->dev, "Identify Controller failed (%d)\n", res);
 +		dma_free_coherent(&dev->pci_dev->dev, 4096, mem, dma_addr);
  		return -EIO;
  	}
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	ctrl = mem;
 +	nn = le32_to_cpup(&ctrl->nn);
 +	dev->oncs = le16_to_cpup(&ctrl->oncs);
 +	dev->abort_limit = ctrl->acl + 1;
 +	dev->vwc = ctrl->vwc;
 +	memcpy(dev->serial, ctrl->sn, sizeof(ctrl->sn));
 +	memcpy(dev->model, ctrl->mn, sizeof(ctrl->mn));
 +	memcpy(dev->firmware_rev, ctrl->fr, sizeof(ctrl->fr));
++=======
+ 	dev->ctrl.oncs = le16_to_cpup(&ctrl->oncs);
+ 	dev->ctrl.abort_limit = ctrl->acl + 1;
+ 	dev->ctrl.vwc = ctrl->vwc;
+ 	memcpy(dev->ctrl.serial, ctrl->sn, sizeof(ctrl->sn));
+ 	memcpy(dev->ctrl.model, ctrl->mn, sizeof(ctrl->mn));
+ 	memcpy(dev->ctrl.firmware_rev, ctrl->fr, sizeof(ctrl->fr));
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  	if (ctrl->mdts)
  		dev->max_hw_sectors = 1 << (ctrl->mdts + shift - 9);
  	else
@@@ -2666,10 -2776,10 +2790,10 @@@ static void nvme_disable_io_queues(stru
  	DEFINE_KTHREAD_WORKER_ONSTACK(worker);
  	struct nvme_delq_ctx dq;
  	struct task_struct *kworker_task = kthread_run(kthread_worker_fn,
- 					&worker, "nvme%d", dev->instance);
+ 					&worker, "nvme%d", dev->ctrl.instance);
  
  	if (IS_ERR(kworker_task)) {
 -		dev_err(dev->dev,
 +		dev_err(&dev->pci_dev->dev,
  			"Failed to create queue del task\n");
  		for (i = dev->queue_count - 1; i > 0; i--)
  			nvme_disable_queue(dev, i);
@@@ -2889,9 -2998,9 +3013,9 @@@ static long nvme_dev_ioctl(struct file 
  		if (list_empty(&dev->namespaces))
  			return -ENOTTY;
  		ns = list_first_entry(&dev->namespaces, struct nvme_ns, list);
- 		return nvme_user_cmd(dev, ns, (void __user *)arg);
+ 		return nvme_user_cmd(&dev->ctrl, ns, (void __user *)arg);
  	case NVME_IOCTL_RESET:
 -		dev_warn(dev->dev, "resetting controller\n");
 +		dev_warn(&dev->pci_dev->dev, "resetting controller\n");
  		return nvme_reset(dev);
  	case NVME_IOCTL_SUBSYS_RESET:
  		return nvme_subsys_reset(dev);
@@@ -2965,10 -3059,21 +3089,28 @@@ static int nvme_dev_start(struct nvme_d
  	if (result)
  		goto free_tags;
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	nvme_set_irq_hints(dev);
 +
 +	dev->event_limit = 1;
 +	return result;
++=======
+ 	dev->ctrl.event_limit = 1;
+ 
+ 	/*
+ 	 * Keep the controller around but remove all namespaces if we don't have
+ 	 * any working I/O queue.
+ 	 */
+ 	if (dev->online_queues < 2) {
+ 		dev_warn(dev->dev, "IO queues not created\n");
+ 		nvme_dev_remove(dev);
+ 	} else {
+ 		nvme_unfreeze_queues(dev);
+ 		nvme_dev_add(dev);
+ 	}
+ 
+ 	return;
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  
   free_tags:
  	nvme_dev_remove_admin(dev);
@@@ -2994,41 -3101,13 +3136,46 @@@ static int nvme_remove_dead_ctrl(void *
  	return 0;
  }
  
 +static void nvme_remove_disks(struct work_struct *ws)
 +{
 +	struct nvme_dev *dev = container_of(ws, struct nvme_dev, reset_work);
 +
 +	nvme_free_queues(dev, 1);
 +	nvme_dev_remove(dev);
 +}
 +
 +static int nvme_dev_resume(struct nvme_dev *dev)
 +{
 +	int ret;
 +
 +	ret = nvme_dev_start(dev);
 +	if (ret)
 +		return ret;
 +	if (dev->online_queues < 2) {
 +		spin_lock(&dev_list_lock);
 +		PREPARE_WORK(&dev->reset_work, nvme_remove_disks);
 +		queue_work(nvme_workq, &dev->reset_work);
 +		spin_unlock(&dev_list_lock);
 +	} else {
 +		nvme_unfreeze_queues(dev);
 +		nvme_dev_add(dev);
 +		nvme_set_irq_hints(dev);
 +	}
 +	return 0;
 +}
 +
  static void nvme_dead_ctrl(struct nvme_dev *dev)
  {
 -	dev_warn(dev->dev, "Device failed to resume\n");
 +	dev_warn(&dev->pci_dev->dev, "Device failed to resume\n");
  	kref_get(&dev->kref);
  	if (IS_ERR(kthread_run(nvme_remove_dead_ctrl, dev, "nvme%d",
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +						dev->instance))) {
 +		dev_err(&dev->pci_dev->dev,
++=======
+ 						dev->ctrl.instance))) {
+ 		dev_err(dev->dev,
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  			"Failed to start controller remove task\n");
  		kref_put(&dev->kref, nvme_free_dev);
  	}
@@@ -3063,9 -3146,9 +3210,9 @@@ static void nvme_reset_failed_dev(struc
  
  static int nvme_reset(struct nvme_dev *dev)
  {
 -	int ret;
 +	int ret = -EBUSY;
  
- 	if (!dev->admin_q || blk_queue_dying(dev->admin_q))
+ 	if (!dev->ctrl.admin_q || blk_queue_dying(dev->ctrl.admin_q))
  		return -ENODEV;
  
  	spin_lock(&dev_list_lock);
@@@ -3100,7 -3179,16 +3247,20 @@@ static ssize_t nvme_sysfs_reset(struct 
  }
  static DEVICE_ATTR(reset_controller, S_IWUSR, NULL, nvme_sysfs_reset);
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +static void nvme_async_probe(struct work_struct *work);
++=======
+ static int nvme_pci_reg_read32(struct nvme_ctrl *ctrl, u32 off, u32 *val)
+ {
+ 	*val = readl(to_nvme_dev(ctrl)->bar + off);
+ 	return 0;
+ }
+ 
+ static const struct nvme_ctrl_ops nvme_pci_ctrl_ops = {
+ 	.reg_read32		= nvme_pci_reg_read32,
+ };
+ 
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/pci.c
  static int nvme_probe(struct pci_dev *pdev, const struct pci_device_id *id)
  {
  	int node, result = -ENOMEM;
@@@ -3123,9 -3211,13 +3283,13 @@@
  		goto free;
  
  	INIT_LIST_HEAD(&dev->namespaces);
 -	INIT_WORK(&dev->reset_work, nvme_reset_work);
 -	dev->dev = get_device(&pdev->dev);
 +	INIT_WORK(&dev->reset_work, nvme_reset_failed_dev);
 +	dev->pci_dev = pci_dev_get(pdev);
  	pci_set_drvdata(pdev, dev);
+ 
+ 	dev->ctrl.ops = &nvme_pci_ctrl_ops;
+ 	dev->ctrl.dev = dev->dev;
+ 
  	result = nvme_set_instance(dev);
  	if (result)
  		goto put_pci;
@@@ -3211,8 -3295,9 +3375,8 @@@ static void nvme_remove(struct pci_dev 
  	nvme_dev_remove(dev);
  	nvme_dev_shutdown(dev);
  	nvme_dev_remove_admin(dev);
- 	device_destroy(nvme_class, MKDEV(nvme_char_major, dev->instance));
+ 	device_destroy(nvme_class, MKDEV(nvme_char_major, dev->ctrl.instance));
  	nvme_free_queues(dev, 0);
 -	nvme_release_cmb(dev);
  	nvme_release_prp_pools(dev);
  	kref_put(&dev->kref, nvme_free_dev);
  }
diff --cc drivers/block/nvme-scsi.c
index daa0d50b3bfd,bba29553bc94..000000000000
--- a/drivers/block/nvme-scsi.c
+++ b/drivers/block/nvme-scsi.c
@@@ -524,9 -524,7 +524,13 @@@ static int nvme_trans_standard_inquiry_
  					struct sg_io_hdr *hdr, u8 *inq_response,
  					int alloc_len)
  {
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	struct nvme_dev *dev = ns->dev;
 +	dma_addr_t dma_addr;
 +	void *mem;
++=======
+ 	struct nvme_ctrl *ctrl = ns->ctrl;
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	struct nvme_id_ns *id_ns;
  	int res;
  	int nvme_sc;
@@@ -534,23 -532,19 +538,27 @@@
  	u8 resp_data_format = 0x02;
  	u8 protect;
  	u8 cmdque = 0x01 << 1;
- 	u8 fw_offset = sizeof(dev->firmware_rev);
+ 	u8 fw_offset = sizeof(ctrl->firmware_rev);
  
 +	mem = dma_alloc_coherent(&dev->pci_dev->dev, sizeof(struct nvme_id_ns),
 +				&dma_addr, GFP_KERNEL);
 +	if (mem == NULL) {
 +		res = -ENOMEM;
 +		goto out_dma;
 +	}
 +
  	/* nvme ns identify - use DPS value for PROTECT field */
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	nvme_sc = nvme_identify(dev, ns->ns_id, 0, dma_addr);
++=======
+ 	nvme_sc = nvme_identify_ns(ctrl, ns->ns_id, &id_ns);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	res = nvme_trans_status_code(hdr, nvme_sc);
  	if (res)
 -		return res;
 +		goto out_free;
  
 -	if (id_ns->dps)
 -		protect = 0x01;
 -	else
 -		protect = 0;
 -	kfree(id_ns);
 +	id_ns = mem;
 +	(id_ns->dps) ? (protect = 0x01) : (protect = 0);
  
  	memset(inq_response, 0, STANDARD_INQUIRY_LENGTH);
  	inq_response[2] = VERSION_SPC_4;
@@@ -559,21 -553,15 +567,21 @@@
  	inq_response[5] = protect;	/* sccs=0 | acc=0 | tpgs=0 | pc3=0 */
  	inq_response[7] = cmdque;	/* wbus16=0 | sync=0 | vs=0 */
  	strncpy(&inq_response[8], "NVMe    ", 8);
- 	strncpy(&inq_response[16], dev->model, 16);
+ 	strncpy(&inq_response[16], ctrl->model, 16);
  
- 	while (dev->firmware_rev[fw_offset - 1] == ' ' && fw_offset > 4)
+ 	while (ctrl->firmware_rev[fw_offset - 1] == ' ' && fw_offset > 4)
  		fw_offset--;
  	fw_offset -= 4;
- 	strncpy(&inq_response[32], dev->firmware_rev + fw_offset, 4);
+ 	strncpy(&inq_response[32], ctrl->firmware_rev + fw_offset, 4);
  
  	xfer_len = min(alloc_len, STANDARD_INQUIRY_LENGTH);
 -	return nvme_trans_copy_to_user(hdr, inq_response, xfer_len);
 +	res = nvme_trans_copy_to_user(hdr, inq_response, xfer_len);
 +
 + out_free:
 +	dma_free_coherent(&dev->pci_dev->dev, sizeof(struct nvme_id_ns), mem,
 +			  dma_addr);
 + out_dma:
 +	return res;
  }
  
  static int nvme_trans_supported_vpd_pages(struct nvme_ns *ns,
@@@ -612,81 -599,107 +619,167 @@@ static int nvme_trans_unit_serial_page(
  	return nvme_trans_copy_to_user(hdr, inq_response, xfer_len);
  }
  
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +static int nvme_trans_device_id_page(struct nvme_ns *ns, struct sg_io_hdr *hdr,
 +					u8 *inq_response, int alloc_len)
 +{
 +	struct nvme_dev *dev = ns->dev;
 +	dma_addr_t dma_addr;
 +	void *mem;
 +	int res;
 +	int nvme_sc;
 +	int xfer_len;
 +	__be32 tmp_id = cpu_to_be32(ns->ns_id);
++=======
+ static int nvme_fill_device_id_eui64(struct nvme_ns *ns, struct sg_io_hdr *hdr,
+ 		u8 *inq_response, int alloc_len, u32 vs)
+ {
+ 	struct nvme_id_ns *id_ns;
+ 	int nvme_sc, res;
+ 	size_t len;
+ 	void *eui;
+ 
+ 	nvme_sc = nvme_identify_ns(ns->ctrl, ns->ns_id, &id_ns);
+ 	res = nvme_trans_status_code(hdr, nvme_sc);
+ 	if (res)
+ 		return res;
+ 
+ 	eui = id_ns->eui64;
+ 	len = sizeof(id_ns->eui64);
+ 
+ 	if (vs >= NVME_VS(1, 2)) {
+ 		if (bitmap_empty(eui, len * 8)) {
+ 			eui = id_ns->nguid;
+ 			len = sizeof(id_ns->nguid);
+ 		}
+ 	}
+ 
+ 	if (bitmap_empty(eui, len * 8)) {
+ 		res = -EOPNOTSUPP;
+ 		goto out_free_id;
+ 	}
+ 
+ 	memset(inq_response, 0, alloc_len);
+ 	inq_response[1] = INQ_DEVICE_IDENTIFICATION_PAGE;
+ 	inq_response[3] = 4 + len; /* Page Length */
+ 
+ 	/* Designation Descriptor start */
+ 	inq_response[4] = 0x01;	/* Proto ID=0h | Code set=1h */
+ 	inq_response[5] = 0x02;	/* PIV=0b | Asso=00b | Designator Type=2h */
+ 	inq_response[6] = 0x00;	/* Rsvd */
+ 	inq_response[7] = len;	/* Designator Length */
+ 	memcpy(&inq_response[8], eui, len);
+ 
+ 	res = nvme_trans_copy_to_user(hdr, inq_response, alloc_len);
+ out_free_id:
+ 	kfree(id_ns);
+ 	return res;
+ }
+ 
+ static int nvme_fill_device_id_scsi_string(struct nvme_ns *ns,
+ 		struct sg_io_hdr *hdr, u8 *inq_response, int alloc_len)
+ {
+ 	struct nvme_ctrl *ctrl = ns->ctrl;
+ 	struct nvme_id_ctrl *id_ctrl;
+ 	int nvme_sc, res;
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  
 -	if (alloc_len < 72) {
 -		return nvme_trans_completion(hdr,
 -				SAM_STAT_CHECK_CONDITION,
 -				ILLEGAL_REQUEST, SCSI_ASC_INVALID_CDB,
 -				SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
 +	mem = dma_alloc_coherent(&dev->pci_dev->dev, sizeof(struct nvme_id_ns),
 +					&dma_addr, GFP_KERNEL);
 +	if (mem == NULL) {
 +		res = -ENOMEM;
 +		goto out_dma;
  	}
  
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
++=======
+ 	nvme_sc = nvme_identify_ctrl(ctrl, &id_ctrl);
+ 	res = nvme_trans_status_code(hdr, nvme_sc);
+ 	if (res)
+ 		return res;
+ 
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	memset(inq_response, 0, alloc_len);
 -	inq_response[1] = INQ_DEVICE_IDENTIFICATION_PAGE;
 -	inq_response[3] = 0x48;	/* Page Length */
 +	inq_response[1] = INQ_DEVICE_IDENTIFICATION_PAGE;    /* Page Code */
 +	if (readl(&dev->bar->vs) >= NVME_VS(1, 1)) {
 +		struct nvme_id_ns *id_ns = mem;
 +		void *eui = id_ns->eui64;
 +		int len = sizeof(id_ns->eui64);
  
 -	/* Designation Descriptor start */
 -	inq_response[4] = 0x03;	/* Proto ID=0h | Code set=3h */
 -	inq_response[5] = 0x08;	/* PIV=0b | Asso=00b | Designator Type=8h */
 -	inq_response[6] = 0x00;	/* Rsvd */
 -	inq_response[7] = 0x44;	/* Designator Length */
 +		nvme_sc = nvme_identify(dev, ns->ns_id, 0, dma_addr);
 +		res = nvme_trans_status_code(hdr, nvme_sc);
 +		if (res)
 +			goto out_free;
  
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +		if (readl(&dev->bar->vs) >= NVME_VS(1, 2)) {
 +			if (bitmap_empty(eui, len * 8)) {
 +				eui = id_ns->nguid;
 +				len = sizeof(id_ns->nguid);
 +			}
 +		}
 +		if (bitmap_empty(eui, len * 8))
 +			goto scsi_string;
++=======
+ 	sprintf(&inq_response[8], "%04x", le16_to_cpu(id_ctrl->vid));
+ 	memcpy(&inq_response[12], ctrl->model, sizeof(ctrl->model));
+ 	sprintf(&inq_response[52], "%04x", cpu_to_be32(ns->ns_id));
+ 	memcpy(&inq_response[56], ctrl->serial, sizeof(ctrl->serial));
 -
 -	res = nvme_trans_copy_to_user(hdr, inq_response, alloc_len);
 -	kfree(id_ctrl);
 -	return res;
 -}
 -
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
 +
 +		inq_response[3] = 4 + len; /* Page Length */
 +		/* Designation Descriptor start */
 +		inq_response[4] = 0x01;    /* Proto ID=0h | Code set=1h */
 +		inq_response[5] = 0x02;    /* PIV=0b | Asso=00b | Designator Type=2h */
 +		inq_response[6] = 0x00;    /* Rsvd */
 +		inq_response[7] = len;     /* Designator Length */
 +		memcpy(&inq_response[8], eui, len);
 +	} else {
 + scsi_string:
 +		if (alloc_len < 72) {
 +			res = nvme_trans_completion(hdr,
 +					SAM_STAT_CHECK_CONDITION,
 +					ILLEGAL_REQUEST, SCSI_ASC_INVALID_CDB,
 +					SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
 +			goto out_free;
 +		}
 +		inq_response[3] = 0x48;    /* Page Length */
 +		/* Designation Descriptor start */
 +		inq_response[4] = 0x03;    /* Proto ID=0h | Code set=3h */
 +		inq_response[5] = 0x08;    /* PIV=0b | Asso=00b | Designator Type=8h */
 +		inq_response[6] = 0x00;    /* Rsvd */
 +		inq_response[7] = 0x44;    /* Designator Length */
 +
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +		sprintf(&inq_response[8], "%04x", dev->pci_dev->vendor);
 +		memcpy(&inq_response[12], dev->model, sizeof(dev->model));
 +		sprintf(&inq_response[52], "%04x", tmp_id);
 +		memcpy(&inq_response[56], dev->serial, sizeof(dev->serial));
++=======
+ static int nvme_trans_device_id_page(struct nvme_ns *ns, struct sg_io_hdr *hdr,
+ 					u8 *resp, int alloc_len)
+ {
+ 	int res;
+ 	u32 vs;
+ 
+ 	res = ns->ctrl->ops->reg_read32(ns->ctrl, NVME_REG_VS, &vs);
+ 	if (res)
+ 		return res;
+ 
+ 	if (vs >= NVME_VS(1, 1)) {
+ 		res = nvme_fill_device_id_eui64(ns, hdr, resp, alloc_len, vs);
+ 		if (res != -EOPNOTSUPP)
+ 			return res;
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	}
 +	xfer_len = alloc_len;
 +	res = nvme_trans_copy_to_user(hdr, inq_response, xfer_len);
  
 -	return nvme_fill_device_id_scsi_string(ns, hdr, resp, alloc_len);
 + out_free:
 +	dma_free_coherent(&dev->pci_dev->dev, sizeof(struct nvme_id_ns), mem,
 +			  dma_addr);
 + out_dma:
 +	return res;
  }
  
  static int nvme_trans_ext_inq_page(struct nvme_ns *ns, struct sg_io_hdr *hdr,
@@@ -695,9 -708,7 +788,13 @@@
  	u8 *inq_response;
  	int res;
  	int nvme_sc;
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	struct nvme_dev *dev = ns->dev;
 +	dma_addr_t dma_addr;
 +	void *mem;
++=======
+ 	struct nvme_ctrl *ctrl = ns->ctrl;
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	struct nvme_id_ctrl *id_ctrl;
  	struct nvme_id_ns *id_ns;
  	int xfer_len;
@@@ -710,39 -721,32 +807,47 @@@
  	u8 luiclr = 0x01;
  
  	inq_response = kmalloc(EXTENDED_INQUIRY_DATA_PAGE_LENGTH, GFP_KERNEL);
 -	if (inq_response == NULL)
 -		return -ENOMEM;
 +	if (inq_response == NULL) {
 +		res = -ENOMEM;
 +		goto out_mem;
 +	}
  
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	mem = dma_alloc_coherent(&dev->pci_dev->dev, sizeof(struct nvme_id_ns),
 +							&dma_addr, GFP_KERNEL);
 +	if (mem == NULL) {
 +		res = -ENOMEM;
 +		goto out_dma;
 +	}
 +
 +	/* nvme ns identify */
 +	nvme_sc = nvme_identify(dev, ns->ns_id, 0, dma_addr);
++=======
+ 	nvme_sc = nvme_identify_ns(ctrl, ns->ns_id, &id_ns);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	res = nvme_trans_status_code(hdr, nvme_sc);
  	if (res)
 -		goto out_free_inq;
 -
 -	spt = spt_lut[id_ns->dpc & 0x07] << 3;
 -	if (id_ns->dps)
 -		protect = 0x01;
 -	else
 -		protect = 0;
 -	kfree(id_ns);
 +		goto out_free;
  
 +	id_ns = mem;
 +	spt = spt_lut[(id_ns->dpc) & 0x07] << 3;
 +	(id_ns->dps) ? (protect = 0x01) : (protect = 0);
  	grd_chk = protect << 2;
  	app_chk = protect << 1;
  	ref_chk = protect;
  
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	/* nvme controller identify */
 +	nvme_sc = nvme_identify(dev, 0, 1, dma_addr);
++=======
+ 	nvme_sc = nvme_identify_ctrl(ctrl, &id_ctrl);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	res = nvme_trans_status_code(hdr, nvme_sc);
  	if (res)
 -		goto out_free_inq;
 +		goto out_free;
  
 +	id_ctrl = mem;
  	v_sup = id_ctrl->vwc;
 -	kfree(id_ctrl);
  
  	memset(inq_response, 0, EXTENDED_INQUIRY_DATA_PAGE_LENGTH);
  	inq_response[1] = INQ_EXTENDED_INQUIRY_DATA_PAGE;    /* Page Code */
@@@ -851,36 -851,18 +956,45 @@@ static int nvme_trans_log_info_exceptio
  	int res;
  	int xfer_len;
  	u8 *log_response;
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	struct nvme_command c;
 +	struct nvme_dev *dev = ns->dev;
++=======
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	struct nvme_smart_log *smart_log;
 +	dma_addr_t dma_addr;
 +	void *mem;
  	u8 temp_c;
  	u16 temp_k;
  
  	log_response = kzalloc(LOG_INFO_EXCP_PAGE_LENGTH, GFP_KERNEL);
 -	if (log_response == NULL)
 -		return -ENOMEM;
 +	if (log_response == NULL) {
 +		res = -ENOMEM;
 +		goto out_mem;
 +	}
  
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	mem = dma_alloc_coherent(&dev->pci_dev->dev,
 +					sizeof(struct nvme_smart_log),
 +					&dma_addr, GFP_KERNEL);
 +	if (mem == NULL) {
 +		res = -ENOMEM;
 +		goto out_dma;
 +	}
++=======
+ 	res = nvme_get_log_page(ns->ctrl, &smart_log);
+ 	if (res < 0)
+ 		goto out_free_response;
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  
 +	/* Get SMART Log Page */
 +	memset(&c, 0, sizeof(c));
 +	c.common.opcode = nvme_admin_get_log_page;
 +	c.common.nsid = cpu_to_le32(0xFFFFFFFF);
 +	c.common.prp1 = cpu_to_le64(dma_addr);
 +	c.common.cdw10[0] = cpu_to_le32((((sizeof(struct nvme_smart_log) /
 +			BYTES_TO_DWORDS) - 1) << 16) | NVME_LOG_SMART);
 +	res = nvme_submit_sync_cmd(dev->admin_q, &c);
  	if (res != NVME_SC_SUCCESS) {
  		temp_c = LOG_TEMP_UNKNOWN;
  	} else {
@@@ -918,37 -897,19 +1032,46 @@@ static int nvme_trans_log_temperature(s
  	int res;
  	int xfer_len;
  	u8 *log_response;
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	struct nvme_command c;
 +	struct nvme_dev *dev = ns->dev;
++=======
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	struct nvme_smart_log *smart_log;
 +	dma_addr_t dma_addr;
 +	void *mem;
  	u32 feature_resp;
  	u8 temp_c_cur, temp_c_thresh;
  	u16 temp_k;
  
  	log_response = kzalloc(LOG_TEMP_PAGE_LENGTH, GFP_KERNEL);
 -	if (log_response == NULL)
 -		return -ENOMEM;
 +	if (log_response == NULL) {
 +		res = -ENOMEM;
 +		goto out_mem;
 +	}
  
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	mem = dma_alloc_coherent(&dev->pci_dev->dev,
 +					sizeof(struct nvme_smart_log),
 +					&dma_addr, GFP_KERNEL);
 +	if (mem == NULL) {
 +		res = -ENOMEM;
 +		goto out_dma;
 +	}
++=======
+ 	res = nvme_get_log_page(ns->ctrl, &smart_log);
+ 	if (res < 0)
+ 		goto out_free_response;
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  
 +	/* Get SMART Log Page */
 +	memset(&c, 0, sizeof(c));
 +	c.common.opcode = nvme_admin_get_log_page;
 +	c.common.nsid = cpu_to_le32(0xFFFFFFFF);
 +	c.common.prp1 = cpu_to_le64(dma_addr);
 +	c.common.cdw10[0] = cpu_to_le32((((sizeof(struct nvme_smart_log) /
 +			BYTES_TO_DWORDS) - 1) << 16) | NVME_LOG_SMART);
 +	res = nvme_submit_sync_cmd(dev->admin_q, &c);
  	if (res != NVME_SC_SUCCESS) {
  		temp_c_cur = LOG_TEMP_UNKNOWN;
  	} else {
@@@ -957,9 -917,10 +1080,9 @@@
  				(smart_log->temperature[0]);
  		temp_c_cur = temp_k - KELVIN_TEMP_FACTOR;
  	}
 -	kfree(smart_log);
  
  	/* Get Features for Temp Threshold */
- 	res = nvme_get_features(dev, NVME_FEAT_TEMP_THRESH, 0, 0,
+ 	res = nvme_get_features(ns->ctrl, NVME_FEAT_TEMP_THRESH, 0, 0,
  								&feature_resp);
  	if (res != NVME_SC_SUCCESS)
  		temp_c_thresh = LOG_TEMP_UNKNOWN;
@@@ -1024,9 -982,6 +1147,12 @@@ static int nvme_trans_fill_blk_desc(str
  {
  	int res;
  	int nvme_sc;
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	struct nvme_dev *dev = ns->dev;
 +	dma_addr_t dma_addr;
 +	void *mem;
++=======
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	struct nvme_id_ns *id_ns;
  	u8 flbas;
  	u32 lba_length;
@@@ -1036,20 -991,11 +1162,24 @@@
  	else if (llbaa > 0 && len < MODE_PAGE_LLBAA_BLK_DES_LEN)
  		return -EINVAL;
  
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	mem = dma_alloc_coherent(&dev->pci_dev->dev, sizeof(struct nvme_id_ns),
 +							&dma_addr, GFP_KERNEL);
 +	if (mem == NULL) {
 +		res = -ENOMEM;
 +		goto out;
 +	}
 +
 +	/* nvme ns identify */
 +	nvme_sc = nvme_identify(dev, ns->ns_id, 0, dma_addr);
++=======
+ 	nvme_sc = nvme_identify_ns(ns->ctrl, ns->ns_id, &id_ns);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	res = nvme_trans_status_code(hdr, nvme_sc);
  	if (res)
 -		return res;
 +		goto out_dma;
  
 +	id_ns = mem;
  	flbas = (id_ns->flbas) & 0x0F;
  	lba_length = (1 << (id_ns->lbaf[flbas].ds));
  
@@@ -1297,28 -1239,17 +1426,35 @@@ static int nvme_trans_power_state(struc
  {
  	int res;
  	int nvme_sc;
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	struct nvme_dev *dev = ns->dev;
 +	dma_addr_t dma_addr;
 +	void *mem;
++=======
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	struct nvme_id_ctrl *id_ctrl;
  	int lowest_pow_st;	/* max npss = lowest power consumption */
  	unsigned ps_desired = 0;
  
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	/* NVMe Controller Identify */
 +	mem = dma_alloc_coherent(&dev->pci_dev->dev,
 +				sizeof(struct nvme_id_ctrl),
 +				&dma_addr, GFP_KERNEL);
 +	if (mem == NULL) {
 +		res = -ENOMEM;
 +		goto out;
 +	}
 +	nvme_sc = nvme_identify(dev, 0, 1, dma_addr);
++=======
+ 	nvme_sc = nvme_identify_ctrl(ns->ctrl, &id_ctrl);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	res = nvme_trans_status_code(hdr, nvme_sc);
  	if (res)
 -		return res;
 +		goto out_dma;
  
 +	id_ctrl = mem;
  	lowest_pow_st = max(POWER_STATE_0, (int)(id_ctrl->npss - 1));
 -	kfree(id_ctrl);
  
  	switch (pc) {
  	case NVME_POWER_STATE_START_VALID:
@@@ -1356,15 -1287,9 +1492,15 @@@
  				SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
  		break;
  	}
- 	nvme_sc = nvme_set_features(dev, NVME_FEAT_POWER_MGMT, ps_desired, 0,
+ 	nvme_sc = nvme_set_features(ns->ctrl, NVME_FEAT_POWER_MGMT, ps_desired, 0,
  				    NULL);
 -	return nvme_trans_status_code(hdr, nvme_sc);
 +	res = nvme_trans_status_code(hdr, nvme_sc);
 +
 + out_dma:
 +	dma_free_coherent(&dev->pci_dev->dev, sizeof(struct nvme_id_ctrl), mem,
 +			  dma_addr);
 + out:
 +	return res;
  }
  
  static int nvme_trans_send_activate_fw_cmd(struct nvme_ns *ns, struct sg_io_hdr *hdr,
@@@ -1385,15 -1310,8 +1521,14 @@@ static int nvme_trans_send_download_fw_
  					u8 opcode, u32 tot_len, u32 offset,
  					u8 buffer_id)
  {
 +	int res;
  	int nvme_sc;
- 	struct nvme_dev *dev = ns->dev;
  	struct nvme_command c;
 +	struct nvme_iod *iod = NULL;
 +	unsigned length;
 +
 +	memset(&c, 0, sizeof(c));
 +	c.common.opcode = nvme_admin_download_fw;
  
  	if (hdr->iovec_count > 0) {
  		/* Assuming SGL is not allowed for this command */
@@@ -1418,13 -1327,9 +1553,19 @@@
  	c.dlfw.numd = cpu_to_le32((tot_len/BYTES_TO_DWORDS) - 1);
  	c.dlfw.offset = cpu_to_le32(offset/BYTES_TO_DWORDS);
  
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	nvme_sc = nvme_submit_sync_cmd(dev->admin_q, &c);
 +	res = nvme_trans_status_code(hdr, nvme_sc);
 +
 + out_unmap:
 +	nvme_unmap_user_pages(dev, DMA_TO_DEVICE, iod);
 +	nvme_free_iod(dev, iod);
 +	return res;
++=======
+ 	nvme_sc = __nvme_submit_sync_cmd(ns->ctrl->admin_q, &c, NULL,
+ 			hdr->dxferp, tot_len, NULL, 0);
+ 	return nvme_trans_status_code(hdr, nvme_sc);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  }
  
  /* Mode Select Helper Functions */
@@@ -1598,10 -1502,6 +1738,13 @@@ static int nvme_trans_fmt_set_blk_size_
  {
  	int res = 0;
  	int nvme_sc;
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	struct nvme_dev *dev = ns->dev;
 +	dma_addr_t dma_addr;
 +	void *mem;
 +	struct nvme_id_ns *id_ns;
++=======
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	u8 flbas;
  
  	/*
@@@ -1612,19 -1512,12 +1755,25 @@@
  	 */
  
  	if (ns->mode_select_num_blocks == 0 || ns->mode_select_block_len == 0) {
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +		mem = dma_alloc_coherent(&dev->pci_dev->dev,
 +			sizeof(struct nvme_id_ns), &dma_addr, GFP_KERNEL);
 +		if (mem == NULL) {
 +			res = -ENOMEM;
 +			goto out;
 +		}
 +		/* nvme ns identify */
 +		nvme_sc = nvme_identify(dev, ns->ns_id, 0, dma_addr);
++=======
+ 		struct nvme_id_ns *id_ns;
+ 
+ 		nvme_sc = nvme_identify_ns(ns->ctrl, ns->ns_id, &id_ns);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  		res = nvme_trans_status_code(hdr, nvme_sc);
  		if (res)
 -			return res;
 +			goto out_dma;
 +
 +		id_ns = mem;
  
  		if (ns->mode_select_num_blocks == 0)
  			ns->mode_select_num_blocks = le64_to_cpu(id_ns->ncap);
@@@ -1706,9 -1598,6 +1855,12 @@@ static int nvme_trans_fmt_send_cmd(stru
  {
  	int res;
  	int nvme_sc;
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	struct nvme_dev *dev = ns->dev;
 +	dma_addr_t dma_addr;
 +	void *mem;
++=======
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	struct nvme_id_ns *id_ns;
  	u8 i;
  	u8 flbas, nlbaf;
@@@ -1717,19 -1606,11 +1869,23 @@@
  	struct nvme_command c;
  
  	/* Loop thru LBAF's in id_ns to match reqd lbaf, put in cdw10 */
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	mem = dma_alloc_coherent(&dev->pci_dev->dev, sizeof(struct nvme_id_ns),
 +							&dma_addr, GFP_KERNEL);
 +	if (mem == NULL) {
 +		res = -ENOMEM;
 +		goto out;
 +	}
 +	/* nvme ns identify */
 +	nvme_sc = nvme_identify(dev, ns->ns_id, 0, dma_addr);
++=======
+ 	nvme_sc = nvme_identify_ns(ns->ctrl, ns->ns_id, &id_ns);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	res = nvme_trans_status_code(hdr, nvme_sc);
  	if (res)
 -		return res;
 +		goto out_dma;
  
 +	id_ns = mem;
  	flbas = (id_ns->flbas) & 0x0F;
  	nlbaf = id_ns->nlbaf;
  
@@@ -1757,13 -1638,10 +1913,17 @@@
  	c.format.nsid = cpu_to_le32(ns->ns_id);
  	c.format.cdw10 = cpu_to_le32(cdw10);
  
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	nvme_sc = nvme_submit_sync_cmd(dev->admin_q, &c);
++=======
+ 	nvme_sc = nvme_submit_sync_cmd(ns->ctrl->admin_q, &c, NULL, 0);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	res = nvme_trans_status_code(hdr, nvme_sc);
  
 -	kfree(id_ns);
 + out_dma:
 +	dma_free_coherent(&dev->pci_dev->dev, sizeof(struct nvme_id_ns), mem,
 +			  dma_addr);
 + out:
  	return res;
  }
  
@@@ -2209,9 -2067,6 +2369,12 @@@ static int nvme_trans_read_capacity(str
  	u32 alloc_len;
  	u32 resp_size;
  	u32 xfer_len;
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	struct nvme_dev *dev = ns->dev;
 +	dma_addr_t dma_addr;
 +	void *mem;
++=======
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	struct nvme_id_ns *id_ns;
  	u8 *response;
  
@@@ -2223,19 -2078,10 +2386,23 @@@
  		resp_size = READ_CAP_10_RESP_SIZE;
  	}
  
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	mem = dma_alloc_coherent(&dev->pci_dev->dev, sizeof(struct nvme_id_ns),
 +							&dma_addr, GFP_KERNEL);
 +	if (mem == NULL) {
 +		res = -ENOMEM;
 +		goto out;
 +	}
 +	/* nvme ns identify */
 +	nvme_sc = nvme_identify(dev, ns->ns_id, 0, dma_addr);
++=======
+ 	nvme_sc = nvme_identify_ns(ns->ctrl, ns->ns_id, &id_ns);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	res = nvme_trans_status_code(hdr, nvme_sc);
  	if (res)
 -		return res;	
 +		goto out_dma;
 +
 +	id_ns = mem;
  
  	response = kzalloc(resp_size, GFP_KERNEL);
  	if (response == NULL) {
@@@ -2262,9 -2106,6 +2429,12 @@@ static int nvme_trans_report_luns(struc
  	int nvme_sc;
  	u32 alloc_len, xfer_len, resp_size;
  	u8 *response;
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	struct nvme_dev *dev = ns->dev;
 +	dma_addr_t dma_addr;
 +	void *mem;
++=======
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  	struct nvme_id_ctrl *id_ctrl;
  	u32 ll_length, lun_id;
  	u8 lun_id_offset = REPORT_LUNS_FIRST_LUN_OFFSET;
@@@ -2278,20 -2119,11 +2448,24 @@@
  	case ALL_LUNS_RETURNED:
  	case ALL_WELL_KNOWN_LUNS_RETURNED:
  	case RESTRICTED_LUNS_RETURNED:
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +		/* NVMe Controller Identify */
 +		mem = dma_alloc_coherent(&dev->pci_dev->dev,
 +					sizeof(struct nvme_id_ctrl),
 +					&dma_addr, GFP_KERNEL);
 +		if (mem == NULL) {
 +			res = -ENOMEM;
 +			goto out;
 +		}
 +		nvme_sc = nvme_identify(dev, 0, 1, dma_addr);
++=======
+ 		nvme_sc = nvme_identify_ctrl(ns->ctrl, &id_ctrl);
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  		res = nvme_trans_status_code(hdr, nvme_sc);
  		if (res)
 -			return res;
 +			goto out_dma;
  
 +		id_ctrl = mem;
  		ll_length = le32_to_cpu(id_ctrl->nn) * LUN_ENTRY_SIZE;
  		resp_size = ll_length + LUN_DATA_HEADER_SIZE;
  
@@@ -2498,9 -2320,7 +2672,13 @@@ static int nvme_trans_test_unit_ready(s
  					struct sg_io_hdr *hdr,
  					u8 *cmd)
  {
++<<<<<<< HEAD:drivers/block/nvme-scsi.c
 +	struct nvme_dev *dev = ns->dev;
 +
 +	if (!(readl(&dev->bar->csts) & NVME_CSTS_RDY))
++=======
+ 	if (nvme_ctrl_ready(ns->ctrl))
++>>>>>>> 1c63dc66580d (nvme: split a new struct nvme_ctrl out of struct nvme_dev):drivers/nvme/host/scsi.c
  		return nvme_trans_completion(hdr, SAM_STAT_CHECK_CONDITION,
  					    NOT_READY, SCSI_ASC_LUN_NOT_READY,
  					    SCSI_ASCQ_CAUSE_NOT_REPORTABLE);
* Unmerged path drivers/nvme/host/core.c
* Unmerged path drivers/nvme/host/nvme.h
* Unmerged path drivers/block/nvme-core.c
* Unmerged path drivers/block/nvme-scsi.c
* Unmerged path drivers/nvme/host/core.c
* Unmerged path drivers/nvme/host/nvme.h
