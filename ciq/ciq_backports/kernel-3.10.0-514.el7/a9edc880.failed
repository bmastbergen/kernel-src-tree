x86/nmi: Perform a safe NMI stack trace on all CPUs

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [x86] nmi: Perform a safe NMI stack trace on all CPUs (Jerry Snitselaar) [1069217]
Rebuild_FUZZ: 95.92%
commit-author Steven Rostedt (Red Hat) <rostedt@goodmis.org>
commit a9edc88093287183ac934be44f295f183b2c62dd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/a9edc880.failed

When trigger_all_cpu_backtrace() is called on x86, it will trigger an
NMI on each CPU and call show_regs(). But this can lead to a hard lock
up if the NMI comes in on another printk().

In order to avoid this, when the NMI triggers, it switches the printk
routine for that CPU to call a NMI safe printk function that records the
printk in a per_cpu seq_buf descriptor. After all NMIs have finished
recording its data, the seq_bufs are printed in a safe context.

Link: http://lkml.kernel.org/p/20140619213952.360076309@goodmis.org
Link: http://lkml.kernel.org/r/20141115050605.055232587@goodmis.org

	Tested-by: Jiri Kosina <jkosina@suse.cz>
	Acked-by: Jiri Kosina <jkosina@suse.cz>
	Acked-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
	Reviewed-by: Petr Mladek <pmladek@suse.cz>
	Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
(cherry picked from commit a9edc88093287183ac934be44f295f183b2c62dd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/apic/hw_nmi.c
diff --cc arch/x86/kernel/apic/hw_nmi.c
index 8a911d4c65ff,c95c3e9ce196..000000000000
--- a/arch/x86/kernel/apic/hw_nmi.c
+++ b/arch/x86/kernel/apic/hw_nmi.c
@@@ -70,7 -128,28 +128,32 @@@ void arch_trigger_all_cpu_backtrace(boo
  	put_cpu();
  }
  
++<<<<<<< HEAD
 +static int __kprobes
++=======
+ /*
+  * It is not safe to call printk() directly from NMI handlers.
+  * It may be fine if the NMI detected a lock up and we have no choice
+  * but to do so, but doing a NMI on all other CPUs to get a back trace
+  * can be done with a sysrq-l. We don't want that to lock up, which
+  * can happen if the NMI interrupts a printk in progress.
+  *
+  * Instead, we redirect the vprintk() to this nmi_vprintk() that writes
+  * the content into a per cpu seq_buf buffer. Then when the NMIs are
+  * all done, we can safely dump the contents of the seq_buf to a printk()
+  * from a non NMI context.
+  */
+ static int nmi_vprintk(const char *fmt, va_list args)
+ {
+ 	struct nmi_seq_buf *s = this_cpu_ptr(&nmi_print_seq);
+ 	unsigned int len = seq_buf_used(&s->seq);
+ 
+ 	seq_buf_vprintf(&s->seq, fmt, args);
+ 	return seq_buf_used(&s->seq) - len;
+ }
+ 
+ static int
++>>>>>>> a9edc8809328 (x86/nmi: Perform a safe NMI stack trace on all CPUs)
  arch_trigger_all_cpu_backtrace_handler(unsigned int cmd, struct pt_regs *regs)
  {
  	int cpu;
* Unmerged path arch/x86/kernel/apic/hw_nmi.c
