rcu: Fix attempt to avoid unsolicited offloading of callbacks

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Paul E. McKenney <paulmck@linux.vnet.ibm.com>
commit f4579fc57cf4244057b713b1f73f4dc9f0b11e97
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/f4579fc5.failed

Commit b58cc46c5f6b (rcu: Don't offload callbacks unless specifically
requested) failed to adjust the callback lists of the CPUs that are
known to be no-CBs CPUs only because they are also nohz_full= CPUs.
This failure can result in callbacks that are posted during early boot
getting stranded on nxtlist for CPUs whose no-CBs property becomes
apparent late, and there can also be spurious warnings about offline
CPUs posting callbacks.

This commit fixes these problems by adding an early-boot rcu_init_nohz()
that properly initializes the no-CBs CPUs.

Note that kernels built with CONFIG_RCU_NOCB_CPU_ALL=y or with
CONFIG_RCU_NOCB_CPU=n do not exhibit this bug.  Neither do kernels
booted without the nohz_full= boot parameter.

	Signed-off-by: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
	Reviewed-by: Pranith Kumar <bobby.prani@gmail.com>
	Tested-by: Paul Gortmaker <paul.gortmaker@windriver.com>
(cherry picked from commit f4579fc57cf4244057b713b1f73f4dc9f0b11e97)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/rcupdate.h
#	init/Kconfig
#	kernel/rcutree_plugin.h
diff --cc include/linux/rcupdate.h
index 4ee09e4bd381,cc7bed1c90dc..000000000000
--- a/include/linux/rcupdate.h
+++ b/include/linux/rcupdate.h
@@@ -251,7 -269,13 +251,17 @@@ static inline void rcu_user_hooks_switc
  					 struct task_struct *next) { }
  #endif /* CONFIG_RCU_USER_QS */
  
++<<<<<<< HEAD
 +extern void exit_rcu(void);
++=======
+ #ifdef CONFIG_RCU_NOCB_CPU
+ void rcu_init_nohz(void);
+ #else /* #ifdef CONFIG_RCU_NOCB_CPU */
+ static inline void rcu_init_nohz(void)
+ {
+ }
+ #endif /* #else #ifdef CONFIG_RCU_NOCB_CPU */
++>>>>>>> f4579fc57cf4 (rcu: Fix attempt to avoid unsolicited offloading of callbacks)
  
  /**
   * RCU_NONIDLE - Indicate idle-loop code that needs RCU readers
diff --cc init/Kconfig
index 9c03541a6bec,64ee4d967786..000000000000
--- a/init/Kconfig
+++ b/init/Kconfig
@@@ -690,7 -737,7 +690,11 @@@ choic
  
  config RCU_NOCB_CPU_NONE
  	bool "No build_forced no-CBs CPUs"
++<<<<<<< HEAD
 +	depends on RCU_NOCB_CPU && !NO_HZ_FULL
++=======
+ 	depends on RCU_NOCB_CPU
++>>>>>>> f4579fc57cf4 (rcu: Fix attempt to avoid unsolicited offloading of callbacks)
  	help
  	  This option does not force any of the CPUs to be no-CBs CPUs.
  	  Only CPUs designated by the rcu_nocbs= boot parameter will be
@@@ -698,14 -751,18 +702,18 @@@
  
  config RCU_NOCB_CPU_ZERO
  	bool "CPU 0 is a build_forced no-CBs CPU"
++<<<<<<< HEAD
 +	depends on RCU_NOCB_CPU && !NO_HZ_FULL
++=======
+ 	depends on RCU_NOCB_CPU
++>>>>>>> f4579fc57cf4 (rcu: Fix attempt to avoid unsolicited offloading of callbacks)
  	help
 -	  This option forces CPU 0 to be a no-CBs CPU, so that its RCU
 -	  callbacks are invoked by a per-CPU kthread whose name begins
 -	  with "rcuo".	Additional CPUs may be designated as no-CBs
 -	  CPUs using the rcu_nocbs= boot parameter will be no-CBs CPUs.
 -	  All other CPUs will invoke their own RCU callbacks in softirq
 -	  context.
 +	  This option forces CPU 0 to be a no-CBs CPU.  Additional CPUs
 +	  may be designated as no-CBs CPUs using the rcu_nocbs= boot
 +	  parameter will be no-CBs CPUs.
  
  	  Select this if CPU 0 needs to be a no-CBs CPU for real-time
 -	  or energy-efficiency reasons, but the real reason it exists
 -	  is to ensure that randconfig testing covers mixed systems.
 +	  or energy-efficiency reasons.
  
  config RCU_NOCB_CPU_ALL
  	bool "All CPUs are build_forced no-CBs CPUs"
diff --cc kernel/rcutree_plugin.h
index a89b52063803,06d077ccf8d5..000000000000
--- a/kernel/rcutree_plugin.h
+++ b/kernel/rcutree_plugin.h
@@@ -84,34 -84,7 +84,38 @@@ static void __init rcu_bootup_announce_
  	if (rcu_fanout_leaf != CONFIG_RCU_FANOUT_LEAF)
  		pr_info("\tBoot-time adjustment of leaf fanout to %d.\n", rcu_fanout_leaf);
  	if (nr_cpu_ids != NR_CPUS)
++<<<<<<< HEAD:kernel/rcutree_plugin.h
 +		printk(KERN_INFO "\tRCU restricting CPUs from NR_CPUS=%d to nr_cpu_ids=%d.\n", NR_CPUS, nr_cpu_ids);
 +#ifdef CONFIG_RCU_NOCB_CPU
 +#ifndef CONFIG_RCU_NOCB_CPU_NONE
 +	if (!have_rcu_nocb_mask) {
 +		zalloc_cpumask_var(&rcu_nocb_mask, GFP_KERNEL);
 +		have_rcu_nocb_mask = true;
 +	}
 +#ifdef CONFIG_RCU_NOCB_CPU_ZERO
 +	pr_info("\tOffload RCU callbacks from CPU 0\n");
 +	cpumask_set_cpu(0, rcu_nocb_mask);
 +#endif /* #ifdef CONFIG_RCU_NOCB_CPU_ZERO */
 +#ifdef CONFIG_RCU_NOCB_CPU_ALL
 +	pr_info("\tOffload RCU callbacks from all CPUs\n");
 +	cpumask_copy(rcu_nocb_mask, cpu_possible_mask);
 +#endif /* #ifdef CONFIG_RCU_NOCB_CPU_ALL */
 +#endif /* #ifndef CONFIG_RCU_NOCB_CPU_NONE */
 +	if (have_rcu_nocb_mask) {
 +		if (!cpumask_subset(rcu_nocb_mask, cpu_possible_mask)) {
 +			pr_info("\tNote: kernel parameter 'rcu_nocbs=' contains nonexistent CPUs.\n");
 +			cpumask_and(rcu_nocb_mask, cpu_possible_mask,
 +				    rcu_nocb_mask);
 +		}
 +		cpulist_scnprintf(nocb_buf, sizeof(nocb_buf), rcu_nocb_mask);
 +		pr_info("\tOffload RCU callbacks from CPUs: %s.\n", nocb_buf);
 +		if (rcu_nocb_poll)
 +			pr_info("\tPoll for callbacks from no-CBs CPUs.\n");
 +	}
 +#endif /* #ifdef CONFIG_RCU_NOCB_CPU */
++=======
+ 		pr_info("\tRCU restricting CPUs from NR_CPUS=%d to nr_cpu_ids=%d.\n", NR_CPUS, nr_cpu_ids);
++>>>>>>> f4579fc57cf4 (rcu: Fix attempt to avoid unsolicited offloading of callbacks):kernel/rcu/tree_plugin.h
  }
  
  #ifdef CONFIG_TREE_PREEMPT_RCU
@@@ -2254,6 -2408,83 +2258,86 @@@ static int rcu_nocb_kthread(void *arg
  	return 0;
  }
  
++<<<<<<< HEAD:kernel/rcutree_plugin.h
++=======
+ /* Is a deferred wakeup of rcu_nocb_kthread() required? */
+ static bool rcu_nocb_need_deferred_wakeup(struct rcu_data *rdp)
+ {
+ 	return ACCESS_ONCE(rdp->nocb_defer_wakeup);
+ }
+ 
+ /* Do a deferred wakeup of rcu_nocb_kthread(). */
+ static void do_nocb_deferred_wakeup(struct rcu_data *rdp)
+ {
+ 	if (!rcu_nocb_need_deferred_wakeup(rdp))
+ 		return;
+ 	ACCESS_ONCE(rdp->nocb_defer_wakeup) = false;
+ 	wake_nocb_leader(rdp, false);
+ 	trace_rcu_nocb_wake(rdp->rsp->name, rdp->cpu, TPS("DeferredWakeEmpty"));
+ }
+ 
+ void __init rcu_init_nohz(void)
+ {
+ 	int cpu;
+ 	bool need_rcu_nocb_mask = true;
+ 	struct rcu_state *rsp;
+ 
+ #ifdef CONFIG_RCU_NOCB_CPU_NONE
+ 	need_rcu_nocb_mask = false;
+ #endif /* #ifndef CONFIG_RCU_NOCB_CPU_NONE */
+ 
+ #if defined(CONFIG_NO_HZ_FULL)
+ 	if (tick_nohz_full_running && cpumask_weight(tick_nohz_full_mask))
+ 		need_rcu_nocb_mask = true;
+ #endif /* #if defined(CONFIG_NO_HZ_FULL) */
+ 
+ 	if (!have_rcu_nocb_mask && need_rcu_nocb_mask) {
+ 		zalloc_cpumask_var(&rcu_nocb_mask, GFP_KERNEL);
+ 		have_rcu_nocb_mask = true;
+ 	}
+ 	if (!have_rcu_nocb_mask)
+ 		return;
+ 
+ #ifdef CONFIG_RCU_NOCB_CPU_ZERO
+ 	pr_info("\tOffload RCU callbacks from CPU 0\n");
+ 	cpumask_set_cpu(0, rcu_nocb_mask);
+ #endif /* #ifdef CONFIG_RCU_NOCB_CPU_ZERO */
+ #ifdef CONFIG_RCU_NOCB_CPU_ALL
+ 	pr_info("\tOffload RCU callbacks from all CPUs\n");
+ 	cpumask_copy(rcu_nocb_mask, cpu_possible_mask);
+ #endif /* #ifdef CONFIG_RCU_NOCB_CPU_ALL */
+ #if defined(CONFIG_NO_HZ_FULL)
+ 	if (tick_nohz_full_running)
+ 		cpumask_or(rcu_nocb_mask, rcu_nocb_mask, tick_nohz_full_mask);
+ #endif /* #if defined(CONFIG_NO_HZ_FULL) */
+ 
+ 	if (!cpumask_subset(rcu_nocb_mask, cpu_possible_mask)) {
+ 		pr_info("\tNote: kernel parameter 'rcu_nocbs=' contains nonexistent CPUs.\n");
+ 		cpumask_and(rcu_nocb_mask, cpu_possible_mask,
+ 			    rcu_nocb_mask);
+ 	}
+ 	cpulist_scnprintf(nocb_buf, sizeof(nocb_buf), rcu_nocb_mask);
+ 	pr_info("\tOffload RCU callbacks from CPUs: %s.\n", nocb_buf);
+ 	if (rcu_nocb_poll)
+ 		pr_info("\tPoll for callbacks from no-CBs CPUs.\n");
+ 
+ 	for_each_rcu_flavor(rsp) {
+ 		for_each_cpu(cpu, rcu_nocb_mask) {
+ 			struct rcu_data *rdp = per_cpu_ptr(rsp->rda, cpu);
+ 
+ 			/*
+ 			 * If there are early callbacks, they will need
+ 			 * to be moved to the nocb lists.
+ 			 */
+ 			WARN_ON_ONCE(rdp->nxttail[RCU_NEXT_TAIL] !=
+ 				     &rdp->nxtlist &&
+ 				     rdp->nxttail[RCU_NEXT_TAIL] != NULL);
+ 			init_nocb_callback_list(rdp);
+ 		}
+ 	}
+ }
+ 
++>>>>>>> f4579fc57cf4 (rcu: Fix attempt to avoid unsolicited offloading of callbacks):kernel/rcu/tree_plugin.h
  /* Initialize per-rcu_data variables for no-CBs CPUs. */
  static void __init rcu_boot_init_nocb_percpu_data(struct rcu_data *rdp)
  {
@@@ -2270,8 -2513,30 +2354,20 @@@ static void __init rcu_spawn_nocb_kthre
  
  	if (rcu_nocb_mask == NULL)
  		return;
++<<<<<<< HEAD:kernel/rcutree_plugin.h
++=======
+ 	if (ls == -1) {
+ 		ls = int_sqrt(nr_cpu_ids);
+ 		rcu_nocb_leader_stride = ls;
+ 	}
+ 
+ 	/*
+ 	 * Each pass through this loop sets up one rcu_data structure and
+ 	 * spawns one rcu_nocb_kthread().
+ 	 */
++>>>>>>> f4579fc57cf4 (rcu: Fix attempt to avoid unsolicited offloading of callbacks):kernel/rcu/tree_plugin.h
  	for_each_cpu(cpu, rcu_nocb_mask) {
  		rdp = per_cpu_ptr(rsp->rda, cpu);
 -		if (rdp->cpu >= nl) {
 -			/* New leader, set up for followers & next leader. */
 -			nl = DIV_ROUND_UP(rdp->cpu + 1, ls) * ls;
 -			rdp->nocb_leader = rdp;
 -			rdp_leader = rdp;
 -		} else {
 -			/* Another follower, link to previous leader. */
 -			rdp->nocb_leader = rdp_leader;
 -			rdp_prev->nocb_next_follower = rdp;
 -		}
 -		rdp_prev = rdp;
 -
 -		/* Spawn the kthread for this CPU. */
  		t = kthread_run(rcu_nocb_kthread, rdp,
  				"rcuo%c/%d", rsp->abbr, cpu);
  		BUG_ON(IS_ERR(t));
* Unmerged path include/linux/rcupdate.h
* Unmerged path init/Kconfig
diff --git a/init/main.c b/init/main.c
index 8678d709aacc..34642fef6272 100644
--- a/init/main.c
+++ b/init/main.c
@@ -547,6 +547,7 @@ asmlinkage void __init start_kernel(void)
 	idr_init_cache();
 	rcu_init();
 	tick_nohz_init();
+	rcu_init_nohz();
 	context_tracking_init();
 	radix_tree_init();
 	/* init some links before init_ISA_irqs() */
* Unmerged path kernel/rcutree_plugin.h
