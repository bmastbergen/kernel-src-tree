net: merge cases where sock_efree and sock_edemux are the same function

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [net] merge cases where sock_efree and sock_edemux are the same function (Jiri Benc) [1297504]
Rebuild_FUZZ: 96.35%
commit-author Alexander Duyck <alexander.h.duyck@intel.com>
commit 82eabd9eb2ec1603282a2c3f74dfcb6fe0aaea0e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/82eabd9e.failed

Since sock_efree and sock_demux are essentially the same code for non-TCP
sockets and the case where CONFIG_INET is not defined we can combine the
code or replace the call to sock_edemux in several spots.  As a result we
can avoid a bit of unnecessary code or code duplication.

	Signed-off-by: Alexander Duyck <alexander.h.duyck@intel.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 82eabd9eb2ec1603282a2c3f74dfcb6fe0aaea0e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/sock.h
#	net/ipv4/udp.c
diff --cc include/net/sock.h
index d2b60f37533f,ad23e80cb8d3..000000000000
--- a/include/net/sock.h
+++ b/include/net/sock.h
@@@ -1567,46 -1563,37 +1567,60 @@@ static inline void unlock_sock_fast(str
  }
  
  
 -struct sock *sk_alloc(struct net *net, int family, gfp_t priority,
 -		      struct proto *prot);
 -void sk_free(struct sock *sk);
 -void sk_release_kernel(struct sock *sk);
 -struct sock *sk_clone_lock(const struct sock *sk, const gfp_t priority);
 -
 +extern struct sock		*sk_alloc(struct net *net, int family,
 +					  gfp_t priority,
 +					  struct proto *prot);
 +extern void			sk_free(struct sock *sk);
 +extern void			sk_release_kernel(struct sock *sk);
 +extern struct sock		*sk_clone_lock(const struct sock *sk,
 +					       const gfp_t priority);
 +
++<<<<<<< HEAD
 +extern struct sk_buff		*sock_wmalloc(struct sock *sk,
 +					      unsigned long size, int force,
 +					      gfp_t priority);
 +extern struct sk_buff		*sock_rmalloc(struct sock *sk,
 +					      unsigned long size, int force,
 +					      gfp_t priority);
 +extern void			sock_wfree(struct sk_buff *skb);
 +extern void			sock_rfree(struct sk_buff *skb);
 +extern void			sock_efree(struct sk_buff *skb);
 +extern void			sock_edemux(struct sk_buff *skb);
++=======
+ struct sk_buff *sock_wmalloc(struct sock *sk, unsigned long size, int force,
+ 			     gfp_t priority);
+ void sock_wfree(struct sk_buff *skb);
+ void skb_orphan_partial(struct sk_buff *skb);
+ void sock_rfree(struct sk_buff *skb);
+ void sock_efree(struct sk_buff *skb);
+ #ifdef CONFIG_INET
+ void sock_edemux(struct sk_buff *skb);
+ #else
+ #define sock_edemux(skb) sock_efree(skb)
+ #endif
 -
 -int sock_setsockopt(struct socket *sock, int level, int op,
 -		    char __user *optval, unsigned int optlen);
 -
 -int sock_getsockopt(struct socket *sock, int level, int op,
 -		    char __user *optval, int __user *optlen);
 -struct sk_buff *sock_alloc_send_skb(struct sock *sk, unsigned long size,
 -				    int noblock, int *errcode);
 -struct sk_buff *sock_alloc_send_pskb(struct sock *sk, unsigned long header_len,
 -				     unsigned long data_len, int noblock,
 -				     int *errcode, int max_page_order);
 -void *sock_kmalloc(struct sock *sk, int size, gfp_t priority);
 -void sock_kfree_s(struct sock *sk, void *mem, int size);
 -void sk_send_sigurg(struct sock *sk);
++>>>>>>> 82eabd9eb2ec (net: merge cases where sock_efree and sock_edemux are the same function)
 +
 +extern int			sock_setsockopt(struct socket *sock, int level,
 +						int op, char __user *optval,
 +						unsigned int optlen);
 +
 +extern int			sock_getsockopt(struct socket *sock, int level,
 +						int op, char __user *optval,
 +						int __user *optlen);
 +extern struct sk_buff		*sock_alloc_send_skb(struct sock *sk,
 +						     unsigned long size,
 +						     int noblock,
 +						     int *errcode);
 +extern struct sk_buff		*sock_alloc_send_pskb(struct sock *sk,
 +						      unsigned long header_len,
 +						      unsigned long data_len,
 +						      int noblock,
 +						      int *errcode,
 +						      int max_page_order);
 +extern void *sock_kmalloc(struct sock *sk, int size,
 +			  gfp_t priority);
 +extern void sock_kfree_s(struct sock *sk, void *mem, int size);
 +extern void sk_send_sigurg(struct sock *sk);
  
  /*
   * Functions to fill in entries in struct proto_ops when a protocol
diff --cc net/ipv4/udp.c
index 556580e2c4f8,cd0db5471bb5..000000000000
--- a/net/ipv4/udp.c
+++ b/net/ipv4/udp.c
@@@ -1809,6 -1845,142 +1809,145 @@@ drop
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ /* We can only early demux multicast if there is a single matching socket.
+  * If more than one socket found returns NULL
+  */
+ static struct sock *__udp4_lib_mcast_demux_lookup(struct net *net,
+ 						  __be16 loc_port, __be32 loc_addr,
+ 						  __be16 rmt_port, __be32 rmt_addr,
+ 						  int dif)
+ {
+ 	struct sock *sk, *result;
+ 	struct hlist_nulls_node *node;
+ 	unsigned short hnum = ntohs(loc_port);
+ 	unsigned int count, slot = udp_hashfn(net, hnum, udp_table.mask);
+ 	struct udp_hslot *hslot = &udp_table.hash[slot];
+ 
+ 	/* Do not bother scanning a too big list */
+ 	if (hslot->count > 10)
+ 		return NULL;
+ 
+ 	rcu_read_lock();
+ begin:
+ 	count = 0;
+ 	result = NULL;
+ 	sk_nulls_for_each_rcu(sk, node, &hslot->head) {
+ 		if (__udp_is_mcast_sock(net, sk,
+ 					loc_port, loc_addr,
+ 					rmt_port, rmt_addr,
+ 					dif, hnum)) {
+ 			result = sk;
+ 			++count;
+ 		}
+ 	}
+ 	/*
+ 	 * if the nulls value we got at the end of this lookup is
+ 	 * not the expected one, we must restart lookup.
+ 	 * We probably met an item that was moved to another chain.
+ 	 */
+ 	if (get_nulls_value(node) != slot)
+ 		goto begin;
+ 
+ 	if (result) {
+ 		if (count != 1 ||
+ 		    unlikely(!atomic_inc_not_zero_hint(&result->sk_refcnt, 2)))
+ 			result = NULL;
+ 		else if (unlikely(!__udp_is_mcast_sock(net, result,
+ 						       loc_port, loc_addr,
+ 						       rmt_port, rmt_addr,
+ 						       dif, hnum))) {
+ 			sock_put(result);
+ 			result = NULL;
+ 		}
+ 	}
+ 	rcu_read_unlock();
+ 	return result;
+ }
+ 
+ /* For unicast we should only early demux connected sockets or we can
+  * break forwarding setups.  The chains here can be long so only check
+  * if the first socket is an exact match and if not move on.
+  */
+ static struct sock *__udp4_lib_demux_lookup(struct net *net,
+ 					    __be16 loc_port, __be32 loc_addr,
+ 					    __be16 rmt_port, __be32 rmt_addr,
+ 					    int dif)
+ {
+ 	struct sock *sk, *result;
+ 	struct hlist_nulls_node *node;
+ 	unsigned short hnum = ntohs(loc_port);
+ 	unsigned int hash2 = udp4_portaddr_hash(net, loc_addr, hnum);
+ 	unsigned int slot2 = hash2 & udp_table.mask;
+ 	struct udp_hslot *hslot2 = &udp_table.hash2[slot2];
+ 	INET_ADDR_COOKIE(acookie, rmt_addr, loc_addr);
+ 	const __portpair ports = INET_COMBINED_PORTS(rmt_port, hnum);
+ 
+ 	rcu_read_lock();
+ 	result = NULL;
+ 	udp_portaddr_for_each_entry_rcu(sk, node, &hslot2->head) {
+ 		if (INET_MATCH(sk, net, acookie,
+ 			       rmt_addr, loc_addr, ports, dif))
+ 			result = sk;
+ 		/* Only check first socket in chain */
+ 		break;
+ 	}
+ 
+ 	if (result) {
+ 		if (unlikely(!atomic_inc_not_zero_hint(&result->sk_refcnt, 2)))
+ 			result = NULL;
+ 		else if (unlikely(!INET_MATCH(sk, net, acookie,
+ 					      rmt_addr, loc_addr,
+ 					      ports, dif))) {
+ 			sock_put(result);
+ 			result = NULL;
+ 		}
+ 	}
+ 	rcu_read_unlock();
+ 	return result;
+ }
+ 
+ void udp_v4_early_demux(struct sk_buff *skb)
+ {
+ 	struct net *net = dev_net(skb->dev);
+ 	const struct iphdr *iph;
+ 	const struct udphdr *uh;
+ 	struct sock *sk;
+ 	struct dst_entry *dst;
+ 	int dif = skb->dev->ifindex;
+ 
+ 	/* validate the packet */
+ 	if (!pskb_may_pull(skb, skb_transport_offset(skb) + sizeof(struct udphdr)))
+ 		return;
+ 
+ 	iph = ip_hdr(skb);
+ 	uh = udp_hdr(skb);
+ 
+ 	if (skb->pkt_type == PACKET_BROADCAST ||
+ 	    skb->pkt_type == PACKET_MULTICAST)
+ 		sk = __udp4_lib_mcast_demux_lookup(net, uh->dest, iph->daddr,
+ 						   uh->source, iph->saddr, dif);
+ 	else if (skb->pkt_type == PACKET_HOST)
+ 		sk = __udp4_lib_demux_lookup(net, uh->dest, iph->daddr,
+ 					     uh->source, iph->saddr, dif);
+ 	else
+ 		return;
+ 
+ 	if (!sk)
+ 		return;
+ 
+ 	skb->sk = sk;
+ 	skb->destructor = sock_efree;
+ 	dst = sk->sk_rx_dst;
+ 
+ 	if (dst)
+ 		dst = dst_check(dst, 0);
+ 	if (dst)
+ 		skb_dst_set_noref(skb, dst);
+ }
+ 
++>>>>>>> 82eabd9eb2ec (net: merge cases where sock_efree and sock_edemux are the same function)
  int udp_rcv(struct sk_buff *skb)
  {
  	return __udp4_lib_rcv(skb, &udp_table, IPPROTO_UDP);
* Unmerged path include/net/sock.h
diff --git a/net/core/sock.c b/net/core/sock.c
index 5df7b494f26e..dbb4cac95562 100644
--- a/net/core/sock.c
+++ b/net/core/sock.c
@@ -1635,18 +1635,18 @@ void sock_efree(struct sk_buff *skb)
 }
 EXPORT_SYMBOL(sock_efree);
 
+#ifdef CONFIG_INET
 void sock_edemux(struct sk_buff *skb)
 {
 	struct sock *sk = skb->sk;
 
-#ifdef CONFIG_INET
 	if (sk->sk_state == TCP_TIME_WAIT)
 		inet_twsk_put(inet_twsk(sk));
 	else
-#endif
 		sock_put(sk);
 }
 EXPORT_SYMBOL(sock_edemux);
+#endif
 
 kuid_t sock_i_uid(struct sock *sk)
 {
* Unmerged path net/ipv4/udp.c
