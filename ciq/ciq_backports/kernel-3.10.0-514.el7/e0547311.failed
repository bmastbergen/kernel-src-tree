perf stat: Make stat options global

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Jiri Olsa <jolsa@kernel.org>
commit e0547311133159bf95f7998726e4e4932d78d8ce
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/e0547311.failed

So they can be used in perf stat record command in following patch.

	Signed-off-by: Jiri Olsa <jolsa@kernel.org>
	Tested-by: Kan Liang <kan.liang@intel.com>
	Cc: David Ahern <dsahern@gmail.com>
	Cc: Namhyung Kim <namhyung@kernel.org>
	Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
Link: http://lkml.kernel.org/r/1446734469-11352-2-git-send-email-jolsa@kernel.org
	Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
(cherry picked from commit e0547311133159bf95f7998726e4e4932d78d8ce)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/perf/builtin-stat.c
diff --cc tools/perf/builtin-stat.c
index 1aef031aa7f8,e77880b5094d..000000000000
--- a/tools/perf/builtin-stat.c
+++ b/tools/perf/builtin-stat.c
@@@ -119,7 -121,10 +119,14 @@@ static unsigned int		unit_width			= 4; 
  static bool			forever				= false;
  static struct timespec		ref_time;
  static struct cpu_map		*aggr_map;
++<<<<<<< HEAD
 +static int			(*aggr_get_id)(struct cpu_map *m, int cpu);
++=======
+ static aggr_get_id_t		aggr_get_id;
+ static bool			append_file;
+ static const char		*output_name;
+ static int			output_fd;
++>>>>>>> e05473111331 (perf stat: Make stat options global)
  
  static volatile int done = 0;
  
@@@ -925,8 -930,120 +932,121 @@@ static int stat__set_big_num(const stru
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static const struct option stat_options[] = {
+ 	OPT_BOOLEAN('T', "transaction", &transaction_run,
+ 		    "hardware transaction statistics"),
+ 	OPT_CALLBACK('e', "event", &evsel_list, "event",
+ 		     "event selector. use 'perf list' to list available events",
+ 		     parse_events_option),
+ 	OPT_CALLBACK(0, "filter", &evsel_list, "filter",
+ 		     "event filter", parse_filter),
+ 	OPT_BOOLEAN('i', "no-inherit", &no_inherit,
+ 		    "child tasks do not inherit counters"),
+ 	OPT_STRING('p', "pid", &target.pid, "pid",
+ 		   "stat events on existing process id"),
+ 	OPT_STRING('t', "tid", &target.tid, "tid",
+ 		   "stat events on existing thread id"),
+ 	OPT_BOOLEAN('a', "all-cpus", &target.system_wide,
+ 		    "system-wide collection from all CPUs"),
+ 	OPT_BOOLEAN('g', "group", &group,
+ 		    "put the counters into a counter group"),
+ 	OPT_BOOLEAN('c', "scale", &stat_config.scale, "scale/normalize counters"),
+ 	OPT_INCR('v', "verbose", &verbose,
+ 		    "be more verbose (show counter open errors, etc)"),
+ 	OPT_INTEGER('r', "repeat", &run_count,
+ 		    "repeat command and print average + stddev (max: 100, forever: 0)"),
+ 	OPT_BOOLEAN('n', "null", &null_run,
+ 		    "null run - dont start any counters"),
+ 	OPT_INCR('d', "detailed", &detailed_run,
+ 		    "detailed run - start a lot of events"),
+ 	OPT_BOOLEAN('S', "sync", &sync_run,
+ 		    "call sync() before starting a run"),
+ 	OPT_CALLBACK_NOOPT('B', "big-num", NULL, NULL,
+ 			   "print large numbers with thousands\' separators",
+ 			   stat__set_big_num),
+ 	OPT_STRING('C', "cpu", &target.cpu_list, "cpu",
+ 		    "list of cpus to monitor in system-wide"),
+ 	OPT_SET_UINT('A', "no-aggr", &stat_config.aggr_mode,
+ 		    "disable CPU count aggregation", AGGR_NONE),
+ 	OPT_STRING('x', "field-separator", &csv_sep, "separator",
+ 		   "print counts with custom separator"),
+ 	OPT_CALLBACK('G', "cgroup", &evsel_list, "name",
+ 		     "monitor event in cgroup name only", parse_cgroups),
+ 	OPT_STRING('o', "output", &output_name, "file", "output file name"),
+ 	OPT_BOOLEAN(0, "append", &append_file, "append to the output file"),
+ 	OPT_INTEGER(0, "log-fd", &output_fd,
+ 		    "log output to fd, instead of stderr"),
+ 	OPT_STRING(0, "pre", &pre_cmd, "command",
+ 			"command to run prior to the measured command"),
+ 	OPT_STRING(0, "post", &post_cmd, "command",
+ 			"command to run after to the measured command"),
+ 	OPT_UINTEGER('I', "interval-print", &stat_config.interval,
+ 		    "print counts at regular interval in ms (>= 10)"),
+ 	OPT_SET_UINT(0, "per-socket", &stat_config.aggr_mode,
+ 		     "aggregate counts per processor socket", AGGR_SOCKET),
+ 	OPT_SET_UINT(0, "per-core", &stat_config.aggr_mode,
+ 		     "aggregate counts per physical processor core", AGGR_CORE),
+ 	OPT_SET_UINT(0, "per-thread", &stat_config.aggr_mode,
+ 		     "aggregate counts per thread", AGGR_THREAD),
+ 	OPT_UINTEGER('D', "delay", &initial_delay,
+ 		     "ms to wait before starting measurement after program start"),
+ 	OPT_END()
+ };
+ 
+ static int perf_stat__get_socket(struct cpu_map *map, int cpu)
+ {
+ 	return cpu_map__get_socket(map, cpu, NULL);
+ }
+ 
+ static int perf_stat__get_core(struct cpu_map *map, int cpu)
+ {
+ 	return cpu_map__get_core(map, cpu, NULL);
+ }
+ 
+ static int cpu_map__get_max(struct cpu_map *map)
+ {
+ 	int i, max = -1;
+ 
+ 	for (i = 0; i < map->nr; i++) {
+ 		if (map->map[i] > max)
+ 			max = map->map[i];
+ 	}
+ 
+ 	return max;
+ }
+ 
+ static struct cpu_map *cpus_aggr_map;
+ 
+ static int perf_stat__get_aggr(aggr_get_id_t get_id, struct cpu_map *map, int idx)
+ {
+ 	int cpu;
+ 
+ 	if (idx >= map->nr)
+ 		return -1;
+ 
+ 	cpu = map->map[idx];
+ 
+ 	if (cpus_aggr_map->map[cpu] == -1)
+ 		cpus_aggr_map->map[cpu] = get_id(map, idx);
+ 
+ 	return cpus_aggr_map->map[cpu];
+ }
+ 
+ static int perf_stat__get_socket_cached(struct cpu_map *map, int idx)
+ {
+ 	return perf_stat__get_aggr(perf_stat__get_socket, map, idx);
+ }
+ 
+ static int perf_stat__get_core_cached(struct cpu_map *map, int idx)
+ {
+ 	return perf_stat__get_aggr(perf_stat__get_core, map, idx);
+ }
+ 
++>>>>>>> e05473111331 (perf stat: Make stat options global)
  static int perf_stat_init_aggr_mode(void)
  {
 -	int nr;
 -
  	switch (stat_config.aggr_mode) {
  	case AGGR_SOCKET:
  		if (cpu_map__build_socket_map(evsel_list->cpus, &aggr_map)) {
* Unmerged path tools/perf/builtin-stat.c
