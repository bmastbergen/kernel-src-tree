staging/rdma/hfi1: Split last 8 bytes of copy to user buffer

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [infiniband] rdma/hfi1: Split last 8 bytes of copy to user buffer (Alex Estrin) [1272062 1273170]
Rebuild_FUZZ: 92.86%
commit-author Dean Luick <dean.luick@intel.com>
commit 7b0b01aa8f48cd237322cbffa05662a9c6b156f8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/7b0b01aa.failed

Copy the last 8 bytes of user mode RC WRITE_ONLY and WRITE_LAST
opcodes separately from the rest of the data.

It is a de-facto standard for some MPI implementations to use a
poll on the last few bytes of a verbs message to indicate that
the message has been received rather than follow the required
function method.  The driver uses the kernel memcpy routine, which
becomes "rep movsb" on modern machines.  This copy, while very
fast, does not guarantee in-order copy completion and the result
is an occasional perceived corrupted packet.  Avoid the issue by
splitting the last 8 bytes to copy from the verbs opcodes where it
matters and performing an in-order byte copy.

	Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
	Signed-off-by: Dean Luick <dean.luick@intel.com>
	Signed-off-by: Jubin John <jubin.john@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 7b0b01aa8f48cd237322cbffa05662a9c6b156f8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/staging/hfi1/rc.c
#	drivers/staging/hfi1/uc.c
#	drivers/staging/hfi1/ud.c
#	drivers/staging/hfi1/verbs.c
#	drivers/staging/rdma/hfi1/verbs.h
diff --cc drivers/staging/hfi1/rc.c
index dd57d65aa9b2,371edc3dd4f6..000000000000
--- a/drivers/staging/hfi1/rc.c
+++ b/drivers/staging/hfi1/rc.c
@@@ -2124,10 -2129,10 +2127,15 @@@ send_last
  		wc.byte_len = tlen + qp->r_rcv_len;
  		if (unlikely(wc.byte_len > qp->r_len))
  			goto nack_inv;
++<<<<<<< HEAD:drivers/staging/hfi1/rc.c
 +		hfi1_copy_sge(&qp->r_sge, data, tlen, 1);
 +		hfi1_put_ss(&qp->r_sge);
++=======
+ 		hfi1_copy_sge(&qp->r_sge, data, tlen, 1, copy_last);
+ 		rvt_put_ss(&qp->r_sge);
++>>>>>>> 7b0b01aa8f48 (staging/rdma/hfi1: Split last 8 bytes of copy to user buffer):drivers/staging/rdma/hfi1/rc.c
  		qp->r_msn++;
 -		if (!test_and_clear_bit(RVT_R_WRID_VALID, &qp->r_aflags))
 +		if (!test_and_clear_bit(HFI1_R_WRID_VALID, &qp->r_aflags))
  			break;
  		wc.wr_id = qp->r_wr_id;
  		wc.status = IB_WC_SUCCESS;
@@@ -2157,12 -2162,14 +2165,14 @@@
  		wc.dlid_path_bits = 0;
  		wc.port_num = 0;
  		/* Signal completion event if the solicited bit is set. */
 -		rvt_cq_enter(ibcq_to_rvtcq(qp->ibqp.recv_cq), &wc,
 -			     (bth0 & IB_BTH_SOLICITED) != 0);
 +		hfi1_cq_enter(to_icq(qp->ibqp.recv_cq), &wc,
 +			      (bth0 & IB_BTH_SOLICITED) != 0);
  		break;
  
- 	case OP(RDMA_WRITE_FIRST):
  	case OP(RDMA_WRITE_ONLY):
+ 		copy_last = 1;
+ 		/* fall through */
+ 	case OP(RDMA_WRITE_FIRST):
  	case OP(RDMA_WRITE_ONLY_WITH_IMMEDIATE):
  		if (unlikely(!(qp->qp_access_flags & IB_ACCESS_REMOTE_WRITE)))
  			goto nack_inv;
diff --cc drivers/staging/hfi1/uc.c
index fc90d4f544e4,0aa604b7557b..000000000000
--- a/drivers/staging/hfi1/uc.c
+++ b/drivers/staging/hfi1/uc.c
@@@ -443,8 -443,8 +443,13 @@@ send_last
  		if (unlikely(wc.byte_len > qp->r_len))
  			goto rewind;
  		wc.opcode = IB_WC_RECV;
++<<<<<<< HEAD:drivers/staging/hfi1/uc.c
 +		hfi1_copy_sge(&qp->r_sge, data, tlen, 0);
 +		hfi1_put_ss(&qp->s_rdma_read_sge);
++=======
+ 		hfi1_copy_sge(&qp->r_sge, data, tlen, 0, 0);
+ 		rvt_put_ss(&qp->s_rdma_read_sge);
++>>>>>>> 7b0b01aa8f48 (staging/rdma/hfi1: Split last 8 bytes of copy to user buffer):drivers/staging/rdma/hfi1/uc.c
  last_imm:
  		wc.wr_id = qp->r_wr_id;
  		wc.status = IB_WC_SUCCESS;
@@@ -547,8 -547,8 +552,13 @@@ rdma_last_imm
  		}
  		wc.byte_len = qp->r_len;
  		wc.opcode = IB_WC_RECV_RDMA_WITH_IMM;
++<<<<<<< HEAD:drivers/staging/hfi1/uc.c
 +		hfi1_copy_sge(&qp->r_sge, data, tlen, 1);
 +		hfi1_put_ss(&qp->r_sge);
++=======
+ 		hfi1_copy_sge(&qp->r_sge, data, tlen, 1, 0);
+ 		rvt_put_ss(&qp->r_sge);
++>>>>>>> 7b0b01aa8f48 (staging/rdma/hfi1: Split last 8 bytes of copy to user buffer):drivers/staging/rdma/hfi1/uc.c
  		goto last_imm;
  
  	case OP(RDMA_WRITE_LAST):
@@@ -563,8 -563,8 +573,13 @@@ rdma_last
  		tlen -= (hdrsize + pad + 4);
  		if (unlikely(tlen + qp->r_rcv_len != qp->r_len))
  			goto drop;
++<<<<<<< HEAD:drivers/staging/hfi1/uc.c
 +		hfi1_copy_sge(&qp->r_sge, data, tlen, 1);
 +		hfi1_put_ss(&qp->r_sge);
++=======
+ 		hfi1_copy_sge(&qp->r_sge, data, tlen, 1, 0);
+ 		rvt_put_ss(&qp->r_sge);
++>>>>>>> 7b0b01aa8f48 (staging/rdma/hfi1: Split last 8 bytes of copy to user buffer):drivers/staging/rdma/hfi1/uc.c
  		break;
  
  	default:
diff --cc drivers/staging/hfi1/ud.c
index a7f67b0111da,fdf6e3bee8f1..000000000000
--- a/drivers/staging/hfi1/ud.c
+++ b/drivers/staging/hfi1/ud.c
@@@ -839,9 -840,10 +839,16 @@@ void hfi1_ud_rcv(struct hfi1_packet *pa
  		wc.wc_flags |= IB_WC_GRH;
  	} else
  		hfi1_skip_sge(&qp->r_sge, sizeof(struct ib_grh), 1);
++<<<<<<< HEAD:drivers/staging/hfi1/ud.c
 +	hfi1_copy_sge(&qp->r_sge, data, wc.byte_len - sizeof(struct ib_grh), 1);
 +	hfi1_put_ss(&qp->r_sge);
 +	if (!test_and_clear_bit(HFI1_R_WRID_VALID, &qp->r_aflags))
++=======
+ 	hfi1_copy_sge(&qp->r_sge, data, wc.byte_len - sizeof(struct ib_grh),
+ 		      1, 0);
+ 	rvt_put_ss(&qp->r_sge);
+ 	if (!test_and_clear_bit(RVT_R_WRID_VALID, &qp->r_aflags))
++>>>>>>> 7b0b01aa8f48 (staging/rdma/hfi1: Split last 8 bytes of copy to user buffer):drivers/staging/rdma/hfi1/ud.c
  		return;
  	wc.wr_id = qp->r_wr_id;
  	wc.status = IB_WC_SUCCESS;
diff --cc drivers/staging/hfi1/verbs.c
index d228eb7fc4f0,8f351bc157df..000000000000
--- a/drivers/staging/hfi1/verbs.c
+++ b/drivers/staging/hfi1/verbs.c
@@@ -274,14 -242,28 +274,32 @@@ __be64 ib_hfi1_sys_image_guid
   * @ss: the SGE state
   * @data: the data to copy
   * @length: the length of the data
+  * @copy_last: do a separate copy of the last 8 bytes
   */
  void hfi1_copy_sge(
 -	struct rvt_sge_state *ss,
 +	struct hfi1_sge_state *ss,
  	void *data, u32 length,
- 	int release)
+ 	int release,
+ 	int copy_last)
  {
++<<<<<<< HEAD:drivers/staging/hfi1/verbs.c
 +	struct hfi1_sge *sge = &ss->sge;
++=======
+ 	struct rvt_sge *sge = &ss->sge;
+ 	int in_last = 0;
+ 	int i;
++>>>>>>> 7b0b01aa8f48 (staging/rdma/hfi1: Split last 8 bytes of copy to user buffer):drivers/staging/rdma/hfi1/verbs.c
  
+ 	if (copy_last) {
+ 		if (length > 8) {
+ 			length -= 8;
+ 		} else {
+ 			copy_last = 0;
+ 			in_last = 1;
+ 		}
+ 	}
+ 
+ again:
  	while (length) {
  		u32 len = sge->length;
  
* Unmerged path drivers/staging/rdma/hfi1/verbs.h
* Unmerged path drivers/staging/hfi1/rc.c
diff --git a/drivers/staging/hfi1/ruc.c b/drivers/staging/hfi1/ruc.c
index c4280b6f47d4..26b524e8cc6d 100644
--- a/drivers/staging/hfi1/ruc.c
+++ b/drivers/staging/hfi1/ruc.c
@@ -368,6 +368,7 @@ static void ruc_loopback(struct hfi1_qp *sqp)
 	enum ib_wc_status send_status;
 	int release;
 	int ret;
+	int copy_last = 0;
 
 	rcu_read_lock();
 
@@ -456,10 +457,13 @@ again:
 			goto op_err;
 		if (!ret)
 			goto rnr_nak;
-		/* FALLTHROUGH */
+		/* skip copy_last set and qp_access_flags recheck */
+		goto do_write;
 	case IB_WR_RDMA_WRITE:
+		copy_last = ibpd_to_rvtpd(qp->ibqp.pd)->user;
 		if (unlikely(!(qp->qp_access_flags & IB_ACCESS_REMOTE_WRITE)))
 			goto inv_err;
+do_write:
 		if (wqe->length == 0)
 			break;
 		if (unlikely(!hfi1_rkey_ok(qp, &qp->r_sge.sge, wqe->length,
@@ -524,7 +528,7 @@ again:
 		if (len > sge->sge_length)
 			len = sge->sge_length;
 		WARN_ON_ONCE(len == 0);
-		hfi1_copy_sge(&qp->r_sge, sge->vaddr, len, release);
+		hfi1_copy_sge(&qp->r_sge, sge->vaddr, len, release, copy_last);
 		sge->vaddr += len;
 		sge->length -= len;
 		sge->sge_length -= len;
* Unmerged path drivers/staging/hfi1/uc.c
* Unmerged path drivers/staging/hfi1/ud.c
* Unmerged path drivers/staging/hfi1/verbs.c
* Unmerged path drivers/staging/rdma/hfi1/verbs.h
