IB/hfi1: Implement SDMA-side buffer caching

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Mitko Haralanov <mitko.haralanov@intel.com>
commit 5cd3a88d7f2b050164dc1df59a398294515126d9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/5cd3a88d.failed

Add support for caching of user buffers used for SDMA
transfers. This change improves performance by
avoiding repeatedly pinning the pages of buffers, which
are being re-used by the application.

While the cost of the pinning operation has been made
heavier by adding the extra code to search the cache tree,
re-allocate pages arrays, and future cache evictions,
that cost will be amortized against the savings when the
same buffer is re-used. It is also worth noting that in
most cases, the cost of pinning should be much lower due
to the buffer already being in the cache.

	Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
	Reviewed-by: Dean Luick <dean.luick@intel.com>
	Signed-off-by: Mitko Haralanov <mitko.haralanov@intel.com>
	Signed-off-by: Jubin John <jubin.john@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 5cd3a88d7f2b050164dc1df59a398294515126d9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/staging/hfi1/user_sdma.c
diff --cc drivers/staging/hfi1/user_sdma.c
index 6967deb7956a,a53edb96ca50..000000000000
--- a/drivers/staging/hfi1/user_sdma.c
+++ b/drivers/staging/hfi1/user_sdma.c
@@@ -386,9 -396,10 +397,10 @@@ int hfi1_user_sdma_alloc_queues(struct 
  	pq->state = SDMA_PKT_Q_INACTIVE;
  	atomic_set(&pq->n_reqs, 0);
  	init_waitqueue_head(&pq->wait);
+ 	pq->sdma_rb_root = RB_ROOT;
  
  	iowait_init(&pq->busy, 0, NULL, defer_packet_queue,
 -		    activate_packet_queue, NULL);
 +		    activate_packet_queue);
  	pq->reqidx = 0;
  	snprintf(buf, 64, "txreq-kmem-cache-%u-%u-%u", dd->unit, uctxt->ctxt,
  		 fd->subctxt);
@@@ -976,16 -975,8 +968,21 @@@ static int user_sdma_send_pkts(struct u
  		if (req_opcode(req->info.ctrl) == EXPECTED)
  			req->tidoffset += datalen;
  		req->sent += data_sent;
++<<<<<<< HEAD:drivers/staging/hfi1/user_sdma.c
 +		if (req->data_len) {
 +			tx->iovecs[tx->idx].vec->offset += iov_offset;
 +			/* If we've reached the end of the io vector, mark it
 +			 * so the callback can unpin the pages and free it. */
 +			if (tx->iovecs[tx->idx].vec->offset ==
 +			    tx->iovecs[tx->idx].vec->iov.iov_len)
 +				tx->iovecs[tx->idx].flags |=
 +					TXREQ_FLAGS_IOVEC_LAST_PKT;
 +		}
 +
++=======
+ 		if (req->data_len)
+ 			iovec->offset += iov_offset;
++>>>>>>> 5cd3a88d7f2b (IB/hfi1: Implement SDMA-side buffer caching):drivers/staging/rdma/hfi1/user_sdma.c
  		list_add_tail(&tx->txreq.list, &req->txps);
  		/*
  		 * It is important to increment this here as it is used to
* Unmerged path drivers/staging/hfi1/user_sdma.c
diff --git a/drivers/staging/hfi1/user_sdma.h b/drivers/staging/hfi1/user_sdma.h
index 7ebbc4634989..8239c9ea7ed1 100644
--- a/drivers/staging/hfi1/user_sdma.h
+++ b/drivers/staging/hfi1/user_sdma.h
@@ -78,6 +78,7 @@ struct hfi1_user_sdma_pkt_q {
 	unsigned state;
 	wait_queue_head_t wait;
 	unsigned long unpinned;
+	struct rb_root sdma_rb_root;
 };
 
 struct hfi1_user_sdma_comp_q {
