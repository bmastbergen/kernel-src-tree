Drivers: hv: vmbus: Implement NUMA aware CPU affinity for channels

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [hv] vmbus: Implement NUMA aware CPU affinity for channels (Vitaly Kuznetsov) [1321073]
Rebuild_FUZZ: 89.08%
commit-author K. Y. Srinivasan <kys@microsoft.com>
commit 1f656ff3fdddc2f59649cc84b633b799908f1f7b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/1f656ff3.failed

Channels/sub-channels can be affinitized to VCPUs in the guest. Implement
this affinity in a way that is NUMA aware. The current protocol distributed
the primary channels uniformly across all available CPUs. The new protocol
is NUMA aware: primary channels are distributed across the available NUMA
nodes while the sub-channels within a primary channel are distributed amongst
CPUs within the NUMA node assigned to the primary channel.

	Signed-off-by: K. Y. Srinivasan <kys@microsoft.com>
	Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
(cherry picked from commit 1f656ff3fdddc2f59649cc84b633b799908f1f7b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/hv/channel_mgmt.c
diff --cc drivers/hv/channel_mgmt.c
index f0a80d821fa3,4506a6623618..000000000000
--- a/drivers/hv/channel_mgmt.c
+++ b/drivers/hv/channel_mgmt.c
@@@ -375,19 -374,23 +375,27 @@@ static int next_numa_node_id
  
  /*
   * Starting with Win8, we can statically distribute the incoming
-  * channel interrupt load by binding a channel to VCPU. We
-  * implement here a simple round robin scheme for distributing
-  * the interrupt load.
-  * We will bind channels that are not performance critical to cpu 0 and
-  * performance critical channels (IDE, SCSI and Network) will be uniformly
-  * distributed across all available CPUs.
+  * channel interrupt load by binding a channel to VCPU.
+  * We do this in a hierarchical fashion:
+  * First distribute the primary channels across available NUMA nodes
+  * and then distribute the subchannels amongst the CPUs in the NUMA
+  * node assigned to the primary channel.
+  *
+  * For pre-win8 hosts or non-performance critical channels we assign the
+  * first CPU in the first NUMA node.
   */
 -static void init_vp_index(struct vmbus_channel *channel, const uuid_le *type_guid)
 +static void init_vp_index(struct vmbus_channel *channel, uuid_le *type_guid)
  {
  	u32 cur_cpu;
  	int i;
  	bool perf_chn = false;
++<<<<<<< HEAD
 +	u32 max_cpus = num_online_cpus();
++=======
+ 	struct vmbus_channel *primary = channel->primary_channel;
+ 	int next_node;
+ 	struct cpumask available_mask;
++>>>>>>> 1f656ff3fddd (Drivers: hv: vmbus: Implement NUMA aware CPU affinity for channels)
  
  	for (i = IDE; i < MAX_PERF_CHN; i++) {
  		if (!memcmp(type_guid->b, hp_devs[i].guid,
@@@ -408,7 -413,42 +418,46 @@@
  		channel->target_vp = hv_context.vp_index[0];
  		return;
  	}
++<<<<<<< HEAD
 +	cur_cpu = (++next_vp % max_cpus);
++=======
+ 
+ 	/*
+ 	 * We distribute primary channels evenly across all the available
+ 	 * NUMA nodes and within the assigned NUMA node we will assign the
+ 	 * first available CPU to the primary channel.
+ 	 * The sub-channels will be assigned to the CPUs available in the
+ 	 * NUMA node evenly.
+ 	 */
+ 	if (!primary) {
+ 		while (true) {
+ 			next_node = next_numa_node_id++;
+ 			if (next_node == nr_node_ids)
+ 				next_node = next_numa_node_id = 0;
+ 			if (cpumask_empty(cpumask_of_node(next_node)))
+ 				continue;
+ 			break;
+ 		}
+ 		channel->numa_node = next_node;
+ 		primary = channel;
+ 	}
+ 
+ 	if (cpumask_weight(&primary->alloced_cpus_in_node) ==
+ 	    cpumask_weight(cpumask_of_node(primary->numa_node))) {
+ 		/*
+ 		 * We have cycled through all the CPUs in the node;
+ 		 * reset the alloced map.
+ 		 */
+ 		cpumask_clear(&primary->alloced_cpus_in_node);
+ 	}
+ 
+ 	cpumask_xor(&available_mask, &primary->alloced_cpus_in_node,
+ 		    cpumask_of_node(primary->numa_node));
+ 
+ 	cur_cpu = cpumask_next(-1, &available_mask);
+ 	cpumask_set_cpu(cur_cpu, &primary->alloced_cpus_in_node);
+ 
++>>>>>>> 1f656ff3fddd (Drivers: hv: vmbus: Implement NUMA aware CPU affinity for channels)
  	channel->target_cpu = cur_cpu;
  	channel->target_vp = hv_context.vp_index[cur_cpu];
  }
* Unmerged path drivers/hv/channel_mgmt.c
diff --git a/include/linux/hyperv.h b/include/linux/hyperv.h
index 5538109db318..8f74809a8bcd 100644
--- a/include/linux/hyperv.h
+++ b/include/linux/hyperv.h
@@ -694,6 +694,11 @@ struct vmbus_channel {
 	u32 target_vp;
 	/* The corresponding CPUID in the guest */
 	u32 target_cpu;
+	/*
+	 * State to manage the CPU affiliation of channels.
+	 */
+	struct cpumask alloced_cpus_in_node;
+	int numa_node;
 	/*
 	 * Support for sub-channels. For high performance devices,
 	 * it will be useful to have multiple sub-channels to support
