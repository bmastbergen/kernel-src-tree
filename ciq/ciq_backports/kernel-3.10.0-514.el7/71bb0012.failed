rhashtable: initialize all rhashtable walker members

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Sasha Levin <sasha.levin@oracle.com>
commit 71bb0012c38fbd090a56b3cb96e9f626c415d264
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/71bb0012.failed

Commit f2dba9c6ff ("rhashtable: Introduce rhashtable_walk_*") forgot to
initialize the members of struct rhashtable_walker after allocating it, which
caused an undefined value for 'resize' which is used later on.

Fixes: f2dba9c6ff ("rhashtable: Introduce rhashtable_walk_*")
	Signed-off-by: Sasha Levin <sasha.levin@oracle.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 71bb0012c38fbd090a56b3cb96e9f626c415d264)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	lib/rhashtable.c
diff --cc lib/rhashtable.c
index 6d0c4774001c,e3a04e4b3ec5..000000000000
--- a/lib/rhashtable.c
+++ b/lib/rhashtable.c
@@@ -461,6 -783,255 +461,258 @@@ void *rhashtable_lookup_compare(const s
  }
  EXPORT_SYMBOL_GPL(rhashtable_lookup_compare);
  
++<<<<<<< HEAD
++=======
+ /**
+  * rhashtable_lookup_insert - lookup and insert object into hash table
+  * @ht:		hash table
+  * @obj:	pointer to hash head inside object
+  *
+  * Locks down the bucket chain in both the old and new table if a resize
+  * is in progress to ensure that writers can't remove from the old table
+  * and can't insert to the new table during the atomic operation of search
+  * and insertion. Searches for duplicates in both the old and new table if
+  * a resize is in progress.
+  *
+  * This lookup function may only be used for fixed key hash table (key_len
+  * parameter set). It will BUG() if used inappropriately.
+  *
+  * It is safe to call this function from atomic context.
+  *
+  * Will trigger an automatic deferred table resizing if the size grows
+  * beyond the watermark indicated by grow_decision() which can be passed
+  * to rhashtable_init().
+  */
+ bool rhashtable_lookup_insert(struct rhashtable *ht, struct rhash_head *obj)
+ {
+ 	struct rhashtable_compare_arg arg = {
+ 		.ht = ht,
+ 		.key = rht_obj(ht, obj) + ht->p.key_offset,
+ 	};
+ 
+ 	BUG_ON(!ht->p.key_len);
+ 
+ 	return rhashtable_lookup_compare_insert(ht, obj, &rhashtable_compare,
+ 						&arg);
+ }
+ EXPORT_SYMBOL_GPL(rhashtable_lookup_insert);
+ 
+ /**
+  * rhashtable_lookup_compare_insert - search and insert object to hash table
+  *                                    with compare function
+  * @ht:		hash table
+  * @obj:	pointer to hash head inside object
+  * @compare:	compare function, must return true on match
+  * @arg:	argument passed on to compare function
+  *
+  * Locks down the bucket chain in both the old and new table if a resize
+  * is in progress to ensure that writers can't remove from the old table
+  * and can't insert to the new table during the atomic operation of search
+  * and insertion. Searches for duplicates in both the old and new table if
+  * a resize is in progress.
+  *
+  * Lookups may occur in parallel with hashtable mutations and resizing.
+  *
+  * Will trigger an automatic deferred table resizing if the size grows
+  * beyond the watermark indicated by grow_decision() which can be passed
+  * to rhashtable_init().
+  */
+ bool rhashtable_lookup_compare_insert(struct rhashtable *ht,
+ 				      struct rhash_head *obj,
+ 				      bool (*compare)(void *, void *),
+ 				      void *arg)
+ {
+ 	struct bucket_table *new_tbl, *old_tbl;
+ 	u32 new_hash;
+ 	bool success = true;
+ 
+ 	BUG_ON(!ht->p.key_len);
+ 
+ 	rcu_read_lock();
+ 	old_tbl = rht_dereference_rcu(ht->tbl, ht);
+ 	new_tbl = rht_dereference_rcu(ht->future_tbl, ht);
+ 	new_hash = obj_raw_hashfn(ht, rht_obj(ht, obj));
+ 
+ 	lock_buckets(new_tbl, old_tbl, new_hash);
+ 
+ 	if (rhashtable_lookup_compare(ht, rht_obj(ht, obj) + ht->p.key_offset,
+ 				      compare, arg)) {
+ 		success = false;
+ 		goto exit;
+ 	}
+ 
+ 	__rhashtable_insert(ht, obj, new_tbl, new_hash);
+ 
+ exit:
+ 	unlock_buckets(new_tbl, old_tbl, new_hash);
+ 	rcu_read_unlock();
+ 
+ 	return success;
+ }
+ EXPORT_SYMBOL_GPL(rhashtable_lookup_compare_insert);
+ 
+ /**
+  * rhashtable_walk_init - Initialise an iterator
+  * @ht:		Table to walk over
+  * @iter:	Hash table Iterator
+  *
+  * This function prepares a hash table walk.
+  *
+  * Note that if you restart a walk after rhashtable_walk_stop you
+  * may see the same object twice.  Also, you may miss objects if
+  * there are removals in between rhashtable_walk_stop and the next
+  * call to rhashtable_walk_start.
+  *
+  * For a completely stable walk you should construct your own data
+  * structure outside the hash table.
+  *
+  * This function may sleep so you must not call it from interrupt
+  * context or with spin locks held.
+  *
+  * You must call rhashtable_walk_exit if this function returns
+  * successfully.
+  */
+ int rhashtable_walk_init(struct rhashtable *ht, struct rhashtable_iter *iter)
+ {
+ 	iter->ht = ht;
+ 	iter->p = NULL;
+ 	iter->slot = 0;
+ 	iter->skip = 0;
+ 
+ 	iter->walker = kmalloc(sizeof(*iter->walker), GFP_KERNEL);
+ 	if (!iter->walker)
+ 		return -ENOMEM;
+ 
+ 	INIT_LIST_HEAD(&iter->walker->list);
+ 	iter->walker->resize = false;
+ 
+ 	mutex_lock(&ht->mutex);
+ 	list_add(&iter->walker->list, &ht->walkers);
+ 	mutex_unlock(&ht->mutex);
+ 
+ 	return 0;
+ }
+ EXPORT_SYMBOL_GPL(rhashtable_walk_init);
+ 
+ /**
+  * rhashtable_walk_exit - Free an iterator
+  * @iter:	Hash table Iterator
+  *
+  * This function frees resources allocated by rhashtable_walk_init.
+  */
+ void rhashtable_walk_exit(struct rhashtable_iter *iter)
+ {
+ 	mutex_lock(&iter->ht->mutex);
+ 	list_del(&iter->walker->list);
+ 	mutex_unlock(&iter->ht->mutex);
+ 	kfree(iter->walker);
+ }
+ EXPORT_SYMBOL_GPL(rhashtable_walk_exit);
+ 
+ /**
+  * rhashtable_walk_start - Start a hash table walk
+  * @iter:	Hash table iterator
+  *
+  * Start a hash table walk.  Note that we take the RCU lock in all
+  * cases including when we return an error.  So you must always call
+  * rhashtable_walk_stop to clean up.
+  *
+  * Returns zero if successful.
+  *
+  * Returns -EAGAIN if resize event occured.  Note that the iterator
+  * will rewind back to the beginning and you may use it immediately
+  * by calling rhashtable_walk_next.
+  */
+ int rhashtable_walk_start(struct rhashtable_iter *iter)
+ {
+ 	rcu_read_lock();
+ 
+ 	if (iter->walker->resize) {
+ 		iter->slot = 0;
+ 		iter->skip = 0;
+ 		iter->walker->resize = false;
+ 		return -EAGAIN;
+ 	}
+ 
+ 	return 0;
+ }
+ EXPORT_SYMBOL_GPL(rhashtable_walk_start);
+ 
+ /**
+  * rhashtable_walk_next - Return the next object and advance the iterator
+  * @iter:	Hash table iterator
+  *
+  * Note that you must call rhashtable_walk_stop when you are finished
+  * with the walk.
+  *
+  * Returns the next object or NULL when the end of the table is reached.
+  *
+  * Returns -EAGAIN if resize event occured.  Note that the iterator
+  * will rewind back to the beginning and you may continue to use it.
+  */
+ void *rhashtable_walk_next(struct rhashtable_iter *iter)
+ {
+ 	const struct bucket_table *tbl;
+ 	struct rhashtable *ht = iter->ht;
+ 	struct rhash_head *p = iter->p;
+ 	void *obj = NULL;
+ 
+ 	tbl = rht_dereference_rcu(ht->tbl, ht);
+ 
+ 	if (p) {
+ 		p = rht_dereference_bucket_rcu(p->next, tbl, iter->slot);
+ 		goto next;
+ 	}
+ 
+ 	for (; iter->slot < tbl->size; iter->slot++) {
+ 		int skip = iter->skip;
+ 
+ 		rht_for_each_rcu(p, tbl, iter->slot) {
+ 			if (!skip)
+ 				break;
+ 			skip--;
+ 		}
+ 
+ next:
+ 		if (!rht_is_a_nulls(p)) {
+ 			iter->skip++;
+ 			iter->p = p;
+ 			obj = rht_obj(ht, p);
+ 			goto out;
+ 		}
+ 
+ 		iter->skip = 0;
+ 	}
+ 
+ 	iter->p = NULL;
+ 
+ out:
+ 	if (iter->walker->resize) {
+ 		iter->p = NULL;
+ 		iter->slot = 0;
+ 		iter->skip = 0;
+ 		iter->walker->resize = false;
+ 		return ERR_PTR(-EAGAIN);
+ 	}
+ 
+ 	return obj;
+ }
+ EXPORT_SYMBOL_GPL(rhashtable_walk_next);
+ 
+ /**
+  * rhashtable_walk_stop - Finish a hash table walk
+  * @iter:	Hash table iterator
+  *
+  * Finish a hash table walk.
+  */
+ void rhashtable_walk_stop(struct rhashtable_iter *iter)
+ {
+ 	rcu_read_unlock();
+ 	iter->p = NULL;
+ }
+ EXPORT_SYMBOL_GPL(rhashtable_walk_stop);
+ 
++>>>>>>> 71bb0012c38f (rhashtable: initialize all rhashtable walker members)
  static size_t rounded_hashtable_size(struct rhashtable_params *params)
  {
  	return max(roundup_pow_of_two(params->nelem_hint * 4 / 3),
* Unmerged path lib/rhashtable.c
