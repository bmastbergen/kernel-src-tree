x86: Make is_64bit_mm() widely available

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [x86] Make is_64bit_mm() widely available (Rui Wang) [1138650]
Rebuild_FUZZ: 93.33%
commit-author Dave Hansen <dave.hansen@linux.intel.com>
commit b0e9b09b3bd64e67bba862e238d3757b2482b6de
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/b0e9b09b.failed

The uprobes code has a nice helper, is_64bit_mm(), that consults
both the runtime and compile-time flags for 32-bit support.
Instead of reinventing the wheel, pull it in to an x86 header so
we can use it for MPX.

I prefer passing the 'mm' around to test_thread_flag(TIF_IA32)
because it makes it explicit where the context is coming from.

	Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
	Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: Andrew Morton <akpm@linux-foundation.org>
	Cc: Dave Hansen <dave@sr71.net>
	Cc: H. Peter Anvin <hpa@zytor.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Oleg Nesterov <oleg@redhat.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
Link: http://lkml.kernel.org/r/20150607183704.F0209999@viggo.jf.intel.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit b0e9b09b3bd64e67bba862e238d3757b2482b6de)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/mmu_context.h
diff --cc arch/x86/include/asm/mmu_context.h
index be12c534fd59,5e8daee7c5c9..000000000000
--- a/arch/x86/include/asm/mmu_context.h
+++ b/arch/x86/include/asm/mmu_context.h
@@@ -96,4 -131,58 +96,61 @@@ do {						
  } while (0)
  #endif
  
++<<<<<<< HEAD
++=======
+ static inline void arch_dup_mmap(struct mm_struct *oldmm,
+ 				 struct mm_struct *mm)
+ {
+ 	paravirt_arch_dup_mmap(oldmm, mm);
+ }
+ 
+ static inline void arch_exit_mmap(struct mm_struct *mm)
+ {
+ 	paravirt_arch_exit_mmap(mm);
+ }
+ 
+ #ifdef CONFIG_X86_64
+ static inline bool is_64bit_mm(struct mm_struct *mm)
+ {
+ 	return	!config_enabled(CONFIG_IA32_EMULATION) ||
+ 		!(mm->context.ia32_compat == TIF_IA32);
+ }
+ #else
+ static inline bool is_64bit_mm(struct mm_struct *mm)
+ {
+ 	return false;
+ }
+ #endif
+ 
+ static inline void arch_bprm_mm_init(struct mm_struct *mm,
+ 		struct vm_area_struct *vma)
+ {
+ 	mpx_mm_init(mm);
+ }
+ 
+ static inline void arch_unmap(struct mm_struct *mm, struct vm_area_struct *vma,
+ 			      unsigned long start, unsigned long end)
+ {
+ 	/*
+ 	 * mpx_notify_unmap() goes and reads a rarely-hot
+ 	 * cacheline in the mm_struct.  That can be expensive
+ 	 * enough to be seen in profiles.
+ 	 *
+ 	 * The mpx_notify_unmap() call and its contents have been
+ 	 * observed to affect munmap() performance on hardware
+ 	 * where MPX is not present.
+ 	 *
+ 	 * The unlikely() optimizes for the fast case: no MPX
+ 	 * in the CPU, or no MPX use in the process.  Even if
+ 	 * we get this wrong (in the unlikely event that MPX
+ 	 * is widely enabled on some system) the overhead of
+ 	 * MPX itself (reading bounds tables) is expected to
+ 	 * overwhelm the overhead of getting this unlikely()
+ 	 * consistently wrong.
+ 	 */
+ 	if (unlikely(cpu_feature_enabled(X86_FEATURE_MPX)))
+ 		mpx_notify_unmap(mm, vma, start, end);
+ }
+ 
++>>>>>>> b0e9b09b3bd6 (x86: Make is_64bit_mm() widely available)
  #endif /* _ASM_X86_MMU_CONTEXT_H */
* Unmerged path arch/x86/include/asm/mmu_context.h
diff --git a/arch/x86/kernel/uprobes.c b/arch/x86/kernel/uprobes.c
index d4fb4c8f5f4e..ec162e762c91 100644
--- a/arch/x86/kernel/uprobes.c
+++ b/arch/x86/kernel/uprobes.c
@@ -29,6 +29,7 @@
 #include <linux/kdebug.h>
 #include <asm/processor.h>
 #include <asm/insn.h>
+#include <asm/mmu_context.h>
 
 /* Post-execution fixups. */
 
@@ -245,11 +246,6 @@ static int uprobe_init_insn(struct arch_uprobe *auprobe, struct insn *insn, bool
 }
 
 #ifdef CONFIG_X86_64
-static inline bool is_64bit_mm(struct mm_struct *mm)
-{
-	return	!config_enabled(CONFIG_IA32_EMULATION) ||
-		!(mm->context.ia32_compat == TIF_IA32);
-}
 /*
  * If arch_uprobe->insn doesn't use rip-relative addressing, return
  * immediately.  Otherwise, rewrite the instruction so that it accesses
@@ -430,10 +426,6 @@ static void riprel_post_xol(struct arch_uprobe *auprobe, struct pt_regs *regs)
 	}
 }
 #else /* 32-bit: */
-static inline bool is_64bit_mm(struct mm_struct *mm)
-{
-	return false;
-}
 /*
  * No RIP-relative addressing on 32-bit
  */
