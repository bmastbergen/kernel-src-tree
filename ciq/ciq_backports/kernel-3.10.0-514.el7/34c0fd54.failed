mm, dax, pmem: introduce pfn_t

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Dan Williams <dan.j.williams@intel.com>
commit 34c0fd540e79fb49ef9ce864dae1058cca265780
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/34c0fd54.failed

For the purpose of communicating the optional presence of a 'struct
page' for the pfn returned from ->direct_access(), introduce a type that
encapsulates a page-frame-number plus flags.  These flags contain the
historical "page_link" encoding for a scatterlist entry, but can also
denote "device memory".  Where "device memory" is a set of pfns that are
not part of the kernel's linear mapping by default, but are accessed via
the same memory controller as ram.

The motivation for this new type is large capacity persistent memory
that needs struct page entries in the 'memmap' to support 3rd party DMA
(i.e.  O_DIRECT I/O with a persistent memory source/target).  However,
we also need it in support of maintaining a list of mapped inodes which
need to be unmapped at driver teardown or freeze_bdev() time.

	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
	Cc: Christoph Hellwig <hch@lst.de>
	Cc: Dave Hansen <dave@sr71.net>
	Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 34c0fd540e79fb49ef9ce864dae1058cca265780)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/sysdev/axonram.c
#	drivers/block/brd.c
#	drivers/nvdimm/pmem.c
#	drivers/s390/block/dcssblk.c
#	fs/dax.c
#	include/linux/blkdev.h
#	kernel/memremap.c
diff --cc arch/powerpc/sysdev/axonram.c
index 45bc123f9227,0d112b94d91d..000000000000
--- a/arch/powerpc/sysdev/axonram.c
+++ b/arch/powerpc/sysdev/axonram.c
@@@ -140,14 -143,13 +141,23 @@@ axon_ram_make_request(struct request_qu
   */
  static long
  axon_ram_direct_access(struct block_device *device, sector_t sector,
++<<<<<<< HEAD
 +		       void **kaddr, unsigned long *pfn, long size)
 +{
 +	struct axon_ram_bank *bank = device->bd_disk->private_data;
 +	loff_t offset = (loff_t)sector << AXON_RAM_SECTOR_SHIFT;
 +
 +	*kaddr = (void *)(bank->ph_addr + offset);
 +	*pfn = virt_to_phys(kaddr) >> PAGE_SHIFT;
++=======
+ 		       void __pmem **kaddr, pfn_t *pfn)
+ {
+ 	struct axon_ram_bank *bank = device->bd_disk->private_data;
+ 	loff_t offset = (loff_t)sector << AXON_RAM_SECTOR_SHIFT;
++>>>>>>> 34c0fd540e79 (mm, dax, pmem: introduce pfn_t)
  
+ 	*kaddr = (void __pmem __force *) bank->io_addr + offset;
+ 	*pfn = phys_to_pfn_t(bank->ph_addr + offset, PFN_DEV);
  	return bank->size - offset;
  }
  
diff --cc drivers/block/brd.c
index 9c60a3cd03eb,cb27190e9f39..000000000000
--- a/drivers/block/brd.c
+++ b/drivers/block/brd.c
@@@ -371,7 -381,7 +374,11 @@@ static int brd_rw_page(struct block_dev
  
  #ifdef CONFIG_BLK_DEV_RAM_DAX
  static long brd_direct_access(struct block_device *bdev, sector_t sector,
++<<<<<<< HEAD
 +			void **kaddr, unsigned long *pfn, long size)
++=======
+ 			void __pmem **kaddr, pfn_t *pfn)
++>>>>>>> 34c0fd540e79 (mm, dax, pmem: introduce pfn_t)
  {
  	struct brd_device *brd = bdev->bd_disk->private_data;
  	struct page *page;
@@@ -381,13 -391,9 +388,18 @@@
  	page = brd_insert_page(brd, sector);
  	if (!page)
  		return -ENOSPC;
++<<<<<<< HEAD
 +	*kaddr = page_address(page);
 +	*pfn = page_to_pfn(page);
++=======
+ 	*kaddr = (void __pmem *)page_address(page);
+ 	*pfn = page_to_pfn_t(page);
++>>>>>>> 34c0fd540e79 (mm, dax, pmem: introduce pfn_t)
  
 +	/*
 +	 * TODO: If size > PAGE_SIZE, we could look to see if the next page in
 +	 * the file happens to be mapped to the next page of physical RAM.
 +	 */
  	return PAGE_SIZE;
  }
  #else
diff --cc drivers/s390/block/dcssblk.c
index 234818c98b8f,ce7b70181740..000000000000
--- a/drivers/s390/block/dcssblk.c
+++ b/drivers/s390/block/dcssblk.c
@@@ -27,9 -28,10 +28,13 @@@
  
  static int dcssblk_open(struct block_device *bdev, fmode_t mode);
  static void dcssblk_release(struct gendisk *disk, fmode_t mode);
 -static blk_qc_t dcssblk_make_request(struct request_queue *q,
 -						struct bio *bio);
 +static void dcssblk_make_request(struct request_queue *q, struct bio *bio);
  static long dcssblk_direct_access(struct block_device *bdev, sector_t secnum,
++<<<<<<< HEAD
 +				 void **kaddr, unsigned long *pfn, long size);
++=======
+ 			 void __pmem **kaddr, pfn_t *pfn);
++>>>>>>> 34c0fd540e79 (mm, dax, pmem: introduce pfn_t)
  
  static char dcssblk_segments[DCSSBLK_PARM_LEN] = "\0";
  
@@@ -867,7 -884,7 +872,11 @@@ fail
  
  static long
  dcssblk_direct_access (struct block_device *bdev, sector_t secnum,
++<<<<<<< HEAD
 +			void **kaddr, unsigned long *pfn, long size)
++=======
+ 			void __pmem **kaddr, pfn_t *pfn)
++>>>>>>> 34c0fd540e79 (mm, dax, pmem: introduce pfn_t)
  {
  	struct dcssblk_dev_info *dev_info;
  	unsigned long offset, dev_sz;
@@@ -877,8 -894,8 +886,13 @@@
  		return -ENODEV;
  	dev_sz = dev_info->end - dev_info->start;
  	offset = secnum * 512;
++<<<<<<< HEAD
 +	*kaddr = (void *) (dev_info->start + offset);
 +	*pfn = virt_to_phys(*kaddr) >> PAGE_SHIFT;
++=======
+ 	*kaddr = (void __pmem *) (dev_info->start + offset);
+ 	*pfn = __pfn_to_pfn_t(PFN_DOWN(dev_info->start + offset), PFN_DEV);
++>>>>>>> 34c0fd540e79 (mm, dax, pmem: introduce pfn_t)
  
  	return dev_sz - offset;
  }
diff --cc include/linux/blkdev.h
index 0e72d45d3caf,bfb64d672e19..000000000000
--- a/include/linux/blkdev.h
+++ b/include/linux/blkdev.h
@@@ -12,9 -12,10 +12,10 @@@
  #include <linux/timer.h>
  #include <linux/workqueue.h>
  #include <linux/pagemap.h>
 -#include <linux/backing-dev-defs.h>
 +#include <linux/backing-dev.h>
  #include <linux/wait.h>
  #include <linux/mempool.h>
+ #include <linux/pfn.h>
  #include <linux/bio.h>
  #include <linux/stringify.h>
  #include <linux/gfp.h>
@@@ -1643,14 -1618,28 +1644,36 @@@ static inline bool blk_integrity_is_ini
  
  #endif /* CONFIG_BLK_DEV_INTEGRITY */
  
++<<<<<<< HEAD
++=======
+ /**
+  * struct blk_dax_ctl - control and output parameters for ->direct_access
+  * @sector: (input) offset relative to a block_device
+  * @addr: (output) kernel virtual address for @sector populated by driver
+  * @pfn: (output) page frame number for @addr populated by driver
+  * @size: (input) number of bytes requested
+  */
+ struct blk_dax_ctl {
+ 	sector_t sector;
+ 	void __pmem *addr;
+ 	long size;
+ 	pfn_t pfn;
+ };
+ 
++>>>>>>> 34c0fd540e79 (mm, dax, pmem: introduce pfn_t)
  struct block_device_operations {
  	int (*open) (struct block_device *, fmode_t);
  	void (*release) (struct gendisk *, fmode_t);
  	int (*rw_page)(struct block_device *, sector_t, struct page *, int rw);
  	int (*ioctl) (struct block_device *, fmode_t, unsigned, unsigned long);
  	int (*compat_ioctl) (struct block_device *, fmode_t, unsigned, unsigned long);
++<<<<<<< HEAD
 +	long (*direct_access)(struct block_device *, sector_t,
 +					void **, unsigned long *pfn, long size);
++=======
+ 	long (*direct_access)(struct block_device *, sector_t, void __pmem **,
+ 			pfn_t *);
++>>>>>>> 34c0fd540e79 (mm, dax, pmem: introduce pfn_t)
  	unsigned int (*check_events) (struct gendisk *disk,
  				      unsigned int clearing);
  	/* ->media_changed() is DEPRECATED, use ->check_events() instead */
diff --cc kernel/memremap.c
index 26717809cbd2,449cb6a5d9a1..000000000000
--- a/kernel/memremap.c
+++ b/kernel/memremap.c
@@@ -12,8 -12,10 +12,9 @@@
   */
  #include <linux/device.h>
  #include <linux/types.h>
+ #include <linux/pfn_t.h>
  #include <linux/io.h>
  #include <linux/mm.h>
 -#include <linux/memory_hotplug.h>
  
  #ifndef ioremap_cache
  /* temporary while we convert existing ioremap_cache users to memremap */
@@@ -144,3 -147,61 +145,64 @@@ void devm_memunmap(struct device *dev, 
  				devm_memremap_match, addr));
  }
  EXPORT_SYMBOL(devm_memunmap);
++<<<<<<< HEAD
++=======
+ 
+ pfn_t phys_to_pfn_t(dma_addr_t addr, unsigned long flags)
+ {
+ 	return __pfn_to_pfn_t(addr >> PAGE_SHIFT, flags);
+ }
+ EXPORT_SYMBOL(phys_to_pfn_t);
+ 
+ #ifdef CONFIG_ZONE_DEVICE
+ struct page_map {
+ 	struct resource res;
+ };
+ 
+ static void devm_memremap_pages_release(struct device *dev, void *res)
+ {
+ 	struct page_map *page_map = res;
+ 
+ 	/* pages are dead and unused, undo the arch mapping */
+ 	arch_remove_memory(page_map->res.start, resource_size(&page_map->res));
+ }
+ 
+ void *devm_memremap_pages(struct device *dev, struct resource *res)
+ {
+ 	int is_ram = region_intersects(res->start, resource_size(res),
+ 			"System RAM");
+ 	struct page_map *page_map;
+ 	int error, nid;
+ 
+ 	if (is_ram == REGION_MIXED) {
+ 		WARN_ONCE(1, "%s attempted on mixed region %pr\n",
+ 				__func__, res);
+ 		return ERR_PTR(-ENXIO);
+ 	}
+ 
+ 	if (is_ram == REGION_INTERSECTS)
+ 		return __va(res->start);
+ 
+ 	page_map = devres_alloc_node(devm_memremap_pages_release,
+ 			sizeof(*page_map), GFP_KERNEL, dev_to_node(dev));
+ 	if (!page_map)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	memcpy(&page_map->res, res, sizeof(*res));
+ 
+ 	nid = dev_to_node(dev);
+ 	if (nid < 0)
+ 		nid = numa_mem_id();
+ 
+ 	error = arch_add_memory(nid, res->start, resource_size(res), true);
+ 	if (error) {
+ 		devres_free(page_map);
+ 		return ERR_PTR(error);
+ 	}
+ 
+ 	devres_add(dev, page_map);
+ 	return __va(res->start);
+ }
+ EXPORT_SYMBOL(devm_memremap_pages);
+ #endif /* CONFIG_ZONE_DEVICE */
++>>>>>>> 34c0fd540e79 (mm, dax, pmem: introduce pfn_t)
* Unmerged path drivers/nvdimm/pmem.c
* Unmerged path fs/dax.c
* Unmerged path arch/powerpc/sysdev/axonram.c
* Unmerged path drivers/block/brd.c
* Unmerged path drivers/nvdimm/pmem.c
* Unmerged path drivers/s390/block/dcssblk.c
* Unmerged path fs/dax.c
* Unmerged path include/linux/blkdev.h
diff --git a/include/linux/pfn.h b/include/linux/pfn.h
index 7646637221f3..96df85985f16 100644
--- a/include/linux/pfn.h
+++ b/include/linux/pfn.h
@@ -3,6 +3,15 @@
 
 #ifndef __ASSEMBLY__
 #include <linux/types.h>
+
+/*
+ * pfn_t: encapsulates a page-frame number that is optionally backed
+ * by memmap (struct page).  Whether a pfn_t has a 'struct page'
+ * backing is indicated by flags in the high bits of the value.
+ */
+typedef struct {
+	unsigned long val;
+} pfn_t;
 #endif
 
 #define PFN_ALIGN(x)	(((unsigned long)(x) + (PAGE_SIZE - 1)) & PAGE_MASK)
diff --git a/include/linux/pfn_t.h b/include/linux/pfn_t.h
new file mode 100644
index 000000000000..c557a0e0b20c
--- /dev/null
+++ b/include/linux/pfn_t.h
@@ -0,0 +1,67 @@
+#ifndef _LINUX_PFN_T_H_
+#define _LINUX_PFN_T_H_
+#include <linux/mm.h>
+
+/*
+ * PFN_FLAGS_MASK - mask of all the possible valid pfn_t flags
+ * PFN_SG_CHAIN - pfn is a pointer to the next scatterlist entry
+ * PFN_SG_LAST - pfn references a page and is the last scatterlist entry
+ * PFN_DEV - pfn is not covered by system memmap by default
+ * PFN_MAP - pfn has a dynamic page mapping established by a device driver
+ */
+#define PFN_FLAGS_MASK (((unsigned long) ~PAGE_MASK) \
+		<< (BITS_PER_LONG - PAGE_SHIFT))
+#define PFN_SG_CHAIN (1UL << (BITS_PER_LONG - 1))
+#define PFN_SG_LAST (1UL << (BITS_PER_LONG - 2))
+#define PFN_DEV (1UL << (BITS_PER_LONG - 3))
+#define PFN_MAP (1UL << (BITS_PER_LONG - 4))
+
+static inline pfn_t __pfn_to_pfn_t(unsigned long pfn, unsigned long flags)
+{
+	pfn_t pfn_t = { .val = pfn | (flags & PFN_FLAGS_MASK), };
+
+	return pfn_t;
+}
+
+/* a default pfn to pfn_t conversion assumes that @pfn is pfn_valid() */
+static inline pfn_t pfn_to_pfn_t(unsigned long pfn)
+{
+	return __pfn_to_pfn_t(pfn, 0);
+}
+
+extern pfn_t phys_to_pfn_t(dma_addr_t addr, unsigned long flags);
+
+static inline bool pfn_t_has_page(pfn_t pfn)
+{
+	return (pfn.val & PFN_MAP) == PFN_MAP || (pfn.val & PFN_DEV) == 0;
+}
+
+static inline unsigned long pfn_t_to_pfn(pfn_t pfn)
+{
+	return pfn.val & ~PFN_FLAGS_MASK;
+}
+
+static inline struct page *pfn_t_to_page(pfn_t pfn)
+{
+	if (pfn_t_has_page(pfn))
+		return pfn_to_page(pfn_t_to_pfn(pfn));
+	return NULL;
+}
+
+static inline dma_addr_t pfn_t_to_phys(pfn_t pfn)
+{
+	return PFN_PHYS(pfn_t_to_pfn(pfn));
+}
+
+static inline void *pfn_t_to_virt(pfn_t pfn)
+{
+	if (pfn_t_has_page(pfn))
+		return __va(pfn_t_to_phys(pfn));
+	return NULL;
+}
+
+static inline pfn_t page_to_pfn_t(struct page *page)
+{
+	return pfn_to_pfn_t(page_to_pfn(page));
+}
+#endif /* _LINUX_PFN_T_H_ */
* Unmerged path kernel/memremap.c
