mm/hmm/mirror: mirror process address space on device with HMM helpers

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [mm] hmm: mirror process address space on device with HMM helpers (Jerome Glisse) [1230959]
Rebuild_FUZZ: 92.31%
commit-author Jérôme Glisse <jglisse@redhat.com>
commit c0b124054f9e42eb6da545a10fe9122a7d7c3f72
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/c0b12405.failed

This is a heterogeneous memory management (HMM) process address space
mirroring.  In a nutshell this provide an API to mirror process address
space on a device.  This boils down to keeping CPU and device page table
synchronize (we assume that both device and CPU are cache coherent like
PCIe device can be).

This patch provide a simple API for device driver to achieve address space
mirroring thus avoiding each device driver to grow its own CPU page table
walker and its own CPU page table synchronization mechanism.

This is useful for NVidia GPU >= Pascal, Mellanox IB >= mlx5 and more
hardware in the future.

[jglisse@redhat.com: fix hmm for "mmu_notifier kill invalidate_page callback"]
  Link: http://lkml.kernel.org/r/20170830231955.GD9445@redhat.com
Link: http://lkml.kernel.org/r/20170817000548.32038-4-jglisse@redhat.com
	Signed-off-by: Jérôme Glisse <jglisse@redhat.com>
	Signed-off-by: Evgeny Baskakov <ebaskakov@nvidia.com>
	Signed-off-by: John Hubbard <jhubbard@nvidia.com>
	Signed-off-by: Mark Hairgrove <mhairgrove@nvidia.com>
	Signed-off-by: Sherry Cheung <SCheung@nvidia.com>
	Signed-off-by: Subhash Gutti <sgutti@nvidia.com>
	Cc: Aneesh Kumar <aneesh.kumar@linux.vnet.ibm.com>
	Cc: Balbir Singh <bsingharora@gmail.com>
	Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
	Cc: Dan Williams <dan.j.williams@intel.com>
	Cc: David Nellans <dnellans@nvidia.com>
	Cc: Johannes Weiner <hannes@cmpxchg.org>
	Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
	Cc: Michal Hocko <mhocko@kernel.org>
	Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
	Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
	Cc: Vladimir Davydov <vdavydov.dev@gmail.com>
	Cc: Bob Liu <liubo95@huawei.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit c0b124054f9e42eb6da545a10fe9122a7d7c3f72)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/hmm.h
#	mm/Kconfig
#	mm/hmm.c
diff --cc mm/Kconfig
index 88ac087b6ee9,254db99f263d..000000000000
--- a/mm/Kconfig
+++ b/mm/Kconfig
@@@ -572,3 -610,125 +572,128 @@@ config PGTABLE_MAPPIN
  
  	  You can check speed with zsmalloc benchmark:
  	  https://github.com/spartacus06/zsmapbench
++<<<<<<< HEAD
++=======
+ 
+ config ZSMALLOC_STAT
+ 	bool "Export zsmalloc statistics"
+ 	depends on ZSMALLOC
+ 	select DEBUG_FS
+ 	help
+ 	  This option enables code in the zsmalloc to collect various
+ 	  statistics about whats happening in zsmalloc and exports that
+ 	  information to userspace via debugfs.
+ 	  If unsure, say N.
+ 
+ config GENERIC_EARLY_IOREMAP
+ 	bool
+ 
+ config MAX_STACK_SIZE_MB
+ 	int "Maximum user stack size for 32-bit processes (MB)"
+ 	default 80
+ 	range 8 256 if METAG
+ 	range 8 2048
+ 	depends on STACK_GROWSUP && (!64BIT || COMPAT)
+ 	help
+ 	  This is the maximum stack size in Megabytes in the VM layout of 32-bit
+ 	  user processes when the stack grows upwards (currently only on parisc
+ 	  and metag arch). The stack will be located at the highest memory
+ 	  address minus the given value, unless the RLIMIT_STACK hard limit is
+ 	  changed to a smaller value in which case that is used.
+ 
+ 	  A sane initial value is 80 MB.
+ 
+ # For architectures that support deferred memory initialisation
+ config ARCH_SUPPORTS_DEFERRED_STRUCT_PAGE_INIT
+ 	bool
+ 
+ config DEFERRED_STRUCT_PAGE_INIT
+ 	bool "Defer initialisation of struct pages to kthreads"
+ 	default n
+ 	depends on ARCH_SUPPORTS_DEFERRED_STRUCT_PAGE_INIT
+ 	depends on NO_BOOTMEM && MEMORY_HOTPLUG
+ 	depends on !FLATMEM
+ 	help
+ 	  Ordinarily all struct pages are initialised during early boot in a
+ 	  single thread. On very large machines this can take a considerable
+ 	  amount of time. If this option is set, large machines will bring up
+ 	  a subset of memmap at boot and then initialise the rest in parallel
+ 	  by starting one-off "pgdatinitX" kernel thread for each node X. This
+ 	  has a potential performance impact on processes running early in the
+ 	  lifetime of the system until these kthreads finish the
+ 	  initialisation.
+ 
+ config IDLE_PAGE_TRACKING
+ 	bool "Enable idle page tracking"
+ 	depends on SYSFS && MMU
+ 	select PAGE_EXTENSION if !64BIT
+ 	help
+ 	  This feature allows to estimate the amount of user pages that have
+ 	  not been touched during a given period of time. This information can
+ 	  be useful to tune memory cgroup limits and/or for job placement
+ 	  within a compute cluster.
+ 
+ 	  See Documentation/vm/idle_page_tracking.txt for more details.
+ 
+ # arch_add_memory() comprehends device memory
+ config ARCH_HAS_ZONE_DEVICE
+ 	bool
+ 
+ config ZONE_DEVICE
+ 	bool "Device memory (pmem, etc...) hotplug support"
+ 	depends on MEMORY_HOTPLUG
+ 	depends on MEMORY_HOTREMOVE
+ 	depends on SPARSEMEM_VMEMMAP
+ 	depends on ARCH_HAS_ZONE_DEVICE
+ 	select RADIX_TREE_MULTIORDER
+ 
+ 	help
+ 	  Device memory hotplug support allows for establishing pmem,
+ 	  or other device driver discovered memory regions, in the
+ 	  memmap. This allows pfn_to_page() lookups of otherwise
+ 	  "device-physical" addresses which is needed for using a DAX
+ 	  mapping in an O_DIRECT operation, among other things.
+ 
+ 	  If FS_DAX is enabled, then say Y.
+ 
+ config ARCH_HAS_HMM
+ 	bool
+ 	default y
+ 	depends on (X86_64 || PPC64)
+ 	depends on ZONE_DEVICE
+ 	depends on MMU && 64BIT
+ 	depends on MEMORY_HOTPLUG
+ 	depends on MEMORY_HOTREMOVE
+ 	depends on SPARSEMEM_VMEMMAP
+ 
+ config HMM
+ 	bool
+ 
+ config HMM_MIRROR
+ 	bool "HMM mirror CPU page table into a device page table"
+ 	depends on ARCH_HAS_HMM
+ 	select MMU_NOTIFIER
+ 	select HMM
+ 	help
+ 	  Select HMM_MIRROR if you want to mirror range of the CPU page table of a
+ 	  process into a device page table. Here, mirror means "keep synchronized".
+ 	  Prerequisites: the device must provide the ability to write-protect its
+ 	  page tables (at PAGE_SIZE granularity), and must be able to recover from
+ 	  the resulting potential page faults.
+ 
+ config FRAME_VECTOR
+ 	bool
+ 
+ config ARCH_USES_HIGH_VMA_FLAGS
+ 	bool
+ config ARCH_HAS_PKEYS
+ 	bool
+ 
+ config PERCPU_STATS
+ 	bool "Collect percpu memory statistics"
+ 	default n
+ 	help
+ 	  This feature collects and exposes statistics via debugfs. The
+ 	  information includes global and per chunk statistics, which can
+ 	  be used to help understand percpu memory usage.
++>>>>>>> c0b124054f9e (mm/hmm/mirror: mirror process address space on device with HMM helpers)
* Unmerged path include/linux/hmm.h
* Unmerged path mm/hmm.c
* Unmerged path include/linux/hmm.h
* Unmerged path mm/Kconfig
* Unmerged path mm/hmm.c
