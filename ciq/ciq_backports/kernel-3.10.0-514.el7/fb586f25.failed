sctp: delay calls to sk_data_ready() as much as possible

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
commit fb586f25300f4587c7ebd097a604bf269b25bfa7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/fb586f25.failed

Currently processing of multiple chunks in a single SCTP packet leads to
multiple calls to sk_data_ready, causing multiple wake up signals which
are costy and doesn't make it wake up any faster.

With this patch it will note that the wake up is pending and will do it
before leaving the state machine interpreter, latest place possible to
do it realiably and cleanly.

Note that sk_data_ready events are not dependent on asocs, unlike waking
up writers.

v2: series re-checked
v3: use local vars to cleanup the code, suggested by Jakub Sitnicki
	Signed-off-by: Marcelo Ricardo Leitner <marcelo.leitner@gmail.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit fb586f25300f4587c7ebd097a604bf269b25bfa7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/sctp/structs.h
#	net/sctp/sm_sideeffect.c
#	net/sctp/ulpqueue.c
diff --cc include/net/sctp/structs.h
index f67eb807b1dd,21cb11107e37..000000000000
--- a/include/net/sctp/structs.h
+++ b/include/net/sctp/structs.h
@@@ -218,14 -206,19 +218,24 @@@ struct sctp_sock 
  	struct sctp_paddrparams paddrparam;
  	struct sctp_event_subscribe subscribe;
  	struct sctp_assocparams assocparams;
 -
  	int user_frag;
 -
  	__u32 autoclose;
 +	__u8 nodelay;
 +	__u8 disable_fragments;
 +	__u8 v4mapped;
 +	__u8 frag_interleave;
  	__u32 adaptation_ind;
  	__u32 pd_point;
++<<<<<<< HEAD
++=======
+ 	__u16	nodelay:1,
+ 		disable_fragments:1,
+ 		v4mapped:1,
+ 		frag_interleave:1,
+ 		recvrcvinfo:1,
+ 		recvnxtinfo:1,
+ 		pending_data_ready:1;
++>>>>>>> fb586f25300f (sctp: delay calls to sk_data_ready() as much as possible)
  
  	atomic_t pd_mode;
  	/* Receive to here while partial delivery is in effect. */
diff --cc net/sctp/sm_sideeffect.c
index 3850ffd28208,d06317de8730..000000000000
--- a/net/sctp/sm_sideeffect.c
+++ b/net/sctp/sm_sideeffect.c
@@@ -1768,9 -1741,14 +1770,18 @@@ out
  	 */
  	if (asoc && SCTP_EVENT_T_CHUNK == event_type && chunk) {
  		if (chunk->end_of_packet || chunk->singleton)
 -			error = sctp_outq_uncork(&asoc->outqueue, gfp);
 +			error = sctp_outq_uncork(&asoc->outqueue);
  	} else if (local_cork)
++<<<<<<< HEAD
 +		error = sctp_outq_uncork(&asoc->outqueue);
++=======
+ 		error = sctp_outq_uncork(&asoc->outqueue, gfp);
+ 
+ 	if (sp->pending_data_ready) {
+ 		sk->sk_data_ready(sk);
+ 		sp->pending_data_ready = 0;
+ 	}
++>>>>>>> fb586f25300f (sctp: delay calls to sk_data_ready() as much as possible)
  	return error;
  nomem:
  	error = -ENOMEM;
diff --cc net/sctp/ulpqueue.c
index 04e3d470f877,72e5b3e41cdd..000000000000
--- a/net/sctp/ulpqueue.c
+++ b/net/sctp/ulpqueue.c
@@@ -266,7 -264,7 +266,11 @@@ int sctp_ulpq_tail_event(struct sctp_ul
  		sctp_ulpq_clear_pd(ulpq);
  
  	if (queue == &sk->sk_receive_queue)
++<<<<<<< HEAD
 +		sk->sk_data_ready(sk, 0);
++=======
+ 		sctp_sk(sk)->pending_data_ready = 1;
++>>>>>>> fb586f25300f (sctp: delay calls to sk_data_ready() as much as possible)
  	return 1;
  
  out_free:
@@@ -1141,5 -1140,5 +1145,9 @@@ void sctp_ulpq_abort_pd(struct sctp_ulp
  
  	/* If there is data waiting, send it up the socket now. */
  	if (sctp_ulpq_clear_pd(ulpq) || ev)
++<<<<<<< HEAD
 +		sk->sk_data_ready(sk, 0);
++=======
+ 		sctp_sk(sk)->pending_data_ready = 1;
++>>>>>>> fb586f25300f (sctp: delay calls to sk_data_ready() as much as possible)
  }
* Unmerged path include/net/sctp/structs.h
* Unmerged path net/sctp/sm_sideeffect.c
* Unmerged path net/sctp/ulpqueue.c
