KVM: nVMX: nested VPID emulation

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Wanpeng Li <wanpeng.li@hotmail.com>
commit 5c614b3583e7b6dab0c86356fa36c2bcbb8322a0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/5c614b35.failed

VPID is used to tag address space and avoid a TLB flush. Currently L0 use
the same VPID to run L1 and all its guests. KVM flushes VPID when switching
between L1 and L2.

This patch advertises VPID to the L1 hypervisor, then address space of L1
and L2 can be separately treated and avoid TLB flush when swithing between
L1 and L2. For each nested vmentry, if vpid12 is changed, reuse shadow vpid
w/ an invvpid.

Performance:

run lmbench on L2 w/ 3.5 kernel.

Context switching - times in microseconds - smaller is better
-------------------------------------------------------------------------
Host                 OS  2p/0K 2p/16K 2p/64K 8p/16K 8p/64K 16p/16K 16p/64K
                         ctxsw  ctxsw  ctxsw ctxsw  ctxsw   ctxsw   ctxsw
--------- ------------- ------ ------ ------ ------ ------ ------- -------
kernel    Linux 3.5.0-1 1.2200 1.3700 1.4500 4.7800 2.3300 5.60000 2.88000  nested VPID
kernel    Linux 3.5.0-1 1.2600 1.4300 1.5600   12.7   12.9 3.49000 7.46000  vanilla

	Reviewed-by: Jan Kiszka <jan.kiszka@siemens.com>
	Reviewed-by: Wincy Van <fanwenyi0529@gmail.com>
	Signed-off-by: Wanpeng Li <wanpeng.li@hotmail.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 5c614b3583e7b6dab0c86356fa36c2bcbb8322a0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/vmx.c
diff --cc arch/x86/kvm/vmx.c
index dd100a1ff95e,bea552204aa2..000000000000
--- a/arch/x86/kvm/vmx.c
+++ b/arch/x86/kvm/vmx.c
@@@ -409,6 -425,27 +409,30 @@@ struct nested_vmx 
  
  	/* to migrate it to L2 if VM_ENTRY_LOAD_DEBUG_CONTROLS is off */
  	u64 vmcs01_debugctl;
++<<<<<<< HEAD
++=======
+ 
+ 	u16 vpid02;
+ 	u16 last_vpid;
+ 
+ 	u32 nested_vmx_procbased_ctls_low;
+ 	u32 nested_vmx_procbased_ctls_high;
+ 	u32 nested_vmx_true_procbased_ctls_low;
+ 	u32 nested_vmx_secondary_ctls_low;
+ 	u32 nested_vmx_secondary_ctls_high;
+ 	u32 nested_vmx_pinbased_ctls_low;
+ 	u32 nested_vmx_pinbased_ctls_high;
+ 	u32 nested_vmx_exit_ctls_low;
+ 	u32 nested_vmx_exit_ctls_high;
+ 	u32 nested_vmx_true_exit_ctls_low;
+ 	u32 nested_vmx_entry_ctls_low;
+ 	u32 nested_vmx_entry_ctls_high;
+ 	u32 nested_vmx_true_entry_ctls_low;
+ 	u32 nested_vmx_misc_low;
+ 	u32 nested_vmx_misc_high;
+ 	u32 nested_vmx_ept_caps;
+ 	u32 nested_vmx_vpid_caps;
++>>>>>>> 5c614b3583e7 (KVM: nVMX: nested VPID emulation)
  };
  
  #define POSTED_INTR_ON  0
@@@ -1148,6 -1205,37 +1172,40 @@@ static inline int nested_cpu_has_ept(st
  	return nested_cpu_has2(vmcs12, SECONDARY_EXEC_ENABLE_EPT);
  }
  
++<<<<<<< HEAD
++=======
+ static inline bool nested_cpu_has_xsaves(struct vmcs12 *vmcs12)
+ {
+ 	return nested_cpu_has2(vmcs12, SECONDARY_EXEC_XSAVES) &&
+ 		vmx_xsaves_supported();
+ }
+ 
+ static inline bool nested_cpu_has_virt_x2apic_mode(struct vmcs12 *vmcs12)
+ {
+ 	return nested_cpu_has2(vmcs12, SECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE);
+ }
+ 
+ static inline bool nested_cpu_has_vpid(struct vmcs12 *vmcs12)
+ {
+ 	return nested_cpu_has2(vmcs12, SECONDARY_EXEC_ENABLE_VPID);
+ }
+ 
+ static inline bool nested_cpu_has_apic_reg_virt(struct vmcs12 *vmcs12)
+ {
+ 	return nested_cpu_has2(vmcs12, SECONDARY_EXEC_APIC_REGISTER_VIRT);
+ }
+ 
+ static inline bool nested_cpu_has_vid(struct vmcs12 *vmcs12)
+ {
+ 	return nested_cpu_has2(vmcs12, SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY);
+ }
+ 
+ static inline bool nested_cpu_has_posted_intr(struct vmcs12 *vmcs12)
+ {
+ 	return vmcs12->pin_based_vm_exec_control & PIN_BASED_POSTED_INTR;
+ }
+ 
++>>>>>>> 5c614b3583e7 (KVM: nVMX: nested VPID emulation)
  static inline bool is_exception(u32 intr_info)
  {
  	return (intr_info & (INTR_INFO_INTR_TYPE_MASK | INTR_INFO_VALID_MASK))
@@@ -2433,11 -2591,19 +2491,22 @@@ static __init void nested_vmx_setup_ctl
  
  	/* secondary cpu-based controls */
  	rdmsr(MSR_IA32_VMX_PROCBASED_CTLS2,
 -		vmx->nested.nested_vmx_secondary_ctls_low,
 -		vmx->nested.nested_vmx_secondary_ctls_high);
 -	vmx->nested.nested_vmx_secondary_ctls_low = 0;
 -	vmx->nested.nested_vmx_secondary_ctls_high &=
 +		nested_vmx_secondary_ctls_low, nested_vmx_secondary_ctls_high);
 +	nested_vmx_secondary_ctls_low = 0;
 +	nested_vmx_secondary_ctls_high &=
  		SECONDARY_EXEC_VIRTUALIZE_APIC_ACCESSES |
++<<<<<<< HEAD
 +		SECONDARY_EXEC_WBINVD_EXITING;
++=======
+ 		SECONDARY_EXEC_RDTSCP |
+ 		SECONDARY_EXEC_VIRTUALIZE_X2APIC_MODE |
+ 		SECONDARY_EXEC_ENABLE_VPID |
+ 		SECONDARY_EXEC_APIC_REGISTER_VIRT |
+ 		SECONDARY_EXEC_VIRTUAL_INTR_DELIVERY |
+ 		SECONDARY_EXEC_WBINVD_EXITING |
+ 		SECONDARY_EXEC_XSAVES |
+ 		SECONDARY_EXEC_PCOMMIT;
++>>>>>>> 5c614b3583e7 (KVM: nVMX: nested VPID emulation)
  
  	if (enable_ept) {
  		/* nested EPT: emulate EPT also to L1 */
@@@ -6966,7 -7342,63 +7036,67 @@@ static int handle_invept(struct kvm_vcp
  
  static int handle_invvpid(struct kvm_vcpu *vcpu)
  {
++<<<<<<< HEAD
 +	kvm_queue_exception(vcpu, UD_VECTOR);
++=======
+ 	struct vcpu_vmx *vmx = to_vmx(vcpu);
+ 	u32 vmx_instruction_info;
+ 	unsigned long type, types;
+ 	gva_t gva;
+ 	struct x86_exception e;
+ 	int vpid;
+ 
+ 	if (!(vmx->nested.nested_vmx_secondary_ctls_high &
+ 	      SECONDARY_EXEC_ENABLE_VPID) ||
+ 			!(vmx->nested.nested_vmx_vpid_caps & VMX_VPID_INVVPID_BIT)) {
+ 		kvm_queue_exception(vcpu, UD_VECTOR);
+ 		return 1;
+ 	}
+ 
+ 	if (!nested_vmx_check_permission(vcpu))
+ 		return 1;
+ 
+ 	vmx_instruction_info = vmcs_read32(VMX_INSTRUCTION_INFO);
+ 	type = kvm_register_readl(vcpu, (vmx_instruction_info >> 28) & 0xf);
+ 
+ 	types = (vmx->nested.nested_vmx_vpid_caps >> 8) & 0x7;
+ 
+ 	if (!(types & (1UL << type))) {
+ 		nested_vmx_failValid(vcpu,
+ 			VMXERR_INVALID_OPERAND_TO_INVEPT_INVVPID);
+ 		return 1;
+ 	}
+ 
+ 	/* according to the intel vmx instruction reference, the memory
+ 	 * operand is read even if it isn't needed (e.g., for type==global)
+ 	 */
+ 	if (get_vmx_mem_address(vcpu, vmcs_readl(EXIT_QUALIFICATION),
+ 			vmx_instruction_info, false, &gva))
+ 		return 1;
+ 	if (kvm_read_guest_virt(&vcpu->arch.emulate_ctxt, gva, &vpid,
+ 				sizeof(u32), &e)) {
+ 		kvm_inject_page_fault(vcpu, &e);
+ 		return 1;
+ 	}
+ 
+ 	switch (type) {
+ 	case VMX_VPID_EXTENT_ALL_CONTEXT:
+ 		if (get_vmcs12(vcpu)->virtual_processor_id == 0) {
+ 			nested_vmx_failValid(vcpu,
+ 				VMXERR_INVALID_OPERAND_TO_INVEPT_INVVPID);
+ 			return 1;
+ 		}
+ 		__vmx_flush_tlb(vcpu, to_vmx(vcpu)->nested.vpid02);
+ 		nested_vmx_succeed(vcpu);
+ 		break;
+ 	default:
+ 		/* Trap single context invalidation invvpid calls */
+ 		BUG_ON(1);
+ 		break;
+ 	}
+ 
+ 	skip_emulated_instruction(vcpu);
++>>>>>>> 5c614b3583e7 (KVM: nVMX: nested VPID emulation)
  	return 1;
  }
  
@@@ -8306,6 -8769,12 +8436,15 @@@ static struct kvm_vcpu *vmx_create_vcpu
  			goto free_vmcs;
  	}
  
++<<<<<<< HEAD
++=======
+ 	if (nested) {
+ 		nested_vmx_setup_ctls_msrs(vmx);
+ 		vmx->nested.vpid02 = allocate_vpid();
+ 	}
+ 
+ 	vmx->nested.posted_intr_nv = -1;
++>>>>>>> 5c614b3583e7 (KVM: nVMX: nested VPID emulation)
  	vmx->nested.current_vmptr = -1ull;
  	vmx->nested.current_vmcs12 = NULL;
  
* Unmerged path arch/x86/kvm/vmx.c
