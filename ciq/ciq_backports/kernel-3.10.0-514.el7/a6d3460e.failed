drm/i915/gen9: Drop re-allocation of DDB at atomic commit (v2)

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Matt Roper <matthew.d.roper@intel.com>
commit a6d3460e62d17098a815a53f23e44d814cb347e0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/a6d3460e.failed

Now that we're properly pre-allocating the DDB during the atomic check
phase and we trust that the allocation is appropriate, let's actually
use the allocation computed and not duplicate that work during the
commit phase.

v2:
 - Significant rebasing now that we can use cached data rates and
   minimum block allocations to avoid grabbing additional plane states.

	Signed-off-by: Matt Roper <matthew.d.roper@intel.com>
	Reviewed-by: Maarten Lankhorst <maarten.lankhorst@linux.intel.com>
Link: http://patchwork.freedesktop.org/patch/msgid/1463061971-19638-11-git-send-email-matthew.d.roper@intel.com
(cherry picked from commit a6d3460e62d17098a815a53f23e44d814cb347e0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/i915/intel_display.c
#	drivers/gpu/drm/i915/intel_pm.c
diff --cc drivers/gpu/drm/i915/intel_display.c
index e2e955a9df5d,325e75f881a2..000000000000
--- a/drivers/gpu/drm/i915/intel_display.c
+++ b/drivers/gpu/drm/i915/intel_display.c
@@@ -11632,818 -13282,516 +11632,1166 @@@ static int __intel_set_mode(struct drm_
  	 * mode set on this crtc.  For other crtcs we need to use the
  	 * adjusted_mode bits in the crtc directly.
  	 */
 -	if (dev_priv->display.modeset_calc_cdclk) {
 -		ret = dev_priv->display.modeset_calc_cdclk(state);
 -
 -		if (!ret && intel_state->dev_cdclk != dev_priv->cdclk_freq)
 -			ret = intel_modeset_all_pipes(state);
 +	if (IS_VALLEYVIEW(dev)) {
 +		valleyview_modeset_global_pipes(dev, &prepare_pipes);
  
 -		if (ret < 0)
 -			return ret;
 -
 -		DRM_DEBUG_KMS("New cdclk calculated to be atomic %u, actual %u\n",
 -			      intel_state->cdclk, intel_state->dev_cdclk);
 -	} else
 -		to_intel_atomic_state(state)->cdclk = dev_priv->atomic_cdclk_freq;
 +		/* may have added more to prepare_pipes than we should */
 +		prepare_pipes &= ~disable_pipes;
 +	}
  
 -	intel_modeset_clear_plls(state);
 +	ret = __intel_set_mode_setup_plls(dev, modeset_pipes, disable_pipes);
 +	if (ret)
 +		goto done;
  
 -	if (IS_HASWELL(dev_priv))
 -		return haswell_mode_set_planes_workaround(state);
 +	for_each_intel_crtc_masked(dev, disable_pipes, intel_crtc)
 +		intel_crtc_disable(&intel_crtc->base);
  
 -	return 0;
 -}
 -
 -/*
 - * Handle calculation of various watermark data at the end of the atomic check
 - * phase.  The code here should be run after the per-crtc and per-plane 'check'
 - * handlers to ensure that all derived state has been updated.
 - */
 -static void calc_watermark_data(struct drm_atomic_state *state)
 -{
 -	struct drm_device *dev = state->dev;
 -	struct drm_i915_private *dev_priv = to_i915(dev);
 -	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
 -	struct drm_crtc *crtc;
 -	struct drm_crtc_state *cstate;
 -	struct drm_plane *plane;
 -	struct drm_plane_state *pstate;
 +	for_each_intel_crtc_masked(dev, prepare_pipes, intel_crtc) {
 +		if (intel_crtc->base.state->enable)
 +			dev_priv->display.crtc_disable(&intel_crtc->base);
 +	}
  
 -	/*
 -	 * Calculate watermark configuration details now that derived
 -	 * plane/crtc state is all properly updated.
 +	/* crtc->mode is already used by the ->mode_set callbacks, hence we need
 +	 * to set it here already despite that we pass it down the callchain.
 +	 *
 +	 * Note we'll need to fix this up when we start tracking multiple
 +	 * pipes; here we assume a single modeset_pipe and only track the
 +	 * single crtc and mode.
  	 */
 -	drm_for_each_crtc(crtc, dev) {
 -		cstate = drm_atomic_get_existing_crtc_state(state, crtc) ?:
 -			crtc->state;
 +	if (modeset_pipes) {
 +		crtc->mode = *mode;
 +		/* mode_set/enable/disable functions rely on a correct pipe
 +		 * config. */
 +		intel_crtc_set_state(to_intel_crtc(crtc), pipe_config);
  
++<<<<<<< HEAD
 +		/*
 +		 * Calculate and store various constants which
 +		 * are later needed by vblank and swap-completion
 +		 * timestamping. They are derived from true hwmode.
 +		 */
 +		drm_calc_timestamping_constants(crtc,
 +						&pipe_config->base.adjusted_mode);
++=======
+ 		if (cstate->active)
+ 			intel_state->wm_config.num_pipes_active++;
+ 	}
+ 	drm_for_each_legacy_plane(plane, dev) {
+ 		pstate = drm_atomic_get_existing_plane_state(state, plane) ?:
+ 			plane->state;
+ 
+ 		if (!to_intel_plane_state(pstate)->visible)
+ 			continue;
+ 
+ 		intel_state->wm_config.sprites_enabled = true;
+ 		if (pstate->crtc_w != pstate->src_w >> 16 ||
+ 		    pstate->crtc_h != pstate->src_h >> 16)
+ 			intel_state->wm_config.sprites_scaled = true;
+ 	}
+ 
+ 	/* Is there platform-specific watermark information to calculate? */
+ 	if (dev_priv->display.compute_global_watermarks)
+ 		dev_priv->display.compute_global_watermarks(state);
+ }
+ 
+ /**
+  * intel_atomic_check - validate state object
+  * @dev: drm device
+  * @state: state to validate
+  */
+ static int intel_atomic_check(struct drm_device *dev,
+ 			      struct drm_atomic_state *state)
+ {
+ 	struct drm_i915_private *dev_priv = to_i915(dev);
+ 	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
+ 	struct drm_crtc *crtc;
+ 	struct drm_crtc_state *crtc_state;
+ 	int ret, i;
+ 	bool any_ms = false;
+ 
+ 	ret = drm_atomic_helper_check_modeset(dev, state);
+ 	if (ret)
+ 		return ret;
+ 
+ 	for_each_crtc_in_state(state, crtc, crtc_state, i) {
+ 		struct intel_crtc_state *pipe_config =
+ 			to_intel_crtc_state(crtc_state);
+ 
+ 		/* Catch I915_MODE_FLAG_INHERITED */
+ 		if (crtc_state->mode.private_flags != crtc->state->mode.private_flags)
+ 			crtc_state->mode_changed = true;
+ 
+ 		if (!crtc_state->enable) {
+ 			if (needs_modeset(crtc_state))
+ 				any_ms = true;
+ 			continue;
+ 		}
+ 
+ 		if (!needs_modeset(crtc_state))
+ 			continue;
+ 
+ 		/* FIXME: For only active_changed we shouldn't need to do any
+ 		 * state recomputation at all. */
+ 
+ 		ret = drm_atomic_add_affected_connectors(state, crtc);
+ 		if (ret)
+ 			return ret;
+ 
+ 		ret = intel_modeset_pipe_config(crtc, pipe_config);
+ 		if (ret) {
+ 			intel_dump_pipe_config(to_intel_crtc(crtc),
+ 					       pipe_config, "[failed]");
+ 			return ret;
+ 		}
+ 
+ 		if (i915.fastboot &&
+ 		    intel_pipe_config_compare(dev,
+ 					to_intel_crtc_state(crtc->state),
+ 					pipe_config, true)) {
+ 			crtc_state->mode_changed = false;
+ 			to_intel_crtc_state(crtc_state)->update_pipe = true;
+ 		}
+ 
+ 		if (needs_modeset(crtc_state)) {
+ 			any_ms = true;
+ 
+ 			ret = drm_atomic_add_affected_planes(state, crtc);
+ 			if (ret)
+ 				return ret;
+ 		}
+ 
+ 		intel_dump_pipe_config(to_intel_crtc(crtc), pipe_config,
+ 				       needs_modeset(crtc_state) ?
+ 				       "[modeset]" : "[fastset]");
+ 	}
+ 
+ 	if (any_ms) {
+ 		ret = intel_modeset_checks(state);
+ 
+ 		if (ret)
+ 			return ret;
+ 	} else
+ 		intel_state->cdclk = dev_priv->cdclk_freq;
+ 
+ 	ret = drm_atomic_helper_check_planes(dev, state);
+ 	if (ret)
+ 		return ret;
+ 
+ 	intel_fbc_choose_crtc(dev_priv, state);
+ 	calc_watermark_data(state);
+ 
+ 	return 0;
+ }
+ 
+ static int intel_atomic_prepare_commit(struct drm_device *dev,
+ 				       struct drm_atomic_state *state,
+ 				       bool async)
+ {
+ 	struct drm_i915_private *dev_priv = dev->dev_private;
+ 	struct drm_plane_state *plane_state;
+ 	struct drm_crtc_state *crtc_state;
+ 	struct drm_plane *plane;
+ 	struct drm_crtc *crtc;
+ 	int i, ret;
+ 
+ 	if (async) {
+ 		DRM_DEBUG_KMS("i915 does not yet support async commit\n");
+ 		return -EINVAL;
+ 	}
+ 
+ 	for_each_crtc_in_state(state, crtc, crtc_state, i) {
+ 		if (state->legacy_cursor_update)
+ 			continue;
+ 
+ 		ret = intel_crtc_wait_for_pending_flips(crtc);
+ 		if (ret)
+ 			return ret;
+ 
+ 		if (atomic_read(&to_intel_crtc(crtc)->unpin_work_count) >= 2)
+ 			flush_workqueue(dev_priv->wq);
+ 	}
+ 
+ 	ret = mutex_lock_interruptible(&dev->struct_mutex);
+ 	if (ret)
+ 		return ret;
+ 
+ 	ret = drm_atomic_helper_prepare_planes(dev, state);
+ 	mutex_unlock(&dev->struct_mutex);
+ 
+ 	if (!ret && !async) {
+ 		for_each_plane_in_state(state, plane, plane_state, i) {
+ 			struct intel_plane_state *intel_plane_state =
+ 				to_intel_plane_state(plane_state);
+ 
+ 			if (!intel_plane_state->wait_req)
+ 				continue;
+ 
+ 			ret = __i915_wait_request(intel_plane_state->wait_req,
+ 						  true, NULL, NULL);
+ 			if (ret) {
+ 				/* Any hang should be swallowed by the wait */
+ 				WARN_ON(ret == -EIO);
+ 				mutex_lock(&dev->struct_mutex);
+ 				drm_atomic_helper_cleanup_planes(dev, state);
+ 				mutex_unlock(&dev->struct_mutex);
+ 				break;
+ 			}
+ 		}
+ 	}
+ 
+ 	return ret;
+ }
+ 
+ static void intel_atomic_wait_for_vblanks(struct drm_device *dev,
+ 					  struct drm_i915_private *dev_priv,
+ 					  unsigned crtc_mask)
+ {
+ 	unsigned last_vblank_count[I915_MAX_PIPES];
+ 	enum pipe pipe;
+ 	int ret;
+ 
+ 	if (!crtc_mask)
+ 		return;
+ 
+ 	for_each_pipe(dev_priv, pipe) {
+ 		struct drm_crtc *crtc = dev_priv->pipe_to_crtc_mapping[pipe];
+ 
+ 		if (!((1 << pipe) & crtc_mask))
+ 			continue;
+ 
+ 		ret = drm_crtc_vblank_get(crtc);
+ 		if (WARN_ON(ret != 0)) {
+ 			crtc_mask &= ~(1 << pipe);
+ 			continue;
+ 		}
+ 
+ 		last_vblank_count[pipe] = drm_crtc_vblank_count(crtc);
+ 	}
+ 
+ 	for_each_pipe(dev_priv, pipe) {
+ 		struct drm_crtc *crtc = dev_priv->pipe_to_crtc_mapping[pipe];
+ 		long lret;
+ 
+ 		if (!((1 << pipe) & crtc_mask))
+ 			continue;
+ 
+ 		lret = wait_event_timeout(dev->vblank[pipe].queue,
+ 				last_vblank_count[pipe] !=
+ 					drm_crtc_vblank_count(crtc),
+ 				msecs_to_jiffies(50));
+ 
+ 		WARN(!lret, "pipe %c vblank wait timed out\n", pipe_name(pipe));
+ 
+ 		drm_crtc_vblank_put(crtc);
+ 	}
+ }
+ 
+ static bool needs_vblank_wait(struct intel_crtc_state *crtc_state)
+ {
+ 	/* fb updated, need to unpin old fb */
+ 	if (crtc_state->fb_changed)
+ 		return true;
+ 
+ 	/* wm changes, need vblank before final wm's */
+ 	if (crtc_state->update_wm_post)
+ 		return true;
+ 
+ 	/*
+ 	 * cxsr is re-enabled after vblank.
+ 	 * This is already handled by crtc_state->update_wm_post,
+ 	 * but added for clarity.
+ 	 */
+ 	if (crtc_state->disable_cxsr)
+ 		return true;
+ 
+ 	return false;
+ }
+ 
+ /**
+  * intel_atomic_commit - commit validated state object
+  * @dev: DRM device
+  * @state: the top-level driver state object
+  * @async: asynchronous commit
+  *
+  * This function commits a top-level state object that has been validated
+  * with drm_atomic_helper_check().
+  *
+  * FIXME:  Atomic modeset support for i915 is not yet complete.  At the moment
+  * we can only handle plane-related operations and do not yet support
+  * asynchronous commit.
+  *
+  * RETURNS
+  * Zero for success or -errno.
+  */
+ static int intel_atomic_commit(struct drm_device *dev,
+ 			       struct drm_atomic_state *state,
+ 			       bool async)
+ {
+ 	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
+ 	struct drm_i915_private *dev_priv = dev->dev_private;
+ 	struct drm_crtc_state *old_crtc_state;
+ 	struct drm_crtc *crtc;
+ 	struct intel_crtc_state *intel_cstate;
+ 	int ret = 0, i;
+ 	bool hw_check = intel_state->modeset;
+ 	unsigned long put_domains[I915_MAX_PIPES] = {};
+ 	unsigned crtc_vblank_mask = 0;
+ 
 -	ret = intel_atomic_prepare_commit(dev, state, async);
 -	if (ret) {
 -		DRM_DEBUG_ATOMIC("Preparing state failed with %i\n", ret);
 -		return ret;
++	ret = intel_atomic_prepare_commit(dev, state, async);
++	if (ret) {
++		DRM_DEBUG_ATOMIC("Preparing state failed with %i\n", ret);
++		return ret;
++	}
++
++	drm_atomic_helper_swap_state(dev, state);
++	dev_priv->wm.config = intel_state->wm_config;
++	dev_priv->wm.distrust_bios_wm = false;
++	dev_priv->wm.skl_results.ddb = intel_state->ddb;
++	intel_shared_dpll_commit(state);
++
++	if (intel_state->modeset) {
++		memcpy(dev_priv->min_pixclk, intel_state->min_pixclk,
++		       sizeof(intel_state->min_pixclk));
++		dev_priv->active_crtcs = intel_state->active_crtcs;
++		dev_priv->atomic_cdclk_freq = intel_state->cdclk;
++
++		intel_display_power_get(dev_priv, POWER_DOMAIN_MODESET);
++	}
++
++	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
++		struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
++
++		if (needs_modeset(crtc->state) ||
++		    to_intel_crtc_state(crtc->state)->update_pipe) {
++			hw_check = true;
++
++			put_domains[to_intel_crtc(crtc)->pipe] =
++				modeset_get_crtc_power_domains(crtc,
++					to_intel_crtc_state(crtc->state));
++		}
++
++		if (!needs_modeset(crtc->state))
++			continue;
++
++		intel_pre_plane_update(to_intel_crtc_state(old_crtc_state));
++
++		if (old_crtc_state->active) {
++			intel_crtc_disable_planes(crtc, old_crtc_state->plane_mask);
++			dev_priv->display.crtc_disable(crtc);
++			intel_crtc->active = false;
++			intel_fbc_disable(intel_crtc);
++			intel_disable_shared_dpll(intel_crtc);
++
++			/*
++			 * Underruns don't always raise
++			 * interrupts, so check manually.
++			 */
++			intel_check_cpu_fifo_underruns(dev_priv);
++			intel_check_pch_fifo_underruns(dev_priv);
++
++			if (!crtc->state->active)
++				intel_update_watermarks(crtc);
++		}
++>>>>>>> a6d3460e62d1 (drm/i915/gen9: Drop re-allocation of DDB at atomic commit (v2))
 +	}
 +
 +	/* Only after disabling all output pipelines that will be changed can we
 +	 * update the the output configuration. */
 +	intel_modeset_update_state(dev, prepare_pipes);
 +
 +	modeset_update_crtc_power_domains(pipe_config->base.state);
 +
 +	/* Set up the DPLL and any encoders state that needs to adjust or depend
 +	 * on the DPLL.
 +	 */
 +	for_each_intel_crtc_masked(dev, modeset_pipes, intel_crtc) {
 +		struct drm_plane *primary = intel_crtc->base.primary;
 +		int vdisplay, hdisplay;
 +
 +		drm_crtc_get_hv_timing(mode, &hdisplay, &vdisplay);
 +		ret = primary->funcs->update_plane(primary, &intel_crtc->base,
 +						   fb, 0, 0,
 +						   hdisplay, vdisplay,
 +						   x << 16, y << 16,
 +						   hdisplay << 16, vdisplay << 16);
 +	}
 +
 +	/* Now enable the clocks, plane, pipe, and connectors that we set up. */
 +	for_each_intel_crtc_masked(dev, prepare_pipes, intel_crtc) {
 +		update_scanline_offset(intel_crtc);
 +
 +		dev_priv->display.crtc_enable(&intel_crtc->base);
 +	}
 +
 +	/* FIXME: add subpixel order */
 +done:
 +	if (ret && crtc->state->enable)
 +		crtc->mode = *saved_mode;
 +
 +	if (ret == 0 && pipe_config) {
 +		struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 +
 +		/* The pipe_config will be freed with the atomic state, so
 +		 * make a copy. */
 +		memcpy(crtc_state_copy, intel_crtc->config,
 +		       sizeof *crtc_state_copy);
 +		intel_crtc->config = crtc_state_copy;
 +		intel_crtc->base.state = &crtc_state_copy->base;
 +
 +		if (modeset_pipes)
 +			intel_crtc->new_config = intel_crtc->config;
 +	} else {
 +		kfree(crtc_state_copy);
 +	}
 +
 +	kfree(saved_mode);
 +	return ret;
 +}
 +
 +static int intel_set_mode_pipes(struct drm_crtc *crtc,
 +				struct drm_display_mode *mode,
 +				int x, int y, struct drm_framebuffer *fb,
 +				struct intel_crtc_state *pipe_config,
 +				unsigned modeset_pipes,
 +				unsigned prepare_pipes,
 +				unsigned disable_pipes)
 +{
 +	int ret;
 +
 +	ret = __intel_set_mode(crtc, mode, x, y, fb, pipe_config, modeset_pipes,
 +			       prepare_pipes, disable_pipes);
 +
 +	if (ret == 0)
 +		intel_modeset_check_state(crtc->dev);
 +
 +	return ret;
 +}
 +
 +static int intel_set_mode(struct drm_crtc *crtc,
 +			  struct drm_display_mode *mode,
 +			  int x, int y, struct drm_framebuffer *fb,
 +			  struct drm_atomic_state *state)
 +{
 +	struct intel_crtc_state *pipe_config;
 +	unsigned modeset_pipes, prepare_pipes, disable_pipes;
 +	int ret = 0;
 +
 +	pipe_config = intel_modeset_compute_config(crtc, mode, fb, state,
 +						   &modeset_pipes,
 +						   &prepare_pipes,
 +						   &disable_pipes);
 +
 +	if (IS_ERR(pipe_config)) {
 +		ret = PTR_ERR(pipe_config);
 +		goto out;
 +	}
 +
++<<<<<<< HEAD
 +	ret = intel_set_mode_pipes(crtc, mode, x, y, fb, pipe_config,
 +				   modeset_pipes, prepare_pipes,
 +				   disable_pipes);
 +	if (ret)
 +		goto out;
 +
 +out:
 +	return ret;
++=======
++	if (intel_state->modeset)
++		intel_display_power_put(dev_priv, POWER_DOMAIN_MODESET);
++
++	mutex_lock(&dev->struct_mutex);
++	drm_atomic_helper_cleanup_planes(dev, state);
++	mutex_unlock(&dev->struct_mutex);
++
++	drm_atomic_state_free(state);
++
++	/* As one of the primary mmio accessors, KMS has a high likelihood
++	 * of triggering bugs in unclaimed access. After we finish
++	 * modesetting, see if an error has been flagged, and if so
++	 * enable debugging for the next modeset - and hope we catch
++	 * the culprit.
++	 *
++	 * XXX note that we assume display power is on at this point.
++	 * This might hold true now but we need to add pm helper to check
++	 * unclaimed only when the hardware is on, as atomic commits
++	 * can happen also when the device is completely off.
++	 */
++	intel_uncore_arm_unclaimed_mmio_detection(dev_priv);
++
++	return 0;
++>>>>>>> a6d3460e62d1 (drm/i915/gen9: Drop re-allocation of DDB at atomic commit (v2))
 +}
 +
 +void intel_crtc_restore_mode(struct drm_crtc *crtc)
 +{
 +	struct drm_device *dev = crtc->dev;
 +	struct drm_atomic_state *state;
 +	struct intel_encoder *encoder;
 +	struct intel_connector *connector;
 +	struct drm_connector_state *connector_state;
 +
 +	state = drm_atomic_state_alloc(dev);
 +	if (!state) {
 +		DRM_DEBUG_KMS("[CRTC:%d] mode restore failed, out of memory",
 +			      crtc->base.id);
 +		return;
 +	}
 +
 +	state->acquire_ctx = dev->mode_config.acquire_ctx;
 +
 +	/* The force restore path in the HW readout code relies on the staged
 +	 * config still keeping the user requested config while the actual
 +	 * state has been overwritten by the configuration read from HW. We
 +	 * need to copy the staged config to the atomic state, otherwise the
 +	 * mode set will just reapply the state the HW is already in. */
 +	for_each_intel_encoder(dev, encoder) {
 +		if (&encoder->new_crtc->base != crtc)
 +			continue;
 +
 +		for_each_intel_connector(dev, connector) {
 +			if (connector->new_encoder != encoder)
 +				continue;
 +
 +			connector_state = drm_atomic_get_connector_state(state, &connector->base);
 +			if (IS_ERR(connector_state)) {
 +				DRM_DEBUG_KMS("Failed to add [CONNECTOR:%d:%s] to state: %ld\n",
 +					      connector->base.base.id,
 +					      connector->base.name,
 +					      PTR_ERR(connector_state));
 +				continue;
 +			}
 +
 +			connector_state->crtc = crtc;
 +			connector_state->best_encoder = &encoder->base;
 +		}
 +	}
 +
 +	intel_set_mode(crtc, &crtc->mode, crtc->x, crtc->y, crtc->primary->fb,
 +		       state);
 +
 +	drm_atomic_state_free(state);
 +}
 +
 +#undef for_each_intel_crtc_masked
 +
 +static void intel_set_config_free(struct intel_set_config *config)
 +{
 +	if (!config)
 +		return;
 +
 +	kfree(config->save_connector_encoders);
 +	kfree(config->save_encoder_crtcs);
 +	kfree(config->save_crtc_enabled);
 +	kfree(config);
 +}
 +
 +static int intel_set_config_save_state(struct drm_device *dev,
 +				       struct intel_set_config *config)
 +{
 +	struct drm_crtc *crtc;
 +	struct drm_encoder *encoder;
 +	struct drm_connector *connector;
 +	int count;
 +
 +	config->save_crtc_enabled =
 +		kcalloc(dev->mode_config.num_crtc,
 +			sizeof(bool), GFP_KERNEL);
 +	if (!config->save_crtc_enabled)
 +		return -ENOMEM;
 +
 +	config->save_encoder_crtcs =
 +		kcalloc(dev->mode_config.num_encoder,
 +			sizeof(struct drm_crtc *), GFP_KERNEL);
 +	if (!config->save_encoder_crtcs)
 +		return -ENOMEM;
 +
 +	config->save_connector_encoders =
 +		kcalloc(dev->mode_config.num_connector,
 +			sizeof(struct drm_encoder *), GFP_KERNEL);
 +	if (!config->save_connector_encoders)
 +		return -ENOMEM;
 +
 +	/* Copy data. Note that driver private data is not affected.
 +	 * Should anything bad happen only the expected state is
 +	 * restored, not the drivers personal bookkeeping.
 +	 */
 +	count = 0;
 +	for_each_crtc(dev, crtc) {
 +		config->save_crtc_enabled[count++] = crtc->state->enable;
 +	}
 +
 +	count = 0;
 +	list_for_each_entry(encoder, &dev->mode_config.encoder_list, head) {
 +		config->save_encoder_crtcs[count++] = encoder->crtc;
 +	}
 +
 +	count = 0;
 +	list_for_each_entry(connector, &dev->mode_config.connector_list, head) {
 +		config->save_connector_encoders[count++] = connector->encoder;
 +	}
 +
 +	return 0;
 +}
 +
 +static void intel_set_config_restore_state(struct drm_device *dev,
 +					   struct intel_set_config *config)
 +{
 +	struct intel_crtc *crtc;
 +	struct intel_encoder *encoder;
 +	struct intel_connector *connector;
 +	int count;
 +
 +	count = 0;
 +	for_each_intel_crtc(dev, crtc) {
 +		crtc->new_enabled = config->save_crtc_enabled[count++];
 +
 +		if (crtc->new_enabled)
 +			crtc->new_config = crtc->config;
 +		else
 +			crtc->new_config = NULL;
 +	}
 +
 +	count = 0;
 +	for_each_intel_encoder(dev, encoder) {
 +		encoder->new_crtc =
 +			to_intel_crtc(config->save_encoder_crtcs[count++]);
 +	}
 +
 +	count = 0;
 +	for_each_intel_connector(dev, connector) {
 +		connector->new_encoder =
 +			to_intel_encoder(config->save_connector_encoders[count++]);
 +	}
 +}
 +
 +static bool
 +is_crtc_connector_off(struct drm_mode_set *set)
 +{
 +	int i;
 +
 +	if (set->num_connectors == 0)
 +		return false;
 +
 +	if (WARN_ON(set->connectors == NULL))
 +		return false;
 +
 +	for (i = 0; i < set->num_connectors; i++)
 +		if (set->connectors[i]->encoder &&
 +		    set->connectors[i]->encoder->crtc == set->crtc &&
 +		    set->connectors[i]->dpms != DRM_MODE_DPMS_ON)
 +			return true;
 +
 +	return false;
 +}
 +
 +static void
 +intel_set_config_compute_mode_changes(struct drm_mode_set *set,
 +				      struct intel_set_config *config)
 +{
 +
 +	/* We should be able to check here if the fb has the same properties
 +	 * and then just flip_or_move it */
 +	if (is_crtc_connector_off(set)) {
 +		config->mode_changed = true;
 +	} else if (set->crtc->primary->fb != set->fb) {
 +		/*
 +		 * If we have no fb, we can only flip as long as the crtc is
 +		 * active, otherwise we need a full mode set.  The crtc may
 +		 * be active if we've only disabled the primary plane, or
 +		 * in fastboot situations.
 +		 */
 +		if (set->crtc->primary->fb == NULL) {
 +			struct intel_crtc *intel_crtc =
 +				to_intel_crtc(set->crtc);
 +
 +			if (intel_crtc->active) {
 +				DRM_DEBUG_KMS("crtc has no fb, will flip\n");
 +				config->fb_changed = true;
 +			} else {
 +				DRM_DEBUG_KMS("inactive crtc, full mode set\n");
 +				config->mode_changed = true;
 +			}
 +		} else if (set->fb == NULL) {
 +			config->mode_changed = true;
 +		} else if (set->fb->pixel_format !=
 +			   set->crtc->primary->fb->pixel_format) {
 +			config->mode_changed = true;
 +		} else {
 +			config->fb_changed = true;
 +		}
 +	}
 +
 +	if (set->fb && (set->x != set->crtc->x || set->y != set->crtc->y))
 +		config->fb_changed = true;
 +
 +	if (set->mode && !drm_mode_equal(set->mode, &set->crtc->mode)) {
 +		DRM_DEBUG_KMS("modes are different, full mode set\n");
 +		drm_mode_debug_printmodeline(&set->crtc->mode);
 +		drm_mode_debug_printmodeline(set->mode);
 +		config->mode_changed = true;
 +	}
 +
 +	DRM_DEBUG_KMS("computed changes for [CRTC:%d], mode_changed=%d, fb_changed=%d\n",
 +			set->crtc->base.id, config->mode_changed, config->fb_changed);
 +}
 +
 +static int
 +intel_modeset_stage_output_state(struct drm_device *dev,
 +				 struct drm_mode_set *set,
 +				 struct intel_set_config *config,
 +				 struct drm_atomic_state *state)
 +{
 +	struct intel_connector *connector;
 +	struct drm_connector_state *connector_state;
 +	struct intel_encoder *encoder;
 +	struct intel_crtc *crtc;
 +	int ro;
 +
 +	/* The upper layers ensure that we either disable a crtc or have a list
 +	 * of connectors. For paranoia, double-check this. */
 +	WARN_ON(!set->fb && (set->num_connectors != 0));
 +	WARN_ON(set->fb && (set->num_connectors == 0));
 +
 +	for_each_intel_connector(dev, connector) {
 +		/* Otherwise traverse passed in connector list and get encoders
 +		 * for them. */
 +		for (ro = 0; ro < set->num_connectors; ro++) {
 +			if (set->connectors[ro] == &connector->base) {
 +				connector->new_encoder = intel_find_encoder(connector, to_intel_crtc(set->crtc)->pipe);
 +				break;
 +			}
 +		}
 +
 +		/* If we disable the crtc, disable all its connectors. Also, if
 +		 * the connector is on the changing crtc but not on the new
 +		 * connector list, disable it. */
 +		if ((!set->fb || ro == set->num_connectors) &&
 +		    connector->base.encoder &&
 +		    connector->base.encoder->crtc == set->crtc) {
 +			connector->new_encoder = NULL;
 +
 +			DRM_DEBUG_KMS("[CONNECTOR:%d:%s] to [NOCRTC]\n",
 +				connector->base.base.id,
 +				connector->base.name);
 +		}
 +
 +
 +		if (&connector->new_encoder->base != connector->base.encoder) {
 +			DRM_DEBUG_KMS("[CONNECTOR:%d:%s] encoder changed, full mode switch\n",
 +				      connector->base.base.id,
 +				      connector->base.name);
 +			config->mode_changed = true;
 +		}
 +	}
 +	/* connector->new_encoder is now updated for all connectors. */
 +
 +	/* Update crtc of enabled connectors. */
 +	for_each_intel_connector(dev, connector) {
 +		struct drm_crtc *new_crtc;
 +
 +		if (!connector->new_encoder)
 +			continue;
 +
 +		new_crtc = connector->new_encoder->base.crtc;
 +
 +		for (ro = 0; ro < set->num_connectors; ro++) {
 +			if (set->connectors[ro] == &connector->base)
 +				new_crtc = set->crtc;
 +		}
 +
 +		/* Make sure the new CRTC will work with the encoder */
 +		if (!drm_encoder_crtc_ok(&connector->new_encoder->base,
 +					 new_crtc)) {
 +			return -EINVAL;
 +		}
 +		connector->new_encoder->new_crtc = to_intel_crtc(new_crtc);
 +
 +		connector_state =
 +			drm_atomic_get_connector_state(state, &connector->base);
 +		if (IS_ERR(connector_state))
 +			return PTR_ERR(connector_state);
 +
 +		connector_state->crtc = new_crtc;
 +		connector_state->best_encoder = &connector->new_encoder->base;
 +
 +		DRM_DEBUG_KMS("[CONNECTOR:%d:%s] to [CRTC:%d]\n",
 +			connector->base.base.id,
 +			connector->base.name,
 +			new_crtc->base.id);
 +	}
 +
 +	/* Check for any encoders that needs to be disabled. */
 +	for_each_intel_encoder(dev, encoder) {
 +		int num_connectors = 0;
 +		for_each_intel_connector(dev, connector) {
 +			if (connector->new_encoder == encoder) {
 +				WARN_ON(!connector->new_encoder->new_crtc);
 +				num_connectors++;
 +			}
 +		}
 +
 +		if (num_connectors == 0)
 +			encoder->new_crtc = NULL;
 +		else if (num_connectors > 1)
 +			return -EINVAL;
 +
 +		/* Only now check for crtc changes so we don't miss encoders
 +		 * that will be disabled. */
 +		if (&encoder->new_crtc->base != encoder->base.crtc) {
 +			DRM_DEBUG_KMS("[ENCODER:%d:%s] crtc changed, full mode switch\n",
 +				      encoder->base.base.id,
 +				      encoder->base.name);
 +			config->mode_changed = true;
 +		}
 +	}
 +	/* Now we've also updated encoder->new_crtc for all encoders. */
 +	for_each_intel_connector(dev, connector) {
 +		connector_state =
 +			drm_atomic_get_connector_state(state, &connector->base);
 +		if (IS_ERR(connector_state))
 +			return PTR_ERR(connector_state);
 +
 +		if (connector->new_encoder) {
 +			if (connector->new_encoder != connector->encoder)
 +				connector->encoder = connector->new_encoder;
 +		} else {
 +			connector_state->crtc = NULL;
 +		}
 +	}
 +	for_each_intel_crtc(dev, crtc) {
 +		crtc->new_enabled = false;
 +
 +		for_each_intel_encoder(dev, encoder) {
 +			if (encoder->new_crtc == crtc) {
 +				crtc->new_enabled = true;
 +				break;
 +			}
 +		}
 +
 +		if (crtc->new_enabled != crtc->base.state->enable) {
 +			DRM_DEBUG_KMS("[CRTC:%d] %sabled, full mode switch\n",
 +				      crtc->base.base.id,
 +				      crtc->new_enabled ? "en" : "dis");
 +			config->mode_changed = true;
 +		}
 +
 +		if (crtc->new_enabled)
 +			crtc->new_config = crtc->config;
 +		else
 +			crtc->new_config = NULL;
  	}
  
 -	drm_atomic_helper_swap_state(dev, state);
 -	dev_priv->wm.config = intel_state->wm_config;
 -	dev_priv->wm.distrust_bios_wm = false;
 -	dev_priv->wm.skl_results.ddb = intel_state->ddb;
 -	intel_shared_dpll_commit(state);
 +	return 0;
 +}
  
 -	if (intel_state->modeset) {
 -		memcpy(dev_priv->min_pixclk, intel_state->min_pixclk,
 -		       sizeof(intel_state->min_pixclk));
 -		dev_priv->active_crtcs = intel_state->active_crtcs;
 -		dev_priv->atomic_cdclk_freq = intel_state->cdclk;
 +static void disable_crtc_nofb(struct intel_crtc *crtc)
 +{
 +	struct drm_device *dev = crtc->base.dev;
 +	struct intel_encoder *encoder;
 +	struct intel_connector *connector;
  
 -		intel_display_power_get(dev_priv, POWER_DOMAIN_MODESET);
 +	DRM_DEBUG_KMS("Trying to restore without FB -> disabling pipe %c\n",
 +		      pipe_name(crtc->pipe));
 +
 +	for_each_intel_connector(dev, connector) {
 +		if (connector->new_encoder &&
 +		    connector->new_encoder->new_crtc == crtc)
 +			connector->new_encoder = NULL;
  	}
  
 -	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
 -		struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 +	for_each_intel_encoder(dev, encoder) {
 +		if (encoder->new_crtc == crtc)
 +			encoder->new_crtc = NULL;
 +	}
  
 -		if (needs_modeset(crtc->state) ||
 -		    to_intel_crtc_state(crtc->state)->update_pipe) {
 -			hw_check = true;
 +	crtc->new_enabled = false;
 +	crtc->new_config = NULL;
 +}
  
 -			put_domains[to_intel_crtc(crtc)->pipe] =
 -				modeset_get_crtc_power_domains(crtc,
 -					to_intel_crtc_state(crtc->state));
 -		}
 +static int intel_crtc_set_config(struct drm_mode_set *set)
 +{
 +	struct drm_device *dev;
 +	struct drm_mode_set save_set;
 +	struct drm_atomic_state *state = NULL;
 +	struct intel_set_config *config;
 +	struct intel_crtc_state *pipe_config;
 +	unsigned modeset_pipes, prepare_pipes, disable_pipes;
 +	int ret;
  
 -		if (!needs_modeset(crtc->state))
 -			continue;
 +	BUG_ON(!set);
 +	BUG_ON(!set->crtc);
 +	BUG_ON(!set->crtc->helper_private);
  
 -		intel_pre_plane_update(to_intel_crtc_state(old_crtc_state));
 +	/* Enforce sane interface api - has been abused by the fb helper. */
 +	BUG_ON(!set->mode && set->fb);
 +	BUG_ON(set->fb && set->num_connectors == 0);
  
 -		if (old_crtc_state->active) {
 -			intel_crtc_disable_planes(crtc, old_crtc_state->plane_mask);
 -			dev_priv->display.crtc_disable(crtc);
 -			intel_crtc->active = false;
 -			intel_fbc_disable(intel_crtc);
 -			intel_disable_shared_dpll(intel_crtc);
 +	if (set->fb) {
 +		DRM_DEBUG_KMS("[CRTC:%d] [FB:%d] #connectors=%d (x y) (%i %i)\n",
 +				set->crtc->base.id, set->fb->base.id,
 +				(int)set->num_connectors, set->x, set->y);
 +	} else {
 +		DRM_DEBUG_KMS("[CRTC:%d] [NOFB]\n", set->crtc->base.id);
 +	}
  
 -			/*
 -			 * Underruns don't always raise
 -			 * interrupts, so check manually.
 -			 */
 -			intel_check_cpu_fifo_underruns(dev_priv);
 -			intel_check_pch_fifo_underruns(dev_priv);
 +	dev = set->crtc->dev;
  
 -			if (!crtc->state->active)
 -				intel_update_watermarks(crtc);
 -		}
 +	ret = -ENOMEM;
 +	config = kzalloc(sizeof(*config), GFP_KERNEL);
 +	if (!config)
 +		goto out_config;
 +
 +	ret = intel_set_config_save_state(dev, config);
 +	if (ret)
 +		goto out_config;
 +
 +	save_set.crtc = set->crtc;
 +	save_set.mode = &set->crtc->mode;
 +	save_set.x = set->crtc->x;
 +	save_set.y = set->crtc->y;
 +	save_set.fb = set->crtc->primary->fb;
 +
 +	/* Compute whether we need a full modeset, only an fb base update or no
 +	 * change at all. In the future we might also check whether only the
 +	 * mode changed, e.g. for LVDS where we only change the panel fitter in
 +	 * such cases. */
 +	intel_set_config_compute_mode_changes(set, config);
 +
 +	state = drm_atomic_state_alloc(dev);
 +	if (!state) {
 +		ret = -ENOMEM;
 +		goto out_config;
  	}
  
 -	/* Only after disabling all output pipelines that will be changed can we
 -	 * update the the output configuration. */
 -	intel_modeset_update_crtc_state(state);
 +	state->acquire_ctx = dev->mode_config.acquire_ctx;
  
 -	if (intel_state->modeset) {
 -		drm_atomic_helper_update_legacy_modeset_state(state->dev, state);
 +	ret = intel_modeset_stage_output_state(dev, set, config, state);
 +	if (ret)
 +		goto fail;
  
 -		if (dev_priv->display.modeset_commit_cdclk &&
 -		    intel_state->dev_cdclk != dev_priv->cdclk_freq)
 -			dev_priv->display.modeset_commit_cdclk(state);
 +	pipe_config = intel_modeset_compute_config(set->crtc, set->mode,
 +						   set->fb, state,
 +						   &modeset_pipes,
 +						   &prepare_pipes,
 +						   &disable_pipes);
 +	if (IS_ERR(pipe_config)) {
 +		ret = PTR_ERR(pipe_config);
 +		goto fail;
 +	} else if (pipe_config) {
 +		if (pipe_config->has_audio !=
 +		    to_intel_crtc(set->crtc)->config->has_audio)
 +			config->mode_changed = true;
  
 -		intel_modeset_verify_disabled(dev);
 +		/*
 +		 * Note we have an issue here with infoframes: current code
 +		 * only updates them on the full mode set path per hw
 +		 * requirements.  So here we should be checking for any
 +		 * required changes and forcing a mode set.
 +		 */
  	}
  
 -	/* Now enable the clocks, plane, pipe, and connectors that we set up. */
 -	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
 -		struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 -		bool modeset = needs_modeset(crtc->state);
 -		struct intel_crtc_state *pipe_config =
 -			to_intel_crtc_state(crtc->state);
 -		bool update_pipe = !modeset && pipe_config->update_pipe;
 +	intel_update_pipe_size(to_intel_crtc(set->crtc));
  
 -		if (modeset && crtc->state->active) {
 -			update_scanline_offset(to_intel_crtc(crtc));
 -			dev_priv->display.crtc_enable(crtc);
 +	if (config->mode_changed) {
 +		ret = intel_set_mode_pipes(set->crtc, set->mode,
 +					   set->x, set->y, set->fb, pipe_config,
 +					   modeset_pipes, prepare_pipes,
 +					   disable_pipes);
 +	} else if (config->fb_changed) {
 +		struct intel_crtc *intel_crtc = to_intel_crtc(set->crtc);
 +		struct drm_plane *primary = set->crtc->primary;
 +		int vdisplay, hdisplay;
 +
 +		drm_crtc_get_hv_timing(set->mode, &hdisplay, &vdisplay);
 +		ret = primary->funcs->update_plane(primary, set->crtc, set->fb,
 +						   0, 0, hdisplay, vdisplay,
 +						   set->x << 16, set->y << 16,
 +						   hdisplay << 16, vdisplay << 16);
 +
 +		/*
 +		 * We need to make sure the primary plane is re-enabled if it
 +		 * has previously been turned off.
 +		 */
 +		if (!intel_crtc->primary_enabled && ret == 0) {
 +			WARN_ON(!intel_crtc->active);
 +			intel_enable_primary_hw_plane(set->crtc->primary, set->crtc);
  		}
  
 -		if (!modeset)
 -			intel_pre_plane_update(to_intel_crtc_state(old_crtc_state));
 +		/*
 +		 * In the fastboot case this may be our only check of the
 +		 * state after boot.  It would be better to only do it on
 +		 * the first update, but we don't have a nice way of doing that
 +		 * (and really, set_config isn't used much for high freq page
 +		 * flipping, so increasing its cost here shouldn't be a big
 +		 * deal).
 +		 */
 +		if (i915.fastboot && ret == 0)
 +			intel_modeset_check_state(set->crtc->dev);
 +	}
 +
 +	if (ret) {
 +		DRM_DEBUG_KMS("failed to set mode on [CRTC:%d], err = %d\n",
 +			      set->crtc->base.id, ret);
 +fail:
 +		intel_set_config_restore_state(dev, config);
  
 -		if (crtc->state->active &&
 -		    drm_atomic_get_existing_plane_state(state, crtc->primary))
 -			intel_fbc_enable(intel_crtc);
 +		drm_atomic_state_clear(state);
  
 -		if (crtc->state->active &&
 -		    (crtc->state->planes_changed || update_pipe))
 -			drm_atomic_helper_commit_planes_on_crtc(old_crtc_state);
 +		/*
 +		 * HACK: if the pipe was on, but we didn't have a framebuffer,
 +		 * force the pipe off to avoid oopsing in the modeset code
 +		 * due to fb==NULL. This should only happen during boot since
 +		 * we don't yet reconstruct the FB from the hardware state.
 +		 */
 +		if (to_intel_crtc(save_set.crtc)->new_enabled && !save_set.fb)
 +			disable_crtc_nofb(to_intel_crtc(save_set.crtc));
  
 -		if (pipe_config->base.active && needs_vblank_wait(pipe_config))
 -			crtc_vblank_mask |= 1 << i;
 +		/* Try to restore the config */
 +		if (config->mode_changed &&
 +		    intel_set_mode(save_set.crtc, save_set.mode,
 +				   save_set.x, save_set.y, save_set.fb,
 +				   state))
 +			DRM_ERROR("failed to restore config after modeset failure\n");
  	}
  
 -	/* FIXME: add subpixel order */
 +out_config:
 +	if (state)
 +		drm_atomic_state_free(state);
  
 -	if (!state->legacy_cursor_update)
 -		intel_atomic_wait_for_vblanks(dev, dev_priv, crtc_vblank_mask);
 +	intel_set_config_free(config);
 +	return ret;
 +}
  
 -	/*
 -	 * Now that the vblank has passed, we can go ahead and program the
 -	 * optimal watermarks on platforms that need two-step watermark
 -	 * programming.
 -	 *
 -	 * TODO: Move this (and other cleanup) to an async worker eventually.
 -	 */
 -	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
 -		intel_cstate = to_intel_crtc_state(crtc->state);
 +static const struct drm_crtc_funcs intel_crtc_funcs = {
 +	.gamma_set = intel_crtc_gamma_set,
 +	.set_config = intel_crtc_set_config,
 +	.destroy = intel_crtc_destroy,
 +	.page_flip = intel_crtc_page_flip,
 +	.atomic_duplicate_state = intel_crtc_duplicate_state,
 +	.atomic_destroy_state = intel_crtc_destroy_state,
 +};
  
 -		if (dev_priv->display.optimize_watermarks)
 -			dev_priv->display.optimize_watermarks(intel_cstate);
 -	}
 +static bool ibx_pch_dpll_get_hw_state(struct drm_i915_private *dev_priv,
 +				      struct intel_shared_dpll *pll,
 +				      struct intel_dpll_hw_state *hw_state)
 +{
 +	uint32_t val;
  
 -	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
 -		intel_post_plane_update(to_intel_crtc_state(old_crtc_state));
 +	if (!intel_display_power_is_enabled(dev_priv, POWER_DOMAIN_PLLS))
 +		return false;
  
 -		if (put_domains[i])
 -			modeset_put_power_domains(dev_priv, put_domains[i]);
 +	val = I915_READ(PCH_DPLL(pll->id));
 +	hw_state->dpll = val;
 +	hw_state->fp0 = I915_READ(PCH_FP0(pll->id));
 +	hw_state->fp1 = I915_READ(PCH_FP1(pll->id));
  
 -		intel_modeset_verify_crtc(crtc, old_crtc_state, crtc->state);
 -	}
 +	return val & DPLL_VCO_ENABLE;
 +}
  
 -	if (intel_state->modeset)
 -		intel_display_power_put(dev_priv, POWER_DOMAIN_MODESET);
 +static void ibx_pch_dpll_mode_set(struct drm_i915_private *dev_priv,
 +				  struct intel_shared_dpll *pll)
 +{
 +	I915_WRITE(PCH_FP0(pll->id), pll->config.hw_state.fp0);
 +	I915_WRITE(PCH_FP1(pll->id), pll->config.hw_state.fp1);
 +}
  
 -	mutex_lock(&dev->struct_mutex);
 -	drm_atomic_helper_cleanup_planes(dev, state);
 -	mutex_unlock(&dev->struct_mutex);
 +static void ibx_pch_dpll_enable(struct drm_i915_private *dev_priv,
 +				struct intel_shared_dpll *pll)
 +{
 +	/* PCH refclock must be enabled first */
 +	ibx_assert_pch_refclk_enabled(dev_priv);
  
 -	drm_atomic_state_free(state);
 +	I915_WRITE(PCH_DPLL(pll->id), pll->config.hw_state.dpll);
  
 -	/* As one of the primary mmio accessors, KMS has a high likelihood
 -	 * of triggering bugs in unclaimed access. After we finish
 -	 * modesetting, see if an error has been flagged, and if so
 -	 * enable debugging for the next modeset - and hope we catch
 -	 * the culprit.
 +	/* Wait for the clocks to stabilize. */
 +	POSTING_READ(PCH_DPLL(pll->id));
 +	udelay(150);
 +
 +	/* The pixel multiplier can only be updated once the
 +	 * DPLL is enabled and the clocks are stable.
  	 *
 -	 * XXX note that we assume display power is on at this point.
 -	 * This might hold true now but we need to add pm helper to check
 -	 * unclaimed only when the hardware is on, as atomic commits
 -	 * can happen also when the device is completely off.
 +	 * So write it again.
  	 */
 -	intel_uncore_arm_unclaimed_mmio_detection(dev_priv);
 -
 -	return 0;
 +	I915_WRITE(PCH_DPLL(pll->id), pll->config.hw_state.dpll);
 +	POSTING_READ(PCH_DPLL(pll->id));
 +	udelay(200);
  }
  
 -void intel_crtc_restore_mode(struct drm_crtc *crtc)
 +static void ibx_pch_dpll_disable(struct drm_i915_private *dev_priv,
 +				 struct intel_shared_dpll *pll)
  {
 -	struct drm_device *dev = crtc->dev;
 -	struct drm_atomic_state *state;
 -	struct drm_crtc_state *crtc_state;
 -	int ret;
 +	struct drm_device *dev = dev_priv->dev;
 +	struct intel_crtc *crtc;
  
 -	state = drm_atomic_state_alloc(dev);
 -	if (!state) {
 -		DRM_DEBUG_KMS("[CRTC:%d] crtc restore failed, out of memory",
 -			      crtc->base.id);
 -		return;
 +	/* Make sure no transcoder isn't still depending on us. */
 +	for_each_intel_crtc(dev, crtc) {
 +		if (intel_crtc_to_shared_dpll(crtc) == pll)
 +			assert_pch_transcoder_disabled(dev_priv, crtc->pipe);
  	}
  
 -	state->acquire_ctx = drm_modeset_legacy_acquire_ctx(crtc);
 +	I915_WRITE(PCH_DPLL(pll->id), 0);
 +	POSTING_READ(PCH_DPLL(pll->id));
 +	udelay(200);
 +}
 +
 +static char *ibx_pch_dpll_names[] = {
 +	"PCH DPLL A",
 +	"PCH DPLL B",
 +};
  
 -retry:
 -	crtc_state = drm_atomic_get_crtc_state(state, crtc);
 -	ret = PTR_ERR_OR_ZERO(crtc_state);
 -	if (!ret) {
 -		if (!crtc_state->active)
 -			goto out;
 +static void ibx_pch_dpll_init(struct drm_device *dev)
 +{
 +	struct drm_i915_private *dev_priv = dev->dev_private;
 +	int i;
  
 -		crtc_state->mode_changed = true;
 -		ret = drm_atomic_commit(state);
 -	}
 +	dev_priv->num_shared_dpll = 2;
  
 -	if (ret == -EDEADLK) {
 -		drm_atomic_state_clear(state);
 -		drm_modeset_backoff(state->acquire_ctx);
 -		goto retry;
 +	for (i = 0; i < dev_priv->num_shared_dpll; i++) {
 +		dev_priv->shared_dplls[i].id = i;
 +		dev_priv->shared_dplls[i].name = ibx_pch_dpll_names[i];
 +		dev_priv->shared_dplls[i].mode_set = ibx_pch_dpll_mode_set;
 +		dev_priv->shared_dplls[i].enable = ibx_pch_dpll_enable;
 +		dev_priv->shared_dplls[i].disable = ibx_pch_dpll_disable;
 +		dev_priv->shared_dplls[i].get_hw_state =
 +			ibx_pch_dpll_get_hw_state;
  	}
 +}
  
 -	if (ret)
 -out:
 -		drm_atomic_state_free(state);
 +static void intel_shared_dpll_init(struct drm_device *dev)
 +{
 +	struct drm_i915_private *dev_priv = dev->dev_private;
 +
 +	if (HAS_DDI(dev))
 +		intel_ddi_pll_init(dev);
 +	else if (HAS_PCH_IBX(dev) || HAS_PCH_CPT(dev))
 +		ibx_pch_dpll_init(dev);
 +	else
 +		dev_priv->num_shared_dpll = 0;
 +
 +	BUG_ON(dev_priv->num_shared_dpll > I915_NUM_PLLS);
  }
  
 -#undef for_each_intel_crtc_masked
 +/**
 + * intel_wm_need_update - Check whether watermarks need updating
 + * @plane: drm plane
 + * @state: new plane state
 + *
 + * Check current plane state versus the new one to determine whether
 + * watermarks need to be recalculated.
 + *
 + * Returns true or false.
 + */
 +bool intel_wm_need_update(struct drm_plane *plane,
 +			  struct drm_plane_state *state)
 +{
 +	/* Update watermarks on tiling changes. */
 +	if (!plane->state->fb || !state->fb ||
 +	    plane->state->fb->modifier[0] != state->fb->modifier[0] ||
 +	    plane->state->rotation != state->rotation)
 +		return true;
  
 -static const struct drm_crtc_funcs intel_crtc_funcs = {
 -	.gamma_set = drm_atomic_helper_legacy_gamma_set,
 -	.set_config = drm_atomic_helper_set_config,
 -	.set_property = drm_atomic_helper_crtc_set_property,
 -	.destroy = intel_crtc_destroy,
 -	.page_flip = intel_crtc_page_flip,
 -	.atomic_duplicate_state = intel_crtc_duplicate_state,
 -	.atomic_destroy_state = intel_crtc_destroy_state,
 -};
 +	return false;
 +}
  
  /**
   * intel_prepare_plane_fb - Prepare fb for usage on plane
diff --cc drivers/gpu/drm/i915/intel_pm.c
index cca54888a5ac,c192028470f8..000000000000
--- a/drivers/gpu/drm/i915/intel_pm.c
+++ b/drivers/gpu/drm/i915/intel_pm.c
@@@ -2539,38 -2825,77 +2539,86 @@@ static bool ilk_disable_lp_wm(struct dr
  
  static void
  skl_ddb_get_pipe_allocation_limits(struct drm_device *dev,
++<<<<<<< HEAD
 +				   struct drm_crtc *for_crtc,
 +				   const struct intel_wm_config *config,
 +				   const struct skl_pipe_wm_parameters *params,
 +				   struct skl_ddb_entry *alloc /* out */)
 +{
 +	struct drm_crtc *crtc;
++=======
+ 				   const struct intel_crtc_state *cstate,
+ 				   struct skl_ddb_entry *alloc, /* out */
+ 				   int *num_active /* out */)
+ {
+ 	struct drm_atomic_state *state = cstate->base.state;
+ 	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
+ 	struct drm_i915_private *dev_priv = to_i915(dev);
+ 	struct drm_crtc *for_crtc = cstate->base.crtc;
++>>>>>>> a6d3460e62d1 (drm/i915/gen9: Drop re-allocation of DDB at atomic commit (v2))
  	unsigned int pipe_size, ddb_size;
  	int nth_active_pipe;
 -	int pipe = to_intel_crtc(for_crtc)->pipe;
  
++<<<<<<< HEAD
 +	if (!params->active) {
++=======
+ 	if (WARN_ON(!state) || !cstate->base.active) {
++>>>>>>> a6d3460e62d1 (drm/i915/gen9: Drop re-allocation of DDB at atomic commit (v2))
  		alloc->start = 0;
  		alloc->end = 0;
+ 		*num_active = hweight32(dev_priv->active_crtcs);
  		return;
  	}
  
++<<<<<<< HEAD
 +	ddb_size = SKL_DDB_SIZE;
 +
 +	ddb_size -= 4; /* 4 blocks for bypass path allocation */
 +
 +	nth_active_pipe = 0;
 +	for_each_crtc(dev, crtc) {
 +		if (!to_intel_crtc(crtc)->active)
 +			continue;
 +
 +		if (crtc == for_crtc)
 +			break;
 +
 +		nth_active_pipe++;
 +	}
 +
 +	pipe_size = ddb_size / config->num_pipes_active;
 +	alloc->start = nth_active_pipe * ddb_size / config->num_pipes_active;
++=======
+ 	if (intel_state->active_pipe_changes)
+ 		*num_active = hweight32(intel_state->active_crtcs);
+ 	else
+ 		*num_active = hweight32(dev_priv->active_crtcs);
+ 
+ 	if (IS_BROXTON(dev))
+ 		ddb_size = BXT_DDB_SIZE;
+ 	else
+ 		ddb_size = SKL_DDB_SIZE;
+ 
+ 	ddb_size -= 4; /* 4 blocks for bypass path allocation */
+ 
+ 	/*
+ 	 * If the state doesn't change the active CRTC's, then there's
+ 	 * no need to recalculate; the existing pipe allocation limits
+ 	 * should remain unchanged.  Note that we're safe from racing
+ 	 * commits since any racing commit that changes the active CRTC
+ 	 * list would need to grab _all_ crtc locks, including the one
+ 	 * we currently hold.
+ 	 */
+ 	if (!intel_state->active_pipe_changes) {
+ 		*alloc = dev_priv->wm.skl_hw.ddb.pipe[pipe];
+ 		return;
+ 	}
+ 
+ 	nth_active_pipe = hweight32(intel_state->active_crtcs &
+ 				    (drm_crtc_mask(for_crtc) - 1));
+ 	pipe_size = ddb_size / hweight32(intel_state->active_crtcs);
+ 	alloc->start = nth_active_pipe * ddb_size / *num_active;
++>>>>>>> a6d3460e62d1 (drm/i915/gen9: Drop re-allocation of DDB at atomic commit (v2))
  	alloc->end = alloc->start + pipe_size;
  }
  
@@@ -2621,66 -2988,128 +2669,148 @@@ skl_plane_relative_data_rate(const stru
   *   3 * 4096 * 8192  * 4 < 2^32
   */
  static unsigned int
 -skl_get_total_relative_data_rate(struct intel_crtc_state *intel_cstate)
 +skl_get_total_relative_data_rate(struct intel_crtc *intel_crtc,
 +				 const struct skl_pipe_wm_parameters *params)
  {
++<<<<<<< HEAD
 +	unsigned int total_data_rate = 0;
 +	int plane;
 +
 +	for (plane = 0; plane < intel_num_planes(intel_crtc); plane++) {
 +		const struct intel_plane_wm_parameters *p;
 +
 +		p = &params->plane[plane];
 +		if (!p->enabled)
 +			continue;
 +
 +		total_data_rate += skl_plane_relative_data_rate(p);
++=======
+ 	struct drm_crtc_state *cstate = &intel_cstate->base;
+ 	struct drm_atomic_state *state = cstate->state;
+ 	struct drm_crtc *crtc = cstate->crtc;
+ 	struct drm_device *dev = crtc->dev;
+ 	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
+ 	const struct drm_plane *plane;
+ 	const struct intel_plane *intel_plane;
+ 	struct drm_plane_state *pstate;
+ 	unsigned int rate, total_data_rate = 0;
+ 	int id;
+ 	int i;
+ 
+ 	if (WARN_ON(!state))
+ 		return 0;
+ 
+ 	/* Calculate and cache data rate for each plane */
+ 	for_each_plane_in_state(state, plane, pstate, i) {
+ 		id = skl_wm_plane_id(to_intel_plane(plane));
+ 		intel_plane = to_intel_plane(plane);
+ 
+ 		if (intel_plane->pipe != intel_crtc->pipe)
+ 			continue;
+ 
+ 		/* packed/uv */
+ 		rate = skl_plane_relative_data_rate(intel_cstate,
+ 						    pstate, 0);
+ 		intel_cstate->wm.skl.plane_data_rate[id] = rate;
+ 
+ 		/* y-plane */
+ 		rate = skl_plane_relative_data_rate(intel_cstate,
+ 						    pstate, 1);
+ 		intel_cstate->wm.skl.plane_y_data_rate[id] = rate;
++>>>>>>> a6d3460e62d1 (drm/i915/gen9: Drop re-allocation of DDB at atomic commit (v2))
  	}
  
 -	/* Calculate CRTC's total data rate from cached values */
 -	for_each_intel_plane_on_crtc(dev, intel_crtc, intel_plane) {
 -		int id = skl_wm_plane_id(intel_plane);
 -
 -		/* packed/uv */
 -		total_data_rate += intel_cstate->wm.skl.plane_data_rate[id];
 -		total_data_rate += intel_cstate->wm.skl.plane_y_data_rate[id];
 -	}
 -
 -	WARN_ON(cstate->plane_mask && total_data_rate == 0);
 -
  	return total_data_rate;
  }
  
 -static int
 -skl_allocate_pipe_ddb(struct intel_crtc_state *cstate,
 +static void
 +skl_allocate_pipe_ddb(struct drm_crtc *crtc,
 +		      const struct intel_wm_config *config,
 +		      const struct skl_pipe_wm_parameters *params,
  		      struct skl_ddb_allocation *ddb /* out */)
  {
 -	struct drm_atomic_state *state = cstate->base.state;
 -	struct drm_crtc *crtc = cstate->base.crtc;
  	struct drm_device *dev = crtc->dev;
++<<<<<<< HEAD
 +	struct drm_i915_private *dev_priv = dev->dev_private;
++=======
++>>>>>>> a6d3460e62d1 (drm/i915/gen9: Drop re-allocation of DDB at atomic commit (v2))
  	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 -	struct intel_plane *intel_plane;
 -	struct drm_plane *plane;
 -	struct drm_plane_state *pstate;
  	enum pipe pipe = intel_crtc->pipe;
  	struct skl_ddb_entry *alloc = &ddb->pipe[pipe];
  	uint16_t alloc_size, start, cursor_blocks;
 -	uint16_t *minimum = cstate->wm.skl.minimum_blocks;
 -	uint16_t *y_minimum = cstate->wm.skl.minimum_y_blocks;
 +	uint16_t minimum[I915_MAX_PLANES];
  	unsigned int total_data_rate;
 -	int num_active;
 -	int id, i;
 +	int plane;
  
++<<<<<<< HEAD
 +	skl_ddb_get_pipe_allocation_limits(dev, crtc, config, params, alloc);
++=======
+ 	if (WARN_ON(!state))
+ 		return 0;
+ 
+ 	if (!cstate->base.active) {
+ 		ddb->pipe[pipe].start = ddb->pipe[pipe].end = 0;
+ 		memset(ddb->plane[pipe], 0, sizeof(ddb->plane[pipe]));
+ 		memset(ddb->y_plane[pipe], 0, sizeof(ddb->y_plane[pipe]));
+ 		return 0;
+ 	}
+ 
+ 	skl_ddb_get_pipe_allocation_limits(dev, cstate, alloc, &num_active);
++>>>>>>> a6d3460e62d1 (drm/i915/gen9: Drop re-allocation of DDB at atomic commit (v2))
  	alloc_size = skl_ddb_entry_size(alloc);
  	if (alloc_size == 0) {
  		memset(ddb->plane[pipe], 0, sizeof(ddb->plane[pipe]));
 -		return 0;
 +		memset(&ddb->cursor[pipe], 0, sizeof(ddb->cursor[pipe]));
 +		return;
  	}
  
 -	cursor_blocks = skl_cursor_allocation(num_active);
 -	ddb->plane[pipe][PLANE_CURSOR].start = alloc->end - cursor_blocks;
 -	ddb->plane[pipe][PLANE_CURSOR].end = alloc->end;
 +	cursor_blocks = skl_cursor_allocation(config);
 +	ddb->cursor[pipe].start = alloc->end - cursor_blocks;
 +	ddb->cursor[pipe].end = alloc->end;
  
  	alloc_size -= cursor_blocks;
- 	alloc->end -= cursor_blocks;
  
  	/* 1. Allocate the mininum required blocks for each active plane */
++<<<<<<< HEAD
 +	for_each_plane(dev_priv, pipe, plane) {
 +		const struct intel_plane_wm_parameters *p;
 +
 +		p = &params->plane[plane];
 +		if (!p->enabled)
 +			continue;
 +
 +		minimum[plane] = 8;
 +		alloc_size -= minimum[plane];
++=======
+ 	for_each_plane_in_state(state, plane, pstate, i) {
+ 		intel_plane = to_intel_plane(plane);
+ 		id = skl_wm_plane_id(intel_plane);
+ 
+ 		if (intel_plane->pipe != pipe)
+ 			continue;
+ 
+ 		if (!to_intel_plane_state(pstate)->visible) {
+ 			minimum[id] = 0;
+ 			y_minimum[id] = 0;
+ 			continue;
+ 		}
+ 		if (plane->type == DRM_PLANE_TYPE_CURSOR) {
+ 			minimum[id] = 0;
+ 			y_minimum[id] = 0;
+ 			continue;
+ 		}
+ 
+ 		minimum[id] = 8;
+ 		if (pstate->fb->pixel_format == DRM_FORMAT_NV12)
+ 			y_minimum[id] = 8;
+ 		else
+ 			y_minimum[id] = 0;
+ 	}
+ 
+ 	for (i = 0; i < PLANE_CURSOR; i++) {
+ 		alloc_size -= minimum[i];
+ 		alloc_size -= y_minimum[i];
++>>>>>>> a6d3460e62d1 (drm/i915/gen9: Drop re-allocation of DDB at atomic commit (v2))
  	}
  
  	/*
@@@ -3260,15 -3653,15 +3390,19 @@@ static bool skl_update_pipe_wm(struct d
  			       struct skl_pipe_wm *pipe_wm /* out */)
  {
  	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 -	struct intel_crtc_state *cstate = to_intel_crtc_state(crtc->state);
  
++<<<<<<< HEAD
 +	skl_compute_wm_pipe_parameters(crtc, params);
 +	skl_allocate_pipe_ddb(crtc, config, params, ddb);
 +	skl_compute_pipe_wm(crtc, ddb, params, pipe_wm);
++=======
+ 	skl_build_pipe_wm(cstate, ddb, pipe_wm);
++>>>>>>> a6d3460e62d1 (drm/i915/gen9: Drop re-allocation of DDB at atomic commit (v2))
  
 -	if (!memcmp(&intel_crtc->wm.active.skl, pipe_wm, sizeof(*pipe_wm)))
 +	if (!memcmp(&intel_crtc->wm.skl_active, pipe_wm, sizeof(*pipe_wm)))
  		return false;
  
 -	intel_crtc->wm.active.skl = *pipe_wm;
 -
 +	intel_crtc->wm.skl_active = *pipe_wm;
  	return true;
  }
  
@@@ -3321,6 -3710,94 +3455,97 @@@ static void skl_update_other_pipe_wm(st
  	}
  }
  
++<<<<<<< HEAD
++=======
+ static void skl_clear_wm(struct skl_wm_values *watermarks, enum pipe pipe)
+ {
+ 	watermarks->wm_linetime[pipe] = 0;
+ 	memset(watermarks->plane[pipe], 0,
+ 	       sizeof(uint32_t) * 8 * I915_MAX_PLANES);
+ 	memset(watermarks->plane_trans[pipe],
+ 	       0, sizeof(uint32_t) * I915_MAX_PLANES);
+ 	watermarks->plane_trans[pipe][PLANE_CURSOR] = 0;
+ }
+ 
+ static int
+ skl_compute_ddb(struct drm_atomic_state *state)
+ {
+ 	struct drm_device *dev = state->dev;
+ 	struct drm_i915_private *dev_priv = to_i915(dev);
+ 	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
+ 	struct intel_crtc *intel_crtc;
+ 	unsigned realloc_pipes = dev_priv->active_crtcs;
+ 	int ret;
+ 
+ 	/*
+ 	 * If this is our first atomic update following hardware readout,
+ 	 * we can't trust the DDB that the BIOS programmed for us.  Let's
+ 	 * pretend that all pipes switched active status so that we'll
+ 	 * ensure a full DDB recompute.
+ 	 */
+ 	if (dev_priv->wm.distrust_bios_wm)
+ 		intel_state->active_pipe_changes = ~0;
+ 
+ 	/*
+ 	 * If the modeset changes which CRTC's are active, we need to
+ 	 * recompute the DDB allocation for *all* active pipes, even
+ 	 * those that weren't otherwise being modified in any way by this
+ 	 * atomic commit.  Due to the shrinking of the per-pipe allocations
+ 	 * when new active CRTC's are added, it's possible for a pipe that
+ 	 * we were already using and aren't changing at all here to suddenly
+ 	 * become invalid if its DDB needs exceeds its new allocation.
+ 	 *
+ 	 * Note that if we wind up doing a full DDB recompute, we can't let
+ 	 * any other display updates race with this transaction, so we need
+ 	 * to grab the lock on *all* CRTC's.
+ 	 */
+ 	if (intel_state->active_pipe_changes)
+ 		realloc_pipes = ~0;
+ 
+ 	for_each_intel_crtc_mask(dev, intel_crtc, realloc_pipes) {
+ 		struct intel_crtc_state *cstate;
+ 
+ 		cstate = intel_atomic_get_crtc_state(state, intel_crtc);
+ 		if (IS_ERR(cstate))
+ 			return PTR_ERR(cstate);
+ 
+ 		ret = skl_allocate_pipe_ddb(cstate, &intel_state->ddb);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int
+ skl_compute_wm(struct drm_atomic_state *state)
+ {
+ 	struct drm_crtc *crtc;
+ 	struct drm_crtc_state *cstate;
+ 	int ret, i;
+ 	bool changed = false;
+ 
+ 	/*
+ 	 * If this transaction isn't actually touching any CRTC's, don't
+ 	 * bother with watermark calculation.  Note that if we pass this
+ 	 * test, we're guaranteed to hold at least one CRTC state mutex,
+ 	 * which means we can safely use values like dev_priv->active_crtcs
+ 	 * since any racing commits that want to update them would need to
+ 	 * hold _all_ CRTC state mutexes.
+ 	 */
+ 	for_each_crtc_in_state(state, crtc, cstate, i)
+ 		changed = true;
+ 	if (!changed)
+ 		return 0;
+ 
+ 	ret = skl_compute_ddb(state);
+ 	if (ret)
+ 		return ret;
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> a6d3460e62d1 (drm/i915/gen9: Drop re-allocation of DDB at atomic commit (v2))
  static void skl_update_wm(struct drm_crtc *crtc)
  {
  	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
* Unmerged path drivers/gpu/drm/i915/intel_display.c
* Unmerged path drivers/gpu/drm/i915/intel_pm.c
