nvme: only add a controller to dev_list after it's been fully initialized

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Christoph Hellwig <hch@lst.de>
commit 7385014c073263b077442439299fad013edd4409
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/7385014c.failed

Without this we can easily get bad derferences on nvmeq->d_db when the nvme
kthread tries to poll the CQs for controllers that are in half initialized
state.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Keith Busch <keith.busch@intel.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 7385014c073263b077442439299fad013edd4409)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/block/nvme-core.c
diff --cc drivers/block/nvme-core.c
index 2a6eb55ad96c,d82f08d671e6..000000000000
--- a/drivers/block/nvme-core.c
+++ b/drivers/block/nvme-core.c
@@@ -2845,89 -2130,10 +2869,93 @@@ static void nvme_free_dev(struct kref *
  	kfree(dev);
  }
  
 -static void nvme_probe_work(struct work_struct *work)
 +static int nvme_dev_open(struct inode *inode, struct file *f)
  {
 +	struct nvme_dev *dev;
 +	int instance = iminor(inode);
 +	int ret = -ENODEV;
 +
 +	spin_lock(&dev_list_lock);
 +	list_for_each_entry(dev, &dev_list, node) {
 +		if (dev->instance == instance) {
 +			if (!dev->admin_q) {
 +				ret = -EWOULDBLOCK;
 +				break;
 +			}
 +			if (!kref_get_unless_zero(&dev->kref))
 +				break;
 +			f->private_data = dev;
 +			ret = 0;
 +			break;
 +		}
 +	}
 +	spin_unlock(&dev_list_lock);
 +
 +	return ret;
 +}
 +
 +static int nvme_dev_release(struct inode *inode, struct file *f)
 +{
 +	struct nvme_dev *dev = f->private_data;
 +	kref_put(&dev->kref, nvme_free_dev);
 +	return 0;
 +}
 +
 +static long nvme_dev_ioctl(struct file *f, unsigned int cmd, unsigned long arg)
 +{
 +	struct nvme_dev *dev = f->private_data;
 +	struct nvme_ns *ns;
 +
 +	switch (cmd) {
 +	case NVME_IOCTL_ADMIN_CMD:
 +		return nvme_user_cmd(dev, NULL, (void __user *)arg);
 +	case NVME_IOCTL_IO_CMD:
 +		if (list_empty(&dev->namespaces))
 +			return -ENOTTY;
 +		ns = list_first_entry(&dev->namespaces, struct nvme_ns, list);
 +		return nvme_user_cmd(dev, ns, (void __user *)arg);
 +	case NVME_IOCTL_RESET:
 +		dev_warn(&dev->pci_dev->dev, "resetting controller\n");
 +		return nvme_reset(dev);
 +	case NVME_IOCTL_SUBSYS_RESET:
 +		return nvme_subsys_reset(dev);
 +	default:
 +		return -ENOTTY;
 +	}
 +}
 +
 +static const struct file_operations nvme_dev_fops = {
 +	.owner		= THIS_MODULE,
 +	.open		= nvme_dev_open,
 +	.release	= nvme_dev_release,
 +	.unlocked_ioctl	= nvme_dev_ioctl,
 +	.compat_ioctl	= nvme_dev_ioctl,
 +};
 +
 +static void nvme_set_irq_hints(struct nvme_dev *dev)
 +{
 +	struct nvme_queue *nvmeq;
 +	int i;
 +
 +	for (i = 0; i < dev->online_queues; i++) {
 +		nvmeq = dev->queues[i];
 +
 +		if (!nvmeq->tags || !(*nvmeq->tags))
 +			continue;
 +
 +		irq_set_affinity_hint(dev->entry[nvmeq->cq_vector].vector,
 +					blk_mq_tags_cpumask(*nvmeq->tags));
 +	}
 +}
 +
 +static int nvme_dev_start(struct nvme_dev *dev)
 +{
++<<<<<<< HEAD:drivers/block/nvme-core.c
++=======
+ 	struct nvme_dev *dev = container_of(work, struct nvme_dev, probe_work);
++>>>>>>> 7385014c0732 (nvme: only add a controller to dev_list after it's been fully initialized):drivers/nvme/host/pci.c
  	int result;
 +	bool start_thread = false;
  
  	result = nvme_dev_map(dev);
  	if (result)
@@@ -2965,22 -2156,40 +2974,43 @@@
  	if (result)
  		goto free_tags;
  
 -	dev->ctrl.event_limit = 1;
 +	nvme_set_irq_hints(dev);
  
++<<<<<<< HEAD:drivers/block/nvme-core.c
 +	dev->event_limit = 1;
 +	return result;
++=======
+ 	result = nvme_dev_list_add(dev);
+ 	if (result)
+ 		goto remove;
+ 
+ 	/*
+ 	 * Keep the controller around but remove all namespaces if we don't have
+ 	 * any working I/O queue.
+ 	 */
+ 	if (dev->online_queues < 2) {
+ 		dev_warn(dev->dev, "IO queues not created\n");
+ 		nvme_remove_namespaces(&dev->ctrl);
+ 	} else {
+ 		nvme_unfreeze_queues(dev);
+ 		nvme_dev_add(dev);
+ 	}
+ 
+ 	return;
++>>>>>>> 7385014c0732 (nvme: only add a controller to dev_list after it's been fully initialized):drivers/nvme/host/pci.c
  
+  remove:
+ 	nvme_dev_list_remove(dev);
   free_tags:
  	nvme_dev_remove_admin(dev);
 -	blk_put_queue(dev->ctrl.admin_q);
 -	dev->ctrl.admin_q = NULL;
 +	blk_put_queue(dev->admin_q);
 +	dev->admin_q = NULL;
  	dev->queues[0]->tags = NULL;
   disable:
  	nvme_disable_queue(dev, 0);
- 	nvme_dev_list_remove(dev);
   unmap:
  	nvme_dev_unmap(dev);
 - out:
 -	if (!work_busy(&dev->reset_work))
 -		nvme_dead_ctrl(dev);
 +	return result;
  }
  
  static int nvme_remove_dead_ctrl(void *arg)
* Unmerged path drivers/block/nvme-core.c
