hv_netvsc: move subchannel existence check to netvsc_select_queue()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Vitaly Kuznetsov <vkuznets@redhat.com>
commit 8b9fbe1ac390689f01153d6af8485caec5423ccc
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/8b9fbe1a.failed

	Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
	Signed-off-by: K. Y. Srinivasan <kys@microsoft.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 8b9fbe1ac390689f01153d6af8485caec5423ccc)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/hyperv/hyperv_net.h
#	drivers/net/hyperv/netvsc.c
diff --cc drivers/net/hyperv/hyperv_net.h
index cf498664d989,8d534a324ce1..000000000000
--- a/drivers/net/hyperv/hyperv_net.h
+++ b/drivers/net/hyperv/hyperv_net.h
@@@ -1180,5 -1272,4 +1180,8 @@@ struct rndis_message 
  #define TRANSPORT_INFO_IPV6_TCP ((INFO_IPV6 << 16) | INFO_TCP)
  #define TRANSPORT_INFO_IPV6_UDP ((INFO_IPV6 << 16) | INFO_UDP)
  
++<<<<<<< HEAD
 +
++=======
++>>>>>>> 8b9fbe1ac390 (hv_netvsc: move subchannel existence check to netvsc_select_queue())
  #endif /* _HYPERV_NET_H */
diff --cc drivers/net/hyperv/netvsc.c
index 74ee1b57e623,419b05515b92..000000000000
--- a/drivers/net/hyperv/netvsc.c
+++ b/drivers/net/hyperv/netvsc.c
@@@ -714,55 -738,43 +714,62 @@@ u32 netvsc_copy_to_send_buf(struct netv
  	return msg_size;
  }
  
 -static inline int netvsc_send_pkt(
 -	struct hv_netvsc_packet *packet,
 -	struct netvsc_device *net_device)
 +int netvsc_send(struct hv_device *device,
 +			struct hv_netvsc_packet *packet)
  {
++<<<<<<< HEAD
 +	struct netvsc_device *net_device;
 +	int ret = 0;
 +	struct nvsp_message sendMessage;
 +	struct net_device *ndev;
 +	struct vmbus_channel *out_channel = NULL;
++=======
+ 	struct nvsp_message nvmsg;
+ 	u16 q_idx = packet->q_idx;
+ 	struct vmbus_channel *out_channel = net_device->chn_table[q_idx];
+ 	struct net_device *ndev = net_device->ndev;
++>>>>>>> 8b9fbe1ac390 (hv_netvsc: move subchannel existence check to netvsc_select_queue())
  	u64 req_id;
 -	int ret;
 -	struct hv_page_buffer *pgbuf;
 -	u32 ring_avail = hv_ringbuf_avail_percent(&out_channel->outbound);
 +	unsigned int section_index = NETVSC_INVALID_INDEX;
 +	u32 msg_size = 0;
 +	struct sk_buff *skb = NULL;
 +	u16 q_idx = packet->q_idx;
 +
 +
 +	net_device = get_outbound_net_device(device);
 +	if (!net_device)
 +		return -ENODEV;
 +	ndev = net_device->ndev;
  
 -	nvmsg.hdr.msg_type = NVSP_MSG1_TYPE_SEND_RNDIS_PKT;
 +	sendMessage.hdr.msg_type = NVSP_MSG1_TYPE_SEND_RNDIS_PKT;
  	if (packet->is_data_pkt) {
  		/* 0 is RMC_DATA; */
 -		nvmsg.msg.v1_msg.send_rndis_pkt.channel_type = 0;
 +		sendMessage.msg.v1_msg.send_rndis_pkt.channel_type = 0;
  	} else {
  		/* 1 is RMC_CONTROL; */
 -		nvmsg.msg.v1_msg.send_rndis_pkt.channel_type = 1;
 +		sendMessage.msg.v1_msg.send_rndis_pkt.channel_type = 1;
  	}
  
 -	nvmsg.msg.v1_msg.send_rndis_pkt.send_buf_section_index =
 -		packet->send_buf_index;
 -	if (packet->send_buf_index == NETVSC_INVALID_INDEX)
 -		nvmsg.msg.v1_msg.send_rndis_pkt.send_buf_section_size = 0;
 -	else
 -		nvmsg.msg.v1_msg.send_rndis_pkt.send_buf_section_size =
 -			packet->total_data_buflen;
 +	/* Attempt to send via sendbuf */
 +	if (packet->total_data_buflen < net_device->send_section_size) {
 +		section_index = netvsc_get_next_send_section(net_device);
 +		if (section_index != NETVSC_INVALID_INDEX) {
 +			msg_size = netvsc_copy_to_send_buf(net_device,
 +							   section_index,
 +							   packet);
 +			skb = (struct sk_buff *)
 +			      (unsigned long)packet->send_completion_tid;
 +			packet->page_buf_cnt = 0;
 +		}
 +	}
 +	packet->send_buf_index = section_index;
  
 -	if (packet->completion_func)
 +
 +	sendMessage.msg.v1_msg.send_rndis_pkt.send_buf_section_index =
 +		section_index;
 +	sendMessage.msg.v1_msg.send_rndis_pkt.send_buf_section_size = msg_size;
 +
 +	if (packet->send_completion)
  		req_id = (ulong)packet;
  	else
  		req_id = 0;
@@@ -817,13 -837,114 +824,71 @@@
  			   packet, ret);
  	}
  
++<<<<<<< HEAD
 +	if (ret != 0) {
 +		if (section_index != NETVSC_INVALID_INDEX)
 +			netvsc_free_send_slot(net_device, section_index);
 +	} else if (skb) {
 +		dev_kfree_skb_any(skb);
++=======
+ 	return ret;
+ }
+ 
+ int netvsc_send(struct hv_device *device,
+ 		struct hv_netvsc_packet *packet,
+ 		struct rndis_message *rndis_msg)
+ {
+ 	struct netvsc_device *net_device;
+ 	int ret = 0, m_ret = 0;
+ 	struct vmbus_channel *out_channel;
+ 	u16 q_idx = packet->q_idx;
+ 	u32 pktlen = packet->total_data_buflen, msd_len = 0;
+ 	unsigned int section_index = NETVSC_INVALID_INDEX;
+ 	unsigned long flag;
+ 	struct multi_send_data *msdp;
+ 	struct hv_netvsc_packet *msd_send = NULL, *cur_send = NULL;
+ 	bool try_batch;
+ 
+ 	net_device = get_outbound_net_device(device);
+ 	if (!net_device)
+ 		return -ENODEV;
+ 
+ 	out_channel = net_device->chn_table[q_idx];
+ 
+ 	packet->send_buf_index = NETVSC_INVALID_INDEX;
+ 	packet->cp_partial = false;
+ 
+ 	msdp = &net_device->msd[q_idx];
+ 
+ 	/* batch packets in send buffer if possible */
+ 	spin_lock_irqsave(&msdp->lock, flag);
+ 	if (msdp->pkt)
+ 		msd_len = msdp->pkt->total_data_buflen;
+ 
+ 	try_batch = packet->is_data_pkt && msd_len > 0 && msdp->count <
+ 		    net_device->max_pkt;
+ 
+ 	if (try_batch && msd_len + pktlen + net_device->pkt_align <
+ 	    net_device->send_section_size) {
+ 		section_index = msdp->pkt->send_buf_index;
+ 
+ 	} else if (try_batch && msd_len + packet->rmsg_size <
+ 		   net_device->send_section_size) {
+ 		section_index = msdp->pkt->send_buf_index;
+ 		packet->cp_partial = true;
+ 
+ 	} else if (packet->is_data_pkt && pktlen + net_device->pkt_align <
+ 		   net_device->send_section_size) {
+ 		section_index = netvsc_get_next_send_section(net_device);
+ 		if (section_index != NETVSC_INVALID_INDEX) {
+ 				msd_send = msdp->pkt;
+ 				msdp->pkt = NULL;
+ 				msdp->count = 0;
+ 				msd_len = 0;
+ 		}
++>>>>>>> 8b9fbe1ac390 (hv_netvsc: move subchannel existence check to netvsc_select_queue())
  	}
  
 -	if (section_index != NETVSC_INVALID_INDEX) {
 -		netvsc_copy_to_send_buf(net_device,
 -					section_index, msd_len,
 -					packet, rndis_msg);
 -
 -		packet->send_buf_index = section_index;
 -
 -		if (packet->cp_partial) {
 -			packet->page_buf_cnt -= packet->rmsg_pgcnt;
 -			packet->total_data_buflen = msd_len + packet->rmsg_size;
 -		} else {
 -			packet->page_buf_cnt = 0;
 -			packet->total_data_buflen += msd_len;
 -		}
 -
 -		if (msdp->pkt)
 -			netvsc_xmit_completion(msdp->pkt);
 -
 -		if (packet->xmit_more && !packet->cp_partial) {
 -			msdp->pkt = packet;
 -			msdp->count++;
 -		} else {
 -			cur_send = packet;
 -			msdp->pkt = NULL;
 -			msdp->count = 0;
 -		}
 -	} else {
 -		msd_send = msdp->pkt;
 -		msdp->pkt = NULL;
 -		msdp->count = 0;
 -		cur_send = packet;
 -	}
 -
 -	spin_unlock_irqrestore(&msdp->lock, flag);
 -
 -	if (msd_send) {
 -		m_ret = netvsc_send_pkt(msd_send, net_device);
 -
 -		if (m_ret != 0) {
 -			netvsc_free_send_slot(net_device,
 -					      msd_send->send_buf_index);
 -			netvsc_xmit_completion(msd_send);
 -		}
 -	}
 -
 -	if (cur_send)
 -		ret = netvsc_send_pkt(cur_send, net_device);
 -
 -	if (ret != 0 && section_index != NETVSC_INVALID_INDEX)
 -		netvsc_free_send_slot(net_device, section_index);
 -
  	return ret;
  }
  
* Unmerged path drivers/net/hyperv/hyperv_net.h
* Unmerged path drivers/net/hyperv/netvsc.c
diff --git a/drivers/net/hyperv/netvsc_drv.c b/drivers/net/hyperv/netvsc_drv.c
index 56b76b7b9a27..6d183cd13a82 100644
--- a/drivers/net/hyperv/netvsc_drv.c
+++ b/drivers/net/hyperv/netvsc_drv.c
@@ -267,6 +267,9 @@ static u16 netvsc_select_queue(struct net_device *ndev, struct sk_buff *skb)
 		skb_set_hash(skb, hash, PKT_HASH_TYPE_L3);
 	}
 
+	if (!nvsc_dev->chn_table[q_idx])
+		q_idx = 0;
+
 	return q_idx;
 }
 
