IB/qib, IB/hfi1: Fix up UD loopback use of irq flags

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Mike Marciniszyn <mike.marciniszyn@intel.com>
commit 747f4d7a9d1bc07e3f9f22c84201ffb0abee1634
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/747f4d7a.failed

The dual lock patch moved locking around and missed an issue
with handling irq flags when processing UD loopback
packets.  This issue was revealed by smatch.

Fix for both qib and hfi1 to pass the saved flags to the UD request
builder and handle the changes correctly.

Fixes: 46a80d62e6e0 ("IB/qib, staging/rdma/hfi1: add s_hlock for use in post send")
	Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
	Reviewed-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
	Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 747f4d7a9d1bc07e3f9f22c84201ffb0abee1634)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/qib/qib_rc.c
#	drivers/infiniband/hw/qib/qib_ruc.c
#	drivers/infiniband/hw/qib/qib_uc.c
#	drivers/infiniband/hw/qib/qib_ud.c
#	drivers/infiniband/hw/qib/qib_verbs.h
#	drivers/staging/hfi1/ruc.c
#	drivers/staging/hfi1/ud.c
#	drivers/staging/rdma/hfi1/verbs.h
diff --cc drivers/infiniband/hw/qib/qib_rc.c
index c23ede5294da,444028a3582a..000000000000
--- a/drivers/infiniband/hw/qib/qib_rc.c
+++ b/drivers/infiniband/hw/qib/qib_rc.c
@@@ -226,9 -226,11 +226,13 @@@ bail
   * qib_make_rc_req - construct a request packet (SEND, RDMA r/w, ATOMIC)
   * @qp: a pointer to the QP
   *
 - * Assumes the s_lock is held.
 - *
   * Return 1 if constructed; otherwise, return 0.
   */
++<<<<<<< HEAD
 +int qib_make_rc_req(struct qib_qp *qp)
++=======
+ int qib_make_rc_req(struct rvt_qp *qp, unsigned long *flags)
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags)
  {
  	struct qib_qp_priv *priv = qp->priv;
  	struct qib_ibdev *dev = to_idev(qp->ibqp.device);
diff --cc drivers/infiniband/hw/qib/qib_ruc.c
index e9132f7a68b0,b67779256297..000000000000
--- a/drivers/infiniband/hw/qib/qib_ruc.c
+++ b/drivers/infiniband/hw/qib/qib_ruc.c
@@@ -717,14 -734,12 +717,18 @@@ void qib_make_ruc_header(struct qib_qp 
   * exhausted.  Only allow one CPU to send a packet per QP (tasklet).
   * Otherwise, two threads could send packets out of order.
   */
 -void qib_do_send(struct rvt_qp *qp)
 +void qib_do_send(struct work_struct *work)
  {
 -	struct qib_qp_priv *priv = qp->priv;
 +	struct qib_qp_priv *priv = container_of(work, struct qib_qp_priv,
 +						s_work);
 +	struct qib_qp *qp = priv->owner;
  	struct qib_ibport *ibp = to_iport(qp->ibqp.device, qp->port_num);
  	struct qib_pportdata *ppd = ppd_from_ibp(ibp);
++<<<<<<< HEAD
 +	int (*make_req)(struct qib_qp *qp);
++=======
+ 	int (*make_req)(struct rvt_qp *qp, unsigned long *flags);
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags)
  	unsigned long flags;
  
  	if ((qp->ibqp.qp_type == IB_QPT_RC ||
@@@ -762,11 -776,14 +766,17 @@@
  			 */
  			if (qib_verbs_send(qp, priv->s_hdr, qp->s_hdrwords,
  					   qp->s_cur_sge, qp->s_cur_size))
 -				return;
 +				break;
  			/* Record that s_hdr is empty. */
  			qp->s_hdrwords = 0;
 -			spin_lock_irqsave(&qp->s_lock, flags);
  		}
++<<<<<<< HEAD
 +	} while (make_req(qp));
++=======
+ 	} while (make_req(qp, &flags));
+ 
+ 	spin_unlock_irqrestore(&qp->s_lock, flags);
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags)
  }
  
  /*
diff --cc drivers/infiniband/hw/qib/qib_uc.c
index bab9aeb5dd9e,1d61bd04f449..000000000000
--- a/drivers/infiniband/hw/qib/qib_uc.c
+++ b/drivers/infiniband/hw/qib/qib_uc.c
@@@ -41,9 -41,11 +41,13 @@@
   * qib_make_uc_req - construct a request packet (SEND, RDMA write)
   * @qp: a pointer to the QP
   *
 - * Assumes the s_lock is held.
 - *
   * Return 1 if constructed; otherwise, return 0.
   */
++<<<<<<< HEAD
 +int qib_make_uc_req(struct qib_qp *qp)
++=======
+ int qib_make_uc_req(struct rvt_qp *qp, unsigned long *flags)
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags)
  {
  	struct qib_qp_priv *priv = qp->priv;
  	struct qib_other_headers *ohdr;
diff --cc drivers/infiniband/hw/qib/qib_ud.c
index 75faa5bd8dd6,846e6c726df7..000000000000
--- a/drivers/infiniband/hw/qib/qib_ud.c
+++ b/drivers/infiniband/hw/qib/qib_ud.c
@@@ -230,9 -234,11 +230,13 @@@ drop
   * qib_make_ud_req - construct a UD request packet
   * @qp: the QP
   *
 - * Assumes the s_lock is held.
 - *
   * Return 1 if constructed; otherwise, return 0.
   */
++<<<<<<< HEAD
 +int qib_make_ud_req(struct qib_qp *qp)
++=======
+ int qib_make_ud_req(struct rvt_qp *qp, unsigned long *flags)
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags)
  {
  	struct qib_qp_priv *priv = qp->priv;
  	struct qib_other_headers *ohdr;
@@@ -288,6 -294,7 +292,10 @@@
  		this_cpu_inc(ibp->pmastats->n_unicast_xmit);
  		lid = ah_attr->dlid & ~((1 << ppd->lmc) - 1);
  		if (unlikely(lid == ppd->lid)) {
++<<<<<<< HEAD
++=======
+ 			unsigned long tflags = *flags;
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags)
  			/*
  			 * If DMAs are in progress, we can't generate
  			 * a completion for the loopback packet since
@@@ -300,9 -307,10 +308,14 @@@
  				goto bail;
  			}
  			qp->s_cur = next_cur;
++<<<<<<< HEAD
 +			spin_unlock_irqrestore(&qp->s_lock, flags);
++=======
+ 			spin_unlock_irqrestore(&qp->s_lock, tflags);
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags)
  			qib_ud_loopback(qp, wqe);
- 			spin_lock_irqsave(&qp->s_lock, flags);
+ 			spin_lock_irqsave(&qp->s_lock, tflags);
+ 			*flags = tflags;
  			qib_send_complete(qp, wqe, IB_WC_SUCCESS);
  			goto done;
  		}
diff --cc drivers/infiniband/hw/qib/qib_verbs.h
index ca366073af4f,6888f03c6d61..000000000000
--- a/drivers/infiniband/hw/qib/qib_verbs.h
+++ b/drivers/infiniband/hw/qib/qib_verbs.h
@@@ -1113,21 -418,23 +1113,29 @@@ int qib_ruc_check_hdr(struct qib_ibpor
  u32 qib_make_grh(struct qib_ibport *ibp, struct ib_grh *hdr,
  		 struct ib_global_route *grh, u32 hwords, u32 nwords);
  
 -void qib_make_ruc_header(struct rvt_qp *qp, struct qib_other_headers *ohdr,
 +void qib_make_ruc_header(struct qib_qp *qp, struct qib_other_headers *ohdr,
  			 u32 bth0, u32 bth2);
  
 -void _qib_do_send(struct work_struct *work);
 +void qib_do_send(struct work_struct *work);
  
 -void qib_do_send(struct rvt_qp *qp);
 -
 -void qib_send_complete(struct rvt_qp *qp, struct rvt_swqe *wqe,
 +void qib_send_complete(struct qib_qp *qp, struct qib_swqe *wqe,
  		       enum ib_wc_status status);
  
 -void qib_send_rc_ack(struct rvt_qp *qp);
 +void qib_send_rc_ack(struct qib_qp *qp);
 +
++<<<<<<< HEAD
 +int qib_make_rc_req(struct qib_qp *qp);
 +
 +int qib_make_uc_req(struct qib_qp *qp);
  
 +int qib_make_ud_req(struct qib_qp *qp);
++=======
+ int qib_make_rc_req(struct rvt_qp *qp, unsigned long *flags);
+ 
+ int qib_make_uc_req(struct rvt_qp *qp, unsigned long *flags);
+ 
+ int qib_make_ud_req(struct rvt_qp *qp, unsigned long *flags);
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags)
  
  int qib_register_ib_device(struct qib_devdata *);
  
diff --cc drivers/staging/hfi1/ruc.c
index c4280b6f47d4,a659aec3c3c6..000000000000
--- a/drivers/staging/hfi1/ruc.c
+++ b/drivers/staging/hfi1/ruc.c
@@@ -809,36 -826,46 +809,45 @@@ void hfi1_make_ruc_header(struct hfi1_q
   * exhausted.  Only allow one CPU to send a packet per QP (tasklet).
   * Otherwise, two threads could send packets out of order.
   */
 -void hfi1_do_send(struct rvt_qp *qp)
 +void hfi1_do_send(struct work_struct *work)
  {
 +	struct iowait *wait = container_of(work, struct iowait, iowork);
 +	struct hfi1_qp *qp = iowait_to_qp(wait);
  	struct hfi1_pkt_state ps;
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +	int (*make_req)(struct hfi1_qp *qp);
 +	unsigned long flags;
++=======
+ 	struct hfi1_qp_priv *priv = qp->priv;
+ 	int (*make_req)(struct rvt_qp *qp, struct hfi1_pkt_state *ps);
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags):drivers/staging/rdma/hfi1/ruc.c
  	unsigned long timeout;
 -	unsigned long timeout_int;
 -	int cpu;
  
  	ps.dev = to_idev(qp->ibqp.device);
  	ps.ibp = to_iport(qp->ibqp.device, qp->port_num);
  	ps.ppd = ppd_from_ibp(ps.ibp);
  
 -	switch (qp->ibqp.qp_type) {
 -	case IB_QPT_RC:
 -		if (!loopback && ((qp->remote_ah_attr.dlid & ~((1 << ps.ppd->lmc
 -								) - 1)) ==
 -				 ps.ppd->lid)) {
 -			ruc_loopback(qp);
 -			return;
 -		}
 +	if ((qp->ibqp.qp_type == IB_QPT_RC ||
 +	     qp->ibqp.qp_type == IB_QPT_UC) &&
 +	    !loopback &&
 +	    (qp->remote_ah_attr.dlid & ~((1 << ps.ppd->lmc) - 1)) ==
 +	    ps.ppd->lid) {
 +		ruc_loopback(qp);
 +		return;
 +	}
 +
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +	if (qp->ibqp.qp_type == IB_QPT_RC)
  		make_req = hfi1_make_rc_req;
 -		timeout_int = (qp->timeout_jiffies);
 -		break;
 -	case IB_QPT_UC:
 -		if (!loopback && ((qp->remote_ah_attr.dlid & ~((1 << ps.ppd->lmc
 -								) - 1)) ==
 -				 ps.ppd->lid)) {
 -			ruc_loopback(qp);
 -			return;
 -		}
 +	else if (qp->ibqp.qp_type == IB_QPT_UC)
  		make_req = hfi1_make_uc_req;
 -		timeout_int = SEND_RESCHED_TIMEOUT;
 -		break;
 -	default:
 +	else
  		make_req = hfi1_make_ud_req;
 -		timeout_int = SEND_RESCHED_TIMEOUT;
 -	}
  
 +	spin_lock_irqsave(&qp->s_lock, flags);
++=======
+ 	spin_lock_irqsave(&qp->s_lock, ps.flags);
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags):drivers/staging/rdma/hfi1/ruc.c
  
  	/* Return if we are already busy processing a work request. */
  	if (!hfi1_send_ok(qp)) {
@@@ -854,23 -883,43 +863,58 @@@
  	do {
  		/* Check for a constructed packet to be sent. */
  		if (qp->s_hdrwords != 0) {
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
++=======
+ 			spin_unlock_irqrestore(&qp->s_lock, ps.flags);
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags):drivers/staging/rdma/hfi1/ruc.c
  			/*
  			 * If the packet cannot be sent now, return and
  			 * the send tasklet will be woken up later.
  			 */
  			if (hfi1_verbs_send(qp, &ps))
 -				return;
 +				break;
  			/* Record that s_hdr is empty. */
  			qp->s_hdrwords = 0;
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
++=======
+ 			/* allow other tasks to run */
+ 			if (unlikely(time_after(jiffies, timeout))) {
+ 				if (workqueue_congested(cpu,
+ 							ps.ppd->hfi1_wq)) {
+ 					spin_lock_irqsave(
+ 						&qp->s_lock,
+ 						ps.flags);
+ 					qp->s_flags &= ~RVT_S_BUSY;
+ 					hfi1_schedule_send(qp);
+ 					spin_unlock_irqrestore(
+ 						&qp->s_lock,
+ 						ps.flags);
+ 					this_cpu_inc(
+ 						*ps.ppd->dd->send_schedule);
+ 					return;
+ 				}
+ 				if (!irqs_disabled()) {
+ 					cond_resched();
+ 					this_cpu_inc(
+ 					   *ps.ppd->dd->send_schedule);
+ 				}
+ 				timeout = jiffies + (timeout_int) / 8;
+ 			}
+ 			spin_lock_irqsave(&qp->s_lock, ps.flags);
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags):drivers/staging/rdma/hfi1/ruc.c
  		}
 -	} while (make_req(qp, &ps));
  
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +		/* allow other tasks to run */
 +		if (unlikely(time_after(jiffies, timeout))) {
 +			cond_resched();
 +			ps.ppd->dd->verbs_dev.n_send_schedule++;
 +			timeout = jiffies + SEND_RESCHED_TIMEOUT;
 +		}
 +	} while (make_req(qp));
++=======
+ 	spin_unlock_irqrestore(&qp->s_lock, ps.flags);
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags):drivers/staging/rdma/hfi1/ruc.c
  }
  
  /*
diff --cc drivers/staging/hfi1/ud.c
index a7f67b0111da,1e503ad0bebb..000000000000
--- a/drivers/staging/hfi1/ud.c
+++ b/drivers/staging/hfi1/ud.c
@@@ -309,13 -314,15 +309,21 @@@ int hfi1_make_ud_req(struct hfi1_qp *qp
  	/* Construct the header. */
  	ibp = to_iport(qp->ibqp.device, qp->port_num);
  	ppd = ppd_from_ibp(ibp);
 -	ah_attr = &ibah_to_rvtah(wqe->ud_wr.ah)->attr;
 -	if (ah_attr->dlid < be16_to_cpu(IB_MULTICAST_LID_BASE) ||
 -	    ah_attr->dlid == be16_to_cpu(IB_LID_PERMISSIVE)) {
 +	ah_attr = &to_iah(wqe->wr.wr.ud.ah)->attr;
 +	if (ah_attr->dlid < HFI1_MULTICAST_LID_BASE ||
 +	    ah_attr->dlid == HFI1_PERMISSIVE_LID) {
  		lid = ah_attr->dlid & ~((1 << ppd->lmc) - 1);
++<<<<<<< HEAD:drivers/staging/hfi1/ud.c
 +		if (unlikely(!loopback && (lid == ppd->lid ||
 +		    (lid == HFI1_PERMISSIVE_LID &&
 +		     qp->ibqp.qp_type == IB_QPT_GSI)))) {
++=======
+ 		if (unlikely(!loopback &&
+ 			     (lid == ppd->lid ||
+ 			      (lid == be16_to_cpu(IB_LID_PERMISSIVE) &&
+ 			      qp->ibqp.qp_type == IB_QPT_GSI)))) {
+ 			unsigned long tflags = ps->flags;
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags):drivers/staging/rdma/hfi1/ud.c
  			/*
  			 * If DMAs are in progress, we can't generate
  			 * a completion for the loopback packet since
@@@ -328,11 -335,12 +336,16 @@@
  				goto bail;
  			}
  			qp->s_cur = next_cur;
++<<<<<<< HEAD:drivers/staging/hfi1/ud.c
 +			spin_unlock_irqrestore(&qp->s_lock, flags);
++=======
+ 			spin_unlock_irqrestore(&qp->s_lock, tflags);
++>>>>>>> 747f4d7a9d1b (IB/qib, IB/hfi1: Fix up UD loopback use of irq flags):drivers/staging/rdma/hfi1/ud.c
  			ud_loopback(qp, wqe);
- 			spin_lock_irqsave(&qp->s_lock, flags);
+ 			spin_lock_irqsave(&qp->s_lock, tflags);
+ 			ps->flags = tflags;
  			hfi1_send_complete(qp, wqe, IB_WC_SUCCESS);
 -			goto done_free_tx;
 +			goto done;
  		}
  	}
  
* Unmerged path drivers/staging/rdma/hfi1/verbs.h
* Unmerged path drivers/infiniband/hw/qib/qib_rc.c
* Unmerged path drivers/infiniband/hw/qib/qib_ruc.c
* Unmerged path drivers/infiniband/hw/qib/qib_uc.c
* Unmerged path drivers/infiniband/hw/qib/qib_ud.c
* Unmerged path drivers/infiniband/hw/qib/qib_verbs.h
* Unmerged path drivers/staging/hfi1/ruc.c
* Unmerged path drivers/staging/hfi1/ud.c
* Unmerged path drivers/staging/rdma/hfi1/verbs.h
