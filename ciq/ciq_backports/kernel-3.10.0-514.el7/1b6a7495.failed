sched/fair: Change "has_capacity" to "has_free_capacity"

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [kernel] sched: Change "has_capacity" to "has_free_capacity" (Jiri Olsa) [1211784]
Rebuild_FUZZ: 95.33%
commit-author Nicolas Pitre <nicolas.pitre@linaro.org>
commit 1b6a7495d343fcfe22ff3a8285544bb8e40f1920
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/1b6a7495.failed

The capacity of a CPU/group should be some intrinsic value that doesn't
change with task placement.  It is like a container which capacity is
stable regardless of the amount of liquid in it (its "utilization")...
unless the container itself is crushed that is, but that's another story.

Therefore let's rename "has_capacity" to "has_free_capacity" in order to
better convey the wanted meaning.

	Signed-off-by: Nicolas Pitre <nico@linaro.org>
	Signed-off-by: Peter Zijlstra <peterz@infradead.org>
	Cc: Vincent Guittot <vincent.guittot@linaro.org>
	Cc: Daniel Lezcano <daniel.lezcano@linaro.org>
	Cc: Morten Rasmussen <morten.rasmussen@arm.com>
	Cc: "Rafael J. Wysocki" <rjw@rjwysocki.net>
	Cc: linaro-kernel@lists.linaro.org
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: linux-kernel@vger.kernel.org
Link: http://lkml.kernel.org/n/tip-djzkk027jm0e8x8jxy70opzh@git.kernel.org
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 1b6a7495d343fcfe22ff3a8285544bb8e40f1920)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/fair.c
diff --cc kernel/sched/fair.c
index 0709f6bcbbf5,8993dfa2e82b..000000000000
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@@ -5825,10 -6028,16 +5825,15 @@@ static inline void update_sd_lb_stats(s
  		 * heaviest group when it is already under-utilized (possible
  		 * with a large weight task outweighs the tasks on the system).
  		 */
++<<<<<<< HEAD
 +		if (prefer_sibling && !local_group &&
 +				sds->this && sds->this_stat.group_has_capacity)
++=======
+ 		if (prefer_sibling && sds->local &&
+ 		    sds->local_stat.group_has_free_capacity)
++>>>>>>> 1b6a7495d343 (sched/fair: Change "has_capacity" to "has_free_capacity")
  			sgs->group_capacity = min(sgs->group_capacity, 1U);
  
 -		if (update_sd_pick_busiest(env, sds, sg, sgs)) {
 -			sds->busiest = sg;
 -			sds->busiest_stat = *sgs;
 -		}
 -
 -next_group:
  		/* Now, start updating sd_lb_stats */
  		sds->total_load += sgs->group_load;
  		sds->total_pwr += sgs->group_power;
@@@ -6094,8 -6289,8 +6099,13 @@@ static struct sched_group *find_busiest
  		goto force_balance;
  
  	/* SD_BALANCE_NEWIDLE trumps SMP nice when underutilized */
++<<<<<<< HEAD
 +	if (env->idle == CPU_NEWLY_IDLE && this->group_has_capacity &&
 +			!busiest->group_has_capacity)
++=======
+ 	if (env->idle == CPU_NEWLY_IDLE && local->group_has_free_capacity &&
+ 	    !busiest->group_has_free_capacity)
++>>>>>>> 1b6a7495d343 (sched/fair: Change "has_capacity" to "has_free_capacity")
  		goto force_balance;
  
  	/*
* Unmerged path kernel/sched/fair.c
