IB/hfi1: Fix adaptive pio packet corruption

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Mike Marciniszyn <mike.marciniszyn@intel.com>
commit 47177f1bac9ca2b65eefdc9b0b63d0505bd4e11e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/47177f1b.failed

The adaptive pio heuristic missed a case that causes a corrupted
packet on the wire.

The case is if SDMA egress had been chosen for a pio-able packet and
then encountered a ring space wait, the packet is queued.   The sge
cursor had been incremented as part of the packet build out for SDMA.

After the send engine restart, the heuristic might now chose pio based
on the sdma count being zero and start the mmio copy using the already
incremented sge cursor.

Fix this by forcing SDMA egress when the SDMA descriptor has already
been built.

Additionally, the code to wait for a QPs pio count to zero when
switching to SDMA was missing.  Add it.

There is also an issue with UD QPs, in that the different SLs can pick
a different egress send context.  For now, just insure the UD/GSI
always go through SDMA.

	Reviewed-by: Vennila Megavannan <vennila.megavannan@intel.com>
	Signed-off-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 47177f1bac9ca2b65eefdc9b0b63d0505bd4e11e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/staging/hfi1/verbs.c
diff --cc drivers/staging/hfi1/verbs.c
index d228eb7fc4f0,62755af693a2..000000000000
--- a/drivers/staging/hfi1/verbs.c
+++ b/drivers/staging/hfi1/verbs.c
@@@ -1302,6 -1173,49 +1302,52 @@@ bad
  }
  
  /**
++<<<<<<< HEAD:drivers/staging/hfi1/verbs.c
++=======
+  * get_send_routine - choose an egress routine
+  *
+  * Choose an egress routine based on QP type
+  * and size
+  */
+ static inline send_routine get_send_routine(struct rvt_qp *qp,
+ 					    struct verbs_txreq *tx)
+ {
+ 	struct hfi1_devdata *dd = dd_from_ibdev(qp->ibqp.device);
+ 	struct hfi1_qp_priv *priv = qp->priv;
+ 	struct hfi1_ib_header *h = &tx->phdr.hdr;
+ 
+ 	if (unlikely(!(dd->flags & HFI1_HAS_SEND_DMA)))
+ 		return dd->process_pio_send;
+ 	switch (qp->ibqp.qp_type) {
+ 	case IB_QPT_SMI:
+ 		return dd->process_pio_send;
+ 	case IB_QPT_GSI:
+ 	case IB_QPT_UD:
+ 		break;
+ 	case IB_QPT_RC:
+ 		if (piothreshold &&
+ 		    qp->s_cur_size <= min(piothreshold, qp->pmtu) &&
+ 		    (BIT(get_opcode(h) & 0x1f) & rc_only_opcode) &&
+ 		    iowait_sdma_pending(&priv->s_iowait) == 0 &&
+ 		    !sdma_txreq_built(&tx->txreq))
+ 			return dd->process_pio_send;
+ 		break;
+ 	case IB_QPT_UC:
+ 		if (piothreshold &&
+ 		    qp->s_cur_size <= min(piothreshold, qp->pmtu) &&
+ 		    (BIT(get_opcode(h) & 0x1f) & uc_only_opcode) &&
+ 		    iowait_sdma_pending(&priv->s_iowait) == 0 &&
+ 		    !sdma_txreq_built(&tx->txreq))
+ 			return dd->process_pio_send;
+ 		break;
+ 	default:
+ 		break;
+ 	}
+ 	return dd->process_dma_send;
+ }
+ 
+ /**
++>>>>>>> 47177f1bac9c (IB/hfi1: Fix adaptive pio packet corruption):drivers/staging/rdma/hfi1/verbs.c
   * hfi1_verbs_send - send a packet
   * @qp: the QP to send on
   * @ps: the state of the packet to send
@@@ -1313,21 -1227,11 +1359,30 @@@ int hfi1_verbs_send(struct hfi1_qp *qp
  {
  	struct hfi1_devdata *dd = dd_from_ibdev(qp->ibqp.device);
  	struct hfi1_qp_priv *priv = qp->priv;
++<<<<<<< HEAD:drivers/staging/hfi1/verbs.c
 +	struct ahg_ib_header *ahdr = priv->s_hdr;
++=======
+ 	send_routine sr;
++>>>>>>> 47177f1bac9c (IB/hfi1: Fix adaptive pio packet corruption):drivers/staging/rdma/hfi1/verbs.c
  	int ret;
 +	int pio = 0;
 +	unsigned long flags = 0;
 +
++<<<<<<< HEAD:drivers/staging/hfi1/verbs.c
 +	/*
 +	 * VL15 packets (IB_QPT_SMI) will always use PIO, so we
 +	 * can defer SDMA restart until link goes ACTIVE without
 +	 * worrying about just how we got there.
 +	 */
 +	if ((qp->ibqp.qp_type == IB_QPT_SMI) ||
 +	    !(dd->flags & HFI1_HAS_SEND_DMA))
 +		pio = 1;
  
 +	ret = egress_pkey_check(dd->pport, &ahdr->ibh, qp);
++=======
+ 	sr = get_send_routine(qp, ps->s_txreq);
+ 	ret = egress_pkey_check(dd->pport, &ps->s_txreq->phdr.hdr, qp);
++>>>>>>> 47177f1bac9c (IB/hfi1: Fix adaptive pio packet corruption):drivers/staging/rdma/hfi1/verbs.c
  	if (unlikely(ret)) {
  		/*
  		 * The value we are returning here does not get propagated to
@@@ -1346,71 -1252,57 +1401,80 @@@
  		}
  		return -EINVAL;
  	}
++<<<<<<< HEAD:drivers/staging/hfi1/verbs.c
 +
 +	if (pio) {
 +		ret = dd->process_pio_send(qp, ps, 0);
 +	} else {
 +#ifdef CONFIG_SDMA_VERBOSITY
 +		dd_dev_err(dd, "CONFIG SDMA %s:%d %s()\n",
 +			   slashstrip(__FILE__), __LINE__, __func__);
 +		dd_dev_err(dd, "SDMA hdrwords = %u, len = %u\n", qp->s_hdrwords,
 +			   qp->s_cur_size);
 +#endif
 +		ret = dd->process_dma_send(qp, ps, 0);
 +	}
 +
 +	return ret;
++=======
+ 	if (sr == dd->process_dma_send && iowait_pio_pending(&priv->s_iowait))
+ 		return pio_wait(qp,
+ 				ps->s_txreq->psc,
+ 				ps,
+ 				RVT_S_WAIT_PIO_DRAIN);
+ 	return sr(qp, ps, 0);
++>>>>>>> 47177f1bac9c (IB/hfi1: Fix adaptive pio packet corruption):drivers/staging/rdma/hfi1/verbs.c
  }
  
 -/**
 - * hfi1_fill_device_attr - Fill in rvt dev info device attributes.
 - * @dd: the device data structure
 - */
 -static void hfi1_fill_device_attr(struct hfi1_devdata *dd)
 +static int query_device(struct ib_device *ibdev,
 +			struct ib_device_attr *props,
 +			struct ib_udata *uhw)
  {
 -	struct rvt_dev_info *rdi = &dd->verbs_dev.rdi;
 -
 -	memset(&rdi->dparms.props, 0, sizeof(rdi->dparms.props));
 -
 -	rdi->dparms.props.device_cap_flags = IB_DEVICE_BAD_PKEY_CNTR |
 -			IB_DEVICE_BAD_QKEY_CNTR | IB_DEVICE_SHUTDOWN_PORT |
 -			IB_DEVICE_SYS_IMAGE_GUID | IB_DEVICE_RC_RNR_NAK_GEN |
 -			IB_DEVICE_PORT_ACTIVE_EVENT | IB_DEVICE_SRQ_RESIZE;
 -	rdi->dparms.props.page_size_cap = PAGE_SIZE;
 -	rdi->dparms.props.vendor_id = dd->oui1 << 16 | dd->oui2 << 8 | dd->oui3;
 -	rdi->dparms.props.vendor_part_id = dd->pcidev->device;
 -	rdi->dparms.props.hw_ver = dd->minrev;
 -	rdi->dparms.props.sys_image_guid = ib_hfi1_sys_image_guid;
 -	rdi->dparms.props.max_mr_size = ~0ULL;
 -	rdi->dparms.props.max_qp = hfi1_max_qps;
 -	rdi->dparms.props.max_qp_wr = hfi1_max_qp_wrs;
 -	rdi->dparms.props.max_sge = hfi1_max_sges;
 -	rdi->dparms.props.max_sge_rd = hfi1_max_sges;
 -	rdi->dparms.props.max_cq = hfi1_max_cqs;
 -	rdi->dparms.props.max_ah = hfi1_max_ahs;
 -	rdi->dparms.props.max_cqe = hfi1_max_cqes;
 -	rdi->dparms.props.max_mr = rdi->lkey_table.max;
 -	rdi->dparms.props.max_fmr = rdi->lkey_table.max;
 -	rdi->dparms.props.max_map_per_fmr = 32767;
 -	rdi->dparms.props.max_pd = hfi1_max_pds;
 -	rdi->dparms.props.max_qp_rd_atom = HFI1_MAX_RDMA_ATOMIC;
 -	rdi->dparms.props.max_qp_init_rd_atom = 255;
 -	rdi->dparms.props.max_srq = hfi1_max_srqs;
 -	rdi->dparms.props.max_srq_wr = hfi1_max_srq_wrs;
 -	rdi->dparms.props.max_srq_sge = hfi1_max_srq_sges;
 -	rdi->dparms.props.atomic_cap = IB_ATOMIC_GLOB;
 -	rdi->dparms.props.max_pkeys = hfi1_get_npkeys(dd);
 -	rdi->dparms.props.max_mcast_grp = hfi1_max_mcast_grps;
 -	rdi->dparms.props.max_mcast_qp_attach = hfi1_max_mcast_qp_attached;
 -	rdi->dparms.props.max_total_mcast_qp_attach =
 -					rdi->dparms.props.max_mcast_qp_attach *
 -					rdi->dparms.props.max_mcast_grp;
 +	struct hfi1_devdata *dd = dd_from_ibdev(ibdev);
 +	struct hfi1_ibdev *dev = to_idev(ibdev);
 +
 +	if (uhw->inlen || uhw->outlen)
 +		return -EINVAL;
 +	memset(props, 0, sizeof(*props));
 +
 +	props->device_cap_flags = IB_DEVICE_BAD_PKEY_CNTR |
 +		IB_DEVICE_BAD_QKEY_CNTR | IB_DEVICE_SHUTDOWN_PORT |
 +		IB_DEVICE_SYS_IMAGE_GUID | IB_DEVICE_RC_RNR_NAK_GEN |
 +		IB_DEVICE_PORT_ACTIVE_EVENT | IB_DEVICE_SRQ_RESIZE;
 +
 +	props->page_size_cap = PAGE_SIZE;
 +	props->vendor_id =
 +		dd->oui1 << 16 | dd->oui2 << 8 | dd->oui3;
 +	props->vendor_part_id = dd->pcidev->device;
 +	props->hw_ver = dd->minrev;
 +	props->sys_image_guid = ib_hfi1_sys_image_guid;
 +	props->max_mr_size = ~0ULL;
 +	props->max_qp = hfi1_max_qps;
 +	props->max_qp_wr = hfi1_max_qp_wrs;
 +	props->max_sge = hfi1_max_sges;
 +	props->max_sge_rd = hfi1_max_sges;
 +	props->max_cq = hfi1_max_cqs;
 +	props->max_ah = hfi1_max_ahs;
 +	props->max_cqe = hfi1_max_cqes;
 +	props->max_mr = dev->lk_table.max;
 +	props->max_fmr = dev->lk_table.max;
 +	props->max_map_per_fmr = 32767;
 +	props->max_pd = dev->rdi.dparms.props.max_pd;
 +	props->max_qp_rd_atom = HFI1_MAX_RDMA_ATOMIC;
 +	props->max_qp_init_rd_atom = 255;
 +	/* props->max_res_rd_atom */
 +	props->max_srq = hfi1_max_srqs;
 +	props->max_srq_wr = hfi1_max_srq_wrs;
 +	props->max_srq_sge = hfi1_max_srq_sges;
 +	/* props->local_ca_ack_delay */
 +	props->atomic_cap = IB_ATOMIC_GLOB;
 +	props->max_pkeys = hfi1_get_npkeys(dd);
 +	props->max_mcast_grp = hfi1_max_mcast_grps;
 +	props->max_mcast_qp_attach = hfi1_max_mcast_qp_attached;
 +	props->max_total_mcast_qp_attach = props->max_mcast_qp_attach *
 +		props->max_mcast_grp;
 +
 +	return 0;
  }
  
  static inline u16 opa_speed_to_ib(u16 in)
* Unmerged path drivers/staging/hfi1/verbs.c
