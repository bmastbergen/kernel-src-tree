i40e/i40evf: Add support for IPIP and SIT offloads

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Alexander Duyck <aduyck@mirantis.com>
commit 577389a5db766c44400e75e6a79f39d9b0d585f8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/577389a5.failed

Looking over the documentation it turns out enabling IPIP and SIT offloads
for i40e is pretty straightforward.  As such I decided to enable them with
this patch.  In my testing I am seeing an improvement of 8 to 10 Gb/s
for IPIP and SIT tunnels with this offload enabled.

	Signed-off-by: Alexander Duyck <aduyck@mirantis.com>
	Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
	Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
(cherry picked from commit 577389a5db766c44400e75e6a79f39d9b0d585f8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/i40e/i40e_main.c
#	drivers/net/ethernet/intel/i40e/i40e_txrx.c
#	drivers/net/ethernet/intel/i40evf/i40e_txrx.c
#	drivers/net/ethernet/intel/i40evf/i40evf_main.c
diff --cc drivers/net/ethernet/intel/i40e/i40e_main.c
index cb15db324c14,ec94ad6c783a..000000000000
--- a/drivers/net/ethernet/intel/i40e/i40e_main.c
+++ b/drivers/net/ethernet/intel/i40e/i40e_main.c
@@@ -9021,40 -9111,38 +9021,59 @@@ static int i40e_config_netdev(struct i4
  	np = netdev_priv(netdev);
  	np->vsi = vsi;
  
++<<<<<<< HEAD
 +	netdev->hw_enc_features |= NETIF_F_IP_CSUM	       |
 +				   NETIF_F_IPV6_CSUM	       |
 +				   NETIF_F_TSO		       |
 +				   NETIF_F_TSO6		       |
 +				   NETIF_F_TSO_ECN	       |
 +				   NETIF_F_GSO_GRE	       |
 +				   NETIF_F_GSO_UDP_TUNNEL      |
 +				   NETIF_F_GSO_UDP_TUNNEL_CSUM |
++=======
+ 	netdev->hw_enc_features |= NETIF_F_SG			|
+ 				   NETIF_F_IP_CSUM		|
+ 				   NETIF_F_IPV6_CSUM		|
+ 				   NETIF_F_HIGHDMA		|
+ 				   NETIF_F_SOFT_FEATURES	|
+ 				   NETIF_F_TSO			|
+ 				   NETIF_F_TSO_ECN		|
+ 				   NETIF_F_TSO6			|
+ 				   NETIF_F_GSO_GRE		|
+ 				   NETIF_F_GSO_IPIP		|
+ 				   NETIF_F_GSO_SIT		|
+ 				   NETIF_F_GSO_UDP_TUNNEL	|
+ 				   NETIF_F_GSO_UDP_TUNNEL_CSUM	|
+ 				   NETIF_F_SCTP_CRC		|
+ 				   NETIF_F_RXHASH		|
+ 				   NETIF_F_RXCSUM		|
++>>>>>>> 577389a5db76 (i40e/i40evf: Add support for IPIP and SIT offloads)
  				   0;
  
 -	if (!(pf->flags & I40E_FLAG_OUTER_UDP_CSUM_CAPABLE))
 -		netdev->hw_enc_features ^= NETIF_F_GSO_UDP_TUNNEL_CSUM;
 -
 -	/* record features VLANs can make use of */
 -	netdev->vlan_features |= netdev->hw_enc_features;
 +	netdev->features = NETIF_F_SG		       |
 +			   NETIF_F_IP_CSUM	       |
 +			   NETIF_F_SCTP_CSUM	       |
 +			   NETIF_F_HIGHDMA	       |
 +			   NETIF_F_GSO_UDP_TUNNEL      |
 +			   NETIF_F_GSO_GRE	       |
 +			   NETIF_F_HW_VLAN_CTAG_TX     |
 +			   NETIF_F_HW_VLAN_CTAG_RX     |
 +			   NETIF_F_HW_VLAN_CTAG_FILTER |
 +			   NETIF_F_IPV6_CSUM	       |
 +			   NETIF_F_TSO		       |
 +			   NETIF_F_TSO_ECN	       |
 +			   NETIF_F_TSO6		       |
 +			   NETIF_F_RXCSUM	       |
 +			   NETIF_F_RXHASH	       |
 +			   0;
  
  	if (!(pf->flags & I40E_FLAG_MFP_ENABLED))
 -		netdev->hw_features |= NETIF_F_NTUPLE;
 -
 -	netdev->hw_features |= netdev->hw_enc_features	|
 -			       NETIF_F_HW_VLAN_CTAG_TX	|
 -			       NETIF_F_HW_VLAN_CTAG_RX;
 +		netdev->features |= NETIF_F_NTUPLE;
 +	if (pf->flags & I40E_FLAG_OUTER_UDP_CSUM_CAPABLE)
 +		netdev->features |= NETIF_F_GSO_UDP_TUNNEL_CSUM;
  
 -	netdev->features |= netdev->hw_features | NETIF_F_HW_VLAN_CTAG_FILTER;
 +	/* copy netdev features into list of user selectable features */
 +	netdev->hw_features |= netdev->features;
  
  	if (vsi->type == I40E_VSI_MAIN) {
  		SET_NETDEV_DEV(netdev, &pf->pdev->dev);
diff --cc drivers/net/ethernet/intel/i40e/i40e_txrx.c
index 025ceb57680d,6e44cf118843..000000000000
--- a/drivers/net/ethernet/intel/i40e/i40e_txrx.c
+++ b/drivers/net/ethernet/intel/i40e/i40e_txrx.c
@@@ -2327,7 -2299,20 +2327,24 @@@ static int i40e_tso(struct sk_buff *skb
  		ip.v6->payload_len = 0;
  	}
  
++<<<<<<< HEAD
 +	if (skb_shinfo(skb)->gso_type & (SKB_GSO_UDP_TUNNEL | SKB_GSO_GRE)) {
++=======
+ 	if (skb_shinfo(skb)->gso_type & (SKB_GSO_GRE |
+ 					 SKB_GSO_IPIP |
+ 					 SKB_GSO_SIT |
+ 					 SKB_GSO_UDP_TUNNEL |
+ 					 SKB_GSO_UDP_TUNNEL_CSUM)) {
+ 		if (skb_shinfo(skb)->gso_type & SKB_GSO_UDP_TUNNEL_CSUM) {
+ 			/* determine offset of outer transport header */
+ 			l4_offset = l4.hdr - skb->data;
+ 
+ 			/* remove payload length from outer checksum */
+ 			paylen = skb->len - l4_offset;
+ 			csum_replace_by_diff(&l4.udp->check, htonl(paylen));
+ 		}
+ 
++>>>>>>> 577389a5db76 (i40e/i40evf: Add support for IPIP and SIT offloads)
  		/* reset pointers to inner headers */
  		ip.hdr = skb_inner_network_header(skb);
  		l4.hdr = skb_inner_transport_header(skb);
@@@ -2413,71 -2397,106 +2430,130 @@@ static int i40e_tsyn(struct i40e_ring *
   * @tx_ring: Tx descriptor ring
   * @cd_tunneling: ptr to context desc bits
   **/
 -static int i40e_tx_enable_csum(struct sk_buff *skb, u32 *tx_flags,
 -			       u32 *td_cmd, u32 *td_offset,
 -			       struct i40e_ring *tx_ring,
 -			       u32 *cd_tunneling)
 +static void i40e_tx_enable_csum(struct sk_buff *skb, u32 *tx_flags,
 +				u32 *td_cmd, u32 *td_offset,
 +				struct i40e_ring *tx_ring,
 +				u32 *cd_tunneling)
  {
 -	union {
 -		struct iphdr *v4;
 -		struct ipv6hdr *v6;
 -		unsigned char *hdr;
 -	} ip;
 -	union {
 -		struct tcphdr *tcp;
 -		struct udphdr *udp;
 -		unsigned char *hdr;
 -	} l4;
 -	unsigned char *exthdr;
 -	u32 offset, cmd = 0;
 -	__be16 frag_off;
 -	u8 l4_proto = 0;
 -
 -	if (skb->ip_summed != CHECKSUM_PARTIAL)
 -		return 0;
 -
 -	ip.hdr = skb_network_header(skb);
 -	l4.hdr = skb_transport_header(skb);
 -
 -	/* compute outer L2 header size */
 -	offset = ((ip.hdr - skb->data) / 2) << I40E_TX_DESC_LENGTH_MACLEN_SHIFT;
 +	struct ipv6hdr *this_ipv6_hdr;
 +	unsigned int this_tcp_hdrlen;
 +	struct iphdr *this_ip_hdr;
 +	u32 network_hdr_len;
 +	u8 l4_hdr = 0;
 +	u32 l4_tunnel = 0;
  
  	if (skb->encapsulation) {
++<<<<<<< HEAD
 +		switch (ip_hdr(skb)->protocol) {
++=======
+ 		u32 tunnel = 0;
+ 		/* define outer network header type */
+ 		if (*tx_flags & I40E_TX_FLAGS_IPV4) {
+ 			tunnel |= (*tx_flags & I40E_TX_FLAGS_TSO) ?
+ 				  I40E_TX_CTX_EXT_IP_IPV4 :
+ 				  I40E_TX_CTX_EXT_IP_IPV4_NO_CSUM;
+ 
+ 			l4_proto = ip.v4->protocol;
+ 		} else if (*tx_flags & I40E_TX_FLAGS_IPV6) {
+ 			tunnel |= I40E_TX_CTX_EXT_IP_IPV6;
+ 
+ 			exthdr = ip.hdr + sizeof(*ip.v6);
+ 			l4_proto = ip.v6->nexthdr;
+ 			if (l4.hdr != exthdr)
+ 				ipv6_skip_exthdr(skb, exthdr - skb->data,
+ 						 &l4_proto, &frag_off);
+ 		}
+ 
+ 		/* define outer transport */
+ 		switch (l4_proto) {
++>>>>>>> 577389a5db76 (i40e/i40evf: Add support for IPIP and SIT offloads)
  		case IPPROTO_UDP:
 -			tunnel |= I40E_TXD_CTX_UDP_TUNNELING;
 +			l4_tunnel = I40E_TXD_CTX_UDP_TUNNELING;
  			*tx_flags |= I40E_TX_FLAGS_UDP_TUNNEL;
  			break;
  		case IPPROTO_GRE:
 -			tunnel |= I40E_TXD_CTX_GRE_TUNNELING;
 -			*tx_flags |= I40E_TX_FLAGS_UDP_TUNNEL;
 +			l4_tunnel = I40E_TXD_CTX_GRE_TUNNELING;
  			break;
+ 		case IPPROTO_IPIP:
+ 		case IPPROTO_IPV6:
+ 			*tx_flags |= I40E_TX_FLAGS_UDP_TUNNEL;
+ 			l4.hdr = skb_inner_network_header(skb);
+ 			break;
  		default:
 -			if (*tx_flags & I40E_TX_FLAGS_TSO)
 -				return -1;
 +			return;
 +		}
 +		network_hdr_len = skb_inner_network_header_len(skb);
 +		this_ip_hdr = inner_ip_hdr(skb);
 +		this_ipv6_hdr = inner_ipv6_hdr(skb);
 +		this_tcp_hdrlen = inner_tcp_hdrlen(skb);
  
 -			skb_checksum_help(skb);
 -			return 0;
 +		if (*tx_flags & I40E_TX_FLAGS_IPV4) {
 +			if (*tx_flags & I40E_TX_FLAGS_TSO) {
 +				*cd_tunneling |= I40E_TX_CTX_EXT_IP_IPV4;
 +			} else {
 +				*cd_tunneling |=
 +					 I40E_TX_CTX_EXT_IP_IPV4_NO_CSUM;
 +			}
 +		} else if (*tx_flags & I40E_TX_FLAGS_IPV6) {
 +			*cd_tunneling |= I40E_TX_CTX_EXT_IP_IPV6;
  		}
  
++<<<<<<< HEAD
 +		/* Now set the ctx descriptor fields */
 +		*cd_tunneling |= (skb_network_header_len(skb) >> 2) <<
 +				   I40E_TXD_CTX_QW0_EXT_IPLEN_SHIFT      |
 +				   l4_tunnel                             |
 +				   ((skb_inner_network_offset(skb) -
 +					skb_transport_offset(skb)) >> 1) <<
 +				   I40E_TXD_CTX_QW0_NATLEN_SHIFT;
 +		if (this_ip_hdr->version == 6) {
 +			*tx_flags &= ~I40E_TX_FLAGS_IPV4;
++=======
+ 		/* compute outer L3 header size */
+ 		tunnel |= ((l4.hdr - ip.hdr) / 4) <<
+ 			  I40E_TXD_CTX_QW0_EXT_IPLEN_SHIFT;
+ 
+ 		/* switch IP header pointer from outer to inner header */
+ 		ip.hdr = skb_inner_network_header(skb);
+ 
+ 		/* compute tunnel header size */
+ 		tunnel |= ((ip.hdr - l4.hdr) / 2) <<
+ 			  I40E_TXD_CTX_QW0_NATLEN_SHIFT;
+ 
+ 		/* indicate if we need to offload outer UDP header */
+ 		if ((*tx_flags & I40E_TX_FLAGS_TSO) &&
+ 		    (skb_shinfo(skb)->gso_type & SKB_GSO_UDP_TUNNEL_CSUM))
+ 			tunnel |= I40E_TXD_CTX_QW0_L4T_CS_MASK;
+ 
+ 		/* record tunnel offload values */
+ 		*cd_tunneling |= tunnel;
+ 
+ 		/* switch L4 header pointer from outer to inner */
+ 		l4.hdr = skb_inner_transport_header(skb);
+ 		l4_proto = 0;
+ 
+ 		/* reset type as we transition from outer to inner headers */
+ 		*tx_flags &= ~(I40E_TX_FLAGS_IPV4 | I40E_TX_FLAGS_IPV6);
+ 		if (ip.v4->version == 4)
+ 			*tx_flags |= I40E_TX_FLAGS_IPV4;
+ 		if (ip.v6->version == 6)
++>>>>>>> 577389a5db76 (i40e/i40evf: Add support for IPIP and SIT offloads)
  			*tx_flags |= I40E_TX_FLAGS_IPV6;
 +		}
 +		if ((tx_ring->flags & I40E_TXR_FLAGS_OUTER_UDP_CSUM) &&
 +		    (l4_tunnel == I40E_TXD_CTX_UDP_TUNNELING)        &&
 +		    (*cd_tunneling & I40E_TXD_CTX_QW0_EXT_IP_MASK)) {
 +			oudph->check = ~csum_tcpudp_magic(oiph->saddr,
 +					oiph->daddr,
 +					(skb->len - skb_transport_offset(skb)),
 +					IPPROTO_UDP, 0);
 +			*cd_tunneling |= I40E_TXD_CTX_QW0_L4T_CS_MASK;
 +		}
 +	} else {
 +		network_hdr_len = skb_network_header_len(skb);
 +		this_ip_hdr = ip_hdr(skb);
 +		this_ipv6_hdr = ipv6_hdr(skb);
 +		this_tcp_hdrlen = tcp_hdrlen(skb);
  	}
  
  	/* Enable IP checksum offloads */
diff --cc drivers/net/ethernet/intel/i40evf/i40e_txrx.c
index 0c3ce26cb67a,f101895ecf4a..000000000000
--- a/drivers/net/ethernet/intel/i40evf/i40e_txrx.c
+++ b/drivers/net/ethernet/intel/i40evf/i40e_txrx.c
@@@ -1578,7 -1564,20 +1578,24 @@@ static int i40e_tso(struct sk_buff *skb
  		ip.v6->payload_len = 0;
  	}
  
++<<<<<<< HEAD
 +	if (skb_shinfo(skb)->gso_type & (SKB_GSO_UDP_TUNNEL | SKB_GSO_GRE)) {
++=======
+ 	if (skb_shinfo(skb)->gso_type & (SKB_GSO_GRE |
+ 					 SKB_GSO_IPIP |
+ 					 SKB_GSO_SIT |
+ 					 SKB_GSO_UDP_TUNNEL |
+ 					 SKB_GSO_UDP_TUNNEL_CSUM)) {
+ 		if (skb_shinfo(skb)->gso_type & SKB_GSO_UDP_TUNNEL_CSUM) {
+ 			/* determine offset of outer transport header */
+ 			l4_offset = l4.hdr - skb->data;
+ 
+ 			/* remove payload length from outer checksum */
+ 			paylen = skb->len - l4_offset;
+ 			csum_replace_by_diff(&l4.udp->check, htonl(paylen));
+ 		}
+ 
++>>>>>>> 577389a5db76 (i40e/i40evf: Add support for IPIP and SIT offloads)
  		/* reset pointers to inner headers */
  		ip.hdr = skb_inner_network_header(skb);
  		l4.hdr = skb_inner_transport_header(skb);
@@@ -1619,72 -1617,109 +1636,131 @@@
   * @tx_flags: pointer to Tx flags currently set
   * @td_cmd: Tx descriptor command bits to set
   * @td_offset: Tx descriptor header offsets to set
 - * @tx_ring: Tx descriptor ring
   * @cd_tunneling: ptr to context desc bits
   **/
 -static int i40e_tx_enable_csum(struct sk_buff *skb, u32 *tx_flags,
 -			       u32 *td_cmd, u32 *td_offset,
 -			       struct i40e_ring *tx_ring,
 -			       u32 *cd_tunneling)
 +static void i40e_tx_enable_csum(struct sk_buff *skb, u32 *tx_flags,
 +				u32 *td_cmd, u32 *td_offset,
 +				struct i40e_ring *tx_ring,
 +				u32 *cd_tunneling)
  {
 -	union {
 -		struct iphdr *v4;
 -		struct ipv6hdr *v6;
 -		unsigned char *hdr;
 -	} ip;
 -	union {
 -		struct tcphdr *tcp;
 -		struct udphdr *udp;
 -		unsigned char *hdr;
 -	} l4;
 -	unsigned char *exthdr;
 -	u32 offset, cmd = 0;
 -	__be16 frag_off;
 -	u8 l4_proto = 0;
 -
 -	if (skb->ip_summed != CHECKSUM_PARTIAL)
 -		return 0;
 -
 -	ip.hdr = skb_network_header(skb);
 -	l4.hdr = skb_transport_header(skb);
 -
 -	/* compute outer L2 header size */
 -	offset = ((ip.hdr - skb->data) / 2) << I40E_TX_DESC_LENGTH_MACLEN_SHIFT;
 +	struct ipv6hdr *this_ipv6_hdr;
 +	unsigned int this_tcp_hdrlen;
 +	struct iphdr *this_ip_hdr;
 +	u32 network_hdr_len;
 +	u8 l4_hdr = 0;
 +	u32 l4_tunnel = 0;
  
  	if (skb->encapsulation) {
++<<<<<<< HEAD
 +		switch (ip_hdr(skb)->protocol) {
++=======
+ 		u32 tunnel = 0;
+ 		/* define outer network header type */
+ 		if (*tx_flags & I40E_TX_FLAGS_IPV4) {
+ 			tunnel |= (*tx_flags & I40E_TX_FLAGS_TSO) ?
+ 				  I40E_TX_CTX_EXT_IP_IPV4 :
+ 				  I40E_TX_CTX_EXT_IP_IPV4_NO_CSUM;
+ 
+ 			l4_proto = ip.v4->protocol;
+ 		} else if (*tx_flags & I40E_TX_FLAGS_IPV6) {
+ 			tunnel |= I40E_TX_CTX_EXT_IP_IPV6;
+ 
+ 			exthdr = ip.hdr + sizeof(*ip.v6);
+ 			l4_proto = ip.v6->nexthdr;
+ 			if (l4.hdr != exthdr)
+ 				ipv6_skip_exthdr(skb, exthdr - skb->data,
+ 						 &l4_proto, &frag_off);
+ 		}
+ 
+ 		/* define outer transport */
+ 		switch (l4_proto) {
++>>>>>>> 577389a5db76 (i40e/i40evf: Add support for IPIP and SIT offloads)
  		case IPPROTO_UDP:
 -			tunnel |= I40E_TXD_CTX_UDP_TUNNELING;
 -			*tx_flags |= I40E_TX_FLAGS_VXLAN_TUNNEL;
 -			break;
 -		case IPPROTO_GRE:
 -			tunnel |= I40E_TXD_CTX_GRE_TUNNELING;
 +			l4_tunnel = I40E_TXD_CTX_UDP_TUNNELING;
  			*tx_flags |= I40E_TX_FLAGS_VXLAN_TUNNEL;
  			break;
+ 		case IPPROTO_IPIP:
+ 		case IPPROTO_IPV6:
+ 			*tx_flags |= I40E_TX_FLAGS_VXLAN_TUNNEL;
+ 			l4.hdr = skb_inner_network_header(skb);
+ 			break;
  		default:
 -			if (*tx_flags & I40E_TX_FLAGS_TSO)
 -				return -1;
 +			return;
 +		}
 +		network_hdr_len = skb_inner_network_header_len(skb);
 +		this_ip_hdr = inner_ip_hdr(skb);
 +		this_ipv6_hdr = inner_ipv6_hdr(skb);
 +		this_tcp_hdrlen = inner_tcp_hdrlen(skb);
  
 -			skb_checksum_help(skb);
 -			return 0;
 +		if (*tx_flags & I40E_TX_FLAGS_IPV4) {
 +			if (*tx_flags & I40E_TX_FLAGS_TSO) {
 +				*cd_tunneling |= I40E_TX_CTX_EXT_IP_IPV4;
 +			} else {
 +				*cd_tunneling |=
 +					 I40E_TX_CTX_EXT_IP_IPV4_NO_CSUM;
 +			}
 +		} else if (*tx_flags & I40E_TX_FLAGS_IPV6) {
 +			*cd_tunneling |= I40E_TX_CTX_EXT_IP_IPV6;
  		}
  
++<<<<<<< HEAD
 +		/* Now set the ctx descriptor fields */
 +		*cd_tunneling |= (skb_network_header_len(skb) >> 2) <<
 +				   I40E_TXD_CTX_QW0_EXT_IPLEN_SHIFT      |
 +				   l4_tunnel                             |
 +				   ((skb_inner_network_offset(skb) -
 +					skb_transport_offset(skb)) >> 1) <<
 +				   I40E_TXD_CTX_QW0_NATLEN_SHIFT;
 +		if (this_ip_hdr->version == 6) {
 +			*tx_flags &= ~I40E_TX_FLAGS_IPV4;
++=======
+ 		/* compute outer L3 header size */
+ 		tunnel |= ((l4.hdr - ip.hdr) / 4) <<
+ 			  I40E_TXD_CTX_QW0_EXT_IPLEN_SHIFT;
+ 
+ 		/* switch IP header pointer from outer to inner header */
+ 		ip.hdr = skb_inner_network_header(skb);
+ 
+ 		/* compute tunnel header size */
+ 		tunnel |= ((ip.hdr - l4.hdr) / 2) <<
+ 			  I40E_TXD_CTX_QW0_NATLEN_SHIFT;
+ 
+ 		/* indicate if we need to offload outer UDP header */
+ 		if ((*tx_flags & I40E_TX_FLAGS_TSO) &&
+ 		    (skb_shinfo(skb)->gso_type & SKB_GSO_UDP_TUNNEL_CSUM))
+ 			tunnel |= I40E_TXD_CTX_QW0_L4T_CS_MASK;
+ 
+ 		/* record tunnel offload values */
+ 		*cd_tunneling |= tunnel;
+ 
+ 		/* switch L4 header pointer from outer to inner */
+ 		l4.hdr = skb_inner_transport_header(skb);
+ 		l4_proto = 0;
+ 
+ 		/* reset type as we transition from outer to inner headers */
+ 		*tx_flags &= ~(I40E_TX_FLAGS_IPV4 | I40E_TX_FLAGS_IPV6);
+ 		if (ip.v4->version == 4)
+ 			*tx_flags |= I40E_TX_FLAGS_IPV4;
+ 		if (ip.v6->version == 6)
++>>>>>>> 577389a5db76 (i40e/i40evf: Add support for IPIP and SIT offloads)
  			*tx_flags |= I40E_TX_FLAGS_IPV6;
 +		}
 +
 +
 +		if ((tx_ring->flags & I40E_TXR_FLAGS_OUTER_UDP_CSUM) &&
 +		    (l4_tunnel == I40E_TXD_CTX_UDP_TUNNELING)        &&
 +		    (*cd_tunneling & I40E_TXD_CTX_QW0_EXT_IP_MASK)) {
 +			oudph->check = ~csum_tcpudp_magic(oiph->saddr,
 +					oiph->daddr,
 +					(skb->len - skb_transport_offset(skb)),
 +					IPPROTO_UDP, 0);
 +			*cd_tunneling |= I40E_TXD_CTX_QW0_L4T_CS_MASK;
 +		}
 +	} else {
 +		network_hdr_len = skb_network_header_len(skb);
 +		this_ip_hdr = ip_hdr(skb);
 +		this_ipv6_hdr = ipv6_hdr(skb);
 +		this_tcp_hdrlen = tcp_hdrlen(skb);
  	}
  
  	/* Enable IP checksum offloads */
diff --cc drivers/net/ethernet/intel/i40evf/i40evf_main.c
index 983394dab5a6,806da2686623..000000000000
--- a/drivers/net/ethernet/intel/i40evf/i40evf_main.c
+++ b/drivers/net/ethernet/intel/i40evf/i40evf_main.c
@@@ -2329,40 -2337,40 +2329,60 @@@ int i40evf_process_config(struct i40evf
  		return -ENODEV;
  	}
  
++<<<<<<< HEAD
 +	netdev->features |= NETIF_F_HIGHDMA |
 +			    NETIF_F_SG |
 +			    NETIF_F_IP_CSUM |
 +			    NETIF_F_SCTP_CSUM |
 +			    NETIF_F_IPV6_CSUM |
 +			    NETIF_F_TSO |
 +			    NETIF_F_TSO6 |
 +			    NETIF_F_TSO_ECN |
 +			    NETIF_F_GSO_GRE |
 +			    NETIF_F_GSO_UDP_TUNNEL |
 +			    NETIF_F_RXCSUM |
 +			    NETIF_F_GRO;
++=======
+ 	netdev->hw_enc_features |= NETIF_F_SG			|
+ 				   NETIF_F_IP_CSUM		|
+ 				   NETIF_F_IPV6_CSUM		|
+ 				   NETIF_F_HIGHDMA		|
+ 				   NETIF_F_SOFT_FEATURES	|
+ 				   NETIF_F_TSO			|
+ 				   NETIF_F_TSO_ECN		|
+ 				   NETIF_F_TSO6			|
+ 				   NETIF_F_GSO_GRE		|
+ 				   NETIF_F_GSO_IPIP		|
+ 				   NETIF_F_GSO_SIT		|
+ 				   NETIF_F_GSO_UDP_TUNNEL	|
+ 				   NETIF_F_GSO_UDP_TUNNEL_CSUM	|
+ 				   NETIF_F_SCTP_CRC		|
+ 				   NETIF_F_RXHASH		|
+ 				   NETIF_F_RXCSUM		|
+ 				   0;
++>>>>>>> 577389a5db76 (i40e/i40evf: Add support for IPIP and SIT offloads)
  
 -	if (!(adapter->flags & I40EVF_FLAG_OUTER_UDP_CSUM_CAPABLE))
 -		netdev->hw_enc_features ^= NETIF_F_GSO_UDP_TUNNEL_CSUM;
 +	netdev->hw_enc_features |= NETIF_F_IP_CSUM	       |
 +				   NETIF_F_IPV6_CSUM	       |
 +				   NETIF_F_TSO		       |
 +				   NETIF_F_TSO6		       |
 +				   NETIF_F_TSO_ECN	       |
 +				   NETIF_F_GSO_GRE	       |
 +				   NETIF_F_GSO_UDP_TUNNEL      |
 +				   NETIF_F_GSO_UDP_TUNNEL_CSUM;
  
 -	/* record features VLANs can make use of */
 -	netdev->vlan_features |= netdev->hw_enc_features;
 +	if (adapter->flags & I40EVF_FLAG_OUTER_UDP_CSUM_CAPABLE)
 +		netdev->features |= NETIF_F_GSO_UDP_TUNNEL_CSUM;
  
 -	/* Write features and hw_features separately to avoid polluting
 -	 * with, or dropping, features that are set when we registgered.
 -	 */
 -	netdev->hw_features |= netdev->hw_enc_features;
 -
 -	netdev->features |= netdev->hw_enc_features | I40EVF_VLAN_FEATURES;
 +	/* always clear VLAN features because they can change at every reset */
 +	netdev->features &= ~(I40EVF_VLAN_FEATURES);
 +	/* copy netdev features into list of user selectable features */
 +	netdev->hw_features |= netdev->features;
  
 -	/* disable VLAN features if not supported */
 -	if (!(vfres->vf_offload_flags & I40E_VIRTCHNL_VF_OFFLOAD_VLAN))
 -		netdev->features ^= I40EVF_VLAN_FEATURES;
 +	if (vfres->vf_offload_flags & I40E_VIRTCHNL_VF_OFFLOAD_VLAN) {
 +		netdev->vlan_features = netdev->features;
 +		netdev->features |= I40EVF_VLAN_FEATURES;
 +	}
  
  	adapter->vsi.id = adapter->vsi_res->vsi_id;
  
* Unmerged path drivers/net/ethernet/intel/i40e/i40e_main.c
* Unmerged path drivers/net/ethernet/intel/i40e/i40e_txrx.c
* Unmerged path drivers/net/ethernet/intel/i40evf/i40e_txrx.c
* Unmerged path drivers/net/ethernet/intel/i40evf/i40evf_main.c
