mm/page_alloc.c: rework code layout in memmap_init_zone()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [mm] page_alloc.c: rework code layout in memmap_init_zone() (Yasuaki Ishimatsu) [1270209]
Rebuild_FUZZ: 97.30%
commit-author Andrew Morton <akpm@linux-foundation.org>
commit b72d0ffb5dbc4070089b36230b98687ca4577cbc
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/b72d0ffb.failed

This function is getting full of weird tricks to avoid word-wrapping.
Use a goto to eliminate a tab stop then use the new space

	Cc: Taku Izumi <izumi.taku@jp.fujitsu.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit b72d0ffb5dbc4070089b36230b98687ca4577cbc)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/page_alloc.c
diff --cc mm/page_alloc.c
index f60ded95bce9,fe4378fc0ab6..000000000000
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@@ -4014,26 -4499,60 +4014,70 @@@ void __meminit memmap_init_zone(unsigne
  	if (highest_memmap_pfn < end_pfn - 1)
  		highest_memmap_pfn = end_pfn - 1;
  
 -	/*
 -	 * Honor reservation requested by the driver for this ZONE_DEVICE
 -	 * memory
 -	 */
 -	if (altmap && start_pfn == altmap->base_pfn)
 -		start_pfn += altmap->reserve;
 -
 +	z = &NODE_DATA(nid)->node_zones[zone];
  	for (pfn = start_pfn; pfn < end_pfn; pfn++) {
  		/*
- 		 * There can be holes in boot-time mem_map[]s
- 		 * handed to this function.  They do not
- 		 * exist on hotplugged memory.
+ 		 * There can be holes in boot-time mem_map[]s handed to this
+ 		 * function.  They do not exist on hotplugged memory.
  		 */
++<<<<<<< HEAD
 +		if (context == MEMMAP_EARLY) {
 +			if (!early_pfn_valid(pfn))
 +				continue;
 +			if (!early_pfn_in_nid(pfn, nid))
 +				continue;
 +		}
 +		page = pfn_to_page(pfn);
 +		set_page_links(page, zone, nid, pfn);
 +		mminit_verify_page_links(page, zone, nid, pfn);
 +		init_page_count(page);
 +		page_mapcount_reset(page);
 +		page_cpupid_reset_last(page);
 +		SetPageReserved(page);
++=======
+ 		if (context != MEMMAP_EARLY)
+ 			goto not_early;
+ 
+ 		if (!early_pfn_valid(pfn))
+ 			continue;
+ 		if (!early_pfn_in_nid(pfn, nid))
+ 			continue;
+ 		if (!update_defer_init(pgdat, pfn, end_pfn, &nr_initialised))
+ 			break;
+ 
+ #ifdef CONFIG_HAVE_MEMBLOCK_NODE_MAP
+ 		/*
+ 		 * If not mirrored_kernelcore and ZONE_MOVABLE exists, range
+ 		 * from zone_movable_pfn[nid] to end of each node should be
+ 		 * ZONE_MOVABLE not ZONE_NORMAL. skip it.
+ 		 */
+ 		if (!mirrored_kernelcore && zone_movable_pfn[nid])
+ 			if (zone == ZONE_NORMAL && pfn >= zone_movable_pfn[nid])
+ 				continue;
+ 
+ 		/*
+ 		 * Check given memblock attribute by firmware which can affect
+ 		 * kernel memory layout.  If zone==ZONE_MOVABLE but memory is
+ 		 * mirrored, it's an overlapped memmap init. skip it.
+ 		 */
+ 		if (mirrored_kernelcore && zone == ZONE_MOVABLE) {
+ 			if (!r || pfn >= memblock_region_memory_end_pfn(r)) {
+ 				for_each_memblock(memory, tmp)
+ 					if (pfn < memblock_region_memory_end_pfn(tmp))
+ 						break;
+ 				r = tmp;
+ 			}
+ 			if (pfn >= memblock_region_memory_base_pfn(r) &&
+ 			    memblock_is_mirror(r)) {
+ 				/* already initialized as NORMAL */
+ 				pfn = memblock_region_memory_end_pfn(r);
+ 				continue;
+ 			}
+ 		}
+ #endif
+ 
+ not_early:
++>>>>>>> b72d0ffb5dbc (mm/page_alloc.c: rework code layout in memmap_init_zone())
  		/*
  		 * Mark the block movable so that blocks are reserved for
  		 * movable at startup. This will force kernel allocations
* Unmerged path mm/page_alloc.c
