IB: remove in-kernel support for memory windows

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Christoph Hellwig <hch@lst.de>
commit feb7c1e38bccfd18cc06677cb648ed2340788fe8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/feb7c1e3.failed

Remove the unused ib_allow_mw and ib_bind_mw functions, remove the
unused IB_WR_BIND_MW and IB_WC_BIND_MW opcodes and move ib_dealloc_mw
into the uverbs module.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Sagi Grimberg <sagig@mellanox.com>
	Reviewed-by: Jason Gunthorpe <jgunthorpe@obsidianresearch.com> [core]
	Reviewed-by: Steve Wise <swise@opengridcomputing.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit feb7c1e38bccfd18cc06677cb648ed2340788fe8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/verbs.c
#	drivers/infiniband/hw/mlx4/mr.c
#	drivers/infiniband/hw/mlx4/qp.c
#	include/rdma/ib_verbs.h
diff --cc drivers/infiniband/core/verbs.c
index 6ff33ede8c15,c5e0f07a7f82..000000000000
--- a/drivers/infiniband/core/verbs.c
+++ b/drivers/infiniband/core/verbs.c
@@@ -1240,67 -1403,6 +1240,70 @@@ struct ib_mr *ib_alloc_mr(struct ib_pd 
  }
  EXPORT_SYMBOL(ib_alloc_mr);
  
++<<<<<<< HEAD
 +struct ib_fast_reg_page_list *ib_alloc_fast_reg_page_list(struct ib_device *device,
 +							  int max_page_list_len)
 +{
 +	struct ib_fast_reg_page_list *page_list;
 +
 +	if (!device->alloc_fast_reg_page_list)
 +		return ERR_PTR(-ENOSYS);
 +
 +	page_list = device->alloc_fast_reg_page_list(device, max_page_list_len);
 +
 +	if (!IS_ERR(page_list)) {
 +		page_list->device = device;
 +		page_list->max_page_list_len = max_page_list_len;
 +	}
 +
 +	return page_list;
 +}
 +EXPORT_SYMBOL(ib_alloc_fast_reg_page_list);
 +
 +void ib_free_fast_reg_page_list(struct ib_fast_reg_page_list *page_list)
 +{
 +	page_list->device->free_fast_reg_page_list(page_list);
 +}
 +EXPORT_SYMBOL(ib_free_fast_reg_page_list);
 +
 +/* Memory windows */
 +
 +struct ib_mw *ib_alloc_mw(struct ib_pd *pd, enum ib_mw_type type)
 +{
 +	struct ib_mw *mw;
 +
 +	if (!pd->device->alloc_mw)
 +		return ERR_PTR(-ENOSYS);
 +
 +	mw = pd->device->alloc_mw(pd, type);
 +	if (!IS_ERR(mw)) {
 +		mw->device  = pd->device;
 +		mw->pd      = pd;
 +		mw->uobject = NULL;
 +		mw->type    = type;
 +		atomic_inc(&pd->usecnt);
 +	}
 +
 +	return mw;
 +}
 +EXPORT_SYMBOL(ib_alloc_mw);
 +
 +int ib_dealloc_mw(struct ib_mw *mw)
 +{
 +	struct ib_pd *pd;
 +	int ret;
 +
 +	pd = mw->pd;
 +	ret = mw->device->dealloc_mw(mw);
 +	if (!ret)
 +		atomic_dec(&pd->usecnt);
 +
 +	return ret;
 +}
 +EXPORT_SYMBOL(ib_dealloc_mw);
 +
++=======
++>>>>>>> feb7c1e38bcc (IB: remove in-kernel support for memory windows)
  /* "Fast" memory regions */
  
  struct ib_fmr *ib_alloc_fmr(struct ib_pd *pd,
diff --cc drivers/infiniband/hw/mlx4/mr.c
index 2542fd3c1a49,242b94ec105b..000000000000
--- a/drivers/infiniband/hw/mlx4/mr.c
+++ b/drivers/infiniband/hw/mlx4/mr.c
@@@ -318,28 -366,6 +318,31 @@@ err_free
  	return ERR_PTR(err);
  }
  
++<<<<<<< HEAD
 +int mlx4_ib_bind_mw(struct ib_qp *qp, struct ib_mw *mw,
 +		    struct ib_mw_bind *mw_bind)
 +{
 +	struct ib_send_wr  wr;
 +	struct ib_send_wr *bad_wr;
 +	int ret;
 +
 +	memset(&wr, 0, sizeof(wr));
 +	wr.opcode               = IB_WR_BIND_MW;
 +	wr.wr_id                = mw_bind->wr_id;
 +	wr.send_flags           = mw_bind->send_flags;
 +	wr.wr.bind_mw.mw        = mw;
 +	wr.wr.bind_mw.bind_info = mw_bind->bind_info;
 +	wr.wr.bind_mw.rkey      = ib_inc_rkey(mw->rkey);
 +
 +	ret = mlx4_ib_post_send(qp, &wr, &bad_wr);
 +	if (!ret)
 +		mw->rkey = wr.wr.bind_mw.rkey;
 +
 +	return ret;
 +}
 +
++=======
++>>>>>>> feb7c1e38bcc (IB: remove in-kernel support for memory windows)
  int mlx4_ib_dealloc_mw(struct ib_mw *ibmw)
  {
  	struct mlx4_ib_mw *mw = to_mmw(ibmw);
diff --cc drivers/infiniband/hw/mlx4/qp.c
index fec8d3a99127,3f5d2af5f8e4..000000000000
--- a/drivers/infiniband/hw/mlx4/qp.c
+++ b/drivers/infiniband/hw/mlx4/qp.c
@@@ -112,10 -112,9 +112,9 @@@ static const __be32 mlx4_ib_opcode[] = 
  	[IB_WR_ATOMIC_FETCH_AND_ADD]		= cpu_to_be32(MLX4_OPCODE_ATOMIC_FA),
  	[IB_WR_SEND_WITH_INV]			= cpu_to_be32(MLX4_OPCODE_SEND_INVAL),
  	[IB_WR_LOCAL_INV]			= cpu_to_be32(MLX4_OPCODE_LOCAL_INVAL),
 -	[IB_WR_REG_MR]				= cpu_to_be32(MLX4_OPCODE_FMR),
 +	[IB_WR_FAST_REG_MR]			= cpu_to_be32(MLX4_OPCODE_FMR),
  	[IB_WR_MASKED_ATOMIC_CMP_AND_SWP]	= cpu_to_be32(MLX4_OPCODE_MASKED_ATOMIC_CS),
  	[IB_WR_MASKED_ATOMIC_FETCH_AND_ADD]	= cpu_to_be32(MLX4_OPCODE_MASKED_ATOMIC_FA),
- 	[IB_WR_BIND_MW]				= cpu_to_be32(MLX4_OPCODE_BIND_MW),
  };
  
  static struct mlx4_ib_sqp *to_msqp(struct mlx4_ib_qp *mqp)
@@@ -2501,24 -2530,6 +2500,27 @@@ static void set_fmr_seg(struct mlx4_wqe
  	fseg->reserved[1]	= 0;
  }
  
++<<<<<<< HEAD
 +static void set_bind_seg(struct mlx4_wqe_bind_seg *bseg, struct ib_send_wr *wr)
 +{
 +	bseg->flags1 =
 +		convert_access(wr->wr.bind_mw.bind_info.mw_access_flags) &
 +		cpu_to_be32(MLX4_WQE_FMR_AND_BIND_PERM_REMOTE_READ  |
 +			    MLX4_WQE_FMR_AND_BIND_PERM_REMOTE_WRITE |
 +			    MLX4_WQE_FMR_AND_BIND_PERM_ATOMIC);
 +	bseg->flags2 = 0;
 +	if (wr->wr.bind_mw.mw->type == IB_MW_TYPE_2)
 +		bseg->flags2 |= cpu_to_be32(MLX4_WQE_BIND_TYPE_2);
 +	if (wr->wr.bind_mw.bind_info.mw_access_flags & IB_ZERO_BASED)
 +		bseg->flags2 |= cpu_to_be32(MLX4_WQE_BIND_ZERO_BASED);
 +	bseg->new_rkey = cpu_to_be32(wr->wr.bind_mw.rkey);
 +	bseg->lkey = cpu_to_be32(wr->wr.bind_mw.bind_info.mr->lkey);
 +	bseg->addr = cpu_to_be64(wr->wr.bind_mw.bind_info.addr);
 +	bseg->length = cpu_to_be64(wr->wr.bind_mw.bind_info.length);
 +}
 +
++=======
++>>>>>>> feb7c1e38bcc (IB: remove in-kernel support for memory windows)
  static void set_local_inv_seg(struct mlx4_wqe_local_inval_seg *iseg, u32 rkey)
  {
  	memset(iseg, 0, sizeof(*iseg));
@@@ -2830,21 -2842,14 +2832,24 @@@ int mlx4_ib_post_send(struct ib_qp *ibq
  				size += sizeof (struct mlx4_wqe_local_inval_seg) / 16;
  				break;
  
 -			case IB_WR_REG_MR:
 +			case IB_WR_FAST_REG_MR:
  				ctrl->srcrb_flags |=
  					cpu_to_be32(MLX4_WQE_CTRL_STRONG_ORDER);
 -				set_reg_seg(wqe, reg_wr(wr));
 -				wqe  += sizeof(struct mlx4_wqe_fmr_seg);
 -				size += sizeof(struct mlx4_wqe_fmr_seg) / 16;
 +				set_fmr_seg(wqe, wr);
 +				wqe  += sizeof (struct mlx4_wqe_fmr_seg);
 +				size += sizeof (struct mlx4_wqe_fmr_seg) / 16;
  				break;
  
++<<<<<<< HEAD
 +			case IB_WR_BIND_MW:
 +				ctrl->srcrb_flags |=
 +					cpu_to_be32(MLX4_WQE_CTRL_STRONG_ORDER);
 +				set_bind_seg(wqe, wr);
 +				wqe  += sizeof(struct mlx4_wqe_bind_seg);
 +				size += sizeof(struct mlx4_wqe_bind_seg) / 16;
 +				break;
++=======
++>>>>>>> feb7c1e38bcc (IB: remove in-kernel support for memory windows)
  			default:
  				/* No extra segments required for sends */
  				break;
diff --cc include/rdma/ib_verbs.h
index 7780289c5a57,177844265c98..000000000000
--- a/include/rdma/ib_verbs.h
+++ b/include/rdma/ib_verbs.h
@@@ -754,10 -812,9 +754,9 @@@ enum ib_wc_opcode 
  	IB_WC_RDMA_READ,
  	IB_WC_COMP_SWAP,
  	IB_WC_FETCH_ADD,
- 	IB_WC_BIND_MW,
  	IB_WC_LSO,
  	IB_WC_LOCAL_INV,
 -	IB_WC_REG_MR,
 +	IB_WC_FAST_REG_MR,
  	IB_WC_MASKED_COMP_SWAP,
  	IB_WC_MASKED_FETCH_ADD,
  /*
@@@ -1047,10 -1106,9 +1046,9 @@@ enum ib_wr_opcode 
  	IB_WR_SEND_WITH_INV,
  	IB_WR_RDMA_READ_WITH_INV,
  	IB_WR_LOCAL_INV,
 -	IB_WR_REG_MR,
 +	IB_WR_FAST_REG_MR,
  	IB_WR_MASKED_ATOMIC_CMP_AND_SWP,
  	IB_WR_MASKED_ATOMIC_FETCH_AND_ADD,
- 	IB_WR_BIND_MW,
  	IB_WR_REG_SIG_MR,
  	/* reserve values for low level drivers' internal use.
  	 * These values will not be used at all in the ib core layer.
@@@ -1085,29 -1143,6 +1083,32 @@@ struct ib_sge 
  	u32	lkey;
  };
  
++<<<<<<< HEAD
 +struct ib_fast_reg_page_list {
 +	struct ib_device       *device;
 +	u64		       *page_list;
 +	unsigned int		max_page_list_len;
 +};
 +
 +/**
 + * struct ib_mw_bind_info - Parameters for a memory window bind operation.
 + * @mr: A memory region to bind the memory window to.
 + * @addr: The address where the memory window should begin.
 + * @length: The length of the memory window, in bytes.
 + * @mw_access_flags: Access flags from enum ib_access_flags for the window.
 + *
 + * This struct contains the shared parameters for type 1 and type 2
 + * memory window bind operations.
 + */
 +struct ib_mw_bind_info {
 +	struct ib_mr   *mr;
 +	u64		addr;
 +	u64		length;
 +	int		mw_access_flags;
 +};
 +
++=======
++>>>>>>> feb7c1e38bcc (IB: remove in-kernel support for memory windows)
  struct ib_cqe {
  	void (*done)(struct ib_cq *cq, struct ib_wc *wc);
  };
@@@ -1126,54 -1161,76 +1127,125 @@@ struct ib_send_wr 
  		__be32		imm_data;
  		u32		invalidate_rkey;
  	} ex;
 +	union {
 +		struct {
 +			u64	remote_addr;
 +			u32	rkey;
 +		} rdma;
 +		struct {
 +			u64	remote_addr;
 +			u64	compare_add;
 +			u64	swap;
 +			u64	compare_add_mask;
 +			u64	swap_mask;
 +			u32	rkey;
 +		} atomic;
 +		struct {
 +			struct ib_ah *ah;
 +			void   *header;
 +			int     hlen;
 +			int     mss;
 +			u32	remote_qpn;
 +			u32	remote_qkey;
 +			u16	pkey_index; /* valid for GSI only */
 +			u8	port_num;   /* valid for DR SMPs on switch only */
 +		} ud;
 +		struct {
 +			u64				iova_start;
 +			struct ib_fast_reg_page_list   *page_list;
 +			unsigned int			page_shift;
 +			unsigned int			page_list_len;
 +			u32				length;
 +			int				access_flags;
 +			u32				rkey;
 +		} fast_reg;
 +		struct {
 +			struct ib_mw            *mw;
 +			/* The new rkey for the memory window. */
 +			u32                      rkey;
 +			struct ib_mw_bind_info   bind_info;
 +		} bind_mw;
 +		struct {
 +			struct ib_sig_attrs    *sig_attrs;
 +			struct ib_mr	       *sig_mr;
 +			int			access_flags;
 +			struct ib_sge	       *prot;
 +		} sig_handover;
 +	} wr;
 +	u32			xrc_remote_srq_num;	/* XRC TGT QPs only */
  };
  
++<<<<<<< HEAD
++=======
+ struct ib_rdma_wr {
+ 	struct ib_send_wr	wr;
+ 	u64			remote_addr;
+ 	u32			rkey;
+ };
+ 
+ static inline struct ib_rdma_wr *rdma_wr(struct ib_send_wr *wr)
+ {
+ 	return container_of(wr, struct ib_rdma_wr, wr);
+ }
+ 
+ struct ib_atomic_wr {
+ 	struct ib_send_wr	wr;
+ 	u64			remote_addr;
+ 	u64			compare_add;
+ 	u64			swap;
+ 	u64			compare_add_mask;
+ 	u64			swap_mask;
+ 	u32			rkey;
+ };
+ 
+ static inline struct ib_atomic_wr *atomic_wr(struct ib_send_wr *wr)
+ {
+ 	return container_of(wr, struct ib_atomic_wr, wr);
+ }
+ 
+ struct ib_ud_wr {
+ 	struct ib_send_wr	wr;
+ 	struct ib_ah		*ah;
+ 	void			*header;
+ 	int			hlen;
+ 	int			mss;
+ 	u32			remote_qpn;
+ 	u32			remote_qkey;
+ 	u16			pkey_index; /* valid for GSI only */
+ 	u8			port_num;   /* valid for DR SMPs on switch only */
+ };
+ 
+ static inline struct ib_ud_wr *ud_wr(struct ib_send_wr *wr)
+ {
+ 	return container_of(wr, struct ib_ud_wr, wr);
+ }
+ 
+ struct ib_reg_wr {
+ 	struct ib_send_wr	wr;
+ 	struct ib_mr		*mr;
+ 	u32			key;
+ 	int			access;
+ };
+ 
+ static inline struct ib_reg_wr *reg_wr(struct ib_send_wr *wr)
+ {
+ 	return container_of(wr, struct ib_reg_wr, wr);
+ }
+ 
+ struct ib_sig_handover_wr {
+ 	struct ib_send_wr	wr;
+ 	struct ib_sig_attrs    *sig_attrs;
+ 	struct ib_mr	       *sig_mr;
+ 	int			access_flags;
+ 	struct ib_sge	       *prot;
+ };
+ 
+ static inline struct ib_sig_handover_wr *sig_handover_wr(struct ib_send_wr *wr)
+ {
+ 	return container_of(wr, struct ib_sig_handover_wr, wr);
+ }
+ 
++>>>>>>> feb7c1e38bcc (IB: remove in-kernel support for memory windows)
  struct ib_recv_wr {
  	struct ib_recv_wr      *next;
  	union {
@@@ -1749,21 -1796,11 +1809,18 @@@ struct ib_device 
  	struct ib_mr *		   (*alloc_mr)(struct ib_pd *pd,
  					       enum ib_mr_type mr_type,
  					       u32 max_num_sg);
 -	int                        (*map_mr_sg)(struct ib_mr *mr,
 -						struct scatterlist *sg,
 -						int sg_nents);
 +	struct ib_fast_reg_page_list * (*alloc_fast_reg_page_list)(struct ib_device *device,
 +								   int page_list_len);
 +	void			   (*free_fast_reg_page_list)(struct ib_fast_reg_page_list *page_list);
 +	int                        (*rereg_phys_mr)(struct ib_mr *mr,
 +						    int mr_rereg_mask,
 +						    struct ib_pd *pd,
 +						    struct ib_phys_buf *phys_buf_array,
 +						    int num_phys_buf,
 +						    int mr_access_flags,
 +						    u64 *iova_start);
  	struct ib_mw *             (*alloc_mw)(struct ib_pd *pd,
  					       enum ib_mw_type type);
- 	int                        (*bind_mw)(struct ib_qp *qp,
- 					      struct ib_mw *mw,
- 					      struct ib_mw_bind *mw_bind);
  	int                        (*dealloc_mw)(struct ib_mw *mw);
  	struct ib_fmr *	           (*alloc_fmr)(struct ib_pd *pd,
  						int mr_access_flags,
diff --git a/Documentation/infiniband/core_locking.txt b/Documentation/infiniband/core_locking.txt
index e1678542279a..4b1f36b6ada0 100644
--- a/Documentation/infiniband/core_locking.txt
+++ b/Documentation/infiniband/core_locking.txt
@@ -15,7 +15,6 @@ Sleeping and interrupt context
     modify_ah
     query_ah
     destroy_ah
-    bind_mw
     post_send
     post_recv
     poll_cq
@@ -31,7 +30,6 @@ Sleeping and interrupt context
     ib_modify_ah
     ib_query_ah
     ib_destroy_ah
-    ib_bind_mw
     ib_post_send
     ib_post_recv
     ib_req_notify_cq
diff --git a/drivers/infiniband/core/uverbs.h b/drivers/infiniband/core/uverbs.h
index 94bbd8c155fc..612ccfd39bf9 100644
--- a/drivers/infiniband/core/uverbs.h
+++ b/drivers/infiniband/core/uverbs.h
@@ -204,6 +204,8 @@ void ib_uverbs_event_handler(struct ib_event_handler *handler,
 			     struct ib_event *event);
 void ib_uverbs_dealloc_xrcd(struct ib_uverbs_device *dev, struct ib_xrcd *xrcd);
 
+int uverbs_dealloc_mw(struct ib_mw *mw);
+
 struct ib_uverbs_flow_spec {
 	union {
 		union {
diff --git a/drivers/infiniband/core/uverbs_cmd.c b/drivers/infiniband/core/uverbs_cmd.c
index 543f7c3c2c6f..72d5b9531ea2 100644
--- a/drivers/infiniband/core/uverbs_cmd.c
+++ b/drivers/infiniband/core/uverbs_cmd.c
@@ -1243,7 +1243,7 @@ err_copy:
 	idr_remove_uobj(&ib_uverbs_mw_idr, uobj);
 
 err_unalloc:
-	ib_dealloc_mw(mw);
+	uverbs_dealloc_mw(mw);
 
 err_put:
 	put_pd_read(pd);
@@ -1272,7 +1272,7 @@ ssize_t ib_uverbs_dealloc_mw(struct ib_uverbs_file *file,
 
 	mw = uobj->object;
 
-	ret = ib_dealloc_mw(mw);
+	ret = uverbs_dealloc_mw(mw);
 	if (!ret)
 		uobj->live = 0;
 
diff --git a/drivers/infiniband/core/uverbs_main.c b/drivers/infiniband/core/uverbs_main.c
index e3ef28861be6..39680aed99dd 100644
--- a/drivers/infiniband/core/uverbs_main.c
+++ b/drivers/infiniband/core/uverbs_main.c
@@ -133,6 +133,17 @@ static int (*uverbs_ex_cmd_table[])(struct ib_uverbs_file *file,
 static void ib_uverbs_add_one(struct ib_device *device);
 static void ib_uverbs_remove_one(struct ib_device *device, void *client_data);
 
+int uverbs_dealloc_mw(struct ib_mw *mw)
+{
+	struct ib_pd *pd = mw->pd;
+	int ret;
+
+	ret = mw->device->dealloc_mw(mw);
+	if (!ret)
+		atomic_dec(&pd->usecnt);
+	return ret;
+}
+
 static void ib_uverbs_release_dev(struct kobject *kobj)
 {
 	struct ib_uverbs_device *dev =
@@ -224,7 +235,7 @@ static int ib_uverbs_cleanup_ucontext(struct ib_uverbs_file *file,
 		struct ib_mw *mw = uobj->object;
 
 		idr_remove_uobj(&ib_uverbs_mw_idr, uobj);
-		ib_dealloc_mw(mw);
+		uverbs_dealloc_mw(mw);
 		kfree(uobj);
 	}
 
* Unmerged path drivers/infiniband/core/verbs.c
diff --git a/drivers/infiniband/hw/amso1100/c2_cq.c b/drivers/infiniband/hw/amso1100/c2_cq.c
index 49e0e8533f74..049d9db86216 100644
--- a/drivers/infiniband/hw/amso1100/c2_cq.c
+++ b/drivers/infiniband/hw/amso1100/c2_cq.c
@@ -173,9 +173,6 @@ static inline int c2_poll_one(struct c2_dev *c2dev,
 	case C2_WR_TYPE_RDMA_READ:
 		entry->opcode = IB_WC_RDMA_READ;
 		break;
-	case C2_WR_TYPE_BIND_MW:
-		entry->opcode = IB_WC_BIND_MW;
-		break;
 	case C2_WR_TYPE_RECV:
 		entry->byte_len = be32_to_cpu(ce->bytes_rcvd);
 		entry->opcode = IB_WC_RECV;
diff --git a/drivers/infiniband/hw/cxgb3/iwch_cq.c b/drivers/infiniband/hw/cxgb3/iwch_cq.c
index cf5474ae68ff..473de0ebce97 100644
--- a/drivers/infiniband/hw/cxgb3/iwch_cq.c
+++ b/drivers/infiniband/hw/cxgb3/iwch_cq.c
@@ -115,10 +115,6 @@ static int iwch_poll_cq_one(struct iwch_dev *rhp, struct iwch_cq *chp,
 		case T3_SEND_WITH_SE_INV:
 			wc->opcode = IB_WC_SEND;
 			break;
-		case T3_BIND_MW:
-			wc->opcode = IB_WC_BIND_MW;
-			break;
-
 		case T3_LOCAL_INV:
 			wc->opcode = IB_WC_LOCAL_INV;
 			break;
diff --git a/drivers/infiniband/hw/cxgb3/iwch_provider.c b/drivers/infiniband/hw/cxgb3/iwch_provider.c
index 93308c45f298..01056b5a5082 100644
--- a/drivers/infiniband/hw/cxgb3/iwch_provider.c
+++ b/drivers/infiniband/hw/cxgb3/iwch_provider.c
@@ -1447,7 +1447,6 @@ int iwch_register_device(struct iwch_dev *dev)
 	dev->ibdev.reg_user_mr = iwch_reg_user_mr;
 	dev->ibdev.dereg_mr = iwch_dereg_mr;
 	dev->ibdev.alloc_mw = iwch_alloc_mw;
-	dev->ibdev.bind_mw = iwch_bind_mw;
 	dev->ibdev.dealloc_mw = iwch_dealloc_mw;
 	dev->ibdev.alloc_mr = iwch_alloc_mr;
 	dev->ibdev.alloc_fast_reg_page_list = iwch_alloc_fastreg_pbl;
diff --git a/drivers/infiniband/hw/cxgb3/iwch_provider.h b/drivers/infiniband/hw/cxgb3/iwch_provider.h
index 87c14b0c5ac0..884b44575da1 100644
--- a/drivers/infiniband/hw/cxgb3/iwch_provider.h
+++ b/drivers/infiniband/hw/cxgb3/iwch_provider.h
@@ -328,9 +328,6 @@ int iwch_post_send(struct ib_qp *ibqp, struct ib_send_wr *wr,
 		      struct ib_send_wr **bad_wr);
 int iwch_post_receive(struct ib_qp *ibqp, struct ib_recv_wr *wr,
 		      struct ib_recv_wr **bad_wr);
-int iwch_bind_mw(struct ib_qp *qp,
-			     struct ib_mw *mw,
-			     struct ib_mw_bind *mw_bind);
 int iwch_poll_cq(struct ib_cq *ibcq, int num_entries, struct ib_wc *wc);
 int iwch_post_terminate(struct iwch_qp *qhp, struct respQ_msg_t *rsp_msg);
 int iwch_post_zb_read(struct iwch_ep *ep);
diff --git a/drivers/infiniband/hw/cxgb3/iwch_qp.c b/drivers/infiniband/hw/cxgb3/iwch_qp.c
index b57c0befd962..35e0de5b3411 100644
--- a/drivers/infiniband/hw/cxgb3/iwch_qp.c
+++ b/drivers/infiniband/hw/cxgb3/iwch_qp.c
@@ -525,88 +525,6 @@ out:
 	return err;
 }
 
-int iwch_bind_mw(struct ib_qp *qp,
-			     struct ib_mw *mw,
-			     struct ib_mw_bind *mw_bind)
-{
-	struct iwch_dev *rhp;
-	struct iwch_mw *mhp;
-	struct iwch_qp *qhp;
-	union t3_wr *wqe;
-	u32 pbl_addr;
-	u8 page_size;
-	u32 num_wrs;
-	unsigned long flag;
-	struct ib_sge sgl;
-	int err=0;
-	enum t3_wr_flags t3_wr_flags;
-	u32 idx;
-	struct t3_swsq *sqp;
-
-	qhp = to_iwch_qp(qp);
-	mhp = to_iwch_mw(mw);
-	rhp = qhp->rhp;
-
-	spin_lock_irqsave(&qhp->lock, flag);
-	if (qhp->attr.state > IWCH_QP_STATE_RTS) {
-		spin_unlock_irqrestore(&qhp->lock, flag);
-		return -EINVAL;
-	}
-	num_wrs = Q_FREECNT(qhp->wq.sq_rptr, qhp->wq.sq_wptr,
-			    qhp->wq.sq_size_log2);
-	if (num_wrs == 0) {
-		spin_unlock_irqrestore(&qhp->lock, flag);
-		return -ENOMEM;
-	}
-	idx = Q_PTR2IDX(qhp->wq.wptr, qhp->wq.size_log2);
-	PDBG("%s: idx 0x%0x, mw 0x%p, mw_bind 0x%p\n", __func__, idx,
-	     mw, mw_bind);
-	wqe = (union t3_wr *) (qhp->wq.queue + idx);
-
-	t3_wr_flags = 0;
-	if (mw_bind->send_flags & IB_SEND_SIGNALED)
-		t3_wr_flags = T3_COMPLETION_FLAG;
-
-	sgl.addr = mw_bind->bind_info.addr;
-	sgl.lkey = mw_bind->bind_info.mr->lkey;
-	sgl.length = mw_bind->bind_info.length;
-	wqe->bind.reserved = 0;
-	wqe->bind.type = TPT_VATO;
-
-	/* TBD: check perms */
-	wqe->bind.perms = iwch_ib_to_tpt_bind_access(
-		mw_bind->bind_info.mw_access_flags);
-	wqe->bind.mr_stag = cpu_to_be32(mw_bind->bind_info.mr->lkey);
-	wqe->bind.mw_stag = cpu_to_be32(mw->rkey);
-	wqe->bind.mw_len = cpu_to_be32(mw_bind->bind_info.length);
-	wqe->bind.mw_va = cpu_to_be64(mw_bind->bind_info.addr);
-	err = iwch_sgl2pbl_map(rhp, &sgl, 1, &pbl_addr, &page_size);
-	if (err) {
-		spin_unlock_irqrestore(&qhp->lock, flag);
-		return err;
-	}
-	wqe->send.wrid.id0.hi = qhp->wq.sq_wptr;
-	sqp = qhp->wq.sq + Q_PTR2IDX(qhp->wq.sq_wptr, qhp->wq.sq_size_log2);
-	sqp->wr_id = mw_bind->wr_id;
-	sqp->opcode = T3_BIND_MW;
-	sqp->sq_wptr = qhp->wq.sq_wptr;
-	sqp->complete = 0;
-	sqp->signaled = (mw_bind->send_flags & IB_SEND_SIGNALED);
-	wqe->bind.mr_pbl_addr = cpu_to_be32(pbl_addr);
-	wqe->bind.mr_pagesz = page_size;
-	build_fw_riwrh((void *)wqe, T3_WR_BIND, t3_wr_flags,
-		       Q_GENBIT(qhp->wq.wptr, qhp->wq.size_log2), 0,
-		       sizeof(struct t3_bind_mw_wr) >> 3, T3_SOPEOP);
-	++(qhp->wq.wptr);
-	++(qhp->wq.sq_wptr);
-	spin_unlock_irqrestore(&qhp->lock, flag);
-
-	if (cxio_wq_db_enabled(&qhp->wq))
-		ring_doorbell(qhp->wq.doorbell, qhp->wq.qpid);
-
-	return err;
-}
-
 static inline void build_term_codes(struct respQ_msg_t *rsp_msg,
 				    u8 *layer_type, u8 *ecode)
 {
diff --git a/drivers/infiniband/hw/cxgb4/cq.c b/drivers/infiniband/hw/cxgb4/cq.c
index 33c24f0bc645..67027caa246d 100644
--- a/drivers/infiniband/hw/cxgb4/cq.c
+++ b/drivers/infiniband/hw/cxgb4/cq.c
@@ -744,9 +744,6 @@ static int c4iw_poll_cq_one(struct c4iw_cq *chp, struct ib_wc *wc)
 		case FW_RI_SEND_WITH_SE:
 			wc->opcode = IB_WC_SEND;
 			break;
-		case FW_RI_BIND_MW:
-			wc->opcode = IB_WC_BIND_MW;
-			break;
 
 		case FW_RI_LOCAL_INV:
 			wc->opcode = IB_WC_LOCAL_INV;
diff --git a/drivers/infiniband/hw/cxgb4/iw_cxgb4.h b/drivers/infiniband/hw/cxgb4/iw_cxgb4.h
index c7bb38c931a5..eb84d42f5b9a 100644
--- a/drivers/infiniband/hw/cxgb4/iw_cxgb4.h
+++ b/drivers/infiniband/hw/cxgb4/iw_cxgb4.h
@@ -957,8 +957,6 @@ int c4iw_post_send(struct ib_qp *ibqp, struct ib_send_wr *wr,
 		      struct ib_send_wr **bad_wr);
 int c4iw_post_receive(struct ib_qp *ibqp, struct ib_recv_wr *wr,
 		      struct ib_recv_wr **bad_wr);
-int c4iw_bind_mw(struct ib_qp *qp, struct ib_mw *mw,
-		 struct ib_mw_bind *mw_bind);
 int c4iw_connect(struct iw_cm_id *cm_id, struct iw_cm_conn_param *conn_param);
 int c4iw_create_listen(struct iw_cm_id *cm_id, int backlog);
 int c4iw_destroy_listen(struct iw_cm_id *cm_id);
diff --git a/drivers/infiniband/hw/cxgb4/provider.c b/drivers/infiniband/hw/cxgb4/provider.c
index 7746113552e7..d1197e1d30a0 100644
--- a/drivers/infiniband/hw/cxgb4/provider.c
+++ b/drivers/infiniband/hw/cxgb4/provider.c
@@ -554,7 +554,6 @@ int c4iw_register_device(struct c4iw_dev *dev)
 	dev->ibdev.reg_user_mr = c4iw_reg_user_mr;
 	dev->ibdev.dereg_mr = c4iw_dereg_mr;
 	dev->ibdev.alloc_mw = c4iw_alloc_mw;
-	dev->ibdev.bind_mw = c4iw_bind_mw;
 	dev->ibdev.dealloc_mw = c4iw_dealloc_mw;
 	dev->ibdev.alloc_mr = c4iw_alloc_mr;
 	dev->ibdev.alloc_fast_reg_page_list = c4iw_alloc_fastreg_pbl;
diff --git a/drivers/infiniband/hw/cxgb4/qp.c b/drivers/infiniband/hw/cxgb4/qp.c
index 323fa1d872d6..d51086cdb793 100644
--- a/drivers/infiniband/hw/cxgb4/qp.c
+++ b/drivers/infiniband/hw/cxgb4/qp.c
@@ -944,11 +944,6 @@ int c4iw_post_receive(struct ib_qp *ibqp, struct ib_recv_wr *wr,
 	return err;
 }
 
-int c4iw_bind_mw(struct ib_qp *qp, struct ib_mw *mw, struct ib_mw_bind *mw_bind)
-{
-	return -ENOSYS;
-}
-
 static inline void build_term_codes(struct t4_cqe *err_cqe, u8 *layer_type,
 				    u8 *ecode)
 {
diff --git a/drivers/infiniband/hw/ehca/ehca_iverbs.h b/drivers/infiniband/hw/ehca/ehca_iverbs.h
index 30b1316c965e..872694a3a436 100644
--- a/drivers/infiniband/hw/ehca/ehca_iverbs.h
+++ b/drivers/infiniband/hw/ehca/ehca_iverbs.h
@@ -99,9 +99,6 @@ int ehca_dereg_mr(struct ib_mr *mr);
 
 struct ib_mw *ehca_alloc_mw(struct ib_pd *pd, enum ib_mw_type type);
 
-int ehca_bind_mw(struct ib_qp *qp, struct ib_mw *mw,
-		 struct ib_mw_bind *mw_bind);
-
 int ehca_dealloc_mw(struct ib_mw *mw);
 
 struct ib_fmr *ehca_alloc_fmr(struct ib_pd *pd,
diff --git a/drivers/infiniband/hw/ehca/ehca_main.c b/drivers/infiniband/hw/ehca/ehca_main.c
index da5ec47d582f..fded40375f61 100644
--- a/drivers/infiniband/hw/ehca/ehca_main.c
+++ b/drivers/infiniband/hw/ehca/ehca_main.c
@@ -516,7 +516,6 @@ static int ehca_init_device(struct ehca_shca *shca)
 	shca->ib_device.dereg_mr	    = ehca_dereg_mr;
 	shca->ib_device.rereg_phys_mr	    = ehca_rereg_phys_mr;
 	shca->ib_device.alloc_mw	    = ehca_alloc_mw;
-	shca->ib_device.bind_mw		    = ehca_bind_mw;
 	shca->ib_device.dealloc_mw	    = ehca_dealloc_mw;
 	shca->ib_device.alloc_fmr	    = ehca_alloc_fmr;
 	shca->ib_device.map_phys_fmr	    = ehca_map_phys_fmr;
diff --git a/drivers/infiniband/hw/ehca/ehca_mrmw.c b/drivers/infiniband/hw/ehca/ehca_mrmw.c
index 121b3356d590..31e145b90ee9 100644
--- a/drivers/infiniband/hw/ehca/ehca_mrmw.c
+++ b/drivers/infiniband/hw/ehca/ehca_mrmw.c
@@ -679,18 +679,6 @@ alloc_mw_exit0:
 
 /*----------------------------------------------------------------------*/
 
-int ehca_bind_mw(struct ib_qp *qp,
-		 struct ib_mw *mw,
-		 struct ib_mw_bind *mw_bind)
-{
-	/* TODO: not supported up to now */
-	ehca_gen_err("bind MW currently not supported by HCAD");
-
-	return -EPERM;
-} /* end ehca_bind_mw() */
-
-/*----------------------------------------------------------------------*/
-
 int ehca_dealloc_mw(struct ib_mw *mw)
 {
 	u64 h_ret;
diff --git a/drivers/infiniband/hw/ehca/ehca_reqs.c b/drivers/infiniband/hw/ehca/ehca_reqs.c
index 47f94984353d..228aa6efd095 100644
--- a/drivers/infiniband/hw/ehca/ehca_reqs.c
+++ b/drivers/infiniband/hw/ehca/ehca_reqs.c
@@ -613,7 +613,6 @@ int ehca_post_srq_recv(struct ib_srq *srq,
 static const u8 ib_wc_opcode[255] = {
 	[0x01] = IB_WC_RECV+1,
 	[0x02] = IB_WC_RECV_RDMA_WITH_IMM+1,
-	[0x04] = IB_WC_BIND_MW+1,
 	[0x08] = IB_WC_FETCH_ADD+1,
 	[0x10] = IB_WC_COMP_SWAP+1,
 	[0x20] = IB_WC_RDMA_WRITE+1,
diff --git a/drivers/infiniband/hw/mlx4/cq.c b/drivers/infiniband/hw/mlx4/cq.c
index 5fd49f9435f9..cfcd5ce49a04 100644
--- a/drivers/infiniband/hw/mlx4/cq.c
+++ b/drivers/infiniband/hw/mlx4/cq.c
@@ -811,9 +811,6 @@ repoll:
 			wc->opcode    = IB_WC_MASKED_FETCH_ADD;
 			wc->byte_len  = 8;
 			break;
-		case MLX4_OPCODE_BIND_MW:
-			wc->opcode    = IB_WC_BIND_MW;
-			break;
 		case MLX4_OPCODE_LSO:
 			wc->opcode    = IB_WC_LSO;
 			break;
diff --git a/drivers/infiniband/hw/mlx4/main.c b/drivers/infiniband/hw/mlx4/main.c
index ce017b8c0359..89dfd4b9cbec 100644
--- a/drivers/infiniband/hw/mlx4/main.c
+++ b/drivers/infiniband/hw/mlx4/main.c
@@ -2699,7 +2699,6 @@ static void *mlx4_ib_add(struct mlx4_dev *dev)
 	if (dev->caps.flags & MLX4_DEV_CAP_FLAG_MEM_WINDOW ||
 	    dev->caps.bmme_flags & MLX4_BMME_FLAG_TYPE_2_WIN) {
 		ibdev->ib_dev.alloc_mw = mlx4_ib_alloc_mw;
-		ibdev->ib_dev.bind_mw = mlx4_ib_bind_mw;
 		ibdev->ib_dev.dealloc_mw = mlx4_ib_dealloc_mw;
 
 		ibdev->ib_dev.uverbs_cmd_mask |=
diff --git a/drivers/infiniband/hw/mlx4/mlx4_ib.h b/drivers/infiniband/hw/mlx4/mlx4_ib.h
index 8009e0b53f2d..25c3e5aab79b 100644
--- a/drivers/infiniband/hw/mlx4/mlx4_ib.h
+++ b/drivers/infiniband/hw/mlx4/mlx4_ib.h
@@ -712,8 +712,6 @@ struct ib_mr *mlx4_ib_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,
 				  struct ib_udata *udata);
 int mlx4_ib_dereg_mr(struct ib_mr *mr);
 struct ib_mw *mlx4_ib_alloc_mw(struct ib_pd *pd, enum ib_mw_type type);
-int mlx4_ib_bind_mw(struct ib_qp *qp, struct ib_mw *mw,
-		    struct ib_mw_bind *mw_bind);
 int mlx4_ib_dealloc_mw(struct ib_mw *mw);
 struct ib_mr *mlx4_ib_alloc_mr(struct ib_pd *pd,
 			       enum ib_mr_type mr_type,
* Unmerged path drivers/infiniband/hw/mlx4/mr.c
* Unmerged path drivers/infiniband/hw/mlx4/qp.c
diff --git a/drivers/infiniband/hw/mlx5/cq.c b/drivers/infiniband/hw/mlx5/cq.c
index bef2b272ab57..9fb0f49b3940 100644
--- a/drivers/infiniband/hw/mlx5/cq.c
+++ b/drivers/infiniband/hw/mlx5/cq.c
@@ -157,9 +157,6 @@ static void handle_good_req(struct ib_wc *wc, struct mlx5_cqe64 *cqe,
 		wc->opcode    = IB_WC_MASKED_FETCH_ADD;
 		wc->byte_len  = 8;
 		break;
-	case MLX5_OPCODE_BIND_MW:
-		wc->opcode    = IB_WC_BIND_MW;
-		break;
 	case MLX5_OPCODE_UMR:
 		wc->opcode = get_umr_comp(wq, idx);
 		break;
diff --git a/drivers/infiniband/hw/mthca/mthca_cq.c b/drivers/infiniband/hw/mthca/mthca_cq.c
index 40ba83338155..a6531ffe29a6 100644
--- a/drivers/infiniband/hw/mthca/mthca_cq.c
+++ b/drivers/infiniband/hw/mthca/mthca_cq.c
@@ -608,9 +608,6 @@ static inline int mthca_poll_one(struct mthca_dev *dev,
 			entry->opcode    = IB_WC_FETCH_ADD;
 			entry->byte_len  = MTHCA_ATOMIC_BYTE_LEN;
 			break;
-		case MTHCA_OPCODE_BIND_MW:
-			entry->opcode    = IB_WC_BIND_MW;
-			break;
 		default:
 			entry->opcode    = MTHCA_OPCODE_INVALID;
 			break;
diff --git a/drivers/infiniband/hw/nes/nes_verbs.c b/drivers/infiniband/hw/nes/nes_verbs.c
index cbbc2523f4aa..cac1518e7f22 100644
--- a/drivers/infiniband/hw/nes/nes_verbs.c
+++ b/drivers/infiniband/hw/nes/nes_verbs.c
@@ -206,80 +206,6 @@ static int nes_dealloc_mw(struct ib_mw *ibmw)
 }
 
 
-/**
- * nes_bind_mw
- */
-static int nes_bind_mw(struct ib_qp *ibqp, struct ib_mw *ibmw,
-		struct ib_mw_bind *ibmw_bind)
-{
-	u64 u64temp;
-	struct nes_vnic *nesvnic = to_nesvnic(ibqp->device);
-	struct nes_device *nesdev = nesvnic->nesdev;
-	/* struct nes_mr *nesmr = to_nesmw(ibmw); */
-	struct nes_qp *nesqp = to_nesqp(ibqp);
-	struct nes_hw_qp_wqe *wqe;
-	unsigned long flags = 0;
-	u32 head;
-	u32 wqe_misc = 0;
-	u32 qsize;
-
-	if (nesqp->ibqp_state > IB_QPS_RTS)
-		return -EINVAL;
-
-	spin_lock_irqsave(&nesqp->lock, flags);
-
-	head = nesqp->hwqp.sq_head;
-	qsize = nesqp->hwqp.sq_tail;
-
-	/* Check for SQ overflow */
-	if (((head + (2 * qsize) - nesqp->hwqp.sq_tail) % qsize) == (qsize - 1)) {
-		spin_unlock_irqrestore(&nesqp->lock, flags);
-		return -ENOMEM;
-	}
-
-	wqe = &nesqp->hwqp.sq_vbase[head];
-	/* nes_debug(NES_DBG_MR, "processing sq wqe at %p, head = %u.\n", wqe, head); */
-	nes_fill_init_qp_wqe(wqe, nesqp, head);
-	u64temp = ibmw_bind->wr_id;
-	set_wqe_64bit_value(wqe->wqe_words, NES_IWARP_SQ_WQE_COMP_SCRATCH_LOW_IDX, u64temp);
-	wqe_misc = NES_IWARP_SQ_OP_BIND;
-
-	wqe_misc |= NES_IWARP_SQ_WQE_LOCAL_FENCE;
-
-	if (ibmw_bind->send_flags & IB_SEND_SIGNALED)
-		wqe_misc |= NES_IWARP_SQ_WQE_SIGNALED_COMPL;
-
-	if (ibmw_bind->bind_info.mw_access_flags & IB_ACCESS_REMOTE_WRITE)
-		wqe_misc |= NES_CQP_STAG_RIGHTS_REMOTE_WRITE;
-	if (ibmw_bind->bind_info.mw_access_flags & IB_ACCESS_REMOTE_READ)
-		wqe_misc |= NES_CQP_STAG_RIGHTS_REMOTE_READ;
-
-	set_wqe_32bit_value(wqe->wqe_words, NES_IWARP_SQ_WQE_MISC_IDX, wqe_misc);
-	set_wqe_32bit_value(wqe->wqe_words, NES_IWARP_SQ_BIND_WQE_MR_IDX,
-			    ibmw_bind->bind_info.mr->lkey);
-	set_wqe_32bit_value(wqe->wqe_words, NES_IWARP_SQ_BIND_WQE_MW_IDX, ibmw->rkey);
-	set_wqe_32bit_value(wqe->wqe_words, NES_IWARP_SQ_BIND_WQE_LENGTH_LOW_IDX,
-			ibmw_bind->bind_info.length);
-	wqe->wqe_words[NES_IWARP_SQ_BIND_WQE_LENGTH_HIGH_IDX] = 0;
-	u64temp = (u64)ibmw_bind->bind_info.addr;
-	set_wqe_64bit_value(wqe->wqe_words, NES_IWARP_SQ_BIND_WQE_VA_FBO_LOW_IDX, u64temp);
-
-	head++;
-	if (head >= qsize)
-		head = 0;
-
-	nesqp->hwqp.sq_head = head;
-	barrier();
-
-	nes_write32(nesdev->regs+NES_WQE_ALLOC,
-			(1 << 24) | 0x00800000 | nesqp->hwqp.qp_id);
-
-	spin_unlock_irqrestore(&nesqp->lock, flags);
-
-	return 0;
-}
-
-
 /*
  * nes_alloc_fast_mr
  */
@@ -4050,7 +3976,6 @@ struct nes_ib_device *nes_init_ofa_device(struct net_device *netdev)
 	nesibdev->ibdev.dereg_mr = nes_dereg_mr;
 	nesibdev->ibdev.alloc_mw = nes_alloc_mw;
 	nesibdev->ibdev.dealloc_mw = nes_dealloc_mw;
-	nesibdev->ibdev.bind_mw = nes_bind_mw;
 
 	nesibdev->ibdev.alloc_mr = nes_alloc_mr;
 	nesibdev->ibdev.map_mr_sg = nes_map_mr_sg;
* Unmerged path include/rdma/ib_verbs.h
