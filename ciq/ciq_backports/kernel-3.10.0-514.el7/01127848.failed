ext4: fix races of writeback with punch hole and zero range

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Jan Kara <jack@suse.com>
commit 011278485ecc3cd2a3954b5d4c73101d919bf1fa
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/01127848.failed

When doing delayed allocation, update of on-disk inode size is postponed
until IO submission time. However hole punch or zero range fallocate
calls can end up discarding the tail page cache page and thus on-disk
inode size would never be properly updated.

Make sure the on-disk inode size is updated before truncating page
cache.

	Signed-off-by: Jan Kara <jack@suse.com>
	Signed-off-by: Theodore Ts'o <tytso@mit.edu>
(cherry picked from commit 011278485ecc3cd2a3954b5d4c73101d919bf1fa)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/ext4/extents.c
diff --cc fs/ext4/extents.c
index d936da6a075b,3578b25fccfd..000000000000
--- a/fs/ext4/extents.c
+++ b/fs/ext4/extents.c
@@@ -4834,7 -4842,17 +4834,21 @@@ static long ext4_zero_range(struct fil
  		flags |= (EXT4_GET_BLOCKS_CONVERT_UNWRITTEN |
  			  EXT4_EX_NOCACHE);
  
++<<<<<<< HEAD
 +		/* Now release the pages and zero block aligned part of pages*/
++=======
+ 		/*
+ 		 * Prevent page faults from reinstantiating pages we have
+ 		 * released from page cache.
+ 		 */
+ 		down_write(&EXT4_I(inode)->i_mmap_sem);
+ 		ret = ext4_update_disksize_before_punch(inode, offset, len);
+ 		if (ret) {
+ 			up_write(&EXT4_I(inode)->i_mmap_sem);
+ 			goto out_dio;
+ 		}
+ 		/* Now release the pages and zero block aligned part of pages */
++>>>>>>> 011278485ecc (ext4: fix races of writeback with punch hole and zero range)
  		truncate_pagecache_range(inode, start, end - 1);
  		inode->i_mtime = inode->i_ctime = ext4_current_time(inode);
  
diff --git a/fs/ext4/ext4.h b/fs/ext4/ext4.h
index 5dda1d21c88f..a2331800b070 100644
--- a/fs/ext4/ext4.h
+++ b/fs/ext4/ext4.h
@@ -2478,6 +2478,9 @@ static inline int ext4_update_inode_size(struct inode *inode, loff_t newsize)
 	return changed;
 }
 
+int ext4_update_disksize_before_punch(struct inode *inode, loff_t offset,
+				      loff_t len);
+
 struct ext4_group_info {
 	unsigned long   bb_state;
 	struct rb_root  bb_free_root;
* Unmerged path fs/ext4/extents.c
diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 235a73f02c8d..edeeb5df1fa9 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -3409,6 +3409,35 @@ int ext4_can_truncate(struct inode *inode)
 	return 0;
 }
 
+/*
+ * We have to make sure i_disksize gets properly updated before we truncate
+ * page cache due to hole punching or zero range. Otherwise i_disksize update
+ * can get lost as it may have been postponed to submission of writeback but
+ * that will never happen after we truncate page cache.
+ */
+int ext4_update_disksize_before_punch(struct inode *inode, loff_t offset,
+				      loff_t len)
+{
+	handle_t *handle;
+	loff_t size = i_size_read(inode);
+
+	WARN_ON(!mutex_is_locked(&inode->i_mutex));
+	if (offset > size || offset + len < size)
+		return 0;
+
+	if (EXT4_I(inode)->i_disksize >= size)
+		return 0;
+
+	handle = ext4_journal_start(inode, EXT4_HT_MISC, 1);
+	if (IS_ERR(handle))
+		return PTR_ERR(handle);
+	ext4_update_i_disksize(inode, size);
+	ext4_mark_inode_dirty(handle, inode);
+	ext4_journal_stop(handle);
+
+	return 0;
+}
+
 /*
  * ext4_punch_hole: punches a hole in a file by releaseing the blocks
  * associated with the given offset and length
@@ -3483,9 +3512,13 @@ int ext4_punch_hole(struct inode *inode, loff_t offset, loff_t length)
 	last_block_offset = round_down((offset + length), sb->s_blocksize) - 1;
 
 	/* Now release the pages and zero block aligned part of pages*/
-	if (last_block_offset > first_block_offset)
+	if (last_block_offset > first_block_offset) {
+		ret = ext4_update_disksize_before_punch(inode, offset, length);
+		if (ret)
+			goto out_dio;
 		truncate_pagecache_range(inode, first_block_offset,
 					 last_block_offset);
+	}
 
 	/* Wait all existing dio workers, newcomers will block on i_mutex */
 	ext4_inode_block_unlocked_dio(inode);
