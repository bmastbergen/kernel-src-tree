ftrace, kprobes: Support IPMODIFY flag to find IP modify conflict

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
commit f8b8be8a310a55856fd2c369dade08088d85df3b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/f8b8be8a.failed

Introduce FTRACE_OPS_FL_IPMODIFY to avoid conflict among
ftrace users who may modify regs->ip to change the execution
path. If two or more users modify the regs->ip on the same
function entry, one of them will be broken. So they must add
IPMODIFY flag and make sure that ftrace_set_filter_ip() succeeds.

Note that ftrace doesn't allow ftrace_ops which has IPMODIFY
flag to have notrace hash, and the ftrace_ops must have a
filter hash (so that the ftrace_ops can hook only specific
entries), because it strongly depends on the address and
must be allowed for only few selected functions.

Link: http://lkml.kernel.org/r/20141121102516.11844.27829.stgit@localhost.localdomain

	Cc: Jiri Kosina <jkosina@suse.cz>
	Cc: Seth Jennings <sjenning@redhat.com>
	Cc: Petr Mladek <pmladek@suse.cz>
	Cc: Vojtech Pavlik <vojtech@suse.cz>
	Cc: Miroslav Benes <mbenes@suse.cz>
	Cc: Ingo Molnar <mingo@kernel.org>
	Cc: Ananth N Mavinakayanahalli <ananth@in.ibm.com>
	Cc: Josh Poimboeuf <jpoimboe@redhat.com>
	Cc: Namhyung Kim <namhyung@kernel.org>
	Signed-off-by: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
[ fixed up some of the comments ]
	Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
(cherry picked from commit f8b8be8a310a55856fd2c369dade08088d85df3b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/ftrace.h
#	kernel/trace/ftrace.c
diff --cc include/linux/ftrace.h
index c3ee50acf41b,ed501953f0b2..000000000000
--- a/include/linux/ftrace.h
+++ b/include/linux/ftrace.h
@@@ -59,11 -59,15 +59,16 @@@ typedef void (*ftrace_func_t)(unsigned 
  /*
   * FTRACE_OPS_FL_* bits denote the state of ftrace_ops struct and are
   * set in the flags member.
+  * CONTROL, SAVE_REGS, SAVE_REGS_IF_SUPPORTED, RECURSION_SAFE, STUB and
+  * IPMODIFY are a kind of attribute flags which can be set only before
+  * registering the ftrace_ops, and can not be modified while registered.
+  * Changing those attribute flags after regsitering ftrace_ops will
+  * cause unexpected results.
   *
   * ENABLED - set/unset when ftrace_ops is registered/unregistered
 + * GLOBAL  - set manualy by ftrace_ops user to denote the ftrace_ops
 + *           is part of the global tracers sharing the same filter
 + *           via set_ftrace_* debugfs files.
   * DYNAMIC - set when ftrace_ops is registered to denote dynamically
   *           allocated ftrace_ops which need special care
   * CONTROL - set manualy by ftrace_ops user to denote the ftrace_ops
@@@ -91,19 -95,59 +96,53 @@@
   * STUB   - The ftrace_ops is just a place holder.
   * INITIALIZED - The ftrace_ops has already been initialized (first use time
   *            register_ftrace_function() is called, it will initialized the ops)
++<<<<<<< HEAD
 + */
 +enum {
 +	FTRACE_OPS_FL_ENABLED			= 1 << 0,
 +	FTRACE_OPS_FL_GLOBAL			= 1 << 1,
 +	FTRACE_OPS_FL_DYNAMIC			= 1 << 2,
 +	FTRACE_OPS_FL_CONTROL			= 1 << 3,
 +	FTRACE_OPS_FL_SAVE_REGS			= 1 << 4,
 +	FTRACE_OPS_FL_SAVE_REGS_IF_SUPPORTED	= 1 << 5,
 +	FTRACE_OPS_FL_RECURSION_SAFE		= 1 << 6,
 +	FTRACE_OPS_FL_STUB			= 1 << 7,
 +	FTRACE_OPS_FL_INITIALIZED		= 1 << 8,
++=======
+  * DELETED - The ops are being deleted, do not let them be registered again.
+  * ADDING  - The ops is in the process of being added.
+  * REMOVING - The ops is in the process of being removed.
+  * MODIFYING - The ops is in the process of changing its filter functions.
+  * ALLOC_TRAMP - A dynamic trampoline was allocated by the core code.
+  *            The arch specific code sets this flag when it allocated a
+  *            trampoline. This lets the arch know that it can update the
+  *            trampoline in case the callback function changes.
+  *            The ftrace_ops trampoline can be set by the ftrace users, and
+  *            in such cases the arch must not modify it. Only the arch ftrace
+  *            core code should set this flag.
+  * IPMODIFY - The ops can modify the IP register. This can only be set with
+  *            SAVE_REGS. If another ops with this flag set is already registered
+  *            for any of the functions that this ops will be registered for, then
+  *            this ops will fail to register or set_filter_ip.
+  */
+ enum {
+ 	FTRACE_OPS_FL_ENABLED			= 1 << 0,
+ 	FTRACE_OPS_FL_DYNAMIC			= 1 << 1,
+ 	FTRACE_OPS_FL_CONTROL			= 1 << 2,
+ 	FTRACE_OPS_FL_SAVE_REGS			= 1 << 3,
+ 	FTRACE_OPS_FL_SAVE_REGS_IF_SUPPORTED	= 1 << 4,
+ 	FTRACE_OPS_FL_RECURSION_SAFE		= 1 << 5,
+ 	FTRACE_OPS_FL_STUB			= 1 << 6,
+ 	FTRACE_OPS_FL_INITIALIZED		= 1 << 7,
+ 	FTRACE_OPS_FL_DELETED			= 1 << 8,
+ 	FTRACE_OPS_FL_ADDING			= 1 << 9,
+ 	FTRACE_OPS_FL_REMOVING			= 1 << 10,
+ 	FTRACE_OPS_FL_MODIFYING			= 1 << 11,
+ 	FTRACE_OPS_FL_ALLOC_TRAMP		= 1 << 12,
+ 	FTRACE_OPS_FL_IPMODIFY			= 1 << 13,
++>>>>>>> f8b8be8a310a (ftrace, kprobes: Support IPMODIFY flag to find IP modify conflict)
  };
  
 -#ifdef CONFIG_DYNAMIC_FTRACE
 -/* The hash used to know what functions callbacks trace */
 -struct ftrace_ops_hash {
 -	struct ftrace_hash		*notrace_hash;
 -	struct ftrace_hash		*filter_hash;
 -	struct mutex			regex_lock;
 -};
 -#endif
 -
 -/*
 - * Note, ftrace_ops can be referenced outside of RCU protection.
 - * (Although, for perf, the control ops prevent that). If ftrace_ops is
 - * allocated and not part of kernel core data, the unregistering of it will
 - * perform a scheduling on all CPUs to make sure that there are no more users.
 - * Depending on the load of the system that may take a bit of time.
 - *
 - * Any private data added must also take care not to be freed and if private
 - * data is added to a ftrace_ops that is in core code, the user of the
 - * ftrace_ops must perform a schedule_on_each_cpu() before freeing it.
 - */
  struct ftrace_ops {
  	ftrace_func_t			func;
  	struct ftrace_ops		*next;
@@@ -276,13 -329,16 +316,24 @@@ extern int ftrace_nr_registered_ops(voi
   * from tracing that function.
   */
  enum {
 -	FTRACE_FL_ENABLED	= (1UL << 31),
 +	FTRACE_FL_ENABLED	= (1UL << 29),
  	FTRACE_FL_REGS		= (1UL << 30),
++<<<<<<< HEAD
 +	FTRACE_FL_REGS_EN	= (1UL << 31)
 +};
 +
 +#define FTRACE_REF_MAX_SHIFT	29
 +#define FTRACE_FL_BITS		3
++=======
+ 	FTRACE_FL_REGS_EN	= (1UL << 29),
+ 	FTRACE_FL_TRAMP		= (1UL << 28),
+ 	FTRACE_FL_TRAMP_EN	= (1UL << 27),
+ 	FTRACE_FL_IPMODIFY	= (1UL << 26),
+ };
+ 
+ #define FTRACE_REF_MAX_SHIFT	26
+ #define FTRACE_FL_BITS		6
++>>>>>>> f8b8be8a310a (ftrace, kprobes: Support IPMODIFY flag to find IP modify conflict)
  #define FTRACE_FL_MASKED_BITS	((1UL << FTRACE_FL_BITS) - 1)
  #define FTRACE_FL_MASK		(FTRACE_FL_MASKED_BITS << FTRACE_REF_MAX_SHIFT)
  #define FTRACE_REF_MAX		((1UL << FTRACE_REF_MAX_SHIFT) - 1)
diff --cc kernel/trace/ftrace.c
index 979b7eac7331,929a733d302e..000000000000
--- a/kernel/trace/ftrace.c
+++ b/kernel/trace/ftrace.c
@@@ -1318,10 -1354,13 +1318,13 @@@ alloc_and_copy_ftrace_hash(int size_bit
  }
  
  static void
 -ftrace_hash_rec_disable_modify(struct ftrace_ops *ops, int filter_hash);
 +ftrace_hash_rec_disable(struct ftrace_ops *ops, int filter_hash);
  static void
 -ftrace_hash_rec_enable_modify(struct ftrace_ops *ops, int filter_hash);
 +ftrace_hash_rec_enable(struct ftrace_ops *ops, int filter_hash);
  
+ static int ftrace_hash_ipmodify_update(struct ftrace_ops *ops,
+ 				       struct ftrace_hash *new_hash);
+ 
  static int
  ftrace_hash_move(struct ftrace_ops *ops, int enable,
  		 struct ftrace_hash **dst, struct ftrace_hash *src)
@@@ -1615,6 -1750,149 +1633,152 @@@ static void ftrace_hash_rec_enable(stru
  	__ftrace_hash_rec_update(ops, filter_hash, 1);
  }
  
++<<<<<<< HEAD
++=======
+ static void ftrace_hash_rec_update_modify(struct ftrace_ops *ops,
+ 					  int filter_hash, int inc)
+ {
+ 	struct ftrace_ops *op;
+ 
+ 	__ftrace_hash_rec_update(ops, filter_hash, inc);
+ 
+ 	if (ops->func_hash != &global_ops.local_hash)
+ 		return;
+ 
+ 	/*
+ 	 * If the ops shares the global_ops hash, then we need to update
+ 	 * all ops that are enabled and use this hash.
+ 	 */
+ 	do_for_each_ftrace_op(op, ftrace_ops_list) {
+ 		/* Already done */
+ 		if (op == ops)
+ 			continue;
+ 		if (op->func_hash == &global_ops.local_hash)
+ 			__ftrace_hash_rec_update(op, filter_hash, inc);
+ 	} while_for_each_ftrace_op(op);
+ }
+ 
+ static void ftrace_hash_rec_disable_modify(struct ftrace_ops *ops,
+ 					   int filter_hash)
+ {
+ 	ftrace_hash_rec_update_modify(ops, filter_hash, 0);
+ }
+ 
+ static void ftrace_hash_rec_enable_modify(struct ftrace_ops *ops,
+ 					  int filter_hash)
+ {
+ 	ftrace_hash_rec_update_modify(ops, filter_hash, 1);
+ }
+ 
+ /*
+  * Try to update IPMODIFY flag on each ftrace_rec. Return 0 if it is OK
+  * or no-needed to update, -EBUSY if it detects a conflict of the flag
+  * on a ftrace_rec, and -EINVAL if the new_hash tries to trace all recs.
+  * Note that old_hash and new_hash has below meanings
+  *  - If the hash is NULL, it hits all recs (if IPMODIFY is set, this is rejected)
+  *  - If the hash is EMPTY_HASH, it hits nothing
+  *  - Anything else hits the recs which match the hash entries.
+  */
+ static int __ftrace_hash_update_ipmodify(struct ftrace_ops *ops,
+ 					 struct ftrace_hash *old_hash,
+ 					 struct ftrace_hash *new_hash)
+ {
+ 	struct ftrace_page *pg;
+ 	struct dyn_ftrace *rec, *end = NULL;
+ 	int in_old, in_new;
+ 
+ 	/* Only update if the ops has been registered */
+ 	if (!(ops->flags & FTRACE_OPS_FL_ENABLED))
+ 		return 0;
+ 
+ 	if (!(ops->flags & FTRACE_OPS_FL_IPMODIFY))
+ 		return 0;
+ 
+ 	/*
+ 	 * Since the IPMODIFY is a very address sensitive action, we do not
+ 	 * allow ftrace_ops to set all functions to new hash.
+ 	 */
+ 	if (!new_hash || !old_hash)
+ 		return -EINVAL;
+ 
+ 	/* Update rec->flags */
+ 	do_for_each_ftrace_rec(pg, rec) {
+ 		/* We need to update only differences of filter_hash */
+ 		in_old = !!ftrace_lookup_ip(old_hash, rec->ip);
+ 		in_new = !!ftrace_lookup_ip(new_hash, rec->ip);
+ 		if (in_old == in_new)
+ 			continue;
+ 
+ 		if (in_new) {
+ 			/* New entries must ensure no others are using it */
+ 			if (rec->flags & FTRACE_FL_IPMODIFY)
+ 				goto rollback;
+ 			rec->flags |= FTRACE_FL_IPMODIFY;
+ 		} else /* Removed entry */
+ 			rec->flags &= ~FTRACE_FL_IPMODIFY;
+ 	} while_for_each_ftrace_rec();
+ 
+ 	return 0;
+ 
+ rollback:
+ 	end = rec;
+ 
+ 	/* Roll back what we did above */
+ 	do_for_each_ftrace_rec(pg, rec) {
+ 		if (rec == end)
+ 			goto err_out;
+ 
+ 		in_old = !!ftrace_lookup_ip(old_hash, rec->ip);
+ 		in_new = !!ftrace_lookup_ip(new_hash, rec->ip);
+ 		if (in_old == in_new)
+ 			continue;
+ 
+ 		if (in_new)
+ 			rec->flags &= ~FTRACE_FL_IPMODIFY;
+ 		else
+ 			rec->flags |= FTRACE_FL_IPMODIFY;
+ 	} while_for_each_ftrace_rec();
+ 
+ err_out:
+ 	return -EBUSY;
+ }
+ 
+ static int ftrace_hash_ipmodify_enable(struct ftrace_ops *ops)
+ {
+ 	struct ftrace_hash *hash = ops->func_hash->filter_hash;
+ 
+ 	if (ftrace_hash_empty(hash))
+ 		hash = NULL;
+ 
+ 	return __ftrace_hash_update_ipmodify(ops, EMPTY_HASH, hash);
+ }
+ 
+ /* Disabling always succeeds */
+ static void ftrace_hash_ipmodify_disable(struct ftrace_ops *ops)
+ {
+ 	struct ftrace_hash *hash = ops->func_hash->filter_hash;
+ 
+ 	if (ftrace_hash_empty(hash))
+ 		hash = NULL;
+ 
+ 	__ftrace_hash_update_ipmodify(ops, hash, EMPTY_HASH);
+ }
+ 
+ static int ftrace_hash_ipmodify_update(struct ftrace_ops *ops,
+ 				       struct ftrace_hash *new_hash)
+ {
+ 	struct ftrace_hash *old_hash = ops->func_hash->filter_hash;
+ 
+ 	if (ftrace_hash_empty(old_hash))
+ 		old_hash = NULL;
+ 
+ 	if (ftrace_hash_empty(new_hash))
+ 		new_hash = NULL;
+ 
+ 	return __ftrace_hash_update_ipmodify(ops, old_hash, new_hash);
+ }
+ 
++>>>>>>> f8b8be8a310a (ftrace, kprobes: Support IPMODIFY flag to find IP modify conflict)
  static void print_ip_ins(const char *fmt, unsigned char *p)
  {
  	int i;
@@@ -2033,18 -2552,26 +2197,31 @@@ static int ftrace_startup(struct ftrace
  	ftrace_start_up++;
  	command |= FTRACE_UPDATE_CALLS;
  
 -	/*
 -	 * Note that ftrace probes uses this to start up
 -	 * and modify functions it will probe. But we still
 -	 * set the ADDING flag for modification, as probes
 -	 * do not have trampolines. If they add them in the
 -	 * future, then the probes will need to distinguish
 -	 * between adding and updating probes.
 -	 */
 -	ops->flags |= FTRACE_OPS_FL_ENABLED | FTRACE_OPS_FL_ADDING;
 +	/* ops marked global share the filter hashes */
 +	if (ops->flags & FTRACE_OPS_FL_GLOBAL) {
 +		ops = &global_ops;
 +		/* Don't update hash if global is already set */
 +		if (global_start_up)
 +			hash_enable = false;
 +		global_start_up++;
 +	}
  
++<<<<<<< HEAD
 +	ops->flags |= FTRACE_OPS_FL_ENABLED;
 +	if (hash_enable)
 +		ftrace_hash_rec_enable(ops, 1);
++=======
+ 	ret = ftrace_hash_ipmodify_enable(ops);
+ 	if (ret < 0) {
+ 		/* Rollback registration process */
+ 		__unregister_ftrace_function(ops);
+ 		ftrace_start_up--;
+ 		ops->flags &= ~FTRACE_OPS_FL_ENABLED;
+ 		return ret;
+ 	}
+ 
+ 	ftrace_hash_rec_enable(ops, 1);
++>>>>>>> f8b8be8a310a (ftrace, kprobes: Support IPMODIFY flag to find IP modify conflict)
  
  	ftrace_startup_enable(command);
  
@@@ -2071,22 -2599,11 +2248,28 @@@ static int ftrace_shutdown(struct ftrac
  	 */
  	WARN_ON_ONCE(ftrace_start_up < 0);
  
++<<<<<<< HEAD
 +	if (ops->flags & FTRACE_OPS_FL_GLOBAL) {
 +		ops = &global_ops;
 +		global_start_up--;
 +		WARN_ON_ONCE(global_start_up < 0);
 +		/* Don't update hash if global still has users */
 +		if (global_start_up) {
 +			WARN_ON_ONCE(!ftrace_start_up);
 +			hash_disable = false;
 +		}
 +	}
++=======
+ 	/* Disabling ipmodify never fails */
+ 	ftrace_hash_ipmodify_disable(ops);
+ 	ftrace_hash_rec_disable(ops, 1);
++>>>>>>> f8b8be8a310a (ftrace, kprobes: Support IPMODIFY flag to find IP modify conflict)
  
 -	ops->flags &= ~FTRACE_OPS_FL_ENABLED;
 +	if (hash_disable)
 +		ftrace_hash_rec_disable(ops, 1);
 +
 +	if (ops != &global_ops || !global_start_up)
 +		ops->flags &= ~FTRACE_OPS_FL_ENABLED;
  
  	command |= FTRACE_UPDATE_CALLS;
  
@@@ -2607,11 -3192,26 +2790,34 @@@ static int t_show(struct seq_file *m, v
  		return 0;
  
  	seq_printf(m, "%ps", (void *)rec->ip);
++<<<<<<< HEAD
 +	if (iter->flags & FTRACE_ITER_ENABLED)
 +		seq_printf(m, " (%ld)%s",
 +			   rec->flags & ~FTRACE_FL_MASK,
 +			   rec->flags & FTRACE_FL_REGS ? " R" : "");
 +	seq_printf(m, "\n");
++=======
+ 	if (iter->flags & FTRACE_ITER_ENABLED) {
+ 		struct ftrace_ops *ops = NULL;
+ 
+ 		seq_printf(m, " (%ld)%s%s",
+ 			   ftrace_rec_count(rec),
+ 			   rec->flags & FTRACE_FL_REGS ? " R" : "  ",
+ 			   rec->flags & FTRACE_FL_IPMODIFY ? " I" : "  ");
+ 		if (rec->flags & FTRACE_FL_TRAMP_EN) {
+ 			ops = ftrace_find_tramp_ops_any(rec);
+ 			if (ops)
+ 				seq_printf(m, "\ttramp: %pS",
+ 					   (void *)ops->trampoline);
+ 			else
+ 				seq_puts(m, "\ttramp: ERROR!");
+ 
+ 		}
+ 		add_trampoline_func(m, ops, rec);
+ 	}	
+ 
+ 	seq_putc(m, '\n');
++>>>>>>> f8b8be8a310a (ftrace, kprobes: Support IPMODIFY flag to find IP modify conflict)
  
  	return 0;
  }
diff --git a/Documentation/trace/ftrace.txt b/Documentation/trace/ftrace.txt
index b937c6e2163c..4501cfe59339 100644
--- a/Documentation/trace/ftrace.txt
+++ b/Documentation/trace/ftrace.txt
@@ -234,6 +234,11 @@ of ftrace. Here is a list of some of the key files:
 	will be displayed on the same line as the function that
 	is returning registers.
 
+	If the callback registered to be traced by a function with
+	the "ip modify" attribute (thus the regs->ip can be changed),
+	an 'I' will be displayed on the same line as the function that
+	can be overridden.
+
   function_profile_enabled:
 
 	When set it will enable all functions with either the function
* Unmerged path include/linux/ftrace.h
* Unmerged path kernel/trace/ftrace.c
