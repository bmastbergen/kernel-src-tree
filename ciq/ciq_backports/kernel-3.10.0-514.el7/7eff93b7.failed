devm_memremap_pages: use numa_mem_id

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Dan Williams <dan.j.williams@intel.com>
commit 7eff93b7c99f5d0024aee677c6c92e32af22e1d2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/7eff93b7.failed

Hint to closest numa node for the placement of newly allocated pages.
As that is where the device's other allocations will originate by
default when it does not specify a NUMA node.

	Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
	Reviewed-by: Tejun Heo <tj@kernel.org>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
(cherry picked from commit 7eff93b7c99f5d0024aee677c6c92e32af22e1d2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/memremap.c
diff --cc kernel/memremap.c
index 26717809cbd2,56fc4783879c..000000000000
--- a/kernel/memremap.c
+++ b/kernel/memremap.c
@@@ -144,3 -135,55 +144,58 @@@ void devm_memunmap(struct device *dev, 
  				devm_memremap_match, addr));
  }
  EXPORT_SYMBOL(devm_memunmap);
++<<<<<<< HEAD
++=======
+ 
+ #ifdef CONFIG_ZONE_DEVICE
+ struct page_map {
+ 	struct resource res;
+ };
+ 
+ static void devm_memremap_pages_release(struct device *dev, void *res)
+ {
+ 	struct page_map *page_map = res;
+ 
+ 	/* pages are dead and unused, undo the arch mapping */
+ 	arch_remove_memory(page_map->res.start, resource_size(&page_map->res));
+ }
+ 
+ void *devm_memremap_pages(struct device *dev, struct resource *res)
+ {
+ 	int is_ram = region_intersects(res->start, resource_size(res),
+ 			"System RAM");
+ 	struct page_map *page_map;
+ 	int error, nid;
+ 
+ 	if (is_ram == REGION_MIXED) {
+ 		WARN_ONCE(1, "%s attempted on mixed region %pr\n",
+ 				__func__, res);
+ 		return ERR_PTR(-ENXIO);
+ 	}
+ 
+ 	if (is_ram == REGION_INTERSECTS)
+ 		return __va(res->start);
+ 
+ 	page_map = devres_alloc(devm_memremap_pages_release,
+ 			sizeof(*page_map), GFP_KERNEL);
+ 	if (!page_map)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	memcpy(&page_map->res, res, sizeof(*res));
+ 
+ 	nid = dev_to_node(dev);
+ 	if (nid < 0)
+ 		nid = numa_mem_id();
+ 
+ 	error = arch_add_memory(nid, res->start, resource_size(res), true);
+ 	if (error) {
+ 		devres_free(page_map);
+ 		return ERR_PTR(error);
+ 	}
+ 
+ 	devres_add(dev, page_map);
+ 	return __va(res->start);
+ }
+ EXPORT_SYMBOL(devm_memremap_pages);
+ #endif /* CONFIG_ZONE_DEVICE */
++>>>>>>> 7eff93b7c99f (devm_memremap_pages: use numa_mem_id)
* Unmerged path kernel/memremap.c
