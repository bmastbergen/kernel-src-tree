staging/rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [infiniband] rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type (Alex Estrin) [1272062 1273170]
Rebuild_FUZZ: 92.73%
commit-author Dennis Dalessandro <dennis.dalessandro@intel.com>
commit 895420ddc8b35099ddd25132f5707306e70f0d6a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/895420dd.failed

This patch does the actual removal of the queue pair from the hfi1 driver
along with a number of dependent data structures. These were moved to rvt.

It also removes the MR functions to use those in rdmavt.

These two pieces can not reasonably be split apart becuase they depend on
each other.

	Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
	Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 895420ddc8b35099ddd25132f5707306e70f0d6a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/staging/hfi1/Makefile
#	drivers/staging/hfi1/driver.c
#	drivers/staging/hfi1/keys.c
#	drivers/staging/hfi1/mr.c
#	drivers/staging/hfi1/ruc.c
#	drivers/staging/hfi1/verbs.c
#	drivers/staging/hfi1/verbs.h
diff --cc drivers/staging/hfi1/Makefile
index 2e5daa6cdcc2,d82d9dc97c39..000000000000
--- a/drivers/staging/hfi1/Makefile
+++ b/drivers/staging/hfi1/Makefile
@@@ -7,10 -7,10 +7,15 @@@
  #
  obj-$(CONFIG_INFINIBAND_HFI1) += hfi1.o
  
++<<<<<<< HEAD:drivers/staging/hfi1/Makefile
 +hfi1-y := chip.o cq.o device.o diag.o dma.o driver.o eprom.o file_ops.o firmware.o \
 +	init.o intr.o keys.o mad.o mmap.o mr.o pcie.o pio.o pio_copy.o \
++=======
+ hfi1-y := chip.o cq.o device.o diag.o driver.o efivar.o eprom.o file_ops.o firmware.o \
+ 	init.o intr.o mad.o mmap.o pcie.o pio.o pio_copy.o \
++>>>>>>> 895420ddc8b3 (staging/rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type):drivers/staging/rdma/hfi1/Makefile
  	qp.o qsfp.o rc.o ruc.o sdma.o srq.o sysfs.o trace.o twsi.o \
 -	uc.o ud.o user_exp_rcv.o user_pages.o user_sdma.o verbs_mcast.o verbs.o
 +	uc.o ud.o user_pages.o user_sdma.o verbs_mcast.o verbs.o
  hfi1-$(CONFIG_DEBUG_FS) += debugfs.o
  
  CFLAGS_trace.o = -I$(src)
diff --cc drivers/staging/hfi1/driver.c
index fca20e92c79b,eaed692ba575..000000000000
--- a/drivers/staging/hfi1/driver.c
+++ b/drivers/staging/hfi1/driver.c
@@@ -300,8 -317,8 +300,13 @@@ static void rcv_hdrerr(struct hfi1_ctxt
  
  		/* Get the destination QP number. */
  		qp_num = be32_to_cpu(ohdr->bth[1]) & HFI1_QPN_MASK;
++<<<<<<< HEAD:drivers/staging/hfi1/driver.c
 +		if (lid < HFI1_MULTICAST_LID_BASE) {
 +			struct hfi1_qp *qp;
++=======
+ 		if (lid < be16_to_cpu(IB_MULTICAST_LID_BASE)) {
+ 			struct rvt_qp *qp;
++>>>>>>> 895420ddc8b3 (staging/rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type):drivers/staging/rdma/hfi1/driver.c
  			unsigned long flags;
  
  			rcu_read_lock();
@@@ -368,9 -385,9 +373,9 @@@
  		if (opcode == IB_OPCODE_CNP) {
  			/*
  			 * Only in pre-B0 h/w is the CNP_OPCODE handled
 -			 * via this code path.
 +			 * via this code path (errata 291394).
  			 */
- 			struct hfi1_qp *qp = NULL;
+ 			struct rvt_qp *qp = NULL;
  			u32 lqpn, rqpn;
  			u16 rlid;
  			u8 svc_type, sl, sc5;
diff --cc drivers/staging/hfi1/ruc.c
index c4280b6f47d4,762fca9d9ad4..000000000000
--- a/drivers/staging/hfi1/ruc.c
+++ b/drivers/staging/hfi1/ruc.c
@@@ -461,11 -461,10 +461,18 @@@ again
  		if (unlikely(!(qp->qp_access_flags & IB_ACCESS_REMOTE_WRITE)))
  			goto inv_err;
  		if (wqe->length == 0)
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +			break;
 +		if (unlikely(!hfi1_rkey_ok(qp, &qp->r_sge.sge, wqe->length,
 +					   wqe->wr.wr.rdma.remote_addr,
 +					   wqe->wr.wr.rdma.rkey,
 +					   IB_ACCESS_REMOTE_WRITE)))
++=======
+ 		if (unlikely(!rvt_rkey_ok(qp, &qp->r_sge.sge, wqe->length,
+ 					  wqe->rdma_wr.remote_addr,
+ 					  wqe->rdma_wr.rkey,
+ 					  IB_ACCESS_REMOTE_WRITE)))
++>>>>>>> 895420ddc8b3 (staging/rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type):drivers/staging/rdma/hfi1/ruc.c
  			goto acc_err;
  		qp->r_sge.sg_list = NULL;
  		qp->r_sge.num_sge = 1;
@@@ -475,10 -474,10 +482,17 @@@
  	case IB_WR_RDMA_READ:
  		if (unlikely(!(qp->qp_access_flags & IB_ACCESS_REMOTE_READ)))
  			goto inv_err;
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +		if (unlikely(!hfi1_rkey_ok(qp, &sqp->s_sge.sge, wqe->length,
 +					   wqe->wr.wr.rdma.remote_addr,
 +					   wqe->wr.wr.rdma.rkey,
 +					   IB_ACCESS_REMOTE_READ)))
++=======
+ 		if (unlikely(!rvt_rkey_ok(qp, &sqp->s_sge.sge, wqe->length,
+ 					  wqe->rdma_wr.remote_addr,
+ 					  wqe->rdma_wr.rkey,
+ 					  IB_ACCESS_REMOTE_READ)))
++>>>>>>> 895420ddc8b3 (staging/rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type):drivers/staging/rdma/hfi1/ruc.c
  			goto acc_err;
  		release = 0;
  		sqp->s_sge.sg_list = NULL;
@@@ -493,10 -492,10 +507,17 @@@
  	case IB_WR_ATOMIC_FETCH_AND_ADD:
  		if (unlikely(!(qp->qp_access_flags & IB_ACCESS_REMOTE_ATOMIC)))
  			goto inv_err;
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +		if (unlikely(!hfi1_rkey_ok(qp, &qp->r_sge.sge, sizeof(u64),
 +					   wqe->wr.wr.atomic.remote_addr,
 +					   wqe->wr.wr.atomic.rkey,
 +					   IB_ACCESS_REMOTE_ATOMIC)))
++=======
+ 		if (unlikely(!rvt_rkey_ok(qp, &qp->r_sge.sge, sizeof(u64),
+ 					  wqe->atomic_wr.remote_addr,
+ 					  wqe->atomic_wr.rkey,
+ 					  IB_ACCESS_REMOTE_ATOMIC)))
++>>>>>>> 895420ddc8b3 (staging/rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type):drivers/staging/rdma/hfi1/ruc.c
  			goto acc_err;
  		/* Perform atomic OP and save result. */
  		maddr = (atomic64_t *) qp->r_sge.sge.vaddr;
@@@ -505,8 -504,8 +526,13 @@@
  			(wqe->wr.opcode == IB_WR_ATOMIC_FETCH_AND_ADD) ?
  			(u64) atomic64_add_return(sdata, maddr) - sdata :
  			(u64) cmpxchg((u64 *) qp->r_sge.sge.vaddr,
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +				      sdata, wqe->wr.wr.atomic.swap);
 +		hfi1_put_mr(qp->r_sge.sge.mr);
++=======
+ 				      sdata, wqe->atomic_wr.swap);
+ 		rvt_put_mr(qp->r_sge.sge.mr);
++>>>>>>> 895420ddc8b3 (staging/rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type):drivers/staging/rdma/hfi1/ruc.c
  		qp->r_sge.num_sge = 0;
  		goto send_comp;
  
diff --cc drivers/staging/hfi1/verbs.c
index cfa74cbcf382,10d6547037d0..000000000000
--- a/drivers/staging/hfi1/verbs.c
+++ b/drivers/staging/hfi1/verbs.c
@@@ -414,10 -412,24 +414,10 @@@ static int post_one_send(struct rvt_qp 
  	if (next == qp->s_last)
  		return -ENOMEM;
  
- 	rkt = &to_idev(qp->ibqp.device)->lk_table;
+ 	rkt = &to_idev(qp->ibqp.device)->rdi.lkey_table;
  	pd = ibpd_to_rvtpd(qp->ibqp.pd);
  	wqe = get_swqe_ptr(qp, qp->s_head);
 -
 -
 -	if (qp->ibqp.qp_type != IB_QPT_UC &&
 -	    qp->ibqp.qp_type != IB_QPT_RC)
 -		memcpy(&wqe->ud_wr, ud_wr(wr), sizeof(wqe->ud_wr));
 -	else if (wr->opcode == IB_WR_RDMA_WRITE_WITH_IMM ||
 -		 wr->opcode == IB_WR_RDMA_WRITE ||
 -		 wr->opcode == IB_WR_RDMA_READ)
 -		memcpy(&wqe->rdma_wr, rdma_wr(wr), sizeof(wqe->rdma_wr));
 -	else if (wr->opcode == IB_WR_ATOMIC_CMP_AND_SWP ||
 -		 wr->opcode == IB_WR_ATOMIC_FETCH_AND_ADD)
 -		memcpy(&wqe->atomic_wr, atomic_wr(wr), sizeof(wqe->atomic_wr));
 -	else
 -		memcpy(&wqe->wr, wr, sizeof(wqe->wr));
 -
 +	wqe->wr = *wr;
  	wqe->length = 0;
  	j = 0;
  	if (wr->num_sge) {
@@@ -1849,9 -1770,9 +1849,9 @@@ static void verbs_txreq_kmem_cache_ctor
  int hfi1_register_ib_device(struct hfi1_devdata *dd)
  {
  	struct hfi1_ibdev *dev = &dd->verbs_dev;
 -	struct ib_device *ibdev = &dev->rdi.ibdev;
 +	struct ib_device *ibdev = &dev->ibdev;
  	struct hfi1_pportdata *ppd = dd->pport;
- 	unsigned i, lk_tab_size;
+ 	unsigned i;
  	int ret;
  	size_t lcpysz = IB_DEVICE_NAME_MAX;
  	u16 descq_cnt;
@@@ -1997,17 -1894,15 +1974,29 @@@
  	ibdev->resize_cq = hfi1_resize_cq;
  	ibdev->poll_cq = hfi1_poll_cq;
  	ibdev->req_notify_cq = hfi1_req_notify_cq;
++<<<<<<< HEAD:drivers/staging/hfi1/verbs.c
 +	ibdev->get_dma_mr = hfi1_get_dma_mr;
 +	ibdev->reg_phys_mr = hfi1_reg_phys_mr;
 +	ibdev->reg_user_mr = hfi1_reg_user_mr;
 +	ibdev->dereg_mr = hfi1_dereg_mr;
 +	ibdev->alloc_mr = hfi1_alloc_mr;
 +	ibdev->alloc_fast_reg_page_list = hfi1_alloc_fast_reg_page_list;
 +	ibdev->free_fast_reg_page_list = hfi1_free_fast_reg_page_list;
 +	ibdev->alloc_fmr = hfi1_alloc_fmr;
 +	ibdev->map_phys_fmr = hfi1_map_phys_fmr;
 +	ibdev->unmap_fmr = hfi1_unmap_fmr;
 +	ibdev->dealloc_fmr = hfi1_dealloc_fmr;
++=======
+ 	ibdev->get_dma_mr = NULL;
+ 	ibdev->reg_user_mr = NULL;
+ 	ibdev->dereg_mr = NULL;
+ 	ibdev->alloc_mr = NULL;
+ 	ibdev->map_mr_sg = NULL;
+ 	ibdev->alloc_fmr = NULL;
+ 	ibdev->map_phys_fmr = NULL;
+ 	ibdev->unmap_fmr = NULL;
+ 	ibdev->dealloc_fmr = NULL;
++>>>>>>> 895420ddc8b3 (staging/rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type):drivers/staging/rdma/hfi1/verbs.c
  	ibdev->attach_mcast = hfi1_multicast_attach;
  	ibdev->detach_mcast = hfi1_multicast_detach;
  	ibdev->process_mad = hfi1_process_mad;
@@@ -2018,7 -1913,21 +2007,25 @@@
  	strncpy(ibdev->node_desc, init_utsname()->nodename,
  		sizeof(ibdev->node_desc));
  
++<<<<<<< HEAD:drivers/staging/hfi1/verbs.c
 +	ret = ib_register_device(ibdev, hfi1_create_port_files);
++=======
+ 	/*
+ 	 * Fill in rvt info object.
+ 	 */
+ 	dd->verbs_dev.rdi.driver_f.port_callback = hfi1_create_port_files;
+ 	dd->verbs_dev.rdi.driver_f.get_card_name = get_card_name;
+ 	dd->verbs_dev.rdi.driver_f.get_pci_dev = get_pci_dev;
+ 	dd->verbs_dev.rdi.driver_f.check_ah = hfi1_check_ah;
+ 	dd->verbs_dev.rdi.driver_f.notify_new_ah = hfi1_notify_new_ah;
+ 	dd->verbs_dev.rdi.dparms.props.max_ah = hfi1_max_ahs;
+ 	dd->verbs_dev.rdi.dparms.props.max_pd = hfi1_max_pds;
+ 	dd->verbs_dev.rdi.flags = (RVT_FLAG_QP_INIT_DRIVER |
+ 				   RVT_FLAG_CQ_INIT_DRIVER);
+ 	dd->verbs_dev.rdi.dparms.lkey_table_size = hfi1_lkey_table_size;
+ 
+ 	ret = rvt_register_device(&dd->verbs_dev.rdi);
++>>>>>>> 895420ddc8b3 (staging/rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type):drivers/staging/rdma/hfi1/verbs.c
  	if (ret)
  		goto err_reg;
  
diff --cc drivers/staging/hfi1/verbs.h
index 34fa7beced4f,0782a85f5d28..000000000000
--- a/drivers/staging/hfi1/verbs.h
+++ b/drivers/staging/hfi1/verbs.h
@@@ -233,27 -234,6 +233,13 @@@ struct hfi1_mcast 
  	int n_attached;
  };
  
 +/* Address Handle */
 +struct hfi1_ah {
 +	struct ib_ah ibah;
 +	struct ib_ah_attr attr;
 +	atomic_t refcount;
 +};
 +
- /*
-  * This structure is used by hfi1_mmap() to validate an offset
-  * when an mmap() request is made.  The vm_area_struct then uses
-  * this as its vm_private_data.
-  */
- struct hfi1_mmap_info {
- 	struct list_head pending_mmaps;
- 	struct ib_ucontext *context;
- 	void *obj;
- 	__u64 offset;
- 	struct kref ref;
- 	unsigned size;
- };
- 
  /*
   * This structure is used to contain the head pointer, tail pointer,
   * and completion queue entries as a single memory allocation so
@@@ -280,74 -260,7 +266,78 @@@ struct hfi1_cq 
  	u8 notify;
  	u8 triggered;
  	struct hfi1_cq_wc *queue;
++<<<<<<< HEAD:drivers/staging/hfi1/verbs.h
 +	struct hfi1_mmap_info *ip;
 +};
 +
 +/*
 + * These keep track of the copy progress within a memory region.
 + * Used by the verbs layer.
 + */
 +struct hfi1_sge {
 +	struct rvt_mregion *mr;
 +	void *vaddr;            /* kernel virtual address of segment */
 +	u32 sge_length;         /* length of the SGE */
 +	u32 length;             /* remaining length of the segment */
 +	u16 m;                  /* current index: mr->map[m] */
 +	u16 n;                  /* current index: mr->map[m]->segs[n] */
 +};
 +
 +/* Memory region */
 +struct hfi1_mr {
 +	struct ib_mr ibmr;
 +	struct ib_umem *umem;
 +	struct rvt_mregion mr;  /* must be last */
 +};
 +
 +/*
 + * Send work request queue entry.
 + * The size of the sg_list is determined when the QP is created and stored
 + * in qp->s_max_sge.
 + */
 +struct hfi1_swqe {
 +	struct ib_send_wr wr;   /* don't use wr.sg_list */
 +	u32 psn;                /* first packet sequence number */
 +	u32 lpsn;               /* last packet sequence number */
 +	u32 ssn;                /* send sequence number */
 +	u32 length;             /* total length of data in sg_list */
 +	struct hfi1_sge sg_list[0];
 +};
 +
 +/*
 + * Receive work request queue entry.
 + * The size of the sg_list is determined when the QP (or SRQ) is created
 + * and stored in qp->r_rq.max_sge (or srq->rq.max_sge).
 + */
 +struct hfi1_rwqe {
 +	u64 wr_id;
 +	u8 num_sge;
 +	struct ib_sge sg_list[0];
 +};
 +
 +/*
 + * This structure is used to contain the head pointer, tail pointer,
 + * and receive work queue entries as a single memory allocation so
 + * it can be mmap'ed into user space.
 + * Note that the wq array elements are variable size so you can't
 + * just index into the array to get the N'th element;
 + * use get_rwqe_ptr() instead.
 + */
 +struct hfi1_rwq {
 +	u32 head;               /* new work requests posted to the head */
 +	u32 tail;               /* receives pull requests from here. */
 +	struct hfi1_rwqe wq[0];
 +};
 +
 +struct hfi1_rq {
 +	struct hfi1_rwq *wq;
 +	u32 size;               /* size of RWQE array */
 +	u8 max_sge;
 +	/* protect changes in this struct */
 +	spinlock_t lock ____cacheline_aligned_in_smp;
++=======
+ 	struct rvt_mmap_info *ip;
++>>>>>>> 895420ddc8b3 (staging/rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type):drivers/staging/rdma/hfi1/verbs.h
  };
  
  struct hfi1_srq {
@@@ -644,10 -419,10 +496,10 @@@ static inline void inc_opstats
  }
  
  struct hfi1_ibport {
- 	struct hfi1_qp __rcu *qp[2];
+ 	struct rvt_qp __rcu *qp[2];
  	struct ib_mad_agent *send_agent;	/* agent for SMI (traps) */
 -	struct rvt_ah *sm_ah;
 -	struct rvt_ah *smi_ah;
 +	struct hfi1_ah *sm_ah;
 +	struct hfi1_ah *smi_ah;
  	struct rb_root mcast_tree;
  	spinlock_t lock;		/* protect changes in this struct */
  
@@@ -763,16 -534,6 +613,19 @@@ struct hfi1_verbs_counters 
  	u32 vl15_dropped;
  };
  
++<<<<<<< HEAD:drivers/staging/hfi1/verbs.h
 +static inline struct hfi1_mr *to_imr(struct ib_mr *ibmr)
 +{
 +	return container_of(ibmr, struct hfi1_mr, ibmr);
 +}
 +
 +static inline struct hfi1_ah *to_iah(struct ib_ah *ibah)
 +{
 +	return container_of(ibah, struct hfi1_ah, ibah);
 +}
 +
++=======
++>>>>>>> 895420ddc8b3 (staging/rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type):drivers/staging/rdma/hfi1/verbs.h
  static inline struct hfi1_cq *to_icq(struct ib_cq *ibcq)
  {
  	return container_of(ibcq, struct hfi1_cq, ibcq);
@@@ -790,10 -551,13 +643,10 @@@ static inline struct rvt_qp *to_iqp(str
  
  static inline struct hfi1_ibdev *to_idev(struct ib_device *ibdev)
  {
 -	struct rvt_dev_info *rdi;
 -
 -	rdi = container_of(ibdev, struct rvt_dev_info, ibdev);
 -	return container_of(rdi, struct hfi1_ibdev, rdi);
 +	return container_of(ibdev, struct hfi1_ibdev, ibdev);
  }
  
- static inline struct hfi1_qp *iowait_to_qp(struct  iowait *s_iowait)
+ static inline struct rvt_qp *iowait_to_qp(struct  iowait *s_iowait)
  {
  	struct hfi1_qp_priv *priv;
  
@@@ -977,54 -729,10 +820,58 @@@ int hfi1_req_notify_cq
  
  int hfi1_resize_cq(struct ib_cq *ibcq, int cqe, struct ib_udata *udata);
  
++<<<<<<< HEAD:drivers/staging/hfi1/verbs.h
 +struct ib_mr *hfi1_get_dma_mr(struct ib_pd *pd, int acc);
 +
 +struct ib_mr *hfi1_reg_phys_mr(struct ib_pd *pd,
 +			       struct ib_phys_buf *buffer_list,
 +			       int num_phys_buf, int acc, u64 *iova_start);
 +
 +struct ib_mr *hfi1_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,
 +			       u64 virt_addr, int mr_access_flags,
 +			       struct ib_udata *udata);
 +
 +int hfi1_dereg_mr(struct ib_mr *ibmr);
 +
 +struct ib_mr *hfi1_alloc_mr(struct ib_pd *pd,
 +			    enum ib_mr_type mr_type,
 +			    u32 max_entries);
 +
 +struct ib_fast_reg_page_list *hfi1_alloc_fast_reg_page_list(
 +				struct ib_device *ibdev, int page_list_len);
 +
 +void hfi1_free_fast_reg_page_list(struct ib_fast_reg_page_list *pl);
 +
 +int hfi1_fast_reg_mr(struct hfi1_qp *qp, struct ib_send_wr *wr);
 +
 +struct ib_fmr *hfi1_alloc_fmr(struct ib_pd *pd, int mr_access_flags,
 +			      struct ib_fmr_attr *fmr_attr);
 +
 +int hfi1_map_phys_fmr(struct ib_fmr *ibfmr, u64 *page_list,
 +		      int list_len, u64 iova);
 +
 +int hfi1_unmap_fmr(struct list_head *fmr_list);
 +
 +int hfi1_dealloc_fmr(struct ib_fmr *ibfmr);
 +
 +static inline void hfi1_get_mr(struct rvt_mregion *mr)
 +{
 +	atomic_inc(&mr->refcount);
 +}
 +
 +static inline void hfi1_put_mr(struct rvt_mregion *mr)
 +{
 +	if (unlikely(atomic_dec_and_test(&mr->refcount)))
 +		complete(&mr->comp);
 +}
 +
 +static inline void hfi1_put_ss(struct hfi1_sge_state *ss)
++=======
+ static inline void hfi1_put_ss(struct rvt_sge_state *ss)
++>>>>>>> 895420ddc8b3 (staging/rdma/hfi1: Remove hfi1 MR and hfi1 specific qp type):drivers/staging/rdma/hfi1/verbs.h
  {
  	while (ss->num_sge) {
- 		hfi1_put_mr(ss->sge.mr);
+ 		rvt_put_mr(ss->sge.mr);
  		if (--ss->num_sge)
  			ss->sge = *ss->sg_list++;
  	}
* Unmerged path drivers/staging/hfi1/keys.c
* Unmerged path drivers/staging/hfi1/mr.c
* Unmerged path drivers/staging/hfi1/Makefile
diff --git a/drivers/staging/hfi1/cq.c b/drivers/staging/hfi1/cq.c
index 4f046ffe7e60..ffd0e7abca00 100644
--- a/drivers/staging/hfi1/cq.c
+++ b/drivers/staging/hfi1/cq.c
@@ -479,7 +479,7 @@ int hfi1_resize_cq(struct ib_cq *ibcq, int cqe, struct ib_udata *udata)
 
 	if (cq->ip) {
 		struct hfi1_ibdev *dev = to_idev(ibcq->device);
-		struct hfi1_mmap_info *ip = cq->ip;
+		struct rvt_mmap_info *ip = cq->ip;
 
 		hfi1_update_mmap_info(dev, ip, sz, wc);
 
diff --git a/drivers/staging/hfi1/diag.c b/drivers/staging/hfi1/diag.c
index 7cc6d2fdaf6b..48675c5e417f 100644
--- a/drivers/staging/hfi1/diag.c
+++ b/drivers/staging/hfi1/diag.c
@@ -1603,7 +1603,7 @@ int snoop_recv_handler(struct hfi1_packet *packet)
 /*
  * Handle snooping and capturing packets when sdma is being used.
  */
-int snoop_send_dma_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
+int snoop_send_dma_handler(struct rvt_qp *qp, struct hfi1_pkt_state *ps,
 			   u64 pbc)
 {
 	pr_alert("Snooping/Capture of Send DMA Packets Is Not Supported!\n");
@@ -1616,13 +1616,13 @@ int snoop_send_dma_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
  * bypass packets. The only way to send a bypass packet currently is to use the
  * diagpkt interface. When that interface is enable snoop/capture is not.
  */
-int snoop_send_pio_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
+int snoop_send_pio_handler(struct rvt_qp *qp, struct hfi1_pkt_state *ps,
 			   u64 pbc)
 {
 	struct hfi1_qp_priv *priv = qp->priv;
 	struct ahg_ib_header *ahdr = priv->s_hdr;
 	u32 hdrwords = qp->s_hdrwords;
-	struct hfi1_sge_state *ss = qp->s_cur_sge;
+	struct rvt_sge_state *ss = qp->s_cur_sge;
 	u32 len = qp->s_cur_size;
 	u32 dwords = (len + 3) >> 2;
 	u32 plen = hdrwords + dwords + 2; /* includes pbc */
@@ -1630,7 +1630,7 @@ int snoop_send_pio_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 	struct snoop_packet *s_packet = NULL;
 	u32 *hdr = (u32 *)&ahdr->ibh;
 	u32 length = 0;
-	struct hfi1_sge_state temp_ss;
+	struct rvt_sge_state temp_ss;
 	void *data = NULL;
 	void *data_start = NULL;
 	int ret;
* Unmerged path drivers/staging/hfi1/driver.c
diff --git a/drivers/staging/hfi1/hfi.h b/drivers/staging/hfi1/hfi.h
index e9ab6719e29f..422f4588326a 100644
--- a/drivers/staging/hfi1/hfi.h
+++ b/drivers/staging/hfi1/hfi.h
@@ -345,7 +345,7 @@ struct hfi1_packet {
 	void *hdr;
 	struct hfi1_ctxtdata *rcd;
 	__le32 *rhf_addr;
-	struct hfi1_qp *qp;
+	struct rvt_qp *qp;
 	struct hfi1_other_headers *ohdr;
 	u64 rhf;
 	u32 maxcnt;
@@ -385,7 +385,7 @@ struct hfi1_snoop_data {
 #define HFI1_PORT_SNOOP_MODE     1U
 #define HFI1_PORT_CAPTURE_MODE   2U
 
-struct hfi1_sge_state;
+struct rvt_sge_state;
 
 /*
  * Get/Set IB link-level config parameters for f_get/set_ib_cfg()
@@ -1102,9 +1102,9 @@ struct hfi1_devdata {
 	 * Handlers for outgoing data so that snoop/capture does not
 	 * have to have its hooks in the send path
 	 */
-	int (*process_pio_send)(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
+	int (*process_pio_send)(struct rvt_qp *qp, struct hfi1_pkt_state *ps,
 				u64 pbc);
-	int (*process_dma_send)(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
+	int (*process_dma_send)(struct rvt_qp *qp, struct hfi1_pkt_state *ps,
 				u64 pbc);
 	void (*pio_inline_send)(struct hfi1_devdata *dd, struct pio_buf *pbuf,
 				u64 pbc, const void *from, size_t count);
@@ -1285,7 +1285,7 @@ static inline u32 egress_cycles(u32 len, u32 rate)
 void set_link_ipg(struct hfi1_pportdata *ppd);
 void process_becn(struct hfi1_pportdata *ppd, u8 sl,  u16 rlid, u32 lqpn,
 		  u32 rqpn, u8 svc_type);
-void return_cnp(struct hfi1_ibport *ibp, struct hfi1_qp *qp, u32 remote_qpn,
+void return_cnp(struct hfi1_ibport *ibp, struct rvt_qp *qp, u32 remote_qpn,
 		u32 pkey, u32 slid, u32 dlid, u8 sc5,
 		const struct ib_grh *old_grh);
 
@@ -1477,9 +1477,9 @@ void reset_link_credits(struct hfi1_devdata *dd);
 void assign_remote_cm_au_table(struct hfi1_devdata *dd, u8 vcu);
 
 int snoop_recv_handler(struct hfi1_packet *packet);
-int snoop_send_dma_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
+int snoop_send_dma_handler(struct rvt_qp *qp, struct hfi1_pkt_state *ps,
 			   u64 pbc);
-int snoop_send_pio_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
+int snoop_send_pio_handler(struct rvt_qp *qp, struct hfi1_pkt_state *ps,
 			   u64 pbc);
 void snoop_inline_pio_send(struct hfi1_devdata *dd, struct pio_buf *pbuf,
 			   u64 pbc, const void *from, size_t count);
@@ -1691,7 +1691,7 @@ int process_receive_invalid(struct hfi1_packet *packet);
 
 extern rhf_rcv_function_ptr snoop_rhf_rcv_functions[8];
 
-void update_sge(struct hfi1_sge_state *ss, u32 length);
+void update_sge(struct rvt_sge_state *ss, u32 length);
 
 /* global module parameter variables */
 extern unsigned int hfi1_max_mtu;
* Unmerged path drivers/staging/hfi1/keys.c
diff --git a/drivers/staging/hfi1/mmap.c b/drivers/staging/hfi1/mmap.c
index 5173b1c60b3d..4ce6be6af17c 100644
--- a/drivers/staging/hfi1/mmap.c
+++ b/drivers/staging/hfi1/mmap.c
@@ -59,12 +59,12 @@
 
 /**
  * hfi1_release_mmap_info - free mmap info structure
- * @ref: a pointer to the kref within struct hfi1_mmap_info
+ * @ref: a pointer to the kref within struct rvt_mmap_info
  */
 void hfi1_release_mmap_info(struct kref *ref)
 {
-	struct hfi1_mmap_info *ip =
-		container_of(ref, struct hfi1_mmap_info, ref);
+	struct rvt_mmap_info *ip =
+		container_of(ref, struct rvt_mmap_info, ref);
 	struct hfi1_ibdev *dev = to_idev(ip->context->device);
 
 	spin_lock_irq(&dev->pending_lock);
@@ -81,14 +81,14 @@ void hfi1_release_mmap_info(struct kref *ref)
  */
 static void hfi1_vma_open(struct vm_area_struct *vma)
 {
-	struct hfi1_mmap_info *ip = vma->vm_private_data;
+	struct rvt_mmap_info *ip = vma->vm_private_data;
 
 	kref_get(&ip->ref);
 }
 
 static void hfi1_vma_close(struct vm_area_struct *vma)
 {
-	struct hfi1_mmap_info *ip = vma->vm_private_data;
+	struct rvt_mmap_info *ip = vma->vm_private_data;
 
 	kref_put(&ip->ref, hfi1_release_mmap_info);
 }
@@ -109,7 +109,7 @@ int hfi1_mmap(struct ib_ucontext *context, struct vm_area_struct *vma)
 	struct hfi1_ibdev *dev = to_idev(context->device);
 	unsigned long offset = vma->vm_pgoff << PAGE_SHIFT;
 	unsigned long size = vma->vm_end - vma->vm_start;
-	struct hfi1_mmap_info *ip, *pp;
+	struct rvt_mmap_info *ip, *pp;
 	int ret = -EINVAL;
 
 	/*
@@ -146,11 +146,11 @@ done:
 /*
  * Allocate information for hfi1_mmap
  */
-struct hfi1_mmap_info *hfi1_create_mmap_info(struct hfi1_ibdev *dev,
-					     u32 size,
-					     struct ib_ucontext *context,
-					     void *obj) {
-	struct hfi1_mmap_info *ip;
+struct rvt_mmap_info *hfi1_create_mmap_info(struct hfi1_ibdev *dev,
+					    u32 size,
+					    struct ib_ucontext *context,
+					    void *obj) {
+	struct rvt_mmap_info *ip;
 
 	ip = kmalloc(sizeof(*ip), GFP_KERNEL);
 	if (!ip)
@@ -175,7 +175,7 @@ bail:
 	return ip;
 }
 
-void hfi1_update_mmap_info(struct hfi1_ibdev *dev, struct hfi1_mmap_info *ip,
+void hfi1_update_mmap_info(struct hfi1_ibdev *dev, struct rvt_mmap_info *ip,
 			   u32 size, void *obj)
 {
 	size = PAGE_ALIGN(size);
* Unmerged path drivers/staging/hfi1/mr.c
diff --git a/drivers/staging/hfi1/pio.c b/drivers/staging/hfi1/pio.c
index 25d65f9a0b94..8ee7ed8e0fb7 100644
--- a/drivers/staging/hfi1/pio.c
+++ b/drivers/staging/hfi1/pio.c
@@ -1526,8 +1526,8 @@ static void sc_piobufavail(struct send_context *sc)
 	struct hfi1_devdata *dd = sc->dd;
 	struct hfi1_ibdev *dev = &dd->verbs_dev;
 	struct list_head *list;
-	struct hfi1_qp *qps[PIO_WAIT_BATCH_SIZE];
-	struct hfi1_qp *qp;
+	struct rvt_qp *qps[PIO_WAIT_BATCH_SIZE];
+	struct rvt_qp *qp;
 	struct hfi1_qp_priv *priv;
 	unsigned long flags;
 	unsigned i, n = 0;
diff --git a/drivers/staging/hfi1/qp.c b/drivers/staging/hfi1/qp.c
index 9ffed6e14d8e..0a5aaddc8356 100644
--- a/drivers/staging/hfi1/qp.c
+++ b/drivers/staging/hfi1/qp.c
@@ -67,7 +67,7 @@ static unsigned int hfi1_qp_table_size = 256;
 module_param_named(qp_table_size, hfi1_qp_table_size, uint, S_IRUGO);
 MODULE_PARM_DESC(qp_table_size, "QP table size");
 
-static void flush_tx_list(struct hfi1_qp *qp);
+static void flush_tx_list(struct rvt_qp *qp);
 static int iowait_sleep(
 	struct sdma_engine *sde,
 	struct iowait *wait,
@@ -229,7 +229,7 @@ static void free_qpn(struct hfi1_qpn_table *qpt, u32 qpn)
  * Put the QP into the hash table.
  * The hash table holds a reference to the QP.
  */
-static void insert_qp(struct hfi1_ibdev *dev, struct hfi1_qp *qp)
+static void insert_qp(struct hfi1_ibdev *dev, struct rvt_qp *qp)
 {
 	struct hfi1_ibport *ibp = to_iport(qp->ibqp.device, qp->port_num);
 	unsigned long flags;
@@ -254,7 +254,7 @@ static void insert_qp(struct hfi1_ibdev *dev, struct hfi1_qp *qp)
  * Remove the QP from the table so it can't be found asynchronously by
  * the receive interrupt routine.
  */
-static void remove_qp(struct hfi1_ibdev *dev, struct hfi1_qp *qp)
+static void remove_qp(struct hfi1_ibdev *dev, struct rvt_qp *qp)
 {
 	struct hfi1_ibport *ibp = to_iport(qp->ibqp.device, qp->port_num);
 	u32 n = qpn_hash(dev->qp_dev, qp->ibqp.qp_num);
@@ -270,8 +270,8 @@ static void remove_qp(struct hfi1_ibdev *dev, struct hfi1_qp *qp)
 			lockdep_is_held(&dev->qp_dev->qpt_lock)) == qp) {
 		RCU_INIT_POINTER(ibp->qp[1], NULL);
 	} else {
-		struct hfi1_qp *q;
-		struct hfi1_qp __rcu **qpp;
+		struct rvt_qp *q;
+		struct rvt_qp __rcu **qpp;
 
 		removed = 0;
 		qpp = &dev->qp_dev->qp_table[n];
@@ -308,7 +308,7 @@ static unsigned free_all_qps(struct hfi1_devdata *dd)
 {
 	struct hfi1_ibdev *dev = &dd->verbs_dev;
 	unsigned long flags;
-	struct hfi1_qp *qp;
+	struct rvt_qp *qp;
 	unsigned n, qp_inuse = 0;
 
 	for (n = 0; n < dd->num_pports; n++) {
@@ -347,7 +347,7 @@ bail:
  * @qp: the QP to reset
  * @type: the QP type
  */
-static void reset_qp(struct hfi1_qp *qp, enum ib_qp_type type)
+static void reset_qp(struct rvt_qp *qp, enum ib_qp_type type)
 {
 	struct hfi1_qp_priv *priv = qp->priv;
 	qp->remote_qpn = 0;
@@ -402,7 +402,7 @@ static void reset_qp(struct hfi1_qp *qp, enum ib_qp_type type)
 	qp->r_sge.num_sge = 0;
 }
 
-static void clear_mr_refs(struct hfi1_qp *qp, int clr_sends)
+static void clear_mr_refs(struct rvt_qp *qp, int clr_sends)
 {
 	unsigned n;
 
@@ -413,13 +413,13 @@ static void clear_mr_refs(struct hfi1_qp *qp, int clr_sends)
 
 	if (clr_sends) {
 		while (qp->s_last != qp->s_head) {
-			struct hfi1_swqe *wqe = get_swqe_ptr(qp, qp->s_last);
+			struct rvt_swqe *wqe = get_swqe_ptr(qp, qp->s_last);
 			unsigned i;
 
 			for (i = 0; i < wqe->wr.num_sge; i++) {
-				struct hfi1_sge *sge = &wqe->sg_list[i];
+				struct rvt_sge *sge = &wqe->sg_list[i];
 
-				hfi1_put_mr(sge->mr);
+				rvt_put_mr(sge->mr);
 			}
 			if (qp->ibqp.qp_type == IB_QPT_UD ||
 			    qp->ibqp.qp_type == IB_QPT_SMI ||
@@ -429,7 +429,7 @@ static void clear_mr_refs(struct hfi1_qp *qp, int clr_sends)
 				qp->s_last = 0;
 		}
 		if (qp->s_rdma_mr) {
-			hfi1_put_mr(qp->s_rdma_mr);
+			rvt_put_mr(qp->s_rdma_mr);
 			qp->s_rdma_mr = NULL;
 		}
 	}
@@ -438,11 +438,11 @@ static void clear_mr_refs(struct hfi1_qp *qp, int clr_sends)
 		return;
 
 	for (n = 0; n < ARRAY_SIZE(qp->s_ack_queue); n++) {
-		struct hfi1_ack_entry *e = &qp->s_ack_queue[n];
+		struct rvt_ack_entry *e = &qp->s_ack_queue[n];
 
 		if (e->opcode == IB_OPCODE_RC_RDMA_READ_REQUEST &&
 		    e->rdma_sge.mr) {
-			hfi1_put_mr(e->rdma_sge.mr);
+			rvt_put_mr(e->rdma_sge.mr);
 			e->rdma_sge.mr = NULL;
 		}
 	}
@@ -458,7 +458,7 @@ static void clear_mr_refs(struct hfi1_qp *qp, int clr_sends)
  * The QP r_lock and s_lock should be held and interrupts disabled.
  * If we are already in error state, just return.
  */
-int hfi1_error_qp(struct hfi1_qp *qp, enum ib_wc_status err)
+int hfi1_error_qp(struct rvt_qp *qp, enum ib_wc_status err)
 {
 	struct hfi1_ibdev *dev = to_idev(qp->ibqp.device);
 	struct hfi1_qp_priv *priv = qp->priv;
@@ -490,7 +490,7 @@ int hfi1_error_qp(struct hfi1_qp *qp, enum ib_wc_status err)
 	if (!(qp->s_flags & HFI1_S_BUSY)) {
 		qp->s_hdrwords = 0;
 		if (qp->s_rdma_mr) {
-			hfi1_put_mr(qp->s_rdma_mr);
+			rvt_put_mr(qp->s_rdma_mr);
 			qp->s_rdma_mr = NULL;
 		}
 		flush_tx_list(qp);
@@ -514,7 +514,7 @@ int hfi1_error_qp(struct hfi1_qp *qp, enum ib_wc_status err)
 	wc.status = IB_WC_WR_FLUSH_ERR;
 
 	if (qp->r_rq.wq) {
-		struct hfi1_rwq *wq;
+		struct rvt_rwq *wq;
 		u32 head;
 		u32 tail;
 
@@ -544,7 +544,7 @@ bail:
 	return ret;
 }
 
-static void flush_tx_list(struct hfi1_qp *qp)
+static void flush_tx_list(struct rvt_qp *qp)
 {
 	struct hfi1_qp_priv *priv = qp->priv;
 
@@ -561,7 +561,7 @@ static void flush_tx_list(struct hfi1_qp *qp)
 	}
 }
 
-static void flush_iowait(struct hfi1_qp *qp)
+static void flush_iowait(struct rvt_qp *qp)
 {
 	struct hfi1_qp_priv *priv = qp->priv;
 	struct hfi1_ibdev *dev = to_idev(qp->ibqp.device);
@@ -616,7 +616,7 @@ int hfi1_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 		   int attr_mask, struct ib_udata *udata)
 {
 	struct hfi1_ibdev *dev = to_idev(ibqp->device);
-	struct hfi1_qp *qp = to_iqp(ibqp);
+	struct rvt_qp *qp = to_iqp(ibqp);
 	struct hfi1_qp_priv *priv = qp->priv;
 	enum ib_qp_state cur_state, new_state;
 	struct ib_event ev;
@@ -914,7 +914,7 @@ bail:
 int hfi1_query_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 		  int attr_mask, struct ib_qp_init_attr *init_attr)
 {
-	struct hfi1_qp *qp = to_iqp(ibqp);
+	struct rvt_qp *qp = to_iqp(ibqp);
 
 	attr->qp_state = qp->state;
 	attr->cur_qp_state = attr->qp_state;
@@ -967,7 +967,7 @@ int hfi1_query_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
  *
  * Returns the AETH.
  */
-__be32 hfi1_compute_aeth(struct hfi1_qp *qp)
+__be32 hfi1_compute_aeth(struct rvt_qp *qp)
 {
 	u32 aeth = qp->r_msn & HFI1_MSN_MASK;
 
@@ -980,7 +980,7 @@ __be32 hfi1_compute_aeth(struct hfi1_qp *qp)
 	} else {
 		u32 min, max, x;
 		u32 credits;
-		struct hfi1_rwq *wq = qp->r_rq.wq;
+		struct rvt_rwq *wq = qp->r_rq.wq;
 		u32 head;
 		u32 tail;
 
@@ -1036,10 +1036,10 @@ struct ib_qp *hfi1_create_qp(struct ib_pd *ibpd,
 			     struct ib_qp_init_attr *init_attr,
 			     struct ib_udata *udata)
 {
-	struct hfi1_qp *qp;
+	struct rvt_qp *qp;
 	struct hfi1_qp_priv *priv;
 	int err;
-	struct hfi1_swqe *swq = NULL;
+	struct rvt_swqe *swq = NULL;
 	struct hfi1_ibdev *dev;
 	struct hfi1_devdata *dd;
 	size_t sz;
@@ -1080,9 +1080,9 @@ struct ib_qp *hfi1_create_qp(struct ib_pd *ibpd,
 	case IB_QPT_UC:
 	case IB_QPT_RC:
 	case IB_QPT_UD:
-		sz = sizeof(struct hfi1_sge) *
+		sz = sizeof(struct rvt_sge) *
 			init_attr->cap.max_send_sge +
-			sizeof(struct hfi1_swqe);
+			sizeof(struct rvt_swqe);
 		swq = vmalloc((init_attr->cap.max_send_wr + 1) * sz);
 		if (swq == NULL) {
 			ret = ERR_PTR(-ENOMEM);
@@ -1126,8 +1126,8 @@ struct ib_qp *hfi1_create_qp(struct ib_pd *ibpd,
 			qp->r_rq.size = init_attr->cap.max_recv_wr + 1;
 			qp->r_rq.max_sge = init_attr->cap.max_recv_sge;
 			sz = (sizeof(struct ib_sge) * qp->r_rq.max_sge) +
-				sizeof(struct hfi1_rwqe);
-			qp->r_rq.wq = vmalloc_user(sizeof(struct hfi1_rwq) +
+				sizeof(struct rvt_rwqe);
+			qp->r_rq.wq = vmalloc_user(sizeof(struct rvt_rwq) +
 						   qp->r_rq.size * sz);
 			if (!qp->r_rq.wq) {
 				ret = ERR_PTR(-ENOMEM);
@@ -1191,7 +1191,7 @@ struct ib_qp *hfi1_create_qp(struct ib_pd *ibpd,
 				goto bail_ip;
 			}
 		} else {
-			u32 s = sizeof(struct hfi1_rwq) + qp->r_rq.size * sz;
+			u32 s = sizeof(struct rvt_rwq) + qp->r_rq.size * sz;
 
 			qp->ip = hfi1_create_mmap_info(dev, s,
 						      ibpd->uobject->context,
@@ -1280,7 +1280,7 @@ bail:
  */
 int hfi1_destroy_qp(struct ib_qp *ibqp)
 {
-	struct hfi1_qp *qp = to_iqp(ibqp);
+	struct rvt_qp *qp = to_iqp(ibqp);
 	struct hfi1_ibdev *dev = to_idev(ibqp->device);
 	struct hfi1_qp_priv *priv = qp->priv;
 
@@ -1386,7 +1386,7 @@ static void free_qpn_table(struct hfi1_qpn_table *qpt)
  *
  * The QP s_lock should be held.
  */
-void hfi1_get_credit(struct hfi1_qp *qp, u32 aeth)
+void hfi1_get_credit(struct rvt_qp *qp, u32 aeth)
 {
 	u32 credit = (aeth >> HFI1_AETH_CREDIT_SHIFT) & HFI1_AETH_CREDIT_MASK;
 
@@ -1416,7 +1416,7 @@ void hfi1_get_credit(struct hfi1_qp *qp, u32 aeth)
 	}
 }
 
-void hfi1_qp_wakeup(struct hfi1_qp *qp, u32 flag)
+void hfi1_qp_wakeup(struct rvt_qp *qp, u32 flag)
 {
 	unsigned long flags;
 
@@ -1439,7 +1439,7 @@ static int iowait_sleep(
 	unsigned seq)
 {
 	struct verbs_txreq *tx = container_of(stx, struct verbs_txreq, txreq);
-	struct hfi1_qp *qp;
+	struct rvt_qp *qp;
 	struct hfi1_qp_priv *priv;
 	unsigned long flags;
 	int ret = 0;
@@ -1490,7 +1490,7 @@ eagain:
 
 static void iowait_wakeup(struct iowait *wait, int reason)
 {
-	struct hfi1_qp *qp = iowait_to_qp(wait);
+	struct rvt_qp *qp = iowait_to_qp(wait);
 
 	WARN_ON(reason != SDMA_AVAIL_REASON);
 	hfi1_qp_wakeup(qp, HFI1_S_WAIT_DMA_DESC);
@@ -1557,7 +1557,7 @@ void hfi1_qp_exit(struct hfi1_ibdev *dev)
  * Return:
  * A send engine for the qp or NULL for SMI type qp.
  */
-struct sdma_engine *qp_to_sdma_engine(struct hfi1_qp *qp, u8 sc5)
+struct sdma_engine *qp_to_sdma_engine(struct rvt_qp *qp, u8 sc5)
 {
 	struct hfi1_devdata *dd = dd_from_ibdev(qp->ibqp.device);
 	struct sdma_engine *sde;
@@ -1576,7 +1576,7 @@ struct sdma_engine *qp_to_sdma_engine(struct hfi1_qp *qp, u8 sc5)
 
 struct qp_iter {
 	struct hfi1_ibdev *dev;
-	struct hfi1_qp *qp;
+	struct rvt_qp *qp;
 	int specials;
 	int n;
 };
@@ -1604,8 +1604,8 @@ int qp_iter_next(struct qp_iter *iter)
 	struct hfi1_ibdev *dev = iter->dev;
 	int n = iter->n;
 	int ret = 1;
-	struct hfi1_qp *pqp = iter->qp;
-	struct hfi1_qp *qp;
+	struct rvt_qp *pqp = iter->qp;
+	struct rvt_qp *qp;
 
 	/*
 	 * The approach is to consider the special qps
@@ -1658,7 +1658,7 @@ static const char * const qp_type_str[] = {
 	"SMI", "GSI", "RC", "UC", "UD",
 };
 
-static int qp_idle(struct hfi1_qp *qp)
+static int qp_idle(struct rvt_qp *qp)
 {
 	return
 		qp->s_last == qp->s_acked &&
@@ -1669,8 +1669,8 @@ static int qp_idle(struct hfi1_qp *qp)
 
 void qp_iter_print(struct seq_file *s, struct qp_iter *iter)
 {
-	struct hfi1_swqe *wqe;
-	struct hfi1_qp *qp = iter->qp;
+	struct rvt_swqe *wqe;
+	struct rvt_qp *qp = iter->qp;
 	struct hfi1_qp_priv *priv = qp->priv;
 	struct sdma_engine *sde;
 
@@ -1708,7 +1708,7 @@ void qp_iter_print(struct seq_file *s, struct qp_iter *iter)
 		   sde ? sde->this_idx : 0);
 }
 
-void qp_comm_est(struct hfi1_qp *qp)
+void qp_comm_est(struct rvt_qp *qp)
 {
 	qp->r_flags |= HFI1_R_COMM_EST;
 	if (qp->ibqp.event_handler) {
@@ -1725,7 +1725,7 @@ void qp_comm_est(struct hfi1_qp *qp)
  * Switch to alternate path.
  * The QP s_lock should be held and interrupts disabled.
  */
-void hfi1_migrate_qp(struct hfi1_qp *qp)
+void hfi1_migrate_qp(struct rvt_qp *qp)
 {
 	struct hfi1_qp_priv *priv = qp->priv;
 	struct ib_event ev;
diff --git a/drivers/staging/hfi1/qp.h b/drivers/staging/hfi1/qp.h
index 1144470a6bc0..1c1f43d82ab1 100644
--- a/drivers/staging/hfi1/qp.h
+++ b/drivers/staging/hfi1/qp.h
@@ -80,7 +80,7 @@ struct hfi1_qpn_table {
 struct hfi1_qp_ibdev {
 	u32 qp_table_size;
 	u32 qp_table_bits;
-	struct hfi1_qp __rcu **qp_table;
+	struct rvt_qp __rcu **qp_table;
 	spinlock_t qpt_lock;
 	struct hfi1_qpn_table qpn_table;
 };
@@ -98,10 +98,10 @@ static inline u32 qpn_hash(struct hfi1_qp_ibdev *dev, u32 qpn)
  * The caller must hold the rcu_read_lock(), and keep the lock until
  * the returned qp is no longer in use.
  */
-static inline struct hfi1_qp *hfi1_lookup_qpn(struct hfi1_ibport *ibp,
-				u32 qpn) __must_hold(RCU)
+static inline struct rvt_qp *hfi1_lookup_qpn(struct hfi1_ibport *ibp,
+					     u32 qpn) __must_hold(RCU)
 {
-	struct hfi1_qp *qp = NULL;
+	struct rvt_qp *qp = NULL;
 
 	if (unlikely(qpn <= 1)) {
 		qp = rcu_dereference(ibp->qp[qpn]);
@@ -117,11 +117,10 @@ static inline struct hfi1_qp *hfi1_lookup_qpn(struct hfi1_ibport *ibp,
 	return qp;
 }
 
-/**
- * clear_ahg - reset ahg status in qp
- * @qp - qp pointer
+/*
+ * free_ahg - clear ahg from QP
  */
-static inline void clear_ahg(struct hfi1_qp *qp)
+static inline void clear_ahg(struct rvt_qp *qp)
 {
 	struct hfi1_qp_priv *priv = qp->priv;
 
@@ -142,7 +141,7 @@ static inline void clear_ahg(struct hfi1_qp *qp)
  * The QP r_lock and s_lock should be held and interrupts disabled.
  * If we are already in error state, just return.
  */
-int hfi1_error_qp(struct hfi1_qp *qp, enum ib_wc_status err);
+int hfi1_error_qp(struct rvt_qp *qp, enum ib_wc_status err);
 
 /**
  * hfi1_modify_qp - modify the attributes of a queue pair
@@ -165,7 +164,7 @@ int hfi1_query_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
  *
  * Returns the AETH.
  */
-__be32 hfi1_compute_aeth(struct hfi1_qp *qp);
+__be32 hfi1_compute_aeth(struct rvt_qp *qp);
 
 /**
  * hfi1_create_qp - create a queue pair for a device
@@ -198,7 +197,7 @@ int hfi1_destroy_qp(struct ib_qp *ibqp);
  *
  * The QP s_lock should be held.
  */
-void hfi1_get_credit(struct hfi1_qp *qp, u32 aeth);
+void hfi1_get_credit(struct rvt_qp *qp, u32 aeth);
 
 /**
  * hfi1_qp_init - allocate QP tables
@@ -217,9 +216,9 @@ void hfi1_qp_exit(struct hfi1_ibdev *dev);
  * @qp: the QP
  * @flag: flag the qp on which the qp is stalled
  */
-void hfi1_qp_wakeup(struct hfi1_qp *qp, u32 flag);
+void hfi1_qp_wakeup(struct rvt_qp *qp, u32 flag);
 
-struct sdma_engine *qp_to_sdma_engine(struct hfi1_qp *qp, u8 sc5);
+struct sdma_engine *qp_to_sdma_engine(struct rvt_qp *qp, u8 sc5);
 
 struct qp_iter;
 
@@ -246,7 +245,7 @@ void qp_iter_print(struct seq_file *s, struct qp_iter *iter);
  * qp_comm_est - handle trap with QP established
  * @qp: the QP
  */
-void qp_comm_est(struct hfi1_qp *qp);
+void qp_comm_est(struct rvt_qp *qp);
 
 /**
  * _hfi1_schedule_send - schedule progress
@@ -257,7 +256,7 @@ void qp_comm_est(struct hfi1_qp *qp);
  * It is only used in the post send, which doesn't hold
  * the s_lock.
  */
-static inline void _hfi1_schedule_send(struct hfi1_qp *qp)
+static inline void _hfi1_schedule_send(struct rvt_qp *qp)
 {
 	struct hfi1_qp_priv *priv = qp->priv;
 	struct hfi1_ibport *ibp =
@@ -278,12 +277,12 @@ static inline void _hfi1_schedule_send(struct hfi1_qp *qp)
  * This schedules qp progress and caller should hold
  * the s_lock.
  */
-static inline void hfi1_schedule_send(struct hfi1_qp *qp)
+static inline void hfi1_schedule_send(struct rvt_qp *qp)
 {
 	if (hfi1_send_ok(qp))
 		_hfi1_schedule_send(qp);
 }
 
-void hfi1_migrate_qp(struct hfi1_qp *qp);
+void hfi1_migrate_qp(struct rvt_qp *qp);
 
 #endif /* _QP_H */
diff --git a/drivers/staging/hfi1/rc.c b/drivers/staging/hfi1/rc.c
index dd57d65aa9b2..c4aef21baf13 100644
--- a/drivers/staging/hfi1/rc.c
+++ b/drivers/staging/hfi1/rc.c
@@ -60,7 +60,7 @@
 
 static void rc_timeout(unsigned long arg);
 
-static u32 restart_sge(struct hfi1_sge_state *ss, struct hfi1_swqe *wqe,
+static u32 restart_sge(struct rvt_sge_state *ss, struct rvt_swqe *wqe,
 		       u32 psn, u32 pmtu)
 {
 	u32 len;
@@ -74,7 +74,7 @@ static u32 restart_sge(struct hfi1_sge_state *ss, struct hfi1_swqe *wqe,
 	return wqe->length - len;
 }
 
-static void start_timer(struct hfi1_qp *qp)
+static void start_timer(struct rvt_qp *qp)
 {
 	qp->s_flags |= HFI1_S_TIMER;
 	qp->s_timer.function = rc_timeout;
@@ -94,10 +94,10 @@ static void start_timer(struct hfi1_qp *qp)
  * Note that we are in the responder's side of the QP context.
  * Note the QP s_lock must be held.
  */
-static int make_rc_ack(struct hfi1_ibdev *dev, struct hfi1_qp *qp,
+static int make_rc_ack(struct hfi1_ibdev *dev, struct rvt_qp *qp,
 		       struct hfi1_other_headers *ohdr, u32 pmtu)
 {
-	struct hfi1_ack_entry *e;
+	struct rvt_ack_entry *e;
 	u32 hwords;
 	u32 len;
 	u32 bth0;
@@ -116,7 +116,7 @@ static int make_rc_ack(struct hfi1_ibdev *dev, struct hfi1_qp *qp,
 	case OP(RDMA_READ_RESPONSE_ONLY):
 		e = &qp->s_ack_queue[qp->s_tail_ack_queue];
 		if (e->rdma_sge.mr) {
-			hfi1_put_mr(e->rdma_sge.mr);
+			rvt_put_mr(e->rdma_sge.mr);
 			e->rdma_sge.mr = NULL;
 		}
 		/* FALLTHROUGH */
@@ -154,7 +154,7 @@ static int make_rc_ack(struct hfi1_ibdev *dev, struct hfi1_qp *qp,
 			/* Copy SGE state in case we need to resend */
 			qp->s_rdma_mr = e->rdma_sge.mr;
 			if (qp->s_rdma_mr)
-				hfi1_get_mr(qp->s_rdma_mr);
+				rvt_get_mr(qp->s_rdma_mr);
 			qp->s_ack_rdma_sge.sge = e->rdma_sge;
 			qp->s_ack_rdma_sge.num_sge = 1;
 			qp->s_cur_sge = &qp->s_ack_rdma_sge;
@@ -193,7 +193,7 @@ static int make_rc_ack(struct hfi1_ibdev *dev, struct hfi1_qp *qp,
 		qp->s_cur_sge = &qp->s_ack_rdma_sge;
 		qp->s_rdma_mr = qp->s_ack_rdma_sge.sge.mr;
 		if (qp->s_rdma_mr)
-			hfi1_get_mr(qp->s_rdma_mr);
+			rvt_get_mr(qp->s_rdma_mr);
 		len = qp->s_ack_rdma_sge.sge.sge_length;
 		if (len > pmtu) {
 			len = pmtu;
@@ -257,13 +257,13 @@ bail:
  *
  * Return 1 if constructed; otherwise, return 0.
  */
-int hfi1_make_rc_req(struct hfi1_qp *qp)
+int hfi1_make_rc_req(struct rvt_qp *qp)
 {
 	struct hfi1_qp_priv *priv = qp->priv;
 	struct hfi1_ibdev *dev = to_idev(qp->ibqp.device);
 	struct hfi1_other_headers *ohdr;
-	struct hfi1_sge_state *ss;
-	struct hfi1_swqe *wqe;
+	struct rvt_sge_state *ss;
+	struct rvt_swqe *wqe;
 	/* header size in 32-bit words LRH+BTH = (8+12)/4. */
 	u32 hwords = 5;
 	u32 len;
@@ -683,7 +683,7 @@ unlock:
  * Note that RDMA reads and atomics are handled in the
  * send side QP state and tasklet.
  */
-void hfi1_send_rc_ack(struct hfi1_ctxtdata *rcd, struct hfi1_qp *qp,
+void hfi1_send_rc_ack(struct hfi1_ctxtdata *rcd, struct rvt_qp *qp,
 		      int is_fecn)
 {
 	struct hfi1_ibport *ibp = to_iport(qp->ibqp.device, qp->port_num);
@@ -794,10 +794,10 @@ queue_ack:
  * for the given QP.
  * Called at interrupt level with the QP s_lock held.
  */
-static void reset_psn(struct hfi1_qp *qp, u32 psn)
+static void reset_psn(struct rvt_qp *qp, u32 psn)
 {
 	u32 n = qp->s_acked;
-	struct hfi1_swqe *wqe = get_swqe_ptr(qp, n);
+	struct rvt_swqe *wqe = get_swqe_ptr(qp, n);
 	u32 opcode;
 
 	qp->s_cur = n;
@@ -880,9 +880,9 @@ done:
  * Back up requester to resend the last un-ACKed request.
  * The QP r_lock and s_lock should be held and interrupts disabled.
  */
-static void restart_rc(struct hfi1_qp *qp, u32 psn, int wait)
+static void restart_rc(struct rvt_qp *qp, u32 psn, int wait)
 {
-	struct hfi1_swqe *wqe = get_swqe_ptr(qp, qp->s_acked);
+	struct rvt_swqe *wqe = get_swqe_ptr(qp, qp->s_acked);
 	struct hfi1_ibport *ibp;
 
 	if (qp->s_retry == 0) {
@@ -917,7 +917,7 @@ static void restart_rc(struct hfi1_qp *qp, u32 psn, int wait)
  */
 static void rc_timeout(unsigned long arg)
 {
-	struct hfi1_qp *qp = (struct hfi1_qp *)arg;
+	struct rvt_qp *qp = (struct rvt_qp *)arg;
 	struct hfi1_ibport *ibp;
 	unsigned long flags;
 
@@ -941,7 +941,7 @@ static void rc_timeout(unsigned long arg)
  */
 void hfi1_rc_rnr_retry(unsigned long arg)
 {
-	struct hfi1_qp *qp = (struct hfi1_qp *)arg;
+	struct rvt_qp *qp = (struct rvt_qp *)arg;
 	unsigned long flags;
 
 	spin_lock_irqsave(&qp->s_lock, flags);
@@ -957,9 +957,9 @@ void hfi1_rc_rnr_retry(unsigned long arg)
  * Set qp->s_sending_psn to the next PSN after the given one.
  * This would be psn+1 except when RDMA reads are present.
  */
-static void reset_sending_psn(struct hfi1_qp *qp, u32 psn)
+static void reset_sending_psn(struct rvt_qp *qp, u32 psn)
 {
-	struct hfi1_swqe *wqe;
+	struct rvt_swqe *wqe;
 	u32 n = qp->s_last;
 
 	/* Find the work request corresponding to the given PSN. */
@@ -982,10 +982,10 @@ static void reset_sending_psn(struct hfi1_qp *qp, u32 psn)
 /*
  * This should be called with the QP s_lock held and interrupts disabled.
  */
-void hfi1_rc_send_complete(struct hfi1_qp *qp, struct hfi1_ib_header *hdr)
+void hfi1_rc_send_complete(struct rvt_qp *qp, struct hfi1_ib_header *hdr)
 {
 	struct hfi1_other_headers *ohdr;
-	struct hfi1_swqe *wqe;
+	struct rvt_swqe *wqe;
 	struct ib_wc wc;
 	unsigned i;
 	u32 opcode;
@@ -1027,9 +1027,9 @@ void hfi1_rc_send_complete(struct hfi1_qp *qp, struct hfi1_ib_header *hdr)
 		    cmp_psn(qp->s_sending_psn, qp->s_sending_hpsn) <= 0)
 			break;
 		for (i = 0; i < wqe->wr.num_sge; i++) {
-			struct hfi1_sge *sge = &wqe->sg_list[i];
+			struct rvt_sge *sge = &wqe->sg_list[i];
 
-			hfi1_put_mr(sge->mr);
+			rvt_put_mr(sge->mr);
 		}
 		/* Post a send completion queue entry if requested. */
 		if (!(qp->s_flags & HFI1_S_SIGNAL_REQ_WR) ||
@@ -1059,7 +1059,7 @@ void hfi1_rc_send_complete(struct hfi1_qp *qp, struct hfi1_ib_header *hdr)
 	}
 }
 
-static inline void update_last_psn(struct hfi1_qp *qp, u32 psn)
+static inline void update_last_psn(struct rvt_qp *qp, u32 psn)
 {
 	qp->s_last_psn = psn;
 }
@@ -1069,9 +1069,9 @@ static inline void update_last_psn(struct hfi1_qp *qp, u32 psn)
  * This is similar to hfi1_send_complete but has to check to be sure
  * that the SGEs are not being referenced if the SWQE is being resent.
  */
-static struct hfi1_swqe *do_rc_completion(struct hfi1_qp *qp,
-					  struct hfi1_swqe *wqe,
-					  struct hfi1_ibport *ibp)
+static struct rvt_swqe *do_rc_completion(struct rvt_qp *qp,
+					 struct rvt_swqe *wqe,
+					 struct hfi1_ibport *ibp)
 {
 	struct ib_wc wc;
 	unsigned i;
@@ -1084,9 +1084,9 @@ static struct hfi1_swqe *do_rc_completion(struct hfi1_qp *qp,
 	if (cmp_psn(wqe->lpsn, qp->s_sending_psn) < 0 ||
 	    cmp_psn(qp->s_sending_psn, qp->s_sending_hpsn) > 0) {
 		for (i = 0; i < wqe->wr.num_sge; i++) {
-			struct hfi1_sge *sge = &wqe->sg_list[i];
+			struct rvt_sge *sge = &wqe->sg_list[i];
 
-			hfi1_put_mr(sge->mr);
+			rvt_put_mr(sge->mr);
 		}
 		/* Post a send completion queue entry if requested. */
 		if (!(qp->s_flags & HFI1_S_SIGNAL_REQ_WR) ||
@@ -1158,12 +1158,12 @@ static struct hfi1_swqe *do_rc_completion(struct hfi1_qp *qp,
  * May be called at interrupt level, with the QP s_lock held.
  * Returns 1 if OK, 0 if current operation should be aborted (NAK).
  */
-static int do_rc_ack(struct hfi1_qp *qp, u32 aeth, u32 psn, int opcode,
+static int do_rc_ack(struct rvt_qp *qp, u32 aeth, u32 psn, int opcode,
 		     u64 val, struct hfi1_ctxtdata *rcd)
 {
 	struct hfi1_ibport *ibp;
 	enum ib_wc_status status;
-	struct hfi1_swqe *wqe;
+	struct rvt_swqe *wqe;
 	int ret = 0;
 	u32 ack_psn;
 	int diff;
@@ -1381,10 +1381,10 @@ bail:
  * We have seen an out of sequence RDMA read middle or last packet.
  * This ACKs SENDs and RDMA writes up to the first RDMA read or atomic SWQE.
  */
-static void rdma_seq_err(struct hfi1_qp *qp, struct hfi1_ibport *ibp, u32 psn,
+static void rdma_seq_err(struct rvt_qp *qp, struct hfi1_ibport *ibp, u32 psn,
 			 struct hfi1_ctxtdata *rcd)
 {
-	struct hfi1_swqe *wqe;
+	struct rvt_swqe *wqe;
 
 	/* Remove QP from retry timer */
 	if (qp->s_flags & (HFI1_S_TIMER | HFI1_S_WAIT_RNR)) {
@@ -1430,11 +1430,11 @@ static void rdma_seq_err(struct hfi1_qp *qp, struct hfi1_ibport *ibp, u32 psn,
  */
 static void rc_rcv_resp(struct hfi1_ibport *ibp,
 			struct hfi1_other_headers *ohdr,
-			void *data, u32 tlen, struct hfi1_qp *qp,
+			void *data, u32 tlen, struct rvt_qp *qp,
 			u32 opcode, u32 psn, u32 hdrsize, u32 pmtu,
 			struct hfi1_ctxtdata *rcd)
 {
-	struct hfi1_swqe *wqe;
+	struct rvt_swqe *wqe;
 	enum ib_wc_status status;
 	unsigned long flags;
 	int diff;
@@ -1610,7 +1610,7 @@ bail:
 }
 
 static inline void rc_defered_ack(struct hfi1_ctxtdata *rcd,
-				  struct hfi1_qp *qp)
+				  struct rvt_qp *qp)
 {
 	if (list_empty(&qp->rspwait)) {
 		qp->r_flags |= HFI1_R_RSP_DEFERED_ACK;
@@ -1619,7 +1619,7 @@ static inline void rc_defered_ack(struct hfi1_ctxtdata *rcd,
 	}
 }
 
-static inline void rc_cancel_ack(struct hfi1_qp *qp)
+static inline void rc_cancel_ack(struct rvt_qp *qp)
 {
 	struct hfi1_qp_priv *priv = qp->priv;
 
@@ -1648,11 +1648,11 @@ static inline void rc_cancel_ack(struct hfi1_qp *qp)
  * schedule a response to be sent.
  */
 static noinline int rc_rcv_error(struct hfi1_other_headers *ohdr, void *data,
-			struct hfi1_qp *qp, u32 opcode, u32 psn, int diff,
+			struct rvt_qp *qp, u32 opcode, u32 psn, int diff,
 			struct hfi1_ctxtdata *rcd)
 {
 	struct hfi1_ibport *ibp = to_iport(qp->ibqp.device, qp->port_num);
-	struct hfi1_ack_entry *e;
+	struct rvt_ack_entry *e;
 	unsigned long flags;
 	u8 i, prev;
 	int old_req;
@@ -1750,7 +1750,7 @@ static noinline int rc_rcv_error(struct hfi1_other_headers *ohdr, void *data,
 		if (unlikely(offset + len != e->rdma_sge.sge_length))
 			goto unlock_done;
 		if (e->rdma_sge.mr) {
-			hfi1_put_mr(e->rdma_sge.mr);
+			rvt_put_mr(e->rdma_sge.mr);
 			e->rdma_sge.mr = NULL;
 		}
 		if (len != 0) {
@@ -1758,8 +1758,8 @@ static noinline int rc_rcv_error(struct hfi1_other_headers *ohdr, void *data,
 			u64 vaddr = be64_to_cpu(reth->vaddr);
 			int ok;
 
-			ok = hfi1_rkey_ok(qp, &e->rdma_sge, len, vaddr, rkey,
-					  IB_ACCESS_REMOTE_READ);
+			ok = rvt_rkey_ok(qp, &e->rdma_sge, len, vaddr, rkey,
+					 IB_ACCESS_REMOTE_READ);
 			if (unlikely(!ok))
 				goto unlock_done;
 		} else {
@@ -1826,7 +1826,7 @@ send_ack:
 	return 0;
 }
 
-void hfi1_rc_error(struct hfi1_qp *qp, enum ib_wc_status err)
+void hfi1_rc_error(struct rvt_qp *qp, enum ib_wc_status err)
 {
 	unsigned long flags;
 	int lastwqe;
@@ -1845,7 +1845,7 @@ void hfi1_rc_error(struct hfi1_qp *qp, enum ib_wc_status err)
 	}
 }
 
-static inline void update_ack_queue(struct hfi1_qp *qp, unsigned n)
+static inline void update_ack_queue(struct rvt_qp *qp, unsigned n)
 {
 	unsigned next;
 
@@ -1960,7 +1960,7 @@ void hfi1_rc_rcv(struct hfi1_packet *packet)
 	u32 rcv_flags = packet->rcv_flags;
 	void *data = packet->ebuf;
 	u32 tlen = packet->tlen;
-	struct hfi1_qp *qp = packet->qp;
+	struct rvt_qp *qp = packet->qp;
 	struct hfi1_ibport *ibp = to_iport(qp->ibqp.device, qp->port_num);
 	struct hfi1_pportdata *ppd = ppd_from_ibp(ibp);
 	struct hfi1_other_headers *ohdr = packet->ohdr;
@@ -2177,8 +2177,8 @@ send_last:
 			int ok;
 
 			/* Check rkey & NAK */
-			ok = hfi1_rkey_ok(qp, &qp->r_sge.sge, qp->r_len, vaddr,
-					  rkey, IB_ACCESS_REMOTE_WRITE);
+			ok = rvt_rkey_ok(qp, &qp->r_sge.sge, qp->r_len, vaddr,
+					 rkey, IB_ACCESS_REMOTE_WRITE);
 			if (unlikely(!ok))
 				goto nack_acc;
 			qp->r_sge.num_sge = 1;
@@ -2203,7 +2203,7 @@ send_last:
 		goto send_last;
 
 	case OP(RDMA_READ_REQUEST): {
-		struct hfi1_ack_entry *e;
+		struct rvt_ack_entry *e;
 		u32 len;
 		u8 next;
 
@@ -2221,7 +2221,7 @@ send_last:
 		}
 		e = &qp->s_ack_queue[qp->r_head_ack_queue];
 		if (e->opcode == OP(RDMA_READ_REQUEST) && e->rdma_sge.mr) {
-			hfi1_put_mr(e->rdma_sge.mr);
+			rvt_put_mr(e->rdma_sge.mr);
 			e->rdma_sge.mr = NULL;
 		}
 		reth = &ohdr->u.rc.reth;
@@ -2232,8 +2232,8 @@ send_last:
 			int ok;
 
 			/* Check rkey & NAK */
-			ok = hfi1_rkey_ok(qp, &e->rdma_sge, len, vaddr,
-					  rkey, IB_ACCESS_REMOTE_READ);
+			ok = rvt_rkey_ok(qp, &e->rdma_sge, len, vaddr,
+					 rkey, IB_ACCESS_REMOTE_READ);
 			if (unlikely(!ok))
 				goto nack_acc_unlck;
 			/*
@@ -2276,7 +2276,7 @@ send_last:
 	case OP(COMPARE_SWAP):
 	case OP(FETCH_ADD): {
 		struct ib_atomic_eth *ateth;
-		struct hfi1_ack_entry *e;
+		struct rvt_ack_entry *e;
 		u64 vaddr;
 		atomic64_t *maddr;
 		u64 sdata;
@@ -2296,7 +2296,7 @@ send_last:
 		}
 		e = &qp->s_ack_queue[qp->r_head_ack_queue];
 		if (e->opcode == OP(RDMA_READ_REQUEST) && e->rdma_sge.mr) {
-			hfi1_put_mr(e->rdma_sge.mr);
+			rvt_put_mr(e->rdma_sge.mr);
 			e->rdma_sge.mr = NULL;
 		}
 		ateth = &ohdr->u.atomic_eth;
@@ -2306,9 +2306,9 @@ send_last:
 			goto nack_inv_unlck;
 		rkey = be32_to_cpu(ateth->rkey);
 		/* Check rkey & NAK */
-		if (unlikely(!hfi1_rkey_ok(qp, &qp->r_sge.sge, sizeof(u64),
-					   vaddr, rkey,
-					   IB_ACCESS_REMOTE_ATOMIC)))
+		if (unlikely(!rvt_rkey_ok(qp, &qp->r_sge.sge, sizeof(u64),
+					  vaddr, rkey,
+					  IB_ACCESS_REMOTE_ATOMIC)))
 			goto nack_acc_unlck;
 		/* Perform atomic OP and save result. */
 		maddr = (atomic64_t *) qp->r_sge.sge.vaddr;
@@ -2318,7 +2318,7 @@ send_last:
 			(u64) cmpxchg((u64 *) qp->r_sge.sge.vaddr,
 				      be64_to_cpu(ateth->compare_data),
 				      sdata);
-		hfi1_put_mr(qp->r_sge.sge.mr);
+		rvt_put_mr(qp->r_sge.sge.mr);
 		qp->r_sge.num_sge = 0;
 		e->opcode = opcode;
 		e->sent = 0;
@@ -2408,7 +2408,7 @@ void hfi1_rc_hdrerr(
 	struct hfi1_ctxtdata *rcd,
 	struct hfi1_ib_header *hdr,
 	u32 rcv_flags,
-	struct hfi1_qp *qp)
+	struct rvt_qp *qp)
 {
 	int has_grh = rcv_flags & HFI1_HAS_GRH;
 	struct hfi1_other_headers *ohdr;
* Unmerged path drivers/staging/hfi1/ruc.c
diff --git a/drivers/staging/hfi1/sdma.h b/drivers/staging/hfi1/sdma.h
index fbd0e41be135..0f51c45869d5 100644
--- a/drivers/staging/hfi1/sdma.h
+++ b/drivers/staging/hfi1/sdma.h
@@ -379,10 +379,10 @@ struct sdma_txreq {
 struct verbs_txreq {
 	struct hfi1_pio_header	phdr;
 	struct sdma_txreq       txreq;
-	struct hfi1_qp           *qp;
-	struct hfi1_swqe         *wqe;
+	struct rvt_qp           *qp;
+	struct rvt_swqe         *wqe;
 	struct rvt_mregion	*mr;
-	struct hfi1_sge_state    *ss;
+	struct rvt_sge_state    *ss;
 	struct sdma_engine     *sde;
 	u16                     hdr_dwords;
 	u16                     hdr_inx;
diff --git a/drivers/staging/hfi1/srq.c b/drivers/staging/hfi1/srq.c
index 67786d417493..932bd96073ca 100644
--- a/drivers/staging/hfi1/srq.c
+++ b/drivers/staging/hfi1/srq.c
@@ -66,12 +66,12 @@ int hfi1_post_srq_receive(struct ib_srq *ibsrq, struct ib_recv_wr *wr,
 			  struct ib_recv_wr **bad_wr)
 {
 	struct hfi1_srq *srq = to_isrq(ibsrq);
-	struct hfi1_rwq *wq;
+	struct rvt_rwq *wq;
 	unsigned long flags;
 	int ret;
 
 	for (; wr; wr = wr->next) {
-		struct hfi1_rwqe *wqe;
+		struct rvt_rwqe *wqe;
 		u32 next;
 		int i;
 
@@ -149,8 +149,8 @@ struct ib_srq *hfi1_create_srq(struct ib_pd *ibpd,
 	srq->rq.size = srq_init_attr->attr.max_wr + 1;
 	srq->rq.max_sge = srq_init_attr->attr.max_sge;
 	sz = sizeof(struct ib_sge) * srq->rq.max_sge +
-		sizeof(struct hfi1_rwqe);
-	srq->rq.wq = vmalloc_user(sizeof(struct hfi1_rwq) + srq->rq.size * sz);
+		sizeof(struct rvt_rwqe);
+	srq->rq.wq = vmalloc_user(sizeof(struct rvt_rwq) + srq->rq.size * sz);
 	if (!srq->rq.wq) {
 		ret = ERR_PTR(-ENOMEM);
 		goto bail_srq;
@@ -162,7 +162,7 @@ struct ib_srq *hfi1_create_srq(struct ib_pd *ibpd,
 	 */
 	if (udata && udata->outlen >= sizeof(__u64)) {
 		int err;
-		u32 s = sizeof(struct hfi1_rwq) + srq->rq.size * sz;
+		u32 s = sizeof(struct rvt_rwq) + srq->rq.size * sz;
 
 		srq->ip =
 		    hfi1_create_mmap_info(dev, s, ibpd->uobject->context,
@@ -230,12 +230,12 @@ int hfi1_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,
 		    struct ib_udata *udata)
 {
 	struct hfi1_srq *srq = to_isrq(ibsrq);
-	struct hfi1_rwq *wq;
+	struct rvt_rwq *wq;
 	int ret = 0;
 
 	if (attr_mask & IB_SRQ_MAX_WR) {
-		struct hfi1_rwq *owq;
-		struct hfi1_rwqe *p;
+		struct rvt_rwq *owq;
+		struct rvt_rwqe *p;
 		u32 sz, size, n, head, tail;
 
 		/* Check that the requested sizes are below the limits. */
@@ -246,10 +246,10 @@ int hfi1_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,
 			goto bail;
 		}
 
-		sz = sizeof(struct hfi1_rwqe) +
+		sz = sizeof(struct rvt_rwqe) +
 			srq->rq.max_sge * sizeof(struct ib_sge);
 		size = attr->max_wr + 1;
-		wq = vmalloc_user(sizeof(struct hfi1_rwq) + size * sz);
+		wq = vmalloc_user(sizeof(struct rvt_rwq) + size * sz);
 		if (!wq) {
 			ret = -ENOMEM;
 			goto bail;
@@ -296,7 +296,7 @@ int hfi1_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,
 		n = 0;
 		p = wq->wq;
 		while (tail != head) {
-			struct hfi1_rwqe *wqe;
+			struct rvt_rwqe *wqe;
 			int i;
 
 			wqe = get_rwqe_ptr(&srq->rq, tail);
@@ -305,7 +305,7 @@ int hfi1_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,
 			for (i = 0; i < wqe->num_sge; i++)
 				p->sg_list[i] = wqe->sg_list[i];
 			n++;
-			p = (struct hfi1_rwqe *)((char *)p + sz);
+			p = (struct rvt_rwqe *)((char *)p + sz);
 			if (++tail >= srq->rq.size)
 				tail = 0;
 		}
@@ -320,9 +320,9 @@ int hfi1_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,
 		vfree(owq);
 
 		if (srq->ip) {
-			struct hfi1_mmap_info *ip = srq->ip;
+			struct rvt_mmap_info *ip = srq->ip;
 			struct hfi1_ibdev *dev = to_idev(srq->ibsrq.device);
-			u32 s = sizeof(struct hfi1_rwq) + size * sz;
+			u32 s = sizeof(struct rvt_rwq) + size * sz;
 
 			hfi1_update_mmap_info(dev, ip, s, wq);
 
diff --git a/drivers/staging/hfi1/trace.h b/drivers/staging/hfi1/trace.h
index 86c12ebfd4f0..b3119a5c02de 100644
--- a/drivers/staging/hfi1/trace.h
+++ b/drivers/staging/hfi1/trace.h
@@ -294,7 +294,7 @@ TRACE_EVENT(hfi1_wantpiointr,
 );
 
 DECLARE_EVENT_CLASS(hfi1_qpsleepwakeup_template,
-	TP_PROTO(struct hfi1_qp *qp, u32 flags),
+	TP_PROTO(struct rvt_qp *qp, u32 flags),
 	TP_ARGS(qp, flags),
 	TP_STRUCT__entry(
 		DD_DEV_ENTRY(dd_from_ibdev(qp->ibqp.device))
@@ -318,17 +318,17 @@ DECLARE_EVENT_CLASS(hfi1_qpsleepwakeup_template,
 );
 
 DEFINE_EVENT(hfi1_qpsleepwakeup_template, hfi1_qpwakeup,
-	     TP_PROTO(struct hfi1_qp *qp, u32 flags),
+	     TP_PROTO(struct rvt_qp *qp, u32 flags),
 	     TP_ARGS(qp, flags));
 
 DEFINE_EVENT(hfi1_qpsleepwakeup_template, hfi1_qpsleep,
-	     TP_PROTO(struct hfi1_qp *qp, u32 flags),
+	     TP_PROTO(struct rvt_qp *qp, u32 flags),
 	     TP_ARGS(qp, flags));
 
 #undef TRACE_SYSTEM
 #define TRACE_SYSTEM hfi1_qphash
 DECLARE_EVENT_CLASS(hfi1_qphash_template,
-	TP_PROTO(struct hfi1_qp *qp, u32 bucket),
+	TP_PROTO(struct rvt_qp *qp, u32 bucket),
 	TP_ARGS(qp, bucket),
 	TP_STRUCT__entry(
 		DD_DEV_ENTRY(dd_from_ibdev(qp->ibqp.device))
@@ -349,11 +349,11 @@ DECLARE_EVENT_CLASS(hfi1_qphash_template,
 );
 
 DEFINE_EVENT(hfi1_qphash_template, hfi1_qpinsert,
-	TP_PROTO(struct hfi1_qp *qp, u32 bucket),
+	TP_PROTO(struct rvt_qp *qp, u32 bucket),
 	TP_ARGS(qp, bucket));
 
 DEFINE_EVENT(hfi1_qphash_template, hfi1_qpremove,
-	TP_PROTO(struct hfi1_qp *qp, u32 bucket),
+	TP_PROTO(struct rvt_qp *qp, u32 bucket),
 	TP_ARGS(qp, bucket));
 
 #undef TRACE_SYSTEM
@@ -1254,7 +1254,7 @@ TRACE_EVENT(hfi1_sdma_state,
 #define TRACE_SYSTEM hfi1_rc
 
 DECLARE_EVENT_CLASS(hfi1_rc_template,
-	TP_PROTO(struct hfi1_qp *qp, u32 psn),
+	TP_PROTO(struct rvt_qp *qp, u32 psn),
 	TP_ARGS(qp, psn),
 	TP_STRUCT__entry(
 		DD_DEV_ENTRY(dd_from_ibdev(qp->ibqp.device))
@@ -1293,22 +1293,22 @@ DECLARE_EVENT_CLASS(hfi1_rc_template,
 );
 
 DEFINE_EVENT(hfi1_rc_template, hfi1_rc_sendcomplete,
-	     TP_PROTO(struct hfi1_qp *qp, u32 psn),
+	     TP_PROTO(struct rvt_qp *qp, u32 psn),
 	     TP_ARGS(qp, psn)
 );
 
 DEFINE_EVENT(hfi1_rc_template, hfi1_rc_ack,
-	     TP_PROTO(struct hfi1_qp *qp, u32 psn),
+	     TP_PROTO(struct rvt_qp *qp, u32 psn),
 	     TP_ARGS(qp, psn)
 );
 
 DEFINE_EVENT(hfi1_rc_template, hfi1_rc_timeout,
-	     TP_PROTO(struct hfi1_qp *qp, u32 psn),
+	     TP_PROTO(struct rvt_qp *qp, u32 psn),
 	     TP_ARGS(qp, psn)
 );
 
 DEFINE_EVENT(hfi1_rc_template, hfi1_rc_rcv_error,
-	     TP_PROTO(struct hfi1_qp *qp, u32 psn),
+	     TP_PROTO(struct rvt_qp *qp, u32 psn),
 	     TP_ARGS(qp, psn)
 );
 
diff --git a/drivers/staging/hfi1/uc.c b/drivers/staging/hfi1/uc.c
index fc90d4f544e4..8b3b5f2b7bac 100644
--- a/drivers/staging/hfi1/uc.c
+++ b/drivers/staging/hfi1/uc.c
@@ -61,11 +61,11 @@
  *
  * Return 1 if constructed; otherwise, return 0.
  */
-int hfi1_make_uc_req(struct hfi1_qp *qp)
+int hfi1_make_uc_req(struct rvt_qp *qp)
 {
 	struct hfi1_qp_priv *priv = qp->priv;
 	struct hfi1_other_headers *ohdr;
-	struct hfi1_swqe *wqe;
+	struct rvt_swqe *wqe;
 	unsigned long flags;
 	u32 hwords = 5;
 	u32 bth0 = 0;
@@ -267,7 +267,7 @@ void hfi1_uc_rcv(struct hfi1_packet *packet)
 	u32 rcv_flags = packet->rcv_flags;
 	void *data = packet->ebuf;
 	u32 tlen = packet->tlen;
-	struct hfi1_qp *qp = packet->qp;
+	struct rvt_qp *qp = packet->qp;
 	struct hfi1_other_headers *ohdr = packet->ohdr;
 	u32 bth0, opcode;
 	u32 hdrsize = packet->hlen;
@@ -492,8 +492,8 @@ rdma_first:
 			int ok;
 
 			/* Check rkey */
-			ok = hfi1_rkey_ok(qp, &qp->r_sge.sge, qp->r_len,
-					  vaddr, rkey, IB_ACCESS_REMOTE_WRITE);
+			ok = rvt_rkey_ok(qp, &qp->r_sge.sge, qp->r_len,
+					 vaddr, rkey, IB_ACCESS_REMOTE_WRITE);
 			if (unlikely(!ok))
 				goto drop;
 			qp->r_sge.num_sge = 1;
diff --git a/drivers/staging/hfi1/ud.c b/drivers/staging/hfi1/ud.c
index a7f67b0111da..726222fd0438 100644
--- a/drivers/staging/hfi1/ud.c
+++ b/drivers/staging/hfi1/ud.c
@@ -65,15 +65,15 @@
  * Note that the receive interrupt handler may be calling hfi1_ud_rcv()
  * while this is being called.
  */
-static void ud_loopback(struct hfi1_qp *sqp, struct hfi1_swqe *swqe)
+static void ud_loopback(struct rvt_qp *sqp, struct rvt_swqe *swqe)
 {
 	struct hfi1_ibport *ibp = to_iport(sqp->ibqp.device, sqp->port_num);
 	struct hfi1_pportdata *ppd;
-	struct hfi1_qp *qp;
+	struct rvt_qp *qp;
 	struct ib_ah_attr *ah_attr;
 	unsigned long flags;
-	struct hfi1_sge_state ssge;
-	struct hfi1_sge *sge;
+	struct rvt_sge_state ssge;
+	struct rvt_sge *sge;
 	struct ib_wc wc;
 	u32 length;
 	enum ib_qp_type sqptype, dqptype;
@@ -262,14 +262,14 @@ drop:
  *
  * Return 1 if constructed; otherwise, return 0.
  */
-int hfi1_make_ud_req(struct hfi1_qp *qp)
+int hfi1_make_ud_req(struct rvt_qp *qp)
 {
 	struct hfi1_qp_priv *priv = qp->priv;
 	struct hfi1_other_headers *ohdr;
 	struct ib_ah_attr *ah_attr;
 	struct hfi1_pportdata *ppd;
 	struct hfi1_ibport *ibp;
-	struct hfi1_swqe *wqe;
+	struct rvt_swqe *wqe;
 	unsigned long flags;
 	u32 nwords;
 	u32 extra_bytes;
@@ -477,7 +477,7 @@ int hfi1_lookup_pkey_idx(struct hfi1_ibport *ibp, u16 pkey)
 	return -1;
 }
 
-void return_cnp(struct hfi1_ibport *ibp, struct hfi1_qp *qp, u32 remote_qpn,
+void return_cnp(struct hfi1_ibport *ibp, struct rvt_qp *qp, u32 remote_qpn,
 		u32 pkey, u32 slid, u32 dlid, u8 sc5,
 		const struct ib_grh *old_grh)
 {
@@ -551,7 +551,7 @@ void return_cnp(struct hfi1_ibport *ibp, struct hfi1_qp *qp, u32 remote_qpn,
  * opa_smp_check() returns 0 if all checks succeed, 1 otherwise.
  */
 static int opa_smp_check(struct hfi1_ibport *ibp, u16 pkey, u8 sc5,
-			 struct hfi1_qp *qp, u16 slid, struct opa_smp *smp)
+			 struct rvt_qp *qp, u16 slid, struct opa_smp *smp)
 {
 	struct hfi1_pportdata *ppd = ppd_from_ibp(ibp);
 
@@ -655,7 +655,7 @@ void hfi1_ud_rcv(struct hfi1_packet *packet)
 	u32 rcv_flags = packet->rcv_flags;
 	void *data = packet->ebuf;
 	u32 tlen = packet->tlen;
-	struct hfi1_qp *qp = packet->qp;
+	struct rvt_qp *qp = packet->qp;
 	bool has_grh = rcv_flags & HFI1_HAS_GRH;
 	bool sc4_bit = has_sc4_bit(packet);
 	u8 sc;
* Unmerged path drivers/staging/hfi1/verbs.c
* Unmerged path drivers/staging/hfi1/verbs.h
diff --git a/drivers/staging/hfi1/verbs_mcast.c b/drivers/staging/hfi1/verbs_mcast.c
index afc6b4c61a1d..49954b9b9e36 100644
--- a/drivers/staging/hfi1/verbs_mcast.c
+++ b/drivers/staging/hfi1/verbs_mcast.c
@@ -56,7 +56,7 @@
  * mcast_qp_alloc - alloc a struct to link a QP to mcast GID struct
  * @qp: the QP to link
  */
-static struct hfi1_mcast_qp *mcast_qp_alloc(struct hfi1_qp *qp)
+static struct hfi1_mcast_qp *mcast_qp_alloc(struct rvt_qp *qp)
 {
 	struct hfi1_mcast_qp *mqp;
 
@@ -73,7 +73,7 @@ bail:
 
 static void mcast_qp_free(struct hfi1_mcast_qp *mqp)
 {
-	struct hfi1_qp *qp = mqp->qp;
+	struct rvt_qp *qp = mqp->qp;
 
 	/* Notify hfi1_destroy_qp() if it is waiting. */
 	if (atomic_dec_and_test(&qp->refcount))
@@ -241,7 +241,7 @@ bail:
 
 int hfi1_multicast_attach(struct ib_qp *ibqp, union ib_gid *gid, u16 lid)
 {
-	struct hfi1_qp *qp = to_iqp(ibqp);
+	struct rvt_qp *qp = to_iqp(ibqp);
 	struct hfi1_ibdev *dev = to_idev(ibqp->device);
 	struct hfi1_ibport *ibp;
 	struct hfi1_mcast *mcast;
@@ -299,7 +299,7 @@ bail:
 
 int hfi1_multicast_detach(struct ib_qp *ibqp, union ib_gid *gid, u16 lid)
 {
-	struct hfi1_qp *qp = to_iqp(ibqp);
+	struct rvt_qp *qp = to_iqp(ibqp);
 	struct hfi1_ibdev *dev = to_idev(ibqp->device);
 	struct hfi1_ibport *ibp = to_iport(ibqp->device, qp->port_num);
 	struct hfi1_mcast *mcast = NULL;
