x86/mce/amd: Introduce deferred error interrupt handler

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [x86] mce/amd: Introduce deferred error interrupt handler (Prarit Bhargava) [1301710]
Rebuild_FUZZ: 96.23%
commit-author Aravind Gopalakrishnan <Aravind.Gopalakrishnan@amd.com>
commit 24fd78a81f6d3fe7f7a440c8629f9c52cd5f830e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/24fd78a8.failed

Deferred errors indicate error conditions that were not corrected, but
require no action from S/W (or action is optional).These errors provide
info about a latent UC MCE that can occur when a poisoned data is
consumed by the processor.

Processors that report these errors can be configured to generate APIC
interrupts to notify OS about the error.

Provide an interrupt handler in this patch so that OS can catch these
errors as and when they happen. Currently, we simply log the errors and
exit the handler as S/W action is not mandated.

	Signed-off-by: Aravind Gopalakrishnan <Aravind.Gopalakrishnan@amd.com>
	Cc: Tony Luck <tony.luck@intel.com>
	Cc: x86-ml <x86@kernel.org>
	Cc: linux-edac <linux-edac@vger.kernel.org>
Link: http://lkml.kernel.org/r/1430913538-1415-5-git-send-email-Aravind.Gopalakrishnan@amd.com
	Signed-off-by: Borislav Petkov <bp@suse.de>
(cherry picked from commit 24fd78a81f6d3fe7f7a440c8629f9c52cd5f830e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/hardirq.h
#	arch/x86/include/asm/hw_irq.h
#	arch/x86/kernel/irqinit.c
diff --cc arch/x86/include/asm/hardirq.h
index 0886952762b8,db9f536f482f..000000000000
--- a/arch/x86/include/asm/hardirq.h
+++ b/arch/x86/include/asm/hardirq.h
@@@ -33,6 -33,12 +33,15 @@@ typedef struct 
  #ifdef CONFIG_X86_MCE_THRESHOLD
  	unsigned int irq_threshold_count;
  #endif
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_X86_MCE_AMD
+ 	unsigned int irq_deferred_error_count;
+ #endif
+ #if IS_ENABLED(CONFIG_HYPERV) || defined(CONFIG_XEN)
+ 	unsigned int irq_hv_callback_count;
+ #endif
++>>>>>>> 24fd78a81f6d (x86/mce/amd: Introduce deferred error interrupt handler)
  } ____cacheline_aligned irq_cpustat_t;
  
  DECLARE_PER_CPU_SHARED_ALIGNED(irq_cpustat_t, irq_stat);
diff --cc arch/x86/include/asm/hw_irq.h
index 4ab2c8af2de0,f71e489d7537..000000000000
--- a/arch/x86/include/asm/hw_irq.h
+++ b/arch/x86/include/asm/hw_irq.h
@@@ -26,56 -26,57 +26,63 @@@
  #include <asm/sections.h>
  
  /* Interrupt handlers registered during init_IRQ */
 -extern asmlinkage void apic_timer_interrupt(void);
 -extern asmlinkage void x86_platform_ipi(void);
 -extern asmlinkage void kvm_posted_intr_ipi(void);
 -extern asmlinkage void error_interrupt(void);
 -extern asmlinkage void irq_work_interrupt(void);
 -
 -extern asmlinkage void spurious_interrupt(void);
 -extern asmlinkage void thermal_interrupt(void);
 -extern asmlinkage void reschedule_interrupt(void);
 -
 -extern asmlinkage void invalidate_interrupt(void);
 -extern asmlinkage void invalidate_interrupt0(void);
 -extern asmlinkage void invalidate_interrupt1(void);
 -extern asmlinkage void invalidate_interrupt2(void);
 -extern asmlinkage void invalidate_interrupt3(void);
 -extern asmlinkage void invalidate_interrupt4(void);
 -extern asmlinkage void invalidate_interrupt5(void);
 -extern asmlinkage void invalidate_interrupt6(void);
 -extern asmlinkage void invalidate_interrupt7(void);
 -extern asmlinkage void invalidate_interrupt8(void);
 -extern asmlinkage void invalidate_interrupt9(void);
 -extern asmlinkage void invalidate_interrupt10(void);
 -extern asmlinkage void invalidate_interrupt11(void);
 -extern asmlinkage void invalidate_interrupt12(void);
 -extern asmlinkage void invalidate_interrupt13(void);
 -extern asmlinkage void invalidate_interrupt14(void);
 -extern asmlinkage void invalidate_interrupt15(void);
 -extern asmlinkage void invalidate_interrupt16(void);
 -extern asmlinkage void invalidate_interrupt17(void);
 -extern asmlinkage void invalidate_interrupt18(void);
 -extern asmlinkage void invalidate_interrupt19(void);
 -extern asmlinkage void invalidate_interrupt20(void);
 -extern asmlinkage void invalidate_interrupt21(void);
 -extern asmlinkage void invalidate_interrupt22(void);
 -extern asmlinkage void invalidate_interrupt23(void);
 -extern asmlinkage void invalidate_interrupt24(void);
 -extern asmlinkage void invalidate_interrupt25(void);
 -extern asmlinkage void invalidate_interrupt26(void);
 -extern asmlinkage void invalidate_interrupt27(void);
 -extern asmlinkage void invalidate_interrupt28(void);
 -extern asmlinkage void invalidate_interrupt29(void);
 -extern asmlinkage void invalidate_interrupt30(void);
 -extern asmlinkage void invalidate_interrupt31(void);
 -
 +extern void apic_timer_interrupt(void);
 +extern void x86_platform_ipi(void);
 +extern void kvm_posted_intr_ipi(void);
 +extern void error_interrupt(void);
 +extern void irq_work_interrupt(void);
 +
 +extern void spurious_interrupt(void);
 +extern void thermal_interrupt(void);
 +extern void reschedule_interrupt(void);
 +
 +extern void invalidate_interrupt(void);
 +extern void invalidate_interrupt0(void);
 +extern void invalidate_interrupt1(void);
 +extern void invalidate_interrupt2(void);
 +extern void invalidate_interrupt3(void);
 +extern void invalidate_interrupt4(void);
 +extern void invalidate_interrupt5(void);
 +extern void invalidate_interrupt6(void);
 +extern void invalidate_interrupt7(void);
 +extern void invalidate_interrupt8(void);
 +extern void invalidate_interrupt9(void);
 +extern void invalidate_interrupt10(void);
 +extern void invalidate_interrupt11(void);
 +extern void invalidate_interrupt12(void);
 +extern void invalidate_interrupt13(void);
 +extern void invalidate_interrupt14(void);
 +extern void invalidate_interrupt15(void);
 +extern void invalidate_interrupt16(void);
 +extern void invalidate_interrupt17(void);
 +extern void invalidate_interrupt18(void);
 +extern void invalidate_interrupt19(void);
 +extern void invalidate_interrupt20(void);
 +extern void invalidate_interrupt21(void);
 +extern void invalidate_interrupt22(void);
 +extern void invalidate_interrupt23(void);
 +extern void invalidate_interrupt24(void);
 +extern void invalidate_interrupt25(void);
 +extern void invalidate_interrupt26(void);
 +extern void invalidate_interrupt27(void);
 +extern void invalidate_interrupt28(void);
 +extern void invalidate_interrupt29(void);
 +extern void invalidate_interrupt30(void);
 +extern void invalidate_interrupt31(void);
 +
++<<<<<<< HEAD
 +extern void irq_move_cleanup_interrupt(void);
 +extern void reboot_interrupt(void);
 +extern void threshold_interrupt(void);
++=======
+ extern asmlinkage void irq_move_cleanup_interrupt(void);
+ extern asmlinkage void reboot_interrupt(void);
+ extern asmlinkage void threshold_interrupt(void);
+ extern asmlinkage void deferred_error_interrupt(void);
++>>>>>>> 24fd78a81f6d (x86/mce/amd: Introduce deferred error interrupt handler)
  
 -extern asmlinkage void call_function_interrupt(void);
 -extern asmlinkage void call_function_single_interrupt(void);
 +extern void call_function_interrupt(void);
 +extern void call_function_single_interrupt(void);
  
  #ifdef CONFIG_TRACING
  /* Interrupt handlers registered during init_IRQ */
diff --cc arch/x86/kernel/irqinit.c
index 1e6cff5814fa,d7ec6e7b2b5b..000000000000
--- a/arch/x86/kernel/irqinit.c
+++ b/arch/x86/kernel/irqinit.c
@@@ -160,7 -135,11 +160,15 @@@ static void __init apic_intr_init(void
  	alloc_intr_gate(THRESHOLD_APIC_VECTOR, threshold_interrupt);
  #endif
  
++<<<<<<< HEAD
 +#if defined(CONFIG_X86_64) || defined(CONFIG_X86_LOCAL_APIC)
++=======
+ #ifdef CONFIG_X86_MCE_AMD
+ 	alloc_intr_gate(DEFERRED_ERROR_VECTOR, deferred_error_interrupt);
+ #endif
+ 
+ #ifdef CONFIG_X86_LOCAL_APIC
++>>>>>>> 24fd78a81f6d (x86/mce/amd: Introduce deferred error interrupt handler)
  	/* self generated IPI for local APIC timer */
  	alloc_intr_gate(LOCAL_TIMER_VECTOR, apic_timer_interrupt);
  
diff --git a/arch/x86/include/asm/entry_arch.h b/arch/x86/include/asm/entry_arch.h
index dc5fa661465f..6da46dbaac87 100644
--- a/arch/x86/include/asm/entry_arch.h
+++ b/arch/x86/include/asm/entry_arch.h
@@ -50,4 +50,7 @@ BUILD_INTERRUPT(thermal_interrupt,THERMAL_APIC_VECTOR)
 BUILD_INTERRUPT(threshold_interrupt,THRESHOLD_APIC_VECTOR)
 #endif
 
+#ifdef CONFIG_X86_MCE_AMD
+BUILD_INTERRUPT(deferred_error_interrupt, DEFERRED_ERROR_VECTOR)
+#endif
 #endif
* Unmerged path arch/x86/include/asm/hardirq.h
* Unmerged path arch/x86/include/asm/hw_irq.h
diff --git a/arch/x86/include/asm/irq_vectors.h b/arch/x86/include/asm/irq_vectors.h
index 5702d7e3111d..0c3a8043efe3 100644
--- a/arch/x86/include/asm/irq_vectors.h
+++ b/arch/x86/include/asm/irq_vectors.h
@@ -113,6 +113,7 @@
 #define IRQ_WORK_VECTOR			0xf6
 
 #define UV_BAU_MESSAGE			0xf5
+#define DEFERRED_ERROR_VECTOR		0xf4
 
 /* Vector on which hypervisor callbacks will be delivered */
 #define HYPERVISOR_CALLBACK_VECTOR	0xf3
diff --git a/arch/x86/include/asm/mce.h b/arch/x86/include/asm/mce.h
index 407ced642ac1..6a3034a0a072 100644
--- a/arch/x86/include/asm/mce.h
+++ b/arch/x86/include/asm/mce.h
@@ -234,6 +234,9 @@ void do_machine_check(struct pt_regs *, long);
 extern void (*mce_threshold_vector)(void);
 extern void (*threshold_cpu_callback)(unsigned long action, unsigned int cpu);
 
+/* Deferred error interrupt handler */
+extern void (*deferred_error_int_vector)(void);
+
 /*
  * Thermal handler
  */
diff --git a/arch/x86/include/asm/trace/irq_vectors.h b/arch/x86/include/asm/trace/irq_vectors.h
index 2874df24e7a4..243cf22c0d90 100644
--- a/arch/x86/include/asm/trace/irq_vectors.h
+++ b/arch/x86/include/asm/trace/irq_vectors.h
@@ -89,6 +89,12 @@ DEFINE_IRQ_VECTOR_EVENT(call_function_single);
  */
 DEFINE_IRQ_VECTOR_EVENT(threshold_apic);
 
+/*
+ * deferred_error_apic - called when entering/exiting a deferred apic interrupt
+ * vector handler
+ */
+DEFINE_IRQ_VECTOR_EVENT(deferred_error_apic);
+
 /*
  * thermal_apic - called when entering/exiting a thermal apic interrupt
  * vector handler
diff --git a/arch/x86/include/asm/traps.h b/arch/x86/include/asm/traps.h
index d017966d93ee..20cd8c7d29ad 100644
--- a/arch/x86/include/asm/traps.h
+++ b/arch/x86/include/asm/traps.h
@@ -112,7 +112,8 @@ void math_error(struct pt_regs *, int, int);
 void math_emulate(struct math_emu_info *);
 #ifndef CONFIG_X86_32
 asmlinkage void smp_thermal_interrupt(void);
-asmlinkage void mce_threshold_interrupt(void);
+asmlinkage void smp_threshold_interrupt(void);
+asmlinkage void smp_deferred_error_interrupt(void);
 #endif
 
 /* Interrupts/Exceptions */
diff --git a/arch/x86/kernel/cpu/mcheck/mce_amd.c b/arch/x86/kernel/cpu/mcheck/mce_amd.c
index 607075726e10..2e7ebe7e1e80 100644
--- a/arch/x86/kernel/cpu/mcheck/mce_amd.c
+++ b/arch/x86/kernel/cpu/mcheck/mce_amd.c
@@ -12,6 +12,8 @@
  *     - added support for AMD Family 0x10 processors
  *  May 2012
  *     - major scrubbing
+ *  May 2015
+ *     - add support for deferred error interrupts (Aravind Gopalakrishnan)
  *
  *  All MC4_MISCi registers are shared between multi-cores
  */
@@ -32,6 +34,7 @@
 #include <asm/idle.h>
 #include <asm/mce.h>
 #include <asm/msr.h>
+#include <asm/trace/irq_vectors.h>
 
 #define NR_BLOCKS         9
 #define THRESHOLD_MAX     0xFFF
@@ -47,6 +50,13 @@
 #define MASK_BLKPTR_LO    0xFF000000
 #define MCG_XBLK_ADDR     0xC0000400
 
+/* Deferred error settings */
+#define MSR_CU_DEF_ERR		0xC0000410
+#define MASK_DEF_LVTOFF		0x000000F0
+#define MASK_DEF_INT_TYPE	0x00000006
+#define DEF_LVT_OFF		0x2
+#define DEF_INT_TYPE_APIC	0x2
+
 static const char * const th_names[] = {
 	"load_store",
 	"insn_fetch",
@@ -60,6 +70,13 @@ static DEFINE_PER_CPU(struct threshold_bank **, threshold_banks);
 static DEFINE_PER_CPU(unsigned char, bank_map);	/* see which banks are on */
 
 static void amd_threshold_interrupt(void);
+static void amd_deferred_error_interrupt(void);
+
+static void default_deferred_error_interrupt(void)
+{
+	pr_err("Unexpected deferred interrupt at vector %x\n", DEFERRED_ERROR_VECTOR);
+}
+void (*deferred_error_int_vector)(void) = default_deferred_error_interrupt;
 
 /*
  * CPU Initialization
@@ -205,6 +222,39 @@ static int setup_APIC_mce(int reserved, int new)
 	return reserved;
 }
 
+static int setup_APIC_deferred_error(int reserved, int new)
+{
+	if (reserved < 0 && !setup_APIC_eilvt(new, DEFERRED_ERROR_VECTOR,
+					      APIC_EILVT_MSG_FIX, 0))
+		return new;
+
+	return reserved;
+}
+
+static void deferred_error_interrupt_enable(struct cpuinfo_x86 *c)
+{
+	u32 low = 0, high = 0;
+	int def_offset = -1, def_new;
+
+	if (rdmsr_safe(MSR_CU_DEF_ERR, &low, &high))
+		return;
+
+	def_new = (low & MASK_DEF_LVTOFF) >> 4;
+	if (!(low & MASK_DEF_LVTOFF)) {
+		pr_err(FW_BUG "Your BIOS is not setting up LVT offset 0x2 for deferred error IRQs correctly.\n");
+		def_new = DEF_LVT_OFF;
+		low = (low & ~MASK_DEF_LVTOFF) | (DEF_LVT_OFF << 4);
+	}
+
+	def_offset = setup_APIC_deferred_error(def_offset, def_new);
+	if ((def_offset == def_new) &&
+	    (deferred_error_int_vector != amd_deferred_error_interrupt))
+		deferred_error_int_vector = amd_deferred_error_interrupt;
+
+	low = (low & ~MASK_DEF_INT_TYPE) | DEF_INT_TYPE_APIC;
+	wrmsr(MSR_CU_DEF_ERR, low, high);
+}
+
 /* cpu init entry point, called from mce.c with preempt off */
 void mce_amd_feature_init(struct cpuinfo_x86 *c)
 {
@@ -262,6 +312,9 @@ init:
 			mce_threshold_block_init(&b, offset);
 		}
 	}
+
+	if (mce_flags.succor)
+		deferred_error_interrupt_enable(c);
 }
 
 static void __log_error(unsigned int bank, bool threshold_err, u64 misc)
@@ -288,6 +341,46 @@ static void __log_error(unsigned int bank, bool threshold_err, u64 misc)
 	wrmsrl(MSR_IA32_MCx_STATUS(bank), 0);
 }
 
+static inline void __smp_deferred_error_interrupt(void)
+{
+	inc_irq_stat(irq_deferred_error_count);
+	deferred_error_int_vector();
+}
+
+asmlinkage __visible void smp_deferred_error_interrupt(void)
+{
+	entering_irq();
+	__smp_deferred_error_interrupt();
+	exiting_ack_irq();
+}
+
+asmlinkage __visible void smp_trace_deferred_error_interrupt(void)
+{
+	entering_irq();
+	trace_deferred_error_apic_entry(DEFERRED_ERROR_VECTOR);
+	__smp_deferred_error_interrupt();
+	trace_deferred_error_apic_exit(DEFERRED_ERROR_VECTOR);
+	exiting_ack_irq();
+}
+
+/* APIC interrupt handler for deferred errors */
+static void amd_deferred_error_interrupt(void)
+{
+	u64 status;
+	unsigned int bank;
+
+	for (bank = 0; bank < mca_cfg.banks; ++bank) {
+		rdmsrl(MSR_IA32_MCx_STATUS(bank), status);
+
+		if (!(status & MCI_STATUS_VAL) ||
+		    !(status & MCI_STATUS_DEFERRED))
+			continue;
+
+		__log_error(bank, false, 0);
+		break;
+	}
+}
+
 /*
  * APIC Interrupt Handler
  */
diff --git a/arch/x86/kernel/entry_64.S b/arch/x86/kernel/entry_64.S
index 39c3b8e356d9..aa9d080c6b54 100644
--- a/arch/x86/kernel/entry_64.S
+++ b/arch/x86/kernel/entry_64.S
@@ -991,6 +991,11 @@ apicinterrupt THRESHOLD_APIC_VECTOR \
 	threshold_interrupt smp_threshold_interrupt
 #endif
 
+#ifdef CONFIG_X86_MCE_AMD
+apicinterrupt DEFERRED_ERROR_VECTOR \
+	deferred_error_interrupt smp_deferred_error_interrupt
+#endif
+
 #ifdef CONFIG_X86_THERMAL_VECTOR
 apicinterrupt THERMAL_APIC_VECTOR \
 	thermal_interrupt smp_thermal_interrupt
diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index 4ab5f9ad5a0c..23ae631ea77b 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -116,6 +116,12 @@ int arch_show_interrupts(struct seq_file *p, int prec)
 		seq_printf(p, "%10u ", irq_stats(j)->irq_threshold_count);
 	seq_printf(p, "  Threshold APIC interrupts\n");
 #endif
+#ifdef CONFIG_X86_MCE_AMD
+	seq_printf(p, "%*s: ", prec, "DFR");
+	for_each_online_cpu(j)
+		seq_printf(p, "%10u ", irq_stats(j)->irq_deferred_error_count);
+	seq_puts(p, "  Deferred Error APIC interrupts\n");
+#endif
 #ifdef CONFIG_X86_MCE
 	seq_printf(p, "%*s: ", prec, "MCE");
 	for_each_online_cpu(j)
* Unmerged path arch/x86/kernel/irqinit.c
diff --git a/arch/x86/kernel/traps.c b/arch/x86/kernel/traps.c
index 9823443df079..9c029c953047 100644
--- a/arch/x86/kernel/traps.c
+++ b/arch/x86/kernel/traps.c
@@ -590,6 +590,11 @@ asmlinkage void __attribute__((weak)) smp_threshold_interrupt(void)
 {
 }
 
+asmlinkage __visible void __attribute__((weak))
+smp_deferred_error_interrupt(void)
+{
+}
+
 /*
  * 'math_state_restore()' saves the current math information in the
  * old math state array, and gets the new ones from the current task
