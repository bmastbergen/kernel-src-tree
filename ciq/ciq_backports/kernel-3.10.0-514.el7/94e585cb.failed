RDMA/cxgb3: Remove old FRWR API

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Sagi Grimberg <sagig@mellanox.com>
commit 94e585cb7467a3e4cecb7267cd8303d2b693a8b9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/94e585cb.failed

No ULP uses it anymore, go ahead and remove it.

	Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
	Acked-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 94e585cb7467a3e4cecb7267cd8303d2b693a8b9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/cxgb3/iwch_provider.c
#	drivers/infiniband/hw/cxgb3/iwch_qp.c
diff --cc drivers/infiniband/hw/cxgb3/iwch_provider.c
index 93308c45f298,c34725ca0bb4..000000000000
--- a/drivers/infiniband/hw/cxgb3/iwch_provider.c
+++ b/drivers/infiniband/hw/cxgb3/iwch_provider.c
@@@ -852,26 -861,27 +852,50 @@@ err
  	return ERR_PTR(ret);
  }
  
++<<<<<<< HEAD
 +static struct ib_fast_reg_page_list *iwch_alloc_fastreg_pbl(
 +					struct ib_device *device,
 +					int page_list_len)
 +{
 +	struct ib_fast_reg_page_list *page_list;
 +
 +	page_list = kmalloc(sizeof *page_list + page_list_len * sizeof(u64),
 +			    GFP_KERNEL);
 +	if (!page_list)
 +		return ERR_PTR(-ENOMEM);
 +
 +	page_list->page_list = (u64 *)(page_list + 1);
 +	page_list->max_page_list_len = page_list_len;
 +
 +	return page_list;
 +}
 +
 +static void iwch_free_fastreg_pbl(struct ib_fast_reg_page_list *page_list)
 +{
 +	kfree(page_list);
++=======
+ static int iwch_set_page(struct ib_mr *ibmr, u64 addr)
+ {
+ 	struct iwch_mr *mhp = to_iwch_mr(ibmr);
+ 
+ 	if (unlikely(mhp->npages == mhp->attr.pbl_size))
+ 		return -ENOMEM;
+ 
+ 	mhp->pages[mhp->npages++] = addr;
+ 
+ 	return 0;
+ }
+ 
+ static int iwch_map_mr_sg(struct ib_mr *ibmr,
+ 			  struct scatterlist *sg,
+ 			  int sg_nents)
+ {
+ 	struct iwch_mr *mhp = to_iwch_mr(ibmr);
+ 
+ 	mhp->npages = 0;
+ 
+ 	return ib_sg_to_pages(ibmr, sg, sg_nents, iwch_set_page);
++>>>>>>> 94e585cb7467 (RDMA/cxgb3: Remove old FRWR API)
  }
  
  static int iwch_destroy_qp(struct ib_qp *ib_qp)
@@@ -1450,8 -1460,7 +1474,12 @@@ int iwch_register_device(struct iwch_de
  	dev->ibdev.bind_mw = iwch_bind_mw;
  	dev->ibdev.dealloc_mw = iwch_dealloc_mw;
  	dev->ibdev.alloc_mr = iwch_alloc_mr;
++<<<<<<< HEAD
 +	dev->ibdev.alloc_fast_reg_page_list = iwch_alloc_fastreg_pbl;
 +	dev->ibdev.free_fast_reg_page_list = iwch_free_fastreg_pbl;
++=======
+ 	dev->ibdev.map_mr_sg = iwch_map_mr_sg;
++>>>>>>> 94e585cb7467 (RDMA/cxgb3: Remove old FRWR API)
  	dev->ibdev.attach_mcast = iwch_multicast_attach;
  	dev->ibdev.detach_mcast = iwch_multicast_detach;
  	dev->ibdev.process_mad = iwch_process_mad;
diff --cc drivers/infiniband/hw/cxgb3/iwch_qp.c
index b57c0befd962,d0548fc6395e..000000000000
--- a/drivers/infiniband/hw/cxgb3/iwch_qp.c
+++ b/drivers/infiniband/hw/cxgb3/iwch_qp.c
@@@ -146,27 -146,28 +146,52 @@@ static int build_rdma_read(union t3_wr 
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int build_fastreg(union t3_wr *wqe, struct ib_send_wr *wr,
 +				u8 *flit_cnt, int *wr_cnt, struct t3_wq *wq)
 +{
 +	int i;
 +	__be64 *p;
 +
 +	if (wr->wr.fast_reg.page_list_len > T3_MAX_FASTREG_DEPTH)
 +		return -EINVAL;
 +	*wr_cnt = 1;
 +	wqe->fastreg.stag = cpu_to_be32(wr->wr.fast_reg.rkey);
 +	wqe->fastreg.len = cpu_to_be32(wr->wr.fast_reg.length);
 +	wqe->fastreg.va_base_hi = cpu_to_be32(wr->wr.fast_reg.iova_start >> 32);
 +	wqe->fastreg.va_base_lo_fbo =
 +				cpu_to_be32(wr->wr.fast_reg.iova_start & 0xffffffff);
 +	wqe->fastreg.page_type_perms = cpu_to_be32(
 +		V_FR_PAGE_COUNT(wr->wr.fast_reg.page_list_len) |
 +		V_FR_PAGE_SIZE(wr->wr.fast_reg.page_shift-12) |
 +		V_FR_TYPE(TPT_VATO) |
 +		V_FR_PERMS(iwch_ib_to_tpt_access(wr->wr.fast_reg.access_flags)));
 +	p = &wqe->fastreg.pbl_addrs[0];
 +	for (i = 0; i < wr->wr.fast_reg.page_list_len; i++, p++) {
++=======
+ static int build_memreg(union t3_wr *wqe, struct ib_reg_wr *wr,
+ 			  u8 *flit_cnt, int *wr_cnt, struct t3_wq *wq)
+ {
+ 	struct iwch_mr *mhp = to_iwch_mr(wr->mr);
+ 	int i;
+ 	__be64 *p;
+ 
+ 	if (mhp->npages > T3_MAX_FASTREG_DEPTH)
+ 		return -EINVAL;
+ 	*wr_cnt = 1;
+ 	wqe->fastreg.stag = cpu_to_be32(wr->key);
+ 	wqe->fastreg.len = cpu_to_be32(mhp->ibmr.length);
+ 	wqe->fastreg.va_base_hi = cpu_to_be32(mhp->ibmr.iova >> 32);
+ 	wqe->fastreg.va_base_lo_fbo =
+ 				cpu_to_be32(mhp->ibmr.iova & 0xffffffff);
+ 	wqe->fastreg.page_type_perms = cpu_to_be32(
+ 		V_FR_PAGE_COUNT(mhp->npages) |
+ 		V_FR_PAGE_SIZE(ilog2(wr->mr->page_size) - 12) |
+ 		V_FR_TYPE(TPT_VATO) |
+ 		V_FR_PERMS(iwch_ib_to_tpt_access(wr->access)));
+ 	p = &wqe->fastreg.pbl_addrs[0];
+ 	for (i = 0; i < mhp->npages; i++, p++) {
++>>>>>>> 94e585cb7467 (RDMA/cxgb3: Remove old FRWR API)
  
  		/* If we need a 2nd WR, then set it up */
  		if (i == T3_MAX_FASTREG_FRAG) {
@@@ -175,14 -176,14 +200,24 @@@
  				Q_PTR2IDX((wq->wptr+1), wq->size_log2));
  			build_fw_riwrh((void *)wqe, T3_WR_FASTREG, 0,
  			       Q_GENBIT(wq->wptr + 1, wq->size_log2),
++<<<<<<< HEAD
 +			       0, 1 + wr->wr.fast_reg.page_list_len - T3_MAX_FASTREG_FRAG,
++=======
+ 			       0, 1 + mhp->npages - T3_MAX_FASTREG_FRAG,
++>>>>>>> 94e585cb7467 (RDMA/cxgb3: Remove old FRWR API)
  			       T3_EOP);
  
  			p = &wqe->pbl_frag.pbl_addrs[0];
  		}
++<<<<<<< HEAD
 +		*p = cpu_to_be64((u64)wr->wr.fast_reg.page_list->page_list[i]);
 +	}
 +	*flit_cnt = 5 + wr->wr.fast_reg.page_list_len;
++=======
+ 		*p = cpu_to_be64((u64)mhp->pages[i]);
+ 	}
+ 	*flit_cnt = 5 + mhp->npages;
++>>>>>>> 94e585cb7467 (RDMA/cxgb3: Remove old FRWR API)
  	if (*flit_cnt > 15)
  		*flit_cnt = 15;
  	return 0;
@@@ -414,10 -415,10 +449,17 @@@ int iwch_post_send(struct ib_qp *ibqp, 
  			if (!qhp->wq.oldest_read)
  				qhp->wq.oldest_read = sqp;
  			break;
++<<<<<<< HEAD
 +		case IB_WR_FAST_REG_MR:
 +			t3_wr_opcode = T3_WR_FASTREG;
 +			err = build_fastreg(wqe, wr, &t3_wr_flit_cnt,
 +						 &wr_cnt, &qhp->wq);
++=======
+ 		case IB_WR_REG_MR:
+ 			t3_wr_opcode = T3_WR_FASTREG;
+ 			err = build_memreg(wqe, reg_wr(wr), &t3_wr_flit_cnt,
+ 					   &wr_cnt, &qhp->wq);
++>>>>>>> 94e585cb7467 (RDMA/cxgb3: Remove old FRWR API)
  			break;
  		case IB_WR_LOCAL_INV:
  			if (wr->send_flags & IB_SEND_FENCE)
diff --git a/drivers/infiniband/hw/cxgb3/iwch_cq.c b/drivers/infiniband/hw/cxgb3/iwch_cq.c
index cf5474ae68ff..cfe404925a39 100644
--- a/drivers/infiniband/hw/cxgb3/iwch_cq.c
+++ b/drivers/infiniband/hw/cxgb3/iwch_cq.c
@@ -123,7 +123,7 @@ static int iwch_poll_cq_one(struct iwch_dev *rhp, struct iwch_cq *chp,
 			wc->opcode = IB_WC_LOCAL_INV;
 			break;
 		case T3_FAST_REGISTER:
-			wc->opcode = IB_WC_FAST_REG_MR;
+			wc->opcode = IB_WC_REG_MR;
 			break;
 		default:
 			printk(KERN_ERR MOD "Unexpected opcode %d "
* Unmerged path drivers/infiniband/hw/cxgb3/iwch_provider.c
* Unmerged path drivers/infiniband/hw/cxgb3/iwch_qp.c
