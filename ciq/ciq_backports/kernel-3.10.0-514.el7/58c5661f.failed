panic, x86: Allow CPUs to save registers even if looping in NMI context

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
commit 58c5661f2144c089bbc2e5d87c9ec1dc1d2964fe
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/58c5661f.failed

Currently, kdump_nmi_shootdown_cpus(), a subroutine of crash_kexec(),
sends an NMI IPI to CPUs which haven't called panic() to stop them,
save their register information and do some cleanups for crash dumping.
However, if such a CPU is infinitely looping in NMI context, we fail to
save its register information into the crash dump.

For example, this can happen when unknown NMIs are broadcast to all
CPUs as follows:

  CPU 0                             CPU 1
  ===========================       ==========================
  receive an unknown NMI
  unknown_nmi_error()
    panic()                         receive an unknown NMI
      spin_trylock(&panic_lock)     unknown_nmi_error()
      crash_kexec()                   panic()
                                        spin_trylock(&panic_lock)
                                        panic_smp_self_stop()
                                          infinite loop
        kdump_nmi_shootdown_cpus()
          issue NMI IPI -----------> blocked until IRET
                                          infinite loop...

Here, since CPU 1 is in NMI context, the second NMI from CPU 0 is
blocked until CPU 1 executes IRET. However, CPU 1 never executes IRET,
so the NMI is not handled and the callback function to save registers is
never called.

In practice, this can happen on some servers which broadcast NMIs to all
CPUs when the NMI button is pushed.

To save registers in this case, we need to:

  a) Return from NMI handler instead of looping infinitely
  or
  b) Call the callback function directly from the infinite loop

Inherently, a) is risky because NMI is also used to prevent corrupted
data from being propagated to devices.  So, we chose b).

This patch does the following:

1. Move the infinite looping of CPUs which haven't called panic() in NMI
   context (actually done by panic_smp_self_stop()) outside of panic() to
   enable us to refer pt_regs. Please note that panic_smp_self_stop() is
   still used for normal context.

2. Call a callback of kdump_nmi_shootdown_cpus() directly to save
   registers and do some cleanups after setting waiting_for_crash_ipi which
   is used for counting down the number of CPUs which handled the callback

	Signed-off-by: Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
	Acked-by: Michal Hocko <mhocko@suse.com>
	Cc: Aaron Tomlin <atomlin@redhat.com>
	Cc: Andrew Morton <akpm@linux-foundation.org>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Baoquan He <bhe@redhat.com>
	Cc: Chris Metcalf <cmetcalf@ezchip.com>
	Cc: Dave Young <dyoung@redhat.com>
	Cc: David Hildenbrand <dahi@linux.vnet.ibm.com>
	Cc: Don Zickus <dzickus@redhat.com>
	Cc: Eric Biederman <ebiederm@xmission.com>
	Cc: Frederic Weisbecker <fweisbec@gmail.com>
	Cc: Gobinda Charan Maji <gobinda.cemk07@gmail.com>
	Cc: HATAYAMA Daisuke <d.hatayama@jp.fujitsu.com>
	Cc: Hidehiro Kawai <hidehiro.kawai.ez@hitachi.com>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Ingo Molnar <mingo@kernel.org>
	Cc: Javi Merino <javi.merino@arm.com>
	Cc: Jiang Liu <jiang.liu@linux.intel.com>
	Cc: Jonathan Corbet <corbet@lwn.net>
	Cc: kexec@lists.infradead.org
	Cc: linux-doc@vger.kernel.org
	Cc: lkml <linux-kernel@vger.kernel.org>
	Cc: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
	Cc: Michal Nazarewicz <mina86@mina86.com>
	Cc: Nicolas Iooss <nicolas.iooss_linux@m4x.org>
	Cc: Oleg Nesterov <oleg@redhat.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Prarit Bhargava <prarit@redhat.com>
	Cc: Rasmus Villemoes <linux@rasmusvillemoes.dk>
	Cc: Seth Jennings <sjenning@redhat.com>
	Cc: Stefan Lippers-Hollmann <s.l-h@gmx.de>
	Cc: Steven Rostedt <rostedt@goodmis.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Ulrich Obergfell <uobergfe@redhat.com>
	Cc: Vitaly Kuznetsov <vkuznets@redhat.com>
	Cc: Vivek Goyal <vgoyal@redhat.com>
	Cc: Yasuaki Ishimatsu <isimatu.yasuaki@jp.fujitsu.com>
Link: http://lkml.kernel.org/r/20151210014628.25437.75256.stgit@softrs
[ Cleanup comments, fixup formatting. ]
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
(cherry picked from commit 58c5661f2144c089bbc2e5d87c9ec1dc1d2964fe)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/nmi.c
#	include/linux/kernel.h
#	kernel/panic.c
#	kernel/watchdog.c
diff --cc arch/x86/kernel/nmi.c
index 60308053fdb2,424aec4a4c71..000000000000
--- a/arch/x86/kernel/nmi.c
+++ b/arch/x86/kernel/nmi.c
@@@ -186,7 -231,7 +186,11 @@@ pci_serr_error(unsigned char reason, st
  #endif
  
  	if (panic_on_unrecovered_nmi)
++<<<<<<< HEAD
 +		panic("NMI: Not continuing");
++=======
+ 		nmi_panic(regs, "NMI: Not continuing");
++>>>>>>> 58c5661f2144 (panic, x86: Allow CPUs to save registers even if looping in NMI context)
  
  	pr_emerg("Dazed and confused, but trying to continue\n");
  
@@@ -209,8 -255,16 +213,21 @@@ io_check_error(unsigned char reason, st
  		 reason, smp_processor_id());
  	show_regs(regs);
  
++<<<<<<< HEAD
 +	if (panic_on_io_nmi)
 +		panic("NMI IOCK error: Not continuing");
++=======
+ 	if (panic_on_io_nmi) {
+ 		nmi_panic(regs, "NMI IOCK error: Not continuing");
+ 
+ 		/*
+ 		 * If we end up here, it means we have received an NMI while
+ 		 * processing panic(). Simply return without delaying and
+ 		 * re-enabling NMIs.
+ 		 */
+ 		return;
+ 	}
++>>>>>>> 58c5661f2144 (panic, x86: Allow CPUs to save registers even if looping in NMI context)
  
  	/* Re-enable the IOCK line, wait for a few seconds */
  	reason = (reason & NMI_REASON_CLEAR_MASK) | NMI_REASON_CLEAR_IOCHK;
@@@ -250,7 -305,7 +267,11 @@@ unknown_nmi_error(unsigned char reason
  
  	pr_emerg("Do you have a strange power saving mode enabled?\n");
  	if (unknown_nmi_panic || panic_on_unrecovered_nmi)
++<<<<<<< HEAD
 +		panic("NMI: Not continuing");
++=======
+ 		nmi_panic(regs, "NMI: Not continuing");
++>>>>>>> 58c5661f2144 (panic, x86: Allow CPUs to save registers even if looping in NMI context)
  
  	pr_emerg("Dazed and confused, but trying to continue\n");
  }
diff --cc include/linux/kernel.h
index 27e50d389c3f,7311c3294e25..000000000000
--- a/include/linux/kernel.h
+++ b/include/linux/kernel.h
@@@ -441,6 -443,36 +442,39 @@@ extern int panic_on_unrecovered_nmi
  extern int panic_on_io_nmi;
  extern int panic_on_warn;
  extern int sysctl_panic_on_stackoverflow;
++<<<<<<< HEAD
++=======
+ 
+ extern bool crash_kexec_post_notifiers;
+ 
+ /*
+  * panic_cpu is used for synchronizing panic() and crash_kexec() execution. It
+  * holds a CPU number which is executing panic() currently. A value of
+  * PANIC_CPU_INVALID means no CPU has entered panic() or crash_kexec().
+  */
+ extern atomic_t panic_cpu;
+ #define PANIC_CPU_INVALID	-1
+ 
+ /*
+  * A variant of panic() called from NMI context. We return if we've already
+  * panicked on this CPU. If another CPU already panicked, loop in
+  * nmi_panic_self_stop() which can provide architecture dependent code such
+  * as saving register state for crash dump.
+  */
+ #define nmi_panic(regs, fmt, ...)					\
+ do {									\
+ 	int old_cpu, cpu;						\
+ 									\
+ 	cpu = raw_smp_processor_id();					\
+ 	old_cpu = atomic_cmpxchg(&panic_cpu, PANIC_CPU_INVALID, cpu);	\
+ 									\
+ 	if (old_cpu == PANIC_CPU_INVALID)				\
+ 		panic(fmt, ##__VA_ARGS__);				\
+ 	else if (old_cpu != cpu)					\
+ 		nmi_panic_self_stop(regs);				\
+ } while (0)
+ 
++>>>>>>> 58c5661f2144 (panic, x86: Allow CPUs to save registers even if looping in NMI context)
  /*
   * Only to be used by arch init code. If the user over-wrote the default
   * CONFIG_PANIC_TIMEOUT, honor it.
diff --cc kernel/panic.c
index 77e119fb43e1,06f31b49b3b4..000000000000
--- a/kernel/panic.c
+++ b/kernel/panic.c
@@@ -59,6 -61,17 +59,20 @@@ void __weak panic_smp_self_stop(void
  		cpu_relax();
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * Stop ourselves in NMI context if another CPU has already panicked. Arch code
+  * may override this to prepare for crash dumping, e.g. save regs info.
+  */
+ void __weak nmi_panic_self_stop(struct pt_regs *regs)
+ {
+ 	panic_smp_self_stop();
+ }
+ 
+ atomic_t panic_cpu = ATOMIC_INIT(PANIC_CPU_INVALID);
+ 
++>>>>>>> 58c5661f2144 (panic, x86: Allow CPUs to save registers even if looping in NMI context)
  /**
   *	panic - halt the system
   *	@fmt: The text string to print
diff --cc kernel/watchdog.c
index edde5b1f4a45,84b5035cb6a5..000000000000
--- a/kernel/watchdog.c
+++ b/kernel/watchdog.c
@@@ -306,12 -334,24 +306,16 @@@ static void watchdog_overflow_callback(
  		if (__this_cpu_read(hard_watchdog_warn) == true)
  			return;
  
 -		pr_emerg("Watchdog detected hard LOCKUP on cpu %d", this_cpu);
 -		print_modules();
 -		print_irqtrace_events(current);
 -		if (regs)
 -			show_regs(regs);
 -		else
 -			dump_stack();
 -
 -		/*
 -		 * Perform all-CPU dump only once to avoid multiple hardlockups
 -		 * generating interleaving traces
 -		 */
 -		if (sysctl_hardlockup_all_cpu_backtrace &&
 -				!test_and_set_bit(0, &hardlockup_allcpu_dumped))
 -			trigger_allbutself_cpu_backtrace();
 -
  		if (hardlockup_panic)
++<<<<<<< HEAD
 +			panic("Watchdog detected hard LOCKUP on cpu %d",
 +			      this_cpu);
 +		else
 +			WARN(1, "Watchdog detected hard LOCKUP on cpu %d",
 +			     this_cpu);
++=======
+ 			nmi_panic(regs, "Hard LOCKUP");
++>>>>>>> 58c5661f2144 (panic, x86: Allow CPUs to save registers even if looping in NMI context)
  
  		__this_cpu_write(hard_watchdog_warn, true);
  		return;
* Unmerged path arch/x86/kernel/nmi.c
diff --git a/arch/x86/kernel/reboot.c b/arch/x86/kernel/reboot.c
index 90fd1195f276..e3c7db902e7b 100644
--- a/arch/x86/kernel/reboot.c
+++ b/arch/x86/kernel/reboot.c
@@ -757,6 +757,7 @@ static int crashing_cpu;
 static nmi_shootdown_cb shootdown_callback;
 
 static atomic_t waiting_for_crash_ipi;
+static int crash_ipi_issued;
 
 static int crash_nmi_callback(unsigned int val, struct pt_regs *regs)
 {
@@ -819,6 +820,9 @@ void nmi_shootdown_cpus(nmi_shootdown_cb callback)
 
 	smp_send_nmi_allbutself();
 
+	/* Kick CPUs looping in NMI context. */
+	WRITE_ONCE(crash_ipi_issued, 1);
+
 	msecs = 1000; /* Wait at most a second for the other cpus to stop */
 	while ((atomic_read(&waiting_for_crash_ipi) > 0) && msecs) {
 		mdelay(1);
@@ -827,6 +831,22 @@ void nmi_shootdown_cpus(nmi_shootdown_cb callback)
 
 	/* Leave the nmi callback set */
 }
+
+/* Override the weak function in kernel/panic.c */
+void nmi_panic_self_stop(struct pt_regs *regs)
+{
+	while (1) {
+		/*
+		 * Wait for the crash dumping IPI to be issued, and then
+		 * call its callback directly.
+		 */
+		if (READ_ONCE(crash_ipi_issued))
+			crash_nmi_callback(0, regs); /* Don't return */
+
+		cpu_relax();
+	}
+}
+
 #else /* !CONFIG_SMP */
 void nmi_shootdown_cpus(nmi_shootdown_cb callback)
 {
* Unmerged path include/linux/kernel.h
* Unmerged path kernel/panic.c
* Unmerged path kernel/watchdog.c
