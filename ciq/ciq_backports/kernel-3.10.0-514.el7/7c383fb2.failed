ip_tunnels: use tos and ttl fields also for IPv6

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Jiri Benc <jbenc@redhat.com>
commit 7c383fb2254c44e096427470da6a36380169b548
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/7c383fb2.failed

Rename the ipv4_tos and ipv4_ttl fields to just 'tos' and 'ttl', as they'll
be used with IPv6 tunnels, too.

	Signed-off-by: Jiri Benc <jbenc@redhat.com>
	Acked-by: Thomas Graf <tgraf@suug.ch>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 7c383fb2254c44e096427470da6a36380169b548)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/vxlan.c
#	include/net/ip_tunnels.h
#	net/ipv4/ip_gre.c
#	net/ipv4/ip_tunnel_core.c
#	net/openvswitch/vport-geneve.c
#	net/openvswitch/vport.c
#	net/openvswitch/vport.h
diff --cc drivers/net/vxlan.c
index 37149323723f,ebeb3def06c5..000000000000
--- a/drivers/net/vxlan.c
+++ b/drivers/net/vxlan.c
@@@ -1200,6 -1268,32 +1200,35 @@@ static int vxlan_udp_encap_recv(struct 
  		vni &= VXLAN_VNI_MASK;
  	}
  
++<<<<<<< HEAD
++=======
+ 	if (vxlan_collect_metadata(vs)) {
+ 		const struct iphdr *iph = ip_hdr(skb);
+ 
+ 		tun_dst = metadata_dst_alloc(sizeof(*md), GFP_ATOMIC);
+ 		if (!tun_dst)
+ 			goto drop;
+ 
+ 		info = &tun_dst->u.tun_info;
+ 		info->key.u.ipv4.src = iph->saddr;
+ 		info->key.u.ipv4.dst = iph->daddr;
+ 		info->key.tos = iph->tos;
+ 		info->key.ttl = iph->ttl;
+ 		info->key.tp_src = udp_hdr(skb)->source;
+ 		info->key.tp_dst = udp_hdr(skb)->dest;
+ 
+ 		info->mode = IP_TUNNEL_INFO_RX;
+ 		info->key.tun_flags = TUNNEL_KEY;
+ 		info->key.tun_id = cpu_to_be64(vni >> 8);
+ 		if (udp_hdr(skb)->check != 0)
+ 			info->key.tun_flags |= TUNNEL_CSUM;
+ 
+ 		md = ip_tunnel_info_opts(info, sizeof(*md));
+ 	} else {
+ 		memset(md, 0, sizeof(*md));
+ 	}
+ 
++>>>>>>> 7c383fb2254c (ip_tunnels: use tos and ttl fields also for IPv6)
  	/* For backwards compatibility, only allow reserved fields to be
  	 * used by VXLAN extensions if explicitly requested.
  	 */
@@@ -1912,12 -1948,29 +1941,32 @@@ static void vxlan_xmit_one(struct sk_bu
  	if (tos == 1)
  		tos = ip_tunnel_get_dsfield(old_iph, skb);
  
 -	src_port = udp_flow_src_port(dev_net(dev), skb, vxlan->cfg.port_min,
 -				     vxlan->cfg.port_max, true);
 +	src_port = udp_flow_src_port(dev_net(dev), skb, vxlan->port_min,
 +				     vxlan->port_max, true);
  
  	if (dst->sa.sa_family == AF_INET) {
++<<<<<<< HEAD
++=======
+ 		if (info) {
+ 			if (info->key.tun_flags & TUNNEL_DONT_FRAGMENT)
+ 				df = htons(IP_DF);
+ 			if (info->key.tun_flags & TUNNEL_CSUM)
+ 				flags |= VXLAN_F_UDP_CSUM;
+ 			else
+ 				flags &= ~VXLAN_F_UDP_CSUM;
+ 
+ 			ttl = info->key.ttl;
+ 			tos = info->key.tos;
+ 
+ 			if (info->options_len)
+ 				md = ip_tunnel_info_opts(info, sizeof(*md));
+ 		} else {
+ 			md->gbp = skb->mark;
+ 		}
+ 
++>>>>>>> 7c383fb2254c (ip_tunnels: use tos and ttl fields also for IPv6)
  		memset(&fl4, 0, sizeof(fl4));
 -		fl4.flowi4_oif = rdst ? rdst->remote_ifindex : 0;
 +		fl4.flowi4_oif = rdst->remote_ifindex;
  		fl4.flowi4_tos = RT_TOS(tos);
  		fl4.flowi4_mark = skb->mark;
  		fl4.flowi4_proto = IPPROTO_UDP;
diff --cc include/net/ip_tunnels.h
index 8a38d811a07c,224e4ecec91b..000000000000
--- a/include/net/ip_tunnels.h
+++ b/include/net/ip_tunnels.h
@@@ -27,13 -25,27 +27,13 @@@
  /* Used to memset ip_tunnel padding. */
  #define IP_TUNNEL_KEY_SIZE	offsetofend(struct ip_tunnel_key, tp_dst)
  
 -/* Used to memset ipv4 address padding. */
 -#define IP_TUNNEL_KEY_IPV4_PAD	offsetofend(struct ip_tunnel_key, u.ipv4.dst)
 -#define IP_TUNNEL_KEY_IPV4_PAD_LEN				\
 -	(FIELD_SIZEOF(struct ip_tunnel_key, u) -		\
 -	 FIELD_SIZEOF(struct ip_tunnel_key, u.ipv4))
 -
  struct ip_tunnel_key {
  	__be64			tun_id;
 -	union {
 -		struct {
 -			__be32	src;
 -			__be32	dst;
 -		} ipv4;
 -		struct {
 -			struct in6_addr src;
 -			struct in6_addr dst;
 -		} ipv6;
 -	} u;
 +	__be32			ipv4_src;
 +	__be32			ipv4_dst;
  	__be16			tun_flags;
- 	u8			ipv4_tos;
- 	u8			ipv4_ttl;
+ 	u8			tos;		/* TOS for IPv4, TC for IPv6 */
+ 	u8			ttl;		/* TTL for IPv4, HL for IPv6 */
  	__be16			tp_src;
  	__be16			tp_dst;
  };
@@@ -176,10 -191,12 +176,19 @@@ static inline void __ip_tunnel_info_ini
  					 const void *opts, u8 opts_len)
  {
  	tun_info->key.tun_id = tun_id;
++<<<<<<< HEAD
 +	tun_info->key.ipv4_src = saddr;
 +	tun_info->key.ipv4_dst = daddr;
 +	tun_info->key.ipv4_tos = tos;
 +	tun_info->key.ipv4_ttl = ttl;
++=======
+ 	tun_info->key.u.ipv4.src = saddr;
+ 	tun_info->key.u.ipv4.dst = daddr;
+ 	memset((unsigned char *)&tun_info->key + IP_TUNNEL_KEY_IPV4_PAD,
+ 	       0, IP_TUNNEL_KEY_IPV4_PAD_LEN);
+ 	tun_info->key.tos = tos;
+ 	tun_info->key.ttl = ttl;
++>>>>>>> 7c383fb2254c (ip_tunnels: use tos and ttl fields also for IPv6)
  	tun_info->key.tun_flags = tun_flags;
  
  	/* For the tunnel types on the top of IPsec, the tp_src and tp_dst of
diff --cc net/ipv4/ip_gre.c
index afc4a83f7ee7,5193618b2600..000000000000
--- a/net/ipv4/ip_gre.c
+++ b/net/ipv4/ip_gre.c
@@@ -218,7 -399,29 +218,33 @@@ static int ipgre_rcv(struct sk_buff *sk
  
  	if (tunnel) {
  		skb_pop_mac_header(skb);
++<<<<<<< HEAD
 +		ip_tunnel_rcv(tunnel, skb, tpi, log_ecn_error);
++=======
+ 		if (tunnel->collect_md) {
+ 			struct ip_tunnel_info *info;
+ 
+ 			tun_dst = metadata_dst_alloc(0, GFP_ATOMIC);
+ 			if (!tun_dst)
+ 				return PACKET_REJECT;
+ 
+ 			info = &tun_dst->u.tun_info;
+ 			info->key.u.ipv4.src = iph->saddr;
+ 			info->key.u.ipv4.dst = iph->daddr;
+ 			info->key.tos = iph->tos;
+ 			info->key.ttl = iph->ttl;
+ 
+ 			info->mode = IP_TUNNEL_INFO_RX;
+ 			info->key.tun_flags = tpi->flags &
+ 					      (TUNNEL_CSUM | TUNNEL_KEY);
+ 			info->key.tun_id = key_to_tunnel_id(tpi->key);
+ 
+ 			info->key.tp_src = 0;
+ 			info->key.tp_dst = 0;
+ 		}
+ 
+ 		ip_tunnel_rcv(tunnel, skb, tpi, tun_dst, log_ecn_error);
++>>>>>>> 7c383fb2254c (ip_tunnels: use tos and ttl fields also for IPv6)
  		return PACKET_RCVD;
  	}
  	return PACKET_REJECT;
@@@ -246,6 -501,81 +272,83 @@@ static void __gre_xmit(struct sk_buff *
  	ip_tunnel_xmit(skb, dev, tnl_params, tnl_params->protocol);
  }
  
++<<<<<<< HEAD
++=======
+ static struct sk_buff *gre_handle_offloads(struct sk_buff *skb,
+ 					   bool csum)
+ {
+ 	return iptunnel_handle_offloads(skb, csum,
+ 					csum ? SKB_GSO_GRE_CSUM : SKB_GSO_GRE);
+ }
+ 
+ static void gre_fb_xmit(struct sk_buff *skb, struct net_device *dev)
+ {
+ 	struct ip_tunnel_info *tun_info;
+ 	struct net *net = dev_net(dev);
+ 	const struct ip_tunnel_key *key;
+ 	struct flowi4 fl;
+ 	struct rtable *rt;
+ 	int min_headroom;
+ 	int tunnel_hlen;
+ 	__be16 df, flags;
+ 	int err;
+ 
+ 	tun_info = skb_tunnel_info(skb, AF_INET);
+ 	if (unlikely(!tun_info || tun_info->mode != IP_TUNNEL_INFO_TX))
+ 		goto err_free_skb;
+ 
+ 	key = &tun_info->key;
+ 	memset(&fl, 0, sizeof(fl));
+ 	fl.daddr = key->u.ipv4.dst;
+ 	fl.saddr = key->u.ipv4.src;
+ 	fl.flowi4_tos = RT_TOS(key->tos);
+ 	fl.flowi4_mark = skb->mark;
+ 	fl.flowi4_proto = IPPROTO_GRE;
+ 
+ 	rt = ip_route_output_key(net, &fl);
+ 	if (IS_ERR(rt))
+ 		goto err_free_skb;
+ 
+ 	tunnel_hlen = ip_gre_calc_hlen(key->tun_flags);
+ 
+ 	min_headroom = LL_RESERVED_SPACE(rt->dst.dev) + rt->dst.header_len
+ 			+ tunnel_hlen + sizeof(struct iphdr);
+ 	if (skb_headroom(skb) < min_headroom || skb_header_cloned(skb)) {
+ 		int head_delta = SKB_DATA_ALIGN(min_headroom -
+ 						skb_headroom(skb) +
+ 						16);
+ 		err = pskb_expand_head(skb, max_t(int, head_delta, 0),
+ 				       0, GFP_ATOMIC);
+ 		if (unlikely(err))
+ 			goto err_free_rt;
+ 	}
+ 
+ 	/* Push Tunnel header. */
+ 	skb = gre_handle_offloads(skb, !!(tun_info->key.tun_flags & TUNNEL_CSUM));
+ 	if (IS_ERR(skb)) {
+ 		skb = NULL;
+ 		goto err_free_rt;
+ 	}
+ 
+ 	flags = tun_info->key.tun_flags & (TUNNEL_CSUM | TUNNEL_KEY);
+ 	build_header(skb, tunnel_hlen, flags, htons(ETH_P_TEB),
+ 		     tunnel_id_to_key(tun_info->key.tun_id), 0);
+ 
+ 	df = key->tun_flags & TUNNEL_DONT_FRAGMENT ?  htons(IP_DF) : 0;
+ 	err = iptunnel_xmit(skb->sk, rt, skb, fl.saddr,
+ 			    key->u.ipv4.dst, IPPROTO_GRE,
+ 			    key->tos, key->ttl, df, false);
+ 	iptunnel_xmit_stats(err, &dev->stats, dev->tstats);
+ 	return;
+ 
+ err_free_rt:
+ 	ip_rt_put(rt);
+ err_free_skb:
+ 	kfree_skb(skb);
+ 	dev->stats.tx_dropped++;
+ }
+ 
++>>>>>>> 7c383fb2254c (ip_tunnels: use tos and ttl fields also for IPv6)
  static netdev_tx_t ipgre_xmit(struct sk_buff *skb,
  			      struct net_device *dev)
  {
diff --cc net/ipv4/ip_tunnel_core.c
index 010b54caceed,f0514e39e57c..000000000000
--- a/net/ipv4/ip_tunnel_core.c
+++ b/net/ipv4/ip_tunnel_core.c
@@@ -188,3 -191,130 +188,133 @@@ struct rtnl_link_stats64 *ip_tunnel_get
  	return tot;
  }
  EXPORT_SYMBOL_GPL(ip_tunnel_get_stats64);
++<<<<<<< HEAD
++=======
+ 
+ static const struct nla_policy ip_tun_policy[LWTUNNEL_IP_MAX + 1] = {
+ 	[LWTUNNEL_IP_ID]	= { .type = NLA_U64 },
+ 	[LWTUNNEL_IP_DST]	= { .type = NLA_U32 },
+ 	[LWTUNNEL_IP_SRC]	= { .type = NLA_U32 },
+ 	[LWTUNNEL_IP_TTL]	= { .type = NLA_U8 },
+ 	[LWTUNNEL_IP_TOS]	= { .type = NLA_U8 },
+ 	[LWTUNNEL_IP_SPORT]	= { .type = NLA_U16 },
+ 	[LWTUNNEL_IP_DPORT]	= { .type = NLA_U16 },
+ 	[LWTUNNEL_IP_FLAGS]	= { .type = NLA_U16 },
+ };
+ 
+ static int ip_tun_build_state(struct net_device *dev, struct nlattr *attr,
+ 			      struct lwtunnel_state **ts)
+ {
+ 	struct ip_tunnel_info *tun_info;
+ 	struct lwtunnel_state *new_state;
+ 	struct nlattr *tb[LWTUNNEL_IP_MAX + 1];
+ 	int err;
+ 
+ 	err = nla_parse_nested(tb, LWTUNNEL_IP_MAX, attr, ip_tun_policy);
+ 	if (err < 0)
+ 		return err;
+ 
+ 	new_state = lwtunnel_state_alloc(sizeof(*tun_info));
+ 	if (!new_state)
+ 		return -ENOMEM;
+ 
+ 	new_state->type = LWTUNNEL_ENCAP_IP;
+ 
+ 	tun_info = lwt_tun_info(new_state);
+ 
+ 	if (tb[LWTUNNEL_IP_ID])
+ 		tun_info->key.tun_id = nla_get_u64(tb[LWTUNNEL_IP_ID]);
+ 
+ 	if (tb[LWTUNNEL_IP_DST])
+ 		tun_info->key.u.ipv4.dst = nla_get_be32(tb[LWTUNNEL_IP_DST]);
+ 
+ 	if (tb[LWTUNNEL_IP_SRC])
+ 		tun_info->key.u.ipv4.src = nla_get_be32(tb[LWTUNNEL_IP_SRC]);
+ 
+ 	if (tb[LWTUNNEL_IP_TTL])
+ 		tun_info->key.ttl = nla_get_u8(tb[LWTUNNEL_IP_TTL]);
+ 
+ 	if (tb[LWTUNNEL_IP_TOS])
+ 		tun_info->key.tos = nla_get_u8(tb[LWTUNNEL_IP_TOS]);
+ 
+ 	if (tb[LWTUNNEL_IP_SPORT])
+ 		tun_info->key.tp_src = nla_get_be16(tb[LWTUNNEL_IP_SPORT]);
+ 
+ 	if (tb[LWTUNNEL_IP_DPORT])
+ 		tun_info->key.tp_dst = nla_get_be16(tb[LWTUNNEL_IP_DPORT]);
+ 
+ 	if (tb[LWTUNNEL_IP_FLAGS])
+ 		tun_info->key.tun_flags = nla_get_u16(tb[LWTUNNEL_IP_FLAGS]);
+ 
+ 	tun_info->mode = IP_TUNNEL_INFO_TX;
+ 	tun_info->options = NULL;
+ 	tun_info->options_len = 0;
+ 
+ 	*ts = new_state;
+ 
+ 	return 0;
+ }
+ 
+ static int ip_tun_fill_encap_info(struct sk_buff *skb,
+ 				  struct lwtunnel_state *lwtstate)
+ {
+ 	struct ip_tunnel_info *tun_info = lwt_tun_info(lwtstate);
+ 
+ 	if (nla_put_u64(skb, LWTUNNEL_IP_ID, tun_info->key.tun_id) ||
+ 	    nla_put_be32(skb, LWTUNNEL_IP_DST, tun_info->key.u.ipv4.dst) ||
+ 	    nla_put_be32(skb, LWTUNNEL_IP_SRC, tun_info->key.u.ipv4.src) ||
+ 	    nla_put_u8(skb, LWTUNNEL_IP_TOS, tun_info->key.tos) ||
+ 	    nla_put_u8(skb, LWTUNNEL_IP_TTL, tun_info->key.ttl) ||
+ 	    nla_put_u16(skb, LWTUNNEL_IP_SPORT, tun_info->key.tp_src) ||
+ 	    nla_put_u16(skb, LWTUNNEL_IP_DPORT, tun_info->key.tp_dst) ||
+ 	    nla_put_u16(skb, LWTUNNEL_IP_FLAGS, tun_info->key.tun_flags))
+ 		return -ENOMEM;
+ 
+ 	return 0;
+ }
+ 
+ static int ip_tun_encap_nlsize(struct lwtunnel_state *lwtstate)
+ {
+ 	return nla_total_size(8)	/* LWTUNNEL_IP_ID */
+ 		+ nla_total_size(4)	/* LWTUNNEL_IP_DST */
+ 		+ nla_total_size(4)	/* LWTUNNEL_IP_SRC */
+ 		+ nla_total_size(1)	/* LWTUNNEL_IP_TOS */
+ 		+ nla_total_size(1)	/* LWTUNNEL_IP_TTL */
+ 		+ nla_total_size(2)	/* LWTUNNEL_IP_SPORT */
+ 		+ nla_total_size(2)	/* LWTUNNEL_IP_DPORT */
+ 		+ nla_total_size(2);	/* LWTUNNEL_IP_FLAGS */
+ }
+ 
+ static int ip_tun_cmp_encap(struct lwtunnel_state *a, struct lwtunnel_state *b)
+ {
+ 	return memcmp(lwt_tun_info(a), lwt_tun_info(b),
+ 		      sizeof(struct ip_tunnel_info));
+ }
+ 
+ static const struct lwtunnel_encap_ops ip_tun_lwt_ops = {
+ 	.build_state = ip_tun_build_state,
+ 	.fill_encap = ip_tun_fill_encap_info,
+ 	.get_encap_size = ip_tun_encap_nlsize,
+ 	.cmp_encap = ip_tun_cmp_encap,
+ };
+ 
+ void __init ip_tunnel_core_init(void)
+ {
+ 	lwtunnel_encap_add_ops(&ip_tun_lwt_ops, LWTUNNEL_ENCAP_IP);
+ }
+ 
+ struct static_key ip_tunnel_metadata_cnt = STATIC_KEY_INIT_FALSE;
+ EXPORT_SYMBOL(ip_tunnel_metadata_cnt);
+ 
+ void ip_tunnel_need_metadata(void)
+ {
+ 	static_key_slow_inc(&ip_tunnel_metadata_cnt);
+ }
+ EXPORT_SYMBOL_GPL(ip_tunnel_need_metadata);
+ 
+ void ip_tunnel_unneed_metadata(void)
+ {
+ 	static_key_slow_dec(&ip_tunnel_metadata_cnt);
+ }
+ EXPORT_SYMBOL_GPL(ip_tunnel_unneed_metadata);
++>>>>>>> 7c383fb2254c (ip_tunnels: use tos and ttl fields also for IPv6)
diff --cc net/openvswitch/vport-geneve.c
index 1da3a14d1010,d01bd6360970..000000000000
--- a/net/openvswitch/vport-geneve.c
+++ b/net/openvswitch/vport-geneve.c
@@@ -203,8 -203,8 +203,13 @@@ static int geneve_tnl_send(struct vpor
  	}
  
  	err = geneve_xmit_skb(geneve_port->gs, rt, skb, fl.saddr,
++<<<<<<< HEAD
 +			      tun_key->ipv4_dst, tun_key->ipv4_tos,
 +			      tun_key->ipv4_ttl, df, sport, dport,
++=======
+ 			      tun_key->u.ipv4.dst, tun_key->tos,
+ 			      tun_key->ttl, df, sport, dport,
++>>>>>>> 7c383fb2254c (ip_tunnels: use tos and ttl fields also for IPv6)
  			      tun_key->tun_flags, vni, opts_len, opts,
  			      !!(tun_key->tun_flags & TUNNEL_CSUM), false);
  	if (err < 0)
diff --cc net/openvswitch/vport.c
index af23ba077836,d73e5a16e7ca..000000000000
--- a/net/openvswitch/vport.c
+++ b/net/openvswitch/vport.c
@@@ -603,9 -603,9 +603,15 @@@ int ovs_tunnel_get_egress_info(struct i
  	 * saddr, tp_src and tp_dst
  	 */
  	__ip_tunnel_info_init(egress_tun_info,
++<<<<<<< HEAD
 +			      fl.saddr, tun_key->ipv4_dst,
 +			      tun_key->ipv4_tos,
 +			      tun_key->ipv4_ttl,
++=======
+ 			      fl.saddr, tun_key->u.ipv4.dst,
+ 			      tun_key->tos,
+ 			      tun_key->ttl,
++>>>>>>> 7c383fb2254c (ip_tunnels: use tos and ttl fields also for IPv6)
  			      tp_src, tp_dst,
  			      tun_key->tun_id,
  			      tun_key->tun_flags,
diff --cc net/openvswitch/vport.h
index 4750fb673a9f,b88b3ee86f07..000000000000
--- a/net/openvswitch/vport.h
+++ b/net/openvswitch/vport.h
@@@ -247,9 -254,9 +247,15 @@@ static inline struct rtable *ovs_tunnel
  	struct rtable *rt;
  
  	memset(fl, 0, sizeof(*fl));
++<<<<<<< HEAD
 +	fl->daddr = key->ipv4_dst;
 +	fl->saddr = key->ipv4_src;
 +	fl->flowi4_tos = RT_TOS(key->ipv4_tos);
++=======
+ 	fl->daddr = key->u.ipv4.dst;
+ 	fl->saddr = key->u.ipv4.src;
+ 	fl->flowi4_tos = RT_TOS(key->tos);
++>>>>>>> 7c383fb2254c (ip_tunnels: use tos and ttl fields also for IPv6)
  	fl->flowi4_mark = mark;
  	fl->flowi4_proto = protocol;
  
* Unmerged path drivers/net/vxlan.c
* Unmerged path include/net/ip_tunnels.h
* Unmerged path net/ipv4/ip_gre.c
* Unmerged path net/ipv4/ip_tunnel_core.c
diff --git a/net/openvswitch/flow_netlink.c b/net/openvswitch/flow_netlink.c
index 7f4707e70b38..85c445c95127 100644
--- a/net/openvswitch/flow_netlink.c
+++ b/net/openvswitch/flow_netlink.c
@@ -542,11 +542,11 @@ static int ipv4_tun_from_nlattr(const struct nlattr *attr,
 					nla_get_in_addr(a), is_mask);
 			break;
 		case OVS_TUNNEL_KEY_ATTR_TOS:
-			SW_FLOW_KEY_PUT(match, tun_key.ipv4_tos,
+			SW_FLOW_KEY_PUT(match, tun_key.tos,
 					nla_get_u8(a), is_mask);
 			break;
 		case OVS_TUNNEL_KEY_ATTR_TTL:
-			SW_FLOW_KEY_PUT(match, tun_key.ipv4_ttl,
+			SW_FLOW_KEY_PUT(match, tun_key.ttl,
 					nla_get_u8(a), is_mask);
 			ttl = true;
 			break;
@@ -655,10 +655,10 @@ static int __ipv4_tun_to_nlattr(struct sk_buff *skb,
 	    nla_put_in_addr(skb, OVS_TUNNEL_KEY_ATTR_IPV4_DST,
 			    output->ipv4_dst))
 		return -EMSGSIZE;
-	if (output->ipv4_tos &&
-	    nla_put_u8(skb, OVS_TUNNEL_KEY_ATTR_TOS, output->ipv4_tos))
+	if (output->tos &&
+	    nla_put_u8(skb, OVS_TUNNEL_KEY_ATTR_TOS, output->tos))
 		return -EMSGSIZE;
-	if (nla_put_u8(skb, OVS_TUNNEL_KEY_ATTR_TTL, output->ipv4_ttl))
+	if (nla_put_u8(skb, OVS_TUNNEL_KEY_ATTR_TTL, output->ttl))
 		return -EMSGSIZE;
 	if ((output->tun_flags & TUNNEL_DONT_FRAGMENT) &&
 	    nla_put_flag(skb, OVS_TUNNEL_KEY_ATTR_DONT_FRAGMENT))
* Unmerged path net/openvswitch/vport-geneve.c
* Unmerged path net/openvswitch/vport.c
* Unmerged path net/openvswitch/vport.h
