hv_netvsc: Fix a bug in netvsc_start_xmit()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author KY Srinivasan <kys@microsoft.com>
commit b56fc3c536541c8081cd5f1f1d101a16c002a365
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/b56fc3c5.failed

Commit b08cc79155fc26d0d112b1470d1ece5034651a4b eliminated memory
allocation in the packet send path:

    "hv_netvsc: Eliminate memory allocation in the packet send path

    The network protocol used to communicate with the host is the remote ndis (rndis)
    protocol. We need to decorate each outgoing packet with a rndis header and
    additional rndis state (rndis per-packet state). To manage this state, we
    currently allocate memory in the transmit path. Eliminate this allocation by
    requesting additional head room in the skb."

This commit introduced a bug since it did not account for the case if the skb
was cloned. Fix this bug.

	Signed-off-by: K. Y. Srinivasan <kys@microsoft.com>
	Tested-by: Dexuan Cui <decui@microsoft.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit b56fc3c536541c8081cd5f1f1d101a16c002a365)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/hyperv/netvsc.c
#	drivers/net/hyperv/netvsc_drv.c
diff --cc drivers/net/hyperv/netvsc.c
index f6702b01e754,2d9ef533cc48..000000000000
--- a/drivers/net/hyperv/netvsc.c
+++ b/drivers/net/hyperv/netvsc.c
@@@ -810,6 -814,116 +810,119 @@@ int netvsc_send(struct hv_device *devic
  			   packet, ret);
  	}
  
++<<<<<<< HEAD
++=======
+ 	return ret;
+ }
+ 
+ int netvsc_send(struct hv_device *device,
+ 		struct hv_netvsc_packet *packet)
+ {
+ 	struct netvsc_device *net_device;
+ 	int ret = 0, m_ret = 0;
+ 	struct vmbus_channel *out_channel;
+ 	u16 q_idx = packet->q_idx;
+ 	u32 pktlen = packet->total_data_buflen, msd_len = 0;
+ 	unsigned int section_index = NETVSC_INVALID_INDEX;
+ 	struct sk_buff *skb = NULL;
+ 	unsigned long flag;
+ 	struct multi_send_data *msdp;
+ 	struct hv_netvsc_packet *msd_send = NULL, *cur_send = NULL;
+ 	bool try_batch;
+ 
+ 	net_device = get_outbound_net_device(device);
+ 	if (!net_device)
+ 		return -ENODEV;
+ 
+ 	out_channel = net_device->chn_table[q_idx];
+ 	if (!out_channel) {
+ 		out_channel = device->channel;
+ 		q_idx = 0;
+ 		packet->q_idx = 0;
+ 	}
+ 	packet->channel = out_channel;
+ 	packet->send_buf_index = NETVSC_INVALID_INDEX;
+ 	packet->cp_partial = false;
+ 
+ 	msdp = &net_device->msd[q_idx];
+ 
+ 	/* batch packets in send buffer if possible */
+ 	spin_lock_irqsave(&msdp->lock, flag);
+ 	if (msdp->pkt)
+ 		msd_len = msdp->pkt->total_data_buflen;
+ 
+ 	try_batch = packet->is_data_pkt && msd_len > 0 && msdp->count <
+ 		    net_device->max_pkt;
+ 
+ 	if (try_batch && msd_len + pktlen + net_device->pkt_align <
+ 	    net_device->send_section_size) {
+ 		section_index = msdp->pkt->send_buf_index;
+ 
+ 	} else if (try_batch && msd_len + packet->rmsg_size <
+ 		   net_device->send_section_size) {
+ 		section_index = msdp->pkt->send_buf_index;
+ 		packet->cp_partial = true;
+ 
+ 	} else if (packet->is_data_pkt && pktlen + net_device->pkt_align <
+ 		   net_device->send_section_size) {
+ 		section_index = netvsc_get_next_send_section(net_device);
+ 		if (section_index != NETVSC_INVALID_INDEX) {
+ 				msd_send = msdp->pkt;
+ 				msdp->pkt = NULL;
+ 				msdp->count = 0;
+ 				msd_len = 0;
+ 		}
+ 	}
+ 
+ 	if (section_index != NETVSC_INVALID_INDEX) {
+ 		netvsc_copy_to_send_buf(net_device,
+ 					section_index, msd_len,
+ 					packet);
+ 
+ 		packet->send_buf_index = section_index;
+ 
+ 		if (packet->cp_partial) {
+ 			packet->page_buf_cnt -= packet->rmsg_pgcnt;
+ 			packet->total_data_buflen = msd_len + packet->rmsg_size;
+ 		} else {
+ 			packet->page_buf_cnt = 0;
+ 			packet->total_data_buflen += msd_len;
+ 		}
+ 
+ 		if (msdp->pkt)
+ 			netvsc_xmit_completion(msdp->pkt);
+ 
+ 		if (packet->xmit_more && !packet->cp_partial) {
+ 			msdp->pkt = packet;
+ 			msdp->count++;
+ 		} else {
+ 			cur_send = packet;
+ 			msdp->pkt = NULL;
+ 			msdp->count = 0;
+ 		}
+ 	} else {
+ 		msd_send = msdp->pkt;
+ 		msdp->pkt = NULL;
+ 		msdp->count = 0;
+ 		cur_send = packet;
+ 	}
+ 
+ 	spin_unlock_irqrestore(&msdp->lock, flag);
+ 
+ 	if (msd_send) {
+ 		m_ret = netvsc_send_pkt(msd_send, net_device);
+ 
+ 		if (m_ret != 0) {
+ 			netvsc_free_send_slot(net_device,
+ 					      msd_send->send_buf_index);
+ 			netvsc_xmit_completion(msd_send);
+ 		}
+ 	}
+ 
+ 	if (cur_send)
+ 		ret = netvsc_send_pkt(cur_send, net_device);
+ 
++>>>>>>> b56fc3c53654 (hv_netvsc: Fix a bug in netvsc_start_xmit())
  	if (ret != 0) {
  		if (section_index != NETVSC_INVALID_INDEX)
  			netvsc_free_send_slot(net_device, section_index);
diff --cc drivers/net/hyperv/netvsc_drv.c
index f6bc78f79972,5993c7e2d723..000000000000
--- a/drivers/net/hyperv/netvsc_drv.c
+++ b/drivers/net/hyperv/netvsc_drv.c
@@@ -234,11 -237,8 +234,15 @@@ static void netvsc_xmit_completion(voi
  	struct hv_netvsc_packet *packet = (struct hv_netvsc_packet *)context;
  	struct sk_buff *skb = (struct sk_buff *)
  		(unsigned long)packet->send_completion_tid;
 +	u32 index = packet->send_buf_index;
  
++<<<<<<< HEAD
 +	kfree(packet);
 +
 +	if (skb && (index == NETVSC_INVALID_INDEX))
++=======
+ 	if (skb)
++>>>>>>> b56fc3c53654 (hv_netvsc: Fix a bug in netvsc_start_xmit())
  		dev_kfree_skb_any(skb);
  }
  
@@@ -383,37 -388,51 +387,59 @@@ static int netvsc_start_xmit(struct sk_
  	int  hdr_offset;
  	u32 net_trans_info;
  	u32 hash;
++<<<<<<< HEAD
 +	u32 skb_length = skb->len;
++=======
+ 	u32 skb_length;
+ 	u32 pkt_sz;
+ 	struct hv_page_buffer page_buf[MAX_PAGE_BUFFER_COUNT];
++>>>>>>> b56fc3c53654 (hv_netvsc: Fix a bug in netvsc_start_xmit())
  
  
  	/* We will atmost need two pages to describe the rndis
  	 * header. We can only transmit MAX_PAGE_BUFFER_COUNT number
 -	 * of pages in a single packet. If skb is scattered around
 -	 * more pages we try linearizing it.
 +	 * of pages in a single packet.
  	 */
++<<<<<<< HEAD
++=======
+ 
+ check_size:
+ 	skb_length = skb->len;
++>>>>>>> b56fc3c53654 (hv_netvsc: Fix a bug in netvsc_start_xmit())
  	num_data_pgs = netvsc_get_slots(skb) + 2;
 -	if (num_data_pgs > MAX_PAGE_BUFFER_COUNT && linear) {
 -		net_alert_ratelimited("packet too big: %u pages (%u bytes)\n",
 -				      num_data_pgs, skb->len);
 -		ret = -EFAULT;
 -		goto drop;
 -	} else if (num_data_pgs > MAX_PAGE_BUFFER_COUNT) {
 -		if (skb_linearize(skb)) {
 -			net_alert_ratelimited("failed to linearize skb\n");
 -			ret = -ENOMEM;
 -			goto drop;
 -		}
 -		linear = true;
 -		goto check_size;
 +	if (num_data_pgs > MAX_PAGE_BUFFER_COUNT) {
 +		netdev_err(net, "Packet too big: %u\n", skb->len);
 +		dev_kfree_skb(skb);
 +		net->stats.tx_dropped++;
 +		return NETDEV_TX_OK;
  	}
  
 -	pkt_sz = sizeof(struct hv_netvsc_packet) + RNDIS_AND_PPI_SIZE;
 -
 +	/* Allocate a netvsc packet based on # of frags. */
 +	packet = kzalloc(sizeof(struct hv_netvsc_packet) +
 +			 (num_data_pgs * sizeof(struct hv_page_buffer)) +
 +			 sizeof(struct rndis_message) +
 +			 NDIS_VLAN_PPI_SIZE + NDIS_CSUM_PPI_SIZE +
 +			 NDIS_LSO_PPI_SIZE + NDIS_HASH_PPI_SIZE, GFP_ATOMIC);
 +	if (!packet) {
 +		/* out of memory, drop packet */
 +		netdev_err(net, "unable to allocate hv_netvsc_packet\n");
 +
++<<<<<<< HEAD
 +		dev_kfree_skb(skb);
 +		net->stats.tx_dropped++;
 +		return NETDEV_TX_OK;
++=======
+ 	ret = skb_cow_head(skb, pkt_sz);
+ 	if (ret) {
+ 		netdev_err(net, "unable to alloc hv_netvsc_packet\n");
+ 		ret = -ENOMEM;
+ 		goto drop;
++>>>>>>> b56fc3c53654 (hv_netvsc: Fix a bug in netvsc_start_xmit())
  	}
+ 	/* Use the headroom for building up the packet */
+ 	packet = (struct hv_netvsc_packet *)skb->head;
  
 -	packet->status = 0;
 -	packet->xmit_more = skb->xmit_more;
 -
  	packet->vlan_tci = skb->vlan_tci;
 -	packet->page_buf = page_buf;
  
  	packet->q_idx = skb_get_queue_mapping(skb);
  
@@@ -563,7 -583,6 +589,10 @@@ drop
  		net->stats.tx_bytes += skb_length;
  		net->stats.tx_packets++;
  	} else {
++<<<<<<< HEAD
 +		kfree(packet);
++=======
++>>>>>>> b56fc3c53654 (hv_netvsc: Fix a bug in netvsc_start_xmit())
  		if (ret != -EAGAIN) {
  			dev_kfree_skb_any(skb);
  			net->stats.tx_dropped++;
* Unmerged path drivers/net/hyperv/netvsc.c
* Unmerged path drivers/net/hyperv/netvsc_drv.c
