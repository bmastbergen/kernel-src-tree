KVM: x86: avoid simultaneous queueing of both IRQ and SMI

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Paolo Bonzini <pbonzini@redhat.com>
commit c43203cab1e2e193c43f8295f01dfb2a0721d9e5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/c43203ca.failed

If the processor exits to KVM while delivering an interrupt,
the hypervisor then requeues the interrupt for the next vmentry.
Trying to enter SMM in this same window causes to enter non-root
mode in emulated SMM (i.e. with IF=0) and with a request to
inject an IRQ (i.e. with a valid VM-entry interrupt info field).
This is invalid guest state (SDM 26.3.1.4 "Check on Guest RIP
and RFLAGS") and the processor fails vmentry.

The fix is to defer the injection from KVM_REQ_SMI to KVM_REQ_EVENT,
like we already do for e.g. NMIs.  This patch doesn't change the
name of the process_smi function so that it can be applied to
stable releases.  The next patch will modify the names so that
process_nmi and process_smi handle respectively KVM_REQ_NMI and
KVM_REQ_SMI.

This is especially common with Windows, probably due to the
self-IPI trick that it uses to deliver deferred procedure
calls (DPCs).

	Reported-by: Laszlo Ersek <lersek@redhat.com>
	Reported-by: Michał Zegan <webczat_200@poczta.onet.pl>
Fixes: 64d6067057d9658acb8675afcfba549abdb7fc16
	Cc: stable@vger.kernel.org
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
	Signed-off-by: Radim Krčmář <rkrcmar@redhat.com>
(cherry picked from commit c43203cab1e2e193c43f8295f01dfb2a0721d9e5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/x86.c
diff --cc arch/x86/kvm/x86.c
index 28851e7c9b6f,5a26f8c066fa..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -6619,6 -6379,17 +6613,20 @@@ static void process_smi(struct kvm_vcp
  	kvm_mmu_reset_context(vcpu);
  }
  
++<<<<<<< HEAD
++=======
+ static void process_smi_request(struct kvm_vcpu *vcpu)
+ {
+ 	vcpu->arch.smi_pending = true;
+ 	kvm_make_request(KVM_REQ_EVENT, vcpu);
+ }
+ 
+ void kvm_make_scan_ioapic_request(struct kvm *kvm)
+ {
+ 	kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
+ }
+ 
++>>>>>>> c43203cab1e2 (KVM: x86: avoid simultaneous queueing of both IRQ and SMI)
  static void vcpu_scan_ioapic(struct kvm_vcpu *vcpu)
  {
  	u64 eoi_exit_bitmap[4];
@@@ -6806,10 -6641,14 +6824,12 @@@ static int vcpu_enter_guest(struct kvm_
  
  	kvm_load_guest_xcr0(vcpu);
  
- 	if (req_immediate_exit)
+ 	if (req_immediate_exit) {
+ 		kvm_make_request(KVM_REQ_EVENT, vcpu);
  		smp_send_reschedule(vcpu->cpu);
+ 	}
  
 -	trace_kvm_entry(vcpu->vcpu_id);
 -	wait_lapic_expire(vcpu);
 -	__kvm_guest_enter();
 +	kvm_guest_enter();
  
  	if (unlikely(vcpu->arch.switch_db_regs)) {
  		set_debugreg(0, 7);
* Unmerged path arch/x86/kvm/x86.c
