IB/qib: Remove old FRWR API

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Sagi Grimberg <sagig@mellanox.com>
commit b8533eccc8eadabc559ed25e4b848c71a2433c18
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/b8533ecc.failed

No ULP uses it anymore, go ahead and remove it.

	Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
	Acked-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit b8533eccc8eadabc559ed25e4b848c71a2433c18)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/qib/qib_keys.c
#	drivers/infiniband/hw/qib/qib_verbs.c
#	drivers/infiniband/hw/qib/qib_verbs.h
diff --cc drivers/infiniband/hw/qib/qib_keys.c
index eabe54738be6,d725c565518d..000000000000
--- a/drivers/infiniband/hw/qib/qib_keys.c
+++ b/drivers/infiniband/hw/qib/qib_keys.c
@@@ -336,14 -336,15 +336,26 @@@ bail
  }
  
  /*
++<<<<<<< HEAD
 + * Initialize the memory region specified by the work reqeust.
 + */
 +int qib_fast_reg_mr(struct qib_qp *qp, struct ib_send_wr *wr)
 +{
 +	struct qib_lkey_table *rkt = &to_idev(qp->ibqp.device)->lk_table;
 +	struct qib_pd *pd = to_ipd(qp->ibqp.pd);
 +	struct qib_mregion *mr;
 +	u32 rkey = wr->wr.fast_reg.rkey;
++=======
+  * Initialize the memory region specified by the work request.
+  */
+ int qib_reg_mr(struct qib_qp *qp, struct ib_reg_wr *wr)
+ {
+ 	struct qib_lkey_table *rkt = &to_idev(qp->ibqp.device)->lk_table;
+ 	struct qib_pd *pd = to_ipd(qp->ibqp.pd);
+ 	struct qib_mr *mr = to_imr(wr->mr);
+ 	struct qib_mregion *mrg;
+ 	u32 key = wr->key;
++>>>>>>> b8533eccc8ea (IB/qib: Remove old FRWR API)
  	unsigned i, n, m;
  	int ret = -EINVAL;
  	unsigned long flags;
@@@ -351,33 -352,33 +363,63 @@@
  	size_t ps;
  
  	spin_lock_irqsave(&rkt->lock, flags);
++<<<<<<< HEAD
 +	if (pd->user || rkey == 0)
 +		goto bail;
 +
 +	mr = rcu_dereference_protected(
 +		rkt->table[(rkey >> (32 - ib_qib_lkey_table_size))],
 +		lockdep_is_held(&rkt->lock));
 +	if (unlikely(mr == NULL || qp->ibqp.pd != mr->pd))
 +		goto bail;
 +
 +	if (wr->wr.fast_reg.page_list_len > mr->max_segs)
 +		goto bail;
 +
 +	ps = 1UL << wr->wr.fast_reg.page_shift;
 +	if (wr->wr.fast_reg.length > ps * wr->wr.fast_reg.page_list_len)
 +		goto bail;
 +
 +	mr->user_base = wr->wr.fast_reg.iova_start;
 +	mr->iova = wr->wr.fast_reg.iova_start;
 +	mr->lkey = rkey;
 +	mr->length = wr->wr.fast_reg.length;
 +	mr->access_flags = wr->wr.fast_reg.access_flags;
 +	page_list = wr->wr.fast_reg.page_list->page_list;
 +	m = 0;
 +	n = 0;
 +	for (i = 0; i < wr->wr.fast_reg.page_list_len; i++) {
 +		mr->map[m]->segs[n].vaddr = (void *) page_list[i];
 +		mr->map[m]->segs[n].length = ps;
++=======
+ 	if (pd->user || key == 0)
+ 		goto bail;
+ 
+ 	mrg = rcu_dereference_protected(
+ 		rkt->table[(key >> (32 - ib_qib_lkey_table_size))],
+ 		lockdep_is_held(&rkt->lock));
+ 	if (unlikely(mrg == NULL || qp->ibqp.pd != mrg->pd))
+ 		goto bail;
+ 
+ 	if (mr->npages > mrg->max_segs)
+ 		goto bail;
+ 
+ 	ps = mr->ibmr.page_size;
+ 	if (mr->ibmr.length > ps * mr->npages)
+ 		goto bail;
+ 
+ 	mrg->user_base = mr->ibmr.iova;
+ 	mrg->iova = mr->ibmr.iova;
+ 	mrg->lkey = key;
+ 	mrg->length = mr->ibmr.length;
+ 	mrg->access_flags = wr->access;
+ 	page_list = mr->pages;
+ 	m = 0;
+ 	n = 0;
+ 	for (i = 0; i < mr->npages; i++) {
+ 		mrg->map[m]->segs[n].vaddr = (void *) page_list[i];
+ 		mrg->map[m]->segs[n].length = ps;
++>>>>>>> b8533eccc8ea (IB/qib: Remove old FRWR API)
  		if (++n == QIB_SEGSZ) {
  			m++;
  			n = 0;
diff --cc drivers/infiniband/hw/qib/qib_verbs.c
index 3dcc4985b60f,de6cb6fcda8d..000000000000
--- a/drivers/infiniband/hw/qib/qib_verbs.c
+++ b/drivers/infiniband/hw/qib/qib_verbs.c
@@@ -362,8 -362,8 +362,13 @@@ static int qib_post_one_send(struct qib
  	 * undefined operations.
  	 * Make sure buffer is large enough to hold the result for atomics.
  	 */
++<<<<<<< HEAD
 +	if (wr->opcode == IB_WR_FAST_REG_MR) {
 +		if (qib_fast_reg_mr(qp, wr))
++=======
+ 	if (wr->opcode == IB_WR_REG_MR) {
+ 		if (qib_reg_mr(qp, reg_wr(wr)))
++>>>>>>> b8533eccc8ea (IB/qib: Remove old FRWR API)
  			goto bail_inval;
  	} else if (qp->ibqp.qp_type == IB_QPT_UC) {
  		if ((unsigned) wr->opcode >= IB_WR_RDMA_READ)
@@@ -397,7 -397,23 +402,27 @@@
  	rkt = &to_idev(qp->ibqp.device)->lk_table;
  	pd = to_ipd(qp->ibqp.pd);
  	wqe = get_swqe_ptr(qp, qp->s_head);
++<<<<<<< HEAD
 +	wqe->wr = *wr;
++=======
+ 
+ 	if (qp->ibqp.qp_type != IB_QPT_UC &&
+ 	    qp->ibqp.qp_type != IB_QPT_RC)
+ 		memcpy(&wqe->ud_wr, ud_wr(wr), sizeof(wqe->ud_wr));
+ 	else if (wr->opcode == IB_WR_REG_MR)
+ 		memcpy(&wqe->reg_wr, reg_wr(wr),
+ 			sizeof(wqe->reg_wr));
+ 	else if (wr->opcode == IB_WR_RDMA_WRITE_WITH_IMM ||
+ 		 wr->opcode == IB_WR_RDMA_WRITE ||
+ 		 wr->opcode == IB_WR_RDMA_READ)
+ 		memcpy(&wqe->rdma_wr, rdma_wr(wr), sizeof(wqe->rdma_wr));
+ 	else if (wr->opcode == IB_WR_ATOMIC_CMP_AND_SWP ||
+ 		 wr->opcode == IB_WR_ATOMIC_FETCH_AND_ADD)
+ 		memcpy(&wqe->atomic_wr, atomic_wr(wr), sizeof(wqe->atomic_wr));
+ 	else
+ 		memcpy(&wqe->wr, wr, sizeof(wqe->wr));
+ 
++>>>>>>> b8533eccc8ea (IB/qib: Remove old FRWR API)
  	wqe->length = 0;
  	j = 0;
  	if (wr->num_sge) {
@@@ -2244,8 -2260,7 +2269,12 @@@ int qib_register_ib_device(struct qib_d
  	ibdev->reg_user_mr = qib_reg_user_mr;
  	ibdev->dereg_mr = qib_dereg_mr;
  	ibdev->alloc_mr = qib_alloc_mr;
++<<<<<<< HEAD
 +	ibdev->alloc_fast_reg_page_list = qib_alloc_fast_reg_page_list;
 +	ibdev->free_fast_reg_page_list = qib_free_fast_reg_page_list;
++=======
+ 	ibdev->map_mr_sg = qib_map_mr_sg;
++>>>>>>> b8533eccc8ea (IB/qib: Remove old FRWR API)
  	ibdev->alloc_fmr = qib_alloc_fmr;
  	ibdev->map_phys_fmr = qib_map_phys_fmr;
  	ibdev->unmap_fmr = qib_unmap_fmr;
diff --cc drivers/infiniband/hw/qib/qib_verbs.h
index a08df70e8503,2baf5ad251ed..000000000000
--- a/drivers/infiniband/hw/qib/qib_verbs.h
+++ b/drivers/infiniband/hw/qib/qib_verbs.h
@@@ -338,7 -340,13 +338,17 @@@ struct qib_mr 
   * in qp->s_max_sge.
   */
  struct qib_swqe {
++<<<<<<< HEAD
 +	struct ib_send_wr wr;   /* don't use wr.sg_list */
++=======
+ 	union {
+ 		struct ib_send_wr wr;   /* don't use wr.sg_list */
+ 		struct ib_ud_wr ud_wr;
+ 		struct ib_reg_wr reg_wr;
+ 		struct ib_rdma_wr rdma_wr;
+ 		struct ib_atomic_wr atomic_wr;
+ 	};
++>>>>>>> b8533eccc8ea (IB/qib: Remove old FRWR API)
  	u32 psn;                /* first packet sequence number */
  	u32 lpsn;               /* last packet sequence number */
  	u32 ssn;                /* send sequence number */
@@@ -1038,12 -1046,11 +1048,20 @@@ struct ib_mr *qib_alloc_mr(struct ib_p
  			   enum ib_mr_type mr_type,
  			   u32 max_entries);
  
++<<<<<<< HEAD
 +struct ib_fast_reg_page_list *qib_alloc_fast_reg_page_list(
 +				struct ib_device *ibdev, int page_list_len);
 +
 +void qib_free_fast_reg_page_list(struct ib_fast_reg_page_list *pl);
 +
 +int qib_fast_reg_mr(struct qib_qp *qp, struct ib_send_wr *wr);
++=======
+ int qib_map_mr_sg(struct ib_mr *ibmr,
+ 		  struct scatterlist *sg,
+ 		  int sg_nents);
+ 
+ int qib_reg_mr(struct qib_qp *qp, struct ib_reg_wr *wr);
++>>>>>>> b8533eccc8ea (IB/qib: Remove old FRWR API)
  
  struct ib_fmr *qib_alloc_fmr(struct ib_pd *pd, int mr_access_flags,
  			     struct ib_fmr_attr *fmr_attr);
* Unmerged path drivers/infiniband/hw/qib/qib_keys.c
diff --git a/drivers/infiniband/hw/qib/qib_mr.c b/drivers/infiniband/hw/qib/qib_mr.c
index 19220dcb9a3b..0f107f765919 100644
--- a/drivers/infiniband/hw/qib/qib_mr.c
+++ b/drivers/infiniband/hw/qib/qib_mr.c
@@ -323,7 +323,7 @@ out:
 
 /*
  * Allocate a memory region usable with the
- * IB_WR_FAST_REG_MR send work request.
+ * IB_WR_REG_MR send work request.
  *
  * Return the memory region on success, otherwise return an errno.
  */
@@ -343,36 +343,6 @@ struct ib_mr *qib_alloc_mr(struct ib_pd *pd,
 	return &mr->ibmr;
 }
 
-struct ib_fast_reg_page_list *
-qib_alloc_fast_reg_page_list(struct ib_device *ibdev, int page_list_len)
-{
-	unsigned size = page_list_len * sizeof(u64);
-	struct ib_fast_reg_page_list *pl;
-
-	if (size > PAGE_SIZE)
-		return ERR_PTR(-EINVAL);
-
-	pl = kzalloc(sizeof(*pl), GFP_KERNEL);
-	if (!pl)
-		return ERR_PTR(-ENOMEM);
-
-	pl->page_list = kzalloc(size, GFP_KERNEL);
-	if (!pl->page_list)
-		goto err_free;
-
-	return pl;
-
-err_free:
-	kfree(pl);
-	return ERR_PTR(-ENOMEM);
-}
-
-void qib_free_fast_reg_page_list(struct ib_fast_reg_page_list *pl)
-{
-	kfree(pl->page_list);
-	kfree(pl);
-}
-
 /**
  * qib_alloc_fmr - allocate a fast memory region
  * @pd: the protection domain for this memory region
* Unmerged path drivers/infiniband/hw/qib/qib_verbs.c
* Unmerged path drivers/infiniband/hw/qib/qib_verbs.h
