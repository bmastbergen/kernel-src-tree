net: remove a dubious unlikely() clause

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [net] remove a dubious unlikely() clause (Ivan Vecera) [1268334]
Rebuild_FUZZ: 93.15%
commit-author Eric Dumazet <edumazet@google.com>
commit abbdb5a74cead60e20b79c960c1772955f0b6b81
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/abbdb5a7.failed

TCP protocol is still used these days, and TCP uses
clones in its transmit path. We can not optimize linux
stack assuming it is mostly used in routers, or that TCP
is dead.

Fixes: 795bb1c00d ("net: bulk free infrastructure for NAPI context, use napi_consume_skb")
	Signed-off-by: Eric Dumazet <edumazet@google.com>
	Cc: Jesper Dangaard Brouer <brouer@redhat.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit abbdb5a74cead60e20b79c960c1772955f0b6b81)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/core/skbuff.c
diff --cc net/core/skbuff.c
index fc02ef9734c7,d04c2d1c8c87..000000000000
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@@ -831,6 -757,80 +831,83 @@@ void consume_skb(struct sk_buff *skb
  }
  EXPORT_SYMBOL(consume_skb);
  
++<<<<<<< HEAD
++=======
+ void __kfree_skb_flush(void)
+ {
+ 	struct napi_alloc_cache *nc = this_cpu_ptr(&napi_alloc_cache);
+ 
+ 	/* flush skb_cache if containing objects */
+ 	if (nc->skb_count) {
+ 		kmem_cache_free_bulk(skbuff_head_cache, nc->skb_count,
+ 				     nc->skb_cache);
+ 		nc->skb_count = 0;
+ 	}
+ }
+ 
+ static inline void _kfree_skb_defer(struct sk_buff *skb)
+ {
+ 	struct napi_alloc_cache *nc = this_cpu_ptr(&napi_alloc_cache);
+ 
+ 	/* drop skb->head and call any destructors for packet */
+ 	skb_release_all(skb);
+ 
+ 	/* record skb to CPU local list */
+ 	nc->skb_cache[nc->skb_count++] = skb;
+ 
+ #ifdef CONFIG_SLUB
+ 	/* SLUB writes into objects when freeing */
+ 	prefetchw(skb);
+ #endif
+ 
+ 	/* flush skb_cache if it is filled */
+ 	if (unlikely(nc->skb_count == NAPI_SKB_CACHE_SIZE)) {
+ 		kmem_cache_free_bulk(skbuff_head_cache, NAPI_SKB_CACHE_SIZE,
+ 				     nc->skb_cache);
+ 		nc->skb_count = 0;
+ 	}
+ }
+ void __kfree_skb_defer(struct sk_buff *skb)
+ {
+ 	_kfree_skb_defer(skb);
+ }
+ 
+ void napi_consume_skb(struct sk_buff *skb, int budget)
+ {
+ 	if (unlikely(!skb))
+ 		return;
+ 
+ 	/* Zero budget indicate non-NAPI context called us, like netpoll */
+ 	if (unlikely(!budget)) {
+ 		dev_consume_skb_any(skb);
+ 		return;
+ 	}
+ 
+ 	if (likely(atomic_read(&skb->users) == 1))
+ 		smp_rmb();
+ 	else if (likely(!atomic_dec_and_test(&skb->users)))
+ 		return;
+ 	/* if reaching here SKB is ready to free */
+ 	trace_consume_skb(skb);
+ 
+ 	/* if SKB is a clone, don't handle this case */
+ 	if (skb->fclone != SKB_FCLONE_UNAVAILABLE) {
+ 		__kfree_skb(skb);
+ 		return;
+ 	}
+ 
+ 	_kfree_skb_defer(skb);
+ }
+ EXPORT_SYMBOL(napi_consume_skb);
+ 
+ /* Make sure a field is enclosed inside headers_start/headers_end section */
+ #define CHECK_SKB_FIELD(field) \
+ 	BUILD_BUG_ON(offsetof(struct sk_buff, field) <		\
+ 		     offsetof(struct sk_buff, headers_start));	\
+ 	BUILD_BUG_ON(offsetof(struct sk_buff, field) >		\
+ 		     offsetof(struct sk_buff, headers_end));	\
+ 
++>>>>>>> abbdb5a74cea (net: remove a dubious unlikely() clause)
  static void __copy_skb_header(struct sk_buff *new, const struct sk_buff *old)
  {
  	new->tstamp		= old->tstamp;
* Unmerged path net/core/skbuff.c
