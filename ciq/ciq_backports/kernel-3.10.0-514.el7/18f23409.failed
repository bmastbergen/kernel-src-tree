iommu: Decouple iommu_map_sg from CPU page size

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [iommu] Decouple iommu_map_sg from CPU page size (Myron Stowe) [1287300]
Rebuild_FUZZ: 91.95%
commit-author Robin Murphy <robin.murphy@arm.com>
commit 18f23409909a9547ac7c149013286f36fcffa433
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/18f23409.failed

If the IOMMU supports pages smaller than the CPU page size, segments
which lie at offsets within the CPU page may be mapped based on the
finer-grained IOMMU page boundaries. This minimises the amount of
non-buffer memory between the CPU page boundary and the start of the
segment which must be mapped and therefore exposed to the device, and
brings the default iommu_map_sg implementation in line with
iommu_map/unmap with respect to alignment.

	Signed-off-by: Robin Murphy <robin.murphy@arm.com>
	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit 18f23409909a9547ac7c149013286f36fcffa433)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/iommu.c
diff --cc drivers/iommu/iommu.c
index 58da13944bc3,1bd63352ab17..000000000000
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@@ -1109,6 -1138,48 +1109,51 @@@ size_t iommu_unmap(struct iommu_domain 
  }
  EXPORT_SYMBOL_GPL(iommu_unmap);
  
++<<<<<<< HEAD
++=======
+ size_t default_iommu_map_sg(struct iommu_domain *domain, unsigned long iova,
+ 			 struct scatterlist *sg, unsigned int nents, int prot)
+ {
+ 	struct scatterlist *s;
+ 	size_t mapped = 0;
+ 	unsigned int i, min_pagesz;
+ 	int ret;
+ 
+ 	if (unlikely(domain->ops->pgsize_bitmap == 0UL))
+ 		return 0;
+ 
+ 	min_pagesz = 1 << __ffs(domain->ops->pgsize_bitmap);
+ 
+ 	for_each_sg(sg, s, nents, i) {
+ 		phys_addr_t phys = page_to_phys(sg_page(s)) + s->offset;
+ 
+ 		/*
+ 		 * We are mapping on IOMMU page boundaries, so offset within
+ 		 * the page must be 0. However, the IOMMU may support pages
+ 		 * smaller than PAGE_SIZE, so s->offset may still represent
+ 		 * an offset of that boundary within the CPU page.
+ 		 */
+ 		if (!IS_ALIGNED(s->offset, min_pagesz))
+ 			goto out_err;
+ 
+ 		ret = iommu_map(domain, iova + mapped, phys, s->length, prot);
+ 		if (ret)
+ 			goto out_err;
+ 
+ 		mapped += s->length;
+ 	}
+ 
+ 	return mapped;
+ 
+ out_err:
+ 	/* undo mappings already done */
+ 	iommu_unmap(domain, iova, mapped);
+ 
+ 	return 0;
+ 
+ }
+ EXPORT_SYMBOL_GPL(default_iommu_map_sg);
++>>>>>>> 18f23409909a (iommu: Decouple iommu_map_sg from CPU page size)
  
  int iommu_domain_window_enable(struct iommu_domain *domain, u32 wnd_nr,
  			       phys_addr_t paddr, u64 size, int prot)
* Unmerged path drivers/iommu/iommu.c
