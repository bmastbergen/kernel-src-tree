xfs: handle DIO overwrite EOF update completion correctly

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Dave Chinner <dchinner@redhat.com>
commit 6dfa1b67e3b3a9bf536e2fb9ed99001c219822a5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/6dfa1b67.failed

Currently a DIO overwrite that extends the EOF (e.g sub-block IO or
write into allocated blocks beyond EOF) requires a transaction for
the EOF update. Thi is done in IO completion context, but we aren't
explicitly handling this situation properly and so it can run in
interrupt context. Ensure that we defer IO that spans EOF correctly
to the DIO completion workqueue, and now that we have an ioend in IO
completion we can use the common ioend completion path to do all the
work.

Note: we do not preallocate the append transaction as we can have
multiple mapping and allocation calls per direct IO. hence
preallocating can still leave us with nested transactions by
attempting to map and allocate more blocks after we've preallocated
an append transaction.

	Signed-off-by: Dave Chinner <dchinner@redhat.com>
	Reviewed-by: Brian Foster <bfoster@redhat.com>
	Signed-off-by: Dave Chinner <david@fromorbit.com>

(cherry picked from commit 6dfa1b67e3b3a9bf536e2fb9ed99001c219822a5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/xfs_aops.c
#	fs/xfs/xfs_trace.h
diff --cc fs/xfs/xfs_aops.c
index bb6024910e57,a59443db1de9..000000000000
--- a/fs/xfs/xfs_aops.c
+++ b/fs/xfs/xfs_aops.c
@@@ -1260,6 -1233,111 +1260,114 @@@ xfs_vm_releasepage
  	return try_to_free_buffers(page);
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * When we map a DIO buffer, we need to attach an ioend that describes the type
+  * of write IO we are doing. This passes to the completion function the
+  * operations it needs to perform.
+  *
+  * If we get multiple mappings in a single IO, we might be mapping different
+  * types. But because the direct IO can only have a single private pointer, we
+  * need to ensure that:
+  *
+  * a) the ioend spans the entire region of the IO; and
+  * b) if it contains unwritten extents, it is *permanently* marked as such
+  *
+  * We could do this by chaining ioends like buffered IO does, but we only
+  * actually get one IO completion callback from the direct IO, and that spans
+  * the entire IO regardless of how many mappings and IOs are needed to complete
+  * the DIO. There is only going to be one reference to the ioend and its life
+  * cycle is constrained by the DIO completion code. hence we don't need
+  * reference counting here.
+  */
+ static void
+ xfs_map_direct(
+ 	struct inode		*inode,
+ 	struct buffer_head	*bh_result,
+ 	struct xfs_bmbt_irec	*imap,
+ 	xfs_off_t		offset)
+ {
+ 	struct xfs_ioend	*ioend;
+ 	xfs_off_t		size = bh_result->b_size;
+ 	int			type;
+ 
+ 	if (ISUNWRITTEN(imap))
+ 		type = XFS_IO_UNWRITTEN;
+ 	else
+ 		type = XFS_IO_OVERWRITE;
+ 
+ 	trace_xfs_gbmap_direct(XFS_I(inode), offset, size, type, imap);
+ 
+ 	if (bh_result->b_private) {
+ 		ioend = bh_result->b_private;
+ 		ASSERT(ioend->io_size > 0);
+ 		ASSERT(offset >= ioend->io_offset);
+ 		if (offset + size > ioend->io_offset + ioend->io_size)
+ 			ioend->io_size = offset - ioend->io_offset + size;
+ 
+ 		if (type == XFS_IO_UNWRITTEN && type != ioend->io_type)
+ 			ioend->io_type = XFS_IO_UNWRITTEN;
+ 
+ 		trace_xfs_gbmap_direct_update(XFS_I(inode), ioend->io_offset,
+ 					      ioend->io_size, ioend->io_type,
+ 					      imap);
+ 	} else {
+ 		ioend = xfs_alloc_ioend(inode, type);
+ 		ioend->io_offset = offset;
+ 		ioend->io_size = size;
+ 		bh_result->b_private = ioend;
+ 
+ 		trace_xfs_gbmap_direct_new(XFS_I(inode), offset, size, type,
+ 					   imap);
+ 	}
+ 
+ 	if (ioend->io_type == XFS_IO_UNWRITTEN || xfs_ioend_is_append(ioend))
+ 		set_buffer_defer_completion(bh_result);
+ }
+ 
+ 
+ /*
+  * If this is O_DIRECT or the mpage code calling tell them how large the mapping
+  * is, so that we can avoid repeated get_blocks calls.
+  *
+  * If the mapping spans EOF, then we have to break the mapping up as the mapping
+  * for blocks beyond EOF must be marked new so that sub block regions can be
+  * correctly zeroed. We can't do this for mappings within EOF unless the mapping
+  * was just allocated or is unwritten, otherwise the callers would overwrite
+  * existing data with zeros. Hence we have to split the mapping into a range up
+  * to and including EOF, and a second mapping for beyond EOF.
+  */
+ static void
+ xfs_map_trim_size(
+ 	struct inode		*inode,
+ 	sector_t		iblock,
+ 	struct buffer_head	*bh_result,
+ 	struct xfs_bmbt_irec	*imap,
+ 	xfs_off_t		offset,
+ 	ssize_t			size)
+ {
+ 	xfs_off_t		mapping_size;
+ 
+ 	mapping_size = imap->br_startoff + imap->br_blockcount - iblock;
+ 	mapping_size <<= inode->i_blkbits;
+ 
+ 	ASSERT(mapping_size > 0);
+ 	if (mapping_size > size)
+ 		mapping_size = size;
+ 	if (offset < i_size_read(inode) &&
+ 	    offset + mapping_size >= i_size_read(inode)) {
+ 		/* limit mapping to block that spans EOF */
+ 		mapping_size = roundup_64(i_size_read(inode) - offset,
+ 					  1 << inode->i_blkbits);
+ 	}
+ 	if (mapping_size > LONG_MAX)
+ 		mapping_size = LONG_MAX;
+ 
+ 	bh_result->b_size = mapping_size;
+ }
+ 
++>>>>>>> 6dfa1b67e3b3 (xfs: handle DIO overwrite EOF update completion correctly)
  STATIC int
  __xfs_get_blocks(
  	struct inode		*inode,
@@@ -1479,50 -1528,68 +1587,113 @@@ xfs_end_io_direct_write
  	struct kiocb		*iocb,
  	loff_t			offset,
  	ssize_t			size,
 -	void			*private)
 +	void			*private,
 +	int			ret,
 +	bool			is_async)
  {
++<<<<<<< HEAD
 +	struct xfs_ioend	*ioend = iocb->private;
 +	struct xfs_inode	*ip = XFS_I(ioend->io_inode);
 +	unsigned long		flags;
 +
 +	/*
 +	 * While the generic direct I/O code updates the inode size, it does
 +	 * so only after the end_io handler is called, which means our
 +	 * end_io handler thinks the on-disk size is outside the in-core
 +	 * size.  To prevent this just update it a little bit earlier here.
 +	 *
 +	 * We need to lock the test/set EOF update as we can be racing with
 +	 * other IO completions here to update the EOF. Failing to serialise
 +	 * here can result in EOF moving backwards and Bad Things Happen when
 +	 * that occurs.
 +	 */
 +	spin_lock_irqsave(&ip->i_size_lock, flags);
 +	if (offset + size > i_size_read(ioend->io_inode))
 +		i_size_write(ioend->io_inode, offset + size);
 +	spin_unlock_irqrestore(&ip->i_size_lock, flags);
 +
 +	/*
 +	 * blockdev_direct_IO can return an error even after the I/O
 +	 * completion handler was called.  Thus we need to protect
 +	 * against double-freeing.
 +	 */
 +	iocb->private = NULL;
 +
 +	ioend->io_offset = offset;
 +	ioend->io_size = size;
 +	ioend->io_iocb = iocb;
 +	ioend->io_result = ret;
 +	if (private && size > 0)
 +		ioend->io_type = XFS_IO_UNWRITTEN;
 +
 +	if (is_async) {
 +		ioend->io_isasync = 1;
 +		xfs_finish_ioend(ioend);
 +	} else {
 +		xfs_finish_ioend_sync(ioend);
 +	}
++=======
+ 	struct inode		*inode = file_inode(iocb->ki_filp);
+ 	struct xfs_inode	*ip = XFS_I(inode);
+ 	struct xfs_mount	*mp = ip->i_mount;
+ 	struct xfs_ioend	*ioend = private;
+ 
+ 	trace_xfs_gbmap_direct_endio(ip, offset, size, ioend->io_type, NULL);
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		goto out_end_io;
+ 
+ 	/*
+ 	 * dio completion end_io functions are only called on writes if more
+ 	 * than 0 bytes was written.
+ 	 */
+ 	ASSERT(size > 0);
+ 
+ 	/*
+ 	 * The ioend only maps whole blocks, while the IO may be sector aligned.
+ 	 * Hence the ioend offset/size may not match the IO offset/size exactly,
+ 	 * but should span it completely. Write the IO sizes into the ioend so
+ 	 * that completion processing does the right thing.
+ 	 */
+ 	ASSERT(size <= ioend->io_size);
+ 	ASSERT(offset >= ioend->io_offset);
+ 	ASSERT(offset + size <= ioend->io_offset + ioend->io_size);
+ 	ioend->io_size = size;
+ 	ioend->io_offset = offset;
+ 
+ 	/*
+ 	 * The ioend tells us whether we are doing unwritten extent conversion
+ 	 * or an append transaction that updates the on-disk file size. These
+ 	 * cases are the only cases where we should *potentially* be needing
+ 	 * to update the VFS inode size. When the ioend indicates this, we
+ 	 * are *guaranteed* to be running in non-interrupt context.
+ 	 *
+ 	 * We need to update the in-core inode size here so that we don't end up
+ 	 * with the on-disk inode size being outside the in-core inode size.
+ 	 * While we can do this in the process context after the IO has
+ 	 * completed, this does not work for AIO and hence we always update
+ 	 * the in-core inode size here if necessary.
+ 	 */
+ 	if (ioend->io_type == XFS_IO_UNWRITTEN || xfs_ioend_is_append(ioend)) {
+ 		if (offset + size > i_size_read(inode))
+ 			i_size_write(inode, offset + size);
+ 	} else
+ 		ASSERT(offset + size <= i_size_read(inode));
+ 
+ 	/*
+ 	 * If we are doing an append IO that needs to update the EOF on disk,
+ 	 * do the transaction reserve now so we can use common end io
+ 	 * processing. Stashing the error (if there is one) in the ioend will
+ 	 * result in the ioend processing passing on the error if it is
+ 	 * possible as we can't return it from here.
+ 	 */
+ 	if (ioend->io_type == XFS_IO_OVERWRITE && xfs_ioend_is_append(ioend))
+ 		ioend->io_error = xfs_setfilesize_trans_alloc(ioend);
+ 
+ out_end_io:
+ 	xfs_end_io(&ioend->io_work);
+ 	return;
++>>>>>>> 6dfa1b67e3b3 (xfs: handle DIO overwrite EOF update completion correctly)
  }
  
  STATIC ssize_t
diff --cc fs/xfs/xfs_trace.h
index 1cc33065983c,0ae50e9847bb..000000000000
--- a/fs/xfs/xfs_trace.h
+++ b/fs/xfs/xfs_trace.h
@@@ -1221,6 -1217,10 +1221,13 @@@ DEFINE_IOMAP_EVENT(xfs_map_blocks_found
  DEFINE_IOMAP_EVENT(xfs_map_blocks_alloc);
  DEFINE_IOMAP_EVENT(xfs_get_blocks_found);
  DEFINE_IOMAP_EVENT(xfs_get_blocks_alloc);
++<<<<<<< HEAD
++=======
+ DEFINE_IOMAP_EVENT(xfs_gbmap_direct);
+ DEFINE_IOMAP_EVENT(xfs_gbmap_direct_new);
+ DEFINE_IOMAP_EVENT(xfs_gbmap_direct_update);
+ DEFINE_IOMAP_EVENT(xfs_gbmap_direct_endio);
++>>>>>>> 6dfa1b67e3b3 (xfs: handle DIO overwrite EOF update completion correctly)
  
  DECLARE_EVENT_CLASS(xfs_simple_io_class,
  	TP_PROTO(struct xfs_inode *ip, xfs_off_t offset, ssize_t count),
* Unmerged path fs/xfs/xfs_aops.c
* Unmerged path fs/xfs/xfs_trace.h
