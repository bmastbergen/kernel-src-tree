perf cpu_map: Add cpu_map event synthesize function

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Jiri Olsa <jolsa@kernel.org>
commit 6c872901af07c41745f1abf5ceac9b3b4d9cdbb6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/6c872901.failed

Introduce the perf_event__synthesize_cpu_map function to synthesize a
struct cpu_map.

Added generic interface:
  cpu_map_data__alloc
  cpu_map_data__synthesize

to make the cpu_map synthesizing usable for other events.

	Signed-off-by: Jiri Olsa <jolsa@kernel.org>
	Tested-by: Kan Liang <kan.liang@intel.com>
	Cc: David Ahern <dsahern@gmail.com>
	Cc: Namhyung Kim <namhyung@kernel.org>
	Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
Link: http://lkml.kernel.org/r/1445784728-21732-9-git-send-email-jolsa@kernel.org
	Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
(cherry picked from commit 6c872901af07c41745f1abf5ceac9b3b4d9cdbb6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/perf/tests/Build
#	tools/perf/tests/builtin-test.c
#	tools/perf/tests/tests.h
#	tools/perf/util/event.c
#	tools/perf/util/event.h
diff --cc tools/perf/tests/Build
index d20d6e6ab65b,7abad28fe17e..000000000000
--- a/tools/perf/tests/Build
+++ b/tools/perf/tests/Build
@@@ -32,8 -31,31 +32,15 @@@ perf-y += sample-parsing.
  perf-y += parse-no-sample-id-all.o
  perf-y += kmod-path.o
  perf-y += thread-map.o
++<<<<<<< HEAD
++=======
+ perf-y += llvm.o llvm-src-base.o llvm-src-kbuild.o llvm-src-prologue.o
+ perf-y += bpf.o
+ perf-y += topology.o
+ perf-y += cpumap.o
++>>>>>>> 6c872901af07 (perf cpu_map: Add cpu_map event synthesize function)
  
 -$(OUTPUT)tests/llvm-src-base.c: tests/bpf-script-example.c tests/Build
 -	$(call rule_mkdir)
 -	$(Q)echo '#include <tests/llvm.h>' > $@
 -	$(Q)echo 'const char test_llvm__bpf_base_prog[] =' >> $@
 -	$(Q)sed -e 's/"/\\"/g' -e 's/\(.*\)/"\1\\n"/g' $< >> $@
 -	$(Q)echo ';' >> $@
 -
 -$(OUTPUT)tests/llvm-src-kbuild.c: tests/bpf-script-test-kbuild.c tests/Build
 -	$(call rule_mkdir)
 -	$(Q)echo '#include <tests/llvm.h>' > $@
 -	$(Q)echo 'const char test_llvm__bpf_test_kbuild_prog[] =' >> $@
 -	$(Q)sed -e 's/"/\\"/g' -e 's/\(.*\)/"\1\\n"/g' $< >> $@
 -	$(Q)echo ';' >> $@
 -
 -$(OUTPUT)tests/llvm-src-prologue.c: tests/bpf-script-test-prologue.c tests/Build
 -	$(call rule_mkdir)
 -	$(Q)echo '#include <tests/llvm.h>' > $@
 -	$(Q)echo 'const char test_llvm__bpf_test_prologue_prog[] =' >> $@
 -	$(Q)sed -e 's/"/\\"/g' -e 's/\(.*\)/"\1\\n"/g' $< >> $@
 -	$(Q)echo ';' >> $@
 +perf-$(CONFIG_X86) += perf-time-to-tsc.o
  
  ifeq ($(ARCH),$(filter $(ARCH),x86 arm arm64))
  perf-$(CONFIG_DWARF_UNWIND) += dwarf-unwind.o
diff --cc tools/perf/tests/builtin-test.c
index 2337c002804d,0c3fe2846de8..000000000000
--- a/tools/perf/tests/builtin-test.c
+++ b/tools/perf/tests/builtin-test.c
@@@ -178,6 -158,36 +178,39 @@@ static struct test generic_tests[] = 
  		.func = test__thread_map,
  	},
  	{
++<<<<<<< HEAD
++=======
+ 		.desc = "Test LLVM searching and compiling",
+ 		.func = test__llvm,
+ 		.subtest = {
+ 			.skip_if_fail	= true,
+ 			.get_nr		= test__llvm_subtest_get_nr,
+ 			.get_desc	= test__llvm_subtest_get_desc,
+ 		},
+ 	},
+ 	{
+ 		.desc = "Test topology in session",
+ 		.func = test_session_topology,
+ 	},
+ 	{
+ 		.desc = "Test BPF filter",
+ 		.func = test__bpf,
+ 		.subtest = {
+ 			.skip_if_fail	= true,
+ 			.get_nr		= test__bpf_subtest_get_nr,
+ 			.get_desc	= test__bpf_subtest_get_desc,
+ 		},
+ 	},
+ 	{
+ 		.desc = "Test thread map synthesize",
+ 		.func = test__thread_map_synthesize,
+ 	},
+ 	{
+ 		.desc = "Test cpu map synthesize",
+ 		.func = test__cpu_map_synthesize,
+ 	},
+ 	{
++>>>>>>> 6c872901af07 (perf cpu_map: Add cpu_map event synthesize function)
  		.func = NULL,
  	},
  };
diff --cc tools/perf/tests/tests.h
index a08027794fa0,f85160f6ebb8..000000000000
--- a/tools/perf/tests/tests.h
+++ b/tools/perf/tests/tests.h
@@@ -30,45 -37,52 +30,92 @@@ struct test 
  };
  
  /* Tests */
++<<<<<<< HEAD
 +int test__vmlinux_matches_kallsyms(void);
 +int test__openat_syscall_event(void);
 +int test__openat_syscall_event_on_all_cpus(void);
 +int test__basic_mmap(void);
 +int test__PERF_RECORD(void);
 +int test__rdpmc(void);
 +int test__perf_evsel__roundtrip_name_test(void);
 +int test__perf_evsel__tp_sched_test(void);
 +int test__syscall_openat_tp_fields(void);
 +int test__pmu(void);
 +int test__attr(void);
 +int test__dso_data(void);
 +int test__dso_data_cache(void);
 +int test__dso_data_reopen(void);
 +int test__parse_events(void);
 +int test__hists_link(void);
 +int test__python_use(void);
 +int test__bp_signal(void);
 +int test__bp_signal_overflow(void);
 +int test__task_exit(void);
 +int test__sw_clock_freq(void);
 +int test__perf_time_to_tsc(void);
 +int test__code_reading(void);
 +int test__sample_parsing(void);
 +int test__keep_tracking(void);
 +int test__parse_no_sample_id_all(void);
 +int test__dwarf_unwind(void);
 +int test__hists_filter(void);
 +int test__mmap_thread_lookup(void);
 +int test__thread_mg_share(void);
 +int test__hists_output(void);
 +int test__hists_cumulate(void);
 +int test__switch_tracking(void);
 +int test__fdarray__filter(void);
 +int test__fdarray__add(void);
 +int test__kmod_path__parse(void);
 +int test__thread_map(void);
++=======
+ int test__vmlinux_matches_kallsyms(int subtest);
+ int test__openat_syscall_event(int subtest);
+ int test__openat_syscall_event_on_all_cpus(int subtest);
+ int test__basic_mmap(int subtest);
+ int test__PERF_RECORD(int subtest);
+ int test__perf_evsel__roundtrip_name_test(int subtest);
+ int test__perf_evsel__tp_sched_test(int subtest);
+ int test__syscall_openat_tp_fields(int subtest);
+ int test__pmu(int subtest);
+ int test__attr(int subtest);
+ int test__dso_data(int subtest);
+ int test__dso_data_cache(int subtest);
+ int test__dso_data_reopen(int subtest);
+ int test__parse_events(int subtest);
+ int test__hists_link(int subtest);
+ int test__python_use(int subtest);
+ int test__bp_signal(int subtest);
+ int test__bp_signal_overflow(int subtest);
+ int test__task_exit(int subtest);
+ int test__sw_clock_freq(int subtest);
+ int test__code_reading(int subtest);
+ int test__sample_parsing(int subtest);
+ int test__keep_tracking(int subtest);
+ int test__parse_no_sample_id_all(int subtest);
+ int test__dwarf_unwind(int subtest);
+ int test__hists_filter(int subtest);
+ int test__mmap_thread_lookup(int subtest);
+ int test__thread_mg_share(int subtest);
+ int test__hists_output(int subtest);
+ int test__hists_cumulate(int subtest);
+ int test__switch_tracking(int subtest);
+ int test__fdarray__filter(int subtest);
+ int test__fdarray__add(int subtest);
+ int test__kmod_path__parse(int subtest);
+ int test__thread_map(int subtest);
+ int test__llvm(int subtest);
+ const char *test__llvm_subtest_get_desc(int subtest);
+ int test__llvm_subtest_get_nr(void);
+ int test__bpf(int subtest);
+ const char *test__bpf_subtest_get_desc(int subtest);
+ int test__bpf_subtest_get_nr(void);
+ int test_session_topology(int subtest);
+ int test__thread_map_synthesize(int subtest);
+ int test__cpu_map_synthesize(int subtest);
++>>>>>>> 6c872901af07 (perf cpu_map: Add cpu_map event synthesize function)
  
 -#if defined(__arm__) || defined(__aarch64__)
 +#if defined(__x86_64__) || defined(__i386__) || defined(__arm__) || defined(__aarch64__)
  #ifdef HAVE_DWARF_UNWIND_SUPPORT
  struct thread;
  struct perf_sample;
diff --cc tools/perf/util/event.c
index 763fbcde76fc,15d6466a4b8f..000000000000
--- a/tools/perf/util/event.c
+++ b/tools/perf/util/event.c
@@@ -687,6 -701,173 +687,176 @@@ int perf_event__synthesize_kernel_mmap(
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ int perf_event__synthesize_thread_map2(struct perf_tool *tool,
+ 				      struct thread_map *threads,
+ 				      perf_event__handler_t process,
+ 				      struct machine *machine)
+ {
+ 	union perf_event *event;
+ 	int i, err, size;
+ 
+ 	size  = sizeof(event->thread_map);
+ 	size +=	threads->nr * sizeof(event->thread_map.entries[0]);
+ 
+ 	event = zalloc(size);
+ 	if (!event)
+ 		return -ENOMEM;
+ 
+ 	event->header.type = PERF_RECORD_THREAD_MAP;
+ 	event->header.size = size;
+ 	event->thread_map.nr = threads->nr;
+ 
+ 	for (i = 0; i < threads->nr; i++) {
+ 		struct thread_map_event_entry *entry = &event->thread_map.entries[i];
+ 		char *comm = thread_map__comm(threads, i);
+ 
+ 		if (!comm)
+ 			comm = (char *) "";
+ 
+ 		entry->pid = thread_map__pid(threads, i);
+ 		strncpy((char *) &entry->comm, comm, sizeof(entry->comm));
+ 	}
+ 
+ 	err = process(tool, event, NULL, machine);
+ 
+ 	free(event);
+ 	return err;
+ }
+ 
+ static void synthesize_cpus(struct cpu_map_entries *cpus,
+ 			    struct cpu_map *map)
+ {
+ 	int i;
+ 
+ 	cpus->nr = map->nr;
+ 
+ 	for (i = 0; i < map->nr; i++)
+ 		cpus->cpu[i] = map->map[i];
+ }
+ 
+ static void synthesize_mask(struct cpu_map_mask *mask,
+ 			    struct cpu_map *map, int max)
+ {
+ 	int i;
+ 
+ 	mask->nr = BITS_TO_LONGS(max);
+ 	mask->long_size = sizeof(long);
+ 
+ 	for (i = 0; i < map->nr; i++)
+ 		set_bit(map->map[i], mask->mask);
+ }
+ 
+ static size_t cpus_size(struct cpu_map *map)
+ {
+ 	return sizeof(struct cpu_map_entries) + map->nr * sizeof(u16);
+ }
+ 
+ static size_t mask_size(struct cpu_map *map, int *max)
+ {
+ 	int i;
+ 
+ 	*max = 0;
+ 
+ 	for (i = 0; i < map->nr; i++) {
+ 		/* bit possition of the cpu is + 1 */
+ 		int bit = map->map[i] + 1;
+ 
+ 		if (bit > *max)
+ 			*max = bit;
+ 	}
+ 
+ 	return sizeof(struct cpu_map_mask) + BITS_TO_LONGS(*max) * sizeof(long);
+ }
+ 
+ void *cpu_map_data__alloc(struct cpu_map *map, size_t *size, u16 *type, int *max)
+ {
+ 	size_t size_cpus, size_mask;
+ 	bool is_dummy = cpu_map__empty(map);
+ 
+ 	/*
+ 	 * Both array and mask data have variable size based
+ 	 * on the number of cpus and their actual values.
+ 	 * The size of the 'struct cpu_map_data' is:
+ 	 *
+ 	 *   array = size of 'struct cpu_map_entries' +
+ 	 *           number of cpus * sizeof(u64)
+ 	 *
+ 	 *   mask  = size of 'struct cpu_map_mask' +
+ 	 *           maximum cpu bit converted to size of longs
+ 	 *
+ 	 * and finaly + the size of 'struct cpu_map_data'.
+ 	 */
+ 	size_cpus = cpus_size(map);
+ 	size_mask = mask_size(map, max);
+ 
+ 	if (is_dummy || (size_cpus < size_mask)) {
+ 		*size += size_cpus;
+ 		*type  = PERF_CPU_MAP__CPUS;
+ 	} else {
+ 		*size += size_mask;
+ 		*type  = PERF_CPU_MAP__MASK;
+ 	}
+ 
+ 	*size += sizeof(struct cpu_map_data);
+ 	return zalloc(*size);
+ }
+ 
+ void cpu_map_data__synthesize(struct cpu_map_data *data, struct cpu_map *map,
+ 			      u16 type, int max)
+ {
+ 	data->type = type;
+ 
+ 	switch (type) {
+ 	case PERF_CPU_MAP__CPUS:
+ 		synthesize_cpus((struct cpu_map_entries *) data->data, map);
+ 		break;
+ 	case PERF_CPU_MAP__MASK:
+ 		synthesize_mask((struct cpu_map_mask *) data->data, map, max);
+ 	default:
+ 		break;
+ 	};
+ }
+ 
+ static struct cpu_map_event* cpu_map_event__new(struct cpu_map *map)
+ {
+ 	size_t size = sizeof(struct cpu_map_event);
+ 	struct cpu_map_event *event;
+ 	int max;
+ 	u16 type;
+ 
+ 	event = cpu_map_data__alloc(map, &size, &type, &max);
+ 	if (!event)
+ 		return NULL;
+ 
+ 	event->header.type = PERF_RECORD_CPU_MAP;
+ 	event->header.size = size;
+ 	event->data.type   = type;
+ 
+ 	cpu_map_data__synthesize(&event->data, map, type, max);
+ 	return event;
+ }
+ 
+ int perf_event__synthesize_cpu_map(struct perf_tool *tool,
+ 				   struct cpu_map *map,
+ 				   perf_event__handler_t process,
+ 				   struct machine *machine)
+ {
+ 	struct cpu_map_event *event;
+ 	int err;
+ 
+ 	event = cpu_map_event__new(map);
+ 	if (!event)
+ 		return -ENOMEM;
+ 
+ 	err = process(tool, (union perf_event *) event, NULL, machine);
+ 
+ 	free(event);
+ 	return err;
+ }
+ 
++>>>>>>> 6c872901af07 (perf cpu_map: Add cpu_map event synthesize function)
  size_t perf_event__fprintf_comm(union perf_event *event, FILE *fp)
  {
  	const char *s;
diff --cc tools/perf/util/event.h
index 9400ef1c1335,de18ee0e9c96..000000000000
--- a/tools/perf/util/event.h
+++ b/tools/perf/util/event.h
@@@ -386,10 -435,20 +387,23 @@@ typedef int (*perf_event__handler_t)(st
  int perf_event__synthesize_thread_map(struct perf_tool *tool,
  				      struct thread_map *threads,
  				      perf_event__handler_t process,
++<<<<<<< HEAD
 +				      struct machine *machine, bool mmap_data);
++=======
+ 				      struct machine *machine, bool mmap_data,
+ 				      unsigned int proc_map_timeout);
+ int perf_event__synthesize_thread_map2(struct perf_tool *tool,
+ 				      struct thread_map *threads,
+ 				      perf_event__handler_t process,
+ 				      struct machine *machine);
+ int perf_event__synthesize_cpu_map(struct perf_tool *tool,
+ 				   struct cpu_map *cpus,
+ 				   perf_event__handler_t process,
+ 				   struct machine *machine);
++>>>>>>> 6c872901af07 (perf cpu_map: Add cpu_map event synthesize function)
  int perf_event__synthesize_threads(struct perf_tool *tool,
  				   perf_event__handler_t process,
 -				   struct machine *machine, bool mmap_data,
 -				   unsigned int proc_map_timeout);
 +				   struct machine *machine, bool mmap_data);
  int perf_event__synthesize_kernel_mmap(struct perf_tool *tool,
  				       perf_event__handler_t process,
  				       struct machine *machine);
* Unmerged path tools/perf/tests/Build
* Unmerged path tools/perf/tests/builtin-test.c
diff --git a/tools/perf/tests/cpumap.c b/tools/perf/tests/cpumap.c
new file mode 100644
index 000000000000..715480558088
--- /dev/null
+++ b/tools/perf/tests/cpumap.c
@@ -0,0 +1,71 @@
+#include "tests.h"
+#include "cpumap.h"
+
+static int process_event_mask(struct perf_tool *tool __maybe_unused,
+			 union perf_event *event,
+			 struct perf_sample *sample __maybe_unused,
+			 struct machine *machine __maybe_unused)
+{
+	struct cpu_map_event *map = &event->cpu_map;
+	struct cpu_map_mask *mask;
+	struct cpu_map_data *data;
+	int i;
+
+	data = &map->data;
+
+	TEST_ASSERT_VAL("wrong type", data->type == PERF_CPU_MAP__MASK);
+
+	mask = (struct cpu_map_mask *)data->data;
+
+	TEST_ASSERT_VAL("wrong nr",   mask->nr == 1);
+
+	for (i = 0; i < 20; i++) {
+		TEST_ASSERT_VAL("wrong cpu", test_bit(i, mask->mask));
+	}
+
+	return 0;
+}
+
+static int process_event_cpus(struct perf_tool *tool __maybe_unused,
+			 union perf_event *event,
+			 struct perf_sample *sample __maybe_unused,
+			 struct machine *machine __maybe_unused)
+{
+	struct cpu_map_event *map = &event->cpu_map;
+	struct cpu_map_entries *cpus;
+	struct cpu_map_data *data;
+
+	data = &map->data;
+
+	TEST_ASSERT_VAL("wrong type", data->type == PERF_CPU_MAP__CPUS);
+
+	cpus = (struct cpu_map_entries *)data->data;
+
+	TEST_ASSERT_VAL("wrong nr",   cpus->nr == 2);
+	TEST_ASSERT_VAL("wrong cpu",  cpus->cpu[0] == 1);
+	TEST_ASSERT_VAL("wrong cpu",  cpus->cpu[1] == 256);
+	return 0;
+}
+
+
+int test__cpu_map_synthesize(int subtest __maybe_unused)
+{
+	struct cpu_map *cpus;
+
+	/* This one is better stores in mask. */
+	cpus = cpu_map__new("0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19");
+
+	TEST_ASSERT_VAL("failed to synthesize map",
+		!perf_event__synthesize_cpu_map(NULL, cpus, process_event_mask, NULL));
+
+	cpu_map__put(cpus);
+
+	/* This one is better stores in cpu values. */
+	cpus = cpu_map__new("1,256");
+
+	TEST_ASSERT_VAL("failed to synthesize map",
+		!perf_event__synthesize_cpu_map(NULL, cpus, process_event_cpus, NULL));
+
+	cpu_map__put(cpus);
+	return 0;
+}
* Unmerged path tools/perf/tests/tests.h
* Unmerged path tools/perf/util/event.c
* Unmerged path tools/perf/util/event.h
