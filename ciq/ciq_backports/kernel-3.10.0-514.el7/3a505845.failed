NFS: Enforce an upper limit on the number of cached access call

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Trond Myklebust <trond.myklebust@primarydata.com>
commit 3a505845cd58a7ff3bc75f96572045d8de34e34e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/3a505845.failed

This may be used to limit the number of cached credentials building up
inside the access cache.

	Signed-off-by: Trond Myklebust <trond.myklebust@primarydata.com>
(cherry picked from commit 3a505845cd58a7ff3bc75f96572045d8de34e34e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/nfs/dir.c
diff --cc fs/nfs/dir.c
index 97dbf163f302,7dc88bb4296c..000000000000
--- a/fs/nfs/dir.c
+++ b/fs/nfs/dir.c
@@@ -2104,18 -2052,14 +2108,28 @@@ static void nfs_access_free_list(struc
  	}
  }
  
++<<<<<<< HEAD
 +int nfs_access_cache_shrinker(struct shrinker *shrink,
 +			      struct shrink_control *sc)
++=======
+ static unsigned long
+ nfs_do_access_cache_scan(unsigned int nr_to_scan)
++>>>>>>> 3a505845cd58 (NFS: Enforce an upper limit on the number of cached access call)
  {
  	LIST_HEAD(head);
  	struct nfs_inode *nfsi, *next;
  	struct nfs_access_entry *cache;
++<<<<<<< HEAD
 +	int nr_to_scan = sc->nr_to_scan;
 +	gfp_t gfp_mask = sc->gfp_mask;
 +
 +	if ((gfp_mask & GFP_KERNEL) != GFP_KERNEL)
 +		return (nr_to_scan == 0) ? 0 : -1;
 +
++=======
+ 	long freed = 0;
+ 
++>>>>>>> 3a505845cd58 (NFS: Enforce an upper limit on the number of cached access call)
  	spin_lock(&nfs_access_lru_lock);
  	list_for_each_entry_safe(nfsi, next, &nfs_access_lru_list, access_cache_inode_lru) {
  		struct inode *inode;
@@@ -2144,7 -2089,41 +2158,45 @@@ remove_lru_entry
  	}
  	spin_unlock(&nfs_access_lru_lock);
  	nfs_access_free_list(&head);
++<<<<<<< HEAD
 +	return (atomic_long_read(&nfs_access_nr_entries) / 100) * sysctl_vfs_cache_pressure;
++=======
+ 	return freed;
+ }
+ 
+ unsigned long
+ nfs_access_cache_scan(struct shrinker *shrink, struct shrink_control *sc)
+ {
+ 	int nr_to_scan = sc->nr_to_scan;
+ 	gfp_t gfp_mask = sc->gfp_mask;
+ 
+ 	if ((gfp_mask & GFP_KERNEL) != GFP_KERNEL)
+ 		return SHRINK_STOP;
+ 	return nfs_do_access_cache_scan(nr_to_scan);
+ }
+ 
+ 
+ unsigned long
+ nfs_access_cache_count(struct shrinker *shrink, struct shrink_control *sc)
+ {
+ 	return vfs_pressure_ratio(atomic_long_read(&nfs_access_nr_entries));
++>>>>>>> 3a505845cd58 (NFS: Enforce an upper limit on the number of cached access call)
+ }
+ 
+ static void
+ nfs_access_cache_enforce_limit(void)
+ {
+ 	long nr_entries = atomic_long_read(&nfs_access_nr_entries);
+ 	unsigned long diff;
+ 	unsigned int nr_to_scan;
+ 
+ 	if (nr_entries < 0 || nr_entries <= nfs_access_max_cachesize)
+ 		return;
+ 	nr_to_scan = 100;
+ 	diff = nr_entries - nfs_access_max_cachesize;
+ 	if (diff < nr_to_scan)
+ 		nr_to_scan = diff;
+ 	nfs_do_access_cache_scan(nr_to_scan);
  }
  
  static void __nfs_access_zap_cache(struct nfs_inode *nfsi, struct list_head *head)
* Unmerged path fs/nfs/dir.c
