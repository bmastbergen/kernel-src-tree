crypto: qat - use list_for_each_entry*

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [crypto] qat - use list_for_each_entry* (Neil Horman) [1274179]
Rebuild_FUZZ: 88.24%
commit-author Geliang Tang <geliangtang@163.com>
commit dc2c632272d5614b77359b24f77c0a80ddc3a962
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/dc2c6322.failed

Use list_for_each_entry*() instead of list_for_each*() to simplify
the code.

	Signed-off-by: Geliang Tang <geliangtang@163.com>
	Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
(cherry picked from commit dc2c632272d5614b77359b24f77c0a80ddc3a962)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/crypto/qat/qat_common/qat_crypto.c
diff --cc drivers/crypto/qat/qat_common/qat_crypto.c
index b73551e286c4,3852d31ce0a4..000000000000
--- a/drivers/crypto/qat/qat_common/qat_crypto.c
+++ b/drivers/crypto/qat/qat_common/qat_crypto.c
@@@ -88,13 -86,7 +85,17 @@@ static int qat_crypto_free_instances(st
  		if (inst->pke_rx)
  			adf_remove_ring(inst->pke_rx);
  
++<<<<<<< HEAD
 +		if (inst->rnd_tx)
 +			adf_remove_ring(inst->rnd_tx);
 +
 +		if (inst->rnd_rx)
 +			adf_remove_ring(inst->rnd_rx);
 +
 +		list_del(list_ptr);
++=======
+ 		list_del(&inst->list);
++>>>>>>> dc2c632272d5 (crypto: qat - use list_for_each_entry*)
  		kfree(inst);
  	}
  	return 0;
@@@ -102,18 -94,23 +103,38 @@@
  
  struct qat_crypto_instance *qat_crypto_get_instance_node(int node)
  {
++<<<<<<< HEAD
 +	struct adf_accel_dev *accel_dev = NULL;
 +	struct qat_crypto_instance *inst_best = NULL;
 +	struct list_head *itr;
 +	unsigned long best = ~0;
 +
 +	list_for_each(itr, adf_devmgr_get_head()) {
 +		accel_dev = list_entry(itr, struct adf_accel_dev, list);
 +		if ((node == dev_to_node(&GET_DEV(accel_dev)) ||
 +		     dev_to_node(&GET_DEV(accel_dev)) < 0) &&
 +		    adf_dev_started(accel_dev))
 +			break;
 +		accel_dev = NULL;
++=======
+ 	struct adf_accel_dev *accel_dev = NULL, *tmp_dev;
+ 	struct qat_crypto_instance *inst = NULL, *tmp_inst;
+ 	unsigned long best = ~0;
+ 
+ 	list_for_each_entry(tmp_dev, adf_devmgr_get_head(), list) {
+ 		unsigned long ctr;
+ 
+ 		if ((node == dev_to_node(&GET_DEV(tmp_dev)) ||
+ 		     dev_to_node(&GET_DEV(tmp_dev)) < 0) &&
+ 		    adf_dev_started(tmp_dev) &&
+ 		    !list_empty(&tmp_dev->crypto_list)) {
+ 			ctr = atomic_read(&tmp_dev->ref_count);
+ 			if (best > ctr) {
+ 				accel_dev = tmp_dev;
+ 				best = ctr;
+ 			}
+ 		}
++>>>>>>> dc2c632272d5 (crypto: qat - use list_for_each_entry*)
  	}
  
  	if (!accel_dev) {
@@@ -134,30 -128,117 +152,41 @@@
  	if (!accel_dev)
  		return NULL;
  
++<<<<<<< HEAD
 +	list_for_each(itr, &accel_dev->crypto_list) {
 +		struct qat_crypto_instance *inst;
 +		unsigned long cur;
 +
 +		inst = list_entry(itr, struct qat_crypto_instance, list);
 +		cur = atomic_read(&inst->refctr);
 +		if (best > cur) {
 +			inst_best = inst;
 +			best = cur;
++=======
+ 	best = ~0;
+ 	list_for_each_entry(tmp_inst, &accel_dev->crypto_list, list) {
+ 		unsigned long ctr;
+ 
+ 		ctr = atomic_read(&tmp_inst->refctr);
+ 		if (best > ctr) {
+ 			inst = tmp_inst;
+ 			best = ctr;
++>>>>>>> dc2c632272d5 (crypto: qat - use list_for_each_entry*)
  		}
  	}
 -	if (inst) {
 -		if (adf_dev_get(accel_dev)) {
 -			dev_err(&GET_DEV(accel_dev), "Could not increment dev refctr\n");
 -			return NULL;
 +	if (inst_best) {
 +		if (atomic_add_return(1, &inst_best->refctr) == 1) {
 +			if (adf_dev_get(accel_dev)) {
 +				atomic_dec(&inst_best->refctr);
 +				dev_err(&GET_DEV(accel_dev),
 +					"Could not increment dev refctr\n");
 +				return NULL;
 +			}
  		}
 -		atomic_inc(&inst->refctr);
  	}
 -	return inst;
 +	return inst_best;
  }
  
 -/**
 - * qat_crypto_dev_config() - create dev config required to create crypto inst.
 - *
 - * @accel_dev: Pointer to acceleration device.
 - *
 - * Function creates device configuration required to create crypto instances
 - *
 - * Return: 0 on success, error code otherwise.
 - */
 -int qat_crypto_dev_config(struct adf_accel_dev *accel_dev)
 -{
 -	int cpus = num_online_cpus();
 -	int banks = GET_MAX_BANKS(accel_dev);
 -	int instances = min(cpus, banks);
 -	char key[ADF_CFG_MAX_KEY_LEN_IN_BYTES];
 -	int i;
 -	unsigned long val;
 -
 -	if (adf_cfg_section_add(accel_dev, ADF_KERNEL_SEC))
 -		goto err;
 -	if (adf_cfg_section_add(accel_dev, "Accelerator0"))
 -		goto err;
 -	for (i = 0; i < instances; i++) {
 -		val = i;
 -		snprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_BANK_NUM, i);
 -		if (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,
 -						key, (void *)&val, ADF_DEC))
 -			goto err;
 -
 -		snprintf(key, sizeof(key), ADF_CY "%d" ADF_ETRMGR_CORE_AFFINITY,
 -			 i);
 -		if (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,
 -						key, (void *)&val, ADF_DEC))
 -			goto err;
 -
 -		snprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_ASYM_SIZE, i);
 -		val = 128;
 -		if (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,
 -						key, (void *)&val, ADF_DEC))
 -			goto err;
 -
 -		val = 512;
 -		snprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_SYM_SIZE, i);
 -		if (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,
 -						key, (void *)&val, ADF_DEC))
 -			goto err;
 -
 -		val = 0;
 -		snprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_ASYM_TX, i);
 -		if (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,
 -						key, (void *)&val, ADF_DEC))
 -			goto err;
 -
 -		val = 2;
 -		snprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_SYM_TX, i);
 -		if (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,
 -						key, (void *)&val, ADF_DEC))
 -			goto err;
 -
 -		val = 8;
 -		snprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_ASYM_RX, i);
 -		if (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,
 -						key, (void *)&val, ADF_DEC))
 -			goto err;
 -
 -		val = 10;
 -		snprintf(key, sizeof(key), ADF_CY "%d" ADF_RING_SYM_RX, i);
 -		if (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,
 -						key, (void *)&val, ADF_DEC))
 -			goto err;
 -
 -		val = ADF_COALESCING_DEF_TIME;
 -		snprintf(key, sizeof(key), ADF_ETRMGR_COALESCE_TIMER_FORMAT, i);
 -		if (adf_cfg_add_key_value_param(accel_dev, "Accelerator0",
 -						key, (void *)&val, ADF_DEC))
 -			goto err;
 -	}
 -
 -	val = i;
 -	if (adf_cfg_add_key_value_param(accel_dev, ADF_KERNEL_SEC,
 -					ADF_NUM_CY, (void *)&val, ADF_DEC))
 -		goto err;
 -
 -	set_bit(ADF_STATUS_CONFIGURED, &accel_dev->status);
 -	return 0;
 -err:
 -	dev_err(&GET_DEV(accel_dev), "Failed to start QAT accel dev\n");
 -	return -EINVAL;
 -}
 -EXPORT_SYMBOL_GPL(qat_crypto_dev_config);
 -
  static int qat_crypto_create_instances(struct adf_accel_dev *accel_dev)
  {
  	int i;
diff --git a/drivers/crypto/qat/qat_common/adf_ctl_drv.c b/drivers/crypto/qat/qat_common/adf_ctl_drv.c
index 4ca0b2350316..33a25fd75ec5 100644
--- a/drivers/crypto/qat/qat_common/adf_ctl_drv.c
+++ b/drivers/crypto/qat/qat_common/adf_ctl_drv.c
@@ -255,12 +255,9 @@ out:
 
 static int adf_ctl_is_device_in_use(int id)
 {
-	struct list_head *itr, *head = adf_devmgr_get_head();
-
-	list_for_each(itr, head) {
-		struct adf_accel_dev *dev =
-				list_entry(itr, struct adf_accel_dev, list);
+	struct adf_accel_dev *dev;
 
+	list_for_each_entry(dev, adf_devmgr_get_head(), list) {
 		if (id == dev->accel_id || id == ADF_CFG_ALL_DEVICES) {
 			if (adf_devmgr_in_reset(dev) || adf_dev_in_use(dev)) {
 				dev_info(&GET_DEV(dev),
@@ -275,12 +272,10 @@ static int adf_ctl_is_device_in_use(int id)
 
 static int adf_ctl_stop_devices(uint32_t id)
 {
-	struct list_head *itr, *head = adf_devmgr_get_head();
+	struct adf_accel_dev *accel_dev;
 	int ret = 0;
 
-	list_for_each_prev(itr, head) {
-		struct adf_accel_dev *accel_dev =
-				list_entry(itr, struct adf_accel_dev, list);
+	list_for_each_entry_reverse(accel_dev, adf_devmgr_get_head(), list) {
 		if (id == accel_dev->accel_id || id == ADF_CFG_ALL_DEVICES) {
 			if (!adf_dev_started(accel_dev))
 				continue;
* Unmerged path drivers/crypto/qat/qat_common/qat_crypto.c
