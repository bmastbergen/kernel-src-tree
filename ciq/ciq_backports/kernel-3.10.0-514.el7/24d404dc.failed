mm: memcontrol: switch soft limit default back to infinity

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [mm] memcontrol: switch soft limit default back to infinity (Jerome Marchand) [1217771]
Rebuild_FUZZ: 96.43%
commit-author Johannes Weiner <hannes@cmpxchg.org>
commit 24d404dc10b903da271e943a0f6b032dcbd177d8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/24d404dc.failed

Commit 3e32cb2e0a12 ("mm: memcontrol: lockless page counters")
accidentally switched the soft limit default from infinity to zero,
which turns all memcgs with even a single page into soft limit excessors
and engages soft limit reclaim on all of them during global memory
pressure.  This makes global reclaim generally more aggressive, but also
inverts the meaning of existing soft limit configurations where unset
soft limits are usually more generous than set ones.

	Signed-off-by: Johannes Weiner <hannes@cmpxchg.org>
	Acked-by: Michal Hocko <mhocko@suse.cz>
	Acked-by: Vladimir Davydov <vdavydov@parallels.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 24d404dc10b903da271e943a0f6b032dcbd177d8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/memcontrol.c
diff --cc mm/memcontrol.c
index 12c52815fd8c,b7104a55ae64..000000000000
--- a/mm/memcontrol.c
+++ b/mm/memcontrol.c
@@@ -6255,11 -4676,12 +6255,18 @@@ mem_cgroup_css_alloc(struct cgroup *con
  			goto free_out;
  
  	/* root ? */
 -	if (parent_css == NULL) {
 +	if (cont->parent == NULL) {
  		root_mem_cgroup = memcg;
++<<<<<<< HEAD
 +		res_counter_init(&memcg->res, NULL);
 +		res_counter_init(&memcg->memsw, NULL);
 +		res_counter_init(&memcg->kmem, NULL);
++=======
+ 		page_counter_init(&memcg->memory, NULL);
+ 		memcg->soft_limit = PAGE_COUNTER_MAX;
+ 		page_counter_init(&memcg->memsw, NULL);
+ 		page_counter_init(&memcg->kmem, NULL);
++>>>>>>> 24d404dc10b9 (mm: memcontrol: switch soft limit default back to infinity)
  	}
  
  	memcg->last_scanned_node = MAX_NUMNODES;
@@@ -6295,69 -4724,93 +6302,90 @@@ mem_cgroup_css_online(struct cgroup *co
  	memcg->swappiness = mem_cgroup_swappiness(parent);
  
  	if (parent->use_hierarchy) {
++<<<<<<< HEAD
 +		res_counter_init(&memcg->res, &parent->res);
 +		res_counter_init(&memcg->memsw, &parent->memsw);
 +		res_counter_init(&memcg->kmem, &parent->kmem);
++=======
+ 		page_counter_init(&memcg->memory, &parent->memory);
+ 		memcg->soft_limit = PAGE_COUNTER_MAX;
+ 		page_counter_init(&memcg->memsw, &parent->memsw);
+ 		page_counter_init(&memcg->kmem, &parent->kmem);
++>>>>>>> 24d404dc10b9 (mm: memcontrol: switch soft limit default back to infinity)
  
  		/*
 -		 * No need to take a reference to the parent because cgroup
 -		 * core guarantees its existence.
 +		 * We increment refcnt of the parent to ensure that we can
 +		 * safely access it on res_counter_charge/uncharge.
 +		 * This refcnt will be decremented when freeing this
 +		 * mem_cgroup(see mem_cgroup_put).
  		 */
 +		mem_cgroup_get(parent);
  	} else {
++<<<<<<< HEAD
 +		res_counter_init(&memcg->res, NULL);
 +		res_counter_init(&memcg->memsw, NULL);
 +		res_counter_init(&memcg->kmem, NULL);
++=======
+ 		page_counter_init(&memcg->memory, NULL);
+ 		memcg->soft_limit = PAGE_COUNTER_MAX;
+ 		page_counter_init(&memcg->memsw, NULL);
+ 		page_counter_init(&memcg->kmem, NULL);
++>>>>>>> 24d404dc10b9 (mm: memcontrol: switch soft limit default back to infinity)
  		/*
  		 * Deeper hierachy with use_hierarchy == false doesn't make
  		 * much sense so let cgroup subsystem know about this
  		 * unfortunate state in our controller.
  		 */
  		if (parent != root_mem_cgroup)
 -			memory_cgrp_subsys.broken_hierarchy = true;
 +			mem_cgroup_subsys.broken_hierarchy = true;
  	}
 -	mutex_unlock(&memcg_create_mutex);
 -
 -	ret = memcg_init_kmem(memcg, &memory_cgrp_subsys);
 -	if (ret)
 -		return ret;
  
 -	/*
 -	 * Make sure the memcg is initialized: mem_cgroup_iter()
 -	 * orders reading memcg->initialized against its callers
 -	 * reading the memcg members.
 -	 */
 -	smp_store_release(&memcg->initialized, 1);
 -
 -	return 0;
 +	error = memcg_init_kmem(memcg, &mem_cgroup_subsys);
 +	mutex_unlock(&memcg_create_mutex);
 +	return error;
  }
  
 -static void mem_cgroup_css_offline(struct cgroup_subsys_state *css)
 +/*
 + * Announce all parents that a group from their hierarchy is gone.
 + */
 +static void mem_cgroup_invalidate_reclaim_iterators(struct mem_cgroup *memcg)
  {
 -	struct mem_cgroup *memcg = mem_cgroup_from_css(css);
 -	struct mem_cgroup_event *event, *tmp;
 +	struct mem_cgroup *parent = memcg;
 +
++<<<<<<< HEAD
 +	while ((parent = parent_mem_cgroup(parent)))
 +		atomic_inc(&parent->dead_count);
  
  	/*
 -	 * Unregister events and notify userspace.
 -	 * Notify userspace about cgroup removing only after rmdir of cgroup
 -	 * directory to avoid race between userspace and kernelspace.
 +	 * if the root memcg is not hierarchical we have to check it
 +	 * explicitely.
  	 */
 -	spin_lock(&memcg->event_list_lock);
 -	list_for_each_entry_safe(event, tmp, &memcg->event_list, list) {
 -		list_del_init(&event->list);
 -		schedule_work(&event->remove);
 -	}
 -	spin_unlock(&memcg->event_list_lock);
 -
 -	vmpressure_cleanup(&memcg->vmpressure);
 +	if (!root_mem_cgroup->use_hierarchy)
 +		atomic_inc(&root_mem_cgroup->dead_count);
  }
  
 -static void mem_cgroup_css_free(struct cgroup_subsys_state *css)
 +static void mem_cgroup_css_offline(struct cgroup *cont)
  {
 -	struct mem_cgroup *memcg = mem_cgroup_from_css(css);
 +	struct mem_cgroup *memcg = mem_cgroup_from_cont(cont);
  
 -	memcg_destroy_kmem(memcg);
 -	__mem_cgroup_free(memcg);
 +	mem_cgroup_invalidate_reclaim_iterators(memcg);
 +	mem_cgroup_reparent_charges(memcg);
 +	mem_cgroup_destroy_all_caches(memcg);
  }
  
 -/**
 - * mem_cgroup_css_reset - reset the states of a mem_cgroup
 - * @css: the target css
 - *
 - * Reset the states of the mem_cgroup associated with @css.  This is
 - * invoked when the userland requests disabling on the default hierarchy
 - * but the memcg is pinned through dependency.  The memcg should stop
 - * applying policies and should revert to the vanilla state as it may be
 - * made visible again.
 - *
 - * The current implementation only resets the essential configurations.
 - * This needs to be expanded to cover all the visible parts.
 - */
 -static void mem_cgroup_css_reset(struct cgroup_subsys_state *css)
 +static void mem_cgroup_css_free(struct cgroup *cont)
  {
 -	struct mem_cgroup *memcg = mem_cgroup_from_css(css);
 +	struct mem_cgroup *memcg = mem_cgroup_from_cont(cont);
 +
 +	kmem_cgroup_destroy(memcg);
  
 +	mem_cgroup_put(memcg);
++=======
+ 	mem_cgroup_resize_limit(memcg, PAGE_COUNTER_MAX);
+ 	mem_cgroup_resize_memsw_limit(memcg, PAGE_COUNTER_MAX);
+ 	memcg_update_kmem_limit(memcg, PAGE_COUNTER_MAX);
+ 	memcg->soft_limit = PAGE_COUNTER_MAX;
++>>>>>>> 24d404dc10b9 (mm: memcontrol: switch soft limit default back to infinity)
  }
  
  #ifdef CONFIG_MMU
* Unmerged path mm/memcontrol.c
