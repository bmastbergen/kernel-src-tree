openvswitch: do not ignore netdev errors when creating tunnel vports

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Martynas Pumputis <martynas@weave.works>
commit 4b5b9ba553f9aa5f484ab972fc9b58061885ceca
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/4b5b9ba5.failed

The creation of a tunnel vport (geneve, gre, vxlan) brings up a
corresponding netdev, a multi-step operation which can fail.

For example, changing a vxlan vport's netdev state to 'up' binds the
vport's socket to a UDP port - if the binding fails (e.g. due to the
port being in use), the error is currently ignored giving the
appearance that the tunnel vport creation completed successfully.

	Signed-off-by: Martynas Pumputis <martynas@weave.works>
	Acked-by: Pravin B Shelar <pshelar@ovn.org>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 4b5b9ba553f9aa5f484ab972fc9b58061885ceca)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/openvswitch/vport-geneve.c
#	net/openvswitch/vport-gre.c
#	net/openvswitch/vport-vxlan.c
diff --cc net/openvswitch/vport-geneve.c
index 1da3a14d1010,5aaf3babfc3f..000000000000
--- a/net/openvswitch/vport-geneve.c
+++ b/net/openvswitch/vport-geneve.c
@@@ -148,15 -83,25 +148,27 @@@ static struct vport *geneve_tnl_create(
  		return vport;
  
  	geneve_port = geneve_vport(vport);
 -	geneve_port->dst_port = dst_port;
 +	strncpy(geneve_port->name, parms->name, IFNAMSIZ);
  
 -	rtnl_lock();
 -	dev = geneve_dev_create_fb(net, parms->name, NET_NAME_USER, dst_port);
 -	if (IS_ERR(dev)) {
 -		rtnl_unlock();
 +	gs = geneve_sock_add(net, htons(dst_port), geneve_rcv, vport, true, 0);
 +	if (IS_ERR(gs)) {
  		ovs_vport_free(vport);
 -		return ERR_CAST(dev);
 +		return (void *)gs;
  	}
 +	geneve_port->gs = gs;
  
++<<<<<<< HEAD
++=======
+ 	err = dev_change_flags(dev, dev->flags | IFF_UP);
+ 	if (err < 0) {
+ 		rtnl_delete_link(dev);
+ 		rtnl_unlock();
+ 		ovs_vport_free(vport);
+ 		goto error;
+ 	}
+ 
+ 	rtnl_unlock();
++>>>>>>> 4b5b9ba553f9 (openvswitch: do not ignore netdev errors when creating tunnel vports)
  	return vport;
  error:
  	return ERR_PTR(err);
diff --cc net/openvswitch/vport-gre.c
index b87656c66aaf,0e72d95b0e8f..000000000000
--- a/net/openvswitch/vport-gre.c
+++ b/net/openvswitch/vport-gre.c
@@@ -48,190 -48,36 +48,204 @@@
  
  static struct vport_ops ovs_gre_vport_ops;
  
 -static struct vport *gre_tnl_create(const struct vport_parms *parms)
 +/* Returns the least-significant 32 bits of a __be64. */
 +static __be32 be64_get_low32(__be64 x)
  {
 -	struct net *net = ovs_dp_get_net(parms->dp);
 -	struct net_device *dev;
 +#ifdef __BIG_ENDIAN
 +	return (__force __be32)x;
 +#else
 +	return (__force __be32)((__force u64)x >> 32);
 +#endif
 +}
 +
 +static __be16 filter_tnl_flags(__be16 flags)
 +{
 +	return flags & (TUNNEL_CSUM | TUNNEL_KEY);
 +}
 +
 +static struct sk_buff *__build_header(struct sk_buff *skb,
 +				      int tunnel_hlen)
 +{
 +	struct tnl_ptk_info tpi;
 +	const struct ip_tunnel_key *tun_key;
 +
 +	tun_key = &OVS_CB(skb)->egress_tun_info->key;
 +
 +	skb = gre_handle_offloads(skb, !!(tun_key->tun_flags & TUNNEL_CSUM));
 +	if (IS_ERR(skb))
 +		return skb;
 +
 +	tpi.flags = filter_tnl_flags(tun_key->tun_flags);
 +	tpi.proto = htons(ETH_P_TEB);
 +	tpi.key = be64_get_low32(tun_key->tun_id);
 +	tpi.seq = 0;
 +	gre_build_header(skb, &tpi, tunnel_hlen);
 +
 +	return skb;
 +}
 +
 +static __be64 key_to_tunnel_id(__be32 key, __be32 seq)
 +{
 +#ifdef __BIG_ENDIAN
 +	return (__force __be64)((__force u64)seq << 32 | (__force u32)key);
 +#else
 +	return (__force __be64)((__force u64)key << 32 | (__force u32)seq);
 +#endif
 +}
 +
 +/* Called with rcu_read_lock and BH disabled. */
 +static int gre_rcv(struct sk_buff *skb,
 +		   const struct tnl_ptk_info *tpi)
 +{
 +	struct ip_tunnel_info tun_info;
 +	struct ovs_net *ovs_net;
 +	struct vport *vport;
 +	__be64 key;
 +
 +	ovs_net = net_generic(dev_net(skb->dev), ovs_net_id);
 +	vport = rcu_dereference(ovs_net->vport_net.gre_vport);
 +	if (unlikely(!vport))
 +		return PACKET_REJECT;
 +
 +	key = key_to_tunnel_id(tpi->key, tpi->seq);
 +	ip_tunnel_info_init(&tun_info, ip_hdr(skb), 0, 0, key,
 +			    filter_tnl_flags(tpi->flags), NULL, 0);
 +
 +	ovs_vport_receive(vport, skb, &tun_info);
 +	return PACKET_RCVD;
 +}
 +
 +/* Called with rcu_read_lock and BH disabled. */
 +static int gre_err(struct sk_buff *skb, u32 info,
 +		   const struct tnl_ptk_info *tpi)
 +{
 +	struct ovs_net *ovs_net;
  	struct vport *vport;
+ 	int err;
  
 -	vport = ovs_vport_alloc(0, &ovs_gre_vport_ops, parms);
 -	if (IS_ERR(vport))
 -		return vport;
 +	ovs_net = net_generic(dev_net(skb->dev), ovs_net_id);
 +	vport = rcu_dereference(ovs_net->vport_net.gre_vport);
  
 -	rtnl_lock();
 -	dev = gretap_fb_dev_create(net, parms->name, NET_NAME_USER);
 -	if (IS_ERR(dev)) {
 -		rtnl_unlock();
 -		ovs_vport_free(vport);
 -		return ERR_CAST(dev);
 +	if (unlikely(!vport))
 +		return PACKET_REJECT;
 +	else
 +		return PACKET_RCVD;
 +}
 +
 +static int gre_tnl_send(struct vport *vport, struct sk_buff *skb)
 +{
 +	struct net *net = ovs_dp_get_net(vport->dp);
 +	const struct ip_tunnel_key *tun_key;
 +	struct flowi4 fl;
 +	struct rtable *rt;
 +	int min_headroom;
 +	int tunnel_hlen;
 +	__be16 df;
 +	int err;
 +
 +	if (unlikely(!OVS_CB(skb)->egress_tun_info)) {
 +		err = -EINVAL;
 +		goto err_free_skb;
 +	}
 +
++<<<<<<< HEAD
 +	tun_key = &OVS_CB(skb)->egress_tun_info->key;
 +	rt = ovs_tunnel_route_lookup(net, tun_key, skb->mark, &fl, IPPROTO_GRE);
 +	if (IS_ERR(rt)) {
 +		err = PTR_ERR(rt);
 +		goto err_free_skb;
 +	}
 +
 +	tunnel_hlen = ip_gre_calc_hlen(tun_key->tun_flags);
 +
 +	min_headroom = LL_RESERVED_SPACE(rt->dst.dev) + rt->dst.header_len
 +			+ tunnel_hlen + sizeof(struct iphdr)
 +			+ (skb_vlan_tag_present(skb) ? VLAN_HLEN : 0);
 +	if (skb_headroom(skb) < min_headroom || skb_header_cloned(skb)) {
 +		int head_delta = SKB_DATA_ALIGN(min_headroom -
 +						skb_headroom(skb) +
 +						16);
 +		err = pskb_expand_head(skb, max_t(int, head_delta, 0),
 +					0, GFP_ATOMIC);
 +		if (unlikely(err))
 +			goto err_free_rt;
 +	}
 +
 +	skb = vlan_hwaccel_push_inside(skb);
 +	if (unlikely(!skb)) {
 +		err = -ENOMEM;
 +		goto err_free_rt;
 +	}
 +
 +	/* Push Tunnel header. */
 +	skb = __build_header(skb, tunnel_hlen);
 +	if (IS_ERR(skb)) {
 +		err = PTR_ERR(skb);
 +		skb = NULL;
 +		goto err_free_rt;
  	}
  
 +	df = tun_key->tun_flags & TUNNEL_DONT_FRAGMENT ?
 +		htons(IP_DF) : 0;
 +
 +	skb->ignore_df = 1;
 +
 +	return iptunnel_xmit(skb->sk, rt, skb, fl.saddr,
 +			     tun_key->ipv4_dst, IPPROTO_GRE,
 +			     tun_key->ipv4_tos, tun_key->ipv4_ttl, df, false);
 +err_free_rt:
 +	ip_rt_put(rt);
 +err_free_skb:
 +	kfree_skb(skb);
 +	return err;
 +}
 +
 +static struct gre_cisco_protocol gre_protocol = {
 +	.handler        = gre_rcv,
 +	.err_handler    = gre_err,
 +	.priority       = 1,
 +};
 +
 +static int gre_ports;
 +static int gre_init(void)
 +{
 +	int err;
 +
 +	gre_ports++;
 +	if (gre_ports > 1)
 +		return 0;
 +
 +	err = gre_cisco_register(&gre_protocol);
 +	if (err)
 +		pr_warn("cannot register gre protocol handler\n");
 +
 +	return err;
 +}
 +
 +static void gre_exit(void)
 +{
 +	gre_ports--;
 +	if (gre_ports > 0)
 +		return;
 +
 +	gre_cisco_unregister(&gre_protocol);
 +}
 +
 +static const char *gre_get_name(const struct vport *vport)
 +{
 +	return vport_priv(vport);
++=======
+ 	err = dev_change_flags(dev, dev->flags | IFF_UP);
+ 	if (err < 0) {
+ 		rtnl_delete_link(dev);
+ 		rtnl_unlock();
+ 		ovs_vport_free(vport);
+ 		return ERR_PTR(err);
+ 	}
+ 
+ 	rtnl_unlock();
+ 	return vport;
++>>>>>>> 4b5b9ba553f9 (openvswitch: do not ignore netdev errors when creating tunnel vports)
  }
  
  static struct vport *gre_create(const struct vport_parms *parms)
diff --cc net/openvswitch/vport-vxlan.c
index 6f7986fabb70,7eb955e453e6..000000000000
--- a/net/openvswitch/vport-vxlan.c
+++ b/net/openvswitch/vport-vxlan.c
@@@ -189,16 -122,24 +189,28 @@@ static struct vport *vxlan_tnl_create(c
  		}
  	}
  
 -	rtnl_lock();
 -	dev = vxlan_dev_create(net, parms->name, NET_NAME_USER, &conf);
 -	if (IS_ERR(dev)) {
 -		rtnl_unlock();
 +	vs = vxlan_sock_add(net, htons(dst_port), vxlan_rcv, vport, true,
 +			    vxlan_port->exts);
 +	if (IS_ERR(vs)) {
  		ovs_vport_free(vport);
 -		return ERR_CAST(dev);
 +		return (void *)vs;
  	}
 +	vxlan_port->vs = vs;
  
++<<<<<<< HEAD
++=======
+ 	err = dev_change_flags(dev, dev->flags | IFF_UP);
+ 	if (err < 0) {
+ 		rtnl_delete_link(dev);
+ 		rtnl_unlock();
+ 		ovs_vport_free(vport);
+ 		goto error;
+ 	}
+ 
+ 	rtnl_unlock();
++>>>>>>> 4b5b9ba553f9 (openvswitch: do not ignore netdev errors when creating tunnel vports)
  	return vport;
 +
  error:
  	return ERR_PTR(err);
  }
* Unmerged path net/openvswitch/vport-geneve.c
* Unmerged path net/openvswitch/vport-gre.c
* Unmerged path net/openvswitch/vport-vxlan.c
