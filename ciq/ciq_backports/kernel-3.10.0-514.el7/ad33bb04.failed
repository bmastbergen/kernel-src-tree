mm: thp: fix SMP race condition between THP page fault and MADV_DONTNEED

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [mm] thp: fix SMP race condition between THP page fault and MADV_DONTNEED (Andrea Arcangeli) [1314132]
Rebuild_FUZZ: 97.14%
commit-author Andrea Arcangeli <aarcange@redhat.com>
commit ad33bb04b2a6cee6c1f99fabb15cddbf93ff0433
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/ad33bb04.failed

pmd_trans_unstable()/pmd_none_or_trans_huge_or_clear_bad() were
introduced to locklessy (but atomically) detect when a pmd is a regular
(stable) pmd or when the pmd is unstable and can infinitely transition
from pmd_none() and pmd_trans_huge() from under us, while only holding
the mmap_sem for reading (for writing not).

While holding the mmap_sem only for reading, MADV_DONTNEED can run from
under us and so before we can assume the pmd to be a regular stable pmd
we need to compare it against pmd_none() and pmd_trans_huge() in an
atomic way, with pmd_trans_unstable().  The old pmd_trans_huge() left a
tiny window for a race.

Useful applications are unlikely to notice the difference as doing
MADV_DONTNEED concurrently with a page fault would lead to undefined
behavior.

[akpm@linux-foundation.org: tidy up comment grammar/layout]
	Signed-off-by: Andrea Arcangeli <aarcange@redhat.com>
	Reported-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
	Cc: <stable@vger.kernel.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit ad33bb04b2a6cee6c1f99fabb15cddbf93ff0433)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/memory.c
diff --cc mm/memory.c
index fce51319197b,8132787ae4d5..000000000000
--- a/mm/memory.c
+++ b/mm/memory.c
@@@ -3979,8 -3404,18 +3979,23 @@@ static int __handle_mm_fault(struct mm_
  	if (unlikely(pmd_none(*pmd)) &&
  	    unlikely(__pte_alloc(mm, vma, pmd, address)))
  		return VM_FAULT_OOM;
++<<<<<<< HEAD
 +	/* if an huge pmd materialized from under us just retry later */
 +	if (unlikely(pmd_trans_huge(*pmd)))
++=======
+ 	/*
+ 	 * If a huge pmd materialized under us just retry later.  Use
+ 	 * pmd_trans_unstable() instead of pmd_trans_huge() to ensure the pmd
+ 	 * didn't become pmd_trans_huge under us and then back to pmd_none, as
+ 	 * a result of MADV_DONTNEED running immediately after a huge pmd fault
+ 	 * in a different thread of this mm, in turn leading to a misleading
+ 	 * pmd_trans_huge() retval.  All we have to ensure is that it is a
+ 	 * regular pmd that we can walk with pte_offset_map() and we can do that
+ 	 * through an atomic read in C, which is what pmd_trans_unstable()
+ 	 * provides.
+ 	 */
+ 	if (unlikely(pmd_trans_unstable(pmd) || pmd_devmap(*pmd)))
++>>>>>>> ad33bb04b2a6 (mm: thp: fix SMP race condition between THP page fault and MADV_DONTNEED)
  		return 0;
  	/*
  	 * A regular pmd is established and it can't morph into a huge pmd
* Unmerged path mm/memory.c
