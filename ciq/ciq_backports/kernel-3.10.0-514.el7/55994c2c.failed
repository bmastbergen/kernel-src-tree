drm/i915/gen9: Propagate watermark calculation failures up the call chain

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Matt Roper <matthew.d.roper@intel.com>
commit 55994c2c38a1101f84cdf277b228f830af8a9c1b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/55994c2c.failed

Once we move watermark calculation to the atomic check phase, we'll want
to start rejecting display configurations that exceed out watermark
limits.  At the moment we just assume that there's always a valid set of
watermarks, even though this may not actually be true.  Let's prepare by
passing return codes up through the call stack in preparation.

	Signed-off-by: Matt Roper <matthew.d.roper@intel.com>
	Reviewed-by: Maarten Lankhorst <maarten.lankhorst@linux.intel.com>
Link: http://patchwork.freedesktop.org/patch/msgid/1463061971-19638-15-git-send-email-matthew.d.roper@intel.com
(cherry picked from commit 55994c2c38a1101f84cdf277b228f830af8a9c1b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/i915/intel_display.c
#	drivers/gpu/drm/i915/intel_pm.c
diff --cc drivers/gpu/drm/i915/intel_display.c
index e2e955a9df5d,94804d992cd1..000000000000
--- a/drivers/gpu/drm/i915/intel_display.c
+++ b/drivers/gpu/drm/i915/intel_display.c
@@@ -11632,691 -13282,511 +11632,1040 @@@ static int __intel_set_mode(struct drm_
  	 * mode set on this crtc.  For other crtcs we need to use the
  	 * adjusted_mode bits in the crtc directly.
  	 */
 -	if (dev_priv->display.modeset_calc_cdclk) {
 -		ret = dev_priv->display.modeset_calc_cdclk(state);
 +	if (IS_VALLEYVIEW(dev)) {
 +		valleyview_modeset_global_pipes(dev, &prepare_pipes);
  
 -		if (!ret && intel_state->dev_cdclk != dev_priv->cdclk_freq)
 -			ret = intel_modeset_all_pipes(state);
 +		/* may have added more to prepare_pipes than we should */
 +		prepare_pipes &= ~disable_pipes;
 +	}
  
 -		if (ret < 0)
 -			return ret;
 +	ret = __intel_set_mode_setup_plls(dev, modeset_pipes, disable_pipes);
 +	if (ret)
 +		goto done;
  
 -		DRM_DEBUG_KMS("New cdclk calculated to be atomic %u, actual %u\n",
 -			      intel_state->cdclk, intel_state->dev_cdclk);
 -	} else
 -		to_intel_atomic_state(state)->cdclk = dev_priv->atomic_cdclk_freq;
 +	for_each_intel_crtc_masked(dev, disable_pipes, intel_crtc)
 +		intel_crtc_disable(&intel_crtc->base);
  
 -	intel_modeset_clear_plls(state);
 +	for_each_intel_crtc_masked(dev, prepare_pipes, intel_crtc) {
 +		if (intel_crtc->base.state->enable)
 +			dev_priv->display.crtc_disable(&intel_crtc->base);
 +	}
  
++<<<<<<< HEAD
 +	/* crtc->mode is already used by the ->mode_set callbacks, hence we need
 +	 * to set it here already despite that we pass it down the callchain.
 +	 *
 +	 * Note we'll need to fix this up when we start tracking multiple
 +	 * pipes; here we assume a single modeset_pipe and only track the
 +	 * single crtc and mode.
++=======
+ 	if (IS_HASWELL(dev_priv))
+ 		return haswell_mode_set_planes_workaround(state);
+ 
+ 	return 0;
+ }
+ 
+ /*
+  * Handle calculation of various watermark data at the end of the atomic check
+  * phase.  The code here should be run after the per-crtc and per-plane 'check'
+  * handlers to ensure that all derived state has been updated.
+  */
+ static int calc_watermark_data(struct drm_atomic_state *state)
+ {
+ 	struct drm_device *dev = state->dev;
+ 	struct drm_i915_private *dev_priv = to_i915(dev);
+ 	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
+ 	struct drm_crtc *crtc;
+ 	struct drm_crtc_state *cstate;
+ 	struct drm_plane *plane;
+ 	struct drm_plane_state *pstate;
+ 
+ 	/*
+ 	 * Calculate watermark configuration details now that derived
+ 	 * plane/crtc state is all properly updated.
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
  	 */
 -	drm_for_each_crtc(crtc, dev) {
 -		cstate = drm_atomic_get_existing_crtc_state(state, crtc) ?:
 -			crtc->state;
 +	if (modeset_pipes) {
 +		crtc->mode = *mode;
 +		/* mode_set/enable/disable functions rely on a correct pipe
 +		 * config. */
 +		intel_crtc_set_state(to_intel_crtc(crtc), pipe_config);
  
++<<<<<<< HEAD
 +		/*
 +		 * Calculate and store various constants which
 +		 * are later needed by vblank and swap-completion
 +		 * timestamping. They are derived from true hwmode.
 +		 */
 +		drm_calc_timestamping_constants(crtc,
 +						&pipe_config->base.adjusted_mode);
++=======
+ 		if (cstate->active)
+ 			intel_state->wm_config.num_pipes_active++;
+ 	}
+ 	drm_for_each_legacy_plane(plane, dev) {
+ 		pstate = drm_atomic_get_existing_plane_state(state, plane) ?:
+ 			plane->state;
+ 
+ 		if (!to_intel_plane_state(pstate)->visible)
+ 			continue;
+ 
+ 		intel_state->wm_config.sprites_enabled = true;
+ 		if (pstate->crtc_w != pstate->src_w >> 16 ||
+ 		    pstate->crtc_h != pstate->src_h >> 16)
+ 			intel_state->wm_config.sprites_scaled = true;
+ 	}
+ 
+ 	/* Is there platform-specific watermark information to calculate? */
+ 	if (dev_priv->display.compute_global_watermarks)
+ 		return dev_priv->display.compute_global_watermarks(state);
+ 
+ 	return 0;
+ }
+ 
+ /**
+  * intel_atomic_check - validate state object
+  * @dev: drm device
+  * @state: state to validate
+  */
+ static int intel_atomic_check(struct drm_device *dev,
+ 			      struct drm_atomic_state *state)
+ {
+ 	struct drm_i915_private *dev_priv = to_i915(dev);
+ 	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
+ 	struct drm_crtc *crtc;
+ 	struct drm_crtc_state *crtc_state;
+ 	int ret, i;
+ 	bool any_ms = false;
+ 
+ 	ret = drm_atomic_helper_check_modeset(dev, state);
+ 	if (ret)
+ 		return ret;
+ 
+ 	for_each_crtc_in_state(state, crtc, crtc_state, i) {
+ 		struct intel_crtc_state *pipe_config =
+ 			to_intel_crtc_state(crtc_state);
+ 
+ 		/* Catch I915_MODE_FLAG_INHERITED */
+ 		if (crtc_state->mode.private_flags != crtc->state->mode.private_flags)
+ 			crtc_state->mode_changed = true;
+ 
+ 		if (!crtc_state->enable) {
+ 			if (needs_modeset(crtc_state))
+ 				any_ms = true;
+ 			continue;
+ 		}
+ 
+ 		if (!needs_modeset(crtc_state))
+ 			continue;
+ 
+ 		/* FIXME: For only active_changed we shouldn't need to do any
+ 		 * state recomputation at all. */
+ 
+ 		ret = drm_atomic_add_affected_connectors(state, crtc);
+ 		if (ret)
+ 			return ret;
+ 
+ 		ret = intel_modeset_pipe_config(crtc, pipe_config);
+ 		if (ret) {
+ 			intel_dump_pipe_config(to_intel_crtc(crtc),
+ 					       pipe_config, "[failed]");
+ 			return ret;
+ 		}
+ 
+ 		if (i915.fastboot &&
+ 		    intel_pipe_config_compare(dev,
+ 					to_intel_crtc_state(crtc->state),
+ 					pipe_config, true)) {
+ 			crtc_state->mode_changed = false;
+ 			to_intel_crtc_state(crtc_state)->update_pipe = true;
+ 		}
+ 
+ 		if (needs_modeset(crtc_state)) {
+ 			any_ms = true;
+ 
+ 			ret = drm_atomic_add_affected_planes(state, crtc);
+ 			if (ret)
+ 				return ret;
+ 		}
+ 
+ 		intel_dump_pipe_config(to_intel_crtc(crtc), pipe_config,
+ 				       needs_modeset(crtc_state) ?
+ 				       "[modeset]" : "[fastset]");
+ 	}
+ 
+ 	if (any_ms) {
+ 		ret = intel_modeset_checks(state);
+ 
+ 		if (ret)
+ 			return ret;
+ 	} else
+ 		intel_state->cdclk = dev_priv->cdclk_freq;
+ 
+ 	ret = drm_atomic_helper_check_planes(dev, state);
+ 	if (ret)
+ 		return ret;
+ 
+ 	intel_fbc_choose_crtc(dev_priv, state);
+ 	return calc_watermark_data(state);
+ }
+ 
+ static int intel_atomic_prepare_commit(struct drm_device *dev,
+ 				       struct drm_atomic_state *state,
+ 				       bool async)
+ {
+ 	struct drm_i915_private *dev_priv = dev->dev_private;
+ 	struct drm_plane_state *plane_state;
+ 	struct drm_crtc_state *crtc_state;
+ 	struct drm_plane *plane;
+ 	struct drm_crtc *crtc;
+ 	int i, ret;
+ 
+ 	if (async) {
+ 		DRM_DEBUG_KMS("i915 does not yet support async commit\n");
+ 		return -EINVAL;
+ 	}
+ 
+ 	for_each_crtc_in_state(state, crtc, crtc_state, i) {
+ 		if (state->legacy_cursor_update)
+ 			continue;
+ 
+ 		ret = intel_crtc_wait_for_pending_flips(crtc);
+ 		if (ret)
+ 			return ret;
+ 
+ 		if (atomic_read(&to_intel_crtc(crtc)->unpin_work_count) >= 2)
+ 			flush_workqueue(dev_priv->wq);
+ 	}
+ 
+ 	ret = mutex_lock_interruptible(&dev->struct_mutex);
+ 	if (ret)
+ 		return ret;
+ 
+ 	ret = drm_atomic_helper_prepare_planes(dev, state);
+ 	mutex_unlock(&dev->struct_mutex);
+ 
+ 	if (!ret && !async) {
+ 		for_each_plane_in_state(state, plane, plane_state, i) {
+ 			struct intel_plane_state *intel_plane_state =
+ 				to_intel_plane_state(plane_state);
+ 
+ 			if (!intel_plane_state->wait_req)
+ 				continue;
+ 
+ 			ret = __i915_wait_request(intel_plane_state->wait_req,
+ 						  true, NULL, NULL);
+ 			if (ret) {
+ 				/* Any hang should be swallowed by the wait */
+ 				WARN_ON(ret == -EIO);
+ 				mutex_lock(&dev->struct_mutex);
+ 				drm_atomic_helper_cleanup_planes(dev, state);
+ 				mutex_unlock(&dev->struct_mutex);
+ 				break;
+ 			}
+ 		}
+ 	}
+ 
+ 	return ret;
+ }
+ 
+ static void intel_atomic_wait_for_vblanks(struct drm_device *dev,
+ 					  struct drm_i915_private *dev_priv,
+ 					  unsigned crtc_mask)
+ {
+ 	unsigned last_vblank_count[I915_MAX_PIPES];
+ 	enum pipe pipe;
+ 	int ret;
+ 
+ 	if (!crtc_mask)
+ 		return;
+ 
+ 	for_each_pipe(dev_priv, pipe) {
+ 		struct drm_crtc *crtc = dev_priv->pipe_to_crtc_mapping[pipe];
+ 
+ 		if (!((1 << pipe) & crtc_mask))
+ 			continue;
+ 
+ 		ret = drm_crtc_vblank_get(crtc);
+ 		if (WARN_ON(ret != 0)) {
+ 			crtc_mask &= ~(1 << pipe);
+ 			continue;
+ 		}
+ 
+ 		last_vblank_count[pipe] = drm_crtc_vblank_count(crtc);
+ 	}
+ 
+ 	for_each_pipe(dev_priv, pipe) {
+ 		struct drm_crtc *crtc = dev_priv->pipe_to_crtc_mapping[pipe];
+ 		long lret;
+ 
+ 		if (!((1 << pipe) & crtc_mask))
+ 			continue;
+ 
+ 		lret = wait_event_timeout(dev->vblank[pipe].queue,
+ 				last_vblank_count[pipe] !=
+ 					drm_crtc_vblank_count(crtc),
+ 				msecs_to_jiffies(50));
+ 
+ 		WARN(!lret, "pipe %c vblank wait timed out\n", pipe_name(pipe));
+ 
+ 		drm_crtc_vblank_put(crtc);
+ 	}
+ }
+ 
+ static bool needs_vblank_wait(struct intel_crtc_state *crtc_state)
+ {
+ 	/* fb updated, need to unpin old fb */
+ 	if (crtc_state->fb_changed)
+ 		return true;
+ 
+ 	/* wm changes, need vblank before final wm's */
+ 	if (crtc_state->update_wm_post)
+ 		return true;
+ 
+ 	/*
+ 	 * cxsr is re-enabled after vblank.
+ 	 * This is already handled by crtc_state->update_wm_post,
+ 	 * but added for clarity.
+ 	 */
+ 	if (crtc_state->disable_cxsr)
+ 		return true;
+ 
+ 	return false;
+ }
+ 
+ /**
+  * intel_atomic_commit - commit validated state object
+  * @dev: DRM device
+  * @state: the top-level driver state object
+  * @async: asynchronous commit
+  *
+  * This function commits a top-level state object that has been validated
+  * with drm_atomic_helper_check().
+  *
+  * FIXME:  Atomic modeset support for i915 is not yet complete.  At the moment
+  * we can only handle plane-related operations and do not yet support
+  * asynchronous commit.
+  *
+  * RETURNS
+  * Zero for success or -errno.
+  */
+ static int intel_atomic_commit(struct drm_device *dev,
+ 			       struct drm_atomic_state *state,
+ 			       bool async)
+ {
+ 	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
+ 	struct drm_i915_private *dev_priv = dev->dev_private;
+ 	struct drm_crtc_state *old_crtc_state;
+ 	struct drm_crtc *crtc;
+ 	struct intel_crtc_state *intel_cstate;
+ 	int ret = 0, i;
+ 	bool hw_check = intel_state->modeset;
+ 	unsigned long put_domains[I915_MAX_PIPES] = {};
+ 	unsigned crtc_vblank_mask = 0;
+ 
+ 	ret = intel_atomic_prepare_commit(dev, state, async);
+ 	if (ret) {
+ 		DRM_DEBUG_ATOMIC("Preparing state failed with %i\n", ret);
+ 		return ret;
+ 	}
+ 
+ 	drm_atomic_helper_swap_state(dev, state);
+ 	dev_priv->wm.config = intel_state->wm_config;
+ 	dev_priv->wm.distrust_bios_wm = false;
+ 	dev_priv->wm.skl_results.ddb = intel_state->ddb;
+ 	intel_shared_dpll_commit(state);
+ 
+ 	if (intel_state->modeset) {
+ 		memcpy(dev_priv->min_pixclk, intel_state->min_pixclk,
+ 		       sizeof(intel_state->min_pixclk));
+ 		dev_priv->active_crtcs = intel_state->active_crtcs;
+ 		dev_priv->atomic_cdclk_freq = intel_state->cdclk;
+ 
+ 		intel_display_power_get(dev_priv, POWER_DOMAIN_MODESET);
+ 	}
+ 
+ 	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
+ 		struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
+ 
+ 		if (needs_modeset(crtc->state) ||
+ 		    to_intel_crtc_state(crtc->state)->update_pipe) {
+ 			hw_check = true;
+ 
 -			put_domains[to_intel_crtc(crtc)->pipe] =
 -				modeset_get_crtc_power_domains(crtc,
 -					to_intel_crtc_state(crtc->state));
 -		}
++			put_domains[to_intel_crtc(crtc)->pipe] =
++				modeset_get_crtc_power_domains(crtc,
++					to_intel_crtc_state(crtc->state));
++		}
++
++		if (!needs_modeset(crtc->state))
++			continue;
++
++		intel_pre_plane_update(to_intel_crtc_state(old_crtc_state));
++
++		if (old_crtc_state->active) {
++			intel_crtc_disable_planes(crtc, old_crtc_state->plane_mask);
++			dev_priv->display.crtc_disable(crtc);
++			intel_crtc->active = false;
++			intel_fbc_disable(intel_crtc);
++			intel_disable_shared_dpll(intel_crtc);
++
++			/*
++			 * Underruns don't always raise
++			 * interrupts, so check manually.
++			 */
++			intel_check_cpu_fifo_underruns(dev_priv);
++			intel_check_pch_fifo_underruns(dev_priv);
++
++			if (!crtc->state->active)
++				intel_update_watermarks(crtc);
++		}
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
 +	}
 +
 +	/* Only after disabling all output pipelines that will be changed can we
 +	 * update the the output configuration. */
 +	intel_modeset_update_state(dev, prepare_pipes);
 +
 +	modeset_update_crtc_power_domains(pipe_config->base.state);
 +
 +	/* Set up the DPLL and any encoders state that needs to adjust or depend
 +	 * on the DPLL.
 +	 */
 +	for_each_intel_crtc_masked(dev, modeset_pipes, intel_crtc) {
 +		struct drm_plane *primary = intel_crtc->base.primary;
 +		int vdisplay, hdisplay;
 +
 +		drm_crtc_get_hv_timing(mode, &hdisplay, &vdisplay);
 +		ret = primary->funcs->update_plane(primary, &intel_crtc->base,
 +						   fb, 0, 0,
 +						   hdisplay, vdisplay,
 +						   x << 16, y << 16,
 +						   hdisplay << 16, vdisplay << 16);
 +	}
 +
 +	/* Now enable the clocks, plane, pipe, and connectors that we set up. */
 +	for_each_intel_crtc_masked(dev, prepare_pipes, intel_crtc) {
 +		update_scanline_offset(intel_crtc);
 +
 +		dev_priv->display.crtc_enable(&intel_crtc->base);
 +	}
 +
 +	/* FIXME: add subpixel order */
 +done:
 +	if (ret && crtc->state->enable)
 +		crtc->mode = *saved_mode;
 +
 +	if (ret == 0 && pipe_config) {
 +		struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 +
 +		/* The pipe_config will be freed with the atomic state, so
 +		 * make a copy. */
 +		memcpy(crtc_state_copy, intel_crtc->config,
 +		       sizeof *crtc_state_copy);
 +		intel_crtc->config = crtc_state_copy;
 +		intel_crtc->base.state = &crtc_state_copy->base;
 +
 +		if (modeset_pipes)
 +			intel_crtc->new_config = intel_crtc->config;
 +	} else {
 +		kfree(crtc_state_copy);
 +	}
 +
 +	kfree(saved_mode);
 +	return ret;
 +}
 +
 +static int intel_set_mode_pipes(struct drm_crtc *crtc,
 +				struct drm_display_mode *mode,
 +				int x, int y, struct drm_framebuffer *fb,
 +				struct intel_crtc_state *pipe_config,
 +				unsigned modeset_pipes,
 +				unsigned prepare_pipes,
 +				unsigned disable_pipes)
 +{
 +	int ret;
 +
 +	ret = __intel_set_mode(crtc, mode, x, y, fb, pipe_config, modeset_pipes,
 +			       prepare_pipes, disable_pipes);
 +
 +	if (ret == 0)
 +		intel_modeset_check_state(crtc->dev);
 +
 +	return ret;
 +}
 +
 +static int intel_set_mode(struct drm_crtc *crtc,
 +			  struct drm_display_mode *mode,
 +			  int x, int y, struct drm_framebuffer *fb,
 +			  struct drm_atomic_state *state)
 +{
 +	struct intel_crtc_state *pipe_config;
 +	unsigned modeset_pipes, prepare_pipes, disable_pipes;
 +	int ret = 0;
 +
 +	pipe_config = intel_modeset_compute_config(crtc, mode, fb, state,
 +						   &modeset_pipes,
 +						   &prepare_pipes,
 +						   &disable_pipes);
 +
 +	if (IS_ERR(pipe_config)) {
 +		ret = PTR_ERR(pipe_config);
 +		goto out;
 +	}
 +
 +	ret = intel_set_mode_pipes(crtc, mode, x, y, fb, pipe_config,
 +				   modeset_pipes, prepare_pipes,
 +				   disable_pipes);
 +	if (ret)
 +		goto out;
 +
 +out:
 +	return ret;
 +}
 +
 +void intel_crtc_restore_mode(struct drm_crtc *crtc)
 +{
 +	struct drm_device *dev = crtc->dev;
 +	struct drm_atomic_state *state;
 +	struct intel_encoder *encoder;
 +	struct intel_connector *connector;
 +	struct drm_connector_state *connector_state;
 +
 +	state = drm_atomic_state_alloc(dev);
 +	if (!state) {
 +		DRM_DEBUG_KMS("[CRTC:%d] mode restore failed, out of memory",
 +			      crtc->base.id);
 +		return;
 +	}
 +
 +	state->acquire_ctx = dev->mode_config.acquire_ctx;
 +
 +	/* The force restore path in the HW readout code relies on the staged
 +	 * config still keeping the user requested config while the actual
 +	 * state has been overwritten by the configuration read from HW. We
 +	 * need to copy the staged config to the atomic state, otherwise the
 +	 * mode set will just reapply the state the HW is already in. */
 +	for_each_intel_encoder(dev, encoder) {
 +		if (&encoder->new_crtc->base != crtc)
 +			continue;
 +
 +		for_each_intel_connector(dev, connector) {
 +			if (connector->new_encoder != encoder)
 +				continue;
 +
 +			connector_state = drm_atomic_get_connector_state(state, &connector->base);
 +			if (IS_ERR(connector_state)) {
 +				DRM_DEBUG_KMS("Failed to add [CONNECTOR:%d:%s] to state: %ld\n",
 +					      connector->base.base.id,
 +					      connector->base.name,
 +					      PTR_ERR(connector_state));
 +				continue;
 +			}
 +
 +			connector_state->crtc = crtc;
 +			connector_state->best_encoder = &encoder->base;
 +		}
 +	}
 +
 +	intel_set_mode(crtc, &crtc->mode, crtc->x, crtc->y, crtc->primary->fb,
 +		       state);
 +
 +	drm_atomic_state_free(state);
 +}
 +
 +#undef for_each_intel_crtc_masked
 +
 +static void intel_set_config_free(struct intel_set_config *config)
 +{
 +	if (!config)
 +		return;
 +
 +	kfree(config->save_connector_encoders);
 +	kfree(config->save_encoder_crtcs);
 +	kfree(config->save_crtc_enabled);
 +	kfree(config);
 +}
 +
 +static int intel_set_config_save_state(struct drm_device *dev,
 +				       struct intel_set_config *config)
 +{
 +	struct drm_crtc *crtc;
 +	struct drm_encoder *encoder;
 +	struct drm_connector *connector;
 +	int count;
 +
 +	config->save_crtc_enabled =
 +		kcalloc(dev->mode_config.num_crtc,
 +			sizeof(bool), GFP_KERNEL);
 +	if (!config->save_crtc_enabled)
 +		return -ENOMEM;
 +
 +	config->save_encoder_crtcs =
 +		kcalloc(dev->mode_config.num_encoder,
 +			sizeof(struct drm_crtc *), GFP_KERNEL);
 +	if (!config->save_encoder_crtcs)
 +		return -ENOMEM;
 +
 +	config->save_connector_encoders =
 +		kcalloc(dev->mode_config.num_connector,
 +			sizeof(struct drm_encoder *), GFP_KERNEL);
 +	if (!config->save_connector_encoders)
 +		return -ENOMEM;
 +
 +	/* Copy data. Note that driver private data is not affected.
 +	 * Should anything bad happen only the expected state is
 +	 * restored, not the drivers personal bookkeeping.
 +	 */
 +	count = 0;
 +	for_each_crtc(dev, crtc) {
 +		config->save_crtc_enabled[count++] = crtc->state->enable;
 +	}
 +
 +	count = 0;
 +	list_for_each_entry(encoder, &dev->mode_config.encoder_list, head) {
 +		config->save_encoder_crtcs[count++] = encoder->crtc;
 +	}
 +
 +	count = 0;
 +	list_for_each_entry(connector, &dev->mode_config.connector_list, head) {
 +		config->save_connector_encoders[count++] = connector->encoder;
 +	}
 +
 +	return 0;
 +}
 +
 +static void intel_set_config_restore_state(struct drm_device *dev,
 +					   struct intel_set_config *config)
 +{
 +	struct intel_crtc *crtc;
 +	struct intel_encoder *encoder;
 +	struct intel_connector *connector;
 +	int count;
 +
 +	count = 0;
 +	for_each_intel_crtc(dev, crtc) {
 +		crtc->new_enabled = config->save_crtc_enabled[count++];
 +
 +		if (crtc->new_enabled)
 +			crtc->new_config = crtc->config;
 +		else
 +			crtc->new_config = NULL;
 +	}
 +
 +	count = 0;
 +	for_each_intel_encoder(dev, encoder) {
 +		encoder->new_crtc =
 +			to_intel_crtc(config->save_encoder_crtcs[count++]);
 +	}
 +
 +	count = 0;
 +	for_each_intel_connector(dev, connector) {
 +		connector->new_encoder =
 +			to_intel_encoder(config->save_connector_encoders[count++]);
 +	}
 +}
 +
 +static bool
 +is_crtc_connector_off(struct drm_mode_set *set)
 +{
 +	int i;
 +
 +	if (set->num_connectors == 0)
 +		return false;
 +
 +	if (WARN_ON(set->connectors == NULL))
 +		return false;
 +
 +	for (i = 0; i < set->num_connectors; i++)
 +		if (set->connectors[i]->encoder &&
 +		    set->connectors[i]->encoder->crtc == set->crtc &&
 +		    set->connectors[i]->dpms != DRM_MODE_DPMS_ON)
 +			return true;
 +
 +	return false;
 +}
 +
 +static void
 +intel_set_config_compute_mode_changes(struct drm_mode_set *set,
 +				      struct intel_set_config *config)
 +{
 +
 +	/* We should be able to check here if the fb has the same properties
 +	 * and then just flip_or_move it */
 +	if (is_crtc_connector_off(set)) {
 +		config->mode_changed = true;
 +	} else if (set->crtc->primary->fb != set->fb) {
 +		/*
 +		 * If we have no fb, we can only flip as long as the crtc is
 +		 * active, otherwise we need a full mode set.  The crtc may
 +		 * be active if we've only disabled the primary plane, or
 +		 * in fastboot situations.
 +		 */
 +		if (set->crtc->primary->fb == NULL) {
 +			struct intel_crtc *intel_crtc =
 +				to_intel_crtc(set->crtc);
 +
 +			if (intel_crtc->active) {
 +				DRM_DEBUG_KMS("crtc has no fb, will flip\n");
 +				config->fb_changed = true;
 +			} else {
 +				DRM_DEBUG_KMS("inactive crtc, full mode set\n");
 +				config->mode_changed = true;
 +			}
 +		} else if (set->fb == NULL) {
 +			config->mode_changed = true;
 +		} else if (set->fb->pixel_format !=
 +			   set->crtc->primary->fb->pixel_format) {
 +			config->mode_changed = true;
 +		} else {
 +			config->fb_changed = true;
 +		}
 +	}
 +
 +	if (set->fb && (set->x != set->crtc->x || set->y != set->crtc->y))
 +		config->fb_changed = true;
 +
 +	if (set->mode && !drm_mode_equal(set->mode, &set->crtc->mode)) {
 +		DRM_DEBUG_KMS("modes are different, full mode set\n");
 +		drm_mode_debug_printmodeline(&set->crtc->mode);
 +		drm_mode_debug_printmodeline(set->mode);
 +		config->mode_changed = true;
 +	}
 +
 +	DRM_DEBUG_KMS("computed changes for [CRTC:%d], mode_changed=%d, fb_changed=%d\n",
 +			set->crtc->base.id, config->mode_changed, config->fb_changed);
 +}
 +
 +static int
 +intel_modeset_stage_output_state(struct drm_device *dev,
 +				 struct drm_mode_set *set,
 +				 struct intel_set_config *config,
 +				 struct drm_atomic_state *state)
 +{
 +	struct intel_connector *connector;
 +	struct drm_connector_state *connector_state;
 +	struct intel_encoder *encoder;
 +	struct intel_crtc *crtc;
 +	int ro;
 +
 +	/* The upper layers ensure that we either disable a crtc or have a list
 +	 * of connectors. For paranoia, double-check this. */
 +	WARN_ON(!set->fb && (set->num_connectors != 0));
 +	WARN_ON(set->fb && (set->num_connectors == 0));
  
 -		if (!needs_modeset(crtc->state))
 -			continue;
 +	for_each_intel_connector(dev, connector) {
 +		/* Otherwise traverse passed in connector list and get encoders
 +		 * for them. */
 +		for (ro = 0; ro < set->num_connectors; ro++) {
 +			if (set->connectors[ro] == &connector->base) {
 +				connector->new_encoder = intel_find_encoder(connector, to_intel_crtc(set->crtc)->pipe);
 +				break;
 +			}
 +		}
  
 -		intel_pre_plane_update(to_intel_crtc_state(old_crtc_state));
 +		/* If we disable the crtc, disable all its connectors. Also, if
 +		 * the connector is on the changing crtc but not on the new
 +		 * connector list, disable it. */
 +		if ((!set->fb || ro == set->num_connectors) &&
 +		    connector->base.encoder &&
 +		    connector->base.encoder->crtc == set->crtc) {
 +			connector->new_encoder = NULL;
  
 -		if (old_crtc_state->active) {
 -			intel_crtc_disable_planes(crtc, old_crtc_state->plane_mask);
 -			dev_priv->display.crtc_disable(crtc);
 -			intel_crtc->active = false;
 -			intel_fbc_disable(intel_crtc);
 -			intel_disable_shared_dpll(intel_crtc);
 +			DRM_DEBUG_KMS("[CONNECTOR:%d:%s] to [NOCRTC]\n",
 +				connector->base.base.id,
 +				connector->base.name);
 +		}
  
 -			/*
 -			 * Underruns don't always raise
 -			 * interrupts, so check manually.
 -			 */
 -			intel_check_cpu_fifo_underruns(dev_priv);
 -			intel_check_pch_fifo_underruns(dev_priv);
  
 -			if (!crtc->state->active)
 -				intel_update_watermarks(crtc);
 +		if (&connector->new_encoder->base != connector->base.encoder) {
 +			DRM_DEBUG_KMS("[CONNECTOR:%d:%s] encoder changed, full mode switch\n",
 +				      connector->base.base.id,
 +				      connector->base.name);
 +			config->mode_changed = true;
  		}
  	}
 +	/* connector->new_encoder is now updated for all connectors. */
  
 -	/* Only after disabling all output pipelines that will be changed can we
 -	 * update the the output configuration. */
 -	intel_modeset_update_crtc_state(state);
 -
 -	if (intel_state->modeset) {
 -		drm_atomic_helper_update_legacy_modeset_state(state->dev, state);
 -
 -		if (dev_priv->display.modeset_commit_cdclk &&
 -		    intel_state->dev_cdclk != dev_priv->cdclk_freq)
 -			dev_priv->display.modeset_commit_cdclk(state);
 +	/* Update crtc of enabled connectors. */
 +	for_each_intel_connector(dev, connector) {
 +		struct drm_crtc *new_crtc;
  
 -		intel_modeset_verify_disabled(dev);
 -	}
 +		if (!connector->new_encoder)
 +			continue;
  
 -	/* Now enable the clocks, plane, pipe, and connectors that we set up. */
 -	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
 -		struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 -		bool modeset = needs_modeset(crtc->state);
 -		struct intel_crtc_state *pipe_config =
 -			to_intel_crtc_state(crtc->state);
 -		bool update_pipe = !modeset && pipe_config->update_pipe;
 +		new_crtc = connector->new_encoder->base.crtc;
  
 -		if (modeset && crtc->state->active) {
 -			update_scanline_offset(to_intel_crtc(crtc));
 -			dev_priv->display.crtc_enable(crtc);
 +		for (ro = 0; ro < set->num_connectors; ro++) {
 +			if (set->connectors[ro] == &connector->base)
 +				new_crtc = set->crtc;
  		}
  
 -		if (!modeset)
 -			intel_pre_plane_update(to_intel_crtc_state(old_crtc_state));
 +		/* Make sure the new CRTC will work with the encoder */
 +		if (!drm_encoder_crtc_ok(&connector->new_encoder->base,
 +					 new_crtc)) {
 +			return -EINVAL;
 +		}
 +		connector->new_encoder->new_crtc = to_intel_crtc(new_crtc);
  
 -		if (crtc->state->active &&
 -		    drm_atomic_get_existing_plane_state(state, crtc->primary))
 -			intel_fbc_enable(intel_crtc);
 +		connector_state =
 +			drm_atomic_get_connector_state(state, &connector->base);
 +		if (IS_ERR(connector_state))
 +			return PTR_ERR(connector_state);
  
 -		if (crtc->state->active &&
 -		    (crtc->state->planes_changed || update_pipe))
 -			drm_atomic_helper_commit_planes_on_crtc(old_crtc_state);
 +		connector_state->crtc = new_crtc;
 +		connector_state->best_encoder = &connector->new_encoder->base;
  
 -		if (pipe_config->base.active && needs_vblank_wait(pipe_config))
 -			crtc_vblank_mask |= 1 << i;
 +		DRM_DEBUG_KMS("[CONNECTOR:%d:%s] to [CRTC:%d]\n",
 +			connector->base.base.id,
 +			connector->base.name,
 +			new_crtc->base.id);
  	}
  
 -	/* FIXME: add subpixel order */
 -
 -	if (!state->legacy_cursor_update)
 -		intel_atomic_wait_for_vblanks(dev, dev_priv, crtc_vblank_mask);
 +	/* Check for any encoders that needs to be disabled. */
 +	for_each_intel_encoder(dev, encoder) {
 +		int num_connectors = 0;
 +		for_each_intel_connector(dev, connector) {
 +			if (connector->new_encoder == encoder) {
 +				WARN_ON(!connector->new_encoder->new_crtc);
 +				num_connectors++;
 +			}
 +		}
  
 -	/*
 -	 * Now that the vblank has passed, we can go ahead and program the
 -	 * optimal watermarks on platforms that need two-step watermark
 -	 * programming.
 -	 *
 -	 * TODO: Move this (and other cleanup) to an async worker eventually.
 -	 */
 -	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
 -		intel_cstate = to_intel_crtc_state(crtc->state);
 +		if (num_connectors == 0)
 +			encoder->new_crtc = NULL;
 +		else if (num_connectors > 1)
 +			return -EINVAL;
  
 -		if (dev_priv->display.optimize_watermarks)
 -			dev_priv->display.optimize_watermarks(intel_cstate);
 +		/* Only now check for crtc changes so we don't miss encoders
 +		 * that will be disabled. */
 +		if (&encoder->new_crtc->base != encoder->base.crtc) {
 +			DRM_DEBUG_KMS("[ENCODER:%d:%s] crtc changed, full mode switch\n",
 +				      encoder->base.base.id,
 +				      encoder->base.name);
 +			config->mode_changed = true;
 +		}
 +	}
 +	/* Now we've also updated encoder->new_crtc for all encoders. */
 +	for_each_intel_connector(dev, connector) {
 +		connector_state =
 +			drm_atomic_get_connector_state(state, &connector->base);
 +		if (IS_ERR(connector_state))
 +			return PTR_ERR(connector_state);
 +
 +		if (connector->new_encoder) {
 +			if (connector->new_encoder != connector->encoder)
 +				connector->encoder = connector->new_encoder;
 +		} else {
 +			connector_state->crtc = NULL;
 +		}
  	}
 +	for_each_intel_crtc(dev, crtc) {
 +		crtc->new_enabled = false;
  
 -	for_each_crtc_in_state(state, crtc, old_crtc_state, i) {
 -		intel_post_plane_update(to_intel_crtc_state(old_crtc_state));
 +		for_each_intel_encoder(dev, encoder) {
 +			if (encoder->new_crtc == crtc) {
 +				crtc->new_enabled = true;
 +				break;
 +			}
 +		}
  
 -		if (put_domains[i])
 -			modeset_put_power_domains(dev_priv, put_domains[i]);
 +		if (crtc->new_enabled != crtc->base.state->enable) {
 +			DRM_DEBUG_KMS("[CRTC:%d] %sabled, full mode switch\n",
 +				      crtc->base.base.id,
 +				      crtc->new_enabled ? "en" : "dis");
 +			config->mode_changed = true;
 +		}
  
 -		intel_modeset_verify_crtc(crtc, old_crtc_state, crtc->state);
 +		if (crtc->new_enabled)
 +			crtc->new_config = crtc->config;
 +		else
 +			crtc->new_config = NULL;
  	}
  
 -	if (intel_state->modeset)
 -		intel_display_power_put(dev_priv, POWER_DOMAIN_MODESET);
 +	return 0;
 +}
  
 -	mutex_lock(&dev->struct_mutex);
 -	drm_atomic_helper_cleanup_planes(dev, state);
 -	mutex_unlock(&dev->struct_mutex);
 +static void disable_crtc_nofb(struct intel_crtc *crtc)
 +{
 +	struct drm_device *dev = crtc->base.dev;
 +	struct intel_encoder *encoder;
 +	struct intel_connector *connector;
  
 -	drm_atomic_state_free(state);
 +	DRM_DEBUG_KMS("Trying to restore without FB -> disabling pipe %c\n",
 +		      pipe_name(crtc->pipe));
  
 -	/* As one of the primary mmio accessors, KMS has a high likelihood
 -	 * of triggering bugs in unclaimed access. After we finish
 -	 * modesetting, see if an error has been flagged, and if so
 -	 * enable debugging for the next modeset - and hope we catch
 -	 * the culprit.
 -	 *
 -	 * XXX note that we assume display power is on at this point.
 -	 * This might hold true now but we need to add pm helper to check
 -	 * unclaimed only when the hardware is on, as atomic commits
 -	 * can happen also when the device is completely off.
 -	 */
 -	intel_uncore_arm_unclaimed_mmio_detection(dev_priv);
 +	for_each_intel_connector(dev, connector) {
 +		if (connector->new_encoder &&
 +		    connector->new_encoder->new_crtc == crtc)
 +			connector->new_encoder = NULL;
 +	}
  
 -	return 0;
 +	for_each_intel_encoder(dev, encoder) {
 +		if (encoder->new_crtc == crtc)
 +			encoder->new_crtc = NULL;
 +	}
 +
 +	crtc->new_enabled = false;
 +	crtc->new_config = NULL;
  }
  
 -void intel_crtc_restore_mode(struct drm_crtc *crtc)
 +static int intel_crtc_set_config(struct drm_mode_set *set)
  {
 -	struct drm_device *dev = crtc->dev;
 -	struct drm_atomic_state *state;
 -	struct drm_crtc_state *crtc_state;
 +	struct drm_device *dev;
 +	struct drm_mode_set save_set;
 +	struct drm_atomic_state *state = NULL;
 +	struct intel_set_config *config;
 +	struct intel_crtc_state *pipe_config;
 +	unsigned modeset_pipes, prepare_pipes, disable_pipes;
  	int ret;
  
 +	BUG_ON(!set);
 +	BUG_ON(!set->crtc);
 +	BUG_ON(!set->crtc->helper_private);
 +
 +	/* Enforce sane interface api - has been abused by the fb helper. */
 +	BUG_ON(!set->mode && set->fb);
 +	BUG_ON(set->fb && set->num_connectors == 0);
 +
 +	if (set->fb) {
 +		DRM_DEBUG_KMS("[CRTC:%d] [FB:%d] #connectors=%d (x y) (%i %i)\n",
 +				set->crtc->base.id, set->fb->base.id,
 +				(int)set->num_connectors, set->x, set->y);
 +	} else {
 +		DRM_DEBUG_KMS("[CRTC:%d] [NOFB]\n", set->crtc->base.id);
 +	}
 +
 +	dev = set->crtc->dev;
 +
 +	ret = -ENOMEM;
 +	config = kzalloc(sizeof(*config), GFP_KERNEL);
 +	if (!config)
 +		goto out_config;
 +
 +	ret = intel_set_config_save_state(dev, config);
 +	if (ret)
 +		goto out_config;
 +
 +	save_set.crtc = set->crtc;
 +	save_set.mode = &set->crtc->mode;
 +	save_set.x = set->crtc->x;
 +	save_set.y = set->crtc->y;
 +	save_set.fb = set->crtc->primary->fb;
 +
 +	/* Compute whether we need a full modeset, only an fb base update or no
 +	 * change at all. In the future we might also check whether only the
 +	 * mode changed, e.g. for LVDS where we only change the panel fitter in
 +	 * such cases. */
 +	intel_set_config_compute_mode_changes(set, config);
 +
  	state = drm_atomic_state_alloc(dev);
  	if (!state) {
 -		DRM_DEBUG_KMS("[CRTC:%d] crtc restore failed, out of memory",
 -			      crtc->base.id);
 -		return;
 +		ret = -ENOMEM;
 +		goto out_config;
  	}
  
 -	state->acquire_ctx = drm_modeset_legacy_acquire_ctx(crtc);
 +	state->acquire_ctx = dev->mode_config.acquire_ctx;
  
 -retry:
 -	crtc_state = drm_atomic_get_crtc_state(state, crtc);
 -	ret = PTR_ERR_OR_ZERO(crtc_state);
 -	if (!ret) {
 -		if (!crtc_state->active)
 -			goto out;
 +	ret = intel_modeset_stage_output_state(dev, set, config, state);
 +	if (ret)
 +		goto fail;
 +
 +	pipe_config = intel_modeset_compute_config(set->crtc, set->mode,
 +						   set->fb, state,
 +						   &modeset_pipes,
 +						   &prepare_pipes,
 +						   &disable_pipes);
 +	if (IS_ERR(pipe_config)) {
 +		ret = PTR_ERR(pipe_config);
 +		goto fail;
 +	} else if (pipe_config) {
 +		if (pipe_config->has_audio !=
 +		    to_intel_crtc(set->crtc)->config->has_audio)
 +			config->mode_changed = true;
  
 -		crtc_state->mode_changed = true;
 -		ret = drm_atomic_commit(state);
 +		/*
 +		 * Note we have an issue here with infoframes: current code
 +		 * only updates them on the full mode set path per hw
 +		 * requirements.  So here we should be checking for any
 +		 * required changes and forcing a mode set.
 +		 */
  	}
  
 -	if (ret == -EDEADLK) {
 +	intel_update_pipe_size(to_intel_crtc(set->crtc));
 +
 +	if (config->mode_changed) {
 +		ret = intel_set_mode_pipes(set->crtc, set->mode,
 +					   set->x, set->y, set->fb, pipe_config,
 +					   modeset_pipes, prepare_pipes,
 +					   disable_pipes);
 +	} else if (config->fb_changed) {
 +		struct intel_crtc *intel_crtc = to_intel_crtc(set->crtc);
 +		struct drm_plane *primary = set->crtc->primary;
 +		int vdisplay, hdisplay;
 +
 +		drm_crtc_get_hv_timing(set->mode, &hdisplay, &vdisplay);
 +		ret = primary->funcs->update_plane(primary, set->crtc, set->fb,
 +						   0, 0, hdisplay, vdisplay,
 +						   set->x << 16, set->y << 16,
 +						   hdisplay << 16, vdisplay << 16);
 +
 +		/*
 +		 * We need to make sure the primary plane is re-enabled if it
 +		 * has previously been turned off.
 +		 */
 +		if (!intel_crtc->primary_enabled && ret == 0) {
 +			WARN_ON(!intel_crtc->active);
 +			intel_enable_primary_hw_plane(set->crtc->primary, set->crtc);
 +		}
 +
 +		/*
 +		 * In the fastboot case this may be our only check of the
 +		 * state after boot.  It would be better to only do it on
 +		 * the first update, but we don't have a nice way of doing that
 +		 * (and really, set_config isn't used much for high freq page
 +		 * flipping, so increasing its cost here shouldn't be a big
 +		 * deal).
 +		 */
 +		if (i915.fastboot && ret == 0)
 +			intel_modeset_check_state(set->crtc->dev);
 +	}
 +
 +	if (ret) {
 +		DRM_DEBUG_KMS("failed to set mode on [CRTC:%d], err = %d\n",
 +			      set->crtc->base.id, ret);
 +fail:
 +		intel_set_config_restore_state(dev, config);
 +
  		drm_atomic_state_clear(state);
 -		drm_modeset_backoff(state->acquire_ctx);
 -		goto retry;
 +
 +		/*
 +		 * HACK: if the pipe was on, but we didn't have a framebuffer,
 +		 * force the pipe off to avoid oopsing in the modeset code
 +		 * due to fb==NULL. This should only happen during boot since
 +		 * we don't yet reconstruct the FB from the hardware state.
 +		 */
 +		if (to_intel_crtc(save_set.crtc)->new_enabled && !save_set.fb)
 +			disable_crtc_nofb(to_intel_crtc(save_set.crtc));
 +
 +		/* Try to restore the config */
 +		if (config->mode_changed &&
 +		    intel_set_mode(save_set.crtc, save_set.mode,
 +				   save_set.x, save_set.y, save_set.fb,
 +				   state))
 +			DRM_ERROR("failed to restore config after modeset failure\n");
  	}
  
 -	if (ret)
 -out:
 +out_config:
 +	if (state)
  		drm_atomic_state_free(state);
 -}
  
 -#undef for_each_intel_crtc_masked
 +	intel_set_config_free(config);
 +	return ret;
 +}
  
  static const struct drm_crtc_funcs intel_crtc_funcs = {
 -	.gamma_set = drm_atomic_helper_legacy_gamma_set,
 -	.set_config = drm_atomic_helper_set_config,
 -	.set_property = drm_atomic_helper_crtc_set_property,
 +	.gamma_set = intel_crtc_gamma_set,
 +	.set_config = intel_crtc_set_config,
  	.destroy = intel_crtc_destroy,
  	.page_flip = intel_crtc_page_flip,
  	.atomic_duplicate_state = intel_crtc_duplicate_state,
diff --cc drivers/gpu/drm/i915/intel_pm.c
index cca54888a5ac,1d8407a8fd34..000000000000
--- a/drivers/gpu/drm/i915/intel_pm.c
+++ b/drivers/gpu/drm/i915/intel_pm.c
@@@ -2793,113 -3238,59 +2793,131 @@@ static bool skl_ddb_allocation_changed(
  	return false;
  }
  
++<<<<<<< HEAD
 +static void skl_compute_wm_global_parameters(struct drm_device *dev,
 +					     struct intel_wm_config *config)
 +{
 +	struct drm_crtc *crtc;
 +	struct drm_plane *plane;
 +
 +	list_for_each_entry(crtc, &dev->mode_config.crtc_list, head)
 +		config->num_pipes_active += to_intel_crtc(crtc)->active;
 +
 +	/* FIXME: I don't think we need those two global parameters on SKL */
 +	list_for_each_entry(plane, &dev->mode_config.plane_list, head) {
 +		struct intel_plane *intel_plane = to_intel_plane(plane);
 +
 +		config->sprites_enabled |= intel_plane->wm.enabled;
 +		config->sprites_scaled |= intel_plane->wm.scaled;
 +	}
 +}
 +
 +static void skl_compute_wm_pipe_parameters(struct drm_crtc *crtc,
 +					   struct skl_pipe_wm_parameters *p)
 +{
 +	struct drm_device *dev = crtc->dev;
 +	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 +	enum pipe pipe = intel_crtc->pipe;
 +	struct drm_plane *plane;
 +	struct drm_framebuffer *fb;
 +	int i = 1; /* Index for sprite planes start */
 +
 +	p->active = intel_crtc->active;
 +	if (p->active) {
 +		p->pipe_htotal = intel_crtc->config->base.adjusted_mode.crtc_htotal;
 +		p->pixel_rate = skl_pipe_pixel_rate(intel_crtc->config);
 +
 +		fb = crtc->primary->state->fb;
 +		if (fb) {
 +			p->plane[0].enabled = true;
 +			p->plane[0].bytes_per_pixel = fb->bits_per_pixel / 8;
 +			p->plane[0].tiling = fb->modifier[0];
 +		} else {
 +			p->plane[0].enabled = false;
 +			p->plane[0].bytes_per_pixel = 0;
 +			p->plane[0].tiling = DRM_FORMAT_MOD_NONE;
 +		}
 +		p->plane[0].horiz_pixels = intel_crtc->config->pipe_src_w;
 +		p->plane[0].vert_pixels = intel_crtc->config->pipe_src_h;
 +		p->plane[0].rotation = crtc->primary->state->rotation;
 +
 +		fb = crtc->cursor->state->fb;
 +		if (fb) {
 +			p->cursor.enabled = true;
 +			p->cursor.bytes_per_pixel = fb->bits_per_pixel / 8;
 +			p->cursor.horiz_pixels = crtc->cursor->state->crtc_w;
 +			p->cursor.vert_pixels = crtc->cursor->state->crtc_h;
 +		} else {
 +			p->cursor.enabled = false;
 +			p->cursor.bytes_per_pixel = 0;
 +			p->cursor.horiz_pixels = 64;
 +			p->cursor.vert_pixels = 64;
 +		}
 +	}
 +
 +	list_for_each_entry(plane, &dev->mode_config.plane_list, head) {
 +		struct intel_plane *intel_plane = to_intel_plane(plane);
 +
 +		if (intel_plane->pipe == pipe &&
 +			plane->type == DRM_PLANE_TYPE_OVERLAY)
 +			p->plane[i++] = intel_plane->wm;
 +	}
 +}
 +
 +static bool skl_compute_plane_wm(const struct drm_i915_private *dev_priv,
 +				 struct skl_pipe_wm_parameters *p,
 +				 struct intel_plane_wm_parameters *p_params,
 +				 uint16_t ddb_allocation,
 +				 int level,
 +				 uint16_t *out_blocks, /* out */
 +				 uint8_t *out_lines /* out */)
++=======
+ static int skl_compute_plane_wm(const struct drm_i915_private *dev_priv,
+ 				struct intel_crtc_state *cstate,
+ 				struct intel_plane_state *intel_pstate,
+ 				uint16_t ddb_allocation,
+ 				int level,
+ 				uint16_t *out_blocks, /* out */
+ 				uint8_t *out_lines, /* out */
+ 				bool *enabled /* out */)
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
  {
 -	struct drm_plane_state *pstate = &intel_pstate->base;
 -	struct drm_framebuffer *fb = pstate->fb;
  	uint32_t latency = dev_priv->wm.skl_latency[level];
  	uint32_t method1, method2;
  	uint32_t plane_bytes_per_line, plane_blocks_per_line;
  	uint32_t res_blocks, res_lines;
  	uint32_t selected_result;
 -	uint8_t cpp;
 -	uint32_t width = 0, height = 0;
  
++<<<<<<< HEAD
 +	if (latency == 0 || !p->active || !p_params->enabled)
 +		return false;
++=======
+ 	if (latency == 0 || !cstate->base.active || !intel_pstate->visible) {
+ 		*enabled = false;
+ 		return 0;
+ 	}
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
  
 -	width = drm_rect_width(&intel_pstate->src) >> 16;
 -	height = drm_rect_height(&intel_pstate->src) >> 16;
 -
 -	if (intel_rotation_90_or_270(pstate->rotation))
 -		swap(width, height);
 -
 -	cpp = drm_format_plane_cpp(fb->pixel_format, 0);
 -	method1 = skl_wm_method1(skl_pipe_pixel_rate(cstate),
 -				 cpp, latency);
 -	method2 = skl_wm_method2(skl_pipe_pixel_rate(cstate),
 -				 cstate->base.adjusted_mode.crtc_htotal,
 -				 width,
 -				 cpp,
 -				 fb->modifier[0],
 +	method1 = skl_wm_method1(p->pixel_rate,
 +				 p_params->bytes_per_pixel,
 +				 latency);
 +	method2 = skl_wm_method2(p->pixel_rate,
 +				 p->pipe_htotal,
 +				 p_params->horiz_pixels,
 +				 p_params->bytes_per_pixel,
 +				 p_params->tiling,
  				 latency);
  
 -	plane_bytes_per_line = width * cpp;
 +	plane_bytes_per_line = p_params->horiz_pixels *
 +					p_params->bytes_per_pixel;
  	plane_blocks_per_line = DIV_ROUND_UP(plane_bytes_per_line, 512);
  
 -	if (fb->modifier[0] == I915_FORMAT_MOD_Y_TILED ||
 -	    fb->modifier[0] == I915_FORMAT_MOD_Yf_TILED) {
 +	if (p_params->tiling == I915_FORMAT_MOD_Y_TILED ||
 +	    p_params->tiling == I915_FORMAT_MOD_Yf_TILED) {
  		uint32_t min_scanlines = 4;
  		uint32_t y_tile_minimum;
 -		if (intel_rotation_90_or_270(pstate->rotation)) {
 -			int cpp = (fb->pixel_format == DRM_FORMAT_NV12) ?
 -				drm_format_plane_cpp(fb->pixel_format, 1) :
 -				drm_format_plane_cpp(fb->pixel_format, 0);
 -
 -			switch (cpp) {
 +		if (intel_rotation_90_or_270(p_params->rotation)) {
 +			switch (p_params->bytes_per_pixel) {
  			case 1:
  				min_scanlines = 16;
  				break;
@@@ -2935,37 -3328,77 +2955,90 @@@
  
  	*out_blocks = res_blocks;
  	*out_lines = res_lines;
+ 	*enabled = true;
  
- 	return true;
+ 	return 0;
  }
  
 -static int
 -skl_compute_wm_level(const struct drm_i915_private *dev_priv,
 -		     struct skl_ddb_allocation *ddb,
 -		     struct intel_crtc_state *cstate,
 -		     int level,
 -		     struct skl_wm_level *result)
 +static void skl_compute_wm_level(const struct drm_i915_private *dev_priv,
 +				 struct skl_ddb_allocation *ddb,
 +				 struct skl_pipe_wm_parameters *p,
 +				 enum pipe pipe,
 +				 int level,
 +				 int num_planes,
 +				 struct skl_wm_level *result)
  {
 -	struct drm_device *dev = dev_priv->dev;
 -	struct drm_atomic_state *state = cstate->base.state;
 -	struct intel_crtc *intel_crtc = to_intel_crtc(cstate->base.crtc);
 -	struct drm_plane *plane;
 -	struct intel_plane *intel_plane;
 -	struct intel_plane_state *intel_pstate;
  	uint16_t ddb_blocks;
++<<<<<<< HEAD
 +	int i;
++=======
+ 	enum pipe pipe = intel_crtc->pipe;
+ 	int ret;
+ 
+ 	/*
+ 	 * We'll only calculate watermarks for planes that are actually
+ 	 * enabled, so make sure all other planes are set as disabled.
+ 	 */
+ 	memset(result, 0, sizeof(*result));
+ 
+ 	for_each_intel_plane_mask(dev, intel_plane, cstate->base.plane_mask) {
+ 		int i = skl_wm_plane_id(intel_plane);
+ 
+ 		plane = &intel_plane->base;
+ 		intel_pstate = NULL;
+ 		if (state)
+ 			intel_pstate =
+ 				intel_atomic_get_existing_plane_state(state,
+ 								      intel_plane);
+ 
+ 		/*
+ 		 * Note: If we start supporting multiple pending atomic commits
+ 		 * against the same planes/CRTC's in the future, plane->state
+ 		 * will no longer be the correct pre-state to use for the
+ 		 * calculations here and we'll need to change where we get the
+ 		 * 'unchanged' plane data from.
+ 		 *
+ 		 * For now this is fine because we only allow one queued commit
+ 		 * against a CRTC.  Even if the plane isn't modified by this
+ 		 * transaction and we don't have a plane lock, we still have
+ 		 * the CRTC's lock, so we know that no other transactions are
+ 		 * racing with us to update it.
+ 		 */
+ 		if (!intel_pstate)
+ 			intel_pstate = to_intel_plane_state(plane->state);
+ 
+ 		WARN_ON(!intel_pstate->base.fb);
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
  
 +	for (i = 0; i < num_planes; i++) {
  		ddb_blocks = skl_ddb_entry_size(&ddb->plane[pipe][i]);
  
++<<<<<<< HEAD
 +		result->plane_en[i] = skl_compute_plane_wm(dev_priv,
 +						p, &p->plane[i],
 +						ddb_blocks,
 +						level,
 +						&result->plane_res_b[i],
 +						&result->plane_res_l[i]);
++=======
+ 		ret = skl_compute_plane_wm(dev_priv,
+ 					   cstate,
+ 					   intel_pstate,
+ 					   ddb_blocks,
+ 					   level,
+ 					   &result->plane_res_b[i],
+ 					   &result->plane_res_l[i],
+ 					   &result->plane_en[i]);
+ 		if (ret)
+ 			return ret;
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
  	}
  
 -	return 0;
 +	ddb_blocks = skl_ddb_entry_size(&ddb->cursor[pipe]);
 +	result->cursor_en = skl_compute_plane_wm(dev_priv, p, &p->cursor,
 +						 ddb_blocks, level,
 +						 &result->cursor_res_b,
 +						 &result->cursor_res_l);
  }
  
  static uint32_t
@@@ -2989,29 -3425,33 +3062,49 @@@ static void skl_compute_transition_wm(s
  		return;
  
  	/* Until we know more, just disable transition WMs */
 -	for_each_intel_plane_on_crtc(crtc->dev, intel_crtc, intel_plane) {
 -		int i = skl_wm_plane_id(intel_plane);
 -
 +	for (i = 0; i < intel_num_planes(intel_crtc); i++)
  		trans_wm->plane_en[i] = false;
 -	}
 +	trans_wm->cursor_en = false;
  }
  
++<<<<<<< HEAD
 +static void skl_compute_pipe_wm(struct drm_crtc *crtc,
 +				struct skl_ddb_allocation *ddb,
 +				struct skl_pipe_wm_parameters *params,
 +				struct skl_pipe_wm *pipe_wm)
++=======
+ static int skl_build_pipe_wm(struct intel_crtc_state *cstate,
+ 			     struct skl_ddb_allocation *ddb,
+ 			     struct skl_pipe_wm *pipe_wm)
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
  {
 -	struct drm_device *dev = cstate->base.crtc->dev;
 +	struct drm_device *dev = crtc->dev;
  	const struct drm_i915_private *dev_priv = dev->dev_private;
 +	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
  	int level, max_level = ilk_wm_max_level(dev);
+ 	int ret;
  
  	for (level = 0; level <= max_level; level++) {
++<<<<<<< HEAD
 +		skl_compute_wm_level(dev_priv, ddb, params, intel_crtc->pipe,
 +				     level, intel_num_planes(intel_crtc),
 +				     &pipe_wm->wm[level]);
++=======
+ 		ret = skl_compute_wm_level(dev_priv, ddb, cstate,
+ 					   level, &pipe_wm->wm[level]);
+ 		if (ret)
+ 			return ret;
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
  	}
 -	pipe_wm->linetime = skl_compute_linetime_wm(cstate);
 +	pipe_wm->linetime = skl_compute_linetime_wm(crtc, params);
  
++<<<<<<< HEAD
 +	skl_compute_transition_wm(crtc, params, &pipe_wm->trans_wm);
++=======
+ 	skl_compute_transition_wm(cstate, &pipe_wm->trans_wm);
+ 
+ 	return 0;
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
  }
  
  static void skl_compute_wm_results(struct drm_device *dev,
@@@ -3253,23 -3698,27 +3346,47 @@@ static void skl_flush_wm_values(struct 
  	}
  }
  
++<<<<<<< HEAD
 +static bool skl_update_pipe_wm(struct drm_crtc *crtc,
 +			       struct skl_pipe_wm_parameters *params,
 +			       struct intel_wm_config *config,
 +			       struct skl_ddb_allocation *ddb, /* out */
 +			       struct skl_pipe_wm *pipe_wm /* out */)
 +{
 +	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
 +
 +	skl_compute_wm_pipe_parameters(crtc, params);
 +	skl_allocate_pipe_ddb(crtc, config, params, ddb);
 +	skl_compute_pipe_wm(crtc, ddb, params, pipe_wm);
 +
 +	if (!memcmp(&intel_crtc->wm.skl_active, pipe_wm, sizeof(*pipe_wm)))
 +		return false;
 +
 +	intel_crtc->wm.skl_active = *pipe_wm;
 +	return true;
++=======
+ static int skl_update_pipe_wm(struct drm_crtc_state *cstate,
+ 			      struct skl_ddb_allocation *ddb, /* out */
+ 			      struct skl_pipe_wm *pipe_wm, /* out */
+ 			      bool *changed /* out */)
+ {
+ 	struct intel_crtc *intel_crtc = to_intel_crtc(cstate->crtc);
+ 	struct intel_crtc_state *intel_cstate = to_intel_crtc_state(cstate);
+ 	int ret;
+ 
+ 	ret = skl_build_pipe_wm(intel_cstate, ddb, pipe_wm);
+ 	if (ret)
+ 		return ret;
+ 
+ 	if (!memcmp(&intel_crtc->wm.active.skl, pipe_wm, sizeof(*pipe_wm)))
+ 		*changed = false;
+ 	else
+ 		*changed = true;
+ 
+ 	intel_crtc->wm.active.skl = *pipe_wm;
+ 
+ 	return 0;
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
  }
  
  static void skl_update_other_pipe_wm(struct drm_device *dev,
@@@ -3305,9 -3751,8 +3422,14 @@@
  		if (!intel_crtc->active)
  			continue;
  
++<<<<<<< HEAD
 +		wm_changed = skl_update_pipe_wm(&intel_crtc->base,
 +						&params, config,
 +						&r->ddb, &pipe_wm);
++=======
+ 		skl_update_pipe_wm(intel_crtc->base.state,
+ 				   &r->ddb, &pipe_wm, &wm_changed);
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
  
  		/*
  		 * If we end up re-computing the other pipe WM values, it's
@@@ -3326,23 -3859,24 +3448,36 @@@ static void skl_update_wm(struct drm_cr
  	struct intel_crtc *intel_crtc = to_intel_crtc(crtc);
  	struct drm_device *dev = crtc->dev;
  	struct drm_i915_private *dev_priv = dev->dev_private;
 +	struct skl_pipe_wm_parameters params = {};
  	struct skl_wm_values *results = &dev_priv->wm.skl_results;
++<<<<<<< HEAD
 +	struct skl_pipe_wm pipe_wm = {};
 +	struct intel_wm_config config = {};
 +
 +	memset(results, 0, sizeof(*results));
++=======
+ 	struct intel_crtc_state *cstate = to_intel_crtc_state(crtc->state);
+ 	struct skl_pipe_wm *pipe_wm = &cstate->wm.skl.optimal;
+ 	bool wm_changed;
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
  
 -	/* Clear all dirty flags */
 -	results->dirty_pipes = 0;
 +	skl_compute_wm_global_parameters(dev, &config);
  
++<<<<<<< HEAD
 +	if (!skl_update_pipe_wm(crtc, &params, &config,
 +				&results->ddb, &pipe_wm))
++=======
+ 	skl_clear_wm(results, intel_crtc->pipe);
+ 
+ 	skl_update_pipe_wm(crtc->state, &results->ddb, pipe_wm, &wm_changed);
+ 	if (!wm_changed)
++>>>>>>> 55994c2c38a1 (drm/i915/gen9: Propagate watermark calculation failures up the call chain)
  		return;
  
 -	skl_compute_wm_results(dev, pipe_wm, results, intel_crtc);
 -	results->dirty_pipes |= drm_crtc_mask(&intel_crtc->base);
 +	skl_compute_wm_results(dev, &params, &pipe_wm, results, intel_crtc);
 +	results->dirty[intel_crtc->pipe] = true;
  
 -	skl_update_other_pipe_wm(dev, crtc, results);
 +	skl_update_other_pipe_wm(dev, crtc, &config, results);
  	skl_write_wm_values(dev_priv, results);
  	skl_flush_wm_values(dev_priv, results);
  
* Unmerged path drivers/gpu/drm/i915/intel_display.c
* Unmerged path drivers/gpu/drm/i915/intel_pm.c
