iommu/amd: Implement dm_region call-backs

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [iommu] amd: Implement dm_region call-backs (Myron Stowe) [1050021]
Rebuild_FUZZ: 92.11%
commit-author Joerg Roedel <jroedel@suse.de>
commit 35cf248f8860b8d2956516d6cdf7e57ff4ed4cbb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/35cf248f.failed

Add the get_dm_regions and put_dm_regions callbacks to the
iommu_ops of the AMD IOMMU driver.

	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit 35cf248f8860b8d2956516d6cdf7e57ff4ed4cbb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/amd_iommu.c
diff --cc drivers/iommu/amd_iommu.c
index fe4bdde82bc7,22d38e3cdc7a..000000000000
--- a/drivers/iommu/amd_iommu.c
+++ b/drivers/iommu/amd_iommu.c
@@@ -3400,23 -3402,69 +3400,76 @@@ static int amd_iommu_domain_has_cap(str
  {
  	switch (cap) {
  	case IOMMU_CAP_CACHE_COHERENCY:
 -		return true;
 +		return 1;
  	case IOMMU_CAP_INTR_REMAP:
 -		return (irq_remapping_enabled == 1);
 -	case IOMMU_CAP_NOEXEC:
 -		return false;
 +		return irq_remapping_enabled;
  	}
  
 -	return false;
 +	return 0;
  }
  
++<<<<<<< HEAD
 +static struct iommu_ops amd_iommu_ops = {
 +	.domain_init = amd_iommu_domain_init,
 +	.domain_destroy = amd_iommu_domain_destroy,
++=======
+ static void amd_iommu_get_dm_regions(struct device *dev,
+ 				     struct list_head *head)
+ {
+ 	struct unity_map_entry *entry;
+ 	u16 devid;
+ 
+ 	devid = get_device_id(dev);
+ 
+ 	list_for_each_entry(entry, &amd_iommu_unity_map, list) {
+ 		struct iommu_dm_region *region;
+ 
+ 		if (devid < entry->devid_start || devid > entry->devid_end)
+ 			continue;
+ 
+ 		region = kzalloc(sizeof(*region), GFP_KERNEL);
+ 		if (!region) {
+ 			pr_err("Out of memory allocating dm-regions for %s\n",
+ 				dev_name(dev));
+ 			return;
+ 		}
+ 
+ 		region->start = entry->address_start;
+ 		region->length = entry->address_end - entry->address_start;
+ 		if (entry->prot & IOMMU_PROT_IR)
+ 			region->prot |= IOMMU_READ;
+ 		if (entry->prot & IOMMU_PROT_IW)
+ 			region->prot |= IOMMU_WRITE;
+ 
+ 		list_add_tail(&region->list, head);
+ 	}
+ }
+ 
+ static void amd_iommu_put_dm_regions(struct device *dev,
+ 				     struct list_head *head)
+ {
+ 	struct iommu_dm_region *entry, *next;
+ 
+ 	list_for_each_entry_safe(entry, next, head, list)
+ 		kfree(entry);
+ }
+ 
+ static const struct iommu_ops amd_iommu_ops = {
+ 	.capable = amd_iommu_capable,
+ 	.domain_alloc = amd_iommu_domain_alloc,
+ 	.domain_free  = amd_iommu_domain_free,
++>>>>>>> 35cf248f8860 (iommu/amd: Implement dm_region call-backs)
  	.attach_dev = amd_iommu_attach_device,
  	.detach_dev = amd_iommu_detach_device,
  	.map = amd_iommu_map,
  	.unmap = amd_iommu_unmap,
 -	.map_sg = default_iommu_map_sg,
  	.iova_to_phys = amd_iommu_iova_to_phys,
++<<<<<<< HEAD
 +	.domain_has_cap = amd_iommu_domain_has_cap,
++=======
+ 	.get_dm_regions = amd_iommu_get_dm_regions,
+ 	.put_dm_regions = amd_iommu_put_dm_regions,
++>>>>>>> 35cf248f8860 (iommu/amd: Implement dm_region call-backs)
  	.pgsize_bitmap	= AMD_IOMMU_PGSIZES,
  };
  
* Unmerged path drivers/iommu/amd_iommu.c
