staging/rdma/hfi1: Remove header memcpy from sdma send path.

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [infiniband] rdma/hfi1: Remove header memcpy from sdma send path (Alex Estrin) [1272062 1273170]
Rebuild_FUZZ: 91.89%
commit-author Dennis Dalessandro <dennis.dalessandro@intel.com>
commit bb5df5f9eea6b9efb5911a5fef63b4614af01c89
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/bb5df5f9.failed

Instead of writing the header into a buffer then copying it into another
buffer to be sent, remove that memcpy and instead build the header directly
into the tx request that will be sent.

	Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
	Signed-off-by: Vennila Megavannan <vennila.megavannan@intel.com>
	Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit bb5df5f9eea6b9efb5911a5fef63b4614af01c89)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/staging/hfi1/rc.c
#	drivers/staging/hfi1/ruc.c
#	drivers/staging/hfi1/uc.c
#	drivers/staging/hfi1/ud.c
#	drivers/staging/hfi1/user_sdma.h
#	drivers/staging/rdma/hfi1/verbs.h
diff --cc drivers/staging/hfi1/rc.c
index dd57d65aa9b2,75d70d583d03..000000000000
--- a/drivers/staging/hfi1/rc.c
+++ b/drivers/staging/hfi1/rc.c
@@@ -94,10 -207,11 +95,16 @@@ static void start_timer(struct hfi1_qp 
   * Note that we are in the responder's side of the QP context.
   * Note the QP s_lock must be held.
   */
++<<<<<<< HEAD:drivers/staging/hfi1/rc.c
 +static int make_rc_ack(struct hfi1_ibdev *dev, struct hfi1_qp *qp,
 +		       struct hfi1_other_headers *ohdr, u32 pmtu)
++=======
+ static int make_rc_ack(struct hfi1_ibdev *dev, struct rvt_qp *qp,
+ 		       struct hfi1_other_headers *ohdr, u32 pmtu,
+ 		       struct hfi1_pkt_state *ps)
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/rc.c
  {
 -	struct rvt_ack_entry *e;
 +	struct hfi1_ack_entry *e;
  	u32 hwords;
  	u32 len;
  	u32 bth0;
@@@ -255,9 -369,11 +262,13 @@@ bail
   * hfi1_make_rc_req - construct a request packet (SEND, RDMA r/w, ATOMIC)
   * @qp: a pointer to the QP
   *
 - * Assumes s_lock is held.
 - *
   * Return 1 if constructed; otherwise, return 0.
   */
++<<<<<<< HEAD:drivers/staging/hfi1/rc.c
 +int hfi1_make_rc_req(struct hfi1_qp *qp)
++=======
+ int hfi1_make_rc_req(struct rvt_qp *qp, struct hfi1_pkt_state *ps)
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/rc.c
  {
  	struct hfi1_qp_priv *priv = qp->priv;
  	struct hfi1_ibdev *dev = to_idev(qp->ibqp.device);
@@@ -271,31 -387,28 +282,44 @@@
  	u32 bth2;
  	u32 pmtu = qp->pmtu;
  	char newreq;
++<<<<<<< HEAD:drivers/staging/hfi1/rc.c
 +	unsigned long flags;
 +	int ret = 0;
++=======
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/rc.c
  	int middle = 0;
  	int delta;
  
- 	ohdr = &priv->s_hdr->ibh.u.oth;
+ 	ps->s_txreq = get_txreq(ps->dev, qp);
+ 	if (IS_ERR(ps->s_txreq))
+ 		goto bail_no_tx;
+ 
+ 	ohdr = &ps->s_txreq->phdr.hdr.u.oth;
  	if (qp->remote_ah_attr.ah_flags & IB_AH_GRH)
- 		ohdr = &priv->s_hdr->ibh.u.l.oth;
+ 		ohdr = &ps->s_txreq->phdr.hdr.u.l.oth;
  
 +	/*
 +	 * The lock is needed to synchronize between the sending tasklet,
 +	 * the receive interrupt handler, and timeout re-sends.
 +	 */
 +	spin_lock_irqsave(&qp->s_lock, flags);
 +
  	/* Sending responses has higher priority over sending requests. */
++<<<<<<< HEAD:drivers/staging/hfi1/rc.c
 +	if ((qp->s_flags & HFI1_S_RESP_PENDING) &&
 +	    make_rc_ack(dev, qp, ohdr, pmtu))
 +		goto done;
++=======
+ 	if ((qp->s_flags & RVT_S_RESP_PENDING) &&
+ 	    make_rc_ack(dev, qp, ohdr, pmtu, ps))
+ 		return 1;
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/rc.c
  
 -	if (!(ib_rvt_state_ops[qp->state] & RVT_PROCESS_SEND_OK)) {
 -		if (!(ib_rvt_state_ops[qp->state] & RVT_FLUSH_SEND))
 +	if (!(ib_hfi1_state_ops[qp->state] & HFI1_PROCESS_SEND_OK)) {
 +		if (!(ib_hfi1_state_ops[qp->state] & HFI1_FLUSH_SEND))
  			goto bail;
  		/* We are in the error state, flush the work request. */
 -		smp_read_barrier_depends(); /* see post_one_send() */
 -		if (qp->s_last == ACCESS_ONCE(qp->s_head))
 +		if (qp->s_last == qp->s_head)
  			goto bail;
  		/* If DMAs are in progress, we can't flush immediately. */
  		if (atomic_read(&priv->s_iowait.sdma_busy)) {
@@@ -307,10 -420,10 +331,10 @@@
  		hfi1_send_complete(qp, wqe, qp->s_last != qp->s_acked ?
  			IB_WC_SUCCESS : IB_WC_WR_FLUSH_ERR);
  		/* will get called again */
- 		goto done;
+ 		goto done_free_tx;
  	}
  
 -	if (qp->s_flags & (RVT_S_WAIT_RNR | RVT_S_WAIT_ACK))
 +	if (qp->s_flags & (HFI1_S_WAIT_RNR | HFI1_S_WAIT_ACK))
  		goto bail;
  
  	if (cmp_psn(qp->s_psn, qp->s_sending_hpsn) <= 0) {
@@@ -663,16 -757,23 +687,36 @@@
  		ohdr,
  		bth0 | (qp->s_state << 24),
  		bth2,
++<<<<<<< HEAD:drivers/staging/hfi1/rc.c
 +		middle);
 +done:
 +	ret = 1;
 +	goto unlock;
 +
 +bail:
 +	qp->s_flags &= ~HFI1_S_BUSY;
 +unlock:
 +	spin_unlock_irqrestore(&qp->s_lock, flags);
 +	return ret;
++=======
+ 		middle,
+ 		ps);
+ 	return 1;
+ 
+ done_free_tx:
+ 	hfi1_put_txreq(ps->s_txreq);
+ 	ps->s_txreq = NULL;
+ 	return 1;
+ 
+ bail:
+ 	hfi1_put_txreq(ps->s_txreq);
+ 
+ bail_no_tx:
+ 	ps->s_txreq = NULL;
+ 	qp->s_flags &= ~RVT_S_BUSY;
+ 	qp->s_hdrwords = 0;
+ 	return 0;
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/rc.c
  }
  
  /**
diff --cc drivers/staging/hfi1/ruc.c
index c4280b6f47d4,70d1d3422e6e..000000000000
--- a/drivers/staging/hfi1/ruc.c
+++ b/drivers/staging/hfi1/ruc.c
@@@ -53,7 -53,8 +53,12 @@@
  #include "hfi.h"
  #include "mad.h"
  #include "qp.h"
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +#include "sdma.h"
++=======
+ #include "verbs_txreq.h"
+ #include "trace.h"
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/ruc.c
  
  /*
   * Convert the AETH RNR timeout code into the number of microseconds.
@@@ -690,12 -696,13 +695,17 @@@ u32 hfi1_make_grh(struct hfi1_ibport *i
   * Subsequent middles use the copied entry, editing the
   * PSN with 1 or 2 edits.
   */
 -static inline void build_ahg(struct rvt_qp *qp, u32 npsn)
 +static inline void build_ahg(struct hfi1_qp *qp, u32 npsn)
  {
  	struct hfi1_qp_priv *priv = qp->priv;
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +	if (unlikely(qp->s_flags & HFI1_S_AHG_CLEAR))
++=======
+ 
+ 	if (unlikely(qp->s_flags & RVT_S_AHG_CLEAR))
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/ruc.c
  		clear_ahg(qp);
 -	if (!(qp->s_flags & RVT_S_AHG_VALID)) {
 +	if (!(qp->s_flags & HFI1_S_AHG_VALID)) {
  		/* first middle that needs copy  */
  		if (qp->s_ahgidx < 0)
  			qp->s_ahgidx = sdma_ahg_alloc(priv->s_sde);
@@@ -734,11 -741,12 +744,17 @@@
  	}
  }
  
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +void hfi1_make_ruc_header(struct hfi1_qp *qp, struct hfi1_other_headers *ohdr,
 +			  u32 bth0, u32 bth2, int middle)
++=======
+ void hfi1_make_ruc_header(struct rvt_qp *qp, struct hfi1_other_headers *ohdr,
+ 			  u32 bth0, u32 bth2, int middle,
+ 			  struct hfi1_pkt_state *ps)
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/ruc.c
  {
- 	struct hfi1_ibport *ibp = to_iport(qp->ibqp.device, qp->port_num);
  	struct hfi1_qp_priv *priv = qp->priv;
+ 	struct hfi1_ibport *ibp = ps->ibp;
  	u16 lrh0;
  	u32 nwords;
  	u32 extra_bytes;
@@@ -778,12 -787,12 +795,19 @@@
  	if (middle)
  		build_ahg(qp, bth2);
  	else
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +		qp->s_flags &= ~HFI1_S_AHG_VALID;
 +	priv->s_hdr->ibh.lrh[0] = cpu_to_be16(lrh0);
 +	priv->s_hdr->ibh.lrh[1] = cpu_to_be16(qp->remote_ah_attr.dlid);
 +	priv->s_hdr->ibh.lrh[2] =
++=======
+ 		qp->s_flags &= ~RVT_S_AHG_VALID;
+ 	ps->s_txreq->phdr.hdr.lrh[0] = cpu_to_be16(lrh0);
+ 	ps->s_txreq->phdr.hdr.lrh[1] = cpu_to_be16(qp->remote_ah_attr.dlid);
+ 	ps->s_txreq->phdr.hdr.lrh[2] =
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/ruc.c
  		cpu_to_be16(qp->s_hdrwords + nwords + SIZE_OF_CRC);
- 	priv->s_hdr->ibh.lrh[3] = cpu_to_be16(ppd_from_ibp(ibp)->lid |
+ 	ps->s_txreq->phdr.hdr.lrh[3] = cpu_to_be16(ppd_from_ibp(ibp)->lid |
  				       qp->remote_ah_attr.src_path_bits);
  	bth0 |= hfi1_get_pkey(ibp, qp->s_pkey_index);
  	bth0 |= extra_bytes << 20;
@@@ -809,14 -826,15 +833,19 @@@
   * exhausted.  Only allow one CPU to send a packet per QP (tasklet).
   * Otherwise, two threads could send packets out of order.
   */
 -void hfi1_do_send(struct rvt_qp *qp)
 +void hfi1_do_send(struct work_struct *work)
  {
 +	struct iowait *wait = container_of(work, struct iowait, iowork);
 +	struct hfi1_qp *qp = iowait_to_qp(wait);
  	struct hfi1_pkt_state ps;
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +	int (*make_req)(struct hfi1_qp *qp);
++=======
+ 	struct hfi1_qp_priv *priv = qp->priv;
+ 	int (*make_req)(struct rvt_qp *qp, struct hfi1_pkt_state *ps);
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/ruc.c
  	unsigned long flags;
  	unsigned long timeout;
 -	unsigned long timeout_int;
 -	int cpu;
  
  	ps.dev = to_idev(qp->ibqp.device);
  	ps.ibp = to_iport(qp->ibqp.device, qp->port_num);
@@@ -859,18 -888,31 +888,24 @@@
  			 * the send tasklet will be woken up later.
  			 */
  			if (hfi1_verbs_send(qp, &ps))
 -				return;
 +				break;
  			/* Record that s_hdr is empty. */
  			qp->s_hdrwords = 0;
 -			/* allow other tasks to run */
 -			if (unlikely(time_after(jiffies, timeout))) {
 -				if (workqueue_congested(cpu,
 -							ps.ppd->hfi1_wq)) {
 -					spin_lock_irqsave(&qp->s_lock, flags);
 -					qp->s_flags &= ~RVT_S_BUSY;
 -					hfi1_schedule_send(qp);
 -					spin_unlock_irqrestore(&qp->s_lock,
 -							       flags);
 -					this_cpu_inc(
 -						*ps.ppd->dd->send_schedule);
 -					return;
 -				}
 -				cond_resched();
 -				this_cpu_inc(*ps.ppd->dd->send_schedule);
 -				timeout = jiffies + (timeout_int) / 8;
 -			}
 -			spin_lock_irqsave(&qp->s_lock, flags);
  		}
 +
 +		/* allow other tasks to run */
 +		if (unlikely(time_after(jiffies, timeout))) {
 +			cond_resched();
 +			ps.ppd->dd->verbs_dev.n_send_schedule++;
 +			timeout = jiffies + SEND_RESCHED_TIMEOUT;
 +		}
++<<<<<<< HEAD:drivers/staging/hfi1/ruc.c
 +	} while (make_req(qp));
++=======
+ 	} while (make_req(qp, &ps));
+ 
+ 	spin_unlock_irqrestore(&qp->s_lock, flags);
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/ruc.c
  }
  
  /*
diff --cc drivers/staging/hfi1/uc.c
index fc90d4f544e4,77431b145305..000000000000
--- a/drivers/staging/hfi1/uc.c
+++ b/drivers/staging/hfi1/uc.c
@@@ -59,9 -59,11 +59,13 @@@
   * hfi1_make_uc_req - construct a request packet (SEND, RDMA write)
   * @qp: a pointer to the QP
   *
 - * Assume s_lock is held.
 - *
   * Return 1 if constructed; otherwise, return 0.
   */
++<<<<<<< HEAD:drivers/staging/hfi1/uc.c
 +int hfi1_make_uc_req(struct hfi1_qp *qp)
++=======
+ int hfi1_make_uc_req(struct rvt_qp *qp, struct hfi1_pkt_state *ps)
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/uc.c
  {
  	struct hfi1_qp_priv *priv = qp->priv;
  	struct hfi1_other_headers *ohdr;
@@@ -71,16 -72,18 +75,24 @@@
  	u32 bth0 = 0;
  	u32 len;
  	u32 pmtu = qp->pmtu;
- 	int ret = 0;
  	int middle = 0;
  
++<<<<<<< HEAD:drivers/staging/hfi1/uc.c
 +	spin_lock_irqsave(&qp->s_lock, flags);
 +
 +	if (!(ib_hfi1_state_ops[qp->state] & HFI1_PROCESS_SEND_OK)) {
 +		if (!(ib_hfi1_state_ops[qp->state] & HFI1_FLUSH_SEND))
++=======
+ 	ps->s_txreq = get_txreq(ps->dev, qp);
+ 	if (IS_ERR(ps->s_txreq))
+ 		goto bail_no_tx;
+ 
+ 	if (!(ib_rvt_state_ops[qp->state] & RVT_PROCESS_SEND_OK)) {
+ 		if (!(ib_rvt_state_ops[qp->state] & RVT_FLUSH_SEND))
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/uc.c
  			goto bail;
  		/* We are in the error state, flush the work request. */
 -		smp_read_barrier_depends(); /* see post_one_send() */
 -		if (qp->s_last == ACCESS_ONCE(qp->s_head))
 +		if (qp->s_last == qp->s_head)
  			goto bail;
  		/* If DMAs are in progress, we can't flush immediately. */
  		if (atomic_read(&priv->s_iowait.sdma_busy)) {
@@@ -88,17 -91,17 +100,17 @@@
  			goto bail;
  		}
  		clear_ahg(qp);
 -		wqe = rvt_get_swqe_ptr(qp, qp->s_last);
 +		wqe = get_swqe_ptr(qp, qp->s_last);
  		hfi1_send_complete(qp, wqe, IB_WC_WR_FLUSH_ERR);
- 		goto done;
+ 		goto done_free_tx;
  	}
  
- 	ohdr = &priv->s_hdr->ibh.u.oth;
+ 	ohdr = &ps->s_txreq->phdr.hdr.u.oth;
  	if (qp->remote_ah_attr.ah_flags & IB_AH_GRH)
- 		ohdr = &priv->s_hdr->ibh.u.l.oth;
+ 		ohdr = &ps->s_txreq->phdr.hdr.u.l.oth;
  
  	/* Get the next send request. */
 -	wqe = rvt_get_swqe_ptr(qp, qp->s_cur);
 +	wqe = get_swqe_ptr(qp, qp->s_cur);
  	qp->s_wqe = NULL;
  	switch (qp->s_state) {
  	default:
@@@ -235,16 -238,22 +247,35 @@@
  	qp->s_cur_sge = &qp->s_sge;
  	qp->s_cur_size = len;
  	hfi1_make_ruc_header(qp, ohdr, bth0 | (qp->s_state << 24),
++<<<<<<< HEAD:drivers/staging/hfi1/uc.c
 +			     mask_psn(qp->s_next_psn++), middle);
 +done:
 +	ret = 1;
 +	goto unlock;
 +
 +bail:
 +	qp->s_flags &= ~HFI1_S_BUSY;
 +unlock:
 +	spin_unlock_irqrestore(&qp->s_lock, flags);
 +	return ret;
++=======
+ 			     mask_psn(qp->s_psn++), middle, ps);
+ 	return 1;
+ 
+ done_free_tx:
+ 	hfi1_put_txreq(ps->s_txreq);
+ 	ps->s_txreq = NULL;
+ 	return 1;
+ 
+ bail:
+ 	hfi1_put_txreq(ps->s_txreq);
+ 
+ bail_no_tx:
+ 	ps->s_txreq = NULL;
+ 	qp->s_flags &= ~RVT_S_BUSY;
+ 	qp->s_hdrwords = 0;
+ 	return 0;
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/uc.c
  }
  
  /**
diff --cc drivers/staging/hfi1/ud.c
index a7f67b0111da,a7118bca0d2a..000000000000
--- a/drivers/staging/hfi1/ud.c
+++ b/drivers/staging/hfi1/ud.c
@@@ -260,9 -262,11 +261,13 @@@ drop
   * hfi1_make_ud_req - construct a UD request packet
   * @qp: the QP
   *
 - * Assume s_lock is held.
 - *
   * Return 1 if constructed; otherwise, return 0.
   */
++<<<<<<< HEAD:drivers/staging/hfi1/ud.c
 +int hfi1_make_ud_req(struct hfi1_qp *qp)
++=======
+ int hfi1_make_ud_req(struct rvt_qp *qp, struct hfi1_pkt_state *ps)
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/ud.c
  {
  	struct hfi1_qp_priv *priv = qp->priv;
  	struct hfi1_other_headers *ohdr;
@@@ -279,29 -282,33 +284,37 @@@
  	int next_cur;
  	u8 sc5;
  
++<<<<<<< HEAD:drivers/staging/hfi1/ud.c
 +	spin_lock_irqsave(&qp->s_lock, flags);
 +
 +	if (!(ib_hfi1_state_ops[qp->state] & HFI1_PROCESS_NEXT_SEND_OK)) {
 +		if (!(ib_hfi1_state_ops[qp->state] & HFI1_FLUSH_SEND))
++=======
+ 	ps->s_txreq = get_txreq(ps->dev, qp);
+ 	if (IS_ERR(ps->s_txreq))
+ 		goto bail_no_tx;
+ 
+ 	if (!(ib_rvt_state_ops[qp->state] & RVT_PROCESS_NEXT_SEND_OK)) {
+ 		if (!(ib_rvt_state_ops[qp->state] & RVT_FLUSH_SEND))
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/ud.c
  			goto bail;
  		/* We are in the error state, flush the work request. */
 -		smp_read_barrier_depends(); /* see post_one_send */
 -		if (qp->s_last == ACCESS_ONCE(qp->s_head))
 +		if (qp->s_last == qp->s_head)
  			goto bail;
  		/* If DMAs are in progress, we can't flush immediately. */
  		if (atomic_read(&priv->s_iowait.sdma_busy)) {
 -			qp->s_flags |= RVT_S_WAIT_DMA;
 +			qp->s_flags |= HFI1_S_WAIT_DMA;
  			goto bail;
  		}
 -		wqe = rvt_get_swqe_ptr(qp, qp->s_last);
 +		wqe = get_swqe_ptr(qp, qp->s_last);
  		hfi1_send_complete(qp, wqe, IB_WC_WR_FLUSH_ERR);
- 		goto done;
+ 		goto done_free_tx;
  	}
  
 -	/* see post_one_send() */
 -	smp_read_barrier_depends();
 -	if (qp->s_cur == ACCESS_ONCE(qp->s_head))
 +	if (qp->s_cur == qp->s_head)
  		goto bail;
  
 -	wqe = rvt_get_swqe_ptr(qp, qp->s_cur);
 +	wqe = get_swqe_ptr(qp, qp->s_cur);
  	next_cur = qp->s_cur + 1;
  	if (next_cur >= qp->s_size)
  		next_cur = 0;
@@@ -421,15 -432,21 +436,33 @@@
  	priv->s_hdr->tx_flags = 0;
  	priv->s_hdr->sde = NULL;
  
++<<<<<<< HEAD:drivers/staging/hfi1/ud.c
 +done:
 +	ret = 1;
 +	goto unlock;
 +
 +bail:
 +	qp->s_flags &= ~HFI1_S_BUSY;
 +unlock:
 +	spin_unlock_irqrestore(&qp->s_lock, flags);
 +	return ret;
++=======
+ 	return 1;
+ 
+ done_free_tx:
+ 	hfi1_put_txreq(ps->s_txreq);
+ 	ps->s_txreq = NULL;
+ 	return 1;
+ 
+ bail:
+ 	hfi1_put_txreq(ps->s_txreq);
+ 
+ bail_no_tx:
+ 	ps->s_txreq = NULL;
+ 	qp->s_flags &= ~RVT_S_BUSY;
+ 	qp->s_hdrwords = 0;
+ 	return 0;
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/ud.c
  }
  
  /*
diff --cc drivers/staging/hfi1/user_sdma.h
index 7ebbc4634989,d89d29b76199..000000000000
--- a/drivers/staging/hfi1/user_sdma.h
+++ b/drivers/staging/hfi1/user_sdma.h
@@@ -47,45 -44,51 +47,57 @@@
   * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
   *
   */
 +#include <linux/device.h>
 +#include <linux/wait.h>
  
 -#ifndef HFI1_VERBS_TXREQ_H
 -#define HFI1_VERBS_TXREQ_H
 +#include "common.h"
 +#include "iowait.h"
  
 -#include <linux/types.h>
 -#include <linux/slab.h>
++<<<<<<< HEAD:drivers/staging/hfi1/user_sdma.h
 +#define EXP_TID_TIDLEN_MASK   0x7FFULL
 +#define EXP_TID_TIDLEN_SHIFT  0
 +#define EXP_TID_TIDCTRL_MASK  0x3ULL
 +#define EXP_TID_TIDCTRL_SHIFT 20
 +#define EXP_TID_TIDIDX_MASK   0x7FFULL
 +#define EXP_TID_TIDIDX_SHIFT  22
 +#define EXP_TID_GET(tid, field)	\
 +	(((tid) >> EXP_TID_TID##field##_SHIFT) & EXP_TID_TID##field##_MASK)
  
 -#include "verbs.h"
 -#include "sdma_txreq.h"
 -#include "iowait.h"
 +extern uint extended_psn;
  
 +struct hfi1_user_sdma_pkt_q {
 +	struct list_head list;
 +	unsigned ctxt;
 +	unsigned subctxt;
 +	u16 n_max_reqs;
 +	atomic_t n_reqs;
 +	u16 reqidx;
 +	struct hfi1_devdata *dd;
 +	struct kmem_cache *txreq_cache;
 +	struct user_sdma_request *reqs;
 +	struct iowait busy;
 +	unsigned state;
 +	wait_queue_head_t wait;
 +	unsigned long unpinned;
++=======
+ struct verbs_txreq {
+ 	struct hfi1_pio_header	phdr;
+ 	struct sdma_txreq       txreq;
+ 	struct rvt_qp           *qp;
+ 	struct rvt_swqe         *wqe;
+ 	struct rvt_mregion	*mr;
+ 	struct rvt_sge_state    *ss;
+ 	struct sdma_engine     *sde;
+ 	u16                     hdr_dwords;
++>>>>>>> bb5df5f9eea6 (staging/rdma/hfi1: Remove header memcpy from sdma send path.):drivers/staging/rdma/hfi1/verbs_txreq.h
  };
  
 -struct hfi1_ibdev;
 -struct verbs_txreq *__get_txreq(struct hfi1_ibdev *dev,
 -				struct rvt_qp *qp);
 -
 -static inline struct verbs_txreq *get_txreq(struct hfi1_ibdev *dev,
 -					    struct rvt_qp *qp)
 -{
 -	struct verbs_txreq *tx;
 -
 -	tx = kmem_cache_alloc(dev->verbs_txreq_cache, GFP_ATOMIC);
 -	if (unlikely(!tx)) {
 -		/* call slow path to get the lock */
 -		tx = __get_txreq(dev, qp);
 -		if (IS_ERR(tx))
 -			return tx;
 -	}
 -	tx->qp = qp;
 -	tx->mr = NULL;
 -	return tx;
 -}
 -
 -void hfi1_put_txreq(struct verbs_txreq *tx);
 -int verbs_txreq_init(struct hfi1_ibdev *dev);
 -void verbs_txreq_exit(struct hfi1_ibdev *dev);
 +struct hfi1_user_sdma_comp_q {
 +	u16 nentries;
 +	struct hfi1_sdma_comp_entry *comps;
 +};
  
 -#endif                         /* HFI1_VERBS_TXREQ_H */
 +int hfi1_user_sdma_alloc_queues(struct hfi1_ctxtdata *, struct file *);
 +int hfi1_user_sdma_free_queues(struct hfi1_filedata *);
 +int hfi1_user_sdma_process_request(struct file *, struct iovec *, unsigned long,
 +				   unsigned long *);
* Unmerged path drivers/staging/rdma/hfi1/verbs.h
diff --git a/drivers/staging/hfi1/diag.c b/drivers/staging/hfi1/diag.c
index 33bfff90ae80..805b662b95d2 100644
--- a/drivers/staging/hfi1/diag.c
+++ b/drivers/staging/hfi1/diag.c
@@ -70,6 +70,7 @@
 #include "hfi.h"
 #include "device.h"
 #include "common.h"
+#include "verbs_txreq.h"
 #include "trace.h"
 
 #undef pr_fmt
@@ -1682,8 +1683,6 @@ int snoop_send_dma_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 int snoop_send_pio_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 			   u64 pbc)
 {
-	struct hfi1_qp_priv *priv = qp->priv;
-	struct ahg_ib_header *ahdr = priv->s_hdr;
 	u32 hdrwords = qp->s_hdrwords;
 	struct hfi1_sge_state *ss = qp->s_cur_sge;
 	u32 len = qp->s_cur_size;
@@ -1691,7 +1690,7 @@ int snoop_send_pio_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 	u32 plen = hdrwords + dwords + 2; /* includes pbc */
 	struct hfi1_pportdata *ppd = ps->ppd;
 	struct snoop_packet *s_packet = NULL;
-	u32 *hdr = (u32 *)&ahdr->ibh;
+	u32 *hdr = (u32 *)&ps->s_txreq->phdr.hdr;
 	u32 length = 0;
 	struct hfi1_sge_state temp_ss;
 	void *data = NULL;
@@ -1702,7 +1701,7 @@ int snoop_send_pio_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 	struct capture_md md;
 	u32 vl;
 	u32 hdr_len = hdrwords << 2;
-	u32 tlen = HFI1_GET_PKT_LEN(&ahdr->ibh);
+	u32 tlen = HFI1_GET_PKT_LEN(&ps->s_txreq->phdr.hdr);
 
 	md.u.pbc = 0;
 
@@ -1729,7 +1728,7 @@ int snoop_send_pio_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 		md.port = 1;
 		md.dir = PKT_DIR_EGRESS;
 		if (likely(pbc == 0)) {
-			vl = be16_to_cpu(ahdr->ibh.lrh[0]) >> 12;
+			vl = be16_to_cpu(ps->s_txreq->phdr.hdr.lrh[0]) >> 12;
 			md.u.pbc = create_pbc(ppd, 0, qp->s_srate, vl, plen);
 		} else {
 			md.u.pbc = 0;
@@ -1791,7 +1790,7 @@ int snoop_send_pio_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 		ret = HFI1_FILTER_HIT;
 	} else {
 		ret = ppd->dd->hfi1_snoop.filter_callback(
-					&ahdr->ibh,
+					&ps->s_txreq->phdr.hdr,
 					NULL,
 					ppd->dd->hfi1_snoop.filter_value);
 	}
@@ -1823,9 +1822,16 @@ int snoop_send_pio_handler(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 				spin_unlock_irqrestore(&qp->s_lock, flags);
 			} else if (qp->ibqp.qp_type == IB_QPT_RC) {
 				spin_lock_irqsave(&qp->s_lock, flags);
-				hfi1_rc_send_complete(qp, &ahdr->ibh);
+				hfi1_rc_send_complete(qp,
+						      &ps->s_txreq->phdr.hdr);
 				spin_unlock_irqrestore(&qp->s_lock, flags);
 			}
+
+			/*
+			 * If snoop is dropping the packet we need to put the
+			 * txreq back because no one else will.
+			 */
+			hfi1_put_txreq(ps->s_txreq);
 			return 0;
 		}
 		break;
* Unmerged path drivers/staging/hfi1/rc.c
* Unmerged path drivers/staging/hfi1/ruc.c
* Unmerged path drivers/staging/hfi1/uc.c
* Unmerged path drivers/staging/hfi1/ud.c
* Unmerged path drivers/staging/hfi1/user_sdma.h
diff --git a/drivers/staging/hfi1/verbs.c b/drivers/staging/hfi1/verbs.c
index d228eb7fc4f0..975538410c7e 100644
--- a/drivers/staging/hfi1/verbs.c
+++ b/drivers/staging/hfi1/verbs.c
@@ -923,8 +923,7 @@ bail_txadd:
  * NOTE: DMA mapping is held in the tx until completed in the ring or
  *       the tx desc is freed without having been submitted to the ring
  *
- * This routine insures the following all the helper routine
- * calls succeed.
+ * This routine ensures all the helper routine calls succeed.
  */
 /* New API */
 static int build_verbs_tx_desc(
@@ -936,10 +935,9 @@ static int build_verbs_tx_desc(
 	u64 pbc)
 {
 	int ret = 0;
-	struct hfi1_pio_header *phdr;
+	struct hfi1_pio_header *phdr = &tx->phdr;
 	u16 hdrbytes = tx->hdr_dwords << 2;
 
-	phdr = &tx->phdr;
 	if (!ahdr->ahgcount) {
 		ret = sdma_txinit_ahg(
 			&tx->txreq,
@@ -953,29 +951,14 @@ static int build_verbs_tx_desc(
 		if (ret)
 			goto bail_txadd;
 		phdr->pbc = cpu_to_le64(pbc);
-		memcpy(&phdr->hdr, &ahdr->ibh, hdrbytes - sizeof(phdr->pbc));
-		/* add the header */
 		ret = sdma_txadd_kvaddr(
 			sde->dd,
 			&tx->txreq,
-			&tx->phdr,
-			tx->hdr_dwords << 2);
+			phdr,
+			hdrbytes);
 		if (ret)
 			goto bail_txadd;
 	} else {
-		struct hfi1_other_headers *sohdr = &ahdr->ibh.u.oth;
-		struct hfi1_other_headers *dohdr = &phdr->hdr.u.oth;
-
-		/* needed in rc_send_complete() */
-		phdr->hdr.lrh[0] = ahdr->ibh.lrh[0];
-		if ((be16_to_cpu(phdr->hdr.lrh[0]) & 3) == HFI1_LRH_GRH) {
-			sohdr = &ahdr->ibh.u.l.oth;
-			dohdr = &phdr->hdr.u.l.oth;
-		}
-		/* opcode */
-		dohdr->bth[0] = sohdr->bth[0];
-		/* PSN/ACK  */
-		dohdr->bth[2] = sohdr->bth[2];
 		ret = sdma_txinit_ahg(
 			&tx->txreq,
 			ahdr->tx_flags,
@@ -1013,6 +996,7 @@ int hfi1_verbs_send_dma(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 	u8 sc5 = priv->s_sc;
 
 	int ret;
+	struct hfi1_ibdev *tdev;
 
 	if (!list_empty(&priv->s_iowait.tx_head)) {
 		stx = list_first_entry(
@@ -1027,7 +1011,10 @@ int hfi1_verbs_send_dma(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 		return ret;
 	}
 
-	tx = get_txreq(dev, qp);
+	tx = ps->s_txreq;
+
+	tdev = to_idev(qp->ibqp.device);
+
 	if (IS_ERR(tx))
 		goto bail_tx;
 
@@ -1049,7 +1036,8 @@ int hfi1_verbs_send_dma(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 	ret = build_verbs_tx_desc(tx->sde, ss, len, tx, ahdr, pbc);
 	if (unlikely(ret))
 		goto bail_build;
-	trace_output_ibhdr(dd_from_ibdev(qp->ibqp.device), &ahdr->ibh);
+	trace_output_ibhdr(dd_from_ibdev(qp->ibqp.device),
+			   &ps->s_txreq->phdr.hdr);
 	ret =  sdma_send_txreq(tx->sde, &priv->s_iowait, &tx->txreq);
 	if (unlikely(ret == -ECOMM))
 		goto bail_ecomm;
@@ -1125,27 +1113,29 @@ int hfi1_verbs_send_pio(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 			u64 pbc)
 {
 	struct hfi1_qp_priv *priv = qp->priv;
-	struct ahg_ib_header *ahdr = priv->s_hdr;
 	u32 hdrwords = qp->s_hdrwords;
 	struct hfi1_sge_state *ss = qp->s_cur_sge;
 	u32 len = qp->s_cur_size;
 	u32 dwords = (len + 3) >> 2;
 	u32 plen = hdrwords + dwords + 2; /* includes pbc */
 	struct hfi1_pportdata *ppd = ps->ppd;
-	u32 *hdr = (u32 *)&ahdr->ibh;
+	u32 *hdr = (u32 *)&ps->s_txreq->phdr.hdr;
 	u64 pbc_flags = 0;
 	u32 sc5;
 	unsigned long flags = 0;
 	struct send_context *sc;
 	struct pio_buf *pbuf;
 	int wc_status = IB_WC_SUCCESS;
+	int ret = 0;
 
 	/* vl15 special case taken care of in ud.c */
 	sc5 = priv->s_sc;
 	sc = qp_to_send_context(qp, sc5);
 
-	if (!sc)
-		return -EINVAL;
+	if (!sc) {
+		ret = -EINVAL;
+		goto bail;
+	}
 	if (likely(pbc == 0)) {
 		u32 vl = sc_to_vlt(dd_from_ibdev(qp->ibqp.device), sc5);
 		/* set PBC_DC_INFO bit (aka SC[4]) in pbc_flags */
@@ -1173,7 +1163,8 @@ int hfi1_verbs_send_pio(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 			 * so lets continue to queue the request.
 			 */
 			hfi1_cdbg(PIO, "alloc failed. state active, queuing");
-			return no_bufs_available(qp, sc);
+			ret = no_bufs_available(qp, sc);
+			goto bail;
 		}
 	}
 
@@ -1196,7 +1187,8 @@ int hfi1_verbs_send_pio(struct hfi1_qp *qp, struct hfi1_pkt_state *ps,
 		}
 	}
 
-	trace_output_ibhdr(dd_from_ibdev(qp->ibqp.device), &ahdr->ibh);
+	trace_output_ibhdr(dd_from_ibdev(qp->ibqp.device),
+			   &ps->s_txreq->phdr.hdr);
 
 	if (qp->s_rdma_mr) {
 		hfi1_put_mr(qp->s_rdma_mr);
@@ -1210,10 +1202,15 @@ pio_bail:
 		spin_unlock_irqrestore(&qp->s_lock, flags);
 	} else if (qp->ibqp.qp_type == IB_QPT_RC) {
 		spin_lock_irqsave(&qp->s_lock, flags);
-		hfi1_rc_send_complete(qp, &ahdr->ibh);
+		hfi1_rc_send_complete(qp, &ps->s_txreq->phdr.hdr);
 		spin_unlock_irqrestore(&qp->s_lock, flags);
 	}
-	return 0;
+
+	ret = 0;
+
+bail:
+	hfi1_put_txreq(ps->s_txreq);
+	return ret;
 }
 
 /*
@@ -1312,8 +1309,6 @@ bad:
 int hfi1_verbs_send(struct hfi1_qp *qp, struct hfi1_pkt_state *ps)
 {
 	struct hfi1_devdata *dd = dd_from_ibdev(qp->ibqp.device);
-	struct hfi1_qp_priv *priv = qp->priv;
-	struct ahg_ib_header *ahdr = priv->s_hdr;
 	int ret;
 	int pio = 0;
 	unsigned long flags = 0;
@@ -1327,7 +1322,7 @@ int hfi1_verbs_send(struct hfi1_qp *qp, struct hfi1_pkt_state *ps)
 	    !(dd->flags & HFI1_HAS_SEND_DMA))
 		pio = 1;
 
-	ret = egress_pkey_check(dd->pport, &ahdr->ibh, qp);
+	ret = egress_pkey_check(dd->pport, &ps->s_txreq->phdr.hdr, qp);
 	if (unlikely(ret)) {
 		/*
 		 * The value we are returning here does not get propagated to
* Unmerged path drivers/staging/rdma/hfi1/verbs.h
