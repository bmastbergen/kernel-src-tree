netfilter: bridge: don't leak skb in error paths

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Florian Westphal <fw@strlen.de>
commit dd302b59bde0149c20df7278c0d36c765e66afbd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/dd302b59.failed

br_nf_dev_queue_xmit must free skb in its error path.
NF_DROP is misleading -- its an okfn, not a netfilter hook.

Fixes: 462fb2af9788a ("bridge : Sanitize skb before it enters the IP stack")
Fixes: efb6de9b4ba00 ("netfilter: bridge: forward IPv6 fragmented packets")
	Signed-off-by: Florian Westphal <fw@strlen.de>
	Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
(cherry picked from commit dd302b59bde0149c20df7278c0d36c765e66afbd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/bridge/br_netfilter.c
diff --cc net/bridge/br_netfilter.c
index bfa28cea8c79,c8b9bcfe997e..000000000000
--- a/net/bridge/br_netfilter.c
+++ b/net/bridge/br_netfilter.c
@@@ -848,29 -667,134 +848,99 @@@ static unsigned int br_nf_forward_arp(c
  	return NF_STOLEN;
  }
  
 -#if IS_ENABLED(CONFIG_NF_DEFRAG_IPV4) || IS_ENABLED(CONFIG_NF_DEFRAG_IPV6)
 -static int br_nf_push_frag_xmit(struct sock *sk, struct sk_buff *skb)
 -{
 -	struct brnf_frag_data *data;
 -	int err;
 -
 -	data = this_cpu_ptr(&brnf_frag_data_storage);
 -	err = skb_cow_head(skb, data->size);
 -
 -	if (err) {
 -		kfree_skb(skb);
 -		return 0;
 -	}
 -
 -	if (data->vlan_tci) {
 -		skb->vlan_tci = data->vlan_tci;
 -		skb->vlan_proto = data->vlan_proto;
 -	}
 -
 -	skb_copy_to_linear_data_offset(skb, -data->size, data->mac, data->size);
 -	__skb_push(skb, data->encap_size);
 -
 -	nf_bridge_info_free(skb);
 -	return br_dev_queue_push_xmit(sk, skb);
 -}
 -#endif
 -
 -#if IS_ENABLED(CONFIG_NF_DEFRAG_IPV4)
 -static int br_nf_ip_fragment(struct sock *sk, struct sk_buff *skb,
 -			     int (*output)(struct sock *, struct sk_buff *))
 -{
 -	unsigned int mtu = ip_skb_dst_mtu(skb);
 -	struct iphdr *iph = ip_hdr(skb);
 -	struct rtable *rt = skb_rtable(skb);
 -	struct net_device *dev = rt->dst.dev;
 -
 -	if (unlikely(((iph->frag_off & htons(IP_DF)) && !skb->ignore_df) ||
 -		     (IPCB(skb)->frag_max_size &&
 -		      IPCB(skb)->frag_max_size > mtu))) {
 -		IP_INC_STATS(dev_net(dev), IPSTATS_MIB_FRAGFAILS);
 -		kfree_skb(skb);
 -		return -EMSGSIZE;
 -	}
 -
 -	return ip_do_fragment(sk, skb, output);
 -}
 -#endif
 -
 -static unsigned int nf_bridge_mtu_reduction(const struct sk_buff *skb)
 -{
 -	if (skb->nf_bridge->orig_proto == BRNF_PROTO_PPPOE)
 -		return PPPOE_SES_HLEN;
 -	return 0;
 -}
 -
 +#if IS_ENABLED(CONFIG_NF_CONNTRACK_IPV4)
  static int br_nf_dev_queue_xmit(struct sock *sk, struct sk_buff *skb)
  {
 -	struct nf_bridge_info *nf_bridge;
 -	unsigned int mtu_reserved;
 +	int ret;
  
++<<<<<<< HEAD:net/bridge/br_netfilter.c
 +	if (skb->nfct != NULL && skb->protocol == htons(ETH_P_IP) &&
 +	    skb->len + nf_bridge_mtu_reduction(skb) > skb->dev->mtu &&
 +	    !skb_is_gso(skb)) {
 +		if (br_parse_ip_options(skb))
 +			/* Drop invalid packet */
 +			return NF_DROP;
 +		ret = ip_fragment(sk, skb, br_dev_queue_push_xmit);
 +	} else
 +		ret = br_dev_queue_push_xmit(sk, skb);
 +
 +	return ret;
++=======
+ 	mtu_reserved = nf_bridge_mtu_reduction(skb);
+ 
+ 	if (skb_is_gso(skb) || skb->len + mtu_reserved <= skb->dev->mtu) {
+ 		nf_bridge_info_free(skb);
+ 		return br_dev_queue_push_xmit(sk, skb);
+ 	}
+ 
+ 	nf_bridge = nf_bridge_info_get(skb);
+ 
+ #if IS_ENABLED(CONFIG_NF_DEFRAG_IPV4)
+ 	/* This is wrong! We should preserve the original fragment
+ 	 * boundaries by preserving frag_list rather than refragmenting.
+ 	 */
+ 	if (skb->protocol == htons(ETH_P_IP)) {
+ 		struct brnf_frag_data *data;
+ 
+ 		if (br_validate_ipv4(skb))
+ 			goto drop;
+ 
+ 		IPCB(skb)->frag_max_size = nf_bridge->frag_max_size;
+ 
+ 		nf_bridge_update_protocol(skb);
+ 
+ 		data = this_cpu_ptr(&brnf_frag_data_storage);
+ 
+ 		data->vlan_tci = skb->vlan_tci;
+ 		data->vlan_proto = skb->vlan_proto;
+ 		data->encap_size = nf_bridge_encap_header_len(skb);
+ 		data->size = ETH_HLEN + data->encap_size;
+ 
+ 		skb_copy_from_linear_data_offset(skb, -data->size, data->mac,
+ 						 data->size);
+ 
+ 		return br_nf_ip_fragment(sk, skb, br_nf_push_frag_xmit);
+ 	}
+ #endif
+ #if IS_ENABLED(CONFIG_NF_DEFRAG_IPV6)
+ 	if (skb->protocol == htons(ETH_P_IPV6)) {
+ 		const struct nf_ipv6_ops *v6ops = nf_get_ipv6_ops();
+ 		struct brnf_frag_data *data;
+ 
+ 		if (br_validate_ipv6(skb))
+ 			goto drop;
+ 
+ 		IP6CB(skb)->frag_max_size = nf_bridge->frag_max_size;
+ 
+ 		nf_bridge_update_protocol(skb);
+ 
+ 		data = this_cpu_ptr(&brnf_frag_data_storage);
+ 		data->encap_size = nf_bridge_encap_header_len(skb);
+ 		data->size = ETH_HLEN + data->encap_size;
+ 
+ 		skb_copy_from_linear_data_offset(skb, -data->size, data->mac,
+ 						 data->size);
+ 
+ 		if (v6ops)
+ 			return v6ops->fragment(sk, skb, br_nf_push_frag_xmit);
+ 
+ 		kfree_skb(skb);
+ 		return -EMSGSIZE;
+ 	}
+ #endif
+ 	nf_bridge_info_free(skb);
+ 	return br_dev_queue_push_xmit(sk, skb);
+  drop:
+ 	kfree_skb(skb);
+ 	return 0;
++>>>>>>> dd302b59bde0 (netfilter: bridge: don't leak skb in error paths):net/bridge/br_netfilter_hooks.c
  }
 +#else
 +static int br_nf_dev_queue_xmit(struct sock *sk, struct sk_buff *skb)
 +{
 +        return br_dev_queue_push_xmit(sk, skb);
 +}
 +#endif
  
  /* PF_BRIDGE/POST_ROUTING ********************************************/
  static unsigned int br_nf_post_routing(const struct nf_hook_ops *ops,
* Unmerged path net/bridge/br_netfilter.c
