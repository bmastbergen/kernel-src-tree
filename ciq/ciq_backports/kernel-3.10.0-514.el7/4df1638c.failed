sched/deadline: Fix overflow to handle period==0 and deadline!=0

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
commit-author Steven Rostedt <rostedt@goodmis.org>
commit 4df1638cfaf9b2b7ad993979a41965acab9cd156
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/4df1638c.failed

While debugging the crash with the bad nr_running accounting, I hit
another bug where, after running my sched deadline test, I was getting
failures to take a CPU offline. It was giving me a -EBUSY error.

Adding a bunch of trace_printk()s around, I found that the cpu
notifier that called sched_cpu_inactive() was returning a failure. The
overflow value was coming up negative?

Talking this over with Juri, the problem is that the total_bw update was
suppose to be made by dl_overflow() which, during my tests, seemed to
not be called. Adding more trace_printk()s, it wasn't that it wasn't
called, but it exited out right away with the check of new_bw being
equal to p->dl.dl_bw. The new_bw calculates the ratio between period and
runtime. The bug is that if you set a deadline, you do not need to set
a period if you plan on the period being equal to the deadline. That
is, if period is zero and deadline is not, then the system call should
set the period to be equal to the deadline. This is done elsewhere in
the code.

The fix is easy, check if period is set, and if it is not, then use the
deadline.

	Cc: Juri Lelli <juri.lelli@gmail.com>
	Cc: Ingo Molnar <mingo@kernel.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Steven Rostedt <rostedt@goodmis.org>
	Signed-off-by: Peter Zijlstra <peterz@infradead.org>
Link: http://lkml.kernel.org/r/20140219135335.7e74abd4@gandalf.local.home
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
(cherry picked from commit 4df1638cfaf9b2b7ad993979a41965acab9cd156)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/core.c
diff --cc kernel/sched/core.c
index f167fdc57a94,24914488da41..000000000000
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@@ -1974,8 -1872,121 +1974,122 @@@ void sched_fork(unsigned long clone_fla
  #endif
  
  	put_cpu();
 -	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ unsigned long to_ratio(u64 period, u64 runtime)
+ {
+ 	if (runtime == RUNTIME_INF)
+ 		return 1ULL << 20;
+ 
+ 	/*
+ 	 * Doing this here saves a lot of checks in all
+ 	 * the calling paths, and returning zero seems
+ 	 * safe for them anyway.
+ 	 */
+ 	if (period == 0)
+ 		return 0;
+ 
+ 	return div64_u64(runtime << 20, period);
+ }
+ 
+ #ifdef CONFIG_SMP
+ inline struct dl_bw *dl_bw_of(int i)
+ {
+ 	return &cpu_rq(i)->rd->dl_bw;
+ }
+ 
+ static inline int dl_bw_cpus(int i)
+ {
+ 	struct root_domain *rd = cpu_rq(i)->rd;
+ 	int cpus = 0;
+ 
+ 	for_each_cpu_and(i, rd->span, cpu_active_mask)
+ 		cpus++;
+ 
+ 	return cpus;
+ }
+ #else
+ inline struct dl_bw *dl_bw_of(int i)
+ {
+ 	return &cpu_rq(i)->dl.dl_bw;
+ }
+ 
+ static inline int dl_bw_cpus(int i)
+ {
+ 	return 1;
+ }
+ #endif
+ 
+ static inline
+ void __dl_clear(struct dl_bw *dl_b, u64 tsk_bw)
+ {
+ 	dl_b->total_bw -= tsk_bw;
+ }
+ 
+ static inline
+ void __dl_add(struct dl_bw *dl_b, u64 tsk_bw)
+ {
+ 	dl_b->total_bw += tsk_bw;
+ }
+ 
+ static inline
+ bool __dl_overflow(struct dl_bw *dl_b, int cpus, u64 old_bw, u64 new_bw)
+ {
+ 	return dl_b->bw != -1 &&
+ 	       dl_b->bw * cpus < dl_b->total_bw - old_bw + new_bw;
+ }
+ 
+ /*
+  * We must be sure that accepting a new task (or allowing changing the
+  * parameters of an existing one) is consistent with the bandwidth
+  * constraints. If yes, this function also accordingly updates the currently
+  * allocated bandwidth to reflect the new situation.
+  *
+  * This function is called while holding p's rq->lock.
+  */
+ static int dl_overflow(struct task_struct *p, int policy,
+ 		       const struct sched_attr *attr)
+ {
+ 
+ 	struct dl_bw *dl_b = dl_bw_of(task_cpu(p));
+ 	u64 period = attr->sched_period ?: attr->sched_deadline;
+ 	u64 runtime = attr->sched_runtime;
+ 	u64 new_bw = dl_policy(policy) ? to_ratio(period, runtime) : 0;
+ 	int cpus, err = -1;
+ 
+ 	if (new_bw == p->dl.dl_bw)
+ 		return 0;
+ 
+ 	/*
+ 	 * Either if a task, enters, leave, or stays -deadline but changes
+ 	 * its parameters, we may need to update accordingly the total
+ 	 * allocated bandwidth of the container.
+ 	 */
+ 	raw_spin_lock(&dl_b->lock);
+ 	cpus = dl_bw_cpus(task_cpu(p));
+ 	if (dl_policy(policy) && !task_has_dl_policy(p) &&
+ 	    !__dl_overflow(dl_b, cpus, 0, new_bw)) {
+ 		__dl_add(dl_b, new_bw);
+ 		err = 0;
+ 	} else if (dl_policy(policy) && task_has_dl_policy(p) &&
+ 		   !__dl_overflow(dl_b, cpus, p->dl.dl_bw, new_bw)) {
+ 		__dl_clear(dl_b, p->dl.dl_bw);
+ 		__dl_add(dl_b, new_bw);
+ 		err = 0;
+ 	} else if (!dl_policy(policy) && task_has_dl_policy(p)) {
+ 		__dl_clear(dl_b, p->dl.dl_bw);
+ 		err = 0;
+ 	}
+ 	raw_spin_unlock(&dl_b->lock);
+ 
+ 	return err;
+ }
+ 
+ extern void init_dl_bw(struct dl_bw *dl_b);
+ 
++>>>>>>> 4df1638cfaf9 (sched/deadline: Fix overflow to handle period==0 and deadline!=0)
  /*
   * wake_up_new_task - wake up a newly created task for the first time.
   *
* Unmerged path kernel/sched/core.c
