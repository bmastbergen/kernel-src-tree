block: Always check queue limits for cloned requests

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-514.el7
Rebuild_CHGLOG: - [block] Always check queue limits for cloned requests (Mike Snitzer) [1286749]
Rebuild_FUZZ: 92.78%
commit-author Hannes Reinecke <hare@suse.de>
commit bf4e6b4e757488dee1b6a581f49c7ac34cd217f8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-514.el7/bf4e6b4e.failed

When a cloned request is retried on other queues it always needs
to be checked against the queue limits of that queue.
Otherwise the calculations for nr_phys_segments might be wrong,
leading to a crash in scsi_init_sgtable().

To clarify this the patch renames blk_rq_check_limits()
to blk_cloned_rq_check_limits() and removes the symbol
export, as the new function should only be used for
cloned requests and never exported.

	Cc: Mike Snitzer <snitzer@redhat.com>
	Cc: Ewan Milne <emilne@redhat.com>
	Cc: Jeff Moyer <jmoyer@redhat.com>
	Signed-off-by: Hannes Reinecke <hare@suse.de>
Fixes: e2a60da74 ("block: Clean up special command handling logic")
	Cc: stable@vger.kernel.org # 3.7+
	Acked-by: Mike Snitzer <snitzer@redhat.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit bf4e6b4e757488dee1b6a581f49c7ac34cd217f8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-core.c
diff --cc block/blk-core.c
index 9073fc590d2f,a0af4043dda2..000000000000
--- a/block/blk-core.c
+++ b/block/blk-core.c
@@@ -2010,20 -2126,13 +2011,21 @@@ EXPORT_SYMBOL(submit_bio)
   *    after it is inserted to @q, it should be checked against @q before
   *    the insertion using this generic function.
   *
-  *    This function should also be useful for request stacking drivers
-  *    in some cases below, so export this function.
   *    Request stacking drivers like request-based dm may change the queue
++<<<<<<< HEAD
 + *    limits while requests are in the queue (e.g. dm's table swapping).
 + *    Such request stacking drivers should check those requests agaist
 + *    the new queue limits again when they dispatch those requests,
 + *    although such checkings are also done against the old queue limits
 + *    when submitting requests.
++=======
+  *    limits when retrying requests on other queues. Those requests need
+  *    to be checked against the new queue limits again during dispatch.
++>>>>>>> bf4e6b4e7574 (block: Always check queue limits for cloned requests)
   */
- int blk_rq_check_limits(struct request_queue *q, struct request *rq)
+ static int blk_cloned_rq_check_limits(struct request_queue *q,
+ 				      struct request *rq)
  {
- 	if (!rq_mergeable(rq))
- 		return 0;
- 
  	if (blk_rq_sectors(rq) > blk_queue_get_max_sectors(q, rq->cmd_flags)) {
  		printk(KERN_ERR "%s: over max size limit.\n", __func__);
  		return -EIO;
* Unmerged path block/blk-core.c
diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
index 60506c44a9ba..01161d53872f 100644
--- a/include/linux/blkdev.h
+++ b/include/linux/blkdev.h
@@ -836,7 +836,6 @@ extern void blk_rq_set_block_pc(struct request *);
 extern void blk_requeue_request(struct request_queue *, struct request *);
 extern void blk_add_request_payload(struct request *rq, struct page *page,
 		unsigned int len);
-extern int blk_rq_check_limits(struct request_queue *q, struct request *rq);
 extern int blk_lld_busy(struct request_queue *q);
 extern int blk_rq_prep_clone(struct request *rq, struct request *rq_src,
 			     struct bio_set *bs, gfp_t gfp_mask,
