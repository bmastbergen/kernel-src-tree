arm64: Force SSBS on context switch

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [arm64] Force SSBS on context switch (Mark Salter) [1756103]
Rebuild_FUZZ: 88.89%
commit-author Marc Zyngier <marc.zyngier@arm.com>
commit cbdf8a189a66001c36007bf0f5c975d0376c5c3a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/cbdf8a18.failed

On a CPU that doesn't support SSBS, PSTATE[12] is RES0.  In a system
where only some of the CPUs implement SSBS, we end-up losing track of
the SSBS bit across task migration.

To address this issue, let's force the SSBS bit on context switch.

Fixes: 8f04e8e6e29c ("arm64: ssbd: Add support for PSTATE.SSBS rather than trapping to EL3")
	Signed-off-by: Marc Zyngier <marc.zyngier@arm.com>
[will: inverted logic and added comments]
	Signed-off-by: Will Deacon <will@kernel.org>
(cherry picked from commit cbdf8a189a66001c36007bf0f5c975d0376c5c3a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/kernel/process.c
diff --cc arch/arm64/kernel/process.c
index 084acadd51f8,f674f28df663..000000000000
--- a/arch/arm64/kernel/process.c
+++ b/arch/arm64/kernel/process.c
@@@ -358,8 -398,11 +358,8 @@@ int copy_thread(unsigned long clone_fla
  			childregs->pstate |= PSR_UAO_BIT;
  
  		if (arm64_get_ssbd_state() == ARM64_SSBD_FORCE_DISABLE)
- 			childregs->pstate |= PSR_SSBS_BIT;
+ 			set_ssbs_bit(childregs);
  
 -		if (system_uses_irq_prio_masking())
 -			childregs->pmr_save = GIC_PRIO_IRQON;
 -
  		p->thread.cpu_context.x19 = stack_start;
  		p->thread.cpu_context.x20 = stk_sz;
  	}
@@@ -427,6 -496,8 +453,11 @@@ __notrace_funcgraph struct task_struct 
  	contextidr_thread_switch(next);
  	entry_task_switch(next);
  	uao_thread_switch(next);
++<<<<<<< HEAD
++=======
+ 	ptrauth_thread_switch(next);
+ 	ssbs_thread_switch(next);
++>>>>>>> cbdf8a189a66 (arm64: Force SSBS on context switch)
  
  	/*
  	 * Complete any pending TLB or cache maintenance on this CPU in case
diff --git a/arch/arm64/include/asm/processor.h b/arch/arm64/include/asm/processor.h
index 80d0ee02d1f0..5e4428cb51a0 100644
--- a/arch/arm64/include/asm/processor.h
+++ b/arch/arm64/include/asm/processor.h
@@ -190,6 +190,16 @@ static inline void start_thread_common(struct pt_regs *regs, unsigned long pc)
 	regs->pc = pc;
 }
 
+static inline void set_ssbs_bit(struct pt_regs *regs)
+{
+	regs->pstate |= PSR_SSBS_BIT;
+}
+
+static inline void set_compat_ssbs_bit(struct pt_regs *regs)
+{
+	regs->pstate |= PSR_AA32_SSBS_BIT;
+}
+
 static inline void start_thread(struct pt_regs *regs, unsigned long pc,
 				unsigned long sp)
 {
@@ -197,7 +207,7 @@ static inline void start_thread(struct pt_regs *regs, unsigned long pc,
 	regs->pstate = PSR_MODE_EL0t;
 
 	if (arm64_get_ssbd_state() != ARM64_SSBD_FORCE_ENABLE)
-		regs->pstate |= PSR_SSBS_BIT;
+		set_ssbs_bit(regs);
 
 	regs->sp = sp;
 }
@@ -216,7 +226,7 @@ static inline void compat_start_thread(struct pt_regs *regs, unsigned long pc,
 #endif
 
 	if (arm64_get_ssbd_state() != ARM64_SSBD_FORCE_ENABLE)
-		regs->pstate |= PSR_AA32_SSBS_BIT;
+		set_compat_ssbs_bit(regs);
 
 	regs->compat_sp = sp;
 }
* Unmerged path arch/arm64/kernel/process.c
