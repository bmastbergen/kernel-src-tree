drivers/base/memory: use "unsigned long" for block ids

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [base] base/memory: use "unsigned long" for block ids (Baoquan He) [1724969]
Rebuild_FUZZ: 92.00%
commit-author David Hildenbrand <david@redhat.com>
commit 90ec010fe0d690665852d6bac21643e9ae7affd8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/90ec010f.failed

Block ids are just shifted section numbers, so let's also use "unsigned
long" for them, too.

Link: http://lkml.kernel.org/r/20190614100114.311-3-david@redhat.com
	Signed-off-by: David Hildenbrand <david@redhat.com>
	Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
	Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
	Cc: "Rafael J. Wysocki" <rafael@kernel.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 90ec010fe0d690665852d6bac21643e9ae7affd8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/base/memory.c
diff --cc drivers/base/memory.c
index 25064c825e5c,c54e80fd25a8..000000000000
--- a/drivers/base/memory.c
+++ b/drivers/base/memory.c
@@@ -39,6 -39,11 +39,14 @@@ static inline unsigned long base_memory
  	return section_nr / sections_per_block;
  }
  
++<<<<<<< HEAD
++=======
+ static inline unsigned long pfn_to_block_id(unsigned long pfn)
+ {
+ 	return base_memory_block_id(pfn_to_section_nr(pfn));
+ }
+ 
++>>>>>>> 90ec010fe0d6 (drivers/base/memory: use "unsigned long" for block ids)
  static int memory_subsys_online(struct device *dev);
  static int memory_subsys_offline(struct device *dev);
  
@@@ -581,10 -587,9 +589,15 @@@ int __weak arch_get_memory_phys_device(
   * A reference for the returned object is held and the reference for the
   * hinted object is released.
   */
++<<<<<<< HEAD
 +struct memory_block *find_memory_block_hinted(struct mem_section *section,
 +					      struct memory_block *hint)
++=======
+ static struct memory_block *find_memory_block_by_id(unsigned long block_id,
+ 						    struct memory_block *hint)
++>>>>>>> 90ec010fe0d6 (drivers/base/memory: use "unsigned long" for block ids)
  {
 +	int block_id = base_memory_block_id(__section_nr(section));
  	struct device *hintdev = hint ? &hint->dev : NULL;
  	struct device *dev;
  
@@@ -596,6 -601,14 +609,17 @@@
  	return to_memory_block(dev);
  }
  
++<<<<<<< HEAD
++=======
+ struct memory_block *find_memory_block_hinted(struct mem_section *section,
+ 					      struct memory_block *hint)
+ {
+ 	unsigned long block_id = base_memory_block_id(__section_nr(section));
+ 
+ 	return find_memory_block_by_id(block_id, hint);
+ }
+ 
++>>>>>>> 90ec010fe0d6 (drivers/base/memory: use "unsigned long" for block ids)
  /*
   * For now, we have a linear search to go find the appropriate
   * memory_block corresponding to a particular phys_index. If
@@@ -733,11 -722,57 +757,57 @@@ unregister_memory(struct memory_block *
  	device_unregister(&memory->dev);
  }
  
 -/*
 - * Create memory block devices for the given memory area. Start and size
 - * have to be aligned to memory block granularity. Memory block devices
 - * will be initialized as offline.
 - */
 -int create_memory_block_devices(unsigned long start, unsigned long size)
 +void unregister_memory_section(struct mem_section *section)
  {
++<<<<<<< HEAD
++=======
+ 	const unsigned long start_block_id = pfn_to_block_id(PFN_DOWN(start));
+ 	unsigned long end_block_id = pfn_to_block_id(PFN_DOWN(start + size));
++>>>>>>> 90ec010fe0d6 (drivers/base/memory: use "unsigned long" for block ids)
  	struct memory_block *mem;
 -	unsigned long block_id;
 -	int ret = 0;
  
++<<<<<<< HEAD
 +	if (WARN_ON_ONCE(!present_section(section)))
++=======
+ 	if (WARN_ON_ONCE(!IS_ALIGNED(start, memory_block_size_bytes()) ||
+ 			 !IS_ALIGNED(size, memory_block_size_bytes())))
+ 		return -EINVAL;
+ 
+ 	mutex_lock(&mem_sysfs_mutex);
+ 	for (block_id = start_block_id; block_id != end_block_id; block_id++) {
+ 		ret = init_memory_block(&mem, block_id, MEM_OFFLINE);
+ 		if (ret)
+ 			break;
+ 		mem->section_count = sections_per_block;
+ 	}
+ 	if (ret) {
+ 		end_block_id = block_id;
+ 		for (block_id = start_block_id; block_id != end_block_id;
+ 		     block_id++) {
+ 			mem = find_memory_block_by_id(block_id, NULL);
+ 			mem->section_count = 0;
+ 			unregister_memory(mem);
+ 		}
+ 	}
+ 	mutex_unlock(&mem_sysfs_mutex);
+ 	return ret;
+ }
+ 
+ /*
+  * Remove memory block devices for the given memory area. Start and size
+  * have to be aligned to memory block granularity. Memory block devices
+  * have to be offline.
+  */
+ void remove_memory_block_devices(unsigned long start, unsigned long size)
+ {
+ 	const unsigned long start_block_id = pfn_to_block_id(PFN_DOWN(start));
+ 	const unsigned long end_block_id = pfn_to_block_id(PFN_DOWN(start + size));
+ 	struct memory_block *mem;
+ 	unsigned long block_id;
+ 
+ 	if (WARN_ON_ONCE(!IS_ALIGNED(start, memory_block_size_bytes()) ||
+ 			 !IS_ALIGNED(size, memory_block_size_bytes())))
++>>>>>>> 90ec010fe0d6 (drivers/base/memory: use "unsigned long" for block ids)
  		return;
  
  	mutex_lock(&mem_sysfs_mutex);
* Unmerged path drivers/base/memory.c
