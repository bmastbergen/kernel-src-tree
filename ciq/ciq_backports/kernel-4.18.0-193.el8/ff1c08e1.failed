bpf: Change size to u64 for bpf_map_{area_alloc, charge_init}()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Björn Töpel <bjorn.topel@intel.com>
commit ff1c08e1f74b6864854c39be48aa799a6a2e4d2b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/ff1c08e1.failed

The functions bpf_map_area_alloc() and bpf_map_charge_init() prior
this commit passed the size parameter as size_t. In this commit this
is changed to u64.

All users of these functions avoid size_t overflows on 32-bit systems,
by explicitly using u64 when calculating the allocation size and
memory charge cost. However, since the result was narrowed by the
size_t when passing size and cost to the functions, the overflow
handling was in vain.

Instead of changing all call sites to size_t and handle overflow at
the call site, the parameter is changed to u64 and checked in the
functions above.

Fixes: d407bd25a204 ("bpf: don't trigger OOM killer under pressure with map alloc")
Fixes: c85d69135a91 ("bpf: move memory size checks to bpf_map_charge_init()")
	Signed-off-by: Björn Töpel <bjorn.topel@intel.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Reviewed-by: Jakub Kicinski <jakub.kicinski@netronome.com>
Link: https://lore.kernel.org/bpf/20191029154307.23053-1-bjorn.topel@gmail.com
(cherry picked from commit ff1c08e1f74b6864854c39be48aa799a6a2e4d2b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
#	kernel/bpf/syscall.c
diff --cc include/linux/bpf.h
index f496f5cf851c,3bf3835d0e86..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -626,12 -650,17 +626,20 @@@ void bpf_map_free_id(struct bpf_map *ma
  struct bpf_map *bpf_map_get_with_uref(u32 ufd);
  struct bpf_map *__bpf_map_get(struct fd f);
  struct bpf_map * __must_check bpf_map_inc(struct bpf_map *map, bool uref);
 -struct bpf_map * __must_check bpf_map_inc_not_zero(struct bpf_map *map,
 -						   bool uref);
  void bpf_map_put_with_uref(struct bpf_map *map);
  void bpf_map_put(struct bpf_map *map);
 +int bpf_map_precharge_memlock(u32 pages);
  int bpf_map_charge_memlock(struct bpf_map *map, u32 pages);
  void bpf_map_uncharge_memlock(struct bpf_map *map, u32 pages);
++<<<<<<< HEAD
 +void *bpf_map_area_alloc(size_t size, int numa_node);
++=======
+ int bpf_map_charge_init(struct bpf_map_memory *mem, u64 size);
+ void bpf_map_charge_finish(struct bpf_map_memory *mem);
+ void bpf_map_charge_move(struct bpf_map_memory *dst,
+ 			 struct bpf_map_memory *src);
+ void *bpf_map_area_alloc(u64 size, int numa_node);
++>>>>>>> ff1c08e1f74b (bpf: Change size to u64 for bpf_map_{area_alloc, charge_init}())
  void bpf_map_area_free(void *base);
  void bpf_map_init_from_attr(struct bpf_map *map, union bpf_attr *attr);
  
diff --cc kernel/bpf/syscall.c
index ec2d27382d4b,ace1cfaa24b6..000000000000
--- a/kernel/bpf/syscall.c
+++ b/kernel/bpf/syscall.c
@@@ -227,15 -196,21 +230,19 @@@ static int bpf_charge_memlock(struct us
  
  static void bpf_uncharge_memlock(struct user_struct *user, u32 pages)
  {
 -	if (user)
 -		atomic_long_sub(pages, &user->locked_vm);
 +	atomic_long_sub(pages, &user->locked_vm);
  }
  
++<<<<<<< HEAD
 +static int bpf_map_init_memlock(struct bpf_map *map)
++=======
+ int bpf_map_charge_init(struct bpf_map_memory *mem, u64 size)
++>>>>>>> ff1c08e1f74b (bpf: Change size to u64 for bpf_map_{area_alloc, charge_init}())
  {
 -	u32 pages = round_up(size, PAGE_SIZE) >> PAGE_SHIFT;
 -	struct user_struct *user;
 +	struct user_struct *user = get_current_user();
  	int ret;
  
 -	if (size >= U32_MAX - PAGE_SIZE)
 -		return -E2BIG;
 -
 -	user = get_current_user();
 -	ret = bpf_charge_memlock(user, pages);
 +	ret = bpf_charge_memlock(user, map->pages);
  	if (ret) {
  		free_uid(user);
  		return ret;
* Unmerged path include/linux/bpf.h
* Unmerged path kernel/bpf/syscall.c
