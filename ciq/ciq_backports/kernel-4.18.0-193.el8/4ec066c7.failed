iommu/vt-d: Cleanup get_valid_domain_for_dev()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [iommu] vt-d: Cleanup get_valid_domain_for_dev() (Jerry Snitselaar) [1742234]
Rebuild_FUZZ: 93.02%
commit-author Lu Baolu <baolu.lu@linux.intel.com>
commit 4ec066c7b1476e0ca66a7acdb575627a5d1a1ee6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/4ec066c7.failed

Previously, get_valid_domain_for_dev() is used to retrieve the
DMA domain which has been attached to the device or allocate one
if no domain has been attached yet. As we have delegated the DMA
domain management to upper layer, this function is used purely to
allocate a private DMA domain if the default domain doesn't work
for ths device. Cleanup the code for readability.

	Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit 4ec066c7b1476e0ca66a7acdb575627a5d1a1ee6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/intel-iommu.c
diff --cc drivers/iommu/intel-iommu.c
index 2e309c5bf99c,ebc06ee79dce..000000000000
--- a/drivers/iommu/intel-iommu.c
+++ b/drivers/iommu/intel-iommu.c
@@@ -3577,56 -3597,52 +3577,79 @@@ static struct dmar_domain *get_private_
  	}
  
  out:
- 
  	if (!domain)
 -		dev_err(dev, "Allocating domain failed\n");
 +		pr_err("Allocating domain for %s failed\n", dev_name(dev));
  
- 
  	return domain;
  }
  
  /* Check if the dev needs to go through non-identity map and unmap process.*/
 -static bool iommu_need_mapping(struct device *dev)
 +static int iommu_no_mapping(struct device *dev)
  {
 -	int ret;
 +	int found;
  
  	if (iommu_dummy(dev))
 -		return false;
 +		return 1;
  
 -	ret = identity_mapping(dev);
 -	if (ret) {
 -		u64 dma_mask = *dev->dma_mask;
 +	if (!iommu_identity_mapping)
 +		return 0;
  
++<<<<<<< HEAD
 +	found = identity_mapping(dev);
 +	if (found) {
 +		if (iommu_should_identity_map(dev, 0))
 +			return 1;
 +		else {
 +			/*
 +			 * 32 bit DMA is removed from si_domain and fall back
 +			 * to non-identity mapping.
 +			 */
 +			dmar_remove_one_dev_info(si_domain, dev);
 +			pr_info("32bit %s uses non-identity mapping\n",
 +				dev_name(dev));
 +			return 0;
 +		}
 +	} else {
 +		/*
 +		 * In case of a detached 64 bit DMA device from vm, the device
 +		 * is put into si_domain for identity mapping.
 +		 */
 +		if (iommu_should_identity_map(dev, 0)) {
 +			int ret;
 +			ret = domain_add_dev_info(si_domain, dev);
 +			if (!ret) {
 +				pr_info("64bit %s uses identity mapping\n",
 +					dev_name(dev));
 +				return 1;
 +			}
++=======
+ 		if (dev->coherent_dma_mask && dev->coherent_dma_mask < dma_mask)
+ 			dma_mask = dev->coherent_dma_mask;
+ 
+ 		if (dma_mask >= dma_get_required_mask(dev))
+ 			return false;
+ 
+ 		/*
+ 		 * 32 bit DMA is removed from si_domain and fall back to
+ 		 * non-identity mapping.
+ 		 */
+ 		dmar_remove_one_dev_info(dev);
+ 		ret = iommu_request_dma_domain_for_dev(dev);
+ 		if (ret) {
+ 			struct iommu_domain *domain;
+ 			struct dmar_domain *dmar_domain;
+ 
+ 			domain = iommu_get_domain_for_dev(dev);
+ 			if (domain) {
+ 				dmar_domain = to_dmar_domain(domain);
+ 				dmar_domain->flags |= DOMAIN_FLAG_LOSE_CHILDREN;
+ 			}
+ 			get_private_domain_for_dev(dev);
++>>>>>>> 4ec066c7b147 (iommu/vt-d: Cleanup get_valid_domain_for_dev())
  		}
 -
 -		dev_info(dev, "32bit DMA uses non-identity mapping\n");
  	}
  
 -	return true;
 +	return 0;
  }
  
  static dma_addr_t __intel_map_single(struct device *dev, phys_addr_t paddr,
@@@ -3642,10 -3658,7 +3665,14 @@@
  
  	BUG_ON(dir == DMA_NONE);
  
++<<<<<<< HEAD
 +	if (iommu_no_mapping(dev))
 +		return paddr;
 +
 +	domain = get_valid_domain_for_dev(dev);
++=======
+ 	domain = find_domain(dev);
++>>>>>>> 4ec066c7b147 (iommu/vt-d: Cleanup get_valid_domain_for_dev())
  	if (!domain)
  		return DMA_MAPPING_ERROR;
  
@@@ -3861,10 -3870,10 +3888,10 @@@ static int intel_map_sg(struct device *
  	struct intel_iommu *iommu;
  
  	BUG_ON(dir == DMA_NONE);
 -	if (!iommu_need_mapping(dev))
 -		return dma_direct_map_sg(dev, sglist, nelems, dir, attrs);
 +	if (iommu_no_mapping(dev))
 +		return intel_nontranslate_map_sg(dev, sglist, nelems, dir);
  
- 	domain = get_valid_domain_for_dev(dev);
+ 	domain = find_domain(dev);
  	if (!domain)
  		return 0;
  
@@@ -5484,7 -5638,7 +5511,11 @@@ int intel_iommu_enable_pasid(struct int
  	u64 ctx_lo;
  	int ret;
  
++<<<<<<< HEAD
 +	domain = get_valid_domain_for_dev(sdev->dev);
++=======
+ 	domain = find_domain(dev);
++>>>>>>> 4ec066c7b147 (iommu/vt-d: Cleanup get_valid_domain_for_dev())
  	if (!domain)
  		return -EINVAL;
  
* Unmerged path drivers/iommu/intel-iommu.c
diff --git a/include/linux/intel-iommu.h b/include/linux/intel-iommu.h
index 8d42a6ffd805..9b718293fe57 100644
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@ -630,7 +630,6 @@ extern int qi_submit_sync(struct qi_desc *desc, struct intel_iommu *iommu);
 
 extern int dmar_ir_support(void);
 
-struct dmar_domain *get_valid_domain_for_dev(struct device *dev);
 void *alloc_pgtable_page(int node);
 void free_pgtable_page(void *vaddr);
 struct intel_iommu *domain_get_iommu(struct dmar_domain *domain);
