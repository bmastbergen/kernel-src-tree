mm/memory_hotplug: drop MHP_MEMBLOCK_API

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [mm] memory_hotplug: drop MHP_MEMBLOCK_API (Baoquan He) [1724969]
Rebuild_FUZZ: 96.10%
commit-author David Hildenbrand <david@redhat.com>
commit 05f800a0bd08e14606ac63e0a5c63ed6880acaab
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/05f800a0.failed

No longer needed, the callers of arch_add_memory() can handle this
manually.

Link: http://lkml.kernel.org/r/20190527111152.16324-9-david@redhat.com
	Signed-off-by: David Hildenbrand <david@redhat.com>
	Reviewed-by: Wei Yang <richardw.yang@linux.intel.com>
	Acked-by: Michal Hocko <mhocko@suse.com>
	Cc: David Hildenbrand <david@redhat.com>
	Cc: Oscar Salvador <osalvador@suse.com>
	Cc: Pavel Tatashin <pasha.tatashin@soleen.com>
	Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
	Cc: Qian Cai <cai@lca.pw>
	Cc: Arun KS <arunks@codeaurora.org>
	Cc: Mathieu Malaterre <malat@debian.org>
	Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
	Cc: Alex Deucher <alexander.deucher@amd.com>
	Cc: Andrew Banman <andrew.banman@hpe.com>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Anshuman Khandual <anshuman.khandual@arm.com>
	Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
	Cc: Baoquan He <bhe@redhat.com>
	Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
	Cc: Borislav Petkov <bp@alien8.de>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Chintan Pandya <cpandya@codeaurora.org>
	Cc: Christophe Leroy <christophe.leroy@c-s.fr>
	Cc: Chris Wilson <chris@chris-wilson.co.uk>
	Cc: Dan Williams <dan.j.williams@intel.com>
	Cc: Dave Hansen <dave.hansen@linux.intel.com>
	Cc: "David S. Miller" <davem@davemloft.net>
	Cc: Fenghua Yu <fenghua.yu@intel.com>
	Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
	Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Ingo Molnar <mingo@kernel.org>
	Cc: Jonathan Cameron <Jonathan.Cameron@huawei.com>
	Cc: Jun Yao <yaojun8558363@gmail.com>
	Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
	Cc: Logan Gunthorpe <logang@deltatee.com>
	Cc: Mark Brown <broonie@kernel.org>
	Cc: Mark Rutland <mark.rutland@arm.com>
	Cc: Masahiro Yamada <yamada.masahiro@socionext.com>
	Cc: Michael Ellerman <mpe@ellerman.id.au>
	Cc: Mike Rapoport <rppt@linux.ibm.com>
	Cc: "mike.travis@hpe.com" <mike.travis@hpe.com>
	Cc: Nicholas Piggin <npiggin@gmail.com>
	Cc: Oscar Salvador <osalvador@suse.de>
	Cc: Paul Mackerras <paulus@samba.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: "Rafael J. Wysocki" <rafael@kernel.org>
	Cc: Rich Felker <dalias@libc.org>
	Cc: Rob Herring <robh@kernel.org>
	Cc: Robin Murphy <robin.murphy@arm.com>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Tony Luck <tony.luck@intel.com>
	Cc: Vasily Gorbik <gor@linux.ibm.com>
	Cc: Will Deacon <will.deacon@arm.com>
	Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
	Cc: Yu Zhao <yuzhao@google.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 05f800a0bd08e14606ac63e0a5c63ed6880acaab)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/memory_hotplug.h
#	mm/memory_hotplug.c
diff --cc include/linux/memory_hotplug.h
index 73f431adb15b,36c514b80cf1..000000000000
--- a/include/linux/memory_hotplug.h
+++ b/include/linux/memory_hotplug.h
@@@ -108,12 -123,10 +108,19 @@@ static inline bool movable_node_is_enab
  	return movable_node_enabled;
  }
  
++<<<<<<< HEAD
 +#ifdef CONFIG_MEMORY_HOTREMOVE
 +extern int arch_remove_memory(int nid, u64 start, u64 size,
 +				struct vmem_altmap *altmap);
 +extern int __remove_pages(struct zone *zone, unsigned long start_pfn,
 +	unsigned long nr_pages, struct vmem_altmap *altmap);
 +#endif /* CONFIG_MEMORY_HOTREMOVE */
++=======
+ extern void arch_remove_memory(int nid, u64 start, u64 size,
+ 			       struct vmem_altmap *altmap);
+ extern void __remove_pages(struct zone *zone, unsigned long start_pfn,
+ 			   unsigned long nr_pages, struct vmem_altmap *altmap);
++>>>>>>> 05f800a0bd08 (mm/memory_hotplug: drop MHP_MEMBLOCK_API)
  
  /* reasonably generic interface to expand the physical pages */
  extern int __add_pages(int nid, unsigned long start_pfn, unsigned long nr_pages,
diff --cc mm/memory_hotplug.c
index 20f1bc790834,fb9dc3fa1138..000000000000
--- a/mm/memory_hotplug.c
+++ b/mm/memory_hotplug.c
@@@ -303,8 -294,7 +303,12 @@@ int __ref __add_pages(int nid, unsigne
  	}
  
  	for (i = start_sec; i <= end_sec; i++) {
++<<<<<<< HEAD
 +		err = __add_section(nid, section_nr_to_pfn(i), altmap,
 +				want_memblock);
++=======
+ 		err = __add_section(nid, section_nr_to_pfn(i), altmap);
++>>>>>>> 05f800a0bd08 (mm/memory_hotplug: drop MHP_MEMBLOCK_API)
  
  		/*
  		 * EEXIST is finally dealt with by ioresource collision
@@@ -1125,6 -1064,7 +1129,10 @@@ static int online_memory_block(struct m
   */
  int __ref add_memory_resource(int nid, struct resource *res)
  {
++<<<<<<< HEAD
++=======
+ 	struct mhp_restrictions restrictions = {};
++>>>>>>> 05f800a0bd08 (mm/memory_hotplug: drop MHP_MEMBLOCK_API)
  	u64 start, size;
  	bool new_node = false;
  	int ret;
* Unmerged path include/linux/memory_hotplug.h
* Unmerged path mm/memory_hotplug.c
