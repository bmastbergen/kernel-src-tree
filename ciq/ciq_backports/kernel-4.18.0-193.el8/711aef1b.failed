bpf, x32: Fix bug for BPF_JMP | {BPF_JSGT, BPF_JSLE, BPF_JSLT, BPF_JSGE}

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Wang YanQing <udknight@gmail.com>
commit 711aef1bbf88212a21f7103e88f397b47a528805
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/711aef1b.failed

The current method to compare 64-bit numbers for conditional jump is:

1) Compare the high 32-bit first.

2) If the high 32-bit isn't the same, then goto step 4.

3) Compare the low 32-bit.

4) Check the desired condition.

This method is right for unsigned comparison, but it is buggy for signed
comparison, because it does signed comparison for low 32-bit too.

There is only one sign bit in 64-bit number, that is the MSB in the 64-bit
number, it is wrong to treat low 32-bit as signed number and do the signed
comparison for it.

This patch fixes the bug and adds a testcase in selftests/bpf for such bug.

	Signed-off-by: Wang YanQing <udknight@gmail.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
(cherry picked from commit 711aef1bbf88212a21f7103e88f397b47a528805)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/net/bpf_jit_comp32.c
#	tools/testing/selftests/bpf/verifier/jit.c
diff --cc arch/x86/net/bpf_jit_comp32.c
index 8f6cc71e0848,8097b88d744f..000000000000
--- a/arch/x86/net/bpf_jit_comp32.c
+++ b/arch/x86/net/bpf_jit_comp32.c
@@@ -2069,10 -2140,17 +2140,24 @@@ static int do_jit(struct bpf_prog *bpf_
  		case BPF_JMP | BPF_JLT | BPF_X:
  		case BPF_JMP | BPF_JGE | BPF_X:
  		case BPF_JMP | BPF_JLE | BPF_X:
++<<<<<<< HEAD
 +		case BPF_JMP | BPF_JSGT | BPF_X:
 +		case BPF_JMP | BPF_JSLE | BPF_X:
 +		case BPF_JMP | BPF_JSLT | BPF_X:
 +		case BPF_JMP | BPF_JSGE | BPF_X: {
++=======
+ 		case BPF_JMP32 | BPF_JEQ | BPF_X:
+ 		case BPF_JMP32 | BPF_JNE | BPF_X:
+ 		case BPF_JMP32 | BPF_JGT | BPF_X:
+ 		case BPF_JMP32 | BPF_JLT | BPF_X:
+ 		case BPF_JMP32 | BPF_JGE | BPF_X:
+ 		case BPF_JMP32 | BPF_JLE | BPF_X:
+ 		case BPF_JMP32 | BPF_JSGT | BPF_X:
+ 		case BPF_JMP32 | BPF_JSLE | BPF_X:
+ 		case BPF_JMP32 | BPF_JSLT | BPF_X:
+ 		case BPF_JMP32 | BPF_JSGE | BPF_X: {
+ 			bool is_jmp64 = BPF_CLASS(insn->code) == BPF_JMP;
++>>>>>>> 711aef1bbf88 (bpf, x32: Fix bug for BPF_JMP | {BPF_JSGT, BPF_JSLE, BPF_JSLT, BPF_JSGE})
  			u8 dreg_lo = dstk ? IA32_EAX : dst_lo;
  			u8 dreg_hi = dstk ? IA32_EDX : dst_hi;
  			u8 sreg_lo = sstk ? IA32_ECX : src_lo;
@@@ -2099,7 -2185,43 +2184,47 @@@
  			EMIT2(0x39, add_2reg(0xC0, dreg_lo, sreg_lo));
  			goto emit_cond_jmp;
  		}
++<<<<<<< HEAD
 +		case BPF_JMP | BPF_JSET | BPF_X: {
++=======
+ 		case BPF_JMP | BPF_JSGT | BPF_X:
+ 		case BPF_JMP | BPF_JSLE | BPF_X:
+ 		case BPF_JMP | BPF_JSLT | BPF_X:
+ 		case BPF_JMP | BPF_JSGE | BPF_X: {
+ 			u8 dreg_lo = dstk ? IA32_EAX : dst_lo;
+ 			u8 dreg_hi = dstk ? IA32_EDX : dst_hi;
+ 			u8 sreg_lo = sstk ? IA32_ECX : src_lo;
+ 			u8 sreg_hi = sstk ? IA32_EBX : src_hi;
+ 
+ 			if (dstk) {
+ 				EMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_EAX),
+ 				      STACK_VAR(dst_lo));
+ 				EMIT3(0x8B,
+ 				      add_2reg(0x40, IA32_EBP,
+ 					       IA32_EDX),
+ 				      STACK_VAR(dst_hi));
+ 			}
+ 
+ 			if (sstk) {
+ 				EMIT3(0x8B, add_2reg(0x40, IA32_EBP, IA32_ECX),
+ 				      STACK_VAR(src_lo));
+ 				EMIT3(0x8B,
+ 				      add_2reg(0x40, IA32_EBP,
+ 					       IA32_EBX),
+ 				      STACK_VAR(src_hi));
+ 			}
+ 
+ 			/* cmp dreg_hi,sreg_hi */
+ 			EMIT2(0x39, add_2reg(0xC0, dreg_hi, sreg_hi));
+ 			EMIT2(IA32_JNE, 10);
+ 			/* cmp dreg_lo,sreg_lo */
+ 			EMIT2(0x39, add_2reg(0xC0, dreg_lo, sreg_lo));
+ 			goto emit_cond_jmp_signed;
+ 		}
+ 		case BPF_JMP | BPF_JSET | BPF_X:
+ 		case BPF_JMP32 | BPF_JSET | BPF_X: {
+ 			bool is_jmp64 = BPF_CLASS(insn->code) == BPF_JMP;
++>>>>>>> 711aef1bbf88 (bpf, x32: Fix bug for BPF_JMP | {BPF_JSGT, BPF_JSLE, BPF_JSLT, BPF_JSGE})
  			u8 dreg_lo = dstk ? IA32_EAX : dst_lo;
  			u8 dreg_hi = dstk ? IA32_EDX : dst_hi;
  			u8 sreg_lo = sstk ? IA32_ECX : src_lo;
@@@ -2160,11 -2295,17 +2285,25 @@@
  		case BPF_JMP | BPF_JLT | BPF_K:
  		case BPF_JMP | BPF_JGE | BPF_K:
  		case BPF_JMP | BPF_JLE | BPF_K:
++<<<<<<< HEAD
 +		case BPF_JMP | BPF_JSGT | BPF_K:
 +		case BPF_JMP | BPF_JSLE | BPF_K:
 +		case BPF_JMP | BPF_JSLT | BPF_K:
 +		case BPF_JMP | BPF_JSGE | BPF_K: {
 +			u32 hi;
++=======
+ 		case BPF_JMP32 | BPF_JEQ | BPF_K:
+ 		case BPF_JMP32 | BPF_JNE | BPF_K:
+ 		case BPF_JMP32 | BPF_JGT | BPF_K:
+ 		case BPF_JMP32 | BPF_JLT | BPF_K:
+ 		case BPF_JMP32 | BPF_JGE | BPF_K:
+ 		case BPF_JMP32 | BPF_JLE | BPF_K:
+ 		case BPF_JMP32 | BPF_JSGT | BPF_K:
+ 		case BPF_JMP32 | BPF_JSLE | BPF_K:
+ 		case BPF_JMP32 | BPF_JSLT | BPF_K:
+ 		case BPF_JMP32 | BPF_JSGE | BPF_K: {
+ 			bool is_jmp64 = BPF_CLASS(insn->code) == BPF_JMP;
++>>>>>>> 711aef1bbf88 (bpf, x32: Fix bug for BPF_JMP | {BPF_JSGT, BPF_JSLE, BPF_JSLT, BPF_JSGE})
  			u8 dreg_lo = dstk ? IA32_EAX : dst_lo;
  			u8 dreg_hi = dstk ? IA32_EDX : dst_hi;
  			u8 sreg_lo = IA32_ECX;
* Unmerged path tools/testing/selftests/bpf/verifier/jit.c
* Unmerged path arch/x86/net/bpf_jit_comp32.c
* Unmerged path tools/testing/selftests/bpf/verifier/jit.c
