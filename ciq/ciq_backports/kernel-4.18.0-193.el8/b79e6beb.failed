net/mlx5: Move IRQ rmap creation to IRQ allocation phase

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [netdrv] mlx5: Move IRQ rmap creation to IRQ allocation phase (Alaa Hleihel) [1724336]
Rebuild_FUZZ: 96.30%
commit-author Yuval Avnery <yuvalav@mellanox.com>
commit b79e6beb9c36a1f26116a9a576392647643ac456
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/b79e6beb.failed

Rmap creation/deletion is part of the IRQ life-cycle.

	Signed-off-by: Yuval Avnery <yuvalav@mellanox.com>
	Reviewed-by: Parav Pandit <parav@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit b79e6beb9c36a1f26116a9a576392647643ac456)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eq.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eq.c
index c00cfa7a9ba0,1ea983c1ec05..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eq.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
@@@ -861,12 -936,6 +904,15 @@@ static void destroy_comp_eqs(struct mlx
  
  	clear_comp_irqs_affinity_hints(dev);
  
++<<<<<<< HEAD
 +#ifdef CONFIG_RFS_ACCEL
 +	if (table->rmap) {
 +		free_irq_cpu_rmap(table->rmap);
 +		table->rmap = NULL;
 +	}
 +#endif
++=======
++>>>>>>> b79e6beb9c36 (net/mlx5: Move IRQ rmap creation to IRQ allocation phase)
  	list_for_each_entry_safe(eq, n, &table->comp_eqs_list, list) {
  		list_del(&eq->list);
  		if (destroy_unmap_eq(dev, &eq->core))
@@@ -887,14 -956,9 +933,18 @@@ static int create_comp_eqs(struct mlx5_
  	int i;
  
  	INIT_LIST_HEAD(&table->comp_eqs_list);
 -	ncomp_eqs = table->num_comp_eqs;
 +	ncomp_vec = table->num_comp_vectors;
  	nent = MLX5_COMP_EQ_SIZE;
++<<<<<<< HEAD
 +#ifdef CONFIG_RFS_ACCEL
 +	table->rmap = alloc_irq_cpu_rmap(ncomp_vec);
 +	if (!table->rmap)
 +		return -ENOMEM;
 +#endif
 +	for (i = 0; i < ncomp_vec; i++) {
++=======
+ 	for (i = 0; i < ncomp_eqs; i++) {
++>>>>>>> b79e6beb9c36 (net/mlx5: Move IRQ rmap creation to IRQ allocation phase)
  		int vecidx = i + MLX5_EQ_VEC_COMP_BASE;
  		struct mlx5_eq_param param = {};
  
@@@ -910,9 -974,6 +960,12 @@@
  		tasklet_init(&eq->tasklet_ctx.task, mlx5_cq_tasklet_cb,
  			     (unsigned long)&eq->tasklet_ctx);
  
++<<<<<<< HEAD
 +#ifdef CONFIG_RFS_ACCEL
 +		irq_cpu_rmap_add(table->rmap, pci_irq_vector(dev->pdev, vecidx));
 +#endif
++=======
++>>>>>>> b79e6beb9c36 (net/mlx5: Move IRQ rmap creation to IRQ allocation phase)
  		eq->irq_nb.notifier_call = mlx5_eq_comp_int;
  		param = (struct mlx5_eq_param) {
  			.index = vecidx,
@@@ -1005,18 -1067,12 +1058,22 @@@ void mlx5_core_eq_free_irqs(struct mlx5
  	int i, max_eqs;
  
  	clear_comp_irqs_affinity_hints(dev);
++<<<<<<< HEAD
 +
 +#ifdef CONFIG_RFS_ACCEL
 +	if (table->rmap) {
 +		free_irq_cpu_rmap(table->rmap);
 +		table->rmap = NULL;
 +	}
 +#endif
 +
++=======
+ 	irq_clear_rmap(dev);
++>>>>>>> b79e6beb9c36 (net/mlx5: Move IRQ rmap creation to IRQ allocation phase)
  	mutex_lock(&table->lock); /* sync with create/destroy_async_eq */
 -	max_eqs = table->num_comp_eqs + MLX5_EQ_VEC_COMP_BASE;
 +	max_eqs = table->num_comp_vectors + MLX5_EQ_VEC_COMP_BASE;
  	for (i = max_eqs - 1; i >= 0; i--) {
 -		free_irq(pci_irq_vector(dev->pdev, i),
 -			 &mlx5_irq_get(dev, i)->nh);
 +		free_irq(pci_irq_vector(dev->pdev, i), &table->irq_info[i].nh);
  	}
  	mutex_unlock(&table->lock);
  	pci_free_irq_vectors(dev->pdev);
@@@ -1049,11 -1105,15 +1106,15 @@@ static int alloc_irq_vectors(struct mlx
  		goto err_free_irq_info;
  	}
  
 -	table->nvec = nvec;
 +	table->num_comp_vectors = nvec - MLX5_EQ_VEC_COMP_BASE;
  
+ 	err = irq_set_rmap(dev);
+ 	if (err)
+ 		goto err_set_rmap;
+ 
  	err = request_irqs(dev, nvec);
  	if (err)
- 		goto err_free_irqs;
+ 		goto err_request_irqs;
  
  	return 0;
  
@@@ -1066,11 -1128,17 +1129,22 @@@ err_free_irq_info
  
  static void free_irq_vectors(struct mlx5_core_dev *dev)
  {
 -	struct mlx5_irq_table *table = dev->priv.irq_table;
 +	struct mlx5_eq_table *table = dev->priv.eq_table;
  	int i;
  
++<<<<<<< HEAD
 +	for (i = 0; i < table->num_comp_vectors + MLX5_EQ_VEC_COMP_BASE; i++)
 +		free_irq(pci_irq_vector(dev->pdev, i), &table->irq_info[i].nh);
++=======
+ 	/* free_irq requires that affinity and rmap will be cleared
+ 	 * before calling it. This is why there is asymmetry with set_rmap
+ 	 * which should be called after alloc_irq but before request_irq.
+ 	 */
+ 	irq_clear_rmap(dev);
+ 	for (i = 0; i < table->nvec; i++)
+ 		free_irq(pci_irq_vector(dev->pdev, i),
+ 			 &mlx5_irq_get(dev, i)->nh);
++>>>>>>> b79e6beb9c36 (net/mlx5: Move IRQ rmap creation to IRQ allocation phase)
  	pci_free_irq_vectors(dev->pdev);
  	kfree(table->irq_info);
  }
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eq.c
