RDMA: Check net namespace access for uverbs, umad, cma and nldev

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Parav Pandit <parav@mellanox.com>
commit 41c6140189afdf67bd07d7bbe2d8f9382b6f9ef7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/41c61401.failed

Introduce an API rdma_dev_access_netns() to check whether a rdma device
can be accessed from the specified net namespace or not.
Use rdma_dev_access_netns() while opening character uverbs, umad network
device and also check while rdma cm_id binds to rdma device.

	Signed-off-by: Parav Pandit <parav@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 41c6140189afdf67bd07d7bbe2d8f9382b6f9ef7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/device.c
diff --cc drivers/infiniband/core/device.c
index 3aa933cc02d9,74736ea9b007..000000000000
--- a/drivers/infiniband/core/device.c
+++ b/drivers/infiniband/core/device.c
@@@ -72,21 -96,102 +72,112 @@@ static LIST_HEAD(device_list)
  static LIST_HEAD(client_list);
  #define CLIENT_REGISTERED XA_MARK_1
  static DEFINE_XARRAY_FLAGS(clients, XA_FLAGS_ALLOC);
 -static DECLARE_RWSEM(clients_rwsem);
  
  /*
 - * If client_data is registered then the corresponding client must also still
 - * be registered.
 + * device_mutex and lists_rwsem protect access to both device_list and
 + * clients.  device_mutex protects writer access by device and client
 + * registration / de-registration.  lists_rwsem protects reader access to
 + * these lists.  Iterators of these lists must lock it for read, while updates
 + * to the lists must be done with a write lock. A special case is when the
 + * device_mutex is locked. In this case locking the lists for read access is
 + * not necessary as the device_mutex implies it.
 + *
 + * lists_rwsem also protects access to the client data list.
   */
 -#define CLIENT_DATA_REGISTERED XA_MARK_1
 +static DEFINE_MUTEX(device_mutex);
 +static DECLARE_RWSEM(lists_rwsem);
  
++<<<<<<< HEAD
++=======
+ /**
+  * struct rdma_dev_net - rdma net namespace metadata for a net
+  * @net:	Pointer to owner net namespace
+  * @id:		xarray id to identify the net namespace.
+  */
+ struct rdma_dev_net {
+ 	possible_net_t net;
+ 	u32 id;
+ };
+ 
+ static unsigned int rdma_dev_net_id;
+ 
+ /*
+  * A list of net namespaces is maintained in an xarray. This is necessary
+  * because we can't get the locking right using the existing net ns list. We
+  * would require a init_net callback after the list is updated.
+  */
+ static DEFINE_XARRAY_FLAGS(rdma_nets, XA_FLAGS_ALLOC);
+ /*
+  * rwsem to protect accessing the rdma_nets xarray entries.
+  */
+ static DECLARE_RWSEM(rdma_nets_rwsem);
+ 
+ static bool ib_devices_shared_netns = true;
+ module_param_named(netns_mode, ib_devices_shared_netns, bool, 0444);
+ MODULE_PARM_DESC(netns_mode,
+ 		 "Share device among net namespaces; default=1 (shared)");
+ /**
+  * rdma_dev_access_netns() - Return whether a rdma device can be accessed
+  *			     from a specified net namespace or not.
+  * @device:	Pointer to rdma device which needs to be checked
+  * @net:	Pointer to net namesapce for which access to be checked
+  *
+  * rdma_dev_access_netns() - Return whether a rdma device can be accessed
+  *			     from a specified net namespace or not. When
+  *			     rdma device is in shared mode, it ignores the
+  *			     net namespace. When rdma device is exclusive
+  *			     to a net namespace, rdma device net namespace is
+  *			     checked against the specified one.
+  */
+ bool rdma_dev_access_netns(const struct ib_device *dev, const struct net *net)
+ {
+ 	return (ib_devices_shared_netns ||
+ 		net_eq(read_pnet(&dev->coredev.rdma_net), net));
+ }
+ EXPORT_SYMBOL(rdma_dev_access_netns);
+ 
+ /*
+  * xarray has this behavior where it won't iterate over NULL values stored in
+  * allocated arrays.  So we need our own iterator to see all values stored in
+  * the array. This does the same thing as xa_for_each except that it also
+  * returns NULL valued entries if the array is allocating. Simplified to only
+  * work on simple xarrays.
+  */
+ static void *xan_find_marked(struct xarray *xa, unsigned long *indexp,
+ 			     xa_mark_t filter)
+ {
+ 	XA_STATE(xas, xa, *indexp);
+ 	void *entry;
+ 
+ 	rcu_read_lock();
+ 	do {
+ 		entry = xas_find_marked(&xas, ULONG_MAX, filter);
+ 		if (xa_is_zero(entry))
+ 			break;
+ 	} while (xas_retry(&xas, entry));
+ 	rcu_read_unlock();
+ 
+ 	if (entry) {
+ 		*indexp = xas.xa_index;
+ 		if (xa_is_zero(entry))
+ 			return NULL;
+ 		return entry;
+ 	}
+ 	return XA_ERROR(-ENOENT);
+ }
+ #define xan_for_each_marked(xa, index, entry, filter)                          \
+ 	for (index = 0, entry = xan_find_marked(xa, &(index), filter);         \
+ 	     !xa_is_err(entry);                                                \
+ 	     (index)++, entry = xan_find_marked(xa, &(index), filter))
+ 
+ /* RCU hash table mapping netdevice pointers to struct ib_port_data */
+ static DEFINE_SPINLOCK(ndev_hash_lock);
+ static DECLARE_HASHTABLE(ndev_hash, 5);
+ 
+ static void free_netdevs(struct ib_device *ib_dev);
+ static void ib_unregister_work(struct work_struct *work);
+ static void __ib_unregister_device(struct ib_device *device);
++>>>>>>> 41c6140189af (RDMA: Check net namespace access for uverbs, umad, cma and nldev)
  static int ib_security_change(struct notifier_block *nb, unsigned long event,
  			      void *lsm_data);
  static void ib_policy_change_task(struct work_struct *work);
diff --git a/drivers/infiniband/core/cma.c b/drivers/infiniband/core/cma.c
index 713b20ee7357..ee7fe12bf70a 100644
--- a/drivers/infiniband/core/cma.c
+++ b/drivers/infiniband/core/cma.c
@@ -616,6 +616,9 @@ cma_validate_port(struct ib_device *device, u8 port,
 	int dev_type = dev_addr->dev_type;
 	struct net_device *ndev = NULL;
 
+	if (!rdma_dev_access_netns(device, id_priv->id.route.addr.dev_addr.net))
+		return ERR_PTR(-ENODEV);
+
 	if ((dev_type == ARPHRD_INFINIBAND) && !rdma_protocol_ib(device, port))
 		return ERR_PTR(-ENODEV);
 
* Unmerged path drivers/infiniband/core/device.c
diff --git a/drivers/infiniband/core/user_mad.c b/drivers/infiniband/core/user_mad.c
index 5c3369895f8c..c4941b7cb55a 100644
--- a/drivers/infiniband/core/user_mad.c
+++ b/drivers/infiniband/core/user_mad.c
@@ -980,6 +980,11 @@ static int ib_umad_open(struct inode *inode, struct file *filp)
 		goto out;
 	}
 
+	if (!rdma_dev_access_netns(port->ib_dev, current->nsproxy->net_ns)) {
+		ret = -EPERM;
+		goto out;
+	}
+
 	file = kzalloc(sizeof(*file), GFP_KERNEL);
 	if (!file) {
 		ret = -ENOMEM;
@@ -1073,6 +1078,11 @@ static int ib_umad_sm_open(struct inode *inode, struct file *filp)
 		}
 	}
 
+	if (!rdma_dev_access_netns(port->ib_dev, current->nsproxy->net_ns)) {
+		ret = -EPERM;
+		goto err_up_sem;
+	}
+
 	ret = ib_modify_port(port->ib_dev, port->port_num, 0, &props);
 	if (ret)
 		goto err_up_sem;
diff --git a/drivers/infiniband/core/uverbs_main.c b/drivers/infiniband/core/uverbs_main.c
index 1cfcd41d038a..ecf94254272a 100644
--- a/drivers/infiniband/core/uverbs_main.c
+++ b/drivers/infiniband/core/uverbs_main.c
@@ -1093,6 +1093,11 @@ static int ib_uverbs_open(struct inode *inode, struct file *filp)
 		goto err;
 	}
 
+	if (!rdma_dev_access_netns(ib_dev, current->nsproxy->net_ns)) {
+		ret = -EPERM;
+		goto err;
+	}
+
 	/* In case IB device supports disassociate ucontext, there is no hard
 	 * dependency between uverbs device and its low level device.
 	 */
diff --git a/include/rdma/ib_verbs.h b/include/rdma/ib_verbs.h
index 2ff74f11eec0..91224672a0ac 100644
--- a/include/rdma/ib_verbs.h
+++ b/include/rdma/ib_verbs.h
@@ -4275,4 +4275,7 @@ static inline struct ib_device *rdma_device_to_ibdev(struct device *device)
  */
 #define rdma_device_to_drv_device(dev, drv_dev_struct, ibdev_member)           \
 	container_of(rdma_device_to_ibdev(dev), drv_dev_struct, ibdev_member)
+
+bool rdma_dev_access_netns(const struct ib_device *device,
+			   const struct net *net);
 #endif /* IB_VERBS_H */
