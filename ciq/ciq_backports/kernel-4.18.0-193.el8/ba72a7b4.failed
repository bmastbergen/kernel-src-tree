selftests/bpf: test for BPF_F_LOCK

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Alexei Starovoitov <ast@kernel.org>
commit ba72a7b4badbf4dd3c49c585c3c662bacc54f46e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/ba72a7b4.failed

Add C based test that runs 4 bpf programs in parallel
that update the same hash and array maps.
And another 2 threads that read from these two maps
via lookup(key, value, BPF_F_LOCK) api
to make sure the user space sees consistent value in both
hash and array elements while user space races with kernel bpf progs.

	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
(cherry picked from commit ba72a7b4badbf4dd3c49c585c3c662bacc54f46e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/testing/selftests/bpf/Makefile
#	tools/testing/selftests/bpf/test_progs.c
diff --cc tools/testing/selftests/bpf/Makefile
index 37b01554670e,9de0a1ae8d65..000000000000
--- a/tools/testing/selftests/bpf/Makefile
+++ b/tools/testing/selftests/bpf/Makefile
@@@ -26,20 -25,41 +26,49 @@@ TEST_GEN_PROGS = test_verifier test_ta
  	test_socket_cookie test_cgroup_storage test_select_reuseport test_section_names \
  	test_netcnt test_tcpnotify_user
  
 -BPF_OBJ_FILES = \
 -	test_xdp_redirect.o test_xdp_meta.o sockmap_parse_prog.o \
 -	sockmap_verdict_prog.o dev_cgroup.o sample_ret0.o \
 -	test_tcpnotify_kern.o sample_map_ret0.o test_tcpbpf_kern.o \
 -	sockmap_tcp_msg_prog.o connect4_prog.o connect6_prog.o \
 -	test_btf_haskv.o test_btf_nokv.o test_sockmap_kern.o \
 -	test_tunnel_kern.o test_sockhash_kern.o test_lwt_seg6local.o \
 -	sendmsg4_prog.o sendmsg6_prog.o test_lirc_mode2_kern.o \
 +TEST_GEN_FILES = test_pkt_access.o test_xdp.o test_l4lb.o test_tcp_estats.o test_obj_id.o \
 +	test_pkt_md_access.o test_xdp_redirect.o test_xdp_meta.o sockmap_parse_prog.o     \
 +	sockmap_verdict_prog.o dev_cgroup.o sample_ret0.o test_tracepoint.o \
 +	test_l4lb_noinline.o test_xdp_noinline.o test_stacktrace_map.o \
 +	test_tcpnotify_kern.o \
 +	sample_map_ret0.o test_tcpbpf_kern.o test_stacktrace_build_id.o \
 +	sockmap_tcp_msg_prog.o connect4_prog.o connect6_prog.o test_adjust_tail.o \
 +	test_btf_haskv.o test_btf_nokv.o test_sockmap_kern.o test_tunnel_kern.o \
 +	test_get_stack_rawtp.o test_sockmap_kern.o test_sockhash_kern.o \
 +	test_lwt_seg6local.o sendmsg4_prog.o sendmsg6_prog.o test_lirc_mode2_kern.o \
  	get_cgroup_id_kern.o socket_cookie_prog.o test_select_reuseport_kern.o \
++<<<<<<< HEAD
 +	test_skb_cgroup_id_kern.o bpf_flow.o netcnt_prog.o \
 +	test_sk_lookup_kern.o test_xdp_vlan.o test_queue_map.o test_stack_map.o \
 +	xdp_dummy.o test_map_in_map.o
++=======
+ 	test_skb_cgroup_id_kern.o bpf_flow.o netcnt_prog.o test_xdp_vlan.o \
+ 	xdp_dummy.o test_map_in_map.o test_spin_lock.o test_map_lock.o
+ 
+ # Objects are built with default compilation flags and with sub-register
+ # code-gen enabled.
+ BPF_OBJ_FILES_DUAL_COMPILE = \
+ 	test_pkt_access.o test_pkt_access.o test_xdp.o test_adjust_tail.o \
+ 	test_l4lb.o test_l4lb_noinline.o test_xdp_noinline.o test_tcp_estats.o \
+ 	test_obj_id.o test_pkt_md_access.o test_tracepoint.o \
+ 	test_stacktrace_map.o test_stacktrace_map.o test_stacktrace_build_id.o \
+ 	test_stacktrace_build_id.o test_get_stack_rawtp.o \
+ 	test_get_stack_rawtp.o test_tracepoint.o test_sk_lookup_kern.o \
+ 	test_queue_map.o test_stack_map.o
+ 
+ TEST_GEN_FILES = $(BPF_OBJ_FILES) $(BPF_OBJ_FILES_DUAL_COMPILE)
+ 
+ # Also test sub-register code-gen if LLVM + kernel both has eBPF v3 processor
+ # support which is the first version to contain both ALU32 and JMP32
+ # instructions.
+ SUBREG_CODEGEN := $(shell echo "int cal(int a) { return a > 0; }" | \
+ 			$(CLANG) -target bpf -O2 -emit-llvm -S -x c - -o - | \
+ 			$(LLC) -mattr=+alu32 -mcpu=probe 2>&1 | \
+ 			grep 'if w')
+ ifneq ($(SUBREG_CODEGEN),)
+ TEST_GEN_FILES += $(patsubst %.o,alu32/%.o, $(BPF_OBJ_FILES_DUAL_COMPILE))
+ endif
++>>>>>>> ba72a7b4badb (selftests/bpf: test for BPF_F_LOCK)
  
  # Order correspond to 'make run_tests' order
  TEST_PROGS := test_kmod.sh \
diff --cc tools/testing/selftests/bpf/test_progs.c
index 07492da31eba,a08d026ac396..000000000000
--- a/tools/testing/selftests/bpf/test_progs.c
+++ b/tools/testing/selftests/bpf/test_progs.c
@@@ -1995,6 -1985,119 +1995,122 @@@ static void test_flow_dissector(void
  	bpf_object__close(obj);
  }
  
++<<<<<<< HEAD
++=======
+ static void *test_spin_lock(void *arg)
+ {
+ 	__u32 duration, retval;
+ 	int err, prog_fd = *(u32 *) arg;
+ 
+ 	err = bpf_prog_test_run(prog_fd, 10000, &pkt_v4, sizeof(pkt_v4),
+ 				NULL, NULL, &retval, &duration);
+ 	CHECK(err || retval, "",
+ 	      "err %d errno %d retval %d duration %d\n",
+ 	      err, errno, retval, duration);
+ 	pthread_exit(arg);
+ }
+ 
+ static void test_spinlock(void)
+ {
+ 	const char *file = "./test_spin_lock.o";
+ 	pthread_t thread_id[4];
+ 	struct bpf_object *obj;
+ 	int prog_fd;
+ 	int err = 0, i;
+ 	void *ret;
+ 
+ 	err = bpf_prog_load(file, BPF_PROG_TYPE_CGROUP_SKB, &obj, &prog_fd);
+ 	if (err) {
+ 		printf("test_spin_lock:bpf_prog_load errno %d\n", errno);
+ 		goto close_prog;
+ 	}
+ 	for (i = 0; i < 4; i++)
+ 		assert(pthread_create(&thread_id[i], NULL,
+ 				      &test_spin_lock, &prog_fd) == 0);
+ 	for (i = 0; i < 4; i++)
+ 		assert(pthread_join(thread_id[i], &ret) == 0 &&
+ 		       ret == (void *)&prog_fd);
+ 	goto close_prog_noerr;
+ close_prog:
+ 	error_cnt++;
+ close_prog_noerr:
+ 	bpf_object__close(obj);
+ }
+ 
+ static void *parallel_map_access(void *arg)
+ {
+ 	int err, map_fd = *(u32 *) arg;
+ 	int vars[17], i, j, rnd, key = 0;
+ 
+ 	for (i = 0; i < 10000; i++) {
+ 		err = bpf_map_lookup_elem_flags(map_fd, &key, vars, BPF_F_LOCK);
+ 		if (err) {
+ 			printf("lookup failed\n");
+ 			error_cnt++;
+ 			goto out;
+ 		}
+ 		if (vars[0] != 0) {
+ 			printf("lookup #%d var[0]=%d\n", i, vars[0]);
+ 			error_cnt++;
+ 			goto out;
+ 		}
+ 		rnd = vars[1];
+ 		for (j = 2; j < 17; j++) {
+ 			if (vars[j] == rnd)
+ 				continue;
+ 			printf("lookup #%d var[1]=%d var[%d]=%d\n",
+ 			       i, rnd, j, vars[j]);
+ 			error_cnt++;
+ 			goto out;
+ 		}
+ 	}
+ out:
+ 	pthread_exit(arg);
+ }
+ 
+ static void test_map_lock(void)
+ {
+ 	const char *file = "./test_map_lock.o";
+ 	int prog_fd, map_fd[2], vars[17] = {};
+ 	pthread_t thread_id[6];
+ 	struct bpf_object *obj;
+ 	int err = 0, key = 0, i;
+ 	void *ret;
+ 
+ 	err = bpf_prog_load(file, BPF_PROG_TYPE_CGROUP_SKB, &obj, &prog_fd);
+ 	if (err) {
+ 		printf("test_map_lock:bpf_prog_load errno %d\n", errno);
+ 		goto close_prog;
+ 	}
+ 	map_fd[0] = bpf_find_map(__func__, obj, "hash_map");
+ 	if (map_fd[0] < 0)
+ 		goto close_prog;
+ 	map_fd[1] = bpf_find_map(__func__, obj, "array_map");
+ 	if (map_fd[1] < 0)
+ 		goto close_prog;
+ 
+ 	bpf_map_update_elem(map_fd[0], &key, vars, BPF_F_LOCK);
+ 
+ 	for (i = 0; i < 4; i++)
+ 		assert(pthread_create(&thread_id[i], NULL,
+ 				      &test_spin_lock, &prog_fd) == 0);
+ 	for (i = 4; i < 6; i++)
+ 		assert(pthread_create(&thread_id[i], NULL,
+ 				      &parallel_map_access, &map_fd[i - 4]) == 0);
+ 	for (i = 0; i < 4; i++)
+ 		assert(pthread_join(thread_id[i], &ret) == 0 &&
+ 		       ret == (void *)&prog_fd);
+ 	for (i = 4; i < 6; i++)
+ 		assert(pthread_join(thread_id[i], &ret) == 0 &&
+ 		       ret == (void *)&map_fd[i - 4]);
+ 	goto close_prog_noerr;
+ close_prog:
+ 	error_cnt++;
+ close_prog_noerr:
+ 	bpf_object__close(obj);
+ }
+ 
++>>>>>>> ba72a7b4badb (selftests/bpf: test for BPF_F_LOCK)
  int main(void)
  {
  	srand(time(NULL));
@@@ -2023,6 -2126,8 +2139,11 @@@
  	test_queue_stack_map(QUEUE);
  	test_queue_stack_map(STACK);
  	test_flow_dissector();
++<<<<<<< HEAD
++=======
+ 	test_spinlock();
+ 	test_map_lock();
++>>>>>>> ba72a7b4badb (selftests/bpf: test for BPF_F_LOCK)
  
  	printf("Summary: %d PASSED, %d FAILED\n", pass_cnt, error_cnt);
  	return error_cnt ? EXIT_FAILURE : EXIT_SUCCESS;
* Unmerged path tools/testing/selftests/bpf/Makefile
diff --git a/tools/testing/selftests/bpf/test_map_lock.c b/tools/testing/selftests/bpf/test_map_lock.c
new file mode 100644
index 000000000000..af8cc68ed2f9
--- /dev/null
+++ b/tools/testing/selftests/bpf/test_map_lock.c
@@ -0,0 +1,66 @@
+// SPDX-License-Identifier: GPL-2.0
+// Copyright (c) 2019 Facebook
+#include <linux/bpf.h>
+#include <linux/version.h>
+#include "bpf_helpers.h"
+
+#define VAR_NUM 16
+
+struct hmap_elem {
+	struct bpf_spin_lock lock;
+	int var[VAR_NUM];
+};
+
+struct bpf_map_def SEC("maps") hash_map = {
+	.type = BPF_MAP_TYPE_HASH,
+	.key_size = sizeof(int),
+	.value_size = sizeof(struct hmap_elem),
+	.max_entries = 1,
+};
+
+BPF_ANNOTATE_KV_PAIR(hash_map, int, struct hmap_elem);
+
+struct array_elem {
+	struct bpf_spin_lock lock;
+	int var[VAR_NUM];
+};
+
+struct bpf_map_def SEC("maps") array_map = {
+	.type = BPF_MAP_TYPE_ARRAY,
+	.key_size = sizeof(int),
+	.value_size = sizeof(struct array_elem),
+	.max_entries = 1,
+};
+
+BPF_ANNOTATE_KV_PAIR(array_map, int, struct array_elem);
+
+SEC("map_lock_demo")
+int bpf_map_lock_test(struct __sk_buff *skb)
+{
+	struct hmap_elem zero = {}, *val;
+	int rnd = bpf_get_prandom_u32();
+	int key = 0, err = 1, i;
+	struct array_elem *q;
+
+	val = bpf_map_lookup_elem(&hash_map, &key);
+	if (!val)
+		goto err;
+	/* spin_lock in hash map */
+	bpf_spin_lock(&val->lock);
+	for (i = 0; i < VAR_NUM; i++)
+		val->var[i] = rnd;
+	bpf_spin_unlock(&val->lock);
+
+	/* spin_lock in array */
+	q = bpf_map_lookup_elem(&array_map, &key);
+	if (!q)
+		goto err;
+	bpf_spin_lock(&q->lock);
+	for (i = 0; i < VAR_NUM; i++)
+		q->var[i] = rnd;
+	bpf_spin_unlock(&q->lock);
+	err = 0;
+err:
+	return err;
+}
+char _license[] SEC("license") = "GPL";
* Unmerged path tools/testing/selftests/bpf/test_progs.c
