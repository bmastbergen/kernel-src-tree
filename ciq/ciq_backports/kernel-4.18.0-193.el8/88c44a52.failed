net/sched: add block pointer to tc_cls_common_offload structure

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [net] sched: add block pointer to tc_cls_common_offload structure (Ivan Vecera) [1731416]
Rebuild_FUZZ: 96.72%
commit-author Pieter Jansen van Vuuren <pieter.jansenvanvuuren@netronome.com>
commit 88c44a5200849c8182eaf36535b4ceae6b90b19d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/88c44a52.failed

Some actions like the police action are stateful and could share state
between devices. This is incompatible with offloading to multiple devices
and drivers might want to test for shared blocks when offloading.
Store a pointer to the tcf_block structure in the tc_cls_common_offload
structure to allow drivers to determine when offloads apply to a shared
block.

	Signed-off-by: Pieter Jansen van Vuuren <pieter.jansenvanvuuren@netronome.com>
	Reviewed-by: Jakub Kicinski <jakub.kicinski@netronome.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 88c44a5200849c8182eaf36535b4ceae6b90b19d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sched/cls_flower.c
diff --cc net/sched/cls_flower.c
index bf30bf04d4ea,3cb372b0e933..000000000000
--- a/net/sched/cls_flower.c
+++ b/net/sched/cls_flower.c
@@@ -370,7 -386,11 +370,15 @@@ static void fl_hw_destroy_filter(struc
  	struct tc_cls_flower_offload cls_flower = {};
  	struct tcf_block *block = tp->chain->block;
  
++<<<<<<< HEAD
 +	tc_cls_common_offload_init(&cls_flower.common, tp, f->flags, extack);
++=======
+ 	if (!rtnl_held)
+ 		rtnl_lock();
+ 
+ 	tc_cls_common_offload_init(&cls_flower.common, tp, f->flags, block,
+ 				   extack);
++>>>>>>> 88c44a520084 (net/sched: add block pointer to tc_cls_common_offload structure)
  	cls_flower.command = TC_CLSFLOWER_DESTROY;
  	cls_flower.cookie = (unsigned long) f;
  
@@@ -385,13 -411,20 +393,14 @@@ static int fl_hw_replace_filter(struct 
  	struct tc_cls_flower_offload cls_flower = {};
  	struct tcf_block *block = tp->chain->block;
  	bool skip_sw = tc_skip_sw(f->flags);
 -	int err = 0;
 -
 -	if (!rtnl_held)
 -		rtnl_lock();
 +	int err;
  
  	cls_flower.rule = flow_rule_alloc(tcf_exts_num_actions(&f->exts));
 -	if (!cls_flower.rule) {
 -		err = -ENOMEM;
 -		goto errout;
 -	}
 +	if (!cls_flower.rule)
 +		return -ENOMEM;
  
- 	tc_cls_common_offload_init(&cls_flower.common, tp, f->flags, extack);
+ 	tc_cls_common_offload_init(&cls_flower.common, tp, f->flags, block,
+ 				   extack);
  	cls_flower.command = TC_CLSFLOWER_REPLACE;
  	cls_flower.cookie = (unsigned long) f;
  	cls_flower.rule->match.dissector = &f->mask->dissector;
@@@ -431,7 -477,11 +440,15 @@@ static void fl_hw_update_stats(struct t
  	struct tc_cls_flower_offload cls_flower = {};
  	struct tcf_block *block = tp->chain->block;
  
++<<<<<<< HEAD
 +	tc_cls_common_offload_init(&cls_flower.common, tp, f->flags, NULL);
++=======
+ 	if (!rtnl_held)
+ 		rtnl_lock();
+ 
+ 	tc_cls_common_offload_init(&cls_flower.common, tp, f->flags, block,
+ 				   NULL);
++>>>>>>> 88c44a520084 (net/sched: add block pointer to tc_cls_common_offload structure)
  	cls_flower.command = TC_CLSFLOWER_STATS;
  	cls_flower.cookie = (unsigned long) f;
  	cls_flower.classid = f->res.classid;
@@@ -1544,57 -1715,89 +1561,68 @@@ static void fl_walk(struct tcf_proto *t
  static int fl_reoffload(struct tcf_proto *tp, bool add, tc_setup_cb_t *cb,
  			void *cb_priv, struct netlink_ext_ack *extack)
  {
 +	struct cls_fl_head *head = fl_head_dereference(tp);
  	struct tc_cls_flower_offload cls_flower = {};
  	struct tcf_block *block = tp->chain->block;
 -	struct cls_fl_filter *f = NULL;
 +	struct fl_flow_mask *mask;
 +	struct cls_fl_filter *f;
  	int err;
  
 -	/* hw_filters list can only be changed by hw offload functions after
 -	 * obtaining rtnl lock. Make sure it is not changed while reoffload is
 -	 * iterating it.
 -	 */
 -	ASSERT_RTNL();
 -
 -	while ((f = fl_get_next_hw_filter(tp, f, add))) {
 -		cls_flower.rule =
 -			flow_rule_alloc(tcf_exts_num_actions(&f->exts));
 -		if (!cls_flower.rule) {
 -			__fl_put(f);
 -			return -ENOMEM;
 -		}
 -
 +	list_for_each_entry(mask, &head->masks, list) {
 +		list_for_each_entry(f, &mask->filters, list) {
 +			if (tc_skip_hw(f->flags))
 +				continue;
 +
 +			cls_flower.rule =
 +				flow_rule_alloc(tcf_exts_num_actions(&f->exts));
 +			if (!cls_flower.rule)
 +				return -ENOMEM;
 +
++<<<<<<< HEAD
 +			tc_cls_common_offload_init(&cls_flower.common, tp,
 +						   f->flags, extack);
 +			cls_flower.command = add ?
 +				TC_CLSFLOWER_REPLACE : TC_CLSFLOWER_DESTROY;
 +			cls_flower.cookie = (unsigned long)f;
 +			cls_flower.rule->match.dissector = &mask->dissector;
 +			cls_flower.rule->match.mask = &mask->key;
 +			cls_flower.rule->match.key = &f->mkey;
++=======
+ 		tc_cls_common_offload_init(&cls_flower.common, tp, f->flags,
+ 					   block, extack);
+ 		cls_flower.command = add ?
+ 			TC_CLSFLOWER_REPLACE : TC_CLSFLOWER_DESTROY;
+ 		cls_flower.cookie = (unsigned long)f;
+ 		cls_flower.rule->match.dissector = &f->mask->dissector;
+ 		cls_flower.rule->match.mask = &f->mask->key;
+ 		cls_flower.rule->match.key = &f->mkey;
 -
 -		err = tc_setup_flow_action(&cls_flower.rule->action, &f->exts);
 -		if (err) {
 -			kfree(cls_flower.rule);
 -			if (tc_skip_sw(f->flags)) {
 -				NL_SET_ERR_MSG_MOD(extack, "Failed to setup flow action");
 -				__fl_put(f);
 -				return err;
++>>>>>>> 88c44a520084 (net/sched: add block pointer to tc_cls_common_offload structure)
 +
 +			err = tc_setup_flow_action(&cls_flower.rule->action,
 +						   &f->exts);
 +			if (err) {
 +				kfree(cls_flower.rule);
 +				if (tc_skip_sw(f->flags)) {
 +					NL_SET_ERR_MSG_MOD(extack, "Failed to setup flow action");
 +					return err;
 +				}
 +				continue;
  			}
 -			goto next_flow;
 -		}
  
 -		cls_flower.classid = f->res.classid;
 +			cls_flower.classid = f->res.classid;
  
 -		err = cb(TC_SETUP_CLSFLOWER, &cls_flower, cb_priv);
 -		kfree(cls_flower.rule);
 +			err = cb(TC_SETUP_CLSFLOWER, &cls_flower, cb_priv);
 +			kfree(cls_flower.rule);
  
 -		if (err) {
 -			if (add && tc_skip_sw(f->flags)) {
 -				__fl_put(f);
 -				return err;
 +			if (err) {
 +				if (add && tc_skip_sw(f->flags))
 +					return err;
 +				continue;
  			}
 -			goto next_flow;
 -		}
  
 -		spin_lock(&tp->lock);
 -		tc_cls_offload_cnt_update(block, &f->in_hw_count, &f->flags,
 -					  add);
 -		spin_unlock(&tp->lock);
 -next_flow:
 -		__fl_put(f);
 +			tc_cls_offload_cnt_update(block, &f->in_hw_count,
 +						  &f->flags, add);
 +		}
  	}
  
  	return 0;
diff --git a/include/net/pkt_cls.h b/include/net/pkt_cls.h
index 835bbad70a4b..9db32da5f24c 100644
--- a/include/net/pkt_cls.h
+++ b/include/net/pkt_cls.h
@@ -104,6 +104,11 @@ int tcf_classify(struct sk_buff *skb, const struct tcf_proto *tp,
 		 struct tcf_result *res, bool compat_mode);
 
 #else
+static inline bool tcf_block_shared(struct tcf_block *block)
+{
+	return false;
+}
+
 static inline
 int tcf_block_get(struct tcf_block **p_block,
 		  struct tcf_proto __rcu **p_filter_chain, struct Qdisc *q,
@@ -628,6 +633,7 @@ struct tc_cls_common_offload {
 	u32 chain_index;
 	__be16 protocol;
 	u32 prio;
+	struct tcf_block *block;
 	struct netlink_ext_ack *extack;
 };
 
@@ -729,11 +735,13 @@ static inline bool tc_in_hw(u32 flags)
 static inline void
 tc_cls_common_offload_init(struct tc_cls_common_offload *cls_common,
 			   const struct tcf_proto *tp, u32 flags,
+			   struct tcf_block *block,
 			   struct netlink_ext_ack *extack)
 {
 	cls_common->chain_index = tp->chain->index;
 	cls_common->protocol = tp->protocol;
 	cls_common->prio = tp->prio;
+	cls_common->block = block;
 	if (tc_skip_sw(flags) || flags & TCA_CLS_FLAGS_VERBOSE)
 		cls_common->extack = extack;
 }
diff --git a/net/sched/cls_bpf.c b/net/sched/cls_bpf.c
index ff1deece0104..c68678606185 100644
--- a/net/sched/cls_bpf.c
+++ b/net/sched/cls_bpf.c
@@ -159,7 +159,7 @@ static int cls_bpf_offload_cmd(struct tcf_proto *tp, struct cls_bpf_prog *prog,
 	skip_sw = prog && tc_skip_sw(prog->gen_flags);
 	obj = prog ?: oldprog;
 
-	tc_cls_common_offload_init(&cls_bpf.common, tp, obj->gen_flags,
+	tc_cls_common_offload_init(&cls_bpf.common, tp, obj->gen_flags, block,
 				   extack);
 	cls_bpf.command = TC_CLSBPF_OFFLOAD;
 	cls_bpf.exts = &obj->exts;
@@ -229,7 +229,8 @@ static void cls_bpf_offload_update_stats(struct tcf_proto *tp,
 	struct tcf_block *block = tp->chain->block;
 	struct tc_cls_bpf_offload cls_bpf = {};
 
-	tc_cls_common_offload_init(&cls_bpf.common, tp, prog->gen_flags, NULL);
+	tc_cls_common_offload_init(&cls_bpf.common, tp, prog->gen_flags, block,
+				   NULL);
 	cls_bpf.command = TC_CLSBPF_STATS;
 	cls_bpf.exts = &prog->exts;
 	cls_bpf.prog = prog->filter;
@@ -673,7 +674,7 @@ static int cls_bpf_reoffload(struct tcf_proto *tp, bool add, tc_setup_cb_t *cb,
 			continue;
 
 		tc_cls_common_offload_init(&cls_bpf.common, tp, prog->gen_flags,
-					   extack);
+					   block, extack);
 		cls_bpf.command = TC_CLSBPF_OFFLOAD;
 		cls_bpf.exts = &prog->exts;
 		cls_bpf.prog = add ? prog->filter : NULL;
* Unmerged path net/sched/cls_flower.c
diff --git a/net/sched/cls_matchall.c b/net/sched/cls_matchall.c
index 297b15dae9b8..8317b14572ee 100644
--- a/net/sched/cls_matchall.c
+++ b/net/sched/cls_matchall.c
@@ -74,7 +74,8 @@ static void mall_destroy_hw_filter(struct tcf_proto *tp,
 	struct tc_cls_matchall_offload cls_mall = {};
 	struct tcf_block *block = tp->chain->block;
 
-	tc_cls_common_offload_init(&cls_mall.common, tp, head->flags, extack);
+	tc_cls_common_offload_init(&cls_mall.common, tp, head->flags, block,
+				   extack);
 	cls_mall.command = TC_CLSMATCHALL_DESTROY;
 	cls_mall.cookie = cookie;
 
@@ -96,7 +97,8 @@ static int mall_replace_hw_filter(struct tcf_proto *tp,
 	if (!cls_mall.rule)
 		return -ENOMEM;
 
-	tc_cls_common_offload_init(&cls_mall.common, tp, head->flags, extack);
+	tc_cls_common_offload_init(&cls_mall.common, tp, head->flags, block,
+				   extack);
 	cls_mall.command = TC_CLSMATCHALL_REPLACE;
 	cls_mall.cookie = cookie;
 
@@ -296,7 +298,8 @@ static int mall_reoffload(struct tcf_proto *tp, bool add, tc_setup_cb_t *cb,
 	if (!cls_mall.rule)
 		return -ENOMEM;
 
-	tc_cls_common_offload_init(&cls_mall.common, tp, head->flags, extack);
+	tc_cls_common_offload_init(&cls_mall.common, tp, head->flags, block,
+				   extack);
 	cls_mall.command = add ?
 		TC_CLSMATCHALL_REPLACE : TC_CLSMATCHALL_DESTROY;
 	cls_mall.cookie = (unsigned long)head;
@@ -332,7 +335,8 @@ static void mall_stats_hw_filter(struct tcf_proto *tp,
 	struct tc_cls_matchall_offload cls_mall = {};
 	struct tcf_block *block = tp->chain->block;
 
-	tc_cls_common_offload_init(&cls_mall.common, tp, head->flags, NULL);
+	tc_cls_common_offload_init(&cls_mall.common, tp, head->flags, block,
+				   NULL);
 	cls_mall.command = TC_CLSMATCHALL_STATS;
 	cls_mall.cookie = cookie;
 
diff --git a/net/sched/cls_u32.c b/net/sched/cls_u32.c
index b0858cec6fae..ec37bc1ed621 100644
--- a/net/sched/cls_u32.c
+++ b/net/sched/cls_u32.c
@@ -485,7 +485,8 @@ static void u32_clear_hw_hnode(struct tcf_proto *tp, struct tc_u_hnode *h,
 	struct tcf_block *block = tp->chain->block;
 	struct tc_cls_u32_offload cls_u32 = {};
 
-	tc_cls_common_offload_init(&cls_u32.common, tp, h->flags, extack);
+	tc_cls_common_offload_init(&cls_u32.common, tp, h->flags, block,
+				   extack);
 	cls_u32.command = TC_CLSU32_DELETE_HNODE;
 	cls_u32.hnode.divisor = h->divisor;
 	cls_u32.hnode.handle = h->handle;
@@ -503,7 +504,7 @@ static int u32_replace_hw_hnode(struct tcf_proto *tp, struct tc_u_hnode *h,
 	bool offloaded = false;
 	int err;
 
-	tc_cls_common_offload_init(&cls_u32.common, tp, flags, extack);
+	tc_cls_common_offload_init(&cls_u32.common, tp, flags, block, extack);
 	cls_u32.command = TC_CLSU32_NEW_HNODE;
 	cls_u32.hnode.divisor = h->divisor;
 	cls_u32.hnode.handle = h->handle;
@@ -529,7 +530,8 @@ static void u32_remove_hw_knode(struct tcf_proto *tp, struct tc_u_knode *n,
 	struct tcf_block *block = tp->chain->block;
 	struct tc_cls_u32_offload cls_u32 = {};
 
-	tc_cls_common_offload_init(&cls_u32.common, tp, n->flags, extack);
+	tc_cls_common_offload_init(&cls_u32.common, tp, n->flags, block,
+				   extack);
 	cls_u32.command = TC_CLSU32_DELETE_KNODE;
 	cls_u32.knode.handle = n->handle;
 
@@ -546,7 +548,7 @@ static int u32_replace_hw_knode(struct tcf_proto *tp, struct tc_u_knode *n,
 	bool skip_sw = tc_skip_sw(flags);
 	int err;
 
-	tc_cls_common_offload_init(&cls_u32.common, tp, flags, extack);
+	tc_cls_common_offload_init(&cls_u32.common, tp, flags, block, extack);
 	cls_u32.command = TC_CLSU32_REPLACE_KNODE;
 	cls_u32.knode.handle = n->handle;
 	cls_u32.knode.fshift = n->fshift;
@@ -1169,10 +1171,12 @@ static int u32_reoffload_hnode(struct tcf_proto *tp, struct tc_u_hnode *ht,
 			       bool add, tc_setup_cb_t *cb, void *cb_priv,
 			       struct netlink_ext_ack *extack)
 {
+	struct tcf_block *block = tp->chain->block;
 	struct tc_cls_u32_offload cls_u32 = {};
 	int err;
 
-	tc_cls_common_offload_init(&cls_u32.common, tp, ht->flags, extack);
+	tc_cls_common_offload_init(&cls_u32.common, tp, ht->flags, block,
+				   extack);
 	cls_u32.command = add ? TC_CLSU32_NEW_HNODE : TC_CLSU32_DELETE_HNODE;
 	cls_u32.hnode.divisor = ht->divisor;
 	cls_u32.hnode.handle = ht->handle;
@@ -1194,7 +1198,8 @@ static int u32_reoffload_knode(struct tcf_proto *tp, struct tc_u_knode *n,
 	struct tc_cls_u32_offload cls_u32 = {};
 	int err;
 
-	tc_cls_common_offload_init(&cls_u32.common, tp, n->flags, extack);
+	tc_cls_common_offload_init(&cls_u32.common, tp, n->flags, block,
+				   extack);
 	cls_u32.command = add ?
 		TC_CLSU32_REPLACE_KNODE : TC_CLSU32_DELETE_KNODE;
 	cls_u32.knode.handle = n->handle;
