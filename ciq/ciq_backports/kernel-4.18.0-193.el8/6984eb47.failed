arm64/cpufeature: detect pointer authentication

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Mark Rutland <mark.rutland@arm.com>
commit 6984eb47d5c1a74bb44467ee4eee22d680f10785
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/6984eb47.failed

So that we can dynamically handle the presence of pointer authentication
functionality, wire up probing code in cpufeature.c.

From ARMv8.3 onwards, ID_AA64ISAR1 is no longer entirely RES0, and now
has four fields describing the presence of pointer authentication
functionality:

* APA - address authentication present, using an architected algorithm
* API - address authentication present, using an IMP DEF algorithm
* GPA - generic authentication present, using an architected algorithm
* GPI - generic authentication present, using an IMP DEF algorithm

This patch checks for both address and generic authentication,
separately. It is assumed that if all CPUs support an IMP DEF algorithm,
the same algorithm is used across all CPUs.

	Reviewed-by: Richard Henderson <richard.henderson@linaro.org>
	Signed-off-by: Mark Rutland <mark.rutland@arm.com>
	Signed-off-by: Kristina Martsenko <kristina.martsenko@arm.com>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Suzuki K Poulose <suzuki.poulose@arm.com>
	Cc: Will Deacon <will.deacon@arm.com>
	Signed-off-by: Will Deacon <will.deacon@arm.com>
(cherry picked from commit 6984eb47d5c1a74bb44467ee4eee22d680f10785)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/cpucaps.h
#	arch/arm64/kernel/cpufeature.c
diff --cc arch/arm64/include/asm/cpucaps.h
index 1a8df16d556c,803f388e81d4..000000000000
--- a/arch/arm64/include/asm/cpucaps.h
+++ b/arch/arm64/include/asm/cpucaps.h
@@@ -51,11 -51,18 +51,23 @@@
  #define ARM64_SSBD				30
  #define ARM64_MISMATCHED_CACHE_TYPE		31
  #define ARM64_HAS_STAGE2_FWB			32
 -#define ARM64_HAS_CRC32				33
 +#define ARM64_WORKAROUND_1188873		33
  #define ARM64_SSBS				34
 -#define ARM64_WORKAROUND_1188873		35
 +#define ARM64_WORKAROUND_1165522		35
  #define ARM64_HAS_SB				36
++<<<<<<< HEAD
 +
 +#define ARM64_NCAPS				37
++=======
+ #define ARM64_WORKAROUND_1165522		37
+ #define ARM64_HAS_ADDRESS_AUTH_ARCH		38
+ #define ARM64_HAS_ADDRESS_AUTH_IMP_DEF		39
+ #define ARM64_HAS_ADDRESS_AUTH			40
+ #define ARM64_HAS_GENERIC_AUTH_ARCH		41
+ #define ARM64_HAS_GENERIC_AUTH_IMP_DEF		42
+ #define ARM64_HAS_GENERIC_AUTH			43
+ 
+ #define ARM64_NCAPS				44
++>>>>>>> 6984eb47d5c1 (arm64/cpufeature: detect pointer authentication)
  
  #endif /* __ASM_CPUCAPS_H */
diff --cc arch/arm64/kernel/cpufeature.c
index ea14666781d7,c82ebd8f0087..000000000000
--- a/arch/arm64/kernel/cpufeature.c
+++ b/arch/arm64/kernel/cpufeature.c
@@@ -1162,6 -1168,58 +1170,61 @@@ static void cpu_enable_ssbs(const struc
  }
  #endif /* CONFIG_ARM64_SSBD */
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_ARM64_PAN
+ static void cpu_enable_pan(const struct arm64_cpu_capabilities *__unused)
+ {
+ 	/*
+ 	 * We modify PSTATE. This won't work from irq context as the PSTATE
+ 	 * is discarded once we return from the exception.
+ 	 */
+ 	WARN_ON_ONCE(in_interrupt());
+ 
+ 	sysreg_clear_set(sctlr_el1, SCTLR_EL1_SPAN, 0);
+ 	asm(SET_PSTATE_PAN(1));
+ }
+ #endif /* CONFIG_ARM64_PAN */
+ 
+ #ifdef CONFIG_ARM64_RAS_EXTN
+ static void cpu_clear_disr(const struct arm64_cpu_capabilities *__unused)
+ {
+ 	/* Firmware may have left a deferred SError in this register. */
+ 	write_sysreg_s(0, SYS_DISR_EL1);
+ }
+ #endif /* CONFIG_ARM64_RAS_EXTN */
+ 
+ #ifdef CONFIG_ARM64_PTR_AUTH
+ static bool has_address_auth(const struct arm64_cpu_capabilities *entry,
+ 			     int __unused)
+ {
+ 	u64 isar1 = read_sanitised_ftr_reg(SYS_ID_AA64ISAR1_EL1);
+ 	bool api, apa;
+ 
+ 	apa = cpuid_feature_extract_unsigned_field(isar1,
+ 					ID_AA64ISAR1_APA_SHIFT) > 0;
+ 	api = cpuid_feature_extract_unsigned_field(isar1,
+ 					ID_AA64ISAR1_API_SHIFT) > 0;
+ 
+ 	return apa || api;
+ }
+ 
+ static bool has_generic_auth(const struct arm64_cpu_capabilities *entry,
+ 			     int __unused)
+ {
+ 	u64 isar1 = read_sanitised_ftr_reg(SYS_ID_AA64ISAR1_EL1);
+ 	bool gpi, gpa;
+ 
+ 	gpa = cpuid_feature_extract_unsigned_field(isar1,
+ 					ID_AA64ISAR1_GPA_SHIFT) > 0;
+ 	gpi = cpuid_feature_extract_unsigned_field(isar1,
+ 					ID_AA64ISAR1_GPI_SHIFT) > 0;
+ 
+ 	return gpa || gpi;
+ }
+ #endif /* CONFIG_ARM64_PTR_AUTH */
+ 
++>>>>>>> 6984eb47d5c1 (arm64/cpufeature: detect pointer authentication)
  static const struct arm64_cpu_capabilities arm64_features[] = {
  	{
  		.desc = "GIC system register CPU interface",
@@@ -1371,19 -1443,68 +1434,74 @@@
  		.cpu_enable = cpu_enable_cnp,
  	},
  #endif
 +#ifdef CONFIG_ARM64_SSBD
  	{
 -		.desc = "Speculation barrier (SB)",
 -		.capability = ARM64_HAS_SB,
 -		.type = ARM64_CPUCAP_SYSTEM_FEATURE,
 +		.desc = "Speculative Store Bypassing Safe (SSBS)",
 +		.capability = ARM64_SSBS,
 +		.type = ARM64_CPUCAP_WEAK_LOCAL_CPU_FEATURE,
  		.matches = has_cpuid_feature,
 -		.sys_reg = SYS_ID_AA64ISAR1_EL1,
 -		.field_pos = ID_AA64ISAR1_SB_SHIFT,
 +		.sys_reg = SYS_ID_AA64PFR1_EL1,
 +		.field_pos = ID_AA64PFR1_SSBS_SHIFT,
  		.sign = FTR_UNSIGNED,
 -		.min_field_value = 1,
 +		.min_field_value = ID_AA64PFR1_SSBS_PSTATE_ONLY,
 +		.cpu_enable = cpu_enable_ssbs,
  	},
++<<<<<<< HEAD
 +#endif
++=======
+ #ifdef CONFIG_ARM64_PTR_AUTH
+ 	{
+ 		.desc = "Address authentication (architected algorithm)",
+ 		.capability = ARM64_HAS_ADDRESS_AUTH_ARCH,
+ 		.type = ARM64_CPUCAP_SYSTEM_FEATURE,
+ 		.sys_reg = SYS_ID_AA64ISAR1_EL1,
+ 		.sign = FTR_UNSIGNED,
+ 		.field_pos = ID_AA64ISAR1_APA_SHIFT,
+ 		.min_field_value = ID_AA64ISAR1_APA_ARCHITECTED,
+ 		.matches = has_cpuid_feature,
+ 	},
+ 	{
+ 		.desc = "Address authentication (IMP DEF algorithm)",
+ 		.capability = ARM64_HAS_ADDRESS_AUTH_IMP_DEF,
+ 		.type = ARM64_CPUCAP_SYSTEM_FEATURE,
+ 		.sys_reg = SYS_ID_AA64ISAR1_EL1,
+ 		.sign = FTR_UNSIGNED,
+ 		.field_pos = ID_AA64ISAR1_API_SHIFT,
+ 		.min_field_value = ID_AA64ISAR1_API_IMP_DEF,
+ 		.matches = has_cpuid_feature,
+ 	},
+ 	{
+ 		.capability = ARM64_HAS_ADDRESS_AUTH,
+ 		.type = ARM64_CPUCAP_SYSTEM_FEATURE,
+ 		.matches = has_address_auth,
+ 	},
+ 	{
+ 		.desc = "Generic authentication (architected algorithm)",
+ 		.capability = ARM64_HAS_GENERIC_AUTH_ARCH,
+ 		.type = ARM64_CPUCAP_SYSTEM_FEATURE,
+ 		.sys_reg = SYS_ID_AA64ISAR1_EL1,
+ 		.sign = FTR_UNSIGNED,
+ 		.field_pos = ID_AA64ISAR1_GPA_SHIFT,
+ 		.min_field_value = ID_AA64ISAR1_GPA_ARCHITECTED,
+ 		.matches = has_cpuid_feature,
+ 	},
+ 	{
+ 		.desc = "Generic authentication (IMP DEF algorithm)",
+ 		.capability = ARM64_HAS_GENERIC_AUTH_IMP_DEF,
+ 		.type = ARM64_CPUCAP_SYSTEM_FEATURE,
+ 		.sys_reg = SYS_ID_AA64ISAR1_EL1,
+ 		.sign = FTR_UNSIGNED,
+ 		.field_pos = ID_AA64ISAR1_GPI_SHIFT,
+ 		.min_field_value = ID_AA64ISAR1_GPI_IMP_DEF,
+ 		.matches = has_cpuid_feature,
+ 	},
+ 	{
+ 		.capability = ARM64_HAS_GENERIC_AUTH,
+ 		.type = ARM64_CPUCAP_SYSTEM_FEATURE,
+ 		.matches = has_generic_auth,
+ 	},
+ #endif /* CONFIG_ARM64_PTR_AUTH */
++>>>>>>> 6984eb47d5c1 (arm64/cpufeature: detect pointer authentication)
  	{},
  };
  
* Unmerged path arch/arm64/include/asm/cpucaps.h
diff --git a/arch/arm64/include/asm/cpufeature.h b/arch/arm64/include/asm/cpufeature.h
index 7c0459c391c4..848b337e5857 100644
--- a/arch/arm64/include/asm/cpufeature.h
+++ b/arch/arm64/include/asm/cpufeature.h
@@ -562,6 +562,18 @@ static inline bool system_supports_cnp(void)
 		cpus_have_const_cap(ARM64_HAS_CNP);
 }
 
+static inline bool system_supports_address_auth(void)
+{
+	return IS_ENABLED(CONFIG_ARM64_PTR_AUTH) &&
+		cpus_have_const_cap(ARM64_HAS_ADDRESS_AUTH);
+}
+
+static inline bool system_supports_generic_auth(void)
+{
+	return IS_ENABLED(CONFIG_ARM64_PTR_AUTH) &&
+		cpus_have_const_cap(ARM64_HAS_GENERIC_AUTH);
+}
+
 #define ARM64_SSBD_UNKNOWN		-1
 #define ARM64_SSBD_FORCE_DISABLE	0
 #define ARM64_SSBD_KERNEL		1
* Unmerged path arch/arm64/kernel/cpufeature.c
