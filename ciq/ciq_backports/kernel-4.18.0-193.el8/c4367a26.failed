IB: Pass uverbs_attr_bundle down ib_x destroy path

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Shamir Rabinovitch <shamir.rabinovitch@oracle.com>
commit c4367a26357be501338e41ceae7ebb7ce57064e5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/c4367a26.failed

The uverbs_attr_bundle with the ucontext is sent down to the drivers ib_x
destroy path as ib_udata. The next patch will use the ib_udata to free the
drivers destroy path from the dependency in 'uobject->context' as we
already did for the create path.

	Signed-off-by: Shamir Rabinovitch <shamir.rabinovitch@oracle.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit c4367a26357be501338e41ceae7ebb7ce57064e5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/uverbs_cmd.c
#	drivers/infiniband/core/uverbs_std_types.c
#	drivers/infiniband/core/verbs.c
#	drivers/infiniband/hw/bnxt_re/ib_verbs.c
#	drivers/infiniband/hw/bnxt_re/ib_verbs.h
#	drivers/infiniband/hw/cxgb3/iwch_provider.c
#	drivers/infiniband/hw/cxgb4/provider.c
#	drivers/infiniband/hw/hns/hns_roce_device.h
#	drivers/infiniband/hw/hns/hns_roce_hw_v1.c
#	drivers/infiniband/hw/hns/hns_roce_mr.c
#	drivers/infiniband/hw/hns/hns_roce_pd.c
#	drivers/infiniband/hw/hns/hns_roce_srq.c
#	drivers/infiniband/hw/i40iw/i40iw_verbs.c
#	drivers/infiniband/hw/mlx4/main.c
#	drivers/infiniband/hw/mlx5/main.c
#	drivers/infiniband/hw/mthca/mthca_provider.c
#	drivers/infiniband/hw/nes/nes_verbs.c
#	drivers/infiniband/hw/ocrdma/ocrdma_verbs.c
#	drivers/infiniband/hw/ocrdma/ocrdma_verbs.h
#	drivers/infiniband/hw/qedr/verbs.c
#	drivers/infiniband/hw/qedr/verbs.h
#	drivers/infiniband/hw/usnic/usnic_ib_verbs.c
#	drivers/infiniband/hw/usnic/usnic_ib_verbs.h
#	drivers/infiniband/hw/vmw_pvrdma/pvrdma_verbs.c
#	drivers/infiniband/hw/vmw_pvrdma/pvrdma_verbs.h
#	drivers/infiniband/sw/rdmavt/pd.c
#	drivers/infiniband/sw/rdmavt/pd.h
#	drivers/infiniband/sw/rxe/rxe_verbs.c
#	include/rdma/ib_verbs.h
diff --cc drivers/infiniband/core/uverbs_cmd.c
index 4aa2231ad8ef,fe63dfd5f1b6..000000000000
--- a/drivers/infiniband/core/uverbs_cmd.c
+++ b/drivers/infiniband/core/uverbs_cmd.c
@@@ -428,13 -436,15 +428,20 @@@ static int ib_uverbs_alloc_pd(struct uv
  	if (ret)
  		goto err_copy;
  
 -	return uobj_alloc_commit(uobj, attrs);
 +	return uobj_alloc_commit(uobj);
  
  err_copy:
++<<<<<<< HEAD
 +	ib_dealloc_pd(pd);
 +
++=======
+ 	ib_dealloc_pd_user(pd, &attrs->driver_udata);
+ 	pd = NULL;
+ err_alloc:
+ 	kfree(pd);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  err:
 -	uobj_alloc_abort(uobj, attrs);
 +	uobj_alloc_abort(uobj);
  	return ret;
  }
  
@@@ -633,10 -643,10 +640,10 @@@ err_copy
  	}
  
  err_dealloc_xrcd:
- 	ib_dealloc_xrcd(xrcd);
+ 	ib_dealloc_xrcd(xrcd, &attrs->driver_udata);
  
  err:
 -	uobj_alloc_abort(&obj->uobject, attrs);
 +	uobj_alloc_abort(&obj->uobject);
  
  err_tree_mutex_unlock:
  	if (f.file)
@@@ -753,10 -762,10 +759,10 @@@ static int ib_uverbs_reg_mr(struct uver
  
  	uobj_put_obj_read(pd);
  
 -	return uobj_alloc_commit(uobj, attrs);
 +	return uobj_alloc_commit(uobj);
  
  err_copy:
- 	ib_dereg_mr(mr);
+ 	ib_dereg_mr_user(mr, &attrs->driver_udata);
  
  err_put:
  	uobj_put_obj_read(pd);
@@@ -2952,10 -2961,10 +2958,10 @@@ static int ib_uverbs_ex_create_wq(struc
  
  	uobj_put_obj_read(pd);
  	uobj_put_obj_read(cq);
 -	return uobj_alloc_commit(&obj->uevent.uobject, attrs);
 +	return uobj_alloc_commit(&obj->uevent.uobject);
  
  err_copy:
- 	ib_destroy_wq(wq);
+ 	ib_destroy_wq(wq, &attrs->driver_udata);
  err_put_cq:
  	uobj_put_obj_read(cq);
  err_put_pd:
@@@ -3448,10 -3457,10 +3454,10 @@@ static int __uverbs_create_xsrq(struct 
  		uobj_put_obj_read(attr.ext.cq);
  
  	uobj_put_obj_read(pd);
 -	return uobj_alloc_commit(&obj->uevent.uobject, attrs);
 +	return uobj_alloc_commit(&obj->uevent.uobject);
  
  err_copy:
- 	ib_destroy_srq(srq);
+ 	ib_destroy_srq_user(srq, &attrs->driver_udata);
  
  err_put:
  	uobj_put_obj_read(pd);
diff --cc drivers/infiniband/core/uverbs_std_types.c
index cbc72312eb41,c625f590a8f0..000000000000
--- a/drivers/infiniband/core/uverbs_std_types.c
+++ b/drivers/infiniband/core/uverbs_std_types.c
@@@ -40,10 -40,12 +40,11 @@@
  #include "uverbs.h"
  
  static int uverbs_free_ah(struct ib_uobject *uobject,
 -			  enum rdma_remove_reason why,
 -			  struct uverbs_attr_bundle *attrs)
 +			  enum rdma_remove_reason why)
  {
- 	return rdma_destroy_ah((struct ib_ah *)uobject->object,
- 			       RDMA_DESTROY_AH_SLEEPABLE);
+ 	return rdma_destroy_ah_user((struct ib_ah *)uobject->object,
+ 				    RDMA_DESTROY_AH_SLEEPABLE,
+ 				    &attrs->driver_udata);
  }
  
  static int uverbs_free_flow(struct ib_uobject *uobject,
@@@ -188,7 -198,7 +189,11 @@@ static int uverbs_free_pd(struct ib_uob
  	if (ret)
  		return ret;
  
++<<<<<<< HEAD
 +	ib_dealloc_pd((struct ib_pd *)uobject->object);
++=======
+ 	ib_dealloc_pd_user(pd, &attrs->driver_udata);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  	return 0;
  }
  
diff --cc drivers/infiniband/core/verbs.c
index 3220fb42ecce,ba9a89df815d..000000000000
--- a/drivers/infiniband/core/verbs.c
+++ b/drivers/infiniband/core/verbs.c
@@@ -329,12 -337,10 +330,17 @@@ void ib_dealloc_pd_user(struct ib_pd *p
  	WARN_ON(atomic_read(&pd->usecnt));
  
  	rdma_restrack_del(&pd->res);
++<<<<<<< HEAD
 +	/* Making delalloc_pd a void return is a WIP, no driver should return
 +	   an error here. */
 +	ret = pd->device->ops.dealloc_pd(pd);
 +	WARN_ONCE(ret, "Infiniband HW driver failed dealloc_pd");
++=======
+ 	pd->device->ops.dealloc_pd(pd, udata);
+ 	kfree(pd);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  }
- EXPORT_SYMBOL(ib_dealloc_pd);
+ EXPORT_SYMBOL(ib_dealloc_pd_user);
  
  /* Address handles */
  
diff --cc drivers/infiniband/hw/bnxt_re/ib_verbs.c
index bfcab22666c5,a586ac28630b..000000000000
--- a/drivers/infiniband/hw/bnxt_re/ib_verbs.c
+++ b/drivers/infiniband/hw/bnxt_re/ib_verbs.c
@@@ -563,7 -564,7 +563,11 @@@ fail
  }
  
  /* Protection Domains */
++<<<<<<< HEAD
 +int bnxt_re_dealloc_pd(struct ib_pd *ib_pd)
++=======
+ void bnxt_re_dealloc_pd(struct ib_pd *ib_pd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	struct bnxt_re_pd *pd = container_of(ib_pd, struct bnxt_re_pd, ib_pd);
  	struct bnxt_re_dev *rdev = pd->rdev;
diff --cc drivers/infiniband/hw/bnxt_re/ib_verbs.h
index c4af72604b4f,44e49988600e..000000000000
--- a/drivers/infiniband/hw/bnxt_re/ib_verbs.h
+++ b/drivers/infiniband/hw/bnxt_re/ib_verbs.h
@@@ -163,10 -163,9 +163,16 @@@ int bnxt_re_query_gid(struct ib_device 
  		      int index, union ib_gid *gid);
  enum rdma_link_layer bnxt_re_get_link_layer(struct ib_device *ibdev,
  					    u8 port_num);
++<<<<<<< HEAD
 +struct ib_pd *bnxt_re_alloc_pd(struct ib_device *ibdev,
 +			       struct ib_ucontext *context,
 +			       struct ib_udata *udata);
 +int bnxt_re_dealloc_pd(struct ib_pd *pd);
++=======
+ int bnxt_re_alloc_pd(struct ib_pd *pd, struct ib_ucontext *context,
+ 		     struct ib_udata *udata);
+ void bnxt_re_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  struct ib_ah *bnxt_re_create_ah(struct ib_pd *pd,
  				struct rdma_ah_attr *ah_attr,
  				u32 flags,
diff --cc drivers/infiniband/hw/cxgb3/iwch_provider.c
index b9bb151437dc,e10a56242998..000000000000
--- a/drivers/infiniband/hw/cxgb3/iwch_provider.c
+++ b/drivers/infiniband/hw/cxgb3/iwch_provider.c
@@@ -88,10 -85,10 +88,10 @@@ static struct ib_ucontext *iwch_alloc_u
  	cxio_init_ucontext(&rhp->rdev, &context->uctx);
  	INIT_LIST_HEAD(&context->mmaps);
  	spin_lock_init(&context->mmap_lock);
 -	return 0;
 +	return &context->ibucontext;
  }
  
- static int iwch_destroy_cq(struct ib_cq *ib_cq)
+ static int iwch_destroy_cq(struct ib_cq *ib_cq, struct ib_udata *udata)
  {
  	struct iwch_cq *chp;
  
@@@ -370,7 -367,7 +370,11 @@@ static int iwch_mmap(struct ib_ucontex
  	return ret;
  }
  
++<<<<<<< HEAD
 +static int iwch_deallocate_pd(struct ib_pd *pd)
++=======
+ static void iwch_deallocate_pd(struct ib_pd *pd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	struct iwch_dev *rhp;
  	struct iwch_pd *php;
@@@ -407,15 -398,15 +411,20 @@@ static struct ib_pd *iwch_allocate_pd(s
  		struct iwch_alloc_pd_resp resp = {.pdid = php->pdid};
  
  		if (ib_copy_to_udata(udata, &resp, sizeof(resp))) {
++<<<<<<< HEAD
 +			iwch_deallocate_pd(&php->ibpd);
 +			return ERR_PTR(-EFAULT);
++=======
+ 			iwch_deallocate_pd(&php->ibpd, udata);
+ 			return -EFAULT;
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  		}
  	}
  	pr_debug("%s pdid 0x%0x ptr 0x%p\n", __func__, pdid, php);
 -	return 0;
 +	return &php->ibpd;
  }
  
- static int iwch_dereg_mr(struct ib_mr *ib_mr)
+ static int iwch_dereg_mr(struct ib_mr *ib_mr, struct ib_udata *udata)
  {
  	struct iwch_dev *rhp;
  	struct iwch_mr *mhp;
diff --cc drivers/infiniband/hw/cxgb4/provider.c
index adda8df00ce5,12f7d3ae6a53..000000000000
--- a/drivers/infiniband/hw/cxgb4/provider.c
+++ b/drivers/infiniband/hw/cxgb4/provider.c
@@@ -199,7 -190,7 +199,11 @@@ static int c4iw_mmap(struct ib_ucontex
  	return ret;
  }
  
++<<<<<<< HEAD
 +static int c4iw_deallocate_pd(struct ib_pd *pd)
++=======
+ static void c4iw_deallocate_pd(struct ib_pd *pd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	struct c4iw_dev *rhp;
  	struct c4iw_pd *php;
@@@ -239,8 -224,8 +243,13 @@@ static struct ib_pd *c4iw_allocate_pd(s
  		struct c4iw_alloc_pd_resp uresp = {.pdid = php->pdid};
  
  		if (ib_copy_to_udata(udata, &uresp, sizeof(uresp))) {
++<<<<<<< HEAD
 +			c4iw_deallocate_pd(&php->ibpd);
 +			return ERR_PTR(-EFAULT);
++=======
+ 			c4iw_deallocate_pd(&php->ibpd, udata);
+ 			return -EFAULT;
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  		}
  	}
  	mutex_lock(&rhp->rdev.stats.lock);
diff --cc drivers/infiniband/hw/hns/hns_roce_device.h
index 5996c474cbe8,780a7ba204db..000000000000
--- a/drivers/infiniband/hw/hns/hns_roce_device.h
+++ b/drivers/infiniband/hw/hns/hns_roce_device.h
@@@ -781,7 -905,9 +781,13 @@@ struct hns_roce_hw 
  	int (*modify_qp)(struct ib_qp *ibqp, const struct ib_qp_attr *attr,
  			 int attr_mask, enum ib_qp_state cur_state,
  			 enum ib_qp_state new_state);
++<<<<<<< HEAD
 +	int (*destroy_qp)(struct ib_qp *ibqp);
++=======
+ 	int (*destroy_qp)(struct ib_qp *ibqp, struct ib_udata *udata);
+ 	int (*qp_flow_control_init)(struct hns_roce_dev *hr_dev,
+ 			 struct hns_roce_qp *hr_qp);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  	int (*post_send)(struct ib_qp *ibqp, const struct ib_send_wr *wr,
  			 const struct ib_send_wr **bad_wr);
  	int (*post_recv)(struct ib_qp *qp, const struct ib_recv_wr *recv_wr,
@@@ -961,12 -1110,11 +968,18 @@@ struct ib_ah *hns_roce_create_ah(struc
  				 u32 flags,
  				 struct ib_udata *udata);
  int hns_roce_query_ah(struct ib_ah *ibah, struct rdma_ah_attr *ah_attr);
- int hns_roce_destroy_ah(struct ib_ah *ah, u32 flags);
+ int hns_roce_destroy_ah(struct ib_ah *ah, u32 flags, struct ib_udata *udata);
  
++<<<<<<< HEAD
 +struct ib_pd *hns_roce_alloc_pd(struct ib_device *ib_dev,
 +				struct ib_ucontext *context,
 +				struct ib_udata *udata);
 +int hns_roce_dealloc_pd(struct ib_pd *pd);
++=======
+ int hns_roce_alloc_pd(struct ib_pd *pd, struct ib_ucontext *context,
+ 		      struct ib_udata *udata);
+ void hns_roce_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  
  struct ib_mr *hns_roce_get_dma_mr(struct ib_pd *pd, int acc);
  struct ib_mr *hns_roce_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,
@@@ -975,7 -1123,11 +988,15 @@@
  int hns_roce_rereg_user_mr(struct ib_mr *mr, int flags, u64 start, u64 length,
  			   u64 virt_addr, int mr_access_flags, struct ib_pd *pd,
  			   struct ib_udata *udata);
++<<<<<<< HEAD
 +int hns_roce_dereg_mr(struct ib_mr *ibmr);
++=======
+ struct ib_mr *hns_roce_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
+ 				u32 max_num_sg, struct ib_udata *udata);
+ int hns_roce_map_mr_sg(struct ib_mr *ibmr, struct scatterlist *sg, int sg_nents,
+ 		       unsigned int *sg_offset);
+ int hns_roce_dereg_mr(struct ib_mr *ibmr, struct ib_udata *udata);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  int hns_roce_hw2sw_mpt(struct hns_roce_dev *hr_dev,
  		       struct hns_roce_cmd_mailbox *mailbox,
  		       unsigned long mpt_index);
@@@ -989,6 -1145,14 +1010,17 @@@ int hns_roce_buf_alloc(struct hns_roce_
  int hns_roce_ib_umem_write_mtt(struct hns_roce_dev *hr_dev,
  			       struct hns_roce_mtt *mtt, struct ib_umem *umem);
  
++<<<<<<< HEAD
++=======
+ struct ib_srq *hns_roce_create_srq(struct ib_pd *pd,
+ 				   struct ib_srq_init_attr *srq_init_attr,
+ 				   struct ib_udata *udata);
+ int hns_roce_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *srq_attr,
+ 			enum ib_srq_attr_mask srq_attr_mask,
+ 			struct ib_udata *udata);
+ int hns_roce_destroy_srq(struct ib_srq *ibsrq, struct ib_udata *udata);
+ 
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  struct ib_qp *hns_roce_create_qp(struct ib_pd *ib_pd,
  				 struct ib_qp_init_attr *init_attr,
  				 struct ib_udata *udata);
@@@ -1016,10 -1180,11 +1048,10 @@@ struct ib_cq *hns_roce_ib_create_cq(str
  				    struct ib_ucontext *context,
  				    struct ib_udata *udata);
  
- int hns_roce_ib_destroy_cq(struct ib_cq *ib_cq);
+ int hns_roce_ib_destroy_cq(struct ib_cq *ib_cq, struct ib_udata *udata);
  void hns_roce_free_cq(struct hns_roce_dev *hr_dev, struct hns_roce_cq *hr_cq);
  
 -int hns_roce_db_map_user(struct hns_roce_ucontext *context,
 -			 struct ib_udata *udata, unsigned long virt,
 +int hns_roce_db_map_user(struct hns_roce_ucontext *context, unsigned long virt,
  			 struct hns_roce_db *db);
  void hns_roce_db_unmap_user(struct hns_roce_ucontext *context,
  			    struct hns_roce_db *db);
diff --cc drivers/infiniband/hw/hns/hns_roce_hw_v1.c
index 2b5be3df27d6,1863516f6be9..000000000000
--- a/drivers/infiniband/hw/hns/hns_roce_hw_v1.c
+++ b/drivers/infiniband/hw/hns/hns_roce_hw_v1.c
@@@ -853,14 -859,16 +853,24 @@@ create_lp_qp_failed
  			dev_err(dev, "Destroy qp %d for mr free failed!\n", i);
  	}
  
++<<<<<<< HEAD
 +	if (hns_roce_dealloc_pd(pd))
 +		dev_err(dev, "Destroy pd for create_lp_qp failed!\n");
 +
 +alloc_pd_failed:
 +	if (hns_roce_ib_destroy_cq(cq))
++=======
+ 	hns_roce_dealloc_pd(pd, NULL);
+ 
+ alloc_pd_failed:
+ 	kfree(pd);
+ 
+ alloc_mem_failed:
+ 	if (hns_roce_ib_destroy_cq(cq, NULL))
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  		dev_err(dev, "Destroy cq for create_lp_qp failed!\n");
  
 -	return ret;
 +	return -EINVAL;
  }
  
  static void hns_roce_v1_release_lp_qp(struct hns_roce_dev *hr_dev)
@@@ -890,9 -898,7 +900,13 @@@
  	if (ret)
  		dev_err(dev, "Destroy cq for mr_free failed(%d)!\n", ret);
  
++<<<<<<< HEAD
 +	ret = hns_roce_dealloc_pd(&free_mr->mr_free_pd->ibpd);
 +	if (ret)
 +		dev_err(dev, "Destroy pd for mr_free failed(%d)!\n", ret);
++=======
+ 	hns_roce_dealloc_pd(&free_mr->mr_free_pd->ibpd, NULL);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  }
  
  static int hns_roce_db_init(struct hns_roce_dev *hr_dev)
diff --cc drivers/infiniband/hw/hns/hns_roce_mr.c
index d066659b382b,9119d875b13d..000000000000
--- a/drivers/infiniband/hw/hns/hns_roce_mr.c
+++ b/drivers/infiniband/hw/hns/hns_roce_mr.c
@@@ -1201,3 -1301,193 +1201,196 @@@ int hns_roce_dereg_mr(struct ib_mr *ibm
  
  	return ret;
  }
++<<<<<<< HEAD
++=======
+ 
+ struct ib_mr *hns_roce_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
+ 				u32 max_num_sg, struct ib_udata *udata)
+ {
+ 	struct hns_roce_dev *hr_dev = to_hr_dev(pd->device);
+ 	struct device *dev = hr_dev->dev;
+ 	struct hns_roce_mr *mr;
+ 	u64 length;
+ 	u32 page_size;
+ 	int ret;
+ 
+ 	page_size = 1 << (hr_dev->caps.pbl_buf_pg_sz + PAGE_SHIFT);
+ 	length = max_num_sg * page_size;
+ 
+ 	if (mr_type != IB_MR_TYPE_MEM_REG)
+ 		return ERR_PTR(-EINVAL);
+ 
+ 	if (max_num_sg > HNS_ROCE_FRMR_MAX_PA) {
+ 		dev_err(dev, "max_num_sg larger than %d\n",
+ 			HNS_ROCE_FRMR_MAX_PA);
+ 		return ERR_PTR(-EINVAL);
+ 	}
+ 
+ 	mr = kzalloc(sizeof(*mr), GFP_KERNEL);
+ 	if (!mr)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	mr->type = MR_TYPE_FRMR;
+ 
+ 	/* Allocate memory region key */
+ 	ret = hns_roce_mr_alloc(hr_dev, to_hr_pd(pd)->pdn, 0, length,
+ 				0, max_num_sg, mr);
+ 	if (ret)
+ 		goto err_free;
+ 
+ 	ret = hns_roce_mr_enable(hr_dev, mr);
+ 	if (ret)
+ 		goto err_mr;
+ 
+ 	mr->ibmr.rkey = mr->ibmr.lkey = mr->key;
+ 	mr->umem = NULL;
+ 
+ 	return &mr->ibmr;
+ 
+ err_mr:
+ 	hns_roce_mr_free(to_hr_dev(pd->device), mr);
+ 
+ err_free:
+ 	kfree(mr);
+ 	return ERR_PTR(ret);
+ }
+ 
+ static int hns_roce_set_page(struct ib_mr *ibmr, u64 addr)
+ {
+ 	struct hns_roce_mr *mr = to_hr_mr(ibmr);
+ 
+ 	mr->pbl_buf[mr->npages++] = cpu_to_le64(addr);
+ 
+ 	return 0;
+ }
+ 
+ int hns_roce_map_mr_sg(struct ib_mr *ibmr, struct scatterlist *sg, int sg_nents,
+ 		       unsigned int *sg_offset)
+ {
+ 	struct hns_roce_mr *mr = to_hr_mr(ibmr);
+ 
+ 	mr->npages = 0;
+ 
+ 	return ib_sg_to_pages(ibmr, sg, sg_nents, sg_offset, hns_roce_set_page);
+ }
+ 
+ static void hns_roce_mw_free(struct hns_roce_dev *hr_dev,
+ 			     struct hns_roce_mw *mw)
+ {
+ 	struct device *dev = hr_dev->dev;
+ 	int ret;
+ 
+ 	if (mw->enabled) {
+ 		ret = hns_roce_hw2sw_mpt(hr_dev, NULL, key_to_hw_index(mw->rkey)
+ 					 & (hr_dev->caps.num_mtpts - 1));
+ 		if (ret)
+ 			dev_warn(dev, "MW HW2SW_MPT failed (%d)\n", ret);
+ 
+ 		hns_roce_table_put(hr_dev, &hr_dev->mr_table.mtpt_table,
+ 				   key_to_hw_index(mw->rkey));
+ 	}
+ 
+ 	hns_roce_bitmap_free(&hr_dev->mr_table.mtpt_bitmap,
+ 			     key_to_hw_index(mw->rkey), BITMAP_NO_RR);
+ }
+ 
+ static int hns_roce_mw_enable(struct hns_roce_dev *hr_dev,
+ 			      struct hns_roce_mw *mw)
+ {
+ 	struct hns_roce_mr_table *mr_table = &hr_dev->mr_table;
+ 	struct hns_roce_cmd_mailbox *mailbox;
+ 	struct device *dev = hr_dev->dev;
+ 	unsigned long mtpt_idx = key_to_hw_index(mw->rkey);
+ 	int ret;
+ 
+ 	/* prepare HEM entry memory */
+ 	ret = hns_roce_table_get(hr_dev, &mr_table->mtpt_table, mtpt_idx);
+ 	if (ret)
+ 		return ret;
+ 
+ 	mailbox = hns_roce_alloc_cmd_mailbox(hr_dev);
+ 	if (IS_ERR(mailbox)) {
+ 		ret = PTR_ERR(mailbox);
+ 		goto err_table;
+ 	}
+ 
+ 	ret = hr_dev->hw->mw_write_mtpt(mailbox->buf, mw);
+ 	if (ret) {
+ 		dev_err(dev, "MW write mtpt fail!\n");
+ 		goto err_page;
+ 	}
+ 
+ 	ret = hns_roce_sw2hw_mpt(hr_dev, mailbox,
+ 				 mtpt_idx & (hr_dev->caps.num_mtpts - 1));
+ 	if (ret) {
+ 		dev_err(dev, "MW sw2hw_mpt failed (%d)\n", ret);
+ 		goto err_page;
+ 	}
+ 
+ 	mw->enabled = 1;
+ 
+ 	hns_roce_free_cmd_mailbox(hr_dev, mailbox);
+ 
+ 	return 0;
+ 
+ err_page:
+ 	hns_roce_free_cmd_mailbox(hr_dev, mailbox);
+ 
+ err_table:
+ 	hns_roce_table_put(hr_dev, &mr_table->mtpt_table, mtpt_idx);
+ 
+ 	return ret;
+ }
+ 
+ struct ib_mw *hns_roce_alloc_mw(struct ib_pd *ib_pd, enum ib_mw_type type,
+ 				struct ib_udata *udata)
+ {
+ 	struct hns_roce_dev *hr_dev = to_hr_dev(ib_pd->device);
+ 	struct hns_roce_mw *mw;
+ 	unsigned long index = 0;
+ 	int ret;
+ 
+ 	mw = kmalloc(sizeof(*mw), GFP_KERNEL);
+ 	if (!mw)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	/* Allocate a key for mw from bitmap */
+ 	ret = hns_roce_bitmap_alloc(&hr_dev->mr_table.mtpt_bitmap, &index);
+ 	if (ret)
+ 		goto err_bitmap;
+ 
+ 	mw->rkey = hw_index_to_key(index);
+ 
+ 	mw->ibmw.rkey = mw->rkey;
+ 	mw->ibmw.type = type;
+ 	mw->pdn = to_hr_pd(ib_pd)->pdn;
+ 	mw->pbl_hop_num = hr_dev->caps.pbl_hop_num;
+ 	mw->pbl_ba_pg_sz = hr_dev->caps.pbl_ba_pg_sz;
+ 	mw->pbl_buf_pg_sz = hr_dev->caps.pbl_buf_pg_sz;
+ 
+ 	ret = hns_roce_mw_enable(hr_dev, mw);
+ 	if (ret)
+ 		goto err_mw;
+ 
+ 	return &mw->ibmw;
+ 
+ err_mw:
+ 	hns_roce_mw_free(hr_dev, mw);
+ 
+ err_bitmap:
+ 	kfree(mw);
+ 
+ 	return ERR_PTR(ret);
+ }
+ 
+ int hns_roce_dealloc_mw(struct ib_mw *ibmw)
+ {
+ 	struct hns_roce_dev *hr_dev = to_hr_dev(ibmw->device);
+ 	struct hns_roce_mw *mw = to_hr_mw(ibmw);
+ 
+ 	hns_roce_mw_free(hr_dev, mw);
+ 	kfree(mw);
+ 
+ 	return 0;
+ }
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
diff --cc drivers/infiniband/hw/hns/hns_roce_pd.c
index 4a29b2cb9bab,504e6e466d72..000000000000
--- a/drivers/infiniband/hw/hns/hns_roce_pd.c
+++ b/drivers/infiniband/hw/hns/hns_roce_pd.c
@@@ -92,12 -86,9 +92,16 @@@ struct ib_pd *hns_roce_alloc_pd(struct 
  }
  EXPORT_SYMBOL_GPL(hns_roce_alloc_pd);
  
++<<<<<<< HEAD
 +int hns_roce_dealloc_pd(struct ib_pd *pd)
++=======
+ void hns_roce_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	hns_roce_pd_free(to_hr_dev(pd->device), to_hr_pd(pd)->pdn);
 +	kfree(to_hr_pd(pd));
 +
 +	return 0;
  }
  EXPORT_SYMBOL_GPL(hns_roce_dealloc_pd);
  
diff --cc drivers/infiniband/hw/i40iw/i40iw_verbs.c
index 524f42b9e564,fd2d7426c832..000000000000
--- a/drivers/infiniband/hw/i40iw/i40iw_verbs.c
+++ b/drivers/infiniband/hw/i40iw/i40iw_verbs.c
@@@ -372,8 -342,9 +372,13 @@@ free_res
  /**
   * i40iw_dealloc_pd - deallocate pd
   * @ibpd: ptr of pd to be deallocated
+  * @udata: user data or null for kernel object
   */
++<<<<<<< HEAD
 +static int i40iw_dealloc_pd(struct ib_pd *ibpd)
++=======
+ static void i40iw_dealloc_pd(struct ib_pd *ibpd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	struct i40iw_pd *iwpd = to_iwpd(ibpd);
  	struct i40iw_device *iwdev = to_iwdev(ibpd->device);
diff --cc drivers/infiniband/hw/mlx4/main.c
index d66002a31000,e50f9de71119..000000000000
--- a/drivers/infiniband/hw/mlx4/main.c
+++ b/drivers/infiniband/hw/mlx4/main.c
@@@ -1186,38 -1177,27 +1186,42 @@@ static int mlx4_ib_mmap(struct ib_ucont
  	}
  }
  
 -static int mlx4_ib_alloc_pd(struct ib_pd *ibpd, struct ib_ucontext *context,
 -			    struct ib_udata *udata)
 +static struct ib_pd *mlx4_ib_alloc_pd(struct ib_device *ibdev,
 +				      struct ib_ucontext *context,
 +				      struct ib_udata *udata)
  {
 -	struct mlx4_ib_pd *pd = to_mpd(ibpd);
 -	struct ib_device *ibdev = ibpd->device;
 +	struct mlx4_ib_pd *pd;
  	int err;
  
 -	err = mlx4_pd_alloc(to_mdev(ibdev)->dev, &pd->pdn);
 -	if (err)
 -		return err;
 +	pd = kzalloc(sizeof(*pd), GFP_KERNEL);
 +	if (!pd)
 +		return ERR_PTR(-ENOMEM);
  
 -	if (context && ib_copy_to_udata(udata, &pd->pdn, sizeof(__u32))) {
 -		mlx4_pd_free(to_mdev(ibdev)->dev, pd->pdn);
 -		return -EFAULT;
 +	err = mlx4_pd_alloc(to_mdev(ibdev)->dev, &pd->pdn);
 +	if (err) {
 +		kfree(pd);
 +		return ERR_PTR(err);
  	}
 -	return 0;
 +
 +	if (context)
 +		if (ib_copy_to_udata(udata, &pd->pdn, sizeof (__u32))) {
 +			mlx4_pd_free(to_mdev(ibdev)->dev, pd->pdn);
 +			kfree(pd);
 +			return ERR_PTR(-EFAULT);
 +		}
 +	return &pd->ibpd;
  }
  
++<<<<<<< HEAD
 +static int mlx4_ib_dealloc_pd(struct ib_pd *pd)
++=======
+ static void mlx4_ib_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	mlx4_pd_free(to_mdev(pd->device)->dev, to_mpd(pd)->pdn);
 +	kfree(pd);
 +
 +	return 0;
  }
  
  static struct ib_xrcd *mlx4_ib_alloc_xrcd(struct ib_device *ibdev,
diff --cc drivers/infiniband/hw/mlx5/main.c
index 2e9e8914ac78,468544819c79..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -2356,10 -2367,10 +2356,14 @@@ static struct ib_pd *mlx5_ib_alloc_pd(s
  		}
  	}
  
 -	return 0;
 +	return &pd->ibpd;
  }
  
++<<<<<<< HEAD
 +static int mlx5_ib_dealloc_pd(struct ib_pd *pd)
++=======
+ static void mlx5_ib_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	struct mlx5_ib_dev *mdev = to_mdev(pd->device);
  	struct mlx5_ib_pd *mpd = to_mpd(pd);
@@@ -4803,16 -4837,17 +4807,16 @@@ static int create_dev_resources(struct 
  	return 0;
  
  error5:
- 	mlx5_ib_destroy_srq(devr->s0);
+ 	mlx5_ib_destroy_srq(devr->s0, NULL);
  error4:
- 	mlx5_ib_dealloc_xrcd(devr->x1);
+ 	mlx5_ib_dealloc_xrcd(devr->x1, NULL);
  error3:
- 	mlx5_ib_dealloc_xrcd(devr->x0);
+ 	mlx5_ib_dealloc_xrcd(devr->x0, NULL);
  error2:
- 	mlx5_ib_destroy_cq(devr->c0);
+ 	mlx5_ib_destroy_cq(devr->c0, NULL);
  error1:
- 	mlx5_ib_dealloc_pd(devr->p0);
+ 	mlx5_ib_dealloc_pd(devr->p0, NULL);
  error0:
 -	kfree(devr->p0);
  	return ret;
  }
  
@@@ -4822,12 -4857,13 +4826,22 @@@ static void destroy_dev_resources(struc
  		container_of(devr, struct mlx5_ib_dev, devr);
  	int port;
  
++<<<<<<< HEAD
 +	mlx5_ib_destroy_srq(devr->s1);
 +	mlx5_ib_destroy_srq(devr->s0);
 +	mlx5_ib_dealloc_xrcd(devr->x0);
 +	mlx5_ib_dealloc_xrcd(devr->x1);
 +	mlx5_ib_destroy_cq(devr->c0);
 +	mlx5_ib_dealloc_pd(devr->p0);
++=======
+ 	mlx5_ib_destroy_srq(devr->s1, NULL);
+ 	mlx5_ib_destroy_srq(devr->s0, NULL);
+ 	mlx5_ib_dealloc_xrcd(devr->x0, NULL);
+ 	mlx5_ib_dealloc_xrcd(devr->x1, NULL);
+ 	mlx5_ib_destroy_cq(devr->c0, NULL);
+ 	mlx5_ib_dealloc_pd(devr->p0, NULL);
+ 	kfree(devr->p0);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  
  	/* Make sure no change P_Key work items are still executing */
  	for (port = 0; port < dev->num_ports; ++port)
diff --cc drivers/infiniband/hw/mthca/mthca_provider.c
index ae6b236e4756,872f0ad556a7..000000000000
--- a/drivers/infiniband/hw/mthca/mthca_provider.c
+++ b/drivers/infiniband/hw/mthca/mthca_provider.c
@@@ -399,15 -381,12 +399,19 @@@ static struct ib_pd *mthca_alloc_pd(str
  		}
  	}
  
 -	return 0;
 +	return &pd->ibpd;
  }
  
++<<<<<<< HEAD
 +static int mthca_dealloc_pd(struct ib_pd *pd)
++=======
+ static void mthca_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	mthca_pd_free(to_mdev(pd->device), to_mpd(pd));
 +	kfree(pd);
 +
 +	return 0;
  }
  
  static struct ib_ah *mthca_ah_create(struct ib_pd *pd,
diff --cc drivers/infiniband/hw/nes/nes_verbs.c
index cd4fa4729089,4b7855c7dacf..000000000000
--- a/drivers/infiniband/hw/nes/nes_verbs.c
+++ b/drivers/infiniband/hw/nes/nes_verbs.c
@@@ -718,7 -699,7 +717,11 @@@ static struct ib_pd *nes_alloc_pd(struc
  /**
   * nes_dealloc_pd
   */
++<<<<<<< HEAD
 +static int nes_dealloc_pd(struct ib_pd *ibpd)
++=======
+ static void nes_dealloc_pd(struct ib_pd *ibpd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	struct nes_ucontext *nesucontext;
  	struct nes_pd *nespd = to_nespd(ibpd);
diff --cc drivers/infiniband/hw/ocrdma/ocrdma_verbs.c
index 27249892f0d1,b8f891660516..000000000000
--- a/drivers/infiniband/hw/ocrdma/ocrdma_verbs.c
+++ b/drivers/infiniband/hw/ocrdma/ocrdma_verbs.c
@@@ -689,20 -669,18 +689,24 @@@ pd_mapping
  		if (status)
  			goto err;
  	}
 -	return 0;
 +	return &pd->ibpd;
  
  err:
 -	if (is_uctx_pd)
 +	if (is_uctx_pd) {
  		ocrdma_release_ucontext_pd(uctx);
 -	else
 -		_ocrdma_dealloc_pd(dev, pd);
 +	} else {
 +		if (_ocrdma_dealloc_pd(dev, pd))
 +			pr_err("%s: _ocrdma_dealloc_pd() failed\n", __func__);
 +	}
  exit:
 -	return status;
 +	return ERR_PTR(status);
  }
  
++<<<<<<< HEAD
 +int ocrdma_dealloc_pd(struct ib_pd *ibpd)
++=======
+ void ocrdma_dealloc_pd(struct ib_pd *ibpd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	struct ocrdma_pd *pd = get_ocrdma_pd(ibpd);
  	struct ocrdma_dev *dev = get_ocrdma_dev(ibpd->device);
diff --cc drivers/infiniband/hw/ocrdma/ocrdma_verbs.h
index b69cfdce7970,3636cbcbcaa4..000000000000
--- a/drivers/infiniband/hw/ocrdma/ocrdma_verbs.h
+++ b/drivers/infiniband/hw/ocrdma/ocrdma_verbs.h
@@@ -70,9 -69,9 +70,15 @@@ int ocrdma_dealloc_ucontext(struct ib_u
  
  int ocrdma_mmap(struct ib_ucontext *, struct vm_area_struct *vma);
  
++<<<<<<< HEAD
 +struct ib_pd *ocrdma_alloc_pd(struct ib_device *,
 +			      struct ib_ucontext *, struct ib_udata *);
 +int ocrdma_dealloc_pd(struct ib_pd *pd);
++=======
+ int ocrdma_alloc_pd(struct ib_pd *pd, struct ib_ucontext *uctx,
+ 		    struct ib_udata *udata);
+ void ocrdma_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  
  struct ib_cq *ocrdma_create_cq(struct ib_device *ibdev,
  			       const struct ib_cq_init_attr *attr,
diff --cc drivers/infiniband/hw/qedr/verbs.c
index 9cb7820beb81,42755e7a10a8..000000000000
--- a/drivers/infiniband/hw/qedr/verbs.c
+++ b/drivers/infiniband/hw/qedr/verbs.c
@@@ -485,14 -475,10 +485,18 @@@ struct ib_pd *qedr_alloc_pd(struct ib_d
  		pd->uctx->pd = pd;
  	}
  
 -	return 0;
 +	return &pd->ibpd;
 +
 +err:
 +	kfree(pd);
 +	return ERR_PTR(rc);
  }
  
++<<<<<<< HEAD
 +int qedr_dealloc_pd(struct ib_pd *ibpd)
++=======
+ void qedr_dealloc_pd(struct ib_pd *ibpd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	struct qedr_dev *dev = get_qedr_dev(ibpd->device);
  	struct qedr_pd *pd = get_qedr_pd(ibpd);
diff --cc drivers/infiniband/hw/qedr/verbs.h
index 0e5fb4e82418,cd9659ac2aad..000000000000
--- a/drivers/infiniband/hw/qedr/verbs.h
+++ b/drivers/infiniband/hw/qedr/verbs.h
@@@ -43,13 -43,13 +43,19 @@@ int qedr_iw_query_gid(struct ib_device 
  
  int qedr_query_pkey(struct ib_device *, u8 port, u16 index, u16 *pkey);
  
 -int qedr_alloc_ucontext(struct ib_ucontext *uctx, struct ib_udata *udata);
 -void qedr_dealloc_ucontext(struct ib_ucontext *uctx);
 +struct ib_ucontext *qedr_alloc_ucontext(struct ib_device *, struct ib_udata *);
 +int qedr_dealloc_ucontext(struct ib_ucontext *);
  
  int qedr_mmap(struct ib_ucontext *, struct vm_area_struct *vma);
++<<<<<<< HEAD
 +struct ib_pd *qedr_alloc_pd(struct ib_device *,
 +			    struct ib_ucontext *, struct ib_udata *);
 +int qedr_dealloc_pd(struct ib_pd *pd);
++=======
+ int qedr_alloc_pd(struct ib_pd *pd, struct ib_ucontext *uctx,
+ 		  struct ib_udata *udata);
+ void qedr_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  
  struct ib_cq *qedr_create_cq(struct ib_device *ibdev,
  			     const struct ib_cq_init_attr *attr,
@@@ -64,7 -64,8 +70,12 @@@ int qedr_modify_qp(struct ib_qp *, stru
  		   int attr_mask, struct ib_udata *udata);
  int qedr_query_qp(struct ib_qp *, struct ib_qp_attr *qp_attr,
  		  int qp_attr_mask, struct ib_qp_init_attr *);
++<<<<<<< HEAD
 +int qedr_destroy_qp(struct ib_qp *ibqp);
++=======
+ int qedr_destroy_qp(struct ib_qp *ibqp, struct ib_udata *udata);
+ 
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  struct ib_srq *qedr_create_srq(struct ib_pd *ibpd,
  			       struct ib_srq_init_attr *attr,
  			       struct ib_udata *udata);
diff --cc drivers/infiniband/hw/usnic/usnic_ib_verbs.c
index 432e6f6599fa,cdb6357337c0..000000000000
--- a/drivers/infiniband/hw/usnic/usnic_ib_verbs.c
+++ b/drivers/infiniband/hw/usnic/usnic_ib_verbs.c
@@@ -456,37 -447,23 +456,41 @@@ int usnic_ib_query_pkey(struct ib_devic
  	return 0;
  }
  
 -int usnic_ib_alloc_pd(struct ib_pd *ibpd, struct ib_ucontext *context,
 -		      struct ib_udata *udata)
 +struct ib_pd *usnic_ib_alloc_pd(struct ib_device *ibdev,
 +					struct ib_ucontext *context,
 +					struct ib_udata *udata)
  {
 -	struct usnic_ib_pd *pd = to_upd(ibpd);
 +	struct usnic_ib_pd *pd;
  	void *umem_pd;
  
 +	usnic_dbg("\n");
 +
 +	pd = kzalloc(sizeof(*pd), GFP_KERNEL);
 +	if (!pd)
 +		return ERR_PTR(-ENOMEM);
 +
  	umem_pd = pd->umem_pd = usnic_uiom_alloc_pd();
  	if (IS_ERR_OR_NULL(umem_pd)) {
 -		return umem_pd ? PTR_ERR(umem_pd) : -ENOMEM;
 +		kfree(pd);
 +		return ERR_PTR(umem_pd ? PTR_ERR(umem_pd) : -ENOMEM);
  	}
  
 -	return 0;
 +	usnic_info("domain 0x%p allocated for context 0x%p and device %s\n",
 +		   pd, context, dev_name(&ibdev->dev));
 +	return &pd->ibpd;
  }
  
++<<<<<<< HEAD
 +int usnic_ib_dealloc_pd(struct ib_pd *pd)
++=======
+ void usnic_ib_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
 +	usnic_info("freeing domain 0x%p\n", pd);
 +
  	usnic_uiom_dealloc_pd((to_upd(pd))->umem_pd);
 +	kfree(pd);
 +	return 0;
  }
  
  struct ib_qp *usnic_ib_create_qp(struct ib_pd *pd,
@@@ -760,57 -731,3 +764,60 @@@ int usnic_ib_mmap(struct ib_ucontext *c
  	return -EINVAL;
  }
  
++<<<<<<< HEAD
 +/* In ib callbacks section -  Start of stub funcs */
 +struct ib_ah *usnic_ib_create_ah(struct ib_pd *pd,
 +				 struct rdma_ah_attr *ah_attr,
 +				 u32 flags,
 +				 struct ib_udata *udata)
 +
 +{
 +	usnic_dbg("\n");
 +	return ERR_PTR(-EPERM);
 +}
 +
 +int usnic_ib_destroy_ah(struct ib_ah *ah, u32 flags)
 +{
 +	usnic_dbg("\n");
 +	return -EINVAL;
 +}
 +
 +int usnic_ib_post_send(struct ib_qp *ibqp, const struct ib_send_wr *wr,
 +		       const struct ib_send_wr **bad_wr)
 +{
 +	usnic_dbg("\n");
 +	return -EINVAL;
 +}
 +
 +int usnic_ib_post_recv(struct ib_qp *ibqp, const struct ib_recv_wr *wr,
 +		       const struct ib_recv_wr **bad_wr)
 +{
 +	usnic_dbg("\n");
 +	return -EINVAL;
 +}
 +
 +int usnic_ib_poll_cq(struct ib_cq *ibcq, int num_entries,
 +				struct ib_wc *wc)
 +{
 +	usnic_dbg("\n");
 +	return -EINVAL;
 +}
 +
 +int usnic_ib_req_notify_cq(struct ib_cq *cq,
 +					enum ib_cq_notify_flags flags)
 +{
 +	usnic_dbg("\n");
 +	return -EINVAL;
 +}
 +
 +struct ib_mr *usnic_ib_get_dma_mr(struct ib_pd *pd, int acc)
 +{
 +	usnic_dbg("\n");
 +	return ERR_PTR(-ENOMEM);
 +}
 +
 +
 +/* In ib callbacks section - End of stub funcs */
 +/* End of ib callbacks section */
++=======
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
diff --cc drivers/infiniband/hw/usnic/usnic_ib_verbs.h
index e33144261b9a,349c8dc13a12..000000000000
--- a/drivers/infiniband/hw/usnic/usnic_ib_verbs.h
+++ b/drivers/infiniband/hw/usnic/usnic_ib_verbs.h
@@@ -48,13 -48,11 +48,19 @@@ int usnic_ib_query_qp(struct ib_qp *qp
  				struct ib_qp_init_attr *qp_init_attr);
  int usnic_ib_query_gid(struct ib_device *ibdev, u8 port, int index,
  				union ib_gid *gid);
 +struct net_device *usnic_get_netdev(struct ib_device *device, u8 port_num);
  int usnic_ib_query_pkey(struct ib_device *ibdev, u8 port, u16 index,
  				u16 *pkey);
++<<<<<<< HEAD
 +struct ib_pd *usnic_ib_alloc_pd(struct ib_device *ibdev,
 +				struct ib_ucontext *context,
 +				struct ib_udata *udata);
 +int usnic_ib_dealloc_pd(struct ib_pd *pd);
++=======
+ int usnic_ib_alloc_pd(struct ib_pd *ibpd, struct ib_ucontext *context,
+ 		      struct ib_udata *udata);
+ void usnic_ib_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  struct ib_qp *usnic_ib_create_qp(struct ib_pd *pd,
  					struct ib_qp_init_attr *init_attr,
  					struct ib_udata *udata);
@@@ -69,25 -67,9 +75,31 @@@ int usnic_ib_destroy_cq(struct ib_cq *c
  struct ib_mr *usnic_ib_reg_mr(struct ib_pd *pd, u64 start, u64 length,
  				u64 virt_addr, int access_flags,
  				struct ib_udata *udata);
++<<<<<<< HEAD
 +int usnic_ib_dereg_mr(struct ib_mr *ibmr);
 +struct ib_ucontext *usnic_ib_alloc_ucontext(struct ib_device *ibdev,
 +						struct ib_udata *udata);
 +int usnic_ib_dealloc_ucontext(struct ib_ucontext *ibcontext);
++=======
+ int usnic_ib_dereg_mr(struct ib_mr *ibmr, struct ib_udata *udata);
+ int usnic_ib_alloc_ucontext(struct ib_ucontext *uctx, struct ib_udata *udata);
+ void usnic_ib_dealloc_ucontext(struct ib_ucontext *ibcontext);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  int usnic_ib_mmap(struct ib_ucontext *context,
  			struct vm_area_struct *vma);
 +struct ib_ah *usnic_ib_create_ah(struct ib_pd *pd,
 +				 struct rdma_ah_attr *ah_attr,
 +				 u32 flags,
 +				 struct ib_udata *udata);
 +
 +int usnic_ib_destroy_ah(struct ib_ah *ah, u32 flags);
 +int usnic_ib_post_send(struct ib_qp *ibqp, const struct ib_send_wr *wr,
 +			const struct ib_send_wr **bad_wr);
 +int usnic_ib_post_recv(struct ib_qp *ibqp, const struct ib_recv_wr *wr,
 +		       const struct ib_recv_wr **bad_wr);
 +int usnic_ib_poll_cq(struct ib_cq *ibcq, int num_entries,
 +			struct ib_wc *wc);
 +int usnic_ib_req_notify_cq(struct ib_cq *cq,
 +				enum ib_cq_notify_flags flags);
 +struct ib_mr *usnic_ib_get_dma_mr(struct ib_pd *pd, int acc);
  #endif /* !USNIC_IB_VERBS_H */
diff --cc drivers/infiniband/hw/vmw_pvrdma/pvrdma_verbs.c
index e426f95731eb,19ff6004b477..000000000000
--- a/drivers/infiniband/hw/vmw_pvrdma/pvrdma_verbs.c
+++ b/drivers/infiniband/hw/vmw_pvrdma/pvrdma_verbs.c
@@@ -487,8 -460,8 +487,13 @@@ struct ib_pd *pvrdma_alloc_pd(struct ib
  		if (ib_copy_to_udata(udata, &pd_resp, sizeof(pd_resp))) {
  			dev_warn(&dev->pdev->dev,
  				 "failed to copy back protection domain\n");
++<<<<<<< HEAD
 +			pvrdma_dealloc_pd(&pd->ibpd);
 +			return ERR_PTR(-EFAULT);
++=======
+ 			pvrdma_dealloc_pd(&pd->ibpd, udata);
+ 			return -EFAULT;
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  		}
  	}
  
@@@ -508,10 -480,10 +514,14 @@@ err
   *
   * @return: 0 on success, otherwise errno.
   */
++<<<<<<< HEAD
 +int pvrdma_dealloc_pd(struct ib_pd *pd)
++=======
+ void pvrdma_dealloc_pd(struct ib_pd *pd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	struct pvrdma_dev *dev = to_vdev(pd->device);
 -	union pvrdma_cmd_req req = {};
 +	union pvrdma_cmd_req req;
  	struct pvrdma_cmd_destroy_pd *cmd = &req.destroy_pd;
  	int ret;
  
diff --cc drivers/infiniband/hw/vmw_pvrdma/pvrdma_verbs.h
index f7f758d60110,2c8ba5bf8d0f..000000000000
--- a/drivers/infiniband/hw/vmw_pvrdma/pvrdma_verbs.h
+++ b/drivers/infiniband/hw/vmw_pvrdma/pvrdma_verbs.h
@@@ -396,13 -396,11 +396,21 @@@ int pvrdma_modify_device(struct ib_devi
  int pvrdma_modify_port(struct ib_device *ibdev, u8 port,
  		       int mask, struct ib_port_modify *props);
  int pvrdma_mmap(struct ib_ucontext *context, struct vm_area_struct *vma);
++<<<<<<< HEAD
 +struct ib_ucontext *pvrdma_alloc_ucontext(struct ib_device *ibdev,
 +					  struct ib_udata *udata);
 +int pvrdma_dealloc_ucontext(struct ib_ucontext *context);
 +struct ib_pd *pvrdma_alloc_pd(struct ib_device *ibdev,
 +			      struct ib_ucontext *context,
 +			      struct ib_udata *udata);
 +int pvrdma_dealloc_pd(struct ib_pd *ibpd);
++=======
+ int pvrdma_alloc_ucontext(struct ib_ucontext *uctx, struct ib_udata *udata);
+ void pvrdma_dealloc_ucontext(struct ib_ucontext *context);
+ int pvrdma_alloc_pd(struct ib_pd *pd, struct ib_ucontext *context,
+ 		    struct ib_udata *udata);
+ void pvrdma_dealloc_pd(struct ib_pd *ibpd, struct ib_udata *udata);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  struct ib_mr *pvrdma_get_dma_mr(struct ib_pd *pd, int acc);
  struct ib_mr *pvrdma_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,
  				 u64 virt_addr, int access_flags,
diff --cc drivers/infiniband/sw/rdmavt/pd.c
index dcc1870b8d23,e84341282374..000000000000
--- a/drivers/infiniband/sw/rdmavt/pd.c
+++ b/drivers/infiniband/sw/rdmavt/pd.c
@@@ -104,9 -97,8 +105,13 @@@ bail
   *
   * Return: always 0
   */
++<<<<<<< HEAD
 +int rvt_dealloc_pd(struct ib_pd *ibpd)
++=======
+ void rvt_dealloc_pd(struct ib_pd *ibpd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
 +	struct rvt_pd *pd = ibpd_to_rvtpd(ibpd);
  	struct rvt_dev_info *dev = ib_to_rvt(ibpd->device);
  
  	spin_lock(&dev->n_pds_lock);
diff --cc drivers/infiniband/sw/rdmavt/pd.h
index 1892ca4a9746,d0368a625e03..000000000000
--- a/drivers/infiniband/sw/rdmavt/pd.h
+++ b/drivers/infiniband/sw/rdmavt/pd.h
@@@ -50,9 -50,8 +50,15 @@@
  
  #include <rdma/rdma_vt.h>
  
++<<<<<<< HEAD
 +struct ib_pd *rvt_alloc_pd(struct ib_device *ibdev,
 +			   struct ib_ucontext *context,
 +			   struct ib_udata *udata);
 +int rvt_dealloc_pd(struct ib_pd *ibpd);
++=======
+ int rvt_alloc_pd(struct ib_pd *pd, struct ib_ucontext *context,
+ 		 struct ib_udata *udata);
+ void rvt_dealloc_pd(struct ib_pd *ibpd, struct ib_udata *udata);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  
  #endif          /* DEF_RDMAVTPD_H */
diff --cc drivers/infiniband/sw/rxe/rxe_verbs.c
index f3188f269481,e625731ae42d..000000000000
--- a/drivers/infiniband/sw/rxe/rxe_verbs.c
+++ b/drivers/infiniband/sw/rxe/rxe_verbs.c
@@@ -178,18 -176,16 +178,22 @@@ static int rxe_port_immutable(struct ib
  	return 0;
  }
  
 -static int rxe_alloc_pd(struct ib_pd *ibpd, struct ib_ucontext *context,
 -			struct ib_udata *udata)
 +static struct ib_pd *rxe_alloc_pd(struct ib_device *dev,
 +				  struct ib_ucontext *context,
 +				  struct ib_udata *udata)
  {
 -	struct rxe_dev *rxe = to_rdev(ibpd->device);
 -	struct rxe_pd *pd = to_rpd(ibpd);
 +	struct rxe_dev *rxe = to_rdev(dev);
 +	struct rxe_pd *pd;
  
 -	return rxe_add_to_pool(&rxe->pd_pool, &pd->pelem);
 +	pd = rxe_alloc(&rxe->pd_pool);
 +	return pd ? &pd->ibpd : ERR_PTR(-ENOMEM);
  }
  
++<<<<<<< HEAD
 +static int rxe_dealloc_pd(struct ib_pd *ibpd)
++=======
+ static void rxe_dealloc_pd(struct ib_pd *ibpd, struct ib_udata *udata)
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  {
  	struct rxe_pd *pd = to_rpd(ibpd);
  
diff --cc include/rdma/ib_verbs.h
index 2ff74f11eec0,54e48dd36644..000000000000
--- a/include/rdma/ib_verbs.h
+++ b/include/rdma/ib_verbs.h
@@@ -2380,15 -2389,14 +2380,21 @@@ struct ib_device_ops 
  	int (*del_gid)(const struct ib_gid_attr *attr, void **context);
  	int (*query_pkey)(struct ib_device *device, u8 port_num, u16 index,
  			  u16 *pkey);
 -	int (*alloc_ucontext)(struct ib_ucontext *context,
 -			      struct ib_udata *udata);
 -	void (*dealloc_ucontext)(struct ib_ucontext *context);
 +	struct ib_ucontext *(*alloc_ucontext)(struct ib_device *device,
 +					      struct ib_udata *udata);
 +	int (*dealloc_ucontext)(struct ib_ucontext *context);
  	int (*mmap)(struct ib_ucontext *context, struct vm_area_struct *vma);
  	void (*disassociate_ucontext)(struct ib_ucontext *ibcontext);
++<<<<<<< HEAD
 +	struct ib_pd *(*alloc_pd)(struct ib_device *device,
 +				  struct ib_ucontext *context,
 +				  struct ib_udata *udata);
 +	int (*dealloc_pd)(struct ib_pd *pd);
++=======
+ 	int (*alloc_pd)(struct ib_pd *pd, struct ib_ucontext *context,
+ 			struct ib_udata *udata);
+ 	void (*dealloc_pd)(struct ib_pd *pd, struct ib_udata *udata);
++>>>>>>> c4367a26357b (IB: Pass uverbs_attr_bundle down ib_x destroy path)
  	struct ib_ah *(*create_ah)(struct ib_pd *pd,
  				   struct rdma_ah_attr *ah_attr, u32 flags,
  				   struct ib_udata *udata);
@@@ -3945,9 -4199,17 +4111,9 @@@ void ib_device_put(struct ib_device *de
  struct net_device *ib_get_net_dev_by_params(struct ib_device *dev, u8 port,
  					    u16 pkey, const union ib_gid *gid,
  					    const struct sockaddr *addr);
 -int ib_device_set_netdev(struct ib_device *ib_dev, struct net_device *ndev,
 -			 unsigned int port);
 -struct net_device *ib_device_netdev(struct ib_device *dev, u8 port);
 -
  struct ib_wq *ib_create_wq(struct ib_pd *pd,
  			   struct ib_wq_init_attr *init_attr);
- int ib_destroy_wq(struct ib_wq *wq);
+ int ib_destroy_wq(struct ib_wq *wq, struct ib_udata *udata);
  int ib_modify_wq(struct ib_wq *wq, struct ib_wq_attr *attr,
  		 u32 wq_attr_mask);
  struct ib_rwq_ind_table *ib_create_rwq_ind_table(struct ib_device *device,
* Unmerged path drivers/infiniband/hw/hns/hns_roce_srq.c
diff --git a/drivers/infiniband/core/cq.c b/drivers/infiniband/core/cq.c
index d61e5e1427c2..4797eef549c3 100644
--- a/drivers/infiniband/core/cq.c
+++ b/drivers/infiniband/core/cq.c
@@ -128,15 +128,17 @@ static void ib_cq_completion_workqueue(struct ib_cq *cq, void *private)
  * @comp_vector:	HCA completion vectors for this CQ
  * @poll_ctx:		context to poll the CQ from.
  * @caller:		module owner name.
+ * @udata:		Valid user data or NULL for kernel object
  *
  * This is the proper interface to allocate a CQ for in-kernel users. A
  * CQ allocated with this interface will automatically be polled from the
  * specified context. The ULP must use wr->wr_cqe instead of wr->wr_id
  * to use this CQ abstraction.
  */
-struct ib_cq *__ib_alloc_cq(struct ib_device *dev, void *private,
-			    int nr_cqe, int comp_vector,
-			    enum ib_poll_context poll_ctx, const char *caller)
+struct ib_cq *__ib_alloc_cq_user(struct ib_device *dev, void *private,
+				 int nr_cqe, int comp_vector,
+				 enum ib_poll_context poll_ctx,
+				 const char *caller, struct ib_udata *udata)
 {
 	struct ib_cq_init_attr cq_attr = {
 		.cqe		= nr_cqe,
@@ -193,16 +195,17 @@ struct ib_cq *__ib_alloc_cq(struct ib_device *dev, void *private,
 	kfree(cq->wc);
 	rdma_restrack_del(&cq->res);
 out_destroy_cq:
-	cq->device->ops.destroy_cq(cq);
+	cq->device->ops.destroy_cq(cq, udata);
 	return ERR_PTR(ret);
 }
-EXPORT_SYMBOL(__ib_alloc_cq);
+EXPORT_SYMBOL(__ib_alloc_cq_user);
 
 /**
  * ib_free_cq - free a completion queue
  * @cq:		completion queue to free.
+ * @udata:	User data or NULL for kernel object
  */
-void ib_free_cq(struct ib_cq *cq)
+void ib_free_cq_user(struct ib_cq *cq, struct ib_udata *udata)
 {
 	int ret;
 
@@ -225,7 +228,7 @@ void ib_free_cq(struct ib_cq *cq)
 
 	kfree(cq->wc);
 	rdma_restrack_del(&cq->res);
-	ret = cq->device->ops.destroy_cq(cq);
+	ret = cq->device->ops.destroy_cq(cq, udata);
 	WARN_ON_ONCE(ret);
 }
-EXPORT_SYMBOL(ib_free_cq);
+EXPORT_SYMBOL(ib_free_cq_user);
diff --git a/drivers/infiniband/core/uverbs.h b/drivers/infiniband/core/uverbs.h
index 32cc8fe7902f..28da29d53043 100644
--- a/drivers/infiniband/core/uverbs.h
+++ b/drivers/infiniband/core/uverbs.h
@@ -241,7 +241,7 @@ void ib_uverbs_srq_event_handler(struct ib_event *event, void *context_ptr);
 void ib_uverbs_event_handler(struct ib_event_handler *handler,
 			     struct ib_event *event);
 int ib_uverbs_dealloc_xrcd(struct ib_uobject *uobject, struct ib_xrcd *xrcd,
-			   enum rdma_remove_reason why);
+			   enum rdma_remove_reason why, struct ib_udata *udata);
 
 int uverbs_dealloc_mw(struct ib_mw *mw);
 void ib_uverbs_detach_umcast(struct ib_qp *qp,
* Unmerged path drivers/infiniband/core/uverbs_cmd.c
* Unmerged path drivers/infiniband/core/uverbs_std_types.c
diff --git a/drivers/infiniband/core/uverbs_std_types_cq.c b/drivers/infiniband/core/uverbs_std_types_cq.c
index a59ea89e3f2b..ca1777ed82b6 100644
--- a/drivers/infiniband/core/uverbs_std_types_cq.c
+++ b/drivers/infiniband/core/uverbs_std_types_cq.c
@@ -43,7 +43,7 @@ static int uverbs_free_cq(struct ib_uobject *uobject,
 		container_of(uobject, struct ib_ucq_object, uobject);
 	int ret;
 
-	ret = ib_destroy_cq(cq);
+	ret = ib_destroy_cq_user(cq, &attrs->driver_udata);
 	if (ib_is_destroy_retryable(ret, why, uobject))
 		return ret;
 
diff --git a/drivers/infiniband/core/uverbs_std_types_dm.c b/drivers/infiniband/core/uverbs_std_types_dm.c
index de3f04a4398c..06d4dca50504 100644
--- a/drivers/infiniband/core/uverbs_std_types_dm.c
+++ b/drivers/infiniband/core/uverbs_std_types_dm.c
@@ -44,7 +44,7 @@ static int uverbs_free_dm(struct ib_uobject *uobject,
 	if (ret)
 		return ret;
 
-	return dm->device->ops.dealloc_dm(dm);
+	return dm->device->ops.dealloc_dm(dm, attrs);
 }
 
 static int UVERBS_HANDLER(UVERBS_METHOD_DM_ALLOC)(
diff --git a/drivers/infiniband/core/uverbs_std_types_mr.c b/drivers/infiniband/core/uverbs_std_types_mr.c
index 3b4bf6370333..c8247db0a1b3 100644
--- a/drivers/infiniband/core/uverbs_std_types_mr.c
+++ b/drivers/infiniband/core/uverbs_std_types_mr.c
@@ -37,7 +37,8 @@
 static int uverbs_free_mr(struct ib_uobject *uobject,
 			  enum rdma_remove_reason why)
 {
-	return ib_dereg_mr((struct ib_mr *)uobject->object);
+	return ib_dereg_mr_user((struct ib_mr *)uobject->object,
+				&attrs->driver_udata);
 }
 
 static int UVERBS_HANDLER(UVERBS_METHOD_ADVISE_MR)(
@@ -146,7 +147,7 @@ static int UVERBS_HANDLER(UVERBS_METHOD_DM_MR_REG)(
 	return 0;
 
 err_dereg:
-	ib_dereg_mr(mr);
+	ib_dereg_mr_user(mr, &attrs->driver_udata);
 
 	return ret;
 }
* Unmerged path drivers/infiniband/core/verbs.c
* Unmerged path drivers/infiniband/hw/bnxt_re/ib_verbs.c
* Unmerged path drivers/infiniband/hw/bnxt_re/ib_verbs.h
* Unmerged path drivers/infiniband/hw/cxgb3/iwch_provider.c
diff --git a/drivers/infiniband/hw/cxgb4/cq.c b/drivers/infiniband/hw/cxgb4/cq.c
index 1fd8798d91a7..4eee60631bd3 100644
--- a/drivers/infiniband/hw/cxgb4/cq.c
+++ b/drivers/infiniband/hw/cxgb4/cq.c
@@ -968,7 +968,7 @@ int c4iw_poll_cq(struct ib_cq *ibcq, int num_entries, struct ib_wc *wc)
 	return !err || err == -ENODATA ? npolled : err;
 }
 
-int c4iw_destroy_cq(struct ib_cq *ib_cq)
+int c4iw_destroy_cq(struct ib_cq *ib_cq, struct ib_udata *udata)
 {
 	struct c4iw_cq *chp;
 	struct c4iw_ucontext *ucontext;
diff --git a/drivers/infiniband/hw/cxgb4/iw_cxgb4.h b/drivers/infiniband/hw/cxgb4/iw_cxgb4.h
index 5a5da41faef6..822da6ea3724 100644
--- a/drivers/infiniband/hw/cxgb4/iw_cxgb4.h
+++ b/drivers/infiniband/hw/cxgb4/iw_cxgb4.h
@@ -1038,9 +1038,8 @@ int c4iw_accept_cr(struct iw_cm_id *cm_id, struct iw_cm_conn_param *conn_param);
 int c4iw_reject_cr(struct iw_cm_id *cm_id, const void *pdata, u8 pdata_len);
 void c4iw_qp_add_ref(struct ib_qp *qp);
 void c4iw_qp_rem_ref(struct ib_qp *qp);
-struct ib_mr *c4iw_alloc_mr(struct ib_pd *pd,
-			    enum ib_mr_type mr_type,
-			    u32 max_num_sg);
+struct ib_mr *c4iw_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
+			    u32 max_num_sg, struct ib_udata *udata);
 int c4iw_map_mr_sg(struct ib_mr *ibmr, struct scatterlist *sg, int sg_nents,
 		   unsigned int *sg_offset);
 int c4iw_dealloc_mw(struct ib_mw *mw);
@@ -1051,8 +1050,8 @@ struct ib_mr *c4iw_reg_user_mr(struct ib_pd *pd, u64 start,
 					   u64 length, u64 virt, int acc,
 					   struct ib_udata *udata);
 struct ib_mr *c4iw_get_dma_mr(struct ib_pd *pd, int acc);
-int c4iw_dereg_mr(struct ib_mr *ib_mr);
-int c4iw_destroy_cq(struct ib_cq *ib_cq);
+int c4iw_dereg_mr(struct ib_mr *ib_mr, struct ib_udata *udata);
+int c4iw_destroy_cq(struct ib_cq *ib_cq, struct ib_udata *udata);
 struct ib_cq *c4iw_create_cq(struct ib_device *ibdev,
 			     const struct ib_cq_init_attr *attr,
 			     struct ib_ucontext *ib_context,
@@ -1061,11 +1060,11 @@ int c4iw_arm_cq(struct ib_cq *ibcq, enum ib_cq_notify_flags flags);
 int c4iw_modify_srq(struct ib_srq *ib_srq, struct ib_srq_attr *attr,
 		    enum ib_srq_attr_mask srq_attr_mask,
 		    struct ib_udata *udata);
-int c4iw_destroy_srq(struct ib_srq *ib_srq);
+int c4iw_destroy_srq(struct ib_srq *ib_srq, struct ib_udata *udata);
 struct ib_srq *c4iw_create_srq(struct ib_pd *pd,
 			       struct ib_srq_init_attr *attrs,
 			       struct ib_udata *udata);
-int c4iw_destroy_qp(struct ib_qp *ib_qp);
+int c4iw_destroy_qp(struct ib_qp *ib_qp, struct ib_udata *udata);
 struct ib_qp *c4iw_create_qp(struct ib_pd *pd,
 			     struct ib_qp_init_attr *attrs,
 			     struct ib_udata *udata);
diff --git a/drivers/infiniband/hw/cxgb4/mem.c b/drivers/infiniband/hw/cxgb4/mem.c
index 864d0facf3cc..fb3c23850ad2 100644
--- a/drivers/infiniband/hw/cxgb4/mem.c
+++ b/drivers/infiniband/hw/cxgb4/mem.c
@@ -689,9 +689,8 @@ int c4iw_dealloc_mw(struct ib_mw *mw)
 	return 0;
 }
 
-struct ib_mr *c4iw_alloc_mr(struct ib_pd *pd,
-			    enum ib_mr_type mr_type,
-			    u32 max_num_sg)
+struct ib_mr *c4iw_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
+			    u32 max_num_sg, struct ib_udata *udata)
 {
 	struct c4iw_dev *rhp;
 	struct c4iw_pd *php;
@@ -792,7 +791,7 @@ int c4iw_map_mr_sg(struct ib_mr *ibmr, struct scatterlist *sg, int sg_nents,
 	return ib_sg_to_pages(ibmr, sg, sg_nents, sg_offset, c4iw_set_page);
 }
 
-int c4iw_dereg_mr(struct ib_mr *ib_mr)
+int c4iw_dereg_mr(struct ib_mr *ib_mr, struct ib_udata *udata)
 {
 	struct c4iw_dev *rhp;
 	struct c4iw_mr *mhp;
* Unmerged path drivers/infiniband/hw/cxgb4/provider.c
diff --git a/drivers/infiniband/hw/cxgb4/qp.c b/drivers/infiniband/hw/cxgb4/qp.c
index 754b76c6d55e..f7df1d01c07c 100644
--- a/drivers/infiniband/hw/cxgb4/qp.c
+++ b/drivers/infiniband/hw/cxgb4/qp.c
@@ -2095,7 +2095,7 @@ int c4iw_modify_qp(struct c4iw_dev *rhp, struct c4iw_qp *qhp,
 	return ret;
 }
 
-int c4iw_destroy_qp(struct ib_qp *ib_qp)
+int c4iw_destroy_qp(struct ib_qp *ib_qp, struct ib_udata *udata)
 {
 	struct c4iw_dev *rhp;
 	struct c4iw_qp *qhp;
@@ -2828,7 +2828,7 @@ struct ib_srq *c4iw_create_srq(struct ib_pd *pd, struct ib_srq_init_attr *attrs,
 	return ERR_PTR(ret);
 }
 
-int c4iw_destroy_srq(struct ib_srq *ibsrq)
+int c4iw_destroy_srq(struct ib_srq *ibsrq, struct ib_udata *udata)
 {
 	struct c4iw_dev *rhp;
 	struct c4iw_srq *srq;
diff --git a/drivers/infiniband/hw/hns/hns_roce_ah.c b/drivers/infiniband/hw/hns/hns_roce_ah.c
index ce7b791ee909..3a2927428e4f 100644
--- a/drivers/infiniband/hw/hns/hns_roce_ah.c
+++ b/drivers/infiniband/hw/hns/hns_roce_ah.c
@@ -107,7 +107,7 @@ int hns_roce_query_ah(struct ib_ah *ibah, struct rdma_ah_attr *ah_attr)
 	return 0;
 }
 
-int hns_roce_destroy_ah(struct ib_ah *ah, u32 flags)
+int hns_roce_destroy_ah(struct ib_ah *ah, u32 flags, struct ib_udata *udata)
 {
 	kfree(to_hr_ah(ah));
 
diff --git a/drivers/infiniband/hw/hns/hns_roce_cq.c b/drivers/infiniband/hw/hns/hns_roce_cq.c
index 3a485f50fede..7a93918c5d5e 100644
--- a/drivers/infiniband/hw/hns/hns_roce_cq.c
+++ b/drivers/infiniband/hw/hns/hns_roce_cq.c
@@ -451,14 +451,14 @@ struct ib_cq *hns_roce_ib_create_cq(struct ib_device *ib_dev,
 }
 EXPORT_SYMBOL_GPL(hns_roce_ib_create_cq);
 
-int hns_roce_ib_destroy_cq(struct ib_cq *ib_cq)
+int hns_roce_ib_destroy_cq(struct ib_cq *ib_cq, struct ib_udata *udata)
 {
 	struct hns_roce_dev *hr_dev = to_hr_dev(ib_cq->device);
 	struct hns_roce_cq *hr_cq = to_hr_cq(ib_cq);
 	int ret = 0;
 
 	if (hr_dev->hw->destroy_cq) {
-		ret = hr_dev->hw->destroy_cq(ib_cq);
+		ret = hr_dev->hw->destroy_cq(ib_cq, udata);
 	} else {
 		hns_roce_free_cq(hr_dev, hr_cq);
 		hns_roce_mtt_cleanup(hr_dev, &hr_cq->hr_buf.hr_mtt);
* Unmerged path drivers/infiniband/hw/hns/hns_roce_device.h
* Unmerged path drivers/infiniband/hw/hns/hns_roce_hw_v1.c
diff --git a/drivers/infiniband/hw/hns/hns_roce_hw_v1.h b/drivers/infiniband/hw/hns/hns_roce_hw_v1.h
index 66440147d9eb..1a2c38785c7f 100644
--- a/drivers/infiniband/hw/hns/hns_roce_hw_v1.h
+++ b/drivers/infiniband/hw/hns/hns_roce_hw_v1.h
@@ -1106,6 +1106,6 @@ struct hns_roce_v1_priv {
 
 int hns_dsaf_roce_reset(struct fwnode_handle *dsaf_fwnode, bool dereset);
 int hns_roce_v1_poll_cq(struct ib_cq *ibcq, int num_entries, struct ib_wc *wc);
-int hns_roce_v1_destroy_qp(struct ib_qp *ibqp);
+int hns_roce_v1_destroy_qp(struct ib_qp *ibqp, struct ib_udata *udata);
 
 #endif
diff --git a/drivers/infiniband/hw/hns/hns_roce_hw_v2.c b/drivers/infiniband/hw/hns/hns_roce_hw_v2.c
index 8c3593be2aa2..06d0b8322880 100644
--- a/drivers/infiniband/hw/hns/hns_roce_hw_v2.c
+++ b/drivers/infiniband/hw/hns/hns_roce_hw_v2.c
@@ -3944,7 +3944,7 @@ static int hns_roce_v2_destroy_qp_common(struct hns_roce_dev *hr_dev,
 	return 0;
 }
 
-static int hns_roce_v2_destroy_qp(struct ib_qp *ibqp)
+static int hns_roce_v2_destroy_qp(struct ib_qp *ibqp, struct ib_udata *udata)
 {
 	struct hns_roce_dev *hr_dev = to_hr_dev(ibqp->device);
 	struct hns_roce_qp *hr_qp = to_hr_qp(ibqp);
* Unmerged path drivers/infiniband/hw/hns/hns_roce_mr.c
* Unmerged path drivers/infiniband/hw/hns/hns_roce_pd.c
* Unmerged path drivers/infiniband/hw/hns/hns_roce_srq.c
diff --git a/drivers/infiniband/hw/i40iw/i40iw_cm.c b/drivers/infiniband/hw/i40iw/i40iw_cm.c
index 206cfb0016f8..7d0037efff2e 100644
--- a/drivers/infiniband/hw/i40iw/i40iw_cm.c
+++ b/drivers/infiniband/hw/i40iw/i40iw_cm.c
@@ -3478,7 +3478,8 @@ static void i40iw_qp_disconnect(struct i40iw_qp *iwqp)
 		/* Need to free the Last Streaming Mode Message */
 		if (iwqp->ietf_mem.va) {
 			if (iwqp->lsmm_mr)
-				iwibdev->ibdev.ops.dereg_mr(iwqp->lsmm_mr);
+				iwibdev->ibdev.ops.dereg_mr(iwqp->lsmm_mr,
+							    NULL);
 			i40iw_free_dma_mem(iwdev->sc_dev.hw, &iwqp->ietf_mem);
 		}
 	}
* Unmerged path drivers/infiniband/hw/i40iw/i40iw_verbs.c
diff --git a/drivers/infiniband/hw/mlx4/ah.c b/drivers/infiniband/hw/mlx4/ah.c
index 1672808262ba..6f552b780b89 100644
--- a/drivers/infiniband/hw/mlx4/ah.c
+++ b/drivers/infiniband/hw/mlx4/ah.c
@@ -250,7 +250,7 @@ int mlx4_ib_query_ah(struct ib_ah *ibah, struct rdma_ah_attr *ah_attr)
 	return 0;
 }
 
-int mlx4_ib_destroy_ah(struct ib_ah *ah, u32 flags)
+int mlx4_ib_destroy_ah(struct ib_ah *ah, u32 flags, struct ib_udata *udata)
 {
 	kfree(to_mah(ah));
 	return 0;
diff --git a/drivers/infiniband/hw/mlx4/cq.c b/drivers/infiniband/hw/mlx4/cq.c
index 43512347b4f0..adc13f6274f4 100644
--- a/drivers/infiniband/hw/mlx4/cq.c
+++ b/drivers/infiniband/hw/mlx4/cq.c
@@ -486,7 +486,7 @@ int mlx4_ib_resize_cq(struct ib_cq *ibcq, int entries, struct ib_udata *udata)
 	return err;
 }
 
-int mlx4_ib_destroy_cq(struct ib_cq *cq)
+int mlx4_ib_destroy_cq(struct ib_cq *cq, struct ib_udata *udata)
 {
 	struct mlx4_ib_dev *dev = to_mdev(cq->device);
 	struct mlx4_ib_cq *mcq = to_mcq(cq);
diff --git a/drivers/infiniband/hw/mlx4/mad.c b/drivers/infiniband/hw/mlx4/mad.c
index 936ee1314bcd..f090c1b40433 100644
--- a/drivers/infiniband/hw/mlx4/mad.c
+++ b/drivers/infiniband/hw/mlx4/mad.c
@@ -1411,7 +1411,7 @@ int mlx4_ib_send_to_wire(struct mlx4_ib_dev *dev, int slave, u8 port,
 
 	sqp_mad = (struct mlx4_mad_snd_buf *) (sqp->tx_ring[wire_tx_ix].buf.addr);
 	if (sqp->tx_ring[wire_tx_ix].ah)
-		mlx4_ib_destroy_ah(sqp->tx_ring[wire_tx_ix].ah, 0);
+		mlx4_ib_destroy_ah(sqp->tx_ring[wire_tx_ix].ah, 0, NULL);
 	sqp->tx_ring[wire_tx_ix].ah = ah;
 	ib_dma_sync_single_for_cpu(&dev->ib_dev,
 				   sqp->tx_ring[wire_tx_ix].buf.map,
@@ -1450,7 +1450,7 @@ int mlx4_ib_send_to_wire(struct mlx4_ib_dev *dev, int slave, u8 port,
 	spin_unlock(&sqp->tx_lock);
 	sqp->tx_ring[wire_tx_ix].ah = NULL;
 out:
-	mlx4_ib_destroy_ah(ah, 0);
+	mlx4_ib_destroy_ah(ah, 0, NULL);
 	return ret;
 }
 
@@ -1903,7 +1903,8 @@ static void mlx4_ib_sqp_comp_worker(struct work_struct *work)
 			switch (wc.opcode) {
 			case IB_WC_SEND:
 				mlx4_ib_destroy_ah(sqp->tx_ring[wc.wr_id &
-					      (MLX4_NUM_TUNNEL_BUFS - 1)].ah, 0);
+					      (MLX4_NUM_TUNNEL_BUFS - 1)].ah,
+					      0, NULL);
 				sqp->tx_ring[wc.wr_id & (MLX4_NUM_TUNNEL_BUFS - 1)].ah
 					= NULL;
 				spin_lock(&sqp->tx_lock);
@@ -1932,7 +1933,8 @@ static void mlx4_ib_sqp_comp_worker(struct work_struct *work)
 				 ctx->slave, wc.status, wc.wr_id);
 			if (!MLX4_TUN_IS_RECV(wc.wr_id)) {
 				mlx4_ib_destroy_ah(sqp->tx_ring[wc.wr_id &
-					      (MLX4_NUM_TUNNEL_BUFS - 1)].ah, 0);
+					      (MLX4_NUM_TUNNEL_BUFS - 1)].ah,
+					      0, NULL);
 				sqp->tx_ring[wc.wr_id & (MLX4_NUM_TUNNEL_BUFS - 1)].ah
 					= NULL;
 				spin_lock(&sqp->tx_lock);
* Unmerged path drivers/infiniband/hw/mlx4/main.c
diff --git a/drivers/infiniband/hw/mlx4/mlx4_ib.h b/drivers/infiniband/hw/mlx4/mlx4_ib.h
index e491f3eda6e7..091340b3b948 100644
--- a/drivers/infiniband/hw/mlx4/mlx4_ib.h
+++ b/drivers/infiniband/hw/mlx4/mlx4_ib.h
@@ -732,13 +732,12 @@ int mlx4_ib_umem_write_mtt(struct mlx4_ib_dev *dev, struct mlx4_mtt *mtt,
 struct ib_mr *mlx4_ib_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,
 				  u64 virt_addr, int access_flags,
 				  struct ib_udata *udata);
-int mlx4_ib_dereg_mr(struct ib_mr *mr);
+int mlx4_ib_dereg_mr(struct ib_mr *mr, struct ib_udata *udata);
 struct ib_mw *mlx4_ib_alloc_mw(struct ib_pd *pd, enum ib_mw_type type,
 			       struct ib_udata *udata);
 int mlx4_ib_dealloc_mw(struct ib_mw *mw);
-struct ib_mr *mlx4_ib_alloc_mr(struct ib_pd *pd,
-			       enum ib_mr_type mr_type,
-			       u32 max_num_sg);
+struct ib_mr *mlx4_ib_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
+			       u32 max_num_sg, struct ib_udata *udata);
 int mlx4_ib_map_mr_sg(struct ib_mr *ibmr, struct scatterlist *sg, int sg_nents,
 		      unsigned int *sg_offset);
 int mlx4_ib_modify_cq(struct ib_cq *cq, u16 cq_count, u16 cq_period);
@@ -747,7 +746,7 @@ struct ib_cq *mlx4_ib_create_cq(struct ib_device *ibdev,
 				const struct ib_cq_init_attr *attr,
 				struct ib_ucontext *context,
 				struct ib_udata *udata);
-int mlx4_ib_destroy_cq(struct ib_cq *cq);
+int mlx4_ib_destroy_cq(struct ib_cq *cq, struct ib_udata *udata);
 int mlx4_ib_poll_cq(struct ib_cq *ibcq, int num_entries, struct ib_wc *wc);
 int mlx4_ib_arm_cq(struct ib_cq *cq, enum ib_cq_notify_flags flags);
 void __mlx4_ib_cq_clean(struct mlx4_ib_cq *cq, u32 qpn, struct mlx4_ib_srq *srq);
@@ -760,7 +759,7 @@ struct ib_ah *mlx4_ib_create_ah_slave(struct ib_pd *pd,
 				      int slave_sgid_index, u8 *s_mac,
 				      u16 vlan_tag);
 int mlx4_ib_query_ah(struct ib_ah *ibah, struct rdma_ah_attr *ah_attr);
-int mlx4_ib_destroy_ah(struct ib_ah *ah, u32 flags);
+int mlx4_ib_destroy_ah(struct ib_ah *ah, u32 flags, struct ib_udata *udata);
 
 struct ib_srq *mlx4_ib_create_srq(struct ib_pd *pd,
 				  struct ib_srq_init_attr *init_attr,
@@ -768,7 +767,7 @@ struct ib_srq *mlx4_ib_create_srq(struct ib_pd *pd,
 int mlx4_ib_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,
 		       enum ib_srq_attr_mask attr_mask, struct ib_udata *udata);
 int mlx4_ib_query_srq(struct ib_srq *srq, struct ib_srq_attr *srq_attr);
-int mlx4_ib_destroy_srq(struct ib_srq *srq);
+int mlx4_ib_destroy_srq(struct ib_srq *srq, struct ib_udata *udata);
 void mlx4_ib_free_srq_wqe(struct mlx4_ib_srq *srq, int wqe_index);
 int mlx4_ib_post_srq_recv(struct ib_srq *ibsrq, const struct ib_recv_wr *wr,
 			  const struct ib_recv_wr **bad_wr);
@@ -776,7 +775,7 @@ int mlx4_ib_post_srq_recv(struct ib_srq *ibsrq, const struct ib_recv_wr *wr,
 struct ib_qp *mlx4_ib_create_qp(struct ib_pd *pd,
 				struct ib_qp_init_attr *init_attr,
 				struct ib_udata *udata);
-int mlx4_ib_destroy_qp(struct ib_qp *qp);
+int mlx4_ib_destroy_qp(struct ib_qp *qp, struct ib_udata *udata);
 void mlx4_ib_drain_sq(struct ib_qp *qp);
 void mlx4_ib_drain_rq(struct ib_qp *qp);
 int mlx4_ib_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
@@ -911,7 +910,7 @@ void mlx4_ib_sl2vl_update(struct mlx4_ib_dev *mdev, int port);
 struct ib_wq *mlx4_ib_create_wq(struct ib_pd *pd,
 				struct ib_wq_init_attr *init_attr,
 				struct ib_udata *udata);
-int mlx4_ib_destroy_wq(struct ib_wq *wq);
+int mlx4_ib_destroy_wq(struct ib_wq *wq, struct ib_udata *udata);
 int mlx4_ib_modify_wq(struct ib_wq *wq, struct ib_wq_attr *wq_attr,
 		      u32 wq_attr_mask, struct ib_udata *udata);
 
diff --git a/drivers/infiniband/hw/mlx4/mr.c b/drivers/infiniband/hw/mlx4/mr.c
index c7c85c22e4e3..0d6cfc34ccc6 100644
--- a/drivers/infiniband/hw/mlx4/mr.c
+++ b/drivers/infiniband/hw/mlx4/mr.c
@@ -596,7 +596,7 @@ mlx4_free_priv_pages(struct mlx4_ib_mr *mr)
 	}
 }
 
-int mlx4_ib_dereg_mr(struct ib_mr *ibmr)
+int mlx4_ib_dereg_mr(struct ib_mr *ibmr, struct ib_udata *udata)
 {
 	struct mlx4_ib_mr *mr = to_mmr(ibmr);
 	int ret;
@@ -656,9 +656,8 @@ int mlx4_ib_dealloc_mw(struct ib_mw *ibmw)
 	return 0;
 }
 
-struct ib_mr *mlx4_ib_alloc_mr(struct ib_pd *pd,
-			       enum ib_mr_type mr_type,
-			       u32 max_num_sg)
+struct ib_mr *mlx4_ib_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
+			       u32 max_num_sg, struct ib_udata *udata)
 {
 	struct mlx4_ib_dev *dev = to_mdev(pd->device);
 	struct mlx4_ib_mr *mr;
diff --git a/drivers/infiniband/hw/mlx4/qp.c b/drivers/infiniband/hw/mlx4/qp.c
index 971e9a9ebdaf..ec7cd7c95611 100644
--- a/drivers/infiniband/hw/mlx4/qp.c
+++ b/drivers/infiniband/hw/mlx4/qp.c
@@ -1620,7 +1620,7 @@ static int _mlx4_ib_destroy_qp(struct ib_qp *qp)
 	return 0;
 }
 
-int mlx4_ib_destroy_qp(struct ib_qp *qp)
+int mlx4_ib_destroy_qp(struct ib_qp *qp, struct ib_udata *udata)
 {
 	struct mlx4_ib_qp *mqp = to_mqp(qp);
 
@@ -4232,7 +4232,7 @@ int mlx4_ib_modify_wq(struct ib_wq *ibwq, struct ib_wq_attr *wq_attr,
 	return err;
 }
 
-int mlx4_ib_destroy_wq(struct ib_wq *ibwq)
+int mlx4_ib_destroy_wq(struct ib_wq *ibwq, struct ib_udata *udata)
 {
 	struct mlx4_ib_dev *dev = to_mdev(ibwq->device);
 	struct mlx4_ib_qp *qp = to_mqp((struct ib_qp *)ibwq);
diff --git a/drivers/infiniband/hw/mlx4/srq.c b/drivers/infiniband/hw/mlx4/srq.c
index 4456f1b8921d..097265c8b2e6 100644
--- a/drivers/infiniband/hw/mlx4/srq.c
+++ b/drivers/infiniband/hw/mlx4/srq.c
@@ -270,7 +270,7 @@ int mlx4_ib_query_srq(struct ib_srq *ibsrq, struct ib_srq_attr *srq_attr)
 	return 0;
 }
 
-int mlx4_ib_destroy_srq(struct ib_srq *srq)
+int mlx4_ib_destroy_srq(struct ib_srq *srq, struct ib_udata *udata)
 {
 	struct mlx4_ib_dev *dev = to_mdev(srq->device);
 	struct mlx4_ib_srq *msrq = to_msrq(srq);
diff --git a/drivers/infiniband/hw/mlx5/ah.c b/drivers/infiniband/hw/mlx5/ah.c
index 420ae0897333..2e377f9699f1 100644
--- a/drivers/infiniband/hw/mlx5/ah.c
+++ b/drivers/infiniband/hw/mlx5/ah.c
@@ -131,7 +131,7 @@ int mlx5_ib_query_ah(struct ib_ah *ibah, struct rdma_ah_attr *ah_attr)
 	return 0;
 }
 
-int mlx5_ib_destroy_ah(struct ib_ah *ah, u32 flags)
+int mlx5_ib_destroy_ah(struct ib_ah *ah, u32 flags, struct ib_udata *udata)
 {
 	kfree(to_mah(ah));
 	return 0;
diff --git a/drivers/infiniband/hw/mlx5/cq.c b/drivers/infiniband/hw/mlx5/cq.c
index 6bfa574fa013..6a47e9dd522c 100644
--- a/drivers/infiniband/hw/mlx5/cq.c
+++ b/drivers/infiniband/hw/mlx5/cq.c
@@ -996,8 +996,7 @@ struct ib_cq *mlx5_ib_create_cq(struct ib_device *ibdev,
 	return ERR_PTR(err);
 }
 
-
-int mlx5_ib_destroy_cq(struct ib_cq *cq)
+int mlx5_ib_destroy_cq(struct ib_cq *cq, struct ib_udata *udata)
 {
 	struct mlx5_ib_dev *dev = to_mdev(cq->device);
 	struct mlx5_ib_cq *mcq = to_mcq(cq);
* Unmerged path drivers/infiniband/hw/mlx5/main.c
diff --git a/drivers/infiniband/hw/mlx5/mlx5_ib.h b/drivers/infiniband/hw/mlx5/mlx5_ib.h
index 8120f808023d..09def627a840 100644
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -1057,14 +1057,14 @@ int mlx5_MAD_IFC(struct mlx5_ib_dev *dev, int ignore_mkey, int ignore_bkey,
 struct ib_ah *mlx5_ib_create_ah(struct ib_pd *pd, struct rdma_ah_attr *ah_attr,
 				u32 flags, struct ib_udata *udata);
 int mlx5_ib_query_ah(struct ib_ah *ibah, struct rdma_ah_attr *ah_attr);
-int mlx5_ib_destroy_ah(struct ib_ah *ah, u32 flags);
+int mlx5_ib_destroy_ah(struct ib_ah *ah, u32 flags, struct ib_udata *udata);
 struct ib_srq *mlx5_ib_create_srq(struct ib_pd *pd,
 				  struct ib_srq_init_attr *init_attr,
 				  struct ib_udata *udata);
 int mlx5_ib_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,
 		       enum ib_srq_attr_mask attr_mask, struct ib_udata *udata);
 int mlx5_ib_query_srq(struct ib_srq *ibsrq, struct ib_srq_attr *srq_attr);
-int mlx5_ib_destroy_srq(struct ib_srq *srq);
+int mlx5_ib_destroy_srq(struct ib_srq *srq, struct ib_udata *udata);
 int mlx5_ib_post_srq_recv(struct ib_srq *ibsrq, const struct ib_recv_wr *wr,
 			  const struct ib_recv_wr **bad_wr);
 int mlx5_ib_enable_lb(struct mlx5_ib_dev *dev, bool td, bool qp);
@@ -1076,7 +1076,7 @@ int mlx5_ib_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 		      int attr_mask, struct ib_udata *udata);
 int mlx5_ib_query_qp(struct ib_qp *ibqp, struct ib_qp_attr *qp_attr, int qp_attr_mask,
 		     struct ib_qp_init_attr *qp_init_attr);
-int mlx5_ib_destroy_qp(struct ib_qp *qp);
+int mlx5_ib_destroy_qp(struct ib_qp *qp, struct ib_udata *udata);
 void mlx5_ib_drain_sq(struct ib_qp *qp);
 void mlx5_ib_drain_rq(struct ib_qp *qp);
 int mlx5_ib_post_send(struct ib_qp *ibqp, const struct ib_send_wr *wr,
@@ -1090,7 +1090,7 @@ struct ib_cq *mlx5_ib_create_cq(struct ib_device *ibdev,
 				const struct ib_cq_init_attr *attr,
 				struct ib_ucontext *context,
 				struct ib_udata *udata);
-int mlx5_ib_destroy_cq(struct ib_cq *cq);
+int mlx5_ib_destroy_cq(struct ib_cq *cq, struct ib_udata *udata);
 int mlx5_ib_poll_cq(struct ib_cq *ibcq, int num_entries, struct ib_wc *wc);
 int mlx5_ib_arm_cq(struct ib_cq *ibcq, enum ib_cq_notify_flags flags);
 int mlx5_ib_modify_cq(struct ib_cq *cq, u16 cq_count, u16 cq_period);
@@ -1116,10 +1116,9 @@ void mlx5_ib_free_implicit_mr(struct mlx5_ib_mr *mr);
 int mlx5_ib_rereg_user_mr(struct ib_mr *ib_mr, int flags, u64 start,
 			  u64 length, u64 virt_addr, int access_flags,
 			  struct ib_pd *pd, struct ib_udata *udata);
-int mlx5_ib_dereg_mr(struct ib_mr *ibmr);
-struct ib_mr *mlx5_ib_alloc_mr(struct ib_pd *pd,
-			       enum ib_mr_type mr_type,
-			       u32 max_num_sg);
+int mlx5_ib_dereg_mr(struct ib_mr *ibmr, struct ib_udata *udata);
+struct ib_mr *mlx5_ib_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
+			       u32 max_num_sg, struct ib_udata *udata);
 int mlx5_ib_map_mr_sg(struct ib_mr *ibmr, struct scatterlist *sg, int sg_nents,
 		      unsigned int *sg_offset);
 int mlx5_ib_process_mad(struct ib_device *ibdev, int mad_flags, u8 port_num,
@@ -1130,7 +1129,7 @@ int mlx5_ib_process_mad(struct ib_device *ibdev, int mad_flags, u8 port_num,
 struct ib_xrcd *mlx5_ib_alloc_xrcd(struct ib_device *ibdev,
 					  struct ib_ucontext *context,
 					  struct ib_udata *udata);
-int mlx5_ib_dealloc_xrcd(struct ib_xrcd *xrcd);
+int mlx5_ib_dealloc_xrcd(struct ib_xrcd *xrcd, struct ib_udata *udata);
 int mlx5_ib_get_buf_offset(u64 addr, int page_shift, u32 *offset);
 int mlx5_query_ext_port_caps(struct mlx5_ib_dev *dev, u8 port);
 int mlx5_query_mad_ifc_smp_attr_node_info(struct ib_device *ibdev,
@@ -1174,7 +1173,7 @@ int mlx5_ib_check_mr_status(struct ib_mr *ibmr, u32 check_mask,
 struct ib_wq *mlx5_ib_create_wq(struct ib_pd *pd,
 				struct ib_wq_init_attr *init_attr,
 				struct ib_udata *udata);
-int mlx5_ib_destroy_wq(struct ib_wq *wq);
+int mlx5_ib_destroy_wq(struct ib_wq *wq, struct ib_udata *udata);
 int mlx5_ib_modify_wq(struct ib_wq *wq, struct ib_wq_attr *wq_attr,
 		      u32 wq_attr_mask, struct ib_udata *udata);
 struct ib_rwq_ind_table *mlx5_ib_create_rwq_ind_table(struct ib_device *device,
@@ -1186,7 +1185,7 @@ struct ib_dm *mlx5_ib_alloc_dm(struct ib_device *ibdev,
 			       struct ib_ucontext *context,
 			       struct ib_dm_alloc_attr *attr,
 			       struct uverbs_attr_bundle *attrs);
-int mlx5_ib_dealloc_dm(struct ib_dm *ibdm);
+int mlx5_ib_dealloc_dm(struct ib_dm *ibdm, struct uverbs_attr_bundle *attrs);
 struct ib_mr *mlx5_ib_reg_dm_mr(struct ib_pd *pd, struct ib_dm *dm,
 				struct ib_dm_mr_attr *attr,
 				struct uverbs_attr_bundle *attrs);
diff --git a/drivers/infiniband/hw/mlx5/mr.c b/drivers/infiniband/hw/mlx5/mr.c
index 117463d43c3b..c26500987748 100644
--- a/drivers/infiniband/hw/mlx5/mr.c
+++ b/drivers/infiniband/hw/mlx5/mr.c
@@ -1656,15 +1656,14 @@ static void dereg_mr(struct mlx5_ib_dev *dev, struct mlx5_ib_mr *mr)
 		kfree(mr);
 }
 
-int mlx5_ib_dereg_mr(struct ib_mr *ibmr)
+int mlx5_ib_dereg_mr(struct ib_mr *ibmr, struct ib_udata *udata)
 {
 	dereg_mr(to_mdev(ibmr->device), to_mmr(ibmr));
 	return 0;
 }
 
-struct ib_mr *mlx5_ib_alloc_mr(struct ib_pd *pd,
-			       enum ib_mr_type mr_type,
-			       u32 max_num_sg)
+struct ib_mr *mlx5_ib_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
+			       u32 max_num_sg, struct ib_udata *udata)
 {
 	struct mlx5_ib_dev *dev = to_mdev(pd->device);
 	int inlen = MLX5_ST_SZ_BYTES(create_mkey_in);
diff --git a/drivers/infiniband/hw/mlx5/qp.c b/drivers/infiniband/hw/mlx5/qp.c
index 7927d666efe8..085701805e33 100644
--- a/drivers/infiniband/hw/mlx5/qp.c
+++ b/drivers/infiniband/hw/mlx5/qp.c
@@ -2636,7 +2636,7 @@ static int mlx5_ib_destroy_dct(struct mlx5_ib_qp *mqp)
 	return 0;
 }
 
-int mlx5_ib_destroy_qp(struct ib_qp *qp)
+int mlx5_ib_destroy_qp(struct ib_qp *qp, struct ib_udata *udata)
 {
 	struct mlx5_ib_dev *dev = to_mdev(qp->device);
 	struct mlx5_ib_qp *mqp = to_mqp(qp);
@@ -5550,7 +5550,7 @@ struct ib_xrcd *mlx5_ib_alloc_xrcd(struct ib_device *ibdev,
 	return &xrcd->ibxrcd;
 }
 
-int mlx5_ib_dealloc_xrcd(struct ib_xrcd *xrcd)
+int mlx5_ib_dealloc_xrcd(struct ib_xrcd *xrcd, struct ib_udata *udata)
 {
 	struct mlx5_ib_dev *dev = to_mdev(xrcd->device);
 	u32 xrcdn = to_mxrcd(xrcd)->xrcdn;
@@ -5868,7 +5868,7 @@ struct ib_wq *mlx5_ib_create_wq(struct ib_pd *pd,
 	return ERR_PTR(err);
 }
 
-int mlx5_ib_destroy_wq(struct ib_wq *wq)
+int mlx5_ib_destroy_wq(struct ib_wq *wq, struct ib_udata *udata)
 {
 	struct mlx5_ib_dev *dev = to_mdev(wq->device);
 	struct mlx5_ib_rwq *rwq = to_mrwq(wq);
diff --git a/drivers/infiniband/hw/mlx5/srq.c b/drivers/infiniband/hw/mlx5/srq.c
index 4e8d18009f58..d9351d2e0e34 100644
--- a/drivers/infiniband/hw/mlx5/srq.c
+++ b/drivers/infiniband/hw/mlx5/srq.c
@@ -388,7 +388,7 @@ int mlx5_ib_query_srq(struct ib_srq *ibsrq, struct ib_srq_attr *srq_attr)
 	return ret;
 }
 
-int mlx5_ib_destroy_srq(struct ib_srq *srq)
+int mlx5_ib_destroy_srq(struct ib_srq *srq, struct ib_udata *udata)
 {
 	struct mlx5_ib_dev *dev = to_mdev(srq->device);
 	struct mlx5_ib_srq *msrq = to_msrq(srq);
* Unmerged path drivers/infiniband/hw/mthca/mthca_provider.c
diff --git a/drivers/infiniband/hw/nes/nes_cm.c b/drivers/infiniband/hw/nes/nes_cm.c
index 8ab104201e4e..51c3ec06005c 100644
--- a/drivers/infiniband/hw/nes/nes_cm.c
+++ b/drivers/infiniband/hw/nes/nes_cm.c
@@ -3031,7 +3031,8 @@ static int nes_disconnect(struct nes_qp *nesqp, int abrupt)
 		/* Need to free the Last Streaming Mode Message */
 		if (nesqp->ietf_frame) {
 			if (nesqp->lsmm_mr)
-				nesibdev->ibdev.ops.dereg_mr(nesqp->lsmm_mr);
+				nesibdev->ibdev.ops.dereg_mr(nesqp->lsmm_mr,
+							     NULL);
 			pci_free_consistent(nesdev->pcidev,
 					    nesqp->private_data_len + nesqp->ietf_frame_size,
 					    nesqp->ietf_frame, nesqp->ietf_frame_pbase);
* Unmerged path drivers/infiniband/hw/nes/nes_verbs.c
diff --git a/drivers/infiniband/hw/ocrdma/ocrdma_ah.c b/drivers/infiniband/hw/ocrdma/ocrdma_ah.c
index 838cf5c36ca4..e824cd6b480e 100644
--- a/drivers/infiniband/hw/ocrdma/ocrdma_ah.c
+++ b/drivers/infiniband/hw/ocrdma/ocrdma_ah.c
@@ -221,7 +221,7 @@ struct ib_ah *ocrdma_create_ah(struct ib_pd *ibpd, struct rdma_ah_attr *attr,
 	return ERR_PTR(status);
 }
 
-int ocrdma_destroy_ah(struct ib_ah *ibah, u32 flags)
+int ocrdma_destroy_ah(struct ib_ah *ibah, u32 flags, struct ib_udata *udata)
 {
 	struct ocrdma_ah *ah = get_ocrdma_ah(ibah);
 	struct ocrdma_dev *dev = get_ocrdma_dev(ibah->device);
diff --git a/drivers/infiniband/hw/ocrdma/ocrdma_ah.h b/drivers/infiniband/hw/ocrdma/ocrdma_ah.h
index eb996e14b520..9b84034d8164 100644
--- a/drivers/infiniband/hw/ocrdma/ocrdma_ah.h
+++ b/drivers/infiniband/hw/ocrdma/ocrdma_ah.h
@@ -53,7 +53,7 @@ enum {
 
 struct ib_ah *ocrdma_create_ah(struct ib_pd *pd, struct rdma_ah_attr *ah_attr,
 			       u32 flags, struct ib_udata *udata);
-int ocrdma_destroy_ah(struct ib_ah *ah, u32 flags);
+int ocrdma_destroy_ah(struct ib_ah *ah, u32 flags, struct ib_udata *udata);
 int ocrdma_query_ah(struct ib_ah *ah, struct rdma_ah_attr *ah_attr);
 
 int ocrdma_process_mad(struct ib_device *,
* Unmerged path drivers/infiniband/hw/ocrdma/ocrdma_verbs.c
* Unmerged path drivers/infiniband/hw/ocrdma/ocrdma_verbs.h
* Unmerged path drivers/infiniband/hw/qedr/verbs.c
* Unmerged path drivers/infiniband/hw/qedr/verbs.h
* Unmerged path drivers/infiniband/hw/usnic/usnic_ib_verbs.c
* Unmerged path drivers/infiniband/hw/usnic/usnic_ib_verbs.h
diff --git a/drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c b/drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c
index 0f004c737620..be759fc75a8f 100644
--- a/drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c
+++ b/drivers/infiniband/hw/vmw_pvrdma/pvrdma_cq.c
@@ -210,7 +210,7 @@ struct ib_cq *pvrdma_create_cq(struct ib_device *ibdev,
 		if (ib_copy_to_udata(udata, &cq_resp, sizeof(cq_resp))) {
 			dev_warn(&dev->pdev->dev,
 				 "failed to copy back udata\n");
-			pvrdma_destroy_cq(&cq->ibcq);
+			pvrdma_destroy_cq(&cq->ibcq, udata);
 			return ERR_PTR(-EINVAL);
 		}
 	}
@@ -245,10 +245,11 @@ static void pvrdma_free_cq(struct pvrdma_dev *dev, struct pvrdma_cq *cq)
 /**
  * pvrdma_destroy_cq - destroy completion queue
  * @cq: the completion queue to destroy.
+ * @udata: user data or null for kernel object
  *
  * @return: 0 for success.
  */
-int pvrdma_destroy_cq(struct ib_cq *cq)
+int pvrdma_destroy_cq(struct ib_cq *cq, struct ib_udata *udata)
 {
 	struct pvrdma_cq *vcq = to_vcq(cq);
 	union pvrdma_cmd_req req;
diff --git a/drivers/infiniband/hw/vmw_pvrdma/pvrdma_mr.c b/drivers/infiniband/hw/vmw_pvrdma/pvrdma_mr.c
index fa96fa4fb829..adf0478b4756 100644
--- a/drivers/infiniband/hw/vmw_pvrdma/pvrdma_mr.c
+++ b/drivers/infiniband/hw/vmw_pvrdma/pvrdma_mr.c
@@ -202,7 +202,7 @@ struct ib_mr *pvrdma_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,
  * @return: ib_mr pointer on success, otherwise returns an errno.
  */
 struct ib_mr *pvrdma_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
-			      u32 max_num_sg)
+			      u32 max_num_sg, struct ib_udata *udata)
 {
 	struct pvrdma_dev *dev = to_vdev(pd->device);
 	struct pvrdma_user_mr *mr;
@@ -273,7 +273,7 @@ struct ib_mr *pvrdma_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
  *
  * @return: 0 on success.
  */
-int pvrdma_dereg_mr(struct ib_mr *ibmr)
+int pvrdma_dereg_mr(struct ib_mr *ibmr, struct ib_udata *udata)
 {
 	struct pvrdma_user_mr *mr = to_vmr(ibmr);
 	struct pvrdma_dev *dev = to_vdev(ibmr->device);
diff --git a/drivers/infiniband/hw/vmw_pvrdma/pvrdma_qp.c b/drivers/infiniband/hw/vmw_pvrdma/pvrdma_qp.c
index 1ec3646087ba..e56fef562b42 100644
--- a/drivers/infiniband/hw/vmw_pvrdma/pvrdma_qp.c
+++ b/drivers/infiniband/hw/vmw_pvrdma/pvrdma_qp.c
@@ -448,10 +448,11 @@ static void pvrdma_free_qp(struct pvrdma_qp *qp)
 /**
  * pvrdma_destroy_qp - destroy a queue pair
  * @qp: the queue pair to destroy
+ * @udata: user data or null for kernel object
  *
  * @return: 0 on success.
  */
-int pvrdma_destroy_qp(struct ib_qp *qp)
+int pvrdma_destroy_qp(struct ib_qp *qp, struct ib_udata *udata)
 {
 	struct pvrdma_qp *vqp = to_vqp(qp);
 	union pvrdma_cmd_req req;
diff --git a/drivers/infiniband/hw/vmw_pvrdma/pvrdma_srq.c b/drivers/infiniband/hw/vmw_pvrdma/pvrdma_srq.c
index 06ba7c7a2235..65ed9e8e65cd 100644
--- a/drivers/infiniband/hw/vmw_pvrdma/pvrdma_srq.c
+++ b/drivers/infiniband/hw/vmw_pvrdma/pvrdma_srq.c
@@ -206,7 +206,7 @@ struct ib_srq *pvrdma_create_srq(struct ib_pd *pd,
 	/* Copy udata back. */
 	if (ib_copy_to_udata(udata, &srq_resp, sizeof(srq_resp))) {
 		dev_warn(&dev->pdev->dev, "failed to copy back udata\n");
-		pvrdma_destroy_srq(&srq->ibsrq);
+		pvrdma_destroy_srq(&srq->ibsrq, udata);
 		return ERR_PTR(-EINVAL);
 	}
 
@@ -248,10 +248,11 @@ static void pvrdma_free_srq(struct pvrdma_dev *dev, struct pvrdma_srq *srq)
 /**
  * pvrdma_destroy_srq - destroy shared receive queue
  * @srq: the shared receive queue to destroy
+ * @udata: user data or null for kernel object
  *
  * @return: 0 for success.
  */
-int pvrdma_destroy_srq(struct ib_srq *srq)
+int pvrdma_destroy_srq(struct ib_srq *srq, struct ib_udata *udata)
 {
 	struct pvrdma_srq *vsrq = to_vsrq(srq);
 	union pvrdma_cmd_req req;
* Unmerged path drivers/infiniband/hw/vmw_pvrdma/pvrdma_verbs.c
* Unmerged path drivers/infiniband/hw/vmw_pvrdma/pvrdma_verbs.h
diff --git a/drivers/infiniband/sw/rdmavt/ah.c b/drivers/infiniband/sw/rdmavt/ah.c
index fc10e4e26ca7..001a5c052580 100644
--- a/drivers/infiniband/sw/rdmavt/ah.c
+++ b/drivers/infiniband/sw/rdmavt/ah.c
@@ -138,10 +138,12 @@ struct ib_ah *rvt_create_ah(struct ib_pd *pd,
  * rvt_destory_ah - Destory an address handle
  * @ibah: address handle
  * @destroy_flags: destroy address handle flags (see enum rdma_destroy_ah_flags)
+ * @udata: user data or NULL for kernel object
  *
  * Return: 0 on success
  */
-int rvt_destroy_ah(struct ib_ah *ibah, u32 destroy_flags)
+int rvt_destroy_ah(struct ib_ah *ibah, u32 destroy_flags,
+		   struct ib_udata *udata)
 {
 	struct rvt_dev_info *dev = ib_to_rvt(ibah->device);
 	struct rvt_ah *ah = ibah_to_rvtah(ibah);
diff --git a/drivers/infiniband/sw/rdmavt/ah.h b/drivers/infiniband/sw/rdmavt/ah.h
index 72431a618d5d..7b27b82d8a90 100644
--- a/drivers/infiniband/sw/rdmavt/ah.h
+++ b/drivers/infiniband/sw/rdmavt/ah.h
@@ -54,7 +54,8 @@ struct ib_ah *rvt_create_ah(struct ib_pd *pd,
 			    struct rdma_ah_attr *ah_attr,
 			    u32 create_flags,
 			    struct ib_udata *udata);
-int rvt_destroy_ah(struct ib_ah *ibah, u32 destroy_flags);
+int rvt_destroy_ah(struct ib_ah *ibah, u32 destroy_flags,
+		   struct ib_udata *udata);
 int rvt_modify_ah(struct ib_ah *ibah, struct rdma_ah_attr *ah_attr);
 int rvt_query_ah(struct ib_ah *ibah, struct rdma_ah_attr *ah_attr);
 
diff --git a/drivers/infiniband/sw/rdmavt/cq.c b/drivers/infiniband/sw/rdmavt/cq.c
index 4f1544ad4aff..6f7ff2384506 100644
--- a/drivers/infiniband/sw/rdmavt/cq.c
+++ b/drivers/infiniband/sw/rdmavt/cq.c
@@ -299,12 +299,13 @@ struct ib_cq *rvt_create_cq(struct ib_device *ibdev,
 /**
  * rvt_destroy_cq - destroy a completion queue
  * @ibcq: the completion queue to destroy.
+ * @udata: user data or NULL for kernel object
  *
  * Called by ib_destroy_cq() in the generic verbs code.
  *
  * Return: always 0
  */
-int rvt_destroy_cq(struct ib_cq *ibcq)
+int rvt_destroy_cq(struct ib_cq *ibcq, struct ib_udata *udata)
 {
 	struct rvt_cq *cq = ibcq_to_rvtcq(ibcq);
 	struct rvt_dev_info *rdi = cq->rdi;
diff --git a/drivers/infiniband/sw/rdmavt/cq.h b/drivers/infiniband/sw/rdmavt/cq.h
index 72184b1c176b..e42661ecdef8 100644
--- a/drivers/infiniband/sw/rdmavt/cq.h
+++ b/drivers/infiniband/sw/rdmavt/cq.h
@@ -55,7 +55,7 @@ struct ib_cq *rvt_create_cq(struct ib_device *ibdev,
 			    const struct ib_cq_init_attr *attr,
 			    struct ib_ucontext *context,
 			    struct ib_udata *udata);
-int rvt_destroy_cq(struct ib_cq *ibcq);
+int rvt_destroy_cq(struct ib_cq *ibcq, struct ib_udata *udata);
 int rvt_req_notify_cq(struct ib_cq *ibcq, enum ib_cq_notify_flags notify_flags);
 int rvt_resize_cq(struct ib_cq *ibcq, int cqe, struct ib_udata *udata);
 int rvt_poll_cq(struct ib_cq *ibcq, int num_entries, struct ib_wc *entry);
diff --git a/drivers/infiniband/sw/rdmavt/mr.c b/drivers/infiniband/sw/rdmavt/mr.c
index e63e21783840..8db9c5c1e10d 100644
--- a/drivers/infiniband/sw/rdmavt/mr.c
+++ b/drivers/infiniband/sw/rdmavt/mr.c
@@ -549,7 +549,7 @@ bool rvt_ss_has_lkey(struct rvt_sge_state *ss, u32 lkey)
  *
  * Returns 0 on success.
  */
-int rvt_dereg_mr(struct ib_mr *ibmr)
+int rvt_dereg_mr(struct ib_mr *ibmr, struct ib_udata *udata)
 {
 	struct rvt_mr *mr = to_imr(ibmr);
 	int ret;
@@ -576,9 +576,8 @@ int rvt_dereg_mr(struct ib_mr *ibmr)
  *
  * Return: the memory region on success, otherwise return an errno.
  */
-struct ib_mr *rvt_alloc_mr(struct ib_pd *pd,
-			   enum ib_mr_type mr_type,
-			   u32 max_num_sg)
+struct ib_mr *rvt_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
+			   u32 max_num_sg, struct ib_udata *udata)
 {
 	struct rvt_mr *mr;
 
diff --git a/drivers/infiniband/sw/rdmavt/mr.h b/drivers/infiniband/sw/rdmavt/mr.h
index 132800ee0205..2c8d0752e8e3 100644
--- a/drivers/infiniband/sw/rdmavt/mr.h
+++ b/drivers/infiniband/sw/rdmavt/mr.h
@@ -78,10 +78,9 @@ struct ib_mr *rvt_get_dma_mr(struct ib_pd *pd, int acc);
 struct ib_mr *rvt_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,
 			      u64 virt_addr, int mr_access_flags,
 			      struct ib_udata *udata);
-int rvt_dereg_mr(struct ib_mr *ibmr);
-struct ib_mr *rvt_alloc_mr(struct ib_pd *pd,
-			   enum ib_mr_type mr_type,
-			   u32 max_num_sg);
+int rvt_dereg_mr(struct ib_mr *ibmr, struct ib_udata *udata);
+struct ib_mr *rvt_alloc_mr(struct ib_pd *pd, enum ib_mr_type mr_type,
+			   u32 max_num_sg, struct ib_udata *udata);
 int rvt_map_mr_sg(struct ib_mr *ibmr, struct scatterlist *sg,
 		  int sg_nents, unsigned int *sg_offset);
 struct ib_fmr *rvt_alloc_fmr(struct ib_pd *pd, int mr_access_flags,
* Unmerged path drivers/infiniband/sw/rdmavt/pd.c
* Unmerged path drivers/infiniband/sw/rdmavt/pd.h
diff --git a/drivers/infiniband/sw/rdmavt/qp.c b/drivers/infiniband/sw/rdmavt/qp.c
index 9fb585ace82f..d9cbfd130072 100644
--- a/drivers/infiniband/sw/rdmavt/qp.c
+++ b/drivers/infiniband/sw/rdmavt/qp.c
@@ -1614,7 +1614,7 @@ int rvt_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
  *
  * Return: 0 on success.
  */
-int rvt_destroy_qp(struct ib_qp *ibqp)
+int rvt_destroy_qp(struct ib_qp *ibqp, struct ib_udata *udata)
 {
 	struct rvt_qp *qp = ibqp_to_rvtqp(ibqp);
 	struct rvt_dev_info *rdi = ib_to_rvt(ibqp->device);
diff --git a/drivers/infiniband/sw/rdmavt/qp.h b/drivers/infiniband/sw/rdmavt/qp.h
index 6d883972e0b8..450b27ea1fa4 100644
--- a/drivers/infiniband/sw/rdmavt/qp.h
+++ b/drivers/infiniband/sw/rdmavt/qp.h
@@ -57,7 +57,7 @@ struct ib_qp *rvt_create_qp(struct ib_pd *ibpd,
 			    struct ib_udata *udata);
 int rvt_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 		  int attr_mask, struct ib_udata *udata);
-int rvt_destroy_qp(struct ib_qp *ibqp);
+int rvt_destroy_qp(struct ib_qp *ibqp, struct ib_udata *udata);
 int rvt_query_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 		 int attr_mask, struct ib_qp_init_attr *init_attr);
 int rvt_post_recv(struct ib_qp *ibqp, const struct ib_recv_wr *wr,
diff --git a/drivers/infiniband/sw/rdmavt/srq.c b/drivers/infiniband/sw/rdmavt/srq.c
index 78e06fc456c5..8f73d7d65e06 100644
--- a/drivers/infiniband/sw/rdmavt/srq.c
+++ b/drivers/infiniband/sw/rdmavt/srq.c
@@ -337,7 +337,7 @@ int rvt_query_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr)
  *
  * Return always 0
  */
-int rvt_destroy_srq(struct ib_srq *ibsrq)
+int rvt_destroy_srq(struct ib_srq *ibsrq, struct ib_udata *udata)
 {
 	struct rvt_srq *srq = ibsrq_to_rvtsrq(ibsrq);
 	struct rvt_dev_info *dev = ib_to_rvt(ibsrq->device);
diff --git a/drivers/infiniband/sw/rdmavt/srq.h b/drivers/infiniband/sw/rdmavt/srq.h
index bf0eaaf56465..69cad2f65408 100644
--- a/drivers/infiniband/sw/rdmavt/srq.h
+++ b/drivers/infiniband/sw/rdmavt/srq.h
@@ -57,6 +57,6 @@ int rvt_modify_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr,
 		   enum ib_srq_attr_mask attr_mask,
 		   struct ib_udata *udata);
 int rvt_query_srq(struct ib_srq *ibsrq, struct ib_srq_attr *attr);
-int rvt_destroy_srq(struct ib_srq *ibsrq);
+int rvt_destroy_srq(struct ib_srq *ibsrq, struct ib_udata *udata);
 
 #endif          /* DEF_RVTSRQ_H */
* Unmerged path drivers/infiniband/sw/rxe/rxe_verbs.c
* Unmerged path include/rdma/ib_verbs.h
