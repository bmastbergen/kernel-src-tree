mm/sparsemem: cleanup 'section number' data types

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [mm] sparsemem: cleanup 'section number' data types (Baoquan He) [1724969]
Rebuild_FUZZ: 96.84%
commit-author Dan Williams <dan.j.williams@intel.com>
commit 9a845030427c7a2879a7d635cc7c0e5f79ec962d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/9a845030.failed

David points out that there is a mixture of 'int' and 'unsigned long'
usage for section number data types.  Update the memory hotplug path to
use 'unsigned long' consistently for section numbers.

[akpm@linux-foundation.org: fix printk format]
Link: http://lkml.kernel.org/r/156107543656.1329419.11505835211949439815.stgit@dwillia2-desk3.amr.corp.intel.com
	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
	Reported-by: David Hildenbrand <david@redhat.com>
	Reviewed-by: David Hildenbrand <david@redhat.com>
	Cc: Michal Hocko <mhocko@suse.com>
	Cc: Oscar Salvador <osalvador@suse.de>
	Cc: Jason Gunthorpe <jgg@mellanox.com>
	Cc: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 9a845030427c7a2879a7d635cc7c0e5f79ec962d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/memory_hotplug.c
#	mm/sparse.c
diff --cc mm/memory_hotplug.c
index e466254573a3,2a9bbddb0e55..000000000000
--- a/mm/memory_hotplug.c
+++ b/mm/memory_hotplug.c
@@@ -277,17 -285,12 +277,23 @@@ static int __meminit __add_section(int 
   * call this function after deciding the zone to which to
   * add the new pages.
   */
 -int __ref __add_pages(int nid, unsigned long pfn, unsigned long nr_pages,
 -		struct mhp_restrictions *restrictions)
 -{
 +int __ref __add_pages(int nid, unsigned long phys_start_pfn,
 +		unsigned long nr_pages, struct vmem_altmap *altmap,
 +		bool want_memblock)
 +{
++<<<<<<< HEAD
 +	unsigned long i;
 +	int err = 0;
 +	int start_sec, end_sec;
 +
 +	/* during initialize mem_map, align hot-added range to section */
 +	start_sec = pfn_to_section_nr(phys_start_pfn);
 +	end_sec = pfn_to_section_nr(phys_start_pfn + nr_pages - 1);
++=======
+ 	int err;
+ 	unsigned long nr, start_sec, end_sec;
+ 	struct vmem_altmap *altmap = restrictions->altmap;
++>>>>>>> 9a845030427c (mm/sparsemem: cleanup 'section number' data types)
  
  	if (altmap) {
  		/*
@@@ -302,18 -304,22 +308,29 @@@
  		altmap->alloc = 0;
  	}
  
++<<<<<<< HEAD
 +	for (i = start_sec; i <= end_sec; i++) {
 +		err = __add_section(nid, section_nr_to_pfn(i), altmap,
 +				want_memblock);
++=======
+ 	err = check_pfn_span(pfn, nr_pages, "add");
+ 	if (err)
+ 		return err;
+ 
+ 	start_sec = pfn_to_section_nr(pfn);
+ 	end_sec = pfn_to_section_nr(pfn + nr_pages - 1);
+ 	for (nr = start_sec; nr <= end_sec; nr++) {
+ 		unsigned long pfns;
++>>>>>>> 9a845030427c (mm/sparsemem: cleanup 'section number' data types)
  
 -		pfns = min(nr_pages, PAGES_PER_SECTION
 -				- (pfn & ~PAGE_SECTION_MASK));
 -		err = sparse_add_section(nid, pfn, pfns, altmap);
 -		if (err)
 +		/*
 +		 * EEXIST is finally dealt with by ioresource collision
 +		 * check. see add_memory() => register_memory_resource()
 +		 * Warning will be printed if there is collision.
 +		 */
 +		if (err && (err != -EEXIST))
  			break;
 -		pfn += pfns;
 -		nr_pages -= pfns;
 +		err = 0;
  		cond_resched();
  	}
  	vmemmap_populate_print_last();
@@@ -539,34 -537,30 +556,45 @@@ static void __remove_section(struct zon
   * sure that pages are marked reserved and zones are adjust properly by
   * calling offline_pages().
   */
 -void __remove_pages(struct zone *zone, unsigned long pfn,
 -		    unsigned long nr_pages, struct vmem_altmap *altmap)
 +int __remove_pages(struct zone *zone, unsigned long phys_start_pfn,
 +		 unsigned long nr_pages, struct vmem_altmap *altmap)
  {
 +	unsigned long i;
  	unsigned long map_offset = 0;
++<<<<<<< HEAD
 +	int sections_to_remove;
++=======
+ 	unsigned long nr, start_sec, end_sec;
++>>>>>>> 9a845030427c (mm/sparsemem: cleanup 'section number' data types)
  
 -	map_offset = vmem_altmap_offset(altmap);
 +	/* In the ZONE_DEVICE case device driver owns the memory region */
 +	if (is_dev_zone(zone)) {
 +		if (altmap)
 +			map_offset = vmem_altmap_offset(altmap);
 +	}
  
  	clear_zone_contiguous(zone);
  
 -	if (check_pfn_span(pfn, nr_pages, "remove"))
 -		return;
 -
 +	/*
 +	 * We can only remove entire sections
 +	 */
 +	BUG_ON(phys_start_pfn & ~PAGE_SECTION_MASK);
 +	BUG_ON(nr_pages % PAGES_PER_SECTION);
 +
++<<<<<<< HEAD
 +	sections_to_remove = nr_pages / PAGES_PER_SECTION;
 +	for (i = 0; i < sections_to_remove; i++) {
 +		unsigned long pfn = phys_start_pfn + i*PAGES_PER_SECTION;
++=======
+ 	start_sec = pfn_to_section_nr(pfn);
+ 	end_sec = pfn_to_section_nr(pfn + nr_pages - 1);
+ 	for (nr = start_sec; nr <= end_sec; nr++) {
+ 		unsigned long pfns;
++>>>>>>> 9a845030427c (mm/sparsemem: cleanup 'section number' data types)
  
  		cond_resched();
 -		pfns = min(nr_pages, PAGES_PER_SECTION
 -				- (pfn & ~PAGE_SECTION_MASK));
 -		__remove_section(zone, pfn, pfns, map_offset, altmap);
 -		pfn += pfns;
 -		nr_pages -= pfns;
 +		__remove_section(zone, __pfn_to_section(pfn), map_offset,
 +				 altmap);
  		map_offset = 0;
  	}
  
diff --cc mm/sparse.c
index 02b5de3161a3,72f010d9bff5..000000000000
--- a/mm/sparse.c
+++ b/mm/sparse.c
@@@ -205,6 -217,41 +205,44 @@@ static inline unsigned long first_prese
  	return next_present_section_nr(-1);
  }
  
++<<<<<<< HEAD
++=======
+ void subsection_mask_set(unsigned long *map, unsigned long pfn,
+ 		unsigned long nr_pages)
+ {
+ 	int idx = subsection_map_index(pfn);
+ 	int end = subsection_map_index(pfn + nr_pages - 1);
+ 
+ 	bitmap_set(map, idx, end - idx + 1);
+ }
+ 
+ void __init subsection_map_init(unsigned long pfn, unsigned long nr_pages)
+ {
+ 	int end_sec = pfn_to_section_nr(pfn + nr_pages - 1);
+ 	unsigned long nr, start_sec = pfn_to_section_nr(pfn);
+ 
+ 	if (!nr_pages)
+ 		return;
+ 
+ 	for (nr = start_sec; nr <= end_sec; nr++) {
+ 		struct mem_section *ms;
+ 		unsigned long pfns;
+ 
+ 		pfns = min(nr_pages, PAGES_PER_SECTION
+ 				- (pfn & ~PAGE_SECTION_MASK));
+ 		ms = __nr_to_section(nr);
+ 		subsection_mask_set(ms->usage->subsection_map, pfn, pfns);
+ 
+ 		pr_debug("%s: sec: %lu pfns: %lu set(%d, %d)\n", __func__, nr,
+ 				pfns, subsection_map_index(pfn),
+ 				subsection_map_index(pfn + pfns - 1));
+ 
+ 		pfn += pfns;
+ 		nr_pages -= pfns;
+ 	}
+ }
+ 
++>>>>>>> 9a845030427c (mm/sparsemem: cleanup 'section number' data types)
  /* Record a memory area against a node. */
  void __init memory_present(int nid, unsigned long start, unsigned long end)
  {
* Unmerged path mm/memory_hotplug.c
* Unmerged path mm/sparse.c
