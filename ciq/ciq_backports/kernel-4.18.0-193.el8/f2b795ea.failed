net: sched: cls_matchall: cleanup flow_action before deallocating

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [net] sched: cls_matchall: cleanup flow_action before deallocating (Ivan Vecera) [1739606]
Rebuild_FUZZ: 96.00%
commit-author Vlad Buslov <vladbu@mellanox.com>
commit f2b795ea025c743073933d5a121e22a2c3e66c99
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/f2b795ea.failed

Recent rtnl lock removal patch changed flow_action infra to require proper
cleanup besides simple memory deallocation. However, matchall classifier
was not updated to call tc_cleanup_flow_action(). Add proper cleanup to
mall_replace_hw_filter() and mall_reoffload().

Fixes: 5a6ff4b13d59 ("net: sched: take reference to action dev before calling offloads")
	Reported-by: Ido Schimmel <idosch@mellanox.com>
	Tested-by: Ido Schimmel <idosch@mellanox.com>
	Signed-off-by: Vlad Buslov <vladbu@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit f2b795ea025c743073933d5a121e22a2c3e66c99)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sched/cls_matchall.c
diff --cc net/sched/cls_matchall.c
index 0d898af13b5f,7fc2eb62aa98..000000000000
--- a/net/sched/cls_matchall.c
+++ b/net/sched/cls_matchall.c
@@@ -113,15 -109,14 +113,21 @@@ static int mall_replace_hw_filter(struc
  		return err;
  	}
  
++<<<<<<< HEAD
 +	err = tc_setup_cb_call(block, TC_SETUP_CLSMATCHALL, &cls_mall, skip_sw);
++=======
+ 	err = tc_setup_cb_add(block, tp, TC_SETUP_CLSMATCHALL, &cls_mall,
+ 			      skip_sw, &head->flags, &head->in_hw_count, true);
+ 	tc_cleanup_flow_action(&cls_mall.rule->action);
++>>>>>>> f2b795ea025c (net: sched: cls_matchall: cleanup flow_action before deallocating)
  	kfree(cls_mall.rule);
  
 -	if (err) {
 +	if (err < 0) {
  		mall_destroy_hw_filter(tp, head, cookie, NULL);
  		return err;
 +	} else if (err > 0) {
 +		head->in_hw_count = err;
 +		tcf_block_offload_inc(block, &head->flags);
  	}
  
  	if (skip_sw && !(head->flags & TCA_CLS_FLAGS_IN_HW))
@@@ -316,16 -311,14 +322,23 @@@ static int mall_reoffload(struct tcf_pr
  		return 0;
  	}
  
++<<<<<<< HEAD
 +	err = cb(TC_SETUP_CLSMATCHALL, &cls_mall, cb_priv);
++=======
+ 	err = tc_setup_cb_reoffload(block, tp, add, cb, TC_SETUP_CLSMATCHALL,
+ 				    &cls_mall, cb_priv, &head->flags,
+ 				    &head->in_hw_count);
+ 	tc_cleanup_flow_action(&cls_mall.rule->action);
++>>>>>>> f2b795ea025c (net: sched: cls_matchall: cleanup flow_action before deallocating)
  	kfree(cls_mall.rule);
  
 -	if (err)
 -		return err;
 +	if (err) {
 +		if (add && tc_skip_sw(head->flags))
 +			return err;
 +		return 0;
 +	}
 +
 +	tc_cls_offload_cnt_update(block, &head->in_hw_count, &head->flags, add);
  
  	return 0;
  }
* Unmerged path net/sched/cls_matchall.c
