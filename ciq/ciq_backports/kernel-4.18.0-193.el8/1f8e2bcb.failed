libbpf: Refactor relocation handling

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Andrii Nakryiko <andriin@fb.com>
commit 1f8e2bcb2cd5ee1a731fb625a5438e2c305f6a7c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/1f8e2bcb.failed

Relocation handling code is convoluted and unnecessarily deeply nested. Split
out per-relocation logic into separate function. Also refactor the logic to be
more a sequence of per-relocation type checks and processing steps, making it
simpler to follow control flow. This makes it easier to further extends it to
new kinds of relocations (e.g., support for extern variables).

This patch also makes relocation's section verification more robust.
Previously relocations against not yet supported externs were silently ignored
because of obj->efile.text_shndx was zero, when all BPF programs had custom
section names and there was no .text section. Also, invalid LDIMM64 relocations
against non-map sections were passed through, if they were pointing to a .text
section (or 0, which is invalid section). All these bugs are fixed within this
refactoring and checks are made more appropriate for each type of relocation.

	Signed-off-by: Andrii Nakryiko <andriin@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20191121070743.1309473-3-andriin@fb.com
(cherry picked from commit 1f8e2bcb2cd5ee1a731fb625a5438e2c305f6a7c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/lib/bpf/libbpf.c
diff --cc tools/lib/bpf/libbpf.c
index 0adc6e12ef11,4c3592c4ec5d..000000000000
--- a/tools/lib/bpf/libbpf.c
+++ b/tools/lib/bpf/libbpf.c
@@@ -1627,10 -1704,10 +1627,17 @@@ static int bpf_object__elf_collect(stru
  				continue;
  			}
  
++<<<<<<< HEAD
 +			reloc = reallocarray(reloc, nr_reloc + 1,
 +					     sizeof(*obj->efile.reloc));
 +			if (!reloc) {
 +				pr_warning("realloc failed\n");
++=======
+ 			sects = reallocarray(sects, nr_sects + 1,
+ 					     sizeof(*obj->efile.reloc_sects));
+ 			if (!sects) {
+ 				pr_warn("reloc_sects realloc failed\n");
++>>>>>>> 1f8e2bcb2cd5 (libbpf: Refactor relocation handling)
  				return -ENOMEM;
  			}
  
@@@ -1754,100 -1929,31 +1859,111 @@@ bpf_program__collect_reloc(struct bpf_p
  		GElf_Rel rel;
  
  		if (!gelf_getrel(data, i, &rel)) {
 -			pr_warn("relocation: failed to get %d reloc\n", i);
 +			pr_warning("relocation: failed to get %d reloc\n", i);
  			return -LIBBPF_ERRNO__FORMAT;
  		}
- 
  		if (!gelf_getsym(symbols, GELF_R_SYM(rel.r_info), &sym)) {
 -			pr_warn("relocation: symbol %"PRIx64" not found\n",
 -				GELF_R_SYM(rel.r_info));
 +			pr_warning("relocation: symbol %"PRIx64" not found\n",
 +				   GELF_R_SYM(rel.r_info));
  			return -LIBBPF_ERRNO__FORMAT;
  		}
+ 		if (rel.r_offset % sizeof(struct bpf_insn))
+ 			return -LIBBPF_ERRNO__FORMAT;
  
+ 		insn_idx = rel.r_offset / sizeof(struct bpf_insn);
  		name = elf_strptr(obj->efile.elf, obj->efile.strtabidx,
  				  sym.st_name) ? : "<?>";
  
- 		pr_debug("relo for %lld value %lld name %d (\'%s\')\n",
- 			 (long long) (rel.r_info >> 32),
- 			 (long long) sym.st_value, sym.st_name, name);
+ 		pr_debug("relo for shdr %u, symb %llu, value %llu, type %d, bind %d, name %d (\'%s\'), insn %u\n",
+ 			 (__u32)sym.st_shndx, (__u64)GELF_R_SYM(rel.r_info),
+ 			 (__u64)sym.st_value, GELF_ST_TYPE(sym.st_info),
+ 			 GELF_ST_BIND(sym.st_info), sym.st_name, name,
+ 			 insn_idx);
  
++<<<<<<< HEAD
 +		shdr_idx = sym.st_shndx;
 +		insn_idx = rel.r_offset / sizeof(struct bpf_insn);
 +		pr_debug("relocation: insn_idx=%u, shdr_idx=%u\n",
 +			 insn_idx, shdr_idx);
 +
 +		if (shdr_idx >= SHN_LORESERVE) {
 +			pr_warning("relocation: not yet supported relo for non-static global \'%s\' variable in special section (0x%x) found in insns[%d].code 0x%x\n",
 +				   name, shdr_idx, insn_idx,
 +				   insns[insn_idx].code);
 +			return -LIBBPF_ERRNO__RELOC;
 +		}
 +		if (!bpf_object__relo_in_known_section(obj, shdr_idx)) {
 +			pr_warning("Program '%s' contains unrecognized relo data pointing to section %u\n",
 +				   prog->section_name, shdr_idx);
 +			return -LIBBPF_ERRNO__RELOC;
 +		}
 +
 +		if (insns[insn_idx].code == (BPF_JMP | BPF_CALL)) {
 +			if (insns[insn_idx].src_reg != BPF_PSEUDO_CALL) {
 +				pr_warning("incorrect bpf_call opcode\n");
 +				return -LIBBPF_ERRNO__RELOC;
 +			}
 +			prog->reloc_desc[i].type = RELO_CALL;
 +			prog->reloc_desc[i].insn_idx = insn_idx;
 +			prog->reloc_desc[i].text_off = sym.st_value;
 +			obj->has_pseudo_calls = true;
 +			continue;
 +		}
 +
 +		if (insns[insn_idx].code != (BPF_LD | BPF_IMM | BPF_DW)) {
 +			pr_warning("bpf: relocation: invalid relo for insns[%d].code 0x%x\n",
 +				   insn_idx, insns[insn_idx].code);
 +			return -LIBBPF_ERRNO__RELOC;
 +		}
 +
 +		if (bpf_object__shndx_is_maps(obj, shdr_idx) ||
 +		    bpf_object__shndx_is_data(obj, shdr_idx)) {
 +			type = bpf_object__section_to_libbpf_map_type(obj, shdr_idx);
 +			if (type != LIBBPF_MAP_UNSPEC) {
 +				if (GELF_ST_BIND(sym.st_info) == STB_GLOBAL) {
 +					pr_warning("bpf: relocation: not yet supported relo for non-static global \'%s\' variable found in insns[%d].code 0x%x\n",
 +						   name, insn_idx, insns[insn_idx].code);
 +					return -LIBBPF_ERRNO__RELOC;
 +				}
 +				if (!obj->caps.global_data) {
 +					pr_warning("bpf: relocation: kernel does not support global \'%s\' variable access in insns[%d]\n",
 +						   name, insn_idx);
 +					return -LIBBPF_ERRNO__RELOC;
 +				}
 +			}
 +
 +			for (map_idx = 0; map_idx < nr_maps; map_idx++) {
 +				if (maps[map_idx].libbpf_type != type)
 +					continue;
 +				if (type != LIBBPF_MAP_UNSPEC ||
 +				    (maps[map_idx].sec_idx == sym.st_shndx &&
 +				     maps[map_idx].sec_offset == sym.st_value)) {
 +					pr_debug("relocation: found map %zd (%s, sec_idx %d, offset %zu) for insn %u\n",
 +						 map_idx, maps[map_idx].name,
 +						 maps[map_idx].sec_idx,
 +						 maps[map_idx].sec_offset,
 +						 insn_idx);
 +					break;
 +				}
 +			}
 +
 +			if (map_idx >= nr_maps) {
 +				pr_warning("bpf relocation: map_idx %d larger than %d\n",
 +					   (int)map_idx, (int)nr_maps - 1);
 +				return -LIBBPF_ERRNO__RELOC;
 +			}
 +
 +			prog->reloc_desc[i].type = type != LIBBPF_MAP_UNSPEC ?
 +						   RELO_DATA : RELO_LD64;
 +			prog->reloc_desc[i].insn_idx = insn_idx;
 +			prog->reloc_desc[i].map_idx = map_idx;
 +		}
++=======
+ 		err = bpf_program__record_reloc(prog, &prog->reloc_desc[i],
+ 						insn_idx, name, &sym, &rel);
+ 		if (err)
+ 			return err;
++>>>>>>> 1f8e2bcb2cd5 (libbpf: Refactor relocation handling)
  	}
  	return 0;
  }
@@@ -2411,39 -2672,1033 +2527,39 @@@ bpf_program__relocate(struct bpf_progra
  	return 0;
  }
  
 -static bool bpf_core_is_flavor_sep(const char *s)
 -{
 -	/* check X___Y name pattern, where X and Y are not underscores */
 -	return s[0] != '_' &&				      /* X */
 -	       s[1] == '_' && s[2] == '_' && s[3] == '_' &&   /* ___ */
 -	       s[4] != '_';				      /* Y */
 -}
  
 -/* Given 'some_struct_name___with_flavor' return the length of a name prefix
 - * before last triple underscore. Struct name part after last triple
 - * underscore is ignored by BPF CO-RE relocation during relocation matching.
 - */
 -static size_t bpf_core_essential_name_len(const char *name)
 +static int
 +bpf_object__relocate(struct bpf_object *obj)
  {
 -	size_t n = strlen(name);
 -	int i;
 -
 -	for (i = n - 5; i >= 0; i--) {
 -		if (bpf_core_is_flavor_sep(name + i))
 -			return i + 1;
 -	}
 -	return n;
 -}
 +	struct bpf_program *prog;
 +	size_t i;
 +	int err;
  
 -/* dynamically sized list of type IDs */
 -struct ids_vec {
 -	__u32 *data;
 -	int len;
 -};
 +	for (i = 0; i < obj->nr_programs; i++) {
 +		prog = &obj->programs[i];
  
 -static void bpf_core_free_cands(struct ids_vec *cand_ids)
 -{
 -	free(cand_ids->data);
 -	free(cand_ids);
 +		err = bpf_program__relocate(prog, obj);
 +		if (err) {
 +			pr_warning("failed to relocate '%s'\n",
 +				   prog->section_name);
 +			return err;
 +		}
 +	}
 +	return 0;
  }
  
 -static struct ids_vec *bpf_core_find_cands(const struct btf *local_btf,
 -					   __u32 local_type_id,
 -					   const struct btf *targ_btf)
 +static int bpf_object__collect_reloc(struct bpf_object *obj)
  {
 -	size_t local_essent_len, targ_essent_len;
 -	const char *local_name, *targ_name;
 -	const struct btf_type *t;
 -	struct ids_vec *cand_ids;
 -	__u32 *new_ids;
 -	int i, err, n;
 -
 -	t = btf__type_by_id(local_btf, local_type_id);
 -	if (!t)
 -		return ERR_PTR(-EINVAL);
 +	int i, err;
  
 -	local_name = btf__name_by_offset(local_btf, t->name_off);
 -	if (str_is_empty(local_name))
 -		return ERR_PTR(-EINVAL);
 -	local_essent_len = bpf_core_essential_name_len(local_name);
 -
 -	cand_ids = calloc(1, sizeof(*cand_ids));
 -	if (!cand_ids)
 -		return ERR_PTR(-ENOMEM);
 -
 -	n = btf__get_nr_types(targ_btf);
 -	for (i = 1; i <= n; i++) {
 -		t = btf__type_by_id(targ_btf, i);
 -		targ_name = btf__name_by_offset(targ_btf, t->name_off);
 -		if (str_is_empty(targ_name))
 -			continue;
 -
 -		targ_essent_len = bpf_core_essential_name_len(targ_name);
 -		if (targ_essent_len != local_essent_len)
 -			continue;
 -
 -		if (strncmp(local_name, targ_name, local_essent_len) == 0) {
 -			pr_debug("[%d] %s: found candidate [%d] %s\n",
 -				 local_type_id, local_name, i, targ_name);
 -			new_ids = realloc(cand_ids->data, cand_ids->len + 1);
 -			if (!new_ids) {
 -				err = -ENOMEM;
 -				goto err_out;
 -			}
 -			cand_ids->data = new_ids;
 -			cand_ids->data[cand_ids->len++] = i;
 -		}
 -	}
 -	return cand_ids;
 -err_out:
 -	bpf_core_free_cands(cand_ids);
 -	return ERR_PTR(err);
 -}
 -
 -/* Check two types for compatibility, skipping const/volatile/restrict and
 - * typedefs, to ensure we are relocating compatible entities:
 - *   - any two STRUCTs/UNIONs are compatible and can be mixed;
 - *   - any two FWDs are compatible, if their names match (modulo flavor suffix);
 - *   - any two PTRs are always compatible;
 - *   - for ENUMs, names should be the same (ignoring flavor suffix) or at
 - *     least one of enums should be anonymous;
 - *   - for ENUMs, check sizes, names are ignored;
 - *   - for INT, size and signedness are ignored;
 - *   - for ARRAY, dimensionality is ignored, element types are checked for
 - *     compatibility recursively;
 - *   - everything else shouldn't be ever a target of relocation.
 - * These rules are not set in stone and probably will be adjusted as we get
 - * more experience with using BPF CO-RE relocations.
 - */
 -static int bpf_core_fields_are_compat(const struct btf *local_btf,
 -				      __u32 local_id,
 -				      const struct btf *targ_btf,
 -				      __u32 targ_id)
 -{
 -	const struct btf_type *local_type, *targ_type;
 -
 -recur:
 -	local_type = skip_mods_and_typedefs(local_btf, local_id, &local_id);
 -	targ_type = skip_mods_and_typedefs(targ_btf, targ_id, &targ_id);
 -	if (!local_type || !targ_type)
 -		return -EINVAL;
 -
 -	if (btf_is_composite(local_type) && btf_is_composite(targ_type))
 -		return 1;
 -	if (btf_kind(local_type) != btf_kind(targ_type))
 -		return 0;
 -
 -	switch (btf_kind(local_type)) {
 -	case BTF_KIND_PTR:
 -		return 1;
 -	case BTF_KIND_FWD:
 -	case BTF_KIND_ENUM: {
 -		const char *local_name, *targ_name;
 -		size_t local_len, targ_len;
 -
 -		local_name = btf__name_by_offset(local_btf,
 -						 local_type->name_off);
 -		targ_name = btf__name_by_offset(targ_btf, targ_type->name_off);
 -		local_len = bpf_core_essential_name_len(local_name);
 -		targ_len = bpf_core_essential_name_len(targ_name);
 -		/* one of them is anonymous or both w/ same flavor-less names */
 -		return local_len == 0 || targ_len == 0 ||
 -		       (local_len == targ_len &&
 -			strncmp(local_name, targ_name, local_len) == 0);
 -	}
 -	case BTF_KIND_INT:
 -		/* just reject deprecated bitfield-like integers; all other
 -		 * integers are by default compatible between each other
 -		 */
 -		return btf_int_offset(local_type) == 0 &&
 -		       btf_int_offset(targ_type) == 0;
 -	case BTF_KIND_ARRAY:
 -		local_id = btf_array(local_type)->type;
 -		targ_id = btf_array(targ_type)->type;
 -		goto recur;
 -	default:
 -		pr_warn("unexpected kind %d relocated, local [%d], target [%d]\n",
 -			btf_kind(local_type), local_id, targ_id);
 -		return 0;
 -	}
 -}
 -
 -/*
 - * Given single high-level named field accessor in local type, find
 - * corresponding high-level accessor for a target type. Along the way,
 - * maintain low-level spec for target as well. Also keep updating target
 - * bit offset.
 - *
 - * Searching is performed through recursive exhaustive enumeration of all
 - * fields of a struct/union. If there are any anonymous (embedded)
 - * structs/unions, they are recursively searched as well. If field with
 - * desired name is found, check compatibility between local and target types,
 - * before returning result.
 - *
 - * 1 is returned, if field is found.
 - * 0 is returned if no compatible field is found.
 - * <0 is returned on error.
 - */
 -static int bpf_core_match_member(const struct btf *local_btf,
 -				 const struct bpf_core_accessor *local_acc,
 -				 const struct btf *targ_btf,
 -				 __u32 targ_id,
 -				 struct bpf_core_spec *spec,
 -				 __u32 *next_targ_id)
 -{
 -	const struct btf_type *local_type, *targ_type;
 -	const struct btf_member *local_member, *m;
 -	const char *local_name, *targ_name;
 -	__u32 local_id;
 -	int i, n, found;
 -
 -	targ_type = skip_mods_and_typedefs(targ_btf, targ_id, &targ_id);
 -	if (!targ_type)
 -		return -EINVAL;
 -	if (!btf_is_composite(targ_type))
 -		return 0;
 -
 -	local_id = local_acc->type_id;
 -	local_type = btf__type_by_id(local_btf, local_id);
 -	local_member = btf_members(local_type) + local_acc->idx;
 -	local_name = btf__name_by_offset(local_btf, local_member->name_off);
 -
 -	n = btf_vlen(targ_type);
 -	m = btf_members(targ_type);
 -	for (i = 0; i < n; i++, m++) {
 -		__u32 bit_offset;
 -
 -		bit_offset = btf_member_bit_offset(targ_type, i);
 -
 -		/* too deep struct/union/array nesting */
 -		if (spec->raw_len == BPF_CORE_SPEC_MAX_LEN)
 -			return -E2BIG;
 -
 -		/* speculate this member will be the good one */
 -		spec->bit_offset += bit_offset;
 -		spec->raw_spec[spec->raw_len++] = i;
 -
 -		targ_name = btf__name_by_offset(targ_btf, m->name_off);
 -		if (str_is_empty(targ_name)) {
 -			/* embedded struct/union, we need to go deeper */
 -			found = bpf_core_match_member(local_btf, local_acc,
 -						      targ_btf, m->type,
 -						      spec, next_targ_id);
 -			if (found) /* either found or error */
 -				return found;
 -		} else if (strcmp(local_name, targ_name) == 0) {
 -			/* matching named field */
 -			struct bpf_core_accessor *targ_acc;
 -
 -			targ_acc = &spec->spec[spec->len++];
 -			targ_acc->type_id = targ_id;
 -			targ_acc->idx = i;
 -			targ_acc->name = targ_name;
 -
 -			*next_targ_id = m->type;
 -			found = bpf_core_fields_are_compat(local_btf,
 -							   local_member->type,
 -							   targ_btf, m->type);
 -			if (!found)
 -				spec->len--; /* pop accessor */
 -			return found;
 -		}
 -		/* member turned out not to be what we looked for */
 -		spec->bit_offset -= bit_offset;
 -		spec->raw_len--;
 -	}
 -
 -	return 0;
 -}
 -
 -/*
 - * Try to match local spec to a target type and, if successful, produce full
 - * target spec (high-level, low-level + bit offset).
 - */
 -static int bpf_core_spec_match(struct bpf_core_spec *local_spec,
 -			       const struct btf *targ_btf, __u32 targ_id,
 -			       struct bpf_core_spec *targ_spec)
 -{
 -	const struct btf_type *targ_type;
 -	const struct bpf_core_accessor *local_acc;
 -	struct bpf_core_accessor *targ_acc;
 -	int i, sz, matched;
 -
 -	memset(targ_spec, 0, sizeof(*targ_spec));
 -	targ_spec->btf = targ_btf;
 -
 -	local_acc = &local_spec->spec[0];
 -	targ_acc = &targ_spec->spec[0];
 -
 -	for (i = 0; i < local_spec->len; i++, local_acc++, targ_acc++) {
 -		targ_type = skip_mods_and_typedefs(targ_spec->btf, targ_id,
 -						   &targ_id);
 -		if (!targ_type)
 -			return -EINVAL;
 -
 -		if (local_acc->name) {
 -			matched = bpf_core_match_member(local_spec->btf,
 -							local_acc,
 -							targ_btf, targ_id,
 -							targ_spec, &targ_id);
 -			if (matched <= 0)
 -				return matched;
 -		} else {
 -			/* for i=0, targ_id is already treated as array element
 -			 * type (because it's the original struct), for others
 -			 * we should find array element type first
 -			 */
 -			if (i > 0) {
 -				const struct btf_array *a;
 -
 -				if (!btf_is_array(targ_type))
 -					return 0;
 -
 -				a = btf_array(targ_type);
 -				if (local_acc->idx >= a->nelems)
 -					return 0;
 -				if (!skip_mods_and_typedefs(targ_btf, a->type,
 -							    &targ_id))
 -					return -EINVAL;
 -			}
 -
 -			/* too deep struct/union/array nesting */
 -			if (targ_spec->raw_len == BPF_CORE_SPEC_MAX_LEN)
 -				return -E2BIG;
 -
 -			targ_acc->type_id = targ_id;
 -			targ_acc->idx = local_acc->idx;
 -			targ_acc->name = NULL;
 -			targ_spec->len++;
 -			targ_spec->raw_spec[targ_spec->raw_len] = targ_acc->idx;
 -			targ_spec->raw_len++;
 -
 -			sz = btf__resolve_size(targ_btf, targ_id);
 -			if (sz < 0)
 -				return sz;
 -			targ_spec->bit_offset += local_acc->idx * sz * 8;
 -		}
 -	}
 -
 -	return 1;
 -}
 -
 -static int bpf_core_calc_field_relo(const struct bpf_program *prog,
 -				    const struct bpf_field_reloc *relo,
 -				    const struct bpf_core_spec *spec,
 -				    __u32 *val, bool *validate)
 -{
 -	const struct bpf_core_accessor *acc = &spec->spec[spec->len - 1];
 -	const struct btf_type *t = btf__type_by_id(spec->btf, acc->type_id);
 -	__u32 byte_off, byte_sz, bit_off, bit_sz;
 -	const struct btf_member *m;
 -	const struct btf_type *mt;
 -	bool bitfield;
 -	__s64 sz;
 -
 -	/* a[n] accessor needs special handling */
 -	if (!acc->name) {
 -		if (relo->kind == BPF_FIELD_BYTE_OFFSET) {
 -			*val = spec->bit_offset / 8;
 -		} else if (relo->kind == BPF_FIELD_BYTE_SIZE) {
 -			sz = btf__resolve_size(spec->btf, acc->type_id);
 -			if (sz < 0)
 -				return -EINVAL;
 -			*val = sz;
 -		} else {
 -			pr_warn("prog '%s': relo %d at insn #%d can't be applied to array access\n",
 -				bpf_program__title(prog, false),
 -				relo->kind, relo->insn_off / 8);
 -			return -EINVAL;
 -		}
 -		if (validate)
 -			*validate = true;
 -		return 0;
 -	}
 -
 -	m = btf_members(t) + acc->idx;
 -	mt = skip_mods_and_typedefs(spec->btf, m->type, NULL);
 -	bit_off = spec->bit_offset;
 -	bit_sz = btf_member_bitfield_size(t, acc->idx);
 -
 -	bitfield = bit_sz > 0;
 -	if (bitfield) {
 -		byte_sz = mt->size;
 -		byte_off = bit_off / 8 / byte_sz * byte_sz;
 -		/* figure out smallest int size necessary for bitfield load */
 -		while (bit_off + bit_sz - byte_off * 8 > byte_sz * 8) {
 -			if (byte_sz >= 8) {
 -				/* bitfield can't be read with 64-bit read */
 -				pr_warn("prog '%s': relo %d at insn #%d can't be satisfied for bitfield\n",
 -					bpf_program__title(prog, false),
 -					relo->kind, relo->insn_off / 8);
 -				return -E2BIG;
 -			}
 -			byte_sz *= 2;
 -			byte_off = bit_off / 8 / byte_sz * byte_sz;
 -		}
 -	} else {
 -		sz = btf__resolve_size(spec->btf, m->type);
 -		if (sz < 0)
 -			return -EINVAL;
 -		byte_sz = sz;
 -		byte_off = spec->bit_offset / 8;
 -		bit_sz = byte_sz * 8;
 -	}
 -
 -	/* for bitfields, all the relocatable aspects are ambiguous and we
 -	 * might disagree with compiler, so turn off validation of expected
 -	 * value, except for signedness
 -	 */
 -	if (validate)
 -		*validate = !bitfield;
 -
 -	switch (relo->kind) {
 -	case BPF_FIELD_BYTE_OFFSET:
 -		*val = byte_off;
 -		break;
 -	case BPF_FIELD_BYTE_SIZE:
 -		*val = byte_sz;
 -		break;
 -	case BPF_FIELD_SIGNED:
 -		/* enums will be assumed unsigned */
 -		*val = btf_is_enum(mt) ||
 -		       (btf_int_encoding(mt) & BTF_INT_SIGNED);
 -		if (validate)
 -			*validate = true; /* signedness is never ambiguous */
 -		break;
 -	case BPF_FIELD_LSHIFT_U64:
 -#if __BYTE_ORDER == __LITTLE_ENDIAN
 -		*val = 64 - (bit_off + bit_sz - byte_off  * 8);
 -#else
 -		*val = (8 - byte_sz) * 8 + (bit_off - byte_off * 8);
 -#endif
 -		break;
 -	case BPF_FIELD_RSHIFT_U64:
 -		*val = 64 - bit_sz;
 -		if (validate)
 -			*validate = true; /* right shift is never ambiguous */
 -		break;
 -	case BPF_FIELD_EXISTS:
 -	default:
 -		pr_warn("prog '%s': unknown relo %d at insn #%d\n",
 -			bpf_program__title(prog, false),
 -			relo->kind, relo->insn_off / 8);
 -		return -EINVAL;
 -	}
 -
 -	return 0;
 -}
 -
 -/*
 - * Patch relocatable BPF instruction.
 - *
 - * Patched value is determined by relocation kind and target specification.
 - * For field existence relocation target spec will be NULL if field is not
 - * found.
 - * Expected insn->imm value is determined using relocation kind and local
 - * spec, and is checked before patching instruction. If actual insn->imm value
 - * is wrong, bail out with error.
 - *
 - * Currently three kinds of BPF instructions are supported:
 - * 1. rX = <imm> (assignment with immediate operand);
 - * 2. rX += <imm> (arithmetic operations with immediate operand);
 - */
 -static int bpf_core_reloc_insn(struct bpf_program *prog,
 -			       const struct bpf_field_reloc *relo,
 -			       const struct bpf_core_spec *local_spec,
 -			       const struct bpf_core_spec *targ_spec)
 -{
 -	bool failed = false, validate = true;
 -	__u32 orig_val, new_val;
 -	struct bpf_insn *insn;
 -	int insn_idx, err;
 -	__u8 class;
 -
 -	if (relo->insn_off % sizeof(struct bpf_insn))
 -		return -EINVAL;
 -	insn_idx = relo->insn_off / sizeof(struct bpf_insn);
 -
 -	if (relo->kind == BPF_FIELD_EXISTS) {
 -		orig_val = 1; /* can't generate EXISTS relo w/o local field */
 -		new_val = targ_spec ? 1 : 0;
 -	} else if (!targ_spec) {
 -		failed = true;
 -		new_val = (__u32)-1;
 -	} else {
 -		err = bpf_core_calc_field_relo(prog, relo, local_spec,
 -					       &orig_val, &validate);
 -		if (err)
 -			return err;
 -		err = bpf_core_calc_field_relo(prog, relo, targ_spec,
 -					       &new_val, NULL);
 -		if (err)
 -			return err;
 -	}
 -
 -	insn = &prog->insns[insn_idx];
 -	class = BPF_CLASS(insn->code);
 -
 -	if (class == BPF_ALU || class == BPF_ALU64) {
 -		if (BPF_SRC(insn->code) != BPF_K)
 -			return -EINVAL;
 -		if (!failed && validate && insn->imm != orig_val) {
 -			pr_warn("prog '%s': unexpected insn #%d value: got %u, exp %u -> %u\n",
 -				bpf_program__title(prog, false), insn_idx,
 -				insn->imm, orig_val, new_val);
 -			return -EINVAL;
 -		}
 -		orig_val = insn->imm;
 -		insn->imm = new_val;
 -		pr_debug("prog '%s': patched insn #%d (ALU/ALU64)%s imm %u -> %u\n",
 -			 bpf_program__title(prog, false), insn_idx,
 -			 failed ? " w/ failed reloc" : "", orig_val, new_val);
 -	} else {
 -		pr_warn("prog '%s': trying to relocate unrecognized insn #%d, code:%x, src:%x, dst:%x, off:%x, imm:%x\n",
 -			bpf_program__title(prog, false),
 -			insn_idx, insn->code, insn->src_reg, insn->dst_reg,
 -			insn->off, insn->imm);
 -		return -EINVAL;
 -	}
 -
 -	return 0;
 -}
 -
 -static struct btf *btf_load_raw(const char *path)
 -{
 -	struct btf *btf;
 -	size_t read_cnt;
 -	struct stat st;
 -	void *data;
 -	FILE *f;
 -
 -	if (stat(path, &st))
 -		return ERR_PTR(-errno);
 -
 -	data = malloc(st.st_size);
 -	if (!data)
 -		return ERR_PTR(-ENOMEM);
 -
 -	f = fopen(path, "rb");
 -	if (!f) {
 -		btf = ERR_PTR(-errno);
 -		goto cleanup;
 -	}
 -
 -	read_cnt = fread(data, 1, st.st_size, f);
 -	fclose(f);
 -	if (read_cnt < st.st_size) {
 -		btf = ERR_PTR(-EBADF);
 -		goto cleanup;
 -	}
 -
 -	btf = btf__new(data, read_cnt);
 -
 -cleanup:
 -	free(data);
 -	return btf;
 -}
 -
 -/*
 - * Probe few well-known locations for vmlinux kernel image and try to load BTF
 - * data out of it to use for target BTF.
 - */
 -static struct btf *bpf_core_find_kernel_btf(void)
 -{
 -	struct {
 -		const char *path_fmt;
 -		bool raw_btf;
 -	} locations[] = {
 -		/* try canonical vmlinux BTF through sysfs first */
 -		{ "/sys/kernel/btf/vmlinux", true /* raw BTF */ },
 -		/* fall back to trying to find vmlinux ELF on disk otherwise */
 -		{ "/boot/vmlinux-%1$s" },
 -		{ "/lib/modules/%1$s/vmlinux-%1$s" },
 -		{ "/lib/modules/%1$s/build/vmlinux" },
 -		{ "/usr/lib/modules/%1$s/kernel/vmlinux" },
 -		{ "/usr/lib/debug/boot/vmlinux-%1$s" },
 -		{ "/usr/lib/debug/boot/vmlinux-%1$s.debug" },
 -		{ "/usr/lib/debug/lib/modules/%1$s/vmlinux" },
 -	};
 -	char path[PATH_MAX + 1];
 -	struct utsname buf;
 -	struct btf *btf;
 -	int i;
 -
 -	uname(&buf);
 -
 -	for (i = 0; i < ARRAY_SIZE(locations); i++) {
 -		snprintf(path, PATH_MAX, locations[i].path_fmt, buf.release);
 -
 -		if (access(path, R_OK))
 -			continue;
 -
 -		if (locations[i].raw_btf)
 -			btf = btf_load_raw(path);
 -		else
 -			btf = btf__parse_elf(path, NULL);
 -
 -		pr_debug("loading kernel BTF '%s': %ld\n",
 -			 path, IS_ERR(btf) ? PTR_ERR(btf) : 0);
 -		if (IS_ERR(btf))
 -			continue;
 -
 -		return btf;
 -	}
 -
 -	pr_warn("failed to find valid kernel BTF\n");
 -	return ERR_PTR(-ESRCH);
 -}
 -
 -/* Output spec definition in the format:
 - * [<type-id>] (<type-name>) + <raw-spec> => <offset>@<spec>,
 - * where <spec> is a C-syntax view of recorded field access, e.g.: x.a[3].b
 - */
 -static void bpf_core_dump_spec(int level, const struct bpf_core_spec *spec)
 -{
 -	const struct btf_type *t;
 -	const char *s;
 -	__u32 type_id;
 -	int i;
 -
 -	type_id = spec->spec[0].type_id;
 -	t = btf__type_by_id(spec->btf, type_id);
 -	s = btf__name_by_offset(spec->btf, t->name_off);
 -	libbpf_print(level, "[%u] %s + ", type_id, s);
 -
 -	for (i = 0; i < spec->raw_len; i++)
 -		libbpf_print(level, "%d%s", spec->raw_spec[i],
 -			     i == spec->raw_len - 1 ? " => " : ":");
 -
 -	libbpf_print(level, "%u.%u @ &x",
 -		     spec->bit_offset / 8, spec->bit_offset % 8);
 -
 -	for (i = 0; i < spec->len; i++) {
 -		if (spec->spec[i].name)
 -			libbpf_print(level, ".%s", spec->spec[i].name);
 -		else
 -			libbpf_print(level, "[%u]", spec->spec[i].idx);
 -	}
 -
 -}
 -
 -static size_t bpf_core_hash_fn(const void *key, void *ctx)
 -{
 -	return (size_t)key;
 -}
 -
 -static bool bpf_core_equal_fn(const void *k1, const void *k2, void *ctx)
 -{
 -	return k1 == k2;
 -}
 -
 -static void *u32_as_hash_key(__u32 x)
 -{
 -	return (void *)(uintptr_t)x;
 -}
 -
 -/*
 - * CO-RE relocate single instruction.
 - *
 - * The outline and important points of the algorithm:
 - * 1. For given local type, find corresponding candidate target types.
 - *    Candidate type is a type with the same "essential" name, ignoring
 - *    everything after last triple underscore (___). E.g., `sample`,
 - *    `sample___flavor_one`, `sample___flavor_another_one`, are all candidates
 - *    for each other. Names with triple underscore are referred to as
 - *    "flavors" and are useful, among other things, to allow to
 - *    specify/support incompatible variations of the same kernel struct, which
 - *    might differ between different kernel versions and/or build
 - *    configurations.
 - *
 - *    N.B. Struct "flavors" could be generated by bpftool's BTF-to-C
 - *    converter, when deduplicated BTF of a kernel still contains more than
 - *    one different types with the same name. In that case, ___2, ___3, etc
 - *    are appended starting from second name conflict. But start flavors are
 - *    also useful to be defined "locally", in BPF program, to extract same
 - *    data from incompatible changes between different kernel
 - *    versions/configurations. For instance, to handle field renames between
 - *    kernel versions, one can use two flavors of the struct name with the
 - *    same common name and use conditional relocations to extract that field,
 - *    depending on target kernel version.
 - * 2. For each candidate type, try to match local specification to this
 - *    candidate target type. Matching involves finding corresponding
 - *    high-level spec accessors, meaning that all named fields should match,
 - *    as well as all array accesses should be within the actual bounds. Also,
 - *    types should be compatible (see bpf_core_fields_are_compat for details).
 - * 3. It is supported and expected that there might be multiple flavors
 - *    matching the spec. As long as all the specs resolve to the same set of
 - *    offsets across all candidates, there is no error. If there is any
 - *    ambiguity, CO-RE relocation will fail. This is necessary to accomodate
 - *    imprefection of BTF deduplication, which can cause slight duplication of
 - *    the same BTF type, if some directly or indirectly referenced (by
 - *    pointer) type gets resolved to different actual types in different
 - *    object files. If such situation occurs, deduplicated BTF will end up
 - *    with two (or more) structurally identical types, which differ only in
 - *    types they refer to through pointer. This should be OK in most cases and
 - *    is not an error.
 - * 4. Candidate types search is performed by linearly scanning through all
 - *    types in target BTF. It is anticipated that this is overall more
 - *    efficient memory-wise and not significantly worse (if not better)
 - *    CPU-wise compared to prebuilding a map from all local type names to
 - *    a list of candidate type names. It's also sped up by caching resolved
 - *    list of matching candidates per each local "root" type ID, that has at
 - *    least one bpf_field_reloc associated with it. This list is shared
 - *    between multiple relocations for the same type ID and is updated as some
 - *    of the candidates are pruned due to structural incompatibility.
 - */
 -static int bpf_core_reloc_field(struct bpf_program *prog,
 -				 const struct bpf_field_reloc *relo,
 -				 int relo_idx,
 -				 const struct btf *local_btf,
 -				 const struct btf *targ_btf,
 -				 struct hashmap *cand_cache)
 -{
 -	const char *prog_name = bpf_program__title(prog, false);
 -	struct bpf_core_spec local_spec, cand_spec, targ_spec;
 -	const void *type_key = u32_as_hash_key(relo->type_id);
 -	const struct btf_type *local_type, *cand_type;
 -	const char *local_name, *cand_name;
 -	struct ids_vec *cand_ids;
 -	__u32 local_id, cand_id;
 -	const char *spec_str;
 -	int i, j, err;
 -
 -	local_id = relo->type_id;
 -	local_type = btf__type_by_id(local_btf, local_id);
 -	if (!local_type)
 -		return -EINVAL;
 -
 -	local_name = btf__name_by_offset(local_btf, local_type->name_off);
 -	if (str_is_empty(local_name))
 -		return -EINVAL;
 -
 -	spec_str = btf__name_by_offset(local_btf, relo->access_str_off);
 -	if (str_is_empty(spec_str))
 -		return -EINVAL;
 -
 -	err = bpf_core_spec_parse(local_btf, local_id, spec_str, &local_spec);
 -	if (err) {
 -		pr_warn("prog '%s': relo #%d: parsing [%d] %s + %s failed: %d\n",
 -			prog_name, relo_idx, local_id, local_name, spec_str,
 -			err);
 -		return -EINVAL;
 -	}
 -
 -	pr_debug("prog '%s': relo #%d: kind %d, spec is ", prog_name, relo_idx,
 -		 relo->kind);
 -	bpf_core_dump_spec(LIBBPF_DEBUG, &local_spec);
 -	libbpf_print(LIBBPF_DEBUG, "\n");
 -
 -	if (!hashmap__find(cand_cache, type_key, (void **)&cand_ids)) {
 -		cand_ids = bpf_core_find_cands(local_btf, local_id, targ_btf);
 -		if (IS_ERR(cand_ids)) {
 -			pr_warn("prog '%s': relo #%d: target candidate search failed for [%d] %s: %ld",
 -				prog_name, relo_idx, local_id, local_name,
 -				PTR_ERR(cand_ids));
 -			return PTR_ERR(cand_ids);
 -		}
 -		err = hashmap__set(cand_cache, type_key, cand_ids, NULL, NULL);
 -		if (err) {
 -			bpf_core_free_cands(cand_ids);
 -			return err;
 -		}
 -	}
 -
 -	for (i = 0, j = 0; i < cand_ids->len; i++) {
 -		cand_id = cand_ids->data[i];
 -		cand_type = btf__type_by_id(targ_btf, cand_id);
 -		cand_name = btf__name_by_offset(targ_btf, cand_type->name_off);
 -
 -		err = bpf_core_spec_match(&local_spec, targ_btf,
 -					  cand_id, &cand_spec);
 -		pr_debug("prog '%s': relo #%d: matching candidate #%d %s against spec ",
 -			 prog_name, relo_idx, i, cand_name);
 -		bpf_core_dump_spec(LIBBPF_DEBUG, &cand_spec);
 -		libbpf_print(LIBBPF_DEBUG, ": %d\n", err);
 -		if (err < 0) {
 -			pr_warn("prog '%s': relo #%d: matching error: %d\n",
 -				prog_name, relo_idx, err);
 -			return err;
 -		}
 -		if (err == 0)
 -			continue;
 -
 -		if (j == 0) {
 -			targ_spec = cand_spec;
 -		} else if (cand_spec.bit_offset != targ_spec.bit_offset) {
 -			/* if there are many candidates, they should all
 -			 * resolve to the same bit offset
 -			 */
 -			pr_warn("prog '%s': relo #%d: offset ambiguity: %u != %u\n",
 -				prog_name, relo_idx, cand_spec.bit_offset,
 -				targ_spec.bit_offset);
 -			return -EINVAL;
 -		}
 -
 -		cand_ids->data[j++] = cand_spec.spec[0].type_id;
 -	}
 -
 -	/*
 -	 * For BPF_FIELD_EXISTS relo or when relaxed CO-RE reloc mode is
 -	 * requested, it's expected that we might not find any candidates.
 -	 * In this case, if field wasn't found in any candidate, the list of
 -	 * candidates shouldn't change at all, we'll just handle relocating
 -	 * appropriately, depending on relo's kind.
 -	 */
 -	if (j > 0)
 -		cand_ids->len = j;
 -
 -	if (j == 0 && !prog->obj->relaxed_core_relocs &&
 -	    relo->kind != BPF_FIELD_EXISTS) {
 -		pr_warn("prog '%s': relo #%d: no matching targets found for [%d] %s + %s\n",
 -			prog_name, relo_idx, local_id, local_name, spec_str);
 -		return -ESRCH;
 -	}
 -
 -	/* bpf_core_reloc_insn should know how to handle missing targ_spec */
 -	err = bpf_core_reloc_insn(prog, relo, &local_spec,
 -				  j ? &targ_spec : NULL);
 -	if (err) {
 -		pr_warn("prog '%s': relo #%d: failed to patch insn at offset %d: %d\n",
 -			prog_name, relo_idx, relo->insn_off, err);
 -		return -EINVAL;
 -	}
 -
 -	return 0;
 -}
 -
 -static int
 -bpf_core_reloc_fields(struct bpf_object *obj, const char *targ_btf_path)
 -{
 -	const struct btf_ext_info_sec *sec;
 -	const struct bpf_field_reloc *rec;
 -	const struct btf_ext_info *seg;
 -	struct hashmap_entry *entry;
 -	struct hashmap *cand_cache = NULL;
 -	struct bpf_program *prog;
 -	struct btf *targ_btf;
 -	const char *sec_name;
 -	int i, err = 0;
 -
 -	if (targ_btf_path)
 -		targ_btf = btf__parse_elf(targ_btf_path, NULL);
 -	else
 -		targ_btf = bpf_core_find_kernel_btf();
 -	if (IS_ERR(targ_btf)) {
 -		pr_warn("failed to get target BTF: %ld\n", PTR_ERR(targ_btf));
 -		return PTR_ERR(targ_btf);
 -	}
 -
 -	cand_cache = hashmap__new(bpf_core_hash_fn, bpf_core_equal_fn, NULL);
 -	if (IS_ERR(cand_cache)) {
 -		err = PTR_ERR(cand_cache);
 -		goto out;
 -	}
 -
 -	seg = &obj->btf_ext->field_reloc_info;
 -	for_each_btf_ext_sec(seg, sec) {
 -		sec_name = btf__name_by_offset(obj->btf, sec->sec_name_off);
 -		if (str_is_empty(sec_name)) {
 -			err = -EINVAL;
 -			goto out;
 -		}
 -		prog = bpf_object__find_program_by_title(obj, sec_name);
 -		if (!prog) {
 -			pr_warn("failed to find program '%s' for CO-RE offset relocation\n",
 -				sec_name);
 -			err = -EINVAL;
 -			goto out;
 -		}
 -
 -		pr_debug("prog '%s': performing %d CO-RE offset relocs\n",
 -			 sec_name, sec->num_info);
 -
 -		for_each_btf_ext_rec(seg, sec, i, rec) {
 -			err = bpf_core_reloc_field(prog, rec, i, obj->btf,
 -						   targ_btf, cand_cache);
 -			if (err) {
 -				pr_warn("prog '%s': relo #%d: failed to relocate: %d\n",
 -					sec_name, i, err);
 -				goto out;
 -			}
 -		}
 -	}
 -
 -out:
 -	btf__free(targ_btf);
 -	if (!IS_ERR_OR_NULL(cand_cache)) {
 -		hashmap__for_each_entry(cand_cache, entry, i) {
 -			bpf_core_free_cands(entry->value);
 -		}
 -		hashmap__free(cand_cache);
 -	}
 -	return err;
 -}
 -
 -static int
 -bpf_object__relocate_core(struct bpf_object *obj, const char *targ_btf_path)
 -{
 -	int err = 0;
 -
 -	if (obj->btf_ext->field_reloc_info.len)
 -		err = bpf_core_reloc_fields(obj, targ_btf_path);
 -
 -	return err;
 -}
 -
 -static int
 -bpf_program__reloc_text(struct bpf_program *prog, struct bpf_object *obj,
 -			struct reloc_desc *relo)
 -{
 -	struct bpf_insn *insn, *new_insn;
 -	struct bpf_program *text;
 -	size_t new_cnt;
 -	int err;
 -
 -	if (relo->type != RELO_CALL)
 -		return -LIBBPF_ERRNO__RELOC;
 -
 -	if (prog->idx == obj->efile.text_shndx) {
 -		pr_warn("relo in .text insn %d into off %d\n",
 -			relo->insn_idx, relo->text_off);
 -		return -LIBBPF_ERRNO__RELOC;
 -	}
 -
 -	if (prog->main_prog_cnt == 0) {
 -		text = bpf_object__find_prog_by_idx(obj, obj->efile.text_shndx);
 -		if (!text) {
 -			pr_warn("no .text section found yet relo into text exist\n");
 -			return -LIBBPF_ERRNO__RELOC;
 -		}
 -		new_cnt = prog->insns_cnt + text->insns_cnt;
 -		new_insn = reallocarray(prog->insns, new_cnt, sizeof(*insn));
 -		if (!new_insn) {
 -			pr_warn("oom in prog realloc\n");
 -			return -ENOMEM;
 -		}
 -		prog->insns = new_insn;
 -
 -		if (obj->btf_ext) {
 -			err = bpf_program_reloc_btf_ext(prog, obj,
 -							text->section_name,
 -							prog->insns_cnt);
 -			if (err)
 -				return err;
 -		}
 -
 -		memcpy(new_insn + prog->insns_cnt, text->insns,
 -		       text->insns_cnt * sizeof(*insn));
 -		prog->main_prog_cnt = prog->insns_cnt;
 -		prog->insns_cnt = new_cnt;
 -		pr_debug("added %zd insn from %s to prog %s\n",
 -			 text->insns_cnt, text->section_name,
 -			 prog->section_name);
 -	}
 -	insn = &prog->insns[relo->insn_idx];
 -	insn->imm += relo->text_off + prog->main_prog_cnt - relo->insn_idx;
 -	return 0;
 -}
 -
 -static int
 -bpf_program__relocate(struct bpf_program *prog, struct bpf_object *obj)
 -{
 -	int i, err;
 -
 -	if (!prog)
 -		return 0;
 -
 -	if (obj->btf_ext) {
 -		err = bpf_program_reloc_btf_ext(prog, obj,
 -						prog->section_name, 0);
 -		if (err)
 -			return err;
 -	}
 -
 -	if (!prog->reloc_desc)
 -		return 0;
 -
 -	for (i = 0; i < prog->nr_reloc; i++) {
 -		if (prog->reloc_desc[i].type == RELO_LD64 ||
 -		    prog->reloc_desc[i].type == RELO_DATA) {
 -			bool relo_data = prog->reloc_desc[i].type == RELO_DATA;
 -			struct bpf_insn *insns = prog->insns;
 -			int insn_idx, map_idx;
 -
 -			insn_idx = prog->reloc_desc[i].insn_idx;
 -			map_idx = prog->reloc_desc[i].map_idx;
 -
 -			if (insn_idx + 1 >= (int)prog->insns_cnt) {
 -				pr_warn("relocation out of range: '%s'\n",
 -					prog->section_name);
 -				return -LIBBPF_ERRNO__RELOC;
 -			}
 -
 -			if (!relo_data) {
 -				insns[insn_idx].src_reg = BPF_PSEUDO_MAP_FD;
 -			} else {
 -				insns[insn_idx].src_reg = BPF_PSEUDO_MAP_VALUE;
 -				insns[insn_idx + 1].imm = insns[insn_idx].imm;
 -			}
 -			insns[insn_idx].imm = obj->maps[map_idx].fd;
 -		} else if (prog->reloc_desc[i].type == RELO_CALL) {
 -			err = bpf_program__reloc_text(prog, obj,
 -						      &prog->reloc_desc[i]);
 -			if (err)
 -				return err;
 -		}
 -	}
 -
 -	zfree(&prog->reloc_desc);
 -	prog->nr_reloc = 0;
 -	return 0;
 -}
 -
 -static int
 -bpf_object__relocate(struct bpf_object *obj, const char *targ_btf_path)
 -{
 -	struct bpf_program *prog;
 -	size_t i;
 -	int err;
 -
 -	if (obj->btf_ext) {
 -		err = bpf_object__relocate_core(obj, targ_btf_path);
 -		if (err) {
 -			pr_warn("failed to perform CO-RE relocations: %d\n",
 -				err);
 -			return err;
 -		}
 -	}
 -	for (i = 0; i < obj->nr_programs; i++) {
 -		prog = &obj->programs[i];
 -
 -		err = bpf_program__relocate(prog, obj);
 -		if (err) {
 -			pr_warn("failed to relocate '%s'\n", prog->section_name);
 -			return err;
 -		}
 -	}
 -	return 0;
 -}
 -
 -static int bpf_object__collect_reloc(struct bpf_object *obj)
 -{
 -	int i, err;
 -
 -	if (!obj_elf_valid(obj)) {
 -		pr_warn("Internal error: elf object is closed\n");
 -		return -LIBBPF_ERRNO__INTERNAL;
 -	}
 +	if (!obj_elf_valid(obj)) {
 +		pr_warning("Internal error: elf object is closed\n");
 +		return -LIBBPF_ERRNO__INTERNAL;
 +	}
  
- 	for (i = 0; i < obj->efile.nr_reloc; i++) {
- 		GElf_Shdr *shdr = &obj->efile.reloc[i].shdr;
- 		Elf_Data *data = obj->efile.reloc[i].data;
+ 	for (i = 0; i < obj->efile.nr_reloc_sects; i++) {
+ 		GElf_Shdr *shdr = &obj->efile.reloc_sects[i].shdr;
+ 		Elf_Data *data = obj->efile.reloc_sects[i].data;
  		int idx = shdr->sh_info;
  		struct bpf_program *prog;
  
* Unmerged path tools/lib/bpf/libbpf.c
