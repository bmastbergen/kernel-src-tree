RDMA/core: Do not invoke init_port on compat devices

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Parav Pandit <parav@mellanox.com>
commit eb15c78b05bd9fbac45ee5b56aaf29b2570b5238
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/eb15c78b.failed

The driver interface cannot manipulate the sysfs of the compat device,
only of the full device so we must avoid calling the driver sysfs APIs on
compat devices.

This prevents an oops:

 Call Trace:
 dump_stack+0x5a/0x73
 kobject_init+0x74/0x80
 kobject_init_and_add+0x35/0xb0
 hfi1_create_port_files+0x6e/0x3c0 [hfi1]
 ib_setup_port_attrs+0x43b/0x560 [ib_core]
 add_one_compat_dev+0x16a/0x230 [ib_core]
 rdma_dev_init_net+0x110/0x160 [ib_core]
 ops_init+0x38/0xf0
 setup_net+0xcf/0x1e0
 copy_net_ns+0xb7/0x130
 create_new_namespaces+0x11a/0x1b0
 unshare_nsproxy_namespaces+0x55/0xa0
 ksys_unshare+0x1a7/0x340
 __x64_sys_unshare+0xe/0x20
 do_syscall_64+0x5b/0x180
 entry_SYSCALL_64_after_hwframe+0x44/0xa9

Fixes: 5417783eabb2 ("RDMA/core: Support core port attributes in non init_net")
	Reported-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
	Tested-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
	Signed-off-by: Parav Pandit <parav@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit eb15c78b05bd9fbac45ee5b56aaf29b2570b5238)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/core_priv.h
#	drivers/infiniband/core/device.c
#	drivers/infiniband/core/sysfs.c
diff --cc drivers/infiniband/core/core_priv.h
index 65f189ee6a3d,ff40a450b5d2..000000000000
--- a/drivers/infiniband/core/core_priv.h
+++ b/drivers/infiniband/core/core_priv.h
@@@ -327,4 -339,17 +327,20 @@@ int roce_resolve_route_from_path(struc
  				 const struct ib_gid_attr *attr);
  
  struct net_device *rdma_read_gid_attr_ndev_rcu(const struct ib_gid_attr *attr);
++<<<<<<< HEAD
++=======
+ 
+ void ib_free_port_attrs(struct ib_core_device *coredev);
+ int ib_setup_port_attrs(struct ib_core_device *coredev);
+ 
+ int rdma_compatdev_set(u8 enable);
+ 
+ int ib_port_register_module_stat(struct ib_device *device, u8 port_num,
+ 				 struct kobject *kobj, struct kobj_type *ktype,
+ 				 const char *name);
+ void ib_port_unregister_module_stat(struct kobject *kobj);
+ 
+ int ib_device_set_netns_put(struct sk_buff *skb,
+ 			    struct ib_device *dev, u32 ns_fd);
++>>>>>>> eb15c78b05bd (RDMA/core: Do not invoke init_port on compat devices)
  #endif /* _CORE_PRIV_H */
diff --cc drivers/infiniband/core/device.c
index ec96a7b1c811,2123cc693a29..000000000000
--- a/drivers/infiniband/core/device.c
+++ b/drivers/infiniband/core/device.c
@@@ -469,28 -815,315 +469,311 @@@ static int ib_security_change(struct no
  	return NOTIFY_OK;
  }
  
++<<<<<<< HEAD
 +/**
 + *	__dev_new_index	-	allocate an device index
 + *
 + *	Returns a suitable unique value for a new device interface
 + *	number.  It assumes that there are less than 2^32-1 ib devices
 + *	will be present in the system.
++=======
+ static void compatdev_release(struct device *dev)
+ {
+ 	struct ib_core_device *cdev =
+ 		container_of(dev, struct ib_core_device, dev);
+ 
+ 	kfree(cdev);
+ }
+ 
+ static int add_one_compat_dev(struct ib_device *device,
+ 			      struct rdma_dev_net *rnet)
+ {
+ 	struct ib_core_device *cdev;
+ 	int ret;
+ 
+ 	lockdep_assert_held(&rdma_nets_rwsem);
+ 	if (!ib_devices_shared_netns)
+ 		return 0;
+ 
+ 	/*
+ 	 * Create and add compat device in all namespaces other than where it
+ 	 * is currently bound to.
+ 	 */
+ 	if (net_eq(read_pnet(&rnet->net),
+ 		   read_pnet(&device->coredev.rdma_net)))
+ 		return 0;
+ 
+ 	/*
+ 	 * The first of init_net() or ib_register_device() to take the
+ 	 * compat_devs_mutex wins and gets to add the device. Others will wait
+ 	 * for completion here.
+ 	 */
+ 	mutex_lock(&device->compat_devs_mutex);
+ 	cdev = xa_load(&device->compat_devs, rnet->id);
+ 	if (cdev) {
+ 		ret = 0;
+ 		goto done;
+ 	}
+ 	ret = xa_reserve(&device->compat_devs, rnet->id, GFP_KERNEL);
+ 	if (ret)
+ 		goto done;
+ 
+ 	cdev = kzalloc(sizeof(*cdev), GFP_KERNEL);
+ 	if (!cdev) {
+ 		ret = -ENOMEM;
+ 		goto cdev_err;
+ 	}
+ 
+ 	cdev->dev.parent = device->dev.parent;
+ 	rdma_init_coredev(cdev, device, read_pnet(&rnet->net));
+ 	cdev->dev.release = compatdev_release;
+ 	dev_set_name(&cdev->dev, "%s", dev_name(&device->dev));
+ 
+ 	ret = device_add(&cdev->dev);
+ 	if (ret)
+ 		goto add_err;
+ 	ret = ib_setup_port_attrs(cdev);
+ 	if (ret)
+ 		goto port_err;
+ 
+ 	ret = xa_err(xa_store(&device->compat_devs, rnet->id,
+ 			      cdev, GFP_KERNEL));
+ 	if (ret)
+ 		goto insert_err;
+ 
+ 	mutex_unlock(&device->compat_devs_mutex);
+ 	return 0;
+ 
+ insert_err:
+ 	ib_free_port_attrs(cdev);
+ port_err:
+ 	device_del(&cdev->dev);
+ add_err:
+ 	put_device(&cdev->dev);
+ cdev_err:
+ 	xa_release(&device->compat_devs, rnet->id);
+ done:
+ 	mutex_unlock(&device->compat_devs_mutex);
+ 	return ret;
+ }
+ 
+ static void remove_one_compat_dev(struct ib_device *device, u32 id)
+ {
+ 	struct ib_core_device *cdev;
+ 
+ 	mutex_lock(&device->compat_devs_mutex);
+ 	cdev = xa_erase(&device->compat_devs, id);
+ 	mutex_unlock(&device->compat_devs_mutex);
+ 	if (cdev) {
+ 		ib_free_port_attrs(cdev);
+ 		device_del(&cdev->dev);
+ 		put_device(&cdev->dev);
+ 	}
+ }
+ 
+ static void remove_compat_devs(struct ib_device *device)
+ {
+ 	struct ib_core_device *cdev;
+ 	unsigned long index;
+ 
+ 	xa_for_each (&device->compat_devs, index, cdev)
+ 		remove_one_compat_dev(device, index);
+ }
+ 
+ static int add_compat_devs(struct ib_device *device)
+ {
+ 	struct rdma_dev_net *rnet;
+ 	unsigned long index;
+ 	int ret = 0;
+ 
+ 	lockdep_assert_held(&devices_rwsem);
+ 
+ 	down_read(&rdma_nets_rwsem);
+ 	xa_for_each (&rdma_nets, index, rnet) {
+ 		ret = add_one_compat_dev(device, rnet);
+ 		if (ret)
+ 			break;
+ 	}
+ 	up_read(&rdma_nets_rwsem);
+ 	return ret;
+ }
+ 
+ static void remove_all_compat_devs(void)
+ {
+ 	struct ib_compat_device *cdev;
+ 	struct ib_device *dev;
+ 	unsigned long index;
+ 
+ 	down_read(&devices_rwsem);
+ 	xa_for_each (&devices, index, dev) {
+ 		unsigned long c_index = 0;
+ 
+ 		/* Hold nets_rwsem so that any other thread modifying this
+ 		 * system param can sync with this thread.
+ 		 */
+ 		down_read(&rdma_nets_rwsem);
+ 		xa_for_each (&dev->compat_devs, c_index, cdev)
+ 			remove_one_compat_dev(dev, c_index);
+ 		up_read(&rdma_nets_rwsem);
+ 	}
+ 	up_read(&devices_rwsem);
+ }
+ 
+ static int add_all_compat_devs(void)
+ {
+ 	struct rdma_dev_net *rnet;
+ 	struct ib_device *dev;
+ 	unsigned long index;
+ 	int ret = 0;
+ 
+ 	down_read(&devices_rwsem);
+ 	xa_for_each_marked (&devices, index, dev, DEVICE_REGISTERED) {
+ 		unsigned long net_index = 0;
+ 
+ 		/* Hold nets_rwsem so that any other thread modifying this
+ 		 * system param can sync with this thread.
+ 		 */
+ 		down_read(&rdma_nets_rwsem);
+ 		xa_for_each (&rdma_nets, net_index, rnet) {
+ 			ret = add_one_compat_dev(dev, rnet);
+ 			if (ret)
+ 				break;
+ 		}
+ 		up_read(&rdma_nets_rwsem);
+ 	}
+ 	up_read(&devices_rwsem);
+ 	if (ret)
+ 		remove_all_compat_devs();
+ 	return ret;
+ }
+ 
+ int rdma_compatdev_set(u8 enable)
+ {
+ 	struct rdma_dev_net *rnet;
+ 	unsigned long index;
+ 	int ret = 0;
+ 
+ 	down_write(&rdma_nets_rwsem);
+ 	if (ib_devices_shared_netns == enable) {
+ 		up_write(&rdma_nets_rwsem);
+ 		return 0;
+ 	}
+ 
+ 	/* enable/disable of compat devices is not supported
+ 	 * when more than default init_net exists.
+ 	 */
+ 	xa_for_each (&rdma_nets, index, rnet) {
+ 		ret++;
+ 		break;
+ 	}
+ 	if (!ret)
+ 		ib_devices_shared_netns = enable;
+ 	up_write(&rdma_nets_rwsem);
+ 	if (ret)
+ 		return -EBUSY;
+ 
+ 	if (enable)
+ 		ret = add_all_compat_devs();
+ 	else
+ 		remove_all_compat_devs();
+ 	return ret;
+ }
+ 
+ static void rdma_dev_exit_net(struct net *net)
+ {
+ 	struct rdma_dev_net *rnet = net_generic(net, rdma_dev_net_id);
+ 	struct ib_device *dev;
+ 	unsigned long index;
+ 	int ret;
+ 
+ 	down_write(&rdma_nets_rwsem);
+ 	/*
+ 	 * Prevent the ID from being re-used and hide the id from xa_for_each.
+ 	 */
+ 	ret = xa_err(xa_store(&rdma_nets, rnet->id, NULL, GFP_KERNEL));
+ 	WARN_ON(ret);
+ 	up_write(&rdma_nets_rwsem);
+ 
+ 	down_read(&devices_rwsem);
+ 	xa_for_each (&devices, index, dev) {
+ 		get_device(&dev->dev);
+ 		/*
+ 		 * Release the devices_rwsem so that pontentially blocking
+ 		 * device_del, doesn't hold the devices_rwsem for too long.
+ 		 */
+ 		up_read(&devices_rwsem);
+ 
+ 		remove_one_compat_dev(dev, rnet->id);
+ 
+ 		/*
+ 		 * If the real device is in the NS then move it back to init.
+ 		 */
+ 		rdma_dev_change_netns(dev, net, &init_net);
+ 
+ 		put_device(&dev->dev);
+ 		down_read(&devices_rwsem);
+ 	}
+ 	up_read(&devices_rwsem);
+ 
+ 	xa_erase(&rdma_nets, rnet->id);
+ }
+ 
+ static __net_init int rdma_dev_init_net(struct net *net)
+ {
+ 	struct rdma_dev_net *rnet = net_generic(net, rdma_dev_net_id);
+ 	unsigned long index;
+ 	struct ib_device *dev;
+ 	int ret;
+ 
+ 	/* No need to create any compat devices in default init_net. */
+ 	if (net_eq(net, &init_net))
+ 		return 0;
+ 
+ 	write_pnet(&rnet->net, net);
+ 
+ 	ret = xa_alloc(&rdma_nets, &rnet->id, rnet, xa_limit_32b, GFP_KERNEL);
+ 	if (ret)
+ 		return ret;
+ 
+ 	down_read(&devices_rwsem);
+ 	xa_for_each_marked (&devices, index, dev, DEVICE_REGISTERED) {
+ 		/* Hold nets_rwsem so that netlink command cannot change
+ 		 * system configuration for device sharing mode.
+ 		 */
+ 		down_read(&rdma_nets_rwsem);
+ 		ret = add_one_compat_dev(dev, rnet);
+ 		up_read(&rdma_nets_rwsem);
+ 		if (ret)
+ 			break;
+ 	}
+ 	up_read(&devices_rwsem);
+ 
+ 	if (ret)
+ 		rdma_dev_exit_net(net);
+ 
+ 	return ret;
+ }
+ 
+ /*
+  * Assign the unique string device name and the unique device index. This is
+  * undone by ib_dealloc_device.
++>>>>>>> eb15c78b05bd (RDMA/core: Do not invoke init_port on compat devices)
   */
 -static int assign_name(struct ib_device *device, const char *name)
 +static u32 __dev_new_index(void)
  {
 -	static u32 last_id;
 -	int ret;
 +	/*
 +	 * The device index to allow stable naming.
 +	 * Similar to struct net -> ifindex.
 +	 */
 +	static u32 index;
  
 -	down_write(&devices_rwsem);
 -	/* Assign a unique name to the device */
 -	if (strchr(name, '%'))
 -		ret = alloc_name(device, name);
 -	else
 -		ret = dev_set_name(&device->dev, name);
 -	if (ret)
 -		goto out;
 +	for (;;) {
 +		if (!(++index))
 +			index = 1;
  
 -	if (__ib_device_get_by_name(dev_name(&device->dev))) {
 -		ret = -ENFILE;
 -		goto out;
 +		if (!__ib_device_get_by_index(index))
 +			return index;
  	}
 -	strlcpy(device->name, dev_name(&device->dev), IB_DEVICE_NAME_MAX);
 -
 -	ret = xa_alloc_cyclic(&devices, &device->index, device, xa_limit_31b,
 -			&last_id, GFP_KERNEL);
 -	if (ret > 0)
 -		ret = 0;
 -
 -out:
 -	up_write(&devices_rwsem);
 -	return ret;
  }
  
  static void setup_dma_device(struct ib_device *device)
diff --cc drivers/infiniband/core/sysfs.c
index 7e51b406e89a,7a599c5e455f..000000000000
--- a/drivers/infiniband/core/sysfs.c
+++ b/drivers/infiniband/core/sysfs.c
@@@ -1015,8 -1015,10 +1015,15 @@@ err_free_stats
  	return;
  }
  
++<<<<<<< HEAD
 +static int add_port(struct ib_device *device, int port_num)
 +{
++=======
+ static int add_port(struct ib_core_device *coredev, int port_num)
+ {
+ 	struct ib_device *device = rdma_device_to_ibdev(&coredev->dev);
+ 	bool is_full_dev = &device->coredev == coredev;
++>>>>>>> eb15c78b05bd (RDMA/core: Do not invoke init_port on compat devices)
  	struct ib_port *p;
  	struct ib_port_attr attr;
  	int i;
@@@ -1055,7 -1057,7 +1062,11 @@@
  		goto err_put;
  	}
  
++<<<<<<< HEAD
 +	if (device->ops.process_mad) {
++=======
+ 	if (device->ops.process_mad && is_full_dev) {
++>>>>>>> eb15c78b05bd (RDMA/core: Do not invoke init_port on compat devices)
  		p->pma_table = get_counter_table(device, port_num);
  		ret = sysfs_create_group(&p->kobj, p->pma_table);
  		if (ret)
@@@ -1122,10 -1124,10 +1133,14 @@@
  	 * port, so holder should be device. Therefore skip per port conunter
  	 * initialization.
  	 */
++<<<<<<< HEAD
 +	if (device->ops.alloc_hw_stats && port_num)
++=======
+ 	if (device->ops.alloc_hw_stats && port_num && is_full_dev)
++>>>>>>> eb15c78b05bd (RDMA/core: Do not invoke init_port on compat devices)
  		setup_hw_stats(device, p, port_num);
  
 -	list_add_tail(&p->kobj.entry, &coredev->port_list);
 +	list_add_tail(&p->kobj.entry, &device->port_list);
  
  	kobject_uevent(&p->kobj, KOBJ_ADD);
  	return 0;
@@@ -1303,28 -1305,24 +1318,37 @@@ static void ib_free_port_attrs(struct i
  		kobject_put(p);
  	}
  
 -	kobject_put(coredev->ports_kobj);
 +	kobject_put(device->ports_kobj);
  }
  
++<<<<<<< HEAD
 +static int ib_setup_port_attrs(struct ib_device *device)
++=======
+ int ib_setup_port_attrs(struct ib_core_device *coredev)
++>>>>>>> eb15c78b05bd (RDMA/core: Do not invoke init_port on compat devices)
  {
 -	struct ib_device *device = rdma_device_to_ibdev(&coredev->dev);
 -	unsigned int port;
  	int ret;
 +	int i;
  
 -	coredev->ports_kobj = kobject_create_and_add("ports",
 -						     &coredev->dev.kobj);
 -	if (!coredev->ports_kobj)
 +	device->ports_kobj = kobject_create_and_add("ports", &device->dev.kobj);
 +	if (!device->ports_kobj)
  		return -ENOMEM;
  
++<<<<<<< HEAD
 +	if (rdma_cap_ib_switch(device)) {
 +		ret = add_port(device, 0);
++=======
+ 	rdma_for_each_port (device, port) {
+ 		ret = add_port(coredev, port);
++>>>>>>> eb15c78b05bd (RDMA/core: Do not invoke init_port on compat devices)
  		if (ret)
  			goto err_put;
 +	} else {
 +		for (i = 1; i <= device->phys_port_cnt; ++i) {
 +			ret = add_port(device, i);
 +			if (ret)
 +				goto err_put;
 +		}
  	}
  
  	return 0;
@@@ -1338,10 -1336,7 +1362,14 @@@ int ib_device_register_sysfs(struct ib_
  {
  	int ret;
  
++<<<<<<< HEAD
 +	device->groups[0] = &dev_attr_group;
 +	device->dev.groups = device->groups;
 +
 +	ret = device_add(&device->dev);
++=======
+ 	ret = ib_setup_port_attrs(&device->coredev);
++>>>>>>> eb15c78b05bd (RDMA/core: Do not invoke init_port on compat devices)
  	if (ret)
  		return ret;
  
* Unmerged path drivers/infiniband/core/core_priv.h
* Unmerged path drivers/infiniband/core/device.c
* Unmerged path drivers/infiniband/core/sysfs.c
