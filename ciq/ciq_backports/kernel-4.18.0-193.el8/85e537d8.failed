s390/qeth: when in TX NAPI mode, use napi_consume_skb()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Julian Wiedmann <jwi@linux.ibm.com>
commit 85e537d8f1b6b1201ced628b124b3d08436f5a04
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/85e537d8.failed

This allows the stack to bulk-free our TX-completed skbs.

	Signed-off-by: Julian Wiedmann <jwi@linux.ibm.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 85e537d8f1b6b1201ced628b124b3d08436f5a04)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/s390/net/qeth_core_main.c
diff --cc drivers/s390/net/qeth_core_main.c
index a0c5702815af,70c7e675431e..000000000000
--- a/drivers/s390/net/qeth_core_main.c
+++ b/drivers/s390/net/qeth_core_main.c
@@@ -70,16 -71,10 +70,21 @@@ static void qeth_free_qdio_queues(struc
  static void qeth_notify_skbs(struct qeth_qdio_out_q *queue,
  		struct qeth_qdio_out_buffer *buf,
  		enum iucv_tx_notify notification);
++<<<<<<< HEAD
 +static void qeth_release_skbs(struct qeth_qdio_out_buffer *buf);
++=======
+ static void qeth_tx_complete_buf(struct qeth_qdio_out_buffer *buf, bool error,
+ 				 int budget);
++>>>>>>> 85e537d8f1b6 (s390/qeth: when in TX NAPI mode, use napi_consume_skb())
  static int qeth_init_qdio_out_buf(struct qeth_qdio_out_q *, int);
  
 +int qeth_card_hw_is_reachable(struct qeth_card *card)
 +{
 +	return (card->state == CARD_STATE_SOFTSETUP) ||
 +		(card->state == CARD_STATE_UP);
 +}
 +EXPORT_SYMBOL_GPL(qeth_card_hw_is_reachable);
 +
  static void qeth_close_dev_handler(struct work_struct *work)
  {
  	struct qeth_card *card;
@@@ -417,7 -412,7 +422,11 @@@ static void qeth_cleanup_handled_pendin
  				/* release here to avoid interleaving between
  				   outbound tasklet and inbound tasklet
  				   regarding notifications and lifecycle */
++<<<<<<< HEAD
 +				qeth_release_skbs(c);
++=======
+ 				qeth_tx_complete_buf(c, forced_cleanup, 0);
++>>>>>>> 85e537d8f1b6 (s390/qeth: when in TX NAPI mode, use napi_consume_skb())
  
  				c = f->next_pending;
  				WARN_ON_ONCE(head->next_pending != f);
@@@ -1185,22 -1078,52 +1194,37 @@@ static void qeth_notify_skbs(struct qet
  	}
  }
  
++<<<<<<< HEAD
 +static void qeth_release_skbs(struct qeth_qdio_out_buffer *buf)
++=======
+ static void qeth_tx_complete_buf(struct qeth_qdio_out_buffer *buf, bool error,
+ 				 int budget)
++>>>>>>> 85e537d8f1b6 (s390/qeth: when in TX NAPI mode, use napi_consume_skb())
  {
 -	struct qeth_qdio_out_q *queue = buf->q;
  	struct sk_buff *skb;
  
  	/* release may never happen from within CQ tasklet scope */
  	WARN_ON_ONCE(atomic_read(&buf->state) == QETH_QDIO_BUF_IN_CQ);
  
  	if (atomic_read(&buf->state) == QETH_QDIO_BUF_PENDING)
 -		qeth_notify_skbs(queue, buf, TX_NOTIFY_GENERALERROR);
 +		qeth_notify_skbs(buf->q, buf, TX_NOTIFY_GENERALERROR);
  
 -	/* Empty buffer? */
 -	if (buf->next_element_to_fill == 0)
 -		return;
 -
 -	QETH_TXQ_STAT_INC(queue, bufs);
 -	QETH_TXQ_STAT_ADD(queue, buf_elements, buf->next_element_to_fill);
 -	while ((skb = __skb_dequeue(&buf->skb_list)) != NULL) {
 -		unsigned int bytes = qdisc_pkt_len(skb);
 -		bool is_tso = skb_is_gso(skb);
 -		unsigned int packets;
 -
 -		packets = is_tso ? skb_shinfo(skb)->gso_segs : 1;
 -		if (error) {
 -			QETH_TXQ_STAT_ADD(queue, tx_errors, packets);
 -		} else {
 -			QETH_TXQ_STAT_ADD(queue, tx_packets, packets);
 -			QETH_TXQ_STAT_ADD(queue, tx_bytes, bytes);
 -			if (skb->ip_summed == CHECKSUM_PARTIAL)
 -				QETH_TXQ_STAT_ADD(queue, skbs_csum, packets);
 -			if (skb_is_nonlinear(skb))
 -				QETH_TXQ_STAT_INC(queue, skbs_sg);
 -			if (is_tso) {
 -				QETH_TXQ_STAT_INC(queue, skbs_tso);
 -				QETH_TXQ_STAT_ADD(queue, tso_bytes, bytes);
 -			}
 -		}
++<<<<<<< HEAD
 +	while ((skb = __skb_dequeue(&buf->skb_list)) != NULL)
 +		consume_skb(skb);
 +}
  
 +static void qeth_clear_output_buffer(struct qeth_qdio_out_q *queue,
 +				     struct qeth_qdio_out_buffer *buf)
++=======
+ 		napi_consume_skb(skb, budget);
+ 	}
+ }
+ 
+ static void qeth_clear_output_buffer(struct qeth_qdio_out_q *queue,
+ 				     struct qeth_qdio_out_buffer *buf,
+ 				     bool error, int budget)
++>>>>>>> 85e537d8f1b6 (s390/qeth: when in TX NAPI mode, use napi_consume_skb())
  {
  	int i;
  
@@@ -1208,9 -1131,9 +1232,13 @@@
  	if (buf->buffer->element[0].sflags & SBAL_SFLAGS0_PCI_REQ)
  		atomic_dec(&queue->set_pci_flags_count);
  
++<<<<<<< HEAD
 +	qeth_release_skbs(buf);
++=======
+ 	qeth_tx_complete_buf(buf, error, budget);
++>>>>>>> 85e537d8f1b6 (s390/qeth: when in TX NAPI mode, use napi_consume_skb())
  
 -	for (i = 0; i < queue->max_elements; ++i) {
 +	for (i = 0; i < QETH_MAX_BUFFER_ELEMENTS(queue->card); ++i) {
  		if (buf->buffer->element[i].addr && buf->is_header[i])
  			kmem_cache_free(qeth_core_header_cache,
  				buf->buffer->element[i].addr);
@@@ -1231,7 -1153,7 +1259,11 @@@ static void qeth_drain_output_queue(str
  		if (!q->bufs[j])
  			continue;
  		qeth_cleanup_handled_pending(q, j, 1);
++<<<<<<< HEAD
 +		qeth_clear_output_buffer(q, q->bufs[j]);
++=======
+ 		qeth_clear_output_buffer(q, q->bufs[j], true, 0);
++>>>>>>> 85e537d8f1b6 (s390/qeth: when in TX NAPI mode, use napi_consume_skb())
  		if (free) {
  			kmem_cache_free(qeth_qdio_outbuf_cache, q->bufs[j]);
  			q->bufs[j] = NULL;
@@@ -3599,47 -3473,19 +3631,51 @@@ static void qeth_qdio_output_handler(st
  		int bidx = i % QDIO_MAX_BUFFERS_PER_Q;
  		buffer = queue->bufs[bidx];
  		qeth_handle_send_error(card, buffer, qdio_error);
++<<<<<<< HEAD
 +
 +		if (queue->bufstates &&
 +		    (queue->bufstates[bidx].flags &
 +		     QDIO_OUTBUF_STATE_FLAG_PENDING) != 0) {
 +			WARN_ON_ONCE(card->options.cq != QETH_CQ_ENABLED);
 +
 +			if (atomic_cmpxchg(&buffer->state,
 +					   QETH_QDIO_BUF_PRIMED,
 +					   QETH_QDIO_BUF_PENDING) ==
 +				QETH_QDIO_BUF_PRIMED) {
 +				qeth_notify_skbs(queue, buffer,
 +						 TX_NOTIFY_PENDING);
 +			}
 +			QETH_CARD_TEXT_(queue->card, 5, "pel%d", bidx);
 +
 +			/* prepare the queue slot for re-use: */
 +			qeth_scrub_qdio_buffer(buffer->buffer,
 +					       QETH_MAX_BUFFER_ELEMENTS(card));
 +			if (qeth_init_qdio_out_buf(queue, bidx)) {
 +				QETH_CARD_TEXT(card, 2, "outofbuf");
 +				qeth_schedule_recovery(card);
 +			}
 +		} else {
 +			if (card->options.cq == QETH_CQ_ENABLED) {
 +				enum iucv_tx_notify n;
 +
 +				n = qeth_compute_cq_notification(
 +					buffer->buffer->element[15].sflags, 0);
 +				qeth_notify_skbs(queue, buffer, n);
 +			}
 +
 +			qeth_clear_output_buffer(queue, buffer);
 +		}
 +		qeth_cleanup_handled_pending(queue, bidx, 0);
++=======
+ 		qeth_clear_output_buffer(queue, buffer, qdio_error, 0);
++>>>>>>> 85e537d8f1b6 (s390/qeth: when in TX NAPI mode, use napi_consume_skb())
  	}
 -
  	atomic_sub(count, &queue->used_buffers);
 -	qeth_check_outbound_queue(queue);
 +	/* check if we need to do something on this outbound queue */
 +	if (!IS_IQD(card))
 +		qeth_check_outbound_queue(queue);
  
 -	txq = netdev_get_tx_queue(dev, __queue);
 -	/* xmit may have observed the full-condition, but not yet stopped the
 -	 * txq. In which case the code below won't trigger. So before returning,
 -	 * xmit will re-check the txq's fill level and wake it up if needed.
 -	 */
 -	if (netif_tx_queue_stopped(txq) && !qeth_out_queue_is_full(queue))
 -		netif_tx_wake_queue(txq);
 +	netif_wake_queue(queue->card->dev);
  }
  
  /**
@@@ -5336,6 -5139,99 +5372,102 @@@ out
  }
  EXPORT_SYMBOL_GPL(qeth_poll);
  
++<<<<<<< HEAD
++=======
+ static void qeth_iqd_tx_complete(struct qeth_qdio_out_q *queue,
+ 				 unsigned int bidx, bool error, int budget)
+ {
+ 	struct qeth_qdio_out_buffer *buffer = queue->bufs[bidx];
+ 	u8 sflags = buffer->buffer->element[15].sflags;
+ 	struct qeth_card *card = queue->card;
+ 
+ 	if (queue->bufstates && (queue->bufstates[bidx].flags &
+ 				 QDIO_OUTBUF_STATE_FLAG_PENDING)) {
+ 		WARN_ON_ONCE(card->options.cq != QETH_CQ_ENABLED);
+ 
+ 		if (atomic_cmpxchg(&buffer->state, QETH_QDIO_BUF_PRIMED,
+ 						   QETH_QDIO_BUF_PENDING) ==
+ 		    QETH_QDIO_BUF_PRIMED)
+ 			qeth_notify_skbs(queue, buffer, TX_NOTIFY_PENDING);
+ 
+ 		QETH_CARD_TEXT_(card, 5, "pel%u", bidx);
+ 
+ 		/* prepare the queue slot for re-use: */
+ 		qeth_scrub_qdio_buffer(buffer->buffer, queue->max_elements);
+ 		if (qeth_init_qdio_out_buf(queue, bidx)) {
+ 			QETH_CARD_TEXT(card, 2, "outofbuf");
+ 			qeth_schedule_recovery(card);
+ 		}
+ 
+ 		return;
+ 	}
+ 
+ 	if (card->options.cq == QETH_CQ_ENABLED)
+ 		qeth_notify_skbs(queue, buffer,
+ 				 qeth_compute_cq_notification(sflags, 0));
+ 	qeth_clear_output_buffer(queue, buffer, error, budget);
+ }
+ 
+ static int qeth_tx_poll(struct napi_struct *napi, int budget)
+ {
+ 	struct qeth_qdio_out_q *queue = qeth_napi_to_out_queue(napi);
+ 	unsigned int queue_no = queue->queue_no;
+ 	struct qeth_card *card = queue->card;
+ 	struct net_device *dev = card->dev;
+ 	unsigned int work_done = 0;
+ 	struct netdev_queue *txq;
+ 
+ 	txq = netdev_get_tx_queue(dev, qeth_iqd_translate_txq(dev, queue_no));
+ 
+ 	while (1) {
+ 		unsigned int start, error, i;
+ 		int completed;
+ 
+ 		if (qeth_out_queue_is_empty(queue)) {
+ 			napi_complete(napi);
+ 			return 0;
+ 		}
+ 
+ 		/* Give the CPU a breather: */
+ 		if (work_done >= QDIO_MAX_BUFFERS_PER_Q) {
+ 			QETH_TXQ_STAT_INC(queue, completion_yield);
+ 			if (napi_complete_done(napi, 0))
+ 				napi_schedule(napi);
+ 			return 0;
+ 		}
+ 
+ 		completed = qdio_inspect_queue(CARD_DDEV(card), queue_no, false,
+ 					       &start, &error);
+ 		if (completed <= 0) {
+ 			/* Ensure we see TX completion for pending work: */
+ 			if (napi_complete_done(napi, 0))
+ 				qeth_tx_arm_timer(queue);
+ 			return 0;
+ 		}
+ 
+ 		for (i = start; i < start + completed; i++) {
+ 			unsigned int bidx = QDIO_BUFNR(i);
+ 
+ 			qeth_handle_send_error(card, queue->bufs[bidx], error);
+ 			qeth_iqd_tx_complete(queue, bidx, error, budget);
+ 			qeth_cleanup_handled_pending(queue, bidx, false);
+ 		}
+ 
+ 		atomic_sub(completed, &queue->used_buffers);
+ 		work_done += completed;
+ 
+ 		/* xmit may have observed the full-condition, but not yet
+ 		 * stopped the txq. In which case the code below won't trigger.
+ 		 * So before returning, xmit will re-check the txq's fill level
+ 		 * and wake it up if needed.
+ 		 */
+ 		if (netif_tx_queue_stopped(txq) &&
+ 		    !qeth_out_queue_is_full(queue))
+ 			netif_tx_wake_queue(txq);
+ 	}
+ }
+ 
++>>>>>>> 85e537d8f1b6 (s390/qeth: when in TX NAPI mode, use napi_consume_skb())
  static int qeth_setassparms_inspect_rc(struct qeth_ipa_cmd *cmd)
  {
  	if (!cmd->hdr.return_code)
* Unmerged path drivers/s390/net/qeth_core_main.c
