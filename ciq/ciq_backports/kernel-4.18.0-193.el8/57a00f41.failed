libbpf: Add auto-pinning of maps when loading BPF objects

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Toke Høiland-Jørgensen <toke@redhat.com>
commit 57a00f41644f20b11c12a27061d814655f633544
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/57a00f41.failed

This adds support to libbpf for setting map pinning information as part of
the BTF map declaration, to get automatic map pinning (and reuse) on load.
The pinning type currently only supports a single PIN_BY_NAME mode, where
each map will be pinned by its name in a path that can be overridden, but
defaults to /sys/fs/bpf.

Since auto-pinning only does something if any maps actually have a
'pinning' BTF attribute set, we default the new option to enabled, on the
assumption that seamless pinning is what most callers want.

When a map has a pin_path set at load time, libbpf will compare the map
pinned at that location (if any), and if the attributes match, will re-use
that map instead of creating a new one. If no existing map is found, the
newly created map will instead be pinned at the location.

Programs wanting to customise the pinning can override the pinning paths
using bpf_map__set_pin_path() before calling bpf_object__load() (including
setting it to NULL to disable pinning of a particular map).

	Signed-off-by: Toke Høiland-Jørgensen <toke@redhat.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Andrii Nakryiko <andriin@fb.com>
Link: https://lore.kernel.org/bpf/157269298092.394725.3966306029218559681.stgit@toke.dk
(cherry picked from commit 57a00f41644f20b11c12a27061d814655f633544)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/lib/bpf/bpf_helpers.h
#	tools/lib/bpf/libbpf.c
#	tools/lib/bpf/libbpf.h
diff --cc tools/lib/bpf/libbpf.c
index d91bdfbf910b,7aa2a2a22cef..000000000000
--- a/tools/lib/bpf/libbpf.c
+++ b/tools/lib/bpf/libbpf.c
@@@ -1245,10 -1293,34 +1267,34 @@@ static int bpf_object__init_user_btf_ma
  			}
  			map->def.value_size = sz;
  			map->btf_value_type_id = t->type;
+ 		} else if (strcmp(name, "pinning") == 0) {
+ 			__u32 val;
+ 			int err;
+ 
+ 			if (!get_map_field_int(map_name, obj->btf, def, m,
+ 					       &val))
+ 				return -EINVAL;
+ 			pr_debug("map '%s': found pinning = %u.\n",
+ 				 map_name, val);
+ 
+ 			if (val != LIBBPF_PIN_NONE &&
+ 			    val != LIBBPF_PIN_BY_NAME) {
+ 				pr_warn("map '%s': invalid pinning value %u.\n",
+ 					map_name, val);
+ 				return -EINVAL;
+ 			}
+ 			if (val == LIBBPF_PIN_BY_NAME) {
+ 				err = build_map_pin_path(map, pin_root_path);
+ 				if (err) {
+ 					pr_warn("map '%s': couldn't build pin path.\n",
+ 						map_name);
+ 					return err;
+ 				}
+ 			}
  		} else {
  			if (strict) {
 -				pr_warn("map '%s': unknown field '%s'.\n",
 -					map_name, name);
 +				pr_warning("map '%s': unknown field '%s'.\n",
 +					   map_name, name);
  				return -ENOTSUP;
  			}
  			pr_debug("map '%s': ignoring unknown field '%s'.\n",
@@@ -1314,9 -1387,10 +1361,14 @@@ static int bpf_object__init_user_btf_ma
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int bpf_object__init_maps(struct bpf_object *obj, int flags)
++=======
+ static int bpf_object__init_maps(struct bpf_object *obj, bool relaxed_maps,
+ 				 const char *pin_root_path)
++>>>>>>> 57a00f41644f (libbpf: Add auto-pinning of maps when loading BPF objects)
  {
 -	bool strict = !relaxed_maps;
 +	bool strict = !(flags & MAPS_RELAX_COMPAT);
  	int err;
  
  	err = bpf_object__init_user_maps(obj, strict);
@@@ -1515,7 -1586,8 +1567,12 @@@ static int bpf_object__sanitize_and_loa
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int bpf_object__elf_collect(struct bpf_object *obj, int flags)
++=======
+ static int bpf_object__elf_collect(struct bpf_object *obj, bool relaxed_maps,
+ 				   const char *pin_root_path)
++>>>>>>> 57a00f41644f (libbpf: Add auto-pinning of maps when loading BPF objects)
  {
  	Elf *elf = obj->efile.elf;
  	GElf_Ehdr *ep = &obj->efile.ehdr;
@@@ -1650,7 -1722,7 +1707,11 @@@
  	}
  	err = bpf_object__init_btf(obj, btf_data, btf_ext_data);
  	if (!err)
++<<<<<<< HEAD
 +		err = bpf_object__init_maps(obj, flags);
++=======
+ 		err = bpf_object__init_maps(obj, relaxed_maps, pin_root_path);
++>>>>>>> 57a00f41644f (libbpf: Add auto-pinning of maps when loading BPF objects)
  	if (!err)
  		err = bpf_object__sanitize_and_load_btf(obj);
  	if (!err)
@@@ -2661,55 -3744,18 +2800,60 @@@ bpf_object__load_progs(struct bpf_objec
  	return 0;
  }
  
 -static int libbpf_attach_btf_id_by_name(const char *name, __u32 *btf_id);
 +static bool bpf_prog_type__needs_kver(enum bpf_prog_type type)
 +{
 +	switch (type) {
 +	case BPF_PROG_TYPE_SOCKET_FILTER:
 +	case BPF_PROG_TYPE_SCHED_CLS:
 +	case BPF_PROG_TYPE_SCHED_ACT:
 +	case BPF_PROG_TYPE_XDP:
 +	case BPF_PROG_TYPE_CGROUP_SKB:
 +	case BPF_PROG_TYPE_CGROUP_SOCK:
 +	case BPF_PROG_TYPE_LWT_IN:
 +	case BPF_PROG_TYPE_LWT_OUT:
 +	case BPF_PROG_TYPE_LWT_XMIT:
 +	case BPF_PROG_TYPE_LWT_SEG6LOCAL:
 +	case BPF_PROG_TYPE_SOCK_OPS:
 +	case BPF_PROG_TYPE_SK_SKB:
 +	case BPF_PROG_TYPE_CGROUP_DEVICE:
 +	case BPF_PROG_TYPE_SK_MSG:
 +	case BPF_PROG_TYPE_CGROUP_SOCK_ADDR:
 +	case BPF_PROG_TYPE_LIRC_MODE2:
 +	case BPF_PROG_TYPE_SK_REUSEPORT:
 +	case BPF_PROG_TYPE_FLOW_DISSECTOR:
 +	case BPF_PROG_TYPE_UNSPEC:
 +	case BPF_PROG_TYPE_TRACEPOINT:
 +	case BPF_PROG_TYPE_RAW_TRACEPOINT:
 +	case BPF_PROG_TYPE_PERF_EVENT:
 +	case BPF_PROG_TYPE_CGROUP_SYSCTL:
 +	case BPF_PROG_TYPE_CGROUP_SOCKOPT:
 +		return false;
 +	case BPF_PROG_TYPE_KPROBE:
 +	default:
 +		return true;
 +	}
 +}
 +
 +static int bpf_object__validate(struct bpf_object *obj, bool needs_kver)
 +{
 +	if (needs_kver && obj->kern_version == 0) {
 +		pr_warning("%s doesn't provide kernel version\n",
 +			   obj->path);
 +		return -LIBBPF_ERRNO__KVERSION;
 +	}
 +	return 0;
 +}
  
  static struct bpf_object *
 -__bpf_object__open(const char *path, const void *obj_buf, size_t obj_buf_sz,
 -		   struct bpf_object_open_opts *opts)
 +__bpf_object__open(const char *path, void *obj_buf, size_t obj_buf_sz,
 +		   bool needs_kver, int flags)
  {
++<<<<<<< HEAD
++=======
+ 	const char *pin_root_path;
+ 	struct bpf_program *prog;
++>>>>>>> 57a00f41644f (libbpf: Add auto-pinning of maps when loading BPF objects)
  	struct bpf_object *obj;
 -	const char *obj_name;
 -	char tmp_name[64];
 -	bool relaxed_maps;
  	int err;
  
  	if (elf_version(EV_CURRENT) == EV_NONE) {
@@@ -2721,14 -3783,41 +2865,26 @@@
  	if (IS_ERR(obj))
  		return obj;
  
++<<<<<<< HEAD
 +	CHECK_ERR(bpf_object__elf_init(obj), err, out);
 +	CHECK_ERR(bpf_object__check_endianness(obj), err, out);
 +	CHECK_ERR(bpf_object__probe_caps(obj), err, out);
 +	CHECK_ERR(bpf_object__elf_collect(obj, flags), err, out);
++=======
+ 	obj->relaxed_core_relocs = OPTS_GET(opts, relaxed_core_relocs, false);
+ 	relaxed_maps = OPTS_GET(opts, relaxed_maps, false);
+ 	pin_root_path = OPTS_GET(opts, pin_root_path, NULL);
+ 
+ 	CHECK_ERR(bpf_object__elf_init(obj), err, out);
+ 	CHECK_ERR(bpf_object__check_endianness(obj), err, out);
+ 	CHECK_ERR(bpf_object__probe_caps(obj), err, out);
+ 	CHECK_ERR(bpf_object__elf_collect(obj, relaxed_maps, pin_root_path),
+ 		  err, out);
++>>>>>>> 57a00f41644f (libbpf: Add auto-pinning of maps when loading BPF objects)
  	CHECK_ERR(bpf_object__collect_reloc(obj), err, out);
 -	bpf_object__elf_finish(obj);
 -
 -	bpf_object__for_each_program(prog, obj) {
 -		enum bpf_prog_type prog_type;
 -		enum bpf_attach_type attach_type;
 -		__u32 btf_id;
 -
 -		err = libbpf_prog_type_by_name(prog->section_name, &prog_type,
 -					       &attach_type);
 -		if (err == -ESRCH)
 -			/* couldn't guess, but user might manually specify */
 -			continue;
 -		if (err)
 -			goto out;
 -
 -		bpf_program__set_type(prog, prog_type);
 -		bpf_program__set_expected_attach_type(prog, attach_type);
 -		if (prog_type == BPF_PROG_TYPE_TRACING) {
 -			err = libbpf_attach_btf_id_by_name(prog->section_name, &btf_id);
 -			if (err)
 -				goto out;
 -			prog->attach_btf_id = btf_id;
 -		}
 -	}
 +	CHECK_ERR(bpf_object__validate(obj, needs_kver), err, out);
  
 +	bpf_object__elf_finish(obj);
  	return obj;
  out:
  	bpf_object__close(obj);
diff --cc tools/lib/bpf/libbpf.h
index 5cbf459ece0b,6ddc0419337b..000000000000
--- a/tools/lib/bpf/libbpf.h
+++ b/tools/lib/bpf/libbpf.h
@@@ -67,18 -67,79 +67,79 @@@ struct bpf_object_open_attr 
  	enum bpf_prog_type prog_type;
  };
  
++<<<<<<< HEAD
++=======
+ /* Helper macro to declare and initialize libbpf options struct
+  *
+  * This dance with uninitialized declaration, followed by memset to zero,
+  * followed by assignment using compound literal syntax is done to preserve
+  * ability to use a nice struct field initialization syntax and **hopefully**
+  * have all the padding bytes initialized to zero. It's not guaranteed though,
+  * when copying literal, that compiler won't copy garbage in literal's padding
+  * bytes, but that's the best way I've found and it seems to work in practice.
+  *
+  * Macro declares opts struct of given type and name, zero-initializes,
+  * including any extra padding, it with memset() and then assigns initial
+  * values provided by users in struct initializer-syntax as varargs.
+  */
+ #define DECLARE_LIBBPF_OPTS(TYPE, NAME, ...)				    \
+ 	struct TYPE NAME = ({ 						    \
+ 		memset(&NAME, 0, sizeof(struct TYPE));			    \
+ 		(struct TYPE) {						    \
+ 			.sz = sizeof(struct TYPE),			    \
+ 			__VA_ARGS__					    \
+ 		};							    \
+ 	})
+ 
+ struct bpf_object_open_opts {
+ 	/* size of this struct, for forward/backward compatiblity */
+ 	size_t sz;
+ 	/* object name override, if provided:
+ 	 * - for object open from file, this will override setting object
+ 	 *   name from file path's base name;
+ 	 * - for object open from memory buffer, this will specify an object
+ 	 *   name and will override default "<addr>-<buf-size>" name;
+ 	 */
+ 	const char *object_name;
+ 	/* parse map definitions non-strictly, allowing extra attributes/data */
+ 	bool relaxed_maps;
+ 	/* process CO-RE relocations non-strictly, allowing them to fail */
+ 	bool relaxed_core_relocs;
+ 	/* maps that set the 'pinning' attribute in their definition will have
+ 	 * their pin_path attribute set to a file in this directory, and be
+ 	 * auto-pinned to that path on load; defaults to "/sys/fs/bpf".
+ 	 */
+ 	const char *pin_root_path;
+ };
+ #define bpf_object_open_opts__last_field pin_root_path
+ 
++>>>>>>> 57a00f41644f (libbpf: Add auto-pinning of maps when loading BPF objects)
  LIBBPF_API struct bpf_object *bpf_object__open(const char *path);
  LIBBPF_API struct bpf_object *
 -bpf_object__open_file(const char *path, struct bpf_object_open_opts *opts);
 -LIBBPF_API struct bpf_object *
 -bpf_object__open_mem(const void *obj_buf, size_t obj_buf_sz,
 -		     struct bpf_object_open_opts *opts);
 -
 -/* deprecated bpf_object__open variants */
 -LIBBPF_API struct bpf_object *
 -bpf_object__open_buffer(const void *obj_buf, size_t obj_buf_sz,
 -			const char *name);
 -LIBBPF_API struct bpf_object *
  bpf_object__open_xattr(struct bpf_object_open_attr *attr);
 -
 +struct bpf_object *__bpf_object__open_xattr(struct bpf_object_open_attr *attr,
 +					    int flags);
 +LIBBPF_API struct bpf_object *bpf_object__open_buffer(void *obj_buf,
 +						      size_t obj_buf_sz,
 +						      const char *name);
  int bpf_object__section_size(const struct bpf_object *obj, const char *name,
  			     __u32 *size);
  int bpf_object__variable_offset(const struct bpf_object *obj, const char *name,
  				__u32 *off);
++<<<<<<< HEAD
++=======
+ 
+ enum libbpf_pin_type {
+ 	LIBBPF_PIN_NONE,
+ 	/* PIN_BY_NAME: pin maps by name (in /sys/fs/bpf by default) */
+ 	LIBBPF_PIN_BY_NAME,
+ };
+ 
+ /* pin_maps and unpin_maps can both be called with a NULL path, in which case
+  * they will use the pin_path attribute of each map (and ignore all maps that
+  * don't have a pin_path set).
+  */
++>>>>>>> 57a00f41644f (libbpf: Add auto-pinning of maps when loading BPF objects)
  LIBBPF_API int bpf_object__pin_maps(struct bpf_object *obj, const char *path);
  LIBBPF_API int bpf_object__unpin_maps(struct bpf_object *obj,
  				      const char *path);
* Unmerged path tools/lib/bpf/bpf_helpers.h
* Unmerged path tools/lib/bpf/bpf_helpers.h
* Unmerged path tools/lib/bpf/libbpf.c
* Unmerged path tools/lib/bpf/libbpf.h
