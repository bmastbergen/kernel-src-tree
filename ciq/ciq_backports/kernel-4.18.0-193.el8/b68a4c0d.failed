sched/topology: Disable EAS on inappropriate platforms

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Quentin Perret <quentin.perret@arm.com>
commit b68a4c0dba3b1e1dda1ede49f3c2fc72d3b54567
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/b68a4c0d.failed

Energy Aware Scheduling (EAS) in its current form is most relevant on
platforms with asymmetric CPU topologies (e.g. Arm big.LITTLE) since
this is where there is a lot of potential for saving energy through
scheduling. This is particularly true since the Energy Model only
includes the active power costs of CPUs, hence not providing enough data
to compare packing-vs-spreading strategies.

As such, disable EAS on root domains where the SD_ASYM_CPUCAPACITY flag
is not set. While at it, disable EAS on systems where the complexity of
the Energy Model is too high since that could lead to unacceptable
scheduling overhead.

All in all, EAS can be used on a root domain if and only if:
  1. an Energy Model is available;
  2. the root domain has an asymmetric CPU capacity topology;
  3. the complexity of the root domain's EM is low enough to keep
     scheduling overheads low.

	Signed-off-by: Quentin Perret <quentin.perret@arm.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Mike Galbraith <efault@gmx.de>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: adharmap@codeaurora.org
	Cc: chris.redpath@arm.com
	Cc: currojerez@riseup.net
	Cc: dietmar.eggemann@arm.com
	Cc: edubezval@gmail.com
	Cc: gregkh@linuxfoundation.org
	Cc: javi.merino@kernel.org
	Cc: joel@joelfernandes.org
	Cc: juri.lelli@redhat.com
	Cc: morten.rasmussen@arm.com
	Cc: patrick.bellasi@arm.com
	Cc: pkondeti@codeaurora.org
	Cc: rjw@rjwysocki.net
	Cc: skannan@codeaurora.org
	Cc: smuckle@google.com
	Cc: srinivas.pandruvada@linux.intel.com
	Cc: thara.gopinath@linaro.org
	Cc: tkjos@google.com
	Cc: valentin.schneider@arm.com
	Cc: vincent.guittot@linaro.org
	Cc: viresh.kumar@linaro.org
Link: https://lkml.kernel.org/r/20181203095628.11858-8-quentin.perret@arm.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit b68a4c0dba3b1e1dda1ede49f3c2fc72d3b54567)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/topology.c
diff --cc kernel/sched/topology.c
index 7e6a83289382,6ddb804b2dec..000000000000
--- a/kernel/sched/topology.c
+++ b/kernel/sched/topology.c
@@@ -201,6 -201,163 +201,166 @@@ sd_parent_degenerate(struct sched_domai
  	return 1;
  }
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_ENERGY_MODEL
+ static void free_pd(struct perf_domain *pd)
+ {
+ 	struct perf_domain *tmp;
+ 
+ 	while (pd) {
+ 		tmp = pd->next;
+ 		kfree(pd);
+ 		pd = tmp;
+ 	}
+ }
+ 
+ static struct perf_domain *find_pd(struct perf_domain *pd, int cpu)
+ {
+ 	while (pd) {
+ 		if (cpumask_test_cpu(cpu, perf_domain_span(pd)))
+ 			return pd;
+ 		pd = pd->next;
+ 	}
+ 
+ 	return NULL;
+ }
+ 
+ static struct perf_domain *pd_init(int cpu)
+ {
+ 	struct em_perf_domain *obj = em_cpu_get(cpu);
+ 	struct perf_domain *pd;
+ 
+ 	if (!obj) {
+ 		if (sched_debug())
+ 			pr_info("%s: no EM found for CPU%d\n", __func__, cpu);
+ 		return NULL;
+ 	}
+ 
+ 	pd = kzalloc(sizeof(*pd), GFP_KERNEL);
+ 	if (!pd)
+ 		return NULL;
+ 	pd->em_pd = obj;
+ 
+ 	return pd;
+ }
+ 
+ static void perf_domain_debug(const struct cpumask *cpu_map,
+ 						struct perf_domain *pd)
+ {
+ 	if (!sched_debug() || !pd)
+ 		return;
+ 
+ 	printk(KERN_DEBUG "root_domain %*pbl:", cpumask_pr_args(cpu_map));
+ 
+ 	while (pd) {
+ 		printk(KERN_CONT " pd%d:{ cpus=%*pbl nr_cstate=%d }",
+ 				cpumask_first(perf_domain_span(pd)),
+ 				cpumask_pr_args(perf_domain_span(pd)),
+ 				em_pd_nr_cap_states(pd->em_pd));
+ 		pd = pd->next;
+ 	}
+ 
+ 	printk(KERN_CONT "\n");
+ }
+ 
+ static void destroy_perf_domain_rcu(struct rcu_head *rp)
+ {
+ 	struct perf_domain *pd;
+ 
+ 	pd = container_of(rp, struct perf_domain, rcu);
+ 	free_pd(pd);
+ }
+ 
+ /*
+  * EAS can be used on a root domain if it meets all the following conditions:
+  *    1. an Energy Model (EM) is available;
+  *    2. the SD_ASYM_CPUCAPACITY flag is set in the sched_domain hierarchy.
+  *    3. the EM complexity is low enough to keep scheduling overheads low;
+  *
+  * The complexity of the Energy Model is defined as:
+  *
+  *              C = nr_pd * (nr_cpus + nr_cs)
+  *
+  * with parameters defined as:
+  *  - nr_pd:    the number of performance domains
+  *  - nr_cpus:  the number of CPUs
+  *  - nr_cs:    the sum of the number of capacity states of all performance
+  *              domains (for example, on a system with 2 performance domains,
+  *              with 10 capacity states each, nr_cs = 2 * 10 = 20).
+  *
+  * It is generally not a good idea to use such a model in the wake-up path on
+  * very complex platforms because of the associated scheduling overheads. The
+  * arbitrary constraint below prevents that. It makes EAS usable up to 16 CPUs
+  * with per-CPU DVFS and less than 8 capacity states each, for example.
+  */
+ #define EM_MAX_COMPLEXITY 2048
+ 
+ static void build_perf_domains(const struct cpumask *cpu_map)
+ {
+ 	int i, nr_pd = 0, nr_cs = 0, nr_cpus = cpumask_weight(cpu_map);
+ 	struct perf_domain *pd = NULL, *tmp;
+ 	int cpu = cpumask_first(cpu_map);
+ 	struct root_domain *rd = cpu_rq(cpu)->rd;
+ 
+ 	/* EAS is enabled for asymmetric CPU capacity topologies. */
+ 	if (!per_cpu(sd_asym_cpucapacity, cpu)) {
+ 		if (sched_debug()) {
+ 			pr_info("rd %*pbl: CPUs do not have asymmetric capacities\n",
+ 					cpumask_pr_args(cpu_map));
+ 		}
+ 		goto free;
+ 	}
+ 
+ 	for_each_cpu(i, cpu_map) {
+ 		/* Skip already covered CPUs. */
+ 		if (find_pd(pd, i))
+ 			continue;
+ 
+ 		/* Create the new pd and add it to the local list. */
+ 		tmp = pd_init(i);
+ 		if (!tmp)
+ 			goto free;
+ 		tmp->next = pd;
+ 		pd = tmp;
+ 
+ 		/*
+ 		 * Count performance domains and capacity states for the
+ 		 * complexity check.
+ 		 */
+ 		nr_pd++;
+ 		nr_cs += em_pd_nr_cap_states(pd->em_pd);
+ 	}
+ 
+ 	/* Bail out if the Energy Model complexity is too high. */
+ 	if (nr_pd * (nr_cs + nr_cpus) > EM_MAX_COMPLEXITY) {
+ 		WARN(1, "rd %*pbl: Failed to start EAS, EM complexity is too high\n",
+ 						cpumask_pr_args(cpu_map));
+ 		goto free;
+ 	}
+ 
+ 	perf_domain_debug(cpu_map, pd);
+ 
+ 	/* Attach the new list of performance domains to the root domain. */
+ 	tmp = rd->pd;
+ 	rcu_assign_pointer(rd->pd, pd);
+ 	if (tmp)
+ 		call_rcu(&tmp->rcu, destroy_perf_domain_rcu);
+ 
+ 	return;
+ 
+ free:
+ 	free_pd(pd);
+ 	tmp = rd->pd;
+ 	rcu_assign_pointer(rd->pd, NULL);
+ 	if (tmp)
+ 		call_rcu(&tmp->rcu, destroy_perf_domain_rcu);
+ }
+ #else
+ static void free_pd(struct perf_domain *pd) { }
+ #endif /* CONFIG_ENERGY_MODEL */
+ 
++>>>>>>> b68a4c0dba3b (sched/topology: Disable EAS on inappropriate platforms)
  static void free_rootdomain(struct rcu_head *rcu)
  {
  	struct root_domain *rd = container_of(rcu, struct root_domain, rcu);
* Unmerged path kernel/sched/topology.c
