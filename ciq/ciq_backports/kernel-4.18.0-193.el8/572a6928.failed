xdp: Make __mem_id_disconnect static

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author YueHaibing <yuehaibing@huawei.com>
commit 572a6928f9e3689ad2c2f94814e6215104eec1b7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/572a6928.failed

Fix sparse warning:

net/core/xdp.c:88:6: warning:
 symbol '__mem_id_disconnect' was not declared. Should it be static?

	Reported-by: Hulk Robot <hulkci@huawei.com>
	Signed-off-by: YueHaibing <yuehaibing@huawei.com>
	Acked-by: Jesper Dangaard Brouer <brouer@redhat.com>
	Acked-by: Song Liu <songliubraving@fb.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
(cherry picked from commit 572a6928f9e3689ad2c2f94814e6215104eec1b7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/core/xdp.c
diff --cc net/core/xdp.c
index 762abeb89847,829377cc83db..000000000000
--- a/net/core/xdp.c
+++ b/net/core/xdp.c
@@@ -94,6 -85,64 +94,67 @@@ static void __xdp_mem_allocator_rcu_fre
  	kfree(xa);
  }
  
++<<<<<<< HEAD
++=======
+ static bool __mem_id_disconnect(int id, bool force)
+ {
+ 	struct xdp_mem_allocator *xa;
+ 	bool safe_to_remove = true;
+ 
+ 	mutex_lock(&mem_id_lock);
+ 
+ 	xa = rhashtable_lookup_fast(mem_id_ht, &id, mem_id_rht_params);
+ 	if (!xa) {
+ 		mutex_unlock(&mem_id_lock);
+ 		WARN(1, "Request remove non-existing id(%d), driver bug?", id);
+ 		return true;
+ 	}
+ 	xa->disconnect_cnt++;
+ 
+ 	/* Detects in-flight packet-pages for page_pool */
+ 	if (xa->mem.type == MEM_TYPE_PAGE_POOL)
+ 		safe_to_remove = page_pool_request_shutdown(xa->page_pool);
+ 
+ 	trace_mem_disconnect(xa, safe_to_remove, force);
+ 
+ 	if ((safe_to_remove || force) &&
+ 	    !rhashtable_remove_fast(mem_id_ht, &xa->node, mem_id_rht_params))
+ 		call_rcu(&xa->rcu, __xdp_mem_allocator_rcu_free);
+ 
+ 	mutex_unlock(&mem_id_lock);
+ 	return (safe_to_remove|force);
+ }
+ 
+ #define DEFER_TIME (msecs_to_jiffies(1000))
+ #define DEFER_WARN_INTERVAL (30 * HZ)
+ #define DEFER_MAX_RETRIES 120
+ 
+ static void mem_id_disconnect_defer_retry(struct work_struct *wq)
+ {
+ 	struct delayed_work *dwq = to_delayed_work(wq);
+ 	struct xdp_mem_allocator *xa = container_of(dwq, typeof(*xa), defer_wq);
+ 	bool force = false;
+ 
+ 	if (xa->disconnect_cnt > DEFER_MAX_RETRIES)
+ 		force = true;
+ 
+ 	if (__mem_id_disconnect(xa->mem.id, force))
+ 		return;
+ 
+ 	/* Periodic warning */
+ 	if (time_after_eq(jiffies, xa->defer_warn)) {
+ 		int sec = (s32)((u32)jiffies - (u32)xa->defer_start) / HZ;
+ 
+ 		pr_warn("%s() stalled mem.id=%u shutdown %d attempts %d sec\n",
+ 			__func__, xa->mem.id, xa->disconnect_cnt, sec);
+ 		xa->defer_warn = jiffies + DEFER_WARN_INTERVAL;
+ 	}
+ 
+ 	/* Still not ready to be disconnected, retry later */
+ 	schedule_delayed_work(&xa->defer_wq, DEFER_TIME);
+ }
+ 
++>>>>>>> 572a6928f9e3 (xdp: Make __mem_id_disconnect static)
  void xdp_rxq_info_unreg_mem_model(struct xdp_rxq_info *xdp_rxq)
  {
  	struct xdp_mem_allocator *xa;
* Unmerged path net/core/xdp.c
