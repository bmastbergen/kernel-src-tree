iommu/vt-d: Shared virtual address in scalable mode

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [iommu] vt-d: Shared virtual address in scalable mode (Jerry Snitselaar) [1742234]
Rebuild_FUZZ: 93.75%
commit-author Lu Baolu <baolu.lu@linux.intel.com>
commit 1c4f88b7f1f9298b56c7dac18c0bcd8d2f75059a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/1c4f88b7.failed

This patch enables the current SVA (Shared Virtual Address)
implementation to work in the scalable mode.

	Cc: Ashok Raj <ashok.raj@intel.com>
	Cc: Jacob Pan <jacob.jun.pan@linux.intel.com>
	Cc: Kevin Tian <kevin.tian@intel.com>
	Signed-off-by: Sanjay Kumar <sanjay.k.kumar@intel.com>
	Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
	Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
	Reviewed-by: Ashok Raj <ashok.raj@intel.com>
	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit 1c4f88b7f1f9298b56c7dac18c0bcd8d2f75059a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/intel-iommu.c
#	drivers/iommu/intel-pasid.h
#	drivers/iommu/intel-svm.c
#	include/linux/intel-iommu.h
diff --cc drivers/iommu/intel-iommu.c
index 123eb1289ade,cec88df671a6..000000000000
--- a/drivers/iommu/intel-iommu.c
+++ b/drivers/iommu/intel-iommu.c
@@@ -5263,25 -5257,6 +5263,28 @@@ static void intel_iommu_put_resv_region
  }
  
  #ifdef CONFIG_INTEL_IOMMU_SVM
++<<<<<<< HEAD
 +#define MAX_NR_PASID_BITS (20)
 +static inline unsigned long intel_iommu_get_pts(struct intel_iommu *iommu)
 +{
 +	/*
 +	 * Convert ecap_pss to extend context entry pts encoding, also
 +	 * respect the soft pasid_max value set by the iommu.
 +	 * - number of PASID bits = ecap_pss + 1
 +	 * - number of PASID table entries = 2^(pts + 5)
 +	 * Therefore, pts = ecap_pss - 4
 +	 * e.g. KBL ecap_pss = 0x13, PASID has 20 bits, pts = 15
 +	 */
 +	if (ecap_pss(iommu->ecap) < 5)
 +		return 0;
 +
 +	/* pasid_max is encoded as actual number of entries not the bits */
 +	return find_first_bit((unsigned long *)&iommu->pasid_max,
 +			MAX_NR_PASID_BITS) - 5;
 +}
 +
++=======
++>>>>>>> 1c4f88b7f1f9 (iommu/vt-d: Shared virtual address in scalable mode)
  int intel_iommu_enable_pasid(struct intel_iommu *iommu, struct intel_svm_dev *sdev)
  {
  	struct device_domain_info *info;
@@@ -5313,33 -5288,7 +5316,32 @@@
  	sdev->sid = PCI_DEVID(info->bus, info->devfn);
  
  	if (!(ctx_lo & CONTEXT_PASIDE)) {
++<<<<<<< HEAD
 +		if (iommu->pasid_state_table)
 +			context[1].hi = (u64)virt_to_phys(iommu->pasid_state_table);
 +		context[1].lo = (u64)virt_to_phys(iommu->pasid_table) |
 +			intel_iommu_get_pts(iommu);
 +
 +		wmb();
 +		/* CONTEXT_TT_MULTI_LEVEL and CONTEXT_TT_DEV_IOTLB are both
 +		 * extended to permit requests-with-PASID if the PASIDE bit
 +		 * is set. which makes sense. For CONTEXT_TT_PASS_THROUGH,
 +		 * however, the PASIDE bit is ignored and requests-with-PASID
 +		 * are unconditionally blocked. Which makes less sense.
 +		 * So convert from CONTEXT_TT_PASS_THROUGH to one of the new
 +		 * "guest mode" translation types depending on whether ATS
 +		 * is available or not. Annoyingly, we can't use the new
 +		 * modes *unless* PASIDE is set. */
 +		if ((ctx_lo & CONTEXT_TT_MASK) == (CONTEXT_TT_PASS_THROUGH << 2)) {
 +			ctx_lo &= ~CONTEXT_TT_MASK;
 +			if (info->ats_supported)
 +				ctx_lo |= CONTEXT_TT_PT_PASID_DEV_IOTLB << 2;
 +			else
 +				ctx_lo |= CONTEXT_TT_PT_PASID << 2;
 +		}
++=======
++>>>>>>> 1c4f88b7f1f9 (iommu/vt-d: Shared virtual address in scalable mode)
  		ctx_lo |= CONTEXT_PASIDE;
- 		if (iommu->pasid_state_table)
- 			ctx_lo |= CONTEXT_DINVE;
- 		if (info->pri_supported)
- 			ctx_lo |= CONTEXT_PRS;
  		context[0].lo = ctx_lo;
  		wmb();
  		iommu->flush.flush_context(iommu, sdev->did, sdev->sid,
diff --cc drivers/iommu/intel-pasid.h
index 7aa7e4a635a7,23537b3f34e3..000000000000
--- a/drivers/iommu/intel-pasid.h
+++ b/drivers/iommu/intel-pasid.h
@@@ -35,7 -58,9 +35,13 @@@ void intel_pasid_free_table(struct devi
  struct pasid_table *intel_pasid_get_table(struct device *dev);
  int intel_pasid_get_dev_max_id(struct device *dev);
  struct pasid_entry *intel_pasid_get_entry(struct device *dev, int pasid);
++<<<<<<< HEAD
 +void intel_pasid_clear_entry(struct device *dev, int pasid);
++=======
+ int intel_pasid_setup_first_level(struct intel_iommu *iommu,
+ 				  struct device *dev, pgd_t *pgd,
+ 				  int pasid, u16 did, int flags);
++>>>>>>> 1c4f88b7f1f9 (iommu/vt-d: Shared virtual address in scalable mode)
  int intel_pasid_setup_second_level(struct intel_iommu *iommu,
  				   struct dmar_domain *domain,
  				   struct device *dev, int pasid);
diff --cc drivers/iommu/intel-svm.c
index 1797ae6439d7,04d6bdb51404..000000000000
--- a/drivers/iommu/intel-svm.c
+++ b/drivers/iommu/intel-svm.c
@@@ -281,12 -261,9 +263,16 @@@ static void intel_mm_release(struct mmu
  	 * page) so that we end up taking a fault that the hardware really
  	 * *has* to handle gracefully without affecting other processes.
  	 */
 +	svm->iommu->pasid_table[svm->pasid].val = 0;
 +	wmb();
 +
  	rcu_read_lock();
  	list_for_each_entry_rcu(sdev, &svm->devs, list) {
++<<<<<<< HEAD
 +		intel_flush_pasid_dev(svm, sdev, svm->pasid);
++=======
+ 		intel_pasid_tear_down_entry(svm->iommu, sdev->dev, svm->pasid);
++>>>>>>> 1c4f88b7f1f9 (iommu/vt-d: Shared virtual address in scalable mode)
  		intel_flush_svm_range_dev(svm, sdev, 0, -1, 0, !svm->mm);
  	}
  	rcu_read_unlock();
@@@ -418,23 -393,22 +403,35 @@@ int intel_svm_bind_mm(struct device *de
  				kfree(sdev);
  				goto out;
  			}
- 			pasid_entry_val = (u64)__pa(mm->pgd) | PASID_ENTRY_P;
- 		} else
- 			pasid_entry_val = (u64)__pa(init_mm.pgd) |
- 					  PASID_ENTRY_P | PASID_ENTRY_SRE;
- 		if (cpu_feature_enabled(X86_FEATURE_LA57))
- 			pasid_entry_val |= PASID_ENTRY_FLPM_5LP;
+ 		}
  
++<<<<<<< HEAD
 +		iommu->pasid_table[svm->pasid].val = pasid_entry_val;
 +
 +		wmb();
 +
 +		/*
 +		 * Flush PASID cache when a PASID table entry becomes
 +		 * present.
 +		 */
 +		if (cap_caching_mode(iommu->cap))
 +			intel_flush_pasid_dev(svm, sdev, svm->pasid);
++=======
+ 		spin_lock(&iommu->lock);
+ 		ret = intel_pasid_setup_first_level(iommu, dev,
+ 				mm ? mm->pgd : init_mm.pgd,
+ 				svm->pasid, FLPT_DEFAULT_DID,
+ 				mm ? 0 : PASID_FLAG_SUPERVISOR_MODE);
+ 		spin_unlock(&iommu->lock);
+ 		if (ret) {
+ 			if (mm)
+ 				mmu_notifier_unregister(&svm->notifier, mm);
+ 			intel_pasid_free_id(svm->pasid);
+ 			kfree(svm);
+ 			kfree(sdev);
+ 			goto out;
+ 		}
++>>>>>>> 1c4f88b7f1f9 (iommu/vt-d: Shared virtual address in scalable mode)
  
  		list_add_tail(&svm->list, &global_svm_list);
  	}
diff --cc include/linux/intel-iommu.h
index d83908420a83,cfcf9c1e1872..000000000000
--- a/include/linux/intel-iommu.h
+++ b/include/linux/intel-iommu.h
@@@ -37,9 -36,29 +37,33 @@@
  #include <asm/iommu.h>
  
  /*
++<<<<<<< HEAD
++=======
+  * VT-d hardware uses 4KiB page size regardless of host page size.
+  */
+ #define VTD_PAGE_SHIFT		(12)
+ #define VTD_PAGE_SIZE		(1UL << VTD_PAGE_SHIFT)
+ #define VTD_PAGE_MASK		(((u64)-1) << VTD_PAGE_SHIFT)
+ #define VTD_PAGE_ALIGN(addr)	(((addr) + VTD_PAGE_SIZE - 1) & VTD_PAGE_MASK)
+ 
+ #define VTD_STRIDE_SHIFT        (9)
+ #define VTD_STRIDE_MASK         (((u64)-1) << VTD_STRIDE_SHIFT)
+ 
+ #define DMA_PTE_READ (1)
+ #define DMA_PTE_WRITE (2)
+ #define DMA_PTE_LARGE_PAGE (1 << 7)
+ #define DMA_PTE_SNP (1 << 11)
+ 
+ #define CONTEXT_TT_MULTI_LEVEL	0
+ #define CONTEXT_TT_DEV_IOTLB	1
+ #define CONTEXT_TT_PASS_THROUGH 2
+ #define CONTEXT_PASIDE		BIT_ULL(3)
+ 
+ /*
++>>>>>>> 1c4f88b7f1f9 (iommu/vt-d: Shared virtual address in scalable mode)
   * Intel IOMMU register specification per version 1.0 public spec.
   */
 +
  #define	DMAR_VER_REG	0x0	/* Arch version supported by this IOMMU */
  #define	DMAR_CAP_REG	0x8	/* Hardware supported capabilities */
  #define	DMAR_ECAP_REG	0x10	/* Extended capabilities supported */
* Unmerged path drivers/iommu/intel-iommu.c
diff --git a/drivers/iommu/intel-pasid.c b/drivers/iommu/intel-pasid.c
index 63accc78b1fb..6d5bd09fd3ad 100644
--- a/drivers/iommu/intel-pasid.c
+++ b/drivers/iommu/intel-pasid.c
@@ -228,7 +228,7 @@ static inline void pasid_clear_entry(struct pasid_entry *pe)
 	WRITE_ONCE(pe->val, 0);
 }
 
-void intel_pasid_clear_entry(struct device *dev, int pasid)
+static void intel_pasid_clear_entry(struct device *dev, int pasid)
 {
 	struct pasid_entry *pe;
 
* Unmerged path drivers/iommu/intel-pasid.h
* Unmerged path drivers/iommu/intel-svm.c
* Unmerged path include/linux/intel-iommu.h
