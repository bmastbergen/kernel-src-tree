xprtrdma: Backchannel can use GFP_KERNEL allocations

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Chuck Lever <chuck.lever@oracle.com>
commit 3f9c7e76934790c53a48b11c7ad54770cd3ae50d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/3f9c7e76.failed

The Receive handler runs in process context, thus can use on-demand
GFP_KERNEL allocations instead of pre-allocation.

This makes the xprtrdma backchannel independent of the number of
backchannel session slots provisioned by the Upper Layer protocol.

	Signed-off-by: Chuck Lever <chuck.lever@oracle.com>
	Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
(cherry picked from commit 3f9c7e76934790c53a48b11c7ad54770cd3ae50d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sunrpc/xprtrdma/backchannel.c
diff --cc net/sunrpc/xprtrdma/backchannel.c
index b25cce6c9556,ae51ef6a897a..000000000000
--- a/net/sunrpc/xprtrdma/backchannel.c
+++ b/net/sunrpc/xprtrdma/backchannel.c
@@@ -19,36 -19,6 +19,39 @@@
  
  #undef RPCRDMA_BACKCHANNEL_DEBUG
  
++<<<<<<< HEAD
 +static int rpcrdma_bc_setup_reqs(struct rpcrdma_xprt *r_xprt,
 +				 unsigned int count)
 +{
 +	struct rpc_xprt *xprt = &r_xprt->rx_xprt;
 +	struct rpcrdma_req *req;
 +	struct rpc_rqst *rqst;
 +	unsigned int i;
 +
 +	for (i = 0; i < (count << 1); i++) {
 +		size_t size;
 +
 +		size = min_t(size_t, r_xprt->rx_data.inline_rsize, PAGE_SIZE);
 +		req = rpcrdma_req_create(r_xprt, size, GFP_KERNEL);
 +		if (!req)
 +			return -ENOMEM;
 +		rqst = &req->rl_slot;
 +
 +		rqst->rq_xprt = xprt;
 +		INIT_LIST_HEAD(&rqst->rq_list);
 +		INIT_LIST_HEAD(&rqst->rq_bc_list);
 +		__set_bit(RPC_BC_PA_IN_USE, &rqst->rq_bc_pa_state);
 +		spin_lock(&xprt->bc_pa_lock);
 +		list_add(&rqst->rq_bc_pa_list, &xprt->bc_pa_list);
 +		spin_unlock(&xprt->bc_pa_lock);
 +		xdr_buf_init(&rqst->rq_snd_buf, rdmab_data(req->rl_sendbuf),
 +			     size);
 +	}
 +	return 0;
 +}
 +
++=======
++>>>>>>> 3f9c7e769347 (xprtrdma: Backchannel can use GFP_KERNEL allocations)
  /**
   * xprt_rdma_bc_setup - Pre-allocate resources for handling backchannel requests
   * @xprt: transport associated with these backchannel resources
@@@ -59,56 -29,12 +62,32 @@@
  int xprt_rdma_bc_setup(struct rpc_xprt *xprt, unsigned int reqs)
  {
  	struct rpcrdma_xprt *r_xprt = rpcx_to_rdmax(xprt);
- 	int rc;
- 
- 	/* The backchannel reply path returns each rpc_rqst to the
- 	 * bc_pa_list _after_ the reply is sent. If the server is
- 	 * faster than the client, it can send another backward
- 	 * direction request before the rpc_rqst is returned to the
- 	 * list. The client rejects the request in this case.
- 	 *
- 	 * Twice as many rpc_rqsts are prepared to ensure there is
- 	 * always an rpc_rqst available as soon as a reply is sent.
- 	 */
- 	if (reqs > RPCRDMA_BACKWARD_WRS >> 1)
- 		goto out_err;
- 
- 	rc = rpcrdma_bc_setup_reqs(r_xprt, reqs);
- 	if (rc)
- 		goto out_free;
  
- 	r_xprt->rx_buf.rb_bc_srv_max_requests = reqs;
+ 	r_xprt->rx_buf.rb_bc_srv_max_requests = RPCRDMA_BACKWARD_WRS >> 1;
  	trace_xprtrdma_cb_setup(r_xprt, reqs);
  	return 0;
- 
- out_free:
- 	xprt_rdma_bc_destroy(xprt, reqs);
- 
- out_err:
- 	pr_err("RPC:       %s: setup backchannel transport failed\n", __func__);
- 	return -ENOMEM;
  }
  
 +/**
 + * xprt_rdma_bc_up - Create transport endpoint for backchannel service
 + * @serv: server endpoint
 + * @net: network namespace
 + *
 + * The "xprt" is an implied argument: it supplies the name of the
 + * backchannel transport class.
 + *
 + * Returns zero on success, negative errno on failure
 + */
 +int xprt_rdma_bc_up(struct svc_serv *serv, struct net *net)
 +{
 +	int ret;
 +
 +	ret = svc_create_xprt(serv, "rdma-bc", net, PF_INET, 0, 0);
 +	if (ret < 0)
 +		return ret;
 +	return 0;
 +}
 +
  /**
   * xprt_rdma_bc_maxpayload - Return maximum backchannel message size
   * @xprt: transport
@@@ -262,20 -228,11 +278,12 @@@ void rpcrdma_bc_receive_call(struct rpc
  	pr_info("RPC:       %s: %*ph\n", __func__, size, p);
  #endif
  
- 	/* Grab a free bc rqst */
- 	spin_lock(&xprt->bc_pa_lock);
- 	if (list_empty(&xprt->bc_pa_list)) {
- 		spin_unlock(&xprt->bc_pa_lock);
+ 	rqst = rpcrdma_bc_rqst_get(r_xprt);
+ 	if (!rqst)
  		goto out_overflow;
- 	}
- 	rqst = list_first_entry(&xprt->bc_pa_list,
- 				struct rpc_rqst, rq_bc_pa_list);
- 	list_del(&rqst->rq_bc_pa_list);
- 	spin_unlock(&xprt->bc_pa_lock);
  
- 	/* Prepare rqst */
  	rqst->rq_reply_bytes_recvd = 0;
 +	rqst->rq_bytes_sent = 0;
  	rqst->rq_xid = *p;
  
  	rqst->rq_private_buf.len = size;
* Unmerged path net/sunrpc/xprtrdma/backchannel.c
