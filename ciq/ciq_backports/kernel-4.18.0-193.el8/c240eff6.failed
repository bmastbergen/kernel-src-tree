bpf: introduce new bpf prog load flags "BPF_F_TEST_RND_HI32"

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Jiong Wang <jiong.wang@netronome.com>
commit c240eff63a1cf1c4edc768e0cfc374811c02f069
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/c240eff6.failed

x86_64 and AArch64 perhaps are two arches that running bpf testsuite
frequently, however the zero extension insertion pass is not enabled for
them because of their hardware support.

It is critical to guarantee the pass correction as it is supposed to be
enabled at default for a couple of other arches, for example PowerPC,
SPARC, arm, NFP etc. Therefore, it would be very useful if there is a way
to test this pass on for example x86_64.

The test methodology employed by this set is "poisoning" useless bits. High
32-bit of a definition is randomized if it is identified as not used by any
later insn. Such randomization is only enabled under testing mode which is
gated by the new bpf prog load flags "BPF_F_TEST_RND_HI32".

	Suggested-by: Alexei Starovoitov <ast@kernel.org>
	Signed-off-by: Jiong Wang <jiong.wang@netronome.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
(cherry picked from commit c240eff63a1cf1c4edc768e0cfc374811c02f069)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/uapi/linux/bpf.h
diff --cc include/uapi/linux/bpf.h
index d421ae5c0fec,7c6aef253173..000000000000
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@@ -262,8 -260,37 +262,40 @@@ enum bpf_attach_type 
   */
  #define BPF_F_ANY_ALIGNMENT	(1U << 1)
  
++<<<<<<< HEAD
 +/* when bpf_ldimm64->src_reg == BPF_PSEUDO_MAP_FD, bpf_ldimm64->imm == fd */
++=======
+ /* BPF_F_TEST_RND_HI32 is used in BPF_PROG_LOAD command for testing purpose.
+  * Verifier does sub-register def/use analysis and identifies instructions whose
+  * def only matters for low 32-bit, high 32-bit is never referenced later
+  * through implicit zero extension. Therefore verifier notifies JIT back-ends
+  * that it is safe to ignore clearing high 32-bit for these instructions. This
+  * saves some back-ends a lot of code-gen. However such optimization is not
+  * necessary on some arches, for example x86_64, arm64 etc, whose JIT back-ends
+  * hence hasn't used verifier's analysis result. But, we really want to have a
+  * way to be able to verify the correctness of the described optimization on
+  * x86_64 on which testsuites are frequently exercised.
+  *
+  * So, this flag is introduced. Once it is set, verifier will randomize high
+  * 32-bit for those instructions who has been identified as safe to ignore them.
+  * Then, if verifier is not doing correct analysis, such randomization will
+  * regress tests to expose bugs.
+  */
+ #define BPF_F_TEST_RND_HI32	(1U << 2)
+ 
+ /* When BPF ldimm64's insn[0].src_reg != 0 then this can have
+  * two extensions:
+  *
+  * insn[0].src_reg:  BPF_PSEUDO_MAP_FD   BPF_PSEUDO_MAP_VALUE
+  * insn[0].imm:      map fd              map fd
+  * insn[1].imm:      0                   offset into value
+  * insn[0].off:      0                   0
+  * insn[1].off:      0                   0
+  * ldimm64 rewrite:  address of map      address of map[0]+offset
+  * verifier type:    CONST_PTR_TO_MAP    PTR_TO_MAP_VALUE
+  */
++>>>>>>> c240eff63a1c (bpf: introduce new bpf prog load flags "BPF_F_TEST_RND_HI32")
  #define BPF_PSEUDO_MAP_FD	1
 -#define BPF_PSEUDO_MAP_VALUE	2
  
  /* when bpf_call->src_reg == BPF_PSEUDO_CALL, bpf_call->imm == pc-relative
   * offset to another bpf function
* Unmerged path include/uapi/linux/bpf.h
diff --git a/kernel/bpf/syscall.c b/kernel/bpf/syscall.c
index 766235d960e2..1812456bbf01 100644
--- a/kernel/bpf/syscall.c
+++ b/kernel/bpf/syscall.c
@@ -1585,7 +1585,9 @@ static int bpf_prog_load(union bpf_attr *attr, union bpf_attr __user *uattr)
 	if (CHECK_ATTR(BPF_PROG_LOAD))
 		return -EINVAL;
 
-	if (attr->prog_flags & ~(BPF_F_STRICT_ALIGNMENT | BPF_F_ANY_ALIGNMENT))
+	if (attr->prog_flags & ~(BPF_F_STRICT_ALIGNMENT |
+				 BPF_F_ANY_ALIGNMENT |
+				 BPF_F_TEST_RND_HI32))
 		return -EINVAL;
 
 	if (!IS_ENABLED(CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS) &&
