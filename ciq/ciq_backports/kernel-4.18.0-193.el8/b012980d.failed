riscv/mmiowb: Hook up mmwiob() implementation to asm-generic code

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Will Deacon <will.deacon@arm.com>
commit b012980d1c6e27f5c4adf0c19defca8658956820
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/b012980d.failed

In a bid to kill off explicit mmiowb() usage in driver code, hook up
the asm-generic mmiowb() tracking code for riscv, so that an mmiowb()
is automatically issued from spin_unlock() if an I/O write was performed
in the critical section.

	Reviewed-by: Palmer Dabbelt <palmer@sifive.com>
	Acked-by: Linus Torvalds <torvalds@linux-foundation.org>
	Signed-off-by: Will Deacon <will.deacon@arm.com>
(cherry picked from commit b012980d1c6e27f5c4adf0c19defca8658956820)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/riscv/Kconfig
#	arch/riscv/include/asm/Kbuild
diff --cc arch/riscv/Kconfig
index 781c5d7fb7db,6e30e8126799..000000000000
--- a/arch/riscv/Kconfig
+++ b/arch/riscv/Kconfig
@@@ -44,6 -46,10 +44,11 @@@ config RISC
  	select RISCV_TIMER
  	select GENERIC_IRQ_MULTI_HANDLER
  	select ARCH_HAS_PTE_SPECIAL
++<<<<<<< HEAD
++=======
+ 	select ARCH_HAS_MMIOWB
+ 	select HAVE_EBPF_JIT if 64BIT
++>>>>>>> b012980d1c6e (riscv/mmiowb: Hook up mmwiob() implementation to asm-generic code)
  
  config MMU
  	def_bool y
diff --cc arch/riscv/include/asm/Kbuild
index 576ffdca06ba,cccd12cf27d4..000000000000
--- a/arch/riscv/include/asm/Kbuild
+++ b/arch/riscv/include/asm/Kbuild
@@@ -27,34 -21,15 +27,37 @@@ generic-y += kvm_para.
  generic-y += local.h
  generic-y += local64.h
  generic-y += mm-arch-hooks.h
++<<<<<<< HEAD
 +generic-y += mman.h
 +generic-y += module.h
 +generic-y += msgbuf.h
++=======
++>>>>>>> b012980d1c6e (riscv/mmiowb: Hook up mmwiob() implementation to asm-generic code)
  generic-y += mutex.h
 +generic-y += param.h
  generic-y += percpu.h
 +generic-y += poll.h
 +generic-y += posix_types.h
  generic-y += preempt.h
 +generic-y += resource.h
  generic-y += scatterlist.h
  generic-y += sections.h
 +generic-y += sembuf.h
  generic-y += serial.h
 +generic-y += setup.h
 +generic-y += shmbuf.h
  generic-y += shmparam.h
 +generic-y += signal.h
 +generic-y += socket.h
 +generic-y += sockios.h
 +generic-y += stat.h
 +generic-y += statfs.h
 +generic-y += swab.h
 +generic-y += termbits.h
 +generic-y += termios.h
  generic-y += topology.h
  generic-y += trace_clock.h
 +generic-y += types.h
  generic-y += unaligned.h
  generic-y += user.h
  generic-y += vga.h
* Unmerged path arch/riscv/Kconfig
* Unmerged path arch/riscv/include/asm/Kbuild
diff --git a/arch/riscv/include/asm/io.h b/arch/riscv/include/asm/io.h
index b269451e7e85..65615df1381d 100644
--- a/arch/riscv/include/asm/io.h
+++ b/arch/riscv/include/asm/io.h
@@ -20,6 +20,7 @@
 #define _ASM_RISCV_IO_H
 
 #include <linux/types.h>
+#include <asm/mmiowb.h>
 
 extern void __iomem *ioremap(phys_addr_t offset, unsigned long size);
 
@@ -99,18 +100,6 @@ static inline u64 __raw_readq(const volatile void __iomem *addr)
 }
 #endif
 
-/*
- * FIXME: I'm flip-flopping on whether or not we should keep this or enforce
- * the ordering with I/O on spinlocks like PowerPC does.  The worry is that
- * drivers won't get this correct, but I also don't want to introduce a fence
- * into the lock code that otherwise only uses AMOs (and is essentially defined
- * by the ISA to be correct).   For now I'm leaving this here: "o,w" is
- * sufficient to ensure that all writes to the device have completed before the
- * write to the spinlock is allowed to commit.  I surmised this from reading
- * "ACQUIRES VS I/O ACCESSES" in memory-barriers.txt.
- */
-#define mmiowb()	__asm__ __volatile__ ("fence o,w" : : : "memory");
-
 /*
  * Unordered I/O memory access primitives.  These are even more relaxed than
  * the relaxed versions, as they don't even order accesses between successive
@@ -165,7 +154,7 @@ static inline u64 __raw_readq(const volatile void __iomem *addr)
 #define __io_br()	do {} while (0)
 #define __io_ar()	__asm__ __volatile__ ("fence i,r" : : : "memory");
 #define __io_bw()	__asm__ __volatile__ ("fence w,o" : : : "memory");
-#define __io_aw()	do {} while (0)
+#define __io_aw()	mmiowb_set_pending()
 
 #define readb(c)	({ u8  __v; __io_br(); __v = readb_cpu(c); __io_ar(); __v; })
 #define readw(c)	({ u16 __v; __io_br(); __v = readw_cpu(c); __io_ar(); __v; })
diff --git a/arch/riscv/include/asm/mmiowb.h b/arch/riscv/include/asm/mmiowb.h
new file mode 100644
index 000000000000..5d7e3a2b4e3b
--- /dev/null
+++ b/arch/riscv/include/asm/mmiowb.h
@@ -0,0 +1,14 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+#ifndef _ASM_RISCV_MMIOWB_H
+#define _ASM_RISCV_MMIOWB_H
+
+/*
+ * "o,w" is sufficient to ensure that all writes to the device have completed
+ * before the write to the spinlock is allowed to commit.
+ */
+#define mmiowb()	__asm__ __volatile__ ("fence o,w" : : : "memory");
+
+#include <asm-generic/mmiowb.h>
+
+#endif	/* ASM_RISCV_MMIOWB_H */
