net/mlx5: E-Switch, Use getter and iterator to access vport/rep

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [netdrv] mlx5: E-Switch, Use getter and iterator to access vport/rep (Alaa Hleihel) [1724333]
Rebuild_FUZZ: 96.72%
commit-author Bodong Wang <bodong@mellanox.com>
commit 879c8f84e3602961e441723aaaac372a44dfe588
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/879c8f84.failed

With only PF and VF, it is sufficient to have the vport/rep array
index as the vport number. This is because PF and VF vports numbers
are consecutive serial numbers. In downstream patches with
introducing of ECPF and UPLINK vports, it's not consecutive any more.

Use getter to get specific vport/rep, and use iterator to traversal
a list of vport/rep. This hides the translation between array index
and vport number, and provides flexibility of using different
translation mechanism in the future.

This patch doesn't change any functionality.

	Signed-off-by: Bodong Wang <bodong@mellanox.com>
	Suggested-by: Saeed Mahameed <saeedm@mellanox.com>
	Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 879c8f84e3602961e441723aaaac372a44dfe588)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
index a13e7b20a794,4979c7ee0ad7..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@@ -54,6 -54,46 +54,49 @@@ enum 
  #define fdb_prio_table(esw, chain, prio, level) \
  	(esw)->fdb_table.offloads.fdb_prio[(chain)][(prio)][(level)]
  
++<<<<<<< HEAD
++=======
+ #define UPLINK_REP_INDEX 0
+ 
+ /* The rep getter/iterator are only valid after esw->total_vports
+  * and vport->vport are initialized in mlx5_eswitch_init.
+  */
+ #define mlx5_esw_for_all_reps(esw, i, rep)			\
+ 	for ((i) = MLX5_VPORT_PF;				\
+ 	     (rep) = &(esw)->offloads.vport_reps[i],		\
+ 	     (i) < (esw)->total_vports; (i)++)
+ 
+ #define mlx5_esw_for_each_vf_rep(esw, i, rep, nvfs)		\
+ 	for ((i) = MLX5_VPORT_FIRST_VF;				\
+ 	     (rep) = &(esw)->offloads.vport_reps[i],		\
+ 	     (i) <= (nvfs); (i)++)
+ 
+ #define mlx5_esw_for_each_vf_rep_reverse(esw, i, rep, nvfs)	\
+ 	for ((i) = (nvfs);					\
+ 	     (rep) = &(esw)->offloads.vport_reps[i],		\
+ 	     (i) >= MLX5_VPORT_FIRST_VF; (i)--)
+ 
+ #define mlx5_esw_for_each_vf_vport(esw, vport, nvfs)		\
+ 	for ((vport) = MLX5_VPORT_FIRST_VF;			\
+ 	     (vport) <= (nvfs); (vport)++)
+ 
+ #define mlx5_esw_for_each_vf_vport_reverse(esw, vport, nvfs)	\
+ 	for ((vport) = (nvfs);					\
+ 	     (vport) >= MLX5_VPORT_FIRST_VF; (vport)--)
+ 
+ static struct mlx5_eswitch_rep *mlx5_eswitch_get_rep(struct mlx5_eswitch *esw,
+ 						     u16 vport_num)
+ {
+ 	u16 idx = vport_num;
+ 
+ 	if (vport_num == MLX5_VPORT_UPLINK)
+ 		idx = UPLINK_REP_INDEX;
+ 
+ 	WARN_ON(idx > esw->total_vports - 1);
+ 	return &esw->offloads.vport_reps[idx];
+ }
+ 
++>>>>>>> 879c8f84e360 (net/mlx5: E-Switch, Use getter and iterator to access vport/rep)
  static struct mlx5_flow_table *
  esw_get_prio_table(struct mlx5_eswitch *esw, u32 chain, u16 prio, int level);
  static void
@@@ -1244,13 -1293,11 +1286,21 @@@ static void esw_offloads_unload_reps_ty
  	struct mlx5_eswitch_rep *rep;
  	int vport;
  
++<<<<<<< HEAD
 +	for (vport = nvports - 1; vport >= 0; vport--) {
 +		rep = &esw->offloads.vport_reps[vport];
 +		if (!rep->rep_if[rep_type].valid)
 +			continue;
 +
 +		rep->rep_if[rep_type].unload(rep);
 +	}
++=======
+ 	mlx5_esw_for_each_vf_rep_reverse(esw, vport, rep, nvports)
+ 		__esw_offloads_unload_rep(esw, rep, rep_type);
+ 
+ 	rep = mlx5_eswitch_get_rep(esw, MLX5_VPORT_UPLINK);
+ 	__esw_offloads_unload_rep(esw, rep, rep_type);
++>>>>>>> 879c8f84e360 (net/mlx5: E-Switch, Use getter and iterator to access vport/rep)
  }
  
  static void esw_offloads_unload_reps(struct mlx5_eswitch *esw, int nvports)
@@@ -1268,12 -1324,13 +1318,22 @@@ static int esw_offloads_load_reps_type(
  	int vport;
  	int err;
  
++<<<<<<< HEAD
 +	for (vport = 0; vport < nvports; vport++) {
 +		rep = &esw->offloads.vport_reps[vport];
 +		if (!rep->rep_if[rep_type].valid)
 +			continue;
 +
 +		err = rep->rep_if[rep_type].load(esw->dev, rep);
++=======
+ 	rep = mlx5_eswitch_get_rep(esw, MLX5_VPORT_UPLINK);
+ 	err = __esw_offloads_load_rep(esw, rep, rep_type);
+ 	if (err)
+ 		goto out;
+ 
+ 	mlx5_esw_for_each_vf_rep(esw, vport, rep, nvports) {
+ 		err = __esw_offloads_load_rep(esw, rep, rep_type);
++>>>>>>> 879c8f84e360 (net/mlx5: E-Switch, Use getter and iterator to access vport/rep)
  		if (err)
  			goto err_reps;
  	}
@@@ -1281,7 -1338,8 +1341,12 @@@
  	return 0;
  
  err_reps:
++<<<<<<< HEAD
 +	esw_offloads_unload_reps_type(esw, vport, rep_type);
++=======
+ 	esw_offloads_unload_reps_type(esw, --vport, rep_type);
+ out:
++>>>>>>> 879c8f84e360 (net/mlx5: E-Switch, Use getter and iterator to access vport/rep)
  	return err;
  }
  
@@@ -1819,11 -1882,9 +1884,14 @@@ EXPORT_SYMBOL(mlx5_eswitch_unregister_v
  
  void *mlx5_eswitch_get_uplink_priv(struct mlx5_eswitch *esw, u8 rep_type)
  {
++<<<<<<< HEAD
 +#define UPLINK_REP_INDEX 0
 +	struct mlx5_esw_offload *offloads = &esw->offloads;
++=======
++>>>>>>> 879c8f84e360 (net/mlx5: E-Switch, Use getter and iterator to access vport/rep)
  	struct mlx5_eswitch_rep *rep;
  
- 	rep = &offloads->vport_reps[UPLINK_REP_INDEX];
+ 	rep = mlx5_eswitch_get_rep(esw, MLX5_VPORT_UPLINK);
  	return rep->rep_if[rep_type].priv;
  }
  
@@@ -1831,13 -1892,9 +1899,16 @@@ void *mlx5_eswitch_get_proto_dev(struc
  				 int vport,
  				 u8 rep_type)
  {
- 	struct mlx5_esw_offload *offloads = &esw->offloads;
  	struct mlx5_eswitch_rep *rep;
  
++<<<<<<< HEAD
 +	if (vport == FDB_UPLINK_VPORT)
 +		vport = UPLINK_REP_INDEX;
 +
 +	rep = &offloads->vport_reps[vport];
++=======
+ 	rep = mlx5_eswitch_get_rep(esw, vport);
++>>>>>>> 879c8f84e360 (net/mlx5: E-Switch, Use getter and iterator to access vport/rep)
  
  	if (rep->rep_if[rep_type].valid &&
  	    rep->rep_if[rep_type].get_proto_dev)
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
index c2e828153dd7..d3a965699008 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@ -70,6 +70,26 @@ enum {
 			    MC_ADDR_CHANGE | \
 			    PROMISC_CHANGE)
 
+/* The vport getter/iterator are only valid after esw->total_vports
+ * and vport->vport are initialized in mlx5_eswitch_init.
+ */
+#define mlx5_esw_for_all_vports(esw, i, vport)			\
+	for ((i) = MLX5_VPORT_PF;				\
+	     (vport) = &(esw)->vports[i],			\
+	     (i) < (esw)->total_vports; (i)++)
+
+#define mlx5_esw_for_each_vf_vport(esw, i, vport, nvfs)	\
+	for ((i) = MLX5_VPORT_FIRST_VF;				\
+	     (vport) = &(esw)->vports[i],			\
+	     (i) <= (nvfs); (i)++)
+
+static struct mlx5_vport *mlx5_eswitch_get_vport(struct mlx5_eswitch *esw,
+						 u16 vport_num)
+{
+	WARN_ON(vport_num > esw->total_vports - 1);
+	return &esw->vports[vport_num];
+}
+
 static int arm_vport_context_events_cmd(struct mlx5_core_dev *dev, u16 vport,
 					u32 events_mask)
 {
@@ -436,17 +456,18 @@ static void update_allmulti_vports(struct mlx5_eswitch *esw,
 				   struct esw_mc_addr *esw_mc)
 {
 	u8 *mac = vaddr->node.addr;
-	u16 vport_idx = 0;
+	struct mlx5_vport *vport;
+	u16 i, vport_num;
 
-	for (vport_idx = 0; vport_idx < esw->total_vports; vport_idx++) {
-		struct mlx5_vport *vport = &esw->vports[vport_idx];
+	mlx5_esw_for_all_vports(esw, i, vport) {
 		struct hlist_head *vport_hash = vport->mc_list;
 		struct vport_addr *iter_vaddr =
 					l2addr_hash_find(vport_hash,
 							 mac,
 							 struct vport_addr);
+		vport_num = vport->vport;
 		if (IS_ERR_OR_NULL(vport->allmulti_rule) ||
-		    vaddr->vport == vport_idx)
+		    vaddr->vport == vport_num)
 			continue;
 		switch (vaddr->action) {
 		case MLX5_ACTION_ADD:
@@ -458,14 +479,14 @@ static void update_allmulti_vports(struct mlx5_eswitch *esw,
 			if (!iter_vaddr) {
 				esw_warn(esw->dev,
 					 "ALL-MULTI: Failed to add MAC(%pM) to vport[%d] DB\n",
-					 mac, vport_idx);
+					 mac, vport_num);
 				continue;
 			}
-			iter_vaddr->vport = vport_idx;
+			iter_vaddr->vport = vport_num;
 			iter_vaddr->flow_rule =
 					esw_fdb_set_vport_rule(esw,
 							       mac,
-							       vport_idx);
+							       vport_num);
 			iter_vaddr->mc_promisc = true;
 			break;
 		case MLX5_ACTION_DEL:
@@ -564,7 +585,7 @@ static int esw_del_mc_addr(struct mlx5_eswitch *esw, struct vport_addr *vaddr)
 static void esw_apply_vport_addr_list(struct mlx5_eswitch *esw,
 				      u16 vport_num, int list_type)
 {
-	struct mlx5_vport *vport = &esw->vports[vport_num];
+	struct mlx5_vport *vport = mlx5_eswitch_get_vport(esw, vport_num);
 	bool is_uc = list_type == MLX5_NVPRT_LIST_TYPE_UC;
 	vport_addr_action vport_addr_add;
 	vport_addr_action vport_addr_del;
@@ -599,7 +620,7 @@ static void esw_apply_vport_addr_list(struct mlx5_eswitch *esw,
 static void esw_update_vport_addr_list(struct mlx5_eswitch *esw,
 				       u16 vport_num, int list_type)
 {
-	struct mlx5_vport *vport = &esw->vports[vport_num];
+	struct mlx5_vport *vport = mlx5_eswitch_get_vport(esw, vport_num);
 	bool is_uc = list_type == MLX5_NVPRT_LIST_TYPE_UC;
 	u8 (*mac_list)[ETH_ALEN];
 	struct l2addr_node *node;
@@ -686,7 +707,7 @@ static void esw_update_vport_addr_list(struct mlx5_eswitch *esw,
  */
 static void esw_update_vport_mc_promisc(struct mlx5_eswitch *esw, u16 vport_num)
 {
-	struct mlx5_vport *vport = &esw->vports[vport_num];
+	struct mlx5_vport *vport = mlx5_eswitch_get_vport(esw, vport_num);
 	struct l2addr_node *node;
 	struct vport_addr *addr;
 	struct hlist_head *hash;
@@ -722,8 +743,8 @@ static void esw_update_vport_mc_promisc(struct mlx5_eswitch *esw, u16 vport_num)
 static void esw_apply_vport_rx_mode(struct mlx5_eswitch *esw, u16 vport_num,
 				    bool promisc, bool mc_promisc)
 {
+	struct mlx5_vport *vport = mlx5_eswitch_get_vport(esw, vport_num);
 	struct esw_mc_addr *allmulti_addr = &esw->mc_promisc;
-	struct mlx5_vport *vport = &esw->vports[vport_num];
 
 	if (IS_ERR_OR_NULL(vport->allmulti_rule) != mc_promisc)
 		goto promisc;
@@ -764,7 +785,7 @@ static void esw_apply_vport_rx_mode(struct mlx5_eswitch *esw, u16 vport_num,
 /* Sync vport rx mode from vport context */
 static void esw_update_vport_rx_mode(struct mlx5_eswitch *esw, u16 vport_num)
 {
-	struct mlx5_vport *vport = &esw->vports[vport_num];
+	struct mlx5_vport *vport = mlx5_eswitch_get_vport(esw, vport_num);
 	int promisc_all = 0;
 	int promisc_uc = 0;
 	int promisc_mc = 0;
@@ -1341,8 +1362,8 @@ static void esw_destroy_tsar(struct mlx5_eswitch *esw)
 static int esw_vport_enable_qos(struct mlx5_eswitch *esw, int vport_num,
 				u32 initial_max_rate, u32 initial_bw_share)
 {
+	struct mlx5_vport *vport = mlx5_eswitch_get_vport(esw, vport_num);
 	u32 sched_ctx[MLX5_ST_SZ_DW(scheduling_context)] = {0};
-	struct mlx5_vport *vport = &esw->vports[vport_num];
 	struct mlx5_core_dev *dev = esw->dev;
 	void *vport_elem;
 	int err = 0;
@@ -1381,7 +1402,7 @@ static int esw_vport_enable_qos(struct mlx5_eswitch *esw, int vport_num,
 
 static void esw_vport_disable_qos(struct mlx5_eswitch *esw, int vport_num)
 {
-	struct mlx5_vport *vport = &esw->vports[vport_num];
+	struct mlx5_vport *vport = mlx5_eswitch_get_vport(esw, vport_num);
 	int err = 0;
 
 	if (!vport->qos.enabled)
@@ -1400,8 +1421,8 @@ static void esw_vport_disable_qos(struct mlx5_eswitch *esw, int vport_num)
 static int esw_vport_qos_config(struct mlx5_eswitch *esw, int vport_num,
 				u32 max_rate, u32 bw_share)
 {
+	struct mlx5_vport *vport = mlx5_eswitch_get_vport(esw, vport_num);
 	u32 sched_ctx[MLX5_ST_SZ_DW(scheduling_context)] = {0};
-	struct mlx5_vport *vport = &esw->vports[vport_num];
 	struct mlx5_core_dev *dev = esw->dev;
 	void *vport_elem;
 	u32 bitmask = 0;
@@ -1511,10 +1532,10 @@ static void esw_vport_destroy_drop_counters(struct mlx5_vport *vport)
 		mlx5_fc_destroy(dev, vport->egress.drop_counter);
 }
 
-static void esw_enable_vport(struct mlx5_eswitch *esw, int vport_num,
+static void esw_enable_vport(struct mlx5_eswitch *esw, struct mlx5_vport *vport,
 			     int enable_events)
 {
-	struct mlx5_vport *vport = &esw->vports[vport_num];
+	u16 vport_num = vport->vport;
 
 	mutex_lock(&esw->state_lock);
 	WARN_ON(vport->enabled);
@@ -1548,9 +1569,10 @@ static void esw_enable_vport(struct mlx5_eswitch *esw, int vport_num,
 	mutex_unlock(&esw->state_lock);
 }
 
-static void esw_disable_vport(struct mlx5_eswitch *esw, int vport_num)
+static void esw_disable_vport(struct mlx5_eswitch *esw,
+			      struct mlx5_vport *vport)
 {
-	struct mlx5_vport *vport = &esw->vports[vport_num];
+	u16 vport_num = vport->vport;
 
 	if (!vport->enabled)
 		return;
@@ -1593,7 +1615,7 @@ static int eswitch_vport_event(struct notifier_block *nb,
 	u16 vport_num;
 
 	vport_num = be16_to_cpu(eqe->data.vport_change.vport_num);
-	vport = &esw->vports[vport_num];
+	vport = mlx5_eswitch_get_vport(esw, vport_num);
 	if (vport->enabled)
 		queue_work(esw->work_queue, &vport->vport_change_handler);
 
@@ -1605,6 +1627,7 @@ static int eswitch_vport_event(struct notifier_block *nb,
 
 int mlx5_eswitch_enable_sriov(struct mlx5_eswitch *esw, int nvfs, int mode)
 {
+	struct mlx5_vport *vport;
 	int err;
 	int i, enabled_events;
 
@@ -1646,8 +1669,14 @@ int mlx5_eswitch_enable_sriov(struct mlx5_eswitch *esw, int nvfs, int mode)
 	 * 2. FDB/Eswitch is programmed by user space tools
 	 */
 	enabled_events = (mode == SRIOV_LEGACY) ? SRIOV_VPORT_EVENTS : 0;
-	for (i = 0; i <= nvfs; i++)
-		esw_enable_vport(esw, i, enabled_events);
+
+	/* Enable PF vport */
+	vport = mlx5_eswitch_get_vport(esw, MLX5_VPORT_PF);
+	esw_enable_vport(esw, vport, enabled_events);
+
+	/* Enable VF vports */
+	mlx5_esw_for_each_vf_vport(esw, i, vport, nvfs)
+		esw_enable_vport(esw, vport, enabled_events);
 
 	if (mode == SRIOV_LEGACY) {
 		MLX5_NB_INIT(&esw->nb, eswitch_vport_event, NIC_VPORT_CHANGE);
@@ -1672,6 +1701,7 @@ int mlx5_eswitch_enable_sriov(struct mlx5_eswitch *esw, int nvfs, int mode)
 void mlx5_eswitch_disable_sriov(struct mlx5_eswitch *esw)
 {
 	struct esw_mc_addr *mc_promisc;
+	struct mlx5_vport *vport;
 	int old_mode;
 	int nvports;
 	int i;
@@ -1688,8 +1718,8 @@ void mlx5_eswitch_disable_sriov(struct mlx5_eswitch *esw)
 	if (esw->mode == SRIOV_LEGACY)
 		mlx5_eq_notifier_unregister(esw->dev, &esw->nb);
 
-	for (i = 0; i < esw->total_vports; i++)
-		esw_disable_vport(esw, i);
+	mlx5_esw_for_all_vports(esw, i, vport)
+		esw_disable_vport(esw, vport);
 
 	if (mc_promisc && mc_promisc->uplink_rule)
 		mlx5_del_flow_rules(mc_promisc->uplink_rule);
@@ -1716,6 +1746,7 @@ int mlx5_eswitch_init(struct mlx5_core_dev *dev)
 {
 	int total_vports = MLX5_TOTAL_VPORTS(dev);
 	struct mlx5_eswitch *esw;
+	struct mlx5_vport *vport;
 	int vport_num;
 	int err;
 
@@ -1747,6 +1778,8 @@ int mlx5_eswitch_init(struct mlx5_core_dev *dev)
 		goto abort;
 	}
 
+	esw->total_vports = total_vports;
+
 	err = esw_offloads_init_reps(esw);
 	if (err)
 		goto abort;
@@ -1755,9 +1788,7 @@ int mlx5_eswitch_init(struct mlx5_core_dev *dev)
 	hash_init(esw->offloads.mod_hdr_tbl);
 	mutex_init(&esw->state_lock);
 
-	for (vport_num = 0; vport_num < total_vports; vport_num++) {
-		struct mlx5_vport *vport = &esw->vports[vport_num];
-
+	mlx5_esw_for_all_vports(esw, vport_num, vport) {
 		vport->vport = vport_num;
 		vport->info.link_state = MLX5_VPORT_ADMIN_STATE_AUTO;
 		vport->dev = dev;
@@ -1765,7 +1796,6 @@ int mlx5_eswitch_init(struct mlx5_core_dev *dev)
 			  esw_vport_change_handler);
 	}
 
-	esw->total_vports = total_vports;
 	esw->enabled_vports = 0;
 	esw->mode = SRIOV_NONE;
 	esw->offloads.inline_mode = MLX5_INLINE_MODE_NONE;
@@ -2007,8 +2037,7 @@ static u32 calculate_vports_min_rate_divider(struct mlx5_eswitch *esw)
 	u32 max_guarantee = 0;
 	int i;
 
-	for (i = 0; i < esw->total_vports; i++) {
-		evport = &esw->vports[i];
+	mlx5_esw_for_all_vports(esw, i, evport) {
 		if (!evport->enabled || evport->info.min_rate < max_guarantee)
 			continue;
 		max_guarantee = evport->info.min_rate;
@@ -2027,8 +2056,7 @@ static int normalize_vports_min_rate(struct mlx5_eswitch *esw, u32 divider)
 	int err;
 	int i;
 
-	for (i = 0; i < esw->total_vports; i++) {
-		evport = &esw->vports[i];
+	mlx5_esw_for_all_vports(esw, i, evport) {
 		if (!evport->enabled)
 			continue;
 		vport_min_rate = evport->info.min_rate;
@@ -2043,7 +2071,7 @@ static int normalize_vports_min_rate(struct mlx5_eswitch *esw, u32 divider)
 		if (bw_share == evport->qos.bw_share)
 			continue;
 
-		err = esw_vport_qos_config(esw, i, vport_max_rate,
+		err = esw_vport_qos_config(esw, evport->vport, vport_max_rate,
 					   bw_share);
 		if (!err)
 			evport->qos.bw_share = bw_share;
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
