mm/memremap: Fix reuse of pgmap instances with internal references

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [mm] memremap: Fix reuse of pgmap instances with internal references (Don Dutile) [1754737]
Rebuild_FUZZ: 97.67%
commit-author Dan Williams <dan.j.williams@intel.com>
commit 06282373ff57a2b82621be4f84f981e1b0a4eb28
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/06282373.failed

Currently, attempts to shutdown and re-enable a device-dax instance
trigger:

    Missing reference count teardown definition
    WARNING: CPU: 37 PID: 1608 at mm/memremap.c:211 devm_memremap_pages+0x234/0x850
    [..]
    RIP: 0010:devm_memremap_pages+0x234/0x850
    [..]
    Call Trace:
     dev_dax_probe+0x66/0x190 [device_dax]
     really_probe+0xef/0x390
     driver_probe_device+0xb4/0x100
     device_driver_attach+0x4f/0x60

Given that the setup path initializes pgmap->ref, arrange for it to be
also torn down so devm_memremap_pages() is ready to be called again and
not be mistaken for the 3rd-party per-cpu-ref case.

Fixes: 24917f6b1041 ("memremap: provide an optional internal refcount in struct dev_pagemap")
	Reported-by: Fan Du <fan.du@intel.com>
	Tested-by: Vishal Verma <vishal.l.verma@intel.com>
	Cc: Andrew Morton <akpm@linux-foundation.org>
	Cc: Christoph Hellwig <hch@lst.de>
	Cc: Ira Weiny <ira.weiny@intel.com>
	Cc: Jason Gunthorpe <jgg@mellanox.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
Link: https://lore.kernel.org/r/156530042781.2068700.8733813683117819799.stgit@dwillia2-desk3.amr.corp.intel.com
	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
(cherry picked from commit 06282373ff57a2b82621be4f84f981e1b0a4eb28)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/memremap.c
diff --cc kernel/memremap.c
index 794888559eb7,86432650f829..000000000000
--- a/kernel/memremap.c
+++ b/kernel/memremap.c
@@@ -113,6 -75,30 +113,33 @@@ static unsigned long pfn_next(unsigned 
  #define for_each_device_pfn(pfn, map) \
  	for (pfn = pfn_first(map); pfn < pfn_end(map); pfn = pfn_next(pfn))
  
++<<<<<<< HEAD:kernel/memremap.c
++=======
+ static void dev_pagemap_kill(struct dev_pagemap *pgmap)
+ {
+ 	if (pgmap->ops && pgmap->ops->kill)
+ 		pgmap->ops->kill(pgmap);
+ 	else
+ 		percpu_ref_kill(pgmap->ref);
+ }
+ 
+ static void dev_pagemap_cleanup(struct dev_pagemap *pgmap)
+ {
+ 	if (pgmap->ops && pgmap->ops->cleanup) {
+ 		pgmap->ops->cleanup(pgmap);
+ 	} else {
+ 		wait_for_completion(&pgmap->done);
+ 		percpu_ref_exit(pgmap->ref);
+ 	}
+ 	/*
+ 	 * Undo the pgmap ref assignment for the internal case as the
+ 	 * caller may re-enable the same pgmap.
+ 	 */
+ 	if (pgmap->ref == &pgmap->internal_ref)
+ 		pgmap->ref = NULL;
+ }
+ 
++>>>>>>> 06282373ff57 (mm/memremap: Fix reuse of pgmap instances with internal references):mm/memremap.c
  static void devm_memremap_pages_release(void *data)
  {
  	struct dev_pagemap *pgmap = data;
* Unmerged path kernel/memremap.c
