net/mlx5e: Support LAG TX port affinity distribution

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [netdrv] mlx5e: Support LAG TX port affinity distribution (Alaa Hleihel) [1760285 1724336]
Rebuild_FUZZ: 96.00%
commit-author Maxim Mikityanskiy <maximmi@mellanox.com>
commit 45f171b1182b9c4ab6d854d6f7fd7dd771fed591
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/45f171b1.failed

When the VF LAG is in use, round-robin the TX affinity of channels among
the different ports, if supported by the firmware. Create a set of TISes
per port, while doing round-robin of the channels over the different
sets. Let all SQs of a channel share the same set of TISes.

If lag_tx_port_affinity HCA cap bit is supported, num_lag_ports > 1 and
we aren't the LACP owner (PF in the regular use), assign the affinities,
otherwise use tx_affinity == 0 in TIS context to let the FW assign the
affinities itself. The TISes of the LACP owner are mapped only to the
native physical port.

For VFs, the starting port for round-robin is determined by its vhca_id,
because a VF may have only one channel if attached to a single-core VM.

	Signed-off-by: Maxim Mikityanskiy <maximmi@mellanox.com>
	Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
	Signed-off-by: Mark Bloch <markb@mellanox.com>
	Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 45f171b1182b9c4ab6d854d6f7fd7dd771fed591)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_main.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index 50379aaf9f9f,2786f5b8057d..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@@ -1641,12 -1687,12 +1641,12 @@@ static int mlx5e_open_sqs(struct mlx5e_
  			  struct mlx5e_channel_param *cparam)
  {
  	struct mlx5e_priv *priv = c->priv;
 -	int err, tc;
 +	int err, tc, max_nch = mlx5e_get_netdev_max_channels(priv->netdev);
  
  	for (tc = 0; tc < params->num_tc; tc++) {
 -		int txq_ix = c->ix + tc * priv->max_nch;
 +		int txq_ix = c->ix + tc * max_nch;
  
- 		err = mlx5e_open_txqsq(c, c->priv->tisn[tc], txq_ix,
+ 		err = mlx5e_open_txqsq(c, c->priv->tisn[c->lag_port][tc], txq_ix,
  				       params, &cparam->sq, &c->sq[tc], tc);
  		if (err)
  			goto err_close_sqs;
@@@ -1894,6 -1906,93 +1894,96 @@@ err_close_tx_cqs
  err_close_icosq_cq:
  	mlx5e_close_cq(&c->icosq.cq);
  
++<<<<<<< HEAD
++=======
+ 	return err;
+ }
+ 
+ static void mlx5e_close_queues(struct mlx5e_channel *c)
+ {
+ 	mlx5e_close_xdpsq(&c->xdpsq);
+ 	mlx5e_close_rq(&c->rq);
+ 	if (c->xdp)
+ 		mlx5e_close_xdpsq(&c->rq_xdpsq);
+ 	mlx5e_close_sqs(c);
+ 	mlx5e_close_icosq(&c->icosq);
+ 	napi_disable(&c->napi);
+ 	if (c->xdp)
+ 		mlx5e_close_cq(&c->rq_xdpsq.cq);
+ 	mlx5e_close_cq(&c->rq.cq);
+ 	mlx5e_close_cq(&c->xdpsq.cq);
+ 	mlx5e_close_tx_cqs(c);
+ 	mlx5e_close_cq(&c->icosq.cq);
+ }
+ 
+ static u8 mlx5e_enumerate_lag_port(struct mlx5_core_dev *mdev, int ix)
+ {
+ 	u16 port_aff_bias = mlx5_core_is_pf(mdev) ? 0 : MLX5_CAP_GEN(mdev, vhca_id);
+ 
+ 	return (ix + port_aff_bias) % mlx5e_get_num_lag_ports(mdev);
+ }
+ 
+ static int mlx5e_open_channel(struct mlx5e_priv *priv, int ix,
+ 			      struct mlx5e_params *params,
+ 			      struct mlx5e_channel_param *cparam,
+ 			      struct xdp_umem *umem,
+ 			      struct mlx5e_channel **cp)
+ {
+ 	int cpu = cpumask_first(mlx5_comp_irq_get_affinity_mask(priv->mdev, ix));
+ 	struct net_device *netdev = priv->netdev;
+ 	struct mlx5e_xsk_param xsk;
+ 	struct mlx5e_channel *c;
+ 	unsigned int irq;
+ 	int err;
+ 	int eqn;
+ 
+ 	err = mlx5_vector2eqn(priv->mdev, ix, &eqn, &irq);
+ 	if (err)
+ 		return err;
+ 
+ 	c = kvzalloc_node(sizeof(*c), GFP_KERNEL, cpu_to_node(cpu));
+ 	if (!c)
+ 		return -ENOMEM;
+ 
+ 	c->priv     = priv;
+ 	c->mdev     = priv->mdev;
+ 	c->tstamp   = &priv->tstamp;
+ 	c->ix       = ix;
+ 	c->cpu      = cpu;
+ 	c->pdev     = priv->mdev->device;
+ 	c->netdev   = priv->netdev;
+ 	c->mkey_be  = cpu_to_be32(priv->mdev->mlx5e_res.mkey.key);
+ 	c->num_tc   = params->num_tc;
+ 	c->xdp      = !!params->xdp_prog;
+ 	c->stats    = &priv->channel_stats[ix].ch;
+ 	c->irq_desc = irq_to_desc(irq);
+ 	c->lag_port = mlx5e_enumerate_lag_port(priv->mdev, ix);
+ 
+ 	err = mlx5e_alloc_xps_cpumask(c, params);
+ 	if (err)
+ 		goto err_free_channel;
+ 
+ 	netif_napi_add(netdev, &c->napi, mlx5e_napi_poll, 64);
+ 
+ 	err = mlx5e_open_queues(c, params, cparam);
+ 	if (unlikely(err))
+ 		goto err_napi_del;
+ 
+ 	if (umem) {
+ 		mlx5e_build_xsk_param(umem, &xsk);
+ 		err = mlx5e_open_xsk(priv, params, &xsk, umem, c);
+ 		if (unlikely(err))
+ 			goto err_close_queues;
+ 	}
+ 
+ 	*cp = c;
+ 
+ 	return 0;
+ 
+ err_close_queues:
+ 	mlx5e_close_queues(c);
+ 
++>>>>>>> 45f171b1182b (net/mlx5e: Support LAG TX port affinity distribution)
  err_napi_del:
  	netif_napi_del(&c->napi);
  	mlx5e_free_xps_cpumask(c);
@@@ -3069,22 -3187,41 +3159,44 @@@ void mlx5e_destroy_tis(struct mlx5_core
  	mlx5_core_destroy_tis(mdev, tisn);
  }
  
++<<<<<<< HEAD
++=======
+ void mlx5e_destroy_tises(struct mlx5e_priv *priv)
+ {
+ 	int tc, i;
+ 
+ 	for (i = 0; i < mlx5e_get_num_lag_ports(priv->mdev); i++)
+ 		for (tc = 0; tc < priv->profile->max_tc; tc++)
+ 			mlx5e_destroy_tis(priv->mdev, priv->tisn[i][tc]);
+ }
+ 
+ static bool mlx5e_lag_should_assign_affinity(struct mlx5_core_dev *mdev)
+ {
+ 	return MLX5_CAP_GEN(mdev, lag_tx_port_affinity) && mlx5e_get_num_lag_ports(mdev) > 1;
+ }
+ 
++>>>>>>> 45f171b1182b (net/mlx5e: Support LAG TX port affinity distribution)
  int mlx5e_create_tises(struct mlx5e_priv *priv)
  {
+ 	int tc, i;
  	int err;
- 	int tc;
  
- 	for (tc = 0; tc < priv->profile->max_tc; tc++) {
- 		u32 in[MLX5_ST_SZ_DW(create_tis_in)] = {};
- 		void *tisc;
+ 	for (i = 0; i < mlx5e_get_num_lag_ports(priv->mdev); i++) {
+ 		for (tc = 0; tc < priv->profile->max_tc; tc++) {
+ 			u32 in[MLX5_ST_SZ_DW(create_tis_in)] = {};
+ 			void *tisc;
  
- 		tisc = MLX5_ADDR_OF(create_tis_in, in, ctx);
+ 			tisc = MLX5_ADDR_OF(create_tis_in, in, ctx);
  
- 		MLX5_SET(tisc, tisc, prio, tc << 1);
+ 			MLX5_SET(tisc, tisc, prio, tc << 1);
  
- 		err = mlx5e_create_tis(priv->mdev, in, &priv->tisn[tc]);
- 		if (err)
- 			goto err_close_tises;
+ 			if (mlx5e_lag_should_assign_affinity(priv->mdev))
+ 				MLX5_SET(tisc, tisc, lag_tx_port_affinity, i + 1);
+ 
+ 			err = mlx5e_create_tis(priv->mdev, in, &priv->tisn[i][tc]);
+ 			if (err)
+ 				goto err_close_tises;
+ 		}
  	}
  
  	return 0;
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en.h b/drivers/net/ethernet/mellanox/mlx5/core/en.h
index 1599dd95552b..bba2886a69dd 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en.h
@@ -156,6 +156,14 @@ do {                                                            \
 } while (0)
 
 
+static inline u8 mlx5e_get_num_lag_ports(struct mlx5_core_dev *mdev)
+{
+	if (mlx5_lag_is_lacp_owner(mdev))
+		return 1;
+
+	return clamp_t(u8, MLX5_CAP_GEN(mdev, num_lag_ports), 1, MLX5_MAX_PORTS);
+}
+
 static inline u16 mlx5_min_rx_wqes(int wq_type, u32 wq_size)
 {
 	switch (wq_type) {
@@ -668,6 +676,7 @@ struct mlx5e_channel {
 	struct net_device         *netdev;
 	__be32                     mkey_be;
 	u8                         num_tc;
+	u8                         lag_port;
 
 	/* XDP_REDIRECT */
 	struct mlx5e_xdpsq         xdpsq;
@@ -750,7 +759,7 @@ struct mlx5e_priv {
 	struct mlx5e_rq            drop_rq;
 
 	struct mlx5e_channels      channels;
-	u32                        tisn[MLX5E_MAX_NUM_TC];
+	u32                        tisn[MLX5_MAX_PORTS][MLX5E_MAX_NUM_TC];
 	struct mlx5e_rqt           indir_rqt;
 	struct mlx5e_tir           indir_tir[MLX5E_NUM_INDIR_TIRS];
 	struct mlx5e_tir           inner_indir_tir[MLX5E_NUM_INDIR_TIRS];
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_main.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/ipoib/ipoib.c b/drivers/net/ethernet/mellanox/mlx5/core/ipoib/ipoib.c
index e01a916f296c..8db470d7538d 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/ipoib/ipoib.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/ipoib/ipoib.c
@@ -281,7 +281,7 @@ static int mlx5i_init_tx(struct mlx5e_priv *priv)
 		return err;
 	}
 
-	err = mlx5i_create_tis(priv->mdev, ipriv->qp.qpn, &priv->tisn[0]);
+	err = mlx5i_create_tis(priv->mdev, ipriv->qp.qpn, &priv->tisn[0][0]);
 	if (err) {
 		mlx5_core_warn(priv->mdev, "create tis failed, %d\n", err);
 		goto err_destroy_underlay_qp;
@@ -298,7 +298,7 @@ static void mlx5i_cleanup_tx(struct mlx5e_priv *priv)
 {
 	struct mlx5i_priv *ipriv = priv->ppriv;
 
-	mlx5e_destroy_tis(priv->mdev, priv->tisn[0]);
+	mlx5e_destroy_tis(priv->mdev, priv->tisn[0][0]);
 	mlx5i_destroy_underlay_qp(priv->mdev, &ipriv->qp);
 }
 
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/ipoib/ipoib_vlan.c b/drivers/net/ethernet/mellanox/mlx5/core/ipoib/ipoib_vlan.c
index 59bc29fec576..381f8294b14b 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/ipoib/ipoib_vlan.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/ipoib/ipoib_vlan.c
@@ -210,7 +210,7 @@ static int mlx5i_pkey_open(struct net_device *netdev)
 		goto err_unint_underlay_qp;
 	}
 
-	err = mlx5i_create_tis(mdev, ipriv->qp.qpn, &epriv->tisn[0]);
+	err = mlx5i_create_tis(mdev, ipriv->qp.qpn, &epriv->tisn[0][0]);
 	if (err) {
 		mlx5_core_warn(mdev, "create child tis failed, %d\n", err);
 		goto err_remove_rx_uderlay_qp;
@@ -228,7 +228,7 @@ static int mlx5i_pkey_open(struct net_device *netdev)
 	return 0;
 
 err_clear_state_opened_flag:
-	mlx5e_destroy_tis(mdev, epriv->tisn[0]);
+	mlx5e_destroy_tis(mdev, epriv->tisn[0][0]);
 err_remove_rx_uderlay_qp:
 	mlx5_fs_remove_rx_underlay_qpn(mdev, ipriv->qp.qpn);
 err_unint_underlay_qp:
@@ -257,7 +257,7 @@ static int mlx5i_pkey_close(struct net_device *netdev)
 	mlx5i_uninit_underlay_qp(priv);
 	mlx5e_deactivate_priv_channels(priv);
 	mlx5e_close_channels(&priv->channels);
-	mlx5e_destroy_tis(mdev, priv->tisn[0]);
+	mlx5e_destroy_tis(mdev, priv->tisn[0][0]);
 unlock:
 	mutex_unlock(&priv->state_lock);
 	return 0;
