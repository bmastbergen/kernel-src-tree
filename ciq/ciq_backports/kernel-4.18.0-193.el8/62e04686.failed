genirq: Add optional hardware synchronization for shutdown

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 62e0468650c30f0298822c580f382b16328119f6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/62e04686.failed

free_irq() ensures that no hardware interrupt handler is executing on a
different CPU before actually releasing resources and deactivating the
interrupt completely in a domain hierarchy.

But that does not catch the case where the interrupt is on flight at the
hardware level but not yet serviced by the target CPU. That creates an
interesing race condition:

   CPU 0                  CPU 1               IRQ CHIP

                                              interrupt is raised
                                              sent to CPU1
			  Unable to handle
			  immediately
			  (interrupts off,
			   deep idle delay)
   mask()
   ...
   free()
     shutdown()
     synchronize_irq()
     release_resources()
                          do_IRQ()
                            -> resources are not available

That might be harmless and just trigger a spurious interrupt warning, but
some interrupt chips might get into a wedged state.

Utilize the existing irq_get_irqchip_state() callback for the
synchronization in free_irq().

synchronize_hardirq() is not using this mechanism as it might actually
deadlock unter certain conditions, e.g. when called with interrupts
disabled and the target CPU is the one on which the synchronization is
invoked. synchronize_irq() uses it because that function cannot be called
from non preemtible contexts as it might sleep.

No functional change intended and according to Marc the existing GIC
implementations where the driver supports the callback should be able
to cope with that core change. Famous last words.

Fixes: 464d12309e1b ("x86/vector: Switch IOAPIC to global reservation mode")
	Reported-by: Robert Hodaszi <Robert.Hodaszi@digi.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
	Tested-by: Marc Zyngier <marc.zyngier@arm.com>
Link: https://lkml.kernel.org/r/20190628111440.279463375@linutronix.de

(cherry picked from commit 62e0468650c30f0298822c580f382b16328119f6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/irq/manage.c
diff --cc kernel/irq/manage.c
index f25540845c73,fad61986f35c..000000000000
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@@ -2170,6 -2466,180 +2198,183 @@@ int __request_percpu_irq(unsigned int i
  EXPORT_SYMBOL_GPL(__request_percpu_irq);
  
  /**
++<<<<<<< HEAD
++=======
+  *	request_percpu_nmi - allocate a percpu interrupt line for NMI delivery
+  *	@irq: Interrupt line to allocate
+  *	@handler: Function to be called when the IRQ occurs.
+  *	@name: An ascii name for the claiming device
+  *	@dev_id: A percpu cookie passed back to the handler function
+  *
+  *	This call allocates interrupt resources for a per CPU NMI. Per CPU NMIs
+  *	have to be setup on each CPU by calling prepare_percpu_nmi() before
+  *	being enabled on the same CPU by using enable_percpu_nmi().
+  *
+  *	Dev_id must be globally unique. It is a per-cpu variable, and
+  *	the handler gets called with the interrupted CPU's instance of
+  *	that variable.
+  *
+  *	Interrupt lines requested for NMI delivering should have auto enabling
+  *	setting disabled.
+  *
+  *	If the interrupt line cannot be used to deliver NMIs, function
+  *	will fail returning a negative value.
+  */
+ int request_percpu_nmi(unsigned int irq, irq_handler_t handler,
+ 		       const char *name, void __percpu *dev_id)
+ {
+ 	struct irqaction *action;
+ 	struct irq_desc *desc;
+ 	unsigned long flags;
+ 	int retval;
+ 
+ 	if (!handler)
+ 		return -EINVAL;
+ 
+ 	desc = irq_to_desc(irq);
+ 
+ 	if (!desc || !irq_settings_can_request(desc) ||
+ 	    !irq_settings_is_per_cpu_devid(desc) ||
+ 	    irq_settings_can_autoenable(desc) ||
+ 	    !irq_supports_nmi(desc))
+ 		return -EINVAL;
+ 
+ 	/* The line cannot already be NMI */
+ 	if (desc->istate & IRQS_NMI)
+ 		return -EINVAL;
+ 
+ 	action = kzalloc(sizeof(struct irqaction), GFP_KERNEL);
+ 	if (!action)
+ 		return -ENOMEM;
+ 
+ 	action->handler = handler;
+ 	action->flags = IRQF_PERCPU | IRQF_NO_SUSPEND | IRQF_NO_THREAD
+ 		| IRQF_NOBALANCING;
+ 	action->name = name;
+ 	action->percpu_dev_id = dev_id;
+ 
+ 	retval = irq_chip_pm_get(&desc->irq_data);
+ 	if (retval < 0)
+ 		goto err_out;
+ 
+ 	retval = __setup_irq(irq, desc, action);
+ 	if (retval)
+ 		goto err_irq_setup;
+ 
+ 	raw_spin_lock_irqsave(&desc->lock, flags);
+ 	desc->istate |= IRQS_NMI;
+ 	raw_spin_unlock_irqrestore(&desc->lock, flags);
+ 
+ 	return 0;
+ 
+ err_irq_setup:
+ 	irq_chip_pm_put(&desc->irq_data);
+ err_out:
+ 	kfree(action);
+ 
+ 	return retval;
+ }
+ 
+ /**
+  *	prepare_percpu_nmi - performs CPU local setup for NMI delivery
+  *	@irq: Interrupt line to prepare for NMI delivery
+  *
+  *	This call prepares an interrupt line to deliver NMI on the current CPU,
+  *	before that interrupt line gets enabled with enable_percpu_nmi().
+  *
+  *	As a CPU local operation, this should be called from non-preemptible
+  *	context.
+  *
+  *	If the interrupt line cannot be used to deliver NMIs, function
+  *	will fail returning a negative value.
+  */
+ int prepare_percpu_nmi(unsigned int irq)
+ {
+ 	unsigned long flags;
+ 	struct irq_desc *desc;
+ 	int ret = 0;
+ 
+ 	WARN_ON(preemptible());
+ 
+ 	desc = irq_get_desc_lock(irq, &flags,
+ 				 IRQ_GET_DESC_CHECK_PERCPU);
+ 	if (!desc)
+ 		return -EINVAL;
+ 
+ 	if (WARN(!(desc->istate & IRQS_NMI),
+ 		 KERN_ERR "prepare_percpu_nmi called for a non-NMI interrupt: irq %u\n",
+ 		 irq)) {
+ 		ret = -EINVAL;
+ 		goto out;
+ 	}
+ 
+ 	ret = irq_nmi_setup(desc);
+ 	if (ret) {
+ 		pr_err("Failed to setup NMI delivery: irq %u\n", irq);
+ 		goto out;
+ 	}
+ 
+ out:
+ 	irq_put_desc_unlock(desc, flags);
+ 	return ret;
+ }
+ 
+ /**
+  *	teardown_percpu_nmi - undoes NMI setup of IRQ line
+  *	@irq: Interrupt line from which CPU local NMI configuration should be
+  *	      removed
+  *
+  *	This call undoes the setup done by prepare_percpu_nmi().
+  *
+  *	IRQ line should not be enabled for the current CPU.
+  *
+  *	As a CPU local operation, this should be called from non-preemptible
+  *	context.
+  */
+ void teardown_percpu_nmi(unsigned int irq)
+ {
+ 	unsigned long flags;
+ 	struct irq_desc *desc;
+ 
+ 	WARN_ON(preemptible());
+ 
+ 	desc = irq_get_desc_lock(irq, &flags,
+ 				 IRQ_GET_DESC_CHECK_PERCPU);
+ 	if (!desc)
+ 		return;
+ 
+ 	if (WARN_ON(!(desc->istate & IRQS_NMI)))
+ 		goto out;
+ 
+ 	irq_nmi_teardown(desc);
+ out:
+ 	irq_put_desc_unlock(desc, flags);
+ }
+ 
+ int __irq_get_irqchip_state(struct irq_data *data, enum irqchip_irq_state which,
+ 			    bool *state)
+ {
+ 	struct irq_chip *chip;
+ 	int err = -EINVAL;
+ 
+ 	do {
+ 		chip = irq_data_get_irq_chip(data);
+ 		if (chip->irq_get_irqchip_state)
+ 			break;
+ #ifdef CONFIG_IRQ_DOMAIN_HIERARCHY
+ 		data = data->parent_data;
+ #else
+ 		data = NULL;
+ #endif
+ 	} while (data);
+ 
+ 	if (data)
+ 		err = chip->irq_get_irqchip_state(data, which, state);
+ 	return err;
+ }
+ 
+ /**
++>>>>>>> 62e0468650c3 (genirq: Add optional hardware synchronization for shutdown)
   *	irq_get_irqchip_state - returns the irqchip state of a interrupt.
   *	@irq: Interrupt line that is forwarded to a VM
   *	@which: One of IRQCHIP_STATE_* the caller wants to know about
diff --git a/kernel/irq/internals.h b/kernel/irq/internals.h
index e74e7eea76cf..6e7369f02c5b 100644
--- a/kernel/irq/internals.h
+++ b/kernel/irq/internals.h
@@ -94,6 +94,10 @@ static inline void irq_mark_irq(unsigned int irq) { }
 extern void irq_mark_irq(unsigned int irq);
 #endif
 
+extern int __irq_get_irqchip_state(struct irq_data *data,
+				   enum irqchip_irq_state which,
+				   bool *state);
+
 extern void init_kstat_irqs(struct irq_desc *desc, int node, int nr);
 
 irqreturn_t __handle_irq_event_percpu(struct irq_desc *desc, unsigned int *flags);
* Unmerged path kernel/irq/manage.c
