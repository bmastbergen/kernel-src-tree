RDMA/mlx5: Fix MR npages calculation for IB_ACCESS_HUGETLB

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Jason Gunthorpe <jgg@ziepe.ca>
commit 27b7fb1ab7bfad45f5702ff0c78a4822a41b1456
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/27b7fb1a.failed

When ODP is enabled with IB_ACCESS_HUGETLB then the required pages
should be calculated based on the extent of the MR, which is rounded
to the nearest huge page alignment.

Fixes: d2183c6f1958 ("RDMA/umem: Move page_shift from ib_umem to ib_odp_umem")
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
Link: https://lore.kernel.org/r/20190815083834.9245-5-leon@kernel.org
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 27b7fb1ab7bfad45f5702ff0c78a4822a41b1456)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/mem.c
diff --cc drivers/infiniband/hw/mlx5/mem.c
index 9f90be296ee0,a40e0abf2338..000000000000
--- a/drivers/infiniband/hw/mlx5/mem.c
+++ b/drivers/infiniband/hw/mlx5/mem.c
@@@ -55,10 -55,12 +55,17 @@@ void mlx5_ib_cont_pages(struct ib_umem 
  	int i = 0;
  	struct scatterlist *sg;
  	int entry;
 +	unsigned long page_shift = umem->page_shift;
  
  	if (umem->is_odp) {
++<<<<<<< HEAD
 +		*ncont = ib_umem_page_count(umem);
++=======
+ 		struct ib_umem_odp *odp = to_ib_umem_odp(umem);
+ 		unsigned int page_shift = odp->page_shift;
+ 
+ 		*ncont = ib_umem_odp_num_pages(odp);
++>>>>>>> 27b7fb1ab7bf (RDMA/mlx5: Fix MR npages calculation for IB_ACCESS_HUGETLB)
  		*count = *ncont << (page_shift - PAGE_SHIFT);
  		*shift = page_shift;
  		if (order)
diff --git a/drivers/infiniband/core/umem.c b/drivers/infiniband/core/umem.c
index edc90e805bd8..116d9ef1305d 100644
--- a/drivers/infiniband/core/umem.c
+++ b/drivers/infiniband/core/umem.c
@@ -367,14 +367,9 @@ EXPORT_SYMBOL(ib_umem_release);
 
 int ib_umem_page_count(struct ib_umem *umem)
 {
-	int i;
-	int n;
+	int i, n = 0;
 	struct scatterlist *sg;
 
-	if (umem->is_odp)
-		return ib_umem_num_pages(umem);
-
-	n = 0;
 	for_each_sg(umem->sg_head.sgl, sg, umem->nmap, i)
 		n += sg_dma_len(sg) >> umem->page_shift;
 
* Unmerged path drivers/infiniband/hw/mlx5/mem.c
