PCI/P2PDMA: use the dev_pagemap internal refcount

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [pci] p2pdma: use the dev_pagemap internal refcount (Don Dutile) [1754734]
Rebuild_FUZZ: 95.74%
commit-author Christoph Hellwig <hch@lst.de>
commit d0b3517dbcf3f632f7554d878f85943439aade64
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/d0b3517d.failed

The functionality is identical to the one currently open coded in
p2pdma.c.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Ira Weiny <ira.weiny@intel.com>
	Reviewed-by: Logan Gunthorpe <logang@deltatee.com>
	Tested-by: Logan Gunthorpe <logang@deltatee.com>
	Reviewed-by: Dan Williams <dan.j.williams@intel.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit d0b3517dbcf3f632f7554d878f85943439aade64)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/pci/p2pdma.c
diff --cc drivers/pci/p2pdma.c
index 923cb3db4b90,a3073ce16520..000000000000
--- a/drivers/pci/p2pdma.c
+++ b/drivers/pci/p2pdma.c
@@@ -79,31 -73,6 +73,34 @@@ static const struct attribute_group p2p
  	.name = "p2pmem",
  };
  
++<<<<<<< HEAD
 +static struct p2pdma_pagemap *to_p2p_pgmap(struct percpu_ref *ref)
 +{
 +	return container_of(ref, struct p2pdma_pagemap, ref);
 +}
 +
 +static void pci_p2pdma_percpu_release(struct percpu_ref *ref)
 +{
 +	struct p2pdma_pagemap *p2p_pgmap = to_p2p_pgmap(ref);
 +
 +	complete(&p2p_pgmap->ref_done);
 +}
 +
 +static void pci_p2pdma_percpu_kill(struct percpu_ref *ref)
 +{
 +	percpu_ref_kill(ref);
 +}
 +
 +static void pci_p2pdma_percpu_cleanup(void *ref)
 +{
 +	struct p2pdma_pagemap *p2p_pgmap = to_p2p_pgmap(ref);
 +
 +	wait_for_completion(&p2p_pgmap->ref_done);
 +	percpu_ref_exit(&p2p_pgmap->ref);
 +}
 +
++=======
++>>>>>>> d0b3517dbcf3 (PCI/P2PDMA: use the dev_pagemap internal refcount)
  static void pci_p2pdma_release(void *data)
  {
  	struct pci_dev *pdev = data;
@@@ -189,36 -157,15 +185,41 @@@ int pci_p2pdma_add_resource(struct pci_
  			return error;
  	}
  
- 	p2p_pgmap = devm_kzalloc(&pdev->dev, sizeof(*p2p_pgmap), GFP_KERNEL);
- 	if (!p2p_pgmap)
+ 	pgmap = devm_kzalloc(&pdev->dev, sizeof(*pgmap), GFP_KERNEL);
+ 	if (!pgmap)
  		return -ENOMEM;
++<<<<<<< HEAD
 +
 +	init_completion(&p2p_pgmap->ref_done);
 +	error = percpu_ref_init(&p2p_pgmap->ref,
 +			pci_p2pdma_percpu_release, 0, GFP_KERNEL);
 +	if (error)
 +		goto pgmap_free;
 +
 +	/*
 +	 * FIXME: the percpu_ref_exit needs to be coordinated internal
 +	 * to devm_memremap_pages_release(). Duplicate the same ordering
 +	 * as other devm_memremap_pages() users for now.
 +	 */
 +	error = devm_add_action(&pdev->dev, pci_p2pdma_percpu_cleanup,
 +			&p2p_pgmap->ref);
 +	if (error)
 +		goto ref_cleanup;
 +
 +	pgmap = &p2p_pgmap->pgmap;
 +
++=======
++>>>>>>> d0b3517dbcf3 (PCI/P2PDMA: use the dev_pagemap internal refcount)
  	pgmap->res.start = pci_resource_start(pdev, bar) + offset;
  	pgmap->res.end = pgmap->res.start + size - 1;
  	pgmap->res.flags = pci_resource_flags(pdev, bar);
  	pgmap->type = MEMORY_DEVICE_PCI_P2PDMA;
  	pgmap->pci_p2pdma_bus_offset = pci_bus_address(pdev, bar) -
  		pci_resource_start(pdev, bar);
++<<<<<<< HEAD
 +	pgmap->kill = pci_p2pdma_percpu_kill;
++=======
++>>>>>>> d0b3517dbcf3 (PCI/P2PDMA: use the dev_pagemap internal refcount)
  
  	addr = devm_memremap_pages(&pdev->dev, pgmap);
  	if (IS_ERR(addr)) {
@@@ -240,10 -187,8 +241,10 @@@
  
  pages_free:
  	devm_memunmap_pages(&pdev->dev, pgmap);
 +ref_cleanup:
 +	percpu_ref_exit(&p2p_pgmap->ref);
  pgmap_free:
- 	devm_kfree(&pdev->dev, p2p_pgmap);
+ 	devm_kfree(&pdev->dev, pgmap);
  	return error;
  }
  EXPORT_SYMBOL_GPL(pci_p2pdma_add_resource);
* Unmerged path drivers/pci/p2pdma.c
