mm: remove vm_insert_pfn()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [mm] remove vm_insert_pfn() (Don Dutile) [1754737]
Rebuild_FUZZ: 91.67%
commit-author Matthew Wilcox <willy@infradead.org>
commit ae2b01f37044c10e975d22116755df56252b09d8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/ae2b01f3.failed

All callers are now converted to vmf_insert_pfn() so convert
vmf_insert_pfn() from being a compatibility wrapper around vm_insert_pfn()
to being a compatibility wrapper around vmf_insert_pfn_prot().

Link: http://lkml.kernel.org/r/20180828145728.11873-8-willy@infradead.org
	Signed-off-by: Matthew Wilcox <willy@infradead.org>
	Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
	Cc: Nicolas Pitre <nicolas.pitre@linaro.org>
	Cc: Souptick Joarder <jrdr.linux@gmail.com>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit ae2b01f37044c10e975d22116755df56252b09d8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/mm.h
diff --cc include/linux/mm.h
index cb7348cca8c9,737279bb479c..000000000000
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@@ -2564,11 -2502,7 +2564,15 @@@ struct vm_area_struct *find_extend_vma(
  int remap_pfn_range(struct vm_area_struct *, unsigned long addr,
  			unsigned long pfn, unsigned long size, pgprot_t);
  int vm_insert_page(struct vm_area_struct *, unsigned long addr, struct page *);
++<<<<<<< HEAD
 +int vm_map_pages(struct vm_area_struct *vma, struct page **pages,
 +				unsigned long num);
 +int vm_map_pages_zero(struct vm_area_struct *vma, struct page **pages,
 +				unsigned long num);
 +int vm_insert_pfn(struct vm_area_struct *vma, unsigned long addr,
++=======
+ vm_fault_t vmf_insert_pfn(struct vm_area_struct *vma, unsigned long addr,
++>>>>>>> ae2b01f37044 (mm: remove vm_insert_pfn())
  			unsigned long pfn);
  vm_fault_t vmf_insert_pfn_prot(struct vm_area_struct *vma, unsigned long addr,
  			unsigned long pfn, pgprot_t pgprot);
* Unmerged path include/linux/mm.h
diff --git a/mm/memory.c b/mm/memory.c
index d374fa4ab73f..321ec07df045 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -1948,30 +1948,6 @@ static int vm_insert_pfn_prot(struct vm_area_struct *vma, unsigned long addr,
 	return ret;
 }
 
-/**
- * vm_insert_pfn - insert single pfn into user vma
- * @vma: user vma to map to
- * @addr: target user address of this page
- * @pfn: source kernel pfn
- *
- * Similar to vm_insert_page, this allows drivers to insert individual pages
- * they've allocated into a user vma. Same comments apply.
- *
- * This function should only be called from a vm_ops->fault handler, and
- * in that case the handler should return NULL.
- *
- * vma cannot be a COW mapping.
- *
- * As this is called only for pages that do not currently exist, we
- * do not need to flush old virtual caches or the TLB.
- */
-int vm_insert_pfn(struct vm_area_struct *vma, unsigned long addr,
-			unsigned long pfn)
-{
-	return vm_insert_pfn_prot(vma, addr, pfn, vma->vm_page_prot);
-}
-EXPORT_SYMBOL(vm_insert_pfn);
-
 /**
  * vmf_insert_pfn_prot - insert single pfn into user vma with specified pgprot
  * @vma: user vma to map to
@@ -1984,9 +1960,10 @@ EXPORT_SYMBOL(vm_insert_pfn);
  *
  * This only makes sense for IO mappings, and it makes no sense for
  * COW mappings.  In general, using multiple vmas is preferable;
- * vm_insert_pfn_prot should only be used if using multiple VMAs is
+ * vmf_insert_pfn_prot should only be used if using multiple VMAs is
  * impractical.
  *
+ * Context: Process context.  May allocate using %GFP_KERNEL.
  * Return: vm_fault_t value.
  */
 vm_fault_t vmf_insert_pfn_prot(struct vm_area_struct *vma, unsigned long addr,
@@ -2003,6 +1980,33 @@ vm_fault_t vmf_insert_pfn_prot(struct vm_area_struct *vma, unsigned long addr,
 }
 EXPORT_SYMBOL(vmf_insert_pfn_prot);
 
+/**
+ * vmf_insert_pfn - insert single pfn into user vma
+ * @vma: user vma to map to
+ * @addr: target user address of this page
+ * @pfn: source kernel pfn
+ *
+ * Similar to vm_insert_page, this allows drivers to insert individual pages
+ * they've allocated into a user vma. Same comments apply.
+ *
+ * This function should only be called from a vm_ops->fault handler, and
+ * in that case the handler should return the result of this function.
+ *
+ * vma cannot be a COW mapping.
+ *
+ * As this is called only for pages that do not currently exist, we
+ * do not need to flush old virtual caches or the TLB.
+ *
+ * Context: Process context.  May allocate using %GFP_KERNEL.
+ * Return: vm_fault_t value.
+ */
+vm_fault_t vmf_insert_pfn(struct vm_area_struct *vma, unsigned long addr,
+			unsigned long pfn)
+{
+	return vmf_insert_pfn_prot(vma, addr, pfn, vma->vm_page_prot);
+}
+EXPORT_SYMBOL(vmf_insert_pfn);
+
 static bool vm_mixed_ok(struct vm_area_struct *vma, pfn_t pfn)
 {
 	/* these checks mirror the abort conditions in vm_normal_page */
