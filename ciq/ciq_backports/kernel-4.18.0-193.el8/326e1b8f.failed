mm/sparsemem: introduce a SECTION_IS_EARLY flag

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [mm] sparsemem: introduce a SECTION_IS_EARLY flag (Baoquan He) [1724969]
Rebuild_FUZZ: 96.70%
commit-author Dan Williams <dan.j.williams@intel.com>
commit 326e1b8f83a4318b09033ef754f40c785aed5e68
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/326e1b8f.failed

In preparation for sub-section hotplug, track whether a given section
was created during early memory initialization, or later via memory
hotplug.  This distinction is needed to maintain the coarse expectation
that pfn_valid() returns true for any pfn within a given section even if
that section has pages that are reserved from the page allocator.

For example one of the of goals of subsection hotplug is to support
cases where the system physical memory layout collides System RAM and
PMEM within a section.  Several pfn_valid() users expect to just check
if a section is valid, but they are not careful to check if the given
pfn is within a "System RAM" boundary and instead expect pgdat
information to further validate the pfn.

Rather than unwind those paths to make their pfn_valid() queries more
precise a follow on patch uses the SECTION_IS_EARLY flag to maintain the
traditional expectation that pfn_valid() returns true for all early
sections.

Link: https://lore.kernel.org/lkml/1560366952-10660-1-git-send-email-cai@lca.pw/
Link: http://lkml.kernel.org/r/156092350358.979959.5817209875548072819.stgit@dwillia2-desk3.amr.corp.intel.com
	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
	Reported-by: Qian Cai <cai@lca.pw>
	Tested-by: Aneesh Kumar K.V <aneesh.kumar@linux.ibm.com>	[ppc64]
	Reviewed-by: Oscar Salvador <osalvador@suse.de>
	Cc: Michal Hocko <mhocko@suse.com>
	Cc: Logan Gunthorpe <logang@deltatee.com>
	Cc: David Hildenbrand <david@redhat.com>
	Cc: Pavel Tatashin <pasha.tatashin@soleen.com>
	Cc: Jane Chu <jane.chu@oracle.com>
	Cc: Jeff Moyer <jmoyer@redhat.com>
	Cc: Jérôme Glisse <jglisse@redhat.com>
	Cc: Jonathan Corbet <corbet@lwn.net>
	Cc: Mike Rapoport <rppt@linux.ibm.com>
	Cc: Toshi Kani <toshi.kani@hpe.com>
	Cc: Vlastimil Babka <vbabka@suse.cz>
	Cc: Wei Yang <richardw.yang@linux.intel.com>
	Cc: Jason Gunthorpe <jgg@mellanox.com>
	Cc: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 326e1b8f83a4318b09033ef754f40c785aed5e68)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/sparse.c
diff --cc mm/sparse.c
index 02b5de3161a3,6d23a526279a..000000000000
--- a/mm/sparse.c
+++ b/mm/sparse.c
@@@ -264,15 -288,15 +264,24 @@@ struct page *sparse_decode_mem_map(unsi
  
  static void __meminit sparse_init_one_section(struct mem_section *ms,
  		unsigned long pnum, struct page *mem_map,
++<<<<<<< HEAD
 +		unsigned long *pageblock_bitmap)
 +{
 +	ms->section_mem_map &= ~SECTION_MAP_MASK;
 +	ms->section_mem_map |= sparse_encode_mem_map(mem_map, pnum) |
 +							SECTION_HAS_MEM_MAP;
 + 	ms->pageblock_flags = pageblock_bitmap;
++=======
+ 		struct mem_section_usage *usage, unsigned long flags)
+ {
+ 	ms->section_mem_map &= ~SECTION_MAP_MASK;
+ 	ms->section_mem_map |= sparse_encode_mem_map(mem_map, pnum)
+ 		| SECTION_HAS_MEM_MAP | flags;
+ 	ms->usage = usage;
++>>>>>>> 326e1b8f83a4 (mm/sparsemem: introduce a SECTION_IS_EARLY flag)
  }
  
 -static unsigned long usemap_size(void)
 +unsigned long usemap_size(void)
  {
  	return BITS_TO_LONGS(SECTION_BLOCKFLAGS_BITS) * sizeof(unsigned long);
  }
@@@ -469,9 -496,10 +478,16 @@@ static void __init sparse_init_nid(int 
  			pnum_begin = pnum;
  			goto failed;
  		}
++<<<<<<< HEAD
 +		check_usemap_section_nr(nid, usemap);
 +		sparse_init_one_section(__nr_to_section(pnum), pnum, map, usemap);
 +		usemap += usemap_longs;
++=======
+ 		check_usemap_section_nr(nid, usage);
+ 		sparse_init_one_section(__nr_to_section(pnum), pnum, map, usage,
+ 				SECTION_IS_EARLY);
+ 		usage = (void *) usage + mem_section_usage_size();
++>>>>>>> 326e1b8f83a4 (mm/sparsemem: introduce a SECTION_IS_EARLY flag)
  	}
  	sparse_buffer_fini();
  	return;
@@@ -709,7 -733,7 +725,11 @@@ int __meminit sparse_add_one_section(in
  
  	set_section_nid(section_nr, nid);
  	section_mark_present(ms);
++<<<<<<< HEAD
 +	sparse_init_one_section(ms, section_nr, memmap, usemap);
++=======
+ 	sparse_init_one_section(ms, section_nr, memmap, usage, 0);
++>>>>>>> 326e1b8f83a4 (mm/sparsemem: introduce a SECTION_IS_EARLY flag)
  
  out:
  	if (ret < 0) {
@@@ -741,20 -773,17 +761,34 @@@ static inline void clear_hwpoisoned_pag
  }
  #endif
  
++<<<<<<< HEAD
 +static void free_section_usemap(struct page *memmap, unsigned long *usemap,
 +		struct vmem_altmap *altmap)
 +{
 +	struct page *usemap_page;
 +
 +	if (!usemap)
 +		return;
 +
 +	usemap_page = virt_to_page(usemap);
 +	/*
 +	 * Check to see if allocation came from hot-plug-add
 +	 */
 +	if (PageSlab(usemap_page) || PageCompound(usemap_page)) {
 +		kfree(usemap);
++=======
+ static void free_section_usage(struct mem_section *ms, struct page *memmap,
+ 		struct mem_section_usage *usage, struct vmem_altmap *altmap)
+ {
+ 	if (!usage)
+ 		return;
+ 
+ 	/*
+ 	 * Check to see if allocation came from hot-plug-add
+ 	 */
+ 	if (!early_section(ms)) {
+ 		kfree(usage);
++>>>>>>> 326e1b8f83a4 (mm/sparsemem: introduce a SECTION_IS_EARLY flag)
  		if (memmap)
  			__kfree_section_memmap(memmap, altmap);
  		return;
@@@ -785,7 -814,6 +819,11 @@@ void sparse_remove_one_section(struct m
  
  	clear_hwpoisoned_pages(memmap + map_offset,
  			PAGES_PER_SECTION - map_offset);
++<<<<<<< HEAD
 +	free_section_usemap(memmap, usemap, altmap);
++=======
+ 	free_section_usage(ms, memmap, usage, altmap);
++>>>>>>> 326e1b8f83a4 (mm/sparsemem: introduce a SECTION_IS_EARLY flag)
  }
 +#endif /* CONFIG_MEMORY_HOTREMOVE */
  #endif /* CONFIG_MEMORY_HOTPLUG */
diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h
index 34d200212014..113eee1395c9 100644
--- a/include/linux/mmzone.h
+++ b/include/linux/mmzone.h
@@ -1202,7 +1202,8 @@ extern unsigned long usemap_size(void);
 #define	SECTION_MARKED_PRESENT	(1UL<<0)
 #define SECTION_HAS_MEM_MAP	(1UL<<1)
 #define SECTION_IS_ONLINE	(1UL<<2)
-#define SECTION_MAP_LAST_BIT	(1UL<<3)
+#define SECTION_IS_EARLY	(1UL<<3)
+#define SECTION_MAP_LAST_BIT	(1UL<<4)
 #define SECTION_MAP_MASK	(~(SECTION_MAP_LAST_BIT-1))
 #define SECTION_NID_SHIFT	3
 
@@ -1228,6 +1229,11 @@ static inline int valid_section(struct mem_section *section)
 	return (section && (section->section_mem_map & SECTION_HAS_MEM_MAP));
 }
 
+static inline int early_section(struct mem_section *section)
+{
+	return (section && (section->section_mem_map & SECTION_IS_EARLY));
+}
+
 static inline int valid_section_nr(unsigned long nr)
 {
 	return valid_section(__nr_to_section(nr));
* Unmerged path mm/sparse.c
