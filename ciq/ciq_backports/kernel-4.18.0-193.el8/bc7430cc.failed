selftests/bpf: convert selftests using BTF-defined maps to new syntax

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Andrii Nakryiko <andriin@fb.com>
commit bc7430cc8bfb51577e466a8ca02ad87375a70bde
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/bc7430cc.failed

Convert all the existing selftests that are already using BTF-defined
maps to use new syntax (with no static data initialization).

	Signed-off-by: Andrii Nakryiko <andriin@fb.com>
	Acked-by: Song Liu <songliubraving@fb.com>
	Acked-by: Yonghong Song <yhs@fb.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
(cherry picked from commit bc7430cc8bfb51577e466a8ca02ad87375a70bde)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/testing/selftests/bpf/bpf_flow.c
#	tools/testing/selftests/bpf/netcnt_prog.c
#	tools/testing/selftests/bpf/progs/test_btf_newkv.c
#	tools/testing/selftests/bpf/progs/test_global_data.c
#	tools/testing/selftests/bpf/progs/test_map_lock.c
#	tools/testing/selftests/bpf/progs/test_send_signal_kern.c
#	tools/testing/selftests/bpf/progs/test_sock_fields_kern.c
#	tools/testing/selftests/bpf/progs/test_spin_lock.c
#	tools/testing/selftests/bpf/socket_cookie_prog.c
#	tools/testing/selftests/bpf/test_get_stack_rawtp.c
#	tools/testing/selftests/bpf/test_l4lb.c
#	tools/testing/selftests/bpf/test_l4lb_noinline.c
#	tools/testing/selftests/bpf/test_select_reuseport_kern.c
#	tools/testing/selftests/bpf/test_stacktrace_build_id.c
#	tools/testing/selftests/bpf/test_stacktrace_map.c
#	tools/testing/selftests/bpf/test_tcp_estats.c
#	tools/testing/selftests/bpf/test_tcpbpf_kern.c
#	tools/testing/selftests/bpf/test_tcpnotify_kern.c
#	tools/testing/selftests/bpf/test_xdp.c
#	tools/testing/selftests/bpf/test_xdp_noinline.c
diff --cc tools/testing/selftests/bpf/bpf_flow.c
index 284660f5aa95,5ae485a6af3f..000000000000
--- a/tools/testing/selftests/bpf/bpf_flow.c
+++ b/tools/testing/selftests/bpf/bpf_flow.c
@@@ -57,13 -57,32 +57,42 @@@ struct frag_hdr 
  	__be32 identification;
  };
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/bpf_flow.c
 +struct bpf_map_def SEC("maps") jmp_table = {
 +	.type = BPF_MAP_TYPE_PROG_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u32),
 +	.max_entries = 8
 +};
 +
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_PROG_ARRAY);
+ 	__uint(max_entries, 8);
+ 	__uint(key_size, sizeof(__u32));
+ 	__uint(value_size, sizeof(__u32));
+ } jmp_table SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 1);
+ 	__type(key, __u32);
+ 	__type(value, struct bpf_flow_keys);
+ } last_dissection SEC(".maps");
+ 
+ static __always_inline int export_flow_keys(struct bpf_flow_keys *keys,
+ 					    int ret)
+ {
+ 	struct bpf_flow_keys *val;
+ 	__u32 key = 0;
+ 
+ 	val = bpf_map_lookup_elem(&last_dissection, &key);
+ 	if (val)
+ 		memcpy(val, keys, sizeof(*val));
+ 	return ret;
+ }
+ 
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/bpf_flow.c
  static __always_inline void *bpf_flow_dissect_get_header(struct __sk_buff *skb,
  							 __u16 hdr_size,
  							 void *buffer)
diff --cc tools/testing/selftests/bpf/netcnt_prog.c
index 9f741e69cebe,38a997852cad..000000000000
--- a/tools/testing/selftests/bpf/netcnt_prog.c
+++ b/tools/testing/selftests/bpf/netcnt_prog.c
@@@ -10,23 -10,17 +10,37 @@@
  #define REFRESH_TIME_NS	100000000
  #define NS_PER_SEC	1000000000
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/netcnt_prog.c
 +struct bpf_map_def SEC("maps") percpu_netcnt = {
 +	.type = BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE,
 +	.key_size = sizeof(struct bpf_cgroup_storage_key),
 +	.value_size = sizeof(struct percpu_net_cnt),
 +};
 +
 +BPF_ANNOTATE_KV_PAIR(percpu_netcnt, struct bpf_cgroup_storage_key,
 +		     struct percpu_net_cnt);
 +
 +struct bpf_map_def SEC("maps") netcnt = {
 +	.type = BPF_MAP_TYPE_CGROUP_STORAGE,
 +	.key_size = sizeof(struct bpf_cgroup_storage_key),
 +	.value_size = sizeof(struct net_cnt),
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_PERCPU_CGROUP_STORAGE);
+ 	__type(key, struct bpf_cgroup_storage_key);
+ 	__type(value, struct percpu_net_cnt);
+ } percpu_netcnt SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_CGROUP_STORAGE);
+ 	__type(key, struct bpf_cgroup_storage_key);
+ 	__type(value, struct net_cnt);
+ } netcnt SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/netcnt_prog.c
 +
 +BPF_ANNOTATE_KV_PAIR(netcnt, struct bpf_cgroup_storage_key,
 +		     struct net_cnt);
  
  SEC("cgroup/skb")
  int bpf_nextcnt(struct __sk_buff *skb)
diff --cc tools/testing/selftests/bpf/socket_cookie_prog.c
index 0db15c3210ad,e4440fdd94cb..000000000000
--- a/tools/testing/selftests/bpf/socket_cookie_prog.c
+++ b/tools/testing/selftests/bpf/socket_cookie_prog.c
@@@ -12,14 -12,12 +12,23 @@@ struct socket_cookie 
  	__u32 cookie_value;
  };
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/socket_cookie_prog.c
 +struct bpf_map_def SEC("maps") socket_cookies = {
 +	.type = BPF_MAP_TYPE_SK_STORAGE,
 +	.key_size = sizeof(int),
 +	.value_size = sizeof(struct socket_cookie),
 +	.map_flags = BPF_F_NO_PREALLOC,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_SK_STORAGE);
+ 	__uint(map_flags, BPF_F_NO_PREALLOC);
+ 	__type(key, int);
+ 	__type(value, struct socket_cookie);
+ } socket_cookies SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/socket_cookie_prog.c
 +
 +BPF_ANNOTATE_KV_PAIR(socket_cookies, int, struct socket_cookie);
  
  SEC("cgroup/connect6")
  int set_cookie(struct bpf_sock_addr *ctx)
diff --cc tools/testing/selftests/bpf/test_get_stack_rawtp.c
index f6d9f238e00a,d06b47a09097..000000000000
--- a/tools/testing/selftests/bpf/test_get_stack_rawtp.c
+++ b/tools/testing/selftests/bpf/test_get_stack_rawtp.c
@@@ -15,19 -15,19 +15,35 @@@ struct stack_trace_t 
  	struct bpf_stack_build_id user_stack_buildid[MAX_STACK_RAWTP];
  };
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/test_get_stack_rawtp.c
 +struct bpf_map_def SEC("maps") perfmap = {
 +	.type = BPF_MAP_TYPE_PERF_EVENT_ARRAY,
 +	.key_size = sizeof(int),
 +	.value_size = sizeof(__u32),
 +	.max_entries = 2,
 +};
 +
 +struct bpf_map_def SEC("maps") stackdata_map = {
 +	.type = BPF_MAP_TYPE_PERCPU_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct stack_trace_t),
 +	.max_entries = 1,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY);
+ 	__uint(max_entries, 2);
+ 	__uint(key_size, sizeof(int));
+ 	__uint(value_size, sizeof(__u32));
+ } perfmap SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+ 	__uint(max_entries, 1);
+ 	__type(key, __u32);
+ 	__type(value, struct stack_trace_t);
+ } stackdata_map SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/test_get_stack_rawtp.c
  
  /* Allocate per-cpu space twice the needed. For the code below
   *   usize = bpf_get_stack(ctx, raw_data, max_len, BPF_F_USER_STACK);
@@@ -47,12 -47,12 +63,21 @@@
   * issue and avoid complicated C programming massaging.
   * This is an acceptable workaround since there is one entry here.
   */
++<<<<<<< HEAD:tools/testing/selftests/bpf/test_get_stack_rawtp.c
 +struct bpf_map_def SEC("maps") rawdata_map = {
 +	.type = BPF_MAP_TYPE_PERCPU_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = MAX_STACK_RAWTP * sizeof(__u64) * 2,
 +	.max_entries = 1,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+ 	__uint(max_entries, 1);
+ 	__type(key, __u32);
+ 	__u64 (*value)[2 * MAX_STACK_RAWTP];
+ } rawdata_map SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/test_get_stack_rawtp.c
  
  SEC("tracepoint/raw_syscalls/sys_enter")
  int bpf_prog1(void *ctx)
diff --cc tools/testing/selftests/bpf/test_l4lb.c
index 1e10c9590991,1d652ee8e73d..000000000000
--- a/tools/testing/selftests/bpf/test_l4lb.c
+++ b/tools/testing/selftests/bpf/test_l4lb.c
@@@ -169,40 -169,40 +169,77 @@@ struct eth_hdr 
  	unsigned short eth_proto;
  };
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/test_l4lb.c
 +struct bpf_map_def SEC("maps") vip_map = {
 +	.type = BPF_MAP_TYPE_HASH,
 +	.key_size = sizeof(struct vip),
 +	.value_size = sizeof(struct vip_meta),
 +	.max_entries = MAX_VIPS,
 +};
 +
 +struct bpf_map_def SEC("maps") ch_rings = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u32),
 +	.max_entries = CH_RINGS_SIZE,
 +};
 +
 +struct bpf_map_def SEC("maps") reals = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct real_definition),
 +	.max_entries = MAX_REALS,
 +};
 +
 +struct bpf_map_def SEC("maps") stats = {
 +	.type = BPF_MAP_TYPE_PERCPU_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct vip_stats),
 +	.max_entries = MAX_VIPS,
 +};
 +
 +struct bpf_map_def SEC("maps") ctl_array = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct ctl_value),
 +	.max_entries = CTL_MAP_SIZE,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_HASH);
+ 	__uint(max_entries, MAX_VIPS);
+ 	__type(key, struct vip);
+ 	__type(value, struct vip_meta);
+ } vip_map SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, CH_RINGS_SIZE);
+ 	__type(key, __u32);
+ 	__type(value, __u32);
+ } ch_rings SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, MAX_REALS);
+ 	__type(key, __u32);
+ 	__type(value, struct real_definition);
+ } reals SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+ 	__uint(max_entries, MAX_VIPS);
+ 	__type(key, __u32);
+ 	__type(value, struct vip_stats);
+ } stats SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, CTL_MAP_SIZE);
+ 	__type(key, __u32);
+ 	__type(value, struct ctl_value);
+ } ctl_array SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/test_l4lb.c
  
  static __always_inline __u32 get_packet_hash(struct packet_description *pckt,
  					     bool ipv6)
diff --cc tools/testing/selftests/bpf/test_l4lb_noinline.c
index ba44a14e6dc4,2e4efe70b1e5..000000000000
--- a/tools/testing/selftests/bpf/test_l4lb_noinline.c
+++ b/tools/testing/selftests/bpf/test_l4lb_noinline.c
@@@ -165,40 -165,40 +165,77 @@@ struct eth_hdr 
  	unsigned short eth_proto;
  };
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/test_l4lb_noinline.c
 +struct bpf_map_def SEC("maps") vip_map = {
 +	.type = BPF_MAP_TYPE_HASH,
 +	.key_size = sizeof(struct vip),
 +	.value_size = sizeof(struct vip_meta),
 +	.max_entries = MAX_VIPS,
 +};
 +
 +struct bpf_map_def SEC("maps") ch_rings = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u32),
 +	.max_entries = CH_RINGS_SIZE,
 +};
 +
 +struct bpf_map_def SEC("maps") reals = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct real_definition),
 +	.max_entries = MAX_REALS,
 +};
 +
 +struct bpf_map_def SEC("maps") stats = {
 +	.type = BPF_MAP_TYPE_PERCPU_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct vip_stats),
 +	.max_entries = MAX_VIPS,
 +};
 +
 +struct bpf_map_def SEC("maps") ctl_array = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct ctl_value),
 +	.max_entries = CTL_MAP_SIZE,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_HASH);
+ 	__uint(max_entries, MAX_VIPS);
+ 	__type(key, struct vip);
+ 	__type(value, struct vip_meta);
+ } vip_map SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, CH_RINGS_SIZE);
+ 	__type(key, __u32);
+ 	__type(value, __u32);
+ } ch_rings SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, MAX_REALS);
+ 	__type(key, __u32);
+ 	__type(value, struct real_definition);
+ } reals SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+ 	__uint(max_entries, MAX_VIPS);
+ 	__type(key, __u32);
+ 	__type(value, struct vip_stats);
+ } stats SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, CTL_MAP_SIZE);
+ 	__type(key, __u32);
+ 	__type(value, struct ctl_value);
+ } ctl_array SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/test_l4lb_noinline.c
  
  static __u32 get_packet_hash(struct packet_description *pckt,
  			     bool ipv6)
diff --cc tools/testing/selftests/bpf/test_select_reuseport_kern.c
index 5b54ec637ada,ea7d84f01235..000000000000
--- a/tools/testing/selftests/bpf/test_select_reuseport_kern.c
+++ b/tools/testing/selftests/bpf/test_select_reuseport_kern.c
@@@ -21,40 -21,40 +21,77 @@@ int _version SEC("version") = 1
  #define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
  #endif
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/test_select_reuseport_kern.c
 +struct bpf_map_def SEC("maps") outer_map = {
 +	.type = BPF_MAP_TYPE_ARRAY_OF_MAPS,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u32),
 +	.max_entries = 1,
 +};
 +
 +struct bpf_map_def SEC("maps") result_map = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u32),
 +	.max_entries = NR_RESULTS,
 +};
 +
 +struct bpf_map_def SEC("maps") tmp_index_ovr_map = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(int),
 +	.max_entries = 1,
 +};
 +
 +struct bpf_map_def SEC("maps") linum_map = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u32),
 +	.max_entries = 1,
 +};
 +
 +struct bpf_map_def SEC("maps") data_check_map = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct data_check),
 +	.max_entries = 1,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY_OF_MAPS);
+ 	__uint(max_entries, 1);
+ 	__uint(key_size, sizeof(__u32));
+ 	__uint(value_size, sizeof(__u32));
+ } outer_map SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, NR_RESULTS);
+ 	__type(key, __u32);
+ 	__type(value, __u32);
+ } result_map SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 1);
+ 	__type(key, __u32);
+ 	__type(value, int);
+ } tmp_index_ovr_map SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 1);
+ 	__type(key, __u32);
+ 	__type(value, __u32);
+ } linum_map SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 1);
+ 	__type(key, __u32);
+ 	__type(value, struct data_check);
+ } data_check_map SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/test_select_reuseport_kern.c
  
  #define GOTO_DONE(_result) ({			\
  	result = (_result);			\
diff --cc tools/testing/selftests/bpf/test_stacktrace_build_id.c
index d86c281e957f,bbfc8337b6f0..000000000000
--- a/tools/testing/selftests/bpf/test_stacktrace_build_id.c
+++ b/tools/testing/selftests/bpf/test_stacktrace_build_id.c
@@@ -8,36 -8,37 +8,70 @@@
  #define PERF_MAX_STACK_DEPTH         127
  #endif
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/test_stacktrace_build_id.c
 +struct bpf_map_def SEC("maps") control_map = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u32),
 +	.max_entries = 1,
 +};
 +
 +struct bpf_map_def SEC("maps") stackid_hmap = {
 +	.type = BPF_MAP_TYPE_HASH,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u32),
 +	.max_entries = 16384,
 +};
 +
 +struct bpf_map_def SEC("maps") stackmap = {
 +	.type = BPF_MAP_TYPE_STACK_TRACE,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct bpf_stack_build_id)
 +		* PERF_MAX_STACK_DEPTH,
 +	.max_entries = 128,
 +	.map_flags = BPF_F_STACK_BUILD_ID,
 +};
 +
 +struct bpf_map_def SEC("maps") stack_amap = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct bpf_stack_build_id)
 +		* PERF_MAX_STACK_DEPTH,
 +	.max_entries = 128,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 1);
+ 	__type(key, __u32);
+ 	__type(value, __u32);
+ } control_map SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_HASH);
+ 	__uint(max_entries, 16384);
+ 	__type(key, __u32);
+ 	__type(value, __u32);
+ } stackid_hmap SEC(".maps");
+ 
+ typedef struct bpf_stack_build_id stack_trace_t[PERF_MAX_STACK_DEPTH];
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_STACK_TRACE);
+ 	__uint(max_entries, 128);
+ 	__uint(map_flags, BPF_F_STACK_BUILD_ID);
+ 	__uint(key_size, sizeof(__u32));
+ 	__uint(value_size, sizeof(stack_trace_t));
+ } stackmap SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 128);
+ 	__type(key, __u32);
+ 	/* there seems to be a bug in kernel not handling typedef properly */
+ 	struct bpf_stack_build_id (*value)[PERF_MAX_STACK_DEPTH];
+ } stack_amap SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/test_stacktrace_build_id.c
  
  /* taken from /sys/kernel/debug/tracing/events/random/urandom_read/format */
  struct random_urandom_args {
diff --cc tools/testing/selftests/bpf/test_stacktrace_map.c
index af111af7ca1a,803c15dc109d..000000000000
--- a/tools/testing/selftests/bpf/test_stacktrace_map.c
+++ b/tools/testing/selftests/bpf/test_stacktrace_map.c
@@@ -8,33 -8,35 +8,65 @@@
  #define PERF_MAX_STACK_DEPTH         127
  #endif
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/test_stacktrace_map.c
 +struct bpf_map_def SEC("maps") control_map = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u32),
 +	.max_entries = 1,
 +};
 +
 +struct bpf_map_def SEC("maps") stackid_hmap = {
 +	.type = BPF_MAP_TYPE_HASH,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u32),
 +	.max_entries = 16384,
 +};
 +
 +struct bpf_map_def SEC("maps") stackmap = {
 +	.type = BPF_MAP_TYPE_STACK_TRACE,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u64) * PERF_MAX_STACK_DEPTH,
 +	.max_entries = 16384,
 +};
 +
 +struct bpf_map_def SEC("maps") stack_amap = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u64) * PERF_MAX_STACK_DEPTH,
 +	.max_entries = 16384,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 1);
+ 	__type(key, __u32);
+ 	__type(value, __u32);
+ } control_map SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_HASH);
+ 	__uint(max_entries, 16384);
+ 	__type(key, __u32);
+ 	__type(value, __u32);
+ } stackid_hmap SEC(".maps");
+ 
+ typedef __u64 stack_trace_t[PERF_MAX_STACK_DEPTH];
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_STACK_TRACE);
+ 	__uint(max_entries, 16384);
+ 	__uint(key_size, sizeof(__u32));
+ 	__uint(value_size, sizeof(stack_trace_t));
+ } stackmap SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 16384);
+ 	__type(key, __u32);
+ 	__u64 (*value)[PERF_MAX_STACK_DEPTH];
+ } stack_amap SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/test_stacktrace_map.c
  
  /* taken from /sys/kernel/debug/tracing/events/sched/sched_switch/format */
  struct sched_switch_args {
diff --cc tools/testing/selftests/bpf/test_tcp_estats.c
index bee3bbecc0c4,c8c595da38d4..000000000000
--- a/tools/testing/selftests/bpf/test_tcp_estats.c
+++ b/tools/testing/selftests/bpf/test_tcp_estats.c
@@@ -148,12 -148,12 +148,21 @@@ struct tcp_estats_basic_event 
  	struct tcp_estats_conn_id conn_id;
  };
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/test_tcp_estats.c
 +struct bpf_map_def SEC("maps") ev_record_map = {
 +	.type = BPF_MAP_TYPE_HASH,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct tcp_estats_basic_event),
 +	.max_entries = 1024,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_HASH);
+ 	__uint(max_entries, 1024);
+ 	__type(key, __u32);
+ 	__type(value, struct tcp_estats_basic_event);
+ } ev_record_map SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/test_tcp_estats.c
  
  struct dummy_tracepoint_args {
  	unsigned long long pad;
diff --cc tools/testing/selftests/bpf/test_tcpbpf_kern.c
index c7c3240e0dd4,2e233613d1fc..000000000000
--- a/tools/testing/selftests/bpf/test_tcpbpf_kern.c
+++ b/tools/testing/selftests/bpf/test_tcpbpf_kern.c
@@@ -14,19 -14,19 +14,35 @@@
  #include "bpf_endian.h"
  #include "test_tcpbpf.h"
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/test_tcpbpf_kern.c
 +struct bpf_map_def SEC("maps") global_map = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct tcpbpf_globals),
 +	.max_entries = 4,
 +};
 +
 +struct bpf_map_def SEC("maps") sockopt_results = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(int),
 +	.max_entries = 2,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 4);
+ 	__type(key, __u32);
+ 	__type(value, struct tcpbpf_globals);
+ } global_map SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 2);
+ 	__type(key, __u32);
+ 	__type(value, int);
+ } sockopt_results SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/test_tcpbpf_kern.c
  
  static inline void update_event_map(int event)
  {
diff --cc tools/testing/selftests/bpf/test_tcpnotify_kern.c
index ec6db6e64c41,08346e7765d5..000000000000
--- a/tools/testing/selftests/bpf/test_tcpnotify_kern.c
+++ b/tools/testing/selftests/bpf/test_tcpnotify_kern.c
@@@ -14,19 -14,19 +14,35 @@@
  #include "bpf_endian.h"
  #include "test_tcpnotify.h"
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/test_tcpnotify_kern.c
 +struct bpf_map_def SEC("maps") global_map = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct tcpnotify_globals),
 +	.max_entries = 4,
 +};
 +
 +struct bpf_map_def SEC("maps") perf_event_map = {
 +	.type = BPF_MAP_TYPE_PERF_EVENT_ARRAY,
 +	.key_size = sizeof(int),
 +	.value_size = sizeof(__u32),
 +	.max_entries = 2,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 4);
+ 	__type(key, __u32);
+ 	__type(value, struct tcpnotify_globals);
+ } global_map SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY);
+ 	__uint(max_entries, 2);
+ 	__uint(key_size, sizeof(int));
+ 	__uint(value_size, sizeof(__u32));
+ } perf_event_map SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/test_tcpnotify_kern.c
  
  int _version SEC("version") = 1;
  
diff --cc tools/testing/selftests/bpf/test_xdp.c
index 5e7df8bb5b5d,0941c655b07b..000000000000
--- a/tools/testing/selftests/bpf/test_xdp.c
+++ b/tools/testing/selftests/bpf/test_xdp.c
@@@ -22,19 -22,19 +22,35 @@@
  
  int _version SEC("version") = 1;
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/test_xdp.c
 +struct bpf_map_def SEC("maps") rxcnt = {
 +	.type = BPF_MAP_TYPE_PERCPU_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u64),
 +	.max_entries = 256,
 +};
 +
 +struct bpf_map_def SEC("maps") vip2tnl = {
 +	.type = BPF_MAP_TYPE_HASH,
 +	.key_size = sizeof(struct vip),
 +	.value_size = sizeof(struct iptnl_info),
 +	.max_entries = MAX_IPTNL_ENTRIES,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+ 	__uint(max_entries, 256);
+ 	__type(key, __u32);
+ 	__type(value, __u64);
+ } rxcnt SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_HASH);
+ 	__uint(max_entries, MAX_IPTNL_ENTRIES);
+ 	__type(key, struct vip);
+ 	__type(value, struct iptnl_info);
+ } vip2tnl SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/test_xdp.c
  
  static __always_inline void count_tx(__u32 protocol)
  {
diff --cc tools/testing/selftests/bpf/test_xdp_noinline.c
index 4fe6aaad22a4,dad8a7e33eaa..000000000000
--- a/tools/testing/selftests/bpf/test_xdp_noinline.c
+++ b/tools/testing/selftests/bpf/test_xdp_noinline.c
@@@ -163,53 -163,48 +163,98 @@@ struct lb_stats 
  	__u64 v1;
  };
  
++<<<<<<< HEAD:tools/testing/selftests/bpf/test_xdp_noinline.c
 +struct bpf_map_def __attribute__ ((section("maps"), used)) vip_map = {
 +	.type = BPF_MAP_TYPE_HASH,
 +	.key_size = sizeof(struct vip_definition),
 +	.value_size = sizeof(struct vip_meta),
 +	.max_entries = 512,
 +	.map_flags = 0,
 +};
 +
 +struct bpf_map_def __attribute__ ((section("maps"), used)) lru_cache = {
 +	.type = BPF_MAP_TYPE_LRU_HASH,
 +	.key_size = sizeof(struct flow_key),
 +	.value_size = sizeof(struct real_pos_lru),
 +	.max_entries = 300,
 +	.map_flags = 1U << 1,
 +};
 +
 +struct bpf_map_def __attribute__ ((section("maps"), used)) ch_rings = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(__u32),
 +	.max_entries = 12 * 655,
 +	.map_flags = 0,
 +};
 +
 +struct bpf_map_def __attribute__ ((section("maps"), used)) reals = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct real_definition),
 +	.max_entries = 40,
 +	.map_flags = 0,
 +};
 +
 +struct bpf_map_def __attribute__ ((section("maps"), used)) stats = {
 +	.type = BPF_MAP_TYPE_PERCPU_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct lb_stats),
 +	.max_entries = 515,
 +	.map_flags = 0,
 +};
 +
 +struct bpf_map_def __attribute__ ((section("maps"), used)) ctl_array = {
 +	.type = BPF_MAP_TYPE_ARRAY,
 +	.key_size = sizeof(__u32),
 +	.value_size = sizeof(struct ctl_value),
 +	.max_entries = 16,
 +	.map_flags = 0,
 +};
++=======
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_HASH);
+ 	__uint(max_entries, 512);
+ 	__type(key, struct vip_definition);
+ 	__type(value, struct vip_meta);
+ } vip_map SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_LRU_HASH);
+ 	__uint(max_entries, 300);
+ 	__uint(map_flags, 1U << 1);
+ 	__type(key, struct flow_key);
+ 	__type(value, struct real_pos_lru);
+ } lru_cache SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 12 * 655);
+ 	__type(key, __u32);
+ 	__type(value, __u32);
+ } ch_rings SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 40);
+ 	__type(key, __u32);
+ 	__type(value, struct real_definition);
+ } reals SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+ 	__uint(max_entries, 515);
+ 	__type(key, __u32);
+ 	__type(value, struct lb_stats);
+ } stats SEC(".maps");
+ 
+ struct {
+ 	__uint(type, BPF_MAP_TYPE_ARRAY);
+ 	__uint(max_entries, 16);
+ 	__type(key, __u32);
+ 	__type(value, struct ctl_value);
+ } ctl_array SEC(".maps");
++>>>>>>> bc7430cc8bfb (selftests/bpf: convert selftests using BTF-defined maps to new syntax):tools/testing/selftests/bpf/progs/test_xdp_noinline.c
  
  struct eth_hdr {
  	unsigned char eth_dest[6];
* Unmerged path tools/testing/selftests/bpf/progs/test_btf_newkv.c
* Unmerged path tools/testing/selftests/bpf/progs/test_global_data.c
* Unmerged path tools/testing/selftests/bpf/progs/test_map_lock.c
* Unmerged path tools/testing/selftests/bpf/progs/test_send_signal_kern.c
* Unmerged path tools/testing/selftests/bpf/progs/test_sock_fields_kern.c
* Unmerged path tools/testing/selftests/bpf/progs/test_spin_lock.c
* Unmerged path tools/testing/selftests/bpf/bpf_flow.c
* Unmerged path tools/testing/selftests/bpf/netcnt_prog.c
* Unmerged path tools/testing/selftests/bpf/progs/test_btf_newkv.c
* Unmerged path tools/testing/selftests/bpf/progs/test_global_data.c
* Unmerged path tools/testing/selftests/bpf/progs/test_map_lock.c
* Unmerged path tools/testing/selftests/bpf/progs/test_send_signal_kern.c
* Unmerged path tools/testing/selftests/bpf/progs/test_sock_fields_kern.c
* Unmerged path tools/testing/selftests/bpf/progs/test_spin_lock.c
* Unmerged path tools/testing/selftests/bpf/socket_cookie_prog.c
* Unmerged path tools/testing/selftests/bpf/test_get_stack_rawtp.c
* Unmerged path tools/testing/selftests/bpf/test_l4lb.c
* Unmerged path tools/testing/selftests/bpf/test_l4lb_noinline.c
* Unmerged path tools/testing/selftests/bpf/test_select_reuseport_kern.c
* Unmerged path tools/testing/selftests/bpf/test_stacktrace_build_id.c
* Unmerged path tools/testing/selftests/bpf/test_stacktrace_map.c
* Unmerged path tools/testing/selftests/bpf/test_tcp_estats.c
* Unmerged path tools/testing/selftests/bpf/test_tcpbpf_kern.c
* Unmerged path tools/testing/selftests/bpf/test_tcpnotify_kern.c
* Unmerged path tools/testing/selftests/bpf/test_xdp.c
* Unmerged path tools/testing/selftests/bpf/test_xdp_noinline.c
