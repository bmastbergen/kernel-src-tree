mm/memory_hotplug: allow arch_remove_memory() without CONFIG_MEMORY_HOTREMOVE

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [mm] memory_hotplug: allow arch_remove_memory() without CONFIG_MEMORY_HOTREMOVE (Baoquan He) [1724969]
Rebuild_FUZZ: 98.01%
commit-author David Hildenbrand <david@redhat.com>
commit 80ec922dbd87fd38d15719c86a94457204648aeb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/80ec922d.failed

We want to improve error handling while adding memory by allowing to use
arch_remove_memory() and __remove_pages() even if
CONFIG_MEMORY_HOTREMOVE is not set to e.g., implement something like:

	arch_add_memory()
	rc = do_something();
	if (rc) {
		arch_remove_memory();
	}

We won't get rid of CONFIG_MEMORY_HOTREMOVE for now, as it will require
quite some dependencies for memory offlining.

Link: http://lkml.kernel.org/r/20190527111152.16324-7-david@redhat.com
	Signed-off-by: David Hildenbrand <david@redhat.com>
	Reviewed-by: Pavel Tatashin <pasha.tatashin@soleen.com>
	Cc: Tony Luck <tony.luck@intel.com>
	Cc: Fenghua Yu <fenghua.yu@intel.com>
	Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
	Cc: Paul Mackerras <paulus@samba.org>
	Cc: Michael Ellerman <mpe@ellerman.id.au>
	Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
	Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
	Cc: Rich Felker <dalias@libc.org>
	Cc: Dave Hansen <dave.hansen@linux.intel.com>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Borislav Petkov <bp@alien8.de>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
	Cc: "Rafael J. Wysocki" <rafael@kernel.org>
	Cc: Michal Hocko <mhocko@suse.com>
	Cc: David Hildenbrand <david@redhat.com>
	Cc: Oscar Salvador <osalvador@suse.com>
	Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
	Cc: Alex Deucher <alexander.deucher@amd.com>
	Cc: "David S. Miller" <davem@davemloft.net>
	Cc: Mark Brown <broonie@kernel.org>
	Cc: Chris Wilson <chris@chris-wilson.co.uk>
	Cc: Christophe Leroy <christophe.leroy@c-s.fr>
	Cc: Nicholas Piggin <npiggin@gmail.com>
	Cc: Vasily Gorbik <gor@linux.ibm.com>
	Cc: Rob Herring <robh@kernel.org>
	Cc: Masahiro Yamada <yamada.masahiro@socionext.com>
	Cc: "mike.travis@hpe.com" <mike.travis@hpe.com>
	Cc: Andrew Banman <andrew.banman@hpe.com>
	Cc: Arun KS <arunks@codeaurora.org>
	Cc: Qian Cai <cai@lca.pw>
	Cc: Mathieu Malaterre <malat@debian.org>
	Cc: Baoquan He <bhe@redhat.com>
	Cc: Logan Gunthorpe <logang@deltatee.com>
	Cc: Anshuman Khandual <anshuman.khandual@arm.com>
	Cc: Ard Biesheuvel <ard.biesheuvel@linaro.org>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Chintan Pandya <cpandya@codeaurora.org>
	Cc: Dan Williams <dan.j.williams@intel.com>
	Cc: Ingo Molnar <mingo@kernel.org>
	Cc: Jonathan Cameron <Jonathan.Cameron@huawei.com>
	Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
	Cc: Jun Yao <yaojun8558363@gmail.com>
	Cc: Mark Rutland <mark.rutland@arm.com>
	Cc: Mike Rapoport <rppt@linux.vnet.ibm.com>
	Cc: Oscar Salvador <osalvador@suse.de>
	Cc: Robin Murphy <robin.murphy@arm.com>
	Cc: Wei Yang <richard.weiyang@gmail.com>
	Cc: Will Deacon <will.deacon@arm.com>
	Cc: Yu Zhao <yuzhao@google.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 80ec922dbd87fd38d15719c86a94457204648aeb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/ia64/mm/init.c
#	arch/powerpc/mm/mem.c
#	arch/s390/mm/init.c
#	arch/sh/mm/init.c
#	arch/x86/mm/init_32.c
#	include/linux/memory_hotplug.h
diff --cc arch/ia64/mm/init.c
index b54d0ee74b53,aae75fd7b810..000000000000
--- a/arch/ia64/mm/init.c
+++ b/arch/ia64/mm/init.c
@@@ -661,21 -681,14 +661,25 @@@ int arch_add_memory(int nid, u64 start
  	return ret;
  }
  
++<<<<<<< HEAD
 +#ifdef CONFIG_MEMORY_HOTREMOVE
 +int arch_remove_memory(int nid, u64 start, u64 size, struct vmem_altmap *altmap)
++=======
+ void arch_remove_memory(int nid, u64 start, u64 size,
+ 			struct vmem_altmap *altmap)
++>>>>>>> 80ec922dbd87 (mm/memory_hotplug: allow arch_remove_memory() without CONFIG_MEMORY_HOTREMOVE)
  {
  	unsigned long start_pfn = start >> PAGE_SHIFT;
  	unsigned long nr_pages = size >> PAGE_SHIFT;
  	struct zone *zone;
 +	int ret;
  
  	zone = page_zone(pfn_to_page(start_pfn));
 -	__remove_pages(zone, start_pfn, nr_pages, altmap);
 +	ret = __remove_pages(zone, start_pfn, nr_pages, altmap);
 +	if (ret)
 +		pr_warn("%s: Problem encountered in __remove_pages() as"
 +			" ret=%d\n", __func__,  ret);
 +
 +	return ret;
  }
  #endif
- #endif
diff --cc arch/powerpc/mm/mem.c
index 7150ace1f956,9259337d7374..000000000000
--- a/arch/powerpc/mm/mem.c
+++ b/arch/powerpc/mm/mem.c
@@@ -134,14 -120,13 +134,19 @@@ int __meminit arch_add_memory(int nid, 
  			start, start + size, rc);
  		return -EFAULT;
  	}
 -	flush_dcache_range(start, start + size);
 +	flush_inval_dcache_range(start, start + size);
  
 -	return __add_pages(nid, start_pfn, nr_pages, restrictions);
 +	return __add_pages(nid, start_pfn, nr_pages, altmap, want_memblock);
  }
  
++<<<<<<< HEAD
 +#ifdef CONFIG_MEMORY_HOTREMOVE
 +int __meminit arch_remove_memory(int nid, u64 start, u64 size,
 +					struct vmem_altmap *altmap)
++=======
+ void __ref arch_remove_memory(int nid, u64 start, u64 size,
+ 			     struct vmem_altmap *altmap)
++>>>>>>> 80ec922dbd87 (mm/memory_hotplug: allow arch_remove_memory() without CONFIG_MEMORY_HOTREMOVE)
  {
  	unsigned long start_pfn = start >> PAGE_SHIFT;
  	unsigned long nr_pages = size >> PAGE_SHIFT;
@@@ -172,40 -148,9 +177,39 @@@
  
  	if (resize_hpt_for_hotplug(memblock_phys_mem_size()) == -ENOSPC)
  		pr_warn("Hash collision while resizing HPT\n");
 +
 +	return ret;
  }
  #endif
- #endif /* CONFIG_MEMORY_HOTPLUG */
  
 +/*
 + * walk_memory_resource() needs to make sure there is no holes in a given
 + * memory range.  PPC64 does not maintain the memory layout in /proc/iomem.
 + * Instead it maintains it in memblock.memory structures.  Walk through the
 + * memory regions, find holes and callback for contiguous regions.
 + */
 +int
 +walk_system_ram_range(unsigned long start_pfn, unsigned long nr_pages,
 +		void *arg, int (*func)(unsigned long, unsigned long, void *))
 +{
 +	struct memblock_region *reg;
 +	unsigned long end_pfn = start_pfn + nr_pages;
 +	unsigned long tstart, tend;
 +	int ret = -1;
 +
 +	for_each_memblock(memory, reg) {
 +		tstart = max(start_pfn, memblock_region_memory_base_pfn(reg));
 +		tend = min(end_pfn, memblock_region_memory_end_pfn(reg));
 +		if (tstart >= tend)
 +			continue;
 +		ret = (*func)(tstart, tend - tstart, arg);
 +		if (ret)
 +			break;
 +	}
 +	return ret;
 +}
 +EXPORT_SYMBOL_GPL(walk_system_ram_range);
 +
  #ifndef CONFIG_NEED_MULTIPLE_NODES
  void __init mem_topology_setup(void)
  {
diff --cc arch/s390/mm/init.c
index b139eb700b1f,4e5bbe328594..000000000000
--- a/arch/s390/mm/init.c
+++ b/arch/s390/mm/init.c
@@@ -300,15 -286,15 +300,19 @@@ int arch_add_memory(int nid, u64 start
  	return rc;
  }
  
++<<<<<<< HEAD
 +#ifdef CONFIG_MEMORY_HOTREMOVE
 +int arch_remove_memory(int nid, u64 start, u64 size, struct vmem_altmap *altmap)
++=======
+ void arch_remove_memory(int nid, u64 start, u64 size,
+ 			struct vmem_altmap *altmap)
++>>>>>>> 80ec922dbd87 (mm/memory_hotplug: allow arch_remove_memory() without CONFIG_MEMORY_HOTREMOVE)
  {
 -	unsigned long start_pfn = start >> PAGE_SHIFT;
 -	unsigned long nr_pages = size >> PAGE_SHIFT;
 -	struct zone *zone;
 -
 -	zone = page_zone(pfn_to_page(start_pfn));
 -	__remove_pages(zone, start_pfn, nr_pages, altmap);
 -	vmem_remove_mapping(start, size);
 +	/*
 +	 * There is no hardware or firmware interface which could trigger a
 +	 * hot memory remove on s390. So there is nothing that needs to be
 +	 * implemented.
 +	 */
 +	return -EBUSY;
  }
- #endif
  #endif /* CONFIG_MEMORY_HOTPLUG */
diff --cc arch/sh/mm/init.c
index 55c740ab861b,dfdbaa50946e..000000000000
--- a/arch/sh/mm/init.c
+++ b/arch/sh/mm/init.c
@@@ -453,21 -429,14 +453,25 @@@ int memory_add_physaddr_to_nid(u64 addr
  EXPORT_SYMBOL_GPL(memory_add_physaddr_to_nid);
  #endif
  
++<<<<<<< HEAD
 +#ifdef CONFIG_MEMORY_HOTREMOVE
 +int arch_remove_memory(int nid, u64 start, u64 size, struct vmem_altmap *altmap)
++=======
+ void arch_remove_memory(int nid, u64 start, u64 size,
+ 			struct vmem_altmap *altmap)
++>>>>>>> 80ec922dbd87 (mm/memory_hotplug: allow arch_remove_memory() without CONFIG_MEMORY_HOTREMOVE)
  {
  	unsigned long start_pfn = PFN_DOWN(start);
  	unsigned long nr_pages = size >> PAGE_SHIFT;
  	struct zone *zone;
 +	int ret;
  
  	zone = page_zone(pfn_to_page(start_pfn));
 -	__remove_pages(zone, start_pfn, nr_pages, altmap);
 +	ret = __remove_pages(zone, start_pfn, nr_pages, altmap);
 +	if (unlikely(ret))
 +		pr_warn("%s: Failed, __remove_pages() == %d\n", __func__,
 +			ret);
 +
 +	return ret;
  }
- #endif
  #endif /* CONFIG_MEMORY_HOTPLUG */
diff --cc arch/x86/mm/init_32.c
index 3988185cef60,4068abb9427f..000000000000
--- a/arch/x86/mm/init_32.c
+++ b/arch/x86/mm/init_32.c
@@@ -857,21 -857,20 +857,25 @@@ int arch_add_memory(int nid, u64 start
  	unsigned long start_pfn = start >> PAGE_SHIFT;
  	unsigned long nr_pages = size >> PAGE_SHIFT;
  
 -	return __add_pages(nid, start_pfn, nr_pages, restrictions);
 +	return __add_pages(nid, start_pfn, nr_pages, altmap, want_memblock);
  }
  
++<<<<<<< HEAD
 +#ifdef CONFIG_MEMORY_HOTREMOVE
 +int arch_remove_memory(int nid, u64 start, u64 size, struct vmem_altmap *altmap)
++=======
+ void arch_remove_memory(int nid, u64 start, u64 size,
+ 			struct vmem_altmap *altmap)
++>>>>>>> 80ec922dbd87 (mm/memory_hotplug: allow arch_remove_memory() without CONFIG_MEMORY_HOTREMOVE)
  {
  	unsigned long start_pfn = start >> PAGE_SHIFT;
  	unsigned long nr_pages = size >> PAGE_SHIFT;
  	struct zone *zone;
  
  	zone = page_zone(pfn_to_page(start_pfn));
 -	__remove_pages(zone, start_pfn, nr_pages, altmap);
 +	return __remove_pages(zone, start_pfn, nr_pages, altmap);
  }
  #endif
- #endif
  
  int kernel_set_to_readonly __read_mostly;
  
diff --cc include/linux/memory_hotplug.h
index 73f431adb15b,87bf9c4a889e..000000000000
--- a/include/linux/memory_hotplug.h
+++ b/include/linux/memory_hotplug.h
@@@ -108,12 -123,18 +108,19 @@@ static inline bool movable_node_is_enab
  	return movable_node_enabled;
  }
  
++<<<<<<< HEAD
 +#ifdef CONFIG_MEMORY_HOTREMOVE
 +extern int arch_remove_memory(int nid, u64 start, u64 size,
 +				struct vmem_altmap *altmap);
 +extern int __remove_pages(struct zone *zone, unsigned long start_pfn,
 +	unsigned long nr_pages, struct vmem_altmap *altmap);
 +#endif /* CONFIG_MEMORY_HOTREMOVE */
++=======
+ extern void arch_remove_memory(int nid, u64 start, u64 size,
+ 			       struct vmem_altmap *altmap);
+ extern void __remove_pages(struct zone *zone, unsigned long start_pfn,
+ 			   unsigned long nr_pages, struct vmem_altmap *altmap);
 -
 -/*
 - * Do we want sysfs memblock files created. This will allow userspace to online
 - * and offline memory explicitly. Lack of this bit means that the caller has to
 - * call move_pfn_range_to_zone to finish the initialization.
 - */
 -
 -#define MHP_MEMBLOCK_API               (1<<0)
++>>>>>>> 80ec922dbd87 (mm/memory_hotplug: allow arch_remove_memory() without CONFIG_MEMORY_HOTREMOVE)
  
  /* reasonably generic interface to expand the physical pages */
  extern int __add_pages(int nid, unsigned long start_pfn, unsigned long nr_pages,
diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c
index e9b4ea5bfb90..3baf35d45646 100644
--- a/arch/arm64/mm/mmu.c
+++ b/arch/arm64/mm/mmu.c
@@ -1060,7 +1060,6 @@ int arch_add_memory(int nid, u64 start, u64 size, struct vmem_altmap *altmap,
 	return __add_pages(nid, start >> PAGE_SHIFT, size >> PAGE_SHIFT,
 			   altmap, want_memblock);
 }
-#ifdef CONFIG_MEMORY_HOTREMOVE
 void arch_remove_memory(int nid, u64 start, u64 size,
 			struct vmem_altmap *altmap)
 {
@@ -1079,4 +1078,3 @@ void arch_remove_memory(int nid, u64 start, u64 size,
 	__remove_pages(zone, start_pfn, nr_pages, altmap);
 }
 #endif
-#endif
* Unmerged path arch/ia64/mm/init.c
* Unmerged path arch/powerpc/mm/mem.c
* Unmerged path arch/s390/mm/init.c
* Unmerged path arch/sh/mm/init.c
* Unmerged path arch/x86/mm/init_32.c
diff --git a/arch/x86/mm/init_64.c b/arch/x86/mm/init_64.c
index df54e352638e..17039b1390b3 100644
--- a/arch/x86/mm/init_64.c
+++ b/arch/x86/mm/init_64.c
@@ -1196,7 +1196,6 @@ void __ref vmemmap_free(unsigned long start, unsigned long end,
 	remove_pagetable(start, end, false, altmap);
 }
 
-#ifdef CONFIG_MEMORY_HOTREMOVE
 static void __meminit
 kernel_physical_mapping_remove(unsigned long start, unsigned long end)
 {
@@ -1225,7 +1224,6 @@ int __ref arch_remove_memory(int nid, u64 start, u64 size,
 
 	return ret;
 }
-#endif
 #endif /* CONFIG_MEMORY_HOTPLUG */
 
 static struct kcore_list kcore_vsyscall;
diff --git a/drivers/base/memory.c b/drivers/base/memory.c
index b031eaa5b09d..ca7fb67d0ff4 100644
--- a/drivers/base/memory.c
+++ b/drivers/base/memory.c
@@ -729,7 +729,6 @@ int hotplug_memory_register(int nid, struct mem_section *section)
 	return ret;
 }
 
-#ifdef CONFIG_MEMORY_HOTREMOVE
 static void
 unregister_memory(struct memory_block *memory)
 {
@@ -768,7 +767,6 @@ void unregister_memory_section(struct mem_section *section)
 out_unlock:
 	mutex_unlock(&mem_sysfs_mutex);
 }
-#endif /* CONFIG_MEMORY_HOTREMOVE */
 
 /* return true if the memory block is offlined, otherwise, return false */
 bool is_memblock_offlined(struct memory_block *mem)
diff --git a/include/linux/memory.h b/include/linux/memory.h
index e1dc1bb2b787..474c7c60c8f2 100644
--- a/include/linux/memory.h
+++ b/include/linux/memory.h
@@ -112,9 +112,7 @@ extern void unregister_memory_notifier(struct notifier_block *nb);
 extern int register_memory_isolate_notifier(struct notifier_block *nb);
 extern void unregister_memory_isolate_notifier(struct notifier_block *nb);
 int hotplug_memory_register(int nid, struct mem_section *section);
-#ifdef CONFIG_MEMORY_HOTREMOVE
 extern void unregister_memory_section(struct mem_section *);
-#endif
 extern int memory_dev_init(void);
 extern int memory_notify(unsigned long val, void *v);
 extern int memory_isolate_notify(unsigned long val, void *v);
* Unmerged path include/linux/memory_hotplug.h
diff --git a/mm/memory_hotplug.c b/mm/memory_hotplug.c
index 20f1bc790834..ae2f58aa2f2c 100644
--- a/mm/memory_hotplug.c
+++ b/mm/memory_hotplug.c
@@ -321,7 +321,6 @@ int __ref __add_pages(int nid, unsigned long phys_start_pfn,
 	return err;
 }
 
-#ifdef CONFIG_MEMORY_HOTREMOVE
 /* find the smallest valid pfn in the range [start_pfn, end_pfn) */
 static unsigned long find_smallest_section_pfn(int nid, struct zone *zone,
 				     unsigned long start_pfn,
@@ -586,7 +585,6 @@ int __remove_pages(struct zone *zone, unsigned long phys_start_pfn,
 	set_zone_contiguous(zone);
 	return 0;
 }
-#endif /* CONFIG_MEMORY_HOTREMOVE */
 
 int set_online_page_callback(online_page_callback_t callback)
 {
diff --git a/mm/sparse.c b/mm/sparse.c
index edfa6639f57a..14f470919341 100644
--- a/mm/sparse.c
+++ b/mm/sparse.c
@@ -576,7 +576,6 @@ static void __kfree_section_memmap(struct page *memmap,
 
 	vmemmap_free(start, end, altmap);
 }
-#ifdef CONFIG_MEMORY_HOTREMOVE
 static void free_map_bootmem(struct page *memmap)
 {
 	unsigned long start = (unsigned long)memmap;
@@ -584,7 +583,6 @@ static void free_map_bootmem(struct page *memmap)
 
 	vmemmap_free(start, end, NULL);
 }
-#endif /* CONFIG_MEMORY_HOTREMOVE */
 #else
 static struct page *__kmalloc_section_memmap(void)
 {
@@ -623,7 +621,6 @@ static void __kfree_section_memmap(struct page *memmap,
 			   get_order(sizeof(struct page) * PAGES_PER_SECTION));
 }
 
-#ifdef CONFIG_MEMORY_HOTREMOVE
 static void free_map_bootmem(struct page *memmap)
 {
 	unsigned long maps_section_nr, removing_section_nr, i;
@@ -653,7 +650,6 @@ static void free_map_bootmem(struct page *memmap)
 			put_page_bootmem(page);
 	}
 }
-#endif /* CONFIG_MEMORY_HOTREMOVE */
 #endif /* CONFIG_SPARSEMEM_VMEMMAP */
 
 /**
@@ -718,7 +714,6 @@ int __meminit sparse_add_one_section(int nid, unsigned long start_pfn,
 	return ret;
 }
 
-#ifdef CONFIG_MEMORY_HOTREMOVE
 #ifdef CONFIG_MEMORY_FAILURE
 static void clear_hwpoisoned_pages(struct page *memmap, int nr_pages)
 {
@@ -786,5 +781,4 @@ void sparse_remove_one_section(struct zone *zone, struct mem_section *ms,
 			PAGES_PER_SECTION - map_offset);
 	free_section_usemap(memmap, usemap, altmap);
 }
-#endif /* CONFIG_MEMORY_HOTREMOVE */
 #endif /* CONFIG_MEMORY_HOTPLUG */
