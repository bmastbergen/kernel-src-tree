locking/lockdep: Define INITIAL_CHAIN_KEY for chain keys to start with

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Yuyang Du <duyuyang@gmail.com>
commit f6ec8829ac9d59b637366c13038f15d6f6156fe1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/f6ec8829.failed

Chain keys are computed using Jenkins hash function, which needs an initial
hash to start with. Dedicate a macro to make this clear and configurable. A
later patch changes this initial chain key.

	Signed-off-by: Yuyang Du <duyuyang@gmail.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: bvanassche@acm.org
	Cc: frederic@kernel.org
	Cc: ming.lei@redhat.com
	Cc: will.deacon@arm.com
Link: https://lkml.kernel.org/r/20190506081939.74287-9-duyuyang@gmail.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit f6ec8829ac9d59b637366c13038f15d6f6156fe1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/locking/lockdep.c
diff --cc kernel/locking/lockdep.c
index 083a2ab0e8d2,9edf6f12b711..000000000000
--- a/kernel/locking/lockdep.c
+++ b/kernel/locking/lockdep.c
@@@ -765,8 -798,195 +765,184 @@@ static bool assign_lock_key(struct lock
  	return true;
  }
  
 -#ifdef CONFIG_DEBUG_LOCKDEP
 -
 -/* Check whether element @e occurs in list @h */
 -static bool in_list(struct list_head *e, struct list_head *h)
 -{
 -	struct list_head *f;
 -
 -	list_for_each(f, h) {
 -		if (e == f)
 -			return true;
 -	}
 -
 -	return false;
 -}
 -
  /*
++<<<<<<< HEAD
 + * Initialize the lock_classes[] array elements.
++=======
+  * Check whether entry @e occurs in any of the locks_after or locks_before
+  * lists.
+  */
+ static bool in_any_class_list(struct list_head *e)
+ {
+ 	struct lock_class *class;
+ 	int i;
+ 
+ 	for (i = 0; i < ARRAY_SIZE(lock_classes); i++) {
+ 		class = &lock_classes[i];
+ 		if (in_list(e, &class->locks_after) ||
+ 		    in_list(e, &class->locks_before))
+ 			return true;
+ 	}
+ 	return false;
+ }
+ 
+ static bool class_lock_list_valid(struct lock_class *c, struct list_head *h)
+ {
+ 	struct lock_list *e;
+ 
+ 	list_for_each_entry(e, h, entry) {
+ 		if (e->links_to != c) {
+ 			printk(KERN_INFO "class %s: mismatch for lock entry %ld; class %s <> %s",
+ 			       c->name ? : "(?)",
+ 			       (unsigned long)(e - list_entries),
+ 			       e->links_to && e->links_to->name ?
+ 			       e->links_to->name : "(?)",
+ 			       e->class && e->class->name ? e->class->name :
+ 			       "(?)");
+ 			return false;
+ 		}
+ 	}
+ 	return true;
+ }
+ 
+ #ifdef CONFIG_PROVE_LOCKING
+ static u16 chain_hlocks[MAX_LOCKDEP_CHAIN_HLOCKS];
+ #endif
+ 
+ static bool check_lock_chain_key(struct lock_chain *chain)
+ {
+ #ifdef CONFIG_PROVE_LOCKING
+ 	u64 chain_key = INITIAL_CHAIN_KEY;
+ 	int i;
+ 
+ 	for (i = chain->base; i < chain->base + chain->depth; i++)
+ 		chain_key = iterate_chain_key(chain_key, chain_hlocks[i] + 1);
+ 	/*
+ 	 * The 'unsigned long long' casts avoid that a compiler warning
+ 	 * is reported when building tools/lib/lockdep.
+ 	 */
+ 	if (chain->chain_key != chain_key) {
+ 		printk(KERN_INFO "chain %lld: key %#llx <> %#llx\n",
+ 		       (unsigned long long)(chain - lock_chains),
+ 		       (unsigned long long)chain->chain_key,
+ 		       (unsigned long long)chain_key);
+ 		return false;
+ 	}
+ #endif
+ 	return true;
+ }
+ 
+ static bool in_any_zapped_class_list(struct lock_class *class)
+ {
+ 	struct pending_free *pf;
+ 	int i;
+ 
+ 	for (i = 0, pf = delayed_free.pf; i < ARRAY_SIZE(delayed_free.pf); i++, pf++) {
+ 		if (in_list(&class->lock_entry, &pf->zapped))
+ 			return true;
+ 	}
+ 
+ 	return false;
+ }
+ 
+ static bool __check_data_structures(void)
+ {
+ 	struct lock_class *class;
+ 	struct lock_chain *chain;
+ 	struct hlist_head *head;
+ 	struct lock_list *e;
+ 	int i;
+ 
+ 	/* Check whether all classes occur in a lock list. */
+ 	for (i = 0; i < ARRAY_SIZE(lock_classes); i++) {
+ 		class = &lock_classes[i];
+ 		if (!in_list(&class->lock_entry, &all_lock_classes) &&
+ 		    !in_list(&class->lock_entry, &free_lock_classes) &&
+ 		    !in_any_zapped_class_list(class)) {
+ 			printk(KERN_INFO "class %px/%s is not in any class list\n",
+ 			       class, class->name ? : "(?)");
+ 			return false;
+ 		}
+ 	}
+ 
+ 	/* Check whether all classes have valid lock lists. */
+ 	for (i = 0; i < ARRAY_SIZE(lock_classes); i++) {
+ 		class = &lock_classes[i];
+ 		if (!class_lock_list_valid(class, &class->locks_before))
+ 			return false;
+ 		if (!class_lock_list_valid(class, &class->locks_after))
+ 			return false;
+ 	}
+ 
+ 	/* Check the chain_key of all lock chains. */
+ 	for (i = 0; i < ARRAY_SIZE(chainhash_table); i++) {
+ 		head = chainhash_table + i;
+ 		hlist_for_each_entry_rcu(chain, head, entry) {
+ 			if (!check_lock_chain_key(chain))
+ 				return false;
+ 		}
+ 	}
+ 
+ 	/*
+ 	 * Check whether all list entries that are in use occur in a class
+ 	 * lock list.
+ 	 */
+ 	for_each_set_bit(i, list_entries_in_use, ARRAY_SIZE(list_entries)) {
+ 		e = list_entries + i;
+ 		if (!in_any_class_list(&e->entry)) {
+ 			printk(KERN_INFO "list entry %d is not in any class list; class %s <> %s\n",
+ 			       (unsigned int)(e - list_entries),
+ 			       e->class->name ? : "(?)",
+ 			       e->links_to->name ? : "(?)");
+ 			return false;
+ 		}
+ 	}
+ 
+ 	/*
+ 	 * Check whether all list entries that are not in use do not occur in
+ 	 * a class lock list.
+ 	 */
+ 	for_each_clear_bit(i, list_entries_in_use, ARRAY_SIZE(list_entries)) {
+ 		e = list_entries + i;
+ 		if (in_any_class_list(&e->entry)) {
+ 			printk(KERN_INFO "list entry %d occurs in a class list; class %s <> %s\n",
+ 			       (unsigned int)(e - list_entries),
+ 			       e->class && e->class->name ? e->class->name :
+ 			       "(?)",
+ 			       e->links_to && e->links_to->name ?
+ 			       e->links_to->name : "(?)");
+ 			return false;
+ 		}
+ 	}
+ 
+ 	return true;
+ }
+ 
+ int check_consistency = 0;
+ module_param(check_consistency, int, 0644);
+ 
+ static void check_data_structures(void)
+ {
+ 	static bool once = false;
+ 
+ 	if (check_consistency && !once) {
+ 		if (!__check_data_structures()) {
+ 			once = true;
+ 			WARN_ON(once);
+ 		}
+ 	}
+ }
+ 
+ #else /* CONFIG_DEBUG_LOCKDEP */
+ 
+ static inline void check_data_structures(void) { }
+ 
+ #endif /* CONFIG_DEBUG_LOCKDEP */
+ 
+ /*
+  * Initialize the lock_classes[] array elements, the free_lock_classes list
+  * and also the delayed_free structure.
++>>>>>>> f6ec8829ac9d (locking/lockdep: Define INITIAL_CHAIN_KEY for chain keys to start with)
   */
  static void init_data_structures_once(void)
  {
@@@ -4291,6 -4607,82 +4467,85 @@@ void lockdep_reset(void
  	raw_local_irq_restore(flags);
  }
  
++<<<<<<< HEAD
++=======
+ /* Remove a class from a lock chain. Must be called with the graph lock held. */
+ static void remove_class_from_lock_chain(struct pending_free *pf,
+ 					 struct lock_chain *chain,
+ 					 struct lock_class *class)
+ {
+ #ifdef CONFIG_PROVE_LOCKING
+ 	struct lock_chain *new_chain;
+ 	u64 chain_key;
+ 	int i;
+ 
+ 	for (i = chain->base; i < chain->base + chain->depth; i++) {
+ 		if (chain_hlocks[i] != class - lock_classes)
+ 			continue;
+ 		/* The code below leaks one chain_hlock[] entry. */
+ 		if (--chain->depth > 0) {
+ 			memmove(&chain_hlocks[i], &chain_hlocks[i + 1],
+ 				(chain->base + chain->depth - i) *
+ 				sizeof(chain_hlocks[0]));
+ 		}
+ 		/*
+ 		 * Each lock class occurs at most once in a lock chain so once
+ 		 * we found a match we can break out of this loop.
+ 		 */
+ 		goto recalc;
+ 	}
+ 	/* Since the chain has not been modified, return. */
+ 	return;
+ 
+ recalc:
+ 	chain_key = INITIAL_CHAIN_KEY;
+ 	for (i = chain->base; i < chain->base + chain->depth; i++)
+ 		chain_key = iterate_chain_key(chain_key, chain_hlocks[i] + 1);
+ 	if (chain->depth && chain->chain_key == chain_key)
+ 		return;
+ 	/* Overwrite the chain key for concurrent RCU readers. */
+ 	WRITE_ONCE(chain->chain_key, chain_key);
+ 	/*
+ 	 * Note: calling hlist_del_rcu() from inside a
+ 	 * hlist_for_each_entry_rcu() loop is safe.
+ 	 */
+ 	hlist_del_rcu(&chain->entry);
+ 	__set_bit(chain - lock_chains, pf->lock_chains_being_freed);
+ 	if (chain->depth == 0)
+ 		return;
+ 	/*
+ 	 * If the modified lock chain matches an existing lock chain, drop
+ 	 * the modified lock chain.
+ 	 */
+ 	if (lookup_chain_cache(chain_key))
+ 		return;
+ 	new_chain = alloc_lock_chain();
+ 	if (WARN_ON_ONCE(!new_chain)) {
+ 		debug_locks_off();
+ 		return;
+ 	}
+ 	*new_chain = *chain;
+ 	hlist_add_head_rcu(&new_chain->entry, chainhashentry(chain_key));
+ #endif
+ }
+ 
+ /* Must be called with the graph lock held. */
+ static void remove_class_from_lock_chains(struct pending_free *pf,
+ 					  struct lock_class *class)
+ {
+ 	struct lock_chain *chain;
+ 	struct hlist_head *head;
+ 	int i;
+ 
+ 	for (i = 0; i < ARRAY_SIZE(chainhash_table); i++) {
+ 		head = chainhash_table + i;
+ 		hlist_for_each_entry_rcu(chain, head, entry) {
+ 			remove_class_from_lock_chain(pf, chain, class);
+ 		}
+ 	}
+ }
+ 
++>>>>>>> f6ec8829ac9d (locking/lockdep: Define INITIAL_CHAIN_KEY for chain keys to start with)
  /*
   * Remove all references to a lock class. The caller must hold the graph lock.
   */
diff --git a/include/linux/lockdep.h b/include/linux/lockdep.h
index e952b94fb5df..fd799539426d 100644
--- a/include/linux/lockdep.h
+++ b/include/linux/lockdep.h
@@ -220,6 +220,7 @@ struct lock_chain {
  * bitfield and hitting the BUG in hlock_class().
  */
 #define MAX_LOCKDEP_KEYS		((1UL << MAX_LOCKDEP_KEYS_BITS) - 1)
+#define INITIAL_CHAIN_KEY		0
 
 struct held_lock {
 	/*
diff --git a/init/init_task.c b/init/init_task.c
index ca808530aa23..da13e6871017 100644
--- a/init/init_task.c
+++ b/init/init_task.c
@@ -168,7 +168,7 @@ struct task_struct init_task
 #endif
 #ifdef CONFIG_LOCKDEP
 	.lockdep_depth = 0, /* no locks held yet */
-	.curr_chain_key = 0,
+	.curr_chain_key = INITIAL_CHAIN_KEY,
 	.lockdep_recursion = 0,
 #endif
 #ifdef CONFIG_FUNCTION_GRAPH_TRACER
* Unmerged path kernel/locking/lockdep.c
