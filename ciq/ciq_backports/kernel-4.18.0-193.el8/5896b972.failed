net/mlx5: E-switch, Tide up eswitch config sequence

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [netdrv] mlx5: E-switch, Tide up eswitch config sequence (Alaa Hleihel) [1724327 1724336]
Rebuild_FUZZ: 95.92%
commit-author Parav Pandit <parav@mellanox.com>
commit 5896b97296a7928035590ff3f477629774dce250
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/5896b972.failed

Currently for PF and ECPF vports, representors are created before
their eswitch hardware ports are initialized in below flow.

mlx5_eswitch_enable()
  esw_offloads_init()
    esw_offloads_load_all_reps()
[..]
esw_enable_vport()

However for VFs, vports are initialized before creating their
respective netdev represnetors in event handling context.

Similarly while disabling eswitch, first hardware vports are disabled,
followed by destroying their representors.
Here while underlying vports gets destroyed but its respective user
facing netdevice can still exist on which user can continue to perform
more offload operations.

Instead, its more accurate to do
enable_eswitch switchdev mode:
1. perform FDB tables initialization
2. initialize hw vport
3. create and publish representor for this vport

disable_eswitch switchdev mode:
1. destroy user facing representor for the vport
2. disable hw vport
3. perform FDB tables cleanup

	Signed-off-by: Parav Pandit <parav@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 5896b97296a7928035590ff3f477629774dce250)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
index be195cce77a4,d4465dd18c11..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@@ -1719,10 -1766,98 +1748,45 @@@ static int eswitch_vport_event(struct n
  /* Public E-Switch API */
  #define ESW_ALLOWED(esw) ((esw) && MLX5_ESWITCH_MANAGER((esw)->dev))
  
 -/* mlx5_eswitch_enable_pf_vf_vports() enables vports of PF, ECPF and VFs
 - * whichever are present on the eswitch.
 - */
 -void
 -mlx5_eswitch_enable_pf_vf_vports(struct mlx5_eswitch *esw,
 -				 enum mlx5_eswitch_vport_event enabled_events)
 +int mlx5_eswitch_enable_sriov(struct mlx5_eswitch *esw, int nvfs, int mode)
  {
++<<<<<<< HEAD
++=======
+ 	struct mlx5_vport *vport;
+ 	int i;
+ 
+ 	/* Enable PF vport */
+ 	vport = mlx5_eswitch_get_vport(esw, MLX5_VPORT_PF);
+ 	esw_enable_vport(esw, vport, enabled_events);
+ 
+ 	/* Enable ECPF vports */
+ 	if (mlx5_ecpf_vport_exists(esw->dev)) {
+ 		vport = mlx5_eswitch_get_vport(esw, MLX5_VPORT_ECPF);
+ 		esw_enable_vport(esw, vport, enabled_events);
+ 	}
+ 
+ 	/* Enable VF vports */
+ 	mlx5_esw_for_each_vf_vport(esw, i, vport, esw->esw_funcs.num_vfs)
+ 		esw_enable_vport(esw, vport, enabled_events);
+ }
+ 
+ /* mlx5_eswitch_disable_pf_vf_vports() disables vports of PF, ECPF and VFs
+  * whichever are previously enabled on the eswitch.
+  */
+ void mlx5_eswitch_disable_pf_vf_vports(struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_vport *vport;
+ 	int i;
+ 
+ 	mlx5_esw_for_all_vports_reverse(esw, i, vport)
+ 		esw_disable_vport(esw, vport);
+ }
+ 
+ int mlx5_eswitch_enable(struct mlx5_eswitch *esw, int mode)
+ {
++>>>>>>> 5896b97296a7 (net/mlx5: E-switch, Tide up eswitch config sequence)
  	int err;
 +	int i, enabled_events;
  
  	if (!ESW_ALLOWED(esw) ||
  	    !MLX5_CAP_ESW_FLOWTABLE_FDB(esw->dev, ft_support)) {
@@@ -1742,36 -1877,23 +1806,53 @@@
  
  	mlx5_lag_update(esw->dev);
  
++<<<<<<< HEAD
 +	if (mode == SRIOV_LEGACY) {
 +		err = esw_create_legacy_table(esw);
 +	} else {
 +		mlx5_reload_interface(esw->dev, MLX5_INTERFACE_PROTOCOL_ETH);
 +		mlx5_reload_interface(esw->dev, MLX5_INTERFACE_PROTOCOL_IB);
 +		err = esw_offloads_init(esw, nvfs + MLX5_SPECIAL_VPORTS);
++=======
+ 	if (mode == MLX5_ESWITCH_LEGACY) {
+ 		err = esw_legacy_enable(esw);
+ 	} else {
+ 		mlx5_reload_interface(esw->dev, MLX5_INTERFACE_PROTOCOL_ETH);
+ 		mlx5_reload_interface(esw->dev, MLX5_INTERFACE_PROTOCOL_IB);
+ 		err = esw_offloads_enable(esw);
++>>>>>>> 5896b97296a7 (net/mlx5: E-switch, Tide up eswitch config sequence)
  	}
  
  	if (err)
  		goto abort;
  
++<<<<<<< HEAD
 +	err = esw_create_tsar(esw);
 +	if (err)
 +		esw_warn(esw->dev, "Failed to create eswitch TSAR");
 +
 +	/* Don't enable vport events when in SRIOV_OFFLOADS mode, since:
 +	 * 1. L2 table (MPFS) is programmed by PF/VF representors netdevs set_rx_mode
 +	 * 2. FDB/Eswitch is programmed by user space tools
 +	 */
 +	enabled_events = (mode == SRIOV_LEGACY) ? SRIOV_VPORT_EVENTS : 0;
 +	for (i = 0; i <= nvfs; i++)
 +		esw_enable_vport(esw, i, enabled_events);
 +
 +	if (mode == SRIOV_LEGACY) {
 +		MLX5_NB_INIT(&esw->nb, eswitch_vport_event, NIC_VPORT_CHANGE);
 +		mlx5_eq_notifier_register(esw->dev, &esw->nb);
 +	}
++=======
+ 	mlx5_eswitch_event_handlers_register(esw);
+ 
+ 	esw_info(esw->dev, "Enable: mode(%s), nvfs(%d), active vports(%d)\n",
+ 		 mode == MLX5_ESWITCH_LEGACY ? "LEGACY" : "OFFLOADS",
+ 		 esw->esw_funcs.num_vfs, esw->enabled_vports);
++>>>>>>> 5896b97296a7 (net/mlx5: E-switch, Tide up eswitch config sequence)
  
 +	esw_info(esw->dev, "SRIOV enabled: active vports(%d)\n",
 +		 esw->enabled_vports);
  	return 0;
  
  abort:
@@@ -1785,30 -1907,23 +1866,42 @@@
  	return err;
  }
  
 -void mlx5_eswitch_disable(struct mlx5_eswitch *esw)
 +void mlx5_eswitch_disable_sriov(struct mlx5_eswitch *esw)
  {
- 	struct esw_mc_addr *mc_promisc;
  	int old_mode;
 +	int nvports;
 +	int i;
  
 -	if (!ESW_ALLOWED(esw) || esw->mode == MLX5_ESWITCH_NONE)
 +	if (!ESW_ALLOWED(esw) || esw->mode == SRIOV_NONE)
  		return;
  
++<<<<<<< HEAD
 +	esw_info(esw->dev, "disable SRIOV: active vports(%d) mode(%d)\n",
 +		 esw->enabled_vports, esw->mode);
 +
 +	mc_promisc = &esw->mc_promisc;
 +	nvports = esw->enabled_vports;
 +
 +	if (esw->mode == SRIOV_LEGACY)
 +		mlx5_eq_notifier_unregister(esw->dev, &esw->nb);
 +
 +	for (i = 0; i < esw->total_vports; i++)
 +		esw_disable_vport(esw, i);
 +
 +	if (mc_promisc && mc_promisc->uplink_rule)
 +		mlx5_del_flow_rules(mc_promisc->uplink_rule);
++=======
+ 	esw_info(esw->dev, "Disable: mode(%s), nvfs(%d), active vports(%d)\n",
+ 		 esw->mode == MLX5_ESWITCH_LEGACY ? "LEGACY" : "OFFLOADS",
+ 		 esw->esw_funcs.num_vfs, esw->enabled_vports);
+ 
+ 	mlx5_eswitch_event_handlers_unregister(esw);
+ 
+ 	if (esw->mode == MLX5_ESWITCH_LEGACY)
+ 		esw_legacy_disable(esw);
+ 	else if (esw->mode == MLX5_ESWITCH_OFFLOADS)
+ 		esw_offloads_disable(esw);
++>>>>>>> 5896b97296a7 (net/mlx5: E-switch, Tide up eswitch config sequence)
  
  	esw_destroy_tsar(esw);
  
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index af9a875f1cf1,d447e1e44d59..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@@ -209,10 -237,13 +209,15 @@@ struct mlx5_eswitch 
  	struct mlx5_esw_offload offloads;
  	int                     mode;
  	int                     nvports;
 -	u16                     manager_vport;
 -	u16                     first_host_vport;
 -	struct mlx5_esw_functions esw_funcs;
  };
  
++<<<<<<< HEAD
 +void esw_offloads_cleanup(struct mlx5_eswitch *esw, int nvports);
 +int esw_offloads_init(struct mlx5_eswitch *esw, int nvports);
++=======
+ void esw_offloads_disable(struct mlx5_eswitch *esw);
+ int esw_offloads_enable(struct mlx5_eswitch *esw);
++>>>>>>> 5896b97296a7 (net/mlx5: E-switch, Tide up eswitch config sequence)
  void esw_offloads_cleanup_reps(struct mlx5_eswitch *esw);
  int esw_offloads_init_reps(struct mlx5_eswitch *esw);
  void esw_vport_cleanup_ingress_rules(struct mlx5_eswitch *esw,
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
index 2a02050a09e7,db01b8ee9385..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@@ -1599,11 -2034,77 +1599,82 @@@ static void esw_offloads_steering_clean
  	esw_destroy_vport_rx_group(esw);
  	esw_destroy_offloads_table(esw);
  	esw_destroy_offloads_fdb_tables(esw);
 -	esw_destroy_offloads_acl_tables(esw);
 +	if (MLX5_CAP_GEN(esw->dev, prio_tag_required))
 +		esw_prio_tag_acls_cleanup(esw);
  }
  
++<<<<<<< HEAD
 +int esw_offloads_init(struct mlx5_eswitch *esw, int nvports)
++=======
+ static void
+ esw_vfs_changed_event_handler(struct mlx5_eswitch *esw, const u32 *out)
+ {
+ 	bool host_pf_disabled;
+ 	u16 new_num_vfs;
+ 
+ 	new_num_vfs = MLX5_GET(query_esw_functions_out, out,
+ 			       host_params_context.host_num_of_vfs);
+ 	host_pf_disabled = MLX5_GET(query_esw_functions_out, out,
+ 				    host_params_context.host_pf_disabled);
+ 
+ 	if (new_num_vfs == esw->esw_funcs.num_vfs || host_pf_disabled)
+ 		return;
+ 
+ 	/* Number of VFs can only change from "0 to x" or "x to 0". */
+ 	if (esw->esw_funcs.num_vfs > 0) {
+ 		esw_offloads_unload_vf_reps(esw, esw->esw_funcs.num_vfs);
+ 	} else {
+ 		int err;
+ 
+ 		err = esw_offloads_load_vf_reps(esw, new_num_vfs);
+ 		if (err)
+ 			return;
+ 	}
+ 	esw->esw_funcs.num_vfs = new_num_vfs;
+ }
+ 
+ static void esw_functions_changed_event_handler(struct work_struct *work)
+ {
+ 	struct mlx5_host_work *host_work;
+ 	struct mlx5_eswitch *esw;
+ 	const u32 *out;
+ 
+ 	host_work = container_of(work, struct mlx5_host_work, work);
+ 	esw = host_work->esw;
+ 
+ 	out = mlx5_esw_query_functions(esw->dev);
+ 	if (IS_ERR(out))
+ 		goto out;
+ 
+ 	esw_vfs_changed_event_handler(esw, out);
+ 	kvfree(out);
+ out:
+ 	kfree(host_work);
+ }
+ 
+ int mlx5_esw_funcs_changed_handler(struct notifier_block *nb, unsigned long type, void *data)
+ {
+ 	struct mlx5_esw_functions *esw_funcs;
+ 	struct mlx5_host_work *host_work;
+ 	struct mlx5_eswitch *esw;
+ 
+ 	host_work = kzalloc(sizeof(*host_work), GFP_ATOMIC);
+ 	if (!host_work)
+ 		return NOTIFY_DONE;
+ 
+ 	esw_funcs = mlx5_nb_cof(nb, struct mlx5_esw_functions, nb);
+ 	esw = container_of(esw_funcs, struct mlx5_eswitch, esw_funcs);
+ 
+ 	host_work->esw = esw;
+ 
+ 	INIT_WORK(&host_work->work, esw_functions_changed_event_handler);
+ 	queue_work(esw->work_queue, &host_work->work);
+ 
+ 	return NOTIFY_OK;
+ }
+ 
+ int esw_offloads_enable(struct mlx5_eswitch *esw)
++>>>>>>> 5896b97296a7 (net/mlx5: E-switch, Tide up eswitch config sequence)
  {
  	int err;
  
@@@ -1613,7 -2118,13 +1684,17 @@@
  	if (err)
  		return err;
  
++<<<<<<< HEAD
 +	err = esw_offloads_load_reps(esw, nvports);
++=======
+ 	err = esw_set_passing_vport_metadata(esw, true);
+ 	if (err)
+ 		goto err_vport_metadata;
+ 
+ 	mlx5_eswitch_enable_pf_vf_vports(esw, MLX5_VPORT_UC_ADDR_CHANGE);
+ 
+ 	err = esw_offloads_load_all_reps(esw);
++>>>>>>> 5896b97296a7 (net/mlx5: E-switch, Tide up eswitch config sequence)
  	if (err)
  		goto err_reps;
  
@@@ -1621,6 -2132,13 +1702,12 @@@
  	return 0;
  
  err_reps:
++<<<<<<< HEAD
++=======
+ 	mlx5_eswitch_disable_pf_vf_vports(esw);
+ 	esw_set_passing_vport_metadata(esw, false);
+ err_vport_metadata:
++>>>>>>> 5896b97296a7 (net/mlx5: E-switch, Tide up eswitch config sequence)
  	esw_offloads_steering_cleanup(esw);
  	return err;
  }
@@@ -1644,11 -2162,15 +1731,21 @@@ static int esw_offloads_stop(struct mlx
  	return err;
  }
  
++<<<<<<< HEAD
 +void esw_offloads_cleanup(struct mlx5_eswitch *esw, int nvports)
++=======
+ void esw_offloads_disable(struct mlx5_eswitch *esw)
++>>>>>>> 5896b97296a7 (net/mlx5: E-switch, Tide up eswitch config sequence)
  {
 -	mlx5_rdma_disable_roce(esw->dev);
  	esw_offloads_devcom_cleanup(esw);
++<<<<<<< HEAD
 +	esw_offloads_unload_reps(esw, nvports);
++=======
+ 	esw_offloads_unload_all_reps(esw);
+ 	mlx5_eswitch_disable_pf_vf_vports(esw);
+ 	esw_set_passing_vport_metadata(esw, false);
++>>>>>>> 5896b97296a7 (net/mlx5: E-switch, Tide up eswitch config sequence)
  	esw_offloads_steering_cleanup(esw);
 -	esw->offloads.encap = DEVLINK_ESWITCH_ENCAP_MODE_NONE;
  }
  
  static int esw_mode_from_devlink(u16 mode, u16 *mlx5_mode)
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
