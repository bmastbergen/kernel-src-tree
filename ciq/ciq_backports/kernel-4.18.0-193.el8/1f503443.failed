mm/sparse.c: reset section's mem_map when fully deactivated

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Pingfan Liu <kernelfans@gmail.com>
commit 1f503443e7df8dc8366608b4d810ce2d6669827c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/1f503443.failed

After commit ba72b4c8cf60 ("mm/sparsemem: support sub-section hotplug"),
when a mem section is fully deactivated, section_mem_map still records
the section's start pfn, which is not used any more and will be
reassigned during re-addition.

In analogy with alloc/free pattern, it is better to clear all fields of
section_mem_map.

Beside this, it breaks the user space tool "makedumpfile" [1], which
makes assumption that a hot-removed section has mem_map as NULL, instead
of checking directly against SECTION_MARKED_PRESENT bit.  (makedumpfile
will be better to change the assumption, and need a patch)

The bug can be reproduced on IBM POWERVM by "drmgr -c mem -r -q 5" ,
trigger a crash, and save vmcore by makedumpfile

[1]: makedumpfile, commit e73016540293 ("[v1.6.7] Update version")

Link: http://lkml.kernel.org/r/1579487594-28889-1-git-send-email-kernelfans@gmail.com
	Signed-off-by: Pingfan Liu <kernelfans@gmail.com>
	Acked-by: Michal Hocko <mhocko@suse.com>
	Acked-by: David Hildenbrand <david@redhat.com>
	Cc: Dan Williams <dan.j.williams@intel.com>
	Cc: Oscar Salvador <osalvador@suse.de>
	Cc: Baoquan He <bhe@redhat.com>
	Cc: Qian Cai <cai@lca.pw>
	Cc: Kazuhito Hagio <k-hagio@ab.jp.nec.com>
	Cc: <stable@vger.kernel.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 1f503443e7df8dc8366608b4d810ce2d6669827c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/sparse.c
diff --cc mm/sparse.c
index 02b5de3161a3,3918fc3eaef1..000000000000
--- a/mm/sparse.c
+++ b/mm/sparse.c
@@@ -653,13 -734,129 +653,132 @@@ static void free_map_bootmem(struct pag
  			put_page_bootmem(page);
  	}
  }
 +#endif /* CONFIG_MEMORY_HOTREMOVE */
  #endif /* CONFIG_SPARSEMEM_VMEMMAP */
  
++<<<<<<< HEAD
++=======
+ static void section_deactivate(unsigned long pfn, unsigned long nr_pages,
+ 		struct vmem_altmap *altmap)
+ {
+ 	DECLARE_BITMAP(map, SUBSECTIONS_PER_SECTION) = { 0 };
+ 	DECLARE_BITMAP(tmp, SUBSECTIONS_PER_SECTION) = { 0 };
+ 	struct mem_section *ms = __pfn_to_section(pfn);
+ 	bool section_is_early = early_section(ms);
+ 	struct page *memmap = NULL;
+ 	unsigned long *subsection_map = ms->usage
+ 		? &ms->usage->subsection_map[0] : NULL;
+ 
+ 	subsection_mask_set(map, pfn, nr_pages);
+ 	if (subsection_map)
+ 		bitmap_and(tmp, map, subsection_map, SUBSECTIONS_PER_SECTION);
+ 
+ 	if (WARN(!subsection_map || !bitmap_equal(tmp, map, SUBSECTIONS_PER_SECTION),
+ 				"section already deactivated (%#lx + %ld)\n",
+ 				pfn, nr_pages))
+ 		return;
+ 
+ 	/*
+ 	 * There are 3 cases to handle across two configurations
+ 	 * (SPARSEMEM_VMEMMAP={y,n}):
+ 	 *
+ 	 * 1/ deactivation of a partial hot-added section (only possible
+ 	 * in the SPARSEMEM_VMEMMAP=y case).
+ 	 *    a/ section was present at memory init
+ 	 *    b/ section was hot-added post memory init
+ 	 * 2/ deactivation of a complete hot-added section
+ 	 * 3/ deactivation of a complete section from memory init
+ 	 *
+ 	 * For 1/, when subsection_map does not empty we will not be
+ 	 * freeing the usage map, but still need to free the vmemmap
+ 	 * range.
+ 	 *
+ 	 * For 2/ and 3/ the SPARSEMEM_VMEMMAP={y,n} cases are unified
+ 	 */
+ 	bitmap_xor(subsection_map, map, subsection_map, SUBSECTIONS_PER_SECTION);
+ 	if (bitmap_empty(subsection_map, SUBSECTIONS_PER_SECTION)) {
+ 		unsigned long section_nr = pfn_to_section_nr(pfn);
+ 
+ 		/*
+ 		 * When removing an early section, the usage map is kept (as the
+ 		 * usage maps of other sections fall into the same page). It
+ 		 * will be re-used when re-adding the section - which is then no
+ 		 * longer an early section. If the usage map is PageReserved, it
+ 		 * was allocated during boot.
+ 		 */
+ 		if (!PageReserved(virt_to_page(ms->usage))) {
+ 			kfree(ms->usage);
+ 			ms->usage = NULL;
+ 		}
+ 		memmap = sparse_decode_mem_map(ms->section_mem_map, section_nr);
+ 		ms->section_mem_map = (unsigned long)NULL;
+ 	}
+ 
+ 	if (section_is_early && memmap)
+ 		free_map_bootmem(memmap);
+ 	else
+ 		depopulate_section_memmap(pfn, nr_pages, altmap);
+ }
+ 
+ static struct page * __meminit section_activate(int nid, unsigned long pfn,
+ 		unsigned long nr_pages, struct vmem_altmap *altmap)
+ {
+ 	DECLARE_BITMAP(map, SUBSECTIONS_PER_SECTION) = { 0 };
+ 	struct mem_section *ms = __pfn_to_section(pfn);
+ 	struct mem_section_usage *usage = NULL;
+ 	unsigned long *subsection_map;
+ 	struct page *memmap;
+ 	int rc = 0;
+ 
+ 	subsection_mask_set(map, pfn, nr_pages);
+ 
+ 	if (!ms->usage) {
+ 		usage = kzalloc(mem_section_usage_size(), GFP_KERNEL);
+ 		if (!usage)
+ 			return ERR_PTR(-ENOMEM);
+ 		ms->usage = usage;
+ 	}
+ 	subsection_map = &ms->usage->subsection_map[0];
+ 
+ 	if (bitmap_empty(map, SUBSECTIONS_PER_SECTION))
+ 		rc = -EINVAL;
+ 	else if (bitmap_intersects(map, subsection_map, SUBSECTIONS_PER_SECTION))
+ 		rc = -EEXIST;
+ 	else
+ 		bitmap_or(subsection_map, map, subsection_map,
+ 				SUBSECTIONS_PER_SECTION);
+ 
+ 	if (rc) {
+ 		if (usage)
+ 			ms->usage = NULL;
+ 		kfree(usage);
+ 		return ERR_PTR(rc);
+ 	}
+ 
+ 	/*
+ 	 * The early init code does not consider partially populated
+ 	 * initial sections, it simply assumes that memory will never be
+ 	 * referenced.  If we hot-add memory into such a section then we
+ 	 * do not need to populate the memmap and can simply reuse what
+ 	 * is already there.
+ 	 */
+ 	if (nr_pages < PAGES_PER_SECTION && early_section(ms))
+ 		return pfn_to_page(pfn);
+ 
+ 	memmap = populate_section_memmap(pfn, nr_pages, nid, altmap);
+ 	if (!memmap) {
+ 		section_deactivate(pfn, nr_pages, altmap);
+ 		return ERR_PTR(-ENOMEM);
+ 	}
+ 
+ 	return memmap;
+ }
+ 
++>>>>>>> 1f503443e7df (mm/sparse.c: reset section's mem_map when fully deactivated)
  /**
 - * sparse_add_section - add a memory section, or populate an existing one
 + * sparse_add_one_section - add a memory section
   * @nid: The node to add section on
   * @start_pfn: start pfn of the memory range
 - * @nr_pages: number of pfns to add in the section
   * @altmap: device page map
   *
   * This is only intended for hotplug.
* Unmerged path mm/sparse.c
