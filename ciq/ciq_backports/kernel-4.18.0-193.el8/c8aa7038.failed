net/flow_dissector: move bpf case into __skb_flow_bpf_dissect

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Stanislav Fomichev <sdf@google.com>
commit c8aa703822bf811269975cf7251b5eaad4c38e9c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/c8aa7038.failed

This way, we can reuse it for flow dissector in BPF_PROG_TEST_RUN.

No functional changes.

	Signed-off-by: Stanislav Fomichev <sdf@google.com>
	Acked-by: Song Liu <songliubraving@fb.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
(cherry picked from commit c8aa703822bf811269975cf7251b5eaad4c38e9c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/core/flow_dissector.c
diff --cc net/core/flow_dissector.c
index ea22c4441222,bb1a54747d64..000000000000
--- a/net/core/flow_dissector.c
+++ b/net/core/flow_dissector.c
@@@ -762,47 -805,18 +805,46 @@@ bool __skb_flow_dissect(const struct sk
  			attached = rcu_dereference(sock_net(skb->sk)->flow_dissector_prog);
  		else
  			WARN_ON_ONCE(1);
- 	}
- 	if (attached) {
- 		/* Note that even though the const qualifier is discarded
- 		 * throughout the execution of the BPF program, all changes(the
- 		 * control block) are reverted after the BPF program returns.
- 		 * Therefore, __skb_flow_dissect does not alter the skb.
- 		 */
- 		struct bpf_flow_keys flow_keys = {};
- 		struct bpf_skb_data_end cb_saved;
- 		struct bpf_skb_data_end *cb;
- 		u32 result;
  
++<<<<<<< HEAD
 +		cb = (struct bpf_skb_data_end *)skb->cb;
 +
 +		/* Save Control Block */
 +		memcpy(&cb_saved, cb, sizeof(cb_saved));
 +		memset(cb, 0, sizeof(cb_saved));
 +
 +		/* Pass parameters to the BPF program */
 +		cb->qdisc_cb.flow_keys = &flow_keys;
 +		flow_keys.nhoff = nhoff;
 +		flow_keys.thoff = nhoff;
 +
 +		bpf_compute_data_pointers((struct sk_buff *)skb);
 +		preempt_disable();
 +		result = BPF_PROG_RUN(attached, skb);
 +		preempt_enable();
 +
 +		/* Restore state */
 +		memcpy(cb, &cb_saved, sizeof(cb_saved));
 +
 +		flow_keys.nhoff = clamp_t(u16, flow_keys.nhoff, 0, skb->len);
 +		flow_keys.thoff = clamp_t(u16, flow_keys.thoff,
 +					  flow_keys.nhoff, skb->len);
 +
 +		__skb_flow_bpf_to_target(&flow_keys, flow_dissector,
 +					 target_container);
++=======
+ 		if (attached) {
+ 			ret = __skb_flow_bpf_dissect(attached, skb,
+ 						     flow_dissector,
+ 						     &flow_keys);
+ 			__skb_flow_bpf_to_target(&flow_keys, flow_dissector,
+ 						 target_container);
+ 			rcu_read_unlock();
+ 			return ret;
+ 		}
++>>>>>>> c8aa703822bf (net/flow_dissector: move bpf case into __skb_flow_bpf_dissect)
  		rcu_read_unlock();
- 		return result == BPF_OK;
  	}
- 	rcu_read_unlock();
  
  	if (dissector_uses_key(flow_dissector,
  			       FLOW_DISSECTOR_KEY_ETH_ADDRS)) {
diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index 6d204af45878..f0489b913a22 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -1250,6 +1250,11 @@ static inline int skb_flow_dissector_bpf_prog_detach(const union bpf_attr *attr)
 }
 #endif
 
+struct bpf_flow_keys;
+bool __skb_flow_bpf_dissect(struct bpf_prog *prog,
+			    const struct sk_buff *skb,
+			    struct flow_dissector *flow_dissector,
+			    struct bpf_flow_keys *flow_keys);
 bool __skb_flow_dissect(const struct sk_buff *skb,
 			struct flow_dissector *flow_dissector,
 			void *target_container,
* Unmerged path net/core/flow_dissector.c
