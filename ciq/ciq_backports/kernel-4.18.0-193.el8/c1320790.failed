arm64: perf: Add support for chaining event counters

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [arm64] perf: Add support for chaining event counters (Auger Eric) [1749501]
Rebuild_FUZZ: 92.78%
commit-author Suzuki K Poulose <suzuki.poulose@arm.com>
commit c13207905340d85eaddd85b6d2868218f324b180
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/c1320790.failed

Add support for 64bit event by using chained event counters
and 64bit cycle counters.

PMUv3 allows chaining a pair of adjacent 32-bit counters, effectively
forming a 64-bit counter. The low/even counter is programmed to count
the event of interest, and the high/odd counter is programmed to count
the CHAIN event, taken when the low/even counter overflows.

For CPU cycles, when 64bit mode is requested, the cycle counter
is used in 64bit mode. If the cycle counter is not available,
falls back to chaining.

	Cc: Will Deacon <will.deacon@arm.com>
	Acked-by: Mark Rutland <mark.rutland@arm.com>
	Signed-off-by: Suzuki K Poulose <suzuki.poulose@arm.com>
	Signed-off-by: Will Deacon <will.deacon@arm.com>
(cherry picked from commit c13207905340d85eaddd85b6d2868218f324b180)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/kernel/perf_event.c
diff --cc arch/arm64/kernel/perf_event.c
index 019a00051790,dfff5ed5c625..000000000000
--- a/arch/arm64/kernel/perf_event.c
+++ b/arch/arm64/kernel/perf_event.c
@@@ -789,15 -911,22 +916,25 @@@ static int armv8pmu_get_event_idx(struc
  	/*
  	 * Otherwise use events counters
  	 */
- 	for (idx = ARMV8_IDX_COUNTER0; idx < cpu_pmu->num_events; ++idx) {
- 		if (!test_and_set_bit(idx, cpuc->used_mask))
- 			return idx;
- 	}
+ 	if (armv8pmu_event_is_64bit(event))
+ 		return	armv8pmu_get_chain_idx(cpuc, cpu_pmu);
+ 	else
+ 		return armv8pmu_get_single_idx(cpuc, cpu_pmu);
+ }
  
- 	/* The counters are all in use. */
- 	return -EAGAIN;
++<<<<<<< HEAD
++=======
+ static void armv8pmu_clear_event_idx(struct pmu_hw_events *cpuc,
+ 				     struct perf_event *event)
+ {
+ 	int idx = event->hw.idx;
+ 
+ 	clear_bit(idx, cpuc->used_mask);
+ 	if (armv8pmu_event_is_chained(event))
+ 		clear_bit(idx - 1, cpuc->used_mask);
  }
  
++>>>>>>> c13207905340 (arm64: perf: Add support for chaining event counters)
  /*
   * Add an event filter to a given event. This will only work for PMUv2 PMUs.
   */
* Unmerged path arch/arm64/kernel/perf_event.c
diff --git a/drivers/perf/arm_pmu.c b/drivers/perf/arm_pmu.c
index da340c14f2a0..76ae119059e9 100644
--- a/drivers/perf/arm_pmu.c
+++ b/drivers/perf/arm_pmu.c
@@ -672,14 +672,9 @@ static void cpu_pm_pmu_setup(struct arm_pmu *armpmu, unsigned long cmd)
 	int idx;
 
 	for (idx = 0; idx < armpmu->num_events; idx++) {
-		/*
-		 * If the counter is not used skip it, there is no
-		 * need of stopping/restarting it.
-		 */
-		if (!test_bit(idx, hw_events->used_mask))
-			continue;
-
 		event = hw_events->events[idx];
+		if (!event)
+			continue;
 
 		switch (cmd) {
 		case CPU_PM_ENTER:
