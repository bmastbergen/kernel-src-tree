net/mlx5: Don't handle VF func change if host PF is disabled

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [netdrv] mlx5: Don't handle VF func change if host PF is disabled (Alaa Hleihel) [1724327 1724336]
Rebuild_FUZZ: 96.55%
commit-author Bodong Wang <bodong@mellanox.com>
commit 5ccf2770e83bf8739f0a7c8bed9186d7e5d2ecbc
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/5ccf2770.failed

When ECPF eswitch manager is at offloads mode, it monitors functions
changed event from host PF side and acts according to the number of
VFs enabled/disabled.

As ECPF and host PF work in two independent hosts, it's possible that
host PF OS reboots but ECPF system is still kept on and continues
monitoring events from host PF. When kernel from host PF side is
booting, PCI iov driver does sriov_init and compute_max_vf_buses by
iterating over all valid num of VFs. This triggers FLR and generates
functions changed events, even though host PF HCA is not enabled at
this time. However, ECPF is not aware of this information, and still
handles these events as usual. ECPF system will see massive number of
reps are created, but destroyed immediately once creation finished.

To eliminate this noise, a bit is added to host parameter context to
indicate host PF is disabled. ECPF will not handle the VF changed
event if this bit is set.

	Signed-off-by: Bodong Wang <bodong@mellanox.com>
	Reviewed-by: Daniel Jurgens <danielj@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 5ccf2770e83bf8739f0a7c8bed9186d7e5d2ecbc)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
index 2a02050a09e7,105c21069c0c..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@@ -1599,11 -2018,110 +1599,115 @@@ static void esw_offloads_steering_clean
  	esw_destroy_vport_rx_group(esw);
  	esw_destroy_offloads_table(esw);
  	esw_destroy_offloads_fdb_tables(esw);
 -	esw_destroy_offloads_acl_tables(esw);
 +	if (MLX5_CAP_GEN(esw->dev, prio_tag_required))
 +		esw_prio_tag_acls_cleanup(esw);
  }
  
++<<<<<<< HEAD
 +int esw_offloads_init(struct mlx5_eswitch *esw, int nvports)
++=======
+ static void esw_functions_changed_event_handler(struct work_struct *work)
+ {
+ 	u32 out[MLX5_ST_SZ_DW(query_esw_functions_out)] = {};
+ 	struct mlx5_host_work *host_work;
+ 	struct mlx5_eswitch *esw;
+ 	bool host_pf_disabled;
+ 	u16 num_vfs = 0;
+ 	int err;
+ 
+ 	host_work = container_of(work, struct mlx5_host_work, work);
+ 	esw = host_work->esw;
+ 
+ 	err = mlx5_esw_query_functions(esw->dev, out, sizeof(out));
+ 	num_vfs = MLX5_GET(query_esw_functions_out, out,
+ 			   host_params_context.host_num_of_vfs);
+ 	host_pf_disabled = MLX5_GET(query_esw_functions_out, out,
+ 				    host_params_context.host_pf_disabled);
+ 	if (err || host_pf_disabled || num_vfs == esw->esw_funcs.num_vfs)
+ 		goto out;
+ 
+ 	/* Number of VFs can only change from "0 to x" or "x to 0". */
+ 	if (esw->esw_funcs.num_vfs > 0) {
+ 		esw_offloads_unload_vf_reps(esw, esw->esw_funcs.num_vfs);
+ 	} else {
+ 		err = esw_offloads_load_vf_reps(esw, num_vfs);
+ 
+ 		if (err)
+ 			goto out;
+ 	}
+ 
+ 	esw->esw_funcs.num_vfs = num_vfs;
+ 
+ out:
+ 	kfree(host_work);
+ }
+ 
+ static void esw_emulate_event_handler(struct work_struct *work)
+ {
+ 	struct mlx5_host_work *host_work =
+ 		container_of(work, struct mlx5_host_work, work);
+ 	struct mlx5_eswitch *esw = host_work->esw;
+ 	int err;
+ 
+ 	if (esw->esw_funcs.num_vfs) {
+ 		err = esw_offloads_load_vf_reps(esw, esw->esw_funcs.num_vfs);
+ 		if (err)
+ 			esw_warn(esw->dev, "Load vf reps err=%d\n", err);
+ 	}
+ 	kfree(host_work);
+ }
+ 
+ static int esw_functions_changed_event(struct notifier_block *nb,
+ 				       unsigned long type, void *data)
+ {
+ 	struct mlx5_esw_functions *esw_funcs;
+ 	struct mlx5_host_work *host_work;
+ 	struct mlx5_eswitch *esw;
+ 
+ 	host_work = kzalloc(sizeof(*host_work), GFP_ATOMIC);
+ 	if (!host_work)
+ 		return NOTIFY_DONE;
+ 
+ 	esw_funcs = mlx5_nb_cof(nb, struct mlx5_esw_functions, nb);
+ 	esw = container_of(esw_funcs, struct mlx5_eswitch, esw_funcs);
+ 
+ 	host_work->esw = esw;
+ 
+ 	if (mlx5_eswitch_is_funcs_handler(esw->dev))
+ 		INIT_WORK(&host_work->work,
+ 			  esw_functions_changed_event_handler);
+ 	else
+ 		INIT_WORK(&host_work->work, esw_emulate_event_handler);
+ 	queue_work(esw->work_queue, &host_work->work);
+ 
+ 	return NOTIFY_OK;
+ }
+ 
+ static void esw_functions_changed_event_init(struct mlx5_eswitch *esw,
+ 					     u16 vf_nvports)
+ {
+ 	if (mlx5_eswitch_is_funcs_handler(esw->dev)) {
+ 		esw->esw_funcs.num_vfs = 0;
+ 		MLX5_NB_INIT(&esw->esw_funcs.nb, esw_functions_changed_event,
+ 			     ESW_FUNCTIONS_CHANGED);
+ 		mlx5_eq_notifier_register(esw->dev, &esw->esw_funcs.nb);
+ 	} else {
+ 		esw->esw_funcs.num_vfs = vf_nvports;
+ 	}
+ }
+ 
+ static void esw_functions_changed_event_cleanup(struct mlx5_eswitch *esw)
+ {
+ 	if (!mlx5_eswitch_is_funcs_handler(esw->dev))
+ 		return;
+ 
+ 	mlx5_eq_notifier_unregister(esw->dev, &esw->esw_funcs.nb);
+ 	flush_workqueue(esw->work_queue);
+ }
+ 
+ int esw_offloads_init(struct mlx5_eswitch *esw, int vf_nvports,
+ 		      int total_nvports)
++>>>>>>> 5ccf2770e83b (net/mlx5: Don't handle VF func change if host PF is disabled)
  {
  	int err;
  
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --git a/include/linux/mlx5/mlx5_ifc.h b/include/linux/mlx5/mlx5_ifc.h
index ecb477572bac..7debe91c7d99 100644
--- a/include/linux/mlx5/mlx5_ifc.h
+++ b/include/linux/mlx5/mlx5_ifc.h
@@ -9778,7 +9778,8 @@ struct mlx5_ifc_mtrc_ctrl_bits {
 
 struct mlx5_ifc_host_params_context_bits {
 	u8         host_number[0x8];
-	u8         reserved_at_8[0x8];
+	u8         reserved_at_8[0x7];
+	u8         host_pf_disabled[0x1];
 	u8         host_num_of_vfs[0x10];
 
 	u8         reserved_at_20[0x10];
