net: sched: modify stats helper functions to support regular stats

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [net] sched: modify stats helper functions to support regular stats (Ivan Vecera) [1739606]
Rebuild_FUZZ: 96.06%
commit-author Vlad Buslov <vladbu@mellanox.com>
commit 5e174d5e73dfbfb2c4bc4804f58f2f2aa34c9281
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/5e174d5e.failed

Modify stats update helper functions introduced in previous patches in this
series to fallback to regular tc_action->tcfa_{b|q}stats if cpu stats are
not allocated for the action argument. If regular non-percpu allocated
counters are in use, then obtain action tcfa_lock while modifying them.

	Signed-off-by: Vlad Buslov <vladbu@mellanox.com>
	Acked-by: Jiri Pirko <jiri@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 5e174d5e73dfbfb2c4bc4804f58f2f2aa34c9281)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/act_api.h
#	net/sched/act_api.c
diff --cc include/net/act_api.h
index c61a1bf4e3de,a56477051dae..000000000000
--- a/include/net/act_api.h
+++ b/include/net/act_api.h
@@@ -179,6 -186,43 +179,46 @@@ int tcf_action_dump(struct sk_buff *skb
  		    int ref);
  int tcf_action_dump_old(struct sk_buff *skb, struct tc_action *a, int, int);
  int tcf_action_dump_1(struct sk_buff *skb, struct tc_action *a, int, int);
++<<<<<<< HEAD
++=======
+ 
+ static inline void tcf_action_update_bstats(struct tc_action *a,
+ 					    struct sk_buff *skb)
+ {
+ 	if (likely(a->cpu_bstats)) {
+ 		bstats_cpu_update(this_cpu_ptr(a->cpu_bstats), skb);
+ 		return;
+ 	}
+ 	spin_lock(&a->tcfa_lock);
+ 	bstats_update(&a->tcfa_bstats, skb);
+ 	spin_unlock(&a->tcfa_lock);
+ }
+ 
+ static inline void tcf_action_inc_drop_qstats(struct tc_action *a)
+ {
+ 	if (likely(a->cpu_qstats)) {
+ 		qstats_drop_inc(this_cpu_ptr(a->cpu_qstats));
+ 		return;
+ 	}
+ 	spin_lock(&a->tcfa_lock);
+ 	qstats_drop_inc(&a->tcfa_qstats);
+ 	spin_unlock(&a->tcfa_lock);
+ }
+ 
+ static inline void tcf_action_inc_overlimit_qstats(struct tc_action *a)
+ {
+ 	if (likely(a->cpu_qstats)) {
+ 		qstats_overlimit_inc(this_cpu_ptr(a->cpu_qstats));
+ 		return;
+ 	}
+ 	spin_lock(&a->tcfa_lock);
+ 	qstats_overlimit_inc(&a->tcfa_qstats);
+ 	spin_unlock(&a->tcfa_lock);
+ }
+ 
+ void tcf_action_update_stats(struct tc_action *a, u64 bytes, u32 packets,
+ 			     bool drop, bool hw);
++>>>>>>> 5e174d5e73df (net: sched: modify stats helper functions to support regular stats)
  int tcf_action_copy_stats(struct sk_buff *, struct tc_action *, int);
  
  int tcf_action_check_ctrlact(int action, struct tcf_proto *tp,
diff --cc net/sched/act_api.c
index d35eb0b8379b,f85b88da5216..000000000000
--- a/net/sched/act_api.c
+++ b/net/sched/act_api.c
@@@ -992,6 -989,29 +992,32 @@@ err
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ void tcf_action_update_stats(struct tc_action *a, u64 bytes, u32 packets,
+ 			     bool drop, bool hw)
+ {
+ 	if (a->cpu_bstats) {
+ 		_bstats_cpu_update(this_cpu_ptr(a->cpu_bstats), bytes, packets);
+ 
+ 		if (drop)
+ 			this_cpu_ptr(a->cpu_qstats)->drops += packets;
+ 
+ 		if (hw)
+ 			_bstats_cpu_update(this_cpu_ptr(a->cpu_bstats_hw),
+ 					   bytes, packets);
+ 		return;
+ 	}
+ 
+ 	_bstats_update(&a->tcfa_bstats, bytes, packets);
+ 	if (drop)
+ 		a->tcfa_qstats.drops += packets;
+ 	if (hw)
+ 		_bstats_update(&a->tcfa_bstats_hw, bytes, packets);
+ }
+ EXPORT_SYMBOL(tcf_action_update_stats);
+ 
++>>>>>>> 5e174d5e73df (net: sched: modify stats helper functions to support regular stats)
  int tcf_action_copy_stats(struct sk_buff *skb, struct tc_action *p,
  			  int compat_mode)
  {
* Unmerged path include/net/act_api.h
* Unmerged path net/sched/act_api.c
