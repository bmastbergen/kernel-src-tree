RDMA/devices: Do not deadlock during client removal

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Jason Gunthorpe <jgg@ziepe.ca>
commit 621e55ff5b8e0ab5d1063f0eae0ef3960bef8f6e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/621e55ff.failed

lockdep reports:

   WARNING: possible circular locking dependency detected

   modprobe/302 is trying to acquire lock:
   0000000007c8919c ((wq_completion)ib_cm){+.+.}, at: flush_workqueue+0xdf/0x990

   but task is already holding lock:
   000000002d3d2ca9 (&device->client_data_rwsem){++++}, at: remove_client_context+0x79/0xd0 [ib_core]

   which lock already depends on the new lock.

   the existing dependency chain (in reverse order) is:

   -> #2 (&device->client_data_rwsem){++++}:
          down_read+0x3f/0x160
          ib_get_net_dev_by_params+0xd5/0x200 [ib_core]
          cma_ib_req_handler+0x5f6/0x2090 [rdma_cm]
          cm_process_work+0x29/0x110 [ib_cm]
          cm_req_handler+0x10f5/0x1c00 [ib_cm]
          cm_work_handler+0x54c/0x311d [ib_cm]
          process_one_work+0x4aa/0xa30
          worker_thread+0x62/0x5b0
          kthread+0x1ca/0x1f0
          ret_from_fork+0x24/0x30

   -> #1 ((work_completion)(&(&work->work)->work)){+.+.}:
          process_one_work+0x45f/0xa30
          worker_thread+0x62/0x5b0
          kthread+0x1ca/0x1f0
          ret_from_fork+0x24/0x30

   -> #0 ((wq_completion)ib_cm){+.+.}:
          lock_acquire+0xc8/0x1d0
          flush_workqueue+0x102/0x990
          cm_remove_one+0x30e/0x3c0 [ib_cm]
          remove_client_context+0x94/0xd0 [ib_core]
          disable_device+0x10a/0x1f0 [ib_core]
          __ib_unregister_device+0x5a/0xe0 [ib_core]
          ib_unregister_device+0x21/0x30 [ib_core]
          mlx5_ib_stage_ib_reg_cleanup+0x9/0x10 [mlx5_ib]
          __mlx5_ib_remove+0x3d/0x70 [mlx5_ib]
          mlx5_ib_remove+0x12e/0x140 [mlx5_ib]
          mlx5_remove_device+0x144/0x150 [mlx5_core]
          mlx5_unregister_interface+0x3f/0xf0 [mlx5_core]
          mlx5_ib_cleanup+0x10/0x3a [mlx5_ib]
          __x64_sys_delete_module+0x227/0x350
          do_syscall_64+0xc3/0x6a4
          entry_SYSCALL_64_after_hwframe+0x49/0xbe

Which is due to the read side of the client_data_rwsem being obtained
recursively through a work queue flush during cm client removal.

The lock is being held across the remove in remove_client_context() so
that the function is a fence, once it returns the client is removed. This
is required so that the two callers do not proceed with destruction until
the client completes removal.

Instead of using client_data_rwsem use the existing device unregistration
refcount and add a similar client unregistration (client->uses) refcount.

This will fence the two unregistration paths without holding any locks.

	Cc: <stable@vger.kernel.org>
Fixes: 921eab1143aa ("RDMA/devices: Re-organize device.c locking")
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
Link: https://lore.kernel.org/r/20190731081841.32345-2-leon@kernel.org
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 621e55ff5b8e0ab5d1063f0eae0ef3960bef8f6e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/device.c
diff --cc drivers/infiniband/core/device.c
index ec96a7b1c811,d86fbabe48d6..000000000000
--- a/drivers/infiniband/core/device.c
+++ b/drivers/infiniband/core/device.c
@@@ -72,21 -97,108 +72,27 @@@ static LIST_HEAD(device_list)
  static LIST_HEAD(client_list);
  #define CLIENT_REGISTERED XA_MARK_1
  static DEFINE_XARRAY_FLAGS(clients, XA_FLAGS_ALLOC);
 -static DECLARE_RWSEM(clients_rwsem);
  
+ static void ib_client_put(struct ib_client *client)
+ {
+ 	if (refcount_dec_and_test(&client->uses))
+ 		complete(&client->uses_zero);
+ }
+ 
  /*
 - * If client_data is registered then the corresponding client must also still
 - * be registered.
 - */
 -#define CLIENT_DATA_REGISTERED XA_MARK_1
 -
 -/**
 - * struct rdma_dev_net - rdma net namespace metadata for a net
 - * @net:	Pointer to owner net namespace
 - * @id:		xarray id to identify the net namespace.
 - */
 -struct rdma_dev_net {
 -	possible_net_t net;
 -	u32 id;
 -};
 -
 -static unsigned int rdma_dev_net_id;
 -
 -/*
 - * A list of net namespaces is maintained in an xarray. This is necessary
 - * because we can't get the locking right using the existing net ns list. We
 - * would require a init_net callback after the list is updated.
 - */
 -static DEFINE_XARRAY_FLAGS(rdma_nets, XA_FLAGS_ALLOC);
 -/*
 - * rwsem to protect accessing the rdma_nets xarray entries.
 - */
 -static DECLARE_RWSEM(rdma_nets_rwsem);
 -
 -bool ib_devices_shared_netns = true;
 -module_param_named(netns_mode, ib_devices_shared_netns, bool, 0444);
 -MODULE_PARM_DESC(netns_mode,
 -		 "Share device among net namespaces; default=1 (shared)");
 -/**
 - * rdma_dev_access_netns() - Return whether a rdma device can be accessed
 - *			     from a specified net namespace or not.
 - * @device:	Pointer to rdma device which needs to be checked
 - * @net:	Pointer to net namesapce for which access to be checked
 + * device_mutex and lists_rwsem protect access to both device_list and
 + * clients.  device_mutex protects writer access by device and client
 + * registration / de-registration.  lists_rwsem protects reader access to
 + * these lists.  Iterators of these lists must lock it for read, while updates
 + * to the lists must be done with a write lock. A special case is when the
 + * device_mutex is locked. In this case locking the lists for read access is
 + * not necessary as the device_mutex implies it.
   *
 - * rdma_dev_access_netns() - Return whether a rdma device can be accessed
 - *			     from a specified net namespace or not. When
 - *			     rdma device is in shared mode, it ignores the
 - *			     net namespace. When rdma device is exclusive
 - *			     to a net namespace, rdma device net namespace is
 - *			     checked against the specified one.
 - */
 -bool rdma_dev_access_netns(const struct ib_device *dev, const struct net *net)
 -{
 -	return (ib_devices_shared_netns ||
 -		net_eq(read_pnet(&dev->coredev.rdma_net), net));
 -}
 -EXPORT_SYMBOL(rdma_dev_access_netns);
 -
 -/*
 - * xarray has this behavior where it won't iterate over NULL values stored in
 - * allocated arrays.  So we need our own iterator to see all values stored in
 - * the array. This does the same thing as xa_for_each except that it also
 - * returns NULL valued entries if the array is allocating. Simplified to only
 - * work on simple xarrays.
 + * lists_rwsem also protects access to the client data list.
   */
 -static void *xan_find_marked(struct xarray *xa, unsigned long *indexp,
 -			     xa_mark_t filter)
 -{
 -	XA_STATE(xas, xa, *indexp);
 -	void *entry;
 -
 -	rcu_read_lock();
 -	do {
 -		entry = xas_find_marked(&xas, ULONG_MAX, filter);
 -		if (xa_is_zero(entry))
 -			break;
 -	} while (xas_retry(&xas, entry));
 -	rcu_read_unlock();
 +static DEFINE_MUTEX(device_mutex);
 +static DECLARE_RWSEM(lists_rwsem);
  
 -	if (entry) {
 -		*indexp = xas.xa_index;
 -		if (xa_is_zero(entry))
 -			return NULL;
 -		return entry;
 -	}
 -	return XA_ERROR(-ENOENT);
 -}
 -#define xan_for_each_marked(xa, index, entry, filter)                          \
 -	for (index = 0, entry = xan_find_marked(xa, &(index), filter);         \
 -	     !xa_is_err(entry);                                                \
 -	     (index)++, entry = xan_find_marked(xa, &(index), filter))
 -
 -/* RCU hash table mapping netdevice pointers to struct ib_port_data */
 -static DEFINE_SPINLOCK(ndev_hash_lock);
 -static DECLARE_HASHTABLE(ndev_hash, 5);
 -
 -static void free_netdevs(struct ib_device *ib_dev);
 -static void ib_unregister_work(struct work_struct *work);
 -static void __ib_unregister_device(struct ib_device *device);
  static int ib_security_change(struct notifier_block *nb, unsigned long event,
  			      void *lsm_data);
  static void ib_policy_change_task(struct work_struct *work);
@@@ -338,27 -649,135 +344,126 @@@ void ib_dealloc_device(struct ib_devic
  }
  EXPORT_SYMBOL(ib_dealloc_device);
  
 -/*
 - * add_client_context() and remove_client_context() must be safe against
 - * parallel calls on the same device - registration/unregistration of both the
 - * device and client can be occurring in parallel.
 - *
 - * The routines need to be a fence, any caller must not return until the add
 - * or remove is fully completed.
 - */
 -static int add_client_context(struct ib_device *device,
 -			      struct ib_client *client)
 +static int add_client_context(struct ib_device *device, struct ib_client *client)
  {
 -	int ret = 0;
 +	struct ib_client_data *context;
  
  	if (!device->kverbs_provider && !client->no_kverbs_req)
 -		return 0;
 +		return -EOPNOTSUPP;
  
++<<<<<<< HEAD
 +	context = kmalloc(sizeof(*context), GFP_KERNEL);
 +	if (!context)
++=======
+ 	down_write(&device->client_data_rwsem);
+ 	/*
+ 	 * So long as the client is registered hold both the client and device
+ 	 * unregistration locks.
+ 	 */
+ 	if (!refcount_inc_not_zero(&client->uses))
+ 		goto out_unlock;
+ 	refcount_inc(&device->refcount);
+ 
+ 	/*
+ 	 * Another caller to add_client_context got here first and has already
+ 	 * completely initialized context.
+ 	 */
+ 	if (xa_get_mark(&device->client_data, client->client_id,
+ 		    CLIENT_DATA_REGISTERED))
+ 		goto out;
+ 
+ 	ret = xa_err(xa_store(&device->client_data, client->client_id, NULL,
+ 			      GFP_KERNEL));
+ 	if (ret)
+ 		goto out;
+ 	downgrade_write(&device->client_data_rwsem);
+ 	if (client->add)
+ 		client->add(device);
+ 
+ 	/* Readers shall not see a client until add has been completed */
+ 	xa_set_mark(&device->client_data, client->client_id,
+ 		    CLIENT_DATA_REGISTERED);
+ 	up_read(&device->client_data_rwsem);
+ 	return 0;
+ 
+ out:
+ 	ib_device_put(device);
+ 	ib_client_put(client);
+ out_unlock:
+ 	up_write(&device->client_data_rwsem);
+ 	return ret;
+ }
+ 
+ static void remove_client_context(struct ib_device *device,
+ 				  unsigned int client_id)
+ {
+ 	struct ib_client *client;
+ 	void *client_data;
+ 
+ 	down_write(&device->client_data_rwsem);
+ 	if (!xa_get_mark(&device->client_data, client_id,
+ 			 CLIENT_DATA_REGISTERED)) {
+ 		up_write(&device->client_data_rwsem);
+ 		return;
+ 	}
+ 	client_data = xa_load(&device->client_data, client_id);
+ 	xa_clear_mark(&device->client_data, client_id, CLIENT_DATA_REGISTERED);
+ 	client = xa_load(&clients, client_id);
+ 	up_write(&device->client_data_rwsem);
+ 
+ 	/*
+ 	 * Notice we cannot be holding any exclusive locks when calling the
+ 	 * remove callback as the remove callback can recurse back into any
+ 	 * public functions in this module and thus try for any locks those
+ 	 * functions take.
+ 	 *
+ 	 * For this reason clients and drivers should not call the
+ 	 * unregistration functions will holdling any locks.
+ 	 */
+ 	if (client->remove)
+ 		client->remove(device, client_data);
+ 
+ 	xa_erase(&device->client_data, client_id);
+ 	ib_device_put(device);
+ 	ib_client_put(client);
+ }
+ 
+ static int alloc_port_data(struct ib_device *device)
+ {
+ 	struct ib_port_data_rcu *pdata_rcu;
+ 	unsigned int port;
+ 
+ 	if (device->port_data)
+ 		return 0;
+ 
+ 	/* This can only be called once the physical port range is defined */
+ 	if (WARN_ON(!device->phys_port_cnt))
+ 		return -EINVAL;
+ 
+ 	/*
+ 	 * device->port_data is indexed directly by the port number to make
+ 	 * access to this data as efficient as possible.
+ 	 *
+ 	 * Therefore port_data is declared as a 1 based array with potential
+ 	 * empty slots at the beginning.
+ 	 */
+ 	pdata_rcu = kzalloc(struct_size(pdata_rcu, pdata,
+ 					rdma_end_port(device) + 1),
+ 			    GFP_KERNEL);
+ 	if (!pdata_rcu)
++>>>>>>> 621e55ff5b8e (RDMA/devices: Do not deadlock during client removal)
  		return -ENOMEM;
 -	/*
 -	 * The rcu_head is put in front of the port data array and the stored
 -	 * pointer is adjusted since we never need to see that member until
 -	 * kfree_rcu.
 -	 */
 -	device->port_data = pdata_rcu->pdata;
  
 -	rdma_for_each_port (device, port) {
 -		struct ib_port_data *pdata = &device->port_data[port];
 +	context->client = client;
 +	context->data   = NULL;
 +	context->going_down = false;
 +
 +	down_write(&lists_rwsem);
 +	write_lock_irq(&device->client_data_lock);
 +	list_add(&context->list, &device->client_data_list);
 +	write_unlock_irq(&device->client_data_lock);
 +	up_write(&lists_rwsem);
  
 -		pdata->ib_dev = device;
 -		spin_lock_init(&pdata->pkey_list_lock);
 -		INIT_LIST_HEAD(&pdata->pkey_list);
 -		spin_lock_init(&pdata->netdev_lock);
 -		INIT_HLIST_NODE(&pdata->ndev_hash_link);
 -	}
  	return 0;
  }
  
@@@ -742,25 -1715,25 +847,30 @@@ out
  int ib_register_client(struct ib_client *client)
  {
  	struct ib_device *device;
 -	unsigned long index;
  	int ret;
  
++<<<<<<< HEAD
 +	mutex_lock(&device_mutex);
++=======
+ 	refcount_set(&client->uses, 1);
+ 	init_completion(&client->uses_zero);
++>>>>>>> 621e55ff5b8e (RDMA/devices: Do not deadlock during client removal)
  	ret = assign_client_id(client);
 -	if (ret)
 +	if (ret) {
 +		mutex_unlock(&device_mutex);
  		return ret;
 -
 -	down_read(&devices_rwsem);
 -	xa_for_each_marked (&devices, index, device, DEVICE_REGISTERED) {
 -		ret = add_client_context(device, client);
 -		if (ret) {
 -			up_read(&devices_rwsem);
 -			ib_unregister_client(client);
 -			return ret;
 -		}
  	}
 -	up_read(&devices_rwsem);
 +
 +	list_for_each_entry(device, &device_list, core_list)
 +		if (!add_client_context(device, client) && client->add)
 +			client->add(device);
 +
 +	down_write(&lists_rwsem);
 +	xa_set_mark(&clients, client->client_id, CLIENT_REGISTERED);
 +	up_write(&lists_rwsem);
 +
 +	mutex_unlock(&device_mutex);
 +
  	return 0;
  }
  EXPORT_SYMBOL(ib_register_client);
@@@ -775,81 -1748,141 +885,108 @@@
   */
  void ib_unregister_client(struct ib_client *client)
  {
 +	struct ib_client_data *context;
  	struct ib_device *device;
 -	unsigned long index;
  
++<<<<<<< HEAD
 +	mutex_lock(&device_mutex);
 +
 +	down_write(&lists_rwsem);
 +	xa_clear_mark(&clients, client->client_id, CLIENT_REGISTERED);
 +	up_write(&lists_rwsem);
++=======
+ 	down_write(&clients_rwsem);
+ 	ib_client_put(client);
+ 	xa_clear_mark(&clients, client->client_id, CLIENT_REGISTERED);
+ 	up_write(&clients_rwsem);
+ 
+ 	/* We do not want to have locks while calling client->remove() */
+ 	rcu_read_lock();
+ 	xa_for_each (&devices, index, device) {
+ 		if (!ib_device_try_get(device))
+ 			continue;
+ 		rcu_read_unlock();
+ 
+ 		remove_client_context(device, client->client_id);
+ 
+ 		ib_device_put(device);
+ 		rcu_read_lock();
+ 	}
+ 	rcu_read_unlock();
+ 
+ 	/*
+ 	 * remove_client_context() is not a fence, it can return even though a
+ 	 * removal is ongoing. Wait until all removals are completed.
+ 	 */
+ 	wait_for_completion(&client->uses_zero);
++>>>>>>> 621e55ff5b8e (RDMA/devices: Do not deadlock during client removal)
  
 -	down_write(&clients_rwsem);
 -	list_del(&client->list);
 -	xa_erase(&clients, client->client_id);
 -	up_write(&clients_rwsem);
 -}
 -EXPORT_SYMBOL(ib_unregister_client);
 -
 -static int __ib_get_global_client_nl_info(const char *client_name,
 -					  struct ib_client_nl_info *res)
 -{
 -	struct ib_client *client;
 -	unsigned long index;
 -	int ret = -ENOENT;
 -
 -	down_read(&clients_rwsem);
 -	xa_for_each_marked (&clients, index, client, CLIENT_REGISTERED) {
 -		if (strcmp(client->name, client_name) != 0)
 -			continue;
 -		if (!client->get_global_nl_info) {
 -			ret = -EOPNOTSUPP;
 -			break;
 -		}
 -		ret = client->get_global_nl_info(res);
 -		if (WARN_ON(ret == -ENOENT))
 -			ret = -EINVAL;
 -		if (!ret && res->cdev)
 -			get_device(res->cdev);
 -		break;
 -	}
 -	up_read(&clients_rwsem);
 -	return ret;
 -}
 +	list_for_each_entry(device, &device_list, core_list) {
 +		struct ib_client_data *found_context = NULL;
  
 -static int __ib_get_client_nl_info(struct ib_device *ibdev,
 -				   const char *client_name,
 -				   struct ib_client_nl_info *res)
 -{
 -	unsigned long index;
 -	void *client_data;
 -	int ret = -ENOENT;
 +		down_write(&lists_rwsem);
 +		write_lock_irq(&device->client_data_lock);
 +		list_for_each_entry(context, &device->client_data_list, list)
 +			if (context->client == client) {
 +				context->going_down = true;
 +				found_context = context;
 +				break;
 +			}
 +		write_unlock_irq(&device->client_data_lock);
 +		up_write(&lists_rwsem);
  
 -	down_read(&ibdev->client_data_rwsem);
 -	xan_for_each_marked (&ibdev->client_data, index, client_data,
 -			     CLIENT_DATA_REGISTERED) {
 -		struct ib_client *client = xa_load(&clients, index);
 +		if (client->remove)
 +			client->remove(device, found_context ?
 +					       found_context->data : NULL);
  
 -		if (!client || strcmp(client->name, client_name) != 0)
 +		if (!found_context) {
 +			dev_warn(&device->dev,
 +				 "No client context found for %s\n",
 +				 client->name);
  			continue;
 -		if (!client->get_nl_info) {
 -			ret = -EOPNOTSUPP;
 -			break;
  		}
 -		ret = client->get_nl_info(ibdev, client_data, res);
 -		if (WARN_ON(ret == -ENOENT))
 -			ret = -EINVAL;
  
 -		/*
 -		 * The cdev is guaranteed valid as long as we are inside the
 -		 * client_data_rwsem as remove_one can't be called. Keep it
 -		 * valid for the caller.
 -		 */
 -		if (!ret && res->cdev)
 -			get_device(res->cdev);
 -		break;
 +		down_write(&lists_rwsem);
 +		write_lock_irq(&device->client_data_lock);
 +		list_del(&found_context->list);
 +		write_unlock_irq(&device->client_data_lock);
 +		up_write(&lists_rwsem);
 +		kfree(found_context);
  	}
 -	up_read(&ibdev->client_data_rwsem);
  
 -	return ret;
 +	down_write(&lists_rwsem);
 +	list_del(&client->list);
 +	xa_erase(&clients, client->client_id);
 +	up_write(&lists_rwsem);
 +	mutex_unlock(&device_mutex);
  }
 +EXPORT_SYMBOL(ib_unregister_client);
  
  /**
 - * ib_get_client_nl_info - Fetch the nl_info from a client
 - * @device - IB device
 - * @client_name - Name of the client
 - * @res - Result of the query
 + * ib_get_client_data - Get IB client context
 + * @device:Device to get context for
 + * @client:Client to get context for
 + *
 + * ib_get_client_data() returns client context set with
 + * ib_set_client_data().
   */
 -int ib_get_client_nl_info(struct ib_device *ibdev, const char *client_name,
 -			  struct ib_client_nl_info *res)
 +void *ib_get_client_data(struct ib_device *device, struct ib_client *client)
  {
 -	int ret;
 +	struct ib_client_data *context;
 +	void *ret = NULL;
 +	unsigned long flags;
  
 -	if (ibdev)
 -		ret = __ib_get_client_nl_info(ibdev, client_name, res);
 -	else
 -		ret = __ib_get_global_client_nl_info(client_name, res);
 -#ifdef CONFIG_MODULES
 -	if (ret == -ENOENT) {
 -		request_module("rdma-client-%s", client_name);
 -		if (ibdev)
 -			ret = __ib_get_client_nl_info(ibdev, client_name, res);
 -		else
 -			ret = __ib_get_global_client_nl_info(client_name, res);
 -	}
 -#endif
 -	if (ret) {
 -		if (ret == -ENOENT)
 -			return -EOPNOTSUPP;
 -		return ret;
 -	}
 +	read_lock_irqsave(&device->client_data_lock, flags);
 +	list_for_each_entry(context, &device->client_data_list, list)
 +		if (context->client == client) {
 +			ret = context->data;
 +			break;
 +		}
 +	read_unlock_irqrestore(&device->client_data_lock, flags);
  
 -	if (WARN_ON(!res->cdev))
 -		return -EINVAL;
 -	return 0;
 +	return ret;
  }
 +EXPORT_SYMBOL(ib_get_client_data);
  
  /**
   * ib_set_client_data - Set IB client context
* Unmerged path drivers/infiniband/core/device.c
diff --git a/include/rdma/ib_verbs.h b/include/rdma/ib_verbs.h
index 9a1c4c9437dd..ae424c3c27f7 100644
--- a/include/rdma/ib_verbs.h
+++ b/include/rdma/ib_verbs.h
@@ -2529,6 +2529,9 @@ struct ib_client {
 			const union ib_gid *gid,
 			const struct sockaddr *addr,
 			void *client_data);
+
+	refcount_t uses;
+	struct completion uses_zero;
 	struct list_head list;
 	u32 client_id;
 
