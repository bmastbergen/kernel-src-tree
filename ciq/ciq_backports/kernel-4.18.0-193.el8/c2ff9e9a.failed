x86/fpu: Merge the two code paths in __fpu__restore_sig()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Sebastian Andrzej Siewior <bigeasy@linutronix.de>
commit c2ff9e9a3d9d6c019394a22989a228d02970a8b1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/c2ff9e9a.failed

The ia32_fxstate case (32bit with fxsr) and the other (64bit frames or
32bit frames without fxsr) restore both from kernel memory and sanitize
the content.

The !ia32_fxstate version restores missing xstates from "init state"
while the ia32_fxstate doesn't and skips it.

Merge the two code paths and keep the !ia32_fxstate one. Copy only the
user_i387_ia32_struct data structure in the ia32_fxstate.

	Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Reviewed-by: Dave Hansen <dave.hansen@intel.com>
	Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: Jann Horn <jannh@google.com>
	Cc: "Jason A. Donenfeld" <Jason@zx2c4.com>
	Cc: kvm ML <kvm@vger.kernel.org>
	Cc: Paolo Bonzini <pbonzini@redhat.com>
	Cc: Radim Krčmář <rkrcmar@redhat.com>
	Cc: Rik van Riel <riel@surriel.com>
	Cc: x86-ml <x86@kernel.org>
Link: https://lkml.kernel.org/r/20190403164156.19645-23-bigeasy@linutronix.de
(cherry picked from commit c2ff9e9a3d9d6c019394a22989a228d02970a8b1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/fpu/signal.c
diff --cc arch/x86/kernel/fpu/signal.c
index ef1568522109,b13e86b29426..000000000000
--- a/arch/x86/kernel/fpu/signal.c
+++ b/arch/x86/kernel/fpu/signal.c
@@@ -304,78 -308,69 +309,140 @@@ static int __fpu__restore_sig(void __us
  		}
  	}
  
+ 	tmp = kzalloc(sizeof(*state) + fpu_kernel_xstate_size + 64, GFP_KERNEL);
+ 	if (!tmp)
+ 		return -ENOMEM;
+ 	state = PTR_ALIGN(tmp, 64);
+ 
+ 	if ((unsigned long)buf_fx % 64)
+ 		fx_only = 1;
+ 
+ 	/*
+ 	 * For 32-bit frames with fxstate, copy the fxstate so it can be
+ 	 * reconstructed later.
+ 	 */
  	if (ia32_fxstate) {
++<<<<<<< HEAD
 +		/*
 +		 * For 32-bit frames with fxstate, copy the user state to the
 +		 * thread's fpu state, reconstruct fxstate from the fsave
 +		 * header. Validate and sanitize the copied state.
 +		 */
 +		struct user_i387_ia32_struct env;
 +		int err = 0;
 +
 +		/*
 +		 * Drop the current fpu which clears fpu->initialized. This ensures
 +		 * that any context-switch during the copy of the new state,
 +		 * avoids the intermediate state from getting restored/saved.
 +		 * Thus avoiding the new restored state from getting corrupted.
 +		 * We will be ready to restore/save the state only after
 +		 * fpu->initialized is again set.
 +		 */
 +		fpu__drop(fpu);
 +
 +		if (using_compacted_format()) {
 +			err = copy_user_to_xstate(&fpu->state.xsave, buf_fx);
 +		} else {
 +			err = __copy_from_user(&fpu->state.xsave, buf_fx, state_size);
 +
 +			if (!err && state_size > offsetof(struct xregs_state, header))
 +				err = validate_xstate_header(&fpu->state.xsave.header);
 +		}
 +
 +		if (err || __copy_from_user(&env, buf, sizeof(env))) {
 +			fpstate_init(&fpu->state);
 +			trace_x86_fpu_init_state(fpu);
 +			err = -1;
 +		} else {
 +			sanitize_restored_xstate(tsk, &env, xfeatures, fx_only);
 +		}
 +
 +		fpu->initialized = 1;
 +		preempt_disable();
 +		fpu__restore(fpu);
 +		preempt_enable();
 +
 +		return err;
 +	} else {
 +		int ret;
 +
 +		/*
 +		 * For 64-bit frames and 32-bit fsave frames, restore the user
 +		 * state to the registers directly (with exceptions handled).
 +		 */
 +		if (use_xsave()) {
 +			if ((unsigned long)buf_fx % 64 || fx_only) {
 +				u64 init_bv = xfeatures_mask & ~XFEATURE_MASK_FPSSE;
 +				copy_kernel_to_xregs(&init_fpstate.xsave, init_bv);
 +				ret = copy_user_to_fxregs(buf_fx);
 +			} else {
 +				u64 init_bv = xfeatures_mask & ~xfeatures;
 +				if (unlikely(init_bv))
 +					copy_kernel_to_xregs(&init_fpstate.xsave, init_bv);
 +				ret = copy_user_to_xregs(buf_fx, xfeatures);
 +			}
 +		} else if (use_fxsr()) {
 +			ret = copy_user_to_fxregs(buf_fx);
 +		} else
 +			ret = copy_user_to_fregs(buf_fx);
 +
 +		if (ret) {
 +			fpu__clear(fpu);
 +			return -1;
 +		}
++=======
+ 		ret = __copy_from_user(&env, buf, sizeof(env));
+ 		if (ret)
+ 			goto err_out;
+ 		envp = &env;
++>>>>>>> c2ff9e9a3d9d (x86/fpu: Merge the two code paths in __fpu__restore_sig())
  	}
  
- 	return 0;
+ 	if (use_xsave() && !fx_only) {
+ 		u64 init_bv = xfeatures_mask & ~xfeatures;
+ 
+ 		if (using_compacted_format()) {
+ 			ret = copy_user_to_xstate(&state->xsave, buf_fx);
+ 		} else {
+ 			ret = __copy_from_user(&state->xsave, buf_fx, state_size);
+ 
+ 			if (!ret && state_size > offsetof(struct xregs_state, header))
+ 				ret = validate_xstate_header(&state->xsave.header);
+ 		}
+ 		if (ret)
+ 			goto err_out;
+ 
+ 		sanitize_restored_xstate(state, envp, xfeatures, fx_only);
+ 
+ 		if (unlikely(init_bv))
+ 			copy_kernel_to_xregs(&init_fpstate.xsave, init_bv);
+ 		ret = copy_kernel_to_xregs_err(&state->xsave, xfeatures);
+ 
+ 	} else if (use_fxsr()) {
+ 		ret = __copy_from_user(&state->fxsave, buf_fx, state_size);
+ 		if (ret)
+ 			goto err_out;
+ 
+ 		sanitize_restored_xstate(state, envp, xfeatures, fx_only);
+ 		if (use_xsave()) {
+ 			u64 init_bv = xfeatures_mask & ~XFEATURE_MASK_FPSSE;
+ 			copy_kernel_to_xregs(&init_fpstate.xsave, init_bv);
+ 		}
+ 
+ 		ret = copy_kernel_to_fxregs_err(&state->fxsave);
+ 	} else {
+ 		ret = __copy_from_user(&state->fsave, buf_fx, state_size);
+ 		if (ret)
+ 			goto err_out;
+ 		ret = copy_kernel_to_fregs_err(&state->fsave);
+ 	}
+ 
+ err_out:
+ 	kfree(tmp);
+ 	if (ret)
+ 		fpu__clear(fpu);
+ 	return ret;
  }
  
  static inline int xstate_sigframe_size(void)
* Unmerged path arch/x86/kernel/fpu/signal.c
