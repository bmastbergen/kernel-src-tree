arm64: cpu: Move errata and feature enable callbacks closer to callers

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Will Deacon <will.deacon@arm.com>
commit b8925ee2e12d1cb9a11d6f28b5814f2bfa59dce1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/b8925ee2.failed

The cpu errata and feature enable callbacks are only called via their
respective arm64_cpu_capabilities structure and therefore shouldn't
exist in the global namespace.

Move the PAN, RAS and cache maintenance emulation enable callbacks into
the same files as their corresponding arm64_cpu_capabilities structures,
making them static in the process.

	Signed-off-by: Will Deacon <will.deacon@arm.com>
	Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
(cherry picked from commit b8925ee2e12d1cb9a11d6f28b5814f2bfa59dce1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/kernel/cpufeature.c
#	arch/arm64/kernel/traps.c
#	arch/arm64/mm/fault.c
diff --cc arch/arm64/kernel/cpufeature.c
index 3630d32ce316,35796ca1db50..000000000000
--- a/arch/arm64/kernel/cpufeature.c
+++ b/arch/arm64/kernel/cpufeature.c
@@@ -1924,21 -1846,3 +1946,24 @@@ static int __init enable_mrs_emulation(
  }
  
  core_initcall(enable_mrs_emulation);
++<<<<<<< HEAD
 +
 +void cpu_clear_disr(const struct arm64_cpu_capabilities *__unused)
 +{
 +	/* Firmware may have left a deferred SError in this register. */
 +	write_sysreg_s(0, SYS_DISR_EL1);
 +}
 +
 +ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr,
 +			  char *buf)
 +{
 +	if (__meltdown_safe)
 +		return sprintf(buf, "Not affected\n");
 +
 +	if (arm64_kernel_unmapped_at_el0())
 +		return sprintf(buf, "Mitigation: PTI\n");
 +
 +	return sprintf(buf, "Vulnerable\n");
 +}
++=======
++>>>>>>> b8925ee2e12d (arm64: cpu: Move errata and feature enable callbacks closer to callers)
diff --cc arch/arm64/kernel/traps.c
index f935d727537a,148de417ed3e..000000000000
--- a/arch/arm64/kernel/traps.c
+++ b/arch/arm64/kernel/traps.c
@@@ -414,13 -409,9 +414,16 @@@ asmlinkage void __exception do_undefins
  		return;
  
  	force_signal_inject(SIGILL, ILL_ILLOPC, regs->pc);
 -	BUG_ON(!user_mode(regs));
  }
  
++<<<<<<< HEAD
 +void cpu_enable_cache_maint_trap(const struct arm64_cpu_capabilities *__unused)
 +{
 +	config_sctlr_el1(SCTLR_EL1_UCI, 0);
 +}
 +
++=======
++>>>>>>> b8925ee2e12d (arm64: cpu: Move errata and feature enable callbacks closer to callers)
  #define __user_cache_maint(insn, address, res)			\
  	if (address >= user_addr_max()) {			\
  		res = -EFAULT;					\
diff --cc arch/arm64/mm/fault.c
index a9bb4186964e,6342f1793c70..000000000000
--- a/arch/arm64/mm/fault.c
+++ b/arch/arm64/mm/fault.c
@@@ -841,17 -864,3 +841,20 @@@ asmlinkage int __exception do_debug_exc
  	return rv;
  }
  NOKPROBE_SYMBOL(do_debug_exception);
++<<<<<<< HEAD
 +
 +#ifdef CONFIG_ARM64_PAN
 +void cpu_enable_pan(const struct arm64_cpu_capabilities *__unused)
 +{
 +	/*
 +	 * We modify PSTATE. This won't work from irq context as the PSTATE
 +	 * is discarded once we return from the exception.
 +	 */
 +	WARN_ON_ONCE(in_interrupt());
 +
 +	config_sctlr_el1(SCTLR_EL1_SPAN, 0);
 +	asm(SET_PSTATE_PAN(1));
 +}
 +#endif /* CONFIG_ARM64_PAN */
++=======
++>>>>>>> b8925ee2e12d (arm64: cpu: Move errata and feature enable callbacks closer to callers)
diff --git a/arch/arm64/include/asm/processor.h b/arch/arm64/include/asm/processor.h
index 80d0ee02d1f0..e593806b9b91 100644
--- a/arch/arm64/include/asm/processor.h
+++ b/arch/arm64/include/asm/processor.h
@@ -272,10 +272,6 @@ static inline void spin_lock_prefetch(const void *ptr)
 
 #endif
 
-void cpu_enable_pan(const struct arm64_cpu_capabilities *__unused);
-void cpu_enable_cache_maint_trap(const struct arm64_cpu_capabilities *__unused);
-void cpu_clear_disr(const struct arm64_cpu_capabilities *__unused);
-
 extern unsigned long __ro_after_init signal_minsigstksz; /* sigframe size */
 extern void __init minsigstksz_setup(void);
 
diff --git a/arch/arm64/kernel/cpu_errata.c b/arch/arm64/kernel/cpu_errata.c
index 444a1c45e81d..cb96e186d0c3 100644
--- a/arch/arm64/kernel/cpu_errata.c
+++ b/arch/arm64/kernel/cpu_errata.c
@@ -502,6 +502,12 @@ static const struct midr_range arm64_ssb_cpus[] = {
 	{},
 };
 
+static void __maybe_unused
+cpu_enable_cache_maint_trap(const struct arm64_cpu_capabilities *__unused)
+{
+	sysreg_clear_set(sctlr_el1, SCTLR_EL1_UCI, 0);
+}
+
 #define CAP_MIDR_RANGE(model, v_min, r_min, v_max, r_max)	\
 	.matches = is_affected_midr_range,			\
 	.midr_range = MIDR_RANGE(model, v_min, r_min, v_max, r_max)
* Unmerged path arch/arm64/kernel/cpufeature.c
* Unmerged path arch/arm64/kernel/traps.c
* Unmerged path arch/arm64/mm/fault.c
