RDMA/nldev: Allow counter manual mode configration through RDMA netlink

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Mark Zhang <markz@mellanox.com>
commit b389327df90530d47931d0f5616b5cd6abb96c96
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/b389327d.failed

Provide an option to allow users to manually bind a qp with a counter
through RDMA netlink. Limit it to users with ADMIN capability only.

	Signed-off-by: Mark Zhang <markz@mellanox.com>
	Reviewed-by: Majd Dibbiny <majd@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit b389327df90530d47931d0f5616b5cd6abb96c96)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/nldev.c
#	include/rdma/rdma_counter.h
#	include/uapi/rdma/rdma_netlink.h
diff --cc drivers/infiniband/core/nldev.c
index efccd8e0fb77,3d750eca53d5..000000000000
--- a/drivers/infiniband/core/nldev.c
+++ b/drivers/infiniband/core/nldev.c
@@@ -1089,6 -1399,453 +1089,456 @@@ RES_GET_FUNCS(cm_id, RDMA_RESTRACK_CM_I
  RES_GET_FUNCS(cq, RDMA_RESTRACK_CQ);
  RES_GET_FUNCS(pd, RDMA_RESTRACK_PD);
  RES_GET_FUNCS(mr, RDMA_RESTRACK_MR);
++<<<<<<< HEAD
++=======
+ RES_GET_FUNCS(counter, RDMA_RESTRACK_COUNTER);
+ 
+ static LIST_HEAD(link_ops);
+ static DECLARE_RWSEM(link_ops_rwsem);
+ 
+ static const struct rdma_link_ops *link_ops_get(const char *type)
+ {
+ 	const struct rdma_link_ops *ops;
+ 
+ 	list_for_each_entry(ops, &link_ops, list) {
+ 		if (!strcmp(ops->type, type))
+ 			goto out;
+ 	}
+ 	ops = NULL;
+ out:
+ 	return ops;
+ }
+ 
+ void rdma_link_register(struct rdma_link_ops *ops)
+ {
+ 	down_write(&link_ops_rwsem);
+ 	if (WARN_ON_ONCE(link_ops_get(ops->type)))
+ 		goto out;
+ 	list_add(&ops->list, &link_ops);
+ out:
+ 	up_write(&link_ops_rwsem);
+ }
+ EXPORT_SYMBOL(rdma_link_register);
+ 
+ void rdma_link_unregister(struct rdma_link_ops *ops)
+ {
+ 	down_write(&link_ops_rwsem);
+ 	list_del(&ops->list);
+ 	up_write(&link_ops_rwsem);
+ }
+ EXPORT_SYMBOL(rdma_link_unregister);
+ 
+ static int nldev_newlink(struct sk_buff *skb, struct nlmsghdr *nlh,
+ 			  struct netlink_ext_ack *extack)
+ {
+ 	struct nlattr *tb[RDMA_NLDEV_ATTR_MAX];
+ 	char ibdev_name[IB_DEVICE_NAME_MAX];
+ 	const struct rdma_link_ops *ops;
+ 	char ndev_name[IFNAMSIZ];
+ 	struct net_device *ndev;
+ 	char type[IFNAMSIZ];
+ 	int err;
+ 
+ 	err = nlmsg_parse_deprecated(nlh, 0, tb, RDMA_NLDEV_ATTR_MAX - 1,
+ 				     nldev_policy, extack);
+ 	if (err || !tb[RDMA_NLDEV_ATTR_DEV_NAME] ||
+ 	    !tb[RDMA_NLDEV_ATTR_LINK_TYPE] || !tb[RDMA_NLDEV_ATTR_NDEV_NAME])
+ 		return -EINVAL;
+ 
+ 	nla_strlcpy(ibdev_name, tb[RDMA_NLDEV_ATTR_DEV_NAME],
+ 		    sizeof(ibdev_name));
+ 	if (strchr(ibdev_name, '%'))
+ 		return -EINVAL;
+ 
+ 	nla_strlcpy(type, tb[RDMA_NLDEV_ATTR_LINK_TYPE], sizeof(type));
+ 	nla_strlcpy(ndev_name, tb[RDMA_NLDEV_ATTR_NDEV_NAME],
+ 		    sizeof(ndev_name));
+ 
+ 	ndev = dev_get_by_name(&init_net, ndev_name);
+ 	if (!ndev)
+ 		return -ENODEV;
+ 
+ 	down_read(&link_ops_rwsem);
+ 	ops = link_ops_get(type);
+ #ifdef CONFIG_MODULES
+ 	if (!ops) {
+ 		up_read(&link_ops_rwsem);
+ 		request_module("rdma-link-%s", type);
+ 		down_read(&link_ops_rwsem);
+ 		ops = link_ops_get(type);
+ 	}
+ #endif
+ 	err = ops ? ops->newlink(ibdev_name, ndev) : -EINVAL;
+ 	up_read(&link_ops_rwsem);
+ 	dev_put(ndev);
+ 
+ 	return err;
+ }
+ 
+ static int nldev_dellink(struct sk_buff *skb, struct nlmsghdr *nlh,
+ 			  struct netlink_ext_ack *extack)
+ {
+ 	struct nlattr *tb[RDMA_NLDEV_ATTR_MAX];
+ 	struct ib_device *device;
+ 	u32 index;
+ 	int err;
+ 
+ 	err = nlmsg_parse_deprecated(nlh, 0, tb, RDMA_NLDEV_ATTR_MAX - 1,
+ 				     nldev_policy, extack);
+ 	if (err || !tb[RDMA_NLDEV_ATTR_DEV_INDEX])
+ 		return -EINVAL;
+ 
+ 	index = nla_get_u32(tb[RDMA_NLDEV_ATTR_DEV_INDEX]);
+ 	device = ib_device_get_by_index(sock_net(skb->sk), index);
+ 	if (!device)
+ 		return -EINVAL;
+ 
+ 	if (!(device->attrs.device_cap_flags & IB_DEVICE_ALLOW_USER_UNREG)) {
+ 		ib_device_put(device);
+ 		return -EINVAL;
+ 	}
+ 
+ 	ib_unregister_device_and_put(device);
+ 	return 0;
+ }
+ 
+ static int nldev_get_chardev(struct sk_buff *skb, struct nlmsghdr *nlh,
+ 			     struct netlink_ext_ack *extack)
+ {
+ 	struct nlattr *tb[RDMA_NLDEV_ATTR_MAX];
+ 	char client_name[RDMA_NLDEV_ATTR_CHARDEV_TYPE_SIZE];
+ 	struct ib_client_nl_info data = {};
+ 	struct ib_device *ibdev = NULL;
+ 	struct sk_buff *msg;
+ 	u32 index;
+ 	int err;
+ 
+ 	err = nlmsg_parse(nlh, 0, tb, RDMA_NLDEV_ATTR_MAX - 1, nldev_policy,
+ 			  extack);
+ 	if (err || !tb[RDMA_NLDEV_ATTR_CHARDEV_TYPE])
+ 		return -EINVAL;
+ 
+ 	nla_strlcpy(client_name, tb[RDMA_NLDEV_ATTR_CHARDEV_TYPE],
+ 		    sizeof(client_name));
+ 
+ 	if (tb[RDMA_NLDEV_ATTR_DEV_INDEX]) {
+ 		index = nla_get_u32(tb[RDMA_NLDEV_ATTR_DEV_INDEX]);
+ 		ibdev = ib_device_get_by_index(sock_net(skb->sk), index);
+ 		if (!ibdev)
+ 			return -EINVAL;
+ 
+ 		if (tb[RDMA_NLDEV_ATTR_PORT_INDEX]) {
+ 			data.port = nla_get_u32(tb[RDMA_NLDEV_ATTR_PORT_INDEX]);
+ 			if (!rdma_is_port_valid(ibdev, data.port)) {
+ 				err = -EINVAL;
+ 				goto out_put;
+ 			}
+ 		} else {
+ 			data.port = -1;
+ 		}
+ 	} else if (tb[RDMA_NLDEV_ATTR_PORT_INDEX]) {
+ 		return -EINVAL;
+ 	}
+ 
+ 	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);
+ 	if (!msg) {
+ 		err = -ENOMEM;
+ 		goto out_put;
+ 	}
+ 	nlh = nlmsg_put(msg, NETLINK_CB(skb).portid, nlh->nlmsg_seq,
+ 			RDMA_NL_GET_TYPE(RDMA_NL_NLDEV,
+ 					 RDMA_NLDEV_CMD_GET_CHARDEV),
+ 			0, 0);
+ 
+ 	data.nl_msg = msg;
+ 	err = ib_get_client_nl_info(ibdev, client_name, &data);
+ 	if (err)
+ 		goto out_nlmsg;
+ 
+ 	err = nla_put_u64_64bit(msg, RDMA_NLDEV_ATTR_CHARDEV,
+ 				huge_encode_dev(data.cdev->devt),
+ 				RDMA_NLDEV_ATTR_PAD);
+ 	if (err)
+ 		goto out_data;
+ 	err = nla_put_u64_64bit(msg, RDMA_NLDEV_ATTR_CHARDEV_ABI, data.abi,
+ 				RDMA_NLDEV_ATTR_PAD);
+ 	if (err)
+ 		goto out_data;
+ 	if (nla_put_string(msg, RDMA_NLDEV_ATTR_CHARDEV_NAME,
+ 			   dev_name(data.cdev))) {
+ 		err = -EMSGSIZE;
+ 		goto out_data;
+ 	}
+ 
+ 	nlmsg_end(msg, nlh);
+ 	put_device(data.cdev);
+ 	if (ibdev)
+ 		ib_device_put(ibdev);
+ 	return rdma_nl_unicast(msg, NETLINK_CB(skb).portid);
+ 
+ out_data:
+ 	put_device(data.cdev);
+ out_nlmsg:
+ 	nlmsg_free(msg);
+ out_put:
+ 	if (ibdev)
+ 		ib_device_put(ibdev);
+ 	return err;
+ }
+ 
+ static int nldev_sys_get_doit(struct sk_buff *skb, struct nlmsghdr *nlh,
+ 			      struct netlink_ext_ack *extack)
+ {
+ 	struct nlattr *tb[RDMA_NLDEV_ATTR_MAX];
+ 	struct sk_buff *msg;
+ 	int err;
+ 
+ 	err = nlmsg_parse(nlh, 0, tb, RDMA_NLDEV_ATTR_MAX - 1,
+ 			  nldev_policy, extack);
+ 	if (err)
+ 		return err;
+ 
+ 	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);
+ 	if (!msg)
+ 		return -ENOMEM;
+ 
+ 	nlh = nlmsg_put(msg, NETLINK_CB(skb).portid, nlh->nlmsg_seq,
+ 			RDMA_NL_GET_TYPE(RDMA_NL_NLDEV,
+ 					 RDMA_NLDEV_CMD_SYS_GET),
+ 			0, 0);
+ 
+ 	err = nla_put_u8(msg, RDMA_NLDEV_SYS_ATTR_NETNS_MODE,
+ 			 (u8)ib_devices_shared_netns);
+ 	if (err) {
+ 		nlmsg_free(msg);
+ 		return err;
+ 	}
+ 	nlmsg_end(msg, nlh);
+ 	return rdma_nl_unicast(msg, NETLINK_CB(skb).portid);
+ }
+ 
+ static int nldev_set_sys_set_doit(struct sk_buff *skb, struct nlmsghdr *nlh,
+ 				  struct netlink_ext_ack *extack)
+ {
+ 	struct nlattr *tb[RDMA_NLDEV_ATTR_MAX];
+ 	u8 enable;
+ 	int err;
+ 
+ 	err = nlmsg_parse(nlh, 0, tb, RDMA_NLDEV_ATTR_MAX - 1,
+ 			  nldev_policy, extack);
+ 	if (err || !tb[RDMA_NLDEV_SYS_ATTR_NETNS_MODE])
+ 		return -EINVAL;
+ 
+ 	enable = nla_get_u8(tb[RDMA_NLDEV_SYS_ATTR_NETNS_MODE]);
+ 	/* Only 0 and 1 are supported */
+ 	if (enable > 1)
+ 		return -EINVAL;
+ 
+ 	err = rdma_compatdev_set(enable);
+ 	return err;
+ }
+ 
+ static int nldev_stat_set_doit(struct sk_buff *skb, struct nlmsghdr *nlh,
+ 			       struct netlink_ext_ack *extack)
+ {
+ 	u32 index, port, mode, mask = 0, qpn, cntn = 0;
+ 	struct nlattr *tb[RDMA_NLDEV_ATTR_MAX];
+ 	struct ib_device *device;
+ 	struct sk_buff *msg;
+ 	int ret;
+ 
+ 	ret = nlmsg_parse(nlh, 0, tb, RDMA_NLDEV_ATTR_MAX - 1,
+ 			  nldev_policy, extack);
+ 	/* Currently only counter for QP is supported */
+ 	if (ret || !tb[RDMA_NLDEV_ATTR_STAT_RES] ||
+ 	    !tb[RDMA_NLDEV_ATTR_DEV_INDEX] ||
+ 	    !tb[RDMA_NLDEV_ATTR_PORT_INDEX] || !tb[RDMA_NLDEV_ATTR_STAT_MODE])
+ 		return -EINVAL;
+ 
+ 	if (nla_get_u32(tb[RDMA_NLDEV_ATTR_STAT_RES]) != RDMA_NLDEV_ATTR_RES_QP)
+ 		return -EINVAL;
+ 
+ 	index = nla_get_u32(tb[RDMA_NLDEV_ATTR_DEV_INDEX]);
+ 	device = ib_device_get_by_index(sock_net(skb->sk), index);
+ 	if (!device)
+ 		return -EINVAL;
+ 
+ 	port = nla_get_u32(tb[RDMA_NLDEV_ATTR_PORT_INDEX]);
+ 	if (!rdma_is_port_valid(device, port)) {
+ 		ret = -EINVAL;
+ 		goto err;
+ 	}
+ 
+ 	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);
+ 	if (!msg) {
+ 		ret = -ENOMEM;
+ 		goto err;
+ 	}
+ 	nlh = nlmsg_put(msg, NETLINK_CB(skb).portid, nlh->nlmsg_seq,
+ 			RDMA_NL_GET_TYPE(RDMA_NL_NLDEV,
+ 					 RDMA_NLDEV_CMD_STAT_SET),
+ 			0, 0);
+ 
+ 	mode = nla_get_u32(tb[RDMA_NLDEV_ATTR_STAT_MODE]);
+ 	if (mode == RDMA_COUNTER_MODE_AUTO) {
+ 		if (tb[RDMA_NLDEV_ATTR_STAT_AUTO_MODE_MASK])
+ 			mask = nla_get_u32(
+ 				tb[RDMA_NLDEV_ATTR_STAT_AUTO_MODE_MASK]);
+ 
+ 		ret = rdma_counter_set_auto_mode(device, port,
+ 						 mask ? true : false, mask);
+ 		if (ret)
+ 			goto err_msg;
+ 	} else {
+ 		qpn = nla_get_u32(tb[RDMA_NLDEV_ATTR_RES_LQPN]);
+ 		if (tb[RDMA_NLDEV_ATTR_STAT_COUNTER_ID]) {
+ 			cntn = nla_get_u32(tb[RDMA_NLDEV_ATTR_STAT_COUNTER_ID]);
+ 			ret = rdma_counter_bind_qpn(device, port, qpn, cntn);
+ 		} else {
+ 			ret = rdma_counter_bind_qpn_alloc(device, port,
+ 							  qpn, &cntn);
+ 		}
+ 		if (ret)
+ 			goto err_msg;
+ 
+ 		if (fill_nldev_handle(msg, device) ||
+ 		    nla_put_u32(msg, RDMA_NLDEV_ATTR_PORT_INDEX, port) ||
+ 		    nla_put_u32(msg, RDMA_NLDEV_ATTR_STAT_COUNTER_ID, cntn) ||
+ 		    nla_put_u32(msg, RDMA_NLDEV_ATTR_RES_LQPN, qpn)) {
+ 			ret = -EMSGSIZE;
+ 			goto err_fill;
+ 		}
+ 	}
+ 
+ 	nlmsg_end(msg, nlh);
+ 	ib_device_put(device);
+ 	return rdma_nl_unicast(msg, NETLINK_CB(skb).portid);
+ 
+ err_fill:
+ 	rdma_counter_unbind_qpn(device, port, qpn, cntn);
+ err_msg:
+ 	nlmsg_free(msg);
+ err:
+ 	ib_device_put(device);
+ 	return ret;
+ }
+ 
+ static int nldev_stat_del_doit(struct sk_buff *skb, struct nlmsghdr *nlh,
+ 			       struct netlink_ext_ack *extack)
+ {
+ 	struct nlattr *tb[RDMA_NLDEV_ATTR_MAX];
+ 	struct ib_device *device;
+ 	struct sk_buff *msg;
+ 	u32 index, port, qpn, cntn;
+ 	int ret;
+ 
+ 	ret = nlmsg_parse(nlh, 0, tb, RDMA_NLDEV_ATTR_MAX - 1,
+ 			  nldev_policy, extack);
+ 	if (ret || !tb[RDMA_NLDEV_ATTR_STAT_RES] ||
+ 	    !tb[RDMA_NLDEV_ATTR_DEV_INDEX] || !tb[RDMA_NLDEV_ATTR_PORT_INDEX] ||
+ 	    !tb[RDMA_NLDEV_ATTR_STAT_COUNTER_ID] ||
+ 	    !tb[RDMA_NLDEV_ATTR_RES_LQPN])
+ 		return -EINVAL;
+ 
+ 	if (nla_get_u32(tb[RDMA_NLDEV_ATTR_STAT_RES]) != RDMA_NLDEV_ATTR_RES_QP)
+ 		return -EINVAL;
+ 
+ 	index = nla_get_u32(tb[RDMA_NLDEV_ATTR_DEV_INDEX]);
+ 	device = ib_device_get_by_index(sock_net(skb->sk), index);
+ 	if (!device)
+ 		return -EINVAL;
+ 
+ 	port = nla_get_u32(tb[RDMA_NLDEV_ATTR_PORT_INDEX]);
+ 	if (!rdma_is_port_valid(device, port)) {
+ 		ret = -EINVAL;
+ 		goto err;
+ 	}
+ 
+ 	msg = nlmsg_new(NLMSG_DEFAULT_SIZE, GFP_KERNEL);
+ 	if (!msg) {
+ 		ret = -ENOMEM;
+ 		goto err;
+ 	}
+ 	nlh = nlmsg_put(msg, NETLINK_CB(skb).portid, nlh->nlmsg_seq,
+ 			RDMA_NL_GET_TYPE(RDMA_NL_NLDEV,
+ 					 RDMA_NLDEV_CMD_STAT_SET),
+ 			0, 0);
+ 
+ 	cntn = nla_get_u32(tb[RDMA_NLDEV_ATTR_STAT_COUNTER_ID]);
+ 	qpn = nla_get_u32(tb[RDMA_NLDEV_ATTR_RES_LQPN]);
+ 	ret = rdma_counter_unbind_qpn(device, port, qpn, cntn);
+ 	if (ret)
+ 		goto err_unbind;
+ 
+ 	if (fill_nldev_handle(msg, device) ||
+ 	    nla_put_u32(msg, RDMA_NLDEV_ATTR_PORT_INDEX, port) ||
+ 	    nla_put_u32(msg, RDMA_NLDEV_ATTR_STAT_COUNTER_ID, cntn) ||
+ 	    nla_put_u32(msg, RDMA_NLDEV_ATTR_RES_LQPN, qpn)) {
+ 		ret = -EMSGSIZE;
+ 		goto err_fill;
+ 	}
+ 
+ 	nlmsg_end(msg, nlh);
+ 	ib_device_put(device);
+ 	return rdma_nl_unicast(msg, NETLINK_CB(skb).portid);
+ 
+ err_fill:
+ 	rdma_counter_bind_qpn(device, port, qpn, cntn);
+ err_unbind:
+ 	nlmsg_free(msg);
+ err:
+ 	ib_device_put(device);
+ 	return ret;
+ }
+ 
+ static int nldev_stat_get_doit(struct sk_buff *skb, struct nlmsghdr *nlh,
+ 			       struct netlink_ext_ack *extack)
+ {
+ 	struct nlattr *tb[RDMA_NLDEV_ATTR_MAX];
+ 	int ret;
+ 
+ 	ret = nlmsg_parse(nlh, 0, tb, RDMA_NLDEV_ATTR_MAX - 1,
+ 			  nldev_policy, extack);
+ 	if (ret || !tb[RDMA_NLDEV_ATTR_STAT_RES])
+ 		return -EINVAL;
+ 
+ 	switch (nla_get_u32(tb[RDMA_NLDEV_ATTR_STAT_RES])) {
+ 	case RDMA_NLDEV_ATTR_RES_QP:
+ 		ret = nldev_res_get_counter_doit(skb, nlh, extack);
+ 		break;
+ 
+ 	default:
+ 		ret = -EINVAL;
+ 		break;
+ 	}
+ 
+ 	return ret;
+ }
+ 
+ static int nldev_stat_get_dumpit(struct sk_buff *skb,
+ 				 struct netlink_callback *cb)
+ {
+ 	struct nlattr *tb[RDMA_NLDEV_ATTR_MAX];
+ 	int ret;
+ 
+ 	ret = nlmsg_parse(cb->nlh, 0, tb, RDMA_NLDEV_ATTR_MAX - 1,
+ 			  nldev_policy, NULL);
+ 	if (ret || !tb[RDMA_NLDEV_ATTR_STAT_RES])
+ 		return -EINVAL;
+ 
+ 	switch (nla_get_u32(tb[RDMA_NLDEV_ATTR_STAT_RES])) {
+ 	case RDMA_NLDEV_ATTR_RES_QP:
+ 		ret = nldev_res_get_counter_dumpit(skb, cb);
+ 		break;
+ 
+ 	default:
+ 		ret = -EINVAL;
+ 		break;
+ 	}
+ 
+ 	return ret;
+ }
++>>>>>>> b389327df905 (RDMA/nldev: Allow counter manual mode configration through RDMA netlink)
  
  static const struct rdma_nl_cbs nldev_cb_table[RDMA_NLDEV_NUM_OPS] = {
  	[RDMA_NLDEV_CMD_GET] = {
@@@ -1130,8 -1891,28 +1580,29 @@@
  		.dump = nldev_res_get_mr_dumpit,
  	},
  	[RDMA_NLDEV_CMD_RES_PD_GET] = {
 -		.doit = nldev_res_get_pd_doit,
  		.dump = nldev_res_get_pd_dumpit,
  	},
++<<<<<<< HEAD
++=======
+ 	[RDMA_NLDEV_CMD_SYS_GET] = {
+ 		.doit = nldev_sys_get_doit,
+ 	},
+ 	[RDMA_NLDEV_CMD_SYS_SET] = {
+ 		.doit = nldev_set_sys_set_doit,
+ 	},
+ 	[RDMA_NLDEV_CMD_STAT_SET] = {
+ 		.doit = nldev_stat_set_doit,
+ 		.flags = RDMA_NL_ADMIN_PERM,
+ 	},
+ 	[RDMA_NLDEV_CMD_STAT_GET] = {
+ 		.doit = nldev_stat_get_doit,
+ 		.dump = nldev_stat_get_dumpit,
+ 	},
+ 	[RDMA_NLDEV_CMD_STAT_DEL] = {
+ 		.doit = nldev_stat_del_doit,
+ 		.flags = RDMA_NL_ADMIN_PERM,
+ 	},
++>>>>>>> b389327df905 (RDMA/nldev: Allow counter manual mode configration through RDMA netlink)
  };
  
  void __init nldev_init(void)
diff --cc include/uapi/rdma/rdma_netlink.h
index 213452ef94a5,ce6fd66e7aa3..000000000000
--- a/include/uapi/rdma/rdma_netlink.h
+++ b/include/uapi/rdma/rdma_netlink.h
@@@ -274,6 -279,14 +274,17 @@@ enum rdma_nldev_command 
  
  	RDMA_NLDEV_CMD_RES_PD_GET, /* can dump */
  
++<<<<<<< HEAD
++=======
+ 	RDMA_NLDEV_CMD_GET_CHARDEV,
+ 
+ 	RDMA_NLDEV_CMD_STAT_SET,
+ 
+ 	RDMA_NLDEV_CMD_STAT_GET, /* can dump */
+ 
+ 	RDMA_NLDEV_CMD_STAT_DEL,
+ 
++>>>>>>> b389327df905 (RDMA/nldev: Allow counter manual mode configration through RDMA netlink)
  	RDMA_NLDEV_NUM_OPS
  };
  
* Unmerged path include/rdma/rdma_counter.h
* Unmerged path drivers/infiniband/core/nldev.c
* Unmerged path include/rdma/rdma_counter.h
* Unmerged path include/uapi/rdma/rdma_netlink.h
