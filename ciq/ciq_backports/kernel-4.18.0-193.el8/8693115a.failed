{IB,net}/mlx5: Constify rep ops functions pointers

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [netdrv] {ib, net}/mlx5: Constify rep ops functions pointers (Alaa Hleihel) [1724327 1724336]
Rebuild_FUZZ: 99.01%
commit-author Parav Pandit <parav@mellanox.com>
commit 8693115af4c24d92b971ad895c5f329761ed5d38
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/8693115a.failed

Currently for every representor type and for every single vport,
representer function pointers copy is stored even though they don't
change from one to other vport.

Additionally priv data entry for the rep is not passed during
registration, but its copied. It is used (set and cleared) by the user
of the reps.

As we want to scale vports, to simplify and also to split constants
from data,

1. Rename mlx5_eswitch_rep_if to mlx5_eswitch_rep_ops as to match _ops
prefix with other standard netdev, ibdev ops.
2. Constify the IB and Ethernet rep ops structure.
3. Instead of storing copy of all rep function pointers, store copy
per eswitch rep type.
4. Split data and function pointers to mlx5_eswitch_rep_ops and
mlx5_eswitch_rep_data.

	Signed-off-by: Parav Pandit <parav@mellanox.com>
	Reviewed-by: Mark Bloch <markb@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 8693115af4c24d92b971ad895c5f329761ed5d38)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/ib_rep.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
#	include/linux/mlx5/eswitch.h
diff --cc drivers/infiniband/hw/mlx5/ib_rep.c
index 95ac97af6166,22e651cb5534..000000000000
--- a/drivers/infiniband/hw/mlx5/ib_rep.c
+++ b/drivers/infiniband/hw/mlx5/ib_rep.c
@@@ -74,16 -42,25 +74,16 @@@ mlx5_ib_vport_rep_load(struct mlx5_core
  	if (!ibdev)
  		return -ENOMEM;
  
 -	ibdev->port = kcalloc(num_ports, sizeof(*ibdev->port),
 -			      GFP_KERNEL);
 -	if (!ibdev->port) {
 -		ib_dealloc_device(&ibdev->ib_dev);
 -		return -ENOMEM;
 -	}
 -
 -	ibdev->is_rep = true;
 -	vport_index = ibdev->free_port++;
 -	ibdev->port[vport_index].rep = rep;
 -	ibdev->port[vport_index].roce.netdev =
 -		mlx5_ib_get_rep_netdev(dev->priv.eswitch, rep->vport);
 +	ibdev->rep = rep;
  	ibdev->mdev = dev;
 -	ibdev->num_ports = num_ports;
 -
 -	if (!__mlx5_ib_add(ibdev, profile))
 +	ibdev->num_ports = max(MLX5_CAP_GEN(dev, num_ports),
 +			       MLX5_CAP_GEN(dev, num_vhca_ports));
 +	if (!__mlx5_ib_add(ibdev, &rep_profile)) {
 +		ib_dealloc_device(&ibdev->ib_dev);
  		return -EINVAL;
 +	}
  
- 	rep->rep_if[REP_IB].priv = ibdev;
+ 	rep->rep_data[REP_IB].priv = ibdev;
  
  	return 0;
  }
@@@ -93,13 -70,13 +93,22 @@@ mlx5_ib_vport_rep_unload(struct mlx5_es
  {
  	struct mlx5_ib_dev *dev;
  
++<<<<<<< HEAD
 +	if (!rep->rep_if[REP_IB].priv)
++=======
+ 	if (!rep->rep_data[REP_IB].priv ||
+ 	    rep->vport != MLX5_VPORT_UPLINK)
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  		return;
  
  	dev = mlx5_ib_rep_to_dev(rep);
  	__mlx5_ib_remove(dev, dev->profile, MLX5_IB_STAGE_MAX);
++<<<<<<< HEAD
 +	rep->rep_if[REP_IB].priv = NULL;
 +	ib_dealloc_device(&dev->ib_dev);
++=======
+ 	rep->rep_data[REP_IB].priv = NULL;
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  }
  
  static void *mlx5_ib_vport_get_proto_dev(struct mlx5_eswitch_rep *rep)
@@@ -107,53 -84,24 +116,67 @@@
  	return mlx5_ib_rep_to_dev(rep);
  }
  
++<<<<<<< HEAD
 +static void mlx5_ib_rep_register_vf_vports(struct mlx5_ib_dev *dev)
 +{
 +	struct mlx5_eswitch *esw   = dev->mdev->priv.eswitch;
 +	int total_vfs = MLX5_TOTAL_VPORTS(dev->mdev);
 +	int vport;
 +
 +	for (vport = 1; vport < total_vfs; vport++) {
 +		struct mlx5_eswitch_rep_if rep_if = {};
 +
 +		rep_if.load = mlx5_ib_vport_rep_load;
 +		rep_if.unload = mlx5_ib_vport_rep_unload;
 +		rep_if.get_proto_dev = mlx5_ib_vport_get_proto_dev;
 +		mlx5_eswitch_register_vport_rep(esw, vport, &rep_if, REP_IB);
 +	}
++=======
+ static const struct mlx5_eswitch_rep_ops rep_ops = {
+ 	.load = mlx5_ib_vport_rep_load,
+ 	.unload = mlx5_ib_vport_rep_unload,
+ 	.get_proto_dev = mlx5_ib_vport_get_proto_dev,
+ };
+ 
+ void mlx5_ib_register_vport_reps(struct mlx5_core_dev *mdev)
+ {
+ 	struct mlx5_eswitch *esw = mdev->priv.eswitch;
+ 
+ 	mlx5_eswitch_register_vport_reps(esw, &rep_ops, REP_IB);
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  }
  
 -void mlx5_ib_unregister_vport_reps(struct mlx5_core_dev *mdev)
 +static void mlx5_ib_rep_unregister_vf_vports(struct mlx5_ib_dev *dev)
  {
 -	struct mlx5_eswitch *esw = mdev->priv.eswitch;
 +	struct mlx5_eswitch *esw   = dev->mdev->priv.eswitch;
 +	int total_vfs = MLX5_TOTAL_VPORTS(dev->mdev);
 +	int vport;
  
 -	mlx5_eswitch_unregister_vport_reps(esw, REP_IB);
 +	for (vport = 1; vport < total_vfs; vport++)
 +		mlx5_eswitch_unregister_vport_rep(esw, vport, REP_IB);
 +}
 +
 +void mlx5_ib_register_vport_reps(struct mlx5_ib_dev *dev)
 +{
 +	struct mlx5_eswitch *esw = dev->mdev->priv.eswitch;
 +	struct mlx5_eswitch_rep_if rep_if = {};
 +
 +	rep_if.load = mlx5_ib_nic_rep_load;
 +	rep_if.unload = mlx5_ib_nic_rep_unload;
 +	rep_if.get_proto_dev = mlx5_ib_vport_get_proto_dev;
 +	rep_if.priv = dev;
 +
 +	mlx5_eswitch_register_vport_rep(esw, 0, &rep_if, REP_IB);
 +
 +	mlx5_ib_rep_register_vf_vports(dev);
 +}
 +
 +void mlx5_ib_unregister_vport_reps(struct mlx5_ib_dev *dev)
 +{
 +	struct mlx5_eswitch *esw   = dev->mdev->priv.eswitch;
 +
 +	mlx5_ib_rep_unregister_vf_vports(dev); /* VFs vports */
 +	mlx5_eswitch_unregister_vport_rep(esw, 0, REP_IB); /* UPLINK PF*/
  }
  
  u8 mlx5_ib_eswitch_mode(struct mlx5_eswitch *esw)
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
index 21f28aa252f3,33f8f99681a5..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
@@@ -1780,10 -1752,10 +1780,10 @@@ mlx5e_vport_rep_load(struct mlx5_core_d
  	}
  
  	rpriv->netdev = netdev;
- 	rep->rep_if[REP_ETH].priv = rpriv;
+ 	rep->rep_data[REP_ETH].priv = rpriv;
  	INIT_LIST_HEAD(&rpriv->vport_sqs_list);
  
 -	if (rep->vport == MLX5_VPORT_UPLINK) {
 +	if (rep->vport == FDB_UPLINK_VPORT) {
  		err = mlx5e_create_mdev_resources(dev);
  		if (err)
  			goto err_destroy_netdev;
@@@ -1857,17 -1835,8 +1863,22 @@@ static const struct mlx5_eswitch_rep_op
  void mlx5e_rep_register_vport_reps(struct mlx5_core_dev *mdev)
  {
  	struct mlx5_eswitch *esw = mdev->priv.eswitch;
++<<<<<<< HEAD
 +	int total_vfs = MLX5_TOTAL_VPORTS(mdev);
 +	int vport;
 +
 +	for (vport = 0; vport < total_vfs; vport++) {
 +		struct mlx5_eswitch_rep_if rep_if = {};
 +
 +		rep_if.load = mlx5e_vport_rep_load;
 +		rep_if.unload = mlx5e_vport_rep_unload;
 +		rep_if.get_proto_dev = mlx5e_vport_rep_get_proto_dev;
 +		mlx5_eswitch_register_vport_rep(esw, vport, &rep_if, REP_ETH);
 +	}
++=======
+ 
+ 	mlx5_eswitch_register_vport_reps(esw, &rep_ops, REP_ETH);
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  }
  
  void mlx5e_rep_unregister_vport_reps(struct mlx5_core_dev *mdev)
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
index 5d30117c7129,d6246ee042fa..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@@ -319,7 -332,7 +319,11 @@@ static int esw_set_global_vlan_pop(stru
  	esw_debug(esw->dev, "%s applying global %s policy\n", __func__, val ? "pop" : "none");
  	for (vf_vport = 1; vf_vport < esw->enabled_vports; vf_vport++) {
  		rep = &esw->offloads.vport_reps[vf_vport];
++<<<<<<< HEAD
 +		if (!rep->rep_if[REP_ETH].valid)
++=======
+ 		if (atomic_read(&rep->rep_data[REP_ETH].state) != REP_LOADED)
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  			continue;
  
  		err = __mlx5_eswitch_set_vport_vlan(esw, rep->vport, 0, 0, val);
@@@ -1219,59 -1269,119 +1223,129 @@@ int esw_offloads_init_reps(struct mlx5_
  	if (!esw->offloads.vport_reps)
  		return -ENOMEM;
  
 +	offloads = &esw->offloads;
  	mlx5_query_nic_vport_mac_address(dev, 0, hw_id);
  
 -	mlx5_esw_for_all_reps(esw, vport, rep) {
 -		rep->vport = mlx5_eswitch_index_to_vport_num(esw, vport);
 -		ether_addr_copy(rep->hw_id, hw_id);
 +	for (vport = 0; vport < total_vfs; vport++) {
 +		rep = &offloads->vport_reps[vport];
  
++<<<<<<< HEAD
 +		rep->vport = vport;
 +		ether_addr_copy(rep->hw_id, hw_id);
++=======
+ 		for (rep_type = 0; rep_type < NUM_REP_TYPES; rep_type++)
+ 			atomic_set(&rep->rep_data[rep_type].state,
+ 				   REP_UNREGISTERED);
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  	}
  
 +	offloads->vport_reps[0].vport = FDB_UPLINK_VPORT;
 +
  	return 0;
  }
  
 -static void __esw_offloads_unload_rep(struct mlx5_eswitch *esw,
 -				      struct mlx5_eswitch_rep *rep, u8 rep_type)
 +static void esw_offloads_unload_reps_type(struct mlx5_eswitch *esw, int nvports,
 +					  u8 rep_type)
  {
++<<<<<<< HEAD
 +	struct mlx5_eswitch_rep *rep;
 +	int vport;
 +
 +	for (vport = nvports - 1; vport >= 0; vport--) {
 +		rep = &esw->offloads.vport_reps[vport];
 +		if (!rep->rep_if[rep_type].valid)
 +			continue;
 +
 +		rep->rep_if[rep_type].unload(rep);
++=======
+ 	if (atomic_cmpxchg(&rep->rep_data[rep_type].state,
+ 			   REP_LOADED, REP_REGISTERED) == REP_LOADED)
+ 		esw->offloads.rep_ops[rep_type]->unload(rep);
+ }
+ 
+ static void __unload_reps_special_vport(struct mlx5_eswitch *esw, u8 rep_type)
+ {
+ 	struct mlx5_eswitch_rep *rep;
+ 
+ 	if (mlx5_ecpf_vport_exists(esw->dev)) {
+ 		rep = mlx5_eswitch_get_rep(esw, MLX5_VPORT_ECPF);
+ 		__esw_offloads_unload_rep(esw, rep, rep_type);
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  	}
 -
 -	if (mlx5_core_is_ecpf_esw_manager(esw->dev)) {
 -		rep = mlx5_eswitch_get_rep(esw, MLX5_VPORT_PF);
 -		__esw_offloads_unload_rep(esw, rep, rep_type);
 -	}
 -
 -	rep = mlx5_eswitch_get_rep(esw, MLX5_VPORT_UPLINK);
 -	__esw_offloads_unload_rep(esw, rep, rep_type);
 -}
 -
 -static void __unload_reps_vf_vport(struct mlx5_eswitch *esw, int nvports,
 -				   u8 rep_type)
 -{
 -	struct mlx5_eswitch_rep *rep;
 -	int i;
 -
 -	mlx5_esw_for_each_vf_rep_reverse(esw, i, rep, nvports)
 -		__esw_offloads_unload_rep(esw, rep, rep_type);
  }
  
 -static void esw_offloads_unload_vf_reps(struct mlx5_eswitch *esw, int nvports)
 +static void esw_offloads_unload_reps(struct mlx5_eswitch *esw, int nvports)
  {
  	u8 rep_type = NUM_REP_TYPES;
  
  	while (rep_type-- > 0)
 -		__unload_reps_vf_vport(esw, nvports, rep_type);
 +		esw_offloads_unload_reps_type(esw, nvports, rep_type);
  }
  
 -static void __unload_reps_all_vport(struct mlx5_eswitch *esw, int nvports,
 -				    u8 rep_type)
 +static int esw_offloads_load_reps_type(struct mlx5_eswitch *esw, int nvports,
 +				       u8 rep_type)
  {
 -	__unload_reps_vf_vport(esw, nvports, rep_type);
 +	struct mlx5_eswitch_rep *rep;
 +	int vport;
 +	int err;
  
 -	/* Special vports must be the last to unload. */
 -	__unload_reps_special_vport(esw, rep_type);
 -}
 +	for (vport = 0; vport < nvports; vport++) {
 +		rep = &esw->offloads.vport_reps[vport];
 +		if (!rep->rep_if[rep_type].valid)
 +			continue;
  
++<<<<<<< HEAD
 +		err = rep->rep_if[rep_type].load(esw->dev, rep);
 +		if (err)
 +			goto err_reps;
++=======
+ static void esw_offloads_unload_all_reps(struct mlx5_eswitch *esw, int nvports)
+ {
+ 	u8 rep_type = NUM_REP_TYPES;
+ 
+ 	while (rep_type-- > 0)
+ 		__unload_reps_all_vport(esw, nvports, rep_type);
+ }
+ 
+ static int __esw_offloads_load_rep(struct mlx5_eswitch *esw,
+ 				   struct mlx5_eswitch_rep *rep, u8 rep_type)
+ {
+ 	int err = 0;
+ 
+ 	if (atomic_cmpxchg(&rep->rep_data[rep_type].state,
+ 			   REP_REGISTERED, REP_LOADED) == REP_REGISTERED) {
+ 		err = esw->offloads.rep_ops[rep_type]->load(esw->dev, rep);
+ 		if (err)
+ 			atomic_set(&rep->rep_data[rep_type].state,
+ 				   REP_REGISTERED);
+ 	}
+ 
+ 	return err;
+ }
+ 
+ static int __load_reps_special_vport(struct mlx5_eswitch *esw, u8 rep_type)
+ {
+ 	struct mlx5_eswitch_rep *rep;
+ 	int err;
+ 
+ 	rep = mlx5_eswitch_get_rep(esw, MLX5_VPORT_UPLINK);
+ 	err = __esw_offloads_load_rep(esw, rep, rep_type);
+ 	if (err)
+ 		return err;
+ 
+ 	if (mlx5_core_is_ecpf_esw_manager(esw->dev)) {
+ 		rep = mlx5_eswitch_get_rep(esw, MLX5_VPORT_PF);
+ 		err = __esw_offloads_load_rep(esw, rep, rep_type);
+ 		if (err)
+ 			goto err_pf;
+ 	}
+ 
+ 	if (mlx5_ecpf_vport_exists(esw->dev)) {
+ 		rep = mlx5_eswitch_get_rep(esw, MLX5_VPORT_ECPF);
+ 		err = __esw_offloads_load_rep(esw, rep, rep_type);
+ 		if (err)
+ 			goto err_ecpf;
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  	}
  
  	return 0;
@@@ -1950,65 -2215,55 +2024,97 @@@ int mlx5_devlink_eswitch_encap_mode_get
  	return 0;
  }
  
++<<<<<<< HEAD
 +void mlx5_eswitch_register_vport_rep(struct mlx5_eswitch *esw,
 +				     int vport_index,
 +				     struct mlx5_eswitch_rep_if *__rep_if,
 +				     u8 rep_type)
 +{
 +	struct mlx5_esw_offload *offloads = &esw->offloads;
 +	struct mlx5_eswitch_rep_if *rep_if;
 +
 +	rep_if = &offloads->vport_reps[vport_index].rep_if[rep_type];
 +
 +	rep_if->load   = __rep_if->load;
 +	rep_if->unload = __rep_if->unload;
 +	rep_if->get_proto_dev = __rep_if->get_proto_dev;
 +	rep_if->priv = __rep_if->priv;
 +
 +	rep_if->valid = true;
++=======
+ void mlx5_eswitch_register_vport_reps(struct mlx5_eswitch *esw,
+ 				      const struct mlx5_eswitch_rep_ops *ops,
+ 				      u8 rep_type)
+ {
+ 	struct mlx5_eswitch_rep_data *rep_data;
+ 	struct mlx5_eswitch_rep *rep;
+ 	int i;
+ 
+ 	esw->offloads.rep_ops[rep_type] = ops;
+ 	mlx5_esw_for_all_reps(esw, i, rep) {
+ 		rep_data = &rep->rep_data[rep_type];
+ 		atomic_set(&rep_data->state, REP_REGISTERED);
+ 	}
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  }
 -EXPORT_SYMBOL(mlx5_eswitch_register_vport_reps);
 +EXPORT_SYMBOL(mlx5_eswitch_register_vport_rep);
  
 -void mlx5_eswitch_unregister_vport_reps(struct mlx5_eswitch *esw, u8 rep_type)
 +void mlx5_eswitch_unregister_vport_rep(struct mlx5_eswitch *esw,
 +				       int vport_index, u8 rep_type)
  {
 -	u16 max_vf = mlx5_core_max_vfs(esw->dev);
 +	struct mlx5_esw_offload *offloads = &esw->offloads;
  	struct mlx5_eswitch_rep *rep;
 -	int i;
  
 -	if (esw->mode == SRIOV_OFFLOADS)
 -		__unload_reps_all_vport(esw, max_vf, rep_type);
 +	rep = &offloads->vport_reps[vport_index];
 +
++<<<<<<< HEAD
 +	if (esw->mode == SRIOV_OFFLOADS && esw->vports[vport_index].enabled)
 +		rep->rep_if[rep_type].unload(rep);
  
 +	rep->rep_if[rep_type].valid = false;
++=======
+ 	mlx5_esw_for_all_reps(esw, i, rep)
+ 		atomic_set(&rep->rep_data[rep_type].state, REP_UNREGISTERED);
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  }
 -EXPORT_SYMBOL(mlx5_eswitch_unregister_vport_reps);
 +EXPORT_SYMBOL(mlx5_eswitch_unregister_vport_rep);
  
  void *mlx5_eswitch_get_uplink_priv(struct mlx5_eswitch *esw, u8 rep_type)
  {
 +#define UPLINK_REP_INDEX 0
 +	struct mlx5_esw_offload *offloads = &esw->offloads;
  	struct mlx5_eswitch_rep *rep;
  
++<<<<<<< HEAD
 +	rep = &offloads->vport_reps[UPLINK_REP_INDEX];
 +	return rep->rep_if[rep_type].priv;
++=======
+ 	rep = mlx5_eswitch_get_rep(esw, MLX5_VPORT_UPLINK);
+ 	return rep->rep_data[rep_type].priv;
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  }
  
  void *mlx5_eswitch_get_proto_dev(struct mlx5_eswitch *esw,
  				 int vport,
  				 u8 rep_type)
  {
 +	struct mlx5_esw_offload *offloads = &esw->offloads;
  	struct mlx5_eswitch_rep *rep;
  
 -	rep = mlx5_eswitch_get_rep(esw, vport);
 +	if (vport == FDB_UPLINK_VPORT)
 +		vport = UPLINK_REP_INDEX;
 +
++<<<<<<< HEAD
 +	rep = &offloads->vport_reps[vport];
  
 +	if (rep->rep_if[rep_type].valid &&
 +	    rep->rep_if[rep_type].get_proto_dev)
 +		return rep->rep_if[rep_type].get_proto_dev(rep);
++=======
+ 	if (atomic_read(&rep->rep_data[rep_type].state) == REP_LOADED &&
+ 	    esw->offloads.rep_ops[rep_type]->get_proto_dev)
+ 		return esw->offloads.rep_ops[rep_type]->get_proto_dev(rep);
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  	return NULL;
  }
  EXPORT_SYMBOL(mlx5_eswitch_get_proto_dev);
diff --cc include/linux/mlx5/eswitch.h
index fab5121ffb8f,d81ee4df181c..000000000000
--- a/include/linux/mlx5/eswitch.h
+++ b/include/linux/mlx5/eswitch.h
@@@ -22,14 -22,22 +22,26 @@@ enum 
  	NUM_REP_TYPES,
  };
  
 -enum {
 -	REP_UNREGISTERED,
 -	REP_REGISTERED,
 -	REP_LOADED,
 -};
 -
  struct mlx5_eswitch_rep;
++<<<<<<< HEAD
 +struct mlx5_eswitch_rep_if {
 +	int		       (*load)(struct mlx5_core_dev *dev,
 +				       struct mlx5_eswitch_rep *rep);
 +	void		       (*unload)(struct mlx5_eswitch_rep *rep);
 +	void		       *(*get_proto_dev)(struct mlx5_eswitch_rep *rep);
 +	void			*priv;
 +	bool		       valid;
++=======
+ struct mlx5_eswitch_rep_ops {
+ 	int (*load)(struct mlx5_core_dev *dev, struct mlx5_eswitch_rep *rep);
+ 	void (*unload)(struct mlx5_eswitch_rep *rep);
+ 	void *(*get_proto_dev)(struct mlx5_eswitch_rep *rep);
+ };
+ 
+ struct mlx5_eswitch_rep_data {
+ 	void *priv;
+ 	atomic_t state;
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  };
  
  struct mlx5_eswitch_rep {
@@@ -40,13 -48,10 +52,20 @@@
  	u32		       vlan_refcount;
  };
  
++<<<<<<< HEAD
 +void mlx5_eswitch_register_vport_rep(struct mlx5_eswitch *esw,
 +				     int vport_index,
 +				     struct mlx5_eswitch_rep_if *rep_if,
 +				     u8 rep_type);
 +void mlx5_eswitch_unregister_vport_rep(struct mlx5_eswitch *esw,
 +				       int vport_index,
 +				       u8 rep_type);
++=======
+ void mlx5_eswitch_register_vport_reps(struct mlx5_eswitch *esw,
+ 				      const struct mlx5_eswitch_rep_ops *ops,
+ 				      u8 rep_type);
+ void mlx5_eswitch_unregister_vport_reps(struct mlx5_eswitch *esw, u8 rep_type);
++>>>>>>> 8693115af4c2 ({IB,net}/mlx5: Constify rep ops functions pointers)
  void *mlx5_eswitch_get_proto_dev(struct mlx5_eswitch *esw,
  				 int vport,
  				 u8 rep_type);
* Unmerged path drivers/infiniband/hw/mlx5/ib_rep.c
diff --git a/drivers/infiniband/hw/mlx5/ib_rep.h b/drivers/infiniband/hw/mlx5/ib_rep.h
index 090c992c76a6..747a6e087c33 100644
--- a/drivers/infiniband/hw/mlx5/ib_rep.h
+++ b/drivers/infiniband/hw/mlx5/ib_rep.h
@@ -67,6 +67,6 @@ struct net_device *mlx5_ib_get_rep_netdev(struct mlx5_eswitch *esw,
 static inline
 struct mlx5_ib_dev *mlx5_ib_rep_to_dev(struct mlx5_eswitch_rep *rep)
 {
-	return rep->rep_if[REP_IB].priv;
+	return rep->rep_data[REP_IB].priv;
 }
 #endif /* __MLX5_IB_REP_H__ */
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.h b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
index c40c025afd99..e34573fd88c1 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
@@ -91,7 +91,7 @@ struct mlx5e_rep_priv {
 static inline
 struct mlx5e_rep_priv *mlx5e_rep_to_rep_priv(struct mlx5_eswitch_rep *rep)
 {
-	return rep->rep_if[REP_ETH].priv;
+	return rep->rep_data[REP_ETH].priv;
 }
 
 struct mlx5e_neigh {
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index 14d8d502a0a3..3b105c6765a5 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@ -174,6 +174,7 @@ struct mlx5_esw_offload {
 	struct mutex peer_mutex;
 	DECLARE_HASHTABLE(encap_tbl, 8);
 	DECLARE_HASHTABLE(mod_hdr_tbl, 8);
+	const struct mlx5_eswitch_rep_ops *rep_ops[NUM_REP_TYPES];
 	u8 inline_mode;
 	u64 num_flows;
 	u8 encap;
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
* Unmerged path include/linux/mlx5/eswitch.h
