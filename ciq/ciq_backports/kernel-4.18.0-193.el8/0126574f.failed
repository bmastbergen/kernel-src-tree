locking/lockdep: Only call init_rcu_head() after RCU has been initialized

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Bart Van Assche <bvanassche@acm.org>
commit 0126574fca2ce0f0d5beb9dade6efb823ff7407b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/0126574f.failed

init_data_structures_once() is called for the first time before RCU has
been initialized. Make sure that init_rcu_head() is called before the
RCU head is used and after RCU has been initialized.

	Signed-off-by: Bart Van Assche <bvanassche@acm.org>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Andrew Morton <akpm@linux-foundation.org>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Borislav Petkov <bp@alien8.de>
	Cc: Dave Hansen <dave.hansen@linux.intel.com>
	Cc: H. Peter Anvin <hpa@zytor.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Paul E. McKenney <paulmck@linux.vnet.ibm.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Rik van Riel <riel@surriel.com>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Will Deacon <will.deacon@arm.com>
	Cc: longman@redhat.com
Link: https://lkml.kernel.org/r/c20aa0f0-42ab-a884-d931-7d4ec2bf0cdc@acm.org
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 0126574fca2ce0f0d5beb9dade6efb823ff7407b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/locking/lockdep.c
diff --cc kernel/locking/lockdep.c
index aed5c03ce876,34cdcbedda49..000000000000
--- a/kernel/locking/lockdep.c
+++ b/kernel/locking/lockdep.c
@@@ -755,15 -982,27 +755,29 @@@ static bool assign_lock_key(struct lock
   */
  static void init_data_structures_once(void)
  {
- 	static bool initialization_happened;
+ 	static bool ds_initialized, rcu_head_initialized;
  	int i;
  
- 	if (likely(initialization_happened))
+ 	if (likely(rcu_head_initialized))
  		return;
  
- 	initialization_happened = true;
+ 	if (system_state >= SYSTEM_SCHEDULING) {
+ 		init_rcu_head(&delayed_free.rcu_head);
+ 		rcu_head_initialized = true;
+ 	}
+ 
+ 	if (ds_initialized)
+ 		return;
+ 
+ 	ds_initialized = true;
+ 
++<<<<<<< HEAD
++=======
+ 	INIT_LIST_HEAD(&delayed_free.pf[0].zapped);
+ 	INIT_LIST_HEAD(&delayed_free.pf[1].zapped);
  
++>>>>>>> 0126574fca2c (locking/lockdep: Only call init_rcu_head() after RCU has been initialized)
  	for (i = 0; i < ARRAY_SIZE(lock_classes); i++) {
 -		list_add_tail(&lock_classes[i].lock_entry, &free_lock_classes);
  		INIT_LIST_HEAD(&lock_classes[i].locks_after);
  		INIT_LIST_HEAD(&lock_classes[i].locks_before);
  	}
* Unmerged path kernel/locking/lockdep.c
