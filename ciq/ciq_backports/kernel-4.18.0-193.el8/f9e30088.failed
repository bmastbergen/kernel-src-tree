net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Pablo Neira Ayuso <pablo@netfilter.org>
commit f9e30088d20016a224d8110d45356da253eaa26a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/f9e30088.failed

And any other existing fields in this structure that refer to tc.
Specifically:

* tc_cls_flower_offload_flow_rule() to flow_cls_offload_flow_rule().
* TC_CLSFLOWER_* to FLOW_CLS_*.
* tc_cls_common_offload to tc_cls_common_offload.

	Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit f9e30088d20016a224d8110d45356da253eaa26a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.c
#	drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.h
#	drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_geneve.c
#	drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_gre.c
#	drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_vxlan.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
#	drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c
#	drivers/net/ethernet/mscc/ocelot_flower.c
#	drivers/net/ethernet/netronome/nfp/flower/action.c
#	drivers/net/ethernet/netronome/nfp/flower/match.c
#	drivers/net/ethernet/netronome/nfp/flower/offload.c
#	include/net/flow_offload.h
#	include/net/pkt_cls.h
#	net/sched/cls_flower.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.c
index fc750bb56f73,a6a52806be45..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.c
@@@ -622,23 -456,87 +622,80 @@@ int mlx5e_tc_tun_parse(struct net_devic
  		       void *headers_c,
  		       void *headers_v, u8 *match_level)
  {
 -	struct mlx5e_tc_tunnel *tunnel = mlx5e_get_tc_tun(filter_dev);
 +	int tunnel_type;
  	int err = 0;
  
 -	if (!tunnel) {
 +	tunnel_type = mlx5e_tc_tun_get_type(filter_dev);
 +	if (tunnel_type == MLX5E_TC_TUNNEL_TYPE_VXLAN) {
 +		*match_level = MLX5_MATCH_L4;
 +		err = mlx5e_tc_tun_parse_vxlan(priv, spec, f,
 +					       headers_c, headers_v);
 +	} else if (tunnel_type == MLX5E_TC_TUNNEL_TYPE_GRETAP) {
 +		*match_level = MLX5_MATCH_L3;
 +		err = mlx5e_tc_tun_parse_gretap(priv, spec, f,
 +						headers_c, headers_v);
 +	} else {
  		netdev_warn(priv->netdev,
 -			    "decapsulation offload is not supported for %s net device\n",
 -			    mlx5e_netdev_kind(filter_dev));
 -		err = -EOPNOTSUPP;
 -		goto out;
 -	}
 -
 -	*match_level = tunnel->match_level;
 -
 -	if (tunnel->parse_udp_ports) {
 -		err = tunnel->parse_udp_ports(priv, spec, f,
 -					      headers_c, headers_v);
 -		if (err)
 -			goto out;
 -	}
 -
 -	if (tunnel->parse_tunnel) {
 -		err = tunnel->parse_tunnel(priv, spec, f,
 -					   headers_c, headers_v);
 -		if (err)
 -			goto out;
 +			    "decapsulation offload is not supported for %s net device (%d)\n",
 +			    mlx5e_netdev_kind(filter_dev), tunnel_type);
 +		return -EOPNOTSUPP;
  	}
 -
 -out:
  	return err;
  }
++<<<<<<< HEAD
++=======
+ 
+ int mlx5e_tc_tun_parse_udp_ports(struct mlx5e_priv *priv,
+ 				 struct mlx5_flow_spec *spec,
+ 				 struct flow_cls_offload *f,
+ 				 void *headers_c,
+ 				 void *headers_v)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(f);
+ 	struct netlink_ext_ack *extack = f->common.extack;
+ 	struct flow_match_ports enc_ports;
+ 
+ 	/* Full udp dst port must be given */
+ 
+ 	if (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ENC_PORTS)) {
+ 		NL_SET_ERR_MSG_MOD(extack,
+ 				   "UDP tunnel decap filter must include enc_dst_port condition");
+ 		netdev_warn(priv->netdev,
+ 			    "UDP tunnel decap filter must include enc_dst_port condition\n");
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	flow_rule_match_enc_ports(rule, &enc_ports);
+ 
+ 	if (memchr_inv(&enc_ports.mask->dst, 0xff,
+ 		       sizeof(enc_ports.mask->dst))) {
+ 		NL_SET_ERR_MSG_MOD(extack,
+ 				   "UDP tunnel decap filter must match enc_dst_port fully");
+ 		netdev_warn(priv->netdev,
+ 			    "UDP tunnel decap filter must match enc_dst_port fully\n");
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	/* match on UDP protocol and dst port number */
+ 
+ 	MLX5_SET_TO_ONES(fte_match_set_lyr_2_4, headers_c, ip_protocol);
+ 	MLX5_SET(fte_match_set_lyr_2_4, headers_v, ip_protocol, IPPROTO_UDP);
+ 
+ 	MLX5_SET(fte_match_set_lyr_2_4, headers_c, udp_dport,
+ 		 ntohs(enc_ports.mask->dst));
+ 	MLX5_SET(fte_match_set_lyr_2_4, headers_v, udp_dport,
+ 		 ntohs(enc_ports.key->dst));
+ 
+ 	/* UDP src port on outer header is generated by HW,
+ 	 * so it is probably a bad idea to request matching it.
+ 	 * Nonetheless, it is allowed.
+ 	 */
+ 
+ 	MLX5_SET(fte_match_set_lyr_2_4, headers_c, udp_sport,
+ 		 ntohs(enc_ports.mask->src));
+ 	MLX5_SET(fte_match_set_lyr_2_4, headers_v, udp_sport,
+ 		 ntohs(enc_ports.key->src));
+ 
+ 	return 0;
+ }
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.h
index b63f15de899d,c362b9225dc2..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.h
@@@ -14,9 -14,41 +14,43 @@@
  enum {
  	MLX5E_TC_TUNNEL_TYPE_UNKNOWN,
  	MLX5E_TC_TUNNEL_TYPE_VXLAN,
 -	MLX5E_TC_TUNNEL_TYPE_GENEVE,
 -	MLX5E_TC_TUNNEL_TYPE_GRETAP,
 +	MLX5E_TC_TUNNEL_TYPE_GRETAP
  };
  
++<<<<<<< HEAD
++=======
+ struct mlx5e_tc_tunnel {
+ 	int tunnel_type;
+ 	enum mlx5_flow_match_level match_level;
+ 
+ 	bool (*can_offload)(struct mlx5e_priv *priv);
+ 	int (*calc_hlen)(struct mlx5e_encap_entry *e);
+ 	int (*init_encap_attr)(struct net_device *tunnel_dev,
+ 			       struct mlx5e_priv *priv,
+ 			       struct mlx5e_encap_entry *e,
+ 			       struct netlink_ext_ack *extack);
+ 	int (*generate_ip_tun_hdr)(char buf[],
+ 				   __u8 *ip_proto,
+ 				   struct mlx5e_encap_entry *e);
+ 	int (*parse_udp_ports)(struct mlx5e_priv *priv,
+ 			       struct mlx5_flow_spec *spec,
+ 			       struct flow_cls_offload *f,
+ 			       void *headers_c,
+ 			       void *headers_v);
+ 	int (*parse_tunnel)(struct mlx5e_priv *priv,
+ 			    struct mlx5_flow_spec *spec,
+ 			    struct flow_cls_offload *f,
+ 			    void *headers_c,
+ 			    void *headers_v);
+ };
+ 
+ extern struct mlx5e_tc_tunnel vxlan_tunnel;
+ extern struct mlx5e_tc_tunnel geneve_tunnel;
+ extern struct mlx5e_tc_tunnel gre_tunnel;
+ 
+ struct mlx5e_tc_tunnel *mlx5e_get_tc_tun(struct net_device *tunnel_dev);
+ 
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  int mlx5e_tc_tun_init_encap_attr(struct net_device *tunnel_dev,
  				 struct mlx5e_priv *priv,
  				 struct mlx5e_encap_entry *e,
@@@ -41,4 -72,10 +75,13 @@@ int mlx5e_tc_tun_parse(struct net_devic
  		       void *headers_c,
  		       void *headers_v, u8 *match_level);
  
++<<<<<<< HEAD
++=======
+ int mlx5e_tc_tun_parse_udp_ports(struct mlx5e_priv *priv,
+ 				 struct mlx5_flow_spec *spec,
+ 				 struct flow_cls_offload *f,
+ 				 void *headers_c,
+ 				 void *headers_v);
+ 
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  #endif //__MLX5_EN_TC_TUNNEL_H__
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index 544bb524513f,2d6436257f9d..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -1337,8 -1358,7 +1337,12 @@@ static int parse_tunnel_attr(struct mlx
  				       outer_headers);
  	void *headers_v = MLX5_ADDR_OF(fte_match_param, spec->match_value,
  				       outer_headers);
++<<<<<<< HEAD
 +	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(f);
 +	struct flow_match_control enc_control;
++=======
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(f);
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  	int err;
  
  	err = mlx5e_tc_tun_parse(filter_dev, priv, spec, f,
@@@ -1438,9 -1456,29 +1442,9 @@@
  	return 0;
  }
  
 -static void *get_match_headers_criteria(u32 flags,
 -					struct mlx5_flow_spec *spec)
 -{
 -	return (flags & MLX5_FLOW_CONTEXT_ACTION_DECAP) ?
 -		MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 -			     inner_headers) :
 -		MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 -			     outer_headers);
 -}
 -
 -static void *get_match_headers_value(u32 flags,
 -				     struct mlx5_flow_spec *spec)
 -{
 -	return (flags & MLX5_FLOW_CONTEXT_ACTION_DECAP) ?
 -		MLX5_ADDR_OF(fte_match_param, spec->match_value,
 -			     inner_headers) :
 -		MLX5_ADDR_OF(fte_match_param, spec->match_value,
 -			     outer_headers);
 -}
 -
  static int __parse_cls_flower(struct mlx5e_priv *priv,
  			      struct mlx5_flow_spec *spec,
- 			      struct tc_cls_flower_offload *f,
+ 			      struct flow_cls_offload *f,
  			      struct net_device *filter_dev,
  			      u8 *match_level, u8 *tunnel_match_level)
  {
diff --cc drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c
index 15f804453cd6,202e9a246019..000000000000
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c
@@@ -120,8 -120,51 +120,54 @@@ static int mlxsw_sp_flower_parse_action
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static int mlxsw_sp_flower_parse_meta(struct mlxsw_sp_acl_rule_info *rulei,
+ 				      struct flow_cls_offload *f,
+ 				      struct mlxsw_sp_acl_block *block)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(f);
+ 	struct mlxsw_sp_port *mlxsw_sp_port;
+ 	struct net_device *ingress_dev;
+ 	struct flow_match_meta match;
+ 
+ 	if (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_META))
+ 		return 0;
+ 
+ 	flow_rule_match_meta(rule, &match);
+ 	if (match.mask->ingress_ifindex != 0xFFFFFFFF) {
+ 		NL_SET_ERR_MSG_MOD(f->common.extack, "Unsupported ingress ifindex mask");
+ 		return -EINVAL;
+ 	}
+ 
+ 	ingress_dev = __dev_get_by_index(block->net,
+ 					 match.key->ingress_ifindex);
+ 	if (!ingress_dev) {
+ 		NL_SET_ERR_MSG_MOD(f->common.extack, "Can't find specified ingress port to match on");
+ 		return -EINVAL;
+ 	}
+ 
+ 	if (!mlxsw_sp_port_dev_check(ingress_dev)) {
+ 		NL_SET_ERR_MSG_MOD(f->common.extack, "Can't match on non-mlxsw ingress port");
+ 		return -EINVAL;
+ 	}
+ 
+ 	mlxsw_sp_port = netdev_priv(ingress_dev);
+ 	if (mlxsw_sp_port->mlxsw_sp != block->mlxsw_sp) {
+ 		NL_SET_ERR_MSG_MOD(f->common.extack, "Can't match on a port from different device");
+ 		return -EINVAL;
+ 	}
+ 
+ 	mlxsw_sp_acl_rulei_keymask_u32(rulei,
+ 				       MLXSW_AFK_ELEMENT_SRC_SYS_PORT,
+ 				       mlxsw_sp_port->local_port,
+ 				       0xFFFFFFFF);
+ 	return 0;
+ }
+ 
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  static void mlxsw_sp_flower_parse_ipv4(struct mlxsw_sp_acl_rule_info *rulei,
- 				       struct tc_cls_flower_offload *f)
+ 				       struct flow_cls_offload *f)
  {
  	struct flow_match_ipv4_addrs match;
  
diff --cc drivers/net/ethernet/netronome/nfp/flower/action.c
index fb9dfbd7a0f5,5a54fe848de4..000000000000
--- a/drivers/net/ethernet/netronome/nfp/flower/action.c
+++ b/drivers/net/ethernet/netronome/nfp/flower/action.c
@@@ -152,9 -170,26 +152,32 @@@ nfp_fl_output(struct nfp_app *app, stru
  	return 0;
  }
  
++<<<<<<< HEAD
 +static enum nfp_flower_tun_type
 +nfp_fl_get_tun_from_act_l4_port(struct nfp_app *app,
 +				const struct flow_action_entry *act)
++=======
+ static bool
+ nfp_flower_tun_is_gre(struct flow_cls_offload *flow, int start_idx)
+ {
+ 	struct flow_action_entry *act = flow->rule->action.entries;
+ 	int num_act = flow->rule->action.num_entries;
+ 	int act_idx;
+ 
+ 	/* Preparse action list for next mirred or redirect action */
+ 	for (act_idx = start_idx + 1; act_idx < num_act; act_idx++)
+ 		if (act[act_idx].id == FLOW_ACTION_REDIRECT ||
+ 		    act[act_idx].id == FLOW_ACTION_MIRRED)
+ 			return netif_is_gretap(act[act_idx].dev);
+ 
+ 	return false;
+ }
+ 
+ static enum nfp_flower_tun_type
+ nfp_fl_get_tun_from_act(struct nfp_app *app,
+ 			struct flow_cls_offload *flow,
+ 			const struct flow_action_entry *act, int act_idx)
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  {
  	const struct ip_tunnel_info *tun = act->tunnel;
  	struct nfp_flower_priv *priv = app->priv;
@@@ -592,50 -664,18 +615,61 @@@ nfp_fl_pedit(const struct flow_action_e
  	struct nfp_fl_set_ipv6_tc_hl_fl set_ip6_tc_hl_fl;
  	struct nfp_fl_set_ip4_ttl_tos set_ip_ttl_tos;
  	struct nfp_fl_set_ip4_addrs set_ip_addr;
 +	enum flow_action_mangle_base htype;
  	struct nfp_fl_set_tport set_tport;
  	struct nfp_fl_set_eth set_eth;
++<<<<<<< HEAD
++=======
+ };
+ 
+ static int
+ nfp_fl_commit_mangle(struct flow_cls_offload *flow, char *nfp_action,
+ 		     int *a_len, struct nfp_flower_pedit_acts *set_act,
+ 		     u32 *csum_updated)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(flow);
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  	size_t act_size = 0;
  	u8 ip_proto = 0;
 +	u32 offset;
 +	int err;
 +
 +	memset(&set_ip6_tc_hl_fl, 0, sizeof(set_ip6_tc_hl_fl));
 +	memset(&set_ip_ttl_tos, 0, sizeof(set_ip_ttl_tos));
 +	memset(&set_ip6_dst, 0, sizeof(set_ip6_dst));
 +	memset(&set_ip6_src, 0, sizeof(set_ip6_src));
 +	memset(&set_ip_addr, 0, sizeof(set_ip_addr));
 +	memset(&set_tport, 0, sizeof(set_tport));
 +	memset(&set_eth, 0, sizeof(set_eth));
 +
 +	htype = act->mangle.htype;
 +	offset = act->mangle.offset;
 +
 +	switch (htype) {
 +	case TCA_PEDIT_KEY_EX_HDR_TYPE_ETH:
 +		err = nfp_fl_set_eth(act, offset, &set_eth);
 +		break;
 +	case TCA_PEDIT_KEY_EX_HDR_TYPE_IP4:
 +		err = nfp_fl_set_ip4(act, offset, &set_ip_addr,
 +				     &set_ip_ttl_tos);
 +		break;
 +	case TCA_PEDIT_KEY_EX_HDR_TYPE_IP6:
 +		err = nfp_fl_set_ip6(act, offset, &set_ip6_dst,
 +				     &set_ip6_src, &set_ip6_tc_hl_fl);
 +		break;
 +	case TCA_PEDIT_KEY_EX_HDR_TYPE_TCP:
 +		err = nfp_fl_set_tport(act, offset, &set_tport,
 +				       NFP_FL_ACTION_OPCODE_SET_TCP);
 +		break;
 +	case TCA_PEDIT_KEY_EX_HDR_TYPE_UDP:
 +		err = nfp_fl_set_tport(act, offset, &set_tport,
 +				       NFP_FL_ACTION_OPCODE_SET_UDP);
 +		break;
 +	default:
 +		return -EOPNOTSUPP;
 +	}
 +	if (err)
 +		return err;
  
  	if (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_BASIC)) {
  		struct flow_match_basic match;
@@@ -725,7 -770,42 +759,46 @@@
  }
  
  static int
++<<<<<<< HEAD
 +nfp_flower_output_action(struct nfp_app *app, const struct flow_action_entry *act,
++=======
+ nfp_fl_pedit(const struct flow_action_entry *act,
+ 	     struct flow_cls_offload *flow, char *nfp_action, int *a_len,
+ 	     u32 *csum_updated, struct nfp_flower_pedit_acts *set_act,
+ 	     struct netlink_ext_ack *extack)
+ {
+ 	enum flow_action_mangle_base htype;
+ 	u32 offset;
+ 
+ 	htype = act->mangle.htype;
+ 	offset = act->mangle.offset;
+ 
+ 	switch (htype) {
+ 	case TCA_PEDIT_KEY_EX_HDR_TYPE_ETH:
+ 		return nfp_fl_set_eth(act, offset, &set_act->set_eth, extack);
+ 	case TCA_PEDIT_KEY_EX_HDR_TYPE_IP4:
+ 		return nfp_fl_set_ip4(act, offset, &set_act->set_ip_addr,
+ 				      &set_act->set_ip_ttl_tos, extack);
+ 	case TCA_PEDIT_KEY_EX_HDR_TYPE_IP6:
+ 		return nfp_fl_set_ip6(act, offset, &set_act->set_ip6_dst,
+ 				      &set_act->set_ip6_src,
+ 				      &set_act->set_ip6_tc_hl_fl, extack);
+ 	case TCA_PEDIT_KEY_EX_HDR_TYPE_TCP:
+ 		return nfp_fl_set_tport(act, offset, &set_act->set_tport,
+ 					NFP_FL_ACTION_OPCODE_SET_TCP, extack);
+ 	case TCA_PEDIT_KEY_EX_HDR_TYPE_UDP:
+ 		return nfp_fl_set_tport(act, offset, &set_act->set_tport,
+ 					NFP_FL_ACTION_OPCODE_SET_UDP, extack);
+ 	default:
+ 		NL_SET_ERR_MSG_MOD(extack, "unsupported offload: pedit on unsupported header");
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int
+ nfp_flower_output_action(struct nfp_app *app,
+ 			 const struct flow_action_entry *act,
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  			 struct nfp_fl_payload *nfp_fl, int *a_len,
  			 struct net_device *netdev, bool last,
  			 enum nfp_flower_tun_type *tun_type, int *tun_out_cnt,
@@@ -880,12 -984,50 +953,12 @@@ nfp_flower_loop_action(struct nfp_app *
  	return 0;
  }
  
 -static bool nfp_fl_check_mangle_start(struct flow_action *flow_act,
 -				      int current_act_idx)
 -{
 -	struct flow_action_entry current_act;
 -	struct flow_action_entry prev_act;
 -
 -	current_act = flow_act->entries[current_act_idx];
 -	if (current_act.id != FLOW_ACTION_MANGLE)
 -		return false;
 -
 -	if (current_act_idx == 0)
 -		return true;
 -
 -	prev_act = flow_act->entries[current_act_idx - 1];
 -
 -	return prev_act.id != FLOW_ACTION_MANGLE;
 -}
 -
 -static bool nfp_fl_check_mangle_end(struct flow_action *flow_act,
 -				    int current_act_idx)
 -{
 -	struct flow_action_entry current_act;
 -	struct flow_action_entry next_act;
 -
 -	current_act = flow_act->entries[current_act_idx];
 -	if (current_act.id != FLOW_ACTION_MANGLE)
 -		return false;
 -
 -	if (current_act_idx == flow_act->num_entries)
 -		return true;
 -
 -	next_act = flow_act->entries[current_act_idx + 1];
 -
 -	return next_act.id != FLOW_ACTION_MANGLE;
 -}
 -
  int nfp_flower_compile_action(struct nfp_app *app,
- 			      struct tc_cls_flower_offload *flow,
+ 			      struct flow_cls_offload *flow,
  			      struct net_device *netdev,
 -			      struct nfp_fl_payload *nfp_flow,
 -			      struct netlink_ext_ack *extack)
 +			      struct nfp_fl_payload *nfp_flow)
  {
  	int act_len, act_cnt, err, tun_out_cnt, out_cnt, i;
 -	struct nfp_flower_pedit_acts set_act;
  	enum nfp_flower_tun_type tun_type;
  	struct flow_action_entry *act;
  	u32 csum_updated = 0;
diff --cc drivers/net/ethernet/netronome/nfp/flower/match.c
index 9b8b843d0340,9cc3ba17ff69..000000000000
--- a/drivers/net/ethernet/netronome/nfp/flower/match.c
+++ b/drivers/net/ethernet/netronome/nfp/flower/match.c
@@@ -278,11 -281,76 +278,79 @@@ nfp_flower_compile_geneve_opt(void *ext
  }
  
  static void
++<<<<<<< HEAD
++=======
+ nfp_flower_compile_tun_ipv4_addrs(struct nfp_flower_tun_ipv4 *ext,
+ 				  struct nfp_flower_tun_ipv4 *msk,
+ 				  struct flow_cls_offload *flow)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(flow);
+ 
+ 	if (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ENC_IPV4_ADDRS)) {
+ 		struct flow_match_ipv4_addrs match;
+ 
+ 		flow_rule_match_enc_ipv4_addrs(rule, &match);
+ 		ext->src = match.key->src;
+ 		ext->dst = match.key->dst;
+ 		msk->src = match.mask->src;
+ 		msk->dst = match.mask->dst;
+ 	}
+ }
+ 
+ static void
+ nfp_flower_compile_tun_ip_ext(struct nfp_flower_tun_ip_ext *ext,
+ 			      struct nfp_flower_tun_ip_ext *msk,
+ 			      struct flow_cls_offload *flow)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(flow);
+ 
+ 	if (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ENC_IP)) {
+ 		struct flow_match_ip match;
+ 
+ 		flow_rule_match_enc_ip(rule, &match);
+ 		ext->tos = match.key->tos;
+ 		ext->ttl = match.key->ttl;
+ 		msk->tos = match.mask->tos;
+ 		msk->ttl = match.mask->ttl;
+ 	}
+ }
+ 
+ static void
+ nfp_flower_compile_ipv4_gre_tun(struct nfp_flower_ipv4_gre_tun *ext,
+ 				struct nfp_flower_ipv4_gre_tun *msk,
+ 				struct flow_cls_offload *flow)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(flow);
+ 
+ 	memset(ext, 0, sizeof(struct nfp_flower_ipv4_gre_tun));
+ 	memset(msk, 0, sizeof(struct nfp_flower_ipv4_gre_tun));
+ 
+ 	/* NVGRE is the only supported GRE tunnel type */
+ 	ext->ethertype = cpu_to_be16(ETH_P_TEB);
+ 	msk->ethertype = cpu_to_be16(~0);
+ 
+ 	if (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ENC_KEYID)) {
+ 		struct flow_match_enc_keyid match;
+ 
+ 		flow_rule_match_enc_keyid(rule, &match);
+ 		ext->tun_key = match.key->keyid;
+ 		msk->tun_key = match.mask->keyid;
+ 
+ 		ext->tun_flags = cpu_to_be16(NFP_FL_GRE_FLAG_KEY);
+ 		msk->tun_flags = cpu_to_be16(NFP_FL_GRE_FLAG_KEY);
+ 	}
+ 
+ 	nfp_flower_compile_tun_ipv4_addrs(&ext->ipv4, &msk->ipv4, flow);
+ 	nfp_flower_compile_tun_ip_ext(&ext->ip_ext, &msk->ip_ext, flow);
+ }
+ 
+ static void
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  nfp_flower_compile_ipv4_udp_tun(struct nfp_flower_ipv4_udp_tun *ext,
  				struct nfp_flower_ipv4_udp_tun *msk,
- 				struct tc_cls_flower_offload *flow)
+ 				struct flow_cls_offload *flow)
  {
- 	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(flow);
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(flow);
  
  	memset(ext, 0, sizeof(struct nfp_flower_ipv4_udp_tun));
  	memset(msk, 0, sizeof(struct nfp_flower_ipv4_udp_tun));
diff --cc drivers/net/ethernet/netronome/nfp/flower/offload.c
index bdd551f36cb7,7e725fa60347..000000000000
--- a/drivers/net/ethernet/netronome/nfp/flower/offload.c
+++ b/drivers/net/ethernet/netronome/nfp/flower/offload.c
@@@ -110,14 -131,25 +110,25 @@@ static bool nfp_flower_check_higher_tha
  	       flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ICMP);
  }
  
++<<<<<<< HEAD
++=======
+ static bool nfp_flower_check_higher_than_l3(struct flow_cls_offload *f)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(f);
+ 
+ 	return flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS) ||
+ 	       flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ICMP);
+ }
+ 
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  static int
 -nfp_flower_calc_opt_layer(struct flow_dissector_key_enc_opts *enc_opts,
 -			  u32 *key_layer_two, int *key_size,
 -			  struct netlink_ext_ack *extack)
 +nfp_flower_calc_opt_layer(struct flow_match_enc_opts *enc_opts,
 +			  u32 *key_layer_two, int *key_size)
  {
 -	if (enc_opts->len > NFP_FL_MAX_GENEVE_OPT_KEY) {
 -		NL_SET_ERR_MSG_MOD(extack, "unsupported offload: geneve options exceed maximum length");
 +	if (enc_opts->key->len > NFP_FL_MAX_GENEVE_OPT_KEY)
  		return -EOPNOTSUPP;
 -	}
  
 -	if (enc_opts->len > 0) {
 +	if (enc_opts->key->len > 0) {
  		*key_layer_two |= NFP_FLOWER_LAYER2_GENEVE_OP;
  		*key_size += sizeof(struct nfp_flower_geneve_options);
  	}
@@@ -129,10 -212,11 +140,16 @@@ static in
  nfp_flower_calculate_key_layers(struct nfp_app *app,
  				struct net_device *netdev,
  				struct nfp_fl_key_ls *ret_key_ls,
++<<<<<<< HEAD
 +				struct tc_cls_flower_offload *flow,
 +				enum nfp_flower_tun_type *tun_type)
++=======
+ 				struct flow_cls_offload *flow,
+ 				enum nfp_flower_tun_type *tun_type,
+ 				struct netlink_ext_ack *extack)
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  {
- 	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(flow);
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(flow);
  	struct flow_dissector *dissector = rule->match.dissector;
  	struct flow_match_basic basic = { NULL, NULL};
  	struct nfp_flower_priv *priv = app->priv;
@@@ -388,6 -507,449 +405,452 @@@ err_free_flow
  	return NULL;
  }
  
++<<<<<<< HEAD
++=======
+ static int
+ nfp_flower_update_merge_with_actions(struct nfp_fl_payload *flow,
+ 				     struct nfp_flower_merge_check *merge,
+ 				     u8 *last_act_id, int *act_out)
+ {
+ 	struct nfp_fl_set_ipv6_tc_hl_fl *ipv6_tc_hl_fl;
+ 	struct nfp_fl_set_ip4_ttl_tos *ipv4_ttl_tos;
+ 	struct nfp_fl_set_ip4_addrs *ipv4_add;
+ 	struct nfp_fl_set_ipv6_addr *ipv6_add;
+ 	struct nfp_fl_push_vlan *push_vlan;
+ 	struct nfp_fl_set_tport *tport;
+ 	struct nfp_fl_set_eth *eth;
+ 	struct nfp_fl_act_head *a;
+ 	unsigned int act_off = 0;
+ 	u8 act_id = 0;
+ 	u8 *ports;
+ 	int i;
+ 
+ 	while (act_off < flow->meta.act_len) {
+ 		a = (struct nfp_fl_act_head *)&flow->action_data[act_off];
+ 		act_id = a->jump_id;
+ 
+ 		switch (act_id) {
+ 		case NFP_FL_ACTION_OPCODE_OUTPUT:
+ 			if (act_out)
+ 				(*act_out)++;
+ 			break;
+ 		case NFP_FL_ACTION_OPCODE_PUSH_VLAN:
+ 			push_vlan = (struct nfp_fl_push_vlan *)a;
+ 			if (push_vlan->vlan_tci)
+ 				merge->tci = cpu_to_be16(0xffff);
+ 			break;
+ 		case NFP_FL_ACTION_OPCODE_POP_VLAN:
+ 			merge->tci = cpu_to_be16(0);
+ 			break;
+ 		case NFP_FL_ACTION_OPCODE_SET_IPV4_TUNNEL:
+ 			/* New tunnel header means l2 to l4 can be matched. */
+ 			eth_broadcast_addr(&merge->l2.mac_dst[0]);
+ 			eth_broadcast_addr(&merge->l2.mac_src[0]);
+ 			memset(&merge->l4, 0xff,
+ 			       sizeof(struct nfp_flower_tp_ports));
+ 			memset(&merge->ipv4, 0xff,
+ 			       sizeof(struct nfp_flower_ipv4));
+ 			break;
+ 		case NFP_FL_ACTION_OPCODE_SET_ETHERNET:
+ 			eth = (struct nfp_fl_set_eth *)a;
+ 			for (i = 0; i < ETH_ALEN; i++)
+ 				merge->l2.mac_dst[i] |= eth->eth_addr_mask[i];
+ 			for (i = 0; i < ETH_ALEN; i++)
+ 				merge->l2.mac_src[i] |=
+ 					eth->eth_addr_mask[ETH_ALEN + i];
+ 			break;
+ 		case NFP_FL_ACTION_OPCODE_SET_IPV4_ADDRS:
+ 			ipv4_add = (struct nfp_fl_set_ip4_addrs *)a;
+ 			merge->ipv4.ipv4_src |= ipv4_add->ipv4_src_mask;
+ 			merge->ipv4.ipv4_dst |= ipv4_add->ipv4_dst_mask;
+ 			break;
+ 		case NFP_FL_ACTION_OPCODE_SET_IPV4_TTL_TOS:
+ 			ipv4_ttl_tos = (struct nfp_fl_set_ip4_ttl_tos *)a;
+ 			merge->ipv4.ip_ext.ttl |= ipv4_ttl_tos->ipv4_ttl_mask;
+ 			merge->ipv4.ip_ext.tos |= ipv4_ttl_tos->ipv4_tos_mask;
+ 			break;
+ 		case NFP_FL_ACTION_OPCODE_SET_IPV6_SRC:
+ 			ipv6_add = (struct nfp_fl_set_ipv6_addr *)a;
+ 			for (i = 0; i < 4; i++)
+ 				merge->ipv6.ipv6_src.in6_u.u6_addr32[i] |=
+ 					ipv6_add->ipv6[i].mask;
+ 			break;
+ 		case NFP_FL_ACTION_OPCODE_SET_IPV6_DST:
+ 			ipv6_add = (struct nfp_fl_set_ipv6_addr *)a;
+ 			for (i = 0; i < 4; i++)
+ 				merge->ipv6.ipv6_dst.in6_u.u6_addr32[i] |=
+ 					ipv6_add->ipv6[i].mask;
+ 			break;
+ 		case NFP_FL_ACTION_OPCODE_SET_IPV6_TC_HL_FL:
+ 			ipv6_tc_hl_fl = (struct nfp_fl_set_ipv6_tc_hl_fl *)a;
+ 			merge->ipv6.ip_ext.ttl |=
+ 				ipv6_tc_hl_fl->ipv6_hop_limit_mask;
+ 			merge->ipv6.ip_ext.tos |= ipv6_tc_hl_fl->ipv6_tc_mask;
+ 			merge->ipv6.ipv6_flow_label_exthdr |=
+ 				ipv6_tc_hl_fl->ipv6_label_mask;
+ 			break;
+ 		case NFP_FL_ACTION_OPCODE_SET_UDP:
+ 		case NFP_FL_ACTION_OPCODE_SET_TCP:
+ 			tport = (struct nfp_fl_set_tport *)a;
+ 			ports = (u8 *)&merge->l4.port_src;
+ 			for (i = 0; i < 4; i++)
+ 				ports[i] |= tport->tp_port_mask[i];
+ 			break;
+ 		case NFP_FL_ACTION_OPCODE_PRE_TUNNEL:
+ 		case NFP_FL_ACTION_OPCODE_PRE_LAG:
+ 		case NFP_FL_ACTION_OPCODE_PUSH_GENEVE:
+ 			break;
+ 		default:
+ 			return -EOPNOTSUPP;
+ 		}
+ 
+ 		act_off += a->len_lw << NFP_FL_LW_SIZ;
+ 	}
+ 
+ 	if (last_act_id)
+ 		*last_act_id = act_id;
+ 
+ 	return 0;
+ }
+ 
+ static int
+ nfp_flower_populate_merge_match(struct nfp_fl_payload *flow,
+ 				struct nfp_flower_merge_check *merge,
+ 				bool extra_fields)
+ {
+ 	struct nfp_flower_meta_tci *meta_tci;
+ 	u8 *mask = flow->mask_data;
+ 	u8 key_layer, match_size;
+ 
+ 	memset(merge, 0, sizeof(struct nfp_flower_merge_check));
+ 
+ 	meta_tci = (struct nfp_flower_meta_tci *)mask;
+ 	key_layer = meta_tci->nfp_flow_key_layer;
+ 
+ 	if (key_layer & ~NFP_FLOWER_MERGE_FIELDS && !extra_fields)
+ 		return -EOPNOTSUPP;
+ 
+ 	merge->tci = meta_tci->tci;
+ 	mask += sizeof(struct nfp_flower_meta_tci);
+ 
+ 	if (key_layer & NFP_FLOWER_LAYER_EXT_META)
+ 		mask += sizeof(struct nfp_flower_ext_meta);
+ 
+ 	mask += sizeof(struct nfp_flower_in_port);
+ 
+ 	if (key_layer & NFP_FLOWER_LAYER_MAC) {
+ 		match_size = sizeof(struct nfp_flower_mac_mpls);
+ 		memcpy(&merge->l2, mask, match_size);
+ 		mask += match_size;
+ 	}
+ 
+ 	if (key_layer & NFP_FLOWER_LAYER_TP) {
+ 		match_size = sizeof(struct nfp_flower_tp_ports);
+ 		memcpy(&merge->l4, mask, match_size);
+ 		mask += match_size;
+ 	}
+ 
+ 	if (key_layer & NFP_FLOWER_LAYER_IPV4) {
+ 		match_size = sizeof(struct nfp_flower_ipv4);
+ 		memcpy(&merge->ipv4, mask, match_size);
+ 	}
+ 
+ 	if (key_layer & NFP_FLOWER_LAYER_IPV6) {
+ 		match_size = sizeof(struct nfp_flower_ipv6);
+ 		memcpy(&merge->ipv6, mask, match_size);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int
+ nfp_flower_can_merge(struct nfp_fl_payload *sub_flow1,
+ 		     struct nfp_fl_payload *sub_flow2)
+ {
+ 	/* Two flows can be merged if sub_flow2 only matches on bits that are
+ 	 * either matched by sub_flow1 or set by a sub_flow1 action. This
+ 	 * ensures that every packet that hits sub_flow1 and recirculates is
+ 	 * guaranteed to hit sub_flow2.
+ 	 */
+ 	struct nfp_flower_merge_check sub_flow1_merge, sub_flow2_merge;
+ 	int err, act_out = 0;
+ 	u8 last_act_id = 0;
+ 
+ 	err = nfp_flower_populate_merge_match(sub_flow1, &sub_flow1_merge,
+ 					      true);
+ 	if (err)
+ 		return err;
+ 
+ 	err = nfp_flower_populate_merge_match(sub_flow2, &sub_flow2_merge,
+ 					      false);
+ 	if (err)
+ 		return err;
+ 
+ 	err = nfp_flower_update_merge_with_actions(sub_flow1, &sub_flow1_merge,
+ 						   &last_act_id, &act_out);
+ 	if (err)
+ 		return err;
+ 
+ 	/* Must only be 1 output action and it must be the last in sequence. */
+ 	if (act_out != 1 || last_act_id != NFP_FL_ACTION_OPCODE_OUTPUT)
+ 		return -EOPNOTSUPP;
+ 
+ 	/* Reject merge if sub_flow2 matches on something that is not matched
+ 	 * on or set in an action by sub_flow1.
+ 	 */
+ 	err = bitmap_andnot(sub_flow2_merge.vals, sub_flow2_merge.vals,
+ 			    sub_flow1_merge.vals,
+ 			    sizeof(struct nfp_flower_merge_check) * 8);
+ 	if (err)
+ 		return -EINVAL;
+ 
+ 	return 0;
+ }
+ 
+ static unsigned int
+ nfp_flower_copy_pre_actions(char *act_dst, char *act_src, int len,
+ 			    bool *tunnel_act)
+ {
+ 	unsigned int act_off = 0, act_len;
+ 	struct nfp_fl_act_head *a;
+ 	u8 act_id = 0;
+ 
+ 	while (act_off < len) {
+ 		a = (struct nfp_fl_act_head *)&act_src[act_off];
+ 		act_len = a->len_lw << NFP_FL_LW_SIZ;
+ 		act_id = a->jump_id;
+ 
+ 		switch (act_id) {
+ 		case NFP_FL_ACTION_OPCODE_PRE_TUNNEL:
+ 			if (tunnel_act)
+ 				*tunnel_act = true;
+ 			/* fall through */
+ 		case NFP_FL_ACTION_OPCODE_PRE_LAG:
+ 			memcpy(act_dst + act_off, act_src + act_off, act_len);
+ 			break;
+ 		default:
+ 			return act_off;
+ 		}
+ 
+ 		act_off += act_len;
+ 	}
+ 
+ 	return act_off;
+ }
+ 
+ static int nfp_fl_verify_post_tun_acts(char *acts, int len)
+ {
+ 	struct nfp_fl_act_head *a;
+ 	unsigned int act_off = 0;
+ 
+ 	while (act_off < len) {
+ 		a = (struct nfp_fl_act_head *)&acts[act_off];
+ 		if (a->jump_id != NFP_FL_ACTION_OPCODE_OUTPUT)
+ 			return -EOPNOTSUPP;
+ 
+ 		act_off += a->len_lw << NFP_FL_LW_SIZ;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int
+ nfp_flower_merge_action(struct nfp_fl_payload *sub_flow1,
+ 			struct nfp_fl_payload *sub_flow2,
+ 			struct nfp_fl_payload *merge_flow)
+ {
+ 	unsigned int sub1_act_len, sub2_act_len, pre_off1, pre_off2;
+ 	bool tunnel_act = false;
+ 	char *merge_act;
+ 	int err;
+ 
+ 	/* The last action of sub_flow1 must be output - do not merge this. */
+ 	sub1_act_len = sub_flow1->meta.act_len - sizeof(struct nfp_fl_output);
+ 	sub2_act_len = sub_flow2->meta.act_len;
+ 
+ 	if (!sub2_act_len)
+ 		return -EINVAL;
+ 
+ 	if (sub1_act_len + sub2_act_len > NFP_FL_MAX_A_SIZ)
+ 		return -EINVAL;
+ 
+ 	/* A shortcut can only be applied if there is a single action. */
+ 	if (sub1_act_len)
+ 		merge_flow->meta.shortcut = cpu_to_be32(NFP_FL_SC_ACT_NULL);
+ 	else
+ 		merge_flow->meta.shortcut = sub_flow2->meta.shortcut;
+ 
+ 	merge_flow->meta.act_len = sub1_act_len + sub2_act_len;
+ 	merge_act = merge_flow->action_data;
+ 
+ 	/* Copy any pre-actions to the start of merge flow action list. */
+ 	pre_off1 = nfp_flower_copy_pre_actions(merge_act,
+ 					       sub_flow1->action_data,
+ 					       sub1_act_len, &tunnel_act);
+ 	merge_act += pre_off1;
+ 	sub1_act_len -= pre_off1;
+ 	pre_off2 = nfp_flower_copy_pre_actions(merge_act,
+ 					       sub_flow2->action_data,
+ 					       sub2_act_len, NULL);
+ 	merge_act += pre_off2;
+ 	sub2_act_len -= pre_off2;
+ 
+ 	/* FW does a tunnel push when egressing, therefore, if sub_flow 1 pushes
+ 	 * a tunnel, sub_flow 2 can only have output actions for a valid merge.
+ 	 */
+ 	if (tunnel_act) {
+ 		char *post_tun_acts = &sub_flow2->action_data[pre_off2];
+ 
+ 		err = nfp_fl_verify_post_tun_acts(post_tun_acts, sub2_act_len);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	/* Copy remaining actions from sub_flows 1 and 2. */
+ 	memcpy(merge_act, sub_flow1->action_data + pre_off1, sub1_act_len);
+ 	merge_act += sub1_act_len;
+ 	memcpy(merge_act, sub_flow2->action_data + pre_off2, sub2_act_len);
+ 
+ 	return 0;
+ }
+ 
+ /* Flow link code should only be accessed under RTNL. */
+ static void nfp_flower_unlink_flow(struct nfp_fl_payload_link *link)
+ {
+ 	list_del(&link->merge_flow.list);
+ 	list_del(&link->sub_flow.list);
+ 	kfree(link);
+ }
+ 
+ static void nfp_flower_unlink_flows(struct nfp_fl_payload *merge_flow,
+ 				    struct nfp_fl_payload *sub_flow)
+ {
+ 	struct nfp_fl_payload_link *link;
+ 
+ 	list_for_each_entry(link, &merge_flow->linked_flows, merge_flow.list)
+ 		if (link->sub_flow.flow == sub_flow) {
+ 			nfp_flower_unlink_flow(link);
+ 			return;
+ 		}
+ }
+ 
+ static int nfp_flower_link_flows(struct nfp_fl_payload *merge_flow,
+ 				 struct nfp_fl_payload *sub_flow)
+ {
+ 	struct nfp_fl_payload_link *link;
+ 
+ 	link = kmalloc(sizeof(*link), GFP_KERNEL);
+ 	if (!link)
+ 		return -ENOMEM;
+ 
+ 	link->merge_flow.flow = merge_flow;
+ 	list_add_tail(&link->merge_flow.list, &merge_flow->linked_flows);
+ 	link->sub_flow.flow = sub_flow;
+ 	list_add_tail(&link->sub_flow.list, &sub_flow->linked_flows);
+ 
+ 	return 0;
+ }
+ 
+ /**
+  * nfp_flower_merge_offloaded_flows() - Merge 2 existing flows to single flow.
+  * @app:	Pointer to the APP handle
+  * @sub_flow1:	Initial flow matched to produce merge hint
+  * @sub_flow2:	Post recirculation flow matched in merge hint
+  *
+  * Combines 2 flows (if valid) to a single flow, removing the initial from hw
+  * and offloading the new, merged flow.
+  *
+  * Return: negative value on error, 0 in success.
+  */
+ int nfp_flower_merge_offloaded_flows(struct nfp_app *app,
+ 				     struct nfp_fl_payload *sub_flow1,
+ 				     struct nfp_fl_payload *sub_flow2)
+ {
+ 	struct flow_cls_offload merge_tc_off;
+ 	struct nfp_flower_priv *priv = app->priv;
+ 	struct netlink_ext_ack *extack = NULL;
+ 	struct nfp_fl_payload *merge_flow;
+ 	struct nfp_fl_key_ls merge_key_ls;
+ 	int err;
+ 
+ 	ASSERT_RTNL();
+ 
+ 	extack = merge_tc_off.common.extack;
+ 	if (sub_flow1 == sub_flow2 ||
+ 	    nfp_flower_is_merge_flow(sub_flow1) ||
+ 	    nfp_flower_is_merge_flow(sub_flow2))
+ 		return -EINVAL;
+ 
+ 	err = nfp_flower_can_merge(sub_flow1, sub_flow2);
+ 	if (err)
+ 		return err;
+ 
+ 	merge_key_ls.key_size = sub_flow1->meta.key_len;
+ 
+ 	merge_flow = nfp_flower_allocate_new(&merge_key_ls);
+ 	if (!merge_flow)
+ 		return -ENOMEM;
+ 
+ 	merge_flow->tc_flower_cookie = (unsigned long)merge_flow;
+ 	merge_flow->ingress_dev = sub_flow1->ingress_dev;
+ 
+ 	memcpy(merge_flow->unmasked_data, sub_flow1->unmasked_data,
+ 	       sub_flow1->meta.key_len);
+ 	memcpy(merge_flow->mask_data, sub_flow1->mask_data,
+ 	       sub_flow1->meta.mask_len);
+ 
+ 	err = nfp_flower_merge_action(sub_flow1, sub_flow2, merge_flow);
+ 	if (err)
+ 		goto err_destroy_merge_flow;
+ 
+ 	err = nfp_flower_link_flows(merge_flow, sub_flow1);
+ 	if (err)
+ 		goto err_destroy_merge_flow;
+ 
+ 	err = nfp_flower_link_flows(merge_flow, sub_flow2);
+ 	if (err)
+ 		goto err_unlink_sub_flow1;
+ 
+ 	merge_tc_off.cookie = merge_flow->tc_flower_cookie;
+ 	err = nfp_compile_flow_metadata(app, &merge_tc_off, merge_flow,
+ 					merge_flow->ingress_dev, extack);
+ 	if (err)
+ 		goto err_unlink_sub_flow2;
+ 
+ 	err = rhashtable_insert_fast(&priv->flow_table, &merge_flow->fl_node,
+ 				     nfp_flower_table_params);
+ 	if (err)
+ 		goto err_release_metadata;
+ 
+ 	err = nfp_flower_xmit_flow(app, merge_flow,
+ 				   NFP_FLOWER_CMSG_TYPE_FLOW_MOD);
+ 	if (err)
+ 		goto err_remove_rhash;
+ 
+ 	merge_flow->in_hw = true;
+ 	sub_flow1->in_hw = false;
+ 
+ 	return 0;
+ 
+ err_remove_rhash:
+ 	WARN_ON_ONCE(rhashtable_remove_fast(&priv->flow_table,
+ 					    &merge_flow->fl_node,
+ 					    nfp_flower_table_params));
+ err_release_metadata:
+ 	nfp_modify_flow_metadata(app, merge_flow);
+ err_unlink_sub_flow2:
+ 	nfp_flower_unlink_flows(merge_flow, sub_flow2);
+ err_unlink_sub_flow1:
+ 	nfp_flower_unlink_flows(merge_flow, sub_flow1);
+ err_destroy_merge_flow:
+ 	kfree(merge_flow->action_data);
+ 	kfree(merge_flow->mask_data);
+ 	kfree(merge_flow->unmasked_data);
+ 	kfree(merge_flow);
+ 	return err;
+ }
+ 
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  /**
   * nfp_flower_add_offload() - Adds a new flow to hardware.
   * @app:	Pointer to the APP handle
@@@ -488,9 -1125,10 +951,9 @@@ err_free_key_ls
   */
  static int
  nfp_flower_del_offload(struct nfp_app *app, struct net_device *netdev,
- 		       struct tc_cls_flower_offload *flow)
+ 		       struct flow_cls_offload *flow)
  {
  	struct nfp_flower_priv *priv = app->priv;
 -	struct netlink_ext_ack *extack = NULL;
  	struct nfp_fl_payload *nfp_flow;
  	struct nfp_port *port = NULL;
  	int err;
@@@ -540,9 -1232,10 +1003,9 @@@ err_free_flow
   */
  static int
  nfp_flower_get_stats(struct nfp_app *app, struct net_device *netdev,
- 		     struct tc_cls_flower_offload *flow)
+ 		     struct flow_cls_offload *flow)
  {
  	struct nfp_flower_priv *priv = app->priv;
 -	struct netlink_ext_ack *extack = NULL;
  	struct nfp_fl_payload *nfp_flow;
  	u32 ctx_id;
  
diff --cc include/net/flow_offload.h
index 1f9db8aa6acb,db337299e81e..000000000000
--- a/include/net/flow_offload.h
+++ b/include/net/flow_offload.h
@@@ -231,4 -238,99 +231,102 @@@ static inline void flow_stats_update(st
  	flow_stats->lastused	= max_t(u64, flow_stats->lastused, lastused);
  }
  
++<<<<<<< HEAD
++=======
+ enum flow_block_command {
+ 	FLOW_BLOCK_BIND,
+ 	FLOW_BLOCK_UNBIND,
+ };
+ 
+ enum flow_block_binder_type {
+ 	FLOW_BLOCK_BINDER_TYPE_UNSPEC,
+ 	FLOW_BLOCK_BINDER_TYPE_CLSACT_INGRESS,
+ 	FLOW_BLOCK_BINDER_TYPE_CLSACT_EGRESS,
+ };
+ 
+ struct netlink_ext_ack;
+ 
+ struct flow_block_offload {
+ 	enum flow_block_command command;
+ 	enum flow_block_binder_type binder_type;
+ 	bool block_shared;
+ 	struct net *net;
+ 	struct list_head cb_list;
+ 	struct list_head *driver_block_list;
+ 	struct netlink_ext_ack *extack;
+ };
+ 
+ struct flow_block_cb {
+ 	struct list_head	driver_list;
+ 	struct list_head	list;
+ 	struct net		*net;
+ 	tc_setup_cb_t		*cb;
+ 	void			*cb_ident;
+ 	void			*cb_priv;
+ 	void			(*release)(void *cb_priv);
+ 	unsigned int		refcnt;
+ };
+ 
+ struct flow_block_cb *flow_block_cb_alloc(struct net *net, tc_setup_cb_t *cb,
+ 					  void *cb_ident, void *cb_priv,
+ 					  void (*release)(void *cb_priv));
+ void flow_block_cb_free(struct flow_block_cb *block_cb);
+ 
+ struct flow_block_cb *flow_block_cb_lookup(struct flow_block_offload *offload,
+ 					   tc_setup_cb_t *cb, void *cb_ident);
+ 
+ void *flow_block_cb_priv(struct flow_block_cb *block_cb);
+ void flow_block_cb_incref(struct flow_block_cb *block_cb);
+ unsigned int flow_block_cb_decref(struct flow_block_cb *block_cb);
+ 
+ static inline void flow_block_cb_add(struct flow_block_cb *block_cb,
+ 				     struct flow_block_offload *offload)
+ {
+ 	list_add_tail(&block_cb->list, &offload->cb_list);
+ }
+ 
+ static inline void flow_block_cb_remove(struct flow_block_cb *block_cb,
+ 					struct flow_block_offload *offload)
+ {
+ 	list_move(&block_cb->list, &offload->cb_list);
+ }
+ 
+ bool flow_block_cb_is_busy(tc_setup_cb_t *cb, void *cb_ident,
+ 			   struct list_head *driver_block_list);
+ 
+ int flow_block_cb_setup_simple(struct flow_block_offload *f,
+ 			       struct list_head *driver_list, tc_setup_cb_t *cb,
+ 			       void *cb_ident, void *cb_priv, bool ingress_only);
+ 
+ enum flow_cls_command {
+ 	FLOW_CLS_REPLACE,
+ 	FLOW_CLS_DESTROY,
+ 	FLOW_CLS_STATS,
+ 	FLOW_CLS_TMPLT_CREATE,
+ 	FLOW_CLS_TMPLT_DESTROY,
+ };
+ 
+ struct flow_cls_common_offload {
+ 	u32 chain_index;
+ 	__be16 protocol;
+ 	u32 prio;
+ 	struct netlink_ext_ack *extack;
+ };
+ 
+ struct flow_cls_offload {
+ 	struct flow_cls_common_offload common;
+ 	enum flow_cls_command command;
+ 	unsigned long cookie;
+ 	struct flow_rule *rule;
+ 	struct flow_stats stats;
+ 	u32 classid;
+ };
+ 
+ static inline struct flow_rule *
+ flow_cls_offload_flow_rule(struct flow_cls_offload *flow_cmd)
+ {
+ 	return flow_cmd->rule;
+ }
+ 
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  #endif /* _NET_FLOW_OFFLOAD_H */
diff --cc include/net/pkt_cls.h
index 835bbad70a4b,b03d466182db..000000000000
--- a/include/net/pkt_cls.h
+++ b/include/net/pkt_cls.h
@@@ -612,25 -535,6 +612,28 @@@ int tc_setup_cb_call(struct tcf_block *
  		     void *type_data, bool err_stop);
  unsigned int tcf_exts_num_actions(struct tcf_exts *exts);
  
++<<<<<<< HEAD
 +enum tc_block_command {
 +	TC_BLOCK_BIND,
 +	TC_BLOCK_UNBIND,
 +};
 +
 +struct tc_block_offload {
 +	enum tc_block_command command;
 +	enum tcf_block_binder_type binder_type;
 +	struct tcf_block *block;
 +	struct netlink_ext_ack *extack;
 +};
 +
 +struct tc_cls_common_offload {
 +	u32 chain_index;
 +	__be16 protocol;
 +	u32 prio;
 +	struct netlink_ext_ack *extack;
 +};
 +
++=======
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  struct tc_cls_u32_knode {
  	struct tcf_exts *exts;
  	struct tcf_result *res;
diff --cc net/sched/cls_flower.c
index 3eb4f57be10d,38d6e85693fc..000000000000
--- a/net/sched/cls_flower.c
+++ b/net/sched/cls_flower.c
@@@ -384,13 -407,16 +384,13 @@@ static void fl_destroy_filter_work(stru
  }
  
  static void fl_hw_destroy_filter(struct tcf_proto *tp, struct cls_fl_filter *f,
 -				 bool rtnl_held, struct netlink_ext_ack *extack)
 +				 struct netlink_ext_ack *extack)
  {
- 	struct tc_cls_flower_offload cls_flower = {};
  	struct tcf_block *block = tp->chain->block;
+ 	struct flow_cls_offload cls_flower = {};
  
 -	if (!rtnl_held)
 -		rtnl_lock();
 -
  	tc_cls_common_offload_init(&cls_flower.common, tp, f->flags, extack);
- 	cls_flower.command = TC_CLSFLOWER_DESTROY;
+ 	cls_flower.command = FLOW_CLS_DESTROY;
  	cls_flower.cookie = (unsigned long) f;
  
  	tc_setup_cb_call(block, TC_SETUP_CLSFLOWER, &cls_flower, false);
@@@ -398,20 -426,30 +398,25 @@@
  }
  
  static int fl_hw_replace_filter(struct tcf_proto *tp,
 -				struct cls_fl_filter *f, bool rtnl_held,
 +				struct cls_fl_filter *f,
  				struct netlink_ext_ack *extack)
  {
++<<<<<<< HEAD
 +	struct tc_cls_flower_offload cls_flower = {};
++=======
+ 	struct cls_fl_head *head = fl_head_dereference(tp);
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  	struct tcf_block *block = tp->chain->block;
+ 	struct flow_cls_offload cls_flower = {};
  	bool skip_sw = tc_skip_sw(f->flags);
 -	int err = 0;
 -
 -	if (!rtnl_held)
 -		rtnl_lock();
 +	int err;
  
  	cls_flower.rule = flow_rule_alloc(tcf_exts_num_actions(&f->exts));
 -	if (!cls_flower.rule) {
 -		err = -ENOMEM;
 -		goto errout;
 -	}
 +	if (!cls_flower.rule)
 +		return -ENOMEM;
  
  	tc_cls_common_offload_init(&cls_flower.common, tp, f->flags, extack);
- 	cls_flower.command = TC_CLSFLOWER_REPLACE;
+ 	cls_flower.command = FLOW_CLS_REPLACE;
  	cls_flower.cookie = (unsigned long) f;
  	cls_flower.rule->match.dissector = &f->mask->dissector;
  	cls_flower.rule->match.mask = &f->mask->key;
@@@ -432,26 -470,42 +437,26 @@@
  	kfree(cls_flower.rule);
  
  	if (err < 0) {
 -		fl_hw_destroy_filter(tp, f, true, NULL);
 -		goto errout;
 +		fl_hw_destroy_filter(tp, f, NULL);
 +		return err;
  	} else if (err > 0) {
  		f->in_hw_count = err;
 -		err = 0;
 -		spin_lock(&tp->lock);
  		tcf_block_offload_inc(block, &f->flags);
 -		spin_unlock(&tp->lock);
 -	}
 -
 -	if (skip_sw && !(f->flags & TCA_CLS_FLAGS_IN_HW)) {
 -		err = -EINVAL;
 -		goto errout;
  	}
  
 -	spin_lock(&tp->lock);
 -	list_add(&f->hw_list, &head->hw_filters);
 -	spin_unlock(&tp->lock);
 -errout:
 -	if (!rtnl_held)
 -		rtnl_unlock();
 +	if (skip_sw && !(f->flags & TCA_CLS_FLAGS_IN_HW))
 +		return -EINVAL;
  
 -	return err;
 +	return 0;
  }
  
 -static void fl_hw_update_stats(struct tcf_proto *tp, struct cls_fl_filter *f,
 -			       bool rtnl_held)
 +static void fl_hw_update_stats(struct tcf_proto *tp, struct cls_fl_filter *f)
  {
- 	struct tc_cls_flower_offload cls_flower = {};
  	struct tcf_block *block = tp->chain->block;
+ 	struct flow_cls_offload cls_flower = {};
  
 -	if (!rtnl_held)
 -		rtnl_lock();
 -
  	tc_cls_common_offload_init(&cls_flower.common, tp, f->flags, NULL);
- 	cls_flower.command = TC_CLSFLOWER_STATS;
+ 	cls_flower.command = FLOW_CLS_STATS;
  	cls_flower.cookie = (unsigned long) f;
  	cls_flower.classid = f->res.classid;
  
@@@ -1626,57 -1803,64 +1631,74 @@@ static void fl_walk(struct tcf_proto *t
  static int fl_reoffload(struct tcf_proto *tp, bool add, tc_setup_cb_t *cb,
  			void *cb_priv, struct netlink_ext_ack *extack)
  {
++<<<<<<< HEAD
 +	struct cls_fl_head *head = fl_head_dereference(tp);
 +	struct tc_cls_flower_offload cls_flower = {};
 +	struct tcf_block *block = tp->chain->block;
 +	struct fl_flow_mask *mask;
 +	struct cls_fl_filter *f;
++=======
+ 	struct tcf_block *block = tp->chain->block;
+ 	struct flow_cls_offload cls_flower = {};
+ 	struct cls_fl_filter *f = NULL;
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
  	int err;
  
 -	/* hw_filters list can only be changed by hw offload functions after
 -	 * obtaining rtnl lock. Make sure it is not changed while reoffload is
 -	 * iterating it.
 -	 */
 -	ASSERT_RTNL();
 -
 -	while ((f = fl_get_next_hw_filter(tp, f, add))) {
 -		cls_flower.rule =
 -			flow_rule_alloc(tcf_exts_num_actions(&f->exts));
 -		if (!cls_flower.rule) {
 -			__fl_put(f);
 -			return -ENOMEM;
 -		}
 -
 +	list_for_each_entry(mask, &head->masks, list) {
 +		list_for_each_entry(f, &mask->filters, list) {
 +			if (tc_skip_hw(f->flags))
 +				continue;
 +
 +			cls_flower.rule =
 +				flow_rule_alloc(tcf_exts_num_actions(&f->exts));
 +			if (!cls_flower.rule)
 +				return -ENOMEM;
 +
++<<<<<<< HEAD
 +			tc_cls_common_offload_init(&cls_flower.common, tp,
 +						   f->flags, extack);
 +			cls_flower.command = add ?
 +				TC_CLSFLOWER_REPLACE : TC_CLSFLOWER_DESTROY;
 +			cls_flower.cookie = (unsigned long)f;
 +			cls_flower.rule->match.dissector = &mask->dissector;
 +			cls_flower.rule->match.mask = &mask->key;
 +			cls_flower.rule->match.key = &f->mkey;
++=======
+ 		tc_cls_common_offload_init(&cls_flower.common, tp, f->flags,
+ 					   extack);
+ 		cls_flower.command = add ?
+ 			FLOW_CLS_REPLACE : FLOW_CLS_DESTROY;
+ 		cls_flower.cookie = (unsigned long)f;
+ 		cls_flower.rule->match.dissector = &f->mask->dissector;
+ 		cls_flower.rule->match.mask = &f->mask->key;
+ 		cls_flower.rule->match.key = &f->mkey;
 -
 -		err = tc_setup_flow_action(&cls_flower.rule->action, &f->exts);
 -		if (err) {
 -			kfree(cls_flower.rule);
 -			if (tc_skip_sw(f->flags)) {
 -				NL_SET_ERR_MSG_MOD(extack, "Failed to setup flow action");
 -				__fl_put(f);
 -				return err;
++>>>>>>> f9e30088d200 (net: flow_offload: rename tc_cls_flower_offload to flow_cls_offload)
 +
 +			err = tc_setup_flow_action(&cls_flower.rule->action,
 +						   &f->exts);
 +			if (err) {
 +				kfree(cls_flower.rule);
 +				if (tc_skip_sw(f->flags)) {
 +					NL_SET_ERR_MSG_MOD(extack, "Failed to setup flow action");
 +					return err;
 +				}
 +				continue;
  			}
 -			goto next_flow;
 -		}
  
 -		cls_flower.classid = f->res.classid;
 +			cls_flower.classid = f->res.classid;
  
 -		err = cb(TC_SETUP_CLSFLOWER, &cls_flower, cb_priv);
 -		kfree(cls_flower.rule);
 +			err = cb(TC_SETUP_CLSFLOWER, &cls_flower, cb_priv);
 +			kfree(cls_flower.rule);
  
 -		if (err) {
 -			if (add && tc_skip_sw(f->flags)) {
 -				__fl_put(f);
 -				return err;
 +			if (err) {
 +				if (add && tc_skip_sw(f->flags))
 +					return err;
 +				continue;
  			}
 -			goto next_flow;
 -		}
  
 -		spin_lock(&tp->lock);
 -		tc_cls_offload_cnt_update(block, &f->in_hw_count, &f->flags,
 -					  add);
 -		spin_unlock(&tp->lock);
 -next_flow:
 -		__fl_put(f);
 +			tc_cls_offload_cnt_update(block, &f->in_hw_count,
 +						  &f->flags, add);
 +		}
  	}
  
  	return 0;
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_geneve.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_gre.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_vxlan.c
* Unmerged path drivers/net/ethernet/mscc/ocelot_flower.c
diff --git a/drivers/net/ethernet/broadcom/bnxt/bnxt_tc.c b/drivers/net/ethernet/broadcom/bnxt/bnxt_tc.c
index 6ccfb8b72ab4..50d85847bb69 100644
--- a/drivers/net/ethernet/broadcom/bnxt/bnxt_tc.c
+++ b/drivers/net/ethernet/broadcom/bnxt/bnxt_tc.c
@@ -170,10 +170,10 @@ static int bnxt_tc_parse_actions(struct bnxt *bp,
 }
 
 static int bnxt_tc_parse_flow(struct bnxt *bp,
-			      struct tc_cls_flower_offload *tc_flow_cmd,
+			      struct flow_cls_offload *tc_flow_cmd,
 			      struct bnxt_tc_flow *flow)
 {
-	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(tc_flow_cmd);
+	struct flow_rule *rule = flow_cls_offload_flow_rule(tc_flow_cmd);
 	struct flow_dissector *dissector = rule->match.dissector;
 
 	/* KEY_CONTROL and KEY_BASIC are needed for forming a meaningful key */
@@ -1262,7 +1262,7 @@ static void bnxt_tc_set_src_fid(struct bnxt *bp, struct bnxt_tc_flow *flow,
  * The hash-tables are already protected by the rhashtable API.
  */
 static int bnxt_tc_add_flow(struct bnxt *bp, u16 src_fid,
-			    struct tc_cls_flower_offload *tc_flow_cmd)
+			    struct flow_cls_offload *tc_flow_cmd)
 {
 	struct bnxt_tc_flow_node *new_node, *old_node;
 	struct bnxt_tc_info *tc_info = bp->tc_info;
@@ -1348,7 +1348,7 @@ static int bnxt_tc_add_flow(struct bnxt *bp, u16 src_fid,
 }
 
 static int bnxt_tc_del_flow(struct bnxt *bp,
-			    struct tc_cls_flower_offload *tc_flow_cmd)
+			    struct flow_cls_offload *tc_flow_cmd)
 {
 	struct bnxt_tc_info *tc_info = bp->tc_info;
 	struct bnxt_tc_flow_node *flow_node;
@@ -1363,7 +1363,7 @@ static int bnxt_tc_del_flow(struct bnxt *bp,
 }
 
 static int bnxt_tc_get_flow_stats(struct bnxt *bp,
-				  struct tc_cls_flower_offload *tc_flow_cmd)
+				  struct flow_cls_offload *tc_flow_cmd)
 {
 	struct bnxt_tc_flow_stats stats, *curr_stats, *prev_stats;
 	struct bnxt_tc_info *tc_info = bp->tc_info;
@@ -1585,14 +1585,14 @@ void bnxt_tc_flow_stats_work(struct bnxt *bp)
 }
 
 int bnxt_tc_setup_flower(struct bnxt *bp, u16 src_fid,
-			 struct tc_cls_flower_offload *cls_flower)
+			 struct flow_cls_offload *cls_flower)
 {
 	switch (cls_flower->command) {
-	case TC_CLSFLOWER_REPLACE:
+	case FLOW_CLS_REPLACE:
 		return bnxt_tc_add_flow(bp, src_fid, cls_flower);
-	case TC_CLSFLOWER_DESTROY:
+	case FLOW_CLS_DESTROY:
 		return bnxt_tc_del_flow(bp, cls_flower);
-	case TC_CLSFLOWER_STATS:
+	case FLOW_CLS_STATS:
 		return bnxt_tc_get_flow_stats(bp, cls_flower);
 	default:
 		return -EOPNOTSUPP;
diff --git a/drivers/net/ethernet/broadcom/bnxt/bnxt_tc.h b/drivers/net/ethernet/broadcom/bnxt/bnxt_tc.h
index 8a0968967bc5..ffec57d1a5ec 100644
--- a/drivers/net/ethernet/broadcom/bnxt/bnxt_tc.h
+++ b/drivers/net/ethernet/broadcom/bnxt/bnxt_tc.h
@@ -196,7 +196,7 @@ struct bnxt_tc_flow_node {
 };
 
 int bnxt_tc_setup_flower(struct bnxt *bp, u16 src_fid,
-			 struct tc_cls_flower_offload *cls_flower);
+			 struct flow_cls_offload *cls_flower);
 int bnxt_init_tc(struct bnxt *bp);
 void bnxt_shutdown_tc(struct bnxt *bp);
 void bnxt_tc_flow_stats_work(struct bnxt *bp);
@@ -209,7 +209,7 @@ static inline bool bnxt_tc_flower_enabled(struct bnxt *bp)
 #else /* CONFIG_BNXT_FLOWER_OFFLOAD */
 
 static inline int bnxt_tc_setup_flower(struct bnxt *bp, u16 src_fid,
-				       struct tc_cls_flower_offload *cls_flower)
+				       struct flow_cls_offload *cls_flower)
 {
 	return -EOPNOTSUPP;
 }
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
index 0613da428339..b1764dec7642 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
@@ -3136,14 +3136,14 @@ static int cxgb_set_tx_maxrate(struct net_device *dev, int index, u32 rate)
 }
 
 static int cxgb_setup_tc_flower(struct net_device *dev,
-				struct tc_cls_flower_offload *cls_flower)
+				struct flow_cls_offload *cls_flower)
 {
 	switch (cls_flower->command) {
-	case TC_CLSFLOWER_REPLACE:
+	case FLOW_CLS_REPLACE:
 		return cxgb4_tc_flower_replace(dev, cls_flower);
-	case TC_CLSFLOWER_DESTROY:
+	case FLOW_CLS_DESTROY:
 		return cxgb4_tc_flower_destroy(dev, cls_flower);
-	case TC_CLSFLOWER_STATS:
+	case FLOW_CLS_STATS:
 		return cxgb4_tc_flower_stats(dev, cls_flower);
 	default:
 		return -EOPNOTSUPP;
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.c b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.c
index 56742fa0c1af..e447976bdd3e 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.c
@@ -81,10 +81,10 @@ static struct ch_tc_flower_entry *ch_flower_lookup(struct adapter *adap,
 }
 
 static void cxgb4_process_flow_match(struct net_device *dev,
-				     struct tc_cls_flower_offload *cls,
+				     struct flow_cls_offload *cls,
 				     struct ch_filter_specification *fs)
 {
-	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(cls);
+	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
 	u16 addr_type = 0;
 
 	if (flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_CONTROL)) {
@@ -224,9 +224,9 @@ static void cxgb4_process_flow_match(struct net_device *dev,
 }
 
 static int cxgb4_validate_flow_match(struct net_device *dev,
-				     struct tc_cls_flower_offload *cls)
+				     struct flow_cls_offload *cls)
 {
-	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(cls);
+	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
 	struct flow_dissector *dissector = rule->match.dissector;
 	u16 ethtype_mask = 0;
 	u16 ethtype_key = 0;
@@ -379,10 +379,10 @@ static void process_pedit_field(struct ch_filter_specification *fs, u32 val,
 }
 
 static void cxgb4_process_flow_actions(struct net_device *in,
-				       struct tc_cls_flower_offload *cls,
+				       struct flow_cls_offload *cls,
 				       struct ch_filter_specification *fs)
 {
-	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(cls);
+	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
 	struct flow_action_entry *act;
 	int i;
 
@@ -545,9 +545,9 @@ static bool valid_pedit_action(struct net_device *dev,
 }
 
 static int cxgb4_validate_flow_actions(struct net_device *dev,
-				       struct tc_cls_flower_offload *cls)
+				       struct flow_cls_offload *cls)
 {
-	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(cls);
+	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
 	struct flow_action_entry *act;
 	bool act_redir = false;
 	bool act_pedit = false;
@@ -634,7 +634,7 @@ static int cxgb4_validate_flow_actions(struct net_device *dev,
 }
 
 int cxgb4_tc_flower_replace(struct net_device *dev,
-			    struct tc_cls_flower_offload *cls)
+			    struct flow_cls_offload *cls)
 {
 	struct adapter *adap = netdev2adap(dev);
 	struct ch_tc_flower_entry *ch_flower;
@@ -710,7 +710,7 @@ int cxgb4_tc_flower_replace(struct net_device *dev,
 }
 
 int cxgb4_tc_flower_destroy(struct net_device *dev,
-			    struct tc_cls_flower_offload *cls)
+			    struct flow_cls_offload *cls)
 {
 	struct adapter *adap = netdev2adap(dev);
 	struct ch_tc_flower_entry *ch_flower;
@@ -784,7 +784,7 @@ static void ch_flower_stats_cb(struct timer_list *t)
 }
 
 int cxgb4_tc_flower_stats(struct net_device *dev,
-			  struct tc_cls_flower_offload *cls)
+			  struct flow_cls_offload *cls)
 {
 	struct adapter *adap = netdev2adap(dev);
 	struct ch_tc_flower_stats *ofld_stats;
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.h b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.h
index 050c8a50ae41..eb4c95248baf 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.h
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.h
@@ -109,11 +109,11 @@ struct ch_tc_pedit_fields {
 #define PEDIT_UDP_SPORT_DPORT		0x0
 
 int cxgb4_tc_flower_replace(struct net_device *dev,
-			    struct tc_cls_flower_offload *cls);
+			    struct flow_cls_offload *cls);
 int cxgb4_tc_flower_destroy(struct net_device *dev,
-			    struct tc_cls_flower_offload *cls);
+			    struct flow_cls_offload *cls);
 int cxgb4_tc_flower_stats(struct net_device *dev,
-			  struct tc_cls_flower_offload *cls);
+			  struct flow_cls_offload *cls);
 
 int cxgb4_init_tc_flower(struct adapter *adap);
 void cxgb4_cleanup_tc_flower(struct adapter *adap);
diff --git a/drivers/net/ethernet/intel/i40e/i40e_main.c b/drivers/net/ethernet/intel/i40e/i40e_main.c
index 21095c37dad6..d4829f2d7df3 100644
--- a/drivers/net/ethernet/intel/i40e/i40e_main.c
+++ b/drivers/net/ethernet/intel/i40e/i40e_main.c
@@ -7228,15 +7228,15 @@ int i40e_add_del_cloud_filter_big_buf(struct i40e_vsi *vsi,
 /**
  * i40e_parse_cls_flower - Parse tc flower filters provided by kernel
  * @vsi: Pointer to VSI
- * @cls_flower: Pointer to struct tc_cls_flower_offload
+ * @cls_flower: Pointer to struct flow_cls_offload
  * @filter: Pointer to cloud filter structure
  *
  **/
 static int i40e_parse_cls_flower(struct i40e_vsi *vsi,
-				 struct tc_cls_flower_offload *f,
+				 struct flow_cls_offload *f,
 				 struct i40e_cloud_filter *filter)
 {
-	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(f);
+	struct flow_rule *rule = flow_cls_offload_flow_rule(f);
 	struct flow_dissector *dissector = rule->match.dissector;
 	u16 n_proto_mask = 0, n_proto_key = 0, addr_type = 0;
 	struct i40e_pf *pf = vsi->back;
@@ -7470,11 +7470,11 @@ static int i40e_handle_tclass(struct i40e_vsi *vsi, u32 tc,
 /**
  * i40e_configure_clsflower - Configure tc flower filters
  * @vsi: Pointer to VSI
- * @cls_flower: Pointer to struct tc_cls_flower_offload
+ * @cls_flower: Pointer to struct flow_cls_offload
  *
  **/
 static int i40e_configure_clsflower(struct i40e_vsi *vsi,
-				    struct tc_cls_flower_offload *cls_flower)
+				    struct flow_cls_offload *cls_flower)
 {
 	int tc = tc_classid_to_hwtc(vsi->netdev, cls_flower->classid);
 	struct i40e_cloud_filter *filter = NULL;
@@ -7566,11 +7566,11 @@ static struct i40e_cloud_filter *i40e_find_cloud_filter(struct i40e_vsi *vsi,
 /**
  * i40e_delete_clsflower - Remove tc flower filters
  * @vsi: Pointer to VSI
- * @cls_flower: Pointer to struct tc_cls_flower_offload
+ * @cls_flower: Pointer to struct flow_cls_offload
  *
  **/
 static int i40e_delete_clsflower(struct i40e_vsi *vsi,
-				 struct tc_cls_flower_offload *cls_flower)
+				 struct flow_cls_offload *cls_flower)
 {
 	struct i40e_cloud_filter *filter = NULL;
 	struct i40e_pf *pf = vsi->back;
@@ -7613,16 +7613,16 @@ static int i40e_delete_clsflower(struct i40e_vsi *vsi,
  * @type_data: offload data
  **/
 static int i40e_setup_tc_cls_flower(struct i40e_netdev_priv *np,
-				    struct tc_cls_flower_offload *cls_flower)
+				    struct flow_cls_offload *cls_flower)
 {
 	struct i40e_vsi *vsi = np->vsi;
 
 	switch (cls_flower->command) {
-	case TC_CLSFLOWER_REPLACE:
+	case FLOW_CLS_REPLACE:
 		return i40e_configure_clsflower(vsi, cls_flower);
-	case TC_CLSFLOWER_DESTROY:
+	case FLOW_CLS_DESTROY:
 		return i40e_delete_clsflower(vsi, cls_flower);
-	case TC_CLSFLOWER_STATS:
+	case FLOW_CLS_STATS:
 		return -EOPNOTSUPP;
 	default:
 		return -EOPNOTSUPP;
diff --git a/drivers/net/ethernet/intel/iavf/iavf_main.c b/drivers/net/ethernet/intel/iavf/iavf_main.c
index 4569d69a2b55..337bcdf414db 100644
--- a/drivers/net/ethernet/intel/iavf/iavf_main.c
+++ b/drivers/net/ethernet/intel/iavf/iavf_main.c
@@ -2432,14 +2432,14 @@ static int __iavf_setup_tc(struct net_device *netdev, void *type_data)
 /**
  * iavf_parse_cls_flower - Parse tc flower filters provided by kernel
  * @adapter: board private structure
- * @cls_flower: pointer to struct tc_cls_flower_offload
+ * @cls_flower: pointer to struct flow_cls_offload
  * @filter: pointer to cloud filter structure
  */
 static int iavf_parse_cls_flower(struct iavf_adapter *adapter,
-				 struct tc_cls_flower_offload *f,
+				 struct flow_cls_offload *f,
 				 struct iavf_cloud_filter *filter)
 {
-	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(f);
+	struct flow_rule *rule = flow_cls_offload_flow_rule(f);
 	struct flow_dissector *dissector = rule->match.dissector;
 	u16 n_proto_mask = 0;
 	u16 n_proto_key = 0;
@@ -2704,10 +2704,10 @@ static int iavf_handle_tclass(struct iavf_adapter *adapter, u32 tc,
 /**
  * iavf_configure_clsflower - Add tc flower filters
  * @adapter: board private structure
- * @cls_flower: Pointer to struct tc_cls_flower_offload
+ * @cls_flower: Pointer to struct flow_cls_offload
  */
 static int iavf_configure_clsflower(struct iavf_adapter *adapter,
-				    struct tc_cls_flower_offload *cls_flower)
+				    struct flow_cls_offload *cls_flower)
 {
 	int tc = tc_classid_to_hwtc(adapter->netdev, cls_flower->classid);
 	struct iavf_cloud_filter *filter = NULL;
@@ -2783,10 +2783,10 @@ static struct iavf_cloud_filter *iavf_find_cf(struct iavf_adapter *adapter,
 /**
  * iavf_delete_clsflower - Remove tc flower filters
  * @adapter: board private structure
- * @cls_flower: Pointer to struct tc_cls_flower_offload
+ * @cls_flower: Pointer to struct flow_cls_offload
  */
 static int iavf_delete_clsflower(struct iavf_adapter *adapter,
-				 struct tc_cls_flower_offload *cls_flower)
+				 struct flow_cls_offload *cls_flower)
 {
 	struct iavf_cloud_filter *filter = NULL;
 	int err = 0;
@@ -2810,17 +2810,17 @@ static int iavf_delete_clsflower(struct iavf_adapter *adapter,
  * @type_data: offload data
  */
 static int iavf_setup_tc_cls_flower(struct iavf_adapter *adapter,
-				    struct tc_cls_flower_offload *cls_flower)
+				    struct flow_cls_offload *cls_flower)
 {
 	if (cls_flower->common.chain_index)
 		return -EOPNOTSUPP;
 
 	switch (cls_flower->command) {
-	case TC_CLSFLOWER_REPLACE:
+	case FLOW_CLS_REPLACE:
 		return iavf_configure_clsflower(adapter, cls_flower);
-	case TC_CLSFLOWER_DESTROY:
+	case FLOW_CLS_DESTROY:
 		return iavf_delete_clsflower(adapter, cls_flower);
-	case TC_CLSFLOWER_STATS:
+	case FLOW_CLS_STATS:
 		return -EOPNOTSUPP;
 	default:
 		return -EOPNOTSUPP;
diff --git a/drivers/net/ethernet/intel/igb/igb_main.c b/drivers/net/ethernet/intel/igb/igb_main.c
index db0d62038082..1ec0f7d03835 100644
--- a/drivers/net/ethernet/intel/igb/igb_main.c
+++ b/drivers/net/ethernet/intel/igb/igb_main.c
@@ -2578,11 +2578,11 @@ static int igb_offload_cbs(struct igb_adapter *adapter,
 #define VLAN_PRIO_FULL_MASK (0x07)
 
 static int igb_parse_cls_flower(struct igb_adapter *adapter,
-				struct tc_cls_flower_offload *f,
+				struct flow_cls_offload *f,
 				int traffic_class,
 				struct igb_nfc_filter *input)
 {
-	struct flow_rule *rule = tc_cls_flower_offload_flow_rule(f);
+	struct flow_rule *rule = flow_cls_offload_flow_rule(f);
 	struct flow_dissector *dissector = rule->match.dissector;
 	struct netlink_ext_ack *extack = f->common.extack;
 
@@ -2660,7 +2660,7 @@ static int igb_parse_cls_flower(struct igb_adapter *adapter,
 }
 
 static int igb_configure_clsflower(struct igb_adapter *adapter,
-				   struct tc_cls_flower_offload *cls_flower)
+				   struct flow_cls_offload *cls_flower)
 {
 	struct netlink_ext_ack *extack = cls_flower->common.extack;
 	struct igb_nfc_filter *filter, *f;
@@ -2722,7 +2722,7 @@ static int igb_configure_clsflower(struct igb_adapter *adapter,
 }
 
 static int igb_delete_clsflower(struct igb_adapter *adapter,
-				struct tc_cls_flower_offload *cls_flower)
+				struct flow_cls_offload *cls_flower)
 {
 	struct igb_nfc_filter *filter;
 	int err;
@@ -2752,14 +2752,14 @@ static int igb_delete_clsflower(struct igb_adapter *adapter,
 }
 
 static int igb_setup_tc_cls_flower(struct igb_adapter *adapter,
-				   struct tc_cls_flower_offload *cls_flower)
+				   struct flow_cls_offload *cls_flower)
 {
 	switch (cls_flower->command) {
-	case TC_CLSFLOWER_REPLACE:
+	case FLOW_CLS_REPLACE:
 		return igb_configure_clsflower(adapter, cls_flower);
-	case TC_CLSFLOWER_DESTROY:
+	case FLOW_CLS_DESTROY:
 		return igb_delete_clsflower(adapter, cls_flower);
-	case TC_CLSFLOWER_STATS:
+	case FLOW_CLS_STATS:
 		return -EOPNOTSUPP;
 	default:
 		return -EOPNOTSUPP;
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_geneve.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_gre.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun_vxlan.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index 347748bc6280..eab6a74a3ff0 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@ -3425,17 +3425,17 @@ static int mlx5e_setup_tc_mqprio(struct net_device *netdev,
 
 #ifdef CONFIG_MLX5_ESWITCH
 static int mlx5e_setup_tc_cls_flower(struct mlx5e_priv *priv,
-				     struct tc_cls_flower_offload *cls_flower,
+				     struct flow_cls_offload *cls_flower,
 				     int flags)
 {
 	switch (cls_flower->command) {
-	case TC_CLSFLOWER_REPLACE:
+	case FLOW_CLS_REPLACE:
 		return mlx5e_configure_flower(priv->netdev, priv, cls_flower,
 					      flags);
-	case TC_CLSFLOWER_DESTROY:
+	case FLOW_CLS_DESTROY:
 		return mlx5e_delete_flower(priv->netdev, priv, cls_flower,
 					   flags);
-	case TC_CLSFLOWER_STATS:
+	case FLOW_CLS_STATS:
 		return mlx5e_stats_flower(priv->netdev, priv, cls_flower,
 					  flags);
 	default:
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
index d4d2e9fb17fa..7f7fbaf17a33 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
@@ -677,7 +677,7 @@ static void mlx5e_rep_indr_clean_block_privs(struct mlx5e_rep_priv *rpriv)
 
 static int
 mlx5e_rep_indr_offload(struct net_device *netdev,
-		       struct tc_cls_flower_offload *flower,
+		       struct flow_cls_offload *flower,
 		       struct mlx5e_rep_indr_block_priv *indr_priv)
 {
 	struct mlx5e_priv *priv = netdev_priv(indr_priv->rpriv->netdev);
@@ -685,13 +685,13 @@ mlx5e_rep_indr_offload(struct net_device *netdev,
 	int err = 0;
 
 	switch (flower->command) {
-	case TC_CLSFLOWER_REPLACE:
+	case FLOW_CLS_REPLACE:
 		err = mlx5e_configure_flower(netdev, priv, flower, flags);
 		break;
-	case TC_CLSFLOWER_DESTROY:
+	case FLOW_CLS_DESTROY:
 		err = mlx5e_delete_flower(netdev, priv, flower, flags);
 		break;
-	case TC_CLSFLOWER_STATS:
+	case FLOW_CLS_STATS:
 		err = mlx5e_stats_flower(netdev, priv, flower, flags);
 		break;
 	default:
@@ -1164,16 +1164,16 @@ static int mlx5e_rep_get_phys_port_name(struct net_device *dev,
 
 static int
 mlx5e_rep_setup_tc_cls_flower(struct mlx5e_priv *priv,
-			      struct tc_cls_flower_offload *cls_flower, int flags)
+			      struct flow_cls_offload *cls_flower, int flags)
 {
 	switch (cls_flower->command) {
-	case TC_CLSFLOWER_REPLACE:
+	case FLOW_CLS_REPLACE:
 		return mlx5e_configure_flower(priv->netdev, priv, cls_flower,
 					      flags);
-	case TC_CLSFLOWER_DESTROY:
+	case FLOW_CLS_DESTROY:
 		return mlx5e_delete_flower(priv->netdev, priv, cls_flower,
 					   flags);
-	case TC_CLSFLOWER_STATS:
+	case FLOW_CLS_STATS:
 		return mlx5e_stats_flower(priv->netdev, priv, cls_flower,
 					  flags);
 	default:
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
index f62e81902d27..3f0554d502cc 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
@@ -54,12 +54,12 @@ int mlx5e_tc_esw_init(struct rhashtable *tc_ht);
 void mlx5e_tc_esw_cleanup(struct rhashtable *tc_ht);
 
 int mlx5e_configure_flower(struct net_device *dev, struct mlx5e_priv *priv,
-			   struct tc_cls_flower_offload *f, int flags);
+			   struct flow_cls_offload *f, int flags);
 int mlx5e_delete_flower(struct net_device *dev, struct mlx5e_priv *priv,
-			struct tc_cls_flower_offload *f, int flags);
+			struct flow_cls_offload *f, int flags);
 
 int mlx5e_stats_flower(struct net_device *dev, struct mlx5e_priv *priv,
-		       struct tc_cls_flower_offload *f, int flags);
+		       struct flow_cls_offload *f, int flags);
 
 struct mlx5e_encap_entry;
 void mlx5e_tc_encap_flows_add(struct mlx5e_priv *priv,
diff --git a/drivers/net/ethernet/mellanox/mlxsw/spectrum.c b/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
index e43d1c130eea..b26e7286f691 100644
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
@@ -1447,21 +1447,21 @@ static int mlxsw_sp_setup_tc_cls_matchall(struct mlxsw_sp_port *mlxsw_sp_port,
 
 static int
 mlxsw_sp_setup_tc_cls_flower(struct mlxsw_sp_acl_block *acl_block,
-			     struct tc_cls_flower_offload *f)
+			     struct flow_cls_offload *f)
 {
 	struct mlxsw_sp *mlxsw_sp = mlxsw_sp_acl_block_mlxsw_sp(acl_block);
 
 	switch (f->command) {
-	case TC_CLSFLOWER_REPLACE:
+	case FLOW_CLS_REPLACE:
 		return mlxsw_sp_flower_replace(mlxsw_sp, acl_block, f);
-	case TC_CLSFLOWER_DESTROY:
+	case FLOW_CLS_DESTROY:
 		mlxsw_sp_flower_destroy(mlxsw_sp, acl_block, f);
 		return 0;
-	case TC_CLSFLOWER_STATS:
+	case FLOW_CLS_STATS:
 		return mlxsw_sp_flower_stats(mlxsw_sp, acl_block, f);
-	case TC_CLSFLOWER_TMPLT_CREATE:
+	case FLOW_CLS_TMPLT_CREATE:
 		return mlxsw_sp_flower_tmplt_create(mlxsw_sp, acl_block, f);
-	case TC_CLSFLOWER_TMPLT_DESTROY:
+	case FLOW_CLS_TMPLT_DESTROY:
 		mlxsw_sp_flower_tmplt_destroy(mlxsw_sp, acl_block, f);
 		return 0;
 	default:
diff --git a/drivers/net/ethernet/mellanox/mlxsw/spectrum.h b/drivers/net/ethernet/mellanox/mlxsw/spectrum.h
index a61c1130d9e3..a46af92cd973 100644
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum.h
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum.h
@@ -782,19 +782,19 @@ extern const struct mlxsw_afk_ops mlxsw_sp2_afk_ops;
 /* spectrum_flower.c */
 int mlxsw_sp_flower_replace(struct mlxsw_sp *mlxsw_sp,
 			    struct mlxsw_sp_acl_block *block,
-			    struct tc_cls_flower_offload *f);
+			    struct flow_cls_offload *f);
 void mlxsw_sp_flower_destroy(struct mlxsw_sp *mlxsw_sp,
 			     struct mlxsw_sp_acl_block *block,
-			     struct tc_cls_flower_offload *f);
+			     struct flow_cls_offload *f);
 int mlxsw_sp_flower_stats(struct mlxsw_sp *mlxsw_sp,
 			  struct mlxsw_sp_acl_block *block,
-			  struct tc_cls_flower_offload *f);
+			  struct flow_cls_offload *f);
 int mlxsw_sp_flower_tmplt_create(struct mlxsw_sp *mlxsw_sp,
 				 struct mlxsw_sp_acl_block *block,
-				 struct tc_cls_flower_offload *f);
+				 struct flow_cls_offload *f);
 void mlxsw_sp_flower_tmplt_destroy(struct mlxsw_sp *mlxsw_sp,
 				   struct mlxsw_sp_acl_block *block,
-				   struct tc_cls_flower_offload *f);
+				   struct flow_cls_offload *f);
 
 /* spectrum_qdisc.c */
 int mlxsw_sp_tc_qdisc_init(struct mlxsw_sp_port *mlxsw_sp_port);
* Unmerged path drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c
* Unmerged path drivers/net/ethernet/mscc/ocelot_flower.c
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/action.c
diff --git a/drivers/net/ethernet/netronome/nfp/flower/main.h b/drivers/net/ethernet/netronome/nfp/flower/main.h
index 6c27e9b403bc..42decb4ed253 100644
--- a/drivers/net/ethernet/netronome/nfp/flower/main.h
+++ b/drivers/net/ethernet/netronome/nfp/flower/main.h
@@ -256,17 +256,17 @@ void nfp_flower_metadata_cleanup(struct nfp_app *app);
 int nfp_flower_setup_tc(struct nfp_app *app, struct net_device *netdev,
 			enum tc_setup_type type, void *type_data);
 int nfp_flower_compile_flow_match(struct nfp_app *app,
-				  struct tc_cls_flower_offload *flow,
+				  struct flow_cls_offload *flow,
 				  struct nfp_fl_key_ls *key_ls,
 				  struct net_device *netdev,
 				  struct nfp_fl_payload *nfp_flow,
 				  enum nfp_flower_tun_type tun_type);
 int nfp_flower_compile_action(struct nfp_app *app,
-			      struct tc_cls_flower_offload *flow,
+			      struct flow_cls_offload *flow,
 			      struct net_device *netdev,
 			      struct nfp_fl_payload *nfp_flow);
 int nfp_compile_flow_metadata(struct nfp_app *app,
-			      struct tc_cls_flower_offload *flow,
+			      struct flow_cls_offload *flow,
 			      struct nfp_fl_payload *nfp_flow,
 			      struct net_device *netdev);
 int nfp_modify_flow_metadata(struct nfp_app *app,
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/match.c
diff --git a/drivers/net/ethernet/netronome/nfp/flower/metadata.c b/drivers/net/ethernet/netronome/nfp/flower/metadata.c
index 492837b852b6..9a987455b679 100644
--- a/drivers/net/ethernet/netronome/nfp/flower/metadata.c
+++ b/drivers/net/ethernet/netronome/nfp/flower/metadata.c
@@ -281,7 +281,7 @@ nfp_check_mask_remove(struct nfp_app *app, char *mask_data, u32 mask_len,
 }
 
 int nfp_compile_flow_metadata(struct nfp_app *app,
-			      struct tc_cls_flower_offload *flow,
+			      struct flow_cls_offload *flow,
 			      struct nfp_fl_payload *nfp_flow,
 			      struct net_device *netdev)
 {
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/offload.c
diff --git a/drivers/net/ethernet/qlogic/qede/qede.h b/drivers/net/ethernet/qlogic/qede/qede.h
index 5b6fa62b4603..785999c482cc 100644
--- a/drivers/net/ethernet/qlogic/qede/qede.h
+++ b/drivers/net/ethernet/qlogic/qede/qede.h
@@ -567,7 +567,7 @@ int qede_txq_has_work(struct qede_tx_queue *txq);
 void qede_recycle_rx_bd_ring(struct qede_rx_queue *rxq, u8 count);
 void qede_update_rx_prod(struct qede_dev *edev, struct qede_rx_queue *rxq);
 int qede_add_tc_flower_fltr(struct qede_dev *edev, __be16 proto,
-			    struct tc_cls_flower_offload *f);
+			    struct flow_cls_offload *f);
 
 #define RX_RING_SIZE_POW	13
 #define RX_RING_SIZE		((u16)BIT(RX_RING_SIZE_POW))
diff --git a/drivers/net/ethernet/qlogic/qede/qede_filter.c b/drivers/net/ethernet/qlogic/qede/qede_filter.c
index add922b93d2c..9a6a9a008714 100644
--- a/drivers/net/ethernet/qlogic/qede/qede_filter.c
+++ b/drivers/net/ethernet/qlogic/qede/qede_filter.c
@@ -1943,7 +1943,7 @@ qede_parse_flow_attr(struct qede_dev *edev, __be16 proto,
 }
 
 int qede_add_tc_flower_fltr(struct qede_dev *edev, __be16 proto,
-			    struct tc_cls_flower_offload *f)
+			    struct flow_cls_offload *f)
 {
 	struct qede_arfs_fltr_node *n;
 	int min_hlen, rc = -EINVAL;
diff --git a/drivers/net/ethernet/qlogic/qede/qede_main.c b/drivers/net/ethernet/qlogic/qede/qede_main.c
index d4a29660751d..5ce8fd44bb64 100644
--- a/drivers/net/ethernet/qlogic/qede/qede_main.c
+++ b/drivers/net/ethernet/qlogic/qede/qede_main.c
@@ -548,13 +548,13 @@ static int qede_setup_tc(struct net_device *ndev, u8 num_tc)
 }
 
 static int
-qede_set_flower(struct qede_dev *edev, struct tc_cls_flower_offload *f,
+qede_set_flower(struct qede_dev *edev, struct flow_cls_offload *f,
 		__be16 proto)
 {
 	switch (f->command) {
-	case TC_CLSFLOWER_REPLACE:
+	case FLOW_CLS_REPLACE:
 		return qede_add_tc_flower_fltr(edev, proto, f);
-	case TC_CLSFLOWER_DESTROY:
+	case FLOW_CLS_DESTROY:
 		return qede_delete_flow_filter(edev, f->cookie);
 	default:
 		return -EOPNOTSUPP;
@@ -564,7 +564,7 @@ qede_set_flower(struct qede_dev *edev, struct tc_cls_flower_offload *f,
 static int qede_setup_tc_block_cb(enum tc_setup_type type, void *type_data,
 				  void *cb_priv)
 {
-	struct tc_cls_flower_offload *f;
+	struct flow_cls_offload *f;
 	struct qede_dev *edev = cb_priv;
 
 	if (!tc_cls_can_offload_and_chain0(edev->ndev, type_data))
* Unmerged path include/net/flow_offload.h
* Unmerged path include/net/pkt_cls.h
* Unmerged path net/sched/cls_flower.c
