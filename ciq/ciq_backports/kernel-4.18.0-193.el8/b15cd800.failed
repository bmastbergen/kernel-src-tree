dax: Convert page fault handlers to XArray

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Matthew Wilcox <willy@infradead.org>
commit b15cd800682fcaf27048b05e42f5c208e4c756c0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/b15cd800.failed

This is the last part of DAX to be converted to the XArray so
remove all the old helper functions.

	Signed-off-by: Matthew Wilcox <willy@infradead.org>
(cherry picked from commit b15cd800682fcaf27048b05e42f5c208e4c756c0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/dax.c
diff --cc fs/dax.c
index 29113658577c,616e36ea6aaa..000000000000
--- a/fs/dax.c
+++ b/fs/dax.c
@@@ -94,10 -93,15 +94,22 @@@ static unsigned long dax_to_pfn(void *e
  	return xa_to_value(entry) >> DAX_SHIFT;
  }
  
++<<<<<<< HEAD
 +static void *dax_make_locked(unsigned long pfn, unsigned long flags)
 +{
 +	return xa_mk_value(flags | ((unsigned long)pfn << DAX_SHIFT) |
 +			DAX_LOCKED);
++=======
+ static void *dax_make_entry(pfn_t pfn, unsigned long flags)
+ {
+ 	return xa_mk_value(flags | (pfn_t_to_pfn(pfn) << DAX_SHIFT));
+ }
+ 
+ static void *dax_make_page_entry(struct page *page)
+ {
+ 	pfn_t pfn = page_to_pfn_t(page);
+ 	return dax_make_entry(pfn, PageHead(page) ? DAX_PMD : 0);
++>>>>>>> b15cd800682f (dax: Convert page fault handlers to XArray)
  }
  
  static bool dax_is_locked(void *entry)
@@@ -1565,11 -1378,8 +1409,10 @@@ static vm_fault_t dax_pmd_load_hole(str
  {
  	struct address_space *mapping = vmf->vma->vm_file->f_mapping;
  	unsigned long pmd_addr = vmf->address & PMD_MASK;
 +	struct vm_area_struct *vma = vmf->vma;
  	struct inode *inode = mapping->host;
 +	pgtable_t pgtable = NULL;
  	struct page *zero_page;
- 	void *ret = NULL;
  	spinlock_t *ptl;
  	pmd_t pmd_entry;
  	pfn_t pfn;
@@@ -1580,15 -1390,9 +1423,15 @@@
  		goto fallback;
  
  	pfn = page_to_pfn_t(zero_page);
- 	ret = dax_insert_entry(mapping, vmf, entry, pfn,
+ 	*entry = dax_insert_entry(xas, mapping, vmf, *entry, pfn,
  			DAX_PMD | DAX_ZERO_PAGE, false);
  
 +	if (arch_needs_pgtable_deposit()) {
 +		pgtable = pte_alloc_one(vma->vm_mm, vmf->address);
 +		if (!pgtable)
 +			return VM_FAULT_OOM;
 +	}
 +
  	ptl = pmd_lock(vmf->vma->vm_mm, vmf->pmd);
  	if (!pmd_none(*(vmf->pmd))) {
  		spin_unlock(ptl);
@@@ -1607,9 -1407,7 +1450,13 @@@
  	return VM_FAULT_NOPAGE;
  
  fallback:
++<<<<<<< HEAD
 +	if (pgtable)
 +		pte_free(vma->vm_mm, pgtable);
 +	trace_dax_pmd_load_hole_fallback(inode, vmf, zero_page, ret);
++=======
+ 	trace_dax_pmd_load_hole_fallback(inode, vmf, zero_page, *entry);
++>>>>>>> b15cd800682f (dax: Convert page fault handlers to XArray)
  	return VM_FAULT_FALLBACK;
  }
  
* Unmerged path fs/dax.c
