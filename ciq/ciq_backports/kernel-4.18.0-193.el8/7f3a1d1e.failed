SUNRPC: Refactor xprt_transmit() to remove wait for reply code

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Trond Myklebust <trond.myklebust@hammerspace.com>
commit 7f3a1d1e1806a0eb9b200e3aed2a04431f2bcc6a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/7f3a1d1e.failed

Allow the caller in clnt.c to call into the code to wait for a reply
after calling xprt_transmit(). Again, the reason is that the backchannel
code does not need this functionality.

	Signed-off-by: Trond Myklebust <trond.myklebust@hammerspace.com>
(cherry picked from commit 7f3a1d1e1806a0eb9b200e3aed2a04431f2bcc6a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/sunrpc/xprt.h
#	net/sunrpc/xprt.c
diff --cc include/linux/sunrpc/xprt.h
index bd743c51a865,4fa2af087cff..000000000000
--- a/include/linux/sunrpc/xprt.h
+++ b/include/linux/sunrpc/xprt.h
@@@ -334,6 -334,8 +334,11 @@@ void			xprt_free_slot(struct rpc_xprt *
  				       struct rpc_rqst *req);
  void			xprt_lock_and_alloc_slot(struct rpc_xprt *xprt, struct rpc_task *task);
  bool			xprt_prepare_transmit(struct rpc_task *task);
++<<<<<<< HEAD
++=======
+ void			xprt_request_enqueue_receive(struct rpc_task *task);
+ void			xprt_request_wait_receive(struct rpc_task *task);
++>>>>>>> 7f3a1d1e1806 (SUNRPC: Refactor xprt_transmit() to remove wait for reply code)
  void			xprt_transmit(struct rpc_task *task);
  void			xprt_end_transmit(struct rpc_task *task);
  int			xprt_adjust_timeout(struct rpc_rqst *req);
diff --cc net/sunrpc/xprt.c
index cc25632c1df5,a6a33c178870..000000000000
--- a/net/sunrpc/xprt.c
+++ b/net/sunrpc/xprt.c
@@@ -1064,22 -1147,6 +1110,25 @@@ void xprt_transmit(struct rpc_task *tas
  	spin_unlock_bh(&xprt->transport_lock);
  
  	req->rq_connect_cookie = connect_cookie;
++<<<<<<< HEAD
 +	if (test_bit(RPC_TASK_NEED_RECV, &task->tk_runstate)) {
 +		/*
 +		 * Sleep on the pending queue if we're expecting a reply.
 +		 * The spinlock ensures atomicity between the test of
 +		 * req->rq_reply_bytes_recvd, and the call to rpc_sleep_on().
 +		 */
 +		spin_lock(&xprt->recv_lock);
 +		if (test_bit(RPC_TASK_NEED_RECV, &task->tk_runstate)) {
 +			rpc_sleep_on(&xprt->pending, task, xprt_timer);
 +			/* Wake up immediately if the connection was dropped */
 +			if (!xprt_connected(xprt))
 +				rpc_wake_up_queued_task_set_status(&xprt->pending,
 +						task, -ENOTCONN);
 +		}
 +		spin_unlock(&xprt->recv_lock);
 +	}
++=======
++>>>>>>> 7f3a1d1e1806 (SUNRPC: Refactor xprt_transmit() to remove wait for reply code)
  }
  
  static void xprt_add_backlog(struct rpc_xprt *xprt, struct rpc_task *task)
* Unmerged path include/linux/sunrpc/xprt.h
diff --git a/net/sunrpc/clnt.c b/net/sunrpc/clnt.c
index a858366cd15d..58a011c6695d 100644
--- a/net/sunrpc/clnt.c
+++ b/net/sunrpc/clnt.c
@@ -1970,15 +1970,6 @@ call_transmit(struct rpc_task *task)
 		return;
 	if (is_retrans)
 		task->tk_client->cl_stats->rpcretrans++;
-	/*
-	 * On success, ensure that we call xprt_end_transmit() before sleeping
-	 * in order to allow access to the socket to other RPC requests.
-	 */
-	call_transmit_status(task);
-	if (rpc_reply_expected(task))
-		return;
-	task->tk_action = rpc_exit_task;
-	rpc_wake_up_queued_task(&task->tk_rqstp->rq_xprt->pending, task);
 }
 
 /*
@@ -1995,6 +1986,7 @@ call_transmit_status(struct rpc_task *task)
 	 */
 	if (task->tk_status == 0) {
 		xprt_end_transmit(task);
+		xprt_request_wait_receive(task);
 		return;
 	}
 
* Unmerged path net/sunrpc/xprt.c
