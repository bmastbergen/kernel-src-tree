net/mlx5: Move device memory management to mlx5_core

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [netdrv] mlx5: Move device memory management to mlx5_core (Alaa Hleihel) [1760284 1724336]
Rebuild_FUZZ: 96.00%
commit-author Ariel Levkovich <lariel@mellanox.com>
commit c9b9dcb430b3cd0ad2b04c360c4e528d73430481
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/c9b9dcb4.failed

Move the device memory allocation and deallocation commands
SW ICM memory to mlx5_core to expose this API for all
mlx5_core users.

This comes as preparation for supporting SW steering in kernel
where it will be required to allocate and register device
memory for direct rule insertion.

In addition, an API to register this device memory for future
remote access operations is introduced using the create_mkey
commands.

	Signed-off-by: Ariel Levkovich <lariel@mellanox.com>
	Reviewed-by: Mark Bloch <markb@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit c9b9dcb430b3cd0ad2b04c360c4e528d73430481)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/main.c
#	drivers/net/ethernet/mellanox/mlx5/core/Makefile
#	include/linux/mlx5/driver.h
diff --cc drivers/infiniband/hw/mlx5/main.c
index 30c3472ce233,42fdbbea06f0..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -2274,15 -2271,35 +2274,44 @@@ static int mlx5_ib_mmap(struct ib_ucont
  	return 0;
  }
  
 -static inline int check_dm_type_support(struct mlx5_ib_dev *dev,
 -					u32 type)
 +struct ib_dm *mlx5_ib_alloc_dm(struct ib_device *ibdev,
 +			       struct ib_ucontext *context,
 +			       struct ib_dm_alloc_attr *attr,
 +			       struct uverbs_attr_bundle *attrs)
  {
++<<<<<<< HEAD
 +	u64 act_size = roundup(attr->length, MLX5_MEMIC_BASE_SIZE);
 +	struct mlx5_memic *memic = &to_mdev(ibdev)->memic;
 +	phys_addr_t memic_addr;
 +	struct mlx5_ib_dm *dm;
++=======
+ 	switch (type) {
+ 	case MLX5_IB_UAPI_DM_TYPE_MEMIC:
+ 		if (!MLX5_CAP_DEV_MEM(dev->mdev, memic))
+ 			return -EOPNOTSUPP;
+ 		break;
+ 	case MLX5_IB_UAPI_DM_TYPE_STEERING_SW_ICM:
+ 	case MLX5_IB_UAPI_DM_TYPE_HEADER_MODIFY_SW_ICM:
+ 		if (!capable(CAP_SYS_RAWIO) ||
+ 		    !capable(CAP_NET_RAW))
+ 			return -EPERM;
+ 
+ 		if (!(MLX5_CAP_FLOWTABLE_NIC_RX(dev->mdev, sw_owner) ||
+ 		      MLX5_CAP_FLOWTABLE_NIC_TX(dev->mdev, sw_owner)))
+ 			return -EOPNOTSUPP;
+ 		break;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int handle_alloc_dm_memic(struct ib_ucontext *ctx,
+ 				 struct mlx5_ib_dm *dm,
+ 				 struct ib_dm_alloc_attr *attr,
+ 				 struct uverbs_attr_bundle *attrs)
+ {
+ 	struct mlx5_dm *dm_db = &to_mdev(ctx->device)->dm;
++>>>>>>> c9b9dcb430b3 (net/mlx5: Move device memory management to mlx5_core)
  	u64 start_offset;
  	u32 page_idx;
  	int err;
@@@ -2316,10 -2328,101 +2345,108 @@@
  	if (err)
  		goto err_dealloc;
  
 +	bitmap_set(to_mucontext(context)->dm_pages, page_idx,
 +		   DIV_ROUND_UP(act_size, PAGE_SIZE));
 +
++<<<<<<< HEAD
 +	dm->dev_addr = memic_addr;
++=======
+ 	bitmap_set(to_mucontext(ctx)->dm_pages, page_idx,
+ 		   DIV_ROUND_UP(dm->size, PAGE_SIZE));
+ 
+ 	return 0;
+ 
+ err_dealloc:
+ 	mlx5_cmd_dealloc_memic(dm_db, dm->dev_addr, dm->size);
+ 
+ 	return err;
+ }
+ 
+ static int handle_alloc_dm_sw_icm(struct ib_ucontext *ctx,
+ 				  struct mlx5_ib_dm *dm,
+ 				  struct ib_dm_alloc_attr *attr,
+ 				  struct uverbs_attr_bundle *attrs,
+ 				  int type)
+ {
+ 	struct mlx5_core_dev *dev = to_mdev(ctx->device)->mdev;
+ 	u64 act_size;
+ 	int err;
+ 
+ 	/* Allocation size must a multiple of the basic block size
+ 	 * and a power of 2.
+ 	 */
+ 	act_size = round_up(attr->length, MLX5_SW_ICM_BLOCK_SIZE(dev));
+ 	act_size = roundup_pow_of_two(act_size);
+ 
+ 	dm->size = act_size;
+ 	err = mlx5_dm_sw_icm_alloc(dev, type, act_size,
+ 				   to_mucontext(ctx)->devx_uid, &dm->dev_addr,
+ 				   &dm->icm_dm.obj_id);
+ 	if (err)
+ 		return err;
+ 
+ 	err = uverbs_copy_to(attrs,
+ 			     MLX5_IB_ATTR_ALLOC_DM_RESP_START_OFFSET,
+ 			     &dm->dev_addr, sizeof(dm->dev_addr));
+ 	if (err)
+ 		mlx5_dm_sw_icm_dealloc(dev, type, dm->size,
+ 				       to_mucontext(ctx)->devx_uid, dm->dev_addr,
+ 				       dm->icm_dm.obj_id);
+ 
+ 	return err;
+ }
+ 
+ struct ib_dm *mlx5_ib_alloc_dm(struct ib_device *ibdev,
+ 			       struct ib_ucontext *context,
+ 			       struct ib_dm_alloc_attr *attr,
+ 			       struct uverbs_attr_bundle *attrs)
+ {
+ 	struct mlx5_ib_dm *dm;
+ 	enum mlx5_ib_uapi_dm_type type;
+ 	int err;
+ 
+ 	err = uverbs_get_const_default(&type, attrs,
+ 				       MLX5_IB_ATTR_ALLOC_DM_REQ_TYPE,
+ 				       MLX5_IB_UAPI_DM_TYPE_MEMIC);
+ 	if (err)
+ 		return ERR_PTR(err);
+ 
+ 	mlx5_ib_dbg(to_mdev(ibdev), "alloc_dm req: dm_type=%d user_length=0x%llx log_alignment=%d\n",
+ 		    type, attr->length, attr->alignment);
+ 
+ 	err = check_dm_type_support(to_mdev(ibdev), type);
+ 	if (err)
+ 		return ERR_PTR(err);
+ 
+ 	dm = kzalloc(sizeof(*dm), GFP_KERNEL);
+ 	if (!dm)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	dm->type = type;
+ 
+ 	switch (type) {
+ 	case MLX5_IB_UAPI_DM_TYPE_MEMIC:
+ 		err = handle_alloc_dm_memic(context, dm,
+ 					    attr,
+ 					    attrs);
+ 		break;
+ 	case MLX5_IB_UAPI_DM_TYPE_STEERING_SW_ICM:
+ 		err = handle_alloc_dm_sw_icm(context, dm,
+ 					     attr, attrs,
+ 					     MLX5_SW_ICM_TYPE_STEERING);
+ 		break;
+ 	case MLX5_IB_UAPI_DM_TYPE_HEADER_MODIFY_SW_ICM:
+ 		err = handle_alloc_dm_sw_icm(context, dm,
+ 					     attr, attrs,
+ 					     MLX5_SW_ICM_TYPE_HEADER_MODIFY);
+ 		break;
+ 	default:
+ 		err = -EOPNOTSUPP;
+ 	}
+ 
+ 	if (err)
+ 		goto err_free;
++>>>>>>> c9b9dcb430b3 (net/mlx5: Move device memory management to mlx5_core)
  
  	return &dm->ibdm;
  
@@@ -2331,24 -2431,45 +2458,57 @@@ err_free
  	return ERR_PTR(err);
  }
  
 -int mlx5_ib_dealloc_dm(struct ib_dm *ibdm, struct uverbs_attr_bundle *attrs)
 +int mlx5_ib_dealloc_dm(struct ib_dm *ibdm)
  {
++<<<<<<< HEAD
 +	struct mlx5_memic *memic = &to_mdev(ibdm->device)->memic;
++=======
+ 	struct mlx5_ib_ucontext *ctx = rdma_udata_to_drv_context(
+ 		&attrs->driver_udata, struct mlx5_ib_ucontext, ibucontext);
+ 	struct mlx5_core_dev *dev = to_mdev(ibdm->device)->mdev;
+ 	struct mlx5_dm *dm_db = &to_mdev(ibdm->device)->dm;
++>>>>>>> c9b9dcb430b3 (net/mlx5: Move device memory management to mlx5_core)
  	struct mlx5_ib_dm *dm = to_mdm(ibdm);
 +	u64 act_size = roundup(dm->ibdm.length, MLX5_MEMIC_BASE_SIZE);
  	u32 page_idx;
  	int ret;
  
 -	switch (dm->type) {
 -	case MLX5_IB_UAPI_DM_TYPE_MEMIC:
 -		ret = mlx5_cmd_dealloc_memic(dm_db, dm->dev_addr, dm->size);
 -		if (ret)
 -			return ret;
 +	ret = mlx5_cmd_dealloc_memic(memic, dm->dev_addr, act_size);
 +	if (ret)
 +		return ret;
  
++<<<<<<< HEAD
 +	page_idx = (dm->dev_addr - memic->dev->bar_addr -
 +		    MLX5_CAP64_DEV_MEM(memic->dev, memic_bar_start_addr)) >>
 +		    PAGE_SHIFT;
 +	bitmap_clear(to_mucontext(ibdm->uobject->context)->dm_pages,
 +		     page_idx,
 +		     DIV_ROUND_UP(act_size, PAGE_SIZE));
++=======
+ 		page_idx = (dm->dev_addr - pci_resource_start(dev->pdev, 0) -
+ 			    MLX5_CAP64_DEV_MEM(dev, memic_bar_start_addr)) >>
+ 			    PAGE_SHIFT;
+ 		bitmap_clear(ctx->dm_pages, page_idx,
+ 			     DIV_ROUND_UP(dm->size, PAGE_SIZE));
+ 		break;
+ 	case MLX5_IB_UAPI_DM_TYPE_STEERING_SW_ICM:
+ 		ret = mlx5_dm_sw_icm_dealloc(dev, MLX5_SW_ICM_TYPE_STEERING,
+ 					     dm->size, ctx->devx_uid, dm->dev_addr,
+ 					     dm->icm_dm.obj_id);
+ 		if (ret)
+ 			return ret;
+ 		break;
+ 	case MLX5_IB_UAPI_DM_TYPE_HEADER_MODIFY_SW_ICM:
+ 		ret = mlx5_dm_sw_icm_dealloc(dev, MLX5_SW_ICM_TYPE_HEADER_MODIFY,
+ 					     dm->size, ctx->devx_uid, dm->dev_addr,
+ 					     dm->icm_dm.obj_id);
+ 		if (ret)
+ 			return ret;
+ 		break;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
++>>>>>>> c9b9dcb430b3 (net/mlx5: Move device memory management to mlx5_core)
  
  	kfree(dm);
  
@@@ -5929,10 -6114,11 +6089,15 @@@ void mlx5_ib_stage_init_cleanup(struct 
  		srcu_barrier(&dev->mr_srcu);
  		cleanup_srcu_struct(&dev->mr_srcu);
  	}
++<<<<<<< HEAD
 +	kfree(dev->port);
++=======
+ 
+ 	WARN_ON(!bitmap_empty(dev->dm.memic_alloc_pages, MLX5_MAX_MEMIC_PAGES));
++>>>>>>> c9b9dcb430b3 (net/mlx5: Move device memory management to mlx5_core)
  }
  
 -static int mlx5_ib_stage_init_init(struct mlx5_ib_dev *dev)
 +int mlx5_ib_stage_init_init(struct mlx5_ib_dev *dev)
  {
  	struct mlx5_core_dev *mdev = dev->mdev;
  	int err;
@@@ -5984,8 -6165,8 +6149,13 @@@
  	INIT_LIST_HEAD(&dev->qp_list);
  	spin_lock_init(&dev->reset_flow_resource_lock);
  
++<<<<<<< HEAD
 +	spin_lock_init(&dev->memic.memic_lock);
 +	dev->memic.dev = mdev;
++=======
+ 	spin_lock_init(&dev->dm.lock);
+ 	dev->dm.dev = mdev;
++>>>>>>> c9b9dcb430b3 (net/mlx5: Move device memory management to mlx5_core)
  
  	if (IS_ENABLED(CONFIG_INFINIBAND_ON_DEMAND_PAGING)) {
  		err = init_srcu_struct(&dev->mr_srcu);
@@@ -5994,6 -6175,7 +6164,10 @@@
  	}
  
  	return 0;
++<<<<<<< HEAD
++=======
+ 
++>>>>>>> c9b9dcb430b3 (net/mlx5: Move device memory management to mlx5_core)
  err_mp:
  	mlx5_ib_cleanup_multiport_master(dev);
  
diff --cc drivers/net/ethernet/mellanox/mlx5/core/Makefile
index 1438dae173b8,4eb52e8500c3..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/Makefile
+++ b/drivers/net/ethernet/mellanox/mlx5/core/Makefile
@@@ -13,9 -13,10 +13,14 @@@ obj-$(CONFIG_MLX5_CORE) += mlx5_core.
  #
  mlx5_core-y :=	main.o cmd.o debugfs.o fw.o eq.o uar.o pagealloc.o \
  		health.o mcg.o cq.o alloc.o qp.o port.o mr.o pd.o \
 -		transobj.o vport.o sriov.o fs_cmd.o fs_core.o pci_irq.o \
 +		transobj.o vport.o sriov.o fs_cmd.o fs_core.o \
  		fs_counters.o rl.o lag.o dev.o events.o wq.o lib/gid.o \
++<<<<<<< HEAD
 +		lib/devcom.o diag/fs_tracepoint.o diag/fw_tracer.o
++=======
+ 		lib/devcom.o lib/pci_vsc.o lib/dm.o diag/fs_tracepoint.o \
+ 		diag/fw_tracer.o diag/crdump.o devlink.o
++>>>>>>> c9b9dcb430b3 (net/mlx5: Move device memory management to mlx5_core)
  
  #
  # Netdev basic
diff --cc include/linux/mlx5/driver.h
index 6e54f159441a,72bc6ce44b55..000000000000
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@@ -648,12 -658,17 +653,22 @@@ struct mlx5_clock 
  	struct mlx5_pps            pps_info;
  };
  
++<<<<<<< HEAD
 +struct mlx5_vxlan;
 +struct mlx5_geneve;
 +
 +struct mlx5_fw_tracer;
++=======
+ struct mlx5_dm;
+ struct mlx5_fw_tracer;
+ struct mlx5_vxlan;
+ struct mlx5_geneve;
+ 
+ #define MLX5_LOG_SW_ICM_BLOCK_SIZE(dev) (MLX5_CAP_DEV_MEM(dev, log_sw_icm_alloc_granularity))
+ #define MLX5_SW_ICM_BLOCK_SIZE(dev) (1 << MLX5_LOG_SW_ICM_BLOCK_SIZE(dev))
++>>>>>>> c9b9dcb430b3 (net/mlx5: Move device memory management to mlx5_core)
  
  struct mlx5_core_dev {
 -	struct device *device;
 -	enum mlx5_coredev_type coredev_type;
  	struct pci_dev	       *pdev;
  	/* sync pci state */
  	struct mutex		pci_status_mutex;
* Unmerged path drivers/infiniband/hw/mlx5/main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/Makefile
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/lib/dm.c b/drivers/net/ethernet/mellanox/mlx5/core/lib/dm.c
new file mode 100644
index 000000000000..e065c2f68f5a
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/lib/dm.c
@@ -0,0 +1,223 @@
+// SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB
+// Copyright (c) 2019 Mellanox Technologies
+
+#include <linux/mlx5/driver.h>
+#include <linux/mlx5/device.h>
+
+#include "mlx5_core.h"
+#include "lib/mlx5.h"
+
+struct mlx5_dm {
+	/* protect access to icm bitmask */
+	spinlock_t lock;
+	unsigned long *steering_sw_icm_alloc_blocks;
+	unsigned long *header_modify_sw_icm_alloc_blocks;
+};
+
+struct mlx5_dm *mlx5_dm_create(struct mlx5_core_dev *dev)
+{
+	u64 header_modify_icm_blocks = 0;
+	u64 steering_icm_blocks = 0;
+	struct mlx5_dm *dm;
+
+	if (!(MLX5_CAP_GEN_64(dev, general_obj_types) & MLX5_GENERAL_OBJ_TYPES_CAP_SW_ICM))
+		return 0;
+
+	dm = kzalloc(sizeof(*dm), GFP_KERNEL);
+	if (!dm)
+		return ERR_PTR(-ENOMEM);
+
+	spin_lock_init(&dm->lock);
+
+	if (MLX5_CAP64_DEV_MEM(dev, steering_sw_icm_start_address)) {
+		steering_icm_blocks =
+			BIT(MLX5_CAP_DEV_MEM(dev, log_steering_sw_icm_size) -
+			    MLX5_LOG_SW_ICM_BLOCK_SIZE(dev));
+
+		dm->steering_sw_icm_alloc_blocks =
+			kcalloc(BITS_TO_LONGS(steering_icm_blocks),
+				sizeof(unsigned long), GFP_KERNEL);
+		if (!dm->steering_sw_icm_alloc_blocks)
+			goto err_steering;
+	}
+
+	if (MLX5_CAP64_DEV_MEM(dev, header_modify_sw_icm_start_address)) {
+		header_modify_icm_blocks =
+			BIT(MLX5_CAP_DEV_MEM(dev, log_header_modify_sw_icm_size) -
+			    MLX5_LOG_SW_ICM_BLOCK_SIZE(dev));
+
+		dm->header_modify_sw_icm_alloc_blocks =
+			kcalloc(BITS_TO_LONGS(header_modify_icm_blocks),
+				sizeof(unsigned long), GFP_KERNEL);
+		if (!dm->header_modify_sw_icm_alloc_blocks)
+			goto err_modify_hdr;
+	}
+
+	return dm;
+
+err_modify_hdr:
+	kfree(dm->steering_sw_icm_alloc_blocks);
+
+err_steering:
+	kfree(dm);
+
+	return ERR_PTR(-ENOMEM);
+}
+
+void mlx5_dm_cleanup(struct mlx5_core_dev *dev)
+{
+	struct mlx5_dm *dm = dev->dm;
+
+	if (!dev->dm)
+		return;
+
+	if (dm->steering_sw_icm_alloc_blocks) {
+		WARN_ON(!bitmap_empty(dm->steering_sw_icm_alloc_blocks,
+				      BIT(MLX5_CAP_DEV_MEM(dev, log_steering_sw_icm_size) -
+					  MLX5_LOG_SW_ICM_BLOCK_SIZE(dev))));
+		kfree(dm->steering_sw_icm_alloc_blocks);
+	}
+
+	if (dm->header_modify_sw_icm_alloc_blocks) {
+		WARN_ON(!bitmap_empty(dm->header_modify_sw_icm_alloc_blocks,
+				      BIT(MLX5_CAP_DEV_MEM(dev,
+							   log_header_modify_sw_icm_size) -
+				      MLX5_LOG_SW_ICM_BLOCK_SIZE(dev))));
+		kfree(dm->header_modify_sw_icm_alloc_blocks);
+	}
+
+	kfree(dm);
+}
+
+int mlx5_dm_sw_icm_alloc(struct mlx5_core_dev *dev, enum mlx5_sw_icm_type type,
+			 u64 length, u16 uid, phys_addr_t *addr, u32 *obj_id)
+{
+	u32 num_blocks = DIV_ROUND_UP_ULL(length, MLX5_SW_ICM_BLOCK_SIZE(dev));
+	u32 out[MLX5_ST_SZ_DW(general_obj_out_cmd_hdr)] = {};
+	u32 in[MLX5_ST_SZ_DW(create_sw_icm_in)] = {};
+	struct mlx5_dm *dm = dev->dm;
+	unsigned long *block_map;
+	u64 icm_start_addr;
+	u32 log_icm_size;
+	u32 max_blocks;
+	u64 block_idx;
+	void *sw_icm;
+	int ret;
+
+	if (!dev->dm)
+		return -EOPNOTSUPP;
+
+	if (!length || (length & (length - 1)) ||
+	    length & (MLX5_SW_ICM_BLOCK_SIZE(dev) - 1))
+		return -EINVAL;
+
+	MLX5_SET(general_obj_in_cmd_hdr, in, opcode,
+		 MLX5_CMD_OP_CREATE_GENERAL_OBJECT);
+	MLX5_SET(general_obj_in_cmd_hdr, in, obj_type, MLX5_OBJ_TYPE_SW_ICM);
+	MLX5_SET(general_obj_in_cmd_hdr, in, uid, uid);
+
+	switch (type) {
+	case MLX5_SW_ICM_TYPE_STEERING:
+		icm_start_addr = MLX5_CAP64_DEV_MEM(dev, steering_sw_icm_start_address);
+		log_icm_size = MLX5_CAP_DEV_MEM(dev, log_steering_sw_icm_size);
+		block_map = dm->steering_sw_icm_alloc_blocks;
+		break;
+	case MLX5_SW_ICM_TYPE_HEADER_MODIFY:
+		icm_start_addr = MLX5_CAP64_DEV_MEM(dev, header_modify_sw_icm_start_address);
+		log_icm_size = MLX5_CAP_DEV_MEM(dev,
+						log_header_modify_sw_icm_size);
+		block_map = dm->header_modify_sw_icm_alloc_blocks;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	if (!block_map)
+		return -EOPNOTSUPP;
+
+	max_blocks = BIT(log_icm_size - MLX5_LOG_SW_ICM_BLOCK_SIZE(dev));
+	spin_lock(&dm->lock);
+	block_idx = bitmap_find_next_zero_area(block_map,
+					       max_blocks,
+					       0,
+					       num_blocks, 0);
+
+	if (block_idx < max_blocks)
+		bitmap_set(block_map,
+			   block_idx, num_blocks);
+
+	spin_unlock(&dm->lock);
+
+	if (block_idx >= max_blocks)
+		return -ENOMEM;
+
+	sw_icm = MLX5_ADDR_OF(create_sw_icm_in, in, sw_icm);
+	icm_start_addr += block_idx << MLX5_LOG_SW_ICM_BLOCK_SIZE(dev);
+	MLX5_SET64(sw_icm, sw_icm, sw_icm_start_addr,
+		   icm_start_addr);
+	MLX5_SET(sw_icm, sw_icm, log_sw_icm_size, ilog2(length));
+
+	ret = mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));
+	if (ret) {
+		spin_lock(&dm->lock);
+		bitmap_clear(block_map,
+			     block_idx, num_blocks);
+		spin_unlock(&dm->lock);
+
+		return ret;
+	}
+
+	*addr = icm_start_addr;
+	*obj_id = MLX5_GET(general_obj_out_cmd_hdr, out, obj_id);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mlx5_dm_sw_icm_alloc);
+
+int mlx5_dm_sw_icm_dealloc(struct mlx5_core_dev *dev, enum mlx5_sw_icm_type type,
+			   u64 length, u16 uid, phys_addr_t addr, u32 obj_id)
+{
+	u32 num_blocks = DIV_ROUND_UP_ULL(length, MLX5_SW_ICM_BLOCK_SIZE(dev));
+	u32 out[MLX5_ST_SZ_DW(general_obj_out_cmd_hdr)] = {};
+	u32 in[MLX5_ST_SZ_DW(general_obj_in_cmd_hdr)] = {};
+	struct mlx5_dm *dm = dev->dm;
+	unsigned long *block_map;
+	u64 icm_start_addr;
+	u64 start_idx;
+	int err;
+
+	if (!dev->dm)
+		return -EOPNOTSUPP;
+
+	switch (type) {
+	case MLX5_SW_ICM_TYPE_STEERING:
+		icm_start_addr = MLX5_CAP64_DEV_MEM(dev, steering_sw_icm_start_address);
+		block_map = dm->steering_sw_icm_alloc_blocks;
+		break;
+	case MLX5_SW_ICM_TYPE_HEADER_MODIFY:
+		icm_start_addr = MLX5_CAP64_DEV_MEM(dev, header_modify_sw_icm_start_address);
+		block_map = dm->header_modify_sw_icm_alloc_blocks;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	MLX5_SET(general_obj_in_cmd_hdr, in, opcode,
+		 MLX5_CMD_OP_DESTROY_GENERAL_OBJECT);
+	MLX5_SET(general_obj_in_cmd_hdr, in, obj_type, MLX5_OBJ_TYPE_SW_ICM);
+	MLX5_SET(general_obj_in_cmd_hdr, in, obj_id, obj_id);
+	MLX5_SET(general_obj_in_cmd_hdr, in, uid, uid);
+
+	err =  mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));
+	if (err)
+		return err;
+
+	start_idx = (addr - icm_start_addr) >> MLX5_LOG_SW_ICM_BLOCK_SIZE(dev);
+	spin_lock(&dm->lock);
+	bitmap_clear(block_map,
+		     start_idx, num_blocks);
+	spin_unlock(&dm->lock);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(mlx5_dm_sw_icm_dealloc);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/main.c b/drivers/net/ethernet/mellanox/mlx5/core/main.c
index 7f8040cb1be0..b111459f88c9 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/main.c
@@ -911,6 +911,10 @@ static int mlx5_init_once(struct mlx5_core_dev *dev, struct mlx5_priv *priv)
 		goto err_sriov_cleanup;
 	}
 
+	dev->dm = mlx5_dm_create(dev);
+	if (IS_ERR(dev->dm))
+		mlx5_core_warn(dev, "Failed to init device memory%d\n", err);
+
 	dev->tracer = mlx5_fw_tracer_create(dev);
 
 	return 0;
@@ -942,6 +946,7 @@ static int mlx5_init_once(struct mlx5_core_dev *dev, struct mlx5_priv *priv)
 static void mlx5_cleanup_once(struct mlx5_core_dev *dev)
 {
 	mlx5_fw_tracer_destroy(dev->tracer);
+	mlx5_dm_cleanup(dev);
 	mlx5_fpga_cleanup(dev);
 	mlx5_sriov_cleanup(dev);
 	mlx5_eswitch_cleanup(dev->priv.eswitch);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h b/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
index 8213c994e205..3dc72db92cbd 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
@@ -174,6 +174,9 @@ int mlx5_set_mtpps(struct mlx5_core_dev *mdev, u32 *mtpps, u32 mtpps_size);
 int mlx5_query_mtppse(struct mlx5_core_dev *mdev, u8 pin, u8 *arm, u8 *mode);
 int mlx5_set_mtppse(struct mlx5_core_dev *mdev, u8 pin, u8 arm, u8 mode);
 
+struct mlx5_dm *mlx5_dm_create(struct mlx5_core_dev *dev);
+void mlx5_dm_cleanup(struct mlx5_core_dev *dev);
+
 #define MLX5_PPS_CAP(mdev) (MLX5_CAP_GEN((mdev), pps) &&		\
 			    MLX5_CAP_GEN((mdev), pps_modify) &&		\
 			    MLX5_CAP_MCAM_FEATURE((mdev), mtpps_fs) &&	\
* Unmerged path include/linux/mlx5/driver.h
