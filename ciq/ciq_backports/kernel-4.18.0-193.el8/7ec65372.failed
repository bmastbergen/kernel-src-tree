tcp: add stat of data packet reordering events

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Wei Wang <weiwan@google.com>
commit 7ec65372ca534217b53fd208500cf7aac223a383
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/7ec65372.failed

Introduce a new TCP stats to record the number of reordering events seen
and expose it in both tcp_info (TCP_INFO) and opt_stats
(SOF_TIMESTAMPING_OPT_STATS).
Application can use this stats to track the frequency of the reordering
events in addition to the existing reordering stats which tracks the
magnitude of the latest reordering event.

Note: this new stats tracks reordering events triggered by ACKs, which
could often be fewer than the actual number of packets being delivered
out-of-order.

	Signed-off-by: Wei Wang <weiwan@google.com>
	Signed-off-by: Eric Dumazet <edumazet@google.com>
	Acked-by: Neal Cardwell <ncardwell@google.com>
	Acked-by: Soheil Hassas Yeganeh <soheil@google.com>
	Acked-by: Yuchung Cheng <ycheng@google.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 7ec65372ca534217b53fd208500cf7aac223a383)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/uapi/linux/tcp.h
#	net/ipv4/tcp.c
diff --cc include/uapi/linux/tcp.h
index e3f6ed8a7064,e02d31986ff9..000000000000
--- a/include/uapi/linux/tcp.h
+++ b/include/uapi/linux/tcp.h
@@@ -235,6 -235,11 +235,14 @@@ struct tcp_info 
  
  	__u32	tcpi_delivered;
  	__u32	tcpi_delivered_ce;
++<<<<<<< HEAD
++=======
+ 
+ 	__u64	tcpi_bytes_sent;     /* RFC4898 tcpEStatsPerfHCDataOctetsOut */
+ 	__u64	tcpi_bytes_retrans;  /* RFC4898 tcpEStatsPerfOctetsRetrans */
+ 	__u32	tcpi_dsack_dups;     /* RFC4898 tcpEStatsStackDSACKDups */
+ 	__u32	tcpi_reord_seen;     /* reordering events seen */
++>>>>>>> 7ec65372ca53 (tcp: add stat of data packet reordering events)
  };
  
  /* netlink attributes types for SCM_TIMESTAMPING_OPT_STATS */
@@@ -257,7 -262,10 +265,14 @@@ enum 
  	TCP_NLA_SND_SSTHRESH,	/* Slow start size threshold */
  	TCP_NLA_DELIVERED,	/* Data pkts delivered incl. out-of-order */
  	TCP_NLA_DELIVERED_CE,	/* Like above but only ones w/ CE marks */
- 
++<<<<<<< HEAD
++
++=======
+ 	TCP_NLA_BYTES_SENT,	/* Data bytes sent including retransmission */
+ 	TCP_NLA_BYTES_RETRANS,	/* Data bytes retransmitted */
+ 	TCP_NLA_DSACK_DUPS,	/* DSACK blocks received */
+ 	TCP_NLA_REORD_SEEN,	/* reordering events seen */
++>>>>>>> 7ec65372ca53 (tcp: add stat of data packet reordering events)
  };
  
  /* for TCP_MD5SIG socket option */
diff --cc net/ipv4/tcp.c
index 6da266d09f97,31fa1c080f28..000000000000
--- a/net/ipv4/tcp.c
+++ b/net/ipv4/tcp.c
@@@ -2611,8 -2594,10 +2611,15 @@@ int tcp_disconnect(struct sock *sk, in
  	sk->sk_rx_dst = NULL;
  	tcp_saved_syn_free(tp);
  	tp->compressed_ack = 0;
++<<<<<<< HEAD
 +	tp->bytes_acked = 0;
 +	tp->bytes_received = 0;
++=======
+ 	tp->bytes_sent = 0;
+ 	tp->bytes_retrans = 0;
+ 	tp->dsack_dups = 0;
+ 	tp->reord_seen = 0;
++>>>>>>> 7ec65372ca53 (tcp: add stat of data packet reordering events)
  
  	/* Clean up fastopen related fields */
  	tcp_free_fastopen_req(tp);
@@@ -3222,6 -3205,10 +3229,13 @@@ void tcp_get_info(struct sock *sk, stru
  		info->tcpi_delivery_rate = rate64;
  	info->tcpi_delivered = tp->delivered;
  	info->tcpi_delivered_ce = tp->delivered_ce;
++<<<<<<< HEAD
++=======
+ 	info->tcpi_bytes_sent = tp->bytes_sent;
+ 	info->tcpi_bytes_retrans = tp->bytes_retrans;
+ 	info->tcpi_dsack_dups = tp->dsack_dups;
+ 	info->tcpi_reord_seen = tp->reord_seen;
++>>>>>>> 7ec65372ca53 (tcp: add stat of data packet reordering events)
  	unlock_sock_fast(sk, slow);
  }
  EXPORT_SYMBOL_GPL(tcp_get_info);
@@@ -3246,6 -3233,10 +3260,13 @@@ static size_t tcp_opt_stats_get_size(vo
  		nla_total_size(sizeof(u32)) + /* TCP_NLA_SND_SSTHRESH */
  		nla_total_size(sizeof(u32)) + /* TCP_NLA_DELIVERED */
  		nla_total_size(sizeof(u32)) + /* TCP_NLA_DELIVERED_CE */
++<<<<<<< HEAD
++=======
+ 		nla_total_size_64bit(sizeof(u64)) + /* TCP_NLA_BYTES_SENT */
+ 		nla_total_size_64bit(sizeof(u64)) + /* TCP_NLA_BYTES_RETRANS */
+ 		nla_total_size(sizeof(u32)) + /* TCP_NLA_DSACK_DUPS */
+ 		nla_total_size(sizeof(u32)) + /* TCP_NLA_REORD_SEEN */
++>>>>>>> 7ec65372ca53 (tcp: add stat of data packet reordering events)
  		0;
  }
  
@@@ -3293,6 -3284,13 +3314,16 @@@ struct sk_buff *tcp_get_timestamping_op
  	nla_put_u32(stats, TCP_NLA_SNDQ_SIZE, tp->write_seq - tp->snd_una);
  	nla_put_u8(stats, TCP_NLA_CA_STATE, inet_csk(sk)->icsk_ca_state);
  
++<<<<<<< HEAD
++=======
+ 	nla_put_u64_64bit(stats, TCP_NLA_BYTES_SENT, tp->bytes_sent,
+ 			  TCP_NLA_PAD);
+ 	nla_put_u64_64bit(stats, TCP_NLA_BYTES_RETRANS, tp->bytes_retrans,
+ 			  TCP_NLA_PAD);
+ 	nla_put_u32(stats, TCP_NLA_DSACK_DUPS, tp->dsack_dups);
+ 	nla_put_u32(stats, TCP_NLA_REORD_SEEN, tp->reord_seen);
+ 
++>>>>>>> 7ec65372ca53 (tcp: add stat of data packet reordering events)
  	return stats;
  }
  
diff --git a/include/linux/tcp.h b/include/linux/tcp.h
index 8c66475339ed..166a292f5318 100644
--- a/include/linux/tcp.h
+++ b/include/linux/tcp.h
@@ -215,8 +215,7 @@ struct tcp_sock {
 #define TCP_RACK_RECOVERY_THRESH 16
 		u8 reo_wnd_persist:5, /* No. of recovery since last adj */
 		   dsack_seen:1, /* Whether DSACK seen after last adj */
-		   advanced:1,	 /* mstamp advanced since last lost marking */
-		   reord:1;	 /* reordering detected */
+		   advanced:1;	 /* mstamp advanced since last lost marking */
 	} rack;
 	u16	advmss;		/* Advertised MSS			*/
 	u8	compressed_ack;
@@ -262,6 +261,7 @@ struct tcp_sock {
 	u8	ecn_flags;	/* ECN status bits.			*/
 	u8	keepalive_probes; /* num of allowed keep alive probes	*/
 	u32	reordering;	/* Packet reordering metric.		*/
+	u32	reord_seen;	/* number of data packet reordering events */
 	u32	snd_up;		/* Urgent pointer		*/
 
 /*
* Unmerged path include/uapi/linux/tcp.h
* Unmerged path net/ipv4/tcp.c
diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
index 50c5aa90e243..019bb3f4cb1a 100644
--- a/net/ipv4/tcp_input.c
+++ b/net/ipv4/tcp_input.c
@@ -909,8 +909,8 @@ static void tcp_check_sack_reordering(struct sock *sk, const u32 low_seq,
 				       sock_net(sk)->ipv4.sysctl_tcp_max_reordering);
 	}
 
-	tp->rack.reord = 1;
 	/* This exciting event is worth to be remembered. 8) */
+	tp->reord_seen++;
 	NET_INC_STATS(sock_net(sk),
 		      ts ? LINUX_MIB_TCPTSREORDER : LINUX_MIB_TCPSACKREORDER);
 }
@@ -1888,6 +1888,7 @@ static void tcp_check_reno_reordering(struct sock *sk, const int addend)
 
 	tp->reordering = min_t(u32, tp->packets_out + addend,
 			       sock_net(sk)->ipv4.sysctl_tcp_max_reordering);
+	tp->reord_seen++;
 	NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPRENOREORDER);
 }
 
diff --git a/net/ipv4/tcp_recovery.c b/net/ipv4/tcp_recovery.c
index 71593e4400ab..c81aadff769b 100644
--- a/net/ipv4/tcp_recovery.c
+++ b/net/ipv4/tcp_recovery.c
@@ -25,7 +25,7 @@ static u32 tcp_rack_reo_wnd(const struct sock *sk)
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 
-	if (!tp->rack.reord) {
+	if (!tp->reord_seen) {
 		/* If reordering has not been observed, be aggressive during
 		 * the recovery or starting the recovery by DUPACK threshold.
 		 */
