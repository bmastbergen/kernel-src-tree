mm/hotplug: fix offline undo_isolate_page_range()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Qian Cai <cai@lca.pw>
commit 9b7ea46a82b31c74a37e6ff1c2a1df7d53e392ab
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/9b7ea46a.failed

Commit f1dd2cd13c4b ("mm, memory_hotplug: do not associate hotadded
memory to zones until online") introduced move_pfn_range_to_zone() which
calls memmap_init_zone() during onlining a memory block.
memmap_init_zone() will reset pagetype flags and makes migrate type to
be MOVABLE.

However, in __offline_pages(), it also call undo_isolate_page_range()
after offline_isolated_pages() to do the same thing.  Due to commit
2ce13640b3f4 ("mm: __first_valid_page skip over offline pages") changed
__first_valid_page() to skip offline pages, undo_isolate_page_range()
here just waste CPU cycles looping around the offlining PFN range while
doing nothing, because __first_valid_page() will return NULL as
offline_isolated_pages() has already marked all memory sections within
the pfn range as offline via offline_mem_sections().

Also, after calling the "useless" undo_isolate_page_range() here, it
reaches the point of no returning by notifying MEM_OFFLINE.  Those pages
will be marked as MIGRATE_MOVABLE again once onlining.  The only thing
left to do is to decrease the number of isolated pageblocks zone counter
which would make some paths of the page allocation slower that the above
commit introduced.

Even if alloc_contig_range() can be used to isolate 16GB-hugetlb pages
on ppc64, an "int" should still be enough to represent the number of
pageblocks there.  Fix an incorrect comment along the way.

[cai@lca.pw: v4]
  Link: http://lkml.kernel.org/r/20190314150641.59358-1-cai@lca.pw
Link: http://lkml.kernel.org/r/20190313143133.46200-1-cai@lca.pw
Fixes: 2ce13640b3f4 ("mm: __first_valid_page skip over offline pages")
	Signed-off-by: Qian Cai <cai@lca.pw>
	Acked-by: Michal Hocko <mhocko@suse.com>
	Reviewed-by: Oscar Salvador <osalvador@suse.de>
	Cc: Vlastimil Babka <vbabka@suse.cz>
	Cc: <stable@vger.kernel.org>	[4.13+]
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 9b7ea46a82b31c74a37e6ff1c2a1df7d53e392ab)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/page-isolation.h
#	mm/memory_hotplug.c
#	mm/page_alloc.c
#	mm/page_isolation.c
diff --cc include/linux/page-isolation.h
index 4ae347cbc36d,280ae96dc4c3..000000000000
--- a/include/linux/page-isolation.h
+++ b/include/linux/page-isolation.h
@@@ -38,12 -41,6 +38,15 @@@ int move_freepages_block(struct zone *z
  
  /*
   * Changes migrate type in [start_pfn, end_pfn) to be MIGRATE_ISOLATE.
++<<<<<<< HEAD
 + * If specified range includes migrate types other than MOVABLE or CMA,
 + * this will fail with -EBUSY.
 + *
 + * For isolating all pages in the range finally, the caller have to
 + * free all pages in the range. test_page_isolated() can be used for
 + * test it.
++=======
++>>>>>>> 9b7ea46a82b3 (mm/hotplug: fix offline undo_isolate_page_range())
   */
  int
  start_isolate_page_range(unsigned long start_pfn, unsigned long end_pfn,
diff --cc mm/memory_hotplug.c
index 46c77cfd9c7d,0e0a16021fd5..000000000000
--- a/mm/memory_hotplug.c
+++ b/mm/memory_hotplug.c
@@@ -1656,9 -1600,13 +1656,19 @@@ static int __ref __offline_pages(unsign
  
  	/* set above range as isolated */
  	ret = start_isolate_page_range(start_pfn, end_pfn,
++<<<<<<< HEAD
 +				       MIGRATE_MOVABLE, true);
 +	if (ret)
 +		return ret;
++=======
+ 				       MIGRATE_MOVABLE,
+ 				       SKIP_HWPOISON | REPORT_FAILURE);
+ 	if (ret < 0) {
+ 		reason = "failure to isolate range";
+ 		goto failed_removal;
+ 	}
+ 	nr_isolate_pageblock = ret;
++>>>>>>> 9b7ea46a82b3 (mm/hotplug: fix offline undo_isolate_page_range())
  
  	arg.start_pfn = start_pfn;
  	arg.nr_pages = nr_pages;
diff --cc mm/page_alloc.c
index a37d44e37bbf,d96ca5bc555b..000000000000
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@@ -7963,9 -8232,8 +7963,14 @@@ int alloc_contig_range(unsigned long st
  	 */
  
  	ret = start_isolate_page_range(pfn_max_align_down(start),
++<<<<<<< HEAD
 +				       pfn_max_align_up(end), migratetype,
 +				       false);
 +	if (ret)
++=======
+ 				       pfn_max_align_up(end), migratetype, 0);
+ 	if (ret < 0)
++>>>>>>> 9b7ea46a82b3 (mm/hotplug: fix offline undo_isolate_page_range())
  		return ret;
  
  	/*
diff --cc mm/page_isolation.c
index 43e085608846,bf4159d771c7..000000000000
--- a/mm/page_isolation.c
+++ b/mm/page_isolation.c
@@@ -171,21 -175,24 +177,24 @@@ __first_valid_page(unsigned long pfn, u
   *
   * Making page-allocation-type to be MIGRATE_ISOLATE means free pages in
   * the range will never be allocated. Any free pages and pages freed in the
-  * future will not be allocated again.
-  *
-  * start_pfn/end_pfn must be aligned to pageblock_order.
-  * Return 0 on success and -EBUSY if any part of range cannot be isolated.
+  * future will not be allocated again. If specified range includes migrate types
+  * other than MOVABLE or CMA, this will fail with -EBUSY. For isolating all
+  * pages in the range finally, the caller have to free all pages in the range.
+  * test_page_isolated() can be used for test it.
   *
   * There is no high level synchronization mechanism that prevents two threads
-  * from trying to isolate overlapping ranges.  If this happens, one thread
+  * from trying to isolate overlapping ranges. If this happens, one thread
   * will notice pageblocks in the overlapping range already set to isolate.
   * This happens in set_migratetype_isolate, and set_migratetype_isolate
-  * returns an error.  We then clean up by restoring the migration type on
-  * pageblocks we may have modified and return -EBUSY to caller.  This
+  * returns an error. We then clean up by restoring the migration type on
+  * pageblocks we may have modified and return -EBUSY to caller. This
   * prevents two threads from simultaneously working on overlapping ranges.
+  *
+  * Return: the number of isolated pageblocks on success and -EBUSY if any part
+  * of range cannot be isolated.
   */
  int start_isolate_page_range(unsigned long start_pfn, unsigned long end_pfn,
 -			     unsigned migratetype, int flags)
 +			     unsigned migratetype, bool skip_hwpoisoned_pages)
  {
  	unsigned long pfn;
  	unsigned long undo_pfn;
@@@ -198,13 -206,15 +208,22 @@@
  	     pfn < end_pfn;
  	     pfn += pageblock_nr_pages) {
  		page = __first_valid_page(pfn, pageblock_nr_pages);
++<<<<<<< HEAD
 +		if (page &&
 +		    set_migratetype_isolate(page, migratetype, skip_hwpoisoned_pages)) {
 +			undo_pfn = pfn;
 +			goto undo;
++=======
+ 		if (page) {
+ 			if (set_migratetype_isolate(page, migratetype, flags)) {
+ 				undo_pfn = pfn;
+ 				goto undo;
+ 			}
+ 			nr_isolate_pageblock++;
++>>>>>>> 9b7ea46a82b3 (mm/hotplug: fix offline undo_isolate_page_range())
  		}
  	}
- 	return 0;
+ 	return nr_isolate_pageblock;
  undo:
  	for (pfn = start_pfn;
  	     pfn < undo_pfn;
* Unmerged path include/linux/page-isolation.h
* Unmerged path mm/memory_hotplug.c
* Unmerged path mm/page_alloc.c
* Unmerged path mm/page_isolation.c
diff --git a/mm/sparse.c b/mm/sparse.c
index 57360bf41bed..0792a552303b 100644
--- a/mm/sparse.c
+++ b/mm/sparse.c
@@ -539,7 +539,7 @@ void online_mem_sections(unsigned long start_pfn, unsigned long end_pfn)
 }
 
 #ifdef CONFIG_MEMORY_HOTREMOVE
-/* Mark all memory sections within the pfn range as online */
+/* Mark all memory sections within the pfn range as offline */
 void offline_mem_sections(unsigned long start_pfn, unsigned long end_pfn)
 {
 	unsigned long pfn;
