iommu/io-pgtable: Remove unused ->tlb_sync() callback

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
Rebuild_CHGLOG: - [iommu] io-pgtable: Remove unused ->tlb_sync() callback (Jerry Snitselaar) [1729845]
Rebuild_FUZZ: 94.00%
commit-author Will Deacon <will@kernel.org>
commit e953f7f2fa78d1c7fd064171f88457c6b1e21af9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/e953f7f2.failed

The ->tlb_sync() callback is no longer used, so it can be removed.

	Signed-off-by: Will Deacon <will@kernel.org>
(cherry picked from commit e953f7f2fa78d1c7fd064171f88457c6b1e21af9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/panfrost/panfrost_mmu.c
#	drivers/iommu/arm-smmu-v3.c
#	drivers/iommu/arm-smmu.c
#	drivers/iommu/io-pgtable-arm-v7s.c
#	drivers/iommu/io-pgtable-arm.c
#	drivers/iommu/ipmmu-vmsa.c
#	drivers/iommu/msm_iommu.c
#	drivers/iommu/mtk_iommu.c
#	drivers/iommu/qcom_iommu.c
#	include/linux/io-pgtable.h
diff --cc drivers/iommu/arm-smmu-v3.c
index c08a34136024,231093413ff9..000000000000
--- a/drivers/iommu/arm-smmu-v3.c
+++ b/drivers/iommu/arm-smmu-v3.c
@@@ -1598,10 -1596,37 +1591,16 @@@ static void arm_smmu_tlb_inv_range_nosy
  	} while (size -= granule);
  }
  
 -static void arm_smmu_tlb_inv_page_nosync(unsigned long iova, size_t granule,
 -					 void *cookie)
 -{
 -	arm_smmu_tlb_inv_range_nosync(iova, granule, granule, true, cookie);
 -}
 -
 -static void arm_smmu_tlb_inv_walk(unsigned long iova, size_t size,
 -				  size_t granule, void *cookie)
 -{
 -	struct arm_smmu_domain *smmu_domain = cookie;
 -	struct arm_smmu_device *smmu = smmu_domain->smmu;
 -
 -	arm_smmu_tlb_inv_range_nosync(iova, size, granule, false, cookie);
 -	arm_smmu_cmdq_issue_sync(smmu);
 -}
 -
 -static void arm_smmu_tlb_inv_leaf(unsigned long iova, size_t size,
 -				  size_t granule, void *cookie)
 -{
 -	struct arm_smmu_domain *smmu_domain = cookie;
 -	struct arm_smmu_device *smmu = smmu_domain->smmu;
 -
 -	arm_smmu_tlb_inv_range_nosync(iova, size, granule, true, cookie);
 -	arm_smmu_cmdq_issue_sync(smmu);
 -}
 -
 -static const struct iommu_flush_ops arm_smmu_flush_ops = {
 +static const struct iommu_gather_ops arm_smmu_gather_ops = {
  	.tlb_flush_all	= arm_smmu_tlb_inv_context,
++<<<<<<< HEAD
 +	.tlb_add_flush	= arm_smmu_tlb_inv_range_nosync,
 +	.tlb_sync	= arm_smmu_tlb_sync,
++=======
+ 	.tlb_flush_walk = arm_smmu_tlb_inv_walk,
+ 	.tlb_flush_leaf = arm_smmu_tlb_inv_leaf,
+ 	.tlb_add_page	= arm_smmu_tlb_inv_page_nosync,
++>>>>>>> e953f7f2fa78 (iommu/io-pgtable: Remove unused ->tlb_sync() callback)
  };
  
  /* IOMMU API */
diff --cc drivers/iommu/arm-smmu.c
index 58f85e7c33c2,07a267c437d6..000000000000
--- a/drivers/iommu/arm-smmu.c
+++ b/drivers/iommu/arm-smmu.c
@@@ -241,6 -248,13 +241,16 @@@ enum arm_smmu_domain_stage 
  	ARM_SMMU_DOMAIN_BYPASS,
  };
  
++<<<<<<< HEAD
++=======
+ struct arm_smmu_flush_ops {
+ 	struct iommu_flush_ops		tlb;
+ 	void (*tlb_inv_range)(unsigned long iova, size_t size, size_t granule,
+ 			      bool leaf, void *cookie);
+ 	void (*tlb_sync)(void *cookie);
+ };
+ 
++>>>>>>> e953f7f2fa78 (iommu/io-pgtable: Remove unused ->tlb_sync() callback)
  struct arm_smmu_domain {
  	struct arm_smmu_device		*smmu;
  	struct io_pgtable_ops		*pgtbl_ops;
@@@ -540,22 -554,66 +550,85 @@@ static void arm_smmu_tlb_inv_vmid_nosyn
  	writel_relaxed(smmu_domain->cfg.vmid, base + ARM_SMMU_GR0_TLBIVMID);
  }
  
++<<<<<<< HEAD
 +static const struct iommu_gather_ops arm_smmu_s1_tlb_ops = {
 +	.tlb_flush_all	= arm_smmu_tlb_inv_context_s1,
 +	.tlb_add_flush	= arm_smmu_tlb_inv_range_nosync,
 +	.tlb_sync	= arm_smmu_tlb_sync_context,
 +};
 +
 +static const struct iommu_gather_ops arm_smmu_s2_tlb_ops_v2 = {
 +	.tlb_flush_all	= arm_smmu_tlb_inv_context_s2,
 +	.tlb_add_flush	= arm_smmu_tlb_inv_range_nosync,
 +	.tlb_sync	= arm_smmu_tlb_sync_context,
 +};
 +
 +static const struct iommu_gather_ops arm_smmu_s2_tlb_ops_v1 = {
 +	.tlb_flush_all	= arm_smmu_tlb_inv_context_s2,
 +	.tlb_add_flush	= arm_smmu_tlb_inv_vmid_nosync,
 +	.tlb_sync	= arm_smmu_tlb_sync_vmid,
++=======
+ static void arm_smmu_tlb_inv_walk(unsigned long iova, size_t size,
+ 				  size_t granule, void *cookie)
+ {
+ 	struct arm_smmu_domain *smmu_domain = cookie;
+ 	const struct arm_smmu_flush_ops *ops = smmu_domain->flush_ops;
+ 
+ 	ops->tlb_inv_range(iova, size, granule, false, cookie);
+ 	ops->tlb_sync(cookie);
+ }
+ 
+ static void arm_smmu_tlb_inv_leaf(unsigned long iova, size_t size,
+ 				  size_t granule, void *cookie)
+ {
+ 	struct arm_smmu_domain *smmu_domain = cookie;
+ 	const struct arm_smmu_flush_ops *ops = smmu_domain->flush_ops;
+ 
+ 	ops->tlb_inv_range(iova, size, granule, true, cookie);
+ 	ops->tlb_sync(cookie);
+ }
+ 
+ static void arm_smmu_tlb_add_page(unsigned long iova, size_t granule,
+ 				  void *cookie)
+ {
+ 	struct arm_smmu_domain *smmu_domain = cookie;
+ 	const struct arm_smmu_flush_ops *ops = smmu_domain->flush_ops;
+ 
+ 	ops->tlb_inv_range(iova, granule, granule, true, cookie);
+ }
+ 
+ static const struct arm_smmu_flush_ops arm_smmu_s1_tlb_ops = {
+ 	.tlb = {
+ 		.tlb_flush_all	= arm_smmu_tlb_inv_context_s1,
+ 		.tlb_flush_walk	= arm_smmu_tlb_inv_walk,
+ 		.tlb_flush_leaf	= arm_smmu_tlb_inv_leaf,
+ 		.tlb_add_page	= arm_smmu_tlb_add_page,
+ 	},
+ 	.tlb_inv_range		= arm_smmu_tlb_inv_range_nosync,
+ 	.tlb_sync		= arm_smmu_tlb_sync_context,
+ };
+ 
+ static const struct arm_smmu_flush_ops arm_smmu_s2_tlb_ops_v2 = {
+ 	.tlb = {
+ 		.tlb_flush_all	= arm_smmu_tlb_inv_context_s2,
+ 		.tlb_flush_walk	= arm_smmu_tlb_inv_walk,
+ 		.tlb_flush_leaf	= arm_smmu_tlb_inv_leaf,
+ 		.tlb_add_page	= arm_smmu_tlb_add_page,
+ 	},
+ 	.tlb_inv_range		= arm_smmu_tlb_inv_range_nosync,
+ 	.tlb_sync		= arm_smmu_tlb_sync_context,
+ };
+ 
+ static const struct arm_smmu_flush_ops arm_smmu_s2_tlb_ops_v1 = {
+ 	.tlb = {
+ 		.tlb_flush_all	= arm_smmu_tlb_inv_context_s2,
+ 		.tlb_flush_walk	= arm_smmu_tlb_inv_walk,
+ 		.tlb_flush_leaf	= arm_smmu_tlb_inv_leaf,
+ 		.tlb_add_page	= arm_smmu_tlb_add_page,
+ 	},
+ 	.tlb_inv_range		= arm_smmu_tlb_inv_vmid_nosync,
+ 	.tlb_sync		= arm_smmu_tlb_sync_vmid,
++>>>>>>> e953f7f2fa78 (iommu/io-pgtable: Remove unused ->tlb_sync() callback)
  };
  
  static irqreturn_t arm_smmu_context_fault(int irq, void *dev)
@@@ -1327,9 -1386,9 +1400,13 @@@ static void arm_smmu_iotlb_sync(struct 
  	struct arm_smmu_domain *smmu_domain = to_smmu_domain(domain);
  	struct arm_smmu_device *smmu = smmu_domain->smmu;
  
 -	if (smmu_domain->flush_ops) {
 +	if (smmu_domain->tlb_ops) {
  		arm_smmu_rpm_get(smmu);
++<<<<<<< HEAD
 +		smmu_domain->tlb_ops->tlb_sync(smmu_domain);
++=======
+ 		smmu_domain->flush_ops->tlb_sync(smmu_domain);
++>>>>>>> e953f7f2fa78 (iommu/io-pgtable: Remove unused ->tlb_sync() callback)
  		arm_smmu_rpm_put(smmu);
  	}
  }
diff --cc drivers/iommu/io-pgtable-arm-v7s.c
index a0032d1cb4ef,203894fb6765..000000000000
--- a/drivers/iommu/io-pgtable-arm-v7s.c
+++ b/drivers/iommu/io-pgtable-arm-v7s.c
@@@ -820,23 -808,16 +820,31 @@@ static void dummy_tlb_flush(unsigned lo
  	WARN_ON(!(size & cfg_cookie->pgsize_bitmap));
  }
  
 -static void dummy_tlb_add_page(unsigned long iova, size_t granule, void *cookie)
 +static void dummy_tlb_add_flush(unsigned long iova, size_t size,
 +				size_t granule, bool leaf, void *cookie)
 +{
 +	dummy_tlb_flush(iova, size, granule, cookie);
 +}
 +
++<<<<<<< HEAD
 +static void dummy_tlb_sync(void *cookie)
  {
 -	dummy_tlb_flush(iova, granule, granule, cookie);
 +	WARN_ON(cookie != cfg_cookie);
  }
  
 +static const struct iommu_gather_ops dummy_tlb_ops = {
 +	.tlb_flush_all	= dummy_tlb_flush_all,
 +	.tlb_flush_walk	= dummy_tlb_flush,
 +	.tlb_flush_leaf	= dummy_tlb_flush,
 +	.tlb_add_flush	= dummy_tlb_add_flush,
 +	.tlb_sync	= dummy_tlb_sync,
++=======
+ static const struct iommu_flush_ops dummy_tlb_ops = {
+ 	.tlb_flush_all	= dummy_tlb_flush_all,
+ 	.tlb_flush_walk	= dummy_tlb_flush,
+ 	.tlb_flush_leaf	= dummy_tlb_flush,
+ 	.tlb_add_page	= dummy_tlb_add_page,
++>>>>>>> e953f7f2fa78 (iommu/io-pgtable: Remove unused ->tlb_sync() callback)
  };
  
  #define __FAIL(ops)	({				\
diff --cc drivers/iommu/io-pgtable-arm.c
index df587d77518c,f35516744965..000000000000
--- a/drivers/iommu/io-pgtable-arm.c
+++ b/drivers/iommu/io-pgtable-arm.c
@@@ -1118,23 -1075,16 +1118,31 @@@ static void dummy_tlb_flush(unsigned lo
  	WARN_ON(!(size & cfg_cookie->pgsize_bitmap));
  }
  
 -static void dummy_tlb_add_page(unsigned long iova, size_t granule, void *cookie)
 +static void dummy_tlb_add_flush(unsigned long iova, size_t size,
 +				size_t granule, bool leaf, void *cookie)
 +{
 +	dummy_tlb_flush(iova, size, granule, cookie);
 +}
 +
++<<<<<<< HEAD
 +static void dummy_tlb_sync(void *cookie)
  {
 -	dummy_tlb_flush(iova, granule, granule, cookie);
 +	WARN_ON(cookie != cfg_cookie);
  }
  
 +static const struct iommu_gather_ops dummy_tlb_ops __initconst = {
 +	.tlb_flush_all	= dummy_tlb_flush_all,
 +	.tlb_flush_walk	= dummy_tlb_flush,
 +	.tlb_flush_leaf	= dummy_tlb_flush,
 +	.tlb_add_flush	= dummy_tlb_add_flush,
 +	.tlb_sync	= dummy_tlb_sync,
++=======
+ static const struct iommu_flush_ops dummy_tlb_ops __initconst = {
+ 	.tlb_flush_all	= dummy_tlb_flush_all,
+ 	.tlb_flush_walk	= dummy_tlb_flush,
+ 	.tlb_flush_leaf	= dummy_tlb_flush,
+ 	.tlb_add_page	= dummy_tlb_add_page,
++>>>>>>> e953f7f2fa78 (iommu/io-pgtable: Remove unused ->tlb_sync() callback)
  };
  
  static void __init arm_lpae_dump_ops(struct io_pgtable_ops *ops)
diff --cc drivers/iommu/ipmmu-vmsa.c
index c842cf9ce2c3,a2b8eff4c1f7..000000000000
--- a/drivers/iommu/ipmmu-vmsa.c
+++ b/drivers/iommu/ipmmu-vmsa.c
@@@ -349,16 -361,16 +349,21 @@@ static void ipmmu_tlb_flush_all(void *c
  	ipmmu_tlb_invalidate(domain);
  }
  
 -static void ipmmu_tlb_flush(unsigned long iova, size_t size,
 -				size_t granule, void *cookie)
 +static void ipmmu_tlb_add_flush(unsigned long iova, size_t size,
 +				size_t granule, bool leaf, void *cookie)
  {
 -	ipmmu_tlb_flush_all(cookie);
 +	/* The hardware doesn't support selective TLB flush. */
  }
  
 -static const struct iommu_flush_ops ipmmu_flush_ops = {
 +static const struct iommu_gather_ops ipmmu_gather_ops = {
  	.tlb_flush_all = ipmmu_tlb_flush_all,
++<<<<<<< HEAD
 +	.tlb_add_flush = ipmmu_tlb_add_flush,
 +	.tlb_sync = ipmmu_tlb_flush_all,
++=======
+ 	.tlb_flush_walk = ipmmu_tlb_flush,
+ 	.tlb_flush_leaf = ipmmu_tlb_flush,
++>>>>>>> e953f7f2fa78 (iommu/io-pgtable: Remove unused ->tlb_sync() callback)
  };
  
  /* -----------------------------------------------------------------------------
diff --cc drivers/iommu/msm_iommu.c
index bc2cef99bb30,ccfc7ed230ef..000000000000
--- a/drivers/iommu/msm_iommu.c
+++ b/drivers/iommu/msm_iommu.c
@@@ -179,20 -168,28 +179,45 @@@ fail
  	return;
  }
  
++<<<<<<< HEAD
 +static void __flush_iotlb_sync(void *cookie)
 +{
 +	/*
 +	 * Nothing is needed here, the barrier to guarantee
 +	 * completion of the tlb sync operation is implicitly
 +	 * taken care when the iommu client does a writel before
 +	 * kick starting the other master.
 +	 */
 +}
 +
 +static const struct iommu_gather_ops msm_iommu_gather_ops = {
 +	.tlb_flush_all = __flush_iotlb,
 +	.tlb_add_flush = __flush_iotlb_range,
 +	.tlb_sync = __flush_iotlb_sync,
++=======
+ static void __flush_iotlb_walk(unsigned long iova, size_t size,
+ 			       size_t granule, void *cookie)
+ {
+ 	__flush_iotlb_range(iova, size, granule, false, cookie);
+ }
+ 
+ static void __flush_iotlb_leaf(unsigned long iova, size_t size,
+ 			       size_t granule, void *cookie)
+ {
+ 	__flush_iotlb_range(iova, size, granule, true, cookie);
+ }
+ 
+ static void __flush_iotlb_page(unsigned long iova, size_t granule, void *cookie)
+ {
+ 	__flush_iotlb_range(iova, granule, granule, true, cookie);
+ }
+ 
+ static const struct iommu_flush_ops msm_iommu_flush_ops = {
+ 	.tlb_flush_all = __flush_iotlb,
+ 	.tlb_flush_walk = __flush_iotlb_walk,
+ 	.tlb_flush_leaf = __flush_iotlb_leaf,
+ 	.tlb_add_page = __flush_iotlb_page,
++>>>>>>> e953f7f2fa78 (iommu/io-pgtable: Remove unused ->tlb_sync() callback)
  };
  
  static int msm_iommu_alloc_ctx(unsigned long *map, int start, int end)
diff --cc drivers/iommu/mtk_iommu.c
index f9f69f7111a9,3785750bdb44..000000000000
--- a/drivers/iommu/mtk_iommu.c
+++ b/drivers/iommu/mtk_iommu.c
@@@ -196,10 -188,31 +196,16 @@@ static void mtk_iommu_tlb_sync(void *co
  	}
  }
  
 -static void mtk_iommu_tlb_flush_walk(unsigned long iova, size_t size,
 -				     size_t granule, void *cookie)
 -{
 -	mtk_iommu_tlb_add_flush_nosync(iova, size, granule, false, cookie);
 -	mtk_iommu_tlb_sync(cookie);
 -}
 -
 -static void mtk_iommu_tlb_flush_leaf(unsigned long iova, size_t size,
 -				     size_t granule, void *cookie)
 -{
 -	mtk_iommu_tlb_add_flush_nosync(iova, size, granule, true, cookie);
 -	mtk_iommu_tlb_sync(cookie);
 -}
 -
 -static void mtk_iommu_tlb_flush_page_nosync(unsigned long iova, size_t granule,
 -					    void *cookie)
 -{
 -	mtk_iommu_tlb_add_flush_nosync(iova, granule, granule, true, cookie);
 -}
 -
 -static const struct iommu_flush_ops mtk_iommu_flush_ops = {
 +static const struct iommu_gather_ops mtk_iommu_gather_ops = {
  	.tlb_flush_all = mtk_iommu_tlb_flush_all,
++<<<<<<< HEAD
 +	.tlb_add_flush = mtk_iommu_tlb_add_flush_nosync,
 +	.tlb_sync = mtk_iommu_tlb_sync,
++=======
+ 	.tlb_flush_walk = mtk_iommu_tlb_flush_walk,
+ 	.tlb_flush_leaf = mtk_iommu_tlb_flush_leaf,
+ 	.tlb_add_page = mtk_iommu_tlb_flush_page_nosync,
++>>>>>>> e953f7f2fa78 (iommu/io-pgtable: Remove unused ->tlb_sync() callback)
  };
  
  static irqreturn_t mtk_iommu_isr(int irq, void *dev_id)
diff --cc drivers/iommu/qcom_iommu.c
index 5fa9507289ec,0b8a6d6bb475..000000000000
--- a/drivers/iommu/qcom_iommu.c
+++ b/drivers/iommu/qcom_iommu.c
@@@ -175,10 -164,31 +175,16 @@@ static void qcom_iommu_tlb_inv_range_no
  	}
  }
  
 -static void qcom_iommu_tlb_flush_walk(unsigned long iova, size_t size,
 -				      size_t granule, void *cookie)
 -{
 -	qcom_iommu_tlb_inv_range_nosync(iova, size, granule, false, cookie);
 -	qcom_iommu_tlb_sync(cookie);
 -}
 -
 -static void qcom_iommu_tlb_flush_leaf(unsigned long iova, size_t size,
 -				      size_t granule, void *cookie)
 -{
 -	qcom_iommu_tlb_inv_range_nosync(iova, size, granule, true, cookie);
 -	qcom_iommu_tlb_sync(cookie);
 -}
 -
 -static void qcom_iommu_tlb_add_page(unsigned long iova, size_t granule,
 -				    void *cookie)
 -{
 -	qcom_iommu_tlb_inv_range_nosync(iova, granule, granule, true, cookie);
 -}
 -
 -static const struct iommu_flush_ops qcom_flush_ops = {
 +static const struct iommu_gather_ops qcom_gather_ops = {
  	.tlb_flush_all	= qcom_iommu_tlb_inv_context,
++<<<<<<< HEAD
 +	.tlb_add_flush	= qcom_iommu_tlb_inv_range_nosync,
 +	.tlb_sync	= qcom_iommu_tlb_sync,
++=======
+ 	.tlb_flush_walk = qcom_iommu_tlb_flush_walk,
+ 	.tlb_flush_leaf = qcom_iommu_tlb_flush_leaf,
+ 	.tlb_add_page	= qcom_iommu_tlb_add_page,
++>>>>>>> e953f7f2fa78 (iommu/io-pgtable: Remove unused ->tlb_sync() callback)
  };
  
  static irqreturn_t qcom_iommu_fault(int irq, void *dev)
diff --cc include/linux/io-pgtable.h
index 7f040c22b7fb,843310484fe2..000000000000
--- a/include/linux/io-pgtable.h
+++ b/include/linux/io-pgtable.h
@@@ -25,15 -25,11 +25,23 @@@ enum io_pgtable_fmt 
   *                  address range.
   * @tlb_flush_leaf: Synchronously invalidate all leaf TLB state for a virtual
   *                  address range.
++<<<<<<< HEAD
 + * @tlb_add_flush:  Optional callback to queue up leaf TLB invalidation for a
 + *                  virtual address range.  This function exists purely as an
 + *                  optimisation for IOMMUs that cannot batch TLB invalidation
 + *                  operations efficiently and are therefore better suited to
 + *                  issuing them early rather than deferring them until
 + *                  iommu_tlb_sync().
 + * @tlb_sync:       Ensure any queued TLB invalidation has taken effect, and
 + *                  any corresponding page table updates are visible to the
 + *                  IOMMU.
++=======
+  * @tlb_add_page:   Optional callback to queue up leaf TLB invalidation for a
+  *                  single page. This function exists purely as an optimisation
+  *                  for IOMMUs that cannot batch TLB invalidation operations
+  *                  efficiently and are therefore better suited to issuing them
+  *                  early rather than deferring them until iommu_tlb_sync().
++>>>>>>> e953f7f2fa78 (iommu/io-pgtable: Remove unused ->tlb_sync() callback)
   *
   * Note that these can all be called in atomic context and must therefore
   * not block.
@@@ -44,9 -40,7 +52,13 @@@ struct iommu_gather_ops 
  			       void *cookie);
  	void (*tlb_flush_leaf)(unsigned long iova, size_t size, size_t granule,
  			       void *cookie);
++<<<<<<< HEAD
 +	void (*tlb_add_flush)(unsigned long iova, size_t size, size_t granule,
 +			      bool leaf, void *cookie);
 +	void (*tlb_sync)(void *cookie);
++=======
+ 	void (*tlb_add_page)(unsigned long iova, size_t granule, void *cookie);
++>>>>>>> e953f7f2fa78 (iommu/io-pgtable: Remove unused ->tlb_sync() callback)
  };
  
  /**
@@@ -212,17 -206,14 +224,12 @@@ io_pgtable_tlb_flush_leaf(struct io_pgt
  	iop->cfg.tlb->tlb_flush_leaf(iova, size, granule, iop->cookie);
  }
  
 -static inline void
 -io_pgtable_tlb_add_page(struct io_pgtable *iop, unsigned long iova,
 -			size_t granule)
 +static inline void io_pgtable_tlb_add_flush(struct io_pgtable *iop,
 +		unsigned long iova, size_t size, size_t granule, bool leaf)
  {
 -	if (iop->cfg.tlb->tlb_add_page)
 -		iop->cfg.tlb->tlb_add_page(iova, granule, iop->cookie);
 +	iop->cfg.tlb->tlb_add_flush(iova, size, granule, leaf, iop->cookie);
  }
  
- static inline void io_pgtable_tlb_sync(struct io_pgtable *iop)
- {
- 	iop->cfg.tlb->tlb_sync(iop->cookie);
- }
- 
  /**
   * struct io_pgtable_init_fns - Alloc/free a set of page tables for a
   *                              particular format.
* Unmerged path drivers/gpu/drm/panfrost/panfrost_mmu.c
* Unmerged path drivers/gpu/drm/panfrost/panfrost_mmu.c
* Unmerged path drivers/iommu/arm-smmu-v3.c
* Unmerged path drivers/iommu/arm-smmu.c
* Unmerged path drivers/iommu/io-pgtable-arm-v7s.c
* Unmerged path drivers/iommu/io-pgtable-arm.c
* Unmerged path drivers/iommu/ipmmu-vmsa.c
* Unmerged path drivers/iommu/msm_iommu.c
* Unmerged path drivers/iommu/mtk_iommu.c
* Unmerged path drivers/iommu/qcom_iommu.c
* Unmerged path include/linux/io-pgtable.h
