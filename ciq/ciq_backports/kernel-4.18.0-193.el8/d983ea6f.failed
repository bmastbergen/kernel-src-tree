tcp: add rcu protection around tp->fastopen_rsk

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-193.el8
commit-author Eric Dumazet <edumazet@google.com>
commit d983ea6f16b835dcde2ee9a58a1e764ce68bfccc
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-193.el8/d983ea6f.failed

Both tcp_v4_err() and tcp_v6_err() do the following operations
while they do not own the socket lock :

	fastopen = tp->fastopen_rsk;
 	snd_una = fastopen ? tcp_rsk(fastopen)->snt_isn : tp->snd_una;

The problem is that without appropriate barrier, the compiler
might reload tp->fastopen_rsk and trigger a NULL deref.

request sockets are protected by RCU, we can simply add
the missing annotations and barriers to solve the issue.

Fixes: 168a8f58059a ("tcp: TCP Fast Open Server - main code path")
	Signed-off-by: Eric Dumazet <edumazet@google.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit d983ea6f16b835dcde2ee9a58a1e764ce68bfccc)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/ipv4/tcp_input.c
#	net/ipv4/tcp_minisocks.c
#	net/ipv4/tcp_timer.c
diff --cc net/ipv4/tcp_input.c
index 50c5aa90e243,5f9b102c3b55..000000000000
--- a/net/ipv4/tcp_input.c
+++ b/net/ipv4/tcp_input.c
@@@ -2670,7 -2666,7 +2670,11 @@@ static void tcp_process_loss(struct soc
  	struct tcp_sock *tp = tcp_sk(sk);
  	bool recovered = !before(tp->snd_una, tp->high_seq);
  
++<<<<<<< HEAD
 +	if ((flag & FLAG_SND_UNA_ADVANCED) &&
++=======
+ 	if ((flag & FLAG_SND_UNA_ADVANCED || rcu_access_pointer(tp->fastopen_rsk)) &&
++>>>>>>> d983ea6f16b8 (tcp: add rcu protection around tp->fastopen_rsk)
  	    tcp_try_undo_loss(sk, false))
  		return;
  
@@@ -5986,6 -6085,34 +5990,37 @@@ reset_and_undo
  	return 1;
  }
  
++<<<<<<< HEAD
++=======
+ static void tcp_rcv_synrecv_state_fastopen(struct sock *sk)
+ {
+ 	struct request_sock *req;
+ 
+ 	tcp_try_undo_loss(sk, false);
+ 
+ 	/* Reset rtx states to prevent spurious retransmits_timed_out() */
+ 	tcp_sk(sk)->retrans_stamp = 0;
+ 	inet_csk(sk)->icsk_retransmits = 0;
+ 
+ 	/* Once we leave TCP_SYN_RECV or TCP_FIN_WAIT_1,
+ 	 * we no longer need req so release it.
+ 	 */
+ 	req = rcu_dereference_protected(tcp_sk(sk)->fastopen_rsk,
+ 					lockdep_sock_is_held(sk));
+ 	reqsk_fastopen_remove(sk, req, false);
+ 
+ 	/* Re-arm the timer because data may have been sent out.
+ 	 * This is similar to the regular data transmission case
+ 	 * when new data has just been ack'ed.
+ 	 *
+ 	 * (TFO) - we could try to be more aggressive and
+ 	 * retransmitting any data sooner based on when they
+ 	 * are sent out.
+ 	 */
+ 	tcp_rearm_rto(sk);
+ }
+ 
++>>>>>>> d983ea6f16b8 (tcp: add rcu protection around tp->fastopen_rsk)
  /*
   *	This function implements the receiving procedure of RFC 793 for
   *	all states except ESTABLISHED and TIME_WAIT.
diff --cc net/ipv4/tcp_minisocks.c
index 3bf9282b15f6,5401dbd39c8f..000000000000
--- a/net/ipv4/tcp_minisocks.c
+++ b/net/ipv4/tcp_minisocks.c
@@@ -555,14 -541,7 +555,18 @@@ struct sock *tcp_create_openreq_child(c
  	newtp->rx_opt.mss_clamp = req->mss;
  	tcp_ecn_openreq_child(newtp, req);
  	newtp->fastopen_req = NULL;
++<<<<<<< HEAD
 +	newtp->fastopen_rsk = NULL;
 +	newtp->syn_data_acked = 0;
 +	newtp->rack.mstamp = 0;
 +	newtp->rack.advanced = 0;
 +	newtp->rack.reo_wnd_steps = 1;
 +	newtp->rack.last_delivered = 0;
 +	newtp->rack.reo_wnd_persist = 0;
 +	newtp->rack.dsack_seen = 0;
++=======
+ 	RCU_INIT_POINTER(newtp->fastopen_rsk, NULL);
++>>>>>>> d983ea6f16b8 (tcp: add rcu protection around tp->fastopen_rsk)
  
  	__TCP_INC_STATS(sock_net(sk), TCP_MIB_PASSIVEOPENS);
  
diff --cc net/ipv4/tcp_timer.c
index f581b63b08b7,dd5a6317a801..000000000000
--- a/net/ipv4/tcp_timer.c
+++ b/net/ipv4/tcp_timer.c
@@@ -395,9 -391,8 +395,12 @@@ static void tcp_fastopen_synack_timer(s
  	struct inet_connection_sock *icsk = inet_csk(sk);
  	int max_retries = icsk->icsk_syn_retries ? :
  	    sock_net(sk)->ipv4.sysctl_tcp_synack_retries + 1; /* add one more retry for fastopen */
++<<<<<<< HEAD
 +	struct request_sock *req;
++=======
+ 	struct tcp_sock *tp = tcp_sk(sk);
++>>>>>>> d983ea6f16b8 (tcp: add rcu protection around tp->fastopen_rsk)
  
- 	req = tcp_sk(sk)->fastopen_rsk;
  	req->rsk_ops->syn_ack_timeout(req);
  
  	if (req->num_timeout >= max_retries) {
diff --git a/include/linux/tcp.h b/include/linux/tcp.h
index 8c66475339ed..35d804ca0c20 100644
--- a/include/linux/tcp.h
+++ b/include/linux/tcp.h
@@ -386,7 +386,7 @@ struct tcp_sock {
 	/* fastopen_rsk points to request_sock that resulted in this big
 	 * socket. Used to retransmit SYNACKs etc.
 	 */
-	struct request_sock *fastopen_rsk;
+	struct request_sock __rcu *fastopen_rsk;
 	u32	*saved_syn;
 };
 
@@ -439,8 +439,8 @@ static inline struct tcp_timewait_sock *tcp_twsk(const struct sock *sk)
 
 static inline bool tcp_passive_fastopen(const struct sock *sk)
 {
-	return (sk->sk_state == TCP_SYN_RECV &&
-		tcp_sk(sk)->fastopen_rsk != NULL);
+	return sk->sk_state == TCP_SYN_RECV &&
+	       rcu_access_pointer(tcp_sk(sk)->fastopen_rsk) != NULL;
 }
 
 static inline void fastopen_queue_tune(struct sock *sk, int backlog)
diff --git a/net/core/request_sock.c b/net/core/request_sock.c
index 9b8727c67b58..7d7ef79ba960 100644
--- a/net/core/request_sock.c
+++ b/net/core/request_sock.c
@@ -100,7 +100,7 @@ void reqsk_fastopen_remove(struct sock *sk, struct request_sock *req,
 
 	fastopenq = &inet_csk(lsk)->icsk_accept_queue.fastopenq;
 
-	tcp_sk(sk)->fastopen_rsk = NULL;
+	RCU_INIT_POINTER(tcp_sk(sk)->fastopen_rsk, NULL);
 	spin_lock_bh(&fastopenq->lock);
 	fastopenq->qlen--;
 	tcp_rsk(req)->tfo_listener = false;
diff --git a/net/ipv4/inet_connection_sock.c b/net/ipv4/inet_connection_sock.c
index 15e7f7915a21..d17eaaa3d862 100644
--- a/net/ipv4/inet_connection_sock.c
+++ b/net/ipv4/inet_connection_sock.c
@@ -909,7 +909,7 @@ static void inet_child_forget(struct sock *sk, struct request_sock *req,
 	percpu_counter_inc(sk->sk_prot->orphan_count);
 
 	if (sk->sk_protocol == IPPROTO_TCP && tcp_rsk(req)->tfo_listener) {
-		BUG_ON(tcp_sk(child)->fastopen_rsk != req);
+		BUG_ON(rcu_access_pointer(tcp_sk(child)->fastopen_rsk) != req);
 		BUG_ON(sk != req->rsk_listener);
 
 		/* Paranoid, to prevent race condition if
@@ -918,7 +918,7 @@ static void inet_child_forget(struct sock *sk, struct request_sock *req,
 		 * Also to satisfy an assertion in
 		 * tcp_v4_destroy_sock().
 		 */
-		tcp_sk(child)->fastopen_rsk = NULL;
+		RCU_INIT_POINTER(tcp_sk(child)->fastopen_rsk, NULL);
 	}
 	inet_csk_destroy_sock(child);
 }
diff --git a/net/ipv4/tcp.c b/net/ipv4/tcp.c
index d17c837b6339..e9608f0c467e 100644
--- a/net/ipv4/tcp.c
+++ b/net/ipv4/tcp.c
@@ -554,7 +554,7 @@ __poll_t tcp_poll(struct file *file, struct socket *sock, poll_table *wait)
 
 	/* Connected or passive Fast Open socket? */
 	if (state != TCP_SYN_SENT &&
-	    (state != TCP_SYN_RECV || tp->fastopen_rsk)) {
+	    (state != TCP_SYN_RECV || rcu_access_pointer(tp->fastopen_rsk))) {
 		int target = sock_rcvlowat(sk, 0, INT_MAX);
 
 		if (tp->urg_seq == tp->copied_seq &&
@@ -2484,7 +2484,10 @@ void tcp_close(struct sock *sk, long timeout)
 	}
 
 	if (sk->sk_state == TCP_CLOSE) {
-		struct request_sock *req = tcp_sk(sk)->fastopen_rsk;
+		struct request_sock *req;
+
+		req = rcu_dereference_protected(tcp_sk(sk)->fastopen_rsk,
+						lockdep_sock_is_held(sk));
 		/* We could get here with a non-NULL req if the socket is
 		 * aborted (e.g., closed with unread data) before 3WHS
 		 * finishes.
@@ -3714,8 +3717,10 @@ EXPORT_SYMBOL(tcp_md5_hash_key);
 
 void tcp_done(struct sock *sk)
 {
-	struct request_sock *req = tcp_sk(sk)->fastopen_rsk;
+	struct request_sock *req;
 
+	req = rcu_dereference_protected(tcp_sk(sk)->fastopen_rsk,
+					lockdep_sock_is_held(sk));
 	if (sk->sk_state == TCP_SYN_SENT || sk->sk_state == TCP_SYN_RECV)
 		TCP_INC_STATS(sock_net(sk), TCP_MIB_ATTEMPTFAILS);
 
diff --git a/net/ipv4/tcp_fastopen.c b/net/ipv4/tcp_fastopen.c
index 018a48477355..7a520d5b4351 100644
--- a/net/ipv4/tcp_fastopen.c
+++ b/net/ipv4/tcp_fastopen.c
@@ -240,7 +240,7 @@ static struct sock *tcp_fastopen_create_child(struct sock *sk,
 	 */
 	tp = tcp_sk(child);
 
-	tp->fastopen_rsk = req;
+	rcu_assign_pointer(tp->fastopen_rsk, req);
 	tcp_rsk(req)->tfo_listener = true;
 
 	/* RFC1323: The window in SYN & SYN/ACK segments is never
* Unmerged path net/ipv4/tcp_input.c
diff --git a/net/ipv4/tcp_ipv4.c b/net/ipv4/tcp_ipv4.c
index d96f498708c5..4dadd6a5c747 100644
--- a/net/ipv4/tcp_ipv4.c
+++ b/net/ipv4/tcp_ipv4.c
@@ -481,7 +481,7 @@ void tcp_v4_err(struct sk_buff *icmp_skb, u32 info)
 	icsk = inet_csk(sk);
 	tp = tcp_sk(sk);
 	/* XXX (TFO) - tp->snd_una should be ISN (tcp_create_openreq_child() */
-	fastopen = tp->fastopen_rsk;
+	fastopen = rcu_dereference(tp->fastopen_rsk);
 	snd_una = fastopen ? tcp_rsk(fastopen)->snt_isn : tp->snd_una;
 	if (sk->sk_state != TCP_LISTEN &&
 	    !between(seq, snd_una, tp->snd_nxt)) {
@@ -1995,7 +1995,7 @@ void tcp_v4_destroy_sock(struct sock *sk)
 	if (inet_csk(sk)->icsk_bind_hash)
 		inet_put_port(sk);
 
-	BUG_ON(tp->fastopen_rsk);
+	BUG_ON(rcu_access_pointer(tp->fastopen_rsk));
 
 	/* If socket is aborted during connect operation */
 	tcp_free_fastopen_req(tp);
* Unmerged path net/ipv4/tcp_minisocks.c
diff --git a/net/ipv4/tcp_output.c b/net/ipv4/tcp_output.c
index 97e11e678888..7b74dbe832e4 100644
--- a/net/ipv4/tcp_output.c
+++ b/net/ipv4/tcp_output.c
@@ -2447,7 +2447,7 @@ bool tcp_schedule_loss_probe(struct sock *sk, bool advancing_rto)
 	/* Don't do any loss probe on a Fast Open connection before 3WHS
 	 * finishes.
 	 */
-	if (tp->fastopen_rsk)
+	if (rcu_access_pointer(tp->fastopen_rsk))
 		return false;
 
 	early_retrans = sock_net(sk)->ipv4.sysctl_tcp_early_retrans;
* Unmerged path net/ipv4/tcp_timer.c
diff --git a/net/ipv6/tcp_ipv6.c b/net/ipv6/tcp_ipv6.c
index 167e6bdb9c3c..5e54c3dfdcf9 100644
--- a/net/ipv6/tcp_ipv6.c
+++ b/net/ipv6/tcp_ipv6.c
@@ -398,7 +398,7 @@ static void tcp_v6_err(struct sk_buff *skb, struct inet6_skb_parm *opt,
 
 	tp = tcp_sk(sk);
 	/* XXX (TFO) - tp->snd_una should be ISN (tcp_create_openreq_child() */
-	fastopen = tp->fastopen_rsk;
+	fastopen = rcu_dereference(tp->fastopen_rsk);
 	snd_una = fastopen ? tcp_rsk(fastopen)->snt_isn : tp->snd_una;
 	if (sk->sk_state != TCP_LISTEN &&
 	    !between(seq, snd_una, tp->snd_nxt)) {
