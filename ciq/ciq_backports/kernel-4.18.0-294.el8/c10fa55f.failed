scsi: scsi_debug: Support hostwide tags

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author John Garry <john.garry@huawei.com>
commit c10fa55f5e7ad3638237dd66fcb28a7225acdff8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/c10fa55f.failed

Many SCSI HBAs support a hostwide tagset, whereby each command submitted to
the HW from all submission queues must have a unique tag identifier.

Normally this unique tag will be in the range [0, max queue], where "max
queue" is the depth of each of the submission queues.

Add support for this hostwide tag feature, via module parameter
"host_max_queue". A non-zero value means that the feature is enabled. In
this case, the submission queues are not exposed to upper layer, i.e. from
blk-mq prespective, the device has a single hw queue. There are 2 reasons
for this:

 a. It is assumed that the host can support nr_hw_queues * can_queue
    commands, but this is not true for hostwide tags

 b. For nr_hw_queues != 0, the request tag is not unique over all HW
    queues, and some HBA drivers want to use this tag for the hostwide tag

However, like many SCSI HBA drivers today - megaraid sas being an example -
the full set of HW submission queues are still used in the LLDD driver. So
instead of using a complicated "reply_map" to create a per-CPU submission
queue mapping like megaraid_sas (as it depends on a PCI device + MSIs) -
use a simple algorithm:

    hwq = cpu % queue count

If the host_max_queue param is set non-zero, then the max queue depth is
fixed at this value also.

If and when hostwide shared tags are supported in blk-mq/scsi mid-layer,
then the policy to set nr_hw_queues = 0 for hostwide tags can be revised.

Link: https://lore.kernel.org/r/1594297400-24756-3-git-send-email-john.garry@huawei.com
	Acked-by: Douglas Gilbert <dgilbert@interlog.com>
	Signed-off-by: John Garry <john.garry@huawei.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit c10fa55f5e7ad3638237dd66fcb28a7225acdff8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/scsi_debug.c
diff --cc drivers/scsi/scsi_debug.c
index 820227007ec1,802ccd32d010..000000000000
--- a/drivers/scsi/scsi_debug.c
+++ b/drivers/scsi/scsi_debug.c
@@@ -3730,17 -4209,528 +3732,30 @@@ static int resp_report_luns(struct scsi
  	return res;
  }
  
 -static int resp_verify(struct scsi_cmnd *scp, struct sdebug_dev_info *devip)
 +static struct sdebug_queue *get_queue(struct scsi_cmnd *cmnd)
  {
- 	u32 tag = blk_mq_unique_tag(cmnd->request);
- 	u16 hwq = blk_mq_unique_tag_to_hwq(tag);
 -	bool is_bytchk3 = false;
 -	u8 bytchk;
 -	int ret, j;
 -	u32 vnum, a_num, off;
 -	const u32 lb_size = sdebug_sector_size;
 -	u64 lba;
 -	u8 *arr;
 -	u8 *cmd = scp->cmnd;
 -	struct sdeb_store_info *sip = devip2sip(devip, true);
 -	rwlock_t *macc_lckp = &sip->macc_lck;
++	u16 hwq;
  
- 	pr_debug("tag=%#x, hwq=%d\n", tag, hwq);
- 	if (WARN_ON_ONCE(hwq >= submit_queues))
- 		hwq = 0;
 -	bytchk = (cmd[1] >> 1) & 0x3;
 -	if (bytchk == 0) {
 -		return 0;	/* always claim internal verify okay */
 -	} else if (bytchk == 2) {
 -		mk_sense_invalid_fld(scp, SDEB_IN_CDB, 2, 2);
 -		return check_condition_result;
 -	} else if (bytchk == 3) {
 -		is_bytchk3 = true;	/* 1 block sent, compared repeatedly */
 -	}
 -	switch (cmd[0]) {
 -	case VERIFY_16:
 -		lba = get_unaligned_be64(cmd + 2);
 -		vnum = get_unaligned_be32(cmd + 10);
 -		break;
 -	case VERIFY:		/* is VERIFY(10) */
 -		lba = get_unaligned_be32(cmd + 2);
 -		vnum = get_unaligned_be16(cmd + 7);
 -		break;
 -	default:
 -		mk_sense_invalid_opcode(scp);
 -		return check_condition_result;
 -	}
 -	a_num = is_bytchk3 ? 1 : vnum;
 -	/* Treat following check like one for read (i.e. no write) access */
 -	ret = check_device_access_params(scp, lba, a_num, false);
 -	if (ret)
 -		return ret;
++	if (sdebug_host_max_queue) {
++		/* Provide a simple method to choose the hwq */
++		hwq = smp_processor_id() % submit_queues;
++	} else {
++		u32 tag = blk_mq_unique_tag(cmnd->request);
+ 
 -	arr = kcalloc(lb_size, vnum, GFP_ATOMIC);
 -	if (!arr) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, INSUFF_RES_ASC,
 -				INSUFF_RES_ASCQ);
 -		return check_condition_result;
 -	}
 -	/* Not changing store, so only need read access */
 -	read_lock(macc_lckp);
++		hwq = blk_mq_unique_tag_to_hwq(tag);
+ 
 -	ret = do_dout_fetch(scp, a_num, arr);
 -	if (ret == -1) {
 -		ret = DID_ERROR << 16;
 -		goto cleanup;
 -	} else if (sdebug_verbose && (ret < (a_num * lb_size))) {
 -		sdev_printk(KERN_INFO, scp->device,
 -			    "%s: %s: cdb indicated=%u, IO sent=%d bytes\n",
 -			    my_name, __func__, a_num * lb_size, ret);
 -	}
 -	if (is_bytchk3) {
 -		for (j = 1, off = lb_size; j < vnum; ++j, off += lb_size)
 -			memcpy(arr + off, arr, lb_size);
 -	}
 -	ret = 0;
 -	if (!comp_write_worker(sip, lba, vnum, arr, true)) {
 -		mk_sense_buffer(scp, MISCOMPARE, MISCOMPARE_VERIFY_ASC, 0);
 -		ret = check_condition_result;
 -		goto cleanup;
++		pr_debug("tag=%#x, hwq=%d\n", tag, hwq);
++		if (WARN_ON_ONCE(hwq >= submit_queues))
++			hwq = 0;
+ 	}
 -cleanup:
 -	read_unlock(macc_lckp);
 -	kfree(arr);
 -	return ret;
 +	return sdebug_q_arr + hwq;
  }
  
 -#define RZONES_DESC_HD 64
 -
 -/* Report zones depending on start LBA nad reporting options */
 -static int resp_report_zones(struct scsi_cmnd *scp,
 -			     struct sdebug_dev_info *devip)
++static u32 get_tag(struct scsi_cmnd *cmnd)
+ {
 -	unsigned int i, max_zones, rep_max_zones, nrz = 0;
 -	int ret = 0;
 -	u32 alloc_len, rep_opts, rep_len;
 -	bool partial;
 -	u64 lba, zs_lba;
 -	u8 *arr = NULL, *desc;
 -	u8 *cmd = scp->cmnd;
 -	struct sdeb_zone_state *zsp;
 -	struct sdeb_store_info *sip = devip2sip(devip, false);
 -	rwlock_t *macc_lckp = sip ? &sip->macc_lck : &sdeb_fake_rw_lck;
 -
 -	if (!sdebug_dev_is_zoned(devip)) {
 -		mk_sense_invalid_opcode(scp);
 -		return check_condition_result;
 -	}
 -	zs_lba = get_unaligned_be64(cmd + 2);
 -	alloc_len = get_unaligned_be32(cmd + 10);
 -	rep_opts = cmd[14] & 0x3f;
 -	partial = cmd[14] & 0x80;
 -
 -	if (zs_lba >= sdebug_capacity) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, LBA_OUT_OF_RANGE, 0);
 -		return check_condition_result;
 -	}
 -
 -	max_zones = devip->nr_zones - (zs_lba >> devip->zsize_shift);
 -	rep_max_zones = min((alloc_len - 64) >> ilog2(RZONES_DESC_HD),
 -			    max_zones);
 -
 -	arr = kcalloc(RZONES_DESC_HD, alloc_len, GFP_ATOMIC);
 -	if (!arr) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, INSUFF_RES_ASC,
 -				INSUFF_RES_ASCQ);
 -		return check_condition_result;
 -	}
 -
 -	read_lock(macc_lckp);
 -
 -	desc = arr + 64;
 -	for (i = 0; i < max_zones; i++) {
 -		lba = zs_lba + devip->zsize * i;
 -		if (lba > sdebug_capacity)
 -			break;
 -		zsp = zbc_zone(devip, lba);
 -		switch (rep_opts) {
 -		case 0x00:
 -			/* All zones */
 -			break;
 -		case 0x01:
 -			/* Empty zones */
 -			if (zsp->z_cond != ZC1_EMPTY)
 -				continue;
 -			break;
 -		case 0x02:
 -			/* Implicit open zones */
 -			if (zsp->z_cond != ZC2_IMPLICIT_OPEN)
 -				continue;
 -			break;
 -		case 0x03:
 -			/* Explicit open zones */
 -			if (zsp->z_cond != ZC3_EXPLICIT_OPEN)
 -				continue;
 -			break;
 -		case 0x04:
 -			/* Closed zones */
 -			if (zsp->z_cond != ZC4_CLOSED)
 -				continue;
 -			break;
 -		case 0x05:
 -			/* Full zones */
 -			if (zsp->z_cond != ZC5_FULL)
 -				continue;
 -			break;
 -		case 0x06:
 -		case 0x07:
 -		case 0x10:
 -			/*
 -			 * Read-only, offline, reset WP recommended are
 -			 * not emulated: no zones to report;
 -			 */
 -			continue;
 -		case 0x11:
 -			/* non-seq-resource set */
 -			if (!zsp->z_non_seq_resource)
 -				continue;
 -			break;
 -		case 0x3f:
 -			/* Not write pointer (conventional) zones */
 -			if (!zbc_zone_is_conv(zsp))
 -				continue;
 -			break;
 -		default:
 -			mk_sense_buffer(scp, ILLEGAL_REQUEST,
 -					INVALID_FIELD_IN_CDB, 0);
 -			ret = check_condition_result;
 -			goto fini;
 -		}
 -
 -		if (nrz < rep_max_zones) {
 -			/* Fill zone descriptor */
 -			desc[0] = zsp->z_type;
 -			desc[1] = zsp->z_cond << 4;
 -			if (zsp->z_non_seq_resource)
 -				desc[1] |= 1 << 1;
 -			put_unaligned_be64((u64)zsp->z_size, desc + 8);
 -			put_unaligned_be64((u64)zsp->z_start, desc + 16);
 -			put_unaligned_be64((u64)zsp->z_wp, desc + 24);
 -			desc += 64;
 -		}
 -
 -		if (partial && nrz >= rep_max_zones)
 -			break;
 -
 -		nrz++;
 -	}
 -
 -	/* Report header */
 -	put_unaligned_be32(nrz * RZONES_DESC_HD, arr + 0);
 -	put_unaligned_be64(sdebug_capacity - 1, arr + 8);
 -
 -	rep_len = (unsigned long)desc - (unsigned long)arr;
 -	ret = fill_from_dev_buffer(scp, arr, min_t(int, alloc_len, rep_len));
 -
 -fini:
 -	read_unlock(macc_lckp);
 -	kfree(arr);
 -	return ret;
 -}
 -
 -/* Logic transplanted from tcmu-runner, file_zbc.c */
 -static void zbc_open_all(struct sdebug_dev_info *devip)
 -{
 -	struct sdeb_zone_state *zsp = &devip->zstate[0];
 -	unsigned int i;
 -
 -	for (i = 0; i < devip->nr_zones; i++, zsp++) {
 -		if (zsp->z_cond == ZC4_CLOSED)
 -			zbc_open_zone(devip, &devip->zstate[i], true);
 -	}
 -}
 -
 -static int resp_open_zone(struct scsi_cmnd *scp, struct sdebug_dev_info *devip)
 -{
 -	int res = 0;
 -	u64 z_id;
 -	enum sdebug_z_cond zc;
 -	u8 *cmd = scp->cmnd;
 -	struct sdeb_zone_state *zsp;
 -	bool all = cmd[14] & 0x01;
 -	struct sdeb_store_info *sip = devip2sip(devip, false);
 -	rwlock_t *macc_lckp = sip ? &sip->macc_lck : &sdeb_fake_rw_lck;
 -
 -	if (!sdebug_dev_is_zoned(devip)) {
 -		mk_sense_invalid_opcode(scp);
 -		return check_condition_result;
 -	}
 -
 -	write_lock(macc_lckp);
 -
 -	if (all) {
 -		/* Check if all closed zones can be open */
 -		if (devip->max_open &&
 -		    devip->nr_exp_open + devip->nr_closed > devip->max_open) {
 -			mk_sense_buffer(scp, DATA_PROTECT, INSUFF_RES_ASC,
 -					INSUFF_ZONE_ASCQ);
 -			res = check_condition_result;
 -			goto fini;
 -		}
 -		/* Open all closed zones */
 -		zbc_open_all(devip);
 -		goto fini;
 -	}
 -
 -	/* Open the specified zone */
 -	z_id = get_unaligned_be64(cmd + 2);
 -	if (z_id >= sdebug_capacity) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, LBA_OUT_OF_RANGE, 0);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -
 -	zsp = zbc_zone(devip, z_id);
 -	if (z_id != zsp->z_start) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -	if (zbc_zone_is_conv(zsp)) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -
 -	zc = zsp->z_cond;
 -	if (zc == ZC3_EXPLICIT_OPEN || zc == ZC5_FULL)
 -		goto fini;
 -
 -	if (devip->max_open && devip->nr_exp_open >= devip->max_open) {
 -		mk_sense_buffer(scp, DATA_PROTECT, INSUFF_RES_ASC,
 -				INSUFF_ZONE_ASCQ);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -
 -	if (zc == ZC2_IMPLICIT_OPEN)
 -		zbc_close_zone(devip, zsp);
 -	zbc_open_zone(devip, zsp, true);
 -fini:
 -	write_unlock(macc_lckp);
 -	return res;
 -}
 -
 -static void zbc_close_all(struct sdebug_dev_info *devip)
 -{
 -	unsigned int i;
 -
 -	for (i = 0; i < devip->nr_zones; i++)
 -		zbc_close_zone(devip, &devip->zstate[i]);
 -}
 -
 -static int resp_close_zone(struct scsi_cmnd *scp,
 -			   struct sdebug_dev_info *devip)
 -{
 -	int res = 0;
 -	u64 z_id;
 -	u8 *cmd = scp->cmnd;
 -	struct sdeb_zone_state *zsp;
 -	bool all = cmd[14] & 0x01;
 -	struct sdeb_store_info *sip = devip2sip(devip, false);
 -	rwlock_t *macc_lckp = sip ? &sip->macc_lck : &sdeb_fake_rw_lck;
 -
 -	if (!sdebug_dev_is_zoned(devip)) {
 -		mk_sense_invalid_opcode(scp);
 -		return check_condition_result;
 -	}
 -
 -	write_lock(macc_lckp);
 -
 -	if (all) {
 -		zbc_close_all(devip);
 -		goto fini;
 -	}
 -
 -	/* Close specified zone */
 -	z_id = get_unaligned_be64(cmd + 2);
 -	if (z_id >= sdebug_capacity) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, LBA_OUT_OF_RANGE, 0);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -
 -	zsp = zbc_zone(devip, z_id);
 -	if (z_id != zsp->z_start) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -	if (zbc_zone_is_conv(zsp)) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -
 -	zbc_close_zone(devip, zsp);
 -fini:
 -	write_unlock(macc_lckp);
 -	return res;
 -}
 -
 -static void zbc_finish_zone(struct sdebug_dev_info *devip,
 -			    struct sdeb_zone_state *zsp, bool empty)
 -{
 -	enum sdebug_z_cond zc = zsp->z_cond;
 -
 -	if (zc == ZC4_CLOSED || zc == ZC2_IMPLICIT_OPEN ||
 -	    zc == ZC3_EXPLICIT_OPEN || (empty && zc == ZC1_EMPTY)) {
 -		if (zc == ZC2_IMPLICIT_OPEN || zc == ZC3_EXPLICIT_OPEN)
 -			zbc_close_zone(devip, zsp);
 -		if (zsp->z_cond == ZC4_CLOSED)
 -			devip->nr_closed--;
 -		zsp->z_wp = zsp->z_start + zsp->z_size;
 -		zsp->z_cond = ZC5_FULL;
 -	}
 -}
 -
 -static void zbc_finish_all(struct sdebug_dev_info *devip)
 -{
 -	unsigned int i;
 -
 -	for (i = 0; i < devip->nr_zones; i++)
 -		zbc_finish_zone(devip, &devip->zstate[i], false);
 -}
 -
 -static int resp_finish_zone(struct scsi_cmnd *scp,
 -			    struct sdebug_dev_info *devip)
 -{
 -	struct sdeb_zone_state *zsp;
 -	int res = 0;
 -	u64 z_id;
 -	u8 *cmd = scp->cmnd;
 -	bool all = cmd[14] & 0x01;
 -	struct sdeb_store_info *sip = devip2sip(devip, false);
 -	rwlock_t *macc_lckp = sip ? &sip->macc_lck : &sdeb_fake_rw_lck;
 -
 -	if (!sdebug_dev_is_zoned(devip)) {
 -		mk_sense_invalid_opcode(scp);
 -		return check_condition_result;
 -	}
 -
 -	write_lock(macc_lckp);
 -
 -	if (all) {
 -		zbc_finish_all(devip);
 -		goto fini;
 -	}
 -
 -	/* Finish the specified zone */
 -	z_id = get_unaligned_be64(cmd + 2);
 -	if (z_id >= sdebug_capacity) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, LBA_OUT_OF_RANGE, 0);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -
 -	zsp = zbc_zone(devip, z_id);
 -	if (z_id != zsp->z_start) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -	if (zbc_zone_is_conv(zsp)) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -
 -	zbc_finish_zone(devip, zsp, true);
 -fini:
 -	write_unlock(macc_lckp);
 -	return res;
 -}
 -
 -static void zbc_rwp_zone(struct sdebug_dev_info *devip,
 -			 struct sdeb_zone_state *zsp)
 -{
 -	enum sdebug_z_cond zc;
 -
 -	if (zbc_zone_is_conv(zsp))
 -		return;
 -
 -	zc = zsp->z_cond;
 -	if (zc == ZC2_IMPLICIT_OPEN || zc == ZC3_EXPLICIT_OPEN)
 -		zbc_close_zone(devip, zsp);
 -
 -	if (zsp->z_cond == ZC4_CLOSED)
 -		devip->nr_closed--;
 -
 -	zsp->z_non_seq_resource = false;
 -	zsp->z_wp = zsp->z_start;
 -	zsp->z_cond = ZC1_EMPTY;
 -}
 -
 -static void zbc_rwp_all(struct sdebug_dev_info *devip)
 -{
 -	unsigned int i;
 -
 -	for (i = 0; i < devip->nr_zones; i++)
 -		zbc_rwp_zone(devip, &devip->zstate[i]);
 -}
 -
 -static int resp_rwp_zone(struct scsi_cmnd *scp, struct sdebug_dev_info *devip)
 -{
 -	struct sdeb_zone_state *zsp;
 -	int res = 0;
 -	u64 z_id;
 -	u8 *cmd = scp->cmnd;
 -	bool all = cmd[14] & 0x01;
 -	struct sdeb_store_info *sip = devip2sip(devip, false);
 -	rwlock_t *macc_lckp = sip ? &sip->macc_lck : &sdeb_fake_rw_lck;
 -
 -	if (!sdebug_dev_is_zoned(devip)) {
 -		mk_sense_invalid_opcode(scp);
 -		return check_condition_result;
 -	}
 -
 -	write_lock(macc_lckp);
 -
 -	if (all) {
 -		zbc_rwp_all(devip);
 -		goto fini;
 -	}
 -
 -	z_id = get_unaligned_be64(cmd + 2);
 -	if (z_id >= sdebug_capacity) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, LBA_OUT_OF_RANGE, 0);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -
 -	zsp = zbc_zone(devip, z_id);
 -	if (z_id != zsp->z_start) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -	if (zbc_zone_is_conv(zsp)) {
 -		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
 -		res = check_condition_result;
 -		goto fini;
 -	}
 -
 -	zbc_rwp_zone(devip, zsp);
 -fini:
 -	write_unlock(macc_lckp);
 -	return res;
 -}
 -
 -static struct sdebug_queue *get_queue(struct scsi_cmnd *cmnd)
 -{
 -	u16 hwq;
 -
 -	if (sdebug_host_max_queue) {
 -		/* Provide a simple method to choose the hwq */
 -		hwq = smp_processor_id() % submit_queues;
 -	} else {
 -		u32 tag = blk_mq_unique_tag(cmnd->request);
 -
 -		hwq = blk_mq_unique_tag_to_hwq(tag);
 -
 -		pr_debug("tag=%#x, hwq=%d\n", tag, hwq);
 -		if (WARN_ON_ONCE(hwq >= submit_queues))
 -			hwq = 0;
 -	}
 -	return sdebug_q_arr + hwq;
 -}
 -
 -static u32 get_tag(struct scsi_cmnd *cmnd)
 -{
 -	return blk_mq_unique_tag(cmnd->request);
 -}
++	return blk_mq_unique_tag(cmnd->request);
++}
+ 
  /* Queued (deferred) command completions converge here. */
  static void sdebug_q_cmd_complete(struct sdebug_defer *sd_dp)
  {
@@@ -4367,17 -5454,28 +4382,28 @@@ static int schedule_resp(struct scsi_cm
  	spin_unlock_irqrestore(&sqp->qc_lock, iflags);
  	if (unlikely(sdebug_every_nth && sdebug_any_injecting_opt))
  		setup_inject(sqp, sqcp);
 -	if (!sd_dp) {
 +	if (sd_dp == NULL) {
  		sd_dp = kzalloc(sizeof(*sd_dp), GFP_ATOMIC);
 -		if (!sd_dp) {
 -			atomic_dec(&devip->num_in_q);
 -			clear_bit(k, sqp->in_use_bm);
 +		if (sd_dp == NULL)
  			return SCSI_MLQUEUE_HOST_BUSY;
 -		}
 -		new_sd_dp = true;
 -	} else {
 -		new_sd_dp = false;
  	}
  
++<<<<<<< HEAD
++=======
+ 	/* Set the hostwide tag */
+ 	if (sdebug_host_max_queue)
+ 		sd_dp->hc_idx = get_tag(cmnd);
+ 
+ 	if (ndelay > 0 && ndelay < INCLUSIVE_TIMING_MAX_NS)
+ 		ns_from_boot = ktime_get_boottime_ns();
+ 
+ 	/* one of the resp_*() response functions is called here */
++>>>>>>> c10fa55f5e7a (scsi: scsi_debug: Support hostwide tags)
  	cmnd->result = pfp != NULL ? pfp(cmnd, devip) : 0;
  	if (cmnd->result & SDEG_RES_IMMED_MASK) {
 +		/*
 +		 * This is the F_DELAY_OVERR case. No delay.
 +		 */
  		cmnd->result &= ~SDEG_RES_IMMED_MASK;
  		delta_jiff = ndelay = 0;
  	}
@@@ -4464,12 -5591,14 +4490,20 @@@ module_param_named(every_nth, sdebug_ev
  module_param_named(fake_rw, sdebug_fake_rw, int, S_IRUGO | S_IWUSR);
  module_param_named(guard, sdebug_guard, uint, S_IRUGO);
  module_param_named(host_lock, sdebug_host_lock, bool, S_IRUGO | S_IWUSR);
++<<<<<<< HEAD
++=======
+ module_param_named(host_max_queue, sdebug_host_max_queue, int, S_IRUGO);
+ module_param_string(inq_product, sdebug_inq_product_id,
+ 		    sizeof(sdebug_inq_product_id), S_IRUGO | S_IWUSR);
+ module_param_string(inq_rev, sdebug_inq_product_rev,
+ 		    sizeof(sdebug_inq_product_rev), S_IRUGO | S_IWUSR);
++>>>>>>> c10fa55f5e7a (scsi: scsi_debug: Support hostwide tags)
  module_param_string(inq_vendor, sdebug_inq_vendor_id,
 -		    sizeof(sdebug_inq_vendor_id), S_IRUGO | S_IWUSR);
 -module_param_named(lbprz, sdebug_lbprz, int, S_IRUGO);
 +		    sizeof(sdebug_inq_vendor_id), S_IRUGO|S_IWUSR);
 +module_param_string(inq_product, sdebug_inq_product_id,
 +		    sizeof(sdebug_inq_product_id), S_IRUGO|S_IWUSR);
 +module_param_string(inq_rev, sdebug_inq_product_rev,
 +		    sizeof(sdebug_inq_product_rev), S_IRUGO|S_IWUSR);
  module_param_named(lbpu, sdebug_lbpu, int, S_IRUGO);
  module_param_named(lbpws, sdebug_lbpws, int, S_IRUGO);
  module_param_named(lbpws10, sdebug_lbpws10, int, S_IRUGO);
@@@ -4525,7 -5662,8 +4559,12 @@@ MODULE_PARM_DESC(every_nth, "timeout ev
  MODULE_PARM_DESC(fake_rw, "fake reads/writes instead of copying (def=0)");
  MODULE_PARM_DESC(guard, "protection checksum: 0=crc, 1=ip (def=0)");
  MODULE_PARM_DESC(host_lock, "host_lock is ignored (def=0)");
++<<<<<<< HEAD
 +MODULE_PARM_DESC(inq_vendor, "SCSI INQUIRY vendor string (def=\"Linux\")");
++=======
+ MODULE_PARM_DESC(host_max_queue,
+ 		 "host max # of queued cmds (0 to max(def) [max_queue fixed equal for !0])");
++>>>>>>> c10fa55f5e7a (scsi: scsi_debug: Support hostwide tags)
  MODULE_PARM_DESC(inq_product, "SCSI INQUIRY product string (def=\"scsi_debug\")");
  MODULE_PARM_DESC(inq_rev, "SCSI INQUIRY revision string (def=\""
  		 SDEBUG_VERSION "\")");
@@@ -5827,9 -7306,13 +5893,19 @@@ static int sdebug_driver_probe(struct d
  
  	sdbg_host = to_sdebug_host(dev);
  
++<<<<<<< HEAD
 +	sdebug_driver_template.can_queue = sdebug_max_queue;
 +	if (sdebug_clustering)
 +		sdebug_driver_template.use_clustering = ENABLE_CLUSTERING;
++=======
+ 	if (sdebug_host_max_queue)
+ 		sdebug_driver_template.can_queue = sdebug_host_max_queue;
+ 	else
+ 		sdebug_driver_template.can_queue = sdebug_max_queue;
+ 	if (!sdebug_clustering)
+ 		sdebug_driver_template.dma_boundary = PAGE_SIZE - 1;
+ 
++>>>>>>> c10fa55f5e7a (scsi: scsi_debug: Support hostwide tags)
  	hpnt = scsi_host_alloc(&sdebug_driver_template, sizeof(sdbg_host));
  	if (NULL == hpnt) {
  		pr_err("scsi_host_alloc failed\n");
* Unmerged path drivers/scsi/scsi_debug.c
