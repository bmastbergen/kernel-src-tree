bpf: Move prog->aux->linked_prog and trampoline into bpf_link on attach

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Toke Høiland-Jørgensen <toke@redhat.com>
commit 3aac1ead5eb6b76f3d2b8d111e6de1c2de23fb34
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/3aac1ead.failed

In preparation for allowing multiple attachments of freplace programs, move
the references to the target program and trampoline into the
bpf_tracing_link structure when that is created. To do this atomically,
introduce a new mutex in prog->aux to protect writing to the two pointers
to target prog and trampoline, and rename the members to make it clear that
they are related.

With this change, it is no longer possible to attach the same tracing
program multiple times (detaching in-between), since the reference from the
tracing program to the target disappears on the first attach. However,
since the next patch will let the caller supply an attach target, that will
also make it possible to attach to the same place multiple times.

	Signed-off-by: Toke Høiland-Jørgensen <toke@redhat.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Andrii Nakryiko <andriin@fb.com>
Link: https://lore.kernel.org/bpf/160138355059.48470.2503076992210324984.stgit@toke.dk
(cherry picked from commit 3aac1ead5eb6b76f3d2b8d111e6de1c2de23fb34)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
#	kernel/bpf/core.c
#	kernel/bpf/preload/iterators/iterators.bpf.c
#	kernel/bpf/preload/iterators/iterators.skel.h
#	kernel/bpf/verifier.c
diff --cc include/linux/bpf.h
index 53810b02f758,839dd8670a7a..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -560,9 -640,10 +560,16 @@@ static __always_inline unsigned int bpf
  	return bpf_func(ctx, insnsi);
  }
  #ifdef CONFIG_BPF_JIT
++<<<<<<< HEAD
 +struct bpf_trampoline *bpf_trampoline_lookup(u64 key);
 +int bpf_trampoline_link_prog(struct bpf_prog *prog);
 +int bpf_trampoline_unlink_prog(struct bpf_prog *prog);
++=======
+ int bpf_trampoline_link_prog(struct bpf_prog *prog, struct bpf_trampoline *tr);
+ int bpf_trampoline_unlink_prog(struct bpf_prog *prog, struct bpf_trampoline *tr);
+ struct bpf_trampoline *bpf_trampoline_get(u64 key,
+ 					  struct bpf_attach_target_info *tgt_info);
++>>>>>>> 3aac1ead5eb6 (bpf: Move prog->aux->linked_prog and trampoline into bpf_link on attach)
  void bpf_trampoline_put(struct bpf_trampoline *tr);
  #define BPF_DISPATCHER_INIT(_name) {				\
  	.mutex = __MUTEX_INITIALIZER(_name.mutex),		\
@@@ -607,11 -688,8 +614,16 @@@ void bpf_image_ksym_del(struct bpf_ksy
  void bpf_ksym_add(struct bpf_ksym *ksym);
  void bpf_ksym_del(struct bpf_ksym *ksym);
  #else
++<<<<<<< HEAD
 +static inline struct bpf_trampoline *bpf_trampoline_lookup(u64 key)
 +{
 +	return NULL;
 +}
 +static inline int bpf_trampoline_link_prog(struct bpf_prog *prog)
++=======
+ static inline int bpf_trampoline_link_prog(struct bpf_prog *prog,
+ 					   struct bpf_trampoline *tr)
++>>>>>>> 3aac1ead5eb6 (bpf: Move prog->aux->linked_prog and trampoline into bpf_link on attach)
  {
  	return -ENOTSUPP;
  }
@@@ -666,29 -759,35 +679,49 @@@ struct bpf_prog_aux 
  	u32 stack_depth;
  	u32 id;
  	u32 func_cnt; /* used by non-func prog as the number of func progs */
++<<<<<<< HEAD
 +	RH_KABI_BROKEN_INSERT(u32 func_idx) /* 0 for non-func prog, the index in func array for func prog */
 +	RH_KABI_BROKEN_INSERT(u32 attach_btf_id) /* in-kernel BTF type id to attach to */
 +	RH_KABI_BROKEN_INSERT(struct bpf_prog *linked_prog)
 +	RH_KABI_BROKEN_INSERT(bool verifier_zext) /* Zero extensions has been inserted by verifier. */
 +	bool offload_requested;
 +	RH_KABI_BROKEN_INSERT(bool attach_btf_trace) /* true if attaching to BTF-enabled raw tp */
 +	RH_KABI_BROKEN_INSERT(bool func_proto_unreliable)
 +	RH_KABI_BROKEN_INSERT(enum bpf_tramp_prog_type trampoline_prog_type)
 +	RH_KABI_BROKEN_INSERT(struct bpf_trampoline *trampoline)
 +	RH_KABI_BROKEN_INSERT(struct hlist_node tramp_hlist)
++=======
+ 	u32 func_idx; /* 0 for non-func prog, the index in func array for func prog */
+ 	u32 attach_btf_id; /* in-kernel BTF type id to attach to */
+ 	u32 ctx_arg_info_size;
+ 	u32 max_rdonly_access;
+ 	u32 max_rdwr_access;
+ 	const struct bpf_ctx_arg_aux *ctx_arg_info;
+ 	struct mutex dst_mutex; /* protects dst_* pointers below, *after* prog becomes visible */
+ 	struct bpf_prog *dst_prog;
+ 	struct bpf_trampoline *dst_trampoline;
+ 	bool verifier_zext; /* Zero extensions has been inserted by verifier. */
+ 	bool offload_requested;
+ 	bool attach_btf_trace; /* true if attaching to BTF-enabled raw tp */
+ 	bool func_proto_unreliable;
+ 	bool sleepable;
+ 	bool tail_call_reachable;
+ 	enum bpf_tramp_prog_type trampoline_prog_type;
+ 	struct hlist_node tramp_hlist;
++>>>>>>> 3aac1ead5eb6 (bpf: Move prog->aux->linked_prog and trampoline into bpf_link on attach)
  	/* BTF_KIND_FUNC_PROTO for valid attach_btf_id */
 -	const struct btf_type *attach_func_proto;
 +	RH_KABI_BROKEN_INSERT(const struct btf_type *attach_func_proto)
  	/* function name for valid attach_btf_id */
 -	const char *attach_func_name;
 +	RH_KABI_BROKEN_INSERT(const char *attach_func_name)
  	struct bpf_prog **func;
  	void *jit_data; /* JIT specific data. arch dependent */
 -	struct bpf_jit_poke_descriptor *poke_tab;
 -	u32 size_poke_tab;
 -	struct bpf_ksym ksym;
 +	RH_KABI_BROKEN_INSERT(struct bpf_jit_poke_descriptor *poke_tab)
 +	RH_KABI_BROKEN_INSERT(u32 size_poke_tab)
 +	RH_KABI_BROKEN_REMOVE(struct latch_tree_node ksym_tnode)
 +	RH_KABI_BROKEN_REMOVE(struct list_head ksym_lnode)
 +	RH_KABI_BROKEN_INSERT(struct bpf_ksym ksym)
  	const struct bpf_prog_ops *ops;
  	struct bpf_map **used_maps;
 -	struct mutex used_maps_mutex; /* mutex for used_maps and used_map_cnt */
  	struct bpf_prog *prog;
  	struct user_struct *user;
  	u64 load_time; /* ns since boottime */
diff --cc kernel/bpf/core.c
index 807b973cb465,cda674f1392f..000000000000
--- a/kernel/bpf/core.c
+++ b/kernel/bpf/core.c
@@@ -102,6 -98,8 +102,11 @@@ struct bpf_prog *bpf_prog_alloc_no_stat
  	fp->jit_requested = ebpf_jit_enabled();
  
  	INIT_LIST_HEAD_RCU(&fp->aux->ksym.lnode);
++<<<<<<< HEAD
++=======
+ 	mutex_init(&fp->aux->used_maps_mutex);
+ 	mutex_init(&fp->aux->dst_mutex);
++>>>>>>> 3aac1ead5eb6 (bpf: Move prog->aux->linked_prog and trampoline into bpf_link on attach)
  
  	return fp;
  }
@@@ -257,6 -255,8 +262,11 @@@ struct bpf_prog *bpf_prog_realloc(struc
  void __bpf_prog_free(struct bpf_prog *fp)
  {
  	if (fp->aux) {
++<<<<<<< HEAD
++=======
+ 		mutex_destroy(&fp->aux->used_maps_mutex);
+ 		mutex_destroy(&fp->aux->dst_mutex);
++>>>>>>> 3aac1ead5eb6 (bpf: Move prog->aux->linked_prog and trampoline into bpf_link on attach)
  		free_percpu(fp->aux->stats);
  		kfree(fp->aux->poke_tab);
  		kfree(fp->aux);
diff --cc kernel/bpf/verifier.c
index 9fd915b15d99,a97a2f2964e3..000000000000
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@@ -10793,23 -11426,125 +10792,108 @@@ static int check_attach_btf_id(struct b
  			}
  		}
  
 -		if (prog->aux->sleepable) {
 -			ret = -EINVAL;
 -			switch (prog->type) {
 -			case BPF_PROG_TYPE_TRACING:
 -				/* fentry/fexit/fmod_ret progs can be sleepable only if they are
 -				 * attached to ALLOW_ERROR_INJECTION and are not in denylist.
 -				 */
 -				if (!check_non_sleepable_error_inject(btf_id) &&
 -				    within_error_injection_list(addr))
 -					ret = 0;
 -				break;
 -			case BPF_PROG_TYPE_LSM:
 -				/* LSM progs check that they are attached to bpf_lsm_*() funcs.
 -				 * Only some of them are sleepable.
 -				 */
 -				if (check_sleepable_lsm_hook(btf_id))
 -					ret = 0;
 -				break;
 -			default:
 -				break;
 -			}
 -			if (ret) {
 -				bpf_log(log, "%s is not sleepable\n", tname);
 -				return ret;
 -			}
 -		} else if (prog->expected_attach_type == BPF_MODIFY_RETURN) {
 -			if (tgt_prog) {
 -				bpf_log(log, "can't modify return codes of BPF programs\n");
 -				return -EINVAL;
 -			}
 -			ret = check_attach_modify_return(addr, tname);
 -			if (ret) {
 -				bpf_log(log, "%s() is not modifiable\n", tname);
 -				return ret;
 -			}
 +		if (prog->expected_attach_type == BPF_MODIFY_RETURN) {
 +			ret = check_attach_modify_return(prog, addr);
 +			if (ret)
 +				verbose(env, "%s() is not modifiable\n",
 +					prog->aux->attach_func_name);
  		}
  
++<<<<<<< HEAD
 +		if (ret)
 +			goto out;
 +		tr->func.addr = (void *)addr;
 +		prog->aux->trampoline = tr;
 +out:
 +		mutex_unlock(&tr->mutex);
 +		if (ret)
 +			bpf_trampoline_put(tr);
 +		return ret;
 +	}
++=======
+ 		break;
+ 	}
+ 	tgt_info->tgt_addr = addr;
+ 	tgt_info->tgt_name = tname;
+ 	tgt_info->tgt_type = t;
+ 	return 0;
+ }
+ 
+ static int check_attach_btf_id(struct bpf_verifier_env *env)
+ {
+ 	struct bpf_prog *prog = env->prog;
+ 	struct bpf_prog *tgt_prog = prog->aux->dst_prog;
+ 	struct bpf_attach_target_info tgt_info = {};
+ 	u32 btf_id = prog->aux->attach_btf_id;
+ 	struct bpf_trampoline *tr;
+ 	int ret;
+ 	u64 key;
+ 
+ 	if (prog->aux->sleepable && prog->type != BPF_PROG_TYPE_TRACING &&
+ 	    prog->type != BPF_PROG_TYPE_LSM) {
+ 		verbose(env, "Only fentry/fexit/fmod_ret and lsm programs can be sleepable\n");
+ 		return -EINVAL;
+ 	}
+ 
+ 	if (prog->type == BPF_PROG_TYPE_STRUCT_OPS)
+ 		return check_struct_ops_btf_id(env);
+ 
+ 	if (prog->type != BPF_PROG_TYPE_TRACING &&
+ 	    prog->type != BPF_PROG_TYPE_LSM &&
+ 	    prog->type != BPF_PROG_TYPE_EXT)
+ 		return 0;
+ 
+ 	ret = bpf_check_attach_target(&env->log, prog, tgt_prog, btf_id, &tgt_info);
+ 	if (ret)
+ 		return ret;
+ 
+ 	if (tgt_prog && prog->type == BPF_PROG_TYPE_EXT) {
+ 		/* to make freplace equivalent to their targets, they need to
+ 		 * inherit env->ops and expected_attach_type for the rest of the
+ 		 * verification
+ 		 */
+ 		env->ops = bpf_verifier_ops[tgt_prog->type];
+ 		prog->expected_attach_type = tgt_prog->expected_attach_type;
+ 	}
+ 
+ 	/* store info about the attachment target that will be used later */
+ 	prog->aux->attach_func_proto = tgt_info.tgt_type;
+ 	prog->aux->attach_func_name = tgt_info.tgt_name;
+ 
+ 	if (prog->expected_attach_type == BPF_TRACE_RAW_TP) {
+ 		prog->aux->attach_btf_trace = true;
+ 		return 0;
+ 	} else if (prog->expected_attach_type == BPF_TRACE_ITER) {
+ 		if (!bpf_iter_prog_supported(prog))
+ 			return -EINVAL;
+ 		return 0;
+ 	}
+ 
+ 	if (prog->type == BPF_PROG_TYPE_LSM) {
+ 		ret = bpf_lsm_verify_prog(&env->log, prog);
+ 		if (ret < 0)
+ 			return ret;
+ 	}
+ 
+ 	key = bpf_trampoline_compute_key(tgt_prog, btf_id);
+ 	tr = bpf_trampoline_get(key, &tgt_info);
+ 	if (!tr)
+ 		return -ENOMEM;
+ 
+ 	prog->aux->dst_trampoline = tr;
+ 	return 0;
+ }
+ 
+ struct btf *bpf_get_btf_vmlinux(void)
+ {
+ 	if (!btf_vmlinux && IS_ENABLED(CONFIG_DEBUG_INFO_BTF)) {
+ 		mutex_lock(&bpf_verifier_lock);
+ 		if (!btf_vmlinux)
+ 			btf_vmlinux = btf_parse_vmlinux();
+ 		mutex_unlock(&bpf_verifier_lock);
+ 	}
+ 	return btf_vmlinux;
++>>>>>>> 3aac1ead5eb6 (bpf: Move prog->aux->linked_prog and trampoline into bpf_link on attach)
  }
  
  int bpf_check(struct bpf_prog **prog, union bpf_attr *attr,
* Unmerged path kernel/bpf/preload/iterators/iterators.bpf.c
* Unmerged path kernel/bpf/preload/iterators/iterators.skel.h
* Unmerged path include/linux/bpf.h
diff --git a/kernel/bpf/btf.c b/kernel/bpf/btf.c
index 52afb4b50a36..5dbf4d98c89f 100644
--- a/kernel/bpf/btf.c
+++ b/kernel/bpf/btf.c
@@ -3649,7 +3649,7 @@ struct btf *btf_parse_vmlinux(void)
 
 struct btf *bpf_prog_get_target_btf(const struct bpf_prog *prog)
 {
-	struct bpf_prog *tgt_prog = prog->aux->linked_prog;
+	struct bpf_prog *tgt_prog = prog->aux->dst_prog;
 
 	if (tgt_prog) {
 		return tgt_prog->aux->btf;
@@ -3676,7 +3676,7 @@ bool btf_ctx_access(int off, int size, enum bpf_access_type type,
 		    struct bpf_insn_access_aux *info)
 {
 	const struct btf_type *t = prog->aux->attach_func_proto;
-	struct bpf_prog *tgt_prog = prog->aux->linked_prog;
+	struct bpf_prog *tgt_prog = prog->aux->dst_prog;
 	struct btf *btf = bpf_prog_get_target_btf(prog);
 	const char *tname = prog->aux->attach_func_name;
 	struct bpf_verifier_log *log = info->log;
@@ -4492,7 +4492,7 @@ int btf_prepare_func_args(struct bpf_verifier_env *env, int subprog,
 		return -EFAULT;
 	}
 	if (prog_type == BPF_PROG_TYPE_EXT)
-		prog_type = prog->aux->linked_prog->type;
+		prog_type = prog->aux->dst_prog->type;
 
 	t = btf_type_by_id(btf, t->type);
 	if (!t || !btf_type_is_func_proto(t)) {
* Unmerged path kernel/bpf/core.c
* Unmerged path kernel/bpf/preload/iterators/iterators.bpf.c
* Unmerged path kernel/bpf/preload/iterators/iterators.skel.h
diff --git a/kernel/bpf/syscall.c b/kernel/bpf/syscall.c
index 124e66325086..45b1ed436257 100644
--- a/kernel/bpf/syscall.c
+++ b/kernel/bpf/syscall.c
@@ -2096,14 +2096,14 @@ static int bpf_prog_load(union bpf_attr *attr, union bpf_attr __user *uattr)
 	prog->expected_attach_type = attr->expected_attach_type;
 	prog->aux->attach_btf_id = attr->attach_btf_id;
 	if (attr->attach_prog_fd) {
-		struct bpf_prog *tgt_prog;
+		struct bpf_prog *dst_prog;
 
-		tgt_prog = bpf_prog_get(attr->attach_prog_fd);
-		if (IS_ERR(tgt_prog)) {
-			err = PTR_ERR(tgt_prog);
+		dst_prog = bpf_prog_get(attr->attach_prog_fd);
+		if (IS_ERR(dst_prog)) {
+			err = PTR_ERR(dst_prog);
 			goto free_prog_nouncharge;
 		}
-		prog->aux->linked_prog = tgt_prog;
+		prog->aux->dst_prog = dst_prog;
 	}
 
 	prog->aux->offload_requested = !!attr->prog_ifindex;
@@ -2439,11 +2439,23 @@ struct bpf_link *bpf_link_get_from_fd(u32 ufd)
 struct bpf_tracing_link {
 	struct bpf_link link;
 	enum bpf_attach_type attach_type;
+	struct bpf_trampoline *trampoline;
+	struct bpf_prog *tgt_prog;
 };
 
 static void bpf_tracing_link_release(struct bpf_link *link)
 {
-	WARN_ON_ONCE(bpf_trampoline_unlink_prog(link->prog));
+	struct bpf_tracing_link *tr_link =
+		container_of(link, struct bpf_tracing_link, link);
+
+	WARN_ON_ONCE(bpf_trampoline_unlink_prog(link->prog,
+						tr_link->trampoline));
+
+	bpf_trampoline_put(tr_link->trampoline);
+
+	/* tgt_prog is NULL if target is a kernel function */
+	if (tr_link->tgt_prog)
+		bpf_prog_put(tr_link->tgt_prog);
 }
 
 static void bpf_tracing_link_dealloc(struct bpf_link *link)
@@ -2486,7 +2498,9 @@ static const struct bpf_link_ops bpf_tracing_link_lops = {
 static int bpf_tracing_prog_attach(struct bpf_prog *prog)
 {
 	struct bpf_link_primer link_primer;
+	struct bpf_prog *tgt_prog = NULL;
 	struct bpf_tracing_link *link;
+	struct bpf_trampoline *tr;
 	int err;
 
 	switch (prog->type) {
@@ -2524,19 +2538,37 @@ static int bpf_tracing_prog_attach(struct bpf_prog *prog)
 		      &bpf_tracing_link_lops, prog);
 	link->attach_type = prog->expected_attach_type;
 
-	err = bpf_link_prime(&link->link, &link_primer);
-	if (err) {
-		kfree(link);
-		goto out_put_prog;
+	mutex_lock(&prog->aux->dst_mutex);
+
+	if (!prog->aux->dst_trampoline) {
+		err = -ENOENT;
+		goto out_unlock;
 	}
+	tr = prog->aux->dst_trampoline;
+	tgt_prog = prog->aux->dst_prog;
+
+	err = bpf_link_prime(&link->link, &link_primer);
+	if (err)
+		goto out_unlock;
 
-	err = bpf_trampoline_link_prog(prog);
+	err = bpf_trampoline_link_prog(prog, tr);
 	if (err) {
 		bpf_link_cleanup(&link_primer);
-		goto out_put_prog;
+		link = NULL;
+		goto out_unlock;
 	}
 
+	link->tgt_prog = tgt_prog;
+	link->trampoline = tr;
+
+	prog->aux->dst_prog = NULL;
+	prog->aux->dst_trampoline = NULL;
+	mutex_unlock(&prog->aux->dst_mutex);
+
 	return bpf_link_settle(&link_primer);
+out_unlock:
+	mutex_unlock(&prog->aux->dst_mutex);
+	kfree(link);
 out_put_prog:
 	bpf_prog_put(prog);
 	return err;
diff --git a/kernel/bpf/trampoline.c b/kernel/bpf/trampoline.c
index 9be85aa4ec5f..3808e47ae98e 100644
--- a/kernel/bpf/trampoline.c
+++ b/kernel/bpf/trampoline.c
@@ -256,14 +256,12 @@ static enum bpf_tramp_prog_type bpf_attach_type_to_tramp(struct bpf_prog *prog)
 	}
 }
 
-int bpf_trampoline_link_prog(struct bpf_prog *prog)
+int bpf_trampoline_link_prog(struct bpf_prog *prog, struct bpf_trampoline *tr)
 {
 	enum bpf_tramp_prog_type kind;
-	struct bpf_trampoline *tr;
 	int err = 0;
 	int cnt;
 
-	tr = prog->aux->trampoline;
 	kind = bpf_attach_type_to_tramp(prog);
 	mutex_lock(&tr->mutex);
 	if (tr->extension_prog) {
@@ -296,7 +294,7 @@ int bpf_trampoline_link_prog(struct bpf_prog *prog)
 	}
 	hlist_add_head(&prog->aux->tramp_hlist, &tr->progs_hlist[kind]);
 	tr->progs_cnt[kind]++;
-	err = bpf_trampoline_update(prog->aux->trampoline);
+	err = bpf_trampoline_update(tr);
 	if (err) {
 		hlist_del(&prog->aux->tramp_hlist);
 		tr->progs_cnt[kind]--;
@@ -307,13 +305,11 @@ int bpf_trampoline_link_prog(struct bpf_prog *prog)
 }
 
 /* bpf_trampoline_unlink_prog() should never fail. */
-int bpf_trampoline_unlink_prog(struct bpf_prog *prog)
+int bpf_trampoline_unlink_prog(struct bpf_prog *prog, struct bpf_trampoline *tr)
 {
 	enum bpf_tramp_prog_type kind;
-	struct bpf_trampoline *tr;
 	int err;
 
-	tr = prog->aux->trampoline;
 	kind = bpf_attach_type_to_tramp(prog);
 	mutex_lock(&tr->mutex);
 	if (kind == BPF_TRAMP_REPLACE) {
@@ -325,7 +321,7 @@ int bpf_trampoline_unlink_prog(struct bpf_prog *prog)
 	}
 	hlist_del(&prog->aux->tramp_hlist);
 	tr->progs_cnt[kind]--;
-	err = bpf_trampoline_update(prog->aux->trampoline);
+	err = bpf_trampoline_update(tr);
 out:
 	mutex_unlock(&tr->mutex);
 	return err;
* Unmerged path kernel/bpf/verifier.c
