mptcp: track window announced to peer

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Florian Westphal <fw@strlen.de>
commit fa3fe2b150316b294f2c662653501273ff25bba8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/fa3fe2b1.failed

OoO handling attempts to detect when packet is out-of-window by testing
current ack sequence and remaining space vs. sequence number.

This doesn't work reliably. Store the highest allowed sequence number
that we've announced and use it to detect oow packets.

Do this when mptcp options get written to the packet (wire format).
For this to work we need to move the write_options call until after
stack selected a new tcp window.

	Acked-by: Paolo Abeni <pabeni@redhat.com>
	Signed-off-by: Florian Westphal <fw@strlen.de>
	Signed-off-by: Mat Martineau <mathew.j.martineau@linux.intel.com>
	Signed-off-by: Jakub Kicinski <kuba@kernel.org>
(cherry picked from commit fa3fe2b150316b294f2c662653501273ff25bba8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/mptcp/protocol.c
diff --cc net/mptcp/protocol.c
index 75ee5f9fd199,e1606e072218..000000000000
--- a/net/mptcp/protocol.c
+++ b/net/mptcp/protocol.c
@@@ -145,10 -149,135 +145,139 @@@ static bool mptcp_try_coalesce(struct s
  	return true;
  }
  
 -static bool mptcp_ooo_try_coalesce(struct mptcp_sock *msk, struct sk_buff *to,
 -				   struct sk_buff *from)
 +static void __mptcp_move_skb(struct mptcp_sock *msk, struct sock *ssk,
 +			     struct sk_buff *skb,
 +			     unsigned int offset, size_t copy_len)
  {
++<<<<<<< HEAD
++=======
+ 	if (MPTCP_SKB_CB(from)->map_seq != MPTCP_SKB_CB(to)->end_seq)
+ 		return false;
+ 
+ 	return mptcp_try_coalesce((struct sock *)msk, to, from);
+ }
+ 
+ /* "inspired" by tcp_data_queue_ofo(), main differences:
+  * - use mptcp seqs
+  * - don't cope with sacks
+  */
+ static void mptcp_data_queue_ofo(struct mptcp_sock *msk, struct sk_buff *skb)
+ {
+ 	struct sock *sk = (struct sock *)msk;
+ 	struct rb_node **p, *parent;
+ 	u64 seq, end_seq, max_seq;
+ 	struct sk_buff *skb1;
+ 
+ 	seq = MPTCP_SKB_CB(skb)->map_seq;
+ 	end_seq = MPTCP_SKB_CB(skb)->end_seq;
+ 	max_seq = READ_ONCE(msk->rcv_wnd_sent);
+ 
+ 	pr_debug("msk=%p seq=%llx limit=%llx empty=%d", msk, seq, max_seq,
+ 		 RB_EMPTY_ROOT(&msk->out_of_order_queue));
+ 	if (after64(end_seq, max_seq)) {
+ 		/* out of window */
+ 		mptcp_drop(sk, skb);
+ 		pr_debug("oow by %lld, rcv_wnd_sent %llu\n",
+ 			 (unsigned long long)end_seq - (unsigned long)max_seq,
+ 			 (unsigned long long)msk->rcv_wnd_sent);
+ 		MPTCP_INC_STATS(sock_net(sk), MPTCP_MIB_NODSSWINDOW);
+ 		return;
+ 	}
+ 
+ 	p = &msk->out_of_order_queue.rb_node;
+ 	MPTCP_INC_STATS(sock_net(sk), MPTCP_MIB_OFOQUEUE);
+ 	if (RB_EMPTY_ROOT(&msk->out_of_order_queue)) {
+ 		rb_link_node(&skb->rbnode, NULL, p);
+ 		rb_insert_color(&skb->rbnode, &msk->out_of_order_queue);
+ 		msk->ooo_last_skb = skb;
+ 		goto end;
+ 	}
+ 
+ 	/* with 2 subflows, adding at end of ooo queue is quite likely
+ 	 * Use of ooo_last_skb avoids the O(Log(N)) rbtree lookup.
+ 	 */
+ 	if (mptcp_ooo_try_coalesce(msk, msk->ooo_last_skb, skb)) {
+ 		MPTCP_INC_STATS(sock_net(sk), MPTCP_MIB_OFOMERGE);
+ 		MPTCP_INC_STATS(sock_net(sk), MPTCP_MIB_OFOQUEUETAIL);
+ 		return;
+ 	}
+ 
+ 	/* Can avoid an rbtree lookup if we are adding skb after ooo_last_skb */
+ 	if (!before64(seq, MPTCP_SKB_CB(msk->ooo_last_skb)->end_seq)) {
+ 		MPTCP_INC_STATS(sock_net(sk), MPTCP_MIB_OFOQUEUETAIL);
+ 		parent = &msk->ooo_last_skb->rbnode;
+ 		p = &parent->rb_right;
+ 		goto insert;
+ 	}
+ 
+ 	/* Find place to insert this segment. Handle overlaps on the way. */
+ 	parent = NULL;
+ 	while (*p) {
+ 		parent = *p;
+ 		skb1 = rb_to_skb(parent);
+ 		if (before64(seq, MPTCP_SKB_CB(skb1)->map_seq)) {
+ 			p = &parent->rb_left;
+ 			continue;
+ 		}
+ 		if (before64(seq, MPTCP_SKB_CB(skb1)->end_seq)) {
+ 			if (!after64(end_seq, MPTCP_SKB_CB(skb1)->end_seq)) {
+ 				/* All the bits are present. Drop. */
+ 				mptcp_drop(sk, skb);
+ 				MPTCP_INC_STATS(sock_net(sk), MPTCP_MIB_DUPDATA);
+ 				return;
+ 			}
+ 			if (after64(seq, MPTCP_SKB_CB(skb1)->map_seq)) {
+ 				/* partial overlap:
+ 				 *     |     skb      |
+ 				 *  |     skb1    |
+ 				 * continue traversing
+ 				 */
+ 			} else {
+ 				/* skb's seq == skb1's seq and skb covers skb1.
+ 				 * Replace skb1 with skb.
+ 				 */
+ 				rb_replace_node(&skb1->rbnode, &skb->rbnode,
+ 						&msk->out_of_order_queue);
+ 				mptcp_drop(sk, skb1);
+ 				MPTCP_INC_STATS(sock_net(sk), MPTCP_MIB_DUPDATA);
+ 				goto merge_right;
+ 			}
+ 		} else if (mptcp_ooo_try_coalesce(msk, skb1, skb)) {
+ 			MPTCP_INC_STATS(sock_net(sk), MPTCP_MIB_OFOMERGE);
+ 			return;
+ 		}
+ 		p = &parent->rb_right;
+ 	}
+ 
+ insert:
+ 	/* Insert segment into RB tree. */
+ 	rb_link_node(&skb->rbnode, parent, p);
+ 	rb_insert_color(&skb->rbnode, &msk->out_of_order_queue);
+ 
+ merge_right:
+ 	/* Remove other segments covered by skb. */
+ 	while ((skb1 = skb_rb_next(skb)) != NULL) {
+ 		if (before64(end_seq, MPTCP_SKB_CB(skb1)->end_seq))
+ 			break;
+ 		rb_erase(&skb1->rbnode, &msk->out_of_order_queue);
+ 		mptcp_drop(sk, skb1);
+ 		MPTCP_INC_STATS(sock_net(sk), MPTCP_MIB_DUPDATA);
+ 	}
+ 	/* If there is no skb after us, we are the last_skb ! */
+ 	if (!skb1)
+ 		msk->ooo_last_skb = skb;
+ 
+ end:
+ 	skb_condense(skb);
+ 	skb_set_owner_r(skb, sk);
+ }
+ 
+ static bool __mptcp_move_skb(struct mptcp_sock *msk, struct sock *ssk,
+ 			     struct sk_buff *skb, unsigned int offset,
+ 			     size_t copy_len)
+ {
+ 	struct mptcp_subflow_context *subflow = mptcp_subflow_ctx(ssk);
++>>>>>>> fa3fe2b15031 (mptcp: track window announced to peer)
  	struct sock *sk = (struct sock *)msk;
  	struct sk_buff *tail;
  
@@@ -1777,7 -2294,8 +1906,12 @@@ struct sock *mptcp_sk_clone(const struc
  		msk->remote_key = mp_opt->sndr_key;
  		mptcp_crypto_key_sha(msk->remote_key, NULL, &ack_seq);
  		ack_seq++;
++<<<<<<< HEAD
 +		msk->ack_seq = ack_seq;
++=======
+ 		WRITE_ONCE(msk->ack_seq, ack_seq);
+ 		WRITE_ONCE(msk->rcv_wnd_sent, ack_seq);
++>>>>>>> fa3fe2b15031 (mptcp: track window announced to peer)
  	}
  
  	sock_reset_flag(nsk, SOCK_RCU_FREE);
diff --git a/include/net/mptcp.h b/include/net/mptcp.h
index 85716fd90e9a..e9f3d3df3863 100644
--- a/include/net/mptcp.h
+++ b/include/net/mptcp.h
@@ -88,7 +88,8 @@ bool mptcp_established_options(struct sock *sk, struct sk_buff *skb,
 			       struct mptcp_out_options *opts);
 void mptcp_incoming_options(struct sock *sk, struct sk_buff *skb);
 
-void mptcp_write_options(__be32 *ptr, struct mptcp_out_options *opts);
+void mptcp_write_options(__be32 *ptr, const struct tcp_sock *tp,
+			 struct mptcp_out_options *opts);
 
 /* move the skb extension owership, with the assumption that 'to' is
  * newly allocated
diff --git a/net/ipv4/tcp_output.c b/net/ipv4/tcp_output.c
index 356a9acdc58b..e90928da7579 100644
--- a/net/ipv4/tcp_output.c
+++ b/net/ipv4/tcp_output.c
@@ -448,11 +448,12 @@ struct tcp_out_options {
 	struct mptcp_out_options mptcp;
 };
 
-static void mptcp_options_write(__be32 *ptr, struct tcp_out_options *opts)
+static void mptcp_options_write(__be32 *ptr, const struct tcp_sock *tp,
+				struct tcp_out_options *opts)
 {
 #if IS_ENABLED(CONFIG_MPTCP)
 	if (unlikely(OPTION_MPTCP & opts->options))
-		mptcp_write_options(ptr, &opts->mptcp);
+		mptcp_write_options(ptr, tp, &opts->mptcp);
 #endif
 }
 
@@ -565,7 +566,7 @@ static void tcp_options_write(__be32 *ptr, struct tcp_sock *tp,
 
 	smc_options_write(ptr, &options);
 
-	mptcp_options_write(ptr, opts);
+	mptcp_options_write(ptr, tp, opts);
 }
 
 static void smc_set_option(const struct tcp_sock *tp,
@@ -1179,7 +1180,6 @@ static int __tcp_transmit_skb(struct sock *sk, struct sk_buff *skb,
 		}
 	}
 
-	tcp_options_write((__be32 *)(th + 1), tp, &opts);
 	skb_shinfo(skb)->gso_type = sk->sk_gso_type;
 	if (likely(!(tcb->tcp_flags & TCPHDR_SYN))) {
 		th->window      = htons(tcp_select_window(sk));
@@ -1190,6 +1190,9 @@ static int __tcp_transmit_skb(struct sock *sk, struct sk_buff *skb,
 		 */
 		th->window	= htons(min(tp->rcv_wnd, 65535U));
 	}
+
+	tcp_options_write((__be32 *)(th + 1), tp, &opts);
+
 #ifdef CONFIG_TCP_MD5SIG
 	/* Calculate the MD5 hash, as we have all we need now */
 	if (md5) {
diff --git a/net/mptcp/options.c b/net/mptcp/options.c
index cfc2e1d06a18..73d65be25a56 100644
--- a/net/mptcp/options.c
+++ b/net/mptcp/options.c
@@ -912,7 +912,24 @@ void mptcp_incoming_options(struct sock *sk, struct sk_buff *skb)
 	}
 }
 
-void mptcp_write_options(__be32 *ptr, struct mptcp_out_options *opts)
+static void mptcp_set_rwin(const struct tcp_sock *tp)
+{
+	const struct sock *ssk = (const struct sock *)tp;
+	const struct mptcp_subflow_context *subflow;
+	struct mptcp_sock *msk;
+	u64 ack_seq;
+
+	subflow = mptcp_subflow_ctx(ssk);
+	msk = mptcp_sk(subflow->conn);
+
+	ack_seq = READ_ONCE(msk->ack_seq) + tp->rcv_wnd;
+
+	if (after64(ack_seq, READ_ONCE(msk->rcv_wnd_sent)))
+		WRITE_ONCE(msk->rcv_wnd_sent, ack_seq);
+}
+
+void mptcp_write_options(__be32 *ptr, const struct tcp_sock *tp,
+			 struct mptcp_out_options *opts)
 {
 	if ((OPTION_MPTCP_MPC_SYN | OPTION_MPTCP_MPC_SYNACK |
 	     OPTION_MPTCP_MPC_ACK) & opts->suboptions) {
@@ -1069,4 +1086,7 @@ void mptcp_write_options(__be32 *ptr, struct mptcp_out_options *opts)
 					   TCPOPT_NOP << 8 | TCPOPT_NOP, ptr);
 		}
 	}
+
+	if (tp)
+		mptcp_set_rwin(tp);
 }
* Unmerged path net/mptcp/protocol.c
diff --git a/net/mptcp/protocol.h b/net/mptcp/protocol.h
index a60ec79c4e54..98bf7bdd93cc 100644
--- a/net/mptcp/protocol.h
+++ b/net/mptcp/protocol.h
@@ -203,6 +203,7 @@ struct mptcp_sock {
 	u64		write_seq;
 	u64		snd_nxt;
 	u64		ack_seq;
+	u64		rcv_wnd_sent;
 	u64		rcv_data_fin_seq;
 	atomic64_t	snd_una;
 	unsigned long	timer_ival;
