docs/mm: vmalloc: re-indent kernel-doc comemnts

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Mike Rapoport <rppt@linux.ibm.com>
commit 92eac16819e47ab919bd8f28ed49f8fadad0954e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/92eac168.failed

Some kernel-doc comments in mm/vmalloc.c have leading tab in
indentation.  This leads to excessive indentation in the generated HTML
and to the inconsistency of its layout ([1] vs [2]).

Besides, multi-line Note: sections are not handled properly with extra
indentation.

[1] https://www.kernel.org/doc/html/v4.20/core-api/mm-api.html?#c.vm_map_ram
[2] https://www.kernel.org/doc/html/v4.20/core-api/mm-api.html?#c.vfree

Link: http://lkml.kernel.org/r/1549549644-4903-2-git-send-email-rppt@linux.ibm.com
	Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
	Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
	Cc: Jonathan Corbet <corbet@lwn.net>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 92eac16819e47ab919bd8f28ed49f8fadad0954e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/vmalloc.c
diff --cc mm/vmalloc.c
index c82a0db1aefc,03cbba890301..000000000000
--- a/mm/vmalloc.c
+++ b/mm/vmalloc.c
@@@ -1645,19 -1570,29 +1646,25 @@@ void vfree_atomic(const void *addr
  	__vfree_deferred(addr);
  }
  
 -static void __vfree(const void *addr)
 -{
 -	if (unlikely(in_interrupt()))
 -		__vfree_deferred(addr);
 -	else
 -		__vunmap(addr, 1);
 -}
 -
  /**
-  *	vfree  -  release memory allocated by vmalloc()
-  *	@addr:		memory base address
+  * vfree - release memory allocated by vmalloc()
+  * @addr:  memory base address
   *
-  *	Free the virtually continuous memory area starting at @addr, as
-  *	obtained from vmalloc(), vmalloc_32() or __vmalloc(). If @addr is
-  *	NULL, no operation is performed.
+  * Free the virtually continuous memory area starting at @addr, as
+  * obtained from vmalloc(), vmalloc_32() or __vmalloc(). If @addr is
+  * NULL, no operation is performed.
   *
-  *	Must not be called in NMI context (strictly speaking, only if we don't
-  *	have CONFIG_ARCH_HAVE_NMI_SAFE_CMPXCHG, but making the calling
-  *	conventions for vfree() arch-depenedent would be a really bad idea)
+  * Must not be called in NMI context (strictly speaking, only if we don't
+  * have CONFIG_ARCH_HAVE_NMI_SAFE_CMPXCHG, but making the calling
+  * conventions for vfree() arch-depenedent would be a really bad idea)
   *
++<<<<<<< HEAD
 + *	NOTE: assumes that the object at @addr has a size >= sizeof(llist_node)
++=======
+  * May sleep if called *not* from interrupt context.
+  *
+  * NOTE: assumes that the object at @addr has a size >= sizeof(llist_node)
++>>>>>>> 92eac16819e4 (docs/mm: vmalloc: re-indent kernel-doc comemnts)
   */
  void vfree(const void *addr)
  {
@@@ -1844,25 -1779,33 +1851,24 @@@ fail
  	return NULL;
  }
  
 -/*
 - * This is only for performance analysis of vmalloc and stress purpose.
 - * It is required by vmalloc test module, therefore do not use it other
 - * than that.
 - */
 -#ifdef CONFIG_TEST_VMALLOC_MODULE
 -EXPORT_SYMBOL_GPL(__vmalloc_node_range);
 -#endif
 -
  /**
-  *	__vmalloc_node  -  allocate virtually contiguous memory
-  *	@size:		allocation size
-  *	@align:		desired alignment
-  *	@gfp_mask:	flags for the page level allocator
-  *	@prot:		protection mask for the allocated pages
-  *	@node:		node to use for allocation or NUMA_NO_NODE
-  *	@caller:	caller's return address
-  *
-  *	Allocate enough pages to cover @size from the page level
-  *	allocator with @gfp_mask flags.  Map them into contiguous
-  *	kernel virtual space, using a pagetable protection of @prot.
+  * __vmalloc_node - allocate virtually contiguous memory
+  * @size:	    allocation size
+  * @align:	    desired alignment
+  * @gfp_mask:	    flags for the page level allocator
+  * @prot:	    protection mask for the allocated pages
+  * @node:	    node to use for allocation or NUMA_NO_NODE
+  * @caller:	    caller's return address
   *
-  *	Reclaim modifiers in @gfp_mask - __GFP_NORETRY, __GFP_RETRY_MAYFAIL
-  *	and __GFP_NOFAIL are not supported
+  * Allocate enough pages to cover @size from the page level
+  * allocator with @gfp_mask flags.  Map them into contiguous
+  * kernel virtual space, using a pagetable protection of @prot.
   *
-  *	Any use of gfp flags outside of GFP_KERNEL should be consulted
-  *	with mm people.
+  * Reclaim modifiers in @gfp_mask - __GFP_NORETRY, __GFP_RETRY_MAYFAIL
+  * and __GFP_NOFAIL are not supported
   *
+  * Any use of gfp flags outside of GFP_KERNEL should be consulted
+  * with mm people.
   */
  static void *__vmalloc_node(unsigned long size, unsigned long align,
  			    gfp_t gfp_mask, pgprot_t prot,
@@@ -1988,46 -1925,20 +1996,50 @@@ void *vzalloc_node(unsigned long size, 
  EXPORT_SYMBOL(vzalloc_node);
  
  /**
++<<<<<<< HEAD
 + * vmalloc_user_node_flags - allocate memory for userspace on a specific node
 + * @size: allocation size
 + * @node: numa node
 + * @flags: flags for the page level allocator
 + *
 + * The resulting memory area is zeroed so it can be mapped to userspace
 + * without leaking data.
 + *
 + * Return: pointer to the allocated memory or %NULL on error
 + */
 +void *vmalloc_user_node_flags(unsigned long size, int node, gfp_t flags)
 +{
 +	return __vmalloc_node_range(size, SHMLBA,  VMALLOC_START, VMALLOC_END,
 +				    flags | __GFP_ZERO, PAGE_KERNEL,
 +				    VM_USERMAP, node,
 +				    __builtin_return_address(0));
 +}
 +EXPORT_SYMBOL(vmalloc_user_node_flags);
 +
 +#ifndef PAGE_KERNEL_EXEC
 +# define PAGE_KERNEL_EXEC PAGE_KERNEL
 +#endif
 +
 +/**
 + *	vmalloc_exec  -  allocate virtually contiguous, executable memory
 + *	@size:		allocation size
++=======
+  * vmalloc_exec - allocate virtually contiguous, executable memory
+  * @size:	  allocation size
++>>>>>>> 92eac16819e4 (docs/mm: vmalloc: re-indent kernel-doc comemnts)
   *
-  *	Kernel-internal function to allocate enough pages to cover @size
-  *	the page level allocator and map them into contiguous and
-  *	executable kernel virtual space.
+  * Kernel-internal function to allocate enough pages to cover @size
+  * the page level allocator and map them into contiguous and
+  * executable kernel virtual space.
   *
-  *	For tight control over page level allocator and protection flags
-  *	use __vmalloc() instead.
+  * For tight control over page level allocator and protection flags
+  * use __vmalloc() instead.
   */
- 
  void *vmalloc_exec(unsigned long size)
  {
 -	return __vmalloc_node(size, 1, GFP_KERNEL, PAGE_KERNEL_EXEC,
 -			      NUMA_NO_NODE, __builtin_return_address(0));
 +	return __vmalloc_node_range(size, 1, VMALLOC_START, VMALLOC_END,
 +			GFP_KERNEL, PAGE_KERNEL_EXEC, VM_FLUSH_RESET_PERMS,
 +			NUMA_NO_NODE, __builtin_return_address(0));
  }
  
  #if defined(CONFIG_64BIT) && defined(CONFIG_ZONE_DMA32)
@@@ -2317,32 -2219,25 +2326,40 @@@ finished
  }
  
  /**
++<<<<<<< HEAD
 + *	remap_vmalloc_range_partial  -  map vmalloc pages to userspace
 + *	@vma:		vma to cover
 + *	@uaddr:		target user address to start at
 + *	@kaddr:		virtual address of vmalloc kernel memory
 + *	@pgoff:		offset from @kaddr to start at
 + *	@size:		size of map area
-  *
-  *	Returns:	0 for success, -Exxx on failure
-  *
-  *	This function checks that @kaddr is a valid vmalloc'ed area,
-  *	and that it is big enough to cover the range starting at
-  *	@uaddr in @vma. Will return failure if that criteria isn't
-  *	met.
-  *
-  *	Similar to remap_pfn_range() (see mm/memory.c)
++=======
+  * remap_vmalloc_range_partial - map vmalloc pages to userspace
+  * @vma:		vma to cover
+  * @uaddr:		target user address to start at
+  * @kaddr:		virtual address of vmalloc kernel memory
+  * @size:		size of map area
++>>>>>>> 92eac16819e4 (docs/mm: vmalloc: re-indent kernel-doc comemnts)
+  *
+  * Returns:	0 for success, -Exxx on failure
+  *
+  * This function checks that @kaddr is a valid vmalloc'ed area,
+  * and that it is big enough to cover the range starting at
+  * @uaddr in @vma. Will return failure if that criteria isn't
+  * met.
+  *
+  * Similar to remap_pfn_range() (see mm/memory.c)
   */
  int remap_vmalloc_range_partial(struct vm_area_struct *vma, unsigned long uaddr,
 -				void *kaddr, unsigned long size)
 +				void *kaddr, unsigned long pgoff,
 +				unsigned long size)
  {
  	struct vm_struct *area;
 +	unsigned long off;
 +	unsigned long end_index;
 +
 +	if (check_shl_overflow(pgoff, PAGE_SHIFT, &off))
 +		return -EINVAL;
  
  	size = PAGE_ALIGN(size);
  
* Unmerged path mm/vmalloc.c
