bpf: Add comments to interpret bpf_prog return values

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Yonghong Song <yhs@fb.com>
commit 2e3ed68bfcd9c5ca2cf8b88ba23a34992ccd0b1f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/2e3ed68b.failed

Add a short comment in bpf_iter_run_prog() function to
explain how bpf_prog return value is converted to
seq_ops->show() return value:
  bpf_prog return           seq_ops()->show() return
     0                         0
     1                         -EAGAIN

When show() return value is -EAGAIN, the current
bpf_seq_read() will end. If the current seq_file buffer
is empty, -EAGAIN will return to user space. Otherwise,
the buffer will be copied to user space.
In both cases, the next bpf_seq_read() call will
try to show the same object which returned -EAGAIN
previously.

	Signed-off-by: Yonghong Song <yhs@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Andrii Nakryiko <andriin@fb.com>
Link: https://lore.kernel.org/bpf/20200513180218.2949517-1-yhs@fb.com
(cherry picked from commit 2e3ed68bfcd9c5ca2cf8b88ba23a34992ccd0b1f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/bpf_iter.c
diff --cc kernel/bpf/bpf_iter.c
index 5a8119d17d14,0a45a6cdfabd..000000000000
--- a/kernel/bpf/bpf_iter.c
+++ b/kernel/bpf/bpf_iter.c
@@@ -57,3 -278,259 +57,262 @@@ void bpf_iter_unreg_target(const char *
  
  	WARN_ON(found == false);
  }
++<<<<<<< HEAD
++=======
+ 
+ static void cache_btf_id(struct bpf_iter_target_info *tinfo,
+ 			 struct bpf_prog *prog)
+ {
+ 	tinfo->btf_id = prog->aux->attach_btf_id;
+ }
+ 
+ bool bpf_iter_prog_supported(struct bpf_prog *prog)
+ {
+ 	const char *attach_fname = prog->aux->attach_func_name;
+ 	u32 prog_btf_id = prog->aux->attach_btf_id;
+ 	const char *prefix = BPF_ITER_FUNC_PREFIX;
+ 	struct bpf_iter_target_info *tinfo;
+ 	int prefix_len = strlen(prefix);
+ 	bool supported = false;
+ 
+ 	if (strncmp(attach_fname, prefix, prefix_len))
+ 		return false;
+ 
+ 	mutex_lock(&targets_mutex);
+ 	list_for_each_entry(tinfo, &targets, list) {
+ 		if (tinfo->btf_id && tinfo->btf_id == prog_btf_id) {
+ 			supported = true;
+ 			break;
+ 		}
+ 		if (!strcmp(attach_fname + prefix_len, tinfo->target)) {
+ 			cache_btf_id(tinfo, prog);
+ 			supported = true;
+ 			break;
+ 		}
+ 	}
+ 	mutex_unlock(&targets_mutex);
+ 
+ 	return supported;
+ }
+ 
+ static void bpf_iter_link_release(struct bpf_link *link)
+ {
+ }
+ 
+ static void bpf_iter_link_dealloc(struct bpf_link *link)
+ {
+ 	struct bpf_iter_link *iter_link =
+ 		container_of(link, struct bpf_iter_link, link);
+ 
+ 	kfree(iter_link);
+ }
+ 
+ static int bpf_iter_link_replace(struct bpf_link *link,
+ 				 struct bpf_prog *new_prog,
+ 				 struct bpf_prog *old_prog)
+ {
+ 	int ret = 0;
+ 
+ 	mutex_lock(&link_mutex);
+ 	if (old_prog && link->prog != old_prog) {
+ 		ret = -EPERM;
+ 		goto out_unlock;
+ 	}
+ 
+ 	if (link->prog->type != new_prog->type ||
+ 	    link->prog->expected_attach_type != new_prog->expected_attach_type ||
+ 	    link->prog->aux->attach_btf_id != new_prog->aux->attach_btf_id) {
+ 		ret = -EINVAL;
+ 		goto out_unlock;
+ 	}
+ 
+ 	old_prog = xchg(&link->prog, new_prog);
+ 	bpf_prog_put(old_prog);
+ 
+ out_unlock:
+ 	mutex_unlock(&link_mutex);
+ 	return ret;
+ }
+ 
+ static const struct bpf_link_ops bpf_iter_link_lops = {
+ 	.release = bpf_iter_link_release,
+ 	.dealloc = bpf_iter_link_dealloc,
+ 	.update_prog = bpf_iter_link_replace,
+ };
+ 
+ bool bpf_link_is_iter(struct bpf_link *link)
+ {
+ 	return link->ops == &bpf_iter_link_lops;
+ }
+ 
+ int bpf_iter_link_attach(const union bpf_attr *attr, struct bpf_prog *prog)
+ {
+ 	struct bpf_link_primer link_primer;
+ 	struct bpf_iter_target_info *tinfo;
+ 	struct bpf_iter_link *link;
+ 	bool existed = false;
+ 	u32 prog_btf_id;
+ 	int err;
+ 
+ 	if (attr->link_create.target_fd || attr->link_create.flags)
+ 		return -EINVAL;
+ 
+ 	prog_btf_id = prog->aux->attach_btf_id;
+ 	mutex_lock(&targets_mutex);
+ 	list_for_each_entry(tinfo, &targets, list) {
+ 		if (tinfo->btf_id == prog_btf_id) {
+ 			existed = true;
+ 			break;
+ 		}
+ 	}
+ 	mutex_unlock(&targets_mutex);
+ 	if (!existed)
+ 		return -ENOENT;
+ 
+ 	link = kzalloc(sizeof(*link), GFP_USER | __GFP_NOWARN);
+ 	if (!link)
+ 		return -ENOMEM;
+ 
+ 	bpf_link_init(&link->link, BPF_LINK_TYPE_ITER, &bpf_iter_link_lops, prog);
+ 	link->tinfo = tinfo;
+ 
+ 	err  = bpf_link_prime(&link->link, &link_primer);
+ 	if (err) {
+ 		kfree(link);
+ 		return err;
+ 	}
+ 
+ 	return bpf_link_settle(&link_primer);
+ }
+ 
+ static void init_seq_meta(struct bpf_iter_priv_data *priv_data,
+ 			  struct bpf_iter_target_info *tinfo,
+ 			  struct bpf_prog *prog)
+ {
+ 	priv_data->tinfo = tinfo;
+ 	priv_data->prog = prog;
+ 	priv_data->session_id = atomic64_inc_return(&session_id);
+ 	priv_data->seq_num = 0;
+ 	priv_data->done_stop = false;
+ }
+ 
+ static int prepare_seq_file(struct file *file, struct bpf_iter_link *link)
+ {
+ 	struct bpf_iter_priv_data *priv_data;
+ 	struct bpf_iter_target_info *tinfo;
+ 	struct bpf_prog *prog;
+ 	u32 total_priv_dsize;
+ 	struct seq_file *seq;
+ 	int err = 0;
+ 
+ 	mutex_lock(&link_mutex);
+ 	prog = link->link.prog;
+ 	bpf_prog_inc(prog);
+ 	mutex_unlock(&link_mutex);
+ 
+ 	tinfo = link->tinfo;
+ 	total_priv_dsize = offsetof(struct bpf_iter_priv_data, target_private) +
+ 			   tinfo->seq_priv_size;
+ 	priv_data = __seq_open_private(file, tinfo->seq_ops, total_priv_dsize);
+ 	if (!priv_data) {
+ 		err = -ENOMEM;
+ 		goto release_prog;
+ 	}
+ 
+ 	if (tinfo->init_seq_private) {
+ 		err = tinfo->init_seq_private(priv_data->target_private);
+ 		if (err)
+ 			goto release_seq_file;
+ 	}
+ 
+ 	init_seq_meta(priv_data, tinfo, prog);
+ 	seq = file->private_data;
+ 	seq->private = priv_data->target_private;
+ 
+ 	return 0;
+ 
+ release_seq_file:
+ 	seq_release_private(file->f_inode, file);
+ 	file->private_data = NULL;
+ release_prog:
+ 	bpf_prog_put(prog);
+ 	return err;
+ }
+ 
+ int bpf_iter_new_fd(struct bpf_link *link)
+ {
+ 	struct file *file;
+ 	unsigned int flags;
+ 	int err, fd;
+ 
+ 	if (link->ops != &bpf_iter_link_lops)
+ 		return -EINVAL;
+ 
+ 	flags = O_RDONLY | O_CLOEXEC;
+ 	fd = get_unused_fd_flags(flags);
+ 	if (fd < 0)
+ 		return fd;
+ 
+ 	file = anon_inode_getfile("bpf_iter", &bpf_iter_fops, NULL, flags);
+ 	if (IS_ERR(file)) {
+ 		err = PTR_ERR(file);
+ 		goto free_fd;
+ 	}
+ 
+ 	err = prepare_seq_file(file,
+ 			       container_of(link, struct bpf_iter_link, link));
+ 	if (err)
+ 		goto free_file;
+ 
+ 	fd_install(fd, file);
+ 	return fd;
+ 
+ free_file:
+ 	fput(file);
+ free_fd:
+ 	put_unused_fd(fd);
+ 	return err;
+ }
+ 
+ struct bpf_prog *bpf_iter_get_info(struct bpf_iter_meta *meta, bool in_stop)
+ {
+ 	struct bpf_iter_priv_data *iter_priv;
+ 	struct seq_file *seq;
+ 	void *seq_priv;
+ 
+ 	seq = meta->seq;
+ 	if (seq->file->f_op != &bpf_iter_fops)
+ 		return NULL;
+ 
+ 	seq_priv = seq->private;
+ 	iter_priv = container_of(seq_priv, struct bpf_iter_priv_data,
+ 				 target_private);
+ 
+ 	if (in_stop && iter_priv->done_stop)
+ 		return NULL;
+ 
+ 	meta->session_id = iter_priv->session_id;
+ 	meta->seq_num = iter_priv->seq_num;
+ 
+ 	return iter_priv->prog;
+ }
+ 
+ int bpf_iter_run_prog(struct bpf_prog *prog, void *ctx)
+ {
+ 	int ret;
+ 
+ 	rcu_read_lock();
+ 	migrate_disable();
+ 	ret = BPF_PROG_RUN(prog, ctx);
+ 	migrate_enable();
+ 	rcu_read_unlock();
+ 
+ 	/* bpf program can only return 0 or 1:
+ 	 *  0 : okay
+ 	 *  1 : retry the same object
+ 	 * The bpf_iter_run_prog() return value
+ 	 * will be seq_ops->show() return value.
+ 	 */
+ 	return ret == 0 ? 0 : -EAGAIN;
+ }
++>>>>>>> 2e3ed68bfcd9 (bpf: Add comments to interpret bpf_prog return values)
* Unmerged path kernel/bpf/bpf_iter.c
