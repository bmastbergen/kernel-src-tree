net/mlx5e: Generalize TX MPWQE checks for full session

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Maxim Mikityanskiy <maximmi@mellanox.com>
commit 530d5ce22ca2d7f54b756580c02d0772c053d221
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/530d5ce2.failed

As preparation for the upcoming TX MPWQE for SKBs, create a function
(mlx5e_tx_mpwqe_is_full) to check whether an MPWQE session is full. This
function will be shared by MPWQE code for XDP and for SKBs. Defines are
renamed and moved to make them not XDP-specific.

	Signed-off-by: Maxim Mikityanskiy <maximmi@mellanox.com>
	Reviewed-by: Tariq Toukan <tariqt@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@nvidia.com>
(cherry picked from commit 530d5ce22ca2d7f54b756580c02d0772c053d221)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en/txrx.h
#	drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/txrx.h
index 5bd77669337b,b4ee1f2f1746..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/txrx.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/txrx.h
@@@ -5,9 -5,60 +5,22 @@@
  #define __MLX5_EN_TXRX_H___
  
  #include "en.h"
 -#include <linux/indirect_call_wrapper.h>
 -
 -#define MLX5E_TX_WQE_EMPTY_DS_COUNT (sizeof(struct mlx5e_tx_wqe) / MLX5_SEND_WQE_DS)
  
+ /* The mult of MLX5_SEND_WQE_MAX_WQEBBS * MLX5_SEND_WQEBB_NUM_DS
+  * (16 * 4 == 64) does not fit in the 6-bit DS field of Ctrl Segment.
+  * We use a bound lower that MLX5_SEND_WQE_MAX_WQEBBS to let a
+  * full-session WQE be cache-aligned.
+  */
+ #if L1_CACHE_BYTES < 128
+ #define MLX5E_TX_MPW_MAX_WQEBBS (MLX5_SEND_WQE_MAX_WQEBBS - 1)
+ #else
+ #define MLX5E_TX_MPW_MAX_WQEBBS (MLX5_SEND_WQE_MAX_WQEBBS - 2)
+ #endif
+ 
+ #define MLX5E_TX_MPW_MAX_NUM_DS (MLX5E_TX_MPW_MAX_WQEBBS * MLX5_SEND_WQEBB_NUM_DS)
+ 
  #define INL_HDR_START_SZ (sizeof(((struct mlx5_wqe_eth_seg *)NULL)->inline_hdr.start))
  
 -enum mlx5e_icosq_wqe_type {
 -	MLX5E_ICOSQ_WQE_NOP,
 -	MLX5E_ICOSQ_WQE_UMR_RX,
 -#ifdef CONFIG_MLX5_EN_TLS
 -	MLX5E_ICOSQ_WQE_UMR_TLS,
 -	MLX5E_ICOSQ_WQE_SET_PSV_TLS,
 -	MLX5E_ICOSQ_WQE_GET_PSV_TLS,
 -#endif
 -};
 -
 -/* General */
 -void mlx5e_trigger_irq(struct mlx5e_icosq *sq);
 -void mlx5e_completion_event(struct mlx5_core_cq *mcq, struct mlx5_eqe *eqe);
 -void mlx5e_cq_error_event(struct mlx5_core_cq *mcq, enum mlx5_event event);
 -int mlx5e_napi_poll(struct napi_struct *napi, int budget);
 -int mlx5e_poll_ico_cq(struct mlx5e_cq *cq);
 -
 -/* RX */
 -void mlx5e_page_dma_unmap(struct mlx5e_rq *rq, struct mlx5e_dma_info *dma_info);
 -void mlx5e_page_release_dynamic(struct mlx5e_rq *rq,
 -				struct mlx5e_dma_info *dma_info,
 -				bool recycle);
 -INDIRECT_CALLABLE_DECLARE(bool mlx5e_post_rx_wqes(struct mlx5e_rq *rq));
 -INDIRECT_CALLABLE_DECLARE(bool mlx5e_post_rx_mpwqes(struct mlx5e_rq *rq));
 -int mlx5e_poll_rx_cq(struct mlx5e_cq *cq, int budget);
 -void mlx5e_free_rx_descs(struct mlx5e_rq *rq);
 -void mlx5e_free_rx_in_progress_descs(struct mlx5e_rq *rq);
 -
 -/* TX */
 -u16 mlx5e_select_queue(struct net_device *dev, struct sk_buff *skb,
 -		       struct net_device *sb_dev);
 -netdev_tx_t mlx5e_xmit(struct sk_buff *skb, struct net_device *dev);
 -bool mlx5e_poll_tx_cq(struct mlx5e_cq *cq, int napi_budget);
 -void mlx5e_free_txqsq_descs(struct mlx5e_txqsq *sq);
 -
  static inline bool
  mlx5e_wqc_has_room_for(struct mlx5_wq_cyc *wq, u16 cc, u16 pc, u16 n)
  {
@@@ -215,6 -277,13 +228,16 @@@ mlx5e_tx_dma_unmap(struct device *pdev
  	}
  }
  
++<<<<<<< HEAD
++=======
+ void mlx5e_sq_xmit_simple(struct mlx5e_txqsq *sq, struct sk_buff *skb, bool xmit_more);
+ 
+ static inline bool mlx5e_tx_mpwqe_is_full(struct mlx5e_xdp_mpwqe *session)
+ {
+ 	return session->ds_count == MLX5E_TX_MPW_MAX_NUM_DS;
+ }
+ 
++>>>>>>> 530d5ce22ca2 (net/mlx5e: Generalize TX MPWQE checks for full session)
  static inline void mlx5e_rqwq_reset(struct mlx5e_rq *rq)
  {
  	if (rq->wq_type == MLX5_WQ_TYPE_LINKED_LIST_STRIDING_RQ) {
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
index 367a398562d2,2a72496ceda9..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
@@@ -212,16 -196,19 +212,22 @@@ static void mlx5e_xdp_mpwqe_session_sta
  {
  	struct mlx5e_xdp_mpwqe *session = &sq->mpwqe;
  	struct mlx5e_xdpsq_stats *stats = sq->stats;
 -	struct mlx5e_tx_wqe *wqe;
  	u16 pi;
  
++<<<<<<< HEAD
 +	pi = mlx5e_xdpsq_get_next_pi(sq, MLX5E_XDP_MPW_MAX_WQEBBS);
 +	session->wqe = MLX5E_TX_FETCH_WQE(sq, pi);
++=======
+ 	pi = mlx5e_xdpsq_get_next_pi(sq, MLX5E_TX_MPW_MAX_WQEBBS);
+ 	wqe = MLX5E_TX_FETCH_WQE(sq, pi);
+ 	net_prefetchw(wqe->data);
++>>>>>>> 530d5ce22ca2 (net/mlx5e: Generalize TX MPWQE checks for full session)
  
 -	*session = (struct mlx5e_xdp_mpwqe) {
 -		.wqe = wqe,
 -		.ds_count = MLX5E_TX_WQE_EMPTY_DS_COUNT,
 -		.pkt_count = 0,
 -		.inline_on = mlx5e_xdp_get_inline_state(sq, session->inline_on),
 -	};
 +	prefetchw(session->wqe->data);
 +	session->ds_count  = MLX5E_XDP_TX_EMPTY_DS_COUNT;
 +	session->pkt_count = 0;
 +
 +	mlx5e_xdp_update_inline_state(sq);
  
  	stats->mpwqe++;
  }
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/txrx.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h b/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h
index b7a97dc7cba2..75c7a6156d1c 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.h
@@ -45,20 +45,6 @@
 	(MLX5E_XDP_INLINE_WQE_MAX_DS_CNT * MLX5_SEND_WQE_DS - \
 	 sizeof(struct mlx5_wqe_inline_seg))
 
-/* The mult of MLX5_SEND_WQE_MAX_WQEBBS * MLX5_SEND_WQEBB_NUM_DS
- * (16 * 4 == 64) does not fit in the 6-bit DS field of Ctrl Segment.
- * We use a bound lower that MLX5_SEND_WQE_MAX_WQEBBS to let a
- * full-session WQE be cache-aligned.
- */
-#if L1_CACHE_BYTES < 128
-#define MLX5E_XDP_MPW_MAX_WQEBBS (MLX5_SEND_WQE_MAX_WQEBBS - 1)
-#else
-#define MLX5E_XDP_MPW_MAX_WQEBBS (MLX5_SEND_WQE_MAX_WQEBBS - 2)
-#endif
-
-#define MLX5E_XDP_MPW_MAX_NUM_DS \
-	(MLX5E_XDP_MPW_MAX_WQEBBS * MLX5_SEND_WQEBB_NUM_DS)
-
 struct mlx5e_xsk_param;
 int mlx5e_xdp_max_mtu(struct mlx5e_params *params, struct mlx5e_xsk_param *xsk);
 bool mlx5e_xdp_handle(struct mlx5e_rq *rq, struct mlx5e_dma_info *di,
@@ -133,8 +119,8 @@ static inline bool mlx5e_xdp_mpqwe_is_full(struct mlx5e_xdp_mpwqe *session)
 {
 	if (session->inline_on)
 		return session->ds_count + MLX5E_XDP_INLINE_WQE_MAX_DS_CNT >
-		       MLX5E_XDP_MPW_MAX_NUM_DS;
-	return session->ds_count == MLX5E_XDP_MPW_MAX_NUM_DS;
+		       MLX5E_TX_MPW_MAX_NUM_DS;
+	return mlx5e_tx_mpwqe_is_full(session);
 }
 
 struct mlx5e_xdp_wqe_info {
