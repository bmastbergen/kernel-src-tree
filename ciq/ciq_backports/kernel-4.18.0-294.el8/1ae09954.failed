KVM: x86: Allow deflecting unknown MSR accesses to user space

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Alexander Graf <graf@amazon.com>
commit 1ae099540e8c7f1ee066b3ad45cc91f582bb1ce8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/1ae09954.failed

MSRs are weird. Some of them are normal control registers, such as EFER.
Some however are registers that really are model specific, not very
interesting to virtualization workloads, and not performance critical.
Others again are really just windows into package configuration.

Out of these MSRs, only the first category is necessary to implement in
kernel space. Rarely accessed MSRs, MSRs that should be fine tunes against
certain CPU models and MSRs that contain information on the package level
are much better suited for user space to process. However, over time we have
accumulated a lot of MSRs that are not the first category, but still handled
by in-kernel KVM code.

This patch adds a generic interface to handle WRMSR and RDMSR from user
space. With this, any future MSR that is part of the latter categories can
be handled in user space.

Furthermore, it allows us to replace the existing "ignore_msrs" logic with
something that applies per-VM rather than on the full system. That way you
can run productive VMs in parallel to experimental ones where you don't care
about proper MSR handling.

	Signed-off-by: Alexander Graf <graf@amazon.com>
	Reviewed-by: Jim Mattson <jmattson@google.com>

Message-Id: <20200925143422.21718-3-graf@amazon.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 1ae099540e8c7f1ee066b3ad45cc91f582bb1ce8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/virt/kvm/api.rst
#	arch/x86/kvm/x86.c
#	include/trace/events/kvm.h
#	include/uapi/linux/kvm.h
diff --cc Documentation/virt/kvm/api.rst
index 235a1db41e51,4fdba43d83e8..000000000000
--- a/Documentation/virt/kvm/api.rst
+++ b/Documentation/virt/kvm/api.rst
@@@ -6156,3 -6221,47 +6214,50 @@@ KVM can therefore start protected VMs
  This capability governs the KVM_S390_PV_COMMAND ioctl and the
  KVM_MP_STATE_LOAD MP_STATE. KVM_SET_MP_STATE can fail for protected
  guests when the state change is invalid.
++<<<<<<< HEAD
++=======
+ 
+ 8.24 KVM_CAP_STEAL_TIME
+ -----------------------
+ 
+ :Architectures: arm64, x86
+ 
+ This capability indicates that KVM supports steal time accounting.
+ When steal time accounting is supported it may be enabled with
+ architecture-specific interfaces.  This capability and the architecture-
+ specific interfaces must be consistent, i.e. if one says the feature
+ is supported, than the other should as well and vice versa.  For arm64
+ see Documentation/virt/kvm/devices/vcpu.rst "KVM_ARM_VCPU_PVTIME_CTRL".
+ For x86 see Documentation/virt/kvm/msr.rst "MSR_KVM_STEAL_TIME".
+ 
+ 8.25 KVM_CAP_S390_DIAG318
+ -------------------------
+ 
+ :Architectures: s390
+ 
+ This capability enables a guest to set information about its control program
+ (i.e. guest kernel type and version). The information is helpful during
+ system/firmware service events, providing additional data about the guest
+ environments running on the machine.
+ 
+ The information is associated with the DIAGNOSE 0x318 instruction, which sets
+ an 8-byte value consisting of a one-byte Control Program Name Code (CPNC) and
+ a 7-byte Control Program Version Code (CPVC). The CPNC determines what
+ environment the control program is running in (e.g. Linux, z/VM...), and the
+ CPVC is used for information specific to OS (e.g. Linux version, Linux
+ distribution...)
+ 
+ If this capability is available, then the CPNC and CPVC can be synchronized
+ between KVM and userspace via the sync regs mechanism (KVM_SYNC_DIAG318).
+ 
+ 8.26 KVM_CAP_X86_USER_SPACE_MSR
+ -------------------------------
+ 
+ :Architectures: x86
+ 
+ This capability indicates that KVM supports deflection of MSR reads and
+ writes to user space. It can be enabled on a VM level. If enabled, MSR
+ accesses that would usually trigger a #GP by KVM into the guest will
+ instead get bounced to user space through the KVM_EXIT_X86_RDMSR and
+ KVM_EXIT_X86_WRMSR exit notifications.
++>>>>>>> 1ae099540e8c (KVM: x86: Allow deflecting unknown MSR accesses to user space)
diff --cc arch/x86/kvm/x86.c
index 71f2e26ab478,af6d008145cd..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -3475,6 -3612,8 +3562,11 @@@ int kvm_vm_ioctl_check_extension(struc
  	case KVM_CAP_MSR_PLATFORM_INFO:
  	case KVM_CAP_EXCEPTION_PAYLOAD:
  	case KVM_CAP_SET_GUEST_DEBUG:
++<<<<<<< HEAD
++=======
+ 	case KVM_CAP_LAST_CPU:
+ 	case KVM_CAP_X86_USER_SPACE_MSR:
++>>>>>>> 1ae099540e8c (KVM: x86: Allow deflecting unknown MSR accesses to user space)
  		r = 1;
  		break;
  	case KVM_CAP_SYNC_REGS:
diff --cc include/trace/events/kvm.h
index 2c735a3e6613,26cfb0fa8e7e..000000000000
--- a/include/trace/events/kvm.h
+++ b/include/trace/events/kvm.h
@@@ -17,7 -17,7 +17,11 @@@
  	ERSN(NMI), ERSN(INTERNAL_ERROR), ERSN(OSI), ERSN(PAPR_HCALL),	\
  	ERSN(S390_UCONTROL), ERSN(WATCHDOG), ERSN(S390_TSCH), ERSN(EPR),\
  	ERSN(SYSTEM_EVENT), ERSN(S390_STSI), ERSN(IOAPIC_EOI),          \
++<<<<<<< HEAD
 +	ERSN(HYPERV)
++=======
+ 	ERSN(HYPERV), ERSN(ARM_NISV), ERSN(X86_RDMSR), ERSN(X86_WRMSR)
++>>>>>>> 1ae099540e8c (KVM: x86: Allow deflecting unknown MSR accesses to user space)
  
  TRACE_EVENT(kvm_userspace_exit,
  	    TP_PROTO(__u32 reason, int errno),
diff --cc include/uapi/linux/kvm.h
index f2c3051a98e4,31292a3cdfc2..000000000000
--- a/include/uapi/linux/kvm.h
+++ b/include/uapi/linux/kvm.h
@@@ -1030,6 -1044,12 +1042,15 @@@ struct kvm_ppc_resize_hpt 
  #define KVM_CAP_S390_PROTECTED 180
  #define KVM_CAP_PPC_SECURE_GUEST 181
  #define KVM_CAP_HALT_POLL 182
++<<<<<<< HEAD
++=======
+ #define KVM_CAP_ASYNC_PF_INT 183
+ #define KVM_CAP_LAST_CPU 184
+ #define KVM_CAP_SMALLER_MAXPHYADDR 185
+ #define KVM_CAP_S390_DIAG318 186
+ #define KVM_CAP_STEAL_TIME 187
+ #define KVM_CAP_X86_USER_SPACE_MSR 188
++>>>>>>> 1ae099540e8c (KVM: x86: Allow deflecting unknown MSR accesses to user space)
  
  #ifdef KVM_CAP_IRQ_ROUTING
  
* Unmerged path Documentation/virt/kvm/api.rst
diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index 5b39fca481b7..bc8e61631024 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -970,6 +970,9 @@ struct kvm_arch {
 	bool guest_can_read_msr_platform_info;
 	bool exception_payload_enabled;
 
+	/* Deflect RDMSR and WRMSR to user space when they trigger a #GP */
+	u32 user_space_msr_mask;
+
 	struct kvm_pmu_event_filter *pmu_event_filter;
 	struct task_struct *nx_lpage_recovery_thread;
 };
diff --git a/arch/x86/kvm/emulate.c b/arch/x86/kvm/emulate.c
index c664cb02f921..82b797c09cf8 100644
--- a/arch/x86/kvm/emulate.c
+++ b/arch/x86/kvm/emulate.c
@@ -3700,11 +3700,18 @@ static int em_dr_write(struct x86_emulate_ctxt *ctxt)
 
 static int em_wrmsr(struct x86_emulate_ctxt *ctxt)
 {
+	u64 msr_index = reg_read(ctxt, VCPU_REGS_RCX);
 	u64 msr_data;
+	int r;
 
 	msr_data = (u32)reg_read(ctxt, VCPU_REGS_RAX)
 		| ((u64)reg_read(ctxt, VCPU_REGS_RDX) << 32);
-	if (ctxt->ops->set_msr(ctxt, reg_read(ctxt, VCPU_REGS_RCX), msr_data))
+	r = ctxt->ops->set_msr(ctxt, msr_index, msr_data);
+
+	if (r == X86EMUL_IO_NEEDED)
+		return r;
+
+	if (r)
 		return emulate_gp(ctxt, 0);
 
 	return X86EMUL_CONTINUE;
@@ -3712,9 +3719,16 @@ static int em_wrmsr(struct x86_emulate_ctxt *ctxt)
 
 static int em_rdmsr(struct x86_emulate_ctxt *ctxt)
 {
+	u64 msr_index = reg_read(ctxt, VCPU_REGS_RCX);
 	u64 msr_data;
+	int r;
+
+	r = ctxt->ops->get_msr(ctxt, msr_index, &msr_data);
+
+	if (r == X86EMUL_IO_NEEDED)
+		return r;
 
-	if (ctxt->ops->get_msr(ctxt, reg_read(ctxt, VCPU_REGS_RCX), &msr_data))
+	if (r)
 		return emulate_gp(ctxt, 0);
 
 	*reg_write(ctxt, VCPU_REGS_RAX) = (u32)msr_data;
* Unmerged path arch/x86/kvm/x86.c
* Unmerged path include/trace/events/kvm.h
* Unmerged path include/uapi/linux/kvm.h
