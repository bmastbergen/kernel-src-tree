RDMA/mlx5: Get ECE options from FW during create QP

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Leon Romanovsky <leon@kernel.org>
commit 3e09a427ae7ac347e08dca5ffac64c902860d675
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/3e09a427.failed

Supported ECE options are returned from FW in the create_qp phase and zero
means that field is not valid. Such default value allows us to reuse
reserved field without worries about comp_mask.

Update create QP API to return ECE options.

Link: https://lore.kernel.org/r/20200526115440.205922-3-leon@kernel.org
	Reviewed-by: Mark Zhang <markz@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 3e09a427ae7ac347e08dca5ffac64c902860d675)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/qp.c
diff --cc drivers/infiniband/hw/mlx5/qp.c
index d7b72402de2d,be7289c480f7..000000000000
--- a/drivers/infiniband/hw/mlx5/qp.c
+++ b/drivers/infiniband/hw/mlx5/qp.c
@@@ -1960,15 -1836,91 +1960,97 @@@ static int get_atomic_mode(struct mlx5_
  	return atomic_mode;
  }
  
 -static int create_xrc_tgt_qp(struct mlx5_ib_dev *dev, struct mlx5_ib_qp *qp,
 -			     struct mlx5_create_qp_params *params)
 +static inline bool check_flags_mask(uint64_t input, uint64_t supported)
  {
++<<<<<<< HEAD
 +	return (input & ~supported) == 0;
++=======
+ 	struct ib_qp_init_attr *attr = params->attr;
+ 	u32 uidx = params->uidx;
+ 	struct mlx5_ib_resources *devr = &dev->devr;
+ 	u32 out[MLX5_ST_SZ_DW(create_qp_out)] = {};
+ 	int inlen = MLX5_ST_SZ_BYTES(create_qp_in);
+ 	struct mlx5_core_dev *mdev = dev->mdev;
+ 	struct mlx5_ib_qp_base *base;
+ 	unsigned long flags;
+ 	void *qpc;
+ 	u32 *in;
+ 	int err;
+ 
+ 	mutex_init(&qp->mutex);
+ 
+ 	if (attr->sq_sig_type == IB_SIGNAL_ALL_WR)
+ 		qp->sq_signal_bits = MLX5_WQE_CTRL_CQ_UPDATE;
+ 
+ 	in = kvzalloc(inlen, GFP_KERNEL);
+ 	if (!in)
+ 		return -ENOMEM;
+ 
+ 	qpc = MLX5_ADDR_OF(create_qp_in, in, qpc);
+ 
+ 	MLX5_SET(qpc, qpc, st, MLX5_QP_ST_XRC);
+ 	MLX5_SET(qpc, qpc, pm_state, MLX5_QP_PM_MIGRATED);
+ 	MLX5_SET(qpc, qpc, pd, to_mpd(devr->p0)->pdn);
+ 
+ 	if (qp->flags & IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK)
+ 		MLX5_SET(qpc, qpc, block_lb_mc, 1);
+ 	if (qp->flags & IB_QP_CREATE_CROSS_CHANNEL)
+ 		MLX5_SET(qpc, qpc, cd_master, 1);
+ 	if (qp->flags & IB_QP_CREATE_MANAGED_SEND)
+ 		MLX5_SET(qpc, qpc, cd_slave_send, 1);
+ 	if (qp->flags & IB_QP_CREATE_MANAGED_RECV)
+ 		MLX5_SET(qpc, qpc, cd_slave_receive, 1);
+ 
+ 	MLX5_SET(qpc, qpc, rq_type, MLX5_SRQ_RQ);
+ 	MLX5_SET(qpc, qpc, no_sq, 1);
+ 	MLX5_SET(qpc, qpc, cqn_rcv, to_mcq(devr->c0)->mcq.cqn);
+ 	MLX5_SET(qpc, qpc, cqn_snd, to_mcq(devr->c0)->mcq.cqn);
+ 	MLX5_SET(qpc, qpc, srqn_rmpn_xrqn, to_msrq(devr->s0)->msrq.srqn);
+ 	MLX5_SET(qpc, qpc, xrcd, to_mxrcd(attr->xrcd)->xrcdn);
+ 	MLX5_SET64(qpc, qpc, dbr_addr, qp->db.dma);
+ 
+ 	/* 0xffffff means we ask to work with cqe version 0 */
+ 	if (MLX5_CAP_GEN(mdev, cqe_version) == MLX5_CQE_VERSION_V1)
+ 		MLX5_SET(qpc, qpc, user_index, uidx);
+ 
+ 	if (qp->flags & IB_QP_CREATE_PCI_WRITE_END_PADDING) {
+ 		MLX5_SET(qpc, qpc, end_padding_mode,
+ 			 MLX5_WQ_END_PAD_MODE_ALIGN);
+ 		/* Special case to clean flag */
+ 		qp->flags &= ~IB_QP_CREATE_PCI_WRITE_END_PADDING;
+ 	}
+ 
+ 	base = &qp->trans_qp.base;
+ 	err = mlx5_qpc_create_qp(dev, &base->mqp, in, inlen, out);
+ 	kvfree(in);
+ 	if (err)
+ 		return err;
+ 
+ 	base->container_mibqp = qp;
+ 	base->mqp.event = mlx5_ib_qp_event;
+ 	params->resp.ece_options = MLX5_GET(create_qp_out, out, ece);
+ 
+ 	spin_lock_irqsave(&dev->reset_flow_resource_lock, flags);
+ 	list_add_tail(&qp->qps_list, &dev->qp_list);
+ 	spin_unlock_irqrestore(&dev->reset_flow_resource_lock, flags);
+ 
+ 	qp->trans_qp.xrcdn = to_mxrcd(attr->xrcd)->xrcdn;
+ 	return 0;
++>>>>>>> 3e09a427ae7a (RDMA/mlx5: Get ECE options from FW during create QP)
  }
  
 -static int create_user_qp(struct mlx5_ib_dev *dev, struct ib_pd *pd,
 -			  struct mlx5_ib_qp *qp,
 -			  struct mlx5_create_qp_params *params)
 +static int create_qp_common(struct mlx5_ib_dev *dev, struct ib_pd *pd,
 +			    struct ib_qp_init_attr *init_attr,
 +			    struct ib_udata *udata, struct mlx5_ib_qp *qp)
  {
++<<<<<<< HEAD
++=======
+ 	struct ib_qp_init_attr *init_attr = params->attr;
+ 	struct mlx5_ib_create_qp *ucmd = params->ucmd;
+ 	u32 out[MLX5_ST_SZ_DW(create_qp_out)] = {};
+ 	struct ib_udata *udata = params->udata;
+ 	u32 uidx = params->uidx;
++>>>>>>> 3e09a427ae7a (RDMA/mlx5: Get ECE options from FW during create QP)
  	struct mlx5_ib_resources *devr = &dev->devr;
  	int inlen = MLX5_ST_SZ_BYTES(create_qp_in);
  	struct mlx5_core_dev *mdev = dev->mdev;
@@@ -2305,21 -2062,148 +2387,158 @@@
  	}
  
  	if (init_attr->qp_type == IB_QPT_RAW_PACKET ||
 -	    qp->flags & IB_QP_CREATE_SOURCE_QPN) {
 -		qp->raw_packet_qp.sq.ubuffer.buf_addr = ucmd->sq_buf_addr;
 +	    qp->flags & MLX5_IB_QP_UNDERLAY) {
 +		qp->raw_packet_qp.sq.ubuffer.buf_addr = ucmd.sq_buf_addr;
  		raw_packet_qp_copy_info(qp, &qp->raw_packet_qp);
  		err = create_raw_packet_qp(dev, qp, in, inlen, pd, udata,
++<<<<<<< HEAD
 +					   &resp);
++=======
+ 					   &params->resp);
+ 	} else
+ 		err = mlx5_qpc_create_qp(dev, &base->mqp, in, inlen, out);
+ 
+ 	kvfree(in);
+ 	if (err)
+ 		goto err_create;
+ 
+ 	base->container_mibqp = qp;
+ 	base->mqp.event = mlx5_ib_qp_event;
+ 	params->resp.ece_options = MLX5_GET(create_qp_out, out, ece);
+ 
+ 	get_cqs(qp->type, init_attr->send_cq, init_attr->recv_cq,
+ 		&send_cq, &recv_cq);
+ 	spin_lock_irqsave(&dev->reset_flow_resource_lock, flags);
+ 	mlx5_ib_lock_cqs(send_cq, recv_cq);
+ 	/* Maintain device to QPs access, needed for further handling via reset
+ 	 * flow
+ 	 */
+ 	list_add_tail(&qp->qps_list, &dev->qp_list);
+ 	/* Maintain CQ to QPs access, needed for further handling via reset flow
+ 	 */
+ 	if (send_cq)
+ 		list_add_tail(&qp->cq_send_list, &send_cq->list_send_qp);
+ 	if (recv_cq)
+ 		list_add_tail(&qp->cq_recv_list, &recv_cq->list_recv_qp);
+ 	mlx5_ib_unlock_cqs(send_cq, recv_cq);
+ 	spin_unlock_irqrestore(&dev->reset_flow_resource_lock, flags);
+ 
+ 	return 0;
+ 
+ err_create:
+ 	destroy_qp(dev, qp, base, udata);
+ 	return err;
+ }
+ 
+ static int create_kernel_qp(struct mlx5_ib_dev *dev, struct ib_pd *pd,
+ 			    struct mlx5_ib_qp *qp,
+ 			    struct mlx5_create_qp_params *params)
+ {
+ 	struct ib_qp_init_attr *attr = params->attr;
+ 	u32 uidx = params->uidx;
+ 	struct mlx5_ib_resources *devr = &dev->devr;
+ 	u32 out[MLX5_ST_SZ_DW(create_qp_out)] = {};
+ 	int inlen = MLX5_ST_SZ_BYTES(create_qp_in);
+ 	struct mlx5_core_dev *mdev = dev->mdev;
+ 	struct mlx5_ib_cq *send_cq;
+ 	struct mlx5_ib_cq *recv_cq;
+ 	unsigned long flags;
+ 	struct mlx5_ib_qp_base *base;
+ 	int mlx5_st;
+ 	void *qpc;
+ 	u32 *in;
+ 	int err;
+ 
+ 	mutex_init(&qp->mutex);
+ 	spin_lock_init(&qp->sq.lock);
+ 	spin_lock_init(&qp->rq.lock);
+ 
+ 	mlx5_st = to_mlx5_st(qp->type);
+ 	if (mlx5_st < 0)
+ 		return -EINVAL;
+ 
+ 	if (attr->sq_sig_type == IB_SIGNAL_ALL_WR)
+ 		qp->sq_signal_bits = MLX5_WQE_CTRL_CQ_UPDATE;
+ 
+ 	base = &qp->trans_qp.base;
+ 
+ 	qp->has_rq = qp_has_rq(attr);
+ 	err = set_rq_size(dev, &attr->cap, qp->has_rq, qp, NULL);
+ 	if (err) {
+ 		mlx5_ib_dbg(dev, "err %d\n", err);
+ 		return err;
+ 	}
+ 
+ 	err = _create_kernel_qp(dev, attr, qp, &in, &inlen, base);
+ 	if (err)
+ 		return err;
+ 
+ 	if (is_sqp(attr->qp_type))
+ 		qp->port = attr->port_num;
+ 
+ 	qpc = MLX5_ADDR_OF(create_qp_in, in, qpc);
+ 
+ 	MLX5_SET(qpc, qpc, st, mlx5_st);
+ 	MLX5_SET(qpc, qpc, pm_state, MLX5_QP_PM_MIGRATED);
+ 
+ 	if (attr->qp_type != MLX5_IB_QPT_REG_UMR)
+ 		MLX5_SET(qpc, qpc, pd, to_mpd(pd ? pd : devr->p0)->pdn);
+ 	else
+ 		MLX5_SET(qpc, qpc, latency_sensitive, 1);
+ 
+ 
+ 	if (qp->flags & IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK)
+ 		MLX5_SET(qpc, qpc, block_lb_mc, 1);
+ 
+ 	if (qp->rq.wqe_cnt) {
+ 		MLX5_SET(qpc, qpc, log_rq_stride, qp->rq.wqe_shift - 4);
+ 		MLX5_SET(qpc, qpc, log_rq_size, ilog2(qp->rq.wqe_cnt));
+ 	}
+ 
+ 	MLX5_SET(qpc, qpc, rq_type, get_rx_type(qp, attr));
+ 
+ 	if (qp->sq.wqe_cnt)
+ 		MLX5_SET(qpc, qpc, log_sq_size, ilog2(qp->sq.wqe_cnt));
+ 	else
+ 		MLX5_SET(qpc, qpc, no_sq, 1);
+ 
+ 	if (attr->srq) {
+ 		MLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x0)->xrcdn);
+ 		MLX5_SET(qpc, qpc, srqn_rmpn_xrqn,
+ 			 to_msrq(attr->srq)->msrq.srqn);
++>>>>>>> 3e09a427ae7a (RDMA/mlx5: Get ECE options from FW during create QP)
  	} else {
 -		MLX5_SET(qpc, qpc, xrcd, to_mxrcd(devr->x1)->xrcdn);
 -		MLX5_SET(qpc, qpc, srqn_rmpn_xrqn,
 -			 to_msrq(devr->s1)->msrq.srqn);
 +		err = mlx5_core_create_qp(dev, &base->mqp, in, inlen);
  	}
  
++<<<<<<< HEAD
 +	if (err) {
 +		mlx5_ib_dbg(dev, "create qp failed\n");
++=======
+ 	if (attr->send_cq)
+ 		MLX5_SET(qpc, qpc, cqn_snd, to_mcq(attr->send_cq)->mcq.cqn);
+ 
+ 	if (attr->recv_cq)
+ 		MLX5_SET(qpc, qpc, cqn_rcv, to_mcq(attr->recv_cq)->mcq.cqn);
+ 
+ 	MLX5_SET64(qpc, qpc, dbr_addr, qp->db.dma);
+ 
+ 	/* 0xffffff means we ask to work with cqe version 0 */
+ 	if (MLX5_CAP_GEN(mdev, cqe_version) == MLX5_CQE_VERSION_V1)
+ 		MLX5_SET(qpc, qpc, user_index, uidx);
+ 
+ 	/* we use IB_QP_CREATE_IPOIB_UD_LSO to indicates ipoib qp */
+ 	if (qp->flags & IB_QP_CREATE_IPOIB_UD_LSO)
+ 		MLX5_SET(qpc, qpc, ulp_stateless_offload_mode, 1);
+ 
+ 	err = mlx5_qpc_create_qp(dev, &base->mqp, in, inlen, out);
+ 	kvfree(in);
+ 	if (err)
++>>>>>>> 3e09a427ae7a (RDMA/mlx5: Get ECE options from FW during create QP)
  		goto err_create;
 +	}
 +
 +	kvfree(in);
  
  	base->container_mibqp = qp;
  	base->mqp.event = mlx5_ib_qp_event;
@@@ -2568,100 -2470,363 +2787,181 @@@ static struct ib_qp *mlx5_ib_create_dct
  {
  	struct mlx5_ib_ucontext *ucontext = rdma_udata_to_drv_context(
  		udata, struct mlx5_ib_ucontext, ibucontext);
 +	struct mlx5_ib_qp *qp;
 +	int err = 0;
 +	u32 uidx = MLX5_IB_DEFAULT_UIDX;
 +	void *dctc;
  
 -	if (!udata) {
 -		/* Kernel create_qp callers */
 -		if (attr->rwq_ind_tbl)
 -			return -EOPNOTSUPP;
 -
 -		switch (attr->qp_type) {
 -		case IB_QPT_RAW_PACKET:
 -		case IB_QPT_DRIVER:
 -			return -EOPNOTSUPP;
 -		default:
 -			return 0;
 -		}
 -	}
 +	if (!attr->srq || !attr->recv_cq)
 +		return ERR_PTR(-EINVAL);
  
 -	/* Userspace create_qp callers */
 -	if (attr->qp_type == IB_QPT_RAW_PACKET && !ucontext->cqe_version) {
 -		mlx5_ib_dbg(dev,
 -			"Raw Packet QP is only supported for CQE version > 0\n");
 -		return -EINVAL;
 -	}
 +	err = get_qp_user_index(ucontext, ucmd, sizeof(*ucmd), &uidx);
 +	if (err)
 +		return ERR_PTR(err);
  
 -	if (attr->qp_type != IB_QPT_RAW_PACKET && attr->rwq_ind_tbl) {
 -		mlx5_ib_dbg(dev,
 -			    "Wrong QP type %d for the RWQ indirect table\n",
 -			    attr->qp_type);
 -		return -EINVAL;
 -	}
 +	qp = kzalloc(sizeof(*qp), GFP_KERNEL);
 +	if (!qp)
 +		return ERR_PTR(-ENOMEM);
  
 -	switch (attr->qp_type) {
 -	case IB_QPT_SMI:
 -	case MLX5_IB_QPT_HW_GSI:
 -	case MLX5_IB_QPT_REG_UMR:
 -	case IB_QPT_GSI:
 -		mlx5_ib_dbg(dev, "Kernel doesn't support QP type %d\n",
 -			    attr->qp_type);
 -		return -EINVAL;
 -	default:
 -		break;
 +	qp->dct.in = kzalloc(MLX5_ST_SZ_BYTES(create_dct_in), GFP_KERNEL);
 +	if (!qp->dct.in) {
 +		err = -ENOMEM;
 +		goto err_free;
  	}
  
 -	/*
 -	 * We don't need to see this warning, it means that kernel code
 -	 * missing ib_pd. Placed here to catch developer's mistakes.
 -	 */
 -	WARN_ONCE(!pd && attr->qp_type != IB_QPT_XRC_TGT,
 -		  "There is a missing PD pointer assignment\n");
 -	return 0;
 -}
 +	MLX5_SET(create_dct_in, qp->dct.in, uid, to_mpd(pd)->uid);
 +	dctc = MLX5_ADDR_OF(create_dct_in, qp->dct.in, dct_context_entry);
 +	qp->qp_sub_type = MLX5_IB_QPT_DCT;
 +	MLX5_SET(dctc, dctc, pd, to_mpd(pd)->pdn);
 +	MLX5_SET(dctc, dctc, srqn_xrqn, to_msrq(attr->srq)->msrq.srqn);
 +	MLX5_SET(dctc, dctc, cqn, to_mcq(attr->recv_cq)->mcq.cqn);
 +	MLX5_SET64(dctc, dctc, dc_access_key, ucmd->access_key);
 +	MLX5_SET(dctc, dctc, user_index, uidx);
  
 -static void process_vendor_flag(struct mlx5_ib_dev *dev, int *flags, int flag,
 -				bool cond, struct mlx5_ib_qp *qp)
 -{
 -	if (!(*flags & flag))
 -		return;
 +	if (ucmd->flags & MLX5_QP_FLAG_SCATTER_CQE) {
 +		int rcqe_sz = mlx5_ib_get_cqe_size(attr->recv_cq);
  
 -	if (cond) {
 -		qp->flags_en |= flag;
 -		*flags &= ~flag;
 -		return;
 +		if (rcqe_sz == 128)
 +			MLX5_SET(dctc, dctc, cs_res, MLX5_RES_SCAT_DATA64_CQE);
  	}
  
 -	if (flag == MLX5_QP_FLAG_SCATTER_CQE) {
 -		/*
 -		 * We don't return error if this flag was provided,
 -		 * and mlx5 doesn't have right capability.
 -		 */
 -		*flags &= ~MLX5_QP_FLAG_SCATTER_CQE;
 -		return;
 -	}
 -	mlx5_ib_dbg(dev, "Vendor create QP flag 0x%X is not supported\n", flag);
 +	qp->state = IB_QPS_RESET;
 +
 +	return &qp->ibqp;
 +err_free:
 +	kfree(qp);
 +	return ERR_PTR(err);
  }
  
 -static int process_vendor_flags(struct mlx5_ib_dev *dev, struct mlx5_ib_qp *qp,
 -				void *ucmd, struct ib_qp_init_attr *attr)
 +static int set_mlx_qp_type(struct mlx5_ib_dev *dev,
 +			   struct ib_qp_init_attr *init_attr,
 +			   struct mlx5_ib_create_qp *ucmd,
 +			   struct ib_udata *udata)
  {
 -	struct mlx5_core_dev *mdev = dev->mdev;
 -	bool cond;
 -	int flags;
 -
 -	if (attr->rwq_ind_tbl)
 -		flags = ((struct mlx5_ib_create_qp_rss *)ucmd)->flags;
 -	else
 -		flags = ((struct mlx5_ib_create_qp *)ucmd)->flags;
 +	enum { MLX_QP_FLAGS = MLX5_QP_FLAG_TYPE_DCT | MLX5_QP_FLAG_TYPE_DCI };
 +	int err;
  
 -	switch (flags & (MLX5_QP_FLAG_TYPE_DCT | MLX5_QP_FLAG_TYPE_DCI)) {
 -	case MLX5_QP_FLAG_TYPE_DCI:
 -		qp->type = MLX5_IB_QPT_DCI;
 -		break;
 -	case MLX5_QP_FLAG_TYPE_DCT:
 -		qp->type = MLX5_IB_QPT_DCT;
 -		break;
 -	default:
 -		if (qp->type != IB_QPT_DRIVER)
 -			break;
 -		/*
 -		 * It is IB_QPT_DRIVER and or no subtype or
 -		 * wrong subtype were provided.
 -		 */
 +	if (!udata)
  		return -EINVAL;
 -	}
  
 -	process_vendor_flag(dev, &flags, MLX5_QP_FLAG_TYPE_DCI, true, qp);
 -	process_vendor_flag(dev, &flags, MLX5_QP_FLAG_TYPE_DCT, true, qp);
 -
 -	process_vendor_flag(dev, &flags, MLX5_QP_FLAG_SIGNATURE, true, qp);
 -	process_vendor_flag(dev, &flags, MLX5_QP_FLAG_SCATTER_CQE,
 -			    MLX5_CAP_GEN(mdev, sctr_data_cqe), qp);
 -
 -	if (qp->type == IB_QPT_RAW_PACKET) {
 -		cond = MLX5_CAP_ETH(mdev, tunnel_stateless_vxlan) ||
 -		       MLX5_CAP_ETH(mdev, tunnel_stateless_gre) ||
 -		       MLX5_CAP_ETH(mdev, tunnel_stateless_geneve_rx);
 -		process_vendor_flag(dev, &flags, MLX5_QP_FLAG_TUNNEL_OFFLOADS,
 -				    cond, qp);
 -		process_vendor_flag(dev, &flags,
 -				    MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_UC, true,
 -				    qp);
 -		process_vendor_flag(dev, &flags,
 -				    MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_MC, true,
 -				    qp);
 -	}
 -
 -	if (qp->type == IB_QPT_RC)
 -		process_vendor_flag(dev, &flags,
 -				    MLX5_QP_FLAG_PACKET_BASED_CREDIT_MODE,
 -				    MLX5_CAP_GEN(mdev, qp_packet_based), qp);
 -
 -	process_vendor_flag(dev, &flags, MLX5_QP_FLAG_BFREG_INDEX, true, qp);
 -	process_vendor_flag(dev, &flags, MLX5_QP_FLAG_UAR_PAGE_INDEX, true, qp);
 -
 -	cond = qp->flags_en & ~(MLX5_QP_FLAG_TUNNEL_OFFLOADS |
 -				MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_UC |
 -				MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_MC);
 -	if (attr->rwq_ind_tbl && cond) {
 -		mlx5_ib_dbg(dev, "RSS RAW QP has unsupported flags 0x%X\n",
 -			    cond);
 +	if (udata->inlen < sizeof(*ucmd)) {
 +		mlx5_ib_dbg(dev, "create_qp user command is smaller than expected\n");
  		return -EINVAL;
  	}
 +	err = ib_copy_from_udata(ucmd, udata, sizeof(*ucmd));
 +	if (err)
 +		return err;
  
 -	if (flags)
 -		mlx5_ib_dbg(dev, "udata has unsupported flags 0x%X\n", flags);
 -
 -	return (flags) ? -EINVAL : 0;
 -	}
 -
 -static void process_create_flag(struct mlx5_ib_dev *dev, int *flags, int flag,
 -				bool cond, struct mlx5_ib_qp *qp)
 -{
 -	if (!(*flags & flag))
 -		return;
 -
 -	if (cond) {
 -		qp->flags |= flag;
 -		*flags &= ~flag;
 -		return;
 -	}
 -
 -	if (flag == MLX5_IB_QP_CREATE_WC_TEST) {
 -		/*
 -		 * Special case, if condition didn't meet, it won't be error,
 -		 * just different in-kernel flow.
 -		 */
 -		*flags &= ~MLX5_IB_QP_CREATE_WC_TEST;
 -		return;
 -	}
 -	mlx5_ib_dbg(dev, "Verbs create QP flag 0x%X is not supported\n", flag);
 -}
 -
 -static int process_create_flags(struct mlx5_ib_dev *dev, struct mlx5_ib_qp *qp,
 -				struct ib_qp_init_attr *attr)
 -{
 -	enum ib_qp_type qp_type = qp->type;
 -	struct mlx5_core_dev *mdev = dev->mdev;
 -	int create_flags = attr->create_flags;
 -	bool cond;
 -
 -	if (qp->type == IB_QPT_UD && dev->profile == &raw_eth_profile)
 -		if (create_flags & ~MLX5_IB_QP_CREATE_WC_TEST)
 +	if ((ucmd->flags & MLX_QP_FLAGS) == MLX5_QP_FLAG_TYPE_DCI) {
 +		init_attr->qp_type = MLX5_IB_QPT_DCI;
 +	} else {
 +		if ((ucmd->flags & MLX_QP_FLAGS) == MLX5_QP_FLAG_TYPE_DCT) {
 +			init_attr->qp_type = MLX5_IB_QPT_DCT;
 +		} else {
 +			mlx5_ib_dbg(dev, "Invalid QP flags\n");
  			return -EINVAL;
 -
 -	if (qp_type == MLX5_IB_QPT_DCT)
 -		return (create_flags) ? -EINVAL : 0;
 -
 -	if (qp_type == IB_QPT_RAW_PACKET && attr->rwq_ind_tbl)
 -		return (create_flags) ? -EINVAL : 0;
 -
 -	process_create_flag(dev, &create_flags,
 -			    IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK,
 -			    MLX5_CAP_GEN(mdev, block_lb_mc), qp);
 -	process_create_flag(dev, &create_flags, IB_QP_CREATE_CROSS_CHANNEL,
 -			    MLX5_CAP_GEN(mdev, cd), qp);
 -	process_create_flag(dev, &create_flags, IB_QP_CREATE_MANAGED_SEND,
 -			    MLX5_CAP_GEN(mdev, cd), qp);
 -	process_create_flag(dev, &create_flags, IB_QP_CREATE_MANAGED_RECV,
 -			    MLX5_CAP_GEN(mdev, cd), qp);
 -
 -	if (qp_type == IB_QPT_UD) {
 -		process_create_flag(dev, &create_flags,
 -				    IB_QP_CREATE_IPOIB_UD_LSO,
 -				    MLX5_CAP_GEN(mdev, ipoib_basic_offloads),
 -				    qp);
 -		cond = MLX5_CAP_GEN(mdev, port_type) == MLX5_CAP_PORT_TYPE_IB;
 -		process_create_flag(dev, &create_flags, IB_QP_CREATE_SOURCE_QPN,
 -				    cond, qp);
 -	}
 -
 -	if (qp_type == IB_QPT_RAW_PACKET) {
 -		cond = MLX5_CAP_GEN(mdev, eth_net_offloads) &&
 -		       MLX5_CAP_ETH(mdev, scatter_fcs);
 -		process_create_flag(dev, &create_flags,
 -				    IB_QP_CREATE_SCATTER_FCS, cond, qp);
 -
 -		cond = MLX5_CAP_GEN(mdev, eth_net_offloads) &&
 -		       MLX5_CAP_ETH(mdev, vlan_cap);
 -		process_create_flag(dev, &create_flags,
 -				    IB_QP_CREATE_CVLAN_STRIPPING, cond, qp);
 -	}
 -
 -	process_create_flag(dev, &create_flags,
 -			    IB_QP_CREATE_PCI_WRITE_END_PADDING,
 -			    MLX5_CAP_GEN(mdev, end_pad), qp);
 -
 -	process_create_flag(dev, &create_flags, MLX5_IB_QP_CREATE_WC_TEST,
 -			    qp_type != MLX5_IB_QPT_REG_UMR, qp);
 -	process_create_flag(dev, &create_flags, MLX5_IB_QP_CREATE_SQPN_QP1,
 -			    true, qp);
 -
 -	if (create_flags)
 -		mlx5_ib_dbg(dev, "Create QP has unsupported flags 0x%X\n",
 -			    create_flags);
 -
 -	return (create_flags) ? -EINVAL : 0;
 -}
 -
 -static int process_udata_size(struct mlx5_ib_dev *dev,
 -			      struct mlx5_create_qp_params *params)
 -{
 -	size_t ucmd = sizeof(struct mlx5_ib_create_qp);
 -	struct ib_qp_init_attr *attr = params->attr;
 -	struct ib_udata *udata = params->udata;
 -	size_t outlen = udata->outlen;
 -	size_t inlen = udata->inlen;
 -
 -	params->outlen = min(outlen, sizeof(struct mlx5_ib_create_qp_resp));
 -	if (attr->qp_type == IB_QPT_DRIVER) {
 -		params->inlen = (inlen < ucmd) ? 0 : ucmd;
 -		goto out;
 +		}
  	}
  
 -	if (!params->is_rss_raw) {
 -		params->inlen = ucmd;
 -		goto out;
 +	if (!MLX5_CAP_GEN(dev->mdev, dct)) {
 +		mlx5_ib_dbg(dev, "DC transport is not supported\n");
 +		return -EOPNOTSUPP;
  	}
  
 -	/* RSS RAW QP */
 -	if (inlen < offsetofend(struct mlx5_ib_create_qp_rss, flags))
 -		return -EINVAL;
 -
 -	if (outlen < offsetofend(struct mlx5_ib_create_qp_resp, bfreg_index))
 -		return -EINVAL;
 -
 -	ucmd = sizeof(struct mlx5_ib_create_qp_rss);
 -	if (inlen > ucmd && !ib_is_udata_cleared(udata, ucmd, inlen - ucmd))
 -		return -EINVAL;
 -
 -	params->inlen = min(ucmd, inlen);
 -out:
 -	if (!params->inlen)
 -		mlx5_ib_dbg(dev, "udata is too small or not cleared\n");
 -
 -	return (params->inlen) ? 0 : -EINVAL;
 +	return 0;
  }
  
 -static int create_qp(struct mlx5_ib_dev *dev, struct ib_pd *pd,
 -		     struct mlx5_ib_qp *qp,
 -		     struct mlx5_create_qp_params *params)
 +struct ib_qp *mlx5_ib_create_qp(struct ib_pd *pd,
 +				struct ib_qp_init_attr *verbs_init_attr,
 +				struct ib_udata *udata)
  {
 +	struct mlx5_ib_dev *dev;
 +	struct mlx5_ib_qp *qp;
 +	u16 xrcdn = 0;
  	int err;
++<<<<<<< HEAD
 +	struct ib_qp_init_attr mlx_init_attr;
 +	struct ib_qp_init_attr *init_attr = verbs_init_attr;
++=======
+ 
+ 	if (params->is_rss_raw) {
+ 		err = create_rss_raw_qp_tir(dev, pd, qp, params);
+ 		goto out;
+ 	}
+ 
+ 	if (qp->type == MLX5_IB_QPT_DCT) {
+ 		err = create_dct(pd, qp, params);
+ 		goto out;
+ 	}
+ 
+ 	if (qp->type == IB_QPT_XRC_TGT) {
+ 		err = create_xrc_tgt_qp(dev, qp, params);
+ 		goto out;
+ 	}
+ 
+ 	if (params->udata)
+ 		err = create_user_qp(dev, pd, qp, params);
+ 	else
+ 		err = create_kernel_qp(dev, pd, qp, params);
+ 
+ out:
+ 	if (err) {
+ 		mlx5_ib_err(dev, "Create QP type %d failed\n", qp->type);
+ 		return err;
+ 	}
+ 
+ 	if (is_qp0(qp->type))
+ 		qp->ibqp.qp_num = 0;
+ 	else if (is_qp1(qp->type))
+ 		qp->ibqp.qp_num = 1;
+ 	else
+ 		qp->ibqp.qp_num = qp->trans_qp.base.mqp.qpn;
+ 
+ 	mlx5_ib_dbg(dev,
+ 		"QP type %d, ib qpn 0x%X, mlx qpn 0x%x, rcqn 0x%x, scqn 0x%x, ece 0x%x\n",
+ 		qp->type, qp->ibqp.qp_num, qp->trans_qp.base.mqp.qpn,
+ 		params->attr->recv_cq ? to_mcq(params->attr->recv_cq)->mcq.cqn :
+ 					-1,
+ 		params->attr->send_cq ? to_mcq(params->attr->send_cq)->mcq.cqn :
+ 					-1,
+ 		params->resp.ece_options);
+ 
+ 	return 0;
+ }
+ 
+ static int check_qp_attr(struct mlx5_ib_dev *dev, struct mlx5_ib_qp *qp,
+ 			 struct ib_qp_init_attr *attr)
+ {
+ 	int ret = 0;
+ 
+ 	switch (qp->type) {
+ 	case MLX5_IB_QPT_DCT:
+ 		ret = (!attr->srq || !attr->recv_cq) ? -EINVAL : 0;
+ 		break;
+ 	case MLX5_IB_QPT_DCI:
+ 		ret = (attr->cap.max_recv_wr || attr->cap.max_recv_sge) ?
+ 			      -EINVAL :
+ 			      0;
+ 		break;
+ 	case IB_QPT_RAW_PACKET:
+ 		ret = (attr->rwq_ind_tbl && attr->send_cq) ? -EINVAL : 0;
+ 		break;
+ 	default:
+ 		break;
+ 	}
+ 
+ 	if (ret)
+ 		mlx5_ib_dbg(dev, "QP type %d has wrong attributes\n", qp->type);
+ 
+ 	return ret;
+ }
+ 
+ static int get_qp_uidx(struct mlx5_ib_qp *qp,
+ 		       struct mlx5_create_qp_params *params)
+ {
+ 	struct mlx5_ib_create_qp *ucmd = params->ucmd;
+ 	struct ib_udata *udata = params->udata;
++>>>>>>> 3e09a427ae7a (RDMA/mlx5: Get ECE options from FW during create QP)
  	struct mlx5_ib_ucontext *ucontext = rdma_udata_to_drv_context(
  		udata, struct mlx5_ib_ucontext, ibucontext);
  
* Unmerged path drivers/infiniband/hw/mlx5/qp.c
diff --git a/drivers/infiniband/hw/mlx5/qp.h b/drivers/infiniband/hw/mlx5/qp.h
index ad9d76e3e18a..795c21f88962 100644
--- a/drivers/infiniband/hw/mlx5/qp.h
+++ b/drivers/infiniband/hw/mlx5/qp.h
@@ -13,8 +13,8 @@ void mlx5_cleanup_qp_table(struct mlx5_ib_dev *dev);
 
 int mlx5_core_create_dct(struct mlx5_ib_dev *dev, struct mlx5_core_dct *qp,
 			 u32 *in, int inlen, u32 *out, int outlen);
-int mlx5_core_create_qp(struct mlx5_ib_dev *dev, struct mlx5_core_qp *qp,
-			u32 *in, int inlen);
+int mlx5_qpc_create_qp(struct mlx5_ib_dev *dev, struct mlx5_core_qp *qp,
+		       u32 *in, int inlen, u32 *out);
 int mlx5_core_qp_modify(struct mlx5_ib_dev *dev, u16 opcode, u32 opt_param_mask,
 			void *qpc, struct mlx5_core_qp *qp);
 int mlx5_core_destroy_qp(struct mlx5_ib_dev *dev, struct mlx5_core_qp *qp);
diff --git a/drivers/infiniband/hw/mlx5/qpc.c b/drivers/infiniband/hw/mlx5/qpc.c
index ea62735042f0..69c80859a6ee 100644
--- a/drivers/infiniband/hw/mlx5/qpc.c
+++ b/drivers/infiniband/hw/mlx5/qpc.c
@@ -236,16 +236,16 @@ int mlx5_core_create_dct(struct mlx5_ib_dev *dev, struct mlx5_core_dct *dct,
 	return err;
 }
 
-int mlx5_core_create_qp(struct mlx5_ib_dev *dev, struct mlx5_core_qp *qp,
-			u32 *in, int inlen)
+int mlx5_qpc_create_qp(struct mlx5_ib_dev *dev, struct mlx5_core_qp *qp,
+		       u32 *in, int inlen, u32 *out)
 {
-	u32 out[MLX5_ST_SZ_DW(create_qp_out)] = {};
 	u32 din[MLX5_ST_SZ_DW(destroy_qp_in)] = {};
 	int err;
 
 	MLX5_SET(create_qp_in, in, opcode, MLX5_CMD_OP_CREATE_QP);
 
-	err = mlx5_cmd_exec(dev->mdev, in, inlen, out, sizeof(out));
+	err = mlx5_cmd_exec(dev->mdev, in, inlen, out,
+			    MLX5_ST_SZ_BYTES(create_qp_out));
 	if (err)
 		return err;
 
diff --git a/include/uapi/rdma/mlx5-abi.h b/include/uapi/rdma/mlx5-abi.h
index a65d60b44829..5603090baa21 100644
--- a/include/uapi/rdma/mlx5-abi.h
+++ b/include/uapi/rdma/mlx5-abi.h
@@ -370,7 +370,7 @@ enum mlx5_ib_create_qp_resp_mask {
 
 struct mlx5_ib_create_qp_resp {
 	__u32	bfreg_index;
-	__u32   reserved;
+	__u32   ece_options;
 	__u32	comp_mask;
 	__u32	tirn;
 	__u32	tisn;
