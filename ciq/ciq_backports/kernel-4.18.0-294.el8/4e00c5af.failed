powerpc/mm: thread pgprot_t through create_section_mapping()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Logan Gunthorpe <logang@deltatee.com>
commit 4e00c5affdd4b04e6392001716333971932f3d0c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/4e00c5af.failed

In prepartion to support a pgprot_t argument for arch_add_memory().

	Signed-off-by: Logan Gunthorpe <logang@deltatee.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
	Cc: Paul Mackerras <paulus@samba.org>
	Cc: Michael Ellerman <mpe@ellerman.id.au>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Borislav Petkov <bp@alien8.de>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Christoph Hellwig <hch@lst.de>
	Cc: Dan Williams <dan.j.williams@intel.com>
	Cc: Dave Hansen <dave.hansen@linux.intel.com>
	Cc: David Hildenbrand <david@redhat.com>
	Cc: Eric Badger <ebadger@gigaio.com>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: Jason Gunthorpe <jgg@ziepe.ca>
	Cc: Michal Hocko <mhocko@suse.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Will Deacon <will@kernel.org>
Link: http://lkml.kernel.org/r/20200306170846.9333-6-logang@deltatee.com
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 4e00c5affdd4b04e6392001716333971932f3d0c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/mm/book3s64/hash_utils.c
#	arch/powerpc/mm/book3s64/radix_pgtable.c
diff --cc arch/powerpc/mm/book3s64/hash_utils.c
index c7f37e28c477,8ed2411c3f39..000000000000
--- a/arch/powerpc/mm/book3s64/hash_utils.c
+++ b/arch/powerpc/mm/book3s64/hash_utils.c
@@@ -804,11 -809,19 +804,25 @@@ int resize_hpt_for_hotplug(unsigned lon
  	return 0;
  }
  
- int hash__create_section_mapping(unsigned long start, unsigned long end, int nid)
+ int hash__create_section_mapping(unsigned long start, unsigned long end,
+ 				 int nid, pgprot_t prot)
  {
++<<<<<<< HEAD
 +	int rc = htab_bolt_mapping(start, end, __pa(start),
 +				   pgprot_val(PAGE_KERNEL), mmu_linear_psize,
 +				   mmu_kernel_ssize);
++=======
+ 	int rc;
+ 
+ 	if (end >= H_VMALLOC_START) {
+ 		pr_warn("Outside the supported range\n");
+ 		return -1;
+ 	}
+ 
+ 	rc = htab_bolt_mapping(start, end, __pa(start),
+ 			       pgprot_val(prot), mmu_linear_psize,
+ 			       mmu_kernel_ssize);
++>>>>>>> 4e00c5affdd4 (powerpc/mm: thread pgprot_t through create_section_mapping())
  
  	if (rc < 0) {
  		int rc2 = htab_remove_mapping(start, end, mmu_linear_psize,
diff --cc arch/powerpc/mm/book3s64/radix_pgtable.c
index e1a99bba24b3,8f9edf07063a..000000000000
--- a/arch/powerpc/mm/book3s64/radix_pgtable.c
+++ b/arch/powerpc/mm/book3s64/radix_pgtable.c
@@@ -258,16 -254,12 +258,16 @@@ static inline void __meminit print_mapp
  
  static int __meminit create_physical_mapping(unsigned long start,
  					     unsigned long end,
- 					     int nid)
+ 					     int nid, pgprot_t _prot)
  {
  	unsigned long vaddr, addr, mapping_size = 0;
 -	bool prev_exec, exec = false;
  	pgprot_t prot;
 -	int psize;
 +	unsigned long max_mapping_size;
 +#ifdef CONFIG_STRICT_KERNEL_RWX
 +	int split_text_mapping = 1;
 +#else
 +	int split_text_mapping = 0;
 +#endif
  
  	start = _ALIGN_UP(start, PAGE_SIZE);
  	for (addr = start; addr < end; addr += mapping_size) {
@@@ -309,10 -286,18 +309,23 @@@ retry
  		vaddr = (unsigned long)__va(addr);
  
  		if (overlaps_kernel_text(vaddr, vaddr + mapping_size) ||
 -		    overlaps_interrupt_vector_text(vaddr, vaddr + mapping_size)) {
 +		    overlaps_interrupt_vector_text(vaddr, vaddr + mapping_size))
  			prot = PAGE_KERNEL_X;
++<<<<<<< HEAD
 +		else
 +			prot = PAGE_KERNEL;
++=======
+ 			exec = true;
+ 		} else {
+ 			prot = _prot;
+ 			exec = false;
+ 		}
+ 
+ 		if (mapping_size != previous_size || exec != prev_exec) {
+ 			print_mapping(start, addr, previous_size, prev_exec);
+ 			start = addr;
+ 		}
++>>>>>>> 4e00c5affdd4 (powerpc/mm: thread pgprot_t through create_section_mapping())
  
  		rc = __map_kernel_page(vaddr, addr, prot, mapping_size, nid, start, end);
  		if (rc)
@@@ -339,9 -326,15 +352,9 @@@ void __init radix_init_pgtable(void
  		 * page tables will be allocated within the range. No
  		 * need or a node (which we don't have yet).
  		 */
 -
 -		if ((reg->base + reg->size) >= RADIX_VMALLOC_START) {
 -			pr_warn("Outside the supported range\n");
 -			continue;
 -		}
 -
  		WARN_ON(create_physical_mapping(reg->base,
  						reg->base + reg->size,
- 						-1));
+ 						-1, PAGE_KERNEL));
  	}
  
  	/* Find out how many PID bits are supported */
@@@ -715,8 -713,10 +728,15 @@@ static int __meminit stop_machine_chang
  
  	spin_unlock(&init_mm.page_table_lock);
  	pte_clear(&init_mm, params->aligned_start, params->pte);
++<<<<<<< HEAD
 +	create_physical_mapping(params->aligned_start, params->start, -1);
 +	create_physical_mapping(params->end, params->aligned_end, -1);
++=======
+ 	create_physical_mapping(__pa(params->aligned_start),
+ 				__pa(params->start), -1, PAGE_KERNEL);
+ 	create_physical_mapping(__pa(params->end), __pa(params->aligned_end),
+ 				-1, PAGE_KERNEL);
++>>>>>>> 4e00c5affdd4 (powerpc/mm: thread pgprot_t through create_section_mapping())
  	spin_lock(&init_mm.page_table_lock);
  	return 0;
  }
@@@ -873,9 -873,16 +893,20 @@@ static void __meminit remove_pagetable(
  	radix__flush_tlb_kernel_range(start, end);
  }
  
- int __meminit radix__create_section_mapping(unsigned long start, unsigned long end, int nid)
+ int __meminit radix__create_section_mapping(unsigned long start,
+ 					    unsigned long end, int nid,
+ 					    pgprot_t prot)
  {
++<<<<<<< HEAD
 +	return create_physical_mapping(start, end, nid);
++=======
+ 	if (end >= RADIX_VMALLOC_START) {
+ 		pr_warn("Outside the supported range\n");
+ 		return -1;
+ 	}
+ 
+ 	return create_physical_mapping(__pa(start), __pa(end), nid, prot);
++>>>>>>> 4e00c5affdd4 (powerpc/mm: thread pgprot_t through create_section_mapping())
  }
  
  int __meminit radix__remove_section_mapping(unsigned long start, unsigned long end)
diff --git a/arch/powerpc/include/asm/book3s/64/hash.h b/arch/powerpc/include/asm/book3s/64/hash.h
index f4e785b5ff90..01e1cbcd7888 100644
--- a/arch/powerpc/include/asm/book3s/64/hash.h
+++ b/arch/powerpc/include/asm/book3s/64/hash.h
@@ -213,7 +213,8 @@ extern int __meminit hash__vmemmap_create_mapping(unsigned long start,
 extern void hash__vmemmap_remove_mapping(unsigned long start,
 				     unsigned long page_size);
 
-int hash__create_section_mapping(unsigned long start, unsigned long end, int nid);
+int hash__create_section_mapping(unsigned long start, unsigned long end,
+				 int nid, pgprot_t prot);
 int hash__remove_section_mapping(unsigned long start, unsigned long end);
 
 #endif /* !__ASSEMBLY__ */
diff --git a/arch/powerpc/include/asm/book3s/64/radix.h b/arch/powerpc/include/asm/book3s/64/radix.h
index 3ab3f7aef022..b80771765f74 100644
--- a/arch/powerpc/include/asm/book3s/64/radix.h
+++ b/arch/powerpc/include/asm/book3s/64/radix.h
@@ -276,7 +276,8 @@ static inline unsigned long radix__get_tree_size(void)
 }
 
 #ifdef CONFIG_MEMORY_HOTPLUG
-int radix__create_section_mapping(unsigned long start, unsigned long end, int nid);
+int radix__create_section_mapping(unsigned long start, unsigned long end,
+				  int nid, pgprot_t prot);
 int radix__remove_section_mapping(unsigned long start, unsigned long end);
 #endif /* CONFIG_MEMORY_HOTPLUG */
 #endif /* __ASSEMBLY__ */
diff --git a/arch/powerpc/include/asm/sparsemem.h b/arch/powerpc/include/asm/sparsemem.h
index b37c802d669c..2d0c725f1ddb 100644
--- a/arch/powerpc/include/asm/sparsemem.h
+++ b/arch/powerpc/include/asm/sparsemem.h
@@ -24,7 +24,8 @@
 #endif /* CONFIG_SPARSEMEM */
 
 #ifdef CONFIG_MEMORY_HOTPLUG
-extern int create_section_mapping(unsigned long start, unsigned long end, int nid);
+extern int create_section_mapping(unsigned long start, unsigned long end,
+				  int nid, pgprot_t prot);
 extern int remove_section_mapping(unsigned long start, unsigned long end);
 
 #ifdef CONFIG_PPC_BOOK3S_64
* Unmerged path arch/powerpc/mm/book3s64/hash_utils.c
diff --git a/arch/powerpc/mm/book3s64/pgtable.c b/arch/powerpc/mm/book3s64/pgtable.c
index 38bc5a35d924..e22737dad145 100644
--- a/arch/powerpc/mm/book3s64/pgtable.c
+++ b/arch/powerpc/mm/book3s64/pgtable.c
@@ -182,12 +182,13 @@ void mmu_cleanup_all(void)
 }
 
 #ifdef CONFIG_MEMORY_HOTPLUG
-int __meminit create_section_mapping(unsigned long start, unsigned long end, int nid)
+int __meminit create_section_mapping(unsigned long start, unsigned long end,
+				     int nid, pgprot_t prot)
 {
 	if (radix_enabled())
-		return radix__create_section_mapping(start, end, nid);
+		return radix__create_section_mapping(start, end, nid, prot);
 
-	return hash__create_section_mapping(start, end, nid);
+	return hash__create_section_mapping(start, end, nid, prot);
 }
 
 int __meminit remove_section_mapping(unsigned long start, unsigned long end)
* Unmerged path arch/powerpc/mm/book3s64/radix_pgtable.c
diff --git a/arch/powerpc/mm/mem.c b/arch/powerpc/mm/mem.c
index fa9ce75915ae..fb0014c7c07b 100644
--- a/arch/powerpc/mm/mem.c
+++ b/arch/powerpc/mm/mem.c
@@ -105,7 +105,8 @@ int memory_add_physaddr_to_nid(u64 start)
 }
 #endif
 
-int __weak create_section_mapping(unsigned long start, unsigned long end, int nid)
+int __weak create_section_mapping(unsigned long start, unsigned long end,
+				  int nid, pgprot_t prot)
 {
 	return -ENODEV;
 }
@@ -146,7 +147,7 @@ int __ref arch_add_memory(int nid, u64 start, u64 size,
 	resize_hpt_for_hotplug(memblock_phys_mem_size());
 
 	start = (unsigned long)__va(start);
-	rc = create_section_mapping(start, start + size, nid);
+	rc = create_section_mapping(start, start + size, nid, PAGE_KERNEL);
 	if (rc) {
 		pr_warn("Unable to create mapping for hot added memory 0x%llx..0x%llx: %d\n",
 			start, start + size, rc);
