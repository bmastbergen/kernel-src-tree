tcp: add tcp_tx_skb_cache sysctl

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Eric Dumazet <edumazet@google.com>
commit 0b7d7f6b22084a3156f267c85303908a8f4c9a08
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/0b7d7f6b.failed

Feng Tang reported a performance regression after introduction
of per TCP socket tx/rx caches, for TCP over loopback (netperf)

There is high chance the regression is caused by a change on
how well the 32 KB per-thread page (current->task_frag) can
be recycled, and lack of pcp caches for order-3 pages.

I could not reproduce the regression myself, cpus all being
spinning on the mm spinlocks for page allocs/freeing, regardless
of enabling or disabling the per tcp socket caches.

It seems best to disable the feature by default, and let
admins enabling it.

MM layer either needs to provide scalable order-3 pages
allocations, or could attempt a trylock on zone->lock if
the caller only attempts to get a high-order page and is
able to fallback to order-0 ones in case of pressure.

Tests run on a 56 cores host (112 hyper threads)

-	35.49%	netperf 		 [kernel.vmlinux]	  [k] queued_spin_lock_slowpath
   - 35.49% queued_spin_lock_slowpath
	  - 18.18% get_page_from_freelist
		 - __alloc_pages_nodemask
			- 18.18% alloc_pages_current
				 skb_page_frag_refill
				 sk_page_frag_refill
				 tcp_sendmsg_locked
				 tcp_sendmsg
				 inet_sendmsg
				 sock_sendmsg
				 __sys_sendto
				 __x64_sys_sendto
				 do_syscall_64
				 entry_SYSCALL_64_after_hwframe
				 __libc_send
	  + 17.31% __free_pages_ok
+	31.43%	swapper 		 [kernel.vmlinux]	  [k] intel_idle
+	 9.12%	netperf 		 [kernel.vmlinux]	  [k] copy_user_enhanced_fast_string
+	 6.53%	netserver		 [kernel.vmlinux]	  [k] copy_user_enhanced_fast_string
+	 0.69%	netserver		 [kernel.vmlinux]	  [k] queued_spin_lock_slowpath
+	 0.68%	netperf 		 [kernel.vmlinux]	  [k] skb_release_data
+	 0.52%	netperf 		 [kernel.vmlinux]	  [k] tcp_sendmsg_locked
	 0.46%	netperf 		 [kernel.vmlinux]	  [k] _raw_spin_lock_irqsave

Fixes: 472c2e07eef0 ("tcp: add one skb cache for tx")
	Signed-off-by: Eric Dumazet <edumazet@google.com>
	Reported-by: Feng Tang <feng.tang@intel.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 0b7d7f6b22084a3156f267c85303908a8f4c9a08)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/sock.h
#	net/ipv4/sysctl_net_ipv4.c
diff --cc include/net/sock.h
index 50c624432ded,7d7f4ce63bb2..000000000000
--- a/include/net/sock.h
+++ b/include/net/sock.h
@@@ -1536,10 -1463,18 +1536,20 @@@ static inline void sk_mem_uncharge(stru
  		__sk_mem_reclaim(sk, 1 << 20);
  }
  
+ DECLARE_STATIC_KEY_FALSE(tcp_tx_skb_cache_key);
  static inline void sk_wmem_free_skb(struct sock *sk, struct sk_buff *skb)
  {
 -	sock_set_flag(sk, SOCK_QUEUE_SHRUNK);
 -	sk->sk_wmem_queued -= skb->truesize;
 +	sk_wmem_queued_add(sk, -skb->truesize);
  	sk_mem_uncharge(sk, skb->truesize);
++<<<<<<< HEAD
++=======
+ 	if (static_branch_unlikely(&tcp_tx_skb_cache_key) &&
+ 	    !sk->sk_tx_skb_cache && !skb_cloned(skb)) {
+ 		skb_zcopy_clear(skb, true);
+ 		sk->sk_tx_skb_cache = skb;
+ 		return;
+ 	}
++>>>>>>> 0b7d7f6b2208 (tcp: add tcp_tx_skb_cache sysctl)
  	__kfree_skb(skb);
  }
  
diff --cc net/ipv4/sysctl_net_ipv4.c
index a9b15c74e438,08a428a7b274..000000000000
--- a/net/ipv4/sysctl_net_ipv4.c
+++ b/net/ipv4/sysctl_net_ipv4.c
@@@ -51,6 -51,11 +51,14 @@@ static int comp_sack_nr_max = 255
  static u32 u32_max_div_HZ = UINT_MAX / HZ;
  static int one_day_secs = 24 * 3600;
  
++<<<<<<< HEAD
++=======
+ DEFINE_STATIC_KEY_FALSE(tcp_rx_skb_cache_key);
+ EXPORT_SYMBOL(tcp_rx_skb_cache_key);
+ 
+ DEFINE_STATIC_KEY_FALSE(tcp_tx_skb_cache_key);
+ 
++>>>>>>> 0b7d7f6b2208 (tcp: add tcp_tx_skb_cache sysctl)
  /* obsolete */
  static int sysctl_tcp_low_latency __read_mostly;
  
@@@ -550,6 -555,27 +558,30 @@@ static struct ctl_table ipv4_table[] = 
  		.mode		= 0644,
  		.proc_handler	= proc_doulongvec_minmax,
  	},
++<<<<<<< HEAD
++=======
+ 	{
+ 		.procname	= "fib_sync_mem",
+ 		.data		= &sysctl_fib_sync_mem,
+ 		.maxlen		= sizeof(sysctl_fib_sync_mem),
+ 		.mode		= 0644,
+ 		.proc_handler	= proc_douintvec_minmax,
+ 		.extra1		= &sysctl_fib_sync_mem_min,
+ 		.extra2		= &sysctl_fib_sync_mem_max,
+ 	},
+ 	{
+ 		.procname	= "tcp_rx_skb_cache",
+ 		.data		= &tcp_rx_skb_cache_key.key,
+ 		.mode		= 0644,
+ 		.proc_handler	= proc_do_static_key,
+ 	},
+ 	{
+ 		.procname	= "tcp_tx_skb_cache",
+ 		.data		= &tcp_tx_skb_cache_key.key,
+ 		.mode		= 0644,
+ 		.proc_handler	= proc_do_static_key,
+ 	},
++>>>>>>> 0b7d7f6b2208 (tcp: add tcp_tx_skb_cache sysctl)
  	{ }
  };
  
* Unmerged path include/net/sock.h
* Unmerged path net/ipv4/sysctl_net_ipv4.c
