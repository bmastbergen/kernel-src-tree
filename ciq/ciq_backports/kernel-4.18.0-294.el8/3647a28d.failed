RDMA/cma: Using the standard locking pattern when delivering the removal event

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Jason Gunthorpe <jgg@nvidia.com>
commit 3647a28de1ada8708efc78d956619b9df5004478
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/3647a28d.failed

Whenever an event is delivered to the handler it should be done under the
handler_mutex and upon any non-zero return from the handler it should
trigger destruction of the cm_id.

cma_process_remove() skips some steps here, it is not necessarily wrong
since the state change should prevent any races, but it is confusing and
unnecessary.

Follow the standard pattern here, with the slight twist that the
transition to RDMA_CM_DEVICE_REMOVAL includes a cma_cancel_operation().

Link: https://lore.kernel.org/r/20200723070707.1771101-3-leon@kernel.org
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@nvidia.com>
(cherry picked from commit 3647a28de1ada8708efc78d956619b9df5004478)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/cma.c
diff --cc drivers/infiniband/core/cma.c
index abf2fb7b598e,b51a0acd672b..000000000000
--- a/drivers/infiniband/core/cma.c
+++ b/drivers/infiniband/core/cma.c
@@@ -4776,33 -4774,46 +4778,47 @@@ free_gid_type
  
  free_cma_dev:
  	kfree(cma_dev);
 -	return ret;
 +
 +	return;
  }
  
- static int cma_remove_id_dev(struct rdma_id_private *id_priv)
+ static void cma_send_device_removal_put(struct rdma_id_private *id_priv)
  {
- 	struct rdma_cm_event event = {};
+ 	struct rdma_cm_event event = { .event = RDMA_CM_EVENT_DEVICE_REMOVAL };
  	enum rdma_cm_state state;
- 	int ret = 0;
- 
- 	/* Record that we want to remove the device */
- 	state = cma_exch(id_priv, RDMA_CM_DEVICE_REMOVAL);
- 	if (state == RDMA_CM_DESTROYING)
- 		return 0;
+ 	unsigned long flags;
  
- 	cma_cancel_operation(id_priv, state);
  	mutex_lock(&id_priv->handler_mutex);
+ 	/* Record that we want to remove the device */
+ 	spin_lock_irqsave(&id_priv->lock, flags);
+ 	state = id_priv->state;
+ 	if (state == RDMA_CM_DESTROYING || state == RDMA_CM_DEVICE_REMOVAL) {
+ 		spin_unlock_irqrestore(&id_priv->lock, flags);
+ 		mutex_unlock(&id_priv->handler_mutex);
+ 		cma_id_put(id_priv);
+ 		return;
+ 	}
+ 	id_priv->state = RDMA_CM_DEVICE_REMOVAL;
+ 	spin_unlock_irqrestore(&id_priv->lock, flags);
  
- 	/* Check for destruction from another callback. */
- 	if (!cma_comp(id_priv, RDMA_CM_DEVICE_REMOVAL))
- 		goto out;
- 
- 	event.event = RDMA_CM_EVENT_DEVICE_REMOVAL;
- 	ret = cma_cm_event_handler(id_priv, &event);
- out:
+ 	if (cma_cm_event_handler(id_priv, &event)) {
+ 		/*
+ 		 * At this point the ULP promises it won't call
+ 		 * rdma_destroy_id() concurrently
+ 		 */
+ 		cma_id_put(id_priv);
+ 		mutex_unlock(&id_priv->handler_mutex);
+ 		rdma_destroy_id(&id_priv->id);
+ 		return;
+ 	}
  	mutex_unlock(&id_priv->handler_mutex);
- 	return ret;
+ 
+ 	/*
+ 	 * If this races with destroy then the thread that first assigns state
+ 	 * to a destroying does the cancel.
+ 	 */
+ 	cma_cancel_operation(id_priv, state);
+ 	cma_id_put(id_priv);
  }
  
  static void cma_process_remove(struct cma_device *cma_dev)
@@@ -4817,13 -4825,10 +4830,17 @@@
  
  		list_del(&id_priv->listen_list);
  		list_del_init(&id_priv->list);
 -		cma_id_get(id_priv);
 +		atomic_inc(&id_priv->refcount);
  		mutex_unlock(&lock);
  
++<<<<<<< HEAD
 +		ret = id_priv->internal_id ? 1 : cma_remove_id_dev(id_priv);
 +		cma_deref_id(id_priv);
 +		if (ret)
 +			rdma_destroy_id(&id_priv->id);
++=======
+ 		cma_send_device_removal_put(id_priv);
++>>>>>>> 3647a28de1ad (RDMA/cma: Using the standard locking pattern when delivering the removal event)
  
  		mutex_lock(&lock);
  	}
* Unmerged path drivers/infiniband/core/cma.c
