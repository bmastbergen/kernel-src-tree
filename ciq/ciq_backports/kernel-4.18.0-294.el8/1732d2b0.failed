mm/vmscan.c: add checks for incorrect handling of current->reclaim_state

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Andrew Morton <akpm@linux-foundation.org>
commit 1732d2b0117c26a6bf6027c919e49603156ea93d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/1732d2b0.failed

Six sites are presently altering current->reclaim_state.  There is a
risk that one function stomps on a caller's value.  Use a helper
function to catch such errors.

	Cc: Yafang Shao <laoar.shao@gmail.com>
	Cc: Kirill Tkhai <ktkhai@virtuozzo.com>
	Cc: Michal Hocko <mhocko@suse.com>
	Cc: Johannes Weiner <hannes@cmpxchg.org>
	Cc: Vladimir Davydov <vdavydov.dev@gmail.com>
	Cc: Mel Gorman <mgorman@techsingularity.net>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 1732d2b0117c26a6bf6027c919e49603156ea93d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/vmscan.c
diff --cc mm/vmscan.c
index aedd3e5691d7,44df66a98f2a..000000000000
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@@ -3276,11 -3206,13 +3288,19 @@@ unsigned long try_to_free_pages(struct 
  	if (throttle_direct_reclaim(sc.gfp_mask, zonelist, nodemask))
  		return 1;
  
++<<<<<<< HEAD
++=======
+ 	set_task_reclaim_state(current, &sc.reclaim_state);
++>>>>>>> 1732d2b0117c (mm/vmscan.c: add checks for incorrect handling of current->reclaim_state)
  	trace_mm_vmscan_direct_reclaim_begin(order, sc.gfp_mask);
  
  	nr_reclaimed = do_try_to_free_pages(zonelist, &sc);
  
  	trace_mm_vmscan_direct_reclaim_end(nr_reclaimed);
++<<<<<<< HEAD
++=======
+ 	set_task_reclaim_state(current, NULL);
++>>>>>>> 1732d2b0117c (mm/vmscan.c: add checks for incorrect handling of current->reclaim_state)
  
  	return nr_reclaimed;
  }
@@@ -3303,6 -3235,7 +3323,10 @@@ unsigned long mem_cgroup_shrink_node(st
  	};
  	unsigned long lru_pages;
  
++<<<<<<< HEAD
++=======
+ 	set_task_reclaim_state(current, &sc.reclaim_state);
++>>>>>>> 1732d2b0117c (mm/vmscan.c: add checks for incorrect handling of current->reclaim_state)
  	sc.gfp_mask = (gfp_mask & GFP_RECLAIM_MASK) |
  			(GFP_HIGHUSER_MOVABLE & ~GFP_RECLAIM_MASK);
  
@@@ -3320,7 -3253,9 +3344,11 @@@
  
  	trace_mm_vmscan_memcg_softlimit_reclaim_end(sc.nr_reclaimed);
  
++<<<<<<< HEAD
++=======
+ 	set_task_reclaim_state(current, NULL);
++>>>>>>> 1732d2b0117c (mm/vmscan.c: add checks for incorrect handling of current->reclaim_state)
  	*nr_scanned = sc.nr_scanned;
 -
  	return sc.nr_reclaimed;
  }
  
@@@ -3344,12 -3281,16 +3372,17 @@@ unsigned long try_to_free_mem_cgroup_pa
  		.may_swap = may_swap,
  		.may_shrinkslab = 1,
  	};
++<<<<<<< HEAD
++=======
+ 
+ 	set_task_reclaim_state(current, &sc.reclaim_state);
++>>>>>>> 1732d2b0117c (mm/vmscan.c: add checks for incorrect handling of current->reclaim_state)
  	/*
 -	 * Unlike direct reclaim via alloc_pages(), memcg's reclaim doesn't
 -	 * take care of from where we get pages. So the node where we start the
 -	 * scan does not need to be the current node.
 +	 * Traverse the ZONELIST_FALLBACK zonelist of the current node to put
 +	 * equal pressure on all the nodes. This is based on the assumption that
 +	 * the reclaim does not bail out early.
  	 */
 -	nid = mem_cgroup_select_victim_node(memcg);
 -
 -	zonelist = &NODE_DATA(nid)->node_zonelists[ZONELIST_FALLBACK];
 +	struct zonelist *zonelist = node_zonelist(numa_node_id(), sc.gfp_mask);
  
  	trace_mm_vmscan_memcg_reclaim_begin(0, sc.gfp_mask);
  
@@@ -3362,6 -3303,7 +3395,10 @@@
  	psi_memstall_leave(&pflags);
  
  	trace_mm_vmscan_memcg_reclaim_end(nr_reclaimed);
++<<<<<<< HEAD
++=======
+ 	set_task_reclaim_state(current, NULL);
++>>>>>>> 1732d2b0117c (mm/vmscan.c: add checks for incorrect handling of current->reclaim_state)
  
  	return nr_reclaimed;
  }
* Unmerged path mm/vmscan.c
