seqlock: s/__SEQ_LOCKDEP/__SEQ_LOCK/g

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Peter Zijlstra <peterz@infradead.org>
commit e55687fe5c1e4849e5559a0a49199c9ca3fff36e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/e55687fe.failed

__SEQ_LOCKDEP() is an expression gate for the
seqcount_LOCKNAME_t::lock member. Rename it to be about the member,
not the gate condition.

Later (PREEMPT_RT) patches will make the member available for !LOCKDEP
configs.

	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
(cherry picked from commit e55687fe5c1e4849e5559a0a49199c9ca3fff36e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/seqlock.h
diff --cc include/linux/seqlock.h
index 362623ec6c41,c689abab06c8..000000000000
--- a/include/linux/seqlock.h
+++ b/include/linux/seqlock.h
@@@ -105,13 -111,273 +105,277 @@@ static inline void seqcount_lockdep_rea
  # define seqcount_lockdep_reader_access(x)
  #endif
  
 -/**
 - * SEQCNT_ZERO() - static initializer for seqcount_t
 - * @name: Name of the seqcount_t instance
 - */
 -#define SEQCNT_ZERO(name) { .sequence = 0, SEQCOUNT_DEP_MAP_INIT(name) }
 +#define SEQCNT_ZERO(lockname) { .sequence = 0, SEQCOUNT_DEP_MAP_INIT(lockname)}
  
++<<<<<<< HEAD
 +
 +/**
 + * __read_seqcount_begin - begin a seq-read critical section (without barrier)
 + * @s: pointer to seqcount_t
 + * Returns: count to be passed to read_seqcount_retry
++=======
+ /*
+  * Sequence counters with associated locks (seqcount_LOCKTYPE_t)
+  *
+  * A sequence counter which associates the lock used for writer
+  * serialization at initialization time. This enables lockdep to validate
+  * that the write side critical section is properly serialized.
+  *
+  * For associated locks which do not implicitly disable preemption,
+  * preemption protection is enforced in the write side function.
+  *
+  * Lockdep is never used in any for the raw write variants.
+  *
+  * See Documentation/locking/seqlock.rst
+  */
+ 
+ #ifdef CONFIG_LOCKDEP
+ #define __SEQ_LOCK(expr)	expr
+ #else
+ #define __SEQ_LOCK(expr)
+ #endif
+ 
+ #define SEQCOUNT_LOCKTYPE_ZERO(seq_name, assoc_lock) {			\
+ 	.seqcount		= SEQCNT_ZERO(seq_name.seqcount),	\
+ 	__SEQ_LOCK(.lock	= (assoc_lock))				\
+ }
+ 
+ #define seqcount_locktype_init(s, assoc_lock)				\
+ do {									\
+ 	seqcount_init(&(s)->seqcount);					\
+ 	__SEQ_LOCK((s)->lock = (assoc_lock));				\
+ } while (0)
+ 
+ /**
+  * typedef seqcount_spinlock_t - sequence counter with spinlock associated
+  * @seqcount:	The real sequence counter
+  * @lock:	Pointer to the associated spinlock
+  *
+  * A plain sequence counter with external writer synchronization by a
+  * spinlock. The spinlock is associated to the sequence count in the
+  * static initializer or init function. This enables lockdep to validate
+  * that the write side critical section is properly serialized.
+  */
+ typedef struct seqcount_spinlock {
+ 	seqcount_t	seqcount;
+ 	__SEQ_LOCK(spinlock_t	*lock);
+ } seqcount_spinlock_t;
+ 
+ /**
+  * SEQCNT_SPINLOCK_ZERO - static initializer for seqcount_spinlock_t
+  * @name:	Name of the seqcount_spinlock_t instance
+  * @lock:	Pointer to the associated spinlock
+  */
+ #define SEQCNT_SPINLOCK_ZERO(name, lock)				\
+ 	SEQCOUNT_LOCKTYPE_ZERO(name, lock)
+ 
+ /**
+  * seqcount_spinlock_init - runtime initializer for seqcount_spinlock_t
+  * @s:		Pointer to the seqcount_spinlock_t instance
+  * @lock:	Pointer to the associated spinlock
+  */
+ #define seqcount_spinlock_init(s, lock)					\
+ 	seqcount_locktype_init(s, lock)
+ 
+ /**
+  * typedef seqcount_raw_spinlock_t - sequence count with raw spinlock associated
+  * @seqcount:	The real sequence counter
+  * @lock:	Pointer to the associated raw spinlock
+  *
+  * A plain sequence counter with external writer synchronization by a
+  * raw spinlock. The raw spinlock is associated to the sequence count in
+  * the static initializer or init function. This enables lockdep to
+  * validate that the write side critical section is properly serialized.
+  */
+ typedef struct seqcount_raw_spinlock {
+ 	seqcount_t      seqcount;
+ 	__SEQ_LOCK(raw_spinlock_t	*lock);
+ } seqcount_raw_spinlock_t;
+ 
+ /**
+  * SEQCNT_RAW_SPINLOCK_ZERO - static initializer for seqcount_raw_spinlock_t
+  * @name:	Name of the seqcount_raw_spinlock_t instance
+  * @lock:	Pointer to the associated raw_spinlock
+  */
+ #define SEQCNT_RAW_SPINLOCK_ZERO(name, lock)				\
+ 	SEQCOUNT_LOCKTYPE_ZERO(name, lock)
+ 
+ /**
+  * seqcount_raw_spinlock_init - runtime initializer for seqcount_raw_spinlock_t
+  * @s:		Pointer to the seqcount_raw_spinlock_t instance
+  * @lock:	Pointer to the associated raw_spinlock
+  */
+ #define seqcount_raw_spinlock_init(s, lock)				\
+ 	seqcount_locktype_init(s, lock)
+ 
+ /**
+  * typedef seqcount_rwlock_t - sequence count with rwlock associated
+  * @seqcount:	The real sequence counter
+  * @lock:	Pointer to the associated rwlock
+  *
+  * A plain sequence counter with external writer synchronization by a
+  * rwlock. The rwlock is associated to the sequence count in the static
+  * initializer or init function. This enables lockdep to validate that
+  * the write side critical section is properly serialized.
+  */
+ typedef struct seqcount_rwlock {
+ 	seqcount_t      seqcount;
+ 	__SEQ_LOCK(rwlock_t		*lock);
+ } seqcount_rwlock_t;
+ 
+ /**
+  * SEQCNT_RWLOCK_ZERO - static initializer for seqcount_rwlock_t
+  * @name:	Name of the seqcount_rwlock_t instance
+  * @lock:	Pointer to the associated rwlock
+  */
+ #define SEQCNT_RWLOCK_ZERO(name, lock)					\
+ 	SEQCOUNT_LOCKTYPE_ZERO(name, lock)
+ 
+ /**
+  * seqcount_rwlock_init - runtime initializer for seqcount_rwlock_t
+  * @s:		Pointer to the seqcount_rwlock_t instance
+  * @lock:	Pointer to the associated rwlock
+  */
+ #define seqcount_rwlock_init(s, lock)					\
+ 	seqcount_locktype_init(s, lock)
+ 
+ /**
+  * typedef seqcount_mutex_t - sequence count with mutex associated
+  * @seqcount:	The real sequence counter
+  * @lock:	Pointer to the associated mutex
+  *
+  * A plain sequence counter with external writer synchronization by a
+  * mutex. The mutex is associated to the sequence counter in the static
+  * initializer or init function. This enables lockdep to validate that
+  * the write side critical section is properly serialized.
+  *
+  * The write side API functions write_seqcount_begin()/end() automatically
+  * disable and enable preemption when used with seqcount_mutex_t.
+  */
+ typedef struct seqcount_mutex {
+ 	seqcount_t      seqcount;
+ 	__SEQ_LOCK(struct mutex	*lock);
+ } seqcount_mutex_t;
+ 
+ /**
+  * SEQCNT_MUTEX_ZERO - static initializer for seqcount_mutex_t
+  * @name:	Name of the seqcount_mutex_t instance
+  * @lock:	Pointer to the associated mutex
+  */
+ #define SEQCNT_MUTEX_ZERO(name, lock)					\
+ 	SEQCOUNT_LOCKTYPE_ZERO(name, lock)
+ 
+ /**
+  * seqcount_mutex_init - runtime initializer for seqcount_mutex_t
+  * @s:		Pointer to the seqcount_mutex_t instance
+  * @lock:	Pointer to the associated mutex
+  */
+ #define seqcount_mutex_init(s, lock)					\
+ 	seqcount_locktype_init(s, lock)
+ 
+ /**
+  * typedef seqcount_ww_mutex_t - sequence count with ww_mutex associated
+  * @seqcount:	The real sequence counter
+  * @lock:	Pointer to the associated ww_mutex
+  *
+  * A plain sequence counter with external writer synchronization by a
+  * ww_mutex. The ww_mutex is associated to the sequence counter in the static
+  * initializer or init function. This enables lockdep to validate that
+  * the write side critical section is properly serialized.
+  *
+  * The write side API functions write_seqcount_begin()/end() automatically
+  * disable and enable preemption when used with seqcount_ww_mutex_t.
+  */
+ typedef struct seqcount_ww_mutex {
+ 	seqcount_t      seqcount;
+ 	__SEQ_LOCK(struct ww_mutex	*lock);
+ } seqcount_ww_mutex_t;
+ 
+ /**
+  * SEQCNT_WW_MUTEX_ZERO - static initializer for seqcount_ww_mutex_t
+  * @name:	Name of the seqcount_ww_mutex_t instance
+  * @lock:	Pointer to the associated ww_mutex
+  */
+ #define SEQCNT_WW_MUTEX_ZERO(name, lock)				\
+ 	SEQCOUNT_LOCKTYPE_ZERO(name, lock)
+ 
+ /**
+  * seqcount_ww_mutex_init - runtime initializer for seqcount_ww_mutex_t
+  * @s:		Pointer to the seqcount_ww_mutex_t instance
+  * @lock:	Pointer to the associated ww_mutex
+  */
+ #define seqcount_ww_mutex_init(s, lock)					\
+ 	seqcount_locktype_init(s, lock)
+ 
+ /*
+  * @preempt: Is the associated write serialization lock preemtpible?
+  */
+ #define SEQCOUNT_LOCKTYPE(locktype, preempt, lockmember)		\
+ static inline seqcount_t *						\
+ __seqcount_##locktype##_ptr(seqcount_##locktype##_t *s)			\
+ {									\
+ 	return &s->seqcount;						\
+ }									\
+ 									\
+ static inline bool							\
+ __seqcount_##locktype##_preemptible(seqcount_##locktype##_t *s)		\
+ {									\
+ 	return preempt;							\
+ }									\
+ 									\
+ static inline void							\
+ __seqcount_##locktype##_assert(seqcount_##locktype##_t *s)		\
+ {									\
+ 	__SEQ_LOCK(lockdep_assert_held(lockmember));			\
+ }
+ 
+ /*
+  * Similar hooks, but for plain seqcount_t
+  */
+ 
+ static inline seqcount_t *__seqcount_ptr(seqcount_t *s)
+ {
+ 	return s;
+ }
+ 
+ static inline bool __seqcount_preemptible(seqcount_t *s)
+ {
+ 	return false;
+ }
+ 
+ static inline void __seqcount_assert(seqcount_t *s)
+ {
+ 	lockdep_assert_preemption_disabled();
+ }
+ 
+ /*
+  * @s: Pointer to seqcount_locktype_t, generated hooks first parameter.
+  */
+ SEQCOUNT_LOCKTYPE(raw_spinlock,	false,	s->lock)
+ SEQCOUNT_LOCKTYPE(spinlock,	false,	s->lock)
+ SEQCOUNT_LOCKTYPE(rwlock,	false,	s->lock)
+ SEQCOUNT_LOCKTYPE(mutex,	true,	s->lock)
+ SEQCOUNT_LOCKTYPE(ww_mutex,	true,	&s->lock->base)
+ 
+ #define __seqprop_case(s, locktype, prop)				\
+ 	seqcount_##locktype##_t: __seqcount_##locktype##_##prop((void *)(s))
+ 
+ #define __seqprop(s, prop) _Generic(*(s),				\
+ 	seqcount_t:		__seqcount_##prop((void *)(s)),		\
+ 	__seqprop_case((s),	raw_spinlock,	prop),			\
+ 	__seqprop_case((s),	spinlock,	prop),			\
+ 	__seqprop_case((s),	rwlock,		prop),			\
+ 	__seqprop_case((s),	mutex,		prop),			\
+ 	__seqprop_case((s),	ww_mutex,	prop))
+ 
+ #define __to_seqcount_t(s)				__seqprop(s, ptr)
+ #define __associated_lock_exists_and_is_preemptible(s)	__seqprop(s, preemptible)
+ #define __assert_write_section_is_protected(s)		__seqprop(s, assert)
+ 
+ /**
+  * __read_seqcount_begin() - begin a seqcount_t read section w/o barrier
+  * @s: Pointer to seqcount_t or any of the seqcount_locktype_t variants
++>>>>>>> e55687fe5c1e (seqlock: s/__SEQ_LOCKDEP/__SEQ_LOCK/g)
   *
   * __read_seqcount_begin is like read_seqcount_begin, but has no smp_rmb()
   * barrier. Callers should ensure that smp_rmb() or equivalent ordering is
* Unmerged path include/linux/seqlock.h
