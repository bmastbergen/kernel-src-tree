asm-generic/tlb: Introduce CONFIG_HAVE_MMU_GATHER_NO_GATHER=y

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Martin Schwidefsky <schwidefsky@de.ibm.com>
commit 952a31c9e6fa963eabf3692f31a769e59f4c8303
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/952a31c9.failed

Add the Kconfig option HAVE_MMU_GATHER_NO_GATHER to the generic
mmu_gather code. If the option is set the mmu_gather will not
track individual pages for delayed page free anymore. A platform
that enables the option needs to provide its own implementation
of the __tlb_remove_page_size() function to free pages.

No change in behavior intended.

	Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Acked-by: Will Deacon <will.deacon@arm.com>
	Cc: Andrew Morton <akpm@linux-foundation.org>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Borislav Petkov <bp@alien8.de>
	Cc: Dave Hansen <dave.hansen@linux.intel.com>
	Cc: H. Peter Anvin <hpa@zytor.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Rik van Riel <riel@surriel.com>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: aneesh.kumar@linux.vnet.ibm.com
	Cc: heiko.carstens@de.ibm.com
	Cc: linux@armlinux.org.uk
	Cc: npiggin@gmail.com
Link: http://lkml.kernel.org/r/20180918125151.31744-2-schwidefsky@de.ibm.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 952a31c9e6fa963eabf3692f31a769e59f4c8303)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/asm-generic/tlb.h
#	mm/mmu_gather.c
diff --cc include/asm-generic/tlb.h
index a94094819a72,af20aa8255cd..000000000000
--- a/include/asm-generic/tlb.h
+++ b/include/asm-generic/tlb.h
@@@ -248,11 -258,23 +253,31 @@@ struct mmu_gather 
  	unsigned int		cleared_puds : 1;
  	unsigned int		cleared_p4ds : 1;
  
++<<<<<<< HEAD
 +	struct mmu_gather_batch *active;
 +	struct mmu_gather_batch	local;
 +	struct page		*__pages[MMU_GATHER_BUNDLE];
 +	unsigned int		batch_count;
 +	int page_size;
++=======
+ 	/*
+ 	 * tracks VM_EXEC | VM_HUGETLB in tlb_start_vma
+ 	 */
+ 	unsigned int		vma_exec : 1;
+ 	unsigned int		vma_huge : 1;
+ 
+ 	unsigned int		batch_count;
+ 
+ #ifndef CONFIG_HAVE_MMU_GATHER_NO_GATHER
+ 	struct mmu_gather_batch *active;
+ 	struct mmu_gather_batch	local;
+ 	struct page		*__pages[MMU_GATHER_BUNDLE];
+ 
+ #ifdef CONFIG_HAVE_MMU_GATHER_PAGE_SIZE
+ 	unsigned int page_size;
+ #endif
+ #endif
++>>>>>>> 952a31c9e6fa (asm-generic/tlb: Introduce CONFIG_HAVE_MMU_GATHER_NO_GATHER=y)
  };
  
  void arch_tlb_gather_mmu(struct mmu_gather *tlb,
@@@ -260,8 -282,7 +285,12 @@@
  void tlb_flush_mmu(struct mmu_gather *tlb);
  void arch_tlb_finish_mmu(struct mmu_gather *tlb,
  			 unsigned long start, unsigned long end, bool force);
++<<<<<<< HEAD
 +extern bool __tlb_remove_page_size(struct mmu_gather *tlb, struct page *page,
 +				   int page_size);
++=======
+ void tlb_flush_mmu_free(struct mmu_gather *tlb);
++>>>>>>> 952a31c9e6fa (asm-generic/tlb: Introduce CONFIG_HAVE_MMU_GATHER_NO_GATHER=y)
  
  static inline void __tlb_adjust_range(struct mmu_gather *tlb,
  				      unsigned long address,
* Unmerged path mm/mmu_gather.c
diff --git a/arch/Kconfig b/arch/Kconfig
index c2142afcf45f..ae033326021d 100644
--- a/arch/Kconfig
+++ b/arch/Kconfig
@@ -372,6 +372,9 @@ config HAVE_RCU_TABLE_FREE
 config HAVE_RCU_TABLE_INVALIDATE
 	bool
 
+config HAVE_MMU_GATHER_NO_GATHER
+	bool
+
 config ARCH_HAVE_NMI_SAFE_CMPXCHG
 	bool
 
* Unmerged path include/asm-generic/tlb.h
* Unmerged path mm/mmu_gather.c
