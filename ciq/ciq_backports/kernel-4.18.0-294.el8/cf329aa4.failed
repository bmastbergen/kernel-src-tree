udp: cope with UDP GRO packet misdirection

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Paolo Abeni <pabeni@redhat.com>
commit cf329aa42b6659204fee865bbce0ea20462552eb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/cf329aa4.failed

In some scenarios, the GRO engine can assemble an UDP GRO packet
that ultimately lands on a non GRO-enabled socket.
This patch tries to address the issue explicitly checking for the UDP
socket features before enqueuing the packet, and eventually segmenting
the unexpected GRO packet, as needed.

We must also cope with re-insertion requests: after segmentation the
UDP code calls the helper introduced by the previous patches, as needed.

Segmentation is performed by a common helper, which takes care of
updating socket and protocol stats is case of failure.

rfc v3 -> v1
 - fix compile issues with rxrpc
 - when gso_segment returns NULL, treat is as an error
 - added 'ipv4' argument to udp_rcv_segment()

rfc v2 -> rfc v3
 - moved udp_rcv_segment() into net/udp.h, account errors to socket
   and ns, always return NULL or segs list

	Signed-off-by: Paolo Abeni <pabeni@redhat.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit cf329aa42b6659204fee865bbce0ea20462552eb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/udp.h
#	net/ipv6/udp.c
diff --cc include/net/udp.h
index dff3cf1814b5,eccca2325ee6..000000000000
--- a/include/net/udp.h
+++ b/include/net/udp.h
@@@ -450,9 -468,26 +457,33 @@@ DECLARE_STATIC_KEY_FALSE(udpv6_encap_ne
  void udpv6_encap_enable(void);
  #endif
  
++<<<<<<< HEAD
 +#ifdef CONFIG_BPF_STREAM_PARSER
 +struct sk_psock;
 +struct proto *udp_bpf_get_proto(struct sock *sk, struct sk_psock *psock);
 +#endif /* BPF_STREAM_PARSER */
++=======
+ static inline struct sk_buff *udp_rcv_segment(struct sock *sk,
+ 					      struct sk_buff *skb, bool ipv4)
+ {
+ 	struct sk_buff *segs;
+ 
+ 	/* the GSO CB lays after the UDP one, no need to save and restore any
+ 	 * CB fragment
+ 	 */
+ 	segs = __skb_gso_segment(skb, NETIF_F_SG, false);
+ 	if (unlikely(IS_ERR_OR_NULL(segs))) {
+ 		int segs_nr = skb_shinfo(skb)->gso_segs;
+ 
+ 		atomic_add(segs_nr, &sk->sk_drops);
+ 		SNMP_ADD_STATS(__UDPX_MIB(sk, ipv4), UDP_MIB_INERRORS, segs_nr);
+ 		kfree_skb(skb);
+ 		return NULL;
+ 	}
+ 
+ 	consume_skb(skb);
+ 	return segs;
+ }
++>>>>>>> cf329aa42b66 (udp: cope with UDP GRO packet misdirection)
  
  #endif	/* _UDP_H */
diff --cc net/ipv6/udp.c
index 517ab020b626,c55698d19d68..000000000000
--- a/net/ipv6/udp.c
+++ b/net/ipv6/udp.c
@@@ -595,7 -547,14 +595,18 @@@ static __inline__ void udpv6_err(struc
  	__udp6_lib_err(skb, opt, type, code, offset, info, &udp_table);
  }
  
++<<<<<<< HEAD
 +static int udpv6_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)
++=======
+ DEFINE_STATIC_KEY_FALSE(udpv6_encap_needed_key);
+ void udpv6_encap_enable(void)
+ {
+ 	static_branch_enable(&udpv6_encap_needed_key);
+ }
+ EXPORT_SYMBOL(udpv6_encap_enable);
+ 
+ static int udpv6_queue_rcv_one_skb(struct sock *sk, struct sk_buff *skb)
++>>>>>>> cf329aa42b66 (udp: cope with UDP GRO packet misdirection)
  {
  	struct udp_sock *up = udp_sk(sk);
  	int is_udplite = IS_UDPLITE(sk);
diff --git a/include/linux/udp.h b/include/linux/udp.h
index 538bcb37e459..27f8e6c5690e 100644
--- a/include/linux/udp.h
+++ b/include/linux/udp.h
@@ -132,6 +132,12 @@ static inline void udp_cmsg_recv(struct msghdr *msg, struct sock *sk,
 	}
 }
 
+static inline bool udp_unexpected_gso(struct sock *sk, struct sk_buff *skb)
+{
+	return !udp_sk(sk)->gro_enabled && skb_is_gso(skb) &&
+	       skb_shinfo(skb)->gso_type & SKB_GSO_UDP_L4;
+}
+
 #define udp_portaddr_for_each_entry(__sk, list) \
 	hlist_for_each_entry(__sk, list, __sk_common.skc_portaddr_node)
 
* Unmerged path include/net/udp.h
diff --git a/net/ipv4/udp.c b/net/ipv4/udp.c
index b179b91fe862..09ea7e625aea 100644
--- a/net/ipv4/udp.c
+++ b/net/ipv4/udp.c
@@ -1980,7 +1980,7 @@ static int __udp_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)
  * Note that in the success and error cases, the skb is assumed to
  * have either been requeued or freed.
  */
-static int udp_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)
+static int udp_queue_rcv_one_skb(struct sock *sk, struct sk_buff *skb)
 {
 	struct udp_sock *up = udp_sk(sk);
 	int is_udplite = IS_UDPLITE(sk);
@@ -2083,6 +2083,27 @@ static int udp_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)
 	return -1;
 }
 
+static int udp_queue_rcv_skb(struct sock *sk, struct sk_buff *skb)
+{
+	struct sk_buff *next, *segs;
+	int ret;
+
+	if (likely(!udp_unexpected_gso(sk, skb)))
+		return udp_queue_rcv_one_skb(sk, skb);
+
+	BUILD_BUG_ON(sizeof(struct udp_skb_cb) > SKB_SGO_CB_OFFSET);
+	__skb_push(skb, -skb_mac_offset(skb));
+	segs = udp_rcv_segment(sk, skb, true);
+	for (skb = segs; skb; skb = next) {
+		next = skb->next;
+		__skb_pull(skb, skb_transport_offset(skb));
+		ret = udp_queue_rcv_one_skb(sk, skb);
+		if (ret > 0)
+			ip_protocol_deliver_rcu(dev_net(skb->dev), skb, -ret);
+	}
+	return 0;
+}
+
 /* For TCP sockets, sk_rx_dst is protected by socket lock
  * For UDP, we use xchg() to guard against concurrent changes.
  */
* Unmerged path net/ipv6/udp.c
