KVM: nSVM: CR3 MBZ bits are only 63:52

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Krish Sadhukhan <krish.sadhukhan@oracle.com>
commit fb0f33fdefe9f473dc5f7b71345096c8d60ab9dd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/fb0f33fd.failed

Commit 761e4169346553c180bbd4a383aedd72f905bc9a created a wrong mask for the
CR3 MBZ bits. According to APM vol 2, only the upper 12 bits are MBZ.

Fixes: 761e41693465 ("KVM: nSVM: Check that MBZ bits in CR3 and CR4 are not set on vmrun of nested guests", 2020-07-08)
	Signed-off-by: Krish Sadhukhan <krish.sadhukhan@oracle.com>
Message-Id: <20200829004824.4577-2-krish.sadhukhan@oracle.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit fb0f33fdefe9f473dc5f7b71345096c8d60ab9dd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/svm/nested.c
#	arch/x86/kvm/svm/svm.h
diff --cc arch/x86/kvm/svm/nested.c
index 3a222ac541d6,da5e87d002e9..000000000000
--- a/arch/x86/kvm/svm/nested.c
+++ b/arch/x86/kvm/svm/nested.c
@@@ -215,19 -211,39 +215,42 @@@ static bool nested_vmcb_check_controls(
  	return true;
  }
  
 -static bool nested_vmcb_checks(struct vcpu_svm *svm, struct vmcb *vmcb12)
 +static bool nested_vmcb_checks(struct vmcb *vmcb)
  {
 -	bool vmcb12_lma;
 -
 -	if ((vmcb12->save.efer & EFER_SVME) == 0)
 +	if ((vmcb->save.efer & EFER_SVME) == 0)
  		return false;
  
 -	if (((vmcb12->save.cr0 & X86_CR0_CD) == 0) && (vmcb12->save.cr0 & X86_CR0_NW))
 +	if (((vmcb->save.cr0 & X86_CR0_CD) == 0) &&
 +	    (vmcb->save.cr0 & X86_CR0_NW))
  		return false;
  
 -	if (!kvm_dr6_valid(vmcb12->save.dr6) || !kvm_dr7_valid(vmcb12->save.dr7))
 +	if (!kvm_dr6_valid(vmcb->save.dr6) || !kvm_dr7_valid(vmcb->save.dr7))
  		return false;
  
++<<<<<<< HEAD
 +	return nested_vmcb_check_controls(&vmcb->control);
++=======
+ 	vmcb12_lma = (vmcb12->save.efer & EFER_LME) && (vmcb12->save.cr0 & X86_CR0_PG);
+ 
+ 	if (!vmcb12_lma) {
+ 		if (vmcb12->save.cr4 & X86_CR4_PAE) {
+ 			if (vmcb12->save.cr3 & MSR_CR3_LEGACY_PAE_RESERVED_MASK)
+ 				return false;
+ 		} else {
+ 			if (vmcb12->save.cr3 & MSR_CR3_LEGACY_RESERVED_MASK)
+ 				return false;
+ 		}
+ 	} else {
+ 		if (!(vmcb12->save.cr4 & X86_CR4_PAE) ||
+ 		    !(vmcb12->save.cr0 & X86_CR0_PE) ||
+ 		    (vmcb12->save.cr3 & MSR_CR3_LONG_MBZ_MASK))
+ 			return false;
+ 	}
+ 	if (kvm_valid_cr4(&svm->vcpu, vmcb12->save.cr4))
+ 		return false;
+ 
+ 	return nested_vmcb_check_controls(&vmcb12->control);
++>>>>>>> fb0f33fdefe9 (KVM: nSVM: CR3 MBZ bits are only 63:52)
  }
  
  static void load_nested_vmcb_control(struct vcpu_svm *svm,
diff --cc arch/x86/kvm/svm/svm.h
index 7e2440454c08,bb3bbc87d3ff..000000000000
--- a/arch/x86/kvm/svm/svm.h
+++ b/arch/x86/kvm/svm/svm.h
@@@ -346,7 -337,10 +346,14 @@@ static inline bool gif_set(struct vcpu_
  }
  
  /* svm.c */
++<<<<<<< HEAD
 +#define MSR_INVALID			0xffffffffU
++=======
+ #define MSR_CR3_LEGACY_RESERVED_MASK		0xfe7U
+ #define MSR_CR3_LEGACY_PAE_RESERVED_MASK	0x7U
+ #define MSR_CR3_LONG_MBZ_MASK			0xfff0000000000000U
+ #define MSR_INVALID				0xffffffffU
++>>>>>>> fb0f33fdefe9 (KVM: nSVM: CR3 MBZ bits are only 63:52)
  
  u32 svm_msrpm_offset(u32 msr);
  void svm_set_efer(struct kvm_vcpu *vcpu, u64 efer);
* Unmerged path arch/x86/kvm/svm/nested.c
* Unmerged path arch/x86/kvm/svm/svm.h
