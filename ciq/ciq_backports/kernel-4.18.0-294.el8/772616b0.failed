mm: memcg/percpu: per-memcg percpu memory statistics

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Roman Gushchin <guro@fb.com>
commit 772616b031f06e05846488b01dab46a7c832da13
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/772616b0.failed

Percpu memory can represent a noticeable chunk of the total memory
consumption, especially on big machines with many CPUs.  Let's track
percpu memory usage for each memcg and display it in memory.stat.

A percpu allocation is usually scattered over multiple pages (and nodes),
and can be significantly smaller than a page.  So let's add a byte-sized
counter on the memcg level: MEMCG_PERCPU_B.  Byte-sized vmstat infra
created for slabs can be perfectly reused for percpu case.

[guro@fb.com: v3]
  Link: http://lkml.kernel.org/r/20200623184515.4132564-4-guro@fb.com

	Signed-off-by: Roman Gushchin <guro@fb.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Reviewed-by: Shakeel Butt <shakeelb@google.com>
	Acked-by: Dennis Zhou <dennis@kernel.org>
	Acked-by: Johannes Weiner <hannes@cmpxchg.org>
	Cc: Christoph Lameter <cl@linux.com>
	Cc: David Rientjes <rientjes@google.com>
	Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
	Cc: Mel Gorman <mgorman@techsingularity.net>
	Cc: Michal Hocko <mhocko@kernel.org>
	Cc: Pekka Enberg <penberg@kernel.org>
	Cc: Tejun Heo <tj@kernel.org>
	Cc: Tobin C. Harding <tobin@kernel.org>
	Cc: Vlastimil Babka <vbabka@suse.cz>
	Cc: Waiman Long <longman@redhat.com>
	Cc: Bixuan Cui <cuibixuan@huawei.com>
	Cc: Michal Koutn√Ω <mkoutny@suse.com>
	Cc: Stephen Rothwell <sfr@canb.auug.org.au>
Link: http://lkml.kernel.org/r/20200608230819.832349-4-guro@fb.com
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 772616b031f06e05846488b01dab46a7c832da13)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/memcontrol.h
#	mm/memcontrol.c
diff --cc include/linux/memcontrol.h
index f23d4613e4a5,2c2d301eac33..000000000000
--- a/include/linux/memcontrol.h
+++ b/include/linux/memcontrol.h
@@@ -38,13 -30,9 +38,17 @@@ struct kmem_cache
  
  /* Cgroup-specific page state, on top of universal node page state */
  enum memcg_stat_item {
 -	MEMCG_SWAP = NR_VM_NODE_STAT_ITEMS,
 +	MEMCG_CACHE = NR_VM_NODE_STAT_ITEMS,
 +	MEMCG_RSS,
 +	MEMCG_RSS_HUGE,
 +	MEMCG_SWAP,
  	MEMCG_SOCK,
++<<<<<<< HEAD
 +	/* XXX: why are these zone and not node counters? */
 +	MEMCG_KERNEL_STACK_KB,
++=======
+ 	MEMCG_PERCPU_B,
++>>>>>>> 772616b031f0 (mm: memcg/percpu: per-memcg percpu memory statistics)
  	MEMCG_NR_STAT,
  };
  
diff --cc mm/memcontrol.c
index 406972ba9675,36d5300f9b69..000000000000
--- a/mm/memcontrol.c
+++ b/mm/memcontrol.c
@@@ -1409,18 -1477,19 +1409,25 @@@ static char *memory_stat_format(struct 
  	 */
  
  	seq_buf_printf(&s, "anon %llu\n",
 -		       (u64)memcg_page_state(memcg, NR_ANON_MAPPED) *
 +		       (u64)memcg_page_state(memcg, MEMCG_RSS) *
  		       PAGE_SIZE);
  	seq_buf_printf(&s, "file %llu\n",
 -		       (u64)memcg_page_state(memcg, NR_FILE_PAGES) *
 +		       (u64)memcg_page_state(memcg, MEMCG_CACHE) *
  		       PAGE_SIZE);
  	seq_buf_printf(&s, "kernel_stack %llu\n",
 -		       (u64)memcg_page_state(memcg, NR_KERNEL_STACK_KB) *
 +		       (u64)memcg_page_state(memcg, MEMCG_KERNEL_STACK_KB) *
  		       1024);
  	seq_buf_printf(&s, "slab %llu\n",
++<<<<<<< HEAD
 +		       (u64)(memcg_page_state(memcg, NR_SLAB_RECLAIMABLE) +
 +			     memcg_page_state(memcg, NR_SLAB_UNRECLAIMABLE)) *
 +		       PAGE_SIZE);
++=======
+ 		       (u64)(memcg_page_state(memcg, NR_SLAB_RECLAIMABLE_B) +
+ 			     memcg_page_state(memcg, NR_SLAB_UNRECLAIMABLE_B)));
+ 	seq_buf_printf(&s, "percpu %llu\n",
+ 		       (u64)memcg_page_state(memcg, MEMCG_PERCPU_B));
++>>>>>>> 772616b031f0 (mm: memcg/percpu: per-memcg percpu memory statistics)
  	seq_buf_printf(&s, "sock %llu\n",
  		       (u64)memcg_page_state(memcg, MEMCG_SOCK) *
  		       PAGE_SIZE);
diff --git a/Documentation/admin-guide/cgroup-v2.rst b/Documentation/admin-guide/cgroup-v2.rst
index 45de03923c4f..3cc9f066cbeb 100644
--- a/Documentation/admin-guide/cgroup-v2.rst
+++ b/Documentation/admin-guide/cgroup-v2.rst
@@ -1212,6 +1212,10 @@ PAGE_SIZE multiple when read back.
 		Amount of memory used for storing in-kernel data
 		structures.
 
+	  percpu
+		Amount of memory used for storing per-cpu kernel
+		data structures.
+
 	  sock
 		Amount of memory used in network transmission buffers
 
* Unmerged path include/linux/memcontrol.h
* Unmerged path mm/memcontrol.c
diff --git a/mm/percpu.c b/mm/percpu.c
index 0900f0948353..2ce8d51be35e 100644
--- a/mm/percpu.c
+++ b/mm/percpu.c
@@ -1640,6 +1640,11 @@ static void pcpu_memcg_post_alloc_hook(struct obj_cgroup *objcg,
 
 	if (chunk) {
 		chunk->obj_cgroups[off >> PCPU_MIN_ALLOC_SHIFT] = objcg;
+
+		rcu_read_lock();
+		mod_memcg_state(obj_cgroup_memcg(objcg), MEMCG_PERCPU_B,
+				size * num_possible_cpus());
+		rcu_read_unlock();
 	} else {
 		obj_cgroup_uncharge(objcg, size * num_possible_cpus());
 		obj_cgroup_put(objcg);
@@ -1658,6 +1663,11 @@ static void pcpu_memcg_free_hook(struct pcpu_chunk *chunk, int off, size_t size)
 
 	obj_cgroup_uncharge(objcg, size * num_possible_cpus());
 
+	rcu_read_lock();
+	mod_memcg_state(obj_cgroup_memcg(objcg), MEMCG_PERCPU_B,
+			-(size * num_possible_cpus()));
+	rcu_read_unlock();
+
 	obj_cgroup_put(objcg);
 }
 
