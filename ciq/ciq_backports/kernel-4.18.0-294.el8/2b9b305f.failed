bpf: Fix build on architectures with special bpf_user_pt_regs_t

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Song Liu <songliubraving@fb.com>
commit 2b9b305fcdda1810bdffeb599361174eb2cd0b7c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/2b9b305f.failed

Architectures like s390, powerpc, arm64, riscv have speical definition of
bpf_user_pt_regs_t. So we need to cast the pointer before passing it to
bpf_get_stack(). This is similar to bpf_get_stack_tp().

Fixes: 03d42fd2d83f ("bpf: Separate bpf_get_[stack|stackid] for perf events BPF")
	Reported-by: kernel test robot <lkp@intel.com>
	Signed-off-by: Song Liu <songliubraving@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20200724200503.3629591-1-songliubraving@fb.com
(cherry picked from commit 2b9b305fcdda1810bdffeb599361174eb2cd0b7c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/stackmap.c
diff --cc kernel/bpf/stackmap.c
index 4153fd4ee538,4fd830a62be2..000000000000
--- a/kernel/bpf/stackmap.c
+++ b/kernel/bpf/stackmap.c
@@@ -525,6 -653,91 +525,94 @@@ const struct bpf_func_proto bpf_get_sta
  	.arg4_type	= ARG_ANYTHING,
  };
  
++<<<<<<< HEAD
++=======
+ BPF_CALL_4(bpf_get_task_stack, struct task_struct *, task, void *, buf,
+ 	   u32, size, u64, flags)
+ {
+ 	struct pt_regs *regs = task_pt_regs(task);
+ 
+ 	return __bpf_get_stack(regs, task, NULL, buf, size, flags);
+ }
+ 
+ BTF_ID_LIST(bpf_get_task_stack_btf_ids)
+ BTF_ID(struct, task_struct)
+ 
+ const struct bpf_func_proto bpf_get_task_stack_proto = {
+ 	.func		= bpf_get_task_stack,
+ 	.gpl_only	= false,
+ 	.ret_type	= RET_INTEGER,
+ 	.arg1_type	= ARG_PTR_TO_BTF_ID,
+ 	.arg2_type	= ARG_PTR_TO_UNINIT_MEM,
+ 	.arg3_type	= ARG_CONST_SIZE_OR_ZERO,
+ 	.arg4_type	= ARG_ANYTHING,
+ 	.btf_id		= bpf_get_task_stack_btf_ids,
+ };
+ 
+ BPF_CALL_4(bpf_get_stack_pe, struct bpf_perf_event_data_kern *, ctx,
+ 	   void *, buf, u32, size, u64, flags)
+ {
+ 	struct pt_regs *regs = (struct pt_regs *)(ctx->regs);
+ 	struct perf_event *event = ctx->event;
+ 	struct perf_callchain_entry *trace;
+ 	bool kernel, user;
+ 	int err = -EINVAL;
+ 	__u64 nr_kernel;
+ 
+ 	if (!(event->attr.sample_type & __PERF_SAMPLE_CALLCHAIN_EARLY))
+ 		return __bpf_get_stack(regs, NULL, NULL, buf, size, flags);
+ 
+ 	if (unlikely(flags & ~(BPF_F_SKIP_FIELD_MASK | BPF_F_USER_STACK |
+ 			       BPF_F_USER_BUILD_ID)))
+ 		goto clear;
+ 
+ 	user = flags & BPF_F_USER_STACK;
+ 	kernel = !user;
+ 
+ 	err = -EFAULT;
+ 	trace = ctx->data->callchain;
+ 	if (unlikely(!trace))
+ 		goto clear;
+ 
+ 	nr_kernel = count_kernel_ip(trace);
+ 
+ 	if (kernel) {
+ 		__u64 nr = trace->nr;
+ 
+ 		trace->nr = nr_kernel;
+ 		err = __bpf_get_stack(regs, NULL, trace, buf, size, flags);
+ 
+ 		/* restore nr */
+ 		trace->nr = nr;
+ 	} else { /* user */
+ 		u64 skip = flags & BPF_F_SKIP_FIELD_MASK;
+ 
+ 		skip += nr_kernel;
+ 		if (skip > BPF_F_SKIP_FIELD_MASK)
+ 			goto clear;
+ 
+ 		flags = (flags & ~BPF_F_SKIP_FIELD_MASK) | skip;
+ 		err = __bpf_get_stack(regs, NULL, trace, buf, size, flags);
+ 	}
+ 	return err;
+ 
+ clear:
+ 	memset(buf, 0, size);
+ 	return err;
+ 
+ }
+ 
+ const struct bpf_func_proto bpf_get_stack_proto_pe = {
+ 	.func		= bpf_get_stack_pe,
+ 	.gpl_only	= true,
+ 	.ret_type	= RET_INTEGER,
+ 	.arg1_type	= ARG_PTR_TO_CTX,
+ 	.arg2_type	= ARG_PTR_TO_UNINIT_MEM,
+ 	.arg3_type	= ARG_CONST_SIZE_OR_ZERO,
+ 	.arg4_type	= ARG_ANYTHING,
+ };
+ 
++>>>>>>> 2b9b305fcdda (bpf: Fix build on architectures with special bpf_user_pt_regs_t)
  /* Called from eBPF program */
  static void *stack_map_lookup_elem(struct bpf_map *map, void *key)
  {
* Unmerged path kernel/bpf/stackmap.c
