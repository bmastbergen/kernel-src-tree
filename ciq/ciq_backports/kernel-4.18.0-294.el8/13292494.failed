tracing: Make struct ring_buffer less ambiguous

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Steven Rostedt (VMware) <rostedt@goodmis.org>
commit 13292494379f92f532de71b31a54018336adc589
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/13292494.failed

As there's two struct ring_buffers in the kernel, it causes some confusion.
The other one being the perf ring buffer. It was agreed upon that as neither
of the ring buffers are generic enough to be used globally, they should be
renamed as:

   perf's ring_buffer -> perf_buffer
   ftrace's ring_buffer -> trace_buffer

This implements the changes to the ring buffer that ftrace uses.

Link: https://lore.kernel.org/r/20191213140531.116b3200@gandalf.local.home

	Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
(cherry picked from commit 13292494379f92f532de71b31a54018336adc589)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/ring_buffer.h
#	kernel/trace/ring_buffer.c
#	kernel/trace/trace.c
#	kernel/trace/trace.h
#	kernel/trace/trace_functions_graph.c
#	kernel/trace/trace_hwlat.c
#	kernel/trace/trace_mmiotrace.c
#	kernel/trace/trace_sched_wakeup.c
diff --cc include/linux/ring_buffer.h
index 003d09ab308d,df0124eabece..000000000000
--- a/include/linux/ring_buffer.h
+++ b/include/linux/ring_buffer.h
@@@ -97,8 -97,8 +97,13 @@@ __ring_buffer_alloc(unsigned long size
  	__ring_buffer_alloc((size), (flags), &__key);	\
  })
  
++<<<<<<< HEAD
 +int ring_buffer_wait(struct ring_buffer *buffer, int cpu, bool full);
 +__poll_t ring_buffer_poll_wait(struct ring_buffer *buffer, int cpu,
++=======
+ int ring_buffer_wait(struct trace_buffer *buffer, int cpu, int full);
+ __poll_t ring_buffer_poll_wait(struct trace_buffer *buffer, int cpu,
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  			  struct file *filp, poll_table *poll_table);
  
  
@@@ -128,7 -128,7 +133,11 @@@ ring_buffer_consume(struct trace_buffe
  		    unsigned long *lost_events);
  
  struct ring_buffer_iter *
++<<<<<<< HEAD
 +ring_buffer_read_prepare(struct ring_buffer *buffer, int cpu);
++=======
+ ring_buffer_read_prepare(struct trace_buffer *buffer, int cpu, gfp_t flags);
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  void ring_buffer_read_prepare_sync(void);
  void ring_buffer_read_start(struct ring_buffer_iter *iter);
  void ring_buffer_read_finish(struct ring_buffer_iter *iter);
@@@ -157,42 -157,42 +166,58 @@@ ring_buffer_swap_cpu(struct trace_buffe
  }
  #endif
  
- bool ring_buffer_empty(struct ring_buffer *buffer);
- bool ring_buffer_empty_cpu(struct ring_buffer *buffer, int cpu);
+ bool ring_buffer_empty(struct trace_buffer *buffer);
+ bool ring_buffer_empty_cpu(struct trace_buffer *buffer, int cpu);
  
++<<<<<<< HEAD
 +void ring_buffer_record_disable(struct ring_buffer *buffer);
 +void ring_buffer_record_enable(struct ring_buffer *buffer);
 +void ring_buffer_record_off(struct ring_buffer *buffer);
 +void ring_buffer_record_on(struct ring_buffer *buffer);
 +int ring_buffer_record_is_on(struct ring_buffer *buffer);
 +int ring_buffer_record_is_set_on(struct ring_buffer *buffer);
 +void ring_buffer_record_disable_cpu(struct ring_buffer *buffer, int cpu);
 +void ring_buffer_record_enable_cpu(struct ring_buffer *buffer, int cpu);
- 
- u64 ring_buffer_oldest_event_ts(struct ring_buffer *buffer, int cpu);
- unsigned long ring_buffer_bytes_cpu(struct ring_buffer *buffer, int cpu);
- unsigned long ring_buffer_entries(struct ring_buffer *buffer);
- unsigned long ring_buffer_overruns(struct ring_buffer *buffer);
- unsigned long ring_buffer_entries_cpu(struct ring_buffer *buffer, int cpu);
- unsigned long ring_buffer_overrun_cpu(struct ring_buffer *buffer, int cpu);
- unsigned long ring_buffer_commit_overrun_cpu(struct ring_buffer *buffer, int cpu);
- unsigned long ring_buffer_dropped_events_cpu(struct ring_buffer *buffer, int cpu);
- unsigned long ring_buffer_read_events_cpu(struct ring_buffer *buffer, int cpu);
- 
- u64 ring_buffer_time_stamp(struct ring_buffer *buffer, int cpu);
- void ring_buffer_normalize_time_stamp(struct ring_buffer *buffer,
++=======
+ void ring_buffer_record_disable(struct trace_buffer *buffer);
+ void ring_buffer_record_enable(struct trace_buffer *buffer);
+ void ring_buffer_record_off(struct trace_buffer *buffer);
+ void ring_buffer_record_on(struct trace_buffer *buffer);
+ bool ring_buffer_record_is_on(struct trace_buffer *buffer);
+ bool ring_buffer_record_is_set_on(struct trace_buffer *buffer);
+ void ring_buffer_record_disable_cpu(struct trace_buffer *buffer, int cpu);
+ void ring_buffer_record_enable_cpu(struct trace_buffer *buffer, int cpu);
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
+ 
+ u64 ring_buffer_oldest_event_ts(struct trace_buffer *buffer, int cpu);
+ unsigned long ring_buffer_bytes_cpu(struct trace_buffer *buffer, int cpu);
+ unsigned long ring_buffer_entries(struct trace_buffer *buffer);
+ unsigned long ring_buffer_overruns(struct trace_buffer *buffer);
+ unsigned long ring_buffer_entries_cpu(struct trace_buffer *buffer, int cpu);
+ unsigned long ring_buffer_overrun_cpu(struct trace_buffer *buffer, int cpu);
+ unsigned long ring_buffer_commit_overrun_cpu(struct trace_buffer *buffer, int cpu);
+ unsigned long ring_buffer_dropped_events_cpu(struct trace_buffer *buffer, int cpu);
+ unsigned long ring_buffer_read_events_cpu(struct trace_buffer *buffer, int cpu);
+ 
+ u64 ring_buffer_time_stamp(struct trace_buffer *buffer, int cpu);
+ void ring_buffer_normalize_time_stamp(struct trace_buffer *buffer,
  				      int cpu, u64 *ts);
- void ring_buffer_set_clock(struct ring_buffer *buffer,
+ void ring_buffer_set_clock(struct trace_buffer *buffer,
  			   u64 (*clock)(void));
- void ring_buffer_set_time_stamp_abs(struct ring_buffer *buffer, bool abs);
- bool ring_buffer_time_stamp_abs(struct ring_buffer *buffer);
+ void ring_buffer_set_time_stamp_abs(struct trace_buffer *buffer, bool abs);
+ bool ring_buffer_time_stamp_abs(struct trace_buffer *buffer);
  
++<<<<<<< HEAD
 +size_t ring_buffer_page_len(void *page);
 +
++=======
+ size_t ring_buffer_nr_pages(struct trace_buffer *buffer, int cpu);
+ size_t ring_buffer_nr_dirty_pages(struct trace_buffer *buffer, int cpu);
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  
- void *ring_buffer_alloc_read_page(struct ring_buffer *buffer, int cpu);
- void ring_buffer_free_read_page(struct ring_buffer *buffer, int cpu, void *data);
- int ring_buffer_read_page(struct ring_buffer *buffer, void **data_page,
+ void *ring_buffer_alloc_read_page(struct trace_buffer *buffer, int cpu);
+ void ring_buffer_free_read_page(struct trace_buffer *buffer, int cpu, void *data);
+ int ring_buffer_read_page(struct trace_buffer *buffer, void **data_page,
  			  size_t len, int cpu, int full);
  
  struct trace_seq;
diff --cc kernel/trace/ring_buffer.c
index d7a0b16ec1fc,f846de2aa435..000000000000
--- a/kernel/trace/ring_buffer.c
+++ b/kernel/trace/ring_buffer.c
@@@ -528,6 -511,41 +528,44 @@@ struct ring_buffer_iter 
  	u64				read_stamp;
  };
  
++<<<<<<< HEAD
++=======
+ /**
+  * ring_buffer_nr_pages - get the number of buffer pages in the ring buffer
+  * @buffer: The ring_buffer to get the number of pages from
+  * @cpu: The cpu of the ring_buffer to get the number of pages from
+  *
+  * Returns the number of pages used by a per_cpu buffer of the ring buffer.
+  */
+ size_t ring_buffer_nr_pages(struct trace_buffer *buffer, int cpu)
+ {
+ 	return buffer->buffers[cpu]->nr_pages;
+ }
+ 
+ /**
+  * ring_buffer_nr_pages_dirty - get the number of used pages in the ring buffer
+  * @buffer: The ring_buffer to get the number of pages from
+  * @cpu: The cpu of the ring_buffer to get the number of pages from
+  *
+  * Returns the number of pages that have content in the ring buffer.
+  */
+ size_t ring_buffer_nr_dirty_pages(struct trace_buffer *buffer, int cpu)
+ {
+ 	size_t read;
+ 	size_t cnt;
+ 
+ 	read = local_read(&buffer->buffers[cpu]->pages_read);
+ 	cnt = local_read(&buffer->buffers[cpu]->pages_touched);
+ 	/* The reader can read an empty page, but not more than that */
+ 	if (cnt < read) {
+ 		WARN_ON_ONCE(read > cnt + 1);
+ 		return 0;
+ 	}
+ 
+ 	return cnt - read;
+ }
+ 
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  /*
   * rb_wake_up_waiters - wake up tasks waiting for ring buffer input
   *
@@@ -555,7 -573,7 +593,11 @@@ static void rb_wake_up_waiters(struct i
   * as data is added to any of the @buffer's cpu buffers. Otherwise
   * it will wait for data to be added to a specific cpu buffer.
   */
++<<<<<<< HEAD
 +int ring_buffer_wait(struct ring_buffer *buffer, int cpu, bool full)
++=======
+ int ring_buffer_wait(struct trace_buffer *buffer, int cpu, int full)
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  {
  	struct ring_buffer_per_cpu *uninitialized_var(cpu_buffer);
  	DEFINE_WAIT(wait);
@@@ -2581,9 -2609,11 +2623,9 @@@ static void rb_commit(struct ring_buffe
  }
  
  static __always_inline void
- rb_wakeups(struct ring_buffer *buffer, struct ring_buffer_per_cpu *cpu_buffer)
+ rb_wakeups(struct trace_buffer *buffer, struct ring_buffer_per_cpu *cpu_buffer)
  {
 -	size_t nr_pages;
 -	size_t dirty;
 -	size_t full;
 +	bool pagebusy;
  
  	if (buffer->irq_work.waiters_pending) {
  		buffer->irq_work.waiters_pending = false;
@@@ -3221,7 -3264,7 +3263,11 @@@ EXPORT_SYMBOL_GPL(ring_buffer_record_on
   *
   * Returns true if the ring buffer is in a state that it accepts writes.
   */
++<<<<<<< HEAD
 +int ring_buffer_record_is_on(struct ring_buffer *buffer)
++=======
+ bool ring_buffer_record_is_on(struct trace_buffer *buffer)
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  {
  	return !atomic_read(&buffer->record_disabled);
  }
@@@ -3237,7 -3280,7 +3283,11 @@@
   * ring_buffer_record_disable(), as that is a temporary disabling of
   * the ring buffer.
   */
++<<<<<<< HEAD
 +int ring_buffer_record_is_set_on(struct ring_buffer *buffer)
++=======
+ bool ring_buffer_record_is_set_on(struct trace_buffer *buffer)
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  {
  	return !(atomic_read(&buffer->record_disabled) & RB_BUFFER_OFF);
  }
@@@ -4155,7 -4201,7 +4205,11 @@@ EXPORT_SYMBOL_GPL(ring_buffer_consume)
   * This overall must be paired with ring_buffer_read_finish.
   */
  struct ring_buffer_iter *
++<<<<<<< HEAD
 +ring_buffer_read_prepare(struct ring_buffer *buffer, int cpu)
++=======
+ ring_buffer_read_prepare(struct trace_buffer *buffer, int cpu, gfp_t flags)
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  {
  	struct ring_buffer_per_cpu *cpu_buffer;
  	struct ring_buffer_iter *iter;
diff --cc kernel/trace/trace.c
index db7e8ffb4c4e,b4a07d7ed82a..000000000000
--- a/kernel/trace/trace.c
+++ b/kernel/trace/trace.c
@@@ -302,9 -318,27 +302,9 @@@ void trace_array_put(struct trace_arra
  	__trace_array_put(this_tr);
  	mutex_unlock(&trace_types_lock);
  }
 -EXPORT_SYMBOL_GPL(trace_array_put);
 -
 -int tracing_check_open_get_tr(struct trace_array *tr)
 -{
 -	int ret;
 -
 -	ret = security_locked_down(LOCKDOWN_TRACEFS);
 -	if (ret)
 -		return ret;
 -
 -	if (tracing_disabled)
 -		return -ENODEV;
 -
 -	if (tr && trace_array_get(tr) < 0)
 -		return -ENODEV;
 -
 -	return 0;
 -}
  
  int call_filter_check_discard(struct trace_event_call *call, void *rec,
- 			      struct ring_buffer *buffer,
+ 			      struct trace_buffer *buffer,
  			      struct ring_buffer_event *event)
  {
  	if (unlikely(call->flags & TRACE_EVENT_FL_FILTERED) &&
@@@ -1672,9 -1962,9 +1672,9 @@@ int __init register_tracer(struct trace
  	return ret;
  }
  
 -static void tracing_reset_cpu(struct array_buffer *buf, int cpu)
 +void tracing_reset(struct trace_buffer *buf, int cpu)
  {
- 	struct ring_buffer *buffer = buf->buffer;
+ 	struct trace_buffer *buffer = buf->buffer;
  
  	if (!buffer)
  		return;
@@@ -1688,9 -1978,9 +1688,9 @@@
  	ring_buffer_record_enable(buffer);
  }
  
 -void tracing_reset_online_cpus(struct array_buffer *buf)
 +void tracing_reset_online_cpus(struct trace_buffer *buf)
  {
- 	struct ring_buffer *buffer = buf->buffer;
+ 	struct trace_buffer *buffer = buf->buffer;
  	int cpu;
  
  	if (!buffer)
@@@ -2554,7 -2845,7 +2554,11 @@@ trace_function(struct trace_array *tr
  	       int pc)
  {
  	struct trace_event_call *call = &event_function;
++<<<<<<< HEAD
 +	struct ring_buffer *buffer = tr->trace_buffer.buffer;
++=======
+ 	struct trace_buffer *buffer = tr->array_buffer.buffer;
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  	struct ring_buffer_event *event;
  	struct ftrace_entry *entry;
  
@@@ -2680,7 -2971,7 +2684,11 @@@ static inline void ftrace_trace_stack(s
  void __trace_stack(struct trace_array *tr, unsigned long flags, int skip,
  		   int pc)
  {
++<<<<<<< HEAD
 +	struct ring_buffer *buffer = tr->trace_buffer.buffer;
++=======
+ 	struct trace_buffer *buffer = tr->array_buffer.buffer;
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  
  	if (rcu_is_watching()) {
  		__ftrace_trace_stack(buffer, flags, skip, pc, NULL);
@@@ -3026,9 -3323,10 +3034,9 @@@ int trace_array_printk(struct trace_arr
  	va_end(ap);
  	return ret;
  }
 -EXPORT_SYMBOL_GPL(trace_array_printk);
  
  __printf(3, 4)
- int trace_array_printk_buf(struct ring_buffer *buffer,
+ int trace_array_printk_buf(struct trace_buffer *buffer,
  			   unsigned long ip, const char *fmt, ...)
  {
  	int ret;
@@@ -3084,7 -3382,7 +3092,11 @@@ static struct trace_entry 
  __find_next_entry(struct trace_iterator *iter, int *ent_cpu,
  		  unsigned long *missing_events, u64 *ent_ts)
  {
++<<<<<<< HEAD
 +	struct ring_buffer *buffer = iter->trace_buffer->buffer;
++=======
+ 	struct trace_buffer *buffer = iter->array_buffer->buffer;
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  	struct trace_entry *ent, *next = NULL;
  	unsigned long lost_events = 0, next_lost = 0;
  	int cpu_file = iter->cpu_file;
@@@ -6069,10 -6470,9 +6081,10 @@@ tracing_mark_write(struct file *filp, c
  	struct trace_array *tr = filp->private_data;
  	struct ring_buffer_event *event;
  	enum event_trigger_type tt = ETT_NONE;
- 	struct ring_buffer *buffer;
+ 	struct trace_buffer *buffer;
  	struct print_entry *entry;
  	unsigned long irq_flags;
 +	const char faulted[] = "<faulted>";
  	ssize_t written;
  	int size;
  	int len;
@@@ -6149,9 -6550,8 +6161,9 @@@ tracing_mark_raw_write(struct file *fil
  {
  	struct trace_array *tr = filp->private_data;
  	struct ring_buffer_event *event;
- 	struct ring_buffer *buffer;
+ 	struct trace_buffer *buffer;
  	struct raw_data_entry *entry;
 +	const char faulted[] = "<faulted>";
  	unsigned long irq_flags;
  	ssize_t written;
  	int size;
@@@ -6783,12 -7433,20 +6795,12 @@@ static int tracing_buffers_release(stru
  }
  
  struct buffer_ref {
- 	struct ring_buffer	*buffer;
+ 	struct trace_buffer	*buffer;
  	void			*page;
  	int			cpu;
 -	refcount_t		refcount;
 +	int			ref;
  };
  
 -static void buffer_ref_release(struct buffer_ref *ref)
 -{
 -	if (!refcount_dec_and_test(&ref->refcount))
 -		return;
 -	ring_buffer_free_read_page(ref->buffer, ref->cpu, ref->page);
 -	kfree(ref);
 -}
 -
  static void buffer_pipe_buf_release(struct pipe_inode_info *pipe,
  				    struct pipe_buffer *buf)
  {
@@@ -7621,7 -8272,7 +7633,11 @@@ rb_simple_write(struct file *filp, cons
  		size_t cnt, loff_t *ppos)
  {
  	struct trace_array *tr = filp->private_data;
++<<<<<<< HEAD
 +	struct ring_buffer *buffer = tr->trace_buffer.buffer;
++=======
+ 	struct trace_buffer *buffer = tr->array_buffer.buffer;
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  	unsigned long val;
  	int ret;
  
diff --cc kernel/trace/trace.h
index ac5533d9bbcd,4812a36affac..000000000000
--- a/kernel/trace/trace.h
+++ b/kernel/trace/trace.h
@@@ -174,9 -176,9 +174,9 @@@ struct trace_array_cpu 
  struct tracer;
  struct trace_option_dentry;
  
 -struct array_buffer {
 +struct trace_buffer {
  	struct trace_array		*tr;
- 	struct ring_buffer		*buffer;
+ 	struct trace_buffer		*buffer;
  	struct trace_array_cpu __percpu	*data;
  	u64				time_start;
  	int				cpu;
@@@ -761,9 -873,7 +761,13 @@@ trace_vprintk(unsigned long ip, const c
  extern int
  trace_array_vprintk(struct trace_array *tr,
  		    unsigned long ip, const char *fmt, va_list args);
++<<<<<<< HEAD
 +int trace_array_printk(struct trace_array *tr,
 +		       unsigned long ip, const char *fmt, ...);
 +int trace_array_printk_buf(struct ring_buffer *buffer,
++=======
+ int trace_array_printk_buf(struct trace_buffer *buffer,
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  			   unsigned long ip, const char *fmt, ...);
  void trace_printk_seq(struct trace_seq *s);
  enum print_line_t print_trace_line(struct trace_iterator *iter);
diff --cc kernel/trace/trace_functions_graph.c
index 603d5b957c73,7d71546ba00a..000000000000
--- a/kernel/trace/trace_functions_graph.c
+++ b/kernel/trace/trace_functions_graph.c
@@@ -388,7 -101,7 +388,11 @@@ int __trace_graph_entry(struct trace_ar
  {
  	struct trace_event_call *call = &event_funcgraph_entry;
  	struct ring_buffer_event *event;
++<<<<<<< HEAD
 +	struct ring_buffer *buffer = tr->trace_buffer.buffer;
++=======
+ 	struct trace_buffer *buffer = tr->array_buffer.buffer;
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  	struct ftrace_graph_ent_entry *entry;
  
  	event = trace_buffer_lock_reserve(buffer, TRACE_GRAPH_ENT,
@@@ -499,7 -221,7 +503,11 @@@ void __trace_graph_return(struct trace_
  {
  	struct trace_event_call *call = &event_funcgraph_exit;
  	struct ring_buffer_event *event;
++<<<<<<< HEAD
 +	struct ring_buffer *buffer = tr->trace_buffer.buffer;
++=======
+ 	struct trace_buffer *buffer = tr->array_buffer.buffer;
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  	struct ftrace_graph_ret_entry *entry;
  
  	event = trace_buffer_lock_reserve(buffer, TRACE_GRAPH_RET,
diff --cc kernel/trace/trace_hwlat.c
index bccff460cd35,b44446bf0872..000000000000
--- a/kernel/trace/trace_hwlat.c
+++ b/kernel/trace/trace_hwlat.c
@@@ -106,7 -104,7 +106,11 @@@ static void trace_hwlat_sample(struct h
  {
  	struct trace_array *tr = hwlat_trace;
  	struct trace_event_call *call = &event_hwlat;
++<<<<<<< HEAD
 +	struct ring_buffer *buffer = tr->trace_buffer.buffer;
++=======
+ 	struct trace_buffer *buffer = tr->array_buffer.buffer;
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  	struct ring_buffer_event *event;
  	struct hwlat_entry *entry;
  	unsigned long flags;
diff --cc kernel/trace/trace_mmiotrace.c
index b0388016b687,84582bf1ed5f..000000000000
--- a/kernel/trace/trace_mmiotrace.c
+++ b/kernel/trace/trace_mmiotrace.c
@@@ -297,7 -297,7 +297,11 @@@ static void __trace_mmiotrace_rw(struc
  				struct mmiotrace_rw *rw)
  {
  	struct trace_event_call *call = &event_mmiotrace_rw;
++<<<<<<< HEAD
 +	struct ring_buffer *buffer = tr->trace_buffer.buffer;
++=======
+ 	struct trace_buffer *buffer = tr->array_buffer.buffer;
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  	struct ring_buffer_event *event;
  	struct trace_mmiotrace_rw *entry;
  	int pc = preempt_count();
@@@ -327,7 -327,7 +331,11 @@@ static void __trace_mmiotrace_map(struc
  				struct mmiotrace_map *map)
  {
  	struct trace_event_call *call = &event_mmiotrace_map;
++<<<<<<< HEAD
 +	struct ring_buffer *buffer = tr->trace_buffer.buffer;
++=======
+ 	struct trace_buffer *buffer = tr->array_buffer.buffer;
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  	struct ring_buffer_event *event;
  	struct trace_mmiotrace_map *entry;
  	int pc = preempt_count();
diff --cc kernel/trace/trace_sched_wakeup.c
index 98425ce52340,97b10bb31a1f..000000000000
--- a/kernel/trace/trace_sched_wakeup.c
+++ b/kernel/trace/trace_sched_wakeup.c
@@@ -387,7 -378,7 +387,11 @@@ tracing_sched_switch_trace(struct trace
  			   unsigned long flags, int pc)
  {
  	struct trace_event_call *call = &event_context_switch;
++<<<<<<< HEAD
 +	struct ring_buffer *buffer = tr->trace_buffer.buffer;
++=======
+ 	struct trace_buffer *buffer = tr->array_buffer.buffer;
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  	struct ring_buffer_event *event;
  	struct ctx_switch_entry *entry;
  
@@@ -417,7 -408,7 +421,11 @@@ tracing_sched_wakeup_trace(struct trace
  	struct trace_event_call *call = &event_wakeup;
  	struct ring_buffer_event *event;
  	struct ctx_switch_entry *entry;
++<<<<<<< HEAD
 +	struct ring_buffer *buffer = tr->trace_buffer.buffer;
++=======
+ 	struct trace_buffer *buffer = tr->array_buffer.buffer;
++>>>>>>> 13292494379f (tracing: Make struct ring_buffer less ambiguous)
  
  	event = trace_buffer_lock_reserve(buffer, TRACE_WAKE,
  					  sizeof(*entry), flags, pc);
diff --git a/drivers/oprofile/cpu_buffer.c b/drivers/oprofile/cpu_buffer.c
index eda2633a393d..9210a95cb4e6 100644
--- a/drivers/oprofile/cpu_buffer.c
+++ b/drivers/oprofile/cpu_buffer.c
@@ -32,7 +32,7 @@
 
 #define OP_BUFFER_FLAGS	0
 
-static struct ring_buffer *op_ring_buffer;
+static struct trace_buffer *op_ring_buffer;
 DEFINE_PER_CPU(struct oprofile_cpu_buffer, op_cpu_buffer);
 
 static void wq_sync_buffer(struct work_struct *work);
* Unmerged path include/linux/ring_buffer.h
diff --git a/include/linux/trace_events.h b/include/linux/trace_events.h
index eeeb0ae86109..8ddb5d47f31a 100644
--- a/include/linux/trace_events.h
+++ b/include/linux/trace_events.h
@@ -147,7 +147,7 @@ void tracing_generic_entry_update(struct trace_entry *entry,
 struct trace_event_file;
 
 struct ring_buffer_event *
-trace_event_buffer_lock_reserve(struct ring_buffer **current_buffer,
+trace_event_buffer_lock_reserve(struct trace_buffer **current_buffer,
 				struct trace_event_file *trace_file,
 				int type, unsigned long len,
 				unsigned long flags, int pc);
@@ -204,7 +204,7 @@ extern int trace_event_reg(struct trace_event_call *event,
 			    enum trace_reg type, void *data);
 
 struct trace_event_buffer {
-	struct ring_buffer		*buffer;
+	struct trace_buffer		*buffer;
 	struct ring_buffer_event	*event;
 	struct trace_event_file		*trace_file;
 	void				*entry;
diff --git a/include/trace/trace_events.h b/include/trace/trace_events.h
index 4ecdfe2e3580..2d7957519ad3 100644
--- a/include/trace/trace_events.h
+++ b/include/trace/trace_events.h
@@ -564,7 +564,7 @@ static inline notrace int trace_event_get_offsets_##call(		\
  *	enum event_trigger_type __tt = ETT_NONE;
  *	struct ring_buffer_event *event;
  *	struct trace_event_raw_<call> *entry; <-- defined in stage 1
- *	struct ring_buffer *buffer;
+ *	struct trace_buffer *buffer;
  *	unsigned long irq_flags;
  *	int __data_size;
  *	int pc;
diff --git a/kernel/trace/blktrace.c b/kernel/trace/blktrace.c
index c53b2838dac9..5b30a24837ee 100644
--- a/kernel/trace/blktrace.c
+++ b/kernel/trace/blktrace.c
@@ -84,7 +84,7 @@ static void trace_note(struct blk_trace *bt, pid_t pid, int action,
 {
 	struct blk_io_trace *t;
 	struct ring_buffer_event *event = NULL;
-	struct ring_buffer *buffer = NULL;
+	struct trace_buffer *buffer = NULL;
 	int pc = 0;
 	int cpu = smp_processor_id();
 	bool blk_tracer = blk_tracer_enabled;
@@ -231,7 +231,7 @@ static void __blk_add_trace(struct blk_trace *bt, sector_t sector, int bytes,
 {
 	struct task_struct *tsk = current;
 	struct ring_buffer_event *event = NULL;
-	struct ring_buffer *buffer = NULL;
+	struct trace_buffer *buffer = NULL;
 	struct blk_io_trace *t;
 	unsigned long flags = 0;
 	unsigned long *sequence;
* Unmerged path kernel/trace/ring_buffer.c
diff --git a/kernel/trace/ring_buffer_benchmark.c b/kernel/trace/ring_buffer_benchmark.c
index 04edbf11e081..bdfbcbd430de 100644
--- a/kernel/trace/ring_buffer_benchmark.c
+++ b/kernel/trace/ring_buffer_benchmark.c
@@ -28,7 +28,7 @@ static int reader_finish;
 static DECLARE_COMPLETION(read_start);
 static DECLARE_COMPLETION(read_done);
 
-static struct ring_buffer *buffer;
+static struct trace_buffer *buffer;
 static struct task_struct *producer;
 static struct task_struct *consumer;
 static unsigned long read;
* Unmerged path kernel/trace/trace.c
* Unmerged path kernel/trace/trace.h
diff --git a/kernel/trace/trace_branch.c b/kernel/trace/trace_branch.c
index 4ad967453b6f..07eb02a30b8c 100644
--- a/kernel/trace/trace_branch.c
+++ b/kernel/trace/trace_branch.c
@@ -32,10 +32,10 @@ probe_likely_condition(struct ftrace_likely_data *f, int val, int expect)
 {
 	struct trace_event_call *call = &event_branch;
 	struct trace_array *tr = branch_tracer;
+	struct trace_buffer *buffer;
 	struct trace_array_cpu *data;
 	struct ring_buffer_event *event;
 	struct trace_branch *entry;
-	struct ring_buffer *buffer;
 	unsigned long flags;
 	int pc;
 	const char *p;
diff --git a/kernel/trace/trace_events.c b/kernel/trace/trace_events.c
index 7e052a5fce39..180d5b1d8eab 100644
--- a/kernel/trace/trace_events.c
+++ b/kernel/trace/trace_events.c
@@ -3368,8 +3368,8 @@ static void __init
 function_test_events_call(unsigned long ip, unsigned long parent_ip,
 			  struct ftrace_ops *op, struct pt_regs *pt_regs)
 {
+	struct trace_buffer *buffer;
 	struct ring_buffer_event *event;
-	struct ring_buffer *buffer;
 	struct ftrace_entry *entry;
 	unsigned long flags;
 	long disabled;
diff --git a/kernel/trace/trace_events_hist.c b/kernel/trace/trace_events_hist.c
index 735725777f88..bc11b63d45f9 100644
--- a/kernel/trace/trace_events_hist.c
+++ b/kernel/trace/trace_events_hist.c
@@ -640,7 +640,7 @@ static notrace void trace_event_raw_event_synth(void *__data,
 	struct trace_event_file *trace_file = __data;
 	struct synth_trace_event *entry;
 	struct trace_event_buffer fbuffer;
-	struct ring_buffer *buffer;
+	struct trace_buffer *buffer;
 	struct synth_event *event;
 	unsigned int i, n_u64;
 	int fields_size = 0;
* Unmerged path kernel/trace/trace_functions_graph.c
* Unmerged path kernel/trace/trace_hwlat.c
diff --git a/kernel/trace/trace_kprobe.c b/kernel/trace/trace_kprobe.c
index c07219273664..caa8f0e5fcb6 100644
--- a/kernel/trace/trace_kprobe.c
+++ b/kernel/trace/trace_kprobe.c
@@ -1000,8 +1000,8 @@ __kprobe_trace_func(struct trace_kprobe *tk, struct pt_regs *regs,
 		    struct trace_event_file *trace_file)
 {
 	struct kprobe_trace_entry_head *entry;
+	struct trace_buffer *buffer;
 	struct ring_buffer_event *event;
-	struct ring_buffer *buffer;
 	int size, dsize, pc;
 	unsigned long irq_flags;
 	struct trace_event_call *call = &tk->tp.call;
@@ -1048,8 +1048,8 @@ __kretprobe_trace_func(struct trace_kprobe *tk, struct kretprobe_instance *ri,
 		       struct trace_event_file *trace_file)
 {
 	struct kretprobe_trace_entry_head *entry;
+	struct trace_buffer *buffer;
 	struct ring_buffer_event *event;
-	struct ring_buffer *buffer;
 	int size, pc, dsize;
 	unsigned long irq_flags;
 	struct trace_event_call *call = &tk->tp.call;
* Unmerged path kernel/trace/trace_mmiotrace.c
* Unmerged path kernel/trace/trace_sched_wakeup.c
diff --git a/kernel/trace/trace_syscalls.c b/kernel/trace/trace_syscalls.c
index f93a56d2db27..59ea9cb6f445 100644
--- a/kernel/trace/trace_syscalls.c
+++ b/kernel/trace/trace_syscalls.c
@@ -312,7 +312,7 @@ static void ftrace_syscall_enter(void *data, struct pt_regs *regs, long id)
 	struct syscall_trace_enter *entry;
 	struct syscall_metadata *sys_data;
 	struct ring_buffer_event *event;
-	struct ring_buffer *buffer;
+	struct trace_buffer *buffer;
 	unsigned long irq_flags;
 	int pc;
 	int syscall_nr;
@@ -360,7 +360,7 @@ static void ftrace_syscall_exit(void *data, struct pt_regs *regs, long ret)
 	struct syscall_trace_exit *entry;
 	struct syscall_metadata *sys_data;
 	struct ring_buffer_event *event;
-	struct ring_buffer *buffer;
+	struct trace_buffer *buffer;
 	unsigned long irq_flags;
 	int pc;
 	int syscall_nr;
diff --git a/kernel/trace/trace_uprobe.c b/kernel/trace/trace_uprobe.c
index e0f7f3052702..336564c33d87 100644
--- a/kernel/trace/trace_uprobe.c
+++ b/kernel/trace/trace_uprobe.c
@@ -831,8 +831,8 @@ static void __uprobe_trace_func(struct trace_uprobe *tu,
 				struct trace_event_file *trace_file)
 {
 	struct uprobe_trace_entry_head *entry;
+	struct trace_buffer *buffer;
 	struct ring_buffer_event *event;
-	struct ring_buffer *buffer;
 	void *data;
 	int size, esize;
 	struct trace_event_call *call = &tu->tp.call;
