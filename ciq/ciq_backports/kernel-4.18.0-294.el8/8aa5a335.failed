xsk: Add new statistics

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Ciara Loftus <ciara.loftus@intel.com>
commit 8aa5a33578e9685d06020bd10d1637557423e945
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/8aa5a335.failed

It can be useful for the user to know the reason behind a dropped packet.
Introduce new counters which track drops on the receive path caused by:
1. rx ring being full
2. fill ring being empty

Also, on the tx path introduce a counter which tracks the number of times
we attempt pull from the tx ring when it is empty.

	Signed-off-by: Ciara Loftus <ciara.loftus@intel.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20200708072835.4427-2-ciara.loftus@intel.com
(cherry picked from commit 8aa5a33578e9685d06020bd10d1637557423e945)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/xdp/xsk.c
#	net/xdp/xsk_buff_pool.c
#	net/xdp/xsk_queue.h
diff --cc net/xdp/xsk.c
index 0bcdbfbd4030,26e3bba8c204..000000000000
--- a/net/xdp/xsk.c
+++ b/net/xdp/xsk.c
@@@ -119,25 -99,51 +119,58 @@@ bool xsk_umem_uses_need_wakeup(struct x
  }
  EXPORT_SYMBOL(xsk_umem_uses_need_wakeup);
  
 -void xp_release(struct xdp_buff_xsk *xskb)
 +/* If a buffer crosses a page boundary, we need to do 2 memcpy's, one for
 + * each page. This is only required in copy mode.
 + */
 +static void __xsk_rcv_memcpy(struct xdp_umem *umem, u64 addr, void *from_buf,
 +			     u32 len, u32 metalen)
  {
 -	xskb->pool->free_heads[xskb->pool->free_heads_cnt++] = xskb;
 -}
 +	void *to_buf = xdp_umem_get_data(umem, addr);
  
 -static u64 xp_get_handle(struct xdp_buff_xsk *xskb)
 -{
 -	u64 offset = xskb->xdp.data - xskb->xdp.data_hard_start;
 +	addr = xsk_umem_add_offset_to_addr(addr);
 +	if (xskq_cons_crosses_non_contig_pg(umem, addr, len + metalen)) {
 +		void *next_pg_addr = umem->pages[(addr >> PAGE_SHIFT) + 1].addr;
 +		u64 page_start = addr & ~(PAGE_SIZE - 1);
 +		u64 first_len = PAGE_SIZE - (addr - page_start);
  
 -	offset += xskb->pool->headroom;
 -	if (!xskb->pool->unaligned)
 -		return xskb->orig_addr + offset;
 -	return xskb->orig_addr + (offset << XSK_UNALIGNED_BUF_OFFSET_SHIFT);
 -}
 +		memcpy(to_buf, from_buf, first_len);
 +		memcpy(next_pg_addr, from_buf + first_len,
 +		       len + metalen - first_len);
  
++<<<<<<< HEAD
 +		return;
++=======
+ static int __xsk_rcv_zc(struct xdp_sock *xs, struct xdp_buff *xdp, u32 len)
+ {
+ 	struct xdp_buff_xsk *xskb = container_of(xdp, struct xdp_buff_xsk, xdp);
+ 	u64 addr;
+ 	int err;
+ 
+ 	addr = xp_get_handle(xskb);
+ 	err = xskq_prod_reserve_desc(xs->rx, addr, len);
+ 	if (err) {
+ 		xs->rx_queue_full++;
+ 		return err;
+ 	}
+ 
+ 	xp_release(xskb);
+ 	return 0;
+ }
+ 
+ static void xsk_copy_xdp(struct xdp_buff *to, struct xdp_buff *from, u32 len)
+ {
+ 	void *from_buf, *to_buf;
+ 	u32 metalen;
+ 
+ 	if (unlikely(xdp_data_meta_unsupported(from))) {
+ 		from_buf = from->data;
+ 		to_buf = to->data;
+ 		metalen = 0;
+ 	} else {
+ 		from_buf = from->data_meta;
+ 		metalen = from->data - from->data_meta;
+ 		to_buf = to->data - metalen;
++>>>>>>> 8aa5a33578e9 (xsk: Add new statistics)
  	}
  
  	memcpy(to_buf, from_buf, len + metalen);
diff --cc net/xdp/xsk_queue.h
index a322a7dac58c,bf42cfd74b89..000000000000
--- a/net/xdp/xsk_queue.h
+++ b/net/xdp/xsk_queue.h
@@@ -381,7 -355,11 +382,15 @@@ static inline u64 xskq_nb_invalid_descs
  	return q ? q->invalid_descs : 0;
  }
  
++<<<<<<< HEAD
 +void xskq_set_umem(struct xsk_queue *q, u64 umem_size, u64 chunk_mask);
++=======
+ static inline u64 xskq_nb_queue_empty_descs(struct xsk_queue *q)
+ {
+ 	return q ? q->queue_empty_descs : 0;
+ }
+ 
++>>>>>>> 8aa5a33578e9 (xsk: Add new statistics)
  struct xsk_queue *xskq_create(u32 nentries, bool umem_queue);
  void xskq_destroy(struct xsk_queue *q_ops);
  
* Unmerged path net/xdp/xsk_buff_pool.c
diff --git a/include/net/xdp_sock.h b/include/net/xdp_sock.h
index c57bb0fdba67..68bcac2b8b66 100644
--- a/include/net/xdp_sock.h
+++ b/include/net/xdp_sock.h
@@ -92,7 +92,11 @@ struct xdp_sock {
 	spinlock_t tx_completion_lock;
 	/* Protects generic receive. */
 	spinlock_t rx_lock;
+
+	/* Statistics */
 	u64 rx_dropped;
+	u64 rx_queue_full;
+
 	struct list_head map_list;
 	/* Protects map_list */
 	spinlock_t map_list_lock;
diff --git a/include/uapi/linux/if_xdp.h b/include/uapi/linux/if_xdp.h
index be328c59389d..a78a8096f4ce 100644
--- a/include/uapi/linux/if_xdp.h
+++ b/include/uapi/linux/if_xdp.h
@@ -73,9 +73,12 @@ struct xdp_umem_reg {
 };
 
 struct xdp_statistics {
-	__u64 rx_dropped; /* Dropped for reasons other than invalid desc */
+	__u64 rx_dropped; /* Dropped for other reasons */
 	__u64 rx_invalid_descs; /* Dropped due to invalid descriptor */
 	__u64 tx_invalid_descs; /* Dropped due to invalid descriptor */
+	__u64 rx_ring_full; /* Dropped due to rx ring being full */
+	__u64 rx_fill_ring_empty_descs; /* Failed to retrieve item from fill ring */
+	__u64 tx_ring_empty_descs; /* Failed to retrieve item from tx ring */
 };
 
 struct xdp_options {
* Unmerged path net/xdp/xsk.c
* Unmerged path net/xdp/xsk_buff_pool.c
* Unmerged path net/xdp/xsk_queue.h
diff --git a/tools/include/uapi/linux/if_xdp.h b/tools/include/uapi/linux/if_xdp.h
index be328c59389d..a78a8096f4ce 100644
--- a/tools/include/uapi/linux/if_xdp.h
+++ b/tools/include/uapi/linux/if_xdp.h
@@ -73,9 +73,12 @@ struct xdp_umem_reg {
 };
 
 struct xdp_statistics {
-	__u64 rx_dropped; /* Dropped for reasons other than invalid desc */
+	__u64 rx_dropped; /* Dropped for other reasons */
 	__u64 rx_invalid_descs; /* Dropped due to invalid descriptor */
 	__u64 tx_invalid_descs; /* Dropped due to invalid descriptor */
+	__u64 rx_ring_full; /* Dropped due to rx ring being full */
+	__u64 rx_fill_ring_empty_descs; /* Failed to retrieve item from fill ring */
+	__u64 tx_ring_empty_descs; /* Failed to retrieve item from tx ring */
 };
 
 struct xdp_options {
