x86/cpu_entry_area: Provide exception stack accessor

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 7623f37e411156e6e09b95cf5c76e509c5fda640
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/7623f37e.failed

Store a pointer to the per cpu entry area exception stack mappings to allow
fast retrieval.

Required for converting various places from using the shadow IST array to
directly doing address calculations on the actual mapping address.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Dave Hansen <dave.hansen@linux.intel.com>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: Josh Poimboeuf <jpoimboe@redhat.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Sean Christopherson <sean.j.christopherson@intel.com>
	Cc: x86-ml <x86@kernel.org>
Link: https://lkml.kernel.org/r/20190414160144.680960459@linutronix.de
(cherry picked from commit 7623f37e411156e6e09b95cf5c76e509c5fda640)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/mm/cpu_entry_area.c
diff --cc arch/x86/mm/cpu_entry_area.c
index 26fa2a5a8715,a00d0d059c8a..000000000000
--- a/arch/x86/mm/cpu_entry_area.c
+++ b/arch/x86/mm/cpu_entry_area.c
@@@ -13,8 -13,8 +13,13 @@@
  static DEFINE_PER_CPU_PAGE_ALIGNED(struct entry_stack_page, entry_stack_storage);
  
  #ifdef CONFIG_X86_64
++<<<<<<< HEAD
 +static DEFINE_PER_CPU_PAGE_ALIGNED(char, exception_stacks
 +	[(N_EXCEPTION_STACKS - 1) * EXCEPTION_STKSZ + DEBUG_STKSZ]);
++=======
+ static DEFINE_PER_CPU_PAGE_ALIGNED(struct exception_stacks, exception_stacks);
+ DEFINE_PER_CPU(struct cea_exception_stacks*, cea_exception_stacks);
++>>>>>>> 7623f37e4111 (x86/cpu_entry_area: Provide exception stack accessor)
  #endif
  
  struct cpu_entry_area *get_cpu_entry_area(int cpu)
@@@ -78,9 -78,41 +83,43 @@@ static void __init percpu_setup_debug_s
  #endif
  }
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_X86_64
+ 
+ #define cea_map_stack(name) do {					\
+ 	npages = sizeof(estacks->name## _stack) / PAGE_SIZE;		\
+ 	cea_map_percpu_pages(cea->estacks.name## _stack,		\
+ 			estacks->name## _stack, npages, PAGE_KERNEL);	\
+ 	} while (0)
+ 
+ static void __init percpu_setup_exception_stacks(unsigned int cpu)
+ {
+ 	struct exception_stacks *estacks = per_cpu_ptr(&exception_stacks, cpu);
+ 	struct cpu_entry_area *cea = get_cpu_entry_area(cpu);
+ 	unsigned int npages;
+ 
+ 	BUILD_BUG_ON(sizeof(exception_stacks) % PAGE_SIZE != 0);
+ 
+ 	per_cpu(cea_exception_stacks, cpu) = &cea->estacks;
+ 
+ 	/*
+ 	 * The exceptions stack mappings in the per cpu area are protected
+ 	 * by guard pages so each stack must be mapped separately.
+ 	 */
+ 	cea_map_stack(DF);
+ 	cea_map_stack(NMI);
+ 	cea_map_stack(DB);
+ 	cea_map_stack(MCE);
+ }
+ #else
+ static inline void percpu_setup_exception_stacks(unsigned int cpu) {}
+ #endif
+ 
++>>>>>>> 7623f37e4111 (x86/cpu_entry_area: Provide exception stack accessor)
  /* Setup the fixmap mappings only once per-processor */
 -static void __init setup_cpu_entry_area(unsigned int cpu)
 +static void __init setup_cpu_entry_area(int cpu)
  {
 -	struct cpu_entry_area *cea = get_cpu_entry_area(cpu);
  #ifdef CONFIG_X86_64
  	/* On 64-bit systems, we use a read-only fixmap GDT and TSS. */
  	pgprot_t gdt_prot = PAGE_KERNEL_RO;
diff --git a/arch/x86/include/asm/cpu_entry_area.h b/arch/x86/include/asm/cpu_entry_area.h
index 29c706415443..be1d1870092e 100644
--- a/arch/x86/include/asm/cpu_entry_area.h
+++ b/arch/x86/include/asm/cpu_entry_area.h
@@ -57,6 +57,7 @@ struct cpu_entry_area {
 #define CPU_ENTRY_AREA_TOT_SIZE	(CPU_ENTRY_AREA_SIZE * NR_CPUS)
 
 DECLARE_PER_CPU(struct cpu_entry_area *, cpu_entry_area);
+DECLARE_PER_CPU(struct cea_exception_stacks *, cea_exception_stacks);
 
 extern void setup_cpu_entry_areas(void);
 extern void cea_set_pte(void *cea_vaddr, phys_addr_t pa, pgprot_t flags);
@@ -76,4 +77,7 @@ static inline struct entry_stack *cpu_entry_stack(int cpu)
 	return &get_cpu_entry_area(cpu)->entry_stack_page.stack;
 }
 
+#define __this_cpu_ist_top_va(name)					\
+	CEA_ESTACK_TOP(__this_cpu_read(cea_exception_stacks), name)
+
 #endif
* Unmerged path arch/x86/mm/cpu_entry_area.c
