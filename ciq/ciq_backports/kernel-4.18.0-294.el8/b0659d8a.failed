bpf: Fix definition of bpf_ringbuf_output() helper in UAPI comments

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Andrii Nakryiko <andriin@fb.com>
commit b0659d8a950d424e57cc0a67afc4740ee561224e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/b0659d8a.failed

Fix definition of bpf_ringbuf_output() in UAPI header comments, which is used
to generate libbpf's bpf_helper_defs.h header. Return value is a number (error
code), not a pointer.

Fixes: 457f44363a88 ("bpf: Implement BPF ring buffer and verifier support for it")
	Signed-off-by: Andrii Nakryiko <andriin@fb.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20200615214926.3638836-1-andriin@fb.com
(cherry picked from commit b0659d8a950d424e57cc0a67afc4740ee561224e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/uapi/linux/bpf.h
#	tools/include/uapi/linux/bpf.h
diff --cc include/uapi/linux/bpf.h
index 7ccb96ed0b1f,974a71342aea..000000000000
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@@ -3127,6 -3135,123 +3127,126 @@@ union bpf_attr 
   * 		0 on success, or a negative error in case of failure:
   *
   *		**-EOVERFLOW** if an overflow happened: The same object will be tried again.
++<<<<<<< HEAD
++=======
+  *
+  * u64 bpf_sk_cgroup_id(struct bpf_sock *sk)
+  *	Description
+  *		Return the cgroup v2 id of the socket *sk*.
+  *
+  *		*sk* must be a non-**NULL** pointer to a full socket, e.g. one
+  *		returned from **bpf_sk_lookup_xxx**\ (),
+  *		**bpf_sk_fullsock**\ (), etc. The format of returned id is
+  *		same as in **bpf_skb_cgroup_id**\ ().
+  *
+  *		This helper is available only if the kernel was compiled with
+  *		the **CONFIG_SOCK_CGROUP_DATA** configuration option.
+  *	Return
+  *		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * u64 bpf_sk_ancestor_cgroup_id(struct bpf_sock *sk, int ancestor_level)
+  *	Description
+  *		Return id of cgroup v2 that is ancestor of cgroup associated
+  *		with the *sk* at the *ancestor_level*.  The root cgroup is at
+  *		*ancestor_level* zero and each step down the hierarchy
+  *		increments the level. If *ancestor_level* == level of cgroup
+  *		associated with *sk*, then return value will be same as that
+  *		of **bpf_sk_cgroup_id**\ ().
+  *
+  *		The helper is useful to implement policies based on cgroups
+  *		that are upper in hierarchy than immediate cgroup associated
+  *		with *sk*.
+  *
+  *		The format of returned id and helper limitations are same as in
+  *		**bpf_sk_cgroup_id**\ ().
+  *	Return
+  *		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * int bpf_ringbuf_output(void *ringbuf, void *data, u64 size, u64 flags)
+  * 	Description
+  * 		Copy *size* bytes from *data* into a ring buffer *ringbuf*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		0, on success;
+  * 		< 0, on error.
+  *
+  * void *bpf_ringbuf_reserve(void *ringbuf, u64 size, u64 flags)
+  * 	Description
+  * 		Reserve *size* bytes of payload in a ring buffer *ringbuf*.
+  * 	Return
+  * 		Valid pointer with *size* bytes of memory available; NULL,
+  * 		otherwise.
+  *
+  * void bpf_ringbuf_submit(void *data, u64 flags)
+  * 	Description
+  * 		Submit reserved ring buffer sample, pointed to by *data*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		Nothing. Always succeeds.
+  *
+  * void bpf_ringbuf_discard(void *data, u64 flags)
+  * 	Description
+  * 		Discard reserved ring buffer sample, pointed to by *data*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		Nothing. Always succeeds.
+  *
+  * u64 bpf_ringbuf_query(void *ringbuf, u64 flags)
+  *	Description
+  *		Query various characteristics of provided ring buffer. What
+  *		exactly is queries is determined by *flags*:
+  *		  - BPF_RB_AVAIL_DATA - amount of data not yet consumed;
+  *		  - BPF_RB_RING_SIZE - the size of ring buffer;
+  *		  - BPF_RB_CONS_POS - consumer position (can wrap around);
+  *		  - BPF_RB_PROD_POS - producer(s) position (can wrap around);
+  *		Data returned is just a momentary snapshots of actual values
+  *		and could be inaccurate, so this facility should be used to
+  *		power heuristics and for reporting, not to make 100% correct
+  *		calculation.
+  *	Return
+  *		Requested value, or 0, if flags are not recognized.
+  *
+  * int bpf_csum_level(struct sk_buff *skb, u64 level)
+  * 	Description
+  * 		Change the skbs checksum level by one layer up or down, or
+  * 		reset it entirely to none in order to have the stack perform
+  * 		checksum validation. The level is applicable to the following
+  * 		protocols: TCP, UDP, GRE, SCTP, FCOE. For example, a decap of
+  * 		| ETH | IP | UDP | GUE | IP | TCP | into | ETH | IP | TCP |
+  * 		through **bpf_skb_adjust_room**\ () helper with passing in
+  * 		**BPF_F_ADJ_ROOM_NO_CSUM_RESET** flag would require one	call
+  * 		to **bpf_csum_level**\ () with **BPF_CSUM_LEVEL_DEC** since
+  * 		the UDP header is removed. Similarly, an encap of the latter
+  * 		into the former could be accompanied by a helper call to
+  * 		**bpf_csum_level**\ () with **BPF_CSUM_LEVEL_INC** if the
+  * 		skb is still intended to be processed in higher layers of the
+  * 		stack instead of just egressing at tc.
+  *
+  * 		There are three supported level settings at this time:
+  *
+  * 		* **BPF_CSUM_LEVEL_INC**: Increases skb->csum_level for skbs
+  * 		  with CHECKSUM_UNNECESSARY.
+  * 		* **BPF_CSUM_LEVEL_DEC**: Decreases skb->csum_level for skbs
+  * 		  with CHECKSUM_UNNECESSARY.
+  * 		* **BPF_CSUM_LEVEL_RESET**: Resets skb->csum_level to 0 and
+  * 		  sets CHECKSUM_NONE to force checksum validation by the stack.
+  * 		* **BPF_CSUM_LEVEL_QUERY**: No-op, returns the current
+  * 		  skb->csum_level.
+  * 	Return
+  * 		0 on success, or a negative error in case of failure. In the
+  * 		case of **BPF_CSUM_LEVEL_QUERY**, the current skb->csum_level
+  * 		is returned or the error code -EACCES in case the skb is not
+  * 		subject to CHECKSUM_UNNECESSARY.
++>>>>>>> b0659d8a950d (bpf: Fix definition of bpf_ringbuf_output() helper in UAPI comments)
   */
  #define __BPF_FUNC_MAPPER(FN)		\
  	FN(unspec),			\
diff --cc tools/include/uapi/linux/bpf.h
index fc883a643880,974a71342aea..000000000000
--- a/tools/include/uapi/linux/bpf.h
+++ b/tools/include/uapi/linux/bpf.h
@@@ -3093,13 -3128,130 +3093,134 @@@ union bpf_attr 
   *
   * int bpf_seq_write(struct seq_file *m, const void *data, u32 len)
   * 	Description
 - * 		**bpf_seq_write**\ () uses seq_file **seq_write**\ () to write the data.
 + * 		seq_write uses seq_file seq_write() to write the data.
   * 		The *m* represents the seq_file. The *data* and *len* represent the
 - * 		data to write in bytes.
 + *		data to write in bytes.
   * 	Return
 - * 		0 on success, or a negative error in case of failure:
 + * 		0 on success, or a negative errno in case of failure.
   *
++<<<<<<< HEAD
 + *		* **-EOVERFLOW**	Overflow happens, the same object will be tried again.
++=======
+  *		**-EOVERFLOW** if an overflow happened: The same object will be tried again.
+  *
+  * u64 bpf_sk_cgroup_id(struct bpf_sock *sk)
+  *	Description
+  *		Return the cgroup v2 id of the socket *sk*.
+  *
+  *		*sk* must be a non-**NULL** pointer to a full socket, e.g. one
+  *		returned from **bpf_sk_lookup_xxx**\ (),
+  *		**bpf_sk_fullsock**\ (), etc. The format of returned id is
+  *		same as in **bpf_skb_cgroup_id**\ ().
+  *
+  *		This helper is available only if the kernel was compiled with
+  *		the **CONFIG_SOCK_CGROUP_DATA** configuration option.
+  *	Return
+  *		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * u64 bpf_sk_ancestor_cgroup_id(struct bpf_sock *sk, int ancestor_level)
+  *	Description
+  *		Return id of cgroup v2 that is ancestor of cgroup associated
+  *		with the *sk* at the *ancestor_level*.  The root cgroup is at
+  *		*ancestor_level* zero and each step down the hierarchy
+  *		increments the level. If *ancestor_level* == level of cgroup
+  *		associated with *sk*, then return value will be same as that
+  *		of **bpf_sk_cgroup_id**\ ().
+  *
+  *		The helper is useful to implement policies based on cgroups
+  *		that are upper in hierarchy than immediate cgroup associated
+  *		with *sk*.
+  *
+  *		The format of returned id and helper limitations are same as in
+  *		**bpf_sk_cgroup_id**\ ().
+  *	Return
+  *		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * int bpf_ringbuf_output(void *ringbuf, void *data, u64 size, u64 flags)
+  * 	Description
+  * 		Copy *size* bytes from *data* into a ring buffer *ringbuf*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		0, on success;
+  * 		< 0, on error.
+  *
+  * void *bpf_ringbuf_reserve(void *ringbuf, u64 size, u64 flags)
+  * 	Description
+  * 		Reserve *size* bytes of payload in a ring buffer *ringbuf*.
+  * 	Return
+  * 		Valid pointer with *size* bytes of memory available; NULL,
+  * 		otherwise.
+  *
+  * void bpf_ringbuf_submit(void *data, u64 flags)
+  * 	Description
+  * 		Submit reserved ring buffer sample, pointed to by *data*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		Nothing. Always succeeds.
+  *
+  * void bpf_ringbuf_discard(void *data, u64 flags)
+  * 	Description
+  * 		Discard reserved ring buffer sample, pointed to by *data*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		Nothing. Always succeeds.
+  *
+  * u64 bpf_ringbuf_query(void *ringbuf, u64 flags)
+  *	Description
+  *		Query various characteristics of provided ring buffer. What
+  *		exactly is queries is determined by *flags*:
+  *		  - BPF_RB_AVAIL_DATA - amount of data not yet consumed;
+  *		  - BPF_RB_RING_SIZE - the size of ring buffer;
+  *		  - BPF_RB_CONS_POS - consumer position (can wrap around);
+  *		  - BPF_RB_PROD_POS - producer(s) position (can wrap around);
+  *		Data returned is just a momentary snapshots of actual values
+  *		and could be inaccurate, so this facility should be used to
+  *		power heuristics and for reporting, not to make 100% correct
+  *		calculation.
+  *	Return
+  *		Requested value, or 0, if flags are not recognized.
+  *
+  * int bpf_csum_level(struct sk_buff *skb, u64 level)
+  * 	Description
+  * 		Change the skbs checksum level by one layer up or down, or
+  * 		reset it entirely to none in order to have the stack perform
+  * 		checksum validation. The level is applicable to the following
+  * 		protocols: TCP, UDP, GRE, SCTP, FCOE. For example, a decap of
+  * 		| ETH | IP | UDP | GUE | IP | TCP | into | ETH | IP | TCP |
+  * 		through **bpf_skb_adjust_room**\ () helper with passing in
+  * 		**BPF_F_ADJ_ROOM_NO_CSUM_RESET** flag would require one	call
+  * 		to **bpf_csum_level**\ () with **BPF_CSUM_LEVEL_DEC** since
+  * 		the UDP header is removed. Similarly, an encap of the latter
+  * 		into the former could be accompanied by a helper call to
+  * 		**bpf_csum_level**\ () with **BPF_CSUM_LEVEL_INC** if the
+  * 		skb is still intended to be processed in higher layers of the
+  * 		stack instead of just egressing at tc.
+  *
+  * 		There are three supported level settings at this time:
+  *
+  * 		* **BPF_CSUM_LEVEL_INC**: Increases skb->csum_level for skbs
+  * 		  with CHECKSUM_UNNECESSARY.
+  * 		* **BPF_CSUM_LEVEL_DEC**: Decreases skb->csum_level for skbs
+  * 		  with CHECKSUM_UNNECESSARY.
+  * 		* **BPF_CSUM_LEVEL_RESET**: Resets skb->csum_level to 0 and
+  * 		  sets CHECKSUM_NONE to force checksum validation by the stack.
+  * 		* **BPF_CSUM_LEVEL_QUERY**: No-op, returns the current
+  * 		  skb->csum_level.
+  * 	Return
+  * 		0 on success, or a negative error in case of failure. In the
+  * 		case of **BPF_CSUM_LEVEL_QUERY**, the current skb->csum_level
+  * 		is returned or the error code -EACCES in case the skb is not
+  * 		subject to CHECKSUM_UNNECESSARY.
++>>>>>>> b0659d8a950d (bpf: Fix definition of bpf_ringbuf_output() helper in UAPI comments)
   */
  #define __BPF_FUNC_MAPPER(FN)		\
  	FN(unspec),			\
* Unmerged path include/uapi/linux/bpf.h
* Unmerged path tools/include/uapi/linux/bpf.h
