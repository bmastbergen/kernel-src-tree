block: add QUEUE_FLAG_NOWAIT

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Mike Snitzer <snitzer@redhat.com>
commit 021a24460dc28e7412aecfae89f60e1847e685c0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/021a2446.failed

Add QUEUE_FLAG_NOWAIT to allow a block device to advertise support for
REQ_NOWAIT. Bio-based devices may set QUEUE_FLAG_NOWAIT where
applicable.

Update QUEUE_FLAG_MQ_DEFAULT to include QUEUE_FLAG_NOWAIT.  Also
update submit_bio_checks() to verify it is set for REQ_NOWAIT bios.

	Reported-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
	Suggested-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Mike Snitzer <snitzer@redhat.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 021a24460dc28e7412aecfae89f60e1847e685c0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/blkdev.h
diff --cc include/linux/blkdev.h
index 43b1486e0588,d5a3e1a4c2f7..000000000000
--- a/include/linux/blkdev.h
+++ b/include/linux/blkdev.h
@@@ -585,66 -586,45 +585,101 @@@ struct request_queue 
  
  	size_t			cmd_size;
  
 +	RH_KABI_DEPRECATE(struct work_struct,      release_work)
 +
  #define BLK_MAX_WRITE_HINTS	5
  	u64			write_hints[BLK_MAX_WRITE_HINTS];
 +
 +	/*
 +	 * for reusing dead hctx instance in case of updating
 +	 * nr_hw_queues
 +	 */
 +	RH_KABI_EXTEND(struct list_head	unused_hctx_list)
 +	RH_KABI_EXTEND(spinlock_t	unused_hctx_lock)
 +	/*
 +	 * Protect concurrent access to q_usage_counter by
 +	 * percpu_ref_kill() and percpu_ref_reinit().
 +	 */
 +	RH_KABI_EXTEND(struct mutex		mq_freeze_lock)
 +
 +	RH_KABI_EXTEND(struct mutex		sysfs_dir_lock)
 +
 +	RH_KABI_EXTEND(struct dentry		*rqos_debugfs_dir)
 +
 +	RH_KABI_EXTEND(unsigned int	required_elevator_features)
  };
  
++<<<<<<< HEAD
 +#define QUEUE_FLAG_STOPPED	1	/* queue is stopped */
 +#define QUEUE_FLAG_DYING	2	/* queue being torn down */
 +#define QUEUE_FLAG_NOMERGES     5	/* disable merge attempts */
 +#define QUEUE_FLAG_SAME_COMP	6	/* complete on same CPU-group */
 +#define QUEUE_FLAG_FAIL_IO	7	/* fake timeout */
 +#define QUEUE_FLAG_UNPRIV_SGIO  8	/* SG_IO free for unprivileged users */
 +#define QUEUE_FLAG_NONROT	9	/* non-rotational device (SSD) */
 +#define QUEUE_FLAG_VIRT        QUEUE_FLAG_NONROT /* paravirt device */
 +#define QUEUE_FLAG_IO_STAT     10	/* do IO stats */
 +#define QUEUE_FLAG_DISCARD     11	/* supports DISCARD */
 +#define QUEUE_FLAG_NOXMERGES   12	/* No extended merges */
 +#define QUEUE_FLAG_ADD_RANDOM  13	/* Contributes to random pool */
 +#define QUEUE_FLAG_SECERASE    14	/* supports secure erase */
 +#define QUEUE_FLAG_SAME_FORCE  15	/* force complete on same CPU */
 +#define QUEUE_FLAG_DEAD        16	/* queue tear-down finished */
 +#define QUEUE_FLAG_INIT_DONE   17	/* queue is initialized */
 +#define QUEUE_FLAG_NO_SG_MERGE 18	/* don't attempt to merge SG segments (obsolete) */
 +#define QUEUE_FLAG_POLL	       19	/* IO polling enabled if set */
 +#define QUEUE_FLAG_WC	       20	/* Write back caching */
 +#define QUEUE_FLAG_FUA	       21	/* device supports FUA writes */
 +#define QUEUE_FLAG_RQ_ALLOC_TIME 22	/* record rq->alloc_time_ns */
 +#define QUEUE_FLAG_DAX         23	/* device supports DAX */
 +#define QUEUE_FLAG_STATS       24	/* track rq completion times */
 +#define QUEUE_FLAG_POLL_STATS  25	/* collecting stats for hybrid polling */
 +#define QUEUE_FLAG_REGISTERED  26	/* queue has been registered to a disk */
 +#define QUEUE_FLAG_SCSI_PASSTHROUGH 27	/* queue supports SCSI commands */
 +#define QUEUE_FLAG_QUIESCED    28	/* queue has been quiesced */
 +#define QUEUE_FLAG_PCI_P2PDMA  29	/* device supports PCI p2p requests */
 +#define QUEUE_FLAG_ZONE_RESETALL 30	/* supports Zone Reset All */
 +
 +#define QUEUE_FLAG_DEFAULT	((1 << QUEUE_FLAG_IO_STAT) |		\
 +				 (1 << QUEUE_FLAG_SAME_COMP)	|	\
 +				 (1 << QUEUE_FLAG_ADD_RANDOM))
++=======
+ /* Keep blk_queue_flag_name[] in sync with the definitions below */
+ #define QUEUE_FLAG_STOPPED	0	/* queue is stopped */
+ #define QUEUE_FLAG_DYING	1	/* queue being torn down */
+ #define QUEUE_FLAG_NOMERGES     3	/* disable merge attempts */
+ #define QUEUE_FLAG_SAME_COMP	4	/* complete on same CPU-group */
+ #define QUEUE_FLAG_FAIL_IO	5	/* fake timeout */
+ #define QUEUE_FLAG_NONROT	6	/* non-rotational device (SSD) */
+ #define QUEUE_FLAG_VIRT		QUEUE_FLAG_NONROT /* paravirt device */
+ #define QUEUE_FLAG_IO_STAT	7	/* do disk/partitions IO accounting */
+ #define QUEUE_FLAG_DISCARD	8	/* supports DISCARD */
+ #define QUEUE_FLAG_NOXMERGES	9	/* No extended merges */
+ #define QUEUE_FLAG_ADD_RANDOM	10	/* Contributes to random pool */
+ #define QUEUE_FLAG_SECERASE	11	/* supports secure erase */
+ #define QUEUE_FLAG_SAME_FORCE	12	/* force complete on same CPU */
+ #define QUEUE_FLAG_DEAD		13	/* queue tear-down finished */
+ #define QUEUE_FLAG_INIT_DONE	14	/* queue is initialized */
+ #define QUEUE_FLAG_STABLE_WRITES 15	/* don't modify blks until WB is done */
+ #define QUEUE_FLAG_POLL		16	/* IO polling enabled if set */
+ #define QUEUE_FLAG_WC		17	/* Write back caching */
+ #define QUEUE_FLAG_FUA		18	/* device supports FUA writes */
+ #define QUEUE_FLAG_DAX		19	/* device supports DAX */
+ #define QUEUE_FLAG_STATS	20	/* track IO start and completion times */
+ #define QUEUE_FLAG_POLL_STATS	21	/* collecting stats for hybrid polling */
+ #define QUEUE_FLAG_REGISTERED	22	/* queue has been registered to a disk */
+ #define QUEUE_FLAG_SCSI_PASSTHROUGH 23	/* queue supports SCSI commands */
+ #define QUEUE_FLAG_QUIESCED	24	/* queue has been quiesced */
+ #define QUEUE_FLAG_PCI_P2PDMA	25	/* device supports PCI p2p requests */
+ #define QUEUE_FLAG_ZONE_RESETALL 26	/* supports Zone Reset All */
+ #define QUEUE_FLAG_RQ_ALLOC_TIME 27	/* record rq->alloc_time_ns */
+ #define QUEUE_FLAG_HCTX_ACTIVE	28	/* at least one blk-mq hctx is active */
+ #define QUEUE_FLAG_NOWAIT       29	/* device supports NOWAIT */
++>>>>>>> 021a24460dc2 (block: add QUEUE_FLAG_NOWAIT)
  
  #define QUEUE_FLAG_MQ_DEFAULT	((1 << QUEUE_FLAG_IO_STAT) |		\
- 				 (1 << QUEUE_FLAG_SAME_COMP))
+ 				 (1 << QUEUE_FLAG_SAME_COMP) |		\
+ 				 (1 << QUEUE_FLAG_NOWAIT))
  
  void blk_queue_flag_set(unsigned int flag, struct request_queue *q);
  void blk_queue_flag_clear(unsigned int flag, struct request_queue *q);
diff --git a/block/blk-core.c b/block/blk-core.c
index 9aabbc020a34..3b2da718eb22 100644
--- a/block/blk-core.c
+++ b/block/blk-core.c
@@ -901,9 +901,9 @@ generic_make_request_checks(struct bio *bio)
 
 	/*
 	 * For a REQ_NOWAIT based request, return -EOPNOTSUPP
-	 * if queue is not a request based queue.
+	 * if queue does not support NOWAIT.
 	 */
-	if ((bio->bi_opf & REQ_NOWAIT) && !queue_is_mq(q))
+	if ((bio->bi_opf & REQ_NOWAIT) && !blk_queue_nowait(q))
 		goto not_supported;
 
 	if (should_fail_bio(bio))
* Unmerged path include/linux/blkdev.h
