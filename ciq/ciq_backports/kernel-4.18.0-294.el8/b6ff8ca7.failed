scsi: scsi_debug: Parser tables and code interaction

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Douglas Gilbert <dgilbert@interlog.com>
commit b6ff8ca733500a7394d926c74ac20b428b225db7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/b6ff8ca7.failed

This patch is in response to a static analyser report from Dan Carpenter
titled: "[bug report] scsi: scsi_debug: Add per_host_store option".  This
code may not clear the static analyzer reports, but may shed light on why
they occur. Amongst other things this driver has a table driven SCSI
command parser which also involves some C code. There are some invariants
between the table entries and the corresponding C code (i.e. the resp_*()
functions) that, if broken, may lead to a NULL dereference.  And the report
is valid, at least in the case of the PRE-FETCH command.  Alas, that is not
one of the cases that the static analyzer reported.

In this particular corner case: when the fake_rw flag is set and the table
entry for a "store"-accessing command does not have the required F_FAKE_RW
flag set, do the following. Call BUG_ON() in the devip2sip() very close to
a comment block explaining why it was called and how to fix it.
checkpatch.pl complains about the BUG_ON() but there is no reasonable
remedial action that can be taken at run time.

This change allows the code reported by the static analyzer to be
simplified. Comments were also added to the table flags (e.g.  F_FAKE_RW)
so developers who add commands might be more inclined to use them
(properly).

Link: https://lore.kernel.org/r/20200513013943.25285-1-dgilbert@interlog.com
	Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
	Signed-off-by: Douglas Gilbert <dgilbert@interlog.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit b6ff8ca733500a7394d926c74ac20b428b225db7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/scsi_debug.c
diff --cc drivers/scsi/scsi_debug.c
index 8a8e70143123,843cccb38cb7..000000000000
--- a/drivers/scsi/scsi_debug.c
+++ b/drivers/scsi/scsi_debug.c
@@@ -518,6 -608,30 +520,33 @@@ static const struct opcode_info_t sync_
  	     0xff, 0xff, 0xff, 0xff, 0x3f, 0xc7} },	/* SYNC_CACHE (16) */
  };
  
++<<<<<<< HEAD
++=======
+ static const struct opcode_info_t pre_fetch_iarr[] = {
+ 	{0, 0x90, 0, F_SYNC_DELAY | FF_MEDIA_IO, resp_pre_fetch, NULL,
+ 	    {16,  0x2, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
+ 	     0xff, 0xff, 0xff, 0xff, 0x3f, 0xc7} },	/* PRE-FETCH (16) */
+ };
+ 
+ static const struct opcode_info_t zone_out_iarr[] = {	/* ZONE OUT(16) */
+ 	{0, 0x94, 0x1, F_SA_LOW | F_M_ACCESS, resp_close_zone, NULL,
+ 	    {16, 0x1, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
+ 	     0xff, 0, 0, 0xff, 0xff, 0x1, 0xc7} },	/* CLOSE ZONE */
+ 	{0, 0x94, 0x2, F_SA_LOW | F_M_ACCESS, resp_finish_zone, NULL,
+ 	    {16, 0x2, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
+ 	     0xff, 0, 0, 0xff, 0xff, 0x1, 0xc7} },	/* FINISH ZONE */
+ 	{0, 0x94, 0x4, F_SA_LOW | F_M_ACCESS, resp_rwp_zone, NULL,
+ 	    {16, 0x4, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
+ 	     0xff, 0, 0, 0xff, 0xff, 0x1, 0xc7} },  /* RESET WRITE POINTER */
+ };
+ 
+ static const struct opcode_info_t zone_in_iarr[] = {	/* ZONE IN(16) */
+ 	{0, 0x95, 0x6, F_SA_LOW | F_D_IN | F_M_ACCESS, NULL, NULL,
+ 	    {16, 0x6, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
+ 	     0xff, 0xff, 0xff, 0xff, 0x3f, 0xc7} }, /* REPORT ZONES */
+ };
+ 
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  
  /* This array is accessed via SDEB_I_* values. Make sure all are mapped,
   * plus the terminating elements for logic that scans this table such as
@@@ -613,8 -728,21 +642,26 @@@ static const struct opcode_info_t opcod
  	{0, 0x89, 0, F_D_OUT | FF_MEDIA_IO, resp_comp_write, NULL,
  	    {16,  0xf8, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0, 0,
  	     0, 0xff, 0x3f, 0xc7} },		/* COMPARE AND WRITE */
++<<<<<<< HEAD
 +
 +/* 29 */
++=======
+ 	{ARRAY_SIZE(pre_fetch_iarr), 0x34, 0, F_SYNC_DELAY | FF_MEDIA_IO,
+ 	    resp_pre_fetch, pre_fetch_iarr,
+ 	    {10,  0x2, 0xff, 0xff, 0xff, 0xff, 0x3f, 0xff, 0xff, 0xc7, 0, 0,
+ 	     0, 0, 0, 0} },			/* PRE-FETCH (10) */
+ 
+ /* 30 */
+ 	{ARRAY_SIZE(zone_out_iarr), 0x94, 0x3, F_SA_LOW | F_M_ACCESS,
+ 	    resp_open_zone, zone_out_iarr, /* ZONE_OUT(16), OPEN ZONE) */
+ 		{16,  0x3 /* SA */, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
+ 		 0xff, 0xff, 0x0, 0x0, 0xff, 0xff, 0x1, 0xc7} },
+ 	{ARRAY_SIZE(zone_in_iarr), 0x95, 0x0, F_SA_LOW | F_M_ACCESS,
+ 	    resp_report_zones, zone_in_iarr, /* ZONE_IN(16), REPORT ZONES) */
+ 		{16,  0x0 /* SA */, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,
+ 		 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xbf, 0xc7} },
+ /* sentinel */
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  	{0xff, 0, 0, 0, NULL, NULL,		/* terminating element */
  	    {0,  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0} },
  };
@@@ -2512,9 -2874,28 +2559,28 @@@ static inline int check_device_access_p
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * Note: if BUG_ON() fires it usually indicates a problem with the parser
+  * tables. Perhaps a missing F_FAKE_RW or FF_MEDIA_IO flag. Response functions
+  * that access any of the "stores" in struct sdeb_store_info should call this
+  * function with bug_if_fake_rw set to true.
+  */
+ static inline struct sdeb_store_info *devip2sip(struct sdebug_dev_info *devip,
+ 						bool bug_if_fake_rw)
+ {
+ 	if (sdebug_fake_rw) {
+ 		BUG_ON(bug_if_fake_rw);	/* See note above */
+ 		return NULL;
+ 	}
+ 	return xa_load(per_store_ap, devip->sdbg_host->si_idx);
+ }
+ 
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  /* Returns number of bytes copied or -1 if error. */
 -static int do_device_access(struct sdeb_store_info *sip, struct scsi_cmnd *scp,
 -			    u32 sg_skip, u64 lba, u32 num, bool do_write)
 +static int do_device_access(struct scsi_cmnd *scmd, u32 sg_skip, u64 lba,
 +			    u32 num, bool do_write)
  {
  	int ret;
  	u64 block, rest = 0;
@@@ -2628,6 -3026,9 +2694,12 @@@ static void dif_copy_prot(struct scsi_c
  {
  	size_t resid;
  	void *paddr;
++<<<<<<< HEAD
++=======
+ 	struct sdeb_store_info *sip = devip2sip((struct sdebug_dev_info *)
+ 						scp->device->hostdata, true);
+ 	struct t10_pi_tuple *dif_storep = sip->dif_storep;
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  	const void *dif_store_end = dif_storep + sdebug_store_sectors;
  	struct sg_mapping_iter miter;
  
@@@ -2670,8 -3071,10 +2742,14 @@@ static int prot_verify_read(struct scsi
  			    unsigned int sectors, u32 ei_lba)
  {
  	unsigned int i;
++<<<<<<< HEAD
++=======
+ 	sector_t sector;
+ 	struct sdeb_store_info *sip = devip2sip((struct sdebug_dev_info *)
+ 						scp->device->hostdata, true);
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  	struct t10_pi_tuple *sdt;
 +	sector_t sector;
  
  	for (i = 0; i < sectors; i++, ei_lba++) {
  		int ret;
@@@ -2697,14 -3101,15 +2775,24 @@@
  
  static int resp_read_dt0(struct scsi_cmnd *scp, struct sdebug_dev_info *devip)
  {
++<<<<<<< HEAD
++=======
+ 	bool check_prot;
+ 	u32 num;
+ 	u32 ei_lba;
+ 	int ret;
+ 	u64 lba;
+ 	struct sdeb_store_info *sip = devip2sip(devip, true);
+ 	rwlock_t *macc_lckp = sip ? &sip->macc_lck : &sdeb_fake_rw_lck;
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  	u8 *cmd = scp->cmnd;
  	struct sdebug_queued_cmd *sqcp;
 +	u64 lba;
 +	u32 num;
 +	u32 ei_lba;
 +	unsigned long iflags;
 +	int ret;
 +	bool check_prot;
  
  	switch (cmd[0]) {
  	case READ_16:
@@@ -3002,13 -3410,14 +3090,20 @@@ static void unmap_region(sector_t lba, 
  
  static int resp_write_dt0(struct scsi_cmnd *scp, struct sdebug_dev_info *devip)
  {
 -	bool check_prot;
 +	u8 *cmd = scp->cmnd;
 +	u64 lba;
  	u32 num;
  	u32 ei_lba;
 +	unsigned long iflags;
  	int ret;
++<<<<<<< HEAD
 +	bool check_prot;
++=======
+ 	u64 lba;
+ 	struct sdeb_store_info *sip = devip2sip(devip, true);
+ 	rwlock_t *macc_lckp = &sip->macc_lck;
+ 	u8 *cmd = scp->cmnd;
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  
  	switch (cmd[0]) {
  	case WRITE_16:
@@@ -3121,6 -3536,8 +3216,11 @@@ static int resp_write_scat(struct scsi_
  	u8 *cmd = scp->cmnd;
  	u8 *lrdp = NULL;
  	u8 *up;
++<<<<<<< HEAD
++=======
+ 	struct sdeb_store_info *sip = devip2sip(devip, true);
+ 	rwlock_t *macc_lckp = &sip->macc_lck;
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  	u8 wrprotect;
  	u16 lbdof, num_lrd, k;
  	u32 num, num_by, bt_len, lbdof_blen, sg_off, cum_lb;
@@@ -3281,21 -3700,28 +3381,27 @@@ err_out
  static int resp_write_same(struct scsi_cmnd *scp, u64 lba, u32 num,
  			   u32 ei_lba, bool unmap, bool ndob)
  {
 -	struct scsi_device *sdp = scp->device;
 -	struct sdebug_dev_info *devip = (struct sdebug_dev_info *)sdp->hostdata;
 +	int ret;
++<<<<<<< HEAD
 +	unsigned long iflags;
  	unsigned long long i;
 -	u64 block, lbaa;
  	u32 lb_size = sdebug_sector_size;
 -	int ret;
 +	u64 block, lbaa;
++=======
+ 	struct sdeb_store_info *sip = devip2sip((struct sdebug_dev_info *)
+ 						scp->device->hostdata, true);
+ 	rwlock_t *macc_lckp = &sip->macc_lck;
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  	u8 *fs1p;
 -	u8 *fsp;
 -
 -	write_lock(macc_lckp);
  
  	ret = check_device_access_params(scp, lba, num, true);
 -	if (ret) {
 -		write_unlock(macc_lckp);
 +	if (ret)
  		return ret;
 -	}
 +
 +	write_lock_irqsave(&atomic_rw, iflags);
  
  	if (unmap && scsi_debug_lbp()) {
 -		unmap_region(sip, lba, num);
 +		unmap_region(lba, num);
  		goto out;
  	}
  	lbaa = lba;
@@@ -3437,7 -3867,8 +3543,12 @@@ static int resp_comp_write(struct scsi_
  {
  	u8 *cmd = scp->cmnd;
  	u8 *arr;
++<<<<<<< HEAD
 +	u8 *fake_storep_hold;
++=======
+ 	struct sdeb_store_info *sip = devip2sip(devip, true);
+ 	rwlock_t *macc_lckp = &sip->macc_lck;
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  	u64 lba;
  	u32 dnum;
  	u32 lb_size = sdebug_sector_size;
@@@ -3509,10 -3934,10 +3620,15 @@@ static int resp_unmap(struct scsi_cmnd 
  {
  	unsigned char *buf;
  	struct unmap_block_desc *desc;
++<<<<<<< HEAD
++=======
+ 	struct sdeb_store_info *sip = devip2sip(devip, true);
+ 	rwlock_t *macc_lckp = &sip->macc_lck;
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  	unsigned int i, payload_len, descriptors;
  	int ret;
 +	unsigned long iflags;
 +
  
  	if (!scsi_debug_lbp())
  		return 0;	/* fib and say its done */
@@@ -3582,9 -4007,11 +3698,17 @@@ static int resp_get_lba_status(struct s
  	if (ret)
  		return ret;
  
++<<<<<<< HEAD
 +	if (scsi_debug_lbp())
 +		mapped = map_state(lba, &num);
 +	else {
++=======
+ 	if (scsi_debug_lbp()) {
+ 		struct sdeb_store_info *sip = devip2sip(devip, true);
+ 
+ 		mapped = map_state(sip, lba, &num);
+ 	} else {
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  		mapped = 1;
  		/* following just in case virtual_gb changed */
  		sdebug_capacity = get_sdebug_capacity();
@@@ -3629,6 -4056,56 +3753,59 @@@ static int resp_sync_cache(struct scsi_
  	return res;
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * Assuming the LBA+num_blocks is not out-of-range, this function will return
+  * CONDITION MET if the specified blocks will/have fitted in the cache, and
+  * a GOOD status otherwise. Model a disk with a big cache and yield
+  * CONDITION MET. Actually tries to bring range in main memory into the
+  * cache associated with the CPU(s).
+  */
+ static int resp_pre_fetch(struct scsi_cmnd *scp,
+ 			  struct sdebug_dev_info *devip)
+ {
+ 	int res = 0;
+ 	u64 lba;
+ 	u64 block, rest = 0;
+ 	u32 nblks;
+ 	u8 *cmd = scp->cmnd;
+ 	struct sdeb_store_info *sip = devip2sip(devip, true);
+ 	rwlock_t *macc_lckp = &sip->macc_lck;
+ 	u8 *fsp = sip->storep;
+ 
+ 	if (cmd[0] == PRE_FETCH) {	/* 10 byte cdb */
+ 		lba = get_unaligned_be32(cmd + 2);
+ 		nblks = get_unaligned_be16(cmd + 7);
+ 	} else {			/* PRE-FETCH(16) */
+ 		lba = get_unaligned_be64(cmd + 2);
+ 		nblks = get_unaligned_be32(cmd + 10);
+ 	}
+ 	if (lba + nblks > sdebug_capacity) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, LBA_OUT_OF_RANGE, 0);
+ 		return check_condition_result;
+ 	}
+ 	if (!fsp)
+ 		goto fini;
+ 	/* PRE-FETCH spec says nothing about LBP or PI so skip them */
+ 	block = do_div(lba, sdebug_store_sectors);
+ 	if (block + nblks > sdebug_store_sectors)
+ 		rest = block + nblks - sdebug_store_sectors;
+ 
+ 	/* Try to bring the PRE-FETCH range into CPU's cache */
+ 	read_lock(macc_lckp);
+ 	prefetch_range(fsp + (sdebug_sector_size * block),
+ 		       (nblks - rest) * sdebug_sector_size);
+ 	if (rest)
+ 		prefetch_range(fsp, rest * sdebug_sector_size);
+ 	read_unlock(macc_lckp);
+ fini:
+ 	if (cmd[1] & 0x2)
+ 		res = SDEG_RES_IMMED_MASK;
+ 	return res | condition_met_result;
+ }
+ 
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  #define RL_BUCKET_ELEMS 8
  
  /* Even though each pseudo target has a REPORT LUNS "well known logical unit"
@@@ -3730,6 -4207,504 +3907,507 @@@ static int resp_report_luns(struct scsi
  	return res;
  }
  
++<<<<<<< HEAD
++=======
+ static int resp_verify(struct scsi_cmnd *scp, struct sdebug_dev_info *devip)
+ {
+ 	bool is_bytchk3 = false;
+ 	u8 bytchk;
+ 	int ret, j;
+ 	u32 vnum, a_num, off;
+ 	const u32 lb_size = sdebug_sector_size;
+ 	u64 lba;
+ 	u8 *arr;
+ 	u8 *cmd = scp->cmnd;
+ 	struct sdeb_store_info *sip = devip2sip(devip, true);
+ 	rwlock_t *macc_lckp = &sip->macc_lck;
+ 
+ 	bytchk = (cmd[1] >> 1) & 0x3;
+ 	if (bytchk == 0) {
+ 		return 0;	/* always claim internal verify okay */
+ 	} else if (bytchk == 2) {
+ 		mk_sense_invalid_fld(scp, SDEB_IN_CDB, 2, 2);
+ 		return check_condition_result;
+ 	} else if (bytchk == 3) {
+ 		is_bytchk3 = true;	/* 1 block sent, compared repeatedly */
+ 	}
+ 	switch (cmd[0]) {
+ 	case VERIFY_16:
+ 		lba = get_unaligned_be64(cmd + 2);
+ 		vnum = get_unaligned_be32(cmd + 10);
+ 		break;
+ 	case VERIFY:		/* is VERIFY(10) */
+ 		lba = get_unaligned_be32(cmd + 2);
+ 		vnum = get_unaligned_be16(cmd + 7);
+ 		break;
+ 	default:
+ 		mk_sense_invalid_opcode(scp);
+ 		return check_condition_result;
+ 	}
+ 	a_num = is_bytchk3 ? 1 : vnum;
+ 	/* Treat following check like one for read (i.e. no write) access */
+ 	ret = check_device_access_params(scp, lba, a_num, false);
+ 	if (ret)
+ 		return ret;
+ 
+ 	arr = kcalloc(lb_size, vnum, GFP_ATOMIC);
+ 	if (!arr) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, INSUFF_RES_ASC,
+ 				INSUFF_RES_ASCQ);
+ 		return check_condition_result;
+ 	}
+ 	/* Not changing store, so only need read access */
+ 	read_lock(macc_lckp);
+ 
+ 	ret = do_dout_fetch(scp, a_num, arr);
+ 	if (ret == -1) {
+ 		ret = DID_ERROR << 16;
+ 		goto cleanup;
+ 	} else if (sdebug_verbose && (ret < (a_num * lb_size))) {
+ 		sdev_printk(KERN_INFO, scp->device,
+ 			    "%s: %s: cdb indicated=%u, IO sent=%d bytes\n",
+ 			    my_name, __func__, a_num * lb_size, ret);
+ 	}
+ 	if (is_bytchk3) {
+ 		for (j = 1, off = lb_size; j < vnum; ++j, off += lb_size)
+ 			memcpy(arr + off, arr, lb_size);
+ 	}
+ 	ret = 0;
+ 	if (!comp_write_worker(sip, lba, vnum, arr, true)) {
+ 		mk_sense_buffer(scp, MISCOMPARE, MISCOMPARE_VERIFY_ASC, 0);
+ 		ret = check_condition_result;
+ 		goto cleanup;
+ 	}
+ cleanup:
+ 	read_unlock(macc_lckp);
+ 	kfree(arr);
+ 	return ret;
+ }
+ 
+ #define RZONES_DESC_HD 64
+ 
+ /* Report zones depending on start LBA nad reporting options */
+ static int resp_report_zones(struct scsi_cmnd *scp,
+ 			     struct sdebug_dev_info *devip)
+ {
+ 	unsigned int i, max_zones, rep_max_zones, nrz = 0;
+ 	int ret = 0;
+ 	u32 alloc_len, rep_opts, rep_len;
+ 	bool partial;
+ 	u64 lba, zs_lba;
+ 	u8 *arr = NULL, *desc;
+ 	u8 *cmd = scp->cmnd;
+ 	struct sdeb_zone_state *zsp;
+ 	struct sdeb_store_info *sip = devip2sip(devip, false);
+ 	rwlock_t *macc_lckp = sip ? &sip->macc_lck : &sdeb_fake_rw_lck;
+ 
+ 	if (!sdebug_dev_is_zoned(devip)) {
+ 		mk_sense_invalid_opcode(scp);
+ 		return check_condition_result;
+ 	}
+ 	zs_lba = get_unaligned_be64(cmd + 2);
+ 	alloc_len = get_unaligned_be32(cmd + 10);
+ 	rep_opts = cmd[14] & 0x3f;
+ 	partial = cmd[14] & 0x80;
+ 
+ 	if (zs_lba >= sdebug_capacity) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, LBA_OUT_OF_RANGE, 0);
+ 		return check_condition_result;
+ 	}
+ 
+ 	max_zones = devip->nr_zones - (zs_lba >> devip->zsize_shift);
+ 	rep_max_zones = min((alloc_len - 64) >> ilog2(RZONES_DESC_HD),
+ 			    max_zones);
+ 
+ 	arr = kcalloc(RZONES_DESC_HD, alloc_len, GFP_ATOMIC);
+ 	if (!arr) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, INSUFF_RES_ASC,
+ 				INSUFF_RES_ASCQ);
+ 		return check_condition_result;
+ 	}
+ 
+ 	read_lock(macc_lckp);
+ 
+ 	desc = arr + 64;
+ 	for (i = 0; i < max_zones; i++) {
+ 		lba = zs_lba + devip->zsize * i;
+ 		if (lba > sdebug_capacity)
+ 			break;
+ 		zsp = zbc_zone(devip, lba);
+ 		switch (rep_opts) {
+ 		case 0x00:
+ 			/* All zones */
+ 			break;
+ 		case 0x01:
+ 			/* Empty zones */
+ 			if (zsp->z_cond != ZC1_EMPTY)
+ 				continue;
+ 			break;
+ 		case 0x02:
+ 			/* Implicit open zones */
+ 			if (zsp->z_cond != ZC2_IMPLICIT_OPEN)
+ 				continue;
+ 			break;
+ 		case 0x03:
+ 			/* Explicit open zones */
+ 			if (zsp->z_cond != ZC3_EXPLICIT_OPEN)
+ 				continue;
+ 			break;
+ 		case 0x04:
+ 			/* Closed zones */
+ 			if (zsp->z_cond != ZC4_CLOSED)
+ 				continue;
+ 			break;
+ 		case 0x05:
+ 			/* Full zones */
+ 			if (zsp->z_cond != ZC5_FULL)
+ 				continue;
+ 			break;
+ 		case 0x06:
+ 		case 0x07:
+ 		case 0x10:
+ 			/*
+ 			 * Read-only, offline, reset WP recommended are
+ 			 * not emulated: no zones to report;
+ 			 */
+ 			continue;
+ 		case 0x11:
+ 			/* non-seq-resource set */
+ 			if (!zsp->z_non_seq_resource)
+ 				continue;
+ 			break;
+ 		case 0x3f:
+ 			/* Not write pointer (conventional) zones */
+ 			if (!zbc_zone_is_conv(zsp))
+ 				continue;
+ 			break;
+ 		default:
+ 			mk_sense_buffer(scp, ILLEGAL_REQUEST,
+ 					INVALID_FIELD_IN_CDB, 0);
+ 			ret = check_condition_result;
+ 			goto fini;
+ 		}
+ 
+ 		if (nrz < rep_max_zones) {
+ 			/* Fill zone descriptor */
+ 			desc[0] = zsp->z_type;
+ 			desc[1] = zsp->z_cond << 4;
+ 			if (zsp->z_non_seq_resource)
+ 				desc[1] |= 1 << 1;
+ 			put_unaligned_be64((u64)zsp->z_size, desc + 8);
+ 			put_unaligned_be64((u64)zsp->z_start, desc + 16);
+ 			put_unaligned_be64((u64)zsp->z_wp, desc + 24);
+ 			desc += 64;
+ 		}
+ 
+ 		if (partial && nrz >= rep_max_zones)
+ 			break;
+ 
+ 		nrz++;
+ 	}
+ 
+ 	/* Report header */
+ 	put_unaligned_be32(nrz * RZONES_DESC_HD, arr + 0);
+ 	put_unaligned_be64(sdebug_capacity - 1, arr + 8);
+ 
+ 	rep_len = (unsigned long)desc - (unsigned long)arr;
+ 	ret = fill_from_dev_buffer(scp, arr, min_t(int, alloc_len, rep_len));
+ 
+ fini:
+ 	read_unlock(macc_lckp);
+ 	kfree(arr);
+ 	return ret;
+ }
+ 
+ /* Logic transplanted from tcmu-runner, file_zbc.c */
+ static void zbc_open_all(struct sdebug_dev_info *devip)
+ {
+ 	struct sdeb_zone_state *zsp = &devip->zstate[0];
+ 	unsigned int i;
+ 
+ 	for (i = 0; i < devip->nr_zones; i++, zsp++) {
+ 		if (zsp->z_cond == ZC4_CLOSED)
+ 			zbc_open_zone(devip, &devip->zstate[i], true);
+ 	}
+ }
+ 
+ static int resp_open_zone(struct scsi_cmnd *scp, struct sdebug_dev_info *devip)
+ {
+ 	int res = 0;
+ 	u64 z_id;
+ 	enum sdebug_z_cond zc;
+ 	u8 *cmd = scp->cmnd;
+ 	struct sdeb_zone_state *zsp;
+ 	bool all = cmd[14] & 0x01;
+ 	struct sdeb_store_info *sip = devip2sip(devip, false);
+ 	rwlock_t *macc_lckp = sip ? &sip->macc_lck : &sdeb_fake_rw_lck;
+ 
+ 	if (!sdebug_dev_is_zoned(devip)) {
+ 		mk_sense_invalid_opcode(scp);
+ 		return check_condition_result;
+ 	}
+ 
+ 	write_lock(macc_lckp);
+ 
+ 	if (all) {
+ 		/* Check if all closed zones can be open */
+ 		if (devip->max_open &&
+ 		    devip->nr_exp_open + devip->nr_closed > devip->max_open) {
+ 			mk_sense_buffer(scp, DATA_PROTECT, INSUFF_RES_ASC,
+ 					INSUFF_ZONE_ASCQ);
+ 			res = check_condition_result;
+ 			goto fini;
+ 		}
+ 		/* Open all closed zones */
+ 		zbc_open_all(devip);
+ 		goto fini;
+ 	}
+ 
+ 	/* Open the specified zone */
+ 	z_id = get_unaligned_be64(cmd + 2);
+ 	if (z_id >= sdebug_capacity) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, LBA_OUT_OF_RANGE, 0);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 
+ 	zsp = zbc_zone(devip, z_id);
+ 	if (z_id != zsp->z_start) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 	if (zbc_zone_is_conv(zsp)) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 
+ 	zc = zsp->z_cond;
+ 	if (zc == ZC3_EXPLICIT_OPEN || zc == ZC5_FULL)
+ 		goto fini;
+ 
+ 	if (devip->max_open && devip->nr_exp_open >= devip->max_open) {
+ 		mk_sense_buffer(scp, DATA_PROTECT, INSUFF_RES_ASC,
+ 				INSUFF_ZONE_ASCQ);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 
+ 	if (zc == ZC2_IMPLICIT_OPEN)
+ 		zbc_close_zone(devip, zsp);
+ 	zbc_open_zone(devip, zsp, true);
+ fini:
+ 	write_unlock(macc_lckp);
+ 	return res;
+ }
+ 
+ static void zbc_close_all(struct sdebug_dev_info *devip)
+ {
+ 	unsigned int i;
+ 
+ 	for (i = 0; i < devip->nr_zones; i++)
+ 		zbc_close_zone(devip, &devip->zstate[i]);
+ }
+ 
+ static int resp_close_zone(struct scsi_cmnd *scp,
+ 			   struct sdebug_dev_info *devip)
+ {
+ 	int res = 0;
+ 	u64 z_id;
+ 	u8 *cmd = scp->cmnd;
+ 	struct sdeb_zone_state *zsp;
+ 	bool all = cmd[14] & 0x01;
+ 	struct sdeb_store_info *sip = devip2sip(devip, false);
+ 	rwlock_t *macc_lckp = sip ? &sip->macc_lck : &sdeb_fake_rw_lck;
+ 
+ 	if (!sdebug_dev_is_zoned(devip)) {
+ 		mk_sense_invalid_opcode(scp);
+ 		return check_condition_result;
+ 	}
+ 
+ 	write_lock(macc_lckp);
+ 
+ 	if (all) {
+ 		zbc_close_all(devip);
+ 		goto fini;
+ 	}
+ 
+ 	/* Close specified zone */
+ 	z_id = get_unaligned_be64(cmd + 2);
+ 	if (z_id >= sdebug_capacity) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, LBA_OUT_OF_RANGE, 0);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 
+ 	zsp = zbc_zone(devip, z_id);
+ 	if (z_id != zsp->z_start) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 	if (zbc_zone_is_conv(zsp)) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 
+ 	zbc_close_zone(devip, zsp);
+ fini:
+ 	write_unlock(macc_lckp);
+ 	return res;
+ }
+ 
+ static void zbc_finish_zone(struct sdebug_dev_info *devip,
+ 			    struct sdeb_zone_state *zsp, bool empty)
+ {
+ 	enum sdebug_z_cond zc = zsp->z_cond;
+ 
+ 	if (zc == ZC4_CLOSED || zc == ZC2_IMPLICIT_OPEN ||
+ 	    zc == ZC3_EXPLICIT_OPEN || (empty && zc == ZC1_EMPTY)) {
+ 		if (zc == ZC2_IMPLICIT_OPEN || zc == ZC3_EXPLICIT_OPEN)
+ 			zbc_close_zone(devip, zsp);
+ 		if (zsp->z_cond == ZC4_CLOSED)
+ 			devip->nr_closed--;
+ 		zsp->z_wp = zsp->z_start + zsp->z_size;
+ 		zsp->z_cond = ZC5_FULL;
+ 	}
+ }
+ 
+ static void zbc_finish_all(struct sdebug_dev_info *devip)
+ {
+ 	unsigned int i;
+ 
+ 	for (i = 0; i < devip->nr_zones; i++)
+ 		zbc_finish_zone(devip, &devip->zstate[i], false);
+ }
+ 
+ static int resp_finish_zone(struct scsi_cmnd *scp,
+ 			    struct sdebug_dev_info *devip)
+ {
+ 	struct sdeb_zone_state *zsp;
+ 	int res = 0;
+ 	u64 z_id;
+ 	u8 *cmd = scp->cmnd;
+ 	bool all = cmd[14] & 0x01;
+ 	struct sdeb_store_info *sip = devip2sip(devip, false);
+ 	rwlock_t *macc_lckp = sip ? &sip->macc_lck : &sdeb_fake_rw_lck;
+ 
+ 	if (!sdebug_dev_is_zoned(devip)) {
+ 		mk_sense_invalid_opcode(scp);
+ 		return check_condition_result;
+ 	}
+ 
+ 	write_lock(macc_lckp);
+ 
+ 	if (all) {
+ 		zbc_finish_all(devip);
+ 		goto fini;
+ 	}
+ 
+ 	/* Finish the specified zone */
+ 	z_id = get_unaligned_be64(cmd + 2);
+ 	if (z_id >= sdebug_capacity) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, LBA_OUT_OF_RANGE, 0);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 
+ 	zsp = zbc_zone(devip, z_id);
+ 	if (z_id != zsp->z_start) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 	if (zbc_zone_is_conv(zsp)) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 
+ 	zbc_finish_zone(devip, zsp, true);
+ fini:
+ 	write_unlock(macc_lckp);
+ 	return res;
+ }
+ 
+ static void zbc_rwp_zone(struct sdebug_dev_info *devip,
+ 			 struct sdeb_zone_state *zsp)
+ {
+ 	enum sdebug_z_cond zc;
+ 
+ 	if (zbc_zone_is_conv(zsp))
+ 		return;
+ 
+ 	zc = zsp->z_cond;
+ 	if (zc == ZC2_IMPLICIT_OPEN || zc == ZC3_EXPLICIT_OPEN)
+ 		zbc_close_zone(devip, zsp);
+ 
+ 	if (zsp->z_cond == ZC4_CLOSED)
+ 		devip->nr_closed--;
+ 
+ 	zsp->z_non_seq_resource = false;
+ 	zsp->z_wp = zsp->z_start;
+ 	zsp->z_cond = ZC1_EMPTY;
+ }
+ 
+ static void zbc_rwp_all(struct sdebug_dev_info *devip)
+ {
+ 	unsigned int i;
+ 
+ 	for (i = 0; i < devip->nr_zones; i++)
+ 		zbc_rwp_zone(devip, &devip->zstate[i]);
+ }
+ 
+ static int resp_rwp_zone(struct scsi_cmnd *scp, struct sdebug_dev_info *devip)
+ {
+ 	struct sdeb_zone_state *zsp;
+ 	int res = 0;
+ 	u64 z_id;
+ 	u8 *cmd = scp->cmnd;
+ 	bool all = cmd[14] & 0x01;
+ 	struct sdeb_store_info *sip = devip2sip(devip, false);
+ 	rwlock_t *macc_lckp = sip ? &sip->macc_lck : &sdeb_fake_rw_lck;
+ 
+ 	if (!sdebug_dev_is_zoned(devip)) {
+ 		mk_sense_invalid_opcode(scp);
+ 		return check_condition_result;
+ 	}
+ 
+ 	write_lock(macc_lckp);
+ 
+ 	if (all) {
+ 		zbc_rwp_all(devip);
+ 		goto fini;
+ 	}
+ 
+ 	z_id = get_unaligned_be64(cmd + 2);
+ 	if (z_id >= sdebug_capacity) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, LBA_OUT_OF_RANGE, 0);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 
+ 	zsp = zbc_zone(devip, z_id);
+ 	if (z_id != zsp->z_start) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 	if (zbc_zone_is_conv(zsp)) {
+ 		mk_sense_buffer(scp, ILLEGAL_REQUEST, INVALID_FIELD_IN_CDB, 0);
+ 		res = check_condition_result;
+ 		goto fini;
+ 	}
+ 
+ 	zbc_rwp_zone(devip, zsp);
+ fini:
+ 	write_unlock(macc_lckp);
+ 	return res;
+ }
+ 
++>>>>>>> b6ff8ca73350 (scsi: scsi_debug: Parser tables and code interaction)
  static struct sdebug_queue *get_queue(struct scsi_cmnd *cmnd)
  {
  	u32 tag = blk_mq_unique_tag(cmnd->request);
* Unmerged path drivers/scsi/scsi_debug.c
