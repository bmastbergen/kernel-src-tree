KVM: VMX: Invoke NMI handler via indirect call instead of INTn

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Sean Christopherson <sean.j.christopherson@intel.com>
commit 1a5488ef0dcf6af5b2a69144ad6732dd67e98146
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/1a5488ef.failed

Rework NMI VM-Exit handling to invoke the kernel handler by function
call instead of INTn.  INTn microcode is relatively expensive, and
aligning the IRQ and NMI handling will make it easier to update KVM
should some newfangled method for invoking the handlers come along.

	Suggested-by: Andi Kleen <ak@linux.intel.com>
	Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
Message-Id: <20200915191505.10355-3-sean.j.christopherson@intel.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 1a5488ef0dcf6af5b2a69144ad6732dd67e98146)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/vmx/vmx.c
diff --cc arch/x86/kvm/vmx/vmx.c
index 7eddc4be3042,1eeafec6c791..000000000000
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@@ -6363,70 -6323,43 +6363,94 @@@ static void vmx_apicv_post_state_restor
  	memset(vmx->pi_desc.pir, 0, sizeof(vmx->pi_desc.pir));
  }
  
++<<<<<<< HEAD
++=======
+ void vmx_do_interrupt_nmi_irqoff(unsigned long entry);
+ 
+ static void handle_interrupt_nmi_irqoff(struct kvm_vcpu *vcpu, u32 intr_info)
+ {
+ 	unsigned int vector = intr_info & INTR_INFO_VECTOR_MASK;
+ 	gate_desc *desc = (gate_desc *)host_idt_base + vector;
+ 
+ 	kvm_before_interrupt(vcpu);
+ 	vmx_do_interrupt_nmi_irqoff(gate_offset(desc));
+ 	kvm_after_interrupt(vcpu);
+ }
+ 
++>>>>>>> 1a5488ef0dcf (KVM: VMX: Invoke NMI handler via indirect call instead of INTn)
  static void handle_exception_nmi_irqoff(struct vcpu_vmx *vmx)
  {
  	u32 intr_info = vmx_get_intr_info(&vmx->vcpu);
  
  	/* if exit due to PF check for async PF */
++<<<<<<< HEAD
 +	if (is_page_fault(intr_info)) {
 +		vmx->vcpu.arch.apf.host_apf_reason = kvm_read_and_reset_pf_reason();
++=======
+ 	if (is_page_fault(intr_info))
+ 		vmx->vcpu.arch.apf.host_apf_flags = kvm_read_and_reset_apf_flags();
++>>>>>>> 1a5488ef0dcf (KVM: VMX: Invoke NMI handler via indirect call instead of INTn)
  	/* Handle machine checks before interrupts are enabled */
- 	} else if (is_machine_check(intr_info)) {
+ 	else if (is_machine_check(intr_info))
  		kvm_machine_check();
  	/* We need to handle NMIs before interrupts are enabled */
- 	} else if (is_nmi(intr_info)) {
- 		kvm_before_interrupt(&vmx->vcpu);
- 		asm("int $2");
- 		kvm_after_interrupt(&vmx->vcpu);
- 	}
+ 	else if (is_nmi(intr_info))
+ 		handle_interrupt_nmi_irqoff(&vmx->vcpu, intr_info);
  }
  
  static void handle_external_interrupt_irqoff(struct kvm_vcpu *vcpu)
  {
++<<<<<<< HEAD
 +	unsigned int vector;
 +	unsigned long entry;
 +#ifdef CONFIG_X86_64
 +	unsigned long tmp;
 +#endif
 +	gate_desc *desc;
++=======
++>>>>>>> 1a5488ef0dcf (KVM: VMX: Invoke NMI handler via indirect call instead of INTn)
  	u32 intr_info = vmx_get_intr_info(vcpu);
  
  	if (WARN_ONCE(!is_external_intr(intr_info),
  	    "KVM: unexpected VM-Exit interrupt info: 0x%x", intr_info))
  		return;
  
++<<<<<<< HEAD
 +	vector = intr_info & INTR_INFO_VECTOR_MASK;
 +	desc = (gate_desc *)host_idt_base + vector;
 +	entry = gate_offset(desc);
 +
 +	kvm_before_interrupt(vcpu);
 +
 +	asm volatile(
 +#ifdef CONFIG_X86_64
 +		"mov %%rsp, %[sp]\n\t"
 +		"and $-16, %%rsp\n\t"
 +		"push %[ss]\n\t"
 +		"push %[sp]\n\t"
 +#endif
 +		"pushf\n\t"
 +		"push %[cs]\n\t"
 +		CALL_NOSPEC
 +		:
 +#ifdef CONFIG_X86_64
 +		[sp]"=&r"(tmp),
 +#endif
 +		ASM_CALL_CONSTRAINT
 +		:
 +		[thunk_target]"r"(entry),
 +#ifdef CONFIG_X86_64
 +		[ss]"i"(__KERNEL_DS),
 +#endif
 +		[cs]"i"(__KERNEL_CS)
 +	);
 +
 +	kvm_after_interrupt(vcpu);
++=======
+ 	handle_interrupt_nmi_irqoff(vcpu, intr_info);
++>>>>>>> 1a5488ef0dcf (KVM: VMX: Invoke NMI handler via indirect call instead of INTn)
  }
 +STACK_FRAME_NON_STANDARD(handle_external_interrupt_irqoff);
  
  static void vmx_handle_exit_irqoff(struct kvm_vcpu *vcpu)
  {
* Unmerged path arch/x86/kvm/vmx/vmx.c
