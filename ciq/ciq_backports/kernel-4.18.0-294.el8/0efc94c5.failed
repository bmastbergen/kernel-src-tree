seqcount: Compress SEQCNT_LOCKNAME_ZERO()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Peter Zijlstra <peterz@infradead.org>
commit 0efc94c5d15c3da0a69543d86ad2180f39256ed6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/0efc94c5.failed

Less is more.

	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
(cherry picked from commit 0efc94c5d15c3da0a69543d86ad2180f39256ed6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/seqlock.h
diff --cc include/linux/seqlock.h
index 362623ec6c41,251dcd6f5cd8..000000000000
--- a/include/linux/seqlock.h
+++ b/include/linux/seqlock.h
@@@ -105,13 -111,149 +105,153 @@@ static inline void seqcount_lockdep_rea
  # define seqcount_lockdep_reader_access(x)
  #endif
  
 -/**
 - * SEQCNT_ZERO() - static initializer for seqcount_t
 - * @name: Name of the seqcount_t instance
 - */
 -#define SEQCNT_ZERO(name) { .sequence = 0, SEQCOUNT_DEP_MAP_INIT(name) }
 +#define SEQCNT_ZERO(lockname) { .sequence = 0, SEQCOUNT_DEP_MAP_INIT(lockname)}
 +
++<<<<<<< HEAD
  
 +/**
 + * __read_seqcount_begin - begin a seq-read critical section (without barrier)
 + * @s: pointer to seqcount_t
 + * Returns: count to be passed to read_seqcount_retry
++=======
+ /*
+  * Sequence counters with associated locks (seqcount_LOCKTYPE_t)
+  *
+  * A sequence counter which associates the lock used for writer
+  * serialization at initialization time. This enables lockdep to validate
+  * that the write side critical section is properly serialized.
+  *
+  * For associated locks which do not implicitly disable preemption,
+  * preemption protection is enforced in the write side function.
+  *
+  * Lockdep is never used in any for the raw write variants.
+  *
+  * See Documentation/locking/seqlock.rst
+  */
+ 
+ #ifdef CONFIG_LOCKDEP
+ #define __SEQ_LOCK(expr)	expr
+ #else
+ #define __SEQ_LOCK(expr)
+ #endif
+ 
+ /**
+  * typedef seqcount_LOCKNAME_t - sequence counter with LOCKTYPR associated
+  * @seqcount:	The real sequence counter
+  * @lock:	Pointer to the associated spinlock
+  *
+  * A plain sequence counter with external writer synchronization by a
+  * spinlock. The spinlock is associated to the sequence count in the
+  * static initializer or init function. This enables lockdep to validate
+  * that the write side critical section is properly serialized.
+  */
+ 
+ /**
+  * seqcount_LOCKNAME_init() - runtime initializer for seqcount_LOCKNAME_t
+  * @s:		Pointer to the seqcount_LOCKNAME_t instance
+  * @lock:	Pointer to the associated LOCKTYPE
+  */
+ 
+ /*
+  * SEQCOUNT_LOCKTYPE() - Instantiate seqcount_LOCKNAME_t and helpers
+  * @locktype:		actual typename
+  * @lockname:		name
+  * @preemptible:	preemptibility of above locktype
+  * @lockmember:		argument for lockdep_assert_held()
+  */
+ #define SEQCOUNT_LOCKTYPE(locktype, lockname, preemptible, lockmember)	\
+ typedef struct seqcount_##lockname {					\
+ 	seqcount_t		seqcount;				\
+ 	__SEQ_LOCK(locktype	*lock);					\
+ } seqcount_##lockname##_t;						\
+ 									\
+ static __always_inline void						\
+ seqcount_##lockname##_init(seqcount_##lockname##_t *s, locktype *lock)	\
+ {									\
+ 	seqcount_init(&s->seqcount);					\
+ 	__SEQ_LOCK(s->lock = lock);					\
+ }									\
+ 									\
+ static __always_inline seqcount_t *					\
+ __seqcount_##lockname##_ptr(seqcount_##lockname##_t *s)			\
+ {									\
+ 	return &s->seqcount;						\
+ }									\
+ 									\
+ static __always_inline bool						\
+ __seqcount_##lockname##_preemptible(seqcount_##lockname##_t *s)		\
+ {									\
+ 	return preemptible;						\
+ }									\
+ 									\
+ static __always_inline void						\
+ __seqcount_##lockname##_assert(seqcount_##lockname##_t *s)		\
+ {									\
+ 	__SEQ_LOCK(lockdep_assert_held(lockmember));			\
+ }
+ 
+ /*
+  * __seqprop() for seqcount_t
+  */
+ 
+ static inline seqcount_t *__seqcount_ptr(seqcount_t *s)
+ {
+ 	return s;
+ }
+ 
+ static inline bool __seqcount_preemptible(seqcount_t *s)
+ {
+ 	return false;
+ }
+ 
+ static inline void __seqcount_assert(seqcount_t *s)
+ {
+ 	lockdep_assert_preemption_disabled();
+ }
+ 
+ SEQCOUNT_LOCKTYPE(raw_spinlock_t,	raw_spinlock,	false,	s->lock)
+ SEQCOUNT_LOCKTYPE(spinlock_t,		spinlock,	false,	s->lock)
+ SEQCOUNT_LOCKTYPE(rwlock_t,		rwlock,		false,	s->lock)
+ SEQCOUNT_LOCKTYPE(struct mutex,		mutex,		true,	s->lock)
+ SEQCOUNT_LOCKTYPE(struct ww_mutex,	ww_mutex,	true,	&s->lock->base)
+ 
+ /**
+  * SEQCNT_LOCKNAME_ZERO - static initializer for seqcount_LOCKNAME_t
+  * @name:	Name of the seqcount_LOCKNAME_t instance
+  * @lock:	Pointer to the associated LOCKTYPE
+  */
+ 
+ #define SEQCOUNT_LOCKTYPE_ZERO(seq_name, assoc_lock) {			\
+ 	.seqcount		= SEQCNT_ZERO(seq_name.seqcount),	\
+ 	__SEQ_LOCK(.lock	= (assoc_lock))				\
+ }
+ 
+ #define SEQCNT_SPINLOCK_ZERO(name, lock)	SEQCOUNT_LOCKTYPE_ZERO(name, lock)
+ #define SEQCNT_RAW_SPINLOCK_ZERO(name, lock)	SEQCOUNT_LOCKTYPE_ZERO(name, lock)
+ #define SEQCNT_RWLOCK_ZERO(name, lock)		SEQCOUNT_LOCKTYPE_ZERO(name, lock)
+ #define SEQCNT_MUTEX_ZERO(name, lock)		SEQCOUNT_LOCKTYPE_ZERO(name, lock)
+ #define SEQCNT_WW_MUTEX_ZERO(name, lock) 	SEQCOUNT_LOCKTYPE_ZERO(name, lock)
+ 
+ 
+ #define __seqprop_case(s, lockname, prop)				\
+ 	seqcount_##lockname##_t: __seqcount_##lockname##_##prop((void *)(s))
+ 
+ #define __seqprop(s, prop) _Generic(*(s),				\
+ 	seqcount_t:		__seqcount_##prop((void *)(s)),		\
+ 	__seqprop_case((s),	raw_spinlock,	prop),			\
+ 	__seqprop_case((s),	spinlock,	prop),			\
+ 	__seqprop_case((s),	rwlock,		prop),			\
+ 	__seqprop_case((s),	mutex,		prop),			\
+ 	__seqprop_case((s),	ww_mutex,	prop))
+ 
+ #define __to_seqcount_t(s)				__seqprop(s, ptr)
+ #define __associated_lock_exists_and_is_preemptible(s)	__seqprop(s, preemptible)
+ #define __assert_write_section_is_protected(s)		__seqprop(s, assert)
+ 
+ /**
+  * __read_seqcount_begin() - begin a seqcount_t read section w/o barrier
+  * @s: Pointer to seqcount_t or any of the seqcount_locktype_t variants
++>>>>>>> 0efc94c5d15c (seqcount: Compress SEQCNT_LOCKNAME_ZERO())
   *
   * __read_seqcount_begin is like read_seqcount_begin, but has no smp_rmb()
   * barrier. Callers should ensure that smp_rmb() or equivalent ordering is
* Unmerged path include/linux/seqlock.h
