RDMA/mlx5: Globally parse DEVX UID

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Leon Romanovsky <leon@kernel.org>
commit 21aad80b17e6d17adf99bf17482a5314bcb0aebb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/21aad80b.failed

Remove duplication in parsing of DEVX UID.

Link: https://lore.kernel.org/r/20200427154636.381474-27-leon@kernel.org
	Reviewed-by: Maor Gottlieb <maorg@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 21aad80b17e6d17adf99bf17482a5314bcb0aebb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/qp.c
diff --cc drivers/infiniband/hw/mlx5/qp.c
index 08f1eef60c1f,b2174e0817f5..000000000000
--- a/drivers/infiniband/hw/mlx5/qp.c
+++ b/drivers/infiniband/hw/mlx5/qp.c
@@@ -1960,14 -1913,11 +1960,20 @@@ static int get_atomic_mode(struct mlx5_
  	return atomic_mode;
  }
  
 +static inline bool check_flags_mask(uint64_t input, uint64_t supported)
 +{
 +	return (input & ~supported) == 0;
 +}
 +
  static int create_qp_common(struct mlx5_ib_dev *dev, struct ib_pd *pd,
  			    struct ib_qp_init_attr *init_attr,
++<<<<<<< HEAD
 +			    struct ib_udata *udata, struct mlx5_ib_qp *qp)
++=======
+ 			    struct mlx5_ib_create_qp *ucmd,
+ 			    struct ib_udata *udata, struct mlx5_ib_qp *qp,
+ 			    u32 uidx)
++>>>>>>> 21aad80b17e6 (RDMA/mlx5: Globally parse DEVX UID)
  {
  	struct mlx5_ib_resources *devr = &dev->devr;
  	int inlen = MLX5_ST_SZ_BYTES(create_qp_in);
@@@ -1976,10 -1926,6 +1982,11 @@@
  	struct mlx5_ib_cq *send_cq;
  	struct mlx5_ib_cq *recv_cq;
  	unsigned long flags;
++<<<<<<< HEAD
 +	u32 uidx = MLX5_IB_DEFAULT_UIDX;
 +	struct mlx5_ib_create_qp ucmd;
++=======
++>>>>>>> 21aad80b17e6 (RDMA/mlx5: Globally parse DEVX UID)
  	struct mlx5_ib_qp_base *base;
  	int mlx5_st;
  	void *qpc;
@@@ -2052,93 -1943,11 +2059,98 @@@
  	if (init_attr->sq_sig_type == IB_SIGNAL_ALL_WR)
  		qp->sq_signal_bits = MLX5_WQE_CTRL_CQ_UPDATE;
  
++<<<<<<< HEAD
 +	if (init_attr->create_flags & IB_QP_CREATE_CVLAN_STRIPPING) {
 +		if (!(MLX5_CAP_GEN(dev->mdev, eth_net_offloads) &&
 +		      MLX5_CAP_ETH(dev->mdev, vlan_cap)) ||
 +		    (init_attr->qp_type != IB_QPT_RAW_PACKET))
 +			return -EOPNOTSUPP;
 +		qp->flags |= MLX5_IB_QP_CVLAN_STRIPPING;
 +	}
 +
 +	if (udata) {
 +		if (ib_copy_from_udata(&ucmd, udata, sizeof(ucmd))) {
 +			mlx5_ib_dbg(dev, "copy failed\n");
 +			return -EFAULT;
 +		}
 +
 +		if (!check_flags_mask(ucmd.flags,
 +				      MLX5_QP_FLAG_ALLOW_SCATTER_CQE |
 +				      MLX5_QP_FLAG_BFREG_INDEX |
 +				      MLX5_QP_FLAG_PACKET_BASED_CREDIT_MODE |
 +				      MLX5_QP_FLAG_SCATTER_CQE |
 +				      MLX5_QP_FLAG_SIGNATURE |
 +				      MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_MC |
 +				      MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_UC |
 +				      MLX5_QP_FLAG_TUNNEL_OFFLOADS |
 +				      MLX5_QP_FLAG_UAR_PAGE_INDEX |
 +				      MLX5_QP_FLAG_TYPE_DCI |
 +				      MLX5_QP_FLAG_TYPE_DCT))
 +			return -EINVAL;
 +
 +		err = get_qp_user_index(ucontext, &ucmd, udata->inlen, &uidx);
 +		if (err)
 +			return err;
 +
 +		qp->wq_sig = !!(ucmd.flags & MLX5_QP_FLAG_SIGNATURE);
 +		if (MLX5_CAP_GEN(dev->mdev, sctr_data_cqe))
 +			qp->scat_cqe = !!(ucmd.flags & MLX5_QP_FLAG_SCATTER_CQE);
 +		if (ucmd.flags & MLX5_QP_FLAG_TUNNEL_OFFLOADS) {
 +			if (init_attr->qp_type != IB_QPT_RAW_PACKET ||
 +			    !tunnel_offload_supported(mdev)) {
 +				mlx5_ib_dbg(dev, "Tunnel offload isn't supported\n");
 +				return -EOPNOTSUPP;
 +			}
 +			qp->flags_en |= MLX5_QP_FLAG_TUNNEL_OFFLOADS;
 +		}
 +
 +		if (ucmd.flags & MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_UC) {
 +			if (init_attr->qp_type != IB_QPT_RAW_PACKET) {
 +				mlx5_ib_dbg(dev, "Self-LB UC isn't supported\n");
 +				return -EOPNOTSUPP;
 +			}
 +			qp->flags_en |= MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_UC;
 +		}
 +
 +		if (ucmd.flags & MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_MC) {
 +			if (init_attr->qp_type != IB_QPT_RAW_PACKET) {
 +				mlx5_ib_dbg(dev, "Self-LB UM isn't supported\n");
 +				return -EOPNOTSUPP;
 +			}
 +			qp->flags_en |= MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_MC;
 +		}
 +
 +		if (ucmd.flags & MLX5_QP_FLAG_PACKET_BASED_CREDIT_MODE) {
 +			if (init_attr->qp_type != IB_QPT_RC ||
 +				!MLX5_CAP_GEN(dev->mdev, qp_packet_based)) {
 +				mlx5_ib_dbg(dev, "packet based credit mode isn't supported\n");
 +				return -EOPNOTSUPP;
 +			}
 +			qp->flags |= MLX5_IB_QP_PACKET_BASED_CREDIT;
 +		}
 +
 +		if (init_attr->create_flags & IB_QP_CREATE_SOURCE_QPN) {
 +			if (init_attr->qp_type != IB_QPT_UD ||
 +			    (MLX5_CAP_GEN(dev->mdev, port_type) !=
 +			     MLX5_CAP_PORT_TYPE_IB) ||
 +			    !mlx5_get_flow_namespace(dev->mdev, MLX5_FLOW_NAMESPACE_BYPASS)) {
 +				mlx5_ib_dbg(dev, "Source QP option isn't supported\n");
 +				return -EOPNOTSUPP;
 +			}
 +
 +			qp->flags |= MLX5_IB_QP_UNDERLAY;
 +			qp->underlay_qpn = init_attr->source_qpn;
 +		}
 +	} else {
 +		qp->wq_sig = !!wq_signature;
 +	}
++=======
+ 	if (qp->flags & IB_QP_CREATE_SOURCE_QPN)
+ 		qp->underlay_qpn = init_attr->source_qpn;
++>>>>>>> 21aad80b17e6 (RDMA/mlx5: Globally parse DEVX UID)
  
  	base = (init_attr->qp_type == IB_QPT_RAW_PACKET ||
 -		qp->flags & IB_QP_CREATE_SOURCE_QPN) ?
 +		qp->flags & MLX5_IB_QP_UNDERLAY) ?
  	       &qp->raw_packet_qp.rq.base :
  	       &qp->trans_qp.base;
  
@@@ -2528,67 -2319,15 +2540,76 @@@ static void destroy_qp_common(struct ml
  		destroy_qp_kernel(dev, qp);
  }
  
++<<<<<<< HEAD
 +static const char *ib_qp_type_str(enum ib_qp_type type)
 +{
 +	switch (type) {
 +	case IB_QPT_SMI:
 +		return "IB_QPT_SMI";
 +	case IB_QPT_GSI:
 +		return "IB_QPT_GSI";
 +	case IB_QPT_RC:
 +		return "IB_QPT_RC";
 +	case IB_QPT_UC:
 +		return "IB_QPT_UC";
 +	case IB_QPT_UD:
 +		return "IB_QPT_UD";
 +	case IB_QPT_RAW_IPV6:
 +		return "IB_QPT_RAW_IPV6";
 +	case IB_QPT_RAW_ETHERTYPE:
 +		return "IB_QPT_RAW_ETHERTYPE";
 +	case IB_QPT_XRC_INI:
 +		return "IB_QPT_XRC_INI";
 +	case IB_QPT_XRC_TGT:
 +		return "IB_QPT_XRC_TGT";
 +	case IB_QPT_RAW_PACKET:
 +		return "IB_QPT_RAW_PACKET";
 +	case MLX5_IB_QPT_REG_UMR:
 +		return "MLX5_IB_QPT_REG_UMR";
 +	case IB_QPT_DRIVER:
 +		return "IB_QPT_DRIVER";
 +	case IB_QPT_MAX:
 +	default:
 +		return "Invalid QP type";
 +	}
 +}
 +
 +static struct ib_qp *mlx5_ib_create_dct(struct ib_pd *pd,
 +					struct ib_qp_init_attr *attr,
 +					struct mlx5_ib_create_qp *ucmd,
 +					struct ib_udata *udata)
 +{
 +	struct mlx5_ib_ucontext *ucontext = rdma_udata_to_drv_context(
 +		udata, struct mlx5_ib_ucontext, ibucontext);
 +	struct mlx5_ib_qp *qp;
 +	int err = 0;
 +	u32 uidx = MLX5_IB_DEFAULT_UIDX;
 +	void *dctc;
 +
 +	if (!attr->srq || !attr->recv_cq)
 +		return ERR_PTR(-EINVAL);
 +
 +	err = get_qp_user_index(ucontext, ucmd, sizeof(*ucmd), &uidx);
 +	if (err)
 +		return ERR_PTR(err);
 +
 +	qp = kzalloc(sizeof(*qp), GFP_KERNEL);
 +	if (!qp)
 +		return ERR_PTR(-ENOMEM);
 +
++=======
+ static int create_dct(struct ib_pd *pd, struct mlx5_ib_qp *qp,
+ 		      struct ib_qp_init_attr *attr,
+ 		      struct mlx5_ib_create_qp *ucmd, u32 uidx)
+ {
+ 	void *dctc;
+ 
++>>>>>>> 21aad80b17e6 (RDMA/mlx5: Globally parse DEVX UID)
  	qp->dct.in = kzalloc(MLX5_ST_SZ_BYTES(create_dct_in), GFP_KERNEL);
 -	if (!qp->dct.in)
 -		return -ENOMEM;
 +	if (!qp->dct.in) {
 +		err = -ENOMEM;
 +		goto err_free;
 +	}
  
  	MLX5_SET(create_dct_in, qp->dct.in, uid, to_mpd(pd)->uid);
  	dctc = MLX5_ADDR_OF(create_dct_in, qp->dct.in, dct_context_entry);
@@@ -2729,51 -2368,429 +2750,447 @@@ struct ib_qp *mlx5_ib_create_qp(struct 
  	case IB_QPT_SMI:
  	case MLX5_IB_QPT_HW_GSI:
  	case MLX5_IB_QPT_REG_UMR:
++<<<<<<< HEAD
 +	case MLX5_IB_QPT_DCI:
 +		qp = kzalloc(sizeof(*qp), GFP_KERNEL);
 +		if (!qp)
++=======
+ 	case IB_QPT_DRIVER:
+ 	case IB_QPT_GSI:
+ 		break;
+ 	default:
+ 		goto out;
+ 	}
+ 
+ 	*type = attr->qp_type;
+ 	return 0;
+ 
+ out:
+ 	mlx5_ib_dbg(dev, "Unsupported QP type %d\n", attr->qp_type);
+ 	return -EOPNOTSUPP;
+ }
+ 
+ static int check_valid_flow(struct mlx5_ib_dev *dev, struct ib_pd *pd,
+ 			    struct ib_qp_init_attr *attr,
+ 			    struct ib_udata *udata)
+ {
+ 	struct mlx5_ib_ucontext *ucontext = rdma_udata_to_drv_context(
+ 		udata, struct mlx5_ib_ucontext, ibucontext);
+ 
+ 	if (!udata) {
+ 		/* Kernel create_qp callers */
+ 		if (attr->rwq_ind_tbl)
+ 			return -EOPNOTSUPP;
+ 
+ 		switch (attr->qp_type) {
+ 		case IB_QPT_RAW_PACKET:
+ 		case IB_QPT_DRIVER:
+ 			return -EOPNOTSUPP;
+ 		default:
+ 			return 0;
+ 		}
+ 	}
+ 
+ 	/* Userspace create_qp callers */
+ 	if (attr->qp_type == IB_QPT_RAW_PACKET && !ucontext->cqe_version) {
+ 		mlx5_ib_dbg(dev,
+ 			"Raw Packet QP is only supported for CQE version > 0\n");
+ 		return -EINVAL;
+ 	}
+ 
+ 	if (attr->qp_type != IB_QPT_RAW_PACKET && attr->rwq_ind_tbl) {
+ 		mlx5_ib_dbg(dev,
+ 			    "Wrong QP type %d for the RWQ indirect table\n",
+ 			    attr->qp_type);
+ 		return -EINVAL;
+ 	}
+ 
+ 	switch (attr->qp_type) {
+ 	case IB_QPT_SMI:
+ 	case MLX5_IB_QPT_HW_GSI:
+ 	case MLX5_IB_QPT_REG_UMR:
+ 	case IB_QPT_GSI:
+ 		mlx5_ib_dbg(dev, "Kernel doesn't support QP type %d\n",
+ 			    attr->qp_type);
+ 		return -EINVAL;
+ 	default:
+ 		break;
+ 	}
+ 
+ 	/*
+ 	 * We don't need to see this warning, it means that kernel code
+ 	 * missing ib_pd. Placed here to catch developer's mistakes.
+ 	 */
+ 	WARN_ONCE(!pd && attr->qp_type != IB_QPT_XRC_TGT,
+ 		  "There is a missing PD pointer assignment\n");
+ 	return 0;
+ }
+ 
+ static void process_vendor_flag(struct mlx5_ib_dev *dev, int *flags, int flag,
+ 				bool cond, struct mlx5_ib_qp *qp)
+ {
+ 	if (!(*flags & flag))
+ 		return;
+ 
+ 	if (cond) {
+ 		qp->flags_en |= flag;
+ 		*flags &= ~flag;
+ 		return;
+ 	}
+ 
+ 	if (flag == MLX5_QP_FLAG_SCATTER_CQE) {
+ 		/*
+ 		 * We don't return error if this flag was provided,
+ 		 * and mlx5 doesn't have right capability.
+ 		 */
+ 		*flags &= ~MLX5_QP_FLAG_SCATTER_CQE;
+ 		return;
+ 	}
+ 	mlx5_ib_dbg(dev, "Vendor create QP flag 0x%X is not supported\n", flag);
+ }
+ 
+ static int process_vendor_flags(struct mlx5_ib_dev *dev, struct mlx5_ib_qp *qp,
+ 				void *ucmd, struct ib_qp_init_attr *attr)
+ {
+ 	struct mlx5_core_dev *mdev = dev->mdev;
+ 	bool cond;
+ 	int flags;
+ 
+ 	if (attr->rwq_ind_tbl)
+ 		flags = ((struct mlx5_ib_create_qp_rss *)ucmd)->flags;
+ 	else
+ 		flags = ((struct mlx5_ib_create_qp *)ucmd)->flags;
+ 
+ 	switch (flags & (MLX5_QP_FLAG_TYPE_DCT | MLX5_QP_FLAG_TYPE_DCI)) {
+ 	case MLX5_QP_FLAG_TYPE_DCI:
+ 		qp->type = MLX5_IB_QPT_DCI;
+ 		break;
+ 	case MLX5_QP_FLAG_TYPE_DCT:
+ 		qp->type = MLX5_IB_QPT_DCT;
+ 		break;
+ 	default:
+ 		if (qp->type != IB_QPT_DRIVER)
+ 			break;
+ 		/*
+ 		 * It is IB_QPT_DRIVER and or no subtype or
+ 		 * wrong subtype were provided.
+ 		 */
+ 		return -EINVAL;
+ 	}
+ 
+ 	process_vendor_flag(dev, &flags, MLX5_QP_FLAG_TYPE_DCI, true, qp);
+ 	process_vendor_flag(dev, &flags, MLX5_QP_FLAG_TYPE_DCT, true, qp);
+ 
+ 	process_vendor_flag(dev, &flags, MLX5_QP_FLAG_SIGNATURE, true, qp);
+ 	process_vendor_flag(dev, &flags, MLX5_QP_FLAG_SCATTER_CQE,
+ 			    MLX5_CAP_GEN(mdev, sctr_data_cqe), qp);
+ 
+ 	if (qp->type == IB_QPT_RAW_PACKET) {
+ 		cond = MLX5_CAP_ETH(mdev, tunnel_stateless_vxlan) ||
+ 		       MLX5_CAP_ETH(mdev, tunnel_stateless_gre) ||
+ 		       MLX5_CAP_ETH(mdev, tunnel_stateless_geneve_rx);
+ 		process_vendor_flag(dev, &flags, MLX5_QP_FLAG_TUNNEL_OFFLOADS,
+ 				    cond, qp);
+ 		process_vendor_flag(dev, &flags,
+ 				    MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_UC, true,
+ 				    qp);
+ 		process_vendor_flag(dev, &flags,
+ 				    MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_MC, true,
+ 				    qp);
+ 	}
+ 
+ 	if (qp->type == IB_QPT_RC)
+ 		process_vendor_flag(dev, &flags,
+ 				    MLX5_QP_FLAG_PACKET_BASED_CREDIT_MODE,
+ 				    MLX5_CAP_GEN(mdev, qp_packet_based), qp);
+ 
+ 	process_vendor_flag(dev, &flags, MLX5_QP_FLAG_BFREG_INDEX, true, qp);
+ 	process_vendor_flag(dev, &flags, MLX5_QP_FLAG_UAR_PAGE_INDEX, true, qp);
+ 
+ 	if (flags)
+ 		mlx5_ib_dbg(dev, "udata has unsupported flags 0x%X\n", flags);
+ 
+ 	return (flags) ? -EINVAL : 0;
+ }
+ 
+ static void process_create_flag(struct mlx5_ib_dev *dev, int *flags, int flag,
+ 				bool cond, struct mlx5_ib_qp *qp)
+ {
+ 	if (!(*flags & flag))
+ 		return;
+ 
+ 	if (cond) {
+ 		qp->flags |= flag;
+ 		*flags &= ~flag;
+ 		return;
+ 	}
+ 
+ 	if (flag == MLX5_IB_QP_CREATE_WC_TEST) {
+ 		/*
+ 		 * Special case, if condition didn't meet, it won't be error,
+ 		 * just different in-kernel flow.
+ 		 */
+ 		*flags &= ~MLX5_IB_QP_CREATE_WC_TEST;
+ 		return;
+ 	}
+ 	mlx5_ib_dbg(dev, "Verbs create QP flag 0x%X is not supported\n", flag);
+ }
+ 
+ static int process_create_flags(struct mlx5_ib_dev *dev, struct mlx5_ib_qp *qp,
+ 				struct ib_qp_init_attr *attr)
+ {
+ 	enum ib_qp_type qp_type = qp->type;
+ 	struct mlx5_core_dev *mdev = dev->mdev;
+ 	int create_flags = attr->create_flags;
+ 	bool cond;
+ 
+ 	if (qp_type == MLX5_IB_QPT_DCT)
+ 		return (create_flags) ? -EINVAL : 0;
+ 
+ 	if (qp_type == IB_QPT_RAW_PACKET && attr->rwq_ind_tbl)
+ 		return (create_flags) ? -EINVAL : 0;
+ 
+ 	process_create_flag(dev, &create_flags,
+ 			    IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK,
+ 			    MLX5_CAP_GEN(mdev, block_lb_mc), qp);
+ 	process_create_flag(dev, &create_flags, IB_QP_CREATE_CROSS_CHANNEL,
+ 			    MLX5_CAP_GEN(mdev, cd), qp);
+ 	process_create_flag(dev, &create_flags, IB_QP_CREATE_MANAGED_SEND,
+ 			    MLX5_CAP_GEN(mdev, cd), qp);
+ 	process_create_flag(dev, &create_flags, IB_QP_CREATE_MANAGED_RECV,
+ 			    MLX5_CAP_GEN(mdev, cd), qp);
+ 
+ 	if (qp_type == IB_QPT_UD) {
+ 		process_create_flag(dev, &create_flags,
+ 				    IB_QP_CREATE_IPOIB_UD_LSO,
+ 				    MLX5_CAP_GEN(mdev, ipoib_basic_offloads),
+ 				    qp);
+ 		cond = MLX5_CAP_GEN(mdev, port_type) == MLX5_CAP_PORT_TYPE_IB;
+ 		process_create_flag(dev, &create_flags, IB_QP_CREATE_SOURCE_QPN,
+ 				    cond, qp);
+ 	}
+ 
+ 	if (qp_type == IB_QPT_RAW_PACKET) {
+ 		cond = MLX5_CAP_GEN(mdev, eth_net_offloads) &&
+ 		       MLX5_CAP_ETH(mdev, scatter_fcs);
+ 		process_create_flag(dev, &create_flags,
+ 				    IB_QP_CREATE_SCATTER_FCS, cond, qp);
+ 
+ 		cond = MLX5_CAP_GEN(mdev, eth_net_offloads) &&
+ 		       MLX5_CAP_ETH(mdev, vlan_cap);
+ 		process_create_flag(dev, &create_flags,
+ 				    IB_QP_CREATE_CVLAN_STRIPPING, cond, qp);
+ 	}
+ 
+ 	process_create_flag(dev, &create_flags,
+ 			    IB_QP_CREATE_PCI_WRITE_END_PADDING,
+ 			    MLX5_CAP_GEN(mdev, end_pad), qp);
+ 
+ 	process_create_flag(dev, &create_flags, MLX5_IB_QP_CREATE_WC_TEST,
+ 			    qp_type != MLX5_IB_QPT_REG_UMR, qp);
+ 	process_create_flag(dev, &create_flags, MLX5_IB_QP_CREATE_SQPN_QP1,
+ 			    true, qp);
+ 
+ 	if (create_flags)
+ 		mlx5_ib_dbg(dev, "Create QP has unsupported flags 0x%X\n",
+ 			    create_flags);
+ 
+ 	return (create_flags) ? -EINVAL : 0;
+ }
+ 
+ static size_t process_udata_size(struct ib_qp_init_attr *attr,
+ 				 struct ib_udata *udata)
+ {
+ 	size_t ucmd = sizeof(struct mlx5_ib_create_qp);
+ 	size_t inlen = udata->inlen;
+ 
+ 	if (attr->qp_type == IB_QPT_DRIVER)
+ 		return (inlen < ucmd) ? 0 : ucmd;
+ 
+ 	if (!attr->rwq_ind_tbl)
+ 		return ucmd;
+ 
+ 	if (inlen < offsetofend(struct mlx5_ib_create_qp_rss, flags))
+ 		return 0;
+ 
+ 	ucmd = sizeof(struct mlx5_ib_create_qp_rss);
+ 	if (inlen > ucmd && !ib_is_udata_cleared(udata, ucmd, inlen - ucmd))
+ 		return 0;
+ 
+ 	return min(ucmd, inlen);
+ }
+ 
+ static int create_raw_qp(struct ib_pd *pd, struct mlx5_ib_qp *qp,
+ 			 struct ib_qp_init_attr *attr, void *ucmd,
+ 			 struct ib_udata *udata, u32 uidx)
+ {
+ 	struct mlx5_ib_dev *dev = to_mdev(pd->device);
+ 
+ 	if (attr->rwq_ind_tbl)
+ 		return create_rss_raw_qp_tir(pd, qp, attr, ucmd, udata);
+ 
+ 	return create_qp_common(dev, pd, attr, ucmd, udata, qp, uidx);
+ }
+ 
+ static int check_qp_attr(struct mlx5_ib_dev *dev, struct mlx5_ib_qp *qp,
+ 			 struct ib_qp_init_attr *attr)
+ {
+ 	int ret = 0;
+ 
+ 	switch (qp->type) {
+ 	case MLX5_IB_QPT_DCT:
+ 		ret = (!attr->srq || !attr->recv_cq) ? -EINVAL : 0;
+ 		break;
+ 	case MLX5_IB_QPT_DCI:
+ 		ret = (attr->cap.max_recv_wr || attr->cap.max_recv_sge) ?
+ 			      -EINVAL :
+ 			      0;
+ 		break;
+ 	case IB_QPT_RAW_PACKET:
+ 		ret = (attr->rwq_ind_tbl && attr->send_cq) ? -EINVAL : 0;
+ 		break;
+ 	default:
+ 		break;
+ 	}
+ 
+ 	if (ret)
+ 		mlx5_ib_dbg(dev, "QP type %d has wrong attributes\n", qp->type);
+ 
+ 	return ret;
+ }
+ 
+ static int get_qp_uidx(struct mlx5_ib_qp *qp, struct ib_udata *udata,
+ 		       struct mlx5_ib_create_qp *ucmd,
+ 		       struct ib_qp_init_attr *attr, u32 *uidx)
+ {
+ 	struct mlx5_ib_ucontext *ucontext = rdma_udata_to_drv_context(
+ 		udata, struct mlx5_ib_ucontext, ibucontext);
+ 
+ 	if (attr->rwq_ind_tbl)
+ 		return 0;
+ 
+ 	return get_qp_user_index(ucontext, ucmd, sizeof(*ucmd), uidx);
+ }
+ 
+ struct ib_qp *mlx5_ib_create_qp(struct ib_pd *pd,
+ 				struct ib_qp_init_attr *init_attr,
+ 				struct ib_udata *udata)
+ {
+ 	u32 uidx = MLX5_IB_DEFAULT_UIDX;
+ 	struct mlx5_ib_dev *dev;
+ 	struct mlx5_ib_qp *qp;
+ 	enum ib_qp_type type;
+ 	void *ucmd = NULL;
+ 	u16 xrcdn = 0;
+ 	int err;
+ 
+ 	dev = pd ? to_mdev(pd->device) :
+ 		   to_mdev(to_mxrcd(init_attr->xrcd)->ibxrcd.device);
+ 
+ 	err = check_qp_type(dev, init_attr, &type);
+ 	if (err) {
+ 		mlx5_ib_dbg(dev, "Unsupported QP type %d\n",
+ 			    init_attr->qp_type);
+ 		return ERR_PTR(err);
+ 	}
+ 
+ 	err = check_valid_flow(dev, pd, init_attr, udata);
+ 	if (err)
+ 		return ERR_PTR(err);
+ 
+ 	if (init_attr->qp_type == IB_QPT_GSI)
+ 		return mlx5_ib_gsi_create_qp(pd, init_attr);
+ 
+ 	if (udata) {
+ 		size_t inlen =
+ 			process_udata_size(init_attr, udata);
+ 
+ 		if (!inlen)
+ 			return ERR_PTR(-EINVAL);
+ 
+ 		ucmd = kzalloc(inlen, GFP_KERNEL);
+ 		if (!ucmd)
++>>>>>>> 21aad80b17e6 (RDMA/mlx5: Globally parse DEVX UID)
  			return ERR_PTR(-ENOMEM);
  
 -		err = ib_copy_from_udata(ucmd, udata, inlen);
 -		if (err)
 -			goto free_ucmd;
 -	}
 -
 -	qp = kzalloc(sizeof(*qp), GFP_KERNEL);
 -	if (!qp) {
 -		err = -ENOMEM;
 -		goto free_ucmd;
 -	}
 +		err = create_qp_common(dev, pd, init_attr, udata, qp);
 +		if (err) {
 +			mlx5_ib_dbg(dev, "create_qp_common failed\n");
 +			kfree(qp);
 +			return ERR_PTR(err);
 +		}
  
 +		if (is_qp0(init_attr->qp_type))
 +			qp->ibqp.qp_num = 0;
 +		else if (is_qp1(init_attr->qp_type))
 +			qp->ibqp.qp_num = 1;
 +		else
 +			qp->ibqp.qp_num = qp->trans_qp.base.mqp.qpn;
 +
++<<<<<<< HEAD
 +		mlx5_ib_dbg(dev, "ib qpnum 0x%x, mlx qpn 0x%x, rcqn 0x%x, scqn 0x%x\n",
 +			    qp->ibqp.qp_num, qp->trans_qp.base.mqp.qpn,
 +			    init_attr->recv_cq ? to_mcq(init_attr->recv_cq)->mcq.cqn : -1,
 +			    init_attr->send_cq ? to_mcq(init_attr->send_cq)->mcq.cqn : -1);
++=======
+ 	qp->type = type;
+ 	if (udata) {
+ 		err = process_vendor_flags(dev, qp, ucmd, init_attr);
+ 		if (err)
+ 			goto free_qp;
+ 
+ 		err = get_qp_uidx(qp, udata, ucmd, init_attr, &uidx);
+ 		if (err)
+ 			goto free_qp;
+ 	}
+ 	err = process_create_flags(dev, qp, init_attr);
+ 	if (err)
+ 		goto free_qp;
++>>>>>>> 21aad80b17e6 (RDMA/mlx5: Globally parse DEVX UID)
  
 -	if (qp->type == IB_QPT_XRC_TGT)
 -		xrcdn = to_mxrcd(init_attr->xrcd)->xrcdn;
 +		qp->trans_qp.xrcdn = xrcdn;
  
++<<<<<<< HEAD
++=======
+ 	err = check_qp_attr(dev, qp, init_attr);
+ 	if (err)
+ 		goto free_qp;
+ 
+ 	switch (qp->type) {
+ 	case IB_QPT_RAW_PACKET:
+ 		err = create_raw_qp(pd, qp, init_attr, ucmd, udata, uidx);
+ 		break;
+ 	case MLX5_IB_QPT_DCT:
+ 		err = create_dct(pd, qp, init_attr, ucmd, uidx);
++>>>>>>> 21aad80b17e6 (RDMA/mlx5: Globally parse DEVX UID)
  		break;
 +
 +	case IB_QPT_GSI:
 +		return mlx5_ib_gsi_create_qp(pd, init_attr);
 +
 +	case IB_QPT_RAW_IPV6:
 +	case IB_QPT_RAW_ETHERTYPE:
 +	case IB_QPT_MAX:
  	default:
++<<<<<<< HEAD
 +		mlx5_ib_dbg(dev, "unsupported qp type %d\n",
 +			    init_attr->qp_type);
 +		/* Don't support raw QPs */
 +		return ERR_PTR(-EINVAL);
++=======
+ 		err = create_qp_common(dev, pd, init_attr, ucmd, udata, qp,
+ 				       uidx);
+ 	}
+ 	if (err) {
+ 		mlx5_ib_dbg(dev, "create_qp_common failed\n");
+ 		goto free_qp;
++>>>>>>> 21aad80b17e6 (RDMA/mlx5: Globally parse DEVX UID)
  	}
  
 -	kfree(ucmd);
 -
 -	if (is_qp0(init_attr->qp_type))
 -		qp->ibqp.qp_num = 0;
 -	else if (is_qp1(init_attr->qp_type))
 -		qp->ibqp.qp_num = 1;
 -	else
 -		qp->ibqp.qp_num = qp->trans_qp.base.mqp.qpn;
 -
 -	qp->trans_qp.xrcdn = xrcdn;
 +	if (verbs_init_attr->qp_type == IB_QPT_DRIVER)
 +		qp->qp_sub_type = init_attr->qp_type;
  
  	return &qp->ibqp;
 -
 -free_qp:
 -	kfree(qp);
 -free_ucmd:
 -	kfree(ucmd);
 -	return ERR_PTR(err);
  }
  
  static int mlx5_ib_destroy_dct(struct mlx5_ib_qp *mqp)
* Unmerged path drivers/infiniband/hw/mlx5/qp.c
