arm64: cpufeature: add cpus_have_final_cap()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
Rebuild_CHGLOG: - [arm64] cpufeature: add cpus_have_final_cap() (Auger Eric) [1882794]
Rebuild_FUZZ: 91.36%
commit-author Mark Rutland <mark.rutland@arm.com>
commit 1db5cdeccd813330aaab19b3fccab15e1d07fe12
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/1db5cdec.failed

When cpus_have_const_cap() was originally introduced it was intended to
be safe in hyp context, where it is not safe to access the cpu_hwcaps
array as cpus_have_cap() did. For more details see commit:

  a4023f682739439b ("arm64: Add hypervisor safe helper for checking constant capabilities")

We then made use of cpus_have_const_cap() throughout the kernel.

Subsequently, we had to defer updating the static_key associated with
each capability in order to avoid lockdep complaints. To avoid breaking
kernel-wide usage of cpus_have_const_cap(), this was updated to fall
back to the cpu_hwcaps array if called before the static_keys were
updated. As the kvm hyp code was only called later than this, the
fallback is redundant but not functionally harmful. For more details,
see commit:

  63a1e1c95e60e798 ("arm64/cpufeature: don't use mutex in bringup path")

Today we have more users of cpus_have_const_cap() which are only called
once the relevant static keys are initialized, and it would be
beneficial to avoid the redundant code.

To that end, this patch adds a new cpus_have_final_cap(), helper which
is intend to be used in code which is only run once capabilities have
been finalized, and will never check the cpus_hwcap array. This helps
the compiler to generate better code as it no longer needs to generate
code to address and test the cpus_hwcap array. To help catch misuse,
cpus_have_final_cap() will BUG() if called before capabilities are
finalized.

In hyp context, BUG() will result in a hyp panic, but the specific BUG()
instance will not be identified in the usual way.

Comments are added to the various cpus_have_*_cap() helpers to describe
the constraints on when they can be used. For clarity cpus_have_cap() is
moved above the other helpers. Similarly the helpers are updated to use
system_capabilities_finalized() consistently, and this is made
__always_inline as required by its new callers.

	Signed-off-by: Mark Rutland <mark.rutland@arm.com>
	Reviewed-by: Marc Zyngier <maz@kernel.org>
	Reviewed-by: Suzuki K Poulose <suzuki.poulose@arm.com>
	Cc: Will Deacon <will@kernel.org>
	Signed-off-by: Catalin Marinas <catalin.marinas@arm.com>
(cherry picked from commit 1db5cdeccd813330aaab19b3fccab15e1d07fe12)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/cpufeature.h
diff --cc arch/arm64/include/asm/cpufeature.h
index 970b7ff7af55,940b2b67b428..000000000000
--- a/arch/arm64/include/asm/cpufeature.h
+++ b/arch/arm64/include/asm/cpufeature.h
@@@ -399,20 -382,24 +399,22 @@@ extern DECLARE_BITMAP(boot_capabilities
  	for_each_set_bit(cap, cpu_hwcaps, ARM64_NCAPS)
  
  bool this_cpu_has_cap(unsigned int cap);
 -void cpu_set_feature(unsigned int num);
 -bool cpu_have_feature(unsigned int num);
 -unsigned long cpu_get_elf_hwcap(void);
 -unsigned long cpu_get_elf_hwcap2(void);
  
 -#define cpu_set_named_feature(name) cpu_set_feature(cpu_feature(name))
 -#define cpu_have_named_feature(name) cpu_have_feature(cpu_feature(name))
 +static inline bool cpu_have_feature(unsigned int num)
 +{
 +	return elf_hwcap & (1UL << num);
 +}
  
- /* System capability check for constant caps */
- static __always_inline bool __cpus_have_const_cap(int num)
+ static __always_inline bool system_capabilities_finalized(void)
  {
- 	if (num >= ARM64_NCAPS)
- 		return false;
- 	return static_branch_unlikely(&cpu_hwcap_keys[num]);
+ 	return static_branch_likely(&arm64_const_caps_ready);
  }
  
+ /*
+  * Test for a capability with a runtime check.
+  *
+  * Before the capability is detected, this returns false.
+  */
  static inline bool cpus_have_cap(unsigned int num)
  {
  	if (num >= ARM64_NCAPS)
@@@ -657,6 -654,12 +698,15 @@@ static inline bool system_has_prio_mask
  	       system_uses_irq_prio_masking();
  }
  
++<<<<<<< HEAD
++=======
+ #define ARM64_BP_HARDEN_UNKNOWN		-1
+ #define ARM64_BP_HARDEN_WA_NEEDED	0
+ #define ARM64_BP_HARDEN_NOT_REQUIRED	1
+ 
+ int get_spectre_v2_workaround_state(void);
+ 
++>>>>>>> 1db5cdeccd81 (arm64: cpufeature: add cpus_have_final_cap())
  #define ARM64_SSBD_UNKNOWN		-1
  #define ARM64_SSBD_FORCE_DISABLE	0
  #define ARM64_SSBD_KERNEL		1
* Unmerged path arch/arm64/include/asm/cpufeature.h
