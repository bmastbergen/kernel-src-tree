cpufreq: intel_pstate: Update cached EPP in the active mode

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Rafael J. Wysocki <rafael.j.wysocki@intel.com>
commit c27a0ccc3c715c55fea6709eab2f9c6f551fcfaa
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/c27a0ccc.failed

Make intel_pstate update the cached EPP value when setting the EPP
via sysfs in the active mode just like it is the case in the passive
mode, for consistency, but also for the benefit of subsequent
changes.

No intentional functional impact.

	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
	Acked-by: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
(cherry picked from commit c27a0ccc3c715c55fea6709eab2f9c6f551fcfaa)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/intel_pstate.c
diff --cc drivers/cpufreq/intel_pstate.c
index 46665cfef5ca,e540448e0bd0..000000000000
--- a/drivers/cpufreq/intel_pstate.c
+++ b/drivers/cpufreq/intel_pstate.c
@@@ -643,6 -642,32 +643,35 @@@ static int intel_pstate_get_energy_pref
  	return index;
  }
  
++<<<<<<< HEAD
++=======
+ static int intel_pstate_set_epp(struct cpudata *cpu, u32 epp)
+ {
+ 	int ret;
+ 
+ 	/*
+ 	 * Use the cached HWP Request MSR value, because in the active mode the
+ 	 * register itself may be updated by intel_pstate_hwp_boost_up() or
+ 	 * intel_pstate_hwp_boost_down() at any time.
+ 	 */
+ 	u64 value = READ_ONCE(cpu->hwp_req_cached);
+ 
+ 	value &= ~GENMASK_ULL(31, 24);
+ 	value |= (u64)epp << 24;
+ 	/*
+ 	 * The only other updater of hwp_req_cached in the active mode,
+ 	 * intel_pstate_hwp_set(), is called under the same lock as this
+ 	 * function, so it cannot run in parallel with the update below.
+ 	 */
+ 	WRITE_ONCE(cpu->hwp_req_cached, value);
+ 	ret = wrmsrl_on_cpu(cpu->cpu, MSR_HWP_REQUEST, value);
+ 	if (!ret)
+ 		cpu->epp_cached = epp;
+ 
+ 	return ret;
+ }
+ 
++>>>>>>> c27a0ccc3c71 (cpufreq: intel_pstate: Update cached EPP in the active mode)
  static int intel_pstate_set_energy_pref_index(struct cpudata *cpu_data,
  					      int pref_index, bool use_raw,
  					      u32 raw_epp)
@@@ -729,11 -740,38 +758,36 @@@ static ssize_t store_energy_performance
  		raw = true;
  	}
  
 -	/*
 -	 * This function runs with the policy R/W semaphore held, which
 -	 * guarantees that the driver pointer will not change while it is
 -	 * running.
 -	 */
 -	if (!intel_pstate_driver)
 -		return -EAGAIN;
 -
  	mutex_lock(&intel_pstate_limits_lock);
  
++<<<<<<< HEAD
 +	ret = intel_pstate_set_energy_pref_index(cpu_data, ret, raw, epp);
 +	if (!ret)
 +		ret = count;
++=======
+ 	if (intel_pstate_driver == &intel_pstate) {
+ 		ret = intel_pstate_set_energy_pref_index(cpu, ret, raw, epp);
+ 	} else {
+ 		/*
+ 		 * In the passive mode the governor needs to be stopped on the
+ 		 * target CPU before the EPP update and restarted after it,
+ 		 * which is super-heavy-weight, so make sure it is worth doing
+ 		 * upfront.
+ 		 */
+ 		if (!raw)
+ 			epp = ret ? epp_values[ret - 1] : cpu->epp_default;
+ 
+ 		if (cpu->epp_cached != epp) {
+ 			int err;
+ 
+ 			cpufreq_stop_governor(policy);
+ 			ret = intel_pstate_set_epp(cpu, epp);
+ 			err = cpufreq_start_governor(policy);
+ 			if (!ret)
+ 				ret = err;
+ 		}
+ 	}
++>>>>>>> c27a0ccc3c71 (cpufreq: intel_pstate: Update cached EPP in the active mode)
  
  	mutex_unlock(&intel_pstate_limits_lock);
  
@@@ -2477,10 -2588,18 +2537,18 @@@ static int intel_cpufreq_cpu_init(struc
  
  	cpu = all_cpu_data[policy->cpu];
  
 -	if (hwp_active) {
 -		u64 value;
 -
 +	if (hwp_active)
  		intel_pstate_get_hwp_max(policy->cpu, &turbo_max, &max_state);
++<<<<<<< HEAD
 +	else
++=======
+ 		policy->transition_delay_us = INTEL_CPUFREQ_TRANSITION_DELAY_HWP;
+ 		rdmsrl_on_cpu(cpu->cpu, MSR_HWP_REQUEST, &value);
+ 		WRITE_ONCE(cpu->hwp_req_cached, value);
+ 		cpu->epp_cached = intel_pstate_get_epp(cpu, value);
+ 	} else {
++>>>>>>> c27a0ccc3c71 (cpufreq: intel_pstate: Update cached EPP in the active mode)
  		turbo_max = cpu->pstate.turbo_pstate;
 -		policy->transition_delay_us = INTEL_CPUFREQ_TRANSITION_DELAY;
 -	}
  
  	min_freq = DIV_ROUND_UP(turbo_max * global.min_perf_pct, 100);
  	min_freq *= cpu->pstate.scaling;
* Unmerged path drivers/cpufreq/intel_pstate.c
