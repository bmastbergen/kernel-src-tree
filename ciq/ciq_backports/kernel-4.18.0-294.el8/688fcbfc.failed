mm/vmalloc: modify struct vmap_area to reduce its size

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Pengfei Li <lpf.vector@gmail.com>
commit 688fcbfc06e4fdfbb7e1d5a942a1460fe6379d2d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/688fcbfc.failed

Objective
---------

The current implementation of struct vmap_area wasted space.

After applying this commit, sizeof(struct vmap_area) has been
reduced from 11 words to 8 words.

Description
-----------

1) Pack "subtree_max_size", "vm" and "purge_list".  This is no problem
   because

A) "subtree_max_size" is only used when vmap_area is in "free" tree

B) "vm" is only used when vmap_area is in "busy" tree

C) "purge_list" is only used when vmap_area is in vmap_purge_list

2) Eliminate "flags".

;Since only one flag VM_VM_AREA is being used, and the same thing can be
done by judging whether "vm" is NULL, then the "flags" can be eliminated.

Link: http://lkml.kernel.org/r/20190716152656.12255-3-lpf.vector@gmail.com
	Signed-off-by: Pengfei Li <lpf.vector@gmail.com>
	Suggested-by: Uladzislau Rezki (Sony) <urezki@gmail.com>
	Reviewed-by: Uladzislau Rezki (Sony) <urezki@gmail.com>
	Cc: Hillf Danton <hdanton@sina.com>
	Cc: Matthew Wilcox <willy@infradead.org>
	Cc: Michal Hocko <mhocko@suse.com>
	Cc: Oleksiy Avramchenko <oleksiy.avramchenko@sonymobile.com>
	Cc: Roman Gushchin <guro@fb.com>
	Cc: Steven Rostedt <rostedt@goodmis.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 688fcbfc06e4fdfbb7e1d5a942a1460fe6379d2d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/vmalloc.h
#	mm/vmalloc.c
diff --cc include/linux/vmalloc.h
index 54492b1d76f1,4e7809408073..000000000000
--- a/include/linux/vmalloc.h
+++ b/include/linux/vmalloc.h
@@@ -52,12 -52,22 +52,31 @@@ struct vm_struct 
  struct vmap_area {
  	unsigned long va_start;
  	unsigned long va_end;
++<<<<<<< HEAD
 +	unsigned long flags;
 +	struct rb_node rb_node;         /* address sorted rbtree */
 +	struct list_head list;          /* address sorted list */
 +	struct llist_node purge_list;    /* "lazy purge" list */
 +	struct vm_struct *vm;
 +	struct rcu_head rcu_head;
++=======
+ 
+ 	struct rb_node rb_node;         /* address sorted rbtree */
+ 	struct list_head list;          /* address sorted list */
+ 
+ 	/*
+ 	 * The following three variables can be packed, because
+ 	 * a vmap_area object is always one of the three states:
+ 	 *    1) in "free" tree (root is vmap_area_root)
+ 	 *    2) in "busy" tree (root is free_vmap_area_root)
+ 	 *    3) in purge list  (head is vmap_purge_list)
+ 	 */
+ 	union {
+ 		unsigned long subtree_max_size; /* in "free" tree */
+ 		struct vm_struct *vm;           /* in "busy" tree */
+ 		struct llist_node purge_list;   /* in purge list */
+ 	};
++>>>>>>> 688fcbfc06e4 (mm/vmalloc: modify struct vmap_area to reduce its size)
  };
  
  /*
diff --cc mm/vmalloc.c
index c82a0db1aefc,f095843fc243..000000000000
--- a/mm/vmalloc.c
+++ b/mm/vmalloc.c
@@@ -327,8 -326,9 +327,14 @@@ EXPORT_SYMBOL(vmalloc_to_pfn)
  
  /*** Global kva allocator ***/
  
++<<<<<<< HEAD
 +#define VM_LAZY_FREE	0x02
 +#define VM_VM_AREA	0x04
++=======
+ #define DEBUG_AUGMENT_PROPAGATE_CHECK 0
+ #define DEBUG_AUGMENT_LOWEST_MATCH_CHECK 0
+ 
++>>>>>>> 688fcbfc06e4 (mm/vmalloc: modify struct vmap_area to reduce its size)
  
  static DEFINE_SPINLOCK(vmap_area_lock);
  /* Export for kexec only */
@@@ -507,9 -1114,9 +513,15 @@@ found
  
  	va->va_start = addr;
  	va->va_end = addr + size;
++<<<<<<< HEAD
 +	va->flags = 0;
 +	__insert_vmap_area(va);
 +	free_vmap_cache = &va->rb_node;
++=======
+ 	va->vm = NULL;
+ 	insert_vmap_area(va, &vmap_area_root, &vmap_area_list);
+ 
++>>>>>>> 688fcbfc06e4 (mm/vmalloc: modify struct vmap_area to reduce its size)
  	spin_unlock(&vmap_area_lock);
  
  	BUG_ON(!IS_ALIGNED(va->va_start, align));
@@@ -1280,8 -1923,10 +1292,15 @@@ void __init vmalloc_init(void
  
  	/* Import existing vmlist entries. */
  	for (tmp = vmlist; tmp; tmp = tmp->next) {
++<<<<<<< HEAD
 +		va = kzalloc(sizeof(struct vmap_area), GFP_NOWAIT);
 +		va->flags = VM_VM_AREA;
++=======
+ 		va = kmem_cache_zalloc(vmap_area_cachep, GFP_NOWAIT);
+ 		if (WARN_ON_ONCE(!va))
+ 			continue;
+ 
++>>>>>>> 688fcbfc06e4 (mm/vmalloc: modify struct vmap_area to reduce its size)
  		va->va_start = (unsigned long)tmp->addr;
  		va->va_end = va->va_start + tmp->size;
  		va->vm = tmp;
@@@ -1498,14 -2150,12 +1516,23 @@@ struct vm_struct *remove_vm_area(const 
  
  	might_sleep();
  
++<<<<<<< HEAD
 +	va = find_vmap_area((unsigned long)addr);
 +	if (va && va->flags & VM_VM_AREA) {
++=======
+ 	spin_lock(&vmap_area_lock);
+ 	va = __find_vmap_area((unsigned long)addr);
+ 	if (va && va->vm) {
++>>>>>>> 688fcbfc06e4 (mm/vmalloc: modify struct vmap_area to reduce its size)
  		struct vm_struct *vm = va->vm;
  
 +		spin_lock(&vmap_area_lock);
  		va->vm = NULL;
++<<<<<<< HEAD
 +		va->flags &= ~VM_VM_AREA;
 +		va->flags |= VM_LAZY_FREE;
++=======
++>>>>>>> 688fcbfc06e4 (mm/vmalloc: modify struct vmap_area to reduce its size)
  		spin_unlock(&vmap_area_lock);
  
  		kasan_free_shadow(vm);
@@@ -2801,14 -3481,13 +2828,19 @@@ static int s_show(struct seq_file *m, v
  	va = list_entry(p, struct vmap_area, list);
  
  	/*
- 	 * s_show can encounter race with remove_vm_area, !VM_VM_AREA on
- 	 * behalf of vmap area is being tear down or vm_map_ram allocation.
+ 	 * s_show can encounter race with remove_vm_area, !vm on behalf
+ 	 * of vmap area is being tear down or vm_map_ram allocation.
  	 */
++<<<<<<< HEAD
 +	if (!(va->flags & VM_VM_AREA)) {
 +		seq_printf(m, "0x%pK-0x%pK %7ld %s\n",
++=======
+ 	if (!va->vm) {
+ 		seq_printf(m, "0x%pK-0x%pK %7ld vm_map_ram\n",
++>>>>>>> 688fcbfc06e4 (mm/vmalloc: modify struct vmap_area to reduce its size)
  			(void *)va->va_start, (void *)va->va_end,
 -			va->va_end - va->va_start);
 +			va->va_end - va->va_start,
 +			va->flags & VM_LAZY_FREE ? "unpurged vm_area" : "vm_map_ram");
  
  		return 0;
  	}
* Unmerged path include/linux/vmalloc.h
* Unmerged path mm/vmalloc.c
