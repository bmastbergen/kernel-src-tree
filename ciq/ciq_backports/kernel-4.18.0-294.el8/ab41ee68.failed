mm: migrate: drop unused argument of migrate_page_move_mapping()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Jan Kara <jack@suse.cz>
commit ab41ee6879981b3d3a16a1079a33fa6fd043eb3c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/ab41ee68.failed

All callers of migrate_page_move_mapping() now pass NULL for 'head'
argument.  Drop it.

Link: http://lkml.kernel.org/r/20181211172143.7358-7-jack@suse.cz
	Signed-off-by: Jan Kara <jack@suse.cz>
	Acked-by: Mel Gorman <mgorman@suse.de>
	Cc: Michal Hocko <mhocko@suse.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit ab41ee6879981b3d3a16a1079a33fa6fd043eb3c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/iomap.c
#	mm/migrate.c
diff --cc mm/migrate.c
index 60059875287d,4389696fba0e..000000000000
--- a/mm/migrate.c
+++ b/mm/migrate.c
@@@ -446,14 -399,13 +446,13 @@@ static int expected_page_refs(struct ad
   * 3 for pages with a mapping and PagePrivate/PagePrivate2 set.
   */
  int migrate_page_move_mapping(struct address_space *mapping,
- 		struct page *newpage, struct page *page,
- 		struct buffer_head *head, enum migrate_mode mode,
+ 		struct page *newpage, struct page *page, enum migrate_mode mode,
  		int extra_count)
  {
 -	XA_STATE(xas, &mapping->i_pages, page_index(page));
  	struct zone *oldzone, *newzone;
  	int dirty;
 -	int expected_count = expected_page_refs(page) + extra_count;
 +	void **pslot;
 +	int expected_count = expected_page_refs(mapping, page) + extra_count;
  
  	if (!mapping) {
  		/* Anonymous page without mapping */
@@@ -789,20 -753,45 +788,47 @@@ int buffer_migrate_page(struct address_
  	if (!page_has_buffers(page))
  		return migrate_page(mapping, newpage, page, mode);
  
 -	/* Check whether page does not have extra refs before we do more work */
 -	expected_count = expected_page_refs(page);
 -	if (page_count(page) != expected_count)
 -		return -EAGAIN;
 -
  	head = page_buffers(page);
 -	if (!buffer_migrate_lock_buffers(head, mode))
 -		return -EAGAIN;
  
 -	if (check_refs) {
 -		bool busy;
 -		bool invalidated = false;
 +	rc = migrate_page_move_mapping(mapping, newpage, page, head, mode, 0);
  
++<<<<<<< HEAD
++=======
+ recheck_buffers:
+ 		busy = false;
+ 		spin_lock(&mapping->private_lock);
+ 		bh = head;
+ 		do {
+ 			if (atomic_read(&bh->b_count)) {
+ 				busy = true;
+ 				break;
+ 			}
+ 			bh = bh->b_this_page;
+ 		} while (bh != head);
+ 		spin_unlock(&mapping->private_lock);
+ 		if (busy) {
+ 			if (invalidated) {
+ 				rc = -EAGAIN;
+ 				goto unlock_buffers;
+ 			}
+ 			invalidate_bh_lrus();
+ 			invalidated = true;
+ 			goto recheck_buffers;
+ 		}
+ 	}
+ 
+ 	rc = migrate_page_move_mapping(mapping, newpage, page, mode, 0);
++>>>>>>> ab41ee687998 (mm: migrate: drop unused argument of migrate_page_move_mapping())
  	if (rc != MIGRATEPAGE_SUCCESS)
 -		goto unlock_buffers;
 +		return rc;
 +
 +	/*
 +	 * In the async case, migrate_page_move_mapping locked the buffers
 +	 * with an IRQ-safe spinlock held. In the sync case, the buffers
 +	 * need to be locked now
 +	 */
 +	if (mode != MIGRATE_ASYNC)
 +		BUG_ON(!buffer_migrate_lock_buffers(head, mode));
  
  	ClearPagePrivate(page);
  	set_page_private(newpage, page_private(page));
* Unmerged path fs/iomap.c
diff --git a/fs/aio.c b/fs/aio.c
index 64d7c2f91509..28a9e36638f1 100644
--- a/fs/aio.c
+++ b/fs/aio.c
@@ -394,7 +394,7 @@ static int aio_migratepage(struct address_space *mapping, struct page *new,
 	BUG_ON(PageWriteback(old));
 	get_page(new);
 
-	rc = migrate_page_move_mapping(mapping, new, old, NULL, mode, 1);
+	rc = migrate_page_move_mapping(mapping, new, old, mode, 1);
 	if (rc != MIGRATEPAGE_SUCCESS) {
 		put_page(new);
 		goto out_unlock;
diff --git a/fs/f2fs/data.c b/fs/f2fs/data.c
index 8f931d699287..672eaa3603dd 100644
--- a/fs/f2fs/data.c
+++ b/fs/f2fs/data.c
@@ -2551,7 +2551,7 @@ int f2fs_migrate_page(struct address_space *mapping,
 	 */
 	extra_count = (atomic_written ? 1 : 0) - page_has_private(page);
 	rc = migrate_page_move_mapping(mapping, newpage,
-				page, NULL, mode, extra_count);
+				page, mode, extra_count);
 	if (rc != MIGRATEPAGE_SUCCESS) {
 		if (atomic_written)
 			mutex_unlock(&fi->inmem_lock);
* Unmerged path fs/iomap.c
diff --git a/fs/ubifs/file.c b/fs/ubifs/file.c
index 79fcb1ae51c6..7f82b160aa83 100644
--- a/fs/ubifs/file.c
+++ b/fs/ubifs/file.c
@@ -1475,7 +1475,7 @@ static int ubifs_migrate_page(struct address_space *mapping,
 {
 	int rc;
 
-	rc = migrate_page_move_mapping(mapping, newpage, page, NULL, mode, 0);
+	rc = migrate_page_move_mapping(mapping, newpage, page, mode, 0);
 	if (rc != MIGRATEPAGE_SUCCESS)
 		return rc;
 
diff --git a/include/linux/migrate.h b/include/linux/migrate.h
index 938271a0b951..0c4ff6cb22a4 100644
--- a/include/linux/migrate.h
+++ b/include/linux/migrate.h
@@ -77,8 +77,7 @@ extern void migrate_page_copy(struct page *newpage, struct page *page);
 extern int migrate_huge_page_move_mapping(struct address_space *mapping,
 				  struct page *newpage, struct page *page);
 extern int migrate_page_move_mapping(struct address_space *mapping,
-		struct page *newpage, struct page *page,
-		struct buffer_head *head, enum migrate_mode mode,
+		struct page *newpage, struct page *page, enum migrate_mode mode,
 		int extra_count);
 #else
 
* Unmerged path mm/migrate.c
