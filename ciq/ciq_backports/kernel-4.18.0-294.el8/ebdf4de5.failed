mm: migrate: fix reference check race between __find_get_block() and migration

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Jan Kara <jack@suse.cz>
commit ebdf4de5642fb6580b0763158b6b4b791c4d6a4d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/ebdf4de5.failed

buffer_migrate_page_norefs() can race with bh users in the following
way:

CPU1                                    CPU2
buffer_migrate_page_norefs()
  buffer_migrate_lock_buffers()
  checks bh refs
  spin_unlock(&mapping->private_lock)
                                        __find_get_block()
                                          spin_lock(&mapping->private_lock)
                                          grab bh ref
                                          spin_unlock(&mapping->private_lock)
  move page                               do bh work

This can result in various issues like lost updates to buffers (i.e.
metadata corruption) or use after free issues for the old page.

This patch closes the race by holding mapping->private_lock while the
mapping is being moved to a new page.  Ordinarily, a reference can be
taken outside of the private_lock using the per-cpu BH LRU but the
references are checked and the LRU invalidated if necessary.  The
private_lock is held once the references are known so the buffer lookup
slow path will spin on the private_lock.  Between the page lock and
private_lock, it should be impossible for other references to be
acquired and updates to happen during the migration.

A user had reported data corruption issues on a distribution kernel with
a similar page migration implementation as mainline.  The data
corruption could not be reproduced with this patch applied.  A small
number of migration-intensive tests were run and no performance problems
were noted.

[mgorman@techsingularity.net: Changelog, removed tracing]
Link: http://lkml.kernel.org/r/20190718090238.GF24383@techsingularity.net
Fixes: 89cb0888ca14 "mm: migrate: provide buffer_migrate_page_norefs()"
	Signed-off-by: Jan Kara <jack@suse.cz>
	Signed-off-by: Mel Gorman <mgorman@techsingularity.net>
	Cc: <stable@vger.kernel.org>	[5.0+]
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit ebdf4de5642fb6580b0763158b6b4b791c4d6a4d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/migrate.c
diff --cc mm/migrate.c
index 5628f1102c6a,515718392b24..000000000000
--- a/mm/migrate.c
+++ b/mm/migrate.c
@@@ -789,20 -743,45 +789,47 @@@ int buffer_migrate_page(struct address_
  	if (!page_has_buffers(page))
  		return migrate_page(mapping, newpage, page, mode);
  
 -	/* Check whether page does not have extra refs before we do more work */
 -	expected_count = expected_page_refs(mapping, page);
 -	if (page_count(page) != expected_count)
 -		return -EAGAIN;
 -
  	head = page_buffers(page);
 -	if (!buffer_migrate_lock_buffers(head, mode))
 -		return -EAGAIN;
  
 -	if (check_refs) {
 -		bool busy;
 -		bool invalidated = false;
 +	rc = migrate_page_move_mapping(mapping, newpage, page, head, mode, 0);
  
++<<<<<<< HEAD
++=======
+ recheck_buffers:
+ 		busy = false;
+ 		spin_lock(&mapping->private_lock);
+ 		bh = head;
+ 		do {
+ 			if (atomic_read(&bh->b_count)) {
+ 				busy = true;
+ 				break;
+ 			}
+ 			bh = bh->b_this_page;
+ 		} while (bh != head);
+ 		if (busy) {
+ 			if (invalidated) {
+ 				rc = -EAGAIN;
+ 				goto unlock_buffers;
+ 			}
+ 			spin_unlock(&mapping->private_lock);
+ 			invalidate_bh_lrus();
+ 			invalidated = true;
+ 			goto recheck_buffers;
+ 		}
+ 	}
+ 
+ 	rc = migrate_page_move_mapping(mapping, newpage, page, 0);
++>>>>>>> ebdf4de5642f (mm: migrate: fix reference check race between __find_get_block() and migration)
  	if (rc != MIGRATEPAGE_SUCCESS)
 -		goto unlock_buffers;
 +		return rc;
 +
 +	/*
 +	 * In the async case, migrate_page_move_mapping locked the buffers
 +	 * with an IRQ-safe spinlock held. In the sync case, the buffers
 +	 * need to be locked now
 +	 */
 +	if (mode != MIGRATE_ASYNC)
 +		BUG_ON(!buffer_migrate_lock_buffers(head, mode));
  
  	ClearPagePrivate(page);
  	set_page_private(newpage, page_private(page));
@@@ -824,6 -803,10 +851,13 @@@
  	else
  		migrate_page_states(newpage, page);
  
++<<<<<<< HEAD
++=======
+ 	rc = MIGRATEPAGE_SUCCESS;
+ unlock_buffers:
+ 	if (check_refs)
+ 		spin_unlock(&mapping->private_lock);
++>>>>>>> ebdf4de5642f (mm: migrate: fix reference check race between __find_get_block() and migration)
  	bh = head;
  	do {
  		unlock_buffer(bh);
* Unmerged path mm/migrate.c
