x86/cpu: Prepare TSS.IST setup for guard pages

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit f6ef73224a0f0400c3979c8bc68b383f9d2eb9d8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/f6ef7322.failed

Convert the TSS.IST setup code to use the cpu entry area information
directly instead of assuming a linear mapping of the IST stacks.

The store to orig_ist[] is no longer required as there are no users
anymore.

This is the last preparatory step towards IST guard pages.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: "Chang S. Bae" <chang.seok.bae@intel.com>
	Cc: Dominik Brodowski <linux@dominikbrodowski.net>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: Josh Poimboeuf <jpoimboe@redhat.com>
	Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Sean Christopherson <sean.j.christopherson@intel.com>
	Cc: x86-ml <x86@kernel.org>
Link: https://lkml.kernel.org/r/20190414160145.061686012@linutronix.de
(cherry picked from commit f6ef73224a0f0400c3979c8bc68b383f9d2eb9d8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/common.c
diff --cc arch/x86/kernel/cpu/common.c
index de68c4e62909,4b01b71415f5..000000000000
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@@ -514,19 -507,6 +514,22 @@@ void load_percpu_segment(int cpu
  DEFINE_PER_CPU(struct cpu_entry_area *, cpu_entry_area);
  #endif
  
++<<<<<<< HEAD
 +#ifdef CONFIG_X86_64
 +/*
 + * Special IST stacks which the CPU switches to when it calls
 + * an IST-marked descriptor entry. Up to 7 stacks (hardware
 + * limit), all of them are 4K, except the debug stack which
 + * is 8K.
 + */
 +static const unsigned int exception_stack_sizes[N_EXCEPTION_STACKS] = {
 +	  [0 ... N_EXCEPTION_STACKS - 1]	= EXCEPTION_STKSZ,
 +	  [DEBUG_STACK - 1]			= DEBUG_STKSZ
 +};
 +#endif
 +
++=======
++>>>>>>> f6ef73224a0f (x86/cpu: Prepare TSS.IST setup for guard pages)
  /* Load the original GDT from the per-cpu structure */
  void load_direct_gdt(int cpu)
  {
@@@ -1842,16 -1736,12 +1841,25 @@@ void cpu_init(void
  	/*
  	 * set up and load the per-CPU TSS
  	 */
++<<<<<<< HEAD
 +	if (!oist->ist[0]) {
 +		char *estacks = get_cpu_entry_area(cpu)->exception_stacks;
 +
 +		for (v = 0; v < N_EXCEPTION_STACKS; v++) {
 +			estacks += exception_stack_sizes[v];
 +			oist->ist[v] = t->x86_tss.ist[v] =
 +					(unsigned long)estacks;
 +			if (v == DEBUG_STACK-1)
 +				per_cpu(debug_stack_addr, cpu) = (unsigned long)estacks;
 +		}
++=======
+ 	if (!t->x86_tss.ist[0]) {
+ 		t->x86_tss.ist[ESTACK_DF] = __this_cpu_ist_top_va(DF);
+ 		t->x86_tss.ist[ESTACK_NMI] = __this_cpu_ist_top_va(NMI);
+ 		t->x86_tss.ist[ESTACK_DB] = __this_cpu_ist_top_va(DB);
+ 		t->x86_tss.ist[ESTACK_MCE] = __this_cpu_ist_top_va(MCE);
+ 		per_cpu(debug_stack_addr, cpu) = t->x86_tss.ist[ESTACK_DB];
++>>>>>>> f6ef73224a0f (x86/cpu: Prepare TSS.IST setup for guard pages)
  	}
  
  	t->x86_tss.io_bitmap_base = IO_BITMAP_OFFSET;
* Unmerged path arch/x86/kernel/cpu/common.c
