powerpc/sstep: Add tests for prefixed integer load/stores

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Jordan Niethe <jniethe5@gmail.com>
commit b6b54b42722a2393056c891c0d05cd8cc40eb776
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/b6b54b42.failed

Add tests for the prefixed versions of the integer load/stores that
are currently tested. This includes the following instructions:
  * Prefixed Load Doubleword (pld)
  * Prefixed Load Word and Zero (plwz)
  * Prefixed Store Doubleword (pstd)

Skip the new tests if ISA v3.1 is unsupported.

	Signed-off-by: Jordan Niethe <jniethe5@gmail.com>
[mpe: Fix conflicts with ppc-opcode.h changes]
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://lore.kernel.org/r/20200525025923.19843-1-jniethe5@gmail.com
(cherry picked from commit b6b54b42722a2393056c891c0d05cd8cc40eb776)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/include/asm/ppc-opcode.h
diff --cc arch/powerpc/include/asm/ppc-opcode.h
index 8fe0becd8b4e,90ae33a74d78..000000000000
--- a/arch/powerpc/include/asm/ppc-opcode.h
+++ b/arch/powerpc/include/asm/ppc-opcode.h
@@@ -328,57 -255,24 +328,65 @@@
  #define PPC_INST_ADDI			0x38000000
  #define PPC_INST_ADDIS			0x3c000000
  #define PPC_INST_ADD			0x7c000214
 +#define PPC_INST_ADDC			0x7c000014
 +#define PPC_INST_SUB			0x7c000050
  #define PPC_INST_BLR			0x4e800020
 +#define PPC_INST_BLRL			0x4e800021
  #define PPC_INST_BCTR			0x4e800420
 -#define PPC_INST_BCTRL			0x4e800421
 +#define PPC_INST_MULLD			0x7c0001d2
 +#define PPC_INST_MULLW			0x7c0001d6
 +#define PPC_INST_MULHWU			0x7c000016
 +#define PPC_INST_MULLI			0x1c000000
 +#define PPC_INST_MADDHD			0x10000030
 +#define PPC_INST_MADDHDU		0x10000031
 +#define PPC_INST_MADDLD			0x10000033
 +#define PPC_INST_DIVWU			0x7c000396
  #define PPC_INST_DIVD			0x7c0003d2
 +#define PPC_INST_DIVDU			0x7c000392
 +#define PPC_INST_RLWINM			0x54000000
 +#define PPC_INST_RLWINM_DOT		0x54000001
 +#define PPC_INST_RLWIMI			0x50000000
 +#define PPC_INST_RLDICL			0x78000000
  #define PPC_INST_RLDICR			0x78000004
 +#define PPC_INST_SLW			0x7c000030
 +#define PPC_INST_SLD			0x7c000036
 +#define PPC_INST_SRW			0x7c000430
 +#define PPC_INST_SRAW			0x7c000630
 +#define PPC_INST_SRAWI			0x7c000670
 +#define PPC_INST_SRD			0x7c000436
 +#define PPC_INST_SRAD			0x7c000634
 +#define PPC_INST_SRADI			0x7c000674
 +#define PPC_INST_AND			0x7c000038
 +#define PPC_INST_ANDDOT			0x7c000039
 +#define PPC_INST_OR			0x7c000378
 +#define PPC_INST_XOR			0x7c000278
 +#define PPC_INST_ANDI			0x70000000
  #define PPC_INST_ORI			0x60000000
  #define PPC_INST_ORIS			0x64000000
 +#define PPC_INST_XORI			0x68000000
 +#define PPC_INST_XORIS			0x6c000000
 +#define PPC_INST_NEG			0x7c0000d0
 +#define PPC_INST_EXTSW			0x7c0007b4
  #define PPC_INST_BRANCH			0x48000000
  #define PPC_INST_BRANCH_COND		0x40800000
 +#define PPC_INST_LBZCIX			0x7c0006aa
 +#define PPC_INST_STBCIX			0x7c0007aa
 +#define PPC_INST_LWZX			0x7c00002e
 +#define PPC_INST_LFSX			0x7c00042e
 +#define PPC_INST_STFSX			0x7c00052e
 +#define PPC_INST_LFDX			0x7c0004ae
 +#define PPC_INST_STFDX			0x7c0005ae
 +#define PPC_INST_LVX			0x7c0000ce
 +#define PPC_INST_STVX			0x7c0001ce
  
+ /* Prefixes */
+ #define PPC_PREFIX_MLS			0x06000000
+ #define PPC_PREFIX_8LS			0x04000000
+ 
+ /* Prefixed instructions */
+ #define PPC_INST_PLD			0xe4000000
+ #define PPC_INST_PSTD			0xf4000000
+ 
  /* macros to insert fields into opcodes */
  #define ___PPC_RA(a)	(((a) & 0x1f) << 16)
  #define ___PPC_RB(b)	(((b) & 0x1f) << 11)
@@@ -409,6 -303,17 +417,20 @@@
  #define __PPC_BI(s)	(((s) & 0x1f) << 16)
  #define __PPC_CT(t)	(((t) & 0x0f) << 21)
  #define __PPC_SPR(r)	((((r) & 0x1f) << 16) | ((((r) >> 5) & 0x1f) << 11))
++<<<<<<< HEAD
++=======
+ #define __PPC_RC21	(0x1 << 10)
+ #define __PPC_PRFX_R(r)	(((r) & 0x1) << 20)
+ 
+ /*
+  * Both low and high 16 bits are added as SIGNED additions, so if low 16 bits
+  * has high bit set, high 16 bits must be adjusted. These macros do that (stolen
+  * from binutils).
+  */
+ #define PPC_LO(v)	((v) & 0xffff)
+ #define PPC_HI(v)	(((v) >> 16) & 0xffff)
+ #define PPC_HA(v)	PPC_HI((v) + 0x8000)
++>>>>>>> b6b54b42722a (powerpc/sstep: Add tests for prefixed integer load/stores)
  
  /*
   * Only use the larx hint bit on 64bit CPUs. e500v1/v2 based CPUs will treat a
* Unmerged path arch/powerpc/include/asm/ppc-opcode.h
diff --git a/arch/powerpc/lib/test_emulate_step.c b/arch/powerpc/lib/test_emulate_step.c
index 91111c36f589..9a2f4b92e667 100644
--- a/arch/powerpc/lib/test_emulate_step.c
+++ b/arch/powerpc/lib/test_emulate_step.c
@@ -65,6 +65,18 @@
 #define IGNORE_XER	(0x1UL << 32)
 #define IGNORE_CCR	(0x1UL << 33)
 
+#define TEST_PLD(r, base, i, pr) \
+	ppc_inst_prefix(PPC_PREFIX_8LS | __PPC_PRFX_R(pr) | IMM_H(i), \
+			PPC_INST_PLD | ___PPC_RT(r) | ___PPC_RA(base) | IMM_L(i))
+
+#define TEST_PLWZ(r, base, i, pr) \
+	ppc_inst_prefix(PPC_PREFIX_MLS | __PPC_PRFX_R(pr) | IMM_H(i), \
+			PPC_RAW_LWZ(r, base, i))
+
+#define TEST_PSTD(r, base, i, pr) \
+	ppc_inst_prefix(PPC_PREFIX_8LS | __PPC_PRFX_R(pr) | IMM_H(i), \
+			PPC_INST_PSTD | ___PPC_RT(r) | ___PPC_RA(base) | IMM_L(i))
+
 static void __init init_pt_regs(struct pt_regs *regs)
 {
 	static unsigned long msr;
@@ -116,6 +128,29 @@ static void __init test_ld(void)
 		show_result("ld", "FAIL");
 }
 
+static void __init test_pld(void)
+{
+	struct pt_regs regs;
+	unsigned long a = 0x23;
+	int stepped = -1;
+
+	if (!cpu_has_feature(CPU_FTR_ARCH_31)) {
+		show_result("pld", "SKIP (!CPU_FTR_ARCH_31)");
+		return;
+	}
+
+	init_pt_regs(&regs);
+	regs.gpr[3] = (unsigned long)&a;
+
+	/* pld r5, 0(r3), 0 */
+	stepped = emulate_step(&regs, TEST_PLD(5, 3, 0, 0));
+
+	if (stepped == 1 && regs.gpr[5] == a)
+		show_result("pld", "PASS");
+	else
+		show_result("pld", "FAIL");
+}
+
 static void __init test_lwz(void)
 {
 	struct pt_regs regs;
@@ -134,6 +169,30 @@ static void __init test_lwz(void)
 		show_result("lwz", "FAIL");
 }
 
+static void __init test_plwz(void)
+{
+	struct pt_regs regs;
+	unsigned int a = 0x4545;
+	int stepped = -1;
+
+	if (!cpu_has_feature(CPU_FTR_ARCH_31)) {
+		show_result("plwz", "SKIP (!CPU_FTR_ARCH_31)");
+		return;
+	}
+
+	init_pt_regs(&regs);
+	regs.gpr[3] = (unsigned long)&a;
+
+	/* plwz r5, 0(r3), 0 */
+
+	stepped = emulate_step(&regs, TEST_PLWZ(5, 3, 0, 0));
+
+	if (stepped == 1 && regs.gpr[5] == a)
+		show_result("plwz", "PASS");
+	else
+		show_result("plwz", "FAIL");
+}
+
 static void __init test_lwzx(void)
 {
 	struct pt_regs regs;
@@ -171,6 +230,29 @@ static void __init test_std(void)
 		show_result("std", "FAIL");
 }
 
+static void __init test_pstd(void)
+{
+	struct pt_regs regs;
+	unsigned long a = 0x1234;
+	int stepped = -1;
+
+	if (!cpu_has_feature(CPU_FTR_ARCH_31)) {
+		show_result("pstd", "SKIP (!CPU_FTR_ARCH_31)");
+		return;
+	}
+
+	init_pt_regs(&regs);
+	regs.gpr[3] = (unsigned long)&a;
+	regs.gpr[5] = 0x5678;
+
+	/* pstd r5, 0(r3), 0 */
+	stepped = emulate_step(&regs, TEST_PSTD(5, 3, 0, 0));
+	if (stepped == 1 || regs.gpr[5] == a)
+		show_result("pstd", "PASS");
+	else
+		show_result("pstd", "FAIL");
+}
+
 static void __init test_ldarx_stdcx(void)
 {
 	struct pt_regs regs;
@@ -450,9 +532,12 @@ static void __init test_lxvd2x_stxvd2x(void)
 static void __init run_tests_load_store(void)
 {
 	test_ld();
+	test_pld();
 	test_lwz();
+	test_plwz();
 	test_lwzx();
 	test_std();
+	test_pstd();
 	test_ldarx_stdcx();
 	test_lfsx_stfsx();
 	test_lfdx_stfdx();
