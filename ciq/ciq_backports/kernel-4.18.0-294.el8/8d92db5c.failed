bpf: rework the compat kernel probe handling

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 8d92db5c04d10381f4db70ed99b1b576f5db18a7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/8d92db5c.failed

Instead of using the dangerous probe_kernel_read and strncpy_from_unsafe
helpers, rework the compat probes to check if an address is a kernel or
userspace one, and then use the low-level kernel or user probe helper
shared by the proper kernel and user probe helpers.  This slightly
changes behavior as the compat probe on a user address doesn't check
the lockdown flags, just as the pure user probes do.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Cc: Alexei Starovoitov <ast@kernel.org>
	Cc: Daniel Borkmann <daniel@iogearbox.net>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Ingo Molnar <mingo@elte.hu>
	Cc: Masami Hiramatsu <mhiramat@kernel.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
Link: http://lkml.kernel.org/r/20200521152301.2587579-14-hch@lst.de
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 8d92db5c04d10381f4db70ed99b1b576f5db18a7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/trace/bpf_trace.c
diff --cc kernel/trace/bpf_trace.c
index 5481c35d2b9d,59cb19888891..000000000000
--- a/kernel/trace/bpf_trace.c
+++ b/kernel/trace/bpf_trace.c
@@@ -162,12 -177,7 +180,16 @@@ bpf_probe_read_user_str_common(void *ds
  BPF_CALL_3(bpf_probe_read_user_str, void *, dst, u32, size,
  	   const void __user *, unsafe_ptr)
  {
++<<<<<<< HEAD
 +	int ret = strncpy_from_unsafe_user(dst, unsafe_ptr, size);
 +
 +	if (unlikely(ret < 0))
 +		memset(dst, 0, size);
 +
 +	return ret;
++=======
+ 	return bpf_probe_read_user_str_common(dst, size, unsafe_ptr);
++>>>>>>> 8d92db5c04d1 (bpf: rework the compat kernel probe handling)
  }
  
  const struct bpf_func_proto bpf_probe_read_user_str_proto = {
@@@ -180,15 -190,18 +202,25 @@@
  };
  
  static __always_inline int
- bpf_probe_read_kernel_common(void *dst, u32 size, const void *unsafe_ptr,
- 			     const bool compat)
+ bpf_probe_read_kernel_common(void *dst, u32 size, const void *unsafe_ptr)
  {
 -	int ret = security_locked_down(LOCKDOWN_BPF_READ);
 +	int ret;
  
++<<<<<<< HEAD
 +	ret = compat ? probe_kernel_read(dst, unsafe_ptr, size) :
 +	      probe_kernel_read_strict(dst, unsafe_ptr, size);
 +	if (unlikely(ret < 0))
 +		memset(dst, 0, size);
++=======
+ 	if (unlikely(ret < 0))
+ 		goto fail;
+ 	ret = probe_kernel_read_strict(dst, unsafe_ptr, size);
+ 	if (unlikely(ret < 0))
+ 		goto fail;
+ 	return ret;
+ fail:
+ 	memset(dst, 0, size);
++>>>>>>> 8d92db5c04d1 (bpf: rework the compat kernel probe handling)
  	return ret;
  }
  
@@@ -207,40 -220,30 +239,40 @@@ const struct bpf_func_proto bpf_probe_r
  	.arg3_type	= ARG_ANYTHING,
  };
  
- BPF_CALL_3(bpf_probe_read_compat, void *, dst, u32, size,
- 	   const void *, unsafe_ptr)
- {
- 	return bpf_probe_read_kernel_common(dst, size, unsafe_ptr, true);
- }
- 
- static const struct bpf_func_proto bpf_probe_read_compat_proto = {
- 	.func		= bpf_probe_read_compat,
- 	.gpl_only	= true,
- 	.ret_type	= RET_INTEGER,
- 	.arg1_type	= ARG_PTR_TO_UNINIT_MEM,
- 	.arg2_type	= ARG_CONST_SIZE_OR_ZERO,
- 	.arg3_type	= ARG_ANYTHING,
- };
- 
  static __always_inline int
- bpf_probe_read_kernel_str_common(void *dst, u32 size, const void *unsafe_ptr,
- 				 const bool compat)
+ bpf_probe_read_kernel_str_common(void *dst, u32 size, const void *unsafe_ptr)
  {
 -	int ret = security_locked_down(LOCKDOWN_BPF_READ);
 +	int ret;
  
++<<<<<<< HEAD
++=======
+ 	if (unlikely(ret < 0))
+ 		goto fail;
+ 
++>>>>>>> 8d92db5c04d1 (bpf: rework the compat kernel probe handling)
  	/*
- 	 * The strncpy_from_unsafe_*() call will likely not fill the entire
- 	 * buffer, but that's okay in this circumstance as we're probing
+ 	 * The strncpy_from_kernel_nofault() call will likely not fill the
+ 	 * entire buffer, but that's okay in this circumstance as we're probing
  	 * arbitrary memory anyway similar to bpf_probe_read_*() and might
  	 * as well probe the stack. Thus, memory is explicitly cleared
  	 * only in error case, so that improper users ignoring return
  	 * code altogether don't copy garbage; otherwise length of string
  	 * is returned that can be used for bpf_perf_event_output() et al.
  	 */
++<<<<<<< HEAD
 +	ret = compat ? strncpy_from_unsafe(dst, unsafe_ptr, size) :
 +	      strncpy_from_unsafe_strict(dst, unsafe_ptr, size);
 +	if (unlikely(ret < 0))
 +		memset(dst, 0, size);
++=======
+ 	ret = strncpy_from_kernel_nofault(dst, unsafe_ptr, size);
+ 	if (unlikely(ret < 0))
+ 		goto fail;
+ 
+ 	return 0;
+ fail:
+ 	memset(dst, 0, size);
++>>>>>>> 8d92db5c04d1 (bpf: rework the compat kernel probe handling)
  	return ret;
  }
  
* Unmerged path kernel/trace/bpf_trace.c
