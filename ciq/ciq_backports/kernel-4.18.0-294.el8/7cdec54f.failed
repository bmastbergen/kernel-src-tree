bpf: Add csum_level helper for fixing up csum levels

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Daniel Borkmann <daniel@iogearbox.net>
commit 7cdec54f9713256bb170873a1fc5c75c9127c9d2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/7cdec54f.failed

Add a bpf_csum_level() helper which BPF programs can use in combination
with bpf_skb_adjust_room() when they pass in BPF_F_ADJ_ROOM_NO_CSUM_RESET
flag to the latter to avoid falling back to CHECKSUM_NONE.

The bpf_csum_level() allows to adjust CHECKSUM_UNNECESSARY skb->csum_levels
via BPF_CSUM_LEVEL_{INC,DEC} which calls __skb_{incr,decr}_checksum_unnecessary()
on the skb. The helper also allows a BPF_CSUM_LEVEL_RESET which sets the skb's
csum to CHECKSUM_NONE as well as a BPF_CSUM_LEVEL_QUERY to just return the
current level. Without this helper, there is no way to otherwise adjust the
skb->csum_level. I did not add an extra dummy flags as there is plenty of free
bitspace in level argument itself iff ever needed in future.

	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Reviewed-by: Alan Maguire <alan.maguire@oracle.com>
	Acked-by: Lorenz Bauer <lmb@cloudflare.com>
Link: https://lore.kernel.org/bpf/279ae3717cb3d03c0ffeb511493c93c450a01e1a.1591108731.git.daniel@iogearbox.net
(cherry picked from commit 7cdec54f9713256bb170873a1fc5c75c9127c9d2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/uapi/linux/bpf.h
#	tools/include/uapi/linux/bpf.h
diff --cc include/uapi/linux/bpf.h
index 7ccb96ed0b1f,c65b374a5090..000000000000
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@@ -3127,6 -3135,123 +3127,126 @@@ union bpf_attr 
   * 		0 on success, or a negative error in case of failure:
   *
   *		**-EOVERFLOW** if an overflow happened: The same object will be tried again.
++<<<<<<< HEAD
++=======
+  *
+  * u64 bpf_sk_cgroup_id(struct bpf_sock *sk)
+  *	Description
+  *		Return the cgroup v2 id of the socket *sk*.
+  *
+  *		*sk* must be a non-**NULL** pointer to a full socket, e.g. one
+  *		returned from **bpf_sk_lookup_xxx**\ (),
+  *		**bpf_sk_fullsock**\ (), etc. The format of returned id is
+  *		same as in **bpf_skb_cgroup_id**\ ().
+  *
+  *		This helper is available only if the kernel was compiled with
+  *		the **CONFIG_SOCK_CGROUP_DATA** configuration option.
+  *	Return
+  *		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * u64 bpf_sk_ancestor_cgroup_id(struct bpf_sock *sk, int ancestor_level)
+  *	Description
+  *		Return id of cgroup v2 that is ancestor of cgroup associated
+  *		with the *sk* at the *ancestor_level*.  The root cgroup is at
+  *		*ancestor_level* zero and each step down the hierarchy
+  *		increments the level. If *ancestor_level* == level of cgroup
+  *		associated with *sk*, then return value will be same as that
+  *		of **bpf_sk_cgroup_id**\ ().
+  *
+  *		The helper is useful to implement policies based on cgroups
+  *		that are upper in hierarchy than immediate cgroup associated
+  *		with *sk*.
+  *
+  *		The format of returned id and helper limitations are same as in
+  *		**bpf_sk_cgroup_id**\ ().
+  *	Return
+  *		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * void *bpf_ringbuf_output(void *ringbuf, void *data, u64 size, u64 flags)
+  * 	Description
+  * 		Copy *size* bytes from *data* into a ring buffer *ringbuf*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		0, on success;
+  * 		< 0, on error.
+  *
+  * void *bpf_ringbuf_reserve(void *ringbuf, u64 size, u64 flags)
+  * 	Description
+  * 		Reserve *size* bytes of payload in a ring buffer *ringbuf*.
+  * 	Return
+  * 		Valid pointer with *size* bytes of memory available; NULL,
+  * 		otherwise.
+  *
+  * void bpf_ringbuf_submit(void *data, u64 flags)
+  * 	Description
+  * 		Submit reserved ring buffer sample, pointed to by *data*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		Nothing. Always succeeds.
+  *
+  * void bpf_ringbuf_discard(void *data, u64 flags)
+  * 	Description
+  * 		Discard reserved ring buffer sample, pointed to by *data*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		Nothing. Always succeeds.
+  *
+  * u64 bpf_ringbuf_query(void *ringbuf, u64 flags)
+  *	Description
+  *		Query various characteristics of provided ring buffer. What
+  *		exactly is queries is determined by *flags*:
+  *		  - BPF_RB_AVAIL_DATA - amount of data not yet consumed;
+  *		  - BPF_RB_RING_SIZE - the size of ring buffer;
+  *		  - BPF_RB_CONS_POS - consumer position (can wrap around);
+  *		  - BPF_RB_PROD_POS - producer(s) position (can wrap around);
+  *		Data returned is just a momentary snapshots of actual values
+  *		and could be inaccurate, so this facility should be used to
+  *		power heuristics and for reporting, not to make 100% correct
+  *		calculation.
+  *	Return
+  *		Requested value, or 0, if flags are not recognized.
+  *
+  * int bpf_csum_level(struct sk_buff *skb, u64 level)
+  * 	Description
+  * 		Change the skbs checksum level by one layer up or down, or
+  * 		reset it entirely to none in order to have the stack perform
+  * 		checksum validation. The level is applicable to the following
+  * 		protocols: TCP, UDP, GRE, SCTP, FCOE. For example, a decap of
+  * 		| ETH | IP | UDP | GUE | IP | TCP | into | ETH | IP | TCP |
+  * 		through **bpf_skb_adjust_room**\ () helper with passing in
+  * 		**BPF_F_ADJ_ROOM_NO_CSUM_RESET** flag would require one	call
+  * 		to **bpf_csum_level**\ () with **BPF_CSUM_LEVEL_DEC** since
+  * 		the UDP header is removed. Similarly, an encap of the latter
+  * 		into the former could be accompanied by a helper call to
+  * 		**bpf_csum_level**\ () with **BPF_CSUM_LEVEL_INC** if the
+  * 		skb is still intended to be processed in higher layers of the
+  * 		stack instead of just egressing at tc.
+  *
+  * 		There are three supported level settings at this time:
+  *
+  * 		* **BPF_CSUM_LEVEL_INC**: Increases skb->csum_level for skbs
+  * 		  with CHECKSUM_UNNECESSARY.
+  * 		* **BPF_CSUM_LEVEL_DEC**: Decreases skb->csum_level for skbs
+  * 		  with CHECKSUM_UNNECESSARY.
+  * 		* **BPF_CSUM_LEVEL_RESET**: Resets skb->csum_level to 0 and
+  * 		  sets CHECKSUM_NONE to force checksum validation by the stack.
+  * 		* **BPF_CSUM_LEVEL_QUERY**: No-op, returns the current
+  * 		  skb->csum_level.
+  * 	Return
+  * 		0 on success, or a negative error in case of failure. In the
+  * 		case of **BPF_CSUM_LEVEL_QUERY**, the current skb->csum_level
+  * 		is returned or the error code -EACCES in case the skb is not
+  * 		subject to CHECKSUM_UNNECESSARY.
++>>>>>>> 7cdec54f9713 (bpf: Add csum_level helper for fixing up csum levels)
   */
  #define __BPF_FUNC_MAPPER(FN)		\
  	FN(unspec),			\
@@@ -3256,7 -3381,15 +3376,19 @@@
  	FN(sk_assign),			\
  	FN(ktime_get_boot_ns),		\
  	FN(seq_printf),			\
++<<<<<<< HEAD
 +	FN(seq_write),
++=======
+ 	FN(seq_write),			\
+ 	FN(sk_cgroup_id),		\
+ 	FN(sk_ancestor_cgroup_id),	\
+ 	FN(ringbuf_output),		\
+ 	FN(ringbuf_reserve),		\
+ 	FN(ringbuf_submit),		\
+ 	FN(ringbuf_discard),		\
+ 	FN(ringbuf_query),		\
+ 	FN(csum_level),
++>>>>>>> 7cdec54f9713 (bpf: Add csum_level helper for fixing up csum levels)
  
  /* integer value in 'imm' field of BPF_CALL instruction selects which helper
   * function eBPF program intends to call
diff --cc tools/include/uapi/linux/bpf.h
index fc883a643880,c65b374a5090..000000000000
--- a/tools/include/uapi/linux/bpf.h
+++ b/tools/include/uapi/linux/bpf.h
@@@ -3093,13 -3128,130 +3093,134 @@@ union bpf_attr 
   *
   * int bpf_seq_write(struct seq_file *m, const void *data, u32 len)
   * 	Description
 - * 		**bpf_seq_write**\ () uses seq_file **seq_write**\ () to write the data.
 + * 		seq_write uses seq_file seq_write() to write the data.
   * 		The *m* represents the seq_file. The *data* and *len* represent the
 - * 		data to write in bytes.
 + *		data to write in bytes.
   * 	Return
 - * 		0 on success, or a negative error in case of failure:
 + * 		0 on success, or a negative errno in case of failure.
   *
++<<<<<<< HEAD
 + *		* **-EOVERFLOW**	Overflow happens, the same object will be tried again.
++=======
+  *		**-EOVERFLOW** if an overflow happened: The same object will be tried again.
+  *
+  * u64 bpf_sk_cgroup_id(struct bpf_sock *sk)
+  *	Description
+  *		Return the cgroup v2 id of the socket *sk*.
+  *
+  *		*sk* must be a non-**NULL** pointer to a full socket, e.g. one
+  *		returned from **bpf_sk_lookup_xxx**\ (),
+  *		**bpf_sk_fullsock**\ (), etc. The format of returned id is
+  *		same as in **bpf_skb_cgroup_id**\ ().
+  *
+  *		This helper is available only if the kernel was compiled with
+  *		the **CONFIG_SOCK_CGROUP_DATA** configuration option.
+  *	Return
+  *		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * u64 bpf_sk_ancestor_cgroup_id(struct bpf_sock *sk, int ancestor_level)
+  *	Description
+  *		Return id of cgroup v2 that is ancestor of cgroup associated
+  *		with the *sk* at the *ancestor_level*.  The root cgroup is at
+  *		*ancestor_level* zero and each step down the hierarchy
+  *		increments the level. If *ancestor_level* == level of cgroup
+  *		associated with *sk*, then return value will be same as that
+  *		of **bpf_sk_cgroup_id**\ ().
+  *
+  *		The helper is useful to implement policies based on cgroups
+  *		that are upper in hierarchy than immediate cgroup associated
+  *		with *sk*.
+  *
+  *		The format of returned id and helper limitations are same as in
+  *		**bpf_sk_cgroup_id**\ ().
+  *	Return
+  *		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * void *bpf_ringbuf_output(void *ringbuf, void *data, u64 size, u64 flags)
+  * 	Description
+  * 		Copy *size* bytes from *data* into a ring buffer *ringbuf*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		0, on success;
+  * 		< 0, on error.
+  *
+  * void *bpf_ringbuf_reserve(void *ringbuf, u64 size, u64 flags)
+  * 	Description
+  * 		Reserve *size* bytes of payload in a ring buffer *ringbuf*.
+  * 	Return
+  * 		Valid pointer with *size* bytes of memory available; NULL,
+  * 		otherwise.
+  *
+  * void bpf_ringbuf_submit(void *data, u64 flags)
+  * 	Description
+  * 		Submit reserved ring buffer sample, pointed to by *data*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		Nothing. Always succeeds.
+  *
+  * void bpf_ringbuf_discard(void *data, u64 flags)
+  * 	Description
+  * 		Discard reserved ring buffer sample, pointed to by *data*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		Nothing. Always succeeds.
+  *
+  * u64 bpf_ringbuf_query(void *ringbuf, u64 flags)
+  *	Description
+  *		Query various characteristics of provided ring buffer. What
+  *		exactly is queries is determined by *flags*:
+  *		  - BPF_RB_AVAIL_DATA - amount of data not yet consumed;
+  *		  - BPF_RB_RING_SIZE - the size of ring buffer;
+  *		  - BPF_RB_CONS_POS - consumer position (can wrap around);
+  *		  - BPF_RB_PROD_POS - producer(s) position (can wrap around);
+  *		Data returned is just a momentary snapshots of actual values
+  *		and could be inaccurate, so this facility should be used to
+  *		power heuristics and for reporting, not to make 100% correct
+  *		calculation.
+  *	Return
+  *		Requested value, or 0, if flags are not recognized.
+  *
+  * int bpf_csum_level(struct sk_buff *skb, u64 level)
+  * 	Description
+  * 		Change the skbs checksum level by one layer up or down, or
+  * 		reset it entirely to none in order to have the stack perform
+  * 		checksum validation. The level is applicable to the following
+  * 		protocols: TCP, UDP, GRE, SCTP, FCOE. For example, a decap of
+  * 		| ETH | IP | UDP | GUE | IP | TCP | into | ETH | IP | TCP |
+  * 		through **bpf_skb_adjust_room**\ () helper with passing in
+  * 		**BPF_F_ADJ_ROOM_NO_CSUM_RESET** flag would require one	call
+  * 		to **bpf_csum_level**\ () with **BPF_CSUM_LEVEL_DEC** since
+  * 		the UDP header is removed. Similarly, an encap of the latter
+  * 		into the former could be accompanied by a helper call to
+  * 		**bpf_csum_level**\ () with **BPF_CSUM_LEVEL_INC** if the
+  * 		skb is still intended to be processed in higher layers of the
+  * 		stack instead of just egressing at tc.
+  *
+  * 		There are three supported level settings at this time:
+  *
+  * 		* **BPF_CSUM_LEVEL_INC**: Increases skb->csum_level for skbs
+  * 		  with CHECKSUM_UNNECESSARY.
+  * 		* **BPF_CSUM_LEVEL_DEC**: Decreases skb->csum_level for skbs
+  * 		  with CHECKSUM_UNNECESSARY.
+  * 		* **BPF_CSUM_LEVEL_RESET**: Resets skb->csum_level to 0 and
+  * 		  sets CHECKSUM_NONE to force checksum validation by the stack.
+  * 		* **BPF_CSUM_LEVEL_QUERY**: No-op, returns the current
+  * 		  skb->csum_level.
+  * 	Return
+  * 		0 on success, or a negative error in case of failure. In the
+  * 		case of **BPF_CSUM_LEVEL_QUERY**, the current skb->csum_level
+  * 		is returned or the error code -EACCES in case the skb is not
+  * 		subject to CHECKSUM_UNNECESSARY.
++>>>>>>> 7cdec54f9713 (bpf: Add csum_level helper for fixing up csum levels)
   */
  #define __BPF_FUNC_MAPPER(FN)		\
  	FN(unspec),			\
@@@ -3229,7 -3381,15 +3350,19 @@@
  	FN(sk_assign),			\
  	FN(ktime_get_boot_ns),		\
  	FN(seq_printf),			\
++<<<<<<< HEAD
 +	FN(seq_write),
++=======
+ 	FN(seq_write),			\
+ 	FN(sk_cgroup_id),		\
+ 	FN(sk_ancestor_cgroup_id),	\
+ 	FN(ringbuf_output),		\
+ 	FN(ringbuf_reserve),		\
+ 	FN(ringbuf_submit),		\
+ 	FN(ringbuf_discard),		\
+ 	FN(ringbuf_query),		\
+ 	FN(csum_level),
++>>>>>>> 7cdec54f9713 (bpf: Add csum_level helper for fixing up csum levels)
  
  /* integer value in 'imm' field of BPF_CALL instruction selects which helper
   * function eBPF program intends to call
* Unmerged path include/uapi/linux/bpf.h
diff --git a/net/core/filter.c b/net/core/filter.c
index 3a061c53ed58..8792d9e308aa 100644
--- a/net/core/filter.c
+++ b/net/core/filter.c
@@ -2027,6 +2027,40 @@ static const struct bpf_func_proto bpf_csum_update_proto = {
 	.arg2_type	= ARG_ANYTHING,
 };
 
+BPF_CALL_2(bpf_csum_level, struct sk_buff *, skb, u64, level)
+{
+	/* The interface is to be used in combination with bpf_skb_adjust_room()
+	 * for encap/decap of packet headers when BPF_F_ADJ_ROOM_NO_CSUM_RESET
+	 * is passed as flags, for example.
+	 */
+	switch (level) {
+	case BPF_CSUM_LEVEL_INC:
+		__skb_incr_checksum_unnecessary(skb);
+		break;
+	case BPF_CSUM_LEVEL_DEC:
+		__skb_decr_checksum_unnecessary(skb);
+		break;
+	case BPF_CSUM_LEVEL_RESET:
+		__skb_reset_checksum_unnecessary(skb);
+		break;
+	case BPF_CSUM_LEVEL_QUERY:
+		return skb->ip_summed == CHECKSUM_UNNECESSARY ?
+		       skb->csum_level : -EACCES;
+	default:
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static const struct bpf_func_proto bpf_csum_level_proto = {
+	.func		= bpf_csum_level,
+	.gpl_only	= false,
+	.ret_type	= RET_INTEGER,
+	.arg1_type	= ARG_PTR_TO_CTX,
+	.arg2_type	= ARG_ANYTHING,
+};
+
 static inline int __bpf_rx_skb(struct net_device *dev, struct sk_buff *skb)
 {
 	return dev_forward_skb(dev, skb);
@@ -6201,6 +6235,8 @@ tc_cls_act_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)
 		return &bpf_csum_diff_proto;
 	case BPF_FUNC_csum_update:
 		return &bpf_csum_update_proto;
+	case BPF_FUNC_csum_level:
+		return &bpf_csum_level_proto;
 	case BPF_FUNC_l3_csum_replace:
 		return &bpf_l3_csum_replace_proto;
 	case BPF_FUNC_l4_csum_replace:
@@ -6534,6 +6570,8 @@ lwt_xmit_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)
 		return &bpf_skb_store_bytes_proto;
 	case BPF_FUNC_csum_update:
 		return &bpf_csum_update_proto;
+	case BPF_FUNC_csum_level:
+		return &bpf_csum_level_proto;
 	case BPF_FUNC_l3_csum_replace:
 		return &bpf_l3_csum_replace_proto;
 	case BPF_FUNC_l4_csum_replace:
* Unmerged path tools/include/uapi/linux/bpf.h
