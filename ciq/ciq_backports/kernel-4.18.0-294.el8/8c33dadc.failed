bpf: Bpf_skc_to_* casting helpers require a NULL check on sk

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Martin KaFai Lau <kafai@fb.com>
commit 8c33dadc3e0eef1599811a55d748a0b95da0317d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/8c33dadc.failed

The bpf_skc_to_* type casting helpers are available to
BPF_PROG_TYPE_TRACING.  The traced PTR_TO_BTF_ID may be NULL.
For example, the skb->sk may be NULL.  Thus, these casting helpers
need to check "!sk" also and this patch fixes them.

Fixes: 0d4fad3e57df ("bpf: Add bpf_skc_to_udp6_sock() helper")
Fixes: 478cfbdf5f13 ("bpf: Add bpf_skc_to_{tcp, tcp_timewait, tcp_request}_sock() helpers")
Fixes: af7ec1383361 ("bpf: Add bpf_skc_to_tcp6_sock() helper")
	Signed-off-by: Martin KaFai Lau <kafai@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Yonghong Song <yhs@fb.com>
	Acked-by: Song Liu <songliubraving@fb.com>
Link: https://lore.kernel.org/bpf/20200915182959.241101-1-kafai@fb.com
(cherry picked from commit 8c33dadc3e0eef1599811a55d748a0b95da0317d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/core/filter.c
diff --cc net/core/filter.c
index 6cbc892ac5eb,23e8ded0ec97..000000000000
--- a/net/core/filter.c
+++ b/net/core/filter.c
@@@ -9144,3 -9495,132 +9144,135 @@@ void bpf_prog_change_xdp(struct bpf_pro
  {
  	bpf_dispatcher_change_prog(BPF_DISPATCHER_PTR(xdp), prev_prog, prog);
  }
++<<<<<<< HEAD
++=======
+ 
+ #ifdef CONFIG_DEBUG_INFO_BTF
+ BTF_ID_LIST_GLOBAL(btf_sock_ids)
+ #define BTF_SOCK_TYPE(name, type) BTF_ID(struct, type)
+ BTF_SOCK_TYPE_xxx
+ #undef BTF_SOCK_TYPE
+ #else
+ u32 btf_sock_ids[MAX_BTF_SOCK_TYPE];
+ #endif
+ 
+ static bool check_arg_btf_id(u32 btf_id, u32 arg)
+ {
+ 	int i;
+ 
+ 	/* only one argument, no need to check arg */
+ 	for (i = 0; i < MAX_BTF_SOCK_TYPE; i++)
+ 		if (btf_sock_ids[i] == btf_id)
+ 			return true;
+ 	return false;
+ }
+ 
+ BPF_CALL_1(bpf_skc_to_tcp6_sock, struct sock *, sk)
+ {
+ 	/* tcp6_sock type is not generated in dwarf and hence btf,
+ 	 * trigger an explicit type generation here.
+ 	 */
+ 	BTF_TYPE_EMIT(struct tcp6_sock);
+ 	if (sk && sk_fullsock(sk) && sk->sk_protocol == IPPROTO_TCP &&
+ 	    sk->sk_family == AF_INET6)
+ 		return (unsigned long)sk;
+ 
+ 	return (unsigned long)NULL;
+ }
+ 
+ const struct bpf_func_proto bpf_skc_to_tcp6_sock_proto = {
+ 	.func			= bpf_skc_to_tcp6_sock,
+ 	.gpl_only		= false,
+ 	.ret_type		= RET_PTR_TO_BTF_ID_OR_NULL,
+ 	.arg1_type		= ARG_PTR_TO_BTF_ID,
+ 	.check_btf_id		= check_arg_btf_id,
+ 	.ret_btf_id		= &btf_sock_ids[BTF_SOCK_TYPE_TCP6],
+ };
+ 
+ BPF_CALL_1(bpf_skc_to_tcp_sock, struct sock *, sk)
+ {
+ 	if (sk && sk_fullsock(sk) && sk->sk_protocol == IPPROTO_TCP)
+ 		return (unsigned long)sk;
+ 
+ 	return (unsigned long)NULL;
+ }
+ 
+ const struct bpf_func_proto bpf_skc_to_tcp_sock_proto = {
+ 	.func			= bpf_skc_to_tcp_sock,
+ 	.gpl_only		= false,
+ 	.ret_type		= RET_PTR_TO_BTF_ID_OR_NULL,
+ 	.arg1_type		= ARG_PTR_TO_BTF_ID,
+ 	.check_btf_id		= check_arg_btf_id,
+ 	.ret_btf_id		= &btf_sock_ids[BTF_SOCK_TYPE_TCP],
+ };
+ 
+ BPF_CALL_1(bpf_skc_to_tcp_timewait_sock, struct sock *, sk)
+ {
+ #ifdef CONFIG_INET
+ 	if (sk && sk->sk_prot == &tcp_prot && sk->sk_state == TCP_TIME_WAIT)
+ 		return (unsigned long)sk;
+ #endif
+ 
+ #if IS_BUILTIN(CONFIG_IPV6)
+ 	if (sk && sk->sk_prot == &tcpv6_prot && sk->sk_state == TCP_TIME_WAIT)
+ 		return (unsigned long)sk;
+ #endif
+ 
+ 	return (unsigned long)NULL;
+ }
+ 
+ const struct bpf_func_proto bpf_skc_to_tcp_timewait_sock_proto = {
+ 	.func			= bpf_skc_to_tcp_timewait_sock,
+ 	.gpl_only		= false,
+ 	.ret_type		= RET_PTR_TO_BTF_ID_OR_NULL,
+ 	.arg1_type		= ARG_PTR_TO_BTF_ID,
+ 	.check_btf_id		= check_arg_btf_id,
+ 	.ret_btf_id		= &btf_sock_ids[BTF_SOCK_TYPE_TCP_TW],
+ };
+ 
+ BPF_CALL_1(bpf_skc_to_tcp_request_sock, struct sock *, sk)
+ {
+ #ifdef CONFIG_INET
+ 	if (sk && sk->sk_prot == &tcp_prot && sk->sk_state == TCP_NEW_SYN_RECV)
+ 		return (unsigned long)sk;
+ #endif
+ 
+ #if IS_BUILTIN(CONFIG_IPV6)
+ 	if (sk && sk->sk_prot == &tcpv6_prot && sk->sk_state == TCP_NEW_SYN_RECV)
+ 		return (unsigned long)sk;
+ #endif
+ 
+ 	return (unsigned long)NULL;
+ }
+ 
+ const struct bpf_func_proto bpf_skc_to_tcp_request_sock_proto = {
+ 	.func			= bpf_skc_to_tcp_request_sock,
+ 	.gpl_only		= false,
+ 	.ret_type		= RET_PTR_TO_BTF_ID_OR_NULL,
+ 	.arg1_type		= ARG_PTR_TO_BTF_ID,
+ 	.check_btf_id		= check_arg_btf_id,
+ 	.ret_btf_id		= &btf_sock_ids[BTF_SOCK_TYPE_TCP_REQ],
+ };
+ 
+ BPF_CALL_1(bpf_skc_to_udp6_sock, struct sock *, sk)
+ {
+ 	/* udp6_sock type is not generated in dwarf and hence btf,
+ 	 * trigger an explicit type generation here.
+ 	 */
+ 	BTF_TYPE_EMIT(struct udp6_sock);
+ 	if (sk && sk_fullsock(sk) && sk->sk_protocol == IPPROTO_UDP &&
+ 	    sk->sk_type == SOCK_DGRAM && sk->sk_family == AF_INET6)
+ 		return (unsigned long)sk;
+ 
+ 	return (unsigned long)NULL;
+ }
+ 
+ const struct bpf_func_proto bpf_skc_to_udp6_sock_proto = {
+ 	.func			= bpf_skc_to_udp6_sock,
+ 	.gpl_only		= false,
+ 	.ret_type		= RET_PTR_TO_BTF_ID_OR_NULL,
+ 	.arg1_type		= ARG_PTR_TO_BTF_ID,
+ 	.check_btf_id		= check_arg_btf_id,
+ 	.ret_btf_id		= &btf_sock_ids[BTF_SOCK_TYPE_UDP6],
+ };
++>>>>>>> 8c33dadc3e0e (bpf: Bpf_skc_to_* casting helpers require a NULL check on sk)
* Unmerged path net/core/filter.c
