bpf: Add bpf_skc_to_tcp6_sock() helper

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Yonghong Song <yhs@fb.com>
commit af7ec13833619e17f03aa73a785a2f871da6d66b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/af7ec138.failed

The helper is used in tracing programs to cast a socket
pointer to a tcp6_sock pointer.
The return value could be NULL if the casting is illegal.

A new helper return type RET_PTR_TO_BTF_ID_OR_NULL is added
so the verifier is able to deduce proper return types for the helper.

Different from the previous BTF_ID based helpers,
the bpf_skc_to_tcp6_sock() argument can be several possible
btf_ids. More specifically, all possible socket data structures
with sock_common appearing in the first in the memory layout.
This patch only added socket types related to tcp and udp.

All possible argument btf_id and return value btf_id
for helper bpf_skc_to_tcp6_sock() are pre-calculcated and
cached. In the future, it is even possible to precompute
these btf_id's at kernel build time.

	Signed-off-by: Yonghong Song <yhs@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Andrii Nakryiko <andriin@fb.com>
	Acked-by: Martin KaFai Lau <kafai@fb.com>
Link: https://lore.kernel.org/bpf/20200623230809.3988195-1-yhs@fb.com
(cherry picked from commit af7ec13833619e17f03aa73a785a2f871da6d66b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
#	include/uapi/linux/bpf.h
#	kernel/bpf/verifier.c
#	tools/include/uapi/linux/bpf.h
diff --cc include/linux/bpf.h
index 531af1e44e56,c0e38ad07848..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -265,6 -264,8 +265,11 @@@ enum bpf_return_type 
  	RET_PTR_TO_SOCKET_OR_NULL,	/* returns a pointer to a socket or NULL */
  	RET_PTR_TO_TCP_SOCK_OR_NULL,	/* returns a pointer to a tcp_sock or NULL */
  	RET_PTR_TO_SOCK_COMMON_OR_NULL,	/* returns a pointer to a sock_common or NULL */
++<<<<<<< HEAD
++=======
+ 	RET_PTR_TO_ALLOC_MEM_OR_NULL,	/* returns a pointer to dynamically allocated memory or NULL */
+ 	RET_PTR_TO_BTF_ID_OR_NULL,	/* returns a pointer to a btf_id or NULL */
++>>>>>>> af7ec1383361 (bpf: Add bpf_skc_to_tcp6_sock() helper)
  };
  
  /* eBPF function prototype used by verifier to allow BPF_CALLs from eBPF programs
@@@ -1593,6 -1644,12 +1608,15 @@@ extern const struct bpf_func_proto bpf_
  extern const struct bpf_func_proto bpf_jiffies64_proto;
  extern const struct bpf_func_proto bpf_get_ns_current_pid_tgid_proto;
  extern const struct bpf_func_proto bpf_event_output_data_proto;
++<<<<<<< HEAD
++=======
+ extern const struct bpf_func_proto bpf_ringbuf_output_proto;
+ extern const struct bpf_func_proto bpf_ringbuf_reserve_proto;
+ extern const struct bpf_func_proto bpf_ringbuf_submit_proto;
+ extern const struct bpf_func_proto bpf_ringbuf_discard_proto;
+ extern const struct bpf_func_proto bpf_ringbuf_query_proto;
+ extern const struct bpf_func_proto bpf_skc_to_tcp6_sock_proto;
++>>>>>>> af7ec1383361 (bpf: Add bpf_skc_to_tcp6_sock() helper)
  
  const struct bpf_func_proto *bpf_tracing_func_proto(
  	enum bpf_func_id func_id, const struct bpf_prog *prog);
diff --cc include/uapi/linux/bpf.h
index af3754a78dbd,e90ad07b291a..000000000000
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@@ -3127,6 -3138,129 +3127,132 @@@ union bpf_attr 
   * 		0 on success, or a negative error in case of failure:
   *
   *		**-EOVERFLOW** if an overflow happened: The same object will be tried again.
++<<<<<<< HEAD
++=======
+  *
+  * u64 bpf_sk_cgroup_id(struct bpf_sock *sk)
+  *	Description
+  *		Return the cgroup v2 id of the socket *sk*.
+  *
+  *		*sk* must be a non-**NULL** pointer to a full socket, e.g. one
+  *		returned from **bpf_sk_lookup_xxx**\ (),
+  *		**bpf_sk_fullsock**\ (), etc. The format of returned id is
+  *		same as in **bpf_skb_cgroup_id**\ ().
+  *
+  *		This helper is available only if the kernel was compiled with
+  *		the **CONFIG_SOCK_CGROUP_DATA** configuration option.
+  *	Return
+  *		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * u64 bpf_sk_ancestor_cgroup_id(struct bpf_sock *sk, int ancestor_level)
+  *	Description
+  *		Return id of cgroup v2 that is ancestor of cgroup associated
+  *		with the *sk* at the *ancestor_level*.  The root cgroup is at
+  *		*ancestor_level* zero and each step down the hierarchy
+  *		increments the level. If *ancestor_level* == level of cgroup
+  *		associated with *sk*, then return value will be same as that
+  *		of **bpf_sk_cgroup_id**\ ().
+  *
+  *		The helper is useful to implement policies based on cgroups
+  *		that are upper in hierarchy than immediate cgroup associated
+  *		with *sk*.
+  *
+  *		The format of returned id and helper limitations are same as in
+  *		**bpf_sk_cgroup_id**\ ().
+  *	Return
+  *		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * int bpf_ringbuf_output(void *ringbuf, void *data, u64 size, u64 flags)
+  * 	Description
+  * 		Copy *size* bytes from *data* into a ring buffer *ringbuf*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		0, on success;
+  * 		< 0, on error.
+  *
+  * void *bpf_ringbuf_reserve(void *ringbuf, u64 size, u64 flags)
+  * 	Description
+  * 		Reserve *size* bytes of payload in a ring buffer *ringbuf*.
+  * 	Return
+  * 		Valid pointer with *size* bytes of memory available; NULL,
+  * 		otherwise.
+  *
+  * void bpf_ringbuf_submit(void *data, u64 flags)
+  * 	Description
+  * 		Submit reserved ring buffer sample, pointed to by *data*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		Nothing. Always succeeds.
+  *
+  * void bpf_ringbuf_discard(void *data, u64 flags)
+  * 	Description
+  * 		Discard reserved ring buffer sample, pointed to by *data*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		Nothing. Always succeeds.
+  *
+  * u64 bpf_ringbuf_query(void *ringbuf, u64 flags)
+  *	Description
+  *		Query various characteristics of provided ring buffer. What
+  *		exactly is queries is determined by *flags*:
+  *		  - BPF_RB_AVAIL_DATA - amount of data not yet consumed;
+  *		  - BPF_RB_RING_SIZE - the size of ring buffer;
+  *		  - BPF_RB_CONS_POS - consumer position (can wrap around);
+  *		  - BPF_RB_PROD_POS - producer(s) position (can wrap around);
+  *		Data returned is just a momentary snapshots of actual values
+  *		and could be inaccurate, so this facility should be used to
+  *		power heuristics and for reporting, not to make 100% correct
+  *		calculation.
+  *	Return
+  *		Requested value, or 0, if flags are not recognized.
+  *
+  * long bpf_csum_level(struct sk_buff *skb, u64 level)
+  * 	Description
+  * 		Change the skbs checksum level by one layer up or down, or
+  * 		reset it entirely to none in order to have the stack perform
+  * 		checksum validation. The level is applicable to the following
+  * 		protocols: TCP, UDP, GRE, SCTP, FCOE. For example, a decap of
+  * 		| ETH | IP | UDP | GUE | IP | TCP | into | ETH | IP | TCP |
+  * 		through **bpf_skb_adjust_room**\ () helper with passing in
+  * 		**BPF_F_ADJ_ROOM_NO_CSUM_RESET** flag would require one	call
+  * 		to **bpf_csum_level**\ () with **BPF_CSUM_LEVEL_DEC** since
+  * 		the UDP header is removed. Similarly, an encap of the latter
+  * 		into the former could be accompanied by a helper call to
+  * 		**bpf_csum_level**\ () with **BPF_CSUM_LEVEL_INC** if the
+  * 		skb is still intended to be processed in higher layers of the
+  * 		stack instead of just egressing at tc.
+  *
+  * 		There are three supported level settings at this time:
+  *
+  * 		* **BPF_CSUM_LEVEL_INC**: Increases skb->csum_level for skbs
+  * 		  with CHECKSUM_UNNECESSARY.
+  * 		* **BPF_CSUM_LEVEL_DEC**: Decreases skb->csum_level for skbs
+  * 		  with CHECKSUM_UNNECESSARY.
+  * 		* **BPF_CSUM_LEVEL_RESET**: Resets skb->csum_level to 0 and
+  * 		  sets CHECKSUM_NONE to force checksum validation by the stack.
+  * 		* **BPF_CSUM_LEVEL_QUERY**: No-op, returns the current
+  * 		  skb->csum_level.
+  * 	Return
+  * 		0 on success, or a negative error in case of failure. In the
+  * 		case of **BPF_CSUM_LEVEL_QUERY**, the current skb->csum_level
+  * 		is returned or the error code -EACCES in case the skb is not
+  * 		subject to CHECKSUM_UNNECESSARY.
+  *
+  * struct tcp6_sock *bpf_skc_to_tcp6_sock(void *sk)
+  *	Description
+  *		Dynamically cast a *sk* pointer to a *tcp6_sock* pointer.
+  *	Return
+  *		*sk* if casting is valid, or NULL otherwise.
++>>>>>>> af7ec1383361 (bpf: Add bpf_skc_to_tcp6_sock() helper)
   */
  #define __BPF_FUNC_MAPPER(FN)		\
  	FN(unspec),			\
@@@ -3256,7 -3390,16 +3382,20 @@@
  	FN(sk_assign),			\
  	FN(ktime_get_boot_ns),		\
  	FN(seq_printf),			\
++<<<<<<< HEAD
 +	FN(seq_write),
++=======
+ 	FN(seq_write),			\
+ 	FN(sk_cgroup_id),		\
+ 	FN(sk_ancestor_cgroup_id),	\
+ 	FN(ringbuf_output),		\
+ 	FN(ringbuf_reserve),		\
+ 	FN(ringbuf_submit),		\
+ 	FN(ringbuf_discard),		\
+ 	FN(ringbuf_query),		\
+ 	FN(csum_level),			\
+ 	FN(skc_to_tcp6_sock),
++>>>>>>> af7ec1383361 (bpf: Add bpf_skc_to_tcp6_sock() helper)
  
  /* integer value in 'imm' field of BPF_CALL instruction selects which helper
   * function eBPF program intends to call
diff --cc kernel/bpf/verifier.c
index b8aec186e303,7de98906ddf4..000000000000
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@@ -4666,6 -4821,23 +4677,26 @@@ static int check_helper_call(struct bpf
  		mark_reg_known_zero(env, regs, BPF_REG_0);
  		regs[BPF_REG_0].type = PTR_TO_TCP_SOCK_OR_NULL;
  		regs[BPF_REG_0].id = ++env->id_gen;
++<<<<<<< HEAD
++=======
+ 	} else if (fn->ret_type == RET_PTR_TO_ALLOC_MEM_OR_NULL) {
+ 		mark_reg_known_zero(env, regs, BPF_REG_0);
+ 		regs[BPF_REG_0].type = PTR_TO_MEM_OR_NULL;
+ 		regs[BPF_REG_0].id = ++env->id_gen;
+ 		regs[BPF_REG_0].mem_size = meta.mem_size;
+ 	} else if (fn->ret_type == RET_PTR_TO_BTF_ID_OR_NULL) {
+ 		int ret_btf_id;
+ 
+ 		mark_reg_known_zero(env, regs, BPF_REG_0);
+ 		regs[BPF_REG_0].type = PTR_TO_BTF_ID_OR_NULL;
+ 		ret_btf_id = *fn->ret_btf_id;
+ 		if (ret_btf_id == 0) {
+ 			verbose(env, "invalid return type %d of func %s#%d\n",
+ 				fn->ret_type, func_id_name(func_id), func_id);
+ 			return -EINVAL;
+ 		}
+ 		regs[BPF_REG_0].btf_id = ret_btf_id;
++>>>>>>> af7ec1383361 (bpf: Add bpf_skc_to_tcp6_sock() helper)
  	} else {
  		verbose(env, "unknown return type %d of func %s#%d\n",
  			fn->ret_type, func_id_name(func_id), func_id);
diff --cc tools/include/uapi/linux/bpf.h
index b34454b6dad0,e90ad07b291a..000000000000
--- a/tools/include/uapi/linux/bpf.h
+++ b/tools/include/uapi/linux/bpf.h
@@@ -3081,25 -3116,151 +3081,152 @@@ union bpf_attr 
   *		valid address but requiring a major memory fault. If reading kernel memory
   *		fails, the string for **%s** will be an empty string, and the ip
   *		address for **%p{i,I}{4,6}** will be 0. Not returning error to
 - *		bpf program is consistent with what **bpf_trace_printk**\ () does for now.
 + *		bpf program is consistent with what bpf_trace_printk() does for now.
   * 	Return
 - * 		0 on success, or a negative error in case of failure:
 - *
 - *		**-EBUSY** if per-CPU memory copy buffer is busy, can try again
 - *		by returning 1 from bpf program.
 - *
 - *		**-EINVAL** if arguments are invalid, or if *fmt* is invalid/unsupported.
 + * 		0 on success, or a negative errno in case of failure.
   *
 - *		**-E2BIG** if *fmt* contains too many format specifiers.
 + *		* **-EBUSY**		Percpu memory copy buffer is busy, can try again
 + *					by returning 1 from bpf program.
 + *		* **-EINVAL**		Invalid arguments, or invalid/unsupported formats.
 + *		* **-E2BIG**		Too many format specifiers.
 + *		* **-EOVERFLOW**	Overflow happens, the same object will be tried again.
   *
 - *		**-EOVERFLOW** if an overflow happened: The same object will be tried again.
 - *
 - * long bpf_seq_write(struct seq_file *m, const void *data, u32 len)
 + * int bpf_seq_write(struct seq_file *m, const void *data, u32 len)
   * 	Description
 - * 		**bpf_seq_write**\ () uses seq_file **seq_write**\ () to write the data.
 + * 		seq_write uses seq_file seq_write() to write the data.
   * 		The *m* represents the seq_file. The *data* and *len* represent the
 - * 		data to write in bytes.
 + *		data to write in bytes.
   * 	Return
 - * 		0 on success, or a negative error in case of failure:
 + * 		0 on success, or a negative errno in case of failure.
   *
++<<<<<<< HEAD
 + *		* **-EOVERFLOW**	Overflow happens, the same object will be tried again.
++=======
+  *		**-EOVERFLOW** if an overflow happened: The same object will be tried again.
+  *
+  * u64 bpf_sk_cgroup_id(struct bpf_sock *sk)
+  *	Description
+  *		Return the cgroup v2 id of the socket *sk*.
+  *
+  *		*sk* must be a non-**NULL** pointer to a full socket, e.g. one
+  *		returned from **bpf_sk_lookup_xxx**\ (),
+  *		**bpf_sk_fullsock**\ (), etc. The format of returned id is
+  *		same as in **bpf_skb_cgroup_id**\ ().
+  *
+  *		This helper is available only if the kernel was compiled with
+  *		the **CONFIG_SOCK_CGROUP_DATA** configuration option.
+  *	Return
+  *		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * u64 bpf_sk_ancestor_cgroup_id(struct bpf_sock *sk, int ancestor_level)
+  *	Description
+  *		Return id of cgroup v2 that is ancestor of cgroup associated
+  *		with the *sk* at the *ancestor_level*.  The root cgroup is at
+  *		*ancestor_level* zero and each step down the hierarchy
+  *		increments the level. If *ancestor_level* == level of cgroup
+  *		associated with *sk*, then return value will be same as that
+  *		of **bpf_sk_cgroup_id**\ ().
+  *
+  *		The helper is useful to implement policies based on cgroups
+  *		that are upper in hierarchy than immediate cgroup associated
+  *		with *sk*.
+  *
+  *		The format of returned id and helper limitations are same as in
+  *		**bpf_sk_cgroup_id**\ ().
+  *	Return
+  *		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * int bpf_ringbuf_output(void *ringbuf, void *data, u64 size, u64 flags)
+  * 	Description
+  * 		Copy *size* bytes from *data* into a ring buffer *ringbuf*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		0, on success;
+  * 		< 0, on error.
+  *
+  * void *bpf_ringbuf_reserve(void *ringbuf, u64 size, u64 flags)
+  * 	Description
+  * 		Reserve *size* bytes of payload in a ring buffer *ringbuf*.
+  * 	Return
+  * 		Valid pointer with *size* bytes of memory available; NULL,
+  * 		otherwise.
+  *
+  * void bpf_ringbuf_submit(void *data, u64 flags)
+  * 	Description
+  * 		Submit reserved ring buffer sample, pointed to by *data*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		Nothing. Always succeeds.
+  *
+  * void bpf_ringbuf_discard(void *data, u64 flags)
+  * 	Description
+  * 		Discard reserved ring buffer sample, pointed to by *data*.
+  * 		If BPF_RB_NO_WAKEUP is specified in *flags*, no notification of
+  * 		new data availability is sent.
+  * 		IF BPF_RB_FORCE_WAKEUP is specified in *flags*, notification of
+  * 		new data availability is sent unconditionally.
+  * 	Return
+  * 		Nothing. Always succeeds.
+  *
+  * u64 bpf_ringbuf_query(void *ringbuf, u64 flags)
+  *	Description
+  *		Query various characteristics of provided ring buffer. What
+  *		exactly is queries is determined by *flags*:
+  *		  - BPF_RB_AVAIL_DATA - amount of data not yet consumed;
+  *		  - BPF_RB_RING_SIZE - the size of ring buffer;
+  *		  - BPF_RB_CONS_POS - consumer position (can wrap around);
+  *		  - BPF_RB_PROD_POS - producer(s) position (can wrap around);
+  *		Data returned is just a momentary snapshots of actual values
+  *		and could be inaccurate, so this facility should be used to
+  *		power heuristics and for reporting, not to make 100% correct
+  *		calculation.
+  *	Return
+  *		Requested value, or 0, if flags are not recognized.
+  *
+  * long bpf_csum_level(struct sk_buff *skb, u64 level)
+  * 	Description
+  * 		Change the skbs checksum level by one layer up or down, or
+  * 		reset it entirely to none in order to have the stack perform
+  * 		checksum validation. The level is applicable to the following
+  * 		protocols: TCP, UDP, GRE, SCTP, FCOE. For example, a decap of
+  * 		| ETH | IP | UDP | GUE | IP | TCP | into | ETH | IP | TCP |
+  * 		through **bpf_skb_adjust_room**\ () helper with passing in
+  * 		**BPF_F_ADJ_ROOM_NO_CSUM_RESET** flag would require one	call
+  * 		to **bpf_csum_level**\ () with **BPF_CSUM_LEVEL_DEC** since
+  * 		the UDP header is removed. Similarly, an encap of the latter
+  * 		into the former could be accompanied by a helper call to
+  * 		**bpf_csum_level**\ () with **BPF_CSUM_LEVEL_INC** if the
+  * 		skb is still intended to be processed in higher layers of the
+  * 		stack instead of just egressing at tc.
+  *
+  * 		There are three supported level settings at this time:
+  *
+  * 		* **BPF_CSUM_LEVEL_INC**: Increases skb->csum_level for skbs
+  * 		  with CHECKSUM_UNNECESSARY.
+  * 		* **BPF_CSUM_LEVEL_DEC**: Decreases skb->csum_level for skbs
+  * 		  with CHECKSUM_UNNECESSARY.
+  * 		* **BPF_CSUM_LEVEL_RESET**: Resets skb->csum_level to 0 and
+  * 		  sets CHECKSUM_NONE to force checksum validation by the stack.
+  * 		* **BPF_CSUM_LEVEL_QUERY**: No-op, returns the current
+  * 		  skb->csum_level.
+  * 	Return
+  * 		0 on success, or a negative error in case of failure. In the
+  * 		case of **BPF_CSUM_LEVEL_QUERY**, the current skb->csum_level
+  * 		is returned or the error code -EACCES in case the skb is not
+  * 		subject to CHECKSUM_UNNECESSARY.
+  *
+  * struct tcp6_sock *bpf_skc_to_tcp6_sock(void *sk)
+  *	Description
+  *		Dynamically cast a *sk* pointer to a *tcp6_sock* pointer.
+  *	Return
+  *		*sk* if casting is valid, or NULL otherwise.
++>>>>>>> af7ec1383361 (bpf: Add bpf_skc_to_tcp6_sock() helper)
   */
  #define __BPF_FUNC_MAPPER(FN)		\
  	FN(unspec),			\
@@@ -3229,7 -3390,16 +3356,20 @@@
  	FN(sk_assign),			\
  	FN(ktime_get_boot_ns),		\
  	FN(seq_printf),			\
++<<<<<<< HEAD
 +	FN(seq_write),
++=======
+ 	FN(seq_write),			\
+ 	FN(sk_cgroup_id),		\
+ 	FN(sk_ancestor_cgroup_id),	\
+ 	FN(ringbuf_output),		\
+ 	FN(ringbuf_reserve),		\
+ 	FN(ringbuf_submit),		\
+ 	FN(ringbuf_discard),		\
+ 	FN(ringbuf_query),		\
+ 	FN(csum_level),			\
+ 	FN(skc_to_tcp6_sock),
++>>>>>>> af7ec1383361 (bpf: Add bpf_skc_to_tcp6_sock() helper)
  
  /* integer value in 'imm' field of BPF_CALL instruction selects which helper
   * function eBPF program intends to call
* Unmerged path include/linux/bpf.h
* Unmerged path include/uapi/linux/bpf.h
diff --git a/kernel/bpf/btf.c b/kernel/bpf/btf.c
index bcee2f08fd19..357c55caf6b5 100644
--- a/kernel/bpf/btf.c
+++ b/kernel/bpf/btf.c
@@ -3635,6 +3635,7 @@ struct btf *btf_parse_vmlinux(void)
 	bpf_ctx_convert.t = btf_type_by_id(btf, btf_id);
 
 	bpf_struct_ops_init(btf, log);
+	init_btf_sock_ids(btf);
 
 	btf_verifier_env_free(env);
 	refcount_set(&btf->refcnt, 1);
* Unmerged path kernel/bpf/verifier.c
diff --git a/kernel/trace/bpf_trace.c b/kernel/trace/bpf_trace.c
index 29a70cbf26d7..68cb2d0b472d 100644
--- a/kernel/trace/bpf_trace.c
+++ b/kernel/trace/bpf_trace.c
@@ -1459,6 +1459,8 @@ tracing_prog_func_proto(enum bpf_func_id func_id, const struct bpf_prog *prog)
 		return &bpf_skb_output_proto;
 	case BPF_FUNC_xdp_output:
 		return &bpf_xdp_output_proto;
+	case BPF_FUNC_skc_to_tcp6_sock:
+		return &bpf_skc_to_tcp6_sock_proto;
 #endif
 	case BPF_FUNC_seq_printf:
 		return prog->expected_attach_type == BPF_TRACE_ITER ?
diff --git a/net/core/filter.c b/net/core/filter.c
index 76aa4a2037db..2b00f2e54446 100644
--- a/net/core/filter.c
+++ b/net/core/filter.c
@@ -51,6 +51,7 @@
 #include <linux/seccomp.h>
 #include <linux/if_vlan.h>
 #include <linux/bpf.h>
+#include <linux/btf.h>
 #include <net/sch_generic.h>
 #include <net/cls_cgroup.h>
 #include <net/dst_metadata.h>
@@ -9114,3 +9115,84 @@ void bpf_prog_change_xdp(struct bpf_prog *prev_prog, struct bpf_prog *prog)
 {
 	bpf_dispatcher_change_prog(BPF_DISPATCHER_PTR(xdp), prev_prog, prog);
 }
+
+/* Define a list of socket types which can be the argument for
+ * skc_to_*_sock() helpers. All these sockets should have
+ * sock_common as the first argument in its memory layout.
+ */
+#define BTF_SOCK_TYPE_xxx \
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_INET, "inet_sock")			\
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_INET_CONN, "inet_connection_sock")	\
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_INET_REQ, "inet_request_sock")	\
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_INET_TW, "inet_timewait_sock")	\
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_REQ, "request_sock")		\
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_SOCK, "sock")			\
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_SOCK_COMMON, "sock_common")		\
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_TCP, "tcp_sock")			\
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_TCP_REQ, "tcp_request_sock")	\
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_TCP_TW, "tcp_timewait_sock")	\
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_TCP6, "tcp6_sock")			\
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_UDP, "udp_sock")			\
+	BTF_SOCK_TYPE(BTF_SOCK_TYPE_UDP6, "udp6_sock")
+
+enum {
+#define BTF_SOCK_TYPE(name, str) name,
+BTF_SOCK_TYPE_xxx
+#undef BTF_SOCK_TYPE
+MAX_BTF_SOCK_TYPE,
+};
+
+static int btf_sock_ids[MAX_BTF_SOCK_TYPE];
+
+#ifdef CONFIG_BPF_SYSCALL
+static const char *bpf_sock_types[] = {
+#define BTF_SOCK_TYPE(name, str) str,
+BTF_SOCK_TYPE_xxx
+#undef BTF_SOCK_TYPE
+};
+
+void init_btf_sock_ids(struct btf *btf)
+{
+	int i, btf_id;
+
+	for (i = 0; i < MAX_BTF_SOCK_TYPE; i++) {
+		btf_id = btf_find_by_name_kind(btf, bpf_sock_types[i],
+					       BTF_KIND_STRUCT);
+		if (btf_id > 0)
+			btf_sock_ids[i] = btf_id;
+	}
+}
+#endif
+
+static bool check_arg_btf_id(u32 btf_id, u32 arg)
+{
+	int i;
+
+	/* only one argument, no need to check arg */
+	for (i = 0; i < MAX_BTF_SOCK_TYPE; i++)
+		if (btf_sock_ids[i] == btf_id)
+			return true;
+	return false;
+}
+
+BPF_CALL_1(bpf_skc_to_tcp6_sock, struct sock *, sk)
+{
+	/* tcp6_sock type is not generated in dwarf and hence btf,
+	 * trigger an explicit type generation here.
+	 */
+	BTF_TYPE_EMIT(struct tcp6_sock);
+	if (sk_fullsock(sk) && sk->sk_protocol == IPPROTO_TCP &&
+	    sk->sk_family == AF_INET6)
+		return (unsigned long)sk;
+
+	return (unsigned long)NULL;
+}
+
+const struct bpf_func_proto bpf_skc_to_tcp6_sock_proto = {
+	.func			= bpf_skc_to_tcp6_sock,
+	.gpl_only		= false,
+	.ret_type		= RET_PTR_TO_BTF_ID_OR_NULL,
+	.arg1_type		= ARG_PTR_TO_BTF_ID,
+	.check_btf_id		= check_arg_btf_id,
+	.ret_btf_id		= &btf_sock_ids[BTF_SOCK_TYPE_TCP6],
+};
diff --git a/scripts/bpf_helpers_doc.py b/scripts/bpf_helpers_doc.py
index 91fa668fa860..6c2f64118651 100755
--- a/scripts/bpf_helpers_doc.py
+++ b/scripts/bpf_helpers_doc.py
@@ -421,6 +421,7 @@ class PrinterHelpers(Printer):
             'struct sockaddr',
             'struct tcphdr',
             'struct seq_file',
+            'struct tcp6_sock',
 
             'struct __sk_buff',
             'struct sk_msg_md',
@@ -458,6 +459,7 @@ class PrinterHelpers(Printer):
             'struct sockaddr',
             'struct tcphdr',
             'struct seq_file',
+            'struct tcp6_sock',
     }
     mapped_types = {
             'u8': '__u8',
* Unmerged path tools/include/uapi/linux/bpf.h
