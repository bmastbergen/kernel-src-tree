x86/dumpstack/64: Add noinstr version of get_stack_info()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
Rebuild_CHGLOG: - [x86] dumpstack/64: Add noinstr version of get_stack_info() (Vitaly Kuznetsov) [1868080]
Rebuild_FUZZ: 96.36%
commit-author Joerg Roedel <jroedel@suse.de>
commit 6b27edd74a5e9669120f7bd0ae1f475d124c1042
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/6b27edd7.failed

The get_stack_info() functionality is needed in the entry code for the
#VC exception handler. Provide a version of it in the .text.noinstr
section which can be called safely from there.

	Signed-off-by: Joerg Roedel <jroedel@suse.de>
	Signed-off-by: Borislav Petkov <bp@suse.de>
Link: https://lkml.kernel.org/r/20200907131613.12703-45-joro@8bytes.org
(cherry picked from commit 6b27edd74a5e9669120f7bd0ae1f475d124c1042)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/dumpstack_64.c
diff --cc arch/x86/kernel/dumpstack_64.c
index 35a75d2d7b5a,1dd851397bd9..000000000000
--- a/arch/x86/kernel/dumpstack_64.c
+++ b/arch/x86/kernel/dumpstack_64.c
@@@ -52,34 -50,83 +52,73 @@@ const char *stack_type_name(enum stack_
  	return NULL;
  }
  
++<<<<<<< HEAD
 +static bool in_exception_stack(unsigned long *stack, struct stack_info *info)
++=======
+ /**
+  * struct estack_pages - Page descriptor for exception stacks
+  * @offs:	Offset from the start of the exception stack area
+  * @size:	Size of the exception stack
+  * @type:	Type to store in the stack_info struct
+  */
+ struct estack_pages {
+ 	u32	offs;
+ 	u16	size;
+ 	u16	type;
+ };
+ 
+ #define EPAGERANGE(st)							\
+ 	[PFN_DOWN(CEA_ESTACK_OFFS(st)) ...				\
+ 	 PFN_DOWN(CEA_ESTACK_OFFS(st) + CEA_ESTACK_SIZE(st) - 1)] = {	\
+ 		.offs	= CEA_ESTACK_OFFS(st),				\
+ 		.size	= CEA_ESTACK_SIZE(st),				\
+ 		.type	= STACK_TYPE_EXCEPTION + ESTACK_ ##st, }
+ 
+ /*
+  * Array of exception stack page descriptors. If the stack is larger than
+  * PAGE_SIZE, all pages covering a particular stack will have the same
+  * info. The guard pages including the not mapped DB2 stack are zeroed
+  * out.
+  */
+ static const
+ struct estack_pages estack_pages[CEA_ESTACK_PAGES] ____cacheline_aligned = {
+ 	EPAGERANGE(DF),
+ 	EPAGERANGE(NMI),
+ 	EPAGERANGE(DB),
+ 	EPAGERANGE(MCE),
+ 	EPAGERANGE(VC),
+ 	EPAGERANGE(VC2),
+ };
+ 
+ static __always_inline bool in_exception_stack(unsigned long *stack, struct stack_info *info)
++>>>>>>> 6b27edd74a5e (x86/dumpstack/64: Add noinstr version of get_stack_info())
  {
 -	unsigned long begin, end, stk = (unsigned long)stack;
 -	const struct estack_pages *ep;
 +	unsigned long *begin, *end;
  	struct pt_regs *regs;
 -	unsigned int k;
 +	unsigned k;
  
 -	BUILD_BUG_ON(N_EXCEPTION_STACKS != 6);
 +	BUILD_BUG_ON(N_EXCEPTION_STACKS != 4);
  
 -	begin = (unsigned long)__this_cpu_read(cea_exception_stacks);
 -	/*
 -	 * Handle the case where stack trace is collected _before_
 -	 * cea_exception_stacks had been initialized.
 -	 */
 -	if (!begin)
 -		return false;
 +	for (k = 0; k < N_EXCEPTION_STACKS; k++) {
 +		end   = (unsigned long *)raw_cpu_ptr(&orig_ist)->ist[k];
 +		begin = end - (exception_stack_sizes[k] / sizeof(long));
 +		regs  = (struct pt_regs *)end - 1;
  
 -	end = begin + sizeof(struct cea_exception_stacks);
 -	/* Bail if @stack is outside the exception stack area. */
 -	if (stk < begin || stk >= end)
 -		return false;
 +		if (stack < begin || stack >= end)
 +			continue;
  
 -	/* Calc page offset from start of exception stacks */
 -	k = (stk - begin) >> PAGE_SHIFT;
 -	/* Lookup the page descriptor */
 -	ep = &estack_pages[k];
 -	/* Guard page? */
 -	if (!ep->size)
 -		return false;
 +		info->type	= STACK_TYPE_EXCEPTION + k;
 +		info->begin	= begin;
 +		info->end	= end;
 +		info->next_sp	= (unsigned long *)regs->sp;
  
 -	begin += (unsigned long)ep->offs;
 -	end = begin + (unsigned long)ep->size;
 -	regs = (struct pt_regs *)end - 1;
 +		return true;
 +	}
  
 -	info->type	= ep->type;
 -	info->begin	= (unsigned long *)begin;
 -	info->end	= (unsigned long *)end;
 -	info->next_sp	= (unsigned long *)regs->sp;
 -	return true;
 +	return false;
  }
  
- static bool in_irq_stack(unsigned long *stack, struct stack_info *info)
+ static __always_inline bool in_irq_stack(unsigned long *stack, struct stack_info *info)
  {
  	unsigned long *end   = (unsigned long *)this_cpu_read(hardirq_stack_ptr);
  	unsigned long *begin = end - (IRQ_STACK_SIZE / sizeof(long));
diff --git a/arch/x86/include/asm/stacktrace.h b/arch/x86/include/asm/stacktrace.h
index cfbabdd5dc13..f1c700413db2 100644
--- a/arch/x86/include/asm/stacktrace.h
+++ b/arch/x86/include/asm/stacktrace.h
@@ -33,6 +33,8 @@ bool in_entry_stack(unsigned long *stack, struct stack_info *info);
 
 int get_stack_info(unsigned long *stack, struct task_struct *task,
 		   struct stack_info *info, unsigned long *visit_mask);
+bool get_stack_info_noinstr(unsigned long *stack, struct task_struct *task,
+			    struct stack_info *info);
 
 const char *stack_type_name(enum stack_type type);
 
diff --git a/arch/x86/kernel/dumpstack.c b/arch/x86/kernel/dumpstack.c
index e07424e19274..60a133ade271 100644
--- a/arch/x86/kernel/dumpstack.c
+++ b/arch/x86/kernel/dumpstack.c
@@ -29,8 +29,8 @@ static int die_counter;
 
 static struct pt_regs exec_summary_regs;
 
-bool in_task_stack(unsigned long *stack, struct task_struct *task,
-		   struct stack_info *info)
+bool noinstr in_task_stack(unsigned long *stack, struct task_struct *task,
+			   struct stack_info *info)
 {
 	unsigned long *begin = task_stack_page(task);
 	unsigned long *end   = task_stack_page(task) + THREAD_SIZE;
@@ -46,7 +46,8 @@ bool in_task_stack(unsigned long *stack, struct task_struct *task,
 	return true;
 }
 
-bool in_entry_stack(unsigned long *stack, struct stack_info *info)
+/* Called from get_stack_info_noinstr - so must be noinstr too */
+bool noinstr in_entry_stack(unsigned long *stack, struct stack_info *info)
 {
 	struct entry_stack *ss = cpu_entry_stack(smp_processor_id());
 
* Unmerged path arch/x86/kernel/dumpstack_64.c
diff --git a/arch/x86/mm/cpu_entry_area.c b/arch/x86/mm/cpu_entry_area.c
index 26fa2a5a8715..bedf5a969bfc 100644
--- a/arch/x86/mm/cpu_entry_area.c
+++ b/arch/x86/mm/cpu_entry_area.c
@@ -17,7 +17,8 @@ static DEFINE_PER_CPU_PAGE_ALIGNED(char, exception_stacks
 	[(N_EXCEPTION_STACKS - 1) * EXCEPTION_STKSZ + DEBUG_STKSZ]);
 #endif
 
-struct cpu_entry_area *get_cpu_entry_area(int cpu)
+/* Is called from entry code, so must be noinstr */
+noinstr struct cpu_entry_area *get_cpu_entry_area(int cpu)
 {
 	unsigned long va = CPU_ENTRY_AREA_PER_CPU + cpu * CPU_ENTRY_AREA_SIZE;
 	BUILD_BUG_ON(sizeof(struct cpu_entry_area) % PAGE_SIZE != 0);
