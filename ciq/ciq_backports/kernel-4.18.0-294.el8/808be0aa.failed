iommu: Introduce guest PASID bind function

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Jacob Pan <jacob.jun.pan@linux.intel.com>
commit 808be0aae53a3675337fad9cde616e086bdc8287
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/808be0aa.failed

Guest shared virtual address (SVA) may require host to shadow guest
PASID tables. Guest PASID can also be allocated from the host via
enlightened interfaces. In this case, guest needs to bind the guest
mm, i.e. cr3 in guest physical address to the actual PASID table in
the host IOMMU. Nesting will be turned on such that guest virtual
address can go through a two level translation:
- 1st level translates GVA to GPA
- 2nd level translates GPA to HPA
This patch introduces APIs to bind guest PASID data to the assigned
device entry in the physical IOMMU. See the diagram below for usage
explanation.

    .-------------.  .---------------------------.
    |   vIOMMU    |  | Guest process mm, FL only |
    |             |  '---------------------------'
    .----------------/
    | PASID Entry |--- PASID cache flush -
    '-------------'                       |
    |             |                       V
    |             |                      GP
    '-------------'
Guest
------| Shadow |----------------------- GP->HP* ---------
      v        v                          |
Host                                      v
    .-------------.  .----------------------.
    |   pIOMMU    |  | Bind FL for GVA-GPA  |
    |             |  '----------------------'
    .----------------/  |
    | PASID Entry |     V (Nested xlate)
    '----------------\.---------------------.
    |             |   |Set SL to GPA-HPA    |
    |             |   '---------------------'
    '-------------'

Where:
 - FL = First level/stage one page tables
 - SL = Second level/stage two page tables
 - GP = Guest PASID
 - HP = Host PASID
* Conversion needed if non-identity GP-HP mapping option is chosen.

	Signed-off-by: Jacob Pan <jacob.jun.pan@linux.intel.com>
	Signed-off-by: Liu Yi L <yi.l.liu@intel.com>
	Reviewed-by: Jean-Philippe Brucker <jean-philippe@linaro.com>
	Reviewed-by: Jean-Philippe Brucker <jean-philippe@linaro.org>
	Reviewed-by: Eric Auger <eric.auger@redhat.com>
	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit 808be0aae53a3675337fad9cde616e086bdc8287)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/iommu.c
#	include/linux/iommu.h
#	include/uapi/linux/iommu.h
diff --cc drivers/iommu/iommu.c
index fc3ac9f31346,4486c4e6830a..000000000000
--- a/drivers/iommu/iommu.c
+++ b/drivers/iommu/iommu.c
@@@ -1949,6 -1665,36 +1949,39 @@@ out_unlock
  }
  EXPORT_SYMBOL_GPL(iommu_attach_device);
  
++<<<<<<< HEAD
++=======
+ int iommu_cache_invalidate(struct iommu_domain *domain, struct device *dev,
+ 			   struct iommu_cache_invalidate_info *inv_info)
+ {
+ 	if (unlikely(!domain->ops->cache_invalidate))
+ 		return -ENODEV;
+ 
+ 	return domain->ops->cache_invalidate(domain, dev, inv_info);
+ }
+ EXPORT_SYMBOL_GPL(iommu_cache_invalidate);
+ 
+ int iommu_sva_bind_gpasid(struct iommu_domain *domain,
+ 			   struct device *dev, struct iommu_gpasid_bind_data *data)
+ {
+ 	if (unlikely(!domain->ops->sva_bind_gpasid))
+ 		return -ENODEV;
+ 
+ 	return domain->ops->sva_bind_gpasid(domain, dev, data);
+ }
+ EXPORT_SYMBOL_GPL(iommu_sva_bind_gpasid);
+ 
+ int iommu_sva_unbind_gpasid(struct iommu_domain *domain, struct device *dev,
+ 			     ioasid_t pasid)
+ {
+ 	if (unlikely(!domain->ops->sva_unbind_gpasid))
+ 		return -ENODEV;
+ 
+ 	return domain->ops->sva_unbind_gpasid(dev, pasid);
+ }
+ EXPORT_SYMBOL_GPL(iommu_sva_unbind_gpasid);
+ 
++>>>>>>> 808be0aae53a (iommu: Introduce guest PASID bind function)
  static void __iommu_detach_device(struct iommu_domain *domain,
  				  struct device *dev)
  {
diff --cc include/linux/iommu.h
index 8f7c43366b8f,f8959f759e41..000000000000
--- a/include/linux/iommu.h
+++ b/include/linux/iommu.h
@@@ -25,7 -13,7 +25,11 @@@
  #include <linux/errno.h>
  #include <linux/err.h>
  #include <linux/of.h>
++<<<<<<< HEAD
 +#include <linux/rh_kabi.h>
++=======
+ #include <linux/ioasid.h>
++>>>>>>> 808be0aae53a (iommu: Introduce guest PASID bind function)
  #include <uapi/linux/iommu.h>
  
  #define IOMMU_READ	(1 << 0)
@@@ -263,12 -245,10 +267,17 @@@ struct iommu_iotlb_gather 
   * @sva_unbind: Unbind process address space from device
   * @sva_get_pasid: Get PASID associated to a SVA handle
   * @page_response: handle page request response
 - * @cache_invalidate: invalidate translation caches
 + * @def_domain_type: device default domain type, return value:
 + *		- IOMMU_DOMAIN_IDENTITY: must use an identity domain
 + *		- IOMMU_DOMAIN_DMA: must use a dma domain
 + *		- 0: use the default setting
   * @pgsize_bitmap: bitmap of all possible supported page sizes
++<<<<<<< HEAD
 + * @owner: Driver module providing these ops
++=======
+  * @sva_bind_gpasid: bind guest pasid and mm
+  * @sva_unbind_gpasid: unbind guest pasid and mm
++>>>>>>> 808be0aae53a (iommu: Introduce guest PASID bind function)
   */
  struct iommu_ops {
  	bool (*capable)(enum iommu_cap);
@@@ -340,14 -309,15 +349,23 @@@
  	int (*page_response)(struct device *dev,
  			     struct iommu_fault_event *evt,
  			     struct iommu_page_response *msg);
++<<<<<<< HEAD
 +	int (*def_domain_type)(struct device *dev);
 +	struct iommu_device *(*probe_device)(struct device *dev);
 +	void (*release_device)(struct device *dev);
 +	void (*probe_finalize)(struct device *dev);
 +	) /* RH_KABI_BROKEN_INSERT_BLOCK */
++=======
+ 	int (*cache_invalidate)(struct iommu_domain *domain, struct device *dev,
+ 				struct iommu_cache_invalidate_info *inv_info);
+ 	int (*sva_bind_gpasid)(struct iommu_domain *domain,
+ 			struct device *dev, struct iommu_gpasid_bind_data *data);
+ 
+ 	int (*sva_unbind_gpasid)(struct device *dev, int pasid);
++>>>>>>> 808be0aae53a (iommu: Introduce guest PASID bind function)
  
  	unsigned long pgsize_bitmap;
 +	RH_KABI_BROKEN_INSERT(struct module *owner)
  };
  
  /**
@@@ -470,6 -427,13 +488,16 @@@ extern int iommu_attach_device(struct i
  			       struct device *dev);
  extern void iommu_detach_device(struct iommu_domain *domain,
  				struct device *dev);
++<<<<<<< HEAD
++=======
+ extern int iommu_cache_invalidate(struct iommu_domain *domain,
+ 				  struct device *dev,
+ 				  struct iommu_cache_invalidate_info *inv_info);
+ extern int iommu_sva_bind_gpasid(struct iommu_domain *domain,
+ 		struct device *dev, struct iommu_gpasid_bind_data *data);
+ extern int iommu_sva_unbind_gpasid(struct iommu_domain *domain,
+ 				struct device *dev, ioasid_t pasid);
++>>>>>>> 808be0aae53a (iommu: Introduce guest PASID bind function)
  extern struct iommu_domain *iommu_get_domain_for_dev(struct device *dev);
  extern struct iommu_domain *iommu_get_dma_domain(struct device *dev);
  extern int iommu_map(struct iommu_domain *domain, unsigned long iova,
@@@ -1091,10 -1022,25 +1119,25 @@@ static inline int iommu_sva_get_pasid(s
  	return IOMMU_PASID_INVALID;
  }
  
 -static inline int
 -iommu_cache_invalidate(struct iommu_domain *domain,
 -		       struct device *dev,
 -		       struct iommu_cache_invalidate_info *inv_info)
 +static inline struct iommu_fwspec *dev_iommu_fwspec_get(struct device *dev)
  {
 -	return -ENODEV;
 +	return NULL;
  }
++<<<<<<< HEAD
++=======
+ static inline int iommu_sva_bind_gpasid(struct iommu_domain *domain,
+ 				struct device *dev, struct iommu_gpasid_bind_data *data)
+ {
+ 	return -ENODEV;
+ }
+ 
+ static inline int iommu_sva_unbind_gpasid(struct iommu_domain *domain,
+ 					   struct device *dev, int pasid)
+ {
+ 	return -ENODEV;
+ }
+ 
++>>>>>>> 808be0aae53a (iommu: Introduce guest PASID bind function)
  #endif /* CONFIG_IOMMU_API */
  
  #ifdef CONFIG_IOMMU_DEBUGFS
diff --cc include/uapi/linux/iommu.h
index fc00c5d4741b,4ad3496e5c43..000000000000
--- a/include/uapi/linux/iommu.h
+++ b/include/uapi/linux/iommu.h
@@@ -152,4 -152,173 +152,176 @@@ struct iommu_page_response 
  	__u32	code;
  };
  
++<<<<<<< HEAD
++=======
+ /* defines the granularity of the invalidation */
+ enum iommu_inv_granularity {
+ 	IOMMU_INV_GRANU_DOMAIN,	/* domain-selective invalidation */
+ 	IOMMU_INV_GRANU_PASID,	/* PASID-selective invalidation */
+ 	IOMMU_INV_GRANU_ADDR,	/* page-selective invalidation */
+ 	IOMMU_INV_GRANU_NR,	/* number of invalidation granularities */
+ };
+ 
+ /**
+  * struct iommu_inv_addr_info - Address Selective Invalidation Structure
+  *
+  * @flags: indicates the granularity of the address-selective invalidation
+  * - If the PASID bit is set, the @pasid field is populated and the invalidation
+  *   relates to cache entries tagged with this PASID and matching the address
+  *   range.
+  * - If ARCHID bit is set, @archid is populated and the invalidation relates
+  *   to cache entries tagged with this architecture specific ID and matching
+  *   the address range.
+  * - Both PASID and ARCHID can be set as they may tag different caches.
+  * - If neither PASID or ARCHID is set, global addr invalidation applies.
+  * - The LEAF flag indicates whether only the leaf PTE caching needs to be
+  *   invalidated and other paging structure caches can be preserved.
+  * @pasid: process address space ID
+  * @archid: architecture-specific ID
+  * @addr: first stage/level input address
+  * @granule_size: page/block size of the mapping in bytes
+  * @nb_granules: number of contiguous granules to be invalidated
+  */
+ struct iommu_inv_addr_info {
+ #define IOMMU_INV_ADDR_FLAGS_PASID	(1 << 0)
+ #define IOMMU_INV_ADDR_FLAGS_ARCHID	(1 << 1)
+ #define IOMMU_INV_ADDR_FLAGS_LEAF	(1 << 2)
+ 	__u32	flags;
+ 	__u32	archid;
+ 	__u64	pasid;
+ 	__u64	addr;
+ 	__u64	granule_size;
+ 	__u64	nb_granules;
+ };
+ 
+ /**
+  * struct iommu_inv_pasid_info - PASID Selective Invalidation Structure
+  *
+  * @flags: indicates the granularity of the PASID-selective invalidation
+  * - If the PASID bit is set, the @pasid field is populated and the invalidation
+  *   relates to cache entries tagged with this PASID and matching the address
+  *   range.
+  * - If the ARCHID bit is set, the @archid is populated and the invalidation
+  *   relates to cache entries tagged with this architecture specific ID and
+  *   matching the address range.
+  * - Both PASID and ARCHID can be set as they may tag different caches.
+  * - At least one of PASID or ARCHID must be set.
+  * @pasid: process address space ID
+  * @archid: architecture-specific ID
+  */
+ struct iommu_inv_pasid_info {
+ #define IOMMU_INV_PASID_FLAGS_PASID	(1 << 0)
+ #define IOMMU_INV_PASID_FLAGS_ARCHID	(1 << 1)
+ 	__u32	flags;
+ 	__u32	archid;
+ 	__u64	pasid;
+ };
+ 
+ /**
+  * struct iommu_cache_invalidate_info - First level/stage invalidation
+  *     information
+  * @version: API version of this structure
+  * @cache: bitfield that allows to select which caches to invalidate
+  * @granularity: defines the lowest granularity used for the invalidation:
+  *     domain > PASID > addr
+  * @padding: reserved for future use (should be zero)
+  * @pasid_info: invalidation data when @granularity is %IOMMU_INV_GRANU_PASID
+  * @addr_info: invalidation data when @granularity is %IOMMU_INV_GRANU_ADDR
+  *
+  * Not all the combinations of cache/granularity are valid:
+  *
+  * +--------------+---------------+---------------+---------------+
+  * | type /       |   DEV_IOTLB   |     IOTLB     |      PASID    |
+  * | granularity  |               |               |      cache    |
+  * +==============+===============+===============+===============+
+  * | DOMAIN       |       N/A     |       Y       |       Y       |
+  * +--------------+---------------+---------------+---------------+
+  * | PASID        |       Y       |       Y       |       Y       |
+  * +--------------+---------------+---------------+---------------+
+  * | ADDR         |       Y       |       Y       |       N/A     |
+  * +--------------+---------------+---------------+---------------+
+  *
+  * Invalidations by %IOMMU_INV_GRANU_DOMAIN don't take any argument other than
+  * @version and @cache.
+  *
+  * If multiple cache types are invalidated simultaneously, they all
+  * must support the used granularity.
+  */
+ struct iommu_cache_invalidate_info {
+ #define IOMMU_CACHE_INVALIDATE_INFO_VERSION_1 1
+ 	__u32	version;
+ /* IOMMU paging structure cache */
+ #define IOMMU_CACHE_INV_TYPE_IOTLB	(1 << 0) /* IOMMU IOTLB */
+ #define IOMMU_CACHE_INV_TYPE_DEV_IOTLB	(1 << 1) /* Device IOTLB */
+ #define IOMMU_CACHE_INV_TYPE_PASID	(1 << 2) /* PASID cache */
+ #define IOMMU_CACHE_INV_TYPE_NR		(3)
+ 	__u8	cache;
+ 	__u8	granularity;
+ 	__u8	padding[2];
+ 	union {
+ 		struct iommu_inv_pasid_info pasid_info;
+ 		struct iommu_inv_addr_info addr_info;
+ 	};
+ };
+ 
+ /**
+  * struct iommu_gpasid_bind_data_vtd - Intel VT-d specific data on device and guest
+  * SVA binding.
+  *
+  * @flags:	VT-d PASID table entry attributes
+  * @pat:	Page attribute table data to compute effective memory type
+  * @emt:	Extended memory type
+  *
+  * Only guest vIOMMU selectable and effective options are passed down to
+  * the host IOMMU.
+  */
+ struct iommu_gpasid_bind_data_vtd {
+ #define IOMMU_SVA_VTD_GPASID_SRE	(1 << 0) /* supervisor request */
+ #define IOMMU_SVA_VTD_GPASID_EAFE	(1 << 1) /* extended access enable */
+ #define IOMMU_SVA_VTD_GPASID_PCD	(1 << 2) /* page-level cache disable */
+ #define IOMMU_SVA_VTD_GPASID_PWT	(1 << 3) /* page-level write through */
+ #define IOMMU_SVA_VTD_GPASID_EMTE	(1 << 4) /* extended mem type enable */
+ #define IOMMU_SVA_VTD_GPASID_CD		(1 << 5) /* PASID-level cache disable */
+ 	__u64 flags;
+ 	__u32 pat;
+ 	__u32 emt;
+ };
+ 
+ /**
+  * struct iommu_gpasid_bind_data - Information about device and guest PASID binding
+  * @version:	Version of this data structure
+  * @format:	PASID table entry format
+  * @flags:	Additional information on guest bind request
+  * @gpgd:	Guest page directory base of the guest mm to bind
+  * @hpasid:	Process address space ID used for the guest mm in host IOMMU
+  * @gpasid:	Process address space ID used for the guest mm in guest IOMMU
+  * @addr_width:	Guest virtual address width
+  * @padding:	Reserved for future use (should be zero)
+  * @vtd:	Intel VT-d specific data
+  *
+  * Guest to host PASID mapping can be an identity or non-identity, where guest
+  * has its own PASID space. For non-identify mapping, guest to host PASID lookup
+  * is needed when VM programs guest PASID into an assigned device. VMM may
+  * trap such PASID programming then request host IOMMU driver to convert guest
+  * PASID to host PASID based on this bind data.
+  */
+ struct iommu_gpasid_bind_data {
+ #define IOMMU_GPASID_BIND_VERSION_1	1
+ 	__u32 version;
+ #define IOMMU_PASID_FORMAT_INTEL_VTD	1
+ 	__u32 format;
+ #define IOMMU_SVA_GPASID_VAL	(1 << 0) /* guest PASID valid */
+ 	__u64 flags;
+ 	__u64 gpgd;
+ 	__u64 hpasid;
+ 	__u64 gpasid;
+ 	__u32 addr_width;
+ 	__u8  padding[12];
+ 	/* Vendor specific data */
+ 	union {
+ 		struct iommu_gpasid_bind_data_vtd vtd;
+ 	};
+ };
+ 
++>>>>>>> 808be0aae53a (iommu: Introduce guest PASID bind function)
  #endif /* _UAPI_IOMMU_H */
* Unmerged path drivers/iommu/iommu.c
* Unmerged path include/linux/iommu.h
* Unmerged path include/uapi/linux/iommu.h
