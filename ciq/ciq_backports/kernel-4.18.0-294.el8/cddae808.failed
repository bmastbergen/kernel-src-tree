block: pass a hd_struct to delete_partition

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Christoph Hellwig <hch@lst.de>
commit cddae808aeb77e5c29d22a8e0dfbdaed413f9e04
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/cddae808.failed

All callers have the hd_struct at hand, so pass it instead of performing
another lookup.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit cddae808aeb77e5c29d22a8e0dfbdaed413f9e04)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk.h
#	block/partition-generic.c
diff --cc block/blk.h
index 5c44b4751a29,0cbf64108922..000000000000
--- a/block/blk.h
+++ b/block/blk.h
@@@ -342,10 -375,119 +342,37 @@@ void blk_queue_free_zone_bitmaps(struc
  static inline void blk_queue_free_zone_bitmaps(struct request_queue *q) {}
  #endif
  
++<<<<<<< HEAD
 +/* internal helper for accessing request_aux  */
 +static inline struct request_aux *rq_aux(const struct request *rq)
++=======
+ void part_dec_in_flight(struct request_queue *q, struct hd_struct *part,
+ 			int rw);
+ void part_inc_in_flight(struct request_queue *q, struct hd_struct *part,
+ 			int rw);
+ void update_io_ticks(struct hd_struct *part, unsigned long now, bool end);
+ struct hd_struct *disk_map_sector_rcu(struct gendisk *disk, sector_t sector);
+ 
+ int blk_alloc_devt(struct hd_struct *part, dev_t *devt);
+ void blk_free_devt(dev_t devt);
+ void blk_invalidate_devt(dev_t devt);
+ char *disk_name(struct gendisk *hd, int partno, char *buf);
+ #define ADDPART_FLAG_NONE	0
+ #define ADDPART_FLAG_RAID	1
+ #define ADDPART_FLAG_WHOLEDISK	2
+ void __delete_partition(struct percpu_ref *ref);
+ void delete_partition(struct gendisk *disk, struct hd_struct *part);
+ int bdev_add_partition(struct block_device *bdev, int partno,
+ 		sector_t start, sector_t length);
+ int bdev_del_partition(struct block_device *bdev, int partno);
+ int bdev_resize_partition(struct block_device *bdev, int partno,
+ 		sector_t start, sector_t length);
+ int disk_expand_part_tbl(struct gendisk *disk, int target);
+ 
+ static inline int hd_ref_init(struct hd_struct *part)
++>>>>>>> cddae808aeb7 (block: pass a hd_struct to delete_partition)
  {
 -	if (percpu_ref_init(&part->ref, __delete_partition, 0,
 -				GFP_KERNEL))
 -		return -ENOMEM;
 -	return 0;
 -}
 -
 -static inline void hd_struct_get(struct hd_struct *part)
 -{
 -	percpu_ref_get(&part->ref);
 -}
 -
 -static inline int hd_struct_try_get(struct hd_struct *part)
 -{
 -	return percpu_ref_tryget_live(&part->ref);
 +	return (struct request_aux *)((void *)rq - sizeof(struct request_aux));
  }
  
 -static inline void hd_struct_put(struct hd_struct *part)
 -{
 -	percpu_ref_put(&part->ref);
 -}
 -
 -static inline void hd_struct_kill(struct hd_struct *part)
 -{
 -	percpu_ref_kill(&part->ref);
 -}
 -
 -static inline void hd_free_part(struct hd_struct *part)
 -{
 -	free_part_stats(part);
 -	kfree(part->info);
 -	percpu_ref_exit(&part->ref);
 -}
 -
 -/*
 - * Any access of part->nr_sects which is not protected by partition
 - * bd_mutex or gendisk bdev bd_mutex, should be done using this
 - * accessor function.
 - *
 - * Code written along the lines of i_size_read() and i_size_write().
 - * CONFIG_PREEMPTION case optimizes the case of UP kernel with preemption
 - * on.
 - */
 -static inline sector_t part_nr_sects_read(struct hd_struct *part)
 -{
 -#if BITS_PER_LONG==32 && defined(CONFIG_SMP)
 -	sector_t nr_sects;
 -	unsigned seq;
 -	do {
 -		seq = read_seqcount_begin(&part->nr_sects_seq);
 -		nr_sects = part->nr_sects;
 -	} while (read_seqcount_retry(&part->nr_sects_seq, seq));
 -	return nr_sects;
 -#elif BITS_PER_LONG==32 && defined(CONFIG_PREEMPTION)
 -	sector_t nr_sects;
 -
 -	preempt_disable();
 -	nr_sects = part->nr_sects;
 -	preempt_enable();
 -	return nr_sects;
 -#else
 -	return part->nr_sects;
 -#endif
 -}
 -
 -/*
 - * Should be called with mutex lock held (typically bd_mutex) of partition
 - * to provide mutual exlusion among writers otherwise seqcount might be
 - * left in wrong state leaving the readers spinning infinitely.
 - */
 -static inline void part_nr_sects_write(struct hd_struct *part, sector_t size)
 -{
 -#if BITS_PER_LONG==32 && defined(CONFIG_SMP)
 -	write_seqcount_begin(&part->nr_sects_seq);
 -	part->nr_sects = size;
 -	write_seqcount_end(&part->nr_sects_seq);
 -#elif BITS_PER_LONG==32 && defined(CONFIG_PREEMPTION)
 -	preempt_disable();
 -	part->nr_sects = size;
 -	preempt_enable();
 -#else
 -	part->nr_sects = size;
 -#endif
 -}
 -
 -struct request_queue *__blk_alloc_queue(int node_id);
 -
 -int __bio_add_pc_page(struct request_queue *q, struct bio *bio,
 -		struct page *page, unsigned int len, unsigned int offset,
 -		bool *same_page);
 -
  #endif /* BLK_INTERNAL_H */
diff --cc block/partition-generic.c
index 459e9684cfbb,6dc534b502a9..000000000000
--- a/block/partition-generic.c
+++ b/block/partition-generic.c
@@@ -263,21 -300,9 +263,25 @@@ void delete_partition(struct gendisk *d
  {
  	struct disk_part_tbl *ptbl =
  		rcu_dereference_protected(disk->part_tbl, 1);
- 	struct hd_struct *part;
  
++<<<<<<< HEAD:block/partition-generic.c
 +	if (partno >= ptbl->len)
 +		return;
 +
 +	part = rcu_dereference_protected(ptbl->part[partno], 1);
 +	if (!part)
 +		return;
 +
 +	/*
 +	 * ->part_tbl is referenced in this part's release handler, so
 +	 *  we have to hold the disk device
 +	 */
 +	get_device(disk_to_dev(part_to_disk(part)));
 +	rcu_assign_pointer(ptbl->part[partno], NULL);
++=======
+ 	rcu_assign_pointer(ptbl->part[part->partno], NULL);
+ 	rcu_assign_pointer(ptbl->last_lookup, NULL);
++>>>>>>> cddae808aeb7 (block: pass a hd_struct to delete_partition):block/partitions/core.c
  	kobject_put(part->holder_dir);
  	device_del(part_to_dev(part));
  
@@@ -437,6 -464,121 +441,124 @@@ out_put
  	return ERR_PTR(err);
  }
  
++<<<<<<< HEAD:block/partition-generic.c
++=======
+ static bool partition_overlaps(struct gendisk *disk, sector_t start,
+ 		sector_t length, int skip_partno)
+ {
+ 	struct disk_part_iter piter;
+ 	struct hd_struct *part;
+ 	bool overlap = false;
+ 
+ 	disk_part_iter_init(&piter, disk, DISK_PITER_INCL_EMPTY);
+ 	while ((part = disk_part_iter_next(&piter))) {
+ 		if (part->partno == skip_partno ||
+ 		    start >= part->start_sect + part->nr_sects ||
+ 		    start + length <= part->start_sect)
+ 			continue;
+ 		overlap = true;
+ 		break;
+ 	}
+ 
+ 	disk_part_iter_exit(&piter);
+ 	return overlap;
+ }
+ 
+ int bdev_add_partition(struct block_device *bdev, int partno,
+ 		sector_t start, sector_t length)
+ {
+ 	struct hd_struct *part;
+ 
+ 	mutex_lock(&bdev->bd_mutex);
+ 	if (partition_overlaps(bdev->bd_disk, start, length, -1)) {
+ 		mutex_unlock(&bdev->bd_mutex);
+ 		return -EBUSY;
+ 	}
+ 
+ 	part = add_partition(bdev->bd_disk, partno, start, length,
+ 			ADDPART_FLAG_NONE, NULL);
+ 	mutex_unlock(&bdev->bd_mutex);
+ 	return PTR_ERR_OR_ZERO(part);
+ }
+ 
+ int bdev_del_partition(struct block_device *bdev, int partno)
+ {
+ 	struct block_device *bdevp;
+ 	struct hd_struct *part;
+ 	int ret = 0;
+ 
+ 	part = disk_get_part(bdev->bd_disk, partno);
+ 	if (!part)
+ 		return -ENXIO;
+ 
+ 	ret = -ENOMEM;
+ 	bdevp = bdget(part_devt(part));
+ 	if (!bdevp)
+ 		goto out_put_part;
+ 
+ 	mutex_lock(&bdevp->bd_mutex);
+ 
+ 	ret = -EBUSY;
+ 	if (bdevp->bd_openers)
+ 		goto out_unlock;
+ 
+ 	fsync_bdev(bdevp);
+ 	invalidate_bdev(bdevp);
+ 
+ 	mutex_lock_nested(&bdev->bd_mutex, 1);
+ 	delete_partition(bdev->bd_disk, part);
+ 	mutex_unlock(&bdev->bd_mutex);
+ 
+ 	ret = 0;
+ out_unlock:
+ 	mutex_unlock(&bdevp->bd_mutex);
+ 	bdput(bdevp);
+ out_put_part:
+ 	disk_put_part(part);
+ 	return ret;
+ }
+ 
+ int bdev_resize_partition(struct block_device *bdev, int partno,
+ 		sector_t start, sector_t length)
+ {
+ 	struct block_device *bdevp;
+ 	struct hd_struct *part;
+ 	int ret = 0;
+ 
+ 	part = disk_get_part(bdev->bd_disk, partno);
+ 	if (!part)
+ 		return -ENXIO;
+ 
+ 	ret = -ENOMEM;
+ 	bdevp = bdget(part_devt(part));
+ 	if (!bdevp)
+ 		goto out_put_part;
+ 
+ 	mutex_lock(&bdevp->bd_mutex);
+ 	mutex_lock_nested(&bdev->bd_mutex, 1);
+ 
+ 	ret = -EINVAL;
+ 	if (start != part->start_sect)
+ 		goto out_unlock;
+ 
+ 	ret = -EBUSY;
+ 	if (partition_overlaps(bdev->bd_disk, start, length, partno))
+ 		goto out_unlock;
+ 
+ 	part_nr_sects_write(part, (sector_t)length);
+ 	i_size_write(bdevp->bd_inode, length << SECTOR_SHIFT);
+ 
+ 	ret = 0;
+ out_unlock:
+ 	mutex_unlock(&bdevp->bd_mutex);
+ 	mutex_unlock(&bdev->bd_mutex);
+ 	bdput(bdevp);
+ out_put_part:
+ 	disk_put_part(part);
+ 	return ret;
+ }
+ 
++>>>>>>> cddae808aeb7 (block: pass a hd_struct to delete_partition):block/partitions/core.c
  static bool disk_unlock_native_capacity(struct gendisk *disk)
  {
  	const struct block_device_operations *bdops = disk->fops;
* Unmerged path block/blk.h
diff --git a/block/genhd.c b/block/genhd.c
index 4c34a620cd26..93387a8cf1b3 100644
--- a/block/genhd.c
+++ b/block/genhd.c
@@ -877,7 +877,7 @@ void del_gendisk(struct gendisk *disk)
 	while ((part = disk_part_iter_next(&piter))) {
 		invalidate_partition(disk, part->partno);
 		bdev_unhash_inode(part_devt(part));
-		delete_partition(disk, part->partno);
+		delete_partition(disk, part);
 	}
 	disk_part_iter_exit(&piter);
 
* Unmerged path block/partition-generic.c
