udp: Support UDP fraglist GRO/GSO.

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Steffen Klassert <steffen.klassert@secunet.com>
commit 9fd1ff5d2ac7181844735806b0a703c942365291
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/9fd1ff5d.failed

This patch extends UDP GRO to support fraglist GRO/GSO
by using the previously introduced infrastructure.
If the feature is enabled, all UDP packets are going to
fraglist GRO (local input and forward).

After validating the csum,  we mark ip_summed as
CHECKSUM_UNNECESSARY for fraglist GRO packets to
make sure that the csum is not touched.

	Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
	Reviewed-by: Willem de Bruijn <willemb@google.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 9fd1ff5d2ac7181844735806b0a703c942365291)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/ipv4/udp_offload.c
#	net/ipv6/udp_offload.c
diff --cc net/ipv4/udp_offload.c
index b081620854e2,1a98583a79f4..000000000000
--- a/net/ipv4/udp_offload.c
+++ b/net/ipv4/udp_offload.c
@@@ -349,22 -362,110 +366,122 @@@ out
  	return segs;
  }
  
++<<<<<<< HEAD
 +INDIRECT_CALLABLE_DECLARE(struct sock *udp6_lib_lookup_skb(struct sk_buff *skb,
 +						   __be16 sport, __be16 dport));
++=======
+ #define UDP_GRO_CNT_MAX 64
+ static struct sk_buff *udp_gro_receive_segment(struct list_head *head,
+ 					       struct sk_buff *skb)
+ {
+ 	struct udphdr *uh = udp_hdr(skb);
+ 	struct sk_buff *pp = NULL;
+ 	struct udphdr *uh2;
+ 	struct sk_buff *p;
+ 	unsigned int ulen;
+ 	int ret = 0;
+ 
+ 	/* requires non zero csum, for symmetry with GSO */
+ 	if (!uh->check) {
+ 		NAPI_GRO_CB(skb)->flush = 1;
+ 		return NULL;
+ 	}
+ 
+ 	/* Do not deal with padded or malicious packets, sorry ! */
+ 	ulen = ntohs(uh->len);
+ 	if (ulen <= sizeof(*uh) || ulen != skb_gro_len(skb)) {
+ 		NAPI_GRO_CB(skb)->flush = 1;
+ 		return NULL;
+ 	}
+ 	/* pull encapsulating udp header */
+ 	skb_gro_pull(skb, sizeof(struct udphdr));
+ 
+ 	list_for_each_entry(p, head, list) {
+ 		if (!NAPI_GRO_CB(p)->same_flow)
+ 			continue;
+ 
+ 		uh2 = udp_hdr(p);
+ 
+ 		/* Match ports only, as csum is always non zero */
+ 		if ((*(u32 *)&uh->source != *(u32 *)&uh2->source)) {
+ 			NAPI_GRO_CB(p)->same_flow = 0;
+ 			continue;
+ 		}
+ 
+ 		if (NAPI_GRO_CB(skb)->is_flist != NAPI_GRO_CB(p)->is_flist) {
+ 			NAPI_GRO_CB(skb)->flush = 1;
+ 			return p;
+ 		}
+ 
+ 		/* Terminate the flow on len mismatch or if it grow "too much".
+ 		 * Under small packet flood GRO count could elsewhere grow a lot
+ 		 * leading to excessive truesize values.
+ 		 * On len mismatch merge the first packet shorter than gso_size,
+ 		 * otherwise complete the GRO packet.
+ 		 */
+ 		if (ulen > ntohs(uh2->len)) {
+ 			pp = p;
+ 		} else {
+ 			if (NAPI_GRO_CB(skb)->is_flist) {
+ 				if (!pskb_may_pull(skb, skb_gro_offset(skb))) {
+ 					NAPI_GRO_CB(skb)->flush = 1;
+ 					return NULL;
+ 				}
+ 				if ((skb->ip_summed != p->ip_summed) ||
+ 				    (skb->csum_level != p->csum_level)) {
+ 					NAPI_GRO_CB(skb)->flush = 1;
+ 					return NULL;
+ 				}
+ 				ret = skb_gro_receive_list(p, skb);
+ 			} else {
+ 				skb_gro_postpull_rcsum(skb, uh,
+ 						       sizeof(struct udphdr));
+ 
+ 				ret = skb_gro_receive(p, skb);
+ 			}
+ 		}
+ 
+ 		if (ret || ulen != ntohs(uh2->len) ||
+ 		    NAPI_GRO_CB(p)->count >= UDP_GRO_CNT_MAX)
+ 			pp = p;
+ 
+ 		return pp;
+ 	}
+ 
+ 	/* mismatch, but we never need to flush */
+ 	return NULL;
+ }
+ 
++>>>>>>> 9fd1ff5d2ac7 (udp: Support UDP fraglist GRO/GSO.)
  struct sk_buff *udp_gro_receive(struct list_head *head, struct sk_buff *skb,
- 				struct udphdr *uh, udp_lookup_t lookup)
+ 				struct udphdr *uh, struct sock *sk)
  {
  	struct sk_buff *pp = NULL;
  	struct sk_buff *p;
  	struct udphdr *uh2;
  	unsigned int off = skb_gro_offset(skb);
  	int flush = 1;
- 	struct sock *sk;
  
++<<<<<<< HEAD
 +	if (NAPI_GRO_CB(skb)->encap_mark ||
 +	    (skb->ip_summed != CHECKSUM_PARTIAL &&
 +	     NAPI_GRO_CB(skb)->csum_cnt == 0 &&
 +	     !NAPI_GRO_CB(skb)->csum_valid))
++=======
+ 	if (skb->dev->features & NETIF_F_GRO_FRAGLIST)
+ 		NAPI_GRO_CB(skb)->is_flist = sk ? !udp_sk(sk)->gro_enabled: 1;
+ 
+ 	if ((sk && udp_sk(sk)->gro_enabled) || NAPI_GRO_CB(skb)->is_flist) {
+ 		pp = call_gro_receive(udp_gro_receive_segment, head, skb);
+ 		return pp;
+ 	}
+ 
+ 	if (!sk || NAPI_GRO_CB(skb)->encap_mark ||
+ 	    (skb->ip_summed != CHECKSUM_PARTIAL &&
+ 	     NAPI_GRO_CB(skb)->csum_cnt == 0 &&
+ 	     !NAPI_GRO_CB(skb)->csum_valid) ||
+ 	    !udp_sk(sk)->gro_receive)
++>>>>>>> 9fd1ff5d2ac7 (udp: Support UDP fraglist GRO/GSO.)
  		goto out;
  
  	/* mark that this skb passed once through the tunnel gro layer */
@@@ -401,8 -493,6 +518,11 @@@ unflush
  	skb_gro_postpull_rcsum(skb, uh, sizeof(struct udphdr));
  	pp = call_gro_receive_sk(udp_sk(sk)->gro_receive, sk, head, skb);
  
++<<<<<<< HEAD
 +out_unlock:
 +	rcu_read_unlock();
++=======
++>>>>>>> 9fd1ff5d2ac7 (udp: Support UDP fraglist GRO/GSO.)
  out:
  	skb_gro_flush_final(skb, pp, flush);
  	return pp;
@@@ -454,9 -558,19 +580,25 @@@ int udp_gro_complete(struct sk_buff *sk
  	rcu_read_lock();
  	sk = INDIRECT_CALL_INET(lookup, udp6_lib_lookup_skb,
  				udp4_lib_lookup_skb, skb, uh->source, uh->dest);
++<<<<<<< HEAD
 +	if (sk && udp_sk(sk)->gro_complete)
 +		err = udp_sk(sk)->gro_complete(sk, skb,
 +				nhoff + sizeof(struct udphdr));
++=======
+ 	if (sk && udp_sk(sk)->gro_complete) {
+ 		skb_shinfo(skb)->gso_type = uh->check ? SKB_GSO_UDP_TUNNEL_CSUM
+ 					: SKB_GSO_UDP_TUNNEL;
+ 
+ 		/* Set encapsulation before calling into inner gro_complete()
+ 		 * functions to make them set up the inner offsets.
+ 		 */
+ 		skb->encapsulation = 1;
+ 		err = udp_sk(sk)->gro_complete(sk, skb,
+ 				nhoff + sizeof(struct udphdr));
+ 	} else {
+ 		err = udp_gro_complete_segment(skb);
+ 	}
++>>>>>>> 9fd1ff5d2ac7 (udp: Support UDP fraglist GRO/GSO.)
  	rcu_read_unlock();
  
  	if (skb->remcsum_offload)
@@@ -471,13 -585,26 +613,34 @@@ INDIRECT_CALLABLE_SCOPE int udp4_gro_co
  	const struct iphdr *iph = ip_hdr(skb);
  	struct udphdr *uh = (struct udphdr *)(skb->data + nhoff);
  
++<<<<<<< HEAD
 +	if (uh->check) {
 +		skb_shinfo(skb)->gso_type |= SKB_GSO_UDP_TUNNEL_CSUM;
++=======
+ 	if (NAPI_GRO_CB(skb)->is_flist) {
+ 		uh->len = htons(skb->len - nhoff);
+ 
+ 		skb_shinfo(skb)->gso_type |= (SKB_GSO_FRAGLIST|SKB_GSO_UDP_L4);
+ 		skb_shinfo(skb)->gso_segs = NAPI_GRO_CB(skb)->count;
+ 
+ 		if (skb->ip_summed == CHECKSUM_UNNECESSARY) {
+ 			if (skb->csum_level < SKB_MAX_CSUM_LEVEL)
+ 				skb->csum_level++;
+ 		} else {
+ 			skb->ip_summed = CHECKSUM_UNNECESSARY;
+ 			skb->csum_level = 0;
+ 		}
+ 
+ 		return 0;
+ 	}
+ 
+ 	if (uh->check)
++>>>>>>> 9fd1ff5d2ac7 (udp: Support UDP fraglist GRO/GSO.)
  		uh->check = ~udp_v4_check(skb->len - nhoff, iph->saddr,
  					  iph->daddr, 0);
 +	} else {
 +		skb_shinfo(skb)->gso_type |= SKB_GSO_UDP_TUNNEL;
 +	}
  
  	return udp_gro_complete(skb, nhoff, udp4_lib_lookup_skb);
  }
diff --cc net/ipv6/udp_offload.c
index c25277706074,584157a07759..000000000000
--- a/net/ipv6/udp_offload.c
+++ b/net/ipv6/udp_offload.c
@@@ -148,13 -150,26 +154,34 @@@ INDIRECT_CALLABLE_SCOPE int udp6_gro_co
  	const struct ipv6hdr *ipv6h = ipv6_hdr(skb);
  	struct udphdr *uh = (struct udphdr *)(skb->data + nhoff);
  
++<<<<<<< HEAD
 +	if (uh->check) {
 +		skb_shinfo(skb)->gso_type |= SKB_GSO_UDP_TUNNEL_CSUM;
++=======
+ 	if (NAPI_GRO_CB(skb)->is_flist) {
+ 		uh->len = htons(skb->len - nhoff);
+ 
+ 		skb_shinfo(skb)->gso_type |= (SKB_GSO_FRAGLIST|SKB_GSO_UDP_L4);
+ 		skb_shinfo(skb)->gso_segs = NAPI_GRO_CB(skb)->count;
+ 
+ 		if (skb->ip_summed == CHECKSUM_UNNECESSARY) {
+ 			if (skb->csum_level < SKB_MAX_CSUM_LEVEL)
+ 				skb->csum_level++;
+ 		} else {
+ 			skb->ip_summed = CHECKSUM_UNNECESSARY;
+ 			skb->csum_level = 0;
+ 		}
+ 
+ 		return 0;
+ 	}
+ 
+ 	if (uh->check)
++>>>>>>> 9fd1ff5d2ac7 (udp: Support UDP fraglist GRO/GSO.)
  		uh->check = ~udp_v6_check(skb->len - nhoff, &ipv6h->saddr,
  					  &ipv6h->daddr, 0);
 +	} else {
 +		skb_shinfo(skb)->gso_type |= SKB_GSO_UDP_TUNNEL;
 +	}
  
  	return udp_gro_complete(skb, nhoff, udp6_lib_lookup_skb);
  }
diff --git a/include/net/udp.h b/include/net/udp.h
index dff3cf1814b5..6c67a1f1f75b 100644
--- a/include/net/udp.h
+++ b/include/net/udp.h
@@ -171,7 +171,7 @@ typedef struct sock *(*udp_lookup_t)(struct sk_buff *skb, __be16 sport,
 				     __be16 dport);
 
 struct sk_buff *udp_gro_receive(struct list_head *head, struct sk_buff *skb,
-				struct udphdr *uh, udp_lookup_t lookup);
+				struct udphdr *uh, struct sock *sk);
 int udp_gro_complete(struct sk_buff *skb, int nhoff, udp_lookup_t lookup);
 
 struct sk_buff *__udp_gso_segment(struct sk_buff *gso_skb,
* Unmerged path net/ipv4/udp_offload.c
* Unmerged path net/ipv6/udp_offload.c
