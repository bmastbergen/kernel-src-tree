bpf: Allow loading of a bpf_iter program

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Yonghong Song <yhs@fb.com>
commit 15d83c4d7cef5c067a8b075ce59e97df4f60706e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/15d83c4d.failed

A bpf_iter program is a tracing program with attach type
BPF_TRACE_ITER. The load attribute
  attach_btf_id
is used by the verifier against a particular kernel function,
which represents a target, e.g., __bpf_iter__bpf_map
for target bpf_map which is implemented later.

The program return value must be 0 or 1 for now.
  0 : successful, except potential seq_file buffer overflow
      which is handled by seq_file reader.
  1 : request to restart the same object

In the future, other return values may be used for filtering or
teminating the iterator.

	Signed-off-by: Yonghong Song <yhs@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Andrii Nakryiko <andriin@fb.com>
Link: https://lore.kernel.org/bpf/20200509175900.2474947-1-yhs@fb.com
(cherry picked from commit 15d83c4d7cef5c067a8b075ce59e97df4f60706e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/uapi/linux/bpf.h
#	kernel/bpf/verifier.c
diff --cc include/uapi/linux/bpf.h
index 23b02c5c3e10,c8a5325cc8d0..000000000000
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@@ -222,7 -218,7 +222,11 @@@ enum bpf_attach_type 
  	BPF_TRACE_FEXIT,
  	BPF_MODIFY_RETURN,
  	BPF_LSM_MAC,
++<<<<<<< HEAD
 +#endif /* __GENKSYMS__ */
++=======
+ 	BPF_TRACE_ITER,
++>>>>>>> 15d83c4d7cef (bpf: Allow loading of a bpf_iter program)
  	__MAX_BPF_ATTACH_TYPE
  };
  
diff --cc kernel/bpf/verifier.c
index 94c907288a2e,d725ff7d11db..000000000000
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@@ -7121,22 -7102,9 +7121,28 @@@ static int check_return_code(struct bpf
  		range = tnum_const(0);
  		break;
  	case BPF_PROG_TYPE_TRACING:
++<<<<<<< HEAD
 +		switch (env->prog->expected_attach_type) {
 +		case BPF_TRACE_FENTRY:
 +		case BPF_TRACE_FEXIT:
 +			range = tnum_const(0);
 +			break;
 +		case BPF_TRACE_RAW_TP:
 +		case BPF_MODIFY_RETURN:
 +			return 0;
 +		default:
 +			return -ENOTSUPP;
 +		}
 +		break;
 +	case BPF_PROG_TYPE_EXT:
 +		/* freplace program can return anything as its return value
 +		 * depends on the to-be-replaced kernel func or bpf program.
 +		 */
++=======
+ 		if (env->prog->expected_attach_type != BPF_TRACE_ITER)
+ 			return 0;
+ 		break;
++>>>>>>> 15d83c4d7cef (bpf: Allow loading of a bpf_iter program)
  	default:
  		return 0;
  	}
diff --git a/include/linux/bpf.h b/include/linux/bpf.h
index 092cd57c664b..63a663a2c18d 100644
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@ -1146,6 +1146,8 @@ struct bpf_link *bpf_link_get_from_fd(u32 ufd);
 int bpf_obj_pin_user(u32 ufd, const char __user *pathname);
 int bpf_obj_get_user(const char __user *pathname, int flags);
 
+#define BPF_ITER_FUNC_PREFIX "__bpf_iter__"
+
 typedef int (*bpf_iter_init_seq_priv_t)(void *private_data);
 typedef void (*bpf_iter_fini_seq_priv_t)(void *private_data);
 
@@ -1159,6 +1161,7 @@ struct bpf_iter_reg {
 
 int bpf_iter_reg_target(struct bpf_iter_reg *reg_info);
 void bpf_iter_unreg_target(const char *target);
+bool bpf_iter_prog_supported(struct bpf_prog *prog);
 
 int bpf_percpu_hash_copy(struct bpf_map *map, void *key, void *value);
 int bpf_percpu_array_copy(struct bpf_map *map, void *key, void *value);
* Unmerged path include/uapi/linux/bpf.h
diff --git a/kernel/bpf/bpf_iter.c b/kernel/bpf/bpf_iter.c
index 5a8119d17d14..dec182d8395a 100644
--- a/kernel/bpf/bpf_iter.c
+++ b/kernel/bpf/bpf_iter.c
@@ -12,6 +12,7 @@ struct bpf_iter_target_info {
 	bpf_iter_init_seq_priv_t init_seq_private;
 	bpf_iter_fini_seq_priv_t fini_seq_private;
 	u32 seq_priv_size;
+	u32 btf_id;	/* cached value */
 };
 
 static struct list_head targets = LIST_HEAD_INIT(targets);
@@ -57,3 +58,38 @@ void bpf_iter_unreg_target(const char *target)
 
 	WARN_ON(found == false);
 }
+
+static void cache_btf_id(struct bpf_iter_target_info *tinfo,
+			 struct bpf_prog *prog)
+{
+	tinfo->btf_id = prog->aux->attach_btf_id;
+}
+
+bool bpf_iter_prog_supported(struct bpf_prog *prog)
+{
+	const char *attach_fname = prog->aux->attach_func_name;
+	u32 prog_btf_id = prog->aux->attach_btf_id;
+	const char *prefix = BPF_ITER_FUNC_PREFIX;
+	struct bpf_iter_target_info *tinfo;
+	int prefix_len = strlen(prefix);
+	bool supported = false;
+
+	if (strncmp(attach_fname, prefix, prefix_len))
+		return false;
+
+	mutex_lock(&targets_mutex);
+	list_for_each_entry(tinfo, &targets, list) {
+		if (tinfo->btf_id && tinfo->btf_id == prog_btf_id) {
+			supported = true;
+			break;
+		}
+		if (!strcmp(attach_fname + prefix_len, tinfo->target)) {
+			cache_btf_id(tinfo, prog);
+			supported = true;
+			break;
+		}
+	}
+	mutex_unlock(&targets_mutex);
+
+	return supported;
+}
* Unmerged path kernel/bpf/verifier.c
diff --git a/tools/include/uapi/linux/bpf.h b/tools/include/uapi/linux/bpf.h
index dd7b920a75cd..43be3bd67848 100644
--- a/tools/include/uapi/linux/bpf.h
+++ b/tools/include/uapi/linux/bpf.h
@@ -217,6 +217,7 @@ enum bpf_attach_type {
 	BPF_TRACE_FEXIT,
 	BPF_MODIFY_RETURN,
 	BPF_LSM_MAC,
+	BPF_TRACE_ITER,
 	__MAX_BPF_ATTACH_TYPE
 };
 
