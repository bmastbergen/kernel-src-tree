x86/boot/compressed/64: Change add_identity_map() to take start and end

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
Rebuild_CHGLOG: - [x86] boot/compressed/64: Change add_identity_map() to take start and end (Vitaly Kuznetsov) [1868080]
Rebuild_FUZZ: 97.10%
commit-author Joerg Roedel <jroedel@suse.de>
commit 21cf2372618ef167d8c4ae04880fb873b55b2daa
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/21cf2372.failed

Changing the function to take start and end as parameters instead of
start and size simplifies the callers which don't need to calculate the
size if they already have start and end.

	Signed-off-by: Joerg Roedel <jroedel@suse.de>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Reviewed-by: Kees Cook <keescook@chromium.org>
Link: https://lkml.kernel.org/r/20200907131613.12703-19-joro@8bytes.org
(cherry picked from commit 21cf2372618ef167d8c4ae04880fb873b55b2daa)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/boot/compressed/kaslr_64.c
diff --cc arch/x86/boot/compressed/kaslr_64.c
index 9557c5a15b91,62e42c11a336..000000000000
--- a/arch/x86/boot/compressed/kaslr_64.c
+++ b/arch/x86/boot/compressed/kaslr_64.c
@@@ -74,6 -86,22 +74,25 @@@ phys_addr_t physical_mask = (1ULL << __
   */
  static struct x86_mapping_info mapping_info;
  
++<<<<<<< HEAD:arch/x86/boot/compressed/kaslr_64.c
++=======
+ /*
+  * Adds the specified range to the identity mappings.
+  */
+ static void add_identity_map(unsigned long start, unsigned long end)
+ {
+ 	/* Align boundary to 2M. */
+ 	start = round_down(start, PMD_SIZE);
+ 	end = round_up(end, PMD_SIZE);
+ 	if (start >= end)
+ 		return;
+ 
+ 	/* Build the mapping. */
+ 	kernel_ident_mapping_init(&mapping_info, (pgd_t *)top_level_pgt,
+ 				  start, end);
+ }
+ 
++>>>>>>> 21cf2372618e (x86/boot/compressed/64: Change add_identity_map() to take start and end):arch/x86/boot/compressed/ident_map_64.c
  /* Locates and clears a region for a new top level page table. */
  void initialize_identity_maps(void)
  {
@@@ -120,26 -146,13 +139,35 @@@
  		memset(pgt_data.pgt_buf, 0, pgt_data.pgt_buf_size);
  		top_level_pgt = (unsigned long)alloc_pgt_page(&pgt_data);
  	}
 +}
 +
++<<<<<<< HEAD:arch/x86/boot/compressed/kaslr_64.c
 +/*
 + * Adds the specified range to what will become the new identity mappings.
 + * Once all ranges have been added, the new mapping is activated by calling
 + * finalize_identity_maps() below.
 + */
 +void add_identity_map(unsigned long start, unsigned long size)
 +{
 +	unsigned long end = start + size;
 +
 +	/* Align boundary to 2M. */
 +	start = round_down(start, PMD_SIZE);
 +	end = round_up(end, PMD_SIZE);
 +	if (start >= end)
 +		return;
  
 +	/* Build the mapping. */
 +	kernel_ident_mapping_init(&mapping_info, (pgd_t *)top_level_pgt,
 +				  start, end);
++=======
+ 	/*
+ 	 * New page-table is set up - map the kernel image and load it
+ 	 * into cr3.
+ 	 */
+ 	add_identity_map((unsigned long)_head, (unsigned long)_end);
+ 	write_cr3(top_level_pgt);
++>>>>>>> 21cf2372618e (x86/boot/compressed/64: Change add_identity_map() to take start and end):arch/x86/boot/compressed/ident_map_64.c
  }
  
  /*
@@@ -151,3 -164,40 +179,43 @@@ void finalize_identity_maps(void
  {
  	write_cr3(top_level_pgt);
  }
++<<<<<<< HEAD:arch/x86/boot/compressed/kaslr_64.c
++=======
+ 
+ static void do_pf_error(const char *msg, unsigned long error_code,
+ 			unsigned long address, unsigned long ip)
+ {
+ 	error_putstr(msg);
+ 
+ 	error_putstr("\nError Code: ");
+ 	error_puthex(error_code);
+ 	error_putstr("\nCR2: 0x");
+ 	error_puthex(address);
+ 	error_putstr("\nRIP relative to _head: 0x");
+ 	error_puthex(ip - (unsigned long)_head);
+ 	error_putstr("\n");
+ 
+ 	error("Stopping.\n");
+ }
+ 
+ void do_boot_page_fault(struct pt_regs *regs, unsigned long error_code)
+ {
+ 	unsigned long address = native_read_cr2() & PMD_MASK;
+ 	unsigned long end = address + PMD_SIZE;
+ 
+ 	/*
+ 	 * Check for unexpected error codes. Unexpected are:
+ 	 *	- Faults on present pages
+ 	 *	- User faults
+ 	 *	- Reserved bits set
+ 	 */
+ 	if (error_code & (X86_PF_PROT | X86_PF_USER | X86_PF_RSVD))
+ 		do_pf_error("Unexpected page-fault:", error_code, address, regs->ip);
+ 
+ 	/*
+ 	 * Error code is sane - now identity map the 2M region around
+ 	 * the faulting address.
+ 	 */
+ 	add_identity_map(address, end);
+ }
++>>>>>>> 21cf2372618e (x86/boot/compressed/64: Change add_identity_map() to take start and end):arch/x86/boot/compressed/ident_map_64.c
* Unmerged path arch/x86/boot/compressed/kaslr_64.c
