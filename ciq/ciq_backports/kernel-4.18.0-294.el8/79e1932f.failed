x86/entry/64: Introduce the FIND_PERCPU_BASE macro

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Chang S. Bae <chang.seok.bae@intel.com>
commit 79e1932fa3cedd731ddbd6af111fe4db8ca109ae
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/79e1932f.failed

GSBASE is used to find per-CPU data in the kernel. But when GSBASE is
unknown, the per-CPU base can be found from the per_cpu_offset table with a
CPU NR.  The CPU NR is extracted from the limit field of the CPUNODE entry
in GDT, or by the RDPID instruction. This is a prerequisite for using
FSGSBASE in the low level entry code.

Also, add the GAS-compatible RDPID macro as binutils 2.21 do not support
it. Support is added in version 2.27.

[ tglx: Massaged changelog ]

	Suggested-by: H. Peter Anvin <hpa@zytor.com>
	Signed-off-by: Chang S. Bae <chang.seok.bae@intel.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Andi Kleen <ak@linux.intel.com>
	Cc: Ravi Shankar <ravi.v.shankar@intel.com>
	Cc: Dave Hansen <dave.hansen@linux.intel.com>
Link: https://lkml.kernel.org/r/1557309753-24073-12-git-send-email-chang.seok.bae@intel.com

(cherry picked from commit 79e1932fa3cedd731ddbd6af111fe4db8ca109ae)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/entry/calling.h
diff --cc arch/x86/entry/calling.h
index 7c56a2af8492,9a524360ae2e..000000000000
--- a/arch/x86/entry/calling.h
+++ b/arch/x86/entry/calling.h
@@@ -335,6 -340,45 +336,48 @@@ For 32-bit we have the following conven
  
  #endif /* CONFIG_X86_64 */
  
++<<<<<<< HEAD
++=======
+ .macro STACKLEAK_ERASE
+ #ifdef CONFIG_GCC_PLUGIN_STACKLEAK
+ 	call stackleak_erase
+ #endif
+ .endm
+ 
+ #ifdef CONFIG_SMP
+ 
+ /*
+  * CPU/node NR is loaded from the limit (size) field of a special segment
+  * descriptor entry in GDT.
+  */
+ .macro LOAD_CPU_AND_NODE_SEG_LIMIT reg:req
+ 	movq	$__CPUNODE_SEG, \reg
+ 	lsl	\reg, \reg
+ .endm
+ 
+ /*
+  * Fetch the per-CPU GSBASE value for this processor and put it in @reg.
+  * We normally use %gs for accessing per-CPU data, but we are setting up
+  * %gs here and obviously can not use %gs itself to access per-CPU data.
+  */
+ .macro GET_PERCPU_BASE reg:req
+ 	ALTERNATIVE \
+ 		"LOAD_CPU_AND_NODE_SEG_LIMIT \reg", \
+ 		"RDPID	\reg", \
+ 		X86_FEATURE_RDPID
+ 	andq	$VDSO_CPUNODE_MASK, \reg
+ 	movq	__per_cpu_offset(, \reg, 8), \reg
+ .endm
+ 
+ #else
+ 
+ .macro GET_PERCPU_BASE reg:req
+ 	movq	pcpu_unit_offsets(%rip), \reg
+ .endm
+ 
+ #endif /* CONFIG_SMP */
+ 
++>>>>>>> 79e1932fa3ce (x86/entry/64: Introduce the FIND_PERCPU_BASE macro)
  /*
   * This does 'call enter_from_user_mode' unless we can avoid it based on
   * kernel config or using the static jump infrastructure.
* Unmerged path arch/x86/entry/calling.h
diff --git a/arch/x86/include/asm/inst.h b/arch/x86/include/asm/inst.h
index f5a796da07f8..d063841a17e3 100644
--- a/arch/x86/include/asm/inst.h
+++ b/arch/x86/include/asm/inst.h
@@ -306,6 +306,21 @@
 	.endif
 	MODRM 0xc0 movq_r64_xmm_opd1 movq_r64_xmm_opd2
 	.endm
+
+.macro RDPID opd
+	REG_TYPE rdpid_opd_type \opd
+	.if rdpid_opd_type == REG_TYPE_R64
+	R64_NUM rdpid_opd \opd
+	.else
+	R32_NUM rdpid_opd \opd
+	.endif
+	.byte 0xf3
+	.if rdpid_opd > 7
+	PFX_REX rdpid_opd 0
+	.endif
+	.byte 0x0f, 0xc7
+	MODRM 0xc0 rdpid_opd 0x7
+.endm
 #endif
 
 #endif
