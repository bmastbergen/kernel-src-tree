irq_work: Slightly simplify IRQ_WORK_PENDING clearing

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Frederic Weisbecker <frederic@kernel.org>
commit feb4a51323babe13315c3b783ea7f1cf25368918
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/feb4a513.failed

Instead of fetching the value of flags and perform an xchg() to clear
a bit, just use atomic_fetch_andnot() that is more suitable to do that
job in one operation while keeping the full ordering.

	Signed-off-by: Frederic Weisbecker <frederic@kernel.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Paul E . McKenney <paulmck@linux.vnet.ibm.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
Link: https://lkml.kernel.org/r/20191108160858.31665-4-frederic@kernel.org
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit feb4a51323babe13315c3b783ea7f1cf25368918)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/irq_work.c
diff --cc kernel/irq_work.c
index 73288914ed5e,49c53f80a13a..000000000000
--- a/kernel/irq_work.c
+++ b/kernel/irq_work.c
@@@ -28,24 -29,16 +28,30 @@@ static DEFINE_PER_CPU(struct llist_head
   */
  static bool irq_work_claim(struct irq_work *work)
  {
 -	int oflags;
 +	unsigned long flags, oflags, nflags;
  
 -	oflags = atomic_fetch_or(IRQ_WORK_CLAIMED, &work->flags);
  	/*
++<<<<<<< HEAD
 +	 * Start with our best wish as a premise but only trust any
 +	 * flag value after cmpxchg() result.
++=======
+ 	 * If the work is already pending, no need to raise the IPI.
+ 	 * The pairing atomic_fetch_andnot() in irq_work_run() makes sure
+ 	 * everything we did before is visible.
++>>>>>>> feb4a51323ba (irq_work: Slightly simplify IRQ_WORK_PENDING clearing)
  	 */
 -	if (oflags & IRQ_WORK_PENDING)
 -		return false;
 +	flags = work->flags & ~IRQ_WORK_PENDING;
 +	for (;;) {
 +		nflags = flags | IRQ_WORK_CLAIMED;
 +		oflags = cmpxchg(&work->flags, flags, nflags);
 +		if (oflags == flags)
 +			break;
 +		if (oflags & IRQ_WORK_PENDING)
 +			return false;
 +		flags = oflags;
 +		cpu_relax();
 +	}
 +
  	return true;
  }
  
@@@ -142,7 -135,6 +148,10 @@@ static void irq_work_run_list(struct ll
  {
  	struct irq_work *work, *tmp;
  	struct llist_node *llnode;
++<<<<<<< HEAD
 +	unsigned long flags;
++=======
++>>>>>>> feb4a51323ba (irq_work: Slightly simplify IRQ_WORK_PENDING clearing)
  
  	BUG_ON(!irqs_disabled());
  
@@@ -158,8 -151,7 +168,12 @@@
  		 * to claim that work don't rely on us to handle their data
  		 * while we are in the middle of the func.
  		 */
++<<<<<<< HEAD
 +		flags = work->flags & ~IRQ_WORK_PENDING;
 +		xchg(&work->flags, flags);
++=======
+ 		flags = atomic_fetch_andnot(IRQ_WORK_PENDING, &work->flags);
++>>>>>>> feb4a51323ba (irq_work: Slightly simplify IRQ_WORK_PENDING clearing)
  
  		work->func(work);
  		/*
* Unmerged path kernel/irq_work.c
