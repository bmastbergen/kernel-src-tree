tcp: add tcp_sock_set_syncnt

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 557eadfcc5ee8f8fa98a795e05ed21db58a65db5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/557eadfc.failed

Add a helper to directly set the TCP_SYNCNT sockopt from kernel space
without going through a fake uaccess.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Acked-by: Sagi Grimberg <sagi@grimberg.me>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 557eadfcc5ee8f8fa98a795e05ed21db58a65db5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/tcp.h
#	net/ipv4/tcp.c
diff --cc include/linux/tcp.h
index 723bf168e2c0,6aa4ae5ebf3d..000000000000
--- a/include/linux/tcp.h
+++ b/include/linux/tcp.h
@@@ -495,4 -497,9 +495,12 @@@ static inline u16 tcp_mss_clamp(const s
  int tcp_skb_shift(struct sk_buff *to, struct sk_buff *from, int pcount,
  		  int shiftlen);
  
++<<<<<<< HEAD
++=======
+ void tcp_sock_set_cork(struct sock *sk, bool on);
+ void tcp_sock_set_nodelay(struct sock *sk);
+ void tcp_sock_set_quickack(struct sock *sk, int val);
+ int tcp_sock_set_syncnt(struct sock *sk, int val);
+ 
++>>>>>>> 557eadfcc5ee (tcp: add tcp_sock_set_syncnt)
  #endif	/* _LINUX_TCP_H */
diff --cc net/ipv4/tcp.c
index 6070cefff2a4,d2c67ae1da07..000000000000
--- a/net/ipv4/tcp.c
+++ b/net/ipv4/tcp.c
@@@ -2735,6 -2786,113 +2735,116 @@@ static int tcp_repair_options_est(struc
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ DEFINE_STATIC_KEY_FALSE(tcp_tx_delay_enabled);
+ EXPORT_SYMBOL(tcp_tx_delay_enabled);
+ 
+ static void tcp_enable_tx_delay(void)
+ {
+ 	if (!static_branch_unlikely(&tcp_tx_delay_enabled)) {
+ 		static int __tcp_tx_delay_enabled = 0;
+ 
+ 		if (cmpxchg(&__tcp_tx_delay_enabled, 0, 1) == 0) {
+ 			static_branch_enable(&tcp_tx_delay_enabled);
+ 			pr_info("TCP_TX_DELAY enabled\n");
+ 		}
+ 	}
+ }
+ 
+ /* When set indicates to always queue non-full frames.  Later the user clears
+  * this option and we transmit any pending partial frames in the queue.  This is
+  * meant to be used alongside sendfile() to get properly filled frames when the
+  * user (for example) must write out headers with a write() call first and then
+  * use sendfile to send out the data parts.
+  *
+  * TCP_CORK can be set together with TCP_NODELAY and it is stronger than
+  * TCP_NODELAY.
+  */
+ static void __tcp_sock_set_cork(struct sock *sk, bool on)
+ {
+ 	struct tcp_sock *tp = tcp_sk(sk);
+ 
+ 	if (on) {
+ 		tp->nonagle |= TCP_NAGLE_CORK;
+ 	} else {
+ 		tp->nonagle &= ~TCP_NAGLE_CORK;
+ 		if (tp->nonagle & TCP_NAGLE_OFF)
+ 			tp->nonagle |= TCP_NAGLE_PUSH;
+ 		tcp_push_pending_frames(sk);
+ 	}
+ }
+ 
+ void tcp_sock_set_cork(struct sock *sk, bool on)
+ {
+ 	lock_sock(sk);
+ 	__tcp_sock_set_cork(sk, on);
+ 	release_sock(sk);
+ }
+ EXPORT_SYMBOL(tcp_sock_set_cork);
+ 
+ /* TCP_NODELAY is weaker than TCP_CORK, so that this option on corked socket is
+  * remembered, but it is not activated until cork is cleared.
+  *
+  * However, when TCP_NODELAY is set we make an explicit push, which overrides
+  * even TCP_CORK for currently queued segments.
+  */
+ static void __tcp_sock_set_nodelay(struct sock *sk, bool on)
+ {
+ 	if (on) {
+ 		tcp_sk(sk)->nonagle |= TCP_NAGLE_OFF|TCP_NAGLE_PUSH;
+ 		tcp_push_pending_frames(sk);
+ 	} else {
+ 		tcp_sk(sk)->nonagle &= ~TCP_NAGLE_OFF;
+ 	}
+ }
+ 
+ void tcp_sock_set_nodelay(struct sock *sk)
+ {
+ 	lock_sock(sk);
+ 	__tcp_sock_set_nodelay(sk, true);
+ 	release_sock(sk);
+ }
+ EXPORT_SYMBOL(tcp_sock_set_nodelay);
+ 
+ static void __tcp_sock_set_quickack(struct sock *sk, int val)
+ {
+ 	if (!val) {
+ 		inet_csk_enter_pingpong_mode(sk);
+ 		return;
+ 	}
+ 
+ 	inet_csk_exit_pingpong_mode(sk);
+ 	if ((1 << sk->sk_state) & (TCPF_ESTABLISHED | TCPF_CLOSE_WAIT) &&
+ 	    inet_csk_ack_scheduled(sk)) {
+ 		inet_csk(sk)->icsk_ack.pending |= ICSK_ACK_PUSHED;
+ 		tcp_cleanup_rbuf(sk, 1);
+ 		if (!(val & 1))
+ 			inet_csk_enter_pingpong_mode(sk);
+ 	}
+ }
+ 
+ void tcp_sock_set_quickack(struct sock *sk, int val)
+ {
+ 	lock_sock(sk);
+ 	__tcp_sock_set_quickack(sk, val);
+ 	release_sock(sk);
+ }
+ EXPORT_SYMBOL(tcp_sock_set_quickack);
+ 
+ int tcp_sock_set_syncnt(struct sock *sk, int val)
+ {
+ 	if (val < 1 || val > MAX_TCP_SYNCNT)
+ 		return -EINVAL;
+ 
+ 	lock_sock(sk);
+ 	inet_csk(sk)->icsk_syn_retries = val;
+ 	release_sock(sk);
+ 	return 0;
+ }
+ EXPORT_SYMBOL(tcp_sock_set_syncnt);
+ 
++>>>>>>> 557eadfcc5ee (tcp: add tcp_sock_set_syncnt)
  /*
   *	Socket option code for TCP.
   */
diff --git a/drivers/nvme/host/tcp.c b/drivers/nvme/host/tcp.c
index c03e25e6b351..b7d6f0d04386 100644
--- a/drivers/nvme/host/tcp.c
+++ b/drivers/nvme/host/tcp.c
@@ -1363,14 +1363,7 @@ static int nvme_tcp_alloc_queue(struct nvme_ctrl *nctrl,
 	}
 
 	/* Single syn retry */
-	opt = 1;
-	ret = kernel_setsockopt(queue->sock, IPPROTO_TCP, TCP_SYNCNT,
-			(char *)&opt, sizeof(opt));
-	if (ret) {
-		dev_err(nctrl->device,
-			"failed to set TCP_SYNCNT sock opt %d\n", ret);
-		goto err_sock;
-	}
+	tcp_sock_set_syncnt(queue->sock->sk, 1);
 
 	/* Set TCP no delay */
 	opt = 1;
* Unmerged path include/linux/tcp.h
* Unmerged path net/ipv4/tcp.c
