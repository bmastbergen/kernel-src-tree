x86/entry, nmi: Disable #DB

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
Rebuild_CHGLOG: - [x86] entry, nmi: Disable #DB (Vitaly Kuznetsov) [1868080]
Rebuild_FUZZ: 92.00%
commit-author Peter Zijlstra <peterz@infradead.org>
commit fd338e3564b0b8597a89f83941a0eda3e5092cc0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/fd338e35.failed

Instead of playing stupid games with IST stacks, fully disallow #DB
during NMIs. There is absolutely no reason to allow them, and killing
this saves a heap of trouble.

#DB is already forbidden on noinstr and CEA, so there can't be a #DB before
this. Disabling it right after nmi_enter() ensures that the full NMI code
is protected.

	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
Link: https://lkml.kernel.org/r/20200529213321.069223695@infradead.org



(cherry picked from commit fd338e3564b0b8597a89f83941a0eda3e5092cc0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/nmi.c
diff --cc arch/x86/kernel/nmi.c
index 086cf1d1d71d,873a8c040b86..000000000000
--- a/arch/x86/kernel/nmi.c
+++ b/arch/x86/kernel/nmi.c
@@@ -471,28 -474,13 +471,32 @@@ enum nmi_states 
  };
  static DEFINE_PER_CPU(enum nmi_states, nmi_state);
  static DEFINE_PER_CPU(unsigned long, nmi_cr2);
++<<<<<<< HEAD
 +
 +#ifdef CONFIG_X86_64
 +/*
 + * In x86_64, we need to handle breakpoint -> NMI -> breakpoint.  Without
 + * some care, the inner breakpoint will clobber the outer breakpoint's
 + * stack.
 + *
 + * If a breakpoint is being processed, and the debug stack is being
 + * used, if an NMI comes in and also hits a breakpoint, the stack
 + * pointer will be set to the same fixed address as the breakpoint that
 + * was interrupted, causing that stack to be corrupted. To handle this
 + * case, check if the stack that was interrupted is the debug stack, and
 + * if so, change the IDT so that new breakpoints will use the current
 + * stack and not switch to the fixed address. On return of the NMI,
 + * switch back to the original IDT.
 + */
 +static DEFINE_PER_CPU(int, update_debug_stack);
 +#endif
++=======
+ static DEFINE_PER_CPU(unsigned long, nmi_dr7);
++>>>>>>> fd338e3564b0 (x86/entry, nmi: Disable #DB)
  
 -DEFINE_IDTENTRY_NMI(exc_nmi)
 +dotraplinkage notrace void
 +do_nmi(struct pt_regs *regs, long error_code)
  {
 -	if (IS_ENABLED(CONFIG_SMP) && cpu_is_offline(smp_processor_id()))
 -		return;
 -
  	if (this_cpu_read(nmi_state) != NMI_NOT_RUNNING) {
  		this_cpu_write(nmi_state, NMI_LATCHED);
  		return;
* Unmerged path arch/x86/kernel/nmi.c
