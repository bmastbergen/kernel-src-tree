shmem: Convert find_swap_entry to XArray

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Matthew Wilcox <willy@infradead.org>
commit e21a29552fa3f44ea41c53488875015ae70fd7f8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/e21a2955.failed

This is a 1:1 conversion.  The major part of this patch is converting
the test framework from userspace to kernel space and mirroring the
algorithm now used in find_swap_entry().

	Signed-off-by: Matthew Wilcox <willy@infradead.org>
(cherry picked from commit e21a29552fa3f44ea41c53488875015ae70fd7f8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	lib/test_xarray.c
#	tools/testing/radix-tree/test.h
diff --cc lib/test_xarray.c
index 9e58a60b7062,815daffdd8c9..000000000000
--- a/lib/test_xarray.c
+++ b/lib/test_xarray.c
@@@ -982,164 -627,65 +982,219 @@@ static noinline void check_find_1(struc
  		XA_BUG_ON(xa, xa_get_mark(xa, i, XA_MARK_0));
  	}
  	XA_BUG_ON(xa, !xa_empty(xa));
 -	check_multi_find(xa);
 +}
 +
 +static noinline void check_find_2(struct xarray *xa)
 +{
 +	void *entry;
 +	unsigned long i, j, index;
 +
 +	xa_for_each(xa, index, entry) {
 +		XA_BUG_ON(xa, true);
 +	}
 +
 +	for (i = 0; i < 1024; i++) {
 +		xa_store_index(xa, index, GFP_KERNEL);
 +		j = 0;
 +		xa_for_each(xa, index, entry) {
 +			XA_BUG_ON(xa, xa_mk_index(index) != entry);
 +			XA_BUG_ON(xa, index != j++);
 +		}
 +	}
 +
 +	xa_destroy(xa);
 +}
 +
 +static noinline void check_find_3(struct xarray *xa)
 +{
 +	XA_STATE(xas, xa, 0);
 +	unsigned long i, j, k;
 +	void *entry;
 +
 +	for (i = 0; i < 100; i++) {
 +		for (j = 0; j < 100; j++) {
 +			rcu_read_lock();
 +			for (k = 0; k < 100; k++) {
 +				xas_set(&xas, j);
 +				xas_for_each_marked(&xas, entry, k, XA_MARK_0)
 +					;
 +				if (j > k)
 +					XA_BUG_ON(xa,
 +						xas.xa_node != XAS_RESTART);
 +			}
 +			rcu_read_unlock();
 +		}
 +		xa_store_index(xa, i, GFP_KERNEL);
 +		xa_set_mark(xa, i, XA_MARK_0);
 +	}
 +	xa_destroy(xa);
 +}
 +
 +static noinline void check_find_4(struct xarray *xa)
 +{
 +	unsigned long index = 0;
 +	void *entry;
 +
 +	xa_store_index(xa, ULONG_MAX, GFP_KERNEL);
 +
 +	entry = xa_find_after(xa, &index, ULONG_MAX, XA_PRESENT);
 +	XA_BUG_ON(xa, entry != xa_mk_index(ULONG_MAX));
 +
 +	entry = xa_find_after(xa, &index, ULONG_MAX, XA_PRESENT);
 +	XA_BUG_ON(xa, entry);
 +
 +	xa_erase_index(xa, ULONG_MAX);
 +}
 +
 +static noinline void check_find(struct xarray *xa)
 +{
 +	unsigned i;
 +
 +	check_find_1(xa);
 +	check_find_2(xa);
 +	check_find_3(xa);
 +	check_find_4(xa);
 +
 +	for (i = 2; i < 10; i++)
 +		check_multi_find_1(xa, i);
  	check_multi_find_2(xa);
 +	check_multi_find_3(xa);
 +}
 +
 +static noinline void check_pause(struct xarray *xa)
 +{
 +	XA_STATE(xas, xa, 0);
 +	void *entry;
 +	unsigned int order;
 +	unsigned long index = 1;
 +	unsigned int count = 0;
 +
 +	for (order = 0; order < order_limit; order++) {
 +		XA_BUG_ON(xa, xa_store_order(xa, index, order,
 +					xa_mk_index(index), GFP_KERNEL));
 +		index += 1UL << order;
 +	}
 +
 +	rcu_read_lock();
 +	xas_for_each(&xas, entry, ULONG_MAX) {
 +		XA_BUG_ON(xa, entry != xa_mk_index(1UL << count));
 +		count++;
 +	}
 +	rcu_read_unlock();
 +	XA_BUG_ON(xa, count != order_limit);
 +
 +	count = 0;
 +	xas_set(&xas, 0);
 +	rcu_read_lock();
 +	xas_for_each(&xas, entry, ULONG_MAX) {
 +		XA_BUG_ON(xa, entry != xa_mk_index(1UL << count));
 +		count++;
 +		xas_pause(&xas);
 +	}
 +	rcu_read_unlock();
 +	XA_BUG_ON(xa, count != order_limit);
 +
 +	xa_destroy(xa);
 +}
 +
 +static noinline void check_move_tiny(struct xarray *xa)
 +{
 +	XA_STATE(xas, xa, 0);
 +
 +	XA_BUG_ON(xa, !xa_empty(xa));
 +	rcu_read_lock();
 +	XA_BUG_ON(xa, xas_next(&xas) != NULL);
 +	XA_BUG_ON(xa, xas_next(&xas) != NULL);
 +	rcu_read_unlock();
 +	xa_store_index(xa, 0, GFP_KERNEL);
 +	rcu_read_lock();
 +	xas_set(&xas, 0);
 +	XA_BUG_ON(xa, xas_next(&xas) != xa_mk_index(0));
 +	XA_BUG_ON(xa, xas_next(&xas) != NULL);
 +	xas_set(&xas, 0);
 +	XA_BUG_ON(xa, xas_prev(&xas) != xa_mk_index(0));
 +	XA_BUG_ON(xa, xas_prev(&xas) != NULL);
 +	rcu_read_unlock();
 +	xa_erase_index(xa, 0);
 +	XA_BUG_ON(xa, !xa_empty(xa));
 +}
 +
 +static noinline void check_move_max(struct xarray *xa)
 +{
 +	XA_STATE(xas, xa, 0);
 +
 +	xa_store_index(xa, ULONG_MAX, GFP_KERNEL);
 +	rcu_read_lock();
 +	XA_BUG_ON(xa, xas_find(&xas, ULONG_MAX) != xa_mk_index(ULONG_MAX));
 +	XA_BUG_ON(xa, xas_find(&xas, ULONG_MAX) != NULL);
 +	rcu_read_unlock();
 +
 +	xas_set(&xas, 0);
 +	rcu_read_lock();
 +	XA_BUG_ON(xa, xas_find(&xas, ULONG_MAX) != xa_mk_index(ULONG_MAX));
 +	xas_pause(&xas);
 +	XA_BUG_ON(xa, xas_find(&xas, ULONG_MAX) != NULL);
 +	rcu_read_unlock();
 +
 +	xa_erase_index(xa, ULONG_MAX);
 +	XA_BUG_ON(xa, !xa_empty(xa));
  }
  
+ /* See find_swap_entry() in mm/shmem.c */
+ static noinline unsigned long xa_find_entry(struct xarray *xa, void *item)
+ {
+ 	XA_STATE(xas, xa, 0);
+ 	unsigned int checked = 0;
+ 	void *entry;
+ 
+ 	rcu_read_lock();
+ 	xas_for_each(&xas, entry, ULONG_MAX) {
+ 		if (xas_retry(&xas, entry))
+ 			continue;
+ 		if (entry == item)
+ 			break;
+ 		checked++;
+ 		if ((checked % 4) != 0)
+ 			continue;
+ 		xas_pause(&xas);
+ 	}
+ 	rcu_read_unlock();
+ 
+ 	return entry ? xas.xa_index : -1;
+ }
+ 
+ static noinline void check_find_entry(struct xarray *xa)
+ {
+ #ifdef CONFIG_XARRAY_MULTI
+ 	unsigned int order;
+ 	unsigned long offset, index;
+ 
+ 	for (order = 0; order < 20; order++) {
+ 		for (offset = 0; offset < (1UL << (order + 3));
+ 		     offset += (1UL << order)) {
+ 			for (index = 0; index < (1UL << (order + 5));
+ 			     index += (1UL << order)) {
+ 				xa_store_order(xa, index, order,
+ 						xa_mk_value(index), GFP_KERNEL);
+ 				XA_BUG_ON(xa, xa_load(xa, index) !=
+ 						xa_mk_value(index));
+ 				XA_BUG_ON(xa, xa_find_entry(xa,
+ 						xa_mk_value(index)) != index);
+ 			}
+ 			XA_BUG_ON(xa, xa_find_entry(xa, xa) != -1);
+ 			xa_destroy(xa);
+ 		}
+ 	}
+ #endif
+ 
+ 	XA_BUG_ON(xa, xa_find_entry(xa, xa) != -1);
+ 	xa_store_index(xa, ULONG_MAX, GFP_KERNEL);
+ 	XA_BUG_ON(xa, xa_find_entry(xa, xa) != -1);
+ 	XA_BUG_ON(xa, xa_find_entry(xa, xa_mk_value(LONG_MAX)) != -1);
+ 	xa_erase_index(xa, ULONG_MAX);
+ 	XA_BUG_ON(xa, !xa_empty(xa));
+ }
+ 
  static noinline void check_move_small(struct xarray *xa, unsigned long idx)
  {
  	XA_STATE(xas, xa, 0);
@@@ -1604,8 -1027,7 +1659,12 @@@ static int xarray_checks(void
  	check_multi_store(&array);
  	check_xa_alloc();
  	check_find(&array);
++<<<<<<< HEAD
 +	check_pause(&array);
 +	check_account(&array);
++=======
+ 	check_find_entry(&array);
++>>>>>>> e21a29552fa3 (shmem: Convert find_swap_entry to XArray)
  	check_destroy(&array);
  	check_move(&array);
  	check_create_range(&array);
diff --cc tools/testing/radix-tree/test.h
index df717df37d89,9532c18c6cb1..000000000000
--- a/tools/testing/radix-tree/test.h
+++ b/tools/testing/radix-tree/test.h
@@@ -30,9 -29,9 +30,15 @@@ void item_full_scan(struct radix_tree_r
  			unsigned long nr, int chunk);
  void item_kill_tree(struct radix_tree_root *root);
  
++<<<<<<< HEAD
 +int tag_tagged_items(struct xarray *, unsigned long start, unsigned long end,
 +		unsigned batch, xa_mark_t iftag, xa_mark_t thentag);
 +unsigned long find_item(struct radix_tree_root *, void *item);
++=======
+ int tag_tagged_items(struct radix_tree_root *, pthread_mutex_t *,
+ 			unsigned long start, unsigned long end, unsigned batch,
+ 			unsigned iftag, unsigned thentag);
++>>>>>>> e21a29552fa3 (shmem: Convert find_swap_entry to XArray)
  
  void xarray_tests(void);
  void tag_check(void);
* Unmerged path lib/test_xarray.c
diff --git a/mm/shmem.c b/mm/shmem.c
index f875ccaa5b54..08a7de7ff5cf 100644
--- a/mm/shmem.c
+++ b/mm/shmem.c
@@ -1117,34 +1117,27 @@ static void shmem_evict_inode(struct inode *inode)
 	clear_inode(inode);
 }
 
-static unsigned long find_swap_entry(struct radix_tree_root *root, void *item)
+static unsigned long find_swap_entry(struct xarray *xa, void *item)
 {
-	struct radix_tree_iter iter;
-	void __rcu **slot;
-	unsigned long found = -1;
+	XA_STATE(xas, xa, 0);
 	unsigned int checked = 0;
+	void *entry;
 
 	rcu_read_lock();
-	radix_tree_for_each_slot(slot, root, &iter, 0) {
-		void *entry = radix_tree_deref_slot(slot);
-
-		if (radix_tree_deref_retry(entry)) {
-			slot = radix_tree_iter_retry(&iter);
+	xas_for_each(&xas, entry, ULONG_MAX) {
+		if (xas_retry(&xas, entry))
 			continue;
-		}
-		if (entry == item) {
-			found = iter.index;
+		if (entry == item)
 			break;
-		}
 		checked++;
-		if ((checked % 4096) != 0)
+		if ((checked % XA_CHECK_SCHED) != 0)
 			continue;
-		slot = radix_tree_iter_resume(slot, &iter);
+		xas_pause(&xas);
 		cond_resched_rcu();
 	}
-
 	rcu_read_unlock();
-	return found;
+
+	return entry ? xas.xa_index : -1;
 }
 
 /*
diff --git a/tools/testing/radix-tree/main.c b/tools/testing/radix-tree/main.c
index d4ac2041e218..f2cbc8e5b97c 100644
--- a/tools/testing/radix-tree/main.c
+++ b/tools/testing/radix-tree/main.c
@@ -236,63 +236,6 @@ void copy_tag_check(void)
 	item_kill_tree(&tree);
 }
 
-static void __locate_check(struct radix_tree_root *tree, unsigned long index,
-			unsigned order)
-{
-	struct item *item;
-	unsigned long index2;
-
-	item_insert_order(tree, index, order);
-	item = item_lookup(tree, index);
-	index2 = find_item(tree, item);
-	if (index != index2) {
-		printv(2, "index %ld order %d inserted; found %ld\n",
-			index, order, index2);
-		abort();
-	}
-}
-
-static void __order_0_locate_check(void)
-{
-	RADIX_TREE(tree, GFP_KERNEL);
-	int i;
-
-	for (i = 0; i < 50; i++)
-		__locate_check(&tree, rand() % INT_MAX, 0);
-
-	item_kill_tree(&tree);
-}
-
-static void locate_check(void)
-{
-	RADIX_TREE(tree, GFP_KERNEL);
-	unsigned order;
-	unsigned long offset, index;
-
-	__order_0_locate_check();
-
-	for (order = 0; order < 20; order++) {
-		for (offset = 0; offset < (1 << (order + 3));
-		     offset += (1UL << order)) {
-			for (index = 0; index < (1UL << (order + 5));
-			     index += (1UL << order)) {
-				__locate_check(&tree, index + offset, order);
-			}
-			if (find_item(&tree, &tree) != -1)
-				abort();
-
-			item_kill_tree(&tree);
-		}
-	}
-
-	if (find_item(&tree, &tree) != -1)
-		abort();
-	__locate_check(&tree, -1, 0);
-	if (find_item(&tree, &tree) != -1)
-		abort();
-	item_kill_tree(&tree);
-}
-
 static void single_thread_tests(bool long_run)
 {
 	int i;
@@ -303,10 +246,6 @@ static void single_thread_tests(bool long_run)
 	rcu_barrier();
 	printv(2, "after multiorder_check: %d allocated, preempt %d\n",
 		nr_allocated, preempt_count);
-	locate_check();
-	rcu_barrier();
-	printv(2, "after locate_check: %d allocated, preempt %d\n",
-		nr_allocated, preempt_count);
 	tag_check();
 	rcu_barrier();
 	printv(2, "after tag_check: %d allocated, preempt %d\n",
diff --git a/tools/testing/radix-tree/test.c b/tools/testing/radix-tree/test.c
index 7702d9b549df..32973dd51ec5 100644
--- a/tools/testing/radix-tree/test.c
+++ b/tools/testing/radix-tree/test.c
@@ -207,28 +207,6 @@ int tag_tagged_items(struct xarray *xa, unsigned long start, unsigned long end,
 	return tagged;
 }
 
-/* Use the same pattern as find_swap_entry() in mm/shmem.c */
-unsigned long find_item(struct radix_tree_root *root, void *item)
-{
-	struct radix_tree_iter iter;
-	void **slot;
-	unsigned long found = -1;
-	unsigned long checked = 0;
-
-	radix_tree_for_each_slot(slot, root, &iter, 0) {
-		if (*slot == item) {
-			found = iter.index;
-			break;
-		}
-		checked++;
-		if ((checked % 4) != 0)
-			continue;
-		slot = radix_tree_iter_resume(slot, &iter);
-	}
-
-	return found;
-}
-
 static int verify_node(struct radix_tree_node *slot, unsigned int tag,
 			int tagged)
 {
* Unmerged path tools/testing/radix-tree/test.h
