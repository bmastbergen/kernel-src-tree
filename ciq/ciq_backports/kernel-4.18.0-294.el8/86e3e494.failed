KVM: VMX: Move uret MSR lookup into update_transition_efer()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Sean Christopherson <sean.j.christopherson@intel.com>
commit 86e3e494fe32d1e7e9180458d857916155dd2856
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/86e3e494.failed

Move checking for the existence of MSR_EFER in the uret MSR array into
update_transition_efer() so that the lookup and manipulation of the
array in setup_msrs() occur back-to-back.  This paves the way toward
adding a helper to wrap the lookup and manipulation.

To avoid unnecessary overhead, defer the lookup until the uret array
would actually be modified in update_transition_efer().  EFER obviously
exists on CPUs that support the dedicated VMCS fields for switching
EFER, and EFER must exist for the guest and host EFER.NX value to
diverge, i.e. there is no danger of attempting to read/write EFER when
it doesn't exist.

	Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
Message-Id: <20200923180409.32255-11-sean.j.christopherson@intel.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 86e3e494fe32d1e7e9180458d857916155dd2856)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/vmx/vmx.c
diff --cc arch/x86/kvm/vmx/vmx.c
index 985a4bfb7517,1ad9faca44ef..000000000000
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@@ -988,17 -977,21 +989,34 @@@ static bool update_transition_efer(stru
  		else
  			clear_atomic_switch_msr(vmx, MSR_EFER);
  		return false;
++<<<<<<< HEAD
 +	} else {
 +		clear_atomic_switch_msr(vmx, MSR_EFER);
 +
 +		guest_efer &= ~ignore_bits;
 +		guest_efer |= host_efer & ignore_bits;
 +
 +		vmx->guest_msrs[efer_offset].data = guest_efer;
 +		vmx->guest_msrs[efer_offset].mask = ~ignore_bits;
 +
 +		return true;
++=======
++>>>>>>> 86e3e494fe32 (KVM: VMX: Move uret MSR lookup into update_transition_efer())
  	}
+ 
+ 	i = __vmx_find_uret_msr(vmx, MSR_EFER);
+ 	if (i < 0)
+ 		return false;
+ 
+ 	clear_atomic_switch_msr(vmx, MSR_EFER);
+ 
+ 	guest_efer &= ~ignore_bits;
+ 	guest_efer |= host_efer & ignore_bits;
+ 
+ 	vmx->guest_uret_msrs[i].data = guest_efer;
+ 	vmx->guest_uret_msrs[i].mask = ~ignore_bits;
+ 
+ 	return true;
  }
  
  #ifdef CONFIG_X86_32
@@@ -1644,29 -1642,33 +1662,43 @@@ static void setup_msrs(struct vcpu_vmx 
  	 * when EFER.SCE is set.
  	 */
  	if (is_long_mode(&vmx->vcpu) && (vmx->vcpu.arch.efer & EFER_SCE)) {
 -		index = __vmx_find_uret_msr(vmx, MSR_STAR);
 +		index = __find_msr_index(vmx, MSR_STAR);
  		if (index >= 0)
 -			move_msr_up(vmx, index, nr_active_uret_msrs++);
 -		index = __vmx_find_uret_msr(vmx, MSR_LSTAR);
 +			move_msr_up(vmx, index, save_nmsrs++);
 +		index = __find_msr_index(vmx, MSR_LSTAR);
  		if (index >= 0)
 -			move_msr_up(vmx, index, nr_active_uret_msrs++);
 -		index = __vmx_find_uret_msr(vmx, MSR_SYSCALL_MASK);
 +			move_msr_up(vmx, index, save_nmsrs++);
 +		index = __find_msr_index(vmx, MSR_SYSCALL_MASK);
  		if (index >= 0)
 -			move_msr_up(vmx, index, nr_active_uret_msrs++);
 +			move_msr_up(vmx, index, save_nmsrs++);
  	}
  #endif
++<<<<<<< HEAD
 +	index = __find_msr_index(vmx, MSR_EFER);
 +	if (index >= 0 && update_transition_efer(vmx, index))
 +		move_msr_up(vmx, index, save_nmsrs++);
 +	index = __find_msr_index(vmx, MSR_TSC_AUX);
 +	if (index >= 0 && guest_cpuid_has(&vmx->vcpu, X86_FEATURE_RDTSCP))
 +		move_msr_up(vmx, index, save_nmsrs++);
 +	index = __find_msr_index(vmx, MSR_IA32_TSX_CTRL);
++=======
+ 	if (update_transition_efer(vmx)) {
+ 		index = __vmx_find_uret_msr(vmx, MSR_EFER);
+ 		if (index >= 0)
+ 			move_msr_up(vmx, index, nr_active_uret_msrs++);
+ 	}
+ 	if (guest_cpuid_has(&vmx->vcpu, X86_FEATURE_RDTSCP)) {
+ 		index = __vmx_find_uret_msr(vmx, MSR_TSC_AUX);
+ 		if (index >= 0)
+ 			move_msr_up(vmx, index, nr_active_uret_msrs++);
+ 	}
+ 	index = __vmx_find_uret_msr(vmx, MSR_IA32_TSX_CTRL);
++>>>>>>> 86e3e494fe32 (KVM: VMX: Move uret MSR lookup into update_transition_efer())
  	if (index >= 0)
 -		move_msr_up(vmx, index, nr_active_uret_msrs++);
 +		move_msr_up(vmx, index, save_nmsrs++);
  
 -	vmx->nr_active_uret_msrs = nr_active_uret_msrs;
 -	vmx->guest_uret_msrs_loaded = false;
 +	vmx->save_nmsrs = save_nmsrs;
 +	vmx->guest_msrs_ready = false;
  
  	if (cpu_has_vmx_msr_bitmap())
  		vmx_update_msr_bitmap(&vmx->vcpu);
* Unmerged path arch/x86/kvm/vmx/vmx.c
