xfs: fold xfs_mount-alloc() into xfs_init_fs_context()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Ian Kent <raven@themaw.net>
commit 50f8300904b1b217328219812ee67c231a5aff8d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/50f83009.failed

After switching to use the mount-api the only remaining caller of
xfs_mount_alloc() is xfs_init_fs_context(), so fold xfs_mount_alloc()
into it.

	Signed-off-by: Ian Kent <raven@themaw.net>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
	Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
(cherry picked from commit 50f8300904b1b217328219812ee67c231a5aff8d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/xfs_super.c
diff --cc fs/xfs/xfs_super.c
index 9024b0a4c895,b3188ea49413..000000000000
--- a/fs/xfs/xfs_super.c
+++ b/fs/xfs/xfs_super.c
@@@ -1532,57 -1038,335 +1532,127 @@@ xfs_destroy_percpu_counters
  	percpu_counter_destroy(&mp->m_delalloc_blks);
  }
  
++<<<<<<< HEAD
 +static struct xfs_mount *
 +xfs_mount_alloc(void)
 +{
 +	struct xfs_mount	*mp;
 +
 +	mp = kmem_alloc(sizeof(struct xfs_mount), KM_ZERO);
 +	if (!mp)
 +		return NULL;
 +
 +	spin_lock_init(&mp->m_sb_lock);
 +	spin_lock_init(&mp->m_agirotor_lock);
 +	INIT_RADIX_TREE(&mp->m_perag_tree, GFP_ATOMIC);
 +	spin_lock_init(&mp->m_perag_lock);
 +	mutex_init(&mp->m_growlock);
 +	atomic_set(&mp->m_active_trans, 0);
 +	INIT_DELAYED_WORK(&mp->m_reclaim_work, xfs_reclaim_worker);
 +	INIT_DELAYED_WORK(&mp->m_eofblocks_work, xfs_eofblocks_worker);
 +	INIT_DELAYED_WORK(&mp->m_cowblocks_work, xfs_cowblocks_worker);
 +	mp->m_kobj.kobject.kset = xfs_kset;
 +	/*
 +	 * We don't create the finobt per-ag space reservation until after log
 +	 * recovery, so we must set this to true so that an ifree transaction
 +	 * started during log recovery will not depend on space reservations
 +	 * for finobt expansion.
 +	 */
 +	mp->m_finobt_nores = true;
 +	return mp;
 +}
 +
++=======
+ static void
+ xfs_fs_put_super(
+ 	struct super_block	*sb)
+ {
+ 	struct xfs_mount	*mp = XFS_M(sb);
+ 
+ 	/* if ->fill_super failed, we have no mount to tear down */
+ 	if (!sb->s_fs_info)
 -		return;
 -
 -	xfs_notice(mp, "Unmounting Filesystem");
 -	xfs_filestream_unmount(mp);
 -	xfs_unmountfs(mp);
 -
 -	xfs_freesb(mp);
 -	free_percpu(mp->m_stats.xs_stats);
 -	xfs_destroy_percpu_counters(mp);
 -	xfs_destroy_mount_workqueues(mp);
 -	xfs_close_devices(mp);
 -
 -	sb->s_fs_info = NULL;
 -	xfs_mount_free(mp);
 -}
 -
 -static long
 -xfs_fs_nr_cached_objects(
 -	struct super_block	*sb,
 -	struct shrink_control	*sc)
 -{
 -	/* Paranoia: catch incorrect calls during mount setup or teardown */
 -	if (WARN_ON_ONCE(!sb->s_fs_info))
 -		return 0;
 -	return xfs_reclaim_inodes_count(XFS_M(sb));
 -}
 -
 -static long
 -xfs_fs_free_cached_objects(
 -	struct super_block	*sb,
 -	struct shrink_control	*sc)
 -{
 -	return xfs_reclaim_inodes_nr(XFS_M(sb), sc->nr_to_scan);
 -}
 -
 -static const struct super_operations xfs_super_operations = {
 -	.alloc_inode		= xfs_fs_alloc_inode,
 -	.destroy_inode		= xfs_fs_destroy_inode,
 -	.dirty_inode		= xfs_fs_dirty_inode,
 -	.drop_inode		= xfs_fs_drop_inode,
 -	.put_super		= xfs_fs_put_super,
 -	.sync_fs		= xfs_fs_sync_fs,
 -	.freeze_fs		= xfs_fs_freeze,
 -	.unfreeze_fs		= xfs_fs_unfreeze,
 -	.statfs			= xfs_fs_statfs,
 -	.show_options		= xfs_fs_show_options,
 -	.nr_cached_objects	= xfs_fs_nr_cached_objects,
 -	.free_cached_objects	= xfs_fs_free_cached_objects,
 -};
 -
 -static int
 -suffix_kstrtoint(
 -	const char	*s,
 -	unsigned int	base,
 -	int		*res)
 -{
 -	int		last, shift_left_factor = 0, _res;
 -	char		*value;
 -	int		ret = 0;
 -
 -	value = kstrdup(s, GFP_KERNEL);
 -	if (!value)
 -		return -ENOMEM;
 -
 -	last = strlen(value) - 1;
 -	if (value[last] == 'K' || value[last] == 'k') {
 -		shift_left_factor = 10;
 -		value[last] = '\0';
 -	}
 -	if (value[last] == 'M' || value[last] == 'm') {
 -		shift_left_factor = 20;
 -		value[last] = '\0';
 -	}
 -	if (value[last] == 'G' || value[last] == 'g') {
 -		shift_left_factor = 30;
 -		value[last] = '\0';
 -	}
 -
 -	if (kstrtoint(value, base, &_res))
 -		ret = -EINVAL;
 -	kfree(value);
 -	*res = _res << shift_left_factor;
 -	return ret;
 -}
 -
 -/*
 - * Set mount state from a mount option.
 - *
 - * NOTE: mp->m_super is NULL here!
 - */
 -static int
 -xfs_fc_parse_param(
 -	struct fs_context	*fc,
 -	struct fs_parameter	*param)
 -{
 -	struct xfs_mount	*mp = fc->s_fs_info;
 -	struct fs_parse_result	result;
 -	int			size = 0;
 -	int			opt;
 -
 -	opt = fs_parse(fc, &xfs_fs_parameters, param, &result);
 -	if (opt < 0)
 -		return opt;
 -
 -	switch (opt) {
 -	case Opt_logbufs:
 -		mp->m_logbufs = result.uint_32;
 -		return 0;
 -	case Opt_logbsize:
 -		if (suffix_kstrtoint(param->string, 10, &mp->m_logbsize))
 -			return -EINVAL;
 -		return 0;
 -	case Opt_logdev:
 -		kfree(mp->m_logname);
 -		mp->m_logname = kstrdup(param->string, GFP_KERNEL);
 -		if (!mp->m_logname)
 -			return -ENOMEM;
 -		return 0;
 -	case Opt_rtdev:
 -		kfree(mp->m_rtname);
 -		mp->m_rtname = kstrdup(param->string, GFP_KERNEL);
 -		if (!mp->m_rtname)
 -			return -ENOMEM;
 -		return 0;
 -	case Opt_allocsize:
 -		if (suffix_kstrtoint(param->string, 10, &size))
 -			return -EINVAL;
 -		mp->m_allocsize_log = ffs(size) - 1;
 -		mp->m_flags |= XFS_MOUNT_ALLOCSIZE;
 -		return 0;
 -	case Opt_grpid:
 -	case Opt_bsdgroups:
 -		mp->m_flags |= XFS_MOUNT_GRPID;
 -		return 0;
 -	case Opt_nogrpid:
 -	case Opt_sysvgroups:
 -		mp->m_flags &= ~XFS_MOUNT_GRPID;
 -		return 0;
 -	case Opt_wsync:
 -		mp->m_flags |= XFS_MOUNT_WSYNC;
 -		return 0;
 -	case Opt_norecovery:
 -		mp->m_flags |= XFS_MOUNT_NORECOVERY;
 -		return 0;
 -	case Opt_noalign:
 -		mp->m_flags |= XFS_MOUNT_NOALIGN;
 -		return 0;
 -	case Opt_swalloc:
 -		mp->m_flags |= XFS_MOUNT_SWALLOC;
 -		return 0;
 -	case Opt_sunit:
 -		mp->m_dalign = result.uint_32;
 -		return 0;
 -	case Opt_swidth:
 -		mp->m_swidth = result.uint_32;
 -		return 0;
 -	case Opt_inode32:
 -		mp->m_flags |= XFS_MOUNT_SMALL_INUMS;
 -		return 0;
 -	case Opt_inode64:
 -		mp->m_flags &= ~XFS_MOUNT_SMALL_INUMS;
 -		return 0;
 -	case Opt_nouuid:
 -		mp->m_flags |= XFS_MOUNT_NOUUID;
 -		return 0;
 -	case Opt_ikeep:
 -		mp->m_flags |= XFS_MOUNT_IKEEP;
 -		return 0;
 -	case Opt_noikeep:
 -		mp->m_flags &= ~XFS_MOUNT_IKEEP;
 -		return 0;
 -	case Opt_largeio:
 -		mp->m_flags |= XFS_MOUNT_LARGEIO;
 -		return 0;
 -	case Opt_nolargeio:
 -		mp->m_flags &= ~XFS_MOUNT_LARGEIO;
 -		return 0;
 -	case Opt_attr2:
 -		mp->m_flags |= XFS_MOUNT_ATTR2;
 -		return 0;
 -	case Opt_noattr2:
 -		mp->m_flags &= ~XFS_MOUNT_ATTR2;
 -		mp->m_flags |= XFS_MOUNT_NOATTR2;
 -		return 0;
 -	case Opt_filestreams:
 -		mp->m_flags |= XFS_MOUNT_FILESTREAMS;
 -		return 0;
 -	case Opt_noquota:
 -		mp->m_qflags &= ~XFS_ALL_QUOTA_ACCT;
 -		mp->m_qflags &= ~XFS_ALL_QUOTA_ENFD;
 -		mp->m_qflags &= ~XFS_ALL_QUOTA_ACTIVE;
 -		return 0;
 -	case Opt_quota:
 -	case Opt_uquota:
 -	case Opt_usrquota:
 -		mp->m_qflags |= (XFS_UQUOTA_ACCT | XFS_UQUOTA_ACTIVE |
 -				 XFS_UQUOTA_ENFD);
 -		return 0;
 -	case Opt_qnoenforce:
 -	case Opt_uqnoenforce:
 -		mp->m_qflags |= (XFS_UQUOTA_ACCT | XFS_UQUOTA_ACTIVE);
 -		mp->m_qflags &= ~XFS_UQUOTA_ENFD;
 -		return 0;
 -	case Opt_pquota:
 -	case Opt_prjquota:
 -		mp->m_qflags |= (XFS_PQUOTA_ACCT | XFS_PQUOTA_ACTIVE |
 -				 XFS_PQUOTA_ENFD);
 -		return 0;
 -	case Opt_pqnoenforce:
 -		mp->m_qflags |= (XFS_PQUOTA_ACCT | XFS_PQUOTA_ACTIVE);
 -		mp->m_qflags &= ~XFS_PQUOTA_ENFD;
 -		return 0;
 -	case Opt_gquota:
 -	case Opt_grpquota:
 -		mp->m_qflags |= (XFS_GQUOTA_ACCT | XFS_GQUOTA_ACTIVE |
 -				 XFS_GQUOTA_ENFD);
 -		return 0;
 -	case Opt_gqnoenforce:
 -		mp->m_qflags |= (XFS_GQUOTA_ACCT | XFS_GQUOTA_ACTIVE);
 -		mp->m_qflags &= ~XFS_GQUOTA_ENFD;
 -		return 0;
 -	case Opt_discard:
 -		mp->m_flags |= XFS_MOUNT_DISCARD;
 -		return 0;
 -	case Opt_nodiscard:
 -		mp->m_flags &= ~XFS_MOUNT_DISCARD;
 -		return 0;
 -#ifdef CONFIG_FS_DAX
 -	case Opt_dax:
 -		mp->m_flags |= XFS_MOUNT_DAX;
 -		return 0;
 -#endif
 -	default:
 -		xfs_warn(mp, "unknown mount option [%s].", param->key);
 -		return -EINVAL;
 -	}
 -
 -	return 0;
 -}
 -
 -static int
 -xfs_fc_validate_params(
 -	struct xfs_mount	*mp)
 -{
 -	/*
 -	 * no recovery flag requires a read-only mount
 -	 */
 -	if ((mp->m_flags & XFS_MOUNT_NORECOVERY) &&
 -	    !(mp->m_flags & XFS_MOUNT_RDONLY)) {
 -		xfs_warn(mp, "no-recovery mounts must be read-only.");
 -		return -EINVAL;
 -	}
 -
 -	if ((mp->m_flags & XFS_MOUNT_NOALIGN) &&
 -	    (mp->m_dalign || mp->m_swidth)) {
 -		xfs_warn(mp,
 -	"sunit and swidth options incompatible with the noalign option");
 -		return -EINVAL;
 -	}
 -
 -	if (!IS_ENABLED(CONFIG_XFS_QUOTA) && mp->m_qflags != 0) {
 -		xfs_warn(mp, "quota support not available in this kernel.");
 -		return -EINVAL;
 -	}
 -
 -	if ((mp->m_dalign && !mp->m_swidth) ||
 -	    (!mp->m_dalign && mp->m_swidth)) {
 -		xfs_warn(mp, "sunit and swidth must be specified together");
 -		return -EINVAL;
 -	}
 -
 -	if (mp->m_dalign && (mp->m_swidth % mp->m_dalign != 0)) {
 -		xfs_warn(mp,
 -	"stripe width (%d) must be a multiple of the stripe unit (%d)",
 -			mp->m_swidth, mp->m_dalign);
 -		return -EINVAL;
 -	}
++		return;
+ 
 -	if (mp->m_logbufs != -1 &&
 -	    mp->m_logbufs != 0 &&
 -	    (mp->m_logbufs < XLOG_MIN_ICLOGS ||
 -	     mp->m_logbufs > XLOG_MAX_ICLOGS)) {
 -		xfs_warn(mp, "invalid logbufs value: %d [not %d-%d]",
 -			mp->m_logbufs, XLOG_MIN_ICLOGS, XLOG_MAX_ICLOGS);
 -		return -EINVAL;
 -	}
++	xfs_notice(mp, "Unmounting Filesystem");
++	xfs_filestream_unmount(mp);
++	xfs_unmountfs(mp);
+ 
 -	if (mp->m_logbsize != -1 &&
 -	    mp->m_logbsize !=  0 &&
 -	    (mp->m_logbsize < XLOG_MIN_RECORD_BSIZE ||
 -	     mp->m_logbsize > XLOG_MAX_RECORD_BSIZE ||
 -	     !is_power_of_2(mp->m_logbsize))) {
 -		xfs_warn(mp,
 -			"invalid logbufsize: %d [not 16k,32k,64k,128k or 256k]",
 -			mp->m_logbsize);
 -		return -EINVAL;
 -	}
++	xfs_freesb(mp);
++	free_percpu(mp->m_stats.xs_stats);
++	xfs_destroy_percpu_counters(mp);
++	xfs_destroy_mount_workqueues(mp);
++	xfs_close_devices(mp);
+ 
 -	if ((mp->m_flags & XFS_MOUNT_ALLOCSIZE) &&
 -	    (mp->m_allocsize_log > XFS_MAX_IO_LOG ||
 -	     mp->m_allocsize_log < XFS_MIN_IO_LOG)) {
 -		xfs_warn(mp, "invalid log iosize: %d [not %d-%d]",
 -			mp->m_allocsize_log, XFS_MIN_IO_LOG, XFS_MAX_IO_LOG);
 -		return -EINVAL;
 -	}
++	sb->s_fs_info = NULL;
++	xfs_mount_free(mp);
++}
+ 
 -	return 0;
++static long
++xfs_fs_nr_cached_objects(
++	struct super_block	*sb,
++	struct shrink_control	*sc)
++{
++	/* Paranoia: catch incorrect calls during mount setup or teardown */
++	if (WARN_ON_ONCE(!sb->s_fs_info))
++		return 0;
++	return xfs_reclaim_inodes_count(XFS_M(sb));
++}
++
++static long
++xfs_fs_free_cached_objects(
++	struct super_block	*sb,
++	struct shrink_control	*sc)
++{
++	return xfs_reclaim_inodes_nr(XFS_M(sb), sc->nr_to_scan);
+ }
+ 
++static const struct super_operations xfs_super_operations = {
++	.alloc_inode		= xfs_fs_alloc_inode,
++	.destroy_inode		= xfs_fs_destroy_inode,
++	.dirty_inode		= xfs_fs_dirty_inode,
++	.drop_inode		= xfs_fs_drop_inode,
++	.put_super		= xfs_fs_put_super,
++	.sync_fs		= xfs_fs_sync_fs,
++	.freeze_fs		= xfs_fs_freeze,
++	.unfreeze_fs		= xfs_fs_unfreeze,
++	.statfs			= xfs_fs_statfs,
++	.show_options		= xfs_fs_show_options,
++	.nr_cached_objects	= xfs_fs_nr_cached_objects,
++	.free_cached_objects	= xfs_fs_free_cached_objects,
++};
++
+ static int
 -xfs_fc_fill_super(
++suffix_kstrtoint(
++	const char	*s,
++	unsigned int	base,
++	int		*res)
++{
++	int		last, shift_left_factor = 0, _res;
++	char		*value;
++	int		ret = 0;
++>>>>>>> 50f8300904b1 (xfs: fold xfs_mount-alloc() into xfs_init_fs_context())
 +
 +STATIC int
 +xfs_fs_fill_super(
  	struct super_block	*sb,
 -	struct fs_context	*fc)
 +	void			*data,
 +	int			silent)
  {
 -	struct xfs_mount	*mp = sb->s_fs_info;
  	struct inode		*root;
 +	struct xfs_mount	*mp = NULL;
  	int			flags = 0, error = -ENOMEM;
  
 +	/*
 +	 * allocate mp and do all low-level struct initializations before we
 +	 * attach it to the super
 +	 */
 +	mp = xfs_mount_alloc();
 +	if (!mp)
 +		goto out;
  	mp->m_super = sb;
 +	sb->s_fs_info = mp;
  
 -	error = xfs_fc_validate_params(mp);
 +	error = xfs_parseargs(mp, (char *)data);
  	if (error)
  		goto out_free_names;
  
@@@ -1765,75 -1543,247 +1835,128 @@@
  	goto out_free_sb;
  }
  
 -static int
 -xfs_fc_get_tree(
 -	struct fs_context	*fc)
 -{
 -	return get_tree_bdev(fc, xfs_fc_fill_super);
 -}
 -
 -static int
 -xfs_remount_rw(
 -	struct xfs_mount	*mp)
 +STATIC void
 +xfs_fs_put_super(
 +	struct super_block	*sb)
  {
 -	struct xfs_sb		*sbp = &mp->m_sb;
 -	int error;
 -
 -	if (mp->m_flags & XFS_MOUNT_NORECOVERY) {
 -		xfs_warn(mp,
 -			"ro->rw transition prohibited on norecovery mount");
 -		return -EINVAL;
 -	}
 -
 -	if (XFS_SB_VERSION_NUM(sbp) == XFS_SB_VERSION_5 &&
 -	    xfs_sb_has_ro_compat_feature(sbp, XFS_SB_FEAT_RO_COMPAT_UNKNOWN)) {
 -		xfs_warn(mp,
 -	"ro->rw transition prohibited on unknown (0x%x) ro-compat filesystem",
 -			(sbp->sb_features_ro_compat &
 -				XFS_SB_FEAT_RO_COMPAT_UNKNOWN));
 -		return -EINVAL;
 -	}
 -
 -	mp->m_flags &= ~XFS_MOUNT_RDONLY;
 -
 -	/*
 -	 * If this is the first remount to writeable state we might have some
 -	 * superblock changes to update.
 -	 */
 -	if (mp->m_update_sb) {
 -		error = xfs_sync_sb(mp, false);
 -		if (error) {
 -			xfs_warn(mp, "failed to write sb changes");
 -			return error;
 -		}
 -		mp->m_update_sb = false;
 -	}
 +	struct xfs_mount	*mp = XFS_M(sb);
  
 -	/*
 -	 * Fill out the reserve pool if it is empty. Use the stashed value if
 -	 * it is non-zero, otherwise go with the default.
 -	 */
 -	xfs_restore_resvblks(mp);
 -	xfs_log_work_queue(mp);
 +	/* if ->fill_super failed, we have no mount to tear down */
 +	if (!sb->s_fs_info)
 +		return;
  
 -	/* Recover any CoW blocks that never got remapped. */
 -	error = xfs_reflink_recover_cow(mp);
 -	if (error) {
 -		xfs_err(mp,
 -			"Error %d recovering leftover CoW allocations.", error);
 -			xfs_force_shutdown(mp, SHUTDOWN_CORRUPT_INCORE);
 -		return error;
 -	}
 -	xfs_start_block_reaping(mp);
 +	xfs_notice(mp, "Unmounting Filesystem");
 +	xfs_filestream_unmount(mp);
 +	xfs_unmountfs(mp);
  
 -	/* Create the per-AG metadata reservation pool .*/
 -	error = xfs_fs_reserve_ag_blocks(mp);
 -	if (error && error != -ENOSPC)
 -		return error;
 +	xfs_freesb(mp);
 +	free_percpu(mp->m_stats.xs_stats);
 +	xfs_destroy_percpu_counters(mp);
 +	xfs_destroy_mount_workqueues(mp);
 +	xfs_close_devices(mp);
  
 -	return 0;
 +	sb->s_fs_info = NULL;
 +	xfs_mount_free(mp);
  }
  
 -static int
 -xfs_remount_ro(
 -	struct xfs_mount	*mp)
 +STATIC struct dentry *
 +xfs_fs_mount(
 +	struct file_system_type	*fs_type,
 +	int			flags,
 +	const char		*dev_name,
 +	void			*data)
  {
 -	int error;
 -
 -	/*
 -	 * Cancel background eofb scanning so it cannot race with the final
 -	 * log force+buftarg wait and deadlock the remount.
 -	 */
 -	xfs_stop_block_reaping(mp);
 -
 -	/* Get rid of any leftover CoW reservations... */
 -	error = xfs_icache_free_cowblocks(mp, NULL);
 -	if (error) {
 -		xfs_force_shutdown(mp, SHUTDOWN_CORRUPT_INCORE);
 -		return error;
 -	}
 -
 -	/* Free the per-AG metadata reservation pool. */
 -	error = xfs_fs_unreserve_ag_blocks(mp);
 -	if (error) {
 -		xfs_force_shutdown(mp, SHUTDOWN_CORRUPT_INCORE);
 -		return error;
 -	}
 -
 -	/*
 -	 * Before we sync the metadata, we need to free up the reserve block
 -	 * pool so that the used block count in the superblock on disk is
 -	 * correct at the end of the remount. Stash the current* reserve pool
 -	 * size so that if we get remounted rw, we can return it to the same
 -	 * size.
 -	 */
 -	xfs_save_resvblks(mp);
 -
 -	xfs_quiesce_attr(mp);
 -	mp->m_flags |= XFS_MOUNT_RDONLY;
 -
 -	return 0;
 +	return mount_bdev(fs_type, flags, dev_name, data, xfs_fs_fill_super);
  }
  
 -/*
 - * Logically we would return an error here to prevent users from believing
 - * they might have changed mount options using remount which can't be changed.
 - *
 - * But unfortunately mount(8) adds all options from mtab and fstab to the mount
 - * arguments in some cases so we can't blindly reject options, but have to
 - * check for each specified option if it actually differs from the currently
 - * set option and only reject it if that's the case.
 - *
 - * Until that is implemented we return success for every remount request, and
 - * silently ignore all options that we can't actually change.
 - */
 -static int
 -xfs_fc_reconfigure(
 -	struct fs_context *fc)
 +static long
 +xfs_fs_nr_cached_objects(
 +	struct super_block	*sb,
 +	struct shrink_control	*sc)
  {
 -	struct xfs_mount	*mp = XFS_M(fc->root->d_sb);
 -	struct xfs_mount        *new_mp = fc->s_fs_info;
 -	xfs_sb_t		*sbp = &mp->m_sb;
 -	int			flags = fc->sb_flags;
 -	int			error;
 -
 -	error = xfs_fc_validate_params(new_mp);
 -	if (error)
 -		return error;
 -
 -	sync_filesystem(mp->m_super);
 -
 -	/* inode32 -> inode64 */
 -	if ((mp->m_flags & XFS_MOUNT_SMALL_INUMS) &&
 -	    !(new_mp->m_flags & XFS_MOUNT_SMALL_INUMS)) {
 -		mp->m_flags &= ~XFS_MOUNT_SMALL_INUMS;
 -		mp->m_maxagi = xfs_set_inode_alloc(mp, sbp->sb_agcount);
 -	}
 -
 -	/* inode64 -> inode32 */
 -	if (!(mp->m_flags & XFS_MOUNT_SMALL_INUMS) &&
 -	    (new_mp->m_flags & XFS_MOUNT_SMALL_INUMS)) {
 -		mp->m_flags |= XFS_MOUNT_SMALL_INUMS;
 -		mp->m_maxagi = xfs_set_inode_alloc(mp, sbp->sb_agcount);
 -	}
 -
 -	/* ro -> rw */
 -	if ((mp->m_flags & XFS_MOUNT_RDONLY) && !(flags & SB_RDONLY)) {
 -		error = xfs_remount_rw(mp);
 -		if (error)
 -			return error;
 -	}
 -
 -	/* rw -> ro */
 -	if (!(mp->m_flags & XFS_MOUNT_RDONLY) && (flags & SB_RDONLY)) {
 -		error = xfs_remount_ro(mp);
 -		if (error)
 -			return error;
 -	}
 -
 -	return 0;
 +	/* Paranoia: catch incorrect calls during mount setup or teardown */
 +	if (WARN_ON_ONCE(!sb->s_fs_info))
 +		return 0;
 +	return xfs_reclaim_inodes_count(XFS_M(sb));
  }
  
 -static void xfs_fc_free(
 -	struct fs_context	*fc)
 +static long
 +xfs_fs_free_cached_objects(
 +	struct super_block	*sb,
 +	struct shrink_control	*sc)
  {
 -	struct xfs_mount	*mp = fc->s_fs_info;
 -
 -	/*
 -	 * mp is stored in the fs_context when it is initialized.
 -	 * mp is transferred to the superblock on a successful mount,
 -	 * but if an error occurs before the transfer we have to free
 -	 * it here.
 -	 */
 -	if (mp)
 -		xfs_mount_free(mp);
 +	return xfs_reclaim_inodes_nr(XFS_M(sb), sc->nr_to_scan);
  }
  
 -static const struct fs_context_operations xfs_context_ops = {
 -	.parse_param = xfs_fc_parse_param,
 -	.get_tree    = xfs_fc_get_tree,
 -	.reconfigure = xfs_fc_reconfigure,
 -	.free        = xfs_fc_free,
 +static const struct super_operations xfs_super_operations = {
 +	.alloc_inode		= xfs_fs_alloc_inode,
 +	.destroy_inode		= xfs_fs_destroy_inode,
 +	.dirty_inode		= xfs_fs_dirty_inode,
 +	.drop_inode		= xfs_fs_drop_inode,
 +	.put_super		= xfs_fs_put_super,
 +	.sync_fs		= xfs_fs_sync_fs,
 +	.freeze_fs		= xfs_fs_freeze,
 +	.unfreeze_fs		= xfs_fs_unfreeze,
 +	.statfs			= xfs_fs_statfs,
 +	.remount_fs		= xfs_fs_remount,
 +	.show_options		= xfs_fs_show_options,
 +	.nr_cached_objects	= xfs_fs_nr_cached_objects,
 +	.free_cached_objects	= xfs_fs_free_cached_objects,
  };
  
++<<<<<<< HEAD
++=======
+ static int xfs_init_fs_context(
+ 	struct fs_context	*fc)
+ {
+ 	struct xfs_mount	*mp;
+ 
+ 	mp = kmem_alloc(sizeof(struct xfs_mount), KM_ZERO);
+ 	if (!mp)
+ 		return -ENOMEM;
+ 
+ 	spin_lock_init(&mp->m_sb_lock);
+ 	spin_lock_init(&mp->m_agirotor_lock);
+ 	INIT_RADIX_TREE(&mp->m_perag_tree, GFP_ATOMIC);
+ 	spin_lock_init(&mp->m_perag_lock);
+ 	mutex_init(&mp->m_growlock);
+ 	atomic_set(&mp->m_active_trans, 0);
+ 	INIT_DELAYED_WORK(&mp->m_reclaim_work, xfs_reclaim_worker);
+ 	INIT_DELAYED_WORK(&mp->m_eofblocks_work, xfs_eofblocks_worker);
+ 	INIT_DELAYED_WORK(&mp->m_cowblocks_work, xfs_cowblocks_worker);
+ 	mp->m_kobj.kobject.kset = xfs_kset;
+ 	/*
+ 	 * We don't create the finobt per-ag space reservation until after log
+ 	 * recovery, so we must set this to true so that an ifree transaction
+ 	 * started during log recovery will not depend on space reservations
+ 	 * for finobt expansion.
+ 	 */
+ 	mp->m_finobt_nores = true;
+ 
+ 	/*
+ 	 * These can be overridden by the mount option parsing.
+ 	 */
+ 	mp->m_logbufs = -1;
+ 	mp->m_logbsize = -1;
+ 	mp->m_allocsize_log = 16; /* 64k */
+ 
+ 	/*
+ 	 * Copy binary VFS mount flags we are interested in.
+ 	 */
+ 	if (fc->sb_flags & SB_RDONLY)
+ 		mp->m_flags |= XFS_MOUNT_RDONLY;
+ 	if (fc->sb_flags & SB_DIRSYNC)
+ 		mp->m_flags |= XFS_MOUNT_DIRSYNC;
+ 	if (fc->sb_flags & SB_SYNCHRONOUS)
+ 		mp->m_flags |= XFS_MOUNT_WSYNC;
+ 
+ 	fc->s_fs_info = mp;
+ 	fc->ops = &xfs_context_ops;
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 50f8300904b1 (xfs: fold xfs_mount-alloc() into xfs_init_fs_context())
  static struct file_system_type xfs_fs_type = {
  	.owner			= THIS_MODULE,
  	.name			= "xfs",
* Unmerged path fs/xfs/xfs_super.c
