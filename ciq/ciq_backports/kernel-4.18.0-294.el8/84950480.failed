mm: memcg/slab: remove unused argument by charge_slab_page()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Roman Gushchin <guro@fb.com>
commit 849504809f86ef43b0b12617c0a71b6c6e61cd78
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/84950480.failed

charge_slab_page() is not using the gfp argument anymore,
remove it.

	Signed-off-by: Roman Gushchin <guro@fb.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Reviewed-by: Shakeel Butt <shakeelb@google.com>
	Acked-by: Vlastimil Babka <vbabka@suse.cz>
	Cc: Christoph Lameter <cl@linux.com>
	Cc: Pekka Enberg <penberg@kernel.org>
	Cc: David Rientjes <rientjes@google.com>
	Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
	Cc: Johannes Weiner <hannes@cmpxchg.org>
	Cc: Michal Hocko <mhocko@kernel.org>
Link: http://lkml.kernel.org/r/20200707173612.124425-1-guro@fb.com
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 849504809f86ef43b0b12617c0a71b6c6e61cd78)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/slab.c
#	mm/slab.h
#	mm/slub.c
diff --cc mm/slab.c
index 98c009baf3ea,92e6f1228526..000000000000
--- a/mm/slab.c
+++ b/mm/slab.c
@@@ -1409,11 -1379,7 +1409,15 @@@ static struct page *kmem_getpages(struc
  		return NULL;
  	}
  
++<<<<<<< HEAD
 +	if (charge_slab_page(page, flags, cachep->gfporder, cachep)) {
 +		__free_pages(page, cachep->gfporder);
 +		return NULL;
 +	}
 +
++=======
+ 	charge_slab_page(page, cachep->gfporder, cachep);
++>>>>>>> 849504809f86 (mm: memcg/slab: remove unused argument by charge_slab_page())
  	__SetPageSlab(page);
  	/* Record if ALLOC_NO_WATERMARKS was set when allocating the slab */
  	if (sk_memalloc_socks() && page_is_pfmemalloc(page))
diff --cc mm/slab.h
index 45ad57de9d88,853a4bd0ede5..000000000000
--- a/mm/slab.h
+++ b/mm/slab.h
@@@ -403,19 -406,28 +403,34 @@@ static inline void memcg_link_cache(str
  {
  }
  
 -static inline void memcg_slab_free_hook(struct kmem_cache *s, struct page *page,
 -					void *p)
 -{
 -}
  #endif /* CONFIG_MEMCG_KMEM */
  
 -static inline struct kmem_cache *virt_to_cache(const void *obj)
 +static __always_inline int charge_slab_page(struct page *page,
 +					    gfp_t gfp, int order,
 +					    struct kmem_cache *s)
  {
 -	struct page *page;
 +	if (is_root_cache(s)) {
 +		mod_node_page_state(page_pgdat(page), cache_vmstat_idx(s),
 +				    1 << order);
 +		return 0;
 +	}
  
++<<<<<<< HEAD
 +	return memcg_charge_slab(page, gfp, order, s);
++=======
+ 	page = virt_to_head_page(obj);
+ 	if (WARN_ONCE(!PageSlab(page), "%s: Object is not a Slab page!\n",
+ 					__func__))
+ 		return NULL;
+ 	return page->slab_cache;
+ }
+ 
+ static __always_inline void charge_slab_page(struct page *page, int order,
+ 					     struct kmem_cache *s)
+ {
+ 	mod_node_page_state(page_pgdat(page), cache_vmstat_idx(s),
+ 			    PAGE_SIZE << order);
++>>>>>>> 849504809f86 (mm: memcg/slab: remove unused argument by charge_slab_page())
  }
  
  static __always_inline void uncharge_slab_page(struct page *page, int order,
diff --cc mm/slub.c
index 135072f4c635,9440c68ffc05..000000000000
--- a/mm/slub.c
+++ b/mm/slub.c
@@@ -1612,10 -1620,8 +1612,15 @@@ static inline struct page *alloc_slab_p
  	else
  		page = __alloc_pages_node(node, flags, order);
  
++<<<<<<< HEAD
 +	if (page && charge_slab_page(page, flags, order, s)) {
 +		__free_pages(page, order);
 +		page = NULL;
 +	}
++=======
+ 	if (page)
+ 		charge_slab_page(page, order, s);
++>>>>>>> 849504809f86 (mm: memcg/slab: remove unused argument by charge_slab_page())
  
  	return page;
  }
* Unmerged path mm/slab.c
* Unmerged path mm/slab.h
* Unmerged path mm/slub.c
