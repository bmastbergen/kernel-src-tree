mm/gup: move __get_user_pages_fast() down a few lines in gup.c

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author John Hubbard <jhubbard@nvidia.com>
commit 9e1f0580d37e0d3fcfc2274128a5cc476feba5d0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/9e1f0580.failed

Patch series "mm/gup, drm/i915: refactor gup_fast, convert to pin_user_pages()", v2.

In order to convert the drm/i915 driver from get_user_pages() to
pin_user_pages(), a FOLL_PIN equivalent of __get_user_pages_fast() was
required.  That led to refactoring __get_user_pages_fast(), with the
following goals:

1) As above: provide a pin_user_pages*() routine for drm/i915 to call,
   in place of __get_user_pages_fast(),

2) Get rid of the gup.c duplicate code for walking page tables with
   interrupts disabled. This duplicate code is a minor maintenance
   problem anyway.

3) Make it easy for an upcoming patch from Souptick, which aims to
   convert __get_user_pages_fast() to use a gup_flags argument, instead
   of a bool writeable arg.  Also, if this series looks good, we can
   ask Souptick to change the name as well, to whatever the consensus
   is. My initial recommendation is: get_user_pages_fast_only(), to
   match the new pin_user_pages_only().

This patch (of 4):

This is in order to avoid a forward declaration of
internal_get_user_pages_fast(), in the next patch.

This is code movement only--all generated code should be identical.

	Signed-off-by: John Hubbard <jhubbard@nvidia.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>
	Cc: Daniel Vetter <daniel@ffwll.ch>
	Cc: David Airlie <airlied@linux.ie>
	Cc: Jani Nikula <jani.nikula@linux.intel.com>
	Cc: "Joonas Lahtinen" <joonas.lahtinen@linux.intel.com>
	Cc: Matthew Auld <matthew.auld@intel.com>
	Cc: Matthew Wilcox <willy@infradead.org>
	Cc: Rodrigo Vivi <rodrigo.vivi@intel.com>
	Cc: Souptick Joarder <jrdr.linux@gmail.com>
	Cc: Tvrtko Ursulin <tvrtko.ursulin@intel.com>
Link: http://lkml.kernel.org/r/20200522051931.54191-1-jhubbard@nvidia.com
Link: http://lkml.kernel.org/r/20200519002124.2025955-1-jhubbard@nvidia.com
Link: http://lkml.kernel.org/r/20200519002124.2025955-2-jhubbard@nvidia.com
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 9e1f0580d37e0d3fcfc2274128a5cc476feba5d0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/gup.c
diff --cc mm/gup.c
index b62e810dd644,57b5f3e22076..000000000000
--- a/mm/gup.c
+++ b/mm/gup.c
@@@ -2168,49 -2703,6 +2168,52 @@@ static bool gup_fast_permitted(unsigne
  }
  #endif
  
++<<<<<<< HEAD
 +/*
 + * Like get_user_pages_fast() except it's IRQ-safe in that it won't fall back to
 + * the regular GUP.
 + * Note a difference with get_user_pages_fast: this always returns the
 + * number of pages pinned, 0 if no pages were pinned.
 + */
 +int __get_user_pages_fast(unsigned long start, int nr_pages, int write,
 +			  struct page **pages)
 +{
 +	unsigned long len, end;
 +	unsigned long flags;
 +	int nr = 0;
 +
 +	start = untagged_addr(start) & PAGE_MASK;
 +	len = (unsigned long) nr_pages << PAGE_SHIFT;
 +	end = start + len;
 +
 +	if (end <= start)
 +		return 0;
 +	if (unlikely(!access_ok((void __user *)start, len)))
 +		return 0;
 +
 +	/*
 +	 * Disable interrupts.  We use the nested form as we can already have
 +	 * interrupts disabled by get_futex_key.
 +	 *
 +	 * With interrupts disabled, we block page table pages from being
 +	 * freed from under us. See struct mmu_table_batch comments in
 +	 * include/asm-generic/tlb.h for more details.
 +	 *
 +	 * We do not adopt an rcu_read_lock(.) here as we also want to
 +	 * block IPIs that come from THPs splitting.
 +	 */
 +
 +	if (gup_fast_permitted(start, end)) {
 +		local_irq_save(flags);
 +		gup_pgd_range(start, end, write ? FOLL_WRITE : 0, pages, &nr);
 +		local_irq_restore(flags);
 +	}
 +
 +	return nr;
 +}
 +
++=======
++>>>>>>> 9e1f0580d37e (mm/gup: move __get_user_pages_fast() down a few lines in gup.c)
  static int __gup_longterm_unlocked(unsigned long start, int nr_pages,
  				   unsigned int gup_flags, struct page **pages)
  {
@@@ -2297,4 -2782,231 +2300,235 @@@ int get_user_pages_fast(unsigned long s
  	return ret;
  }
  
++<<<<<<< HEAD
 +#endif /* CONFIG_HAVE_GENERIC_GUP */
++=======
+ /*
+  * Like get_user_pages_fast() except it's IRQ-safe in that it won't fall back to
+  * the regular GUP.
+  * Note a difference with get_user_pages_fast: this always returns the
+  * number of pages pinned, 0 if no pages were pinned.
+  *
+  * If the architecture does not support this function, simply return with no
+  * pages pinned.
+  *
+  * Careful, careful! COW breaking can go either way, so a non-write
+  * access can get ambiguous page results. If you call this function without
+  * 'write' set, you'd better be sure that you're ok with that ambiguity.
+  */
+ int __get_user_pages_fast(unsigned long start, int nr_pages, int write,
+ 			  struct page **pages)
+ {
+ 	unsigned long len, end;
+ 	unsigned long flags;
+ 	int nr_pinned = 0;
+ 	/*
+ 	 * Internally (within mm/gup.c), gup fast variants must set FOLL_GET,
+ 	 * because gup fast is always a "pin with a +1 page refcount" request.
+ 	 */
+ 	unsigned int gup_flags = FOLL_GET;
+ 
+ 	if (write)
+ 		gup_flags |= FOLL_WRITE;
+ 
+ 	start = untagged_addr(start) & PAGE_MASK;
+ 	len = (unsigned long) nr_pages << PAGE_SHIFT;
+ 	end = start + len;
+ 
+ 	if (end <= start)
+ 		return 0;
+ 	if (unlikely(!access_ok((void __user *)start, len)))
+ 		return 0;
+ 
+ 	/*
+ 	 * Disable interrupts.  We use the nested form as we can already have
+ 	 * interrupts disabled by get_futex_key.
+ 	 *
+ 	 * With interrupts disabled, we block page table pages from being
+ 	 * freed from under us. See struct mmu_table_batch comments in
+ 	 * include/asm-generic/tlb.h for more details.
+ 	 *
+ 	 * We do not adopt an rcu_read_lock(.) here as we also want to
+ 	 * block IPIs that come from THPs splitting.
+ 	 *
+ 	 * NOTE! We allow read-only gup_fast() here, but you'd better be
+ 	 * careful about possible COW pages. You'll get _a_ COW page, but
+ 	 * not necessarily the one you intended to get depending on what
+ 	 * COW event happens after this. COW may break the page copy in a
+ 	 * random direction.
+ 	 */
+ 
+ 	if (IS_ENABLED(CONFIG_HAVE_FAST_GUP) &&
+ 	    gup_fast_permitted(start, end)) {
+ 		local_irq_save(flags);
+ 		gup_pgd_range(start, end, gup_flags, pages, &nr_pinned);
+ 		local_irq_restore(flags);
+ 	}
+ 
+ 	return nr_pinned;
+ }
+ EXPORT_SYMBOL_GPL(__get_user_pages_fast);
+ 
+ /**
+  * get_user_pages_fast() - pin user pages in memory
+  * @start:      starting user address
+  * @nr_pages:   number of pages from start to pin
+  * @gup_flags:  flags modifying pin behaviour
+  * @pages:      array that receives pointers to the pages pinned.
+  *              Should be at least nr_pages long.
+  *
+  * Attempt to pin user pages in memory without taking mm->mmap_sem.
+  * If not successful, it will fall back to taking the lock and
+  * calling get_user_pages().
+  *
+  * Returns number of pages pinned. This may be fewer than the number requested.
+  * If nr_pages is 0 or negative, returns 0. If no pages were pinned, returns
+  * -errno.
+  */
+ int get_user_pages_fast(unsigned long start, int nr_pages,
+ 			unsigned int gup_flags, struct page **pages)
+ {
+ 	/*
+ 	 * FOLL_PIN must only be set internally by the pin_user_pages*() APIs,
+ 	 * never directly by the caller, so enforce that:
+ 	 */
+ 	if (WARN_ON_ONCE(gup_flags & FOLL_PIN))
+ 		return -EINVAL;
+ 
+ 	/*
+ 	 * The caller may or may not have explicitly set FOLL_GET; either way is
+ 	 * OK. However, internally (within mm/gup.c), gup fast variants must set
+ 	 * FOLL_GET, because gup fast is always a "pin with a +1 page refcount"
+ 	 * request.
+ 	 */
+ 	gup_flags |= FOLL_GET;
+ 	return internal_get_user_pages_fast(start, nr_pages, gup_flags, pages);
+ }
+ EXPORT_SYMBOL_GPL(get_user_pages_fast);
+ 
+ /**
+  * pin_user_pages_fast() - pin user pages in memory without taking locks
+  *
+  * @start:      starting user address
+  * @nr_pages:   number of pages from start to pin
+  * @gup_flags:  flags modifying pin behaviour
+  * @pages:      array that receives pointers to the pages pinned.
+  *              Should be at least nr_pages long.
+  *
+  * Nearly the same as get_user_pages_fast(), except that FOLL_PIN is set. See
+  * get_user_pages_fast() for documentation on the function arguments, because
+  * the arguments here are identical.
+  *
+  * FOLL_PIN means that the pages must be released via unpin_user_page(). Please
+  * see Documentation/core-api/pin_user_pages.rst for further details.
+  *
+  * This is intended for Case 1 (DIO) in Documentation/core-api/pin_user_pages.rst. It
+  * is NOT intended for Case 2 (RDMA: long-term pins).
+  */
+ int pin_user_pages_fast(unsigned long start, int nr_pages,
+ 			unsigned int gup_flags, struct page **pages)
+ {
+ 	/* FOLL_GET and FOLL_PIN are mutually exclusive. */
+ 	if (WARN_ON_ONCE(gup_flags & FOLL_GET))
+ 		return -EINVAL;
+ 
+ 	gup_flags |= FOLL_PIN;
+ 	return internal_get_user_pages_fast(start, nr_pages, gup_flags, pages);
+ }
+ EXPORT_SYMBOL_GPL(pin_user_pages_fast);
+ 
+ /**
+  * pin_user_pages_remote() - pin pages of a remote process (task != current)
+  *
+  * @tsk:	the task_struct to use for page fault accounting, or
+  *		NULL if faults are not to be recorded.
+  * @mm:		mm_struct of target mm
+  * @start:	starting user address
+  * @nr_pages:	number of pages from start to pin
+  * @gup_flags:	flags modifying lookup behaviour
+  * @pages:	array that receives pointers to the pages pinned.
+  *		Should be at least nr_pages long. Or NULL, if caller
+  *		only intends to ensure the pages are faulted in.
+  * @vmas:	array of pointers to vmas corresponding to each page.
+  *		Or NULL if the caller does not require them.
+  * @locked:	pointer to lock flag indicating whether lock is held and
+  *		subsequently whether VM_FAULT_RETRY functionality can be
+  *		utilised. Lock must initially be held.
+  *
+  * Nearly the same as get_user_pages_remote(), except that FOLL_PIN is set. See
+  * get_user_pages_remote() for documentation on the function arguments, because
+  * the arguments here are identical.
+  *
+  * FOLL_PIN means that the pages must be released via unpin_user_page(). Please
+  * see Documentation/core-api/pin_user_pages.rst for details.
+  *
+  * This is intended for Case 1 (DIO) in Documentation/core-api/pin_user_pages.rst. It
+  * is NOT intended for Case 2 (RDMA: long-term pins).
+  */
+ long pin_user_pages_remote(struct task_struct *tsk, struct mm_struct *mm,
+ 			   unsigned long start, unsigned long nr_pages,
+ 			   unsigned int gup_flags, struct page **pages,
+ 			   struct vm_area_struct **vmas, int *locked)
+ {
+ 	/* FOLL_GET and FOLL_PIN are mutually exclusive. */
+ 	if (WARN_ON_ONCE(gup_flags & FOLL_GET))
+ 		return -EINVAL;
+ 
+ 	gup_flags |= FOLL_PIN;
+ 	return __get_user_pages_remote(tsk, mm, start, nr_pages, gup_flags,
+ 				       pages, vmas, locked);
+ }
+ EXPORT_SYMBOL(pin_user_pages_remote);
+ 
+ /**
+  * pin_user_pages() - pin user pages in memory for use by other devices
+  *
+  * @start:	starting user address
+  * @nr_pages:	number of pages from start to pin
+  * @gup_flags:	flags modifying lookup behaviour
+  * @pages:	array that receives pointers to the pages pinned.
+  *		Should be at least nr_pages long. Or NULL, if caller
+  *		only intends to ensure the pages are faulted in.
+  * @vmas:	array of pointers to vmas corresponding to each page.
+  *		Or NULL if the caller does not require them.
+  *
+  * Nearly the same as get_user_pages(), except that FOLL_TOUCH is not set, and
+  * FOLL_PIN is set.
+  *
+  * FOLL_PIN means that the pages must be released via unpin_user_page(). Please
+  * see Documentation/core-api/pin_user_pages.rst for details.
+  *
+  * This is intended for Case 1 (DIO) in Documentation/core-api/pin_user_pages.rst. It
+  * is NOT intended for Case 2 (RDMA: long-term pins).
+  */
+ long pin_user_pages(unsigned long start, unsigned long nr_pages,
+ 		    unsigned int gup_flags, struct page **pages,
+ 		    struct vm_area_struct **vmas)
+ {
+ 	/* FOLL_GET and FOLL_PIN are mutually exclusive. */
+ 	if (WARN_ON_ONCE(gup_flags & FOLL_GET))
+ 		return -EINVAL;
+ 
+ 	gup_flags |= FOLL_PIN;
+ 	return __gup_longterm_locked(current, current->mm, start, nr_pages,
+ 				     pages, vmas, gup_flags);
+ }
+ EXPORT_SYMBOL(pin_user_pages);
+ 
+ /*
+  * pin_user_pages_unlocked() is the FOLL_PIN variant of
+  * get_user_pages_unlocked(). Behavior is the same, except that this one sets
+  * FOLL_PIN and rejects FOLL_GET.
+  */
+ long pin_user_pages_unlocked(unsigned long start, unsigned long nr_pages,
+ 			     struct page **pages, unsigned int gup_flags)
+ {
+ 	/* FOLL_GET and FOLL_PIN are mutually exclusive. */
+ 	if (WARN_ON_ONCE(gup_flags & FOLL_GET))
+ 		return -EINVAL;
+ 
+ 	gup_flags |= FOLL_PIN;
+ 	return get_user_pages_unlocked(start, nr_pages, pages, gup_flags);
+ }
+ EXPORT_SYMBOL(pin_user_pages_unlocked);
++>>>>>>> 9e1f0580d37e (mm/gup: move __get_user_pages_fast() down a few lines in gup.c)
* Unmerged path mm/gup.c
