mptcp: fix pending data accounting

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Paolo Abeni <pabeni@redhat.com>
commit 13e1603739e58e94e7a3c24191fa2dcd1a8a5df3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/13e16037.failed

When sendmsg() needs to wait for memory, the pending data
is not updated. That causes a drift in forward memory allocation,
leading to stall and/or warnings at socket close time.

This change addresses the above issue moving the pending data
counter update inside the sendmsg() main loop.

Fixes: 6e628cd3a8f7 ("mptcp: use mptcp release_cb for delayed tasks")
	Reviewed-by: Mat Martineau <mathew.j.martineau@linux.intel.com>
	Signed-off-by: Paolo Abeni <pabeni@redhat.com>
	Signed-off-by: Jakub Kicinski <kuba@kernel.org>
(cherry picked from commit 13e1603739e58e94e7a3c24191fa2dcd1a8a5df3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/mptcp/protocol.c
diff --cc net/mptcp/protocol.c
index 509aa48ee70d,09b19aa2f205..000000000000
--- a/net/mptcp/protocol.c
+++ b/net/mptcp/protocol.c
@@@ -946,119 -1597,97 +946,195 @@@ static int mptcp_sendmsg(struct sock *s
  			goto out;
  	}
  
 -	pfrag = sk_page_frag(sk);
 +restart:
 +	mptcp_clean_una(sk);
  
 -	while (msg_data_left(msg)) {
 -		int total_ts, frag_truesize = 0;
 -		struct mptcp_data_frag *dfrag;
 -		struct sk_buff_head skbs;
 -		bool dfrag_collapsed;
 -		size_t psize, offset;
 +	if (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN)) {
 +		ret = -EPIPE;
 +		goto out;
 +	}
  
 -		if (sk->sk_err || (sk->sk_shutdown & SEND_SHUTDOWN)) {
 -			ret = -EPIPE;
 -			goto out;
 +	__mptcp_flush_join_list(msk);
 +	ssk = mptcp_subflow_get_send(msk);
 +	while (!sk_stream_memory_free(sk) || !ssk) {
 +		if (ssk) {
 +			/* make sure retransmit timer is
 +			 * running before we wait for memory.
 +			 *
 +			 * The retransmit timer might be needed
 +			 * to make the peer send an up-to-date
 +			 * MPTCP Ack.
 +			 */
 +			mptcp_set_timeout(sk, ssk);
 +			if (!mptcp_timer_pending(sk))
 +				mptcp_reset_timer(sk);
  		}
  
++<<<<<<< HEAD
 +		mptcp_nospace(msk);
++=======
+ 		/* reuse tail pfrag, if possible, or carve a new one from the
+ 		 * page allocator
+ 		 */
+ 		dfrag = mptcp_pending_tail(sk);
+ 		dfrag_collapsed = mptcp_frag_can_collapse_to(msk, pfrag, dfrag);
+ 		if (!dfrag_collapsed) {
+ 			if (!sk_stream_memory_free(sk))
+ 				goto wait_for_memory;
+ 
+ 			if (!mptcp_page_frag_refill(sk, pfrag))
+ 				goto wait_for_memory;
+ 
+ 			dfrag = mptcp_carve_data_frag(msk, pfrag, pfrag->offset);
+ 			frag_truesize = dfrag->overhead;
+ 		}
+ 
+ 		/* we do not bound vs wspace, to allow a single packet.
+ 		 * memory accounting will prevent execessive memory usage
+ 		 * anyway
+ 		 */
+ 		offset = dfrag->offset + dfrag->data_len;
+ 		psize = pfrag->size - offset;
+ 		psize = min_t(size_t, psize, msg_data_left(msg));
+ 		total_ts = psize + frag_truesize;
+ 		__skb_queue_head_init(&skbs);
+ 		if (!mptcp_tx_cache_refill(sk, psize, &skbs, &total_ts))
+ 			goto wait_for_memory;
+ 
+ 		if (!mptcp_wmem_alloc(sk, total_ts)) {
+ 			__skb_queue_purge(&skbs);
+ 			goto wait_for_memory;
+ 		}
+ 
+ 		skb_queue_splice_tail(&skbs, &msk->skb_tx_cache);
+ 		if (copy_page_from_iter(dfrag->page, offset, psize,
+ 					&msg->msg_iter) != psize) {
+ 			mptcp_wmem_uncharge(sk, psize + frag_truesize);
+ 			ret = -EFAULT;
+ 			goto out;
+ 		}
+ 
+ 		/* data successfully copied into the write queue */
+ 		copied += psize;
+ 		dfrag->data_len += psize;
+ 		frag_truesize += psize;
+ 		pfrag->offset += frag_truesize;
+ 		WRITE_ONCE(msk->write_seq, msk->write_seq + psize);
+ 		msk->tx_pending_data += psize;
+ 
+ 		/* charge data on mptcp pending queue to the msk socket
+ 		 * Note: we charge such data both to sk and ssk
+ 		 */
+ 		sk_wmem_queued_add(sk, frag_truesize);
+ 		if (!dfrag_collapsed) {
+ 			get_page(dfrag->page);
+ 			list_add_tail(&dfrag->list, &msk->rtx_queue);
+ 			if (!msk->first_pending)
+ 				WRITE_ONCE(msk->first_pending, dfrag);
+ 		}
+ 		pr_debug("msk=%p dfrag at seq=%lld len=%d sent=%d new=%d", msk,
+ 			 dfrag->data_seq, dfrag->data_len, dfrag->already_sent,
+ 			 !dfrag_collapsed);
+ 
+ 		continue;
+ 
+ wait_for_memory:
+ 		set_bit(MPTCP_NOSPACE, &msk->flags);
+ 		mptcp_push_pending(sk, msg->msg_flags);
++>>>>>>> 13e1603739e5 (mptcp: fix pending data accounting)
  		ret = sk_stream_wait_memory(sk, &timeo);
  		if (ret)
  			goto out;
 +
 +		mptcp_clean_una(sk);
 +
 +		ssk = mptcp_subflow_get_send(msk);
 +		if (list_empty(&msk->conn_list)) {
 +			ret = -ENOTCONN;
 +			goto out;
 +		}
 +	}
 +
++<<<<<<< HEAD
 +	pr_debug("conn_list->subflow=%p", ssk);
 +
 +	lock_sock(ssk);
 +	tx_ok = msg_data_left(msg);
 +	while (tx_ok) {
 +		ret = mptcp_sendmsg_frag(sk, ssk, msg, NULL, &timeo, &mss_now,
 +					 &size_goal);
 +		if (ret < 0) {
 +			if (ret == -EAGAIN && timeo > 0) {
 +				mptcp_set_timeout(sk, ssk);
 +				release_sock(ssk);
 +				goto restart;
 +			}
 +			break;
 +		}
 +
 +		copied += ret;
 +
 +		tx_ok = msg_data_left(msg);
 +		if (!tx_ok)
 +			break;
 +
 +		if (!sk_stream_memory_free(ssk) ||
 +		    !mptcp_ext_cache_refill(msk)) {
 +			tcp_push(ssk, msg->msg_flags, mss_now,
 +				 tcp_sk(ssk)->nonagle, size_goal);
 +			mptcp_set_timeout(sk, ssk);
 +			release_sock(ssk);
 +			goto restart;
 +		}
 +
 +		/* memory is charged to mptcp level socket as well, i.e.
 +		 * if msg is very large, mptcp socket may run out of buffer
 +		 * space.  mptcp_clean_una() will release data that has
 +		 * been acked at mptcp level in the mean time, so there is
 +		 * a good chance we can continue sending data right away.
 +		 *
 +		 * Normally, when the tcp subflow can accept more data, then
 +		 * so can the MPTCP socket.  However, we need to cope with
 +		 * peers that might lag behind in their MPTCP-level
 +		 * acknowledgements, i.e.  data might have been acked at
 +		 * tcp level only.  So, we must also check the MPTCP socket
 +		 * limits before we send more data.
 +		 */
 +		if (unlikely(!sk_stream_memory_free(sk))) {
 +			tcp_push(ssk, msg->msg_flags, mss_now,
 +				 tcp_sk(ssk)->nonagle, size_goal);
 +			mptcp_clean_una(sk);
 +			if (!sk_stream_memory_free(sk)) {
 +				/* can't send more for now, need to wait for
 +				 * MPTCP-level ACKs from peer.
 +				 *
 +				 * Wakeup will happen via mptcp_clean_una().
 +				 */
 +				mptcp_set_timeout(sk, ssk);
 +				release_sock(ssk);
 +				goto restart;
 +			}
 +		}
  	}
  
 +	mptcp_set_timeout(sk, ssk);
 +	if (copied) {
 +		tcp_push(ssk, msg->msg_flags, mss_now, tcp_sk(ssk)->nonagle,
 +			 size_goal);
 +
 +		/* start the timer, if it's not pending */
 +		if (!mptcp_timer_pending(sk))
 +			mptcp_reset_timer(sk);
 +	}
++=======
+ 	if (copied)
+ 		mptcp_push_pending(sk, msg->msg_flags);
++>>>>>>> 13e1603739e5 (mptcp: fix pending data accounting)
  
 +	release_sock(ssk);
  out:
 +	msk->snd_nxt = msk->write_seq;
 +	ssk_check_wmem(msk);
  	release_sock(sk);
  	return copied ? : ret;
  }
* Unmerged path net/mptcp/protocol.c
