blk-mq: add new API of blk_mq_hctx_set_fq_lock_class

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Ming Lei <ming.lei@redhat.com>
commit fb01a2932e81a1fb2273f87ff92dc8172b8880ee
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/fb01a293.failed

flush_end_io() may be called recursively from some driver, such as
nvme-loop, so lockdep may complain 'possible recursive locking'.
Commit b3c6a5997541("block: Fix a lockdep complaint triggered by
request queue flushing") tried to address this issue by assigning
dynamically allocated per-flush-queue lock class. This solution
adds synchronize_rcu() for each hctx's release handler, and causes
horrible SCSI MQ probe delay(more than half an hour on megaraid sas).

Add new API of blk_mq_hctx_set_fq_lock_class() for these drivers, so
we just need to use driver specific lock class for avoiding the
lockdep warning of 'possible recursive locking'.

	Tested-by: Kashyap Desai <kashyap.desai@broadcom.com>
	Reported-by: Qian Cai <cai@redhat.com>
	Cc: Sumit Saxena <sumit.saxena@broadcom.com>
	Cc: John Garry <john.garry@huawei.com>
	Cc: Kashyap Desai <kashyap.desai@broadcom.com>
	Cc: Bart Van Assche <bvanassche@acm.org>
	Cc: Hannes Reinecke <hare@suse.de>
	Signed-off-by: Ming Lei <ming.lei@redhat.com>
	Reviewed-by: Hannes Reinecke <hare@suse.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit fb01a2932e81a1fb2273f87ff92dc8172b8880ee)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/blk-mq.h
diff --cc include/linux/blk-mq.h
index 200eeffcb439,5f639240760e..000000000000
--- a/include/linux/blk-mq.h
+++ b/include/linux/blk-mq.h
@@@ -469,4 -594,8 +470,11 @@@ static inline void blk_mq_cleanup_rq(st
  		rq->q->mq_ops->cleanup_rq(rq);
  }
  
++<<<<<<< HEAD
++=======
+ blk_qc_t blk_mq_submit_bio(struct bio *bio);
+ void blk_mq_hctx_set_fq_lock_class(struct blk_mq_hw_ctx *hctx,
+ 		struct lock_class_key *key);
+ 
++>>>>>>> fb01a2932e81 (blk-mq: add new API of blk_mq_hctx_set_fq_lock_class)
  #endif
diff --git a/block/blk-flush.c b/block/blk-flush.c
index 683374e4d084..4421016682df 100644
--- a/block/blk-flush.c
+++ b/block/blk-flush.c
@@ -498,3 +498,28 @@ void blk_free_flush_queue(struct blk_flush_queue *fq)
 	kfree((void *)fq->flush_rq - sizeof(struct request_aux));
 	kfree(fq);
 }
+
+/*
+ * Allow driver to set its own lock class to fq->mq_flush_lock for
+ * avoiding lockdep complaint.
+ *
+ * flush_end_io() may be called recursively from some driver, such as
+ * nvme-loop, so lockdep may complain 'possible recursive locking' because
+ * all 'struct blk_flush_queue' instance share same mq_flush_lock lock class
+ * key. We need to assign different lock class for these driver's
+ * fq->mq_flush_lock for avoiding the lockdep warning.
+ *
+ * Use dynamically allocated lock class key for each 'blk_flush_queue'
+ * instance is over-kill, and more worse it introduces horrible boot delay
+ * issue because synchronize_rcu() is implied in lockdep_unregister_key which
+ * is called for each hctx release. SCSI probing may synchronously create and
+ * destroy lots of MQ request_queues for non-existent devices, and some robot
+ * test kernel always enable lockdep option. It is observed that more than half
+ * an hour is taken during SCSI MQ probe with per-fq lock class.
+ */
+void blk_mq_hctx_set_fq_lock_class(struct blk_mq_hw_ctx *hctx,
+		struct lock_class_key *key)
+{
+	lockdep_set_class(&hctx->fq->mq_flush_lock, key);
+}
+EXPORT_SYMBOL_GPL(blk_mq_hctx_set_fq_lock_class);
* Unmerged path include/linux/blk-mq.h
