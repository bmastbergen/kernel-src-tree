iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Will Deacon <will@kernel.org>
commit fba6e960772b7b68189168abc3259384b7a44388
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/fba6e960.failed

Now that we have arm-smmu.h defining various SMMU constants, ensure that
they are namespaced with the ARM_SMMU_ prefix in order to avoid conflicts
with the CPU, such as the one we're currently bodging around with the
TCR.

	Cc: Robin Murphy <robin.murphy@arm.com>
	Signed-off-by: Will Deacon <will@kernel.org>
(cherry picked from commit fba6e960772b7b68189168abc3259384b7a44388)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/arm-smmu-impl.c
#	drivers/iommu/arm-smmu.c
#	drivers/iommu/arm-smmu.h
#	drivers/iommu/qcom_iommu.c
diff --cc drivers/iommu/arm-smmu.c
index b4652ac29e56,214be09f6ded..000000000000
--- a/drivers/iommu/arm-smmu.c
+++ b/drivers/iommu/arm-smmu.c
@@@ -452,15 -258,20 +452,20 @@@ static void __arm_smmu_free_bitmap(unsi
  }
  
  /* Wait for any pending TLB invalidations to complete */
 -static void __arm_smmu_tlb_sync(struct arm_smmu_device *smmu, int page,
 -				int sync, int status)
 +static void __arm_smmu_tlb_sync(struct arm_smmu_device *smmu,
 +				void __iomem *sync, void __iomem *status)
  {
  	unsigned int spin_cnt, delay;
 -	u32 reg;
  
 -	if (smmu->impl && unlikely(smmu->impl->tlb_sync))
 -		return smmu->impl->tlb_sync(smmu, page, sync, status);
 -
 -	arm_smmu_writel(smmu, page, sync, QCOM_DUMMY_VAL);
 +	writel_relaxed(QCOM_DUMMY_VAL, sync);
  	for (delay = 1; delay < TLB_LOOP_TIMEOUT; delay *= 2) {
  		for (spin_cnt = TLB_SPIN_COUNT; spin_cnt > 0; spin_cnt--) {
++<<<<<<< HEAD
 +			if (!(readl_relaxed(status) & sTLBGSTATUS_GSACTIVE))
++=======
+ 			reg = arm_smmu_readl(smmu, page, status);
+ 			if (!(reg & ARM_SMMU_sTLBGSTATUS_GSACTIVE))
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  				return;
  			cpu_relax();
  		}
@@@ -653,19 -474,16 +658,24 @@@ static irqreturn_t arm_smmu_context_fau
  	unsigned long iova;
  	struct iommu_domain *domain = dev;
  	struct arm_smmu_domain *smmu_domain = to_smmu_domain(domain);
 +	struct arm_smmu_cfg *cfg = &smmu_domain->cfg;
  	struct arm_smmu_device *smmu = smmu_domain->smmu;
 -	int idx = smmu_domain->cfg.cbndx;
 +	void __iomem *cb_base;
 +
 +	cb_base = ARM_SMMU_CB(smmu, cfg->cbndx);
 +	fsr = readl_relaxed(cb_base + ARM_SMMU_CB_FSR);
  
++<<<<<<< HEAD
 +	if (!(fsr & FSR_FAULT))
++=======
+ 	fsr = arm_smmu_cb_read(smmu, idx, ARM_SMMU_CB_FSR);
+ 	if (!(fsr & ARM_SMMU_FSR_FAULT))
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  		return IRQ_NONE;
  
 -	fsynr = arm_smmu_cb_read(smmu, idx, ARM_SMMU_CB_FSYNR0);
 -	iova = arm_smmu_cb_readq(smmu, idx, ARM_SMMU_CB_FAR);
 -	cbfrsynra = arm_smmu_gr1_read(smmu, ARM_SMMU_GR1_CBFRSYNRA(idx));
 +	fsynr = readl_relaxed(cb_base + ARM_SMMU_CB_FSYNR0);
 +	iova = readq_relaxed(cb_base + ARM_SMMU_CB_FAR);
 +	cbfrsynra = arm_smmu_gr1_read(smmu, ARM_SMMU_GR1_CBFRSYNRA(cfg->cbndx));
  
  	dev_err_ratelimited(smmu->dev,
  	"Unhandled context fault: fsr=0x%x, iova=0x%08lx, fsynr=0x%x, cbfrsynra=0x%x, cb=%d\n",
@@@ -689,13 -508,21 +699,29 @@@ static irqreturn_t arm_smmu_global_faul
  	if (!gfsr)
  		return IRQ_NONE;
  
++<<<<<<< HEAD
 +	dev_err_ratelimited(smmu->dev,
 +		"Unexpected global fault, this could be serious\n");
 +	dev_err_ratelimited(smmu->dev,
 +		"\tGFSR 0x%08x, GFSYNR0 0x%08x, GFSYNR1 0x%08x, GFSYNR2 0x%08x\n",
 +		gfsr, gfsynr0, gfsynr1, gfsynr2);
++=======
+ 	if (__ratelimit(&rs)) {
+ 		if (IS_ENABLED(CONFIG_ARM_SMMU_DISABLE_BYPASS_BY_DEFAULT) &&
+ 		    (gfsr & ARM_SMMU_sGFSR_USF))
+ 			dev_err(smmu->dev,
+ 				"Blocked unknown Stream ID 0x%hx; boot with \"arm-smmu.disable_bypass=0\" to allow, but this may have security implications\n",
+ 				(u16)gfsynr1);
+ 		else
+ 			dev_err(smmu->dev,
+ 				"Unexpected global fault, this could be serious\n");
+ 		dev_err(smmu->dev,
+ 			"\tGFSR 0x%08x, GFSYNR0 0x%08x, GFSYNR1 0x%08x, GFSYNR2 0x%08x\n",
+ 			gfsr, gfsynr0, gfsynr1, gfsynr2);
+ 	}
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  
 -	arm_smmu_gr0_write(smmu, ARM_SMMU_GR0_sGFSR, gfsr);
 +	writel(gfsr, gr0_base + ARM_SMMU_GR0_sGFSR);
  	return IRQ_HANDLED;
  }
  
@@@ -713,11 -540,12 +739,17 @@@ static void arm_smmu_init_context_bank(
  		if (cfg->fmt == ARM_SMMU_CTX_FMT_AARCH32_S) {
  			cb->tcr[0] = pgtbl_cfg->arm_v7s_cfg.tcr;
  		} else {
 -			cb->tcr[0] = arm_smmu_lpae_tcr(pgtbl_cfg);
 -			cb->tcr[1] = arm_smmu_lpae_tcr2(pgtbl_cfg);
 +			cb->tcr[0] = pgtbl_cfg->arm_lpae_s1_cfg.tcr;
 +			cb->tcr[1] = pgtbl_cfg->arm_lpae_s1_cfg.tcr >> 32;
 +			cb->tcr[1] |= FIELD_PREP(TCR2_SEP, TCR2_SEP_UPSTREAM);
  			if (cfg->fmt == ARM_SMMU_CTX_FMT_AARCH64)
++<<<<<<< HEAD
 +				cb->tcr[1] |= TCR2_AS;
++=======
+ 				cb->tcr[1] |= ARM_SMMU_TCR2_AS;
+ 			else
+ 				cb->tcr[0] |= ARM_SMMU_TCR_EAE;
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  		}
  	} else {
  		cb->tcr[0] = pgtbl_cfg->arm_lpae_s2_cfg.vtcr;
@@@ -726,13 -554,14 +758,21 @@@
  	/* TTBRs */
  	if (stage1) {
  		if (cfg->fmt == ARM_SMMU_CTX_FMT_AARCH32_S) {
 -			cb->ttbr[0] = pgtbl_cfg->arm_v7s_cfg.ttbr;
 -			cb->ttbr[1] = 0;
 +			cb->ttbr[0] = pgtbl_cfg->arm_v7s_cfg.ttbr[0];
 +			cb->ttbr[1] = pgtbl_cfg->arm_v7s_cfg.ttbr[1];
  		} else {
++<<<<<<< HEAD
 +			cb->ttbr[0] = pgtbl_cfg->arm_lpae_s1_cfg.ttbr[0];
 +			cb->ttbr[0] |= FIELD_PREP(TTBRn_ASID, cfg->asid);
 +			cb->ttbr[1] = pgtbl_cfg->arm_lpae_s1_cfg.ttbr[1];
 +			cb->ttbr[1] |= FIELD_PREP(TTBRn_ASID, cfg->asid);
++=======
+ 			cb->ttbr[0] = pgtbl_cfg->arm_lpae_s1_cfg.ttbr;
+ 			cb->ttbr[0] |= FIELD_PREP(ARM_SMMU_TTBRn_ASID,
+ 						  cfg->asid);
+ 			cb->ttbr[1] = FIELD_PREP(ARM_SMMU_TTBRn_ASID,
+ 						 cfg->asid);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  		}
  	} else {
  		cb->ttbr[0] = pgtbl_cfg->arm_lpae_s2_cfg.vttbr;
@@@ -826,13 -655,14 +868,14 @@@ static void arm_smmu_write_context_bank
  	}
  
  	/* SCTLR */
- 	reg = SCTLR_CFIE | SCTLR_CFRE | SCTLR_AFE | SCTLR_TRE | SCTLR_M;
+ 	reg = ARM_SMMU_SCTLR_CFIE | ARM_SMMU_SCTLR_CFRE | ARM_SMMU_SCTLR_AFE |
+ 	      ARM_SMMU_SCTLR_TRE | ARM_SMMU_SCTLR_M;
  	if (stage1)
- 		reg |= SCTLR_S1_ASIDPNE;
+ 		reg |= ARM_SMMU_SCTLR_S1_ASIDPNE;
  	if (IS_ENABLED(CONFIG_CPU_BIG_ENDIAN))
- 		reg |= SCTLR_E;
+ 		reg |= ARM_SMMU_SCTLR_E;
  
 -	arm_smmu_cb_write(smmu, idx, ARM_SMMU_CB_SCTLR, reg);
 +	writel_relaxed(reg, cb_base + ARM_SMMU_CB_SCTLR);
  }
  
  static int arm_smmu_init_domain_context(struct iommu_domain *domain,
@@@ -1100,24 -936,25 +1143,44 @@@ static void arm_smmu_domain_free(struc
  static void arm_smmu_write_smr(struct arm_smmu_device *smmu, int idx)
  {
  	struct arm_smmu_smr *smr = smmu->smrs + idx;
++<<<<<<< HEAD
 +	u32 reg = smr->id << SMR_ID_SHIFT | smr->mask << SMR_MASK_SHIFT;
 +
 +	if (!(smmu->features & ARM_SMMU_FEAT_EXIDS) && smr->valid)
 +		reg |= SMR_VALID;
 +	writel_relaxed(reg, ARM_SMMU_GR0(smmu) + ARM_SMMU_GR0_SMR(idx));
++=======
+ 	u32 reg = FIELD_PREP(ARM_SMMU_SMR_ID, smr->id) |
+ 		  FIELD_PREP(ARM_SMMU_SMR_MASK, smr->mask);
+ 
+ 	if (!(smmu->features & ARM_SMMU_FEAT_EXIDS) && smr->valid)
+ 		reg |= ARM_SMMU_SMR_VALID;
+ 	arm_smmu_gr0_write(smmu, ARM_SMMU_GR0_SMR(idx), reg);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  }
  
  static void arm_smmu_write_s2cr(struct arm_smmu_device *smmu, int idx)
  {
  	struct arm_smmu_s2cr *s2cr = smmu->s2crs + idx;
++<<<<<<< HEAD
 +	u32 reg = (s2cr->type & S2CR_TYPE_MASK) << S2CR_TYPE_SHIFT |
 +		  (s2cr->cbndx & S2CR_CBNDX_MASK) << S2CR_CBNDX_SHIFT |
 +		  (s2cr->privcfg & S2CR_PRIVCFG_MASK) << S2CR_PRIVCFG_SHIFT;
 +
 +	if (smmu->features & ARM_SMMU_FEAT_EXIDS && smmu->smrs &&
 +	    smmu->smrs[idx].valid)
 +		reg |= S2CR_EXIDVALID;
 +	writel_relaxed(reg, ARM_SMMU_GR0(smmu) + ARM_SMMU_GR0_S2CR(idx));
++=======
+ 	u32 reg = FIELD_PREP(ARM_SMMU_S2CR_TYPE, s2cr->type) |
+ 		  FIELD_PREP(ARM_SMMU_S2CR_CBNDX, s2cr->cbndx) |
+ 		  FIELD_PREP(ARM_SMMU_S2CR_PRIVCFG, s2cr->privcfg);
+ 
+ 	if (smmu->features & ARM_SMMU_FEAT_EXIDS && smmu->smrs &&
+ 	    smmu->smrs[idx].valid)
+ 		reg |= ARM_SMMU_S2CR_EXIDVALID;
+ 	arm_smmu_gr0_write(smmu, ARM_SMMU_GR0_S2CR(idx), reg);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  }
  
  static void arm_smmu_write_sme(struct arm_smmu_device *smmu, int idx)
@@@ -1144,15 -980,15 +1207,27 @@@ static void arm_smmu_test_smr_masks(str
  	 * bits are set, so check each one separately. We can reject
  	 * masters later if they try to claim IDs outside these masks.
  	 */
++<<<<<<< HEAD
 +	smr = smmu->streamid_mask << SMR_ID_SHIFT;
 +	writel_relaxed(smr, gr0_base + ARM_SMMU_GR0_SMR(0));
 +	smr = readl_relaxed(gr0_base + ARM_SMMU_GR0_SMR(0));
 +	smmu->streamid_mask = smr >> SMR_ID_SHIFT;
 +
 +	smr = smmu->streamid_mask << SMR_MASK_SHIFT;
 +	writel_relaxed(smr, gr0_base + ARM_SMMU_GR0_SMR(0));
 +	smr = readl_relaxed(gr0_base + ARM_SMMU_GR0_SMR(0));
 +	smmu->smr_mask_mask = smr >> SMR_MASK_SHIFT;
++=======
+ 	smr = FIELD_PREP(ARM_SMMU_SMR_ID, smmu->streamid_mask);
+ 	arm_smmu_gr0_write(smmu, ARM_SMMU_GR0_SMR(0), smr);
+ 	smr = arm_smmu_gr0_read(smmu, ARM_SMMU_GR0_SMR(0));
+ 	smmu->streamid_mask = FIELD_GET(ARM_SMMU_SMR_ID, smr);
+ 
+ 	smr = FIELD_PREP(ARM_SMMU_SMR_MASK, smmu->streamid_mask);
+ 	arm_smmu_gr0_write(smmu, ARM_SMMU_GR0_SMR(0), smr);
+ 	smr = arm_smmu_gr0_read(smmu, ARM_SMMU_GR0_SMR(0));
+ 	smmu->smr_mask_mask = FIELD_GET(ARM_SMMU_SMR_MASK, smr);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  }
  
  static int arm_smmu_find_sme(struct arm_smmu_device *smmu, u16 id, u16 mask)
@@@ -1219,9 -1056,9 +1294,15 @@@ static int arm_smmu_master_alloc_smes(s
  
  	mutex_lock(&smmu->stream_map_mutex);
  	/* Figure out a viable stream map entry allocation */
++<<<<<<< HEAD
 +	for_each_cfg_sme(cfg, fwspec, i, idx) {
 +		u16 sid = fwspec->ids[i];
 +		u16 mask = fwspec->ids[i] >> SMR_MASK_SHIFT;
++=======
+ 	for_each_cfg_sme(fwspec, i, idx) {
+ 		u16 sid = FIELD_GET(ARM_SMMU_SMR_ID, fwspec->ids[i]);
+ 		u16 mask = FIELD_GET(ARM_SMMU_SMR_MASK, fwspec->ids[i]);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  
  		if (idx != INVALID_SMENDX) {
  			ret = -EEXIST;
@@@ -1446,18 -1294,16 +1527,24 @@@ static phys_addr_t arm_smmu_iova_to_phy
  	if (ret < 0)
  		return 0;
  
 +	cb_base = ARM_SMMU_CB(smmu, cfg->cbndx);
 +
++<<<<<<< HEAD
  	spin_lock_irqsave(&smmu_domain->cb_lock, flags);
 +	/* ATS1 registers can only be written atomically */
  	va = iova & ~0xfffUL;
 -	if (cfg->fmt == ARM_SMMU_CTX_FMT_AARCH64)
 -		arm_smmu_cb_writeq(smmu, idx, ARM_SMMU_CB_ATS1PR, va);
 -	else
 -		arm_smmu_cb_write(smmu, idx, ARM_SMMU_CB_ATS1PR, va);
 -
 +	if (smmu->version == ARM_SMMU_V2)
 +		smmu_write_atomic_lq(va, cb_base + ARM_SMMU_CB_ATS1PR);
 +	else /* Register is only 32-bit in v1 */
 +		writel_relaxed(va, cb_base + ARM_SMMU_CB_ATS1PR);
 +
 +	if (readl_poll_timeout_atomic(cb_base + ARM_SMMU_CB_ATSR, tmp,
 +				      !(tmp & ATSR_ACTIVE), 5, 50)) {
++=======
+ 	reg = arm_smmu_page(smmu, ARM_SMMU_CB(smmu, idx)) + ARM_SMMU_CB_ATSR;
+ 	if (readl_poll_timeout_atomic(reg, tmp, !(tmp & ARM_SMMU_ATSR_ACTIVE),
+ 				      5, 50)) {
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  		spin_unlock_irqrestore(&smmu_domain->cb_lock, flags);
  		dev_err(dev,
  			"iova to phys timed out on %pad. Falling back to software table walk.\n",
@@@ -1465,9 -1311,9 +1552,9 @@@
  		return ops->iova_to_phys(ops, iova);
  	}
  
 -	phys = arm_smmu_cb_readq(smmu, idx, ARM_SMMU_CB_PAR);
 +	phys = readq_relaxed(cb_base + ARM_SMMU_CB_PAR);
  	spin_unlock_irqrestore(&smmu_domain->cb_lock, flags);
- 	if (phys & CB_PAR_F) {
+ 	if (phys & ARM_SMMU_CB_PAR_F) {
  		dev_err(dev, "translation fault!\n");
  		dev_err(dev, "PAR = 0x%llx\n", phys);
  		return 0;
@@@ -1553,8 -1394,8 +1640,13 @@@ static struct iommu_device *arm_smmu_pr
  
  	ret = -EINVAL;
  	for (i = 0; i < fwspec->num_ids; i++) {
++<<<<<<< HEAD
 +		u16 sid = fwspec->ids[i];
 +		u16 mask = fwspec->ids[i] >> SMR_MASK_SHIFT;
++=======
+ 		u16 sid = FIELD_GET(ARM_SMMU_SMR_ID, fwspec->ids[i]);
+ 		u16 mask = FIELD_GET(ARM_SMMU_SMR_MASK, fwspec->ids[i]);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  
  		if (sid & ~smmu->streamid_mask) {
  			dev_err(dev, "stream ID 0x%x out of range for SMMU (0x%x)\n",
@@@ -1736,12 -1576,12 +1828,21 @@@ static int arm_smmu_of_xlate(struct dev
  	u32 mask, fwid = 0;
  
  	if (args->args_count > 0)
++<<<<<<< HEAD
 +		fwid |= (u16)args->args[0];
 +
 +	if (args->args_count > 1)
 +		fwid |= (u16)args->args[1] << SMR_MASK_SHIFT;
 +	else if (!of_property_read_u32(args->np, "stream-match-mask", &mask))
 +		fwid |= (u16)mask << SMR_MASK_SHIFT;
++=======
+ 		fwid |= FIELD_PREP(ARM_SMMU_SMR_ID, args->args[0]);
+ 
+ 	if (args->args_count > 1)
+ 		fwid |= FIELD_PREP(ARM_SMMU_SMR_MASK, args->args[1]);
+ 	else if (!of_property_read_u32(args->np, "stream-match-mask", &mask))
+ 		fwid |= FIELD_PREP(ARM_SMMU_SMR_MASK, mask);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  
  	return iommu_fwspec_add_ids(dev, &fwid, 1);
  }
@@@ -1800,76 -1648,50 +1901,85 @@@ static void arm_smmu_device_reset(struc
  	for (i = 0; i < smmu->num_mapping_groups; ++i)
  		arm_smmu_write_sme(smmu, i);
  
 +	if (smmu->model == ARM_MMU500) {
 +		/*
 +		 * Before clearing ARM_MMU500_ACTLR_CPRE, need to
 +		 * clear CACHE_LOCK bit of ACR first. And, CACHE_LOCK
 +		 * bit is only present in MMU-500r2 onwards.
 +		 */
 +		reg = readl_relaxed(gr0_base + ARM_SMMU_GR0_ID7);
 +		major = (reg >> ID7_MAJOR_SHIFT) & ID7_MAJOR_MASK;
 +		reg = readl_relaxed(gr0_base + ARM_SMMU_GR0_sACR);
 +		if (major >= 2)
 +			reg &= ~ARM_MMU500_ACR_CACHE_LOCK;
 +		/*
 +		 * Allow unmatched Stream IDs to allocate bypass
 +		 * TLB entries for reduced latency.
 +		 */
 +		reg |= ARM_MMU500_ACR_SMTNMB_TLBEN | ARM_MMU500_ACR_S2CRB_TLBEN;
 +		writel_relaxed(reg, gr0_base + ARM_SMMU_GR0_sACR);
 +	}
 +
  	/* Make sure all context banks are disabled and clear CB_FSR  */
  	for (i = 0; i < smmu->num_context_banks; ++i) {
 +		void __iomem *cb_base = ARM_SMMU_CB(smmu, i);
 +
  		arm_smmu_write_context_bank(smmu, i);
++<<<<<<< HEAD
 +		writel_relaxed(FSR_FAULT, cb_base + ARM_SMMU_CB_FSR);
 +		/*
 +		 * Disable MMU-500's not-particularly-beneficial next-page
 +		 * prefetcher for the sake of errata #841119 and #826419.
 +		 */
 +		if (smmu->model == ARM_MMU500) {
 +			reg = readl_relaxed(cb_base + ARM_SMMU_CB_ACTLR);
 +			reg &= ~ARM_MMU500_ACTLR_CPRE;
 +			writel_relaxed(reg, cb_base + ARM_SMMU_CB_ACTLR);
 +		}
++=======
+ 		arm_smmu_cb_write(smmu, i, ARM_SMMU_CB_FSR, ARM_SMMU_FSR_FAULT);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  	}
  
  	/* Invalidate the TLB, just in case */
 -	arm_smmu_gr0_write(smmu, ARM_SMMU_GR0_TLBIALLH, QCOM_DUMMY_VAL);
 -	arm_smmu_gr0_write(smmu, ARM_SMMU_GR0_TLBIALLNSNH, QCOM_DUMMY_VAL);
 +	writel_relaxed(QCOM_DUMMY_VAL, gr0_base + ARM_SMMU_GR0_TLBIALLH);
 +	writel_relaxed(QCOM_DUMMY_VAL, gr0_base + ARM_SMMU_GR0_TLBIALLNSNH);
  
 -	reg = arm_smmu_gr0_read(smmu, ARM_SMMU_GR0_sCR0);
 +	reg = readl_relaxed(ARM_SMMU_GR0_NS(smmu) + ARM_SMMU_GR0_sCR0);
  
  	/* Enable fault reporting */
- 	reg |= (sCR0_GFRE | sCR0_GFIE | sCR0_GCFGFRE | sCR0_GCFGFIE);
+ 	reg |= (ARM_SMMU_sCR0_GFRE | ARM_SMMU_sCR0_GFIE |
+ 		ARM_SMMU_sCR0_GCFGFRE | ARM_SMMU_sCR0_GCFGFIE);
  
  	/* Disable TLB broadcasting. */
- 	reg |= (sCR0_VMIDPNE | sCR0_PTM);
+ 	reg |= (ARM_SMMU_sCR0_VMIDPNE | ARM_SMMU_sCR0_PTM);
  
  	/* Enable client access, handling unmatched streams as appropriate */
- 	reg &= ~sCR0_CLIENTPD;
+ 	reg &= ~ARM_SMMU_sCR0_CLIENTPD;
  	if (disable_bypass)
- 		reg |= sCR0_USFCFG;
+ 		reg |= ARM_SMMU_sCR0_USFCFG;
  	else
- 		reg &= ~sCR0_USFCFG;
+ 		reg &= ~ARM_SMMU_sCR0_USFCFG;
  
  	/* Disable forced broadcasting */
- 	reg &= ~sCR0_FB;
+ 	reg &= ~ARM_SMMU_sCR0_FB;
  
  	/* Don't upgrade barriers */
++<<<<<<< HEAD
 +	reg &= ~(sCR0_BSU_MASK << sCR0_BSU_SHIFT);
++=======
+ 	reg &= ~(ARM_SMMU_sCR0_BSU);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  
  	if (smmu->features & ARM_SMMU_FEAT_VMID16)
- 		reg |= sCR0_VMID16EN;
+ 		reg |= ARM_SMMU_sCR0_VMID16EN;
  
  	if (smmu->features & ARM_SMMU_FEAT_EXIDS)
- 		reg |= sCR0_EXIDENABLE;
+ 		reg |= ARM_SMMU_sCR0_EXIDENABLE;
  
 -	if (smmu->impl && smmu->impl->reset)
 -		smmu->impl->reset(smmu);
 -
  	/* Push the button */
  	arm_smmu_tlb_sync_global(smmu);
 -	arm_smmu_gr0_write(smmu, ARM_SMMU_GR0_sCR0, reg);
 +	writel(reg, ARM_SMMU_GR0_NS(smmu) + ARM_SMMU_GR0_sCR0);
  }
  
  static int arm_smmu_id_size_to_bits(int size)
@@@ -1958,12 -1779,12 +2068,20 @@@ static int arm_smmu_device_cfg_probe(st
  		smmu->features |= ARM_SMMU_FEAT_EXIDS;
  		size = 1 << 16;
  	} else {
++<<<<<<< HEAD
 +		size = 1 << ((id >> ID0_NUMSIDB_SHIFT) & ID0_NUMSIDB_MASK);
++=======
+ 		size = 1 << FIELD_GET(ARM_SMMU_ID0_NUMSIDB, id);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  	}
  	smmu->streamid_mask = size - 1;
- 	if (id & ID0_SMS) {
+ 	if (id & ARM_SMMU_ID0_SMS) {
  		smmu->features |= ARM_SMMU_FEAT_STREAM_MATCH;
++<<<<<<< HEAD
 +		size = (id >> ID0_NUMSMRG_SHIFT) & ID0_NUMSMRG_MASK;
++=======
+ 		size = FIELD_GET(ARM_SMMU_ID0_NUMSMRG, id);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  		if (size == 0) {
  			dev_err(smmu->dev,
  				"stream-matching supported, but no SMRs present!\n");
@@@ -1998,19 -1820,20 +2117,33 @@@
  	}
  
  	/* ID1 */
++<<<<<<< HEAD
 +	id = readl_relaxed(gr0_base + ARM_SMMU_GR0_ID1);
 +	smmu->pgshift = (id & ID1_PAGESIZE) ? 16 : 12;
 +
 +	/* Check for size mismatch of SMMU address space from mapped region */
 +	size = 1 << (((id >> ID1_NUMPAGENDXB_SHIFT) & ID1_NUMPAGENDXB_MASK) + 1);
 +	size <<= smmu->pgshift;
 +	if (smmu->cb_base != gr0_base + size)
++=======
+ 	id = arm_smmu_gr0_read(smmu, ARM_SMMU_GR0_ID1);
+ 	smmu->pgshift = (id & ARM_SMMU_ID1_PAGESIZE) ? 16 : 12;
+ 
+ 	/* Check for size mismatch of SMMU address space from mapped region */
+ 	size = 1 << (FIELD_GET(ARM_SMMU_ID1_NUMPAGENDXB, id) + 1);
+ 	if (smmu->numpage != 2 * size << smmu->pgshift)
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  		dev_warn(smmu->dev,
 -			"SMMU address space size (0x%x) differs from mapped region size (0x%x)!\n",
 -			2 * size << smmu->pgshift, smmu->numpage);
 -	/* Now properly encode NUMPAGE to subsequently derive SMMU_CB_BASE */
 -	smmu->numpage = size;
 +			"SMMU address space size (0x%lx) differs from mapped region size (0x%tx)!\n",
 +			size * 2, (smmu->cb_base - gr0_base) * 2);
  
++<<<<<<< HEAD
 +	smmu->num_s2_context_banks = (id >> ID1_NUMS2CB_SHIFT) & ID1_NUMS2CB_MASK;
 +	smmu->num_context_banks = (id >> ID1_NUMCB_SHIFT) & ID1_NUMCB_MASK;
++=======
+ 	smmu->num_s2_context_banks = FIELD_GET(ARM_SMMU_ID1_NUMS2CB, id);
+ 	smmu->num_context_banks = FIELD_GET(ARM_SMMU_ID1_NUMCB, id);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  	if (smmu->num_s2_context_banks > smmu->num_context_banks) {
  		dev_err(smmu->dev, "impossible number of S2 context banks!\n");
  		return -ENODEV;
@@@ -2035,15 -1846,15 +2168,24 @@@
  		return -ENOMEM;
  
  	/* ID2 */
++<<<<<<< HEAD
 +	id = readl_relaxed(gr0_base + ARM_SMMU_GR0_ID2);
 +	size = arm_smmu_id_size_to_bits((id >> ID2_IAS_SHIFT) & ID2_IAS_MASK);
 +	smmu->ipa_size = size;
 +
 +	/* The output mask is also applied for bypass */
 +	size = arm_smmu_id_size_to_bits((id >> ID2_OAS_SHIFT) & ID2_OAS_MASK);
++=======
+ 	id = arm_smmu_gr0_read(smmu, ARM_SMMU_GR0_ID2);
+ 	size = arm_smmu_id_size_to_bits(FIELD_GET(ARM_SMMU_ID2_IAS, id));
+ 	smmu->ipa_size = size;
+ 
+ 	/* The output mask is also applied for bypass */
+ 	size = arm_smmu_id_size_to_bits(FIELD_GET(ARM_SMMU_ID2_OAS, id));
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  	smmu->pa_size = size;
  
- 	if (id & ID2_VMID16)
+ 	if (id & ARM_SMMU_ID2_VMID16)
  		smmu->features |= ARM_SMMU_FEAT_VMID16;
  
  	/*
@@@ -2060,13 -1871,13 +2202,17 @@@
  		if (smmu->version == ARM_SMMU_V1_64K)
  			smmu->features |= ARM_SMMU_FEAT_FMT_AARCH64_64K;
  	} else {
++<<<<<<< HEAD
 +		size = (id >> ID2_UBS_SHIFT) & ID2_UBS_MASK;
++=======
+ 		size = FIELD_GET(ARM_SMMU_ID2_UBS, id);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  		smmu->va_size = arm_smmu_id_size_to_bits(size);
- 		if (id & ID2_PTFS_4K)
+ 		if (id & ARM_SMMU_ID2_PTFS_4K)
  			smmu->features |= ARM_SMMU_FEAT_FMT_AARCH64_4K;
- 		if (id & ID2_PTFS_16K)
+ 		if (id & ARM_SMMU_ID2_PTFS_16K)
  			smmu->features |= ARM_SMMU_FEAT_FMT_AARCH64_16K;
- 		if (id & ID2_PTFS_64K)
+ 		if (id & ARM_SMMU_ID2_PTFS_64K)
  			smmu->features |= ARM_SMMU_FEAT_FMT_AARCH64_64K;
  	}
  
@@@ -2416,9 -2248,13 +2562,13 @@@ static void arm_smmu_device_shutdown(st
  	if (!bitmap_empty(smmu->context_map, ARM_SMMU_MAX_CBS))
  		dev_err(&pdev->dev, "removing device with active domains!\n");
  
 -	arm_smmu_bus_init(NULL);
 -	iommu_device_unregister(&smmu->iommu);
 -	iommu_device_sysfs_remove(&smmu->iommu);
 -
  	arm_smmu_rpm_get(smmu);
  	/* Turn the thing off */
++<<<<<<< HEAD
 +	writel(sCR0_CLIENTPD, ARM_SMMU_GR0_NS(smmu) + ARM_SMMU_GR0_sCR0);
++=======
+ 	arm_smmu_gr0_write(smmu, ARM_SMMU_GR0_sCR0, ARM_SMMU_sCR0_CLIENTPD);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  	arm_smmu_rpm_put(smmu);
  
  	if (pm_runtime_enabled(smmu->dev))
diff --cc drivers/iommu/arm-smmu.h
index 671b3a337fea,6501f38a5966..000000000000
--- a/drivers/iommu/arm-smmu.h
+++ b/drivers/iommu/arm-smmu.h
@@@ -22,35 -10,78 +22,90 @@@
  #ifndef _ARM_SMMU_H
  #define _ARM_SMMU_H
  
 -#include <linux/atomic.h>
 -#include <linux/bitfield.h>
 -#include <linux/bits.h>
 -#include <linux/clk.h>
 -#include <linux/device.h>
 -#include <linux/io-64-nonatomic-hi-lo.h>
 -#include <linux/io-pgtable.h>
 -#include <linux/iommu.h>
 -#include <linux/mutex.h>
 -#include <linux/spinlock.h>
 -#include <linux/types.h>
 -
  /* Configuration registers */
  #define ARM_SMMU_GR0_sCR0		0x0
++<<<<<<< HEAD
 +#define sCR0_CLIENTPD			(1 << 0)
 +#define sCR0_GFRE			(1 << 1)
 +#define sCR0_GFIE			(1 << 2)
 +#define sCR0_EXIDENABLE			(1 << 3)
 +#define sCR0_GCFGFRE			(1 << 4)
 +#define sCR0_GCFGFIE			(1 << 5)
 +#define sCR0_USFCFG			(1 << 10)
 +#define sCR0_VMIDPNE			(1 << 11)
 +#define sCR0_PTM			(1 << 12)
 +#define sCR0_FB				(1 << 13)
 +#define sCR0_VMID16EN			(1 << 31)
 +#define sCR0_BSU_SHIFT			14
 +#define sCR0_BSU_MASK			0x3
++=======
+ #define ARM_SMMU_sCR0_VMID16EN		BIT(31)
+ #define ARM_SMMU_sCR0_BSU		GENMASK(15, 14)
+ #define ARM_SMMU_sCR0_FB		BIT(13)
+ #define ARM_SMMU_sCR0_PTM		BIT(12)
+ #define ARM_SMMU_sCR0_VMIDPNE		BIT(11)
+ #define ARM_SMMU_sCR0_USFCFG		BIT(10)
+ #define ARM_SMMU_sCR0_GCFGFIE		BIT(5)
+ #define ARM_SMMU_sCR0_GCFGFRE		BIT(4)
+ #define ARM_SMMU_sCR0_EXIDENABLE	BIT(3)
+ #define ARM_SMMU_sCR0_GFIE		BIT(2)
+ #define ARM_SMMU_sCR0_GFRE		BIT(1)
+ #define ARM_SMMU_sCR0_CLIENTPD		BIT(0)
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  
  /* Auxiliary Configuration register */
  #define ARM_SMMU_GR0_sACR		0x10
  
  /* Identification registers */
  #define ARM_SMMU_GR0_ID0		0x20
++<<<<<<< HEAD
 +#define ARM_SMMU_GR0_ID1		0x24
 +#define ARM_SMMU_GR0_ID2		0x28
++=======
+ #define ARM_SMMU_ID0_S1TS		BIT(30)
+ #define ARM_SMMU_ID0_S2TS		BIT(29)
+ #define ARM_SMMU_ID0_NTS		BIT(28)
+ #define ARM_SMMU_ID0_SMS		BIT(27)
+ #define ARM_SMMU_ID0_ATOSNS		BIT(26)
+ #define ARM_SMMU_ID0_PTFS_NO_AARCH32	BIT(25)
+ #define ARM_SMMU_ID0_PTFS_NO_AARCH32S	BIT(24)
+ #define ARM_SMMU_ID0_NUMIRPT		GENMASK(23, 16)
+ #define ARM_SMMU_ID0_CTTW		BIT(14)
+ #define ARM_SMMU_ID0_NUMSIDB		GENMASK(12, 9)
+ #define ARM_SMMU_ID0_EXIDS		BIT(8)
+ #define ARM_SMMU_ID0_NUMSMRG		GENMASK(7, 0)
+ 
+ #define ARM_SMMU_GR0_ID1		0x24
+ #define ARM_SMMU_ID1_PAGESIZE		BIT(31)
+ #define ARM_SMMU_ID1_NUMPAGENDXB	GENMASK(30, 28)
+ #define ARM_SMMU_ID1_NUMS2CB		GENMASK(23, 16)
+ #define ARM_SMMU_ID1_NUMCB		GENMASK(7, 0)
+ 
+ #define ARM_SMMU_GR0_ID2		0x28
+ #define ARM_SMMU_ID2_VMID16		BIT(15)
+ #define ARM_SMMU_ID2_PTFS_64K		BIT(14)
+ #define ARM_SMMU_ID2_PTFS_16K		BIT(13)
+ #define ARM_SMMU_ID2_PTFS_4K		BIT(12)
+ #define ARM_SMMU_ID2_UBS		GENMASK(11, 8)
+ #define ARM_SMMU_ID2_OAS		GENMASK(7, 4)
+ #define ARM_SMMU_ID2_IAS		GENMASK(3, 0)
+ 
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  #define ARM_SMMU_GR0_ID3		0x2c
  #define ARM_SMMU_GR0_ID4		0x30
  #define ARM_SMMU_GR0_ID5		0x34
  #define ARM_SMMU_GR0_ID6		0x38
 -
  #define ARM_SMMU_GR0_ID7		0x3c
++<<<<<<< HEAD
 +#define ARM_SMMU_GR0_sGFSR		0x48
++=======
+ #define ARM_SMMU_ID7_MAJOR		GENMASK(7, 4)
+ #define ARM_SMMU_ID7_MINOR		GENMASK(3, 0)
+ 
+ #define ARM_SMMU_GR0_sGFSR		0x48
+ #define ARM_SMMU_sGFSR_USF		BIT(1)
+ 
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  #define ARM_SMMU_GR0_sGFSYNR0		0x50
  #define ARM_SMMU_GR0_sGFSYNR1		0x54
  #define ARM_SMMU_GR0_sGFSYNR2		0x58
@@@ -98,35 -91,32 +153,59 @@@
  #define ARM_SMMU_GR0_TLBIALLNSNH	0x68
  #define ARM_SMMU_GR0_TLBIALLH		0x6c
  #define ARM_SMMU_GR0_sTLBGSYNC		0x70
 -
  #define ARM_SMMU_GR0_sTLBGSTATUS	0x74
++<<<<<<< HEAD
 +#define sTLBGSTATUS_GSACTIVE		(1 << 0)
 +
 +/* Stream mapping registers */
 +#define ARM_SMMU_GR0_SMR(n)		(0x800 + ((n) << 2))
 +#define SMR_VALID			(1 << 31)
 +#define SMR_MASK_SHIFT			16
 +#define SMR_ID_SHIFT			0
 +
 +#define ARM_SMMU_GR0_S2CR(n)		(0xc00 + ((n) << 2))
 +#define S2CR_CBNDX_SHIFT		0
 +#define S2CR_CBNDX_MASK			0xff
 +#define S2CR_EXIDVALID			(1 << 10)
 +#define S2CR_TYPE_SHIFT			16
 +#define S2CR_TYPE_MASK			0x3
 +enum arm_smmu_s2cr_type {
 +	S2CR_TYPE_TRANS,
 +	S2CR_TYPE_BYPASS,
 +	S2CR_TYPE_FAULT,
 +};
 +
 +#define S2CR_PRIVCFG_SHIFT		24
 +#define S2CR_PRIVCFG_MASK		0x3
++=======
+ #define ARM_SMMU_sTLBGSTATUS_GSACTIVE	BIT(0)
+ 
+ /* Stream mapping registers */
+ #define ARM_SMMU_GR0_SMR(n)		(0x800 + ((n) << 2))
+ #define ARM_SMMU_SMR_VALID		BIT(31)
+ #define ARM_SMMU_SMR_MASK		GENMASK(31, 16)
+ #define ARM_SMMU_SMR_ID			GENMASK(15, 0)
+ 
+ #define ARM_SMMU_GR0_S2CR(n)		(0xc00 + ((n) << 2))
+ #define ARM_SMMU_S2CR_PRIVCFG		GENMASK(25, 24)
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  enum arm_smmu_s2cr_privcfg {
  	S2CR_PRIVCFG_DEFAULT,
  	S2CR_PRIVCFG_DIPAN,
  	S2CR_PRIVCFG_UNPRIV,
  	S2CR_PRIVCFG_PRIV,
  };
++<<<<<<< HEAD
++=======
+ #define ARM_SMMU_S2CR_TYPE		GENMASK(17, 16)
+ enum arm_smmu_s2cr_type {
+ 	S2CR_TYPE_TRANS,
+ 	S2CR_TYPE_BYPASS,
+ 	S2CR_TYPE_FAULT,
+ };
+ #define ARM_SMMU_S2CR_EXIDVALID		BIT(10)
+ #define ARM_SMMU_S2CR_CBNDX		GENMASK(7, 0)
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  
  /* Context bank attribute registers */
  #define ARM_SMMU_GR1_CBAR(n)		(0x0 + ((n) << 2))
@@@ -163,18 -153,27 +242,39 @@@ enum arm_smmu_cbar_type 
  #define ARM_SMMU_CB_ACTLR		0x4
  
  #define ARM_SMMU_CB_RESUME		0x8
- #define RESUME_TERMINATE		BIT(0)
+ #define ARM_SMMU_RESUME_TERMINATE	BIT(0)
  
  #define ARM_SMMU_CB_TCR2		0x10
++<<<<<<< HEAD
 +#define TCR2_SEP			GENMASK(17, 15)
 +#define TCR2_SEP_UPSTREAM		0x7
 +#define TCR2_AS				BIT(4)
 +
 +#define ARM_SMMU_CB_TTBR0		0x20
 +#define ARM_SMMU_CB_TTBR1		0x28
 +#define TTBRn_ASID			GENMASK_ULL(63, 48)
 +
 +#define ARM_SMMU_CB_TCR			0x30
++=======
+ #define ARM_SMMU_TCR2_SEP		GENMASK(17, 15)
+ #define ARM_SMMU_TCR2_SEP_UPSTREAM	0x7
+ #define ARM_SMMU_TCR2_AS		BIT(4)
+ #define ARM_SMMU_TCR2_PASIZE		GENMASK(3, 0)
+ 
+ #define ARM_SMMU_CB_TTBR0		0x20
+ #define ARM_SMMU_CB_TTBR1		0x28
+ #define ARM_SMMU_TTBRn_ASID		GENMASK_ULL(63, 48)
+ 
+ #define ARM_SMMU_CB_TCR			0x30
+ #define ARM_SMMU_TCR_EAE		BIT(31)
+ #define ARM_SMMU_TCR_EPD1		BIT(23)
+ #define ARM_SMMU_TCR_TG0		GENMASK(15, 14)
+ #define ARM_SMMU_TCR_SH0		GENMASK(13, 12)
+ #define ARM_SMMU_TCR_ORGN0		GENMASK(11, 10)
+ #define ARM_SMMU_TCR_IRGN0		GENMASK(9, 8)
+ #define ARM_SMMU_TCR_T0SZ		GENMASK(5, 0)
+ 
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  #define ARM_SMMU_CB_CONTEXTIDR		0x34
  #define ARM_SMMU_CB_S1_MAIR0		0x38
  #define ARM_SMMU_CB_S1_MAIR1		0x3c
@@@ -214,6 -221,215 +322,218 @@@
  #define ARM_SMMU_CB_ATS1PR		0x800
  
  #define ARM_SMMU_CB_ATSR		0x8f0
- #define ATSR_ACTIVE			BIT(0)
+ #define ARM_SMMU_ATSR_ACTIVE		BIT(0)
+ 
++<<<<<<< HEAD
++=======
+ 
+ /* Maximum number of context banks per SMMU */
+ #define ARM_SMMU_MAX_CBS		128
+ 
+ 
+ /* Shared driver definitions */
+ enum arm_smmu_arch_version {
+ 	ARM_SMMU_V1,
+ 	ARM_SMMU_V1_64K,
+ 	ARM_SMMU_V2,
+ };
+ 
+ enum arm_smmu_implementation {
+ 	GENERIC_SMMU,
+ 	ARM_MMU500,
+ 	CAVIUM_SMMUV2,
+ 	QCOM_SMMUV2,
+ };
+ 
+ struct arm_smmu_device {
+ 	struct device			*dev;
+ 
+ 	void __iomem			*base;
+ 	unsigned int			numpage;
+ 	unsigned int			pgshift;
+ 
+ #define ARM_SMMU_FEAT_COHERENT_WALK	(1 << 0)
+ #define ARM_SMMU_FEAT_STREAM_MATCH	(1 << 1)
+ #define ARM_SMMU_FEAT_TRANS_S1		(1 << 2)
+ #define ARM_SMMU_FEAT_TRANS_S2		(1 << 3)
+ #define ARM_SMMU_FEAT_TRANS_NESTED	(1 << 4)
+ #define ARM_SMMU_FEAT_TRANS_OPS		(1 << 5)
+ #define ARM_SMMU_FEAT_VMID16		(1 << 6)
+ #define ARM_SMMU_FEAT_FMT_AARCH64_4K	(1 << 7)
+ #define ARM_SMMU_FEAT_FMT_AARCH64_16K	(1 << 8)
+ #define ARM_SMMU_FEAT_FMT_AARCH64_64K	(1 << 9)
+ #define ARM_SMMU_FEAT_FMT_AARCH32_L	(1 << 10)
+ #define ARM_SMMU_FEAT_FMT_AARCH32_S	(1 << 11)
+ #define ARM_SMMU_FEAT_EXIDS		(1 << 12)
+ 	u32				features;
+ 
+ 	enum arm_smmu_arch_version	version;
+ 	enum arm_smmu_implementation	model;
+ 	const struct arm_smmu_impl	*impl;
+ 
+ 	u32				num_context_banks;
+ 	u32				num_s2_context_banks;
+ 	DECLARE_BITMAP(context_map, ARM_SMMU_MAX_CBS);
+ 	struct arm_smmu_cb		*cbs;
+ 	atomic_t			irptndx;
+ 
+ 	u32				num_mapping_groups;
+ 	u16				streamid_mask;
+ 	u16				smr_mask_mask;
+ 	struct arm_smmu_smr		*smrs;
+ 	struct arm_smmu_s2cr		*s2crs;
+ 	struct mutex			stream_map_mutex;
+ 
+ 	unsigned long			va_size;
+ 	unsigned long			ipa_size;
+ 	unsigned long			pa_size;
+ 	unsigned long			pgsize_bitmap;
+ 
+ 	u32				num_global_irqs;
+ 	u32				num_context_irqs;
+ 	unsigned int			*irqs;
+ 	struct clk_bulk_data		*clks;
+ 	int				num_clks;
+ 
+ 	spinlock_t			global_sync_lock;
+ 
+ 	/* IOMMU core code handle */
+ 	struct iommu_device		iommu;
+ };
+ 
+ enum arm_smmu_context_fmt {
+ 	ARM_SMMU_CTX_FMT_NONE,
+ 	ARM_SMMU_CTX_FMT_AARCH64,
+ 	ARM_SMMU_CTX_FMT_AARCH32_L,
+ 	ARM_SMMU_CTX_FMT_AARCH32_S,
+ };
+ 
+ struct arm_smmu_cfg {
+ 	u8				cbndx;
+ 	u8				irptndx;
+ 	union {
+ 		u16			asid;
+ 		u16			vmid;
+ 	};
+ 	enum arm_smmu_cbar_type		cbar;
+ 	enum arm_smmu_context_fmt	fmt;
+ };
+ #define ARM_SMMU_INVALID_IRPTNDX	0xff
+ 
+ enum arm_smmu_domain_stage {
+ 	ARM_SMMU_DOMAIN_S1 = 0,
+ 	ARM_SMMU_DOMAIN_S2,
+ 	ARM_SMMU_DOMAIN_NESTED,
+ 	ARM_SMMU_DOMAIN_BYPASS,
+ };
+ 
+ struct arm_smmu_domain {
+ 	struct arm_smmu_device		*smmu;
+ 	struct io_pgtable_ops		*pgtbl_ops;
+ 	const struct iommu_flush_ops	*flush_ops;
+ 	struct arm_smmu_cfg		cfg;
+ 	enum arm_smmu_domain_stage	stage;
+ 	bool				non_strict;
+ 	struct mutex			init_mutex; /* Protects smmu pointer */
+ 	spinlock_t			cb_lock; /* Serialises ATS1* ops and TLB syncs */
+ 	struct iommu_domain		domain;
+ };
+ 
+ static inline u32 arm_smmu_lpae_tcr(struct io_pgtable_cfg *cfg)
+ {
+ 	return ARM_SMMU_TCR_EPD1 |
+ 	       FIELD_PREP(ARM_SMMU_TCR_TG0, cfg->arm_lpae_s1_cfg.tcr.tg) |
+ 	       FIELD_PREP(ARM_SMMU_TCR_SH0, cfg->arm_lpae_s1_cfg.tcr.sh) |
+ 	       FIELD_PREP(ARM_SMMU_TCR_ORGN0, cfg->arm_lpae_s1_cfg.tcr.orgn) |
+ 	       FIELD_PREP(ARM_SMMU_TCR_IRGN0, cfg->arm_lpae_s1_cfg.tcr.irgn) |
+ 	       FIELD_PREP(ARM_SMMU_TCR_T0SZ, cfg->arm_lpae_s1_cfg.tcr.tsz);
+ }
+ 
+ static inline u32 arm_smmu_lpae_tcr2(struct io_pgtable_cfg *cfg)
+ {
+ 	return FIELD_PREP(ARM_SMMU_TCR2_PASIZE, cfg->arm_lpae_s1_cfg.tcr.ips) |
+ 	       FIELD_PREP(ARM_SMMU_TCR2_SEP, ARM_SMMU_TCR2_SEP_UPSTREAM);
+ }
+ 
+ /* Implementation details, yay! */
+ struct arm_smmu_impl {
+ 	u32 (*read_reg)(struct arm_smmu_device *smmu, int page, int offset);
+ 	void (*write_reg)(struct arm_smmu_device *smmu, int page, int offset,
+ 			  u32 val);
+ 	u64 (*read_reg64)(struct arm_smmu_device *smmu, int page, int offset);
+ 	void (*write_reg64)(struct arm_smmu_device *smmu, int page, int offset,
+ 			    u64 val);
+ 	int (*cfg_probe)(struct arm_smmu_device *smmu);
+ 	int (*reset)(struct arm_smmu_device *smmu);
+ 	int (*init_context)(struct arm_smmu_domain *smmu_domain);
+ 	void (*tlb_sync)(struct arm_smmu_device *smmu, int page, int sync,
+ 			 int status);
+ };
+ 
+ static inline void __iomem *arm_smmu_page(struct arm_smmu_device *smmu, int n)
+ {
+ 	return smmu->base + (n << smmu->pgshift);
+ }
+ 
+ static inline u32 arm_smmu_readl(struct arm_smmu_device *smmu, int page, int offset)
+ {
+ 	if (smmu->impl && unlikely(smmu->impl->read_reg))
+ 		return smmu->impl->read_reg(smmu, page, offset);
+ 	return readl_relaxed(arm_smmu_page(smmu, page) + offset);
+ }
+ 
+ static inline void arm_smmu_writel(struct arm_smmu_device *smmu, int page,
+ 				   int offset, u32 val)
+ {
+ 	if (smmu->impl && unlikely(smmu->impl->write_reg))
+ 		smmu->impl->write_reg(smmu, page, offset, val);
+ 	else
+ 		writel_relaxed(val, arm_smmu_page(smmu, page) + offset);
+ }
+ 
+ static inline u64 arm_smmu_readq(struct arm_smmu_device *smmu, int page, int offset)
+ {
+ 	if (smmu->impl && unlikely(smmu->impl->read_reg64))
+ 		return smmu->impl->read_reg64(smmu, page, offset);
+ 	return readq_relaxed(arm_smmu_page(smmu, page) + offset);
+ }
+ 
+ static inline void arm_smmu_writeq(struct arm_smmu_device *smmu, int page,
+ 				   int offset, u64 val)
+ {
+ 	if (smmu->impl && unlikely(smmu->impl->write_reg64))
+ 		smmu->impl->write_reg64(smmu, page, offset, val);
+ 	else
+ 		writeq_relaxed(val, arm_smmu_page(smmu, page) + offset);
+ }
+ 
+ #define ARM_SMMU_GR0		0
+ #define ARM_SMMU_GR1		1
+ #define ARM_SMMU_CB(s, n)	((s)->numpage + (n))
+ 
+ #define arm_smmu_gr0_read(s, o)		\
+ 	arm_smmu_readl((s), ARM_SMMU_GR0, (o))
+ #define arm_smmu_gr0_write(s, o, v)	\
+ 	arm_smmu_writel((s), ARM_SMMU_GR0, (o), (v))
+ 
+ #define arm_smmu_gr1_read(s, o)		\
+ 	arm_smmu_readl((s), ARM_SMMU_GR1, (o))
+ #define arm_smmu_gr1_write(s, o, v)	\
+ 	arm_smmu_writel((s), ARM_SMMU_GR1, (o), (v))
+ 
+ #define arm_smmu_cb_read(s, n, o)	\
+ 	arm_smmu_readl((s), ARM_SMMU_CB((s), (n)), (o))
+ #define arm_smmu_cb_write(s, n, o, v)	\
+ 	arm_smmu_writel((s), ARM_SMMU_CB((s), (n)), (o), (v))
+ #define arm_smmu_cb_readq(s, n, o)	\
+ 	arm_smmu_readq((s), ARM_SMMU_CB((s), (n)), (o))
+ #define arm_smmu_cb_writeq(s, n, o, v)	\
+ 	arm_smmu_writeq((s), ARM_SMMU_CB((s), (n)), (o), (v))
+ 
+ struct arm_smmu_device *arm_smmu_impl_init(struct arm_smmu_device *smmu);
+ struct arm_smmu_device *qcom_smmu_impl_init(struct arm_smmu_device *smmu);
+ 
+ int arm_mmu500_reset(struct arm_smmu_device *smmu);
  
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  #endif /* _ARM_SMMU_H */
diff --cc drivers/iommu/qcom_iommu.c
index 763f16e52d2a,39759db4f003..000000000000
--- a/drivers/iommu/qcom_iommu.c
+++ b/drivers/iommu/qcom_iommu.c
@@@ -280,31 -269,30 +280,43 @@@ static int qcom_iommu_init_domain(struc
  
  		/* TTBRs */
  		iommu_writeq(ctx, ARM_SMMU_CB_TTBR0,
++<<<<<<< HEAD
 +				pgtbl_cfg.arm_lpae_s1_cfg.ttbr[0] |
 +				FIELD_PREP(TTBRn_ASID, ctx->asid));
 +		iommu_writeq(ctx, ARM_SMMU_CB_TTBR1,
 +				pgtbl_cfg.arm_lpae_s1_cfg.ttbr[1] |
 +				FIELD_PREP(TTBRn_ASID, ctx->asid));
++=======
+ 				pgtbl_cfg.arm_lpae_s1_cfg.ttbr |
+ 				FIELD_PREP(ARM_SMMU_TTBRn_ASID, ctx->asid));
+ 		iommu_writeq(ctx, ARM_SMMU_CB_TTBR1, 0);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  
  		/* TCR */
  		iommu_writel(ctx, ARM_SMMU_CB_TCR2,
 -				arm_smmu_lpae_tcr2(&pgtbl_cfg));
 +				(pgtbl_cfg.arm_lpae_s1_cfg.tcr >> 32) |
 +				FIELD_PREP(TCR2_SEP, TCR2_SEP_UPSTREAM));
  		iommu_writel(ctx, ARM_SMMU_CB_TCR,
++<<<<<<< HEAD
 +				pgtbl_cfg.arm_lpae_s1_cfg.tcr);
++=======
+ 			     arm_smmu_lpae_tcr(&pgtbl_cfg) | ARM_SMMU_TCR_EAE);
++>>>>>>> fba6e960772b (iommu/arm-smmu: Rename public #defines under ARM_SMMU_ namespace)
  
  		/* MAIRs (stage-1 only) */
  		iommu_writel(ctx, ARM_SMMU_CB_S1_MAIR0,
 -				pgtbl_cfg.arm_lpae_s1_cfg.mair);
 +				pgtbl_cfg.arm_lpae_s1_cfg.mair[0]);
  		iommu_writel(ctx, ARM_SMMU_CB_S1_MAIR1,
 -				pgtbl_cfg.arm_lpae_s1_cfg.mair >> 32);
 +				pgtbl_cfg.arm_lpae_s1_cfg.mair[1]);
  
  		/* SCTLR */
- 		reg = SCTLR_CFIE | SCTLR_CFRE | SCTLR_AFE | SCTLR_TRE |
- 			SCTLR_M | SCTLR_S1_ASIDPNE | SCTLR_CFCFG;
+ 		reg = ARM_SMMU_SCTLR_CFIE | ARM_SMMU_SCTLR_CFRE |
+ 		      ARM_SMMU_SCTLR_AFE | ARM_SMMU_SCTLR_TRE |
+ 		      ARM_SMMU_SCTLR_M | ARM_SMMU_SCTLR_S1_ASIDPNE |
+ 		      ARM_SMMU_SCTLR_CFCFG;
  
  		if (IS_ENABLED(CONFIG_BIG_ENDIAN))
- 			reg |= SCTLR_E;
+ 			reg |= ARM_SMMU_SCTLR_E;
  
  		iommu_writel(ctx, ARM_SMMU_CB_SCTLR, reg);
  
* Unmerged path drivers/iommu/arm-smmu-impl.c
* Unmerged path drivers/iommu/arm-smmu-impl.c
* Unmerged path drivers/iommu/arm-smmu.c
* Unmerged path drivers/iommu/arm-smmu.h
* Unmerged path drivers/iommu/qcom_iommu.c
