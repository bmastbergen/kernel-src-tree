RDMA/umem: Add a schedule point in ib_umem_get()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Eric Dumazet <edumazet@google.com>
commit 928da37a229f344424ffc89c9a58feb2368bb018
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/928da37a.failed

Mapping as little as 64GB can take more than 10 seconds, triggering issues
on kernels with CONFIG_PREEMPT_NONE=y.

ib_umem_get() already splits the work in 2MB units on x86_64, adding a
cond_resched() in the long-lasting loop is enough to solve the issue.

Note that sg_alloc_table() can still use more than 100 ms, which is also
problematic. This might be addressed later in ib_umem_add_sg_table(),
adding new blocks in sgl on demand.

Link: https://lore.kernel.org/r/20200730015755.1827498-1-edumazet@google.com
	Signed-off-by: Eric Dumazet <edumazet@google.com>
	Signed-off-by: Jason Gunthorpe <jgg@nvidia.com>
(cherry picked from commit 928da37a229f344424ffc89c9a58feb2368bb018)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/umem.c
diff --cc drivers/infiniband/core/umem.c
index 378698f5b8ce,831bff8d52e5..000000000000
--- a/drivers/infiniband/core/umem.c
+++ b/drivers/infiniband/core/umem.c
@@@ -269,7 -261,8 +269,12 @@@ struct ib_umem *ib_umem_get(struct ib_u
  	sg = umem->sg_head.sgl;
  
  	while (npages) {
++<<<<<<< HEAD
 +		ret = get_user_pages_fast(cur_base,
++=======
+ 		cond_resched();
+ 		ret = pin_user_pages_fast(cur_base,
++>>>>>>> 928da37a229f (RDMA/umem: Add a schedule point in ib_umem_get())
  					  min_t(unsigned long, npages,
  						PAGE_SIZE /
  						sizeof(struct page *)),
* Unmerged path drivers/infiniband/core/umem.c
