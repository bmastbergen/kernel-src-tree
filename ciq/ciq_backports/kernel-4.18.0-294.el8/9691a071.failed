mm: use free_area_init() instead of free_area_init_nodes()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Mike Rapoport <rppt@linux.ibm.com>
commit 9691a071aa26a21fc8dac804a2b98d3c24f76f9a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/9691a071.failed

free_area_init() has effectively became a wrapper for
free_area_init_nodes() and there is no point of keeping it.  Still
free_area_init() name is shorter and more general as it does not imply
necessity to initialize multiple nodes.

Rename free_area_init_nodes() to free_area_init(), update the callers and
drop old version of free_area_init().

	Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Tested-by: Hoan Tran <hoan@os.amperecomputing.com>	[arm64]
	Reviewed-by: Baoquan He <bhe@redhat.com>
	Acked-by: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Brian Cain <bcain@codeaurora.org>
	Cc: "David S. Miller" <davem@davemloft.net>
	Cc: Geert Uytterhoeven <geert@linux-m68k.org>
	Cc: Greentime Hu <green.hu@gmail.com>
	Cc: Greg Ungerer <gerg@linux-m68k.org>
	Cc: Guan Xuetao <gxt@pku.edu.cn>
	Cc: Guo Ren <guoren@kernel.org>
	Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
	Cc: Helge Deller <deller@gmx.de>
	Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
	Cc: Jonathan Corbet <corbet@lwn.net>
	Cc: Ley Foon Tan <ley.foon.tan@intel.com>
	Cc: Mark Salter <msalter@redhat.com>
	Cc: Matt Turner <mattst88@gmail.com>
	Cc: Max Filippov <jcmvbkbc@gmail.com>
	Cc: Michael Ellerman <mpe@ellerman.id.au>
	Cc: Michal Hocko <mhocko@kernel.org>
	Cc: Michal Simek <monstr@monstr.eu>
	Cc: Nick Hu <nickhu@andestech.com>
	Cc: Paul Walmsley <paul.walmsley@sifive.com>
	Cc: Richard Weinberger <richard@nod.at>
	Cc: Rich Felker <dalias@libc.org>
	Cc: Russell King <linux@armlinux.org.uk>
	Cc: Stafford Horne <shorne@gmail.com>
	Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
	Cc: Tony Luck <tony.luck@intel.com>
	Cc: Vineet Gupta <vgupta@synopsys.com>
	Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
Link: http://lkml.kernel.org/r/20200412194859.12663-6-rppt@kernel.org
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 9691a071aa26a21fc8dac804a2b98d3c24f76f9a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/ia64/mm/contig.c
#	include/linux/mm.h
#	mm/page_alloc.c
diff --cc arch/ia64/mm/contig.c
index bb0ece211e54,8786fa5c7612..000000000000
--- a/arch/ia64/mm/contig.c
+++ b/arch/ia64/mm/contig.c
@@@ -270,9 -209,7 +270,14 @@@ paging_init (void
  
  		printk("Virtual mem_map starts at 0x%p\n", mem_map);
  	}
++<<<<<<< HEAD
 +#else /* !CONFIG_VIRTUAL_MEM_MAP */
 +	memblock_add_node(0, PFN_PHYS(max_low_pfn), 0);
 +	free_area_init_nodes(max_zone_pfns);
 +#endif /* !CONFIG_VIRTUAL_MEM_MAP */
++=======
+ #endif /* !CONFIG_VIRTUAL_MEM_MAP */
+ 	free_area_init(max_zone_pfns);
++>>>>>>> 9691a071aa26 (mm: use free_area_init() instead of free_area_init_nodes())
  	zero_page_memmap_ptr = virt_to_page(ia64_imva(empty_zero_page));
  }
diff --cc include/linux/mm.h
index c2872a52dcb3,ff2c19e14c1e..000000000000
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@@ -1970,8 -2329,7 +1970,12 @@@ static inline spinlock_t *pud_lock(stru
  }
  
  extern void __init pagecache_init(void);
++<<<<<<< HEAD
 +extern void free_area_init(unsigned long * zones_size);
 +extern void free_area_init_node(int nid, unsigned long * zones_size,
++=======
+ extern void __init free_area_init_node(int nid, unsigned long * zones_size,
++>>>>>>> 9691a071aa26 (mm: use free_area_init() instead of free_area_init_nodes())
  		unsigned long zone_start_pfn, unsigned long *zholes_size);
  extern void free_initmem(void);
  
@@@ -2065,11 -2422,8 +2069,11 @@@ static inline unsigned long get_num_phy
   * registered physical page range.  Similarly
   * sparse_memory_present_with_active_regions() calls memory_present() for
   * each range when SPARSEMEM is enabled.
 + *
 + * See mm/page_alloc.c for more information on each function exposed by
 + * CONFIG_HAVE_MEMBLOCK_NODE_MAP.
   */
- extern void free_area_init_nodes(unsigned long *max_zone_pfn);
+ void free_area_init(unsigned long *max_zone_pfn);
  unsigned long node_map_pfn_alignment(void);
  unsigned long __absent_pages_in_range(int nid, unsigned long start_pfn,
  						unsigned long end_pfn);
diff --cc mm/page_alloc.c
index f9684b405897,644a59d17318..000000000000
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@@ -7434,13 -7712,6 +7434,16 @@@ void __init set_dma_reserve(unsigned lo
  	dma_reserve = new_dma_reserve;
  }
  
++<<<<<<< HEAD
 +void __init free_area_init(unsigned long *zones_size)
 +{
 +	init_unavailable_mem();
 +	free_area_init_node(0, zones_size,
 +			__pa(PAGE_OFFSET) >> PAGE_SHIFT, NULL);
 +}
 +
++=======
++>>>>>>> 9691a071aa26 (mm: use free_area_init() instead of free_area_init_nodes())
  static int page_alloc_cpu_dead(unsigned int cpu)
  {
  
diff --git a/arch/arm64/mm/init.c b/arch/arm64/mm/init.c
index 4311e4a65f34..a600713efb51 100644
--- a/arch/arm64/mm/init.c
+++ b/arch/arm64/mm/init.c
@@ -237,7 +237,7 @@ static void __init zone_sizes_init(unsigned long min, unsigned long max)
 #endif
 	max_zone_pfns[ZONE_NORMAL] = max;
 
-	free_area_init_nodes(max_zone_pfns);
+	free_area_init(max_zone_pfns);
 }
 
 #else
* Unmerged path arch/ia64/mm/contig.c
diff --git a/arch/ia64/mm/discontig.c b/arch/ia64/mm/discontig.c
index a69c83049d5d..a9ae3862f7de 100644
--- a/arch/ia64/mm/discontig.c
+++ b/arch/ia64/mm/discontig.c
@@ -730,7 +730,7 @@ void __init paging_init(void)
 	max_zone_pfns[ZONE_DMA32] = max_dma;
 #endif
 	max_zone_pfns[ZONE_NORMAL] = max_pfn;
-	free_area_init_nodes(max_zone_pfns);
+	free_area_init(max_zone_pfns);
 
 	zero_page_memmap_ptr = virt_to_page(ia64_imva(empty_zero_page));
 }
diff --git a/arch/microblaze/mm/init.c b/arch/microblaze/mm/init.c
index 8c14988f52f2..5a95bd1d1d94 100644
--- a/arch/microblaze/mm/init.c
+++ b/arch/microblaze/mm/init.c
@@ -108,7 +108,7 @@ static void __init paging_init(void)
 #endif
 
 	/* We don't have holes in memory map */
-	free_area_init_nodes(zones_size);
+	free_area_init(zones_size);
 }
 
 void __init setup_memory(void)
diff --git a/arch/mips/loongson64/loongson-3/numa.c b/arch/mips/loongson64/loongson-3/numa.c
index 3000eb1d1bb8..8bd4fa8e29b3 100644
--- a/arch/mips/loongson64/loongson-3/numa.c
+++ b/arch/mips/loongson64/loongson-3/numa.c
@@ -269,7 +269,7 @@ void __init paging_init(void)
 	zones_size[ZONE_DMA32] = MAX_DMA32_PFN;
 #endif
 	zones_size[ZONE_NORMAL] = max_low_pfn;
-	free_area_init_nodes(zones_size);
+	free_area_init(zones_size);
 }
 
 void __init mem_init(void)
diff --git a/arch/mips/mm/init.c b/arch/mips/mm/init.c
index 1e3df5832fd7..aa80574918b0 100644
--- a/arch/mips/mm/init.c
+++ b/arch/mips/mm/init.c
@@ -425,7 +425,7 @@ void __init paging_init(void)
 	}
 #endif
 
-	free_area_init_nodes(max_zone_pfns);
+	free_area_init(max_zone_pfns);
 }
 
 #ifdef CONFIG_64BIT
diff --git a/arch/mips/sgi-ip27/ip27-memory.c b/arch/mips/sgi-ip27/ip27-memory.c
index 8854cdfe1e29..a16c76740aeb 100644
--- a/arch/mips/sgi-ip27/ip27-memory.c
+++ b/arch/mips/sgi-ip27/ip27-memory.c
@@ -471,7 +471,7 @@ void __init paging_init(void)
 			max_low_pfn = end_pfn;
 	}
 	zones_size[ZONE_NORMAL] = max_low_pfn;
-	free_area_init_nodes(zones_size);
+	free_area_init(zones_size);
 }
 
 void __init mem_init(void)
diff --git a/arch/powerpc/mm/mem.c b/arch/powerpc/mm/mem.c
index fa9ce75915ae..f35341969a6e 100644
--- a/arch/powerpc/mm/mem.c
+++ b/arch/powerpc/mm/mem.c
@@ -321,7 +321,7 @@ void __init paging_init(void)
 	max_zone_pfns[ZONE_HIGHMEM] = max_pfn;
 #endif
 
-	free_area_init_nodes(max_zone_pfns);
+	free_area_init(max_zone_pfns);
 
 	mark_nonram_nosave();
 }
diff --git a/arch/riscv/mm/init.c b/arch/riscv/mm/init.c
index 1d9bfaff60bc..18ef92e089f6 100644
--- a/arch/riscv/mm/init.c
+++ b/arch/riscv/mm/init.c
@@ -32,7 +32,7 @@ static void __init zone_sizes_init(void)
 #endif
 	max_zone_pfns[ZONE_NORMAL] = max_low_pfn;
 
-	free_area_init_nodes(max_zone_pfns);
+	free_area_init(max_zone_pfns);
 }
 
 void setup_zero_page(void)
diff --git a/arch/s390/mm/init.c b/arch/s390/mm/init.c
index c73cc156f3ba..616d8fd08a00 100644
--- a/arch/s390/mm/init.c
+++ b/arch/s390/mm/init.c
@@ -123,7 +123,7 @@ void __init paging_init(void)
 	memset(max_zone_pfns, 0, sizeof(max_zone_pfns));
 	max_zone_pfns[ZONE_DMA] = PFN_DOWN(MAX_DMA_ADDRESS);
 	max_zone_pfns[ZONE_NORMAL] = max_low_pfn;
-	free_area_init_nodes(max_zone_pfns);
+	free_area_init(max_zone_pfns);
 }
 
 void mark_rodata_ro(void)
diff --git a/arch/sh/mm/init.c b/arch/sh/mm/init.c
index db47300bc72b..679b3a7710ed 100644
--- a/arch/sh/mm/init.c
+++ b/arch/sh/mm/init.c
@@ -335,7 +335,7 @@ void __init paging_init(void)
 
 	memset(max_zone_pfns, 0, sizeof(max_zone_pfns));
 	max_zone_pfns[ZONE_NORMAL] = max_low_pfn;
-	free_area_init_nodes(max_zone_pfns);
+	free_area_init(max_zone_pfns);
 }
 
 /*
diff --git a/arch/sparc/mm/init_64.c b/arch/sparc/mm/init_64.c
index 971de3a1c532..997d5f50492a 100644
--- a/arch/sparc/mm/init_64.c
+++ b/arch/sparc/mm/init_64.c
@@ -2472,7 +2472,7 @@ void __init paging_init(void)
 
 		max_zone_pfns[ZONE_NORMAL] = end_pfn;
 
-		free_area_init_nodes(max_zone_pfns);
+		free_area_init(max_zone_pfns);
 	}
 
 	printk("Booting Linux...\n");
diff --git a/arch/x86/mm/init.c b/arch/x86/mm/init.c
index ea2eebacf5fa..8572c89afd48 100644
--- a/arch/x86/mm/init.c
+++ b/arch/x86/mm/init.c
@@ -910,7 +910,7 @@ void __init zone_sizes_init(void)
 	max_zone_pfns[ZONE_HIGHMEM]	= max_pfn;
 #endif
 
-	free_area_init_nodes(max_zone_pfns);
+	free_area_init(max_zone_pfns);
 }
 
 __visible DEFINE_PER_CPU_SHARED_ALIGNED(struct tlb_state, cpu_tlbstate) = {
* Unmerged path include/linux/mm.h
* Unmerged path mm/page_alloc.c
