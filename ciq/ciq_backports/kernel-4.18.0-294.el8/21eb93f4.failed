driver core: Call sync_state() even if supplier has no consumers

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Saravana Kannan <saravanak@google.com>
commit 21eb93f432b1a785df193df1a56a59e9eb3a985f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/21eb93f4.failed

The initial patch that added sync_state() support didn't handle the case
where a supplier has no consumers. This was because when a device is
successfully bound with a driver, only its suppliers were checked to see
if they are eligible to get a sync_state(). This is not sufficient for
devices that have no consumers but still need to do device state clean
up. So fix this.

Fixes: fc5a251d0fd7ca90 (driver core: Add sync_state driver/bus callback)
	Signed-off-by: Saravana Kannan <saravanak@google.com>
	Cc: stable <stable@vger.kernel.org>
Link: https://lore.kernel.org/r/20200221080510.197337-2-saravanak@google.com
	Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
(cherry picked from commit 21eb93f432b1a785df193df1a56a59e9eb3a985f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/base/core.c
diff --cc drivers/base/core.c
index 8a0d36852b14,3306d5ae92a6..000000000000
--- a/drivers/base/core.c
+++ b/drivers/base/core.c
@@@ -603,6 -696,134 +603,137 @@@ int device_links_check_suppliers(struc
  }
  
  /**
++<<<<<<< HEAD
++=======
+  * __device_links_queue_sync_state - Queue a device for sync_state() callback
+  * @dev: Device to call sync_state() on
+  * @list: List head to queue the @dev on
+  *
+  * Queues a device for a sync_state() callback when the device links write lock
+  * isn't held. This allows the sync_state() execution flow to use device links
+  * APIs.  The caller must ensure this function is called with
+  * device_links_write_lock() held.
+  *
+  * This function does a get_device() to make sure the device is not freed while
+  * on this list.
+  *
+  * So the caller must also ensure that device_links_flush_sync_list() is called
+  * as soon as the caller releases device_links_write_lock().  This is necessary
+  * to make sure the sync_state() is called in a timely fashion and the
+  * put_device() is called on this device.
+  */
+ static void __device_links_queue_sync_state(struct device *dev,
+ 					    struct list_head *list)
+ {
+ 	struct device_link *link;
+ 
+ 	if (dev->state_synced)
+ 		return;
+ 
+ 	list_for_each_entry(link, &dev->links.consumers, s_node) {
+ 		if (!(link->flags & DL_FLAG_MANAGED))
+ 			continue;
+ 		if (link->status != DL_STATE_ACTIVE)
+ 			return;
+ 	}
+ 
+ 	/*
+ 	 * Set the flag here to avoid adding the same device to a list more
+ 	 * than once. This can happen if new consumers get added to the device
+ 	 * and probed before the list is flushed.
+ 	 */
+ 	dev->state_synced = true;
+ 
+ 	if (WARN_ON(!list_empty(&dev->links.defer_sync)))
+ 		return;
+ 
+ 	get_device(dev);
+ 	list_add_tail(&dev->links.defer_sync, list);
+ }
+ 
+ /**
+  * device_links_flush_sync_list - Call sync_state() on a list of devices
+  * @list: List of devices to call sync_state() on
+  * @dont_lock_dev: Device for which lock is already held by the caller
+  *
+  * Calls sync_state() on all the devices that have been queued for it. This
+  * function is used in conjunction with __device_links_queue_sync_state(). The
+  * @dont_lock_dev parameter is useful when this function is called from a
+  * context where a device lock is already held.
+  */
+ static void device_links_flush_sync_list(struct list_head *list,
+ 					 struct device *dont_lock_dev)
+ {
+ 	struct device *dev, *tmp;
+ 
+ 	list_for_each_entry_safe(dev, tmp, list, links.defer_sync) {
+ 		list_del_init(&dev->links.defer_sync);
+ 
+ 		if (dev != dont_lock_dev)
+ 			device_lock(dev);
+ 
+ 		if (dev->bus->sync_state)
+ 			dev->bus->sync_state(dev);
+ 		else if (dev->driver && dev->driver->sync_state)
+ 			dev->driver->sync_state(dev);
+ 
+ 		if (dev != dont_lock_dev)
+ 			device_unlock(dev);
+ 
+ 		put_device(dev);
+ 	}
+ }
+ 
+ void device_links_supplier_sync_state_pause(void)
+ {
+ 	device_links_write_lock();
+ 	defer_sync_state_count++;
+ 	device_links_write_unlock();
+ }
+ 
+ void device_links_supplier_sync_state_resume(void)
+ {
+ 	struct device *dev, *tmp;
+ 	LIST_HEAD(sync_list);
+ 
+ 	device_links_write_lock();
+ 	if (!defer_sync_state_count) {
+ 		WARN(true, "Unmatched sync_state pause/resume!");
+ 		goto out;
+ 	}
+ 	defer_sync_state_count--;
+ 	if (defer_sync_state_count)
+ 		goto out;
+ 
+ 	list_for_each_entry_safe(dev, tmp, &deferred_sync, links.defer_sync) {
+ 		/*
+ 		 * Delete from deferred_sync list before queuing it to
+ 		 * sync_list because defer_sync is used for both lists.
+ 		 */
+ 		list_del_init(&dev->links.defer_sync);
+ 		__device_links_queue_sync_state(dev, &sync_list);
+ 	}
+ out:
+ 	device_links_write_unlock();
+ 
+ 	device_links_flush_sync_list(&sync_list, NULL);
+ }
+ 
+ static int sync_state_resume_initcall(void)
+ {
+ 	device_links_supplier_sync_state_resume();
+ 	return 0;
+ }
+ late_initcall(sync_state_resume_initcall);
+ 
+ static void __device_links_supplier_defer_sync(struct device *sup)
+ {
+ 	if (list_empty(&sup->links.defer_sync))
+ 		list_add_tail(&sup->links.defer_sync, &deferred_sync);
+ }
+ 
+ /**
++>>>>>>> 21eb93f432b1 (driver core: Call sync_state() even if supplier has no consumers)
   * device_links_driver_bound - Update device links after probing its driver.
   * @dev: Device to update the links for.
   *
@@@ -651,6 -893,8 +787,11 @@@ void device_links_driver_bound(struct d
  	dev->links.status = DL_DEV_DRIVER_BOUND;
  
  	device_links_write_unlock();
++<<<<<<< HEAD
++=======
+ 
+ 	device_links_flush_sync_list(&sync_list, dev);
++>>>>>>> 21eb93f432b1 (driver core: Call sync_state() even if supplier has no consumers)
  }
  
  static void device_link_drop_managed(struct device_link *link)
* Unmerged path drivers/base/core.c
