bpf: Compute bpf_skc_to_*() helper socket btf ids at build time

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Yonghong Song <yhs@fb.com>
commit bc4f0548f683a3d53359cef15f088d2d5bb4bc39
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/bc4f0548.failed

Currently, socket types (struct tcp_sock, udp_sock, etc.)
used by bpf_skc_to_*() helpers are computed when vmlinux_btf
is first built in the kernel.

Commit 5a2798ab32ba
("bpf: Add BTF_ID_LIST/BTF_ID/BTF_ID_UNUSED macros")
implemented a mechanism to compute btf_ids at kernel build
time which can simplify kernel implementation and reduce
runtime overhead by removing in-kernel btf_id calculation.
This patch did exactly this, removing in-kernel btf_id
computation and utilizing build-time btf_id computation.

If CONFIG_DEBUG_INFO_BTF is not defined, BTF_ID_LIST will
define an array with size of 5, which is not enough for
btf_sock_ids. So define its own static array if
CONFIG_DEBUG_INFO_BTF is not defined.

	Signed-off-by: Yonghong Song <yhs@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20200720163358.1393023-1-yhs@fb.com
(cherry picked from commit bc4f0548f683a3d53359cef15f088d2d5bb4bc39)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/core/filter.c
diff --cc net/core/filter.c
index 76aa4a2037db,5a65fb4b95ff..000000000000
--- a/net/core/filter.c
+++ b/net/core/filter.c
@@@ -9114,3 -9420,158 +9114,161 @@@ void bpf_prog_change_xdp(struct bpf_pro
  {
  	bpf_dispatcher_change_prog(BPF_DISPATCHER_PTR(xdp), prev_prog, prog);
  }
++<<<<<<< HEAD
++=======
+ 
+ /* Define a list of socket types which can be the argument for
+  * skc_to_*_sock() helpers. All these sockets should have
+  * sock_common as the first argument in its memory layout.
+  */
+ #define BTF_SOCK_TYPE_xxx \
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_INET, inet_sock)			\
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_INET_CONN, inet_connection_sock)	\
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_INET_REQ, inet_request_sock)	\
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_INET_TW, inet_timewait_sock)	\
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_REQ, request_sock)			\
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_SOCK, sock)				\
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_SOCK_COMMON, sock_common)		\
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_TCP, tcp_sock)			\
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_TCP_REQ, tcp_request_sock)		\
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_TCP_TW, tcp_timewait_sock)		\
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_TCP6, tcp6_sock)			\
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_UDP, udp_sock)			\
+ 	BTF_SOCK_TYPE(BTF_SOCK_TYPE_UDP6, udp6_sock)
+ 
+ enum {
+ #define BTF_SOCK_TYPE(name, str) name,
+ BTF_SOCK_TYPE_xxx
+ #undef BTF_SOCK_TYPE
+ MAX_BTF_SOCK_TYPE,
+ };
+ 
+ #ifdef CONFIG_DEBUG_INFO_BTF
+ BTF_ID_LIST(btf_sock_ids)
+ #define BTF_SOCK_TYPE(name, type) BTF_ID(struct, type)
+ BTF_SOCK_TYPE_xxx
+ #undef BTF_SOCK_TYPE
+ #else
+ static u32 btf_sock_ids[MAX_BTF_SOCK_TYPE];
+ #endif
+ 
+ static bool check_arg_btf_id(u32 btf_id, u32 arg)
+ {
+ 	int i;
+ 
+ 	/* only one argument, no need to check arg */
+ 	for (i = 0; i < MAX_BTF_SOCK_TYPE; i++)
+ 		if (btf_sock_ids[i] == btf_id)
+ 			return true;
+ 	return false;
+ }
+ 
+ BPF_CALL_1(bpf_skc_to_tcp6_sock, struct sock *, sk)
+ {
+ 	/* tcp6_sock type is not generated in dwarf and hence btf,
+ 	 * trigger an explicit type generation here.
+ 	 */
+ 	BTF_TYPE_EMIT(struct tcp6_sock);
+ 	if (sk_fullsock(sk) && sk->sk_protocol == IPPROTO_TCP &&
+ 	    sk->sk_family == AF_INET6)
+ 		return (unsigned long)sk;
+ 
+ 	return (unsigned long)NULL;
+ }
+ 
+ const struct bpf_func_proto bpf_skc_to_tcp6_sock_proto = {
+ 	.func			= bpf_skc_to_tcp6_sock,
+ 	.gpl_only		= false,
+ 	.ret_type		= RET_PTR_TO_BTF_ID_OR_NULL,
+ 	.arg1_type		= ARG_PTR_TO_BTF_ID,
+ 	.check_btf_id		= check_arg_btf_id,
+ 	.ret_btf_id		= &btf_sock_ids[BTF_SOCK_TYPE_TCP6],
+ };
+ 
+ BPF_CALL_1(bpf_skc_to_tcp_sock, struct sock *, sk)
+ {
+ 	if (sk_fullsock(sk) && sk->sk_protocol == IPPROTO_TCP)
+ 		return (unsigned long)sk;
+ 
+ 	return (unsigned long)NULL;
+ }
+ 
+ const struct bpf_func_proto bpf_skc_to_tcp_sock_proto = {
+ 	.func			= bpf_skc_to_tcp_sock,
+ 	.gpl_only		= false,
+ 	.ret_type		= RET_PTR_TO_BTF_ID_OR_NULL,
+ 	.arg1_type		= ARG_PTR_TO_BTF_ID,
+ 	.check_btf_id		= check_arg_btf_id,
+ 	.ret_btf_id		= &btf_sock_ids[BTF_SOCK_TYPE_TCP],
+ };
+ 
+ BPF_CALL_1(bpf_skc_to_tcp_timewait_sock, struct sock *, sk)
+ {
+ #ifdef CONFIG_INET
+ 	if (sk->sk_prot == &tcp_prot && sk->sk_state == TCP_TIME_WAIT)
+ 		return (unsigned long)sk;
+ #endif
+ 
+ #if IS_BUILTIN(CONFIG_IPV6)
+ 	if (sk->sk_prot == &tcpv6_prot && sk->sk_state == TCP_TIME_WAIT)
+ 		return (unsigned long)sk;
+ #endif
+ 
+ 	return (unsigned long)NULL;
+ }
+ 
+ const struct bpf_func_proto bpf_skc_to_tcp_timewait_sock_proto = {
+ 	.func			= bpf_skc_to_tcp_timewait_sock,
+ 	.gpl_only		= false,
+ 	.ret_type		= RET_PTR_TO_BTF_ID_OR_NULL,
+ 	.arg1_type		= ARG_PTR_TO_BTF_ID,
+ 	.check_btf_id		= check_arg_btf_id,
+ 	.ret_btf_id		= &btf_sock_ids[BTF_SOCK_TYPE_TCP_TW],
+ };
+ 
+ BPF_CALL_1(bpf_skc_to_tcp_request_sock, struct sock *, sk)
+ {
+ #ifdef CONFIG_INET
+ 	if (sk->sk_prot == &tcp_prot  && sk->sk_state == TCP_NEW_SYN_RECV)
+ 		return (unsigned long)sk;
+ #endif
+ 
+ #if IS_BUILTIN(CONFIG_IPV6)
+ 	if (sk->sk_prot == &tcpv6_prot && sk->sk_state == TCP_NEW_SYN_RECV)
+ 		return (unsigned long)sk;
+ #endif
+ 
+ 	return (unsigned long)NULL;
+ }
+ 
+ const struct bpf_func_proto bpf_skc_to_tcp_request_sock_proto = {
+ 	.func			= bpf_skc_to_tcp_request_sock,
+ 	.gpl_only		= false,
+ 	.ret_type		= RET_PTR_TO_BTF_ID_OR_NULL,
+ 	.arg1_type		= ARG_PTR_TO_BTF_ID,
+ 	.check_btf_id		= check_arg_btf_id,
+ 	.ret_btf_id		= &btf_sock_ids[BTF_SOCK_TYPE_TCP_REQ],
+ };
+ 
+ BPF_CALL_1(bpf_skc_to_udp6_sock, struct sock *, sk)
+ {
+ 	/* udp6_sock type is not generated in dwarf and hence btf,
+ 	 * trigger an explicit type generation here.
+ 	 */
+ 	BTF_TYPE_EMIT(struct udp6_sock);
+ 	if (sk_fullsock(sk) && sk->sk_protocol == IPPROTO_UDP &&
+ 	    sk->sk_type == SOCK_DGRAM && sk->sk_family == AF_INET6)
+ 		return (unsigned long)sk;
+ 
+ 	return (unsigned long)NULL;
+ }
+ 
+ const struct bpf_func_proto bpf_skc_to_udp6_sock_proto = {
+ 	.func			= bpf_skc_to_udp6_sock,
+ 	.gpl_only		= false,
+ 	.ret_type		= RET_PTR_TO_BTF_ID_OR_NULL,
+ 	.arg1_type		= ARG_PTR_TO_BTF_ID,
+ 	.check_btf_id		= check_arg_btf_id,
+ 	.ret_btf_id		= &btf_sock_ids[BTF_SOCK_TYPE_UDP6],
+ };
++>>>>>>> bc4f0548f683 (bpf: Compute bpf_skc_to_*() helper socket btf ids at build time)
* Unmerged path net/core/filter.c
