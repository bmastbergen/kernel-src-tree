iommu/io-pgtable-arm: Rationalise VTCR handling

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Will Deacon <will@kernel.org>
commit ac4b80e5b9d0ecf906300d79e4dc4df5526579a8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/ac4b80e5.failed

Commit 05a648cd2dd7 ("iommu/io-pgtable-arm: Rationalise TCR handling")
reworked the way in which the TCR register value is returned from the
io-pgtable code when targetting the Arm long-descriptor format, in
preparation for allowing page-tables to target TTBR1.

As it turns out, the new interface is a lot nicer to use, so do the same
conversion for the VTCR register even though there is only a single base
register for stage-2 translation.

	Cc: Robin Murphy <robin.murphy@arm.com>
	Signed-off-by: Will Deacon <will@kernel.org>
(cherry picked from commit ac4b80e5b9d0ecf906300d79e4dc4df5526579a8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/arm-smmu.h
#	drivers/iommu/io-pgtable-arm.c
diff --cc drivers/iommu/arm-smmu.h
index 671b3a337fea,8d1cd54d82a6..000000000000
--- a/drivers/iommu/arm-smmu.h
+++ b/drivers/iommu/arm-smmu.h
@@@ -172,9 -163,26 +172,29 @@@ enum arm_smmu_cbar_type 
  
  #define ARM_SMMU_CB_TTBR0		0x20
  #define ARM_SMMU_CB_TTBR1		0x28
 -#define ARM_SMMU_TTBRn_ASID		GENMASK_ULL(63, 48)
 +#define TTBRn_ASID			GENMASK_ULL(63, 48)
  
  #define ARM_SMMU_CB_TCR			0x30
++<<<<<<< HEAD
++=======
+ #define ARM_SMMU_TCR_EAE		BIT(31)
+ #define ARM_SMMU_TCR_EPD1		BIT(23)
+ #define ARM_SMMU_TCR_TG0		GENMASK(15, 14)
+ #define ARM_SMMU_TCR_SH0		GENMASK(13, 12)
+ #define ARM_SMMU_TCR_ORGN0		GENMASK(11, 10)
+ #define ARM_SMMU_TCR_IRGN0		GENMASK(9, 8)
+ #define ARM_SMMU_TCR_T0SZ		GENMASK(5, 0)
+ 
+ #define ARM_SMMU_VTCR_RES1		BIT(31)
+ #define ARM_SMMU_VTCR_PS		GENMASK(18, 16)
+ #define ARM_SMMU_VTCR_TG0		ARM_SMMU_TCR_TG0
+ #define ARM_SMMU_VTCR_SH0		ARM_SMMU_TCR_SH0
+ #define ARM_SMMU_VTCR_ORGN0		ARM_SMMU_TCR_ORGN0
+ #define ARM_SMMU_VTCR_IRGN0		ARM_SMMU_TCR_IRGN0
+ #define ARM_SMMU_VTCR_SL0		GENMASK(7, 6)
+ #define ARM_SMMU_VTCR_T0SZ		ARM_SMMU_TCR_T0SZ
+ 
++>>>>>>> ac4b80e5b9d0 (iommu/io-pgtable-arm: Rationalise VTCR handling)
  #define ARM_SMMU_CB_CONTEXTIDR		0x34
  #define ARM_SMMU_CB_S1_MAIR0		0x38
  #define ARM_SMMU_CB_S1_MAIR1		0x3c
@@@ -214,6 -230,227 +234,231 @@@
  #define ARM_SMMU_CB_ATS1PR		0x800
  
  #define ARM_SMMU_CB_ATSR		0x8f0
++<<<<<<< HEAD
 +#define ATSR_ACTIVE			BIT(0)
++=======
+ #define ARM_SMMU_ATSR_ACTIVE		BIT(0)
+ 
+ 
+ /* Maximum number of context banks per SMMU */
+ #define ARM_SMMU_MAX_CBS		128
+ 
+ 
+ /* Shared driver definitions */
+ enum arm_smmu_arch_version {
+ 	ARM_SMMU_V1,
+ 	ARM_SMMU_V1_64K,
+ 	ARM_SMMU_V2,
+ };
+ 
+ enum arm_smmu_implementation {
+ 	GENERIC_SMMU,
+ 	ARM_MMU500,
+ 	CAVIUM_SMMUV2,
+ 	QCOM_SMMUV2,
+ };
+ 
+ struct arm_smmu_device {
+ 	struct device			*dev;
+ 
+ 	void __iomem			*base;
+ 	unsigned int			numpage;
+ 	unsigned int			pgshift;
+ 
+ #define ARM_SMMU_FEAT_COHERENT_WALK	(1 << 0)
+ #define ARM_SMMU_FEAT_STREAM_MATCH	(1 << 1)
+ #define ARM_SMMU_FEAT_TRANS_S1		(1 << 2)
+ #define ARM_SMMU_FEAT_TRANS_S2		(1 << 3)
+ #define ARM_SMMU_FEAT_TRANS_NESTED	(1 << 4)
+ #define ARM_SMMU_FEAT_TRANS_OPS		(1 << 5)
+ #define ARM_SMMU_FEAT_VMID16		(1 << 6)
+ #define ARM_SMMU_FEAT_FMT_AARCH64_4K	(1 << 7)
+ #define ARM_SMMU_FEAT_FMT_AARCH64_16K	(1 << 8)
+ #define ARM_SMMU_FEAT_FMT_AARCH64_64K	(1 << 9)
+ #define ARM_SMMU_FEAT_FMT_AARCH32_L	(1 << 10)
+ #define ARM_SMMU_FEAT_FMT_AARCH32_S	(1 << 11)
+ #define ARM_SMMU_FEAT_EXIDS		(1 << 12)
+ 	u32				features;
+ 
+ 	enum arm_smmu_arch_version	version;
+ 	enum arm_smmu_implementation	model;
+ 	const struct arm_smmu_impl	*impl;
+ 
+ 	u32				num_context_banks;
+ 	u32				num_s2_context_banks;
+ 	DECLARE_BITMAP(context_map, ARM_SMMU_MAX_CBS);
+ 	struct arm_smmu_cb		*cbs;
+ 	atomic_t			irptndx;
+ 
+ 	u32				num_mapping_groups;
+ 	u16				streamid_mask;
+ 	u16				smr_mask_mask;
+ 	struct arm_smmu_smr		*smrs;
+ 	struct arm_smmu_s2cr		*s2crs;
+ 	struct mutex			stream_map_mutex;
+ 
+ 	unsigned long			va_size;
+ 	unsigned long			ipa_size;
+ 	unsigned long			pa_size;
+ 	unsigned long			pgsize_bitmap;
+ 
+ 	u32				num_global_irqs;
+ 	u32				num_context_irqs;
+ 	unsigned int			*irqs;
+ 	struct clk_bulk_data		*clks;
+ 	int				num_clks;
+ 
+ 	spinlock_t			global_sync_lock;
+ 
+ 	/* IOMMU core code handle */
+ 	struct iommu_device		iommu;
+ };
+ 
+ enum arm_smmu_context_fmt {
+ 	ARM_SMMU_CTX_FMT_NONE,
+ 	ARM_SMMU_CTX_FMT_AARCH64,
+ 	ARM_SMMU_CTX_FMT_AARCH32_L,
+ 	ARM_SMMU_CTX_FMT_AARCH32_S,
+ };
+ 
+ struct arm_smmu_cfg {
+ 	u8				cbndx;
+ 	u8				irptndx;
+ 	union {
+ 		u16			asid;
+ 		u16			vmid;
+ 	};
+ 	enum arm_smmu_cbar_type		cbar;
+ 	enum arm_smmu_context_fmt	fmt;
+ };
+ #define ARM_SMMU_INVALID_IRPTNDX	0xff
+ 
+ enum arm_smmu_domain_stage {
+ 	ARM_SMMU_DOMAIN_S1 = 0,
+ 	ARM_SMMU_DOMAIN_S2,
+ 	ARM_SMMU_DOMAIN_NESTED,
+ 	ARM_SMMU_DOMAIN_BYPASS,
+ };
+ 
+ struct arm_smmu_domain {
+ 	struct arm_smmu_device		*smmu;
+ 	struct io_pgtable_ops		*pgtbl_ops;
+ 	const struct iommu_flush_ops	*flush_ops;
+ 	struct arm_smmu_cfg		cfg;
+ 	enum arm_smmu_domain_stage	stage;
+ 	bool				non_strict;
+ 	struct mutex			init_mutex; /* Protects smmu pointer */
+ 	spinlock_t			cb_lock; /* Serialises ATS1* ops and TLB syncs */
+ 	struct iommu_domain		domain;
+ };
+ 
+ static inline u32 arm_smmu_lpae_tcr(struct io_pgtable_cfg *cfg)
+ {
+ 	return ARM_SMMU_TCR_EPD1 |
+ 	       FIELD_PREP(ARM_SMMU_TCR_TG0, cfg->arm_lpae_s1_cfg.tcr.tg) |
+ 	       FIELD_PREP(ARM_SMMU_TCR_SH0, cfg->arm_lpae_s1_cfg.tcr.sh) |
+ 	       FIELD_PREP(ARM_SMMU_TCR_ORGN0, cfg->arm_lpae_s1_cfg.tcr.orgn) |
+ 	       FIELD_PREP(ARM_SMMU_TCR_IRGN0, cfg->arm_lpae_s1_cfg.tcr.irgn) |
+ 	       FIELD_PREP(ARM_SMMU_TCR_T0SZ, cfg->arm_lpae_s1_cfg.tcr.tsz);
+ }
+ 
+ static inline u32 arm_smmu_lpae_tcr2(struct io_pgtable_cfg *cfg)
+ {
+ 	return FIELD_PREP(ARM_SMMU_TCR2_PASIZE, cfg->arm_lpae_s1_cfg.tcr.ips) |
+ 	       FIELD_PREP(ARM_SMMU_TCR2_SEP, ARM_SMMU_TCR2_SEP_UPSTREAM);
+ }
+ 
+ static inline u32 arm_smmu_lpae_vtcr(struct io_pgtable_cfg *cfg)
+ {
+ 	return ARM_SMMU_VTCR_RES1 |
+ 	       FIELD_PREP(ARM_SMMU_VTCR_PS, cfg->arm_lpae_s2_cfg.vtcr.ps) |
+ 	       FIELD_PREP(ARM_SMMU_VTCR_TG0, cfg->arm_lpae_s2_cfg.vtcr.tg) |
+ 	       FIELD_PREP(ARM_SMMU_VTCR_SH0, cfg->arm_lpae_s2_cfg.vtcr.sh) |
+ 	       FIELD_PREP(ARM_SMMU_VTCR_ORGN0, cfg->arm_lpae_s2_cfg.vtcr.orgn) |
+ 	       FIELD_PREP(ARM_SMMU_VTCR_IRGN0, cfg->arm_lpae_s2_cfg.vtcr.irgn) |
+ 	       FIELD_PREP(ARM_SMMU_VTCR_SL0, cfg->arm_lpae_s2_cfg.vtcr.sl) |
+ 	       FIELD_PREP(ARM_SMMU_VTCR_T0SZ, cfg->arm_lpae_s2_cfg.vtcr.tsz);
+ }
+ 
+ /* Implementation details, yay! */
+ struct arm_smmu_impl {
+ 	u32 (*read_reg)(struct arm_smmu_device *smmu, int page, int offset);
+ 	void (*write_reg)(struct arm_smmu_device *smmu, int page, int offset,
+ 			  u32 val);
+ 	u64 (*read_reg64)(struct arm_smmu_device *smmu, int page, int offset);
+ 	void (*write_reg64)(struct arm_smmu_device *smmu, int page, int offset,
+ 			    u64 val);
+ 	int (*cfg_probe)(struct arm_smmu_device *smmu);
+ 	int (*reset)(struct arm_smmu_device *smmu);
+ 	int (*init_context)(struct arm_smmu_domain *smmu_domain);
+ 	void (*tlb_sync)(struct arm_smmu_device *smmu, int page, int sync,
+ 			 int status);
+ };
+ 
+ static inline void __iomem *arm_smmu_page(struct arm_smmu_device *smmu, int n)
+ {
+ 	return smmu->base + (n << smmu->pgshift);
+ }
+ 
+ static inline u32 arm_smmu_readl(struct arm_smmu_device *smmu, int page, int offset)
+ {
+ 	if (smmu->impl && unlikely(smmu->impl->read_reg))
+ 		return smmu->impl->read_reg(smmu, page, offset);
+ 	return readl_relaxed(arm_smmu_page(smmu, page) + offset);
+ }
+ 
+ static inline void arm_smmu_writel(struct arm_smmu_device *smmu, int page,
+ 				   int offset, u32 val)
+ {
+ 	if (smmu->impl && unlikely(smmu->impl->write_reg))
+ 		smmu->impl->write_reg(smmu, page, offset, val);
+ 	else
+ 		writel_relaxed(val, arm_smmu_page(smmu, page) + offset);
+ }
+ 
+ static inline u64 arm_smmu_readq(struct arm_smmu_device *smmu, int page, int offset)
+ {
+ 	if (smmu->impl && unlikely(smmu->impl->read_reg64))
+ 		return smmu->impl->read_reg64(smmu, page, offset);
+ 	return readq_relaxed(arm_smmu_page(smmu, page) + offset);
+ }
+ 
+ static inline void arm_smmu_writeq(struct arm_smmu_device *smmu, int page,
+ 				   int offset, u64 val)
+ {
+ 	if (smmu->impl && unlikely(smmu->impl->write_reg64))
+ 		smmu->impl->write_reg64(smmu, page, offset, val);
+ 	else
+ 		writeq_relaxed(val, arm_smmu_page(smmu, page) + offset);
+ }
+ 
+ #define ARM_SMMU_GR0		0
+ #define ARM_SMMU_GR1		1
+ #define ARM_SMMU_CB(s, n)	((s)->numpage + (n))
+ 
+ #define arm_smmu_gr0_read(s, o)		\
+ 	arm_smmu_readl((s), ARM_SMMU_GR0, (o))
+ #define arm_smmu_gr0_write(s, o, v)	\
+ 	arm_smmu_writel((s), ARM_SMMU_GR0, (o), (v))
+ 
+ #define arm_smmu_gr1_read(s, o)		\
+ 	arm_smmu_readl((s), ARM_SMMU_GR1, (o))
+ #define arm_smmu_gr1_write(s, o, v)	\
+ 	arm_smmu_writel((s), ARM_SMMU_GR1, (o), (v))
+ 
+ #define arm_smmu_cb_read(s, n, o)	\
+ 	arm_smmu_readl((s), ARM_SMMU_CB((s), (n)), (o))
+ #define arm_smmu_cb_write(s, n, o, v)	\
+ 	arm_smmu_writel((s), ARM_SMMU_CB((s), (n)), (o), (v))
+ #define arm_smmu_cb_readq(s, n, o)	\
+ 	arm_smmu_readq((s), ARM_SMMU_CB((s), (n)), (o))
+ #define arm_smmu_cb_writeq(s, n, o, v)	\
+ 	arm_smmu_writeq((s), ARM_SMMU_CB((s), (n)), (o), (v))
+ 
+ struct arm_smmu_device *arm_smmu_impl_init(struct arm_smmu_device *smmu);
+ struct arm_smmu_device *qcom_smmu_impl_init(struct arm_smmu_device *smmu);
+ 
+ int arm_mmu500_reset(struct arm_smmu_device *smmu);
++>>>>>>> ac4b80e5b9d0 (iommu/io-pgtable-arm: Rationalise VTCR handling)
  
  #endif /* _ARM_SMMU_H */
diff --cc drivers/iommu/io-pgtable-arm.c
index c5503d730284,2ae4da4dea5e..000000000000
--- a/drivers/iommu/io-pgtable-arm.c
+++ b/drivers/iommu/io-pgtable-arm.c
@@@ -111,40 -100,25 +111,54 @@@
  #define ARM_LPAE_PTE_MEMATTR_DEV	(((arm_lpae_iopte)0x1) << 2)
  
  /* Register bits */
++<<<<<<< HEAD
 +#define ARM_32_LPAE_TCR_EAE		(1 << 31)
 +#define ARM_64_LPAE_S2_TCR_RES1		(1U << 31)
 +
 +#define ARM_LPAE_TCR_EPD1		(1 << 23)
 +
 +#define ARM_LPAE_TCR_TG0_4K		(0 << 14)
 +#define ARM_LPAE_TCR_TG0_64K		(1 << 14)
 +#define ARM_LPAE_TCR_TG0_16K		(2 << 14)
 +
 +#define ARM_LPAE_TCR_SH0_SHIFT		12
 +#define ARM_LPAE_TCR_SH0_MASK		0x3
++=======
+ #define ARM_LPAE_TCR_TG0_4K		0
+ #define ARM_LPAE_TCR_TG0_64K		1
+ #define ARM_LPAE_TCR_TG0_16K		2
+ 
++>>>>>>> ac4b80e5b9d0 (iommu/io-pgtable-arm: Rationalise VTCR handling)
  #define ARM_LPAE_TCR_SH_NS		0
  #define ARM_LPAE_TCR_SH_OS		2
  #define ARM_LPAE_TCR_SH_IS		3
  
++<<<<<<< HEAD
 +#define ARM_LPAE_TCR_ORGN0_SHIFT	10
 +#define ARM_LPAE_TCR_IRGN0_SHIFT	8
 +#define ARM_LPAE_TCR_RGN_MASK		0x3
++=======
++>>>>>>> ac4b80e5b9d0 (iommu/io-pgtable-arm: Rationalise VTCR handling)
  #define ARM_LPAE_TCR_RGN_NC		0
  #define ARM_LPAE_TCR_RGN_WBWA		1
  #define ARM_LPAE_TCR_RGN_WT		2
  #define ARM_LPAE_TCR_RGN_WB		3
  
++<<<<<<< HEAD
 +#define ARM_LPAE_TCR_SL0_SHIFT		6
 +#define ARM_LPAE_TCR_SL0_MASK		0x3
++=======
+ #define ARM_LPAE_VTCR_SL0_MASK		0x3
++>>>>>>> ac4b80e5b9d0 (iommu/io-pgtable-arm: Rationalise VTCR handling)
  
  #define ARM_LPAE_TCR_T0SZ_SHIFT		0
 +#define ARM_LPAE_TCR_SZ_MASK		0xf
  
 -#define ARM_LPAE_VTCR_PS_SHIFT		16
 -#define ARM_LPAE_VTCR_PS_MASK		0x7
 +#define ARM_LPAE_TCR_PS_SHIFT		16
 +#define ARM_LPAE_TCR_PS_MASK		0x7
 +
 +#define ARM_LPAE_TCR_IPS_SHIFT		32
 +#define ARM_LPAE_TCR_IPS_MASK		0x7
  
  #define ARM_LPAE_TCR_PS_32_BIT		0x0ULL
  #define ARM_LPAE_TCR_PS_36_BIT		0x1ULL
@@@ -923,61 -898,59 +938,102 @@@ arm_64_lpae_alloc_pgtable_s2(struct io_
  	}
  
  	/* VTCR */
++<<<<<<< HEAD
 +	reg = ARM_64_LPAE_S2_TCR_RES1;
++=======
++>>>>>>> ac4b80e5b9d0 (iommu/io-pgtable-arm: Rationalise VTCR handling)
  	if (cfg->coherent_walk) {
- 		reg |= (ARM_LPAE_TCR_SH_IS << ARM_LPAE_TCR_SH0_SHIFT) |
- 		       (ARM_LPAE_TCR_RGN_WBWA << ARM_LPAE_TCR_IRGN0_SHIFT) |
- 		       (ARM_LPAE_TCR_RGN_WBWA << ARM_LPAE_TCR_ORGN0_SHIFT);
+ 		vtcr->sh = ARM_LPAE_TCR_SH_IS;
+ 		vtcr->irgn = ARM_LPAE_TCR_RGN_WBWA;
+ 		vtcr->orgn = ARM_LPAE_TCR_RGN_WBWA;
  	} else {
- 		reg |= (ARM_LPAE_TCR_SH_OS << ARM_LPAE_TCR_SH0_SHIFT) |
- 		       (ARM_LPAE_TCR_RGN_NC << ARM_LPAE_TCR_IRGN0_SHIFT) |
- 		       (ARM_LPAE_TCR_RGN_NC << ARM_LPAE_TCR_ORGN0_SHIFT);
+ 		vtcr->sh = ARM_LPAE_TCR_SH_OS;
+ 		vtcr->irgn = ARM_LPAE_TCR_RGN_NC;
+ 		vtcr->orgn = ARM_LPAE_TCR_RGN_NC;
  	}
  
  	sl = data->start_level;
  
  	switch (ARM_LPAE_GRANULE(data)) {
  	case SZ_4K:
++<<<<<<< HEAD
 +		reg |= ARM_LPAE_TCR_TG0_4K;
 +		sl++; /* SL0 format is different for 4K granule size */
 +		break;
 +	case SZ_16K:
 +		reg |= ARM_LPAE_TCR_TG0_16K;
 +		break;
 +	case SZ_64K:
 +		reg |= ARM_LPAE_TCR_TG0_64K;
++=======
+ 		vtcr->tg = ARM_LPAE_TCR_TG0_4K;
+ 		sl++; /* SL0 format is different for 4K granule size */
+ 		break;
+ 	case SZ_16K:
+ 		vtcr->tg = ARM_LPAE_TCR_TG0_16K;
+ 		break;
+ 	case SZ_64K:
+ 		vtcr->tg = ARM_LPAE_TCR_TG0_64K;
++>>>>>>> ac4b80e5b9d0 (iommu/io-pgtable-arm: Rationalise VTCR handling)
  		break;
  	}
  
  	switch (cfg->oas) {
  	case 32:
++<<<<<<< HEAD
 +		reg |= (ARM_LPAE_TCR_PS_32_BIT << ARM_LPAE_TCR_PS_SHIFT);
 +		break;
 +	case 36:
 +		reg |= (ARM_LPAE_TCR_PS_36_BIT << ARM_LPAE_TCR_PS_SHIFT);
 +		break;
 +	case 40:
 +		reg |= (ARM_LPAE_TCR_PS_40_BIT << ARM_LPAE_TCR_PS_SHIFT);
 +		break;
 +	case 42:
 +		reg |= (ARM_LPAE_TCR_PS_42_BIT << ARM_LPAE_TCR_PS_SHIFT);
 +		break;
 +	case 44:
 +		reg |= (ARM_LPAE_TCR_PS_44_BIT << ARM_LPAE_TCR_PS_SHIFT);
 +		break;
 +	case 48:
 +		reg |= (ARM_LPAE_TCR_PS_48_BIT << ARM_LPAE_TCR_PS_SHIFT);
 +		break;
 +	case 52:
 +		reg |= (ARM_LPAE_TCR_PS_52_BIT << ARM_LPAE_TCR_PS_SHIFT);
++=======
+ 		vtcr->ps = ARM_LPAE_TCR_PS_32_BIT;
+ 		break;
+ 	case 36:
+ 		vtcr->ps = ARM_LPAE_TCR_PS_36_BIT;
+ 		break;
+ 	case 40:
+ 		vtcr->ps = ARM_LPAE_TCR_PS_40_BIT;
+ 		break;
+ 	case 42:
+ 		vtcr->ps = ARM_LPAE_TCR_PS_42_BIT;
+ 		break;
+ 	case 44:
+ 		vtcr->ps = ARM_LPAE_TCR_PS_44_BIT;
+ 		break;
+ 	case 48:
+ 		vtcr->ps = ARM_LPAE_TCR_PS_48_BIT;
+ 		break;
+ 	case 52:
+ 		vtcr->ps = ARM_LPAE_TCR_PS_52_BIT;
++>>>>>>> ac4b80e5b9d0 (iommu/io-pgtable-arm: Rationalise VTCR handling)
  		break;
  	default:
  		goto out_free_data;
  	}
  
++<<<<<<< HEAD
 +	reg |= (64ULL - cfg->ias) << ARM_LPAE_TCR_T0SZ_SHIFT;
 +	reg |= (~sl & ARM_LPAE_TCR_SL0_MASK) << ARM_LPAE_TCR_SL0_SHIFT;
 +	cfg->arm_lpae_s2_cfg.vtcr = reg;
++=======
+ 	vtcr->tsz = 64ULL - cfg->ias;
+ 	vtcr->sl = ~sl & ARM_LPAE_VTCR_SL0_MASK;
++>>>>>>> ac4b80e5b9d0 (iommu/io-pgtable-arm: Rationalise VTCR handling)
  
  	/* Allocate pgd pages */
  	data->pgd = __arm_lpae_alloc_pages(ARM_LPAE_PGD_SIZE(data),
@@@ -1006,13 -977,7 +1062,17 @@@ arm_32_lpae_alloc_pgtable_s1(struct io_
  		return NULL;
  
  	cfg->pgsize_bitmap &= (SZ_4K | SZ_2M | SZ_1G);
++<<<<<<< HEAD
 +	iop = arm_64_lpae_alloc_pgtable_s1(cfg, cookie);
 +	if (iop) {
 +		cfg->arm_lpae_s1_cfg.tcr |= ARM_32_LPAE_TCR_EAE;
 +		cfg->arm_lpae_s1_cfg.tcr &= 0xffffffff;
 +	}
 +
 +	return iop;
++=======
+ 	return arm_64_lpae_alloc_pgtable_s1(cfg, cookie);
++>>>>>>> ac4b80e5b9d0 (iommu/io-pgtable-arm: Rationalise VTCR handling)
  }
  
  static struct io_pgtable *
diff --git a/drivers/iommu/arm-smmu-v3.c b/drivers/iommu/arm-smmu-v3.c
index 4810cdc2e204..3ff402a14fbb 100644
--- a/drivers/iommu/arm-smmu-v3.c
+++ b/drivers/iommu/arm-smmu-v3.c
@@ -251,6 +251,13 @@
 
 #define STRTAB_STE_2_S2VMID		GENMASK_ULL(15, 0)
 #define STRTAB_STE_2_VTCR		GENMASK_ULL(50, 32)
+#define STRTAB_STE_2_VTCR_S2T0SZ	GENMASK_ULL(5, 0)
+#define STRTAB_STE_2_VTCR_S2SL0		GENMASK_ULL(7, 6)
+#define STRTAB_STE_2_VTCR_S2IR0		GENMASK_ULL(9, 8)
+#define STRTAB_STE_2_VTCR_S2OR0		GENMASK_ULL(11, 10)
+#define STRTAB_STE_2_VTCR_S2SH0		GENMASK_ULL(13, 12)
+#define STRTAB_STE_2_VTCR_S2TG		GENMASK_ULL(15, 14)
+#define STRTAB_STE_2_VTCR_S2PS		GENMASK_ULL(18, 16)
 #define STRTAB_STE_2_S2AA64		(1UL << 51)
 #define STRTAB_STE_2_S2ENDI		(1UL << 52)
 #define STRTAB_STE_2_S2PTW		(1UL << 54)
@@ -2193,14 +2200,22 @@ static int arm_smmu_domain_finalise_s2(struct arm_smmu_domain *smmu_domain,
 	int vmid;
 	struct arm_smmu_device *smmu = smmu_domain->smmu;
 	struct arm_smmu_s2_cfg *cfg = &smmu_domain->s2_cfg;
+	typeof(&pgtbl_cfg->arm_lpae_s2_cfg.vtcr) vtcr;
 
 	vmid = arm_smmu_bitmap_alloc(smmu->vmid_map, smmu->vmid_bits);
 	if (vmid < 0)
 		return vmid;
 
+	vtcr = &pgtbl_cfg->arm_lpae_s2_cfg.vtcr;
 	cfg->vmid	= (u16)vmid;
 	cfg->vttbr	= pgtbl_cfg->arm_lpae_s2_cfg.vttbr;
-	cfg->vtcr	= pgtbl_cfg->arm_lpae_s2_cfg.vtcr;
+	cfg->vtcr	= FIELD_PREP(STRTAB_STE_2_VTCR_S2T0SZ, vtcr->tsz) |
+			  FIELD_PREP(STRTAB_STE_2_VTCR_S2SL0, vtcr->sl) |
+			  FIELD_PREP(STRTAB_STE_2_VTCR_S2IR0, vtcr->irgn) |
+			  FIELD_PREP(STRTAB_STE_2_VTCR_S2OR0, vtcr->orgn) |
+			  FIELD_PREP(STRTAB_STE_2_VTCR_S2SH0, vtcr->sh) |
+			  FIELD_PREP(STRTAB_STE_2_VTCR_S2TG, vtcr->tg) |
+			  FIELD_PREP(STRTAB_STE_2_VTCR_S2PS, vtcr->ps);
 	return 0;
 }
 
diff --git a/drivers/iommu/arm-smmu.c b/drivers/iommu/arm-smmu.c
index b4652ac29e56..90b1bba48071 100644
--- a/drivers/iommu/arm-smmu.c
+++ b/drivers/iommu/arm-smmu.c
@@ -720,7 +720,7 @@ static void arm_smmu_init_context_bank(struct arm_smmu_domain *smmu_domain,
 				cb->tcr[1] |= TCR2_AS;
 		}
 	} else {
-		cb->tcr[0] = pgtbl_cfg->arm_lpae_s2_cfg.vtcr;
+		cb->tcr[0] = arm_smmu_lpae_vtcr(pgtbl_cfg);
 	}
 
 	/* TTBRs */
* Unmerged path drivers/iommu/arm-smmu.h
* Unmerged path drivers/iommu/io-pgtable-arm.c
diff --git a/include/linux/io-pgtable.h b/include/linux/io-pgtable.h
index 6b1b8be3ebec..ff3c7381dbca 100644
--- a/include/linux/io-pgtable.h
+++ b/include/linux/io-pgtable.h
@@ -108,7 +108,15 @@ struct io_pgtable_cfg {
 
 		struct {
 			u64	vttbr;
-			u64	vtcr;
+			struct {
+				u32	ps:3;
+				u32	tg:2;
+				u32	sh:2;
+				u32	orgn:2;
+				u32	irgn:2;
+				u32	sl:2;
+				u32	tsz:6;
+			}	vtcr;
 		} arm_lpae_s2_cfg;
 
 		struct {
