net: stmmac: Add Frame Preemption support using TAPRIO API

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Jose Abreu <Jose.Abreu@synopsys.com>
commit 1ac14241543c0108e9fd23aca4927a148a44c815
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/1ac14241.failed

Adds the support for Frame Preemption using TAPRIO API. This works along
with EST feature and allows to select if preemptable traffic shall be
sent during specific queues opening time.

	Signed-off-by: Jose Abreu <Jose.Abreu@synopsys.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 1ac14241543c0108e9fd23aca4927a148a44c815)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/stmicro/stmmac/common.h
#	drivers/net/ethernet/stmicro/stmmac/hwif.h
#	drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
diff --cc drivers/net/ethernet/stmicro/stmmac/common.h
index 41eb39add60e,09c72025ed3e..000000000000
--- a/drivers/net/ethernet/stmicro/stmmac/common.h
+++ b/drivers/net/ethernet/stmicro/stmmac/common.h
@@@ -371,10 -361,18 +371,20 @@@ struct dma_features 
  	unsigned int sphen;
  	unsigned int vlins;
  	unsigned int dvlan;
++<<<<<<< HEAD
++=======
+ 	unsigned int l3l4fnum;
+ 	unsigned int arpoffsel;
+ 	/* TSN Features */
+ 	unsigned int estwid;
+ 	unsigned int estdep;
+ 	unsigned int estsel;
+ 	unsigned int fpesel;
++>>>>>>> 1ac14241543c (net: stmmac: Add Frame Preemption support using TAPRIO API)
  };
  
 -/* GMAC TX FIFO is 8K, Rx FIFO is 16K */
 -#define BUF_SIZE_16KiB 16384
 -/* RX Buffer size must be < 8191 and multiple of 4/8/16 bytes */
 +/* RX Buffer size must be multiple of 4/8/16 bytes */
 +#define BUF_SIZE_16KiB 16368
  #define BUF_SIZE_8KiB 8188
  #define BUF_SIZE_4KiB 4096
  #define BUF_SIZE_2KiB 2048
diff --cc drivers/net/ethernet/stmicro/stmmac/hwif.h
index 59108f05df14,905a6f0edaca..000000000000
--- a/drivers/net/ethernet/stmicro/stmmac/hwif.h
+++ b/drivers/net/ethernet/stmicro/stmmac/hwif.h
@@@ -362,6 -366,18 +362,21 @@@ struct stmmac_ops 
  	int (*get_mac_tx_timestamp)(struct mac_device_info *hw, u64 *ts);
  	/* Source Address Insertion / Replacement */
  	void (*sarc_configure)(void __iomem *ioaddr, int val);
++<<<<<<< HEAD
++=======
+ 	/* Filtering */
+ 	int (*config_l3_filter)(struct mac_device_info *hw, u32 filter_no,
+ 				bool en, bool ipv6, bool sa, bool inv,
+ 				u32 match);
+ 	int (*config_l4_filter)(struct mac_device_info *hw, u32 filter_no,
+ 				bool en, bool udp, bool sa, bool inv,
+ 				u32 match);
+ 	void (*set_arp_offload)(struct mac_device_info *hw, bool en, u32 addr);
+ 	int (*est_configure)(void __iomem *ioaddr, struct stmmac_est *cfg,
+ 			     unsigned int ptp_rate);
+ 	void (*fpe_configure)(void __iomem *ioaddr, u32 num_txq, u32 num_rxq,
+ 			      bool enable);
++>>>>>>> 1ac14241543c (net: stmmac: Add Frame Preemption support using TAPRIO API)
  };
  
  #define stmmac_core_init(__priv, __args...) \
@@@ -442,6 -458,16 +457,19 @@@
  	stmmac_do_callback(__priv, mac, get_mac_tx_timestamp, __args)
  #define stmmac_sarc_configure(__priv, __args...) \
  	stmmac_do_void_callback(__priv, mac, sarc_configure, __args)
++<<<<<<< HEAD
++=======
+ #define stmmac_config_l3_filter(__priv, __args...) \
+ 	stmmac_do_callback(__priv, mac, config_l3_filter, __args)
+ #define stmmac_config_l4_filter(__priv, __args...) \
+ 	stmmac_do_callback(__priv, mac, config_l4_filter, __args)
+ #define stmmac_set_arp_offload(__priv, __args...) \
+ 	stmmac_do_void_callback(__priv, mac, set_arp_offload, __args)
+ #define stmmac_est_configure(__priv, __args...) \
+ 	stmmac_do_callback(__priv, mac, est_configure, __args)
+ #define stmmac_fpe_configure(__priv, __args...) \
+ 	stmmac_do_void_callback(__priv, mac, fpe_configure, __args)
++>>>>>>> 1ac14241543c (net: stmmac: Add Frame Preemption support using TAPRIO API)
  
  /* PTP and HW Timer helpers */
  struct stmmac_hwtimestamp {
diff --cc drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
index 9f686caafe62,8ff8f9b9bb22..000000000000
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
@@@ -289,6 -306,425 +289,428 @@@ static int tc_init(struct stmmac_priv *
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static int tc_setup_cbs(struct stmmac_priv *priv,
+ 			struct tc_cbs_qopt_offload *qopt)
+ {
+ 	u32 tx_queues_count = priv->plat->tx_queues_to_use;
+ 	u32 queue = qopt->queue;
+ 	u32 ptr, speed_div;
+ 	u32 mode_to_use;
+ 	u64 value;
+ 	int ret;
+ 
+ 	/* Queue 0 is not AVB capable */
+ 	if (queue <= 0 || queue >= tx_queues_count)
+ 		return -EINVAL;
+ 	if (!priv->dma_cap.av)
+ 		return -EOPNOTSUPP;
+ 
+ 	mode_to_use = priv->plat->tx_queues_cfg[queue].mode_to_use;
+ 	if (mode_to_use == MTL_QUEUE_DCB && qopt->enable) {
+ 		ret = stmmac_dma_qmode(priv, priv->ioaddr, queue, MTL_QUEUE_AVB);
+ 		if (ret)
+ 			return ret;
+ 
+ 		priv->plat->tx_queues_cfg[queue].mode_to_use = MTL_QUEUE_AVB;
+ 	} else if (!qopt->enable) {
+ 		return stmmac_dma_qmode(priv, priv->ioaddr, queue, MTL_QUEUE_DCB);
+ 	}
+ 
+ 	/* Port Transmit Rate and Speed Divider */
+ 	ptr = (priv->speed == SPEED_100) ? 4 : 8;
+ 	speed_div = (priv->speed == SPEED_100) ? 100000 : 1000000;
+ 
+ 	/* Final adjustments for HW */
+ 	value = div_s64(qopt->idleslope * 1024ll * ptr, speed_div);
+ 	priv->plat->tx_queues_cfg[queue].idle_slope = value & GENMASK(31, 0);
+ 
+ 	value = div_s64(-qopt->sendslope * 1024ll * ptr, speed_div);
+ 	priv->plat->tx_queues_cfg[queue].send_slope = value & GENMASK(31, 0);
+ 
+ 	value = qopt->hicredit * 1024ll * 8;
+ 	priv->plat->tx_queues_cfg[queue].high_credit = value & GENMASK(31, 0);
+ 
+ 	value = qopt->locredit * 1024ll * 8;
+ 	priv->plat->tx_queues_cfg[queue].low_credit = value & GENMASK(31, 0);
+ 
+ 	ret = stmmac_config_cbs(priv, priv->hw,
+ 				priv->plat->tx_queues_cfg[queue].send_slope,
+ 				priv->plat->tx_queues_cfg[queue].idle_slope,
+ 				priv->plat->tx_queues_cfg[queue].high_credit,
+ 				priv->plat->tx_queues_cfg[queue].low_credit,
+ 				queue);
+ 	if (ret)
+ 		return ret;
+ 
+ 	dev_info(priv->device, "CBS queue %d: send %d, idle %d, hi %d, lo %d\n",
+ 			queue, qopt->sendslope, qopt->idleslope,
+ 			qopt->hicredit, qopt->locredit);
+ 	return 0;
+ }
+ 
+ static int tc_parse_flow_actions(struct stmmac_priv *priv,
+ 				 struct flow_action *action,
+ 				 struct stmmac_flow_entry *entry)
+ {
+ 	struct flow_action_entry *act;
+ 	int i;
+ 
+ 	if (!flow_action_has_entries(action))
+ 		return -EINVAL;
+ 
+ 	flow_action_for_each(i, act, action) {
+ 		switch (act->id) {
+ 		case FLOW_ACTION_DROP:
+ 			entry->action |= STMMAC_FLOW_ACTION_DROP;
+ 			return 0;
+ 		default:
+ 			break;
+ 		}
+ 	}
+ 
+ 	/* Nothing to do, maybe inverse filter ? */
+ 	return 0;
+ }
+ 
+ static int tc_add_basic_flow(struct stmmac_priv *priv,
+ 			     struct flow_cls_offload *cls,
+ 			     struct stmmac_flow_entry *entry)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
+ 	struct flow_dissector *dissector = rule->match.dissector;
+ 	struct flow_match_basic match;
+ 
+ 	/* Nothing to do here */
+ 	if (!dissector_uses_key(dissector, FLOW_DISSECTOR_KEY_BASIC))
+ 		return -EINVAL;
+ 
+ 	flow_rule_match_basic(rule, &match);
+ 	entry->ip_proto = match.key->ip_proto;
+ 	return 0;
+ }
+ 
+ static int tc_add_ip4_flow(struct stmmac_priv *priv,
+ 			   struct flow_cls_offload *cls,
+ 			   struct stmmac_flow_entry *entry)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
+ 	struct flow_dissector *dissector = rule->match.dissector;
+ 	bool inv = entry->action & STMMAC_FLOW_ACTION_DROP;
+ 	struct flow_match_ipv4_addrs match;
+ 	u32 hw_match;
+ 	int ret;
+ 
+ 	/* Nothing to do here */
+ 	if (!dissector_uses_key(dissector, FLOW_DISSECTOR_KEY_IPV4_ADDRS))
+ 		return -EINVAL;
+ 
+ 	flow_rule_match_ipv4_addrs(rule, &match);
+ 	hw_match = ntohl(match.key->src) & ntohl(match.mask->src);
+ 	if (hw_match) {
+ 		ret = stmmac_config_l3_filter(priv, priv->hw, entry->idx, true,
+ 					      false, true, inv, hw_match);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	hw_match = ntohl(match.key->dst) & ntohl(match.mask->dst);
+ 	if (hw_match) {
+ 		ret = stmmac_config_l3_filter(priv, priv->hw, entry->idx, true,
+ 					      false, false, inv, hw_match);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int tc_add_ports_flow(struct stmmac_priv *priv,
+ 			     struct flow_cls_offload *cls,
+ 			     struct stmmac_flow_entry *entry)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
+ 	struct flow_dissector *dissector = rule->match.dissector;
+ 	bool inv = entry->action & STMMAC_FLOW_ACTION_DROP;
+ 	struct flow_match_ports match;
+ 	u32 hw_match;
+ 	bool is_udp;
+ 	int ret;
+ 
+ 	/* Nothing to do here */
+ 	if (!dissector_uses_key(dissector, FLOW_DISSECTOR_KEY_PORTS))
+ 		return -EINVAL;
+ 
+ 	switch (entry->ip_proto) {
+ 	case IPPROTO_TCP:
+ 		is_udp = false;
+ 		break;
+ 	case IPPROTO_UDP:
+ 		is_udp = true;
+ 		break;
+ 	default:
+ 		return -EINVAL;
+ 	}
+ 
+ 	flow_rule_match_ports(rule, &match);
+ 
+ 	hw_match = ntohs(match.key->src) & ntohs(match.mask->src);
+ 	if (hw_match) {
+ 		ret = stmmac_config_l4_filter(priv, priv->hw, entry->idx, true,
+ 					      is_udp, true, inv, hw_match);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	hw_match = ntohs(match.key->dst) & ntohs(match.mask->dst);
+ 	if (hw_match) {
+ 		ret = stmmac_config_l4_filter(priv, priv->hw, entry->idx, true,
+ 					      is_udp, false, inv, hw_match);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	entry->is_l4 = true;
+ 	return 0;
+ }
+ 
+ static struct stmmac_flow_entry *tc_find_flow(struct stmmac_priv *priv,
+ 					      struct flow_cls_offload *cls,
+ 					      bool get_free)
+ {
+ 	int i;
+ 
+ 	for (i = 0; i < priv->flow_entries_max; i++) {
+ 		struct stmmac_flow_entry *entry = &priv->flow_entries[i];
+ 
+ 		if (entry->cookie == cls->cookie)
+ 			return entry;
+ 		if (get_free && (entry->in_use == false))
+ 			return entry;
+ 	}
+ 
+ 	return NULL;
+ }
+ 
+ static struct {
+ 	int (*fn)(struct stmmac_priv *priv, struct flow_cls_offload *cls,
+ 		  struct stmmac_flow_entry *entry);
+ } tc_flow_parsers[] = {
+ 	{ .fn = tc_add_basic_flow },
+ 	{ .fn = tc_add_ip4_flow },
+ 	{ .fn = tc_add_ports_flow },
+ };
+ 
+ static int tc_add_flow(struct stmmac_priv *priv,
+ 		       struct flow_cls_offload *cls)
+ {
+ 	struct stmmac_flow_entry *entry = tc_find_flow(priv, cls, false);
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
+ 	int i, ret;
+ 
+ 	if (!entry) {
+ 		entry = tc_find_flow(priv, cls, true);
+ 		if (!entry)
+ 			return -ENOENT;
+ 	}
+ 
+ 	ret = tc_parse_flow_actions(priv, &rule->action, entry);
+ 	if (ret)
+ 		return ret;
+ 
+ 	for (i = 0; i < ARRAY_SIZE(tc_flow_parsers); i++) {
+ 		ret = tc_flow_parsers[i].fn(priv, cls, entry);
+ 		if (!ret) {
+ 			entry->in_use = true;
+ 			continue;
+ 		}
+ 	}
+ 
+ 	if (!entry->in_use)
+ 		return -EINVAL;
+ 
+ 	entry->cookie = cls->cookie;
+ 	return 0;
+ }
+ 
+ static int tc_del_flow(struct stmmac_priv *priv,
+ 		       struct flow_cls_offload *cls)
+ {
+ 	struct stmmac_flow_entry *entry = tc_find_flow(priv, cls, false);
+ 	int ret;
+ 
+ 	if (!entry || !entry->in_use)
+ 		return -ENOENT;
+ 
+ 	if (entry->is_l4) {
+ 		ret = stmmac_config_l4_filter(priv, priv->hw, entry->idx, false,
+ 					      false, false, false, 0);
+ 	} else {
+ 		ret = stmmac_config_l3_filter(priv, priv->hw, entry->idx, false,
+ 					      false, false, false, 0);
+ 	}
+ 
+ 	entry->in_use = false;
+ 	entry->cookie = 0;
+ 	entry->is_l4 = false;
+ 	return ret;
+ }
+ 
+ static int tc_setup_cls(struct stmmac_priv *priv,
+ 			struct flow_cls_offload *cls)
+ {
+ 	int ret = 0;
+ 
+ 	switch (cls->command) {
+ 	case FLOW_CLS_REPLACE:
+ 		ret = tc_add_flow(priv, cls);
+ 		break;
+ 	case FLOW_CLS_DESTROY:
+ 		ret = tc_del_flow(priv, cls);
+ 		break;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	return ret;
+ }
+ 
+ static int tc_setup_taprio(struct stmmac_priv *priv,
+ 			   struct tc_taprio_qopt_offload *qopt)
+ {
+ 	u32 size, wid = priv->dma_cap.estwid, dep = priv->dma_cap.estdep;
+ 	struct plat_stmmacenet_data *plat = priv->plat;
+ 	struct timespec64 time;
+ 	bool fpe = false;
+ 	int i, ret = 0;
+ 
+ 	if (!priv->dma_cap.estsel)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (wid) {
+ 	case 0x1:
+ 		wid = 16;
+ 		break;
+ 	case 0x2:
+ 		wid = 20;
+ 		break;
+ 	case 0x3:
+ 		wid = 24;
+ 		break;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	switch (dep) {
+ 	case 0x1:
+ 		dep = 64;
+ 		break;
+ 	case 0x2:
+ 		dep = 128;
+ 		break;
+ 	case 0x3:
+ 		dep = 256;
+ 		break;
+ 	case 0x4:
+ 		dep = 512;
+ 		break;
+ 	case 0x5:
+ 		dep = 1024;
+ 		break;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	if (!qopt->enable)
+ 		goto disable;
+ 	if (qopt->num_entries >= dep)
+ 		return -EINVAL;
+ 	if (!qopt->base_time)
+ 		return -ERANGE;
+ 	if (!qopt->cycle_time)
+ 		return -ERANGE;
+ 
+ 	if (!plat->est) {
+ 		plat->est = devm_kzalloc(priv->device, sizeof(*plat->est),
+ 					 GFP_KERNEL);
+ 		if (!plat->est)
+ 			return -ENOMEM;
+ 	} else {
+ 		memset(plat->est, 0, sizeof(*plat->est));
+ 	}
+ 
+ 	size = qopt->num_entries;
+ 
+ 	priv->plat->est->gcl_size = size;
+ 	priv->plat->est->enable = qopt->enable;
+ 
+ 	for (i = 0; i < size; i++) {
+ 		s64 delta_ns = qopt->entries[i].interval;
+ 		u32 gates = qopt->entries[i].gate_mask;
+ 
+ 		if (delta_ns > GENMASK(wid, 0))
+ 			return -ERANGE;
+ 		if (gates > GENMASK(31 - wid, 0))
+ 			return -ERANGE;
+ 
+ 		switch (qopt->entries[i].command) {
+ 		case TC_TAPRIO_CMD_SET_GATES:
+ 			if (fpe)
+ 				return -EINVAL;
+ 			break;
+ 		case TC_TAPRIO_CMD_SET_AND_HOLD:
+ 			gates |= BIT(0);
+ 			fpe = true;
+ 			break;
+ 		case TC_TAPRIO_CMD_SET_AND_RELEASE:
+ 			gates &= ~BIT(0);
+ 			fpe = true;
+ 			break;
+ 		default:
+ 			return -EOPNOTSUPP;
+ 		}
+ 
+ 		priv->plat->est->gcl[i] = delta_ns | (gates << wid);
+ 	}
+ 
+ 	/* Adjust for real system time */
+ 	time = ktime_to_timespec64(qopt->base_time);
+ 	priv->plat->est->btr[0] = (u32)time.tv_nsec;
+ 	priv->plat->est->btr[1] = (u32)time.tv_sec;
+ 
+ 	priv->plat->est->ctr[0] = (u32)(qopt->cycle_time % NSEC_PER_SEC);
+ 	priv->plat->est->ctr[1] = (u32)(qopt->cycle_time / NSEC_PER_SEC);
+ 
+ 	if (fpe && !priv->dma_cap.fpesel)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = stmmac_fpe_configure(priv, priv->ioaddr,
+ 				   priv->plat->tx_queues_to_use,
+ 				   priv->plat->rx_queues_to_use, fpe);
+ 	if (ret && fpe) {
+ 		netdev_err(priv->dev, "failed to enable Frame Preemption\n");
+ 		return ret;
+ 	}
+ 
+ 	ret = stmmac_est_configure(priv, priv->ioaddr, priv->plat->est,
+ 				   priv->plat->clk_ptp_rate);
+ 	if (ret) {
+ 		netdev_err(priv->dev, "failed to configure EST\n");
+ 		goto disable;
+ 	}
+ 
+ 	netdev_info(priv->dev, "configured EST\n");
+ 	return 0;
+ 
+ disable:
+ 	priv->plat->est->enable = false;
+ 	stmmac_est_configure(priv, priv->ioaddr, priv->plat->est,
+ 			     priv->plat->clk_ptp_rate);
+ 	return ret;
+ }
+ 
++>>>>>>> 1ac14241543c (net: stmmac: Add Frame Preemption support using TAPRIO API)
  const struct stmmac_tc_ops dwmac510_tc_ops = {
  	.init = tc_init,
  	.setup_cls_u32 = tc_setup_cls_u32,
* Unmerged path drivers/net/ethernet/stmicro/stmmac/common.h
* Unmerged path drivers/net/ethernet/stmicro/stmmac/hwif.h
* Unmerged path drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
