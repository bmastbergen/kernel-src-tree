RDMA/mlx5: Change scatter CQE flag to be set like other vendor flags

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Leon Romanovsky <leon@kernel.org>
commit 90ecb37a751b6923bee846c4e19f73b943c6ffa1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/90ecb37a.failed

In similar way to wqe_sig, the scat_cqe was treated differently from
other create QP vendor flags. Change it to be similar to other flags
and use flags_en mechanism.

Link: https://lore.kernel.org/r/20200427154636.381474-17-leon@kernel.org
	Reviewed-by: Maor Gottlieb <maorg@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 90ecb37a751b6923bee846c4e19f73b943c6ffa1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/mlx5_ib.h
#	drivers/infiniband/hw/mlx5/qp.c
diff --cc drivers/infiniband/hw/mlx5/mlx5_ib.h
index 23d1e95a5a49,b6467cadc384..000000000000
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@@ -428,11 -446,10 +428,14 @@@ struct mlx5_ib_qp 
  	u32			flags;
  	u8			port;
  	u8			state;
++<<<<<<< HEAD
 +	int			wq_sig;
 +	int			scat_cqe;
++=======
++>>>>>>> 90ecb37a751b (RDMA/mlx5: Change scatter CQE flag to be set like other vendor flags)
  	int			max_inline_data;
  	struct mlx5_bf	        bf;
 -	u8			has_rq:1;
 -	u8			is_rss:1;
 +	int			has_rq;
  
  	/* only for user space QPs. For kernel
  	 * we have it from the bf object
diff --cc drivers/infiniband/hw/mlx5/qp.c
index 745e3ea1cb8f,6a4b20c71b40..000000000000
--- a/drivers/infiniband/hw/mlx5/qp.c
+++ b/drivers/infiniband/hw/mlx5/qp.c
@@@ -2085,10 -2017,13 +2085,20 @@@ static int create_qp_common(struct mlx5
  		if (err)
  			return err;
  
++<<<<<<< HEAD
 +		qp->wq_sig = !!(ucmd.flags & MLX5_QP_FLAG_SIGNATURE);
 +		if (MLX5_CAP_GEN(dev->mdev, sctr_data_cqe))
 +			qp->scat_cqe = !!(ucmd.flags & MLX5_QP_FLAG_SCATTER_CQE);
 +		if (ucmd.flags & MLX5_QP_FLAG_TUNNEL_OFFLOADS) {
++=======
+ 		if (ucmd->flags & MLX5_QP_FLAG_SIGNATURE)
+ 			qp->flags_en |= MLX5_QP_FLAG_SIGNATURE;
+ 		if (ucmd->flags & MLX5_QP_FLAG_SCATTER_CQE &&
+ 		    MLX5_CAP_GEN(dev->mdev, sctr_data_cqe))
+ 			qp->flags_en |= MLX5_QP_FLAG_SCATTER_CQE;
+ 
+ 		if (ucmd->flags & MLX5_QP_FLAG_TUNNEL_OFFLOADS) {
++>>>>>>> 90ecb37a751b (RDMA/mlx5: Change scatter CQE flag to be set like other vendor flags)
  			if (init_attr->qp_type != IB_QPT_RAW_PACKET ||
  			    !tunnel_offload_supported(mdev)) {
  				mlx5_ib_dbg(dev, "Tunnel offload isn't supported\n");
@@@ -2206,22 -2124,23 +2216,23 @@@
  		MLX5_SET(qpc, qpc, latency_sensitive, 1);
  
  
 -	if (qp->flags_en & MLX5_QP_FLAG_SIGNATURE)
 +	if (qp->wq_sig)
  		MLX5_SET(qpc, qpc, wq_signature, 1);
  
 -	if (qp->flags & IB_QP_CREATE_BLOCK_MULTICAST_LOOPBACK)
 +	if (qp->flags & MLX5_IB_QP_BLOCK_MULTICAST_LOOPBACK)
  		MLX5_SET(qpc, qpc, block_lb_mc, 1);
  
 -	if (qp->flags & IB_QP_CREATE_CROSS_CHANNEL)
 +	if (qp->flags & MLX5_IB_QP_CROSS_CHANNEL)
  		MLX5_SET(qpc, qpc, cd_master, 1);
 -	if (qp->flags & IB_QP_CREATE_MANAGED_SEND)
 +	if (qp->flags & MLX5_IB_QP_MANAGED_SEND)
  		MLX5_SET(qpc, qpc, cd_slave_send, 1);
 -	if (qp->flags & IB_QP_CREATE_MANAGED_RECV)
 +	if (qp->flags & MLX5_IB_QP_MANAGED_RECV)
  		MLX5_SET(qpc, qpc, cd_slave_receive, 1);
 -	if (qp->flags_en & MLX5_QP_FLAG_PACKET_BASED_CREDIT_MODE)
 +	if (qp->flags & MLX5_IB_QP_PACKET_BASED_CREDIT)
  		MLX5_SET(qpc, qpc, req_e2e_credit_mode, 1);
- 	if (qp->scat_cqe && (init_attr->qp_type == IB_QPT_RC ||
- 			     init_attr->qp_type == IB_QPT_UC)) {
+ 	if ((qp->flags_en & MLX5_QP_FLAG_SCATTER_CQE) &&
+ 	    (init_attr->qp_type == IB_QPT_RC ||
+ 	     init_attr->qp_type == IB_QPT_UC)) {
  		int rcqe_sz = rcqe_sz =
  			mlx5_ib_get_cqe_size(init_attr->recv_cq);
  
@@@ -2229,11 -2148,10 +2240,18 @@@
  			 rcqe_sz == 128 ? MLX5_RES_SCAT_DATA64_CQE :
  					  MLX5_RES_SCAT_DATA32_CQE);
  	}
++<<<<<<< HEAD
 +	if (qp->scat_cqe && (qp->qp_sub_type == MLX5_IB_QPT_DCI ||
 +			     init_attr->qp_type == IB_QPT_RC))
 +		configure_requester_scat_cqe(dev, init_attr,
 +					     udata ? &ucmd : NULL,
 +					     qpc);
++=======
+ 	if ((qp->flags_en & MLX5_QP_FLAG_SCATTER_CQE) &&
+ 	    (qp->qp_sub_type == MLX5_IB_QPT_DCI ||
+ 	     init_attr->qp_type == IB_QPT_RC))
+ 		configure_requester_scat_cqe(dev, init_attr, ucmd, qpc);
++>>>>>>> 90ecb37a751b (RDMA/mlx5: Change scatter CQE flag to be set like other vendor flags)
  
  	if (qp->rq.wqe_cnt) {
  		MLX5_SET(qpc, qpc, log_rq_stride, qp->rq.wqe_shift - 4);
* Unmerged path drivers/infiniband/hw/mlx5/mlx5_ib.h
* Unmerged path drivers/infiniband/hw/mlx5/qp.c
