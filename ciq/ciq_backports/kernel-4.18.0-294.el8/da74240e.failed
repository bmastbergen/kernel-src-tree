mm/filemap: add missing mem_cgroup_uncharge() to __add_to_page_cache_locked()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Waiman Long <longman@redhat.com>
commit da74240eb3fcd806edb1643874363e954d9e948b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/da74240e.failed

Commit 3fea5a499d57 ("mm: memcontrol: convert page cache to a new
mem_cgroup_charge() API") introduced a bug in __add_to_page_cache_locked()
causing the following splat:

  page dumped because: VM_BUG_ON_PAGE(page_memcg(page))
  pages's memcg:ffff8889a4116000
  ------------[ cut here ]------------
  kernel BUG at mm/memcontrol.c:2924!
  invalid opcode: 0000 [#1] SMP KASAN PTI
  CPU: 35 PID: 12345 Comm: cat Tainted: G S      W I       5.11.0-rc4-debug+ #1
  Hardware name: HP HP Z8 G4 Workstation/81C7, BIOS P60 v01.25 12/06/2017
  RIP: commit_charge+0xf4/0x130
  Call Trace:
    mem_cgroup_charge+0x175/0x770
    __add_to_page_cache_locked+0x712/0xad0
    add_to_page_cache_lru+0xc5/0x1f0
    cachefiles_read_or_alloc_pages+0x895/0x2e10 [cachefiles]
    __fscache_read_or_alloc_pages+0x6c0/0xa00 [fscache]
    __nfs_readpages_from_fscache+0x16d/0x630 [nfs]
    nfs_readpages+0x24e/0x540 [nfs]
    read_pages+0x5b1/0xc40
    page_cache_ra_unbounded+0x460/0x750
    generic_file_buffered_read_get_pages+0x290/0x1710
    generic_file_buffered_read+0x2a9/0xc30
    nfs_file_read+0x13f/0x230 [nfs]
    new_sync_read+0x3af/0x610
    vfs_read+0x339/0x4b0
    ksys_read+0xf1/0x1c0
    do_syscall_64+0x33/0x40
    entry_SYSCALL_64_after_hwframe+0x44/0xa9

Before that commit, there was a try_charge() and commit_charge() in
__add_to_page_cache_locked().  These two separated charge functions were
replaced by a single mem_cgroup_charge().  However, it forgot to add a
matching mem_cgroup_uncharge() when the xarray insertion failed with the
page released back to the pool.

Fix this by adding a mem_cgroup_uncharge() call when insertion error
happens.

Link: https://lkml.kernel.org/r/20210125042441.20030-1-longman@redhat.com
Fixes: 3fea5a499d57 ("mm: memcontrol: convert page cache to a new mem_cgroup_charge() API")
	Signed-off-by: Waiman Long <longman@redhat.com>
	Reviewed-by: Alex Shi <alex.shi@linux.alibaba.com>
	Acked-by: Johannes Weiner <hannes@cmpxchg.org>
	Cc: Matthew Wilcox <willy@infradead.org>
	Cc: Miaohe Lin <linmiaohe@huawei.com>
	Cc: Muchun Song <smuchun@gmail.com>
	Cc: Michal Hocko <mhocko@suse.com>
	Cc: <stable@vger.kernel.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit da74240eb3fcd806edb1643874363e954d9e948b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/filemap.c
diff --cc mm/filemap.c
index 20e5a7c67c1c,aa0e0fb04670..000000000000
--- a/mm/filemap.c
+++ b/mm/filemap.c
@@@ -824,9 -834,8 +824,13 @@@ static int __add_to_page_cache_locked(s
  {
  	XA_STATE(xas, &mapping->i_pages, offset);
  	int huge = PageHuge(page);
 +	struct mem_cgroup *memcg;
  	int error;
++<<<<<<< HEAD
 +	void *old;
++=======
+ 	bool charged = false;
++>>>>>>> da74240eb3fc (mm/filemap: add missing mem_cgroup_uncharge() to __add_to_page_cache_locked())
  
  	VM_BUG_ON_PAGE(!PageLocked(page), page);
  	VM_BUG_ON_PAGE(PageSwapBacked(page), page);
@@@ -843,11 -845,42 +847,23 @@@
  	page->mapping = mapping;
  	page->index = offset;
  
++<<<<<<< HEAD
++=======
+ 	if (!huge) {
+ 		error = mem_cgroup_charge(page, current->mm, gfp);
+ 		if (error)
+ 			goto error;
+ 		charged = true;
+ 	}
+ 
+ 	gfp &= GFP_RECLAIM_MASK;
+ 
++>>>>>>> da74240eb3fc (mm/filemap: add missing mem_cgroup_uncharge() to __add_to_page_cache_locked())
  	do {
 -		unsigned int order = xa_get_order(xas.xa, xas.xa_index);
 -		void *entry, *old = NULL;
 -
 -		if (order > thp_order(page))
 -			xas_split_alloc(&xas, xa_load(xas.xa, xas.xa_index),
 -					order, gfp);
  		xas_lock_irq(&xas);
 -		xas_for_each_conflict(&xas, entry) {
 -			old = entry;
 -			if (!xa_is_value(entry)) {
 -				xas_set_err(&xas, -EEXIST);
 -				goto unlock;
 -			}
 -		}
 -
 -		if (old) {
 -			if (shadowp)
 -				*shadowp = old;
 -			/* entry may have been split before we acquired lock */
 -			order = xa_get_order(xas.xa, xas.xa_index);
 -			if (order > thp_order(page)) {
 -				xas_split(&xas, old, order);
 -				xas_reset(&xas);
 -			}
 -		}
 -
 +		old = xas_load(&xas);
 +		if (old && !xa_is_value(old))
 +			xas_set_err(&xas, -EEXIST);
  		xas_store(&xas, page);
  		if (xas_error(&xas))
  			goto unlock;
@@@ -861,16 -891,18 +877,23 @@@
  
  		/* hugetlb pages do not participate in page cache accounting */
  		if (!huge)
 -			__inc_lruvec_page_state(page, NR_FILE_PAGES);
 +			__inc_node_page_state(page, NR_FILE_PAGES);
  unlock:
  		xas_unlock_irq(&xas);
 -	} while (xas_nomem(&xas, gfp));
 +	} while (xas_nomem(&xas, gfp_mask & GFP_RECLAIM_MASK));
  
++<<<<<<< HEAD
 +	if (xas_error(&xas))
++=======
+ 	if (xas_error(&xas)) {
+ 		error = xas_error(&xas);
+ 		if (charged)
+ 			mem_cgroup_uncharge(page);
++>>>>>>> da74240eb3fc (mm/filemap: add missing mem_cgroup_uncharge() to __add_to_page_cache_locked())
  		goto error;
 -	}
  
 +	if (!huge)
 +		mem_cgroup_commit_charge(page, memcg, false, false);
  	trace_mm_filemap_add_to_page_cache(page);
  	return 0;
  error:
* Unmerged path mm/filemap.c
