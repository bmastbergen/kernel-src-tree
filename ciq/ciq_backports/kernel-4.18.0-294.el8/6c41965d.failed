RDMA/mlx5: Don't access ib_qp fields in internal destroy QP path

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Leon Romanovsky <leon@kernel.org>
commit 6c41965d647a97b51ff665c7406ec9435aab7fc1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/6c41965d.failed

destroy_qp_common is called for flows where QP is already created by
HW. While it is called from IB/core, the ibqp.* fields will be fully
initialized, but it is not the case if this function is called during QP
creation.

Don't rely on ibqp fields as much as possible and initialize
send_cq/recv_cq as temporal solution till all drivers will be converted to
IB/core QP allocation scheme.

refcount_t: underflow; use-after-free.
WARNING: CPU: 1 PID: 5372 at lib/refcount.c:28 refcount_warn_saturate+0xfe/0x1a0
Kernel panic - not syncing: panic_on_warn set ...
CPU: 1 PID: 5372 Comm: syz-executor.2 Not tainted 5.5.0-rc5 #2
Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS rel-1.12.1-0-ga5cab58e9a3f-prebuilt.qemu.org 04/01/2014
Call Trace:
 mlx5_core_put_rsc+0x70/0x80
 destroy_resource_common+0x8e/0xb0
 mlx5_core_destroy_qp+0xaf/0x1d0
 mlx5_ib_destroy_qp+0xeb0/0x1460
 ib_destroy_qp_user+0x2d5/0x7d0
 create_qp+0xed3/0x2130
 ib_uverbs_create_qp+0x13e/0x190
 ? ib_uverbs_ex_create_qp
 ib_uverbs_write+0xaa5/0xdf0
 __vfs_write+0x7c/0x100
 ksys_write+0xc8/0x200
 do_syscall_64+0x9c/0x390
 entry_SYSCALL_64_after_hwframe+0x44/0xa9

Fixes: 08d53976609a ("RDMA/mlx5: Copy response to the user in one place")
Link: https://lore.kernel.org/r/20200617130148.2846643-1-leon@kernel.org
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 6c41965d647a97b51ff665c7406ec9435aab7fc1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/qp.c
diff --cc drivers/infiniband/hw/mlx5/qp.c
index 68ab87769d36,1e567fe3a527..000000000000
--- a/drivers/infiniband/hw/mlx5/qp.c
+++ b/drivers/infiniband/hw/mlx5/qp.c
@@@ -2467,16 -2346,16 +2467,27 @@@ static void destroy_qp_common(struct ml
  		return;
  	}
  
++<<<<<<< HEAD
 +	base = (qp->ibqp.qp_type == IB_QPT_RAW_PACKET ||
 +		qp->flags & MLX5_IB_QP_UNDERLAY) ?
 +	       &qp->raw_packet_qp.rq.base :
 +	       &qp->trans_qp.base;
 +
 +	if (qp->state != IB_QPS_RESET) {
 +		if (qp->ibqp.qp_type != IB_QPT_RAW_PACKET &&
 +		    !(qp->flags & MLX5_IB_QP_UNDERLAY)) {
++=======
+ 	base = (qp->type == IB_QPT_RAW_PACKET ||
+ 		qp->flags & IB_QP_CREATE_SOURCE_QPN) ?
+ 		       &qp->raw_packet_qp.rq.base :
+ 		       &qp->trans_qp.base;
+ 
+ 	if (qp->state != IB_QPS_RESET) {
+ 		if (qp->type != IB_QPT_RAW_PACKET &&
+ 		    !(qp->flags & IB_QP_CREATE_SOURCE_QPN)) {
++>>>>>>> 6c41965d647a (RDMA/mlx5: Don't access ib_qp fields in internal destroy QP path)
  			err = mlx5_core_qp_modify(dev, MLX5_CMD_OP_2RST_QP, 0,
 -						  NULL, &base->mqp, NULL);
 +						  NULL, &base->mqp);
  		} else {
  			struct mlx5_modify_raw_qp_param raw_qp_param = {
  				.operation = MLX5_CMD_OP_2RST_QP
@@@ -2512,8 -2391,8 +2523,13 @@@
  	mlx5_ib_unlock_cqs(send_cq, recv_cq);
  	spin_unlock_irqrestore(&dev->reset_flow_resource_lock, flags);
  
++<<<<<<< HEAD
 +	if (qp->ibqp.qp_type == IB_QPT_RAW_PACKET ||
 +	    qp->flags & MLX5_IB_QP_UNDERLAY) {
++=======
+ 	if (qp->type == IB_QPT_RAW_PACKET ||
+ 	    qp->flags & IB_QP_CREATE_SOURCE_QPN) {
++>>>>>>> 6c41965d647a (RDMA/mlx5: Don't access ib_qp fields in internal destroy QP path)
  		destroy_raw_packet_qp(dev, qp);
  	} else {
  		err = mlx5_core_destroy_qp(dev, &base->mqp);
@@@ -2795,6 -2870,158 +2811,161 @@@ static int mlx5_ib_destroy_dct(struct m
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static int check_ucmd_data(struct mlx5_ib_dev *dev,
+ 			   struct mlx5_create_qp_params *params)
+ {
+ 	struct ib_qp_init_attr *attr = params->attr;
+ 	struct ib_udata *udata = params->udata;
+ 	size_t size, last;
+ 	int ret;
+ 
+ 	if (params->is_rss_raw)
+ 		/*
+ 		 * These QPs don't have "reserved" field in their
+ 		 * create_qp input struct, so their data is always valid.
+ 		 */
+ 		last = sizeof(struct mlx5_ib_create_qp_rss);
+ 	else
+ 		/* IB_QPT_RAW_PACKET doesn't have ECE data */
+ 		switch (attr->qp_type) {
+ 		case IB_QPT_RAW_PACKET:
+ 			last = offsetof(struct mlx5_ib_create_qp, ece_options);
+ 			break;
+ 		default:
+ 			last = offsetof(struct mlx5_ib_create_qp, reserved);
+ 		}
+ 
+ 	if (udata->inlen <= last)
+ 		return 0;
+ 
+ 	/*
+ 	 * User provides different create_qp structures based on the
+ 	 * flow and we need to know if he cleared memory after our
+ 	 * struct create_qp ends.
+ 	 */
+ 	size = udata->inlen - last;
+ 	ret = ib_is_udata_cleared(params->udata, last, size);
+ 	if (!ret)
+ 		mlx5_ib_dbg(
+ 			dev,
+ 			"udata is not cleared, inlen = %zu, ucmd = %zu, last = %zu, size = %zu\n",
+ 			udata->inlen, params->ucmd_size, last, size);
+ 	return ret ? 0 : -EINVAL;
+ }
+ 
+ struct ib_qp *mlx5_ib_create_qp(struct ib_pd *pd, struct ib_qp_init_attr *attr,
+ 				struct ib_udata *udata)
+ {
+ 	struct mlx5_create_qp_params params = {};
+ 	struct mlx5_ib_dev *dev;
+ 	struct mlx5_ib_qp *qp;
+ 	enum ib_qp_type type;
+ 	int err;
+ 
+ 	dev = pd ? to_mdev(pd->device) :
+ 		   to_mdev(to_mxrcd(attr->xrcd)->ibxrcd.device);
+ 
+ 	err = check_qp_type(dev, attr, &type);
+ 	if (err)
+ 		return ERR_PTR(err);
+ 
+ 	err = check_valid_flow(dev, pd, attr, udata);
+ 	if (err)
+ 		return ERR_PTR(err);
+ 
+ 	if (attr->qp_type == IB_QPT_GSI)
+ 		return mlx5_ib_gsi_create_qp(pd, attr);
+ 
+ 	params.udata = udata;
+ 	params.uidx = MLX5_IB_DEFAULT_UIDX;
+ 	params.attr = attr;
+ 	params.is_rss_raw = !!attr->rwq_ind_tbl;
+ 
+ 	if (udata) {
+ 		err = process_udata_size(dev, &params);
+ 		if (err)
+ 			return ERR_PTR(err);
+ 
+ 		err = check_ucmd_data(dev, &params);
+ 		if (err)
+ 			return ERR_PTR(err);
+ 
+ 		params.ucmd = kzalloc(params.ucmd_size, GFP_KERNEL);
+ 		if (!params.ucmd)
+ 			return ERR_PTR(-ENOMEM);
+ 
+ 		err = ib_copy_from_udata(params.ucmd, udata, params.inlen);
+ 		if (err)
+ 			goto free_ucmd;
+ 	}
+ 
+ 	qp = kzalloc(sizeof(*qp), GFP_KERNEL);
+ 	if (!qp) {
+ 		err = -ENOMEM;
+ 		goto free_ucmd;
+ 	}
+ 
+ 	qp->type = type;
+ 	if (udata) {
+ 		err = process_vendor_flags(dev, qp, params.ucmd, attr);
+ 		if (err)
+ 			goto free_qp;
+ 
+ 		err = get_qp_uidx(qp, &params);
+ 		if (err)
+ 			goto free_qp;
+ 	}
+ 	err = process_create_flags(dev, qp, attr);
+ 	if (err)
+ 		goto free_qp;
+ 
+ 	err = check_qp_attr(dev, qp, attr);
+ 	if (err)
+ 		goto free_qp;
+ 
+ 	err = create_qp(dev, pd, qp, &params);
+ 	if (err)
+ 		goto free_qp;
+ 
+ 	kfree(params.ucmd);
+ 	params.ucmd = NULL;
+ 
+ 	if (udata)
+ 		/*
+ 		 * It is safe to copy response for all user create QP flows,
+ 		 * including MLX5_IB_QPT_DCT, which doesn't need it.
+ 		 * In that case, resp will be filled with zeros.
+ 		 */
+ 		err = ib_copy_to_udata(udata, &params.resp, params.outlen);
+ 	if (err)
+ 		goto destroy_qp;
+ 
+ 	return &qp->ibqp;
+ 
+ destroy_qp:
+ 	if (qp->type == MLX5_IB_QPT_DCT) {
+ 		mlx5_ib_destroy_dct(qp);
+ 	} else {
+ 		/*
+ 		 * The two lines below are temp solution till QP allocation
+ 		 * will be moved to be under IB/core responsiblity.
+ 		 */
+ 		qp->ibqp.send_cq = attr->send_cq;
+ 		qp->ibqp.recv_cq = attr->recv_cq;
+ 		destroy_qp_common(dev, qp, udata);
+ 	}
+ 
+ 	qp = NULL;
+ free_qp:
+ 	kfree(qp);
+ free_ucmd:
+ 	kfree(params.ucmd);
+ 	return ERR_PTR(err);
+ }
+ 
++>>>>>>> 6c41965d647a (RDMA/mlx5: Don't access ib_qp fields in internal destroy QP path)
  int mlx5_ib_destroy_qp(struct ib_qp *qp, struct ib_udata *udata)
  {
  	struct mlx5_ib_dev *dev = to_mdev(qp->device);
* Unmerged path drivers/infiniband/hw/mlx5/qp.c
