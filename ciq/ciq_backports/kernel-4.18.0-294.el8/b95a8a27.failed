x86/vdso: Use generic VDSO clock mode storage

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit b95a8a27c300d1a39a4e36f63a518ef36e4b966c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/b95a8a27.failed

Switch to the generic VDSO clock mode storage.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Reviewed-by: Vincenzo Frascino <vincenzo.frascino@arm.com> (VDSO parts)
	Acked-by: Juergen Gross <jgross@suse.com> (Xen parts)
	Acked-by: Paolo Bonzini <pbonzini@redhat.com> (KVM parts)
Link: https://lkml.kernel.org/r/20200207124403.152039903@linutronix.de


(cherry picked from commit b95a8a27c300d1a39a4e36f63a518ef36e4b966c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/Kconfig
#	arch/x86/entry/vdso/vma.c
#	arch/x86/include/asm/mshyperv.h
#	arch/x86/include/asm/vdso/gettimeofday.h
#	arch/x86/include/asm/vdso/vsyscall.h
#	arch/x86/kernel/kvmclock.c
#	arch/x86/kernel/tsc.c
#	arch/x86/xen/time.c
diff --cc arch/x86/Kconfig
index 3fc0a4c91af5,698e9c835cc5..000000000000
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@@ -57,10 -56,8 +57,14 @@@ config X8
  	#
  	select ACPI_LEGACY_TABLES_LOOKUP	if ACPI
  	select ACPI_SYSTEM_POWER_STATES_SUPPORT	if ACPI
++<<<<<<< HEAD
 +	select ANON_INODES
 +	select ARCH_CLOCKSOURCE_DATA
++=======
+ 	select ARCH_32BIT_OFF_T			if X86_32
++>>>>>>> b95a8a27c300 (x86/vdso: Use generic VDSO clock mode storage)
  	select ARCH_CLOCKSOURCE_INIT
 +	select ARCH_DISCARD_MEMBLOCK
  	select ARCH_HAS_ACPI_TABLE_UPGRADE	if ACPI
  	select ARCH_HAS_DEBUG_VIRTUAL
  	select ARCH_HAS_DEVMEM_IS_ALLOWED
@@@ -127,7 -124,10 +131,14 @@@
  	select GENERIC_STRNCPY_FROM_USER
  	select GENERIC_STRNLEN_USER
  	select GENERIC_TIME_VSYSCALL
++<<<<<<< HEAD
 +	select HARDIRQS_SW_RESEND
++=======
+ 	select GENERIC_GETTIMEOFDAY
+ 	select GENERIC_VDSO_CLOCK_MODE
+ 	select GENERIC_VDSO_TIME_NS
+ 	select GUP_GET_PTE_LOW_HIGH		if X86_PAE
++>>>>>>> b95a8a27c300 (x86/vdso: Use generic VDSO clock mode storage)
  	select HARDLOCKUP_CHECK_TIMESTAMP	if X86_64
  	select HAVE_ACPI_APEI			if ACPI
  	select HAVE_ACPI_APEI_NMI		if ACPI
diff --cc arch/x86/entry/vdso/vma.c
index 6a5ebfebd133,43428cc514c8..000000000000
--- a/arch/x86/entry/vdso/vma.c
+++ b/arch/x86/entry/vdso/vma.c
@@@ -407,6 -447,8 +407,11 @@@ __setup("vdso=", vdso_setup)
  
  static int __init init_vdso(void)
  {
++<<<<<<< HEAD
++=======
+ 	BUILD_BUG_ON(VDSO_CLOCKMODE_MAX >= 32);
+ 
++>>>>>>> b95a8a27c300 (x86/vdso: Use generic VDSO clock mode storage)
  	init_vdso_image(&vdso_image_64);
  
  #ifdef CONFIG_X86_X32_ABI
diff --cc arch/x86/include/asm/mshyperv.h
index d893b0b8985e,edc2c581704a..000000000000
--- a/arch/x86/include/asm/mshyperv.h
+++ b/arch/x86/include/asm/mshyperv.h
@@@ -49,7 -46,9 +49,13 @@@ typedef int (*hyperv_fill_flush_list_fu
  #define hv_set_reference_tsc(val) \
  	wrmsrl(HV_X64_MSR_REFERENCE_TSC, val)
  #define hv_set_clocksource_vdso(val) \
++<<<<<<< HEAD
 +	((val).archdata.vclock_mode = VCLOCK_HVCLOCK)
++=======
+ 	((val).vdso_clock_mode = VDSO_CLOCKMODE_HVCLOCK)
+ #define hv_enable_vdso_clocksource() \
+ 	vclocks_set_used(VDSO_CLOCKMODE_HVCLOCK);
++>>>>>>> b95a8a27c300 (x86/vdso: Use generic VDSO clock mode storage)
  #define hv_get_raw_timer() rdtsc_ordered()
  
  void hyperv_callback_vector(void);
diff --cc arch/x86/kernel/kvmclock.c
index 04021fb87d29,34b18f6eeb2c..000000000000
--- a/arch/x86/kernel/kvmclock.c
+++ b/arch/x86/kernel/kvmclock.c
@@@ -159,6 -159,12 +159,15 @@@ bool kvm_check_and_clear_guest_paused(v
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ static int kvm_cs_enable(struct clocksource *cs)
+ {
+ 	vclocks_set_used(VDSO_CLOCKMODE_PVCLOCK);
+ 	return 0;
+ }
+ 
++>>>>>>> b95a8a27c300 (x86/vdso: Use generic VDSO clock mode storage)
  struct clocksource kvm_clock = {
  	.name	= "kvm-clock",
  	.read	= kvm_clock_get_cycles,
diff --cc arch/x86/kernel/tsc.c
index 0c4803b7fa8d,971d6f0216df..000000000000
--- a/arch/x86/kernel/tsc.c
+++ b/arch/x86/kernel/tsc.c
@@@ -1090,17 -1108,24 +1090,31 @@@ static void tsc_cs_tick_stable(struct c
  		sched_clock_tick_stable();
  }
  
++<<<<<<< HEAD
++=======
+ static int tsc_cs_enable(struct clocksource *cs)
+ {
+ 	vclocks_set_used(VDSO_CLOCKMODE_TSC);
+ 	return 0;
+ }
+ 
++>>>>>>> b95a8a27c300 (x86/vdso: Use generic VDSO clock mode storage)
  /*
   * .mask MUST be CLOCKSOURCE_MASK(64). See comment above read_tsc()
   */
  static struct clocksource clocksource_tsc_early = {
 -	.name			= "tsc-early",
 -	.rating			= 299,
 -	.read			= read_tsc,
 -	.mask			= CLOCKSOURCE_MASK(64),
 -	.flags			= CLOCK_SOURCE_IS_CONTINUOUS |
 +	.name                   = "tsc-early",
 +	.rating                 = 299,
 +	.read                   = read_tsc,
 +	.mask                   = CLOCKSOURCE_MASK(64),
 +	.flags                  = CLOCK_SOURCE_IS_CONTINUOUS |
  				  CLOCK_SOURCE_MUST_VERIFY,
++<<<<<<< HEAD
 +	.archdata               = { .vclock_mode = VCLOCK_TSC },
++=======
+ 	.vdso_clock_mode	= VDSO_CLOCKMODE_TSC,
+ 	.enable			= tsc_cs_enable,
++>>>>>>> b95a8a27c300 (x86/vdso: Use generic VDSO clock mode storage)
  	.resume			= tsc_resume,
  	.mark_unstable		= tsc_cs_mark_unstable,
  	.tick_stable		= tsc_cs_tick_stable,
@@@ -1113,14 -1138,15 +1127,19 @@@
   * been found good.
   */
  static struct clocksource clocksource_tsc = {
 -	.name			= "tsc",
 -	.rating			= 300,
 -	.read			= read_tsc,
 -	.mask			= CLOCKSOURCE_MASK(64),
 -	.flags			= CLOCK_SOURCE_IS_CONTINUOUS |
 +	.name                   = "tsc",
 +	.rating                 = 300,
 +	.read                   = read_tsc,
 +	.mask                   = CLOCKSOURCE_MASK(64),
 +	.flags                  = CLOCK_SOURCE_IS_CONTINUOUS |
  				  CLOCK_SOURCE_VALID_FOR_HRES |
  				  CLOCK_SOURCE_MUST_VERIFY,
++<<<<<<< HEAD
 +	.archdata               = { .vclock_mode = VCLOCK_TSC },
++=======
+ 	.vdso_clock_mode	= VDSO_CLOCKMODE_TSC,
+ 	.enable			= tsc_cs_enable,
++>>>>>>> b95a8a27c300 (x86/vdso: Use generic VDSO clock mode storage)
  	.resume			= tsc_resume,
  	.mark_unstable		= tsc_cs_mark_unstable,
  	.tick_stable		= tsc_cs_tick_stable,
diff --cc arch/x86/xen/time.c
index e0f1bcf01d63,c8897aad13cd..000000000000
--- a/arch/x86/xen/time.c
+++ b/arch/x86/xen/time.c
@@@ -138,12 -145,19 +138,21 @@@ static struct notifier_block xen_pvcloc
  	.notifier_call = xen_pvclock_gtod_notify,
  };
  
++<<<<<<< HEAD
++=======
+ static int xen_cs_enable(struct clocksource *cs)
+ {
+ 	vclocks_set_used(VDSO_CLOCKMODE_PVCLOCK);
+ 	return 0;
+ }
+ 
++>>>>>>> b95a8a27c300 (x86/vdso: Use generic VDSO clock mode storage)
  static struct clocksource xen_clocksource __read_mostly = {
 -	.name	= "xen",
 -	.rating	= 400,
 -	.read	= xen_clocksource_get_cycles,
 -	.mask	= CLOCKSOURCE_MASK(64),
 -	.flags	= CLOCK_SOURCE_IS_CONTINUOUS,
 -	.enable = xen_cs_enable,
 +	.name = "xen",
 +	.rating = 400,
 +	.read = xen_clocksource_get_cycles,
 +	.mask = ~0,
 +	.flags = CLOCK_SOURCE_IS_CONTINUOUS,
  };
  
  /*
* Unmerged path arch/x86/include/asm/vdso/gettimeofday.h
* Unmerged path arch/x86/include/asm/vdso/vsyscall.h
* Unmerged path arch/x86/Kconfig
* Unmerged path arch/x86/entry/vdso/vma.c
diff --git a/arch/x86/include/asm/clocksource.h b/arch/x86/include/asm/clocksource.h
index dc4cfc888d6d..7c728b1941b0 100644
--- a/arch/x86/include/asm/clocksource.h
+++ b/arch/x86/include/asm/clocksource.h
@@ -4,14 +4,9 @@
 #ifndef _ASM_X86_CLOCKSOURCE_H
 #define _ASM_X86_CLOCKSOURCE_H
 
-#define VCLOCK_NONE	0	/* No vDSO clock available.		*/
-#define VCLOCK_TSC	1	/* vDSO should use vread_tsc.		*/
-#define VCLOCK_PVCLOCK	2	/* vDSO should use vread_pvclock.	*/
-#define VCLOCK_HVCLOCK	3	/* vDSO should use vread_hvclock.	*/
-#define VCLOCK_MAX	3
-
-struct arch_clocksource_data {
-	int vclock_mode;
-};
+#define VDSO_ARCH_CLOCKMODES	\
+	VDSO_CLOCKMODE_TSC,	\
+	VDSO_CLOCKMODE_PVCLOCK,	\
+	VDSO_CLOCKMODE_HVCLOCK
 
 #endif /* _ASM_X86_CLOCKSOURCE_H */
* Unmerged path arch/x86/include/asm/mshyperv.h
* Unmerged path arch/x86/include/asm/vdso/gettimeofday.h
* Unmerged path arch/x86/include/asm/vdso/vsyscall.h
* Unmerged path arch/x86/kernel/kvmclock.c
diff --git a/arch/x86/kernel/pvclock.c b/arch/x86/kernel/pvclock.c
index 9b158b4716d2..7ce90d5206e8 100644
--- a/arch/x86/kernel/pvclock.c
+++ b/arch/x86/kernel/pvclock.c
@@ -156,7 +156,7 @@ void pvclock_read_wallclock(struct pvclock_wall_clock *wall_clock,
 
 void pvclock_set_pvti_cpu0_va(struct pvclock_vsyscall_time_info *pvti)
 {
-	WARN_ON(vclock_was_used(VCLOCK_PVCLOCK));
+	WARN_ON(vclock_was_used(VDSO_CLOCKMODE_PVCLOCK));
 	pvti_cpu0_va = pvti;
 }
 
diff --git a/arch/x86/kernel/time.c b/arch/x86/kernel/time.c
index d8673d8a779b..4d545db52efc 100644
--- a/arch/x86/kernel/time.c
+++ b/arch/x86/kernel/time.c
@@ -122,18 +122,12 @@ void __init time_init(void)
  */
 void clocksource_arch_init(struct clocksource *cs)
 {
-	if (cs->archdata.vclock_mode == VCLOCK_NONE)
+	if (cs->vdso_clock_mode == VDSO_CLOCKMODE_NONE)
 		return;
 
-	if (cs->archdata.vclock_mode > VCLOCK_MAX) {
-		pr_warn("clocksource %s registered with invalid vclock_mode %d. Disabling vclock.\n",
-			cs->name, cs->archdata.vclock_mode);
-		cs->archdata.vclock_mode = VCLOCK_NONE;
-	}
-
 	if (cs->mask != CLOCKSOURCE_MASK(64)) {
-		pr_warn("clocksource %s registered with invalid mask %016llx. Disabling vclock.\n",
+		pr_warn("clocksource %s registered with invalid mask %016llx for VDSO. Disabling VDSO support.\n",
 			cs->name, cs->mask);
-		cs->archdata.vclock_mode = VCLOCK_NONE;
+		cs->vdso_clock_mode = VDSO_CLOCKMODE_NONE;
 	}
 }
* Unmerged path arch/x86/kernel/tsc.c
diff --git a/arch/x86/kvm/trace.h b/arch/x86/kvm/trace.h
index 157fce4acda6..54a10c98d746 100644
--- a/arch/x86/kvm/trace.h
+++ b/arch/x86/kvm/trace.h
@@ -823,8 +823,8 @@ TRACE_EVENT(kvm_write_tsc_offset,
 #ifdef CONFIG_X86_64
 
 #define host_clocks					\
-	{VCLOCK_NONE, "none"},				\
-	{VCLOCK_TSC,  "tsc"}				\
+	{VDSO_CLOCKMODE_NONE, "none"},			\
+	{VDSO_CLOCKMODE_TSC,  "tsc"}			\
 
 TRACE_EVENT(kvm_update_master_clock,
 	TP_PROTO(bool use_master_clock, unsigned int host_clock, bool offset_matched),
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index b686a6a17c93..5c43831c0802 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -1692,7 +1692,7 @@ static void update_pvclock_gtod(struct timekeeper *tk)
 	write_seqcount_begin(&vdata->seq);
 
 	/* copy pvclock gtod data */
-	vdata->clock.vclock_mode	= tk->tkr_mono.clock->archdata.vclock_mode;
+	vdata->clock.vclock_mode	= tk->tkr_mono.clock->vdso_clock_mode;
 	vdata->clock.cycle_last		= tk->tkr_mono.cycle_last;
 	vdata->clock.mask		= tk->tkr_mono.mask;
 	vdata->clock.mult		= tk->tkr_mono.mult;
@@ -1700,7 +1700,7 @@ static void update_pvclock_gtod(struct timekeeper *tk)
 	vdata->clock.base_cycles	= tk->tkr_mono.xtime_nsec;
 	vdata->clock.offset		= tk->tkr_mono.base;
 
-	vdata->raw_clock.vclock_mode	= tk->tkr_raw.clock->archdata.vclock_mode;
+	vdata->raw_clock.vclock_mode	= tk->tkr_raw.clock->vdso_clock_mode;
 	vdata->raw_clock.cycle_last	= tk->tkr_raw.cycle_last;
 	vdata->raw_clock.mask		= tk->tkr_raw.mask;
 	vdata->raw_clock.mult		= tk->tkr_raw.mult;
@@ -1901,7 +1901,7 @@ static u64 compute_guest_tsc(struct kvm_vcpu *vcpu, s64 kernel_ns)
 
 static inline int gtod_is_based_on_tsc(int mode)
 {
-	return mode == VCLOCK_TSC || mode == VCLOCK_HVCLOCK;
+	return mode == VDSO_CLOCKMODE_TSC || mode == VDSO_CLOCKMODE_HVCLOCK;
 }
 
 static void kvm_track_tsc_matching(struct kvm_vcpu *vcpu)
@@ -1993,7 +1993,7 @@ static inline bool kvm_check_tsc_unstable(void)
 	 * TSC is marked unstable when we're running on Hyper-V,
 	 * 'TSC page' clocksource is good.
 	 */
-	if (pvclock_gtod_data.clock.vclock_mode == VCLOCK_HVCLOCK)
+	if (pvclock_gtod_data.clock.vclock_mode == VDSO_CLOCKMODE_HVCLOCK)
 		return false;
 #endif
 	return check_tsc_unstable();
@@ -2148,30 +2148,30 @@ static inline u64 vgettsc(struct pvclock_clock *clock, u64 *tsc_timestamp,
 	u64 tsc_pg_val;
 
 	switch (clock->vclock_mode) {
-	case VCLOCK_HVCLOCK:
+	case VDSO_CLOCKMODE_HVCLOCK:
 		tsc_pg_val = hv_read_tsc_page_tsc(hv_get_tsc_page(),
 						  tsc_timestamp);
 		if (tsc_pg_val != U64_MAX) {
 			/* TSC page valid */
-			*mode = VCLOCK_HVCLOCK;
+			*mode = VDSO_CLOCKMODE_HVCLOCK;
 			v = (tsc_pg_val - clock->cycle_last) &
 				clock->mask;
 		} else {
 			/* TSC page invalid */
-			*mode = VCLOCK_NONE;
+			*mode = VDSO_CLOCKMODE_NONE;
 		}
 		break;
-	case VCLOCK_TSC:
-		*mode = VCLOCK_TSC;
+	case VDSO_CLOCKMODE_TSC:
+		*mode = VDSO_CLOCKMODE_TSC;
 		*tsc_timestamp = read_tsc();
 		v = (*tsc_timestamp - clock->cycle_last) &
 			clock->mask;
 		break;
 	default:
-		*mode = VCLOCK_NONE;
+		*mode = VDSO_CLOCKMODE_NONE;
 	}
 
-	if (*mode == VCLOCK_NONE)
+	if (*mode == VDSO_CLOCKMODE_NONE)
 		*tsc_timestamp = v = 0;
 
 	return v * clock->mult;
* Unmerged path arch/x86/xen/time.c
