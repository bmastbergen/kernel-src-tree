tcp: merge 'init_req' and 'route_req' functions

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Florian Westphal <fw@strlen.de>
commit 7ea851d19b23593d7601ecb8091d529f4f475bf5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/7ea851d1.failed

The Multipath-TCP standard (RFC 8684) says that an MPTCP host should send
a TCP reset if the token in a MP_JOIN request is unknown.

At this time we don't do this, the 3whs completes and the 'new subflow'
is reset afterwards.  There are two ways to allow MPTCP to send the
reset.

1. override 'send_synack' callback and emit the rst from there.
   The drawback is that the request socket gets inserted into the
   listeners queue just to get removed again right away.

2. Send the reset from the 'route_req' function instead.
   This avoids the 'add&remove request socket', but route_req lacks the
   skb that is required to send the TCP reset.

Instead of just adding the skb to that function for MPTCP sake alone,
Paolo suggested to merge init_req and route_req functions.

This saves one indirection from syn processing path and provides the skb
to the merged function at the same time.

'send reset on unknown mptcp join token' is added in next patch.

	Suggested-by: Paolo Abeni <pabeni@redhat.com>
	Cc: Eric Dumazet <edumazet@google.com>
	Signed-off-by: Florian Westphal <fw@strlen.de>
	Signed-off-by: Jakub Kicinski <kuba@kernel.org>
(cherry picked from commit 7ea851d19b23593d7601ecb8091d529f4f475bf5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/mptcp/subflow.c
diff --cc net/mptcp/subflow.c
index 7eeb71b1861e,727e607f40d2..000000000000
--- a/net/mptcp/subflow.c
+++ b/net/mptcp/subflow.c
@@@ -193,15 -185,64 +193,70 @@@ static void subflow_init_req(struct req
  	}
  }
  
++<<<<<<< HEAD
 +static void subflow_v4_init_req(struct request_sock *req,
 +				const struct sock *sk_listener,
 +				struct sk_buff *skb)
++=======
+ int mptcp_subflow_init_cookie_req(struct request_sock *req,
+ 				  const struct sock *sk_listener,
+ 				  struct sk_buff *skb)
  {
+ 	struct mptcp_subflow_context *listener = mptcp_subflow_ctx(sk_listener);
+ 	struct mptcp_subflow_request_sock *subflow_req = mptcp_subflow_rsk(req);
+ 	struct mptcp_options_received mp_opt;
+ 	int err;
+ 
+ 	err = __subflow_init_req(req, sk_listener);
+ 	if (err)
+ 		return err;
+ 
+ 	mptcp_get_options(skb, &mp_opt);
+ 
+ 	if (mp_opt.mp_capable && mp_opt.mp_join)
+ 		return -EINVAL;
+ 
+ 	if (mp_opt.mp_capable && listener->request_mptcp) {
+ 		if (mp_opt.sndr_key == 0)
+ 			return -EINVAL;
+ 
+ 		subflow_req->local_key = mp_opt.rcvr_key;
+ 		err = mptcp_token_new_request(req);
+ 		if (err)
+ 			return err;
+ 
+ 		subflow_req->mp_capable = 1;
+ 		subflow_req->ssn_offset = TCP_SKB_CB(skb)->seq - 1;
+ 	} else if (mp_opt.mp_join && listener->request_mptcp) {
+ 		if (!mptcp_token_join_cookie_init_state(subflow_req, skb))
+ 			return -EINVAL;
+ 
+ 		if (mptcp_can_accept_new_subflow(subflow_req->msk))
+ 			subflow_req->mp_join = 1;
+ 
+ 		subflow_req->ssn_offset = TCP_SKB_CB(skb)->seq - 1;
+ 	}
+ 
+ 	return 0;
+ }
+ EXPORT_SYMBOL_GPL(mptcp_subflow_init_cookie_req);
+ 
+ static struct dst_entry *subflow_v4_route_req(const struct sock *sk,
+ 					      struct sk_buff *skb,
+ 					      struct flowi *fl,
+ 					      struct request_sock *req)
++>>>>>>> 7ea851d19b23 (tcp: merge 'init_req' and 'route_req' functions)
+ {
+ 	struct dst_entry *dst;
+ 
  	tcp_rsk(req)->is_mptcp = 1;
  
- 	tcp_request_sock_ipv4_ops.init_req(req, sk_listener, skb);
+ 	dst = tcp_request_sock_ipv4_ops.route_req(sk, skb, fl, req);
+ 	if (!dst)
+ 		return NULL;
  
- 	subflow_init_req(req, sk_listener, skb);
+ 	subflow_init_req(req, sk, skb);
+ 	return dst;
  }
  
  #if IS_ENABLED(CONFIG_MPTCP_IPV6)
diff --git a/include/net/tcp.h b/include/net/tcp.h
index 19b590b7db75..a1d4af7a97f4 100644
--- a/include/net/tcp.h
+++ b/include/net/tcp.h
@@ -1951,15 +1951,14 @@ struct tcp_request_sock_ops {
 					  const struct sock *sk,
 					  const struct sk_buff *skb);
 #endif
-	void (*init_req)(struct request_sock *req,
-			 const struct sock *sk_listener,
-			 struct sk_buff *skb);
 #ifdef CONFIG_SYN_COOKIES
 	__u32 (*cookie_init_seq)(const struct sk_buff *skb,
 				 __u16 *mss);
 #endif
-	struct dst_entry *(*route_req)(const struct sock *sk, struct flowi *fl,
-				       const struct request_sock *req);
+	struct dst_entry *(*route_req)(const struct sock *sk,
+				       struct sk_buff *skb,
+				       struct flowi *fl,
+				       struct request_sock *req);
 	u32 (*init_seq)(const struct sk_buff *skb);
 	u32 (*init_ts_off)(const struct net *net, const struct sk_buff *skb);
 	int (*send_synack)(const struct sock *sk, struct dst_entry *dst,
diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
index 6542b07d9471..3f695c903d60 100644
--- a/net/ipv4/tcp_input.c
+++ b/net/ipv4/tcp_input.c
@@ -6563,18 +6563,13 @@ int tcp_conn_request(struct request_sock_ops *rsk_ops,
 	/* Note: tcp_v6_init_req() might override ir_iif for link locals */
 	inet_rsk(req)->ir_iif = inet_request_bound_dev_if(sk, skb);
 
-	af_ops->init_req(req, sk, skb);
-
-	if (security_inet_conn_request(sk, skb, req))
+	dst = af_ops->route_req(sk, skb, &fl, req);
+	if (!dst)
 		goto drop_and_free;
 
 	if (tmp_opt.tstamp_ok)
 		tcp_rsk(req)->ts_off = af_ops->init_ts_off(net, skb);
 
-	dst = af_ops->route_req(sk, &fl, req);
-	if (!dst)
-		goto drop_and_free;
-
 	if (!want_cookie && !isn) {
 		/* Kill the following clause, if you dislike this way. */
 		if (!net->ipv4.sysctl_tcp_syncookies &&
diff --git a/net/ipv4/tcp_ipv4.c b/net/ipv4/tcp_ipv4.c
index 6d045fe0871a..a762a5ca33b8 100644
--- a/net/ipv4/tcp_ipv4.c
+++ b/net/ipv4/tcp_ipv4.c
@@ -1357,9 +1357,15 @@ static void tcp_v4_init_req(struct request_sock *req,
 }
 
 static struct dst_entry *tcp_v4_route_req(const struct sock *sk,
+					  struct sk_buff *skb,
 					  struct flowi *fl,
-					  const struct request_sock *req)
+					  struct request_sock *req)
 {
+	tcp_v4_init_req(req, sk, skb);
+
+	if (security_inet_conn_request(sk, skb, req))
+		return NULL;
+
 	return inet_csk_route_req(sk, &fl->u.ip4, req);
 }
 
@@ -1379,7 +1385,6 @@ const struct tcp_request_sock_ops tcp_request_sock_ipv4_ops = {
 	.req_md5_lookup	=	tcp_v4_md5_lookup,
 	.calc_md5_hash	=	tcp_v4_md5_hash_skb,
 #endif
-	.init_req	=	tcp_v4_init_req,
 #ifdef CONFIG_SYN_COOKIES
 	.cookie_init_seq =	cookie_v4_init_sequence,
 #endif
diff --git a/net/ipv6/tcp_ipv6.c b/net/ipv6/tcp_ipv6.c
index f6c6f74cd9bc..2bec95bb25be 100644
--- a/net/ipv6/tcp_ipv6.c
+++ b/net/ipv6/tcp_ipv6.c
@@ -761,9 +761,15 @@ static void tcp_v6_init_req(struct request_sock *req,
 }
 
 static struct dst_entry *tcp_v6_route_req(const struct sock *sk,
+					  struct sk_buff *skb,
 					  struct flowi *fl,
-					  const struct request_sock *req)
+					  struct request_sock *req)
 {
+	tcp_v6_init_req(req, sk, skb);
+
+	if (security_inet_conn_request(sk, skb, req))
+		return NULL;
+
 	return inet6_csk_route_req(sk, &fl->u.ip6, req, IPPROTO_TCP);
 }
 
@@ -784,7 +790,6 @@ const struct tcp_request_sock_ops tcp_request_sock_ipv6_ops = {
 	.req_md5_lookup	=	tcp_v6_md5_lookup,
 	.calc_md5_hash	=	tcp_v6_md5_hash_skb,
 #endif
-	.init_req	=	tcp_v6_init_req,
 #ifdef CONFIG_SYN_COOKIES
 	.cookie_init_seq =	cookie_v6_init_sequence,
 #endif
* Unmerged path net/mptcp/subflow.c
