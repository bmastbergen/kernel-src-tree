mm/khugepaged: fix the xas_create_range() error path

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Hugh Dickins <hughd@google.com>
commit 95feeabb77149f7d48f05bde61d75621c57db67e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/95feeabb.failed

collapse_shmem()'s xas_nomem() is very unlikely to fail, but it is
rightly given a failure path, so move the whole xas_create_range() block
up before __SetPageLocked(new_page): so that it does not need to
remember to unlock_page(new_page).

Add the missing mem_cgroup_cancel_charge(), and set (currently unused)
result to SCAN_FAIL rather than SCAN_SUCCEED.

Link: http://lkml.kernel.org/r/alpine.LSU.2.11.1811261531200.2275@eggly.anvils
Fixes: 77da9389b9d5 ("mm: Convert collapse_shmem to XArray")
	Signed-off-by: Hugh Dickins <hughd@kernel.org>
	Cc: Matthew Wilcox <willy@infradead.org>
	Cc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
	Cc: Jerome Glisse <jglisse@redhat.com>
	Cc: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 95feeabb77149f7d48f05bde61d75621c57db67e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/khugepaged.c
diff --cc mm/khugepaged.c
index 2b8823d267fb,8e2ff195ecb3..000000000000
--- a/mm/khugepaged.c
+++ b/mm/khugepaged.c
@@@ -1333,47 -1329,59 +1333,93 @@@ static void collapse_shmem(struct mm_st
  		goto out;
  	}
  
++<<<<<<< HEAD
++=======
+ 	/* This will be less messy when we use multi-index entries */
+ 	do {
+ 		xas_lock_irq(&xas);
+ 		xas_create_range(&xas);
+ 		if (!xas_error(&xas))
+ 			break;
+ 		xas_unlock_irq(&xas);
+ 		if (!xas_nomem(&xas, GFP_KERNEL)) {
+ 			mem_cgroup_cancel_charge(new_page, memcg, true);
+ 			result = SCAN_FAIL;
+ 			goto out;
+ 		}
+ 	} while (1);
+ 
+ 	__SetPageLocked(new_page);
+ 	__SetPageSwapBacked(new_page);
++>>>>>>> 95feeabb7714 (mm/khugepaged: fix the xas_create_range() error path)
  	new_page->index = start;
  	new_page->mapping = mapping;
 +	__SetPageSwapBacked(new_page);
 +	__SetPageLocked(new_page);
 +	BUG_ON(!page_ref_freeze(new_page, 1));
 +
  
  	/*
 -	 * At this point the new_page is locked and not up-to-date.
 -	 * It's safe to insert it into the page cache, because nobody would
 -	 * be able to map it or use it in another way until we unlock it.
 +	 * At this point the new_page is 'frozen' (page_count() is zero), locked
 +	 * and not up-to-date. It's safe to insert it into radix tree, because
 +	 * nobody would be able to map it or use it in other way until we
 +	 * unfreeze it.
  	 */
  
++<<<<<<< HEAD
 +	index = start;
 +	xa_lock_irq(&mapping->i_pages);
 +	radix_tree_for_each_slot(slot, &mapping->i_pages, &iter, start) {
 +		int n = min(iter.index, end) - index;
 +
 +		/*
 +		 * Handle holes in the radix tree: charge it from shmem and
 +		 * insert relevant subpage of new_page into the radix-tree.
 +		 */
 +		if (n && !shmem_charge(mapping->host, n)) {
 +			result = SCAN_FAIL;
 +			break;
 +		}
 +		nr_none += n;
 +		for (; index < min(iter.index, end); index++) {
 +			radix_tree_insert(&mapping->i_pages, index,
 +					new_page + (index % HPAGE_PMD_NR));
++=======
+ 	xas_set(&xas, start);
+ 	for (index = start; index < end; index++) {
+ 		struct page *page = xas_next(&xas);
+ 
+ 		VM_BUG_ON(index != xas.xa_index);
+ 		if (!page) {
+ 			/*
+ 			 * Stop if extent has been truncated or hole-punched,
+ 			 * and is now completely empty.
+ 			 */
+ 			if (index == start) {
+ 				if (!xas_next_entry(&xas, end - 1)) {
+ 					result = SCAN_TRUNCATED;
+ 					goto xa_locked;
+ 				}
+ 				xas_set(&xas, index);
+ 			}
+ 			if (!shmem_charge(mapping->host, 1)) {
+ 				result = SCAN_FAIL;
+ 				goto xa_locked;
+ 			}
+ 			xas_store(&xas, new_page + (index % HPAGE_PMD_NR));
+ 			nr_none++;
+ 			continue;
++>>>>>>> 95feeabb7714 (mm/khugepaged: fix the xas_create_range() error path)
  		}
  
 +		/* We are done. */
 +		if (index >= end)
 +			break;
 +
 +		page = radix_tree_deref_slot_protected(slot,
 +				&mapping->i_pages.xa_lock);
  		if (xa_is_value(page) || !PageUptodate(page)) {
 -			xas_unlock_irq(&xas);
 +			xa_unlock_irq(&mapping->i_pages);
  			/* swap in or instantiate fallocated page */
  			if (shmem_getpage(mapping->host, index, &page,
  						SGP_NOHUGE)) {
* Unmerged path mm/khugepaged.c
