mm: move memcmp_pages() and pages_identical()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Song Liu <songliubraving@fb.com>
commit 010c164a5fa7e169deab0a4d8211611f1930c1cd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/010c164a.failed

Patch series "THP aware uprobe", v13.

This patchset makes uprobe aware of THPs.

Currently, when uprobe is attached to text on THP, the page is split by
FOLL_SPLIT.  As a result, uprobe eliminates the performance benefit of
THP.

This set makes uprobe THP-aware.  Instead of FOLL_SPLIT, we introduces
FOLL_SPLIT_PMD, which only split PMD for uprobe.

After all uprobes within the THP are removed, the PTE-mapped pages are
regrouped as huge PMD.

This set (plus a few THP patches) is also available at

   https://github.com/liu-song-6/linux/tree/uprobe-thp

This patch (of 6):

Move memcmp_pages() to mm/util.c and pages_identical() to mm.h, so that we
can use them in other files.

Link: http://lkml.kernel.org/r/20190815164525.1848545-2-songliubraving@fb.com
	Signed-off-by: Song Liu <songliubraving@fb.com>
	Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
	Reviewed-by: Oleg Nesterov <oleg@redhat.com>
	Cc: Johannes Weiner <hannes@cmpxchg.org>
	Cc: Matthew Wilcox <matthew.wilcox@oracle.com>
	Cc: William Kucharski <william.kucharski@oracle.com>
	Cc: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 010c164a5fa7e169deab0a4d8211611f1930c1cd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/mm.h
diff --cc include/linux/mm.h
index ef77bd76b21c,0ac87d9ee9d8..000000000000
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@@ -2742,17 -2868,12 +2742,26 @@@ void __init setup_nr_node_ids(void)
  static inline void setup_nr_node_ids(void) {}
  #endif
  
++<<<<<<< HEAD
 +#ifdef CONFIG_MAPPING_DIRTY_HELPERS
 +unsigned long clean_record_shared_mapping_range(struct address_space *mapping,
 +						pgoff_t first_index, pgoff_t nr,
 +						pgoff_t bitmap_pgoff,
 +						unsigned long *bitmap,
 +						pgoff_t *start,
 +						pgoff_t *end);
 +
 +unsigned long wp_shared_mapping_range(struct address_space *mapping,
 +				      pgoff_t first_index, pgoff_t nr);
 +#endif
++=======
+ extern int memcmp_pages(struct page *page1, struct page *page2);
+ 
+ static inline int pages_identical(struct page *page1, struct page *page2)
+ {
+ 	return !memcmp_pages(page1, page2);
+ }
++>>>>>>> 010c164a5fa7 (mm: move memcmp_pages() and pages_identical())
  
  #endif /* __KERNEL__ */
  #endif /* _LINUX_MM_H */
* Unmerged path include/linux/mm.h
diff --git a/mm/ksm.c b/mm/ksm.c
index b45b50bd58db..7daf3c6131ad 100644
--- a/mm/ksm.c
+++ b/mm/ksm.c
@@ -1014,24 +1014,6 @@ static u32 calc_checksum(struct page *page)
 	return checksum;
 }
 
-static int memcmp_pages(struct page *page1, struct page *page2)
-{
-	char *addr1, *addr2;
-	int ret;
-
-	addr1 = kmap_atomic(page1);
-	addr2 = kmap_atomic(page2);
-	ret = memcmp(addr1, addr2, PAGE_SIZE);
-	kunmap_atomic(addr2);
-	kunmap_atomic(addr1);
-	return ret;
-}
-
-static inline int pages_identical(struct page *page1, struct page *page2)
-{
-	return !memcmp_pages(page1, page2);
-}
-
 static int write_protect_page(struct vm_area_struct *vma, struct page *page,
 			      pte_t *orig_pte)
 {
diff --git a/mm/util.c b/mm/util.c
index e99de9d3c8ae..5abf246aaf4b 100644
--- a/mm/util.c
+++ b/mm/util.c
@@ -804,3 +804,16 @@ int get_cmdline(struct task_struct *task, char *buffer, int buflen)
 out:
 	return res;
 }
+
+int memcmp_pages(struct page *page1, struct page *page2)
+{
+	char *addr1, *addr2;
+	int ret;
+
+	addr1 = kmap_atomic(page1);
+	addr2 = kmap_atomic(page2);
+	ret = memcmp(addr1, addr2, PAGE_SIZE);
+	kunmap_atomic(addr2);
+	kunmap_atomic(addr1);
+	return ret;
+}
