block: provide a blk_rq_map_sg variant that returns the last element

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 89de1504d53b59b12bfff227328ee3e63dd3a112
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/89de1504.failed

To be able to move some of the special purpose hacks in blk_rq_map_sg
into the callers we need a variant that returns the last mapped
S/G list element to the caller.  Add that variant as __blk_rq_map_sg
and make blk_rq_map_sg a trivial inline wrapper around it.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 89de1504d53b59b12bfff227328ee3e63dd3a112)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-merge.c
diff --cc block/blk-merge.c
index 96b6e62209ca,ee618cdb141e..000000000000
--- a/block/blk-merge.c
+++ b/block/blk-merge.c
@@@ -461,12 -525,11 +461,17 @@@ int __blk_rq_map_sg(struct request_queu
  	int nsegs = 0;
  
  	if (rq->rq_flags & RQF_SPECIAL_PAYLOAD)
++<<<<<<< HEAD
 +		nsegs = __blk_bvec_map_sg(q, rq->special_vec, sglist, &sg);
 +	else if (rq->bio && bio_op(rq->bio) == REQ_OP_WRITE_SAME)
 +		nsegs = __blk_bvec_map_sg(q, bio_iovec(rq->bio), sglist, &sg);
++=======
+ 		nsegs = __blk_bvec_map_sg(rq->special_vec, sglist, last_sg);
+ 	else if (rq->bio && bio_op(rq->bio) == REQ_OP_WRITE_SAME)
+ 		nsegs = __blk_bvec_map_sg(bio_iovec(rq->bio), sglist, last_sg);
++>>>>>>> 89de1504d53b (block: provide a blk_rq_map_sg variant that returns the last element)
  	else if (rq->bio)
- 		nsegs = __blk_bios_map_sg(q, rq->bio, sglist, &sg);
+ 		nsegs = __blk_bios_map_sg(q, rq->bio, sglist, last_sg);
  
  	if (blk_rq_bytes(rq) && (blk_rq_bytes(rq) & q->dma_pad_mask)) {
  		unsigned int pad_len =
@@@ -501,25 -564,15 +506,25 @@@
  
  	return nsegs;
  }
- EXPORT_SYMBOL(blk_rq_map_sg);
+ EXPORT_SYMBOL(__blk_rq_map_sg);
  
 -static inline int ll_new_hw_segment(struct request *req, struct bio *bio,
 -		unsigned int nr_phys_segs)
 +static inline unsigned int blk_rq_get_max_segments(struct request *rq)
  {
 -	if (req->nr_phys_segments + nr_phys_segs > queue_max_segments(req->q))
 +	if (req_op(rq) == REQ_OP_DISCARD)
 +		return queue_max_discard_segments(rq->q);
 +	return queue_max_segments(rq->q);
 +}
 +
 +static inline int ll_new_hw_segment(struct request_queue *q,
 +				    struct request *req,
 +				    struct bio *bio)
 +{
 +	int nr_phys_segs = bio_phys_segments(q, bio);
 +
 +	if (req->nr_phys_segments + nr_phys_segs > blk_rq_get_max_segments(req))
  		goto no_merge;
  
 -	if (blk_integrity_merge_bio(req->q, req, bio) == false)
 +	if (blk_integrity_merge_bio(q, req, bio) == false)
  		goto no_merge;
  
  	/*
* Unmerged path block/blk-merge.c
diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
index 6140ddd995b0..a0501afb8f1a 100644
--- a/include/linux/blkdev.h
+++ b/include/linux/blkdev.h
@@ -1164,7 +1164,15 @@ static inline unsigned short blk_rq_nr_discard_segments(struct request *rq)
 	return max_t(unsigned short, rq->nr_phys_segments, 1);
 }
 
-extern int blk_rq_map_sg(struct request_queue *, struct request *, struct scatterlist *);
+int __blk_rq_map_sg(struct request_queue *q, struct request *rq,
+		struct scatterlist *sglist, struct scatterlist **last_sg);
+static inline int blk_rq_map_sg(struct request_queue *q, struct request *rq,
+		struct scatterlist *sglist)
+{
+	struct scatterlist *last_sg = NULL;
+
+	return __blk_rq_map_sg(q, rq, sglist, &last_sg);
+}
 extern void blk_dump_rq_flags(struct request *, char *);
 extern long nr_blockdev_pages(void);
 
