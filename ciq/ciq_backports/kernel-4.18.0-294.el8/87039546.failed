mm: swapoff: shmem_find_swap_entries() filter out other types

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Hugh Dickins <hughd@google.com>
commit 87039546544479d4bedb19d0ea525270c43c1c9b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/87039546.failed

Swapfile "type" was passed all the way down to shmem_unuse_inode(), but
then forgotten from shmem_find_swap_entries(): with the result that
removing one swapfile would try to free up all the swap from shmem - no
problem when only one swapfile anyway, but counter-productive when more,
causing swapoff to be unnecessarily OOM-killed when it should succeed.

Link: http://lkml.kernel.org/r/alpine.LSU.2.11.1904081254470.1523@eggly.anvils
Fixes: b56a2d8af914 ("mm: rid swapoff of quadratic complexity")
	Signed-off-by: Hugh Dickins <hughd@google.com>
	Cc: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
	Cc: "Alex Xu (Hello71)" <alex_y_xu@yahoo.ca>
	Cc: Vineeth Pillai <vpillai@digitalocean.com>
	Cc: Kelley Nielsen <kelleynnn@gmail.com>
	Cc: Rik van Riel <riel@surriel.com>
	Cc: Huang Ying <ying.huang@intel.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 87039546544479d4bedb19d0ea525270c43c1c9b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/shmem.c
diff --cc mm/shmem.c
index fd519560c907,859e8628071f..000000000000
--- a/mm/shmem.c
+++ b/mm/shmem.c
@@@ -1107,112 -1094,128 +1107,160 @@@ static void shmem_evict_inode(struct in
  	clear_inode(inode);
  }
  
++<<<<<<< HEAD
 +static unsigned long find_swap_entry(struct radix_tree_root *root, void *item)
 +{
 +	struct radix_tree_iter iter;
 +	void __rcu **slot;
 +	unsigned long found = -1;
 +	unsigned int checked = 0;
++=======
+ extern struct swap_info_struct *swap_info[];
+ 
+ static int shmem_find_swap_entries(struct address_space *mapping,
+ 				   pgoff_t start, unsigned int nr_entries,
+ 				   struct page **entries, pgoff_t *indices,
+ 				   unsigned int type, bool frontswap)
+ {
+ 	XA_STATE(xas, &mapping->i_pages, start);
+ 	struct page *page;
+ 	swp_entry_t entry;
+ 	unsigned int ret = 0;
+ 
+ 	if (!nr_entries)
+ 		return 0;
++>>>>>>> 870395465444 (mm: swapoff: shmem_find_swap_entries() filter out other types)
  
  	rcu_read_lock();
 -	xas_for_each(&xas, page, ULONG_MAX) {
 -		if (xas_retry(&xas, page))
 +	radix_tree_for_each_slot(slot, root, &iter, 0) {
 +		void *entry = radix_tree_deref_slot(slot);
 +
 +		if (radix_tree_deref_retry(entry)) {
 +			slot = radix_tree_iter_retry(&iter);
  			continue;
++<<<<<<< HEAD
 +		}
 +		if (entry == item) {
 +			found = iter.index;
++=======
+ 
+ 		if (!xa_is_value(page))
+ 			continue;
+ 
+ 		entry = radix_to_swp_entry(page);
+ 		if (swp_type(entry) != type)
+ 			continue;
+ 		if (frontswap &&
+ 		    !frontswap_test(swap_info[type], swp_offset(entry)))
+ 			continue;
+ 
+ 		indices[ret] = xas.xa_index;
+ 		entries[ret] = page;
+ 
+ 		if (need_resched()) {
+ 			xas_pause(&xas);
+ 			cond_resched_rcu();
+ 		}
+ 		if (++ret == nr_entries)
++>>>>>>> 870395465444 (mm: swapoff: shmem_find_swap_entries() filter out other types)
  			break;
 +		}
 +		checked++;
 +		if ((checked % 4096) != 0)
 +			continue;
 +		slot = radix_tree_iter_resume(slot, &iter);
 +		cond_resched_rcu();
  	}
 -	rcu_read_unlock();
  
 -	return ret;
 +	rcu_read_unlock();
 +	return found;
  }
  
  /*
 - * Move the swapped pages for an inode to page cache. Returns the count
 - * of pages swapped in, or the error in case of failure.
 + * If swap found in inode, free it and move page from swapcache to filecache.
   */
 -static int shmem_unuse_swap_entries(struct inode *inode, struct pagevec pvec,
 -				    pgoff_t *indices)
 +static int shmem_unuse_inode(struct shmem_inode_info *info,
 +			     swp_entry_t swap, struct page **pagep)
  {
 -	int i = 0;
 -	int ret = 0;
 +	struct address_space *mapping = info->vfs_inode.i_mapping;
 +	void *radswap;
 +	pgoff_t index;
 +	gfp_t gfp;
  	int error = 0;
 -	struct address_space *mapping = inode->i_mapping;
  
 -	for (i = 0; i < pvec.nr; i++) {
 -		struct page *page = pvec.pages[i];
 +	radswap = swp_to_radix_entry(swap);
 +	index = find_swap_entry(&mapping->i_pages, radswap);
 +	if (index == -1)
 +		return -EAGAIN;	/* tell shmem_unuse we found nothing */
  
 -		if (!xa_is_value(page))
 -			continue;
 -		error = shmem_swapin_page(inode, indices[i],
 -					  &page, SGP_CACHE,
 -					  mapping_gfp_mask(mapping),
 -					  NULL, NULL);
 -		if (error == 0) {
 -			unlock_page(page);
 -			put_page(page);
 -			ret++;
 -		}
 -		if (error == -ENOMEM)
 -			break;
 -		error = 0;
 -	}
 -	return error ? error : ret;
 -}
 -
 -/*
 - * If swap found in inode, free it and move page from swapcache to filecache.
 - */
 -static int shmem_unuse_inode(struct inode *inode, unsigned int type,
 -			     bool frontswap, unsigned long *fs_pages_to_unuse)
 -{
 -	struct address_space *mapping = inode->i_mapping;
 -	pgoff_t start = 0;
 -	struct pagevec pvec;
 -	pgoff_t indices[PAGEVEC_SIZE];
 -	bool frontswap_partial = (frontswap && *fs_pages_to_unuse > 0);
 -	int ret = 0;
 -
 -	pagevec_init(&pvec);
 -	do {
 -		unsigned int nr_entries = PAGEVEC_SIZE;
 +	/*
 +	 * Move _head_ to start search for next from here.
 +	 * But be careful: shmem_evict_inode checks list_empty without taking
 +	 * mutex, and there's an instant in list_move_tail when info->swaplist
 +	 * would appear empty, if it were the only one on shmem_swaplist.
 +	 */
 +	if (shmem_swaplist.next != &info->swaplist)
 +		list_move_tail(&shmem_swaplist, &info->swaplist);
  
 -		if (frontswap_partial && *fs_pages_to_unuse < PAGEVEC_SIZE)
 -			nr_entries = *fs_pages_to_unuse;
++<<<<<<< HEAD
 +	gfp = mapping_gfp_mask(mapping);
 +	if (shmem_should_replace_page(*pagep, gfp)) {
 +		mutex_unlock(&shmem_swaplist_mutex);
 +		error = shmem_replace_page(pagep, gfp, info, index);
 +		mutex_lock(&shmem_swaplist_mutex);
 +		/*
 +		 * We needed to drop mutex to make that restrictive page
 +		 * allocation, but the inode might have been freed while we
 +		 * dropped it: although a racing shmem_evict_inode() cannot
 +		 * complete without emptying the page cache, our page lock
 +		 * on this swapcache page is not enough to prevent that -
 +		 * free_swap_and_cache() of our swap entry will only
 +		 * trylock_page(), removing swap from page cache whatever.
 +		 *
 +		 * We must not proceed to shmem_add_to_page_cache() if the
 +		 * inode has been freed, but of course we cannot rely on
 +		 * inode or mapping or info to check that.  However, we can
 +		 * safely check if our swap entry is still in use (and here
 +		 * it can't have got reused for another page): if it's still
 +		 * in use, then the inode cannot have been freed yet, and we
 +		 * can safely proceed (if it's no longer in use, that tells
 +		 * nothing about the inode, but we don't need to unuse swap).
 +		 */
 +		if (!page_swapcount(*pagep))
 +			error = -ENOENT;
 +	}
  
 +	/*
 +	 * We rely on shmem_swaplist_mutex, not only to protect the swaplist,
 +	 * but also to hold up shmem_evict_inode(): so inode cannot be freed
 +	 * beneath us (pagelock doesn't help until the page is in pagecache).
 +	 */
 +	if (!error)
 +		error = shmem_add_to_page_cache(*pagep, mapping, index,
 +						radswap, gfp);
 +	if (error != -ENOMEM) {
 +		/*
 +		 * Truncation and eviction use free_swap_and_cache(), which
 +		 * only does trylock page: if we raced, best clean up here.
 +		 */
 +		delete_from_swap_cache(*pagep);
 +		set_page_dirty(*pagep);
 +		if (!error) {
 +			spin_lock_irq(&info->lock);
 +			info->swapped--;
 +			spin_unlock_irq(&info->lock);
 +			swap_free(swap);
++=======
+ 		pvec.nr = shmem_find_swap_entries(mapping, start, nr_entries,
+ 						  pvec.pages, indices,
+ 						  type, frontswap);
+ 		if (pvec.nr == 0) {
+ 			ret = 0;
+ 			break;
++>>>>>>> 870395465444 (mm: swapoff: shmem_find_swap_entries() filter out other types)
  		}
 -
 -		ret = shmem_unuse_swap_entries(inode, pvec, indices);
 -		if (ret < 0)
 -			break;
 -
 -		if (frontswap_partial) {
 -			*fs_pages_to_unuse -= ret;
 -			if (*fs_pages_to_unuse == 0) {
 -				ret = FRONTSWAP_PAGES_UNUSED;
 -				break;
 -			}
 -		}
 -
 -		start = indices[pvec.nr - 1];
 -	} while (true);
 -
 -	return ret;
 +	}
 +	return error;
  }
  
  /*
* Unmerged path mm/shmem.c
