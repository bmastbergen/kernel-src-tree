KVM: x86: use positive error values for msr emulation that causes #GP

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Maxim Levitsky <mlevitsk@redhat.com>
commit cc4cb017678aa66d3fb4501b2f7424ed28fc7f4d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/cc4cb017.failed

Recent introduction of the userspace msr filtering added code that uses
negative error codes for cases that result in either #GP delivery to
the guest, or handled by the userspace msr filtering.

This breaks an assumption that a negative error code returned from the
msr emulation code is a semi-fatal error which should be returned
to userspace via KVM_RUN ioctl and usually kill the guest.

Fix this by reusing the already existing KVM_MSR_RET_INVALID error code,
and by adding a new KVM_MSR_RET_FILTERED error code for the
userspace filtered msrs.

Fixes: 291f35fb2c1d1 ("KVM: x86: report negative values from wrmsr emulation to userspace")
	Reported-by: Qian Cai <cai@redhat.com>
	Signed-off-by: Maxim Levitsky <mlevitsk@redhat.com>
Message-Id: <20201101115523.115780-1-mlevitsk@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit cc4cb017678aa66d3fb4501b2f7424ed28fc7f4d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/x86.c
diff --cc arch/x86/kvm/x86.c
index c2403e53a8de,a4c59be8d566..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -1500,6 -1539,9 +1500,12 @@@ static int __kvm_set_msr(struct kvm_vcp
  {
  	struct msr_data msr;
  
++<<<<<<< HEAD
++=======
+ 	if (!host_initiated && !kvm_msr_allowed(vcpu, index, KVM_MSR_FILTER_WRITE))
+ 		return KVM_MSR_RET_FILTERED;
+ 
++>>>>>>> cc4cb017678a (KVM: x86: use positive error values for msr emulation that causes #GP)
  	switch (index) {
  	case MSR_FS_BASE:
  	case MSR_GS_BASE:
@@@ -1556,6 -1599,9 +1563,12 @@@ int __kvm_get_msr(struct kvm_vcpu *vcpu
  	struct msr_data msr;
  	int ret;
  
++<<<<<<< HEAD
++=======
+ 	if (!host_initiated && !kvm_msr_allowed(vcpu, index, KVM_MSR_FILTER_READ))
+ 		return KVM_MSR_RET_FILTERED;
+ 
++>>>>>>> cc4cb017678a (KVM: x86: use positive error values for msr emulation that causes #GP)
  	msr.index = index;
  	msr.host_initiated = host_initiated;
  
@@@ -1591,6 -1638,75 +1605,78 @@@ int kvm_set_msr(struct kvm_vcpu *vcpu, 
  }
  EXPORT_SYMBOL_GPL(kvm_set_msr);
  
++<<<<<<< HEAD
++=======
+ static int complete_emulated_msr(struct kvm_vcpu *vcpu, bool is_read)
+ {
+ 	if (vcpu->run->msr.error) {
+ 		kvm_inject_gp(vcpu, 0);
+ 		return 1;
+ 	} else if (is_read) {
+ 		kvm_rax_write(vcpu, (u32)vcpu->run->msr.data);
+ 		kvm_rdx_write(vcpu, vcpu->run->msr.data >> 32);
+ 	}
+ 
+ 	return kvm_skip_emulated_instruction(vcpu);
+ }
+ 
+ static int complete_emulated_rdmsr(struct kvm_vcpu *vcpu)
+ {
+ 	return complete_emulated_msr(vcpu, true);
+ }
+ 
+ static int complete_emulated_wrmsr(struct kvm_vcpu *vcpu)
+ {
+ 	return complete_emulated_msr(vcpu, false);
+ }
+ 
+ static u64 kvm_msr_reason(int r)
+ {
+ 	switch (r) {
+ 	case KVM_MSR_RET_INVALID:
+ 		return KVM_MSR_EXIT_REASON_UNKNOWN;
+ 	case KVM_MSR_RET_FILTERED:
+ 		return KVM_MSR_EXIT_REASON_FILTER;
+ 	default:
+ 		return KVM_MSR_EXIT_REASON_INVAL;
+ 	}
+ }
+ 
+ static int kvm_msr_user_space(struct kvm_vcpu *vcpu, u32 index,
+ 			      u32 exit_reason, u64 data,
+ 			      int (*completion)(struct kvm_vcpu *vcpu),
+ 			      int r)
+ {
+ 	u64 msr_reason = kvm_msr_reason(r);
+ 
+ 	/* Check if the user wanted to know about this MSR fault */
+ 	if (!(vcpu->kvm->arch.user_space_msr_mask & msr_reason))
+ 		return 0;
+ 
+ 	vcpu->run->exit_reason = exit_reason;
+ 	vcpu->run->msr.error = 0;
+ 	memset(vcpu->run->msr.pad, 0, sizeof(vcpu->run->msr.pad));
+ 	vcpu->run->msr.reason = msr_reason;
+ 	vcpu->run->msr.index = index;
+ 	vcpu->run->msr.data = data;
+ 	vcpu->arch.complete_userspace_io = completion;
+ 
+ 	return 1;
+ }
+ 
+ static int kvm_get_msr_user_space(struct kvm_vcpu *vcpu, u32 index, int r)
+ {
+ 	return kvm_msr_user_space(vcpu, index, KVM_EXIT_X86_RDMSR, 0,
+ 				   complete_emulated_rdmsr, r);
+ }
+ 
+ static int kvm_set_msr_user_space(struct kvm_vcpu *vcpu, u32 index, u64 data, int r)
+ {
+ 	return kvm_msr_user_space(vcpu, index, KVM_EXIT_X86_WRMSR, data,
+ 				   complete_emulated_wrmsr, r);
+ }
+ 
++>>>>>>> cc4cb017678a (KVM: x86: use positive error values for msr emulation that causes #GP)
  int kvm_emulate_rdmsr(struct kvm_vcpu *vcpu)
  {
  	u32 ecx = kvm_rcx_read(vcpu);
* Unmerged path arch/x86/kvm/x86.c
diff --git a/arch/x86/kvm/x86.h b/arch/x86/kvm/x86.h
index 9d742f062ef2..f9c45bfcb683 100644
--- a/arch/x86/kvm/x86.h
+++ b/arch/x86/kvm/x86.h
@@ -374,7 +374,13 @@ bool kvm_vcpu_exit_request(struct kvm_vcpu *vcpu);
 int kvm_handle_memory_failure(struct kvm_vcpu *vcpu, int r,
 			      struct x86_exception *e);
 
-#define  KVM_MSR_RET_INVALID  2
+/*
+ * Internal error codes that are used to indicate that MSR emulation encountered
+ * an error that should result in #GP in the guest, unless userspace
+ * handles it.
+ */
+#define  KVM_MSR_RET_INVALID	2	/* in-kernel MSR emulation #GP condition */
+#define  KVM_MSR_RET_FILTERED	3	/* #GP due to userspace MSR filter */
 
 #define __cr4_reserved_bits(__cpu_has, __c)             \
 ({                                                      \
