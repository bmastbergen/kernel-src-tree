mm, treewide: rename kzfree() to kfree_sensitive()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Waiman Long <longman@redhat.com>
commit 453431a54934d917153c65211b2dabf45562ca88
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/453431a5.failed

As said by Linus:

  A symmetric naming is only helpful if it implies symmetries in use.
  Otherwise it's actively misleading.

  In "kzalloc()", the z is meaningful and an important part of what the
  caller wants.

  In "kzfree()", the z is actively detrimental, because maybe in the
  future we really _might_ want to use that "memfill(0xdeadbeef)" or
  something. The "zero" part of the interface isn't even _relevant_.

The main reason that kzfree() exists is to clear sensitive information
that should not be leaked to other future users of the same memory
objects.

Rename kzfree() to kfree_sensitive() to follow the example of the recently
added kvfree_sensitive() and make the intention of the API more explicit.
In addition, memzero_explicit() is used to clear the memory to make sure
that it won't get optimized away by the compiler.

The renaming is done by using the command sequence:

  git grep -w --name-only kzfree |\
  xargs sed -i 's/kzfree/kfree_sensitive/'

followed by some editing of the kfree_sensitive() kerneldoc and adding
a kzfree backward compatibility macro in slab.h.

[akpm@linux-foundation.org: fs/crypto/inline_crypt.c needs linux/slab.h]
[akpm@linux-foundation.org: fix fs/crypto/inline_crypt.c some more]

	Suggested-by: Joe Perches <joe@perches.com>
	Signed-off-by: Waiman Long <longman@redhat.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Acked-by: David Howells <dhowells@redhat.com>
	Acked-by: Michal Hocko <mhocko@suse.com>
	Acked-by: Johannes Weiner <hannes@cmpxchg.org>
	Cc: Jarkko Sakkinen <jarkko.sakkinen@linux.intel.com>
	Cc: James Morris <jmorris@namei.org>
	Cc: "Serge E. Hallyn" <serge@hallyn.com>
	Cc: Joe Perches <joe@perches.com>
	Cc: Matthew Wilcox <willy@infradead.org>
	Cc: David Rientjes <rientjes@google.com>
	Cc: Dan Carpenter <dan.carpenter@oracle.com>
	Cc: "Jason A . Donenfeld" <Jason@zx2c4.com>
Link: http://lkml.kernel.org/r/20200616154311.12314-3-longman@redhat.com
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 453431a54934d917153c65211b2dabf45562ca88)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	crypto/adiantum.c
#	crypto/asymmetric_keys/verify_pefile.c
#	crypto/testmgr.c
#	drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c
#	drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c
#	drivers/crypto/amlogic/amlogic-gxl-cipher.c
#	drivers/crypto/cavium/cpt/cptvf_reqmanager.c
#	drivers/crypto/cavium/nitrox/nitrox_lib.c
#	drivers/crypto/ccree/cc_aead.c
#	drivers/crypto/ccree/cc_buffer_mgr.c
#	drivers/crypto/ccree/cc_cipher.c
#	drivers/crypto/ccree/cc_hash.c
#	drivers/crypto/marvell/hash.c
#	drivers/crypto/marvell/octeontx/otx_cptvf_main.c
#	drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h
#	drivers/crypto/virtio/virtio_crypto_algs.c
#	drivers/net/ppp/ppp_mppe.c
#	drivers/net/wireguard/noise.c
#	drivers/net/wireguard/peer.c
#	drivers/staging/ks7010/ks_hostif.c
#	drivers/staging/rtl8723bs/core/rtw_security.c
#	fs/crypto/inline_crypt.c
#	fs/crypto/keyring.c
#	fs/crypto/keysetup_v1.c
#	include/linux/slab.h
#	lib/test_kasan.c
#	net/atm/mpoa_caches.c
#	net/bluetooth/smp.c
#	net/ipv4/tcp_fastopen.c
#	net/mac802154/llsec.c
#	security/apparmor/policy.c
#	security/keys/encrypted-keys/encrypted.c
diff --cc crypto/asymmetric_keys/verify_pefile.c
index 1131c9a0a24a,7553ab18db89..000000000000
--- a/crypto/asymmetric_keys/verify_pefile.c
+++ b/crypto/asymmetric_keys/verify_pefile.c
@@@ -470,41 -427,26 +470,47 @@@ int verify_pefile_signature(const void 
  	if (ret < 0)
  		return ret;
  
 -	ret = pefile_strip_sig_wrapper(pebuf, &ctx);
 -	if (ret < 0)
 -		return ret;
 +	/* The pefile may have multiple signatures with different keys.
 +	 * pefile_parse_binary set the context to the first signature
 +	 * and pefile_next_sig advances the context to potential next.
 +	 */
 +	do {
 +		ret = pefile_strip_sig_wrapper(pebuf, &ctx);
 +		if (ret < 0)
 +			return ret;
  
 -	ret = verify_pkcs7_signature(NULL, 0,
 -				     pebuf + ctx.sig_offset, ctx.sig_len,
 -				     trusted_keys, usage,
 -				     mscode_parse, &ctx);
 -	if (ret < 0)
 -		goto error;
++<<<<<<< HEAD
 +		ret = verify_pkcs7_signature(NULL, 0,
 +					     pebuf + ctx.sig_offset,
 +					     ctx.sig_len,
 +					     trusted_keys, usage,
 +					     mscode_parse, &ctx);
 +		if (ret < 0) {
 +			kfree(ctx.digest);
 +			ctx.digest = NULL;
 +			if (ret == -ENOKEY)
 +				continue;
 +			return ret;
 +		}
  
 -	pr_debug("Digest: %u [%*ph]\n",
 -		 ctx.digest_len, ctx.digest_len, ctx.digest);
 +		pr_debug("Digest: %u [%*ph]\n",
 +			 ctx.digest_len, ctx.digest_len, ctx.digest);
  
 -	/* Generate the digest and check against the PKCS7 certificate
 -	 * contents.
 -	 */
 -	ret = pefile_digest_pe(pebuf, pelen, &ctx);
 +		/* Generate the digest and check against the PKCS7 certificate
 +		 * contents.
 +		 */
 +		ret_final = pefile_digest_pe(pebuf, pelen, &ctx);
 +		kfree(ctx.digest);
 +		ctx.digest = NULL;
 +		if (ret_final < 0)
 +			return ret_final;
 +
 +	} while (pefile_next_sig(&ctx));
  
 +	return ret_final;
++=======
+ error:
+ 	kfree_sensitive(ctx.digest);
+ 	return ret;
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  }
diff --cc crypto/testmgr.c
index aa31592f25b8,23c27fc96394..000000000000
--- a/crypto/testmgr.c
+++ b/crypto/testmgr.c
@@@ -172,10 -190,2136 +172,2140 @@@ static void testmgr_free_buf(char *buf[
  	int i;
  
  	for (i = 0; i < XBUFSIZE; i++)
 -		free_pages((unsigned long)buf[i], order);
 +		free_page((unsigned long)buf[i]);
  }
  
++<<<<<<< HEAD
 +static int ahash_guard_result(char *result, char c, int size)
++=======
+ static void testmgr_free_buf(char *buf[XBUFSIZE])
+ {
+ 	__testmgr_free_buf(buf, 0);
+ }
+ 
+ #define TESTMGR_POISON_BYTE	0xfe
+ #define TESTMGR_POISON_LEN	16
+ 
+ static inline void testmgr_poison(void *addr, size_t len)
+ {
+ 	memset(addr, TESTMGR_POISON_BYTE, len);
+ }
+ 
+ /* Is the memory region still fully poisoned? */
+ static inline bool testmgr_is_poison(const void *addr, size_t len)
+ {
+ 	return memchr_inv(addr, TESTMGR_POISON_BYTE, len) == NULL;
+ }
+ 
+ /* flush type for hash algorithms */
+ enum flush_type {
+ 	/* merge with update of previous buffer(s) */
+ 	FLUSH_TYPE_NONE = 0,
+ 
+ 	/* update with previous buffer(s) before doing this one */
+ 	FLUSH_TYPE_FLUSH,
+ 
+ 	/* likewise, but also export and re-import the intermediate state */
+ 	FLUSH_TYPE_REIMPORT,
+ };
+ 
+ /* finalization function for hash algorithms */
+ enum finalization_type {
+ 	FINALIZATION_TYPE_FINAL,	/* use final() */
+ 	FINALIZATION_TYPE_FINUP,	/* use finup() */
+ 	FINALIZATION_TYPE_DIGEST,	/* use digest() */
+ };
+ 
+ #define TEST_SG_TOTAL	10000
+ 
+ /**
+  * struct test_sg_division - description of a scatterlist entry
+  *
+  * This struct describes one entry of a scatterlist being constructed to check a
+  * crypto test vector.
+  *
+  * @proportion_of_total: length of this chunk relative to the total length,
+  *			 given as a proportion out of TEST_SG_TOTAL so that it
+  *			 scales to fit any test vector
+  * @offset: byte offset into a 2-page buffer at which this chunk will start
+  * @offset_relative_to_alignmask: if true, add the algorithm's alignmask to the
+  *				  @offset
+  * @flush_type: for hashes, whether an update() should be done now vs.
+  *		continuing to accumulate data
+  * @nosimd: if doing the pending update(), do it with SIMD disabled?
+  */
+ struct test_sg_division {
+ 	unsigned int proportion_of_total;
+ 	unsigned int offset;
+ 	bool offset_relative_to_alignmask;
+ 	enum flush_type flush_type;
+ 	bool nosimd;
+ };
+ 
+ /**
+  * struct testvec_config - configuration for testing a crypto test vector
+  *
+  * This struct describes the data layout and other parameters with which each
+  * crypto test vector can be tested.
+  *
+  * @name: name of this config, logged for debugging purposes if a test fails
+  * @inplace: operate on the data in-place, if applicable for the algorithm type?
+  * @req_flags: extra request_flags, e.g. CRYPTO_TFM_REQ_MAY_SLEEP
+  * @src_divs: description of how to arrange the source scatterlist
+  * @dst_divs: description of how to arrange the dst scatterlist, if applicable
+  *	      for the algorithm type.  Defaults to @src_divs if unset.
+  * @iv_offset: misalignment of the IV in the range [0..MAX_ALGAPI_ALIGNMASK+1],
+  *	       where 0 is aligned to a 2*(MAX_ALGAPI_ALIGNMASK+1) byte boundary
+  * @iv_offset_relative_to_alignmask: if true, add the algorithm's alignmask to
+  *				     the @iv_offset
+  * @key_offset: misalignment of the key, where 0 is default alignment
+  * @key_offset_relative_to_alignmask: if true, add the algorithm's alignmask to
+  *				      the @key_offset
+  * @finalization_type: what finalization function to use for hashes
+  * @nosimd: execute with SIMD disabled?  Requires !CRYPTO_TFM_REQ_MAY_SLEEP.
+  */
+ struct testvec_config {
+ 	const char *name;
+ 	bool inplace;
+ 	u32 req_flags;
+ 	struct test_sg_division src_divs[XBUFSIZE];
+ 	struct test_sg_division dst_divs[XBUFSIZE];
+ 	unsigned int iv_offset;
+ 	unsigned int key_offset;
+ 	bool iv_offset_relative_to_alignmask;
+ 	bool key_offset_relative_to_alignmask;
+ 	enum finalization_type finalization_type;
+ 	bool nosimd;
+ };
+ 
+ #define TESTVEC_CONFIG_NAMELEN	192
+ 
+ /*
+  * The following are the lists of testvec_configs to test for each algorithm
+  * type when the basic crypto self-tests are enabled, i.e. when
+  * CONFIG_CRYPTO_MANAGER_DISABLE_TESTS is unset.  They aim to provide good test
+  * coverage, while keeping the test time much shorter than the full fuzz tests
+  * so that the basic tests can be enabled in a wider range of circumstances.
+  */
+ 
+ /* Configs for skciphers and aeads */
+ static const struct testvec_config default_cipher_testvec_configs[] = {
+ 	{
+ 		.name = "in-place",
+ 		.inplace = true,
+ 		.src_divs = { { .proportion_of_total = 10000 } },
+ 	}, {
+ 		.name = "out-of-place",
+ 		.src_divs = { { .proportion_of_total = 10000 } },
+ 	}, {
+ 		.name = "unaligned buffer, offset=1",
+ 		.src_divs = { { .proportion_of_total = 10000, .offset = 1 } },
+ 		.iv_offset = 1,
+ 		.key_offset = 1,
+ 	}, {
+ 		.name = "buffer aligned only to alignmask",
+ 		.src_divs = {
+ 			{
+ 				.proportion_of_total = 10000,
+ 				.offset = 1,
+ 				.offset_relative_to_alignmask = true,
+ 			},
+ 		},
+ 		.iv_offset = 1,
+ 		.iv_offset_relative_to_alignmask = true,
+ 		.key_offset = 1,
+ 		.key_offset_relative_to_alignmask = true,
+ 	}, {
+ 		.name = "two even aligned splits",
+ 		.src_divs = {
+ 			{ .proportion_of_total = 5000 },
+ 			{ .proportion_of_total = 5000 },
+ 		},
+ 	}, {
+ 		.name = "uneven misaligned splits, may sleep",
+ 		.req_flags = CRYPTO_TFM_REQ_MAY_SLEEP,
+ 		.src_divs = {
+ 			{ .proportion_of_total = 1900, .offset = 33 },
+ 			{ .proportion_of_total = 3300, .offset = 7  },
+ 			{ .proportion_of_total = 4800, .offset = 18 },
+ 		},
+ 		.iv_offset = 3,
+ 		.key_offset = 3,
+ 	}, {
+ 		.name = "misaligned splits crossing pages, inplace",
+ 		.inplace = true,
+ 		.src_divs = {
+ 			{
+ 				.proportion_of_total = 7500,
+ 				.offset = PAGE_SIZE - 32
+ 			}, {
+ 				.proportion_of_total = 2500,
+ 				.offset = PAGE_SIZE - 7
+ 			},
+ 		},
+ 	}
+ };
+ 
+ static const struct testvec_config default_hash_testvec_configs[] = {
+ 	{
+ 		.name = "init+update+final aligned buffer",
+ 		.src_divs = { { .proportion_of_total = 10000 } },
+ 		.finalization_type = FINALIZATION_TYPE_FINAL,
+ 	}, {
+ 		.name = "init+finup aligned buffer",
+ 		.src_divs = { { .proportion_of_total = 10000 } },
+ 		.finalization_type = FINALIZATION_TYPE_FINUP,
+ 	}, {
+ 		.name = "digest aligned buffer",
+ 		.src_divs = { { .proportion_of_total = 10000 } },
+ 		.finalization_type = FINALIZATION_TYPE_DIGEST,
+ 	}, {
+ 		.name = "init+update+final misaligned buffer",
+ 		.src_divs = { { .proportion_of_total = 10000, .offset = 1 } },
+ 		.finalization_type = FINALIZATION_TYPE_FINAL,
+ 		.key_offset = 1,
+ 	}, {
+ 		.name = "digest buffer aligned only to alignmask",
+ 		.src_divs = {
+ 			{
+ 				.proportion_of_total = 10000,
+ 				.offset = 1,
+ 				.offset_relative_to_alignmask = true,
+ 			},
+ 		},
+ 		.finalization_type = FINALIZATION_TYPE_DIGEST,
+ 		.key_offset = 1,
+ 		.key_offset_relative_to_alignmask = true,
+ 	}, {
+ 		.name = "init+update+update+final two even splits",
+ 		.src_divs = {
+ 			{ .proportion_of_total = 5000 },
+ 			{
+ 				.proportion_of_total = 5000,
+ 				.flush_type = FLUSH_TYPE_FLUSH,
+ 			},
+ 		},
+ 		.finalization_type = FINALIZATION_TYPE_FINAL,
+ 	}, {
+ 		.name = "digest uneven misaligned splits, may sleep",
+ 		.req_flags = CRYPTO_TFM_REQ_MAY_SLEEP,
+ 		.src_divs = {
+ 			{ .proportion_of_total = 1900, .offset = 33 },
+ 			{ .proportion_of_total = 3300, .offset = 7  },
+ 			{ .proportion_of_total = 4800, .offset = 18 },
+ 		},
+ 		.finalization_type = FINALIZATION_TYPE_DIGEST,
+ 	}, {
+ 		.name = "digest misaligned splits crossing pages",
+ 		.src_divs = {
+ 			{
+ 				.proportion_of_total = 7500,
+ 				.offset = PAGE_SIZE - 32,
+ 			}, {
+ 				.proportion_of_total = 2500,
+ 				.offset = PAGE_SIZE - 7,
+ 			},
+ 		},
+ 		.finalization_type = FINALIZATION_TYPE_DIGEST,
+ 	}, {
+ 		.name = "import/export",
+ 		.src_divs = {
+ 			{
+ 				.proportion_of_total = 6500,
+ 				.flush_type = FLUSH_TYPE_REIMPORT,
+ 			}, {
+ 				.proportion_of_total = 3500,
+ 				.flush_type = FLUSH_TYPE_REIMPORT,
+ 			},
+ 		},
+ 		.finalization_type = FINALIZATION_TYPE_FINAL,
+ 	}
+ };
+ 
+ static unsigned int count_test_sg_divisions(const struct test_sg_division *divs)
+ {
+ 	unsigned int remaining = TEST_SG_TOTAL;
+ 	unsigned int ndivs = 0;
+ 
+ 	do {
+ 		remaining -= divs[ndivs++].proportion_of_total;
+ 	} while (remaining);
+ 
+ 	return ndivs;
+ }
+ 
+ #define SGDIVS_HAVE_FLUSHES	BIT(0)
+ #define SGDIVS_HAVE_NOSIMD	BIT(1)
+ 
+ static bool valid_sg_divisions(const struct test_sg_division *divs,
+ 			       unsigned int count, int *flags_ret)
+ {
+ 	unsigned int total = 0;
+ 	unsigned int i;
+ 
+ 	for (i = 0; i < count && total != TEST_SG_TOTAL; i++) {
+ 		if (divs[i].proportion_of_total <= 0 ||
+ 		    divs[i].proportion_of_total > TEST_SG_TOTAL - total)
+ 			return false;
+ 		total += divs[i].proportion_of_total;
+ 		if (divs[i].flush_type != FLUSH_TYPE_NONE)
+ 			*flags_ret |= SGDIVS_HAVE_FLUSHES;
+ 		if (divs[i].nosimd)
+ 			*flags_ret |= SGDIVS_HAVE_NOSIMD;
+ 	}
+ 	return total == TEST_SG_TOTAL &&
+ 		memchr_inv(&divs[i], 0, (count - i) * sizeof(divs[0])) == NULL;
+ }
+ 
+ /*
+  * Check whether the given testvec_config is valid.  This isn't strictly needed
+  * since every testvec_config should be valid, but check anyway so that people
+  * don't unknowingly add broken configs that don't do what they wanted.
+  */
+ static bool valid_testvec_config(const struct testvec_config *cfg)
+ {
+ 	int flags = 0;
+ 
+ 	if (cfg->name == NULL)
+ 		return false;
+ 
+ 	if (!valid_sg_divisions(cfg->src_divs, ARRAY_SIZE(cfg->src_divs),
+ 				&flags))
+ 		return false;
+ 
+ 	if (cfg->dst_divs[0].proportion_of_total) {
+ 		if (!valid_sg_divisions(cfg->dst_divs,
+ 					ARRAY_SIZE(cfg->dst_divs), &flags))
+ 			return false;
+ 	} else {
+ 		if (memchr_inv(cfg->dst_divs, 0, sizeof(cfg->dst_divs)))
+ 			return false;
+ 		/* defaults to dst_divs=src_divs */
+ 	}
+ 
+ 	if (cfg->iv_offset +
+ 	    (cfg->iv_offset_relative_to_alignmask ? MAX_ALGAPI_ALIGNMASK : 0) >
+ 	    MAX_ALGAPI_ALIGNMASK + 1)
+ 		return false;
+ 
+ 	if ((flags & (SGDIVS_HAVE_FLUSHES | SGDIVS_HAVE_NOSIMD)) &&
+ 	    cfg->finalization_type == FINALIZATION_TYPE_DIGEST)
+ 		return false;
+ 
+ 	if ((cfg->nosimd || (flags & SGDIVS_HAVE_NOSIMD)) &&
+ 	    (cfg->req_flags & CRYPTO_TFM_REQ_MAY_SLEEP))
+ 		return false;
+ 
+ 	return true;
+ }
+ 
+ struct test_sglist {
+ 	char *bufs[XBUFSIZE];
+ 	struct scatterlist sgl[XBUFSIZE];
+ 	struct scatterlist sgl_saved[XBUFSIZE];
+ 	struct scatterlist *sgl_ptr;
+ 	unsigned int nents;
+ };
+ 
+ static int init_test_sglist(struct test_sglist *tsgl)
+ {
+ 	return __testmgr_alloc_buf(tsgl->bufs, 1 /* two pages per buffer */);
+ }
+ 
+ static void destroy_test_sglist(struct test_sglist *tsgl)
+ {
+ 	return __testmgr_free_buf(tsgl->bufs, 1 /* two pages per buffer */);
+ }
+ 
+ /**
+  * build_test_sglist() - build a scatterlist for a crypto test
+  *
+  * @tsgl: the scatterlist to build.  @tsgl->bufs[] contains an array of 2-page
+  *	  buffers which the scatterlist @tsgl->sgl[] will be made to point into.
+  * @divs: the layout specification on which the scatterlist will be based
+  * @alignmask: the algorithm's alignmask
+  * @total_len: the total length of the scatterlist to build in bytes
+  * @data: if non-NULL, the buffers will be filled with this data until it ends.
+  *	  Otherwise the buffers will be poisoned.  In both cases, some bytes
+  *	  past the end of each buffer will be poisoned to help detect overruns.
+  * @out_divs: if non-NULL, the test_sg_division to which each scatterlist entry
+  *	      corresponds will be returned here.  This will match @divs except
+  *	      that divisions resolving to a length of 0 are omitted as they are
+  *	      not included in the scatterlist.
+  *
+  * Return: 0 or a -errno value
+  */
+ static int build_test_sglist(struct test_sglist *tsgl,
+ 			     const struct test_sg_division *divs,
+ 			     const unsigned int alignmask,
+ 			     const unsigned int total_len,
+ 			     struct iov_iter *data,
+ 			     const struct test_sg_division *out_divs[XBUFSIZE])
+ {
+ 	struct {
+ 		const struct test_sg_division *div;
+ 		size_t length;
+ 	} partitions[XBUFSIZE];
+ 	const unsigned int ndivs = count_test_sg_divisions(divs);
+ 	unsigned int len_remaining = total_len;
+ 	unsigned int i;
+ 
+ 	BUILD_BUG_ON(ARRAY_SIZE(partitions) != ARRAY_SIZE(tsgl->sgl));
+ 	if (WARN_ON(ndivs > ARRAY_SIZE(partitions)))
+ 		return -EINVAL;
+ 
+ 	/* Calculate the (div, length) pairs */
+ 	tsgl->nents = 0;
+ 	for (i = 0; i < ndivs; i++) {
+ 		unsigned int len_this_sg =
+ 			min(len_remaining,
+ 			    (total_len * divs[i].proportion_of_total +
+ 			     TEST_SG_TOTAL / 2) / TEST_SG_TOTAL);
+ 
+ 		if (len_this_sg != 0) {
+ 			partitions[tsgl->nents].div = &divs[i];
+ 			partitions[tsgl->nents].length = len_this_sg;
+ 			tsgl->nents++;
+ 			len_remaining -= len_this_sg;
+ 		}
+ 	}
+ 	if (tsgl->nents == 0) {
+ 		partitions[tsgl->nents].div = &divs[0];
+ 		partitions[tsgl->nents].length = 0;
+ 		tsgl->nents++;
+ 	}
+ 	partitions[tsgl->nents - 1].length += len_remaining;
+ 
+ 	/* Set up the sgl entries and fill the data or poison */
+ 	sg_init_table(tsgl->sgl, tsgl->nents);
+ 	for (i = 0; i < tsgl->nents; i++) {
+ 		unsigned int offset = partitions[i].div->offset;
+ 		void *addr;
+ 
+ 		if (partitions[i].div->offset_relative_to_alignmask)
+ 			offset += alignmask;
+ 
+ 		while (offset + partitions[i].length + TESTMGR_POISON_LEN >
+ 		       2 * PAGE_SIZE) {
+ 			if (WARN_ON(offset <= 0))
+ 				return -EINVAL;
+ 			offset /= 2;
+ 		}
+ 
+ 		addr = &tsgl->bufs[i][offset];
+ 		sg_set_buf(&tsgl->sgl[i], addr, partitions[i].length);
+ 
+ 		if (out_divs)
+ 			out_divs[i] = partitions[i].div;
+ 
+ 		if (data) {
+ 			size_t copy_len, copied;
+ 
+ 			copy_len = min(partitions[i].length, data->count);
+ 			copied = copy_from_iter(addr, copy_len, data);
+ 			if (WARN_ON(copied != copy_len))
+ 				return -EINVAL;
+ 			testmgr_poison(addr + copy_len, partitions[i].length +
+ 				       TESTMGR_POISON_LEN - copy_len);
+ 		} else {
+ 			testmgr_poison(addr, partitions[i].length +
+ 				       TESTMGR_POISON_LEN);
+ 		}
+ 	}
+ 
+ 	sg_mark_end(&tsgl->sgl[tsgl->nents - 1]);
+ 	tsgl->sgl_ptr = tsgl->sgl;
+ 	memcpy(tsgl->sgl_saved, tsgl->sgl, tsgl->nents * sizeof(tsgl->sgl[0]));
+ 	return 0;
+ }
+ 
+ /*
+  * Verify that a scatterlist crypto operation produced the correct output.
+  *
+  * @tsgl: scatterlist containing the actual output
+  * @expected_output: buffer containing the expected output
+  * @len_to_check: length of @expected_output in bytes
+  * @unchecked_prefix_len: number of ignored bytes in @tsgl prior to real result
+  * @check_poison: verify that the poison bytes after each chunk are intact?
+  *
+  * Return: 0 if correct, -EINVAL if incorrect, -EOVERFLOW if buffer overrun.
+  */
+ static int verify_correct_output(const struct test_sglist *tsgl,
+ 				 const char *expected_output,
+ 				 unsigned int len_to_check,
+ 				 unsigned int unchecked_prefix_len,
+ 				 bool check_poison)
+ {
+ 	unsigned int i;
+ 
+ 	for (i = 0; i < tsgl->nents; i++) {
+ 		struct scatterlist *sg = &tsgl->sgl_ptr[i];
+ 		unsigned int len = sg->length;
+ 		unsigned int offset = sg->offset;
+ 		const char *actual_output;
+ 
+ 		if (unchecked_prefix_len) {
+ 			if (unchecked_prefix_len >= len) {
+ 				unchecked_prefix_len -= len;
+ 				continue;
+ 			}
+ 			offset += unchecked_prefix_len;
+ 			len -= unchecked_prefix_len;
+ 			unchecked_prefix_len = 0;
+ 		}
+ 		len = min(len, len_to_check);
+ 		actual_output = page_address(sg_page(sg)) + offset;
+ 		if (memcmp(expected_output, actual_output, len) != 0)
+ 			return -EINVAL;
+ 		if (check_poison &&
+ 		    !testmgr_is_poison(actual_output + len, TESTMGR_POISON_LEN))
+ 			return -EOVERFLOW;
+ 		len_to_check -= len;
+ 		expected_output += len;
+ 	}
+ 	if (WARN_ON(len_to_check != 0))
+ 		return -EINVAL;
+ 	return 0;
+ }
+ 
+ static bool is_test_sglist_corrupted(const struct test_sglist *tsgl)
+ {
+ 	unsigned int i;
+ 
+ 	for (i = 0; i < tsgl->nents; i++) {
+ 		if (tsgl->sgl[i].page_link != tsgl->sgl_saved[i].page_link)
+ 			return true;
+ 		if (tsgl->sgl[i].offset != tsgl->sgl_saved[i].offset)
+ 			return true;
+ 		if (tsgl->sgl[i].length != tsgl->sgl_saved[i].length)
+ 			return true;
+ 	}
+ 	return false;
+ }
+ 
+ struct cipher_test_sglists {
+ 	struct test_sglist src;
+ 	struct test_sglist dst;
+ };
+ 
+ static struct cipher_test_sglists *alloc_cipher_test_sglists(void)
+ {
+ 	struct cipher_test_sglists *tsgls;
+ 
+ 	tsgls = kmalloc(sizeof(*tsgls), GFP_KERNEL);
+ 	if (!tsgls)
+ 		return NULL;
+ 
+ 	if (init_test_sglist(&tsgls->src) != 0)
+ 		goto fail_kfree;
+ 	if (init_test_sglist(&tsgls->dst) != 0)
+ 		goto fail_destroy_src;
+ 
+ 	return tsgls;
+ 
+ fail_destroy_src:
+ 	destroy_test_sglist(&tsgls->src);
+ fail_kfree:
+ 	kfree(tsgls);
+ 	return NULL;
+ }
+ 
+ static void free_cipher_test_sglists(struct cipher_test_sglists *tsgls)
+ {
+ 	if (tsgls) {
+ 		destroy_test_sglist(&tsgls->src);
+ 		destroy_test_sglist(&tsgls->dst);
+ 		kfree(tsgls);
+ 	}
+ }
+ 
+ /* Build the src and dst scatterlists for an skcipher or AEAD test */
+ static int build_cipher_test_sglists(struct cipher_test_sglists *tsgls,
+ 				     const struct testvec_config *cfg,
+ 				     unsigned int alignmask,
+ 				     unsigned int src_total_len,
+ 				     unsigned int dst_total_len,
+ 				     const struct kvec *inputs,
+ 				     unsigned int nr_inputs)
+ {
+ 	struct iov_iter input;
+ 	int err;
+ 
+ 	iov_iter_kvec(&input, WRITE, inputs, nr_inputs, src_total_len);
+ 	err = build_test_sglist(&tsgls->src, cfg->src_divs, alignmask,
+ 				cfg->inplace ?
+ 					max(dst_total_len, src_total_len) :
+ 					src_total_len,
+ 				&input, NULL);
+ 	if (err)
+ 		return err;
+ 
+ 	if (cfg->inplace) {
+ 		tsgls->dst.sgl_ptr = tsgls->src.sgl;
+ 		tsgls->dst.nents = tsgls->src.nents;
+ 		return 0;
+ 	}
+ 	return build_test_sglist(&tsgls->dst,
+ 				 cfg->dst_divs[0].proportion_of_total ?
+ 					cfg->dst_divs : cfg->src_divs,
+ 				 alignmask, dst_total_len, NULL, NULL);
+ }
+ 
+ /*
+  * Support for testing passing a misaligned key to setkey():
+  *
+  * If cfg->key_offset is set, copy the key into a new buffer at that offset,
+  * optionally adding alignmask.  Else, just use the key directly.
+  */
+ static int prepare_keybuf(const u8 *key, unsigned int ksize,
+ 			  const struct testvec_config *cfg,
+ 			  unsigned int alignmask,
+ 			  const u8 **keybuf_ret, const u8 **keyptr_ret)
+ {
+ 	unsigned int key_offset = cfg->key_offset;
+ 	u8 *keybuf = NULL, *keyptr = (u8 *)key;
+ 
+ 	if (key_offset != 0) {
+ 		if (cfg->key_offset_relative_to_alignmask)
+ 			key_offset += alignmask;
+ 		keybuf = kmalloc(key_offset + ksize, GFP_KERNEL);
+ 		if (!keybuf)
+ 			return -ENOMEM;
+ 		keyptr = keybuf + key_offset;
+ 		memcpy(keyptr, key, ksize);
+ 	}
+ 	*keybuf_ret = keybuf;
+ 	*keyptr_ret = keyptr;
+ 	return 0;
+ }
+ 
+ /* Like setkey_f(tfm, key, ksize), but sometimes misalign the key */
+ #define do_setkey(setkey_f, tfm, key, ksize, cfg, alignmask)		\
+ ({									\
+ 	const u8 *keybuf, *keyptr;					\
+ 	int err;							\
+ 									\
+ 	err = prepare_keybuf((key), (ksize), (cfg), (alignmask),	\
+ 			     &keybuf, &keyptr);				\
+ 	if (err == 0) {							\
+ 		err = setkey_f((tfm), keyptr, (ksize));			\
+ 		kfree(keybuf);						\
+ 	}								\
+ 	err;								\
+ })
+ 
+ #ifdef CONFIG_CRYPTO_MANAGER_EXTRA_TESTS
+ 
+ /* Generate a random length in range [0, max_len], but prefer smaller values */
+ static unsigned int generate_random_length(unsigned int max_len)
+ {
+ 	unsigned int len = prandom_u32() % (max_len + 1);
+ 
+ 	switch (prandom_u32() % 4) {
+ 	case 0:
+ 		return len % 64;
+ 	case 1:
+ 		return len % 256;
+ 	case 2:
+ 		return len % 1024;
+ 	default:
+ 		return len;
+ 	}
+ }
+ 
+ /* Flip a random bit in the given nonempty data buffer */
+ static void flip_random_bit(u8 *buf, size_t size)
+ {
+ 	size_t bitpos;
+ 
+ 	bitpos = prandom_u32() % (size * 8);
+ 	buf[bitpos / 8] ^= 1 << (bitpos % 8);
+ }
+ 
+ /* Flip a random byte in the given nonempty data buffer */
+ static void flip_random_byte(u8 *buf, size_t size)
+ {
+ 	buf[prandom_u32() % size] ^= 0xff;
+ }
+ 
+ /* Sometimes make some random changes to the given nonempty data buffer */
+ static void mutate_buffer(u8 *buf, size_t size)
+ {
+ 	size_t num_flips;
+ 	size_t i;
+ 
+ 	/* Sometimes flip some bits */
+ 	if (prandom_u32() % 4 == 0) {
+ 		num_flips = min_t(size_t, 1 << (prandom_u32() % 8), size * 8);
+ 		for (i = 0; i < num_flips; i++)
+ 			flip_random_bit(buf, size);
+ 	}
+ 
+ 	/* Sometimes flip some bytes */
+ 	if (prandom_u32() % 4 == 0) {
+ 		num_flips = min_t(size_t, 1 << (prandom_u32() % 8), size);
+ 		for (i = 0; i < num_flips; i++)
+ 			flip_random_byte(buf, size);
+ 	}
+ }
+ 
+ /* Randomly generate 'count' bytes, but sometimes make them "interesting" */
+ static void generate_random_bytes(u8 *buf, size_t count)
+ {
+ 	u8 b;
+ 	u8 increment;
+ 	size_t i;
+ 
+ 	if (count == 0)
+ 		return;
+ 
+ 	switch (prandom_u32() % 8) { /* Choose a generation strategy */
+ 	case 0:
+ 	case 1:
+ 		/* All the same byte, plus optional mutations */
+ 		switch (prandom_u32() % 4) {
+ 		case 0:
+ 			b = 0x00;
+ 			break;
+ 		case 1:
+ 			b = 0xff;
+ 			break;
+ 		default:
+ 			b = (u8)prandom_u32();
+ 			break;
+ 		}
+ 		memset(buf, b, count);
+ 		mutate_buffer(buf, count);
+ 		break;
+ 	case 2:
+ 		/* Ascending or descending bytes, plus optional mutations */
+ 		increment = (u8)prandom_u32();
+ 		b = (u8)prandom_u32();
+ 		for (i = 0; i < count; i++, b += increment)
+ 			buf[i] = b;
+ 		mutate_buffer(buf, count);
+ 		break;
+ 	default:
+ 		/* Fully random bytes */
+ 		for (i = 0; i < count; i++)
+ 			buf[i] = (u8)prandom_u32();
+ 	}
+ }
+ 
+ static char *generate_random_sgl_divisions(struct test_sg_division *divs,
+ 					   size_t max_divs, char *p, char *end,
+ 					   bool gen_flushes, u32 req_flags)
+ {
+ 	struct test_sg_division *div = divs;
+ 	unsigned int remaining = TEST_SG_TOTAL;
+ 
+ 	do {
+ 		unsigned int this_len;
+ 		const char *flushtype_str;
+ 
+ 		if (div == &divs[max_divs - 1] || prandom_u32() % 2 == 0)
+ 			this_len = remaining;
+ 		else
+ 			this_len = 1 + (prandom_u32() % remaining);
+ 		div->proportion_of_total = this_len;
+ 
+ 		if (prandom_u32() % 4 == 0)
+ 			div->offset = (PAGE_SIZE - 128) + (prandom_u32() % 128);
+ 		else if (prandom_u32() % 2 == 0)
+ 			div->offset = prandom_u32() % 32;
+ 		else
+ 			div->offset = prandom_u32() % PAGE_SIZE;
+ 		if (prandom_u32() % 8 == 0)
+ 			div->offset_relative_to_alignmask = true;
+ 
+ 		div->flush_type = FLUSH_TYPE_NONE;
+ 		if (gen_flushes) {
+ 			switch (prandom_u32() % 4) {
+ 			case 0:
+ 				div->flush_type = FLUSH_TYPE_REIMPORT;
+ 				break;
+ 			case 1:
+ 				div->flush_type = FLUSH_TYPE_FLUSH;
+ 				break;
+ 			}
+ 		}
+ 
+ 		if (div->flush_type != FLUSH_TYPE_NONE &&
+ 		    !(req_flags & CRYPTO_TFM_REQ_MAY_SLEEP) &&
+ 		    prandom_u32() % 2 == 0)
+ 			div->nosimd = true;
+ 
+ 		switch (div->flush_type) {
+ 		case FLUSH_TYPE_FLUSH:
+ 			if (div->nosimd)
+ 				flushtype_str = "<flush,nosimd>";
+ 			else
+ 				flushtype_str = "<flush>";
+ 			break;
+ 		case FLUSH_TYPE_REIMPORT:
+ 			if (div->nosimd)
+ 				flushtype_str = "<reimport,nosimd>";
+ 			else
+ 				flushtype_str = "<reimport>";
+ 			break;
+ 		default:
+ 			flushtype_str = "";
+ 			break;
+ 		}
+ 
+ 		BUILD_BUG_ON(TEST_SG_TOTAL != 10000); /* for "%u.%u%%" */
+ 		p += scnprintf(p, end - p, "%s%u.%u%%@%s+%u%s", flushtype_str,
+ 			       this_len / 100, this_len % 100,
+ 			       div->offset_relative_to_alignmask ?
+ 					"alignmask" : "",
+ 			       div->offset, this_len == remaining ? "" : ", ");
+ 		remaining -= this_len;
+ 		div++;
+ 	} while (remaining);
+ 
+ 	return p;
+ }
+ 
+ /* Generate a random testvec_config for fuzz testing */
+ static void generate_random_testvec_config(struct testvec_config *cfg,
+ 					   char *name, size_t max_namelen)
+ {
+ 	char *p = name;
+ 	char * const end = name + max_namelen;
+ 
+ 	memset(cfg, 0, sizeof(*cfg));
+ 
+ 	cfg->name = name;
+ 
+ 	p += scnprintf(p, end - p, "random:");
+ 
+ 	if (prandom_u32() % 2 == 0) {
+ 		cfg->inplace = true;
+ 		p += scnprintf(p, end - p, " inplace");
+ 	}
+ 
+ 	if (prandom_u32() % 2 == 0) {
+ 		cfg->req_flags |= CRYPTO_TFM_REQ_MAY_SLEEP;
+ 		p += scnprintf(p, end - p, " may_sleep");
+ 	}
+ 
+ 	switch (prandom_u32() % 4) {
+ 	case 0:
+ 		cfg->finalization_type = FINALIZATION_TYPE_FINAL;
+ 		p += scnprintf(p, end - p, " use_final");
+ 		break;
+ 	case 1:
+ 		cfg->finalization_type = FINALIZATION_TYPE_FINUP;
+ 		p += scnprintf(p, end - p, " use_finup");
+ 		break;
+ 	default:
+ 		cfg->finalization_type = FINALIZATION_TYPE_DIGEST;
+ 		p += scnprintf(p, end - p, " use_digest");
+ 		break;
+ 	}
+ 
+ 	if (!(cfg->req_flags & CRYPTO_TFM_REQ_MAY_SLEEP) &&
+ 	    prandom_u32() % 2 == 0) {
+ 		cfg->nosimd = true;
+ 		p += scnprintf(p, end - p, " nosimd");
+ 	}
+ 
+ 	p += scnprintf(p, end - p, " src_divs=[");
+ 	p = generate_random_sgl_divisions(cfg->src_divs,
+ 					  ARRAY_SIZE(cfg->src_divs), p, end,
+ 					  (cfg->finalization_type !=
+ 					   FINALIZATION_TYPE_DIGEST),
+ 					  cfg->req_flags);
+ 	p += scnprintf(p, end - p, "]");
+ 
+ 	if (!cfg->inplace && prandom_u32() % 2 == 0) {
+ 		p += scnprintf(p, end - p, " dst_divs=[");
+ 		p = generate_random_sgl_divisions(cfg->dst_divs,
+ 						  ARRAY_SIZE(cfg->dst_divs),
+ 						  p, end, false,
+ 						  cfg->req_flags);
+ 		p += scnprintf(p, end - p, "]");
+ 	}
+ 
+ 	if (prandom_u32() % 2 == 0) {
+ 		cfg->iv_offset = 1 + (prandom_u32() % MAX_ALGAPI_ALIGNMASK);
+ 		p += scnprintf(p, end - p, " iv_offset=%u", cfg->iv_offset);
+ 	}
+ 
+ 	if (prandom_u32() % 2 == 0) {
+ 		cfg->key_offset = 1 + (prandom_u32() % MAX_ALGAPI_ALIGNMASK);
+ 		p += scnprintf(p, end - p, " key_offset=%u", cfg->key_offset);
+ 	}
+ 
+ 	WARN_ON_ONCE(!valid_testvec_config(cfg));
+ }
+ 
+ static void crypto_disable_simd_for_test(void)
+ {
+ 	preempt_disable();
+ 	__this_cpu_write(crypto_simd_disabled_for_test, true);
+ }
+ 
+ static void crypto_reenable_simd_for_test(void)
+ {
+ 	__this_cpu_write(crypto_simd_disabled_for_test, false);
+ 	preempt_enable();
+ }
+ 
+ /*
+  * Given an algorithm name, build the name of the generic implementation of that
+  * algorithm, assuming the usual naming convention.  Specifically, this appends
+  * "-generic" to every part of the name that is not a template name.  Examples:
+  *
+  *	aes => aes-generic
+  *	cbc(aes) => cbc(aes-generic)
+  *	cts(cbc(aes)) => cts(cbc(aes-generic))
+  *	rfc7539(chacha20,poly1305) => rfc7539(chacha20-generic,poly1305-generic)
+  *
+  * Return: 0 on success, or -ENAMETOOLONG if the generic name would be too long
+  */
+ static int build_generic_driver_name(const char *algname,
+ 				     char driver_name[CRYPTO_MAX_ALG_NAME])
+ {
+ 	const char *in = algname;
+ 	char *out = driver_name;
+ 	size_t len = strlen(algname);
+ 
+ 	if (len >= CRYPTO_MAX_ALG_NAME)
+ 		goto too_long;
+ 	do {
+ 		const char *in_saved = in;
+ 
+ 		while (*in && *in != '(' && *in != ')' && *in != ',')
+ 			*out++ = *in++;
+ 		if (*in != '(' && in > in_saved) {
+ 			len += 8;
+ 			if (len >= CRYPTO_MAX_ALG_NAME)
+ 				goto too_long;
+ 			memcpy(out, "-generic", 8);
+ 			out += 8;
+ 		}
+ 	} while ((*out++ = *in++) != '\0');
+ 	return 0;
+ 
+ too_long:
+ 	pr_err("alg: generic driver name for \"%s\" would be too long\n",
+ 	       algname);
+ 	return -ENAMETOOLONG;
+ }
+ #else /* !CONFIG_CRYPTO_MANAGER_EXTRA_TESTS */
+ static void crypto_disable_simd_for_test(void)
+ {
+ }
+ 
+ static void crypto_reenable_simd_for_test(void)
+ {
+ }
+ #endif /* !CONFIG_CRYPTO_MANAGER_EXTRA_TESTS */
+ 
+ static int build_hash_sglist(struct test_sglist *tsgl,
+ 			     const struct hash_testvec *vec,
+ 			     const struct testvec_config *cfg,
+ 			     unsigned int alignmask,
+ 			     const struct test_sg_division *divs[XBUFSIZE])
+ {
+ 	struct kvec kv;
+ 	struct iov_iter input;
+ 
+ 	kv.iov_base = (void *)vec->plaintext;
+ 	kv.iov_len = vec->psize;
+ 	iov_iter_kvec(&input, WRITE, &kv, 1, vec->psize);
+ 	return build_test_sglist(tsgl, cfg->src_divs, alignmask, vec->psize,
+ 				 &input, divs);
+ }
+ 
+ static int check_hash_result(const char *type,
+ 			     const u8 *result, unsigned int digestsize,
+ 			     const struct hash_testvec *vec,
+ 			     const char *vec_name,
+ 			     const char *driver,
+ 			     const struct testvec_config *cfg)
+ {
+ 	if (memcmp(result, vec->digest, digestsize) != 0) {
+ 		pr_err("alg: %s: %s test failed (wrong result) on test vector %s, cfg=\"%s\"\n",
+ 		       type, driver, vec_name, cfg->name);
+ 		return -EINVAL;
+ 	}
+ 	if (!testmgr_is_poison(&result[digestsize], TESTMGR_POISON_LEN)) {
+ 		pr_err("alg: %s: %s overran result buffer on test vector %s, cfg=\"%s\"\n",
+ 		       type, driver, vec_name, cfg->name);
+ 		return -EOVERFLOW;
+ 	}
+ 	return 0;
+ }
+ 
+ static inline int check_shash_op(const char *op, int err,
+ 				 const char *driver, const char *vec_name,
+ 				 const struct testvec_config *cfg)
+ {
+ 	if (err)
+ 		pr_err("alg: shash: %s %s() failed with err %d on test vector %s, cfg=\"%s\"\n",
+ 		       driver, op, err, vec_name, cfg->name);
+ 	return err;
+ }
+ 
+ static inline const void *sg_data(struct scatterlist *sg)
+ {
+ 	return page_address(sg_page(sg)) + sg->offset;
+ }
+ 
+ /* Test one hash test vector in one configuration, using the shash API */
+ static int test_shash_vec_cfg(const char *driver,
+ 			      const struct hash_testvec *vec,
+ 			      const char *vec_name,
+ 			      const struct testvec_config *cfg,
+ 			      struct shash_desc *desc,
+ 			      struct test_sglist *tsgl,
+ 			      u8 *hashstate)
+ {
+ 	struct crypto_shash *tfm = desc->tfm;
+ 	const unsigned int alignmask = crypto_shash_alignmask(tfm);
+ 	const unsigned int digestsize = crypto_shash_digestsize(tfm);
+ 	const unsigned int statesize = crypto_shash_statesize(tfm);
+ 	const struct test_sg_division *divs[XBUFSIZE];
+ 	unsigned int i;
+ 	u8 result[HASH_MAX_DIGESTSIZE + TESTMGR_POISON_LEN];
+ 	int err;
+ 
+ 	/* Set the key, if specified */
+ 	if (vec->ksize) {
+ 		err = do_setkey(crypto_shash_setkey, tfm, vec->key, vec->ksize,
+ 				cfg, alignmask);
+ 		if (err) {
+ 			if (err == vec->setkey_error)
+ 				return 0;
+ 			pr_err("alg: shash: %s setkey failed on test vector %s; expected_error=%d, actual_error=%d, flags=%#x\n",
+ 			       driver, vec_name, vec->setkey_error, err,
+ 			       crypto_shash_get_flags(tfm));
+ 			return err;
+ 		}
+ 		if (vec->setkey_error) {
+ 			pr_err("alg: shash: %s setkey unexpectedly succeeded on test vector %s; expected_error=%d\n",
+ 			       driver, vec_name, vec->setkey_error);
+ 			return -EINVAL;
+ 		}
+ 	}
+ 
+ 	/* Build the scatterlist for the source data */
+ 	err = build_hash_sglist(tsgl, vec, cfg, alignmask, divs);
+ 	if (err) {
+ 		pr_err("alg: shash: %s: error preparing scatterlist for test vector %s, cfg=\"%s\"\n",
+ 		       driver, vec_name, cfg->name);
+ 		return err;
+ 	}
+ 
+ 	/* Do the actual hashing */
+ 
+ 	testmgr_poison(desc->__ctx, crypto_shash_descsize(tfm));
+ 	testmgr_poison(result, digestsize + TESTMGR_POISON_LEN);
+ 
+ 	if (cfg->finalization_type == FINALIZATION_TYPE_DIGEST ||
+ 	    vec->digest_error) {
+ 		/* Just using digest() */
+ 		if (tsgl->nents != 1)
+ 			return 0;
+ 		if (cfg->nosimd)
+ 			crypto_disable_simd_for_test();
+ 		err = crypto_shash_digest(desc, sg_data(&tsgl->sgl[0]),
+ 					  tsgl->sgl[0].length, result);
+ 		if (cfg->nosimd)
+ 			crypto_reenable_simd_for_test();
+ 		if (err) {
+ 			if (err == vec->digest_error)
+ 				return 0;
+ 			pr_err("alg: shash: %s digest() failed on test vector %s; expected_error=%d, actual_error=%d, cfg=\"%s\"\n",
+ 			       driver, vec_name, vec->digest_error, err,
+ 			       cfg->name);
+ 			return err;
+ 		}
+ 		if (vec->digest_error) {
+ 			pr_err("alg: shash: %s digest() unexpectedly succeeded on test vector %s; expected_error=%d, cfg=\"%s\"\n",
+ 			       driver, vec_name, vec->digest_error, cfg->name);
+ 			return -EINVAL;
+ 		}
+ 		goto result_ready;
+ 	}
+ 
+ 	/* Using init(), zero or more update(), then final() or finup() */
+ 
+ 	if (cfg->nosimd)
+ 		crypto_disable_simd_for_test();
+ 	err = crypto_shash_init(desc);
+ 	if (cfg->nosimd)
+ 		crypto_reenable_simd_for_test();
+ 	err = check_shash_op("init", err, driver, vec_name, cfg);
+ 	if (err)
+ 		return err;
+ 
+ 	for (i = 0; i < tsgl->nents; i++) {
+ 		if (i + 1 == tsgl->nents &&
+ 		    cfg->finalization_type == FINALIZATION_TYPE_FINUP) {
+ 			if (divs[i]->nosimd)
+ 				crypto_disable_simd_for_test();
+ 			err = crypto_shash_finup(desc, sg_data(&tsgl->sgl[i]),
+ 						 tsgl->sgl[i].length, result);
+ 			if (divs[i]->nosimd)
+ 				crypto_reenable_simd_for_test();
+ 			err = check_shash_op("finup", err, driver, vec_name,
+ 					     cfg);
+ 			if (err)
+ 				return err;
+ 			goto result_ready;
+ 		}
+ 		if (divs[i]->nosimd)
+ 			crypto_disable_simd_for_test();
+ 		err = crypto_shash_update(desc, sg_data(&tsgl->sgl[i]),
+ 					  tsgl->sgl[i].length);
+ 		if (divs[i]->nosimd)
+ 			crypto_reenable_simd_for_test();
+ 		err = check_shash_op("update", err, driver, vec_name, cfg);
+ 		if (err)
+ 			return err;
+ 		if (divs[i]->flush_type == FLUSH_TYPE_REIMPORT) {
+ 			/* Test ->export() and ->import() */
+ 			testmgr_poison(hashstate + statesize,
+ 				       TESTMGR_POISON_LEN);
+ 			err = crypto_shash_export(desc, hashstate);
+ 			err = check_shash_op("export", err, driver, vec_name,
+ 					     cfg);
+ 			if (err)
+ 				return err;
+ 			if (!testmgr_is_poison(hashstate + statesize,
+ 					       TESTMGR_POISON_LEN)) {
+ 				pr_err("alg: shash: %s export() overran state buffer on test vector %s, cfg=\"%s\"\n",
+ 				       driver, vec_name, cfg->name);
+ 				return -EOVERFLOW;
+ 			}
+ 			testmgr_poison(desc->__ctx, crypto_shash_descsize(tfm));
+ 			err = crypto_shash_import(desc, hashstate);
+ 			err = check_shash_op("import", err, driver, vec_name,
+ 					     cfg);
+ 			if (err)
+ 				return err;
+ 		}
+ 	}
+ 
+ 	if (cfg->nosimd)
+ 		crypto_disable_simd_for_test();
+ 	err = crypto_shash_final(desc, result);
+ 	if (cfg->nosimd)
+ 		crypto_reenable_simd_for_test();
+ 	err = check_shash_op("final", err, driver, vec_name, cfg);
+ 	if (err)
+ 		return err;
+ result_ready:
+ 	return check_hash_result("shash", result, digestsize, vec, vec_name,
+ 				 driver, cfg);
+ }
+ 
+ static int do_ahash_op(int (*op)(struct ahash_request *req),
+ 		       struct ahash_request *req,
+ 		       struct crypto_wait *wait, bool nosimd)
+ {
+ 	int err;
+ 
+ 	if (nosimd)
+ 		crypto_disable_simd_for_test();
+ 
+ 	err = op(req);
+ 
+ 	if (nosimd)
+ 		crypto_reenable_simd_for_test();
+ 
+ 	return crypto_wait_req(err, wait);
+ }
+ 
+ static int check_nonfinal_ahash_op(const char *op, int err,
+ 				   u8 *result, unsigned int digestsize,
+ 				   const char *driver, const char *vec_name,
+ 				   const struct testvec_config *cfg)
+ {
+ 	if (err) {
+ 		pr_err("alg: ahash: %s %s() failed with err %d on test vector %s, cfg=\"%s\"\n",
+ 		       driver, op, err, vec_name, cfg->name);
+ 		return err;
+ 	}
+ 	if (!testmgr_is_poison(result, digestsize)) {
+ 		pr_err("alg: ahash: %s %s() used result buffer on test vector %s, cfg=\"%s\"\n",
+ 		       driver, op, vec_name, cfg->name);
+ 		return -EINVAL;
+ 	}
+ 	return 0;
+ }
+ 
+ /* Test one hash test vector in one configuration, using the ahash API */
+ static int test_ahash_vec_cfg(const char *driver,
+ 			      const struct hash_testvec *vec,
+ 			      const char *vec_name,
+ 			      const struct testvec_config *cfg,
+ 			      struct ahash_request *req,
+ 			      struct test_sglist *tsgl,
+ 			      u8 *hashstate)
+ {
+ 	struct crypto_ahash *tfm = crypto_ahash_reqtfm(req);
+ 	const unsigned int alignmask = crypto_ahash_alignmask(tfm);
+ 	const unsigned int digestsize = crypto_ahash_digestsize(tfm);
+ 	const unsigned int statesize = crypto_ahash_statesize(tfm);
+ 	const u32 req_flags = CRYPTO_TFM_REQ_MAY_BACKLOG | cfg->req_flags;
+ 	const struct test_sg_division *divs[XBUFSIZE];
+ 	DECLARE_CRYPTO_WAIT(wait);
+ 	unsigned int i;
+ 	struct scatterlist *pending_sgl;
+ 	unsigned int pending_len;
+ 	u8 result[HASH_MAX_DIGESTSIZE + TESTMGR_POISON_LEN];
+ 	int err;
+ 
+ 	/* Set the key, if specified */
+ 	if (vec->ksize) {
+ 		err = do_setkey(crypto_ahash_setkey, tfm, vec->key, vec->ksize,
+ 				cfg, alignmask);
+ 		if (err) {
+ 			if (err == vec->setkey_error)
+ 				return 0;
+ 			pr_err("alg: ahash: %s setkey failed on test vector %s; expected_error=%d, actual_error=%d, flags=%#x\n",
+ 			       driver, vec_name, vec->setkey_error, err,
+ 			       crypto_ahash_get_flags(tfm));
+ 			return err;
+ 		}
+ 		if (vec->setkey_error) {
+ 			pr_err("alg: ahash: %s setkey unexpectedly succeeded on test vector %s; expected_error=%d\n",
+ 			       driver, vec_name, vec->setkey_error);
+ 			return -EINVAL;
+ 		}
+ 	}
+ 
+ 	/* Build the scatterlist for the source data */
+ 	err = build_hash_sglist(tsgl, vec, cfg, alignmask, divs);
+ 	if (err) {
+ 		pr_err("alg: ahash: %s: error preparing scatterlist for test vector %s, cfg=\"%s\"\n",
+ 		       driver, vec_name, cfg->name);
+ 		return err;
+ 	}
+ 
+ 	/* Do the actual hashing */
+ 
+ 	testmgr_poison(req->__ctx, crypto_ahash_reqsize(tfm));
+ 	testmgr_poison(result, digestsize + TESTMGR_POISON_LEN);
+ 
+ 	if (cfg->finalization_type == FINALIZATION_TYPE_DIGEST ||
+ 	    vec->digest_error) {
+ 		/* Just using digest() */
+ 		ahash_request_set_callback(req, req_flags, crypto_req_done,
+ 					   &wait);
+ 		ahash_request_set_crypt(req, tsgl->sgl, result, vec->psize);
+ 		err = do_ahash_op(crypto_ahash_digest, req, &wait, cfg->nosimd);
+ 		if (err) {
+ 			if (err == vec->digest_error)
+ 				return 0;
+ 			pr_err("alg: ahash: %s digest() failed on test vector %s; expected_error=%d, actual_error=%d, cfg=\"%s\"\n",
+ 			       driver, vec_name, vec->digest_error, err,
+ 			       cfg->name);
+ 			return err;
+ 		}
+ 		if (vec->digest_error) {
+ 			pr_err("alg: ahash: %s digest() unexpectedly succeeded on test vector %s; expected_error=%d, cfg=\"%s\"\n",
+ 			       driver, vec_name, vec->digest_error, cfg->name);
+ 			return -EINVAL;
+ 		}
+ 		goto result_ready;
+ 	}
+ 
+ 	/* Using init(), zero or more update(), then final() or finup() */
+ 
+ 	ahash_request_set_callback(req, req_flags, crypto_req_done, &wait);
+ 	ahash_request_set_crypt(req, NULL, result, 0);
+ 	err = do_ahash_op(crypto_ahash_init, req, &wait, cfg->nosimd);
+ 	err = check_nonfinal_ahash_op("init", err, result, digestsize,
+ 				      driver, vec_name, cfg);
+ 	if (err)
+ 		return err;
+ 
+ 	pending_sgl = NULL;
+ 	pending_len = 0;
+ 	for (i = 0; i < tsgl->nents; i++) {
+ 		if (divs[i]->flush_type != FLUSH_TYPE_NONE &&
+ 		    pending_sgl != NULL) {
+ 			/* update() with the pending data */
+ 			ahash_request_set_callback(req, req_flags,
+ 						   crypto_req_done, &wait);
+ 			ahash_request_set_crypt(req, pending_sgl, result,
+ 						pending_len);
+ 			err = do_ahash_op(crypto_ahash_update, req, &wait,
+ 					  divs[i]->nosimd);
+ 			err = check_nonfinal_ahash_op("update", err,
+ 						      result, digestsize,
+ 						      driver, vec_name, cfg);
+ 			if (err)
+ 				return err;
+ 			pending_sgl = NULL;
+ 			pending_len = 0;
+ 		}
+ 		if (divs[i]->flush_type == FLUSH_TYPE_REIMPORT) {
+ 			/* Test ->export() and ->import() */
+ 			testmgr_poison(hashstate + statesize,
+ 				       TESTMGR_POISON_LEN);
+ 			err = crypto_ahash_export(req, hashstate);
+ 			err = check_nonfinal_ahash_op("export", err,
+ 						      result, digestsize,
+ 						      driver, vec_name, cfg);
+ 			if (err)
+ 				return err;
+ 			if (!testmgr_is_poison(hashstate + statesize,
+ 					       TESTMGR_POISON_LEN)) {
+ 				pr_err("alg: ahash: %s export() overran state buffer on test vector %s, cfg=\"%s\"\n",
+ 				       driver, vec_name, cfg->name);
+ 				return -EOVERFLOW;
+ 			}
+ 
+ 			testmgr_poison(req->__ctx, crypto_ahash_reqsize(tfm));
+ 			err = crypto_ahash_import(req, hashstate);
+ 			err = check_nonfinal_ahash_op("import", err,
+ 						      result, digestsize,
+ 						      driver, vec_name, cfg);
+ 			if (err)
+ 				return err;
+ 		}
+ 		if (pending_sgl == NULL)
+ 			pending_sgl = &tsgl->sgl[i];
+ 		pending_len += tsgl->sgl[i].length;
+ 	}
+ 
+ 	ahash_request_set_callback(req, req_flags, crypto_req_done, &wait);
+ 	ahash_request_set_crypt(req, pending_sgl, result, pending_len);
+ 	if (cfg->finalization_type == FINALIZATION_TYPE_FINAL) {
+ 		/* finish with update() and final() */
+ 		err = do_ahash_op(crypto_ahash_update, req, &wait, cfg->nosimd);
+ 		err = check_nonfinal_ahash_op("update", err, result, digestsize,
+ 					      driver, vec_name, cfg);
+ 		if (err)
+ 			return err;
+ 		err = do_ahash_op(crypto_ahash_final, req, &wait, cfg->nosimd);
+ 		if (err) {
+ 			pr_err("alg: ahash: %s final() failed with err %d on test vector %s, cfg=\"%s\"\n",
+ 			       driver, err, vec_name, cfg->name);
+ 			return err;
+ 		}
+ 	} else {
+ 		/* finish with finup() */
+ 		err = do_ahash_op(crypto_ahash_finup, req, &wait, cfg->nosimd);
+ 		if (err) {
+ 			pr_err("alg: ahash: %s finup() failed with err %d on test vector %s, cfg=\"%s\"\n",
+ 			       driver, err, vec_name, cfg->name);
+ 			return err;
+ 		}
+ 	}
+ 
+ result_ready:
+ 	return check_hash_result("ahash", result, digestsize, vec, vec_name,
+ 				 driver, cfg);
+ }
+ 
+ static int test_hash_vec_cfg(const char *driver,
+ 			     const struct hash_testvec *vec,
+ 			     const char *vec_name,
+ 			     const struct testvec_config *cfg,
+ 			     struct ahash_request *req,
+ 			     struct shash_desc *desc,
+ 			     struct test_sglist *tsgl,
+ 			     u8 *hashstate)
+ {
+ 	int err;
+ 
+ 	/*
+ 	 * For algorithms implemented as "shash", most bugs will be detected by
+ 	 * both the shash and ahash tests.  Test the shash API first so that the
+ 	 * failures involve less indirection, so are easier to debug.
+ 	 */
+ 
+ 	if (desc) {
+ 		err = test_shash_vec_cfg(driver, vec, vec_name, cfg, desc, tsgl,
+ 					 hashstate);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	return test_ahash_vec_cfg(driver, vec, vec_name, cfg, req, tsgl,
+ 				  hashstate);
+ }
+ 
+ static int test_hash_vec(const char *driver, const struct hash_testvec *vec,
+ 			 unsigned int vec_num, struct ahash_request *req,
+ 			 struct shash_desc *desc, struct test_sglist *tsgl,
+ 			 u8 *hashstate)
+ {
+ 	char vec_name[16];
+ 	unsigned int i;
+ 	int err;
+ 
+ 	sprintf(vec_name, "%u", vec_num);
+ 
+ 	for (i = 0; i < ARRAY_SIZE(default_hash_testvec_configs); i++) {
+ 		err = test_hash_vec_cfg(driver, vec, vec_name,
+ 					&default_hash_testvec_configs[i],
+ 					req, desc, tsgl, hashstate);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ #ifdef CONFIG_CRYPTO_MANAGER_EXTRA_TESTS
+ 	if (!noextratests) {
+ 		struct testvec_config cfg;
+ 		char cfgname[TESTVEC_CONFIG_NAMELEN];
+ 
+ 		for (i = 0; i < fuzz_iterations; i++) {
+ 			generate_random_testvec_config(&cfg, cfgname,
+ 						       sizeof(cfgname));
+ 			err = test_hash_vec_cfg(driver, vec, vec_name, &cfg,
+ 						req, desc, tsgl, hashstate);
+ 			if (err)
+ 				return err;
+ 			cond_resched();
+ 		}
+ 	}
+ #endif
+ 	return 0;
+ }
+ 
+ #ifdef CONFIG_CRYPTO_MANAGER_EXTRA_TESTS
+ /*
+  * Generate a hash test vector from the given implementation.
+  * Assumes the buffers in 'vec' were already allocated.
+  */
+ static void generate_random_hash_testvec(struct shash_desc *desc,
+ 					 struct hash_testvec *vec,
+ 					 unsigned int maxkeysize,
+ 					 unsigned int maxdatasize,
+ 					 char *name, size_t max_namelen)
+ {
+ 	/* Data */
+ 	vec->psize = generate_random_length(maxdatasize);
+ 	generate_random_bytes((u8 *)vec->plaintext, vec->psize);
+ 
+ 	/*
+ 	 * Key: length in range [1, maxkeysize], but usually choose maxkeysize.
+ 	 * If algorithm is unkeyed, then maxkeysize == 0 and set ksize = 0.
+ 	 */
+ 	vec->setkey_error = 0;
+ 	vec->ksize = 0;
+ 	if (maxkeysize) {
+ 		vec->ksize = maxkeysize;
+ 		if (prandom_u32() % 4 == 0)
+ 			vec->ksize = 1 + (prandom_u32() % maxkeysize);
+ 		generate_random_bytes((u8 *)vec->key, vec->ksize);
+ 
+ 		vec->setkey_error = crypto_shash_setkey(desc->tfm, vec->key,
+ 							vec->ksize);
+ 		/* If the key couldn't be set, no need to continue to digest. */
+ 		if (vec->setkey_error)
+ 			goto done;
+ 	}
+ 
+ 	/* Digest */
+ 	vec->digest_error = crypto_shash_digest(desc, vec->plaintext,
+ 						vec->psize, (u8 *)vec->digest);
+ done:
+ 	snprintf(name, max_namelen, "\"random: psize=%u ksize=%u\"",
+ 		 vec->psize, vec->ksize);
+ }
+ 
+ /*
+  * Test the hash algorithm represented by @req against the corresponding generic
+  * implementation, if one is available.
+  */
+ static int test_hash_vs_generic_impl(const char *driver,
+ 				     const char *generic_driver,
+ 				     unsigned int maxkeysize,
+ 				     struct ahash_request *req,
+ 				     struct shash_desc *desc,
+ 				     struct test_sglist *tsgl,
+ 				     u8 *hashstate)
+ {
+ 	struct crypto_ahash *tfm = crypto_ahash_reqtfm(req);
+ 	const unsigned int digestsize = crypto_ahash_digestsize(tfm);
+ 	const unsigned int blocksize = crypto_ahash_blocksize(tfm);
+ 	const unsigned int maxdatasize = (2 * PAGE_SIZE) - TESTMGR_POISON_LEN;
+ 	const char *algname = crypto_hash_alg_common(tfm)->base.cra_name;
+ 	char _generic_driver[CRYPTO_MAX_ALG_NAME];
+ 	struct crypto_shash *generic_tfm = NULL;
+ 	struct shash_desc *generic_desc = NULL;
+ 	unsigned int i;
+ 	struct hash_testvec vec = { 0 };
+ 	char vec_name[64];
+ 	struct testvec_config *cfg;
+ 	char cfgname[TESTVEC_CONFIG_NAMELEN];
+ 	int err;
+ 
+ 	if (noextratests)
+ 		return 0;
+ 
+ 	if (!generic_driver) { /* Use default naming convention? */
+ 		err = build_generic_driver_name(algname, _generic_driver);
+ 		if (err)
+ 			return err;
+ 		generic_driver = _generic_driver;
+ 	}
+ 
+ 	if (strcmp(generic_driver, driver) == 0) /* Already the generic impl? */
+ 		return 0;
+ 
+ 	generic_tfm = crypto_alloc_shash(generic_driver, 0, 0);
+ 	if (IS_ERR(generic_tfm)) {
+ 		err = PTR_ERR(generic_tfm);
+ 		if (err == -ENOENT) {
+ 			pr_warn("alg: hash: skipping comparison tests for %s because %s is unavailable\n",
+ 				driver, generic_driver);
+ 			return 0;
+ 		}
+ 		pr_err("alg: hash: error allocating %s (generic impl of %s): %d\n",
+ 		       generic_driver, algname, err);
+ 		return err;
+ 	}
+ 
+ 	cfg = kzalloc(sizeof(*cfg), GFP_KERNEL);
+ 	if (!cfg) {
+ 		err = -ENOMEM;
+ 		goto out;
+ 	}
+ 
+ 	generic_desc = kzalloc(sizeof(*desc) +
+ 			       crypto_shash_descsize(generic_tfm), GFP_KERNEL);
+ 	if (!generic_desc) {
+ 		err = -ENOMEM;
+ 		goto out;
+ 	}
+ 	generic_desc->tfm = generic_tfm;
+ 
+ 	/* Check the algorithm properties for consistency. */
+ 
+ 	if (digestsize != crypto_shash_digestsize(generic_tfm)) {
+ 		pr_err("alg: hash: digestsize for %s (%u) doesn't match generic impl (%u)\n",
+ 		       driver, digestsize,
+ 		       crypto_shash_digestsize(generic_tfm));
+ 		err = -EINVAL;
+ 		goto out;
+ 	}
+ 
+ 	if (blocksize != crypto_shash_blocksize(generic_tfm)) {
+ 		pr_err("alg: hash: blocksize for %s (%u) doesn't match generic impl (%u)\n",
+ 		       driver, blocksize, crypto_shash_blocksize(generic_tfm));
+ 		err = -EINVAL;
+ 		goto out;
+ 	}
+ 
+ 	/*
+ 	 * Now generate test vectors using the generic implementation, and test
+ 	 * the other implementation against them.
+ 	 */
+ 
+ 	vec.key = kmalloc(maxkeysize, GFP_KERNEL);
+ 	vec.plaintext = kmalloc(maxdatasize, GFP_KERNEL);
+ 	vec.digest = kmalloc(digestsize, GFP_KERNEL);
+ 	if (!vec.key || !vec.plaintext || !vec.digest) {
+ 		err = -ENOMEM;
+ 		goto out;
+ 	}
+ 
+ 	for (i = 0; i < fuzz_iterations * 8; i++) {
+ 		generate_random_hash_testvec(generic_desc, &vec,
+ 					     maxkeysize, maxdatasize,
+ 					     vec_name, sizeof(vec_name));
+ 		generate_random_testvec_config(cfg, cfgname, sizeof(cfgname));
+ 
+ 		err = test_hash_vec_cfg(driver, &vec, vec_name, cfg,
+ 					req, desc, tsgl, hashstate);
+ 		if (err)
+ 			goto out;
+ 		cond_resched();
+ 	}
+ 	err = 0;
+ out:
+ 	kfree(cfg);
+ 	kfree(vec.key);
+ 	kfree(vec.plaintext);
+ 	kfree(vec.digest);
+ 	crypto_free_shash(generic_tfm);
+ 	kfree_sensitive(generic_desc);
+ 	return err;
+ }
+ #else /* !CONFIG_CRYPTO_MANAGER_EXTRA_TESTS */
+ static int test_hash_vs_generic_impl(const char *driver,
+ 				     const char *generic_driver,
+ 				     unsigned int maxkeysize,
+ 				     struct ahash_request *req,
+ 				     struct shash_desc *desc,
+ 				     struct test_sglist *tsgl,
+ 				     u8 *hashstate)
+ {
+ 	return 0;
+ }
+ #endif /* !CONFIG_CRYPTO_MANAGER_EXTRA_TESTS */
+ 
+ static int alloc_shash(const char *driver, u32 type, u32 mask,
+ 		       struct crypto_shash **tfm_ret,
+ 		       struct shash_desc **desc_ret)
+ {
+ 	struct crypto_shash *tfm;
+ 	struct shash_desc *desc;
+ 
+ 	tfm = crypto_alloc_shash(driver, type, mask);
+ 	if (IS_ERR(tfm)) {
+ 		if (PTR_ERR(tfm) == -ENOENT) {
+ 			/*
+ 			 * This algorithm is only available through the ahash
+ 			 * API, not the shash API, so skip the shash tests.
+ 			 */
+ 			return 0;
+ 		}
+ 		pr_err("alg: hash: failed to allocate shash transform for %s: %ld\n",
+ 		       driver, PTR_ERR(tfm));
+ 		return PTR_ERR(tfm);
+ 	}
+ 
+ 	desc = kmalloc(sizeof(*desc) + crypto_shash_descsize(tfm), GFP_KERNEL);
+ 	if (!desc) {
+ 		crypto_free_shash(tfm);
+ 		return -ENOMEM;
+ 	}
+ 	desc->tfm = tfm;
+ 
+ 	*tfm_ret = tfm;
+ 	*desc_ret = desc;
+ 	return 0;
+ }
+ 
+ static int __alg_test_hash(const struct hash_testvec *vecs,
+ 			   unsigned int num_vecs, const char *driver,
+ 			   u32 type, u32 mask,
+ 			   const char *generic_driver, unsigned int maxkeysize)
+ {
+ 	struct crypto_ahash *atfm = NULL;
+ 	struct ahash_request *req = NULL;
+ 	struct crypto_shash *stfm = NULL;
+ 	struct shash_desc *desc = NULL;
+ 	struct test_sglist *tsgl = NULL;
+ 	u8 *hashstate = NULL;
+ 	unsigned int statesize;
+ 	unsigned int i;
+ 	int err;
+ 
+ 	/*
+ 	 * Always test the ahash API.  This works regardless of whether the
+ 	 * algorithm is implemented as ahash or shash.
+ 	 */
+ 
+ 	atfm = crypto_alloc_ahash(driver, type, mask);
+ 	if (IS_ERR(atfm)) {
+ 		pr_err("alg: hash: failed to allocate transform for %s: %ld\n",
+ 		       driver, PTR_ERR(atfm));
+ 		return PTR_ERR(atfm);
+ 	}
+ 
+ 	req = ahash_request_alloc(atfm, GFP_KERNEL);
+ 	if (!req) {
+ 		pr_err("alg: hash: failed to allocate request for %s\n",
+ 		       driver);
+ 		err = -ENOMEM;
+ 		goto out;
+ 	}
+ 
+ 	/*
+ 	 * If available also test the shash API, to cover corner cases that may
+ 	 * be missed by testing the ahash API only.
+ 	 */
+ 	err = alloc_shash(driver, type, mask, &stfm, &desc);
+ 	if (err)
+ 		goto out;
+ 
+ 	tsgl = kmalloc(sizeof(*tsgl), GFP_KERNEL);
+ 	if (!tsgl || init_test_sglist(tsgl) != 0) {
+ 		pr_err("alg: hash: failed to allocate test buffers for %s\n",
+ 		       driver);
+ 		kfree(tsgl);
+ 		tsgl = NULL;
+ 		err = -ENOMEM;
+ 		goto out;
+ 	}
+ 
+ 	statesize = crypto_ahash_statesize(atfm);
+ 	if (stfm)
+ 		statesize = max(statesize, crypto_shash_statesize(stfm));
+ 	hashstate = kmalloc(statesize + TESTMGR_POISON_LEN, GFP_KERNEL);
+ 	if (!hashstate) {
+ 		pr_err("alg: hash: failed to allocate hash state buffer for %s\n",
+ 		       driver);
+ 		err = -ENOMEM;
+ 		goto out;
+ 	}
+ 
+ 	for (i = 0; i < num_vecs; i++) {
+ 		err = test_hash_vec(driver, &vecs[i], i, req, desc, tsgl,
+ 				    hashstate);
+ 		if (err)
+ 			goto out;
+ 		cond_resched();
+ 	}
+ 	err = test_hash_vs_generic_impl(driver, generic_driver, maxkeysize, req,
+ 					desc, tsgl, hashstate);
+ out:
+ 	kfree(hashstate);
+ 	if (tsgl) {
+ 		destroy_test_sglist(tsgl);
+ 		kfree(tsgl);
+ 	}
+ 	kfree(desc);
+ 	crypto_free_shash(stfm);
+ 	ahash_request_free(req);
+ 	crypto_free_ahash(atfm);
+ 	return err;
+ }
+ 
+ static int alg_test_hash(const struct alg_test_desc *desc, const char *driver,
+ 			 u32 type, u32 mask)
+ {
+ 	const struct hash_testvec *template = desc->suite.hash.vecs;
+ 	unsigned int tcount = desc->suite.hash.count;
+ 	unsigned int nr_unkeyed, nr_keyed;
+ 	unsigned int maxkeysize = 0;
+ 	int err;
+ 
+ 	/*
+ 	 * For OPTIONAL_KEY algorithms, we have to do all the unkeyed tests
+ 	 * first, before setting a key on the tfm.  To make this easier, we
+ 	 * require that the unkeyed test vectors (if any) are listed first.
+ 	 */
+ 
+ 	for (nr_unkeyed = 0; nr_unkeyed < tcount; nr_unkeyed++) {
+ 		if (template[nr_unkeyed].ksize)
+ 			break;
+ 	}
+ 	for (nr_keyed = 0; nr_unkeyed + nr_keyed < tcount; nr_keyed++) {
+ 		if (!template[nr_unkeyed + nr_keyed].ksize) {
+ 			pr_err("alg: hash: test vectors for %s out of order, "
+ 			       "unkeyed ones must come first\n", desc->alg);
+ 			return -EINVAL;
+ 		}
+ 		maxkeysize = max_t(unsigned int, maxkeysize,
+ 				   template[nr_unkeyed + nr_keyed].ksize);
+ 	}
+ 
+ 	err = 0;
+ 	if (nr_unkeyed) {
+ 		err = __alg_test_hash(template, nr_unkeyed, driver, type, mask,
+ 				      desc->generic_driver, maxkeysize);
+ 		template += nr_unkeyed;
+ 	}
+ 
+ 	if (!err && nr_keyed)
+ 		err = __alg_test_hash(template, nr_keyed, driver, type, mask,
+ 				      desc->generic_driver, maxkeysize);
+ 
+ 	return err;
+ }
+ 
+ static int test_aead_vec_cfg(const char *driver, int enc,
+ 			     const struct aead_testvec *vec,
+ 			     const char *vec_name,
+ 			     const struct testvec_config *cfg,
+ 			     struct aead_request *req,
+ 			     struct cipher_test_sglists *tsgls)
+ {
+ 	struct crypto_aead *tfm = crypto_aead_reqtfm(req);
+ 	const unsigned int alignmask = crypto_aead_alignmask(tfm);
+ 	const unsigned int ivsize = crypto_aead_ivsize(tfm);
+ 	const unsigned int authsize = vec->clen - vec->plen;
+ 	const u32 req_flags = CRYPTO_TFM_REQ_MAY_BACKLOG | cfg->req_flags;
+ 	const char *op = enc ? "encryption" : "decryption";
+ 	DECLARE_CRYPTO_WAIT(wait);
+ 	u8 _iv[3 * (MAX_ALGAPI_ALIGNMASK + 1) + MAX_IVLEN];
+ 	u8 *iv = PTR_ALIGN(&_iv[0], 2 * (MAX_ALGAPI_ALIGNMASK + 1)) +
+ 		 cfg->iv_offset +
+ 		 (cfg->iv_offset_relative_to_alignmask ? alignmask : 0);
+ 	struct kvec input[2];
+ 	int err;
+ 
+ 	/* Set the key */
+ 	if (vec->wk)
+ 		crypto_aead_set_flags(tfm, CRYPTO_TFM_REQ_FORBID_WEAK_KEYS);
+ 	else
+ 		crypto_aead_clear_flags(tfm, CRYPTO_TFM_REQ_FORBID_WEAK_KEYS);
+ 
+ 	err = do_setkey(crypto_aead_setkey, tfm, vec->key, vec->klen,
+ 			cfg, alignmask);
+ 	if (err && err != vec->setkey_error) {
+ 		pr_err("alg: aead: %s setkey failed on test vector %s; expected_error=%d, actual_error=%d, flags=%#x\n",
+ 		       driver, vec_name, vec->setkey_error, err,
+ 		       crypto_aead_get_flags(tfm));
+ 		return err;
+ 	}
+ 	if (!err && vec->setkey_error) {
+ 		pr_err("alg: aead: %s setkey unexpectedly succeeded on test vector %s; expected_error=%d\n",
+ 		       driver, vec_name, vec->setkey_error);
+ 		return -EINVAL;
+ 	}
+ 
+ 	/* Set the authentication tag size */
+ 	err = crypto_aead_setauthsize(tfm, authsize);
+ 	if (err && err != vec->setauthsize_error) {
+ 		pr_err("alg: aead: %s setauthsize failed on test vector %s; expected_error=%d, actual_error=%d\n",
+ 		       driver, vec_name, vec->setauthsize_error, err);
+ 		return err;
+ 	}
+ 	if (!err && vec->setauthsize_error) {
+ 		pr_err("alg: aead: %s setauthsize unexpectedly succeeded on test vector %s; expected_error=%d\n",
+ 		       driver, vec_name, vec->setauthsize_error);
+ 		return -EINVAL;
+ 	}
+ 
+ 	if (vec->setkey_error || vec->setauthsize_error)
+ 		return 0;
+ 
+ 	/* The IV must be copied to a buffer, as the algorithm may modify it */
+ 	if (WARN_ON(ivsize > MAX_IVLEN))
+ 		return -EINVAL;
+ 	if (vec->iv)
+ 		memcpy(iv, vec->iv, ivsize);
+ 	else
+ 		memset(iv, 0, ivsize);
+ 
+ 	/* Build the src/dst scatterlists */
+ 	input[0].iov_base = (void *)vec->assoc;
+ 	input[0].iov_len = vec->alen;
+ 	input[1].iov_base = enc ? (void *)vec->ptext : (void *)vec->ctext;
+ 	input[1].iov_len = enc ? vec->plen : vec->clen;
+ 	err = build_cipher_test_sglists(tsgls, cfg, alignmask,
+ 					vec->alen + (enc ? vec->plen :
+ 						     vec->clen),
+ 					vec->alen + (enc ? vec->clen :
+ 						     vec->plen),
+ 					input, 2);
+ 	if (err) {
+ 		pr_err("alg: aead: %s %s: error preparing scatterlists for test vector %s, cfg=\"%s\"\n",
+ 		       driver, op, vec_name, cfg->name);
+ 		return err;
+ 	}
+ 
+ 	/* Do the actual encryption or decryption */
+ 	testmgr_poison(req->__ctx, crypto_aead_reqsize(tfm));
+ 	aead_request_set_callback(req, req_flags, crypto_req_done, &wait);
+ 	aead_request_set_crypt(req, tsgls->src.sgl_ptr, tsgls->dst.sgl_ptr,
+ 			       enc ? vec->plen : vec->clen, iv);
+ 	aead_request_set_ad(req, vec->alen);
+ 	if (cfg->nosimd)
+ 		crypto_disable_simd_for_test();
+ 	err = enc ? crypto_aead_encrypt(req) : crypto_aead_decrypt(req);
+ 	if (cfg->nosimd)
+ 		crypto_reenable_simd_for_test();
+ 	err = crypto_wait_req(err, &wait);
+ 
+ 	/* Check that the algorithm didn't overwrite things it shouldn't have */
+ 	if (req->cryptlen != (enc ? vec->plen : vec->clen) ||
+ 	    req->assoclen != vec->alen ||
+ 	    req->iv != iv ||
+ 	    req->src != tsgls->src.sgl_ptr ||
+ 	    req->dst != tsgls->dst.sgl_ptr ||
+ 	    crypto_aead_reqtfm(req) != tfm ||
+ 	    req->base.complete != crypto_req_done ||
+ 	    req->base.flags != req_flags ||
+ 	    req->base.data != &wait) {
+ 		pr_err("alg: aead: %s %s corrupted request struct on test vector %s, cfg=\"%s\"\n",
+ 		       driver, op, vec_name, cfg->name);
+ 		if (req->cryptlen != (enc ? vec->plen : vec->clen))
+ 			pr_err("alg: aead: changed 'req->cryptlen'\n");
+ 		if (req->assoclen != vec->alen)
+ 			pr_err("alg: aead: changed 'req->assoclen'\n");
+ 		if (req->iv != iv)
+ 			pr_err("alg: aead: changed 'req->iv'\n");
+ 		if (req->src != tsgls->src.sgl_ptr)
+ 			pr_err("alg: aead: changed 'req->src'\n");
+ 		if (req->dst != tsgls->dst.sgl_ptr)
+ 			pr_err("alg: aead: changed 'req->dst'\n");
+ 		if (crypto_aead_reqtfm(req) != tfm)
+ 			pr_err("alg: aead: changed 'req->base.tfm'\n");
+ 		if (req->base.complete != crypto_req_done)
+ 			pr_err("alg: aead: changed 'req->base.complete'\n");
+ 		if (req->base.flags != req_flags)
+ 			pr_err("alg: aead: changed 'req->base.flags'\n");
+ 		if (req->base.data != &wait)
+ 			pr_err("alg: aead: changed 'req->base.data'\n");
+ 		return -EINVAL;
+ 	}
+ 	if (is_test_sglist_corrupted(&tsgls->src)) {
+ 		pr_err("alg: aead: %s %s corrupted src sgl on test vector %s, cfg=\"%s\"\n",
+ 		       driver, op, vec_name, cfg->name);
+ 		return -EINVAL;
+ 	}
+ 	if (tsgls->dst.sgl_ptr != tsgls->src.sgl &&
+ 	    is_test_sglist_corrupted(&tsgls->dst)) {
+ 		pr_err("alg: aead: %s %s corrupted dst sgl on test vector %s, cfg=\"%s\"\n",
+ 		       driver, op, vec_name, cfg->name);
+ 		return -EINVAL;
+ 	}
+ 
+ 	/* Check for unexpected success or failure, or wrong error code */
+ 	if ((err == 0 && vec->novrfy) ||
+ 	    (err != vec->crypt_error && !(err == -EBADMSG && vec->novrfy))) {
+ 		char expected_error[32];
+ 
+ 		if (vec->novrfy &&
+ 		    vec->crypt_error != 0 && vec->crypt_error != -EBADMSG)
+ 			sprintf(expected_error, "-EBADMSG or %d",
+ 				vec->crypt_error);
+ 		else if (vec->novrfy)
+ 			sprintf(expected_error, "-EBADMSG");
+ 		else
+ 			sprintf(expected_error, "%d", vec->crypt_error);
+ 		if (err) {
+ 			pr_err("alg: aead: %s %s failed on test vector %s; expected_error=%s, actual_error=%d, cfg=\"%s\"\n",
+ 			       driver, op, vec_name, expected_error, err,
+ 			       cfg->name);
+ 			return err;
+ 		}
+ 		pr_err("alg: aead: %s %s unexpectedly succeeded on test vector %s; expected_error=%s, cfg=\"%s\"\n",
+ 		       driver, op, vec_name, expected_error, cfg->name);
+ 		return -EINVAL;
+ 	}
+ 	if (err) /* Expectedly failed. */
+ 		return 0;
+ 
+ 	/* Check for the correct output (ciphertext or plaintext) */
+ 	err = verify_correct_output(&tsgls->dst, enc ? vec->ctext : vec->ptext,
+ 				    enc ? vec->clen : vec->plen,
+ 				    vec->alen, enc || !cfg->inplace);
+ 	if (err == -EOVERFLOW) {
+ 		pr_err("alg: aead: %s %s overran dst buffer on test vector %s, cfg=\"%s\"\n",
+ 		       driver, op, vec_name, cfg->name);
+ 		return err;
+ 	}
+ 	if (err) {
+ 		pr_err("alg: aead: %s %s test failed (wrong result) on test vector %s, cfg=\"%s\"\n",
+ 		       driver, op, vec_name, cfg->name);
+ 		return err;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int test_aead_vec(const char *driver, int enc,
+ 			 const struct aead_testvec *vec, unsigned int vec_num,
+ 			 struct aead_request *req,
+ 			 struct cipher_test_sglists *tsgls)
+ {
+ 	char vec_name[16];
+ 	unsigned int i;
+ 	int err;
+ 
+ 	if (enc && vec->novrfy)
+ 		return 0;
+ 
+ 	sprintf(vec_name, "%u", vec_num);
+ 
+ 	for (i = 0; i < ARRAY_SIZE(default_cipher_testvec_configs); i++) {
+ 		err = test_aead_vec_cfg(driver, enc, vec, vec_name,
+ 					&default_cipher_testvec_configs[i],
+ 					req, tsgls);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ #ifdef CONFIG_CRYPTO_MANAGER_EXTRA_TESTS
+ 	if (!noextratests) {
+ 		struct testvec_config cfg;
+ 		char cfgname[TESTVEC_CONFIG_NAMELEN];
+ 
+ 		for (i = 0; i < fuzz_iterations; i++) {
+ 			generate_random_testvec_config(&cfg, cfgname,
+ 						       sizeof(cfgname));
+ 			err = test_aead_vec_cfg(driver, enc, vec, vec_name,
+ 						&cfg, req, tsgls);
+ 			if (err)
+ 				return err;
+ 			cond_resched();
+ 		}
+ 	}
+ #endif
+ 	return 0;
+ }
+ 
+ #ifdef CONFIG_CRYPTO_MANAGER_EXTRA_TESTS
+ 
+ struct aead_extra_tests_ctx {
+ 	struct aead_request *req;
+ 	struct crypto_aead *tfm;
+ 	const char *driver;
+ 	const struct alg_test_desc *test_desc;
+ 	struct cipher_test_sglists *tsgls;
+ 	unsigned int maxdatasize;
+ 	unsigned int maxkeysize;
+ 
+ 	struct aead_testvec vec;
+ 	char vec_name[64];
+ 	char cfgname[TESTVEC_CONFIG_NAMELEN];
+ 	struct testvec_config cfg;
+ };
+ 
+ /*
+  * Make at least one random change to a (ciphertext, AAD) pair.  "Ciphertext"
+  * here means the full ciphertext including the authentication tag.  The
+  * authentication tag (and hence also the ciphertext) is assumed to be nonempty.
+  */
+ static void mutate_aead_message(struct aead_testvec *vec, bool aad_iv,
+ 				unsigned int ivsize)
+ {
+ 	const unsigned int aad_tail_size = aad_iv ? ivsize : 0;
+ 	const unsigned int authsize = vec->clen - vec->plen;
+ 
+ 	if (prandom_u32() % 2 == 0 && vec->alen > aad_tail_size) {
+ 		 /* Mutate the AAD */
+ 		flip_random_bit((u8 *)vec->assoc, vec->alen - aad_tail_size);
+ 		if (prandom_u32() % 2 == 0)
+ 			return;
+ 	}
+ 	if (prandom_u32() % 2 == 0) {
+ 		/* Mutate auth tag (assuming it's at the end of ciphertext) */
+ 		flip_random_bit((u8 *)vec->ctext + vec->plen, authsize);
+ 	} else {
+ 		/* Mutate any part of the ciphertext */
+ 		flip_random_bit((u8 *)vec->ctext, vec->clen);
+ 	}
+ }
+ 
+ /*
+  * Minimum authentication tag size in bytes at which we assume that we can
+  * reliably generate inauthentic messages, i.e. not generate an authentic
+  * message by chance.
+  */
+ #define MIN_COLLISION_FREE_AUTHSIZE 8
+ 
+ static void generate_aead_message(struct aead_request *req,
+ 				  const struct aead_test_suite *suite,
+ 				  struct aead_testvec *vec,
+ 				  bool prefer_inauthentic)
+ {
+ 	struct crypto_aead *tfm = crypto_aead_reqtfm(req);
+ 	const unsigned int ivsize = crypto_aead_ivsize(tfm);
+ 	const unsigned int authsize = vec->clen - vec->plen;
+ 	const bool inauthentic = (authsize >= MIN_COLLISION_FREE_AUTHSIZE) &&
+ 				 (prefer_inauthentic || prandom_u32() % 4 == 0);
+ 
+ 	/* Generate the AAD. */
+ 	generate_random_bytes((u8 *)vec->assoc, vec->alen);
+ 	if (suite->aad_iv && vec->alen >= ivsize)
+ 		/* Avoid implementation-defined behavior. */
+ 		memcpy((u8 *)vec->assoc + vec->alen - ivsize, vec->iv, ivsize);
+ 
+ 	if (inauthentic && prandom_u32() % 2 == 0) {
+ 		/* Generate a random ciphertext. */
+ 		generate_random_bytes((u8 *)vec->ctext, vec->clen);
+ 	} else {
+ 		int i = 0;
+ 		struct scatterlist src[2], dst;
+ 		u8 iv[MAX_IVLEN];
+ 		DECLARE_CRYPTO_WAIT(wait);
+ 
+ 		/* Generate a random plaintext and encrypt it. */
+ 		sg_init_table(src, 2);
+ 		if (vec->alen)
+ 			sg_set_buf(&src[i++], vec->assoc, vec->alen);
+ 		if (vec->plen) {
+ 			generate_random_bytes((u8 *)vec->ptext, vec->plen);
+ 			sg_set_buf(&src[i++], vec->ptext, vec->plen);
+ 		}
+ 		sg_init_one(&dst, vec->ctext, vec->alen + vec->clen);
+ 		memcpy(iv, vec->iv, ivsize);
+ 		aead_request_set_callback(req, 0, crypto_req_done, &wait);
+ 		aead_request_set_crypt(req, src, &dst, vec->plen, iv);
+ 		aead_request_set_ad(req, vec->alen);
+ 		vec->crypt_error = crypto_wait_req(crypto_aead_encrypt(req),
+ 						   &wait);
+ 		/* If encryption failed, we're done. */
+ 		if (vec->crypt_error != 0)
+ 			return;
+ 		memmove((u8 *)vec->ctext, vec->ctext + vec->alen, vec->clen);
+ 		if (!inauthentic)
+ 			return;
+ 		/*
+ 		 * Mutate the authentic (ciphertext, AAD) pair to get an
+ 		 * inauthentic one.
+ 		 */
+ 		mutate_aead_message(vec, suite->aad_iv, ivsize);
+ 	}
+ 	vec->novrfy = 1;
+ 	if (suite->einval_allowed)
+ 		vec->crypt_error = -EINVAL;
+ }
+ 
+ /*
+  * Generate an AEAD test vector 'vec' using the implementation specified by
+  * 'req'.  The buffers in 'vec' must already be allocated.
+  *
+  * If 'prefer_inauthentic' is true, then this function will generate inauthentic
+  * test vectors (i.e. vectors with 'vec->novrfy=1') more often.
+  */
+ static void generate_random_aead_testvec(struct aead_request *req,
+ 					 struct aead_testvec *vec,
+ 					 const struct aead_test_suite *suite,
+ 					 unsigned int maxkeysize,
+ 					 unsigned int maxdatasize,
+ 					 char *name, size_t max_namelen,
+ 					 bool prefer_inauthentic)
+ {
+ 	struct crypto_aead *tfm = crypto_aead_reqtfm(req);
+ 	const unsigned int ivsize = crypto_aead_ivsize(tfm);
+ 	const unsigned int maxauthsize = crypto_aead_maxauthsize(tfm);
+ 	unsigned int authsize;
+ 	unsigned int total_len;
+ 
+ 	/* Key: length in [0, maxkeysize], but usually choose maxkeysize */
+ 	vec->klen = maxkeysize;
+ 	if (prandom_u32() % 4 == 0)
+ 		vec->klen = prandom_u32() % (maxkeysize + 1);
+ 	generate_random_bytes((u8 *)vec->key, vec->klen);
+ 	vec->setkey_error = crypto_aead_setkey(tfm, vec->key, vec->klen);
+ 
+ 	/* IV */
+ 	generate_random_bytes((u8 *)vec->iv, ivsize);
+ 
+ 	/* Tag length: in [0, maxauthsize], but usually choose maxauthsize */
+ 	authsize = maxauthsize;
+ 	if (prandom_u32() % 4 == 0)
+ 		authsize = prandom_u32() % (maxauthsize + 1);
+ 	if (prefer_inauthentic && authsize < MIN_COLLISION_FREE_AUTHSIZE)
+ 		authsize = MIN_COLLISION_FREE_AUTHSIZE;
+ 	if (WARN_ON(authsize > maxdatasize))
+ 		authsize = maxdatasize;
+ 	maxdatasize -= authsize;
+ 	vec->setauthsize_error = crypto_aead_setauthsize(tfm, authsize);
+ 
+ 	/* AAD, plaintext, and ciphertext lengths */
+ 	total_len = generate_random_length(maxdatasize);
+ 	if (prandom_u32() % 4 == 0)
+ 		vec->alen = 0;
+ 	else
+ 		vec->alen = generate_random_length(total_len);
+ 	vec->plen = total_len - vec->alen;
+ 	vec->clen = vec->plen + authsize;
+ 
+ 	/*
+ 	 * Generate the AAD, plaintext, and ciphertext.  Not applicable if the
+ 	 * key or the authentication tag size couldn't be set.
+ 	 */
+ 	vec->novrfy = 0;
+ 	vec->crypt_error = 0;
+ 	if (vec->setkey_error == 0 && vec->setauthsize_error == 0)
+ 		generate_aead_message(req, suite, vec, prefer_inauthentic);
+ 	snprintf(name, max_namelen,
+ 		 "\"random: alen=%u plen=%u authsize=%u klen=%u novrfy=%d\"",
+ 		 vec->alen, vec->plen, authsize, vec->klen, vec->novrfy);
+ }
+ 
+ static void try_to_generate_inauthentic_testvec(
+ 					struct aead_extra_tests_ctx *ctx)
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  {
  	int i;
  
diff --cc drivers/crypto/cavium/cpt/cptvf_reqmanager.c
index b0ba4331944b,dc5fda522719..000000000000
--- a/drivers/crypto/cavium/cpt/cptvf_reqmanager.c
+++ b/drivers/crypto/cavium/cpt/cptvf_reqmanager.c
@@@ -308,25 -305,15 +308,34 @@@ void do_request_cleanup(struct cpt_vf *
  		}
  	}
  
++<<<<<<< HEAD
 +	if (info->scatter_components)
 +		kzfree(info->scatter_components);
 +
 +	if (info->gather_components)
 +		kzfree(info->gather_components);
 +
 +	if (info->out_buffer)
 +		kzfree(info->out_buffer);
 +
 +	if (info->in_buffer)
 +		kzfree(info->in_buffer);
 +
 +	if (info->completion_addr)
 +		kzfree((void *)info->completion_addr);
 +
 +	kzfree(info);
++=======
+ 	kfree_sensitive(info->scatter_components);
+ 	kfree_sensitive(info->gather_components);
+ 	kfree_sensitive(info->out_buffer);
+ 	kfree_sensitive(info->in_buffer);
+ 	kfree_sensitive((void *)info->completion_addr);
+ 	kfree_sensitive(info);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  }
  
 -static void do_post_process(struct cpt_vf *cptvf, struct cpt_info_buffer *info)
 +void do_post_process(struct cpt_vf *cptvf, struct cpt_info_buffer *info)
  {
  	struct pci_dev *pdev = cptvf->pdev;
  
diff --cc drivers/crypto/cavium/nitrox/nitrox_lib.c
index 4fdc921ba611,a5cdc2b48bd6..000000000000
--- a/drivers/crypto/cavium/nitrox/nitrox_lib.c
+++ b/drivers/crypto/cavium/nitrox/nitrox_lib.c
@@@ -74,21 -89,73 +74,87 @@@ static void nitrox_cleanup_pkt_cmdqs(st
  	int i;
  
  	for (i = 0; i < ndev->nr_queues; i++) {
++<<<<<<< HEAD
 +		struct nitrox_cmdq *cmdq = &ndev->pkt_cmdqs[i];
 +
 +		cmdq_common_cleanup(cmdq);
++=======
+ 		nitrox_cmdq_cleanup(ndev->aqmq[i]);
+ 		kfree_sensitive(ndev->aqmq[i]);
+ 		ndev->aqmq[i] = NULL;
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	}
 +	kfree(ndev->pkt_cmdqs);
 +	ndev->pkt_cmdqs = NULL;
  }
  
 -static int nitrox_alloc_aqm_queues(struct nitrox_device *ndev)
 +static int nitrox_init_pkt_cmdqs(struct nitrox_device *ndev)
  {
 -	int i, err;
 +	int i, err, size;
  
++<<<<<<< HEAD
 +	size = ndev->nr_queues * sizeof(struct nitrox_cmdq);
 +	ndev->pkt_cmdqs = kzalloc(size, GFP_KERNEL);
 +	if (!ndev->pkt_cmdqs)
++=======
+ 	for (i = 0; i < ndev->nr_queues; i++) {
+ 		struct nitrox_cmdq *cmdq;
+ 		u64 offset;
+ 
+ 		cmdq = kzalloc_node(sizeof(*cmdq), GFP_KERNEL, ndev->node);
+ 		if (!cmdq) {
+ 			err = -ENOMEM;
+ 			goto aqmq_fail;
+ 		}
+ 
+ 		cmdq->ndev = ndev;
+ 		cmdq->qno = i;
+ 		cmdq->instr_size = sizeof(struct aqmq_command_s);
+ 
+ 		/* AQM Queue Doorbell Counter Register Address */
+ 		offset = AQMQ_DRBLX(i);
+ 		cmdq->dbell_csr_addr = NITROX_CSR_ADDR(ndev, offset);
+ 		/* AQM Queue Commands Completed Count Register Address */
+ 		offset = AQMQ_CMD_CNTX(i);
+ 		cmdq->compl_cnt_csr_addr = NITROX_CSR_ADDR(ndev, offset);
+ 
+ 		err = nitrox_cmdq_init(cmdq, AQM_Q_ALIGN_BYTES);
+ 		if (err) {
+ 			kfree_sensitive(cmdq);
+ 			goto aqmq_fail;
+ 		}
+ 		ndev->aqmq[i] = cmdq;
+ 	}
+ 
+ 	return 0;
+ 
+ aqmq_fail:
+ 	nitrox_free_aqm_queues(ndev);
+ 	return err;
+ }
+ 
+ static void nitrox_free_pktin_queues(struct nitrox_device *ndev)
+ {
+ 	int i;
+ 
+ 	for (i = 0; i < ndev->nr_queues; i++) {
+ 		struct nitrox_cmdq *cmdq = &ndev->pkt_inq[i];
+ 
+ 		nitrox_cmdq_cleanup(cmdq);
+ 	}
+ 	kfree(ndev->pkt_inq);
+ 	ndev->pkt_inq = NULL;
+ }
+ 
+ static int nitrox_alloc_pktin_queues(struct nitrox_device *ndev)
+ {
+ 	int i, err;
+ 
+ 	ndev->pkt_inq = kcalloc_node(ndev->nr_queues,
+ 				     sizeof(struct nitrox_cmdq),
+ 				     GFP_KERNEL, ndev->node);
+ 	if (!ndev->pkt_inq)
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  		return -ENOMEM;
  
  	for (i = 0; i < ndev->nr_queues; i++) {
diff --cc drivers/crypto/ccree/cc_aead.c
index f71917756a7f,35794c7271fb..000000000000
--- a/drivers/crypto/ccree/cc_aead.c
+++ b/drivers/crypto/ccree/cc_aead.c
@@@ -451,6 -448,7 +451,10 @@@ static int cc_get_plain_hmac_key(struc
  		if (dma_mapping_error(dev, key_dma_addr)) {
  			dev_err(dev, "Mapping key va=0x%p len=%u for DMA failed\n",
  				key, keylen);
++<<<<<<< HEAD
++=======
+ 			kfree_sensitive(key);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  			return -ENOMEM;
  		}
  		if (keylen > blocksize) {
@@@ -533,6 -533,8 +537,11 @@@
  	if (key_dma_addr)
  		dma_unmap_single(dev, key_dma_addr, keylen, DMA_TO_DEVICE);
  
++<<<<<<< HEAD
++=======
+ 	kfree_sensitive(key);
+ 
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	return rc;
  }
  
diff --cc drivers/crypto/ccree/cc_buffer_mgr.c
index b32577477b4c,a5e041d9d2cf..000000000000
--- a/drivers/crypto/ccree/cc_buffer_mgr.c
+++ b/drivers/crypto/ccree/cc_buffer_mgr.c
@@@ -616,12 -488,13 +616,16 @@@ void cc_unmap_aead_request(struct devic
  	if (areq_ctx->gen_ctx.iv_dma_addr) {
  		dma_unmap_single(dev, areq_ctx->gen_ctx.iv_dma_addr,
  				 hw_iv_size, DMA_BIDIRECTIONAL);
++<<<<<<< HEAD
++=======
+ 		kfree_sensitive(areq_ctx->gen_ctx.iv);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	}
  
 -	/* Release pool */
 -	if ((areq_ctx->assoc_buff_type == CC_DMA_BUF_MLLI ||
 -	     areq_ctx->data_buff_type == CC_DMA_BUF_MLLI) &&
 -	    (areq_ctx->mlli_params.mlli_virt_addr)) {
 +	/*In case a pool was set, a table was
 +	 *allocated and should be released
 +	 */
 +	if (areq_ctx->mlli_params.curr_pool) {
  		dev_dbg(dev, "free MLLI buffer: dma=%pad virt=%pK\n",
  			&areq_ctx->mlli_params.mlli_dma_addr,
  			areq_ctx->mlli_params.mlli_virt_addr);
@@@ -734,6 -559,8 +738,11 @@@ static int cc_aead_chain_iv(struct cc_d
  	if (dma_mapping_error(dev, areq_ctx->gen_ctx.iv_dma_addr)) {
  		dev_err(dev, "Mapping iv %u B at va=%pK for DMA failed\n",
  			hw_iv_size, req->iv);
++<<<<<<< HEAD
++=======
+ 		kfree_sensitive(areq_ctx->gen_ctx.iv);
+ 		areq_ctx->gen_ctx.iv = NULL;
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  		rc = -ENOMEM;
  		goto chain_iv_exit;
  	}
diff --cc drivers/crypto/ccree/cc_cipher.c
index d2810c183b73,d77ae981b64b..000000000000
--- a/drivers/crypto/ccree/cc_cipher.c
+++ b/drivers/crypto/ccree/cc_cipher.c
@@@ -599,26 -874,14 +599,34 @@@ static void cc_cipher_complete(struct d
  	struct scatterlist *dst = req->dst;
  	struct scatterlist *src = req->src;
  	struct cipher_req_ctx *req_ctx = skcipher_request_ctx(req);
 -	struct crypto_skcipher *sk_tfm = crypto_skcipher_reqtfm(req);
 -	unsigned int ivsize = crypto_skcipher_ivsize(sk_tfm);
 +	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
 +	unsigned int ivsize = crypto_skcipher_ivsize(tfm);
  
++<<<<<<< HEAD
 +	cc_unmap_cipher_request(dev, req_ctx, ivsize, src, dst);
 +	kzfree(req_ctx->iv);
 +
 +	/*
 +	 * The crypto API expects us to set the req->iv to the last
 +	 * ciphertext block. For encrypt, simply copy from the result.
 +	 * For decrypt, we must copy from a saved buffer since this
 +	 * could be an in-place decryption operation and the src is
 +	 * lost by this point.
 +	 */
 +	if (req_ctx->gen_ctx.op_type == DRV_CRYPTO_DIRECTION_DECRYPT)  {
 +		memcpy(req->iv, req_ctx->backup_info, ivsize);
 +		kzfree(req_ctx->backup_info);
 +	} else if (!err) {
 +		scatterwalk_map_and_copy(req->iv, req->dst,
 +					 (req->cryptlen - ivsize),
 +					 ivsize, 0);
++=======
+ 	if (err != -EINPROGRESS) {
+ 		/* Not a BACKLOG notification */
+ 		cc_unmap_cipher_request(dev, req_ctx, ivsize, src, dst);
+ 		memcpy(req->iv, req_ctx->iv, ivsize);
+ 		kfree_sensitive(req_ctx->iv);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	}
  
  	skcipher_request_complete(req, err);
@@@ -728,12 -993,8 +736,16 @@@ static int cc_cipher_process(struct skc
  	}
  
  exit_process:
 +	if (cts_restore_flag)
 +		ctx_p->cipher_mode = DRV_CIPHER_CBC_CTS;
 +
  	if (rc != -EINPROGRESS && rc != -EBUSY) {
++<<<<<<< HEAD
 +		kzfree(req_ctx->backup_info);
 +		kzfree(req_ctx->iv);
++=======
+ 		kfree_sensitive(req_ctx->iv);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	}
  
  	return rc;
diff --cc drivers/crypto/ccree/cc_hash.c
index 96ff777474d7,683c9a430e11..000000000000
--- a/drivers/crypto/ccree/cc_hash.c
+++ b/drivers/crypto/ccree/cc_hash.c
@@@ -773,13 -751,20 +773,18 @@@ static int cc_hash_setkey(struct crypto
  	ctx->key_params.keylen = keylen;
  	ctx->key_params.key_dma_addr = 0;
  	ctx->is_hmac = true;
 -	ctx->key_params.key = NULL;
  
  	if (keylen) {
 -		ctx->key_params.key = kmemdup(key, keylen, GFP_KERNEL);
 -		if (!ctx->key_params.key)
 -			return -ENOMEM;
 -
  		ctx->key_params.key_dma_addr =
 -			dma_map_single(dev, ctx->key_params.key, keylen,
 -				       DMA_TO_DEVICE);
 +			dma_map_single(dev, (void *)key, keylen, DMA_TO_DEVICE);
  		if (dma_mapping_error(dev, ctx->key_params.key_dma_addr)) {
  			dev_err(dev, "Mapping key va=0x%p len=%u for DMA failed\n",
++<<<<<<< HEAD
 +				key, keylen);
++=======
+ 				ctx->key_params.key, keylen);
+ 			kfree_sensitive(ctx->key_params.key);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  			return -ENOMEM;
  		}
  		dev_dbg(dev, "mapping key-buffer: key_dma_addr=%pad keylen=%u\n",
@@@ -930,6 -912,9 +935,12 @@@ out
  		dev_dbg(dev, "Unmapped key-buffer: key_dma_addr=%pad keylen=%u\n",
  			&ctx->key_params.key_dma_addr, ctx->key_params.keylen);
  	}
++<<<<<<< HEAD
++=======
+ 
+ 	kfree_sensitive(ctx->key_params.key);
+ 
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	return rc;
  }
  
@@@ -961,6 -950,7 +972,10 @@@ static int cc_xcbc_setkey(struct crypto
  	if (dma_mapping_error(dev, ctx->key_params.key_dma_addr)) {
  		dev_err(dev, "Mapping key va=0x%p len=%u for DMA failed\n",
  			key, keylen);
++<<<<<<< HEAD
++=======
+ 		kfree_sensitive(ctx->key_params.key);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  		return -ENOMEM;
  	}
  	dev_dbg(dev, "mapping key-buffer: key_dma_addr=%pad keylen=%u\n",
@@@ -1012,6 -999,8 +1027,11 @@@
  	dev_dbg(dev, "Unmapped key-buffer: key_dma_addr=%pad keylen=%u\n",
  		&ctx->key_params.key_dma_addr, ctx->key_params.keylen);
  
++<<<<<<< HEAD
++=======
+ 	kfree_sensitive(ctx->key_params.key);
+ 
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	return rc;
  }
  
diff --cc drivers/crypto/marvell/hash.c
index e34d80b6b7e5,f2a2fc111164..000000000000
--- a/drivers/crypto/marvell/hash.c
+++ b/drivers/crypto/marvell/hash.c
@@@ -1152,8 -1157,7 +1152,12 @@@ static int mv_cesa_ahmac_pad_init(struc
  		}
  
  		/* Set the memory region to 0 to avoid any leak. */
++<<<<<<< HEAD:drivers/crypto/marvell/hash.c
 +		memset(keydup, 0, keylen);
 +		kfree(keydup);
++=======
+ 		kfree_sensitive(keydup);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive()):drivers/crypto/marvell/cesa/hash.c
  
  		if (ret)
  			return ret;
diff --cc drivers/crypto/virtio/virtio_crypto_algs.c
index af6a908dfa7a,583c0b535d13..000000000000
--- a/drivers/crypto/virtio/virtio_crypto_algs.c
+++ b/drivers/crypto/virtio/virtio_crypto_algs.c
@@@ -560,38 -574,42 +560,46 @@@ int virtio_crypto_ablkcipher_crypt_req
  	return 0;
  }
  
 -static void virtio_crypto_skcipher_finalize_req(
 +static void virtio_crypto_ablkcipher_finalize_req(
  	struct virtio_crypto_sym_request *vc_sym_req,
 -	struct skcipher_request *req,
 +	struct ablkcipher_request *req,
  	int err)
  {
++<<<<<<< HEAD
 +	crypto_finalize_ablkcipher_request(vc_sym_req->base.dataq->engine,
 +					   req, err);
 +	kzfree(vc_sym_req->iv);
++=======
+ 	if (vc_sym_req->encrypt)
+ 		scatterwalk_map_and_copy(req->iv, req->dst,
+ 					 req->cryptlen - AES_BLOCK_SIZE,
+ 					 AES_BLOCK_SIZE, 0);
+ 	kfree_sensitive(vc_sym_req->iv);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	virtcrypto_clear_request(&vc_sym_req->base);
 -
 -	crypto_finalize_skcipher_request(vc_sym_req->base.dataq->engine,
 -					   req, err);
  }
  
 -static struct virtio_crypto_algo virtio_crypto_algs[] = { {
 -	.algonum = VIRTIO_CRYPTO_CIPHER_AES_CBC,
 -	.service = VIRTIO_CRYPTO_SERVICE_CIPHER,
 -	.algo = {
 -		.base.cra_name		= "cbc(aes)",
 -		.base.cra_driver_name	= "virtio_crypto_aes_cbc",
 -		.base.cra_priority	= 150,
 -		.base.cra_flags		= CRYPTO_ALG_ASYNC |
 -					  CRYPTO_ALG_ALLOCATES_MEMORY,
 -		.base.cra_blocksize	= AES_BLOCK_SIZE,
 -		.base.cra_ctxsize	= sizeof(struct virtio_crypto_skcipher_ctx),
 -		.base.cra_module	= THIS_MODULE,
 -		.init			= virtio_crypto_skcipher_init,
 -		.exit			= virtio_crypto_skcipher_exit,
 -		.setkey			= virtio_crypto_skcipher_setkey,
 -		.decrypt		= virtio_crypto_skcipher_decrypt,
 -		.encrypt		= virtio_crypto_skcipher_encrypt,
 -		.min_keysize		= AES_MIN_KEY_SIZE,
 -		.max_keysize		= AES_MAX_KEY_SIZE,
 -		.ivsize			= AES_BLOCK_SIZE,
 +static struct crypto_alg virtio_crypto_algs[] = { {
 +	.cra_name = "cbc(aes)",
 +	.cra_driver_name = "virtio_crypto_aes_cbc",
 +	.cra_priority = 150,
 +	.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
 +	.cra_blocksize = AES_BLOCK_SIZE,
 +	.cra_ctxsize  = sizeof(struct virtio_crypto_ablkcipher_ctx),
 +	.cra_alignmask = 0,
 +	.cra_module = THIS_MODULE,
 +	.cra_type = &crypto_ablkcipher_type,
 +	.cra_init = virtio_crypto_ablkcipher_init,
 +	.cra_exit = virtio_crypto_ablkcipher_exit,
 +	.cra_u = {
 +	   .ablkcipher = {
 +			.setkey = virtio_crypto_ablkcipher_setkey,
 +			.decrypt = virtio_crypto_ablkcipher_decrypt,
 +			.encrypt = virtio_crypto_ablkcipher_encrypt,
 +			.min_keysize = AES_MIN_KEY_SIZE,
 +			.max_keysize = AES_MAX_KEY_SIZE,
 +			.ivsize = AES_BLOCK_SIZE,
 +		},
  	},
  } };
  
diff --cc drivers/net/ppp/ppp_mppe.c
index 6c7fd98cb00a,208f6e24f37c..000000000000
--- a/drivers/net/ppp/ppp_mppe.c
+++ b/drivers/net/ppp/ppp_mppe.c
@@@ -246,8 -220,10 +246,15 @@@ static void *mppe_alloc(unsigned char *
  
  out_free:
  	kfree(state->sha1_digest);
++<<<<<<< HEAD
 +	crypto_free_ahash(state->sha1);
 +	crypto_free_skcipher(state->arc4);
++=======
+ 	if (state->sha1) {
+ 		crypto_free_shash(state->sha1->tfm);
+ 		kfree_sensitive(state->sha1);
+ 	}
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	kfree(state);
  out:
  	return NULL;
@@@ -261,9 -237,9 +268,15 @@@ static void mppe_free(void *arg
  	struct ppp_mppe_state *state = (struct ppp_mppe_state *) arg;
  	if (state) {
  		kfree(state->sha1_digest);
++<<<<<<< HEAD
 +		crypto_free_ahash(state->sha1);
 +		crypto_free_skcipher(state->arc4);
 +		kfree(state);
++=======
+ 		crypto_free_shash(state->sha1->tfm);
+ 		kfree_sensitive(state->sha1);
+ 		kfree_sensitive(state);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	}
  }
  
diff --cc drivers/staging/ks7010/ks_hostif.c
index abdaf7cf8162,eaaf6a5440a9..000000000000
--- a/drivers/staging/ks7010/ks_hostif.c
+++ b/drivers/staging/ks7010/ks_hostif.c
@@@ -191,6 -193,66 +191,69 @@@ static u8 read_ie(unsigned char *bp, u
  	return size;
  }
  
++<<<<<<< HEAD
++=======
+ static int
+ michael_mic(u8 *key, u8 *data, unsigned int len, u8 priority, u8 *result)
+ {
+ 	u8 pad_data[4] = { priority, 0, 0, 0 };
+ 	struct crypto_shash *tfm = NULL;
+ 	struct shash_desc *desc = NULL;
+ 	int ret;
+ 
+ 	tfm = crypto_alloc_shash("michael_mic", 0, 0);
+ 	if (IS_ERR(tfm)) {
+ 		ret = PTR_ERR(tfm);
+ 		goto err;
+ 	}
+ 
+ 	ret = crypto_shash_setkey(tfm, key, MICHAEL_MIC_KEY_LEN);
+ 	if (ret < 0)
+ 		goto err_free_tfm;
+ 
+ 	desc = kmalloc(sizeof(*desc) + crypto_shash_descsize(tfm), GFP_KERNEL);
+ 	if (!desc) {
+ 		ret = -ENOMEM;
+ 		goto err_free_tfm;
+ 	}
+ 
+ 	desc->tfm = tfm;
+ 
+ 	ret = crypto_shash_init(desc);
+ 	if (ret < 0)
+ 		goto err_free_desc;
+ 
+ 	// Compute the MIC value
+ 	/*
+ 	 * IEEE802.11i  page 47
+ 	 * Figure 43g TKIP MIC processing format
+ 	 * +--+--+--------+--+----+--+--+--+--+--+--+--+--+
+ 	 * |6 |6 |1       |3 |M   |1 |1 |1 |1 |1 |1 |1 |1 | Octet
+ 	 * +--+--+--------+--+----+--+--+--+--+--+--+--+--+
+ 	 * |DA|SA|Priority|0 |Data|M0|M1|M2|M3|M4|M5|M6|M7|
+ 	 * +--+--+--------+--+----+--+--+--+--+--+--+--+--+
+ 	 */
+ 
+ 	ret = crypto_shash_update(desc, data, 12);
+ 	if (ret < 0)
+ 		goto err_free_desc;
+ 
+ 	ret = crypto_shash_update(desc, pad_data, 4);
+ 	if (ret < 0)
+ 		goto err_free_desc;
+ 
+ 	ret = crypto_shash_finup(desc, data + 12, len - 12, result);
+ 
+ err_free_desc:
+ 	kfree_sensitive(desc);
+ 
+ err_free_tfm:
+ 	crypto_free_shash(tfm);
+ 
+ err:
+ 	return ret;
+ }
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  
  static
  int get_ap_information(struct ks_wlan_private *priv, struct ap_info *ap_info,
diff --cc drivers/staging/rtl8723bs/core/rtw_security.c
index 612277a555d2,7f74e1d05b3a..000000000000
--- a/drivers/staging/rtl8723bs/core/rtw_security.c
+++ b/drivers/staging/rtl8723bs/core/rtw_security.c
@@@ -2292,8 -2251,7 +2292,12 @@@ static void gf_mulx(u8 *pad
  
  static void aes_encrypt_deinit(void *ctx)
  {
++<<<<<<< HEAD
 +	memset(ctx, 0, AES_PRIV_SIZE);
 +	kfree(ctx);
++=======
+ 	kfree_sensitive(ctx);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  }
  
  
diff --cc include/linux/slab.h
index 7964239d627e,0884d82c55ee..000000000000
--- a/include/linux/slab.h
+++ b/include/linux/slab.h
@@@ -184,12 -184,14 +184,19 @@@ void memcg_deactivate_kmem_caches(struc
  /*
   * Common kmalloc functions provided by all allocators
   */
 +void * __must_check __krealloc(const void *, size_t, gfp_t);
  void * __must_check krealloc(const void *, size_t, gfp_t);
  void kfree(const void *);
++<<<<<<< HEAD
 +void kzfree(const void *);
++=======
+ void kfree_sensitive(const void *);
+ size_t __ksize(const void *);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  size_t ksize(const void *);
  
+ #define kzfree(x)	kfree_sensitive(x)	/* For backward compatibility */
+ 
  #ifdef CONFIG_HAVE_HARDENED_USERCOPY_ALLOCATOR
  void __check_heap_object(const void *ptr, unsigned long n, struct page *page,
  			bool to_user);
diff --cc lib/test_kasan.c
index ec657105edbf,e4d9a86b174b..000000000000
--- a/lib/test_kasan.c
+++ b/lib/test_kasan.c
@@@ -579,6 -620,187 +579,190 @@@ static noinline void __init kmem_cache_
  	kmem_cache_destroy(cache);
  }
  
++<<<<<<< HEAD
++=======
+ static noinline void __init kasan_memchr(void)
+ {
+ 	char *ptr;
+ 	size_t size = 24;
+ 
+ 	pr_info("out-of-bounds in memchr\n");
+ 	ptr = kmalloc(size, GFP_KERNEL | __GFP_ZERO);
+ 	if (!ptr)
+ 		return;
+ 
+ 	kasan_ptr_result = memchr(ptr, '1', size + 1);
+ 	kfree(ptr);
+ }
+ 
+ static noinline void __init kasan_memcmp(void)
+ {
+ 	char *ptr;
+ 	size_t size = 24;
+ 	int arr[9];
+ 
+ 	pr_info("out-of-bounds in memcmp\n");
+ 	ptr = kmalloc(size, GFP_KERNEL | __GFP_ZERO);
+ 	if (!ptr)
+ 		return;
+ 
+ 	memset(arr, 0, sizeof(arr));
+ 	kasan_int_result = memcmp(ptr, arr, size + 1);
+ 	kfree(ptr);
+ }
+ 
+ static noinline void __init kasan_strings(void)
+ {
+ 	char *ptr;
+ 	size_t size = 24;
+ 
+ 	pr_info("use-after-free in strchr\n");
+ 	ptr = kmalloc(size, GFP_KERNEL | __GFP_ZERO);
+ 	if (!ptr)
+ 		return;
+ 
+ 	kfree(ptr);
+ 
+ 	/*
+ 	 * Try to cause only 1 invalid access (less spam in dmesg).
+ 	 * For that we need ptr to point to zeroed byte.
+ 	 * Skip metadata that could be stored in freed object so ptr
+ 	 * will likely point to zeroed byte.
+ 	 */
+ 	ptr += 16;
+ 	kasan_ptr_result = strchr(ptr, '1');
+ 
+ 	pr_info("use-after-free in strrchr\n");
+ 	kasan_ptr_result = strrchr(ptr, '1');
+ 
+ 	pr_info("use-after-free in strcmp\n");
+ 	kasan_int_result = strcmp(ptr, "2");
+ 
+ 	pr_info("use-after-free in strncmp\n");
+ 	kasan_int_result = strncmp(ptr, "2", 1);
+ 
+ 	pr_info("use-after-free in strlen\n");
+ 	kasan_int_result = strlen(ptr);
+ 
+ 	pr_info("use-after-free in strnlen\n");
+ 	kasan_int_result = strnlen(ptr, 1);
+ }
+ 
+ static noinline void __init kasan_bitops(void)
+ {
+ 	/*
+ 	 * Allocate 1 more byte, which causes kzalloc to round up to 16-bytes;
+ 	 * this way we do not actually corrupt other memory.
+ 	 */
+ 	long *bits = kzalloc(sizeof(*bits) + 1, GFP_KERNEL);
+ 	if (!bits)
+ 		return;
+ 
+ 	/*
+ 	 * Below calls try to access bit within allocated memory; however, the
+ 	 * below accesses are still out-of-bounds, since bitops are defined to
+ 	 * operate on the whole long the bit is in.
+ 	 */
+ 	pr_info("out-of-bounds in set_bit\n");
+ 	set_bit(BITS_PER_LONG, bits);
+ 
+ 	pr_info("out-of-bounds in __set_bit\n");
+ 	__set_bit(BITS_PER_LONG, bits);
+ 
+ 	pr_info("out-of-bounds in clear_bit\n");
+ 	clear_bit(BITS_PER_LONG, bits);
+ 
+ 	pr_info("out-of-bounds in __clear_bit\n");
+ 	__clear_bit(BITS_PER_LONG, bits);
+ 
+ 	pr_info("out-of-bounds in clear_bit_unlock\n");
+ 	clear_bit_unlock(BITS_PER_LONG, bits);
+ 
+ 	pr_info("out-of-bounds in __clear_bit_unlock\n");
+ 	__clear_bit_unlock(BITS_PER_LONG, bits);
+ 
+ 	pr_info("out-of-bounds in change_bit\n");
+ 	change_bit(BITS_PER_LONG, bits);
+ 
+ 	pr_info("out-of-bounds in __change_bit\n");
+ 	__change_bit(BITS_PER_LONG, bits);
+ 
+ 	/*
+ 	 * Below calls try to access bit beyond allocated memory.
+ 	 */
+ 	pr_info("out-of-bounds in test_and_set_bit\n");
+ 	test_and_set_bit(BITS_PER_LONG + BITS_PER_BYTE, bits);
+ 
+ 	pr_info("out-of-bounds in __test_and_set_bit\n");
+ 	__test_and_set_bit(BITS_PER_LONG + BITS_PER_BYTE, bits);
+ 
+ 	pr_info("out-of-bounds in test_and_set_bit_lock\n");
+ 	test_and_set_bit_lock(BITS_PER_LONG + BITS_PER_BYTE, bits);
+ 
+ 	pr_info("out-of-bounds in test_and_clear_bit\n");
+ 	test_and_clear_bit(BITS_PER_LONG + BITS_PER_BYTE, bits);
+ 
+ 	pr_info("out-of-bounds in __test_and_clear_bit\n");
+ 	__test_and_clear_bit(BITS_PER_LONG + BITS_PER_BYTE, bits);
+ 
+ 	pr_info("out-of-bounds in test_and_change_bit\n");
+ 	test_and_change_bit(BITS_PER_LONG + BITS_PER_BYTE, bits);
+ 
+ 	pr_info("out-of-bounds in __test_and_change_bit\n");
+ 	__test_and_change_bit(BITS_PER_LONG + BITS_PER_BYTE, bits);
+ 
+ 	pr_info("out-of-bounds in test_bit\n");
+ 	kasan_int_result = test_bit(BITS_PER_LONG + BITS_PER_BYTE, bits);
+ 
+ #if defined(clear_bit_unlock_is_negative_byte)
+ 	pr_info("out-of-bounds in clear_bit_unlock_is_negative_byte\n");
+ 	kasan_int_result = clear_bit_unlock_is_negative_byte(BITS_PER_LONG +
+ 		BITS_PER_BYTE, bits);
+ #endif
+ 	kfree(bits);
+ }
+ 
+ static noinline void __init kmalloc_double_kzfree(void)
+ {
+ 	char *ptr;
+ 	size_t size = 16;
+ 
+ 	pr_info("double-free (kfree_sensitive)\n");
+ 	ptr = kmalloc(size, GFP_KERNEL);
+ 	if (!ptr) {
+ 		pr_err("Allocation failed\n");
+ 		return;
+ 	}
+ 
+ 	kfree_sensitive(ptr);
+ 	kfree_sensitive(ptr);
+ }
+ 
+ #ifdef CONFIG_KASAN_VMALLOC
+ static noinline void __init vmalloc_oob(void)
+ {
+ 	void *area;
+ 
+ 	pr_info("vmalloc out-of-bounds\n");
+ 
+ 	/*
+ 	 * We have to be careful not to hit the guard page.
+ 	 * The MMU will catch that and crash us.
+ 	 */
+ 	area = vmalloc(3000);
+ 	if (!area) {
+ 		pr_err("Allocation failed\n");
+ 		return;
+ 	}
+ 
+ 	((volatile char *)area)[3100];
+ 	vfree(area);
+ }
+ #else
+ static void __init vmalloc_oob(void) {}
+ #endif
+ 
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  static int __init kmalloc_tests_init(void)
  {
  	/*
diff --cc net/atm/mpoa_caches.c
index 4bb418313720,f7a2f0e41105..000000000000
--- a/net/atm/mpoa_caches.c
+++ b/net/atm/mpoa_caches.c
@@@ -180,8 -180,7 +180,12 @@@ static int cache_hit(in_cache_entry *en
  static void in_cache_put(in_cache_entry *entry)
  {
  	if (refcount_dec_and_test(&entry->use)) {
++<<<<<<< HEAD
 +		memset(entry, 0, sizeof(in_cache_entry));
 +		kfree(entry);
++=======
+ 		kfree_sensitive(entry);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	}
  }
  
@@@ -416,8 -415,7 +420,12 @@@ static eg_cache_entry *eg_cache_get_by_
  static void eg_cache_put(eg_cache_entry *entry)
  {
  	if (refcount_dec_and_test(&entry->use)) {
++<<<<<<< HEAD
 +		memset(entry, 0, sizeof(eg_cache_entry));
 +		kfree(entry);
++=======
+ 		kfree_sensitive(entry);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	}
  }
  
diff --cc net/bluetooth/smp.c
index d941c7b388ac,bf4bef13d935..000000000000
--- a/net/bluetooth/smp.c
+++ b/net/bluetooth/smp.c
@@@ -765,11 -753,10 +765,11 @@@ static void smp_chan_destroy(struct l2c
  	complete = test_bit(SMP_FLAG_COMPLETE, &smp->flags);
  	mgmt_smp_complete(hcon, complete);
  
- 	kzfree(smp->csrk);
- 	kzfree(smp->slave_csrk);
- 	kzfree(smp->link_key);
+ 	kfree_sensitive(smp->csrk);
+ 	kfree_sensitive(smp->slave_csrk);
+ 	kfree_sensitive(smp->link_key);
  
 +	crypto_free_cipher(smp->tfm_aes);
  	crypto_free_shash(smp->tfm_cmac);
  	crypto_free_kpp(smp->tfm_ecdh);
  
@@@ -1421,10 -1406,8 +1421,10 @@@ static struct smp_chan *smp_chan_create
  
  free_shash:
  	crypto_free_shash(smp->tfm_cmac);
 +free_cipher:
 +	crypto_free_cipher(smp->tfm_aes);
  zfree_smp:
- 	kzfree(smp);
+ 	kfree_sensitive(smp);
  	return NULL;
  }
  
@@@ -3295,8 -3278,7 +3295,12 @@@ static struct l2cap_chan *smp_add_cid(s
  	tfm_cmac = crypto_alloc_shash("cmac(aes)", 0, 0);
  	if (IS_ERR(tfm_cmac)) {
  		BT_ERR("Unable to create CMAC crypto context");
++<<<<<<< HEAD
 +		crypto_free_cipher(tfm_aes);
 +		kzfree(smp);
++=======
+ 		kfree_sensitive(smp);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  		return ERR_CAST(tfm_cmac);
  	}
  
@@@ -3304,8 -3286,7 +3308,12 @@@
  	if (IS_ERR(tfm_ecdh)) {
  		BT_ERR("Unable to create ECDH crypto context");
  		crypto_free_shash(tfm_cmac);
++<<<<<<< HEAD
 +		crypto_free_cipher(tfm_aes);
 +		kzfree(smp);
++=======
+ 		kfree_sensitive(smp);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  		return ERR_CAST(tfm_ecdh);
  	}
  
@@@ -3318,10 -3298,9 +3326,10 @@@ create_chan
  	chan = l2cap_chan_create();
  	if (!chan) {
  		if (smp) {
 +			crypto_free_cipher(smp->tfm_aes);
  			crypto_free_shash(smp->tfm_cmac);
  			crypto_free_kpp(smp->tfm_ecdh);
- 			kzfree(smp);
+ 			kfree_sensitive(smp);
  		}
  		return ERR_PTR(-ENOMEM);
  	}
@@@ -3366,10 -3345,9 +3374,10 @@@ static void smp_del_chan(struct l2cap_c
  	smp = chan->data;
  	if (smp) {
  		chan->data = NULL;
 +		crypto_free_cipher(smp->tfm_aes);
  		crypto_free_shash(smp->tfm_cmac);
  		crypto_free_kpp(smp->tfm_ecdh);
- 		kzfree(smp);
+ 		kfree_sensitive(smp);
  	}
  
  	l2cap_chan_put(chan);
diff --cc net/ipv4/tcp_fastopen.c
index 7a520d5b4351,c1a54f3d58f5..000000000000
--- a/net/ipv4/tcp_fastopen.c
+++ b/net/ipv4/tcp_fastopen.c
@@@ -37,8 -37,8 +37,13 @@@ static void tcp_fastopen_ctx_free(struc
  {
  	struct tcp_fastopen_context *ctx =
  	    container_of(head, struct tcp_fastopen_context, rcu);
++<<<<<<< HEAD
 +	crypto_free_cipher(ctx->tfm);
 +	kfree(ctx);
++=======
+ 
+ 	kfree_sensitive(ctx);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  }
  
  void tcp_fastopen_destroy_cipher(struct sock *sk)
diff --cc net/mac802154/llsec.c
index 2fb703d70803,585d33144c33..000000000000
--- a/net/mac802154/llsec.c
+++ b/net/mac802154/llsec.c
@@@ -177,8 -169,8 +177,13 @@@ static void llsec_key_release(struct kr
  	for (i = 0; i < ARRAY_SIZE(key->tfm); i++)
  		crypto_free_aead(key->tfm[i]);
  
++<<<<<<< HEAD
 +	crypto_free_skcipher(key->tfm0);
 +	kzfree(key);
++=======
+ 	crypto_free_sync_skcipher(key->tfm0);
+ 	kfree_sensitive(key);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  }
  
  static struct mac802154_llsec_key*
diff --cc security/apparmor/policy.c
index 1590e2de4e84,4c010c9a6af1..000000000000
--- a/security/apparmor/policy.c
+++ b/security/apparmor/policy.c
@@@ -229,9 -224,12 +229,18 @@@ void aa_free_profile(struct aa_profile 
  	aa_free_rlimit_rules(&profile->rlimits);
  
  	for (i = 0; i < profile->xattr_count; i++)
++<<<<<<< HEAD
 +		kzfree(profile->xattrs[i]);
 +	kzfree(profile->xattrs);
 +	kzfree(profile->dirname);
++=======
+ 		kfree_sensitive(profile->xattrs[i]);
+ 	kfree_sensitive(profile->xattrs);
+ 	for (i = 0; i < profile->secmark_count; i++)
+ 		kfree_sensitive(profile->secmark[i].label);
+ 	kfree_sensitive(profile->secmark);
+ 	kfree_sensitive(profile->dirname);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	aa_put_dfa(profile->xmatch);
  	aa_put_dfa(profile->policy.dfa);
  
@@@ -239,13 -237,14 +248,13 @@@
  		rht = profile->data;
  		profile->data = NULL;
  		rhashtable_free_and_destroy(rht, aa_free_data, NULL);
- 		kzfree(rht);
+ 		kfree_sensitive(rht);
  	}
  
- 	kzfree(profile->hash);
+ 	kfree_sensitive(profile->hash);
  	aa_put_loaddata(profile->rawdata);
 -	aa_label_destroy(&profile->label);
  
- 	kzfree(profile);
+ 	kfree_sensitive(profile);
  }
  
  /**
diff --cc security/keys/encrypted-keys/encrypted.c
index a26c743ad622,deebbf14eeca..000000000000
--- a/security/keys/encrypted-keys/encrypted.c
+++ b/security/keys/encrypted-keys/encrypted.c
@@@ -385,8 -368,9 +385,14 @@@ static int get_derived_key(u8 *derived_
  
  	memcpy(derived_buf + strlen(derived_buf) + 1, master_key,
  	       master_keylen);
++<<<<<<< HEAD
 +	ret = calc_hash(hash_tfm, derived_key, derived_buf, derived_buf_len);
 +	kzfree(derived_buf);
++=======
+ 	ret = crypto_shash_tfm_digest(hash_tfm, derived_buf, derived_buf_len,
+ 				      derived_key);
+ 	kfree_sensitive(derived_buf);
++>>>>>>> 453431a54934 (mm, treewide: rename kzfree() to kfree_sensitive())
  	return ret;
  }
  
* Unmerged path crypto/adiantum.c
* Unmerged path drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c
* Unmerged path drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c
* Unmerged path drivers/crypto/amlogic/amlogic-gxl-cipher.c
* Unmerged path drivers/crypto/marvell/octeontx/otx_cptvf_main.c
* Unmerged path drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h
* Unmerged path drivers/net/wireguard/noise.c
* Unmerged path drivers/net/wireguard/peer.c
* Unmerged path fs/crypto/inline_crypt.c
* Unmerged path fs/crypto/keyring.c
* Unmerged path fs/crypto/keysetup_v1.c
diff --git a/arch/s390/crypto/prng.c b/arch/s390/crypto/prng.c
index d977643fa627..04caac037b7a 100644
--- a/arch/s390/crypto/prng.c
+++ b/arch/s390/crypto/prng.c
@@ -249,7 +249,7 @@ static void prng_tdes_deinstantiate(void)
 {
 	pr_debug("The prng module stopped "
 		 "after running in triple DES mode\n");
-	kzfree(prng_data);
+	kfree_sensitive(prng_data);
 }
 
 
@@ -442,7 +442,7 @@ static int __init prng_sha512_instantiate(void)
 static void prng_sha512_deinstantiate(void)
 {
 	pr_debug("The prng module stopped after running in SHA-512 mode\n");
-	kzfree(prng_data);
+	kfree_sensitive(prng_data);
 }
 
 
diff --git a/arch/x86/power/hibernate.c b/arch/x86/power/hibernate.c
index 6e47d08ec087..9c71418831b7 100644
--- a/arch/x86/power/hibernate.c
+++ b/arch/x86/power/hibernate.c
@@ -98,7 +98,7 @@ static int get_e820_md5(struct e820_table *table, void *buf)
 	if (crypto_shash_digest(desc, (u8 *)table, size, buf))
 		ret = -EINVAL;
 
-	kzfree(desc);
+	kfree_sensitive(desc);
 
 free_tfm:
 	crypto_free_shash(tfm);
* Unmerged path crypto/adiantum.c
diff --git a/crypto/ahash.c b/crypto/ahash.c
index 78aaf2158c43..5757a92b4a10 100644
--- a/crypto/ahash.c
+++ b/crypto/ahash.c
@@ -186,7 +186,7 @@ static int ahash_setkey_unaligned(struct crypto_ahash *tfm, const u8 *key,
 	alignbuffer = (u8 *)ALIGN((unsigned long)buffer, alignmask + 1);
 	memcpy(alignbuffer, key, keylen);
 	ret = tfm->setkey(tfm, alignbuffer, keylen);
-	kzfree(buffer);
+	kfree_sensitive(buffer);
 	return ret;
 }
 
@@ -294,7 +294,7 @@ static void ahash_restore_req(struct ahash_request *req, int err)
 	req->priv = NULL;
 
 	/* Free the req->priv.priv from the ADJUSTED request. */
-	kzfree(priv);
+	kfree_sensitive(priv);
 }
 
 static void ahash_notify_einprogress(struct ahash_request *req)
diff --git a/crypto/api.c b/crypto/api.c
index 0ee632bba064..565e6e2ff6eb 100644
--- a/crypto/api.c
+++ b/crypto/api.c
@@ -581,7 +581,7 @@ void crypto_destroy_tfm(void *mem, struct crypto_tfm *tfm)
 		alg->cra_exit(tfm);
 	crypto_exit_ops(tfm);
 	crypto_mod_put(alg);
-	kzfree(mem);
+	kfree_sensitive(mem);
 }
 EXPORT_SYMBOL_GPL(crypto_destroy_tfm);
 
* Unmerged path crypto/asymmetric_keys/verify_pefile.c
diff --git a/crypto/deflate.c b/crypto/deflate.c
index 94ec3b36a8e8..f80fafc5329d 100644
--- a/crypto/deflate.c
+++ b/crypto/deflate.c
@@ -167,7 +167,7 @@ static void __deflate_exit(void *ctx)
 static void deflate_free_ctx(struct crypto_scomp *tfm, void *ctx)
 {
 	__deflate_exit(ctx);
-	kzfree(ctx);
+	kfree_sensitive(ctx);
 }
 
 static void deflate_exit(struct crypto_tfm *tfm)
diff --git a/crypto/drbg.c b/crypto/drbg.c
index 4096a246f2e7..d62710c3fa44 100644
--- a/crypto/drbg.c
+++ b/crypto/drbg.c
@@ -1208,19 +1208,19 @@ static inline void drbg_dealloc_state(struct drbg_state *drbg)
 {
 	if (!drbg)
 		return;
-	kzfree(drbg->Vbuf);
+	kfree_sensitive(drbg->Vbuf);
 	drbg->Vbuf = NULL;
 	drbg->V = NULL;
-	kzfree(drbg->Cbuf);
+	kfree_sensitive(drbg->Cbuf);
 	drbg->Cbuf = NULL;
 	drbg->C = NULL;
-	kzfree(drbg->scratchpadbuf);
+	kfree_sensitive(drbg->scratchpadbuf);
 	drbg->scratchpadbuf = NULL;
 	drbg->reseed_ctr = 0;
 	drbg->d_ops = NULL;
 	drbg->core = NULL;
 	if (IS_ENABLED(CONFIG_CRYPTO_FIPS)) {
-		kzfree(drbg->prev);
+		kfree_sensitive(drbg->prev);
 		drbg->prev = NULL;
 		drbg->fips_primed = false;
 	}
@@ -1690,7 +1690,7 @@ static int drbg_fini_hash_kernel(struct drbg_state *drbg)
 	struct sdesc *sdesc = (struct sdesc *)drbg->priv_data;
 	if (sdesc) {
 		crypto_free_shash(sdesc->shash.tfm);
-		kzfree(sdesc);
+		kfree_sensitive(sdesc);
 	}
 	drbg->priv_data = NULL;
 	return 0;
diff --git a/crypto/ecc.c b/crypto/ecc.c
index 6f473573b944..6ff48d97a33d 100644
--- a/crypto/ecc.c
+++ b/crypto/ecc.c
@@ -64,7 +64,7 @@ static u64 *ecc_alloc_digits_space(unsigned int ndigits)
 
 static void ecc_free_digits_space(u64 *space)
 {
-	kzfree(space);
+	kfree_sensitive(space);
 }
 
 static struct ecc_point *ecc_alloc_point(unsigned int ndigits)
@@ -98,9 +98,9 @@ static void ecc_free_point(struct ecc_point *p)
 	if (!p)
 		return;
 
-	kzfree(p->x);
-	kzfree(p->y);
-	kzfree(p);
+	kfree_sensitive(p->x);
+	kfree_sensitive(p->y);
+	kfree_sensitive(p);
 }
 
 static void vli_clear(u64 *vli, unsigned int ndigits)
diff --git a/crypto/ecdh.c b/crypto/ecdh.c
index bf6300175b9c..96f69cbbc38a 100644
--- a/crypto/ecdh.c
+++ b/crypto/ecdh.c
@@ -128,7 +128,7 @@ static int ecdh_compute_value(struct kpp_request *req)
 
 	/* fall through */
 free_all:
-	kzfree(shared_secret);
+	kfree_sensitive(shared_secret);
 free_pubkey:
 	kfree(public_key);
 	return ret;
diff --git a/crypto/gcm.c b/crypto/gcm.c
index 0ad879e1f9b2..019a5f08d840 100644
--- a/crypto/gcm.c
+++ b/crypto/gcm.c
@@ -148,7 +148,7 @@ static int crypto_gcm_setkey(struct crypto_aead *aead, const u8 *key,
 			      CRYPTO_TFM_RES_MASK);
 
 out:
-	kzfree(data);
+	kfree_sensitive(data);
 	return err;
 }
 
diff --git a/crypto/gf128mul.c b/crypto/gf128mul.c
index a4b1c026aaee..a69ae3e6c16c 100644
--- a/crypto/gf128mul.c
+++ b/crypto/gf128mul.c
@@ -304,8 +304,8 @@ void gf128mul_free_64k(struct gf128mul_64k *t)
 	int i;
 
 	for (i = 0; i < 16; i++)
-		kzfree(t->t[i]);
-	kzfree(t);
+		kfree_sensitive(t->t[i]);
+	kfree_sensitive(t);
 }
 EXPORT_SYMBOL(gf128mul_free_64k);
 
diff --git a/crypto/jitterentropy-kcapi.c b/crypto/jitterentropy-kcapi.c
index 787dccca3715..07d5e52fe93e 100644
--- a/crypto/jitterentropy-kcapi.c
+++ b/crypto/jitterentropy-kcapi.c
@@ -68,7 +68,7 @@ void *jent_zalloc(unsigned int len)
 
 void jent_zfree(void *ptr)
 {
-	kzfree(ptr);
+	kfree_sensitive(ptr);
 }
 
 int jent_fips_enabled(void)
diff --git a/crypto/rng.c b/crypto/rng.c
index fb73f993f80e..f4183aaa7330 100644
--- a/crypto/rng.c
+++ b/crypto/rng.c
@@ -54,7 +54,7 @@ int crypto_rng_reset(struct crypto_rng *tfm, const u8 *seed, unsigned int slen)
 
 	err = crypto_rng_alg(tfm)->seed(tfm, seed, slen);
 out:
-	kzfree(buf);
+	kfree_sensitive(buf);
 	return err;
 }
 EXPORT_SYMBOL_GPL(crypto_rng_reset);
diff --git a/crypto/rsa-pkcs1pad.c b/crypto/rsa-pkcs1pad.c
index 99b5f7207e78..3bd75907a2a3 100644
--- a/crypto/rsa-pkcs1pad.c
+++ b/crypto/rsa-pkcs1pad.c
@@ -202,7 +202,7 @@ static int pkcs1pad_encrypt_sign_complete(struct akcipher_request *req, int err)
 	sg_copy_from_buffer(req->dst,
 			    sg_nents_for_len(req->dst, ctx->key_size),
 			    out_buf, ctx->key_size);
-	kzfree(out_buf);
+	kfree_sensitive(out_buf);
 
 out:
 	req->dst_len = ctx->key_size;
@@ -334,7 +334,7 @@ static int pkcs1pad_decrypt_complete(struct akcipher_request *req, int err)
 				out_buf + pos, req->dst_len);
 
 done:
-	kzfree(req_ctx->out_buf);
+	kfree_sensitive(req_ctx->out_buf);
 
 	return err;
 }
@@ -500,7 +500,7 @@ static int pkcs1pad_verify_complete(struct akcipher_request *req, int err)
 				sg_nents_for_len(req->dst, req->dst_len),
 				out_buf + pos, req->dst_len);
 done:
-	kzfree(req_ctx->out_buf);
+	kfree_sensitive(req_ctx->out_buf);
 
 	return err;
 }
diff --git a/crypto/seqiv.c b/crypto/seqiv.c
index 39dbf2f7e5f5..47cb0416d849 100644
--- a/crypto/seqiv.c
+++ b/crypto/seqiv.c
@@ -40,7 +40,7 @@ static void seqiv_aead_encrypt_complete2(struct aead_request *req, int err)
 	memcpy(req->iv, subreq->iv, crypto_aead_ivsize(geniv));
 
 out:
-	kzfree(subreq->iv);
+	kfree_sensitive(subreq->iv);
 }
 
 static void seqiv_aead_encrypt_complete(struct crypto_async_request *base,
diff --git a/crypto/shash.c b/crypto/shash.c
index 86d76b5c626c..cb528186b08a 100644
--- a/crypto/shash.c
+++ b/crypto/shash.c
@@ -49,7 +49,7 @@ static int shash_setkey_unaligned(struct crypto_shash *tfm, const u8 *key,
 	alignbuffer = (u8 *)ALIGN((unsigned long)buffer, alignmask + 1);
 	memcpy(alignbuffer, key, keylen);
 	err = shash->setkey(tfm, alignbuffer, keylen);
-	kzfree(buffer);
+	kfree_sensitive(buffer);
 	return err;
 }
 
diff --git a/crypto/skcipher.c b/crypto/skcipher.c
index 0f834eeafd61..2bdff892ae89 100644
--- a/crypto/skcipher.c
+++ b/crypto/skcipher.c
@@ -799,7 +799,7 @@ static int skcipher_setkey_unaligned(struct crypto_skcipher *tfm,
 	alignbuffer = (u8 *)ALIGN((unsigned long)buffer, alignmask + 1);
 	memcpy(alignbuffer, key, keylen);
 	ret = cipher->setkey(tfm, alignbuffer, keylen);
-	kzfree(buffer);
+	kfree_sensitive(buffer);
 	return ret;
 }
 
* Unmerged path crypto/testmgr.c
diff --git a/crypto/zstd.c b/crypto/zstd.c
index 9a76b3ed8b8b..e1fc66d70315 100644
--- a/crypto/zstd.c
+++ b/crypto/zstd.c
@@ -145,7 +145,7 @@ static void __zstd_exit(void *ctx)
 static void zstd_free_ctx(struct crypto_scomp *tfm, void *ctx)
 {
 	__zstd_exit(ctx);
-	kzfree(ctx);
+	kfree_sensitive(ctx);
 }
 
 static void zstd_exit(struct crypto_tfm *tfm)
* Unmerged path drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c
* Unmerged path drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c
* Unmerged path drivers/crypto/amlogic/amlogic-gxl-cipher.c
diff --git a/drivers/crypto/atmel-ecc.c b/drivers/crypto/atmel-ecc.c
index e66f18a0ddd0..a8029674822b 100644
--- a/drivers/crypto/atmel-ecc.c
+++ b/drivers/crypto/atmel-ecc.c
@@ -282,7 +282,7 @@ static void atmel_ecdh_done(struct atmel_ecc_work_data *work_data, void *areq,
 
 	/* fall through */
 free_work_data:
-	kzfree(work_data);
+	kfree_sensitive(work_data);
 	kpp_request_complete(req, status);
 }
 
diff --git a/drivers/crypto/caam/caampkc.c b/drivers/crypto/caam/caampkc.c
index 822f1d47a03c..6e36b390cafb 100644
--- a/drivers/crypto/caam/caampkc.c
+++ b/drivers/crypto/caam/caampkc.c
@@ -723,14 +723,14 @@ static int caam_rsa_dec(struct akcipher_request *req)
 
 static void caam_rsa_free_key(struct caam_rsa_key *key)
 {
-	kzfree(key->d);
-	kzfree(key->p);
-	kzfree(key->q);
-	kzfree(key->dp);
-	kzfree(key->dq);
-	kzfree(key->qinv);
-	kzfree(key->tmp1);
-	kzfree(key->tmp2);
+	kfree_sensitive(key->d);
+	kfree_sensitive(key->p);
+	kfree_sensitive(key->q);
+	kfree_sensitive(key->dp);
+	kfree_sensitive(key->dq);
+	kfree_sensitive(key->qinv);
+	kfree_sensitive(key->tmp1);
+	kfree_sensitive(key->tmp2);
 	kfree(key->e);
 	kfree(key->n);
 	memset(key, 0, sizeof(*key));
@@ -889,17 +889,17 @@ static void caam_rsa_set_priv_key_form(struct caam_rsa_ctx *ctx,
 	return;
 
 free_dq:
-	kzfree(rsa_key->dq);
+	kfree_sensitive(rsa_key->dq);
 free_dp:
-	kzfree(rsa_key->dp);
+	kfree_sensitive(rsa_key->dp);
 free_tmp2:
-	kzfree(rsa_key->tmp2);
+	kfree_sensitive(rsa_key->tmp2);
 free_tmp1:
-	kzfree(rsa_key->tmp1);
+	kfree_sensitive(rsa_key->tmp1);
 free_q:
-	kzfree(rsa_key->q);
+	kfree_sensitive(rsa_key->q);
 free_p:
-	kzfree(rsa_key->p);
+	kfree_sensitive(rsa_key->p);
 }
 
 static int caam_rsa_set_priv_key(struct crypto_akcipher *tfm, const void *key,
diff --git a/drivers/crypto/cavium/cpt/cptvf_main.c b/drivers/crypto/cavium/cpt/cptvf_main.c
index 5c796ed55eba..db3d9b5b44ef 100644
--- a/drivers/crypto/cavium/cpt/cptvf_main.c
+++ b/drivers/crypto/cavium/cpt/cptvf_main.c
@@ -77,7 +77,7 @@ static void cleanup_worker_threads(struct cpt_vf *cptvf)
 	for (i = 0; i < cptvf->nr_queues; i++)
 		tasklet_kill(&cwqe_info->vq_wqe[i].twork);
 
-	kzfree(cwqe_info);
+	kfree_sensitive(cwqe_info);
 	cptvf->wqe_info = NULL;
 }
 
@@ -91,7 +91,7 @@ static void free_pending_queues(struct pending_qinfo *pqinfo)
 			continue;
 
 		/* free single queue */
-		kzfree((queue->head));
+		kfree_sensitive((queue->head));
 
 		queue->front = 0;
 		queue->rear = 0;
@@ -192,7 +192,7 @@ static void free_command_queues(struct cpt_vf *cptvf,
 			chunk->head = NULL;
 			chunk->dma_addr = 0;
 			hlist_del(&chunk->nextchunk);
-			kzfree(chunk);
+			kfree_sensitive(chunk);
 		}
 
 		queue->nchunks = 0;
* Unmerged path drivers/crypto/cavium/cpt/cptvf_reqmanager.c
* Unmerged path drivers/crypto/cavium/nitrox/nitrox_lib.c
diff --git a/drivers/crypto/cavium/zip/zip_crypto.c b/drivers/crypto/cavium/zip/zip_crypto.c
index b92b6e7e100f..655fe98e0ba0 100644
--- a/drivers/crypto/cavium/zip/zip_crypto.c
+++ b/drivers/crypto/cavium/zip/zip_crypto.c
@@ -260,7 +260,7 @@ void *zip_alloc_scomp_ctx_deflate(struct crypto_scomp *tfm)
 	ret = zip_ctx_init(zip_ctx, 0);
 
 	if (ret) {
-		kzfree(zip_ctx);
+		kfree_sensitive(zip_ctx);
 		return ERR_PTR(ret);
 	}
 
@@ -279,7 +279,7 @@ void *zip_alloc_scomp_ctx_lzs(struct crypto_scomp *tfm)
 	ret = zip_ctx_init(zip_ctx, 1);
 
 	if (ret) {
-		kzfree(zip_ctx);
+		kfree_sensitive(zip_ctx);
 		return ERR_PTR(ret);
 	}
 
@@ -291,7 +291,7 @@ void zip_free_scomp_ctx(struct crypto_scomp *tfm, void *ctx)
 	struct zip_kernel_ctx *zip_ctx = ctx;
 
 	zip_ctx_exit(zip_ctx);
-	kzfree(zip_ctx);
+	kfree_sensitive(zip_ctx);
 }
 
 int zip_scomp_compress(struct crypto_scomp *tfm,
diff --git a/drivers/crypto/ccp/ccp-crypto-rsa.c b/drivers/crypto/ccp/ccp-crypto-rsa.c
index 1f7cb7abece2..9e05295c05a0 100644
--- a/drivers/crypto/ccp/ccp-crypto-rsa.c
+++ b/drivers/crypto/ccp/ccp-crypto-rsa.c
@@ -112,13 +112,13 @@ static int ccp_check_key_length(unsigned int len)
 static void ccp_rsa_free_key_bufs(struct ccp_ctx *ctx)
 {
 	/* Clean up old key data */
-	kzfree(ctx->u.rsa.e_buf);
+	kfree_sensitive(ctx->u.rsa.e_buf);
 	ctx->u.rsa.e_buf = NULL;
 	ctx->u.rsa.e_len = 0;
-	kzfree(ctx->u.rsa.n_buf);
+	kfree_sensitive(ctx->u.rsa.n_buf);
 	ctx->u.rsa.n_buf = NULL;
 	ctx->u.rsa.n_len = 0;
-	kzfree(ctx->u.rsa.d_buf);
+	kfree_sensitive(ctx->u.rsa.d_buf);
 	ctx->u.rsa.d_buf = NULL;
 	ctx->u.rsa.d_len = 0;
 }
* Unmerged path drivers/crypto/ccree/cc_aead.c
* Unmerged path drivers/crypto/ccree/cc_buffer_mgr.c
* Unmerged path drivers/crypto/ccree/cc_cipher.c
* Unmerged path drivers/crypto/ccree/cc_hash.c
diff --git a/drivers/crypto/ccree/cc_request_mgr.c b/drivers/crypto/ccree/cc_request_mgr.c
index 83a8aaae61c7..7338eb0f3e35 100644
--- a/drivers/crypto/ccree/cc_request_mgr.c
+++ b/drivers/crypto/ccree/cc_request_mgr.c
@@ -81,7 +81,7 @@ void cc_req_mgr_fini(struct cc_drvdata *drvdata)
 	/* Kill tasklet */
 	tasklet_kill(&req_mgr_h->comptask);
 #endif
-	kzfree(req_mgr_h);
+	kfree_sensitive(req_mgr_h);
 	drvdata->request_mgr_handle = NULL;
 }
 
* Unmerged path drivers/crypto/marvell/hash.c
* Unmerged path drivers/crypto/marvell/octeontx/otx_cptvf_main.c
* Unmerged path drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h
diff --git a/drivers/crypto/nx/nx.c b/drivers/crypto/nx/nx.c
index 3a5e31be4764..841b99d3ced7 100644
--- a/drivers/crypto/nx/nx.c
+++ b/drivers/crypto/nx/nx.c
@@ -759,7 +759,7 @@ void nx_crypto_ctx_exit(struct crypto_tfm *tfm)
 {
 	struct nx_crypto_ctx *nx_ctx = crypto_tfm_ctx(tfm);
 
-	kzfree(nx_ctx->kmem);
+	kfree_sensitive(nx_ctx->kmem);
 	nx_ctx->csbcpb = NULL;
 	nx_ctx->csbcpb_aead = NULL;
 	nx_ctx->in_sg = NULL;
@@ -770,7 +770,7 @@ void nx_crypto_ctx_aead_exit(struct crypto_aead *tfm)
 {
 	struct nx_crypto_ctx *nx_ctx = crypto_aead_ctx(tfm);
 
-	kzfree(nx_ctx->kmem);
+	kfree_sensitive(nx_ctx->kmem);
 }
 
 static int nx_probe(struct vio_dev *viodev, const struct vio_device_id *id)
* Unmerged path drivers/crypto/virtio/virtio_crypto_algs.c
diff --git a/drivers/crypto/virtio/virtio_crypto_core.c b/drivers/crypto/virtio/virtio_crypto_core.c
index 7c7198553699..ca941f7643ed 100644
--- a/drivers/crypto/virtio/virtio_crypto_core.c
+++ b/drivers/crypto/virtio/virtio_crypto_core.c
@@ -29,7 +29,7 @@ void
 virtcrypto_clear_request(struct virtio_crypto_request *vc_req)
 {
 	if (vc_req) {
-		kzfree(vc_req->req_data);
+		kfree_sensitive(vc_req->req_data);
 		kfree(vc_req->sgs);
 	}
 }
diff --git a/drivers/md/dm-crypt.c b/drivers/md/dm-crypt.c
index 8db489a72c72..bb6d82c5723e 100644
--- a/drivers/md/dm-crypt.c
+++ b/drivers/md/dm-crypt.c
@@ -407,7 +407,7 @@ static void crypt_iv_lmk_dtr(struct crypt_config *cc)
 		crypto_free_shash(lmk->hash_tfm);
 	lmk->hash_tfm = NULL;
 
-	kzfree(lmk->seed);
+	kfree_sensitive(lmk->seed);
 	lmk->seed = NULL;
 }
 
@@ -559,9 +559,9 @@ static void crypt_iv_tcw_dtr(struct crypt_config *cc)
 {
 	struct iv_tcw_private *tcw = &cc->iv_gen_private.tcw;
 
-	kzfree(tcw->iv_seed);
+	kfree_sensitive(tcw->iv_seed);
 	tcw->iv_seed = NULL;
-	kzfree(tcw->whitening);
+	kfree_sensitive(tcw->whitening);
 	tcw->whitening = NULL;
 
 	if (tcw->crc32_tfm && !IS_ERR(tcw->crc32_tfm))
@@ -997,8 +997,8 @@ static int crypt_iv_elephant(struct crypt_config *cc, struct dm_crypt_request *d
 
 	kunmap_atomic(data);
 out:
-	kzfree(ks);
-	kzfree(es);
+	kfree_sensitive(ks);
+	kfree_sensitive(es);
 	skcipher_request_free(req);
 	return r;
 }
@@ -2299,7 +2299,7 @@ static int crypt_set_keyring_key(struct crypt_config *cc, const char *key_string
 
 	key = request_key(type, key_desc + 1, NULL);
 	if (IS_ERR(key)) {
-		kzfree(new_key_string);
+		kfree_sensitive(new_key_string);
 		return PTR_ERR(key);
 	}
 
@@ -2309,7 +2309,7 @@ static int crypt_set_keyring_key(struct crypt_config *cc, const char *key_string
 	if (ret < 0) {
 		up_read(&key->sem);
 		key_put(key);
-		kzfree(new_key_string);
+		kfree_sensitive(new_key_string);
 		return ret;
 	}
 
@@ -2323,10 +2323,10 @@ static int crypt_set_keyring_key(struct crypt_config *cc, const char *key_string
 
 	if (!ret) {
 		set_bit(DM_CRYPT_KEY_VALID, &cc->flags);
-		kzfree(cc->key_string);
+		kfree_sensitive(cc->key_string);
 		cc->key_string = new_key_string;
 	} else
-		kzfree(new_key_string);
+		kfree_sensitive(new_key_string);
 
 	return ret;
 }
@@ -2387,7 +2387,7 @@ static int crypt_set_key(struct crypt_config *cc, char *key)
 	clear_bit(DM_CRYPT_KEY_VALID, &cc->flags);
 
 	/* wipe references to any kernel keyring key */
-	kzfree(cc->key_string);
+	kfree_sensitive(cc->key_string);
 	cc->key_string = NULL;
 
 	/* Decode key from its hex representation. */
@@ -2419,7 +2419,7 @@ static int crypt_wipe_key(struct crypt_config *cc)
 			return r;
 	}
 
-	kzfree(cc->key_string);
+	kfree_sensitive(cc->key_string);
 	cc->key_string = NULL;
 	r = crypt_setkey(cc);
 	memset(&cc->key, 0, cc->key_size * sizeof(u8));
@@ -2498,15 +2498,15 @@ static void crypt_dtr(struct dm_target *ti)
 	if (cc->dev)
 		dm_put_device(ti, cc->dev);
 
-	kzfree(cc->cipher_string);
-	kzfree(cc->key_string);
-	kzfree(cc->cipher_auth);
-	kzfree(cc->authenc_key);
+	kfree_sensitive(cc->cipher_string);
+	kfree_sensitive(cc->key_string);
+	kfree_sensitive(cc->cipher_auth);
+	kfree_sensitive(cc->authenc_key);
 
 	mutex_destroy(&cc->bio_alloc_lock);
 
 	/* Must zero key material before freeing */
-	kzfree(cc);
+	kfree_sensitive(cc);
 
 	spin_lock(&dm_crypt_clients_lock);
 	WARN_ON(!dm_crypt_clients_n);
diff --git a/drivers/md/dm-integrity.c b/drivers/md/dm-integrity.c
index e622ff369142..3f4ac25f4372 100644
--- a/drivers/md/dm-integrity.c
+++ b/drivers/md/dm-integrity.c
@@ -3421,8 +3421,8 @@ static struct scatterlist **dm_integrity_alloc_journal_scatterlist(struct dm_int
 
 static void free_alg(struct alg_spec *a)
 {
-	kzfree(a->alg_string);
-	kzfree(a->key);
+	kfree_sensitive(a->alg_string);
+	kfree_sensitive(a->key);
 	memset(a, 0, sizeof *a);
 }
 
@@ -4353,7 +4353,7 @@ static void dm_integrity_dtr(struct dm_target *ti)
 		for (i = 0; i < ic->journal_sections; i++) {
 			struct skcipher_request *req = ic->sk_requests[i];
 			if (req) {
-				kzfree(req->iv);
+				kfree_sensitive(req->iv);
 				skcipher_request_free(req);
 			}
 		}
diff --git a/drivers/misc/ibmvmc.c b/drivers/misc/ibmvmc.c
index fb83d1375638..aebac3938d92 100644
--- a/drivers/misc/ibmvmc.c
+++ b/drivers/misc/ibmvmc.c
@@ -286,7 +286,7 @@ static void *alloc_dma_buffer(struct vio_dev *vdev, size_t size,
 
 	if (dma_mapping_error(&vdev->dev, *dma_handle)) {
 		*dma_handle = 0;
-		kzfree(buffer);
+		kfree_sensitive(buffer);
 		return NULL;
 	}
 
@@ -310,7 +310,7 @@ static void free_dma_buffer(struct vio_dev *vdev, size_t size, void *vaddr,
 	dma_unmap_single(&vdev->dev, dma_handle, size, DMA_BIDIRECTIONAL);
 
 	/* deallocate memory */
-	kzfree(vaddr);
+	kfree_sensitive(vaddr);
 }
 
 /**
@@ -880,7 +880,7 @@ static int ibmvmc_close(struct inode *inode, struct file *file)
 		spin_unlock_irqrestore(&hmc->lock, flags);
 	}
 
-	kzfree(session);
+	kfree_sensitive(session);
 
 	return rc;
 }
diff --git a/drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c b/drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c
index 9d36bccde31b..4fc32267ef09 100644
--- a/drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c
+++ b/drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c
@@ -99,7 +99,7 @@ static void hclge_free_vector_ring_chain(struct hnae3_ring_chain_node *head)
 
 	while (chain) {
 		chain_tmp = chain->next;
-		kzfree(chain);
+		kfree_sensitive(chain);
 		chain = chain_tmp;
 	}
 }
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_ipsec.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_ipsec.c
index 94663c2213da..c9f7e554e0ca 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_ipsec.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_ipsec.c
@@ -983,9 +983,9 @@ int ixgbe_ipsec_vf_add_sa(struct ixgbe_adapter *adapter, u32 *msgbuf, u32 vf)
 	return 0;
 
 err_aead:
-	kzfree(xs->aead);
+	kfree_sensitive(xs->aead);
 err_xs:
-	kzfree(xs);
+	kfree_sensitive(xs);
 err_out:
 	msgbuf[1] = err;
 	return err;
@@ -1070,7 +1070,7 @@ int ixgbe_ipsec_vf_del_sa(struct ixgbe_adapter *adapter, u32 *msgbuf, u32 vf)
 	ixgbe_ipsec_del_sa(xs);
 
 	/* remove the xs that was made-up in the add request */
-	kzfree(xs);
+	kfree_sensitive(xs);
 
 	return 0;
 }
* Unmerged path drivers/net/ppp/ppp_mppe.c
* Unmerged path drivers/net/wireguard/noise.c
* Unmerged path drivers/net/wireguard/peer.c
diff --git a/drivers/net/wireless/intel/iwlwifi/pcie/rx.c b/drivers/net/wireless/intel/iwlwifi/pcie/rx.c
index 25a108d6a902..1641d41eb68b 100644
--- a/drivers/net/wireless/intel/iwlwifi/pcie/rx.c
+++ b/drivers/net/wireless/intel/iwlwifi/pcie/rx.c
@@ -1369,7 +1369,7 @@ static void iwl_pcie_rx_handle_rb(struct iwl_trans *trans,
 					   &rxcb, rxq->id);
 
 		if (reclaim) {
-			kzfree(txq->entries[cmd_index].free_buf);
+			kfree_sensitive(txq->entries[cmd_index].free_buf);
 			txq->entries[cmd_index].free_buf = NULL;
 		}
 
diff --git a/drivers/net/wireless/intel/iwlwifi/pcie/tx-gen2.c b/drivers/net/wireless/intel/iwlwifi/pcie/tx-gen2.c
index 7fc7542535d8..606bef2ecc7b 100644
--- a/drivers/net/wireless/intel/iwlwifi/pcie/tx-gen2.c
+++ b/drivers/net/wireless/intel/iwlwifi/pcie/tx-gen2.c
@@ -1026,7 +1026,7 @@ static int iwl_pcie_gen2_enqueue_hcmd(struct iwl_trans *trans,
 	BUILD_BUG_ON(IWL_TFH_NUM_TBS > sizeof(out_meta->tbs) * BITS_PER_BYTE);
 	out_meta->flags = cmd->flags;
 	if (WARN_ON_ONCE(txq->entries[idx].free_buf))
-		kzfree(txq->entries[idx].free_buf);
+		kfree_sensitive(txq->entries[idx].free_buf);
 	txq->entries[idx].free_buf = dup_buf;
 
 	trace_iwlwifi_dev_hcmd(trans->dev, cmd, cmd_size, &out_cmd->hdr_wide);
@@ -1257,8 +1257,8 @@ static void iwl_pcie_gen2_txq_free(struct iwl_trans *trans, int txq_id)
 	/* De-alloc array of command/tx buffers */
 	if (txq_id == trans->txqs.cmd.q_id)
 		for (i = 0; i < txq->n_window; i++) {
-			kzfree(txq->entries[i].cmd);
-			kzfree(txq->entries[i].free_buf);
+			kfree_sensitive(txq->entries[i].cmd);
+			kfree_sensitive(txq->entries[i].free_buf);
 		}
 	del_timer_sync(&txq->stuck_timer);
 
diff --git a/drivers/net/wireless/intel/iwlwifi/pcie/tx.c b/drivers/net/wireless/intel/iwlwifi/pcie/tx.c
index 5c6c3fa0d29f..eb396c06b7fb 100644
--- a/drivers/net/wireless/intel/iwlwifi/pcie/tx.c
+++ b/drivers/net/wireless/intel/iwlwifi/pcie/tx.c
@@ -721,8 +721,8 @@ static void iwl_pcie_txq_free(struct iwl_trans *trans, int txq_id)
 	/* De-alloc array of command/tx buffers */
 	if (txq_id == trans->txqs.cmd.q_id)
 		for (i = 0; i < txq->n_window; i++) {
-			kzfree(txq->entries[i].cmd);
-			kzfree(txq->entries[i].free_buf);
+			kfree_sensitive(txq->entries[i].cmd);
+			kfree_sensitive(txq->entries[i].free_buf);
 		}
 
 	/* De-alloc circular buffer of TFDs */
@@ -1765,7 +1765,7 @@ static int iwl_pcie_enqueue_hcmd(struct iwl_trans *trans,
 	BUILD_BUG_ON(IWL_TFH_NUM_TBS > sizeof(out_meta->tbs) * BITS_PER_BYTE);
 	out_meta->flags = cmd->flags;
 	if (WARN_ON_ONCE(txq->entries[idx].free_buf))
-		kzfree(txq->entries[idx].free_buf);
+		kfree_sensitive(txq->entries[idx].free_buf);
 	txq->entries[idx].free_buf = dup_buf;
 
 	trace_iwlwifi_dev_hcmd(trans->dev, cmd, cmd_size, &out_cmd->hdr_wide);
diff --git a/drivers/net/wireless/intersil/orinoco/wext.c b/drivers/net/wireless/intersil/orinoco/wext.c
index 1d4dae422106..7b6c4ae8ddb3 100644
--- a/drivers/net/wireless/intersil/orinoco/wext.c
+++ b/drivers/net/wireless/intersil/orinoco/wext.c
@@ -31,8 +31,8 @@ static int orinoco_set_key(struct orinoco_private *priv, int index,
 			   enum orinoco_alg alg, const u8 *key, int key_len,
 			   const u8 *seq, int seq_len)
 {
-	kzfree(priv->keys[index].key);
-	kzfree(priv->keys[index].seq);
+	kfree_sensitive(priv->keys[index].key);
+	kfree_sensitive(priv->keys[index].seq);
 
 	if (key_len) {
 		priv->keys[index].key = kzalloc(key_len, GFP_ATOMIC);
diff --git a/drivers/s390/crypto/ap_bus.h b/drivers/s390/crypto/ap_bus.h
index 0a20eede0143..1059cb9a42d4 100644
--- a/drivers/s390/crypto/ap_bus.h
+++ b/drivers/s390/crypto/ap_bus.h
@@ -222,8 +222,8 @@ static inline void ap_init_message(struct ap_message *ap_msg)
  */
 static inline void ap_release_message(struct ap_message *ap_msg)
 {
-	kzfree(ap_msg->msg);
-	kzfree(ap_msg->private);
+	kfree_sensitive(ap_msg->msg);
+	kfree_sensitive(ap_msg->private);
 }
 
 /*
* Unmerged path drivers/staging/ks7010/ks_hostif.c
* Unmerged path drivers/staging/rtl8723bs/core/rtw_security.c
diff --git a/drivers/staging/wlan-ng/p80211netdev.c b/drivers/staging/wlan-ng/p80211netdev.c
index 67d4abdf0a9a..8fd6e4a07181 100644
--- a/drivers/staging/wlan-ng/p80211netdev.c
+++ b/drivers/staging/wlan-ng/p80211netdev.c
@@ -429,7 +429,7 @@ static netdev_tx_t p80211knetdev_hard_start_xmit(struct sk_buff *skb,
 failed:
 	/* Free up the WEP buffer if it's not the same as the skb */
 	if ((p80211_wep.data) && (p80211_wep.data != skb->data))
-		kzfree(p80211_wep.data);
+		kfree_sensitive(p80211_wep.data);
 
 	/* we always free the skb here, never in a lower level. */
 	if (!result)
diff --git a/drivers/target/iscsi/iscsi_target_auth.c b/drivers/target/iscsi/iscsi_target_auth.c
index 1fa4870a51fd..9b2fc9a02248 100644
--- a/drivers/target/iscsi/iscsi_target_auth.c
+++ b/drivers/target/iscsi/iscsi_target_auth.c
@@ -493,7 +493,7 @@ static int chap_server_compute_hash(
 	pr_debug("[server] Sending CHAP_R=0x%s\n", response);
 	auth_ret = 0;
 out:
-	kzfree(desc);
+	kfree_sensitive(desc);
 	if (tfm)
 		crypto_free_shash(tfm);
 	kfree(initiatorchg);
diff --git a/fs/cifs/cifsencrypt.c b/fs/cifs/cifsencrypt.c
index 874a551f339c..9daa256f69d4 100644
--- a/fs/cifs/cifsencrypt.c
+++ b/fs/cifs/cifsencrypt.c
@@ -797,7 +797,7 @@ calc_seckey(struct cifs_ses *ses)
 	ses->auth_key.len = CIFS_SESS_KEY_SIZE;
 
 	memzero_explicit(sec_key, CIFS_SESS_KEY_SIZE);
-	kzfree(ctx_arc4);
+	kfree_sensitive(ctx_arc4);
 	return 0;
 }
 
diff --git a/fs/cifs/connect.c b/fs/cifs/connect.c
index 5e6f0ec47a02..90b53d702501 100644
--- a/fs/cifs/connect.c
+++ b/fs/cifs/connect.c
@@ -2182,7 +2182,7 @@ cifs_parse_mount_options(const char *mountdata, const char *devname,
 			tmp_end++;
 			if (!(tmp_end < end && tmp_end[1] == delim)) {
 				/* No it is not. Set the password to NULL */
-				kzfree(vol->password);
+				kfree_sensitive(vol->password);
 				vol->password = NULL;
 				break;
 			}
@@ -2220,7 +2220,7 @@ cifs_parse_mount_options(const char *mountdata, const char *devname,
 					options = end;
 			}
 
-			kzfree(vol->password);
+			kfree_sensitive(vol->password);
 			/* Now build new password string */
 			temp_len = strlen(value);
 			vol->password = kzalloc(temp_len+1, GFP_KERNEL);
@@ -3198,7 +3198,7 @@ cifs_set_cifscreds(struct smb_vol *vol, struct cifs_ses *ses)
 			rc = -ENOMEM;
 			kfree(vol->username);
 			vol->username = NULL;
-			kzfree(vol->password);
+			kfree_sensitive(vol->password);
 			vol->password = NULL;
 			goto out_key_put;
 		}
@@ -4225,7 +4225,7 @@ void
 cifs_cleanup_volume_info_contents(struct smb_vol *volume_info)
 {
 	kfree(volume_info->username);
-	kzfree(volume_info->password);
+	kfree_sensitive(volume_info->password);
 	kfree(volume_info->UNC);
 	kfree(volume_info->domainname);
 	kfree(volume_info->iocharset);
@@ -5351,7 +5351,7 @@ cifs_construct_tcon(struct cifs_sb_info *cifs_sb, kuid_t fsuid)
 
 out:
 	kfree(vol_info->username);
-	kzfree(vol_info->password);
+	kfree_sensitive(vol_info->password);
 	kfree(vol_info);
 
 	return tcon;
diff --git a/fs/cifs/dfs_cache.c b/fs/cifs/dfs_cache.c
index 79c5e251aaad..ee042312e891 100644
--- a/fs/cifs/dfs_cache.c
+++ b/fs/cifs/dfs_cache.c
@@ -1130,7 +1130,7 @@ static int dup_vol(struct smb_vol *vol, struct smb_vol *new)
 err_free_unc:
 	kfree(new->UNC);
 err_free_password:
-	kzfree(new->password);
+	kfree_sensitive(new->password);
 err_free_username:
 	kfree(new->username);
 	kfree(new);
diff --git a/fs/cifs/misc.c b/fs/cifs/misc.c
index f239c8023f33..2abfd0509fee 100644
--- a/fs/cifs/misc.c
+++ b/fs/cifs/misc.c
@@ -103,12 +103,12 @@ sesInfoFree(struct cifs_ses *buf_to_free)
 	kfree(buf_to_free->serverOS);
 	kfree(buf_to_free->serverDomain);
 	kfree(buf_to_free->serverNOS);
-	kzfree(buf_to_free->password);
+	kfree_sensitive(buf_to_free->password);
 	kfree(buf_to_free->user_name);
 	kfree(buf_to_free->domainName);
-	kzfree(buf_to_free->auth_key.response);
+	kfree_sensitive(buf_to_free->auth_key.response);
 	kfree(buf_to_free->iface_list);
-	kzfree(buf_to_free);
+	kfree_sensitive(buf_to_free);
 }
 
 struct cifs_tcon *
@@ -148,7 +148,7 @@ tconInfoFree(struct cifs_tcon *buf_to_free)
 	}
 	atomic_dec(&tconInfoAllocCount);
 	kfree(buf_to_free->nativeFileSystem);
-	kzfree(buf_to_free->password);
+	kfree_sensitive(buf_to_free->password);
 	kfree(buf_to_free->crfid.fid);
 #ifdef CONFIG_CIFS_DFS_UPCALL
 	kfree(buf_to_free->dfs_path);
* Unmerged path fs/crypto/inline_crypt.c
* Unmerged path fs/crypto/keyring.c
* Unmerged path fs/crypto/keysetup_v1.c
diff --git a/fs/ecryptfs/keystore.c b/fs/ecryptfs/keystore.c
index e74fe84d0886..72f7e1da6a92 100644
--- a/fs/ecryptfs/keystore.c
+++ b/fs/ecryptfs/keystore.c
@@ -853,7 +853,7 @@ ecryptfs_write_tag_70_packet(char *dest, size_t *remaining_bytes,
 out_release_free_unlock:
 	crypto_free_shash(s->hash_tfm);
 out_free_unlock:
-	kzfree(s->block_aligned_filename);
+	kfree_sensitive(s->block_aligned_filename);
 out_unlock:
 	mutex_unlock(s->tfm_mutex);
 out:
@@ -862,7 +862,7 @@ ecryptfs_write_tag_70_packet(char *dest, size_t *remaining_bytes,
 		key_put(auth_tok_key);
 	}
 	skcipher_request_free(s->skcipher_req);
-	kzfree(s->hash_desc);
+	kfree_sensitive(s->hash_desc);
 	kfree(s);
 	return rc;
 }
diff --git a/fs/ecryptfs/messaging.c b/fs/ecryptfs/messaging.c
index 9fdd5bcf4564..0887359a524a 100644
--- a/fs/ecryptfs/messaging.c
+++ b/fs/ecryptfs/messaging.c
@@ -188,7 +188,7 @@ int ecryptfs_exorcise_daemon(struct ecryptfs_daemon *daemon)
 	}
 	hlist_del(&daemon->euid_chain);
 	mutex_unlock(&daemon->mux);
-	kzfree(daemon);
+	kfree_sensitive(daemon);
 out:
 	return rc;
 }
diff --git a/include/crypto/aead.h b/include/crypto/aead.h
index 1e26f790b03f..acd02841742a 100644
--- a/include/crypto/aead.h
+++ b/include/crypto/aead.h
@@ -436,7 +436,7 @@ static inline struct aead_request *aead_request_alloc(struct crypto_aead *tfm,
  */
 static inline void aead_request_free(struct aead_request *req)
 {
-	kzfree(req);
+	kfree_sensitive(req);
 }
 
 /**
diff --git a/include/crypto/akcipher.h b/include/crypto/akcipher.h
index b5e11de4d497..3cfca2203a03 100644
--- a/include/crypto/akcipher.h
+++ b/include/crypto/akcipher.h
@@ -207,7 +207,7 @@ static inline struct akcipher_request *akcipher_request_alloc(
  */
 static inline void akcipher_request_free(struct akcipher_request *req)
 {
-	kzfree(req);
+	kfree_sensitive(req);
 }
 
 /**
diff --git a/include/crypto/gf128mul.h b/include/crypto/gf128mul.h
index fa0a63d298dc..81330c6446f6 100644
--- a/include/crypto/gf128mul.h
+++ b/include/crypto/gf128mul.h
@@ -230,7 +230,7 @@ void gf128mul_4k_bbe(be128 *a, const struct gf128mul_4k *t);
 void gf128mul_x8_ble(le128 *r, const le128 *x);
 static inline void gf128mul_free_4k(struct gf128mul_4k *t)
 {
-	kzfree(t);
+	kfree_sensitive(t);
 }
 
 
diff --git a/include/crypto/hash.h b/include/crypto/hash.h
index ad2d998f1b03..746ec9571881 100644
--- a/include/crypto/hash.h
+++ b/include/crypto/hash.h
@@ -592,7 +592,7 @@ static inline struct ahash_request *ahash_request_alloc(
  */
 static inline void ahash_request_free(struct ahash_request *req)
 {
-	kzfree(req);
+	kfree_sensitive(req);
 }
 
 static inline void ahash_request_zero(struct ahash_request *req)
diff --git a/include/crypto/internal/acompress.h b/include/crypto/internal/acompress.h
index 51052f65cefc..b7ea98b70854 100644
--- a/include/crypto/internal/acompress.h
+++ b/include/crypto/internal/acompress.h
@@ -51,7 +51,7 @@ static inline struct acomp_req *__acomp_request_alloc(struct crypto_acomp *tfm)
 
 static inline void __acomp_request_free(struct acomp_req *req)
 {
-	kzfree(req);
+	kfree_sensitive(req);
 }
 
 /**
diff --git a/include/crypto/kpp.h b/include/crypto/kpp.h
index 1bde0a6514fa..f89f55c1aeb7 100644
--- a/include/crypto/kpp.h
+++ b/include/crypto/kpp.h
@@ -192,7 +192,7 @@ static inline struct kpp_request *kpp_request_alloc(struct crypto_kpp *tfm,
  */
 static inline void kpp_request_free(struct kpp_request *req)
 {
-	kzfree(req);
+	kfree_sensitive(req);
 }
 
 /**
diff --git a/include/crypto/skcipher.h b/include/crypto/skcipher.h
index d00ce90dc7da..f75e7916cdb1 100644
--- a/include/crypto/skcipher.h
+++ b/include/crypto/skcipher.h
@@ -612,7 +612,7 @@ static inline struct skcipher_request *skcipher_request_alloc(
  */
 static inline void skcipher_request_free(struct skcipher_request *req)
 {
-	kzfree(req);
+	kfree_sensitive(req);
 }
 
 static inline void skcipher_request_zero(struct skcipher_request *req)
* Unmerged path include/linux/slab.h
diff --git a/lib/mpi/mpiutil.c b/lib/mpi/mpiutil.c
index 20ed0f766787..4cd2b335cb7f 100644
--- a/lib/mpi/mpiutil.c
+++ b/lib/mpi/mpiutil.c
@@ -69,7 +69,7 @@ void mpi_free_limb_space(mpi_ptr_t a)
 	if (!a)
 		return;
 
-	kzfree(a);
+	kfree_sensitive(a);
 }
 
 void mpi_assign_limb_space(MPI a, mpi_ptr_t ap, unsigned nlimbs)
@@ -95,7 +95,7 @@ int mpi_resize(MPI a, unsigned nlimbs)
 		if (!p)
 			return -ENOMEM;
 		memcpy(p, a->d, a->alloced * sizeof(mpi_limb_t));
-		kzfree(a->d);
+		kfree_sensitive(a->d);
 		a->d = p;
 	} else {
 		a->d = kcalloc(nlimbs, sizeof(mpi_limb_t), GFP_KERNEL);
@@ -112,7 +112,7 @@ void mpi_free(MPI a)
 		return;
 
 	if (a->flags & 4)
-		kzfree(a->d);
+		kfree_sensitive(a->d);
 	else
 		mpi_free_limb_space(a->d);
 
* Unmerged path lib/test_kasan.c
diff --git a/mm/slab_common.c b/mm/slab_common.c
index 0ab19790edb9..b2b282d3df8e 100644
--- a/mm/slab_common.c
+++ b/mm/slab_common.c
@@ -1714,17 +1714,17 @@ void *krealloc(const void *p, size_t new_size, gfp_t flags)
 EXPORT_SYMBOL(krealloc);
 
 /**
- * kzfree - like kfree but zero memory
+ * kfree_sensitive - Clear sensitive information in memory before freeing
  * @p: object to free memory of
  *
  * The memory of the object @p points to is zeroed before freed.
- * If @p is %NULL, kzfree() does nothing.
+ * If @p is %NULL, kfree_sensitive() does nothing.
  *
  * Note: this function zeroes the whole allocated buffer which can be a good
  * deal bigger than the requested buffer size passed to kmalloc(). So be
  * careful when using this function in performance sensitive code.
  */
-void kzfree(const void *p)
+void kfree_sensitive(const void *p)
 {
 	size_t ks;
 	void *mem = (void *)p;
@@ -1735,7 +1735,7 @@ void kzfree(const void *p)
 	memzero_explicit(mem, ks);
 	kfree(mem);
 }
-EXPORT_SYMBOL(kzfree);
+EXPORT_SYMBOL(kfree_sensitive);
 
 /* Tracepoints definitions. */
 EXPORT_TRACEPOINT_SYMBOL(kmalloc);
* Unmerged path net/atm/mpoa_caches.c
diff --git a/net/bluetooth/ecdh_helper.c b/net/bluetooth/ecdh_helper.c
index 2155ce802877..3226fe02e875 100644
--- a/net/bluetooth/ecdh_helper.c
+++ b/net/bluetooth/ecdh_helper.c
@@ -104,7 +104,7 @@ int compute_ecdh_secret(struct crypto_kpp *tfm, const u8 public_key[64],
 free_all:
 	kpp_request_free(req);
 free_tmp:
-	kzfree(tmp);
+	kfree_sensitive(tmp);
 	return err;
 }
 
@@ -151,9 +151,9 @@ int set_ecdh_privkey(struct crypto_kpp *tfm, const u8 private_key[32])
 	err = crypto_kpp_set_secret(tfm, buf, buf_len);
 	/* fall through */
 free_all:
-	kzfree(buf);
+	kfree_sensitive(buf);
 free_tmp:
-	kzfree(tmp);
+	kfree_sensitive(tmp);
 	return err;
 }
 
* Unmerged path net/bluetooth/smp.c
diff --git a/net/core/sock.c b/net/core/sock.c
index d5f0115da4aa..a88ccbe25444 100644
--- a/net/core/sock.c
+++ b/net/core/sock.c
@@ -2133,7 +2133,7 @@ static inline void __sock_kfree_s(struct sock *sk, void *mem, int size,
 	if (WARN_ON_ONCE(!mem))
 		return;
 	if (nullify)
-		kzfree(mem);
+		kfree_sensitive(mem);
 	else
 		kfree(mem);
 	atomic_sub(size, &sk->sk_omem_alloc);
* Unmerged path net/ipv4/tcp_fastopen.c
diff --git a/net/mac80211/aead_api.c b/net/mac80211/aead_api.c
index c5fe95e49c68..d7b3d905d535 100644
--- a/net/mac80211/aead_api.c
+++ b/net/mac80211/aead_api.c
@@ -41,7 +41,7 @@ int aead_encrypt(struct crypto_aead *tfm, u8 *b_0, u8 *aad, size_t aad_len,
 	aead_request_set_ad(aead_req, sg[0].length);
 
 	crypto_aead_encrypt(aead_req);
-	kzfree(aead_req);
+	kfree_sensitive(aead_req);
 
 	return 0;
 }
@@ -76,7 +76,7 @@ int aead_decrypt(struct crypto_aead *tfm, u8 *b_0, u8 *aad, size_t aad_len,
 	aead_request_set_ad(aead_req, sg[0].length);
 
 	err = crypto_aead_decrypt(aead_req);
-	kzfree(aead_req);
+	kfree_sensitive(aead_req);
 
 	return err;
 }
diff --git a/net/mac80211/aes_gmac.c b/net/mac80211/aes_gmac.c
index 16ba09cb5def..6f3b3a0cc10a 100644
--- a/net/mac80211/aes_gmac.c
+++ b/net/mac80211/aes_gmac.c
@@ -60,7 +60,7 @@ int ieee80211_aes_gmac(struct crypto_aead *tfm, const u8 *aad, u8 *nonce,
 	aead_request_set_ad(aead_req, GMAC_AAD_LEN + data_len);
 
 	crypto_aead_encrypt(aead_req);
-	kzfree(aead_req);
+	kfree_sensitive(aead_req);
 
 	return 0;
 }
diff --git a/net/mac80211/key.c b/net/mac80211/key.c
index 9c2888004878..2df636c32432 100644
--- a/net/mac80211/key.c
+++ b/net/mac80211/key.c
@@ -732,7 +732,7 @@ static void ieee80211_key_free_common(struct ieee80211_key *key)
 		ieee80211_aes_gcm_key_free(key->u.gcmp.tfm);
 		break;
 	}
-	kzfree(key);
+	kfree_sensitive(key);
 }
 
 static void __ieee80211_key_destroy(struct ieee80211_key *key,
* Unmerged path net/mac802154/llsec.c
diff --git a/net/sctp/auth.c b/net/sctp/auth.c
index f469004cfeba..7a28a57e1af3 100644
--- a/net/sctp/auth.c
+++ b/net/sctp/auth.c
@@ -64,7 +64,7 @@ void sctp_auth_key_put(struct sctp_auth_bytes *key)
 		return;
 
 	if (refcount_dec_and_test(&key->refcnt)) {
-		kzfree(key);
+		kfree_sensitive(key);
 		SCTP_DBG_OBJCNT_DEC(keys);
 	}
 }
diff --git a/net/sunrpc/auth_gss/gss_krb5_crypto.c b/net/sunrpc/auth_gss/gss_krb5_crypto.c
index 4b15e4ebe67a..aab422f03210 100644
--- a/net/sunrpc/auth_gss/gss_krb5_crypto.c
+++ b/net/sunrpc/auth_gss/gss_krb5_crypto.c
@@ -1001,7 +1001,7 @@ krb5_rc4_setup_seq_key(struct krb5_ctx *kctx, struct crypto_skcipher *cipher,
 	err = 0;
 
 out_err:
-	kzfree(desc);
+	kfree_sensitive(desc);
 	crypto_free_shash(hmac);
 	dprintk("%s: returning %d\n", __func__, err);
 	return err;
@@ -1076,7 +1076,7 @@ krb5_rc4_setup_enc_key(struct krb5_ctx *kctx, struct crypto_skcipher *cipher,
 	err = 0;
 
 out_err:
-	kzfree(desc);
+	kfree_sensitive(desc);
 	crypto_free_shash(hmac);
 	dprintk("%s: returning %d\n", __func__, err);
 	return err;
diff --git a/net/sunrpc/auth_gss/gss_krb5_keys.c b/net/sunrpc/auth_gss/gss_krb5_keys.c
index f732511ac107..7e8c59f1da65 100644
--- a/net/sunrpc/auth_gss/gss_krb5_keys.c
+++ b/net/sunrpc/auth_gss/gss_krb5_keys.c
@@ -229,11 +229,11 @@ u32 krb5_derive_key(const struct gss_krb5_enctype *gk5e,
 	ret = 0;
 
 err_free_raw:
-	kzfree(rawkey);
+	kfree_sensitive(rawkey);
 err_free_out:
-	kzfree(outblockdata);
+	kfree_sensitive(outblockdata);
 err_free_in:
-	kzfree(inblockdata);
+	kfree_sensitive(inblockdata);
 err_free_cipher:
 	crypto_free_skcipher(cipher);
 err_return:
diff --git a/net/sunrpc/auth_gss/gss_krb5_mech.c b/net/sunrpc/auth_gss/gss_krb5_mech.c
index e049eff002cf..845022d56a55 100644
--- a/net/sunrpc/auth_gss/gss_krb5_mech.c
+++ b/net/sunrpc/auth_gss/gss_krb5_mech.c
@@ -470,7 +470,7 @@ context_derive_keys_rc4(struct krb5_ctx *ctx)
 	desc->flags = 0;
 
 	err = crypto_shash_digest(desc, sigkeyconstant, slen, ctx->cksum);
-	kzfree(desc);
+	kfree_sensitive(desc);
 	if (err)
 		goto out_err_free_hmac;
 	/*
diff --git a/net/tipc/crypto.c b/net/tipc/crypto.c
index a6b91089d2fa..c4e998e2ddee 100644
--- a/net/tipc/crypto.c
+++ b/net/tipc/crypto.c
@@ -530,7 +530,7 @@ static int tipc_aead_init(struct tipc_aead **aead, struct tipc_aead_key *ukey,
 	/* Allocate per-cpu TFM entry pointer */
 	tmp->tfm_entry = alloc_percpu(struct tipc_tfm *);
 	if (!tmp->tfm_entry) {
-		kzfree(tmp);
+		kfree_sensitive(tmp);
 		return -ENOMEM;
 	}
 
@@ -580,7 +580,7 @@ static int tipc_aead_init(struct tipc_aead **aead, struct tipc_aead_key *ukey,
 	/* Not any TFM is allocated? */
 	if (!tfm_cnt) {
 		free_percpu(tmp->tfm_entry);
-		kzfree(tmp);
+		kfree_sensitive(tmp);
 		return err;
 	}
 
@@ -635,7 +635,7 @@ static int tipc_aead_clone(struct tipc_aead **dst, struct tipc_aead *src)
 
 	aead->tfm_entry = alloc_percpu_gfp(struct tipc_tfm *, GFP_ATOMIC);
 	if (unlikely(!aead->tfm_entry)) {
-		kzfree(aead);
+		kfree_sensitive(aead);
 		return -ENOMEM;
 	}
 
@@ -1488,7 +1488,7 @@ int tipc_crypto_start(struct tipc_crypto **crypto, struct net *net,
 	/* Allocate statistic structure */
 	c->stats = alloc_percpu_gfp(struct tipc_crypto_stats, GFP_ATOMIC);
 	if (!c->stats) {
-		kzfree(c);
+		kfree_sensitive(c);
 		return -ENOMEM;
 	}
 
@@ -1543,7 +1543,7 @@ void tipc_crypto_stop(struct tipc_crypto **crypto)
 	free_percpu(c->stats);
 
 	*crypto = NULL;
-	kzfree(c);
+	kfree_sensitive(c);
 }
 
 void tipc_crypto_timeout(struct tipc_crypto *rx)
diff --git a/net/wireless/core.c b/net/wireless/core.c
index 1971d7e6eb55..354b0ccbdc24 100644
--- a/net/wireless/core.c
+++ b/net/wireless/core.c
@@ -1125,7 +1125,7 @@ static void __cfg80211_unregister_wdev(struct wireless_dev *wdev, bool sync)
 	}
 
 #ifdef CONFIG_CFG80211_WEXT
-	kzfree(wdev->wext.keys);
+	kfree_sensitive(wdev->wext.keys);
 	wdev->wext.keys = NULL;
 #endif
 	/* only initialized if we have a netdev */
diff --git a/net/wireless/ibss.c b/net/wireless/ibss.c
index ae8fe66a9bb8..a0621bb76d8e 100644
--- a/net/wireless/ibss.c
+++ b/net/wireless/ibss.c
@@ -127,7 +127,7 @@ int __cfg80211_join_ibss(struct cfg80211_registered_device *rdev,
 		return -EINVAL;
 
 	if (WARN_ON(wdev->connect_keys))
-		kzfree(wdev->connect_keys);
+		kfree_sensitive(wdev->connect_keys);
 	wdev->connect_keys = connkeys;
 
 	wdev->ibss_fixed = params->channel_fixed;
@@ -161,7 +161,7 @@ static void __cfg80211_clear_ibss(struct net_device *dev, bool nowext)
 
 	ASSERT_WDEV_LOCK(wdev);
 
-	kzfree(wdev->connect_keys);
+	kfree_sensitive(wdev->connect_keys);
 	wdev->connect_keys = NULL;
 
 	rdev_set_qos_map(rdev, dev, NULL);
diff --git a/net/wireless/lib80211_crypt_tkip.c b/net/wireless/lib80211_crypt_tkip.c
index f5e842ba7673..1b4d6c87a5c5 100644
--- a/net/wireless/lib80211_crypt_tkip.c
+++ b/net/wireless/lib80211_crypt_tkip.c
@@ -131,7 +131,7 @@ static void lib80211_tkip_deinit(void *priv)
 		crypto_free_shash(_priv->tx_tfm_michael);
 		crypto_free_shash(_priv->rx_tfm_michael);
 	}
-	kzfree(priv);
+	kfree_sensitive(priv);
 }
 
 static inline u16 RotR1(u16 val)
diff --git a/net/wireless/lib80211_crypt_wep.c b/net/wireless/lib80211_crypt_wep.c
index dafc6f3571db..6ab9957b8f96 100644
--- a/net/wireless/lib80211_crypt_wep.c
+++ b/net/wireless/lib80211_crypt_wep.c
@@ -56,7 +56,7 @@ static void *lib80211_wep_init(int keyidx)
 
 static void lib80211_wep_deinit(void *priv)
 {
-	kzfree(priv);
+	kfree_sensitive(priv);
 }
 
 /* Add WEP IV/key info to a frame that has at least 4 bytes of headroom */
diff --git a/net/wireless/nl80211.c b/net/wireless/nl80211.c
index 48d44c8a9ffc..ea93ac066047 100644
--- a/net/wireless/nl80211.c
+++ b/net/wireless/nl80211.c
@@ -9840,7 +9840,7 @@ static int nl80211_join_ibss(struct sk_buff *skb, struct genl_info *info)
 
 		if ((ibss.chandef.width != NL80211_CHAN_WIDTH_20_NOHT) &&
 		    no_ht) {
-			kzfree(connkeys);
+			kfree_sensitive(connkeys);
 			return -EINVAL;
 		}
 	}
@@ -9852,7 +9852,7 @@ static int nl80211_join_ibss(struct sk_buff *skb, struct genl_info *info)
 		int r = validate_pae_over_nl80211(rdev, info);
 
 		if (r < 0) {
-			kzfree(connkeys);
+			kfree_sensitive(connkeys);
 			return r;
 		}
 
@@ -9865,7 +9865,7 @@ static int nl80211_join_ibss(struct sk_buff *skb, struct genl_info *info)
 	wdev_lock(dev->ieee80211_ptr);
 	err = __cfg80211_join_ibss(rdev, dev, &ibss, connkeys);
 	if (err)
-		kzfree(connkeys);
+		kfree_sensitive(connkeys);
 	else if (info->attrs[NL80211_ATTR_SOCKET_OWNER])
 		dev->ieee80211_ptr->conn_owner_nlportid = info->snd_portid;
 	wdev_unlock(dev->ieee80211_ptr);
@@ -10293,7 +10293,7 @@ static int nl80211_connect(struct sk_buff *skb, struct genl_info *info)
 
 	if (info->attrs[NL80211_ATTR_HT_CAPABILITY]) {
 		if (!info->attrs[NL80211_ATTR_HT_CAPABILITY_MASK]) {
-			kzfree(connkeys);
+			kfree_sensitive(connkeys);
 			return -EINVAL;
 		}
 		memcpy(&connect.ht_capa,
@@ -10311,7 +10311,7 @@ static int nl80211_connect(struct sk_buff *skb, struct genl_info *info)
 
 	if (info->attrs[NL80211_ATTR_VHT_CAPABILITY]) {
 		if (!info->attrs[NL80211_ATTR_VHT_CAPABILITY_MASK]) {
-			kzfree(connkeys);
+			kfree_sensitive(connkeys);
 			return -EINVAL;
 		}
 		memcpy(&connect.vht_capa,
@@ -10325,7 +10325,7 @@ static int nl80211_connect(struct sk_buff *skb, struct genl_info *info)
 		       (rdev->wiphy.features & NL80211_FEATURE_QUIET)) &&
 		    !wiphy_ext_feature_isset(&rdev->wiphy,
 					     NL80211_EXT_FEATURE_RRM)) {
-			kzfree(connkeys);
+			kfree_sensitive(connkeys);
 			return -EINVAL;
 		}
 		connect.flags |= ASSOC_REQ_USE_RRM;
@@ -10333,21 +10333,21 @@ static int nl80211_connect(struct sk_buff *skb, struct genl_info *info)
 
 	connect.pbss = nla_get_flag(info->attrs[NL80211_ATTR_PBSS]);
 	if (connect.pbss && !rdev->wiphy.bands[NL80211_BAND_60GHZ]) {
-		kzfree(connkeys);
+		kfree_sensitive(connkeys);
 		return -EOPNOTSUPP;
 	}
 
 	if (info->attrs[NL80211_ATTR_BSS_SELECT]) {
 		/* bss selection makes no sense if bssid is set */
 		if (connect.bssid) {
-			kzfree(connkeys);
+			kfree_sensitive(connkeys);
 			return -EINVAL;
 		}
 
 		err = parse_bss_select(info->attrs[NL80211_ATTR_BSS_SELECT],
 				       wiphy, &connect.bss_select);
 		if (err) {
-			kzfree(connkeys);
+			kfree_sensitive(connkeys);
 			return err;
 		}
 	}
@@ -10377,13 +10377,13 @@ static int nl80211_connect(struct sk_buff *skb, struct genl_info *info)
 		   info->attrs[NL80211_ATTR_FILS_ERP_REALM] ||
 		   info->attrs[NL80211_ATTR_FILS_ERP_NEXT_SEQ_NUM] ||
 		   info->attrs[NL80211_ATTR_FILS_ERP_RRK]) {
-		kzfree(connkeys);
+		kfree_sensitive(connkeys);
 		return -EINVAL;
 	}
 
 	if (nla_get_flag(info->attrs[NL80211_ATTR_EXTERNAL_AUTH_SUPPORT])) {
 		if (!info->attrs[NL80211_ATTR_SOCKET_OWNER]) {
-			kzfree(connkeys);
+			kfree_sensitive(connkeys);
 			GENL_SET_ERR_MSG(info,
 					 "external auth requires connection ownership");
 			return -EINVAL;
@@ -10396,7 +10396,7 @@ static int nl80211_connect(struct sk_buff *skb, struct genl_info *info)
 	err = cfg80211_connect(rdev, dev, &connect, connkeys,
 			       connect.prev_bssid);
 	if (err)
-		kzfree(connkeys);
+		kfree_sensitive(connkeys);
 
 	if (!err && info->attrs[NL80211_ATTR_SOCKET_OWNER]) {
 		dev->ieee80211_ptr->conn_owner_nlportid = info->snd_portid;
diff --git a/net/wireless/sme.c b/net/wireless/sme.c
index 15595cf401de..985f3c23f054 100644
--- a/net/wireless/sme.c
+++ b/net/wireless/sme.c
@@ -742,7 +742,7 @@ void __cfg80211_connect_result(struct net_device *dev,
 	}
 
 	if (cr->status != WLAN_STATUS_SUCCESS) {
-		kzfree(wdev->connect_keys);
+		kfree_sensitive(wdev->connect_keys);
 		wdev->connect_keys = NULL;
 		wdev->ssid_len = 0;
 		wdev->conn_owner_nlportid = 0;
@@ -1098,7 +1098,7 @@ void __cfg80211_disconnected(struct net_device *dev, const u8 *ie,
 	wdev->current_bss = NULL;
 	wdev->ssid_len = 0;
 	wdev->conn_owner_nlportid = 0;
-	kzfree(wdev->connect_keys);
+	kfree_sensitive(wdev->connect_keys);
 	wdev->connect_keys = NULL;
 
 	nl80211_send_disconnected(rdev, dev, reason, ie, ie_len, from_ap);
@@ -1281,7 +1281,7 @@ int cfg80211_disconnect(struct cfg80211_registered_device *rdev,
 
 	ASSERT_WDEV_LOCK(wdev);
 
-	kzfree(wdev->connect_keys);
+	kfree_sensitive(wdev->connect_keys);
 	wdev->connect_keys = NULL;
 
 	wdev->conn_owner_nlportid = 0;
diff --git a/net/wireless/util.c b/net/wireless/util.c
index 7c5888a31af0..7d00e266838c 100644
--- a/net/wireless/util.c
+++ b/net/wireless/util.c
@@ -873,7 +873,7 @@ void cfg80211_upload_connect_keys(struct wireless_dev *wdev)
 		}
 	}
 
-	kzfree(wdev->connect_keys);
+	kfree_sensitive(wdev->connect_keys);
 	wdev->connect_keys = NULL;
 }
 
diff --git a/net/wireless/wext-sme.c b/net/wireless/wext-sme.c
index 73fd0eae08ca..73df23570d43 100644
--- a/net/wireless/wext-sme.c
+++ b/net/wireless/wext-sme.c
@@ -57,7 +57,7 @@ int cfg80211_mgd_wext_connect(struct cfg80211_registered_device *rdev,
 	err = cfg80211_connect(rdev, wdev->netdev,
 			       &wdev->wext.connect, ck, prev_bssid);
 	if (err)
-		kzfree(ck);
+		kfree_sensitive(ck);
 
 	return err;
 }
diff --git a/scripts/coccinelle/free/devm_free.cocci b/scripts/coccinelle/free/devm_free.cocci
index b2a2cf8bf81f..80b732f7747f 100644
--- a/scripts/coccinelle/free/devm_free.cocci
+++ b/scripts/coccinelle/free/devm_free.cocci
@@ -92,7 +92,7 @@ position p;
 (
  kfree@p(x)
 |
- kzfree@p(x)
+ kfree_sensitive@p(x)
 |
  __krealloc@p(x, ...)
 |
@@ -117,7 +117,7 @@ position p != safe.p;
 (
 * kfree@p(x)
 |
-* kzfree@p(x)
+* kfree_sensitive@p(x)
 |
 * __krealloc@p(x, ...)
 |
diff --git a/scripts/coccinelle/free/ifnullfree.cocci b/scripts/coccinelle/free/ifnullfree.cocci
index a70e123cb12b..7505a515fead 100644
--- a/scripts/coccinelle/free/ifnullfree.cocci
+++ b/scripts/coccinelle/free/ifnullfree.cocci
@@ -20,7 +20,7 @@ expression E;
 (
   kfree(E);
 |
-  kzfree(E);
+  kfree_sensitive(E);
 |
   debugfs_remove(E);
 |
@@ -41,7 +41,7 @@ position p;
 @@
 
 * if (E != NULL)
-*	\(kfree@p\|kzfree@p\|debugfs_remove@p\|debugfs_remove_recursive@p\|
+*	\(kfree@p\|kfree_sensitive@p\|debugfs_remove@p\|debugfs_remove_recursive@p\|
 *         usb_free_urb@p\|kmem_cache_destroy@p\|mempool_destroy@p\|
 *         dma_pool_destroy@p\)(E);
 
diff --git a/scripts/coccinelle/free/kfree.cocci b/scripts/coccinelle/free/kfree.cocci
index ac438da4fd7b..3a7b15c241dc 100644
--- a/scripts/coccinelle/free/kfree.cocci
+++ b/scripts/coccinelle/free/kfree.cocci
@@ -23,7 +23,7 @@ position p1;
 (
 * kfree@p1(E)
 |
-* kzfree@p1(E)
+* kfree_sensitive@p1(E)
 )
 
 @print expression@
@@ -67,7 +67,7 @@ while (1) { ...
 (
 * kfree@ok(E)
 |
-* kzfree@ok(E)
+* kfree_sensitive@ok(E)
 )
   ... when != break;
       when != goto l;
@@ -85,7 +85,7 @@ position free.p1!=loop.ok,p2!={print.p,sz.p};
 (
 * kfree@p1(E,...)
 |
-* kzfree@p1(E,...)
+* kfree_sensitive@p1(E,...)
 )
 ...
 (
diff --git a/scripts/coccinelle/free/kfreeaddr.cocci b/scripts/coccinelle/free/kfreeaddr.cocci
index d46063b1db8b..5b0c85164214 100644
--- a/scripts/coccinelle/free/kfreeaddr.cocci
+++ b/scripts/coccinelle/free/kfreeaddr.cocci
@@ -19,7 +19,7 @@ position p;
 (
 * kfree@p(&e->f)
 |
-* kzfree@p(&e->f)
+* kfree_sensitive@p(&e->f)
 )
 
 @script:python depends on org@
diff --git a/security/apparmor/domain.c b/security/apparmor/domain.c
index 098d546d8253..989d65d26689 100644
--- a/security/apparmor/domain.c
+++ b/security/apparmor/domain.c
@@ -44,8 +44,8 @@ void aa_free_domain_entries(struct aa_domain *domain)
 			return;
 
 		for (i = 0; i < domain->size; i++)
-			kzfree(domain->table[i]);
-		kzfree(domain->table);
+			kfree_sensitive(domain->table[i]);
+		kfree_sensitive(domain->table);
 		domain->table = NULL;
 	}
 }
diff --git a/security/apparmor/include/file.h b/security/apparmor/include/file.h
index 4c2c8ac8842f..2e3a67b2f44d 100644
--- a/security/apparmor/include/file.h
+++ b/security/apparmor/include/file.h
@@ -73,7 +73,7 @@ static inline void aa_free_file_ctx(struct aa_file_ctx *ctx)
 {
 	if (ctx) {
 		aa_put_label(rcu_access_pointer(ctx->label));
-		kzfree(ctx);
+		kfree_sensitive(ctx);
 	}
 }
 
* Unmerged path security/apparmor/policy.c
diff --git a/security/apparmor/policy_ns.c b/security/apparmor/policy_ns.c
index b0f9dc3f765a..ec6672cf6d10 100644
--- a/security/apparmor/policy_ns.c
+++ b/security/apparmor/policy_ns.c
@@ -125,9 +125,9 @@ static struct aa_ns *alloc_ns(const char *prefix, const char *name)
 	return ns;
 
 fail_unconfined:
-	kzfree(ns->base.hname);
+	kfree_sensitive(ns->base.hname);
 fail_ns:
-	kzfree(ns);
+	kfree_sensitive(ns);
 	return NULL;
 }
 
@@ -149,7 +149,7 @@ void aa_free_ns(struct aa_ns *ns)
 
 	ns->unconfined->ns = NULL;
 	aa_free_profile(ns->unconfined);
-	kzfree(ns);
+	kfree_sensitive(ns);
 }
 
 /**
diff --git a/security/apparmor/policy_unpack.c b/security/apparmor/policy_unpack.c
index 0e566a01d217..361dac790566 100644
--- a/security/apparmor/policy_unpack.c
+++ b/security/apparmor/policy_unpack.c
@@ -164,10 +164,10 @@ static void do_loaddata_free(struct work_struct *work)
 		aa_put_ns(ns);
 	}
 
-	kzfree(d->hash);
-	kzfree(d->name);
+	kfree_sensitive(d->hash);
+	kfree_sensitive(d->name);
 	kvfree(d->data);
-	kzfree(d);
+	kfree_sensitive(d);
 }
 
 void aa_loaddata_kref(struct kref *kref)
@@ -830,7 +830,7 @@ static struct aa_profile *unpack_profile(struct aa_ext *e, char **ns_name)
 		while (unpack_strdup(e, &key, NULL)) {
 			data = kzalloc(sizeof(*data), GFP_KERNEL);
 			if (!data) {
-				kzfree(key);
+				kfree_sensitive(key);
 				goto fail;
 			}
 
@@ -838,8 +838,8 @@ static struct aa_profile *unpack_profile(struct aa_ext *e, char **ns_name)
 			data->size = unpack_blob(e, &data->data, NULL);
 			data->data = kvmemdup(data->data, data->size);
 			if (data->size && !data->data) {
-				kzfree(data->key);
-				kzfree(data);
+				kfree_sensitive(data->key);
+				kfree_sensitive(data);
 				goto fail;
 			}
 
@@ -970,7 +970,7 @@ void aa_load_ent_free(struct aa_load_ent *ent)
 		aa_put_profile(ent->old);
 		aa_put_profile(ent->new);
 		kfree(ent->ns_name);
-		kzfree(ent);
+		kfree_sensitive(ent);
 	}
 }
 
diff --git a/security/keys/big_key.c b/security/keys/big_key.c
index 630594a5b46e..15381ee591bb 100644
--- a/security/keys/big_key.c
+++ b/security/keys/big_key.c
@@ -285,7 +285,7 @@ int big_key_preparse(struct key_preparsed_payload *prep)
 err_fput:
 	fput(file);
 err_enckey:
-	kzfree(enckey);
+	kfree_sensitive(enckey);
 error:
 	big_key_free_buffer(buf);
 	return ret;
@@ -301,7 +301,7 @@ void big_key_free_preparse(struct key_preparsed_payload *prep)
 
 		path_put(path);
 	}
-	kzfree(prep->payload.data[big_key_data]);
+	kfree_sensitive(prep->payload.data[big_key_data]);
 }
 
 /*
@@ -333,7 +333,7 @@ void big_key_destroy(struct key *key)
 		path->mnt = NULL;
 		path->dentry = NULL;
 	}
-	kzfree(key->payload.data[big_key_data]);
+	kfree_sensitive(key->payload.data[big_key_data]);
 	key->payload.data[big_key_data] = NULL;
 }
 
diff --git a/security/keys/dh.c b/security/keys/dh.c
index b203f7758f97..f644fafdcc62 100644
--- a/security/keys/dh.c
+++ b/security/keys/dh.c
@@ -62,9 +62,9 @@ static ssize_t dh_data_from_key(key_serial_t keyid, void **data)
 
 static void dh_free_data(struct dh *dh)
 {
-	kzfree(dh->key);
-	kzfree(dh->p);
-	kzfree(dh->g);
+	kfree_sensitive(dh->key);
+	kfree_sensitive(dh->p);
+	kfree_sensitive(dh->g);
 }
 
 struct dh_completion {
@@ -131,7 +131,7 @@ static void kdf_dealloc(struct kdf_sdesc *sdesc)
 	if (sdesc->shash.tfm)
 		crypto_free_shash(sdesc->shash.tfm);
 
-	kzfree(sdesc);
+	kfree_sensitive(sdesc);
 }
 
 /*
@@ -225,7 +225,7 @@ static int keyctl_dh_compute_kdf(struct kdf_sdesc *sdesc,
 		ret = -EFAULT;
 
 err:
-	kzfree(outbuf);
+	kfree_sensitive(outbuf);
 	return ret;
 }
 
@@ -400,11 +400,11 @@ long __keyctl_dh_compute(struct keyctl_dh_params __user *params,
 out6:
 	kpp_request_free(req);
 out5:
-	kzfree(outbuf);
+	kfree_sensitive(outbuf);
 out4:
 	crypto_free_kpp(tfm);
 out3:
-	kzfree(secret);
+	kfree_sensitive(secret);
 out2:
 	dh_free_data(&dh_inputs);
 out1:
* Unmerged path security/keys/encrypted-keys/encrypted.c
diff --git a/security/keys/trusted-keys/trusted_tpm1.c b/security/keys/trusted-keys/trusted_tpm1.c
index 52d68ed0d997..7a1fc51a6e36 100644
--- a/security/keys/trusted-keys/trusted_tpm1.c
+++ b/security/keys/trusted-keys/trusted_tpm1.c
@@ -72,7 +72,7 @@ static int TSS_sha1(const unsigned char *data, unsigned int datalen,
 	}
 
 	ret = crypto_shash_digest(&sdesc->shash, data, datalen, digest);
-	kzfree(sdesc);
+	kfree_sensitive(sdesc);
 	return ret;
 }
 
@@ -116,7 +116,7 @@ static int TSS_rawhmac(unsigned char *digest, const unsigned char *key,
 	if (!ret)
 		ret = crypto_shash_final(&sdesc->shash, digest);
 out:
-	kzfree(sdesc);
+	kfree_sensitive(sdesc);
 	return ret;
 }
 
@@ -170,7 +170,7 @@ int TSS_authhmac(unsigned char *digest, const unsigned char *key,
 				  paramdigest, TPM_NONCE_SIZE, h1,
 				  TPM_NONCE_SIZE, h2, 1, &c, 0, 0);
 out:
-	kzfree(sdesc);
+	kfree_sensitive(sdesc);
 	return ret;
 }
 EXPORT_SYMBOL_GPL(TSS_authhmac);
@@ -255,7 +255,7 @@ int TSS_checkhmac1(unsigned char *buffer,
 	if (memcmp(testhmac, authdata, SHA1_DIGEST_SIZE))
 		ret = -EINVAL;
 out:
-	kzfree(sdesc);
+	kfree_sensitive(sdesc);
 	return ret;
 }
 EXPORT_SYMBOL_GPL(TSS_checkhmac1);
@@ -357,7 +357,7 @@ static int TSS_checkhmac2(unsigned char *buffer,
 	if (memcmp(testhmac2, authdata2, SHA1_DIGEST_SIZE))
 		ret = -EINVAL;
 out:
-	kzfree(sdesc);
+	kfree_sensitive(sdesc);
 	return ret;
 }
 
@@ -567,7 +567,7 @@ static int tpm_seal(struct tpm_buf *tb, uint16_t keytype,
 		*bloblen = storedsize;
 	}
 out:
-	kzfree(td);
+	kfree_sensitive(td);
 	return ret;
 }
 
@@ -1035,12 +1035,12 @@ static int trusted_instantiate(struct key *key,
 	if (!ret && options->pcrlock)
 		ret = pcrlock(options->pcrlock);
 out:
-	kzfree(datablob);
-	kzfree(options);
+	kfree_sensitive(datablob);
+	kfree_sensitive(options);
 	if (!ret)
 		rcu_assign_keypointer(key, payload);
 	else
-		kzfree(payload);
+		kfree_sensitive(payload);
 	return ret;
 }
 
@@ -1049,7 +1049,7 @@ static void trusted_rcu_free(struct rcu_head *rcu)
 	struct trusted_key_payload *p;
 
 	p = container_of(rcu, struct trusted_key_payload, rcu);
-	kzfree(p);
+	kfree_sensitive(p);
 }
 
 /*
@@ -1091,13 +1091,13 @@ static int trusted_update(struct key *key, struct key_preparsed_payload *prep)
 	ret = datablob_parse(datablob, new_p, new_o);
 	if (ret != Opt_update) {
 		ret = -EINVAL;
-		kzfree(new_p);
+		kfree_sensitive(new_p);
 		goto out;
 	}
 
 	if (!new_o->keyhandle) {
 		ret = -EINVAL;
-		kzfree(new_p);
+		kfree_sensitive(new_p);
 		goto out;
 	}
 
@@ -1111,22 +1111,22 @@ static int trusted_update(struct key *key, struct key_preparsed_payload *prep)
 	ret = key_seal(new_p, new_o);
 	if (ret < 0) {
 		pr_info("trusted_key: key_seal failed (%d)\n", ret);
-		kzfree(new_p);
+		kfree_sensitive(new_p);
 		goto out;
 	}
 	if (new_o->pcrlock) {
 		ret = pcrlock(new_o->pcrlock);
 		if (ret < 0) {
 			pr_info("trusted_key: pcrlock failed (%d)\n", ret);
-			kzfree(new_p);
+			kfree_sensitive(new_p);
 			goto out;
 		}
 	}
 	rcu_assign_keypointer(key, new_p);
 	call_rcu(&p->rcu, trusted_rcu_free);
 out:
-	kzfree(datablob);
-	kzfree(new_o);
+	kfree_sensitive(datablob);
+	kfree_sensitive(new_o);
 	return ret;
 }
 
@@ -1158,7 +1158,7 @@ static long trusted_read(const struct key *key, char *buffer,
  */
 static void trusted_destroy(struct key *key)
 {
-	kzfree(key->payload.data[0]);
+	kfree_sensitive(key->payload.data[0]);
 }
 
 struct key_type key_type_trusted = {
diff --git a/security/keys/user_defined.c b/security/keys/user_defined.c
index c49d46ffef19..aa0dd6fb8a0b 100644
--- a/security/keys/user_defined.c
+++ b/security/keys/user_defined.c
@@ -86,7 +86,7 @@ EXPORT_SYMBOL_GPL(user_preparse);
  */
 void user_free_preparse(struct key_preparsed_payload *prep)
 {
-	kzfree(prep->payload.data[0]);
+	kfree_sensitive(prep->payload.data[0]);
 }
 EXPORT_SYMBOL_GPL(user_free_preparse);
 
@@ -95,7 +95,7 @@ static void user_free_payload_rcu(struct rcu_head *head)
 	struct user_key_payload *payload;
 
 	payload = container_of(head, struct user_key_payload, rcu);
-	kzfree(payload);
+	kfree_sensitive(payload);
 }
 
 /*
@@ -151,7 +151,7 @@ void user_destroy(struct key *key)
 {
 	struct user_key_payload *upayload = key->payload.data[0];
 
-	kzfree(upayload);
+	kfree_sensitive(upayload);
 }
 
 EXPORT_SYMBOL_GPL(user_destroy);
