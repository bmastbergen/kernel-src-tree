x86/asm: Carve out a generic movdir64b() helper for general usage

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Dave Jiang <dave.jiang@intel.com>
commit 0888e1030d3e3e5ce9dfd8e030cf13a2e9a1519a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/0888e103.failed

Carve out the MOVDIR64B inline asm primitive into a generic helper so
that it can be used by other functions. Move it to special_insns.h and
have iosubmit_cmds512() call it.

 [ bp: Massage commit message. ]

	Suggested-by: Michael Matz <matz@suse.de>
	Signed-off-by: Dave Jiang <dave.jiang@intel.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Reviewed-by: Tony Luck <tony.luck@intel.com>
	Reviewed-by: Borislav Petkov <bp@suse.de>
Link: https://lkml.kernel.org/r/20201005151126.657029-2-dave.jiang@intel.com
(cherry picked from commit 0888e1030d3e3e5ce9dfd8e030cf13a2e9a1519a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/special_insns.h
diff --cc arch/x86/include/asm/special_insns.h
index 3a97fbd3d547,d4baa0eb5564..000000000000
--- a/arch/x86/include/asm/special_insns.h
+++ b/arch/x86/include/asm/special_insns.h
@@@ -252,47 -234,26 +252,70 @@@ static inline void clwb(volatile void *
  
  #define nop() asm volatile ("nop")
  
++<<<<<<< HEAD
 +
 +/**
 + * enqcmds - Enqueue a command in supervisor (CPL0) mode
 + * @dst: destination, in MMIO space (must be 512-bit aligned)
 + * @src: 512 bits memory operand
 + *
 + * The ENQCMDS instruction allows software to write a 512-bit command to
 + * a 512-bit-aligned special MMIO region that supports the instruction.
 + * A return status is loaded into the ZF flag in the RFLAGS register.
 + * ZF = 0 equates to success, and ZF = 1 indicates retry or error.
 + *
 + * This function issues the ENQCMDS instruction to submit data from
 + * kernel space to MMIO space, in a unit of 512 bits. Order of data access
 + * is not guaranteed, nor is a memory barrier performed afterwards. It
 + * returns 0 on success and -EAGAIN on failure.
 + *
 + * Warning: Do not use this helper unless your driver has checked that the
 + * ENQCMDS instruction is supported on the platform and the device accepts
 + * ENQCMDS.
 + */
 +static inline int enqcmds(void __iomem *dst, const void *src)
 +{
 +	const struct { char _[64]; } *__src = src;
 +	struct { char _[64]; } *__dst = dst;
 +	int zf;
 +
 +	/*
 +	 * ENQCMDS %(rdx), rax
 +	 *
 +	 * See movdir64b()'s comment on operand specification.
 +	 */
 +	asm volatile(".byte 0xf3, 0x0f, 0x38, 0xf8, 0x02, 0x66, 0x90"
 +		     CC_SET(z)
 +		     : CC_OUT(z) (zf), "+m" (*__dst)
 +		     : "m" (*__src), "a" (__dst), "d" (__src));
 +
 +	/* Submission failure is indicated via EFLAGS.ZF=1 */
 +	if (zf)
 +		return -EAGAIN;
 +
 +	return 0;
++=======
+ /* The dst parameter must be 64-bytes aligned */
+ static inline void movdir64b(void *dst, const void *src)
+ {
+ 	const struct { char _[64]; } *__src = src;
+ 	struct { char _[64]; } *__dst = dst;
+ 
+ 	/*
+ 	 * MOVDIR64B %(rdx), rax.
+ 	 *
+ 	 * Both __src and __dst must be memory constraints in order to tell the
+ 	 * compiler that no other memory accesses should be reordered around
+ 	 * this one.
+ 	 *
+ 	 * Also, both must be supplied as lvalues because this tells
+ 	 * the compiler what the object is (its size) the instruction accesses.
+ 	 * I.e., not the pointers but what they point to, thus the deref'ing '*'.
+ 	 */
+ 	asm volatile(".byte 0x66, 0x0f, 0x38, 0xf8, 0x02"
+ 		     : "+m" (*__dst)
+ 		     :  "m" (*__src), "a" (__dst), "d" (__src));
++>>>>>>> 0888e1030d3e (x86/asm: Carve out a generic movdir64b() helper for general usage)
  }
  
  #endif /* __KERNEL__ */
diff --git a/arch/x86/include/asm/io.h b/arch/x86/include/asm/io.h
index 4d3d0e1203b6..a4d10afc6bcd 100644
--- a/arch/x86/include/asm/io.h
+++ b/arch/x86/include/asm/io.h
@@ -399,7 +399,7 @@ extern bool phys_mem_access_encrypted(unsigned long phys_addr,
 
 /**
  * iosubmit_cmds512 - copy data to single MMIO location, in 512-bit units
- * @__dst: destination, in MMIO space (must be 512-bit aligned)
+ * @dst: destination, in MMIO space (must be 512-bit aligned)
  * @src: source
  * @count: number of 512 bits quantities to submit
  *
@@ -410,25 +410,14 @@ extern bool phys_mem_access_encrypted(unsigned long phys_addr,
  * Warning: Do not use this helper unless your driver has checked that the CPU
  * instruction is supported on the platform.
  */
-static inline void iosubmit_cmds512(void __iomem *__dst, const void *src,
+static inline void iosubmit_cmds512(void __iomem *dst, const void *src,
 				    size_t count)
 {
-	/*
-	 * Note that this isn't an "on-stack copy", just definition of "dst"
-	 * as a pointer to 64-bytes of stuff that is going to be overwritten.
-	 * In the MOVDIR64B case that may be needed as you can use the
-	 * MOVDIR64B instruction to copy arbitrary memory around. This trick
-	 * lets the compiler know how much gets clobbered.
-	 */
-	volatile struct { char _[64]; } *dst = __dst;
 	const u8 *from = src;
 	const u8 *end = from + count * 64;
 
 	while (from < end) {
-		/* MOVDIR64B [rdx], rax */
-		asm volatile(".byte 0x66, 0x0f, 0x38, 0xf8, 0x02"
-			     : "=m" (dst)
-			     : "d" (from), "a" (dst));
+		movdir64b(dst, from);
 		from += 64;
 	}
 }
* Unmerged path arch/x86/include/asm/special_insns.h
