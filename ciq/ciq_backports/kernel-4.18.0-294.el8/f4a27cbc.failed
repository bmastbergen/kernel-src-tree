seqlock: Reorder seqcount_t and seqlock_t API definitions

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Ahmed S. Darwish <a.darwish@linutronix.de>
commit f4a27cbcec90ac04ee60e04b222e1449dcdba0bd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/f4a27cbc.failed

The seqlock.h seqcount_t and seqlock_t API definitions are presented in
the chronological order of their development rather than the order that
makes most sense to readers. This makes it hard to follow and understand
the header file code.

Group and reorder all of the exported seqlock.h functions according to
their function.

First, group together the seqcount_t standard read path functions:

    - __read_seqcount_begin()
    - raw_read_seqcount_begin()
    - read_seqcount_begin()

since each function is implemented exactly in terms of the one above
it. Then, group the special-case seqcount_t readers on their own as:

    - raw_read_seqcount()
    - raw_seqcount_begin()

since the only difference between the two functions is that the second
one masks the sequence counter LSB while the first one does not. Note
that raw_seqcount_begin() can actually be implemented in terms of
raw_read_seqcount(), which will be done in a follow-up commit.

Then, group the seqcount_t write path functions, instead of injecting
unrelated seqcount_t latch functions between them, and order them as:

    - raw_write_seqcount_begin()
    - raw_write_seqcount_end()
    - write_seqcount_begin_nested()
    - write_seqcount_begin()
    - write_seqcount_end()
    - raw_write_seqcount_barrier()
    - write_seqcount_invalidate()

which is the expected natural order. This also isolates the seqcount_t
latch functions into their own area, at the end of the sequence counters
section, and before jumping to the next one: sequential locks
(seqlock_t).

Do a similar grouping and reordering for seqlock_t "locking" readers vs.
the "conditionally locking or lockless" ones.

No implementation code was changed in any of the reordering above.

	Signed-off-by: Ahmed S. Darwish <a.darwish@linutronix.de>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: https://lkml.kernel.org/r/20200720155530.1173732-5-a.darwish@linutronix.de
(cherry picked from commit f4a27cbcec90ac04ee60e04b222e1449dcdba0bd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/seqlock.h
diff --cc include/linux/seqlock.h
index 07f6a4bc9dd1,4c1456008d89..000000000000
--- a/include/linux/seqlock.h
+++ b/include/linux/seqlock.h
@@@ -403,41 -426,15 +433,53 @@@ static inline void raw_write_seqcount_l
  }
  
  /*
++<<<<<<< HEAD
 + * Sequence counter only version assumes that callers are using their
 + * own mutexing.
 + */
 +static inline void write_seqcount_begin_nested(seqcount_t *s, int subclass)
 +{
 +	raw_write_seqcount_begin(s);
 +	seqcount_acquire(&s->dep_map, subclass, 0, _RET_IP_);
 +}
 +
 +static inline void write_seqcount_begin(seqcount_t *s)
 +{
 +	write_seqcount_begin_nested(s, 0);
 +}
 +
 +static inline void write_seqcount_end(seqcount_t *s)
 +{
 +	seqcount_release(&s->dep_map, _RET_IP_);
 +	raw_write_seqcount_end(s);
 +}
 +
 +/**
 + * write_seqcount_invalidate - invalidate in-progress read-side seq operations
 + * @s: pointer to seqcount_t
 + *
 + * After write_seqcount_invalidate, no read-side seq operations will complete
 + * successfully and see data older than this.
 + */
 +static inline void write_seqcount_invalidate(seqcount_t *s)
 +{
 +	smp_wmb();
 +	kcsan_nestable_atomic_begin();
 +	s->sequence+=2;
 +	kcsan_nestable_atomic_end();
 +}
 +
++=======
+  * Sequential locks (seqlock_t)
+  *
+  * Sequence counters with an embedded spinlock for writer serialization
+  * and non-preemptibility.
+  *
+  * For more info, see:
+  *    - Comments on top of seqcount_t
+  *    - Documentation/locking/seqlock.rst
+  */
++>>>>>>> f4a27cbcec90 (seqlock: Reorder seqcount_t and seqlock_t API definitions)
  typedef struct {
  	struct seqcount seqcount;
  	spinlock_t lock;
* Unmerged path include/linux/seqlock.h
