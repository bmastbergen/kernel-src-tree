mm: slub: really fix slab walking for init_on_free

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Laura Abbott <labbott@redhat.com>
commit aea4df4c53f754cc229edde6c5465e481311cc49
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/aea4df4c.failed

Commit 1b7e816fc80e ("mm: slub: Fix slab walking for init_on_free")
fixed one problem with the slab walking but missed a key detail: When
walking the list, the head and tail pointers need to be updated since we
end up reversing the list as a result.  Without doing this, bulk free is
broken.

One way this is exposed is a NULL pointer with slub_debug=F:

  =============================================================================
  BUG skbuff_head_cache (Tainted: G                T): Object already free
  -----------------------------------------------------------------------------

  INFO: Slab 0x000000000d2d2f8f objects=16 used=3 fp=0x0000000064309071 flags=0x3fff00000000201
  BUG: kernel NULL pointer dereference, address: 0000000000000000
  Oops: 0000 [#1] PREEMPT SMP PTI
  RIP: 0010:print_trailer+0x70/0x1d5
  Call Trace:
   <IRQ>
   free_debug_processing.cold.37+0xc9/0x149
   __slab_free+0x22a/0x3d0
   kmem_cache_free_bulk+0x415/0x420
   __kfree_skb_flush+0x30/0x40
   net_rx_action+0x2dd/0x480
   __do_softirq+0xf0/0x246
   irq_exit+0x93/0xb0
   do_IRQ+0xa0/0x110
   common_interrupt+0xf/0xf
   </IRQ>

Given we're now almost identical to the existing debugging code which
correctly walks the list, combine with that.

Link: https://lkml.kernel.org/r/20191104170303.GA50361@gandi.net
Link: http://lkml.kernel.org/r/20191106222208.26815-1-labbott@redhat.com
Fixes: 1b7e816fc80e ("mm: slub: Fix slab walking for init_on_free")
	Signed-off-by: Laura Abbott <labbott@redhat.com>
	Reported-by: Thibaut Sautereau <thibaut.sautereau@clip-os.org>
	Acked-by: David Rientjes <rientjes@google.com>
	Tested-by: Alexander Potapenko <glider@google.com>
	Acked-by: Alexander Potapenko <glider@google.com>
	Cc: Kees Cook <keescook@chromium.org>
	Cc: "David S. Miller" <davem@davemloft.net>
	Cc: Vlastimil Babka <vbabka@suse.cz>
	Cc: <clipos@ssi.gouv.fr>
	Cc: Christoph Lameter <cl@linux.com>
	Cc: Pekka Enberg <penberg@kernel.org>
	Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
	Cc: <stable@vger.kernel.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit aea4df4c53f754cc229edde6c5465e481311cc49)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/slub.c
diff --cc mm/slub.c
index 135072f4c635,e72e802fc569..000000000000
--- a/mm/slub.c
+++ b/mm/slub.c
@@@ -1546,18 -1427,11 +1546,25 @@@ static __always_inline bool slab_free_h
  static inline bool slab_free_freelist_hook(struct kmem_cache *s,
  					   void **head, void **tail)
  {
++<<<<<<< HEAD
 +/*
 + * Compiler cannot detect this function can be removed if slab_free_hook()
 + * evaluates to nothing.  Thus, catch all relevant config debug options here.
 + */
 +#if defined(CONFIG_LOCKDEP)	||		\
 +	defined(CONFIG_DEBUG_KMEMLEAK) ||	\
 +	defined(CONFIG_DEBUG_OBJECTS_FREE) ||	\
 +	defined(CONFIG_KASAN)
++=======
++>>>>>>> aea4df4c53f7 (mm: slub: really fix slab walking for init_on_free)
  
  	void *object;
  	void *next = *head;
  	void *old_tail = *tail ? *tail : *head;
++<<<<<<< HEAD
++=======
+ 	int rsize;
++>>>>>>> aea4df4c53f7 (mm: slub: really fix slab walking for init_on_free)
  
  	/* Head and tail of the reconstructed freelist */
  	*head = NULL;
@@@ -1566,6 -1440,19 +1573,22 @@@
  	do {
  		object = next;
  		next = get_freepointer(s, object);
++<<<<<<< HEAD
++=======
+ 
+ 		if (slab_want_init_on_free(s)) {
+ 			/*
+ 			 * Clear the object and the metadata, but don't touch
+ 			 * the redzone.
+ 			 */
+ 			memset(object, 0, s->object_size);
+ 			rsize = (s->flags & SLAB_RED_ZONE) ? s->red_left_pad
+ 							   : 0;
+ 			memset((char *)object + s->inuse, 0,
+ 			       s->size - s->inuse - rsize);
+ 
+ 		}
++>>>>>>> aea4df4c53f7 (mm: slub: really fix slab walking for init_on_free)
  		/* If object's reuse doesn't have to be delayed */
  		if (!slab_free_hook(s, object)) {
  			/* Move object to the new freelist */
* Unmerged path mm/slub.c
