xfs: improve the xfs_dabuf_map calling conventions

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 199e9ba4e4a9927f5addb644c1a1e1002e68cc30
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/199e9ba4.failed

Use a flags argument with the XFS_DABUF_MAP_HOLE_OK flag to signal that
a hole is okay and not corruption, and return 0 with *nmap set to 0 to
signal that case in the return value instead of a nameless -1 return
code.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
	Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
(cherry picked from commit 199e9ba4e4a9927f5addb644c1a1e1002e68cc30)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/libxfs/xfs_da_btree.c
diff --cc fs/xfs/libxfs/xfs_da_btree.c
index b4bb7f36af89,4d582a327c12..000000000000
--- a/fs/xfs/libxfs/xfs_da_btree.c
+++ b/fs/xfs/libxfs/xfs_da_btree.c
@@@ -2467,129 -2460,77 +2467,160 @@@ xfs_da_shrink_inode
  	return error;
  }
  
++<<<<<<< HEAD
 +/*
 + * See if the mapping(s) for this btree block are valid, i.e.
 + * don't contain holes, are logically contiguous, and cover the whole range.
 + */
 +STATIC int
 +xfs_da_map_covers_blocks(
 +	int		nmap,
 +	xfs_bmbt_irec_t	*mapp,
 +	xfs_dablk_t	bno,
 +	int		count)
 +{
 +	int		i;
 +	xfs_fileoff_t	off;
 +
 +	for (i = 0, off = bno; i < nmap; i++) {
 +		if (mapp[i].br_startblock == HOLESTARTBLOCK ||
 +		    mapp[i].br_startblock == DELAYSTARTBLOCK) {
 +			return 0;
 +		}
 +		if (off != mapp[i].br_startoff) {
 +			return 0;
 +		}
 +		off += mapp[i].br_blockcount;
 +	}
 +	return off == bno + count;
 +}
 +
 +/*
 + * Convert a struct xfs_bmbt_irec to a struct xfs_buf_map.
 + *
 + * For the single map case, it is assumed that the caller has provided a pointer
 + * to a valid xfs_buf_map.  For the multiple map case, this function will
 + * allocate the xfs_buf_map to hold all the maps and replace the caller's single
 + * map pointer with the allocated map.
 + */
 +static int
 +xfs_buf_map_from_irec(
 +	struct xfs_mount	*mp,
 +	struct xfs_buf_map	**mapp,
 +	int			*nmaps,
 +	struct xfs_bmbt_irec	*irecs,
 +	int			nirecs)
 +{
 +	struct xfs_buf_map	*map;
 +	int			i;
 +
 +	ASSERT(*nmaps == 1);
 +	ASSERT(nirecs >= 1);
 +
 +	if (nirecs > 1) {
 +		map = kmem_zalloc(nirecs * sizeof(struct xfs_buf_map),
 +				  KM_NOFS);
 +		if (!map)
 +			return -ENOMEM;
 +		*mapp = map;
 +	}
 +
 +	*nmaps = nirecs;
 +	map = *mapp;
 +	for (i = 0; i < *nmaps; i++) {
 +		ASSERT(irecs[i].br_startblock != DELAYSTARTBLOCK &&
 +		       irecs[i].br_startblock != HOLESTARTBLOCK);
 +		map[i].bm_bn = XFS_FSB_TO_DADDR(mp, irecs[i].br_startblock);
 +		map[i].bm_len = XFS_FSB_TO_BB(mp, irecs[i].br_blockcount);
 +	}
 +	return 0;
 +}
 +
 +/*
 + * Map the block we are given ready for reading. There are three possible return
 + * values:
 + *	-1 - will be returned if we land in a hole and mappedbno == -2 so the
 + *	     caller knows not to execute a subsequent read.
 + *	 0 - if we mapped the block successfully
 + *	>0 - positive error number if there was an error.
 + */
++=======
++>>>>>>> 199e9ba4e4a9 (xfs: improve the xfs_dabuf_map calling conventions)
  static int
  xfs_dabuf_map(
  	struct xfs_inode	*dp,
  	xfs_dablk_t		bno,
- 	xfs_daddr_t		mappedbno,
+ 	unsigned int		flags,
  	int			whichfork,
 -	struct xfs_buf_map	**mapp,
 +	struct xfs_buf_map	**map,
  	int			*nmaps)
  {
  	struct xfs_mount	*mp = dp->i_mount;
  	int			nfsb = xfs_dabuf_nfsb(mp, whichfork);
 -	struct xfs_bmbt_irec	irec, *irecs = &irec;
 -	struct xfs_buf_map	*map = *mapp;
 -	xfs_fileoff_t		off = bno;
 -	int			error = 0, nirecs, i;
 +	int			error = 0;
 +	struct xfs_bmbt_irec	irec;
 +	struct xfs_bmbt_irec	*irecs = &irec;
 +	int			nirecs;
  
 -	if (nfsb > 1)
 -		irecs = kmem_zalloc(sizeof(irec) * nfsb, KM_NOFS);
 +	ASSERT(map && *map);
 +	ASSERT(*nmaps == 1);
  
 +	if (nfsb != 1)
 +		irecs = kmem_zalloc(sizeof(irec) * nfsb, KM_NOFS);
  	nirecs = nfsb;
 -	error = xfs_bmapi_read(dp, bno, nfsb, irecs, &nirecs,
 -			xfs_bmapi_aflag(whichfork));
 +	error = xfs_bmapi_read(dp, (xfs_fileoff_t)bno, nfsb, irecs,
 +			       &nirecs, xfs_bmapi_aflag(whichfork));
  	if (error)
 -		goto out_free_irecs;
 +		goto out;
  
 -	/*
 -	 * Use the caller provided map for the single map case, else allocate a
 -	 * larger one that needs to be free by the caller.
 -	 */
 -	if (nirecs > 1) {
 -		map = kmem_zalloc(nirecs * sizeof(struct xfs_buf_map), KM_NOFS);
 -		if (!map)
 -			goto out_free_irecs;
 -		*mapp = map;
 -	}
 +	if (!xfs_da_map_covers_blocks(nirecs, irecs, bno, nfsb)) {
 +		/* Caller ok with no mapping. */
 +		if (mappedbno == -2) {
 +			error = -1;
 +			goto out;
 +		}
  
++<<<<<<< HEAD
 +		/* Caller expected a mapping, so abort. */
++=======
+ 	for (i = 0; i < nirecs; i++) {
+ 		if (irecs[i].br_startblock == HOLESTARTBLOCK ||
+ 		    irecs[i].br_startblock == DELAYSTARTBLOCK)
+ 			goto invalid_mapping;
+ 		if (off != irecs[i].br_startoff)
+ 			goto invalid_mapping;
+ 
+ 		map[i].bm_bn = XFS_FSB_TO_DADDR(mp, irecs[i].br_startblock);
+ 		map[i].bm_len = XFS_FSB_TO_BB(mp, irecs[i].br_blockcount);
+ 		off += irecs[i].br_blockcount;
+ 	}
+ 
+ 	if (off != bno + nfsb)
+ 		goto invalid_mapping;
+ 
+ 	*nmaps = nirecs;
+ out_free_irecs:
+ 	if (irecs != &irec)
+ 		kmem_free(irecs);
+ 	return error;
+ 
+ invalid_mapping:
+ 	/* Caller ok with no mapping. */
+ 	if (XFS_IS_CORRUPT(mp, !(flags & XFS_DABUF_MAP_HOLE_OK))) {
+ 		error = -EFSCORRUPTED;
++>>>>>>> 199e9ba4e4a9 (xfs: improve the xfs_dabuf_map calling conventions)
  		if (xfs_error_level >= XFS_ERRLEVEL_LOW) {
 -			xfs_alert(mp, "%s: bno %u inode %llu",
 -					__func__, bno, dp->i_ino);
 +			int i;
  
 -			for (i = 0; i < nirecs; i++) {
 +			xfs_alert(mp, "%s: bno %lld dir: inode %lld", __func__,
 +					(long long)bno, (long long)dp->i_ino);
 +			for (i = 0; i < *nmaps; i++) {
  				xfs_alert(mp,
  "[%02d] br_startoff %lld br_startblock %lld br_blockcount %lld br_state %d",
 -					i, irecs[i].br_startoff,
 -					irecs[i].br_startblock,
 -					irecs[i].br_blockcount,
 +					i,
 +					(long long)irecs[i].br_startoff,
 +					(long long)irecs[i].br_startblock,
 +					(long long)irecs[i].br_blockcount,
  					irecs[i].br_state);
  			}
  		}
* Unmerged path fs/xfs/libxfs/xfs_da_btree.c
diff --git a/fs/xfs/libxfs/xfs_da_btree.h b/fs/xfs/libxfs/xfs_da_btree.h
index ed3b558a9c1a..64624d5717c9 100644
--- a/fs/xfs/libxfs/xfs_da_btree.h
+++ b/fs/xfs/libxfs/xfs_da_btree.h
@@ -194,6 +194,9 @@ int	xfs_da3_node_read(struct xfs_trans *tp, struct xfs_inode *dp,
 /*
  * Utility routines.
  */
+
+#define XFS_DABUF_MAP_HOLE_OK	(1 << 0)
+
 int	xfs_da_grow_inode(xfs_da_args_t *args, xfs_dablk_t *new_blkno);
 int	xfs_da_grow_inode_int(struct xfs_da_args *args, xfs_fileoff_t *bno,
 			      int count);
