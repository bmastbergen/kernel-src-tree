mm: rename free_area_init_node() to free_area_init_memoryless_node()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Mike Rapoport <rppt@linux.ibm.com>
commit bc9331a19d758706493cbebba67ca70382edddac
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/bc9331a1.failed

free_area_init_node() is only used by x86 to initialize a memory-less
nodes.  Make its name reflect this and drop all the function parameters
except node ID as they are anyway zero.

	Signed-off-by: Mike Rapoport <rppt@linux.ibm.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Tested-by: Hoan Tran <hoan@os.amperecomputing.com>	[arm64]
	Cc: Baoquan He <bhe@redhat.com>
	Cc: Brian Cain <bcain@codeaurora.org>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: "David S. Miller" <davem@davemloft.net>
	Cc: Geert Uytterhoeven <geert@linux-m68k.org>
	Cc: Greentime Hu <green.hu@gmail.com>
	Cc: Greg Ungerer <gerg@linux-m68k.org>
	Cc: Guan Xuetao <gxt@pku.edu.cn>
	Cc: Guo Ren <guoren@kernel.org>
	Cc: Heiko Carstens <heiko.carstens@de.ibm.com>
	Cc: Helge Deller <deller@gmx.de>
	Cc: "James E.J. Bottomley" <James.Bottomley@HansenPartnership.com>
	Cc: Jonathan Corbet <corbet@lwn.net>
	Cc: Ley Foon Tan <ley.foon.tan@intel.com>
	Cc: Mark Salter <msalter@redhat.com>
	Cc: Matt Turner <mattst88@gmail.com>
	Cc: Max Filippov <jcmvbkbc@gmail.com>
	Cc: Michael Ellerman <mpe@ellerman.id.au>
	Cc: Michal Hocko <mhocko@kernel.org>
	Cc: Michal Simek <monstr@monstr.eu>
	Cc: Nick Hu <nickhu@andestech.com>
	Cc: Paul Walmsley <paul.walmsley@sifive.com>
	Cc: Richard Weinberger <richard@nod.at>
	Cc: Rich Felker <dalias@libc.org>
	Cc: Russell King <linux@armlinux.org.uk>
	Cc: Stafford Horne <shorne@gmail.com>
	Cc: Thomas Bogendoerfer <tsbogend@alpha.franken.de>
	Cc: Tony Luck <tony.luck@intel.com>
	Cc: Vineet Gupta <vgupta@synopsys.com>
	Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
Link: http://lkml.kernel.org/r/20200412194859.12663-19-rppt@kernel.org
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit bc9331a19d758706493cbebba67ca70382edddac)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/mm.h
#	mm/page_alloc.c
diff --cc include/linux/mm.h
index c2872a52dcb3,0d998c84231c..000000000000
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@@ -1970,9 -2329,7 +1970,13 @@@ static inline spinlock_t *pud_lock(stru
  }
  
  extern void __init pagecache_init(void);
++<<<<<<< HEAD
 +extern void free_area_init(unsigned long * zones_size);
 +extern void free_area_init_node(int nid, unsigned long * zones_size,
 +		unsigned long zone_start_pfn, unsigned long *zholes_size);
++=======
+ extern void __init free_area_init_memoryless_node(int nid);
++>>>>>>> bc9331a19d75 (mm: rename free_area_init_node() to free_area_init_memoryless_node())
  extern void free_initmem(void);
  
  /*
@@@ -2042,13 -2399,10 +2046,19 @@@ static inline unsigned long get_num_phy
  	return phys_pages;
  }
  
 +#ifdef CONFIG_HAVE_MEMBLOCK_NODE_MAP
  /*
++<<<<<<< HEAD
 + * With CONFIG_HAVE_MEMBLOCK_NODE_MAP set, an architecture may initialise its
 + * zones, allocate the backing mem_map and account for memory holes in a more
 + * architecture independent manner. This is a substitute for creating the
 + * zone_sizes[] and zholes_size[] arrays and passing them to
 + * free_area_init_node()
++=======
+  * Using memblock node mappings, an architecture may initialise its
+  * zones, allocate the backing mem_map and account for memory holes in an
+  * architecture independent manner.
++>>>>>>> bc9331a19d75 (mm: rename free_area_init_node() to free_area_init_memoryless_node())
   *
   * An architecture is expected to register range of page frames backed by
   * physical memory with memblock_add[_node]() before calling
diff --cc mm/page_alloc.c
index f9684b405897,cc96ecbe52f7..000000000000
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@@ -6737,6 -6974,11 +6737,14 @@@ void __paginginit free_area_init_node(i
  	free_area_init_core(pgdat);
  }
  
++<<<<<<< HEAD
++=======
+ void __init free_area_init_memoryless_node(int nid)
+ {
+ 	__free_area_init_node(nid, NULL, 0, NULL, false);
+ }
+ 
++>>>>>>> bc9331a19d75 (mm: rename free_area_init_node() to free_area_init_memoryless_node())
  #if !defined(CONFIG_FLAT_NODE_MEM_MAP)
  /*
   * Initialize all valid struct pages in the range [spfn, epfn) and mark them
diff --git a/arch/x86/mm/numa.c b/arch/x86/mm/numa.c
index b1672ac8005d..b0a6b9b547d8 100644
--- a/arch/x86/mm/numa.c
+++ b/arch/x86/mm/numa.c
@@ -725,12 +725,9 @@ void __init x86_numa_init(void)
 
 static void __init init_memory_less_node(int nid)
 {
-	unsigned long zones_size[MAX_NR_ZONES] = {0};
-	unsigned long zholes_size[MAX_NR_ZONES] = {0};
-
 	/* Allocate and initialize node data. Memory-less node is now online.*/
 	alloc_node_data(nid);
-	free_area_init_node(nid, zones_size, 0, zholes_size);
+	free_area_init_memoryless_node(nid);
 
 	/*
 	 * All zonelists will be built later in start_kernel() after per cpu
* Unmerged path include/linux/mm.h
* Unmerged path mm/page_alloc.c
