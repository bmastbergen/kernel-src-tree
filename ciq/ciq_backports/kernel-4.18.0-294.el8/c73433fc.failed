arm64/cpufeature: Validate hypervisor capabilities during CPU hotplug

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
Rebuild_CHGLOG: - [arm64] cpufeature: Validate hypervisor capabilities during CPU hotplug (Auger Eric) [1882794]
Rebuild_FUZZ: 95.45%
commit-author Anshuman Khandual <anshuman.khandual@arm.com>
commit c73433fc630cda102f6527d4e5dfd289a9baec08
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/c73433fc.failed

This validates hypervisor capabilities like VMID width, IPA range for any
hot plug CPU against system finalized values. KVM's view of the IPA space
is used while allowing a given CPU to come up. While here, it factors out
get_vmid_bits() for general use.

	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Will Deacon <will@kernel.org>
	Cc: Marc Zyngier <maz@kernel.org>
	Cc: Mark Rutland <mark.rutland@arm.com>
	Cc: James Morse <james.morse@arm.com>
	Cc: Suzuki K Poulose <suzuki.poulose@arm.com>
	Cc: linux-arm-kernel@lists.infradead.org
	Cc: kvmarm@lists.cs.columbia.edu
	Cc: linux-kernel@vger.kernel.org

	Suggested-by: Suzuki Poulose <suzuki.poulose@arm.com>
	Signed-off-by: Anshuman Khandual <anshuman.khandual@arm.com>
	Reviewed-by: Marc Zyngier <maz@kernel.org>
Link: https://lore.kernel.org/r/1589248647-22925-1-git-send-email-anshuman.khandual@arm.com
	Signed-off-by: Will Deacon <will@kernel.org>
(cherry picked from commit c73433fc630cda102f6527d4e5dfd289a9baec08)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/cpufeature.h
diff --cc arch/arm64/include/asm/cpufeature.h
index 970b7ff7af55,928814d35669..000000000000
--- a/arch/arm64/include/asm/cpufeature.h
+++ b/arch/arm64/include/asm/cpufeature.h
@@@ -695,6 -733,43 +695,46 @@@ static inline u32 id_aa64mmfr0_parange_
  	default: return CONFIG_ARM64_PA_BITS;
  	}
  }
++<<<<<<< HEAD
++=======
+ 
+ /* Check whether hardware update of the Access flag is supported */
+ static inline bool cpu_has_hw_af(void)
+ {
+ 	u64 mmfr1;
+ 
+ 	if (!IS_ENABLED(CONFIG_ARM64_HW_AFDBM))
+ 		return false;
+ 
+ 	mmfr1 = read_cpuid(ID_AA64MMFR1_EL1);
+ 	return cpuid_feature_extract_unsigned_field(mmfr1,
+ 						ID_AA64MMFR1_HADBS_SHIFT);
+ }
+ 
+ #ifdef CONFIG_ARM64_AMU_EXTN
+ /* Check whether the cpu supports the Activity Monitors Unit (AMU) */
+ extern bool cpu_has_amu_feat(int cpu);
+ #endif
+ 
+ static inline unsigned int get_vmid_bits(u64 mmfr1)
+ {
+ 	int vmid_bits;
+ 
+ 	vmid_bits = cpuid_feature_extract_unsigned_field(mmfr1,
+ 						ID_AA64MMFR1_VMIDBITS_SHIFT);
+ 	if (vmid_bits == ID_AA64MMFR1_VMIDBITS_16)
+ 		return 16;
+ 
+ 	/*
+ 	 * Return the default here even if any reserved
+ 	 * value is fetched from the system register.
+ 	 */
+ 	return 8;
+ }
+ 
+ u32 get_kvm_ipa_limit(void);
+ 
++>>>>>>> c73433fc630c (arm64/cpufeature: Validate hypervisor capabilities during CPU hotplug)
  #endif /* __ASSEMBLY__ */
  
  #endif
* Unmerged path arch/arm64/include/asm/cpufeature.h
diff --git a/arch/arm64/include/asm/kvm_mmu.h b/arch/arm64/include/asm/kvm_mmu.h
index 76a8a207324d..46fe2ab9fa65 100644
--- a/arch/arm64/include/asm/kvm_mmu.h
+++ b/arch/arm64/include/asm/kvm_mmu.h
@@ -405,7 +405,7 @@ static inline unsigned int kvm_get_vmid_bits(void)
 {
 	int reg = read_sanitised_ftr_reg(SYS_ID_AA64MMFR1_EL1);
 
-	return (cpuid_feature_extract_unsigned_field(reg, ID_AA64MMFR1_VMIDBITS_SHIFT) == 2) ? 16 : 8;
+	return get_vmid_bits(reg);
 }
 
 /*
diff --git a/arch/arm64/kernel/cpufeature.c b/arch/arm64/kernel/cpufeature.c
index bd7dd6afa10c..a62445cab102 100644
--- a/arch/arm64/kernel/cpufeature.c
+++ b/arch/arm64/kernel/cpufeature.c
@@ -1923,6 +1923,35 @@ static void verify_sve_features(void)
 	/* Add checks on other ZCR bits here if necessary */
 }
 
+static void verify_hyp_capabilities(void)
+{
+	u64 safe_mmfr1, mmfr0, mmfr1;
+	int parange, ipa_max;
+	unsigned int safe_vmid_bits, vmid_bits;
+
+	if (!IS_ENABLED(CONFIG_KVM) || !IS_ENABLED(CONFIG_KVM_ARM_HOST))
+		return;
+
+	safe_mmfr1 = read_sanitised_ftr_reg(SYS_ID_AA64MMFR1_EL1);
+	mmfr0 = read_cpuid(ID_AA64MMFR0_EL1);
+	mmfr1 = read_cpuid(ID_AA64MMFR1_EL1);
+
+	/* Verify VMID bits */
+	safe_vmid_bits = get_vmid_bits(safe_mmfr1);
+	vmid_bits = get_vmid_bits(mmfr1);
+	if (vmid_bits < safe_vmid_bits) {
+		pr_crit("CPU%d: VMID width mismatch\n", smp_processor_id());
+		cpu_die_early();
+	}
+
+	/* Verify IPA range */
+	parange = mmfr0 & 0x7;
+	ipa_max = id_aa64mmfr0_parange_to_phys_shift(parange);
+	if (ipa_max < get_kvm_ipa_limit()) {
+		pr_crit("CPU%d: IPA range mismatch\n", smp_processor_id());
+		cpu_die_early();
+	}
+}
 
 /*
  * Run through the enabled system capabilities and enable() it on this CPU.
@@ -1949,6 +1978,9 @@ static void verify_local_cpu_capabilities(void)
 
 	if (system_supports_sve())
 		verify_sve_features();
+
+	if (is_hyp_mode_available())
+		verify_hyp_capabilities();
 }
 
 void check_local_cpu_capabilities(void)
diff --git a/arch/arm64/kvm/reset.c b/arch/arm64/kvm/reset.c
index 33f4aee10da3..90146fb32518 100644
--- a/arch/arm64/kvm/reset.c
+++ b/arch/arm64/kvm/reset.c
@@ -344,6 +344,11 @@ int kvm_reset_vcpu(struct kvm_vcpu *vcpu)
 	return ret;
 }
 
+u32 get_kvm_ipa_limit(void)
+{
+	return kvm_ipa_limit;
+}
+
 void kvm_set_ipa_limit(void)
 {
 	unsigned int ipa_max, pa_max, va_max, parange;
