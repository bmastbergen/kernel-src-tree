block: add a blk_account_io_merge_bio helper

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
commit b5af37ab3a2b143e278340d2c6fa5790d53817e7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/b5af37ab.failed

Move the non-"new_io" branch of blk_account_io_start() into separate
function.  Fix merge accounting for discards (they were counted as write
merges).

The new blk_account_io_merge_bio() doesn't call update_io_ticks() unlike
blk_account_io_start(), as there is no reason for that.

[hch: rebased]

	Signed-off-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit b5af37ab3a2b143e278340d2c6fa5790d53817e7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-core.c
diff --cc block/blk-core.c
index 9aabbc020a34,bf2f7d4bc0c1..000000000000
--- a/block/blk-core.c
+++ b/block/blk-core.c
@@@ -614,8 -636,18 +614,23 @@@ void blk_put_request(struct request *re
  }
  EXPORT_SYMBOL(blk_put_request);
  
++<<<<<<< HEAD
 +bool bio_attempt_back_merge(struct request_queue *q, struct request *req,
 +			    struct bio *bio)
++=======
+ static void blk_account_io_merge_bio(struct request *req)
+ {
+ 	if (!blk_do_io_stat(req))
+ 		return;
+ 
+ 	part_stat_lock();
+ 	part_stat_inc(req->part, merges[op_stat_group(req_op(req))]);
+ 	part_stat_unlock();
+ }
+ 
+ bool bio_attempt_back_merge(struct request *req, struct bio *bio,
+ 		unsigned int nr_segs)
++>>>>>>> b5af37ab3a2b (block: add a blk_account_io_merge_bio helper)
  {
  	const int ff = bio->bi_opf & REQ_FAILFAST_MASK;
  
@@@ -632,7 -664,9 +647,13 @@@
  	req->biotail = bio;
  	req->__data_len += bio->bi_iter.bi_size;
  
++<<<<<<< HEAD
 +	blk_account_io_start(req, false);
++=======
+ 	bio_crypt_free_ctx(bio);
+ 
+ 	blk_account_io_merge_bio(req);
++>>>>>>> b5af37ab3a2b (block: add a blk_account_io_merge_bio helper)
  	return true;
  }
  
@@@ -656,7 -690,9 +677,13 @@@ bool bio_attempt_front_merge(struct req
  	req->__sector = bio->bi_iter.bi_sector;
  	req->__data_len += bio->bi_iter.bi_size;
  
++<<<<<<< HEAD
 +	blk_account_io_start(req, false);
++=======
+ 	bio_crypt_do_front_merge(req, bio);
+ 
+ 	blk_account_io_merge_bio(req);
++>>>>>>> b5af37ab3a2b (block: add a blk_account_io_merge_bio helper)
  	return true;
  }
  
@@@ -1239,8 -1335,11 +1266,8 @@@ blk_status_t blk_insert_cloned_request(
  	    should_fail_request(&rq->rq_disk->part0, blk_rq_bytes(rq)))
  		return BLK_STS_IOERR;
  
 -	if (blk_crypto_insert_cloned_request(rq))
 -		return BLK_STS_IOERR;
 -
  	if (blk_queue_io_stat(q))
- 		blk_account_io_start(rq, true);
+ 		blk_account_io_start(rq);
  
  	/*
  	 * Since we have a scheduler attached on the top device,
@@@ -1331,29 -1443,50 +1358,34 @@@ void blk_account_io_done(struct reques
  	}
  }
  
- void blk_account_io_start(struct request *rq, bool new_io)
+ void blk_account_io_start(struct request *rq)
  {
 +	struct hd_struct *part;
 +	int rw = rq_data_dir(rq);
 +
  	if (!blk_do_io_stat(rq))
  		return;
  
  	part_stat_lock();
 -	rq->part = disk_map_sector_rcu(rq->rq_disk, blk_rq_pos(rq));
 -	update_io_ticks(rq->part, jiffies, false);
 -	part_stat_unlock();
 -}
 -
 -unsigned long disk_start_io_acct(struct gendisk *disk, unsigned int sectors,
 -		unsigned int op)
 -{
 -	struct hd_struct *part = &disk->part0;
 -	const int sgrp = op_stat_group(op);
 -	unsigned long now = READ_ONCE(jiffies);
 -
 -	part_stat_lock();
 -	update_io_ticks(part, now, false);
 -	part_stat_inc(part, ios[sgrp]);
 -	part_stat_add(part, sectors[sgrp], sectors);
 -	part_stat_local_inc(part, in_flight[op_is_write(op)]);
 -	part_stat_unlock();
++<<<<<<< HEAD
  
 -	return now;
 -}
 -EXPORT_SYMBOL(disk_start_io_acct);
 +	if (!new_io) {
 +		part = rq->part;
 +		part_stat_inc(part, merges[rw]);
 +	} else {
 +		part = disk_map_sector_rcu(rq->rq_disk, blk_rq_pos(rq));
 +		part_inc_in_flight(rq->q, part, rw);
 +		rq->part = part;
 +	}
  
 -void disk_end_io_acct(struct gendisk *disk, unsigned int op,
 -		unsigned long start_time)
 -{
 -	struct hd_struct *part = &disk->part0;
 -	const int sgrp = op_stat_group(op);
 -	unsigned long now = READ_ONCE(jiffies);
 -	unsigned long duration = now - start_time;
 +	update_io_ticks(part, jiffies, false);
  
 -	part_stat_lock();
 -	update_io_ticks(part, now, true);
 -	part_stat_add(part, nsecs[sgrp], jiffies_to_nsecs(duration));
 -	part_stat_local_dec(part, in_flight[op_is_write(op)]);
++=======
++	rq->part = disk_map_sector_rcu(rq->rq_disk, blk_rq_pos(rq));
++	update_io_ticks(rq->part, jiffies, false);
++>>>>>>> b5af37ab3a2b (block: add a blk_account_io_merge_bio helper)
  	part_stat_unlock();
  }
 -EXPORT_SYMBOL(disk_end_io_acct);
  
  /*
   * Steal bios from a request and add them to a bio list.
* Unmerged path block/blk-core.c
diff --git a/block/blk-exec.c b/block/blk-exec.c
index 466eafc9af80..8e3f135ea760 100644
--- a/block/blk-exec.c
+++ b/block/blk-exec.c
@@ -54,7 +54,7 @@ void blk_execute_rq_nowait(struct request_queue *q, struct gendisk *bd_disk,
 	rq->rq_disk = bd_disk;
 	rq->end_io = done;
 
-	blk_account_io_start(rq, true);
+	blk_account_io_start(rq);
 
 	/*
 	 * don't check dying flag for MQ because the request won't
diff --git a/block/blk-mq.c b/block/blk-mq.c
index 9ae50b6aa4f6..a5ba185599e4 100644
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@ -1822,7 +1822,7 @@ static void blk_mq_bio_to_request(struct request *rq, struct bio *bio)
 	rq->write_hint = bio->bi_write_hint;
 	blk_rq_bio_prep(rq->q, rq, bio);
 
-	blk_account_io_start(rq, true);
+	blk_account_io_start(rq);
 }
 
 static blk_status_t __blk_mq_issue_directly(struct blk_mq_hw_ctx *hctx,
diff --git a/block/blk.h b/block/blk.h
index cc930ffd7656..82efb4309543 100644
--- a/block/blk.h
+++ b/block/blk.h
@@ -174,7 +174,7 @@ bool bio_attempt_discard_merge(struct request_queue *q, struct request *req,
 bool blk_attempt_plug_merge(struct request_queue *q, struct bio *bio,
 			    struct request **same_queue_rq);
 
-void blk_account_io_start(struct request *req, bool new_io);
+void blk_account_io_start(struct request *req);
 void blk_account_io_done(struct request *req, u64 now);
 
 /*
