nvme: only use power of two io boundaries

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Keith Busch <kbusch@kernel.org>
commit e83d776f9f98b4af18d67f05f9d1f3042dbe62c7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/e83d776f.failed

The kernel requires a power of two for boundaries because that's the
only way it can efficiently split commands that cross them. A
controller, however, may report a non-power of two boundary.

The driver had been rounding the controller's value to one the kernel
can use, but splitting on the wrong boundary provides no benefit on the
device side, and incurs additional submission overhead from non-optimal
splits.

Don't provide any boundary hint if the controller's value can't be used
and log a warning when first scanning a disk's unreported IO boundary.
Since the chunk sector logic has grown, move it to a separate function.

	Cc: Martin K. Petersen <martin.petersen@oracle.com>
	Signed-off-by: Keith Busch <kbusch@kernel.org>
	Reviewed-by: Martin K. Petersen <martin.petersen@oracle.com>
	Signed-off-by: Sagi Grimberg <sagi@grimberg.me>
(cherry picked from commit e83d776f9f98b4af18d67f05f9d1f3042dbe62c7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/core.c
diff --cc drivers/nvme/host/core.c
index c05e996ebc7d,5702a3843746..000000000000
--- a/drivers/nvme/host/core.c
+++ b/drivers/nvme/host/core.c
@@@ -1971,10 -2026,49 +1971,56 @@@ static void nvme_update_disk_info(struc
  	blk_mq_unfreeze_queue(disk->queue);
  }
  
++<<<<<<< HEAD
 +static void __nvme_revalidate_disk(struct gendisk *disk, struct nvme_id_ns *id)
++=======
+ static inline bool nvme_first_scan(struct gendisk *disk)
+ {
+ 	/* nvme_alloc_ns() scans the disk prior to adding it */
+ 	return !(disk->flags & GENHD_FL_UP);
+ }
+ 
+ static void nvme_set_chunk_sectors(struct nvme_ns *ns, struct nvme_id_ns *id)
+ {
+ 	struct nvme_ctrl *ctrl = ns->ctrl;
+ 	u32 iob;
+ 
+ 	if ((ctrl->quirks & NVME_QUIRK_STRIPE_SIZE) &&
+ 	    is_power_of_2(ctrl->max_hw_sectors))
+ 		iob = ctrl->max_hw_sectors;
+ 	else
+ 		iob = nvme_lba_to_sect(ns, le16_to_cpu(id->noiob));
+ 
+ 	if (!iob)
+ 		return;
+ 
+ 	if (!is_power_of_2(iob)) {
+ 		if (nvme_first_scan(ns->disk))
+ 			pr_warn("%s: ignoring unaligned IO boundary:%u\n",
+ 				ns->disk->disk_name, iob);
+ 		return;
+ 	}
+ 
+ 	if (blk_queue_is_zoned(ns->disk->queue)) {
+ 		if (nvme_first_scan(ns->disk))
+ 			pr_warn("%s: ignoring zoned namespace IO boundary\n",
+ 				ns->disk->disk_name);
+ 		return;
+ 	}
+ 
+ 	blk_queue_chunk_sectors(ns->queue, iob);
+ }
+ 
+ static int __nvme_revalidate_disk(struct gendisk *disk, struct nvme_id_ns *id)
++>>>>>>> e83d776f9f98 (nvme: only use power of two io boundaries)
  {
 -	unsigned lbaf = id->flbas & NVME_NS_FLBAS_LBA_MASK;
  	struct nvme_ns *ns = disk->private_data;
++<<<<<<< HEAD
 +	u32 iob;
++=======
+ 	struct nvme_ctrl *ctrl = ns->ctrl;
+ 	int ret;
++>>>>>>> e83d776f9f98 (nvme: only use power of two io boundaries)
  
  	/*
  	 * If identify namespace failed, use default 512 byte block size so
@@@ -1984,22 -2078,56 +2030,72 @@@
  	if (ns->lba_shift == 0)
  		ns->lba_shift = 9;
  
++<<<<<<< HEAD
 +	if ((ns->ctrl->quirks & NVME_QUIRK_STRIPE_SIZE) &&
 +	    is_power_of_2(ns->ctrl->max_hw_sectors))
 +		iob = ns->ctrl->max_hw_sectors;
 +	else
 +		iob = nvme_lba_to_sect(ns, le16_to_cpu(id->noiob));
 +
 +	ns->ms = le16_to_cpu(id->lbaf[id->flbas & NVME_NS_FLBAS_LBA_MASK].ms);
 +	ns->ext = ns->ms && (id->flbas & NVME_NS_FLBAS_META_EXT);
++=======
+ 	switch (ns->head->ids.csi) {
+ 	case NVME_CSI_NVM:
+ 		break;
+ 	case NVME_CSI_ZNS:
+ 		ret = nvme_update_zone_info(disk, ns, lbaf);
+ 		if (ret) {
+ 			dev_warn(ctrl->device,
+ 				"failed to add zoned namespace:%u ret:%d\n",
+ 				ns->head->ns_id, ret);
+ 			return ret;
+ 		}
+ 		break;
+ 	default:
+ 		dev_warn(ctrl->device, "unknown csi:%u ns:%u\n",
+ 			ns->head->ids.csi, ns->head->ns_id);
+ 		return -ENODEV;
+ 	}
+ 
+ 	ns->features = 0;
+ 	ns->ms = le16_to_cpu(id->lbaf[lbaf].ms);
++>>>>>>> e83d776f9f98 (nvme: only use power of two io boundaries)
  	/* the PI implementation requires metadata equal t10 pi tuple size */
  	if (ns->ms == sizeof(struct t10_pi_tuple))
  		ns->pi_type = id->dps & NVME_NS_DPS_PI_MASK;
  	else
  		ns->pi_type = 0;
  
++<<<<<<< HEAD
 +	if (iob)
 +		blk_queue_chunk_sectors(ns->queue, rounddown_pow_of_two(iob));
++=======
+ 	if (ns->ms) {
+ 		/*
+ 		 * For PCIe only the separate metadata pointer is supported,
+ 		 * as the block layer supplies metadata in a separate bio_vec
+ 		 * chain. For Fabrics, only metadata as part of extended data
+ 		 * LBA is supported on the wire per the Fabrics specification,
+ 		 * but the HBA/HCA will do the remapping from the separate
+ 		 * metadata buffers for us.
+ 		 */
+ 		if (id->flbas & NVME_NS_FLBAS_META_EXT) {
+ 			ns->features |= NVME_NS_EXT_LBAS;
+ 			if ((ctrl->ops->flags & NVME_F_FABRICS) &&
+ 			    (ctrl->ops->flags & NVME_F_METADATA_SUPPORTED) &&
+ 			    ctrl->max_integrity_segments)
+ 				ns->features |= NVME_NS_METADATA_SUPPORTED;
+ 		} else {
+ 			if (WARN_ON_ONCE(ctrl->ops->flags & NVME_F_FABRICS))
+ 				return -EINVAL;
+ 			if (ctrl->ops->flags & NVME_F_METADATA_SUPPORTED)
+ 				ns->features |= NVME_NS_METADATA_SUPPORTED;
+ 		}
+ 	}
+ 
+ 	nvme_set_chunk_sectors(ns, id);
++>>>>>>> e83d776f9f98 (nvme: only use power of two io boundaries)
  	nvme_update_disk_info(disk, ns, id);
  #ifdef CONFIG_NVME_MULTIPATH
  	if (ns->head->disk) {
* Unmerged path drivers/nvme/host/core.c
