netfilter: use actual socket sk rather than skb sk when routing harder

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Jason A. Donenfeld <Jason@zx2c4.com>
commit 46d6c5ae953cc0be38efd0e469284df7c4328cf8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/46d6c5ae.failed

If netfilter changes the packet mark when mangling, the packet is
rerouted using the route_me_harder set of functions. Prior to this
commit, there's one big difference between route_me_harder and the
ordinary initial routing functions, described in the comment above
__ip_queue_xmit():

   /* Note: skb->sk can be different from sk, in case of tunnels */
   int __ip_queue_xmit(struct sock *sk, struct sk_buff *skb, struct flowi *fl,

That function goes on to correctly make use of sk->sk_bound_dev_if,
rather than skb->sk->sk_bound_dev_if. And indeed the comment is true: a
tunnel will receive a packet in ndo_start_xmit with an initial skb->sk.
It will make some transformations to that packet, and then it will send
the encapsulated packet out of a *new* socket. That new socket will
basically always have a different sk_bound_dev_if (otherwise there'd be
a routing loop). So for the purposes of routing the encapsulated packet,
the routing information as it pertains to the socket should come from
that socket's sk, rather than the packet's original skb->sk. For that
reason __ip_queue_xmit() and related functions all do the right thing.

One might argue that all tunnels should just call skb_orphan(skb) before
transmitting the encapsulated packet into the new socket. But tunnels do
*not* do this -- and this is wisely avoided in skb_scrub_packet() too --
because features like TSQ rely on skb->destructor() being called when
that buffer space is truely available again. Calling skb_orphan(skb) too
early would result in buffers filling up unnecessarily and accounting
info being all wrong. Instead, additional routing must take into account
the new sk, just as __ip_queue_xmit() notes.

So, this commit addresses the problem by fishing the correct sk out of
state->sk -- it's already set properly in the call to nf_hook() in
__ip_local_out(), which receives the sk as part of its normal
functionality. So we make sure to plumb state->sk through the various
route_me_harder functions, and then make correct use of it following the
example of __ip_queue_xmit().

Fixes: 1da177e4c3f4 ("Linux-2.6.12-rc2")
	Signed-off-by: Jason A. Donenfeld <Jason@zx2c4.com>
	Reviewed-by: Florian Westphal <fw@strlen.de>
	Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
(cherry picked from commit 46d6c5ae953cc0be38efd0e469284df7c4328cf8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/netfilter_ipv6.h
#	net/netfilter/nf_synproxy_core.c
diff --cc include/linux/netfilter_ipv6.h
index 12113e502656,48314ade1506..000000000000
--- a/include/linux/netfilter_ipv6.h
+++ b/include/linux/netfilter_ipv6.h
@@@ -86,9 -114,38 +86,42 @@@ static inline int nf_ip6_route(struct n
  #endif
  }
  
++<<<<<<< HEAD
 +int ip6_route_me_harder(struct net *net, struct sk_buff *skb);
++=======
+ #include <net/netfilter/ipv6/nf_defrag_ipv6.h>
+ 
+ int br_ip6_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,
+ 		    struct nf_bridge_frag_data *data,
+ 		    int (*output)(struct net *, struct sock *sk,
+ 				  const struct nf_bridge_frag_data *data,
+ 				  struct sk_buff *));
+ 
+ static inline int nf_br_ip6_fragment(struct net *net, struct sock *sk,
+ 				     struct sk_buff *skb,
+ 				     struct nf_bridge_frag_data *data,
+ 				     int (*output)(struct net *, struct sock *sk,
+ 						   const struct nf_bridge_frag_data *data,
+ 						   struct sk_buff *))
+ {
+ #if IS_MODULE(CONFIG_IPV6)
+ 	const struct nf_ipv6_ops *v6_ops = nf_get_ipv6_ops();
+ 
+ 	if (!v6_ops)
+ 		return 1;
+ 
+ 	return v6_ops->br_fragment(net, sk, skb, data, output);
+ #elif IS_BUILTIN(CONFIG_IPV6)
+ 	return br_ip6_fragment(net, sk, skb, data, output);
+ #else
+ 	return 1;
+ #endif
+ }
+ 
+ int ip6_route_me_harder(struct net *net, struct sock *sk, struct sk_buff *skb);
++>>>>>>> 46d6c5ae953c (netfilter: use actual socket sk rather than skb sk when routing harder)
  
- static inline int nf_ip6_route_me_harder(struct net *net, struct sk_buff *skb)
+ static inline int nf_ip6_route_me_harder(struct net *net, struct sock *sk, struct sk_buff *skb)
  {
  #if IS_MODULE(CONFIG_IPV6)
  	const struct nf_ipv6_ops *v6_ops = nf_get_ipv6_ops();
@@@ -96,10 -153,45 +129,16 @@@
  	if (!v6_ops)
  		return -EHOSTUNREACH;
  
++<<<<<<< HEAD
 +	return v6_ops->route_me_harder(net, skb);
++=======
+ 	return v6_ops->route_me_harder(net, sk, skb);
+ #elif IS_BUILTIN(CONFIG_IPV6)
+ 	return ip6_route_me_harder(net, sk, skb);
++>>>>>>> 46d6c5ae953c (netfilter: use actual socket sk rather than skb sk when routing harder)
  #else
 -	return -EHOSTUNREACH;
 -#endif
 -}
 -
 -static inline u32 nf_ipv6_cookie_init_sequence(const struct ipv6hdr *iph,
 -					       const struct tcphdr *th,
 -					       u16 *mssp)
 -{
 -#if IS_ENABLED(CONFIG_SYN_COOKIES)
 -#if IS_MODULE(CONFIG_IPV6)
 -	const struct nf_ipv6_ops *v6_ops = nf_get_ipv6_ops();
 -
 -	if (v6_ops)
 -		return v6_ops->cookie_init_sequence(iph, th, mssp);
 -#elif IS_BUILTIN(CONFIG_IPV6)
 -	return __cookie_v6_init_sequence(iph, th, mssp);
 -#endif
 -#endif
 -	return 0;
 -}
 -
 -static inline int nf_cookie_v6_check(const struct ipv6hdr *iph,
 -				     const struct tcphdr *th, __u32 cookie)
 -{
 -#if IS_ENABLED(CONFIG_SYN_COOKIES)
 -#if IS_MODULE(CONFIG_IPV6)
 -	const struct nf_ipv6_ops *v6_ops = nf_get_ipv6_ops();
 -
 -	if (v6_ops)
 -		return v6_ops->cookie_v6_check(iph, th, cookie);
 -#elif IS_BUILTIN(CONFIG_IPV6)
 -	return __cookie_v6_check(iph, th, cookie);
 -#endif
 +	return ip6_route_me_harder(net, skb);
  #endif
 -	return 0;
  }
  
  __sum16 nf_ip6_checksum(struct sk_buff *skb, unsigned int hook,
diff --cc net/netfilter/nf_synproxy_core.c
index 8ff4d22f10b2,d7d34a62d3bf..000000000000
--- a/net/netfilter/nf_synproxy_core.c
+++ b/net/netfilter/nf_synproxy_core.c
@@@ -416,5 -410,829 +416,831 @@@ static void __exit synproxy_core_exit(v
  module_init(synproxy_core_init);
  module_exit(synproxy_core_exit);
  
++<<<<<<< HEAD
++=======
+ static struct iphdr *
+ synproxy_build_ip(struct net *net, struct sk_buff *skb, __be32 saddr,
+ 		  __be32 daddr)
+ {
+ 	struct iphdr *iph;
+ 
+ 	skb_reset_network_header(skb);
+ 	iph = skb_put(skb, sizeof(*iph));
+ 	iph->version	= 4;
+ 	iph->ihl	= sizeof(*iph) / 4;
+ 	iph->tos	= 0;
+ 	iph->id		= 0;
+ 	iph->frag_off	= htons(IP_DF);
+ 	iph->ttl	= net->ipv4.sysctl_ip_default_ttl;
+ 	iph->protocol	= IPPROTO_TCP;
+ 	iph->check	= 0;
+ 	iph->saddr	= saddr;
+ 	iph->daddr	= daddr;
+ 
+ 	return iph;
+ }
+ 
+ static void
+ synproxy_send_tcp(struct net *net,
+ 		  const struct sk_buff *skb, struct sk_buff *nskb,
+ 		  struct nf_conntrack *nfct, enum ip_conntrack_info ctinfo,
+ 		  struct iphdr *niph, struct tcphdr *nth,
+ 		  unsigned int tcp_hdr_size)
+ {
+ 	nth->check = ~tcp_v4_check(tcp_hdr_size, niph->saddr, niph->daddr, 0);
+ 	nskb->ip_summed   = CHECKSUM_PARTIAL;
+ 	nskb->csum_start  = (unsigned char *)nth - nskb->head;
+ 	nskb->csum_offset = offsetof(struct tcphdr, check);
+ 
+ 	skb_dst_set_noref(nskb, skb_dst(skb));
+ 	nskb->protocol = htons(ETH_P_IP);
+ 	if (ip_route_me_harder(net, nskb->sk, nskb, RTN_UNSPEC))
+ 		goto free_nskb;
+ 
+ 	if (nfct) {
+ 		nf_ct_set(nskb, (struct nf_conn *)nfct, ctinfo);
+ 		nf_conntrack_get(nfct);
+ 	}
+ 
+ 	ip_local_out(net, nskb->sk, nskb);
+ 	return;
+ 
+ free_nskb:
+ 	kfree_skb(nskb);
+ }
+ 
+ void
+ synproxy_send_client_synack(struct net *net,
+ 			    const struct sk_buff *skb, const struct tcphdr *th,
+ 			    const struct synproxy_options *opts)
+ {
+ 	struct sk_buff *nskb;
+ 	struct iphdr *iph, *niph;
+ 	struct tcphdr *nth;
+ 	unsigned int tcp_hdr_size;
+ 	u16 mss = opts->mss_encode;
+ 
+ 	iph = ip_hdr(skb);
+ 
+ 	tcp_hdr_size = sizeof(*nth) + synproxy_options_size(opts);
+ 	nskb = alloc_skb(sizeof(*niph) + tcp_hdr_size + MAX_TCP_HEADER,
+ 			 GFP_ATOMIC);
+ 	if (!nskb)
+ 		return;
+ 	skb_reserve(nskb, MAX_TCP_HEADER);
+ 
+ 	niph = synproxy_build_ip(net, nskb, iph->daddr, iph->saddr);
+ 
+ 	skb_reset_transport_header(nskb);
+ 	nth = skb_put(nskb, tcp_hdr_size);
+ 	nth->source	= th->dest;
+ 	nth->dest	= th->source;
+ 	nth->seq	= htonl(__cookie_v4_init_sequence(iph, th, &mss));
+ 	nth->ack_seq	= htonl(ntohl(th->seq) + 1);
+ 	tcp_flag_word(nth) = TCP_FLAG_SYN | TCP_FLAG_ACK;
+ 	if (opts->options & NF_SYNPROXY_OPT_ECN)
+ 		tcp_flag_word(nth) |= TCP_FLAG_ECE;
+ 	nth->doff	= tcp_hdr_size / 4;
+ 	nth->window	= 0;
+ 	nth->check	= 0;
+ 	nth->urg_ptr	= 0;
+ 
+ 	synproxy_build_options(nth, opts);
+ 
+ 	synproxy_send_tcp(net, skb, nskb, skb_nfct(skb),
+ 			  IP_CT_ESTABLISHED_REPLY, niph, nth, tcp_hdr_size);
+ }
+ EXPORT_SYMBOL_GPL(synproxy_send_client_synack);
+ 
+ static void
+ synproxy_send_server_syn(struct net *net,
+ 			 const struct sk_buff *skb, const struct tcphdr *th,
+ 			 const struct synproxy_options *opts, u32 recv_seq)
+ {
+ 	struct synproxy_net *snet = synproxy_pernet(net);
+ 	struct sk_buff *nskb;
+ 	struct iphdr *iph, *niph;
+ 	struct tcphdr *nth;
+ 	unsigned int tcp_hdr_size;
+ 
+ 	iph = ip_hdr(skb);
+ 
+ 	tcp_hdr_size = sizeof(*nth) + synproxy_options_size(opts);
+ 	nskb = alloc_skb(sizeof(*niph) + tcp_hdr_size + MAX_TCP_HEADER,
+ 			 GFP_ATOMIC);
+ 	if (!nskb)
+ 		return;
+ 	skb_reserve(nskb, MAX_TCP_HEADER);
+ 
+ 	niph = synproxy_build_ip(net, nskb, iph->saddr, iph->daddr);
+ 
+ 	skb_reset_transport_header(nskb);
+ 	nth = skb_put(nskb, tcp_hdr_size);
+ 	nth->source	= th->source;
+ 	nth->dest	= th->dest;
+ 	nth->seq	= htonl(recv_seq - 1);
+ 	/* ack_seq is used to relay our ISN to the synproxy hook to initialize
+ 	 * sequence number translation once a connection tracking entry exists.
+ 	 */
+ 	nth->ack_seq	= htonl(ntohl(th->ack_seq) - 1);
+ 	tcp_flag_word(nth) = TCP_FLAG_SYN;
+ 	if (opts->options & NF_SYNPROXY_OPT_ECN)
+ 		tcp_flag_word(nth) |= TCP_FLAG_ECE | TCP_FLAG_CWR;
+ 	nth->doff	= tcp_hdr_size / 4;
+ 	nth->window	= th->window;
+ 	nth->check	= 0;
+ 	nth->urg_ptr	= 0;
+ 
+ 	synproxy_build_options(nth, opts);
+ 
+ 	synproxy_send_tcp(net, skb, nskb, &snet->tmpl->ct_general, IP_CT_NEW,
+ 			  niph, nth, tcp_hdr_size);
+ }
+ 
+ static void
+ synproxy_send_server_ack(struct net *net,
+ 			 const struct ip_ct_tcp *state,
+ 			 const struct sk_buff *skb, const struct tcphdr *th,
+ 			 const struct synproxy_options *opts)
+ {
+ 	struct sk_buff *nskb;
+ 	struct iphdr *iph, *niph;
+ 	struct tcphdr *nth;
+ 	unsigned int tcp_hdr_size;
+ 
+ 	iph = ip_hdr(skb);
+ 
+ 	tcp_hdr_size = sizeof(*nth) + synproxy_options_size(opts);
+ 	nskb = alloc_skb(sizeof(*niph) + tcp_hdr_size + MAX_TCP_HEADER,
+ 			 GFP_ATOMIC);
+ 	if (!nskb)
+ 		return;
+ 	skb_reserve(nskb, MAX_TCP_HEADER);
+ 
+ 	niph = synproxy_build_ip(net, nskb, iph->daddr, iph->saddr);
+ 
+ 	skb_reset_transport_header(nskb);
+ 	nth = skb_put(nskb, tcp_hdr_size);
+ 	nth->source	= th->dest;
+ 	nth->dest	= th->source;
+ 	nth->seq	= htonl(ntohl(th->ack_seq));
+ 	nth->ack_seq	= htonl(ntohl(th->seq) + 1);
+ 	tcp_flag_word(nth) = TCP_FLAG_ACK;
+ 	nth->doff	= tcp_hdr_size / 4;
+ 	nth->window	= htons(state->seen[IP_CT_DIR_ORIGINAL].td_maxwin);
+ 	nth->check	= 0;
+ 	nth->urg_ptr	= 0;
+ 
+ 	synproxy_build_options(nth, opts);
+ 
+ 	synproxy_send_tcp(net, skb, nskb, NULL, 0, niph, nth, tcp_hdr_size);
+ }
+ 
+ static void
+ synproxy_send_client_ack(struct net *net,
+ 			 const struct sk_buff *skb, const struct tcphdr *th,
+ 			 const struct synproxy_options *opts)
+ {
+ 	struct sk_buff *nskb;
+ 	struct iphdr *iph, *niph;
+ 	struct tcphdr *nth;
+ 	unsigned int tcp_hdr_size;
+ 
+ 	iph = ip_hdr(skb);
+ 
+ 	tcp_hdr_size = sizeof(*nth) + synproxy_options_size(opts);
+ 	nskb = alloc_skb(sizeof(*niph) + tcp_hdr_size + MAX_TCP_HEADER,
+ 			 GFP_ATOMIC);
+ 	if (!nskb)
+ 		return;
+ 	skb_reserve(nskb, MAX_TCP_HEADER);
+ 
+ 	niph = synproxy_build_ip(net, nskb, iph->saddr, iph->daddr);
+ 
+ 	skb_reset_transport_header(nskb);
+ 	nth = skb_put(nskb, tcp_hdr_size);
+ 	nth->source	= th->source;
+ 	nth->dest	= th->dest;
+ 	nth->seq	= htonl(ntohl(th->seq) + 1);
+ 	nth->ack_seq	= th->ack_seq;
+ 	tcp_flag_word(nth) = TCP_FLAG_ACK;
+ 	nth->doff	= tcp_hdr_size / 4;
+ 	nth->window	= htons(ntohs(th->window) >> opts->wscale);
+ 	nth->check	= 0;
+ 	nth->urg_ptr	= 0;
+ 
+ 	synproxy_build_options(nth, opts);
+ 
+ 	synproxy_send_tcp(net, skb, nskb, skb_nfct(skb),
+ 			  IP_CT_ESTABLISHED_REPLY, niph, nth, tcp_hdr_size);
+ }
+ 
+ bool
+ synproxy_recv_client_ack(struct net *net,
+ 			 const struct sk_buff *skb, const struct tcphdr *th,
+ 			 struct synproxy_options *opts, u32 recv_seq)
+ {
+ 	struct synproxy_net *snet = synproxy_pernet(net);
+ 	int mss;
+ 
+ 	mss = __cookie_v4_check(ip_hdr(skb), th, ntohl(th->ack_seq) - 1);
+ 	if (mss == 0) {
+ 		this_cpu_inc(snet->stats->cookie_invalid);
+ 		return false;
+ 	}
+ 
+ 	this_cpu_inc(snet->stats->cookie_valid);
+ 	opts->mss_option = mss;
+ 	opts->options |= NF_SYNPROXY_OPT_MSS;
+ 
+ 	if (opts->options & NF_SYNPROXY_OPT_TIMESTAMP)
+ 		synproxy_check_timestamp_cookie(opts);
+ 
+ 	synproxy_send_server_syn(net, skb, th, opts, recv_seq);
+ 	return true;
+ }
+ EXPORT_SYMBOL_GPL(synproxy_recv_client_ack);
+ 
+ unsigned int
+ ipv4_synproxy_hook(void *priv, struct sk_buff *skb,
+ 		   const struct nf_hook_state *nhs)
+ {
+ 	struct net *net = nhs->net;
+ 	struct synproxy_net *snet = synproxy_pernet(net);
+ 	enum ip_conntrack_info ctinfo;
+ 	struct nf_conn *ct;
+ 	struct nf_conn_synproxy *synproxy;
+ 	struct synproxy_options opts = {};
+ 	const struct ip_ct_tcp *state;
+ 	struct tcphdr *th, _th;
+ 	unsigned int thoff;
+ 
+ 	ct = nf_ct_get(skb, &ctinfo);
+ 	if (!ct)
+ 		return NF_ACCEPT;
+ 
+ 	synproxy = nfct_synproxy(ct);
+ 	if (!synproxy)
+ 		return NF_ACCEPT;
+ 
+ 	if (nf_is_loopback_packet(skb) ||
+ 	    ip_hdr(skb)->protocol != IPPROTO_TCP)
+ 		return NF_ACCEPT;
+ 
+ 	thoff = ip_hdrlen(skb);
+ 	th = skb_header_pointer(skb, thoff, sizeof(_th), &_th);
+ 	if (!th)
+ 		return NF_DROP;
+ 
+ 	state = &ct->proto.tcp;
+ 	switch (state->state) {
+ 	case TCP_CONNTRACK_CLOSE:
+ 		if (th->rst && CTINFO2DIR(ctinfo) != IP_CT_DIR_ORIGINAL) {
+ 			nf_ct_seqadj_init(ct, ctinfo, synproxy->isn -
+ 						      ntohl(th->seq) + 1);
+ 			break;
+ 		}
+ 
+ 		if (!th->syn || th->ack ||
+ 		    CTINFO2DIR(ctinfo) != IP_CT_DIR_ORIGINAL)
+ 			break;
+ 
+ 		/* Reopened connection - reset the sequence number and timestamp
+ 		 * adjustments, they will get initialized once the connection is
+ 		 * reestablished.
+ 		 */
+ 		nf_ct_seqadj_init(ct, ctinfo, 0);
+ 		synproxy->tsoff = 0;
+ 		this_cpu_inc(snet->stats->conn_reopened);
+ 		fallthrough;
+ 	case TCP_CONNTRACK_SYN_SENT:
+ 		if (!synproxy_parse_options(skb, thoff, th, &opts))
+ 			return NF_DROP;
+ 
+ 		if (!th->syn && th->ack &&
+ 		    CTINFO2DIR(ctinfo) == IP_CT_DIR_ORIGINAL) {
+ 			/* Keep-Alives are sent with SEG.SEQ = SND.NXT-1,
+ 			 * therefore we need to add 1 to make the SYN sequence
+ 			 * number match the one of first SYN.
+ 			 */
+ 			if (synproxy_recv_client_ack(net, skb, th, &opts,
+ 						     ntohl(th->seq) + 1)) {
+ 				this_cpu_inc(snet->stats->cookie_retrans);
+ 				consume_skb(skb);
+ 				return NF_STOLEN;
+ 			} else {
+ 				return NF_DROP;
+ 			}
+ 		}
+ 
+ 		synproxy->isn = ntohl(th->ack_seq);
+ 		if (opts.options & NF_SYNPROXY_OPT_TIMESTAMP)
+ 			synproxy->its = opts.tsecr;
+ 
+ 		nf_conntrack_event_cache(IPCT_SYNPROXY, ct);
+ 		break;
+ 	case TCP_CONNTRACK_SYN_RECV:
+ 		if (!th->syn || !th->ack)
+ 			break;
+ 
+ 		if (!synproxy_parse_options(skb, thoff, th, &opts))
+ 			return NF_DROP;
+ 
+ 		if (opts.options & NF_SYNPROXY_OPT_TIMESTAMP) {
+ 			synproxy->tsoff = opts.tsval - synproxy->its;
+ 			nf_conntrack_event_cache(IPCT_SYNPROXY, ct);
+ 		}
+ 
+ 		opts.options &= ~(NF_SYNPROXY_OPT_MSS |
+ 				  NF_SYNPROXY_OPT_WSCALE |
+ 				  NF_SYNPROXY_OPT_SACK_PERM);
+ 
+ 		swap(opts.tsval, opts.tsecr);
+ 		synproxy_send_server_ack(net, state, skb, th, &opts);
+ 
+ 		nf_ct_seqadj_init(ct, ctinfo, synproxy->isn - ntohl(th->seq));
+ 		nf_conntrack_event_cache(IPCT_SEQADJ, ct);
+ 
+ 		swap(opts.tsval, opts.tsecr);
+ 		synproxy_send_client_ack(net, skb, th, &opts);
+ 
+ 		consume_skb(skb);
+ 		return NF_STOLEN;
+ 	default:
+ 		break;
+ 	}
+ 
+ 	synproxy_tstamp_adjust(skb, thoff, th, ct, ctinfo, synproxy);
+ 	return NF_ACCEPT;
+ }
+ EXPORT_SYMBOL_GPL(ipv4_synproxy_hook);
+ 
+ static const struct nf_hook_ops ipv4_synproxy_ops[] = {
+ 	{
+ 		.hook		= ipv4_synproxy_hook,
+ 		.pf		= NFPROTO_IPV4,
+ 		.hooknum	= NF_INET_LOCAL_IN,
+ 		.priority	= NF_IP_PRI_CONNTRACK_CONFIRM - 1,
+ 	},
+ 	{
+ 		.hook		= ipv4_synproxy_hook,
+ 		.pf		= NFPROTO_IPV4,
+ 		.hooknum	= NF_INET_POST_ROUTING,
+ 		.priority	= NF_IP_PRI_CONNTRACK_CONFIRM - 1,
+ 	},
+ };
+ 
+ int nf_synproxy_ipv4_init(struct synproxy_net *snet, struct net *net)
+ {
+ 	int err;
+ 
+ 	if (snet->hook_ref4 == 0) {
+ 		err = nf_register_net_hooks(net, ipv4_synproxy_ops,
+ 					    ARRAY_SIZE(ipv4_synproxy_ops));
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	snet->hook_ref4++;
+ 	return 0;
+ }
+ EXPORT_SYMBOL_GPL(nf_synproxy_ipv4_init);
+ 
+ void nf_synproxy_ipv4_fini(struct synproxy_net *snet, struct net *net)
+ {
+ 	snet->hook_ref4--;
+ 	if (snet->hook_ref4 == 0)
+ 		nf_unregister_net_hooks(net, ipv4_synproxy_ops,
+ 					ARRAY_SIZE(ipv4_synproxy_ops));
+ }
+ EXPORT_SYMBOL_GPL(nf_synproxy_ipv4_fini);
+ 
+ #if IS_ENABLED(CONFIG_IPV6)
+ static struct ipv6hdr *
+ synproxy_build_ip_ipv6(struct net *net, struct sk_buff *skb,
+ 		       const struct in6_addr *saddr,
+ 		       const struct in6_addr *daddr)
+ {
+ 	struct ipv6hdr *iph;
+ 
+ 	skb_reset_network_header(skb);
+ 	iph = skb_put(skb, sizeof(*iph));
+ 	ip6_flow_hdr(iph, 0, 0);
+ 	iph->hop_limit	= net->ipv6.devconf_all->hop_limit;
+ 	iph->nexthdr	= IPPROTO_TCP;
+ 	iph->saddr	= *saddr;
+ 	iph->daddr	= *daddr;
+ 
+ 	return iph;
+ }
+ 
+ static void
+ synproxy_send_tcp_ipv6(struct net *net,
+ 		       const struct sk_buff *skb, struct sk_buff *nskb,
+ 		       struct nf_conntrack *nfct, enum ip_conntrack_info ctinfo,
+ 		       struct ipv6hdr *niph, struct tcphdr *nth,
+ 		       unsigned int tcp_hdr_size)
+ {
+ 	struct dst_entry *dst;
+ 	struct flowi6 fl6;
+ 	int err;
+ 
+ 	nth->check = ~tcp_v6_check(tcp_hdr_size, &niph->saddr, &niph->daddr, 0);
+ 	nskb->ip_summed   = CHECKSUM_PARTIAL;
+ 	nskb->csum_start  = (unsigned char *)nth - nskb->head;
+ 	nskb->csum_offset = offsetof(struct tcphdr, check);
+ 
+ 	memset(&fl6, 0, sizeof(fl6));
+ 	fl6.flowi6_proto = IPPROTO_TCP;
+ 	fl6.saddr = niph->saddr;
+ 	fl6.daddr = niph->daddr;
+ 	fl6.fl6_sport = nth->source;
+ 	fl6.fl6_dport = nth->dest;
+ 	security_skb_classify_flow((struct sk_buff *)skb,
+ 				   flowi6_to_flowi(&fl6));
+ 	err = nf_ip6_route(net, &dst, flowi6_to_flowi(&fl6), false);
+ 	if (err) {
+ 		goto free_nskb;
+ 	}
+ 
+ 	dst = xfrm_lookup(net, dst, flowi6_to_flowi(&fl6), NULL, 0);
+ 	if (IS_ERR(dst))
+ 		goto free_nskb;
+ 
+ 	skb_dst_set(nskb, dst);
+ 
+ 	if (nfct) {
+ 		nf_ct_set(nskb, (struct nf_conn *)nfct, ctinfo);
+ 		nf_conntrack_get(nfct);
+ 	}
+ 
+ 	ip6_local_out(net, nskb->sk, nskb);
+ 	return;
+ 
+ free_nskb:
+ 	kfree_skb(nskb);
+ }
+ 
+ void
+ synproxy_send_client_synack_ipv6(struct net *net,
+ 				 const struct sk_buff *skb,
+ 				 const struct tcphdr *th,
+ 				 const struct synproxy_options *opts)
+ {
+ 	struct sk_buff *nskb;
+ 	struct ipv6hdr *iph, *niph;
+ 	struct tcphdr *nth;
+ 	unsigned int tcp_hdr_size;
+ 	u16 mss = opts->mss_encode;
+ 
+ 	iph = ipv6_hdr(skb);
+ 
+ 	tcp_hdr_size = sizeof(*nth) + synproxy_options_size(opts);
+ 	nskb = alloc_skb(sizeof(*niph) + tcp_hdr_size + MAX_TCP_HEADER,
+ 			 GFP_ATOMIC);
+ 	if (!nskb)
+ 		return;
+ 	skb_reserve(nskb, MAX_TCP_HEADER);
+ 
+ 	niph = synproxy_build_ip_ipv6(net, nskb, &iph->daddr, &iph->saddr);
+ 
+ 	skb_reset_transport_header(nskb);
+ 	nth = skb_put(nskb, tcp_hdr_size);
+ 	nth->source	= th->dest;
+ 	nth->dest	= th->source;
+ 	nth->seq	= htonl(nf_ipv6_cookie_init_sequence(iph, th, &mss));
+ 	nth->ack_seq	= htonl(ntohl(th->seq) + 1);
+ 	tcp_flag_word(nth) = TCP_FLAG_SYN | TCP_FLAG_ACK;
+ 	if (opts->options & NF_SYNPROXY_OPT_ECN)
+ 		tcp_flag_word(nth) |= TCP_FLAG_ECE;
+ 	nth->doff	= tcp_hdr_size / 4;
+ 	nth->window	= 0;
+ 	nth->check	= 0;
+ 	nth->urg_ptr	= 0;
+ 
+ 	synproxy_build_options(nth, opts);
+ 
+ 	synproxy_send_tcp_ipv6(net, skb, nskb, skb_nfct(skb),
+ 			       IP_CT_ESTABLISHED_REPLY, niph, nth,
+ 			       tcp_hdr_size);
+ }
+ EXPORT_SYMBOL_GPL(synproxy_send_client_synack_ipv6);
+ 
+ static void
+ synproxy_send_server_syn_ipv6(struct net *net, const struct sk_buff *skb,
+ 			      const struct tcphdr *th,
+ 			      const struct synproxy_options *opts, u32 recv_seq)
+ {
+ 	struct synproxy_net *snet = synproxy_pernet(net);
+ 	struct sk_buff *nskb;
+ 	struct ipv6hdr *iph, *niph;
+ 	struct tcphdr *nth;
+ 	unsigned int tcp_hdr_size;
+ 
+ 	iph = ipv6_hdr(skb);
+ 
+ 	tcp_hdr_size = sizeof(*nth) + synproxy_options_size(opts);
+ 	nskb = alloc_skb(sizeof(*niph) + tcp_hdr_size + MAX_TCP_HEADER,
+ 			 GFP_ATOMIC);
+ 	if (!nskb)
+ 		return;
+ 	skb_reserve(nskb, MAX_TCP_HEADER);
+ 
+ 	niph = synproxy_build_ip_ipv6(net, nskb, &iph->saddr, &iph->daddr);
+ 
+ 	skb_reset_transport_header(nskb);
+ 	nth = skb_put(nskb, tcp_hdr_size);
+ 	nth->source	= th->source;
+ 	nth->dest	= th->dest;
+ 	nth->seq	= htonl(recv_seq - 1);
+ 	/* ack_seq is used to relay our ISN to the synproxy hook to initialize
+ 	 * sequence number translation once a connection tracking entry exists.
+ 	 */
+ 	nth->ack_seq	= htonl(ntohl(th->ack_seq) - 1);
+ 	tcp_flag_word(nth) = TCP_FLAG_SYN;
+ 	if (opts->options & NF_SYNPROXY_OPT_ECN)
+ 		tcp_flag_word(nth) |= TCP_FLAG_ECE | TCP_FLAG_CWR;
+ 	nth->doff	= tcp_hdr_size / 4;
+ 	nth->window	= th->window;
+ 	nth->check	= 0;
+ 	nth->urg_ptr	= 0;
+ 
+ 	synproxy_build_options(nth, opts);
+ 
+ 	synproxy_send_tcp_ipv6(net, skb, nskb, &snet->tmpl->ct_general,
+ 			       IP_CT_NEW, niph, nth, tcp_hdr_size);
+ }
+ 
+ static void
+ synproxy_send_server_ack_ipv6(struct net *net, const struct ip_ct_tcp *state,
+ 			      const struct sk_buff *skb,
+ 			      const struct tcphdr *th,
+ 			      const struct synproxy_options *opts)
+ {
+ 	struct sk_buff *nskb;
+ 	struct ipv6hdr *iph, *niph;
+ 	struct tcphdr *nth;
+ 	unsigned int tcp_hdr_size;
+ 
+ 	iph = ipv6_hdr(skb);
+ 
+ 	tcp_hdr_size = sizeof(*nth) + synproxy_options_size(opts);
+ 	nskb = alloc_skb(sizeof(*niph) + tcp_hdr_size + MAX_TCP_HEADER,
+ 			 GFP_ATOMIC);
+ 	if (!nskb)
+ 		return;
+ 	skb_reserve(nskb, MAX_TCP_HEADER);
+ 
+ 	niph = synproxy_build_ip_ipv6(net, nskb, &iph->daddr, &iph->saddr);
+ 
+ 	skb_reset_transport_header(nskb);
+ 	nth = skb_put(nskb, tcp_hdr_size);
+ 	nth->source	= th->dest;
+ 	nth->dest	= th->source;
+ 	nth->seq	= htonl(ntohl(th->ack_seq));
+ 	nth->ack_seq	= htonl(ntohl(th->seq) + 1);
+ 	tcp_flag_word(nth) = TCP_FLAG_ACK;
+ 	nth->doff	= tcp_hdr_size / 4;
+ 	nth->window	= htons(state->seen[IP_CT_DIR_ORIGINAL].td_maxwin);
+ 	nth->check	= 0;
+ 	nth->urg_ptr	= 0;
+ 
+ 	synproxy_build_options(nth, opts);
+ 
+ 	synproxy_send_tcp_ipv6(net, skb, nskb, NULL, 0, niph, nth,
+ 			       tcp_hdr_size);
+ }
+ 
+ static void
+ synproxy_send_client_ack_ipv6(struct net *net, const struct sk_buff *skb,
+ 			      const struct tcphdr *th,
+ 			      const struct synproxy_options *opts)
+ {
+ 	struct sk_buff *nskb;
+ 	struct ipv6hdr *iph, *niph;
+ 	struct tcphdr *nth;
+ 	unsigned int tcp_hdr_size;
+ 
+ 	iph = ipv6_hdr(skb);
+ 
+ 	tcp_hdr_size = sizeof(*nth) + synproxy_options_size(opts);
+ 	nskb = alloc_skb(sizeof(*niph) + tcp_hdr_size + MAX_TCP_HEADER,
+ 			 GFP_ATOMIC);
+ 	if (!nskb)
+ 		return;
+ 	skb_reserve(nskb, MAX_TCP_HEADER);
+ 
+ 	niph = synproxy_build_ip_ipv6(net, nskb, &iph->saddr, &iph->daddr);
+ 
+ 	skb_reset_transport_header(nskb);
+ 	nth = skb_put(nskb, tcp_hdr_size);
+ 	nth->source	= th->source;
+ 	nth->dest	= th->dest;
+ 	nth->seq	= htonl(ntohl(th->seq) + 1);
+ 	nth->ack_seq	= th->ack_seq;
+ 	tcp_flag_word(nth) = TCP_FLAG_ACK;
+ 	nth->doff	= tcp_hdr_size / 4;
+ 	nth->window	= htons(ntohs(th->window) >> opts->wscale);
+ 	nth->check	= 0;
+ 	nth->urg_ptr	= 0;
+ 
+ 	synproxy_build_options(nth, opts);
+ 
+ 	synproxy_send_tcp_ipv6(net, skb, nskb, skb_nfct(skb),
+ 			       IP_CT_ESTABLISHED_REPLY, niph, nth,
+ 			       tcp_hdr_size);
+ }
+ 
+ bool
+ synproxy_recv_client_ack_ipv6(struct net *net,
+ 			      const struct sk_buff *skb,
+ 			      const struct tcphdr *th,
+ 			      struct synproxy_options *opts, u32 recv_seq)
+ {
+ 	struct synproxy_net *snet = synproxy_pernet(net);
+ 	int mss;
+ 
+ 	mss = nf_cookie_v6_check(ipv6_hdr(skb), th, ntohl(th->ack_seq) - 1);
+ 	if (mss == 0) {
+ 		this_cpu_inc(snet->stats->cookie_invalid);
+ 		return false;
+ 	}
+ 
+ 	this_cpu_inc(snet->stats->cookie_valid);
+ 	opts->mss_option = mss;
+ 	opts->options |= NF_SYNPROXY_OPT_MSS;
+ 
+ 	if (opts->options & NF_SYNPROXY_OPT_TIMESTAMP)
+ 		synproxy_check_timestamp_cookie(opts);
+ 
+ 	synproxy_send_server_syn_ipv6(net, skb, th, opts, recv_seq);
+ 	return true;
+ }
+ EXPORT_SYMBOL_GPL(synproxy_recv_client_ack_ipv6);
+ 
+ unsigned int
+ ipv6_synproxy_hook(void *priv, struct sk_buff *skb,
+ 		   const struct nf_hook_state *nhs)
+ {
+ 	struct net *net = nhs->net;
+ 	struct synproxy_net *snet = synproxy_pernet(net);
+ 	enum ip_conntrack_info ctinfo;
+ 	struct nf_conn *ct;
+ 	struct nf_conn_synproxy *synproxy;
+ 	struct synproxy_options opts = {};
+ 	const struct ip_ct_tcp *state;
+ 	struct tcphdr *th, _th;
+ 	__be16 frag_off;
+ 	u8 nexthdr;
+ 	int thoff;
+ 
+ 	ct = nf_ct_get(skb, &ctinfo);
+ 	if (!ct)
+ 		return NF_ACCEPT;
+ 
+ 	synproxy = nfct_synproxy(ct);
+ 	if (!synproxy)
+ 		return NF_ACCEPT;
+ 
+ 	if (nf_is_loopback_packet(skb))
+ 		return NF_ACCEPT;
+ 
+ 	nexthdr = ipv6_hdr(skb)->nexthdr;
+ 	thoff = ipv6_skip_exthdr(skb, sizeof(struct ipv6hdr), &nexthdr,
+ 				 &frag_off);
+ 	if (thoff < 0 || nexthdr != IPPROTO_TCP)
+ 		return NF_ACCEPT;
+ 
+ 	th = skb_header_pointer(skb, thoff, sizeof(_th), &_th);
+ 	if (!th)
+ 		return NF_DROP;
+ 
+ 	state = &ct->proto.tcp;
+ 	switch (state->state) {
+ 	case TCP_CONNTRACK_CLOSE:
+ 		if (th->rst && CTINFO2DIR(ctinfo) != IP_CT_DIR_ORIGINAL) {
+ 			nf_ct_seqadj_init(ct, ctinfo, synproxy->isn -
+ 						      ntohl(th->seq) + 1);
+ 			break;
+ 		}
+ 
+ 		if (!th->syn || th->ack ||
+ 		    CTINFO2DIR(ctinfo) != IP_CT_DIR_ORIGINAL)
+ 			break;
+ 
+ 		/* Reopened connection - reset the sequence number and timestamp
+ 		 * adjustments, they will get initialized once the connection is
+ 		 * reestablished.
+ 		 */
+ 		nf_ct_seqadj_init(ct, ctinfo, 0);
+ 		synproxy->tsoff = 0;
+ 		this_cpu_inc(snet->stats->conn_reopened);
+ 		fallthrough;
+ 	case TCP_CONNTRACK_SYN_SENT:
+ 		if (!synproxy_parse_options(skb, thoff, th, &opts))
+ 			return NF_DROP;
+ 
+ 		if (!th->syn && th->ack &&
+ 		    CTINFO2DIR(ctinfo) == IP_CT_DIR_ORIGINAL) {
+ 			/* Keep-Alives are sent with SEG.SEQ = SND.NXT-1,
+ 			 * therefore we need to add 1 to make the SYN sequence
+ 			 * number match the one of first SYN.
+ 			 */
+ 			if (synproxy_recv_client_ack_ipv6(net, skb, th, &opts,
+ 							  ntohl(th->seq) + 1)) {
+ 				this_cpu_inc(snet->stats->cookie_retrans);
+ 				consume_skb(skb);
+ 				return NF_STOLEN;
+ 			} else {
+ 				return NF_DROP;
+ 			}
+ 		}
+ 
+ 		synproxy->isn = ntohl(th->ack_seq);
+ 		if (opts.options & NF_SYNPROXY_OPT_TIMESTAMP)
+ 			synproxy->its = opts.tsecr;
+ 
+ 		nf_conntrack_event_cache(IPCT_SYNPROXY, ct);
+ 		break;
+ 	case TCP_CONNTRACK_SYN_RECV:
+ 		if (!th->syn || !th->ack)
+ 			break;
+ 
+ 		if (!synproxy_parse_options(skb, thoff, th, &opts))
+ 			return NF_DROP;
+ 
+ 		if (opts.options & NF_SYNPROXY_OPT_TIMESTAMP) {
+ 			synproxy->tsoff = opts.tsval - synproxy->its;
+ 			nf_conntrack_event_cache(IPCT_SYNPROXY, ct);
+ 		}
+ 
+ 		opts.options &= ~(NF_SYNPROXY_OPT_MSS |
+ 				  NF_SYNPROXY_OPT_WSCALE |
+ 				  NF_SYNPROXY_OPT_SACK_PERM);
+ 
+ 		swap(opts.tsval, opts.tsecr);
+ 		synproxy_send_server_ack_ipv6(net, state, skb, th, &opts);
+ 
+ 		nf_ct_seqadj_init(ct, ctinfo, synproxy->isn - ntohl(th->seq));
+ 		nf_conntrack_event_cache(IPCT_SEQADJ, ct);
+ 
+ 		swap(opts.tsval, opts.tsecr);
+ 		synproxy_send_client_ack_ipv6(net, skb, th, &opts);
+ 
+ 		consume_skb(skb);
+ 		return NF_STOLEN;
+ 	default:
+ 		break;
+ 	}
+ 
+ 	synproxy_tstamp_adjust(skb, thoff, th, ct, ctinfo, synproxy);
+ 	return NF_ACCEPT;
+ }
+ EXPORT_SYMBOL_GPL(ipv6_synproxy_hook);
+ 
+ static const struct nf_hook_ops ipv6_synproxy_ops[] = {
+ 	{
+ 		.hook		= ipv6_synproxy_hook,
+ 		.pf		= NFPROTO_IPV6,
+ 		.hooknum	= NF_INET_LOCAL_IN,
+ 		.priority	= NF_IP_PRI_CONNTRACK_CONFIRM - 1,
+ 	},
+ 	{
+ 		.hook		= ipv6_synproxy_hook,
+ 		.pf		= NFPROTO_IPV6,
+ 		.hooknum	= NF_INET_POST_ROUTING,
+ 		.priority	= NF_IP_PRI_CONNTRACK_CONFIRM - 1,
+ 	},
+ };
+ 
+ int
+ nf_synproxy_ipv6_init(struct synproxy_net *snet, struct net *net)
+ {
+ 	int err;
+ 
+ 	if (snet->hook_ref6 == 0) {
+ 		err = nf_register_net_hooks(net, ipv6_synproxy_ops,
+ 					    ARRAY_SIZE(ipv6_synproxy_ops));
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	snet->hook_ref6++;
+ 	return 0;
+ }
+ EXPORT_SYMBOL_GPL(nf_synproxy_ipv6_init);
+ 
+ void
+ nf_synproxy_ipv6_fini(struct synproxy_net *snet, struct net *net)
+ {
+ 	snet->hook_ref6--;
+ 	if (snet->hook_ref6 == 0)
+ 		nf_unregister_net_hooks(net, ipv6_synproxy_ops,
+ 					ARRAY_SIZE(ipv6_synproxy_ops));
+ }
+ EXPORT_SYMBOL_GPL(nf_synproxy_ipv6_fini);
+ #endif /* CONFIG_IPV6 */
+ 
++>>>>>>> 46d6c5ae953c (netfilter: use actual socket sk rather than skb sk when routing harder)
  MODULE_LICENSE("GPL");
  MODULE_AUTHOR("Patrick McHardy <kaber@trash.net>");
 -MODULE_DESCRIPTION("nftables SYNPROXY expression support");
diff --git a/include/linux/netfilter_ipv4.h b/include/linux/netfilter_ipv4.h
index 082e2c41b7ff..5b70ca868bb1 100644
--- a/include/linux/netfilter_ipv4.h
+++ b/include/linux/netfilter_ipv4.h
@@ -16,7 +16,7 @@ struct ip_rt_info {
 	u_int32_t mark;
 };
 
-int ip_route_me_harder(struct net *net, struct sk_buff *skb, unsigned addr_type);
+int ip_route_me_harder(struct net *net, struct sock *sk, struct sk_buff *skb, unsigned addr_type);
 
 struct nf_queue_entry;
 
* Unmerged path include/linux/netfilter_ipv6.h
diff --git a/net/ipv4/netfilter.c b/net/ipv4/netfilter.c
index a058213b77a7..7c841037c533 100644
--- a/net/ipv4/netfilter.c
+++ b/net/ipv4/netfilter.c
@@ -17,17 +17,19 @@
 #include <net/netfilter/nf_queue.h>
 
 /* route_me_harder function, used by iptable_nat, iptable_mangle + ip_queue */
-int ip_route_me_harder(struct net *net, struct sk_buff *skb, unsigned int addr_type)
+int ip_route_me_harder(struct net *net, struct sock *sk, struct sk_buff *skb, unsigned int addr_type)
 {
 	const struct iphdr *iph = ip_hdr(skb);
 	struct rtable *rt;
 	struct flowi4 fl4 = {};
 	__be32 saddr = iph->saddr;
-	const struct sock *sk = skb_to_full_sk(skb);
-	__u8 flags = sk ? inet_sk_flowi_flags(sk) : 0;
+	__u8 flags;
 	struct net_device *dev = skb_dst(skb)->dev;
 	unsigned int hh_len;
 
+	sk = sk_to_full_sk(sk);
+	flags = sk ? inet_sk_flowi_flags(sk) : 0;
+
 	if (addr_type == RTN_UNSPEC)
 		addr_type = inet_addr_type_dev_table(net, dev, saddr);
 	if (addr_type == RTN_LOCAL || addr_type == RTN_UNICAST)
diff --git a/net/ipv4/netfilter/iptable_mangle.c b/net/ipv4/netfilter/iptable_mangle.c
index 1a32d8b49c9c..3bc6adc2b3eb 100644
--- a/net/ipv4/netfilter/iptable_mangle.c
+++ b/net/ipv4/netfilter/iptable_mangle.c
@@ -65,7 +65,7 @@ ipt_mangle_out(struct sk_buff *skb, const struct nf_hook_state *state)
 		    iph->daddr != daddr ||
 		    skb->mark != mark ||
 		    iph->tos != tos) {
-			err = ip_route_me_harder(state->net, skb, RTN_UNSPEC);
+			err = ip_route_me_harder(state->net, state->sk, skb, RTN_UNSPEC);
 			if (err < 0)
 				ret = NF_DROP_ERR(err);
 		}
diff --git a/net/ipv4/netfilter/nf_reject_ipv4.c b/net/ipv4/netfilter/nf_reject_ipv4.c
index 7dc3c324b911..6b290b765594 100644
--- a/net/ipv4/netfilter/nf_reject_ipv4.c
+++ b/net/ipv4/netfilter/nf_reject_ipv4.c
@@ -130,7 +130,7 @@ void nf_send_reset(struct net *net, struct sk_buff *oldskb, int hook)
 				   ip4_dst_hoplimit(skb_dst(nskb)));
 	nf_reject_ip_tcphdr_put(nskb, oldskb, oth);
 
-	if (ip_route_me_harder(net, nskb, RTN_UNSPEC))
+	if (ip_route_me_harder(net, nskb->sk, nskb, RTN_UNSPEC))
 		goto free_nskb;
 
 	niph = ip_hdr(nskb);
diff --git a/net/ipv6/netfilter.c b/net/ipv6/netfilter.c
index 1240ccd57f39..63449d9ce39e 100644
--- a/net/ipv6/netfilter.c
+++ b/net/ipv6/netfilter.c
@@ -17,10 +17,10 @@
 #include <net/xfrm.h>
 #include <net/netfilter/nf_queue.h>
 
-int ip6_route_me_harder(struct net *net, struct sk_buff *skb)
+int ip6_route_me_harder(struct net *net, struct sock *sk_partial, struct sk_buff *skb)
 {
 	const struct ipv6hdr *iph = ipv6_hdr(skb);
-	struct sock *sk = sk_to_full_sk(skb->sk);
+	struct sock *sk = sk_to_full_sk(sk_partial);
 	unsigned int hh_len;
 	struct dst_entry *dst;
 	int strict = (ipv6_addr_type(&iph->daddr) &
@@ -81,7 +81,7 @@ static int nf_ip6_reroute(struct sk_buff *skb,
 		if (!ipv6_addr_equal(&iph->daddr, &rt_info->daddr) ||
 		    !ipv6_addr_equal(&iph->saddr, &rt_info->saddr) ||
 		    skb->mark != rt_info->mark)
-			return ip6_route_me_harder(entry->state.net, skb);
+			return ip6_route_me_harder(entry->state.net, entry->state.sk, skb);
 	}
 	return 0;
 }
diff --git a/net/ipv6/netfilter/ip6table_mangle.c b/net/ipv6/netfilter/ip6table_mangle.c
index 1969e07ba30e..4dac9e3ab99b 100644
--- a/net/ipv6/netfilter/ip6table_mangle.c
+++ b/net/ipv6/netfilter/ip6table_mangle.c
@@ -60,7 +60,7 @@ ip6t_mangle_out(struct sk_buff *skb, const struct nf_hook_state *state)
 	     skb->mark != mark ||
 	     ipv6_hdr(skb)->hop_limit != hop_limit ||
 	     flowlabel != *((u_int32_t *)ipv6_hdr(skb)))) {
-		err = ip6_route_me_harder(state->net, skb);
+		err = ip6_route_me_harder(state->net, state->sk, skb);
 		if (err < 0)
 			ret = NF_DROP_ERR(err);
 	}
diff --git a/net/netfilter/ipvs/ip_vs_core.c b/net/netfilter/ipvs/ip_vs_core.c
index a71f777d1353..5d66854309b7 100644
--- a/net/netfilter/ipvs/ip_vs_core.c
+++ b/net/netfilter/ipvs/ip_vs_core.c
@@ -725,12 +725,12 @@ static int ip_vs_route_me_harder(struct netns_ipvs *ipvs, int af,
 		struct dst_entry *dst = skb_dst(skb);
 
 		if (dst->dev && !(dst->dev->flags & IFF_LOOPBACK) &&
-		    ip6_route_me_harder(ipvs->net, skb) != 0)
+		    ip6_route_me_harder(ipvs->net, skb->sk, skb) != 0)
 			return 1;
 	} else
 #endif
 		if (!(skb_rtable(skb)->rt_flags & RTCF_LOCAL) &&
-		    ip_route_me_harder(ipvs->net, skb, RTN_LOCAL) != 0)
+		    ip_route_me_harder(ipvs->net, skb->sk, skb, RTN_LOCAL) != 0)
 			return 1;
 
 	return 0;
diff --git a/net/netfilter/nf_nat_proto.c b/net/netfilter/nf_nat_proto.c
index ee532f2c71c5..ff0937f28dbf 100644
--- a/net/netfilter/nf_nat_proto.c
+++ b/net/netfilter/nf_nat_proto.c
@@ -718,7 +718,7 @@ nf_nat_ipv4_local_fn(void *priv, struct sk_buff *skb,
 
 		if (ct->tuplehash[dir].tuple.dst.u3.ip !=
 		    ct->tuplehash[!dir].tuple.src.u3.ip) {
-			err = ip_route_me_harder(state->net, skb, RTN_UNSPEC);
+			err = ip_route_me_harder(state->net, state->sk, skb, RTN_UNSPEC);
 			if (err < 0)
 				ret = NF_DROP_ERR(err);
 		}
@@ -956,7 +956,7 @@ nf_nat_ipv6_local_fn(void *priv, struct sk_buff *skb,
 
 		if (!nf_inet_addr_cmp(&ct->tuplehash[dir].tuple.dst.u3,
 				      &ct->tuplehash[!dir].tuple.src.u3)) {
-			err = nf_ip6_route_me_harder(state->net, skb);
+			err = nf_ip6_route_me_harder(state->net, state->sk, skb);
 			if (err < 0)
 				ret = NF_DROP_ERR(err);
 		}
* Unmerged path net/netfilter/nf_synproxy_core.c
diff --git a/net/netfilter/nft_chain_route.c b/net/netfilter/nft_chain_route.c
index 8826bbe71136..edd02cda57fc 100644
--- a/net/netfilter/nft_chain_route.c
+++ b/net/netfilter/nft_chain_route.c
@@ -42,7 +42,7 @@ static unsigned int nf_route_table_hook4(void *priv,
 		    iph->daddr != daddr ||
 		    skb->mark != mark ||
 		    iph->tos != tos) {
-			err = ip_route_me_harder(state->net, skb, RTN_UNSPEC);
+			err = ip_route_me_harder(state->net, state->sk, skb, RTN_UNSPEC);
 			if (err < 0)
 				ret = NF_DROP_ERR(err);
 		}
@@ -92,7 +92,7 @@ static unsigned int nf_route_table_hook6(void *priv,
 	     skb->mark != mark ||
 	     ipv6_hdr(skb)->hop_limit != hop_limit ||
 	     flowlabel != *((u32 *)ipv6_hdr(skb)))) {
-		err = nf_ip6_route_me_harder(state->net, skb);
+		err = nf_ip6_route_me_harder(state->net, state->sk, skb);
 		if (err < 0)
 			ret = NF_DROP_ERR(err);
 	}
diff --git a/net/netfilter/utils.c b/net/netfilter/utils.c
index 51b454d8fa9c..924195861faf 100644
--- a/net/netfilter/utils.c
+++ b/net/netfilter/utils.c
@@ -191,8 +191,8 @@ static int nf_ip_reroute(struct sk_buff *skb, const struct nf_queue_entry *entry
 		      skb->mark == rt_info->mark &&
 		      iph->daddr == rt_info->daddr &&
 		      iph->saddr == rt_info->saddr))
-			return ip_route_me_harder(entry->state.net, skb,
-						  RTN_UNSPEC);
+			return ip_route_me_harder(entry->state.net, entry->state.sk,
+						  skb, RTN_UNSPEC);
 	}
 #endif
 	return 0;
