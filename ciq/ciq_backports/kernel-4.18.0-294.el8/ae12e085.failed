lib/vdso: Allow fixed clock mode

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Christophe Leroy <christophe.leroy@c-s.fr>
commit ae12e08539de6717502c2f9f83bd60df939b5c08
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/ae12e085.failed

Some architectures have a fixed clocksource which is known at compile time
and cannot be replaced or disabled at runtime, e.g. timebase on
PowerPC. For such cases the clock mode check in the VDSO code is pointless.

Move the check for a VDSO capable clocksource into an inline function and
allow architectures to redefine it via a macro.

[ tglx: Removed the #ifdef mess ]

	Signed-off-by: Christophe Leroy <christophe.leroy@c-s.fr>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Tested-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
	Reviewed-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
Link: https://lkml.kernel.org/r/20200207124403.748756829@linutronix.de



(cherry picked from commit ae12e08539de6717502c2f9f83bd60df939b5c08)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	lib/vdso/gettimeofday.c
diff --cc lib/vdso/gettimeofday.c
index 632c43443888,8eb6d1e9a8ff..000000000000
--- a/lib/vdso/gettimeofday.c
+++ b/lib/vdso/gettimeofday.c
@@@ -26,23 -27,127 +26,137 @@@
  #include <asm/vdso/gettimeofday.h>
  #endif /* ENABLE_COMPAT_VDSO */
  
++<<<<<<< HEAD
 +static int do_hres(const struct vdso_data *vd, clockid_t clk,
 +		   struct __kernel_timespec *ts)
++=======
+ #ifndef vdso_calc_delta
+ /*
+  * Default implementation which works for all sane clocksources. That
+  * obviously excludes x86/TSC.
+  */
+ static __always_inline
+ u64 vdso_calc_delta(u64 cycles, u64 last, u64 mask, u32 mult)
+ {
+ 	return ((cycles - last) & mask) * mult;
+ }
+ #endif
+ 
+ #ifndef __arch_vdso_hres_capable
+ static inline bool __arch_vdso_hres_capable(void)
+ {
+ 	return true;
+ }
+ #endif
+ 
+ #ifndef vdso_clocksource_ok
+ static inline bool vdso_clocksource_ok(const struct vdso_data *vd)
+ {
+ 	return vd->clock_mode != VDSO_CLOCKMODE_NONE;
+ }
+ #endif
+ 
+ #ifdef CONFIG_TIME_NS
+ static int do_hres_timens(const struct vdso_data *vdns, clockid_t clk,
+ 			  struct __kernel_timespec *ts)
+ {
+ 	const struct vdso_data *vd = __arch_get_timens_vdso_data();
+ 	const struct timens_offset *offs = &vdns->offset[clk];
+ 	const struct vdso_timestamp *vdso_ts;
+ 	u64 cycles, last, ns;
+ 	u32 seq;
+ 	s64 sec;
+ 
+ 	if (clk != CLOCK_MONOTONIC_RAW)
+ 		vd = &vd[CS_HRES_COARSE];
+ 	else
+ 		vd = &vd[CS_RAW];
+ 	vdso_ts = &vd->basetime[clk];
+ 
+ 	do {
+ 		seq = vdso_read_begin(vd);
+ 
+ 		if (unlikely(!vdso_clocksource_ok(vd)))
+ 			return -1;
+ 
+ 		cycles = __arch_get_hw_counter(vd->clock_mode);
+ 		ns = vdso_ts->nsec;
+ 		last = vd->cycle_last;
+ 		ns += vdso_calc_delta(cycles, last, vd->mask, vd->mult);
+ 		ns >>= vd->shift;
+ 		sec = vdso_ts->sec;
+ 	} while (unlikely(vdso_read_retry(vd, seq)));
+ 
+ 	/* Add the namespace offset */
+ 	sec += offs->sec;
+ 	ns += offs->nsec;
+ 
+ 	/*
+ 	 * Do this outside the loop: a race inside the loop could result
+ 	 * in __iter_div_u64_rem() being extremely slow.
+ 	 */
+ 	ts->tv_sec = sec + __iter_div_u64_rem(ns, NSEC_PER_SEC, &ns);
+ 	ts->tv_nsec = ns;
+ 
+ 	return 0;
+ }
+ #else
+ static __always_inline const struct vdso_data *__arch_get_timens_vdso_data(void)
+ {
+ 	return NULL;
+ }
+ 
+ static int do_hres_timens(const struct vdso_data *vdns, clockid_t clk,
+ 			  struct __kernel_timespec *ts)
+ {
+ 	return -EINVAL;
+ }
+ #endif
+ 
+ static __always_inline int do_hres(const struct vdso_data *vd, clockid_t clk,
+ 				   struct __kernel_timespec *ts)
++>>>>>>> ae12e08539de (lib/vdso: Allow fixed clock mode)
  {
  	const struct vdso_timestamp *vdso_ts = &vd->basetime[clk];
  	u64 cycles, last, sec, ns;
  	u32 seq;
  
 -	/* Allows to compile the high resolution parts out */
 -	if (!__arch_vdso_hres_capable())
 -		return -1;
 -
  	do {
++<<<<<<< HEAD
 +		seq = vdso_read_begin(vd);
 +		cycles = __arch_get_hw_counter(vd->clock_mode) &
 +			vd->mask;
++=======
+ 		/*
+ 		 * Open coded to handle VDSO_CLOCKMODE_TIMENS. Time namespace
+ 		 * enabled tasks have a special VVAR page installed which
+ 		 * has vd->seq set to 1 and vd->clock_mode set to
+ 		 * VDSO_CLOCKMODE_TIMENS. For non time namespace affected tasks
+ 		 * this does not affect performance because if vd->seq is
+ 		 * odd, i.e. a concurrent update is in progress the extra
+ 		 * check for vd->clock_mode is just a few extra
+ 		 * instructions while spin waiting for vd->seq to become
+ 		 * even again.
+ 		 */
+ 		while (unlikely((seq = READ_ONCE(vd->seq)) & 1)) {
+ 			if (IS_ENABLED(CONFIG_TIME_NS) &&
+ 			    vd->clock_mode == VDSO_CLOCKMODE_TIMENS)
+ 				return do_hres_timens(vd, clk, ts);
+ 			cpu_relax();
+ 		}
+ 		smp_rmb();
+ 
+ 		if (unlikely(!vdso_clocksource_ok(vd)))
+ 			return -1;
+ 
+ 		cycles = __arch_get_hw_counter(vd->clock_mode);
++>>>>>>> ae12e08539de (lib/vdso: Allow fixed clock mode)
  		ns = vdso_ts->nsec;
  		last = vd->cycle_last;
 -		ns += vdso_calc_delta(cycles, last, vd->mask, vd->mult);
 +		if (unlikely((s64)cycles < 0))
 +			return clock_gettime_fallback(clk, ts);
 +		if (cycles > last)
 +			ns += (cycles - last) * vd->mult;
  		ns >>= vd->shift;
  		sec = vdso_ts->sec;
  	} while (unlikely(vdso_read_retry(vd, seq)));
* Unmerged path lib/vdso/gettimeofday.c
