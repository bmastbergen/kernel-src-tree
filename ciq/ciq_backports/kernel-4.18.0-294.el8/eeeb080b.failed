kprobes: Prohibit probing on hardirq tracers

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-294.el8
commit-author Masami Hiramatsu <mhiramat@kernel.org>
commit eeeb080bae906a57b6513d37efe3c38f2cb87a1c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-294.el8/eeeb080b.failed

Since kprobes breakpoint handling involves hardirq tracer,
probing these functions cause breakpoint recursion problem.

Prohibit probing on those functions.

	Signed-off-by: Masami Hiramatsu <mhiramat@kernel.org>
	Acked-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
	Cc: Alexander Shishkin <alexander.shishkin@linux.intel.com>
	Cc: Andrea Righi <righi.andrea@gmail.com>
	Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
	Cc: Jiri Olsa <jolsa@redhat.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Mathieu Desnoyers <mathieu.desnoyers@efficios.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
Link: http://lkml.kernel.org/r/154998802073.31052.17255044712514564153.stgit@devbox
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit eeeb080bae906a57b6513d37efe3c38f2cb87a1c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/trace/trace_irqsoff.c
#	kernel/trace/trace_preemptirq.c
diff --cc kernel/trace/trace_irqsoff.c
index f8daa754cce2,d42a473b8240..000000000000
--- a/kernel/trace/trace_irqsoff.c
+++ b/kernel/trace/trace_irqsoff.c
@@@ -366,8 -366,8 +367,13 @@@ out
  	__trace_function(tr, CALLER_ADDR0, parent_ip, flags, pc);
  }
  
++<<<<<<< HEAD
 +static inline void
 +start_critical_timing(unsigned long ip, unsigned long parent_ip)
++=======
+ static nokprobe_inline void
+ start_critical_timing(unsigned long ip, unsigned long parent_ip, int pc)
++>>>>>>> eeeb080bae90 (kprobes: Prohibit probing on hardirq tracers)
  {
  	int cpu;
  	struct trace_array *tr = irqsoff_trace;
@@@ -402,8 -402,8 +408,13 @@@
  	atomic_dec(&data->disabled);
  }
  
++<<<<<<< HEAD
 +static inline void
 +stop_critical_timing(unsigned long ip, unsigned long parent_ip)
++=======
+ static nokprobe_inline void
+ stop_critical_timing(unsigned long ip, unsigned long parent_ip, int pc)
++>>>>>>> eeeb080bae90 (kprobes: Prohibit probing on hardirq tracers)
  {
  	int cpu;
  	struct trace_array *tr = irqsoff_trace;
@@@ -438,78 -438,24 +449,80 @@@
  /* start and stop critical timings used to for stoppage (in idle) */
  void start_critical_timings(void)
  {
 -	int pc = preempt_count();
 -
 -	if (preempt_trace(pc) || irq_trace())
 -		start_critical_timing(CALLER_ADDR0, CALLER_ADDR1, pc);
 +	if (preempt_trace() || irq_trace())
 +		start_critical_timing(CALLER_ADDR0, CALLER_ADDR1);
  }
  EXPORT_SYMBOL_GPL(start_critical_timings);
+ NOKPROBE_SYMBOL(start_critical_timings);
  
  void stop_critical_timings(void)
  {
 -	int pc = preempt_count();
 -
 -	if (preempt_trace(pc) || irq_trace())
 -		stop_critical_timing(CALLER_ADDR0, CALLER_ADDR1, pc);
 +	if (preempt_trace() || irq_trace())
 +		stop_critical_timing(CALLER_ADDR0, CALLER_ADDR1);
  }
  EXPORT_SYMBOL_GPL(stop_critical_timings);
+ NOKPROBE_SYMBOL(stop_critical_timings);
  
 +#ifdef CONFIG_IRQSOFF_TRACER
 +#ifdef CONFIG_PROVE_LOCKING
 +void time_hardirqs_on(unsigned long a0, unsigned long a1)
 +{
 +	if (!preempt_trace() && irq_trace())
 +		stop_critical_timing(a0, a1);
 +}
 +
 +void time_hardirqs_off(unsigned long a0, unsigned long a1)
 +{
 +	if (!preempt_trace() && irq_trace())
 +		start_critical_timing(a0, a1);
 +}
 +
 +#else /* !CONFIG_PROVE_LOCKING */
 +
 +/*
 + * We are only interested in hardirq on/off events:
 + */
 +static inline void tracer_hardirqs_on(void)
 +{
 +	if (!preempt_trace() && irq_trace())
 +		stop_critical_timing(CALLER_ADDR0, CALLER_ADDR1);
 +}
 +
 +static inline void tracer_hardirqs_off(void)
 +{
 +	if (!preempt_trace() && irq_trace())
 +		start_critical_timing(CALLER_ADDR0, CALLER_ADDR1);
 +}
 +
 +static inline void tracer_hardirqs_on_caller(unsigned long caller_addr)
 +{
 +	if (!preempt_trace() && irq_trace())
 +		stop_critical_timing(CALLER_ADDR0, caller_addr);
 +}
 +
 +static inline void tracer_hardirqs_off_caller(unsigned long caller_addr)
 +{
 +	if (!preempt_trace() && irq_trace())
 +		start_critical_timing(CALLER_ADDR0, caller_addr);
 +}
 +
 +#endif /* CONFIG_PROVE_LOCKING */
 +#endif /*  CONFIG_IRQSOFF_TRACER */
 +
 +#ifdef CONFIG_PREEMPT_TRACER
 +static inline void tracer_preempt_on(unsigned long a0, unsigned long a1)
 +{
 +	if (preempt_trace() && !irq_trace())
 +		stop_critical_timing(a0, a1);
 +}
 +
 +static inline void tracer_preempt_off(unsigned long a0, unsigned long a1)
 +{
 +	if (preempt_trace() && !irq_trace())
 +		start_critical_timing(a0, a1);
 +}
 +#endif /* CONFIG_PREEMPT_TRACER */
 +
  #ifdef CONFIG_FUNCTION_TRACER
  static bool function_enabled;
  
@@@ -659,6 -604,27 +672,30 @@@ static void irqsoff_tracer_stop(struct 
  }
  
  #ifdef CONFIG_IRQSOFF_TRACER
++<<<<<<< HEAD
++=======
+ /*
+  * We are only interested in hardirq on/off events:
+  */
+ void tracer_hardirqs_on(unsigned long a0, unsigned long a1)
+ {
+ 	unsigned int pc = preempt_count();
+ 
+ 	if (!preempt_trace(pc) && irq_trace())
+ 		stop_critical_timing(a0, a1, pc);
+ }
+ NOKPROBE_SYMBOL(tracer_hardirqs_on);
+ 
+ void tracer_hardirqs_off(unsigned long a0, unsigned long a1)
+ {
+ 	unsigned int pc = preempt_count();
+ 
+ 	if (!preempt_trace(pc) && irq_trace())
+ 		start_critical_timing(a0, a1, pc);
+ }
+ NOKPROBE_SYMBOL(tracer_hardirqs_off);
+ 
++>>>>>>> eeeb080bae90 (kprobes: Prohibit probing on hardirq tracers)
  static int irqsoff_tracer_init(struct trace_array *tr)
  {
  	trace_type = TRACER_IRQS_OFF;
* Unmerged path kernel/trace/trace_preemptirq.c
* Unmerged path kernel/trace/trace_irqsoff.c
* Unmerged path kernel/trace/trace_preemptirq.c
