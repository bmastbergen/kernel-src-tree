powerpc/smp: Add Power9 scheduler topology

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1160.6.1.el7
commit-author Oliver O'Halloran <oohall@gmail.com>
commit 96d91431d6915073c539c8bdd439b4c863148fc1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.6.1.el7/96d91431.failed

In previous generations of Power processors each core had a private L2
cache. The Power 9 processor has a slightly different design where the
L2 cache is shared among pairs of cores rather than being completely
private.

Making the scheduler aware of this cache sharing allows the scheduler to
make better migration decisions. For example, if two CPU heavy tasks
share a core then one task can be migrated to the paired core to improve
throughput. Under the existing three level topology the task could be
migrated to any core on the same chip, while with the new topology it
would be preferentially migrated to the paired core so it remains
cache-hot.

	Signed-off-by: Oliver O'Halloran <oohall@gmail.com>
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
(cherry picked from commit 96d91431d6915073c539c8bdd439b4c863148fc1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/kernel/smp.c
diff --cc arch/powerpc/kernel/smp.c
index d8707eef215d,e0a4c1f82e25..000000000000
--- a/arch/powerpc/kernel/smp.c
+++ b/arch/powerpc/kernel/smp.c
@@@ -821,18 -1036,40 +830,47 @@@ static struct sched_domain_topology_lev
  	{ NULL, },
  };
  
+ /*
+  * P9 has a slightly odd architecture where pairs of cores share an L2 cache.
+  * This topology makes it *much* cheaper to migrate tasks between adjacent cores
+  * since the migrated task remains cache hot. We want to take advantage of this
+  * at the scheduler level so an extra topology level is required.
+  */
+ static int powerpc_shared_cache_flags(void)
+ {
+ 	return SD_SHARE_PKG_RESOURCES;
+ }
+ 
+ /*
+  * We can't just pass cpu_l2_cache_mask() directly because
+  * returns a non-const pointer and the compiler barfs on that.
+  */
+ static const struct cpumask *shared_cache_mask(int cpu)
+ {
+ 	return cpu_l2_cache_mask(cpu);
+ }
+ 
+ static struct sched_domain_topology_level power9_topology[] = {
+ #ifdef CONFIG_SCHED_SMT
+ 	{ cpu_smt_mask, powerpc_smt_flags, SD_INIT_NAME(SMT) },
+ #endif
+ 	{ shared_cache_mask, powerpc_shared_cache_flags, SD_INIT_NAME(CACHE) },
+ 	{ cpu_cpu_mask, SD_INIT_NAME(DIE) },
+ 	{ NULL, },
+ };
+ 
  void __init smp_cpus_done(unsigned int max_cpus)
  {
 -	/*
 -	 * We are running pinned to the boot CPU, see rest_init().
 +	cpumask_var_t old_mask;
 +
 +	/* We want the setup_cpu() here to be called from CPU 0, but our
 +	 * init thread may have been "borrowed" by another CPU in the meantime
 +	 * se we pin us down to CPU 0 for a short while
  	 */
 +	alloc_cpumask_var(&old_mask, GFP_NOWAIT);
 +	cpumask_copy(old_mask, tsk_cpus_allowed(current));
 +	set_cpus_allowed_ptr(current, cpumask_of(boot_cpuid));
 +	
  	if (smp_ops && smp_ops->setup_cpu)
  		smp_ops->setup_cpu(boot_cpuid);
  
@@@ -843,15 -1076,19 +881,29 @@@
  	if (smp_ops && smp_ops->bringup_done)
  		smp_ops->bringup_done();
  
 +	/*
 +	 * On a shared LPAR, associativity needs to be requested.
 +	 * Hence, get numa topology before dumping cpu topology
 +	 */
 +	shared_proc_topology_init();
  	dump_numa_cpu_topology();
  
++<<<<<<< HEAD
 +	set_sched_topology(powerpc_topology);
 +
++=======
+ 	/*
+ 	 * If any CPU detects that it's sharing a cache with another CPU then
+ 	 * use the deeper topology that is aware of this sharing.
+ 	 */
+ 	if (shared_caches) {
+ 		pr_info("Using shared cache scheduler topology\n");
+ 		set_sched_topology(power9_topology);
+ 	} else {
+ 		pr_info("Using standard scheduler topology\n");
+ 		set_sched_topology(powerpc_topology);
+ 	}
++>>>>>>> 96d91431d691 (powerpc/smp: Add Power9 scheduler topology)
  }
  
  #ifdef CONFIG_HOTPLUG_CPU
* Unmerged path arch/powerpc/kernel/smp.c
