dm table: make dm_table_supports_discards static

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
Rebuild_CHGLOG: - [md] dm-table: make dm_table_supports_discards static (Mike Snitzer) [1117872]
Rebuild_FUZZ: 97.92%
commit-author Mikulas Patocka <mpatocka@redhat.com>
commit a7ffb6a53391c2690263675f13c79a273301d2b3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/a7ffb6a5.failed

The function dm_table_supports_discards is only called from
dm-table.c:dm_table_set_restrictions().  So move it above
dm_table_set_restrictions and make it static.

	Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
	Signed-off-by: Mike Snitzer <snitzer@redhat.com>
(cherry picked from commit a7ffb6a53391c2690263675f13c79a273301d2b3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/dm-table.c
diff --cc drivers/md/dm-table.c
index 2ae35b2f80fd,3c72bf10e9dc..000000000000
--- a/drivers/md/dm-table.c
+++ b/drivers/md/dm-table.c
@@@ -1618,39 -1654,22 +1655,61 @@@ struct mapped_device *dm_table_get_md(s
  }
  EXPORT_SYMBOL(dm_table_get_md);
  
++<<<<<<< HEAD
 +static int device_discard_capable(struct dm_target *ti, struct dm_dev *dev,
 +				  sector_t start, sector_t len, void *data)
 +{
 +	struct request_queue *q = bdev_get_queue(dev->bdev);
 +
 +	return q && blk_queue_discard(q);
 +}
 +
 +bool dm_table_supports_discards(struct dm_table *t)
 +{
 +	struct dm_target *ti;
 +	unsigned i = 0;
 +
 +	/*
 +	 * Unless any target used by the table set discards_supported,
 +	 * require at least one underlying device to support discards.
 +	 * t->devices includes internal dm devices such as mirror logs
 +	 * so we need to use iterate_devices here, which targets
 +	 * supporting discard selectively must provide.
 +	 */
 +	while (i < dm_table_get_num_targets(t)) {
 +		ti = dm_table_get_target(t, i++);
 +
 +		if (!ti->num_discard_bios)
 +			continue;
 +
 +		if (ti->discards_supported)
 +			return 1;
 +
 +		if (ti->type->iterate_devices &&
 +		    ti->type->iterate_devices(ti, device_discard_capable, NULL))
 +			return 1;
 +	}
 +
 +	return 0;
 +}
++=======
+ void dm_table_run_md_queue_async(struct dm_table *t)
+ {
+ 	struct mapped_device *md;
+ 	struct request_queue *queue;
+ 	unsigned long flags;
+ 
+ 	if (!dm_table_request_based(t))
+ 		return;
+ 
+ 	md = dm_table_get_md(t);
+ 	queue = dm_get_md_queue(md);
+ 	if (queue) {
+ 		spin_lock_irqsave(queue->queue_lock, flags);
+ 		blk_run_queue_async(queue);
+ 		spin_unlock_irqrestore(queue->queue_lock, flags);
+ 	}
+ }
+ EXPORT_SYMBOL(dm_table_run_md_queue_async);
+ 
++>>>>>>> a7ffb6a53391 (dm table: make dm_table_supports_discards static)
* Unmerged path drivers/md/dm-table.c
diff --git a/drivers/md/dm.h b/drivers/md/dm.h
index 88cc58c5871a..09bb47ee313e 100644
--- a/drivers/md/dm.h
+++ b/drivers/md/dm.h
@@ -72,7 +72,6 @@ int dm_table_any_busy_target(struct dm_table *t);
 unsigned dm_table_get_type(struct dm_table *t);
 struct target_type *dm_table_get_immutable_target_type(struct dm_table *t);
 bool dm_table_request_based(struct dm_table *t);
-bool dm_table_supports_discards(struct dm_table *t);
 void dm_table_free_md_mempools(struct dm_table *t);
 struct dm_md_mempools *dm_table_get_md_mempools(struct dm_table *t);
 
