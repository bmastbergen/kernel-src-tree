blk-mq: make ->flush_rq fully transparent to drivers

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
commit-author Christoph Hellwig <hch@lst.de>
commit 8727af4b9d45c7503042e3fbd926c1a173876e9c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/8727af4b.failed

Drivers shouldn't have to care about the block layer setting aside a
request to implement the flush state machine.  We already override the
mq context and tag to make it more transparent, but so far haven't deal
with the driver private data in the request.  Make sure to override this
as well, and while we're at it add a proper helper sitting in blk-mq.c
that implements the full impersonation.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 8727af4b9d45c7503042e3fbd926c1a173876e9c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-flush.c
#	block/blk-mq.h
diff --cc block/blk-flush.c
index 8e8098693aac,c41fc19f75d1..000000000000
--- a/block/blk-flush.c
+++ b/block/blk-flush.c
@@@ -306,23 -306,9 +306,29 @@@ static bool blk_kick_flush(struct reque
  	 */
  	q->flush_pending_idx ^= 1;
  
++<<<<<<< HEAD
 +	if (q->mq_ops) {
 +		struct blk_mq_ctx *ctx = first_rq->mq_ctx;
 +		struct blk_mq_hw_ctx *hctx = q->mq_ops->map_queue(q, ctx->cpu);
 +
 +		blk_mq_rq_init(hctx, q->flush_rq);
 +		q->flush_rq->mq_ctx = ctx;
 +
 +		/*
 +		 * Reuse the tag value from the fist waiting request,
 +		 * with blk-mq the tag is generated during request
 +		 * allocation and drivers can rely on it being inside
 +		 * the range they asked for.
 +		 */
 +		q->flush_rq->tag = first_rq->tag;
 +	} else {
 +		blk_rq_init(q, q->flush_rq);
 +	}
++=======
+ 	blk_rq_init(q, q->flush_rq);
+ 	if (q->mq_ops)
+ 		blk_mq_clone_flush_request(q->flush_rq, first_rq);
++>>>>>>> 8727af4b9d45 (blk-mq: make ->flush_rq fully transparent to drivers)
  
  	q->flush_rq->cmd_type = REQ_TYPE_FS;
  	q->flush_rq->cmd_flags = WRITE_FLUSH | REQ_FLUSH_SEQ;
diff --cc block/blk-mq.h
index ebbe6bac9d61,7964dadb7d64..000000000000
--- a/block/blk-mq.h
+++ b/block/blk-mq.h
@@@ -27,7 -27,8 +27,12 @@@ void blk_mq_run_hw_queue(struct blk_mq_
  void blk_mq_init_flush(struct request_queue *q);
  void blk_mq_drain_queue(struct request_queue *q);
  void blk_mq_free_queue(struct request_queue *q);
++<<<<<<< HEAD
 +void blk_mq_rq_init(struct blk_mq_hw_ctx *hctx, struct request *rq);
++=======
+ void blk_mq_clone_flush_request(struct request *flush_rq,
+ 		struct request *orig_rq);
++>>>>>>> 8727af4b9d45 (blk-mq: make ->flush_rq fully transparent to drivers)
  
  /*
   * CPU hotplug helpers
* Unmerged path block/blk-flush.c
diff --git a/block/blk-mq.c b/block/blk-mq.c
index aa3684343138..212026713f92 100644
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@ -286,6 +286,26 @@ void blk_mq_free_request(struct request *rq)
 	__blk_mq_free_request(hctx, ctx, rq);
 }
 
+/*
+ * Clone all relevant state from a request that has been put on hold in
+ * the flush state machine into the preallocated flush request that hangs
+ * off the request queue.
+ *
+ * For a driver the flush request should be invisible, that's why we are
+ * impersonating the original request here.
+ */
+void blk_mq_clone_flush_request(struct request *flush_rq,
+		struct request *orig_rq)
+{
+	struct blk_mq_hw_ctx *hctx =
+		orig_rq->q->mq_ops->map_queue(orig_rq->q, orig_rq->mq_ctx->cpu);
+
+	flush_rq->mq_ctx = orig_rq->mq_ctx;
+	flush_rq->tag = orig_rq->tag;
+	memcpy(blk_mq_rq_to_pdu(flush_rq), blk_mq_rq_to_pdu(orig_rq),
+		hctx->cmd_size);
+}
+
 bool blk_mq_end_io_partial(struct request *rq, int error, unsigned int nr_bytes)
 {
 	if (blk_update_request(rq, error, blk_rq_bytes(rq)))
* Unmerged path block/blk-mq.h
