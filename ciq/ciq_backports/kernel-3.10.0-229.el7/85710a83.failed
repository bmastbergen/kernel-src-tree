nfs: nfs_page should take a ref on the head req

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
commit-author Weston Andros Adamson <dros@primarydata.com>
commit 85710a837c2026aae80b7c64187edf1f10027b0b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/85710a83.failed

nfs_pages that aren't the the head of a group must take a reference on the
head as long as ->wb_head is set to it. This stops the head from hitting
a refcount of 0 while there is still an active nfs_page for the page group.

This avoids kref warnings in the writeback code when the page group head
is found and referenced.

	Signed-off-by: Weston Andros Adamson <dros@primarydata.com>
	Signed-off-by: Trond Myklebust <trond.myklebust@primarydata.com>
(cherry picked from commit 85710a837c2026aae80b7c64187edf1f10027b0b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/nfs/pagelist.c
diff --cc fs/nfs/pagelist.c
index 5f18707a0319,05a63593a61f..000000000000
--- a/fs/nfs/pagelist.c
+++ b/fs/nfs/pagelist.c
@@@ -133,6 -138,163 +133,166 @@@ nfs_iocounter_wait(struct nfs_io_counte
  	return __nfs_iocounter_wait(c);
  }
  
++<<<<<<< HEAD
++=======
+ static int nfs_wait_bit_uninterruptible(void *word)
+ {
+ 	io_schedule();
+ 	return 0;
+ }
+ 
+ /*
+  * nfs_page_group_lock - lock the head of the page group
+  * @req - request in group that is to be locked
+  *
+  * this lock must be held if modifying the page group list
+  */
+ void
+ nfs_page_group_lock(struct nfs_page *req)
+ {
+ 	struct nfs_page *head = req->wb_head;
+ 
+ 	WARN_ON_ONCE(head != head->wb_head);
+ 
+ 	wait_on_bit_lock(&head->wb_flags, PG_HEADLOCK,
+ 			nfs_wait_bit_uninterruptible,
+ 			TASK_UNINTERRUPTIBLE);
+ }
+ 
+ /*
+  * nfs_page_group_unlock - unlock the head of the page group
+  * @req - request in group that is to be unlocked
+  */
+ void
+ nfs_page_group_unlock(struct nfs_page *req)
+ {
+ 	struct nfs_page *head = req->wb_head;
+ 
+ 	WARN_ON_ONCE(head != head->wb_head);
+ 
+ 	smp_mb__before_atomic();
+ 	clear_bit(PG_HEADLOCK, &head->wb_flags);
+ 	smp_mb__after_atomic();
+ 	wake_up_bit(&head->wb_flags, PG_HEADLOCK);
+ }
+ 
+ /*
+  * nfs_page_group_sync_on_bit_locked
+  *
+  * must be called with page group lock held
+  */
+ static bool
+ nfs_page_group_sync_on_bit_locked(struct nfs_page *req, unsigned int bit)
+ {
+ 	struct nfs_page *head = req->wb_head;
+ 	struct nfs_page *tmp;
+ 
+ 	WARN_ON_ONCE(!test_bit(PG_HEADLOCK, &head->wb_flags));
+ 	WARN_ON_ONCE(test_and_set_bit(bit, &req->wb_flags));
+ 
+ 	tmp = req->wb_this_page;
+ 	while (tmp != req) {
+ 		if (!test_bit(bit, &tmp->wb_flags))
+ 			return false;
+ 		tmp = tmp->wb_this_page;
+ 	}
+ 
+ 	/* true! reset all bits */
+ 	tmp = req;
+ 	do {
+ 		clear_bit(bit, &tmp->wb_flags);
+ 		tmp = tmp->wb_this_page;
+ 	} while (tmp != req);
+ 
+ 	return true;
+ }
+ 
+ /*
+  * nfs_page_group_sync_on_bit - set bit on current request, but only
+  *   return true if the bit is set for all requests in page group
+  * @req - request in page group
+  * @bit - PG_* bit that is used to sync page group
+  */
+ bool nfs_page_group_sync_on_bit(struct nfs_page *req, unsigned int bit)
+ {
+ 	bool ret;
+ 
+ 	nfs_page_group_lock(req);
+ 	ret = nfs_page_group_sync_on_bit_locked(req, bit);
+ 	nfs_page_group_unlock(req);
+ 
+ 	return ret;
+ }
+ 
+ /*
+  * nfs_page_group_init - Initialize the page group linkage for @req
+  * @req - a new nfs request
+  * @prev - the previous request in page group, or NULL if @req is the first
+  *         or only request in the group (the head).
+  */
+ static inline void
+ nfs_page_group_init(struct nfs_page *req, struct nfs_page *prev)
+ {
+ 	WARN_ON_ONCE(prev == req);
+ 
+ 	if (!prev) {
+ 		/* a head request */
+ 		req->wb_head = req;
+ 		req->wb_this_page = req;
+ 	} else {
+ 		/* a subrequest */
+ 		WARN_ON_ONCE(prev->wb_this_page != prev->wb_head);
+ 		WARN_ON_ONCE(!test_bit(PG_HEADLOCK, &prev->wb_head->wb_flags));
+ 		req->wb_head = prev->wb_head;
+ 		req->wb_this_page = prev->wb_this_page;
+ 		prev->wb_this_page = req;
+ 
+ 		/* All subrequests take a ref on the head request until
+ 		 * nfs_page_group_destroy is called */
+ 		kref_get(&req->wb_head->wb_kref);
+ 
+ 		/* grab extra ref if head request has extra ref from
+ 		 * the write/commit path to handle handoff between write
+ 		 * and commit lists */
+ 		if (test_bit(PG_INODE_REF, &prev->wb_head->wb_flags)) {
+ 			set_bit(PG_INODE_REF, &req->wb_flags);
+ 			kref_get(&req->wb_kref);
+ 		}
+ 	}
+ }
+ 
+ /*
+  * nfs_page_group_destroy - sync the destruction of page groups
+  * @req - request that no longer needs the page group
+  *
+  * releases the page group reference from each member once all
+  * members have called this function.
+  */
+ static void
+ nfs_page_group_destroy(struct kref *kref)
+ {
+ 	struct nfs_page *req = container_of(kref, struct nfs_page, wb_kref);
+ 	struct nfs_page *tmp, *next;
+ 
+ 	/* subrequests must release the ref on the head request */
+ 	if (req->wb_head != req)
+ 		nfs_release_request(req->wb_head);
+ 
+ 	if (!nfs_page_group_sync_on_bit(req, PG_TEARDOWN))
+ 		return;
+ 
+ 	tmp = req;
+ 	do {
+ 		next = tmp->wb_this_page;
+ 		/* unlink and free */
+ 		tmp->wb_this_page = tmp;
+ 		tmp->wb_head = tmp;
+ 		nfs_free_request(tmp);
+ 		tmp = next;
+ 	} while (tmp != req);
+ }
+ 
++>>>>>>> 85710a837c20 (nfs: nfs_page should take a ref on the head req)
  /**
   * nfs_create_request - Create an NFS read/write request.
   * @ctx: open context to use
* Unmerged path fs/nfs/pagelist.c
