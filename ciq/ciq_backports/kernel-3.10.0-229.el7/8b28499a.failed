smp: Consolidate the various smp_call_function_single() declensions

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
commit-author Frederic Weisbecker <fweisbec@gmail.com>
commit 8b28499a71d3431c9128abc743e2d2bfbdae3ed4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/8b28499a.failed

__smp_call_function_single() and smp_call_function_single() share some
code that can be factorized: execute inline when the target is local,
check if the target is online, lock the csd, call generic_exec_single().

Lets move the common parts to generic_exec_single().

	Reviewed-by: Jan Kara <jack@suse.cz>
	Cc: Andrew Morton <akpm@linux-foundation.org>
	Cc: Christoph Hellwig <hch@infradead.org>
	Cc: Ingo Molnar <mingo@kernel.org>
	Cc: Jan Kara <jack@suse.cz>
	Cc: Jens Axboe <axboe@fb.com>
	Signed-off-by: Frederic Weisbecker <fweisbec@gmail.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 8b28499a71d3431c9128abc743e2d2bfbdae3ed4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/smp.c
diff --cc kernel/smp.c
index 74100ac030d3,64bb0d48e96f..000000000000
--- a/kernel/smp.c
+++ b/kernel/smp.c
@@@ -140,11 -124,35 +142,41 @@@ static DEFINE_PER_CPU_SHARED_ALIGNED(st
   * for execution on the given CPU. data must already have
   * ->func, ->info, and ->flags set.
   */
- static void generic_exec_single(int cpu, struct call_single_data *csd, int wait)
+ static int generic_exec_single(int cpu, struct call_single_data *csd,
+ 			       smp_call_func_t func, void *info, int wait)
  {
++<<<<<<< HEAD
 +	struct call_single_queue *dst = &per_cpu(call_single_queue, cpu);
 +	unsigned long flags;
 +	int ipi;
++=======
+ 	struct call_single_data csd_stack = { .flags = 0 };
+ 	unsigned long flags;
+ 
+ 
+ 	if (cpu == smp_processor_id()) {
+ 		local_irq_save(flags);
+ 		func(info);
+ 		local_irq_restore(flags);
+ 		return 0;
+ 	}
+ 
+ 
+ 	if ((unsigned)cpu >= nr_cpu_ids || !cpu_online(cpu))
+ 		return -ENXIO;
+ 
+ 
+ 	if (!csd) {
+ 		csd = &csd_stack;
+ 		if (!wait)
+ 			csd = &__get_cpu_var(csd_data);
+ 	}
+ 
+ 	csd_lock(csd);
+ 
+ 	csd->func = func;
+ 	csd->info = info;
++>>>>>>> 8b28499a71d3 (smp: Consolidate the various smp_call_function_single() declensions)
  
  	if (wait)
  		csd->flags |= CSD_FLAG_WAIT;
@@@ -317,11 -290,10 +326,16 @@@ EXPORT_SYMBOL_GPL(smp_call_function_any
   * pre-allocated data structure. Useful for embedding @data inside
   * other structures, for instance.
   */
 -int __smp_call_function_single(int cpu, struct call_single_data *csd, int wait)
 +void __smp_call_function_single(int cpu, struct call_single_data *csd,
 +				int wait)
  {
++<<<<<<< HEAD
 +	unsigned int this_cpu;
 +	unsigned long flags;
++=======
+ 	int err = 0;
+ 	int this_cpu;
++>>>>>>> 8b28499a71d3 (smp: Consolidate the various smp_call_function_single() declensions)
  
  	this_cpu = get_cpu();
  	/*
@@@ -330,20 -302,15 +344,27 @@@
  	 * send smp call function interrupt to this cpu and as such deadlocks
  	 * can't happen.
  	 */
- 	WARN_ON_ONCE(cpu_online(smp_processor_id()) && wait && irqs_disabled()
+ 	WARN_ON_ONCE(cpu_online(this_cpu) && wait && irqs_disabled()
  		     && !oops_in_progress);
  
++<<<<<<< HEAD
 +	if (cpu == this_cpu) {
 +		local_irq_save(flags);
 +		csd->func(csd->info);
 +		local_irq_restore(flags);
 +	} else {
 +		csd_lock(csd);
 +		generic_exec_single(cpu, csd, wait);
 +	}
 +	put_cpu();
++=======
+ 	err = generic_exec_single(cpu, csd, csd->func, csd->info, wait);
+ 	put_cpu();
+ 
+ 	return err;
++>>>>>>> 8b28499a71d3 (smp: Consolidate the various smp_call_function_single() declensions)
  }
 -EXPORT_SYMBOL_GPL(__smp_call_function_single);
 +EXPORT_SYMBOL(__smp_call_function_single);
  
  /**
   * smp_call_function_many(): Run a function on a set of other CPUs.
* Unmerged path kernel/smp.c
