mtip32xx: convert to use blk-mq

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
commit-author Jens Axboe <axboe@fb.com>
commit ffc771b3ca8b2c03e5e9faa6335b4862108f111f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/ffc771b3.failed

This rips out timeout handling, requeueing, etc in converting
it to use blk-mq instead.

	Acked-by: Asai Thambi S P <asamymuthupa@micron.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit ffc771b3ca8b2c03e5e9faa6335b4862108f111f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/block/mtip32xx/mtip32xx.c
diff --cc drivers/block/mtip32xx/mtip32xx.c
index ab3b42d18772,3a0882ee1642..000000000000
--- a/drivers/block/mtip32xx/mtip32xx.c
+++ b/drivers/block/mtip32xx/mtip32xx.c
@@@ -248,86 -225,28 +225,103 @@@ static struct mtip_cmd *mtip_cmd_from_t
   *	None
   */
  static void mtip_async_complete(struct mtip_port *port,
- 				int tag,
- 				void *data,
- 				int status)
+ 				int tag, struct mtip_cmd *cmd, int status)
  {
++<<<<<<< HEAD
 +	struct mtip_cmd *command;
 +	struct driver_data *dd = data;
 +	int cb_status = status ? -EIO : 0;
++=======
+ 	struct driver_data *dd = port->dd;
+ 	struct request *rq;
++>>>>>>> ffc771b3ca8b (mtip32xx: convert to use blk-mq)
  
  	if (unlikely(!dd) || unlikely(!port))
  		return;
  
++<<<<<<< HEAD
 +	command = &port->commands[tag];
 +
++=======
++>>>>>>> ffc771b3ca8b (mtip32xx: convert to use blk-mq)
  	if (unlikely(status == PORT_IRQ_TF_ERR)) {
  		dev_warn(&port->dd->pdev->dev,
  			"Command tag %d failed due to TFE\n", tag);
  	}
  
  	/* Unmap the DMA scatter list entries */
++<<<<<<< HEAD
 +	dma_unmap_sg(&dd->pdev->dev,
 +		command->sg,
 +		command->scatter_ents,
 +		command->direction);
 +
 +	/* Upper layer callback */
 +	if (likely(command->async_callback))
 +		command->async_callback(command->async_data, cb_status);
 +
 +	command->async_callback = NULL;
 +	command->comp_func = NULL;
 +
 +	/* Clear the allocated and active bits for the command */
 +	atomic_set(&port->commands[tag].active, 0);
 +	release_slot(port, tag);
 +
 +	up(&port->cmd_slot);
 +}
 +
 +/*
 + * This function is called for clean the pending command in the
 + * command slot during the surprise removal of device and return
 + * error to the upper layer.
 + *
 + * @dd Pointer to the DRIVER_DATA structure.
 + *
 + * return value
 + *	None
 + */
 +static void mtip_command_cleanup(struct driver_data *dd)
 +{
 +	int tag = 0;
 +	struct mtip_cmd *cmd;
 +	struct mtip_port *port = dd->port;
 +	unsigned int num_cmd_slots = dd->slot_groups * 32;
 +
 +	if (!test_bit(MTIP_DDF_INIT_DONE_BIT, &dd->dd_flag))
 +		return;
 +
 +	if (!port)
 +		return;
 +
 +	cmd = &port->commands[MTIP_TAG_INTERNAL];
 +	if (atomic_read(&cmd->active))
 +		if (readl(port->cmd_issue[MTIP_TAG_INTERNAL]) &
 +					(1 << MTIP_TAG_INTERNAL))
 +			if (cmd->comp_func)
 +				cmd->comp_func(port, MTIP_TAG_INTERNAL,
 +					 cmd->comp_data, -ENODEV);
 +
 +	while (1) {
 +		tag = find_next_bit(port->allocated, num_cmd_slots, tag);
 +		if (tag >= num_cmd_slots)
 +			break;
 +
 +		cmd = &port->commands[tag];
 +		if (atomic_read(&cmd->active))
 +			mtip_async_complete(port, tag, dd, -ENODEV);
 +	}
 +
 +	set_bit(MTIP_DDF_CLEANUP_BIT, &dd->dd_flag);
++=======
+ 	dma_unmap_sg(&dd->pdev->dev, cmd->sg, cmd->scatter_ents, cmd->direction);
+ 
+ 	rq = mtip_rq_from_tag(dd, tag);
+ 
+ 	if (unlikely(cmd->unaligned))
+ 		up(&port->cmd_slot_unal);
+ 
+ 	blk_mq_end_io(rq, status ? -EIO : 0);
++>>>>>>> ffc771b3ca8b (mtip32xx: convert to use blk-mq)
  }
  
  /*
@@@ -648,121 -561,6 +636,124 @@@ static void print_tags(struct driver_da
  }
  
  /*
++<<<<<<< HEAD
 + * Called periodically to see if any read/write commands are
 + * taking too long to complete.
 + *
 + * @data Pointer to the PORT data structure.
 + *
 + * return value
 + *	None
 + */
 +static void mtip_timeout_function(unsigned long int data)
 +{
 +	struct mtip_port *port = (struct mtip_port *) data;
 +	struct host_to_dev_fis *fis;
 +	struct mtip_cmd *command;
 +	int tag, cmdto_cnt = 0;
 +	unsigned int bit, group;
 +	unsigned int num_command_slots;
 +	unsigned long to, tagaccum[SLOTBITS_IN_LONGS];
 +
 +	if (unlikely(!port))
 +		return;
 +
 +	if (unlikely(port->dd->sr))
 +		return;
 +
 +	if (test_bit(MTIP_DDF_RESUME_BIT, &port->dd->dd_flag)) {
 +		mod_timer(&port->cmd_timer,
 +			jiffies + msecs_to_jiffies(30000));
 +		return;
 +	}
 +	/* clear the tag accumulator */
 +	memset(tagaccum, 0, SLOTBITS_IN_LONGS * sizeof(long));
 +	num_command_slots = port->dd->slot_groups * 32;
 +
 +	for (tag = 0; tag < num_command_slots; tag++) {
 +		/*
 +		 * Skip internal command slot as it has
 +		 * its own timeout mechanism
 +		 */
 +		if (tag == MTIP_TAG_INTERNAL)
 +			continue;
 +
 +		if (atomic_read(&port->commands[tag].active) &&
 +		   (time_after(jiffies, port->commands[tag].comp_time))) {
 +			group = tag >> 5;
 +			bit = tag & 0x1F;
 +
 +			command = &port->commands[tag];
 +			fis = (struct host_to_dev_fis *) command->command;
 +
 +			set_bit(tag, tagaccum);
 +			cmdto_cnt++;
 +			if (cmdto_cnt == 1)
 +				set_bit(MTIP_PF_EH_ACTIVE_BIT, &port->flags);
 +
 +			/*
 +			 * Clear the completed bit. This should prevent
 +			 *  any interrupt handlers from trying to retire
 +			 *  the command.
 +			 */
 +			writel(1 << bit, port->completed[group]);
 +
 +			/* Unmap the DMA scatter list entries */
 +			dma_unmap_sg(&port->dd->pdev->dev,
 +					command->sg,
 +					command->scatter_ents,
 +					command->direction);
 +
 +			/* Call the async completion callback. */
 +			if (likely(command->async_callback))
 +				command->async_callback(command->async_data,
 +							 -EIO);
 +			command->async_callback = NULL;
 +			command->comp_func = NULL;
 +
 +			/*
 +			 * Clear the allocated bit and active tag for the
 +			 * command.
 +			 */
 +			atomic_set(&port->commands[tag].active, 0);
 +			release_slot(port, tag);
 +
 +			up(&port->cmd_slot);
 +		}
 +	}
 +
 +	if (cmdto_cnt) {
 +		print_tags(port->dd, "timed out", tagaccum, cmdto_cnt);
 +		if (!test_bit(MTIP_PF_IC_ACTIVE_BIT, &port->flags)) {
 +			mtip_device_reset(port->dd);
 +			wake_up_interruptible(&port->svc_wait);
 +		}
 +		clear_bit(MTIP_PF_EH_ACTIVE_BIT, &port->flags);
 +	}
 +
 +	if (port->ic_pause_timer) {
 +		to  = port->ic_pause_timer + msecs_to_jiffies(1000);
 +		if (time_after(jiffies, to)) {
 +			if (!test_bit(MTIP_PF_IC_ACTIVE_BIT, &port->flags)) {
 +				port->ic_pause_timer = 0;
 +				clear_bit(MTIP_PF_SE_ACTIVE_BIT, &port->flags);
 +				clear_bit(MTIP_PF_DM_ACTIVE_BIT, &port->flags);
 +				clear_bit(MTIP_PF_IC_ACTIVE_BIT, &port->flags);
 +				wake_up_interruptible(&port->svc_wait);
 +			}
 +
 +
 +		}
 +	}
 +
 +	/* Restart the timer */
 +	mod_timer(&port->cmd_timer,
 +		jiffies + msecs_to_jiffies(MTIP_TIMEOUT_CHECK_PERIOD));
 +}
 +
 +/*
++=======
++>>>>>>> ffc771b3ca8b (mtip32xx: convert to use blk-mq)
   * Internal command completion callback function.
   *
   * This function is normally called by the driver ISR when an internal
@@@ -4025,16 -3671,14 +3864,22 @@@ static const struct block_device_operat
   *
   * @queue Pointer to the request queue. Unused other than to obtain
   *              the driver data structure.
-  * @bio   Pointer to the BIO.
+  * @rq    Pointer to the request.
   *
   */
- static void mtip_make_request(struct request_queue *queue, struct bio *bio)
+ static int mtip_submit_request(struct blk_mq_hw_ctx *hctx, struct request *rq)
  {
++<<<<<<< HEAD
 +	struct driver_data *dd = queue->queuedata;
 +	struct scatterlist *sg;
 +	struct bio_vec *bvec;
 +	int i, nents = 0;
 +	int tag = 0, unaligned = 0;
++=======
+ 	struct driver_data *dd = hctx->queue->queuedata;
+ 	struct mtip_cmd *cmd = blk_mq_rq_to_pdu(rq);
+ 	unsigned int nents;
++>>>>>>> ffc771b3ca8b (mtip32xx: convert to use blk-mq)
  
  	if (unlikely(dd->dd_flag & MTIP_DDF_STOP_IO)) {
  		if (unlikely(test_bit(MTIP_DDF_REMOVE_PENDING_BIT,
@@@ -4048,75 -3690,121 +3891,172 @@@
  		}
  		if (unlikely(test_bit(MTIP_DDF_WRITE_PROTECT_BIT,
  							&dd->dd_flag) &&
- 				bio_data_dir(bio))) {
- 			bio_endio(bio, -ENODATA);
- 			return;
- 		}
- 		if (unlikely(test_bit(MTIP_DDF_SEC_LOCK_BIT, &dd->dd_flag))) {
- 			bio_endio(bio, -ENODATA);
- 			return;
- 		}
- 		if (test_bit(MTIP_DDF_REBUILD_FAILED_BIT, &dd->dd_flag)) {
- 			bio_endio(bio, -ENXIO);
- 			return;
+ 				rq_data_dir(rq))) {
+ 			return -ENODATA;
  		}
+ 		if (unlikely(test_bit(MTIP_DDF_SEC_LOCK_BIT, &dd->dd_flag)))
+ 			return -ENODATA;
+ 		if (test_bit(MTIP_DDF_REBUILD_FAILED_BIT, &dd->dd_flag))
+ 			return -ENXIO;
  	}
  
++<<<<<<< HEAD
 +	if (unlikely(bio->bi_rw & REQ_DISCARD)) {
 +		bio_endio(bio, mtip_send_trim(dd, bio->bi_sector,
 +						bio_sectors(bio)));
 +		return;
- 	}
++=======
+ 	if (rq->cmd_flags & REQ_DISCARD) {
+ 		int err;
  
- 	if (unlikely(!bio_has_data(bio))) {
- 		blk_queue_flush(queue, 0);
- 		bio_endio(bio, 0);
- 		return;
+ 		err = mtip_send_trim(dd, blk_rq_pos(rq), blk_rq_sectors(rq));
+ 		blk_mq_end_io(rq, err);
+ 		return 0;
++>>>>>>> ffc771b3ca8b (mtip32xx: convert to use blk-mq)
  	}
  
+ 	/* Create the scatter list for this request. */
+ 	nents = blk_rq_map_sg(hctx->queue, rq, cmd->sg);
+ 
++<<<<<<< HEAD
 +	if (bio_data_dir(bio) == WRITE && bio_sectors(bio) <= 64 &&
 +							dd->unal_qdepth) {
 +		if (bio->bi_sector % 8 != 0) /* Unaligned on 4k boundaries */
 +			unaligned = 1;
 +		else if (bio_sectors(bio) % 8 != 0) /* Aligned but not 4k/8k */
 +			unaligned = 1;
 +	}
 +
 +	sg = mtip_hw_get_scatterlist(dd, &tag, unaligned);
 +	if (likely(sg != NULL)) {
 +		blk_queue_bounce(queue, &bio);
 +
 +		if (unlikely((bio)->bi_vcnt > MTIP_MAX_SG)) {
 +			dev_warn(&dd->pdev->dev,
 +				"Maximum number of SGL entries exceeded\n");
 +			bio_io_error(bio);
 +			mtip_hw_release_scatterlist(dd, tag, unaligned);
 +			return;
 +		}
 +
 +		/* Create the scatter list for this bio. */
 +		bio_for_each_segment(bvec, bio, i) {
 +			sg_set_page(&sg[nents],
 +					bvec->bv_page,
 +					bvec->bv_len,
 +					bvec->bv_offset);
 +			nents++;
 +		}
 +
 +		/* Issue the read/write. */
 +		mtip_hw_submit_io(dd,
 +				bio->bi_sector,
 +				bio_sectors(bio),
 +				nents,
 +				tag,
 +				bio_endio,
 +				bio,
 +				bio_data_dir(bio),
 +				unaligned);
 +	} else
 +		bio_io_error(bio);
++=======
+ 	/* Issue the read/write. */
+ 	mtip_hw_submit_io(dd, rq, cmd, nents, hctx);
+ 	return 0;
++>>>>>>> ffc771b3ca8b (mtip32xx: convert to use blk-mq)
+ }
+ 
+ static bool mtip_check_unal_depth(struct blk_mq_hw_ctx *hctx,
+ 				  struct request *rq)
+ {
+ 	struct driver_data *dd = hctx->queue->queuedata;
+ 	struct mtip_cmd *cmd = blk_mq_rq_to_pdu(rq);
+ 
+ 	if (!dd->unal_qdepth || rq_data_dir(rq) == READ)
+ 		return false;
+ 
+ 	/*
+ 	 * If unaligned depth must be limited on this controller, mark it
+ 	 * as unaligned if the IO isn't on a 4k boundary (start of length).
+ 	 */
+ 	if (blk_rq_sectors(rq) <= 64) {
+ 		if ((blk_rq_pos(rq) & 7) || (blk_rq_sectors(rq) & 7))
+ 			cmd->unaligned = 1;
+ 	}
+ 
+ 	if (cmd->unaligned && down_trylock(&dd->port->cmd_slot_unal))
+ 		return true;
+ 
+ 	return false;
+ }
+ 
+ static int mtip_queue_rq(struct blk_mq_hw_ctx *hctx, struct request *rq)
+ {
+ 	int ret;
+ 
+ 	if (mtip_check_unal_depth(hctx, rq))
+ 		return BLK_MQ_RQ_QUEUE_BUSY;
+ 
+ 	ret = mtip_submit_request(hctx, rq);
+ 	if (!ret)
+ 		return BLK_MQ_RQ_QUEUE_OK;
+ 
+ 	rq->errors = ret;
+ 	return BLK_MQ_RQ_QUEUE_ERROR;
+ }
+ 
+ static void mtip_free_cmd(void *data, struct request *rq,
+ 			  unsigned int hctx_idx, unsigned int request_idx)
+ {
+ 	struct driver_data *dd = data;
+ 	struct mtip_cmd *cmd = blk_mq_rq_to_pdu(rq);
+ 
+ 	if (!cmd->command)
+ 		return;
+ 
+ 	dmam_free_coherent(&dd->pdev->dev, CMD_DMA_ALLOC_SZ,
+ 				cmd->command, cmd->command_dma);
  }
  
+ static int mtip_init_cmd(void *data, struct request *rq, unsigned int hctx_idx,
+ 			 unsigned int request_idx, unsigned int numa_node)
+ {
+ 	struct driver_data *dd = data;
+ 	struct mtip_cmd *cmd = blk_mq_rq_to_pdu(rq);
+ 	u32 host_cap_64 = readl(dd->mmio + HOST_CAP) & HOST_CAP_64;
+ 
+ 	cmd->command = dmam_alloc_coherent(&dd->pdev->dev, CMD_DMA_ALLOC_SZ,
+ 			&cmd->command_dma, GFP_KERNEL);
+ 	if (!cmd->command)
+ 		return -ENOMEM;
+ 
+ 	memset(cmd->command, 0, CMD_DMA_ALLOC_SZ);
+ 
+ 	/* Point the command headers at the command tables. */
+ 	cmd->command_header = dd->port->command_list +
+ 				(sizeof(struct mtip_cmd_hdr) * request_idx);
+ 	cmd->command_header_dma = dd->port->command_list_dma +
+ 				(sizeof(struct mtip_cmd_hdr) * request_idx);
+ 
+ 	if (host_cap_64)
+ 		cmd->command_header->ctbau = __force_bit2int cpu_to_le32((cmd->command_dma >> 16) >> 16);
+ 
+ 	cmd->command_header->ctba = __force_bit2int cpu_to_le32(cmd->command_dma & 0xFFFFFFFF);
+ 
+ 	sg_init_table(cmd->sg, MTIP_MAX_SG);
+ 	return 0;
+ }
+ 
+ static struct blk_mq_ops mtip_mq_ops = {
+ 	.queue_rq	= mtip_queue_rq,
+ 	.map_queue	= blk_mq_map_queue,
+ 	.alloc_hctx	= blk_mq_alloc_single_hw_queue,
+ 	.free_hctx	= blk_mq_free_single_hw_queue,
+ 	.init_request	= mtip_init_cmd,
+ 	.exit_request	= mtip_free_cmd,
+ };
+ 
  /*
   * Block layer initialization function.
   *
* Unmerged path drivers/block/mtip32xx/mtip32xx.c
diff --git a/drivers/block/mtip32xx/mtip32xx.h b/drivers/block/mtip32xx/mtip32xx.h
index 54174cb32feb..ec44d414062e 100644
--- a/drivers/block/mtip32xx/mtip32xx.h
+++ b/drivers/block/mtip32xx/mtip32xx.h
@@ -331,12 +331,8 @@ struct mtip_cmd {
 	 */
 	void (*comp_func)(struct mtip_port *port,
 				int tag,
-				void *data,
+				struct mtip_cmd *cmd,
 				int status);
-	/* Additional callback function that may be called by comp_func() */
-	void (*async_callback)(void *data, int status);
-
-	void *async_data; /* Addl. data passed to async_callback() */
 
 	int scatter_ents; /* Number of scatter list entries used */
 
@@ -347,10 +343,6 @@ struct mtip_cmd {
 	int retries; /* The number of retries left for this command. */
 
 	int direction; /* Data transfer direction */
-
-	unsigned long comp_time; /* command completion time, in jiffies */
-
-	atomic_t active; /* declares if this command sent to the drive. */
 };
 
 /* Structure used to describe a port. */
@@ -436,12 +428,6 @@ struct mtip_port {
 	 * or error handling is active
 	 */
 	unsigned long cmds_to_issue[SLOTBITS_IN_LONGS];
-	/*
-	 * Array of command slots. Structure includes pointers to the
-	 * command header and command table, and completion function and data
-	 * pointers.
-	 */
-	struct mtip_cmd commands[MTIP_MAX_COMMAND_SLOTS];
 	/* Used by mtip_service_thread to wait for an event */
 	wait_queue_head_t svc_wait;
 	/*
@@ -452,13 +438,7 @@ struct mtip_port {
 	/*
 	 * Timer used to complete commands that have been active for too long.
 	 */
-	struct timer_list cmd_timer;
 	unsigned long ic_pause_timer;
-	/*
-	 * Semaphore used to block threads if there are no
-	 * command slots available.
-	 */
-	struct semaphore cmd_slot;
 
 	/* Semaphore to control queue depth of unaligned IOs */
 	struct semaphore cmd_slot_unal;
@@ -485,6 +465,8 @@ struct driver_data {
 
 	struct request_queue *queue; /* Our request queue. */
 
+	struct blk_mq_tag_set tags; /* blk_mq tags */
+
 	struct mtip_port *port; /* Pointer to the port data structure. */
 
 	unsigned product_type; /* magic value declaring the product type */
