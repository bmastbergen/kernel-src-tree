KVM: PPC: Load/save FP/VMX/VSX state directly to/from vcpu struct

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
Rebuild_CHGLOG: - [virt] kvm/ppc: Load/save FP/VMX/VSX state directly to/from vcpu struct (David Gibson) [1123145 1123133 1123367]
Rebuild_FUZZ: 97.67%
commit-author Paul Mackerras <paulus@samba.org>
commit 99dae3bad28d8fdd32b7bfdd5e2ec7bb2d4d019d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/99dae3ba.failed

Now that we have the vcpu floating-point and vector state stored in
the same type of struct as the main kernel uses, we can load that
state directly from the vcpu struct instead of having extra copies
to/from the thread_struct.  Similarly, when the guest state needs to
be saved, we can have it saved it directly to the vcpu struct by
setting the current->thread.fp_save_area and current->thread.vr_save_area
pointers.  That also means that we don't need to back up and restore
userspace's FP/vector state.  This all makes the code simpler and
faster.

Note that it's not necessary to save or modify current->thread.fpexc_mode,
since nothing in KVM uses or is affected by its value.  Nor is it
necessary to touch used_vr or used_vsr.

	Signed-off-by: Paul Mackerras <paulus@samba.org>
	Signed-off-by: Alexander Graf <agraf@suse.de>
(cherry picked from commit 99dae3bad28d8fdd32b7bfdd5e2ec7bb2d4d019d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/kvm/book3s_pr.c
#	arch/powerpc/kvm/booke.c
#	arch/powerpc/kvm/booke.h
diff --cc arch/powerpc/kvm/book3s_pr.c
index 8956df8d25a8,aedba681bb94..000000000000
--- a/arch/powerpc/kvm/book3s_pr.c
+++ b/arch/powerpc/kvm/book3s_pr.c
@@@ -655,16 -661,16 +655,28 @@@ static int kvmppc_handle_ext(struct kvm
  #endif
  
  	if (msr & MSR_FP) {
++<<<<<<< HEAD
 +		t->fp_state = vcpu->arch.fp;
 +		t->fpexc_mode = 0;
 +		kvmppc_load_up_fpu();
++=======
+ 		enable_kernel_fp();
+ 		load_fp_state(&vcpu->arch.fp);
+ 		t->fp_save_area = &vcpu->arch.fp;
++>>>>>>> 99dae3bad28d (KVM: PPC: Load/save FP/VMX/VSX state directly to/from vcpu struct)
  	}
  
  	if (msr & MSR_VEC) {
  #ifdef CONFIG_ALTIVEC
++<<<<<<< HEAD
 +		t->vr_state = vcpu->arch.vr;
 +		t->vrsave = -1;
 +		kvmppc_load_up_altivec();
++=======
+ 		enable_kernel_altivec();
+ 		load_vr_state(&vcpu->arch.vr);
+ 		t->vr_save_area = &vcpu->arch.vr;
++>>>>>>> 99dae3bad28d (KVM: PPC: Load/save FP/VMX/VSX state directly to/from vcpu struct)
  #endif
  	}
  
@@@ -687,11 -693,15 +699,23 @@@ static void kvmppc_handle_lost_ext(stru
  	if (!lost_ext)
  		return;
  
++<<<<<<< HEAD
 +	if (lost_ext & MSR_FP)
 +		kvmppc_load_up_fpu();
 +#ifdef CONFIG_ALTIVEC
 +	if (lost_ext & MSR_VEC)
 +		kvmppc_load_up_altivec();
++=======
+ 	if (lost_ext & MSR_FP) {
+ 		enable_kernel_fp();
+ 		load_fp_state(&vcpu->arch.fp);
+ 	}
+ #ifdef CONFIG_ALTIVEC
+ 	if (lost_ext & MSR_VEC) {
+ 		enable_kernel_altivec();
+ 		load_vr_state(&vcpu->arch.vr);
+ 	}
++>>>>>>> 99dae3bad28d (KVM: PPC: Load/save FP/VMX/VSX state directly to/from vcpu struct)
  #endif
  	current->thread.regs->msr |= lost_ext;
  }
@@@ -1192,20 -1199,12 +1216,12 @@@ void kvmppc_core_vcpu_free(struct kvm_v
  	kmem_cache_free(kvm_vcpu_cache, vcpu);
  }
  
 -static int kvmppc_vcpu_run_pr(struct kvm_run *kvm_run, struct kvm_vcpu *vcpu)
 +int kvmppc_vcpu_run(struct kvm_run *kvm_run, struct kvm_vcpu *vcpu)
  {
  	int ret;
- 	struct thread_fp_state fp;
- 	int fpexc_mode;
  #ifdef CONFIG_ALTIVEC
- 	struct thread_vr_state vr;
  	unsigned long uninitialized_var(vrsave);
- 	int used_vr;
- #endif
- #ifdef CONFIG_VSX
- 	int used_vsr;
  #endif
- 	ulong ext_msr;
  
  	/* Check if we can run the vcpu at all */
  	if (!vcpu->arch.sane) {
diff --cc arch/powerpc/kvm/booke.c
index 6e46ad5b1f8d,a983ccaf3cce..000000000000
--- a/arch/powerpc/kvm/booke.c
+++ b/arch/powerpc/kvm/booke.c
@@@ -655,10 -681,7 +655,14 @@@ int kvmppc_core_check_requests(struct k
  int kvmppc_vcpu_run(struct kvm_run *kvm_run, struct kvm_vcpu *vcpu)
  {
  	int ret, s;
++<<<<<<< HEAD
 +#ifdef CONFIG_PPC_FPU
 +	struct thread_fp_state fp;
 +	int fpexc_mode;
 +#endif
++=======
+ 	struct thread_struct thread;
++>>>>>>> 99dae3bad28d (KVM: PPC: Load/save FP/VMX/VSX state directly to/from vcpu struct)
  
  	if (!vcpu->arch.sane) {
  		kvm_run->exit_reason = KVM_EXIT_INTERNAL_ERROR;
diff --cc arch/powerpc/kvm/booke.h
index 5fd1ba693579,b632cd35919b..000000000000
--- a/arch/powerpc/kvm/booke.h
+++ b/arch/powerpc/kvm/booke.h
@@@ -112,7 -136,9 +112,13 @@@ static inline void kvmppc_load_guest_fp
  {
  #ifdef CONFIG_PPC_FPU
  	if (vcpu->fpu_active && !(current->thread.regs->msr & MSR_FP)) {
++<<<<<<< HEAD
 +		load_up_fpu();
++=======
+ 		enable_kernel_fp();
+ 		load_fp_state(&vcpu->arch.fp);
+ 		current->thread.fp_save_area = &vcpu->arch.fp;
++>>>>>>> 99dae3bad28d (KVM: PPC: Load/save FP/VMX/VSX state directly to/from vcpu struct)
  		current->thread.regs->msr |= MSR_FP;
  	}
  #endif
@@@ -127,6 -153,12 +133,7 @@@ static inline void kvmppc_save_guest_fp
  #ifdef CONFIG_PPC_FPU
  	if (vcpu->fpu_active && (current->thread.regs->msr & MSR_FP))
  		giveup_fpu(current);
+ 	current->thread.fp_save_area = NULL;
  #endif
  }
 -
 -static inline void kvmppc_clear_dbsr(void)
 -{
 -	mtspr(SPRN_DBSR, mfspr(SPRN_DBSR));
 -}
  #endif /* __KVM_BOOKE_H__ */
* Unmerged path arch/powerpc/kvm/book3s_pr.c
* Unmerged path arch/powerpc/kvm/booke.c
* Unmerged path arch/powerpc/kvm/booke.h
