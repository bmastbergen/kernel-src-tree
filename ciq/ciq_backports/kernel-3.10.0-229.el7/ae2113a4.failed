KVM: PPC: Book3S: Allow only implemented hcalls to be enabled or disabled

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
Rebuild_CHGLOG: - [virt] kvm/ppc: book3s - Allow only implemented hcalls to be enabled or disabled (David Gibson) [1123145 1123133 1123367]
Rebuild_FUZZ: 95.89%
commit-author Paul Mackerras <paulus@samba.org>
commit ae2113a4f1a6cd5a3cd3d75f394547922758e9ac
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/ae2113a4.failed

This adds code to check that when the KVM_CAP_PPC_ENABLE_HCALL
capability is used to enable or disable in-kernel handling of an
hcall, that the hcall is actually implemented by the kernel.
If not an EINVAL error is returned.

This also checks the default-enabled list of hcalls and prints a
warning if any hcall there is not actually implemented.

	Signed-off-by: Paul Mackerras <paulus@samba.org>
	Signed-off-by: Alexander Graf <agraf@suse.de>
(cherry picked from commit ae2113a4f1a6cd5a3cd3d75f394547922758e9ac)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/virtual/kvm/api.txt
#	arch/powerpc/include/asm/kvm_book3s.h
#	arch/powerpc/include/asm/kvm_ppc.h
#	arch/powerpc/kvm/book3s.c
#	arch/powerpc/kvm/book3s_hv.c
#	arch/powerpc/kvm/book3s_hv_rmhandlers.S
#	arch/powerpc/kvm/book3s_pr.c
#	arch/powerpc/kvm/book3s_pr_papr.c
#	arch/powerpc/kvm/powerpc.c
diff --cc Documentation/virtual/kvm/api.txt
index b2bc745240b2,69553183ef0f..000000000000
--- a/Documentation/virtual/kvm/api.txt
+++ b/Documentation/virtual/kvm/api.txt
@@@ -2842,3 -3002,44 +2842,47 @@@ Parameters: args[0] is the XICS device 
              args[1] is the XICS CPU number (server ID) for this vcpu
  
  This capability connects the vcpu to an in-kernel XICS device.
++<<<<<<< HEAD
++=======
+ 
+ 
+ 7. Capabilities that can be enabled on VMs
+ ------------------------------------------
+ 
+ There are certain capabilities that change the behavior of the virtual
+ machine when enabled. To enable them, please see section 4.37. Below
+ you can find a list of capabilities and what their effect on the VM
+ is when enabling them.
+ 
+ The following information is provided along with the description:
+ 
+   Architectures: which instruction set architectures provide this ioctl.
+       x86 includes both i386 and x86_64.
+ 
+   Parameters: what parameters are accepted by the capability.
+ 
+   Returns: the return value.  General error numbers (EBADF, ENOMEM, EINVAL)
+       are not detailed, but errors with specific meanings are.
+ 
+ 
+ 7.1 KVM_CAP_PPC_ENABLE_HCALL
+ 
+ Architectures: ppc
+ Parameters: args[0] is the sPAPR hcall number
+ 	    args[1] is 0 to disable, 1 to enable in-kernel handling
+ 
+ This capability controls whether individual sPAPR hypercalls (hcalls)
+ get handled by the kernel or not.  Enabling or disabling in-kernel
+ handling of an hcall is effective across the VM.  On creation, an
+ initial set of hcalls are enabled for in-kernel handling, which
+ consists of those hcalls for which in-kernel handlers were implemented
+ before this capability was implemented.  If disabled, the kernel will
+ not to attempt to handle the hcall, but will always exit to userspace
+ to handle it.  Note that it may not make sense to enable some and
+ disable others of a group of related hcalls, but KVM does not prevent
+ userspace from doing that.
+ 
+ If the hcall number specified is not one that has an in-kernel
+ implementation, the KVM_ENABLE_CAP ioctl will fail with an EINVAL
+ error.
++>>>>>>> ae2113a4f1a6 (KVM: PPC: Book3S: Allow only implemented hcalls to be enabled or disabled)
diff --cc arch/powerpc/include/asm/kvm_book3s.h
index 621f2858583f,ceb70aaad6d4..000000000000
--- a/arch/powerpc/include/asm/kvm_book3s.h
+++ b/arch/powerpc/include/asm/kvm_book3s.h
@@@ -193,6 -188,13 +194,16 @@@ extern void kvmppc_load_up_vsx(void)
  extern u32 kvmppc_alignment_dsisr(struct kvm_vcpu *vcpu, unsigned int inst);
  extern ulong kvmppc_alignment_dar(struct kvm_vcpu *vcpu, unsigned int inst);
  extern int kvmppc_h_pr(struct kvm_vcpu *vcpu, unsigned long cmd);
++<<<<<<< HEAD
++=======
+ extern void kvmppc_pr_init_default_hcalls(struct kvm *kvm);
+ extern int kvmppc_hcall_impl_pr(unsigned long cmd);
+ extern int kvmppc_hcall_impl_hv_realmode(unsigned long cmd);
+ extern void kvmppc_copy_to_svcpu(struct kvmppc_book3s_shadow_vcpu *svcpu,
+ 				 struct kvm_vcpu *vcpu);
+ extern void kvmppc_copy_from_svcpu(struct kvm_vcpu *vcpu,
+ 				   struct kvmppc_book3s_shadow_vcpu *svcpu);
++>>>>>>> ae2113a4f1a6 (KVM: PPC: Book3S: Allow only implemented hcalls to be enabled or disabled)
  
  static inline struct kvmppc_vcpu_book3s *to_book3s(struct kvm_vcpu *vcpu)
  {
diff --cc arch/powerpc/include/asm/kvm_ppc.h
index 122dbb9c9205,e2fd5a133b9c..000000000000
--- a/arch/powerpc/include/asm/kvm_ppc.h
+++ b/arch/powerpc/include/asm/kvm_ppc.h
@@@ -177,6 -173,72 +177,75 @@@ extern int kvmppc_xics_get_xive(struct 
  extern int kvmppc_xics_int_on(struct kvm *kvm, u32 irq);
  extern int kvmppc_xics_int_off(struct kvm *kvm, u32 irq);
  
++<<<<<<< HEAD
++=======
+ union kvmppc_one_reg {
+ 	u32	wval;
+ 	u64	dval;
+ 	vector128 vval;
+ 	u64	vsxval[2];
+ 	struct {
+ 		u64	addr;
+ 		u64	length;
+ 	}	vpaval;
+ };
+ 
+ struct kvmppc_ops {
+ 	struct module *owner;
+ 	int (*get_sregs)(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs);
+ 	int (*set_sregs)(struct kvm_vcpu *vcpu, struct kvm_sregs *sregs);
+ 	int (*get_one_reg)(struct kvm_vcpu *vcpu, u64 id,
+ 			   union kvmppc_one_reg *val);
+ 	int (*set_one_reg)(struct kvm_vcpu *vcpu, u64 id,
+ 			   union kvmppc_one_reg *val);
+ 	void (*vcpu_load)(struct kvm_vcpu *vcpu, int cpu);
+ 	void (*vcpu_put)(struct kvm_vcpu *vcpu);
+ 	void (*set_msr)(struct kvm_vcpu *vcpu, u64 msr);
+ 	int (*vcpu_run)(struct kvm_run *run, struct kvm_vcpu *vcpu);
+ 	struct kvm_vcpu *(*vcpu_create)(struct kvm *kvm, unsigned int id);
+ 	void (*vcpu_free)(struct kvm_vcpu *vcpu);
+ 	int (*check_requests)(struct kvm_vcpu *vcpu);
+ 	int (*get_dirty_log)(struct kvm *kvm, struct kvm_dirty_log *log);
+ 	void (*flush_memslot)(struct kvm *kvm, struct kvm_memory_slot *memslot);
+ 	int (*prepare_memory_region)(struct kvm *kvm,
+ 				     struct kvm_memory_slot *memslot,
+ 				     struct kvm_userspace_memory_region *mem);
+ 	void (*commit_memory_region)(struct kvm *kvm,
+ 				     struct kvm_userspace_memory_region *mem,
+ 				     const struct kvm_memory_slot *old);
+ 	int (*unmap_hva)(struct kvm *kvm, unsigned long hva);
+ 	int (*unmap_hva_range)(struct kvm *kvm, unsigned long start,
+ 			   unsigned long end);
+ 	int (*age_hva)(struct kvm *kvm, unsigned long hva);
+ 	int (*test_age_hva)(struct kvm *kvm, unsigned long hva);
+ 	void (*set_spte_hva)(struct kvm *kvm, unsigned long hva, pte_t pte);
+ 	void (*mmu_destroy)(struct kvm_vcpu *vcpu);
+ 	void (*free_memslot)(struct kvm_memory_slot *free,
+ 			     struct kvm_memory_slot *dont);
+ 	int (*create_memslot)(struct kvm_memory_slot *slot,
+ 			      unsigned long npages);
+ 	int (*init_vm)(struct kvm *kvm);
+ 	void (*destroy_vm)(struct kvm *kvm);
+ 	int (*get_smmu_info)(struct kvm *kvm, struct kvm_ppc_smmu_info *info);
+ 	int (*emulate_op)(struct kvm_run *run, struct kvm_vcpu *vcpu,
+ 			  unsigned int inst, int *advance);
+ 	int (*emulate_mtspr)(struct kvm_vcpu *vcpu, int sprn, ulong spr_val);
+ 	int (*emulate_mfspr)(struct kvm_vcpu *vcpu, int sprn, ulong *spr_val);
+ 	void (*fast_vcpu_kick)(struct kvm_vcpu *vcpu);
+ 	long (*arch_vm_ioctl)(struct file *filp, unsigned int ioctl,
+ 			      unsigned long arg);
+ 	int (*hcall_implemented)(unsigned long hcall);
+ };
+ 
+ extern struct kvmppc_ops *kvmppc_hv_ops;
+ extern struct kvmppc_ops *kvmppc_pr_ops;
+ 
+ static inline bool is_kvmppc_hv_enabled(struct kvm *kvm)
+ {
+ 	return kvm->arch.kvm_ops == kvmppc_hv_ops;
+ }
+ 
++>>>>>>> ae2113a4f1a6 (KVM: PPC: Book3S: Allow only implemented hcalls to be enabled or disabled)
  /*
   * Cuts out inst bits with ordering according to spec.
   * That means the leftmost bit is zero. All given bits are included.
diff --cc arch/powerpc/kvm/book3s.c
index be63f63c167b,bd75902b38ba..000000000000
--- a/arch/powerpc/kvm/book3s.c
+++ b/arch/powerpc/kvm/book3s.c
@@@ -679,3 -811,152 +679,155 @@@ void kvmppc_decrementer_func(unsigned l
  	kvmppc_core_queue_dec(vcpu);
  	kvm_vcpu_kick(vcpu);
  }
++<<<<<<< HEAD
++=======
+ 
+ struct kvm_vcpu *kvmppc_core_vcpu_create(struct kvm *kvm, unsigned int id)
+ {
+ 	return kvm->arch.kvm_ops->vcpu_create(kvm, id);
+ }
+ 
+ void kvmppc_core_vcpu_free(struct kvm_vcpu *vcpu)
+ {
+ 	vcpu->kvm->arch.kvm_ops->vcpu_free(vcpu);
+ }
+ 
+ int kvmppc_core_check_requests(struct kvm_vcpu *vcpu)
+ {
+ 	return vcpu->kvm->arch.kvm_ops->check_requests(vcpu);
+ }
+ 
+ int kvm_vm_ioctl_get_dirty_log(struct kvm *kvm, struct kvm_dirty_log *log)
+ {
+ 	return kvm->arch.kvm_ops->get_dirty_log(kvm, log);
+ }
+ 
+ void kvmppc_core_free_memslot(struct kvm *kvm, struct kvm_memory_slot *free,
+ 			      struct kvm_memory_slot *dont)
+ {
+ 	kvm->arch.kvm_ops->free_memslot(free, dont);
+ }
+ 
+ int kvmppc_core_create_memslot(struct kvm *kvm, struct kvm_memory_slot *slot,
+ 			       unsigned long npages)
+ {
+ 	return kvm->arch.kvm_ops->create_memslot(slot, npages);
+ }
+ 
+ void kvmppc_core_flush_memslot(struct kvm *kvm, struct kvm_memory_slot *memslot)
+ {
+ 	kvm->arch.kvm_ops->flush_memslot(kvm, memslot);
+ }
+ 
+ int kvmppc_core_prepare_memory_region(struct kvm *kvm,
+ 				struct kvm_memory_slot *memslot,
+ 				struct kvm_userspace_memory_region *mem)
+ {
+ 	return kvm->arch.kvm_ops->prepare_memory_region(kvm, memslot, mem);
+ }
+ 
+ void kvmppc_core_commit_memory_region(struct kvm *kvm,
+ 				struct kvm_userspace_memory_region *mem,
+ 				const struct kvm_memory_slot *old)
+ {
+ 	kvm->arch.kvm_ops->commit_memory_region(kvm, mem, old);
+ }
+ 
+ int kvm_unmap_hva(struct kvm *kvm, unsigned long hva)
+ {
+ 	return kvm->arch.kvm_ops->unmap_hva(kvm, hva);
+ }
+ EXPORT_SYMBOL_GPL(kvm_unmap_hva);
+ 
+ int kvm_unmap_hva_range(struct kvm *kvm, unsigned long start, unsigned long end)
+ {
+ 	return kvm->arch.kvm_ops->unmap_hva_range(kvm, start, end);
+ }
+ 
+ int kvm_age_hva(struct kvm *kvm, unsigned long hva)
+ {
+ 	return kvm->arch.kvm_ops->age_hva(kvm, hva);
+ }
+ 
+ int kvm_test_age_hva(struct kvm *kvm, unsigned long hva)
+ {
+ 	return kvm->arch.kvm_ops->test_age_hva(kvm, hva);
+ }
+ 
+ void kvm_set_spte_hva(struct kvm *kvm, unsigned long hva, pte_t pte)
+ {
+ 	kvm->arch.kvm_ops->set_spte_hva(kvm, hva, pte);
+ }
+ 
+ void kvmppc_mmu_destroy(struct kvm_vcpu *vcpu)
+ {
+ 	vcpu->kvm->arch.kvm_ops->mmu_destroy(vcpu);
+ }
+ 
+ int kvmppc_core_init_vm(struct kvm *kvm)
+ {
+ 
+ #ifdef CONFIG_PPC64
+ 	INIT_LIST_HEAD(&kvm->arch.spapr_tce_tables);
+ 	INIT_LIST_HEAD(&kvm->arch.rtas_tokens);
+ #endif
+ 
+ 	return kvm->arch.kvm_ops->init_vm(kvm);
+ }
+ 
+ void kvmppc_core_destroy_vm(struct kvm *kvm)
+ {
+ 	kvm->arch.kvm_ops->destroy_vm(kvm);
+ 
+ #ifdef CONFIG_PPC64
+ 	kvmppc_rtas_tokens_free(kvm);
+ 	WARN_ON(!list_empty(&kvm->arch.spapr_tce_tables));
+ #endif
+ }
+ 
+ int kvmppc_core_check_processor_compat(void)
+ {
+ 	/*
+ 	 * We always return 0 for book3s. We check
+ 	 * for compatability while loading the HV
+ 	 * or PR module
+ 	 */
+ 	return 0;
+ }
+ 
+ int kvmppc_book3s_hcall_implemented(struct kvm *kvm, unsigned long hcall)
+ {
+ 	return kvm->arch.kvm_ops->hcall_implemented(hcall);
+ }
+ 
+ static int kvmppc_book3s_init(void)
+ {
+ 	int r;
+ 
+ 	r = kvm_init(NULL, sizeof(struct kvm_vcpu), 0, THIS_MODULE);
+ 	if (r)
+ 		return r;
+ #ifdef CONFIG_KVM_BOOK3S_32_HANDLER
+ 	r = kvmppc_book3s_init_pr();
+ #endif
+ 	return r;
+ 
+ }
+ 
+ static void kvmppc_book3s_exit(void)
+ {
+ #ifdef CONFIG_KVM_BOOK3S_32_HANDLER
+ 	kvmppc_book3s_exit_pr();
+ #endif
+ 	kvm_exit();
+ }
+ 
+ module_init(kvmppc_book3s_init);
+ module_exit(kvmppc_book3s_exit);
+ 
+ /* On 32bit this is our one and only kernel module */
+ #ifdef CONFIG_KVM_BOOK3S_32_HANDLER
+ MODULE_ALIAS_MISCDEV(KVM_MINOR);
+ MODULE_ALIAS("devname:kvm");
+ #endif
++>>>>>>> ae2113a4f1a6 (KVM: PPC: Book3S: Allow only implemented hcalls to be enabled or disabled)
diff --cc arch/powerpc/kvm/book3s_hv.c
index 25619035861f,c4377c70787a..000000000000
--- a/arch/powerpc/kvm/book3s_hv.c
+++ b/arch/powerpc/kvm/book3s_hv.c
@@@ -632,8 -645,30 +632,35 @@@ int kvmppc_pseries_do_hcall(struct kvm_
  	return RESUME_GUEST;
  }
  
++<<<<<<< HEAD
 +static int kvmppc_handle_exit(struct kvm_run *run, struct kvm_vcpu *vcpu,
 +			      struct task_struct *tsk)
++=======
+ static int kvmppc_hcall_impl_hv(unsigned long cmd)
+ {
+ 	switch (cmd) {
+ 	case H_CEDE:
+ 	case H_PROD:
+ 	case H_CONFER:
+ 	case H_REGISTER_VPA:
+ #ifdef CONFIG_KVM_XICS
+ 	case H_XIRR:
+ 	case H_CPPR:
+ 	case H_EOI:
+ 	case H_IPI:
+ 	case H_IPOLL:
+ 	case H_XIRR_X:
+ #endif
+ 		return 1;
+ 	}
+ 
+ 	/* See if it's in the real-mode table */
+ 	return kvmppc_hcall_impl_hv_realmode(cmd);
+ }
+ 
+ static int kvmppc_handle_exit_hv(struct kvm_run *run, struct kvm_vcpu *vcpu,
+ 				 struct task_struct *tsk)
++>>>>>>> ae2113a4f1a6 (KVM: PPC: Book3S: Allow only implemented hcalls to be enabled or disabled)
  {
  	int r = RESUME_HOST;
  
@@@ -2070,17 -2380,159 +2097,158 @@@ int kvmppc_core_emulate_mfspr(struct kv
  	return EMULATE_FAIL;
  }
  
++<<<<<<< HEAD
 +static int kvmppc_book3s_hv_init(void)
++=======
+ static int kvmppc_core_check_processor_compat_hv(void)
+ {
+ 	if (!cpu_has_feature(CPU_FTR_HVMODE))
+ 		return -EIO;
+ 	return 0;
+ }
+ 
+ static long kvm_arch_vm_ioctl_hv(struct file *filp,
+ 				 unsigned int ioctl, unsigned long arg)
+ {
+ 	struct kvm *kvm __maybe_unused = filp->private_data;
+ 	void __user *argp = (void __user *)arg;
+ 	long r;
+ 
+ 	switch (ioctl) {
+ 
+ 	case KVM_ALLOCATE_RMA: {
+ 		struct kvm_allocate_rma rma;
+ 		struct kvm *kvm = filp->private_data;
+ 
+ 		r = kvm_vm_ioctl_allocate_rma(kvm, &rma);
+ 		if (r >= 0 && copy_to_user(argp, &rma, sizeof(rma)))
+ 			r = -EFAULT;
+ 		break;
+ 	}
+ 
+ 	case KVM_PPC_ALLOCATE_HTAB: {
+ 		u32 htab_order;
+ 
+ 		r = -EFAULT;
+ 		if (get_user(htab_order, (u32 __user *)argp))
+ 			break;
+ 		r = kvmppc_alloc_reset_hpt(kvm, &htab_order);
+ 		if (r)
+ 			break;
+ 		r = -EFAULT;
+ 		if (put_user(htab_order, (u32 __user *)argp))
+ 			break;
+ 		r = 0;
+ 		break;
+ 	}
+ 
+ 	case KVM_PPC_GET_HTAB_FD: {
+ 		struct kvm_get_htab_fd ghf;
+ 
+ 		r = -EFAULT;
+ 		if (copy_from_user(&ghf, argp, sizeof(ghf)))
+ 			break;
+ 		r = kvm_vm_ioctl_get_htab_fd(kvm, &ghf);
+ 		break;
+ 	}
+ 
+ 	default:
+ 		r = -ENOTTY;
+ 	}
+ 
+ 	return r;
+ }
+ 
+ /*
+  * List of hcall numbers to enable by default.
+  * For compatibility with old userspace, we enable by default
+  * all hcalls that were implemented before the hcall-enabling
+  * facility was added.  Note this list should not include H_RTAS.
+  */
+ static unsigned int default_hcall_list[] = {
+ 	H_REMOVE,
+ 	H_ENTER,
+ 	H_READ,
+ 	H_PROTECT,
+ 	H_BULK_REMOVE,
+ 	H_GET_TCE,
+ 	H_PUT_TCE,
+ 	H_SET_DABR,
+ 	H_SET_XDABR,
+ 	H_CEDE,
+ 	H_PROD,
+ 	H_CONFER,
+ 	H_REGISTER_VPA,
+ #ifdef CONFIG_KVM_XICS
+ 	H_EOI,
+ 	H_CPPR,
+ 	H_IPI,
+ 	H_IPOLL,
+ 	H_XIRR,
+ 	H_XIRR_X,
+ #endif
+ 	0
+ };
+ 
+ static void init_default_hcalls(void)
+ {
+ 	int i;
+ 	unsigned int hcall;
+ 
+ 	for (i = 0; default_hcall_list[i]; ++i) {
+ 		hcall = default_hcall_list[i];
+ 		WARN_ON(!kvmppc_hcall_impl_hv(hcall));
+ 		__set_bit(hcall / 4, default_enabled_hcalls);
+ 	}
+ }
+ 
+ static struct kvmppc_ops kvm_ops_hv = {
+ 	.get_sregs = kvm_arch_vcpu_ioctl_get_sregs_hv,
+ 	.set_sregs = kvm_arch_vcpu_ioctl_set_sregs_hv,
+ 	.get_one_reg = kvmppc_get_one_reg_hv,
+ 	.set_one_reg = kvmppc_set_one_reg_hv,
+ 	.vcpu_load   = kvmppc_core_vcpu_load_hv,
+ 	.vcpu_put    = kvmppc_core_vcpu_put_hv,
+ 	.set_msr     = kvmppc_set_msr_hv,
+ 	.vcpu_run    = kvmppc_vcpu_run_hv,
+ 	.vcpu_create = kvmppc_core_vcpu_create_hv,
+ 	.vcpu_free   = kvmppc_core_vcpu_free_hv,
+ 	.check_requests = kvmppc_core_check_requests_hv,
+ 	.get_dirty_log  = kvm_vm_ioctl_get_dirty_log_hv,
+ 	.flush_memslot  = kvmppc_core_flush_memslot_hv,
+ 	.prepare_memory_region = kvmppc_core_prepare_memory_region_hv,
+ 	.commit_memory_region  = kvmppc_core_commit_memory_region_hv,
+ 	.unmap_hva = kvm_unmap_hva_hv,
+ 	.unmap_hva_range = kvm_unmap_hva_range_hv,
+ 	.age_hva  = kvm_age_hva_hv,
+ 	.test_age_hva = kvm_test_age_hva_hv,
+ 	.set_spte_hva = kvm_set_spte_hva_hv,
+ 	.mmu_destroy  = kvmppc_mmu_destroy_hv,
+ 	.free_memslot = kvmppc_core_free_memslot_hv,
+ 	.create_memslot = kvmppc_core_create_memslot_hv,
+ 	.init_vm =  kvmppc_core_init_vm_hv,
+ 	.destroy_vm = kvmppc_core_destroy_vm_hv,
+ 	.get_smmu_info = kvm_vm_ioctl_get_smmu_info_hv,
+ 	.emulate_op = kvmppc_core_emulate_op_hv,
+ 	.emulate_mtspr = kvmppc_core_emulate_mtspr_hv,
+ 	.emulate_mfspr = kvmppc_core_emulate_mfspr_hv,
+ 	.fast_vcpu_kick = kvmppc_fast_vcpu_kick_hv,
+ 	.arch_vm_ioctl  = kvm_arch_vm_ioctl_hv,
+ 	.hcall_implemented = kvmppc_hcall_impl_hv,
+ };
+ 
+ static int kvmppc_book3s_init_hv(void)
++>>>>>>> ae2113a4f1a6 (KVM: PPC: Book3S: Allow only implemented hcalls to be enabled or disabled)
  {
  	int r;
 -	/*
 -	 * FIXME!! Do we need to check on all cpus ?
 -	 */
 -	r = kvmppc_core_check_processor_compat_hv();
 -	if (r < 0)
 -		return -ENODEV;
  
 -	kvm_ops_hv.owner = THIS_MODULE;
 -	kvmppc_hv_ops = &kvm_ops_hv;
 +	r = kvm_init(NULL, sizeof(struct kvm_vcpu), 0, THIS_MODULE);
  
 -	init_default_hcalls();
 +	if (r)
 +		return r;
  
  	r = kvmppc_mmu_hv_init();
 +
  	return r;
  }
  
diff --cc arch/powerpc/kvm/book3s_hv_rmhandlers.S
index 0ae4c28ae4b6,e66c1e388ddf..000000000000
--- a/arch/powerpc/kvm/book3s_hv_rmhandlers.S
+++ b/arch/powerpc/kvm/book3s_hv_rmhandlers.S
@@@ -1615,7 -2037,12 +1615,16 @@@ hcall_real_table
  	.long	0		/* 0x118 */
  	.long	0		/* 0x11c */
  	.long	0		/* 0x120 */
++<<<<<<< HEAD
 +	.long	.kvmppc_h_bulk_remove - hcall_real_table
++=======
+ 	.long	DOTSYM(kvmppc_h_bulk_remove) - hcall_real_table
+ 	.long	0		/* 0x128 */
+ 	.long	0		/* 0x12c */
+ 	.long	0		/* 0x130 */
+ 	.long	DOTSYM(kvmppc_h_set_xdabr) - hcall_real_table
+ 	.globl	hcall_real_table_end
++>>>>>>> ae2113a4f1a6 (KVM: PPC: Book3S: Allow only implemented hcalls to be enabled or disabled)
  hcall_real_table_end:
  
  ignore_hdec:
diff --cc arch/powerpc/kvm/book3s_pr.c
index 8956df8d25a8,15fd6c25179c..000000000000
--- a/arch/powerpc/kvm/book3s_pr.c
+++ b/arch/powerpc/kvm/book3s_pr.c
@@@ -1441,7 -1626,57 +1441,61 @@@ void kvmppc_core_destroy_vm(struct kvm 
  	}
  }
  
++<<<<<<< HEAD
 +static int kvmppc_book3s_init(void)
++=======
+ static int kvmppc_core_check_processor_compat_pr(void)
+ {
+ 	/* we are always compatible */
+ 	return 0;
+ }
+ 
+ static long kvm_arch_vm_ioctl_pr(struct file *filp,
+ 				 unsigned int ioctl, unsigned long arg)
+ {
+ 	return -ENOTTY;
+ }
+ 
+ static struct kvmppc_ops kvm_ops_pr = {
+ 	.get_sregs = kvm_arch_vcpu_ioctl_get_sregs_pr,
+ 	.set_sregs = kvm_arch_vcpu_ioctl_set_sregs_pr,
+ 	.get_one_reg = kvmppc_get_one_reg_pr,
+ 	.set_one_reg = kvmppc_set_one_reg_pr,
+ 	.vcpu_load   = kvmppc_core_vcpu_load_pr,
+ 	.vcpu_put    = kvmppc_core_vcpu_put_pr,
+ 	.set_msr     = kvmppc_set_msr_pr,
+ 	.vcpu_run    = kvmppc_vcpu_run_pr,
+ 	.vcpu_create = kvmppc_core_vcpu_create_pr,
+ 	.vcpu_free   = kvmppc_core_vcpu_free_pr,
+ 	.check_requests = kvmppc_core_check_requests_pr,
+ 	.get_dirty_log = kvm_vm_ioctl_get_dirty_log_pr,
+ 	.flush_memslot = kvmppc_core_flush_memslot_pr,
+ 	.prepare_memory_region = kvmppc_core_prepare_memory_region_pr,
+ 	.commit_memory_region = kvmppc_core_commit_memory_region_pr,
+ 	.unmap_hva = kvm_unmap_hva_pr,
+ 	.unmap_hva_range = kvm_unmap_hva_range_pr,
+ 	.age_hva  = kvm_age_hva_pr,
+ 	.test_age_hva = kvm_test_age_hva_pr,
+ 	.set_spte_hva = kvm_set_spte_hva_pr,
+ 	.mmu_destroy  = kvmppc_mmu_destroy_pr,
+ 	.free_memslot = kvmppc_core_free_memslot_pr,
+ 	.create_memslot = kvmppc_core_create_memslot_pr,
+ 	.init_vm = kvmppc_core_init_vm_pr,
+ 	.destroy_vm = kvmppc_core_destroy_vm_pr,
+ 	.get_smmu_info = kvm_vm_ioctl_get_smmu_info_pr,
+ 	.emulate_op = kvmppc_core_emulate_op_pr,
+ 	.emulate_mtspr = kvmppc_core_emulate_mtspr_pr,
+ 	.emulate_mfspr = kvmppc_core_emulate_mfspr_pr,
+ 	.fast_vcpu_kick = kvm_vcpu_kick,
+ 	.arch_vm_ioctl  = kvm_arch_vm_ioctl_pr,
+ #ifdef CONFIG_PPC_BOOK3S_64
+ 	.hcall_implemented = kvmppc_hcall_impl_pr,
+ #endif
+ };
+ 
+ 
+ int kvmppc_book3s_init_pr(void)
++>>>>>>> ae2113a4f1a6 (KVM: PPC: Book3S: Allow only implemented hcalls to be enabled or disabled)
  {
  	int r;
  
diff --cc arch/powerpc/kvm/book3s_pr_papr.c
index 5efa97b993d8,6d0143fbeb63..000000000000
--- a/arch/powerpc/kvm/book3s_pr_papr.c
+++ b/arch/powerpc/kvm/book3s_pr_papr.c
@@@ -295,3 -308,61 +295,64 @@@ int kvmppc_h_pr(struct kvm_vcpu *vcpu, 
  
  	return EMULATE_FAIL;
  }
++<<<<<<< HEAD
++=======
+ 
+ int kvmppc_hcall_impl_pr(unsigned long cmd)
+ {
+ 	switch (cmd) {
+ 	case H_ENTER:
+ 	case H_REMOVE:
+ 	case H_PROTECT:
+ 	case H_BULK_REMOVE:
+ 	case H_PUT_TCE:
+ 	case H_CEDE:
+ #ifdef CONFIG_KVM_XICS
+ 	case H_XIRR:
+ 	case H_CPPR:
+ 	case H_EOI:
+ 	case H_IPI:
+ 	case H_IPOLL:
+ 	case H_XIRR_X:
+ #endif
+ 		return 1;
+ 	}
+ 	return 0;
+ }
+ 
+ /*
+  * List of hcall numbers to enable by default.
+  * For compatibility with old userspace, we enable by default
+  * all hcalls that were implemented before the hcall-enabling
+  * facility was added.  Note this list should not include H_RTAS.
+  */
+ static unsigned int default_hcall_list[] = {
+ 	H_ENTER,
+ 	H_REMOVE,
+ 	H_PROTECT,
+ 	H_BULK_REMOVE,
+ 	H_PUT_TCE,
+ 	H_CEDE,
+ #ifdef CONFIG_KVM_XICS
+ 	H_XIRR,
+ 	H_CPPR,
+ 	H_EOI,
+ 	H_IPI,
+ 	H_IPOLL,
+ 	H_XIRR_X,
+ #endif
+ 	0
+ };
+ 
+ void kvmppc_pr_init_default_hcalls(struct kvm *kvm)
+ {
+ 	int i;
+ 	unsigned int hcall;
+ 
+ 	for (i = 0; default_hcall_list[i]; ++i) {
+ 		hcall = default_hcall_list[i];
+ 		WARN_ON(!kvmppc_hcall_impl_pr(hcall));
+ 		__set_bit(hcall / 4, kvm->arch.enabled_hcalls);
+ 	}
+ }
++>>>>>>> ae2113a4f1a6 (KVM: PPC: Book3S: Allow only implemented hcalls to be enabled or disabled)
diff --cc arch/powerpc/kvm/powerpc.c
index 126467ebd44f,7efc2b711404..000000000000
--- a/arch/powerpc/kvm/powerpc.c
+++ b/arch/powerpc/kvm/powerpc.c
@@@ -995,6 -1101,42 +995,45 @@@ int kvm_vm_ioctl_irq_line(struct kvm *k
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ 
+ static int kvm_vm_ioctl_enable_cap(struct kvm *kvm,
+ 				   struct kvm_enable_cap *cap)
+ {
+ 	int r;
+ 
+ 	if (cap->flags)
+ 		return -EINVAL;
+ 
+ 	switch (cap->cap) {
+ #ifdef CONFIG_KVM_BOOK3S_64_HANDLER
+ 	case KVM_CAP_PPC_ENABLE_HCALL: {
+ 		unsigned long hcall = cap->args[0];
+ 
+ 		r = -EINVAL;
+ 		if (hcall > MAX_HCALL_OPCODE || (hcall & 3) ||
+ 		    cap->args[1] > 1)
+ 			break;
+ 		if (!kvmppc_book3s_hcall_implemented(kvm, hcall))
+ 			break;
+ 		if (cap->args[1])
+ 			set_bit(hcall / 4, kvm->arch.enabled_hcalls);
+ 		else
+ 			clear_bit(hcall / 4, kvm->arch.enabled_hcalls);
+ 		r = 0;
+ 		break;
+ 	}
+ #endif
+ 	default:
+ 		r = -EINVAL;
+ 		break;
+ 	}
+ 
+ 	return r;
+ }
+ 
++>>>>>>> ae2113a4f1a6 (KVM: PPC: Book3S: Allow only implemented hcalls to be enabled or disabled)
  long kvm_arch_vm_ioctl(struct file *filp,
                         unsigned int ioctl, unsigned long arg)
  {
* Unmerged path Documentation/virtual/kvm/api.txt
* Unmerged path arch/powerpc/include/asm/kvm_book3s.h
* Unmerged path arch/powerpc/include/asm/kvm_ppc.h
* Unmerged path arch/powerpc/kvm/book3s.c
* Unmerged path arch/powerpc/kvm/book3s_hv.c
diff --git a/arch/powerpc/kvm/book3s_hv_builtin.c b/arch/powerpc/kvm/book3s_hv_builtin.c
index 7cde8a665205..3b41447482e5 100644
--- a/arch/powerpc/kvm/book3s_hv_builtin.c
+++ b/arch/powerpc/kvm/book3s_hv_builtin.c
@@ -212,3 +212,16 @@ bool kvm_hv_mode_active(void)
 {
 	return atomic_read(&hv_vm_count) != 0;
 }
+
+extern int hcall_real_table[], hcall_real_table_end[];
+
+int kvmppc_hcall_impl_hv_realmode(unsigned long cmd)
+{
+	cmd /= 4;
+	if (cmd < hcall_real_table_end - hcall_real_table &&
+	    hcall_real_table[cmd])
+		return 1;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(kvmppc_hcall_impl_hv_realmode);
* Unmerged path arch/powerpc/kvm/book3s_hv_rmhandlers.S
* Unmerged path arch/powerpc/kvm/book3s_pr.c
* Unmerged path arch/powerpc/kvm/book3s_pr_papr.c
* Unmerged path arch/powerpc/kvm/powerpc.c
