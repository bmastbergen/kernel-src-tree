blk-mq: allow drivers to hook into I/O completion

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
Rebuild_CHGLOG: - [block] blk-mq: allow drivers to hook into I_O completion (Mike Snitzer) [1105204]
Rebuild_FUZZ: 97.96%
commit-author Christoph Hellwig <hch@lst.de>
commit 63151a449ebaef062ffac5b302206565ff5ef62e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/63151a44.failed

Split out the bottom half of blk_mq_end_io so that drivers can perform
work when they know a request has been completed, but before it has been
freed.  This also obsoletes blk_mq_end_io_partial as drivers can now
pass any value to blk_update_request directly.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 63151a449ebaef062ffac5b302206565ff5ef62e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq.c
diff --cc block/blk-mq.c
index 9a84bbb2459d,86d66e0e900c..000000000000
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@@ -286,11 -274,28 +286,32 @@@ void blk_mq_free_request(struct reques
  	__blk_mq_free_request(hctx, ctx, rq);
  }
  
++<<<<<<< HEAD
 +bool blk_mq_end_io_partial(struct request *rq, int error, unsigned int nr_bytes)
++=======
+ /*
+  * Clone all relevant state from a request that has been put on hold in
+  * the flush state machine into the preallocated flush request that hangs
+  * off the request queue.
+  *
+  * For a driver the flush request should be invisible, that's why we are
+  * impersonating the original request here.
+  */
+ void blk_mq_clone_flush_request(struct request *flush_rq,
+ 		struct request *orig_rq)
  {
- 	if (blk_update_request(rq, error, blk_rq_bytes(rq)))
- 		return true;
+ 	struct blk_mq_hw_ctx *hctx =
+ 		orig_rq->q->mq_ops->map_queue(orig_rq->q, orig_rq->mq_ctx->cpu);
  
+ 	flush_rq->mq_ctx = orig_rq->mq_ctx;
+ 	flush_rq->tag = orig_rq->tag;
+ 	memcpy(blk_mq_rq_to_pdu(flush_rq), blk_mq_rq_to_pdu(orig_rq),
+ 		hctx->cmd_size);
+ }
+ 
+ inline void __blk_mq_end_io(struct request *rq, int error)
++>>>>>>> 63151a449eba (blk-mq: allow drivers to hook into I/O completion)
+ {
  	blk_account_io_done(rq);
  
  	if (rq->end_io)
* Unmerged path block/blk-mq.c
diff --git a/include/linux/blk-mq.h b/include/linux/blk-mq.h
index f13671a6c70c..909ee12e023f 100644
--- a/include/linux/blk-mq.h
+++ b/include/linux/blk-mq.h
@@ -134,13 +134,8 @@ struct blk_mq_hw_ctx *blk_mq_map_queue(struct request_queue *, const int ctx_ind
 struct blk_mq_hw_ctx *blk_mq_alloc_single_hw_queue(struct blk_mq_reg *, unsigned int);
 void blk_mq_free_single_hw_queue(struct blk_mq_hw_ctx *, unsigned int);
 
-bool blk_mq_end_io_partial(struct request *rq, int error,
-		unsigned int nr_bytes);
-static inline void blk_mq_end_io(struct request *rq, int error)
-{
-	bool done = !blk_mq_end_io_partial(rq, error, blk_rq_bytes(rq));
-	BUG_ON(!done);
-}
+void blk_mq_end_io(struct request *rq, int error);
+void __blk_mq_end_io(struct request *rq, int error);
 
 void blk_mq_complete_request(struct request *rq);
 
