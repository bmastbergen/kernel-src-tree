xprtrdma: Properly handle exhaustion of the rb_mws list

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
commit-author Chuck Lever <chuck.lever@oracle.com>
commit c2922c0235aac1c787fa81e24d7d7e93c2202275
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/c2922c02.failed

If the rb_mws list is exhausted, clean up and return NULL so that
call_allocate() will delay and try again.

	Signed-off-by: Chuck Lever <chuck.lever@oracle.com>
	Tested-by: Steve Wise <swise@opengridcomputing.com>
	Tested-by: Shirley Ma <shirley.ma@oracle.com>
	Tested-by: Devesh Sharma <devesh.sharma@emulex.com>
	Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
(cherry picked from commit c2922c0235aac1c787fa81e24d7d7e93c2202275)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sunrpc/xprtrdma/verbs.c
diff --cc net/sunrpc/xprtrdma/verbs.c
index 499e0d7e7773,017f0abb2a86..000000000000
--- a/net/sunrpc/xprtrdma/verbs.c
+++ b/net/sunrpc/xprtrdma/verbs.c
@@@ -1321,34 -1375,11 +1380,41 @@@ rpcrdma_buffer_put(struct rpcrdma_req *
  	unsigned long flags;
  
  	spin_lock_irqsave(&buffers->rb_lock, flags);
++<<<<<<< HEAD
 +	buffers->rb_send_bufs[--buffers->rb_send_index] = req;
 +	req->rl_niovs = 0;
 +	if (req->rl_reply) {
 +		buffers->rb_recv_bufs[--buffers->rb_recv_index] = req->rl_reply;
 +		init_waitqueue_head(&req->rl_reply->rr_unbind);
 +		req->rl_reply->rr_func = NULL;
 +		req->rl_reply = NULL;
 +	}
 +	switch (ia->ri_memreg_strategy) {
 +	case RPCRDMA_FRMR:
 +	case RPCRDMA_MTHCAFMR:
 +	case RPCRDMA_MEMWINDOWS_ASYNC:
 +	case RPCRDMA_MEMWINDOWS:
 +		/*
 +		 * Cycle mw's back in reverse order, and "spin" them.
 +		 * This delays and scrambles reuse as much as possible.
 +		 */
 +		i = 1;
 +		do {
 +			struct rpcrdma_mw **mw;
 +			mw = &req->rl_segments[i].mr_chunk.rl_mw;
 +			list_add_tail(&(*mw)->mw_list, &buffers->rb_mws);
 +			*mw = NULL;
 +		} while (++i < RPCRDMA_MAX_SEGS);
 +		list_add_tail(&req->rl_segments[0].mr_chunk.rl_mw->mw_list,
 +					&buffers->rb_mws);
 +		req->rl_segments[0].mr_chunk.rl_mw = NULL;
++=======
+ 	rpcrdma_buffer_put_sendbuf(req, buffers);
+ 	switch (ia->ri_memreg_strategy) {
+ 	case RPCRDMA_FRMR:
+ 	case RPCRDMA_MTHCAFMR:
+ 		rpcrdma_buffer_put_mrs(req, buffers);
++>>>>>>> c2922c0235aa (xprtrdma: Properly handle exhaustion of the rb_mws list)
  		break;
  	default:
  		break;
* Unmerged path net/sunrpc/xprtrdma/verbs.c
