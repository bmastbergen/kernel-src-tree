sched: Skip double execution of pick_next_task_fair()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
commit-author Peter Zijlstra <peterz@infradead.org>
commit 6ccdc84b81a0a6c09a7f0427761d2f8cecfc2218
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/6ccdc84b.failed

Tim wrote:

 "The current code will call pick_next_task_fair a second time in the
  slow path if we did not pull any task in our first try.  This is
  really unnecessary as we already know no task can be pulled and it
  doubles the delay for the cpu to enter idle.

  We instrumented some network workloads and that saw that
  pick_next_task_fair is frequently called twice before a cpu enters
  idle.  The call to pick_next_task_fair can add non trivial latency as
  it calls load_balance which runs find_busiest_group on an hierarchy of
  sched domains spanning the cpus for a large system.  For some 4 socket
  systems, we saw almost 0.25 msec spent per call of pick_next_task_fair
  before a cpu can be idled."

Optimize the second call away for the common case and document the
dependency.

	Reported-by: Tim Chen <tim.c.chen@linux.intel.com>
	Signed-off-by: Peter Zijlstra <peterz@infradead.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Len Brown <len.brown@intel.com>
Link: http://lkml.kernel.org/r/20140424100047.GP11096@twins.programming.kicks-ass.net
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 6ccdc84b81a0a6c09a7f0427761d2f8cecfc2218)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/core.c
diff --cc kernel/sched/core.c
index 7afa56e8b311,28921ec91b3d..000000000000
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@@ -3082,16 -2589,27 +3082,30 @@@ pick_next_task(struct rq *rq
  	 * Optimization: we know that if all tasks are in
  	 * the fair class we can call that function directly:
  	 */
++<<<<<<< HEAD
 +	if (likely(rq->nr_running == rq->cfs.h_nr_running)) {
 +		p = fair_sched_class.pick_next_task(rq);
 +		if (likely(p))
 +			return p;
++=======
+ 	if (likely(prev->sched_class == class &&
+ 		   rq->nr_running == rq->cfs.h_nr_running)) {
+ 		p = fair_sched_class.pick_next_task(rq, prev);
+ 		if (unlikely(p == RETRY_TASK))
+ 			goto again;
+ 
+ 		/* assumes fair_sched_class->next == idle_sched_class */
+ 		if (unlikely(!p))
+ 			p = idle_sched_class.pick_next_task(rq, prev);
+ 
+ 		return p;
++>>>>>>> 6ccdc84b81a0 (sched: Skip double execution of pick_next_task_fair())
  	}
  
 -again:
  	for_each_class(class) {
 -		p = class->pick_next_task(rq, prev);
 -		if (p) {
 -			if (unlikely(p == RETRY_TASK))
 -				goto again;
 +		p = class->pick_next_task(rq);
 +		if (p)
  			return p;
 -		}
  	}
  
  	BUG(); /* the idle class will always have a runnable task */
* Unmerged path kernel/sched/core.c
