KVM: PPC: Book3S: Controls for in-kernel sPAPR hypercall handling

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
Rebuild_CHGLOG: - [virt] kvm/ppc: book3s - Controls for in-kernel sPAPR hypercall handling (David Gibson) [1123145 1123133 1123367]
Rebuild_FUZZ: 95.38%
commit-author Paul Mackerras <paulus@samba.org>
commit 699a0ea0823d32030b0666b28ff8633960f7ffa7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/699a0ea0.failed

This provides a way for userspace controls which sPAPR hcalls get
handled in the kernel.  Each hcall can be individually enabled or
disabled for in-kernel handling, except for H_RTAS.  The exception
for H_RTAS is because userspace can already control whether
individual RTAS functions are handled in-kernel or not via the
KVM_PPC_RTAS_DEFINE_TOKEN ioctl, and because the numeric value for
H_RTAS is out of the normal sequence of hcall numbers.

Hcalls are enabled or disabled using the KVM_ENABLE_CAP ioctl for the
KVM_CAP_PPC_ENABLE_HCALL capability on the file descriptor for the VM.
The args field of the struct kvm_enable_cap specifies the hcall number
in args[0] and the enable/disable flag in args[1]; 0 means disable
in-kernel handling (so that the hcall will always cause an exit to
userspace) and 1 means enable.  Enabling or disabling in-kernel
handling of an hcall is effective across the whole VM.

The ability for KVM_ENABLE_CAP to be used on a VM file descriptor
on PowerPC is new, added by this commit.  The KVM_CAP_ENABLE_CAP_VM
capability advertises that this ability exists.

When a VM is created, an initial set of hcalls are enabled for
in-kernel handling.  The set that is enabled is the set that have
an in-kernel implementation at this point.  Any new hcall
implementations from this point onwards should not be added to the
default set without a good reason.

No distinction is made between real-mode and virtual-mode hcall
implementations; the one setting controls them both.

	Signed-off-by: Paul Mackerras <paulus@samba.org>
	Signed-off-by: Alexander Graf <agraf@suse.de>
(cherry picked from commit 699a0ea0823d32030b0666b28ff8633960f7ffa7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/virtual/kvm/api.txt
#	arch/powerpc/include/asm/kvm_book3s.h
#	arch/powerpc/kvm/book3s_hv.c
#	arch/powerpc/kvm/powerpc.c
#	include/uapi/linux/kvm.h
diff --cc Documentation/virtual/kvm/api.txt
index b2bc745240b2,5c54d196f4c8..000000000000
--- a/Documentation/virtual/kvm/api.txt
+++ b/Documentation/virtual/kvm/api.txt
@@@ -2703,8 -2792,79 +2703,84 @@@ and usually define the validity of a gr
  };
  
  
++<<<<<<< HEAD
 +6. Capabilities that can be enabled
 +-----------------------------------
++=======
+ 4.81 KVM_GET_EMULATED_CPUID
+ 
+ Capability: KVM_CAP_EXT_EMUL_CPUID
+ Architectures: x86
+ Type: system ioctl
+ Parameters: struct kvm_cpuid2 (in/out)
+ Returns: 0 on success, -1 on error
+ 
+ struct kvm_cpuid2 {
+ 	__u32 nent;
+ 	__u32 flags;
+ 	struct kvm_cpuid_entry2 entries[0];
+ };
+ 
+ The member 'flags' is used for passing flags from userspace.
+ 
+ #define KVM_CPUID_FLAG_SIGNIFCANT_INDEX		BIT(0)
+ #define KVM_CPUID_FLAG_STATEFUL_FUNC		BIT(1)
+ #define KVM_CPUID_FLAG_STATE_READ_NEXT		BIT(2)
+ 
+ struct kvm_cpuid_entry2 {
+ 	__u32 function;
+ 	__u32 index;
+ 	__u32 flags;
+ 	__u32 eax;
+ 	__u32 ebx;
+ 	__u32 ecx;
+ 	__u32 edx;
+ 	__u32 padding[3];
+ };
+ 
+ This ioctl returns x86 cpuid features which are emulated by
+ kvm.Userspace can use the information returned by this ioctl to query
+ which features are emulated by kvm instead of being present natively.
+ 
+ Userspace invokes KVM_GET_EMULATED_CPUID by passing a kvm_cpuid2
+ structure with the 'nent' field indicating the number of entries in
+ the variable-size array 'entries'. If the number of entries is too low
+ to describe the cpu capabilities, an error (E2BIG) is returned. If the
+ number is too high, the 'nent' field is adjusted and an error (ENOMEM)
+ is returned. If the number is just right, the 'nent' field is adjusted
+ to the number of valid entries in the 'entries' array, which is then
+ filled.
+ 
+ The entries returned are the set CPUID bits of the respective features
+ which kvm emulates, as returned by the CPUID instruction, with unknown
+ or unsupported feature bits cleared.
+ 
+ Features like x2apic, for example, may not be present in the host cpu
+ but are exposed by kvm in KVM_GET_SUPPORTED_CPUID because they can be
+ emulated efficiently and thus not included here.
+ 
+ The fields in each entry are defined as follows:
+ 
+   function: the eax value used to obtain the entry
+   index: the ecx value used to obtain the entry (for entries that are
+          affected by ecx)
+   flags: an OR of zero or more of the following:
+         KVM_CPUID_FLAG_SIGNIFCANT_INDEX:
+            if the index field is valid
+         KVM_CPUID_FLAG_STATEFUL_FUNC:
+            if cpuid for this function returns different values for successive
+            invocations; there will be several entries with the same function,
+            all with this flag set
+         KVM_CPUID_FLAG_STATE_READ_NEXT:
+            for KVM_CPUID_FLAG_STATEFUL_FUNC entries, set if this entry is
+            the first entry to be read by a cpu
+    eax, ebx, ecx, edx: the values returned by the cpuid instruction for
+          this function/index combination
+ 
+ 
+ 6. Capabilities that can be enabled on vCPUs
+ --------------------------------------------
++>>>>>>> 699a0ea0823d (KVM: PPC: Book3S: Controls for in-kernel sPAPR hypercall handling)
  
  There are certain capabilities that change the behavior of the virtual CPU when
  enabled. To enable them, please see section 4.37. Below you can find a list of
diff --cc arch/powerpc/include/asm/kvm_book3s.h
index 621f2858583f,052ab2ad49b5..000000000000
--- a/arch/powerpc/include/asm/kvm_book3s.h
+++ b/arch/powerpc/include/asm/kvm_book3s.h
@@@ -193,6 -187,11 +193,14 @@@ extern void kvmppc_load_up_vsx(void)
  extern u32 kvmppc_alignment_dsisr(struct kvm_vcpu *vcpu, unsigned int inst);
  extern ulong kvmppc_alignment_dar(struct kvm_vcpu *vcpu, unsigned int inst);
  extern int kvmppc_h_pr(struct kvm_vcpu *vcpu, unsigned long cmd);
++<<<<<<< HEAD
++=======
+ extern void kvmppc_pr_init_default_hcalls(struct kvm *kvm);
+ extern void kvmppc_copy_to_svcpu(struct kvmppc_book3s_shadow_vcpu *svcpu,
+ 				 struct kvm_vcpu *vcpu);
+ extern void kvmppc_copy_from_svcpu(struct kvm_vcpu *vcpu,
+ 				   struct kvmppc_book3s_shadow_vcpu *svcpu);
++>>>>>>> 699a0ea0823d (KVM: PPC: Book3S: Controls for in-kernel sPAPR hypercall handling)
  
  static inline struct kvmppc_vcpu_book3s *to_book3s(struct kvm_vcpu *vcpu)
  {
diff --cc arch/powerpc/kvm/book3s_hv.c
index 25619035861f,cf445d22570f..000000000000
--- a/arch/powerpc/kvm/book3s_hv.c
+++ b/arch/powerpc/kvm/book3s_hv.c
@@@ -1995,8 -2275,9 +2001,14 @@@ int kvmppc_core_init_vm(struct kvm *kvm
  	 */
  	cpumask_setall(&kvm->arch.need_tlb_flush);
  
++<<<<<<< HEAD
 +	INIT_LIST_HEAD(&kvm->arch.spapr_tce_tables);
 +	INIT_LIST_HEAD(&kvm->arch.rtas_tokens);
++=======
+ 	/* Start out with the default set of hcalls enabled */
+ 	memcpy(kvm->arch.enabled_hcalls, default_enabled_hcalls,
+ 	       sizeof(kvm->arch.enabled_hcalls));
++>>>>>>> 699a0ea0823d (KVM: PPC: Book3S: Controls for in-kernel sPAPR hypercall handling)
  
  	kvm->arch.rma = NULL;
  
@@@ -2070,17 -2358,154 +2082,155 @@@ int kvmppc_core_emulate_mfspr(struct kv
  	return EMULATE_FAIL;
  }
  
++<<<<<<< HEAD
 +static int kvmppc_book3s_hv_init(void)
++=======
+ static int kvmppc_core_check_processor_compat_hv(void)
+ {
+ 	if (!cpu_has_feature(CPU_FTR_HVMODE))
+ 		return -EIO;
+ 	return 0;
+ }
+ 
+ static long kvm_arch_vm_ioctl_hv(struct file *filp,
+ 				 unsigned int ioctl, unsigned long arg)
+ {
+ 	struct kvm *kvm __maybe_unused = filp->private_data;
+ 	void __user *argp = (void __user *)arg;
+ 	long r;
+ 
+ 	switch (ioctl) {
+ 
+ 	case KVM_ALLOCATE_RMA: {
+ 		struct kvm_allocate_rma rma;
+ 		struct kvm *kvm = filp->private_data;
+ 
+ 		r = kvm_vm_ioctl_allocate_rma(kvm, &rma);
+ 		if (r >= 0 && copy_to_user(argp, &rma, sizeof(rma)))
+ 			r = -EFAULT;
+ 		break;
+ 	}
+ 
+ 	case KVM_PPC_ALLOCATE_HTAB: {
+ 		u32 htab_order;
+ 
+ 		r = -EFAULT;
+ 		if (get_user(htab_order, (u32 __user *)argp))
+ 			break;
+ 		r = kvmppc_alloc_reset_hpt(kvm, &htab_order);
+ 		if (r)
+ 			break;
+ 		r = -EFAULT;
+ 		if (put_user(htab_order, (u32 __user *)argp))
+ 			break;
+ 		r = 0;
+ 		break;
+ 	}
+ 
+ 	case KVM_PPC_GET_HTAB_FD: {
+ 		struct kvm_get_htab_fd ghf;
+ 
+ 		r = -EFAULT;
+ 		if (copy_from_user(&ghf, argp, sizeof(ghf)))
+ 			break;
+ 		r = kvm_vm_ioctl_get_htab_fd(kvm, &ghf);
+ 		break;
+ 	}
+ 
+ 	default:
+ 		r = -ENOTTY;
+ 	}
+ 
+ 	return r;
+ }
+ 
+ /*
+  * List of hcall numbers to enable by default.
+  * For compatibility with old userspace, we enable by default
+  * all hcalls that were implemented before the hcall-enabling
+  * facility was added.  Note this list should not include H_RTAS.
+  */
+ static unsigned int default_hcall_list[] = {
+ 	H_REMOVE,
+ 	H_ENTER,
+ 	H_READ,
+ 	H_PROTECT,
+ 	H_BULK_REMOVE,
+ 	H_GET_TCE,
+ 	H_PUT_TCE,
+ 	H_SET_DABR,
+ 	H_SET_XDABR,
+ 	H_CEDE,
+ 	H_PROD,
+ 	H_CONFER,
+ 	H_REGISTER_VPA,
+ #ifdef CONFIG_KVM_XICS
+ 	H_EOI,
+ 	H_CPPR,
+ 	H_IPI,
+ 	H_IPOLL,
+ 	H_XIRR,
+ 	H_XIRR_X,
+ #endif
+ 	0
+ };
+ 
+ static void init_default_hcalls(void)
+ {
+ 	int i;
+ 
+ 	for (i = 0; default_hcall_list[i]; ++i)
+ 		__set_bit(default_hcall_list[i] / 4, default_enabled_hcalls);
+ }
+ 
+ static struct kvmppc_ops kvm_ops_hv = {
+ 	.get_sregs = kvm_arch_vcpu_ioctl_get_sregs_hv,
+ 	.set_sregs = kvm_arch_vcpu_ioctl_set_sregs_hv,
+ 	.get_one_reg = kvmppc_get_one_reg_hv,
+ 	.set_one_reg = kvmppc_set_one_reg_hv,
+ 	.vcpu_load   = kvmppc_core_vcpu_load_hv,
+ 	.vcpu_put    = kvmppc_core_vcpu_put_hv,
+ 	.set_msr     = kvmppc_set_msr_hv,
+ 	.vcpu_run    = kvmppc_vcpu_run_hv,
+ 	.vcpu_create = kvmppc_core_vcpu_create_hv,
+ 	.vcpu_free   = kvmppc_core_vcpu_free_hv,
+ 	.check_requests = kvmppc_core_check_requests_hv,
+ 	.get_dirty_log  = kvm_vm_ioctl_get_dirty_log_hv,
+ 	.flush_memslot  = kvmppc_core_flush_memslot_hv,
+ 	.prepare_memory_region = kvmppc_core_prepare_memory_region_hv,
+ 	.commit_memory_region  = kvmppc_core_commit_memory_region_hv,
+ 	.unmap_hva = kvm_unmap_hva_hv,
+ 	.unmap_hva_range = kvm_unmap_hva_range_hv,
+ 	.age_hva  = kvm_age_hva_hv,
+ 	.test_age_hva = kvm_test_age_hva_hv,
+ 	.set_spte_hva = kvm_set_spte_hva_hv,
+ 	.mmu_destroy  = kvmppc_mmu_destroy_hv,
+ 	.free_memslot = kvmppc_core_free_memslot_hv,
+ 	.create_memslot = kvmppc_core_create_memslot_hv,
+ 	.init_vm =  kvmppc_core_init_vm_hv,
+ 	.destroy_vm = kvmppc_core_destroy_vm_hv,
+ 	.get_smmu_info = kvm_vm_ioctl_get_smmu_info_hv,
+ 	.emulate_op = kvmppc_core_emulate_op_hv,
+ 	.emulate_mtspr = kvmppc_core_emulate_mtspr_hv,
+ 	.emulate_mfspr = kvmppc_core_emulate_mfspr_hv,
+ 	.fast_vcpu_kick = kvmppc_fast_vcpu_kick_hv,
+ 	.arch_vm_ioctl  = kvm_arch_vm_ioctl_hv,
+ };
+ 
+ static int kvmppc_book3s_init_hv(void)
++>>>>>>> 699a0ea0823d (KVM: PPC: Book3S: Controls for in-kernel sPAPR hypercall handling)
  {
  	int r;
 -	/*
 -	 * FIXME!! Do we need to check on all cpus ?
 -	 */
 -	r = kvmppc_core_check_processor_compat_hv();
 -	if (r < 0)
 -		return -ENODEV;
  
 -	kvm_ops_hv.owner = THIS_MODULE;
 -	kvmppc_hv_ops = &kvm_ops_hv;
 +	r = kvm_init(NULL, sizeof(struct kvm_vcpu), 0, THIS_MODULE);
 +
 +	if (r)
 +		return r;
  
+ 	init_default_hcalls();
+ 
  	r = kvmppc_mmu_hv_init();
 +
  	return r;
  }
  
diff --cc arch/powerpc/kvm/powerpc.c
index 126467ebd44f,3222a4d08a6f..000000000000
--- a/arch/powerpc/kvm/powerpc.c
+++ b/arch/powerpc/kvm/powerpc.c
@@@ -340,6 -417,8 +341,11 @@@ int kvm_dev_ioctl_check_extension(long 
  	case KVM_CAP_SPAPR_TCE:
  	case KVM_CAP_PPC_ALLOC_HTAB:
  	case KVM_CAP_PPC_RTAS:
++<<<<<<< HEAD
++=======
+ 	case KVM_CAP_PPC_FIXUP_HCALL:
+ 	case KVM_CAP_PPC_ENABLE_HCALL:
++>>>>>>> 699a0ea0823d (KVM: PPC: Book3S: Controls for in-kernel sPAPR hypercall handling)
  #ifdef CONFIG_KVM_XICS
  	case KVM_CAP_IRQ_XICS:
  #endif
diff --cc include/uapi/linux/kvm.h
index 1ba9af99e2bc,0418b746cb68..000000000000
--- a/include/uapi/linux/kvm.h
+++ b/include/uapi/linux/kvm.h
@@@ -667,8 -747,18 +667,18 @@@ struct kvm_ppc_smmu_info 
  #define KVM_CAP_IRQ_MPIC 90
  #define KVM_CAP_PPC_RTAS 91
  #define KVM_CAP_IRQ_XICS 92
 -#define KVM_CAP_ARM_EL1_32BIT 93
 -#define KVM_CAP_SPAPR_MULTITCE 94
 -#define KVM_CAP_EXT_EMUL_CPUID 95
  #define KVM_CAP_HYPERV_TIME 96
  #define KVM_CAP_IOAPIC_POLARITY_IGNORED 97
++<<<<<<< HEAD
++=======
+ #define KVM_CAP_ENABLE_CAP_VM 98
+ #define KVM_CAP_S390_IRQCHIP 99
+ #define KVM_CAP_IOEVENTFD_NO_LENGTH 100
+ #define KVM_CAP_VM_ATTRIBUTES 101
+ #define KVM_CAP_ARM_PSCI_0_2 102
+ #define KVM_CAP_PPC_FIXUP_HCALL 103
+ #define KVM_CAP_PPC_ENABLE_HCALL 104
++>>>>>>> 699a0ea0823d (KVM: PPC: Book3S: Controls for in-kernel sPAPR hypercall handling)
  
  #ifdef KVM_CAP_IRQ_ROUTING
  
* Unmerged path Documentation/virtual/kvm/api.txt
* Unmerged path arch/powerpc/include/asm/kvm_book3s.h
diff --git a/arch/powerpc/include/asm/kvm_host.h b/arch/powerpc/include/asm/kvm_host.h
index 80c8a73bb706..fe32187a049e 100644
--- a/arch/powerpc/include/asm/kvm_host.h
+++ b/arch/powerpc/include/asm/kvm_host.h
@@ -34,6 +34,7 @@
 #include <asm/processor.h>
 #include <asm/page.h>
 #include <asm/cacheflush.h>
+#include <asm/hvcall.h>
 
 #define KVM_MAX_VCPUS		NR_CPUS
 #define KVM_MAX_VCORES		NR_CPUS
@@ -268,6 +269,7 @@ struct kvm_arch {
 #ifdef CONFIG_PPC_BOOK3S_64
 	struct list_head spapr_tce_tables;
 	struct list_head rtas_tokens;
+	DECLARE_BITMAP(enabled_hcalls, MAX_HCALL_OPCODE/4 + 1);
 #endif
 #ifdef CONFIG_KVM_MPIC
 	struct openpic *mpic;
diff --git a/arch/powerpc/kernel/asm-offsets.c b/arch/powerpc/kernel/asm-offsets.c
index 79fa5c26d629..3c8ba851c609 100644
--- a/arch/powerpc/kernel/asm-offsets.c
+++ b/arch/powerpc/kernel/asm-offsets.c
@@ -477,6 +477,7 @@ int main(void)
 	DEFINE(KVM_HOST_SDR1, offsetof(struct kvm, arch.host_sdr1));
 	DEFINE(KVM_TLBIE_LOCK, offsetof(struct kvm, arch.tlbie_lock));
 	DEFINE(KVM_NEED_FLUSH, offsetof(struct kvm, arch.need_tlb_flush.bits));
+	DEFINE(KVM_ENABLED_HCALLS, offsetof(struct kvm, arch.enabled_hcalls));
 	DEFINE(KVM_LPCR, offsetof(struct kvm, arch.lpcr));
 	DEFINE(KVM_RMOR, offsetof(struct kvm, arch.rmor));
 	DEFINE(KVM_VRMA_SLB_V, offsetof(struct kvm, arch.vrma_slb_v));
* Unmerged path arch/powerpc/kvm/book3s_hv.c
diff --git a/arch/powerpc/kvm/book3s_hv_rmhandlers.S b/arch/powerpc/kvm/book3s_hv_rmhandlers.S
index 0ae4c28ae4b6..57924f719898 100644
--- a/arch/powerpc/kvm/book3s_hv_rmhandlers.S
+++ b/arch/powerpc/kvm/book3s_hv_rmhandlers.S
@@ -1497,6 +1497,17 @@ hcall_try_real_mode:
 	clrrdi	r3,r3,2
 	cmpldi	r3,hcall_real_table_end - hcall_real_table
 	bge	guest_exit_cont
+	/* See if this hcall is enabled for in-kernel handling */
+	ld	r4, VCPU_KVM(r9)
+	srdi	r0, r3, 8	/* r0 = (r3 / 4) >> 6 */
+	sldi	r0, r0, 3	/* index into kvm->arch.enabled_hcalls[] */
+	add	r4, r4, r0
+	ld	r0, KVM_ENABLED_HCALLS(r4)
+	rlwinm	r4, r3, 32-2, 0x3f	/* r4 = (r3 / 4) & 0x3f */
+	srd	r0, r0, r4
+	andi.	r0, r0, 1
+	beq	guest_exit_cont
+	/* Get pointer to handler, if any, and call it */
 	LOAD_REG_ADDR(r4, hcall_real_table)
 	lwax	r3,r3,r4
 	cmpwi	r3,0
diff --git a/arch/powerpc/kvm/book3s_pr.c b/arch/powerpc/kvm/book3s_pr.c
index 8956df8d25a8..5d995cae0d16 100644
--- a/arch/powerpc/kvm/book3s_pr.c
+++ b/arch/powerpc/kvm/book3s_pr.c
@@ -1417,6 +1417,11 @@ int kvmppc_core_init_vm(struct kvm *kvm)
 #endif
 	mutex_init(&kvm->arch.hpt_mutex);
 
+#ifdef CONFIG_PPC_BOOK3S_64
+	/* Start out with the default set of hcalls enabled */
+	kvmppc_pr_init_default_hcalls(kvm);
+#endif
+
 	if (firmware_has_feature(FW_FEATURE_SET_MODE)) {
 		spin_lock(&kvm_global_user_count_lock);
 		if (++kvm_global_user_count == 1)
diff --git a/arch/powerpc/kvm/book3s_pr_papr.c b/arch/powerpc/kvm/book3s_pr_papr.c
index 5efa97b993d8..5aeb46531142 100644
--- a/arch/powerpc/kvm/book3s_pr_papr.c
+++ b/arch/powerpc/kvm/book3s_pr_papr.c
@@ -258,6 +258,10 @@ static int kvmppc_h_pr_xics_hcall(struct kvm_vcpu *vcpu, u32 cmd)
 
 int kvmppc_h_pr(struct kvm_vcpu *vcpu, unsigned long cmd)
 {
+	if (cmd <= MAX_HCALL_OPCODE &&
+	    !test_bit(cmd/4, vcpu->kvm->arch.enabled_hcalls))
+		return EMULATE_FAIL;
+
 	switch (cmd) {
 	case H_ENTER:
 		return kvmppc_h_pr_enter(vcpu);
@@ -295,3 +299,36 @@ int kvmppc_h_pr(struct kvm_vcpu *vcpu, unsigned long cmd)
 
 	return EMULATE_FAIL;
 }
+
+
+/*
+ * List of hcall numbers to enable by default.
+ * For compatibility with old userspace, we enable by default
+ * all hcalls that were implemented before the hcall-enabling
+ * facility was added.  Note this list should not include H_RTAS.
+ */
+static unsigned int default_hcall_list[] = {
+	H_ENTER,
+	H_REMOVE,
+	H_PROTECT,
+	H_BULK_REMOVE,
+	H_PUT_TCE,
+	H_CEDE,
+#ifdef CONFIG_KVM_XICS
+	H_XIRR,
+	H_CPPR,
+	H_EOI,
+	H_IPI,
+	H_IPOLL,
+	H_XIRR_X,
+#endif
+	0
+};
+
+void kvmppc_pr_init_default_hcalls(struct kvm *kvm)
+{
+	int i;
+
+	for (i = 0; default_hcall_list[i]; ++i)
+		__set_bit(default_hcall_list[i] / 4, kvm->arch.enabled_hcalls);
+}
* Unmerged path arch/powerpc/kvm/powerpc.c
* Unmerged path include/uapi/linux/kvm.h
