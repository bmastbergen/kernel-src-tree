cpufreq: move call to __find_governor() to cpufreq_init_policy()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
Rebuild_CHGLOG: - [cpufreq] move call to __find_governor() to cpufreq_init_policy() (Prarit Bhargava) [1134369]
Rebuild_FUZZ: 92.44%
commit-author viresh kumar <viresh.kumar@linaro.org>
commit 6e2c89d16d987e6e11c531b039a42d3f5f1d7c32
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/6e2c89d1.failed

We call __find_governor() during the addition of the first CPU of
each policy from __cpufreq_add_dev() to find the last governor used
for this CPU before it was hot-removed.

After that we call cpufreq_parse_governor() in cpufreq_init_policy(),
either with this governor, or with the default governor. Right after
that policy->governor is set to NULL.

While that code is not functionally problematic, the structure of it
is suboptimal, because some of the code required in cpufreq_init_policy()
is being executed by its caller, __cpufreq_add_dev(). So, it would make
more sense to get all of it together in a single place to make code more
readable.

Accordingly, move the code needed for policy initialization to
cpufreq_init_policy() and initialize policy->governor to NULL at the
beginning.

In order to clean up the code a bit more, some of the #ifdefs for
CONFIG_HOTPLUG_CPU are dropped too.

	Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
[rjw: Changelog]
	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
(cherry picked from commit 6e2c89d16d987e6e11c531b039a42d3f5f1d7c32)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/cpufreq.c
diff --cc drivers/cpufreq/cpufreq.c
index c8bc717e8458,2de2f1ddd95f..000000000000
--- a/drivers/cpufreq/cpufreq.c
+++ b/drivers/cpufreq/cpufreq.c
@@@ -37,58 -37,19 +37,56 @@@
   */
  static struct cpufreq_driver *cpufreq_driver;
  static DEFINE_PER_CPU(struct cpufreq_policy *, cpufreq_cpu_data);
 -static DEFINE_PER_CPU(struct cpufreq_policy *, cpufreq_cpu_data_fallback);
  static DEFINE_RWLOCK(cpufreq_driver_lock);
 -DEFINE_MUTEX(cpufreq_governor_lock);
 -static LIST_HEAD(cpufreq_policy_list);
 +static DEFINE_MUTEX(cpufreq_governor_lock);
  
- #ifdef CONFIG_HOTPLUG_CPU
  /* This one keeps track of the previously set governor of a removed CPU */
  static DEFINE_PER_CPU(char[CPUFREQ_NAME_LEN], cpufreq_cpu_governor);
- #endif
  
 -static inline bool has_target(void)
 -{
 -	return cpufreq_driver->target_index || cpufreq_driver->target;
 +/*
 + * cpu_policy_rwsem is a per CPU reader-writer semaphore designed to cure
 + * all cpufreq/hotplug/workqueue/etc related lock issues.
 + *
 + * The rules for this semaphore:
 + * - Any routine that wants to read from the policy structure will
 + *   do a down_read on this semaphore.
 + * - Any routine that will write to the policy structure and/or may take away
 + *   the policy altogether (eg. CPU hotplug), will hold this lock in write
 + *   mode before doing so.
 + *
 + * Additional rules:
 + * - Governor routines that can be called in cpufreq hotplug path should not
 + *   take this sem as top level hotplug notifier handler takes this.
 + * - Lock should not be held across
 + *     __cpufreq_governor(data, CPUFREQ_GOV_STOP);
 + */
 +static DEFINE_PER_CPU(int, cpufreq_policy_cpu);
 +static DEFINE_PER_CPU(struct rw_semaphore, cpu_policy_rwsem);
 +
 +#define lock_policy_rwsem(mode, cpu)					\
 +static int lock_policy_rwsem_##mode(int cpu)				\
 +{									\
 +	int policy_cpu = per_cpu(cpufreq_policy_cpu, cpu);		\
 +	BUG_ON(policy_cpu == -1);					\
 +	down_##mode(&per_cpu(cpu_policy_rwsem, policy_cpu));		\
 +									\
 +	return 0;							\
 +}
 +
 +lock_policy_rwsem(read, cpu);
 +lock_policy_rwsem(write, cpu);
 +
 +#define unlock_policy_rwsem(mode, cpu)					\
 +static void unlock_policy_rwsem_##mode(int cpu)				\
 +{									\
 +	int policy_cpu = per_cpu(cpufreq_policy_cpu, cpu);		\
 +	BUG_ON(policy_cpu == -1);					\
 +	up_##mode(&per_cpu(cpu_policy_rwsem, policy_cpu));		\
  }
  
 +unlock_policy_rwsem(read, cpu);
 +unlock_policy_rwsem(write, cpu);
 +
  /*
   * rwsem to guarantee that cpufreq driver module doesn't unload during critical
   * sections
@@@ -857,15 -881,24 +856,33 @@@ static void cpufreq_init_policy(struct 
  	struct cpufreq_policy new_policy;
  	int ret = 0;
  
++<<<<<<< HEAD
 +	memcpy(&new_policy, policy, sizeof(struct cpufreq_policy));
 +	/* assure that the starting sequence is run in __cpufreq_set_policy */
 +	policy->governor = NULL;
++=======
+ 	memcpy(&new_policy, policy, sizeof(*policy));
+ 
+ 	/* Update governor of new_policy to the governor used before hotplug */
+ 	gov = __find_governor(per_cpu(cpufreq_cpu_governor, policy->cpu));
+ 	if (gov)
+ 		pr_debug("Restoring governor %s for cpu %d\n",
+ 				policy->governor->name, policy->cpu);
+ 	else
+ 		gov = CPUFREQ_DEFAULT_GOVERNOR;
+ 
+ 	new_policy.governor = gov;
+ 
+ 	/* Use the default policy if its valid. */
+ 	if (cpufreq_driver->setpolicy)
+ 		cpufreq_parse_governor(gov->name, &new_policy.policy, NULL);
++>>>>>>> 6e2c89d16d98 (cpufreq: move call to __find_governor() to cpufreq_init_policy())
  
  	/* set default policy */
 -	ret = cpufreq_set_policy(policy, &new_policy);
 +	ret = __cpufreq_set_policy(policy, &new_policy);
 +	policy->user_policy.policy = policy->policy;
 +	policy->user_policy.governor = policy->governor;
 +
  	if (ret) {
  		pr_debug("setting policy failed\n");
  		if (cpufreq_driver->exit)
@@@ -911,24 -943,106 +928,124 @@@ static int cpufreq_add_policy_cpu(unsig
  }
  #endif
  
++<<<<<<< HEAD
 +/**
 + * cpufreq_add_dev - add a CPU device
 + *
 + * Adds the cpufreq interface for a CPU device.
 + *
 + * The Oracle says: try running cpufreq registration/unregistration concurrently
 + * with with cpu hotplugging and all hell will break loose. Tried to clean this
 + * mess up, but more thorough testing is needed. - Mathieu
 + */
 +static int cpufreq_add_dev(struct device *dev, struct subsys_interface *sif)
++=======
+ static struct cpufreq_policy *cpufreq_policy_restore(unsigned int cpu)
+ {
+ 	struct cpufreq_policy *policy;
+ 	unsigned long flags;
+ 
+ 	read_lock_irqsave(&cpufreq_driver_lock, flags);
+ 
+ 	policy = per_cpu(cpufreq_cpu_data_fallback, cpu);
+ 
+ 	read_unlock_irqrestore(&cpufreq_driver_lock, flags);
+ 
+ 	policy->governor = NULL;
+ 
+ 	return policy;
+ }
+ 
+ static struct cpufreq_policy *cpufreq_policy_alloc(void)
+ {
+ 	struct cpufreq_policy *policy;
+ 
+ 	policy = kzalloc(sizeof(*policy), GFP_KERNEL);
+ 	if (!policy)
+ 		return NULL;
+ 
+ 	if (!alloc_cpumask_var(&policy->cpus, GFP_KERNEL))
+ 		goto err_free_policy;
+ 
+ 	if (!zalloc_cpumask_var(&policy->related_cpus, GFP_KERNEL))
+ 		goto err_free_cpumask;
+ 
+ 	INIT_LIST_HEAD(&policy->policy_list);
+ 	init_rwsem(&policy->rwsem);
+ 
+ 	return policy;
+ 
+ err_free_cpumask:
+ 	free_cpumask_var(policy->cpus);
+ err_free_policy:
+ 	kfree(policy);
+ 
+ 	return NULL;
+ }
+ 
+ static void cpufreq_policy_put_kobj(struct cpufreq_policy *policy)
+ {
+ 	struct kobject *kobj;
+ 	struct completion *cmp;
+ 
+ 	blocking_notifier_call_chain(&cpufreq_policy_notifier_list,
+ 			CPUFREQ_REMOVE_POLICY, policy);
+ 
+ 	down_read(&policy->rwsem);
+ 	kobj = &policy->kobj;
+ 	cmp = &policy->kobj_unregister;
+ 	up_read(&policy->rwsem);
+ 	kobject_put(kobj);
+ 
+ 	/*
+ 	 * We need to make sure that the underlying kobj is
+ 	 * actually not referenced anymore by anybody before we
+ 	 * proceed with unloading.
+ 	 */
+ 	pr_debug("waiting for dropping of refcount\n");
+ 	wait_for_completion(cmp);
+ 	pr_debug("wait complete\n");
+ }
+ 
+ static void cpufreq_policy_free(struct cpufreq_policy *policy)
+ {
+ 	free_cpumask_var(policy->related_cpus);
+ 	free_cpumask_var(policy->cpus);
+ 	kfree(policy);
+ }
+ 
+ static void update_policy_cpu(struct cpufreq_policy *policy, unsigned int cpu)
+ {
+ 	if (WARN_ON(cpu == policy->cpu))
+ 		return;
+ 
+ 	down_write(&policy->rwsem);
+ 
+ 	policy->last_cpu = policy->cpu;
+ 	policy->cpu = cpu;
+ 
+ 	up_write(&policy->rwsem);
+ 
+ 	cpufreq_frequency_table_update_policy_cpu(policy);
+ 	blocking_notifier_call_chain(&cpufreq_policy_notifier_list,
+ 			CPUFREQ_UPDATE_POLICY_CPU, policy);
+ }
+ 
+ static int __cpufreq_add_dev(struct device *dev, struct subsys_interface *sif,
+ 			     bool frozen)
++>>>>>>> 6e2c89d16d98 (cpufreq: move call to __find_governor() to cpufreq_init_policy())
  {
  	unsigned int j, cpu = dev->id;
  	int ret = -ENOMEM;
  	struct cpufreq_policy *policy;
  	unsigned long flags;
  #ifdef CONFIG_HOTPLUG_CPU
++<<<<<<< HEAD
 +	struct cpufreq_governor *gov;
 +	int sibling;
++=======
+ 	struct cpufreq_policy *tpolicy;
++>>>>>>> 6e2c89d16d98 (cpufreq: move call to __find_governor() to cpufreq_init_policy())
  #endif
  
  	if (cpu_is_offline(cpu))
@@@ -964,23 -1077,31 +1081,26 @@@
  	read_unlock_irqrestore(&cpufreq_driver_lock, flags);
  #endif
  
 -	/*
 -	 * Restore the saved policy when doing light-weight init and fall back
 -	 * to the full init if that fails.
 -	 */
 -	policy = frozen ? cpufreq_policy_restore(cpu) : NULL;
 -	if (!policy) {
 -		frozen = false;
 -		policy = cpufreq_policy_alloc();
 -		if (!policy)
 -			goto nomem_out;
 -	}
 +	policy = kzalloc(sizeof(struct cpufreq_policy), GFP_KERNEL);
 +	if (!policy)
 +		goto nomem_out;
  
 -	/*
 -	 * In the resume path, since we restore a saved policy, the assignment
 -	 * to policy->cpu is like an update of the existing policy, rather than
 -	 * the creation of a brand new one. So we need to perform this update
 -	 * by invoking update_policy_cpu().
 -	 */
 -	if (frozen && cpu != policy->cpu)
 -		update_policy_cpu(policy, cpu);
 -	else
 -		policy->cpu = cpu;
 +	if (!alloc_cpumask_var(&policy->cpus, GFP_KERNEL))
 +		goto err_free_policy;
  
++<<<<<<< HEAD
 +	if (!zalloc_cpumask_var(&policy->related_cpus, GFP_KERNEL))
 +		goto err_free_cpumask;
 +
 +	policy->cpu = cpu;
 +	policy->governor = CPUFREQ_DEFAULT_GOVERNOR;
++=======
++>>>>>>> 6e2c89d16d98 (cpufreq: move call to __find_governor() to cpufreq_init_policy())
  	cpumask_copy(policy->cpus, cpumask_of(cpu));
  
 +	/* Initially set CPU itself as the policy_cpu */
 +	per_cpu(cpufreq_policy_cpu, cpu) = cpu;
 +
  	init_completion(&policy->kobj_unregister);
  	INIT_WORK(&policy->update, handle_update);
  
@@@ -1056,27 -1185,25 +1176,37 @@@
  	blocking_notifier_call_chain(&cpufreq_policy_notifier_list,
  				     CPUFREQ_START, policy);
  
++<<<<<<< HEAD
 +#ifdef CONFIG_HOTPLUG_CPU
 +	gov = __find_governor(per_cpu(cpufreq_cpu_governor, cpu));
 +	if (gov) {
 +		policy->governor = gov;
 +		pr_debug("Restoring governor %s for cpu %d\n",
 +		       policy->governor->name, cpu);
 +	}
 +#endif
++=======
+ 	if (!frozen) {
+ 		ret = cpufreq_add_dev_interface(policy, dev);
+ 		if (ret)
+ 			goto err_out_unregister;
+ 		blocking_notifier_call_chain(&cpufreq_policy_notifier_list,
+ 				CPUFREQ_CREATE_POLICY, policy);
+ 	}
++>>>>>>> 6e2c89d16d98 (cpufreq: move call to __find_governor() to cpufreq_init_policy())
  
  	write_lock_irqsave(&cpufreq_driver_lock, flags);
 -	list_add(&policy->policy_list, &cpufreq_policy_list);
 +	for_each_cpu(j, policy->cpus) {
 +		per_cpu(cpufreq_cpu_data, j) = policy;
 +		per_cpu(cpufreq_policy_cpu, j) = policy->cpu;
 +	}
  	write_unlock_irqrestore(&cpufreq_driver_lock, flags);
  
 -	cpufreq_init_policy(policy);
 +	ret = cpufreq_add_dev_interface(cpu, policy, dev);
 +	if (ret)
 +		goto err_out_unregister;
  
 -	if (!frozen) {
 -		policy->user_policy.policy = policy->policy;
 -		policy->user_policy.governor = policy->governor;
 -	}
 -	up_write(&policy->rwsem);
 +	cpufreq_init_policy(policy);
  
  	kobject_uevent(&policy->kobj, KOBJ_ADD);
  	up_read(&cpufreq_rwsem);
@@@ -1186,33 -1302,33 +1316,36 @@@ static int __cpufreq_remove_dev(struct 
  		return -EINVAL;
  	}
  
 -	if (has_target()) {
 -		ret = __cpufreq_governor(policy, CPUFREQ_GOV_STOP);
 -		if (ret) {
 -			pr_err("%s: Failed to stop governor\n", __func__);
 -			return ret;
 -		}
 -	}
 +	if (cpufreq_driver->target)
 +		__cpufreq_governor(data, CPUFREQ_GOV_STOP);
  
- #ifdef CONFIG_HOTPLUG_CPU
  	if (!cpufreq_driver->setpolicy)
  		strncpy(per_cpu(cpufreq_cpu_governor, cpu),
++<<<<<<< HEAD
 +			data->governor->name, CPUFREQ_NAME_LEN);
 +#endif
++=======
+ 			policy->governor->name, CPUFREQ_NAME_LEN);
++>>>>>>> 6e2c89d16d98 (cpufreq: move call to __find_governor() to cpufreq_init_policy())
  
 -	down_read(&policy->rwsem);
 -	cpus = cpumask_weight(policy->cpus);
 -	up_read(&policy->rwsem);
 +	WARN_ON(lock_policy_rwsem_write(cpu));
 +	cpus = cpumask_weight(data->cpus);
 +
 +	if (cpus > 1)
 +		cpumask_clear_cpu(cpu, data->cpus);
 +	unlock_policy_rwsem_write(cpu);
  
 -	if (cpu != policy->cpu) {
 +	if (cpu != data->cpu) {
  		sysfs_remove_link(&dev->kobj, "cpufreq");
  	} else if (cpus > 1) {
 -		new_cpu = cpufreq_nominate_new_policy_cpu(policy, cpu);
 -		if (new_cpu >= 0) {
 -			update_policy_cpu(policy, new_cpu);
  
 -			if (!frozen) {
 -				pr_debug("%s: policy Kobject moved to cpu: %d from: %d\n",
 -						__func__, new_cpu, cpu);
 -			}
 +		new_cpu = cpufreq_nominate_new_policy_cpu(data, cpu);
 +		if (new_cpu >= 0) {
 +			WARN_ON(lock_policy_rwsem_write(cpu));
 +			update_policy_cpu(data, new_cpu);
 +			unlock_policy_rwsem_write(cpu);
 +			pr_debug("%s: policy Kobject moved to cpu: %d "
 +				 "from: %d\n",__func__, new_cpu, cpu);
  		}
  	}
  
* Unmerged path drivers/cpufreq/cpufreq.c
