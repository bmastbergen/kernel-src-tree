ceph: handle cap import atomically

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
commit-author Yan, Zheng <zheng.z.yan@intel.com>
commit 2cd698be9a3d3a0f8f3c66814eac34144c31954c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/2cd698be.failed

cap import messages are processed by both handle_cap_import() and
handle_cap_grant(). These two functions are not executed in the same
atomic context, so they can races with cap release.

The fix is make handle_cap_import() not release the i_ceph_lock when
it returns. Let handle_cap_grant() release the lock after it finishes
its job.

	Signed-off-by: Yan, Zheng <zheng.z.yan@intel.com>
(cherry picked from commit 2cd698be9a3d3a0f8f3c66814eac34144c31954c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/ceph/caps.c
diff --cc fs/ceph/caps.c
index 5db8817ba1a5,9f2c99c34e92..000000000000
--- a/fs/ceph/caps.c
+++ b/fs/ceph/caps.c
@@@ -2583,6 -2577,24 +2576,27 @@@ static void handle_cap_grant(struct cep
  	BUG_ON(cap->issued & ~cap->implemented);
  
  	spin_unlock(&ci->i_ceph_lock);
++<<<<<<< HEAD
++=======
+ 
+ 	if (le32_to_cpu(grant->op) == CEPH_CAP_OP_IMPORT) {
+ 		down_write(&mdsc->snap_rwsem);
+ 		ceph_update_snap_trace(mdsc, snaptrace,
+ 				       snaptrace + snaptrace_len, false);
+ 		downgrade_write(&mdsc->snap_rwsem);
+ 		kick_flushing_inode_caps(mdsc, session, inode);
+ 		up_read(&mdsc->snap_rwsem);
+ 		if (newcaps & ~issued)
+ 			wake = 1;
+ 	}
+ 
+ 	if (queue_trunc) {
+ 		ceph_queue_vmtruncate(inode);
+ 		ceph_queue_revalidate(inode);
+ 	} else if (queue_revalidate)
+ 		ceph_queue_revalidate(inode);
+ 
++>>>>>>> 2cd698be9a3d (ceph: handle cap import atomically)
  	if (writeback)
  		/*
  		 * queue inode for writeback: we can't actually call
@@@ -2883,12 -2898,14 +2896,18 @@@ static void handle_cap_import(struct ce
  			      struct inode *inode, struct ceph_mds_caps *im,
  			      struct ceph_mds_cap_peer *ph,
  			      struct ceph_mds_session *session,
- 			      void *snaptrace, int snaptrace_len)
+ 			      struct ceph_cap **target_cap, int *old_issued)
+ 	__acquires(ci->i_ceph_lock)
  {
  	struct ceph_inode_info *ci = ceph_inode(inode);
++<<<<<<< HEAD
 +	struct ceph_cap *cap;
++=======
+ 	struct ceph_cap *cap, *ocap, *new_cap = NULL;
++>>>>>>> 2cd698be9a3d (ceph: handle cap import atomically)
  	int mds = session->s_mds;
- 	unsigned issued = le32_to_cpu(im->caps);
+ 	int issued;
+ 	unsigned caps = le32_to_cpu(im->caps);
  	unsigned wanted = le32_to_cpu(im->wanted);
  	unsigned seq = le32_to_cpu(im->seq);
  	unsigned mseq = le32_to_cpu(im->migrate_seq);
@@@ -2908,40 -2925,52 +2927,74 @@@
  	dout("handle_cap_import inode %p ci %p mds%d mseq %d peer %d\n",
  	     inode, ci, mds, mseq, peer);
  
 -retry:
  	spin_lock(&ci->i_ceph_lock);
++<<<<<<< HEAD
 +	cap = peer >= 0 ? __get_cap_for_mds(ci, peer) : NULL;
 +	if (cap && cap->cap_id == p_cap_id) {
++=======
+ 	cap = __get_cap_for_mds(ci, mds);
+ 	if (!cap) {
+ 		if (!new_cap) {
+ 			spin_unlock(&ci->i_ceph_lock);
+ 			new_cap = ceph_get_cap(mdsc, NULL);
+ 			goto retry;
+ 		}
+ 		cap = new_cap;
+ 	} else {
+ 		if (new_cap) {
+ 			ceph_put_cap(mdsc, new_cap);
+ 			new_cap = NULL;
+ 		}
+ 	}
+ 
+ 	__ceph_caps_issued(ci, &issued);
+ 	issued |= __ceph_caps_dirty(ci);
+ 
+ 	ceph_add_cap(inode, session, cap_id, -1, caps, wanted, seq, mseq,
+ 		     realmino, CEPH_CAP_FLAG_AUTH, &new_cap);
+ 
+ 	ocap = peer >= 0 ? __get_cap_for_mds(ci, peer) : NULL;
+ 	if (ocap && ocap->cap_id == p_cap_id) {
++>>>>>>> 2cd698be9a3d (ceph: handle cap import atomically)
  		dout(" remove export cap %p mds%d flags %d\n",
- 		     cap, peer, ph->flags);
+ 		     ocap, peer, ph->flags);
  		if ((ph->flags & CEPH_CAP_FLAG_AUTH) &&
- 		    (cap->seq != le32_to_cpu(ph->seq) ||
- 		     cap->mseq != le32_to_cpu(ph->mseq))) {
+ 		    (ocap->seq != le32_to_cpu(ph->seq) ||
+ 		     ocap->mseq != le32_to_cpu(ph->mseq))) {
  			pr_err("handle_cap_import: mismatched seq/mseq: "
  			       "ino (%llx.%llx) mds%d seq %d mseq %d "
  			       "importer mds%d has peer seq %d mseq %d\n",
- 			       ceph_vinop(inode), peer, cap->seq,
- 			       cap->mseq, mds, le32_to_cpu(ph->seq),
+ 			       ceph_vinop(inode), peer, ocap->seq,
+ 			       ocap->mseq, mds, le32_to_cpu(ph->seq),
  			       le32_to_cpu(ph->mseq));
  		}
++<<<<<<< HEAD
 +		ci->i_cap_exporting_issued = cap->issued;
 +		__ceph_remove_cap(cap, (ph->flags & CEPH_CAP_FLAG_RELEASE));
++=======
+ 		__ceph_remove_cap(ocap, (ph->flags & CEPH_CAP_FLAG_RELEASE));
++>>>>>>> 2cd698be9a3d (ceph: handle cap import atomically)
  	}
  
  	/* make sure we re-request max_size, if necessary */
  	ci->i_wanted_max_size = 0;
  	ci->i_requested_max_size = 0;
- 	spin_unlock(&ci->i_ceph_lock);
  
++<<<<<<< HEAD
 +	down_write(&mdsc->snap_rwsem);
 +	ceph_update_snap_trace(mdsc, snaptrace, snaptrace+snaptrace_len,
 +			       false);
 +	downgrade_write(&mdsc->snap_rwsem);
 +	ceph_add_cap(inode, session, cap_id, -1,
 +		     issued, wanted, seq, mseq, realmino, CEPH_CAP_FLAG_AUTH,
 +		     NULL /* no caps context */);
 +	kick_flushing_inode_caps(mdsc, session, inode);
 +	up_read(&mdsc->snap_rwsem);
 +
++=======
+ 	*old_issued = issued;
+ 	*target_cap = cap;
++>>>>>>> 2cd698be9a3d (ceph: handle cap import atomically)
  }
  
  /*
* Unmerged path fs/ceph/caps.c
