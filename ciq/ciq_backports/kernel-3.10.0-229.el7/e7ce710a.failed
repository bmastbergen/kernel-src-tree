xprtrdma: Avoid deadlock when credit window is reset

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
Rebuild_CHGLOG: - [net] sunrpc/xprtrdma: Avoid deadlock when credit window is reset (Steve Dickson) [1113248]
Rebuild_FUZZ: 93.69%
commit-author Chuck Lever <chuck.lever@oracle.com>
commit e7ce710a8802351bd4118c5d6136c1d850f67cf9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/e7ce710a.failed

Update the cwnd while processing the server's reply.  Otherwise the
next task on the xprt_sending queue is still subject to the old
credit window. Currently, no task is awoken if the old congestion
window is still exceeded, even if the new window is larger, and a
deadlock results.

This is an issue during a transport reconnect. Servers don't
normally shrink the credit window, but the client does reset it to
1 when reconnecting so the server can safely grow it again.

As a minor optimization, remove the hack of grabbing the initial
cwnd size (which happens to be RPC_CWNDSCALE) and using that value
as the congestion scaling factor. The scaling value is invariant,
and we are better off without the multiplication operation.

	Signed-off-by: Chuck Lever <chuck.lever@oracle.com>
	Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
(cherry picked from commit e7ce710a8802351bd4118c5d6136c1d850f67cf9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sunrpc/xprtrdma/rpc_rdma.c
diff --cc net/sunrpc/xprtrdma/rpc_rdma.c
index d8cf393c8eb6,77b84cfa5c77..000000000000
--- a/net/sunrpc/xprtrdma/rpc_rdma.c
+++ b/net/sunrpc/xprtrdma/rpc_rdma.c
@@@ -727,7 -715,8 +727,12 @@@ rpcrdma_reply_handler(struct rpcrdma_re
  	struct rpc_xprt *xprt = rep->rr_xprt;
  	struct rpcrdma_xprt *r_xprt = rpcx_to_rdmax(xprt);
  	__be32 *iptr;
++<<<<<<< HEAD
 +	int i, rdmalen, status;
++=======
+ 	int rdmalen, status;
+ 	unsigned long cwnd;
++>>>>>>> e7ce710a8802 (xprtrdma: Avoid deadlock when credit window is reset)
  
  	/* Check status. If bad, signal disconnect and return rep to pool */
  	if (rep->rr_len == ~0U) {
@@@ -857,26 -846,10 +862,33 @@@ badheader
  		break;
  	}
  
++<<<<<<< HEAD
 +	/* If using mw bind, start the deregister process now. */
 +	/* (Note: if mr_free(), cannot perform it here, in tasklet context) */
 +	if (req->rl_nchunks) switch (r_xprt->rx_ia.ri_memreg_strategy) {
 +	case RPCRDMA_MEMWINDOWS:
 +		for (i = 0; req->rl_nchunks-- > 1;)
 +			i += rpcrdma_deregister_external(
 +				&req->rl_segments[i], r_xprt, NULL);
 +		/* Optionally wait (not here) for unbinds to complete */
 +		rep->rr_func = rpcrdma_unbind_func;
 +		(void) rpcrdma_deregister_external(&req->rl_segments[i],
 +						   r_xprt, rep);
 +		break;
 +	case RPCRDMA_MEMWINDOWS_ASYNC:
 +		for (i = 0; req->rl_nchunks--;)
 +			i += rpcrdma_deregister_external(&req->rl_segments[i],
 +							 r_xprt, NULL);
 +		break;
 +	default:
 +		break;
 +	}
++=======
+ 	cwnd = xprt->cwnd;
+ 	xprt->cwnd = atomic_read(&r_xprt->rx_buf.rb_credits) << RPC_CWNDSHIFT;
+ 	if (xprt->cwnd > cwnd)
+ 		xprt_release_rqst_cong(rqst->rq_task);
++>>>>>>> e7ce710a8802 (xprtrdma: Avoid deadlock when credit window is reset)
  
  	dprintk("RPC:       %s: xprt_complete_rqst(0x%p, 0x%p, %d)\n",
  			__func__, xprt, rqst, status);
* Unmerged path net/sunrpc/xprtrdma/rpc_rdma.c
diff --git a/net/sunrpc/xprtrdma/transport.c b/net/sunrpc/xprtrdma/transport.c
index 8b03bef87044..8bfa045dbdec 100644
--- a/net/sunrpc/xprtrdma/transport.c
+++ b/net/sunrpc/xprtrdma/transport.c
@@ -448,23 +448,6 @@ xprt_rdma_connect(struct rpc_xprt *xprt, struct rpc_task *task)
 	}
 }
 
-static int
-xprt_rdma_reserve_xprt(struct rpc_xprt *xprt, struct rpc_task *task)
-{
-	struct rpcrdma_xprt *r_xprt = rpcx_to_rdmax(xprt);
-	int credits = atomic_read(&r_xprt->rx_buf.rb_credits);
-
-	/* == RPC_CWNDSCALE @ init, but *after* setup */
-	if (r_xprt->rx_buf.rb_cwndscale == 0UL) {
-		r_xprt->rx_buf.rb_cwndscale = xprt->cwnd;
-		dprintk("RPC:       %s: cwndscale %lu\n", __func__,
-			r_xprt->rx_buf.rb_cwndscale);
-		BUG_ON(r_xprt->rx_buf.rb_cwndscale <= 0);
-	}
-	xprt->cwnd = credits * r_xprt->rx_buf.rb_cwndscale;
-	return xprt_reserve_xprt_cong(xprt, task);
-}
-
 /*
  * The RDMA allocate/free functions need the task structure as a place
  * to hide the struct rpcrdma_req, which is necessary for the actual send/recv
@@ -693,7 +676,7 @@ static void xprt_rdma_print_stats(struct rpc_xprt *xprt, struct seq_file *seq)
  */
 
 static struct rpc_xprt_ops xprt_rdma_procs = {
-	.reserve_xprt		= xprt_rdma_reserve_xprt,
+	.reserve_xprt		= xprt_reserve_xprt_cong,
 	.release_xprt		= xprt_release_xprt_cong, /* sunrpc/xprt.c */
 	.alloc_slot		= xprt_alloc_slot,
 	.release_request	= xprt_release_rqst_cong,       /* ditto */
diff --git a/net/sunrpc/xprtrdma/xprt_rdma.h b/net/sunrpc/xprtrdma/xprt_rdma.h
index cd7bc9218343..cb15f2b8af62 100644
--- a/net/sunrpc/xprtrdma/xprt_rdma.h
+++ b/net/sunrpc/xprtrdma/xprt_rdma.h
@@ -210,7 +210,6 @@ struct rpcrdma_req {
 struct rpcrdma_buffer {
 	spinlock_t	rb_lock;	/* protects indexes */
 	atomic_t	rb_credits;	/* most recent server credits */
-	unsigned long	rb_cwndscale;	/* cached framework rpc_cwndscale */
 	int		rb_max_requests;/* client max requests */
 	struct list_head rb_mws;	/* optional memory windows/fmrs/frmrs */
 	int		rb_send_index;
