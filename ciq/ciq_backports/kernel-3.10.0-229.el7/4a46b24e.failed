openvswitch: Use exact lookup for flow_get and flow_del.

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
Rebuild_CHGLOG: - [net] openvswitch: Use exact lookup for flow_get and flow_del (Jiri Benc) [1110384]
Rebuild_FUZZ: 99.10%
commit-author Alex Wang <alexw@nicira.com>
commit 4a46b24e147dfa9b858026da02cad0bdd4e149d2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/4a46b24e.failed

Due to the race condition in userspace, there is chance that two
overlapping megaflows could be installed in datapath.  And this
causes userspace unable to delete the less inclusive megaflow flow
even after it timeout, since the flow_del logic will stop at the
first match of masked flow.

This commit fixes the bug by making the kernel flow_del and flow_get
logic check all masks in that case.

Introduced by 03f0d916a (openvswitch: Mega flow implementation).

	Signed-off-by: Alex Wang <alexw@nicira.com>
	Acked-by: Andy Zhou <azhou@nicira.com>
	Signed-off-by: Pravin B Shelar <pshelar@nicira.com>
(cherry picked from commit 4a46b24e147dfa9b858026da02cad0bdd4e149d2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/openvswitch/datapath.c
diff --cc net/openvswitch/datapath.c
index 18b658c8c6ae,9db4bf6740d1..000000000000
--- a/net/openvswitch/datapath.c
+++ b/net/openvswitch/datapath.c
@@@ -770,7 -790,145 +770,149 @@@ static struct sk_buff *ovs_flow_cmd_bui
  	return skb;
  }
  
++<<<<<<< HEAD
 +static int ovs_flow_cmd_new_or_set(struct sk_buff *skb, struct genl_info *info)
++=======
+ static int ovs_flow_cmd_new(struct sk_buff *skb, struct genl_info *info)
+ {
+ 	struct nlattr **a = info->attrs;
+ 	struct ovs_header *ovs_header = info->userhdr;
+ 	struct sw_flow *flow, *new_flow;
+ 	struct sw_flow_mask mask;
+ 	struct sk_buff *reply;
+ 	struct datapath *dp;
+ 	struct sw_flow_actions *acts;
+ 	struct sw_flow_match match;
+ 	int error;
+ 
+ 	/* Must have key and actions. */
+ 	error = -EINVAL;
+ 	if (!a[OVS_FLOW_ATTR_KEY])
+ 		goto error;
+ 	if (!a[OVS_FLOW_ATTR_ACTIONS])
+ 		goto error;
+ 
+ 	/* Most of the time we need to allocate a new flow, do it before
+ 	 * locking.
+ 	 */
+ 	new_flow = ovs_flow_alloc();
+ 	if (IS_ERR(new_flow)) {
+ 		error = PTR_ERR(new_flow);
+ 		goto error;
+ 	}
+ 
+ 	/* Extract key. */
+ 	ovs_match_init(&match, &new_flow->unmasked_key, &mask);
+ 	error = ovs_nla_get_match(&match,
+ 				  a[OVS_FLOW_ATTR_KEY], a[OVS_FLOW_ATTR_MASK]);
+ 	if (error)
+ 		goto err_kfree_flow;
+ 
+ 	ovs_flow_mask_key(&new_flow->key, &new_flow->unmasked_key, &mask);
+ 
+ 	/* Validate actions. */
+ 	acts = ovs_nla_alloc_flow_actions(nla_len(a[OVS_FLOW_ATTR_ACTIONS]));
+ 	error = PTR_ERR(acts);
+ 	if (IS_ERR(acts))
+ 		goto err_kfree_flow;
+ 
+ 	error = ovs_nla_copy_actions(a[OVS_FLOW_ATTR_ACTIONS], &new_flow->key,
+ 				     0, &acts);
+ 	if (error) {
+ 		OVS_NLERR("Flow actions may not be safe on all matching packets.\n");
+ 		goto err_kfree_acts;
+ 	}
+ 
+ 	reply = ovs_flow_cmd_alloc_info(acts, info, false);
+ 	if (IS_ERR(reply)) {
+ 		error = PTR_ERR(reply);
+ 		goto err_kfree_acts;
+ 	}
+ 
+ 	ovs_lock();
+ 	dp = get_dp(sock_net(skb->sk), ovs_header->dp_ifindex);
+ 	if (unlikely(!dp)) {
+ 		error = -ENODEV;
+ 		goto err_unlock_ovs;
+ 	}
+ 	/* Check if this is a duplicate flow */
+ 	flow = ovs_flow_tbl_lookup(&dp->table, &new_flow->unmasked_key);
+ 	if (likely(!flow)) {
+ 		rcu_assign_pointer(new_flow->sf_acts, acts);
+ 
+ 		/* Put flow in bucket. */
+ 		error = ovs_flow_tbl_insert(&dp->table, new_flow, &mask);
+ 		if (unlikely(error)) {
+ 			acts = NULL;
+ 			goto err_unlock_ovs;
+ 		}
+ 
+ 		if (unlikely(reply)) {
+ 			error = ovs_flow_cmd_fill_info(new_flow,
+ 						       ovs_header->dp_ifindex,
+ 						       reply, info->snd_portid,
+ 						       info->snd_seq, 0,
+ 						       OVS_FLOW_CMD_NEW);
+ 			BUG_ON(error < 0);
+ 		}
+ 		ovs_unlock();
+ 	} else {
+ 		struct sw_flow_actions *old_acts;
+ 
+ 		/* Bail out if we're not allowed to modify an existing flow.
+ 		 * We accept NLM_F_CREATE in place of the intended NLM_F_EXCL
+ 		 * because Generic Netlink treats the latter as a dump
+ 		 * request.  We also accept NLM_F_EXCL in case that bug ever
+ 		 * gets fixed.
+ 		 */
+ 		if (unlikely(info->nlhdr->nlmsg_flags & (NLM_F_CREATE
+ 							 | NLM_F_EXCL))) {
+ 			error = -EEXIST;
+ 			goto err_unlock_ovs;
+ 		}
+ 		/* The unmasked key has to be the same for flow updates. */
+ 		if (unlikely(!ovs_flow_cmp_unmasked_key(flow, &match))) {
+ 			flow = ovs_flow_tbl_lookup_exact(&dp->table, &match);
+ 			if (!flow) {
+ 				error = -ENOENT;
+ 				goto err_unlock_ovs;
+ 			}
+ 		}
+ 		/* Update actions. */
+ 		old_acts = ovsl_dereference(flow->sf_acts);
+ 		rcu_assign_pointer(flow->sf_acts, acts);
+ 
+ 		if (unlikely(reply)) {
+ 			error = ovs_flow_cmd_fill_info(flow,
+ 						       ovs_header->dp_ifindex,
+ 						       reply, info->snd_portid,
+ 						       info->snd_seq, 0,
+ 						       OVS_FLOW_CMD_NEW);
+ 			BUG_ON(error < 0);
+ 		}
+ 		ovs_unlock();
+ 
+ 		ovs_nla_free_flow_actions(old_acts);
+ 		ovs_flow_free(new_flow, false);
+ 	}
+ 
+ 	if (reply)
+ 		ovs_notify(&dp_flow_genl_family, reply, info);
+ 	return 0;
+ 
+ err_unlock_ovs:
+ 	ovs_unlock();
+ 	kfree_skb(reply);
+ err_kfree_acts:
+ 	kfree(acts);
+ err_kfree_flow:
+ 	ovs_flow_free(new_flow, false);
+ error:
+ 	return error;
+ }
+ 
+ static int ovs_flow_cmd_set(struct sk_buff *skb, struct genl_info *info)
++>>>>>>> 4a46b24e147d (openvswitch: Use exact lookup for flow_get and flow_del.)
  {
  	struct nlattr **a = info->attrs;
  	struct ovs_header *ovs_header = info->userhdr;
@@@ -816,82 -979,56 +958,97 @@@
  
  	ovs_lock();
  	dp = get_dp(sock_net(skb->sk), ovs_header->dp_ifindex);
 -	if (unlikely(!dp)) {
 -		error = -ENODEV;
 +	error = -ENODEV;
 +	if (!dp)
  		goto err_unlock_ovs;
++<<<<<<< HEAD
++=======
+ 	}
+ 	/* Check that the flow exists. */
+ 	flow = ovs_flow_tbl_lookup_exact(&dp->table, &match);
+ 	if (unlikely(!flow)) {
+ 		error = -ENOENT;
+ 		goto err_unlock_ovs;
+ 	}
+ 
+ 	/* Update actions, if present. */
+ 	if (likely(acts)) {
+ 		old_acts = ovsl_dereference(flow->sf_acts);
+ 		rcu_assign_pointer(flow->sf_acts, acts);
++>>>>>>> 4a46b24e147d (openvswitch: Use exact lookup for flow_get and flow_del.)
  
 -		if (unlikely(reply)) {
 -			error = ovs_flow_cmd_fill_info(flow,
 -						       ovs_header->dp_ifindex,
 -						       reply, info->snd_portid,
 -						       info->snd_seq, 0,
 -						       OVS_FLOW_CMD_NEW);
 -			BUG_ON(error < 0);
 +	/* Check if this is a duplicate flow */
 +	flow = ovs_flow_tbl_lookup(&dp->table, &key);
 +	if (!flow) {
 +		/* Bail out if we're not allowed to create a new flow. */
 +		error = -ENOENT;
 +		if (info->genlhdr->cmd == OVS_FLOW_CMD_SET)
 +			goto err_unlock_ovs;
 +
 +		/* Allocate flow. */
 +		flow = ovs_flow_alloc();
 +		if (IS_ERR(flow)) {
 +			error = PTR_ERR(flow);
 +			goto err_unlock_ovs;
  		}
 +
 +		flow->key = masked_key;
 +		flow->unmasked_key = key;
 +		rcu_assign_pointer(flow->sf_acts, acts);
 +
 +		/* Put flow in bucket. */
 +		error = ovs_flow_tbl_insert(&dp->table, flow, &mask);
 +		if (error) {
 +			acts = NULL;
 +			goto err_flow_free;
 +		}
 +
 +		reply = ovs_flow_cmd_build_info(flow, dp, info, OVS_FLOW_CMD_NEW);
  	} else {
 -		/* Could not alloc without acts before locking. */
 -		reply = ovs_flow_cmd_build_info(flow, ovs_header->dp_ifindex,
 -						info, OVS_FLOW_CMD_NEW, false);
 -		if (unlikely(IS_ERR(reply))) {
 -			error = PTR_ERR(reply);
 +		/* We found a matching flow. */
 +		/* Bail out if we're not allowed to modify an existing flow.
 +		 * We accept NLM_F_CREATE in place of the intended NLM_F_EXCL
 +		 * because Generic Netlink treats the latter as a dump
 +		 * request.  We also accept NLM_F_EXCL in case that bug ever
 +		 * gets fixed.
 +		 */
 +		error = -EEXIST;
 +		if (info->genlhdr->cmd == OVS_FLOW_CMD_NEW &&
 +		    info->nlhdr->nlmsg_flags & (NLM_F_CREATE | NLM_F_EXCL))
  			goto err_unlock_ovs;
 +
 +		/* The unmasked key has to be the same for flow updates. */
 +		if (!ovs_flow_cmp_unmasked_key(flow, &match))
 +			goto err_unlock_ovs;
 +
 +		/* Update actions, if present. */
 +		if (acts) {
 +			struct sw_flow_actions *old_acts;
 +
 +			old_acts = ovsl_dereference(flow->sf_acts);
 +			rcu_assign_pointer(flow->sf_acts, acts);
 +			ovs_nla_free_flow_actions(old_acts);
  		}
 -	}
 +		reply = ovs_flow_cmd_build_info(flow, dp, info, OVS_FLOW_CMD_NEW);
  
 -	/* Clear stats. */
 -	if (a[OVS_FLOW_ATTR_CLEAR])
 -		ovs_flow_stats_clear(flow);
 +		/* Clear stats. */
 +		if (a[OVS_FLOW_ATTR_CLEAR])
 +			ovs_flow_stats_clear(flow);
 +	}
  	ovs_unlock();
  
 -	if (reply)
 -		ovs_notify(&dp_flow_genl_family, reply, info);
 -	if (old_acts)
 -		ovs_nla_free_flow_actions(old_acts);
 -
 +	if (!IS_ERR(reply))
 +		ovs_notify(reply, info, &ovs_dp_flow_multicast_group);
 +	else
 +		genl_set_err(sock_net(skb->sk), 0,
 +			     ovs_dp_flow_multicast_group.id, PTR_ERR(reply));
  	return 0;
  
 +err_flow_free:
 +	ovs_flow_free(flow, false);
  err_unlock_ovs:
  	ovs_unlock();
 -	kfree_skb(reply);
 -err_kfree_acts:
 +err_kfree:
  	kfree(acts);
  error:
  	return error;
@@@ -967,13 -1112,8 +1124,18 @@@ static int ovs_flow_cmd_del(struct sk_b
  		goto unlock;
  	}
  
++<<<<<<< HEAD
 +	ovs_match_init(&match, &key, NULL);
 +	err = ovs_nla_get_match(&match, a[OVS_FLOW_ATTR_KEY], NULL);
 +	if (err)
 +		goto unlock;
 +
 +	flow = ovs_flow_tbl_lookup(&dp->table, &key);
 +	if (!flow || !ovs_flow_cmp_unmasked_key(flow, &match)) {
++=======
+ 	flow = ovs_flow_tbl_lookup_exact(&dp->table, &match);
+ 	if (unlikely(!flow)) {
++>>>>>>> 4a46b24e147d (openvswitch: Use exact lookup for flow_get and flow_del.)
  		err = -ENOENT;
  		goto unlock;
  	}
* Unmerged path net/openvswitch/datapath.c
diff --git a/net/openvswitch/flow_table.c b/net/openvswitch/flow_table.c
index 574c3abc9b30..cf2d853646f0 100644
--- a/net/openvswitch/flow_table.c
+++ b/net/openvswitch/flow_table.c
@@ -456,6 +456,22 @@ struct sw_flow *ovs_flow_tbl_lookup(struct flow_table *tbl,
 	return ovs_flow_tbl_lookup_stats(tbl, key, &n_mask_hit);
 }
 
+struct sw_flow *ovs_flow_tbl_lookup_exact(struct flow_table *tbl,
+					  struct sw_flow_match *match)
+{
+	struct table_instance *ti = rcu_dereference_ovsl(tbl->ti);
+	struct sw_flow_mask *mask;
+	struct sw_flow *flow;
+
+	/* Always called under ovs-mutex. */
+	list_for_each_entry(mask, &tbl->mask_list, list) {
+		flow = masked_flow_lookup(ti, match->key, mask);
+		if (flow && ovs_flow_cmp_unmasked_key(flow, match))  /* Found */
+			return flow;
+	}
+	return NULL;
+}
+
 int ovs_flow_tbl_num_masks(const struct flow_table *table)
 {
 	struct sw_flow_mask *mask;
diff --git a/net/openvswitch/flow_table.h b/net/openvswitch/flow_table.h
index ca8a5820f615..5918bff7f3f6 100644
--- a/net/openvswitch/flow_table.h
+++ b/net/openvswitch/flow_table.h
@@ -76,7 +76,8 @@ struct sw_flow *ovs_flow_tbl_lookup_stats(struct flow_table *,
 				    u32 *n_mask_hit);
 struct sw_flow *ovs_flow_tbl_lookup(struct flow_table *,
 				    const struct sw_flow_key *);
-
+struct sw_flow *ovs_flow_tbl_lookup_exact(struct flow_table *tbl,
+					  struct sw_flow_match *match);
 bool ovs_flow_cmp_unmasked_key(const struct sw_flow *flow,
 			       struct sw_flow_match *match);
 
