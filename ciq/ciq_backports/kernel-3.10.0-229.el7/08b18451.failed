dm cache: revert "prevent corruption caused by discard_block_size > cache_block_size"

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
Rebuild_CHGLOG: - [md] dm-cache: revert "prevent corruption caused by discard_block_size > cache_block_size" (Mike Snitzer) [1159001]
Rebuild_FUZZ: 98.82%
commit-author Joe Thornber <ejt@redhat.com>
commit 08b184514f65d160ce66381dafca5962e3d8f785
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/08b18451.failed

This reverts commit d132cc6d9e92424bb9d4fd35f5bd0e55d583f4be because we
actually do want to allow the discard blocksize to be larger than the
cache blocksize.  Further dm-cache discard changes will make this
possible.

	Signed-off-by: Joe Thornber <ejt@redhat.com>
	Signed-off-by: Mike Snitzer <snitzer@redhat.com>
(cherry picked from commit 08b184514f65d160ce66381dafca5962e3d8f785)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/dm-cache-target.c
diff --cc drivers/md/dm-cache-target.c
index e75d70ec363a,c2ca74374944..000000000000
--- a/drivers/md/dm-cache-target.c
+++ b/drivers/md/dm-cache-target.c
@@@ -230,8 -236,9 +230,12 @@@ struct cache 
  	/*
  	 * origin_blocks entries, discarded if set.
  	 */
 -	dm_dblock_t discard_nr_blocks;
 +	dm_oblock_t discard_nr_blocks;
  	unsigned long *discard_bitset;
++<<<<<<< HEAD
++=======
+ 	uint32_t discard_block_size; /* a power of 2 times sectors per block */
++>>>>>>> 08b184514f65 (dm cache: revert "prevent corruption caused by discard_block_size > cache_block_size")
  
  	/*
  	 * Rather than reconstructing the table line for the status we just
@@@ -2297,8 -2349,11 +2330,16 @@@ static int cache_create(struct cache_ar
  	}
  	clear_bitset(cache->dirty_bitset, from_cblock(cache->cache_size));
  
++<<<<<<< HEAD
 +	cache->discard_nr_blocks = cache->origin_blocks;
 +	cache->discard_bitset = alloc_bitset(from_oblock(cache->discard_nr_blocks));
++=======
+ 	cache->discard_block_size =
+ 		calculate_discard_block_size(cache->sectors_per_block,
+ 					     cache->origin_sectors);
+ 	cache->discard_nr_blocks = oblock_to_dblock(cache, cache->origin_blocks);
+ 	cache->discard_bitset = alloc_bitset(from_dblock(cache->discard_nr_blocks));
++>>>>>>> 08b184514f65 (dm cache: revert "prevent corruption caused by discard_block_size > cache_block_size")
  	if (!cache->discard_bitset) {
  		*error = "could not allocate discard bitset";
  		goto bad;
@@@ -3078,8 -3130,8 +3119,13 @@@ static void set_discard_limits(struct c
  	/*
  	 * FIXME: these limits may be incompatible with the cache device
  	 */
++<<<<<<< HEAD
 +	limits->max_discard_sectors = cache->sectors_per_block;
 +	limits->discard_granularity = cache->sectors_per_block << SECTOR_SHIFT;
++=======
+ 	limits->max_discard_sectors = cache->discard_block_size * 1024;
+ 	limits->discard_granularity = cache->discard_block_size << SECTOR_SHIFT;
++>>>>>>> 08b184514f65 (dm cache: revert "prevent corruption caused by discard_block_size > cache_block_size")
  }
  
  static void cache_io_hints(struct dm_target *ti, struct queue_limits *limits)
* Unmerged path drivers/md/dm-cache-target.c
