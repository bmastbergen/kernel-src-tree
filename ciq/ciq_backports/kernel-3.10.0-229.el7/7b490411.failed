KVM: PPC: Book3S HV: Add new state for transactional memory

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
Rebuild_CHGLOG: - [virt] kvm/ppc: book3s hv - Add new state for transactional memory (Don Zickus) [1127366]
Rebuild_FUZZ: 94.92%
commit-author Michael Neuling <mikey@neuling.org>
commit 7b490411c37f7ab7965cbdfe5e3ec28eadb6db5b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/7b490411.failed

Add new state for transactional memory (TM) to kvm_vcpu_arch.  Also add
asm-offset bits that are going to be required.

This also moves the existing TFHAR, TFIAR and TEXASR SPRs into a
CONFIG_PPC_TRANSACTIONAL_MEM section.  This requires some code changes to
ensure we still compile with CONFIG_PPC_TRANSACTIONAL_MEM=N.  Much of the added
the added #ifdefs are removed in a later patch when the bulk of the TM code is
added.

	Signed-off-by: Michael Neuling <mikey@neuling.org>
	Signed-off-by: Paul Mackerras <paulus@samba.org>
[agraf: fix merge conflict]
	Signed-off-by: Alexander Graf <agraf@suse.de>
(cherry picked from commit 7b490411c37f7ab7965cbdfe5e3ec28eadb6db5b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/include/asm/kvm_host.h
#	arch/powerpc/kernel/asm-offsets.c
#	arch/powerpc/kvm/book3s_hv.c
#	arch/powerpc/kvm/book3s_hv_rmhandlers.S
diff --cc arch/powerpc/include/asm/kvm_host.h
index 80c8a73bb706,1eaea2dea174..000000000000
--- a/arch/powerpc/include/asm/kvm_host.h
+++ b/arch/powerpc/include/asm/kvm_host.h
@@@ -473,10 -462,27 +473,23 @@@ struct kvm_vcpu_arch 
  	ulong dscr;
  	ulong amr;
  	ulong uamor;
 -	ulong iamr;
  	u32 ctrl;
 -	u32 dabrx;
  	ulong dabr;
 -	ulong dawr;
 -	ulong dawrx;
 -	ulong ciabr;
  	ulong cfar;
  	ulong ppr;
++<<<<<<< HEAD
++=======
+ 	ulong pspb;
+ 	ulong fscr;
+ 	ulong ebbhr;
+ 	ulong ebbrr;
+ 	ulong bescr;
+ 	ulong csigr;
+ 	ulong tacr;
+ 	ulong tcscr;
+ 	ulong acop;
+ 	ulong wort;
++>>>>>>> 7b490411c37f (KVM: PPC: Book3S HV: Add new state for transactional memory)
  	ulong shadow_srr1;
  #endif
  	u32 vrsave; /* also USPRG0 */
@@@ -511,10 -517,33 +524,35 @@@
  	u32 ccr1;
  	u32 dbsr;
  
 -	u64 mmcr[5];
 +	u64 mmcr[3];
  	u32 pmc[8];
 -	u32 spmc[2];
  	u64 siar;
  	u64 sdar;
++<<<<<<< HEAD
++=======
+ 	u64 sier;
+ #ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+ 	u64 tfhar;
+ 	u64 texasr;
+ 	u64 tfiar;
+ 
+ 	u32 cr_tm;
+ 	u64 lr_tm;
+ 	u64 ctr_tm;
+ 	u64 amr_tm;
+ 	u64 ppr_tm;
+ 	u64 dscr_tm;
+ 	u64 tar_tm;
+ 
+ 	ulong gpr_tm[32];
+ 
+ 	struct thread_fp_state fp_tm;
+ 
+ 	struct thread_vr_state vr_tm;
+ 	u32 vrsave_tm; /* also USPRG0 */
+ 
+ #endif
++>>>>>>> 7b490411c37f (KVM: PPC: Book3S HV: Add new state for transactional memory)
  
  #ifdef CONFIG_KVM_EXIT_TIMING
  	struct mutex exit_timing_lock;
diff --cc arch/powerpc/kernel/asm-offsets.c
index 79fa5c26d629,687f2ebf0cce..000000000000
--- a/arch/powerpc/kernel/asm-offsets.c
+++ b/arch/powerpc/kernel/asm-offsets.c
@@@ -511,9 -517,18 +511,22 @@@ int main(void
  	DEFINE(VCPU_FAULT_DAR, offsetof(struct kvm_vcpu, arch.fault_dar));
  	DEFINE(VCPU_LAST_INST, offsetof(struct kvm_vcpu, arch.last_inst));
  	DEFINE(VCPU_TRAP, offsetof(struct kvm_vcpu, arch.trap));
 +	DEFINE(VCPU_PTID, offsetof(struct kvm_vcpu, arch.ptid));
  	DEFINE(VCPU_CFAR, offsetof(struct kvm_vcpu, arch.cfar));
  	DEFINE(VCPU_PPR, offsetof(struct kvm_vcpu, arch.ppr));
++<<<<<<< HEAD
++=======
+ 	DEFINE(VCPU_FSCR, offsetof(struct kvm_vcpu, arch.fscr));
+ 	DEFINE(VCPU_PSPB, offsetof(struct kvm_vcpu, arch.pspb));
+ 	DEFINE(VCPU_EBBHR, offsetof(struct kvm_vcpu, arch.ebbhr));
+ 	DEFINE(VCPU_EBBRR, offsetof(struct kvm_vcpu, arch.ebbrr));
+ 	DEFINE(VCPU_BESCR, offsetof(struct kvm_vcpu, arch.bescr));
+ 	DEFINE(VCPU_CSIGR, offsetof(struct kvm_vcpu, arch.csigr));
+ 	DEFINE(VCPU_TACR, offsetof(struct kvm_vcpu, arch.tacr));
+ 	DEFINE(VCPU_TCSCR, offsetof(struct kvm_vcpu, arch.tcscr));
+ 	DEFINE(VCPU_ACOP, offsetof(struct kvm_vcpu, arch.acop));
+ 	DEFINE(VCPU_WORT, offsetof(struct kvm_vcpu, arch.wort));
++>>>>>>> 7b490411c37f (KVM: PPC: Book3S HV: Add new state for transactional memory)
  	DEFINE(VCPU_SHADOW_SRR1, offsetof(struct kvm_vcpu, arch.shadow_srr1));
  	DEFINE(VCORE_ENTRY_EXIT, offsetof(struct kvmppc_vcore, entry_exit_count));
  	DEFINE(VCORE_NAP_COUNT, offsetof(struct kvmppc_vcore, nap_count));
diff --cc arch/powerpc/kvm/book3s_hv.c
index bd4792543205,f4a4c5c82fb2..000000000000
--- a/arch/powerpc/kvm/book3s_hv.c
+++ b/arch/powerpc/kvm/book3s_hv.c
@@@ -833,6 -869,77 +833,80 @@@ int kvmppc_get_one_reg(struct kvm_vcpu 
  	case KVM_REG_PPC_SDAR:
  		*val = get_reg_val(id, vcpu->arch.sdar);
  		break;
++<<<<<<< HEAD
++=======
+ 	case KVM_REG_PPC_SIER:
+ 		*val = get_reg_val(id, vcpu->arch.sier);
+ 		break;
+ 	case KVM_REG_PPC_IAMR:
+ 		*val = get_reg_val(id, vcpu->arch.iamr);
+ 		break;
+ #ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+ 	case KVM_REG_PPC_TFHAR:
+ 		*val = get_reg_val(id, vcpu->arch.tfhar);
+ 		break;
+ 	case KVM_REG_PPC_TFIAR:
+ 		*val = get_reg_val(id, vcpu->arch.tfiar);
+ 		break;
+ 	case KVM_REG_PPC_TEXASR:
+ 		*val = get_reg_val(id, vcpu->arch.texasr);
+ 		break;
+ #endif
+ 	case KVM_REG_PPC_FSCR:
+ 		*val = get_reg_val(id, vcpu->arch.fscr);
+ 		break;
+ 	case KVM_REG_PPC_PSPB:
+ 		*val = get_reg_val(id, vcpu->arch.pspb);
+ 		break;
+ 	case KVM_REG_PPC_EBBHR:
+ 		*val = get_reg_val(id, vcpu->arch.ebbhr);
+ 		break;
+ 	case KVM_REG_PPC_EBBRR:
+ 		*val = get_reg_val(id, vcpu->arch.ebbrr);
+ 		break;
+ 	case KVM_REG_PPC_BESCR:
+ 		*val = get_reg_val(id, vcpu->arch.bescr);
+ 		break;
+ 	case KVM_REG_PPC_TAR:
+ 		*val = get_reg_val(id, vcpu->arch.tar);
+ 		break;
+ 	case KVM_REG_PPC_DPDES:
+ 		*val = get_reg_val(id, vcpu->arch.vcore->dpdes);
+ 		break;
+ 	case KVM_REG_PPC_DAWR:
+ 		*val = get_reg_val(id, vcpu->arch.dawr);
+ 		break;
+ 	case KVM_REG_PPC_DAWRX:
+ 		*val = get_reg_val(id, vcpu->arch.dawrx);
+ 		break;
+ 	case KVM_REG_PPC_CIABR:
+ 		*val = get_reg_val(id, vcpu->arch.ciabr);
+ 		break;
+ 	case KVM_REG_PPC_IC:
+ 		*val = get_reg_val(id, vcpu->arch.ic);
+ 		break;
+ 	case KVM_REG_PPC_VTB:
+ 		*val = get_reg_val(id, vcpu->arch.vtb);
+ 		break;
+ 	case KVM_REG_PPC_CSIGR:
+ 		*val = get_reg_val(id, vcpu->arch.csigr);
+ 		break;
+ 	case KVM_REG_PPC_TACR:
+ 		*val = get_reg_val(id, vcpu->arch.tacr);
+ 		break;
+ 	case KVM_REG_PPC_TCSCR:
+ 		*val = get_reg_val(id, vcpu->arch.tcscr);
+ 		break;
+ 	case KVM_REG_PPC_PID:
+ 		*val = get_reg_val(id, vcpu->arch.pid);
+ 		break;
+ 	case KVM_REG_PPC_ACOP:
+ 		*val = get_reg_val(id, vcpu->arch.acop);
+ 		break;
+ 	case KVM_REG_PPC_WORT:
+ 		*val = get_reg_val(id, vcpu->arch.wort);
+ 		break;
++>>>>>>> 7b490411c37f (KVM: PPC: Book3S HV: Add new state for transactional memory)
  	case KVM_REG_PPC_VPA_ADDR:
  		spin_lock(&vcpu->arch.vpa_update_lock);
  		*val = get_reg_val(id, vcpu->arch.vpa.next_gpa);
@@@ -914,6 -1029,80 +988,83 @@@ int kvmppc_set_one_reg(struct kvm_vcpu 
  	case KVM_REG_PPC_SDAR:
  		vcpu->arch.sdar = set_reg_val(id, *val);
  		break;
++<<<<<<< HEAD
++=======
+ 	case KVM_REG_PPC_SIER:
+ 		vcpu->arch.sier = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_IAMR:
+ 		vcpu->arch.iamr = set_reg_val(id, *val);
+ 		break;
+ #ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+ 	case KVM_REG_PPC_TFHAR:
+ 		vcpu->arch.tfhar = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_TFIAR:
+ 		vcpu->arch.tfiar = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_TEXASR:
+ 		vcpu->arch.texasr = set_reg_val(id, *val);
+ 		break;
+ #endif
+ 	case KVM_REG_PPC_FSCR:
+ 		vcpu->arch.fscr = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_PSPB:
+ 		vcpu->arch.pspb = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_EBBHR:
+ 		vcpu->arch.ebbhr = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_EBBRR:
+ 		vcpu->arch.ebbrr = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_BESCR:
+ 		vcpu->arch.bescr = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_TAR:
+ 		vcpu->arch.tar = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_DPDES:
+ 		vcpu->arch.vcore->dpdes = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_DAWR:
+ 		vcpu->arch.dawr = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_DAWRX:
+ 		vcpu->arch.dawrx = set_reg_val(id, *val) & ~DAWRX_HYP;
+ 		break;
+ 	case KVM_REG_PPC_CIABR:
+ 		vcpu->arch.ciabr = set_reg_val(id, *val);
+ 		/* Don't allow setting breakpoints in hypervisor code */
+ 		if ((vcpu->arch.ciabr & CIABR_PRIV) == CIABR_PRIV_HYPER)
+ 			vcpu->arch.ciabr &= ~CIABR_PRIV;	/* disable */
+ 		break;
+ 	case KVM_REG_PPC_IC:
+ 		vcpu->arch.ic = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_VTB:
+ 		vcpu->arch.vtb = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_CSIGR:
+ 		vcpu->arch.csigr = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_TACR:
+ 		vcpu->arch.tacr = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_TCSCR:
+ 		vcpu->arch.tcscr = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_PID:
+ 		vcpu->arch.pid = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_ACOP:
+ 		vcpu->arch.acop = set_reg_val(id, *val);
+ 		break;
+ 	case KVM_REG_PPC_WORT:
+ 		vcpu->arch.wort = set_reg_val(id, *val);
+ 		break;
++>>>>>>> 7b490411c37f (KVM: PPC: Book3S HV: Add new state for transactional memory)
  	case KVM_REG_PPC_VPA_ADDR:
  		addr = set_reg_val(id, *val);
  		r = -EINVAL;
diff --cc arch/powerpc/kvm/book3s_hv_rmhandlers.S
index 4e71b0446184,dfa144cb199b..000000000000
--- a/arch/powerpc/kvm/book3s_hv_rmhandlers.S
+++ b/arch/powerpc/kvm/book3s_hv_rmhandlers.S
@@@ -642,6 -559,209 +642,212 @@@ toc_tlbie_lock
  	addi	r6,r6,VCPU_SLB_SIZE
  	bdnz	1b
  9:
++<<<<<<< HEAD
++=======
+ 	/* Increment yield count if they have a VPA */
+ 	ld	r3, VCPU_VPA(r4)
+ 	cmpdi	r3, 0
+ 	beq	25f
+ 	lwz	r5, LPPACA_YIELDCOUNT(r3)
+ 	addi	r5, r5, 1
+ 	stw	r5, LPPACA_YIELDCOUNT(r3)
+ 	li	r6, 1
+ 	stb	r6, VCPU_VPA_DIRTY(r4)
+ 25:
+ 
+ BEGIN_FTR_SECTION
+ 	/* Save purr/spurr */
+ 	mfspr	r5,SPRN_PURR
+ 	mfspr	r6,SPRN_SPURR
+ 	std	r5,HSTATE_PURR(r13)
+ 	std	r6,HSTATE_SPURR(r13)
+ 	ld	r7,VCPU_PURR(r4)
+ 	ld	r8,VCPU_SPURR(r4)
+ 	mtspr	SPRN_PURR,r7
+ 	mtspr	SPRN_SPURR,r8
+ END_FTR_SECTION_IFSET(CPU_FTR_ARCH_206)
+ 
+ BEGIN_FTR_SECTION
+ 	/* Set partition DABR */
+ 	/* Do this before re-enabling PMU to avoid P7 DABR corruption bug */
+ 	lwz	r5,VCPU_DABRX(r4)
+ 	ld	r6,VCPU_DABR(r4)
+ 	mtspr	SPRN_DABRX,r5
+ 	mtspr	SPRN_DABR,r6
+  BEGIN_FTR_SECTION_NESTED(89)
+ 	isync
+  END_FTR_SECTION_NESTED(CPU_FTR_ARCH_206, CPU_FTR_ARCH_206, 89)
+ END_FTR_SECTION_IFCLR(CPU_FTR_ARCH_207S)
+ 
+ 	/* Load guest PMU registers */
+ 	/* R4 is live here (vcpu pointer) */
+ 	li	r3, 1
+ 	sldi	r3, r3, 31		/* MMCR0_FC (freeze counters) bit */
+ 	mtspr	SPRN_MMCR0, r3		/* freeze all counters, disable ints */
+ 	isync
+ 	lwz	r3, VCPU_PMC(r4)	/* always load up guest PMU registers */
+ 	lwz	r5, VCPU_PMC + 4(r4)	/* to prevent information leak */
+ 	lwz	r6, VCPU_PMC + 8(r4)
+ 	lwz	r7, VCPU_PMC + 12(r4)
+ 	lwz	r8, VCPU_PMC + 16(r4)
+ 	lwz	r9, VCPU_PMC + 20(r4)
+ BEGIN_FTR_SECTION
+ 	lwz	r10, VCPU_PMC + 24(r4)
+ 	lwz	r11, VCPU_PMC + 28(r4)
+ END_FTR_SECTION_IFSET(CPU_FTR_ARCH_201)
+ 	mtspr	SPRN_PMC1, r3
+ 	mtspr	SPRN_PMC2, r5
+ 	mtspr	SPRN_PMC3, r6
+ 	mtspr	SPRN_PMC4, r7
+ 	mtspr	SPRN_PMC5, r8
+ 	mtspr	SPRN_PMC6, r9
+ BEGIN_FTR_SECTION
+ 	mtspr	SPRN_PMC7, r10
+ 	mtspr	SPRN_PMC8, r11
+ END_FTR_SECTION_IFSET(CPU_FTR_ARCH_201)
+ 	ld	r3, VCPU_MMCR(r4)
+ 	ld	r5, VCPU_MMCR + 8(r4)
+ 	ld	r6, VCPU_MMCR + 16(r4)
+ 	ld	r7, VCPU_SIAR(r4)
+ 	ld	r8, VCPU_SDAR(r4)
+ 	mtspr	SPRN_MMCR1, r5
+ 	mtspr	SPRN_MMCRA, r6
+ 	mtspr	SPRN_SIAR, r7
+ 	mtspr	SPRN_SDAR, r8
+ BEGIN_FTR_SECTION
+ 	ld	r5, VCPU_MMCR + 24(r4)
+ 	ld	r6, VCPU_SIER(r4)
+ 	lwz	r7, VCPU_PMC + 24(r4)
+ 	lwz	r8, VCPU_PMC + 28(r4)
+ 	ld	r9, VCPU_MMCR + 32(r4)
+ 	mtspr	SPRN_MMCR2, r5
+ 	mtspr	SPRN_SIER, r6
+ 	mtspr	SPRN_SPMC1, r7
+ 	mtspr	SPRN_SPMC2, r8
+ 	mtspr	SPRN_MMCRS, r9
+ END_FTR_SECTION_IFSET(CPU_FTR_ARCH_207S)
+ 	mtspr	SPRN_MMCR0, r3
+ 	isync
+ 
+ 	/* Load up FP, VMX and VSX registers */
+ 	bl	kvmppc_load_fp
+ 
+ 	ld	r14, VCPU_GPR(R14)(r4)
+ 	ld	r15, VCPU_GPR(R15)(r4)
+ 	ld	r16, VCPU_GPR(R16)(r4)
+ 	ld	r17, VCPU_GPR(R17)(r4)
+ 	ld	r18, VCPU_GPR(R18)(r4)
+ 	ld	r19, VCPU_GPR(R19)(r4)
+ 	ld	r20, VCPU_GPR(R20)(r4)
+ 	ld	r21, VCPU_GPR(R21)(r4)
+ 	ld	r22, VCPU_GPR(R22)(r4)
+ 	ld	r23, VCPU_GPR(R23)(r4)
+ 	ld	r24, VCPU_GPR(R24)(r4)
+ 	ld	r25, VCPU_GPR(R25)(r4)
+ 	ld	r26, VCPU_GPR(R26)(r4)
+ 	ld	r27, VCPU_GPR(R27)(r4)
+ 	ld	r28, VCPU_GPR(R28)(r4)
+ 	ld	r29, VCPU_GPR(R29)(r4)
+ 	ld	r30, VCPU_GPR(R30)(r4)
+ 	ld	r31, VCPU_GPR(R31)(r4)
+ 
+ BEGIN_FTR_SECTION
+ 	/* Switch DSCR to guest value */
+ 	ld	r5, VCPU_DSCR(r4)
+ 	mtspr	SPRN_DSCR, r5
+ END_FTR_SECTION_IFSET(CPU_FTR_ARCH_206)
+ 
+ BEGIN_FTR_SECTION
+ 	/* Skip next section on POWER7 or PPC970 */
+ 	b	8f
+ END_FTR_SECTION_IFCLR(CPU_FTR_ARCH_207S)
+ 	/* Turn on TM so we can access TFHAR/TFIAR/TEXASR */
+ 	mfmsr	r8
+ 	li	r0, 1
+ 	rldimi	r8, r0, MSR_TM_LG, 63-MSR_TM_LG
+ 	mtmsrd	r8
+ 
+ 	/* Load up POWER8-specific registers */
+ 	ld	r5, VCPU_IAMR(r4)
+ 	lwz	r6, VCPU_PSPB(r4)
+ 	ld	r7, VCPU_FSCR(r4)
+ 	mtspr	SPRN_IAMR, r5
+ 	mtspr	SPRN_PSPB, r6
+ 	mtspr	SPRN_FSCR, r7
+ 	ld	r5, VCPU_DAWR(r4)
+ 	ld	r6, VCPU_DAWRX(r4)
+ 	ld	r7, VCPU_CIABR(r4)
+ 	ld	r8, VCPU_TAR(r4)
+ 	mtspr	SPRN_DAWR, r5
+ 	mtspr	SPRN_DAWRX, r6
+ 	mtspr	SPRN_CIABR, r7
+ 	mtspr	SPRN_TAR, r8
+ 	ld	r5, VCPU_IC(r4)
+ 	ld	r6, VCPU_VTB(r4)
+ 	mtspr	SPRN_IC, r5
+ 	mtspr	SPRN_VTB, r6
+ #ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+ 	ld	r5, VCPU_TFHAR(r4)
+ 	ld	r6, VCPU_TFIAR(r4)
+ 	ld	r7, VCPU_TEXASR(r4)
+ 	mtspr	SPRN_TFHAR, r5
+ 	mtspr	SPRN_TFIAR, r6
+ 	mtspr	SPRN_TEXASR, r7
+ #endif
+ 	ld	r8, VCPU_EBBHR(r4)
+ 	mtspr	SPRN_EBBHR, r8
+ 	ld	r5, VCPU_EBBRR(r4)
+ 	ld	r6, VCPU_BESCR(r4)
+ 	ld	r7, VCPU_CSIGR(r4)
+ 	ld	r8, VCPU_TACR(r4)
+ 	mtspr	SPRN_EBBRR, r5
+ 	mtspr	SPRN_BESCR, r6
+ 	mtspr	SPRN_CSIGR, r7
+ 	mtspr	SPRN_TACR, r8
+ 	ld	r5, VCPU_TCSCR(r4)
+ 	ld	r6, VCPU_ACOP(r4)
+ 	lwz	r7, VCPU_GUEST_PID(r4)
+ 	ld	r8, VCPU_WORT(r4)
+ 	mtspr	SPRN_TCSCR, r5
+ 	mtspr	SPRN_ACOP, r6
+ 	mtspr	SPRN_PID, r7
+ 	mtspr	SPRN_WORT, r8
+ 8:
+ 
+ 	/*
+ 	 * Set the decrementer to the guest decrementer.
+ 	 */
+ 	ld	r8,VCPU_DEC_EXPIRES(r4)
+ 	mftb	r7
+ 	subf	r3,r7,r8
+ 	mtspr	SPRN_DEC,r3
+ 	stw	r3,VCPU_DEC(r4)
+ 
+ 	ld	r5, VCPU_SPRG0(r4)
+ 	ld	r6, VCPU_SPRG1(r4)
+ 	ld	r7, VCPU_SPRG2(r4)
+ 	ld	r8, VCPU_SPRG3(r4)
+ 	mtspr	SPRN_SPRG0, r5
+ 	mtspr	SPRN_SPRG1, r6
+ 	mtspr	SPRN_SPRG2, r7
+ 	mtspr	SPRN_SPRG3, r8
+ 
+ 	/* Load up DAR and DSISR */
+ 	ld	r5, VCPU_DAR(r4)
+ 	lwz	r6, VCPU_DSISR(r4)
+ 	mtspr	SPRN_DAR, r5
+ 	mtspr	SPRN_DSISR, r6
+ 
+ BEGIN_FTR_SECTION
+ 	/* Restore AMR and UAMOR, set AMOR to all 1s */
+ 	ld	r5,VCPU_AMR(r4)
+ 	ld	r6,VCPU_UAMOR(r4)
+ 	li	r7,-1
+ 	mtspr	SPRN_AMR,r5
+ 	mtspr	SPRN_UAMOR,r6
+ 	mtspr	SPRN_AMOR,r7
+ END_FTR_SECTION_IFSET(CPU_FTR_ARCH_206)
++>>>>>>> 7b490411c37f (KVM: PPC: Book3S HV: Add new state for transactional memory)
  
  	/* Restore state of CTRL run bit; assume 1 on entry */
  	lwz	r5,VCPU_CTRL(r4)
@@@ -1221,144 -1508,74 +1427,276 @@@ END_FTR_SECTION_IFSET(CPU_FTR_ARCH_201
  	add	r5,r5,r6
  	std	r5,VCPU_DEC_EXPIRES(r9)
  
++<<<<<<< HEAD
++=======
++BEGIN_FTR_SECTION
++	b	8f
++END_FTR_SECTION_IFCLR(CPU_FTR_ARCH_207S)
++	/* Turn on TM so we can access TFHAR/TFIAR/TEXASR */
++	mfmsr	r8
++	li	r0, 1
++	rldimi	r8, r0, MSR_TM_LG, 63-MSR_TM_LG
++	mtmsrd	r8
++
++	/* Save POWER8-specific registers */
++	mfspr	r5, SPRN_IAMR
++	mfspr	r6, SPRN_PSPB
++	mfspr	r7, SPRN_FSCR
++	std	r5, VCPU_IAMR(r9)
++	stw	r6, VCPU_PSPB(r9)
++	std	r7, VCPU_FSCR(r9)
++	mfspr	r5, SPRN_IC
++	mfspr	r6, SPRN_VTB
++	mfspr	r7, SPRN_TAR
++	std	r5, VCPU_IC(r9)
++	std	r6, VCPU_VTB(r9)
++	std	r7, VCPU_TAR(r9)
++#ifdef CONFIG_PPC_TRANSACTIONAL_MEM
++	mfspr	r5, SPRN_TFHAR
++	mfspr	r6, SPRN_TFIAR
++	mfspr	r7, SPRN_TEXASR
++	std	r5, VCPU_TFHAR(r9)
++	std	r6, VCPU_TFIAR(r9)
++	std	r7, VCPU_TEXASR(r9)
++#endif
++	mfspr	r8, SPRN_EBBHR
++	std	r8, VCPU_EBBHR(r9)
++	mfspr	r5, SPRN_EBBRR
++	mfspr	r6, SPRN_BESCR
++	mfspr	r7, SPRN_CSIGR
++	mfspr	r8, SPRN_TACR
++	std	r5, VCPU_EBBRR(r9)
++	std	r6, VCPU_BESCR(r9)
++	std	r7, VCPU_CSIGR(r9)
++	std	r8, VCPU_TACR(r9)
++	mfspr	r5, SPRN_TCSCR
++	mfspr	r6, SPRN_ACOP
++	mfspr	r7, SPRN_PID
++	mfspr	r8, SPRN_WORT
++	std	r5, VCPU_TCSCR(r9)
++	std	r6, VCPU_ACOP(r9)
++	stw	r7, VCPU_GUEST_PID(r9)
++	std	r8, VCPU_WORT(r9)
++8:
++
++>>>>>>> 7b490411c37f (KVM: PPC: Book3S HV: Add new state for transactional memory)
 +	/* Save and reset AMR and UAMOR before turning on the MMU */
 +BEGIN_FTR_SECTION
 +	mfspr	r5,SPRN_AMR
 +	mfspr	r6,SPRN_UAMOR
 +	std	r5,VCPU_AMR(r9)
 +	std	r6,VCPU_UAMOR(r9)
 +	li	r6,0
 +	mtspr	SPRN_AMR,r6
 +END_FTR_SECTION_IFSET(CPU_FTR_ARCH_206)
 +
 +	/* Unset guest mode */
 +	li	r0, KVM_GUEST_MODE_NONE
 +	stb	r0, HSTATE_IN_GUEST(r13)
 +
 +	/* Switch DSCR back to host value */
 +BEGIN_FTR_SECTION
 +	mfspr	r8, SPRN_DSCR
 +	ld	r7, HSTATE_DSCR(r13)
 +	std	r8, VCPU_DSCR(r9)
 +	mtspr	SPRN_DSCR, r7
 +END_FTR_SECTION_IFSET(CPU_FTR_ARCH_206)
 +
 +	/* Save non-volatile GPRs */
 +	std	r14, VCPU_GPR(R14)(r9)
 +	std	r15, VCPU_GPR(R15)(r9)
 +	std	r16, VCPU_GPR(R16)(r9)
 +	std	r17, VCPU_GPR(R17)(r9)
 +	std	r18, VCPU_GPR(R18)(r9)
 +	std	r19, VCPU_GPR(R19)(r9)
 +	std	r20, VCPU_GPR(R20)(r9)
 +	std	r21, VCPU_GPR(R21)(r9)
 +	std	r22, VCPU_GPR(R22)(r9)
 +	std	r23, VCPU_GPR(R23)(r9)
 +	std	r24, VCPU_GPR(R24)(r9)
 +	std	r25, VCPU_GPR(R25)(r9)
 +	std	r26, VCPU_GPR(R26)(r9)
 +	std	r27, VCPU_GPR(R27)(r9)
 +	std	r28, VCPU_GPR(R28)(r9)
 +	std	r29, VCPU_GPR(R29)(r9)
 +	std	r30, VCPU_GPR(R30)(r9)
 +	std	r31, VCPU_GPR(R31)(r9)
 +
 +	/* Save SPRGs */
 +	mfspr	r3, SPRN_SPRG0
 +	mfspr	r4, SPRN_SPRG1
 +	mfspr	r5, SPRN_SPRG2
 +	mfspr	r6, SPRN_SPRG3
 +	std	r3, VCPU_SPRG0(r9)
 +	std	r4, VCPU_SPRG1(r9)
 +	std	r5, VCPU_SPRG2(r9)
 +	std	r6, VCPU_SPRG3(r9)
 +
 +	/* save FP state */
 +	mr	r3, r9
 +	bl	kvmppc_save_fp
 +
 +	/* Increment yield count if they have a VPA */
 +	ld	r8, VCPU_VPA(r9)	/* do they have a VPA? */
 +	cmpdi	r8, 0
 +	beq	25f
 +	lwz	r3, LPPACA_YIELDCOUNT(r8)
 +	addi	r3, r3, 1
 +	stw	r3, LPPACA_YIELDCOUNT(r8)
 +	li	r3, 1
 +	stb	r3, VCPU_VPA_DIRTY(r9)
 +25:
 +	/* Save PMU registers if requested */
 +	/* r8 and cr0.eq are live here */
 +	li	r3, 1
 +	sldi	r3, r3, 31		/* MMCR0_FC (freeze counters) bit */
 +	mfspr	r4, SPRN_MMCR0		/* save MMCR0 */
 +	mtspr	SPRN_MMCR0, r3		/* freeze all counters, disable ints */
 +	mfspr	r6, SPRN_MMCRA
 +BEGIN_FTR_SECTION
 +	/* On P7, clear MMCRA in order to disable SDAR updates */
 +	li	r7, 0
 +	mtspr	SPRN_MMCRA, r7
 +END_FTR_SECTION_IFSET(CPU_FTR_ARCH_206)
 +	isync
 +	beq	21f			/* if no VPA, save PMU stuff anyway */
 +	lbz	r7, LPPACA_PMCINUSE(r8)
 +	cmpwi	r7, 0			/* did they ask for PMU stuff to be saved? */
 +	bne	21f
 +	std	r3, VCPU_MMCR(r9)	/* if not, set saved MMCR0 to FC */
 +	b	22f
 +21:	mfspr	r5, SPRN_MMCR1
 +	mfspr	r7, SPRN_SIAR
 +	mfspr	r8, SPRN_SDAR
 +	std	r4, VCPU_MMCR(r9)
 +	std	r5, VCPU_MMCR + 8(r9)
 +	std	r6, VCPU_MMCR + 16(r9)
 +	std	r7, VCPU_SIAR(r9)
 +	std	r8, VCPU_SDAR(r9)
 +	mfspr	r3, SPRN_PMC1
 +	mfspr	r4, SPRN_PMC2
 +	mfspr	r5, SPRN_PMC3
 +	mfspr	r6, SPRN_PMC4
 +	mfspr	r7, SPRN_PMC5
 +	mfspr	r8, SPRN_PMC6
 +BEGIN_FTR_SECTION
 +	mfspr	r10, SPRN_PMC7
 +	mfspr	r11, SPRN_PMC8
 +END_FTR_SECTION_IFSET(CPU_FTR_ARCH_201)
 +	stw	r3, VCPU_PMC(r9)
 +	stw	r4, VCPU_PMC + 4(r9)
 +	stw	r5, VCPU_PMC + 8(r9)
 +	stw	r6, VCPU_PMC + 12(r9)
 +	stw	r7, VCPU_PMC + 16(r9)
 +	stw	r8, VCPU_PMC + 20(r9)
 +BEGIN_FTR_SECTION
 +	stw	r10, VCPU_PMC + 24(r9)
 +	stw	r11, VCPU_PMC + 28(r9)
 +END_FTR_SECTION_IFSET(CPU_FTR_ARCH_201)
 +22:
 +	ld	r0, 112+PPC_LR_STKOFF(r1)
 +	addi	r1, r1, 112
 +	mtlr	r0
 +	blr
 +secondary_too_late:
 +	ld	r5,HSTATE_KVM_VCORE(r13)
 +	HMT_LOW
 +13:	lbz	r3,VCORE_IN_GUEST(r5)
 +	cmpwi	r3,0
 +	bne	13b
 +	HMT_MEDIUM
 +	li	r0, KVM_GUEST_MODE_NONE
 +	stb	r0, HSTATE_IN_GUEST(r13)
 +	ld	r11,PACA_SLBSHADOWPTR(r13)
 +
 +	.rept	SLB_NUM_BOLTED
 +	ld	r5,SLBSHADOW_SAVEAREA(r11)
 +	ld	r6,SLBSHADOW_SAVEAREA+8(r11)
 +	andis.	r7,r5,SLB_ESID_V@h
 +	beq	1f
 +	slbmte	r6,r5
 +1:	addi	r11,r11,16
 +	.endr
++<<<<<<< HEAD
 +	b	22b
++=======
++
++	/* Save DEC */
++	mfspr	r5,SPRN_DEC
++	mftb	r6
++	extsw	r5,r5
++	add	r5,r5,r6
++	std	r5,VCPU_DEC_EXPIRES(r9)
++
+ BEGIN_FTR_SECTION
+ 	b	8f
+ END_FTR_SECTION_IFCLR(CPU_FTR_ARCH_207S)
+ 	/* Turn on TM so we can access TFHAR/TFIAR/TEXASR */
+ 	mfmsr	r8
+ 	li	r0, 1
+ 	rldimi	r8, r0, MSR_TM_LG, 63-MSR_TM_LG
+ 	mtmsrd	r8
+ 
+ 	/* Save POWER8-specific registers */
+ 	mfspr	r5, SPRN_IAMR
+ 	mfspr	r6, SPRN_PSPB
+ 	mfspr	r7, SPRN_FSCR
+ 	std	r5, VCPU_IAMR(r9)
+ 	stw	r6, VCPU_PSPB(r9)
+ 	std	r7, VCPU_FSCR(r9)
+ 	mfspr	r5, SPRN_IC
+ 	mfspr	r6, SPRN_VTB
+ 	mfspr	r7, SPRN_TAR
+ 	std	r5, VCPU_IC(r9)
+ 	std	r6, VCPU_VTB(r9)
+ 	std	r7, VCPU_TAR(r9)
+ #ifdef CONFIG_PPC_TRANSACTIONAL_MEM
+ 	mfspr	r5, SPRN_TFHAR
+ 	mfspr	r6, SPRN_TFIAR
+ 	mfspr	r7, SPRN_TEXASR
+ 	std	r5, VCPU_TFHAR(r9)
+ 	std	r6, VCPU_TFIAR(r9)
+ 	std	r7, VCPU_TEXASR(r9)
+ #endif
+ 	mfspr	r8, SPRN_EBBHR
+ 	std	r8, VCPU_EBBHR(r9)
+ 	mfspr	r5, SPRN_EBBRR
+ 	mfspr	r6, SPRN_BESCR
+ 	mfspr	r7, SPRN_CSIGR
+ 	mfspr	r8, SPRN_TACR
+ 	std	r5, VCPU_EBBRR(r9)
+ 	std	r6, VCPU_BESCR(r9)
+ 	std	r7, VCPU_CSIGR(r9)
+ 	std	r8, VCPU_TACR(r9)
+ 	mfspr	r5, SPRN_TCSCR
+ 	mfspr	r6, SPRN_ACOP
+ 	mfspr	r7, SPRN_PID
+ 	mfspr	r8, SPRN_WORT
+ 	std	r5, VCPU_TCSCR(r9)
+ 	std	r6, VCPU_ACOP(r9)
+ 	stw	r7, VCPU_GUEST_PID(r9)
+ 	std	r8, VCPU_WORT(r9)
+ 8:
+ 
+ 	/* Save and reset AMR and UAMOR before turning on the MMU */
+ BEGIN_FTR_SECTION
+ 	mfspr	r5,SPRN_AMR
+ 	mfspr	r6,SPRN_UAMOR
+ 	std	r5,VCPU_AMR(r9)
+ 	std	r6,VCPU_UAMOR(r9)
+ 	li	r6,0
+ 	mtspr	SPRN_AMR,r6
+ END_FTR_SECTION_IFSET(CPU_FTR_ARCH_206)
+ 
+ 	/* Unset guest mode */
+ 	li	r0, KVM_GUEST_MODE_NONE
+ 	stb	r0, HSTATE_IN_GUEST(r13)
+ 
+ 	ld	r0, 112+PPC_LR_STKOFF(r1)
+ 	addi	r1, r1, 112
+ 	mtlr	r0
+ 	blr
++>>>>>>> 7b490411c37f (KVM: PPC: Book3S HV: Add new state for transactional memory)
  
  /*
   * Check whether an HDSI is an HPTE not found fault or something else.
* Unmerged path arch/powerpc/include/asm/kvm_host.h
* Unmerged path arch/powerpc/kernel/asm-offsets.c
* Unmerged path arch/powerpc/kvm/book3s_hv.c
* Unmerged path arch/powerpc/kvm/book3s_hv_rmhandlers.S
