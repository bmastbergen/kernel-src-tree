KVM: Convert kvm_lock back to non-raw spinlock

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
commit-author Paolo Bonzini <pbonzini@redhat.com>
commit 2f303b74a62fb74983c0a66e2df353be963c527c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/2f303b74.failed

In commit e935b8372cf8 ("KVM: Convert kvm_lock to raw_spinlock"),
the kvm_lock was made a raw lock.  However, the kvm mmu_shrink()
function tries to grab the (non-raw) mmu_lock within the scope of
the raw locked kvm_lock being held.  This leads to the following:

BUG: sleeping function called from invalid context at kernel/rtmutex.c:659
in_atomic(): 1, irqs_disabled(): 0, pid: 55, name: kswapd0
Preemption disabled at:[<ffffffffa0376eac>] mmu_shrink+0x5c/0x1b0 [kvm]

Pid: 55, comm: kswapd0 Not tainted 3.4.34_preempt-rt
Call Trace:
 [<ffffffff8106f2ad>] __might_sleep+0xfd/0x160
 [<ffffffff817d8d64>] rt_spin_lock+0x24/0x50
 [<ffffffffa0376f3c>] mmu_shrink+0xec/0x1b0 [kvm]
 [<ffffffff8111455d>] shrink_slab+0x17d/0x3a0
 [<ffffffff81151f00>] ? mem_cgroup_iter+0x130/0x260
 [<ffffffff8111824a>] balance_pgdat+0x54a/0x730
 [<ffffffff8111fe47>] ? set_pgdat_percpu_threshold+0xa7/0xd0
 [<ffffffff811185bf>] kswapd+0x18f/0x490
 [<ffffffff81070961>] ? get_parent_ip+0x11/0x50
 [<ffffffff81061970>] ? __init_waitqueue_head+0x50/0x50
 [<ffffffff81118430>] ? balance_pgdat+0x730/0x730
 [<ffffffff81060d2b>] kthread+0xdb/0xe0
 [<ffffffff8106e122>] ? finish_task_switch+0x52/0x100
 [<ffffffff817e1e94>] kernel_thread_helper+0x4/0x10
 [<ffffffff81060c50>] ? __init_kthread_worker+0x

After the previous patch, kvm_lock need not be a raw spinlock anymore,
so change it back.

	Reported-by: Paul Gortmaker <paul.gortmaker@windriver.com>
	Cc: kvm@vger.kernel.org
	Cc: gleb@redhat.com
	Cc: jan.kiszka@siemens.com
	Reviewed-by: Gleb Natapov <gleb@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 2f303b74a62fb74983c0a66e2df353be963c527c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu.c
#	virt/kvm/kvm_main.c
diff --cc arch/x86/kvm/mmu.c
index 94dde056e31c,cf95cfe050a6..000000000000
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@@ -4368,11 -4426,9 +4368,11 @@@ static int mmu_shrink(struct shrinker *
  {
  	struct kvm *kvm;
  	int nr_to_scan = sc->nr_to_scan;
 -	unsigned long freed = 0;
 +
 +	if (nr_to_scan == 0)
 +		goto out;
  
- 	raw_spin_lock(&kvm_lock);
+ 	spin_lock(&kvm_lock);
  
  	list_for_each_entry(kvm, &vm_list, vm_list) {
  		int idx;
@@@ -4416,9 -4478,13 +4416,19 @@@ unlock
  		break;
  	}
  
++<<<<<<< HEAD
 +	raw_spin_unlock(&kvm_lock);
 +
 +out:
++=======
+ 	spin_unlock(&kvm_lock);
+ 	return freed;
+ }
+ 
+ static unsigned long
+ mmu_shrink_count(struct shrinker *shrink, struct shrink_control *sc)
+ {
++>>>>>>> 2f303b74a62f (KVM: Convert kvm_lock back to non-raw spinlock)
  	return percpu_counter_read_positive(&kvm_total_used_mmu_pages);
  }
  
diff --cc virt/kvm/kvm_main.c
index 6d05f4aed965,d469114aff09..000000000000
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@@ -70,7 -70,8 +70,12 @@@ MODULE_LICENSE("GPL")
   * 		kvm->lock --> kvm->slots_lock --> kvm->irq_lock
   */
  
++<<<<<<< HEAD
 +DEFINE_RAW_SPINLOCK(kvm_lock);
++=======
+ DEFINE_SPINLOCK(kvm_lock);
+ static DEFINE_RAW_SPINLOCK(kvm_count_lock);
++>>>>>>> 2f303b74a62f (KVM: Convert kvm_lock back to non-raw spinlock)
  LIST_HEAD(vm_list);
  
  static cpumask_var_t cpus_hardware_enabled;
diff --git a/Documentation/virtual/kvm/locking.txt b/Documentation/virtual/kvm/locking.txt
index caaf635f5c63..55317f9f0d72 100644
--- a/Documentation/virtual/kvm/locking.txt
+++ b/Documentation/virtual/kvm/locking.txt
@@ -132,7 +132,7 @@ See the comments in spte_has_volatile_bits() and mmu_spte_update().
 ------------
 
 Name:		kvm_lock
-Type:		raw_spinlock
+Type:		spinlock_t
 Arch:		any
 Protects:	- vm_list
 		- hardware virtualization enable/disable
* Unmerged path arch/x86/kvm/mmu.c
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index f0cdd181f16a..bf60d7ec7e05 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -5306,7 +5306,7 @@ static int kvmclock_cpufreq_notifier(struct notifier_block *nb, unsigned long va
 
 	smp_call_function_single(freq->cpu, tsc_khz_changed, freq, 1);
 
-	raw_spin_lock(&kvm_lock);
+	spin_lock(&kvm_lock);
 	list_for_each_entry(kvm, &vm_list, vm_list) {
 		kvm_for_each_vcpu(i, vcpu, kvm) {
 			if (vcpu->cpu != freq->cpu)
@@ -5316,7 +5316,7 @@ static int kvmclock_cpufreq_notifier(struct notifier_block *nb, unsigned long va
 				send_ipi = 1;
 		}
 	}
-	raw_spin_unlock(&kvm_lock);
+	spin_unlock(&kvm_lock);
 
 	if (freq->old < freq->new && send_ipi) {
 		/*
@@ -5474,12 +5474,12 @@ static void pvclock_gtod_update_fn(struct work_struct *work)
 	struct kvm_vcpu *vcpu;
 	int i;
 
-	raw_spin_lock(&kvm_lock);
+	spin_lock(&kvm_lock);
 	list_for_each_entry(kvm, &vm_list, vm_list)
 		kvm_for_each_vcpu(i, vcpu, kvm)
 			set_bit(KVM_REQ_MASTERCLOCK_UPDATE, &vcpu->requests);
 	atomic_set(&kvm_guest_has_master_clock, 0);
-	raw_spin_unlock(&kvm_lock);
+	spin_unlock(&kvm_lock);
 }
 
 static DECLARE_WORK(pvclock_gtod_work, pvclock_gtod_update_fn);
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index 4892021bd057..fd92986ac06f 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -142,7 +142,7 @@ struct kvm;
 struct kvm_vcpu;
 extern struct kmem_cache *kvm_vcpu_cache;
 
-extern raw_spinlock_t kvm_lock;
+extern spinlock_t kvm_lock;
 extern struct list_head vm_list;
 
 struct kvm_io_range {
* Unmerged path virt/kvm/kvm_main.c
