hyperv: Add hash value into RNDIS Per-packet info

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-229.el7
commit-author Haiyang Zhang <haiyangz@microsoft.com>
commit 307f099520b66504cf6c5638f3f404c48b9fb45b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-229.el7/307f0995.failed

It passes the hash value as the RNDIS Per-packet info to the Hyper-V host,
so that the send completion notices can be spread across multiple channels.
MS-TFS: 140273

	Signed-off-by: Haiyang Zhang <haiyangz@microsoft.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 307f099520b66504cf6c5638f3f404c48b9fb45b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/hyperv/hyperv_net.h
#	drivers/net/hyperv/netvsc_drv.c
diff --cc drivers/net/hyperv/hyperv_net.h
index a2561fea6d21,6cc37c15e0bf..000000000000
--- a/drivers/net/hyperv/hyperv_net.h
+++ b/drivers/net/hyperv/hyperv_net.h
@@@ -729,6 -813,134 +730,18 @@@ struct ndis_pkt_8021q_info 
  #define NDIS_VLAN_PPI_SIZE (sizeof(struct rndis_per_packet_info) + \
  		sizeof(struct ndis_pkt_8021q_info))
  
++<<<<<<< HEAD
++=======
+ #define NDIS_CSUM_PPI_SIZE (sizeof(struct rndis_per_packet_info) + \
+ 		sizeof(struct ndis_tcp_ip_checksum_info))
+ 
+ #define NDIS_LSO_PPI_SIZE (sizeof(struct rndis_per_packet_info) + \
+ 		sizeof(struct ndis_tcp_lso_info))
+ 
+ #define NDIS_HASH_PPI_SIZE (sizeof(struct rndis_per_packet_info) + \
+ 		sizeof(u32))
+ 
++>>>>>>> 307f099520b6 (hyperv: Add hash value into RNDIS Per-packet info)
  /* Format of Information buffer passed in a SetRequest for the OID */
  /* OID_GEN_RNDIS_CONFIG_PARAMETER. */
  struct rndis_config_parameter_info {
diff --cc drivers/net/hyperv/netvsc_drv.c
index 854b31f1a85a,4fd71b75e666..000000000000
--- a/drivers/net/hyperv/netvsc_drv.c
+++ b/drivers/net/hyperv/netvsc_drv.c
@@@ -129,6 -128,111 +129,114 @@@ static int netvsc_close(struct net_devi
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ static void *init_ppi_data(struct rndis_message *msg, u32 ppi_size,
+ 				int pkt_type)
+ {
+ 	struct rndis_packet *rndis_pkt;
+ 	struct rndis_per_packet_info *ppi;
+ 
+ 	rndis_pkt = &msg->msg.pkt;
+ 	rndis_pkt->data_offset += ppi_size;
+ 
+ 	ppi = (struct rndis_per_packet_info *)((void *)rndis_pkt +
+ 		rndis_pkt->per_pkt_info_offset + rndis_pkt->per_pkt_info_len);
+ 
+ 	ppi->size = ppi_size;
+ 	ppi->type = pkt_type;
+ 	ppi->ppi_offset = sizeof(struct rndis_per_packet_info);
+ 
+ 	rndis_pkt->per_pkt_info_len += ppi_size;
+ 
+ 	return ppi;
+ }
+ 
+ union sub_key {
+ 	u64 k;
+ 	struct {
+ 		u8 pad[3];
+ 		u8 kb;
+ 		u32 ka;
+ 	};
+ };
+ 
+ /* Toeplitz hash function
+  * data: network byte order
+  * return: host byte order
+  */
+ static u32 comp_hash(u8 *key, int klen, u8 *data, int dlen)
+ {
+ 	union sub_key subk;
+ 	int k_next = 4;
+ 	u8 dt;
+ 	int i, j;
+ 	u32 ret = 0;
+ 
+ 	subk.k = 0;
+ 	subk.ka = ntohl(*(u32 *)key);
+ 
+ 	for (i = 0; i < dlen; i++) {
+ 		subk.kb = key[k_next];
+ 		k_next = (k_next + 1) % klen;
+ 		dt = data[i];
+ 		for (j = 0; j < 8; j++) {
+ 			if (dt & 0x80)
+ 				ret ^= subk.ka;
+ 			dt <<= 1;
+ 			subk.k <<= 1;
+ 		}
+ 	}
+ 
+ 	return ret;
+ }
+ 
+ static bool netvsc_set_hash(u32 *hash, struct sk_buff *skb)
+ {
+ 	struct iphdr *iphdr;
+ 	int data_len;
+ 	bool ret = false;
+ 
+ 	if (eth_hdr(skb)->h_proto != htons(ETH_P_IP))
+ 		return false;
+ 
+ 	iphdr = ip_hdr(skb);
+ 
+ 	if (iphdr->version == 4) {
+ 		if (iphdr->protocol == IPPROTO_TCP)
+ 			data_len = 12;
+ 		else
+ 			data_len = 8;
+ 		*hash = comp_hash(netvsc_hash_key, HASH_KEYLEN,
+ 				  (u8 *)&iphdr->saddr, data_len);
+ 		ret = true;
+ 	}
+ 
+ 	return ret;
+ }
+ 
+ static u16 netvsc_select_queue(struct net_device *ndev, struct sk_buff *skb,
+ 			void *accel_priv, select_queue_fallback_t fallback)
+ {
+ 	struct net_device_context *net_device_ctx = netdev_priv(ndev);
+ 	struct hv_device *hdev =  net_device_ctx->device_ctx;
+ 	struct netvsc_device *nvsc_dev = hv_get_drvdata(hdev);
+ 	u32 hash;
+ 	u16 q_idx = 0;
+ 
+ 	if (nvsc_dev == NULL || ndev->real_num_tx_queues <= 1)
+ 		return 0;
+ 
+ 	if (netvsc_set_hash(&hash, skb)) {
+ 		q_idx = nvsc_dev->send_table[hash % VRSS_SEND_TAB_SIZE] %
+ 			ndev->real_num_tx_queues;
+ 		skb_set_hash(skb, hash, PKT_HASH_TYPE_L3);
+ 	}
+ 
+ 	return q_idx;
+ }
+ 
++>>>>>>> 307f099520b6 (hyperv: Add hash value into RNDIS Per-packet info)
  static void netvsc_xmit_completion(void *context)
  {
  	struct hv_netvsc_packet *packet = (struct hv_netvsc_packet *)context;
@@@ -146,18 -376,37 +254,39 @@@ static int netvsc_start_xmit(struct sk_
  	struct net_device_context *net_device_ctx = netdev_priv(net);
  	struct hv_netvsc_packet *packet;
  	int ret;
++<<<<<<< HEAD
 +	unsigned int i, num_pages, npg_data;
++=======
+ 	unsigned int num_data_pgs;
+ 	struct rndis_message *rndis_msg;
+ 	struct rndis_packet *rndis_pkt;
+ 	u32 rndis_msg_size;
+ 	bool isvlan;
+ 	struct rndis_per_packet_info *ppi;
+ 	struct ndis_tcp_ip_checksum_info *csum_info;
+ 	struct ndis_tcp_lso_info *lso_info;
+ 	int  hdr_offset;
+ 	u32 net_trans_info;
+ 	u32 hash;
++>>>>>>> 307f099520b6 (hyperv: Add hash value into RNDIS Per-packet info)
  
 -
 -	/* We will atmost need two pages to describe the rndis
 -	 * header. We can only transmit MAX_PAGE_BUFFER_COUNT number
 -	 * of pages in a single packet.
 -	 */
 -	num_data_pgs = netvsc_get_slots(skb) + 2;
 -	if (num_data_pgs > MAX_PAGE_BUFFER_COUNT) {
 -		netdev_err(net, "Packet too big: %u\n", skb->len);
 -		dev_kfree_skb(skb);
 -		net->stats.tx_dropped++;
 -		return NETDEV_TX_OK;
 -	}
 +	/* Add multipages for skb->data and additional 2 for RNDIS */
 +	npg_data = (((unsigned long)skb->data + skb_headlen(skb) - 1)
 +		>> PAGE_SHIFT) - ((unsigned long)skb->data >> PAGE_SHIFT) + 1;
 +	num_pages = skb_shinfo(skb)->nr_frags + npg_data + 2;
  
  	/* Allocate a netvsc packet based on # of frags. */
  	packet = kzalloc(sizeof(struct hv_netvsc_packet) +
++<<<<<<< HEAD
 +			 (num_pages * sizeof(struct hv_page_buffer)) +
 +			 sizeof(struct rndis_filter_packet) +
 +			 NDIS_VLAN_PPI_SIZE, GFP_ATOMIC);
++=======
+ 			 (num_data_pgs * sizeof(struct hv_page_buffer)) +
+ 			 sizeof(struct rndis_message) +
+ 			 NDIS_VLAN_PPI_SIZE + NDIS_CSUM_PPI_SIZE +
+ 			 NDIS_LSO_PPI_SIZE + NDIS_HASH_PPI_SIZE, GFP_ATOMIC);
++>>>>>>> 307f099520b6 (hyperv: Add hash value into RNDIS Per-packet info)
  	if (!packet) {
  		/* out of memory, drop packet */
  		netdev_err(net, "unable to allocate hv_netvsc_packet\n");
@@@ -169,53 -418,149 +298,185 @@@
  
  	packet->vlan_tci = skb->vlan_tci;
  
 -	packet->q_idx = skb_get_queue_mapping(skb);
 +	packet->extension = (void *)(unsigned long)packet +
 +				sizeof(struct hv_netvsc_packet) +
 +				    (num_pages * sizeof(struct hv_page_buffer));
 +
 +	/* If the rndis msg goes beyond 1 page, we will add 1 later */
 +	packet->page_buf_cnt = num_pages - 1;
  
 -	packet->is_data_pkt = true;
 +	/* Initialize it from the skb */
  	packet->total_data_buflen = skb->len;
  
 -	packet->rndis_msg = (struct rndis_message *)((unsigned long)packet +
 -				sizeof(struct hv_netvsc_packet) +
 -				(num_data_pgs * sizeof(struct hv_page_buffer)));
 +	/* Start filling in the page buffers starting after RNDIS buffer. */
 +	packet->page_buf[1].pfn = virt_to_phys(skb->data) >> PAGE_SHIFT;
 +	packet->page_buf[1].offset
 +		= (unsigned long)skb->data & (PAGE_SIZE - 1);
 +	if (npg_data == 1)
 +		packet->page_buf[1].len = skb_headlen(skb);
 +	else
 +		packet->page_buf[1].len = PAGE_SIZE
 +			- packet->page_buf[1].offset;
 +
 +	for (i = 2; i <= npg_data; i++) {
 +		packet->page_buf[i].pfn = virt_to_phys(skb->data
 +			+ PAGE_SIZE * (i-1)) >> PAGE_SHIFT;
 +		packet->page_buf[i].offset = 0;
 +		packet->page_buf[i].len = PAGE_SIZE;
 +	}
 +	if (npg_data > 1)
 +		packet->page_buf[npg_data].len = (((unsigned long)skb->data
 +			+ skb_headlen(skb) - 1) & (PAGE_SIZE - 1)) + 1;
 +
 +	/* Additional fragments are after SKB data */
 +	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
 +		const skb_frag_t *f = &skb_shinfo(skb)->frags[i];
 +
 +		packet->page_buf[i+npg_data+1].pfn =
 +			page_to_pfn(skb_frag_page(f));
 +		packet->page_buf[i+npg_data+1].offset = f->page_offset;
 +		packet->page_buf[i+npg_data+1].len = skb_frag_size(f);
 +	}
  
  	/* Set the completion routine */
 -	packet->send_completion = netvsc_xmit_completion;
 -	packet->send_completion_ctx = packet;
 -	packet->send_completion_tid = (unsigned long)skb;
 -
 +	packet->completion.send.send_completion = netvsc_xmit_completion;
 +	packet->completion.send.send_completion_ctx = packet;
 +	packet->completion.send.send_completion_tid = (unsigned long)skb;
 +
++<<<<<<< HEAD
 +	ret = rndis_filter_send(net_device_ctx->device_ctx,
 +				  packet);
++=======
+ 	isvlan = packet->vlan_tci & VLAN_TAG_PRESENT;
+ 
+ 	/* Add the rndis header */
+ 	rndis_msg = packet->rndis_msg;
+ 	rndis_msg->ndis_msg_type = RNDIS_MSG_PACKET;
+ 	rndis_msg->msg_len = packet->total_data_buflen;
+ 	rndis_pkt = &rndis_msg->msg.pkt;
+ 	rndis_pkt->data_offset = sizeof(struct rndis_packet);
+ 	rndis_pkt->data_len = packet->total_data_buflen;
+ 	rndis_pkt->per_pkt_info_offset = sizeof(struct rndis_packet);
+ 
+ 	rndis_msg_size = RNDIS_MESSAGE_SIZE(struct rndis_packet);
+ 
+ 	hash = skb_get_hash_raw(skb);
+ 	if (hash != 0 && net->real_num_tx_queues > 1) {
+ 		rndis_msg_size += NDIS_HASH_PPI_SIZE;
+ 		ppi = init_ppi_data(rndis_msg, NDIS_HASH_PPI_SIZE,
+ 				    NBL_HASH_VALUE);
+ 		*(u32 *)((void *)ppi + ppi->ppi_offset) = hash;
+ 	}
+ 
+ 	if (isvlan) {
+ 		struct ndis_pkt_8021q_info *vlan;
+ 
+ 		rndis_msg_size += NDIS_VLAN_PPI_SIZE;
+ 		ppi = init_ppi_data(rndis_msg, NDIS_VLAN_PPI_SIZE,
+ 					IEEE_8021Q_INFO);
+ 		vlan = (struct ndis_pkt_8021q_info *)((void *)ppi +
+ 						ppi->ppi_offset);
+ 		vlan->vlanid = packet->vlan_tci & VLAN_VID_MASK;
+ 		vlan->pri = (packet->vlan_tci & VLAN_PRIO_MASK) >>
+ 				VLAN_PRIO_SHIFT;
+ 	}
+ 
+ 	net_trans_info = get_net_transport_info(skb, &hdr_offset);
+ 	if (net_trans_info == TRANSPORT_INFO_NOT_IP)
+ 		goto do_send;
+ 
+ 	/*
+ 	 * Setup the sendside checksum offload only if this is not a
+ 	 * GSO packet.
+ 	 */
+ 	if (skb_is_gso(skb))
+ 		goto do_lso;
+ 
+ 	if ((skb->ip_summed == CHECKSUM_NONE) ||
+ 	    (skb->ip_summed == CHECKSUM_UNNECESSARY))
+ 		goto do_send;
+ 
+ 	rndis_msg_size += NDIS_CSUM_PPI_SIZE;
+ 	ppi = init_ppi_data(rndis_msg, NDIS_CSUM_PPI_SIZE,
+ 			    TCPIP_CHKSUM_PKTINFO);
+ 
+ 	csum_info = (struct ndis_tcp_ip_checksum_info *)((void *)ppi +
+ 			ppi->ppi_offset);
+ 
+ 	if (net_trans_info & (INFO_IPV4 << 16))
+ 		csum_info->transmit.is_ipv4 = 1;
+ 	else
+ 		csum_info->transmit.is_ipv6 = 1;
+ 
+ 	if (net_trans_info & INFO_TCP) {
+ 		csum_info->transmit.tcp_checksum = 1;
+ 		csum_info->transmit.tcp_header_offset = hdr_offset;
+ 	} else if (net_trans_info & INFO_UDP) {
+ 		/* UDP checksum offload is not supported on ws2008r2.
+ 		 * Furthermore, on ws2012 and ws2012r2, there are some
+ 		 * issues with udp checksum offload from Linux guests.
+ 		 * (these are host issues).
+ 		 * For now compute the checksum here.
+ 		 */
+ 		struct udphdr *uh;
+ 		u16 udp_len;
+ 
+ 		ret = skb_cow_head(skb, 0);
+ 		if (ret)
+ 			goto drop;
+ 
+ 		uh = udp_hdr(skb);
+ 		udp_len = ntohs(uh->len);
+ 		uh->check = 0;
+ 		uh->check = csum_tcpudp_magic(ip_hdr(skb)->saddr,
+ 					      ip_hdr(skb)->daddr,
+ 					      udp_len, IPPROTO_UDP,
+ 					      csum_partial(uh, udp_len, 0));
+ 		if (uh->check == 0)
+ 			uh->check = CSUM_MANGLED_0;
+ 
+ 		csum_info->transmit.udp_checksum = 0;
+ 	}
+ 	goto do_send;
+ 
+ do_lso:
+ 	rndis_msg_size += NDIS_LSO_PPI_SIZE;
+ 	ppi = init_ppi_data(rndis_msg, NDIS_LSO_PPI_SIZE,
+ 			    TCP_LARGESEND_PKTINFO);
+ 
+ 	lso_info = (struct ndis_tcp_lso_info *)((void *)ppi +
+ 			ppi->ppi_offset);
+ 
+ 	lso_info->lso_v2_transmit.type = NDIS_TCP_LARGE_SEND_OFFLOAD_V2_TYPE;
+ 	if (net_trans_info & (INFO_IPV4 << 16)) {
+ 		lso_info->lso_v2_transmit.ip_version =
+ 			NDIS_TCP_LARGE_SEND_OFFLOAD_IPV4;
+ 		ip_hdr(skb)->tot_len = 0;
+ 		ip_hdr(skb)->check = 0;
+ 		tcp_hdr(skb)->check =
+ 		~csum_tcpudp_magic(ip_hdr(skb)->saddr,
+ 				   ip_hdr(skb)->daddr, 0, IPPROTO_TCP, 0);
+ 	} else {
+ 		lso_info->lso_v2_transmit.ip_version =
+ 			NDIS_TCP_LARGE_SEND_OFFLOAD_IPV6;
+ 		ipv6_hdr(skb)->payload_len = 0;
+ 		tcp_hdr(skb)->check =
+ 		~csum_ipv6_magic(&ipv6_hdr(skb)->saddr,
+ 				&ipv6_hdr(skb)->daddr, 0, IPPROTO_TCP, 0);
+ 	}
+ 	lso_info->lso_v2_transmit.tcp_header_offset = hdr_offset;
+ 	lso_info->lso_v2_transmit.mss = skb_shinfo(skb)->gso_size;
+ 
+ do_send:
+ 	/* Start filling in the page buffers with the rndis hdr */
+ 	rndis_msg->msg_len += rndis_msg_size;
+ 	packet->page_buf_cnt = init_page_array(rndis_msg, rndis_msg_size,
+ 					skb, &packet->page_buf[0]);
+ 
+ 	ret = netvsc_send(net_device_ctx->device_ctx, packet);
+ 
+ drop:
++>>>>>>> 307f099520b6 (hyperv: Add hash value into RNDIS Per-packet info)
  	if (ret == 0) {
  		net->stats.tx_bytes += skb->len;
  		net->stats.tx_packets++;
* Unmerged path drivers/net/hyperv/hyperv_net.h
* Unmerged path drivers/net/hyperv/netvsc_drv.c
