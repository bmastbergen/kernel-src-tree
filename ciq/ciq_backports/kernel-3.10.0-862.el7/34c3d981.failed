genirq/affinity: Provide smarter irq spreading infrastructure

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 34c3d9819fda464be4f1bec59b63353814f76c73
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/34c3d981.failed

The current irq spreading infrastructure is just looking at a cpumask and
tries to spread the interrupts over the mask. Thats suboptimal as it does
not take numa nodes into account.

Change the logic so the interrupts are spread across numa nodes and inside
the nodes. If there are more cpus than vectors per node, then we set the
affinity to several cpus. If HT siblings are available we take that into
account and try to set all siblings to a single vector.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: Christoph Hellwig <hch@lst.de>
	Cc: axboe@fb.com
	Cc: keith.busch@intel.com
	Cc: agordeev@redhat.com
	Cc: linux-block@vger.kernel.org
Link: http://lkml.kernel.org/r/1473862739-15032-3-git-send-email-hch@lst.de

(cherry picked from commit 34c3d9819fda464be4f1bec59b63353814f76c73)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/interrupt.h
#	kernel/irq/affinity.c
diff --cc include/linux/interrupt.h
index 775c38a0baff,4e59d122cad9..000000000000
--- a/include/linux/interrupt.h
+++ b/include/linux/interrupt.h
@@@ -299,6 -278,10 +299,13 @@@ struct irq_affinity_notify 
  extern int
  irq_set_affinity_notifier(unsigned int irq, struct irq_affinity_notify *notify);
  
++<<<<<<< HEAD
++=======
+ struct cpumask *irq_create_affinity_mask(unsigned int *nr_vecs);
+ struct cpumask *irq_create_affinity_masks(const struct cpumask *affinity, int nvec);
+ int irq_calc_affinity_vectors(const struct cpumask *affinity, int maxvec);
+ 
++>>>>>>> 34c3d9819fda (genirq/affinity: Provide smarter irq spreading infrastructure)
  #else /* CONFIG_SMP */
  
  static inline int irq_set_affinity(unsigned int irq, const struct cpumask *m)
@@@ -318,9 -306,33 +325,38 @@@ static inline int irq_set_affinity_hint
  {
  	return -EINVAL;
  }
 +#endif /* CONFIG_SMP && CONFIG_GENERIC_HARDIRQS */
  
++<<<<<<< HEAD
 +#ifdef CONFIG_GENERIC_HARDIRQS
++=======
+ static inline int
+ irq_set_affinity_notifier(unsigned int irq, struct irq_affinity_notify *notify)
+ {
+ 	return 0;
+ }
+ 
+ static inline struct cpumask *irq_create_affinity_mask(unsigned int *nr_vecs)
+ {
+ 	*nr_vecs = 1;
+ 	return NULL;
+ }
+ 
+ static inline struct cpumask *
+ irq_create_affinity_masks(const struct cpumask *affinity, int nvec)
+ {
+ 	return NULL;
+ }
+ 
+ static inline int
+ irq_calc_affinity_vectors(const struct cpumask *affinity, int maxvec)
+ {
+ 	return maxvec;
+ }
+ 
+ #endif /* CONFIG_SMP */
+ 
++>>>>>>> 34c3d9819fda (genirq/affinity: Provide smarter irq spreading infrastructure)
  /*
   * Special lockdep variants of irq disabling/enabling.
   * These should be used for locking constructs that
* Unmerged path kernel/irq/affinity.c
* Unmerged path include/linux/interrupt.h
* Unmerged path kernel/irq/affinity.c
