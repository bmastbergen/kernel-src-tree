scsi: smartpqi: mark PM functions as __maybe_unused

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [scsi] smartpqi: mark PM functions as __maybe_unused (Don Brace) [1457414]
Rebuild_FUZZ: 93.75%
commit-author Arnd Bergmann <arnd@arndb.de>
commit 5c146686e32085e76ad9e2957f3dee9b28fe4f22
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/5c146686.failed

The newly added suspend/resume support causes harmless warnings when
CONFIG_PM is disabled:

smartpqi/smartpqi_init.c:5147:12: error: 'pqi_ctrl_wait_for_pending_io' defined but not used [-Werror=unused-function]
smartpqi/smartpqi_init.c:2019:13: error: 'pqi_wait_until_lun_reset_finished' defined but not used [-Werror=unused-function]
smartpqi/smartpqi_init.c:2013:13: error: 'pqi_wait_until_scan_finished' defined but not used [-Werror=unused-function]

We can avoid the warnings by removing the #ifdef around the handlers and
instead marking them as __maybe_unused, which will let gcc drop the
unused code silently.

Fixes: f44d210312a6 ("scsi: smartpqi: add suspend and resume support")
	Signed-off-by: Arnd Bergmann <arnd@arndb.de>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit 5c146686e32085e76ad9e2957f3dee9b28fe4f22)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/smartpqi/smartpqi_init.c
diff --cc drivers/scsi/smartpqi/smartpqi_init.c
index 13a5a9aaadf9,cb8f886e705c..000000000000
--- a/drivers/scsi/smartpqi/smartpqi_init.c
+++ b/drivers/scsi/smartpqi/smartpqi_init.c
@@@ -5845,6 -6213,112 +5845,115 @@@ static int pqi_ctrl_init(struct pqi_ctr
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static void pqi_reinit_queues(struct pqi_ctrl_info *ctrl_info)
+ {
+ 	unsigned int i;
+ 	struct pqi_admin_queues *admin_queues;
+ 	struct pqi_event_queue *event_queue;
+ 
+ 	admin_queues = &ctrl_info->admin_queues;
+ 	admin_queues->iq_pi_copy = 0;
+ 	admin_queues->oq_ci_copy = 0;
+ 	*admin_queues->oq_pi = 0;
+ 
+ 	for (i = 0; i < ctrl_info->num_queue_groups; i++) {
+ 		ctrl_info->queue_groups[i].iq_pi_copy[RAID_PATH] = 0;
+ 		ctrl_info->queue_groups[i].iq_pi_copy[AIO_PATH] = 0;
+ 		ctrl_info->queue_groups[i].oq_ci_copy = 0;
+ 
+ 		*ctrl_info->queue_groups[i].iq_ci[RAID_PATH] = 0;
+ 		*ctrl_info->queue_groups[i].iq_ci[AIO_PATH] = 0;
+ 		*ctrl_info->queue_groups[i].oq_pi = 0;
+ 	}
+ 
+ 	event_queue = &ctrl_info->event_queue;
+ 	*event_queue->oq_pi = 0;
+ 	event_queue->oq_ci_copy = 0;
+ }
+ 
+ static int pqi_ctrl_init_resume(struct pqi_ctrl_info *ctrl_info)
+ {
+ 	int rc;
+ 
+ 	rc = pqi_force_sis_mode(ctrl_info);
+ 	if (rc)
+ 		return rc;
+ 
+ 	/*
+ 	 * Wait until the controller is ready to start accepting SIS
+ 	 * commands.
+ 	 */
+ 	rc = sis_wait_for_ctrl_ready_resume(ctrl_info);
+ 	if (rc)
+ 		return rc;
+ 
+ 	/*
+ 	 * If the function we are about to call succeeds, the
+ 	 * controller will transition from legacy SIS mode
+ 	 * into PQI mode.
+ 	 */
+ 	rc = sis_init_base_struct_addr(ctrl_info);
+ 	if (rc) {
+ 		dev_err(&ctrl_info->pci_dev->dev,
+ 			"error initializing PQI mode\n");
+ 		return rc;
+ 	}
+ 
+ 	/* Wait for the controller to complete the SIS -> PQI transition. */
+ 	rc = pqi_wait_for_pqi_mode_ready(ctrl_info);
+ 	if (rc) {
+ 		dev_err(&ctrl_info->pci_dev->dev,
+ 			"transition to PQI mode failed\n");
+ 		return rc;
+ 	}
+ 
+ 	/* From here on, we are running in PQI mode. */
+ 	ctrl_info->pqi_mode_enabled = true;
+ 	pqi_save_ctrl_mode(ctrl_info, PQI_MODE);
+ 
+ 	pqi_reinit_queues(ctrl_info);
+ 
+ 	rc = pqi_create_admin_queues(ctrl_info);
+ 	if (rc) {
+ 		dev_err(&ctrl_info->pci_dev->dev,
+ 			"error creating admin queues\n");
+ 		return rc;
+ 	}
+ 
+ 	rc = pqi_create_queues(ctrl_info);
+ 	if (rc)
+ 		return rc;
+ 
+ 	pqi_change_irq_mode(ctrl_info, IRQ_MODE_MSIX);
+ 
+ 	ctrl_info->controller_online = true;
+ 	pqi_start_heartbeat_timer(ctrl_info);
+ 	pqi_ctrl_unblock_requests(ctrl_info);
+ 
+ 	rc = pqi_enable_events(ctrl_info);
+ 	if (rc) {
+ 		dev_err(&ctrl_info->pci_dev->dev,
+ 			"error enabling events\n");
+ 		return rc;
+ 	}
+ 
+ 	rc = pqi_write_driver_version_to_host_wellness(ctrl_info);
+ 	if (rc) {
+ 		dev_err(&ctrl_info->pci_dev->dev,
+ 			"error updating host wellness\n");
+ 		return rc;
+ 	}
+ 
+ 	pqi_schedule_update_time_worker(ctrl_info);
+ 
+ 	pqi_scan_scsi_devices(ctrl_info);
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 5c146686e320 (scsi: smartpqi: mark PM functions as __maybe_unused)
  static inline int pqi_set_pcie_completion_timeout(struct pci_dev *pci_dev,
  	u16 timeout)
  {
@@@ -6105,6 -6668,91 +6214,94 @@@ error
  		"unable to flush controller cache\n");
  }
  
++<<<<<<< HEAD
++=======
+ static void pqi_process_lockup_action_param(void)
+ {
+ 	unsigned int i;
+ 
+ 	if (!pqi_lockup_action_param)
+ 		return;
+ 
+ 	for (i = 0; i < ARRAY_SIZE(pqi_lockup_actions); i++) {
+ 		if (strcmp(pqi_lockup_action_param,
+ 			pqi_lockup_actions[i].name) == 0) {
+ 			pqi_lockup_action = pqi_lockup_actions[i].action;
+ 			return;
+ 		}
+ 	}
+ 
+ 	pr_warn("%s: invalid lockup action setting \"%s\" - supported settings: none, reboot, panic\n",
+ 		DRIVER_NAME_SHORT, pqi_lockup_action_param);
+ }
+ 
+ static void pqi_process_module_params(void)
+ {
+ 	pqi_process_lockup_action_param();
+ }
+ 
+ static __maybe_unused int pqi_suspend(struct pci_dev *pci_dev, pm_message_t state)
+ {
+ 	struct pqi_ctrl_info *ctrl_info;
+ 
+ 	ctrl_info = pci_get_drvdata(pci_dev);
+ 
+ 	pqi_disable_events(ctrl_info);
+ 	pqi_cancel_update_time_worker(ctrl_info);
+ 	pqi_cancel_rescan_worker(ctrl_info);
+ 	pqi_wait_until_scan_finished(ctrl_info);
+ 	pqi_wait_until_lun_reset_finished(ctrl_info);
+ 	pqi_flush_cache(ctrl_info);
+ 	pqi_ctrl_block_requests(ctrl_info);
+ 	pqi_ctrl_wait_until_quiesced(ctrl_info);
+ 	pqi_wait_until_inbound_queues_empty(ctrl_info);
+ 	pqi_ctrl_wait_for_pending_io(ctrl_info);
+ 	pqi_stop_heartbeat_timer(ctrl_info);
+ 
+ 	if (state.event == PM_EVENT_FREEZE)
+ 		return 0;
+ 
+ 	pci_save_state(pci_dev);
+ 	pci_set_power_state(pci_dev, pci_choose_state(pci_dev, state));
+ 
+ 	ctrl_info->controller_online = false;
+ 	ctrl_info->pqi_mode_enabled = false;
+ 
+ 	return 0;
+ }
+ 
+ static __maybe_unused int pqi_resume(struct pci_dev *pci_dev)
+ {
+ 	int rc;
+ 	struct pqi_ctrl_info *ctrl_info;
+ 
+ 	ctrl_info = pci_get_drvdata(pci_dev);
+ 
+ 	if (pci_dev->current_state != PCI_D0) {
+ 		ctrl_info->max_hw_queue_index = 0;
+ 		pqi_free_interrupts(ctrl_info);
+ 		pqi_change_irq_mode(ctrl_info, IRQ_MODE_INTX);
+ 		rc = request_irq(pci_irq_vector(pci_dev, 0), pqi_irq_handler,
+ 			IRQF_SHARED, DRIVER_NAME_SHORT,
+ 			&ctrl_info->queue_groups[0]);
+ 		if (rc) {
+ 			dev_err(&ctrl_info->pci_dev->dev,
+ 				"irq %u init failed with error %d\n",
+ 				pci_dev->irq, rc);
+ 			return rc;
+ 		}
+ 		pqi_start_heartbeat_timer(ctrl_info);
+ 		pqi_ctrl_unblock_requests(ctrl_info);
+ 		return 0;
+ 	}
+ 
+ 	pci_set_power_state(pci_dev, PCI_D0);
+ 	pci_restore_state(pci_dev);
+ 
+ 	return pqi_ctrl_init_resume(ctrl_info);
+ }
+ 
++>>>>>>> 5c146686e320 (scsi: smartpqi: mark PM functions as __maybe_unused)
  /* Define the PCI IDs for the controllers that we support. */
  static const struct pci_device_id pqi_pci_id_table[] = {
  	{
* Unmerged path drivers/scsi/smartpqi/smartpqi_init.c
