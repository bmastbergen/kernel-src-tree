mlx4: do not access rx_desc from mlx4_en_process_rx_cq()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Eric Dumazet <edumazet@google.com>
commit 9e8c0395a7e87a8f0eb008297df25ffdf3e0e5b3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/9e8c0395.failed

Instead of fetching dma address from rx_desc->data[0].addr,
prefer using frags[0].dma + frags[0].page_offset to avoid
a potential cache line miss.

	Signed-off-by: Eric Dumazet <edumazet@google.com>
	Acked-by: Tariq Toukan <tariqt@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 9e8c0395a7e87a8f0eb008297df25ffdf3e0e5b3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx4/en_rx.c
diff --cc drivers/net/ethernet/mellanox/mlx4/en_rx.c
index 984f22166c89,b62fa265890e..000000000000
--- a/drivers/net/ethernet/mellanox/mlx4/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx4/en_rx.c
@@@ -798,7 -702,8 +797,12 @@@ int mlx4_en_process_rx_cq(struct net_de
  	struct mlx4_cqe *cqe;
  	struct mlx4_en_rx_ring *ring = priv->rx_ring[cq->ring];
  	struct mlx4_en_rx_alloc *frags;
++<<<<<<< HEAD
 +	struct mlx4_en_rx_desc *rx_desc;
++=======
+ 	struct bpf_prog *xdp_prog;
+ 	int doorbell_pending;
++>>>>>>> 9e8c0395a7e8 (mlx4: do not access rx_desc from mlx4_en_process_rx_cq())
  	struct sk_buff *skb;
  	int index;
  	int nr;
@@@ -886,10 -791,61 +889,66 @@@
  		 */
  		length = be32_to_cpu(cqe->byte_cnt);
  		length -= ring->fcs_del;
++<<<<<<< HEAD
++=======
+ 		l2_tunnel = (dev->hw_enc_features & NETIF_F_RXCSUM) &&
+ 			(cqe->vlan_my_qpn & cpu_to_be32(MLX4_CQE_L2_TUNNEL));
+ 
+ 		/* A bpf program gets first chance to drop the packet. It may
+ 		 * read bytes but not past the end of the frag.
+ 		 */
+ 		if (xdp_prog) {
+ 			struct xdp_buff xdp;
+ 			dma_addr_t dma;
+ 			void *orig_data;
+ 			u32 act;
+ 
+ 			dma = frags[0].dma + frags[0].page_offset;
+ 			dma_sync_single_for_cpu(priv->ddev, dma,
+ 						priv->frag_info[0].frag_size,
+ 						DMA_FROM_DEVICE);
+ 
+ 			xdp.data_hard_start = page_address(frags[0].page);
+ 			xdp.data = xdp.data_hard_start + frags[0].page_offset;
+ 			xdp.data_end = xdp.data + length;
+ 			orig_data = xdp.data;
+ 
+ 			act = bpf_prog_run_xdp(xdp_prog, &xdp);
+ 
+ 			if (xdp.data != orig_data) {
+ 				length = xdp.data_end - xdp.data;
+ 				frags[0].page_offset = xdp.data -
+ 					xdp.data_hard_start;
+ 			}
+ 
+ 			switch (act) {
+ 			case XDP_PASS:
+ 				break;
+ 			case XDP_TX:
+ 				if (likely(!mlx4_en_xmit_frame(ring, frags, dev,
+ 							length, cq->ring,
+ 							&doorbell_pending))) {
+ 					frags[0].page = NULL;
+ 					goto next;
+ 				}
+ 				trace_xdp_exception(dev, xdp_prog, act);
+ 				goto xdp_drop_no_cnt; /* Drop on xmit failure */
+ 			default:
+ 				bpf_warn_invalid_xdp_action(act);
+ 			case XDP_ABORTED:
+ 				trace_xdp_exception(dev, xdp_prog, act);
+ 			case XDP_DROP:
+ 				ring->xdp_drop++;
+ xdp_drop_no_cnt:
+ 				goto next;
+ 			}
+ 		}
+ 
++>>>>>>> 9e8c0395a7e8 (mlx4: do not access rx_desc from mlx4_en_process_rx_cq())
  		ring->bytes += length;
  		ring->packets++;
 +		l2_tunnel = (dev->hw_enc_features & NETIF_F_RXCSUM) &&
 +			(cqe->vlan_my_qpn & cpu_to_be32(MLX4_CQE_L2_TUNNEL));
  
  		if (likely(dev->features & NETIF_F_RXCSUM)) {
  			if (cqe->status & cpu_to_be16(MLX4_CQE_STATUS_TCP |
* Unmerged path drivers/net/ethernet/mellanox/mlx4/en_rx.c
