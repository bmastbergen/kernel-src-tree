net: add SOCK_RCU_FREE socket flag

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [net] add SOCK_RCU_FREE socket flag (Paolo Abeni) [1444980]
Rebuild_FUZZ: 92.06%
commit-author Eric Dumazet <edumazet@google.com>
commit a4298e4522d687a79af8f8fbb7eca68399ab2d81
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/a4298e45.failed

We want a generic way to insert an RCU grace period before socket
freeing for cases where RCU_SLAB_DESTROY_BY_RCU is adding too
much overhead.

SLAB_DESTROY_BY_RCU strict rules force us to take a reference
on the socket sk_refcnt, and it is a performance problem for UDP
encapsulation, or TCP synflood behavior, as many CPUs might
attempt the atomic operations on a shared sk_refcnt

UDP sockets and TCP listeners can set SOCK_RCU_FREE so that their
lookup can use traditional RCU rules, without refcount changes.
They can set the flag only once hashed and visible by other cpus.

	Signed-off-by: Eric Dumazet <edumazet@google.com>
	Cc: Tom Herbert <tom@herbertland.com>
	Tested-by: Tom Herbert <tom@herbertland.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit a4298e4522d687a79af8f8fbb7eca68399ab2d81)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/sock.h
#	net/core/sock.c
diff --cc include/net/sock.h
index f6191ea845e2,9e77353a92ae..000000000000
--- a/include/net/sock.h
+++ b/include/net/sock.h
@@@ -436,22 -437,8 +436,27 @@@ struct sock 
  	int			(*sk_backlog_rcv)(struct sock *sk,
  						  struct sk_buff *skb);
  	void                    (*sk_destruct)(struct sock *sk);
++<<<<<<< HEAD
 +
 +	/* RHEL SPECIFIC
 +	 *
 +	 * The following padding has been inserted before ABI freeze to
 +	 * allow extending the structure while preserve ABI. Feel free
 +	 * to replace reserved slots with required structure field
 +	 * additions of your backport.
 +	 */
 +	RH_KABI_USE2_P(1, __u32	sk_txhash, u32 sk_max_pacing_rate)
 +	RH_KABI_USE2_P(2, u16 sk_tsflags, __u32 sk_dst_pending_confirm)
 +	RH_KABI_RESERVE_P(3)
 +	RH_KABI_RESERVE_P(4)
 +	RH_KABI_RESERVE_P(5)
 +	RH_KABI_RESERVE_P(6)
 +	RH_KABI_RESERVE_P(7)
 +	RH_KABI_RESERVE_P(8)
++=======
+ 	struct sock_reuseport __rcu	*sk_reuseport_cb;
+ 	struct rcu_head		sk_rcu;
++>>>>>>> a4298e4522d6 (net: add SOCK_RCU_FREE socket flag)
  };
  
  #define __sk_user_data(sk) ((*((void __rcu **)&(sk)->sk_user_data)))
diff --cc net/core/sock.c
index acc5f5f76b01,7a6a063b28b3..000000000000
--- a/net/core/sock.c
+++ b/net/core/sock.c
@@@ -1387,8 -1419,12 +1387,16 @@@ struct sock *sk_alloc(struct net *net, 
  }
  EXPORT_SYMBOL(sk_alloc);
  
++<<<<<<< HEAD
 +static void __sk_free(struct sock *sk)
++=======
+ /* Sockets having SOCK_RCU_FREE will call this function after one RCU
+  * grace period. This is the case for UDP sockets and TCP listeners.
+  */
+ static void __sk_destruct(struct rcu_head *head)
++>>>>>>> a4298e4522d6 (net: add SOCK_RCU_FREE socket flag)
  {
+ 	struct sock *sk = container_of(head, struct sock, sk_rcu);
  	struct sk_filter *filter;
  
  	if (sk->sk_destruct)
@@@ -1414,6 -1453,22 +1422,25 @@@
  	sk_prot_free(sk->sk_prot_creator, sk);
  }
  
++<<<<<<< HEAD
++=======
+ void sk_destruct(struct sock *sk)
+ {
+ 	if (sock_flag(sk, SOCK_RCU_FREE))
+ 		call_rcu(&sk->sk_rcu, __sk_destruct);
+ 	else
+ 		__sk_destruct(&sk->sk_rcu);
+ }
+ 
+ static void __sk_free(struct sock *sk)
+ {
+ 	if (unlikely(sock_diag_has_destroy_listeners(sk) && sk->sk_net_refcnt))
+ 		sock_diag_broadcast_destroy(sk);
+ 	else
+ 		sk_destruct(sk);
+ }
+ 
++>>>>>>> a4298e4522d6 (net: add SOCK_RCU_FREE socket flag)
  void sk_free(struct sock *sk)
  {
  	/*
* Unmerged path include/net/sock.h
* Unmerged path net/core/sock.c
