KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author David Gibson <david@gibson.dropbear.id.au>
commit 3f9d4f5a5f35e402e91bedf0c15e29cef187a29d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/3f9d4f5a.failed

Currently, the powerpc kvm_arch structure contains a number of variables
tracking the state of the guest's hashed page table (HPT) in KVM HV.  This
patch gathers them all together into a single kvm_hpt_info substructure.
This makes life more convenient for the upcoming HPT resizing
implementation.

	Signed-off-by: David Gibson <david@gibson.dropbear.id.au>
	Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
(cherry picked from commit 3f9d4f5a5f35e402e91bedf0c15e29cef187a29d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/include/asm/kvm_host.h
#	arch/powerpc/kvm/book3s_64_mmu_hv.c
#	arch/powerpc/kvm/book3s_hv_rm_mmu.c
diff --cc arch/powerpc/include/asm/kvm_host.h
index 328d42daf22c,ea6f0c659936..000000000000
--- a/arch/powerpc/include/asm/kvm_host.h
+++ b/arch/powerpc/include/asm/kvm_host.h
@@@ -238,8 -257,9 +251,14 @@@ struct kvm_hpt_info 
  struct kvm_arch {
  	unsigned int lpid;
  #ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE
++<<<<<<< HEAD
 +	unsigned long hpt_virt;
 +	struct revmap_entry *revmap;
++=======
+ 	unsigned int tlb_sets;
+ 	struct kvm_hpt_info hpt;
+ 	atomic64_t mmio_update;
++>>>>>>> 3f9d4f5a5f35 (KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure)
  	unsigned int host_lpid;
  	unsigned long host_lpcr;
  	unsigned long sdr1;
@@@ -248,14 -268,14 +267,18 @@@
  	unsigned long lpcr;
  	unsigned long vrma_slb_v;
  	int hpte_setup_done;
- 	u32 hpt_order;
  	atomic_t vcpus_running;
  	u32 online_vcores;
- 	unsigned long hpt_npte;
- 	unsigned long hpt_mask;
  	atomic_t hpte_mod_interest;
  	cpumask_t need_tlb_flush;
++<<<<<<< HEAD
 +	int hpt_cma_alloc;
++=======
+ 	cpumask_t cpu_in_guest;
+ 	u8 radix;
+ 	pgd_t *pgtable;
+ 	u64 process_table;
++>>>>>>> 3f9d4f5a5f35 (KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure)
  	struct dentry *debugfs_dir;
  	struct dentry *htab_dentry;
  #endif /* CONFIG_KVM_BOOK3S_HV_POSSIBLE */
diff --cc arch/powerpc/kvm/book3s_64_mmu_hv.c
index 283e37e10f56,2af63ce129bc..000000000000
--- a/arch/powerpc/kvm/book3s_64_mmu_hv.c
+++ b/arch/powerpc/kvm/book3s_64_mmu_hv.c
@@@ -62,12 -61,12 +62,21 @@@ long kvmppc_alloc_hpt(struct kvm *kvm, 
  			order = PPC_MIN_HPT_ORDER;
  	}
  
++<<<<<<< HEAD
 +	kvm->arch.hpt_cma_alloc = 0;
 +	VM_BUG_ON(order < KVM_CMA_CHUNK_ORDER);
 +	page = kvm_alloc_hpt(1 << (order - PAGE_SHIFT));
 +	if (page) {
 +		hpt = (unsigned long)pfn_to_kaddr(page_to_pfn(page));
 +		kvm->arch.hpt_cma_alloc = 1;
++=======
+ 	kvm->arch.hpt.cma = 0;
+ 	page = kvm_alloc_hpt_cma(1ul << (order - PAGE_SHIFT));
+ 	if (page) {
+ 		hpt = (unsigned long)pfn_to_kaddr(page_to_pfn(page));
+ 		memset((void *)hpt, 0, (1ul << order));
+ 		kvm->arch.hpt.cma = 1;
++>>>>>>> 3f9d4f5a5f35 (KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure)
  	}
  
  	/* Lastly try successively smaller sizes from the page allocator */
@@@ -82,15 -81,17 +91,15 @@@
  	if (!hpt)
  		return -ENOMEM;
  
- 	kvm->arch.hpt_virt = hpt;
- 	kvm->arch.hpt_order = order;
+ 	kvm->arch.hpt.virt = hpt;
+ 	kvm->arch.hpt.order = order;
  	/* HPTEs are 2**4 bytes long */
- 	kvm->arch.hpt_npte = 1ul << (order - 4);
+ 	kvm->arch.hpt.npte = 1ul << (order - 4);
  	/* 128 (2**7) bytes in each HPTEG */
- 	kvm->arch.hpt_mask = (1ul << (order - 7)) - 1;
+ 	kvm->arch.hpt.mask = (1ul << (order - 7)) - 1;
  
 -	atomic64_set(&kvm->arch.mmio_update, 0);
 -
  	/* Allocate reverse map array */
- 	rev = vmalloc(sizeof(struct revmap_entry) * kvm->arch.hpt_npte);
+ 	rev = vmalloc(sizeof(struct revmap_entry) * kvm->arch.hpt.npte);
  	if (!rev) {
  		pr_err("kvmppc_alloc_hpt: Couldn't alloc reverse map array\n");
  		goto out_freehpt;
@@@ -106,8 -107,8 +115,13 @@@
  	return 0;
  
   out_freehpt:
++<<<<<<< HEAD
 +	if (kvm->arch.hpt_cma_alloc)
 +		kvm_release_hpt(page, 1 << (order - PAGE_SHIFT));
++=======
+ 	if (kvm->arch.hpt.cma)
+ 		kvm_free_hpt_cma(page, 1 << (order - PAGE_SHIFT));
++>>>>>>> 3f9d4f5a5f35 (KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure)
  	else
  		free_pages(hpt, order - PAGE_SHIFT);
  	return -ENOMEM;
@@@ -151,14 -155,13 +165,24 @@@ long kvmppc_alloc_reset_hpt(struct kvm 
  
  void kvmppc_free_hpt(struct kvm *kvm)
  {
++<<<<<<< HEAD
 +	kvmppc_free_lpid(kvm->arch.lpid);
 +	vfree(kvm->arch.revmap);
 +	if (kvm->arch.hpt_cma_alloc)
 +		kvm_release_hpt(virt_to_page(kvm->arch.hpt_virt),
 +				1 << (kvm->arch.hpt_order - PAGE_SHIFT));
 +	else
 +		free_pages(kvm->arch.hpt_virt,
 +			   kvm->arch.hpt_order - PAGE_SHIFT);
++=======
+ 	vfree(kvm->arch.hpt.rev);
+ 	if (kvm->arch.hpt.cma)
+ 		kvm_free_hpt_cma(virt_to_page(kvm->arch.hpt.virt),
+ 				 1 << (kvm->arch.hpt.order - PAGE_SHIFT));
+ 	else if (kvm->arch.hpt.virt)
+ 		free_pages(kvm->arch.hpt.virt,
+ 			   kvm->arch.hpt.order - PAGE_SHIFT);
++>>>>>>> 3f9d4f5a5f35 (KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure)
  }
  
  /* Bits in first HPTE dword for pagesize 4k, 64k or 16M */
@@@ -337,11 -340,13 +361,19 @@@ static int kvmppc_mmu_book3s_64_hv_xlat
  		preempt_enable();
  		return -ENOENT;
  	}
++<<<<<<< HEAD
 +	hptep = (__be64 *)(kvm->arch.hpt_virt + (index << 4));
 +	v = be64_to_cpu(hptep[0]) & ~HPTE_V_HVLOCK;
 +	gr = kvm->arch.revmap[index].guest_rpte;
++=======
+ 	hptep = (__be64 *)(kvm->arch.hpt.virt + (index << 4));
+ 	v = orig_v = be64_to_cpu(hptep[0]) & ~HPTE_V_HVLOCK;
+ 	if (cpu_has_feature(CPU_FTR_ARCH_300))
+ 		v = hpte_new_to_old_v(v, be64_to_cpu(hptep[1]));
+ 	gr = kvm->arch.hpt.rev[index].guest_rpte;
++>>>>>>> 3f9d4f5a5f35 (KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure)
  
 -	unlock_hpte(hptep, orig_v);
 +	unlock_hpte(hptep, v);
  	preempt_enable();
  
  	gpte->eaddr = eaddr;
@@@ -461,9 -471,22 +493,9 @@@ int kvmppc_book3s_hv_page_fault(struct 
  	 */
  	if (ea != vcpu->arch.pgfault_addr)
  		return RESUME_GUEST;
 -
 -	if (vcpu->arch.pgfault_cache) {
 -		mmio_update = atomic64_read(&kvm->arch.mmio_update);
 -		if (mmio_update == vcpu->arch.pgfault_cache->mmio_update) {
 -			r = vcpu->arch.pgfault_cache->rpte;
 -			psize = hpte_page_size(vcpu->arch.pgfault_hpte[0], r);
 -			gpa_base = r & HPTE_R_RPN & ~(psize - 1);
 -			gfn_base = gpa_base >> PAGE_SHIFT;
 -			gpa = gpa_base | (ea & (psize - 1));
 -			return kvmppc_hv_emulate_mmio(run, vcpu, gpa, ea,
 -						dsisr & DSISR_ISSTORE);
 -		}
 -	}
  	index = vcpu->arch.pgfault_index;
- 	hptep = (__be64 *)(kvm->arch.hpt_virt + (index << 4));
- 	rev = &kvm->arch.revmap[index];
+ 	hptep = (__be64 *)(kvm->arch.hpt.virt + (index << 4));
+ 	rev = &kvm->arch.hpt.rev[index];
  	preempt_disable();
  	while (!try_lock_hpte(hptep, HPTE_V_HVLOCK))
  		cpu_relax();
@@@ -711,10 -745,10 +743,10 @@@ static int kvm_handle_hva(struct kvm *k
  	return kvm_handle_hva_range(kvm, hva, hva + 1, handler);
  }
  
 -static int kvm_unmap_rmapp(struct kvm *kvm, struct kvm_memory_slot *memslot,
 +static int kvm_unmap_rmapp(struct kvm *kvm, unsigned long *rmapp,
  			   unsigned long gfn)
  {
- 	struct revmap_entry *rev = kvm->arch.revmap;
+ 	struct revmap_entry *rev = kvm->arch.hpt.rev;
  	unsigned long h, i, j;
  	__be64 *hptep;
  	unsigned long ptel, psize, rcbits;
@@@ -811,10 -857,10 +843,10 @@@ void kvmppc_core_flush_memslot_hv(struc
  	}
  }
  
 -static int kvm_age_rmapp(struct kvm *kvm, struct kvm_memory_slot *memslot,
 +static int kvm_age_rmapp(struct kvm *kvm, unsigned long *rmapp,
  			 unsigned long gfn)
  {
- 	struct revmap_entry *rev = kvm->arch.revmap;
+ 	struct revmap_entry *rev = kvm->arch.hpt.rev;
  	unsigned long head, i, j;
  	__be64 *hptep;
  	int ret = 0;
@@@ -864,15 -912,18 +896,15 @@@
  	return ret;
  }
  
 -int kvm_age_hva_hv(struct kvm *kvm, unsigned long start, unsigned long end)
 +int kvm_age_hva_hv(struct kvm *kvm, unsigned long hva)
  {
 -	hva_handler_fn handler;
 -
 -	handler = kvm_is_radix(kvm) ? kvm_age_radix : kvm_age_rmapp;
 -	return kvm_handle_hva_range(kvm, start, end, handler);
 +	return kvm_handle_hva(kvm, hva, kvm_age_rmapp);
  }
  
 -static int kvm_test_age_rmapp(struct kvm *kvm, struct kvm_memory_slot *memslot,
 +static int kvm_test_age_rmapp(struct kvm *kvm, unsigned long *rmapp,
  			      unsigned long gfn)
  {
- 	struct revmap_entry *rev = kvm->arch.revmap;
+ 	struct revmap_entry *rev = kvm->arch.hpt.rev;
  	unsigned long head, i, j;
  	unsigned long *hp;
  	int ret = 1;
diff --cc arch/powerpc/kvm/book3s_hv_rm_mmu.c
index 1b6a18cc43c5,175748acc9a1..000000000000
--- a/arch/powerpc/kvm/book3s_hv_rm_mmu.c
+++ b/arch/powerpc/kvm/book3s_hv_rm_mmu.c
@@@ -437,14 -465,21 +437,20 @@@ long kvmppc_do_h_remove(struct kvm *kvm
  	__be64 *hpte;
  	unsigned long v, r, rb;
  	struct revmap_entry *rev;
 -	u64 pte, orig_pte, pte_r;
 +	u64 pte;
  
++<<<<<<< HEAD
 +	if (pte_index >= kvm->arch.hpt_npte)
++=======
+ 	if (kvm_is_radix(kvm))
+ 		return H_FUNCTION;
+ 	if (pte_index >= kvm->arch.hpt.npte)
++>>>>>>> 3f9d4f5a5f35 (KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure)
  		return H_PARAMETER;
- 	hpte = (__be64 *)(kvm->arch.hpt_virt + (pte_index << 4));
+ 	hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
  	while (!try_lock_hpte(hpte, HPTE_V_HVLOCK))
  		cpu_relax();
 -	pte = orig_pte = be64_to_cpu(hpte[0]);
 -	pte_r = be64_to_cpu(hpte[1]);
 -	if (cpu_has_feature(CPU_FTR_ARCH_300)) {
 -		pte = hpte_new_to_old_v(pte, pte_r);
 -		pte_r = hpte_new_to_old_r(pte_r);
 -	}
 +	pte = be64_to_cpu(hpte[0]);
  	if ((pte & (HPTE_V_ABSENT | HPTE_V_VALID)) == 0 ||
  	    ((flags & H_AVPN) && (pte & ~0x7fUL) != avpn) ||
  	    ((flags & H_ANDCOND) && (pte & avpn) != 0)) {
@@@ -607,18 -653,22 +613,24 @@@ long kvmppc_h_protect(struct kvm_vcpu *
  	__be64 *hpte;
  	struct revmap_entry *rev;
  	unsigned long v, r, rb, mask, bits;
 -	u64 pte_v, pte_r;
 +	u64 pte;
  
++<<<<<<< HEAD
 +	if (pte_index >= kvm->arch.hpt_npte)
++=======
+ 	if (kvm_is_radix(kvm))
+ 		return H_FUNCTION;
+ 	if (pte_index >= kvm->arch.hpt.npte)
++>>>>>>> 3f9d4f5a5f35 (KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure)
  		return H_PARAMETER;
  
- 	hpte = (__be64 *)(kvm->arch.hpt_virt + (pte_index << 4));
+ 	hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
  	while (!try_lock_hpte(hpte, HPTE_V_HVLOCK))
  		cpu_relax();
 -	v = pte_v = be64_to_cpu(hpte[0]);
 -	if (cpu_has_feature(CPU_FTR_ARCH_300))
 -		v = hpte_new_to_old_v(v, be64_to_cpu(hpte[1]));
 -	if ((v & (HPTE_V_ABSENT | HPTE_V_VALID)) == 0 ||
 -	    ((flags & H_AVPN) && (v & ~0x7fUL) != avpn)) {
 -		__unlock_hpte(hpte, pte_v);
 +	pte = be64_to_cpu(hpte[0]);
 +	if ((pte & (HPTE_V_ABSENT | HPTE_V_VALID)) == 0 ||
 +	    ((flags & H_AVPN) && (pte & ~0x7fUL) != avpn)) {
 +		__unlock_hpte(hpte, pte);
  		return H_NOT_FOUND;
  	}
  
@@@ -672,17 -726,23 +684,23 @@@ long kvmppc_h_read(struct kvm_vcpu *vcp
  	int i, n = 1;
  	struct revmap_entry *rev = NULL;
  
++<<<<<<< HEAD
 +	if (pte_index >= kvm->arch.hpt_npte)
++=======
+ 	if (kvm_is_radix(kvm))
+ 		return H_FUNCTION;
+ 	if (pte_index >= kvm->arch.hpt.npte)
++>>>>>>> 3f9d4f5a5f35 (KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure)
  		return H_PARAMETER;
  	if (flags & H_READ_4) {
  		pte_index &= ~3;
  		n = 4;
  	}
- 	rev = real_vmalloc_addr(&kvm->arch.revmap[pte_index]);
+ 	rev = real_vmalloc_addr(&kvm->arch.hpt.rev[pte_index]);
  	for (i = 0; i < n; ++i, ++pte_index) {
- 		hpte = (__be64 *)(kvm->arch.hpt_virt + (pte_index << 4));
+ 		hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
  		v = be64_to_cpu(hpte[0]) & ~HPTE_V_HVLOCK;
  		r = be64_to_cpu(hpte[1]);
 -		if (cpu_has_feature(CPU_FTR_ARCH_300)) {
 -			v = hpte_new_to_old_v(v, r);
 -			r = hpte_new_to_old_r(r);
 -		}
  		if (v & HPTE_V_ABSENT) {
  			v &= ~HPTE_V_ABSENT;
  			v |= HPTE_V_VALID;
@@@ -707,11 -767,13 +725,17 @@@ long kvmppc_h_clear_ref(struct kvm_vcp
  	unsigned long *rmap;
  	long ret = H_NOT_FOUND;
  
++<<<<<<< HEAD
 +	if (pte_index >= kvm->arch.hpt_npte)
++=======
+ 	if (kvm_is_radix(kvm))
+ 		return H_FUNCTION;
+ 	if (pte_index >= kvm->arch.hpt.npte)
++>>>>>>> 3f9d4f5a5f35 (KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure)
  		return H_PARAMETER;
  
- 	rev = real_vmalloc_addr(&kvm->arch.revmap[pte_index]);
- 	hpte = (__be64 *)(kvm->arch.hpt_virt + (pte_index << 4));
+ 	rev = real_vmalloc_addr(&kvm->arch.hpt.rev[pte_index]);
+ 	hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
  	while (!try_lock_hpte(hpte, HPTE_V_HVLOCK))
  		cpu_relax();
  	v = be64_to_cpu(hpte[0]);
@@@ -753,11 -815,13 +777,17 @@@ long kvmppc_h_clear_mod(struct kvm_vcp
  	unsigned long *rmap;
  	long ret = H_NOT_FOUND;
  
++<<<<<<< HEAD
 +	if (pte_index >= kvm->arch.hpt_npte)
++=======
+ 	if (kvm_is_radix(kvm))
+ 		return H_FUNCTION;
+ 	if (pte_index >= kvm->arch.hpt.npte)
++>>>>>>> 3f9d4f5a5f35 (KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure)
  		return H_PARAMETER;
  
- 	rev = real_vmalloc_addr(&kvm->arch.revmap[pte_index]);
- 	hpte = (__be64 *)(kvm->arch.hpt_virt + (pte_index << 4));
+ 	rev = real_vmalloc_addr(&kvm->arch.hpt.rev[pte_index]);
+ 	hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
  	while (!try_lock_hpte(hpte, HPTE_V_HVLOCK))
  		cpu_relax();
  	v = be64_to_cpu(hpte[0]);
@@@ -934,22 -1047,37 +964,49 @@@ long kvmppc_hpte_hv_fault(struct kvm_vc
  
  	/* For protection fault, expect to find a valid HPTE */
  	valid = HPTE_V_VALID;
 -	if (status & DSISR_NOHPTE) {
 +	if (status & DSISR_NOHPTE)
  		valid |= HPTE_V_ABSENT;
++<<<<<<< HEAD
++=======
+ 		mmio_update = atomic64_read(&kvm->arch.mmio_update);
+ 		cache_entry = mmio_cache_search(vcpu, addr, slb_v, mmio_update);
+ 	}
+ 	if (cache_entry) {
+ 		index = cache_entry->pte_index;
+ 		v = cache_entry->hpte_v;
+ 		r = cache_entry->hpte_r;
+ 		gr = cache_entry->rpte;
+ 	} else {
+ 		index = kvmppc_hv_find_lock_hpte(kvm, addr, slb_v, valid);
+ 		if (index < 0) {
+ 			if (status & DSISR_NOHPTE)
+ 				return status;	/* there really was no HPTE */
+ 			return 0;	/* for prot fault, HPTE disappeared */
+ 		}
+ 		hpte = (__be64 *)(kvm->arch.hpt.virt + (index << 4));
+ 		v = orig_v = be64_to_cpu(hpte[0]) & ~HPTE_V_HVLOCK;
+ 		r = be64_to_cpu(hpte[1]);
+ 		if (cpu_has_feature(CPU_FTR_ARCH_300)) {
+ 			v = hpte_new_to_old_v(v, r);
+ 			r = hpte_new_to_old_r(r);
+ 		}
+ 		rev = real_vmalloc_addr(&kvm->arch.hpt.rev[index]);
+ 		gr = rev->guest_rpte;
++>>>>>>> 3f9d4f5a5f35 (KVM: PPC: Book3S HV: Gather HPT related variables into sub-structure)
  
 -		unlock_hpte(hpte, orig_v);
 +	index = kvmppc_hv_find_lock_hpte(kvm, addr, slb_v, valid);
 +	if (index < 0) {
 +		if (status & DSISR_NOHPTE)
 +			return status;	/* there really was no HPTE */
 +		return 0;		/* for prot fault, HPTE disappeared */
  	}
 +	hpte = (__be64 *)(kvm->arch.hpt_virt + (index << 4));
 +	v = be64_to_cpu(hpte[0]) & ~HPTE_V_HVLOCK;
 +	r = be64_to_cpu(hpte[1]);
 +	rev = real_vmalloc_addr(&kvm->arch.revmap[index]);
 +	gr = rev->guest_rpte;
 +
 +	unlock_hpte(hpte, v);
  
  	/* For not found, if the HPTE is valid by now, retry the instruction */
  	if ((status & DSISR_NOHPTE) && (v & HPTE_V_VALID))
* Unmerged path arch/powerpc/include/asm/kvm_host.h
* Unmerged path arch/powerpc/kvm/book3s_64_mmu_hv.c
diff --git a/arch/powerpc/kvm/book3s_hv.c b/arch/powerpc/kvm/book3s_hv.c
index 92357b82799a..5a5f6eac2d7a 100644
--- a/arch/powerpc/kvm/book3s_hv.c
+++ b/arch/powerpc/kvm/book3s_hv.c
@@ -3017,7 +3017,7 @@ static int kvmppc_hv_setup_htab_rma(struct kvm_vcpu *vcpu)
 		goto out;	/* another vcpu beat us to it */
 
 	/* Allocate hashed page table (if not done already) and reset it */
-	if (!kvm->arch.hpt_virt) {
+	if (!kvm->arch.hpt.virt) {
 		err = kvmppc_alloc_hpt(kvm, NULL);
 		if (err) {
 			pr_err("KVM: Couldn't alloc HPT\n");
* Unmerged path arch/powerpc/kvm/book3s_hv_rm_mmu.c
