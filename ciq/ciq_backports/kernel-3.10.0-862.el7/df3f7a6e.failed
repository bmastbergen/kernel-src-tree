iommu/amd: Use is_attach_deferred call-back

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [iommu] amd: Use is_attach_deferred call-back (Jerry Snitselaar) [1062729]
Rebuild_FUZZ: 92.50%
commit-author Baoquan He <bhe@redhat.com>
commit df3f7a6e8e855e4ff533508807cd7c3723faa51f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/df3f7a6e.failed

Implement call-back is_attach_deferred and use it to defer the
domain attach from iommu driver init to device driver init when
iommu is pre-enabled in kdump kernel.

	Signed-off-by: Baoquan He <bhe@redhat.com>
	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit df3f7a6e8e855e4ff533508807cd7c3723faa51f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/amd_iommu.c
diff --cc drivers/iommu/amd_iommu.c
index e80343c1de99,eebf4590cef9..000000000000
--- a/drivers/iommu/amd_iommu.c
+++ b/drivers/iommu/amd_iommu.c
@@@ -102,6 -120,10 +102,13 @@@ struct iommu_dev_data 
  	bool pri_tlp;			  /* PASID TLB required for
  					     PPR completions */
  	u32 errata;			  /* Bitmap for errata to apply */
++<<<<<<< HEAD
++=======
+ 	bool use_vapic;			  /* Enable device to use vapic mode */
+ 	bool defer_attach;
+ 
+ 	struct ratelimit_state rs;	  /* Ratelimit IOPF messages */
++>>>>>>> df3f7a6e8e85 (iommu/amd: Use is_attach_deferred call-back)
  };
  
  /*
@@@ -3206,7 -3372,27 +3225,31 @@@ static void amd_iommu_put_dm_regions(st
  		kfree(entry);
  }
  
++<<<<<<< HEAD
 +static struct iommu_ops amd_iommu_ops = {
++=======
+ static void amd_iommu_apply_resv_region(struct device *dev,
+ 				      struct iommu_domain *domain,
+ 				      struct iommu_resv_region *region)
+ {
+ 	struct dma_ops_domain *dma_dom = to_dma_ops_domain(to_pdomain(domain));
+ 	unsigned long start, end;
+ 
+ 	start = IOVA_PFN(region->start);
+ 	end   = IOVA_PFN(region->start + region->length);
+ 
+ 	WARN_ON_ONCE(reserve_iova(&dma_dom->iovad, start, end) == NULL);
+ }
+ 
+ static bool amd_iommu_is_attach_deferred(struct iommu_domain *domain,
+ 					 struct device *dev)
+ {
+ 	struct iommu_dev_data *dev_data = dev->archdata.iommu;
+ 	return dev_data->defer_attach;
+ }
+ 
+ const struct iommu_ops amd_iommu_ops = {
++>>>>>>> df3f7a6e8e85 (iommu/amd: Use is_attach_deferred call-back)
  	.capable = amd_iommu_capable,
  	.domain_alloc = amd_iommu_domain_alloc,
  	.domain_free  = amd_iommu_domain_free,
@@@ -3219,8 -3405,10 +3262,15 @@@
  	.add_device = amd_iommu_add_device,
  	.remove_device = amd_iommu_remove_device,
  	.device_group = amd_iommu_device_group,
++<<<<<<< HEAD
 +	.get_dm_regions = amd_iommu_get_dm_regions,
 +	.put_dm_regions = amd_iommu_put_dm_regions,
++=======
+ 	.get_resv_regions = amd_iommu_get_resv_regions,
+ 	.put_resv_regions = amd_iommu_put_resv_regions,
+ 	.apply_resv_region = amd_iommu_apply_resv_region,
+ 	.is_attach_deferred = amd_iommu_is_attach_deferred,
++>>>>>>> df3f7a6e8e85 (iommu/amd: Use is_attach_deferred call-back)
  	.pgsize_bitmap	= AMD_IOMMU_PGSIZES,
  };
  
* Unmerged path drivers/iommu/amd_iommu.c
