mlxsw: spectrum_router: Add support for nexthop group consolidation for IPv6

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Arkadi Sharshevsky <arkadis@mellanox.com>
commit e6f3b379c0c599a870bc0e7d8a0cbb0b316502f5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/e6f3b379.failed

Due to limited ASIC resources the maximum number of routes is limited by
the nexthop resource. In order to improve the routing scale nexthop
consolidation should be performed.

This patch adds support for IPv6 neighbor consolidation. The hash value
is calculated based on the nexthop set, by performing bitwise xor on the
ifindexs of the nexthops, in a similar way to IPv4's kernel implementation.
In case of collision a full match is performed between the sets which
include address and ifindex comparison.

Non gateway nexthop groups are not inserted to the hash table due to
lack of nexthop device (ifindex).

	Signed-off-by: Arkadi Sharshevsky <arkadis@mellanox.com>
	Reviewed-by: Ido Schimmel <idosch@mellanox.com>
	Signed-off-by: Jiri Pirko <jiri@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit e6f3b379c0c599a870bc0e7d8a0cbb0b316502f5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c
diff --cc drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c
index 4a30fec5c668,16676fffbf70..000000000000
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c
@@@ -1171,7 -1508,9 +1171,13 @@@ struct mlxsw_sp_nexthop 
  						*/
  	struct rhash_head ht_node;
  	struct mlxsw_sp_nexthop_key key;
++<<<<<<< HEAD
 +	struct mlxsw_sp_rif *r;
++=======
+ 	unsigned char gw_addr[sizeof(struct in6_addr)];
+ 	int ifindex;
+ 	struct mlxsw_sp_rif *rif;
++>>>>>>> e6f3b379c0c5 (mlxsw: spectrum_router: Add support for nexthop group consolidation for IPv6)
  	u8 should_offload:1, /* set indicates this neigh is connected and
  			      * should be put to KVD linear area of this group.
  			      */
@@@ -1198,19 -1534,158 +1204,164 @@@ struct mlxsw_sp_nexthop_group 
  	u16 ecmp_size;
  	u16 count;
  	struct mlxsw_sp_nexthop nexthops[0];
 -#define nh_rif	nexthops[0].rif
 +#define nh_rif	nexthops[0].r
  };
  
++<<<<<<< HEAD
++=======
+ static struct fib_info *
+ mlxsw_sp_nexthop4_group_fi(const struct mlxsw_sp_nexthop_group *nh_grp)
+ {
+ 	return nh_grp->priv;
+ }
+ 
+ struct mlxsw_sp_nexthop_group_cmp_arg {
+ 	enum mlxsw_sp_l3proto proto;
+ 	union {
+ 		struct fib_info *fi;
+ 		struct mlxsw_sp_fib6_entry *fib6_entry;
+ 	};
+ };
+ 
+ static bool
+ mlxsw_sp_nexthop6_group_has_nexthop(const struct mlxsw_sp_nexthop_group *nh_grp,
+ 				    const struct in6_addr *gw, int ifindex)
+ {
+ 	int i;
+ 
+ 	for (i = 0; i < nh_grp->count; i++) {
+ 		const struct mlxsw_sp_nexthop *nh;
+ 
+ 		nh = &nh_grp->nexthops[i];
+ 		if (nh->ifindex == ifindex &&
+ 		    ipv6_addr_equal(gw, (struct in6_addr *) nh->gw_addr))
+ 			return true;
+ 	}
+ 
+ 	return false;
+ }
+ 
+ static bool
+ mlxsw_sp_nexthop6_group_cmp(const struct mlxsw_sp_nexthop_group *nh_grp,
+ 			    const struct mlxsw_sp_fib6_entry *fib6_entry)
+ {
+ 	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
+ 
+ 	if (nh_grp->count != fib6_entry->nrt6)
+ 		return false;
+ 
+ 	list_for_each_entry(mlxsw_sp_rt6, &fib6_entry->rt6_list, list) {
+ 		struct in6_addr *gw;
+ 		int ifindex;
+ 
+ 		ifindex = mlxsw_sp_rt6->rt->dst.dev->ifindex;
+ 		gw = &mlxsw_sp_rt6->rt->rt6i_gateway;
+ 		if (!mlxsw_sp_nexthop6_group_has_nexthop(nh_grp, gw, ifindex))
+ 			return false;
+ 	}
+ 
+ 	return true;
+ }
+ 
+ static int
+ mlxsw_sp_nexthop_group_cmp(struct rhashtable_compare_arg *arg, const void *ptr)
+ {
+ 	const struct mlxsw_sp_nexthop_group_cmp_arg *cmp_arg = arg->key;
+ 	const struct mlxsw_sp_nexthop_group *nh_grp = ptr;
+ 
+ 	switch (cmp_arg->proto) {
+ 	case MLXSW_SP_L3_PROTO_IPV4:
+ 		return cmp_arg->fi != mlxsw_sp_nexthop4_group_fi(nh_grp);
+ 	case MLXSW_SP_L3_PROTO_IPV6:
+ 		return !mlxsw_sp_nexthop6_group_cmp(nh_grp,
+ 						    cmp_arg->fib6_entry);
+ 	default:
+ 		WARN_ON(1);
+ 		return 1;
+ 	}
+ }
+ 
+ static int
+ mlxsw_sp_nexthop_group_type(const struct mlxsw_sp_nexthop_group *nh_grp)
+ {
+ 	return nh_grp->neigh_tbl->family;
+ }
+ 
+ static u32 mlxsw_sp_nexthop_group_hash_obj(const void *data, u32 len, u32 seed)
+ {
+ 	const struct mlxsw_sp_nexthop_group *nh_grp = data;
+ 	const struct mlxsw_sp_nexthop *nh;
+ 	struct fib_info *fi;
+ 	unsigned int val;
+ 	int i;
+ 
+ 	switch (mlxsw_sp_nexthop_group_type(nh_grp)) {
+ 	case AF_INET:
+ 		fi = mlxsw_sp_nexthop4_group_fi(nh_grp);
+ 		return jhash(&fi, sizeof(fi), seed);
+ 	case AF_INET6:
+ 		val = nh_grp->count;
+ 		for (i = 0; i < nh_grp->count; i++) {
+ 			nh = &nh_grp->nexthops[i];
+ 			val ^= nh->ifindex;
+ 		}
+ 		return jhash(&val, sizeof(val), seed);
+ 	default:
+ 		WARN_ON(1);
+ 		return 0;
+ 	}
+ }
+ 
+ static u32
+ mlxsw_sp_nexthop6_group_hash(struct mlxsw_sp_fib6_entry *fib6_entry, u32 seed)
+ {
+ 	unsigned int val = fib6_entry->nrt6;
+ 	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
+ 	struct net_device *dev;
+ 
+ 	list_for_each_entry(mlxsw_sp_rt6, &fib6_entry->rt6_list, list) {
+ 		dev = mlxsw_sp_rt6->rt->dst.dev;
+ 		val ^= dev->ifindex;
+ 	}
+ 
+ 	return jhash(&val, sizeof(val), seed);
+ }
+ 
+ static u32
+ mlxsw_sp_nexthop_group_hash(const void *data, u32 len, u32 seed)
+ {
+ 	const struct mlxsw_sp_nexthop_group_cmp_arg *cmp_arg = data;
+ 
+ 	switch (cmp_arg->proto) {
+ 	case MLXSW_SP_L3_PROTO_IPV4:
+ 		return jhash(&cmp_arg->fi, sizeof(cmp_arg->fi), seed);
+ 	case MLXSW_SP_L3_PROTO_IPV6:
+ 		return mlxsw_sp_nexthop6_group_hash(cmp_arg->fib6_entry, seed);
+ 	default:
+ 		WARN_ON(1);
+ 		return 0;
+ 	}
+ }
+ 
++>>>>>>> e6f3b379c0c5 (mlxsw: spectrum_router: Add support for nexthop group consolidation for IPv6)
  static const struct rhashtable_params mlxsw_sp_nexthop_group_ht_params = {
 +	.key_offset = offsetof(struct mlxsw_sp_nexthop_group, key),
  	.head_offset = offsetof(struct mlxsw_sp_nexthop_group, ht_node),
 -	.hashfn	     = mlxsw_sp_nexthop_group_hash,
 -	.obj_hashfn  = mlxsw_sp_nexthop_group_hash_obj,
 -	.obj_cmpfn   = mlxsw_sp_nexthop_group_cmp,
 +	.key_len = sizeof(struct mlxsw_sp_nexthop_group_key),
  };
  
  static int mlxsw_sp_nexthop_group_insert(struct mlxsw_sp *mlxsw_sp,
  					 struct mlxsw_sp_nexthop_group *nh_grp)
  {
++<<<<<<< HEAD
 +	return rhashtable_insert_fast(&mlxsw_sp->router.nexthop_group_ht,
++=======
+ 	if (mlxsw_sp_nexthop_group_type(nh_grp) == AF_INET6 &&
+ 	    !nh_grp->gateway)
+ 		return 0;
+ 
+ 	return rhashtable_insert_fast(&mlxsw_sp->router->nexthop_group_ht,
++>>>>>>> e6f3b379c0c5 (mlxsw: spectrum_router: Add support for nexthop group consolidation for IPv6)
  				      &nh_grp->ht_node,
  				      mlxsw_sp_nexthop_group_ht_params);
  }
@@@ -1218,16 -1693,38 +1369,46 @@@
  static void mlxsw_sp_nexthop_group_remove(struct mlxsw_sp *mlxsw_sp,
  					  struct mlxsw_sp_nexthop_group *nh_grp)
  {
++<<<<<<< HEAD
 +	rhashtable_remove_fast(&mlxsw_sp->router.nexthop_group_ht,
++=======
+ 	if (mlxsw_sp_nexthop_group_type(nh_grp) == AF_INET6 &&
+ 	    !nh_grp->gateway)
+ 		return;
+ 
+ 	rhashtable_remove_fast(&mlxsw_sp->router->nexthop_group_ht,
++>>>>>>> e6f3b379c0c5 (mlxsw: spectrum_router: Add support for nexthop group consolidation for IPv6)
  			       &nh_grp->ht_node,
  			       mlxsw_sp_nexthop_group_ht_params);
  }
  
  static struct mlxsw_sp_nexthop_group *
 -mlxsw_sp_nexthop4_group_lookup(struct mlxsw_sp *mlxsw_sp,
 -			       struct fib_info *fi)
 +mlxsw_sp_nexthop_group_lookup(struct mlxsw_sp *mlxsw_sp,
 +			      struct mlxsw_sp_nexthop_group_key key)
  {
++<<<<<<< HEAD
 +	return rhashtable_lookup_fast(&mlxsw_sp->router.nexthop_group_ht, &key,
++=======
+ 	struct mlxsw_sp_nexthop_group_cmp_arg cmp_arg;
+ 
+ 	cmp_arg.proto = MLXSW_SP_L3_PROTO_IPV4;
+ 	cmp_arg.fi = fi;
+ 	return rhashtable_lookup_fast(&mlxsw_sp->router->nexthop_group_ht,
+ 				      &cmp_arg,
++>>>>>>> e6f3b379c0c5 (mlxsw: spectrum_router: Add support for nexthop group consolidation for IPv6)
+ 				      mlxsw_sp_nexthop_group_ht_params);
+ }
+ 
+ static struct mlxsw_sp_nexthop_group *
+ mlxsw_sp_nexthop6_group_lookup(struct mlxsw_sp *mlxsw_sp,
+ 			       struct mlxsw_sp_fib6_entry *fib6_entry)
+ {
+ 	struct mlxsw_sp_nexthop_group_cmp_arg cmp_arg;
+ 
+ 	cmp_arg.proto = MLXSW_SP_L3_PROTO_IPV6;
+ 	cmp_arg.fib6_entry = fib6_entry;
+ 	return rhashtable_lookup_fast(&mlxsw_sp->router->nexthop_group_ht,
+ 				      &cmp_arg,
  				      mlxsw_sp_nexthop_group_ht_params);
  }
  
@@@ -2599,19 -3174,672 +2780,409 @@@ err_fib4_entry_create
  static void mlxsw_sp_router_fib4_del(struct mlxsw_sp *mlxsw_sp,
  				     struct fib_entry_notifier_info *fen_info)
  {
++<<<<<<< HEAD
++=======
+ 	struct mlxsw_sp_fib4_entry *fib4_entry;
+ 	struct mlxsw_sp_fib_node *fib_node;
+ 
+ 	if (mlxsw_sp->router->aborted)
+ 		return;
+ 
+ 	fib4_entry = mlxsw_sp_fib4_entry_lookup(mlxsw_sp, fen_info);
+ 	if (WARN_ON(!fib4_entry))
+ 		return;
+ 	fib_node = fib4_entry->common.fib_node;
+ 
+ 	mlxsw_sp_fib4_node_entry_unlink(mlxsw_sp, fib4_entry);
+ 	mlxsw_sp_fib4_entry_destroy(mlxsw_sp, fib4_entry);
+ 	mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
+ }
+ 
+ static bool mlxsw_sp_fib6_rt_should_ignore(const struct rt6_info *rt)
+ {
+ 	/* Packets with link-local destination IP arriving to the router
+ 	 * are trapped to the CPU, so no need to program specific routes
+ 	 * for them.
+ 	 */
+ 	if (ipv6_addr_type(&rt->rt6i_dst.addr) & IPV6_ADDR_LINKLOCAL)
+ 		return true;
+ 
+ 	/* Multicast routes aren't supported, so ignore them. Neighbour
+ 	 * Discovery packets are specifically trapped.
+ 	 */
+ 	if (ipv6_addr_type(&rt->rt6i_dst.addr) & IPV6_ADDR_MULTICAST)
+ 		return true;
+ 
+ 	/* Cloned routes are irrelevant in the forwarding path. */
+ 	if (rt->rt6i_flags & RTF_CACHE)
+ 		return true;
+ 
+ 	return false;
+ }
+ 
+ static struct mlxsw_sp_rt6 *mlxsw_sp_rt6_create(struct rt6_info *rt)
+ {
+ 	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
+ 
+ 	mlxsw_sp_rt6 = kzalloc(sizeof(*mlxsw_sp_rt6), GFP_KERNEL);
+ 	if (!mlxsw_sp_rt6)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	/* In case of route replace, replaced route is deleted with
+ 	 * no notification. Take reference to prevent accessing freed
+ 	 * memory.
+ 	 */
+ 	mlxsw_sp_rt6->rt = rt;
+ 	rt6_hold(rt);
+ 
+ 	return mlxsw_sp_rt6;
+ }
+ 
+ #if IS_ENABLED(CONFIG_IPV6)
+ static void mlxsw_sp_rt6_release(struct rt6_info *rt)
+ {
+ 	rt6_release(rt);
+ }
+ #else
+ static void mlxsw_sp_rt6_release(struct rt6_info *rt)
+ {
+ }
+ #endif
+ 
+ static void mlxsw_sp_rt6_destroy(struct mlxsw_sp_rt6 *mlxsw_sp_rt6)
+ {
+ 	mlxsw_sp_rt6_release(mlxsw_sp_rt6->rt);
+ 	kfree(mlxsw_sp_rt6);
+ }
+ 
+ static bool mlxsw_sp_fib6_rt_can_mp(const struct rt6_info *rt)
+ {
+ 	/* RTF_CACHE routes are ignored */
+ 	return (rt->rt6i_flags & (RTF_GATEWAY | RTF_ADDRCONF)) == RTF_GATEWAY;
+ }
+ 
+ static struct rt6_info *
+ mlxsw_sp_fib6_entry_rt(const struct mlxsw_sp_fib6_entry *fib6_entry)
+ {
+ 	return list_first_entry(&fib6_entry->rt6_list, struct mlxsw_sp_rt6,
+ 				list)->rt;
+ }
+ 
+ static struct mlxsw_sp_fib6_entry *
+ mlxsw_sp_fib6_node_mp_entry_find(const struct mlxsw_sp_fib_node *fib_node,
+ 				 const struct rt6_info *nrt, bool replace)
+ {
+ 	struct mlxsw_sp_fib6_entry *fib6_entry;
+ 
+ 	if (!mlxsw_sp_fib6_rt_can_mp(nrt) || replace)
+ 		return NULL;
+ 
+ 	list_for_each_entry(fib6_entry, &fib_node->entry_list, common.list) {
+ 		struct rt6_info *rt = mlxsw_sp_fib6_entry_rt(fib6_entry);
+ 
+ 		/* RT6_TABLE_LOCAL and RT6_TABLE_MAIN share the same
+ 		 * virtual router.
+ 		 */
+ 		if (rt->rt6i_table->tb6_id > nrt->rt6i_table->tb6_id)
+ 			continue;
+ 		if (rt->rt6i_table->tb6_id != nrt->rt6i_table->tb6_id)
+ 			break;
+ 		if (rt->rt6i_metric < nrt->rt6i_metric)
+ 			continue;
+ 		if (rt->rt6i_metric == nrt->rt6i_metric &&
+ 		    mlxsw_sp_fib6_rt_can_mp(rt))
+ 			return fib6_entry;
+ 		if (rt->rt6i_metric > nrt->rt6i_metric)
+ 			break;
+ 	}
+ 
+ 	return NULL;
+ }
+ 
+ static struct mlxsw_sp_rt6 *
+ mlxsw_sp_fib6_entry_rt_find(const struct mlxsw_sp_fib6_entry *fib6_entry,
+ 			    const struct rt6_info *rt)
+ {
+ 	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
+ 
+ 	list_for_each_entry(mlxsw_sp_rt6, &fib6_entry->rt6_list, list) {
+ 		if (mlxsw_sp_rt6->rt == rt)
+ 			return mlxsw_sp_rt6;
+ 	}
+ 
+ 	return NULL;
+ }
+ 
+ static int mlxsw_sp_nexthop6_init(struct mlxsw_sp *mlxsw_sp,
+ 				  struct mlxsw_sp_nexthop_group *nh_grp,
+ 				  struct mlxsw_sp_nexthop *nh,
+ 				  const struct rt6_info *rt)
+ {
+ 	struct net_device *dev = rt->dst.dev;
+ 	struct mlxsw_sp_rif *rif;
+ 	int err;
+ 
+ 	nh->nh_grp = nh_grp;
+ 	memcpy(&nh->gw_addr, &rt->rt6i_gateway, sizeof(nh->gw_addr));
+ 
+ 	if (!dev)
+ 		return 0;
+ 	nh->ifindex = dev->ifindex;
+ 
+ 	rif = mlxsw_sp_rif_find_by_dev(mlxsw_sp, dev);
+ 	if (!rif)
+ 		return 0;
+ 	mlxsw_sp_nexthop_rif_init(nh, rif);
+ 
+ 	err = mlxsw_sp_nexthop_neigh_init(mlxsw_sp, nh);
+ 	if (err)
+ 		goto err_nexthop_neigh_init;
+ 
+ 	return 0;
+ 
+ err_nexthop_neigh_init:
+ 	mlxsw_sp_nexthop_rif_fini(nh);
+ 	return err;
+ }
+ 
+ static void mlxsw_sp_nexthop6_fini(struct mlxsw_sp *mlxsw_sp,
+ 				   struct mlxsw_sp_nexthop *nh)
+ {
+ 	mlxsw_sp_nexthop_neigh_fini(mlxsw_sp, nh);
+ 	mlxsw_sp_nexthop_rif_fini(nh);
+ }
+ 
+ static struct mlxsw_sp_nexthop_group *
+ mlxsw_sp_nexthop6_group_create(struct mlxsw_sp *mlxsw_sp,
+ 			       struct mlxsw_sp_fib6_entry *fib6_entry)
+ {
+ 	struct mlxsw_sp_nexthop_group *nh_grp;
+ 	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
+ 	struct mlxsw_sp_nexthop *nh;
+ 	size_t alloc_size;
+ 	int i = 0;
+ 	int err;
+ 
+ 	alloc_size = sizeof(*nh_grp) +
+ 		     fib6_entry->nrt6 * sizeof(struct mlxsw_sp_nexthop);
+ 	nh_grp = kzalloc(alloc_size, GFP_KERNEL);
+ 	if (!nh_grp)
+ 		return ERR_PTR(-ENOMEM);
+ 	INIT_LIST_HEAD(&nh_grp->fib_list);
+ #if IS_ENABLED(CONFIG_IPV6)
+ 	nh_grp->neigh_tbl = &nd_tbl;
+ #endif
+ 	mlxsw_sp_rt6 = list_first_entry(&fib6_entry->rt6_list,
+ 					struct mlxsw_sp_rt6, list);
+ 	nh_grp->gateway = !!(mlxsw_sp_rt6->rt->rt6i_flags & RTF_GATEWAY);
+ 	nh_grp->count = fib6_entry->nrt6;
+ 	for (i = 0; i < nh_grp->count; i++) {
+ 		struct rt6_info *rt = mlxsw_sp_rt6->rt;
+ 
+ 		nh = &nh_grp->nexthops[i];
+ 		err = mlxsw_sp_nexthop6_init(mlxsw_sp, nh_grp, nh, rt);
+ 		if (err)
+ 			goto err_nexthop6_init;
+ 		mlxsw_sp_rt6 = list_next_entry(mlxsw_sp_rt6, list);
+ 	}
+ 
+ 	err = mlxsw_sp_nexthop_group_insert(mlxsw_sp, nh_grp);
+ 	if (err)
+ 		goto err_nexthop_group_insert;
+ 
+ 	mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh_grp);
+ 	return nh_grp;
+ 
+ err_nexthop_group_insert:
+ err_nexthop6_init:
+ 	for (i--; i >= 0; i--) {
+ 		nh = &nh_grp->nexthops[i];
+ 		mlxsw_sp_nexthop6_fini(mlxsw_sp, nh);
+ 	}
+ 	kfree(nh_grp);
+ 	return ERR_PTR(err);
+ }
+ 
+ static void
+ mlxsw_sp_nexthop6_group_destroy(struct mlxsw_sp *mlxsw_sp,
+ 				struct mlxsw_sp_nexthop_group *nh_grp)
+ {
+ 	struct mlxsw_sp_nexthop *nh;
+ 	int i = nh_grp->count;
+ 
+ 	mlxsw_sp_nexthop_group_remove(mlxsw_sp, nh_grp);
+ 	for (i--; i >= 0; i--) {
+ 		nh = &nh_grp->nexthops[i];
+ 		mlxsw_sp_nexthop6_fini(mlxsw_sp, nh);
+ 	}
+ 	mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh_grp);
+ 	WARN_ON(nh_grp->adj_index_valid);
+ 	kfree(nh_grp);
+ }
+ 
+ static int mlxsw_sp_nexthop6_group_get(struct mlxsw_sp *mlxsw_sp,
+ 				       struct mlxsw_sp_fib6_entry *fib6_entry)
+ {
+ 	struct mlxsw_sp_nexthop_group *nh_grp;
+ 
+ 	nh_grp = mlxsw_sp_nexthop6_group_lookup(mlxsw_sp, fib6_entry);
+ 	if (!nh_grp) {
+ 		nh_grp = mlxsw_sp_nexthop6_group_create(mlxsw_sp, fib6_entry);
+ 		if (IS_ERR(nh_grp))
+ 			return PTR_ERR(nh_grp);
+ 	}
+ 
+ 	list_add_tail(&fib6_entry->common.nexthop_group_node,
+ 		      &nh_grp->fib_list);
+ 	fib6_entry->common.nh_group = nh_grp;
+ 
+ 	return 0;
+ }
+ 
+ static void mlxsw_sp_nexthop6_group_put(struct mlxsw_sp *mlxsw_sp,
+ 					struct mlxsw_sp_fib_entry *fib_entry)
+ {
+ 	struct mlxsw_sp_nexthop_group *nh_grp = fib_entry->nh_group;
+ 
+ 	list_del(&fib_entry->nexthop_group_node);
+ 	if (!list_empty(&nh_grp->fib_list))
+ 		return;
+ 	mlxsw_sp_nexthop6_group_destroy(mlxsw_sp, nh_grp);
+ }
+ 
+ static int
+ mlxsw_sp_nexthop6_group_update(struct mlxsw_sp *mlxsw_sp,
+ 			       struct mlxsw_sp_fib6_entry *fib6_entry)
+ {
+ 	struct mlxsw_sp_nexthop_group *old_nh_grp = fib6_entry->common.nh_group;
+ 	int err;
+ 
+ 	fib6_entry->common.nh_group = NULL;
+ 	list_del(&fib6_entry->common.nexthop_group_node);
+ 
+ 	err = mlxsw_sp_nexthop6_group_get(mlxsw_sp, fib6_entry);
+ 	if (err)
+ 		goto err_nexthop6_group_get;
+ 
+ 	/* In case this entry is offloaded, then the adjacency index
+ 	 * currently associated with it in the device's table is that
+ 	 * of the old group. Start using the new one instead.
+ 	 */
+ 	err = mlxsw_sp_fib_node_entry_add(mlxsw_sp, &fib6_entry->common);
+ 	if (err)
+ 		goto err_fib_node_entry_add;
+ 
+ 	if (list_empty(&old_nh_grp->fib_list))
+ 		mlxsw_sp_nexthop6_group_destroy(mlxsw_sp, old_nh_grp);
+ 
+ 	return 0;
+ 
+ err_fib_node_entry_add:
+ 	mlxsw_sp_nexthop6_group_put(mlxsw_sp, &fib6_entry->common);
+ err_nexthop6_group_get:
+ 	list_add_tail(&fib6_entry->common.nexthop_group_node,
+ 		      &old_nh_grp->fib_list);
+ 	fib6_entry->common.nh_group = old_nh_grp;
+ 	return err;
+ }
+ 
+ static int
+ mlxsw_sp_fib6_entry_nexthop_add(struct mlxsw_sp *mlxsw_sp,
+ 				struct mlxsw_sp_fib6_entry *fib6_entry,
+ 				struct rt6_info *rt)
+ {
+ 	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
+ 	int err;
+ 
+ 	mlxsw_sp_rt6 = mlxsw_sp_rt6_create(rt);
+ 	if (IS_ERR(mlxsw_sp_rt6))
+ 		return PTR_ERR(mlxsw_sp_rt6);
+ 
+ 	list_add_tail(&mlxsw_sp_rt6->list, &fib6_entry->rt6_list);
+ 	fib6_entry->nrt6++;
+ 
+ 	err = mlxsw_sp_nexthop6_group_update(mlxsw_sp, fib6_entry);
+ 	if (err)
+ 		goto err_nexthop6_group_update;
+ 
+ 	return 0;
+ 
+ err_nexthop6_group_update:
+ 	fib6_entry->nrt6--;
+ 	list_del(&mlxsw_sp_rt6->list);
+ 	mlxsw_sp_rt6_destroy(mlxsw_sp_rt6);
+ 	return err;
+ }
+ 
+ static void
+ mlxsw_sp_fib6_entry_nexthop_del(struct mlxsw_sp *mlxsw_sp,
+ 				struct mlxsw_sp_fib6_entry *fib6_entry,
+ 				struct rt6_info *rt)
+ {
+ 	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
+ 
+ 	mlxsw_sp_rt6 = mlxsw_sp_fib6_entry_rt_find(fib6_entry, rt);
+ 	if (WARN_ON(!mlxsw_sp_rt6))
+ 		return;
+ 
+ 	fib6_entry->nrt6--;
+ 	list_del(&mlxsw_sp_rt6->list);
+ 	mlxsw_sp_nexthop6_group_update(mlxsw_sp, fib6_entry);
+ 	mlxsw_sp_rt6_destroy(mlxsw_sp_rt6);
+ }
+ 
+ static void mlxsw_sp_fib6_entry_type_set(struct mlxsw_sp_fib_entry *fib_entry,
+ 					 const struct rt6_info *rt)
+ {
+ 	/* Packets hitting RTF_REJECT routes need to be discarded by the
+ 	 * stack. We can rely on their destination device not having a
+ 	 * RIF (it's the loopback device) and can thus use action type
+ 	 * local, which will cause them to be trapped with a lower
+ 	 * priority than packets that need to be locally received.
+ 	 */
+ 	if (rt->rt6i_flags & RTF_LOCAL)
+ 		fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_TRAP;
+ 	else if (rt->rt6i_flags & RTF_REJECT)
+ 		fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_LOCAL;
+ 	else if (rt->rt6i_flags & RTF_GATEWAY)
+ 		fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_REMOTE;
+ 	else
+ 		fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_LOCAL;
+ }
+ 
+ static void
+ mlxsw_sp_fib6_entry_rt_destroy_all(struct mlxsw_sp_fib6_entry *fib6_entry)
+ {
+ 	struct mlxsw_sp_rt6 *mlxsw_sp_rt6, *tmp;
+ 
+ 	list_for_each_entry_safe(mlxsw_sp_rt6, tmp, &fib6_entry->rt6_list,
+ 				 list) {
+ 		fib6_entry->nrt6--;
+ 		list_del(&mlxsw_sp_rt6->list);
+ 		mlxsw_sp_rt6_destroy(mlxsw_sp_rt6);
+ 	}
+ }
+ 
+ static struct mlxsw_sp_fib6_entry *
+ mlxsw_sp_fib6_entry_create(struct mlxsw_sp *mlxsw_sp,
+ 			   struct mlxsw_sp_fib_node *fib_node,
+ 			   struct rt6_info *rt)
+ {
+ 	struct mlxsw_sp_fib6_entry *fib6_entry;
++>>>>>>> e6f3b379c0c5 (mlxsw: spectrum_router: Add support for nexthop group consolidation for IPv6)
  	struct mlxsw_sp_fib_entry *fib_entry;
 -	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
 -	int err;
 -
 -	fib6_entry = kzalloc(sizeof(*fib6_entry), GFP_KERNEL);
 -	if (!fib6_entry)
 -		return ERR_PTR(-ENOMEM);
 -	fib_entry = &fib6_entry->common;
 -
 -	mlxsw_sp_rt6 = mlxsw_sp_rt6_create(rt);
 -	if (IS_ERR(mlxsw_sp_rt6)) {
 -		err = PTR_ERR(mlxsw_sp_rt6);
 -		goto err_rt6_create;
 -	}
 -
 -	mlxsw_sp_fib6_entry_type_set(fib_entry, mlxsw_sp_rt6->rt);
 -
 -	INIT_LIST_HEAD(&fib6_entry->rt6_list);
 -	list_add_tail(&mlxsw_sp_rt6->list, &fib6_entry->rt6_list);
 -	fib6_entry->nrt6 = 1;
 -	err = mlxsw_sp_nexthop6_group_get(mlxsw_sp, fib6_entry);
 -	if (err)
 -		goto err_nexthop6_group_get;
 -
 -	fib_entry->fib_node = fib_node;
 -
 -	return fib6_entry;
 -
 -err_nexthop6_group_get:
 -	list_del(&mlxsw_sp_rt6->list);
 -	mlxsw_sp_rt6_destroy(mlxsw_sp_rt6);
 -err_rt6_create:
 -	kfree(fib6_entry);
 -	return ERR_PTR(err);
 -}
 -
 -static void mlxsw_sp_fib6_entry_destroy(struct mlxsw_sp *mlxsw_sp,
 -					struct mlxsw_sp_fib6_entry *fib6_entry)
 -{
 -	mlxsw_sp_nexthop6_group_put(mlxsw_sp, &fib6_entry->common);
 -	mlxsw_sp_fib6_entry_rt_destroy_all(fib6_entry);
 -	WARN_ON(fib6_entry->nrt6);
 -	kfree(fib6_entry);
 -}
 -
 -static struct mlxsw_sp_fib6_entry *
 -mlxsw_sp_fib6_node_entry_find(const struct mlxsw_sp_fib_node *fib_node,
 -			      const struct rt6_info *nrt, bool replace)
 -{
 -	struct mlxsw_sp_fib6_entry *fib6_entry, *fallback = NULL;
 -
 -	list_for_each_entry(fib6_entry, &fib_node->entry_list, common.list) {
 -		struct rt6_info *rt = mlxsw_sp_fib6_entry_rt(fib6_entry);
 -
 -		if (rt->rt6i_table->tb6_id > nrt->rt6i_table->tb6_id)
 -			continue;
 -		if (rt->rt6i_table->tb6_id != nrt->rt6i_table->tb6_id)
 -			break;
 -		if (replace && rt->rt6i_metric == nrt->rt6i_metric) {
 -			if (mlxsw_sp_fib6_rt_can_mp(rt) ==
 -			    mlxsw_sp_fib6_rt_can_mp(nrt))
 -				return fib6_entry;
 -			if (mlxsw_sp_fib6_rt_can_mp(nrt))
 -				fallback = fallback ?: fib6_entry;
 -		}
 -		if (rt->rt6i_metric > nrt->rt6i_metric)
 -			return fallback ?: fib6_entry;
 -	}
 -
 -	return fallback;
 -}
 -
 -static int
 -mlxsw_sp_fib6_node_list_insert(struct mlxsw_sp_fib6_entry *new6_entry,
 -			       bool replace)
 -{
 -	struct mlxsw_sp_fib_node *fib_node = new6_entry->common.fib_node;
 -	struct rt6_info *nrt = mlxsw_sp_fib6_entry_rt(new6_entry);
 -	struct mlxsw_sp_fib6_entry *fib6_entry;
 -
 -	fib6_entry = mlxsw_sp_fib6_node_entry_find(fib_node, nrt, replace);
 -
 -	if (replace && WARN_ON(!fib6_entry))
 -		return -EINVAL;
 -
 -	if (fib6_entry) {
 -		list_add_tail(&new6_entry->common.list,
 -			      &fib6_entry->common.list);
 -	} else {
 -		struct mlxsw_sp_fib6_entry *last;
 -
 -		list_for_each_entry(last, &fib_node->entry_list, common.list) {
 -			struct rt6_info *rt = mlxsw_sp_fib6_entry_rt(last);
 -
 -			if (nrt->rt6i_table->tb6_id > rt->rt6i_table->tb6_id)
 -				break;
 -			fib6_entry = last;
 -		}
 -
 -		if (fib6_entry)
 -			list_add(&new6_entry->common.list,
 -				 &fib6_entry->common.list);
 -		else
 -			list_add(&new6_entry->common.list,
 -				 &fib_node->entry_list);
 -	}
 -
 -	return 0;
 -}
 -
 -static void
 -mlxsw_sp_fib6_node_list_remove(struct mlxsw_sp_fib6_entry *fib6_entry)
 -{
 -	list_del(&fib6_entry->common.list);
 -}
 -
 -static int mlxsw_sp_fib6_node_entry_link(struct mlxsw_sp *mlxsw_sp,
 -					 struct mlxsw_sp_fib6_entry *fib6_entry,
 -					 bool replace)
 -{
 -	int err;
 -
 -	err = mlxsw_sp_fib6_node_list_insert(fib6_entry, replace);
 -	if (err)
 -		return err;
 -
 -	err = mlxsw_sp_fib_node_entry_add(mlxsw_sp, &fib6_entry->common);
 -	if (err)
 -		goto err_fib_node_entry_add;
 -
 -	return 0;
 -
 -err_fib_node_entry_add:
 -	mlxsw_sp_fib6_node_list_remove(fib6_entry);
 -	return err;
 -}
 -
 -static void
 -mlxsw_sp_fib6_node_entry_unlink(struct mlxsw_sp *mlxsw_sp,
 -				struct mlxsw_sp_fib6_entry *fib6_entry)
 -{
 -	mlxsw_sp_fib_node_entry_del(mlxsw_sp, &fib6_entry->common);
 -	mlxsw_sp_fib6_node_list_remove(fib6_entry);
 -}
 -
 -static struct mlxsw_sp_fib6_entry *
 -mlxsw_sp_fib6_entry_lookup(struct mlxsw_sp *mlxsw_sp,
 -			   const struct rt6_info *rt)
 -{
 -	struct mlxsw_sp_fib6_entry *fib6_entry;
 -	struct mlxsw_sp_fib_node *fib_node;
 -	struct mlxsw_sp_fib *fib;
 -	struct mlxsw_sp_vr *vr;
 -
 -	vr = mlxsw_sp_vr_find(mlxsw_sp, rt->rt6i_table->tb6_id);
 -	if (!vr)
 -		return NULL;
 -	fib = mlxsw_sp_vr_fib(vr, MLXSW_SP_L3_PROTO_IPV6);
 -
 -	fib_node = mlxsw_sp_fib_node_lookup(fib, &rt->rt6i_dst.addr,
 -					    sizeof(rt->rt6i_dst.addr),
 -					    rt->rt6i_dst.plen);
 -	if (!fib_node)
 -		return NULL;
 -
 -	list_for_each_entry(fib6_entry, &fib_node->entry_list, common.list) {
 -		struct rt6_info *iter_rt = mlxsw_sp_fib6_entry_rt(fib6_entry);
 -
 -		if (rt->rt6i_table->tb6_id == iter_rt->rt6i_table->tb6_id &&
 -		    rt->rt6i_metric == iter_rt->rt6i_metric &&
 -		    mlxsw_sp_fib6_entry_rt_find(fib6_entry, rt))
 -			return fib6_entry;
 -	}
 -
 -	return NULL;
 -}
 -
 -static void mlxsw_sp_fib6_entry_replace(struct mlxsw_sp *mlxsw_sp,
 -					struct mlxsw_sp_fib6_entry *fib6_entry,
 -					bool replace)
 -{
 -	struct mlxsw_sp_fib_node *fib_node = fib6_entry->common.fib_node;
 -	struct mlxsw_sp_fib6_entry *replaced;
 -
 -	if (!replace)
 -		return;
 -
 -	replaced = list_next_entry(fib6_entry, common.list);
 -
 -	mlxsw_sp_fib6_node_entry_unlink(mlxsw_sp, replaced);
 -	mlxsw_sp_fib6_entry_destroy(mlxsw_sp, replaced);
 -	mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
 -}
 -
 -static int mlxsw_sp_router_fib6_add(struct mlxsw_sp *mlxsw_sp,
 -				    struct rt6_info *rt, bool replace)
 -{
 -	struct mlxsw_sp_fib6_entry *fib6_entry;
 -	struct mlxsw_sp_fib_node *fib_node;
 -	int err;
 -
 -	if (mlxsw_sp->router->aborted)
 -		return 0;
 -
 -	if (rt->rt6i_src.plen)
 -		return -EINVAL;
 -
 -	if (mlxsw_sp_fib6_rt_should_ignore(rt))
 -		return 0;
 -
 -	fib_node = mlxsw_sp_fib_node_get(mlxsw_sp, rt->rt6i_table->tb6_id,
 -					 &rt->rt6i_dst.addr,
 -					 sizeof(rt->rt6i_dst.addr),
 -					 rt->rt6i_dst.plen,
 -					 MLXSW_SP_L3_PROTO_IPV6);
 -	if (IS_ERR(fib_node))
 -		return PTR_ERR(fib_node);
 -
 -	/* Before creating a new entry, try to append route to an existing
 -	 * multipath entry.
 -	 */
 -	fib6_entry = mlxsw_sp_fib6_node_mp_entry_find(fib_node, rt, replace);
 -	if (fib6_entry) {
 -		err = mlxsw_sp_fib6_entry_nexthop_add(mlxsw_sp, fib6_entry, rt);
 -		if (err)
 -			goto err_fib6_entry_nexthop_add;
 -		return 0;
 -	}
 -
 -	fib6_entry = mlxsw_sp_fib6_entry_create(mlxsw_sp, fib_node, rt);
 -	if (IS_ERR(fib6_entry)) {
 -		err = PTR_ERR(fib6_entry);
 -		goto err_fib6_entry_create;
 -	}
 -
 -	err = mlxsw_sp_fib6_node_entry_link(mlxsw_sp, fib6_entry, replace);
 -	if (err)
 -		goto err_fib6_node_entry_link;
 -
 -	mlxsw_sp_fib6_entry_replace(mlxsw_sp, fib6_entry, replace);
 -
 -	return 0;
 -
 -err_fib6_node_entry_link:
 -	mlxsw_sp_fib6_entry_destroy(mlxsw_sp, fib6_entry);
 -err_fib6_entry_create:
 -err_fib6_entry_nexthop_add:
 -	mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
 -	return err;
 -}
 -
 -static void mlxsw_sp_router_fib6_del(struct mlxsw_sp *mlxsw_sp,
 -				     struct rt6_info *rt)
 -{
 -	struct mlxsw_sp_fib6_entry *fib6_entry;
  	struct mlxsw_sp_fib_node *fib_node;
  
 -	if (mlxsw_sp->router->aborted)
 -		return;
 -
 -	if (mlxsw_sp_fib6_rt_should_ignore(rt))
 -		return;
 -
 -	fib6_entry = mlxsw_sp_fib6_entry_lookup(mlxsw_sp, rt);
 -	if (WARN_ON(!fib6_entry))
 +	if (mlxsw_sp->router.aborted)
  		return;
  
 -	/* If route is part of a multipath entry, but not the last one
 -	 * removed, then only reduce its nexthop group.
 -	 */
 -	if (!list_is_singular(&fib6_entry->rt6_list)) {
 -		mlxsw_sp_fib6_entry_nexthop_del(mlxsw_sp, fib6_entry, rt);
 +	fib_entry = mlxsw_sp_fib4_entry_lookup(mlxsw_sp, fen_info);
 +	if (WARN_ON(!fib_entry))
  		return;
 -	}
 -
 -	fib_node = fib6_entry->common.fib_node;
 +	fib_node = fib_entry->fib_node;
  
 -	mlxsw_sp_fib6_node_entry_unlink(mlxsw_sp, fib6_entry);
 -	mlxsw_sp_fib6_entry_destroy(mlxsw_sp, fib6_entry);
 +	mlxsw_sp_fib4_node_entry_unlink(mlxsw_sp, fib_entry);
 +	mlxsw_sp_fib4_entry_destroy(mlxsw_sp, fib_entry);
  	mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
  }
  
* Unmerged path drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c
