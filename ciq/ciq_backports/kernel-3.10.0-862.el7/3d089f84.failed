KVM: PPC: Book3S HV: Don't store values derivable from HPT order

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author David Gibson <david@gibson.dropbear.id.au>
commit 3d089f84c6f9b7b0eda993142d73961a44b553d2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/3d089f84.failed

Currently the kvm_hpt_info structure stores the hashed page table's order,
and also the number of HPTEs it contains and a mask for its size.  The
last two can be easily derived from the order, so remove them and just
calculate them as necessary with a couple of helper inlines.

	Signed-off-by: David Gibson <david@gibson.dropbear.id.au>
	Reviewed-by: Thomas Huth <thuth@redhat.com>
	Signed-off-by: Paul Mackerras <paulus@ozlabs.org>
(cherry picked from commit 3d089f84c6f9b7b0eda993142d73961a44b553d2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/include/asm/kvm_host.h
#	arch/powerpc/kvm/book3s_64_mmu_hv.c
#	arch/powerpc/kvm/book3s_hv_rm_mmu.c
diff --cc arch/powerpc/include/asm/kvm_host.h
index 328d42daf22c,0aa0f22d775a..000000000000
--- a/arch/powerpc/include/asm/kvm_host.h
+++ b/arch/powerpc/include/asm/kvm_host.h
@@@ -235,6 -241,17 +235,20 @@@ struct kvm_arch_memory_slot 
  #endif /* CONFIG_KVM_BOOK3S_HV_POSSIBLE */
  };
  
++<<<<<<< HEAD
++=======
+ struct kvm_hpt_info {
+ 	/* Host virtual (linear mapping) address of guest HPT */
+ 	unsigned long virt;
+ 	/* Array of reverse mapping entries for each guest HPTE */
+ 	struct revmap_entry *rev;
+ 	/* Guest HPT size is 2**(order) bytes */
+ 	u32 order;
+ 	/* 1 if HPT allocated with CMA, 0 otherwise */
+ 	int cma;
+ };
+ 
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  struct kvm_arch {
  	unsigned int lpid;
  #ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE
diff --cc arch/powerpc/kvm/book3s_64_mmu_hv.c
index 283e37e10f56,d89995ef6c7b..000000000000
--- a/arch/powerpc/kvm/book3s_64_mmu_hv.c
+++ b/arch/powerpc/kvm/book3s_64_mmu_hv.c
@@@ -82,15 -81,13 +82,25 @@@ long kvmppc_alloc_hpt(struct kvm *kvm, 
  	if (!hpt)
  		return -ENOMEM;
  
++<<<<<<< HEAD
 +	kvm->arch.hpt_virt = hpt;
 +	kvm->arch.hpt_order = order;
 +	/* HPTEs are 2**4 bytes long */
 +	kvm->arch.hpt_npte = 1ul << (order - 4);
 +	/* 128 (2**7) bytes in each HPTEG */
 +	kvm->arch.hpt_mask = (1ul << (order - 7)) - 1;
 +
 +	/* Allocate reverse map array */
 +	rev = vmalloc(sizeof(struct revmap_entry) * kvm->arch.hpt_npte);
++=======
+ 	kvm->arch.hpt.virt = hpt;
+ 	kvm->arch.hpt.order = order;
+ 
+ 	atomic64_set(&kvm->arch.mmio_update, 0);
+ 
+ 	/* Allocate reverse map array */
+ 	rev = vmalloc(sizeof(struct revmap_entry) * kvmppc_hpt_npte(&kvm->arch.hpt));
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  	if (!rev) {
  		pr_err("kvmppc_alloc_hpt: Couldn't alloc reverse map array\n");
  		goto out_freehpt;
@@@ -193,8 -192,8 +203,13 @@@ void kvmppc_map_vrma(struct kvm_vcpu *v
  	if (npages > 1ul << (40 - porder))
  		npages = 1ul << (40 - porder);
  	/* Can't use more than 1 HPTE per HPTEG */
++<<<<<<< HEAD
 +	if (npages > kvm->arch.hpt_mask + 1)
 +		npages = kvm->arch.hpt_mask + 1;
++=======
+ 	if (npages > kvmppc_hpt_mask(&kvm->arch.hpt) + 1)
+ 		npages = kvmppc_hpt_mask(&kvm->arch.hpt) + 1;
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  
  	hp0 = HPTE_V_1TB_SEG | (VRMA_VSID << (40 - 16)) |
  		HPTE_V_BOLTED | hpte0_pgsize_encoding(psize);
@@@ -204,7 -203,8 +219,12 @@@
  	for (i = 0; i < npages; ++i) {
  		addr = i << porder;
  		/* can't use hpt_hash since va > 64 bits */
++<<<<<<< HEAD
 +		hash = (i ^ (VRMA_VSID ^ (VRMA_VSID << 25))) & kvm->arch.hpt_mask;
++=======
+ 		hash = (i ^ (VRMA_VSID ^ (VRMA_VSID << 25)))
+ 			& kvmppc_hpt_mask(&kvm->arch.hpt);
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  		/*
  		 * We assume that the hash table is empty and no
  		 * vcpus are using it at this stage.  Since we create
@@@ -1269,7 -1324,7 +1289,11 @@@ static ssize_t kvm_htab_read(struct fil
  
  		/* Skip uninteresting entries, i.e. clean on not-first pass */
  		if (!first_pass) {
++<<<<<<< HEAD
 +			while (i < kvm->arch.hpt_npte &&
++=======
+ 			while (i < kvmppc_hpt_npte(&kvm->arch.hpt) &&
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  			       !hpte_dirty(revp, hptp)) {
  				++i;
  				hptp += 2;
@@@ -1279,7 -1334,7 +1303,11 @@@
  		hdr.index = i;
  
  		/* Grab a series of valid entries */
++<<<<<<< HEAD
 +		while (i < kvm->arch.hpt_npte &&
++=======
+ 		while (i < kvmppc_hpt_npte(&kvm->arch.hpt) &&
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  		       hdr.n_valid < 0xffff &&
  		       nb + HPTE_SIZE < count &&
  		       record_hpte(flags, hptp, hpte, revp, 1, first_pass)) {
@@@ -1295,7 -1350,7 +1323,11 @@@
  			++revp;
  		}
  		/* Now skip invalid entries while we can */
++<<<<<<< HEAD
 +		while (i < kvm->arch.hpt_npte &&
++=======
+ 		while (i < kvmppc_hpt_npte(&kvm->arch.hpt) &&
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  		       hdr.n_invalid < 0xffff &&
  		       record_hpte(flags, hptp, hpte, revp, 0, first_pass)) {
  			/* found an invalid entry */
@@@ -1316,7 -1371,7 +1348,11 @@@
  		}
  
  		/* Check if we've wrapped around the hash table */
++<<<<<<< HEAD
 +		if (i >= kvm->arch.hpt_npte) {
++=======
+ 		if (i >= kvmppc_hpt_npte(&kvm->arch.hpt)) {
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  			i = 0;
  			ctx->first_pass = 0;
  			break;
@@@ -1375,11 -1430,11 +1411,16 @@@ static ssize_t kvm_htab_write(struct fi
  
  		err = -EINVAL;
  		i = hdr.index;
++<<<<<<< HEAD
 +		if (i >= kvm->arch.hpt_npte ||
 +		    i + hdr.n_valid + hdr.n_invalid > kvm->arch.hpt_npte)
++=======
+ 		if (i >= kvmppc_hpt_npte(&kvm->arch.hpt) ||
+ 		    i + hdr.n_valid + hdr.n_invalid > kvmppc_hpt_npte(&kvm->arch.hpt))
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  			break;
  
 -		hptp = (__be64 *)(kvm->arch.hpt.virt + (i * HPTE_SIZE));
 +		hptp = (__be64 *)(kvm->arch.hpt_virt + (i * HPTE_SIZE));
  		lbuf = (unsigned long __user *)buf;
  		for (j = 0; j < hdr.n_valid; ++j) {
  			__be64 hpte_v;
@@@ -1566,8 -1621,9 +1607,14 @@@ static ssize_t debugfs_htab_read(struc
  
  	kvm = p->kvm;
  	i = p->hpt_index;
++<<<<<<< HEAD
 +	hptp = (__be64 *)(kvm->arch.hpt_virt + (i * HPTE_SIZE));
 +	for (; len != 0 && i < kvm->arch.hpt_npte; ++i, hptp += 2) {
++=======
+ 	hptp = (__be64 *)(kvm->arch.hpt.virt + (i * HPTE_SIZE));
+ 	for (; len != 0 && i < kvmppc_hpt_npte(&kvm->arch.hpt);
+ 	     ++i, hptp += 2) {
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  		if (!(be64_to_cpu(hptp[0]) & (HPTE_V_VALID | HPTE_V_ABSENT)))
  			continue;
  
diff --cc arch/powerpc/kvm/book3s_hv_rm_mmu.c
index 1b6a18cc43c5,6fca970373ee..000000000000
--- a/arch/powerpc/kvm/book3s_hv_rm_mmu.c
+++ b/arch/powerpc/kvm/book3s_hv_rm_mmu.c
@@@ -283,7 -292,7 +283,11 @@@ long kvmppc_do_h_enter(struct kvm *kvm
  
  	/* Find and lock the HPTEG slot to use */
   do_insert:
++<<<<<<< HEAD
 +	if (pte_index >= kvm->arch.hpt_npte)
++=======
+ 	if (pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt))
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  		return H_PARAMETER;
  	if (likely((flags & H_EXACT) == 0)) {
  		pte_index &= ~7UL;
@@@ -437,14 -465,21 +441,20 @@@ long kvmppc_do_h_remove(struct kvm *kvm
  	__be64 *hpte;
  	unsigned long v, r, rb;
  	struct revmap_entry *rev;
 -	u64 pte, orig_pte, pte_r;
 +	u64 pte;
  
++<<<<<<< HEAD
 +	if (pte_index >= kvm->arch.hpt_npte)
++=======
+ 	if (kvm_is_radix(kvm))
+ 		return H_FUNCTION;
+ 	if (pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt))
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  		return H_PARAMETER;
 -	hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
 +	hpte = (__be64 *)(kvm->arch.hpt_virt + (pte_index << 4));
  	while (!try_lock_hpte(hpte, HPTE_V_HVLOCK))
  		cpu_relax();
 -	pte = orig_pte = be64_to_cpu(hpte[0]);
 -	pte_r = be64_to_cpu(hpte[1]);
 -	if (cpu_has_feature(CPU_FTR_ARCH_300)) {
 -		pte = hpte_new_to_old_v(pte, pte_r);
 -		pte_r = hpte_new_to_old_r(pte_r);
 -	}
 +	pte = be64_to_cpu(hpte[0]);
  	if ((pte & (HPTE_V_ABSENT | HPTE_V_VALID)) == 0 ||
  	    ((flags & H_AVPN) && (pte & ~0x7fUL) != avpn) ||
  	    ((flags & H_ANDCOND) && (pte & avpn) != 0)) {
@@@ -517,7 -557,7 +527,11 @@@ long kvmppc_h_bulk_remove(struct kvm_vc
  				break;
  			}
  			if (req != 1 || flags == 3 ||
++<<<<<<< HEAD
 +			    pte_index >= kvm->arch.hpt_npte) {
++=======
+ 			    pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt)) {
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  				/* parameter error */
  				args[j] = ((0xa0 | flags) << 56) + pte_index;
  				ret = H_PARAMETER;
@@@ -607,18 -653,22 +621,24 @@@ long kvmppc_h_protect(struct kvm_vcpu *
  	__be64 *hpte;
  	struct revmap_entry *rev;
  	unsigned long v, r, rb, mask, bits;
 -	u64 pte_v, pte_r;
 +	u64 pte;
  
++<<<<<<< HEAD
 +	if (pte_index >= kvm->arch.hpt_npte)
++=======
+ 	if (kvm_is_radix(kvm))
+ 		return H_FUNCTION;
+ 	if (pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt))
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  		return H_PARAMETER;
  
 -	hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
 +	hpte = (__be64 *)(kvm->arch.hpt_virt + (pte_index << 4));
  	while (!try_lock_hpte(hpte, HPTE_V_HVLOCK))
  		cpu_relax();
 -	v = pte_v = be64_to_cpu(hpte[0]);
 -	if (cpu_has_feature(CPU_FTR_ARCH_300))
 -		v = hpte_new_to_old_v(v, be64_to_cpu(hpte[1]));
 -	if ((v & (HPTE_V_ABSENT | HPTE_V_VALID)) == 0 ||
 -	    ((flags & H_AVPN) && (v & ~0x7fUL) != avpn)) {
 -		__unlock_hpte(hpte, pte_v);
 +	pte = be64_to_cpu(hpte[0]);
 +	if ((pte & (HPTE_V_ABSENT | HPTE_V_VALID)) == 0 ||
 +	    ((flags & H_AVPN) && (pte & ~0x7fUL) != avpn)) {
 +		__unlock_hpte(hpte, pte);
  		return H_NOT_FOUND;
  	}
  
@@@ -672,7 -726,9 +692,13 @@@ long kvmppc_h_read(struct kvm_vcpu *vcp
  	int i, n = 1;
  	struct revmap_entry *rev = NULL;
  
++<<<<<<< HEAD
 +	if (pte_index >= kvm->arch.hpt_npte)
++=======
+ 	if (kvm_is_radix(kvm))
+ 		return H_FUNCTION;
+ 	if (pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt))
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  		return H_PARAMETER;
  	if (flags & H_READ_4) {
  		pte_index &= ~3;
@@@ -707,11 -767,13 +733,17 @@@ long kvmppc_h_clear_ref(struct kvm_vcp
  	unsigned long *rmap;
  	long ret = H_NOT_FOUND;
  
++<<<<<<< HEAD
 +	if (pte_index >= kvm->arch.hpt_npte)
++=======
+ 	if (kvm_is_radix(kvm))
+ 		return H_FUNCTION;
+ 	if (pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt))
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  		return H_PARAMETER;
  
 -	rev = real_vmalloc_addr(&kvm->arch.hpt.rev[pte_index]);
 -	hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
 +	rev = real_vmalloc_addr(&kvm->arch.revmap[pte_index]);
 +	hpte = (__be64 *)(kvm->arch.hpt_virt + (pte_index << 4));
  	while (!try_lock_hpte(hpte, HPTE_V_HVLOCK))
  		cpu_relax();
  	v = be64_to_cpu(hpte[0]);
@@@ -753,11 -815,13 +785,17 @@@ long kvmppc_h_clear_mod(struct kvm_vcp
  	unsigned long *rmap;
  	long ret = H_NOT_FOUND;
  
++<<<<<<< HEAD
 +	if (pte_index >= kvm->arch.hpt_npte)
++=======
+ 	if (kvm_is_radix(kvm))
+ 		return H_FUNCTION;
+ 	if (pte_index >= kvmppc_hpt_npte(&kvm->arch.hpt))
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  		return H_PARAMETER;
  
 -	rev = real_vmalloc_addr(&kvm->arch.hpt.rev[pte_index]);
 -	hpte = (__be64 *)(kvm->arch.hpt.virt + (pte_index << 4));
 +	rev = real_vmalloc_addr(&kvm->arch.revmap[pte_index]);
 +	hpte = (__be64 *)(kvm->arch.hpt_virt + (pte_index << 4));
  	while (!try_lock_hpte(hpte, HPTE_V_HVLOCK))
  		cpu_relax();
  	v = be64_to_cpu(hpte[0]);
@@@ -863,7 -970,7 +901,11 @@@ long kvmppc_hv_find_lock_hpte(struct kv
  		somask = (1UL << 28) - 1;
  		vsid = (slb_v & ~SLB_VSID_B) >> SLB_VSID_SHIFT;
  	}
++<<<<<<< HEAD
 +	hash = (vsid ^ ((eaddr & somask) >> pshift)) & kvm->arch.hpt_mask;
++=======
+ 	hash = (vsid ^ ((eaddr & somask) >> pshift)) & kvmppc_hpt_mask(&kvm->arch.hpt);
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  	avpn = slb_v & ~(somask >> 16);	/* also includes B */
  	avpn |= (eaddr & somask) >> 16;
  
@@@ -904,7 -1017,7 +946,11 @@@
  		if (val & HPTE_V_SECONDARY)
  			break;
  		val |= HPTE_V_SECONDARY;
++<<<<<<< HEAD
 +		hash = hash ^ kvm->arch.hpt_mask;
++=======
+ 		hash = hash ^ kvmppc_hpt_mask(&kvm->arch.hpt);
++>>>>>>> 3d089f84c6f9 (KVM: PPC: Book3S HV: Don't store values derivable from HPT order)
  	}
  	return -1;
  }
diff --git a/arch/powerpc/include/asm/kvm_book3s_64.h b/arch/powerpc/include/asm/kvm_book3s_64.h
index 67964ff815d3..bebb270402aa 100644
--- a/arch/powerpc/include/asm/kvm_book3s_64.h
+++ b/arch/powerpc/include/asm/kvm_book3s_64.h
@@ -434,6 +434,18 @@ static inline struct kvm_memslots *kvm_memslots_raw(struct kvm *kvm)
 extern void kvmhv_rm_send_ipi(int cpu);
 extern void kvmppc_mmu_debugfs_init(struct kvm *kvm);
 
+static inline unsigned long kvmppc_hpt_npte(struct kvm_hpt_info *hpt)
+{
+	/* HPTEs are 2**4 bytes long */
+	return 1UL << (hpt->order - 4);
+}
+
+static inline unsigned long kvmppc_hpt_mask(struct kvm_hpt_info *hpt)
+{
+	/* 128 (2**7) bytes in each HPTEG */
+	return (1UL << (hpt->order - 7)) - 1;
+}
+
 #endif /* CONFIG_KVM_BOOK3S_HV_POSSIBLE */
 
 #endif /* __ASM_KVM_BOOK3S_64_H__ */
* Unmerged path arch/powerpc/include/asm/kvm_host.h
* Unmerged path arch/powerpc/kvm/book3s_64_mmu_hv.c
* Unmerged path arch/powerpc/kvm/book3s_hv_rm_mmu.c
