blk-mq: really fix plug list flushing for nomerge queues

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Omar Sandoval <osandov@fb.com>
commit 87c279e613f848c691111b29d49de8df3f4f56da
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/87c279e6.failed

Commit 0809e3ac6231 ("block: fix plug list flushing for nomerge queues")
updated blk_mq_make_request() to set request_count even when
blk_queue_nomerges() returns true. However, blk_mq_make_request() only
does limited plugging and doesn't use request_count;
blk_sq_make_request() is the one that should have been fixed. Do that
and get rid of the unnecessary work in the mq version.

Fixes: 0809e3ac6231 ("block: fix plug list flushing for nomerge queues")
	Signed-off-by: Omar Sandoval <osandov@fb.com>
	Reviewed-by: Ming Lei <tom.leiming@gmail.com>
	Reviewed-by: Jeff Moyer <jmoyer@redhat.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 87c279e613f848c691111b29d49de8df3f4f56da)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq.c
diff --cc block/blk-mq.c
index 49418900af65,f9b9049b1284..000000000000
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@@ -1392,13 -1256,15 +1392,21 @@@ static void blk_mq_make_request(struct 
  	blk_queue_bounce(q, &bio);
  
  	if (bio_integrity_enabled(bio) && bio_integrity_prep(bio)) {
 -		bio_io_error(bio);
 -		return BLK_QC_T_NONE;
 +		bio_endio(bio, -EIO);
 +		return;
  	}
  
++<<<<<<< HEAD
 +	if (!is_flush_fua && !blk_queue_nomerges(q) &&
 +	    blk_attempt_plug_merge(q, bio, &request_count, &same_queue_rq))
 +		return;
++=======
+ 	blk_queue_split(q, &bio, q->bio_split);
+ 
+ 	if (!is_flush_fua && !blk_queue_nomerges(q) &&
+ 	    blk_attempt_plug_merge(q, bio, &request_count, &same_queue_rq))
+ 		return BLK_QC_T_NONE;
++>>>>>>> 87c279e613f8 (blk-mq: really fix plug list flushing for nomerge queues)
  
  	rq = blk_mq_map_request(q, bio, &data);
  	if (unlikely(!rq))
@@@ -1485,13 -1349,17 +1493,23 @@@ static void blk_sq_make_request(struct 
  	blk_queue_bounce(q, &bio);
  
  	if (bio_integrity_enabled(bio) && bio_integrity_prep(bio)) {
 -		bio_io_error(bio);
 -		return BLK_QC_T_NONE;
 +		bio_endio(bio, -EIO);
 +		return;
  	}
  
++<<<<<<< HEAD
 +	if (!is_flush_fua && !blk_queue_nomerges(q) &&
 +	    blk_attempt_plug_merge(q, bio, &request_count, NULL))
 +		return;
++=======
+ 	blk_queue_split(q, &bio, q->bio_split);
+ 
+ 	if (!is_flush_fua && !blk_queue_nomerges(q)) {
+ 		if (blk_attempt_plug_merge(q, bio, &request_count, NULL))
+ 			return BLK_QC_T_NONE;
+ 	} else
+ 		request_count = blk_plug_queued_count(q);
++>>>>>>> 87c279e613f8 (blk-mq: really fix plug list flushing for nomerge queues)
  
  	rq = blk_mq_map_request(q, bio, &data);
  	if (unlikely(!rq))
* Unmerged path block/blk-mq.c
