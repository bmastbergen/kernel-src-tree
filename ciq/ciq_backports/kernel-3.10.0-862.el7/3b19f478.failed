qed: Make VF legacy a bitfield

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Mintz, Yuval <Yuval.Mintz@cavium.com>
commit 3b19f47820756f9905e7ef184747fbb3c8ed062f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/3b19f478.failed

Until now we used to have a single VF legacy compatibility mode,
one that affected the place of the Rx producers of those VFs [mostly].

As PF would soon support allocating CIDs for VFs instead of having
a static CID<->queue configuration for them, we'll need to have
an additional legacy mode since existing VFs would need to continue
on using the older mode of operation.

Change the infrastrucutre so that the legacy would be able to indicate
which of the legacy behaviors is needed for a given VF.

	Signed-off-by: Yuval Mintz <Yuval.Mintz@cavium.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 3b19f47820756f9905e7ef184747fbb3c8ed062f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/qlogic/qed/qed_l2.c
#	drivers/net/ethernet/qlogic/qed/qed_l2.h
#	drivers/net/ethernet/qlogic/qed/qed_sriov.c
diff --cc drivers/net/ethernet/qlogic/qed/qed_l2.c
index f852981b5922,7096a3c0103d..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_l2.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_l2.c
@@@ -95,10 -230,24 +95,29 @@@ _qed_eth_queue_to_cid(struct qed_hwfn *
  
  	p_cid->opaque_fid = opaque_fid;
  	p_cid->cid = cid;
 +	p_cid->vf_qid = vf_qid;
 +	p_cid->rel = *p_params;
  	p_cid->p_owner = p_hwfn;
  
++<<<<<<< HEAD
++=======
+ 	/* Fill in parameters */
+ 	p_cid->rel.vport_id = p_params->vport_id;
+ 	p_cid->rel.queue_id = p_params->queue_id;
+ 	p_cid->rel.stats_id = p_params->stats_id;
+ 	p_cid->sb_igu_id = p_params->p_sb->igu_sb_id;
+ 	p_cid->sb_idx = p_params->sb_idx;
+ 
+ 	/* Fill-in bits related to VFs' queues if information was provided */
+ 	if (p_vf_params) {
+ 		p_cid->vfid = p_vf_params->vfid;
+ 		p_cid->vf_qid = p_vf_params->vf_qid;
+ 		p_cid->vf_legacy = p_vf_params->vf_legacy;
+ 	} else {
+ 		p_cid->vfid = QED_QUEUE_CID_SELF;
+ 	}
+ 
++>>>>>>> 3b19f4782075 (qed: Make VF legacy a bitfield)
  	/* Don't try calculating the absolute indices for VFs */
  	if (IS_VF(p_hwfn->cdev)) {
  		p_cid->abs = p_cid->rel;
@@@ -710,7 -877,10 +729,14 @@@ int qed_eth_rxq_start_ramrod(struct qed
  	p_ramrod->num_of_pbl_pages = cpu_to_le16(cqe_pbl_size);
  	DMA_REGPAIR_LE(p_ramrod->cqe_pbl_addr, cqe_pbl_addr);
  
++<<<<<<< HEAD
 +	if (p_cid->is_vf) {
++=======
+ 	if (p_cid->vfid != QED_QUEUE_CID_SELF) {
+ 		bool b_legacy_vf = !!(p_cid->vf_legacy &
+ 				      QED_QCID_LEGACY_VF_RX_PROD);
+ 
++>>>>>>> 3b19f4782075 (qed: Make VF legacy a bitfield)
  		p_ramrod->vf_rx_prod_index = p_cid->vf_qid;
  		DP_VERBOSE(p_hwfn, QED_MSG_SP,
  			   "Queue%s is meant for VF rxq[%02x]\n",
diff --cc drivers/net/ethernet/qlogic/qed/qed_l2.h
index 93cb932ef663,3f94c2207dff..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_l2.h
+++ b/drivers/net/ethernet/qlogic/qed/qed_l2.h
@@@ -268,14 -277,48 +268,50 @@@ void qed_get_vport_stats(struct qed_de
  
  void qed_reset_vport_stats(struct qed_dev *cdev);
  
++<<<<<<< HEAD
++=======
+ #define MAX_QUEUES_PER_QZONE    (sizeof(unsigned long) * 8)
+ #define QED_QUEUE_CID_SELF	(0xff)
+ 
+ /* Almost identical to the qed_queue_start_common_params,
+  * but here we maintain the SB index in IGU CAM.
+  */
+ struct qed_queue_cid_params {
+ 	u8 vport_id;
+ 	u16 queue_id;
+ 	u8 stats_id;
+ };
+ 
+ /* Additional parameters required for initialization of the queue_cid
+  * and are relevant only for a PF initializing one for its VFs.
+  */
+ struct qed_queue_cid_vf_params {
+ 	/* Should match the VF's relative index */
+ 	u8 vfid;
+ 
+ 	/* 0-based queue index. Should reflect the relative qzone the
+ 	 * VF thinks is associated with it [in its range].
+ 	 */
+ 	u8 vf_qid;
+ 
+ 	/* Indicates a VF is legacy, making it differ in several things:
+ 	 *  - Producers would be placed in a different place.
+ 	 *  - Makes assumptions regarding the CIDs.
+ 	 */
+ 	u8 vf_legacy;
+ 
+ 	u8 qid_usage_idx;
+ };
+ 
++>>>>>>> 3b19f4782075 (qed: Make VF legacy a bitfield)
  struct qed_queue_cid {
 -	/* For stats-id, the `rel' is actually absolute as well */
 -	struct qed_queue_cid_params rel;
 -	struct qed_queue_cid_params abs;
 -
 -	/* These have no 'relative' meaning */
 -	u16 sb_igu_id;
 -	u8 sb_idx;
 -
 +	/* 'Relative' is a relative term ;-). Usually the indices [not counting
 +	 * SBs] would be PF-relative, but there are some cases where that isn't
 +	 * the case - specifically for a PF configuring its VF indices it's
 +	 * possible some fields [E.g., stats-id] in 'rel' would already be abs.
 +	 */
 +	struct qed_queue_start_common_params rel;
 +	struct qed_queue_start_common_params abs;
  	u32 cid;
  	u16 opaque_fid;
  
@@@ -284,11 -327,18 +320,23 @@@
  	 * Notice this is relevant on the *PF* queue-cid of its VF's queues,
  	 * and not on the VF itself.
  	 */
 -	u8 vfid;
 +	bool is_vf;
  	u8 vf_qid;
  
++<<<<<<< HEAD
 +	/* Legacy VFs might have Rx producer located elsewhere */
 +	bool b_legacy_vf;
++=======
+ 	/* We need an additional index to differentiate between queues opened
+ 	 * for same queue-zone, as VFs would have to communicate the info
+ 	 * to the PF [otherwise PF has no way to differentiate].
+ 	 */
+ 	u8 qid_usage_idx;
+ 
+ 	u8 vf_legacy;
+ #define QED_QCID_LEGACY_VF_RX_PROD	(BIT(0))
+ #define QED_QCID_LEGACY_VF_CID		(BIT(1))
++>>>>>>> 3b19f4782075 (qed: Make VF legacy a bitfield)
  
  	struct qed_hwfn *p_owner;
  };
diff --cc drivers/net/ethernet/qlogic/qed/qed_sriov.c
index c231e788de76,ed35ae03d080..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_sriov.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_sriov.c
@@@ -1983,11 -1967,13 +1994,16 @@@ static void qed_iov_vf_mbx_start_rxq(st
  				     struct qed_vf_info *vf)
  {
  	struct qed_queue_start_common_params params;
 -	struct qed_queue_cid_vf_params vf_params;
  	struct qed_iov_vf_mbx *mbx = &vf->vf_mbx;
  	u8 status = PFVF_STATUS_NO_RESOURCE;
+ 	u8 qid_usage_idx, vf_legacy = 0;
  	struct qed_vf_q_info *p_queue;
  	struct vfpf_start_rxq_tlv *req;
++<<<<<<< HEAD
 +	bool b_legacy_vf = false;
++=======
+ 	struct qed_sb_info sb_dummy;
++>>>>>>> 3b19f4782075 (qed: Make VF legacy a bitfield)
  	int rc;
  
  	req = &mbx->req_virt->start_rxq;
@@@ -1997,30 -1983,36 +2013,50 @@@
  	    !qed_iov_validate_sb(p_hwfn, vf, req->hw_sb))
  		goto out;
  
 -	qid_usage_idx = qed_iov_vf_mbx_qid(p_hwfn, vf, false);
 +	/* Acquire a new queue-cid */
  	p_queue = &vf->vf_queues[req->rx_qid];
  
++<<<<<<< HEAD
++=======
+ 	vf_legacy = qed_vf_calculate_legacy(vf);
+ 
+ 	/* Acquire a new queue-cid */
++>>>>>>> 3b19f4782075 (qed: Make VF legacy a bitfield)
  	memset(&params, 0, sizeof(params));
  	params.queue_id = p_queue->fw_rx_qid;
  	params.vport_id = vf->vport_id;
  	params.stats_id = vf->abs_vf_id + 0x10;
 -	/* Since IGU index is passed via sb_info, construct a dummy one */
 -	memset(&sb_dummy, 0, sizeof(sb_dummy));
 -	sb_dummy.igu_sb_id = req->hw_sb;
 -	params.p_sb = &sb_dummy;
 +	params.sb = req->hw_sb;
  	params.sb_idx = req->sb_index;
  
++<<<<<<< HEAD
 +	p_queue->p_rx_cid = _qed_eth_queue_to_cid(p_hwfn,
 +						  vf->opaque_fid,
 +						  p_queue->fw_cid,
 +						  req->rx_qid, &params);
++=======
+ 	memset(&vf_params, 0, sizeof(vf_params));
+ 	vf_params.vfid = vf->relative_vf_id;
+ 	vf_params.vf_qid = (u8)req->rx_qid;
+ 	vf_params.vf_legacy = vf_legacy;
+ 	vf_params.qid_usage_idx = qid_usage_idx;
+ 	p_queue->p_rx_cid = qed_eth_queue_to_cid(p_hwfn, vf->opaque_fid,
+ 						 &params, &vf_params);
++>>>>>>> 3b19f4782075 (qed: Make VF legacy a bitfield)
  	if (!p_queue->p_rx_cid)
  		goto out;
  
  	/* Legacy VFs have their Producers in a different location, which they
  	 * calculate on their own and clean the producer prior to this.
  	 */
++<<<<<<< HEAD
 +	if (vf->acquire.vfdev_info.eth_fp_hsi_minor ==
 +	    ETH_HSI_VER_NO_PKT_LEN_TUNN) {
 +		b_legacy_vf = true;
 +	} else {
++=======
+ 	if (!(vf_legacy & QED_QCID_LEGACY_VF_RX_PROD))
++>>>>>>> 3b19f4782075 (qed: Make VF legacy a bitfield)
  		REG_WR(p_hwfn,
  		       GTT_BAR0_MAP_REG_MSDM_RAM +
  		       MSTORM_ETH_VF_PRODS_OFFSET(vf->abs_vf_id, req->rx_qid),
@@@ -2043,9 -2033,225 +2079,11 @@@
  	}
  
  out:
- 	qed_iov_vf_mbx_start_rxq_resp(p_hwfn, p_ptt, vf, status, b_legacy_vf);
+ 	qed_iov_vf_mbx_start_rxq_resp(p_hwfn, p_ptt, vf, status,
+ 				      !!(vf_legacy &
+ 					 QED_QCID_LEGACY_VF_RX_PROD));
  }
  
 -static void
 -qed_iov_pf_update_tun_response(struct pfvf_update_tunn_param_tlv *p_resp,
 -			       struct qed_tunnel_info *p_tun,
 -			       u16 tunn_feature_mask)
 -{
 -	p_resp->tunn_feature_mask = tunn_feature_mask;
 -	p_resp->vxlan_mode = p_tun->vxlan.b_mode_enabled;
 -	p_resp->l2geneve_mode = p_tun->l2_geneve.b_mode_enabled;
 -	p_resp->ipgeneve_mode = p_tun->ip_geneve.b_mode_enabled;
 -	p_resp->l2gre_mode = p_tun->l2_gre.b_mode_enabled;
 -	p_resp->ipgre_mode = p_tun->l2_gre.b_mode_enabled;
 -	p_resp->vxlan_clss = p_tun->vxlan.tun_cls;
 -	p_resp->l2gre_clss = p_tun->l2_gre.tun_cls;
 -	p_resp->ipgre_clss = p_tun->ip_gre.tun_cls;
 -	p_resp->l2geneve_clss = p_tun->l2_geneve.tun_cls;
 -	p_resp->ipgeneve_clss = p_tun->ip_geneve.tun_cls;
 -	p_resp->geneve_udp_port = p_tun->geneve_port.port;
 -	p_resp->vxlan_udp_port = p_tun->vxlan_port.port;
 -}
 -
 -static void
 -__qed_iov_pf_update_tun_param(struct vfpf_update_tunn_param_tlv *p_req,
 -			      struct qed_tunn_update_type *p_tun,
 -			      enum qed_tunn_mode mask, u8 tun_cls)
 -{
 -	if (p_req->tun_mode_update_mask & BIT(mask)) {
 -		p_tun->b_update_mode = true;
 -
 -		if (p_req->tunn_mode & BIT(mask))
 -			p_tun->b_mode_enabled = true;
 -	}
 -
 -	p_tun->tun_cls = tun_cls;
 -}
 -
 -static void
 -qed_iov_pf_update_tun_param(struct vfpf_update_tunn_param_tlv *p_req,
 -			    struct qed_tunn_update_type *p_tun,
 -			    struct qed_tunn_update_udp_port *p_port,
 -			    enum qed_tunn_mode mask,
 -			    u8 tun_cls, u8 update_port, u16 port)
 -{
 -	if (update_port) {
 -		p_port->b_update_port = true;
 -		p_port->port = port;
 -	}
 -
 -	__qed_iov_pf_update_tun_param(p_req, p_tun, mask, tun_cls);
 -}
 -
 -static bool
 -qed_iov_pf_validate_tunn_param(struct vfpf_update_tunn_param_tlv *p_req)
 -{
 -	bool b_update_requested = false;
 -
 -	if (p_req->tun_mode_update_mask || p_req->update_tun_cls ||
 -	    p_req->update_geneve_port || p_req->update_vxlan_port)
 -		b_update_requested = true;
 -
 -	return b_update_requested;
 -}
 -
 -static void qed_pf_validate_tunn_mode(struct qed_tunn_update_type *tun, int *rc)
 -{
 -	if (tun->b_update_mode && !tun->b_mode_enabled) {
 -		tun->b_update_mode = false;
 -		*rc = -EINVAL;
 -	}
 -}
 -
 -static int
 -qed_pf_validate_modify_tunn_config(struct qed_hwfn *p_hwfn,
 -				   u16 *tun_features, bool *update,
 -				   struct qed_tunnel_info *tun_src)
 -{
 -	struct qed_eth_cb_ops *ops = p_hwfn->cdev->protocol_ops.eth;
 -	struct qed_tunnel_info *tun = &p_hwfn->cdev->tunnel;
 -	u16 bultn_vxlan_port, bultn_geneve_port;
 -	void *cookie = p_hwfn->cdev->ops_cookie;
 -	int i, rc = 0;
 -
 -	*tun_features = p_hwfn->cdev->tunn_feature_mask;
 -	bultn_vxlan_port = tun->vxlan_port.port;
 -	bultn_geneve_port = tun->geneve_port.port;
 -	qed_pf_validate_tunn_mode(&tun_src->vxlan, &rc);
 -	qed_pf_validate_tunn_mode(&tun_src->l2_geneve, &rc);
 -	qed_pf_validate_tunn_mode(&tun_src->ip_geneve, &rc);
 -	qed_pf_validate_tunn_mode(&tun_src->l2_gre, &rc);
 -	qed_pf_validate_tunn_mode(&tun_src->ip_gre, &rc);
 -
 -	if ((tun_src->b_update_rx_cls || tun_src->b_update_tx_cls) &&
 -	    (tun_src->vxlan.tun_cls != QED_TUNN_CLSS_MAC_VLAN ||
 -	     tun_src->l2_geneve.tun_cls != QED_TUNN_CLSS_MAC_VLAN ||
 -	     tun_src->ip_geneve.tun_cls != QED_TUNN_CLSS_MAC_VLAN ||
 -	     tun_src->l2_gre.tun_cls != QED_TUNN_CLSS_MAC_VLAN ||
 -	     tun_src->ip_gre.tun_cls != QED_TUNN_CLSS_MAC_VLAN)) {
 -		tun_src->b_update_rx_cls = false;
 -		tun_src->b_update_tx_cls = false;
 -		rc = -EINVAL;
 -	}
 -
 -	if (tun_src->vxlan_port.b_update_port) {
 -		if (tun_src->vxlan_port.port == tun->vxlan_port.port) {
 -			tun_src->vxlan_port.b_update_port = false;
 -		} else {
 -			*update = true;
 -			bultn_vxlan_port = tun_src->vxlan_port.port;
 -		}
 -	}
 -
 -	if (tun_src->geneve_port.b_update_port) {
 -		if (tun_src->geneve_port.port == tun->geneve_port.port) {
 -			tun_src->geneve_port.b_update_port = false;
 -		} else {
 -			*update = true;
 -			bultn_geneve_port = tun_src->geneve_port.port;
 -		}
 -	}
 -
 -	qed_for_each_vf(p_hwfn, i) {
 -		qed_iov_bulletin_set_udp_ports(p_hwfn, i, bultn_vxlan_port,
 -					       bultn_geneve_port);
 -	}
 -
 -	qed_schedule_iov(p_hwfn, QED_IOV_WQ_BULLETIN_UPDATE_FLAG);
 -	ops->ports_update(cookie, bultn_vxlan_port, bultn_geneve_port);
 -
 -	return rc;
 -}
 -
 -static void qed_iov_vf_mbx_update_tunn_param(struct qed_hwfn *p_hwfn,
 -					     struct qed_ptt *p_ptt,
 -					     struct qed_vf_info *p_vf)
 -{
 -	struct qed_tunnel_info *p_tun = &p_hwfn->cdev->tunnel;
 -	struct qed_iov_vf_mbx *mbx = &p_vf->vf_mbx;
 -	struct pfvf_update_tunn_param_tlv *p_resp;
 -	struct vfpf_update_tunn_param_tlv *p_req;
 -	u8 status = PFVF_STATUS_SUCCESS;
 -	bool b_update_required = false;
 -	struct qed_tunnel_info tunn;
 -	u16 tunn_feature_mask = 0;
 -	int i, rc = 0;
 -
 -	mbx->offset = (u8 *)mbx->reply_virt;
 -
 -	memset(&tunn, 0, sizeof(tunn));
 -	p_req = &mbx->req_virt->tunn_param_update;
 -
 -	if (!qed_iov_pf_validate_tunn_param(p_req)) {
 -		DP_VERBOSE(p_hwfn, QED_MSG_IOV,
 -			   "No tunnel update requested by VF\n");
 -		status = PFVF_STATUS_FAILURE;
 -		goto send_resp;
 -	}
 -
 -	tunn.b_update_rx_cls = p_req->update_tun_cls;
 -	tunn.b_update_tx_cls = p_req->update_tun_cls;
 -
 -	qed_iov_pf_update_tun_param(p_req, &tunn.vxlan, &tunn.vxlan_port,
 -				    QED_MODE_VXLAN_TUNN, p_req->vxlan_clss,
 -				    p_req->update_vxlan_port,
 -				    p_req->vxlan_port);
 -	qed_iov_pf_update_tun_param(p_req, &tunn.l2_geneve, &tunn.geneve_port,
 -				    QED_MODE_L2GENEVE_TUNN,
 -				    p_req->l2geneve_clss,
 -				    p_req->update_geneve_port,
 -				    p_req->geneve_port);
 -	__qed_iov_pf_update_tun_param(p_req, &tunn.ip_geneve,
 -				      QED_MODE_IPGENEVE_TUNN,
 -				      p_req->ipgeneve_clss);
 -	__qed_iov_pf_update_tun_param(p_req, &tunn.l2_gre,
 -				      QED_MODE_L2GRE_TUNN, p_req->l2gre_clss);
 -	__qed_iov_pf_update_tun_param(p_req, &tunn.ip_gre,
 -				      QED_MODE_IPGRE_TUNN, p_req->ipgre_clss);
 -
 -	/* If PF modifies VF's req then it should
 -	 * still return an error in case of partial configuration
 -	 * or modified configuration as opposed to requested one.
 -	 */
 -	rc = qed_pf_validate_modify_tunn_config(p_hwfn, &tunn_feature_mask,
 -						&b_update_required, &tunn);
 -
 -	if (rc)
 -		status = PFVF_STATUS_FAILURE;
 -
 -	/* If QED client is willing to update anything ? */
 -	if (b_update_required) {
 -		u16 geneve_port;
 -
 -		rc = qed_sp_pf_update_tunn_cfg(p_hwfn, p_ptt, &tunn,
 -					       QED_SPQ_MODE_EBLOCK, NULL);
 -		if (rc)
 -			status = PFVF_STATUS_FAILURE;
 -
 -		geneve_port = p_tun->geneve_port.port;
 -		qed_for_each_vf(p_hwfn, i) {
 -			qed_iov_bulletin_set_udp_ports(p_hwfn, i,
 -						       p_tun->vxlan_port.port,
 -						       geneve_port);
 -		}
 -	}
 -
 -send_resp:
 -	p_resp = qed_add_tlv(p_hwfn, &mbx->offset,
 -			     CHANNEL_TLV_UPDATE_TUNN_PARAM, sizeof(*p_resp));
 -
 -	qed_iov_pf_update_tun_response(p_resp, p_tun, tunn_feature_mask);
 -	qed_add_tlv(p_hwfn, &mbx->offset, CHANNEL_TLV_LIST_END,
 -		    sizeof(struct channel_list_end_tlv));
 -
 -	qed_iov_send_response(p_hwfn, p_ptt, p_vf, sizeof(*p_resp), status);
 -}
 -
  static void qed_iov_vf_mbx_start_txq_resp(struct qed_hwfn *p_hwfn,
  					  struct qed_ptt *p_ptt,
  					  struct qed_vf_info *p_vf, u8 status)
@@@ -2095,6 -2302,8 +2133,11 @@@ static void qed_iov_vf_mbx_start_txq(st
  	u8 status = PFVF_STATUS_NO_RESOURCE;
  	struct vfpf_start_txq_tlv *req;
  	struct qed_vf_q_info *p_queue;
++<<<<<<< HEAD
++=======
+ 	struct qed_sb_info sb_dummy;
+ 	u8 qid_usage_idx, vf_legacy;
++>>>>>>> 3b19f4782075 (qed: Make VF legacy a bitfield)
  	int rc;
  	u16 pq;
  
@@@ -2106,19 -2315,31 +2149,37 @@@
  	    !qed_iov_validate_sb(p_hwfn, vf, req->hw_sb))
  		goto out;
  
 -	qid_usage_idx = qed_iov_vf_mbx_qid(p_hwfn, vf, true);
 +	/* Acquire a new queue-cid */
  	p_queue = &vf->vf_queues[req->tx_qid];
  
++<<<<<<< HEAD
++=======
+ 	vf_legacy = qed_vf_calculate_legacy(vf);
+ 
+ 	/* Acquire a new queue-cid */
++>>>>>>> 3b19f4782075 (qed: Make VF legacy a bitfield)
  	params.queue_id = p_queue->fw_tx_qid;
  	params.vport_id = vf->vport_id;
  	params.stats_id = vf->abs_vf_id + 0x10;
 -
 -	/* Since IGU index is passed via sb_info, construct a dummy one */
 -	memset(&sb_dummy, 0, sizeof(sb_dummy));
 -	sb_dummy.igu_sb_id = req->hw_sb;
 -	params.p_sb = &sb_dummy;
 +	params.sb = req->hw_sb;
  	params.sb_idx = req->sb_index;
  
++<<<<<<< HEAD
 +	p_queue->p_tx_cid = _qed_eth_queue_to_cid(p_hwfn,
 +						  vf->opaque_fid,
 +						  p_queue->fw_cid,
 +						  req->tx_qid, &params);
++=======
+ 	memset(&vf_params, 0, sizeof(vf_params));
+ 	vf_params.vfid = vf->relative_vf_id;
+ 	vf_params.vf_qid = (u8)req->tx_qid;
+ 	vf_params.vf_legacy = vf_legacy;
+ 	vf_params.qid_usage_idx = qid_usage_idx;
+ 
+ 	p_queue->p_tx_cid = qed_eth_queue_to_cid(p_hwfn,
+ 						 vf->opaque_fid,
+ 						 &params, &vf_params);
++>>>>>>> 3b19f4782075 (qed: Make VF legacy a bitfield)
  	if (!p_queue->p_tx_cid)
  		goto out;
  
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_l2.c
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_l2.h
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_sriov.c
