blk-mq: move blk_mq_put_driver_tag*() into blk-mq.h

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Ming Lei <ming.lei@redhat.com>
commit 244c65a3ccaa06fd15cc940315606674d3108b2f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/244c65a3.failed

We need this helper to put the driver tag for flush rq, since we will
not share tag in the flush request sequence in the following patch
in case that I/O scheduler is applied.

	Signed-off-by: Ming Lei <ming.lei@redhat.com>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 244c65a3ccaa06fd15cc940315606674d3108b2f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq.c
#	block/blk-mq.h
diff --cc block/blk-mq.c
index d9bfe0c6bc0e,14f6886fbec8..000000000000
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@@ -825,19 -964,111 +825,91 @@@ static inline unsigned int queued_to_in
  	return min(BLK_MQ_MAX_DISPATCH_ORDER - 1, ilog2(queued) + 1);
  }
  
 -bool blk_mq_get_driver_tag(struct request *rq, struct blk_mq_hw_ctx **hctx,
 -			   bool wait)
 +bool blk_mq_dispatch_rq_list(struct blk_mq_hw_ctx *hctx, struct list_head *list)
  {
++<<<<<<< HEAD
 +	struct request_queue *q = hctx->queue;
 +	struct request *rq;
 +	LIST_HEAD(driver_list);
 +	struct list_head *dptr;
 +	int errors, queued, ret = BLK_MQ_RQ_QUEUE_OK;
++=======
+ 	struct blk_mq_alloc_data data = {
+ 		.q = rq->q,
+ 		.hctx = blk_mq_map_queue(rq->q, rq->mq_ctx->cpu),
+ 		.flags = wait ? 0 : BLK_MQ_REQ_NOWAIT,
+ 	};
+ 
+ 	might_sleep_if(wait);
+ 
+ 	if (rq->tag != -1)
+ 		goto done;
+ 
+ 	if (blk_mq_tag_is_reserved(data.hctx->sched_tags, rq->internal_tag))
+ 		data.flags |= BLK_MQ_REQ_RESERVED;
+ 
+ 	rq->tag = blk_mq_get_tag(&data);
+ 	if (rq->tag >= 0) {
+ 		if (blk_mq_tag_busy(data.hctx)) {
+ 			rq->rq_flags |= RQF_MQ_INFLIGHT;
+ 			atomic_inc(&data.hctx->nr_active);
+ 		}
+ 		data.hctx->tags->rqs[rq->tag] = rq;
+ 	}
+ 
+ done:
+ 	if (hctx)
+ 		*hctx = data.hctx;
+ 	return rq->tag != -1;
+ }
+ 
+ /*
+  * If we fail getting a driver tag because all the driver tags are already
+  * assigned and on the dispatch list, BUT the first entry does not have a
+  * tag, then we could deadlock. For that case, move entries with assigned
+  * driver tags to the front, leaving the set of tagged requests in the
+  * same order, and the untagged set in the same order.
+  */
+ static bool reorder_tags_to_front(struct list_head *list)
+ {
+ 	struct request *rq, *tmp, *first = NULL;
+ 
+ 	list_for_each_entry_safe_reverse(rq, tmp, list, queuelist) {
+ 		if (rq == first)
+ 			break;
+ 		if (rq->tag != -1) {
+ 			list_move(&rq->queuelist, list);
+ 			if (!first)
+ 				first = rq;
+ 		}
+ 	}
+ 
+ 	return first != NULL;
+ }
+ 
+ static int blk_mq_dispatch_wake(wait_queue_entry_t *wait, unsigned mode, int flags,
+ 				void *key)
+ {
+ 	struct blk_mq_hw_ctx *hctx;
+ 
+ 	hctx = container_of(wait, struct blk_mq_hw_ctx, dispatch_wait);
+ 
+ 	list_del(&wait->entry);
+ 	clear_bit_unlock(BLK_MQ_S_TAG_WAITING, &hctx->state);
+ 	blk_mq_run_hw_queue(hctx, true);
+ 	return 1;
+ }
+ 
+ static bool blk_mq_dispatch_wait_add(struct blk_mq_hw_ctx *hctx)
+ {
+ 	struct sbq_wait_state *ws;
++>>>>>>> 244c65a3ccaa (blk-mq: move blk_mq_put_driver_tag*() into blk-mq.h)
  
  	/*
 -	 * The TAG_WAITING bit serves as a lock protecting hctx->dispatch_wait.
 -	 * The thread which wins the race to grab this bit adds the hardware
 -	 * queue to the wait queue.
 +	 * Start off with dptr being NULL, so we start the first request
 +	 * immediately, even if we have more pending.
  	 */
 -	if (test_bit(BLK_MQ_S_TAG_WAITING, &hctx->state) ||
 -	    test_and_set_bit_lock(BLK_MQ_S_TAG_WAITING, &hctx->state))
 -		return false;
 -
 -	init_waitqueue_func_entry(&hctx->dispatch_wait, blk_mq_dispatch_wake);
 -	ws = bt_wait_ptr(&hctx->tags->bitmap_tags, hctx);
 -
 -	/*
 -	 * As soon as this returns, it's no longer safe to fiddle with
 -	 * hctx->dispatch_wait, since a completion can wake up the wait queue
 -	 * and unlock the bit.
 -	 */
 -	add_wait_queue(&ws->wait, &hctx->dispatch_wait);
 -	return true;
 -}
 -
 -bool blk_mq_dispatch_rq_list(struct request_queue *q, struct list_head *list,
 -		bool got_budget)
 -{
 -	struct blk_mq_hw_ctx *hctx;
 -	struct request *rq, *nxt;
 -	int errors, queued;
 -
 -	if (list_empty(list))
 -		return false;
 -
 -	WARN_ON(!list_is_singular(list) && got_budget);
 +	dptr = NULL;
  
  	/*
  	 * Now process all the entries, sending them to the driver.
diff --cc block/blk-mq.h
index 2d50f02667c4,2502f40ccdc0..000000000000
--- a/block/blk-mq.h
+++ b/block/blk-mq.h
@@@ -1,7 -1,8 +1,12 @@@
  #ifndef INT_BLK_MQ_H
  #define INT_BLK_MQ_H
  
++<<<<<<< HEAD
 +#include <linux/rh_kabi.h>
++=======
+ #include "blk-stat.h"
+ #include "blk-mq-tag.h"
++>>>>>>> 244c65a3ccaa (blk-mq: move blk_mq_put_driver_tag*() into blk-mq.h)
  
  struct blk_mq_tag_set;
  
@@@ -126,4 -137,56 +131,59 @@@ static inline bool blk_mq_hw_queue_mapp
  	return hctx->nr_ctx && hctx->tags;
  }
  
++<<<<<<< HEAD
++=======
+ void blk_mq_in_flight(struct request_queue *q, struct hd_struct *part,
+ 			unsigned int inflight[2]);
+ 
+ static inline void blk_mq_put_dispatch_budget(struct blk_mq_hw_ctx *hctx)
+ {
+ 	struct request_queue *q = hctx->queue;
+ 
+ 	if (q->mq_ops->put_budget)
+ 		q->mq_ops->put_budget(hctx);
+ }
+ 
+ static inline bool blk_mq_get_dispatch_budget(struct blk_mq_hw_ctx *hctx)
+ {
+ 	struct request_queue *q = hctx->queue;
+ 
+ 	if (q->mq_ops->get_budget)
+ 		return q->mq_ops->get_budget(hctx);
+ 	return true;
+ }
+ 
+ static inline void __blk_mq_put_driver_tag(struct blk_mq_hw_ctx *hctx,
+ 					   struct request *rq)
+ {
+ 	blk_mq_put_tag(hctx, hctx->tags, rq->mq_ctx, rq->tag);
+ 	rq->tag = -1;
+ 
+ 	if (rq->rq_flags & RQF_MQ_INFLIGHT) {
+ 		rq->rq_flags &= ~RQF_MQ_INFLIGHT;
+ 		atomic_dec(&hctx->nr_active);
+ 	}
+ }
+ 
+ static inline void blk_mq_put_driver_tag_hctx(struct blk_mq_hw_ctx *hctx,
+ 				       struct request *rq)
+ {
+ 	if (rq->tag == -1 || rq->internal_tag == -1)
+ 		return;
+ 
+ 	__blk_mq_put_driver_tag(hctx, rq);
+ }
+ 
+ static inline void blk_mq_put_driver_tag(struct request *rq)
+ {
+ 	struct blk_mq_hw_ctx *hctx;
+ 
+ 	if (rq->tag == -1 || rq->internal_tag == -1)
+ 		return;
+ 
+ 	hctx = blk_mq_map_queue(rq->q, rq->mq_ctx->cpu);
+ 	__blk_mq_put_driver_tag(hctx, rq);
+ }
+ 
++>>>>>>> 244c65a3ccaa (blk-mq: move blk_mq_put_driver_tag*() into blk-mq.h)
  #endif
* Unmerged path block/blk-mq.c
* Unmerged path block/blk-mq.h
