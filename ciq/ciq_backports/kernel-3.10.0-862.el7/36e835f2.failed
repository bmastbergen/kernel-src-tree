nvme-rdma: add support for duplicate_connect option

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author James Smart <jsmart2021@gmail.com>
commit 36e835f2432d8f16845307b5fb7e88d1e5af041d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/36e835f2.failed

Adds support for the duplicate_connect option. When set to true,
checks whether there's an existing controller via the same target
address (traddr), target port (trsvcid), and if specified, host
address (host_traddr). Fails the connection request if there is
an existing controller.

	Signed-off-by: James Smart <james.smart@broadcom.com>
	Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
(cherry picked from commit 36e835f2432d8f16845307b5fb7e88d1e5af041d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/rdma.c
diff --cc drivers/nvme/host/rdma.c
index d32f781f91a5,32b0a9ef26e6..000000000000
--- a/drivers/nvme/host/rdma.c
+++ b/drivers/nvme/host/rdma.c
@@@ -1805,79 -1847,85 +1805,157 @@@ static const struct nvme_ctrl_ops nvme_
  	.free_ctrl		= nvme_rdma_free_ctrl,
  	.submit_async_event	= nvme_rdma_submit_async_event,
  	.delete_ctrl		= nvme_rdma_del_ctrl,
 +	.get_subsysnqn		= nvmf_get_subsysnqn,
  	.get_address		= nvmf_get_address,
 -	.reinit_request		= nvme_rdma_reinit_request,
  };
  
++<<<<<<< HEAD
 +static int nvme_rdma_create_io_queues(struct nvme_rdma_ctrl *ctrl)
 +{
 +	int ret;
 +
 +	ret = nvme_rdma_init_io_queues(ctrl);
 +	if (ret)
 +		return ret;
 +
 +	/*
 +	 * We need a reference on the device as long as the tag_set is alive,
 +	 * as the MRs in the request structures need a valid ib_device.
 +	 */
 +	ret = -EINVAL;
 +	if (!nvme_rdma_dev_get(ctrl->device))
 +		goto out_free_io_queues;
 +
 +	memset(&ctrl->tag_set, 0, sizeof(ctrl->tag_set));
 +	ctrl->tag_set.ops = &nvme_rdma_mq_ops;
 +	ctrl->tag_set.queue_depth = ctrl->ctrl.opts->queue_size;
 +	ctrl->tag_set.reserved_tags = 1; /* fabric connect */
 +	ctrl->tag_set.numa_node = NUMA_NO_NODE;
 +	ctrl->tag_set.flags = BLK_MQ_F_SHOULD_MERGE;
 +	ctrl->tag_set.cmd_size = sizeof(struct nvme_rdma_request) +
 +		SG_CHUNK_SIZE * sizeof(struct scatterlist);
 +	ctrl->tag_set.driver_data = ctrl;
 +	ctrl->tag_set.nr_hw_queues = ctrl->queue_count - 1;
 +	ctrl->tag_set.timeout = NVME_IO_TIMEOUT;
 +
 +	ret = blk_mq_alloc_tag_set(&ctrl->tag_set);
 +	if (ret)
 +		goto out_put_dev;
 +	ctrl->ctrl.tagset = &ctrl->tag_set;
 +
 +	ctrl->ctrl.connect_q = blk_mq_init_queue(&ctrl->tag_set);
 +	if (IS_ERR(ctrl->ctrl.connect_q)) {
 +		ret = PTR_ERR(ctrl->ctrl.connect_q);
 +		goto out_free_tag_set;
 +	}
 +
 +	ret = nvme_rdma_connect_io_queues(ctrl);
 +	if (ret)
 +		goto out_cleanup_connect_q;
 +
 +	return 0;
 +
 +out_cleanup_connect_q:
 +	blk_cleanup_queue(ctrl->ctrl.connect_q);
 +out_free_tag_set:
 +	blk_mq_free_tag_set(&ctrl->tag_set);
 +out_put_dev:
 +	nvme_rdma_dev_put(ctrl->device);
 +out_free_io_queues:
 +	nvme_rdma_free_io_queues(ctrl);
 +	return ret;
 +}
 +
 +static int nvme_rdma_parse_ipaddr(struct sockaddr_in *in_addr, char *p)
 +{
 +	u8 *addr = (u8 *)&in_addr->sin_addr.s_addr;
 +	size_t buflen = strlen(p);
 +
 +	/* XXX: handle IPv6 addresses */
 +
 +	if (buflen > INET_ADDRSTRLEN)
 +		return -EINVAL;
 +	if (in4_pton(p, buflen, addr, '\0', NULL) == 0)
 +		return -EINVAL;
 +	in_addr->sin_family = AF_INET;
 +	return 0;
++=======
+ static inline bool
+ __nvme_rdma_options_match(struct nvme_rdma_ctrl *ctrl,
+ 	struct nvmf_ctrl_options *opts)
+ {
+ 	char *stdport = __stringify(NVME_RDMA_IP_PORT);
+ 
+ 
+ 	if (!nvmf_ctlr_matches_baseopts(&ctrl->ctrl, opts) ||
+ 	    strcmp(opts->traddr, ctrl->ctrl.opts->traddr))
+ 		return false;
+ 
+ 	if (opts->mask & NVMF_OPT_TRSVCID &&
+ 	    ctrl->ctrl.opts->mask & NVMF_OPT_TRSVCID) {
+ 		if (strcmp(opts->trsvcid, ctrl->ctrl.opts->trsvcid))
+ 			return false;
+ 	} else if (opts->mask & NVMF_OPT_TRSVCID) {
+ 		if (strcmp(opts->trsvcid, stdport))
+ 			return false;
+ 	} else if (ctrl->ctrl.opts->mask & NVMF_OPT_TRSVCID) {
+ 		if (strcmp(stdport, ctrl->ctrl.opts->trsvcid))
+ 			return false;
+ 	}
+ 	/* else, it's a match as both have stdport. Fall to next checks */
+ 
+ 	/*
+ 	 * checking the local address is rough. In most cases, one
+ 	 * is not specified and the host port is selected by the stack.
+ 	 *
+ 	 * Assume no match if:
+ 	 *  local address is specified and address is not the same
+ 	 *  local address is not specified but remote is, or vice versa
+ 	 *    (admin using specific host_traddr when it matters).
+ 	 */
+ 	if (opts->mask & NVMF_OPT_HOST_TRADDR &&
+ 	    ctrl->ctrl.opts->mask & NVMF_OPT_HOST_TRADDR) {
+ 		if (strcmp(opts->host_traddr, ctrl->ctrl.opts->host_traddr))
+ 			return false;
+ 	} else if (opts->mask & NVMF_OPT_HOST_TRADDR ||
+ 		   ctrl->ctrl.opts->mask & NVMF_OPT_HOST_TRADDR)
+ 		return false;
+ 	/*
+ 	 * if neither controller had an host port specified, assume it's
+ 	 * a match as everything else matched.
+ 	 */
+ 
+ 	return true;
+ }
+ 
+ /*
+  * Fails a connection request if it matches an existing controller
+  * (association) with the same tuple:
+  * <Host NQN, Host ID, local address, remote address, remote port, SUBSYS NQN>
+  *
+  * if local address is not specified in the request, it will match an
+  * existing controller with all the other parameters the same and no
+  * local port address specified as well.
+  *
+  * The ports don't need to be compared as they are intrinsically
+  * already matched by the port pointers supplied.
+  */
+ static bool
+ nvme_rdma_existing_controller(struct nvmf_ctrl_options *opts)
+ {
+ 	struct nvme_rdma_ctrl *ctrl;
+ 	bool found = false;
+ 
+ 	mutex_lock(&nvme_rdma_ctrl_mutex);
+ 	list_for_each_entry(ctrl, &nvme_rdma_ctrl_list, list) {
+ 		found = __nvme_rdma_options_match(ctrl, opts);
+ 		if (found)
+ 			break;
+ 	}
+ 	mutex_unlock(&nvme_rdma_ctrl_mutex);
+ 
+ 	return found;
++>>>>>>> 36e835f2432d (nvme-rdma: add support for duplicate_connect option)
  }
  
  static struct nvme_ctrl *nvme_rdma_create_ctrl(struct device *dev,
@@@ -1899,18 -1954,21 +1977,23 @@@
  		goto out_free_ctrl;
  	}
  
 -	if (opts->mask & NVMF_OPT_HOST_TRADDR) {
 -		ret = inet_pton_with_scope(&init_net, AF_UNSPEC,
 -			opts->host_traddr, NULL, &ctrl->src_addr);
 -		if (ret) {
 -			pr_err("malformed src address passed: %s\n",
 -			       opts->host_traddr);
 +	if (opts->mask & NVMF_OPT_TRSVCID) {
 +		u16 port;
 +
 +		ret = kstrtou16(opts->trsvcid, 0, &port);
 +		if (ret)
  			goto out_free_ctrl;
 -		}
 +
 +		ctrl->addr_in.sin_port = cpu_to_be16(port);
 +	} else {
 +		ctrl->addr_in.sin_port = cpu_to_be16(NVME_RDMA_IP_PORT);
  	}
  
+ 	if (!opts->duplicate_connect && nvme_rdma_existing_controller(opts)) {
+ 		ret = -EALREADY;
+ 		goto out_free_ctrl;
+ 	}
+ 
  	ret = nvme_init_ctrl(&ctrl->ctrl, dev, &nvme_rdma_ctrl_ops,
  				0 /* no quirks, we're perfect! */);
  	if (ret)
* Unmerged path drivers/nvme/host/rdma.c
