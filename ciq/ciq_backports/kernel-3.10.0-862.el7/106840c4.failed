crypto: aesni - fix typo in generic_gcmaes_decrypt

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [crypto] aesni: fix typo in generic_gcmaes_decrypt (Sabrina Dubroca) [1525527]
Rebuild_FUZZ: 87.91%
commit-author Sabrina Dubroca <sd@queasysnail.net>
commit 106840c41096a01079d3a2025225029c13713802
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/106840c4.failed

generic_gcmaes_decrypt needs to use generic_gcmaes_ctx, not
aesni_rfc4106_gcm_ctx. This is actually harmless because the fields in
struct generic_gcmaes_ctx share the layout of the same fields in
aesni_rfc4106_gcm_ctx.

Fixes: cce2ea8d90fe ("crypto: aesni - add generic gcm(aes)")
	Cc: <stable@vger.kernel.org>
	Signed-off-by: Sabrina Dubroca <sd@queasysnail.net>
	Reviewed-by: Stefano Brivio <sbrivio@redhat.com>
	Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
(cherry picked from commit 106840c41096a01079d3a2025225029c13713802)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/crypto/aesni-intel_glue.c
diff --cc arch/x86/crypto/aesni-intel_glue.c
index 521e258e2cca,8981ed1eb7ad..000000000000
--- a/arch/x86/crypto/aesni-intel_glue.c
+++ b/arch/x86/crypto/aesni-intel_glue.c
@@@ -1105,291 -996,193 +1105,428 @@@ static struct crypto_alg aesni_algs[] 
  			.cia_decrypt		= __aes_decrypt
  		}
  	}
 -} };
 -
 -static struct skcipher_alg aesni_skciphers[] = {
 -	{
 -		.base = {
 -			.cra_name		= "__ecb(aes)",
 -			.cra_driver_name	= "__ecb-aes-aesni",
 -			.cra_priority		= 400,
 -			.cra_flags		= CRYPTO_ALG_INTERNAL,
 -			.cra_blocksize		= AES_BLOCK_SIZE,
 -			.cra_ctxsize		= CRYPTO_AES_CTX_SIZE,
 -			.cra_module		= THIS_MODULE,
 +}, {
 +	.cra_name		= "__ecb-aes-aesni",
 +	.cra_driver_name	= "__driver-ecb-aes-aesni",
 +	.cra_priority		= 0,
 +	.cra_flags		= CRYPTO_ALG_TYPE_BLKCIPHER |
 +				  CRYPTO_ALG_INTERNAL,
 +	.cra_blocksize		= AES_BLOCK_SIZE,
 +	.cra_ctxsize		= sizeof(struct crypto_aes_ctx) +
 +				  AESNI_ALIGN - 1,
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_blkcipher_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_u = {
 +		.blkcipher = {
 +			.min_keysize	= AES_MIN_KEY_SIZE,
 +			.max_keysize	= AES_MAX_KEY_SIZE,
 +			.setkey		= aes_set_key,
 +			.encrypt	= ecb_encrypt,
 +			.decrypt	= ecb_decrypt,
  		},
++<<<<<<< HEAD
++=======
+ 		.min_keysize	= AES_MIN_KEY_SIZE,
+ 		.max_keysize	= AES_MAX_KEY_SIZE,
+ 		.setkey		= aesni_skcipher_setkey,
+ 		.encrypt	= ecb_encrypt,
+ 		.decrypt	= ecb_decrypt,
+ 	}, {
+ 		.base = {
+ 			.cra_name		= "__cbc(aes)",
+ 			.cra_driver_name	= "__cbc-aes-aesni",
+ 			.cra_priority		= 400,
+ 			.cra_flags		= CRYPTO_ALG_INTERNAL,
+ 			.cra_blocksize		= AES_BLOCK_SIZE,
+ 			.cra_ctxsize		= CRYPTO_AES_CTX_SIZE,
+ 			.cra_module		= THIS_MODULE,
+ 		},
+ 		.min_keysize	= AES_MIN_KEY_SIZE,
+ 		.max_keysize	= AES_MAX_KEY_SIZE,
+ 		.ivsize		= AES_BLOCK_SIZE,
+ 		.setkey		= aesni_skcipher_setkey,
+ 		.encrypt	= cbc_encrypt,
+ 		.decrypt	= cbc_decrypt,
+ #ifdef CONFIG_X86_64
+ 	}, {
+ 		.base = {
+ 			.cra_name		= "__ctr(aes)",
+ 			.cra_driver_name	= "__ctr-aes-aesni",
+ 			.cra_priority		= 400,
+ 			.cra_flags		= CRYPTO_ALG_INTERNAL,
+ 			.cra_blocksize		= 1,
+ 			.cra_ctxsize		= CRYPTO_AES_CTX_SIZE,
+ 			.cra_module		= THIS_MODULE,
+ 		},
+ 		.min_keysize	= AES_MIN_KEY_SIZE,
+ 		.max_keysize	= AES_MAX_KEY_SIZE,
+ 		.ivsize		= AES_BLOCK_SIZE,
+ 		.chunksize	= AES_BLOCK_SIZE,
+ 		.setkey		= aesni_skcipher_setkey,
+ 		.encrypt	= ctr_crypt,
+ 		.decrypt	= ctr_crypt,
+ 	}, {
+ 		.base = {
+ 			.cra_name		= "__xts(aes)",
+ 			.cra_driver_name	= "__xts-aes-aesni",
+ 			.cra_priority		= 401,
+ 			.cra_flags		= CRYPTO_ALG_INTERNAL,
+ 			.cra_blocksize		= AES_BLOCK_SIZE,
+ 			.cra_ctxsize		= XTS_AES_CTX_SIZE,
+ 			.cra_module		= THIS_MODULE,
+ 		},
+ 		.min_keysize	= 2 * AES_MIN_KEY_SIZE,
+ 		.max_keysize	= 2 * AES_MAX_KEY_SIZE,
+ 		.ivsize		= AES_BLOCK_SIZE,
+ 		.setkey		= xts_aesni_setkey,
+ 		.encrypt	= xts_encrypt,
+ 		.decrypt	= xts_decrypt,
+ #endif
+ 	}
+ };
+ 
+ static
+ struct simd_skcipher_alg *aesni_simd_skciphers[ARRAY_SIZE(aesni_skciphers)];
+ 
+ static struct {
+ 	const char *algname;
+ 	const char *drvname;
+ 	const char *basename;
+ 	struct simd_skcipher_alg *simd;
+ } aesni_simd_skciphers2[] = {
+ #if (defined(MODULE) && IS_ENABLED(CONFIG_CRYPTO_PCBC)) || \
+     IS_BUILTIN(CONFIG_CRYPTO_PCBC)
+ 	{
+ 		.algname	= "pcbc(aes)",
+ 		.drvname	= "pcbc-aes-aesni",
+ 		.basename	= "fpu(pcbc(__aes-aesni))",
+ 	},
+ #endif
+ };
+ 
+ #ifdef CONFIG_X86_64
+ static int generic_gcmaes_set_key(struct crypto_aead *aead, const u8 *key,
+ 				  unsigned int key_len)
+ {
+ 	struct generic_gcmaes_ctx *ctx = generic_gcmaes_ctx_get(aead);
+ 
+ 	return aes_set_key_common(crypto_aead_tfm(aead),
+ 				  &ctx->aes_key_expanded, key, key_len) ?:
+ 	       rfc4106_set_hash_subkey(ctx->hash_subkey, key, key_len);
+ }
+ 
+ static int generic_gcmaes_encrypt(struct aead_request *req)
+ {
+ 	struct crypto_aead *tfm = crypto_aead_reqtfm(req);
+ 	struct generic_gcmaes_ctx *ctx = generic_gcmaes_ctx_get(tfm);
+ 	void *aes_ctx = &(ctx->aes_key_expanded);
+ 	u8 iv[16] __attribute__ ((__aligned__(AESNI_ALIGN)));
+ 	__be32 counter = cpu_to_be32(1);
+ 
+ 	memcpy(iv, req->iv, 12);
+ 	*((__be32 *)(iv+12)) = counter;
+ 
+ 	return gcmaes_encrypt(req, req->assoclen, ctx->hash_subkey, iv,
+ 			      aes_ctx);
+ }
+ 
+ static int generic_gcmaes_decrypt(struct aead_request *req)
+ {
+ 	__be32 counter = cpu_to_be32(1);
+ 	struct crypto_aead *tfm = crypto_aead_reqtfm(req);
+ 	struct generic_gcmaes_ctx *ctx = generic_gcmaes_ctx_get(tfm);
+ 	void *aes_ctx = &(ctx->aes_key_expanded);
+ 	u8 iv[16] __attribute__ ((__aligned__(AESNI_ALIGN)));
+ 
+ 	memcpy(iv, req->iv, 12);
+ 	*((__be32 *)(iv+12)) = counter;
+ 
+ 	return gcmaes_decrypt(req, req->assoclen, ctx->hash_subkey, iv,
+ 			      aes_ctx);
+ }
+ 
+ static struct aead_alg aesni_aead_algs[] = { {
+ 	.setkey			= common_rfc4106_set_key,
+ 	.setauthsize		= common_rfc4106_set_authsize,
+ 	.encrypt		= helper_rfc4106_encrypt,
+ 	.decrypt		= helper_rfc4106_decrypt,
+ 	.ivsize			= GCM_RFC4106_IV_SIZE,
+ 	.maxauthsize		= 16,
+ 	.base = {
+ 		.cra_name		= "__gcm-aes-aesni",
+ 		.cra_driver_name	= "__driver-gcm-aes-aesni",
+ 		.cra_flags		= CRYPTO_ALG_INTERNAL,
+ 		.cra_blocksize		= 1,
+ 		.cra_ctxsize		= sizeof(struct aesni_rfc4106_gcm_ctx),
+ 		.cra_alignmask		= AESNI_ALIGN - 1,
+ 		.cra_module		= THIS_MODULE,
++>>>>>>> 106840c41096 (crypto: aesni - fix typo in generic_gcmaes_decrypt)
  	},
  }, {
 -	.init			= rfc4106_init,
 -	.exit			= rfc4106_exit,
 -	.setkey			= rfc4106_set_key,
 -	.setauthsize		= rfc4106_set_authsize,
 -	.encrypt		= rfc4106_encrypt,
 -	.decrypt		= rfc4106_decrypt,
 -	.ivsize			= GCM_RFC4106_IV_SIZE,
 -	.maxauthsize		= 16,
 -	.base = {
 -		.cra_name		= "rfc4106(gcm(aes))",
 -		.cra_driver_name	= "rfc4106-gcm-aesni",
 -		.cra_priority		= 400,
 -		.cra_flags		= CRYPTO_ALG_ASYNC,
 -		.cra_blocksize		= 1,
 -		.cra_ctxsize		= sizeof(struct cryptd_aead *),
 -		.cra_module		= THIS_MODULE,
 +	.cra_name		= "__cbc-aes-aesni",
 +	.cra_driver_name	= "__driver-cbc-aes-aesni",
 +	.cra_priority		= 0,
 +	.cra_flags		= CRYPTO_ALG_TYPE_BLKCIPHER |
 +				  CRYPTO_ALG_INTERNAL,
 +	.cra_blocksize		= AES_BLOCK_SIZE,
 +	.cra_ctxsize		= sizeof(struct crypto_aes_ctx) +
 +				  AESNI_ALIGN - 1,
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_blkcipher_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_u = {
 +		.blkcipher = {
 +			.min_keysize	= AES_MIN_KEY_SIZE,
 +			.max_keysize	= AES_MAX_KEY_SIZE,
 +			.setkey		= aes_set_key,
 +			.encrypt	= cbc_encrypt,
 +			.decrypt	= cbc_decrypt,
 +		},
  	},
  }, {
 -	.setkey			= generic_gcmaes_set_key,
 -	.setauthsize		= generic_gcmaes_set_authsize,
 -	.encrypt		= generic_gcmaes_encrypt,
 -	.decrypt		= generic_gcmaes_decrypt,
 -	.ivsize			= GCM_AES_IV_SIZE,
 -	.maxauthsize		= 16,
 -	.base = {
 -		.cra_name		= "gcm(aes)",
 -		.cra_driver_name	= "generic-gcm-aesni",
 -		.cra_priority		= 400,
 -		.cra_flags		= CRYPTO_ALG_ASYNC,
 -		.cra_blocksize		= 1,
 -		.cra_ctxsize		= sizeof(struct generic_gcmaes_ctx),
 -		.cra_alignmask		= AESNI_ALIGN - 1,
 -		.cra_module		= THIS_MODULE,
 +	.cra_name		= "ecb(aes)",
 +	.cra_driver_name	= "ecb-aes-aesni",
 +	.cra_priority		= 400,
 +	.cra_flags		= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
 +	.cra_blocksize		= AES_BLOCK_SIZE,
 +	.cra_ctxsize		= sizeof(struct async_helper_ctx),
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_ablkcipher_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_init		= ablk_ecb_init,
 +	.cra_exit		= ablk_exit,
 +	.cra_u = {
 +		.ablkcipher = {
 +			.min_keysize	= AES_MIN_KEY_SIZE,
 +			.max_keysize	= AES_MAX_KEY_SIZE,
 +			.setkey		= ablk_set_key,
 +			.encrypt	= ablk_encrypt,
 +			.decrypt	= ablk_decrypt,
 +		},
 +	},
 +}, {
 +	.cra_name		= "cbc(aes)",
 +	.cra_driver_name	= "cbc-aes-aesni",
 +	.cra_priority		= 400,
 +	.cra_flags		= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
 +	.cra_blocksize		= AES_BLOCK_SIZE,
 +	.cra_ctxsize		= sizeof(struct async_helper_ctx),
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_ablkcipher_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_init		= ablk_cbc_init,
 +	.cra_exit		= ablk_exit,
 +	.cra_u = {
 +		.ablkcipher = {
 +			.min_keysize	= AES_MIN_KEY_SIZE,
 +			.max_keysize	= AES_MAX_KEY_SIZE,
 +			.ivsize		= AES_BLOCK_SIZE,
 +			.setkey		= ablk_set_key,
 +			.encrypt	= ablk_encrypt,
 +			.decrypt	= ablk_decrypt,
 +		},
 +	},
 +#ifdef CONFIG_X86_64
 +}, {
 +	.cra_name		= "__ctr-aes-aesni",
 +	.cra_driver_name	= "__driver-ctr-aes-aesni",
 +	.cra_priority		= 0,
 +	.cra_flags		= CRYPTO_ALG_TYPE_BLKCIPHER |
 +				  CRYPTO_ALG_INTERNAL,
 +	.cra_blocksize		= 1,
 +	.cra_ctxsize		= sizeof(struct crypto_aes_ctx) +
 +				  AESNI_ALIGN - 1,
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_blkcipher_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_u = {
 +		.blkcipher = {
 +			.min_keysize	= AES_MIN_KEY_SIZE,
 +			.max_keysize	= AES_MAX_KEY_SIZE,
 +			.ivsize		= AES_BLOCK_SIZE,
 +			.setkey		= aes_set_key,
 +			.encrypt	= ctr_crypt,
 +			.decrypt	= ctr_crypt,
 +		},
 +	},
 +}, {
 +	.cra_name		= "ctr(aes)",
 +	.cra_driver_name	= "ctr-aes-aesni",
 +	.cra_priority		= 400,
 +	.cra_flags		= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
 +	.cra_blocksize		= 1,
 +	.cra_ctxsize		= sizeof(struct async_helper_ctx),
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_ablkcipher_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_init		= ablk_ctr_init,
 +	.cra_exit		= ablk_exit,
 +	.cra_u = {
 +		.ablkcipher = {
 +			.min_keysize	= AES_MIN_KEY_SIZE,
 +			.max_keysize	= AES_MAX_KEY_SIZE,
 +			.ivsize		= AES_BLOCK_SIZE,
 +			.setkey		= ablk_set_key,
 +			.encrypt	= ablk_encrypt,
 +			.decrypt	= ablk_encrypt,
 +			.geniv		= "chainiv",
 +		},
 +	},
 +}, {
 +	.cra_name		= "__gcm-aes-aesni",
 +	.cra_driver_name	= "__driver-gcm-aes-aesni",
 +	.cra_priority		= 0,
 +	.cra_flags		= CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_INTERNAL,
 +	.cra_blocksize		= 1,
 +	.cra_ctxsize		= sizeof(struct aesni_rfc4106_gcm_ctx) +
 +				  AESNI_ALIGN,
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_aead_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_u = {
 +		.aead = {
 +			.encrypt	= __driver_rfc4106_encrypt,
 +			.decrypt	= __driver_rfc4106_decrypt,
 +		},
 +	},
 +}, {
 +	.cra_name		= "rfc4106(gcm(aes))",
 +	.cra_driver_name	= "rfc4106-gcm-aesni",
 +	.cra_priority		= 400,
 +	.cra_flags		= CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,
 +	.cra_blocksize		= 1,
 +	.cra_ctxsize		= sizeof(struct aesni_rfc4106_gcm_ctx) +
 +				  AESNI_ALIGN,
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_nivaead_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_init		= rfc4106_init,
 +	.cra_exit		= rfc4106_exit,
 +	.cra_u = {
 +		.aead = {
 +			.setkey		= rfc4106_set_key,
 +			.setauthsize	= rfc4106_set_authsize,
 +			.encrypt	= rfc4106_encrypt,
 +			.decrypt	= rfc4106_decrypt,
 +			.geniv		= "seqiv",
 +			.ivsize		= 8,
 +			.maxauthsize	= 16,
 +		},
 +	},
 +#endif
 +#ifdef HAS_PCBC
 +}, {
 +	.cra_name		= "pcbc(aes)",
 +	.cra_driver_name	= "pcbc-aes-aesni",
 +	.cra_priority		= 400,
 +	.cra_flags		= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
 +	.cra_blocksize		= AES_BLOCK_SIZE,
 +	.cra_ctxsize		= sizeof(struct async_helper_ctx),
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_ablkcipher_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_init		= ablk_pcbc_init,
 +	.cra_exit		= ablk_exit,
 +	.cra_u = {
 +		.ablkcipher = {
 +			.min_keysize	= AES_MIN_KEY_SIZE,
 +			.max_keysize	= AES_MAX_KEY_SIZE,
 +			.ivsize		= AES_BLOCK_SIZE,
 +			.setkey		= ablk_set_key,
 +			.encrypt	= ablk_encrypt,
 +			.decrypt	= ablk_decrypt,
 +		},
  	},
 -} };
 -#else
 -static struct aead_alg aesni_aead_algs[0];
  #endif
 +}, {
 +	.cra_name		= "__lrw-aes-aesni",
 +	.cra_driver_name	= "__driver-lrw-aes-aesni",
 +	.cra_priority		= 0,
 +	.cra_flags		= CRYPTO_ALG_TYPE_BLKCIPHER |
 +				  CRYPTO_ALG_INTERNAL,
 +	.cra_blocksize		= AES_BLOCK_SIZE,
 +	.cra_ctxsize		= sizeof(struct aesni_lrw_ctx),
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_blkcipher_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_exit		= lrw_aesni_exit_tfm,
 +	.cra_u = {
 +		.blkcipher = {
 +			.min_keysize	= AES_MIN_KEY_SIZE + AES_BLOCK_SIZE,
 +			.max_keysize	= AES_MAX_KEY_SIZE + AES_BLOCK_SIZE,
 +			.ivsize		= AES_BLOCK_SIZE,
 +			.setkey		= lrw_aesni_setkey,
 +			.encrypt	= lrw_encrypt,
 +			.decrypt	= lrw_decrypt,
 +		},
 +	},
 +}, {
 +	.cra_name		= "__xts-aes-aesni",
 +	.cra_driver_name	= "__driver-xts-aes-aesni",
 +	.cra_priority		= 0,
 +	.cra_flags		= CRYPTO_ALG_TYPE_BLKCIPHER |
 +				  CRYPTO_ALG_INTERNAL,
 +	.cra_blocksize		= AES_BLOCK_SIZE,
 +	.cra_ctxsize		= sizeof(struct aesni_xts_ctx),
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_blkcipher_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_u = {
 +		.blkcipher = {
 +			.min_keysize	= 2 * AES_MIN_KEY_SIZE,
 +			.max_keysize	= 2 * AES_MAX_KEY_SIZE,
 +			.ivsize		= AES_BLOCK_SIZE,
 +			.setkey		= xts_aesni_setkey,
 +			.encrypt	= xts_encrypt,
 +			.decrypt	= xts_decrypt,
 +		},
 +	},
 +}, {
 +	.cra_name		= "lrw(aes)",
 +	.cra_driver_name	= "lrw-aes-aesni",
 +	.cra_priority		= 400,
 +	.cra_flags		= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
 +	.cra_blocksize		= AES_BLOCK_SIZE,
 +	.cra_ctxsize		= sizeof(struct async_helper_ctx),
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_ablkcipher_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_init		= ablk_init,
 +	.cra_exit		= ablk_exit,
 +	.cra_u = {
 +		.ablkcipher = {
 +			.min_keysize	= AES_MIN_KEY_SIZE + AES_BLOCK_SIZE,
 +			.max_keysize	= AES_MAX_KEY_SIZE + AES_BLOCK_SIZE,
 +			.ivsize		= AES_BLOCK_SIZE,
 +			.setkey		= ablk_set_key,
 +			.encrypt	= ablk_encrypt,
 +			.decrypt	= ablk_decrypt,
 +		},
 +	},
 +}, {
 +	.cra_name		= "xts(aes)",
 +	.cra_driver_name	= "xts-aes-aesni",
 +	.cra_priority		= 400,
 +	.cra_flags		= CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
 +	.cra_blocksize		= AES_BLOCK_SIZE,
 +	.cra_ctxsize		= sizeof(struct async_helper_ctx),
 +	.cra_alignmask		= 0,
 +	.cra_type		= &crypto_ablkcipher_type,
 +	.cra_module		= THIS_MODULE,
 +	.cra_init		= ablk_init,
 +	.cra_exit		= ablk_exit,
 +	.cra_u = {
 +		.ablkcipher = {
 +			.min_keysize	= 2 * AES_MIN_KEY_SIZE,
 +			.max_keysize	= 2 * AES_MAX_KEY_SIZE,
 +			.ivsize		= AES_BLOCK_SIZE,
 +			.setkey		= ablk_set_key,
 +			.encrypt	= ablk_encrypt,
 +			.decrypt	= ablk_decrypt,
 +		},
 +	},
 +} };
  
  
  static const struct x86_cpu_id aesni_cpu_id[] = {
* Unmerged path arch/x86/crypto/aesni-intel_glue.c
