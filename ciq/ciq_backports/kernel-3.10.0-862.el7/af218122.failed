sched/topology: Simplify sched_group_mask() usage

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Peter Zijlstra <peterz@infradead.org>
commit af218122b103900fa33d408aea0c2468791e698c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/af218122.failed

While writing the comments, it occurred to me that:

  sg_cpus & sg_mask == sg_mask

at least conceptually; the !overlap case sets the all 1s mask. If we
correct that we can simplify things and directly use sg_mask.

	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Mike Galbraith <efault@gmx.de>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: linux-kernel@vger.kernel.org
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit af218122b103900fa33d408aea0c2468791e698c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/topology.c
* Unmerged path kernel/sched/topology.c
diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 38afc41c3538..7048c02a8ad4 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -6404,7 +6404,7 @@ static int active_load_balance_cpu_stop(void *data);
 static int should_we_balance(struct lb_env *env)
 {
 	struct sched_group *sg = env->sd->groups;
-	struct cpumask *sg_cpus, *sg_mask;
+	struct cpumask *sg_mask;
 	int cpu, balance_cpu = -1;
 
 	/*
@@ -6414,11 +6414,10 @@ static int should_we_balance(struct lb_env *env)
 	if (env->idle == CPU_NEWLY_IDLE)
 		return 1;
 
-	sg_cpus = sched_group_cpus(sg);
 	sg_mask = sched_group_mask(sg);
 	/* Try to find first idle cpu */
-	for_each_cpu_and(cpu, sg_cpus, env->cpus) {
-		if (!cpumask_test_cpu(cpu, sg_mask) || !idle_cpu(cpu))
+	for_each_cpu_and(cpu, sg_mask, env->cpus) {
+		if (!idle_cpu(cpu))
 			continue;
 
 		balance_cpu = cpu;
* Unmerged path kernel/sched/topology.c
