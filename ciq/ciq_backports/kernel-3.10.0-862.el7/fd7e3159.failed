x86/mm: Simplify p[g4um]d_page() macros

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [x86] mm: Simplify p[g4um]d_page() macros (Suravee Suthikulpanit) [1361287]
Rebuild_FUZZ: 94.59%
commit-author Tom Lendacky <thomas.lendacky@amd.com>
commit fd7e315988b784509ba3f1b42f539bd0b1fca9bb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/fd7e3159.failed

Create a pgd_pfn() macro similar to the p[4um]d_pfn() macros and then
use the p[g4um]d_pfn() macros in the p[g4um]d_page() macros instead of
duplicating the code.

	Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
	Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
	Reviewed-by: Borislav Petkov <bp@suse.de>
	Cc: Alexander Potapenko <glider@google.com>
	Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Arnd Bergmann <arnd@arndb.de>
	Cc: Borislav Petkov <bp@alien8.de>
	Cc: Brijesh Singh <brijesh.singh@amd.com>
	Cc: Dave Young <dyoung@redhat.com>
	Cc: Dmitry Vyukov <dvyukov@google.com>
	Cc: Jonathan Corbet <corbet@lwn.net>
	Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
	Cc: Larry Woodman <lwoodman@redhat.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Matt Fleming <matt@codeblueprint.co.uk>
	Cc: Michael S. Tsirkin <mst@redhat.com>
	Cc: Paolo Bonzini <pbonzini@redhat.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Radim Krčmář <rkrcmar@redhat.com>
	Cc: Rik van Riel <riel@redhat.com>
	Cc: Toshimitsu Kani <toshi.kani@hpe.com>
	Cc: kasan-dev@googlegroups.com
	Cc: kvm@vger.kernel.org
	Cc: linux-arch@vger.kernel.org
	Cc: linux-doc@vger.kernel.org
	Cc: linux-efi@vger.kernel.org
	Cc: linux-mm@kvack.org
Link: http://lkml.kernel.org/r/e61eb533a6d0aac941db2723d8aa63ef6b882dee.1500319216.git.thomas.lendacky@amd.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit fd7e315988b784509ba3f1b42f539bd0b1fca9bb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/pgtable.h
diff --cc arch/x86/include/asm/pgtable.h
index 5c05ac8f19ab,b64ea527edfb..000000000000
--- a/arch/x86/include/asm/pgtable.h
+++ b/arch/x86/include/asm/pgtable.h
@@@ -162,6 -190,22 +162,25 @@@ static inline unsigned long pud_pfn(pud
  	return (pud_val(pud) & pud_pfn_mask(pud)) >> PAGE_SHIFT;
  }
  
++<<<<<<< HEAD
++=======
+ static inline unsigned long p4d_pfn(p4d_t p4d)
+ {
+ 	return (p4d_val(p4d) & p4d_pfn_mask(p4d)) >> PAGE_SHIFT;
+ }
+ 
+ static inline unsigned long pgd_pfn(pgd_t pgd)
+ {
+ 	return (pgd_val(pgd) & PTE_PFN_MASK) >> PAGE_SHIFT;
+ }
+ 
+ static inline int p4d_large(p4d_t p4d)
+ {
+ 	/* No 512 GiB pages yet */
+ 	return 0;
+ }
+ 
++>>>>>>> fd7e315988b7 (x86/mm: Simplify p[g4um]d_page() macros)
  #define pte_page(pte)	pfn_to_page(pte_pfn(pte))
  
  static inline int pmd_large(pmd_t pte)
@@@ -644,9 -800,53 +661,57 @@@ static inline int pud_large(pud_t pud
  {
  	return 0;
  }
 -#endif	/* CONFIG_PGTABLE_LEVELS > 2 */
 +#endif	/* PAGETABLE_LEVELS > 2 */
  
++<<<<<<< HEAD
 +#if PAGETABLE_LEVELS > 3
++=======
+ static inline unsigned long pud_index(unsigned long address)
+ {
+ 	return (address >> PUD_SHIFT) & (PTRS_PER_PUD - 1);
+ }
+ 
+ #if CONFIG_PGTABLE_LEVELS > 3
+ static inline int p4d_none(p4d_t p4d)
+ {
+ 	return (native_p4d_val(p4d) & ~(_PAGE_KNL_ERRATUM_MASK)) == 0;
+ }
+ 
+ static inline int p4d_present(p4d_t p4d)
+ {
+ 	return p4d_flags(p4d) & _PAGE_PRESENT;
+ }
+ 
+ static inline unsigned long p4d_page_vaddr(p4d_t p4d)
+ {
+ 	return (unsigned long)__va(p4d_val(p4d) & p4d_pfn_mask(p4d));
+ }
+ 
+ /*
+  * Currently stuck as a macro due to indirect forward reference to
+  * linux/mmzone.h's __section_mem_map_addr() definition:
+  */
+ #define p4d_page(p4d)	pfn_to_page(p4d_pfn(p4d))
+ 
+ /* Find an entry in the third-level page table.. */
+ static inline pud_t *pud_offset(p4d_t *p4d, unsigned long address)
+ {
+ 	return (pud_t *)p4d_page_vaddr(*p4d) + pud_index(address);
+ }
+ 
+ static inline int p4d_bad(p4d_t p4d)
+ {
+ 	return (p4d_flags(p4d) & ~(_KERNPG_TABLE | _PAGE_USER)) != 0;
+ }
+ #endif  /* CONFIG_PGTABLE_LEVELS > 3 */
+ 
+ static inline unsigned long p4d_index(unsigned long address)
+ {
+ 	return (address >> P4D_SHIFT) & (PTRS_PER_P4D - 1);
+ }
+ 
+ #if CONFIG_PGTABLE_LEVELS > 4
++>>>>>>> fd7e315988b7 (x86/mm: Simplify p[g4um]d_page() macros)
  static inline int pgd_present(pgd_t pgd)
  {
  	return pgd_flags(pgd) & _PAGE_PRESENT;
@@@ -661,17 -861,12 +726,17 @@@ static inline unsigned long pgd_page_va
   * Currently stuck as a macro due to indirect forward reference to
   * linux/mmzone.h's __section_mem_map_addr() definition:
   */
- #define pgd_page(pgd)		pfn_to_page(pgd_val(pgd) >> PAGE_SHIFT)
+ #define pgd_page(pgd)	pfn_to_page(pgd_pfn(pgd))
  
  /* to find an entry in a page-table-directory. */
 -static inline p4d_t *p4d_offset(pgd_t *pgd, unsigned long address)
 +static inline unsigned long pud_index(unsigned long address)
 +{
 +	return (address >> PUD_SHIFT) & (PTRS_PER_PUD - 1);
 +}
 +
 +static inline pud_t *pud_offset(pgd_t *pgd, unsigned long address)
  {
 -	return (p4d_t *)pgd_page_vaddr(*pgd) + p4d_index(address);
 +	return (pud_t *)pgd_page_vaddr(*pgd) + pud_index(address);
  }
  
  static inline int pgd_bad(pgd_t pgd)
* Unmerged path arch/x86/include/asm/pgtable.h
