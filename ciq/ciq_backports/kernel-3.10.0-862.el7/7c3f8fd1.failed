scsi: qla2xxx: move fields from qla_hw_data to qla_qpair

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [scsi] qla2xxx: move fields from qla_hw_data to qla_qpair (Himanshu Madhani) [1460030]
Rebuild_FUZZ: 94.34%
commit-author Quinn Tran <quinn.tran@cavium.com>
commit 7c3f8fd10bab0b4d9021a11f123fd67e81ef3b0e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/7c3f8fd1.failed

- Move chip_reset, enable_class_2 fields from qla_hw_data to qla_qpair
  to reduce cache thrash for target MQ.
- Optimizations to reduce unnecessary memory load for good path io.

	Signed-off-by: Quinn Tran <quinn.tran@cavium.com>
	Signed-off-by: Himanshu Madhani <himanshu.madhani@cavium.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit 7c3f8fd10bab0b4d9021a11f123fd67e81ef3b0e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/qla2xxx/qla_def.h
#	drivers/scsi/qla2xxx/qla_init.c
#	drivers/scsi/qla2xxx/qla_os.c
#	drivers/scsi/qla2xxx/qla_target.c
#	drivers/scsi/qla2xxx/qla_target.h
diff --cc drivers/scsi/qla2xxx/qla_def.h
index 3f28536dc812,dfa001357110..000000000000
--- a/drivers/scsi/qla2xxx/qla_def.h
+++ b/drivers/scsi/qla2xxx/qla_def.h
@@@ -2894,6 -3245,15 +2894,18 @@@ struct req_que 
  struct qla_qpair {
  	spinlock_t qp_lock;
  	atomic_t ref_count;
++<<<<<<< HEAD
++=======
+ 	uint32_t lun_cnt;
+ 	/*
+ 	 * For qpair 0, qp_lock_ptr will point at hardware_lock due to
+ 	 * legacy code. For other Qpair(s), it will point at qp_lock.
+ 	 */
+ 	spinlock_t *qp_lock_ptr;
+ 	struct scsi_qla_host *vha;
+ 	u32 chip_reset;
+ 
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  	/* distill these fields down to 'online=0/1'
  	 * ha->flags.eeh_busy
  	 * ha->flags.pci_channel_io_perm_failure
@@@ -2903,12 -3263,12 +2915,18 @@@
  	/* move vha->flags.difdix_supported here */
  	uint32_t difdix_supported:1;
  	uint32_t delete_in_progress:1;
++<<<<<<< HEAD
++=======
+ 	uint32_t fw_started:1;
+ 	uint32_t enable_class_2:1;
+ 	uint32_t enable_explicit_conf:1;
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  
  	uint16_t id;			/* qp number used with FW */
 +	uint16_t num_active_cmd;	/* cmds down at firmware */
 +	cpumask_t cpu_mask; /* CPU mask for cpu affinity operation */
  	uint16_t vp_idx;		/* vport ID */
 +
  	mempool_t *srb_mempool;
  
  	/* to do: New driver: move queues to here instead of pointers */
@@@ -2935,11 -3290,15 +2953,14 @@@ struct qlfc_fw 
  	uint32_t len;
  };
  
 -struct scsi_qlt_host {
 -	void *target_lport_ptr;
 -	struct mutex tgt_mutex;
 -	struct mutex tgt_host_action_mutex;
 -	struct qla_tgt *qla_tgt;
 -};
 -
  struct qlt_hw_data {
  	/* Protected by hw lock */
++<<<<<<< HEAD
 +	uint32_t enable_class_2:1;
 +	uint32_t enable_explicit_conf:1;
 +	uint32_t ini_mode_force_reverse:1;
++=======
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  	uint32_t node_name_set:1;
  
  	dma_addr_t atio_dma;	/* Physical address. */
diff --cc drivers/scsi/qla2xxx/qla_init.c
index b9189cae77e5,3e5f193480f0..000000000000
--- a/drivers/scsi/qla2xxx/qla_init.c
+++ b/drivers/scsi/qla2xxx/qla_init.c
@@@ -452,46 -1319,53 +452,55 @@@ qla2x00_async_login_done(struct scsi_ql
  		 * force a relogin attempt via implicit LOGO, PLOGI, and PRLI
  		 * requests.
  		 */
++<<<<<<< HEAD
 +		rval = qla2x00_get_port_database(vha, fcport, 0);
 +		if (rval == QLA_NOT_LOGGED_IN) {
 +			fcport->flags &= ~FCF_ASYNC_SENT;
 +			fcport->flags |= FCF_LOGIN_NEEDED;
 +			set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
 +			break;
 +		}
 +
 +		if (rval != QLA_SUCCESS) {
 +			qla2x00_post_async_logout_work(vha, fcport, NULL);
 +			qla2x00_post_async_login_work(vha, fcport, NULL);
 +			break;
 +		}
 +		if (fcport->flags & FCF_FCP2_DEVICE) {
 +			qla2x00_post_async_adisc_work(vha, fcport, data);
 +			break;
 +		}
 +		qla2x00_update_fcport(vha, fcport);
++=======
+ 		ql_dbg(ql_dbg_disc, vha, 0x20ea,
+ 		    "%s %d %8phC post gpdb\n",
+ 		    __func__, __LINE__, ea->fcport->port_name);
+ 		ea->fcport->chip_reset = vha->hw->base_qpair->chip_reset;
+ 		ea->fcport->logout_on_delete = 1;
+ 		qla24xx_post_gpdb_work(vha, ea->fcport, 0);
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  		break;
  	case MBS_COMMAND_ERROR:
 -		ql_dbg(ql_dbg_disc, vha, 0x20eb, "%s %d %8phC cmd error %x\n",
 -		    __func__, __LINE__, ea->fcport->port_name, ea->data[1]);
 -
 -		ea->fcport->flags &= ~FCF_ASYNC_SENT;
 -		ea->fcport->disc_state = DSC_LOGIN_FAILED;
 -		if (ea->data[1] & QLA_LOGIO_LOGIN_RETRIED)
 +		fcport->flags &= ~FCF_ASYNC_SENT;
 +		if (data[1] & QLA_LOGIO_LOGIN_RETRIED)
  			set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
  		else
 -			qla2x00_mark_device_lost(vha, ea->fcport, 1, 0);
 +			qla2x00_mark_device_lost(vha, fcport, 1, 0);
 +		break;
 +	case MBS_PORT_ID_USED:
 +		fcport->loop_id = data[1];
 +		qla2x00_post_async_logout_work(vha, fcport, NULL);
 +		qla2x00_post_async_login_work(vha, fcport, NULL);
  		break;
  	case MBS_LOOP_ID_USED:
 -		/* data[1] = IO PARAM 1 = nport ID  */
 -		cid.b.domain = (ea->iop[1] >> 16) & 0xff;
 -		cid.b.area   = (ea->iop[1] >>  8) & 0xff;
 -		cid.b.al_pa  = ea->iop[1] & 0xff;
 -		cid.b.rsvd_1 = 0;
 -
 -		ql_dbg(ql_dbg_disc, vha, 0x20ec,
 -		    "%s %d %8phC LoopID 0x%x in use post gnl\n",
 -		    __func__, __LINE__, ea->fcport->port_name,
 -		    ea->fcport->loop_id);
 -
 -		if (IS_SW_RESV_ADDR(cid)) {
 -			set_bit(ea->fcport->loop_id, vha->hw->loop_id_map);
 -			ea->fcport->loop_id = FC_NO_LOOP_ID;
 -		} else {
 -			qla2x00_clear_loop_id(ea->fcport);
 +		fcport->loop_id++;
 +		rval = qla2x00_find_new_loop_id(vha, fcport);
 +		if (rval != QLA_SUCCESS) {
 +			fcport->flags &= ~FCF_ASYNC_SENT;
 +			qla2x00_mark_device_lost(vha, fcport, 1, 0);
 +			break;
  		}
 -		qla24xx_post_gnl_work(vha, ea->fcport);
 -		break;
 -	case MBS_PORT_ID_USED:
 -		ql_dbg(ql_dbg_disc, vha, 0x20ed,
 -		    "%s %d %8phC NPortId %02x%02x%02x inuse post gidpn\n",
 -		    __func__, __LINE__, ea->fcport->port_name,
 -		    ea->fcport->d_id.b.domain, ea->fcport->d_id.b.area,
 -		    ea->fcport->d_id.b.al_pa);
 -
 -		qla2x00_clear_loop_id(ea->fcport);
 -		qla24xx_post_gidpn_work(vha, ea->fcport);
 +		qla2x00_post_async_login_work(vha, fcport, NULL);
  		break;
  	}
  	return;
@@@ -4602,6 -5545,18 +4612,21 @@@ qla2x00_abort_isp_cleanup(scsi_qla_host
  	if (!(IS_P3P_TYPE(ha)))
  		ha->isp_ops->reset_chip(vha);
  
++<<<<<<< HEAD
++=======
+ 	ha->flags.n2n_ae = 0;
+ 	ha->flags.lip_ae = 0;
+ 	ha->current_topology = 0;
+ 	ha->flags.fw_started = 0;
+ 	ha->flags.fw_init_done = 0;
+ 	ha->base_qpair->chip_reset++;
+ 	for (i = 0; i < ha->max_qpairs; i++) {
+ 		if (ha->queue_pair_map[i])
+ 			ha->queue_pair_map[i]->chip_reset =
+ 				ha->base_qpair->chip_reset;
+ 	}
+ 
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  	atomic_set(&vha->loop_down_timer, LOOP_DOWN_TIME);
  	if (atomic_read(&vha->loop_state) != LOOP_DOWN) {
  		atomic_set(&vha->loop_state, LOOP_DOWN);
@@@ -6667,6 -7629,11 +6692,14 @@@ struct qla_qpair *qla2xxx_create_qpair(
  		ha->queue_pair_map[qpair_id] = qpair;
  		qpair->id = qpair_id;
  		qpair->vp_idx = vp_idx;
++<<<<<<< HEAD
++=======
+ 		INIT_LIST_HEAD(&qpair->hints_list);
+ 		qpair->chip_reset = ha->base_qpair->chip_reset;
+ 		qpair->enable_class_2 = ha->base_qpair->enable_class_2;
+ 		qpair->enable_explicit_conf =
+ 		    ha->base_qpair->enable_explicit_conf;
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  
  		for (i = 0; i < ha->msix_count; i++) {
  			msix = &ha->msix_entries[i];
diff --cc drivers/scsi/qla2xxx/qla_os.c
index 4e0d0a2f9461,44be2c8237fd..000000000000
--- a/drivers/scsi/qla2xxx/qla_os.c
+++ b/drivers/scsi/qla2xxx/qla_os.c
@@@ -347,9 -371,28 +347,31 @@@ static int qla2x00_alloc_queues(struct 
  		goto fail_rsp_map;
  	}
  
++<<<<<<< HEAD
++=======
+ 	ha->base_qpair = kzalloc(sizeof(struct qla_qpair), GFP_KERNEL);
+ 	if (ha->base_qpair == NULL) {
+ 		ql_log(ql_log_warn, vha, 0x00e0,
+ 		    "Failed to allocate base queue pair memory.\n");
+ 		goto fail_base_qpair;
+ 	}
+ 
+ 	rsp->qpair = ha->base_qpair;
+ 	rsp->req = req;
+ 	ha->base_qpair->req = req;
+ 	ha->base_qpair->rsp = rsp;
+ 	ha->base_qpair->vha = vha;
+ 	ha->base_qpair->qp_lock_ptr = &ha->hardware_lock;
+ 	/* init qpair to this cpu. Will adjust at run time. */
+ 	ha->base_qpair->msix = &ha->msix_entries[QLA_MSIX_RSP_Q];
+ 	INIT_LIST_HEAD(&ha->base_qpair->hints_list);
+ 	ha->base_qpair->enable_class_2 = ql2xenableclass2;
+ 	qla_cpu_update(rsp->qpair, smp_processor_id());
+ 
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  	if (ql2xmqsupport && ha->max_qpairs) {
 -		ha->queue_pair_map = kcalloc(ha->max_qpairs, sizeof(struct qla_qpair *),
 -			GFP_KERNEL);
 +		ha->queue_pair_map = kcalloc(ha->max_qpairs,
 +			sizeof(struct qla_qpair *), GFP_KERNEL);
  		if (!ha->queue_pair_map) {
  			ql_log(ql_log_fatal, vha, 0x0180,
  			    "Unable to allocate memory for queue pair ptrs.\n");
@@@ -2650,7 -2709,11 +2672,15 @@@ qla2x00_probe_one(struct pci_dev *pdev
  	ql_dbg_pci(ql_dbg_init, pdev, 0x000a,
  	    "Memory allocated for ha=%p.\n", ha);
  	ha->pdev = pdev;
++<<<<<<< HEAD
 +	ha->tgt.enable_class_2 = ql2xenableclass2;
++=======
+ 	INIT_LIST_HEAD(&ha->tgt.q_full_list);
+ 	spin_lock_init(&ha->tgt.q_full_lock);
+ 	spin_lock_init(&ha->tgt.sess_lock);
+ 	spin_lock_init(&ha->tgt.atio_lock);
+ 
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  
  	/* Clear our data area */
  	ha->bars = bars;
diff --cc drivers/scsi/qla2xxx/qla_target.c
index 7a27b61e2d53,7e6c575e3e29..000000000000
--- a/drivers/scsi/qla2xxx/qla_target.c
+++ b/drivers/scsi/qla2xxx/qla_target.c
@@@ -333,9 -547,405 +333,408 @@@ void qlt_response_pkt_all_vps(struct sc
  
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * All qlt_plogi_ack_t operations are protected by hardware_lock
+  */
+ static int qla24xx_post_nack_work(struct scsi_qla_host *vha, fc_port_t *fcport,
+ 	struct imm_ntfy_from_isp *ntfy, int type)
+ {
+ 	struct qla_work_evt *e;
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_NACK);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.nack.fcport = fcport;
+ 	e->u.nack.type = type;
+ 	memcpy(e->u.nack.iocb, ntfy, sizeof(struct imm_ntfy_from_isp));
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ static
+ void qla2x00_async_nack_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = (struct srb *)s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	unsigned long flags;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20f2,
+ 	    "Async done-%s res %x %8phC  type %d\n",
+ 	    sp->name, res, sp->fcport->port_name, sp->type);
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 	sp->fcport->flags &= ~FCF_ASYNC_SENT;
+ 	sp->fcport->chip_reset = vha->hw->base_qpair->chip_reset;
+ 
+ 	switch (sp->type) {
+ 	case SRB_NACK_PLOGI:
+ 		sp->fcport->login_gen++;
+ 		sp->fcport->fw_login_state = DSC_LS_PLOGI_COMP;
+ 		sp->fcport->logout_on_delete = 1;
+ 		sp->fcport->plogi_nack_done_deadline = jiffies + HZ;
+ 		break;
+ 
+ 	case SRB_NACK_PRLI:
+ 		sp->fcport->fw_login_state = DSC_LS_PRLI_COMP;
+ 		sp->fcport->deleted = 0;
+ 
+ 		if (!sp->fcport->login_succ &&
+ 		    !IS_SW_RESV_ADDR(sp->fcport->d_id)) {
+ 			sp->fcport->login_succ = 1;
+ 
+ 			vha->fcport_count++;
+ 
+ 			if (!IS_IIDMA_CAPABLE(vha->hw) ||
+ 			    !vha->hw->flags.gpsc_supported) {
+ 				ql_dbg(ql_dbg_disc, vha, 0x20f3,
+ 				    "%s %d %8phC post upd_fcport fcp_cnt %d\n",
+ 				    __func__, __LINE__,
+ 				    sp->fcport->port_name,
+ 				    vha->fcport_count);
+ 
+ 				qla24xx_post_upd_fcport_work(vha, sp->fcport);
+ 			} else {
+ 				ql_dbg(ql_dbg_disc, vha, 0x20f5,
+ 				    "%s %d %8phC post gpsc fcp_cnt %d\n",
+ 				    __func__, __LINE__,
+ 				    sp->fcport->port_name,
+ 				    vha->fcport_count);
+ 
+ 				qla24xx_post_gpsc_work(vha, sp->fcport);
+ 			}
+ 		}
+ 		break;
+ 
+ 	case SRB_NACK_LOGO:
+ 		sp->fcport->login_gen++;
+ 		sp->fcport->fw_login_state = DSC_LS_PORT_UNAVAIL;
+ 		qlt_logo_completion_handler(sp->fcport, MBS_COMMAND_COMPLETE);
+ 		break;
+ 	}
+ 	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_notify_ack(scsi_qla_host_t *vha, fc_port_t *fcport,
+ 	struct imm_ntfy_from_isp *ntfy, int type)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	srb_t *sp;
+ 	char *c = NULL;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	switch (type) {
+ 	case SRB_NACK_PLOGI:
+ 		fcport->fw_login_state = DSC_LS_PLOGI_PEND;
+ 		c = "PLOGI";
+ 		break;
+ 	case SRB_NACK_PRLI:
+ 		fcport->fw_login_state = DSC_LS_PRLI_PEND;
+ 		fcport->deleted = 0;
+ 		c = "PRLI";
+ 		break;
+ 	case SRB_NACK_LOGO:
+ 		fcport->fw_login_state = DSC_LS_LOGO_PEND;
+ 		c = "LOGO";
+ 		break;
+ 	}
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_ATOMIC);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	sp->type = type;
+ 	sp->name = "nack";
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha)+2);
+ 
+ 	sp->u.iocb_cmd.u.nack.ntfy = ntfy;
+ 
+ 	sp->done = qla2x00_async_nack_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20f4,
+ 	    "Async-%s %8phC hndl %x %s\n",
+ 	    sp->name, fcport->port_name, sp->handle, c);
+ 
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ done:
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ void qla24xx_do_nack_work(struct scsi_qla_host *vha, struct qla_work_evt *e)
+ {
+ 	fc_port_t *t;
+ 	unsigned long flags;
+ 
+ 	switch (e->u.nack.type) {
+ 	case SRB_NACK_PRLI:
+ 		mutex_lock(&vha->vha_tgt.tgt_mutex);
+ 		t = qlt_create_sess(vha, e->u.nack.fcport, 0);
+ 		mutex_unlock(&vha->vha_tgt.tgt_mutex);
+ 		if (t) {
+ 			ql_log(ql_log_info, vha, 0xd034,
+ 			    "%s create sess success %p", __func__, t);
+ 			spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 			/* create sess has an extra kref */
+ 			vha->hw->tgt.tgt_ops->put_sess(e->u.nack.fcport);
+ 			spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 		}
+ 		break;
+ 	}
+ 	qla24xx_async_notify_ack(vha, e->u.nack.fcport,
+ 	    (struct imm_ntfy_from_isp*)e->u.nack.iocb, e->u.nack.type);
+ }
+ 
+ void qla24xx_delete_sess_fn(struct work_struct *work)
+ {
+ 	fc_port_t *fcport = container_of(work, struct fc_port, del_work);
+ 	struct qla_hw_data *ha = fcport->vha->hw;
+ 	unsigned long flags;
+ 
+ 	spin_lock_irqsave(&ha->tgt.sess_lock, flags);
+ 
+ 	if (fcport->se_sess) {
+ 		ha->tgt.tgt_ops->shutdown_sess(fcport);
+ 		ha->tgt.tgt_ops->put_sess(fcport);
+ 	} else {
+ 		qlt_unreg_sess(fcport);
+ 	}
+ 	spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ }
+ 
+ /*
+  * Called from qla2x00_reg_remote_port()
+  */
+ void qlt_fc_port_added(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_hw_data *ha = vha->hw;
+ 	struct qla_tgt *tgt = vha->vha_tgt.qla_tgt;
+ 	struct fc_port *sess = fcport;
+ 	unsigned long flags;
+ 
+ 	if (!vha->hw->tgt.tgt_ops)
+ 		return;
+ 
+ 	spin_lock_irqsave(&ha->tgt.sess_lock, flags);
+ 	if (tgt->tgt_stop) {
+ 		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 		return;
+ 	}
+ 
+ 	if (fcport->disc_state == DSC_DELETE_PEND) {
+ 		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 		return;
+ 	}
+ 
+ 	if (!sess->se_sess) {
+ 		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 
+ 		mutex_lock(&vha->vha_tgt.tgt_mutex);
+ 		sess = qlt_create_sess(vha, fcport, false);
+ 		mutex_unlock(&vha->vha_tgt.tgt_mutex);
+ 
+ 		spin_lock_irqsave(&ha->tgt.sess_lock, flags);
+ 	} else {
+ 		if (fcport->fw_login_state == DSC_LS_PRLI_COMP) {
+ 			spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 			return;
+ 		}
+ 
+ 		if (!kref_get_unless_zero(&sess->sess_kref)) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x2107,
+ 			    "%s: kref_get fail sess %8phC \n",
+ 			    __func__, sess->port_name);
+ 			spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 			return;
+ 		}
+ 
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf04c,
+ 		    "qla_target(%u): %ssession for port %8phC "
+ 		    "(loop ID %d) reappeared\n", vha->vp_idx,
+ 		    sess->local ? "local " : "", sess->port_name, sess->loop_id);
+ 
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf007,
+ 		    "Reappeared sess %p\n", sess);
+ 
+ 		ha->tgt.tgt_ops->update_sess(sess, fcport->d_id,
+ 		    fcport->loop_id,
+ 		    (fcport->flags & FCF_CONF_COMP_SUPPORTED));
+ 	}
+ 
+ 	if (sess && sess->local) {
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf04d,
+ 		    "qla_target(%u): local session for "
+ 		    "port %8phC (loop ID %d) became global\n", vha->vp_idx,
+ 		    fcport->port_name, sess->loop_id);
+ 		sess->local = 0;
+ 	}
+ 	ha->tgt.tgt_ops->put_sess(sess);
+ 	spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ }
+ 
+ /*
+  * This is a zero-base ref-counting solution, since hardware_lock
+  * guarantees that ref_count is not modified concurrently.
+  * Upon successful return content of iocb is undefined
+  */
+ static struct qlt_plogi_ack_t *
+ qlt_plogi_ack_find_add(struct scsi_qla_host *vha, port_id_t *id,
+ 		       struct imm_ntfy_from_isp *iocb)
+ {
+ 	struct qlt_plogi_ack_t *pla;
+ 
+ 	list_for_each_entry(pla, &vha->plogi_ack_list, list) {
+ 		if (pla->id.b24 == id->b24) {
+ 			qlt_send_term_imm_notif(vha, &pla->iocb, 1);
+ 			memcpy(&pla->iocb, iocb, sizeof(pla->iocb));
+ 			return pla;
+ 		}
+ 	}
+ 
+ 	pla = kmem_cache_zalloc(qla_tgt_plogi_cachep, GFP_ATOMIC);
+ 	if (!pla) {
+ 		ql_dbg(ql_dbg_async, vha, 0x5088,
+ 		       "qla_target(%d): Allocation of plogi_ack failed\n",
+ 		       vha->vp_idx);
+ 		return NULL;
+ 	}
+ 
+ 	memcpy(&pla->iocb, iocb, sizeof(pla->iocb));
+ 	pla->id = *id;
+ 	list_add_tail(&pla->list, &vha->plogi_ack_list);
+ 
+ 	return pla;
+ }
+ 
+ void qlt_plogi_ack_unref(struct scsi_qla_host *vha,
+     struct qlt_plogi_ack_t *pla)
+ {
+ 	struct imm_ntfy_from_isp *iocb = &pla->iocb;
+ 	port_id_t port_id;
+ 	uint16_t loop_id;
+ 	fc_port_t *fcport = pla->fcport;
+ 
+ 	BUG_ON(!pla->ref_count);
+ 	pla->ref_count--;
+ 
+ 	if (pla->ref_count)
+ 		return;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x5089,
+ 	    "Sending PLOGI ACK to wwn %8phC s_id %02x:%02x:%02x loop_id %#04x"
+ 	    " exch %#x ox_id %#x\n", iocb->u.isp24.port_name,
+ 	    iocb->u.isp24.port_id[2], iocb->u.isp24.port_id[1],
+ 	    iocb->u.isp24.port_id[0],
+ 	    le16_to_cpu(iocb->u.isp24.nport_handle),
+ 	    iocb->u.isp24.exchange_address, iocb->ox_id);
+ 
+ 	port_id.b.domain = iocb->u.isp24.port_id[2];
+ 	port_id.b.area   = iocb->u.isp24.port_id[1];
+ 	port_id.b.al_pa  = iocb->u.isp24.port_id[0];
+ 	port_id.b.rsvd_1 = 0;
+ 
+ 	loop_id = le16_to_cpu(iocb->u.isp24.nport_handle);
+ 
+ 	fcport->loop_id = loop_id;
+ 	fcport->d_id = port_id;
+ 	qla24xx_post_nack_work(vha, fcport, iocb, SRB_NACK_PLOGI);
+ 
+ 	list_for_each_entry(fcport, &vha->vp_fcports, list) {
+ 		if (fcport->plogi_link[QLT_PLOGI_LINK_SAME_WWN] == pla)
+ 			fcport->plogi_link[QLT_PLOGI_LINK_SAME_WWN] = NULL;
+ 		if (fcport->plogi_link[QLT_PLOGI_LINK_CONFLICT] == pla)
+ 			fcport->plogi_link[QLT_PLOGI_LINK_CONFLICT] = NULL;
+ 	}
+ 
+ 	list_del(&pla->list);
+ 	kmem_cache_free(qla_tgt_plogi_cachep, pla);
+ }
+ 
+ void
+ qlt_plogi_ack_link(struct scsi_qla_host *vha, struct qlt_plogi_ack_t *pla,
+     struct fc_port *sess, enum qlt_plogi_link_t link)
+ {
+ 	struct imm_ntfy_from_isp *iocb = &pla->iocb;
+ 	/* Inc ref_count first because link might already be pointing at pla */
+ 	pla->ref_count++;
+ 
+ 	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf097,
+ 		"Linking sess %p [%d] wwn %8phC with PLOGI ACK to wwn %8phC"
+ 		" s_id %02x:%02x:%02x, ref=%d pla %p link %d\n",
+ 		sess, link, sess->port_name,
+ 		iocb->u.isp24.port_name, iocb->u.isp24.port_id[2],
+ 		iocb->u.isp24.port_id[1], iocb->u.isp24.port_id[0],
+ 		pla->ref_count, pla, link);
+ 
+ 	if (sess->plogi_link[link])
+ 		qlt_plogi_ack_unref(vha, sess->plogi_link[link]);
+ 
+ 	if (link == QLT_PLOGI_LINK_SAME_WWN)
+ 		pla->fcport = sess;
+ 
+ 	sess->plogi_link[link] = pla;
+ }
+ 
+ typedef struct {
+ 	/* These fields must be initialized by the caller */
+ 	port_id_t id;
+ 	/*
+ 	 * number of cmds dropped while we were waiting for
+ 	 * initiator to ack LOGO initialize to 1 if LOGO is
+ 	 * triggered by a command, otherwise, to 0
+ 	 */
+ 	int cmd_count;
+ 
+ 	/* These fields are used by callee */
+ 	struct list_head list;
+ } qlt_port_logo_t;
+ 
+ static void
+ qlt_send_first_logo(struct scsi_qla_host *vha, qlt_port_logo_t *logo)
+ {
+ 	qlt_port_logo_t *tmp;
+ 	int res;
+ 
+ 	mutex_lock(&vha->vha_tgt.tgt_mutex);
+ 
+ 	list_for_each_entry(tmp, &vha->logo_list, list) {
+ 		if (tmp->id.b24 == logo->id.b24) {
+ 			tmp->cmd_count += logo->cmd_count;
+ 			mutex_unlock(&vha->vha_tgt.tgt_mutex);
+ 			return;
+ 		}
+ 	}
+ 
+ 	list_add_tail(&logo->list, &vha->logo_list);
+ 
+ 	mutex_unlock(&vha->vha_tgt.tgt_mutex);
+ 
+ 	res = qla24xx_els_dcmd_iocb(vha, ELS_DCMD_LOGO, logo->id);
+ 
+ 	mutex_lock(&vha->vha_tgt.tgt_mutex);
+ 	list_del(&logo->list);
+ 	mutex_unlock(&vha->vha_tgt.tgt_mutex);
+ 
+ 	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf098,
+ 	    "Finished LOGO to %02x:%02x:%02x, dropped %d cmds, res = %#x\n",
+ 	    logo->id.b.domain, logo->id.b.area, logo->id.b.al_pa,
+ 	    logo->cmd_count, res);
+ }
+ 
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  static void qlt_free_session_done(struct work_struct *work)
  {
 -	struct fc_port *sess = container_of(work, struct fc_port,
 +	struct qla_tgt_sess *sess = container_of(work, struct qla_tgt_sess,
  	    free_work);
  	struct qla_tgt *tgt = sess->tgt;
  	struct scsi_qla_host *vha = sess->vha;
@@@ -348,21 -992,115 +747,109 @@@
  	if (sess->se_sess != NULL)
  		ha->tgt.tgt_ops->free_session(sess);
  
++<<<<<<< HEAD
++=======
+ 	if (logout_started) {
+ 		bool traced = false;
+ 
+ 		while (!ACCESS_ONCE(sess->logout_completed)) {
+ 			if (!traced) {
+ 				ql_dbg(ql_dbg_tgt_mgt, vha, 0xf086,
+ 					"%s: waiting for sess %p logout\n",
+ 					__func__, sess);
+ 				traced = true;
+ 			}
+ 			msleep(100);
+ 		}
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0xf087,
+ 		    "%s: sess %p logout completed\n",__func__, sess);
+ 	}
+ 
+ 	if (sess->logo_ack_needed) {
+ 		sess->logo_ack_needed = 0;
+ 		qla24xx_async_notify_ack(vha, sess,
+ 			(struct imm_ntfy_from_isp *)sess->iocb, SRB_NACK_LOGO);
+ 	}
+ 
+ 	spin_lock_irqsave(&ha->tgt.sess_lock, flags);
+ 	if (sess->se_sess) {
+ 		sess->se_sess = NULL;
+ 		if (tgt && !IS_SW_RESV_ADDR(sess->d_id))
+ 			tgt->sess_count--;
+ 	}
+ 
+ 	sess->disc_state = DSC_DELETED;
+ 	sess->fw_login_state = DSC_LS_PORT_UNAVAIL;
+ 	sess->deleted = QLA_SESS_DELETED;
+ 	sess->login_retry = vha->hw->login_retry_count;
+ 
+ 	if (sess->login_succ && !IS_SW_RESV_ADDR(sess->d_id)) {
+ 		vha->fcport_count--;
+ 		sess->login_succ = 0;
+ 	}
+ 
+ 	if (sess->chip_reset != ha->base_qpair->chip_reset)
+ 		qla2x00_clear_loop_id(sess);
+ 
+ 	if (sess->conflict) {
+ 		sess->conflict->login_pause = 0;
+ 		sess->conflict = NULL;
+ 		if (!test_bit(UNLOADING, &vha->dpc_flags))
+ 			set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
+ 	}
+ 
+ 	{
+ 		struct qlt_plogi_ack_t *own =
+ 		    sess->plogi_link[QLT_PLOGI_LINK_SAME_WWN];
+ 		struct qlt_plogi_ack_t *con =
+ 		    sess->plogi_link[QLT_PLOGI_LINK_CONFLICT];
+ 		struct imm_ntfy_from_isp *iocb;
+ 
+ 		if (con) {
+ 			iocb = &con->iocb;
+ 			ql_dbg(ql_dbg_tgt_mgt, vha, 0xf099,
+ 				 "se_sess %p / sess %p port %8phC is gone,"
+ 				 " %s (ref=%d), releasing PLOGI for %8phC (ref=%d)\n",
+ 				 sess->se_sess, sess, sess->port_name,
+ 				 own ? "releasing own PLOGI" : "no own PLOGI pending",
+ 				 own ? own->ref_count : -1,
+ 				 iocb->u.isp24.port_name, con->ref_count);
+ 			qlt_plogi_ack_unref(vha, con);
+ 			sess->plogi_link[QLT_PLOGI_LINK_CONFLICT] = NULL;
+ 		} else {
+ 			ql_dbg(ql_dbg_tgt_mgt, vha, 0xf09a,
+ 			    "se_sess %p / sess %p port %8phC is gone, %s (ref=%d)\n",
+ 			    sess->se_sess, sess, sess->port_name,
+ 			    own ? "releasing own PLOGI" :
+ 			    "no own PLOGI pending",
+ 			    own ? own->ref_count : -1);
+ 		}
+ 
+ 		if (own) {
+ 			sess->fw_login_state = DSC_LS_PLOGI_PEND;
+ 			qlt_plogi_ack_unref(vha, own);
+ 			sess->plogi_link[QLT_PLOGI_LINK_SAME_WWN] = NULL;
+ 		}
+ 	}
+ 	spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf001,
 -	    "Unregistration of sess %p %8phC finished fcp_cnt %d\n",
 -		sess, sess->port_name, vha->fcport_count);
 +	    "Unregistration of sess %p finished\n", sess);
  
 -	if (tgt && (tgt->sess_count == 0))
 +	kfree(sess);
 +	/*
 +	 * We need to protect against race, when tgt is freed before or
 +	 * inside wake_up()
 +	 */
 +	tgt->sess_count--;
 +	if (tgt->sess_count == 0)
  		wake_up_all(&tgt->waitQ);
 -
 -	if (vha->fcport_count == 0)
 -		wake_up_all(&vha->fcport_waitQ);
 -
 -	base_vha = pci_get_drvdata(ha->pdev);
 -	if (test_bit(PFLG_DRIVER_REMOVING, &base_vha->pci_flags))
 -		return;
 -
 -	if (!tgt || !tgt->tgt_stop) {
 -		memset(&ea, 0, sizeof(ea));
 -		ea.event = FCME_DELETE_DONE;
 -		ea.fcport = sess;
 -		qla2x00_fcport_event_handler(vha, &ea);
 -	}
  }
  
 -/* ha->tgt.sess_lock supposed to be held on entry */
 -void qlt_unreg_sess(struct fc_port *sess)
 +/* ha->hardware_lock supposed to be held on entry */
 +void qlt_unreg_sess(struct qla_tgt_sess *sess)
  {
  	struct scsi_qla_host *vha = sess->vha;
  
@@@ -434,15 -1157,21 +921,30 @@@ static int qlt_reset(struct scsi_qla_ho
  	    "loop_id %d)\n", vha->host_no, sess, sess->port_name,
  	    mcmd, loop_id);
  
 -	return qlt_issue_task_mgmt(sess, 0, mcmd, iocb, QLA24XX_MGMT_SEND_NACK);
 +	lun = a->u.isp24.fcp_cmnd.lun;
 +	unpacked_lun = scsilun_to_int((struct scsi_lun *)&lun);
 +
 +	return qlt_issue_task_mgmt(sess, unpacked_lun, mcmd,
 +	    iocb, QLA24XX_MGMT_SEND_NACK);
  }
  
++<<<<<<< HEAD
 +/* ha->hardware_lock supposed to be held on entry */
 +static void qlt_schedule_sess_for_deletion(struct qla_tgt_sess *sess,
++=======
+ static void qla24xx_chk_fcp_state(struct fc_port *sess)
+ {
+ 	if (sess->chip_reset != sess->vha->hw->base_qpair->chip_reset) {
+ 		sess->logout_on_delete = 0;
+ 		sess->logo_ack_needed = 0;
+ 		sess->fw_login_state = DSC_LS_PORT_UNAVAIL;
+ 		sess->scan_state = 0;
+ 	}
+ }
+ 
+ /* ha->tgt.sess_lock supposed to be held on entry */
+ void qlt_schedule_sess_for_deletion(struct fc_port *sess,
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  	bool immediate)
  {
  	struct qla_tgt *tgt = sess->tgt;
@@@ -1238,51 -1779,149 +1740,57 @@@ static void qlt_24xx_retry_term_exchang
  	    FCP_TMF_CMPL, true);
  }
  
 -static int abort_cmd_for_tag(struct scsi_qla_host *vha, uint32_t tag)
 +/* ha->hardware_lock supposed to be held on entry */
 +static int __qlt_24xx_handle_abts(struct scsi_qla_host *vha,
 +	struct abts_recv_from_24xx *abts, struct qla_tgt_sess *sess)
  {
 -	struct qla_tgt_sess_op *op;
 -	struct qla_tgt_cmd *cmd;
 -	unsigned long flags;
 +	struct qla_hw_data *ha = vha->hw;
 +	struct se_session *se_sess = sess->se_sess;
 +	struct qla_tgt_mgmt_cmd *mcmd;
 +	struct se_cmd *se_cmd;
 +	u32 lun = 0;
 +	int rc;
 +	bool found_lun = false;
  
 -	spin_lock_irqsave(&vha->cmd_list_lock, flags);
 -	list_for_each_entry(op, &vha->qla_sess_op_cmd_list, cmd_list) {
 -		if (tag == op->atio.u.isp24.exchange_addr) {
 -			op->aborted = true;
 -			spin_unlock_irqrestore(&vha->cmd_list_lock, flags);
 -			return 1;
 +	spin_lock(&se_sess->sess_cmd_lock);
 +	list_for_each_entry(se_cmd, &se_sess->sess_cmd_list, se_cmd_list) {
 +		struct qla_tgt_cmd *cmd =
 +			container_of(se_cmd, struct qla_tgt_cmd, se_cmd);
 +		if (cmd->tag == abts->exchange_addr_to_abort) {
 +			lun = cmd->unpacked_lun;
 +			found_lun = true;
 +			break;
  		}
  	}
 +	spin_unlock(&se_sess->sess_cmd_lock);
  
 -	list_for_each_entry(op, &vha->unknown_atio_list, cmd_list) {
 -		if (tag == op->atio.u.isp24.exchange_addr) {
 -			op->aborted = true;
 -			spin_unlock_irqrestore(&vha->cmd_list_lock, flags);
 -			return 1;
 -		}
 -	}
 +	if (!found_lun)
 +		return -ENOENT;
  
 -	list_for_each_entry(cmd, &vha->qla_cmd_list, cmd_list) {
 -		if (tag == cmd->atio.u.isp24.exchange_addr) {
 -			cmd->aborted = 1;
 -			spin_unlock_irqrestore(&vha->cmd_list_lock, flags);
 -			return 1;
 -		}
 +	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf00f,
 +	    "qla_target(%d): task abort (tag=%d)\n",
 +	    vha->vp_idx, abts->exchange_addr_to_abort);
 +
 +	mcmd = mempool_alloc(qla_tgt_mgmt_cmd_mempool, GFP_ATOMIC);
 +	if (mcmd == NULL) {
 +		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf051,
 +		    "qla_target(%d): %s: Allocation of ABORT cmd failed",
 +		    vha->vp_idx, __func__);
 +		return -ENOMEM;
  	}
 -	spin_unlock_irqrestore(&vha->cmd_list_lock, flags);
 +	memset(mcmd, 0, sizeof(*mcmd));
  
 -	return 0;
 -}
 -
 -/* drop cmds for the given lun
 - * XXX only looks for cmds on the port through which lun reset was recieved
 - * XXX does not go through the list of other port (which may have cmds
 - *     for the same lun)
 - */
 -static void abort_cmds_for_lun(struct scsi_qla_host *vha,
 -			        u64 lun, uint8_t *s_id)
 -{
 -	struct qla_tgt_sess_op *op;
 -	struct qla_tgt_cmd *cmd;
 -	uint32_t key;
 -	unsigned long flags;
 -
 -	key = sid_to_key(s_id);
 -	spin_lock_irqsave(&vha->cmd_list_lock, flags);
 -	list_for_each_entry(op, &vha->qla_sess_op_cmd_list, cmd_list) {
 -		uint32_t op_key;
 -		u64 op_lun;
 -
 -		op_key = sid_to_key(op->atio.u.isp24.fcp_hdr.s_id);
 -		op_lun = scsilun_to_int(
 -			(struct scsi_lun *)&op->atio.u.isp24.fcp_cmnd.lun);
 -		if (op_key == key && op_lun == lun)
 -			op->aborted = true;
 -	}
 -
 -	list_for_each_entry(op, &vha->unknown_atio_list, cmd_list) {
 -		uint32_t op_key;
 -		u64 op_lun;
 -
 -		op_key = sid_to_key(op->atio.u.isp24.fcp_hdr.s_id);
 -		op_lun = scsilun_to_int(
 -			(struct scsi_lun *)&op->atio.u.isp24.fcp_cmnd.lun);
 -		if (op_key == key && op_lun == lun)
 -			op->aborted = true;
 -	}
 -
 -	list_for_each_entry(cmd, &vha->qla_cmd_list, cmd_list) {
 -		uint32_t cmd_key;
 -		u64 cmd_lun;
 -
 -		cmd_key = sid_to_key(cmd->atio.u.isp24.fcp_hdr.s_id);
 -		cmd_lun = scsilun_to_int(
 -			(struct scsi_lun *)&cmd->atio.u.isp24.fcp_cmnd.lun);
 -		if (cmd_key == key && cmd_lun == lun)
 -			cmd->aborted = 1;
 -	}
 -	spin_unlock_irqrestore(&vha->cmd_list_lock, flags);
 -}
 -
 -/* ha->hardware_lock supposed to be held on entry */
 -static int __qlt_24xx_handle_abts(struct scsi_qla_host *vha,
 -	struct abts_recv_from_24xx *abts, struct fc_port *sess)
 -{
 -	struct qla_hw_data *ha = vha->hw;
 -	struct se_session *se_sess = sess->se_sess;
 -	struct qla_tgt_mgmt_cmd *mcmd;
 -	struct qla_tgt_cmd *cmd;
 -	struct se_cmd *se_cmd;
 -	int rc;
 -	bool found_lun = false;
 -	unsigned long flags;
 -
 -	spin_lock_irqsave(&se_sess->sess_cmd_lock, flags);
 -	list_for_each_entry(se_cmd, &se_sess->sess_cmd_list, se_cmd_list) {
 -		if (se_cmd->tag == abts->exchange_addr_to_abort) {
 -			found_lun = true;
 -			break;
 -		}
 -	}
 -	spin_unlock_irqrestore(&se_sess->sess_cmd_lock, flags);
 -
 -	/* cmd not in LIO lists, look in qla list */
 -	if (!found_lun) {
 -		if (abort_cmd_for_tag(vha, abts->exchange_addr_to_abort)) {
 -			/* send TASK_ABORT response immediately */
 -			qlt_24xx_send_abts_resp(ha->base_qpair, abts,
 -			    FCP_TMF_CMPL, false);
 -			return 0;
 -		} else {
 -			ql_dbg(ql_dbg_tgt_mgt, vha, 0xf081,
 -			    "unable to find cmd in driver or LIO for tag 0x%x\n",
 -			    abts->exchange_addr_to_abort);
 -			return -ENOENT;
 -		}
 -	}
 -
 -	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf00f,
 -	    "qla_target(%d): task abort (tag=%d)\n",
 -	    vha->vp_idx, abts->exchange_addr_to_abort);
 -
 -	mcmd = mempool_alloc(qla_tgt_mgmt_cmd_mempool, GFP_ATOMIC);
 -	if (mcmd == NULL) {
 -		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf051,
 -		    "qla_target(%d): %s: Allocation of ABORT cmd failed",
 -		    vha->vp_idx, __func__);
 -		return -ENOMEM;
 -	}
 -	memset(mcmd, 0, sizeof(*mcmd));
 -
 -	cmd = container_of(se_cmd, struct qla_tgt_cmd, se_cmd);
  	mcmd->sess = sess;
  	memcpy(&mcmd->orig_iocb.abts, abts, sizeof(mcmd->orig_iocb.abts));
++<<<<<<< HEAD
 +	mcmd->reset_count = vha->hw->chip_reset;
++=======
+ 	mcmd->reset_count = ha->base_qpair->chip_reset;
+ 	mcmd->tmr_func = QLA_TGT_ABTS;
+ 	mcmd->qpair = ha->base_qpair;
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  
 -	rc = ha->tgt.tgt_ops->handle_tmr(mcmd, cmd->unpacked_lun, mcmd->tmr_func,
 +	rc = ha->tgt.tgt_ops->handle_tmr(mcmd, lun, TMR_ABORT_TASK,
  	    abts->exchange_addr_to_abort);
  	if (rc != 0) {
  		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf052,
@@@ -1422,16 -2144,44 +1930,52 @@@ void qlt_xmit_tm_rsp(struct qla_tgt_mgm
  	    "TM response mcmd (%p) status %#x state %#x",
  	    mcmd, mcmd->fc_tm_rsp, mcmd->flags);
  
++<<<<<<< HEAD
 +	spin_lock_irqsave(&ha->hardware_lock, flags);
 +	if (mcmd->flags == QLA24XX_MGMT_SEND_NACK)
 +		qlt_send_notify_ack(vha, &mcmd->orig_iocb.imm_ntfy,
 +		    0, 0, 0, 0, 0, 0);
 +	else {
++=======
+ 	spin_lock_irqsave(qpair->qp_lock_ptr, flags);
+ 
+ 	if (!vha->flags.online || mcmd->reset_count != qpair->chip_reset) {
+ 		/*
+ 		 * Either the port is not online or this request was from
+ 		 * previous life, just abort the processing.
+ 		 */
+ 		ql_dbg(ql_dbg_async, vha, 0xe100,
+ 			"RESET-TMR online/active/old-count/new-count = %d/%d/%d/%d.\n",
+ 			vha->flags.online, qla2x00_reset_active(vha),
+ 			mcmd->reset_count, qpair->chip_reset);
+ 		ha->tgt.tgt_ops->free_mcmd(mcmd);
+ 		spin_unlock_irqrestore(qpair->qp_lock_ptr, flags);
+ 		return;
+ 	}
+ 
+ 	if (mcmd->flags == QLA24XX_MGMT_SEND_NACK) {
+ 		if (mcmd->orig_iocb.imm_ntfy.u.isp24.status_subcode ==
+ 		    ELS_LOGO ||
+ 		    mcmd->orig_iocb.imm_ntfy.u.isp24.status_subcode ==
+ 		    ELS_PRLO ||
+ 		    mcmd->orig_iocb.imm_ntfy.u.isp24.status_subcode ==
+ 		    ELS_TPRLO) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x2106,
+ 			    "TM response logo %phC status %#x state %#x",
+ 			    mcmd->sess->port_name, mcmd->fc_tm_rsp,
+ 			    mcmd->flags);
+ 			qlt_schedule_sess_for_deletion_lock(mcmd->sess);
+ 		} else {
+ 			qlt_send_notify_ack(vha->hw->base_qpair,
+ 			    &mcmd->orig_iocb.imm_ntfy, 0, 0, 0, 0, 0, 0);
+ 		}
+ 	} else {
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  		if (mcmd->orig_iocb.atio.u.raw.entry_type == ABTS_RECV_24XX)
 -			qlt_24xx_send_abts_resp(qpair, &mcmd->orig_iocb.abts,
 +			qlt_24xx_send_abts_resp(vha, &mcmd->orig_iocb.abts,
  			    mcmd->fc_tm_rsp, false);
  		else
 -			qlt_24xx_send_task_mgmt_ctio(qpair, mcmd,
 +			qlt_24xx_send_task_mgmt_ctio(vha, mcmd,
  			    mcmd->fc_tm_rsp);
  	}
  	/*
@@@ -1756,47 -2568,23 +2300,49 @@@ static int qlt_pre_xmit_response(struc
  	struct qla_tgt_prm *prm, int xmit_type, uint8_t scsi_status,
  	uint32_t *full_req_cnt)
  {
- 	struct qla_tgt *tgt = cmd->tgt;
- 	struct scsi_qla_host *vha = tgt->vha;
- 	struct qla_hw_data *ha = vha->hw;
  	struct se_cmd *se_cmd = &cmd->se_cmd;
  
 +	if (unlikely(cmd->aborted)) {
 +		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf014,
 +		    "qla_target(%d): terminating exchange "
 +		    "for aborted cmd=%p (se_cmd=%p, tag=%d)", vha->vp_idx, cmd,
 +		    se_cmd, cmd->tag);
 +
 +		cmd->state = QLA_TGT_STATE_ABORTED;
 +
 +		qlt_send_term_exchange(vha, cmd, &cmd->atio, 0);
 +
 +		/* !! At this point cmd could be already freed !! */
 +		return QLA_TGT_PRE_XMIT_RESP_CMD_ABORTED;
 +	}
 +
 +	ql_dbg(ql_dbg_tgt, vha, 0xe011, "qla_target(%d): tag=%u\n",
 +	    vha->vp_idx, cmd->tag);
 +
  	prm->cmd = cmd;
- 	prm->tgt = tgt;
+ 	prm->tgt = cmd->tgt;
+ 	prm->pkt = NULL;
  	prm->rq_result = scsi_status;
  	prm->sense_buffer = &cmd->sense_buffer[0];
  	prm->sense_buffer_len = TRANSPORT_SENSE_BUFFER;
  	prm->sg = NULL;
  	prm->seg_cnt = -1;
  	prm->req_cnt = 1;
+ 	prm->residual = 0;
  	prm->add_status_pkt = 0;
+ 	prm->prot_sg = NULL;
+ 	prm->prot_seg_cnt = 0;
+ 	prm->tot_dsds = 0;
  
 +	ql_dbg(ql_dbg_tgt, vha, 0xe012, "rq_result=%x, xmit_type=%x\n",
 +	    prm->rq_result, xmit_type);
 +
 +	/* Send marker if required */
 +	if (qlt_issue_marker(vha, 0) != QLA_SUCCESS)
 +		return -EFAULT;
 +
 +	ql_dbg(ql_dbg_tgt, vha, 0xe013, "CTIO start: vha(%d)\n", vha->vp_idx);
 +
  	if ((xmit_type & QLA_TGT_XMIT_DATA) && qlt_has_data(cmd)) {
  		if  (qlt_pci_map_calc_cnt(prm) != 0)
  			return -EAGAIN;
@@@ -1806,19 -2594,18 +2352,34 @@@
  
  	if (se_cmd->se_cmd_flags & SCF_UNDERFLOW_BIT) {
  		prm->residual = se_cmd->residual_count;
++<<<<<<< HEAD
 +		ql_dbg(ql_dbg_tgt, vha, 0xe014,
 +		    "Residual underflow: %d (tag %d, "
 +		    "op %x, bufflen %d, rq_result %x)\n", prm->residual,
 +		    cmd->tag, se_cmd->t_task_cdb ? se_cmd->t_task_cdb[0] : 0,
 +		    cmd->bufflen, prm->rq_result);
 +		prm->rq_result |= SS_RESIDUAL_UNDER;
 +	} else if (se_cmd->se_cmd_flags & SCF_OVERFLOW_BIT) {
 +		prm->residual = se_cmd->residual_count;
 +		ql_dbg(ql_dbg_tgt, vha, 0xe015,
 +		    "Residual overflow: %d (tag %d, "
 +		    "op %x, bufflen %d, rq_result %x)\n", prm->residual,
 +		    cmd->tag, se_cmd->t_task_cdb ? se_cmd->t_task_cdb[0] : 0,
 +		    cmd->bufflen, prm->rq_result);
++=======
+ 		ql_dbg(ql_dbg_io + ql_dbg_verbose, cmd->vha, 0x305c,
+ 		    "Residual underflow: %d (tag %lld, op %x, bufflen %d, rq_result %x)\n",
+ 		       prm->residual, se_cmd->tag,
+ 		       se_cmd->t_task_cdb ? se_cmd->t_task_cdb[0] : 0,
+ 		       cmd->bufflen, prm->rq_result);
+ 		prm->rq_result |= SS_RESIDUAL_UNDER;
+ 	} else if (se_cmd->se_cmd_flags & SCF_OVERFLOW_BIT) {
+ 		prm->residual = se_cmd->residual_count;
+ 		ql_dbg(ql_dbg_io, cmd->vha, 0x305d,
+ 		    "Residual overflow: %d (tag %lld, op %x, bufflen %d, rq_result %x)\n",
+ 		       prm->residual, se_cmd->tag, se_cmd->t_task_cdb ?
+ 		       se_cmd->t_task_cdb[0] : 0, cmd->bufflen, prm->rq_result);
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  		prm->rq_result |= SS_RESIDUAL_OVER;
  	}
  
@@@ -1853,99 -2636,10 +2414,99 @@@ static inline int qlt_need_explicit_con
  	if (sending_sense)
  		return cmd->conf_compl_supported;
  	else
- 		return ha->tgt.enable_explicit_conf &&
- 		    cmd->conf_compl_supported;
+ 		return cmd->qpair->enable_explicit_conf &&
+                     cmd->conf_compl_supported;
  }
  
 +#ifdef CONFIG_QLA_TGT_DEBUG_SRR
 +/*
 + *  Original taken from the XFS code
 + */
 +static unsigned long qlt_srr_random(void)
 +{
 +	static int Inited;
 +	static unsigned long RandomValue;
 +	static DEFINE_SPINLOCK(lock);
 +	/* cycles pseudo-randomly through all values between 1 and 2^31 - 2 */
 +	register long rv;
 +	register long lo;
 +	register long hi;
 +	unsigned long flags;
 +
 +	spin_lock_irqsave(&lock, flags);
 +	if (!Inited) {
 +		RandomValue = jiffies;
 +		Inited = 1;
 +	}
 +	rv = RandomValue;
 +	hi = rv / 127773;
 +	lo = rv % 127773;
 +	rv = 16807 * lo - 2836 * hi;
 +	if (rv <= 0)
 +		rv += 2147483647;
 +	RandomValue = rv;
 +	spin_unlock_irqrestore(&lock, flags);
 +	return rv;
 +}
 +
 +static void qlt_check_srr_debug(struct qla_tgt_cmd *cmd, int *xmit_type)
 +{
 +#if 0 /* This is not a real status packets lost, so it won't lead to SRR */
 +	if ((*xmit_type & QLA_TGT_XMIT_STATUS) && (qlt_srr_random() % 200)
 +	    == 50) {
 +		*xmit_type &= ~QLA_TGT_XMIT_STATUS;
 +		ql_dbg(ql_dbg_tgt_mgt, cmd->vha, 0xf015,
 +		    "Dropping cmd %p (tag %d) status", cmd, cmd->tag);
 +	}
 +#endif
 +	/*
 +	 * It's currently not possible to simulate SRRs for FCP_WRITE without
 +	 * a physical link layer failure, so don't even try here..
 +	 */
 +	if (cmd->dma_data_direction != DMA_FROM_DEVICE)
 +		return;
 +
 +	if (qlt_has_data(cmd) && (cmd->sg_cnt > 1) &&
 +	    ((qlt_srr_random() % 100) == 20)) {
 +		int i, leave = 0;
 +		unsigned int tot_len = 0;
 +
 +		while (leave == 0)
 +			leave = qlt_srr_random() % cmd->sg_cnt;
 +
 +		for (i = 0; i < leave; i++)
 +			tot_len += cmd->sg[i].length;
 +
 +		ql_dbg(ql_dbg_tgt_mgt, cmd->vha, 0xf016,
 +		    "Cutting cmd %p (tag %d) buffer"
 +		    " tail to len %d, sg_cnt %d (cmd->bufflen %d,"
 +		    " cmd->sg_cnt %d)", cmd, cmd->tag, tot_len, leave,
 +		    cmd->bufflen, cmd->sg_cnt);
 +
 +		cmd->bufflen = tot_len;
 +		cmd->sg_cnt = leave;
 +	}
 +
 +	if (qlt_has_data(cmd) && ((qlt_srr_random() % 100) == 70)) {
 +		unsigned int offset = qlt_srr_random() % cmd->bufflen;
 +
 +		ql_dbg(ql_dbg_tgt_mgt, cmd->vha, 0xf017,
 +		    "Cutting cmd %p (tag %d) buffer head "
 +		    "to offset %d (cmd->bufflen %d)", cmd, cmd->tag, offset,
 +		    cmd->bufflen);
 +		if (offset == 0)
 +			*xmit_type &= ~QLA_TGT_XMIT_DATA;
 +		else if (qlt_set_data_offset(cmd, offset)) {
 +			ql_dbg(ql_dbg_tgt_mgt, cmd->vha, 0xf018,
 +			    "qlt_set_data_offset() failed (tag %d)", cmd->tag);
 +		}
 +	}
 +}
 +#else
 +static inline void qlt_check_srr_debug(struct qla_tgt_cmd *cmd, int *xmit_type)
 +{}
 +#endif
 +
  static void qlt_24xx_init_ctio_to_isp(struct ctio7_to_24xx *ctio,
  	struct qla_tgt_prm *prm)
  {
@@@ -2020,20 -3049,28 +2581,36 @@@ int qlt_xmit_response(struct qla_tgt_cm
  	uint8_t scsi_status)
  {
  	struct scsi_qla_host *vha = cmd->vha;
++<<<<<<< HEAD
 +	struct qla_hw_data *ha = vha->hw;
++=======
+ 	struct qla_qpair *qpair = cmd->qpair;
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  	struct ctio7_to_24xx *pkt;
  	struct qla_tgt_prm prm;
  	uint32_t full_req_cnt = 0;
  	unsigned long flags = 0;
  	int res;
  
++<<<<<<< HEAD
 +	memset(&prm, 0, sizeof(prm));
 +	qlt_check_srr_debug(cmd, &xmit_type);
++=======
+ 	if (cmd->sess && cmd->sess->deleted) {
+ 		cmd->state = QLA_TGT_STATE_PROCESSED;
+ 		if (cmd->sess->logout_completed)
+ 			/* no need to terminate. FW already freed exchange. */
+ 			qlt_abort_cmd_on_host_reset(cmd->vha, cmd);
+ 		else
+ 			qlt_send_term_exchange(qpair, cmd, &cmd->atio, 0, 0);
+ 		return 0;
+ 	}
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  
  	ql_dbg(ql_dbg_tgt, cmd->vha, 0xe018,
 -	    "is_send_status=%d, cmd->bufflen=%d, cmd->sg_cnt=%d, cmd->dma_data_direction=%d se_cmd[%p] qp %d\n",
 -	    (xmit_type & QLA_TGT_XMIT_STATUS) ?
 -	    1 : 0, cmd->bufflen, cmd->sg_cnt, cmd->dma_data_direction,
 -	    &cmd->se_cmd, qpair->id);
 +	    "is_send_status=%d, cmd->bufflen=%d, cmd->sg_cnt=%d, "
 +	    "cmd->dma_data_direction=%d\n", (xmit_type & QLA_TGT_XMIT_STATUS) ?
 +	    1 : 0, cmd->bufflen, cmd->sg_cnt, cmd->dma_data_direction);
  
  	res = qlt_pre_xmit_response(cmd, &prm, xmit_type, scsi_status,
  	    &full_req_cnt);
@@@ -2044,10 -3078,30 +2621,34 @@@
  		return res;
  	}
  
++<<<<<<< HEAD
 +	spin_lock_irqsave(&ha->hardware_lock, flags);
++=======
+ 	spin_lock_irqsave(qpair->qp_lock_ptr, flags);
+ 
+ 	if (xmit_type == QLA_TGT_XMIT_STATUS)
+ 		vha->tgt_counters.core_qla_snd_status++;
+ 	else
+ 		vha->tgt_counters.core_qla_que_buf++;
+ 
+ 	if (!qpair->fw_started || cmd->reset_count != qpair->chip_reset) {
+ 		/*
+ 		 * Either the port is not online or this request was from
+ 		 * previous life, just abort the processing.
+ 		 */
+ 		cmd->state = QLA_TGT_STATE_PROCESSED;
+ 		qlt_abort_cmd_on_host_reset(cmd->vha, cmd);
+ 		ql_dbg(ql_dbg_async, vha, 0xe101,
+ 			"RESET-RSP online/active/old-count/new-count = %d/%d/%d/%d.\n",
+ 			vha->flags.online, qla2x00_reset_active(vha),
+ 			cmd->reset_count, qpair->chip_reset);
+ 		spin_unlock_irqrestore(qpair->qp_lock_ptr, flags);
+ 		return 0;
+ 	}
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  
  	/* Does F/W have an IOCBs for this request */
 -	res = qlt_check_reserve_free_req(qpair, full_req_cnt);
 +	res = qlt_check_reserve_free_req(vha, full_req_cnt);
  	if (unlikely(res))
  		goto out_unmap_unlock;
  
@@@ -2160,43 -3221,251 +2761,60 @@@ int qlt_rdy_to_xfer(struct qla_tgt_cmd 
  	if (qlt_pci_map_calc_cnt(&prm) != 0)
  		return -EAGAIN;
  
++<<<<<<< HEAD
 +	spin_lock_irqsave(&ha->hardware_lock, flags);
++=======
+ 	if (!qpair->fw_started || (cmd->reset_count != qpair->chip_reset) ||
+ 	    (cmd->sess && cmd->sess->deleted)) {
+ 		/*
+ 		 * Either the port is not online or this request was from
+ 		 * previous life, just abort the processing.
+ 		 */
+ 		cmd->state = QLA_TGT_STATE_NEED_DATA;
+ 		qlt_abort_cmd_on_host_reset(cmd->vha, cmd);
+ 		ql_dbg(ql_dbg_async, vha, 0xe102,
+ 			"RESET-XFR online/active/old-count/new-count = %d/%d/%d/%d.\n",
+ 			vha->flags.online, qla2x00_reset_active(vha),
+ 			cmd->reset_count, qpair->chip_reset);
+ 		return 0;
+ 	}
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  
 -	spin_lock_irqsave(qpair->qp_lock_ptr, flags);
  	/* Does F/W have an IOCBs for this request */
 -	res = qlt_check_reserve_free_req(qpair, prm.req_cnt);
 +	res = qlt_check_reserve_free_req(vha, prm.req_cnt);
  	if (res != 0)
  		goto out_unlock_free_unmap;
 -	if (cmd->se_cmd.prot_op)
 -		res = qlt_build_ctio_crc2_pkt(qpair, &prm);
 -	else
 -		res = qlt_24xx_build_ctio_pkt(qpair, &prm);
  
 -	if (unlikely(res != 0)) {
 -		qpair->req->cnt += prm.req_cnt;
 +	res = qlt_24xx_build_ctio_pkt(&prm, vha);
 +	if (unlikely(res != 0))
  		goto out_unlock_free_unmap;
 -	}
 -
 -	pkt = (struct ctio7_to_24xx *)prm.pkt;
 -	pkt->u.status0.flags |= cpu_to_le16(CTIO7_FLAGS_DATA_OUT |
 -	    CTIO7_FLAGS_STATUS_MODE_0);
 -
 -	if (cmd->se_cmd.prot_op == TARGET_PROT_NORMAL)
 -		qlt_load_data_segments(&prm, vha);
 -
 -	cmd->state = QLA_TGT_STATE_NEED_DATA;
 -	cmd->cmd_sent_to_fw = 1;
 -
 -	/* Memory Barrier */
 -	wmb();
 -	qla2x00_start_iocbs(vha, qpair->req);
 -	spin_unlock_irqrestore(qpair->qp_lock_ptr, flags);
 -
 -	return res;
 -
 -out_unlock_free_unmap:
 -	qlt_unmap_sg(vha, cmd);
 -	spin_unlock_irqrestore(qpair->qp_lock_ptr, flags);
 -
 -	return res;
 -}
 -EXPORT_SYMBOL(qlt_rdy_to_xfer);
 -
 -
 -/*
 - * it is assumed either hardware_lock or qpair lock is held.
 - */
 -static void
 -qlt_handle_dif_error(struct scsi_qla_host *vha, struct qla_tgt_cmd *cmd,
 -	struct ctio_crc_from_fw *sts)
 -{
 -	uint8_t		*ap = &sts->actual_dif[0];
 -	uint8_t		*ep = &sts->expected_dif[0];
 -	uint64_t	lba = cmd->se_cmd.t_task_lba;
 -	uint8_t scsi_status, sense_key, asc, ascq;
 -	unsigned long flags;
 -
 -	cmd->trc_flags |= TRC_DIF_ERR;
 -
 -	cmd->a_guard   = be16_to_cpu(*(uint16_t *)(ap + 0));
 -	cmd->a_app_tag = be16_to_cpu(*(uint16_t *)(ap + 2));
 -	cmd->a_ref_tag = be32_to_cpu(*(uint32_t *)(ap + 4));
 -
 -	cmd->e_guard   = be16_to_cpu(*(uint16_t *)(ep + 0));
 -	cmd->e_app_tag = be16_to_cpu(*(uint16_t *)(ep + 2));
 -	cmd->e_ref_tag = be32_to_cpu(*(uint32_t *)(ep + 4));
 -
 -	ql_dbg(ql_dbg_tgt_dif, vha, 0xf075,
 -	    "%s: aborted %d state %d\n", __func__, cmd->aborted, cmd->state);
 -
 -	scsi_status = sense_key = asc = ascq = 0;
 -
 -	/* check appl tag */
 -	if (cmd->e_app_tag != cmd->a_app_tag) {
 -		ql_dbg(ql_dbg_tgt_dif, vha, 0xe00d,
 -		    "App Tag ERR: cdb[%x] lba[%llx %llx] blks[%x] [Actual|Expected] Ref[%x|%x], App[%x|%x], Guard [%x|%x] cmd=%p ox_id[%04x]",
 -		    cmd->cdb[0], lba, (lba+cmd->num_blks), cmd->num_blks,
 -		    cmd->a_ref_tag, cmd->e_ref_tag, cmd->a_app_tag,
 -		    cmd->e_app_tag, cmd->a_guard, cmd->e_guard, cmd,
 -		    cmd->atio.u.isp24.fcp_hdr.ox_id);
 -
 -		cmd->dif_err_code = DIF_ERR_APP;
 -		scsi_status = SAM_STAT_CHECK_CONDITION;
 -		sense_key = ABORTED_COMMAND;
 -		asc = 0x10;
 -		ascq = 0x2;
 -	}
 -
 -	/* check ref tag */
 -	if (cmd->e_ref_tag != cmd->a_ref_tag) {
 -		ql_dbg(ql_dbg_tgt_dif, vha, 0xe00e,
 -		    "Ref Tag ERR: cdb[%x] lba[%llx %llx] blks[%x] [Actual|Expected] Ref[%x|%x], App[%x|%x], Guard[%x|%x] cmd=%p ox_id[%04x] ",
 -		    cmd->cdb[0], lba, (lba+cmd->num_blks), cmd->num_blks,
 -		    cmd->a_ref_tag, cmd->e_ref_tag, cmd->a_app_tag,
 -		    cmd->e_app_tag, cmd->a_guard, cmd->e_guard, cmd,
 -		    cmd->atio.u.isp24.fcp_hdr.ox_id);
 -
 -		cmd->dif_err_code = DIF_ERR_REF;
 -		scsi_status = SAM_STAT_CHECK_CONDITION;
 -		sense_key = ABORTED_COMMAND;
 -		asc = 0x10;
 -		ascq = 0x3;
 -		goto out;
 -	}
 -
 -	/* check guard */
 -	if (cmd->e_guard != cmd->a_guard) {
 -		ql_dbg(ql_dbg_tgt_dif, vha, 0xe012,
 -		    "Guard ERR: cdb[%x] lba[%llx %llx] blks[%x] [Actual|Expected] Ref[%x|%x], App[%x|%x], Guard [%x|%x] cmd=%p ox_id[%04x]",
 -		    cmd->cdb[0], lba, (lba+cmd->num_blks), cmd->num_blks,
 -		    cmd->a_ref_tag, cmd->e_ref_tag, cmd->a_app_tag,
 -		    cmd->e_app_tag, cmd->a_guard, cmd->e_guard, cmd,
 -		    cmd->atio.u.isp24.fcp_hdr.ox_id);
 -
 -		cmd->dif_err_code = DIF_ERR_GRD;
 -		scsi_status = SAM_STAT_CHECK_CONDITION;
 -		sense_key = ABORTED_COMMAND;
 -		asc = 0x10;
 -		ascq = 0x1;
 -	}
 -out:
 -	switch (cmd->state) {
 -	case QLA_TGT_STATE_NEED_DATA:
 -		/* handle_data will load DIF error code  */
 -		cmd->state = QLA_TGT_STATE_DATA_IN;
 -		vha->hw->tgt.tgt_ops->handle_data(cmd);
 -		break;
 -	default:
 -		spin_lock_irqsave(&cmd->cmd_lock, flags);
 -		if (cmd->aborted) {
 -			spin_unlock_irqrestore(&cmd->cmd_lock, flags);
 -			vha->hw->tgt.tgt_ops->free_cmd(cmd);
 -			break;
 -		}
 -		spin_unlock_irqrestore(&cmd->cmd_lock, flags);
 -
 -		qlt_send_resp_ctio(vha, cmd, scsi_status, sense_key, asc, ascq);
 -		/* assume scsi status gets out on the wire.
 -		 * Will not wait for completion.
 -		 */
 -		vha->hw->tgt.tgt_ops->free_cmd(cmd);
 -		break;
 -	}
 -}
 -
 -/* If hardware_lock held on entry, might drop it, then reaquire */
 -/* This function sends the appropriate CTIO to ISP 2xxx or 24xx */
 -static int __qlt_send_term_imm_notif(struct scsi_qla_host *vha,
 -	struct imm_ntfy_from_isp *ntfy)
 -{
 -	struct nack_to_isp *nack;
 -	struct qla_hw_data *ha = vha->hw;
 -	request_t *pkt;
 -	int ret = 0;
 -
 -	ql_dbg(ql_dbg_tgt_tmr, vha, 0xe01c,
 -	    "Sending TERM ELS CTIO (ha=%p)\n", ha);
 -
 -	pkt = (request_t *)qla2x00_alloc_iocbs(vha, NULL);
 -	if (pkt == NULL) {
 -		ql_dbg(ql_dbg_tgt, vha, 0xe080,
 -		    "qla_target(%d): %s failed: unable to allocate "
 -		    "request packet\n", vha->vp_idx, __func__);
 -		return -ENOMEM;
 -	}
 -
 -	pkt->entry_type = NOTIFY_ACK_TYPE;
 -	pkt->entry_count = 1;
 -	pkt->handle = QLA_TGT_SKIP_HANDLE;
 -
 -	nack = (struct nack_to_isp *)pkt;
 -	nack->ox_id = ntfy->ox_id;
 -
 -	nack->u.isp24.nport_handle = ntfy->u.isp24.nport_handle;
 -	if (le16_to_cpu(ntfy->u.isp24.status) == IMM_NTFY_ELS) {
 -		nack->u.isp24.flags = ntfy->u.isp24.flags &
 -			__constant_cpu_to_le32(NOTIFY24XX_FLAGS_PUREX_IOCB);
 -	}
 -
 -	/* terminate */
 -	nack->u.isp24.flags |=
 -		__constant_cpu_to_le16(NOTIFY_ACK_FLAGS_TERMINATE);
 -
 -	nack->u.isp24.srr_rx_id = ntfy->u.isp24.srr_rx_id;
 -	nack->u.isp24.status = ntfy->u.isp24.status;
 -	nack->u.isp24.status_subcode = ntfy->u.isp24.status_subcode;
 -	nack->u.isp24.fw_handle = ntfy->u.isp24.fw_handle;
 -	nack->u.isp24.exchange_address = ntfy->u.isp24.exchange_address;
 -	nack->u.isp24.srr_rel_offs = ntfy->u.isp24.srr_rel_offs;
 -	nack->u.isp24.srr_ui = ntfy->u.isp24.srr_ui;
 -	nack->u.isp24.vp_index = ntfy->u.isp24.vp_index;
 -
 -	qla2x00_start_iocbs(vha, vha->req);
 -	return ret;
 -}
 -
 -static void qlt_send_term_imm_notif(struct scsi_qla_host *vha,
 -	struct imm_ntfy_from_isp *imm, int ha_locked)
 -{
 -	unsigned long flags = 0;
 -	int rc;
 +	pkt = (struct ctio7_to_24xx *)prm.pkt;
 +	pkt->u.status0.flags |= cpu_to_le16(CTIO7_FLAGS_DATA_OUT |
 +	    CTIO7_FLAGS_STATUS_MODE_0);
 +	qlt_load_data_segments(&prm, vha);
  
 -	if (ha_locked) {
 -		rc = __qlt_send_term_imm_notif(vha, imm);
 +	cmd->state = QLA_TGT_STATE_NEED_DATA;
  
 -#if 0	/* Todo  */
 -		if (rc == -ENOMEM)
 -			qlt_alloc_qfull_cmd(vha, imm, 0, 0);
 -#else
 -		if (rc) {
 -		}
 -#endif
 -		goto done;
 -	}
 +	/* Memory Barrier */
 +	wmb();
 +	qla2x00_start_iocbs(vha, vha->req);
 +	spin_unlock_irqrestore(&ha->hardware_lock, flags);
  
 -	spin_lock_irqsave(&vha->hw->hardware_lock, flags);
 -	rc = __qlt_send_term_imm_notif(vha, imm);
 +	return res;
  
 -#if 0	/* Todo */
 -	if (rc == -ENOMEM)
 -		qlt_alloc_qfull_cmd(vha, imm, 0, 0);
 -#endif
 +out_unlock_free_unmap:
 +	if (cmd->sg_mapped)
 +		qlt_unmap_sg(vha, cmd);
 +	spin_unlock_irqrestore(&ha->hardware_lock, flags);
  
 -done:
 -	if (!ha_locked)
 -		spin_unlock_irqrestore(&vha->hw->hardware_lock, flags);
 +	return res;
  }
 +EXPORT_SYMBOL(qlt_rdy_to_xfer);
  
 -/*
 - * If hardware_lock held on entry, might drop it, then reaquire
 - * This function sends the appropriate CTIO to ISP 2xxx or 24xx
 - */
 -static int __qlt_send_term_exchange(struct qla_qpair *qpair,
 +
 +/* If hardware_lock held on entry, might drop it, then reaquire */
 +/* This function sends the appropriate CTIO to ISP 2xxx or 24xx */
 +static int __qlt_send_term_exchange(struct scsi_qla_host *vha,
  	struct qla_tgt_cmd *cmd,
  	struct atio_from_isp *atio)
  {
@@@ -2622,61 -3974,31 +3240,70 @@@ static struct qla_tgt_sess *qlt_make_lo
  /*
   * Process context for I/O path into tcm_qla2xxx code
   */
 -static void __qlt_do_work(struct qla_tgt_cmd *cmd)
 +static void qlt_do_work(struct work_struct *work)
  {
 +	struct qla_tgt_cmd *cmd = container_of(work, struct qla_tgt_cmd, work);
  	scsi_qla_host_t *vha = cmd->vha;
  	struct qla_hw_data *ha = vha->hw;
++<<<<<<< HEAD
 +	struct qla_tgt *tgt = ha->tgt.qla_tgt;
 +	struct qla_tgt_sess *sess = NULL;
++=======
+ 	struct fc_port *sess = cmd->sess;
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  	struct atio_from_isp *atio = &cmd->atio;
  	unsigned char *cdb;
  	unsigned long flags;
  	uint32_t data_length;
  	int ret, fcp_task_attr, data_dir, bidi = 0;
 -	struct qla_qpair *qpair = cmd->qpair;
  
++<<<<<<< HEAD
 +	if (tgt->tgt_stop)
 +		goto out_term;
++=======
+ 	cmd->cmd_in_wq = 0;
+ 	cmd->trc_flags |= TRC_DO_WORK;
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  
 -	if (cmd->aborted) {
 -		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf082,
 -		    "cmd with tag %u is aborted\n",
 -		    cmd->atio.u.isp24.exchange_addr);
 -		goto out_term;
 +	spin_lock_irqsave(&ha->hardware_lock, flags);
 +	sess = ha->tgt.tgt_ops->find_sess_by_s_id(vha,
 +	    atio->u.isp24.fcp_hdr.s_id);
 +	/* Do kref_get() before dropping qla_hw_data->hardware_lock. */
 +	if (sess)
 +		kref_get(&sess->se_sess->sess_kref);
 +	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 +
 +	if (unlikely(!sess)) {
 +		uint8_t *s_id =	atio->u.isp24.fcp_hdr.s_id;
 +
 +		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf022,
 +			"qla_target(%d): Unable to find wwn login"
 +			" (s_id %x:%x:%x), trying to create it manually\n",
 +			vha->vp_idx, s_id[0], s_id[1], s_id[2]);
 +
 +		if (atio->u.raw.entry_count > 1) {
 +			ql_dbg(ql_dbg_tgt_mgt, vha, 0xf023,
 +				"Dropping multy entry cmd %p\n", cmd);
 +			goto out_term;
 +		}
 +
 +		mutex_lock(&ha->tgt.tgt_mutex);
 +		sess = qlt_make_local_sess(vha, s_id);
 +		/* sess has an extra creation ref. */
 +		mutex_unlock(&ha->tgt.tgt_mutex);
 +
 +		if (!sess)
 +			goto out_term;
  	}
  
 -	spin_lock_init(&cmd->cmd_lock);
 +	cmd->sess = sess;
 +	cmd->loop_id = sess->loop_id;
 +	cmd->conf_compl_supported = sess->conf_compl_supported;
 +
  	cdb = &atio->u.isp24.fcp_cmnd.cdb[0];
 -	cmd->se_cmd.tag = atio->u.isp24.exchange_addr;
 +	cmd->tag = atio->u.isp24.exchange_addr;
 +	cmd->unpacked_lun = scsilun_to_int(
 +	    (struct scsi_lun *)&atio->u.isp24.fcp_cmnd.lun);
  
  	if (atio->u.isp24.fcp_cmnd.rddata &&
  	    atio->u.isp24.fcp_cmnd.wrdata) {
@@@ -2715,12 -4035,240 +3342,233 @@@ out_term
  	 * cmd has not sent to target yet, so pass NULL as the second
  	 * argument to qlt_send_term_exchange() and free the memory here.
  	 */
++<<<<<<< HEAD
 +	spin_lock_irqsave(&ha->hardware_lock, flags);
 +	qlt_send_term_exchange(vha, NULL, &cmd->atio, 1);
 +	kmem_cache_free(qla_tgt_cmd_cachep, cmd);
 +	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 +	if (sess)
++=======
+ 	cmd->trc_flags |= TRC_DO_WORK_ERR;
+ 	spin_lock_irqsave(qpair->qp_lock_ptr, flags);
+ 	qlt_send_term_exchange(qpair, NULL, &cmd->atio, 1, 0);
+ 
+ 	qlt_decr_num_pend_cmds(vha);
+ 	percpu_ida_free(&sess->se_sess->sess_tag_pool, cmd->se_cmd.map_tag);
+ 	spin_unlock_irqrestore(qpair->qp_lock_ptr, flags);
+ 
+ 	spin_lock_irqsave(&ha->tgt.sess_lock, flags);
+ 	ha->tgt.tgt_ops->put_sess(sess);
+ 	spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ }
+ 
+ static void qlt_do_work(struct work_struct *work)
+ {
+ 	struct qla_tgt_cmd *cmd = container_of(work, struct qla_tgt_cmd, work);
+ 	scsi_qla_host_t *vha = cmd->vha;
+ 	unsigned long flags;
+ 
+ 	spin_lock_irqsave(&vha->cmd_list_lock, flags);
+ 	list_del(&cmd->cmd_list);
+ 	spin_unlock_irqrestore(&vha->cmd_list_lock, flags);
+ 
+ 	__qlt_do_work(cmd);
+ }
+ 
+ void qlt_clr_qp_table(struct scsi_qla_host *vha)
+ {
+ 	unsigned long flags;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	struct qla_tgt *tgt = vha->vha_tgt.qla_tgt;
+ 	void *node;
+ 	u64 key = 0;
+ 
+ 	ql_log(ql_log_info, vha, 0x706c,
+ 	    "User update Number of Active Qpairs %d\n",
+ 	    ha->tgt.num_act_qpairs);
+ 
+ 	spin_lock_irqsave(&ha->tgt.atio_lock, flags);
+ 
+ 	btree_for_each_safe64(&tgt->lun_qpair_map, key, node)
+ 		btree_remove64(&tgt->lun_qpair_map, key);
+ 
+ 	ha->base_qpair->lun_cnt = 0;
+ 	for (key = 0; key < ha->max_qpairs; key++)
+ 		if (ha->queue_pair_map[key])
+ 			ha->queue_pair_map[key]->lun_cnt = 0;
+ 
+ 	spin_unlock_irqrestore(&ha->tgt.atio_lock, flags);
+ }
+ 
+ static void qlt_assign_qpair(struct scsi_qla_host *vha,
+ 	struct qla_tgt_cmd *cmd)
+ {
+ 	struct qla_qpair *qpair, *qp;
+ 	struct qla_tgt *tgt = vha->vha_tgt.qla_tgt;
+ 	struct qla_qpair_hint *h;
+ 
+ 	if (vha->flags.qpairs_available) {
+ 		h = btree_lookup64(&tgt->lun_qpair_map, cmd->unpacked_lun);
+ 		if (unlikely(!h)) {
+ 			/* spread lun to qpair ratio evently */
+ 			int lcnt = 0, rc;
+ 			struct scsi_qla_host *base_vha =
+ 				pci_get_drvdata(vha->hw->pdev);
+ 
+ 			qpair = vha->hw->base_qpair;
+ 			if (qpair->lun_cnt == 0) {
+ 				qpair->lun_cnt++;
+ 				h = qla_qpair_to_hint(tgt, qpair);
+ 				BUG_ON(!h);
+ 				rc = btree_insert64(&tgt->lun_qpair_map,
+ 					cmd->unpacked_lun, h, GFP_ATOMIC);
+ 				if (rc) {
+ 					qpair->lun_cnt--;
+ 					ql_log(ql_log_info, vha, 0xd037,
+ 					    "Unable to insert lun %llx into lun_qpair_map\n",
+ 					    cmd->unpacked_lun);
+ 				}
+ 				goto out;
+ 			} else {
+ 				lcnt = qpair->lun_cnt;
+ 			}
+ 
+ 			h = NULL;
+ 			list_for_each_entry(qp, &base_vha->qp_list,
+ 			    qp_list_elem) {
+ 				if (qp->lun_cnt == 0) {
+ 					qp->lun_cnt++;
+ 					h = qla_qpair_to_hint(tgt, qp);
+ 					BUG_ON(!h);
+ 					rc = btree_insert64(&tgt->lun_qpair_map,
+ 					    cmd->unpacked_lun, h, GFP_ATOMIC);
+ 					if (rc) {
+ 						qp->lun_cnt--;
+ 						ql_log(ql_log_info, vha, 0xd038,
+ 							"Unable to insert lun %llx into lun_qpair_map\n",
+ 							cmd->unpacked_lun);
+ 					}
+ 					qpair = qp;
+ 					goto out;
+ 				} else {
+ 					if (qp->lun_cnt < lcnt) {
+ 						lcnt = qp->lun_cnt;
+ 						qpair = qp;
+ 						continue;
+ 					}
+ 				}
+ 			}
+ 			BUG_ON(!qpair);
+ 			qpair->lun_cnt++;
+ 			h = qla_qpair_to_hint(tgt, qpair);
+ 			BUG_ON(!h);
+ 			rc = btree_insert64(&tgt->lun_qpair_map,
+ 				cmd->unpacked_lun, h, GFP_ATOMIC);
+ 			if (rc) {
+ 				qpair->lun_cnt--;
+ 				ql_log(ql_log_info, vha, 0xd039,
+ 				   "Unable to insert lun %llx into lun_qpair_map\n",
+ 				   cmd->unpacked_lun);
+ 			}
+ 		}
+ 	} else {
+ 		h = &tgt->qphints[0];
+ 	}
+ out:
+ 	cmd->qpair = h->qpair;
+ 	cmd->se_cmd.cpuid = h->cpuid;
+ }
+ 
+ static struct qla_tgt_cmd *qlt_get_tag(scsi_qla_host_t *vha,
+ 				       struct fc_port *sess,
+ 				       struct atio_from_isp *atio)
+ {
+ 	struct se_session *se_sess = sess->se_sess;
+ 	struct qla_tgt_cmd *cmd;
+ 	int tag;
+ 
+ 	tag = percpu_ida_alloc(&se_sess->sess_tag_pool, TASK_RUNNING);
+ 	if (tag < 0)
+ 		return NULL;
+ 
+ 	cmd = &((struct qla_tgt_cmd *)se_sess->sess_cmd_map)[tag];
+ 	memset(cmd, 0, sizeof(struct qla_tgt_cmd));
+ 	cmd->cmd_type = TYPE_TGT_CMD;
+ 	memcpy(&cmd->atio, atio, sizeof(*atio));
+ 	cmd->state = QLA_TGT_STATE_NEW;
+ 	cmd->tgt = vha->vha_tgt.qla_tgt;
+ 	qlt_incr_num_pend_cmds(vha);
+ 	cmd->vha = vha;
+ 	cmd->se_cmd.map_tag = tag;
+ 	cmd->sess = sess;
+ 	cmd->loop_id = sess->loop_id;
+ 	cmd->conf_compl_supported = sess->conf_compl_supported;
+ 
+ 	cmd->trc_flags = 0;
+ 	cmd->jiffies_at_alloc = get_jiffies_64();
+ 
+ 	cmd->unpacked_lun = scsilun_to_int(
+ 	    (struct scsi_lun *)&atio->u.isp24.fcp_cmnd.lun);
+ 	qlt_assign_qpair(vha, cmd);
+ 	cmd->reset_count = vha->hw->base_qpair->chip_reset;
+ 
+ 	return cmd;
+ }
+ 
+ static void qlt_create_sess_from_atio(struct work_struct *work)
+ {
+ 	struct qla_tgt_sess_op *op = container_of(work,
+ 					struct qla_tgt_sess_op, work);
+ 	scsi_qla_host_t *vha = op->vha;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	struct fc_port *sess;
+ 	struct qla_tgt_cmd *cmd;
+ 	unsigned long flags;
+ 	uint8_t *s_id = op->atio.u.isp24.fcp_hdr.s_id;
+ 
+ 	spin_lock_irqsave(&vha->cmd_list_lock, flags);
+ 	list_del(&op->cmd_list);
+ 	spin_unlock_irqrestore(&vha->cmd_list_lock, flags);
+ 
+ 	if (op->aborted) {
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf083,
+ 		    "sess_op with tag %u is aborted\n",
+ 		    op->atio.u.isp24.exchange_addr);
+ 		goto out_term;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf022,
+ 	    "qla_target(%d): Unable to find wwn login"
+ 	    " (s_id %x:%x:%x), trying to create it manually\n",
+ 	    vha->vp_idx, s_id[0], s_id[1], s_id[2]);
+ 
+ 	if (op->atio.u.raw.entry_count > 1) {
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf023,
+ 		    "Dropping multy entry atio %p\n", &op->atio);
+ 		goto out_term;
+ 	}
+ 
+ 	sess = qlt_make_local_sess(vha, s_id);
+ 	/* sess has an extra creation ref. */
+ 
+ 	if (!sess)
+ 		goto out_term;
+ 	/*
+ 	 * Now obtain a pre-allocated session tag using the original op->atio
+ 	 * packet header, and dispatch into __qlt_do_work() using the existing
+ 	 * process context.
+ 	 */
+ 	cmd = qlt_get_tag(vha, sess, &op->atio);
+ 	if (!cmd) {
+ 		struct qla_qpair *qpair = ha->base_qpair;
+ 
+ 		spin_lock_irqsave(qpair->qp_lock_ptr, flags);
+ 		qlt_send_busy(qpair, &op->atio, SAM_STAT_BUSY);
+ 		spin_unlock_irqrestore(qpair->qp_lock_ptr, flags);
+ 
+ 		spin_lock_irqsave(&ha->tgt.sess_lock, flags);
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  		ha->tgt.tgt_ops->put_sess(sess);
 -		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
 -		kfree(op);
 -		return;
 -	}
 -
 -	/*
 -	 * __qlt_do_work() will call qlt_put_sess() to release
 -	 * the extra reference taken above by qlt_make_local_sess()
 -	 */
 -	__qlt_do_work(cmd);
 -	kfree(op);
 -	return;
 -out_term:
 -	qlt_send_term_exchange(vha->hw->base_qpair, NULL, &op->atio, 0, 0);
 -	kfree(op);
  }
  
  /* ha->hardware_lock supposed to be held on entry */
@@@ -2784,75 -4387,16 +3632,80 @@@ static int qlt_issue_task_mgmt(struct q
  	}
  	mcmd->tmr_func = fn;
  	mcmd->flags = flags;
++<<<<<<< HEAD
++=======
+ 	mcmd->reset_count = ha->base_qpair->chip_reset;
+ 	mcmd->qpair = ha->base_qpair;
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
 +
 +	switch (fn) {
 +	case QLA_TGT_CLEAR_ACA:
 +		ql_dbg(ql_dbg_tgt_tmr, vha, 0x10000,
 +		    "qla_target(%d): CLEAR_ACA received\n", sess->vha->vp_idx);
 +		tmr_func = TMR_CLEAR_ACA;
 +		break;
 +
 +	case QLA_TGT_TARGET_RESET:
 +		ql_dbg(ql_dbg_tgt_tmr, vha, 0x10001,
 +		    "qla_target(%d): TARGET_RESET received\n",
 +		    sess->vha->vp_idx);
 +		tmr_func = TMR_TARGET_WARM_RESET;
 +		break;
 +
 +	case QLA_TGT_LUN_RESET:
 +		ql_dbg(ql_dbg_tgt_tmr, vha, 0x10002,
 +		    "qla_target(%d): LUN_RESET received\n", sess->vha->vp_idx);
 +		tmr_func = TMR_LUN_RESET;
 +		break;
 +
 +	case QLA_TGT_CLEAR_TS:
 +		ql_dbg(ql_dbg_tgt_tmr, vha, 0x10003,
 +		    "qla_target(%d): CLEAR_TS received\n", sess->vha->vp_idx);
 +		tmr_func = TMR_CLEAR_TASK_SET;
 +		break;
 +
 +	case QLA_TGT_ABORT_TS:
 +		ql_dbg(ql_dbg_tgt_tmr, vha, 0x10004,
 +		    "qla_target(%d): ABORT_TS received\n", sess->vha->vp_idx);
 +		tmr_func = TMR_ABORT_TASK_SET;
 +		break;
 +#if 0
 +	case QLA_TGT_ABORT_ALL:
 +		ql_dbg(ql_dbg_tgt_tmr, vha, 0x10005,
 +		    "qla_target(%d): Doing ABORT_ALL_TASKS\n",
 +		    sess->vha->vp_idx);
 +		tmr_func = 0;
 +		break;
  
 -	switch (fn) {
 -	case QLA_TGT_LUN_RESET:
 -	    abort_cmds_for_lun(vha, lun, a->u.isp24.fcp_hdr.s_id);
 -	    break;
 +	case QLA_TGT_ABORT_ALL_SESS:
 +		ql_dbg(ql_dbg_tgt_tmr, vha, 0x10006,
 +		    "qla_target(%d): Doing ABORT_ALL_TASKS_SESS\n",
 +		    sess->vha->vp_idx);
 +		tmr_func = 0;
 +		break;
 +
 +	case QLA_TGT_NEXUS_LOSS_SESS:
 +		ql_dbg(ql_dbg_tgt_tmr, vha, 0x10007,
 +		    "qla_target(%d): Doing NEXUS_LOSS_SESS\n",
 +		    sess->vha->vp_idx);
 +		tmr_func = 0;
 +		break;
 +
 +	case QLA_TGT_NEXUS_LOSS:
 +		ql_dbg(ql_dbg_tgt_tmr, vha, 0x10008,
 +		    "qla_target(%d): Doing NEXUS_LOSS\n", sess->vha->vp_idx);
 +		tmr_func = 0;
 +		break;
 +#endif
 +	default:
 +		ql_dbg(ql_dbg_tgt_tmr, vha, 0x1000a,
 +		    "qla_target(%d): Unknown task mgmt fn 0x%x\n",
 +		    sess->vha->vp_idx, fn);
 +		mempool_free(mcmd, qla_tgt_mgmt_cmd_mempool);
 +		return -ENOSYS;
  	}
  
 -	res = ha->tgt.tgt_ops->handle_tmr(mcmd, lun, mcmd->tmr_func, 0);
 +	res = ha->tgt.tgt_ops->handle_tmr(mcmd, lun, tmr_func, 0);
  	if (res != 0) {
  		ql_dbg(ql_dbg_tgt_tmr, vha, 0x1000b,
  		    "qla_target(%d): tgt.tgt_ops->handle_tmr() failed: %d\n",
@@@ -2916,11 -4468,13 +3769,19 @@@ static int __qlt_abort_task(struct scsi
  	memcpy(&mcmd->orig_iocb.imm_ntfy, iocb,
  	    sizeof(mcmd->orig_iocb.imm_ntfy));
  
++<<<<<<< HEAD
 +	lun = a->u.isp24.fcp_cmnd.lun;
 +	unpacked_lun = scsilun_to_int((struct scsi_lun *)&lun);
 +	mcmd->reset_count = vha->hw->chip_reset;
++=======
+ 	unpacked_lun =
+ 	    scsilun_to_int((struct scsi_lun *)&a->u.isp24.fcp_cmnd.lun);
+ 	mcmd->reset_count = ha->base_qpair->chip_reset;
+ 	mcmd->tmr_func = QLA_TGT_2G_ABORT_TASK;
+ 	mcmd->qpair = ha->base_qpair;
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  
 -	rc = ha->tgt.tgt_ops->handle_tmr(mcmd, unpacked_lun, mcmd->tmr_func,
 +	rc = ha->tgt.tgt_ops->handle_tmr(mcmd, unpacked_lun, TMR_ABORT_TASK,
  	    le16_to_cpu(iocb->u.isp2x.seq_id));
  	if (rc != 0) {
  		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf060,
@@@ -3634,7 -5120,213 +4495,217 @@@ static void qlt_send_busy(struct scsi_q
  	ctio24->u.status1.scsi_status = cpu_to_le16(status);
  	/* Memory Barrier */
  	wmb();
++<<<<<<< HEAD
 +	qla2x00_start_iocbs(vha, vha->req);
++=======
+ 	qla2x00_start_iocbs(vha, qpair->req);
+ 	return 0;
+ }
+ 
+ /*
+  * This routine is used to allocate a command for either a QFull condition
+  * (ie reply SAM_STAT_BUSY) or to terminate an exchange that did not go
+  * out previously.
+  */
+ static void
+ qlt_alloc_qfull_cmd(struct scsi_qla_host *vha,
+ 	struct atio_from_isp *atio, uint16_t status, int qfull)
+ {
+ 	struct qla_tgt *tgt = vha->vha_tgt.qla_tgt;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	struct fc_port *sess;
+ 	struct se_session *se_sess;
+ 	struct qla_tgt_cmd *cmd;
+ 	int tag;
+ 	unsigned long flags;
+ 
+ 	if (unlikely(tgt->tgt_stop)) {
+ 		ql_dbg(ql_dbg_io, vha, 0x300a,
+ 			"New command while device %p is shutting down\n", tgt);
+ 		return;
+ 	}
+ 
+ 	if ((vha->hw->tgt.num_qfull_cmds_alloc + 1) > MAX_QFULL_CMDS_ALLOC) {
+ 		vha->hw->tgt.num_qfull_cmds_dropped++;
+ 		if (vha->hw->tgt.num_qfull_cmds_dropped >
+ 			vha->qla_stats.stat_max_qfull_cmds_dropped)
+ 			vha->qla_stats.stat_max_qfull_cmds_dropped =
+ 				vha->hw->tgt.num_qfull_cmds_dropped;
+ 
+ 		ql_dbg(ql_dbg_io, vha, 0x3068,
+ 			"qla_target(%d): %s: QFull CMD dropped[%d]\n",
+ 			vha->vp_idx, __func__,
+ 			vha->hw->tgt.num_qfull_cmds_dropped);
+ 
+ 		qlt_chk_exch_leak_thresh_hold(vha);
+ 		return;
+ 	}
+ 
+ 	sess = ha->tgt.tgt_ops->find_sess_by_s_id
+ 		(vha, atio->u.isp24.fcp_hdr.s_id);
+ 	if (!sess)
+ 		return;
+ 
+ 	se_sess = sess->se_sess;
+ 
+ 	tag = percpu_ida_alloc(&se_sess->sess_tag_pool, TASK_RUNNING);
+ 	if (tag < 0)
+ 		return;
+ 
+ 	cmd = &((struct qla_tgt_cmd *)se_sess->sess_cmd_map)[tag];
+ 	if (!cmd) {
+ 		ql_dbg(ql_dbg_io, vha, 0x3009,
+ 			"qla_target(%d): %s: Allocation of cmd failed\n",
+ 			vha->vp_idx, __func__);
+ 
+ 		vha->hw->tgt.num_qfull_cmds_dropped++;
+ 		if (vha->hw->tgt.num_qfull_cmds_dropped >
+ 			vha->qla_stats.stat_max_qfull_cmds_dropped)
+ 			vha->qla_stats.stat_max_qfull_cmds_dropped =
+ 				vha->hw->tgt.num_qfull_cmds_dropped;
+ 
+ 		qlt_chk_exch_leak_thresh_hold(vha);
+ 		return;
+ 	}
+ 
+ 	memset(cmd, 0, sizeof(struct qla_tgt_cmd));
+ 
+ 	qlt_incr_num_pend_cmds(vha);
+ 	INIT_LIST_HEAD(&cmd->cmd_list);
+ 	memcpy(&cmd->atio, atio, sizeof(*atio));
+ 
+ 	cmd->tgt = vha->vha_tgt.qla_tgt;
+ 	cmd->vha = vha;
+ 	cmd->reset_count = ha->base_qpair->chip_reset;
+ 	cmd->q_full = 1;
+ 	cmd->qpair = ha->base_qpair;
+ 
+ 	if (qfull) {
+ 		cmd->q_full = 1;
+ 		/* NOTE: borrowing the state field to carry the status */
+ 		cmd->state = status;
+ 	} else
+ 		cmd->term_exchg = 1;
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.q_full_lock, flags);
+ 	list_add_tail(&cmd->cmd_list, &vha->hw->tgt.q_full_list);
+ 
+ 	vha->hw->tgt.num_qfull_cmds_alloc++;
+ 	if (vha->hw->tgt.num_qfull_cmds_alloc >
+ 		vha->qla_stats.stat_max_qfull_cmds_alloc)
+ 		vha->qla_stats.stat_max_qfull_cmds_alloc =
+ 			vha->hw->tgt.num_qfull_cmds_alloc;
+ 	spin_unlock_irqrestore(&vha->hw->tgt.q_full_lock, flags);
+ }
+ 
+ int
+ qlt_free_qfull_cmds(struct qla_qpair *qpair)
+ {
+ 	struct scsi_qla_host *vha = qpair->vha;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	unsigned long flags;
+ 	struct qla_tgt_cmd *cmd, *tcmd;
+ 	struct list_head free_list, q_full_list;
+ 	int rc = 0;
+ 
+ 	if (list_empty(&ha->tgt.q_full_list))
+ 		return 0;
+ 
+ 	INIT_LIST_HEAD(&free_list);
+ 	INIT_LIST_HEAD(&q_full_list);
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.q_full_lock, flags);
+ 	if (list_empty(&ha->tgt.q_full_list)) {
+ 		spin_unlock_irqrestore(&vha->hw->tgt.q_full_lock, flags);
+ 		return 0;
+ 	}
+ 
+ 	list_splice_init(&vha->hw->tgt.q_full_list, &q_full_list);
+ 	spin_unlock_irqrestore(&vha->hw->tgt.q_full_lock, flags);
+ 
+ 	spin_lock_irqsave(qpair->qp_lock_ptr, flags);
+ 	list_for_each_entry_safe(cmd, tcmd, &q_full_list, cmd_list) {
+ 		if (cmd->q_full)
+ 			/* cmd->state is a borrowed field to hold status */
+ 			rc = __qlt_send_busy(qpair, &cmd->atio, cmd->state);
+ 		else if (cmd->term_exchg)
+ 			rc = __qlt_send_term_exchange(qpair, NULL, &cmd->atio);
+ 
+ 		if (rc == -ENOMEM)
+ 			break;
+ 
+ 		if (cmd->q_full)
+ 			ql_dbg(ql_dbg_io, vha, 0x3006,
+ 			    "%s: busy sent for ox_id[%04x]\n", __func__,
+ 			    be16_to_cpu(cmd->atio.u.isp24.fcp_hdr.ox_id));
+ 		else if (cmd->term_exchg)
+ 			ql_dbg(ql_dbg_io, vha, 0x3007,
+ 			    "%s: Term exchg sent for ox_id[%04x]\n", __func__,
+ 			    be16_to_cpu(cmd->atio.u.isp24.fcp_hdr.ox_id));
+ 		else
+ 			ql_dbg(ql_dbg_io, vha, 0x3008,
+ 			    "%s: Unexpected cmd in QFull list %p\n", __func__,
+ 			    cmd);
+ 
+ 		list_del(&cmd->cmd_list);
+ 		list_add_tail(&cmd->cmd_list, &free_list);
+ 
+ 		/* piggy back on hardware_lock for protection */
+ 		vha->hw->tgt.num_qfull_cmds_alloc--;
+ 	}
+ 	spin_unlock_irqrestore(qpair->qp_lock_ptr, flags);
+ 
+ 	cmd = NULL;
+ 
+ 	list_for_each_entry_safe(cmd, tcmd, &free_list, cmd_list) {
+ 		list_del(&cmd->cmd_list);
+ 		/* This cmd was never sent to TCM.  There is no need
+ 		 * to schedule free or call free_cmd
+ 		 */
+ 		qlt_free_cmd(cmd);
+ 	}
+ 
+ 	if (!list_empty(&q_full_list)) {
+ 		spin_lock_irqsave(&vha->hw->tgt.q_full_lock, flags);
+ 		list_splice(&q_full_list, &vha->hw->tgt.q_full_list);
+ 		spin_unlock_irqrestore(&vha->hw->tgt.q_full_lock, flags);
+ 	}
+ 
+ 	return rc;
+ }
+ 
+ static void
+ qlt_send_busy(struct qla_qpair *qpair, struct atio_from_isp *atio,
+     uint16_t status)
+ {
+ 	int rc = 0;
+ 	struct scsi_qla_host *vha = qpair->vha;
+ 
+ 	rc = __qlt_send_busy(qpair, atio, status);
+ 	if (rc == -ENOMEM)
+ 		qlt_alloc_qfull_cmd(vha, atio, status, 1);
+ }
+ 
+ static int
+ qlt_chk_qfull_thresh_hold(struct scsi_qla_host *vha, struct qla_qpair *qpair,
+ 	struct atio_from_isp *atio, uint8_t ha_locked)
+ {
+ 	struct qla_hw_data *ha = vha->hw;
+ 	uint16_t status;
+ 	unsigned long flags;
+ 
+ 	if (ha->tgt.num_pend_cmds < Q_FULL_THRESH_HOLD(ha))
+ 		return 0;
+ 
+ 	if (!ha_locked)
+ 		spin_lock_irqsave(&ha->hardware_lock, flags);
+ 	status = temp_sam_status;
+ 	qlt_send_busy(qpair, atio, status);
+ 	if (!ha_locked)
+ 		spin_unlock_irqrestore(&ha->hardware_lock, flags);
+ 
+ 	return 1;
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  }
  
  /* ha->hardware_lock supposed to be held on entry */
@@@ -4947,14 -6844,62 +6018,72 @@@ qla83xx_msix_atio_q(int irq, void *dev_
  	ha = rsp->hw;
  	vha = pci_get_drvdata(ha->pdev);
  
++<<<<<<< HEAD
++=======
+ 	spin_lock_irqsave(&ha->tgt.atio_lock, flags);
+ 
+ 	qlt_24xx_process_atio_queue(vha, 0);
+ 
+ 	spin_unlock_irqrestore(&ha->tgt.atio_lock, flags);
+ 
+ 	return IRQ_HANDLED;
+ }
+ 
+ static void
+ qlt_handle_abts_recv_work(struct work_struct *work)
+ {
+ 	struct qla_tgt_sess_op *op = container_of(work,
+ 		struct qla_tgt_sess_op, work);
+ 	scsi_qla_host_t *vha = op->vha;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	unsigned long flags;
+ 
+ 	if (qla2x00_reset_active(vha) ||
+ 	    (op->chip_reset != ha->base_qpair->chip_reset))
+ 		return;
+ 
+ 	spin_lock_irqsave(&ha->tgt.atio_lock, flags);
+ 	qlt_24xx_process_atio_queue(vha, 0);
+ 	spin_unlock_irqrestore(&ha->tgt.atio_lock, flags);
+ 
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  	spin_lock_irqsave(&ha->hardware_lock, flags);
 -	qlt_response_pkt_all_vps(vha, op->rsp, (response_t *)&op->atio);
 +
 +	qlt_24xx_process_atio_queue(vha);
 +	qla24xx_process_response_queue(vha, rsp);
 +
  	spin_unlock_irqrestore(&ha->hardware_lock, flags);
  
++<<<<<<< HEAD
 +	return IRQ_HANDLED;
++=======
+ 	kfree(op);
+ }
+ 
+ void
+ qlt_handle_abts_recv(struct scsi_qla_host *vha, struct rsp_que *rsp,
+     response_t *pkt)
+ {
+ 	struct qla_tgt_sess_op *op;
+ 
+ 	op = kzalloc(sizeof(*op), GFP_ATOMIC);
+ 
+ 	if (!op) {
+ 		/* do not reach for ATIO queue here.  This is best effort err
+ 		 * recovery at this point.
+ 		 */
+ 		qlt_response_pkt_all_vps(vha, rsp, pkt);
+ 		return;
+ 	}
+ 
+ 	memcpy(&op->atio, pkt, sizeof(*pkt));
+ 	op->vha = vha;
+ 	op->chip_reset = vha->hw->base_qpair->chip_reset;
+ 	op->rsp = rsp;
+ 	INIT_WORK(&op->work, qlt_handle_abts_recv_work);
+ 	queue_work(qla_tgt_wq, &op->work);
+ 	return;
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  }
  
  int
diff --cc drivers/scsi/qla2xxx/qla_target.h
index b33e411f28a0,5f497311d7b7..000000000000
--- a/drivers/scsi/qla2xxx/qla_target.h
+++ b/drivers/scsi/qla2xxx/qla_target.h
@@@ -829,10 -873,16 +829,22 @@@ struct qla_tgt_sess 
  };
  
  struct qla_tgt_cmd {
++<<<<<<< HEAD
 +	struct qla_tgt_sess *sess;
++=======
+ 	/*
+ 	 * Do not move cmd_type field. it needs to line up with srb->cmd_type
+ 	 */
+ 	uint8_t cmd_type;
+ 	uint8_t pad[7];
+ 	struct se_cmd se_cmd;
+ 	struct fc_port *sess;
+ 	struct qla_qpair *qpair;
+ 	uint32_t reset_count;
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  	int state;
 +	struct se_cmd se_cmd;
 +	struct work_struct free_work;
  	struct work_struct work;
  	/* Sense buffer that will be mapped into outgoing status */
  	unsigned char sense_buffer[TRANSPORT_SENSE_BUFFER];
@@@ -897,8 -979,7 +909,11 @@@ struct qla_tgt_prm 
  	int seg_cnt;
  	int req_cnt;
  	uint16_t rq_result;
++<<<<<<< HEAD
 +	uint16_t scsi_status;
 +	unsigned char *sense_buffer;
++=======
++>>>>>>> 7c3f8fd10bab (scsi: qla2xxx: move fields from qla_hw_data to qla_qpair)
  	int sense_buffer_len;
  	int residual;
  	int add_status_pkt;
diff --git a/drivers/scsi/qla2xxx/qla_attr.c b/drivers/scsi/qla2xxx/qla_attr.c
index 23b15e5afee2..521fe118221e 100644
--- a/drivers/scsi/qla2xxx/qla_attr.c
+++ b/drivers/scsi/qla2xxx/qla_attr.c
@@ -2249,7 +2249,7 @@ qla2x00_init_host_attr(scsi_qla_host_t *vha)
 	fc_host_dev_loss_tmo(vha->host) = ha->port_down_retry_count;
 	fc_host_node_name(vha->host) = wwn_to_u64(vha->node_name);
 	fc_host_port_name(vha->host) = wwn_to_u64(vha->port_name);
-	fc_host_supported_classes(vha->host) = ha->tgt.enable_class_2 ?
+	fc_host_supported_classes(vha->host) = ha->base_qpair->enable_class_2 ?
 			(FC_COS_CLASS2|FC_COS_CLASS3) : FC_COS_CLASS3;
 	fc_host_max_npiv_vports(vha->host) = ha->max_npiv_vports;
 	fc_host_npiv_vports_inuse(vha->host) = ha->cur_vport_count;
* Unmerged path drivers/scsi/qla2xxx/qla_def.h
* Unmerged path drivers/scsi/qla2xxx/qla_init.c
* Unmerged path drivers/scsi/qla2xxx/qla_os.c
* Unmerged path drivers/scsi/qla2xxx/qla_target.c
* Unmerged path drivers/scsi/qla2xxx/qla_target.h
