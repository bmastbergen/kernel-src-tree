x86/mm: Prepare sme_encrypt_kernel() for PAGE aligned encryption

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [x86] mm: Prepare sme_encrypt_kernel() for PAGE aligned encryption (Suravee Suthikulpanit) [1540104]
Rebuild_FUZZ: 96.77%
commit-author Tom Lendacky <thomas.lendacky@amd.com>
commit cc5f01e28d6c60f274fd1e33b245f679f79f543c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/cc5f01e2.failed

In preparation for encrypting more than just the kernel, the encryption
support in sme_encrypt_kernel() needs to support 4KB page aligned
encryption instead of just 2MB large page aligned encryption.

Update the routines that populate the PGD to support non-2MB aligned
addresses.  This is done by creating PTE page tables for the start
and end portion of the address range that fall outside of the 2MB
alignment.  This results in, at most, two extra pages to hold the
PTE entries for each mapping of a range.

	Tested-by: Gabriel Craciunescu <nix.or.die@gmail.com>
	Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
	Reviewed-by: Borislav Petkov <bp@suse.de>
	Cc: Borislav Petkov <bp@alien8.de>
	Cc: Brijesh Singh <brijesh.singh@amd.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
Link: http://lkml.kernel.org/r/20180110192626.6026.75387.stgit@tlendack-t1.amdoffice.net
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit cc5f01e28d6c60f274fd1e33b245f679f79f543c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/mm/mem_encrypt.c
#	arch/x86/mm/mem_encrypt_boot.S
* Unmerged path arch/x86/mm/mem_encrypt.c
* Unmerged path arch/x86/mm/mem_encrypt_boot.S
* Unmerged path arch/x86/mm/mem_encrypt.c
* Unmerged path arch/x86/mm/mem_encrypt_boot.S
