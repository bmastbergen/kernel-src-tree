qed: Implement iWARP initialization, teardown and qp operations

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Kalderon, Michal <Michal.Kalderon@cavium.com>
commit 67b40dccc45ff5d488aad17114e80e00029fd854
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/67b40dcc.failed

This patch adds iWARP support for flows that have common code
between RoCE and iWARP, such as initialization, teardown and
qp setup verbs: create, destroy, modify, query.
It introduces the iWARP specific files qed_iwarp.[ch] and
iwarp_common.h

	Signed-off-by: Michal Kalderon <Michal.Kalderon@cavium.com>
	Signed-off-by: Yuval Mintz <Yuval.Mintz@cavium.com>
	Signed-off-by: Ariel Elior <Ariel.Elior@cavium.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 67b40dccc45ff5d488aad17114e80e00029fd854)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/qlogic/qed/Makefile
#	drivers/net/ethernet/qlogic/qed/qed_dev.c
#	drivers/net/ethernet/qlogic/qed/qed_rdma.c
#	drivers/net/ethernet/qlogic/qed/qed_rdma.h
#	drivers/net/ethernet/qlogic/qed/qed_roce.c
diff --cc drivers/net/ethernet/qlogic/qed/Makefile
index e23408341819,82dd47068e18..000000000000
--- a/drivers/net/ethernet/qlogic/qed/Makefile
+++ b/drivers/net/ethernet/qlogic/qed/Makefile
@@@ -2,9 -2,9 +2,13 @@@ obj-$(CONFIG_QED) := qed.
  
  qed-y := qed_cxt.o qed_dev.o qed_hw.o qed_init_fw_funcs.o qed_init_ops.o \
  	 qed_int.o qed_main.o qed_mcp.o qed_sp_commands.o qed_spq.o qed_l2.o \
 -	 qed_selftest.o qed_dcbx.o qed_debug.o qed_ptp.o
 +	 qed_selftest.o qed_dcbx.o qed_debug.o
  qed-$(CONFIG_QED_SRIOV) += qed_sriov.o qed_vf.o
  qed-$(CONFIG_QED_LL2) += qed_ll2.o
++<<<<<<< HEAD
 +qed-$(CONFIG_QED_RDMA) += qed_roce.o
++=======
+ qed-$(CONFIG_QED_RDMA) += qed_roce.o qed_rdma.o qed_iwarp.o
++>>>>>>> 67b40dccc45f (qed: Implement iWARP initialization, teardown and qp operations)
  qed-$(CONFIG_QED_ISCSI) += qed_iscsi.o qed_ooo.o
  qed-$(CONFIG_QED_FCOE) += qed_fcoe.o
diff --cc drivers/net/ethernet/qlogic/qed/qed_dev.c
index 1b5a3d62b9f3,6c8505dc5c31..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_dev.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_dev.c
@@@ -932,9 -936,16 +932,20 @@@ int qed_resc_alloc(struct qed_dev *cdev
  
  		/* EQ */
  		n_eqes = qed_chain_get_capacity(&p_hwfn->p_spq->chain);
++<<<<<<< HEAD
 +		if (p_hwfn->hw_info.personality == QED_PCI_ETH_ROCE) {
++=======
+ 		if (QED_IS_RDMA_PERSONALITY(p_hwfn)) {
+ 			enum protocol_type rdma_proto;
+ 
+ 			if (QED_IS_ROCE_PERSONALITY(p_hwfn))
+ 				rdma_proto = PROTOCOLID_ROCE;
+ 			else
+ 				rdma_proto = PROTOCOLID_IWARP;
+ 
++>>>>>>> 67b40dccc45f (qed: Implement iWARP initialization, teardown and qp operations)
  			num_cons = qed_cxt_get_proto_cid_count(p_hwfn,
- 							       PROTOCOLID_ROCE,
+ 							       rdma_proto,
  							       NULL) * 2;
  			n_eqes += num_cons + 2 * MAX_NUM_VFS_BB;
  		} else if (p_hwfn->hw_info.personality == QED_PCI_ISCSI) {
diff --cc drivers/net/ethernet/qlogic/qed/qed_rdma.c
index 9dc41a899ef2,ee6887f8c260..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_rdma.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_rdma.c
@@@ -666,8 -648,15 +673,20 @@@ static int qed_rdma_setup(struct qed_hw
  	if (rc)
  		return rc;
  
++<<<<<<< HEAD
 +	qed_spq_register_async_cb(p_hwfn, PROTOCOLID_ROCE,
 +				  qed_roce_async_event);
++=======
+ 	if (QED_IS_IWARP_PERSONALITY(p_hwfn)) {
+ 		rc = qed_iwarp_setup(p_hwfn, p_ptt, params);
+ 		if (rc)
+ 			return rc;
+ 	} else {
+ 		rc = qed_roce_setup(p_hwfn);
+ 		if (rc)
+ 			return rc;
+ 	}
++>>>>>>> 67b40dccc45f (qed: Implement iWARP initialization, teardown and qp operations)
  
  	return qed_rdma_start_fw(p_hwfn, params, p_ptt);
  }
diff --cc drivers/net/ethernet/qlogic/qed/qed_rdma.h
index b178d9994a45,90e4e0f13727..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_rdma.h
+++ b/drivers/net/ethernet/qlogic/qed/qed_rdma.h
@@@ -42,7 -42,8 +42,12 @@@
  #include "qed.h"
  #include "qed_dev_api.h"
  #include "qed_hsi.h"
++<<<<<<< HEAD
 +#include "qed_ll2.h"
++=======
+ #include "qed_iwarp.h"
+ #include "qed_roce.h"
++>>>>>>> 67b40dccc45f (qed: Implement iWARP initialization, teardown and qp operations)
  
  #define QED_RDMA_MAX_FMR                    (RDMA_MAX_TIDS)
  #define QED_RDMA_MAX_P_KEY                  (1)
diff --cc drivers/net/ethernet/qlogic/qed/qed_roce.c
index 7c1640575bc6,fb7c2d1562ae..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_roce.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_roce.c
@@@ -2694,405 -1143,29 +2694,428 @@@ void qed_roce_dpm_dcbx(struct qed_hwfn 
  	qed_rdma_dpm_conf(p_hwfn, p_ptt);
  }
  
 -int qed_roce_setup(struct qed_hwfn *p_hwfn)
 +void qed_rdma_dpm_bar(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)
 +{
 +	p_hwfn->db_bar_no_edpm = true;
 +
 +	qed_rdma_dpm_conf(p_hwfn, p_ptt);
 +}
 +
++<<<<<<< HEAD
 +static int qed_rdma_start(void *rdma_cxt,
 +			  struct qed_rdma_start_in_params *params)
 +{
 +	struct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;
 +	struct qed_ptt *p_ptt;
 +	int rc = -EBUSY;
 +
 +	DP_VERBOSE(p_hwfn, QED_MSG_RDMA,
 +		   "desired_cnq = %08x\n", params->desired_cnq);
 +
 +	p_ptt = qed_ptt_acquire(p_hwfn);
 +	if (!p_ptt)
 +		goto err;
 +
 +	rc = qed_rdma_alloc(p_hwfn, p_ptt, params);
 +	if (rc)
 +		goto err1;
 +
 +	rc = qed_rdma_setup(p_hwfn, p_ptt, params);
 +	if (rc)
 +		goto err2;
 +
 +	qed_ptt_release(p_hwfn, p_ptt);
 +
 +	return rc;
 +
 +err2:
 +	qed_rdma_free(p_hwfn);
 +err1:
 +	qed_ptt_release(p_hwfn, p_ptt);
 +err:
 +	DP_VERBOSE(p_hwfn, QED_MSG_RDMA, "RDMA start - error, rc = %d\n", rc);
 +	return rc;
 +}
 +
 +static int qed_rdma_init(struct qed_dev *cdev,
 +			 struct qed_rdma_start_in_params *params)
 +{
 +	return qed_rdma_start(QED_LEADING_HWFN(cdev), params);
 +}
 +
 +static void qed_rdma_remove_user(void *rdma_cxt, u16 dpi)
 +{
 +	struct qed_hwfn *p_hwfn = (struct qed_hwfn *)rdma_cxt;
 +
 +	DP_VERBOSE(p_hwfn, QED_MSG_RDMA, "dpi = %08x\n", dpi);
 +
 +	spin_lock_bh(&p_hwfn->p_rdma_info->lock);
 +	qed_bmap_release_id(p_hwfn, &p_hwfn->p_rdma_info->dpi_map, dpi);
 +	spin_unlock_bh(&p_hwfn->p_rdma_info->lock);
 +}
 +
 +void qed_ll2b_complete_tx_gsi_packet(struct qed_hwfn *p_hwfn,
 +				     u8 connection_handle,
 +				     void *cookie,
 +				     dma_addr_t first_frag_addr,
 +				     bool b_last_fragment, bool b_last_packet)
 +{
 +	struct qed_roce_ll2_packet *packet = cookie;
 +	struct qed_roce_ll2_info *roce_ll2 = p_hwfn->ll2;
 +
 +	roce_ll2->cbs.tx_cb(roce_ll2->cb_cookie, packet);
 +}
 +
 +void qed_ll2b_release_tx_gsi_packet(struct qed_hwfn *p_hwfn,
 +				    u8 connection_handle,
 +				    void *cookie,
 +				    dma_addr_t first_frag_addr,
 +				    bool b_last_fragment, bool b_last_packet)
 +{
 +	qed_ll2b_complete_tx_gsi_packet(p_hwfn, connection_handle,
 +					cookie, first_frag_addr,
 +					b_last_fragment, b_last_packet);
 +}
 +
 +void qed_ll2b_complete_rx_gsi_packet(struct qed_hwfn *p_hwfn,
 +				     u8 connection_handle,
 +				     void *cookie,
 +				     dma_addr_t rx_buf_addr,
 +				     u16 data_length,
 +				     u8 data_length_error,
 +				     u16 parse_flags,
 +				     u16 vlan,
 +				     u32 src_mac_addr_hi,
 +				     u16 src_mac_addr_lo, bool b_last_packet)
 +{
 +	struct qed_roce_ll2_info *roce_ll2 = p_hwfn->ll2;
 +	struct qed_roce_ll2_rx_params params;
 +	struct qed_dev *cdev = p_hwfn->cdev;
 +	struct qed_roce_ll2_packet pkt;
 +
 +	DP_VERBOSE(cdev,
 +		   QED_MSG_LL2,
 +		   "roce ll2 rx complete: bus_addr=%p, len=%d, data_len_err=%d\n",
 +		   (void *)(uintptr_t)rx_buf_addr,
 +		   data_length, data_length_error);
 +
 +	memset(&pkt, 0, sizeof(pkt));
 +	pkt.n_seg = 1;
 +	pkt.payload[0].baddr = rx_buf_addr;
 +	pkt.payload[0].len = data_length;
 +
 +	memset(&params, 0, sizeof(params));
 +	params.vlan_id = vlan;
 +	*((u32 *)&params.smac[0]) = ntohl(src_mac_addr_hi);
 +	*((u16 *)&params.smac[4]) = ntohs(src_mac_addr_lo);
 +
 +	if (data_length_error) {
 +		DP_ERR(cdev,
 +		       "roce ll2 rx complete: data length error %d, length=%d\n",
 +		       data_length_error, data_length);
 +		params.rc = -EINVAL;
 +	}
 +
 +	roce_ll2->cbs.rx_cb(roce_ll2->cb_cookie, &pkt, &params);
 +}
 +
 +static int qed_roce_ll2_set_mac_filter(struct qed_dev *cdev,
 +				       u8 *old_mac_address,
 +				       u8 *new_mac_address)
 +{
 +	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
 +	struct qed_ptt *p_ptt;
 +	int rc = 0;
 +
 +	if (!hwfn->ll2 || hwfn->ll2->handle == QED_LL2_UNUSED_HANDLE) {
 +		DP_ERR(cdev,
 +		       "qed roce mac filter failed - roce_info/ll2 NULL\n");
 +		return -EINVAL;
 +	}
 +
 +	p_ptt = qed_ptt_acquire(QED_LEADING_HWFN(cdev));
 +	if (!p_ptt) {
 +		DP_ERR(cdev,
 +		       "qed roce ll2 mac filter set: failed to acquire PTT\n");
 +		return -EINVAL;
 +	}
 +
 +	mutex_lock(&hwfn->ll2->lock);
 +	if (old_mac_address)
 +		qed_llh_remove_mac_filter(QED_LEADING_HWFN(cdev), p_ptt,
 +					  old_mac_address);
 +	if (new_mac_address)
 +		rc = qed_llh_add_mac_filter(QED_LEADING_HWFN(cdev), p_ptt,
 +					    new_mac_address);
 +	mutex_unlock(&hwfn->ll2->lock);
 +
 +	qed_ptt_release(QED_LEADING_HWFN(cdev), p_ptt);
 +
 +	if (rc)
 +		DP_ERR(cdev,
 +		       "qed roce ll2 mac filter set: failed to add mac filter\n");
 +
 +	return rc;
 +}
 +
 +static int qed_roce_ll2_start(struct qed_dev *cdev,
 +			      struct qed_roce_ll2_params *params)
  {
 -	return qed_spq_register_async_cb(p_hwfn, PROTOCOLID_ROCE,
 -					 qed_roce_async_event);
 +	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
 +	struct qed_roce_ll2_info *roce_ll2;
 +	struct qed_ll2_conn ll2_params;
 +	int rc;
 +
 +	if (!params) {
 +		DP_ERR(cdev, "qed roce ll2 start: failed due to NULL params\n");
 +		return -EINVAL;
 +	}
 +	if (!params->cbs.tx_cb || !params->cbs.rx_cb) {
 +		DP_ERR(cdev,
 +		       "qed roce ll2 start: failed due to NULL tx/rx. tx_cb=%p, rx_cb=%p\n",
 +		       params->cbs.tx_cb, params->cbs.rx_cb);
 +		return -EINVAL;
 +	}
 +	if (!is_valid_ether_addr(params->mac_address)) {
 +		DP_ERR(cdev,
 +		       "qed roce ll2 start: failed due to invalid Ethernet address %pM\n",
 +		       params->mac_address);
 +		return -EINVAL;
 +	}
 +
 +	/* Initialize */
 +	roce_ll2 = kzalloc(sizeof(*roce_ll2), GFP_ATOMIC);
 +	if (!roce_ll2) {
 +		DP_ERR(cdev, "qed roce ll2 start: failed memory allocation\n");
 +		return -ENOMEM;
 +	}
 +	roce_ll2->handle = QED_LL2_UNUSED_HANDLE;
 +	roce_ll2->cbs = params->cbs;
 +	roce_ll2->cb_cookie = params->cb_cookie;
 +	mutex_init(&roce_ll2->lock);
 +
 +	memset(&ll2_params, 0, sizeof(ll2_params));
 +	ll2_params.conn_type = QED_LL2_TYPE_ROCE;
 +	ll2_params.mtu = params->mtu;
 +	ll2_params.rx_drop_ttl0_flg = true;
 +	ll2_params.rx_vlan_removal_en = false;
 +	ll2_params.tx_dest = CORE_TX_DEST_NW;
 +	ll2_params.ai_err_packet_too_big = LL2_DROP_PACKET;
 +	ll2_params.ai_err_no_buf = LL2_DROP_PACKET;
 +	ll2_params.gsi_enable = true;
 +
 +	rc = qed_ll2_acquire_connection(QED_LEADING_HWFN(cdev), &ll2_params,
 +					params->max_rx_buffers,
 +					params->max_tx_buffers,
 +					&roce_ll2->handle);
 +	if (rc) {
 +		DP_ERR(cdev,
 +		       "qed roce ll2 start: failed to acquire LL2 connection (rc=%d)\n",
 +		       rc);
 +		goto err;
 +	}
 +
 +	rc = qed_ll2_establish_connection(QED_LEADING_HWFN(cdev),
 +					  roce_ll2->handle);
 +	if (rc) {
 +		DP_ERR(cdev,
 +		       "qed roce ll2 start: failed to establish LL2 connection (rc=%d)\n",
 +		       rc);
 +		goto err1;
 +	}
 +
 +	hwfn->ll2 = roce_ll2;
 +
 +	rc = qed_roce_ll2_set_mac_filter(cdev, NULL, params->mac_address);
 +	if (rc) {
 +		hwfn->ll2 = NULL;
 +		goto err2;
 +	}
 +	ether_addr_copy(roce_ll2->mac_address, params->mac_address);
 +
 +	return 0;
 +
 +err2:
 +	qed_ll2_terminate_connection(QED_LEADING_HWFN(cdev), roce_ll2->handle);
 +err1:
 +	qed_ll2_release_connection(QED_LEADING_HWFN(cdev), roce_ll2->handle);
 +err:
 +	kfree(roce_ll2);
 +	return rc;
 +}
 +
 +static int qed_roce_ll2_stop(struct qed_dev *cdev)
 +{
 +	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
 +	struct qed_roce_ll2_info *roce_ll2 = hwfn->ll2;
 +	int rc;
 +
 +	if (roce_ll2->handle == QED_LL2_UNUSED_HANDLE) {
 +		DP_ERR(cdev, "qed roce ll2 stop: cannot stop an unused LL2\n");
 +		return -EINVAL;
 +	}
 +
 +	/* remove LL2 MAC address filter */
 +	rc = qed_roce_ll2_set_mac_filter(cdev, roce_ll2->mac_address, NULL);
 +	eth_zero_addr(roce_ll2->mac_address);
 +
 +	rc = qed_ll2_terminate_connection(QED_LEADING_HWFN(cdev),
 +					  roce_ll2->handle);
 +	if (rc)
 +		DP_ERR(cdev,
 +		       "qed roce ll2 stop: failed to terminate LL2 connection (rc=%d)\n",
 +		       rc);
 +
 +	qed_ll2_release_connection(QED_LEADING_HWFN(cdev), roce_ll2->handle);
 +
 +	roce_ll2->handle = QED_LL2_UNUSED_HANDLE;
 +
 +	kfree(roce_ll2);
 +
 +	return rc;
 +}
 +
 +static int qed_roce_ll2_tx(struct qed_dev *cdev,
 +			   struct qed_roce_ll2_packet *pkt,
 +			   struct qed_roce_ll2_tx_params *params)
 +{
 +	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
 +	struct qed_roce_ll2_info *roce_ll2 = hwfn->ll2;
 +	enum qed_ll2_roce_flavor_type qed_roce_flavor;
 +	struct qed_ll2_tx_pkt_info ll2_pkt;
 +	u8 flags = 0;
 +	int rc;
 +	int i;
 +
 +	if (!pkt || !params) {
 +		DP_ERR(cdev,
 +		       "roce ll2 tx: failed tx because one of the following is NULL - drv=%p, pkt=%p, params=%p\n",
 +		       cdev, pkt, params);
 +		return -EINVAL;
 +	}
 +
 +	qed_roce_flavor = (pkt->roce_mode == ROCE_V1) ? QED_LL2_ROCE
 +						      : QED_LL2_RROCE;
 +
 +	if (pkt->roce_mode == ROCE_V2_IPV4)
 +		flags |= BIT(CORE_TX_BD_DATA_IP_CSUM_SHIFT);
 +
 +	/* Tx header */
 +	memset(&ll2_pkt, 0, sizeof(ll2_pkt));
 +	ll2_pkt.num_of_bds = 1 + pkt->n_seg;
 +	ll2_pkt.bd_flags = flags;
 +	ll2_pkt.tx_dest = QED_LL2_TX_DEST_NW;
 +	ll2_pkt.qed_roce_flavor = qed_roce_flavor;
 +	ll2_pkt.first_frag = pkt->header.baddr;
 +	ll2_pkt.first_frag_len = pkt->header.len;
 +	ll2_pkt.cookie = pkt;
 +
 +	rc = qed_ll2_prepare_tx_packet(QED_LEADING_HWFN(cdev),
 +				       roce_ll2->handle,
 +				       &ll2_pkt, 1);
 +	if (rc) {
 +		DP_ERR(cdev, "roce ll2 tx: header failed (rc=%d)\n", rc);
 +		return QED_ROCE_TX_HEAD_FAILURE;
 +	}
 +
 +	/* Tx payload */
 +	for (i = 0; i < pkt->n_seg; i++) {
 +		rc = qed_ll2_set_fragment_of_tx_packet(QED_LEADING_HWFN(cdev),
 +						       roce_ll2->handle,
 +						       pkt->payload[i].baddr,
 +						       pkt->payload[i].len);
 +		if (rc) {
 +			/* If failed not much to do here, partial packet has
 +			 * been posted * we can't free memory, will need to wait
 +			 * for completion
 +			 */
 +			DP_ERR(cdev,
 +			       "roce ll2 tx: payload failed (rc=%d)\n", rc);
 +			return QED_ROCE_TX_FRAG_FAILURE;
 +		}
 +	}
 +
 +	return 0;
 +}
 +
 +static int qed_roce_ll2_post_rx_buffer(struct qed_dev *cdev,
 +				       struct qed_roce_ll2_buffer *buf,
 +				       u64 cookie, u8 notify_fw)
 +{
 +	return qed_ll2_post_rx_buffer(QED_LEADING_HWFN(cdev),
 +				      QED_LEADING_HWFN(cdev)->ll2->handle,
 +				      buf->baddr, buf->len,
 +				      (void *)(uintptr_t)cookie, notify_fw);
 +}
 +
 +static int qed_roce_ll2_stats(struct qed_dev *cdev, struct qed_ll2_stats *stats)
 +{
 +	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
 +	struct qed_roce_ll2_info *roce_ll2 = hwfn->ll2;
 +
 +	return qed_ll2_get_stats(QED_LEADING_HWFN(cdev),
 +				 roce_ll2->handle, stats);
  }
  
 +static const struct qed_rdma_ops qed_rdma_ops_pass = {
 +	.common = &qed_common_ops_pass,
 +	.fill_dev_info = &qed_fill_rdma_dev_info,
 +	.rdma_get_rdma_ctx = &qed_rdma_get_rdma_ctx,
 +	.rdma_init = &qed_rdma_init,
 +	.rdma_add_user = &qed_rdma_add_user,
 +	.rdma_remove_user = &qed_rdma_remove_user,
 +	.rdma_stop = &qed_rdma_stop,
 +	.rdma_query_port = &qed_rdma_query_port,
 +	.rdma_query_device = &qed_rdma_query_device,
 +	.rdma_get_start_sb = &qed_rdma_get_sb_start,
 +	.rdma_get_rdma_int = &qed_rdma_get_int,
 +	.rdma_set_rdma_int = &qed_rdma_set_int,
 +	.rdma_get_min_cnq_msix = &qed_rdma_get_min_cnq_msix,
 +	.rdma_cnq_prod_update = &qed_rdma_cnq_prod_update,
 +	.rdma_alloc_pd = &qed_rdma_alloc_pd,
 +	.rdma_dealloc_pd = &qed_rdma_free_pd,
 +	.rdma_create_cq = &qed_rdma_create_cq,
 +	.rdma_destroy_cq = &qed_rdma_destroy_cq,
 +	.rdma_create_qp = &qed_rdma_create_qp,
 +	.rdma_modify_qp = &qed_rdma_modify_qp,
 +	.rdma_query_qp = &qed_rdma_query_qp,
 +	.rdma_destroy_qp = &qed_rdma_destroy_qp,
 +	.rdma_alloc_tid = &qed_rdma_alloc_tid,
 +	.rdma_free_tid = &qed_rdma_free_tid,
 +	.rdma_register_tid = &qed_rdma_register_tid,
 +	.rdma_deregister_tid = &qed_rdma_deregister_tid,
 +	.roce_ll2_start = &qed_roce_ll2_start,
 +	.roce_ll2_stop = &qed_roce_ll2_stop,
 +	.roce_ll2_tx = &qed_roce_ll2_tx,
 +	.roce_ll2_post_rx_buffer = &qed_roce_ll2_post_rx_buffer,
 +	.roce_ll2_set_mac_filter = &qed_roce_ll2_set_mac_filter,
 +	.roce_ll2_stats = &qed_roce_ll2_stats,
 +};
 +
 +const struct qed_rdma_ops *qed_get_rdma_ops(void)
 +{
 +	return &qed_rdma_ops_pass;
 +}
 +EXPORT_SYMBOL(qed_get_rdma_ops);
++=======
+ int qed_roce_init_hw(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)
+ {
+ 	u32 ll2_ethertype_en;
+ 
+ 	qed_wr(p_hwfn, p_ptt, PRS_REG_ROCE_DEST_QP_MAX_PF, 0);
+ 
+ 	p_hwfn->rdma_prs_search_reg = PRS_REG_SEARCH_ROCE;
+ 
+ 	ll2_ethertype_en = qed_rd(p_hwfn, p_ptt, PRS_REG_LIGHT_L2_ETHERTYPE_EN);
+ 	qed_wr(p_hwfn, p_ptt, PRS_REG_LIGHT_L2_ETHERTYPE_EN,
+ 	       (ll2_ethertype_en | 0x01));
+ 
+ 	if (qed_cxt_get_proto_cid_start(p_hwfn, PROTOCOLID_ROCE) % 2) {
+ 		DP_NOTICE(p_hwfn, "The first RoCE's cid should be even\n");
+ 		return -EINVAL;
+ 	}
+ 
+ 	DP_VERBOSE(p_hwfn, QED_MSG_RDMA, "Initializing HW - Done\n");
+ 	return 0;
+ }
++>>>>>>> 67b40dccc45f (qed: Implement iWARP initialization, teardown and qp operations)
* Unmerged path drivers/net/ethernet/qlogic/qed/Makefile
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_dev.c
diff --git a/drivers/net/ethernet/qlogic/qed/qed_hsi.h b/drivers/net/ethernet/qlogic/qed/qed_hsi.h
index 60cc88a3ac01..314479510989 100644
--- a/drivers/net/ethernet/qlogic/qed/qed_hsi.h
+++ b/drivers/net/ethernet/qlogic/qed/qed_hsi.h
@@ -46,6 +46,7 @@
 #include <linux/qed/fcoe_common.h>
 #include <linux/qed/eth_common.h>
 #include <linux/qed/iscsi_common.h>
+#include <linux/qed/iwarp_common.h>
 #include <linux/qed/rdma_common.h>
 #include <linux/qed/roce_common.h>
 #include <linux/qed/qed_fcoe_if.h>
diff --git a/drivers/net/ethernet/qlogic/qed/qed_iwarp.c b/drivers/net/ethernet/qlogic/qed/qed_iwarp.c
new file mode 100644
index 000000000000..a8bd5f8edec6
--- /dev/null
+++ b/drivers/net/ethernet/qlogic/qed/qed_iwarp.c
@@ -0,0 +1,531 @@
+/* QLogic qed NIC Driver
+ * Copyright (c) 2015-2017  QLogic Corporation
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and /or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+#include "qed_cxt.h"
+#include "qed_hw.h"
+#include "qed_rdma.h"
+#include "qed_reg_addr.h"
+#include "qed_sp.h"
+
+#define QED_IWARP_ORD_DEFAULT		32
+#define QED_IWARP_IRD_DEFAULT		32
+#define QED_IWARP_RCV_WND_SIZE_DEF	(256 * 1024)
+#define QED_IWARP_RCV_WND_SIZE_MIN	(64 * 1024)
+#define QED_IWARP_TS_EN			BIT(0)
+#define QED_IWARP_PARAM_CRC_NEEDED	(1)
+#define QED_IWARP_PARAM_P2P		(1)
+
+static int qed_iwarp_async_event(struct qed_hwfn *p_hwfn,
+				 u8 fw_event_code, u16 echo,
+				 union event_ring_data *data,
+				 u8 fw_return_code);
+
+/* Override devinfo with iWARP specific values */
+void qed_iwarp_init_devinfo(struct qed_hwfn *p_hwfn)
+{
+	struct qed_rdma_device *dev = p_hwfn->p_rdma_info->dev;
+
+	dev->max_inline = IWARP_REQ_MAX_INLINE_DATA_SIZE;
+	dev->max_qp = min_t(u32,
+			    IWARP_MAX_QPS,
+			    p_hwfn->p_rdma_info->num_qps);
+
+	dev->max_cq = dev->max_qp;
+
+	dev->max_qp_resp_rd_atomic_resc = QED_IWARP_IRD_DEFAULT;
+	dev->max_qp_req_rd_atomic_resc = QED_IWARP_ORD_DEFAULT;
+}
+
+void qed_iwarp_init_hw(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)
+{
+	p_hwfn->rdma_prs_search_reg = PRS_REG_SEARCH_TCP;
+	qed_wr(p_hwfn, p_ptt, p_hwfn->rdma_prs_search_reg, 1);
+	p_hwfn->b_rdma_enabled_in_prs = true;
+}
+
+static void qed_iwarp_cid_cleaned(struct qed_hwfn *p_hwfn, u32 cid)
+{
+	cid -= qed_cxt_get_proto_cid_start(p_hwfn, p_hwfn->p_rdma_info->proto);
+
+	spin_lock_bh(&p_hwfn->p_rdma_info->lock);
+	qed_bmap_release_id(p_hwfn, &p_hwfn->p_rdma_info->cid_map, cid);
+	spin_unlock_bh(&p_hwfn->p_rdma_info->lock);
+}
+
+static int qed_iwarp_alloc_cid(struct qed_hwfn *p_hwfn, u32 *cid)
+{
+	int rc;
+
+	spin_lock_bh(&p_hwfn->p_rdma_info->lock);
+	rc = qed_rdma_bmap_alloc_id(p_hwfn, &p_hwfn->p_rdma_info->cid_map, cid);
+	spin_unlock_bh(&p_hwfn->p_rdma_info->lock);
+	if (rc) {
+		DP_NOTICE(p_hwfn, "Failed in allocating iwarp cid\n");
+		return rc;
+	}
+	*cid += qed_cxt_get_proto_cid_start(p_hwfn, p_hwfn->p_rdma_info->proto);
+
+	rc = qed_cxt_dynamic_ilt_alloc(p_hwfn, QED_ELEM_CXT, *cid);
+	if (rc)
+		qed_iwarp_cid_cleaned(p_hwfn, *cid);
+
+	return rc;
+}
+
+int qed_iwarp_create_qp(struct qed_hwfn *p_hwfn,
+			struct qed_rdma_qp *qp,
+			struct qed_rdma_create_qp_out_params *out_params)
+{
+	struct iwarp_create_qp_ramrod_data *p_ramrod;
+	struct qed_sp_init_data init_data;
+	struct qed_spq_entry *p_ent;
+	u16 physical_queue;
+	u32 cid;
+	int rc;
+
+	qp->shared_queue = dma_alloc_coherent(&p_hwfn->cdev->pdev->dev,
+					      IWARP_SHARED_QUEUE_PAGE_SIZE,
+					      &qp->shared_queue_phys_addr,
+					      GFP_KERNEL);
+	if (!qp->shared_queue)
+		return -ENOMEM;
+
+	out_params->sq_pbl_virt = (u8 *)qp->shared_queue +
+	    IWARP_SHARED_QUEUE_PAGE_SQ_PBL_OFFSET;
+	out_params->sq_pbl_phys = qp->shared_queue_phys_addr +
+	    IWARP_SHARED_QUEUE_PAGE_SQ_PBL_OFFSET;
+	out_params->rq_pbl_virt = (u8 *)qp->shared_queue +
+	    IWARP_SHARED_QUEUE_PAGE_RQ_PBL_OFFSET;
+	out_params->rq_pbl_phys = qp->shared_queue_phys_addr +
+	    IWARP_SHARED_QUEUE_PAGE_RQ_PBL_OFFSET;
+
+	rc = qed_iwarp_alloc_cid(p_hwfn, &cid);
+	if (rc)
+		goto err1;
+
+	qp->icid = (u16)cid;
+
+	memset(&init_data, 0, sizeof(init_data));
+	init_data.opaque_fid = p_hwfn->hw_info.opaque_fid;
+	init_data.cid = qp->icid;
+	init_data.comp_mode = QED_SPQ_MODE_EBLOCK;
+
+	rc = qed_sp_init_request(p_hwfn, &p_ent,
+				 IWARP_RAMROD_CMD_ID_CREATE_QP,
+				 PROTOCOLID_IWARP, &init_data);
+	if (rc)
+		goto err2;
+
+	p_ramrod = &p_ent->ramrod.iwarp_create_qp;
+
+	SET_FIELD(p_ramrod->flags,
+		  IWARP_CREATE_QP_RAMROD_DATA_FMR_AND_RESERVED_EN,
+		  qp->fmr_and_reserved_lkey);
+
+	SET_FIELD(p_ramrod->flags,
+		  IWARP_CREATE_QP_RAMROD_DATA_SIGNALED_COMP, qp->signal_all);
+
+	SET_FIELD(p_ramrod->flags,
+		  IWARP_CREATE_QP_RAMROD_DATA_RDMA_RD_EN,
+		  qp->incoming_rdma_read_en);
+
+	SET_FIELD(p_ramrod->flags,
+		  IWARP_CREATE_QP_RAMROD_DATA_RDMA_WR_EN,
+		  qp->incoming_rdma_write_en);
+
+	SET_FIELD(p_ramrod->flags,
+		  IWARP_CREATE_QP_RAMROD_DATA_ATOMIC_EN,
+		  qp->incoming_atomic_en);
+
+	SET_FIELD(p_ramrod->flags,
+		  IWARP_CREATE_QP_RAMROD_DATA_SRQ_FLG, qp->use_srq);
+
+	p_ramrod->pd = qp->pd;
+	p_ramrod->sq_num_pages = qp->sq_num_pages;
+	p_ramrod->rq_num_pages = qp->rq_num_pages;
+
+	p_ramrod->qp_handle_for_cqe.hi = cpu_to_le32(qp->qp_handle.hi);
+	p_ramrod->qp_handle_for_cqe.lo = cpu_to_le32(qp->qp_handle.lo);
+
+	p_ramrod->cq_cid_for_sq =
+	    cpu_to_le32((p_hwfn->hw_info.opaque_fid << 16) | qp->sq_cq_id);
+	p_ramrod->cq_cid_for_rq =
+	    cpu_to_le32((p_hwfn->hw_info.opaque_fid << 16) | qp->rq_cq_id);
+
+	p_ramrod->dpi = cpu_to_le16(qp->dpi);
+
+	physical_queue = qed_get_cm_pq_idx(p_hwfn, PQ_FLAGS_OFLD);
+	p_ramrod->physical_q0 = cpu_to_le16(physical_queue);
+	physical_queue = qed_get_cm_pq_idx(p_hwfn, PQ_FLAGS_ACK);
+	p_ramrod->physical_q1 = cpu_to_le16(physical_queue);
+
+	rc = qed_spq_post(p_hwfn, p_ent, NULL);
+	if (rc)
+		goto err2;
+
+	return rc;
+
+err2:
+	qed_iwarp_cid_cleaned(p_hwfn, cid);
+err1:
+	dma_free_coherent(&p_hwfn->cdev->pdev->dev,
+			  IWARP_SHARED_QUEUE_PAGE_SIZE,
+			  qp->shared_queue, qp->shared_queue_phys_addr);
+
+	return rc;
+}
+
+static int qed_iwarp_modify_fw(struct qed_hwfn *p_hwfn, struct qed_rdma_qp *qp)
+{
+	struct iwarp_modify_qp_ramrod_data *p_ramrod;
+	struct qed_sp_init_data init_data;
+	struct qed_spq_entry *p_ent;
+	int rc;
+
+	/* Get SPQ entry */
+	memset(&init_data, 0, sizeof(init_data));
+	init_data.cid = qp->icid;
+	init_data.opaque_fid = p_hwfn->hw_info.opaque_fid;
+	init_data.comp_mode = QED_SPQ_MODE_EBLOCK;
+
+	rc = qed_sp_init_request(p_hwfn, &p_ent,
+				 IWARP_RAMROD_CMD_ID_MODIFY_QP,
+				 p_hwfn->p_rdma_info->proto, &init_data);
+	if (rc)
+		return rc;
+
+	p_ramrod = &p_ent->ramrod.iwarp_modify_qp;
+	SET_FIELD(p_ramrod->flags, IWARP_MODIFY_QP_RAMROD_DATA_STATE_TRANS_EN,
+		  0x1);
+	if (qp->iwarp_state == QED_IWARP_QP_STATE_CLOSING)
+		p_ramrod->transition_to_state = IWARP_MODIFY_QP_STATE_CLOSING;
+	else
+		p_ramrod->transition_to_state = IWARP_MODIFY_QP_STATE_ERROR;
+
+	rc = qed_spq_post(p_hwfn, p_ent, NULL);
+
+	DP_VERBOSE(p_hwfn, QED_MSG_RDMA, "QP(0x%x)rc=%d\n", qp->icid, rc);
+
+	return rc;
+}
+
+enum qed_iwarp_qp_state qed_roce2iwarp_state(enum qed_roce_qp_state state)
+{
+	switch (state) {
+	case QED_ROCE_QP_STATE_RESET:
+	case QED_ROCE_QP_STATE_INIT:
+	case QED_ROCE_QP_STATE_RTR:
+		return QED_IWARP_QP_STATE_IDLE;
+	case QED_ROCE_QP_STATE_RTS:
+		return QED_IWARP_QP_STATE_RTS;
+	case QED_ROCE_QP_STATE_SQD:
+		return QED_IWARP_QP_STATE_CLOSING;
+	case QED_ROCE_QP_STATE_ERR:
+		return QED_IWARP_QP_STATE_ERROR;
+	case QED_ROCE_QP_STATE_SQE:
+		return QED_IWARP_QP_STATE_TERMINATE;
+	default:
+		return QED_IWARP_QP_STATE_ERROR;
+	}
+}
+
+static enum qed_roce_qp_state
+qed_iwarp2roce_state(enum qed_iwarp_qp_state state)
+{
+	switch (state) {
+	case QED_IWARP_QP_STATE_IDLE:
+		return QED_ROCE_QP_STATE_INIT;
+	case QED_IWARP_QP_STATE_RTS:
+		return QED_ROCE_QP_STATE_RTS;
+	case QED_IWARP_QP_STATE_TERMINATE:
+		return QED_ROCE_QP_STATE_SQE;
+	case QED_IWARP_QP_STATE_CLOSING:
+		return QED_ROCE_QP_STATE_SQD;
+	case QED_IWARP_QP_STATE_ERROR:
+		return QED_ROCE_QP_STATE_ERR;
+	default:
+		return QED_ROCE_QP_STATE_ERR;
+	}
+}
+
+const char *iwarp_state_names[] = {
+	"IDLE",
+	"RTS",
+	"TERMINATE",
+	"CLOSING",
+	"ERROR",
+};
+
+int
+qed_iwarp_modify_qp(struct qed_hwfn *p_hwfn,
+		    struct qed_rdma_qp *qp,
+		    enum qed_iwarp_qp_state new_state, bool internal)
+{
+	enum qed_iwarp_qp_state prev_iw_state;
+	bool modify_fw = false;
+	int rc = 0;
+
+	/* modify QP can be called from upper-layer or as a result of async
+	 * RST/FIN... therefore need to protect
+	 */
+	spin_lock_bh(&p_hwfn->p_rdma_info->iwarp.qp_lock);
+	prev_iw_state = qp->iwarp_state;
+
+	if (prev_iw_state == new_state) {
+		spin_unlock_bh(&p_hwfn->p_rdma_info->iwarp.qp_lock);
+		return 0;
+	}
+
+	switch (prev_iw_state) {
+	case QED_IWARP_QP_STATE_IDLE:
+		switch (new_state) {
+		case QED_IWARP_QP_STATE_RTS:
+			qp->iwarp_state = QED_IWARP_QP_STATE_RTS;
+			break;
+		case QED_IWARP_QP_STATE_ERROR:
+			qp->iwarp_state = QED_IWARP_QP_STATE_ERROR;
+			if (!internal)
+				modify_fw = true;
+			break;
+		default:
+			break;
+		}
+		break;
+	case QED_IWARP_QP_STATE_RTS:
+		switch (new_state) {
+		case QED_IWARP_QP_STATE_CLOSING:
+			if (!internal)
+				modify_fw = true;
+
+			qp->iwarp_state = QED_IWARP_QP_STATE_CLOSING;
+			break;
+		case QED_IWARP_QP_STATE_ERROR:
+			if (!internal)
+				modify_fw = true;
+			qp->iwarp_state = QED_IWARP_QP_STATE_ERROR;
+			break;
+		default:
+			break;
+		}
+		break;
+	case QED_IWARP_QP_STATE_ERROR:
+		switch (new_state) {
+		case QED_IWARP_QP_STATE_IDLE:
+
+			qp->iwarp_state = new_state;
+			break;
+		case QED_IWARP_QP_STATE_CLOSING:
+			/* could happen due to race... do nothing.... */
+			break;
+		default:
+			rc = -EINVAL;
+		}
+		break;
+	case QED_IWARP_QP_STATE_TERMINATE:
+	case QED_IWARP_QP_STATE_CLOSING:
+		qp->iwarp_state = new_state;
+		break;
+	default:
+		break;
+	}
+
+	DP_VERBOSE(p_hwfn, QED_MSG_RDMA, "QP(0x%x) %s --> %s%s\n",
+		   qp->icid,
+		   iwarp_state_names[prev_iw_state],
+		   iwarp_state_names[qp->iwarp_state],
+		   internal ? "internal" : "");
+
+	spin_unlock_bh(&p_hwfn->p_rdma_info->iwarp.qp_lock);
+
+	if (modify_fw)
+		rc = qed_iwarp_modify_fw(p_hwfn, qp);
+
+	return rc;
+}
+
+int qed_iwarp_fw_destroy(struct qed_hwfn *p_hwfn, struct qed_rdma_qp *qp)
+{
+	struct qed_sp_init_data init_data;
+	struct qed_spq_entry *p_ent;
+	int rc;
+
+	/* Get SPQ entry */
+	memset(&init_data, 0, sizeof(init_data));
+	init_data.cid = qp->icid;
+	init_data.opaque_fid = p_hwfn->hw_info.opaque_fid;
+	init_data.comp_mode = QED_SPQ_MODE_EBLOCK;
+
+	rc = qed_sp_init_request(p_hwfn, &p_ent,
+				 IWARP_RAMROD_CMD_ID_DESTROY_QP,
+				 p_hwfn->p_rdma_info->proto, &init_data);
+	if (rc)
+		return rc;
+
+	rc = qed_spq_post(p_hwfn, p_ent, NULL);
+
+	DP_VERBOSE(p_hwfn, QED_MSG_RDMA, "QP(0x%x) rc = %d\n", qp->icid, rc);
+
+	return rc;
+}
+
+int qed_iwarp_destroy_qp(struct qed_hwfn *p_hwfn, struct qed_rdma_qp *qp)
+{
+	int rc = 0;
+
+	if (qp->iwarp_state != QED_IWARP_QP_STATE_ERROR) {
+		rc = qed_iwarp_modify_qp(p_hwfn, qp,
+					 QED_IWARP_QP_STATE_ERROR, false);
+		if (rc)
+			return rc;
+	}
+
+	rc = qed_iwarp_fw_destroy(p_hwfn, qp);
+
+	if (qp->shared_queue)
+		dma_free_coherent(&p_hwfn->cdev->pdev->dev,
+				  IWARP_SHARED_QUEUE_PAGE_SIZE,
+				  qp->shared_queue, qp->shared_queue_phys_addr);
+
+	return rc;
+}
+
+#define QED_IWARP_MAX_CID_CLEAN_TIME  100
+#define QED_IWARP_MAX_NO_PROGRESS_CNT 5
+
+/* This function waits for all the bits of a bmap to be cleared, as long as
+ * there is progress ( i.e. the number of bits left to be cleared decreases )
+ * the function continues.
+ */
+static int
+qed_iwarp_wait_cid_map_cleared(struct qed_hwfn *p_hwfn, struct qed_bmap *bmap)
+{
+	int prev_weight = 0;
+	int wait_count = 0;
+	int weight = 0;
+
+	weight = bitmap_weight(bmap->bitmap, bmap->max_count);
+	prev_weight = weight;
+
+	while (weight) {
+		msleep(QED_IWARP_MAX_CID_CLEAN_TIME);
+
+		weight = bitmap_weight(bmap->bitmap, bmap->max_count);
+
+		if (prev_weight == weight) {
+			wait_count++;
+		} else {
+			prev_weight = weight;
+			wait_count = 0;
+		}
+
+		if (wait_count > QED_IWARP_MAX_NO_PROGRESS_CNT) {
+			DP_NOTICE(p_hwfn,
+				  "%s bitmap wait timed out (%d cids pending)\n",
+				  bmap->name, weight);
+			return -EBUSY;
+		}
+	}
+	return 0;
+}
+
+static int qed_iwarp_wait_for_all_cids(struct qed_hwfn *p_hwfn)
+{
+	/* Now wait for all cids to be completed */
+	return qed_iwarp_wait_cid_map_cleared(p_hwfn,
+					      &p_hwfn->p_rdma_info->cid_map);
+}
+
+int qed_iwarp_alloc(struct qed_hwfn *p_hwfn)
+{
+	spin_lock_init(&p_hwfn->p_rdma_info->iwarp.iw_lock);
+
+	return 0;
+}
+
+void qed_iwarp_resc_free(struct qed_hwfn *p_hwfn)
+{
+}
+
+int qed_iwarp_setup(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt,
+		    struct qed_rdma_start_in_params *params)
+{
+	struct qed_iwarp_info *iwarp_info;
+	u32 rcv_wnd_size;
+	int rc = 0;
+
+	iwarp_info = &p_hwfn->p_rdma_info->iwarp;
+
+	iwarp_info->tcp_flags = QED_IWARP_TS_EN;
+	rcv_wnd_size = QED_IWARP_RCV_WND_SIZE_DEF;
+
+	/* value 0 is used for ilog2(QED_IWARP_RCV_WND_SIZE_MIN) */
+	iwarp_info->rcv_wnd_scale = ilog2(rcv_wnd_size) -
+	    ilog2(QED_IWARP_RCV_WND_SIZE_MIN);
+	iwarp_info->crc_needed = QED_IWARP_PARAM_CRC_NEEDED;
+	iwarp_info->mpa_rev = MPA_NEGOTIATION_TYPE_ENHANCED;
+
+	iwarp_info->peer2peer = QED_IWARP_PARAM_P2P;
+
+	spin_lock_init(&p_hwfn->p_rdma_info->iwarp.qp_lock);
+
+	qed_spq_register_async_cb(p_hwfn, PROTOCOLID_IWARP,
+				  qed_iwarp_async_event);
+
+	return rc;
+}
+
+int qed_iwarp_stop(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)
+{
+	int rc;
+
+	rc = qed_iwarp_wait_for_all_cids(p_hwfn);
+	if (rc)
+		return rc;
+
+	qed_spq_unregister_async_cb(p_hwfn, PROTOCOLID_IWARP);
+
+	return 0;
+}
+
+static int qed_iwarp_async_event(struct qed_hwfn *p_hwfn,
+				 u8 fw_event_code, u16 echo,
+				 union event_ring_data *data,
+				 u8 fw_return_code)
+{
+	return 0;
+}
+
+void
+qed_iwarp_query_qp(struct qed_rdma_qp *qp,
+		   struct qed_rdma_query_qp_out_params *out_params)
+{
+	out_params->state = qed_iwarp2roce_state(qp->iwarp_state);
+}
diff --git a/drivers/net/ethernet/qlogic/qed/qed_iwarp.h b/drivers/net/ethernet/qlogic/qed/qed_iwarp.h
new file mode 100644
index 000000000000..05e5e45be6cf
--- /dev/null
+++ b/drivers/net/ethernet/qlogic/qed/qed_iwarp.h
@@ -0,0 +1,85 @@
+/* QLogic qed NIC Driver
+ * Copyright (c) 2015-2017  QLogic Corporation
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and /or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+#ifndef _QED_IWARP_H
+#define _QED_IWARP_H
+
+enum qed_iwarp_qp_state {
+	QED_IWARP_QP_STATE_IDLE,
+	QED_IWARP_QP_STATE_RTS,
+	QED_IWARP_QP_STATE_TERMINATE,
+	QED_IWARP_QP_STATE_CLOSING,
+	QED_IWARP_QP_STATE_ERROR,
+};
+
+enum qed_iwarp_qp_state qed_roce2iwarp_state(enum qed_roce_qp_state state);
+
+struct qed_iwarp_info {
+	spinlock_t iw_lock;	/* for iwarp resources */
+	spinlock_t qp_lock;	/* for teardown races */
+	u32 rcv_wnd_scale;
+	u16 max_mtu;
+	u8 mac_addr[ETH_ALEN];
+	u8 crc_needed;
+	u8 tcp_flags;
+	u8 peer2peer;
+	enum mpa_negotiation_mode mpa_rev;
+	enum mpa_rtr_type rtr_type;
+};
+
+int qed_iwarp_alloc(struct qed_hwfn *p_hwfn);
+
+int qed_iwarp_setup(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt,
+		    struct qed_rdma_start_in_params *params);
+
+int qed_iwarp_stop(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt);
+
+void qed_iwarp_resc_free(struct qed_hwfn *p_hwfn);
+
+void qed_iwarp_init_devinfo(struct qed_hwfn *p_hwfn);
+
+void qed_iwarp_init_hw(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt);
+
+int qed_iwarp_create_qp(struct qed_hwfn *p_hwfn,
+			struct qed_rdma_qp *qp,
+			struct qed_rdma_create_qp_out_params *out_params);
+
+int qed_iwarp_modify_qp(struct qed_hwfn *p_hwfn, struct qed_rdma_qp *qp,
+			enum qed_iwarp_qp_state new_state, bool internal);
+
+int qed_iwarp_destroy_qp(struct qed_hwfn *p_hwfn, struct qed_rdma_qp *qp);
+
+int qed_iwarp_fw_destroy(struct qed_hwfn *p_hwfn, struct qed_rdma_qp *qp);
+
+void qed_iwarp_query_qp(struct qed_rdma_qp *qp,
+			struct qed_rdma_query_qp_out_params *out_params);
+
+#endif
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_rdma.c
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_rdma.h
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_roce.c
diff --git a/drivers/net/ethernet/qlogic/qed/qed_sp.h b/drivers/net/ethernet/qlogic/qed/qed_sp.h
index 109909f6ad23..42b03e3f5efb 100644
--- a/drivers/net/ethernet/qlogic/qed/qed_sp.h
+++ b/drivers/net/ethernet/qlogic/qed/qed_sp.h
@@ -103,12 +103,15 @@ union ramrod_data {
 	struct roce_query_qp_req_ramrod_data roce_query_qp_req;
 	struct roce_destroy_qp_resp_ramrod_data roce_destroy_qp_resp;
 	struct roce_destroy_qp_req_ramrod_data roce_destroy_qp_req;
+	struct roce_init_func_ramrod_data roce_init_func;
 	struct rdma_create_cq_ramrod_data rdma_create_cq;
 	struct rdma_destroy_cq_ramrod_data rdma_destroy_cq;
 	struct rdma_srq_create_ramrod_data rdma_create_srq;
 	struct rdma_srq_destroy_ramrod_data rdma_destroy_srq;
 	struct rdma_srq_modify_ramrod_data rdma_modify_srq;
-	struct roce_init_func_ramrod_data roce_init_func;
+	struct iwarp_create_qp_ramrod_data iwarp_create_qp;
+	struct iwarp_modify_qp_ramrod_data iwarp_modify_qp;
+	struct iwarp_init_func_ramrod_data iwarp_init_func;
 	struct fcoe_init_ramrod_params fcoe_init;
 	struct fcoe_conn_offload_ramrod_params fcoe_conn_ofld;
 	struct fcoe_conn_terminate_ramrod_params fcoe_conn_terminate;
diff --git a/include/linux/qed/iwarp_common.h b/include/linux/qed/iwarp_common.h
new file mode 100644
index 000000000000..b8b3e1cfae90
--- /dev/null
+++ b/include/linux/qed/iwarp_common.h
@@ -0,0 +1,53 @@
+/* QLogic qed NIC Driver
+ * Copyright (c) 2015-2017  QLogic Corporation
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * OpenIB.org BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and /or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+#ifndef __IWARP_COMMON__
+#define __IWARP_COMMON__
+#include <linux/qed/rdma_common.h>
+/************************/
+/* IWARP FW CONSTANTS	*/
+/************************/
+
+#define IWARP_ACTIVE_MODE 0
+#define IWARP_PASSIVE_MODE 1
+
+#define IWARP_SHARED_QUEUE_PAGE_SIZE		(0x8000)
+#define IWARP_SHARED_QUEUE_PAGE_RQ_PBL_OFFSET   (0x4000)
+#define IWARP_SHARED_QUEUE_PAGE_RQ_PBL_MAX_SIZE (0x1000)
+#define IWARP_SHARED_QUEUE_PAGE_SQ_PBL_OFFSET   (0x5000)
+#define IWARP_SHARED_QUEUE_PAGE_SQ_PBL_MAX_SIZE (0x3000)
+
+#define IWARP_REQ_MAX_INLINE_DATA_SIZE          (128)
+#define IWARP_REQ_MAX_SINGLE_SQ_WQE_SIZE        (176)
+
+#define IWARP_MAX_QPS                           (64 * 1024)
+
+#endif /* __IWARP_COMMON__ */
diff --git a/include/linux/qed/qed_roce_if.h b/include/linux/qed/qed_roce_if.h
index cbb2ff0ce4bc..cebee04108fe 100644
--- a/include/linux/qed/qed_roce_if.h
+++ b/include/linux/qed/qed_roce_if.h
@@ -529,6 +529,7 @@ struct qed_roce_ll2_info {
 
 enum qed_rdma_type {
 	QED_RDMA_TYPE_ROCE,
+	QED_RDMA_TYPE_IWARP
 };
 
 struct qed_dev_rdma_info {
