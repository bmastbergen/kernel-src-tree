xprtrdma: Replace rpcrdma_count_chunks()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Chuck Lever <chuck.lever@oracle.com>
commit 264b0cdbcb93e6d7b419fcc82fca9413a13f87ae
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/264b0cdb.failed

Clean up chunk list decoding by using the xdr_stream set up in
rpcrdma_reply_handler. This hardens decoding by checking for buffer
overflow at every step while unmarshaling variable-length XDR
objects.

	Signed-off-by: Chuck Lever <chuck.lever@oracle.com>
	Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
(cherry picked from commit 264b0cdbcb93e6d7b419fcc82fca9413a13f87ae)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sunrpc/xprtrdma/rpc_rdma.c
diff --cc net/sunrpc/xprtrdma/rpc_rdma.c
index 24f58c7b3106,e422c0f63a69..000000000000
--- a/net/sunrpc/xprtrdma/rpc_rdma.c
+++ b/net/sunrpc/xprtrdma/rpc_rdma.c
@@@ -956,30 -913,248 +914,226 @@@ rpcrdma_mark_remote_invalidation(struc
   * straightforward to check the RPC header's direction field.
   */
  static bool
 -rpcrdma_is_bcall(struct rpcrdma_xprt *r_xprt, struct rpcrdma_rep *rep,
 -		 __be32 xid, __be32 proc)
 -#if defined(CONFIG_SUNRPC_BACKCHANNEL)
 +rpcrdma_is_bcall(struct rpcrdma_msg *headerp)
  {
 -	struct xdr_stream *xdr = &rep->rr_stream;
 -	__be32 *p;
 +	__be32 *p = (__be32 *)headerp;
  
 -	if (proc != rdma_msg)
 +	if (headerp->rm_type != rdma_msg)
  		return false;
 -
 -	/* Peek at stream contents without advancing. */
 -	p = xdr_inline_decode(xdr, 0);
 -
 -	/* Chunk lists */
 -	if (*p++ != xdr_zero)
 +	if (headerp->rm_body.rm_chunks[0] != xdr_zero)
  		return false;
 -	if (*p++ != xdr_zero)
 +	if (headerp->rm_body.rm_chunks[1] != xdr_zero)
  		return false;
 -	if (*p++ != xdr_zero)
 +	if (headerp->rm_body.rm_chunks[2] != xdr_zero)
  		return false;
  
 -	/* RPC header */
 -	if (*p++ != xid)
 +	/* sanity */
 +	if (p[7] != headerp->rm_xid)
  		return false;
 -	if (*p != cpu_to_be32(RPC_CALL))
 +	/* call direction */
 +	if (p[8] != cpu_to_be32(RPC_CALL))
  		return false;
  
 -	/* Now that we are sure this is a backchannel call,
 -	 * advance to the RPC header.
 -	 */
 -	p = xdr_inline_decode(xdr, 3 * sizeof(*p));
 -	if (unlikely(!p))
 -		goto out_short;
 -
 -	rpcrdma_bc_receive_call(r_xprt, rep);
 -	return true;
 -
 -out_short:
 -	pr_warn("RPC/RDMA short backward direction call\n");
 -	if (rpcrdma_ep_post_recv(&r_xprt->rx_ia, rep))
 -		xprt_disconnect_done(&r_xprt->rx_xprt);
  	return true;
  }
 -#else	/* CONFIG_SUNRPC_BACKCHANNEL */
 -{
 -	return false;
 -}
  #endif	/* CONFIG_SUNRPC_BACKCHANNEL */
  
++<<<<<<< HEAD
++=======
+ static int decode_rdma_segment(struct xdr_stream *xdr, u32 *length)
+ {
+ 	__be32 *p;
+ 
+ 	p = xdr_inline_decode(xdr, 4 * sizeof(*p));
+ 	if (unlikely(!p))
+ 		return -EIO;
+ 
+ 	ifdebug(FACILITY) {
+ 		u64 offset;
+ 		u32 handle;
+ 
+ 		handle = be32_to_cpup(p++);
+ 		*length = be32_to_cpup(p++);
+ 		xdr_decode_hyper(p, &offset);
+ 		dprintk("RPC:       %s:   segment %u@0x%016llx:0x%08x\n",
+ 			__func__, *length, (unsigned long long)offset,
+ 			handle);
+ 	} else {
+ 		*length = be32_to_cpup(p + 1);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int decode_write_chunk(struct xdr_stream *xdr, u32 *length)
+ {
+ 	u32 segcount, seglength;
+ 	__be32 *p;
+ 
+ 	p = xdr_inline_decode(xdr, sizeof(*p));
+ 	if (unlikely(!p))
+ 		return -EIO;
+ 
+ 	*length = 0;
+ 	segcount = be32_to_cpup(p);
+ 	while (segcount--) {
+ 		if (decode_rdma_segment(xdr, &seglength))
+ 			return -EIO;
+ 		*length += seglength;
+ 	}
+ 
+ 	dprintk("RPC:       %s: segcount=%u, %u bytes\n",
+ 		__func__, be32_to_cpup(p), *length);
+ 	return 0;
+ }
+ 
+ /* In RPC-over-RDMA Version One replies, a Read list is never
+  * expected. This decoder is a stub that returns an error if
+  * a Read list is present.
+  */
+ static int decode_read_list(struct xdr_stream *xdr)
+ {
+ 	__be32 *p;
+ 
+ 	p = xdr_inline_decode(xdr, sizeof(*p));
+ 	if (unlikely(!p))
+ 		return -EIO;
+ 	if (unlikely(*p != xdr_zero))
+ 		return -EIO;
+ 	return 0;
+ }
+ 
+ /* Supports only one Write chunk in the Write list
+  */
+ static int decode_write_list(struct xdr_stream *xdr, u32 *length)
+ {
+ 	u32 chunklen;
+ 	bool first;
+ 	__be32 *p;
+ 
+ 	*length = 0;
+ 	first = true;
+ 	do {
+ 		p = xdr_inline_decode(xdr, sizeof(*p));
+ 		if (unlikely(!p))
+ 			return -EIO;
+ 		if (*p == xdr_zero)
+ 			break;
+ 		if (!first)
+ 			return -EIO;
+ 
+ 		if (decode_write_chunk(xdr, &chunklen))
+ 			return -EIO;
+ 		*length += chunklen;
+ 		first = false;
+ 	} while (true);
+ 	return 0;
+ }
+ 
+ static int decode_reply_chunk(struct xdr_stream *xdr, u32 *length)
+ {
+ 	__be32 *p;
+ 
+ 	p = xdr_inline_decode(xdr, sizeof(*p));
+ 	if (unlikely(!p))
+ 		return -EIO;
+ 
+ 	*length = 0;
+ 	if (*p != xdr_zero)
+ 		if (decode_write_chunk(xdr, length))
+ 			return -EIO;
+ 	return 0;
+ }
+ 
+ static int
+ rpcrdma_decode_msg(struct rpcrdma_xprt *r_xprt, struct rpcrdma_rep *rep,
+ 		   struct rpc_rqst *rqst)
+ {
+ 	struct xdr_stream *xdr = &rep->rr_stream;
+ 	u32 writelist, replychunk, rpclen;
+ 	char *base;
+ 
+ 	/* Decode the chunk lists */
+ 	if (decode_read_list(xdr))
+ 		return -EIO;
+ 	if (decode_write_list(xdr, &writelist))
+ 		return -EIO;
+ 	if (decode_reply_chunk(xdr, &replychunk))
+ 		return -EIO;
+ 
+ 	/* RDMA_MSG sanity checks */
+ 	if (unlikely(replychunk))
+ 		return -EIO;
+ 
+ 	/* Build the RPC reply's Payload stream in rqst->rq_rcv_buf */
+ 	base = (char *)xdr_inline_decode(xdr, 0);
+ 	rpclen = xdr_stream_remaining(xdr);
+ 	r_xprt->rx_stats.fixup_copy_count +=
+ 		rpcrdma_inline_fixup(rqst, base, rpclen, writelist & 3);
+ 
+ 	r_xprt->rx_stats.total_rdma_reply += writelist;
+ 	return rpclen + xdr_align_size(writelist);
+ }
+ 
+ static noinline int
+ rpcrdma_decode_nomsg(struct rpcrdma_xprt *r_xprt, struct rpcrdma_rep *rep)
+ {
+ 	struct xdr_stream *xdr = &rep->rr_stream;
+ 	u32 writelist, replychunk;
+ 
+ 	/* Decode the chunk lists */
+ 	if (decode_read_list(xdr))
+ 		return -EIO;
+ 	if (decode_write_list(xdr, &writelist))
+ 		return -EIO;
+ 	if (decode_reply_chunk(xdr, &replychunk))
+ 		return -EIO;
+ 
+ 	/* RDMA_NOMSG sanity checks */
+ 	if (unlikely(writelist))
+ 		return -EIO;
+ 	if (unlikely(!replychunk))
+ 		return -EIO;
+ 
+ 	/* Reply chunk buffer already is the reply vector */
+ 	r_xprt->rx_stats.total_rdma_reply += replychunk;
+ 	return replychunk;
+ }
+ 
+ static noinline int
+ rpcrdma_decode_error(struct rpcrdma_xprt *r_xprt, struct rpcrdma_rep *rep,
+ 		     struct rpc_rqst *rqst)
+ {
+ 	struct xdr_stream *xdr = &rep->rr_stream;
+ 	__be32 *p;
+ 
+ 	p = xdr_inline_decode(xdr, sizeof(*p));
+ 	if (unlikely(!p))
+ 		return -EIO;
+ 
+ 	switch (*p) {
+ 	case err_vers:
+ 		p = xdr_inline_decode(xdr, 2 * sizeof(*p));
+ 		if (!p)
+ 			break;
+ 		dprintk("RPC: %5u: %s: server reports version error (%u-%u)\n",
+ 			rqst->rq_task->tk_pid, __func__,
+ 			be32_to_cpup(p), be32_to_cpu(*(p + 1)));
+ 		break;
+ 	case err_chunk:
+ 		dprintk("RPC: %5u: %s: server reports header decoding error\n",
+ 			rqst->rq_task->tk_pid, __func__);
+ 		break;
+ 	default:
+ 		dprintk("RPC: %5u: %s: server reports unrecognized error %d\n",
+ 			rqst->rq_task->tk_pid, __func__, be32_to_cpup(p));
+ 	}
+ 
+ 	r_xprt->rx_stats.bad_reply_count++;
+ 	return -EREMOTEIO;
+ }
+ 
++>>>>>>> 264b0cdbcb93 (xprtrdma: Replace rpcrdma_count_chunks())
  /* Process received RPC/RDMA messages.
   *
   * Errors must result in the RPC task either being awakened, or
* Unmerged path net/sunrpc/xprtrdma/rpc_rdma.c
