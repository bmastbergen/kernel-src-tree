md/raid1, raid10: move rXbio accounting closer to allocation.

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [md] raid1, raid10: move rXbio accounting closer to allocation (Nigel Croxon) [1455932]
Rebuild_FUZZ: 96.61%
commit-author NeilBrown <neilb@suse.com>
commit 6b6c8110e173ce10f2b169d82a6670001f7184d1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/6b6c8110.failed

When raid1 or raid10 find they will need to allocate a new
r1bio/r10bio, in order to work around a known bad block, they
account for the allocation well before the allocation is
made.  This separation makes the correctness less obvious
and requires comments.

The accounting needs to be a little before: before the first
rXbio is submitted, but that is all.

So move the accounting down to where it makes more sense.

	Signed-off-by: NeilBrown <neilb@suse.com>
	Signed-off-by: Shaohua Li <shli@fb.com>
(cherry picked from commit 6b6c8110e173ce10f2b169d82a6670001f7184d1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/raid1.c
#	drivers/md/raid10.c
diff --cc drivers/md/raid1.c
index 0e63e69d3bfb,3afa60eb72c5..000000000000
--- a/drivers/md/raid1.c
+++ b/drivers/md/raid1.c
@@@ -1406,20 -1436,10 +1406,27 @@@ static void raid1_write_request(struct 
  		goto retry_write;
  	}
  
++<<<<<<< HEAD
 +	max_sectors = align_to_barrier_unit_end(r1_bio->sector, max_sectors);
 +	if (max_sectors < r1_bio->sectors) {
 +		/* We are splitting this write into multiple parts, so
 +		 * we need to prepare for allocating another r1_bio.
 +		 */
 +		r1_bio->sectors = max_sectors;
 +		spin_lock_irq(&conf->device_lock);
 +		if (bio->bi_phys_segments == 0)
 +			bio->bi_phys_segments = 2;
 +		else
 +			bio->bi_phys_segments++;
 +		spin_unlock_irq(&conf->device_lock);
 +	}
 +	sectors_handled = r1_bio->sector + max_sectors - bio->bi_sector;
++=======
+ 	if (max_sectors < r1_bio->sectors)
+ 		r1_bio->sectors = max_sectors;
+ 
+ 	sectors_handled = r1_bio->sector + max_sectors - bio->bi_iter.bi_sector;
++>>>>>>> 6b6c8110e173 (md/raid1, raid10: move rXbio accounting closer to allocation.)
  
  	atomic_set(&r1_bio->remaining, 1);
  	atomic_set(&r1_bio->behind_remaining, 0);
diff --cc drivers/md/raid10.c
index 9928c2ec9859,c7c5b2693fc9..000000000000
--- a/drivers/md/raid10.c
+++ b/drivers/md/raid10.c
@@@ -1500,19 -1384,10 +1500,21 @@@ retry_write
  		goto retry_write;
  	}
  
- 	if (max_sectors < r10_bio->sectors) {
- 		/* We are splitting this into multiple parts, so
- 		 * we need to prepare for allocating another r10_bio.
- 		 */
+ 	if (max_sectors < r10_bio->sectors)
  		r10_bio->sectors = max_sectors;
++<<<<<<< HEAD
 +		spin_lock_irq(&conf->device_lock);
 +		if (bio->bi_phys_segments == 0)
 +			bio->bi_phys_segments = 2;
 +		else
 +			bio->bi_phys_segments++;
 +		spin_unlock_irq(&conf->device_lock);
 +	}
 +	sectors_handled = r10_bio->sector + max_sectors - bio->bi_sector;
++=======
+ 	sectors_handled = r10_bio->sector + max_sectors -
+ 		bio->bi_iter.bi_sector;
++>>>>>>> 6b6c8110e173 (md/raid1, raid10: move rXbio accounting closer to allocation.)
  
  	atomic_set(&r10_bio->remaining, 1);
  	bitmap_startwrite(mddev->bitmap, r10_bio->sector, r10_bio->sectors, 0);
* Unmerged path drivers/md/raid1.c
* Unmerged path drivers/md/raid10.c
