net: sched: change names of action number helpers to be aligned with the rest

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [net] sched: change names of action number helpers to be aligned with the rest (Ivan Vecera) [1445420]
Rebuild_FUZZ: 96.64%
commit-author Jiri Pirko <jiri@mellanox.com>
commit 3bcc0cec818fa969fe555b44443347211ed787a3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/3bcc0cec.failed

The rest of the helpers are named tcf_exts_*, so change the name of
the action number helpers to be aligned. While at it, change to inline
functions.

	Signed-off-by: Jiri Pirko <jiri@mellanox.com>
	Acked-by: Jamal Hadi Salim <jhs@mojatatu.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 3bcc0cec818fa969fe555b44443347211ed787a3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
#	drivers/net/ethernet/netronome/nfp/bpf/offload.c
#	include/net/pkt_cls.h
#	net/dsa/slave.c
diff --cc drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
index c0b8df7cf72a,091fcc7e6e43..000000000000
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
@@@ -8564,10 -8793,468 +8564,472 @@@ int ixgbe_setup_tc(struct net_device *d
  	return 0;
  }
  
 -static int ixgbe_delete_clsu32(struct ixgbe_adapter *adapter,
 -			       struct tc_cls_u32_offload *cls)
 +static int __ixgbe_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
 +			    struct tc_to_netdev *tc)
  {
++<<<<<<< HEAD
 +	/* Only support egress tc setup for now */
++=======
+ 	u32 hdl = cls->knode.handle;
+ 	u32 uhtid = TC_U32_USERHTID(cls->knode.handle);
+ 	u32 loc = cls->knode.handle & 0xfffff;
+ 	int err = 0, i, j;
+ 	struct ixgbe_jump_table *jump = NULL;
+ 
+ 	if (loc > IXGBE_MAX_HW_ENTRIES)
+ 		return -EINVAL;
+ 
+ 	if ((uhtid != 0x800) && (uhtid >= IXGBE_MAX_LINK_HANDLE))
+ 		return -EINVAL;
+ 
+ 	/* Clear this filter in the link data it is associated with */
+ 	if (uhtid != 0x800) {
+ 		jump = adapter->jump_tables[uhtid];
+ 		if (!jump)
+ 			return -EINVAL;
+ 		if (!test_bit(loc - 1, jump->child_loc_map))
+ 			return -EINVAL;
+ 		clear_bit(loc - 1, jump->child_loc_map);
+ 	}
+ 
+ 	/* Check if the filter being deleted is a link */
+ 	for (i = 1; i < IXGBE_MAX_LINK_HANDLE; i++) {
+ 		jump = adapter->jump_tables[i];
+ 		if (jump && jump->link_hdl == hdl) {
+ 			/* Delete filters in the hardware in the child hash
+ 			 * table associated with this link
+ 			 */
+ 			for (j = 0; j < IXGBE_MAX_HW_ENTRIES; j++) {
+ 				if (!test_bit(j, jump->child_loc_map))
+ 					continue;
+ 				spin_lock(&adapter->fdir_perfect_lock);
+ 				err = ixgbe_update_ethtool_fdir_entry(adapter,
+ 								      NULL,
+ 								      j + 1);
+ 				spin_unlock(&adapter->fdir_perfect_lock);
+ 				clear_bit(j, jump->child_loc_map);
+ 			}
+ 			/* Remove resources for this link */
+ 			kfree(jump->input);
+ 			kfree(jump->mask);
+ 			kfree(jump);
+ 			adapter->jump_tables[i] = NULL;
+ 			return err;
+ 		}
+ 	}
+ 
+ 	spin_lock(&adapter->fdir_perfect_lock);
+ 	err = ixgbe_update_ethtool_fdir_entry(adapter, NULL, loc);
+ 	spin_unlock(&adapter->fdir_perfect_lock);
+ 	return err;
+ }
+ 
+ static int ixgbe_configure_clsu32_add_hnode(struct ixgbe_adapter *adapter,
+ 					    __be16 protocol,
+ 					    struct tc_cls_u32_offload *cls)
+ {
+ 	u32 uhtid = TC_U32_USERHTID(cls->hnode.handle);
+ 
+ 	if (uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 		return -EINVAL;
+ 
+ 	/* This ixgbe devices do not support hash tables at the moment
+ 	 * so abort when given hash tables.
+ 	 */
+ 	if (cls->hnode.divisor > 0)
+ 		return -EINVAL;
+ 
+ 	set_bit(uhtid - 1, &adapter->tables);
+ 	return 0;
+ }
+ 
+ static int ixgbe_configure_clsu32_del_hnode(struct ixgbe_adapter *adapter,
+ 					    struct tc_cls_u32_offload *cls)
+ {
+ 	u32 uhtid = TC_U32_USERHTID(cls->hnode.handle);
+ 
+ 	if (uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 		return -EINVAL;
+ 
+ 	clear_bit(uhtid - 1, &adapter->tables);
+ 	return 0;
+ }
+ 
+ #ifdef CONFIG_NET_CLS_ACT
+ struct upper_walk_data {
+ 	struct ixgbe_adapter *adapter;
+ 	u64 action;
+ 	int ifindex;
+ 	u8 queue;
+ };
+ 
+ static int get_macvlan_queue(struct net_device *upper, void *_data)
+ {
+ 	if (netif_is_macvlan(upper)) {
+ 		struct macvlan_dev *dfwd = netdev_priv(upper);
+ 		struct ixgbe_fwd_adapter *vadapter = dfwd->fwd_priv;
+ 		struct upper_walk_data *data = _data;
+ 		struct ixgbe_adapter *adapter = data->adapter;
+ 		int ifindex = data->ifindex;
+ 
+ 		if (vadapter && vadapter->netdev->ifindex == ifindex) {
+ 			data->queue = adapter->rx_ring[vadapter->rx_base_queue]->reg_idx;
+ 			data->action = data->queue;
+ 			return 1;
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int handle_redirect_action(struct ixgbe_adapter *adapter, int ifindex,
+ 				  u8 *queue, u64 *action)
+ {
+ 	unsigned int num_vfs = adapter->num_vfs, vf;
+ 	struct upper_walk_data data;
+ 	struct net_device *upper;
+ 
+ 	/* redirect to a SRIOV VF */
+ 	for (vf = 0; vf < num_vfs; ++vf) {
+ 		upper = pci_get_drvdata(adapter->vfinfo[vf].vfdev);
+ 		if (upper->ifindex == ifindex) {
+ 			if (adapter->num_rx_pools > 1)
+ 				*queue = vf * 2;
+ 			else
+ 				*queue = vf * adapter->num_rx_queues_per_pool;
+ 
+ 			*action = vf + 1;
+ 			*action <<= ETHTOOL_RX_FLOW_SPEC_RING_VF_OFF;
+ 			return 0;
+ 		}
+ 	}
+ 
+ 	/* redirect to a offloaded macvlan netdev */
+ 	data.adapter = adapter;
+ 	data.ifindex = ifindex;
+ 	data.action = 0;
+ 	data.queue = 0;
+ 	if (netdev_walk_all_upper_dev_rcu(adapter->netdev,
+ 					  get_macvlan_queue, &data)) {
+ 		*action = data.action;
+ 		*queue = data.queue;
+ 
+ 		return 0;
+ 	}
+ 
+ 	return -EINVAL;
+ }
+ 
+ static int parse_tc_actions(struct ixgbe_adapter *adapter,
+ 			    struct tcf_exts *exts, u64 *action, u8 *queue)
+ {
+ 	const struct tc_action *a;
+ 	LIST_HEAD(actions);
+ 	int err;
+ 
+ 	if (!tcf_exts_has_actions(exts))
+ 		return -EINVAL;
+ 
+ 	tcf_exts_to_list(exts, &actions);
+ 	list_for_each_entry(a, &actions, list) {
+ 
+ 		/* Drop action */
+ 		if (is_tcf_gact_shot(a)) {
+ 			*action = IXGBE_FDIR_DROP_QUEUE;
+ 			*queue = IXGBE_FDIR_DROP_QUEUE;
+ 			return 0;
+ 		}
+ 
+ 		/* Redirect to a VF or a offloaded macvlan */
+ 		if (is_tcf_mirred_egress_redirect(a)) {
+ 			int ifindex = tcf_mirred_ifindex(a);
+ 
+ 			err = handle_redirect_action(adapter, ifindex, queue,
+ 						     action);
+ 			if (err == 0)
+ 				return err;
+ 		}
+ 	}
+ 
+ 	return -EINVAL;
+ }
+ #else
+ static int parse_tc_actions(struct ixgbe_adapter *adapter,
+ 			    struct tcf_exts *exts, u64 *action, u8 *queue)
+ {
+ 	return -EINVAL;
+ }
+ #endif /* CONFIG_NET_CLS_ACT */
+ 
+ static int ixgbe_clsu32_build_input(struct ixgbe_fdir_filter *input,
+ 				    union ixgbe_atr_input *mask,
+ 				    struct tc_cls_u32_offload *cls,
+ 				    struct ixgbe_mat_field *field_ptr,
+ 				    struct ixgbe_nexthdr *nexthdr)
+ {
+ 	int i, j, off;
+ 	__be32 val, m;
+ 	bool found_entry = false, found_jump_field = false;
+ 
+ 	for (i = 0; i < cls->knode.sel->nkeys; i++) {
+ 		off = cls->knode.sel->keys[i].off;
+ 		val = cls->knode.sel->keys[i].val;
+ 		m = cls->knode.sel->keys[i].mask;
+ 
+ 		for (j = 0; field_ptr[j].val; j++) {
+ 			if (field_ptr[j].off == off) {
+ 				field_ptr[j].val(input, mask, val, m);
+ 				input->filter.formatted.flow_type |=
+ 					field_ptr[j].type;
+ 				found_entry = true;
+ 				break;
+ 			}
+ 		}
+ 		if (nexthdr) {
+ 			if (nexthdr->off == cls->knode.sel->keys[i].off &&
+ 			    nexthdr->val == cls->knode.sel->keys[i].val &&
+ 			    nexthdr->mask == cls->knode.sel->keys[i].mask)
+ 				found_jump_field = true;
+ 			else
+ 				continue;
+ 		}
+ 	}
+ 
+ 	if (nexthdr && !found_jump_field)
+ 		return -EINVAL;
+ 
+ 	if (!found_entry)
+ 		return 0;
+ 
+ 	mask->formatted.flow_type = IXGBE_ATR_L4TYPE_IPV6_MASK |
+ 				    IXGBE_ATR_L4TYPE_MASK;
+ 
+ 	if (input->filter.formatted.flow_type == IXGBE_ATR_FLOW_TYPE_IPV4)
+ 		mask->formatted.flow_type &= IXGBE_ATR_L4TYPE_IPV6_MASK;
+ 
+ 	return 0;
+ }
+ 
+ static int ixgbe_configure_clsu32(struct ixgbe_adapter *adapter,
+ 				  __be16 protocol,
+ 				  struct tc_cls_u32_offload *cls)
+ {
+ 	u32 loc = cls->knode.handle & 0xfffff;
+ 	struct ixgbe_hw *hw = &adapter->hw;
+ 	struct ixgbe_mat_field *field_ptr;
+ 	struct ixgbe_fdir_filter *input = NULL;
+ 	union ixgbe_atr_input *mask = NULL;
+ 	struct ixgbe_jump_table *jump = NULL;
+ 	int i, err = -EINVAL;
+ 	u8 queue;
+ 	u32 uhtid, link_uhtid;
+ 
+ 	uhtid = TC_U32_USERHTID(cls->knode.handle);
+ 	link_uhtid = TC_U32_USERHTID(cls->knode.link_handle);
+ 
+ 	/* At the moment cls_u32 jumps to network layer and skips past
+ 	 * L2 headers. The canonical method to match L2 frames is to use
+ 	 * negative values. However this is error prone at best but really
+ 	 * just broken because there is no way to "know" what sort of hdr
+ 	 * is in front of the network layer. Fix cls_u32 to support L2
+ 	 * headers when needed.
+ 	 */
+ 	if (protocol != htons(ETH_P_IP))
+ 		return err;
+ 
+ 	if (loc >= ((1024 << adapter->fdir_pballoc) - 2)) {
+ 		e_err(drv, "Location out of range\n");
+ 		return err;
+ 	}
+ 
+ 	/* cls u32 is a graph starting at root node 0x800. The driver tracks
+ 	 * links and also the fields used to advance the parser across each
+ 	 * link (e.g. nexthdr/eat parameters from 'tc'). This way we can map
+ 	 * the u32 graph onto the hardware parse graph denoted in ixgbe_model.h
+ 	 * To add support for new nodes update ixgbe_model.h parse structures
+ 	 * this function _should_ be generic try not to hardcode values here.
+ 	 */
+ 	if (uhtid == 0x800) {
+ 		field_ptr = (adapter->jump_tables[0])->mat;
+ 	} else {
+ 		if (uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 			return err;
+ 		if (!adapter->jump_tables[uhtid])
+ 			return err;
+ 		field_ptr = (adapter->jump_tables[uhtid])->mat;
+ 	}
+ 
+ 	if (!field_ptr)
+ 		return err;
+ 
+ 	/* At this point we know the field_ptr is valid and need to either
+ 	 * build cls_u32 link or attach filter. Because adding a link to
+ 	 * a handle that does not exist is invalid and the same for adding
+ 	 * rules to handles that don't exist.
+ 	 */
+ 
+ 	if (link_uhtid) {
+ 		struct ixgbe_nexthdr *nexthdr = ixgbe_ipv4_jumps;
+ 
+ 		if (link_uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 			return err;
+ 
+ 		if (!test_bit(link_uhtid - 1, &adapter->tables))
+ 			return err;
+ 
+ 		/* Multiple filters as links to the same hash table are not
+ 		 * supported. To add a new filter with the same next header
+ 		 * but different match/jump conditions, create a new hash table
+ 		 * and link to it.
+ 		 */
+ 		if (adapter->jump_tables[link_uhtid] &&
+ 		    (adapter->jump_tables[link_uhtid])->link_hdl) {
+ 			e_err(drv, "Link filter exists for link: %x\n",
+ 			      link_uhtid);
+ 			return err;
+ 		}
+ 
+ 		for (i = 0; nexthdr[i].jump; i++) {
+ 			if (nexthdr[i].o != cls->knode.sel->offoff ||
+ 			    nexthdr[i].s != cls->knode.sel->offshift ||
+ 			    nexthdr[i].m != cls->knode.sel->offmask)
+ 				return err;
+ 
+ 			jump = kzalloc(sizeof(*jump), GFP_KERNEL);
+ 			if (!jump)
+ 				return -ENOMEM;
+ 			input = kzalloc(sizeof(*input), GFP_KERNEL);
+ 			if (!input) {
+ 				err = -ENOMEM;
+ 				goto free_jump;
+ 			}
+ 			mask = kzalloc(sizeof(*mask), GFP_KERNEL);
+ 			if (!mask) {
+ 				err = -ENOMEM;
+ 				goto free_input;
+ 			}
+ 			jump->input = input;
+ 			jump->mask = mask;
+ 			jump->link_hdl = cls->knode.handle;
+ 
+ 			err = ixgbe_clsu32_build_input(input, mask, cls,
+ 						       field_ptr, &nexthdr[i]);
+ 			if (!err) {
+ 				jump->mat = nexthdr[i].jump;
+ 				adapter->jump_tables[link_uhtid] = jump;
+ 				break;
+ 			}
+ 		}
+ 		return 0;
+ 	}
+ 
+ 	input = kzalloc(sizeof(*input), GFP_KERNEL);
+ 	if (!input)
+ 		return -ENOMEM;
+ 	mask = kzalloc(sizeof(*mask), GFP_KERNEL);
+ 	if (!mask) {
+ 		err = -ENOMEM;
+ 		goto free_input;
+ 	}
+ 
+ 	if ((uhtid != 0x800) && (adapter->jump_tables[uhtid])) {
+ 		if ((adapter->jump_tables[uhtid])->input)
+ 			memcpy(input, (adapter->jump_tables[uhtid])->input,
+ 			       sizeof(*input));
+ 		if ((adapter->jump_tables[uhtid])->mask)
+ 			memcpy(mask, (adapter->jump_tables[uhtid])->mask,
+ 			       sizeof(*mask));
+ 
+ 		/* Lookup in all child hash tables if this location is already
+ 		 * filled with a filter
+ 		 */
+ 		for (i = 1; i < IXGBE_MAX_LINK_HANDLE; i++) {
+ 			struct ixgbe_jump_table *link = adapter->jump_tables[i];
+ 
+ 			if (link && (test_bit(loc - 1, link->child_loc_map))) {
+ 				e_err(drv, "Filter exists in location: %x\n",
+ 				      loc);
+ 				err = -EINVAL;
+ 				goto err_out;
+ 			}
+ 		}
+ 	}
+ 	err = ixgbe_clsu32_build_input(input, mask, cls, field_ptr, NULL);
+ 	if (err)
+ 		goto err_out;
+ 
+ 	err = parse_tc_actions(adapter, cls->knode.exts, &input->action,
+ 			       &queue);
+ 	if (err < 0)
+ 		goto err_out;
+ 
+ 	input->sw_idx = loc;
+ 
+ 	spin_lock(&adapter->fdir_perfect_lock);
+ 
+ 	if (hlist_empty(&adapter->fdir_filter_list)) {
+ 		memcpy(&adapter->fdir_mask, mask, sizeof(*mask));
+ 		err = ixgbe_fdir_set_input_mask_82599(hw, mask);
+ 		if (err)
+ 			goto err_out_w_lock;
+ 	} else if (memcmp(&adapter->fdir_mask, mask, sizeof(*mask))) {
+ 		err = -EINVAL;
+ 		goto err_out_w_lock;
+ 	}
+ 
+ 	ixgbe_atr_compute_perfect_hash_82599(&input->filter, mask);
+ 	err = ixgbe_fdir_write_perfect_filter_82599(hw, &input->filter,
+ 						    input->sw_idx, queue);
+ 	if (!err)
+ 		ixgbe_update_ethtool_fdir_entry(adapter, input, input->sw_idx);
+ 	spin_unlock(&adapter->fdir_perfect_lock);
+ 
+ 	if ((uhtid != 0x800) && (adapter->jump_tables[uhtid]))
+ 		set_bit(loc - 1, (adapter->jump_tables[uhtid])->child_loc_map);
+ 
+ 	kfree(mask);
+ 	return err;
+ err_out_w_lock:
+ 	spin_unlock(&adapter->fdir_perfect_lock);
+ err_out:
+ 	kfree(mask);
+ free_input:
+ 	kfree(input);
+ free_jump:
+ 	kfree(jump);
+ 	return err;
+ }
+ 
+ static int __ixgbe_setup_tc(struct net_device *dev, u32 handle, u32 chain_index,
+ 			    __be16 proto, struct tc_to_netdev *tc)
+ {
+ 	struct ixgbe_adapter *adapter = netdev_priv(dev);
+ 
+ 	if (chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	if (TC_H_MAJ(handle) == TC_H_MAJ(TC_H_INGRESS) &&
+ 	    tc->type == TC_SETUP_CLSU32) {
+ 		switch (tc->cls_u32->command) {
+ 		case TC_CLSU32_NEW_KNODE:
+ 		case TC_CLSU32_REPLACE_KNODE:
+ 			return ixgbe_configure_clsu32(adapter,
+ 						      proto, tc->cls_u32);
+ 		case TC_CLSU32_DELETE_KNODE:
+ 			return ixgbe_delete_clsu32(adapter, tc->cls_u32);
+ 		case TC_CLSU32_NEW_HNODE:
+ 		case TC_CLSU32_REPLACE_HNODE:
+ 			return ixgbe_configure_clsu32_add_hnode(adapter, proto,
+ 								tc->cls_u32);
+ 		case TC_CLSU32_DELETE_HNODE:
+ 			return ixgbe_configure_clsu32_del_hnode(adapter,
+ 								tc->cls_u32);
+ 		default:
+ 			return -EINVAL;
+ 		}
+ 	}
+ 
++>>>>>>> 3bcc0cec818f (net: sched: change names of action number helpers to be aligned with the rest)
  	if (tc->type != TC_SETUP_MQPRIO)
  		return -EINVAL;
  
diff --cc include/net/pkt_cls.h
index ddbf01b80b4c,7f2563636df0..000000000000
--- a/include/net/pkt_cls.h
+++ b/include/net/pkt_cls.h
@@@ -130,24 -199,35 +130,54 @@@ tcf_exts_exec(struct sk_buff *skb, stru
  	return 0;
  }
  
+ /**
+  * tcf_exts_has_actions - check if at least one action is present
+  * @exts: tc filter extensions handle
+  *
+  * Returns true if at least one action is present.
+  */
+ static inline bool tcf_exts_has_actions(struct tcf_exts *exts)
+ {
  #ifdef CONFIG_NET_CLS_ACT
+ 	return exts->nr_actions;
+ #else
+ 	return false;
+ #endif
+ }
  
++<<<<<<< HEAD
 +#define tc_no_actions(_exts) \
 +	(list_empty(&(_exts)->actions))
 +
 +#define tc_for_each_action(_a, _exts) \
 +	list_for_each_entry(_a, &(_exts)->actions, list)
 +
 +#define tc_single_action(_exts) \
 +	(list_is_singular(&(_exts)->actions))
 +
 +#else /* CONFIG_NET_CLS_ACT */
 +
 +#define tc_no_actions(_exts) true
 +#define tc_for_each_action(_a, _exts) while ((void)(_a), 0)
 +#define tc_single_action(_exts) false
 +
 +#endif /* CONFIG_NET_CLS_ACT */
++=======
+ /**
+  * tcf_exts_has_one_action - check if exactly one action is present
+  * @exts: tc filter extensions handle
+  *
+  * Returns true if exactly one action is present.
+  */
+ static inline bool tcf_exts_has_one_action(struct tcf_exts *exts)
+ {
+ #ifdef CONFIG_NET_CLS_ACT
+ 	return exts->nr_actions == 1;
+ #else
+ 	return false;
+ #endif
+ }
++>>>>>>> 3bcc0cec818f (net: sched: change names of action number helpers to be aligned with the rest)
  
  int tcf_exts_validate(struct net *net, struct tcf_proto *tp,
  		      struct nlattr **tb, struct nlattr *rate_tlv,
diff --cc net/dsa/slave.c
index f3efc3546e20,83252e8426d7..000000000000
--- a/net/dsa/slave.c
+++ b/net/dsa/slave.c
@@@ -290,12 -627,310 +290,310 @@@ static int dsa_slave_get_sset_count(str
  	return -EOPNOTSUPP;
  }
  
++<<<<<<< HEAD
++=======
+ static void dsa_slave_get_wol(struct net_device *dev, struct ethtool_wolinfo *w)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (ds->ops->get_wol)
+ 		ds->ops->get_wol(ds, p->dp->index, w);
+ }
+ 
+ static int dsa_slave_set_wol(struct net_device *dev, struct ethtool_wolinfo *w)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	int ret = -EOPNOTSUPP;
+ 
+ 	if (ds->ops->set_wol)
+ 		ret = ds->ops->set_wol(ds, p->dp->index, w);
+ 
+ 	return ret;
+ }
+ 
+ static int dsa_slave_set_eee(struct net_device *dev, struct ethtool_eee *e)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	int ret;
+ 
+ 	/* Port's PHY and MAC both need to be EEE capable */
+ 	if (!p->phy)
+ 		return -ENODEV;
+ 
+ 	if (!ds->ops->set_mac_eee)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = ds->ops->set_mac_eee(ds, p->dp->index, e);
+ 	if (ret)
+ 		return ret;
+ 
+ 	if (e->eee_enabled) {
+ 		ret = phy_init_eee(p->phy, 0);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	return phy_ethtool_set_eee(p->phy, e);
+ }
+ 
+ static int dsa_slave_get_eee(struct net_device *dev, struct ethtool_eee *e)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	int ret;
+ 
+ 	/* Port's PHY and MAC both need to be EEE capable */
+ 	if (!p->phy)
+ 		return -ENODEV;
+ 
+ 	if (!ds->ops->get_mac_eee)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = ds->ops->get_mac_eee(ds, p->dp->index, e);
+ 	if (ret)
+ 		return ret;
+ 
+ 	return phy_ethtool_get_eee(p->phy, e);
+ }
+ 
+ #ifdef CONFIG_NET_POLL_CONTROLLER
+ static int dsa_slave_netpoll_setup(struct net_device *dev,
+ 				   struct netpoll_info *ni)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct net_device *master = dsa_master_netdev(p);
+ 	struct netpoll *netpoll;
+ 	int err = 0;
+ 
+ 	netpoll = kzalloc(sizeof(*netpoll), GFP_KERNEL);
+ 	if (!netpoll)
+ 		return -ENOMEM;
+ 
+ 	err = __netpoll_setup(netpoll, master);
+ 	if (err) {
+ 		kfree(netpoll);
+ 		goto out;
+ 	}
+ 
+ 	p->netpoll = netpoll;
+ out:
+ 	return err;
+ }
+ 
+ static void dsa_slave_netpoll_cleanup(struct net_device *dev)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct netpoll *netpoll = p->netpoll;
+ 
+ 	if (!netpoll)
+ 		return;
+ 
+ 	p->netpoll = NULL;
+ 
+ 	__netpoll_free_async(netpoll);
+ }
+ 
+ static void dsa_slave_poll_controller(struct net_device *dev)
+ {
+ }
+ #endif
+ 
+ static int dsa_slave_get_phys_port_name(struct net_device *dev,
+ 					char *name, size_t len)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 
+ 	if (snprintf(name, len, "p%d", p->dp->index) >= len)
+ 		return -EINVAL;
+ 
+ 	return 0;
+ }
+ 
+ static struct dsa_mall_tc_entry *
+ dsa_slave_mall_tc_entry_find(struct dsa_slave_priv *p,
+ 			     unsigned long cookie)
+ {
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 
+ 	list_for_each_entry(mall_tc_entry, &p->mall_tc_list, list)
+ 		if (mall_tc_entry->cookie == cookie)
+ 			return mall_tc_entry;
+ 
+ 	return NULL;
+ }
+ 
+ static int dsa_slave_add_cls_matchall(struct net_device *dev,
+ 				      __be16 protocol,
+ 				      struct tc_cls_matchall_offload *cls,
+ 				      bool ingress)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	struct net *net = dev_net(dev);
+ 	struct dsa_slave_priv *to_p;
+ 	struct net_device *to_dev;
+ 	const struct tc_action *a;
+ 	int err = -EOPNOTSUPP;
+ 	LIST_HEAD(actions);
+ 	int ifindex;
+ 
+ 	if (!ds->ops->port_mirror_add)
+ 		return err;
+ 
+ 	if (!tcf_exts_has_one_action(cls->exts))
+ 		return err;
+ 
+ 	tcf_exts_to_list(cls->exts, &actions);
+ 	a = list_first_entry(&actions, struct tc_action, list);
+ 
+ 	if (is_tcf_mirred_egress_mirror(a) && protocol == htons(ETH_P_ALL)) {
+ 		struct dsa_mall_mirror_tc_entry *mirror;
+ 
+ 		ifindex = tcf_mirred_ifindex(a);
+ 		to_dev = __dev_get_by_index(net, ifindex);
+ 		if (!to_dev)
+ 			return -EINVAL;
+ 
+ 		if (!dsa_slave_dev_check(to_dev))
+ 			return -EOPNOTSUPP;
+ 
+ 		mall_tc_entry = kzalloc(sizeof(*mall_tc_entry), GFP_KERNEL);
+ 		if (!mall_tc_entry)
+ 			return -ENOMEM;
+ 
+ 		mall_tc_entry->cookie = cls->cookie;
+ 		mall_tc_entry->type = DSA_PORT_MALL_MIRROR;
+ 		mirror = &mall_tc_entry->mirror;
+ 
+ 		to_p = netdev_priv(to_dev);
+ 
+ 		mirror->to_local_port = to_p->dp->index;
+ 		mirror->ingress = ingress;
+ 
+ 		err = ds->ops->port_mirror_add(ds, p->dp->index, mirror,
+ 					       ingress);
+ 		if (err) {
+ 			kfree(mall_tc_entry);
+ 			return err;
+ 		}
+ 
+ 		list_add_tail(&mall_tc_entry->list, &p->mall_tc_list);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void dsa_slave_del_cls_matchall(struct net_device *dev,
+ 				       struct tc_cls_matchall_offload *cls)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (!ds->ops->port_mirror_del)
+ 		return;
+ 
+ 	mall_tc_entry = dsa_slave_mall_tc_entry_find(p, cls->cookie);
+ 	if (!mall_tc_entry)
+ 		return;
+ 
+ 	list_del(&mall_tc_entry->list);
+ 
+ 	switch (mall_tc_entry->type) {
+ 	case DSA_PORT_MALL_MIRROR:
+ 		ds->ops->port_mirror_del(ds, p->dp->index,
+ 					 &mall_tc_entry->mirror);
+ 		break;
+ 	default:
+ 		WARN_ON(1);
+ 	}
+ 
+ 	kfree(mall_tc_entry);
+ }
+ 
+ static int dsa_slave_setup_tc(struct net_device *dev, u32 handle,
+ 			      u32 chain_index, __be16 protocol,
+ 			      struct tc_to_netdev *tc)
+ {
+ 	bool ingress = TC_H_MAJ(handle) == TC_H_MAJ(TC_H_INGRESS);
+ 
+ 	if (chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (tc->type) {
+ 	case TC_SETUP_MATCHALL:
+ 		switch (tc->cls_mall->command) {
+ 		case TC_CLSMATCHALL_REPLACE:
+ 			return dsa_slave_add_cls_matchall(dev, protocol,
+ 							  tc->cls_mall,
+ 							  ingress);
+ 		case TC_CLSMATCHALL_DESTROY:
+ 			dsa_slave_del_cls_matchall(dev, tc->cls_mall);
+ 			return 0;
+ 		}
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static void dsa_slave_get_stats64(struct net_device *dev,
+ 				  struct rtnl_link_stats64 *stats)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	unsigned int start;
+ 
+ 	netdev_stats_to_stats64(stats, &dev->stats);
+ 	do {
+ 		start = u64_stats_fetch_begin_irq(&p->stats64.syncp);
+ 		stats->tx_packets = p->stats64.tx_packets;
+ 		stats->tx_bytes = p->stats64.tx_bytes;
+ 		stats->rx_packets = p->stats64.rx_packets;
+ 		stats->rx_bytes = p->stats64.rx_bytes;
+ 	} while (u64_stats_fetch_retry_irq(&p->stats64.syncp, start));
+ }
+ 
+ void dsa_cpu_port_ethtool_init(struct ethtool_ops *ops)
+ {
+ 	ops->get_sset_count = dsa_cpu_port_get_sset_count;
+ 	ops->get_ethtool_stats = dsa_cpu_port_get_ethtool_stats;
+ 	ops->get_strings = dsa_cpu_port_get_strings;
+ }
+ 
+ static int dsa_slave_get_rxnfc(struct net_device *dev,
+ 			       struct ethtool_rxnfc *nfc, u32 *rule_locs)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (!ds->ops->get_rxnfc)
+ 		return -EOPNOTSUPP;
+ 
+ 	return ds->ops->get_rxnfc(ds, p->dp->index, nfc, rule_locs);
+ }
+ 
+ static int dsa_slave_set_rxnfc(struct net_device *dev,
+ 			       struct ethtool_rxnfc *nfc)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (!ds->ops->set_rxnfc)
+ 		return -EOPNOTSUPP;
+ 
+ 	return ds->ops->set_rxnfc(ds, p->dp->index, nfc);
+ }
+ 
++>>>>>>> 3bcc0cec818f (net: sched: change names of action number helpers to be aligned with the rest)
  static const struct ethtool_ops dsa_slave_ethtool_ops = {
 +	.get_settings		= dsa_slave_get_settings,
 +	.set_settings		= dsa_slave_set_settings,
  	.get_drvinfo		= dsa_slave_get_drvinfo,
 -	.get_regs_len		= dsa_slave_get_regs_len,
 -	.get_regs		= dsa_slave_get_regs,
  	.nway_reset		= dsa_slave_nway_reset,
  	.get_link		= dsa_slave_get_link,
 -	.get_eeprom_len		= dsa_slave_get_eeprom_len,
 -	.get_eeprom		= dsa_slave_get_eeprom,
 -	.set_eeprom		= dsa_slave_set_eeprom,
  	.get_strings		= dsa_slave_get_strings,
  	.get_ethtool_stats	= dsa_slave_get_ethtool_stats,
  	.get_sset_count		= dsa_slave_get_sset_count,
* Unmerged path drivers/net/ethernet/netronome/nfp/bpf/offload.c
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_u32.c b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_u32.c
index 82a33ea38f03..3ff43d0e1042 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_u32.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_u32.c
@@ -96,7 +96,7 @@ static int fill_action_fields(struct adapter *adap,
 	LIST_HEAD(actions);
 
 	exts = cls->knode.exts;
-	if (tc_no_actions(exts))
+	if (!tcf_exts_has_actions(exts))
 		return -EINVAL;
 
 	tc_for_each_action(a, exts) {
* Unmerged path drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index 7ecb54e0e3be..216f6a639643 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@ -653,7 +653,7 @@ static int parse_tc_nic_actions(struct mlx5e_priv *priv, struct tcf_exts *exts,
 {
 	const struct tc_action *a;
 
-	if (tc_no_actions(exts))
+	if (!tcf_exts_has_actions(exts))
 		return -EINVAL;
 
 	*flow_tag = MLX5_FS_DEFAULT_FLOW_TAG;
@@ -1083,7 +1083,7 @@ static int parse_tc_fdb_actions(struct mlx5e_priv *priv, struct tcf_exts *exts,
 	bool encap = false;
 	int err;
 
-	if (tc_no_actions(exts))
+	if (!tcf_exts_has_actions(exts))
 		return -EINVAL;
 
 	memset(attr, 0, sizeof(*attr));
diff --git a/drivers/net/ethernet/mellanox/mlxsw/spectrum.c b/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
index c628b7aede0f..1e79e7a33599 100644
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
@@ -1227,7 +1227,7 @@ static int mlxsw_sp_port_add_cls_matchall(struct mlxsw_sp_port *mlxsw_sp_port,
 	const struct tc_action *a;
 	int err;
 
-	if (!tc_single_action(cls->exts)) {
+	if (!tcf_exts_has_one_action(cls->exts)) {
 		netdev_err(mlxsw_sp_port->dev, "only singular actions are supported\n");
 		return -EOPNOTSUPP;
 	}
diff --git a/drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c b/drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c
index c668b6dd906d..ae063179e014 100644
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c
@@ -51,7 +51,7 @@ static int mlxsw_sp_flower_parse_actions(struct mlxsw_sp *mlxsw_sp,
 	const struct tc_action *a;
 	int err;
 
-	if (tc_no_actions(exts))
+	if (!tcf_exts_has_actions(exts))
 		return 0;
 
 	tc_for_each_action(a, exts) {
* Unmerged path drivers/net/ethernet/netronome/nfp/bpf/offload.c
* Unmerged path include/net/pkt_cls.h
* Unmerged path net/dsa/slave.c
diff --git a/net/sched/cls_api.c b/net/sched/cls_api.c
index 1dc6d123ed94..d108e860b191 100644
--- a/net/sched/cls_api.c
+++ b/net/sched/cls_api.c
@@ -665,7 +665,7 @@ int tcf_exts_get_dev(struct net_device *dev, struct tcf_exts *exts,
 #ifdef CONFIG_NET_CLS_ACT
 	const struct tc_action *a;
 
-	if (tc_no_actions(exts))
+	if (!tcf_exts_has_actions(exts))
 		return -EINVAL;
 
 	list_for_each_entry(a, &exts->actions, list) {
