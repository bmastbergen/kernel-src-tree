cpufreq: intel_pstate: Use locking in intel_cpufreq_verify_policy()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [cpufreq] intel_pstate: Use locking in intel_cpufreq_verify_policy() (Prarit Bhargava) [1465349]
Rebuild_FUZZ: 92.80%
commit-author Rafael J. Wysocki <rafael.j.wysocki@intel.com>
commit cad30467963267509d5b0d7d3c9bd1af3b91e720
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/cad30467.failed

Race conditions are possible if intel_cpufreq_verify_policy()
is executed in parallel with global limits updates from sysfs,
so the invocation of intel_pstate_update_perf_limits() in it
should be carried out under intel_pstate_limits_lock.

Make that happen.

	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
	Acked-by: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
(cherry picked from commit cad30467963267509d5b0d7d3c9bd1af3b91e720)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/intel_pstate.c
diff --cc drivers/cpufreq/intel_pstate.c
index e5b33d3c3e3c,f8e514d7fbc4..000000000000
--- a/drivers/cpufreq/intel_pstate.c
+++ b/drivers/cpufreq/intel_pstate.c
@@@ -1538,6 -2089,122 +1538,125 @@@ static struct cpufreq_driver intel_psta
  	.name		= "intel_pstate",
  };
  
++<<<<<<< HEAD
++=======
+ static int intel_cpufreq_verify_policy(struct cpufreq_policy *policy)
+ {
+ 	struct cpudata *cpu = all_cpu_data[policy->cpu];
+ 	struct perf_limits *perf_limits = limits;
+ 
+ 	update_turbo_state();
+ 	policy->cpuinfo.max_freq = limits->turbo_disabled ?
+ 			cpu->pstate.max_freq : cpu->pstate.turbo_freq;
+ 
+ 	cpufreq_verify_within_cpu_limits(policy);
+ 
+ 	if (per_cpu_limits)
+ 		perf_limits = cpu->perf_limits;
+ 
+ 	mutex_lock(&intel_pstate_limits_lock);
+ 
+ 	intel_pstate_update_perf_limits(policy, perf_limits);
+ 
+ 	mutex_unlock(&intel_pstate_limits_lock);
+ 
+ 	return 0;
+ }
+ 
+ static unsigned int intel_cpufreq_turbo_update(struct cpudata *cpu,
+ 					       struct cpufreq_policy *policy,
+ 					       unsigned int target_freq)
+ {
+ 	unsigned int max_freq;
+ 
+ 	update_turbo_state();
+ 
+ 	max_freq = limits->no_turbo || limits->turbo_disabled ?
+ 			cpu->pstate.max_freq : cpu->pstate.turbo_freq;
+ 	policy->cpuinfo.max_freq = max_freq;
+ 	if (policy->max > max_freq)
+ 		policy->max = max_freq;
+ 
+ 	if (target_freq > max_freq)
+ 		target_freq = max_freq;
+ 
+ 	return target_freq;
+ }
+ 
+ static int intel_cpufreq_target(struct cpufreq_policy *policy,
+ 				unsigned int target_freq,
+ 				unsigned int relation)
+ {
+ 	struct cpudata *cpu = all_cpu_data[policy->cpu];
+ 	struct cpufreq_freqs freqs;
+ 	int target_pstate;
+ 
+ 	freqs.old = policy->cur;
+ 	freqs.new = intel_cpufreq_turbo_update(cpu, policy, target_freq);
+ 
+ 	cpufreq_freq_transition_begin(policy, &freqs);
+ 	switch (relation) {
+ 	case CPUFREQ_RELATION_L:
+ 		target_pstate = DIV_ROUND_UP(freqs.new, cpu->pstate.scaling);
+ 		break;
+ 	case CPUFREQ_RELATION_H:
+ 		target_pstate = freqs.new / cpu->pstate.scaling;
+ 		break;
+ 	default:
+ 		target_pstate = DIV_ROUND_CLOSEST(freqs.new, cpu->pstate.scaling);
+ 		break;
+ 	}
+ 	target_pstate = intel_pstate_prepare_request(cpu, target_pstate);
+ 	if (target_pstate != cpu->pstate.current_pstate) {
+ 		cpu->pstate.current_pstate = target_pstate;
+ 		wrmsrl_on_cpu(policy->cpu, MSR_IA32_PERF_CTL,
+ 			      pstate_funcs.get_val(cpu, target_pstate));
+ 	}
+ 	cpufreq_freq_transition_end(policy, &freqs, false);
+ 
+ 	return 0;
+ }
+ 
+ static unsigned int intel_cpufreq_fast_switch(struct cpufreq_policy *policy,
+ 					      unsigned int target_freq)
+ {
+ 	struct cpudata *cpu = all_cpu_data[policy->cpu];
+ 	int target_pstate;
+ 
+ 	target_freq = intel_cpufreq_turbo_update(cpu, policy, target_freq);
+ 	target_pstate = DIV_ROUND_UP(target_freq, cpu->pstate.scaling);
+ 	intel_pstate_update_pstate(cpu, target_pstate);
+ 	return target_freq;
+ }
+ 
+ static int intel_cpufreq_cpu_init(struct cpufreq_policy *policy)
+ {
+ 	int ret = __intel_pstate_cpu_init(policy);
+ 
+ 	if (ret)
+ 		return ret;
+ 
+ 	policy->cpuinfo.transition_latency = INTEL_CPUFREQ_TRANSITION_LATENCY;
+ 	/* This reflects the intel_pstate_get_cpu_pstates() setting. */
+ 	policy->cur = policy->cpuinfo.min_freq;
+ 
+ 	return 0;
+ }
+ 
+ static struct cpufreq_driver intel_cpufreq = {
+ 	.flags		= CPUFREQ_CONST_LOOPS,
+ 	.verify		= intel_cpufreq_verify_policy,
+ 	.target		= intel_cpufreq_target,
+ 	.fast_switch	= intel_cpufreq_fast_switch,
+ 	.init		= intel_cpufreq_cpu_init,
+ 	.exit		= intel_pstate_cpu_exit,
+ 	.stop_cpu	= intel_cpufreq_stop_cpu,
+ 	.name		= "intel_cpufreq",
+ };
+ 
+ static struct cpufreq_driver *intel_pstate_driver = &intel_pstate;
+ 
++>>>>>>> cad304679632 (cpufreq: intel_pstate: Use locking in intel_cpufreq_verify_policy())
  static int no_load __initdata;
  static int no_hwp __initdata;
  static int hwp_only __initdata;
* Unmerged path drivers/cpufreq/intel_pstate.c
