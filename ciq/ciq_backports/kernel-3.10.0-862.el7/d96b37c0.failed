blk-mq: move tags and sched_tags info from sysfs to debugfs

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Omar Sandoval <osandov@fb.com>
commit d96b37c0af3e4f42928a1361d5cd9f4f8921b4a8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/d96b37c0.failed

These are very tied to the blk-mq tag implementation, so exposing them
to sysfs isn't a great idea. Move the debugging information to debugfs
and add basic entries for the number of tags and the number of reserved
tags to sysfs.

	Reviewed-by: Hannes Reinecke <hare@suse.com>
	Signed-off-by: Omar Sandoval <osandov@fb.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit d96b37c0af3e4f42928a1361d5cd9f4f8921b4a8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq-debugfs.c
#	block/blk-mq-sysfs.c
#	block/blk-mq-tag.c
#	block/blk-mq-tag.h
diff --cc block/blk-mq-sysfs.c
index 08941faf0f9a,a0ae1f536ed0..000000000000
--- a/block/blk-mq-sysfs.c
+++ b/block/blk-mq-sysfs.c
@@@ -204,21 -184,16 +204,29 @@@ static ssize_t blk_mq_hw_sysfs_dispatch
  	return page - start_page;
  }
  
++<<<<<<< HEAD
 +static ssize_t blk_mq_hw_sysfs_rq_list_show(struct blk_mq_hw_ctx *hctx,
 +					    char *page)
 +{
 +	ssize_t ret;
 +
 +	spin_lock(&hctx->lock);
 +	ret = sysfs_list_show(page, &hctx->dispatch, "HCTX pending");
 +	spin_unlock(&hctx->lock);
 +
 +	return ret;
++=======
+ static ssize_t blk_mq_hw_sysfs_nr_tags_show(struct blk_mq_hw_ctx *hctx,
+ 					    char *page)
+ {
+ 	return sprintf(page, "%u\n", hctx->tags->nr_tags);
++>>>>>>> d96b37c0af3e (blk-mq: move tags and sched_tags info from sysfs to debugfs)
  }
  
- static ssize_t blk_mq_hw_sysfs_tags_show(struct blk_mq_hw_ctx *hctx, char *page)
+ static ssize_t blk_mq_hw_sysfs_nr_reserved_tags_show(struct blk_mq_hw_ctx *hctx,
+ 						     char *page)
  {
- 	return blk_mq_tag_sysfs_show(hctx->tags, page);
+ 	return sprintf(page, "%u\n", hctx->tags->nr_reserved_tags);
  }
  
  static ssize_t blk_mq_hw_sysfs_active_show(struct blk_mq_hw_ctx *hctx, char *page)
@@@ -285,14 -304,6 +301,17 @@@ static struct blk_mq_hw_ctx_sysfs_entr
  	.attr = {.name = "active", .mode = S_IRUGO },
  	.show = blk_mq_hw_sysfs_active_show,
  };
++<<<<<<< HEAD
 +static struct blk_mq_hw_ctx_sysfs_entry blk_mq_hw_sysfs_pending = {
 +	.attr = {.name = "pending", .mode = S_IRUGO },
 +	.show = blk_mq_hw_sysfs_rq_list_show,
 +};
 +static struct blk_mq_hw_ctx_sysfs_entry blk_mq_hw_sysfs_tags = {
 +	.attr = {.name = "tags", .mode = S_IRUGO },
 +	.show = blk_mq_hw_sysfs_tags_show,
 +};
++=======
++>>>>>>> d96b37c0af3e (blk-mq: move tags and sched_tags info from sysfs to debugfs)
  static struct blk_mq_hw_ctx_sysfs_entry blk_mq_hw_sysfs_cpus = {
  	.attr = {.name = "cpu_list", .mode = S_IRUGO },
  	.show = blk_mq_hw_sysfs_cpus_show,
@@@ -302,10 -323,12 +321,15 @@@ static struct attribute *default_hw_ctx
  	&blk_mq_hw_sysfs_queued.attr,
  	&blk_mq_hw_sysfs_run.attr,
  	&blk_mq_hw_sysfs_dispatched.attr,
++<<<<<<< HEAD
 +	&blk_mq_hw_sysfs_pending.attr,
 +	&blk_mq_hw_sysfs_tags.attr,
++=======
+ 	&blk_mq_hw_sysfs_nr_tags.attr,
+ 	&blk_mq_hw_sysfs_nr_reserved_tags.attr,
++>>>>>>> d96b37c0af3e (blk-mq: move tags and sched_tags info from sysfs to debugfs)
  	&blk_mq_hw_sysfs_cpus.attr,
  	&blk_mq_hw_sysfs_active.attr,
 -	&blk_mq_hw_sysfs_poll.attr,
 -	&blk_mq_hw_sysfs_stat.attr,
  	NULL,
  };
  
diff --cc block/blk-mq-tag.c
index 7e6885bccaac,f8de2dbbb29f..000000000000
--- a/block/blk-mq-tag.c
+++ b/block/blk-mq-tag.c
@@@ -533,100 -329,11 +533,105 @@@ void blk_mq_queue_tag_busy_iter(struct 
  
  }
  
++<<<<<<< HEAD
 +static unsigned int bt_unused_tags(struct blk_mq_bitmap_tags *bt)
 +{
 +	unsigned int i, used;
 +
 +	for (i = 0, used = 0; i < bt->map_nr; i++) {
 +		struct blk_align_bitmap *bm = &bt->map[i];
 +
 +		used += bitmap_weight(&bm->word, bm->depth);
 +	}
 +
 +	return bt->depth - used;
 +}
 +
 +static void bt_update_count(struct blk_mq_bitmap_tags *bt,
 +			    unsigned int depth)
++=======
+ static int bt_alloc(struct sbitmap_queue *bt, unsigned int depth,
+ 		    bool round_robin, int node)
++>>>>>>> d96b37c0af3e (blk-mq: move tags and sched_tags info from sysfs to debugfs)
  {
 -	return sbitmap_queue_init_node(bt, depth, -1, round_robin, GFP_KERNEL,
 -				       node);
 +	unsigned int tags_per_word = 1U << bt->bits_per_word;
 +	unsigned int map_depth = depth;
 +
 +	if (depth) {
 +		int i;
 +
 +		for (i = 0; i < bt->map_nr; i++) {
 +			bt->map[i].depth = min(map_depth, tags_per_word);
 +			map_depth -= bt->map[i].depth;
 +		}
 +	}
 +
 +	bt->wake_cnt = BT_WAIT_BATCH;
 +	if (bt->wake_cnt > depth / BT_WAIT_QUEUES)
 +		bt->wake_cnt = max(1U, depth / BT_WAIT_QUEUES);
 +
 +	bt->depth = depth;
 +}
 +
 +static int bt_alloc(struct blk_mq_bitmap_tags *bt, unsigned int depth,
 +			int node, bool reserved)
 +{
 +	int i;
 +
 +	bt->bits_per_word = ilog2(BITS_PER_LONG);
 +
 +	/*
 +	 * Depth can be zero for reserved tags, that's not a failure
 +	 * condition.
 +	 */
 +	if (depth) {
 +		unsigned int nr, tags_per_word;
 +
 +		tags_per_word = (1 << bt->bits_per_word);
 +
 +		/*
 +		 * If the tag space is small, shrink the number of tags
 +		 * per word so we spread over a few cachelines, at least.
 +		 * If less than 4 tags, just forget about it, it's not
 +		 * going to work optimally anyway.
 +		 */
 +		if (depth >= 4) {
 +			while (tags_per_word * 4 > depth) {
 +				bt->bits_per_word--;
 +				tags_per_word = (1 << bt->bits_per_word);
 +			}
 +		}
 +
 +		nr = ALIGN(depth, tags_per_word) / tags_per_word;
 +		bt->map = kzalloc_node(nr * sizeof(struct blk_align_bitmap),
 +						GFP_KERNEL, node);
 +		if (!bt->map)
 +			return -ENOMEM;
 +
 +		bt->map_nr = nr;
 +	}
 +
 +	bt->bs = kzalloc(BT_WAIT_QUEUES * sizeof(*bt->bs), GFP_KERNEL);
 +	if (!bt->bs) {
 +		kfree(bt->map);
 +		bt->map = NULL;
 +		return -ENOMEM;
 +	}
 +
 +	bt_update_count(bt, depth);
 +
 +	for (i = 0; i < BT_WAIT_QUEUES; i++) {
 +		init_waitqueue_head(&bt->bs[i].wait);
 +		atomic_set(&bt->bs[i].wait_cnt, bt->wake_cnt);
 +	}
 +
 +	return 0;
 +}
 +
 +static void bt_free(struct blk_mq_bitmap_tags *bt)
 +{
 +	kfree(bt->map);
 +	kfree(bt->bs);
  }
  
  static struct blk_mq_tags *blk_mq_init_bitmap_tags(struct blk_mq_tags *tags,
@@@ -728,25 -464,3 +733,28 @@@ u32 blk_mq_unique_tag(struct request *r
  		(rq->tag & BLK_MQ_UNIQUE_TAG_MASK);
  }
  EXPORT_SYMBOL(blk_mq_unique_tag);
++<<<<<<< HEAD
 +
 +ssize_t blk_mq_tag_sysfs_show(struct blk_mq_tags *tags, char *page)
 +{
 +	char *orig_page = page;
 +	unsigned int free, res;
 +
 +	if (!tags)
 +		return 0;
 +
 +	page += sprintf(page, "nr_tags=%u, reserved_tags=%u, "
 +			"bits_per_word=%u\n",
 +			tags->nr_tags, tags->nr_reserved_tags,
 +			tags->bitmap_tags.bits_per_word);
 +
 +	free = bt_unused_tags(&tags->bitmap_tags);
 +	res = bt_unused_tags(&tags->breserved_tags);
 +
 +	page += sprintf(page, "nr_free=%u, nr_reserved=%u\n", free, res);
 +	page += sprintf(page, "active_queues=%u\n", atomic_read(&tags->active_queues));
 +
 +	return page - orig_page;
 +}
++=======
++>>>>>>> d96b37c0af3e (blk-mq: move tags and sched_tags info from sysfs to debugfs)
diff --cc block/blk-mq-tag.h
index 5cdeb865c8ff,63497423c5cd..000000000000
--- a/block/blk-mq-tag.h
+++ b/block/blk-mq-tag.h
@@@ -51,11 -25,12 +51,17 @@@ extern struct blk_mq_tags *blk_mq_init_
  extern void blk_mq_free_tags(struct blk_mq_tags *tags);
  
  extern unsigned int blk_mq_get_tag(struct blk_mq_alloc_data *data);
 -extern void blk_mq_put_tag(struct blk_mq_hw_ctx *hctx, struct blk_mq_tags *tags,
 -			   struct blk_mq_ctx *ctx, unsigned int tag);
 +extern void blk_mq_put_tag(struct blk_mq_hw_ctx *hctx, unsigned int tag, unsigned int *last_tag);
  extern bool blk_mq_has_free_tags(struct blk_mq_tags *tags);
++<<<<<<< HEAD
 +extern ssize_t blk_mq_tag_sysfs_show(struct blk_mq_tags *tags, char *page);
 +extern void blk_mq_tag_init_last_tag(struct blk_mq_tags *tags, unsigned int *last_tag);
 +extern int blk_mq_tag_update_depth(struct blk_mq_tags *tags, unsigned int depth);
++=======
+ extern int blk_mq_tag_update_depth(struct blk_mq_hw_ctx *hctx,
+ 					struct blk_mq_tags **tags,
+ 					unsigned int depth, bool can_grow);
++>>>>>>> d96b37c0af3e (blk-mq: move tags and sched_tags info from sysfs to debugfs)
  extern void blk_mq_tag_wakeup_all(struct blk_mq_tags *tags, bool);
  void blk_mq_queue_tag_busy_iter(struct request_queue *q, busy_iter_fn *fn,
  		void *priv);
* Unmerged path block/blk-mq-debugfs.c
* Unmerged path block/blk-mq-debugfs.c
* Unmerged path block/blk-mq-sysfs.c
* Unmerged path block/blk-mq-tag.c
* Unmerged path block/blk-mq-tag.h
