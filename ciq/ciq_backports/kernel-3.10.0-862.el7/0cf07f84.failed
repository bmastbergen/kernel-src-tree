scsi: lpfc: Add auto EQ delay logic

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [scsi] lpfc: Add auto EQ delay logic (Dick Kennedy) [1385844 1461977 1387768]
Rebuild_FUZZ: 90.62%
commit-author James Smart <jsmart2021@gmail.com>
commit 0cf07f84dd32639394084b9d6794424587a38789
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/0cf07f84.failed

Administrator intervention is currently required to get good numbers
when switching from running latency tests to IOPS tests.

The configured interrupt coalescing values will greatly effect the
results of these tests.  Currently, the driver has a single coalescing
value set by values of the module attribute.  This patch changes the
driver to support auto-configuration of the coalescing value based on
the total number of outstanding IOs and average number of CQEs processed
per interrupt for an EQ.  Values are checked every 5 seconds.

The driver defaults to the automatic selection. Automatic selection can
be disabled by the new lpfc_auto_imax module_parameter.

Older hardware can only change interrupt coalescing by mailbox
command. Newer hardware supports change via a register. The patch
support both.

	Signed-off-by: Dick Kennedy <dick.kennedy@broadcom.com>
	Signed-off-by: James Smart <james.smart@broadcom.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit 0cf07f84dd32639394084b9d6794424587a38789)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/lpfc/lpfc_attr.c
#	drivers/scsi/lpfc/lpfc_debugfs.c
#	drivers/scsi/lpfc/lpfc_hw4.h
#	drivers/scsi/lpfc/lpfc_init.c
#	drivers/scsi/lpfc/lpfc_sli.c
#	drivers/scsi/lpfc/lpfc_sli.h
#	drivers/scsi/lpfc/lpfc_sli4.h
diff --cc drivers/scsi/lpfc/lpfc_attr.c
index e030a290e43b,66269e342c7e..000000000000
--- a/drivers/scsi/lpfc/lpfc_attr.c
+++ b/drivers/scsi/lpfc/lpfc_attr.c
@@@ -4160,8 -4481,11 +4160,16 @@@ lpfc_fcp_imax_store(struct device *dev
  		return -EINVAL;
  
  	phba->cfg_fcp_imax = (uint32_t)val;
++<<<<<<< HEAD
 +	for (i = 0; i < phba->cfg_fcp_io_channel; i += LPFC_MAX_EQ_DELAY)
 +		lpfc_modify_fcp_eq_delay(phba, i);
++=======
+ 	phba->initial_imax = phba->cfg_fcp_imax;
+ 
+ 	for (i = 0; i < phba->io_channel_irqs; i += LPFC_MAX_EQ_DELAY_EQID_CNT)
+ 		lpfc_modify_hba_eq_delay(phba, i, LPFC_MAX_EQ_DELAY_EQID_CNT,
+ 					 val);
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  
  	return strlen(buf);
  }
@@@ -4762,6 -5175,8 +4780,11 @@@ struct device_attribute *lpfc_hba_attrs
  	&dev_attr_lpfc_poll_tmo,
  	&dev_attr_lpfc_task_mgmt_tmo,
  	&dev_attr_lpfc_use_msi,
++<<<<<<< HEAD
++=======
+ 	&dev_attr_lpfc_nvme_oas,
+ 	&dev_attr_lpfc_auto_imax,
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  	&dev_attr_lpfc_fcp_imax,
  	&dev_attr_lpfc_fcp_cpu_map,
  	&dev_attr_lpfc_fcp_io_channel,
@@@ -5775,11 -6194,13 +5798,16 @@@ lpfc_get_cfgparam(struct lpfc_hba *phba
  	lpfc_fdmi_on_init(phba, lpfc_fdmi_on);
  	lpfc_enable_SmartSAN_init(phba, lpfc_enable_SmartSAN);
  	lpfc_use_msi_init(phba, lpfc_use_msi);
++<<<<<<< HEAD
++=======
+ 	lpfc_nvme_oas_init(phba, lpfc_nvme_oas);
+ 	lpfc_auto_imax_init(phba, lpfc_auto_imax);
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  	lpfc_fcp_imax_init(phba, lpfc_fcp_imax);
  	lpfc_fcp_cpu_map_init(phba, lpfc_fcp_cpu_map);
 +	lpfc_fcp_io_channel_init(phba, lpfc_fcp_io_channel);
  	lpfc_enable_hba_reset_init(phba, lpfc_enable_hba_reset);
  	lpfc_enable_hba_heartbeat_init(phba, lpfc_enable_hba_heartbeat);
 -
  	lpfc_EnableXLane_init(phba, lpfc_EnableXLane);
  	if (phba->sli_rev != LPFC_SLI_REV4)
  		phba->cfg_EnableXLane = 0;
@@@ -5795,6 -6219,47 +5823,50 @@@
  		phba->cfg_poll = 0;
  	else
  		phba->cfg_poll = lpfc_poll;
++<<<<<<< HEAD
++=======
+ 	lpfc_suppress_rsp_init(phba, lpfc_suppress_rsp);
+ 
+ 	lpfc_enable_fc4_type_init(phba, lpfc_enable_fc4_type);
+ 	lpfc_nvmet_mrq_init(phba, lpfc_nvmet_mrq);
+ 
+ 	/* Initialize first burst. Target vs Initiator are different. */
+ 	lpfc_nvme_enable_fb_init(phba, lpfc_nvme_enable_fb);
+ 	lpfc_nvmet_fb_size_init(phba, lpfc_nvmet_fb_size);
+ 	lpfc_fcp_io_channel_init(phba, lpfc_fcp_io_channel);
+ 	lpfc_nvme_io_channel_init(phba, lpfc_nvme_io_channel);
+ 
+ 	if (phba->sli_rev != LPFC_SLI_REV4) {
+ 		/* NVME only supported on SLI4 */
+ 		phba->nvmet_support = 0;
+ 		phba->cfg_enable_fc4_type = LPFC_ENABLE_FCP;
+ 	} else {
+ 		/* We MUST have FCP support */
+ 		if (!(phba->cfg_enable_fc4_type & LPFC_ENABLE_FCP))
+ 			phba->cfg_enable_fc4_type |= LPFC_ENABLE_FCP;
+ 	}
+ 
+ 	if (phba->cfg_auto_imax && !phba->cfg_fcp_imax)
+ 		phba->cfg_auto_imax = 0;
+ 	phba->initial_imax = phba->cfg_fcp_imax;
+ 
+ 	/* A value of 0 means use the number of CPUs found in the system */
+ 	if (phba->cfg_fcp_io_channel == 0)
+ 		phba->cfg_fcp_io_channel = phba->sli4_hba.num_present_cpu;
+ 	if (phba->cfg_nvme_io_channel == 0)
+ 		phba->cfg_nvme_io_channel = phba->sli4_hba.num_present_cpu;
+ 
+ 	if (phba->cfg_enable_fc4_type == LPFC_ENABLE_NVME)
+ 		phba->cfg_fcp_io_channel = 0;
+ 
+ 	if (phba->cfg_enable_fc4_type == LPFC_ENABLE_FCP)
+ 		phba->cfg_nvme_io_channel = 0;
+ 
+ 	if (phba->cfg_fcp_io_channel > phba->cfg_nvme_io_channel)
+ 		phba->io_channel_irqs = phba->cfg_fcp_io_channel;
+ 	else
+ 		phba->io_channel_irqs = phba->cfg_nvme_io_channel;
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  
  	phba->cfg_soft_wwnn = 0L;
  	phba->cfg_soft_wwpn = 0L;
diff --cc drivers/scsi/lpfc/lpfc_debugfs.c
index 389b2bc6c406,cc49850e18a9..000000000000
--- a/drivers/scsi/lpfc/lpfc_debugfs.c
+++ b/drivers/scsi/lpfc/lpfc_debugfs.c
@@@ -1988,6 -3083,201 +1988,204 @@@ error_out
  	return -EINVAL;
  }
  
++<<<<<<< HEAD
++=======
+ static int
+ __lpfc_idiag_print_wq(struct lpfc_queue *qp, char *wqtype,
+ 			char *pbuffer, int len)
+ {
+ 	if (!qp)
+ 		return len;
+ 
+ 	len += snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len,
+ 			"\t\t%s WQ info: ", wqtype);
+ 	len += snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len,
+ 			"AssocCQID[%04d]: WQ-STAT[oflow:x%x posted:x%llx]\n",
+ 			qp->assoc_qid, qp->q_cnt_1,
+ 			(unsigned long long)qp->q_cnt_4);
+ 	len += snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len,
+ 			"\t\tWQID[%02d], QE-CNT[%04d], QE-SZ[%04d], "
+ 			"HST-IDX[%04d], PRT-IDX[%04d], PST[%03d]",
+ 			qp->queue_id, qp->entry_count,
+ 			qp->entry_size, qp->host_index,
+ 			qp->hba_index, qp->entry_repost);
+ 	len +=  snprintf(pbuffer + len,
+ 			LPFC_QUE_INFO_GET_BUF_SIZE - len, "\n");
+ 	return len;
+ }
+ 
+ static int
+ lpfc_idiag_wqs_for_cq(struct lpfc_hba *phba, char *wqtype, char *pbuffer,
+ 		int *len, int max_cnt, int cq_id)
+ {
+ 	struct lpfc_queue *qp;
+ 	int qidx;
+ 
+ 	for (qidx = 0; qidx < phba->cfg_fcp_io_channel; qidx++) {
+ 		qp = phba->sli4_hba.fcp_wq[qidx];
+ 		if (qp->assoc_qid != cq_id)
+ 			continue;
+ 		*len = __lpfc_idiag_print_wq(qp, wqtype, pbuffer, *len);
+ 		if (*len >= max_cnt)
+ 			return 1;
+ 	}
+ 	for (qidx = 0; qidx < phba->cfg_nvme_io_channel; qidx++) {
+ 		qp = phba->sli4_hba.nvme_wq[qidx];
+ 		if (qp->assoc_qid != cq_id)
+ 			continue;
+ 		*len = __lpfc_idiag_print_wq(qp, wqtype, pbuffer, *len);
+ 		if (*len >= max_cnt)
+ 			return 1;
+ 	}
+ 	return 0;
+ }
+ 
+ static int
+ __lpfc_idiag_print_cq(struct lpfc_queue *qp, char *cqtype,
+ 			char *pbuffer, int len)
+ {
+ 	if (!qp)
+ 		return len;
+ 
+ 	len += snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len,
+ 			"\t%s CQ info: ", cqtype);
+ 	len += snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len,
+ 			"AssocEQID[%02d]: CQ STAT[max:x%x relw:x%x "
+ 			"xabt:x%x wq:x%llx]\n",
+ 			qp->assoc_qid, qp->q_cnt_1, qp->q_cnt_2,
+ 			qp->q_cnt_3, (unsigned long long)qp->q_cnt_4);
+ 	len += snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len,
+ 			"\tCQID[%02d], QE-CNT[%04d], QE-SZ[%04d], "
+ 			"HST-IDX[%04d], PRT-IDX[%04d], PST[%03d]",
+ 			qp->queue_id, qp->entry_count,
+ 			qp->entry_size, qp->host_index,
+ 			qp->hba_index, qp->entry_repost);
+ 
+ 	len +=  snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len, "\n");
+ 
+ 	return len;
+ }
+ 
+ static int
+ __lpfc_idiag_print_rqpair(struct lpfc_queue *qp, struct lpfc_queue *datqp,
+ 			char *rqtype, char *pbuffer, int len)
+ {
+ 	if (!qp || !datqp)
+ 		return len;
+ 
+ 	len += snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len,
+ 			"\t\t%s RQ info: ", rqtype);
+ 	len += snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len,
+ 			"AssocCQID[%02d]: RQ-STAT[nopost:x%x nobuf:x%x "
+ 			"posted:x%x rcv:x%llx]\n",
+ 			qp->assoc_qid, qp->q_cnt_1, qp->q_cnt_2,
+ 			qp->q_cnt_3, (unsigned long long)qp->q_cnt_4);
+ 	len += snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len,
+ 			"\t\tHQID[%02d], QE-CNT[%04d], QE-SZ[%04d], "
+ 			"HST-IDX[%04d], PRT-IDX[%04d], PST[%03d]\n",
+ 			qp->queue_id, qp->entry_count, qp->entry_size,
+ 			qp->host_index, qp->hba_index, qp->entry_repost);
+ 	len += snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len,
+ 			"\t\tDQID[%02d], QE-CNT[%04d], QE-SZ[%04d], "
+ 			"HST-IDX[%04d], PRT-IDX[%04d], PST[%03d]\n",
+ 			datqp->queue_id, datqp->entry_count,
+ 			datqp->entry_size, datqp->host_index,
+ 			datqp->hba_index, datqp->entry_repost);
+ 	return len;
+ }
+ 
+ static int
+ lpfc_idiag_cqs_for_eq(struct lpfc_hba *phba, char *pbuffer,
+ 		int *len, int max_cnt, int eqidx, int eq_id)
+ {
+ 	struct lpfc_queue *qp;
+ 	int qidx, rc;
+ 
+ 	for (qidx = 0; qidx < phba->cfg_fcp_io_channel; qidx++) {
+ 		qp = phba->sli4_hba.fcp_cq[qidx];
+ 		if (qp->assoc_qid != eq_id)
+ 			continue;
+ 
+ 		*len = __lpfc_idiag_print_cq(qp, "FCP", pbuffer, *len);
+ 
+ 		/* Reset max counter */
+ 		qp->CQ_max_cqe = 0;
+ 
+ 		if (*len >= max_cnt)
+ 			return 1;
+ 
+ 		rc = lpfc_idiag_wqs_for_cq(phba, "FCP", pbuffer, len,
+ 				max_cnt, qp->queue_id);
+ 		if (rc)
+ 			return 1;
+ 	}
+ 
+ 	for (qidx = 0; qidx < phba->cfg_nvme_io_channel; qidx++) {
+ 		qp = phba->sli4_hba.nvme_cq[qidx];
+ 		if (qp->assoc_qid != eq_id)
+ 			continue;
+ 
+ 		*len = __lpfc_idiag_print_cq(qp, "NVME", pbuffer, *len);
+ 
+ 		/* Reset max counter */
+ 		qp->CQ_max_cqe = 0;
+ 
+ 		if (*len >= max_cnt)
+ 			return 1;
+ 
+ 		rc = lpfc_idiag_wqs_for_cq(phba, "NVME", pbuffer, len,
+ 				max_cnt, qp->queue_id);
+ 		if (rc)
+ 			return 1;
+ 	}
+ 
+ 	if (eqidx < phba->cfg_nvmet_mrq) {
+ 		/* NVMET CQset */
+ 		qp = phba->sli4_hba.nvmet_cqset[eqidx];
+ 		*len = __lpfc_idiag_print_cq(qp, "NVMET CQset", pbuffer, *len);
+ 
+ 		/* Reset max counter */
+ 		qp->CQ_max_cqe = 0;
+ 
+ 		if (*len >= max_cnt)
+ 			return 1;
+ 
+ 		/* RQ header */
+ 		qp = phba->sli4_hba.nvmet_mrq_hdr[eqidx];
+ 		*len = __lpfc_idiag_print_rqpair(qp,
+ 				phba->sli4_hba.nvmet_mrq_data[eqidx],
+ 				"NVMET MRQ", pbuffer, *len);
+ 
+ 		if (*len >= max_cnt)
+ 			return 1;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int
+ __lpfc_idiag_print_eq(struct lpfc_queue *qp, char *eqtype,
+ 			char *pbuffer, int len)
+ {
+ 	if (!qp)
+ 		return len;
+ 
+ 	len += snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len,
+ 			"\n%s EQ info: EQ-STAT[max:x%x noE:x%x "
+ 			"bs:x%x proc:x%llx eqd %d]\n",
+ 			eqtype, qp->q_cnt_1, qp->q_cnt_2, qp->q_cnt_3,
+ 			(unsigned long long)qp->q_cnt_4, qp->q_mode);
+ 	len += snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len,
+ 			"EQID[%02d], QE-CNT[%04d], QE-SZ[%04d], "
+ 			"HST-IDX[%04d], PRT-IDX[%04d], PST[%03d]",
+ 			qp->queue_id, qp->entry_count, qp->entry_size,
+ 			qp->host_index, qp->hba_index, qp->entry_repost);
+ 	len +=  snprintf(pbuffer + len, LPFC_QUE_INFO_GET_BUF_SIZE - len, "\n");
+ 
+ 	return len;
+ }
+ 
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  /**
   * lpfc_idiag_queinfo_read - idiag debugfs read queue information
   * @file: The file pointer to read from.
diff --cc drivers/scsi/lpfc/lpfc_hw4.h
index 3567b6a0d2ee,bb4715705fa3..000000000000
--- a/drivers/scsi/lpfc/lpfc_hw4.h
+++ b/drivers/scsi/lpfc/lpfc_hw4.h
@@@ -2897,6 -3262,16 +2907,19 @@@ struct lpfc_sli4_parameters 
  #define cfg_mds_diags_SHIFT			1
  #define cfg_mds_diags_MASK			0x00000001
  #define cfg_mds_diags_WORD			word19
++<<<<<<< HEAD
++=======
+ #define cfg_nvme_SHIFT				3
+ #define cfg_nvme_MASK				0x00000001
+ #define cfg_nvme_WORD				word19
+ #define cfg_xib_SHIFT				4
+ #define cfg_xib_MASK				0x00000001
+ #define cfg_xib_WORD				word19
+ #define cfg_eqdr_SHIFT				8
+ #define cfg_eqdr_MASK				0x00000001
+ #define cfg_eqdr_WORD				word19
+ #define LPFC_NODELAY_MAX_IO		32
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  };
  
  #define LPFC_SET_UE_RECOVERY		0x10
diff --cc drivers/scsi/lpfc/lpfc_init.c
index 4d8c754a14fe,9d3a12636455..000000000000
--- a/drivers/scsi/lpfc/lpfc_init.c
+++ b/drivers/scsi/lpfc/lpfc_init.c
@@@ -8016,34 -8880,14 +8114,41 @@@ lpfc_sli4_queue_setup(struct lpfc_hba *
  		}
  	}
  
++<<<<<<< HEAD
 +	/*
 +	 * Configure EQ delay multipier for interrupt coalescing using
 +	 * MODIFY_EQ_DELAY for all EQs created, LPFC_MAX_EQ_DELAY at a time.
 +	 */
 +	for (fcp_eqidx = 0; fcp_eqidx < phba->cfg_fcp_io_channel;
 +			fcp_eqidx += LPFC_MAX_EQ_DELAY)
 +		lpfc_modify_fcp_eq_delay(phba, fcp_eqidx);
++=======
+ 	for (qidx = 0; qidx < io_channel; qidx += LPFC_MAX_EQ_DELAY_EQID_CNT)
+ 		lpfc_modify_hba_eq_delay(phba, qidx, LPFC_MAX_EQ_DELAY_EQID_CNT,
+ 					 phba->cfg_fcp_imax);
+ 
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  	return 0;
  
 -out_destroy:
 -	lpfc_sli4_queue_unset(phba);
 +out_destroy_els_rq:
 +	lpfc_rq_destroy(phba, phba->sli4_hba.hdr_rq, phba->sli4_hba.dat_rq);
 +out_destroy_els_wq:
 +	lpfc_wq_destroy(phba, phba->sli4_hba.els_wq);
 +out_destroy_mbx_wq:
 +	lpfc_mq_destroy(phba, phba->sli4_hba.mbx_wq);
 +out_destroy_els_cq:
 +	lpfc_cq_destroy(phba, phba->sli4_hba.els_cq);
 +out_destroy_mbx_cq:
 +	lpfc_cq_destroy(phba, phba->sli4_hba.mbx_cq);
 +out_destroy_fcp_wq:
 +	for (--fcp_wqidx; fcp_wqidx >= 0; fcp_wqidx--)
 +		lpfc_wq_destroy(phba, phba->sli4_hba.fcp_wq[fcp_wqidx]);
 +out_destroy_fcp_cq:
 +	for (--fcp_cqidx; fcp_cqidx >= 0; fcp_cqidx--)
 +		lpfc_cq_destroy(phba, phba->sli4_hba.fcp_cq[fcp_cqidx]);
 +out_destroy_hba_eq:
 +	for (--fcp_eqidx; fcp_eqidx >= 0; fcp_eqidx--)
 +		lpfc_eq_destroy(phba, phba->sli4_hba.hba_eq[fcp_eqidx]);
  out_error:
  	return rc;
  }
@@@ -9739,7 -10326,34 +9844,10 @@@ lpfc_get_sli4_parameters(struct lpfc_hb
  					   mbx_sli4_parameters);
  	phba->sli4_hba.extents_in_use = bf_get(cfg_ext, mbx_sli4_parameters);
  	phba->sli4_hba.rpi_hdrs_in_use = bf_get(cfg_hdrr, mbx_sli4_parameters);
 -	phba->nvme_support = (bf_get(cfg_nvme, mbx_sli4_parameters) &&
 -			      bf_get(cfg_xib, mbx_sli4_parameters));
 -
 -	if ((phba->cfg_enable_fc4_type == LPFC_ENABLE_FCP) ||
 -	    !phba->nvme_support) {
 -		phba->nvme_support = 0;
 -		phba->nvmet_support = 0;
 -		phba->cfg_nvmet_mrq = 0;
 -		phba->cfg_nvme_io_channel = 0;
 -		phba->io_channel_irqs = phba->cfg_fcp_io_channel;
 -		lpfc_printf_log(phba, KERN_ERR, LOG_INIT | LOG_NVME,
 -				"6101 Disabling NVME support: "
 -				"Not supported by firmware: %d %d\n",
 -				bf_get(cfg_nvme, mbx_sli4_parameters),
 -				bf_get(cfg_xib, mbx_sli4_parameters));
 -
 -		/* If firmware doesn't support NVME, just use SCSI support */
 -		if (!(phba->cfg_enable_fc4_type & LPFC_ENABLE_FCP))
 -			return -ENODEV;
 -		phba->cfg_enable_fc4_type = LPFC_ENABLE_FCP;
 -	}
 -
 -	if (bf_get(cfg_xib, mbx_sli4_parameters) && phba->cfg_suppress_rsp)
 -		phba->sli.sli_flag |= LPFC_SLI_SUPPRESS_RSP;
  
+ 	if (bf_get(cfg_eqdr, mbx_sli4_parameters))
+ 		phba->sli.sli_flag |= LPFC_SLI_USE_EQDR;
+ 
  	/* Make sure that sge_supp_len can be handled by the driver */
  	if (sli4_params->sge_supp_len > LPFC_MAX_SGE_SIZE)
  		sli4_params->sge_supp_len = LPFC_MAX_SGE_SIZE;
diff --cc drivers/scsi/lpfc/lpfc_sli.c
index 8324e9337564,040575adf9c6..000000000000
--- a/drivers/scsi/lpfc/lpfc_sli.c
+++ b/drivers/scsi/lpfc/lpfc_sli.c
@@@ -13077,15 -14000,16 +13077,25 @@@ lpfc_dual_chute_pci_bar_map(struct lpfc
   * fails this function will return -ENXIO.
   **/
  int
++<<<<<<< HEAD
 +lpfc_modify_fcp_eq_delay(struct lpfc_hba *phba, uint32_t startq)
++=======
+ lpfc_modify_hba_eq_delay(struct lpfc_hba *phba, uint32_t startq,
+ 			 uint32_t numq, uint32_t imax)
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  {
  	struct lpfc_mbx_modify_eq_delay *eq_delay;
  	LPFC_MBOXQ_t *mbox;
  	struct lpfc_queue *eq;
  	int cnt, rc, length, status = 0;
  	uint32_t shdr_status, shdr_add_status;
++<<<<<<< HEAD
 +	uint32_t result;
 +	int fcp_eqidx;
++=======
+ 	uint32_t result, val;
+ 	int qidx;
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  	union lpfc_sli4_cfg_shdr *shdr;
  	uint16_t dmult;
  
@@@ -13103,23 -14027,45 +13113,55 @@@
  	eq_delay = &mbox->u.mqe.un.eq_delay;
  
  	/* Calculate delay multiper from maximum interrupt per second */
++<<<<<<< HEAD
 +	result = phba->cfg_fcp_imax / phba->cfg_fcp_io_channel;
 +	if (result > LPFC_DMULT_CONST)
++=======
+ 	result = imax / phba->io_channel_irqs;
+ 	if (result > LPFC_DMULT_CONST || result == 0)
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  		dmult = 0;
  	else
  		dmult = LPFC_DMULT_CONST/result - 1;
+ 	if (dmult > LPFC_DMULT_MAX)
+ 		dmult = LPFC_DMULT_MAX;
  
  	cnt = 0;
 -	for (qidx = startq; qidx < phba->io_channel_irqs; qidx++) {
 -		eq = phba->sli4_hba.hba_eq[qidx];
 +	for (fcp_eqidx = startq; fcp_eqidx < phba->cfg_fcp_io_channel;
 +	    fcp_eqidx++) {
 +		eq = phba->sli4_hba.hba_eq[fcp_eqidx];
  		if (!eq)
  			continue;
+ 		eq->q_mode = imax;
  		eq_delay->u.request.eq[cnt].eq_id = eq->queue_id;
  		eq_delay->u.request.eq[cnt].phase = 0;
  		eq_delay->u.request.eq[cnt].delay_multi = dmult;
  		cnt++;
++<<<<<<< HEAD
 +		if (cnt >= LPFC_MAX_EQ_DELAY)
++=======
+ 
+ 		/* q_mode is only used for auto_imax */
+ 		if (phba->sli.sli_flag & LPFC_SLI_USE_EQDR) {
+ 			/* Use EQ Delay Register method for q_mode */
+ 
+ 			/* Convert for EQ Delay register */
+ 			val =  phba->cfg_fcp_imax;
+ 			if (val) {
+ 				/* First, interrupts per sec per EQ */
+ 				val = phba->cfg_fcp_imax /
+ 					phba->io_channel_irqs;
+ 
+ 				/* us delay between each interrupt */
+ 				val = LPFC_SEC_TO_USEC / val;
+ 			}
+ 			eq->q_mode = val;
+ 		} else {
+ 			eq->q_mode = imax;
+ 		}
+ 
+ 		if (cnt >= numq)
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  			break;
  	}
  	eq_delay->u.request.num_eq = cnt;
diff --cc drivers/scsi/lpfc/lpfc_sli.h
index 74227a28bd56,a3b1b5145d2b..000000000000
--- a/drivers/scsi/lpfc/lpfc_sli.h
+++ b/drivers/scsi/lpfc/lpfc_sli.h
@@@ -297,12 -320,10 +297,17 @@@ struct lpfc_sli 
  #define LPFC_BLOCK_MGMT_IO        0x800	/* Don't allow mgmt mbx or iocb cmds */
  #define LPFC_MENLO_MAINT          0x1000 /* need for menl fw download */
  #define LPFC_SLI_ASYNC_MBX_BLK    0x2000 /* Async mailbox is blocked */
++<<<<<<< HEAD
++=======
+ #define LPFC_SLI_SUPPRESS_RSP     0x4000 /* Suppress RSP feature is supported */
+ #define LPFC_SLI_USE_EQDR         0x8000 /* EQ Delay Register is supported */
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
 +
 +	struct lpfc_sli_ring *ring;
 +	int fcp_ring;		/* ring used for FCP initiator commands */
 +	int next_ring;
  
 -	struct lpfc_sli_ring *sli3_ring;
 +	int extra_ring;		/* extra ring used for other protocols */
  
  	struct lpfc_sli_stat slistat;	/* SLI statistical info */
  	struct list_head mboxq;
diff --cc drivers/scsi/lpfc/lpfc_sli4.h
index 10078254ebc7,830dc83b9c21..000000000000
--- a/drivers/scsi/lpfc/lpfc_sli4.h
+++ b/drivers/scsi/lpfc/lpfc_sli4.h
@@@ -143,7 -166,9 +143,11 @@@ struct lpfc_queue 
  	uint32_t hba_index;	/* The last known hba index for get or put */
  
  	struct lpfc_sli_ring *pring; /* ptr to io ring associated with q */
 -	struct lpfc_rqb *rqbp;	/* ptr to RQ buffers */
  
++<<<<<<< HEAD
++=======
+ 	uint32_t q_mode;
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  	uint16_t db_format;
  #define LPFC_DB_RING_FORMAT	0x01
  #define LPFC_DB_LIST_FORMAT	0x02
@@@ -695,9 -756,13 +700,14 @@@ struct lpfc_queue *lpfc_sli4_queue_allo
  			uint32_t);
  void lpfc_sli4_queue_free(struct lpfc_queue *);
  int lpfc_eq_create(struct lpfc_hba *, struct lpfc_queue *, uint32_t);
++<<<<<<< HEAD
 +int lpfc_modify_fcp_eq_delay(struct lpfc_hba *, uint32_t);
++=======
+ int lpfc_modify_hba_eq_delay(struct lpfc_hba *phba, uint32_t startq,
+ 			     uint32_t numq, uint32_t imax);
++>>>>>>> 0cf07f84dd32 (scsi: lpfc: Add auto EQ delay logic)
  int lpfc_cq_create(struct lpfc_hba *, struct lpfc_queue *,
  			struct lpfc_queue *, uint32_t, uint32_t);
 -int lpfc_cq_create_set(struct lpfc_hba *phba, struct lpfc_queue **cqp,
 -			struct lpfc_queue **eqp, uint32_t type,
 -			uint32_t subtype);
  int32_t lpfc_mq_create(struct lpfc_hba *, struct lpfc_queue *,
  		       struct lpfc_queue *, uint32_t);
  int lpfc_wq_create(struct lpfc_hba *, struct lpfc_queue *,
diff --git a/drivers/scsi/lpfc/lpfc.h b/drivers/scsi/lpfc/lpfc.h
index 61c6751c0584..daf9419ecfea 100644
--- a/drivers/scsi/lpfc/lpfc.h
+++ b/drivers/scsi/lpfc/lpfc.h
@@ -704,6 +704,7 @@ struct lpfc_hba {
 	uint32_t RandomData[7];
 	uint8_t  fcp_embed_io;
 	uint8_t  mds_diags_support;
+	uint32_t initial_imax;
 
 	/* HBA Config Parameters */
 	uint32_t cfg_ack0;
@@ -726,6 +727,7 @@ struct lpfc_hba {
 	uint32_t cfg_poll_tmo;
 	uint32_t cfg_task_mgmt_tmo;
 	uint32_t cfg_use_msi;
+	uint32_t cfg_auto_imax;
 	uint32_t cfg_fcp_imax;
 	uint32_t cfg_fcp_cpu_map;
 	uint32_t cfg_fcp_io_channel;
@@ -961,6 +963,7 @@ struct lpfc_hba {
 
 	uint8_t temp_sensor_support;
 	/* Fields used for heart beat. */
+	unsigned long last_eqdelay_time;
 	unsigned long last_completion_time;
 	unsigned long skipped_hb;
 	struct timer_list hb_tmofunc;
* Unmerged path drivers/scsi/lpfc/lpfc_attr.c
* Unmerged path drivers/scsi/lpfc/lpfc_debugfs.c
* Unmerged path drivers/scsi/lpfc/lpfc_hw4.h
* Unmerged path drivers/scsi/lpfc/lpfc_init.c
* Unmerged path drivers/scsi/lpfc/lpfc_sli.c
* Unmerged path drivers/scsi/lpfc/lpfc_sli.h
* Unmerged path drivers/scsi/lpfc/lpfc_sli4.h
