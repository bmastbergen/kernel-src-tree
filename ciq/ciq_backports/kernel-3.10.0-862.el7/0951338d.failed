nvme: allow timed-out ios to retry

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [nvme] allow timed-out ios to retry (Ewan Milne) [1503181]
Rebuild_FUZZ: 90.32%
commit-author James Smart <jsmart2021@gmail.com>
commit 0951338d9677f546e230685d68631dfd3f81cca5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/0951338d.failed

Currently the nvme_req_needs_retry() applies several checks to see if
a retry is allowed. On of those is whether the current time has exceeded
the start time of the io plus the timeout length. This check, if an io
times out, means there is never a retry allowed for the io. Which means
applications see the io failure.

Remove this check and allow the io to timeout, like it does on other
protocols, and retries to be made.

On the FC transport, a frame can be lost for an individual io, and there
may be no other errors that escalate for the connection/association.
The io will timeout, which causes the transport to escalate into creating
a new association, but the io that timed out, due to this retry logic, has
already failed back to the application and things are hosed.

	Signed-off-by: James Smart <james.smart@broadcom.com>
	Reviewed-by: Keith Busch <keith.busch@intel.com>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 0951338d9677f546e230685d68631dfd3f81cca5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/core.c
diff --cc drivers/nvme/host/core.c
index 8a3c06e0bcb2,5589f67d2cd8..000000000000
--- a/drivers/nvme/host/core.c
+++ b/drivers/nvme/host/core.c
@@@ -61,6 -76,81 +61,84 @@@ static DEFINE_SPINLOCK(dev_list_lock)
  
  static struct class *nvme_class;
  
++<<<<<<< HEAD
++=======
+ static __le32 nvme_get_log_dw10(u8 lid, size_t size)
+ {
+ 	return cpu_to_le32((((size / 4) - 1) << 16) | lid);
+ }
+ 
+ int nvme_reset_ctrl(struct nvme_ctrl *ctrl)
+ {
+ 	if (!nvme_change_ctrl_state(ctrl, NVME_CTRL_RESETTING))
+ 		return -EBUSY;
+ 	if (!queue_work(nvme_wq, &ctrl->reset_work))
+ 		return -EBUSY;
+ 	return 0;
+ }
+ EXPORT_SYMBOL_GPL(nvme_reset_ctrl);
+ 
+ static int nvme_reset_ctrl_sync(struct nvme_ctrl *ctrl)
+ {
+ 	int ret;
+ 
+ 	ret = nvme_reset_ctrl(ctrl);
+ 	if (!ret)
+ 		flush_work(&ctrl->reset_work);
+ 	return ret;
+ }
+ 
+ static blk_status_t nvme_error_status(struct request *req)
+ {
+ 	switch (nvme_req(req)->status & 0x7ff) {
+ 	case NVME_SC_SUCCESS:
+ 		return BLK_STS_OK;
+ 	case NVME_SC_CAP_EXCEEDED:
+ 		return BLK_STS_NOSPC;
+ 	case NVME_SC_ONCS_NOT_SUPPORTED:
+ 		return BLK_STS_NOTSUPP;
+ 	case NVME_SC_WRITE_FAULT:
+ 	case NVME_SC_READ_ERROR:
+ 	case NVME_SC_UNWRITTEN_BLOCK:
+ 	case NVME_SC_ACCESS_DENIED:
+ 	case NVME_SC_READ_ONLY:
+ 		return BLK_STS_MEDIUM;
+ 	case NVME_SC_GUARD_CHECK:
+ 	case NVME_SC_APPTAG_CHECK:
+ 	case NVME_SC_REFTAG_CHECK:
+ 	case NVME_SC_INVALID_PI:
+ 		return BLK_STS_PROTECTION;
+ 	case NVME_SC_RESERVATION_CONFLICT:
+ 		return BLK_STS_NEXUS;
+ 	default:
+ 		return BLK_STS_IOERR;
+ 	}
+ }
+ 
+ static inline bool nvme_req_needs_retry(struct request *req)
+ {
+ 	if (blk_noretry_request(req))
+ 		return false;
+ 	if (nvme_req(req)->status & NVME_SC_DNR)
+ 		return false;
+ 	if (nvme_req(req)->retries >= nvme_max_retries)
+ 		return false;
+ 	return true;
+ }
+ 
+ void nvme_complete_rq(struct request *req)
+ {
+ 	if (unlikely(nvme_req(req)->status && nvme_req_needs_retry(req))) {
+ 		nvme_req(req)->retries++;
+ 		blk_mq_requeue_request(req, true);
+ 		return;
+ 	}
+ 
+ 	blk_mq_end_request(req, nvme_error_status(req));
+ }
+ EXPORT_SYMBOL_GPL(nvme_complete_rq);
+ 
++>>>>>>> 0951338d9677 (nvme: allow timed-out ios to retry)
  void nvme_cancel_request(struct request *req, void *data, bool reserved)
  {
  	int status;
* Unmerged path drivers/nvme/host/core.c
