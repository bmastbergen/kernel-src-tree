mlx4: reduce rx ring page_cache size

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Eric Dumazet <edumazet@google.com>
commit acd7628de05c73118aab7ae4847a5b5b2c6999c9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/acd7628d.failed

We only need to store the page and dma address.

	Signed-off-by: Eric Dumazet <edumazet@google.com>
	Acked-by: Tariq Toukan <tariqt@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit acd7628de05c73118aab7ae4847a5b5b2c6999c9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx4/en_rx.c
#	drivers/net/ethernet/mellanox/mlx4/en_tx.c
diff --cc drivers/net/ethernet/mellanox/mlx4/en_rx.c
index 984f22166c89,453313d404e3..000000000000
--- a/drivers/net/ethernet/mellanox/mlx4/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx4/en_rx.c
@@@ -247,8 -250,12 +247,17 @@@ static int mlx4_en_prepare_rx_desc(stru
  					(index << priv->log_rx_info);
  
  	if (ring->page_cache.index > 0) {
++<<<<<<< HEAD
 +		frags[0] = ring->page_cache.buf[--ring->page_cache.index];
 +		rx_desc->data[0].addr = cpu_to_be64(frags[0].dma);
++=======
+ 		ring->page_cache.index--;
+ 		frags[0].page = ring->page_cache.buf[ring->page_cache.index].page;
+ 		frags[0].dma  = ring->page_cache.buf[ring->page_cache.index].dma;
+ 		frags[0].page_offset = XDP_PACKET_HEADROOM;
+ 		rx_desc->data[0].addr = cpu_to_be64(frags[0].dma +
+ 						    frags[0].page_offset);
++>>>>>>> acd7628de05c (mlx4: reduce rx ring page_cache size)
  		return 0;
  	}
  
@@@ -557,11 -572,9 +568,17 @@@ void mlx4_en_deactivate_rx_ring(struct 
  	int i;
  
  	for (i = 0; i < ring->page_cache.index; i++) {
++<<<<<<< HEAD
 +		struct mlx4_en_rx_alloc *frame = &ring->page_cache.buf[i];
 +
 +		dma_unmap_page(priv->ddev, frame->dma, frame->page_size,
 +			       priv->frag_info[0].dma_dir);
 +		put_page(frame->page);
++=======
+ 		dma_unmap_page(priv->ddev, ring->page_cache.buf[i].dma,
+ 			       PAGE_SIZE, priv->dma_dir);
+ 		put_page(ring->page_cache.buf[i].page);
++>>>>>>> acd7628de05c (mlx4: reduce rx ring page_cache size)
  	}
  	ring->page_cache.index = 0;
  	mlx4_en_free_rx_buf(priv, ring);
diff --cc drivers/net/ethernet/mellanox/mlx4/en_tx.c
index df6a060edf95,e0c5ffb3e3a6..000000000000
--- a/drivers/net/ethernet/mellanox/mlx4/en_tx.c
+++ b/drivers/net/ethernet/mellanox/mlx4/en_tx.c
@@@ -344,6 -345,25 +344,28 @@@ static u32 mlx4_en_free_tx_desc(struct 
  	return tx_info->nr_txbb;
  }
  
++<<<<<<< HEAD
++=======
+ u32 mlx4_en_recycle_tx_desc(struct mlx4_en_priv *priv,
+ 			    struct mlx4_en_tx_ring *ring,
+ 			    int index, u8 owner, u64 timestamp,
+ 			    int napi_mode)
+ {
+ 	struct mlx4_en_tx_info *tx_info = &ring->tx_info[index];
+ 	struct mlx4_en_rx_alloc frame = {
+ 		.page = tx_info->page,
+ 		.dma = tx_info->map0_dma,
+ 	};
+ 
+ 	if (!mlx4_en_rx_recycle(ring->recycle_ring, &frame)) {
+ 		dma_unmap_page(priv->ddev, tx_info->map0_dma,
+ 			       PAGE_SIZE, priv->dma_dir);
+ 		put_page(tx_info->page);
+ 	}
+ 
+ 	return tx_info->nr_txbb;
+ }
++>>>>>>> acd7628de05c (mlx4: reduce rx ring page_cache size)
  
  int mlx4_en_free_tx_buf(struct net_device *dev, struct mlx4_en_tx_ring *ring)
  {
* Unmerged path drivers/net/ethernet/mellanox/mlx4/en_rx.c
* Unmerged path drivers/net/ethernet/mellanox/mlx4/en_tx.c
diff --git a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d8f46d99701e..5fbcdd2e54eb 100644
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@ -269,9 +269,13 @@ struct mlx4_en_rx_alloc {
 };
 
 #define MLX4_EN_CACHE_SIZE (2 * NAPI_POLL_WEIGHT)
+
 struct mlx4_en_page_cache {
 	u32 index;
-	struct mlx4_en_rx_alloc buf[MLX4_EN_CACHE_SIZE];
+	struct {
+		struct page	*page;
+		dma_addr_t	dma;
+	} buf[MLX4_EN_CACHE_SIZE];
 };
 
 struct mlx4_en_priv;
