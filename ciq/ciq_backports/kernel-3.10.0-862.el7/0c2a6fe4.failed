blk-mq: don't special case flush inserts for blk-mq-sched

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Jens Axboe <axboe@fb.com>
commit 0c2a6fe4dc3e8c24bc67cd5d0a36092834027cf0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/0c2a6fe4.failed

The current request insertion machinery works just fine for
directly inserting flushes, so no need to special case
this anymore.

	Signed-off-by: Jens Axboe <axboe@fb.com>
	Reviewed-by: Omar Sandoval <osandov@fb.com>
(cherry picked from commit 0c2a6fe4dc3e8c24bc67cd5d0a36092834027cf0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq.c
diff --cc block/blk-mq.c
index 3e6f9b3d2b64,ee8c6f9f1d4d..000000000000
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@@ -1401,19 -1406,36 +1401,24 @@@ static void blk_mq_make_request(struct 
  	blk_queue_bounce(q, &bio);
  
  	if (bio_integrity_enabled(bio) && bio_integrity_prep(bio)) {
 -		bio_io_error(bio);
 -		return BLK_QC_T_NONE;
 +		bio_endio(bio, -EIO);
 +		return;
  	}
  
 -	blk_queue_split(q, &bio, q->bio_split);
 -
  	if (!is_flush_fua && !blk_queue_nomerges(q) &&
  	    blk_attempt_plug_merge(q, bio, &request_count, &same_queue_rq))
 -		return BLK_QC_T_NONE;
 -
 -	if (blk_mq_sched_bio_merge(q, bio))
 -		return BLK_QC_T_NONE;
 -
 -	wb_acct = wbt_wait(q->rq_wb, bio, NULL);
 -
 -	trace_block_getrq(q, bio, bio->bi_opf);
 -
 -	rq = blk_mq_sched_get_request(q, bio, bio->bi_opf, &data);
 -	if (unlikely(!rq)) {
 -		__wbt_done(q->rq_wb, wb_acct);
 -		return BLK_QC_T_NONE;
 -	}
 -
 -	wbt_track(&rq->issue_stat, wb_acct);
 +		return;
  
 -	cookie = request_to_qc_t(data.hctx, rq);
 +	rq = blk_mq_map_request(q, bio, &data);
 +	if (unlikely(!rq))
 +		return;
  
  	if (unlikely(is_flush_fua)) {
++<<<<<<< HEAD
++=======
+ 		if (q->elevator)
+ 			goto elv_insert;
++>>>>>>> 0c2a6fe4dc3e (blk-mq: don't special case flush inserts for blk-mq-sched)
  		blk_mq_bio_to_request(rq, bio);
  		blk_insert_flush(rq);
  		goto run_queue;
@@@ -1459,12 -1481,20 +1464,23 @@@
  			rcu_read_unlock();
  		} else {
  			srcu_idx = srcu_read_lock(&data.hctx->queue_rq_srcu);
 -			blk_mq_try_issue_directly(old_rq, &cookie);
 +			blk_mq_try_issue_directly(old_rq);
  			srcu_read_unlock(&data.hctx->queue_rq_srcu, srcu_idx);
  		}
 -		goto done;
 +		return;
  	}
  
++<<<<<<< HEAD
++=======
+ 	if (q->elevator) {
+ elv_insert:
+ 		blk_mq_put_ctx(data.ctx);
+ 		blk_mq_bio_to_request(rq, bio);
+ 		blk_mq_sched_insert_request(rq, false, true,
+ 						!is_sync || is_flush_fua, true);
+ 		goto done;
+ 	}
++>>>>>>> 0c2a6fe4dc3e (blk-mq: don't special case flush inserts for blk-mq-sched)
  	if (!blk_mq_merge_queue_io(data.hctx, data.ctx, rq, bio)) {
  		/*
  		 * For a SYNC request, send it to the hardware immediately. For
@@@ -1494,19 -1528,38 +1510,24 @@@ static void blk_sq_make_request(struct 
  	blk_queue_bounce(q, &bio);
  
  	if (bio_integrity_enabled(bio) && bio_integrity_prep(bio)) {
 -		bio_io_error(bio);
 -		return BLK_QC_T_NONE;
 -	}
 -
 -	blk_queue_split(q, &bio, q->bio_split);
 -
 -	if (!is_flush_fua && !blk_queue_nomerges(q)) {
 -		if (blk_attempt_plug_merge(q, bio, &request_count, NULL))
 -			return BLK_QC_T_NONE;
 -	} else
 -		request_count = blk_plug_queued_count(q);
 -
 -	if (blk_mq_sched_bio_merge(q, bio))
 -		return BLK_QC_T_NONE;
 -
 -	wb_acct = wbt_wait(q->rq_wb, bio, NULL);
 -
 -	trace_block_getrq(q, bio, bio->bi_opf);
 -
 -	rq = blk_mq_sched_get_request(q, bio, bio->bi_opf, &data);
 -	if (unlikely(!rq)) {
 -		__wbt_done(q->rq_wb, wb_acct);
 -		return BLK_QC_T_NONE;
 +		bio_endio(bio, -EIO);
 +		return;
  	}
  
 -	wbt_track(&rq->issue_stat, wb_acct);
 +	if (!is_flush_fua && !blk_queue_nomerges(q) &&
 +	    blk_attempt_plug_merge(q, bio, &request_count, NULL))
 +		return;
  
 -	cookie = request_to_qc_t(data.hctx, rq);
 +	rq = blk_mq_map_request(q, bio, &data);
 +	if (unlikely(!rq))
 +		return;
  
  	if (unlikely(is_flush_fua)) {
++<<<<<<< HEAD
++=======
+ 		if (q->elevator)
+ 			goto elv_insert;
++>>>>>>> 0c2a6fe4dc3e (blk-mq: don't special case flush inserts for blk-mq-sched)
  		blk_mq_bio_to_request(rq, bio);
  		blk_insert_flush(rq);
  		goto run_queue;
@@@ -1531,9 -1596,17 +1552,20 @@@
  		}
  
  		list_add_tail(&rq->queuelist, &plug->mq_list);
 -		return cookie;
 +		return;
  	}
  
++<<<<<<< HEAD
++=======
+ 	if (q->elevator) {
+ elv_insert:
+ 		blk_mq_put_ctx(data.ctx);
+ 		blk_mq_bio_to_request(rq, bio);
+ 		blk_mq_sched_insert_request(rq, false, true,
+ 						!is_sync || is_flush_fua, true);
+ 		goto done;
+ 	}
++>>>>>>> 0c2a6fe4dc3e (blk-mq: don't special case flush inserts for blk-mq-sched)
  	if (!blk_mq_merge_queue_io(data.hctx, data.ctx, rq, bio)) {
  		/*
  		 * For a SYNC request, send it to the hardware immediately. For
* Unmerged path block/blk-mq.c
