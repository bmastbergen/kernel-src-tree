xfs: include an allocfree res for inobt modifications

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Brian Foster <bfoster@redhat.com>
commit f03c78f39710995d2766236f229295d91b8de9dd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/f03c78f3.failed

Analysis of recent reports of log reservation overruns and code
inspection has uncovered that the reservations associated with inode
operations may not cover the worst case scenarios. In particular,
many cases only include one allocfree res. for a particular
operation even though said operations may also entail AGFL fixups
and inode btree block allocations in addition to the actual inode
chunk allocation. This can easily turn into two or three block
allocations (or frees) per operation.

In theory, the only way to define the worst case reservation is to
include an allocfree res for each individual allocation in a
transaction. Since that is impractical (we can perform multiple agfl
fixups per tx and not every allocation results in a full tree
operation), we need to find a reasonable compromise that addresses
the deficiency in practice without blowing out the size of the
transactions.

Since the inode btrees are not filled by the AGFL, record insertion
and removal can directly result in block allocations and frees
depending on the shape of the tree. These allocations and frees
occur in the same transaction context as the inobt update itself,
but are separate from the allocation/free that might be required for
an inode chunk. Therefore, it makes sense to assume that an [f]inobt
insert/remove can directly result in one or more block allocations
on behalf of the tree.

Refactor the inode transaction reservations to include one allocfree
res. per inode btree modification to cover allocations required by
the tree itself. This separates the reservation required to allocate
the inode chunk from the reservation required for inobt record
insertion/removal. Apply the same logic to the finobt. This results
in killing off the finobt modify condition because we no longer
assume that the broader transaction reservation will cover finobt
block allocations and finobt shape changes can occur in either of
the inobt allocation or modify situations.

	Suggested-by: Dave Chinner <david@fromorbit.com>
	Signed-off-by: Brian Foster <bfoster@redhat.com>
	Reviewed-by: Dave Chinner <dchinner@redhat.com>
	Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
	Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
(cherry picked from commit f03c78f39710995d2766236f229295d91b8de9dd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/libxfs/xfs_trans_resv.c
diff --cc fs/xfs/libxfs/xfs_trans_resv.c
index 1b754cb1e8ae,19f3a226a357..000000000000
--- a/fs/xfs/libxfs/xfs_trans_resv.c
+++ b/fs/xfs/libxfs/xfs_trans_resv.c
@@@ -126,23 -163,12 +136,29 @@@ xfs_calc_inobt_res
   */
  STATIC uint
  xfs_calc_finobt_res(
++<<<<<<< HEAD
 +	struct xfs_mount 	*mp,
 +	int			alloc,
 +	int			modify)
++=======
+ 	struct xfs_mount	*mp)
++>>>>>>> f03c78f39710 (xfs: include an allocfree res for inobt modifications)
  {
- 	uint res;
- 
  	if (!xfs_sb_version_hasfinobt(&mp->m_sb))
  		return 0;
  
++<<<<<<< HEAD
 +	res = xfs_calc_buf_res(mp->m_in_maxlevels, XFS_FSB_TO_B(mp, 1));
 +	if (alloc)
 +		res += xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(mp, 1), 
 +					XFS_FSB_TO_B(mp, 1));
 +	if (modify)
 +		res += (uint)XFS_FSB_TO_B(mp, 1);
 +
 +	return res;
++=======
+ 	return xfs_calc_inobt_res(mp);
++>>>>>>> f03c78f39710 (xfs: include an allocfree res for inobt modifications)
  }
  
  /*
@@@ -370,9 -390,9 +386,15 @@@ xfs_calc_create_resv_alloc
  	return xfs_calc_buf_res(2, mp->m_sb.sb_sectsize) +
  		mp->m_sb.sb_sectsize +
  		xfs_calc_buf_res(mp->m_ialloc_blks, XFS_FSB_TO_B(mp, 1)) +
++<<<<<<< HEAD
 +		xfs_calc_buf_res(mp->m_in_maxlevels, XFS_FSB_TO_B(mp, 1)) +
 +		xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(mp, 1),
 +				 XFS_FSB_TO_B(mp, 1));
++=======
+ 		xfs_calc_buf_res(xfs_allocfree_log_count(mp, 1),
+ 				 XFS_FSB_TO_B(mp, 1)) +
+ 		xfs_calc_inobt_res(mp);
++>>>>>>> f03c78f39710 (xfs: include an allocfree res for inobt modifications)
  }
  
  STATIC uint
@@@ -398,10 -418,10 +420,15 @@@ xfs_calc_icreate_resv_alloc
  {
  	return xfs_calc_buf_res(2, mp->m_sb.sb_sectsize) +
  		mp->m_sb.sb_sectsize +
++<<<<<<< HEAD
 +		xfs_calc_buf_res(mp->m_in_maxlevels, XFS_FSB_TO_B(mp, 1)) +
 +		xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(mp, 1),
++=======
+ 		xfs_calc_buf_res(xfs_allocfree_log_count(mp, 1),
++>>>>>>> f03c78f39710 (xfs: include an allocfree res for inobt modifications)
  				 XFS_FSB_TO_B(mp, 1)) +
- 		xfs_calc_finobt_res(mp, 0, 0);
+ 		xfs_calc_inobt_res(mp) +
+ 		xfs_calc_finobt_res(mp);
  }
  
  STATIC uint
@@@ -463,13 -483,17 +490,26 @@@ xfs_calc_symlink_reservation
  /*
   * In freeing an inode we can modify:
   *    the inode being freed: inode size
++<<<<<<< HEAD
 + *    the super block free inode counter: sector size
 + *    the agi hash list and counters: sector size
 + *    the inode btree entry: block size
 + *    the on disk inode before ours in the agi hash list: inode cluster size
 + *    the inode btree: max depth * blocksize
 + *    the allocation btrees: 2 trees * (max depth - 1) * block size
++=======
+  *    the super block free inode counter, AGF and AGFL: sector size
+  *    the on disk inode (agi unlinked list removal)
+  *    the inode chunk is marked stale (headers only)
+  *    the inode btree
++>>>>>>> f03c78f39710 (xfs: include an allocfree res for inobt modifications)
   *    the finobt (record insertion, removal or modification)
+  *
+  * Note that the allocfree res. for the inode chunk itself is not included
+  * because the extent free occurs after a transaction roll. We could take the
+  * maximum of the pre/post roll operations, but the pre-roll reservation already
+  * includes at least one allocfree res. for the inobt and is thus guaranteed to
+  * be larger.
   */
  STATIC uint
  xfs_calc_ifree_reservation(
@@@ -477,15 -501,11 +517,21 @@@
  {
  	return XFS_DQUOT_LOGRES(mp) +
  		xfs_calc_inode_res(mp, 1) +
 -		xfs_calc_buf_res(3, mp->m_sb.sb_sectsize) +
 +		xfs_calc_buf_res(1, mp->m_sb.sb_sectsize) +
 +		xfs_calc_buf_res(1, XFS_FSB_TO_B(mp, 1)) +
  		xfs_calc_iunlink_remove_reservation(mp) +
++<<<<<<< HEAD
 +		xfs_calc_buf_res(1, 0) +
 +		xfs_calc_buf_res(2 + mp->m_ialloc_blks +
 +				 mp->m_in_maxlevels, 0) +
 +		xfs_calc_buf_res(XFS_ALLOCFREE_LOG_COUNT(mp, 1),
 +				 XFS_FSB_TO_B(mp, 1)) +
 +		xfs_calc_finobt_res(mp, 0, 1);
++=======
+ 		xfs_calc_buf_res(mp->m_ialloc_blks, 0) +
+ 		xfs_calc_inobt_res(mp) +
+ 		xfs_calc_finobt_res(mp);
++>>>>>>> f03c78f39710 (xfs: include an allocfree res for inobt modifications)
  }
  
  /*
* Unmerged path fs/xfs/libxfs/xfs_trans_resv.c
