IB/CM: Create appropriate path records when handling CM request

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
commit 6b3c0e6e6d5abfefb0112cd450e0aee97fcab7a8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/6b3c0e6e.failed

When handling an incoming conection request, ib_cm creates
either an IB or an OPA path record based on the gid field
in the request.

	Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
	Reviewed-by: Don Hiatt <don.hiatt@intel.com>
	Reviewed-by: Ira Weiny <ira.weiny@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 6b3c0e6e6d5abfefb0112cd450e0aee97fcab7a8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/cm.c
diff --cc drivers/infiniband/core/cm.c
index 70c24aef631d,4d870a0c2955..000000000000
--- a/drivers/infiniband/core/cm.c
+++ b/drivers/infiniband/core/cm.c
@@@ -1400,15 -1428,31 +1400,30 @@@ static inline int cm_is_active_peer(__b
  		 (be32_to_cpu(local_qpn) > be32_to_cpu(remote_qpn))));
  }
  
+ static bool cm_req_has_alt_path(struct cm_req_msg *req_msg)
+ {
+ 	return ((req_msg->alt_local_lid) ||
+ 		(ib_is_opa_gid(&req_msg->alt_local_gid)));
+ }
+ 
+ static void cm_path_set_rec_type(struct ib_device *ib_device, u8 port_num,
+ 				 struct sa_path_rec *path, union ib_gid *gid)
+ {
+ 	if (ib_is_opa_gid(gid) && rdma_cap_opa_ah(ib_device, port_num))
+ 		path->rec_type = SA_PATH_REC_TYPE_OPA;
+ 	else
+ 		path->rec_type = SA_PATH_REC_TYPE_IB;
+ }
+ 
  static void cm_format_paths_from_req(struct cm_req_msg *req_msg,
 -				     struct sa_path_rec *primary_path,
 -				     struct sa_path_rec *alt_path)
 +					    struct ib_sa_path_rec *primary_path,
 +					    struct ib_sa_path_rec *alt_path)
  {
 +	memset(primary_path, 0, sizeof(*primary_path));
  	primary_path->dgid = req_msg->primary_local_gid;
  	primary_path->sgid = req_msg->primary_remote_gid;
 -	sa_path_set_dlid(primary_path,
 -			 htonl(ntohs(req_msg->primary_local_lid)));
 -	sa_path_set_slid(primary_path,
 -			 htonl(ntohs(req_msg->primary_remote_lid)));
 +	primary_path->dlid = req_msg->primary_local_lid;
 +	primary_path->slid = req_msg->primary_remote_lid;
  	primary_path->flow_label = cm_req_get_primary_flow_label(req_msg);
  	primary_path->hop_limit = req_msg->primary_hop_limit;
  	primary_path->traffic_class = req_msg->primary_traffic_class;
@@@ -1768,11 -1814,27 +1783,28 @@@ static int cm_req_handler(struct cm_wor
  				&gid, &gid_attr);
  	if (!ret) {
  		if (gid_attr.ndev) {
 -			work->path[0].rec_type =
 -				sa_conv_gid_to_pathrec_type(gid_attr.gid_type);
 -			sa_path_set_ifindex(&work->path[0],
 -					    gid_attr.ndev->ifindex);
 -			sa_path_set_ndev(&work->path[0],
 -					 dev_net(gid_attr.ndev));
 +			work->path[0].ifindex = gid_attr.ndev->ifindex;
 +			work->path[0].net = dev_net(gid_attr.ndev);
  			dev_put(gid_attr.ndev);
++<<<<<<< HEAD
 +		}
 +		work->path[0].gid_type = gid_attr.gid_type;
++=======
+ 		} else {
+ 			cm_path_set_rec_type(work->port->cm_dev->ib_device,
+ 					     work->port->port_num,
+ 					     &work->path[0],
+ 					     &req_msg->primary_local_gid);
+ 		}
+ 		if (cm_req_has_alt_path(req_msg))
+ 			work->path[1].rec_type = work->path[0].rec_type;
+ 		cm_format_paths_from_req(req_msg, &work->path[0],
+ 					 &work->path[1]);
+ 		if (cm_id_priv->av.ah_attr.type == RDMA_AH_ATTR_TYPE_ROCE)
+ 			sa_path_set_dmac(&work->path[0],
+ 					 cm_id_priv->av.ah_attr.roce.dmac);
+ 		work->path[0].hop_limit = grh->hop_limit;
++>>>>>>> 6b3c0e6e6d5a (IB/CM: Create appropriate path records when handling CM request)
  		ret = cm_init_av_by_path(&work->path[0], &cm_id_priv->av,
  					 cm_id_priv);
  	}
@@@ -1782,11 -1844,21 +1814,22 @@@
  					    &work->path[0].sgid,
  					    &gid_attr);
  		if (!err && gid_attr.ndev) {
 -			work->path[0].rec_type =
 -				sa_conv_gid_to_pathrec_type(gid_attr.gid_type);
 -			sa_path_set_ifindex(&work->path[0],
 -					    gid_attr.ndev->ifindex);
 -			sa_path_set_ndev(&work->path[0],
 -					 dev_net(gid_attr.ndev));
 +			work->path[0].ifindex = gid_attr.ndev->ifindex;
 +			work->path[0].net = dev_net(gid_attr.ndev);
  			dev_put(gid_attr.ndev);
++<<<<<<< HEAD
 +		}
 +		work->path[0].gid_type = gid_attr.gid_type;
++=======
+ 		} else {
+ 			cm_path_set_rec_type(work->port->cm_dev->ib_device,
+ 					     work->port->port_num,
+ 					     &work->path[0],
+ 					     &req_msg->primary_local_gid);
+ 		}
+ 		if (cm_req_has_alt_path(req_msg))
+ 			work->path[1].rec_type = work->path[0].rec_type;
++>>>>>>> 6b3c0e6e6d5a (IB/CM: Create appropriate path records when handling CM request)
  		ib_send_cm_rej(cm_id, IB_CM_REJ_INVALID_GID,
  			       &work->path[0].sgid, sizeof work->path[0].sgid,
  			       NULL, 0);
@@@ -2895,14 -2980,13 +2938,17 @@@ out:	spin_unlock_irqrestore(&cm_id_priv
  EXPORT_SYMBOL(ib_send_cm_lap);
  
  static void cm_format_path_from_lap(struct cm_id_private *cm_id_priv,
 -				    struct sa_path_rec *path,
 +				    struct ib_sa_path_rec *path,
  				    struct cm_lap_msg *lap_msg)
  {
++<<<<<<< HEAD
 +	memset(path, 0, sizeof *path);
++=======
++>>>>>>> 6b3c0e6e6d5a (IB/CM: Create appropriate path records when handling CM request)
  	path->dgid = lap_msg->alt_local_gid;
  	path->sgid = lap_msg->alt_remote_gid;
 -	sa_path_set_dlid(path, htonl(ntohs(lap_msg->alt_local_lid)));
 -	sa_path_set_slid(path, htonl(ntohs(lap_msg->alt_remote_lid)));
 +	path->dlid = lap_msg->alt_local_lid;
 +	path->slid = lap_msg->alt_remote_lid;
  	path->flow_label = cm_lap_get_flow_label(lap_msg);
  	path->hop_limit = lap_msg->alt_hop_limit;
  	path->traffic_class = cm_lap_get_traffic_class(lap_msg);
* Unmerged path drivers/infiniband/core/cm.c
