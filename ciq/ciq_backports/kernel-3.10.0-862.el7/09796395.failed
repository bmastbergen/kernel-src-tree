mm: add follow_pte_pmd()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [mm] add follow_pte_pmd() (Larry Woodman) [1457572]
Rebuild_FUZZ: 90.91%
commit-author Ross Zwisler <ross.zwisler@linux.intel.com>
commit 097963959594c5eccaba42510f7033f703211bda
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/09796395.failed

Patch series "Write protect DAX PMDs in *sync path".

Currently dax_mapping_entry_mkclean() fails to clean and write protect
the pmd_t of a DAX PMD entry during an *sync operation.  This can result
in data loss, as detailed in patch 2.

This series is based on Dan's "libnvdimm-pending" branch, which is the
current home for Jan's "dax: Page invalidation fixes" series.  You can
find a working tree here:

  https://git.kernel.org/cgit/linux/kernel/git/zwisler/linux.git/log/?h=dax_pmd_clean

This patch (of 2):

Similar to follow_pte(), follow_pte_pmd() allows either a PTE leaf or a
huge page PMD leaf to be found and returned.

Link: http://lkml.kernel.org/r/1482272586-21177-2-git-send-email-ross.zwisler@linux.intel.com
	Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
	Suggested-by: Dave Hansen <dave.hansen@intel.com>
	Cc: Alexander Viro <viro@zeniv.linux.org.uk>
	Cc: Christoph Hellwig <hch@lst.de>
	Cc: Dan Williams <dan.j.williams@intel.com>
	Cc: Dave Chinner <david@fromorbit.com>
	Cc: Jan Kara <jack@suse.cz>
	Cc: Matthew Wilcox <mawilcox@microsoft.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 097963959594c5eccaba42510f7033f703211bda)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/memory.c
diff --cc mm/memory.c
index 14270187456b,b62f3bc63481..000000000000
--- a/mm/memory.c
+++ b/mm/memory.c
@@@ -3442,46 -3772,8 +3442,51 @@@ int __pmd_alloc(struct mm_struct *mm, p
  }
  #endif /* __PAGETABLE_PMD_FOLDED */
  
++<<<<<<< HEAD
 +#if !defined(__HAVE_ARCH_GATE_AREA)
 +
 +#if defined(AT_SYSINFO_EHDR)
 +static struct vm_area_struct gate_vma;
 +
 +static int __init gate_vma_init(void)
 +{
 +	gate_vma.vm_mm = NULL;
 +	gate_vma.vm_start = FIXADDR_USER_START;
 +	gate_vma.vm_end = FIXADDR_USER_END;
 +	gate_vma.vm_flags = VM_READ | VM_MAYREAD | VM_EXEC | VM_MAYEXEC;
 +	gate_vma.vm_page_prot = __P101;
 +
 +	return 0;
 +}
 +__initcall(gate_vma_init);
 +#endif
 +
 +struct vm_area_struct *get_gate_vma(struct mm_struct *mm)
 +{
 +#ifdef AT_SYSINFO_EHDR
 +	return &gate_vma;
 +#else
 +	return NULL;
 +#endif
 +}
 +
 +int in_gate_area_no_mm(unsigned long addr)
 +{
 +#ifdef AT_SYSINFO_EHDR
 +	if ((addr >= FIXADDR_USER_START) && (addr < FIXADDR_USER_END))
 +		return 1;
 +#endif
 +	return 0;
 +}
 +
 +#endif	/* __HAVE_ARCH_GATE_AREA */
 +
 +static int __follow_pte(struct mm_struct *mm, unsigned long address,
 +		pte_t **ptepp, spinlock_t **ptlp)
++=======
+ static int __follow_pte_pmd(struct mm_struct *mm, unsigned long address,
+ 		pte_t **ptepp, pmd_t **pmdpp, spinlock_t **ptlp)
++>>>>>>> 097963959594 (mm: add follow_pte_pmd())
  {
  	pgd_t *pgd;
  	pud_t *pud;
diff --git a/include/linux/mm.h b/include/linux/mm.h
index 3416fff96060..838b1022e446 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -1222,6 +1222,8 @@ void unmap_mapping_range(struct address_space *mapping,
 		loff_t const holebegin, loff_t const holelen, int even_cows);
 int follow_pte(struct mm_struct *mm, unsigned long address, pte_t **ptepp,
 	       spinlock_t **ptlp);
+int follow_pte_pmd(struct mm_struct *mm, unsigned long address,
+			     pte_t **ptepp, pmd_t **pmdpp, spinlock_t **ptlp);
 int follow_pfn(struct vm_area_struct *vma, unsigned long address,
 	unsigned long *pfn);
 int follow_phys(struct vm_area_struct *vma, unsigned long address,
* Unmerged path mm/memory.c
