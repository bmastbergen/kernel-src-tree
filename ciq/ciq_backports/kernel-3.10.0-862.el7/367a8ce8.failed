net_sched: only create filter chains for new filters/actions

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author WANG Cong <xiyou.wangcong@gmail.com>
commit 367a8ce896f14018cc2c6cf2681aa440fff274f4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/367a8ce8.failed

tcf_chain_get() always creates a new filter chain if not found
in existing ones. This is totally unnecessary when we get or
delete filters, new chain should be only created for new filters
(or new actions).

Fixes: 5bc1701881e3 ("net: sched: introduce multichain support for filters")
	Cc: Jamal Hadi Salim <jhs@mojatatu.com>
	Cc: Jiri Pirko <jiri@mellanox.com>
	Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 367a8ce896f14018cc2c6cf2681aa440fff274f4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/pkt_cls.h
#	net/sched/act_api.c
#	net/sched/cls_api.c
diff --cc include/net/pkt_cls.h
index ddbf01b80b4c,f7762295b7b8..000000000000
--- a/include/net/pkt_cls.h
+++ b/include/net/pkt_cls.h
@@@ -17,6 -17,35 +17,38 @@@ struct tcf_walker 
  int register_tcf_proto_ops(struct tcf_proto_ops *ops);
  int unregister_tcf_proto_ops(struct tcf_proto_ops *ops);
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_NET_CLS
+ struct tcf_chain *tcf_chain_get(struct tcf_block *block, u32 chain_index,
+ 				bool create);
+ void tcf_chain_put(struct tcf_chain *chain);
+ int tcf_block_get(struct tcf_block **p_block,
+ 		  struct tcf_proto __rcu **p_filter_chain);
+ void tcf_block_put(struct tcf_block *block);
+ int tcf_classify(struct sk_buff *skb, const struct tcf_proto *tp,
+ 		 struct tcf_result *res, bool compat_mode);
+ 
+ #else
+ static inline
+ int tcf_block_get(struct tcf_block **p_block,
+ 		  struct tcf_proto __rcu **p_filter_chain)
+ {
+ 	return 0;
+ }
+ 
+ static inline void tcf_block_put(struct tcf_block *block)
+ {
+ }
+ 
+ static inline int tcf_classify(struct sk_buff *skb, const struct tcf_proto *tp,
+ 			       struct tcf_result *res, bool compat_mode)
+ {
+ 	return TC_ACT_UNSPEC;
+ }
+ #endif
+ 
++>>>>>>> 367a8ce896f1 (net_sched: only create filter chains for new filters/actions)
  static inline unsigned long
  __cls_set_class(unsigned long *clp, unsigned long cl)
  {
diff --cc net/sched/act_api.c
index 19022d7219af,aed6cf2e9fd8..000000000000
--- a/net/sched/act_api.c
+++ b/net/sched/act_api.c
@@@ -28,9 -28,34 +28,37 @@@
  #include <net/act_api.h>
  #include <net/netlink.h>
  
++<<<<<<< HEAD
++=======
+ static int tcf_action_goto_chain_init(struct tc_action *a, struct tcf_proto *tp)
+ {
+ 	u32 chain_index = a->tcfa_action & TC_ACT_EXT_VAL_MASK;
+ 
+ 	if (!tp)
+ 		return -EINVAL;
+ 	a->goto_chain = tcf_chain_get(tp->chain->block, chain_index, true);
+ 	if (!a->goto_chain)
+ 		return -ENOMEM;
+ 	return 0;
+ }
+ 
+ static void tcf_action_goto_chain_fini(struct tc_action *a)
+ {
+ 	tcf_chain_put(a->goto_chain);
+ }
+ 
+ static void tcf_action_goto_chain_exec(const struct tc_action *a,
+ 				       struct tcf_result *res)
+ {
+ 	const struct tcf_chain *chain = a->goto_chain;
+ 
+ 	res->goto_tp = rcu_dereference_bh(chain->filter_chain);
+ }
+ 
++>>>>>>> 367a8ce896f1 (net_sched: only create filter chains for new filters/actions)
  static void free_tcf(struct rcu_head *head)
  {
 -	struct tc_action *p = container_of(head, struct tc_action, tcfa_rcu);
 +	struct tcf_common *p = container_of(head, struct tcf_common, tcfc_rcu);
  
  	free_percpu(p->cpu_bstats);
  	free_percpu(p->cpu_qstats);
diff --cc net/sched/cls_api.c
index 1dc6d123ed94,39da0c5801c9..000000000000
--- a/net/sched/cls_api.c
+++ b/net/sched/cls_api.c
@@@ -124,7 -124,287 +124,291 @@@ static inline u32 tcf_auto_prio(struct 
  	if (tp)
  		first = tp->prio - 1;
  
++<<<<<<< HEAD
 +	return first;
++=======
+ 	return TC_H_MAJ(first);
+ }
+ 
+ static struct tcf_proto *tcf_proto_create(const char *kind, u32 protocol,
+ 					  u32 prio, u32 parent, struct Qdisc *q,
+ 					  struct tcf_chain *chain)
+ {
+ 	struct tcf_proto *tp;
+ 	int err;
+ 
+ 	tp = kzalloc(sizeof(*tp), GFP_KERNEL);
+ 	if (!tp)
+ 		return ERR_PTR(-ENOBUFS);
+ 
+ 	err = -ENOENT;
+ 	tp->ops = tcf_proto_lookup_ops(kind);
+ 	if (!tp->ops) {
+ #ifdef CONFIG_MODULES
+ 		rtnl_unlock();
+ 		request_module("cls_%s", kind);
+ 		rtnl_lock();
+ 		tp->ops = tcf_proto_lookup_ops(kind);
+ 		/* We dropped the RTNL semaphore in order to perform
+ 		 * the module load. So, even if we succeeded in loading
+ 		 * the module we have to replay the request. We indicate
+ 		 * this using -EAGAIN.
+ 		 */
+ 		if (tp->ops) {
+ 			module_put(tp->ops->owner);
+ 			err = -EAGAIN;
+ 		} else {
+ 			err = -ENOENT;
+ 		}
+ 		goto errout;
+ #endif
+ 	}
+ 	tp->classify = tp->ops->classify;
+ 	tp->protocol = protocol;
+ 	tp->prio = prio;
+ 	tp->classid = parent;
+ 	tp->q = q;
+ 	tp->chain = chain;
+ 
+ 	err = tp->ops->init(tp);
+ 	if (err) {
+ 		module_put(tp->ops->owner);
+ 		goto errout;
+ 	}
+ 	return tp;
+ 
+ errout:
+ 	kfree(tp);
+ 	return ERR_PTR(err);
+ }
+ 
+ static void tcf_proto_destroy(struct tcf_proto *tp)
+ {
+ 	tp->ops->destroy(tp);
+ 	module_put(tp->ops->owner);
+ 	kfree_rcu(tp, rcu);
+ }
+ 
+ static struct tcf_chain *tcf_chain_create(struct tcf_block *block,
+ 					  u32 chain_index)
+ {
+ 	struct tcf_chain *chain;
+ 
+ 	chain = kzalloc(sizeof(*chain), GFP_KERNEL);
+ 	if (!chain)
+ 		return NULL;
+ 	list_add_tail(&chain->list, &block->chain_list);
+ 	chain->block = block;
+ 	chain->index = chain_index;
+ 	chain->refcnt = 1;
+ 	return chain;
+ }
+ 
+ static void tcf_chain_flush(struct tcf_chain *chain)
+ {
+ 	struct tcf_proto *tp;
+ 
+ 	if (*chain->p_filter_chain)
+ 		RCU_INIT_POINTER(*chain->p_filter_chain, NULL);
+ 	while ((tp = rtnl_dereference(chain->filter_chain)) != NULL) {
+ 		RCU_INIT_POINTER(chain->filter_chain, tp->next);
+ 		tcf_proto_destroy(tp);
+ 	}
+ }
+ 
+ static void tcf_chain_destroy(struct tcf_chain *chain)
+ {
+ 	list_del(&chain->list);
+ 	tcf_chain_flush(chain);
+ 	kfree(chain);
+ }
+ 
+ struct tcf_chain *tcf_chain_get(struct tcf_block *block, u32 chain_index,
+ 				bool create)
+ {
+ 	struct tcf_chain *chain;
+ 
+ 	list_for_each_entry(chain, &block->chain_list, list) {
+ 		if (chain->index == chain_index) {
+ 			chain->refcnt++;
+ 			return chain;
+ 		}
+ 	}
+ 	if (create)
+ 		return tcf_chain_create(block, chain_index);
+ 	else
+ 		return NULL;
+ }
+ EXPORT_SYMBOL(tcf_chain_get);
+ 
+ void tcf_chain_put(struct tcf_chain *chain)
+ {
+ 	/* Destroy unused chain, with exception of chain 0, which is the
+ 	 * default one and has to be always present.
+ 	 */
+ 	if (--chain->refcnt == 0 && !chain->filter_chain && chain->index != 0)
+ 		tcf_chain_destroy(chain);
+ }
+ EXPORT_SYMBOL(tcf_chain_put);
+ 
+ static void
+ tcf_chain_filter_chain_ptr_set(struct tcf_chain *chain,
+ 			       struct tcf_proto __rcu **p_filter_chain)
+ {
+ 	chain->p_filter_chain = p_filter_chain;
+ }
+ 
+ int tcf_block_get(struct tcf_block **p_block,
+ 		  struct tcf_proto __rcu **p_filter_chain)
+ {
+ 	struct tcf_block *block = kzalloc(sizeof(*block), GFP_KERNEL);
+ 	struct tcf_chain *chain;
+ 	int err;
+ 
+ 	if (!block)
+ 		return -ENOMEM;
+ 	INIT_LIST_HEAD(&block->chain_list);
+ 	/* Create chain 0 by default, it has to be always present. */
+ 	chain = tcf_chain_create(block, 0);
+ 	if (!chain) {
+ 		err = -ENOMEM;
+ 		goto err_chain_create;
+ 	}
+ 	tcf_chain_filter_chain_ptr_set(chain, p_filter_chain);
+ 	*p_block = block;
+ 	return 0;
+ 
+ err_chain_create:
+ 	kfree(block);
+ 	return err;
+ }
+ EXPORT_SYMBOL(tcf_block_get);
+ 
+ void tcf_block_put(struct tcf_block *block)
+ {
+ 	struct tcf_chain *chain, *tmp;
+ 
+ 	if (!block)
+ 		return;
+ 
+ 	list_for_each_entry_safe(chain, tmp, &block->chain_list, list)
+ 		tcf_chain_destroy(chain);
+ 	kfree(block);
+ }
+ EXPORT_SYMBOL(tcf_block_put);
+ 
+ /* Main classifier routine: scans classifier chain attached
+  * to this qdisc, (optionally) tests for protocol and asks
+  * specific classifiers.
+  */
+ int tcf_classify(struct sk_buff *skb, const struct tcf_proto *tp,
+ 		 struct tcf_result *res, bool compat_mode)
+ {
+ 	__be16 protocol = tc_skb_protocol(skb);
+ #ifdef CONFIG_NET_CLS_ACT
+ 	const int max_reclassify_loop = 4;
+ 	const struct tcf_proto *orig_tp = tp;
+ 	const struct tcf_proto *first_tp;
+ 	int limit = 0;
+ 
+ reclassify:
+ #endif
+ 	for (; tp; tp = rcu_dereference_bh(tp->next)) {
+ 		int err;
+ 
+ 		if (tp->protocol != protocol &&
+ 		    tp->protocol != htons(ETH_P_ALL))
+ 			continue;
+ 
+ 		err = tp->classify(skb, tp, res);
+ #ifdef CONFIG_NET_CLS_ACT
+ 		if (unlikely(err == TC_ACT_RECLASSIFY && !compat_mode)) {
+ 			first_tp = orig_tp;
+ 			goto reset;
+ 		} else if (unlikely(TC_ACT_EXT_CMP(err, TC_ACT_GOTO_CHAIN))) {
+ 			first_tp = res->goto_tp;
+ 			goto reset;
+ 		}
+ #endif
+ 		if (err >= 0)
+ 			return err;
+ 	}
+ 
+ 	return TC_ACT_UNSPEC; /* signal: continue lookup */
+ #ifdef CONFIG_NET_CLS_ACT
+ reset:
+ 	if (unlikely(limit++ >= max_reclassify_loop)) {
+ 		net_notice_ratelimited("%s: reclassify loop, rule prio %u, protocol %02x\n",
+ 				       tp->q->ops->id, tp->prio & 0xffff,
+ 				       ntohs(tp->protocol));
+ 		return TC_ACT_SHOT;
+ 	}
+ 
+ 	tp = first_tp;
+ 	protocol = tc_skb_protocol(skb);
+ 	goto reclassify;
+ #endif
+ }
+ EXPORT_SYMBOL(tcf_classify);
+ 
+ struct tcf_chain_info {
+ 	struct tcf_proto __rcu **pprev;
+ 	struct tcf_proto __rcu *next;
+ };
+ 
+ static struct tcf_proto *tcf_chain_tp_prev(struct tcf_chain_info *chain_info)
+ {
+ 	return rtnl_dereference(*chain_info->pprev);
+ }
+ 
+ static void tcf_chain_tp_insert(struct tcf_chain *chain,
+ 				struct tcf_chain_info *chain_info,
+ 				struct tcf_proto *tp)
+ {
+ 	if (chain->p_filter_chain &&
+ 	    *chain_info->pprev == chain->filter_chain)
+ 		rcu_assign_pointer(*chain->p_filter_chain, tp);
+ 	RCU_INIT_POINTER(tp->next, tcf_chain_tp_prev(chain_info));
+ 	rcu_assign_pointer(*chain_info->pprev, tp);
+ }
+ 
+ static void tcf_chain_tp_remove(struct tcf_chain *chain,
+ 				struct tcf_chain_info *chain_info,
+ 				struct tcf_proto *tp)
+ {
+ 	struct tcf_proto *next = rtnl_dereference(chain_info->next);
+ 
+ 	if (chain->p_filter_chain && tp == chain->filter_chain)
+ 		RCU_INIT_POINTER(*chain->p_filter_chain, next);
+ 	RCU_INIT_POINTER(*chain_info->pprev, next);
+ }
+ 
+ static struct tcf_proto *tcf_chain_tp_find(struct tcf_chain *chain,
+ 					   struct tcf_chain_info *chain_info,
+ 					   u32 protocol, u32 prio,
+ 					   bool prio_allocate)
+ {
+ 	struct tcf_proto **pprev;
+ 	struct tcf_proto *tp;
+ 
+ 	/* Check the chain for existence of proto-tcf with this priority */
+ 	for (pprev = &chain->filter_chain;
+ 	     (tp = rtnl_dereference(*pprev)); pprev = &tp->next) {
+ 		if (tp->prio >= prio) {
+ 			if (tp->prio == prio) {
+ 				if (prio_allocate ||
+ 				    (tp->protocol != protocol && protocol))
+ 					return ERR_PTR(-EINVAL);
+ 			} else {
+ 				tp = NULL;
+ 			}
+ 			break;
+ 		}
+ 	}
+ 	chain_info->pprev = pprev;
+ 	chain_info->next = tp ? tp->next : NULL;
+ 	return tp;
++>>>>>>> 367a8ce896f1 (net_sched: only create filter chains for new filters/actions)
  }
  
  /* Add/change/delete/get a filter node */
@@@ -221,13 -504,27 +505,30 @@@ replay
  	}
  
  	/* And the last stroke */
 -	block = cops->tcf_block(q, cl);
 -	if (!block) {
 -		err = -EINVAL;
 +	chain = cops->tcf_chain(q, cl);
 +	err = -EINVAL;
 +	if (chain == NULL)
  		goto errout;
++<<<<<<< HEAD
++=======
+ 	}
+ 
+ 	chain_index = tca[TCA_CHAIN] ? nla_get_u32(tca[TCA_CHAIN]) : 0;
+ 	if (chain_index > TC_ACT_EXT_VAL_MASK) {
+ 		err = -EINVAL;
+ 		goto errout;
+ 	}
+ 	chain = tcf_chain_get(block, chain_index,
+ 			      n->nlmsg_type == RTM_NEWTFILTER);
+ 	if (!chain) {
+ 		err = n->nlmsg_type == RTM_NEWTFILTER ? -ENOMEM : -EINVAL;
+ 		goto errout;
+ 	}
+ 
++>>>>>>> 367a8ce896f1 (net_sched: only create filter chains for new filters/actions)
  	if (n->nlmsg_type == RTM_DELTFILTER && prio == 0) {
  		tfilter_notify_chain(net, skb, n, chain, RTM_DELTFILTER);
 -		tcf_chain_flush(chain);
 +		tcf_destroy_chain(chain);
  		err = 0;
  		goto errout;
  	}
* Unmerged path include/net/pkt_cls.h
* Unmerged path net/sched/act_api.c
* Unmerged path net/sched/cls_api.c
