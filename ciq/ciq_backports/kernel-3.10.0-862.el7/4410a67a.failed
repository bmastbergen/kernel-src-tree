Fix nvme initiator handling when not enabled.

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [scsi] Fix nvme initiator handling when not enabled (Dick Kennedy) [1385844 1461977 1387768]
Rebuild_FUZZ: 98.88%
commit-author James Smart <jsmart2021@gmail.com>
commit 4410a67a9e53d3cf8d1b88169c642d91f1292fb2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/4410a67a.failed

Fix nvme initiator handline when CONFIG_LPFC_NVME_INITIATOR is not enabled.

With update nvme upstream driver sources, loading
the driver with nvme enabled resulting in this Oops.

 BUG: unable to handle kernel NULL pointer dereference at 0000000000000018
 IP: lpfc_nvme_update_localport+0x23/0xd0 [lpfc]
 PGD 0
 Oops: 0000 [#1] SMP
 CPU: 0 PID: 10256 Comm: lpfc_worker_0 Tainted
 Hardware name: ...
 task: ffff881028191c40 task.stack: ffff880ffdf00000
 RIP: 0010:lpfc_nvme_update_localport+0x23/0xd0 [lpfc]
 RSP: 0018:ffff880ffdf03c20 EFLAGS: 00010202

Cause: As the initiator driver completes discovery at different stages,
it call lpfc_nvme_update_localport to hint that the DID and role may have
changed.  In the implementation of lpfc_nvme_update_localport, the driver
was not validating the localport or the lport during the execution
of the update_localport routine.  With the recent upstream additions to
the driver, the create_localport routine didn't run and so the localport
was NULL causing the page-fault Oops.

Fix: Add the CONFIG_LPFC_NVME_INITIATOR preprocessor inclusions to
lpfc_nvme_update_localport to turn off all routine processing when
the running kernel does not have NVME configured.  Add NULL pointer
checks on the localport and lport in lpfc_nvme_update_localport and
dump messages if they are NULL and just exit.
Also one alingment issue fixed.
Repalces the ifdef with the IS_ENABLED macro.

	Signed-off-by: Dick Kennedy <dick.kennedy@broadcom.com>
	Signed-off-by: James Smart <james.smart@broadcom.com>
	Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
(cherry picked from commit 4410a67a9e53d3cf8d1b88169c642d91f1292fb2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/lpfc/lpfc_attr.c
#	drivers/scsi/lpfc/lpfc_nvme.c
diff --cc drivers/scsi/lpfc/lpfc_attr.c
index d6e33d236a19,4b32d021f7d9..000000000000
--- a/drivers/scsi/lpfc/lpfc_attr.c
+++ b/drivers/scsi/lpfc/lpfc_attr.c
@@@ -3032,6 -3285,59 +3032,62 @@@ static DEVICE_ATTR(lpfc_devloss_tmo, S_
  		   lpfc_devloss_tmo_show, lpfc_devloss_tmo_store);
  
  /*
++<<<<<<< HEAD
++=======
+  * lpfc_suppress_rsp: Enable suppress rsp feature is firmware supports it
+  * lpfc_suppress_rsp = 0  Disable
+  * lpfc_suppress_rsp = 1  Enable (default)
+  *
+  */
+ LPFC_ATTR_R(suppress_rsp, 1, 0, 1,
+ 	    "Enable suppress rsp feature is firmware supports it");
+ 
+ /*
+  * lpfc_nvmet_mrq: Specify number of RQ pairs for processing NVMET cmds
+  * lpfc_nvmet_mrq = 1  use a single RQ pair
+  * lpfc_nvmet_mrq >= 2  use specified RQ pairs for MRQ
+  *
+  */
+ LPFC_ATTR_R(nvmet_mrq,
+ 	    1, 1, 16,
+ 	    "Specify number of RQ pairs for processing NVMET cmds");
+ 
+ /*
+  * lpfc_nvmet_mrq_post: Specify number buffers to post on every MRQ
+  *
+  */
+ LPFC_ATTR_R(nvmet_mrq_post, LPFC_DEF_MRQ_POST,
+ 	    LPFC_MIN_MRQ_POST, LPFC_MAX_MRQ_POST,
+ 	    "Specify number of buffers to post on every MRQ");
+ 
+ /*
+  * lpfc_enable_fc4_type: Defines what FC4 types are supported.
+  * Supported Values:  1 - register just FCP
+  *                    3 - register both FCP and NVME
+  * Supported values are [1,3]. Default value is 1
+  */
+ LPFC_ATTR_R(enable_fc4_type, LPFC_ENABLE_FCP,
+ 	    LPFC_ENABLE_FCP, LPFC_ENABLE_BOTH,
+ 	    "Define fc4 type to register with fabric.");
+ 
+ /*
+  * lpfc_xri_split: Defines the division of XRI resources between SCSI and NVME
+  * This parameter is only used if:
+  *     lpfc_enable_fc4_type is 3 - register both FCP and NVME and
+  *     port is not configured for NVMET.
+  *
+  * ELS/CT always get 10% of XRIs, up to a maximum of 250
+  * The remaining XRIs get split up based on lpfc_xri_split per port:
+  *
+  * Supported Values are in percentages
+  * the xri_split value is the percentage the SCSI port will get. The remaining
+  * percentage will go to NVME.
+  */
+ LPFC_ATTR_R(xri_split, 50, 10, 90,
+ 	    "Division of XRI resources between SCSI and NVME");
+ 
+ /*
++>>>>>>> 4410a67a9e53 (Fix nvme initiator handling when not enabled.)
  # lpfc_log_verbose: Only turn this flag on if you are willing to risk being
  # deluged with LOTS of information.
  # You can set a bit mask to record specific types of verbose messages:
* Unmerged path drivers/scsi/lpfc/lpfc_nvme.c
* Unmerged path drivers/scsi/lpfc/lpfc_attr.c
* Unmerged path drivers/scsi/lpfc/lpfc_nvme.c
