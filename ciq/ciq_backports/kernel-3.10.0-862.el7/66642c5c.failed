xfs: take the ilock shared if possible in xfs_file_iomap_begin

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Christoph Hellwig <hch@lst.de>
commit 66642c5c1dea411dd2842159f9f297ce8e914994
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/66642c5c.failed

We always just read the extent first, and will later lock exlusively
after first dropping the lock in case we actually allocate blocks.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Dave Chinner <dchinner@redhat.com>
	Signed-off-by: Dave Chinner <david@fromorbit.com>

(cherry picked from commit 66642c5c1dea411dd2842159f9f297ce8e914994)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/xfs_iomap.c
diff --cc fs/xfs/xfs_iomap.c
index 2f3719461cbd,fe4a26d752d0..000000000000
--- a/fs/xfs/xfs_iomap.c
+++ b/fs/xfs/xfs_iomap.c
@@@ -942,28 -934,187 +942,114 @@@ error_on_bmapi_transaction
  	return error;
  }
  
++<<<<<<< HEAD
 +void
 +xfs_bmbt_to_iomap(
++=======
+ static inline bool imap_needs_alloc(struct xfs_bmbt_irec *imap, int nimaps)
+ {
+ 	return !nimaps ||
+ 		imap->br_startblock == HOLESTARTBLOCK ||
+ 		imap->br_startblock == DELAYSTARTBLOCK;
+ }
+ 
+ static int
+ xfs_file_iomap_begin(
+ 	struct inode		*inode,
+ 	loff_t			offset,
+ 	loff_t			length,
+ 	unsigned		flags,
+ 	struct iomap		*iomap)
+ {
+ 	struct xfs_inode	*ip = XFS_I(inode);
+ 	struct xfs_mount	*mp = ip->i_mount;
+ 	struct xfs_bmbt_irec	imap;
+ 	xfs_fileoff_t		offset_fsb, end_fsb;
+ 	int			nimaps = 1, error = 0;
+ 	unsigned		lockmode;
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		return -EIO;
+ 
+ 	if ((flags & IOMAP_WRITE) && !xfs_get_extsz_hint(ip)) {
+ 		return xfs_file_iomap_begin_delay(inode, offset, length, flags,
+ 				iomap);
+ 	}
+ 
+ 	lockmode = xfs_ilock_data_map_shared(ip);
+ 
+ 	ASSERT(offset <= mp->m_super->s_maxbytes);
+ 	if ((xfs_fsize_t)offset + length > mp->m_super->s_maxbytes)
+ 		length = mp->m_super->s_maxbytes - offset;
+ 	offset_fsb = XFS_B_TO_FSBT(mp, offset);
+ 	end_fsb = XFS_B_TO_FSB(mp, offset + length);
+ 
+ 	error = xfs_bmapi_read(ip, offset_fsb, end_fsb - offset_fsb, &imap,
+ 			       &nimaps, XFS_BMAPI_ENTIRE);
+ 	if (error) {
+ 		xfs_iunlock(ip, lockmode);
+ 		return error;
+ 	}
+ 
+ 	if ((flags & IOMAP_WRITE) && imap_needs_alloc(&imap, nimaps)) {
+ 		/*
+ 		 * We cap the maximum length we map here to MAX_WRITEBACK_PAGES
+ 		 * pages to keep the chunks of work done where somewhat symmetric
+ 		 * with the work writeback does. This is a completely arbitrary
+ 		 * number pulled out of thin air as a best guess for initial
+ 		 * testing.
+ 		 *
+ 		 * Note that the values needs to be less than 32-bits wide until
+ 		 * the lower level functions are updated.
+ 		 */
+ 		length = min_t(loff_t, length, 1024 * PAGE_SIZE);
+ 		/*
+ 		 * xfs_iomap_write_direct() expects the shared lock. It
+ 		 * is unlocked on return.
+ 		 */
+ 		if (lockmode == XFS_ILOCK_EXCL)
+ 			xfs_ilock_demote(ip, lockmode);
+ 		error = xfs_iomap_write_direct(ip, offset, length, &imap,
+ 				nimaps);
+ 		if (error)
+ 			return error;
+ 
+ 		iomap->flags = IOMAP_F_NEW;
+ 		trace_xfs_iomap_alloc(ip, offset, length, 0, &imap);
+ 	} else {
+ 		ASSERT(nimaps);
+ 
+ 		xfs_iunlock(ip, lockmode);
+ 		trace_xfs_iomap_found(ip, offset, length, 0, &imap);
+ 	}
+ 
+ 	xfs_bmbt_to_iomap(ip, iomap, &imap);
+ 	return 0;
+ }
+ 
+ static int
+ xfs_file_iomap_end_delalloc(
++>>>>>>> 66642c5c1dea (xfs: take the ilock shared if possible in xfs_file_iomap_begin)
  	struct xfs_inode	*ip,
 -	loff_t			offset,
 -	loff_t			length,
 -	ssize_t			written)
 -{
 -	struct xfs_mount	*mp = ip->i_mount;
 -	xfs_fileoff_t		start_fsb;
 -	xfs_fileoff_t		end_fsb;
 -	int			error = 0;
 -
 -	start_fsb = XFS_B_TO_FSB(mp, offset + written);
 -	end_fsb = XFS_B_TO_FSB(mp, offset + length);
 -
 -	/*
 -	 * Trim back delalloc blocks if we didn't manage to write the whole
 -	 * range reserved.
 -	 *
 -	 * We don't need to care about racing delalloc as we hold i_mutex
 -	 * across the reserve/allocate/unreserve calls. If there are delalloc
 -	 * blocks in the range, they are ours.
 -	 */
 -	if (start_fsb < end_fsb) {
 -		xfs_ilock(ip, XFS_ILOCK_EXCL);
 -		error = xfs_bmap_punch_delalloc_range(ip, start_fsb,
 -					       end_fsb - start_fsb);
 -		xfs_iunlock(ip, XFS_ILOCK_EXCL);
 -
 -		if (error && !XFS_FORCED_SHUTDOWN(mp)) {
 -			xfs_alert(mp, "%s: unable to clean up ino %lld",
 -				__func__, ip->i_ino);
 -			return error;
 -		}
 -	}
 -
 -	return 0;
 -}
 -
 -static int
 -xfs_file_iomap_end(
 -	struct inode		*inode,
 -	loff_t			offset,
 -	loff_t			length,
 -	ssize_t			written,
 -	unsigned		flags,
 -	struct iomap		*iomap)
 -{
 -	if ((flags & IOMAP_WRITE) && iomap->type == IOMAP_DELALLOC)
 -		return xfs_file_iomap_end_delalloc(XFS_I(inode), offset,
 -				length, written);
 -	return 0;
 -}
 -
 -struct iomap_ops xfs_iomap_ops = {
 -	.iomap_begin		= xfs_file_iomap_begin,
 -	.iomap_end		= xfs_file_iomap_end,
 -};
 -
 -static int
 -xfs_xattr_iomap_begin(
 -	struct inode		*inode,
 -	loff_t			offset,
 -	loff_t			length,
 -	unsigned		flags,
 -	struct iomap		*iomap)
 +	struct iomap		*iomap,
 +	struct xfs_bmbt_irec	*imap)
  {
 -	struct xfs_inode	*ip = XFS_I(inode);
  	struct xfs_mount	*mp = ip->i_mount;
 -	xfs_fileoff_t		offset_fsb = XFS_B_TO_FSBT(mp, offset);
 -	xfs_fileoff_t		end_fsb = XFS_B_TO_FSB(mp, offset + length);
 -	struct xfs_bmbt_irec	imap;
 -	int			nimaps = 1, error = 0;
 -	unsigned		lockmode;
 -
 -	if (XFS_FORCED_SHUTDOWN(mp))
 -		return -EIO;
 -
 -	lockmode = xfs_ilock_data_map_shared(ip);
 -
 -	/* if there are no attribute fork or extents, return ENOENT */
 -	if (XFS_IFORK_Q(ip) || !ip->i_d.di_anextents) {
 -		error = -ENOENT;
 -		goto out_unlock;
 -	}
 -
 -	ASSERT(ip->i_d.di_aformat != XFS_DINODE_FMT_LOCAL);
 -	error = xfs_bmapi_read(ip, offset_fsb, end_fsb - offset_fsb, &imap,
 -			       &nimaps, XFS_BMAPI_ENTIRE | XFS_BMAPI_ATTRFORK);
 -out_unlock:
 -	xfs_iunlock(ip, lockmode);
  
 -	if (!error) {
 -		ASSERT(nimaps);
 -		xfs_bmbt_to_iomap(ip, iomap, &imap);
 +	if (imap->br_startblock == HOLESTARTBLOCK) {
 +		iomap->blkno = IOMAP_NULL_BLOCK;
 +		iomap->type = IOMAP_HOLE;
 +	} else if (imap->br_startblock == DELAYSTARTBLOCK) {
 +		iomap->blkno = IOMAP_NULL_BLOCK;
 +		iomap->type = IOMAP_DELALLOC;
 +	} else {
 +		iomap->blkno = xfs_fsb_to_db(ip, imap->br_startblock);
 +		if (imap->br_state == XFS_EXT_UNWRITTEN)
 +			iomap->type = IOMAP_UNWRITTEN;
 +		else
 +			iomap->type = IOMAP_MAPPED;
  	}
 -
 -	return error;
 +	iomap->offset = XFS_FSB_TO_B(mp, imap->br_startoff);
 +	iomap->length = XFS_FSB_TO_B(mp, imap->br_blockcount);
 +	iomap->bdev = xfs_find_bdev_for_inode(VFS_I(ip));
  }
 -
 -struct iomap_ops xfs_xattr_iomap_ops = {
 -	.iomap_begin		= xfs_xattr_iomap_begin,
 -};
* Unmerged path fs/xfs/xfs_iomap.c
