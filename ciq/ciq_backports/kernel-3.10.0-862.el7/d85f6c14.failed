mlx4: rx_headroom is a per port attribute

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Eric Dumazet <edumazet@google.com>
commit d85f6c14e967b0bddfa9712daa17d79e297d18b8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/d85f6c14.failed

No need to duplicate it per RX queue / frags.

	Signed-off-by: Eric Dumazet <edumazet@google.com>
	Acked-by: Tariq Toukan <tariqt@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit d85f6c14e967b0bddfa9712daa17d79e297d18b8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx4/en_rx.c
#	drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
diff --cc drivers/net/ethernet/mellanox/mlx4/en_rx.c
index 984f22166c89,bb33032a280f..000000000000
--- a/drivers/net/ethernet/mellanox/mlx4/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx4/en_rx.c
@@@ -114,9 -115,10 +114,15 @@@ static int mlx4_en_alloc_frags(struct m
  
  	for (i = 0; i < priv->num_frags; i++) {
  		frags[i] = ring_alloc[i];
++<<<<<<< HEAD
 +		dma = ring_alloc[i].dma + ring_alloc[i].page_offset;
++=======
+ 		frags[i].page_offset += priv->rx_headroom;
+ 		rx_desc->data[i].addr = cpu_to_be64(frags[i].dma +
+ 						    frags[i].page_offset);
++>>>>>>> d85f6c14e967 (mlx4: rx_headroom is a per port attribute)
  		ring_alloc[i] = page_alloc[i];
 +		rx_desc->data[i].addr = cpu_to_be64(dma);
  	}
  
  	return 0;
@@@ -1138,28 -1187,39 +1144,60 @@@ static const int frag_sizes[] = 
  
  void mlx4_en_calc_rx_buf(struct net_device *dev)
  {
 +	enum dma_data_direction dma_dir = PCI_DMA_FROMDEVICE;
  	struct mlx4_en_priv *priv = netdev_priv(dev);
 -	int eff_mtu = MLX4_EN_EFF_MTU(dev->mtu);
 +	/* VLAN_HLEN is added twice,to support skb vlan tagged with multiple
 +	 * headers. (For example: ETH_P_8021Q and ETH_P_8021AD).
 +	 */
 +	int eff_mtu = dev->mtu + ETH_HLEN + (2 * VLAN_HLEN);
 +	int order = MLX4_EN_ALLOC_PREFER_ORDER;
 +	u32 align = SMP_CACHE_BYTES;
 +	int buf_size = 0;
  	int i = 0;
  
++<<<<<<< HEAD
 +	while (buf_size < eff_mtu) {
 +		priv->frag_info[i].order = order;
 +		priv->frag_info[i].frag_size =
 +			(eff_mtu > buf_size + frag_sizes[i]) ?
 +				frag_sizes[i] : eff_mtu - buf_size;
 +		priv->frag_info[i].frag_prefix_size = buf_size;
 +		priv->frag_info[i].frag_stride =
 +				ALIGN(priv->frag_info[i].frag_size, align);
 +		priv->frag_info[i].dma_dir = dma_dir;
 +		buf_size += priv->frag_info[i].frag_size;
 +		i++;
++=======
+ 	/* bpf requires buffers to be set up as 1 packet per page.
+ 	 * This only works when num_frags == 1.
+ 	 */
+ 	if (priv->tx_ring_num[TX_XDP]) {
+ 		priv->rx_page_order = 0;
+ 		priv->frag_info[0].frag_size = eff_mtu;
+ 		/* This will gain efficient xdp frame recycling at the
+ 		 * expense of more costly truesize accounting
+ 		 */
+ 		priv->frag_info[0].frag_stride = PAGE_SIZE;
+ 		priv->dma_dir = PCI_DMA_BIDIRECTIONAL;
+ 		priv->rx_headroom = XDP_PACKET_HEADROOM;
+ 		i = 1;
+ 	} else {
+ 		int buf_size = 0;
+ 
+ 		while (buf_size < eff_mtu) {
+ 			priv->frag_info[i].frag_size =
+ 				(eff_mtu > buf_size + frag_sizes[i]) ?
+ 					frag_sizes[i] : eff_mtu - buf_size;
+ 			priv->frag_info[i].frag_stride =
+ 				ALIGN(priv->frag_info[i].frag_size,
+ 				      SMP_CACHE_BYTES);
+ 			buf_size += priv->frag_info[i].frag_size;
+ 			i++;
+ 		}
+ 		priv->rx_page_order = MLX4_EN_ALLOC_PREFER_ORDER;
+ 		priv->dma_dir = PCI_DMA_FROMDEVICE;
+ 		priv->rx_headroom = 0;
++>>>>>>> d85f6c14e967 (mlx4: rx_headroom is a per port attribute)
  	}
  
  	priv->num_frags = i;
diff --cc drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
index d8f46d99701e,fc7b4da5d8c3..000000000000
--- a/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
+++ b/drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
@@@ -472,10 -472,7 +472,13 @@@ struct mlx4_en_mc_list 
  
  struct mlx4_en_frag_info {
  	u16 frag_size;
++<<<<<<< HEAD
 +	u16 frag_prefix_size;
++=======
++>>>>>>> d85f6c14e967 (mlx4: rx_headroom is a per port attribute)
  	u32 frag_stride;
 +	enum dma_data_direction dma_dir;
 +	int order;
  };
  
  #ifdef CONFIG_MLX4_EN_DCB
@@@ -583,8 -580,11 +586,16 @@@ struct mlx4_en_priv 
  	u32 rx_ring_num;
  	u32 rx_skb_size;
  	struct mlx4_en_frag_info frag_info[MLX4_EN_MAX_RX_FRAGS];
++<<<<<<< HEAD
 +	u16 num_frags;
 +	u16 log_rx_info;
++=======
+ 	u8 num_frags;
+ 	u8 log_rx_info;
+ 	u8 dma_dir;
+ 	u8 rx_page_order;
+ 	u16 rx_headroom;
++>>>>>>> d85f6c14e967 (mlx4: rx_headroom is a per port attribute)
  
  	struct mlx4_en_tx_ring **tx_ring[MLX4_EN_NUM_TX_TYPES];
  	struct mlx4_en_rx_ring *rx_ring[MAX_RX_RINGS];
* Unmerged path drivers/net/ethernet/mellanox/mlx4/en_rx.c
* Unmerged path drivers/net/ethernet/mellanox/mlx4/mlx4_en.h
