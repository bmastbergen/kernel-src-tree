KVM: nSVM: do not forward NMI window singlestep VM exits to L1

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Ladi Prosek <lprosek@redhat.com>
commit ab2f4d73ebc33487930e7adf1dd8ed671c72827c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/ab2f4d73.failed

Nested hypervisor should not see singlestep VM exits if singlestepping
was enabled internally by KVM. Windows is particularly sensitive to this
and known to bluescreen on unexpected VM exits.

	Signed-off-by: Ladi Prosek <lprosek@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit ab2f4d73ebc33487930e7adf1dd8ed671c72827c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/svm.c
diff --cc arch/x86/kvm/svm.c
index 673cbc167bdc,1a854ce6025e..000000000000
--- a/arch/x86/kvm/svm.c
+++ b/arch/x86/kvm/svm.c
@@@ -925,6 -964,67 +926,70 @@@ static void svm_disable_lbrv(struct vcp
  	set_msr_interception(msrpm, MSR_IA32_LASTINTTOIP, 0, 0);
  }
  
++<<<<<<< HEAD
++=======
+ static void disable_nmi_singlestep(struct vcpu_svm *svm)
+ {
+ 	svm->nmi_singlestep = false;
+ 	if (!(svm->vcpu.guest_debug & KVM_GUESTDBG_SINGLESTEP)) {
+ 		/* Clear our flags if they were not set by the guest */
+ 		if (!(svm->nmi_singlestep_guest_rflags & X86_EFLAGS_TF))
+ 			svm->vmcb->save.rflags &= ~X86_EFLAGS_TF;
+ 		if (!(svm->nmi_singlestep_guest_rflags & X86_EFLAGS_RF))
+ 			svm->vmcb->save.rflags &= ~X86_EFLAGS_RF;
+ 	}
+ }
+ 
+ /* Note:
+  * This hash table is used to map VM_ID to a struct kvm_arch,
+  * when handling AMD IOMMU GALOG notification to schedule in
+  * a particular vCPU.
+  */
+ #define SVM_VM_DATA_HASH_BITS	8
+ static DEFINE_HASHTABLE(svm_vm_data_hash, SVM_VM_DATA_HASH_BITS);
+ static DEFINE_SPINLOCK(svm_vm_data_hash_lock);
+ 
+ /* Note:
+  * This function is called from IOMMU driver to notify
+  * SVM to schedule in a particular vCPU of a particular VM.
+  */
+ static int avic_ga_log_notifier(u32 ga_tag)
+ {
+ 	unsigned long flags;
+ 	struct kvm_arch *ka = NULL;
+ 	struct kvm_vcpu *vcpu = NULL;
+ 	u32 vm_id = AVIC_GATAG_TO_VMID(ga_tag);
+ 	u32 vcpu_id = AVIC_GATAG_TO_VCPUID(ga_tag);
+ 
+ 	pr_debug("SVM: %s: vm_id=%#x, vcpu_id=%#x\n", __func__, vm_id, vcpu_id);
+ 
+ 	spin_lock_irqsave(&svm_vm_data_hash_lock, flags);
+ 	hash_for_each_possible(svm_vm_data_hash, ka, hnode, vm_id) {
+ 		struct kvm *kvm = container_of(ka, struct kvm, arch);
+ 		struct kvm_arch *vm_data = &kvm->arch;
+ 
+ 		if (vm_data->avic_vm_id != vm_id)
+ 			continue;
+ 		vcpu = kvm_get_vcpu_by_id(kvm, vcpu_id);
+ 		break;
+ 	}
+ 	spin_unlock_irqrestore(&svm_vm_data_hash_lock, flags);
+ 
+ 	if (!vcpu)
+ 		return 0;
+ 
+ 	/* Note:
+ 	 * At this point, the IOMMU should have already set the pending
+ 	 * bit in the vAPIC backing page. So, we just need to schedule
+ 	 * in the vcpu.
+ 	 */
+ 	if (vcpu->mode == OUTSIDE_GUEST_MODE)
+ 		kvm_vcpu_wake_up(vcpu);
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> ab2f4d73ebc3 (KVM: nSVM: do not forward NMI window singlestep VM exits to L1)
  static __init int svm_hardware_setup(void)
  {
  	int cpu;
* Unmerged path arch/x86/kvm/svm.c
