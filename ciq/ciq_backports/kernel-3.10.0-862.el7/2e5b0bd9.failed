kvm: nVMX: Don't validate disabled secondary controls

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Jim Mattson <jmattson@google.com>
commit 2e5b0bd9cc6172edef502dfae28ae790f74a882e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/2e5b0bd9.failed

According to the SDM, if the "activate secondary controls" primary
processor-based VM-execution control is 0, no checks are performed on
the secondary processor-based VM-execution controls.

	Signed-off-by: Jim Mattson <jmattson@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 2e5b0bd9cc6172edef502dfae28ae790f74a882e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/vmx.c
diff --cc arch/x86/kvm/vmx.c
index 152adaa32966,e7d929103f4a..000000000000
--- a/arch/x86/kvm/vmx.c
+++ b/arch/x86/kvm/vmx.c
@@@ -9963,6 -10220,155 +9963,158 @@@ static int prepare_vmcs02(struct kvm_vc
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static int check_vmentry_prereqs(struct kvm_vcpu *vcpu, struct vmcs12 *vmcs12)
+ {
+ 	struct vcpu_vmx *vmx = to_vmx(vcpu);
+ 
+ 	if (vmcs12->guest_activity_state != GUEST_ACTIVITY_ACTIVE &&
+ 	    vmcs12->guest_activity_state != GUEST_ACTIVITY_HLT)
+ 		return VMXERR_ENTRY_INVALID_CONTROL_FIELD;
+ 
+ 	if (nested_vmx_check_msr_bitmap_controls(vcpu, vmcs12))
+ 		return VMXERR_ENTRY_INVALID_CONTROL_FIELD;
+ 
+ 	if (nested_vmx_check_apicv_controls(vcpu, vmcs12))
+ 		return VMXERR_ENTRY_INVALID_CONTROL_FIELD;
+ 
+ 	if (nested_vmx_check_msr_switch_controls(vcpu, vmcs12))
+ 		return VMXERR_ENTRY_INVALID_CONTROL_FIELD;
+ 
+ 	if (!vmx_control_verify(vmcs12->cpu_based_vm_exec_control,
+ 				vmx->nested.nested_vmx_procbased_ctls_low,
+ 				vmx->nested.nested_vmx_procbased_ctls_high) ||
+ 	    (nested_cpu_has(vmcs12, CPU_BASED_ACTIVATE_SECONDARY_CONTROLS) &&
+ 	     !vmx_control_verify(vmcs12->secondary_vm_exec_control,
+ 				 vmx->nested.nested_vmx_secondary_ctls_low,
+ 				 vmx->nested.nested_vmx_secondary_ctls_high)) ||
+ 	    !vmx_control_verify(vmcs12->pin_based_vm_exec_control,
+ 				vmx->nested.nested_vmx_pinbased_ctls_low,
+ 				vmx->nested.nested_vmx_pinbased_ctls_high) ||
+ 	    !vmx_control_verify(vmcs12->vm_exit_controls,
+ 				vmx->nested.nested_vmx_exit_ctls_low,
+ 				vmx->nested.nested_vmx_exit_ctls_high) ||
+ 	    !vmx_control_verify(vmcs12->vm_entry_controls,
+ 				vmx->nested.nested_vmx_entry_ctls_low,
+ 				vmx->nested.nested_vmx_entry_ctls_high))
+ 		return VMXERR_ENTRY_INVALID_CONTROL_FIELD;
+ 
+ 	if (!nested_host_cr0_valid(vcpu, vmcs12->host_cr0) ||
+ 	    !nested_host_cr4_valid(vcpu, vmcs12->host_cr4) ||
+ 	    !nested_cr3_valid(vcpu, vmcs12->host_cr3))
+ 		return VMXERR_ENTRY_INVALID_HOST_STATE_FIELD;
+ 
+ 	return 0;
+ }
+ 
+ static int check_vmentry_postreqs(struct kvm_vcpu *vcpu, struct vmcs12 *vmcs12,
+ 				  u32 *exit_qual)
+ {
+ 	bool ia32e;
+ 
+ 	*exit_qual = ENTRY_FAIL_DEFAULT;
+ 
+ 	if (!nested_guest_cr0_valid(vcpu, vmcs12->guest_cr0) ||
+ 	    !nested_guest_cr4_valid(vcpu, vmcs12->guest_cr4))
+ 		return 1;
+ 
+ 	if (!nested_cpu_has2(vmcs12, SECONDARY_EXEC_SHADOW_VMCS) &&
+ 	    vmcs12->vmcs_link_pointer != -1ull) {
+ 		*exit_qual = ENTRY_FAIL_VMCS_LINK_PTR;
+ 		return 1;
+ 	}
+ 
+ 	/*
+ 	 * If the load IA32_EFER VM-entry control is 1, the following checks
+ 	 * are performed on the field for the IA32_EFER MSR:
+ 	 * - Bits reserved in the IA32_EFER MSR must be 0.
+ 	 * - Bit 10 (corresponding to IA32_EFER.LMA) must equal the value of
+ 	 *   the IA-32e mode guest VM-exit control. It must also be identical
+ 	 *   to bit 8 (LME) if bit 31 in the CR0 field (corresponding to
+ 	 *   CR0.PG) is 1.
+ 	 */
+ 	if (to_vmx(vcpu)->nested.nested_run_pending &&
+ 	    (vmcs12->vm_entry_controls & VM_ENTRY_LOAD_IA32_EFER)) {
+ 		ia32e = (vmcs12->vm_entry_controls & VM_ENTRY_IA32E_MODE) != 0;
+ 		if (!kvm_valid_efer(vcpu, vmcs12->guest_ia32_efer) ||
+ 		    ia32e != !!(vmcs12->guest_ia32_efer & EFER_LMA) ||
+ 		    ((vmcs12->guest_cr0 & X86_CR0_PG) &&
+ 		     ia32e != !!(vmcs12->guest_ia32_efer & EFER_LME)))
+ 			return 1;
+ 	}
+ 
+ 	/*
+ 	 * If the load IA32_EFER VM-exit control is 1, bits reserved in the
+ 	 * IA32_EFER MSR must be 0 in the field for that register. In addition,
+ 	 * the values of the LMA and LME bits in the field must each be that of
+ 	 * the host address-space size VM-exit control.
+ 	 */
+ 	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER) {
+ 		ia32e = (vmcs12->vm_exit_controls &
+ 			 VM_EXIT_HOST_ADDR_SPACE_SIZE) != 0;
+ 		if (!kvm_valid_efer(vcpu, vmcs12->host_ia32_efer) ||
+ 		    ia32e != !!(vmcs12->host_ia32_efer & EFER_LMA) ||
+ 		    ia32e != !!(vmcs12->host_ia32_efer & EFER_LME))
+ 			return 1;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int enter_vmx_non_root_mode(struct kvm_vcpu *vcpu, bool from_vmentry)
+ {
+ 	struct vcpu_vmx *vmx = to_vmx(vcpu);
+ 	struct vmcs12 *vmcs12 = get_vmcs12(vcpu);
+ 	struct loaded_vmcs *vmcs02;
+ 	u32 msr_entry_idx;
+ 	u32 exit_qual;
+ 
+ 	vmcs02 = nested_get_current_vmcs02(vmx);
+ 	if (!vmcs02)
+ 		return -ENOMEM;
+ 
+ 	enter_guest_mode(vcpu);
+ 
+ 	if (!(vmcs12->vm_entry_controls & VM_ENTRY_LOAD_DEBUG_CONTROLS))
+ 		vmx->nested.vmcs01_debugctl = vmcs_read64(GUEST_IA32_DEBUGCTL);
+ 
+ 	vmx_switch_vmcs(vcpu, vmcs02);
+ 	vmx_segment_cache_clear(vmx);
+ 
+ 	if (prepare_vmcs02(vcpu, vmcs12, from_vmentry, &exit_qual)) {
+ 		leave_guest_mode(vcpu);
+ 		vmx_switch_vmcs(vcpu, &vmx->vmcs01);
+ 		nested_vmx_entry_failure(vcpu, vmcs12,
+ 					 EXIT_REASON_INVALID_STATE, exit_qual);
+ 		return 1;
+ 	}
+ 
+ 	nested_get_vmcs12_pages(vcpu, vmcs12);
+ 
+ 	msr_entry_idx = nested_vmx_load_msr(vcpu,
+ 					    vmcs12->vm_entry_msr_load_addr,
+ 					    vmcs12->vm_entry_msr_load_count);
+ 	if (msr_entry_idx) {
+ 		leave_guest_mode(vcpu);
+ 		vmx_switch_vmcs(vcpu, &vmx->vmcs01);
+ 		nested_vmx_entry_failure(vcpu, vmcs12,
+ 				EXIT_REASON_MSR_LOAD_FAIL, msr_entry_idx);
+ 		return 1;
+ 	}
+ 
+ 	vmcs12->launch_state = 1;
+ 
+ 	/*
+ 	 * Note no nested_vmx_succeed or nested_vmx_fail here. At this point
+ 	 * we are no longer running L1, and VMLAUNCH/VMRESUME has not yet
+ 	 * returned as far as L1 is concerned. It will only return (and set
+ 	 * the success flag) when L2 exits (see nested_vmx_vmexit()).
+ 	 */
+ 	return 0;
+ }
+ 
++>>>>>>> 2e5b0bd9cc61 (kvm: nVMX: Don't validate disabled secondary controls)
  /*
   * nested_vmx_run() handles a nested entry, i.e., a VMLAUNCH or VMRESUME on L1
   * for running an L2 nested guest.
* Unmerged path arch/x86/kvm/vmx.c
