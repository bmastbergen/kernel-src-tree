x86/mm: Make the SME mask a u64

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [x86] mm: Make the SME mask a u64 (Suravee Suthikulpanit) [1361287]
Rebuild_FUZZ: 93.10%
commit-author Borislav Petkov <bp@suse.de>
commit 21d9bb4a05bac50fb4f850517af4030baecd00f6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/21d9bb4a.failed

The SME encryption mask is for masking 64-bit pagetable entries. It
being an unsigned long works fine on X86_64 but on 32-bit builds in
truncates bits leading to Xen guests crashing very early.

And regardless, the whole SME mask handling shouldnt've leaked into
32-bit because SME is X86_64-only feature. So, first make the mask u64.
And then, add trivial 32-bit versions of the __sme_* macros so that
nothing happens there.

Reported-and-tested-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
	Tested-by: Brijesh Singh <brijesh.singh@amd.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Acked-by: Tom Lendacky <Thomas.Lendacky@amd.com>
	Acked-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas <Thomas.Lendacky@amd.com>
Fixes: 21729f81ce8a ("x86/mm: Provide general kernel support for memory encryption")
Link: http://lkml.kernel.org/r/20170907093837.76zojtkgebwtqc74@pd.tnic
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 21d9bb4a05bac50fb4f850517af4030baecd00f6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/mem_encrypt.h
#	arch/x86/mm/mem_encrypt.c
#	include/linux/mem_encrypt.h
* Unmerged path arch/x86/include/asm/mem_encrypt.h
* Unmerged path arch/x86/mm/mem_encrypt.c
* Unmerged path include/linux/mem_encrypt.h
* Unmerged path arch/x86/include/asm/mem_encrypt.h
* Unmerged path arch/x86/mm/mem_encrypt.c
* Unmerged path include/linux/mem_encrypt.h
