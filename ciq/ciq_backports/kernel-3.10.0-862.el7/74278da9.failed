inode: convert inode_sb_list_lock to per-sb

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Dave Chinner <dchinner@redhat.com>
commit 74278da9f70d84d715601fe794567a6d2bfdf078
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/74278da9.failed

The process of reducing contention on per-superblock inode lists
starts with moving the locking to match the per-superblock inode
list. This takes the global lock out of the picture and reduces the
contention problems to within a single filesystem. This doesn't get
rid of contention as the locks still have global CPU scope, but it
does isolate operations on different superblocks form each other.

	Signed-off-by: Dave Chinner <dchinner@redhat.com>
	Signed-off-by: Josef Bacik <jbacik@fb.com>
	Reviewed-by: Jan Kara <jack@suse.cz>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Tested-by: Dave Chinner <dchinner@redhat.com>
(cherry picked from commit 74278da9f70d84d715601fe794567a6d2bfdf078)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/internal.h
#	fs/notify/inode_mark.c
#	fs/super.c
#	include/linux/fs.h
diff --cc fs/internal.h
index c58979ac0a78,ee1209c54eb1..000000000000
--- a/fs/internal.h
+++ b/fs/internal.h
@@@ -114,18 -112,9 +114,22 @@@ extern int open_check_o_direct(struct f
  /*
   * inode.c
   */
++<<<<<<< HEAD
 +extern spinlock_t inode_sb_list_lock;
++=======
+ extern long prune_icache_sb(struct super_block *sb, struct shrink_control *sc);
++>>>>>>> 74278da9f70d (inode: convert inode_sb_list_lock to per-sb)
  extern void inode_add_lru(struct inode *inode);
  
 +extern bool __atime_needs_update(const struct path *, struct inode *, bool);
 +static inline bool atime_needs_update_rcu(const struct path *path,
 +					  struct inode *inode)
 +{
 +	return __atime_needs_update(path, inode, true);
 +}
 +
 +extern bool atime_needs_update_rcu(const struct path *, struct inode *);
 +
  /*
   * fs-writeback.c
   */
diff --cc fs/notify/inode_mark.c
index 1168d71dbf85,a4e1a8f6c329..000000000000
--- a/fs/notify/inode_mark.c
+++ b/fs/notify/inode_mark.c
@@@ -143,17 -163,19 +143,24 @@@ int fsnotify_add_inode_mark(struct fsno
  
  /**
   * fsnotify_unmount_inodes - an sb is unmounting.  handle any watched inodes.
-  * @list: list of inodes being unmounted (sb->s_inodes)
+  * @sb: superblock being unmounted.
   *
   * Called during unmount with no locks held, so needs to be safe against
-  * concurrent modifiers. We temporarily drop inode_sb_list_lock and CAN block.
+  * concurrent modifiers. We temporarily drop sb->s_inode_list_lock and CAN block.
   */
- void fsnotify_unmount_inodes(struct list_head *list)
+ void fsnotify_unmount_inodes(struct super_block *sb)
  {
 -	struct inode *inode, *next_i, *need_iput = NULL;
 +	struct inode *inode, *iput_inode = NULL;
  
++<<<<<<< HEAD
 +	spin_lock(&inode_sb_list_lock);
 +	list_for_each_entry(inode, list, i_sb_list) {
++=======
+ 	spin_lock(&sb->s_inode_list_lock);
+ 	list_for_each_entry_safe(inode, next_i, &sb->s_inodes, i_sb_list) {
+ 		struct inode *need_iput_tmp;
+ 
++>>>>>>> 74278da9f70d (inode: convert inode_sb_list_lock to per-sb)
  		/*
  		 * We cannot __iget() an inode in state I_FREEING,
  		 * I_WILL_FREE, or I_NEW which is fine because by that point
@@@ -176,24 -198,50 +183,54 @@@
  			continue;
  		}
  
 -		need_iput_tmp = need_iput;
 -		need_iput = NULL;
 -
 -		/* In case fsnotify_inode_delete() drops a reference. */
 -		if (inode != need_iput_tmp)
 -			__iget(inode);
 -		else
 -			need_iput_tmp = NULL;
 +		__iget(inode);
  		spin_unlock(&inode->i_lock);
++<<<<<<< HEAD
 +		spin_unlock(&inode_sb_list_lock);
++=======
+ 
+ 		/* In case the dropping of a reference would nuke next_i. */
+ 		while (&next_i->i_sb_list != &sb->s_inodes) {
+ 			spin_lock(&next_i->i_lock);
+ 			if (!(next_i->i_state & (I_FREEING | I_WILL_FREE)) &&
+ 						atomic_read(&next_i->i_count)) {
+ 				__iget(next_i);
+ 				need_iput = next_i;
+ 				spin_unlock(&next_i->i_lock);
+ 				break;
+ 			}
+ 			spin_unlock(&next_i->i_lock);
+ 			next_i = list_entry(next_i->i_sb_list.next,
+ 						struct inode, i_sb_list);
+ 		}
+ 
+ 		/*
+ 		 * We can safely drop s_inode_list_lock here because either
+ 		 * we actually hold references on both inode and next_i or
+ 		 * end of list.  Also no new inodes will be added since the
+ 		 * umount has begun.
+ 		 */
+ 		spin_unlock(&sb->s_inode_list_lock);
++>>>>>>> 74278da9f70d (inode: convert inode_sb_list_lock to per-sb)
  
 -		if (need_iput_tmp)
 -			iput(need_iput_tmp);
 +		if (iput_inode)
 +			iput(iput_inode);
  
  		/* for each watch, send FS_UNMOUNT and then remove it */
  		fsnotify(inode, FS_UNMOUNT, inode, FSNOTIFY_EVENT_INODE, NULL, 0);
  
  		fsnotify_inode_delete(inode);
  
 -		iput(inode);
 +		iput_inode = inode;
  
- 		spin_lock(&inode_sb_list_lock);
+ 		spin_lock(&sb->s_inode_list_lock);
  	}
++<<<<<<< HEAD
 +	spin_unlock(&inode_sb_list_lock);
 +
 +	if (iput_inode)
 +		iput(iput_inode);
++=======
+ 	spin_unlock(&sb->s_inode_list_lock);
++>>>>>>> 74278da9f70d (inode: convert inode_sb_list_lock to per-sb)
  }
diff --cc fs/super.c
index 985ae62de171,c808183554a2..000000000000
--- a/fs/super.c
+++ b/fs/super.c
@@@ -158,10 -191,13 +158,20 @@@ static struct super_block *alloc_super(
  	INIT_HLIST_NODE(&s->s_instances);
  	INIT_HLIST_BL_HEAD(&s->s_anon);
  	INIT_LIST_HEAD(&s->s_inodes);
++<<<<<<< HEAD
 +	INIT_LIST_HEAD(&s->s_dentry_lru);
 +	INIT_LIST_HEAD(&s->s_inode_lru);
 +	spin_lock_init(&s->s_inode_lru_lock);
 +	INIT_LIST_HEAD(&s->s_mounts);
++=======
+ 	spin_lock_init(&s->s_inode_list_lock);
+ 
+ 	if (list_lru_init_memcg(&s->s_dentry_lru))
+ 		goto fail;
+ 	if (list_lru_init_memcg(&s->s_inode_lru))
+ 		goto fail;
+ 
++>>>>>>> 74278da9f70d (inode: convert inode_sb_list_lock to per-sb)
  	init_rwsem(&s->s_umount);
  	lockdep_set_class(&s->s_umount, &type->s_umount_key);
  	/*
diff --cc include/linux/fs.h
index 4086333a0708,09bbd38485f9..000000000000
--- a/include/linux/fs.h
+++ b/include/linux/fs.h
@@@ -1446,31 -1309,8 +1446,30 @@@ struct super_block 
  #endif
  	const struct xattr_handler **s_xattr;
  
- 	struct list_head	s_inodes;	/* all inodes */
  	struct hlist_bl_head	s_anon;		/* anonymous dentries for (nfs) exporting */
 +#ifdef __GENKSYMS__
 +#ifdef CONFIG_SMP
 +	struct list_head __percpu *s_files;
 +#else
 +	struct list_head	s_files;
 +#endif
 +#else
 +#ifdef CONFIG_SMP
 +	struct list_head __percpu *s_files_deprecated;
 +#else
 +	struct list_head	s_files_deprecated;
 +#endif
 +#endif
  	struct list_head	s_mounts;	/* list of mounts; _not_ for fs use */
 +	/* s_dentry_lru, s_nr_dentry_unused protected by dcache.c lru locks */
 +	struct list_head	s_dentry_lru;	/* unused dentry lru */
 +	int			s_nr_dentry_unused;	/* # of dentry on lru */
 +
 +	/* s_inode_lru_lock protects s_inode_lru and s_nr_inodes_unused */
 +	spinlock_t		s_inode_lru_lock ____cacheline_aligned_in_smp;
 +	struct list_head	s_inode_lru;		/* unused inode lru */
 +	int			s_nr_inodes_unused;	/* # of inodes on lru */
 +
  	struct block_device	*s_bdev;
  	struct backing_dev_info *s_bdi;
  	struct mtd_info		*s_mtd;
@@@ -1538,30 -1380,11 +1537,36 @@@ struct super_block_wrapper 
  	 */
  	int s_stack_depth;
  
++<<<<<<< HEAD
 +	/* -- Wrapper version 1 -- */
++=======
+ 	/* s_inode_list_lock protects s_inodes */
+ 	spinlock_t		s_inode_list_lock ____cacheline_aligned_in_smp;
+ 	struct list_head	s_inodes;	/* all inodes */
++>>>>>>> 74278da9f70d (inode: convert inode_sb_list_lock to per-sb)
  };
  
 +static inline struct super_block_wrapper *get_sb_wrapper(struct super_block *sb,
 +							 unsigned version)
 +{
 +	/* Make sure we get a link failure if this function is used against an
 +	 * older kernel that doesn't have the superblock wrapper.
 +	 */
 +	if (super_block_wrapper_version < version)
 +		return NULL;
 +	return container_of(sb, struct super_block_wrapper, sb);
 +}
 +
 +static inline int *get_s_stack_depth(struct super_block *sb)
 +{
 +	struct super_block_wrapper *wrapper = get_sb_wrapper(sb, 0);
 +	return wrapper ? &wrapper->s_stack_depth : NULL;
 +}
 +
 +/* superblock cache pruning functions */
 +extern void prune_icache_sb(struct super_block *sb, int nr_to_scan);
 +extern void prune_dcache_sb(struct super_block *sb, int nr_to_scan);
 +
  extern struct timespec current_fs_time(struct super_block *sb);
  
  /*
diff --git a/fs/block_dev.c b/fs/block_dev.c
index ed7207dfa086..c2bedb67dc4d 100644
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@ -1893,7 +1893,7 @@ void iterate_bdevs(void (*func)(struct block_device *, void *), void *arg)
 {
 	struct inode *inode, *old_inode = NULL;
 
-	spin_lock(&inode_sb_list_lock);
+	spin_lock(&blockdev_superblock->s_inode_list_lock);
 	list_for_each_entry(inode, &blockdev_superblock->s_inodes, i_sb_list) {
 		struct address_space *mapping = inode->i_mapping;
 
@@ -1905,13 +1905,13 @@ void iterate_bdevs(void (*func)(struct block_device *, void *), void *arg)
 		}
 		__iget(inode);
 		spin_unlock(&inode->i_lock);
-		spin_unlock(&inode_sb_list_lock);
+		spin_unlock(&blockdev_superblock->s_inode_list_lock);
 		/*
 		 * We hold a reference to 'inode' so it couldn't have been
 		 * removed from s_inodes list while we dropped the
-		 * inode_sb_list_lock.  We cannot iput the inode now as we can
+		 * s_inode_list_lock  We cannot iput the inode now as we can
 		 * be holding the last reference and we cannot iput it under
-		 * inode_sb_list_lock. So we keep the reference and iput it
+		 * s_inode_list_lock. So we keep the reference and iput it
 		 * later.
 		 */
 		iput(old_inode);
@@ -1919,8 +1919,8 @@ void iterate_bdevs(void (*func)(struct block_device *, void *), void *arg)
 
 		func(I_BDEV(inode), arg);
 
-		spin_lock(&inode_sb_list_lock);
+		spin_lock(&blockdev_superblock->s_inode_list_lock);
 	}
-	spin_unlock(&inode_sb_list_lock);
+	spin_unlock(&blockdev_superblock->s_inode_list_lock);
 	iput(old_inode);
 }
diff --git a/fs/drop_caches.c b/fs/drop_caches.c
index 24a1957e170c..70b4a9eedc3a 100644
--- a/fs/drop_caches.c
+++ b/fs/drop_caches.c
@@ -17,7 +17,7 @@ static void drop_pagecache_sb(struct super_block *sb, void *unused)
 {
 	struct inode *inode, *toput_inode = NULL;
 
-	spin_lock(&inode_sb_list_lock);
+	spin_lock(&sb->s_inode_list_lock);
 	list_for_each_entry(inode, &sb->s_inodes, i_sb_list) {
 		spin_lock(&inode->i_lock);
 		if ((inode->i_state & (I_FREEING|I_WILL_FREE|I_NEW)) ||
@@ -27,13 +27,15 @@ static void drop_pagecache_sb(struct super_block *sb, void *unused)
 		}
 		__iget(inode);
 		spin_unlock(&inode->i_lock);
-		spin_unlock(&inode_sb_list_lock);
+		spin_unlock(&sb->s_inode_list_lock);
+
 		invalidate_mapping_pages(inode->i_mapping, 0, -1);
 		iput(toput_inode);
 		toput_inode = inode;
-		spin_lock(&inode_sb_list_lock);
+
+		spin_lock(&sb->s_inode_list_lock);
 	}
-	spin_unlock(&inode_sb_list_lock);
+	spin_unlock(&sb->s_inode_list_lock);
 	iput(toput_inode);
 }
 
diff --git a/fs/fs-writeback.c b/fs/fs-writeback.c
index 204141e64775..3e65044efba0 100644
--- a/fs/fs-writeback.c
+++ b/fs/fs-writeback.c
@@ -1224,7 +1224,7 @@ static void wait_sb_inodes(struct super_block *sb)
 	 */
 	WARN_ON(!rwsem_is_locked(&sb->s_umount));
 
-	spin_lock(&inode_sb_list_lock);
+	spin_lock(&sb->s_inode_list_lock);
 
 	/*
 	 * Data integrity sync. Must wait for all pages under writeback,
@@ -1244,14 +1244,14 @@ static void wait_sb_inodes(struct super_block *sb)
 		}
 		__iget(inode);
 		spin_unlock(&inode->i_lock);
-		spin_unlock(&inode_sb_list_lock);
+		spin_unlock(&sb->s_inode_list_lock);
 
 		/*
 		 * We hold a reference to 'inode' so it couldn't have been
 		 * removed from s_inodes list while we dropped the
-		 * inode_sb_list_lock.  We cannot iput the inode now as we can
+		 * s_inode_list_lock.  We cannot iput the inode now as we can
 		 * be holding the last reference and we cannot iput it under
-		 * inode_sb_list_lock. So we keep the reference and iput it
+		 * s_inode_list_lock. So we keep the reference and iput it
 		 * later.
 		 */
 		iput(old_inode);
@@ -1266,9 +1266,9 @@ static void wait_sb_inodes(struct super_block *sb)
 
 		cond_resched();
 
-		spin_lock(&inode_sb_list_lock);
+		spin_lock(&sb->s_inode_list_lock);
 	}
-	spin_unlock(&inode_sb_list_lock);
+	spin_unlock(&sb->s_inode_list_lock);
 	iput(old_inode);
 }
 
diff --git a/fs/inode.c b/fs/inode.c
index aaf9ae90702b..7e3f88532ddf 100644
--- a/fs/inode.c
+++ b/fs/inode.c
@@ -26,8 +26,8 @@
  *   inode->i_state, inode->i_hash, __iget()
  * inode->i_sb->s_inode_lru_lock protects:
  *   inode->i_sb->s_inode_lru, inode->i_lru
- * inode_sb_list_lock protects:
- *   sb->s_inodes, inode->i_sb_list
+ * inode->i_sb->s_inode_list_lock protects:
+ *   inode->i_sb->s_inodes, inode->i_sb_list
  * bdi->wb.list_lock protects:
  *   bdi->wb.b_{dirty,io,more_io}, inode->i_wb_list
  * inode_hash_lock protects:
@@ -35,7 +35,7 @@
  *
  * Lock ordering:
  *
- * inode_sb_list_lock
+ * inode->i_sb->s_inode_list_lock
  *   inode->i_lock
  *     inode->i_sb->s_inode_lru_lock
  *
@@ -43,7 +43,7 @@
  *   inode->i_lock
  *
  * inode_hash_lock
- *   inode_sb_list_lock
+ *   inode->i_sb->s_inode_list_lock
  *   inode->i_lock
  *
  * iunique_lock
@@ -55,8 +55,6 @@ static unsigned int i_hash_shift __read_mostly;
 static struct hlist_head *inode_hashtable __read_mostly;
 static __cacheline_aligned_in_smp DEFINE_SPINLOCK(inode_hash_lock);
 
-__cacheline_aligned_in_smp DEFINE_SPINLOCK(inode_sb_list_lock);
-
 /*
  * Empty aops. Can be used for the cases where the user does not
  * define any of the address_space operations.
@@ -446,18 +444,18 @@ static void inode_lru_list_del(struct inode *inode)
  */
 void inode_sb_list_add(struct inode *inode)
 {
-	spin_lock(&inode_sb_list_lock);
+	spin_lock(&inode->i_sb->s_inode_list_lock);
 	list_add(&inode->i_sb_list, &inode->i_sb->s_inodes);
-	spin_unlock(&inode_sb_list_lock);
+	spin_unlock(&inode->i_sb->s_inode_list_lock);
 }
 EXPORT_SYMBOL_GPL(inode_sb_list_add);
 
 static inline void inode_sb_list_del(struct inode *inode)
 {
 	if (!list_empty(&inode->i_sb_list)) {
-		spin_lock(&inode_sb_list_lock);
+		spin_lock(&inode->i_sb->s_inode_list_lock);
 		list_del_init(&inode->i_sb_list);
-		spin_unlock(&inode_sb_list_lock);
+		spin_unlock(&inode->i_sb->s_inode_list_lock);
 	}
 }
 
@@ -614,7 +612,7 @@ void evict_inodes(struct super_block *sb)
 	struct inode *inode, *next;
 	LIST_HEAD(dispose);
 
-	spin_lock(&inode_sb_list_lock);
+	spin_lock(&sb->s_inode_list_lock);
 	list_for_each_entry_safe(inode, next, &sb->s_inodes, i_sb_list) {
 		if (atomic_read(&inode->i_count))
 			continue;
@@ -630,7 +628,7 @@ void evict_inodes(struct super_block *sb)
 		spin_unlock(&inode->i_lock);
 		list_add(&inode->i_lru, &dispose);
 	}
-	spin_unlock(&inode_sb_list_lock);
+	spin_unlock(&sb->s_inode_list_lock);
 
 	dispose_list(&dispose);
 }
@@ -651,7 +649,7 @@ int invalidate_inodes(struct super_block *sb, bool kill_dirty)
 	struct inode *inode, *next;
 	LIST_HEAD(dispose);
 
-	spin_lock(&inode_sb_list_lock);
+	spin_lock(&sb->s_inode_list_lock);
 	list_for_each_entry_safe(inode, next, &sb->s_inodes, i_sb_list) {
 		spin_lock(&inode->i_lock);
 		if (inode->i_state & (I_NEW | I_FREEING | I_WILL_FREE)) {
@@ -674,7 +672,7 @@ int invalidate_inodes(struct super_block *sb, bool kill_dirty)
 		spin_unlock(&inode->i_lock);
 		list_add(&inode->i_lru, &dispose);
 	}
-	spin_unlock(&inode_sb_list_lock);
+	spin_unlock(&sb->s_inode_list_lock);
 
 	dispose_list(&dispose);
 
@@ -942,7 +940,7 @@ struct inode *new_inode(struct super_block *sb)
 {
 	struct inode *inode;
 
-	spin_lock_prefetch(&inode_sb_list_lock);
+	spin_lock_prefetch(&sb->s_inode_list_lock);
 
 	inode = new_inode_pseudo(sb);
 	if (inode)
* Unmerged path fs/internal.h
* Unmerged path fs/notify/inode_mark.c
diff --git a/fs/quota/dquot.c b/fs/quota/dquot.c
index d7d5a0afc057..0dd25b68301c 100644
--- a/fs/quota/dquot.c
+++ b/fs/quota/dquot.c
@@ -913,7 +913,7 @@ static void add_dquot_ref(struct super_block *sb, int type)
 	int reserved = 0;
 #endif
 
-	spin_lock(&inode_sb_list_lock);
+	spin_lock(&sb->s_inode_list_lock);
 	list_for_each_entry(inode, &sb->s_inodes, i_sb_list) {
 		spin_lock(&inode->i_lock);
 		if ((inode->i_state & (I_FREEING|I_WILL_FREE|I_NEW)) ||
@@ -924,7 +924,7 @@ static void add_dquot_ref(struct super_block *sb, int type)
 		}
 		__iget(inode);
 		spin_unlock(&inode->i_lock);
-		spin_unlock(&inode_sb_list_lock);
+		spin_unlock(&sb->s_inode_list_lock);
 
 #ifdef CONFIG_QUOTA_DEBUG
 		if (unlikely(inode_get_rsv_space(inode) > 0))
@@ -936,15 +936,15 @@ static void add_dquot_ref(struct super_block *sb, int type)
 		/*
 		 * We hold a reference to 'inode' so it couldn't have been
 		 * removed from s_inodes list while we dropped the
-		 * inode_sb_list_lock We cannot iput the inode now as we can be
+		 * s_inode_list_lock. We cannot iput the inode now as we can be
 		 * holding the last reference and we cannot iput it under
-		 * inode_sb_list_lock. So we keep the reference and iput it
+		 * s_inode_list_lock. So we keep the reference and iput it
 		 * later.
 		 */
 		old_inode = inode;
-		spin_lock(&inode_sb_list_lock);
+		spin_lock(&sb->s_inode_list_lock);
 	}
-	spin_unlock(&inode_sb_list_lock);
+	spin_unlock(&sb->s_inode_list_lock);
 	iput(old_inode);
 
 #ifdef CONFIG_QUOTA_DEBUG
@@ -1012,7 +1012,7 @@ static void remove_dquot_ref(struct super_block *sb, int type,
 	struct inode *inode;
 	int reserved = 0;
 
-	spin_lock(&inode_sb_list_lock);
+	spin_lock(&sb->s_inode_list_lock);
 	list_for_each_entry(inode, &sb->s_inodes, i_sb_list) {
 		/*
 		 *  We have to scan also I_NEW inodes because they can already
@@ -1028,7 +1028,7 @@ static void remove_dquot_ref(struct super_block *sb, int type,
 		}
 		spin_unlock(&dq_data_lock);
 	}
-	spin_unlock(&inode_sb_list_lock);
+	spin_unlock(&sb->s_inode_list_lock);
 #ifdef CONFIG_QUOTA_DEBUG
 	if (reserved) {
 		printk(KERN_WARNING "VFS (%s): Writes happened after quota"
* Unmerged path fs/super.c
* Unmerged path include/linux/fs.h
diff --git a/include/linux/fsnotify_backend.h b/include/linux/fsnotify_backend.h
index d3138f0bea0a..4e93ae109de5 100644
--- a/include/linux/fsnotify_backend.h
+++ b/include/linux/fsnotify_backend.h
@@ -363,7 +363,7 @@ extern void fsnotify_clear_inode_marks_by_group(struct fsnotify_group *group);
 extern void fsnotify_clear_marks_by_group_flags(struct fsnotify_group *group, unsigned int flags);
 extern void fsnotify_get_mark(struct fsnotify_mark *mark);
 extern void fsnotify_put_mark(struct fsnotify_mark *mark);
-extern void fsnotify_unmount_inodes(struct list_head *list);
+extern void fsnotify_unmount_inodes(struct super_block *sb);
 
 /* put here because inotify does some weird stuff when destroying watches */
 extern void fsnotify_init_event(struct fsnotify_event *event,
@@ -399,7 +399,7 @@ static inline u32 fsnotify_get_cookie(void)
 	return 0;
 }
 
-static inline void fsnotify_unmount_inodes(struct list_head *list)
+static inline void fsnotify_unmount_inodes(struct super_block *sb)
 {}
 
 #endif	/* CONFIG_FSNOTIFY */
