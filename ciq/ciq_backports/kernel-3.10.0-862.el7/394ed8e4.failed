md: cleanup mddev flag clear for takeover

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [md] cleanup mddev flag clear for takeover (Nigel Croxon) [1455932]
Rebuild_FUZZ: 94.87%
commit-author Shaohua Li <shli@fb.com>
commit 394ed8e4743b0cfc5496fe49059fbfc2bc8eae35
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/394ed8e4.failed

Commit 6995f0b (md: takeover should clear unrelated bits) clear
unrelated bits, but it's quite fragile. To avoid error in the future,
define a macro for unsupported mddev flags for each raid type and use it
to clear unsupported mddev flags. This should be less error-prone.

	Suggested-by: NeilBrown <neilb@suse.com>
	Signed-off-by: Shaohua Li <shli@fb.com>
(cherry picked from commit 394ed8e4743b0cfc5496fe49059fbfc2bc8eae35)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/md.h
#	drivers/md/raid0.c
#	drivers/md/raid5.c
diff --cc drivers/md/md.h
index 0d13bf88f41f,2a514036a83d..000000000000
--- a/drivers/md/md.h
+++ b/drivers/md/md.h
@@@ -220,6 -212,25 +220,28 @@@ extern int rdev_clear_badblocks(struct 
  				int is_new);
  struct md_cluster_info;
  
++<<<<<<< HEAD
++=======
+ /* change UNSUPPORTED_MDDEV_FLAGS for each array type if new flag is added */
+ enum mddev_flags {
+ 	MD_ARRAY_FIRST_USE,	/* First use of array, needs initialization */
+ 	MD_CLOSING,		/* If set, we are closing the array, do not open
+ 				 * it then */
+ 	MD_JOURNAL_CLEAN,	/* A raid with journal is already clean */
+ 	MD_HAS_JOURNAL,		/* The raid array has journal feature set */
+ 	MD_RELOAD_SB,		/* Reload the superblock because another node
+ 				 * updated it.
+ 				 */
+ 	MD_CLUSTER_RESYNC_LOCKED, /* cluster raid only, which means node
+ 				   * already took resync lock, need to
+ 				   * release the lock */
+ 	MD_FAILFAST_SUPPORTED,	/* Using MD_FAILFAST on metadata writes is
+ 				 * supported as calls to md_error() will
+ 				 * never cause the array to become failed.
+ 				 */
+ };
+ 
++>>>>>>> 394ed8e4743b (md: cleanup mddev flag clear for takeover)
  enum mddev_sb_flags {
  	MD_SB_CHANGE_DEVS,		/* Some device status has changed */
  	MD_SB_CHANGE_CLEAN,	/* transition to or from 'clean' */
@@@ -705,4 -698,16 +727,19 @@@ static inline void rdev_dec_pending(str
  	}
  }
  
++<<<<<<< HEAD
++=======
+ extern struct md_cluster_operations *md_cluster_ops;
+ static inline int mddev_is_clustered(struct mddev *mddev)
+ {
+ 	return mddev->cluster_info && mddev->bitmap_info.nodes > 1;
+ }
+ 
+ /* clear unsupported mddev_flags */
+ static inline void mddev_clear_unsupported_flags(struct mddev *mddev,
+ 	unsigned long unsupported_flags)
+ {
+ 	mddev->flags &= ~unsupported_flags;
+ }
++>>>>>>> 394ed8e4743b (md: cleanup mddev flag clear for takeover)
  #endif /* _MD_MD_H */
diff --cc drivers/md/raid0.c
index 5d0952d819f8,848365d474f3..000000000000
--- a/drivers/md/raid0.c
+++ b/drivers/md/raid0.c
@@@ -25,10 -26,10 +25,17 @@@
  #include "raid0.h"
  #include "raid5.h"
  
++<<<<<<< HEAD
 +static bool devices_discard_performance = false;
 +module_param(devices_discard_performance, bool, 0644);
 +MODULE_PARM_DESC(devices_discard_performance,
 +		 "Set to Y if all devices in each array handles discard requests at proper speed");
++=======
+ #define UNSUPPORTED_MDDEV_FLAGS		\
+ 	((1L << MD_HAS_JOURNAL) |	\
+ 	 (1L << MD_JOURNAL_CLEAN) |	\
+ 	 (1L << MD_FAILFAST_SUPPORTED))
++>>>>>>> 394ed8e4743b (md: cleanup mddev flag clear for takeover)
  
  static int raid0_congested(struct mddev *mddev, int bits)
  {
diff --cc drivers/md/raid5.c
index 91b644b32dcc,7b1da6e95a56..000000000000
--- a/drivers/md/raid5.c
+++ b/drivers/md/raid5.c
@@@ -61,8 -61,9 +61,10 @@@
  #include "raid5.h"
  #include "raid0.h"
  #include "bitmap.h"
 +#include "raid5-log.h"
  
+ #define UNSUPPORTED_MDDEV_FLAGS	(1L << MD_FAILFAST_SUPPORTED)
+ 
  #define cpu_to_group(cpu) cpu_to_node(cpu)
  #define ANY_GROUP NUMA_NO_NODE
  
@@@ -7944,8 -7831,9 +7946,14 @@@ static void *raid5_takeover_raid1(struc
  	mddev->new_chunk_sectors = chunksect;
  
  	ret = setup_conf(mddev);
++<<<<<<< HEAD
 +	if (!IS_ERR(ret))
 +		clear_bit(MD_FAILFAST_SUPPORTED, &mddev->flags);
++=======
+ 	if (!IS_ERR_VALUE(ret))
+ 		mddev_clear_unsupported_flags(mddev,
+ 			UNSUPPORTED_MDDEV_FLAGS);
++>>>>>>> 394ed8e4743b (md: cleanup mddev flag clear for takeover)
  	return ret;
  }
  
* Unmerged path drivers/md/md.h
* Unmerged path drivers/md/raid0.c
diff --git a/drivers/md/raid1.c b/drivers/md/raid1.c
index 481b2b2701df..e446acf17f1d 100644
--- a/drivers/md/raid1.c
+++ b/drivers/md/raid1.c
@@ -41,6 +41,10 @@
 #include "raid1.h"
 #include "bitmap.h"
 
+#define UNSUPPORTED_MDDEV_FLAGS		\
+	((1L << MD_HAS_JOURNAL) |	\
+	 (1L << MD_JOURNAL_CLEAN))
+
 /*
  * Number of guaranteed r1bios in case of extreme VM load:
  */
@@ -3335,8 +3339,8 @@ static void *raid1_takeover(struct mddev *mddev)
 		if (!IS_ERR(conf)) {
 			/* Array must appear to be quiesced */
 			conf->array_frozen = 1;
-			clear_bit(MD_HAS_JOURNAL, &mddev->flags);
-			clear_bit(MD_JOURNAL_CLEAN, &mddev->flags);
+			mddev_clear_unsupported_flags(mddev,
+				UNSUPPORTED_MDDEV_FLAGS);
 		}
 		return conf;
 	}
* Unmerged path drivers/md/raid5.c
