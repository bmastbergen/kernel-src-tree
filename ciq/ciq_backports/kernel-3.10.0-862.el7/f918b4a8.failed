scsi: cxlflash: Serialize RRQ access and support offlevel processing

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [scsi] cxlflash: Serialize RRQ access and support offlevel processing (Gustavo Duarte) [1456494]
Rebuild_FUZZ: 95.38%
commit-author Matthew R. Ochs <mrochs@linux.vnet.ibm.com>
commit f918b4a8e6f8bb59c44045f85d10fd9cc7e5a4c0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/f918b4a8.failed

As further staging to support processing the HRRQ by other means, access to
the HRRQ needs to be serialized by a disabled lock. This will allow safe
access in other non-hardware interrupt contexts. In an effort to minimize the
period where interrupts are disabled, support is added to queue up commands
harvested from the RRQ such that they can be processed with hardware
interrupts enabled. While this doesn't offer any improvement with processing
on a hardware interrupt it will help when IRQ polling is supported and the
command completions can execute on softirq context.

	Signed-off-by: Matthew R. Ochs <mrochs@linux.vnet.ibm.com>
	Signed-off-by: Uma Krishnan <ukrishn@linux.vnet.ibm.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit f918b4a8e6f8bb59c44045f85d10fd9cc7e5a4c0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/cxlflash/common.h
#	drivers/scsi/cxlflash/main.c
diff --cc drivers/scsi/cxlflash/common.h
index 811927d91c5c,9d56b8c797c4..000000000000
--- a/drivers/scsi/cxlflash/common.h
+++ b/drivers/scsi/cxlflash/common.h
@@@ -132,11 -131,10 +132,15 @@@ struct cxlflash_cfg 
  struct afu_cmd {
  	struct sisl_ioarcb rcb;	/* IOARCB (cache line aligned) */
  	struct sisl_ioasa sa;	/* IOASA must follow IOARCB */
 -	struct afu *parent;
 -	struct scsi_cmnd *scp;
 +	spinlock_t slock;
  	struct completion cevent;
++<<<<<<< HEAD
 +	struct afu *parent;
 +	int slot;
 +	atomic_t free;
++=======
+ 	struct list_head queue;
++>>>>>>> f918b4a8e6f8 (scsi: cxlflash: Serialize RRQ access and support offlevel processing)
  
  	u8 cmd_tmf:1;
  
@@@ -166,6 -176,13 +170,16 @@@ struct afu 
  	struct sisl_ctrl_map __iomem *ctrl_map;		/* MC control map */
  
  	ctx_hndl_t ctx_hndl;	/* master's context handle */
++<<<<<<< HEAD
++=======
+ 
+ 	atomic_t hsq_credits;
+ 	spinlock_t hsq_slock;
+ 	struct sisl_ioarcb *hsq_start;
+ 	struct sisl_ioarcb *hsq_end;
+ 	struct sisl_ioarcb *hsq_curr;
+ 	spinlock_t hrrq_slock;
++>>>>>>> f918b4a8e6f8 (scsi: cxlflash: Serialize RRQ access and support offlevel processing)
  	u64 *hrrq_start;
  	u64 *hrrq_end;
  	u64 *hrrq_curr;
diff --cc drivers/scsi/cxlflash/main.c
index c68badcfa77f,8c207ba8474b..000000000000
--- a/drivers/scsi/cxlflash/main.c
+++ b/drivers/scsi/cxlflash/main.c
@@@ -1210,6 -1155,80 +1210,83 @@@ cxlflash_sync_err_irq_exit
  }
  
  /**
++<<<<<<< HEAD
++=======
+  * process_hrrq() - process the read-response queue
+  * @afu:	AFU associated with the host.
+  * @doneq:	Queue of commands harvested from the RRQ.
+  *
+  * This routine must be called holding the disabled RRQ spin lock.
+  *
+  * Return: The number of entries processed.
+  */
+ static int process_hrrq(struct afu *afu, struct list_head *doneq)
+ {
+ 	struct afu_cmd *cmd;
+ 	struct sisl_ioasa *ioasa;
+ 	struct sisl_ioarcb *ioarcb;
+ 	bool toggle = afu->toggle;
+ 	int num_hrrq = 0;
+ 	u64 entry,
+ 	    *hrrq_start = afu->hrrq_start,
+ 	    *hrrq_end = afu->hrrq_end,
+ 	    *hrrq_curr = afu->hrrq_curr;
+ 
+ 	/* Process however many RRQ entries that are ready */
+ 	while (true) {
+ 		entry = *hrrq_curr;
+ 
+ 		if ((entry & SISL_RESP_HANDLE_T_BIT) != toggle)
+ 			break;
+ 
+ 		entry &= ~SISL_RESP_HANDLE_T_BIT;
+ 
+ 		if (afu_is_sq_cmd_mode(afu)) {
+ 			ioasa = (struct sisl_ioasa *)entry;
+ 			cmd = container_of(ioasa, struct afu_cmd, sa);
+ 		} else {
+ 			ioarcb = (struct sisl_ioarcb *)entry;
+ 			cmd = container_of(ioarcb, struct afu_cmd, rcb);
+ 		}
+ 
+ 		list_add_tail(&cmd->queue, doneq);
+ 
+ 		/* Advance to next entry or wrap and flip the toggle bit */
+ 		if (hrrq_curr < hrrq_end)
+ 			hrrq_curr++;
+ 		else {
+ 			hrrq_curr = hrrq_start;
+ 			toggle ^= SISL_RESP_HANDLE_T_BIT;
+ 		}
+ 
+ 		atomic_inc(&afu->hsq_credits);
+ 		num_hrrq++;
+ 	}
+ 
+ 	afu->hrrq_curr = hrrq_curr;
+ 	afu->toggle = toggle;
+ 
+ 	return num_hrrq;
+ }
+ 
+ /**
+  * process_cmd_doneq() - process a queue of harvested RRQ commands
+  * @doneq:	Queue of completed commands.
+  *
+  * Note that upon return the queue can no longer be trusted.
+  */
+ static void process_cmd_doneq(struct list_head *doneq)
+ {
+ 	struct afu_cmd *cmd, *tmp;
+ 
+ 	WARN_ON(list_empty(doneq));
+ 
+ 	list_for_each_entry_safe(cmd, tmp, doneq, queue)
+ 		cmd_complete(cmd);
+ }
+ 
+ /**
++>>>>>>> f918b4a8e6f8 (scsi: cxlflash: Serialize RRQ access and support offlevel processing)
   * cxlflash_rrq_irq() - interrupt handler for read-response queue (normal path)
   * @irq:	Interrupt number.
   * @data:	Private data provided at interrupt registration, the AFU.
@@@ -1219,35 -1238,18 +1296,50 @@@
  static irqreturn_t cxlflash_rrq_irq(int irq, void *data)
  {
  	struct afu *afu = (struct afu *)data;
++<<<<<<< HEAD
 +	struct afu_cmd *cmd;
 +	bool toggle = afu->toggle;
 +	u64 entry,
 +	    *hrrq_start = afu->hrrq_start,
 +	    *hrrq_end = afu->hrrq_end,
 +	    *hrrq_curr = afu->hrrq_curr;
 +
 +	/* Process however many RRQ entries that are ready */
 +	while (true) {
 +		entry = *hrrq_curr;
 +
 +		if ((entry & SISL_RESP_HANDLE_T_BIT) != toggle)
 +			break;
 +
 +		cmd = (struct afu_cmd *)(entry & ~SISL_RESP_HANDLE_T_BIT);
 +		cmd_complete(cmd);
 +
 +		/* Advance to next entry or wrap and flip the toggle bit */
 +		if (hrrq_curr < hrrq_end)
 +			hrrq_curr++;
 +		else {
 +			hrrq_curr = hrrq_start;
 +			toggle ^= SISL_RESP_HANDLE_T_BIT;
 +		}
 +	}
 +
 +	afu->hrrq_curr = hrrq_curr;
 +	afu->toggle = toggle;
 +
++=======
+ 	unsigned long hrrq_flags;
+ 	LIST_HEAD(doneq);
+ 	int num_entries = 0;
+ 
+ 	spin_lock_irqsave(&afu->hrrq_slock, hrrq_flags);
+ 	num_entries = process_hrrq(afu, &doneq);
+ 	spin_unlock_irqrestore(&afu->hrrq_slock, hrrq_flags);
+ 
+ 	if (num_entries == 0)
+ 		return IRQ_NONE;
+ 
+ 	process_cmd_doneq(&doneq);
++>>>>>>> f918b4a8e6f8 (scsi: cxlflash: Serialize RRQ access and support offlevel processing)
  	return IRQ_HANDLED;
  }
  
@@@ -1565,33 -1564,33 +1657,32 @@@ out
  static int start_afu(struct cxlflash_cfg *cfg)
  {
  	struct afu *afu = cfg->afu;
 -	struct device *dev = &cfg->dev->dev;
 +	struct afu_cmd *cmd;
 +
 +	int i = 0;
  	int rc = 0;
  
 +	for (i = 0; i < CXLFLASH_NUM_CMDS; i++) {
 +		cmd = &afu->cmd[i];
 +
 +		init_completion(&cmd->cevent);
 +		spin_lock_init(&cmd->slock);
 +		cmd->parent = afu;
 +	}
 +
  	init_pcr(cfg);
  
- 	/* After an AFU reset, RRQ entries are stale, clear them */
+ 	/* Initialize RRQ */
  	memset(&afu->rrq_entry, 0, sizeof(afu->rrq_entry));
- 
- 	/* Initialize RRQ pointers */
  	afu->hrrq_start = &afu->rrq_entry[0];
  	afu->hrrq_end = &afu->rrq_entry[NUM_RRQ_ENTRY - 1];
  	afu->hrrq_curr = afu->hrrq_start;
  	afu->toggle = 1;
+ 	spin_lock_init(&afu->hrrq_slock);
  
 -	/* Initialize SQ */
 -	if (afu_is_sq_cmd_mode(afu)) {
 -		memset(&afu->sq, 0, sizeof(afu->sq));
 -		afu->hsq_start = &afu->sq[0];
 -		afu->hsq_end = &afu->sq[NUM_SQ_ENTRY - 1];
 -		afu->hsq_curr = afu->hsq_start;
 -
 -		spin_lock_init(&afu->hsq_slock);
 -		atomic_set(&afu->hsq_credits, NUM_SQ_ENTRY - 1);
 -	}
 -
  	rc = init_global(cfg);
  
 -	dev_dbg(dev, "%s: returning rc=%d\n", __func__, rc);
 +	pr_debug("%s: returning rc=%d\n", __func__, rc);
  	return rc;
  }
  
* Unmerged path drivers/scsi/cxlflash/common.h
* Unmerged path drivers/scsi/cxlflash/main.c
