cpuset: refactor cpuset_hotplug_update_tasks()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Li Zefan <lizefan@huawei.com>
commit 390a36aadf39e241c83035469aae48ed1a144088
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/390a36aa.failed

We mix the handling for both default hierarchy and legacy hierarchy in
the same function, and it's quite messy, so split into two functions.

	Signed-off-by: Li Zefan <lizefan@huawei.com>
	Signed-off-by: Tejun Heo <tj@kernel.org>
(cherry picked from commit 390a36aadf39e241c83035469aae48ed1a144088)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/cpuset.c
diff --cc kernel/cpuset.c
index 650413f2caa8,41822e2027c1..000000000000
--- a/kernel/cpuset.c
+++ b/kernel/cpuset.c
@@@ -2099,9 -2151,6 +2158,12 @@@ static void cpuset_hotplug_update_tasks
  {
  	static cpumask_t off_cpus;
  	static nodemask_t off_mems;
++<<<<<<< HEAD
 +	bool is_empty;
 +	bool sane = cgroup_sane_behavior(cs->css.cgroup);
 +
++=======
++>>>>>>> 390a36aadf39 (cpuset: refactor cpuset_hotplug_update_tasks())
  retry:
  	wait_event(cpuset_attach_wq, cs->attach_in_progress == 0);
  
@@@ -2116,49 -2165,16 +2178,59 @@@
  		goto retry;
  	}
  
- 	cpumask_andnot(&off_cpus, cs->cpus_allowed, top_cpuset.cpus_allowed);
- 	nodes_andnot(off_mems, cs->mems_allowed, top_cpuset.mems_allowed);
+ 	cpumask_andnot(&off_cpus, cs->effective_cpus,
+ 		       top_cpuset.effective_cpus);
+ 	nodes_andnot(off_mems, cs->effective_mems, top_cpuset.effective_mems);
  
++<<<<<<< HEAD
 +	mutex_lock(&callback_mutex);
 +	cpumask_andnot(cs->cpus_allowed, cs->cpus_allowed, &off_cpus);
 +	cpumask_andnot(cs->effective_cpus, cs->effective_cpus, &off_cpus);
 +	mutex_unlock(&callback_mutex);
 +
 +	/*
 +	 * If sane_behavior flag is set, we need to update tasks' cpumask
 +	 * for empty cpuset to take on ancestor's cpumask.
 +	 */
 +	if ((sane && cpumask_empty(cs->cpus_allowed)) ||
 +	    !cpumask_empty(&off_cpus))
 +		update_tasks_cpumask(cs, NULL);
 +
 +	mutex_lock(&callback_mutex);
 +	nodes_andnot(cs->mems_allowed, cs->mems_allowed, off_mems);
 +	nodes_andnot(cs->effective_mems, cs->effective_mems, off_mems);
 +	mutex_unlock(&callback_mutex);
 +
 +	/*
 +	 * If sane_behavior flag is set, we need to update tasks' nodemask
 +	 * for empty cpuset to take on ancestor's nodemask.
 +	 */
 +	if ((sane && nodes_empty(cs->mems_allowed)) ||
 +	    !nodes_empty(off_mems))
 +		update_tasks_nodemask(cs, NULL);
 +
 +	is_empty = cpumask_empty(cs->cpus_allowed) ||
 +		nodes_empty(cs->mems_allowed);
 +
 +	mutex_unlock(&cpuset_mutex);
 +
 +	/*
 +	 * If sane_behavior flag is set, we'll keep tasks in empty cpusets.
 +	 *
 +	 * Otherwise move tasks to the nearest ancestor with execution
 +	 * resources.  This is full cgroup operation which will
 +	 * also call back into cpuset.  Should be done outside any lock.
 +	 */
 +	if (!sane && is_empty)
 +		remove_tasks_in_empty_cpuset(cs);
++=======
+ 	if (cgroup_on_dfl(cs->css.cgroup))
+ 		hotplug_update_tasks(cs, &off_cpus, &off_mems);
+ 	else
+ 		hotplug_update_tasks_legacy(cs, &off_cpus, &off_mems);
+ 
+ 	mutex_unlock(&cpuset_mutex);
++>>>>>>> 390a36aadf39 (cpuset: refactor cpuset_hotplug_update_tasks())
  }
  
  /**
* Unmerged path kernel/cpuset.c
