filesystem-dax: fix broken __dax_zero_page_range() conversion

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Dan Williams <dan.j.williams@intel.com>
commit e84b83b9ee2187817cf895471675f1ccdf64cd53
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/e84b83b9.failed

The conversion of __dax_zero_page_range() to 'struct dax_operations'
caused it to frequently fail. The mistake was treating the @size
parameter as a dax mapping length rather than just a length of the
clear_pmem() operation. The dax mapping length is assumed to be hard
coded as PAGE_SIZE.

Without this fix any page unaligned zeroing request will trigger a
-EINVAL return from bdev_dax_pgoff().

	Cc: Jan Kara <jack@suse.com>
	Cc: Christoph Hellwig <hch@lst.de>
	Reported-by: Ross Zwisler <ross.zwisler@linux.intel.com>
	Tested-by: Ross Zwisler <ross.zwisler@linux.intel.com>
Fixes: cccbce671582 ("filesystem-dax: convert to dax_direct_access()")
	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
(cherry picked from commit e84b83b9ee2187817cf895471675f1ccdf64cd53)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/dax.c
diff --cc fs/dax.c
index fa7935571d11,5ee1d212d81f..000000000000
--- a/fs/dax.c
+++ b/fs/dax.c
@@@ -962,28 -956,34 +962,49 @@@ static bool dax_range_is_aligned(struc
  	return true;
  }
  
 -int __dax_zero_page_range(struct block_device *bdev,
 -		struct dax_device *dax_dev, sector_t sector,
 -		unsigned int offset, unsigned int size)
 +int __dax_zero_page_range(struct block_device *bdev, sector_t sector,
 +		unsigned int offset, unsigned int length)
  {
 -	if (dax_range_is_aligned(bdev, offset, size)) {
 -		sector_t start_sector = sector + (offset >> 9);
 +	struct blk_dax_ctl dax = {
 +		.sector		= sector,
 +		.size		= PAGE_CACHE_SIZE,
 +	};
 +
 +	if (dax_map_atomic(bdev, &dax) < 0)
 +		return PTR_ERR(dax.addr);
 +	clear_pmem(dax.addr + offset, length);
 +	dax_unmap_atomic(bdev, &dax);
 +	if (dax_range_is_aligned(bdev, offset, length)) {
 +		sector_t start_sector = dax.sector + (offset >> 9);
  
  		return blkdev_issue_zeroout(bdev, start_sector,
 -				size >> 9, GFP_NOFS, true);
 +				length >> 9, GFP_NOFS);
  	} else {
++<<<<<<< HEAD
 +		if (dax_map_atomic(bdev, &dax) < 0)
 +			return PTR_ERR(dax.addr);
 +		clear_pmem(dax.addr + offset, length);
 +		dax_unmap_atomic(bdev, &dax);
++=======
+ 		pgoff_t pgoff;
+ 		long rc, id;
+ 		void *kaddr;
+ 		pfn_t pfn;
+ 
+ 		rc = bdev_dax_pgoff(bdev, sector, PAGE_SIZE, &pgoff);
+ 		if (rc)
+ 			return rc;
+ 
+ 		id = dax_read_lock();
+ 		rc = dax_direct_access(dax_dev, pgoff, 1, &kaddr,
+ 				&pfn);
+ 		if (rc < 0) {
+ 			dax_read_unlock(id);
+ 			return rc;
+ 		}
+ 		clear_pmem(kaddr + offset, size);
+ 		dax_read_unlock(id);
++>>>>>>> e84b83b9ee21 (filesystem-dax: fix broken __dax_zero_page_range() conversion)
  	}
  	return 0;
  }
* Unmerged path fs/dax.c
