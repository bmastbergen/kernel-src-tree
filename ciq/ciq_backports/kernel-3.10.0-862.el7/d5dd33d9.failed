cpufreq: intel_pstate: increase precision of performance limits

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [cpufreq] intel_pstate: increase precision of performance limits (Prarit Bhargava) [1465349]
Rebuild_FUZZ: 92.31%
commit-author Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
commit d5dd33d9de0d50db7f3ba221f9c4e4f74e61a69d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/d5dd33d9.failed

Even with round up of limits->min_perf and limits->max_perf, in some
cases resultant performance is 100 MHz less than the desired.

For example when the maximum frequency is 3.50 GHz, setting
scaling_min_frequency to 2.3 GHz always results in 2.2 GHz minimum.

Currently the fixed floating point operation uses 8 bit precision for
calculating limits->min_perf and limits->max_perf. For some operations
in this driver the 14 bit precision is used. Using the 14 bit precision
also for calculating limits->min_perf and limits->max_perf, addresses
this issue.

Introduced fp_ext_toint() equivalent to fp_toint() and int_ext_tofp()
equivalent to int_tofp() with 14 bit precision.

	Signed-off-by: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
(cherry picked from commit d5dd33d9de0d50db7f3ba221f9c4e4f74e61a69d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/intel_pstate.c
diff --cc drivers/cpufreq/intel_pstate.c
index e7b574938221,7159dbde0160..000000000000
--- a/drivers/cpufreq/intel_pstate.c
+++ b/drivers/cpufreq/intel_pstate.c
@@@ -46,6 -52,11 +46,14 @@@
  #define int_tofp(X) ((int64_t)(X) << FRAC_BITS)
  #define fp_toint(X) ((X) >> FRAC_BITS)
  
++<<<<<<< HEAD
++=======
+ #define EXT_BITS 6
+ #define EXT_FRAC_BITS (EXT_BITS + FRAC_BITS)
+ #define fp_ext_toint(X) ((X) >> EXT_FRAC_BITS)
+ #define int_ext_tofp(X) ((int64_t)(X) << EXT_FRAC_BITS)
+ 
++>>>>>>> d5dd33d9de0d (cpufreq: intel_pstate: increase precision of performance limits)
  static inline int32_t mul_fp(int32_t x, int32_t y)
  {
  	return ((int64_t)x * (int64_t)y) >> FRAC_BITS;
@@@ -731,8 -778,9 +739,14 @@@ static ssize_t store_max_perf_pct(struc
  				   limits->max_perf_pct);
  	limits->max_perf_pct = max(limits->min_perf_pct,
  				   limits->max_perf_pct);
++<<<<<<< HEAD
 +	limits->max_perf = div_fp(int_tofp(limits->max_perf_pct),
 +				  int_tofp(100));
++=======
+ 	limits->max_perf = div_ext_fp(limits->max_perf_pct, 100);
+ 
+ 	mutex_unlock(&intel_pstate_limits_lock);
++>>>>>>> d5dd33d9de0d (cpufreq: intel_pstate: increase precision of performance limits)
  
  	if (hwp_active)
  		intel_pstate_hwp_set_online_cpus();
@@@ -756,8 -806,9 +770,14 @@@ static ssize_t store_min_perf_pct(struc
  				   limits->min_perf_pct);
  	limits->min_perf_pct = min(limits->max_perf_pct,
  				   limits->min_perf_pct);
++<<<<<<< HEAD
 +	limits->min_perf = div_fp(int_tofp(limits->min_perf_pct),
 +				  int_tofp(100));
++=======
+ 	limits->min_perf = div_ext_fp(limits->min_perf_pct, 100);
+ 
+ 	mutex_unlock(&intel_pstate_limits_lock);
++>>>>>>> d5dd33d9de0d (cpufreq: intel_pstate: increase precision of performance limits)
  
  	if (hwp_active)
  		intel_pstate_hwp_set_online_cpus();
@@@ -1086,11 -1191,11 +1106,19 @@@ static void intel_pstate_get_min_max(st
  	 * policy, or by cpu specific default values determined through
  	 * experimentation.
  	 */
++<<<<<<< HEAD
 +	max_perf_adj = fp_toint(max_perf * limits->max_perf);
 +	*max = clamp_t(int, max_perf_adj,
 +			cpu->pstate.min_pstate, cpu->pstate.turbo_pstate);
 +
 +	min_perf = fp_toint(max_perf * limits->min_perf);
++=======
+ 	max_perf_adj = fp_ext_toint(max_perf * perf_limits->max_perf);
+ 	*max = clamp_t(int, max_perf_adj,
+ 			cpu->pstate.min_pstate, cpu->pstate.turbo_pstate);
+ 
+ 	min_perf = fp_ext_toint(max_perf * perf_limits->min_perf);
++>>>>>>> d5dd33d9de0d (cpufreq: intel_pstate: increase precision of performance limits)
  	*min = clamp_t(int, min_perf, cpu->pstate.min_pstate, max_perf);
  }
  
@@@ -1406,40 -1526,70 +1434,83 @@@ static int intel_pstate_init_cpu(unsign
  
  static unsigned int intel_pstate_get(unsigned int cpu_num)
  {
 -	struct cpudata *cpu = all_cpu_data[cpu_num];
 +	struct sample *sample;
 +	struct cpudata *cpu;
  
 -	return cpu ? get_avg_frequency(cpu) : 0;
 +	cpu = all_cpu_data[cpu_num];
 +	if (!cpu)
 +		return 0;
 +	sample = &cpu->sample;
 +	return sample->freq;
  }
  
 -static void intel_pstate_set_update_util_hook(unsigned int cpu_num)
 +static int intel_pstate_set_policy(struct cpufreq_policy *policy)
  {
 -	struct cpudata *cpu = all_cpu_data[cpu_num];
 +	if (!policy->cpuinfo.max_freq)
 +		return -ENODEV;
  
 -	if (cpu->update_util_set)
 -		return;
 +	pr_debug("set_policy cpuinfo.max %u policy->max %u\n",
 +		 policy->cpuinfo.max_freq, policy->max);
  
++<<<<<<< HEAD
 +	if (policy->policy == CPUFREQ_POLICY_PERFORMANCE &&
 +	    policy->max >= policy->cpuinfo.max_freq) {
 +		pr_debug("intel_pstate: set performance\n");
 +		limits = &performance_limits;
 +		if (hwp_active)
 +			intel_pstate_hwp_set(policy->cpus);
 +		return 0;
 +	}
++=======
+ 	/* Prevent intel_pstate_update_util() from using stale data. */
+ 	cpu->sample.time = 0;
+ 	cpufreq_add_update_util_hook(cpu_num, &cpu->update_util,
+ 				     intel_pstate_update_util);
+ 	cpu->update_util_set = true;
+ }
+ 
+ static void intel_pstate_clear_update_util_hook(unsigned int cpu)
+ {
+ 	struct cpudata *cpu_data = all_cpu_data[cpu];
+ 
+ 	if (!cpu_data->update_util_set)
+ 		return;
+ 
+ 	cpufreq_remove_update_util_hook(cpu);
+ 	cpu_data->update_util_set = false;
+ 	synchronize_sched();
+ }
+ 
+ static void intel_pstate_set_performance_limits(struct perf_limits *limits)
+ {
+ 	mutex_lock(&intel_pstate_limits_lock);
+ 	limits->no_turbo = 0;
+ 	limits->turbo_disabled = 0;
+ 	limits->max_perf_pct = 100;
+ 	limits->max_perf = int_ext_tofp(1);
+ 	limits->min_perf_pct = 100;
+ 	limits->min_perf = int_ext_tofp(1);
+ 	limits->max_policy_pct = 100;
+ 	limits->max_sysfs_pct = 100;
+ 	limits->min_policy_pct = 0;
+ 	limits->min_sysfs_pct = 0;
+ 	mutex_unlock(&intel_pstate_limits_lock);
+ }
+ 
+ static void intel_pstate_update_perf_limits(struct cpufreq_policy *policy,
+ 					    struct perf_limits *limits)
+ {
+ 
+ 	mutex_lock(&intel_pstate_limits_lock);
++>>>>>>> d5dd33d9de0d (cpufreq: intel_pstate: increase precision of performance limits)
  
 +	pr_debug("intel_pstate: set powersave\n");
 +	limits = &powersave_limits;
 +	limits->min_policy_pct = (policy->min * 100) / policy->cpuinfo.max_freq;
 +	limits->min_policy_pct = clamp_t(int, limits->min_policy_pct, 0 , 100);
  	limits->max_policy_pct = DIV_ROUND_UP(policy->max * 100,
  					      policy->cpuinfo.max_freq);
 -	limits->max_policy_pct = clamp_t(int, limits->max_policy_pct, 0, 100);
 -	if (policy->max == policy->min) {
 -		limits->min_policy_pct = limits->max_policy_pct;
 -	} else {
 -		limits->min_policy_pct = DIV_ROUND_UP(policy->min * 100,
 -						      policy->cpuinfo.max_freq);
 -		limits->min_policy_pct = clamp_t(int, limits->min_policy_pct,
 -						 0, 100);
 -	}
 +	limits->max_policy_pct = clamp_t(int, limits->max_policy_pct, 0 , 100);
  
  	/* Normalize user input to [min_policy_pct, max_policy_pct] */
  	limits->min_perf_pct = max(limits->min_policy_pct,
@@@ -1454,14 -1604,74 +1525,21 @@@
  	/* Make sure min_perf_pct <= max_perf_pct */
  	limits->min_perf_pct = min(limits->max_perf_pct, limits->min_perf_pct);
  
++<<<<<<< HEAD
 +	limits->min_perf = div_fp(int_tofp(limits->min_perf_pct),
 +				  int_tofp(100));
 +	limits->max_perf = div_fp(int_tofp(limits->max_perf_pct),
 +				  int_tofp(100));
 +	limits->max_perf = round_up(limits->max_perf, FRAC_BITS);
++=======
+ 	limits->min_perf = div_ext_fp(limits->min_perf_pct, 100);
+ 	limits->max_perf = div_ext_fp(limits->max_perf_pct, 100);
+ 	limits->max_perf = round_up(limits->max_perf, EXT_FRAC_BITS);
+ 	limits->min_perf = round_up(limits->min_perf, EXT_FRAC_BITS);
++>>>>>>> d5dd33d9de0d (cpufreq: intel_pstate: increase precision of performance limits)
  
 -	mutex_unlock(&intel_pstate_limits_lock);
 -
 -	pr_debug("cpu:%d max_perf_pct:%d min_perf_pct:%d\n", policy->cpu,
 -		 limits->max_perf_pct, limits->min_perf_pct);
 -}
 -
 -static int intel_pstate_set_policy(struct cpufreq_policy *policy)
 -{
 -	struct cpudata *cpu;
 -	struct perf_limits *perf_limits = NULL;
 -
 -	if (!policy->cpuinfo.max_freq)
 -		return -ENODEV;
 -
 -	pr_debug("set_policy cpuinfo.max %u policy->max %u\n",
 -		 policy->cpuinfo.max_freq, policy->max);
 -
 -	cpu = all_cpu_data[policy->cpu];
 -	cpu->policy = policy->policy;
 -
 -	if (cpu->pstate.max_pstate_physical > cpu->pstate.max_pstate &&
 -	    policy->max < policy->cpuinfo.max_freq &&
 -	    policy->max > cpu->pstate.max_pstate * cpu->pstate.scaling) {
 -		pr_debug("policy->max > max non turbo frequency\n");
 -		policy->max = policy->cpuinfo.max_freq;
 -	}
 -
 -	if (per_cpu_limits)
 -		perf_limits = cpu->perf_limits;
 -
 -	if (policy->policy == CPUFREQ_POLICY_PERFORMANCE) {
 -		if (!perf_limits) {
 -			limits = &performance_limits;
 -			perf_limits = limits;
 -		}
 -		if (policy->max >= policy->cpuinfo.max_freq) {
 -			pr_debug("set performance\n");
 -			intel_pstate_set_performance_limits(perf_limits);
 -			goto out;
 -		}
 -	} else {
 -		pr_debug("set powersave\n");
 -		if (!perf_limits) {
 -			limits = &powersave_limits;
 -			perf_limits = limits;
 -		}
 -
 -	}
 -
 -	intel_pstate_update_perf_limits(policy, perf_limits);
 - out:
 -	if (cpu->policy == CPUFREQ_POLICY_PERFORMANCE) {
 -		/*
 -		 * NOHZ_FULL CPUs need this as the governor callback may not
 -		 * be invoked on them.
 -		 */
 -		intel_pstate_clear_update_util_hook(policy->cpu);
 -		intel_pstate_max_within_limits(cpu);
 -	}
 -
 -	intel_pstate_set_update_util_hook(policy->cpu);
 -
 -	intel_pstate_hwp_set_policy(policy);
 +	if (hwp_active)
 +		intel_pstate_hwp_set(policy->cpus);
  
  	return 0;
  }
* Unmerged path drivers/cpufreq/intel_pstate.c
