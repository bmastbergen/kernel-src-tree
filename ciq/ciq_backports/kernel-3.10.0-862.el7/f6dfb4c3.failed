net/mlx5e: Update neighbour 'used' state using HW flow rules counters

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [kernel] [netdrv] mlx5e: Update neighbour 'used' state using HW flow rules counters (Don Dutile) [1456687 1499362]
Rebuild_FUZZ: 97.01%
commit-author Hadar Hen Zion <hadarh@mellanox.com>
commit f6dfb4c3f2161c23ab2939dd1b5f133dcdf147c6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/f6dfb4c3.failed

When IP tunnel encapsulation rules are offloaded, the kernel can't see
the traffic of the offloaded flow. The neighbour for the IP tunnel
destination of the offloaded flow can mistakenly become STALE and
deleted by the kernel since its 'used' value wasn't changed.

To make sure that a neighbour which is used by the HW won't become
STALE, we proactively update the neighbour 'used' value every
DELAY_PROBE_TIME period, when packets were matched and counted by the HW
for one of the tunnel encap flows related to this neighbour.

The periodic task that updates the used neighbours is scheduled when a
tunnel encap rule is successfully offloaded into HW and keeps re-scheduling
itself as long as the representor's neighbours list isn't empty.

Add, remove, lookup and status change operations done over the
representor's neighbours list or the neighbour hash entry encaps list
are all serialized by RTNL lock.

	Signed-off-by: Hadar Hen Zion <hadarh@mellanox.com>
	Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit f6dfb4c3f2161c23ab2939dd1b5f133dcdf147c6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
index abcb1976163d,af61b10b85bf..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
@@@ -37,7 -37,11 +37,8 @@@
  
  #include "eswitch.h"
  #include "en.h"
 -#include "en_rep.h"
  #include "en_tc.h"
+ #include "fs_core.h"
  
  static const char mlx5e_rep_driver_name[] = "mlx5e_rep";
  
@@@ -224,18 -227,343 +225,264 @@@ void mlx5e_remove_sqs_fwd_rules(struct 
  	mlx5_eswitch_sqs2vport_stop(esw, rep);
  }
  
++<<<<<<< HEAD
 +void mlx5e_nic_rep_unload(struct mlx5_eswitch *esw,
 +			  struct mlx5_eswitch_rep *rep)
++=======
+ static void mlx5e_rep_neigh_update_init_interval(struct mlx5e_rep_priv *rpriv)
+ {
+ #if IS_ENABLED(CONFIG_IPV6)
+ 	unsigned long ipv6_interval = NEIGH_VAR(&ipv6_stub->nd_tbl->parms,
+ 						DELAY_PROBE_TIME);
+ #else
+ 	unsigned long ipv6_interval = ~0UL;
+ #endif
+ 	unsigned long ipv4_interval = NEIGH_VAR(&arp_tbl.parms,
+ 						DELAY_PROBE_TIME);
+ 	struct net_device *netdev = rpriv->rep->netdev;
+ 	struct mlx5e_priv *priv = netdev_priv(netdev);
+ 
+ 	rpriv->neigh_update.min_interval = min_t(unsigned long, ipv6_interval, ipv4_interval);
+ 	mlx5_fc_update_sampling_interval(priv->mdev, rpriv->neigh_update.min_interval);
+ }
+ 
+ void mlx5e_rep_queue_neigh_stats_work(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_rep_priv *rpriv = priv->ppriv;
+ 	struct mlx5e_neigh_update_table *neigh_update = &rpriv->neigh_update;
+ 
+ 	mlx5_fc_queue_stats_work(priv->mdev,
+ 				 &neigh_update->neigh_stats_work,
+ 				 neigh_update->min_interval);
+ }
+ 
+ static void mlx5e_rep_neigh_stats_work(struct work_struct *work)
+ {
+ 	struct mlx5e_rep_priv *rpriv = container_of(work, struct mlx5e_rep_priv,
+ 						    neigh_update.neigh_stats_work.work);
+ 	struct net_device *netdev = rpriv->rep->netdev;
+ 	struct mlx5e_priv *priv = netdev_priv(netdev);
+ 	struct mlx5e_neigh_hash_entry *nhe;
+ 
+ 	rtnl_lock();
+ 	if (!list_empty(&rpriv->neigh_update.neigh_list))
+ 		mlx5e_rep_queue_neigh_stats_work(priv);
+ 
+ 	list_for_each_entry(nhe, &rpriv->neigh_update.neigh_list, neigh_list)
+ 		mlx5e_tc_update_neigh_used_value(nhe);
+ 
+ 	rtnl_unlock();
+ }
+ 
+ static void mlx5e_rep_neigh_entry_hold(struct mlx5e_neigh_hash_entry *nhe)
++>>>>>>> f6dfb4c3f216 (net/mlx5e: Update neighbour 'used' state using HW flow rules counters)
  {
 -	refcount_inc(&nhe->refcnt);
 -}
 -
 -static void mlx5e_rep_neigh_entry_release(struct mlx5e_neigh_hash_entry *nhe)
 -{
 -	if (refcount_dec_and_test(&nhe->refcnt))
 -		kfree(nhe);
 -}
 -
 -static void mlx5e_rep_update_flows(struct mlx5e_priv *priv,
 -				   struct mlx5e_encap_entry *e,
 -				   bool neigh_connected,
 -				   unsigned char ha[ETH_ALEN])
 -{
 -	struct ethhdr *eth = (struct ethhdr *)e->encap_header;
 -
 -	ASSERT_RTNL();
 -
 -	if ((!neigh_connected && (e->flags & MLX5_ENCAP_ENTRY_VALID)) ||
 -	    !ether_addr_equal(e->h_dest, ha))
 -		mlx5e_tc_encap_flows_del(priv, e);
 -
 -	if (neigh_connected && !(e->flags & MLX5_ENCAP_ENTRY_VALID)) {
 -		ether_addr_copy(e->h_dest, ha);
 -		ether_addr_copy(eth->h_dest, ha);
 -
 -		mlx5e_tc_encap_flows_add(priv, e);
 -	}
 -}
 -
 -static void mlx5e_rep_neigh_update(struct work_struct *work)
 -{
 -	struct mlx5e_neigh_hash_entry *nhe =
 -		container_of(work, struct mlx5e_neigh_hash_entry, neigh_update_work);
 -	struct neighbour *n = nhe->n;
 -	struct mlx5e_encap_entry *e;
 -	unsigned char ha[ETH_ALEN];
 -	struct mlx5e_priv *priv;
 -	bool neigh_connected;
 -	bool encap_connected;
 -	u8 nud_state, dead;
 -
 -	rtnl_lock();
 -
 -	/* If these parameters are changed after we release the lock,
 -	 * we'll receive another event letting us know about it.
 -	 * We use this lock to avoid inconsistency between the neigh validity
 -	 * and it's hw address.
 -	 */
 -	read_lock_bh(&n->lock);
 -	memcpy(ha, n->ha, ETH_ALEN);
 -	nud_state = n->nud_state;
 -	dead = n->dead;
 -	read_unlock_bh(&n->lock);
 -
 -	neigh_connected = (nud_state & NUD_VALID) && !dead;
 -
 -	list_for_each_entry(e, &nhe->encap_list, encap_list) {
 -		encap_connected = !!(e->flags & MLX5_ENCAP_ENTRY_VALID);
 -		priv = netdev_priv(e->out_dev);
 -
 -		if (encap_connected != neigh_connected ||
 -		    !ether_addr_equal(e->h_dest, ha))
 -			mlx5e_rep_update_flows(priv, e, neigh_connected, ha);
 -	}
 -	mlx5e_rep_neigh_entry_release(nhe);
 -	rtnl_unlock();
 -	neigh_release(n);
 -}
 -
 -static struct mlx5e_neigh_hash_entry *
 -mlx5e_rep_neigh_entry_lookup(struct mlx5e_priv *priv,
 -			     struct mlx5e_neigh *m_neigh);
 -
 -static int mlx5e_rep_netevent_event(struct notifier_block *nb,
 -				    unsigned long event, void *ptr)
 -{
 -	struct mlx5e_rep_priv *rpriv = container_of(nb, struct mlx5e_rep_priv,
 -						    neigh_update.netevent_nb);
 -	struct mlx5e_neigh_update_table *neigh_update = &rpriv->neigh_update;
 -	struct net_device *netdev = rpriv->rep->netdev;
 +	struct net_device *netdev = rep->netdev;
  	struct mlx5e_priv *priv = netdev_priv(netdev);
 -	struct mlx5e_neigh_hash_entry *nhe = NULL;
 -	struct mlx5e_neigh m_neigh = {};
 -	struct neighbour *n;
  
 -	switch (event) {
 -	case NETEVENT_NEIGH_UPDATE:
 -		n = ptr;
 -#if IS_ENABLED(CONFIG_IPV6)
 -		if (n->tbl != ipv6_stub->nd_tbl && n->tbl != &arp_tbl)
 -#else
 -		if (n->tbl != &arp_tbl)
 -#endif
 -			return NOTIFY_DONE;
 +	if (test_bit(MLX5E_STATE_OPENED, &priv->state))
 +		mlx5e_remove_sqs_fwd_rules(priv);
  
++<<<<<<< HEAD
 +	/* clean (and re-init) existing uplink offloaded TC rules */
 +	mlx5e_tc_cleanup(priv);
 +	mlx5e_tc_init(priv);
++=======
+ 		m_neigh.dev = n->dev;
+ 		m_neigh.family = n->ops->family;
+ 		memcpy(&m_neigh.dst_ip, n->primary_key, n->tbl->key_len);
+ 
+ 		/* We are in atomic context and can't take RTNL mutex, so use
+ 		 * spin_lock_bh to lookup the neigh table. bh is used since
+ 		 * netevent can be called from a softirq context.
+ 		 */
+ 		spin_lock_bh(&neigh_update->encap_lock);
+ 		nhe = mlx5e_rep_neigh_entry_lookup(priv, &m_neigh);
+ 		if (!nhe) {
+ 			spin_unlock_bh(&neigh_update->encap_lock);
+ 			return NOTIFY_DONE;
+ 		}
+ 
+ 		/* This assignment is valid as long as the the neigh reference
+ 		 * is taken
+ 		 */
+ 		nhe->n = n;
+ 
+ 		/* Take a reference to ensure the neighbour and mlx5 encap
+ 		 * entry won't be destructed until we drop the reference in
+ 		 * delayed work.
+ 		 */
+ 		neigh_hold(n);
+ 		mlx5e_rep_neigh_entry_hold(nhe);
+ 
+ 		if (!queue_work(priv->wq, &nhe->neigh_update_work)) {
+ 			mlx5e_rep_neigh_entry_release(nhe);
+ 			neigh_release(n);
+ 		}
+ 		spin_unlock_bh(&neigh_update->encap_lock);
+ 		break;
+ 	}
+ 	return NOTIFY_DONE;
+ }
+ 
+ static const struct rhashtable_params mlx5e_neigh_ht_params = {
+ 	.head_offset = offsetof(struct mlx5e_neigh_hash_entry, rhash_node),
+ 	.key_offset = offsetof(struct mlx5e_neigh_hash_entry, m_neigh),
+ 	.key_len = sizeof(struct mlx5e_neigh),
+ 	.automatic_shrinking = true,
+ };
+ 
+ static int mlx5e_rep_neigh_init(struct mlx5e_rep_priv *rpriv)
+ {
+ 	struct mlx5e_neigh_update_table *neigh_update = &rpriv->neigh_update;
+ 	int err;
+ 
+ 	err = rhashtable_init(&neigh_update->neigh_ht, &mlx5e_neigh_ht_params);
+ 	if (err)
+ 		return err;
+ 
+ 	INIT_LIST_HEAD(&neigh_update->neigh_list);
+ 	spin_lock_init(&neigh_update->encap_lock);
+ 	INIT_DELAYED_WORK(&neigh_update->neigh_stats_work,
+ 			  mlx5e_rep_neigh_stats_work);
+ 	mlx5e_rep_neigh_update_init_interval(rpriv);
+ 
+ 	rpriv->neigh_update.netevent_nb.notifier_call = mlx5e_rep_netevent_event;
+ 	err = register_netevent_notifier(&rpriv->neigh_update.netevent_nb);
+ 	if (err)
+ 		goto out_err;
+ 	return 0;
+ 
+ out_err:
+ 	rhashtable_destroy(&neigh_update->neigh_ht);
+ 	return err;
+ }
+ 
+ static void mlx5e_rep_neigh_cleanup(struct mlx5e_rep_priv *rpriv)
+ {
+ 	struct mlx5e_neigh_update_table *neigh_update = &rpriv->neigh_update;
+ 	struct mlx5e_priv *priv = netdev_priv(rpriv->rep->netdev);
+ 
+ 	unregister_netevent_notifier(&neigh_update->netevent_nb);
+ 
+ 	flush_workqueue(priv->wq); /* flush neigh update works */
+ 
+ 	cancel_delayed_work_sync(&rpriv->neigh_update.neigh_stats_work);
+ 
+ 	rhashtable_destroy(&neigh_update->neigh_ht);
+ }
+ 
+ static int mlx5e_rep_neigh_entry_insert(struct mlx5e_priv *priv,
+ 					struct mlx5e_neigh_hash_entry *nhe)
+ {
+ 	struct mlx5e_rep_priv *rpriv = priv->ppriv;
+ 	int err;
+ 
+ 	err = rhashtable_insert_fast(&rpriv->neigh_update.neigh_ht,
+ 				     &nhe->rhash_node,
+ 				     mlx5e_neigh_ht_params);
+ 	if (err)
+ 		return err;
+ 
+ 	list_add(&nhe->neigh_list, &rpriv->neigh_update.neigh_list);
+ 
+ 	return err;
+ }
+ 
+ static void mlx5e_rep_neigh_entry_remove(struct mlx5e_priv *priv,
+ 					 struct mlx5e_neigh_hash_entry *nhe)
+ {
+ 	struct mlx5e_rep_priv *rpriv = priv->ppriv;
+ 
+ 	spin_lock_bh(&rpriv->neigh_update.encap_lock);
+ 
+ 	list_del(&nhe->neigh_list);
+ 
+ 	rhashtable_remove_fast(&rpriv->neigh_update.neigh_ht,
+ 			       &nhe->rhash_node,
+ 			       mlx5e_neigh_ht_params);
+ 	spin_unlock_bh(&rpriv->neigh_update.encap_lock);
+ }
+ 
+ /* This function must only be called under RTNL lock or under the
+  * representor's encap_lock in case RTNL mutex can't be held.
+  */
+ static struct mlx5e_neigh_hash_entry *
+ mlx5e_rep_neigh_entry_lookup(struct mlx5e_priv *priv,
+ 			     struct mlx5e_neigh *m_neigh)
+ {
+ 	struct mlx5e_rep_priv *rpriv = priv->ppriv;
+ 	struct mlx5e_neigh_update_table *neigh_update = &rpriv->neigh_update;
+ 
+ 	return rhashtable_lookup_fast(&neigh_update->neigh_ht, m_neigh,
+ 				      mlx5e_neigh_ht_params);
+ }
+ 
+ static int mlx5e_rep_neigh_entry_create(struct mlx5e_priv *priv,
+ 					struct mlx5e_encap_entry *e,
+ 					struct mlx5e_neigh_hash_entry **nhe)
+ {
+ 	int err;
+ 
+ 	*nhe = kzalloc(sizeof(**nhe), GFP_KERNEL);
+ 	if (!*nhe)
+ 		return -ENOMEM;
+ 
+ 	memcpy(&(*nhe)->m_neigh, &e->m_neigh, sizeof(e->m_neigh));
+ 	INIT_WORK(&(*nhe)->neigh_update_work, mlx5e_rep_neigh_update);
+ 	INIT_LIST_HEAD(&(*nhe)->encap_list);
+ 	refcount_set(&(*nhe)->refcnt, 1);
+ 
+ 	err = mlx5e_rep_neigh_entry_insert(priv, *nhe);
+ 	if (err)
+ 		goto out_free;
+ 	return 0;
+ 
+ out_free:
+ 	kfree(*nhe);
+ 	return err;
+ }
+ 
+ static void mlx5e_rep_neigh_entry_destroy(struct mlx5e_priv *priv,
+ 					  struct mlx5e_neigh_hash_entry *nhe)
+ {
+ 	/* The neigh hash entry must be removed from the hash table regardless
+ 	 * of the reference count value, so it won't be found by the next
+ 	 * neigh notification call. The neigh hash entry reference count is
+ 	 * incremented only during creation and neigh notification calls and
+ 	 * protects from freeing the nhe struct.
+ 	 */
+ 	mlx5e_rep_neigh_entry_remove(priv, nhe);
+ 	mlx5e_rep_neigh_entry_release(nhe);
+ }
+ 
+ int mlx5e_rep_encap_entry_attach(struct mlx5e_priv *priv,
+ 				 struct mlx5e_encap_entry *e)
+ {
+ 	struct mlx5e_neigh_hash_entry *nhe;
+ 	int err;
+ 
+ 	nhe = mlx5e_rep_neigh_entry_lookup(priv, &e->m_neigh);
+ 	if (!nhe) {
+ 		err = mlx5e_rep_neigh_entry_create(priv, e, &nhe);
+ 		if (err)
+ 			return err;
+ 	}
+ 	list_add(&e->encap_list, &nhe->encap_list);
+ 	return 0;
+ }
+ 
+ void mlx5e_rep_encap_entry_detach(struct mlx5e_priv *priv,
+ 				  struct mlx5e_encap_entry *e)
+ {
+ 	struct mlx5e_neigh_hash_entry *nhe;
+ 
+ 	list_del(&e->encap_list);
+ 	nhe = mlx5e_rep_neigh_entry_lookup(priv, &e->m_neigh);
+ 
+ 	if (list_empty(&nhe->encap_list))
+ 		mlx5e_rep_neigh_entry_destroy(priv, nhe);
++>>>>>>> f6dfb4c3f216 (net/mlx5e: Update neighbour 'used' state using HW flow rules counters)
  }
  
  static int mlx5e_rep_open(struct net_device *dev)
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index d3c637b0294b,11c27e4fadf6..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -42,8 -42,11 +42,9 @@@
  #include <net/tc_act/tc_mirred.h>
  #include <net/tc_act/tc_vlan.h>
  #include <net/tc_act/tc_tunnel_key.h>
 -#include <net/tc_act/tc_pedit.h>
  #include <net/vxlan.h>
+ #include <net/arp.h>
  #include "en.h"
 -#include "en_rep.h"
  #include "en_tc.h"
  #include "eswitch.h"
  #include "vxlan.h"
@@@ -208,8 -253,120 +209,122 @@@ static void mlx5e_tc_del_fdb_flow(struc
  
  	mlx5_eswitch_del_vlan_action(esw, flow->esw_attr);
  
 -	if (flow->esw_attr->action & MLX5_FLOW_CONTEXT_ACTION_ENCAP) {
 +	if (flow->esw_attr->action & MLX5_FLOW_CONTEXT_ACTION_ENCAP)
  		mlx5e_detach_encap(priv, flow);
++<<<<<<< HEAD
++=======
+ 		kvfree(flow->esw_attr->parse_attr);
+ 	}
+ 
+ 	if (flow->esw_attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR)
+ 		mlx5_modify_header_dealloc(priv->mdev,
+ 					   attr->mod_hdr_id);
+ }
+ 
+ void mlx5e_tc_encap_flows_add(struct mlx5e_priv *priv,
+ 			      struct mlx5e_encap_entry *e)
+ {
+ 	struct mlx5e_tc_flow *flow;
+ 	int err;
+ 
+ 	err = mlx5_encap_alloc(priv->mdev, e->tunnel_type,
+ 			       e->encap_size, e->encap_header,
+ 			       &e->encap_id);
+ 	if (err) {
+ 		mlx5_core_warn(priv->mdev, "Failed to offload cached encapsulation header, %d\n",
+ 			       err);
+ 		return;
+ 	}
+ 	e->flags |= MLX5_ENCAP_ENTRY_VALID;
+ 	mlx5e_rep_queue_neigh_stats_work(priv);
+ 
+ 	list_for_each_entry(flow, &e->flows, encap) {
+ 		flow->esw_attr->encap_id = e->encap_id;
+ 		flow->rule = mlx5e_tc_add_fdb_flow(priv,
+ 						   flow->esw_attr->parse_attr,
+ 						   flow);
+ 		if (IS_ERR(flow->rule)) {
+ 			err = PTR_ERR(flow->rule);
+ 			mlx5_core_warn(priv->mdev, "Failed to update cached encapsulation flow, %d\n",
+ 				       err);
+ 			continue;
+ 		}
+ 		flow->flags |= MLX5E_TC_FLOW_OFFLOADED;
+ 	}
+ }
+ 
+ void mlx5e_tc_encap_flows_del(struct mlx5e_priv *priv,
+ 			      struct mlx5e_encap_entry *e)
+ {
+ 	struct mlx5e_tc_flow *flow;
+ 	struct mlx5_fc *counter;
+ 
+ 	list_for_each_entry(flow, &e->flows, encap) {
+ 		if (flow->flags & MLX5E_TC_FLOW_OFFLOADED) {
+ 			flow->flags &= ~MLX5E_TC_FLOW_OFFLOADED;
+ 			counter = mlx5_flow_rule_counter(flow->rule);
+ 			mlx5_del_flow_rules(flow->rule);
+ 			mlx5_fc_destroy(priv->mdev, counter);
+ 		}
+ 	}
+ 
+ 	if (e->flags & MLX5_ENCAP_ENTRY_VALID) {
+ 		e->flags &= ~MLX5_ENCAP_ENTRY_VALID;
+ 		mlx5_encap_dealloc(priv->mdev, e->encap_id);
+ 	}
++>>>>>>> f6dfb4c3f216 (net/mlx5e: Update neighbour 'used' state using HW flow rules counters)
+ }
+ 
+ void mlx5e_tc_update_neigh_used_value(struct mlx5e_neigh_hash_entry *nhe)
+ {
+ 	struct mlx5e_neigh *m_neigh = &nhe->m_neigh;
+ 	u64 bytes, packets, lastuse = 0;
+ 	struct mlx5e_tc_flow *flow;
+ 	struct mlx5e_encap_entry *e;
+ 	struct mlx5_fc *counter;
+ 	struct neigh_table *tbl;
+ 	bool neigh_used = false;
+ 	struct neighbour *n;
+ 
+ 	if (m_neigh->family == AF_INET)
+ 		tbl = &arp_tbl;
+ #if IS_ENABLED(CONFIG_IPV6)
+ 	else if (m_neigh->family == AF_INET6)
+ 		tbl = ipv6_stub->nd_tbl;
+ #endif
+ 	else
+ 		return;
+ 
+ 	list_for_each_entry(e, &nhe->encap_list, encap_list) {
+ 		if (!(e->flags & MLX5_ENCAP_ENTRY_VALID))
+ 			continue;
+ 		list_for_each_entry(flow, &e->flows, encap) {
+ 			if (flow->flags & MLX5E_TC_FLOW_OFFLOADED) {
+ 				counter = mlx5_flow_rule_counter(flow->rule);
+ 				mlx5_fc_query_cached(counter, &bytes, &packets, &lastuse);
+ 				if (time_after((unsigned long)lastuse, nhe->reported_lastuse)) {
+ 					neigh_used = true;
+ 					break;
+ 				}
+ 			}
+ 		}
+ 	}
+ 
+ 	if (neigh_used) {
+ 		nhe->reported_lastuse = jiffies;
+ 
+ 		/* find the relevant neigh according to the cached device and
+ 		 * dst ip pair
+ 		 */
+ 		n = neigh_lookup(tbl, &m_neigh->dst_ip, m_neigh->dev);
+ 		if (!n) {
+ 			WARN(1, "The neighbour already freed\n");
+ 			return;
+ 		}
+ 
+ 		neigh_event_send(n, NULL);
+ 		neigh_release(n);
+ 	}
  }
  
  static void mlx5e_detach_encap(struct mlx5e_priv *priv,
@@@ -918,16 -1365,27 +1033,26 @@@ static int mlx5e_create_encap_header_ip
  	if (err)
  		goto out;
  
++<<<<<<< HEAD
 +	e->n = n;
 +	e->out_dev = *out_dev;
++=======
+ 	/* used by mlx5e_detach_encap to lookup a neigh hash table
+ 	 * entry in the neigh hash table when a user deletes a rule
+ 	 */
+ 	e->m_neigh.dev = n->dev;
+ 	e->m_neigh.family = n->ops->family;
+ 	memcpy(&e->m_neigh.dst_ip, n->primary_key, n->tbl->key_len);
+ 	e->out_dev = out_dev;
++>>>>>>> f6dfb4c3f216 (net/mlx5e: Update neighbour 'used' state using HW flow rules counters)
  
 -	/* It's importent to add the neigh to the hash table before checking
 -	 * the neigh validity state. So if we'll get a notification, in case the
 -	 * neigh changes it's validity state, we would find the relevant neigh
 -	 * in the hash.
 -	 */
 -	err = mlx5e_rep_encap_entry_attach(netdev_priv(out_dev), e);
 -	if (err)
 +	if (!(n->nud_state & NUD_VALID)) {
 +		pr_warn("%s: can't offload, neighbour to %pI4 invalid\n", __func__, &fl4.daddr);
 +		err = -EOPNOTSUPP;
  		goto out;
 +	}
  
 -	read_lock_bh(&n->lock);
 -	nud_state = n->nud_state;
 -	ether_addr_copy(e->h_dest, n->ha);
 -	read_unlock_bh(&n->lock);
 +	neigh_ha_snapshot(e->h_dest, n, *out_dev);
  
  	switch (e->tunnel_type) {
  	case MLX5_HEADER_TYPE_VXLAN:
@@@ -943,11 -1409,21 +1068,25 @@@
  	}
  
  	err = mlx5_encap_alloc(priv->mdev, e->tunnel_type,
++<<<<<<< HEAD
 +			       encap_size, encap_header, &e->encap_id);
++=======
+ 			       ipv4_encap_size, encap_header, &e->encap_id);
+ 	if (err)
+ 		goto destroy_neigh_entry;
+ 
+ 	e->flags |= MLX5_ENCAP_ENTRY_VALID;
+ 	mlx5e_rep_queue_neigh_stats_work(netdev_priv(out_dev));
+ 	neigh_release(n);
+ 	return err;
+ 
+ destroy_neigh_entry:
+ 	mlx5e_rep_encap_entry_detach(netdev_priv(e->out_dev), e);
++>>>>>>> f6dfb4c3f216 (net/mlx5e: Update neighbour 'used' state using HW flow rules counters)
  out:
 -	kfree(encap_header);
 -	if (n)
 +	if (err && n)
  		neigh_release(n);
 +	kfree(encap_header);
  	return err;
  }
  
@@@ -994,16 -1470,27 +1133,34 @@@ static int mlx5e_create_encap_header_ip
  	if (err)
  		goto out;
  
++<<<<<<< HEAD
 +	if (!(n->nud_state & NUD_VALID)) {
 +		pr_warn("%s: can't offload, neighbour to %pI6 invalid\n", __func__, &fl6.daddr);
 +		err = -EOPNOTSUPP;
++=======
+ 	/* used by mlx5e_detach_encap to lookup a neigh hash table
+ 	 * entry in the neigh hash table when a user deletes a rule
+ 	 */
+ 	e->m_neigh.dev = n->dev;
+ 	e->m_neigh.family = n->ops->family;
+ 	memcpy(&e->m_neigh.dst_ip, n->primary_key, n->tbl->key_len);
+ 	e->out_dev = out_dev;
+ 
+ 	/* It's importent to add the neigh to the hash table before checking
+ 	 * the neigh validity state. So if we'll get a notification, in case the
+ 	 * neigh changes it's validity state, we would find the relevant neigh
+ 	 * in the hash.
+ 	 */
+ 	err = mlx5e_rep_encap_entry_attach(netdev_priv(out_dev), e);
+ 	if (err)
++>>>>>>> f6dfb4c3f216 (net/mlx5e: Update neighbour 'used' state using HW flow rules counters)
  		goto out;
 +	}
 +
 +	e->n = n;
 +	e->out_dev = *out_dev;
  
 -	read_lock_bh(&n->lock);
 -	nud_state = n->nud_state;
 -	ether_addr_copy(e->h_dest, n->ha);
 -	read_unlock_bh(&n->lock);
 +	neigh_ha_snapshot(e->h_dest, n, *out_dev);
  
  	switch (e->tunnel_type) {
  	case MLX5_HEADER_TYPE_VXLAN:
@@@ -1020,10 -1516,20 +1177,23 @@@
  
  	err = mlx5_encap_alloc(priv->mdev, e->tunnel_type,
  			       ipv6_encap_size, encap_header, &e->encap_id);
++<<<<<<< HEAD
++=======
+ 	if (err)
+ 		goto destroy_neigh_entry;
+ 
+ 	e->flags |= MLX5_ENCAP_ENTRY_VALID;
+ 	mlx5e_rep_queue_neigh_stats_work(netdev_priv(out_dev));
+ 	neigh_release(n);
+ 	return err;
+ 
+ destroy_neigh_entry:
+ 	mlx5e_rep_encap_entry_detach(netdev_priv(e->out_dev), e);
++>>>>>>> f6dfb4c3f216 (net/mlx5e: Update neighbour 'used' state using HW flow rules counters)
  out:
 -	kfree(encap_header);
 -	if (n)
 +	if (err && n)
  		neigh_release(n);
 +	kfree(encap_header);
  	return err;
  }
  
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
index 34bf903fc886,ecbe30d808ae..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
@@@ -46,6 -46,15 +46,18 @@@ int mlx5e_delete_flower(struct mlx5e_pr
  int mlx5e_stats_flower(struct mlx5e_priv *priv,
  		       struct tc_cls_flower_offload *f);
  
++<<<<<<< HEAD
++=======
+ struct mlx5e_encap_entry;
+ void mlx5e_tc_encap_flows_add(struct mlx5e_priv *priv,
+ 			      struct mlx5e_encap_entry *e);
+ void mlx5e_tc_encap_flows_del(struct mlx5e_priv *priv,
+ 			      struct mlx5e_encap_entry *e);
+ 
+ struct mlx5e_neigh_hash_entry;
+ void mlx5e_tc_update_neigh_used_value(struct mlx5e_neigh_hash_entry *nhe);
+ 
++>>>>>>> f6dfb4c3f216 (net/mlx5e: Update neighbour 'used' state using HW flow rules counters)
  static inline int mlx5e_tc_num_filters(struct mlx5e_priv *priv)
  {
  	return atomic_read(&priv->fs.tc.ht.nelems);
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.h b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.h
index 577d056bf3df..81eafc7b9dd9 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.h
@@ -199,6 +199,11 @@ struct mlx5_flow_root_namespace {
 
 int mlx5_init_fc_stats(struct mlx5_core_dev *dev);
 void mlx5_cleanup_fc_stats(struct mlx5_core_dev *dev);
+void mlx5_fc_queue_stats_work(struct mlx5_core_dev *dev,
+			      struct delayed_work *dwork,
+			      unsigned long delay);
+void mlx5_fc_update_sampling_interval(struct mlx5_core_dev *dev,
+				      unsigned long interval);
 
 int mlx5_init_fs(struct mlx5_core_dev *dev);
 void mlx5_cleanup_fs(struct mlx5_core_dev *dev);
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/fs_counters.c b/drivers/net/ethernet/mellanox/mlx5/core/fs_counters.c
index 7431f633de31..6507d8acc54d 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_counters.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_counters.c
@@ -165,7 +165,8 @@ static void mlx5_fc_stats_work(struct work_struct *work)
 	list_splice_tail_init(&fc_stats->addlist, &tmplist);
 
 	if (!list_empty(&tmplist) || !RB_EMPTY_ROOT(&fc_stats->counters))
-		queue_delayed_work(fc_stats->wq, &fc_stats->work, MLX5_FC_STATS_PERIOD);
+		queue_delayed_work(fc_stats->wq, &fc_stats->work,
+				   fc_stats->sampling_interval);
 
 	spin_unlock(&fc_stats->addlist_lock);
 
@@ -200,7 +201,7 @@ static void mlx5_fc_stats_work(struct work_struct *work)
 		node = mlx5_fc_stats_query(dev, counter, last->id);
 	}
 
-	fc_stats->next_query = now + MLX5_FC_STATS_PERIOD;
+	fc_stats->next_query = now + fc_stats->sampling_interval;
 }
 
 struct mlx5_fc *mlx5_fc_create(struct mlx5_core_dev *dev, bool aging)
@@ -265,6 +266,7 @@ int mlx5_init_fc_stats(struct mlx5_core_dev *dev)
 	if (!fc_stats->wq)
 		return -ENOMEM;
 
+	fc_stats->sampling_interval = MLX5_FC_STATS_PERIOD;
 	INIT_DELAYED_WORK(&fc_stats->work, mlx5_fc_stats_work);
 
 	return 0;
@@ -317,3 +319,21 @@ void mlx5_fc_query_cached(struct mlx5_fc *counter,
 	counter->lastbytes = c.bytes;
 	counter->lastpackets = c.packets;
 }
+
+void mlx5_fc_queue_stats_work(struct mlx5_core_dev *dev,
+			      struct delayed_work *dwork,
+			      unsigned long delay)
+{
+	struct mlx5_fc_stats *fc_stats = &dev->priv.fc_stats;
+
+	queue_delayed_work(fc_stats->wq, dwork, delay);
+}
+
+void mlx5_fc_update_sampling_interval(struct mlx5_core_dev *dev,
+				      unsigned long interval)
+{
+	struct mlx5_fc_stats *fc_stats = &dev->priv.fc_stats;
+
+	fc_stats->sampling_interval = min_t(unsigned long, interval,
+					    fc_stats->sampling_interval);
+}
diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 61d8bec93f9f..381e726fcf3d 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -505,6 +505,7 @@ struct mlx5_fc_stats {
 	struct workqueue_struct *wq;
 	struct delayed_work work;
 	unsigned long next_query;
+	unsigned long sampling_interval; /* jiffies */
 };
 
 struct mlx5_eswitch;
