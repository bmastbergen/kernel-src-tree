cpufreq: Support for fast frequency switching

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Rafael J. Wysocki <rafael.j.wysocki@intel.com>
commit b7898fda5bc7e786e76ce24fbd2ec993b08ec518
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/b7898fda.failed

Modify the ACPI cpufreq driver to provide a method for switching
CPU frequencies from interrupt context and update the cpufreq core
to support that method if available.

Introduce a new cpufreq driver callback, ->fast_switch, to be
invoked for frequency switching from interrupt context by (future)
governors supporting that feature via (new) helper function
cpufreq_driver_fast_switch().

Add two new policy flags, fast_switch_possible, to be set by the
cpufreq driver if fast frequency switching can be used for the
given policy and fast_switch_enabled, to be set by the governor
if it is going to use fast frequency switching for the given
policy.  Also add a helper for setting the latter.

Since fast frequency switching is inherently incompatible with
cpufreq transition notifiers, make it possible to set the
fast_switch_enabled only if there are no transition notifiers
already registered and make the registration of new transition
notifiers fail if fast_switch_enabled is set for at least one
policy.

Implement the ->fast_switch callback in the ACPI cpufreq driver
and make it set fast_switch_possible during policy initialization
as appropriate.

	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
	Acked-by: Viresh Kumar <viresh.kumar@linaro.org>
(cherry picked from commit b7898fda5bc7e786e76ce24fbd2ec993b08ec518)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/acpi-cpufreq.c
#	drivers/cpufreq/cpufreq.c
#	include/linux/cpufreq.h
diff --cc drivers/cpufreq/acpi-cpufreq.c
index b0c18ed8d83f,7f38fb55f223..000000000000
--- a/drivers/cpufreq/acpi-cpufreq.c
+++ b/drivers/cpufreq/acpi-cpufreq.c
@@@ -854,9 -883,9 +894,15 @@@ static int acpi_cpufreq_cpu_exit(struc
  	pr_debug("acpi_cpufreq_cpu_exit\n");
  
  	if (data) {
++<<<<<<< HEAD
 +		per_cpu(acfreq_data, policy->cpu) = NULL;
 +		acpi_processor_unregister_performance(data->acpi_data,
 +						      policy->cpu);
++=======
+ 		policy->fast_switch_possible = false;
+ 		policy->driver_data = NULL;
+ 		acpi_processor_unregister_performance(data->acpi_perf_cpu);
++>>>>>>> b7898fda5bc7 (cpufreq: Support for fast frequency switching)
  		free_cpumask_var(data->freqdomain_cpus);
  		kfree(data->freq_table);
  		kfree(data);
diff --cc drivers/cpufreq/cpufreq.c
index 6ce63ca52d98,a5b7d77d4816..000000000000
--- a/drivers/cpufreq/cpufreq.c
+++ b/drivers/cpufreq/cpufreq.c
@@@ -53,17 -73,11 +53,24 @@@ static inline bool has_target(void
  	return cpufreq_driver->target_index || cpufreq_driver->target;
  }
  
 +/*
 + * rwsem to guarantee that cpufreq driver module doesn't unload during critical
 + * sections
 + */
 +static DECLARE_RWSEM(cpufreq_rwsem);
 +
  /* internal prototypes */
++<<<<<<< HEAD
 +static int __cpufreq_governor(struct cpufreq_policy *policy,
 +		unsigned int event);
 +static unsigned int __cpufreq_get(unsigned int cpu);
 +static void handle_update(struct work_struct *work);
++=======
+ static int cpufreq_governor(struct cpufreq_policy *policy, unsigned int event);
+ static unsigned int __cpufreq_get(struct cpufreq_policy *policy);
+ static int cpufreq_start_governor(struct cpufreq_policy *policy);
+ static int cpufreq_exit_governor(struct cpufreq_policy *policy);
++>>>>>>> b7898fda5bc7 (cpufreq: Support for fast frequency switching)
  
  /**
   * Two notifier lists: the "policy" list is involved in the
@@@ -1347,131 -1340,65 +1416,138 @@@ static int __cpufreq_remove_dev_prepare
  
  	pr_debug("%s: unregistering CPU %u\n", __func__, cpu);
  
 -	policy = cpufreq_cpu_get_raw(cpu);
 +	write_lock_irqsave(&cpufreq_driver_lock, flags);
 +
 +	policy = per_cpu(cpufreq_cpu_data, cpu);
 +
 +	/* Save the policy somewhere when doing a light-weight tear-down */
 +	if (cpufreq_suspended)
 +		per_cpu(cpufreq_cpu_data_fallback, cpu) = policy;
 +
 +	write_unlock_irqrestore(&cpufreq_driver_lock, flags);
 +
  	if (!policy) {
  		pr_debug("%s: No cpu_data found\n", __func__);
 -		return;
 +		return -EINVAL;
  	}
  
 -	down_write(&policy->rwsem);
  	if (has_target()) {
 -		ret = cpufreq_governor(policy, CPUFREQ_GOV_STOP);
 -		if (ret)
 +		ret = __cpufreq_governor(policy, CPUFREQ_GOV_STOP);
 +		if (ret) {
  			pr_err("%s: Failed to stop governor\n", __func__);
 +			return ret;
 +		}
  	}
  
 -	cpumask_clear_cpu(cpu, policy->cpus);
 +	if (!cpufreq_driver->setpolicy)
 +		strncpy(per_cpu(cpufreq_cpu_governor, cpu),
 +			policy->governor->name, CPUFREQ_NAME_LEN);
  
 -	if (policy_is_inactive(policy)) {
 -		if (has_target())
 -			strncpy(policy->last_governor, policy->governor->name,
 -				CPUFREQ_NAME_LEN);
 -		else
 -			policy->last_policy = policy->policy;
 -	} else if (cpu == policy->cpu) {
 +	down_read(&policy->rwsem);
 +	cpus = cpumask_weight(policy->cpus);
 +	up_read(&policy->rwsem);
 +
 +	if (cpu != policy->cpu) {
 +		sysfs_remove_link(&dev->kobj, "cpufreq");
 +	} else if (cpus > 1) {
  		/* Nominate new CPU */
 -		policy->cpu = cpumask_any(policy->cpus);
 -	}
 +		int new_cpu = cpumask_any_but(policy->cpus, cpu);
 +		struct device *cpu_dev = get_cpu_device(new_cpu);
  
 -	/* Start governor again for active policy */
 -	if (!policy_is_inactive(policy)) {
 -		if (has_target()) {
 -			ret = cpufreq_start_governor(policy);
 -			if (ret)
 -				pr_err("%s: Failed to start governor\n", __func__);
 +		sysfs_remove_link(&cpu_dev->kobj, "cpufreq");
 +		ret = update_policy_cpu(policy, new_cpu, cpu_dev);
 +		if (ret) {
 +			if (sysfs_create_link(&cpu_dev->kobj, &policy->kobj,
 +					      "cpufreq"))
 +				pr_err("%s: Failed to restore kobj link to cpu:%d\n",
 +				       __func__, cpu_dev->id);
 +			return ret;
  		}
  
 -		goto unlock;
 +		if (!cpufreq_suspended)
 +			pr_debug("%s: policy Kobject moved to cpu: %d from: %d\n",
 +				 __func__, new_cpu, cpu);
 +	} else if (cpufreq_driver->stop_cpu) {
 +		cpufreq_driver->stop_cpu(policy);
  	}
  
 -	if (cpufreq_driver->stop_cpu)
 -		cpufreq_driver->stop_cpu(policy);
 +	return 0;
 +}
 +
 +static int __cpufreq_remove_dev_finish(struct device *dev,
 +				       struct subsys_interface *sif)
 +{
 +	unsigned int cpu = dev->id, cpus;
 +	int ret;
 +	unsigned long flags;
 +	struct cpufreq_policy *policy;
 +
 +	write_lock_irqsave(&cpufreq_driver_lock, flags);
 +	policy = per_cpu(cpufreq_cpu_data, cpu);
 +	per_cpu(cpufreq_cpu_data, cpu) = NULL;
 +	write_unlock_irqrestore(&cpufreq_driver_lock, flags);
 +
 +	if (!policy) {
 +		pr_debug("%s: No cpu_data found\n", __func__);
 +		return -EINVAL;
 +	}
 +
 +	down_write(&policy->rwsem);
 +	cpus = cpumask_weight(policy->cpus);
 +
 +	if (cpus > 1)
 +		cpumask_clear_cpu(cpu, policy->cpus);
 +	up_write(&policy->rwsem);
  
  	/* If cpu is last user of policy, free policy */
++<<<<<<< HEAD
 +	if (cpus == 1) {
 +		if (has_target()) {
 +			ret = __cpufreq_governor(policy,
 +					CPUFREQ_GOV_POLICY_EXIT);
 +			if (ret) {
 +				pr_err("%s: Failed to exit governor\n",
 +				       __func__);
 +				return ret;
 +			}
 +		}
 +
 +		if (!cpufreq_suspended)
 +			cpufreq_policy_put_kobj(policy);
 +
 +		/*
 +		 * Perform the ->exit() even during light-weight tear-down,
 +		 * since this is a core component, and is essential for the
 +		 * subsequent light-weight ->init() to succeed.
 +		 */
 +		if (cpufreq_driver->exit)
 +			cpufreq_driver->exit(policy);
 +
 +		/* Remove policy from list of active policies */
 +		write_lock_irqsave(&cpufreq_driver_lock, flags);
 +		list_del(&policy->policy_list);
 +		write_unlock_irqrestore(&cpufreq_driver_lock, flags);
 +
 +		if (!cpufreq_suspended)
 +			cpufreq_policy_free(policy);
 +	} else if (has_target()) {
 +		ret = __cpufreq_governor(policy, CPUFREQ_GOV_START);
 +		if (!ret)
 +			ret = __cpufreq_governor(policy, CPUFREQ_GOV_LIMITS);
 +
 +		if (ret) {
 +			pr_err("%s: Failed to start governor\n", __func__);
 +			return ret;
 +		}
++=======
+ 	if (has_target()) {
+ 		ret = cpufreq_exit_governor(policy);
+ 		if (ret)
+ 			pr_err("%s: Failed to exit governor\n", __func__);
++>>>>>>> b7898fda5bc7 (cpufreq: Support for fast frequency switching)
  	}
  
 -	/*
 -	 * Perform the ->exit() even during light-weight tear-down,
 -	 * since this is a core component, and is essential for the
 -	 * subsequent light-weight ->init() to succeed.
 -	 */
 -	if (cpufreq_driver->exit) {
 -		cpufreq_driver->exit(policy);
 -		policy->freq_table = NULL;
 -	}
 -
 -unlock:
 -	up_write(&policy->rwsem);
 +	return 0;
  }
  
  /**
@@@ -1586,7 -1508,15 +1662,19 @@@ static unsigned int __cpufreq_get(unsig
  	if (!cpufreq_driver->get)
  		return ret_freq;
  
++<<<<<<< HEAD
 +	ret_freq = cpufreq_driver->get(cpu);
++=======
+ 	ret_freq = cpufreq_driver->get(policy->cpu);
+ 
+ 	/*
+ 	 * Updating inactive policies is invalid, so avoid doing that.  Also
+ 	 * if fast frequency switching is used with the given policy, the check
+ 	 * against policy->cur is pointless, so skip it in that case too.
+ 	 */
+ 	if (unlikely(policy_is_inactive(policy)) || policy->fast_switch_enabled)
+ 		return ret_freq;
++>>>>>>> b7898fda5bc7 (cpufreq: Support for fast frequency switching)
  
  	if (ret_freq && policy->cur &&
  		!(cpufreq_driver->flags & CPUFREQ_CONST_LOOPS)) {
@@@ -2066,6 -2049,23 +2201,26 @@@ static int __cpufreq_governor(struct cp
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ static int cpufreq_start_governor(struct cpufreq_policy *policy)
+ {
+ 	int ret;
+ 
+ 	if (cpufreq_driver->get && !cpufreq_driver->setpolicy)
+ 		cpufreq_update_current_freq(policy);
+ 
+ 	ret = cpufreq_governor(policy, CPUFREQ_GOV_START);
+ 	return ret ? ret : cpufreq_governor(policy, CPUFREQ_GOV_LIMITS);
+ }
+ 
+ static int cpufreq_exit_governor(struct cpufreq_policy *policy)
+ {
+ 	cpufreq_disable_fast_switch(policy);
+ 	return cpufreq_governor(policy, CPUFREQ_GOV_POLICY_EXIT);
+ }
+ 
++>>>>>>> b7898fda5bc7 (cpufreq: Support for fast frequency switching)
  int cpufreq_register_governor(struct cpufreq_governor *governor)
  {
  	int err;
@@@ -2207,17 -2213,32 +2362,45 @@@ static int cpufreq_set_policy(struct cp
  	old_gov = policy->governor;
  	/* end old governor */
  	if (old_gov) {
++<<<<<<< HEAD
 +		__cpufreq_governor(policy, CPUFREQ_GOV_STOP);
 +		__cpufreq_governor(policy, CPUFREQ_GOV_POLICY_EXIT);
++=======
+ 		ret = cpufreq_governor(policy, CPUFREQ_GOV_STOP);
+ 		if (ret) {
+ 			/* This can happen due to race with other operations */
+ 			pr_debug("%s: Failed to Stop Governor: %s (%d)\n",
+ 				 __func__, old_gov->name, ret);
+ 			return ret;
+ 		}
+ 
+ 		ret = cpufreq_exit_governor(policy);
+ 		if (ret) {
+ 			pr_err("%s: Failed to Exit Governor: %s (%d)\n",
+ 			       __func__, old_gov->name, ret);
+ 			return ret;
+ 		}
++>>>>>>> b7898fda5bc7 (cpufreq: Support for fast frequency switching)
  	}
  
  	/* start new governor */
  	policy->governor = new_policy->governor;
++<<<<<<< HEAD
 +	if (!__cpufreq_governor(policy, CPUFREQ_GOV_POLICY_INIT)) {
 +		if (!__cpufreq_governor(policy, CPUFREQ_GOV_START))
 +			goto out;
 +
 +		__cpufreq_governor(policy, CPUFREQ_GOV_POLICY_EXIT);
++=======
+ 	ret = cpufreq_governor(policy, CPUFREQ_GOV_POLICY_INIT);
+ 	if (!ret) {
+ 		ret = cpufreq_start_governor(policy);
+ 		if (!ret) {
+ 			pr_debug("cpufreq: governor change\n");
+ 			return 0;
+ 		}
+ 		cpufreq_exit_governor(policy);
++>>>>>>> b7898fda5bc7 (cpufreq: Support for fast frequency switching)
  	}
  
  	/* new governor failed, so re-start old one */
diff --cc include/linux/cpufreq.h
index 6c9a308dec37,55e69ebb035c..000000000000
--- a/include/linux/cpufreq.h
+++ b/include/linux/cpufreq.h
@@@ -162,96 -132,56 +173,110 @@@ struct cpufreq_policy 
  #define CPUFREQ_SHARED_TYPE_ALL	 (2) /* All dependent CPUs should set freq */
  #define CPUFREQ_SHARED_TYPE_ANY	 (3) /* Freq can be set from any dependent CPU*/
  
 -#ifdef CONFIG_CPU_FREQ
 -struct cpufreq_policy *cpufreq_cpu_get_raw(unsigned int cpu);
 -struct cpufreq_policy *cpufreq_cpu_get(unsigned int cpu);
 -void cpufreq_cpu_put(struct cpufreq_policy *policy);
 -#else
 -static inline struct cpufreq_policy *cpufreq_cpu_get_raw(unsigned int cpu)
 +static inline bool policy_is_shared(struct cpufreq_policy *policy)
  {
 -	return NULL;
 +	return cpumask_weight(policy->cpus) > 1;
  }
 -static inline struct cpufreq_policy *cpufreq_cpu_get(unsigned int cpu)
 +
 +/******************** cpufreq transition notifiers *******************/
 +
 +#define CPUFREQ_PRECHANGE	(0)
 +#define CPUFREQ_POSTCHANGE	(1)
 +
 +struct cpufreq_freqs {
 +	unsigned int cpu;	/* cpu nr */
 +	unsigned int old;
 +	unsigned int new;
 +	u8 flags;		/* flags of cpufreq_driver, see below. */
 +};
 +
 +/**
 + * cpufreq_scale - "old * mult / div" calculation for large values (32-bit-arch
 + * safe)
 + * @old:   old value
 + * @div:   divisor
 + * @mult:  multiplier
 + *
 + *
 + * new = old * mult / div
 + */
 +static inline unsigned long cpufreq_scale(unsigned long old, u_int div,
 +		u_int mult)
  {
 -	return NULL;
 -}
 -static inline void cpufreq_cpu_put(struct cpufreq_policy *policy) { }
 +#if BITS_PER_LONG == 32
 +
 +	u64 result = ((u64) old) * ((u64) mult);
 +	do_div(result, div);
 +	return (unsigned long) result;
 +
 +#elif BITS_PER_LONG == 64
 +
 +	unsigned long result = old * ((u64) mult);
 +	result /= div;
 +	return result;
 +
  #endif
 +};
  
 -static inline bool policy_is_shared(struct cpufreq_policy *policy)
 -{
 -	return cpumask_weight(policy->cpus) > 1;
 -}
 +/*********************************************************************
 + *                          CPUFREQ GOVERNORS                        *
 + *********************************************************************/
  
 -/* /sys/devices/system/cpu/cpufreq: entry point for global variables */
 -extern struct kobject *cpufreq_global_kobject;
 +#define CPUFREQ_GOV_START	1
 +#define CPUFREQ_GOV_STOP	2
 +#define CPUFREQ_GOV_LIMITS	3
 +#define CPUFREQ_GOV_POLICY_INIT	4
 +#define CPUFREQ_GOV_POLICY_EXIT	5
 +
 +struct cpufreq_governor {
 +	char	name[CPUFREQ_NAME_LEN];
 +	int	initialized;
 +	int	(*governor)	(struct cpufreq_policy *policy,
 +				 unsigned int event);
 +	ssize_t	(*show_setspeed)	(struct cpufreq_policy *policy,
 +					 char *buf);
 +	int	(*store_setspeed)	(struct cpufreq_policy *policy,
 +					 unsigned int freq);
 +	unsigned int max_transition_latency; /* HW must be able to switch to
 +			next freq faster than this value in nano secs or we
 +			will fallback to performance governor */
 +	struct list_head	governor_list;
 +	struct module		*owner;
 +};
 +
 +/*
 + * Pass a target to the cpufreq driver.
 + */
 +extern int cpufreq_driver_target(struct cpufreq_policy *policy,
 +				 unsigned int target_freq,
 +				 unsigned int relation);
 +extern int __cpufreq_driver_target(struct cpufreq_policy *policy,
 +				   unsigned int target_freq,
 +				   unsigned int relation);
 +int cpufreq_register_governor(struct cpufreq_governor *governor);
 +void cpufreq_unregister_governor(struct cpufreq_governor *governor);
  
  #ifdef CONFIG_CPU_FREQ
++<<<<<<< HEAD
 +void cpufreq_suspend(void);
 +void cpufreq_resume(void);
 +int cpufreq_generic_suspend(struct cpufreq_policy *policy);
++=======
+ unsigned int cpufreq_get(unsigned int cpu);
+ unsigned int cpufreq_quick_get(unsigned int cpu);
+ unsigned int cpufreq_quick_get_max(unsigned int cpu);
+ void disable_cpufreq(void);
+ 
+ u64 get_cpu_idle_time(unsigned int cpu, u64 *wall, int io_busy);
+ int cpufreq_get_policy(struct cpufreq_policy *policy, unsigned int cpu);
+ int cpufreq_update_policy(unsigned int cpu);
+ bool have_governor_per_policy(void);
+ struct kobject *get_governor_parent_kobj(struct cpufreq_policy *policy);
+ void cpufreq_enable_fast_switch(struct cpufreq_policy *policy);
++>>>>>>> b7898fda5bc7 (cpufreq: Support for fast frequency switching)
  #else
 -static inline unsigned int cpufreq_get(unsigned int cpu)
 -{
 -	return 0;
 -}
 -static inline unsigned int cpufreq_quick_get(unsigned int cpu)
 -{
 -	return 0;
 -}
 -static inline unsigned int cpufreq_quick_get_max(unsigned int cpu)
 -{
 -	return 0;
 -}
 -static inline void disable_cpufreq(void) { }
 +static inline void cpufreq_suspend(void) {}
 +static inline void cpufreq_resume(void) {}
  #endif
  
  /*********************************************************************
@@@ -392,110 -354,167 +419,259 @@@ cpufreq_verify_within_cpu_limits(struc
  			policy->cpuinfo.max_freq);
  }
  
 -#ifdef CONFIG_CPU_FREQ
 -void cpufreq_suspend(void);
 -void cpufreq_resume(void);
 -int cpufreq_generic_suspend(struct cpufreq_policy *policy);
 -#else
 -static inline void cpufreq_suspend(void) {}
 -static inline void cpufreq_resume(void) {}
 -#endif
  
++<<<<<<< HEAD
 +struct freq_attr {
++=======
+ /*********************************************************************
+  *                     CPUFREQ NOTIFIER INTERFACE                    *
+  *********************************************************************/
+ 
+ #define CPUFREQ_TRANSITION_NOTIFIER	(0)
+ #define CPUFREQ_POLICY_NOTIFIER		(1)
+ 
+ /* Transition notifiers */
+ #define CPUFREQ_PRECHANGE		(0)
+ #define CPUFREQ_POSTCHANGE		(1)
+ 
+ /* Policy Notifiers  */
+ #define CPUFREQ_ADJUST			(0)
+ #define CPUFREQ_NOTIFY			(1)
+ #define CPUFREQ_START			(2)
+ #define CPUFREQ_CREATE_POLICY		(3)
+ #define CPUFREQ_REMOVE_POLICY		(4)
+ 
+ #ifdef CONFIG_CPU_FREQ
+ int cpufreq_register_notifier(struct notifier_block *nb, unsigned int list);
+ int cpufreq_unregister_notifier(struct notifier_block *nb, unsigned int list);
+ 
+ void cpufreq_freq_transition_begin(struct cpufreq_policy *policy,
+ 		struct cpufreq_freqs *freqs);
+ void cpufreq_freq_transition_end(struct cpufreq_policy *policy,
+ 		struct cpufreq_freqs *freqs, int transition_failed);
+ 
+ #else /* CONFIG_CPU_FREQ */
+ static inline int cpufreq_register_notifier(struct notifier_block *nb,
+ 						unsigned int list)
+ {
+ 	return 0;
+ }
+ static inline int cpufreq_unregister_notifier(struct notifier_block *nb,
+ 						unsigned int list)
+ {
+ 	return 0;
+ }
+ #endif /* !CONFIG_CPU_FREQ */
+ 
+ /**
+  * cpufreq_scale - "old * mult / div" calculation for large values (32-bit-arch
+  * safe)
+  * @old:   old value
+  * @div:   divisor
+  * @mult:  multiplier
+  *
+  *
+  * new = old * mult / div
+  */
+ static inline unsigned long cpufreq_scale(unsigned long old, u_int div,
+ 		u_int mult)
+ {
+ #if BITS_PER_LONG == 32
+ 	u64 result = ((u64) old) * ((u64) mult);
+ 	do_div(result, div);
+ 	return (unsigned long) result;
+ 
+ #elif BITS_PER_LONG == 64
+ 	unsigned long result = old * ((u64) mult);
+ 	result /= div;
+ 	return result;
+ #endif
+ }
+ 
+ /*********************************************************************
+  *                          CPUFREQ GOVERNORS                        *
+  *********************************************************************/
+ 
+ /*
+  * If (cpufreq_driver->target) exists, the ->governor decides what frequency
+  * within the limits is used. If (cpufreq_driver->setpolicy> exists, these
+  * two generic policies are available:
+  */
+ #define CPUFREQ_POLICY_POWERSAVE	(1)
+ #define CPUFREQ_POLICY_PERFORMANCE	(2)
+ 
+ /*
+  * The polling frequency depends on the capability of the processor. Default
+  * polling frequency is 1000 times the transition latency of the processor. The
+  * ondemand governor will work on any processor with transition latency <= 10ms,
+  * using appropriate sampling rate.
+  *
+  * For CPUs with transition latency > 10ms (mostly drivers with CPUFREQ_ETERNAL)
+  * the ondemand governor will not work. All times here are in us (microseconds).
+  */
+ #define MIN_SAMPLING_RATE_RATIO		(2)
+ #define LATENCY_MULTIPLIER		(1000)
+ #define MIN_LATENCY_MULTIPLIER		(20)
+ #define TRANSITION_LATENCY_LIMIT	(10 * 1000 * 1000)
+ 
+ /* Governor Events */
+ #define CPUFREQ_GOV_START	1
+ #define CPUFREQ_GOV_STOP	2
+ #define CPUFREQ_GOV_LIMITS	3
+ #define CPUFREQ_GOV_POLICY_INIT	4
+ #define CPUFREQ_GOV_POLICY_EXIT	5
+ 
+ struct cpufreq_governor {
+ 	char	name[CPUFREQ_NAME_LEN];
+ 	int	initialized;
+ 	int	(*governor)	(struct cpufreq_policy *policy,
+ 				 unsigned int event);
+ 	ssize_t	(*show_setspeed)	(struct cpufreq_policy *policy,
+ 					 char *buf);
+ 	int	(*store_setspeed)	(struct cpufreq_policy *policy,
+ 					 unsigned int freq);
+ 	unsigned int max_transition_latency; /* HW must be able to switch to
+ 			next freq faster than this value in nano secs or we
+ 			will fallback to performance governor */
+ 	struct list_head	governor_list;
+ 	struct module		*owner;
+ };
+ 
+ /* Pass a target to the cpufreq driver */
+ unsigned int cpufreq_driver_fast_switch(struct cpufreq_policy *policy,
+ 					unsigned int target_freq);
+ int cpufreq_driver_target(struct cpufreq_policy *policy,
+ 				 unsigned int target_freq,
+ 				 unsigned int relation);
+ int __cpufreq_driver_target(struct cpufreq_policy *policy,
+ 				   unsigned int target_freq,
+ 				   unsigned int relation);
+ int cpufreq_register_governor(struct cpufreq_governor *governor);
+ void cpufreq_unregister_governor(struct cpufreq_governor *governor);
+ 
+ struct cpufreq_governor *cpufreq_default_governor(void);
+ struct cpufreq_governor *cpufreq_fallback_governor(void);
+ 
+ /* Governor attribute set */
+ struct gov_attr_set {
+ 	struct kobject kobj;
+ 	struct list_head policy_list;
+ 	struct mutex update_lock;
+ 	int usage_count;
+ };
+ 
+ /* sysfs ops for cpufreq governors */
+ extern const struct sysfs_ops governor_sysfs_ops;
+ 
+ void gov_attr_set_init(struct gov_attr_set *attr_set, struct list_head *list_node);
+ void gov_attr_set_get(struct gov_attr_set *attr_set, struct list_head *list_node);
+ unsigned int gov_attr_set_put(struct gov_attr_set *attr_set, struct list_head *list_node);
+ 
+ /* Governor sysfs attribute */
+ struct governor_attr {
++>>>>>>> b7898fda5bc7 (cpufreq: Support for fast frequency switching)
  	struct attribute attr;
 -	ssize_t (*show)(struct gov_attr_set *attr_set, char *buf);
 -	ssize_t (*store)(struct gov_attr_set *attr_set, const char *buf,
 -			 size_t count);
 +	ssize_t (*show)(struct cpufreq_policy *, char *);
 +	ssize_t (*store)(struct cpufreq_policy *, const char *, size_t count);
  };
  
 +#define cpufreq_freq_attr_ro(_name)		\
 +static struct freq_attr _name =			\
 +__ATTR(_name, 0444, show_##_name, NULL)
 +
 +#define cpufreq_freq_attr_ro_perm(_name, _perm)	\
 +static struct freq_attr _name =			\
 +__ATTR(_name, _perm, show_##_name, NULL)
 +
 +#define cpufreq_freq_attr_rw(_name)		\
 +static struct freq_attr _name =			\
 +__ATTR(_name, 0644, show_##_name, store_##_name)
 +
 +struct global_attr {
 +	struct attribute attr;
 +	ssize_t (*show)(struct kobject *kobj,
 +			struct attribute *attr, char *buf);
 +	ssize_t (*store)(struct kobject *a, struct attribute *b,
 +			 const char *c, size_t count);
 +};
 +
 +#define define_one_global_ro(_name)		\
 +static struct global_attr _name =		\
 +__ATTR(_name, 0444, show_##_name, NULL)
 +
 +#define define_one_global_rw(_name)		\
 +static struct global_attr _name =		\
 +__ATTR(_name, 0644, show_##_name, store_##_name)
 +
 +struct cpufreq_policy *cpufreq_cpu_get(unsigned int cpu);
 +void cpufreq_cpu_put(struct cpufreq_policy *policy);
 +const char *cpufreq_get_current_driver(void);
 +
 +/*********************************************************************
 + *                        CPUFREQ 2.6. INTERFACE                     *
 + *********************************************************************/
 +u64 get_cpu_idle_time(unsigned int cpu, u64 *wall, int io_busy);
 +int cpufreq_get_policy(struct cpufreq_policy *policy, unsigned int cpu);
 +int cpufreq_update_policy(unsigned int cpu);
 +bool have_governor_per_policy(void);
 +struct kobject *get_governor_parent_kobj(struct cpufreq_policy *policy);
 +
 +#ifdef CONFIG_CPU_FREQ
 +/*
 + * query the current CPU frequency (in kHz). If zero, cpufreq couldn't detect it
 + */
 +unsigned int cpufreq_get(unsigned int cpu);
 +#else
 +static inline unsigned int cpufreq_get(unsigned int cpu)
 +{
 +	return 0;
 +}
 +#endif
 +
 +/*
 + * query the last known CPU freq (in kHz). If zero, cpufreq couldn't detect it
 + */
 +#ifdef CONFIG_CPU_FREQ
 +unsigned int cpufreq_quick_get(unsigned int cpu);
 +unsigned int cpufreq_quick_get_max(unsigned int cpu);
 +#else
 +static inline unsigned int cpufreq_quick_get(unsigned int cpu)
 +{
 +	return 0;
 +}
 +static inline unsigned int cpufreq_quick_get_max(unsigned int cpu)
 +{
 +	return 0;
 +}
 +#endif
 +
 +/*********************************************************************
 + *                       CPUFREQ DEFAULT GOVERNOR                    *
 + *********************************************************************/
 +
 +/*
 + * Performance governor is fallback governor if any other gov failed to auto
 + * load due latency restrictions
 + */
 +#ifdef CONFIG_CPU_FREQ_GOV_PERFORMANCE
 +extern struct cpufreq_governor cpufreq_gov_performance;
 +#endif
 +#ifdef CONFIG_CPU_FREQ_DEFAULT_GOV_PERFORMANCE
 +#define CPUFREQ_DEFAULT_GOVERNOR	(&cpufreq_gov_performance)
 +#elif defined(CONFIG_CPU_FREQ_DEFAULT_GOV_POWERSAVE)
 +extern struct cpufreq_governor cpufreq_gov_powersave;
 +#define CPUFREQ_DEFAULT_GOVERNOR	(&cpufreq_gov_powersave)
 +#elif defined(CONFIG_CPU_FREQ_DEFAULT_GOV_USERSPACE)
 +extern struct cpufreq_governor cpufreq_gov_userspace;
 +#define CPUFREQ_DEFAULT_GOVERNOR	(&cpufreq_gov_userspace)
 +#elif defined(CONFIG_CPU_FREQ_DEFAULT_GOV_ONDEMAND)
 +extern struct cpufreq_governor cpufreq_gov_ondemand;
 +#define CPUFREQ_DEFAULT_GOVERNOR	(&cpufreq_gov_ondemand)
 +#elif defined(CONFIG_CPU_FREQ_DEFAULT_GOV_CONSERVATIVE)
 +extern struct cpufreq_governor cpufreq_gov_conservative;
 +#define CPUFREQ_DEFAULT_GOVERNOR	(&cpufreq_gov_conservative)
 +#endif
 +
  /*********************************************************************
   *                     FREQUENCY TABLE HELPERS                       *
   *********************************************************************/
* Unmerged path drivers/cpufreq/acpi-cpufreq.c
* Unmerged path drivers/cpufreq/cpufreq.c
* Unmerged path include/linux/cpufreq.h
