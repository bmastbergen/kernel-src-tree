x86/cpufeatures: Clean up Spectre v2 related CPUID flags

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [x86] cpufeatures: Clean up Spectre v2 related CPUID flags (Paolo Bonzini) [1537379]
Rebuild_FUZZ: 96.30%
commit-author David Woodhouse <dwmw@amazon.co.uk>
commit 2961298efe1ea1b6fc0d7ee8b76018fa6c0bcef2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/2961298e.failed

We want to expose the hardware features simply in /proc/cpuinfo as "ibrs",
"ibpb" and "stibp". Since AMD has separate CPUID bits for those, use them
as the user-visible bits.

When the Intel SPEC_CTRL bit is set which indicates both IBRS and IBPB
capability, set those (AMD) bits accordingly. Likewise if the Intel STIBP
bit is set, set the AMD STIBP that's used for the generic hardware
capability.

Hide the rest from /proc/cpuinfo by putting "" in the comments. Including
RETPOLINE and RETPOLINE_AMD which shouldn't be visible there. There are
patches to make the sysfs vulnerabilities information non-readable by
non-root, and the same should apply to all information about which
mitigations are actually in use. Those *shouldn't* appear in /proc/cpuinfo.

The feature bit for whether IBPB is actually used, which is needed for
ALTERNATIVEs, is renamed to X86_FEATURE_USE_IBPB.

Originally-by: Borislav Petkov <bp@suse.de>
	Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: ak@linux.intel.com
	Cc: dave.hansen@intel.com
	Cc: karahmed@amazon.de
	Cc: arjan@linux.intel.com
	Cc: torvalds@linux-foundation.org
	Cc: peterz@infradead.org
	Cc: bp@alien8.de
	Cc: pbonzini@redhat.com
	Cc: tim.c.chen@linux.intel.com
	Cc: gregkh@linux-foundation.org
Link: https://lkml.kernel.org/r/1517070274-12128-2-git-send-email-dwmw@amazon.co.uk

(cherry picked from commit 2961298efe1ea1b6fc0d7ee8b76018fa6c0bcef2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/cpufeatures.h
#	arch/x86/include/asm/nospec-branch.h
#	arch/x86/kernel/cpu/bugs.c
#	arch/x86/kernel/cpu/intel.c
diff --cc arch/x86/kernel/cpu/bugs.c
index 4112be9a4659,32d8e6cdc09e..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -103,9 -55,259 +103,252 @@@ void __init check_bugs(void
  		'0' + (boot_cpu_data.x86 > 6 ? 6 : boot_cpu_data.x86);
  	alternative_instructions();
  
 -	fpu__init_check_bugs();
 -#else /* CONFIG_X86_64 */
 -	alternative_instructions();
 -
  	/*
 -	 * Make sure the first 2MB area is not mapped by huge pages
 -	 * There are typically fixed size MTRRs in there and overlapping
 -	 * MTRRs into large pages causes slow downs.
 -	 *
 -	 * Right now we don't do that with gbpages because there seems
 -	 * very little benefit for that case.
 +	 * kernel_fpu_begin/end() in check_fpu() relies on the patched
 +	 * alternative instructions.
  	 */
 -	if (!direct_gbpages)
 -		set_memory_4k((unsigned long)__va(0), 1);
 -#endif
 +	check_fpu();
  }
++<<<<<<< HEAD
++=======
+ 
+ /* The kernel command line selection */
+ enum spectre_v2_mitigation_cmd {
+ 	SPECTRE_V2_CMD_NONE,
+ 	SPECTRE_V2_CMD_AUTO,
+ 	SPECTRE_V2_CMD_FORCE,
+ 	SPECTRE_V2_CMD_RETPOLINE,
+ 	SPECTRE_V2_CMD_RETPOLINE_GENERIC,
+ 	SPECTRE_V2_CMD_RETPOLINE_AMD,
+ };
+ 
+ static const char *spectre_v2_strings[] = {
+ 	[SPECTRE_V2_NONE]			= "Vulnerable",
+ 	[SPECTRE_V2_RETPOLINE_MINIMAL]		= "Vulnerable: Minimal generic ASM retpoline",
+ 	[SPECTRE_V2_RETPOLINE_MINIMAL_AMD]	= "Vulnerable: Minimal AMD ASM retpoline",
+ 	[SPECTRE_V2_RETPOLINE_GENERIC]		= "Mitigation: Full generic retpoline",
+ 	[SPECTRE_V2_RETPOLINE_AMD]		= "Mitigation: Full AMD retpoline",
+ };
+ 
+ #undef pr_fmt
+ #define pr_fmt(fmt)     "Spectre V2 : " fmt
+ 
+ static enum spectre_v2_mitigation spectre_v2_enabled = SPECTRE_V2_NONE;
+ 
+ #ifdef RETPOLINE
+ static bool spectre_v2_bad_module;
+ 
+ bool retpoline_module_ok(bool has_retpoline)
+ {
+ 	if (spectre_v2_enabled == SPECTRE_V2_NONE || has_retpoline)
+ 		return true;
+ 
+ 	pr_err("System may be vunerable to spectre v2\n");
+ 	spectre_v2_bad_module = true;
+ 	return false;
+ }
+ 
+ static inline const char *spectre_v2_module_string(void)
+ {
+ 	return spectre_v2_bad_module ? " - vulnerable module loaded" : "";
+ }
+ #else
+ static inline const char *spectre_v2_module_string(void) { return ""; }
+ #endif
+ 
+ static void __init spec2_print_if_insecure(const char *reason)
+ {
+ 	if (boot_cpu_has_bug(X86_BUG_SPECTRE_V2))
+ 		pr_info("%s\n", reason);
+ }
+ 
+ static void __init spec2_print_if_secure(const char *reason)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V2))
+ 		pr_info("%s\n", reason);
+ }
+ 
+ static inline bool retp_compiler(void)
+ {
+ 	return __is_defined(RETPOLINE);
+ }
+ 
+ static inline bool match_option(const char *arg, int arglen, const char *opt)
+ {
+ 	int len = strlen(opt);
+ 
+ 	return len == arglen && !strncmp(arg, opt, len);
+ }
+ 
+ static enum spectre_v2_mitigation_cmd __init spectre_v2_parse_cmdline(void)
+ {
+ 	char arg[20];
+ 	int ret;
+ 
+ 	ret = cmdline_find_option(boot_command_line, "spectre_v2", arg,
+ 				  sizeof(arg));
+ 	if (ret > 0)  {
+ 		if (match_option(arg, ret, "off")) {
+ 			goto disable;
+ 		} else if (match_option(arg, ret, "on")) {
+ 			spec2_print_if_secure("force enabled on command line.");
+ 			return SPECTRE_V2_CMD_FORCE;
+ 		} else if (match_option(arg, ret, "retpoline")) {
+ 			spec2_print_if_insecure("retpoline selected on command line.");
+ 			return SPECTRE_V2_CMD_RETPOLINE;
+ 		} else if (match_option(arg, ret, "retpoline,amd")) {
+ 			if (boot_cpu_data.x86_vendor != X86_VENDOR_AMD) {
+ 				pr_err("retpoline,amd selected but CPU is not AMD. Switching to AUTO select\n");
+ 				return SPECTRE_V2_CMD_AUTO;
+ 			}
+ 			spec2_print_if_insecure("AMD retpoline selected on command line.");
+ 			return SPECTRE_V2_CMD_RETPOLINE_AMD;
+ 		} else if (match_option(arg, ret, "retpoline,generic")) {
+ 			spec2_print_if_insecure("generic retpoline selected on command line.");
+ 			return SPECTRE_V2_CMD_RETPOLINE_GENERIC;
+ 		} else if (match_option(arg, ret, "auto")) {
+ 			return SPECTRE_V2_CMD_AUTO;
+ 		}
+ 	}
+ 
+ 	if (!cmdline_find_option_bool(boot_command_line, "nospectre_v2"))
+ 		return SPECTRE_V2_CMD_AUTO;
+ disable:
+ 	spec2_print_if_insecure("disabled on command line.");
+ 	return SPECTRE_V2_CMD_NONE;
+ }
+ 
+ /* Check for Skylake-like CPUs (for RSB handling) */
+ static bool __init is_skylake_era(void)
+ {
+ 	if (boot_cpu_data.x86_vendor == X86_VENDOR_INTEL &&
+ 	    boot_cpu_data.x86 == 6) {
+ 		switch (boot_cpu_data.x86_model) {
+ 		case INTEL_FAM6_SKYLAKE_MOBILE:
+ 		case INTEL_FAM6_SKYLAKE_DESKTOP:
+ 		case INTEL_FAM6_SKYLAKE_X:
+ 		case INTEL_FAM6_KABYLAKE_MOBILE:
+ 		case INTEL_FAM6_KABYLAKE_DESKTOP:
+ 			return true;
+ 		}
+ 	}
+ 	return false;
+ }
+ 
+ static void __init spectre_v2_select_mitigation(void)
+ {
+ 	enum spectre_v2_mitigation_cmd cmd = spectre_v2_parse_cmdline();
+ 	enum spectre_v2_mitigation mode = SPECTRE_V2_NONE;
+ 
+ 	/*
+ 	 * If the CPU is not affected and the command line mode is NONE or AUTO
+ 	 * then nothing to do.
+ 	 */
+ 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V2) &&
+ 	    (cmd == SPECTRE_V2_CMD_NONE || cmd == SPECTRE_V2_CMD_AUTO))
+ 		return;
+ 
+ 	switch (cmd) {
+ 	case SPECTRE_V2_CMD_NONE:
+ 		return;
+ 
+ 	case SPECTRE_V2_CMD_FORCE:
+ 		/* FALLTRHU */
+ 	case SPECTRE_V2_CMD_AUTO:
+ 		goto retpoline_auto;
+ 
+ 	case SPECTRE_V2_CMD_RETPOLINE_AMD:
+ 		if (IS_ENABLED(CONFIG_RETPOLINE))
+ 			goto retpoline_amd;
+ 		break;
+ 	case SPECTRE_V2_CMD_RETPOLINE_GENERIC:
+ 		if (IS_ENABLED(CONFIG_RETPOLINE))
+ 			goto retpoline_generic;
+ 		break;
+ 	case SPECTRE_V2_CMD_RETPOLINE:
+ 		if (IS_ENABLED(CONFIG_RETPOLINE))
+ 			goto retpoline_auto;
+ 		break;
+ 	}
+ 	pr_err("kernel not compiled with retpoline; no mitigation available!");
+ 	return;
+ 
+ retpoline_auto:
+ 	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD) {
+ 	retpoline_amd:
+ 		if (!boot_cpu_has(X86_FEATURE_LFENCE_RDTSC)) {
+ 			pr_err("LFENCE not serializing. Switching to generic retpoline\n");
+ 			goto retpoline_generic;
+ 		}
+ 		mode = retp_compiler() ? SPECTRE_V2_RETPOLINE_AMD :
+ 					 SPECTRE_V2_RETPOLINE_MINIMAL_AMD;
+ 		setup_force_cpu_cap(X86_FEATURE_RETPOLINE_AMD);
+ 		setup_force_cpu_cap(X86_FEATURE_RETPOLINE);
+ 	} else {
+ 	retpoline_generic:
+ 		mode = retp_compiler() ? SPECTRE_V2_RETPOLINE_GENERIC :
+ 					 SPECTRE_V2_RETPOLINE_MINIMAL;
+ 		setup_force_cpu_cap(X86_FEATURE_RETPOLINE);
+ 	}
+ 
+ 	spectre_v2_enabled = mode;
+ 	pr_info("%s\n", spectre_v2_strings[mode]);
+ 
+ 	/*
+ 	 * If neither SMEP or KPTI are available, there is a risk of
+ 	 * hitting userspace addresses in the RSB after a context switch
+ 	 * from a shallow call stack to a deeper one. To prevent this fill
+ 	 * the entire RSB, even when using IBRS.
+ 	 *
+ 	 * Skylake era CPUs have a separate issue with *underflow* of the
+ 	 * RSB, when they will predict 'ret' targets from the generic BTB.
+ 	 * The proper mitigation for this is IBRS. If IBRS is not supported
+ 	 * or deactivated in favour of retpolines the RSB fill on context
+ 	 * switch is required.
+ 	 */
+ 	if ((!boot_cpu_has(X86_FEATURE_PTI) &&
+ 	     !boot_cpu_has(X86_FEATURE_SMEP)) || is_skylake_era()) {
+ 		setup_force_cpu_cap(X86_FEATURE_RSB_CTXSW);
+ 		pr_info("Filling RSB on context switch\n");
+ 	}
+ 
+ 	/* Initialize Indirect Branch Prediction Barrier if supported */
+ 	if (boot_cpu_has(X86_FEATURE_IBPB)) {
+ 		setup_force_cpu_cap(X86_FEATURE_USE_IBPB);
+ 		pr_info("Enabling Indirect Branch Prediction Barrier\n");
+ 	}
+ }
+ 
+ #undef pr_fmt
+ 
+ #ifdef CONFIG_SYSFS
+ ssize_t cpu_show_meltdown(struct device *dev,
+ 			  struct device_attribute *attr, char *buf)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_CPU_MELTDOWN))
+ 		return sprintf(buf, "Not affected\n");
+ 	if (boot_cpu_has(X86_FEATURE_PTI))
+ 		return sprintf(buf, "Mitigation: PTI\n");
+ 	return sprintf(buf, "Vulnerable\n");
+ }
+ 
+ ssize_t cpu_show_spectre_v1(struct device *dev,
+ 			    struct device_attribute *attr, char *buf)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V1))
+ 		return sprintf(buf, "Not affected\n");
+ 	return sprintf(buf, "Vulnerable\n");
+ }
+ 
+ ssize_t cpu_show_spectre_v2(struct device *dev,
+ 			    struct device_attribute *attr, char *buf)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V2))
+ 		return sprintf(buf, "Not affected\n");
+ 
+ 	return sprintf(buf, "%s%s%s\n", spectre_v2_strings[spectre_v2_enabled],
+ 		       boot_cpu_has(X86_FEATURE_USE_IBPB) ? ", IBPB" : "",
+ 		       spectre_v2_module_string());
+ }
+ #endif
++>>>>>>> 2961298efe1e (x86/cpufeatures: Clean up Spectre v2 related CPUID flags)
diff --cc arch/x86/kernel/cpu/intel.c
index 74476001995a,0c8b916abced..000000000000
--- a/arch/x86/kernel/cpu/intel.c
+++ b/arch/x86/kernel/cpu/intel.c
@@@ -123,13 -172,31 +123,38 @@@ static void early_init_intel(struct cpu
  		(c->x86 == 0x6 && c->x86_model >= 0x0e))
  		set_cpu_cap(c, X86_FEATURE_CONSTANT_TSC);
  
 -	if (c->x86 >= 6 && !cpu_has(c, X86_FEATURE_IA64))
 -		c->microcode = intel_get_microcode_revision();
 +	if (c->x86 >= 6 && !cpu_has(c, X86_FEATURE_IA64)) {
 +		unsigned lower_word;
  
++<<<<<<< HEAD
 +		wrmsr(MSR_IA32_UCODE_REV, 0, 0);
 +		/* Required by the SDM */
 +		sync_core();
 +		rdmsr(MSR_IA32_UCODE_REV, lower_word, c->microcode);
++=======
+ 	/*
+ 	 * The Intel SPEC_CTRL CPUID bit implies IBRS and IBPB support,
+ 	 * and they also have a different bit for STIBP support. Also,
+ 	 * a hypervisor might have set the individual AMD bits even on
+ 	 * Intel CPUs, for finer-grained selection of what's available.
+ 	 */
+ 	if (cpu_has(c, X86_FEATURE_SPEC_CTRL)) {
+ 		set_cpu_cap(c, X86_FEATURE_IBRS);
+ 		set_cpu_cap(c, X86_FEATURE_IBPB);
+ 	}
+ 	if (cpu_has(c, X86_FEATURE_INTEL_STIBP))
+ 		set_cpu_cap(c, X86_FEATURE_STIBP);
+ 
+ 	/* Now if any of them are set, check the blacklist and clear the lot */
+ 	if ((cpu_has(c, X86_FEATURE_IBRS) || cpu_has(c, X86_FEATURE_IBPB) ||
+ 	     cpu_has(c, X86_FEATURE_STIBP)) && bad_spectre_microcode(c)) {
+ 		pr_warn("Intel Spectre v2 broken microcode detected; disabling Speculation Control\n");
+ 		clear_cpu_cap(c, X86_FEATURE_IBRS);
+ 		clear_cpu_cap(c, X86_FEATURE_IBPB);
+ 		clear_cpu_cap(c, X86_FEATURE_STIBP);
+ 		clear_cpu_cap(c, X86_FEATURE_SPEC_CTRL);
+ 		clear_cpu_cap(c, X86_FEATURE_INTEL_STIBP);
++>>>>>>> 2961298efe1e (x86/cpufeatures: Clean up Spectre v2 related CPUID flags)
  	}
  
  	/*
* Unmerged path arch/x86/include/asm/cpufeatures.h
* Unmerged path arch/x86/include/asm/nospec-branch.h
* Unmerged path arch/x86/include/asm/cpufeatures.h
* Unmerged path arch/x86/include/asm/nospec-branch.h
* Unmerged path arch/x86/kernel/cpu/bugs.c
* Unmerged path arch/x86/kernel/cpu/intel.c
