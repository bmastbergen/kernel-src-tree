qed: Encapsulate interrupt counters in struct

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Mintz, Yuval <Yuval.Mintz@cavium.com>
commit 726fdbe9fa7ebccda1579716f68f8bae6fa9c87a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/726fdbe9.failed

We already have an API struct that contains interrupt-related
numbers. Use it to encapsulate all information relating to the
status of SBs as (used|free).

	Signed-off-by: Yuval Mintz <Yuval.Mintz@cavium.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 726fdbe9fa7ebccda1579716f68f8bae6fa9c87a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/qlogic/qed/qed_dev.c
#	drivers/net/ethernet/qlogic/qed/qed_int.c
#	drivers/net/ethernet/qlogic/qed/qed_int.h
#	drivers/net/ethernet/qlogic/qed/qed_sriov.c
diff --cc drivers/net/ethernet/qlogic/qed/qed_dev.c
index 1b5a3d62b9f3,1fff0473ddbb..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_dev.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_dev.c
@@@ -2238,12 -2121,170 +2238,173 @@@ static const char *qed_hw_get_resc_name
  	}
  }
  
 -static int
 -__qed_hw_set_soft_resc_size(struct qed_hwfn *p_hwfn,
 -			    struct qed_ptt *p_ptt,
 -			    enum qed_resources res_id,
 -			    u32 resc_max_val, u32 *p_mcp_resp)
 +static int qed_hw_set_resc_info(struct qed_hwfn *p_hwfn,
 +				enum qed_resources res_id)
  {
++<<<<<<< HEAD
 +	u32 dflt_resc_num = 0, dflt_resc_start = 0, mcp_resp, mcp_param;
 +	u32 *p_resc_num, *p_resc_start;
 +	struct resource_info resc_info;
++=======
+ 	int rc;
+ 
+ 	rc = qed_mcp_set_resc_max_val(p_hwfn, p_ptt, res_id,
+ 				      resc_max_val, p_mcp_resp);
+ 	if (rc) {
+ 		DP_NOTICE(p_hwfn,
+ 			  "MFW response failure for a max value setting of resource %d [%s]\n",
+ 			  res_id, qed_hw_get_resc_name(res_id));
+ 		return rc;
+ 	}
+ 
+ 	if (*p_mcp_resp != FW_MSG_CODE_RESOURCE_ALLOC_OK)
+ 		DP_INFO(p_hwfn,
+ 			"Failed to set the max value of resource %d [%s]. mcp_resp = 0x%08x.\n",
+ 			res_id, qed_hw_get_resc_name(res_id), *p_mcp_resp);
+ 
+ 	return 0;
+ }
+ 
+ static int
+ qed_hw_set_soft_resc_size(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)
+ {
+ 	bool b_ah = QED_IS_AH(p_hwfn->cdev);
+ 	u32 resc_max_val, mcp_resp;
+ 	u8 res_id;
+ 	int rc;
+ 
+ 	for (res_id = 0; res_id < QED_MAX_RESC; res_id++) {
+ 		switch (res_id) {
+ 		case QED_LL2_QUEUE:
+ 			resc_max_val = MAX_NUM_LL2_RX_QUEUES;
+ 			break;
+ 		case QED_RDMA_CNQ_RAM:
+ 			/* No need for a case for QED_CMDQS_CQS since
+ 			 * CNQ/CMDQS are the same resource.
+ 			 */
+ 			resc_max_val = NUM_OF_CMDQS_CQS;
+ 			break;
+ 		case QED_RDMA_STATS_QUEUE:
+ 			resc_max_val = b_ah ? RDMA_NUM_STATISTIC_COUNTERS_K2
+ 			    : RDMA_NUM_STATISTIC_COUNTERS_BB;
+ 			break;
+ 		case QED_BDQ:
+ 			resc_max_val = BDQ_NUM_RESOURCES;
+ 			break;
+ 		default:
+ 			continue;
+ 		}
+ 
+ 		rc = __qed_hw_set_soft_resc_size(p_hwfn, p_ptt, res_id,
+ 						 resc_max_val, &mcp_resp);
+ 		if (rc)
+ 			return rc;
+ 
+ 		/* There's no point to continue to the next resource if the
+ 		 * command is not supported by the MFW.
+ 		 * We do continue if the command is supported but the resource
+ 		 * is unknown to the MFW. Such a resource will be later
+ 		 * configured with the default allocation values.
+ 		 */
+ 		if (mcp_resp == FW_MSG_CODE_UNSUPPORTED)
+ 			return -EINVAL;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static
+ int qed_hw_get_dflt_resc(struct qed_hwfn *p_hwfn,
+ 			 enum qed_resources res_id,
+ 			 u32 *p_resc_num, u32 *p_resc_start)
+ {
+ 	u8 num_funcs = p_hwfn->num_funcs_on_engine;
+ 	bool b_ah = QED_IS_AH(p_hwfn->cdev);
+ 	struct qed_sb_cnt_info sb_cnt_info;
+ 
+ 	switch (res_id) {
+ 	case QED_L2_QUEUE:
+ 		*p_resc_num = (b_ah ? MAX_NUM_L2_QUEUES_K2 :
+ 			       MAX_NUM_L2_QUEUES_BB) / num_funcs;
+ 		break;
+ 	case QED_VPORT:
+ 		*p_resc_num = (b_ah ? MAX_NUM_VPORTS_K2 :
+ 			       MAX_NUM_VPORTS_BB) / num_funcs;
+ 		break;
+ 	case QED_RSS_ENG:
+ 		*p_resc_num = (b_ah ? ETH_RSS_ENGINE_NUM_K2 :
+ 			       ETH_RSS_ENGINE_NUM_BB) / num_funcs;
+ 		break;
+ 	case QED_PQ:
+ 		*p_resc_num = (b_ah ? MAX_QM_TX_QUEUES_K2 :
+ 			       MAX_QM_TX_QUEUES_BB) / num_funcs;
+ 		*p_resc_num &= ~0x7;	/* The granularity of the PQs is 8 */
+ 		break;
+ 	case QED_RL:
+ 		*p_resc_num = MAX_QM_GLOBAL_RLS / num_funcs;
+ 		break;
+ 	case QED_MAC:
+ 	case QED_VLAN:
+ 		/* Each VFC resource can accommodate both a MAC and a VLAN */
+ 		*p_resc_num = ETH_NUM_MAC_FILTERS / num_funcs;
+ 		break;
+ 	case QED_ILT:
+ 		*p_resc_num = (b_ah ? PXP_NUM_ILT_RECORDS_K2 :
+ 			       PXP_NUM_ILT_RECORDS_BB) / num_funcs;
+ 		break;
+ 	case QED_LL2_QUEUE:
+ 		*p_resc_num = MAX_NUM_LL2_RX_QUEUES / num_funcs;
+ 		break;
+ 	case QED_RDMA_CNQ_RAM:
+ 	case QED_CMDQS_CQS:
+ 		/* CNQ/CMDQS are the same resource */
+ 		*p_resc_num = NUM_OF_CMDQS_CQS / num_funcs;
+ 		break;
+ 	case QED_RDMA_STATS_QUEUE:
+ 		*p_resc_num = (b_ah ? RDMA_NUM_STATISTIC_COUNTERS_K2 :
+ 			       RDMA_NUM_STATISTIC_COUNTERS_BB) / num_funcs;
+ 		break;
+ 	case QED_BDQ:
+ 		if (p_hwfn->hw_info.personality != QED_PCI_ISCSI &&
+ 		    p_hwfn->hw_info.personality != QED_PCI_FCOE)
+ 			*p_resc_num = 0;
+ 		else
+ 			*p_resc_num = 1;
+ 		break;
+ 	case QED_SB:
+ 		memset(&sb_cnt_info, 0, sizeof(sb_cnt_info));
+ 		qed_int_get_num_sbs(p_hwfn, &sb_cnt_info);
+ 		*p_resc_num = sb_cnt_info.cnt;
+ 		break;
+ 	default:
+ 		return -EINVAL;
+ 	}
+ 
+ 	switch (res_id) {
+ 	case QED_BDQ:
+ 		if (!*p_resc_num)
+ 			*p_resc_start = 0;
+ 		else if (p_hwfn->cdev->num_ports_in_engine == 4)
+ 			*p_resc_start = p_hwfn->port_id;
+ 		else if (p_hwfn->hw_info.personality == QED_PCI_ISCSI)
+ 			*p_resc_start = p_hwfn->port_id;
+ 		else if (p_hwfn->hw_info.personality == QED_PCI_FCOE)
+ 			*p_resc_start = p_hwfn->port_id + 2;
+ 		break;
+ 	default:
+ 		*p_resc_start = *p_resc_num * p_hwfn->enabled_func_idx;
+ 		break;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int __qed_hw_set_resc_info(struct qed_hwfn *p_hwfn,
+ 				  enum qed_resources res_id)
+ {
+ 	u32 dflt_resc_num = 0, dflt_resc_start = 0;
+ 	u32 mcp_resp, *p_resc_num, *p_resc_start;
++>>>>>>> 726fdbe9fa7e (qed: Encapsulate interrupt counters in struct)
  	int rc;
  
  	p_resc_num = &RESC_NUM(p_hwfn, res_id);
diff --cc drivers/net/ethernet/qlogic/qed/qed_int.c
index 37b56d7fa1f8,c9164e27a1b2..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_int.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_int.c
@@@ -3029,8 -1769,8 +3029,13 @@@ void qed_int_igu_init_pure_rt(struct qe
  			      bool b_set, bool b_slowpath)
  {
  	u32 igu_base_sb = p_hwfn->hw_info.p_igu_info->igu_base_sb;
++<<<<<<< HEAD
 +	u32 igu_sb_cnt = p_hwfn->hw_info.p_igu_info->igu_sb_cnt;
 +	u32 sb_id = 0, val = 0;
++=======
+ 	u32 igu_sb_cnt = p_hwfn->hw_info.p_igu_info->usage.cnt;
+ 	u32 igu_sb_id = 0, val = 0;
++>>>>>>> 726fdbe9fa7e (qed: Encapsulate interrupt counters in struct)
  
  	val = qed_rd(p_hwfn, p_ptt, IGU_REG_BLOCK_CONFIGURATION);
  	val |= IGU_REG_BLOCK_CONFIGURATION_VF_CLEANUP_EN;
@@@ -3101,12 -1825,14 +3106,18 @@@ int qed_int_igu_read_cam(struct qed_hwf
  
  	p_igu_info = p_hwfn->hw_info.p_igu_info;
  
++<<<<<<< HEAD
 +	/* Initialize base sb / sb cnt for PFs and VFs */
 +	p_igu_info->igu_base_sb		= 0xffff;
 +	p_igu_info->igu_sb_cnt		= 0;
 +	p_igu_info->igu_dsb_id		= 0xffff;
 +	p_igu_info->igu_base_sb_iov	= 0xffff;
++=======
+        /* Initialize base sb / sb cnt for PFs and VFs */
+ 	p_igu_info->igu_base_sb = 0xffff;
+ 	p_igu_info->igu_base_sb_iov = 0xffff;
++>>>>>>> 726fdbe9fa7e (qed: Encapsulate interrupt counters in struct)
  
 -	/* Distinguish between existent and non-existent default SB */
 -	p_igu_info->igu_dsb_id = QED_SB_INVALID_IDX;
 -
 -	/* Find the range of VF ids whose SB belong to this PF */
  	if (p_hwfn->cdev->p_iov_info) {
  		struct qed_hw_sriov_info *p_iov = p_hwfn->cdev->p_iov_info;
  
@@@ -3114,112 -1840,72 +3125,162 @@@
  		max_vf	= p_iov->first_vf_in_pf + p_iov->total_vfs;
  	}
  
 -	for (igu_sb_id = 0;
 -	     igu_sb_id < QED_MAPPING_MEMORY_SIZE(p_hwfn->cdev); igu_sb_id++) {
 -		/* Read current entry; Notice it might not belong to this PF */
 -		qed_int_igu_read_cam_block(p_hwfn, p_ptt, igu_sb_id);
 -		p_block = &p_igu_info->entry[igu_sb_id];
 +	for (sb_id = 0; sb_id < QED_MAPPING_MEMORY_SIZE(p_hwfn->cdev);
 +	     sb_id++) {
 +		blk = &p_igu_info->igu_map.igu_blocks[sb_id];
  
 -		if ((p_block->is_pf) &&
 -		    (p_block->function_id == p_hwfn->rel_pf_id)) {
 -			p_block->status = QED_IGU_STATUS_PF |
 -					  QED_IGU_STATUS_VALID |
 -					  QED_IGU_STATUS_FREE;
 +		val	= qed_int_igu_read_cam_block(p_hwfn, p_ptt, sb_id);
 +
++<<<<<<< HEAD
 +		/* stop scanning when hit first invalid PF entry */
 +		if (!GET_FIELD(val, IGU_MAPPING_LINE_VALID) &&
 +		    GET_FIELD(val, IGU_MAPPING_LINE_PF_VALID))
 +			break;
  
 +		if (blk->is_pf) {
 +			if (blk->function_id == p_hwfn->rel_pf_id) {
 +				blk->status |= QED_IGU_STATUS_PF;
 +
 +				if (blk->vector_number == 0) {
 +					if (p_igu_info->igu_dsb_id == 0xffff)
 +						p_igu_info->igu_dsb_id = sb_id;
 +				} else {
 +					if (p_igu_info->igu_base_sb ==
 +					    0xffff) {
 +						p_igu_info->igu_base_sb = sb_id;
 +					} else if (prev_sb_id != sb_id - 1) {
 +						DP_NOTICE(p_hwfn->cdev,
 +							  "consecutive igu vectors for HWFN %x broken",
 +							  p_hwfn->rel_pf_id);
 +						break;
 +					}
 +					prev_sb_id = sb_id;
 +					/* we don't count the default */
 +					(p_igu_info->igu_sb_cnt)++;
 +				}
 +			}
 +		} else {
 +			if ((blk->function_id >= min_vf) &&
 +			    (blk->function_id < max_vf)) {
 +				/* Available for VFs of this PF */
 +				if (p_igu_info->igu_base_sb_iov == 0xffff) {
 +					p_igu_info->igu_base_sb_iov = sb_id;
 +				} else if (last_iov_sb_id != sb_id - 1) {
 +					if (!val) {
 +						DP_VERBOSE(p_hwfn->cdev,
 +							   NETIF_MSG_INTR,
 +							   "First uninitialized IGU CAM entry at index 0x%04x\n",
 +							   sb_id);
 +					} else {
 +						DP_NOTICE(p_hwfn->cdev,
 +							  "Consecutive igu vectors for HWFN %x vfs is broken [jumps from %04x to %04x]\n",
 +							  p_hwfn->rel_pf_id,
 +							  last_iov_sb_id,
 +							  sb_id); }
 +					break;
 +				}
 +				blk->status |= QED_IGU_STATUS_FREE;
 +				p_hwfn->hw_info.p_igu_info->free_blks++;
 +				last_iov_sb_id = sb_id;
 +			}
++=======
+ 			if (p_igu_info->igu_dsb_id != QED_SB_INVALID_IDX) {
+ 				if (p_igu_info->igu_base_sb == 0xffff)
+ 					p_igu_info->igu_base_sb = igu_sb_id;
+ 				p_igu_info->usage.cnt++;
+ 			}
+ 		} else if (!(p_block->is_pf) &&
+ 			   (p_block->function_id >= min_vf) &&
+ 			   (p_block->function_id < max_vf)) {
+ 			/* Available for VFs of this PF */
+ 			p_block->status = QED_IGU_STATUS_VALID |
+ 					  QED_IGU_STATUS_FREE;
+ 
+ 			if (p_igu_info->igu_base_sb_iov == 0xffff)
+ 				p_igu_info->igu_base_sb_iov = igu_sb_id;
+ 			p_igu_info->usage.iov_cnt++;
+ 		}
+ 
+ 		/* Mark the First entry belonging to the PF or its VFs
+ 		 * as the default SB.
+ 		 */
+ 		if ((p_block->status & QED_IGU_STATUS_VALID) &&
+ 		    (p_igu_info->igu_dsb_id == QED_SB_INVALID_IDX)) {
+ 			p_igu_info->igu_dsb_id = igu_sb_id;
+ 			p_block->status |= QED_IGU_STATUS_DSB;
+ 		}
+ 
+ 		/* limit number of prints by having each PF print only its
+ 		 * entries with the exception of PF0 which would print
+ 		 * everything.
+ 		 */
+ 		if ((p_block->status & QED_IGU_STATUS_VALID) ||
+ 		    (p_hwfn->abs_pf_id == 0)) {
+ 			DP_VERBOSE(p_hwfn, NETIF_MSG_INTR,
+ 				   "IGU_BLOCK: [SB 0x%04x] func_id = %d is_pf = %d vector_num = 0x%x\n",
+ 				   igu_sb_id, p_block->function_id,
+ 				   p_block->is_pf, p_block->vector_number);
++>>>>>>> 726fdbe9fa7e (qed: Encapsulate interrupt counters in struct)
  		}
  	}
  
 -	if (p_igu_info->igu_dsb_id == QED_SB_INVALID_IDX) {
 +	/* There's a possibility the igu_sb_cnt_iov doesn't properly reflect
 +	 * the number of VF SBs [especially for first VF on engine, as we can't
 +	 * diffrentiate between empty entries and its entries].
 +	 * Since we don't really support more SBs than VFs today, prevent any
 +	 * such configuration by sanitizing the number of SBs to equal the
 +	 * number of VFs.
 +	 */
 +	if (IS_PF_SRIOV(p_hwfn)) {
 +		u16 total_vfs = p_hwfn->cdev->p_iov_info->total_vfs;
 +
++<<<<<<< HEAD
 +		if (total_vfs < p_igu_info->free_blks) {
 +			DP_VERBOSE(p_hwfn,
 +				   (NETIF_MSG_INTR | QED_MSG_IOV),
 +				   "Limiting number of SBs for IOV - %04x --> %04x\n",
 +				   p_igu_info->free_blks,
 +				   p_hwfn->cdev->p_iov_info->total_vfs);
 +			p_igu_info->free_blks = total_vfs;
 +		} else if (total_vfs > p_igu_info->free_blks) {
 +			DP_NOTICE(p_hwfn,
 +				  "IGU has only %04x SBs for VFs while the device has %04x VFs\n",
 +				  p_igu_info->free_blks, total_vfs);
 +			return -EINVAL;
 +		}
 +	}
 +	p_igu_info->igu_sb_cnt_iov = p_igu_info->free_blks;
 +
 +	DP_VERBOSE(
 +		p_hwfn,
 +		NETIF_MSG_INTR,
 +		"IGU igu_base_sb=0x%x [IOV 0x%x] igu_sb_cnt=%d [IOV 0x%x] igu_dsb_id=0x%x\n",
 +		p_igu_info->igu_base_sb,
 +		p_igu_info->igu_base_sb_iov,
 +		p_igu_info->igu_sb_cnt,
 +		p_igu_info->igu_sb_cnt_iov,
 +		p_igu_info->igu_dsb_id);
 +
 +	if (p_igu_info->igu_base_sb == 0xffff ||
 +	    p_igu_info->igu_dsb_id == 0xffff ||
 +	    p_igu_info->igu_sb_cnt == 0) {
  		DP_NOTICE(p_hwfn,
 -			  "IGU CAM returned invalid values igu_dsb_id=0x%x\n",
 -			  p_igu_info->igu_dsb_id);
 +			  "IGU CAM returned invalid values igu_base_sb=0x%x igu_sb_cnt=%d igu_dsb_id=0x%x\n",
 +			   p_igu_info->igu_base_sb,
 +			   p_igu_info->igu_sb_cnt,
 +			   p_igu_info->igu_dsb_id);
  		return -EINVAL;
  	}
 -
++=======
+ 	/* All non default SB are considered free at this point */
+ 	p_igu_info->usage.free_cnt = p_igu_info->usage.cnt;
+ 	p_igu_info->usage.free_cnt_iov = p_igu_info->usage.iov_cnt;
+ 
+ 	DP_VERBOSE(p_hwfn, NETIF_MSG_INTR,
+ 		   "igu_dsb_id=0x%x, num Free SBs - PF: %04x VF: %04x\n",
+ 		   p_igu_info->igu_dsb_id,
+ 		   p_igu_info->usage.cnt, p_igu_info->usage.iov_cnt);
++>>>>>>> 726fdbe9fa7e (qed: Encapsulate interrupt counters in struct)
  
  	return 0;
  }
diff --cc drivers/net/ethernet/qlogic/qed/qed_int.h
index a8e48e14efef,5a0e8f02c969..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_int.h
+++ b/drivers/net/ethernet/qlogic/qed/qed_int.h
@@@ -210,18 -213,14 +210,28 @@@ struct qed_igu_block 
  	u8	is_pf;
  };
  
 +struct qed_igu_map {
 +	struct qed_igu_block igu_blocks[MAX_TOT_SB_PER_PATH];
 +};
 +
  struct qed_igu_info {
++<<<<<<< HEAD
 +	struct qed_igu_map	igu_map;
 +	u16			igu_dsb_id;
 +	u16			igu_base_sb;
 +	u16			igu_base_sb_iov;
 +	u16			igu_sb_cnt;
 +	u16			igu_sb_cnt_iov;
 +	u16			free_blks;
++=======
+ 	struct qed_igu_block entry[MAX_TOT_SB_PER_PATH];
+ 	u16 igu_dsb_id;
+ 
+ 	u16 igu_base_sb;
+ 	u16 igu_base_sb_iov;
+ 	struct qed_sb_cnt_info usage;
+ 
++>>>>>>> 726fdbe9fa7e (qed: Encapsulate interrupt counters in struct)
  };
  
  /* TODO Names of function may change... */
diff --cc drivers/net/ethernet/qlogic/qed/qed_sriov.c
index c231e788de76,62b207a80a03..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_sriov.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_sriov.c
@@@ -872,11 -872,11 +872,11 @@@ static u8 qed_iov_alloc_vf_igu_sbs(stru
  	int qid = 0, igu_id = 0;
  	u32 val = 0;
  
 -	igu_blocks = p_hwfn->hw_info.p_igu_info->entry;
 +	igu_blocks = p_hwfn->hw_info.p_igu_info->igu_map.igu_blocks;
  
- 	if (num_rx_queues > p_hwfn->hw_info.p_igu_info->free_blks)
- 		num_rx_queues = p_hwfn->hw_info.p_igu_info->free_blks;
- 	p_hwfn->hw_info.p_igu_info->free_blks -= num_rx_queues;
+ 	if (num_rx_queues > p_hwfn->hw_info.p_igu_info->usage.free_cnt_iov)
+ 		num_rx_queues = p_hwfn->hw_info.p_igu_info->usage.free_cnt_iov;
+ 	p_hwfn->hw_info.p_igu_info->usage.free_cnt_iov -= num_rx_queues;
  
  	SET_FIELD(val, IGU_MAPPING_LINE_FUNCTION_NUMBER, vf->abs_vf_id);
  	SET_FIELD(val, IGU_MAPPING_LINE_VALID, 1);
@@@ -931,10 -931,8 +931,15 @@@ static void qed_iov_free_vf_igu_sbs(str
  		SET_FIELD(val, IGU_MAPPING_LINE_VALID, 0);
  		qed_wr(p_hwfn, p_ptt, addr, val);
  
++<<<<<<< HEAD
 +		p_info->igu_map.igu_blocks[igu_id].status |=
 +		    QED_IGU_STATUS_FREE;
 +
 +		p_hwfn->hw_info.p_igu_info->free_blks++;
++=======
+ 		p_info->entry[igu_id].status |= QED_IGU_STATUS_FREE;
+ 		p_hwfn->hw_info.p_igu_info->usage.free_cnt_iov++;
++>>>>>>> 726fdbe9fa7e (qed: Encapsulate interrupt counters in struct)
  	}
  
  	vf->num_sbs = 0;
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_dev.c
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_int.c
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_int.h
diff --git a/drivers/net/ethernet/qlogic/qed/qed_main.c b/drivers/net/ethernet/qlogic/qed/qed_main.c
index 545e79f7504c..535f8bfa3b88 100644
--- a/drivers/net/ethernet/qlogic/qed/qed_main.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_main.c
@@ -732,7 +732,7 @@ static int qed_slowpath_setup_int(struct qed_dev *cdev,
 	for_each_hwfn(cdev, i) {
 		memset(&sb_cnt_info, 0, sizeof(sb_cnt_info));
 		qed_int_get_num_sbs(&cdev->hwfns[i], &sb_cnt_info);
-		cdev->int_params.in.num_vectors += sb_cnt_info.sb_cnt;
+		cdev->int_params.in.num_vectors += sb_cnt_info.cnt;
 		cdev->int_params.in.num_vectors++; /* slowpath */
 	}
 
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_sriov.c
diff --git a/include/linux/qed/qed_if.h b/include/linux/qed/qed_if.h
index cbe538f3b78a..e9761ae85795 100644
--- a/include/linux/qed/qed_if.h
+++ b/include/linux/qed/qed_if.h
@@ -874,9 +874,15 @@ struct qed_eth_stats {
 #define TX_PI(tc)       (RX_PI + 1 + tc)
 
 struct qed_sb_cnt_info {
-	int	sb_cnt;
-	int	sb_iov_cnt;
-	int	sb_free_blk;
+	/* Original, current, and free SBs for PF */
+	int orig;
+	int cnt;
+	int free_cnt;
+
+	/* Original, current and free SBS for child VFs */
+	int iov_orig;
+	int iov_cnt;
+	int free_cnt_iov;
 };
 
 static inline u16 qed_sb_update_sb_idx(struct qed_sb_info *sb_info)
