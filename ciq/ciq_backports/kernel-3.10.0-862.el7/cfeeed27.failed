x86/dumpstack: Allow preemption in show_stack_log_lvl() and dump_trace()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [x86] dumpstack: Allow preemption in show_stack_log_lvl() and dump_trace() (Josh Poimboeuf) [1430637]
Rebuild_FUZZ: 97.14%
commit-author Josh Poimboeuf <jpoimboe@redhat.com>
commit cfeeed279dc2fa83a00fbe4856ebd231d56201ab
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/cfeeed27.failed

show_stack_log_lvl() and dump_trace() are already preemption safe:

- If they're running in irq or exception context, preemption is already
  disabled and the percpu stack pointers can be trusted.

- If they're running with preemption enabled, they must be running on
  the task stack anyway, so it doesn't matter if they're comparing the
  stack pointer against a percpu stack pointer from this CPU or another
  one: either way it won't match.

	Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
	Cc: Andy Lutomirski <luto@amacapital.net>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Borislav Petkov <bp@alien8.de>
	Cc: Brian Gerst <brgerst@gmail.com>
	Cc: Byungchul Park <byungchul.park@lge.com>
	Cc: Denys Vlasenko <dvlasenk@redhat.com>
	Cc: Frederic Weisbecker <fweisbec@gmail.com>
	Cc: H. Peter Anvin <hpa@zytor.com>
	Cc: Kees Cook <keescook@chromium.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Nilay Vaish <nilayvaish@gmail.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Steven Rostedt <rostedt@goodmis.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
Link: http://lkml.kernel.org/r/a0ca0b1044eca97d4f0ec7c1619cf80b3b65560d.1473371307.git.jpoimboe@redhat.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit cfeeed279dc2fa83a00fbe4856ebd231d56201ab)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/dumpstack_32.c
#	arch/x86/kernel/dumpstack_64.c
diff --cc arch/x86/kernel/dumpstack_32.c
index c90b53d2857e,da5cd62f93ab..000000000000
--- a/arch/x86/kernel/dumpstack_32.c
+++ b/arch/x86/kernel/dumpstack_32.c
@@@ -16,37 -16,59 +16,67 @@@
  
  #include <asm/stacktrace.h>
  
++<<<<<<< HEAD
++=======
+ static void *is_irq_stack(void *p, void *irq)
+ {
+ 	if (p < irq || p >= (irq + THREAD_SIZE))
+ 		return NULL;
+ 	return irq + THREAD_SIZE;
+ }
+ 
+ 
+ static void *is_hardirq_stack(unsigned long *stack)
+ {
+ 	void *irq = this_cpu_read(hardirq_stack);
+ 
+ 	return is_irq_stack(stack, irq);
+ }
+ 
+ static void *is_softirq_stack(unsigned long *stack)
+ {
+ 	void *irq = this_cpu_read(softirq_stack);
+ 
+ 	return is_irq_stack(stack, irq);
+ }
++>>>>>>> cfeeed279dc2 (x86/dumpstack: Allow preemption in show_stack_log_lvl() and dump_trace())
  
  void dump_trace(struct task_struct *task, struct pt_regs *regs,
  		unsigned long *stack, unsigned long bp,
  		const struct stacktrace_ops *ops, void *data)
  {
  	int graph = 0;
 -	u32 *prev_esp;
  
 -	task = task ? : current;
 -	stack = stack ? : get_stack_pointer(task, regs);
 -	bp = bp ? : (unsigned long)get_frame_pointer(task, regs);
 +	if (!task)
 +		task = current;
 +
 +	if (!stack) {
 +		unsigned long dummy;
 +
 +		stack = &dummy;
 +		if (task && task != current)
 +			stack = (unsigned long *)task->thread.sp;
 +	}
 +
 +	if (!bp)
 +		bp = stack_frame(task, regs);
  
  	for (;;) {
 -		void *end_stack;
 +		struct thread_info *context;
  
++<<<<<<< HEAD
 +		context = (struct thread_info *)
 +			((unsigned long)stack & (~(THREAD_SIZE - 1)));
 +		bp = ops->walk_stack(context, stack, bp, ops, data, NULL, &graph);
++=======
+ 		end_stack = is_hardirq_stack(stack);
+ 		if (!end_stack)
+ 			end_stack = is_softirq_stack(stack);
++>>>>>>> cfeeed279dc2 (x86/dumpstack: Allow preemption in show_stack_log_lvl() and dump_trace())
  
 -		bp = ops->walk_stack(task, stack, bp, ops, data,
 -				     end_stack, &graph);
 -
 -		/* Stop if not on irq stack */
 -		if (!end_stack)
 -			break;
 -
 -		/* The previous esp is saved on the bottom of the stack */
 -		prev_esp = (u32 *)(end_stack - THREAD_SIZE);
 -		stack = (unsigned long *)*prev_esp;
 +		stack = (unsigned long *)context->previous_esp;
  		if (!stack)
  			break;
 -
  		if (ops->stack(data, "IRQ") < 0)
  			break;
  		touch_nmi_watchdog();
diff --cc arch/x86/kernel/dumpstack_64.c
index 101e30243d5b,07373bec76f1..000000000000
--- a/arch/x86/kernel/dumpstack_64.c
+++ b/arch/x86/kernel/dumpstack_64.c
@@@ -149,10 -148,7 +148,14 @@@ void dump_trace(struct task_struct *tas
  		unsigned long *stack, unsigned long bp,
  		const struct stacktrace_ops *ops, void *data)
  {
++<<<<<<< HEAD
 +	const unsigned cpu = get_cpu();
 +	struct thread_info *tinfo;
 +	unsigned long *irq_stack = (unsigned long *)per_cpu(irq_stack_ptr, cpu);
 +	unsigned long dummy;
++=======
+ 	unsigned long *irq_stack = (unsigned long *)this_cpu_read(irq_stack_ptr);
++>>>>>>> cfeeed279dc2 (x86/dumpstack: Allow preemption in show_stack_log_lvl() and dump_trace())
  	unsigned used = 0;
  	int graph = 0;
  	int done = 0;
@@@ -237,8 -222,7 +240,12 @@@
  	/*
  	 * This handles the process stack:
  	 */
++<<<<<<< HEAD
 +	bp = ops->walk_stack(tinfo, stack, bp, ops, data, NULL, &graph);
 +	put_cpu();
++=======
+ 	bp = ops->walk_stack(task, stack, bp, ops, data, NULL, &graph);
++>>>>>>> cfeeed279dc2 (x86/dumpstack: Allow preemption in show_stack_log_lvl() and dump_trace())
  }
  EXPORT_SYMBOL(dump_trace);
  
@@@ -249,27 -233,12 +256,23 @@@ show_stack_log_lvl(struct task_struct *
  	unsigned long *irq_stack_end;
  	unsigned long *irq_stack;
  	unsigned long *stack;
- 	int cpu;
  	int i;
  
- 	preempt_disable();
- 	cpu = smp_processor_id();
- 
- 	irq_stack_end = (unsigned long *)(per_cpu(irq_stack_ptr, cpu));
+ 	irq_stack_end = (unsigned long *)this_cpu_read(irq_stack_ptr);
  	irq_stack     = irq_stack_end - (IRQ_STACK_SIZE / sizeof(long));
  
 -	sp = sp ? : get_stack_pointer(task, regs);
 +	/*
 +	 * Debugging aid: "show_stack(NULL, NULL);" prints the
 +	 * back trace for this cpu:
 +	 */
 +	if (sp == NULL) {
 +		if (regs)
 +			sp = (unsigned long *)regs->sp;
 +		else if (task)
 +			sp = (unsigned long *)task->thread.sp;
 +		else
 +			sp = (unsigned long *)&sp;
 +	}
  
  	stack = sp;
  	for (i = 0; i < kstack_depth_to_print; i++) {
@@@ -285,12 -256,17 +288,11 @@@
  		if ((i % STACKSLOTS_PER_LINE) == 0) {
  			if (i != 0)
  				pr_cont("\n");
 -			printk("%s %016lx", log_lvl, word);
 +			printk("%s %016lx", log_lvl, *stack++);
  		} else
 -			pr_cont(" %016lx", word);
 -
 -		stack++;
 +			pr_cont(" %016lx", *stack++);
  		touch_nmi_watchdog();
  	}
- 	preempt_enable();
  
  	pr_cont("\n");
  	show_trace_log_lvl(task, regs, sp, bp, log_lvl);
* Unmerged path arch/x86/kernel/dumpstack_32.c
* Unmerged path arch/x86/kernel/dumpstack_64.c
