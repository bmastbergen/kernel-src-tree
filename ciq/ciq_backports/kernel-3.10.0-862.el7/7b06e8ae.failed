net: sched: remove cops->tcf_cl_offload

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [net] sched: remove cops->tcf_cl_offload (Ivan Vecera) [1445420]
Rebuild_FUZZ: 93.15%
commit-author Jiri Pirko <jiri@mellanox.com>
commit 7b06e8aed283081010596c98a67f06c595affe51
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/7b06e8ae.failed

cops->tcf_cl_offload is no longer needed, as the drivers check what they
can and cannot offload using the classid identify helpers. So remove this.

	Signed-off-by: Jiri Pirko <jiri@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 7b06e8aed283081010596c98a67f06c595affe51)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/pkt_cls.h
#	include/net/sch_generic.h
#	net/sched/cls_bpf.c
#	net/sched/cls_u32.c
#	net/sched/sch_ingress.c
diff --cc include/net/pkt_cls.h
index db4cec05920e,e80edd8879ef..000000000000
--- a/include/net/pkt_cls.h
+++ b/include/net/pkt_cls.h
@@@ -420,7 -463,6 +419,10 @@@ static inline bool tc_can_offload(cons
  		return false;
  	if (!dev->netdev_ops->ndo_setup_tc)
  		return false;
++<<<<<<< HEAD
 +
++=======
++>>>>>>> 7b06e8aed283 (net: sched: remove cops->tcf_cl_offload)
  	return true;
  }
  
diff --cc include/net/sch_generic.h
index 7b71681b10fc,5865db91976b..000000000000
--- a/include/net/sch_generic.h
+++ b/include/net/sch_generic.h
@@@ -146,7 -155,7 +146,11 @@@ struct Qdisc_class_ops 
  	void			(*walk)(struct Qdisc *, struct qdisc_walker * arg);
  
  	/* Filter manipulation */
++<<<<<<< HEAD
 +	struct tcf_proto __rcu ** (*tcf_chain)(struct Qdisc *, unsigned long);
++=======
+ 	struct tcf_block *	(*tcf_block)(struct Qdisc *, unsigned long);
++>>>>>>> 7b06e8aed283 (net: sched: remove cops->tcf_cl_offload)
  	unsigned long		(*bind_tcf)(struct Qdisc *, unsigned long,
  					u32 classid);
  	void			(*unbind_tcf)(struct Qdisc *, unsigned long);
diff --cc net/sched/cls_bpf.c
index c13fb5505297,6f2dffe30f25..000000000000
--- a/net/sched/cls_bpf.c
+++ b/net/sched/cls_bpf.c
@@@ -70,10 -131,102 +70,72 @@@ static int cls_bpf_classify(struct sk_b
  		if (ret < 0)
  			continue;
  
++<<<<<<< HEAD
 +		return ret;
++=======
+ 		break;
+ 	}
+ 	rcu_read_unlock();
+ 
+ 	return ret;
+ }
+ 
+ static bool cls_bpf_is_ebpf(const struct cls_bpf_prog *prog)
+ {
+ 	return !prog->bpf_ops;
+ }
+ 
+ static int cls_bpf_offload_cmd(struct tcf_proto *tp, struct cls_bpf_prog *prog,
+ 			       enum tc_clsbpf_command cmd)
+ {
+ 	struct net_device *dev = tp->q->dev_queue->dev;
+ 	struct tc_cls_bpf_offload cls_bpf = {};
+ 	int err;
+ 
+ 	tc_cls_common_offload_init(&cls_bpf.common, tp);
+ 	cls_bpf.command = cmd;
+ 	cls_bpf.exts = &prog->exts;
+ 	cls_bpf.prog = prog->filter;
+ 	cls_bpf.name = prog->bpf_name;
+ 	cls_bpf.exts_integrated = prog->exts_integrated;
+ 	cls_bpf.gen_flags = prog->gen_flags;
+ 
+ 	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSBPF, &cls_bpf);
+ 	if (!err && (cmd == TC_CLSBPF_ADD || cmd == TC_CLSBPF_REPLACE))
+ 		prog->gen_flags |= TCA_CLS_FLAGS_IN_HW;
+ 
+ 	return err;
+ }
+ 
+ static int cls_bpf_offload(struct tcf_proto *tp, struct cls_bpf_prog *prog,
+ 			   struct cls_bpf_prog *oldprog)
+ {
+ 	struct net_device *dev = tp->q->dev_queue->dev;
+ 	struct cls_bpf_prog *obj = prog;
+ 	enum tc_clsbpf_command cmd;
+ 	bool skip_sw;
+ 	int ret;
+ 
+ 	skip_sw = tc_skip_sw(prog->gen_flags) ||
+ 		(oldprog && tc_skip_sw(oldprog->gen_flags));
+ 
+ 	if (oldprog && oldprog->offloaded) {
+ 		if (tc_should_offload(dev, prog->gen_flags)) {
+ 			cmd = TC_CLSBPF_REPLACE;
+ 		} else if (!tc_skip_sw(prog->gen_flags)) {
+ 			obj = oldprog;
+ 			cmd = TC_CLSBPF_DESTROY;
+ 		} else {
+ 			return -EINVAL;
+ 		}
+ 	} else {
+ 		if (!tc_should_offload(dev, prog->gen_flags))
+ 			return skip_sw ? -EINVAL : 0;
+ 		cmd = TC_CLSBPF_ADD;
++>>>>>>> 7b06e8aed283 (net: sched: remove cops->tcf_cl_offload)
  	}
  
 -	ret = cls_bpf_offload_cmd(tp, obj, cmd);
 -	if (ret)
 -		return skip_sw ? ret : 0;
 -
 -	obj->offloaded = true;
 -	if (oldprog)
 -		oldprog->offloaded = false;
 -
 -	return 0;
 -}
 -
 -static void cls_bpf_stop_offload(struct tcf_proto *tp,
 -				 struct cls_bpf_prog *prog)
 -{
 -	int err;
 -
 -	if (!prog->offloaded)
 -		return;
 -
 -	err = cls_bpf_offload_cmd(tp, prog, TC_CLSBPF_DESTROY);
 -	if (err) {
 -		pr_err("Stopping hardware offload failed: %d\n", err);
 -		return;
 -	}
 -
 -	prog->offloaded = false;
 -}
 -
 -static void cls_bpf_offload_update_stats(struct tcf_proto *tp,
 -					 struct cls_bpf_prog *prog)
 -{
 -	if (!prog->offloaded)
 -		return;
 -
 -	cls_bpf_offload_cmd(tp, prog, TC_CLSBPF_STATS);
 +	return -1;
  }
  
  static int cls_bpf_init(struct tcf_proto *tp)
diff --cc net/sched/cls_u32.c
index dfc76f51e07c,af22742d2847..000000000000
--- a/net/sched/cls_u32.c
+++ b/net/sched/cls_u32.c
@@@ -431,41 -431,35 +431,46 @@@ static int u32_delete_key(struct tcf_pr
  static void u32_remove_hw_knode(struct tcf_proto *tp, u32 handle)
  {
  	struct net_device *dev = tp->q->dev_queue->dev;
 -	struct tc_cls_u32_offload cls_u32 = {};
 +	struct tc_cls_u32_offload u32_offload = {0};
 +	struct tc_to_netdev offload;
  
++<<<<<<< HEAD
 +	offload.type = TC_SETUP_CLSU32;
 +	offload.cls_u32 = &u32_offload;
++=======
+ 	if (!tc_should_offload(dev, 0))
+ 		return;
++>>>>>>> 7b06e8aed283 (net: sched: remove cops->tcf_cl_offload)
  
 -	tc_cls_common_offload_init(&cls_u32.common, tp);
 -	cls_u32.command = TC_CLSU32_DELETE_KNODE;
 -	cls_u32.knode.handle = handle;
 -
 -	dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSU32, &cls_u32);
 +	if (tc_should_offload(dev, tp, 0)) {
 +		offload.cls_u32->command = TC_CLSU32_DELETE_KNODE;
 +		offload.cls_u32->knode.handle = handle;
 +		dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle,
 +					      tp->protocol, &offload);
 +	}
  }
  
  static int u32_replace_hw_hnode(struct tcf_proto *tp, struct tc_u_hnode *h,
  				u32 flags)
  {
  	struct net_device *dev = tp->q->dev_queue->dev;
 -	struct tc_cls_u32_offload cls_u32 = {};
 +	struct tc_cls_u32_offload u32_offload = {0};
 +	struct tc_to_netdev offload;
  	int err;
  
- 	if (!tc_should_offload(dev, tp, flags))
+ 	if (!tc_should_offload(dev, flags))
  		return tc_skip_sw(flags) ? -EINVAL : 0;
  
 -	tc_cls_common_offload_init(&cls_u32.common, tp);
 -	cls_u32.command = TC_CLSU32_NEW_HNODE;
 -	cls_u32.hnode.divisor = h->divisor;
 -	cls_u32.hnode.handle = h->handle;
 -	cls_u32.hnode.prio = h->prio;
 +	offload.type = TC_SETUP_CLSU32;
 +	offload.cls_u32 = &u32_offload;
  
 -	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSU32, &cls_u32);
 +	offload.cls_u32->command = TC_CLSU32_NEW_HNODE;
 +	offload.cls_u32->hnode.divisor = h->divisor;
 +	offload.cls_u32->hnode.handle = h->handle;
 +	offload.cls_u32->hnode.prio = h->prio;
 +
 +	err = dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle,
 +					    tp->protocol, &offload);
  	if (tc_skip_sw(flags))
  		return err;
  
@@@ -475,54 -469,47 +480,63 @@@
  static void u32_clear_hw_hnode(struct tcf_proto *tp, struct tc_u_hnode *h)
  {
  	struct net_device *dev = tp->q->dev_queue->dev;
 -	struct tc_cls_u32_offload cls_u32 = {};
 +	struct tc_cls_u32_offload u32_offload = {0};
 +	struct tc_to_netdev offload;
  
++<<<<<<< HEAD
 +	offload.type = TC_SETUP_CLSU32;
 +	offload.cls_u32 = &u32_offload;
++=======
+ 	if (!tc_should_offload(dev, 0))
+ 		return;
++>>>>>>> 7b06e8aed283 (net: sched: remove cops->tcf_cl_offload)
  
 -	tc_cls_common_offload_init(&cls_u32.common, tp);
 -	cls_u32.command = TC_CLSU32_DELETE_HNODE;
 -	cls_u32.hnode.divisor = h->divisor;
 -	cls_u32.hnode.handle = h->handle;
 -	cls_u32.hnode.prio = h->prio;
 +	if (tc_should_offload(dev, tp, 0)) {
 +		offload.cls_u32->command = TC_CLSU32_DELETE_HNODE;
 +		offload.cls_u32->hnode.divisor = h->divisor;
 +		offload.cls_u32->hnode.handle = h->handle;
 +		offload.cls_u32->hnode.prio = h->prio;
  
 -	dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSU32, &cls_u32);
 +		dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle,
 +					      tp->protocol, &offload);
 +	}
  }
  
  static int u32_replace_hw_knode(struct tcf_proto *tp, struct tc_u_knode *n,
  				u32 flags)
  {
  	struct net_device *dev = tp->q->dev_queue->dev;
 -	struct tc_cls_u32_offload cls_u32 = {};
 +	struct tc_cls_u32_offload u32_offload = {0};
 +	struct tc_to_netdev offload;
  	int err;
  
++<<<<<<< HEAD
 +	offload.type = TC_SETUP_CLSU32;
 +	offload.cls_u32 = &u32_offload;
 +
 +	if (!tc_should_offload(dev, tp, flags))
++=======
+ 	if (!tc_should_offload(dev, flags))
++>>>>>>> 7b06e8aed283 (net: sched: remove cops->tcf_cl_offload)
  		return tc_skip_sw(flags) ? -EINVAL : 0;
  
 -	tc_cls_common_offload_init(&cls_u32.common, tp);
 -	cls_u32.command = TC_CLSU32_REPLACE_KNODE;
 -	cls_u32.knode.handle = n->handle;
 -	cls_u32.knode.fshift = n->fshift;
 +	offload.cls_u32->command = TC_CLSU32_REPLACE_KNODE;
 +	offload.cls_u32->knode.handle = n->handle;
 +	offload.cls_u32->knode.fshift = n->fshift;
  #ifdef CONFIG_CLS_U32_MARK
 -	cls_u32.knode.val = n->val;
 -	cls_u32.knode.mask = n->mask;
 +	offload.cls_u32->knode.val = n->val;
 +	offload.cls_u32->knode.mask = n->mask;
  #else
 -	cls_u32.knode.val = 0;
 -	cls_u32.knode.mask = 0;
 +	offload.cls_u32->knode.val = 0;
 +	offload.cls_u32->knode.mask = 0;
  #endif
 -	cls_u32.knode.sel = &n->sel;
 -	cls_u32.knode.exts = &n->exts;
 +	offload.cls_u32->knode.sel = &n->sel;
 +	offload.cls_u32->knode.exts = &n->exts;
  	if (n->ht_down)
 -		cls_u32.knode.link_handle = n->ht_down->handle;
 +		offload.cls_u32->knode.link_handle = n->ht_down->handle;
  
 -	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSU32, &cls_u32);
 +	err = dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle,
 +					    tp->protocol, &offload);
  
  	if (!err)
  		n->flags |= TCA_CLS_FLAGS_IN_HW;
diff --cc net/sched/sch_ingress.c
index e7c648fa9dc3,a15c543c3569..000000000000
--- a/net/sched/sch_ingress.c
+++ b/net/sched/sch_ingress.c
@@@ -84,7 -97,7 +84,11 @@@ static const struct Qdisc_class_ops ing
  	.get		=	ingress_get,
  	.put		=	ingress_put,
  	.walk		=	ingress_walk,
++<<<<<<< HEAD
 +	.tcf_chain	=	ingress_find_tcf,
++=======
+ 	.tcf_block	=	ingress_tcf_block,
++>>>>>>> 7b06e8aed283 (net: sched: remove cops->tcf_cl_offload)
  	.bind_tcf	=	ingress_bind_filter,
  	.unbind_tcf	=	ingress_put,
  };
@@@ -98,9 -112,107 +102,101 @@@ static struct Qdisc_ops ingress_qdisc_o
  	.owner		=	THIS_MODULE,
  };
  
++<<<<<<< HEAD
++=======
+ struct clsact_sched_data {
+ 	struct tcf_block *ingress_block;
+ 	struct tcf_block *egress_block;
+ };
+ 
+ static unsigned long clsact_get(struct Qdisc *sch, u32 classid)
+ {
+ 	switch (TC_H_MIN(classid)) {
+ 	case TC_H_MIN(TC_H_MIN_INGRESS):
+ 	case TC_H_MIN(TC_H_MIN_EGRESS):
+ 		return TC_H_MIN(classid);
+ 	default:
+ 		return 0;
+ 	}
+ }
+ 
+ static unsigned long clsact_bind_filter(struct Qdisc *sch,
+ 					unsigned long parent, u32 classid)
+ {
+ 	return clsact_get(sch, classid);
+ }
+ 
+ static struct tcf_block *clsact_tcf_block(struct Qdisc *sch, unsigned long cl)
+ {
+ 	struct clsact_sched_data *q = qdisc_priv(sch);
+ 
+ 	switch (cl) {
+ 	case TC_H_MIN(TC_H_MIN_INGRESS):
+ 		return q->ingress_block;
+ 	case TC_H_MIN(TC_H_MIN_EGRESS):
+ 		return q->egress_block;
+ 	default:
+ 		return NULL;
+ 	}
+ }
+ 
+ static int clsact_init(struct Qdisc *sch, struct nlattr *opt)
+ {
+ 	struct clsact_sched_data *q = qdisc_priv(sch);
+ 	struct net_device *dev = qdisc_dev(sch);
+ 	int err;
+ 
+ 	err = tcf_block_get(&q->ingress_block, &dev->ingress_cl_list);
+ 	if (err)
+ 		return err;
+ 
+ 	err = tcf_block_get(&q->egress_block, &dev->egress_cl_list);
+ 	if (err)
+ 		return err;
+ 
+ 	net_inc_ingress_queue();
+ 	net_inc_egress_queue();
+ 
+ 	sch->flags |= TCQ_F_CPUSTATS;
+ 
+ 	return 0;
+ }
+ 
+ static void clsact_destroy(struct Qdisc *sch)
+ {
+ 	struct clsact_sched_data *q = qdisc_priv(sch);
+ 
+ 	tcf_block_put(q->egress_block);
+ 	tcf_block_put(q->ingress_block);
+ 
+ 	net_dec_ingress_queue();
+ 	net_dec_egress_queue();
+ }
+ 
+ static const struct Qdisc_class_ops clsact_class_ops = {
+ 	.leaf		=	ingress_leaf,
+ 	.get		=	clsact_get,
+ 	.put		=	ingress_put,
+ 	.walk		=	ingress_walk,
+ 	.tcf_block	=	clsact_tcf_block,
+ 	.bind_tcf	=	clsact_bind_filter,
+ 	.unbind_tcf	=	ingress_put,
+ };
+ 
+ static struct Qdisc_ops clsact_qdisc_ops __read_mostly = {
+ 	.cl_ops		=	&clsact_class_ops,
+ 	.id		=	"clsact",
+ 	.priv_size	=	sizeof(struct clsact_sched_data),
+ 	.init		=	clsact_init,
+ 	.destroy	=	clsact_destroy,
+ 	.dump		=	ingress_dump,
+ 	.owner		=	THIS_MODULE,
+ };
+ 
++>>>>>>> 7b06e8aed283 (net: sched: remove cops->tcf_cl_offload)
  static int __init ingress_module_init(void)
  {
 -	int ret;
 -
 -	ret = register_qdisc(&ingress_qdisc_ops);
 -	if (!ret) {
 -		ret = register_qdisc(&clsact_qdisc_ops);
 -		if (ret)
 -			unregister_qdisc(&ingress_qdisc_ops);
 -	}
 -
 -	return ret;
 +	return register_qdisc(&ingress_qdisc_ops);
  }
  
  static void __exit ingress_module_exit(void)
* Unmerged path include/net/pkt_cls.h
* Unmerged path include/net/sch_generic.h
* Unmerged path net/sched/cls_bpf.c
diff --git a/net/sched/cls_flower.c b/net/sched/cls_flower.c
index 2d81cc7499da..fa091ef53cea 100644
--- a/net/sched/cls_flower.c
+++ b/net/sched/cls_flower.c
@@ -229,7 +229,7 @@ static void fl_hw_destroy_filter(struct tcf_proto *tp, struct cls_fl_filter *f)
 	struct net_device *dev = f->hw_dev;
 	struct tc_to_netdev *tc = &f->tc;
 
-	if (!tc_can_offload(dev, tp))
+	if (!tc_can_offload(dev))
 		return;
 
 	offload.command = TC_CLSFLOWER_DESTROY;
@@ -252,9 +252,9 @@ static int fl_hw_replace_filter(struct tcf_proto *tp,
 	struct tc_to_netdev *tc = &f->tc;
 	int err;
 
-	if (!tc_can_offload(dev, tp)) {
+	if (!tc_can_offload(dev)) {
 		if (tcf_exts_get_dev(dev, &f->exts, &f->hw_dev) ||
-		    (f->hw_dev && !tc_can_offload(f->hw_dev, tp))) {
+		    (f->hw_dev && !tc_can_offload(f->hw_dev))) {
 			f->hw_dev = dev;
 			return tc_skip_sw(f->flags) ? -EINVAL : 0;
 		}
@@ -291,7 +291,7 @@ static void fl_hw_update_stats(struct tcf_proto *tp, struct cls_fl_filter *f)
 	struct net_device *dev = f->hw_dev;
 	struct tc_to_netdev *tc = &f->tc;
 
-	if (!tc_can_offload(dev, tp))
+	if (!tc_can_offload(dev))
 		return;
 
 	offload.command = TC_CLSFLOWER_STATS;
diff --git a/net/sched/cls_matchall.c b/net/sched/cls_matchall.c
index f7bc58777169..02f9b256899d 100644
--- a/net/sched/cls_matchall.c
+++ b/net/sched/cls_matchall.c
@@ -99,7 +99,7 @@ static bool mall_destroy(struct tcf_proto *tp, bool force)
 	if (!head)
 		return true;
 
-	if (tc_should_offload(dev, tp, head->flags))
+	if (tc_should_offload(dev, head->flags))
 		mall_destroy_hw_filter(tp, head, (unsigned long) head);
 
 	call_rcu(&head->rcu, mall_destroy_rcu);
@@ -192,7 +192,7 @@ static int mall_change(struct net *net, struct sk_buff *in_skb,
 	if (err)
 		goto err_set_parms;
 
-	if (tc_should_offload(dev, tp, flags)) {
+	if (tc_should_offload(dev, flags)) {
 		err = mall_replace_hw_filter(tp, new, (unsigned long) new);
 		if (err) {
 			if (tc_skip_sw(flags))
* Unmerged path net/sched/cls_u32.c
* Unmerged path net/sched/sch_ingress.c
