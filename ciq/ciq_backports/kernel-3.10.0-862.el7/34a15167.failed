s390/zcrypt: Introduce workload balancing

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [s390] zcrypt: Introduce workload balancing (Hendrik Brueckner) [1380349]
Rebuild_FUZZ: 93.51%
commit-author Ingo Tuchscherer <ingo.tuchscherer@linux.vnet.ibm.com>
commit 34a15167739412750846d4f1a5540d9e592fd815
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/34a15167.failed

Crypto requests are very different in complexity and thus runtime.
Also various crypto adapters are differ with regard to the execution
time. Crypto requests can be balanced much better when the request
type and eligible crypto adapters are rated in a more precise
granularity. Therefore, request weights and adapter speed rates for
dedicated requests will be introduced.

	Signed-off-by: Ingo Tuchscherer <ingo.tuchscherer@linux.vnet.ibm.com>
	Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
(cherry picked from commit 34a15167739412750846d4f1a5540d9e592fd815)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/s390/crypto/zcrypt_cex2a.c
#	drivers/s390/crypto/zcrypt_cex4.c
#	drivers/s390/crypto/zcrypt_msgtype50.h
#	drivers/s390/crypto/zcrypt_msgtype6.c
diff --cc drivers/s390/crypto/zcrypt_cex2a.c
index 1e849d6e1dfe,4bb13eadd0f1..000000000000
--- a/drivers/s390/crypto/zcrypt_cex2a.c
+++ b/drivers/s390/crypto/zcrypt_cex2a.c
@@@ -122,11 -123,11 +123,16 @@@ static int zcrypt_cex2a_probe(struct ap
  	}
  	if (!zdev)
  		return -ENODEV;
 -	zdev->ops = zcrypt_msgtype(MSGTYPE50_NAME, MSGTYPE50_VARIANT_DEFAULT);
 +	zdev->ops = zcrypt_msgtype_request(MSGTYPE50_NAME,
 +					   MSGTYPE50_VARIANT_DEFAULT);
  	zdev->ap_dev = ap_dev;
  	zdev->online = 1;
++<<<<<<< HEAD
 +	ap_dev->reply = &zdev->reply;
++=======
+ 	zdev->load = zdev->speed_rating[0];
+ 	ap_device_init_reply(ap_dev, &zdev->reply);
++>>>>>>> 34a151677394 (s390/zcrypt: Introduce workload balancing)
  	ap_dev->private = zdev;
  	rc = zcrypt_device_register(zdev);
  	if (rc) {
diff --cc drivers/s390/crypto/zcrypt_cex4.c
index bb3908818505,ff28ad543c30..000000000000
--- a/drivers/s390/crypto/zcrypt_cex4.c
+++ b/drivers/s390/crypto/zcrypt_cex4.c
@@@ -147,7 -156,8 +156,12 @@@ static int zcrypt_cex4_probe(struct ap_
  		return -ENODEV;
  	zdev->ap_dev = ap_dev;
  	zdev->online = 1;
++<<<<<<< HEAD
 +	ap_dev->reply = &zdev->reply;
++=======
+ 	zdev->load = zdev->speed_rating[0];
+ 	ap_device_init_reply(ap_dev, &zdev->reply);
++>>>>>>> 34a151677394 (s390/zcrypt: Introduce workload balancing)
  	ap_dev->private = zdev;
  	rc = zcrypt_device_register(zdev);
  	if (rc) {
diff --cc drivers/s390/crypto/zcrypt_msgtype50.h
index 0a66e4aeeb50,5cc280318ee7..000000000000
--- a/drivers/s390/crypto/zcrypt_msgtype50.h
+++ b/drivers/s390/crypto/zcrypt_msgtype50.h
@@@ -35,7 -35,10 +35,14 @@@
  
  #define MSGTYPE_ADJUSTMENT		0x08  /*type04 extension (not needed in type50)*/
  
++<<<<<<< HEAD
 +int zcrypt_msgtype50_init(void);
++=======
+ unsigned int get_rsa_modex_fc(struct ica_rsa_modexpo *, int *);
+ unsigned int get_rsa_crt_fc(struct ica_rsa_modexpo_crt *, int *);
+ 
+ void zcrypt_msgtype50_init(void);
++>>>>>>> 34a151677394 (s390/zcrypt: Introduce workload balancing)
  void zcrypt_msgtype50_exit(void);
  
  #endif /* _ZCRYPT_MSGTYPE50_H_ */
diff --cc drivers/s390/crypto/zcrypt_msgtype6.c
index 9adcfa43d01d,957a88d5768b..000000000000
--- a/drivers/s390/crypto/zcrypt_msgtype6.c
+++ b/drivers/s390/crypto/zcrypt_msgtype6.c
@@@ -450,36 -556,7 +556,40 @@@ static int xcrb_msg_to_type6_ep11cprb_m
  		return -EFAULT;
  	}
  
++<<<<<<< HEAD
 +	/*
 +	 The target domain field within the cprb body/payload block will be
 +	 replaced by the usage domain for non-management commands only.
 +	 Therefore we check the first bit of the 'flags' parameter for
 +	 management command indication.
 +	   0 - non managment command
 +	   1 - management command
 +	*/
 +	if (!((msg->cprbx.flags & 0x80) == 0x80)) {
 +		msg->cprbx.target_id = (unsigned int)
 +					AP_QID_QUEUE(zdev->ap_dev->qid);
 +
 +		if ((msg->pld_lenfmt & 0x80) == 0x80) { /*ext.len.fmt 2 or 3*/
 +			switch (msg->pld_lenfmt & 0x03) {
 +			case 1:
 +				lfmt = 2;
 +				break;
 +			case 2:
 +				lfmt = 3;
 +				break;
 +			default:
 +				return -EINVAL;
 +			}
 +		} else {
 +			lfmt = 1; /* length format #1 */
 +		  }
 +		payload_hdr = (struct pld_hdr *)((&(msg->pld_lenfmt))+lfmt);
 +		payload_hdr->dom_val = (unsigned int)
 +					AP_QID_QUEUE(zdev->ap_dev->qid);
 +	}
++=======
+ 	*fcode = speed_idx_ep11(payload_hdr->func_val & 0xFFFF);
++>>>>>>> 34a151677394 (s390/zcrypt: Introduce workload balancing)
  	return 0;
  }
  
@@@ -1003,27 -1135,24 +1166,41 @@@ unsigned int get_ep11cprb_fc(struct ep1
  	};
  	int rc;
  
- 	ap_init_message(&ap_msg);
- 	ap_msg.message = kmalloc(MSGTYPE06_MAX_MSG_SIZE, GFP_KERNEL);
- 	if (!ap_msg.message)
+ 	ap_init_message(ap_msg);
+ 	ap_msg->message = kmalloc(MSGTYPE06_MAX_MSG_SIZE, GFP_KERNEL);
+ 	if (!ap_msg->message)
  		return -ENOMEM;
- 	ap_msg.receive = zcrypt_msgtype6_receive;
- 	ap_msg.psmid = (((unsigned long long) current->pid) << 32) +
+ 	ap_msg->receive = zcrypt_msgtype6_receive_ep11;
+ 	ap_msg->psmid = (((unsigned long long) current->pid) << 32) +
  				atomic_inc_return(&zcrypt_step);
++<<<<<<< HEAD
 +	ap_msg.private = &resp_type;
 +	rc = XCRB_msg_to_type6CPRB_msgX(zdev, &ap_msg, xcRB);
 +	if (rc)
 +		goto out_free;
 +	init_completion(&resp_type.work);
 +	ap_queue_message(zdev->ap_dev, &ap_msg);
 +	rc = wait_for_completion_interruptible(&resp_type.work);
 +	if (rc == 0)
 +		rc = convert_response_xcrb(zdev, &ap_msg, xcRB);
 +	else
 +		/* Signal pending. */
 +		ap_cancel_message(zdev->ap_dev, &ap_msg);
 +out_free:
 +	kzfree(ap_msg.message);
++=======
+ 	ap_msg->private = kmalloc(sizeof(resp_type), GFP_KERNEL);
+ 	if (!ap_msg->private) {
+ 		kzfree(ap_msg->message);
+ 		return -ENOMEM;
+ 	}
+ 	memcpy(ap_msg->private, &resp_type, sizeof(resp_type));
+ 	rc = xcrb_msg_to_type6_ep11cprb_msgx(ap_msg, xcrb, func_code);
+ 	if (rc) {
+ 		kzfree(ap_msg->message);
+ 		kzfree(ap_msg->private);
+ 	}
++>>>>>>> 34a151677394 (s390/zcrypt: Introduce workload balancing)
  	return rc;
  }
  
@@@ -1035,35 -1164,72 +1212,93 @@@
   * @xcRB: pointer to the ep11 user request block
   */
  static long zcrypt_msgtype6_send_ep11_cprb(struct zcrypt_device *zdev,
- 						struct ep11_urb *xcrb)
+ 					   struct ep11_urb *xcrb,
+ 					   struct ap_message *ap_msg)
  {
- 	struct ap_message ap_msg;
- 	struct response_type resp_type = {
- 		.type = PCIXCC_RESPONSE_TYPE_EP11,
- 	};
  	int rc;
+ 	unsigned int lfmt;
+ 	struct response_type *rtype = (struct response_type *)(ap_msg->private);
+ 	struct {
+ 		struct type6_hdr hdr;
+ 		struct ep11_cprb cprbx;
+ 		unsigned char	pld_tag;	/* fixed value 0x30 */
+ 		unsigned char	pld_lenfmt;	/* payload length format */
+ 	} __packed * msg = ap_msg->message;
+ 	struct pld_hdr {
+ 		unsigned char	func_tag;	/* fixed value 0x4 */
+ 		unsigned char	func_len;	/* fixed value 0x4 */
+ 		unsigned int	func_val;	/* function ID	   */
+ 		unsigned char	dom_tag;	/* fixed value 0x4 */
+ 		unsigned char	dom_len;	/* fixed value 0x4 */
+ 		unsigned int	dom_val;	/* domain id	   */
+ 	} __packed * payload_hdr = NULL;
  
++<<<<<<< HEAD
 +	ap_init_message(&ap_msg);
 +	ap_msg.message = kmalloc(MSGTYPE06_MAX_MSG_SIZE, GFP_KERNEL);
 +	if (!ap_msg.message)
 +		return -ENOMEM;
 +	ap_msg.receive = zcrypt_msgtype6_receive_ep11;
 +	ap_msg.psmid = (((unsigned long long) current->pid) << 32) +
 +				atomic_inc_return(&zcrypt_step);
 +	ap_msg.private = &resp_type;
 +	rc = xcrb_msg_to_type6_ep11cprb_msgx(zdev, &ap_msg, xcrb);
 +	if (rc)
 +		goto out_free;
 +	init_completion(&resp_type.work);
 +	ap_queue_message(zdev->ap_dev, &ap_msg);
 +	rc = wait_for_completion_interruptible(&resp_type.work);
 +	if (rc == 0)
 +		rc = convert_response_ep11_xcrb(zdev, &ap_msg, xcrb);
 +	else /* Signal pending. */
 +		ap_cancel_message(zdev->ap_dev, &ap_msg);
++=======
+ 
+ 	/**
+ 	 * The target domain field within the cprb body/payload block will be
+ 	 * replaced by the usage domain for non-management commands only.
+ 	 * Therefore we check the first bit of the 'flags' parameter for
+ 	 * management command indication.
+ 	 *   0 - non management command
+ 	 *   1 - management command
+ 	 */
+ 	if (!((msg->cprbx.flags & 0x80) == 0x80)) {
+ 		msg->cprbx.target_id = (unsigned int)
+ 					AP_QID_QUEUE(zdev->ap_dev->qid);
  
- out_free:
- 	kzfree(ap_msg.message);
+ 		if ((msg->pld_lenfmt & 0x80) == 0x80) { /*ext.len.fmt 2 or 3*/
+ 			switch (msg->pld_lenfmt & 0x03) {
+ 			case 1:
+ 				lfmt = 2;
+ 				break;
+ 			case 2:
+ 				lfmt = 3;
+ 				break;
+ 			default:
+ 				return -EINVAL;
+ 			}
+ 		} else {
+ 			lfmt = 1; /* length format #1 */
+ 		}
+ 		payload_hdr = (struct pld_hdr *)((&(msg->pld_lenfmt))+lfmt);
+ 		payload_hdr->dom_val = (unsigned int)
+ 					AP_QID_QUEUE(zdev->ap_dev->qid);
+ 	}
+ 
+ 	init_completion(&rtype->work);
+ 	ap_queue_message(zdev->ap_dev, ap_msg);
+ 	rc = wait_for_completion_interruptible(&rtype->work);
+ 	if (rc == 0) {
+ 		rc = ap_msg->rc;
+ 		if (rc == 0)
+ 			rc = convert_response_ep11_xcrb(zdev, ap_msg, xcrb);
+ 	} else
+ 		/* Signal pending. */
+ 		ap_cancel_message(zdev->ap_dev, ap_msg);
++>>>>>>> 34a151677394 (s390/zcrypt: Introduce workload balancing)
+ 
+ 	kzfree(ap_msg->message);
+ 	kzfree(ap_msg->private);
  	return rc;
  }
  
@@@ -1074,34 -1266,36 +1335,54 @@@ unsigned int get_rng_fc(struct ap_messa
   *	  PCIXCC/CEX2C device to the request distributor
   * @buffer: pointer to a memory page to return random data
   */
- 
  static long zcrypt_msgtype6_rng(struct zcrypt_device *zdev,
- 				    char *buffer)
+ 				char *buffer, struct ap_message *ap_msg)
  {
- 	struct ap_message ap_msg;
- 	struct response_type resp_type = {
- 		.type = PCIXCC_RESPONSE_TYPE_XCRB,
- 	};
+ 	struct {
+ 		struct type6_hdr hdr;
+ 		struct CPRBX cprbx;
+ 		char function_code[2];
+ 		short int rule_length;
+ 		char rule[8];
+ 		short int verb_length;
+ 		short int key_length;
+ 	} __packed * msg = ap_msg->message;
+ 	struct response_type *rtype = (struct response_type *)(ap_msg->private);
  	int rc;
  
++<<<<<<< HEAD
 +	ap_init_message(&ap_msg);
 +	ap_msg.message = kmalloc(MSGTYPE06_MAX_MSG_SIZE, GFP_KERNEL);
 +	if (!ap_msg.message)
 +		return -ENOMEM;
 +	ap_msg.receive = zcrypt_msgtype6_receive;
 +	ap_msg.psmid = (((unsigned long long) current->pid) << 32) +
 +				atomic_inc_return(&zcrypt_step);
 +	ap_msg.private = &resp_type;
 +	rng_type6CPRB_msgX(zdev->ap_dev, &ap_msg, ZCRYPT_RNG_BUFFER_SIZE);
 +	init_completion(&resp_type.work);
 +	ap_queue_message(zdev->ap_dev, &ap_msg);
 +	rc = wait_for_completion_interruptible(&resp_type.work);
 +	if (rc == 0)
 +		rc = convert_response_rng(zdev, &ap_msg, buffer);
 +	else
++=======
+ 	msg->cprbx.domain = AP_QID_QUEUE(zdev->ap_dev->qid);
+ 
+ 	init_completion(&rtype->work);
+ 	ap_queue_message(zdev->ap_dev, ap_msg);
+ 	rc = wait_for_completion_interruptible(&rtype->work);
+ 	if (rc == 0) {
+ 		rc = ap_msg->rc;
+ 		if (rc == 0)
+ 			rc = convert_response_rng(zdev, ap_msg, buffer);
+ 	} else
++>>>>>>> 34a151677394 (s390/zcrypt: Introduce workload balancing)
  		/* Signal pending. */
- 		ap_cancel_message(zdev->ap_dev, &ap_msg);
- 	kfree(ap_msg.message);
+ 		ap_cancel_message(zdev->ap_dev, ap_msg);
+ 
+ 	kzfree(ap_msg->message);
+ 	kzfree(ap_msg->private);
  	return rc;
  }
  
diff --git a/drivers/s390/crypto/zcrypt_api.c b/drivers/s390/crypto/zcrypt_api.c
index aac1d13c55dd..71cf51ea2b74 100644
--- a/drivers/s390/crypto/zcrypt_api.c
+++ b/drivers/s390/crypto/zcrypt_api.c
@@ -147,18 +147,16 @@ static inline int zcrypt_process_rescan(void)
  * Need to be called while holding the zcrypt device list lock.
  * Note: cards with speed_rating of 0 are kept at the end of the list.
  */
-static void __zcrypt_increase_preference(struct zcrypt_device *zdev)
+static void __zcrypt_increase_preference(struct zcrypt_device *zdev,
+				  unsigned int weight)
 {
 	struct zcrypt_device *tmp;
 	struct list_head *l;
 
-	if (zdev->speed_rating == 0)
-		return;
+	zdev->load -= weight;
 	for (l = zdev->list.prev; l != &zcrypt_device_list; l = l->prev) {
 		tmp = list_entry(l, struct zcrypt_device, list);
-		if ((tmp->request_count + 1) * tmp->speed_rating <=
-		    (zdev->request_count + 1) * zdev->speed_rating &&
-		    tmp->speed_rating != 0)
+		if (tmp->load <= zdev->load)
 			break;
 	}
 	if (l == zdev->list.prev)
@@ -175,18 +173,16 @@ static void __zcrypt_increase_preference(struct zcrypt_device *zdev)
  * Need to be called while holding the zcrypt device list lock.
  * Note: cards with speed_rating of 0 are kept at the end of the list.
  */
-static void __zcrypt_decrease_preference(struct zcrypt_device *zdev)
+static void __zcrypt_decrease_preference(struct zcrypt_device *zdev,
+				  unsigned int weight)
 {
 	struct zcrypt_device *tmp;
 	struct list_head *l;
 
-	if (zdev->speed_rating == 0)
-		return;
+	zdev->load += weight;
 	for (l = zdev->list.next; l != &zcrypt_device_list; l = l->next) {
 		tmp = list_entry(l, struct zcrypt_device, list);
-		if ((tmp->request_count + 1) * tmp->speed_rating >
-		    (zdev->request_count + 1) * zdev->speed_rating ||
-		    tmp->speed_rating == 0)
+		if (tmp->load > zdev->load)
 			break;
 	}
 	if (l == zdev->list.next)
@@ -266,7 +262,7 @@ int zcrypt_device_register(struct zcrypt_device *zdev)
 	ZCRYPT_DBF_DEV(DBF_INFO, zdev, "dev%04xo%dreg", zdev->ap_dev->qid,
 		       zdev->online);
 	list_add_tail(&zdev->list, &zcrypt_device_list);
-	__zcrypt_increase_preference(zdev);
+	__zcrypt_increase_preference(zdev, 0); /* sort devices acc. weight */
 	zcrypt_device_count++;
 	spin_unlock_bh(&zcrypt_device_lock);
 	if (zdev->ops->rng) {
@@ -420,8 +416,9 @@ static int zcrypt_release(struct inode *inode, struct file *filp)
  */
 static long zcrypt_rsa_modexpo(struct ica_rsa_modexpo *mex)
 {
-	struct zcrypt_device *zdev;
+	struct zcrypt_device *zdev, *pref_zdev = NULL;
 	int rc;
+	unsigned int weight, func_code, pref_weight = 0;
 
 	if (mex->outputdatalength < mex->inputdatalength)
 		return -EINVAL;
@@ -432,6 +429,10 @@ static long zcrypt_rsa_modexpo(struct ica_rsa_modexpo *mex)
 	 */
 	mex->outputdatalength = mex->inputdatalength;
 
+	rc = get_rsa_modex_fc(mex, &func_code);
+	if (rc)
+		return rc;
+
 	spin_lock_bh(&zcrypt_device_lock);
 	list_for_each_entry(zdev, &zcrypt_device_list, list) {
 		if (!zdev->online ||
@@ -439,34 +440,52 @@ static long zcrypt_rsa_modexpo(struct ica_rsa_modexpo *mex)
 		    zdev->min_mod_size > mex->inputdatalength ||
 		    zdev->max_mod_size < mex->inputdatalength)
 			continue;
-		zcrypt_device_get(zdev);
-		get_device(&zdev->ap_dev->device);
-		zdev->request_count++;
-		__zcrypt_decrease_preference(zdev);
-		if (try_module_get(zdev->ap_dev->drv->driver.owner)) {
-			spin_unlock_bh(&zcrypt_device_lock);
-			rc = zdev->ops->rsa_modexpo(zdev, mex);
-			spin_lock_bh(&zcrypt_device_lock);
-			module_put(zdev->ap_dev->drv->driver.owner);
+		weight = zdev->speed_rating[func_code];
+		if (!pref_zdev) {
+			pref_zdev = zdev;
+			pref_weight = weight;
+			continue;
 		}
-		else
-			rc = -EAGAIN;
-		zdev->request_count--;
-		__zcrypt_increase_preference(zdev);
-		put_device(&zdev->ap_dev->device);
-		zcrypt_device_put(zdev);
+		if ((pref_zdev->load + pref_weight) > (zdev->load + weight)) {
+			pref_zdev = zdev;
+			pref_weight = weight;
+			continue;
+		}
+		if ((pref_zdev->load + pref_weight) <= zdev->load)
+			break; /* Load on remaining devices too high - abort */
+	}
+
+	if (!pref_zdev) {
 		spin_unlock_bh(&zcrypt_device_lock);
-		return rc;
+		return -ENODEV;
 	}
+	__zcrypt_decrease_preference(pref_zdev, pref_weight);
+	zcrypt_device_get(pref_zdev);
+	get_device(&pref_zdev->ap_dev->device);
+	pref_zdev->request_count++;
+	if (try_module_get(pref_zdev->ap_dev->drv->driver.owner)) {
+		spin_unlock_bh(&zcrypt_device_lock);
+		rc = -ENODEV;
+		rc = pref_zdev->ops->rsa_modexpo(pref_zdev, mex);
+		spin_lock_bh(&zcrypt_device_lock);
+		module_put(pref_zdev->ap_dev->drv->driver.owner);
+	} else
+		rc = -EAGAIN;
+
+	pref_zdev->request_count--;
+	__zcrypt_increase_preference(pref_zdev, pref_weight);
+	put_device(&pref_zdev->ap_dev->device);
+	zcrypt_device_put(pref_zdev);
 	spin_unlock_bh(&zcrypt_device_lock);
-	return -ENODEV;
+	return rc;
 }
 
 static long zcrypt_rsa_crt(struct ica_rsa_modexpo_crt *crt)
 {
-	struct zcrypt_device *zdev;
+	struct zcrypt_device *zdev, *pref_zdev = NULL;
 	unsigned long long z1, z2, z3;
 	int rc, copied;
+	unsigned int weight, func_code, pref_weight = 0;
 
 	if (crt->outputdatalength < crt->inputdatalength)
 		return -EINVAL;
@@ -477,6 +496,10 @@ static long zcrypt_rsa_crt(struct ica_rsa_modexpo_crt *crt)
 	 */
 	crt->outputdatalength = crt->inputdatalength;
 
+	rc = get_rsa_crt_fc(crt, &func_code);
+	if (rc)
+		return rc;
+
 	copied = 0;
  restart:
 	spin_lock_bh(&zcrypt_device_lock);
@@ -523,33 +546,54 @@ static long zcrypt_rsa_crt(struct ica_rsa_modexpo_crt *crt)
 				/* The device can't handle this request. */
 				continue;
 		}
-		zcrypt_device_get(zdev);
-		get_device(&zdev->ap_dev->device);
-		zdev->request_count++;
-		__zcrypt_decrease_preference(zdev);
-		if (try_module_get(zdev->ap_dev->drv->driver.owner)) {
-			spin_unlock_bh(&zcrypt_device_lock);
-			rc = zdev->ops->rsa_modexpo_crt(zdev, crt);
-			spin_lock_bh(&zcrypt_device_lock);
-			module_put(zdev->ap_dev->drv->driver.owner);
+
+		weight = zdev->speed_rating[func_code];
+		if (!pref_zdev) {
+			pref_zdev = zdev;
+			pref_weight = weight;
+			continue;
+		}
+		if ((pref_zdev->load + pref_weight) > (zdev->load + weight)) {
+			pref_zdev = zdev;
+			pref_weight = weight;
+			continue;
 		}
-		else
-			rc = -EAGAIN;
-		zdev->request_count--;
-		__zcrypt_increase_preference(zdev);
-		put_device(&zdev->ap_dev->device);
-		zcrypt_device_put(zdev);
+		if ((pref_zdev->load + pref_weight) <= zdev->load)
+			break; /* Load on remaining devices too high - abort */
+	}
+	if (!pref_zdev) {
 		spin_unlock_bh(&zcrypt_device_lock);
-		return rc;
+		return -ENODEV;
 	}
+	__zcrypt_decrease_preference(pref_zdev, pref_weight);
+	zcrypt_device_get(pref_zdev);
+	get_device(&pref_zdev->ap_dev->device);
+	pref_zdev->request_count++;
+	if (try_module_get(pref_zdev->ap_dev->drv->driver.owner)) {
+		spin_unlock_bh(&zcrypt_device_lock);
+		rc = pref_zdev->ops->rsa_modexpo_crt(pref_zdev, crt);
+		spin_lock_bh(&zcrypt_device_lock);
+		module_put(pref_zdev->ap_dev->drv->driver.owner);
+	} else
+		rc = -EAGAIN;
+	pref_zdev->request_count--;
+	__zcrypt_increase_preference(pref_zdev, pref_weight);
+	put_device(&pref_zdev->ap_dev->device);
+	zcrypt_device_put(pref_zdev);
 	spin_unlock_bh(&zcrypt_device_lock);
-	return -ENODEV;
+	return rc;
 }
 
 static long zcrypt_send_cprb(struct ica_xcRB *xcRB)
 {
-	struct zcrypt_device *zdev;
+	struct zcrypt_device *zdev, *pref_zdev = NULL;
+	unsigned int weight = 0, func_code = 0, pref_weight = 0;
 	int rc;
+	struct ap_message ap_msg;
+
+	rc = get_cprb_fc(xcRB, &ap_msg, &func_code);
+	if (rc)
+		return rc;
 
 	spin_lock_bh(&zcrypt_device_lock);
 	list_for_each_entry(zdev, &zcrypt_device_list, list) {
@@ -558,27 +602,42 @@ static long zcrypt_send_cprb(struct ica_xcRB *xcRB)
 		   (xcRB->user_defined != AUTOSELECT &&
 		    AP_QID_DEVICE(zdev->ap_dev->qid) != xcRB->user_defined))
 			continue;
-		zcrypt_device_get(zdev);
-		get_device(&zdev->ap_dev->device);
-		zdev->request_count++;
-		__zcrypt_decrease_preference(zdev);
-		if (try_module_get(zdev->ap_dev->drv->driver.owner)) {
-			spin_unlock_bh(&zcrypt_device_lock);
-			rc = zdev->ops->send_cprb(zdev, xcRB);
-			spin_lock_bh(&zcrypt_device_lock);
-			module_put(zdev->ap_dev->drv->driver.owner);
+
+		weight = speed_idx_cca(func_code) * zdev->speed_rating[SECKEY];
+		if (!pref_zdev) {
+			pref_zdev = zdev;
+			pref_weight = weight;
+			continue;
+		}
+		if ((pref_zdev->load + pref_weight) > (zdev->load + weight)) {
+			pref_zdev = zdev;
+			pref_weight = weight;
+			continue;
 		}
-		else
-			rc = -EAGAIN;
-		zdev->request_count--;
-		__zcrypt_increase_preference(zdev);
-		put_device(&zdev->ap_dev->device);
-		zcrypt_device_put(zdev);
+		if ((pref_zdev->load + pref_weight) <= zdev->load)
+			break; /* Load on remaining devices too high - abort */
+	}
+	if (!pref_zdev) {
 		spin_unlock_bh(&zcrypt_device_lock);
-		return rc;
+		return -ENODEV;
 	}
+	__zcrypt_decrease_preference(pref_zdev, pref_weight);
+	zcrypt_device_get(pref_zdev);
+	get_device(&pref_zdev->ap_dev->device);
+	pref_zdev->request_count++;
+	if (try_module_get(pref_zdev->ap_dev->drv->driver.owner)) {
+		spin_unlock_bh(&zcrypt_device_lock);
+		rc = pref_zdev->ops->send_cprb(pref_zdev, xcRB, &ap_msg);
+		spin_lock_bh(&zcrypt_device_lock);
+		module_put(pref_zdev->ap_dev->drv->driver.owner);
+	} else
+		rc = -EAGAIN;
+	pref_zdev->request_count--;
+	__zcrypt_increase_preference(pref_zdev, pref_weight);
+	put_device(&pref_zdev->ap_dev->device);
+	zcrypt_device_put(pref_zdev);
 	spin_unlock_bh(&zcrypt_device_lock);
-	return -ENODEV;
+	return rc;
 }
 
 struct ep11_target_dev_list {
@@ -602,7 +661,9 @@ static bool is_desired_ep11dev(unsigned int dev_qid,
 
 static long zcrypt_send_ep11_cprb(struct ep11_urb *xcrb)
 {
-	struct zcrypt_device *zdev;
+	struct zcrypt_device *zdev, *pref_zdev = NULL;
+	struct ap_message ap_msg;
+	unsigned int weight = 0, func_code = 0, pref_weight = 0;
 	bool autoselect = false;
 	int rc;
 	struct ep11_target_dev_list ep11_dev_list = {
@@ -630,6 +691,10 @@ static long zcrypt_send_ep11_cprb(struct ep11_urb *xcrb)
 			return -EFAULT;
 	}
 
+	rc = get_ep11cprb_fc(xcrb, &ap_msg, &func_code);
+	if (rc)
+		return rc;
+
 	spin_lock_bh(&zcrypt_device_lock);
 	list_for_each_entry(zdev, &zcrypt_device_list, list) {
 		/* check if device is eligible */
@@ -642,58 +707,93 @@ static long zcrypt_send_ep11_cprb(struct ep11_urb *xcrb)
 		    !autoselect)
 			continue;
 
-		zcrypt_device_get(zdev);
-		get_device(&zdev->ap_dev->device);
-		zdev->request_count++;
-		__zcrypt_decrease_preference(zdev);
-		if (try_module_get(zdev->ap_dev->drv->driver.owner)) {
-			spin_unlock_bh(&zcrypt_device_lock);
-			rc = zdev->ops->send_ep11_cprb(zdev, xcrb);
-			spin_lock_bh(&zcrypt_device_lock);
-			module_put(zdev->ap_dev->drv->driver.owner);
-		} else {
-			rc = -EAGAIN;
-		  }
-		zdev->request_count--;
-		__zcrypt_increase_preference(zdev);
-		put_device(&zdev->ap_dev->device);
-		zcrypt_device_put(zdev);
+		weight = speed_idx_ep11(func_code) * zdev->speed_rating[SECKEY];
+		if (!pref_zdev) {
+			pref_zdev = zdev;
+			pref_weight = weight;
+			continue;
+		}
+		if ((pref_zdev->load + pref_weight) > (zdev->load + weight)) {
+			pref_zdev = zdev;
+			pref_weight = weight;
+			continue;
+		}
+		if ((pref_zdev->load + pref_weight) <= zdev->load)
+			break; /* Load on remaining devices too high - abort */
+	}
+	if (!pref_zdev) {
 		spin_unlock_bh(&zcrypt_device_lock);
-		return rc;
+		return -ENODEV;
+	}
+
+	zcrypt_device_get(pref_zdev);
+	get_device(&pref_zdev->ap_dev->device);
+	pref_zdev->request_count++;
+	if (try_module_get(pref_zdev->ap_dev->drv->driver.owner)) {
+		spin_unlock_bh(&zcrypt_device_lock);
+		rc = pref_zdev->ops->send_ep11_cprb(pref_zdev, xcrb, &ap_msg);
+		spin_lock_bh(&zcrypt_device_lock);
+		module_put(pref_zdev->ap_dev->drv->driver.owner);
+	} else {
+		rc = -EAGAIN;
 	}
+	pref_zdev->request_count--;
+	put_device(&pref_zdev->ap_dev->device);
+	zcrypt_device_put(pref_zdev);
 	spin_unlock_bh(&zcrypt_device_lock);
-	return -ENODEV;
+	return rc;
 }
 
 static long zcrypt_rng(char *buffer)
 {
-	struct zcrypt_device *zdev;
+	struct zcrypt_device *zdev, *pref_zdev = NULL;
+	struct ap_message ap_msg;
+	unsigned int weight = 0, func_code = 0, pref_weight = 0;
 	int rc;
 
+	rc = get_rng_fc(&ap_msg, &func_code);
+	if (rc)
+		return rc;
+
 	spin_lock_bh(&zcrypt_device_lock);
 	list_for_each_entry(zdev, &zcrypt_device_list, list) {
 		if (!zdev->online || !zdev->ops->rng)
 			continue;
-		zcrypt_device_get(zdev);
-		get_device(&zdev->ap_dev->device);
-		zdev->request_count++;
-		__zcrypt_decrease_preference(zdev);
-		if (try_module_get(zdev->ap_dev->drv->driver.owner)) {
-			spin_unlock_bh(&zcrypt_device_lock);
-			rc = zdev->ops->rng(zdev, buffer);
-			spin_lock_bh(&zcrypt_device_lock);
-			module_put(zdev->ap_dev->drv->driver.owner);
-		} else
-			rc = -EAGAIN;
-		zdev->request_count--;
-		__zcrypt_increase_preference(zdev);
-		put_device(&zdev->ap_dev->device);
-		zcrypt_device_put(zdev);
+
+		weight = zdev->speed_rating[func_code];
+		if (!pref_zdev) {
+			pref_zdev = zdev;
+			pref_weight = weight;
+			continue;
+		}
+		if ((pref_zdev->load + pref_weight) > (zdev->load + weight)) {
+			pref_zdev = zdev;
+			pref_weight = weight;
+			continue;
+		}
+		if ((pref_zdev->load + pref_weight) <= zdev->load)
+			break; /* Load on remaining devices too high - abort */
+	}
+	if (!pref_zdev) {
 		spin_unlock_bh(&zcrypt_device_lock);
-		return rc;
+		return -ENODEV;
 	}
+
+	zcrypt_device_get(pref_zdev);
+	get_device(&pref_zdev->ap_dev->device);
+	pref_zdev->request_count++;
+	if (try_module_get(pref_zdev->ap_dev->drv->driver.owner)) {
+		spin_unlock_bh(&zcrypt_device_lock);
+		rc = pref_zdev->ops->rng(pref_zdev, buffer, &ap_msg);
+		spin_lock_bh(&zcrypt_device_lock);
+		module_put(pref_zdev->ap_dev->drv->driver.owner);
+	} else
+		rc = -EAGAIN;
+	pref_zdev->request_count--;
+	put_device(&pref_zdev->ap_dev->device);
+	zcrypt_device_put(pref_zdev);
 	spin_unlock_bh(&zcrypt_device_lock);
-	return -ENODEV;
+	return rc;
 }
 
 static void zcrypt_status_mask(char status[AP_DEVICES])
diff --git a/drivers/s390/crypto/zcrypt_api.h b/drivers/s390/crypto/zcrypt_api.h
index 01d02342c190..6ea916143ec8 100644
--- a/drivers/s390/crypto/zcrypt_api.h
+++ b/drivers/s390/crypto/zcrypt_api.h
@@ -84,15 +84,32 @@ struct ica_z90_status {
  */
 #define ZCRYPT_RNG_BUFFER_SIZE	4096
 
+/*
+ * Identifier for Crypto Request Performance Index
+ */
+enum crypto_ops {
+	MEX_1K = 0,
+	MEX_2K,
+	MEX_4K,
+	CRT_1K,
+	CRT_2K,
+	CRT_4K,
+	HWRNG,
+	SECKEY,
+	NUM_OPS
+};
+
 struct zcrypt_device;
 
 struct zcrypt_ops {
 	long (*rsa_modexpo)(struct zcrypt_device *, struct ica_rsa_modexpo *);
 	long (*rsa_modexpo_crt)(struct zcrypt_device *,
 				struct ica_rsa_modexpo_crt *);
-	long (*send_cprb)(struct zcrypt_device *, struct ica_xcRB *);
-	long (*send_ep11_cprb)(struct zcrypt_device *, struct ep11_urb *);
-	long (*rng)(struct zcrypt_device *, char *);
+	long (*send_cprb)(struct zcrypt_device *, struct ica_xcRB *,
+			  struct ap_message *);
+	long (*send_ep11_cprb)(struct zcrypt_device *, struct ep11_urb *,
+			       struct ap_message *);
+	long (*rng)(struct zcrypt_device *, char *, struct ap_message *);
 	struct list_head list;		/* zcrypt ops list. */
 	struct module *owner;
 	int variant;
@@ -111,7 +128,8 @@ struct zcrypt_device {
 	int min_mod_size;		/* Min number of bits. */
 	int max_mod_size;		/* Max number of bits. */
 	int short_crt;			/* Card has crt length restriction. */
-	int speed_rating;		/* Speed of the crypto device. */
+	int speed_rating[NUM_OPS];	/* Speed idx of crypto ops. */
+	int load;			/* Utilization of the crypto device */
 
 	int request_count;		/* # current requests. */
 
* Unmerged path drivers/s390/crypto/zcrypt_cex2a.c
* Unmerged path drivers/s390/crypto/zcrypt_cex4.c
diff --git a/drivers/s390/crypto/zcrypt_msgtype50.c b/drivers/s390/crypto/zcrypt_msgtype50.c
index 64cd342bbc8d..3bda35a0c544 100644
--- a/drivers/s390/crypto/zcrypt_msgtype50.c
+++ b/drivers/s390/crypto/zcrypt_msgtype50.c
@@ -173,6 +173,38 @@ struct type80_hdr {
 	unsigned char	reserved3[8];
 } __packed;
 
+unsigned int get_rsa_modex_fc(struct ica_rsa_modexpo *mex, int *fcode)
+{
+
+	if (!mex->inputdatalength)
+		return -EINVAL;
+
+	if (mex->inputdatalength <= 128)	/* 1024 bit */
+		*fcode = MEX_1K;
+	else if (mex->inputdatalength <= 256)	/* 2048 bit */
+		*fcode = MEX_2K;
+	else					/* 4096 bit */
+		*fcode = MEX_4K;
+
+	return 0;
+}
+
+unsigned int get_rsa_crt_fc(struct ica_rsa_modexpo_crt *crt, int *fcode)
+{
+
+	if (!crt->inputdatalength)
+		return -EINVAL;
+
+	if (crt->inputdatalength <= 128)	/* 1024 bit */
+		*fcode = CRT_1K;
+	else if (crt->inputdatalength <= 256)	/* 2048 bit */
+		*fcode = CRT_2K;
+	else					/* 4096 bit */
+		*fcode = CRT_4K;
+
+	return 0;
+}
+
 /**
  * Convert a ICAMEX message to a type50 MEX message.
  *
* Unmerged path drivers/s390/crypto/zcrypt_msgtype50.h
* Unmerged path drivers/s390/crypto/zcrypt_msgtype6.c
diff --git a/drivers/s390/crypto/zcrypt_msgtype6.h b/drivers/s390/crypto/zcrypt_msgtype6.h
index 207247570623..07aaebd1f781 100644
--- a/drivers/s390/crypto/zcrypt_msgtype6.h
+++ b/drivers/s390/crypto/zcrypt_msgtype6.h
@@ -116,15 +116,25 @@ struct type86_fmt2_ext {
 	unsigned int	  offset4;	/* 0x00000000			*/
 } __packed;
 
+unsigned int get_cprb_fc(struct ica_xcRB *, struct ap_message *, int *);
+unsigned int get_ep11cprb_fc(struct ep11_urb *, struct ap_message *, int *);
+unsigned int get_rng_fc(struct ap_message *, int *);
+
+#define LOW	10
+#define MEDIUM	100
+#define HIGH	500
+
+int speed_idx_cca(int);
+int speed_idx_ep11(int);
+
 /**
  * Prepare a type6 CPRB message for random number generation
  *
  * @ap_dev: AP device pointer
  * @ap_msg: pointer to AP message
  */
-static inline void rng_type6CPRB_msgX(struct ap_device *ap_dev,
-			       struct ap_message *ap_msg,
-			       unsigned random_number_length)
+static inline void rng_type6CPRB_msgX(struct ap_message *ap_msg,
+				      unsigned int random_number_length)
 {
 	struct {
 		struct type6_hdr hdr;
@@ -156,7 +166,6 @@ static inline void rng_type6CPRB_msgX(struct ap_device *ap_dev,
 	msg->hdr.FromCardLen2 = random_number_length,
 	msg->cprbx = local_cprbx;
 	msg->cprbx.rpl_datal = random_number_length,
-	msg->cprbx.domain = AP_QID_QUEUE(ap_dev->qid);
 	memcpy(msg->function_code, msg->hdr.function_code, 0x02);
 	msg->rule_length = 0x0a;
 	memcpy(msg->rule, "RANDOM  ", 8);
diff --git a/drivers/s390/crypto/zcrypt_pcixcc.c b/drivers/s390/crypto/zcrypt_pcixcc.c
index 899ffa19f5ec..1ab4fd643377 100644
--- a/drivers/s390/crypto/zcrypt_pcixcc.c
+++ b/drivers/s390/crypto/zcrypt_pcixcc.c
@@ -46,11 +46,6 @@
 #define CEX3C_MIN_MOD_SIZE	PCIXCC_MIN_MOD_SIZE
 #define CEX3C_MAX_MOD_SIZE	512	/* 4096 bits	*/
 
-#define PCIXCC_MCL2_SPEED_RATING	7870
-#define PCIXCC_MCL3_SPEED_RATING	7870
-#define CEX2C_SPEED_RATING		7000
-#define CEX3C_SPEED_RATING		6500
-
 #define PCIXCC_MAX_ICA_MESSAGE_SIZE 0x77c  /* max size type6 v2 crt message */
 #define PCIXCC_MAX_ICA_RESPONSE_SIZE 0x77c /* max size type86 v2 reply	    */
 
@@ -220,6 +215,15 @@ static int zcrypt_pcixcc_rng_supported(struct ap_device *ap_dev)
 		struct type86_fmt2_ext fmt2;
 		struct CPRBX cprbx;
 	} __attribute__((packed)) *reply;
+	struct {
+		struct type6_hdr hdr;
+		struct CPRBX cprbx;
+		char function_code[2];
+		short int rule_length;
+		char rule[8];
+		short int verb_length;
+		short int key_length;
+	} __packed * msg;
 	int rc, i;
 
 	ap_init_message(&ap_msg);
@@ -227,7 +231,11 @@ static int zcrypt_pcixcc_rng_supported(struct ap_device *ap_dev)
 	if (!ap_msg.message)
 		return -ENOMEM;
 
-	rng_type6CPRB_msgX(ap_dev, &ap_msg, 4);
+	rng_type6CPRB_msgX(&ap_msg, 4);
+
+	msg = ap_msg.message;
+	msg->cprbx.domain = AP_QID_QUEUE(ap_dev->qid);
+
 	rc = ap_send(ap_dev->qid, 0x0102030405060708ULL, ap_msg.message,
 		     ap_msg.length);
 	if (rc)
@@ -267,6 +275,14 @@ out_free:
 static int zcrypt_pcixcc_probe(struct ap_device *ap_dev)
 {
 	struct zcrypt_device *zdev;
+	/*
+	 * Normalized speed ratings per crypto adapter
+	 * MEX_1k, MEX_2k, MEX_4k, CRT_1k, CRT_2k, CRT_4k, RNG, SECKEY
+	 */
+	int PCIXCC_MCL2_SPEED_IDX[] = {10, 10, 10, 10, 10, 10, 10, 10};
+	int PCIXCC_MCL3_SPEED_IDX[] = { 8,  8,	8,  8,	8,  8,	8,  8};
+	int CEX2C_SPEED_IDX[] = {1000, 1400, 2400, 1100, 1500, 2600, 100, 12};
+	int CEX3C_SPEED_IDX[] = { 500,	700, 1400,  550,  800, 1500,  80, 10};
 	int rc = 0;
 
 	zdev = zcrypt_device_alloc(PCIXCC_MAX_XCRB_MESSAGE_SIZE);
@@ -284,13 +300,15 @@ static int zcrypt_pcixcc_probe(struct ap_device *ap_dev)
 		zdev->user_space_type = rc;
 		if (rc == ZCRYPT_PCIXCC_MCL2) {
 			zdev->type_string = "PCIXCC_MCL2";
-			zdev->speed_rating = PCIXCC_MCL2_SPEED_RATING;
+			memcpy(zdev->speed_rating, PCIXCC_MCL2_SPEED_IDX,
+			       sizeof(PCIXCC_MCL2_SPEED_IDX));
 			zdev->min_mod_size = PCIXCC_MIN_MOD_SIZE_OLD;
 			zdev->max_mod_size = PCIXCC_MAX_MOD_SIZE;
 			zdev->max_exp_bit_length = PCIXCC_MAX_MOD_SIZE;
 		} else {
 			zdev->type_string = "PCIXCC_MCL3";
-			zdev->speed_rating = PCIXCC_MCL3_SPEED_RATING;
+			memcpy(zdev->speed_rating, PCIXCC_MCL3_SPEED_IDX,
+			       sizeof(PCIXCC_MCL3_SPEED_IDX));
 			zdev->min_mod_size = PCIXCC_MIN_MOD_SIZE;
 			zdev->max_mod_size = PCIXCC_MAX_MOD_SIZE;
 			zdev->max_exp_bit_length = PCIXCC_MAX_MOD_SIZE;
@@ -299,7 +317,8 @@ static int zcrypt_pcixcc_probe(struct ap_device *ap_dev)
 	case AP_DEVICE_TYPE_CEX2C:
 		zdev->user_space_type = ZCRYPT_CEX2C;
 		zdev->type_string = "CEX2C";
-		zdev->speed_rating = CEX2C_SPEED_RATING;
+		memcpy(zdev->speed_rating, CEX2C_SPEED_IDX,
+		       sizeof(CEX2C_SPEED_IDX));
 		zdev->min_mod_size = PCIXCC_MIN_MOD_SIZE;
 		zdev->max_mod_size = PCIXCC_MAX_MOD_SIZE;
 		zdev->max_exp_bit_length = PCIXCC_MAX_MOD_SIZE;
@@ -307,7 +326,8 @@ static int zcrypt_pcixcc_probe(struct ap_device *ap_dev)
 	case AP_DEVICE_TYPE_CEX3C:
 		zdev->user_space_type = ZCRYPT_CEX3C;
 		zdev->type_string = "CEX3C";
-		zdev->speed_rating = CEX3C_SPEED_RATING;
+		memcpy(zdev->speed_rating, CEX3C_SPEED_IDX,
+		       sizeof(CEX3C_SPEED_IDX));
 		zdev->min_mod_size = CEX3C_MIN_MOD_SIZE;
 		zdev->max_mod_size = CEX3C_MAX_MOD_SIZE;
 		zdev->max_exp_bit_length = CEX3C_MAX_MOD_SIZE;
@@ -315,6 +335,7 @@ static int zcrypt_pcixcc_probe(struct ap_device *ap_dev)
 	default:
 		goto out_free;
 	}
+	zdev->load = zdev->speed_rating[0];
 
 	rc = zcrypt_pcixcc_rng_supported(ap_dev);
 	if (rc < 0) {
