IB/mlx5: Respect mlx5_core reserved GIDs

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Ilan Tayari <ilant@mellanox.com>
commit 095b0927f0ce74f7211b9046f8493dbba26ca930
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/095b0927.failed

Reserved gids are taken by the mlx5_core, report smaller GID table
size to IB core.

Set mlx5_query_roce_port's return value back to int. In case of
error, return an indication. This rolls back some of the change
in commit 50f22fd8ecf9 ("IB/mlx5: Set mlx5_query_roce_port's return value to void")

Change set_roce_addr to use gid_set function, instead of directly
sending the command.

	Signed-off-by: Ilan Tayari <ilant@mellanox.com>
	Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 095b0927f0ce74f7211b9046f8493dbba26ca930)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/main.c
diff --cc drivers/infiniband/hw/mlx5/main.c
index af6314d865ab,dc2f59e33971..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -194,6 -165,64 +194,67 @@@ static struct net_device *mlx5_ib_get_n
  	return ndev;
  }
  
++<<<<<<< HEAD
++=======
+ static int translate_eth_proto_oper(u32 eth_proto_oper, u8 *active_speed,
+ 				    u8 *active_width)
+ {
+ 	switch (eth_proto_oper) {
+ 	case MLX5E_PROT_MASK(MLX5E_1000BASE_CX_SGMII):
+ 	case MLX5E_PROT_MASK(MLX5E_1000BASE_KX):
+ 	case MLX5E_PROT_MASK(MLX5E_100BASE_TX):
+ 	case MLX5E_PROT_MASK(MLX5E_1000BASE_T):
+ 		*active_width = IB_WIDTH_1X;
+ 		*active_speed = IB_SPEED_SDR;
+ 		break;
+ 	case MLX5E_PROT_MASK(MLX5E_10GBASE_T):
+ 	case MLX5E_PROT_MASK(MLX5E_10GBASE_CX4):
+ 	case MLX5E_PROT_MASK(MLX5E_10GBASE_KX4):
+ 	case MLX5E_PROT_MASK(MLX5E_10GBASE_KR):
+ 	case MLX5E_PROT_MASK(MLX5E_10GBASE_CR):
+ 	case MLX5E_PROT_MASK(MLX5E_10GBASE_SR):
+ 	case MLX5E_PROT_MASK(MLX5E_10GBASE_ER):
+ 		*active_width = IB_WIDTH_1X;
+ 		*active_speed = IB_SPEED_QDR;
+ 		break;
+ 	case MLX5E_PROT_MASK(MLX5E_25GBASE_CR):
+ 	case MLX5E_PROT_MASK(MLX5E_25GBASE_KR):
+ 	case MLX5E_PROT_MASK(MLX5E_25GBASE_SR):
+ 		*active_width = IB_WIDTH_1X;
+ 		*active_speed = IB_SPEED_EDR;
+ 		break;
+ 	case MLX5E_PROT_MASK(MLX5E_40GBASE_CR4):
+ 	case MLX5E_PROT_MASK(MLX5E_40GBASE_KR4):
+ 	case MLX5E_PROT_MASK(MLX5E_40GBASE_SR4):
+ 	case MLX5E_PROT_MASK(MLX5E_40GBASE_LR4):
+ 		*active_width = IB_WIDTH_4X;
+ 		*active_speed = IB_SPEED_QDR;
+ 		break;
+ 	case MLX5E_PROT_MASK(MLX5E_50GBASE_CR2):
+ 	case MLX5E_PROT_MASK(MLX5E_50GBASE_KR2):
+ 	case MLX5E_PROT_MASK(MLX5E_50GBASE_SR2):
+ 		*active_width = IB_WIDTH_1X;
+ 		*active_speed = IB_SPEED_HDR;
+ 		break;
+ 	case MLX5E_PROT_MASK(MLX5E_56GBASE_R4):
+ 		*active_width = IB_WIDTH_4X;
+ 		*active_speed = IB_SPEED_FDR;
+ 		break;
+ 	case MLX5E_PROT_MASK(MLX5E_100GBASE_CR4):
+ 	case MLX5E_PROT_MASK(MLX5E_100GBASE_SR4):
+ 	case MLX5E_PROT_MASK(MLX5E_100GBASE_KR4):
+ 	case MLX5E_PROT_MASK(MLX5E_100GBASE_LR4):
+ 		*active_width = IB_WIDTH_4X;
+ 		*active_speed = IB_SPEED_EDR;
+ 		break;
+ 	default:
+ 		return -EINVAL;
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 095b0927f0ce (IB/mlx5: Respect mlx5_core reserved GIDs)
  static int mlx5_query_port_roce(struct ib_device *device, u8 port_num,
  				struct ib_port_attr *props)
  {
@@@ -201,8 -230,19 +262,23 @@@
  	struct net_device *ndev, *upper;
  	enum ib_mtu ndev_ib_mtu;
  	u16 qkey_viol_cntr;
++<<<<<<< HEAD
 +
 +	memset(props, 0, sizeof(*props));
++=======
+ 	u32 eth_prot_oper;
+ 	int err;
+ 
+ 	/* Possible bad flows are checked before filling out props so in case
+ 	 * of an error it will still be zeroed out.
+ 	 */
+ 	err = mlx5_query_port_eth_proto_oper(mdev, &eth_prot_oper, port_num);
+ 	if (err)
+ 		return err;
+ 
+ 	translate_eth_proto_oper(eth_prot_oper, &props->active_speed,
+ 				 &props->active_width);
++>>>>>>> 095b0927f0ce (IB/mlx5: Respect mlx5_core reserved GIDs)
  
  	props->port_cap_flags  |= IB_PORT_CM_SUP;
  	props->port_cap_flags  |= IB_PORT_IP_BASED_GIDS;
@@@ -243,10 -283,6 +319,13 @@@
  	dev_put(ndev);
  
  	props->active_mtu	= min(props->max_mtu, ndev_ib_mtu);
++<<<<<<< HEAD
 +
 +	props->active_width	= IB_WIDTH_4X;  /* TODO */
 +	props->active_speed	= IB_SPEED_QDR; /* TODO */
 +
++=======
++>>>>>>> 095b0927f0ce (IB/mlx5: Respect mlx5_core reserved GIDs)
  	return 0;
  }
  
@@@ -982,19 -954,31 +1034,35 @@@ out
  int mlx5_ib_query_port(struct ib_device *ibdev, u8 port,
  		       struct ib_port_attr *props)
  {
+ 	unsigned int count;
+ 	int ret;
+ 
  	switch (mlx5_get_vport_access_method(ibdev)) {
  	case MLX5_VPORT_ACCESS_METHOD_MAD:
- 		return mlx5_query_mad_ifc_port(ibdev, port, props);
+ 		ret = mlx5_query_mad_ifc_port(ibdev, port, props);
+ 		break;
  
  	case MLX5_VPORT_ACCESS_METHOD_HCA:
- 		return mlx5_query_hca_port(ibdev, port, props);
+ 		ret = mlx5_query_hca_port(ibdev, port, props);
+ 		break;
  
  	case MLX5_VPORT_ACCESS_METHOD_NIC:
++<<<<<<< HEAD
 +		return mlx5_query_port_roce(ibdev, port, props);
++=======
+ 		ret = mlx5_query_port_roce(ibdev, port, props);
+ 		break;
++>>>>>>> 095b0927f0ce (IB/mlx5: Respect mlx5_core reserved GIDs)
  
  	default:
- 		return -EINVAL;
+ 		ret = -EINVAL;
  	}
+ 
+ 	if (!ret && props) {
+ 		count = mlx5_core_reserved_gids_count(to_mdev(ibdev)->mdev);
+ 		props->gid_tbl_len -= count;
+ 	}
+ 	return ret;
  }
  
  static int mlx5_ib_query_gid(struct ib_device *ibdev, u8 port, int index,
* Unmerged path drivers/infiniband/hw/mlx5/main.c
