net/mlx5e: Remove unnecessary fields in ICO SQ

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [netdrv] mlx5e: Remove unnecessary fields in ICO SQ (Kamal Heib) [1456694]
Rebuild_FUZZ: 95.45%
commit-author Tariq Toukan <tariqt@mellanox.com>
commit 3b56f7b2af86033f421d0f0fd10cf5c3f74872e0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/3b56f7b2.failed

As of current design, in each NAPI, only a single UMR WQE
completion could be available in the completion queue of the
the internal control operations (ICO) send queue, in addition
to nop operations that require no actions upon completion.
This renders the consume index obsolete, as the wqe_counter
field in CQE is sufficient.

This helps removing a memory barrier, and obsoletes the need
for tracking the num_wqebbs to update the consumer counter.

In addition, remove other unused fields in icosq struct:
pdev, dma_fifo_pc, and prev_cc.

	Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 3b56f7b2af86033f421d0f0fd10cf5c3f74872e0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en.h
#	drivers/net/ethernet/mellanox/mlx5/core/en_main.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en.h
index 819a88f4cbad,e55d9439bc12..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en.h
@@@ -296,13 -317,135 +296,137 @@@ struct mlx5e_cq 
  	struct mlx5_frag_wq_ctrl   wq_ctrl;
  } ____cacheline_aligned_in_smp;
  
 -struct mlx5e_tx_wqe_info {
 -	struct sk_buff *skb;
 -	u32 num_bytes;
 -	u8  num_wqebbs;
 -	u8  num_dma;
 -};
 -
 +struct mlx5e_rq;
 +typedef void (*mlx5e_fp_handle_rx_cqe)(struct mlx5e_rq *rq,
 +				       struct mlx5_cqe64 *cqe);
 +typedef int (*mlx5e_fp_alloc_wqe)(struct mlx5e_rq *rq, struct mlx5e_rx_wqe *wqe,
 +				  u16 ix);
 +
++<<<<<<< HEAD
 +typedef void (*mlx5e_fp_dealloc_wqe)(struct mlx5e_rq *rq, u16 ix);
++=======
+ enum mlx5e_dma_map_type {
+ 	MLX5E_DMA_MAP_SINGLE,
+ 	MLX5E_DMA_MAP_PAGE
+ };
+ 
+ struct mlx5e_sq_dma {
+ 	dma_addr_t              addr;
+ 	u32                     size;
+ 	enum mlx5e_dma_map_type type;
+ };
+ 
+ enum {
+ 	MLX5E_SQ_STATE_ENABLED,
+ 	MLX5E_SQ_STATE_IPSEC,
+ };
+ 
+ struct mlx5e_sq_wqe_info {
+ 	u8  opcode;
+ };
+ 
+ struct mlx5e_txqsq {
+ 	/* data path */
+ 
+ 	/* dirtied @completion */
+ 	u16                        cc;
+ 	u32                        dma_fifo_cc;
+ 
+ 	/* dirtied @xmit */
+ 	u16                        pc ____cacheline_aligned_in_smp;
+ 	u32                        dma_fifo_pc;
+ 	struct mlx5e_sq_stats      stats;
+ 
+ 	struct mlx5e_cq            cq;
+ 
+ 	/* write@xmit, read@completion */
+ 	struct {
+ 		struct mlx5e_sq_dma       *dma_fifo;
+ 		struct mlx5e_tx_wqe_info  *wqe_info;
+ 	} db;
+ 
+ 	/* read only */
+ 	struct mlx5_wq_cyc         wq;
+ 	u32                        dma_fifo_mask;
+ 	void __iomem              *uar_map;
+ 	struct netdev_queue       *txq;
+ 	u32                        sqn;
+ 	u16                        max_inline;
+ 	u8                         min_inline_mode;
+ 	u16                        edge;
+ 	struct device             *pdev;
+ 	struct mlx5e_tstamp       *tstamp;
+ 	__be32                     mkey_be;
+ 	unsigned long              state;
+ 
+ 	/* control path */
+ 	struct mlx5_wq_ctrl        wq_ctrl;
+ 	struct mlx5e_channel      *channel;
+ 	int                        txq_ix;
+ 	u32                        rate_limit;
+ } ____cacheline_aligned_in_smp;
+ 
+ struct mlx5e_xdpsq {
+ 	/* data path */
+ 
+ 	/* dirtied @rx completion */
+ 	u16                        cc;
+ 	u16                        pc;
+ 
+ 	struct mlx5e_cq            cq;
+ 
+ 	/* write@xmit, read@completion */
+ 	struct {
+ 		struct mlx5e_dma_info     *di;
+ 		bool                       doorbell;
+ 	} db;
+ 
+ 	/* read only */
+ 	struct mlx5_wq_cyc         wq;
+ 	void __iomem              *uar_map;
+ 	u32                        sqn;
+ 	struct device             *pdev;
+ 	__be32                     mkey_be;
+ 	u8                         min_inline_mode;
+ 	unsigned long              state;
+ 
+ 	/* control path */
+ 	struct mlx5_wq_ctrl        wq_ctrl;
+ 	struct mlx5e_channel      *channel;
+ } ____cacheline_aligned_in_smp;
+ 
+ struct mlx5e_icosq {
+ 	/* data path */
+ 
+ 	/* dirtied @xmit */
+ 	u16                        pc ____cacheline_aligned_in_smp;
+ 
+ 	struct mlx5e_cq            cq;
+ 
+ 	/* write@xmit, read@completion */
+ 	struct {
+ 		struct mlx5e_sq_wqe_info *ico_wqe;
+ 	} db;
+ 
+ 	/* read only */
+ 	struct mlx5_wq_cyc         wq;
+ 	void __iomem              *uar_map;
+ 	u32                        sqn;
+ 	u16                        edge;
+ 	__be32                     mkey_be;
+ 	unsigned long              state;
+ 
+ 	/* control path */
+ 	struct mlx5_wq_ctrl        wq_ctrl;
+ 	struct mlx5e_channel      *channel;
+ } ____cacheline_aligned_in_smp;
+ 
+ static inline bool
+ mlx5e_wqc_has_room_for(struct mlx5_wq_cyc *wq, u16 cc, u16 pc, u16 n)
+ {
+ 	return (((wq->sz_m1 & (cc - pc)) >= n) || (cc == pc));
+ }
++>>>>>>> 3b56f7b2af86 (net/mlx5e: Remove unnecessary fields in ICO SQ)
  
  struct mlx5e_dma_info {
  	struct page	*page;
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index d8b64a5a33e7,a4c9a0a2c408..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@@ -864,18 -942,91 +864,39 @@@ err_destroy_rq
  	return err;
  }
  
++<<<<<<< HEAD
++=======
+ static void mlx5e_activate_rq(struct mlx5e_rq *rq)
+ {
+ 	struct mlx5e_icosq *sq = &rq->channel->icosq;
+ 	u16 pi = sq->pc & sq->wq.sz_m1;
+ 	struct mlx5e_tx_wqe *nopwqe;
+ 
+ 	set_bit(MLX5E_RQ_STATE_ENABLED, &rq->state);
+ 	sq->db.ico_wqe[pi].opcode     = MLX5_OPCODE_NOP;
+ 	nopwqe = mlx5e_post_nop(&sq->wq, sq->sqn, &sq->pc);
+ 	mlx5e_notify_hw(&sq->wq, sq->pc, sq->uar_map, &nopwqe->ctrl);
+ }
+ 
+ static void mlx5e_deactivate_rq(struct mlx5e_rq *rq)
+ {
+ 	clear_bit(MLX5E_RQ_STATE_ENABLED, &rq->state);
+ 	napi_synchronize(&rq->channel->napi); /* prevent mlx5e_post_rx_wqes */
+ }
+ 
++>>>>>>> 3b56f7b2af86 (net/mlx5e: Remove unnecessary fields in ICO SQ)
  static void mlx5e_close_rq(struct mlx5e_rq *rq)
  {
 +	clear_bit(MLX5E_RQ_STATE_ENABLED, &rq->state);
 +	napi_synchronize(&rq->channel->napi); /* prevent mlx5e_post_rx_wqes */
  	cancel_work_sync(&rq->am.work);
 -	mlx5e_destroy_rq(rq);
 -	mlx5e_free_rx_descs(rq);
 -	mlx5e_free_rq(rq);
 -}
 -
 -static void mlx5e_free_xdpsq_db(struct mlx5e_xdpsq *sq)
 -{
 -	kfree(sq->db.di);
 -}
 -
 -static int mlx5e_alloc_xdpsq_db(struct mlx5e_xdpsq *sq, int numa)
 -{
 -	int wq_sz = mlx5_wq_cyc_get_size(&sq->wq);
 -
 -	sq->db.di = kzalloc_node(sizeof(*sq->db.di) * wq_sz,
 -				     GFP_KERNEL, numa);
 -	if (!sq->db.di) {
 -		mlx5e_free_xdpsq_db(sq);
 -		return -ENOMEM;
 -	}
 -
 -	return 0;
 -}
 -
 -static int mlx5e_alloc_xdpsq(struct mlx5e_channel *c,
 -			     struct mlx5e_params *params,
 -			     struct mlx5e_sq_param *param,
 -			     struct mlx5e_xdpsq *sq)
 -{
 -	void *sqc_wq               = MLX5_ADDR_OF(sqc, param->sqc, wq);
 -	struct mlx5_core_dev *mdev = c->mdev;
 -	int err;
 -
 -	sq->pdev      = c->pdev;
 -	sq->mkey_be   = c->mkey_be;
 -	sq->channel   = c;
 -	sq->uar_map   = mdev->mlx5e_res.bfreg.map;
 -	sq->min_inline_mode = params->tx_min_inline_mode;
  
 -	param->wq.db_numa_node = cpu_to_node(c->cpu);
 -	err = mlx5_wq_cyc_create(mdev, &param->wq, sqc_wq, &sq->wq, &sq->wq_ctrl);
 -	if (err)
 -		return err;
 -	sq->wq.db = &sq->wq.db[MLX5_SND_DBR];
 -
 -	err = mlx5e_alloc_xdpsq_db(sq, cpu_to_node(c->cpu));
 -	if (err)
 -		goto err_sq_wq_destroy;
 -
 -	return 0;
 -
 -err_sq_wq_destroy:
 -	mlx5_wq_destroy(&sq->wq_ctrl);
 -
 -	return err;
 -}
 -
 -static void mlx5e_free_xdpsq(struct mlx5e_xdpsq *sq)
 -{
 -	mlx5e_free_xdpsq_db(sq);
 -	mlx5_wq_destroy(&sq->wq_ctrl);
 +	mlx5e_disable_rq(rq);
 +	mlx5e_free_rx_descs(rq);
 +	mlx5e_destroy_rq(rq);
  }
  
 -static void mlx5e_free_icosq_db(struct mlx5e_icosq *sq)
 +static void mlx5e_free_sq_ico_db(struct mlx5e_sq *sq)
  {
  	kfree(sq->db.ico_wqe);
  }
@@@ -892,14 -1043,51 +913,43 @@@ static int mlx5e_alloc_sq_ico_db(struc
  	return 0;
  }
  
 -static int mlx5e_alloc_icosq(struct mlx5e_channel *c,
 -			     struct mlx5e_sq_param *param,
 -			     struct mlx5e_icosq *sq)
 +static void mlx5e_free_sq_txq_db(struct mlx5e_sq *sq)
  {
++<<<<<<< HEAD
 +	kfree(sq->db.txq.wqe_info);
 +	kfree(sq->db.txq.dma_fifo);
 +	kfree(sq->db.txq.skb);
++=======
+ 	void *sqc_wq               = MLX5_ADDR_OF(sqc, param->sqc, wq);
+ 	struct mlx5_core_dev *mdev = c->mdev;
+ 	int err;
+ 
+ 	sq->mkey_be   = c->mkey_be;
+ 	sq->channel   = c;
+ 	sq->uar_map   = mdev->mlx5e_res.bfreg.map;
+ 
+ 	param->wq.db_numa_node = cpu_to_node(c->cpu);
+ 	err = mlx5_wq_cyc_create(mdev, &param->wq, sqc_wq, &sq->wq, &sq->wq_ctrl);
+ 	if (err)
+ 		return err;
+ 	sq->wq.db = &sq->wq.db[MLX5_SND_DBR];
+ 
+ 	err = mlx5e_alloc_icosq_db(sq, cpu_to_node(c->cpu));
+ 	if (err)
+ 		goto err_sq_wq_destroy;
+ 
+ 	sq->edge = (sq->wq.sz_m1 + 1) - MLX5E_ICOSQ_MAX_WQEBBS;
+ 
+ 	return 0;
+ 
+ err_sq_wq_destroy:
+ 	mlx5_wq_destroy(&sq->wq_ctrl);
+ 
+ 	return err;
++>>>>>>> 3b56f7b2af86 (net/mlx5e: Remove unnecessary fields in ICO SQ)
  }
  
 -static void mlx5e_free_icosq(struct mlx5e_icosq *sq)
 -{
 -	mlx5e_free_icosq_db(sq);
 -	mlx5_wq_destroy(&sq->wq_ctrl);
 -}
 -
 -static void mlx5e_free_txqsq_db(struct mlx5e_txqsq *sq)
 -{
 -	kfree(sq->db.wqe_info);
 -	kfree(sq->db.dma_fifo);
 -}
 -
 -static int mlx5e_alloc_txqsq_db(struct mlx5e_txqsq *sq, int numa)
 +static int mlx5e_alloc_sq_txq_db(struct mlx5e_sq *sq, int numa)
  {
  	int wq_sz = mlx5_wq_cyc_get_size(&sq->wq);
  	int df_sz = wq_sz * MLX5_SEND_WQEBB_NUM_DS;
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
index d6a4d3219a46,88a8749c67d6..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
@@@ -340,8 -357,7 +340,12 @@@ static inline void mlx5e_post_umr_wqe(s
  	/* fill sq edge with nops to avoid wqe wrap around */
  	while ((pi = (sq->pc & wq->sz_m1)) > sq->edge) {
  		sq->db.ico_wqe[pi].opcode = MLX5_OPCODE_NOP;
++<<<<<<< HEAD
 +		sq->db.ico_wqe[pi].num_wqebbs = 1;
 +		mlx5e_send_nop(sq, false);
++=======
+ 		mlx5e_post_nop(wq, sq->sqn, &sq->pc);
++>>>>>>> 3b56f7b2af86 (net/mlx5e: Remove unnecessary fields in ICO SQ)
  	}
  
  	wqe = mlx5_wq_cyc_get_wqe(wq, pi);
@@@ -351,9 -367,8 +355,8 @@@
  			    MLX5_OPCODE_UMR);
  
  	sq->db.ico_wqe[pi].opcode = MLX5_OPCODE_UMR;
- 	sq->db.ico_wqe[pi].num_wqebbs = num_wqebbs;
  	sq->pc += num_wqebbs;
 -	mlx5e_notify_hw(&sq->wq, sq->pc, sq->uar_map, &wqe->ctrl);
 +	mlx5e_tx_notify_hw(sq, &wqe->ctrl, 0);
  }
  
  static int mlx5e_alloc_rx_umr_mpwqe(struct mlx5e_rq *rq,
@@@ -469,7 -479,71 +472,75 @@@ bool mlx5e_post_rx_wqes(struct mlx5e_r
  
  	mlx5_wq_ll_update_db_record(wq);
  
++<<<<<<< HEAD
 +	return !mlx5_wq_ll_is_full(wq);
++=======
+ 	return !!err;
+ }
+ 
+ static inline void mlx5e_poll_ico_single_cqe(struct mlx5e_cq *cq,
+ 					     struct mlx5e_icosq *sq,
+ 					     struct mlx5e_rq *rq,
+ 					     struct mlx5_cqe64 *cqe)
+ {
+ 	struct mlx5_wq_cyc *wq = &sq->wq;
+ 	u16 ci = be16_to_cpu(cqe->wqe_counter) & wq->sz_m1;
+ 	struct mlx5e_sq_wqe_info *icowi = &sq->db.ico_wqe[ci];
+ 
+ 	mlx5_cqwq_pop(&cq->wq);
+ 
+ 	if (unlikely((cqe->op_own >> 4) != MLX5_CQE_REQ)) {
+ 		WARN_ONCE(true, "mlx5e: Bad OP in ICOSQ CQE: 0x%x\n",
+ 			  cqe->op_own);
+ 		return;
+ 	}
+ 
+ 	if (likely(icowi->opcode == MLX5_OPCODE_UMR)) {
+ 		mlx5e_post_rx_mpwqe(rq);
+ 		return;
+ 	}
+ 
+ 	if (unlikely(icowi->opcode != MLX5_OPCODE_NOP))
+ 		WARN_ONCE(true,
+ 			  "mlx5e: Bad OPCODE in ICOSQ WQE info: 0x%x\n",
+ 			  icowi->opcode);
+ }
+ 
+ static void mlx5e_poll_ico_cq(struct mlx5e_cq *cq, struct mlx5e_rq *rq)
+ {
+ 	struct mlx5e_icosq *sq = container_of(cq, struct mlx5e_icosq, cq);
+ 	struct mlx5_cqe64 *cqe;
+ 
+ 	if (unlikely(!MLX5E_TEST_BIT(sq->state, MLX5E_SQ_STATE_ENABLED)))
+ 		return;
+ 
+ 	cqe = mlx5_cqwq_get_cqe(&cq->wq);
+ 	if (likely(!cqe))
+ 		return;
+ 
+ 	/* by design, there's only a single cqe */
+ 	mlx5e_poll_ico_single_cqe(cq, sq, rq, cqe);
+ 
+ 	mlx5_cqwq_update_db_record(&cq->wq);
+ }
+ 
+ bool mlx5e_post_rx_mpwqes(struct mlx5e_rq *rq)
+ {
+ 	struct mlx5_wq_ll *wq = &rq->wq;
+ 
+ 	if (unlikely(!MLX5E_TEST_BIT(rq->state, MLX5E_RQ_STATE_ENABLED)))
+ 		return false;
+ 
+ 	mlx5e_poll_ico_cq(&rq->channel->icosq.cq, rq);
+ 
+ 	if (mlx5_wq_ll_is_full(wq))
+ 		return false;
+ 
+ 	if (!rq->mpwqe.umr_in_progress)
+ 		mlx5e_alloc_rx_mpwqe(rq, wq->head);
+ 
+ 	return true;
++>>>>>>> 3b56f7b2af86 (net/mlx5e: Remove unnecessary fields in ICO SQ)
  }
  
  static void mlx5e_lro_update_hdr(struct sk_buff *skb, struct mlx5_cqe64 *cqe,
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
