x86/intel_rdt: Simplify info and base file lists

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [x86] intel_rdt: Simplify info and base file lists (Jiri Olsa) [1457533]
Rebuild_FUZZ: 95.65%
commit-author Tony Luck <tony.luck@intel.com>
commit 5dc1d5c6bac2cfe3420cf353dfb0ef2e543f7c10
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/5dc1d5c6.failed

The info directory files and base files need to be different for each
resource like cache and Memory bandwidth. With in each resource, the
files would be further different for monitoring and ctrl. This leads to
a lot of different static array declarations given that we are adding
resctrl monitoring.

Simplify this to one common list of files and then declare a set of
flags to choose the files based on the resource, whether it is info or
base and if it is control type file. This is as a preparation to include
monitoring based info and base files.

No functional change.

[Vikas: Extended the flags to have few bits per category like resource,
	info/base etc]

	Signed-off-by: Tony luck <tony.luck@intel.com>
	Signed-off-by: Vikas Shivappa <vikas.shivappa@linux.intel.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: ravi.v.shankar@intel.com
	Cc: fenghua.yu@intel.com
	Cc: peterz@infradead.org
	Cc: eranian@google.com
	Cc: vikas.shivappa@intel.com
	Cc: ak@linux.intel.com
	Cc: davidcc@google.com
	Cc: reinette.chatre@intel.com
Link: http://lkml.kernel.org/r/1501017287-28083-11-git-send-email-vikas.shivappa@linux.intel.com

(cherry picked from commit 5dc1d5c6bac2cfe3420cf353dfb0ef2e543f7c10)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/intel_rdt.c
#	arch/x86/kernel/cpu/intel_rdt.h
#	arch/x86/kernel/cpu/intel_rdt_rdtgroup.c
diff --cc arch/x86/kernel/cpu/intel_rdt.c
index ad087dd4421e,7cae4ec75cfe..000000000000
--- a/arch/x86/kernel/cpu/intel_rdt.c
+++ b/arch/x86/kernel/cpu/intel_rdt.c
@@@ -45,42 -55,94 +45,117 @@@ DEFINE_PER_CPU_READ_MOSTLY(int, cpu_clo
   */
  int max_name_width, max_data_width;
  
 -/*
 - * Global boolean for rdt_alloc which is true if any
 - * resource allocation is enabled.
 - */
 -bool rdt_alloc_capable;
 -
 -static void
 -mba_wrmsr(struct rdt_domain *d, struct msr_param *m, struct rdt_resource *r);
 -static void
 -cat_wrmsr(struct rdt_domain *d, struct msr_param *m, struct rdt_resource *r);
 -
 -#define domain_init(id) LIST_HEAD_INIT(rdt_resources_all[id].domains)
 -
  struct rdt_resource rdt_resources_all[] = {
 -	[RDT_RESOURCE_L3] =
  	{
++<<<<<<< HEAD
 +		.name		= "L3",
 +		.domains	= domain_init(RDT_RESOURCE_L3),
 +		.msr_base	= IA32_L3_CBM_BASE,
 +		.min_cbm_bits	= 1,
 +		.cache_level	= 3,
 +		.cbm_idx_multi	= 1,
 +		.cbm_idx_offset	= 0
++=======
+ 		.name			= "L3",
+ 		.domains		= domain_init(RDT_RESOURCE_L3),
+ 		.msr_base		= IA32_L3_CBM_BASE,
+ 		.msr_update		= cat_wrmsr,
+ 		.cache_level		= 3,
+ 		.cache = {
+ 			.min_cbm_bits	= 1,
+ 			.cbm_idx_mult	= 1,
+ 			.cbm_idx_offset	= 0,
+ 		},
+ 		.parse_ctrlval		= parse_cbm,
+ 		.format_str		= "%d=%0*x",
+ 		.fflags			= RFTYPE_RES_CACHE,
++>>>>>>> 5dc1d5c6bac2 (x86/intel_rdt: Simplify info and base file lists)
  	},
 -	[RDT_RESOURCE_L3DATA] =
  	{
++<<<<<<< HEAD
 +		.name		= "L3DATA",
 +		.domains	= domain_init(RDT_RESOURCE_L3DATA),
 +		.msr_base	= IA32_L3_CBM_BASE,
 +		.min_cbm_bits	= 1,
 +		.cache_level	= 3,
 +		.cbm_idx_multi	= 2,
 +		.cbm_idx_offset	= 0
++=======
+ 		.name			= "L3DATA",
+ 		.domains		= domain_init(RDT_RESOURCE_L3DATA),
+ 		.msr_base		= IA32_L3_CBM_BASE,
+ 		.msr_update		= cat_wrmsr,
+ 		.cache_level		= 3,
+ 		.cache = {
+ 			.min_cbm_bits	= 1,
+ 			.cbm_idx_mult	= 2,
+ 			.cbm_idx_offset	= 0,
+ 		},
+ 		.parse_ctrlval		= parse_cbm,
+ 		.format_str		= "%d=%0*x",
+ 		.fflags			= RFTYPE_RES_CACHE,
++>>>>>>> 5dc1d5c6bac2 (x86/intel_rdt: Simplify info and base file lists)
  	},
 -	[RDT_RESOURCE_L3CODE] =
  	{
++<<<<<<< HEAD
 +		.name		= "L3CODE",
 +		.domains	= domain_init(RDT_RESOURCE_L3CODE),
 +		.msr_base	= IA32_L3_CBM_BASE,
 +		.min_cbm_bits	= 1,
 +		.cache_level	= 3,
 +		.cbm_idx_multi	= 2,
 +		.cbm_idx_offset	= 1
++=======
+ 		.name			= "L3CODE",
+ 		.domains		= domain_init(RDT_RESOURCE_L3CODE),
+ 		.msr_base		= IA32_L3_CBM_BASE,
+ 		.msr_update		= cat_wrmsr,
+ 		.cache_level		= 3,
+ 		.cache = {
+ 			.min_cbm_bits	= 1,
+ 			.cbm_idx_mult	= 2,
+ 			.cbm_idx_offset	= 1,
+ 		},
+ 		.parse_ctrlval		= parse_cbm,
+ 		.format_str		= "%d=%0*x",
+ 		.fflags			= RFTYPE_RES_CACHE,
++>>>>>>> 5dc1d5c6bac2 (x86/intel_rdt: Simplify info and base file lists)
  	},
 -	[RDT_RESOURCE_L2] =
  	{
++<<<<<<< HEAD
 +		.name		= "L2",
 +		.domains	= domain_init(RDT_RESOURCE_L2),
 +		.msr_base	= IA32_L2_CBM_BASE,
 +		.min_cbm_bits	= 1,
 +		.cache_level	= 2,
 +		.cbm_idx_multi	= 1,
 +		.cbm_idx_offset	= 0
++=======
+ 		.name			= "L2",
+ 		.domains		= domain_init(RDT_RESOURCE_L2),
+ 		.msr_base		= IA32_L2_CBM_BASE,
+ 		.msr_update		= cat_wrmsr,
+ 		.cache_level		= 2,
+ 		.cache = {
+ 			.min_cbm_bits	= 1,
+ 			.cbm_idx_mult	= 1,
+ 			.cbm_idx_offset	= 0,
+ 		},
+ 		.parse_ctrlval		= parse_cbm,
+ 		.format_str		= "%d=%0*x",
+ 		.fflags			= RFTYPE_RES_CACHE,
+ 	},
+ 	[RDT_RESOURCE_MBA] =
+ 	{
+ 		.name			= "MB",
+ 		.domains		= domain_init(RDT_RESOURCE_MBA),
+ 		.msr_base		= IA32_MBA_THRTL_BASE,
+ 		.msr_update		= mba_wrmsr,
+ 		.cache_level		= 3,
+ 		.parse_ctrlval		= parse_bw,
+ 		.format_str		= "%d=%*d",
+ 		.fflags			= RFTYPE_RES_MB,
++>>>>>>> 5dc1d5c6bac2 (x86/intel_rdt: Simplify info and base file lists)
  	},
  };
  
@@@ -136,19 -198,66 +211,78 @@@ static inline bool cache_alloc_hsw_prob
  	return false;
  }
  
++<<<<<<< HEAD
 +static void rdt_get_config(int idx, struct rdt_resource *r)
++=======
+ /*
+  * rdt_get_mb_table() - get a mapping of bandwidth(b/w) percentage values
+  * exposed to user interface and the h/w understandable delay values.
+  *
+  * The non-linear delay values have the granularity of power of two
+  * and also the h/w does not guarantee a curve for configured delay
+  * values vs. actual b/w enforced.
+  * Hence we need a mapping that is pre calibrated so the user can
+  * express the memory b/w as a percentage value.
+  */
+ static inline bool rdt_get_mb_table(struct rdt_resource *r)
+ {
+ 	/*
+ 	 * There are no Intel SKUs as of now to support non-linear delay.
+ 	 */
+ 	pr_info("MBA b/w map not implemented for cpu:%d, model:%d",
+ 		boot_cpu_data.x86, boot_cpu_data.x86_model);
+ 
+ 	return false;
+ }
+ 
+ static bool rdt_get_mem_config(struct rdt_resource *r)
+ {
+ 	union cpuid_0x10_3_eax eax;
+ 	union cpuid_0x10_x_edx edx;
+ 	u32 ebx, ecx;
+ 
+ 	cpuid_count(0x00000010, 3, &eax.full, &ebx, &ecx, &edx.full);
+ 	r->num_closid = edx.split.cos_max + 1;
+ 	r->membw.max_delay = eax.split.max_delay + 1;
+ 	r->default_ctrl = MAX_MBA_BW;
+ 	if (ecx & MBA_IS_LINEAR) {
+ 		r->membw.delay_linear = true;
+ 		r->membw.min_bw = MAX_MBA_BW - r->membw.max_delay;
+ 		r->membw.bw_gran = MAX_MBA_BW - r->membw.max_delay;
+ 	} else {
+ 		if (!rdt_get_mb_table(r))
+ 			return false;
+ 	}
+ 	r->data_width = 3;
+ 
+ 	r->alloc_capable = true;
+ 	r->alloc_enabled = true;
+ 
+ 	return true;
+ }
+ 
+ static void rdt_get_cache_alloc_cfg(int idx, struct rdt_resource *r)
++>>>>>>> 5dc1d5c6bac2 (x86/intel_rdt: Simplify info and base file lists)
  {
  	union cpuid_0x10_1_eax eax;
 -	union cpuid_0x10_x_edx edx;
 +	union cpuid_0x10_1_edx edx;
  	u32 ebx, ecx;
  
  	cpuid_count(0x00000010, idx, &eax.full, &ebx, &ecx, &edx.full);
  	r->num_closid = edx.split.cos_max + 1;
++<<<<<<< HEAD
 +	r->cbm_len = eax.split.cbm_len + 1;
 +	r->max_cbm = BIT_MASK(eax.split.cbm_len + 1) - 1;
 +	r->data_width = (r->cbm_len + 3) / 4;
 +	r->capable = true;
 +	r->enabled = true;
++=======
+ 	r->cache.cbm_len = eax.split.cbm_len + 1;
+ 	r->default_ctrl = BIT_MASK(eax.split.cbm_len + 1) - 1;
+ 	r->data_width = (r->cache.cbm_len + 3) / 4;
+ 	r->alloc_capable = true;
+ 	r->alloc_enabled = true;
++>>>>>>> 5dc1d5c6bac2 (x86/intel_rdt: Simplify info and base file lists)
  }
  
  static void rdt_get_cdp_l3_config(int type)
diff --cc arch/x86/kernel/cpu/intel_rdt_rdtgroup.c
index 1c3603d97e9d,7627b31937e9..000000000000
--- a/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c
+++ b/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c
@@@ -539,7 -509,7 +484,11 @@@ static int rdt_min_cbm_bits_show(struc
  }
  
  /* rdtgroup information files for one cache resource. */
++<<<<<<< HEAD
 +static struct rftype res_info_files[] = {
++=======
+ static struct rftype res_common_files[] = {
++>>>>>>> 5dc1d5c6bac2 (x86/intel_rdt: Simplify info and base file lists)
  	{
  		.name		= "num_closids",
  		.mode		= 0444,
@@@ -550,20 -521,127 +500,141 @@@
  		.name		= "cbm_mask",
  		.mode		= 0444,
  		.kf_ops		= &rdtgroup_kf_single_ops,
++<<<<<<< HEAD
 +		.seq_show	= rdt_cbm_mask_show,
++=======
+ 		.seq_show	= rdt_default_ctrl_show,
+ 		.fflags		= RF_CTRL_INFO | RFTYPE_RES_CACHE,
++>>>>>>> 5dc1d5c6bac2 (x86/intel_rdt: Simplify info and base file lists)
  	},
  	{
  		.name		= "min_cbm_bits",
  		.mode		= 0444,
  		.kf_ops		= &rdtgroup_kf_single_ops,
  		.seq_show	= rdt_min_cbm_bits_show,
++<<<<<<< HEAD
 +	},
 +};
 +
 +static int rdtgroup_create_info_dir(struct kernfs_node *parent_kn)
 +{
 +	struct kernfs_node *kn_subdir;
 +	struct rdt_resource *r;
++=======
+ 		.fflags		= RF_CTRL_INFO | RFTYPE_RES_CACHE,
+ 	},
+ 	{
+ 		.name		= "min_bandwidth",
+ 		.mode		= 0444,
+ 		.kf_ops		= &rdtgroup_kf_single_ops,
+ 		.seq_show	= rdt_min_bw_show,
+ 		.fflags		= RF_CTRL_INFO | RFTYPE_RES_MB,
+ 	},
+ 	{
+ 		.name		= "bandwidth_gran",
+ 		.mode		= 0444,
+ 		.kf_ops		= &rdtgroup_kf_single_ops,
+ 		.seq_show	= rdt_bw_gran_show,
+ 		.fflags		= RF_CTRL_INFO | RFTYPE_RES_MB,
+ 	},
+ 	{
+ 		.name		= "delay_linear",
+ 		.mode		= 0444,
+ 		.kf_ops		= &rdtgroup_kf_single_ops,
+ 		.seq_show	= rdt_delay_linear_show,
+ 		.fflags		= RF_CTRL_INFO | RFTYPE_RES_MB,
+ 	},
+ 	{
+ 		.name		= "cpus",
+ 		.mode		= 0644,
+ 		.kf_ops		= &rdtgroup_kf_single_ops,
+ 		.write		= rdtgroup_cpus_write,
+ 		.seq_show	= rdtgroup_cpus_show,
+ 		.fflags		= RFTYPE_BASE,
+ 	},
+ 	{
+ 		.name		= "cpus_list",
+ 		.mode		= 0644,
+ 		.kf_ops		= &rdtgroup_kf_single_ops,
+ 		.write		= rdtgroup_cpus_write,
+ 		.seq_show	= rdtgroup_cpus_show,
+ 		.flags		= RFTYPE_FLAGS_CPUS_LIST,
+ 		.fflags		= RFTYPE_BASE,
+ 	},
+ 	{
+ 		.name		= "tasks",
+ 		.mode		= 0644,
+ 		.kf_ops		= &rdtgroup_kf_single_ops,
+ 		.write		= rdtgroup_tasks_write,
+ 		.seq_show	= rdtgroup_tasks_show,
+ 		.fflags		= RFTYPE_BASE,
+ 	},
+ 	{
+ 		.name		= "schemata",
+ 		.mode		= 0644,
+ 		.kf_ops		= &rdtgroup_kf_single_ops,
+ 		.write		= rdtgroup_schemata_write,
+ 		.seq_show	= rdtgroup_schemata_show,
+ 		.fflags		= RF_CTRL_BASE,
+ 	},
+ };
+ 
+ static int rdtgroup_add_files(struct kernfs_node *kn, unsigned long fflags)
+ {
+ 	struct rftype *rfts, *rft;
+ 	int ret, len;
+ 
+ 	rfts = res_common_files;
+ 	len = ARRAY_SIZE(res_common_files);
+ 
+ 	lockdep_assert_held(&rdtgroup_mutex);
+ 
+ 	for (rft = rfts; rft < rfts + len; rft++) {
+ 		if ((fflags & rft->fflags) == rft->fflags) {
+ 			ret = rdtgroup_add_file(kn, rft);
+ 			if (ret)
+ 				goto error;
+ 		}
+ 	}
+ 
+ 	return 0;
+ error:
+ 	pr_warn("Failed to add %s, err=%d\n", rft->name, ret);
+ 	while (--rft >= rfts) {
+ 		if ((fflags & rft->fflags) == rft->fflags)
+ 			kernfs_remove_by_name(kn, rft->name);
+ 	}
+ 	return ret;
+ }
+ 
+ static int rdtgroup_mkdir_info_resdir(struct rdt_resource *r, char *name,
+ 				      unsigned long fflags)
+ {
+ 	struct kernfs_node *kn_subdir;
+ 	int ret;
+ 
+ 	kn_subdir = kernfs_create_dir(kn_info, name,
+ 				      kn_info->mode, r);
+ 	if (IS_ERR(kn_subdir))
+ 		return PTR_ERR(kn_subdir);
+ 
+ 	kernfs_get(kn_subdir);
+ 	ret = rdtgroup_kn_set_ugid(kn_subdir);
+ 	if (ret)
+ 		return ret;
+ 
+ 	ret = rdtgroup_add_files(kn_subdir, fflags);
+ 	if (!ret)
+ 		kernfs_activate(kn_subdir);
+ 
+ 	return ret;
+ }
+ 
+ static int rdtgroup_create_info_dir(struct kernfs_node *parent_kn)
+ {
+ 	struct rdt_resource *r;
+ 	unsigned long fflags;
++>>>>>>> 5dc1d5c6bac2 (x86/intel_rdt: Simplify info and base file lists)
  	int ret;
  
  	/* create the directory */
@@@ -572,24 -650,12 +643,31 @@@
  		return PTR_ERR(kn_info);
  	kernfs_get(kn_info);
  
++<<<<<<< HEAD
 +	for_each_enabled_rdt_resource(r) {
 +		kn_subdir = kernfs_create_dir(kn_info, r->name,
 +					      kn_info->mode, r);
 +		if (IS_ERR(kn_subdir)) {
 +			ret = PTR_ERR(kn_subdir);
 +			goto out_destroy;
 +		}
 +		kernfs_get(kn_subdir);
 +		ret = rdtgroup_kn_set_ugid(kn_subdir);
 +		if (ret)
 +			goto out_destroy;
 +		ret = rdtgroup_add_files(kn_subdir, res_info_files,
 +					 ARRAY_SIZE(res_info_files));
 +		if (ret)
 +			goto out_destroy;
 +		kernfs_activate(kn_subdir);
++=======
+ 	for_each_alloc_enabled_rdt_resource(r) {
+ 		fflags =  r->fflags | RF_CTRL_INFO;
+ 		ret = rdtgroup_mkdir_info_resdir(r, r->name, fflags);
+ 		if (ret)
+ 			goto out_destroy;
++>>>>>>> 5dc1d5c6bac2 (x86/intel_rdt: Simplify info and base file lists)
  	}
- 
  	/*
  	 * This extra ref will be put in kernfs_remove() and guarantees
  	 * that @rdtgrp->kn is always accessible.
* Unmerged path arch/x86/kernel/cpu/intel_rdt.h
* Unmerged path arch/x86/kernel/cpu/intel_rdt.c
* Unmerged path arch/x86/kernel/cpu/intel_rdt.h
* Unmerged path arch/x86/kernel/cpu/intel_rdt_rdtgroup.c
