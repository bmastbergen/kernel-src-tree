net: add __sock_wfree() helper

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [net] add __sock_wfree() helper (Ivan Vecera) [1445420]
Rebuild_FUZZ: 90.91%
commit-author Eric Dumazet <edumazet@google.com>
commit 1d2077ac0165c0d173a2255e37cf4dc5033d92c7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/1d2077ac.failed

Hosts sending lot of ACK packets exhibit high sock_wfree() cost
because of cache line miss to test SOCK_USE_WRITE_QUEUE

We could move this flag close to sk_wmem_alloc but it is better
to perform the atomic_sub_and_test() on a clean cache line,
as it avoid one extra bus transaction.

skb_orphan_partial() can also have a fast track for packets that either
are TCP acks, or already went through another skb_orphan_partial()

	Signed-off-by: Eric Dumazet <edumazet@google.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 1d2077ac0165c0d173a2255e37cf4dc5033d92c7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/sock.h
#	net/core/sock.c
diff --cc include/net/sock.h
index c604e82aea2a,45f5b492c658..000000000000
--- a/include/net/sock.h
+++ b/include/net/sock.h
@@@ -1592,25 -1407,49 +1592,49 @@@ static inline void unlock_sock_fast(str
  		spin_unlock_bh(&sk->sk_lock.slock);
  }
  
 -/* Used by processes to "lock" a socket state, so that
 - * interrupts and bottom half handlers won't change it
 - * from under us. It essentially blocks any incoming
 - * packets, so that we won't get any new data or any
 - * packets that change the state of the socket.
 - *
 - * While locked, BH processing will add new packets to
 - * the backlog queue.  This queue is processed by the
 - * owner of the socket lock right before it is released.
 - *
 - * Since ~2.3.5 it is also exclusive sleep lock serializing
 - * accesses from user process context.
 - */
 -
 -static inline bool sock_owned_by_user(const struct sock *sk)
 -{
 -#ifdef CONFIG_LOCKDEP
 -	WARN_ON_ONCE(!lockdep_sock_is_held(sk) && debug_locks);
 -#endif
 -	return sk->sk_lock.owned;
 -}
  
 +extern struct sock		*sk_alloc(struct net *net, int family,
 +					  gfp_t priority,
 +					  struct proto *prot);
 +extern void			sk_free(struct sock *sk);
 +extern void			sk_release_kernel(struct sock *sk);
 +extern struct sock		*sk_clone_lock(const struct sock *sk,
 +					       const gfp_t priority);
 +
++<<<<<<< HEAD
 +extern struct sk_buff		*sock_wmalloc(struct sock *sk,
 +					      unsigned long size, int force,
 +					      gfp_t priority);
 +extern struct sk_buff		*sock_rmalloc(struct sock *sk,
 +					      unsigned long size, int force,
 +					      gfp_t priority);
 +extern void			sock_wfree(struct sk_buff *skb);
 +extern void			skb_orphan_partial(struct sk_buff *skb);
 +extern void			sock_rfree(struct sk_buff *skb);
 +extern void			sock_efree(struct sk_buff *skb);
++=======
+ /* no reclassification while locks are held */
+ static inline bool sock_allow_reclassification(const struct sock *csk)
+ {
+ 	struct sock *sk = (struct sock *)csk;
+ 
+ 	return !sk->sk_lock.owned && !spin_is_locked(&sk->sk_lock.slock);
+ }
+ 
+ struct sock *sk_alloc(struct net *net, int family, gfp_t priority,
+ 		      struct proto *prot, int kern);
+ void sk_free(struct sock *sk);
+ void sk_destruct(struct sock *sk);
+ struct sock *sk_clone_lock(const struct sock *sk, const gfp_t priority);
+ 
+ struct sk_buff *sock_wmalloc(struct sock *sk, unsigned long size, int force,
+ 			     gfp_t priority);
+ void __sock_wfree(struct sk_buff *skb);
+ void sock_wfree(struct sk_buff *skb);
+ void skb_orphan_partial(struct sk_buff *skb);
+ void sock_rfree(struct sk_buff *skb);
+ void sock_efree(struct sk_buff *skb);
++>>>>>>> 1d2077ac0165 (net: add __sock_wfree() helper)
  #ifdef CONFIG_INET
  void sock_edemux(struct sk_buff *skb);
  #else
diff --cc net/core/sock.c
index b453f6bf7361,08bf97eceeb3..000000000000
--- a/net/core/sock.c
+++ b/net/core/sock.c
@@@ -1602,8 -1655,54 +1602,57 @@@ void sock_wfree(struct sk_buff *skb
  }
  EXPORT_SYMBOL(sock_wfree);
  
++<<<<<<< HEAD
++=======
+ /* This variant of sock_wfree() is used by TCP,
+  * since it sets SOCK_USE_WRITE_QUEUE.
+  */
+ void __sock_wfree(struct sk_buff *skb)
+ {
+ 	struct sock *sk = skb->sk;
+ 
+ 	if (atomic_sub_and_test(skb->truesize, &sk->sk_wmem_alloc))
+ 		__sk_free(sk);
+ }
+ 
+ void skb_set_owner_w(struct sk_buff *skb, struct sock *sk)
+ {
+ 	skb_orphan(skb);
+ 	skb->sk = sk;
+ #ifdef CONFIG_INET
+ 	if (unlikely(!sk_fullsock(sk))) {
+ 		skb->destructor = sock_edemux;
+ 		sock_hold(sk);
+ 		return;
+ 	}
+ #endif
+ 	skb->destructor = sock_wfree;
+ 	skb_set_hash_from_sk(skb, sk);
+ 	/*
+ 	 * We used to take a refcount on sk, but following operation
+ 	 * is enough to guarantee sk_free() wont free this sock until
+ 	 * all in-flight packets are completed
+ 	 */
+ 	atomic_add(skb->truesize, &sk->sk_wmem_alloc);
+ }
+ EXPORT_SYMBOL(skb_set_owner_w);
+ 
+ /* This helper is used by netem, as it can hold packets in its
+  * delay queue. We want to allow the owner socket to send more
+  * packets, as if they were already TX completed by a typical driver.
+  * But we also want to keep skb->sk set because some packet schedulers
+  * rely on it (sch_fq for example). So we set skb->truesize to a small
+  * amount (1) and decrease sk_wmem_alloc accordingly.
+  */
++>>>>>>> 1d2077ac0165 (net: add __sock_wfree() helper)
  void skb_orphan_partial(struct sk_buff *skb)
  {
+ 	/* If this skb is a TCP pure ACK or already went here,
+ 	 * we have nothing to do. 2 is already a very small truesize.
+ 	 */
+ 	if (skb->truesize <= 2)
+ 		return;
+ 
  	/* TCP stack sets skb->ooo_okay based on sk_wmem_alloc,
  	 * so we do not completely orphan skb, but transfert all
  	 * accounted bytes but one, to avoid unexpected reorders.
* Unmerged path include/net/sock.h
* Unmerged path net/core/sock.c
diff --git a/net/ipv4/tcp_output.c b/net/ipv4/tcp_output.c
index cdc9110edc62..8b25745d21b7 100644
--- a/net/ipv4/tcp_output.c
+++ b/net/ipv4/tcp_output.c
@@ -946,7 +946,7 @@ static int tcp_transmit_skb(struct sock *sk, struct sk_buff *skb, int clone_it,
 
 	skb_orphan(skb);
 	skb->sk = sk;
-	skb->destructor = skb_is_tcp_pure_ack(skb) ? sock_wfree : tcp_wfree;
+	skb->destructor = skb_is_tcp_pure_ack(skb) ? __sock_wfree : tcp_wfree;
 	skb_set_hash_from_sk(skb, sk);
 	atomic_add(skb->truesize, &sk->sk_wmem_alloc);
 
