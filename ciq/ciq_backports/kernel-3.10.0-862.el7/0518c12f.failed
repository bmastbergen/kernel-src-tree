qed*: LL2 callback operations

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Michal Kalderon <Michal.Kalderon@cavium.com>
commit 0518c12f1f79dc2f2020836974c577404e42ae89
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/0518c12f.failed

LL2 today is interrupt driven - when tx/rx completion arrives [or any
other indication], qed needs to operate on the connection and pass
the information to the protocol-driver [or internal qed consumer].
Since we have several flavors of ll2 employeed by the driver,
each handler needs to do an if-else to determine the right functionality
to use based on the connection type.

In order to make things more scalable [given that we're going to add
additional types of ll2 flavors] move the infrastrucutre into using
a callback-based approach - the callbacks would be provided as part
of the connection's initialization parameters.

	Signed-off-by: Michal Kalderon <Michal.Kalderon@cavium.com>
	Signed-off-by: Yuval Mintz <Yuval.Mintz@cavium.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 0518c12f1f79dc2f2020836974c577404e42ae89)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/qlogic/qed/qed_ll2.c
#	drivers/net/ethernet/qlogic/qed/qed_ll2.h
#	drivers/net/ethernet/qlogic/qed/qed_roce.c
#	include/linux/qed/qed_ll2_if.h
diff --cc drivers/net/ethernet/qlogic/qed/qed_ll2.c
index b1ff824f44b2,b222b2b471e8..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_ll2.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_ll2.c
@@@ -327,21 -328,12 +328,30 @@@ static void qed_ll2_txq_flush(struct qe
  			b_last_frag =
  				p_tx->cur_completing_bd_idx == p_pkt->bd_used;
  			tx_frag = p_pkt->bds_set[0].tx_frag;
++<<<<<<< HEAD
 +			if (p_ll2_conn->conn.gsi_enable)
 +				qed_ll2b_release_tx_gsi_packet(p_hwfn,
 +							       p_ll2_conn->
 +							       my_id,
 +							       p_pkt->cookie,
 +							       tx_frag,
 +							       b_last_frag,
 +							       b_last_packet);
 +			else
 +				qed_ll2b_complete_tx_packet(p_hwfn,
 +							    p_ll2_conn->my_id,
 +							    p_pkt->cookie,
 +							    tx_frag,
 +							    b_last_frag,
 +							    b_last_packet);
++=======
+ 			p_ll2_conn->cbs.tx_release_cb(p_ll2_conn->cbs.cookie,
+ 						      p_ll2_conn->my_id,
+ 						      p_pkt->cookie,
+ 						      tx_frag,
+ 						      b_last_frag,
+ 						      b_last_packet);
++>>>>>>> 0518c12f1f79 (qed*: LL2 callback operations)
  		}
  	}
  }
@@@ -395,19 -386,13 +404,29 @@@ static int qed_ll2_txq_completion(struc
  		list_add_tail(&p_pkt->list_entry, &p_tx->free_descq);
  
  		spin_unlock_irqrestore(&p_tx->lock, flags);
++<<<<<<< HEAD
 +		tx_frag = p_pkt->bds_set[0].tx_frag;
 +		if (p_ll2_conn->conn.gsi_enable)
 +			qed_ll2b_complete_tx_gsi_packet(p_hwfn,
 +							p_ll2_conn->my_id,
 +							p_pkt->cookie,
 +							tx_frag,
 +							b_last_frag, !num_bds);
 +		else
 +			qed_ll2b_complete_tx_packet(p_hwfn,
 +						    p_ll2_conn->my_id,
 +						    p_pkt->cookie,
 +						    tx_frag,
 +						    b_last_frag, !num_bds);
++=======
+ 
+ 		p_ll2_conn->cbs.tx_comp_cb(p_ll2_conn->cbs.cookie,
+ 					   p_ll2_conn->my_id,
+ 					   p_pkt->cookie,
+ 					   p_pkt->bds_set[0].tx_frag,
+ 					   b_last_frag, !num_bds);
+ 
++>>>>>>> 0518c12f1f79 (qed*: LL2 callback operations)
  		spin_lock_irqsave(&p_tx->lock, flags);
  	}
  
@@@ -1326,18 -1139,102 +1310,110 @@@ out
  	return rc;
  }
  
++<<<<<<< HEAD
 +int qed_ll2_acquire_connection(struct qed_hwfn *p_hwfn,
 +			       struct qed_ll2_conn *p_params,
 +			       u16 rx_num_desc,
 +			       u16 tx_num_desc,
 +			       u8 *p_connection_handle)
++=======
+ static int
+ qed_ll2_acquire_connection_ooo(struct qed_hwfn *p_hwfn,
+ 			       struct qed_ll2_info *p_ll2_info, u16 mtu)
+ {
+ 	struct qed_ooo_buffer *p_buf = NULL;
+ 	void *p_virt;
+ 	u16 buf_idx;
+ 	int rc = 0;
+ 
+ 	if (p_ll2_info->input.conn_type != QED_LL2_TYPE_ISCSI_OOO)
+ 		return rc;
+ 
+ 	/* Correct number of requested OOO buffers if needed */
+ 	if (!p_ll2_info->input.rx_num_ooo_buffers) {
+ 		u16 num_desc = p_ll2_info->input.rx_num_desc;
+ 
+ 		if (!num_desc)
+ 			return -EINVAL;
+ 		p_ll2_info->input.rx_num_ooo_buffers = num_desc * 2;
+ 	}
+ 
+ 	for (buf_idx = 0; buf_idx < p_ll2_info->input.rx_num_ooo_buffers;
+ 	     buf_idx++) {
+ 		p_buf = kzalloc(sizeof(*p_buf), GFP_KERNEL);
+ 		if (!p_buf) {
+ 			rc = -ENOMEM;
+ 			goto out;
+ 		}
+ 
+ 		p_buf->rx_buffer_size = mtu + 26 + ETH_CACHE_LINE_SIZE;
+ 		p_buf->rx_buffer_size = (p_buf->rx_buffer_size +
+ 					 ETH_CACHE_LINE_SIZE - 1) &
+ 					~(ETH_CACHE_LINE_SIZE - 1);
+ 		p_virt = dma_alloc_coherent(&p_hwfn->cdev->pdev->dev,
+ 					    p_buf->rx_buffer_size,
+ 					    &p_buf->rx_buffer_phys_addr,
+ 					    GFP_KERNEL);
+ 		if (!p_virt) {
+ 			kfree(p_buf);
+ 			rc = -ENOMEM;
+ 			goto out;
+ 		}
+ 
+ 		p_buf->rx_buffer_virt_addr = p_virt;
+ 		qed_ooo_put_free_buffer(p_hwfn, p_hwfn->p_ooo_info, p_buf);
+ 	}
+ 
+ 	DP_VERBOSE(p_hwfn, QED_MSG_LL2,
+ 		   "Allocated [%04x] LL2 OOO buffers [each of size 0x%08x]\n",
+ 		   p_ll2_info->input.rx_num_ooo_buffers, p_buf->rx_buffer_size);
+ 
+ out:
+ 	return rc;
+ }
+ 
+ static int
+ qed_ll2_set_cbs(struct qed_ll2_info *p_ll2_info, const struct qed_ll2_cbs *cbs)
+ {
+ 	if (!cbs || (!cbs->rx_comp_cb ||
+ 		     !cbs->rx_release_cb ||
+ 		     !cbs->tx_comp_cb || !cbs->tx_release_cb || !cbs->cookie))
+ 		return -EINVAL;
+ 
+ 	p_ll2_info->cbs.rx_comp_cb = cbs->rx_comp_cb;
+ 	p_ll2_info->cbs.rx_release_cb = cbs->rx_release_cb;
+ 	p_ll2_info->cbs.tx_comp_cb = cbs->tx_comp_cb;
+ 	p_ll2_info->cbs.tx_release_cb = cbs->tx_release_cb;
+ 	p_ll2_info->cbs.cookie = cbs->cookie;
+ 
+ 	return 0;
+ }
+ 
+ static enum core_error_handle
+ qed_ll2_get_error_choice(enum qed_ll2_error_handle err)
  {
+ 	switch (err) {
+ 	case QED_LL2_DROP_PACKET:
+ 		return LL2_DROP_PACKET;
+ 	case QED_LL2_DO_NOTHING:
+ 		return LL2_DO_NOTHING;
+ 	case QED_LL2_ASSERT:
+ 		return LL2_ASSERT;
+ 	default:
+ 		return LL2_DO_NOTHING;
+ 	}
+ }
+ 
+ int qed_ll2_acquire_connection(void *cxt, struct qed_ll2_acquire_data *data)
++>>>>>>> 0518c12f1f79 (qed*: LL2 callback operations)
+ {
+ 	struct qed_hwfn *p_hwfn = cxt;
  	qed_int_comp_cb_t comp_rx_cb, comp_tx_cb;
  	struct qed_ll2_info *p_ll2_info = NULL;
 -	u8 i, *p_tx_max;
  	int rc;
 +	u8 i;
  
 -	if (!data->p_connection_handle || !p_hwfn->p_ll2_info)
 +	if (!p_connection_handle || !p_hwfn->p_ll2_info)
  		return -EINVAL;
  
  	/* Find a free connection to be used */
@@@ -1356,9 -1253,26 +1432,30 @@@
  	if (!p_ll2_info)
  		return -EBUSY;
  
 -	memcpy(&p_ll2_info->input, &data->input, sizeof(p_ll2_info->input));
 +	p_ll2_info->conn = *p_params;
  
++<<<<<<< HEAD
 +	rc = qed_ll2_acquire_connection_rx(p_hwfn, p_ll2_info, rx_num_desc);
++=======
+ 	p_ll2_info->tx_dest = (data->input.tx_dest == QED_LL2_TX_DEST_NW) ?
+ 			      CORE_TX_DEST_NW : CORE_TX_DEST_LB;
+ 
+ 	/* Correct maximum number of Tx BDs */
+ 	p_tx_max = &p_ll2_info->input.tx_max_bds_per_packet;
+ 	if (*p_tx_max == 0)
+ 		*p_tx_max = CORE_LL2_TX_MAX_BDS_PER_PACKET;
+ 	else
+ 		*p_tx_max = min_t(u8, *p_tx_max,
+ 				  CORE_LL2_TX_MAX_BDS_PER_PACKET);
+ 
+ 	rc = qed_ll2_set_cbs(p_ll2_info, data->cbs);
+ 	if (rc) {
+ 		DP_NOTICE(p_hwfn, "Invalid callback functions\n");
+ 		goto q_allocate_fail;
+ 	}
+ 
+ 	rc = qed_ll2_acquire_connection_rx(p_hwfn, p_ll2_info);
++>>>>>>> 0518c12f1f79 (qed*: LL2 callback operations)
  	if (rc)
  		goto q_allocate_fail;
  
@@@ -1424,8 -1341,20 +1521,24 @@@ static int qed_ll2_establish_connection
  	return qed_sp_ll2_rx_queue_start(p_hwfn, p_ll2_conn, action_on_error);
  }
  
++<<<<<<< HEAD
 +int qed_ll2_establish_connection(struct qed_hwfn *p_hwfn, u8 connection_handle)
++=======
+ static void
+ qed_ll2_establish_connection_ooo(struct qed_hwfn *p_hwfn,
+ 				 struct qed_ll2_info *p_ll2_conn)
+ {
+ 	if (p_ll2_conn->input.conn_type != QED_LL2_TYPE_ISCSI_OOO)
+ 		return;
+ 
+ 	qed_ooo_release_all_isles(p_hwfn, p_hwfn->p_ooo_info);
+ 	qed_ooo_submit_rx_buffers(p_hwfn, p_ll2_conn);
+ }
+ 
+ int qed_ll2_establish_connection(void *cxt, u8 connection_handle)
++>>>>>>> 0518c12f1f79 (qed*: LL2 callback operations)
  {
+ 	struct qed_hwfn *p_hwfn = cxt;
  	struct qed_ll2_info *p_ll2_conn;
  	struct qed_ll2_rx_queue *p_rx;
  	struct qed_ll2_tx_queue *p_tx;
@@@ -1742,10 -1672,11 +1856,10 @@@ static void qed_ll2_tx_packet_notify(st
  		   (NETIF_MSG_TX_QUEUED | QED_MSG_LL2),
  		   "LL2 [q 0x%02x cid 0x%08x type 0x%08x] Doorbelled [producer 0x%04x]\n",
  		   p_ll2_conn->queue_id,
 -		   p_ll2_conn->cid,
 -		   p_ll2_conn->input.conn_type, db_msg.spq_prod);
 +		   p_ll2_conn->cid, p_ll2_conn->conn.conn_type, db_msg.spq_prod);
  }
  
- int qed_ll2_prepare_tx_packet(struct qed_hwfn *p_hwfn,
+ int qed_ll2_prepare_tx_packet(void *cxt,
  			      u8 connection_handle,
  			      struct qed_ll2_tx_pkt_info *pkt,
  			      bool notify_fw)
@@@ -1883,8 -1817,28 +2000,32 @@@ out
  	return rc;
  }
  
++<<<<<<< HEAD
 +void qed_ll2_release_connection(struct qed_hwfn *p_hwfn, u8 connection_handle)
++=======
+ static void qed_ll2_release_connection_ooo(struct qed_hwfn *p_hwfn,
+ 					   struct qed_ll2_info *p_ll2_conn)
+ {
+ 	struct qed_ooo_buffer *p_buffer;
+ 
+ 	if (p_ll2_conn->input.conn_type != QED_LL2_TYPE_ISCSI_OOO)
+ 		return;
+ 
+ 	qed_ooo_release_all_isles(p_hwfn, p_hwfn->p_ooo_info);
+ 	while ((p_buffer = qed_ooo_get_free_buffer(p_hwfn,
+ 						   p_hwfn->p_ooo_info))) {
+ 		dma_free_coherent(&p_hwfn->cdev->pdev->dev,
+ 				  p_buffer->rx_buffer_size,
+ 				  p_buffer->rx_buffer_virt_addr,
+ 				  p_buffer->rx_buffer_phys_addr);
+ 		kfree(p_buffer);
+ 	}
+ }
+ 
+ void qed_ll2_release_connection(void *cxt, u8 connection_handle)
++>>>>>>> 0518c12f1f79 (qed*: LL2 callback operations)
  {
+ 	struct qed_hwfn *p_hwfn = cxt;
  	struct qed_ll2_info *p_ll2_conn = NULL;
  
  	p_ll2_conn = qed_ll2_handle_sanity(p_hwfn, connection_handle);
@@@ -2054,14 -2020,80 +2207,83 @@@ static void qed_ll2_register_cb_ops(str
  	cdev->ll2->cb_cookie = cookie;
  }
  
++<<<<<<< HEAD
++=======
+ struct qed_ll2_cbs ll2_cbs = {
+ 	.rx_comp_cb = &qed_ll2b_complete_rx_packet,
+ 	.rx_release_cb = &qed_ll2b_release_rx_packet,
+ 	.tx_comp_cb = &qed_ll2b_complete_tx_packet,
+ 	.tx_release_cb = &qed_ll2b_complete_tx_packet,
+ };
+ 
+ static void qed_ll2_set_conn_data(struct qed_dev *cdev,
+ 				  struct qed_ll2_acquire_data *data,
+ 				  struct qed_ll2_params *params,
+ 				  enum qed_ll2_conn_type conn_type,
+ 				  u8 *handle, bool lb)
+ {
+ 	memset(data, 0, sizeof(*data));
+ 
+ 	data->input.conn_type = conn_type;
+ 	data->input.mtu = params->mtu;
+ 	data->input.rx_num_desc = QED_LL2_RX_SIZE;
+ 	data->input.rx_drop_ttl0_flg = params->drop_ttl0_packets;
+ 	data->input.rx_vlan_removal_en = params->rx_vlan_stripping;
+ 	data->input.tx_num_desc = QED_LL2_TX_SIZE;
+ 	data->p_connection_handle = handle;
+ 	data->cbs = &ll2_cbs;
+ 	ll2_cbs.cookie = QED_LEADING_HWFN(cdev);
+ 
+ 	if (lb) {
+ 		data->input.tx_tc = OOO_LB_TC;
+ 		data->input.tx_dest = QED_LL2_TX_DEST_LB;
+ 	} else {
+ 		data->input.tx_tc = 0;
+ 		data->input.tx_dest = QED_LL2_TX_DEST_NW;
+ 	}
+ }
+ 
+ static int qed_ll2_start_ooo(struct qed_dev *cdev,
+ 			     struct qed_ll2_params *params)
+ {
+ 	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
+ 	u8 *handle = &hwfn->pf_params.iscsi_pf_params.ll2_ooo_queue_id;
+ 	struct qed_ll2_acquire_data data;
+ 	int rc;
+ 
+ 	qed_ll2_set_conn_data(cdev, &data, params,
+ 			      QED_LL2_TYPE_ISCSI_OOO, handle, true);
+ 
+ 	rc = qed_ll2_acquire_connection(hwfn, &data);
+ 	if (rc) {
+ 		DP_INFO(cdev, "Failed to acquire LL2 OOO connection\n");
+ 		goto out;
+ 	}
+ 
+ 	rc = qed_ll2_establish_connection(hwfn, *handle);
+ 	if (rc) {
+ 		DP_INFO(cdev, "Failed to establist LL2 OOO connection\n");
+ 		goto fail;
+ 	}
+ 
+ 	return 0;
+ 
+ fail:
+ 	qed_ll2_release_connection(hwfn, *handle);
+ out:
+ 	*handle = QED_LL2_UNUSED_HANDLE;
+ 	return rc;
+ }
+ 
++>>>>>>> 0518c12f1f79 (qed*: LL2 callback operations)
  static int qed_ll2_start(struct qed_dev *cdev, struct qed_ll2_params *params)
  {
 +	struct qed_ll2_conn ll2_info;
  	struct qed_ll2_buffer *buffer, *tmp_buffer;
  	enum qed_ll2_conn_type conn_type;
 -	struct qed_ll2_acquire_data data;
  	struct qed_ptt *p_ptt;
  	int rc, i;
- 	u8 gsi_enable = 1;
+ 
  
  	/* Initialize LL2 locks & lists */
  	INIT_LIST_HEAD(&cdev->ll2->list);
@@@ -2106,20 -2136,10 +2326,25 @@@
  		conn_type = QED_LL2_TYPE_TEST;
  	}
  
++<<<<<<< HEAD
 +	/* Prepare the temporary ll2 information */
 +	memset(&ll2_info, 0, sizeof(ll2_info));
++=======
+ 	qed_ll2_set_conn_data(cdev, &data, params, conn_type,
+ 			      &cdev->ll2->handle, false);
 -
 -	rc = qed_ll2_acquire_connection(QED_LEADING_HWFN(cdev), &data);
++>>>>>>> 0518c12f1f79 (qed*: LL2 callback operations)
 +
 +	ll2_info.conn_type = conn_type;
 +	ll2_info.mtu = params->mtu;
 +	ll2_info.rx_drop_ttl0_flg = params->drop_ttl0_packets;
 +	ll2_info.rx_vlan_removal_en = params->rx_vlan_stripping;
 +	ll2_info.tx_tc = 0;
 +	ll2_info.tx_dest = CORE_TX_DEST_NW;
 +	ll2_info.gsi_enable = gsi_enable;
 +
 +	rc = qed_ll2_acquire_connection(QED_LEADING_HWFN(cdev), &ll2_info,
 +					QED_LL2_RX_SIZE, QED_LL2_TX_SIZE,
 +					&cdev->ll2->handle);
  	if (rc) {
  		DP_INFO(cdev, "Failed to acquire LL2 connection\n");
  		goto fail;
diff --cc drivers/net/ethernet/qlogic/qed/qed_ll2.h
index 96af50b733e8,a822528e9c63..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_ll2.h
+++ b/drivers/net/ethernet/qlogic/qed/qed_ll2.h
@@@ -154,20 -134,12 +155,29 @@@ struct qed_ll2_info 
   *        starts rx & tx (if relevant) queues pair. Provides
   *        connecion handler as output parameter.
   *
++<<<<<<< HEAD
 + * @param p_hwfn
 + * @param p_params		Contain various configuration properties
 + * @param rx_num_desc
 + * @param tx_num_desc
 + *
 + * @param p_connection_handle  Output container for LL2 connection's handle
 + *
 + * @return 0 on success, failure otherwise
 + */
 +int qed_ll2_acquire_connection(struct qed_hwfn *p_hwfn,
 +			       struct qed_ll2_conn *p_params,
 +			       u16 rx_num_desc,
 +			       u16 tx_num_desc,
 +			       u8 *p_connection_handle);
++=======
+  *
+  * @param cxt - pointer to the hw-function [opaque to some]
+  * @param data - describes connection parameters
+  * @return int
+  */
+ int qed_ll2_acquire_connection(void *cxt, struct qed_ll2_acquire_data *data);
++>>>>>>> 0518c12f1f79 (qed*: LL2 callback operations)
  
  /**
   * @brief qed_ll2_establish_connection - start previously
diff --cc drivers/net/ethernet/qlogic/qed/qed_roce.c
index 92968ecf3bc4,4bc2f6c47f69..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_roce.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_roce.c
@@@ -2816,205 -2738,6 +2741,208 @@@ static int qed_roce_ll2_set_mac_filter(
  	return rc;
  }
  
++<<<<<<< HEAD
 +static int qed_roce_ll2_start(struct qed_dev *cdev,
 +			      struct qed_roce_ll2_params *params)
 +{
 +	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
 +	struct qed_roce_ll2_info *roce_ll2;
 +	struct qed_ll2_conn ll2_params;
 +	int rc;
 +
 +	if (!params) {
 +		DP_ERR(cdev, "qed roce ll2 start: failed due to NULL params\n");
 +		return -EINVAL;
 +	}
 +	if (!params->cbs.tx_cb || !params->cbs.rx_cb) {
 +		DP_ERR(cdev,
 +		       "qed roce ll2 start: failed due to NULL tx/rx. tx_cb=%p, rx_cb=%p\n",
 +		       params->cbs.tx_cb, params->cbs.rx_cb);
 +		return -EINVAL;
 +	}
 +	if (!is_valid_ether_addr(params->mac_address)) {
 +		DP_ERR(cdev,
 +		       "qed roce ll2 start: failed due to invalid Ethernet address %pM\n",
 +		       params->mac_address);
 +		return -EINVAL;
 +	}
 +
 +	/* Initialize */
 +	roce_ll2 = kzalloc(sizeof(*roce_ll2), GFP_ATOMIC);
 +	if (!roce_ll2) {
 +		DP_ERR(cdev, "qed roce ll2 start: failed memory allocation\n");
 +		return -ENOMEM;
 +	}
 +	roce_ll2->handle = QED_LL2_UNUSED_HANDLE;
 +	roce_ll2->cbs = params->cbs;
 +	roce_ll2->cb_cookie = params->cb_cookie;
 +	mutex_init(&roce_ll2->lock);
 +
 +	memset(&ll2_params, 0, sizeof(ll2_params));
 +	ll2_params.conn_type = QED_LL2_TYPE_ROCE;
 +	ll2_params.mtu = params->mtu;
 +	ll2_params.rx_drop_ttl0_flg = true;
 +	ll2_params.rx_vlan_removal_en = false;
 +	ll2_params.tx_dest = CORE_TX_DEST_NW;
 +	ll2_params.ai_err_packet_too_big = LL2_DROP_PACKET;
 +	ll2_params.ai_err_no_buf = LL2_DROP_PACKET;
 +	ll2_params.gsi_enable = true;
 +
 +	rc = qed_ll2_acquire_connection(QED_LEADING_HWFN(cdev), &ll2_params,
 +					params->max_rx_buffers,
 +					params->max_tx_buffers,
 +					&roce_ll2->handle);
 +	if (rc) {
 +		DP_ERR(cdev,
 +		       "qed roce ll2 start: failed to acquire LL2 connection (rc=%d)\n",
 +		       rc);
 +		goto err;
 +	}
 +
 +	rc = qed_ll2_establish_connection(QED_LEADING_HWFN(cdev),
 +					  roce_ll2->handle);
 +	if (rc) {
 +		DP_ERR(cdev,
 +		       "qed roce ll2 start: failed to establish LL2 connection (rc=%d)\n",
 +		       rc);
 +		goto err1;
 +	}
 +
 +	hwfn->ll2 = roce_ll2;
 +
 +	rc = qed_roce_ll2_set_mac_filter(cdev, NULL, params->mac_address);
 +	if (rc) {
 +		hwfn->ll2 = NULL;
 +		goto err2;
 +	}
 +	ether_addr_copy(roce_ll2->mac_address, params->mac_address);
 +
 +	return 0;
 +
 +err2:
 +	qed_ll2_terminate_connection(QED_LEADING_HWFN(cdev), roce_ll2->handle);
 +err1:
 +	qed_ll2_release_connection(QED_LEADING_HWFN(cdev), roce_ll2->handle);
 +err:
 +	kfree(roce_ll2);
 +	return rc;
 +}
 +
 +static int qed_roce_ll2_stop(struct qed_dev *cdev)
 +{
 +	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
 +	struct qed_roce_ll2_info *roce_ll2 = hwfn->ll2;
 +	int rc;
 +
 +	if (roce_ll2->handle == QED_LL2_UNUSED_HANDLE) {
 +		DP_ERR(cdev, "qed roce ll2 stop: cannot stop an unused LL2\n");
 +		return -EINVAL;
 +	}
 +
 +	/* remove LL2 MAC address filter */
 +	rc = qed_roce_ll2_set_mac_filter(cdev, roce_ll2->mac_address, NULL);
 +	eth_zero_addr(roce_ll2->mac_address);
 +
 +	rc = qed_ll2_terminate_connection(QED_LEADING_HWFN(cdev),
 +					  roce_ll2->handle);
 +	if (rc)
 +		DP_ERR(cdev,
 +		       "qed roce ll2 stop: failed to terminate LL2 connection (rc=%d)\n",
 +		       rc);
 +
 +	qed_ll2_release_connection(QED_LEADING_HWFN(cdev), roce_ll2->handle);
 +
 +	roce_ll2->handle = QED_LL2_UNUSED_HANDLE;
 +
 +	kfree(roce_ll2);
 +
 +	return rc;
 +}
 +
 +static int qed_roce_ll2_tx(struct qed_dev *cdev,
 +			   struct qed_roce_ll2_packet *pkt,
 +			   struct qed_roce_ll2_tx_params *params)
 +{
 +	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
 +	struct qed_roce_ll2_info *roce_ll2 = hwfn->ll2;
 +	enum qed_ll2_roce_flavor_type qed_roce_flavor;
 +	struct qed_ll2_tx_pkt_info ll2_pkt;
 +	u8 flags = 0;
 +	int rc;
 +	int i;
 +
 +	if (!pkt || !params) {
 +		DP_ERR(cdev,
 +		       "roce ll2 tx: failed tx because one of the following is NULL - drv=%p, pkt=%p, params=%p\n",
 +		       cdev, pkt, params);
 +		return -EINVAL;
 +	}
 +
 +	qed_roce_flavor = (pkt->roce_mode == ROCE_V1) ? QED_LL2_ROCE
 +						      : QED_LL2_RROCE;
 +
 +	if (pkt->roce_mode == ROCE_V2_IPV4)
 +		flags |= BIT(CORE_TX_BD_DATA_IP_CSUM_SHIFT);
 +
 +	/* Tx header */
 +	memset(&ll2_pkt, 0, sizeof(ll2_pkt));
 +	ll2_pkt.num_of_bds = 1 + pkt->n_seg;
 +	ll2_pkt.bd_flags = flags;
 +	ll2_pkt.tx_dest = QED_LL2_TX_DEST_NW;
 +	ll2_pkt.qed_roce_flavor = qed_roce_flavor;
 +	ll2_pkt.first_frag = pkt->header.baddr;
 +	ll2_pkt.first_frag_len = pkt->header.len;
 +	ll2_pkt.cookie = pkt;
 +
 +	rc = qed_ll2_prepare_tx_packet(QED_LEADING_HWFN(cdev),
 +				       roce_ll2->handle,
 +				       &ll2_pkt, 1);
 +	if (rc) {
 +		DP_ERR(cdev, "roce ll2 tx: header failed (rc=%d)\n", rc);
 +		return QED_ROCE_TX_HEAD_FAILURE;
 +	}
 +
 +	/* Tx payload */
 +	for (i = 0; i < pkt->n_seg; i++) {
 +		rc = qed_ll2_set_fragment_of_tx_packet(QED_LEADING_HWFN(cdev),
 +						       roce_ll2->handle,
 +						       pkt->payload[i].baddr,
 +						       pkt->payload[i].len);
 +		if (rc) {
 +			/* If failed not much to do here, partial packet has
 +			 * been posted * we can't free memory, will need to wait
 +			 * for completion
 +			 */
 +			DP_ERR(cdev,
 +			       "roce ll2 tx: payload failed (rc=%d)\n", rc);
 +			return QED_ROCE_TX_FRAG_FAILURE;
 +		}
 +	}
 +
 +	return 0;
 +}
 +
 +static int qed_roce_ll2_post_rx_buffer(struct qed_dev *cdev,
 +				       struct qed_roce_ll2_buffer *buf,
 +				       u64 cookie, u8 notify_fw)
 +{
 +	return qed_ll2_post_rx_buffer(QED_LEADING_HWFN(cdev),
 +				      QED_LEADING_HWFN(cdev)->ll2->handle,
 +				      buf->baddr, buf->len,
 +				      (void *)(uintptr_t)cookie, notify_fw);
 +}
 +
 +static int qed_roce_ll2_stats(struct qed_dev *cdev, struct qed_ll2_stats *stats)
 +{
 +	struct qed_hwfn *hwfn = QED_LEADING_HWFN(cdev);
 +	struct qed_roce_ll2_info *roce_ll2 = hwfn->ll2;
 +
 +	return qed_ll2_get_stats(QED_LEADING_HWFN(cdev),
 +				 roce_ll2->handle, stats);
 +}
 +
++=======
++>>>>>>> 0518c12f1f79 (qed*: LL2 callback operations)
  static const struct qed_rdma_ops qed_rdma_ops_pass = {
  	.common = &qed_common_ops_pass,
  	.fill_dev_info = &qed_fill_rdma_dev_info,
diff --cc include/linux/qed/qed_ll2_if.h
index 056ac007dd12,5958b45eb699..000000000000
--- a/include/linux/qed/qed_ll2_if.h
+++ b/include/linux/qed/qed_ll2_if.h
@@@ -105,6 -122,64 +105,67 @@@ struct qed_ll2_comp_rx_data 
  	} u;
  };
  
++<<<<<<< HEAD
++=======
+ typedef
+ void (*qed_ll2_complete_rx_packet_cb)(void *cxt,
+ 				      struct qed_ll2_comp_rx_data *data);
+ 
+ typedef
+ void (*qed_ll2_release_rx_packet_cb)(void *cxt,
+ 				     u8 connection_handle,
+ 				     void *cookie,
+ 				     dma_addr_t rx_buf_addr,
+ 				     bool b_last_packet);
+ 
+ typedef
+ void (*qed_ll2_complete_tx_packet_cb)(void *cxt,
+ 				      u8 connection_handle,
+ 				      void *cookie,
+ 				      dma_addr_t first_frag_addr,
+ 				      bool b_last_fragment,
+ 				      bool b_last_packet);
+ 
+ typedef
+ void (*qed_ll2_release_tx_packet_cb)(void *cxt,
+ 				     u8 connection_handle,
+ 				     void *cookie,
+ 				     dma_addr_t first_frag_addr,
+ 				     bool b_last_fragment, bool b_last_packet);
+ 
+ struct qed_ll2_cbs {
+ 	qed_ll2_complete_rx_packet_cb rx_comp_cb;
+ 	qed_ll2_release_rx_packet_cb rx_release_cb;
+ 	qed_ll2_complete_tx_packet_cb tx_comp_cb;
+ 	qed_ll2_release_tx_packet_cb tx_release_cb;
+ 	void *cookie;
+ };
+ 
+ struct qed_ll2_acquire_data_inputs {
+ 	enum qed_ll2_conn_type conn_type;
+ 	u16 mtu;
+ 	u16 rx_num_desc;
+ 	u16 rx_num_ooo_buffers;
+ 	u8 rx_drop_ttl0_flg;
+ 	u8 rx_vlan_removal_en;
+ 	u16 tx_num_desc;
+ 	u8 tx_max_bds_per_packet;
+ 	u8 tx_tc;
+ 	enum qed_ll2_tx_dest tx_dest;
+ 	enum qed_ll2_error_handle ai_err_packet_too_big;
+ 	enum qed_ll2_error_handle ai_err_no_buf;
+ 	u8 gsi_enable;
+ };
+ 
+ struct qed_ll2_acquire_data {
+ 	struct qed_ll2_acquire_data_inputs input;
+ 	const struct qed_ll2_cbs *cbs;
+ 
+ 	/* Output container for LL2 connection's handle */
+ 	u8 *p_connection_handle;
+ };
+ 
++>>>>>>> 0518c12f1f79 (qed*: LL2 callback operations)
  struct qed_ll2_tx_pkt_info {
  	void *cookie;
  	dma_addr_t first_frag;
diff --git a/drivers/infiniband/hw/qedr/main.c b/drivers/infiniband/hw/qedr/main.c
index ef11e770f822..a9c5d47cffdb 100644
--- a/drivers/infiniband/hw/qedr/main.c
+++ b/drivers/infiniband/hw/qedr/main.c
@@ -885,9 +885,9 @@ static void qedr_mac_address_change(struct qedr_dev *dev)
 	memcpy(&sgid->raw[8], guid, sizeof(guid));
 
 	/* Update LL2 */
-	rc = dev->ops->roce_ll2_set_mac_filter(dev->cdev,
-					       dev->gsi_ll2_mac_address,
-					       dev->ndev->dev_addr);
+	rc = dev->ops->ll2_set_mac_filter(dev->cdev,
+					  dev->gsi_ll2_mac_address,
+					  dev->ndev->dev_addr);
 
 	ether_addr_copy(dev->gsi_ll2_mac_address, dev->ndev->dev_addr);
 
diff --git a/drivers/infiniband/hw/qedr/qedr.h b/drivers/infiniband/hw/qedr/qedr.h
index bf02ae4c8891..cbf64f2d0044 100644
--- a/drivers/infiniband/hw/qedr/qedr.h
+++ b/drivers/infiniband/hw/qedr/qedr.h
@@ -150,6 +150,8 @@ struct qedr_dev {
 	u32			dp_module;
 	u8			dp_level;
 	u8			num_hwfns;
+	u8			gsi_ll2_handle;
+
 	uint			wq_multiplier;
 	u8			gsi_ll2_mac_address[ETH_ALEN];
 	int			gsi_qp_created;
diff --git a/drivers/infiniband/hw/qedr/qedr_cm.c b/drivers/infiniband/hw/qedr/qedr_cm.c
index 54568c16e682..6e6bed407264 100644
--- a/drivers/infiniband/hw/qedr/qedr_cm.c
+++ b/drivers/infiniband/hw/qedr/qedr_cm.c
@@ -64,9 +64,14 @@ void qedr_store_gsi_qp_cq(struct qedr_dev *dev, struct qedr_qp *qp,
 	dev->gsi_qp = qp;
 }
 
-void qedr_ll2_tx_cb(void *_qdev, struct qed_roce_ll2_packet *pkt)
+void qedr_ll2_complete_tx_packet(void *cxt,
+				 u8 connection_handle,
+				 void *cookie,
+				 dma_addr_t first_frag_addr,
+				 bool b_last_fragment, bool b_last_packet)
 {
-	struct qedr_dev *dev = (struct qedr_dev *)_qdev;
+	struct qedr_dev *dev = (struct qedr_dev *)cxt;
+	struct qed_roce_ll2_packet *pkt = cookie;
 	struct qedr_cq *cq = dev->gsi_sqcq;
 	struct qedr_qp *qp = dev->gsi_qp;
 	unsigned long flags;
@@ -88,20 +93,26 @@ void qedr_ll2_tx_cb(void *_qdev, struct qed_roce_ll2_packet *pkt)
 		(*cq->ibcq.comp_handler) (&cq->ibcq, cq->ibcq.cq_context);
 }
 
-void qedr_ll2_rx_cb(void *_dev, struct qed_roce_ll2_packet *pkt,
-		    struct qed_roce_ll2_rx_params *params)
+void qedr_ll2_complete_rx_packet(void *cxt,
+				 struct qed_ll2_comp_rx_data *data)
 {
-	struct qedr_dev *dev = (struct qedr_dev *)_dev;
+	struct qedr_dev *dev = (struct qedr_dev *)cxt;
 	struct qedr_cq *cq = dev->gsi_rqcq;
 	struct qedr_qp *qp = dev->gsi_qp;
 	unsigned long flags;
 
 	spin_lock_irqsave(&qp->q_lock, flags);
 
-	qp->rqe_wr_id[qp->rq.gsi_cons].rc = params->rc;
-	qp->rqe_wr_id[qp->rq.gsi_cons].vlan_id = params->vlan_id;
-	qp->rqe_wr_id[qp->rq.gsi_cons].sg_list[0].length = pkt->payload[0].len;
-	ether_addr_copy(qp->rqe_wr_id[qp->rq.gsi_cons].smac, params->smac);
+	qp->rqe_wr_id[qp->rq.gsi_cons].rc = data->u.data_length_error ?
+		-EINVAL : 0;
+	qp->rqe_wr_id[qp->rq.gsi_cons].vlan_id = data->vlan;
+	/* note: length stands for data length i.e. GRH is excluded */
+	qp->rqe_wr_id[qp->rq.gsi_cons].sg_list[0].length =
+		data->length.data_length;
+	*((u32 *)&qp->rqe_wr_id[qp->rq.gsi_cons].smac[0]) =
+		ntohl(data->opaque_data_0);
+	*((u16 *)&qp->rqe_wr_id[qp->rq.gsi_cons].smac[4]) =
+		ntohs((u16)data->opaque_data_1);
 
 	qedr_inc_sw_gsi_cons(&qp->rq);
 
@@ -111,6 +122,14 @@ void qedr_ll2_rx_cb(void *_dev, struct qed_roce_ll2_packet *pkt,
 		(*cq->ibcq.comp_handler) (&cq->ibcq, cq->ibcq.cq_context);
 }
 
+void qedr_ll2_release_rx_packet(void *cxt,
+				u8 connection_handle,
+				void *cookie,
+				dma_addr_t rx_buf_addr, bool b_last_packet)
+{
+	/* Do nothing... */
+}
+
 static void qedr_destroy_gsi_cq(struct qedr_dev *dev,
 				struct ib_qp_init_attr *attrs)
 {
@@ -159,27 +178,159 @@ static inline int qedr_check_gsi_qp_attrs(struct qedr_dev *dev,
 	return 0;
 }
 
+static int qedr_ll2_post_tx(struct qedr_dev *dev,
+			    struct qed_roce_ll2_packet *pkt)
+{
+	enum qed_ll2_roce_flavor_type roce_flavor;
+	struct qed_ll2_tx_pkt_info ll2_tx_pkt;
+	int rc;
+	int i;
+
+	memset(&ll2_tx_pkt, 0, sizeof(ll2_tx_pkt));
+
+	roce_flavor = (pkt->roce_mode == ROCE_V1) ?
+	    QED_LL2_ROCE : QED_LL2_RROCE;
+
+	if (pkt->roce_mode == ROCE_V2_IPV4)
+		ll2_tx_pkt.enable_ip_cksum = 1;
+
+	ll2_tx_pkt.num_of_bds = 1 /* hdr */  + pkt->n_seg;
+	ll2_tx_pkt.vlan = 0;
+	ll2_tx_pkt.tx_dest = pkt->tx_dest;
+	ll2_tx_pkt.qed_roce_flavor = roce_flavor;
+	ll2_tx_pkt.first_frag = pkt->header.baddr;
+	ll2_tx_pkt.first_frag_len = pkt->header.len;
+	ll2_tx_pkt.cookie = pkt;
+
+	/* tx header */
+	rc = dev->ops->ll2_prepare_tx_packet(dev->rdma_ctx,
+					     dev->gsi_ll2_handle,
+					     &ll2_tx_pkt, 1);
+	if (rc) {
+		/* TX failed while posting header - release resources */
+		dma_free_coherent(&dev->pdev->dev, pkt->header.len,
+				  pkt->header.vaddr, pkt->header.baddr);
+		kfree(pkt);
+
+		DP_ERR(dev, "roce ll2 tx: header failed (rc=%d)\n", rc);
+		return rc;
+	}
+
+	/* tx payload */
+	for (i = 0; i < pkt->n_seg; i++) {
+		rc = dev->ops->ll2_set_fragment_of_tx_packet(
+			dev->rdma_ctx,
+			dev->gsi_ll2_handle,
+			pkt->payload[i].baddr,
+			pkt->payload[i].len);
+
+		if (rc) {
+			/* if failed not much to do here, partial packet has
+			 * been posted we can't free memory, will need to wait
+			 * for completion
+			 */
+			DP_ERR(dev, "ll2 tx: payload failed (rc=%d)\n", rc);
+			return rc;
+		}
+	}
+
+	return 0;
+}
+
+int qedr_ll2_stop(struct qedr_dev *dev)
+{
+	int rc;
+
+	if (dev->gsi_ll2_handle == QED_LL2_UNUSED_HANDLE)
+		return 0;
+
+	/* remove LL2 MAC address filter */
+	rc = dev->ops->ll2_set_mac_filter(dev->cdev,
+					  dev->gsi_ll2_mac_address, NULL);
+
+	rc = dev->ops->ll2_terminate_connection(dev->rdma_ctx,
+						dev->gsi_ll2_handle);
+	if (rc)
+		DP_ERR(dev, "Failed to terminate LL2 connection (rc=%d)\n", rc);
+
+	dev->ops->ll2_release_connection(dev->rdma_ctx, dev->gsi_ll2_handle);
+
+	dev->gsi_ll2_handle = QED_LL2_UNUSED_HANDLE;
+
+	return rc;
+}
+
+int qedr_ll2_start(struct qedr_dev *dev,
+		   struct ib_qp_init_attr *attrs, struct qedr_qp *qp)
+{
+	struct qed_ll2_acquire_data data;
+	struct qed_ll2_cbs cbs;
+	int rc;
+
+	/* configure and start LL2 */
+	cbs.rx_comp_cb = qedr_ll2_complete_rx_packet;
+	cbs.tx_comp_cb = qedr_ll2_complete_tx_packet;
+	cbs.rx_release_cb = qedr_ll2_release_rx_packet;
+	cbs.tx_release_cb = qedr_ll2_complete_tx_packet;
+	cbs.cookie = dev;
+
+	memset(&data, 0, sizeof(data));
+	data.input.conn_type = QED_LL2_TYPE_ROCE;
+	data.input.mtu = dev->ndev->mtu;
+	data.input.rx_num_desc = attrs->cap.max_recv_wr;
+	data.input.rx_drop_ttl0_flg = true;
+	data.input.rx_vlan_removal_en = false;
+	data.input.tx_num_desc = attrs->cap.max_send_wr;
+	data.input.tx_tc = 0;
+	data.input.tx_dest = QED_LL2_TX_DEST_NW;
+	data.input.ai_err_packet_too_big = QED_LL2_DROP_PACKET;
+	data.input.ai_err_no_buf = QED_LL2_DROP_PACKET;
+	data.input.gsi_enable = 1;
+	data.p_connection_handle = &dev->gsi_ll2_handle;
+	data.cbs = &cbs;
+
+	rc = dev->ops->ll2_acquire_connection(dev->rdma_ctx, &data);
+	if (rc) {
+		DP_ERR(dev,
+		       "ll2 start: failed to acquire LL2 connection (rc=%d)\n",
+		       rc);
+		return rc;
+	}
+
+	rc = dev->ops->ll2_establish_connection(dev->rdma_ctx,
+						dev->gsi_ll2_handle);
+	if (rc) {
+		DP_ERR(dev,
+		       "ll2 start: failed to establish LL2 connection (rc=%d)\n",
+		       rc);
+		goto err1;
+	}
+
+	rc = dev->ops->ll2_set_mac_filter(dev->cdev, NULL, dev->ndev->dev_addr);
+	if (rc)
+		goto err2;
+
+	return 0;
+
+err2:
+	dev->ops->ll2_terminate_connection(dev->rdma_ctx, dev->gsi_ll2_handle);
+err1:
+	dev->ops->ll2_release_connection(dev->rdma_ctx, dev->gsi_ll2_handle);
+
+	return rc;
+}
+
 struct ib_qp *qedr_create_gsi_qp(struct qedr_dev *dev,
 				 struct ib_qp_init_attr *attrs,
 				 struct qedr_qp *qp)
 {
-	struct qed_roce_ll2_params ll2_params;
 	int rc;
 
 	rc = qedr_check_gsi_qp_attrs(dev, attrs);
 	if (rc)
 		return ERR_PTR(rc);
 
-	/* configure and start LL2 */
-	memset(&ll2_params, 0, sizeof(ll2_params));
-	ll2_params.max_tx_buffers = attrs->cap.max_send_wr;
-	ll2_params.max_rx_buffers = attrs->cap.max_recv_wr;
-	ll2_params.cbs.tx_cb = qedr_ll2_tx_cb;
-	ll2_params.cbs.rx_cb = qedr_ll2_rx_cb;
-	ll2_params.cb_cookie = (void *)dev;
-	ll2_params.mtu = dev->ndev->mtu;
-	ether_addr_copy(ll2_params.mac_address, dev->ndev->dev_addr);
-	rc = dev->ops->roce_ll2_start(dev->cdev, &ll2_params);
+	rc = qedr_ll2_start(dev, attrs, qp);
 	if (rc) {
 		DP_ERR(dev, "create gsi qp: failed on ll2 start. rc=%d\n", rc);
 		return ERR_PTR(rc);
@@ -214,7 +365,7 @@ struct ib_qp *qedr_create_gsi_qp(struct qedr_dev *dev,
 err:
 	kfree(qp->rqe_wr_id);
 
-	rc = dev->ops->roce_ll2_stop(dev->cdev);
+	rc = qedr_ll2_stop(dev);
 	if (rc)
 		DP_ERR(dev, "create gsi qp: failed destroy on create\n");
 
@@ -223,15 +374,7 @@ err:
 
 int qedr_destroy_gsi_qp(struct qedr_dev *dev)
 {
-	int rc;
-
-	rc = dev->ops->roce_ll2_stop(dev->cdev);
-	if (rc)
-		DP_ERR(dev, "destroy gsi qp: failed (rc=%d)\n", rc);
-	else
-		DP_DEBUG(dev, QEDR_MSG_GSI, "destroy gsi qp: success\n");
-
-	return rc;
+	return qedr_ll2_stop(dev);
 }
 
 #define QEDR_MAX_UD_HEADER_SIZE	(100)
@@ -420,7 +563,6 @@ int qedr_gsi_post_send(struct ib_qp *ibqp, struct ib_send_wr *wr,
 {
 	struct qed_roce_ll2_packet *pkt = NULL;
 	struct qedr_qp *qp = get_qedr_qp(ibqp);
-	struct qed_roce_ll2_tx_params params;
 	struct qedr_dev *dev = qp->dev;
 	unsigned long flags;
 	int rc;
@@ -448,8 +590,6 @@ int qedr_gsi_post_send(struct ib_qp *ibqp, struct ib_send_wr *wr,
 		goto err;
 	}
 
-	memset(&params, 0, sizeof(params));
-
 	spin_lock_irqsave(&qp->q_lock, flags);
 
 	rc = qedr_gsi_build_packet(dev, qp, wr, &pkt);
@@ -458,7 +598,8 @@ int qedr_gsi_post_send(struct ib_qp *ibqp, struct ib_send_wr *wr,
 		goto err;
 	}
 
-	rc = dev->ops->roce_ll2_tx(dev->cdev, pkt, &params);
+	rc = qedr_ll2_post_tx(dev, pkt);
+
 	if (!rc) {
 		qp->wqe_wr_id[qp->sq.prod].wr_id = wr->wr_id;
 		qedr_inc_sw_prod(&qp->sq);
@@ -466,17 +607,6 @@ int qedr_gsi_post_send(struct ib_qp *ibqp, struct ib_send_wr *wr,
 			 "gsi post send: opcode=%d, in_irq=%ld, irqs_disabled=%d, wr_id=%llx\n",
 			 wr->opcode, in_irq(), irqs_disabled(), wr->wr_id);
 	} else {
-		if (rc == QED_ROCE_TX_HEAD_FAILURE) {
-			/* TX failed while posting header - release resources */
-			dma_free_coherent(&dev->pdev->dev, pkt->header.len,
-					  pkt->header.vaddr, pkt->header.baddr);
-			kfree(pkt);
-		} else if (rc == QED_ROCE_TX_FRAG_FAILURE) {
-			/* NTD since TX failed while posting a fragment. We will
-			 * release the resources on TX callback
-			 */
-		}
-
 		DP_ERR(dev, "gsi post send: failed to transmit (rc=%d)\n", rc);
 		rc = -EAGAIN;
 		*bad_wr = wr;
@@ -503,10 +633,8 @@ int qedr_gsi_post_recv(struct ib_qp *ibqp, struct ib_recv_wr *wr,
 {
 	struct qedr_dev *dev = get_qedr_dev(ibqp->device);
 	struct qedr_qp *qp = get_qedr_qp(ibqp);
-	struct qed_roce_ll2_buffer buf;
 	unsigned long flags;
-	int status = 0;
-	int rc;
+	int rc = 0;
 
 	if ((qp->state != QED_ROCE_QP_STATE_RTR) &&
 	    (qp->state != QED_ROCE_QP_STATE_RTS)) {
@@ -517,8 +645,6 @@ int qedr_gsi_post_recv(struct ib_qp *ibqp, struct ib_recv_wr *wr,
 		return -EINVAL;
 	}
 
-	memset(&buf, 0, sizeof(buf));
-
 	spin_lock_irqsave(&qp->q_lock, flags);
 
 	while (wr) {
@@ -529,10 +655,12 @@ int qedr_gsi_post_recv(struct ib_qp *ibqp, struct ib_recv_wr *wr,
 			goto err;
 		}
 
-		buf.baddr = wr->sg_list[0].addr;
-		buf.len = wr->sg_list[0].length;
-
-		rc = dev->ops->roce_ll2_post_rx_buffer(dev->cdev, &buf, 0, 1);
+		rc = dev->ops->ll2_post_rx_buffer(dev->rdma_ctx,
+						  dev->gsi_ll2_handle,
+						  wr->sg_list[0].addr,
+						  wr->sg_list[0].length,
+						  0 /* cookie */,
+						  1 /* notify_fw */);
 		if (rc) {
 			DP_ERR(dev,
 			       "gsi post recv: failed to post rx buffer (rc=%d)\n",
@@ -552,7 +680,7 @@ int qedr_gsi_post_recv(struct ib_qp *ibqp, struct ib_recv_wr *wr,
 
 	spin_unlock_irqrestore(&qp->q_lock, flags);
 
-	return status;
+	return rc;
 err:
 	spin_unlock_irqrestore(&qp->q_lock, flags);
 	*bad_wr = wr;
diff --git a/drivers/net/ethernet/qlogic/qed/qed.h b/drivers/net/ethernet/qlogic/qed/qed.h
index 848905e401aa..638f5af0b946 100644
--- a/drivers/net/ethernet/qlogic/qed/qed.h
+++ b/drivers/net/ethernet/qlogic/qed/qed.h
@@ -512,7 +512,6 @@ struct qed_hwfn {
 #endif
 
 	struct z_stream_s		*stream;
-	struct qed_roce_ll2_info	*ll2;
 };
 
 struct pci_params {
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_ll2.c
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_ll2.h
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_roce.c
diff --git a/drivers/net/ethernet/qlogic/qed/qed_roce.h b/drivers/net/ethernet/qlogic/qed/qed_roce.h
index 9742af516183..94be3b5a39c4 100644
--- a/drivers/net/ethernet/qlogic/qed/qed_roce.h
+++ b/drivers/net/ethernet/qlogic/qed/qed_roce.h
@@ -170,53 +170,10 @@ struct qed_rdma_qp {
 void qed_rdma_dpm_bar(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt);
 void qed_roce_async_event(struct qed_hwfn *p_hwfn,
 			  u8 fw_event_code, union rdma_eqe_data *rdma_data);
-void qed_ll2b_complete_tx_gsi_packet(struct qed_hwfn *p_hwfn,
-				     u8 connection_handle,
-				     void *cookie,
-				     dma_addr_t first_frag_addr,
-				     bool b_last_fragment, bool b_last_packet);
-void qed_ll2b_release_tx_gsi_packet(struct qed_hwfn *p_hwfn,
-				    u8 connection_handle,
-				    void *cookie,
-				    dma_addr_t first_frag_addr,
-				    bool b_last_fragment, bool b_last_packet);
-void qed_ll2b_complete_rx_gsi_packet(struct qed_hwfn *p_hwfn,
-				     u8 connection_handle,
-				     void *cookie,
-				     dma_addr_t rx_buf_addr,
-				     u16 data_length,
-				     u8 data_length_error,
-				     u16 parse_flags,
-				     u16 vlan,
-				     u32 src_mac_addr_hi,
-				     u16 src_mac_addr_lo, bool b_last_packet);
 #else
 static inline void qed_rdma_dpm_bar(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt) {}
 static inline void qed_roce_async_event(struct qed_hwfn *p_hwfn,
 					u8 fw_event_code,
 					union rdma_eqe_data *rdma_data) {}
-static inline void qed_ll2b_complete_tx_gsi_packet(struct qed_hwfn *p_hwfn,
-						   u8 connection_handle,
-						   void *cookie,
-						   dma_addr_t first_frag_addr,
-						   bool b_last_fragment,
-						   bool b_last_packet) {}
-static inline void qed_ll2b_release_tx_gsi_packet(struct qed_hwfn *p_hwfn,
-						  u8 connection_handle,
-						  void *cookie,
-						  dma_addr_t first_frag_addr,
-						  bool b_last_fragment,
-						  bool b_last_packet) {}
-static inline void qed_ll2b_complete_rx_gsi_packet(struct qed_hwfn *p_hwfn,
-						   u8 connection_handle,
-						   void *cookie,
-						   dma_addr_t rx_buf_addr,
-						   u16 data_length,
-						   u8 data_length_error,
-						   u16 parse_flags,
-						   u16 vlan,
-						   u32 src_mac_addr_hi,
-						   u16 src_mac_addr_lo,
-						   bool b_last_packet) {}
 #endif
 #endif
* Unmerged path include/linux/qed/qed_ll2_if.h
diff --git a/include/linux/qed/qed_roce_if.h b/include/linux/qed/qed_roce_if.h
index cbb2ff0ce4bc..8e70f5ee05af 100644
--- a/include/linux/qed/qed_roce_if.h
+++ b/include/linux/qed/qed_roce_if.h
@@ -34,8 +34,6 @@
 #include <linux/types.h>
 #include <linux/delay.h>
 #include <linux/list.h>
-#include <linux/mutex.h>
-#include <linux/pci.h>
 #include <linux/slab.h>
 #include <linux/qed/qed_if.h>
 #include <linux/qed/qed_ll2_if.h>
@@ -491,42 +489,6 @@ struct qed_roce_ll2_packet {
 	enum qed_roce_ll2_tx_dest tx_dest;
 };
 
-struct qed_roce_ll2_tx_params {
-	int reserved;
-};
-
-struct qed_roce_ll2_rx_params {
-	u16 vlan_id;
-	u8 smac[ETH_ALEN];
-	int rc;
-};
-
-struct qed_roce_ll2_cbs {
-	void (*tx_cb)(void *pdev, struct qed_roce_ll2_packet *pkt);
-
-	void (*rx_cb)(void *pdev, struct qed_roce_ll2_packet *pkt,
-		      struct qed_roce_ll2_rx_params *params);
-};
-
-struct qed_roce_ll2_params {
-	u16 max_rx_buffers;
-	u16 max_tx_buffers;
-	u16 mtu;
-	u8 mac_address[ETH_ALEN];
-	struct qed_roce_ll2_cbs cbs;
-	void *cb_cookie;
-};
-
-struct qed_roce_ll2_info {
-	u8 handle;
-	struct qed_roce_ll2_cbs cbs;
-	u8 mac_address[ETH_ALEN];
-	void *cb_cookie;
-
-	/* Lock to protect ll2 */
-	struct mutex lock;
-};
-
 enum qed_rdma_type {
 	QED_RDMA_TYPE_ROCE,
 };
@@ -579,26 +541,40 @@ struct qed_rdma_ops {
 	int (*rdma_query_qp)(void *rdma_cxt, struct qed_rdma_qp *qp,
 			     struct qed_rdma_query_qp_out_params *oparams);
 	int (*rdma_destroy_qp)(void *rdma_cxt, struct qed_rdma_qp *qp);
+
 	int
 	(*rdma_register_tid)(void *rdma_cxt,
 			     struct qed_rdma_register_tid_in_params *iparams);
+
 	int (*rdma_deregister_tid)(void *rdma_cxt, u32 itid);
 	int (*rdma_alloc_tid)(void *rdma_cxt, u32 *itid);
 	void (*rdma_free_tid)(void *rdma_cxt, u32 itid);
-	int (*roce_ll2_start)(struct qed_dev *cdev,
-			      struct qed_roce_ll2_params *params);
-	int (*roce_ll2_stop)(struct qed_dev *cdev);
-	int (*roce_ll2_tx)(struct qed_dev *cdev,
-			   struct qed_roce_ll2_packet *packet,
-			   struct qed_roce_ll2_tx_params *params);
-	int (*roce_ll2_post_rx_buffer)(struct qed_dev *cdev,
-				       struct qed_roce_ll2_buffer *buf,
-				       u64 cookie, u8 notify_fw);
-	int (*roce_ll2_set_mac_filter)(struct qed_dev *cdev,
-				       u8 *old_mac_address,
-				       u8 *new_mac_address);
-	int (*roce_ll2_stats)(struct qed_dev *cdev,
-			      struct qed_ll2_stats *stats);
+
+	int (*ll2_acquire_connection)(void *rdma_cxt,
+				      struct qed_ll2_acquire_data *data);
+
+	int (*ll2_establish_connection)(void *rdma_cxt, u8 connection_handle);
+	int (*ll2_terminate_connection)(void *rdma_cxt, u8 connection_handle);
+	void (*ll2_release_connection)(void *rdma_cxt, u8 connection_handle);
+
+	int (*ll2_prepare_tx_packet)(void *rdma_cxt,
+				     u8 connection_handle,
+				     struct qed_ll2_tx_pkt_info *pkt,
+				     bool notify_fw);
+
+	int (*ll2_set_fragment_of_tx_packet)(void *rdma_cxt,
+					     u8 connection_handle,
+					     dma_addr_t addr,
+					     u16 nbytes);
+	int (*ll2_post_rx_buffer)(void *rdma_cxt, u8 connection_handle,
+				  dma_addr_t addr, u16 buf_len, void *cookie,
+				  u8 notify_fw);
+	int (*ll2_get_stats)(void *rdma_cxt,
+			     u8 connection_handle,
+			     struct qed_ll2_stats *p_stats);
+	int (*ll2_set_mac_filter)(struct qed_dev *cdev,
+				  u8 *old_mac_address, u8 *new_mac_address);
+
 };
 
 const struct qed_rdma_ops *qed_get_rdma_ops(void);
