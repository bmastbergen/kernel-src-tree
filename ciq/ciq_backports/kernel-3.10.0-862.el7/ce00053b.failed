x86: kvm: mmu: dead code thanks to access tracking

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [x86] kvm: mmu: dead code thanks to access tracking (Paolo Bonzini) [1469685]
Rebuild_FUZZ: 94.74%
commit-author Peter Feiner <pfeiner@google.com>
commit ce00053b1cfca312c22e2a6465451f1862561eab
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/ce00053b.failed

The MMU always has hardware A bits or access tracking support, thus
it's unnecessary to handle the scenario where we have neither.

	Signed-off-by: Peter Feiner <pfeiner@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit ce00053b1cfca312c22e2a6465451f1862561eab)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu.c
diff --cc arch/x86/kvm/mmu.c
index 588adec09b8c,dfd4cd67e5a6..000000000000
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@@ -282,9 -315,22 +282,24 @@@ static bool check_mmio_spte(struct kvm_
  	return likely(kvm_gen == spte_gen);
  }
  
+ /*
+  * Sets the shadow PTE masks used by the MMU.
+  *
+  * Assumptions:
+  *  - Setting either @accessed_mask or @dirty_mask requires setting both
+  *  - At least one of @accessed_mask or @acc_track_mask must be set
+  */
  void kvm_mmu_set_mask_ptes(u64 user_mask, u64 accessed_mask,
 -		u64 dirty_mask, u64 nx_mask, u64 x_mask, u64 p_mask,
 -		u64 acc_track_mask)
 +		u64 dirty_mask, u64 nx_mask, u64 x_mask, u64 p_mask)
  {
++<<<<<<< HEAD
++=======
+ 	if (acc_track_mask != 0)
+ 		acc_track_mask |= SPTE_SPECIAL_MASK;
+ 	BUG_ON(!dirty_mask != !accessed_mask);
+ 	BUG_ON(!accessed_mask && !acc_track_mask);
+ 
++>>>>>>> ce00053b1cfc (x86: kvm: mmu: dead code thanks to access tracking)
  	shadow_user_mask = user_mask;
  	shadow_accessed_mask = accessed_mask;
  	shadow_dirty_mask = dirty_mask;
@@@ -1676,14 -1775,6 +1691,17 @@@ static int kvm_test_age_rmapp(struct kv
  	u64 *sptep;
  	struct rmap_iterator iter;
  
++<<<<<<< HEAD
 +	/*
 +	 * If there's no access bit in the secondary pte set by the
 +	 * hardware it's up to gup-fast/gup to set the access bit in
 +	 * the primary pte or in the page structure.
 +	 */
 +	if (!shadow_accessed_mask)
 +		goto out;
 +
++=======
++>>>>>>> ce00053b1cfc (x86: kvm: mmu: dead code thanks to access tracking)
  	for_each_rmap_spte(rmap_head, &iter, sptep)
  		if (is_accessed_spte(*sptep))
  			return 1;
@@@ -1706,9 -1796,9 +1723,13 @@@ static void rmap_recycle(struct kvm_vcp
  	kvm_flush_remote_tlbs(vcpu->kvm);
  }
  
 -int kvm_age_hva(struct kvm *kvm, unsigned long start, unsigned long end)
 +int kvm_age_hva(struct kvm *kvm, unsigned long hva)
  {
++<<<<<<< HEAD
 +	return kvm_handle_hva(kvm, hva, 0, kvm_age_rmapp);
++=======
+ 	return kvm_handle_hva_range(kvm, start, end, 0, kvm_age_rmapp);
++>>>>>>> ce00053b1cfc (x86: kvm: mmu: dead code thanks to access tracking)
  }
  
  int kvm_test_age_hva(struct kvm *kvm, unsigned long hva)
* Unmerged path arch/x86/kvm/mmu.c
