netvsc: fix rtnl deadlock on unregister of vf

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author stephen hemminger <stephen@networkplumber.org>
commit fb84af8a4397ee664a51c2da1dd64fb3d582ee24
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/fb84af8a.failed

With new transparent VF support, it is possible to get a deadlock
when some of the deferred work is running and the unregister_vf
is trying to cancel the work element. The solution is to use
trylock and reschedule (similar to bonding and team device).

	Reported-by: Vitaly Kuznetsov <vkuznets@redhat.com>
Fixes: 0c195567a8f6 ("netvsc: transparent VF management")
	Signed-off-by: Stephen Hemminger <sthemmin@microsoft.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit fb84af8a4397ee664a51c2da1dd64fb3d582ee24)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/hyperv/netvsc_drv.c
diff --cc drivers/net/hyperv/netvsc_drv.c
index d4dc9c189b85,e75c0f852a63..000000000000
--- a/drivers/net/hyperv/netvsc_drv.c
+++ b/drivers/net/hyperv/netvsc_drv.c
@@@ -1358,6 -1511,108 +1358,111 @@@ static struct net_device *get_netvsc_by
  	return NULL;
  }
  
++<<<<<<< HEAD
++=======
+ /* Called when VF is injecting data into network stack.
+  * Change the associated network device from VF to netvsc.
+  * note: already called with rcu_read_lock
+  */
+ static rx_handler_result_t netvsc_vf_handle_frame(struct sk_buff **pskb)
+ {
+ 	struct sk_buff *skb = *pskb;
+ 	struct net_device *ndev = rcu_dereference(skb->dev->rx_handler_data);
+ 	struct net_device_context *ndev_ctx = netdev_priv(ndev);
+ 	struct netvsc_vf_pcpu_stats *pcpu_stats
+ 		 = this_cpu_ptr(ndev_ctx->vf_stats);
+ 
+ 	skb->dev = ndev;
+ 
+ 	u64_stats_update_begin(&pcpu_stats->syncp);
+ 	pcpu_stats->rx_packets++;
+ 	pcpu_stats->rx_bytes += skb->len;
+ 	u64_stats_update_end(&pcpu_stats->syncp);
+ 
+ 	return RX_HANDLER_ANOTHER;
+ }
+ 
+ static int netvsc_vf_join(struct net_device *vf_netdev,
+ 			  struct net_device *ndev)
+ {
+ 	struct net_device_context *ndev_ctx = netdev_priv(ndev);
+ 	int ret;
+ 
+ 	ret = netdev_rx_handler_register(vf_netdev,
+ 					 netvsc_vf_handle_frame, ndev);
+ 	if (ret != 0) {
+ 		netdev_err(vf_netdev,
+ 			   "can not register netvsc VF receive handler (err = %d)\n",
+ 			   ret);
+ 		goto rx_handler_failed;
+ 	}
+ 
+ 	ret = netdev_upper_dev_link(vf_netdev, ndev);
+ 	if (ret != 0) {
+ 		netdev_err(vf_netdev,
+ 			   "can not set master device %s (err = %d)\n",
+ 			   ndev->name, ret);
+ 		goto upper_link_failed;
+ 	}
+ 
+ 	/* set slave flag before open to prevent IPv6 addrconf */
+ 	vf_netdev->flags |= IFF_SLAVE;
+ 
+ 	schedule_work(&ndev_ctx->vf_takeover);
+ 
+ 	netdev_info(vf_netdev, "joined to %s\n", ndev->name);
+ 	return 0;
+ 
+ upper_link_failed:
+ 	netdev_rx_handler_unregister(vf_netdev);
+ rx_handler_failed:
+ 	return ret;
+ }
+ 
+ static void __netvsc_vf_setup(struct net_device *ndev,
+ 			      struct net_device *vf_netdev)
+ {
+ 	int ret;
+ 
+ 	call_netdevice_notifiers(NETDEV_JOIN, vf_netdev);
+ 
+ 	/* Align MTU of VF with master */
+ 	ret = dev_set_mtu(vf_netdev, ndev->mtu);
+ 	if (ret)
+ 		netdev_warn(vf_netdev,
+ 			    "unable to change mtu to %u\n", ndev->mtu);
+ 
+ 	if (netif_running(ndev)) {
+ 		ret = dev_open(vf_netdev);
+ 		if (ret)
+ 			netdev_warn(vf_netdev,
+ 				    "unable to open: %d\n", ret);
+ 	}
+ }
+ 
+ /* Setup VF as slave of the synthetic device.
+  * Runs in workqueue to avoid recursion in netlink callbacks.
+  */
+ static void netvsc_vf_setup(struct work_struct *w)
+ {
+ 	struct net_device_context *ndev_ctx
+ 		= container_of(w, struct net_device_context, vf_takeover);
+ 	struct net_device *ndev = hv_get_drvdata(ndev_ctx->device_ctx);
+ 	struct net_device *vf_netdev;
+ 
+ 	if (!rtnl_trylock()) {
+ 		schedule_work(w);
+ 		return;
+ 	}
+ 
+ 	vf_netdev = rtnl_dereference(ndev_ctx->vf_netdev);
+ 	if (vf_netdev)
+ 		__netvsc_vf_setup(ndev, vf_netdev);
+ 
+ 	rtnl_unlock();
+ }
+ 
++>>>>>>> fb84af8a4397 (netvsc: fix rtnl deadlock on unregister of vf)
  static int netvsc_register_vf(struct net_device *vf_netdev)
  {
  	struct net_device *ndev;
@@@ -1392,11 -1649,56 +1497,60 @@@
  	return NOTIFY_OK;
  }
  
 -/* Change datapath */
 -static void netvsc_vf_update(struct work_struct *w)
 +static int netvsc_vf_up(struct net_device *vf_netdev)
  {
++<<<<<<< HEAD
++=======
+ 	struct net_device_context *ndev_ctx
+ 		= container_of(w, struct net_device_context, vf_notify);
+ 	struct net_device *ndev = hv_get_drvdata(ndev_ctx->device_ctx);
+ 	struct netvsc_device *netvsc_dev;
+ 	struct net_device *vf_netdev;
+ 	bool vf_is_up;
+ 
+ 	if (!rtnl_trylock()) {
+ 		schedule_work(w);
+ 		return;
+ 	}
+ 
+ 	vf_netdev = rtnl_dereference(ndev_ctx->vf_netdev);
+ 	if (!vf_netdev)
+ 		goto unlock;
+ 
+ 	netvsc_dev = rtnl_dereference(ndev_ctx->nvdev);
+ 	if (!netvsc_dev)
+ 		goto unlock;
+ 
+ 	vf_is_up = netif_running(vf_netdev);
+ 	if (vf_is_up != ndev_ctx->datapath) {
+ 		if (vf_is_up) {
+ 			netdev_info(ndev, "VF up: %s\n", vf_netdev->name);
+ 			rndis_filter_open(netvsc_dev);
+ 			netvsc_switch_datapath(ndev, true);
+ 			netdev_info(ndev, "Data path switched to VF: %s\n",
+ 				    vf_netdev->name);
+ 		} else {
+ 			netdev_info(ndev, "VF down: %s\n", vf_netdev->name);
+ 			netvsc_switch_datapath(ndev, false);
+ 			rndis_filter_close(netvsc_dev);
+ 			netdev_info(ndev, "Data path switched from VF: %s\n",
+ 				    vf_netdev->name);
+ 		}
+ 
+ 		/* Now notify peers through VF device. */
+ 		call_netdevice_notifiers(NETDEV_NOTIFY_PEERS, ndev);
+ 	}
+ unlock:
+ 	rtnl_unlock();
+ }
+ 
+ static int netvsc_vf_notify(struct net_device *vf_netdev)
+ {
+ 	struct net_device_context *net_device_ctx;
++>>>>>>> fb84af8a4397 (netvsc: fix rtnl deadlock on unregister of vf)
  	struct net_device *ndev;
 +	struct netvsc_device *netvsc_dev;
 +	struct net_device_context *net_device_ctx;
  
  	ndev = get_netvsc_byref(vf_netdev);
  	if (!ndev)
* Unmerged path drivers/net/hyperv/netvsc_drv.c
