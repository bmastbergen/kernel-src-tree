scsi: lpfc: ensure els_wq is being checked before destroying it

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [scsi] lpfc: ensure els_wq is being checked before destroying it (Dick Kennedy) [1385844 1461977 1387768]
Rebuild_FUZZ: 95.00%
commit-author Colin Ian King <colin.king@canonical.com>
commit 019c0d66f66a8612bb867caf05e865a4766238a4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/019c0d66.failed

I believe there is a typo on the wq destroy of els_wq, currently the
driver is checking if els_cq is not null and I think this should be a
check on els_wq instead.

Detected by CoverityScan, CID#1411629 ("Copy-paste error")

	Signed-off-by: Colin Ian King <colin.king@canonical.com>
	Acked-by: Dick Kennedy <dick.kennedy@broadcom.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit 019c0d66f66a8612bb867caf05e865a4766238a4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/lpfc/lpfc_init.c
diff --cc drivers/scsi/lpfc/lpfc_init.c
index 6b2100eb2346,4b1eb98c228d..000000000000
--- a/drivers/scsi/lpfc/lpfc_init.c
+++ b/drivers/scsi/lpfc/lpfc_init.c
@@@ -8082,34 -8844,76 +8082,40 @@@ lpfc_sli4_queue_unset(struct lpfc_hba *
  	/* Unset the queues created for Flash Optimized Fabric operations */
  	if (phba->cfg_fof)
  		lpfc_fof_queue_destroy(phba);
 -
  	/* Unset mailbox command work queue */
 -	if (phba->sli4_hba.mbx_wq)
 -		lpfc_mq_destroy(phba, phba->sli4_hba.mbx_wq);
 -
 -	/* Unset NVME LS work queue */
 -	if (phba->sli4_hba.nvmels_wq)
 -		lpfc_wq_destroy(phba, phba->sli4_hba.nvmels_wq);
 -
 +	lpfc_mq_destroy(phba, phba->sli4_hba.mbx_wq);
  	/* Unset ELS work queue */
++<<<<<<< HEAD
 +	lpfc_wq_destroy(phba, phba->sli4_hba.els_wq);
++=======
+ 	if (phba->sli4_hba.els_wq)
+ 		lpfc_wq_destroy(phba, phba->sli4_hba.els_wq);
+ 
++>>>>>>> 019c0d66f66a (scsi: lpfc: ensure els_wq is being checked before destroying it)
  	/* Unset unsolicited receive queue */
 -	if (phba->sli4_hba.hdr_rq)
 -		lpfc_rq_destroy(phba, phba->sli4_hba.hdr_rq,
 -				phba->sli4_hba.dat_rq);
 -
 +	lpfc_rq_destroy(phba, phba->sli4_hba.hdr_rq, phba->sli4_hba.dat_rq);
  	/* Unset FCP work queue */
 -	if (phba->sli4_hba.fcp_wq)
 -		for (qidx = 0; qidx < phba->cfg_fcp_io_channel; qidx++)
 -			lpfc_wq_destroy(phba, phba->sli4_hba.fcp_wq[qidx]);
 -
 -	/* Unset NVME work queue */
 -	if (phba->sli4_hba.nvme_wq) {
 -		for (qidx = 0; qidx < phba->cfg_nvme_io_channel; qidx++)
 -			lpfc_wq_destroy(phba, phba->sli4_hba.nvme_wq[qidx]);
 +	if (phba->sli4_hba.fcp_wq) {
 +		for (fcp_qidx = 0; fcp_qidx < phba->cfg_fcp_io_channel;
 +		     fcp_qidx++)
 +			lpfc_wq_destroy(phba, phba->sli4_hba.fcp_wq[fcp_qidx]);
  	}
 -
  	/* Unset mailbox command complete queue */
 -	if (phba->sli4_hba.mbx_cq)
 -		lpfc_cq_destroy(phba, phba->sli4_hba.mbx_cq);
 -
 +	lpfc_cq_destroy(phba, phba->sli4_hba.mbx_cq);
  	/* Unset ELS complete queue */
 -	if (phba->sli4_hba.els_cq)
 -		lpfc_cq_destroy(phba, phba->sli4_hba.els_cq);
 -
 -	/* Unset NVME LS complete queue */
 -	if (phba->sli4_hba.nvmels_cq)
 -		lpfc_cq_destroy(phba, phba->sli4_hba.nvmels_cq);
 -
 -	/* Unset NVME response complete queue */
 -	if (phba->sli4_hba.nvme_cq)
 -		for (qidx = 0; qidx < phba->cfg_nvme_io_channel; qidx++)
 -			lpfc_cq_destroy(phba, phba->sli4_hba.nvme_cq[qidx]);
 -
 -	/* Unset NVMET MRQ queue */
 -	if (phba->sli4_hba.nvmet_mrq_hdr) {
 -		for (qidx = 0; qidx < phba->cfg_nvmet_mrq; qidx++)
 -			lpfc_rq_destroy(phba,
 -					phba->sli4_hba.nvmet_mrq_hdr[qidx],
 -					phba->sli4_hba.nvmet_mrq_data[qidx]);
 -	}
 -
 -	/* Unset NVMET CQ Set complete queue */
 -	if (phba->sli4_hba.nvmet_cqset) {
 -		for (qidx = 0; qidx < phba->cfg_nvmet_mrq; qidx++)
 -			lpfc_cq_destroy(phba,
 -					phba->sli4_hba.nvmet_cqset[qidx]);
 -	}
 -
 +	lpfc_cq_destroy(phba, phba->sli4_hba.els_cq);
  	/* Unset FCP response complete queue */
 -	if (phba->sli4_hba.fcp_cq)
 -		for (qidx = 0; qidx < phba->cfg_fcp_io_channel; qidx++)
 -			lpfc_cq_destroy(phba, phba->sli4_hba.fcp_cq[qidx]);
 -
 +	if (phba->sli4_hba.fcp_cq) {
 +		for (fcp_qidx = 0; fcp_qidx < phba->cfg_fcp_io_channel;
 +		     fcp_qidx++)
 +			lpfc_cq_destroy(phba, phba->sli4_hba.fcp_cq[fcp_qidx]);
 +	}
  	/* Unset fast-path event queue */
 -	if (phba->sli4_hba.hba_eq)
 -		for (qidx = 0; qidx < phba->io_channel_irqs; qidx++)
 -			lpfc_eq_destroy(phba, phba->sli4_hba.hba_eq[qidx]);
 +	if (phba->sli4_hba.hba_eq) {
 +		for (fcp_qidx = 0; fcp_qidx < phba->cfg_fcp_io_channel;
 +		     fcp_qidx++)
 +			lpfc_eq_destroy(phba, phba->sli4_hba.hba_eq[fcp_qidx]);
 +	}
  }
  
  /**
* Unmerged path drivers/scsi/lpfc/lpfc_init.c
