x86/intel_rdt: Add resource specific msr update function

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [x86] intel_rdt: Add resource specific msr update function (Jiri Olsa) [1379551]
Rebuild_FUZZ: 96.30%
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 0921c54769bac209b302027384e9dc081198c8f5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/0921c547.failed

Updating of Cache and Memory bandwidth QOS MSRs is different.

Add a function pointer to struct rdt_resource and convert the cache part
over.

Based on Vikas all in one patch^Wmess.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: ravi.v.shankar@intel.com
	Cc: tony.luck@intel.com
	Cc: fenghua.yu@intel.com
	Cc: vikas.shivappa@intel.com
(cherry picked from commit 0921c54769bac209b302027384e9dc081198c8f5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/intel_rdt.h
#	arch/x86/kernel/cpu/intel_rdt.c
diff --cc arch/x86/include/asm/intel_rdt.h
index 06f50d0ed14f,51e4a1ca9551..000000000000
--- a/arch/x86/include/asm/intel_rdt.h
+++ b/arch/x86/include/asm/intel_rdt.h
@@@ -74,39 -74,6 +74,42 @@@ struct rftype 
  };
  
  /**
++<<<<<<< HEAD
 + * struct rdt_resource - attributes of an RDT resource
 + * @enabled:			Is this feature enabled on this machine
 + * @capable:			Is this feature available on this machine
 + * @name:			Name to use in "schemata" file
 + * @num_closid:			Number of CLOSIDs available
 + * @max_cbm:			Largest Cache Bit Mask allowed
 + * @data_width:			Character width of data when displaying
 + * @min_cbm_bits:		Minimum number of consecutive bits to be set
 + *				in a cache bit mask
 + * @domains:			All domains for this resource
 + * @msr_base:			Base MSR address for CBMs
 + * @cache_level:		Which cache level defines scope of this domain
 + * @cbm_idx_multi:		Multiplier of CBM index
 + * @cbm_idx_offset:		Offset of CBM index. CBM index is computed by:
 + *				closid * cbm_idx_multi + cbm_idx_offset
 + */
 +struct rdt_resource {
 +	bool			enabled;
 +	bool			capable;
 +	char			*name;
 +	int			num_closid;
 +	int			cbm_len;
 +	int			min_cbm_bits;
 +	u32			max_cbm;
 +	int			data_width;
 +	struct list_head	domains;
 +	int			msr_base;
 +	int			cache_level;
 +	int			cbm_idx_multi;
 +	int			cbm_idx_offset;
 +};
 +
 +/**
++=======
++>>>>>>> 0921c54769ba (x86/intel_rdt: Add resource specific msr update function)
   * struct rdt_domain - group of cpus sharing an RDT resource
   * @list:	all instances of this resource
   * @id:		unique id for this instance
diff --cc arch/x86/kernel/cpu/intel_rdt.c
index ad087dd4421e,8486abe40c3f..000000000000
--- a/arch/x86/kernel/cpu/intel_rdt.c
+++ b/arch/x86/kernel/cpu/intel_rdt.c
@@@ -45,42 -43,59 +45,98 @@@ DEFINE_PER_CPU_READ_MOSTLY(int, cpu_clo
   */
  int max_name_width, max_data_width;
  
++<<<<<<< HEAD
 +struct rdt_resource rdt_resources_all[] = {
 +	{
 +		.name		= "L3",
 +		.domains	= domain_init(RDT_RESOURCE_L3),
 +		.msr_base	= IA32_L3_CBM_BASE,
 +		.min_cbm_bits	= 1,
 +		.cache_level	= 3,
 +		.cbm_idx_multi	= 1,
 +		.cbm_idx_offset	= 0
 +	},
 +	{
 +		.name		= "L3DATA",
 +		.domains	= domain_init(RDT_RESOURCE_L3DATA),
 +		.msr_base	= IA32_L3_CBM_BASE,
 +		.min_cbm_bits	= 1,
 +		.cache_level	= 3,
 +		.cbm_idx_multi	= 2,
 +		.cbm_idx_offset	= 0
 +	},
 +	{
 +		.name		= "L3CODE",
 +		.domains	= domain_init(RDT_RESOURCE_L3CODE),
 +		.msr_base	= IA32_L3_CBM_BASE,
 +		.min_cbm_bits	= 1,
 +		.cache_level	= 3,
 +		.cbm_idx_multi	= 2,
 +		.cbm_idx_offset	= 1
 +	},
 +	{
 +		.name		= "L2",
 +		.domains	= domain_init(RDT_RESOURCE_L2),
 +		.msr_base	= IA32_L2_CBM_BASE,
 +		.min_cbm_bits	= 1,
 +		.cache_level	= 2,
 +		.cbm_idx_multi	= 1,
 +		.cbm_idx_offset	= 0
++=======
+ static void
+ cat_wrmsr(struct rdt_domain *d, struct msr_param *m, struct rdt_resource *r);
+ 
+ #define domain_init(id) LIST_HEAD_INIT(rdt_resources_all[id].domains)
+ 
+ struct rdt_resource rdt_resources_all[] = {
+ 	{
+ 		.name			= "L3",
+ 		.domains		= domain_init(RDT_RESOURCE_L3),
+ 		.msr_base		= IA32_L3_CBM_BASE,
+ 		.msr_update		= cat_wrmsr,
+ 		.cache_level		= 3,
+ 		.cache = {
+ 			.min_cbm_bits	= 1,
+ 			.cbm_idx_mult	= 1,
+ 			.cbm_idx_offset	= 0,
+ 		},
+ 	},
+ 	{
+ 		.name			= "L3DATA",
+ 		.domains		= domain_init(RDT_RESOURCE_L3DATA),
+ 		.msr_base		= IA32_L3_CBM_BASE,
+ 		.msr_update		= cat_wrmsr,
+ 		.cache_level		= 3,
+ 		.cache = {
+ 			.min_cbm_bits	= 1,
+ 			.cbm_idx_mult	= 2,
+ 			.cbm_idx_offset	= 0,
+ 		},
+ 	},
+ 	{
+ 		.name			= "L3CODE",
+ 		.domains		= domain_init(RDT_RESOURCE_L3CODE),
+ 		.msr_base		= IA32_L3_CBM_BASE,
+ 		.msr_update		= cat_wrmsr,
+ 		.cache_level		= 3,
+ 		.cache = {
+ 			.min_cbm_bits	= 1,
+ 			.cbm_idx_mult	= 2,
+ 			.cbm_idx_offset	= 1,
+ 		},
+ 	},
+ 	{
+ 		.name			= "L2",
+ 		.domains		= domain_init(RDT_RESOURCE_L2),
+ 		.msr_base		= IA32_L2_CBM_BASE,
+ 		.msr_update		= cat_wrmsr,
+ 		.cache_level		= 2,
+ 		.cache = {
+ 			.min_cbm_bits	= 1,
+ 			.cbm_idx_mult	= 1,
+ 			.cbm_idx_offset	= 0,
+ 		},
++>>>>>>> 0921c54769ba (x86/intel_rdt: Add resource specific msr update function)
  	},
  };
  
@@@ -168,83 -183,44 +224,101 @@@ static void rdt_get_cdp_l3_config(int t
  	r->enabled = false;
  }
  
 -static int get_cache_id(int cpu, int level)
 +/**
 + * Choose a width for the resource name
 + * and resource data based on the resource that has
 + * widest name and cbm.
 + */
 +static void rdt_init_padding(void)
  {
 -	struct cpu_cacheinfo *ci = get_cpu_cacheinfo(cpu);
 -	int i;
 +	struct rdt_resource *r;
 +	int cl;
 +
 +	for_each_enabled_rdt_resource(r) {
 +		cl = strlen(r->name);
 +		if (cl > max_name_width)
 +			max_name_width = cl;
  
 -	for (i = 0; i < ci->num_leaves; i++) {
 -		if (ci->info_list[i].level == level)
 -			return ci->info_list[i].id;
 +		if (r->data_width > max_data_width)
 +			max_data_width = r->data_width;
  	}
 +}
 +
++<<<<<<< HEAD
 +static inline bool get_rdt_resources(void)
 +{
 +	bool ret = false;
 +
 +	if (cache_alloc_hsw_probe())
 +		return true;
 +
 +	if (!boot_cpu_has(X86_FEATURE_RDT_A))
 +		return false;
 +
 +	if (boot_cpu_has(X86_FEATURE_CAT_L3)) {
 +		rdt_get_config(1, &rdt_resources_all[RDT_RESOURCE_L3]);
 +		if (boot_cpu_has(X86_FEATURE_CDP_L3)) {
 +			rdt_get_cdp_l3_config(RDT_RESOURCE_L3DATA);
 +			rdt_get_cdp_l3_config(RDT_RESOURCE_L3CODE);
 +		}
 +		ret = true;
 +	}
 +	if (boot_cpu_has(X86_FEATURE_CAT_L2)) {
 +		/* CPUID 0x10.2 fields are same format at 0x10.1 */
 +		rdt_get_config(2, &rdt_resources_all[RDT_RESOURCE_L2]);
 +		ret = true;
 +	}
 +
 +	rdt_init_padding();
 +
 +	return ret;
 +}
  
 -	return -1;
 +static int get_cache_id(int cpu, int level)
 +{
 +	return get_cpu_cache_id(cpu, level);
  }
  
 +void rdt_cbm_update(void *arg)
++=======
+ static void
+ cat_wrmsr(struct rdt_domain *d, struct msr_param *m, struct rdt_resource *r)
+ {
+ 	unsigned int i;
+ 
+ 	for (i = m->low; i < m->high; i++)
+ 		wrmsrl(r->msr_base + cbm_idx(r, i), d->ctrl_val[i]);
+ }
+ 
+ void rdt_ctrl_update(void *arg)
++>>>>>>> 0921c54769ba (x86/intel_rdt: Add resource specific msr update function)
  {
- 	struct msr_param *m = (struct msr_param *)arg;
+ 	struct msr_param *m = arg;
  	struct rdt_resource *r = m->res;
- 	int i, cpu = smp_processor_id();
+ 	int cpu = smp_processor_id();
  	struct rdt_domain *d;
  
  	list_for_each_entry(d, &r->domains, list) {
  		/* Find the domain that contains this CPU */
- 		if (cpumask_test_cpu(cpu, &d->cpu_mask))
- 			goto found;
+ 		if (cpumask_test_cpu(cpu, &d->cpu_mask)) {
+ 			r->msr_update(d, m, r);
+ 			return;
+ 		}
  	}
- 	pr_info_once("cpu %d not found in any domain for resource %s\n",
+ 	pr_warn_once("cpu %d not found in any domain for resource %s\n",
  		     cpu, r->name);
++<<<<<<< HEAD
 +
 +	return;
 +
 +found:
 +	for (i = m->low; i < m->high; i++) {
 +		int idx = cbm_idx(r, i);
 +
 +		wrmsrl(r->msr_base + idx, d->cbm[i]);
 +	}
++=======
++>>>>>>> 0921c54769ba (x86/intel_rdt: Add resource specific msr update function)
  }
  
  /*
@@@ -293,9 -295,9 +393,9 @@@ static int domain_setup_ctrlval(struct 
   * in the schemata file and schemata input is validated to have the same order
   * as this list.
   */
 -static void domain_add_cpu(int cpu, struct rdt_resource *r)
 +static void domain_add_cpu(int cpu, struct rdt_resource *r, bool notifier)
  {
- 	int i, id = get_cache_id(cpu, r->cache_level);
+ 	int id = get_cache_id(cpu, r->cache_level);
  	struct list_head *add_pos = NULL;
  	struct rdt_domain *d;
  
@@@ -316,20 -318,11 +416,27 @@@
  
  	d->id = id;
  
++<<<<<<< HEAD
 +	d->cbm = kmalloc_array(r->num_closid, sizeof(*d->cbm), GFP_KERNEL);
 +	if (!d->cbm) {
++=======
+ 	if (domain_setup_ctrlval(r, d)) {
++>>>>>>> 0921c54769ba (x86/intel_rdt: Add resource specific msr update function)
  		kfree(d);
  		return;
  	}
  
++<<<<<<< HEAD
 +	for (i = 0; i < r->num_closid; i++) {
 +		int idx = cbm_idx(r, i);
 +
 +		d->cbm[i] = r->max_cbm;
 +		if (notifier)
 +			wrmsrl(r->msr_base + idx, d->cbm[i]);
 +	}
 +
++=======
++>>>>>>> 0921c54769ba (x86/intel_rdt: Add resource specific msr update function)
  	cpumask_set_cpu(cpu, &d->cpu_mask);
  	list_add_tail(&d->list, add_pos);
  }
* Unmerged path arch/x86/include/asm/intel_rdt.h
* Unmerged path arch/x86/kernel/cpu/intel_rdt.c
