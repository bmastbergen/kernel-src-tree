IB/hfi1: Clean up on context initialization failure

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Michael J. Ruhl <michael.j.ruhl@intel.com>
commit 62239fc6e5545b2e59f83dfbc5db231a81f37a45
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/62239fc6.failed

The error path for context initialization is not consistent. Cleanup all
resources on failure.

Removed unused variable user_event_mask.

Add the _BASE_FAILED bit to the event flags so that a base context can
notify waiting sub contexts that they cannot continue.

Running out of sub contexts is an EBUSY result, not EINVAL.

	Reviewed-by: Mike Marciniszyn <mike.marciniszyn@intel.com>
	Signed-off-by: Michael J. Ruhl <michael.j.ruhl@intel.com>
	Signed-off-by: Dennis Dalessandro <dennis.dalessandro@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 62239fc6e5545b2e59f83dfbc5db231a81f37a45)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/hfi1/file_ops.c
#	drivers/infiniband/hw/hfi1/hfi.h
#	drivers/infiniband/hw/hfi1/user_exp_rcv.c
#	drivers/infiniband/hw/hfi1/user_sdma.c
diff --cc drivers/infiniband/hw/hfi1/file_ops.c
index 32dd4a920494,3158128d57e8..000000000000
--- a/drivers/infiniband/hw/hfi1/file_ops.c
+++ b/drivers/infiniband/hw/hfi1/file_ops.c
@@@ -70,31 -71,37 +70,59 @@@
  /*
   * File operation functions
   */
 -static int hfi1_file_open(struct inode *inode, struct file *fp);
 -static int hfi1_file_close(struct inode *inode, struct file *fp);
 -static ssize_t hfi1_write_iter(struct kiocb *kiocb, struct iov_iter *from);
 -static unsigned int hfi1_poll(struct file *fp, struct poll_table_struct *pt);
 -static int hfi1_file_mmap(struct file *fp, struct vm_area_struct *vma);
 -
 +static int hfi1_file_open(struct inode *, struct file *);
 +static int hfi1_file_close(struct inode *, struct file *);
 +static ssize_t hfi1_aio_write(struct kiocb *, const struct iovec *,
 +			      unsigned long, loff_t);
 +static unsigned int hfi1_poll(struct file *, struct poll_table_struct *);
 +static int hfi1_file_mmap(struct file *, struct vm_area_struct *);
 +
++<<<<<<< HEAD
 +static u64 kvirt_to_phys(void *);
 +static int assign_ctxt(struct file *, struct hfi1_user_info *);
 +static int init_subctxts(struct hfi1_ctxtdata *, const struct hfi1_user_info *);
 +static int user_init(struct file *);
 +static int get_ctxt_info(struct file *, void __user *, __u32);
 +static int get_base_info(struct file *, void __user *, __u32);
 +static int setup_ctxt(struct file *);
 +static int setup_subctxt(struct hfi1_ctxtdata *);
 +static int get_user_context(struct file *, struct hfi1_user_info *, int);
 +static int find_shared_ctxt(struct file *, const struct hfi1_user_info *);
 +static int allocate_ctxt(struct file *, struct hfi1_devdata *,
 +			 struct hfi1_user_info *);
 +static unsigned int poll_urgent(struct file *, struct poll_table_struct *);
 +static unsigned int poll_next(struct file *, struct poll_table_struct *);
 +static int user_event_ack(struct hfi1_ctxtdata *, int, unsigned long);
 +static int set_ctxt_pkey(struct hfi1_ctxtdata *, unsigned, u16);
 +static int manage_rcvq(struct hfi1_ctxtdata *, unsigned, int);
 +static int vma_fault(struct vm_area_struct *, struct vm_fault *);
++=======
+ static u64 kvirt_to_phys(void *addr);
+ static int assign_ctxt(struct hfi1_filedata *fd, struct hfi1_user_info *uinfo);
+ static int init_subctxts(struct hfi1_ctxtdata *uctxt,
+ 			 const struct hfi1_user_info *uinfo);
+ static int init_user_ctxt(struct hfi1_filedata *fd);
+ static void user_init(struct hfi1_ctxtdata *uctxt);
+ static int get_ctxt_info(struct hfi1_filedata *fd, void __user *ubase,
+ 			 __u32 len);
+ static int get_base_info(struct hfi1_filedata *fd, void __user *ubase,
+ 			 __u32 len);
+ static int setup_base_ctxt(struct hfi1_filedata *fd);
+ static int setup_subctxt(struct hfi1_ctxtdata *uctxt);
+ 
+ static int find_sub_ctxt(struct hfi1_filedata *fd,
+ 			 const struct hfi1_user_info *uinfo);
+ static int allocate_ctxt(struct hfi1_filedata *fd, struct hfi1_devdata *dd,
+ 			 struct hfi1_user_info *uinfo);
+ static unsigned int poll_urgent(struct file *fp, struct poll_table_struct *pt);
+ static unsigned int poll_next(struct file *fp, struct poll_table_struct *pt);
+ static int user_event_ack(struct hfi1_ctxtdata *uctxt, u16 subctxt,
+ 			  unsigned long events);
+ static int set_ctxt_pkey(struct hfi1_ctxtdata *uctxt, u16 subctxt, u16 pkey);
+ static int manage_rcvq(struct hfi1_ctxtdata *uctxt, u16 subctxt,
+ 		       int start_stop);
+ static int vma_fault(struct vm_fault *vmf);
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  static long hfi1_file_ioctl(struct file *fp, unsigned int cmd,
  			    unsigned long arg);
  
@@@ -840,9 -845,9 +868,13 @@@ static u64 kvirt_to_phys(void *addr
  	return paddr;
  }
  
 -static int assign_ctxt(struct hfi1_filedata *fd, struct hfi1_user_info *uinfo)
 +static int assign_ctxt(struct file *fp, struct hfi1_user_info *uinfo)
  {
++<<<<<<< HEAD
 +	int i_minor, ret = 0;
++=======
+ 	int ret;
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  	unsigned int swmajor, swminor;
  
  	swmajor = uinfo->userversion >> 16;
@@@ -854,113 -857,123 +886,194 @@@
  	swminor = uinfo->userversion & 0xffff;
  
  	mutex_lock(&hfi1_mutex);
++<<<<<<< HEAD
 +	/* First, lets check if we need to setup a shared context? */
 +	if (uinfo->subctxt_cnt) {
 +		struct hfi1_filedata *fd = fp->private_data;
 +
 +		ret = find_shared_ctxt(fp, uinfo);
 +		if (ret < 0)
 +			goto done_unlock;
 +		if (ret) {
++=======
+ 	/*
+ 	 * Get a sub context if necessary.
+ 	 * ret < 0 error, 0 no context, 1 sub-context found
+ 	 */
+ 	ret = 0;
+ 	if (uinfo->subctxt_cnt) {
+ 		ret = find_sub_ctxt(fd, uinfo);
+ 		if (ret > 0)
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  			fd->rec_cpu_num =
  				hfi1_get_proc_affinity(fd->uctxt->numa_id);
- 		}
  	}
  
  	/*
 -	 * Allocate a base context if context sharing is not required or we
 -	 * couldn't find a sub context.
 +	 * We execute the following block if we couldn't find a
 +	 * shared context or if context sharing is not required.
  	 */
++<<<<<<< HEAD
 +	if (!ret) {
 +		i_minor = iminor(file_inode(fp)) - HFI1_USER_MINOR_BASE;
 +		ret = get_user_context(fp, uinfo, i_minor);
++=======
+ 	if (!ret)
+ 		ret = allocate_ctxt(fd, fd->dd, uinfo);
+ 
+ 	mutex_unlock(&hfi1_mutex);
+ 
+ 	/* Depending on the context type, do the appropriate init */
+ 	if (ret > 0) {
+ 		/*
+ 		 * sub-context info can only be set up after the base
+ 		 * context has been completed.
+ 		 */
+ 		ret = wait_event_interruptible(fd->uctxt->wait, !test_bit(
+ 					       HFI1_CTXT_BASE_UNINIT,
+ 					       &fd->uctxt->event_flags));
+ 		if (test_bit(HFI1_CTXT_BASE_FAILED, &fd->uctxt->event_flags)) {
+ 			clear_bit(fd->subctxt, fd->uctxt->in_use_ctxts);
+ 			return -ENOMEM;
+ 		}
+ 		/* The only thing a sub context needs is the user_xxx stuff */
+ 		if (!ret)
+ 			ret = init_user_ctxt(fd);
+ 
+ 		if (ret)
+ 			clear_bit(fd->subctxt, fd->uctxt->in_use_ctxts);
+ 	} else if (!ret) {
+ 		ret = setup_base_ctxt(fd);
+ 		if (fd->uctxt->subctxt_cnt) {
+ 			/* If there is an error, set the failed bit. */
+ 			if (ret)
+ 				set_bit(HFI1_CTXT_BASE_FAILED,
+ 					&fd->uctxt->event_flags);
+ 			/*
+ 			 * Base context is done, notify anybody using a
+ 			 * sub-context that is waiting for this completion
+ 			 */
+ 			clear_bit(HFI1_CTXT_BASE_UNINIT,
+ 				  &fd->uctxt->event_flags);
+ 			wake_up(&fd->uctxt->wait);
+ 		}
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  	}
 -
 +done_unlock:
 +	mutex_unlock(&hfi1_mutex);
 +done:
  	return ret;
  }
  
 -/*
 - * The hfi1_mutex must be held when this function is called.  It is
 - * necessary to ensure serialized access to the bitmask in_use_ctxts.
 - */
 -static int find_sub_ctxt(struct hfi1_filedata *fd,
 -			 const struct hfi1_user_info *uinfo)
 +static int get_user_context(struct file *fp, struct hfi1_user_info *uinfo,
 +			    int devno)
  {
 -	int i;
 -	struct hfi1_devdata *dd = fd->dd;
 -	u16 subctxt;
 +	struct hfi1_devdata *dd = NULL;
 +	int devmax, npresent, nup;
  
 -	for (i = dd->first_dyn_alloc_ctxt; i < dd->num_rcv_contexts; i++) {
 -		struct hfi1_ctxtdata *uctxt = dd->rcd[i];
 +	devmax = hfi1_count_units(&npresent, &nup);
 +	if (!npresent)
 +		return -ENXIO;
  
 -		/* Skip ctxts which are not yet open */
 -		if (!uctxt ||
 -		    bitmap_empty(uctxt->in_use_ctxts,
 -				 HFI1_MAX_SHARED_CTXTS))
 -			continue;
 +	if (!nup)
 +		return -ENETDOWN;
  
 -		/* Skip dynamically allocted kernel contexts */
 -		if (uctxt->sc && (uctxt->sc->type == SC_KERNEL))
 -			continue;
 +	dd = hfi1_lookup(devno);
 +	if (!dd)
 +		return -ENODEV;
 +	else if (!dd->freectxts)
 +		return -EBUSY;
  
++<<<<<<< HEAD
 +	return allocate_ctxt(fp, dd, uinfo);
++=======
+ 		/* Skip ctxt if it doesn't match the requested one */
+ 		if (memcmp(uctxt->uuid, uinfo->uuid,
+ 			   sizeof(uctxt->uuid)) ||
+ 		    uctxt->jkey != generate_jkey(current_uid()) ||
+ 		    uctxt->subctxt_id != uinfo->subctxt_id ||
+ 		    uctxt->subctxt_cnt != uinfo->subctxt_cnt)
+ 			continue;
+ 
+ 		/* Verify the sharing process matches the master */
+ 		if (uctxt->userversion != uinfo->userversion)
+ 			return -EINVAL;
+ 
+ 		/* Find an unused context */
+ 		subctxt = find_first_zero_bit(uctxt->in_use_ctxts,
+ 					      HFI1_MAX_SHARED_CTXTS);
+ 		if (subctxt >= uctxt->subctxt_cnt)
+ 			return -EBUSY;
+ 
+ 		fd->uctxt = uctxt;
+ 		fd->subctxt = subctxt;
+ 		__set_bit(fd->subctxt, uctxt->in_use_ctxts);
+ 
+ 		return 1;
+ 	}
+ 
+ 	return 0;
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  }
  
 -static int allocate_ctxt(struct hfi1_filedata *fd, struct hfi1_devdata *dd,
 +static int find_shared_ctxt(struct file *fp,
 +			    const struct hfi1_user_info *uinfo)
 +{
 +	int devmax, ndev, i;
 +	int ret = 0;
 +	struct hfi1_filedata *fd = fp->private_data;
 +
 +	devmax = hfi1_count_units(NULL, NULL);
 +
 +	for (ndev = 0; ndev < devmax; ndev++) {
 +		struct hfi1_devdata *dd = hfi1_lookup(ndev);
 +
 +		if (!(dd && (dd->flags & HFI1_PRESENT) && dd->kregbase))
 +			continue;
 +		for (i = dd->first_dyn_alloc_ctxt;
 +		     i < dd->num_rcv_contexts; i++) {
 +			struct hfi1_ctxtdata *uctxt = dd->rcd[i];
 +
 +			/* Skip ctxts which are not yet open */
 +			if (!uctxt || !uctxt->cnt)
 +				continue;
 +
 +			/* Skip dynamically allocted kernel contexts */
 +			if (uctxt->sc && (uctxt->sc->type == SC_KERNEL))
 +				continue;
 +
 +			/* Skip ctxt if it doesn't match the requested one */
 +			if (memcmp(uctxt->uuid, uinfo->uuid,
 +				   sizeof(uctxt->uuid)) ||
 +			    uctxt->jkey != generate_jkey(current_uid()) ||
 +			    uctxt->subctxt_id != uinfo->subctxt_id ||
 +			    uctxt->subctxt_cnt != uinfo->subctxt_cnt)
 +				continue;
 +
 +			/* Verify the sharing process matches the master */
 +			if (uctxt->userversion != uinfo->userversion ||
 +			    uctxt->cnt >= uctxt->subctxt_cnt) {
 +				ret = -EINVAL;
 +				goto done;
 +			}
 +			fd->uctxt = uctxt;
 +			fd->subctxt  = uctxt->cnt++;
 +			uctxt->active_slaves |= 1 << fd->subctxt;
 +			ret = 1;
 +			goto done;
 +		}
 +	}
 +
 +done:
 +	return ret;
 +}
 +
 +static int allocate_ctxt(struct file *fp, struct hfi1_devdata *dd,
  			 struct hfi1_user_info *uinfo)
  {
 +	struct hfi1_filedata *fd = fp->private_data;
  	struct hfi1_ctxtdata *uctxt;
 -	unsigned int ctxt;
 +	unsigned ctxt;
  	int ret, numa;
  
  	if (dd->flags & HFI1_FROZEN) {
@@@ -1108,15 -1130,9 +1221,19 @@@ bail
  	return ret;
  }
  
++<<<<<<< HEAD
 +static int user_init(struct file *fp)
++=======
+ static void user_init(struct hfi1_ctxtdata *uctxt)
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  {
  	unsigned int rcvctrl_ops = 0;
 +	struct hfi1_filedata *fd = fp->private_data;
 +	struct hfi1_ctxtdata *uctxt = fd->uctxt;
 +
 +	/* make sure that the context has already been setup */
 +	if (!test_bit(HFI1_CTXT_SETUP_DONE, &uctxt->event_flags))
 +		return -EFAULT;
  
  	/* initialize poll variables... */
  	uctxt->urgent = 0;
@@@ -1164,20 -1180,12 +1281,23 @@@
  	else
  		rcvctrl_ops |= HFI1_RCVCTRL_TAILUPD_DIS;
  	hfi1_rcvctrl(uctxt->dd, rcvctrl_ops, uctxt->ctxt);
++<<<<<<< HEAD
 +
 +	/* Notify any waiting slaves */
 +	if (uctxt->subctxt_cnt) {
 +		clear_bit(HFI1_CTXT_MASTER_UNINIT, &uctxt->event_flags);
 +		wake_up(&uctxt->wait);
 +	}
 +
 +	return 0;
++=======
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  }
  
 -static int get_ctxt_info(struct hfi1_filedata *fd, void __user *ubase,
 -			 __u32 len)
 +static int get_ctxt_info(struct file *fp, void __user *ubase, __u32 len)
  {
  	struct hfi1_ctxt_info cinfo;
 +	struct hfi1_filedata *fd = fp->private_data;
  	struct hfi1_ctxtdata *uctxt = fd->uctxt;
  	int ret = 0;
  
@@@ -1222,54 -1243,37 +1342,81 @@@ static int setup_ctxt(struct file *fp
  	struct hfi1_devdata *dd = uctxt->dd;
  	int ret = 0;
  
 -	hfi1_init_ctxt(uctxt->sc);
 +	/*
 +	 * Context should be set up only once, including allocation and
 +	 * programming of eager buffers. This is done if context sharing
 +	 * is not requested or by the master process.
 +	 */
 +	if (!uctxt->subctxt_cnt || !fd->subctxt) {
 +		ret = hfi1_init_ctxt(uctxt->sc);
 +		if (ret)
 +			goto done;
 +
 +		/* Now allocate the RcvHdr queue and eager buffers. */
 +		ret = hfi1_create_rcvhdrq(dd, uctxt);
 +		if (ret)
 +			goto done;
 +		ret = hfi1_setup_eagerbufs(uctxt);
 +		if (ret)
 +			goto done;
 +		if (uctxt->subctxt_cnt && !fd->subctxt) {
 +			ret = setup_subctxt(uctxt);
 +			if (ret)
 +				goto done;
 +		}
 +	} else {
 +		ret = wait_event_interruptible(uctxt->wait, !test_bit(
 +					       HFI1_CTXT_MASTER_UNINIT,
 +					       &uctxt->event_flags));
 +		if (ret)
 +			goto done;
 +	}
  
 -	/* Now allocate the RcvHdr queue and eager buffers. */
 -	ret = hfi1_create_rcvhdrq(dd, uctxt);
 +	ret = hfi1_user_sdma_alloc_queues(uctxt, fp);
 +	if (ret)
 +		goto done;
 +	/*
 +	 * Expected receive has to be setup for all processes (including
 +	 * shared contexts). However, it has to be done after the master
 +	 * context has been fully configured as it depends on the
 +	 * eager/expected split of the RcvArray entries.
 +	 * Setting it up here ensures that the subcontexts will be waiting
 +	 * (due to the above wait_event_interruptible() until the master
 +	 * is setup.
 +	 */
 +	ret = hfi1_user_exp_rcv_init(fp);
  	if (ret)
- 		goto done;
+ 		return ret;
  
++<<<<<<< HEAD
 +	set_bit(HFI1_CTXT_SETUP_DONE, &uctxt->event_flags);
 +done:
++=======
+ 	ret = hfi1_setup_eagerbufs(uctxt);
+ 	if (ret)
+ 		goto setup_failed;
+ 
+ 	/* If sub-contexts are enabled, do the appropriate setup */
+ 	if (uctxt->subctxt_cnt)
+ 		ret = setup_subctxt(uctxt);
+ 	if (ret)
+ 		goto setup_failed;
+ 
+ 	ret = hfi1_user_exp_rcv_grp_init(fd);
+ 	if (ret)
+ 		goto setup_failed;
+ 
+ 	ret = init_user_ctxt(fd);
+ 	if (ret)
+ 		goto setup_failed;
+ 
+ 	user_init(uctxt);
+ 
+ 	return 0;
+ 
+ setup_failed:
+ 	hfi1_free_ctxtdata(dd, uctxt);
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  	return ret;
  }
  
diff --cc drivers/infiniband/hw/hfi1/hfi.h
index b1aefd5ddffe,509df984a09f..000000000000
--- a/drivers/infiniband/hw/hfi1/hfi.h
+++ b/drivers/infiniband/hw/hfi1/hfi.h
@@@ -1733,19 -1718,19 +1727,28 @@@ struct cc_state *get_cc_state_protected
  #define HFI1_PBC_LENGTH_MASK                     ((1 << 11) - 1)
  
  /* ctxt_flag bit offsets */
++<<<<<<< HEAD
 +		/* context has been setup */
 +#define HFI1_CTXT_SETUP_DONE 1
 +		/* waiting for a packet to arrive */
 +#define HFI1_CTXT_WAITING_RCV   2
 +		/* master has not finished initializing */
 +#define HFI1_CTXT_MASTER_UNINIT 4
++=======
+ 		/* base context has not finished initializing */
+ #define HFI1_CTXT_BASE_UNINIT 1
+ 		/* base context initaliation failed */
+ #define HFI1_CTXT_BASE_FAILED 2
+ 		/* waiting for a packet to arrive */
+ #define HFI1_CTXT_WAITING_RCV 3
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  		/* waiting for an urgent packet to arrive */
- #define HFI1_CTXT_WAITING_URG 5
+ #define HFI1_CTXT_WAITING_URG 4
  
  /* free up any allocated data at closes */
 -struct hfi1_devdata *hfi1_init_dd(struct pci_dev *pdev,
 -				  const struct pci_device_id *ent);
 -void hfi1_free_devdata(struct hfi1_devdata *dd);
 +struct hfi1_devdata *hfi1_init_dd(struct pci_dev *,
 +				  const struct pci_device_id *);
 +void hfi1_free_devdata(struct hfi1_devdata *);
  struct hfi1_devdata *hfi1_alloc_devdata(struct pci_dev *pdev, size_t extra);
  
  /* LED beaconing functions */
diff --cc drivers/infiniband/hw/hfi1/user_exp_rcv.c
index c7f13df471c4,a8f0aa4722f6..000000000000
--- a/drivers/infiniband/hw/hfi1/user_exp_rcv.c
+++ b/drivers/infiniband/hw/hfi1/user_exp_rcv.c
@@@ -149,6 -154,43 +149,46 @@@ static inline void tid_group_move(struc
  	tid_group_add_tail(group, s2);
  }
  
++<<<<<<< HEAD
++=======
+ int hfi1_user_exp_rcv_grp_init(struct hfi1_filedata *fd)
+ {
+ 	struct hfi1_ctxtdata *uctxt = fd->uctxt;
+ 	struct hfi1_devdata *dd = fd->dd;
+ 	u32 tidbase;
+ 	u32 i;
+ 	struct tid_group *grp, *gptr;
+ 
+ 	exp_tid_group_init(&uctxt->tid_group_list);
+ 	exp_tid_group_init(&uctxt->tid_used_list);
+ 	exp_tid_group_init(&uctxt->tid_full_list);
+ 
+ 	tidbase = uctxt->expected_base;
+ 	for (i = 0; i < uctxt->expected_count /
+ 		     dd->rcv_entries.group_size; i++) {
+ 		grp = kzalloc(sizeof(*grp), GFP_KERNEL);
+ 		if (!grp)
+ 			goto grp_failed;
+ 
+ 		grp->size = dd->rcv_entries.group_size;
+ 		grp->base = tidbase;
+ 		tid_group_add_tail(grp, &uctxt->tid_group_list);
+ 		tidbase += dd->rcv_entries.group_size;
+ 	}
+ 
+ 	return 0;
+ 
+ grp_failed:
+ 	list_for_each_entry_safe(grp, gptr, &uctxt->tid_group_list.list,
+ 				 list) {
+ 		list_del_init(&grp->list);
+ 		kfree(grp);
+ 	}
+ 
+ 	return -ENOMEM;
+ }
+ 
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  /*
   * Initialize context and file private data needed for Expected
   * receive caching. This needs to be done after the context has
@@@ -204,8 -217,9 +244,14 @@@ int hfi1_user_exp_rcv_init(struct file 
  					   sizeof(*fd->invalid_tids),
  					   GFP_KERNEL);
  		if (!fd->invalid_tids) {
++<<<<<<< HEAD
 +			ret = -ENOMEM;
 +			goto done;
++=======
+ 			kfree(fd->entry_to_rb);
+ 			fd->entry_to_rb = NULL;
+ 			return -ENOMEM;
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  		}
  
  		/*
diff --cc drivers/infiniband/hw/hfi1/user_sdma.c
index 6387a75dc8ba,d55339f5d73b..000000000000
--- a/drivers/infiniband/hw/hfi1/user_sdma.c
+++ b/drivers/infiniband/hw/hfi1/user_sdma.c
@@@ -369,27 -371,21 +369,39 @@@ static void sdma_kmem_cache_ctor(void *
  	memset(tx, 0, sizeof(*tx));
  }
  
 -int hfi1_user_sdma_alloc_queues(struct hfi1_ctxtdata *uctxt,
 -				struct hfi1_filedata *fd)
 +int hfi1_user_sdma_alloc_queues(struct hfi1_ctxtdata *uctxt, struct file *fp)
  {
++<<<<<<< HEAD
 +	struct hfi1_filedata *fd;
 +	int ret = 0;
++=======
+ 	int ret = -ENOMEM;
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  	char buf[64];
  	struct hfi1_devdata *dd;
  	struct hfi1_user_sdma_comp_q *cq;
  	struct hfi1_user_sdma_pkt_q *pq;
  	unsigned long flags;
  
++<<<<<<< HEAD
 +	if (!uctxt || !fp) {
 +		ret = -EBADF;
 +		goto done;
 +	}
 +
 +	fd = fp->private_data;
 +
 +	if (!hfi1_sdma_comp_ring_size) {
 +		ret = -EINVAL;
 +		goto done;
 +	}
++=======
+ 	if (!uctxt || !fd)
+ 		return -EBADF;
+ 
+ 	if (!hfi1_sdma_comp_ring_size)
+ 		return -EINVAL;
++>>>>>>> 62239fc6e554 (IB/hfi1: Clean up on context initialization failure)
  
  	dd = uctxt->dd;
  
* Unmerged path drivers/infiniband/hw/hfi1/file_ops.c
* Unmerged path drivers/infiniband/hw/hfi1/hfi.h
diff --git a/drivers/infiniband/hw/hfi1/init.c b/drivers/infiniband/hw/hfi1/init.c
index d1e1227c533d..7554331da67e 100644
--- a/drivers/infiniband/hw/hfi1/init.c
+++ b/drivers/infiniband/hw/hfi1/init.c
@@ -969,7 +969,6 @@ void hfi1_free_ctxtdata(struct hfi1_devdata *dd, struct hfi1_ctxtdata *rcd)
 	kfree(rcd->egrbufs.buffers);
 
 	sc_free(rcd->sc);
-	vfree(rcd->user_event_mask);
 	vfree(rcd->subctxt_uregbase);
 	vfree(rcd->subctxt_rcvegrbuf);
 	vfree(rcd->subctxt_rcvhdr_base);
@@ -1688,8 +1687,6 @@ bail_free:
 	dd_dev_err(dd,
 		   "attempt to allocate 1 page for ctxt %u rcvhdrqtailaddr failed\n",
 		   rcd->ctxt);
-	vfree(rcd->user_event_mask);
-	rcd->user_event_mask = NULL;
 	dma_free_coherent(&dd->pcidev->dev, amt, rcd->rcvhdrq,
 			  rcd->rcvhdrq_dma);
 	rcd->rcvhdrq = NULL;
@@ -1856,7 +1853,7 @@ int hfi1_setup_eagerbufs(struct hfi1_ctxtdata *rcd)
 			  "ctxt%u: current Eager buffer size is invalid %u\n",
 			  rcd->ctxt, rcd->egrbufs.rcvtid_size);
 		ret = -EINVAL;
-		goto bail;
+		goto bail_rcvegrbuf_phys;
 	}
 
 	for (idx = 0; idx < rcd->egrbufs.alloced; idx++) {
@@ -1864,7 +1861,8 @@ int hfi1_setup_eagerbufs(struct hfi1_ctxtdata *rcd)
 			     rcd->egrbufs.rcvtids[idx].dma, order);
 		cond_resched();
 	}
-	goto bail;
+
+	return 0;
 
 bail_rcvegrbuf_phys:
 	for (idx = 0; idx < rcd->egrbufs.alloced &&
@@ -1878,6 +1876,6 @@ bail_rcvegrbuf_phys:
 		rcd->egrbufs.buffers[idx].dma = 0;
 		rcd->egrbufs.buffers[idx].len = 0;
 	}
-bail:
+
 	return ret;
 }
* Unmerged path drivers/infiniband/hw/hfi1/user_exp_rcv.c
* Unmerged path drivers/infiniband/hw/hfi1/user_sdma.c
