hv_netvsc: fix send buffer failure on MTU change

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Alex Ng <alexng@microsoft.com>
commit 0ab09befdbb7ca9b969d6206108629ddff43876e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/0ab09bef.failed

If MTU is changed the host would reject the send buffer change.
This problem is result of recent change to allow changing send
buffer size.

Every time we change the MTU, we store the previous net_device section
count before destroying the buffer, but we donâ€™t store the previous
section size. When we reinitialize the buffer, its size is calculated
by multiplying the previous count and previous size. Since we
continuously increase the MTU, the host returns us a decreasing count
value while the section size is reinitialized to 1728 bytes every
time.

This eventually leads to a condition where the calculated buf_size is
so small that the host rejects it.

Fixes: 8b5327975ae1 ("netvsc: allow controlling send/recv buffer size")
	Signed-off-by: Alex Ng <alexng@microsoft.com>
	Signed-off-by: Stephen Hemminger <sthemmin@microsoft.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 0ab09befdbb7ca9b969d6206108629ddff43876e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/hyperv/hyperv_net.h
#	drivers/net/hyperv/netvsc.c
#	drivers/net/hyperv/netvsc_drv.c
diff --cc drivers/net/hyperv/hyperv_net.h
index a32d7f1b2505,5176be76ca7d..000000000000
--- a/drivers/net/hyperv/hyperv_net.h
+++ b/drivers/net/hyperv/hyperv_net.h
@@@ -146,10 -146,12 +146,17 @@@ struct hv_netvsc_packet 
  
  struct netvsc_device_info {
  	unsigned char mac_adr[ETH_ALEN];
 +	bool link_state;	/* 0 - link up, 1 - link down */
  	int  ring_size;
 +	u32  max_num_vrss_chns;
  	u32  num_chn;
++<<<<<<< HEAD
++=======
+ 	u32  send_sections;
+ 	u32  recv_sections;
+ 	u32  send_section_size;
+ 	u32  recv_section_size;
++>>>>>>> 0ab09befdbb7 (hv_netvsc: fix send buffer failure on MTU change)
  };
  
  enum rndis_device_state {
diff --cc drivers/net/hyperv/netvsc.c
index cbd02a283e6e,8d5077fb0492..000000000000
--- a/drivers/net/hyperv/netvsc.c
+++ b/drivers/net/hyperv/netvsc.c
@@@ -83,7 -75,10 +83,11 @@@ static struct netvsc_device *alloc_net_
  	atomic_set(&net_device->open_cnt, 0);
  	net_device->max_pkt = RNDIS_MAX_PKT_DEFAULT;
  	net_device->pkt_align = RNDIS_PKT_ALIGN_DEFAULT;
++<<<<<<< HEAD
++=======
+ 
++>>>>>>> 0ab09befdbb7 (hv_netvsc: fix send buffer failure on MTU change)
  	init_completion(&net_device->channel_init_wait);
 -	init_waitqueue_head(&net_device->subchan_open);
 -	INIT_WORK(&net_device->subchan_work, rndis_set_subchannel);
  
  	return net_device;
  }
@@@ -261,25 -233,40 +265,31 @@@ static void netvsc_destroy_buf(struct h
  	kfree(net_device->send_section_map);
  }
  
 -int netvsc_alloc_recv_comp_ring(struct netvsc_device *net_device, u32 q_idx)
 -{
 -	struct netvsc_channel *nvchan = &net_device->chan_table[q_idx];
 -	int node = cpu_to_node(nvchan->channel->target_cpu);
 -	size_t size;
 -
 -	size = net_device->recv_completion_cnt * sizeof(struct recv_comp_data);
 -	nvchan->mrc.slots = vzalloc_node(size, node);
 -	if (!nvchan->mrc.slots)
 -		nvchan->mrc.slots = vzalloc(size);
 -
 -	return nvchan->mrc.slots ? 0 : -ENOMEM;
 -}
 -
  static int netvsc_init_buf(struct hv_device *device,
 -			   struct netvsc_device *net_device,
 -			   const struct netvsc_device_info *device_info)
 +			   struct netvsc_device *net_device)
  {
 -	struct nvsp_1_message_send_receive_buffer_complete *resp;
 -	struct net_device *ndev = hv_get_drvdata(device);
 +	int ret = 0;
  	struct nvsp_message *init_packet;
 -	unsigned int buf_size;
 +	struct net_device *ndev;
  	size_t map_words;
 -	int ret = 0;
 +	int node;
 +
++<<<<<<< HEAD
 +	ndev = hv_get_drvdata(device);
  
 +	node = cpu_to_node(device->channel->target_cpu);
 +	net_device->recv_buf = vzalloc_node(net_device->recv_buf_size, node);
 +	if (!net_device->recv_buf)
 +		net_device->recv_buf = vzalloc(net_device->recv_buf_size);
++=======
+ 	/* Get receive buffer area. */
+ 	buf_size = device_info->recv_sections * device_info->recv_section_size;
+ 	buf_size = roundup(buf_size, PAGE_SIZE);
++>>>>>>> 0ab09befdbb7 (hv_netvsc: fix send buffer failure on MTU change)
  
 -	net_device->recv_buf = vzalloc(buf_size);
  	if (!net_device->recv_buf) {
 -		netdev_err(ndev,
 -			   "unable to allocate receive buffer of size %u\n",
 -			   buf_size);
 +		netdev_err(ndev, "unable to allocate receive "
 +			"buffer of size %d\n", net_device->recv_buf_size);
  		ret = -ENOMEM;
  		goto cleanup;
  	}
@@@ -347,24 -329,25 +357,32 @@@
  		goto cleanup;
  	}
  
 -	net_device->recv_section_size = resp->sections[0].sub_alloc_size;
 -	net_device->recv_section_cnt = resp->sections[0].num_sub_allocs;
 -
 -	/* Setup receive completion ring */
 -	net_device->recv_completion_cnt
 -		= round_up(net_device->recv_section_cnt + 1,
 -			   PAGE_SIZE / sizeof(u64));
 -	ret = netvsc_alloc_recv_comp_ring(net_device, 0);
 -	if (ret)
 +	/*
 +	 * For 1st release, there should only be 1 section that represents the
 +	 * entire receive buffer
 +	 */
 +	if (net_device->recv_section_cnt != 1 ||
 +	    net_device->recv_section->offset != 0) {
 +		ret = -EINVAL;
  		goto cleanup;
 +	}
  
++<<<<<<< HEAD
 +	/* Now setup the send buffer.
 +	 */
 +	net_device->send_buf = vzalloc_node(net_device->send_buf_size, node);
 +	if (!net_device->send_buf)
 +		net_device->send_buf = vzalloc(net_device->send_buf_size);
++=======
+ 	/* Now setup the send buffer. */
+ 	buf_size = device_info->send_sections * device_info->send_section_size;
+ 	buf_size = round_up(buf_size, PAGE_SIZE);
+ 
+ 	net_device->send_buf = vzalloc(buf_size);
++>>>>>>> 0ab09befdbb7 (hv_netvsc: fix send buffer failure on MTU change)
  	if (!net_device->send_buf) {
 -		netdev_err(ndev, "unable to allocate send buffer of size %u\n",
 -			   buf_size);
 +		netdev_err(ndev, "unable to allocate send "
 +			   "buffer of size %d\n", net_device->send_buf_size);
  		ret = -ENOMEM;
  		goto cleanup;
  	}
diff --cc drivers/net/hyperv/netvsc_drv.c
index 5103dca8a92e,a32ae02e1b6c..000000000000
--- a/drivers/net/hyperv/netvsc_drv.c
+++ b/drivers/net/hyperv/netvsc_drv.c
@@@ -739,84 -819,57 +739,117 @@@ static int netvsc_set_channels(struct n
  {
  	struct net_device_context *net_device_ctx = netdev_priv(net);
  	struct hv_device *dev = net_device_ctx->device_ctx;
 -	struct netvsc_device *nvdev = rtnl_dereference(net_device_ctx->nvdev);
 -	unsigned int orig, count = channels->combined_count;
 +	struct netvsc_device *nvdev = net_device_ctx->nvdev;
  	struct netvsc_device_info device_info;
 -	bool was_opened;
 +	u32 num_chn;
 +	u32 max_chn;
  	int ret = 0;
 +	bool recovering = false;
  
 -	/* We do not support separate count for rx, tx, or other */
 -	if (count == 0 ||
 -	    channels->rx_count || channels->tx_count || channels->other_count)
 -		return -EINVAL;
 -
 -	if (!nvdev || nvdev->destroy)
 +	if (net_device_ctx->start_remove || !nvdev || nvdev->destroy)
  		return -ENODEV;
  
 -	if (nvdev->nvsp_version < NVSP_PROTOCOL_VERSION_5)
 +	num_chn = nvdev->num_chn;
 +	max_chn = min_t(u32, nvdev->max_chn, num_online_cpus());
 +
 +	if (nvdev->nvsp_version < NVSP_PROTOCOL_VERSION_5) {
 +		pr_info("vRSS unsupported before NVSP Version 5\n");
  		return -EINVAL;
++<<<<<<< HEAD
++=======
+ 
+ 	if (count > nvdev->max_chn)
+ 		return -EINVAL;
+ 
+ 	orig = nvdev->num_chn;
+ 	was_opened = rndis_filter_opened(nvdev);
+ 	if (was_opened)
+ 		rndis_filter_close(nvdev);
+ 
+ 	memset(&device_info, 0, sizeof(device_info));
+ 	device_info.num_chn = count;
+ 	device_info.ring_size = ring_size;
+ 	device_info.send_sections = nvdev->send_section_cnt;
+ 	device_info.send_section_size = nvdev->send_section_size;
+ 	device_info.recv_sections = nvdev->recv_section_cnt;
+ 	device_info.recv_section_size = nvdev->recv_section_size;
+ 
+ 	rndis_filter_device_remove(dev, nvdev);
+ 
+ 	nvdev = rndis_filter_device_add(dev, &device_info);
+ 	if (IS_ERR(nvdev)) {
+ 		ret = PTR_ERR(nvdev);
+ 		device_info.num_chn = orig;
+ 		nvdev = rndis_filter_device_add(dev, &device_info);
+ 
+ 		if (IS_ERR(nvdev)) {
+ 			netdev_err(net, "restoring channel setting failed: %ld\n",
+ 				   PTR_ERR(nvdev));
+ 			return ret;
+ 		}
++>>>>>>> 0ab09befdbb7 (hv_netvsc: fix send buffer failure on MTU change)
  	}
  
 -	if (was_opened)
 -		rndis_filter_open(nvdev);
 +	/* We do not support rx, tx, or other */
 +	if (!channels ||
 +	    channels->rx_count ||
 +	    channels->tx_count ||
 +	    channels->other_count ||
 +	    (channels->combined_count < 1))
 +		return -EINVAL;
 +
 +	if (channels->combined_count > max_chn) {
 +		pr_info("combined channels too high, using %d\n", max_chn);
 +		channels->combined_count = max_chn;
 +	}
 +
 +	ret = netvsc_close(net);
 +	if (ret)
 +		goto out;
 +
 + do_set:
 +	net_device_ctx->start_remove = true;
 +	rndis_filter_device_remove(dev);
 +
 +	nvdev->num_chn = channels->combined_count;
 +
 +	memset(&device_info, 0, sizeof(device_info));
 +	device_info.num_chn = nvdev->num_chn; /* passed to RNDIS */
 +	device_info.ring_size = ring_size;
 +	device_info.max_num_vrss_chns = max_num_vrss_chns;
 +
 +	ret = rndis_filter_device_add(dev, &device_info);
 +	if (ret) {
 +		if (recovering) {
 +			netdev_err(net, "unable to add netvsc device (ret %d)\n", ret);
 +			return ret;
 +		}
 +		goto recover;
 +	}
 +
 +	nvdev = net_device_ctx->nvdev;
 +
 +	ret = netif_set_real_num_tx_queues(net, nvdev->num_chn);
 +	if (ret) {
 +		if (recovering) {
 +			netdev_err(net, "could not set tx queue count (ret %d)\n", ret);
 +			return ret;
 +		}
 +		goto recover;
 +	}
  
 +	ret = netif_set_real_num_rx_queues(net, nvdev->num_chn);
 +	if (ret) {
 +		if (recovering) {
 +			netdev_err(net, "could not set rx queue count (ret %d)\n", ret);
 +			return ret;
 +		}
 +		goto recover;
 +	}
 +
 + out:
 +	netvsc_open(net);
 +	net_device_ctx->start_remove = false;
  	/* We may have missed link change notifications */
  	net_device_ctx->last_reconfig = 0;
  	schedule_delayed_work(&net_device_ctx->dwork, 0);
@@@ -891,42 -938,63 +924,52 @@@ static int netvsc_set_link_ksettings(st
  static int netvsc_change_mtu(struct net_device *ndev, int mtu)
  {
  	struct net_device_context *ndevctx = netdev_priv(ndev);
 -	struct net_device *vf_netdev = rtnl_dereference(ndevctx->vf_netdev);
 -	struct netvsc_device *nvdev = rtnl_dereference(ndevctx->nvdev);
 +	struct netvsc_device *nvdev = ndevctx->nvdev;
  	struct hv_device *hdev = ndevctx->device_ctx;
 -	int orig_mtu = ndev->mtu;
  	struct netvsc_device_info device_info;
 -	bool was_opened;
 +	int limit = ETH_DATA_LEN;
 +	u32 num_chn;
  	int ret = 0;
  
 -	if (!nvdev || nvdev->destroy)
 +	if (ndevctx->start_remove || !nvdev || nvdev->destroy)
  		return -ENODEV;
  
 -	/* Change MTU of underlying VF netdev first. */
 -	if (vf_netdev) {
 -		ret = dev_set_mtu(vf_netdev, mtu);
 -		if (ret)
 -			return ret;
 -	}
 +	if (nvdev->nvsp_version >= NVSP_PROTOCOL_VERSION_2)
 +		limit = NETVSC_MTU - ETH_HLEN;
  
 -	netif_device_detach(ndev);
 -	was_opened = rndis_filter_opened(nvdev);
 -	if (was_opened)
 -		rndis_filter_close(nvdev);
 +	if (mtu < NETVSC_MTU_MIN || mtu > limit)
 +		return -EINVAL;
  
++<<<<<<< HEAD
 +	ret = netvsc_close(ndev);
 +	if (ret)
 +		goto out;
++=======
+ 	memset(&device_info, 0, sizeof(device_info));
+ 	device_info.ring_size = ring_size;
+ 	device_info.num_chn = nvdev->num_chn;
+ 	device_info.send_sections = nvdev->send_section_cnt;
+ 	device_info.send_section_size = nvdev->send_section_size;
+ 	device_info.recv_sections = nvdev->recv_section_cnt;
+ 	device_info.recv_section_size = nvdev->recv_section_size;
++>>>>>>> 0ab09befdbb7 (hv_netvsc: fix send buffer failure on MTU change)
  
 -	rndis_filter_device_remove(hdev, nvdev);
 -
 -	ndev->mtu = mtu;
 -
 -	nvdev = rndis_filter_device_add(hdev, &device_info);
 -	if (IS_ERR(nvdev)) {
 -		ret = PTR_ERR(nvdev);
 -
 -		/* Attempt rollback to original MTU */
 -		ndev->mtu = orig_mtu;
 -		nvdev = rndis_filter_device_add(hdev, &device_info);
 +	num_chn = nvdev->num_chn;
  
 -		if (vf_netdev)
 -			dev_set_mtu(vf_netdev, orig_mtu);
 +	ndevctx->start_remove = true;
 +	rndis_filter_device_remove(hdev);
  
 -		if (IS_ERR(nvdev)) {
 -			netdev_err(ndev, "restoring mtu failed: %ld\n",
 -				   PTR_ERR(nvdev));
 -			return ret;
 -		}
 -	}
 +	ndev->mtu = mtu;
  
 -	if (was_opened)
 -		rndis_filter_open(nvdev);
 +	memset(&device_info, 0, sizeof(device_info));
 +	device_info.ring_size = ring_size;
 +	device_info.num_chn = num_chn;
 +	device_info.max_num_vrss_chns = max_num_vrss_chns;
 +	rndis_filter_device_add(hdev, &device_info);
  
 -	netif_device_attach(ndev);
 +out:
 +	netvsc_open(ndev);
 +	ndevctx->start_remove = false;
  
  	/* We may have missed link change notifications */
  	schedule_delayed_work(&ndevctx->dwork, 0);
@@@ -1166,7 -1422,107 +1209,111 @@@ static int netvsc_set_rxfh(struct net_d
  		key = rndis_dev->rss_key;
  	}
  
++<<<<<<< HEAD
 +	return rndis_filter_set_rss_param(rndis_dev, key, ndev->num_chn);
++=======
+ 	return rndis_filter_set_rss_param(rndis_dev, key);
+ }
+ 
+ /* Hyper-V RNDIS protocol does not have ring in the HW sense.
+  * It does have pre-allocated receive area which is divided into sections.
+  */
+ static void __netvsc_get_ringparam(struct netvsc_device *nvdev,
+ 				   struct ethtool_ringparam *ring)
+ {
+ 	u32 max_buf_size;
+ 
+ 	ring->rx_pending = nvdev->recv_section_cnt;
+ 	ring->tx_pending = nvdev->send_section_cnt;
+ 
+ 	if (nvdev->nvsp_version <= NVSP_PROTOCOL_VERSION_2)
+ 		max_buf_size = NETVSC_RECEIVE_BUFFER_SIZE_LEGACY;
+ 	else
+ 		max_buf_size = NETVSC_RECEIVE_BUFFER_SIZE;
+ 
+ 	ring->rx_max_pending = max_buf_size / nvdev->recv_section_size;
+ 	ring->tx_max_pending = NETVSC_SEND_BUFFER_SIZE
+ 		/ nvdev->send_section_size;
+ }
+ 
+ static void netvsc_get_ringparam(struct net_device *ndev,
+ 				 struct ethtool_ringparam *ring)
+ {
+ 	struct net_device_context *ndevctx = netdev_priv(ndev);
+ 	struct netvsc_device *nvdev = rtnl_dereference(ndevctx->nvdev);
+ 
+ 	if (!nvdev)
+ 		return;
+ 
+ 	__netvsc_get_ringparam(nvdev, ring);
+ }
+ 
+ static int netvsc_set_ringparam(struct net_device *ndev,
+ 				struct ethtool_ringparam *ring)
+ {
+ 	struct net_device_context *ndevctx = netdev_priv(ndev);
+ 	struct netvsc_device *nvdev = rtnl_dereference(ndevctx->nvdev);
+ 	struct hv_device *hdev = ndevctx->device_ctx;
+ 	struct netvsc_device_info device_info;
+ 	struct ethtool_ringparam orig;
+ 	u32 new_tx, new_rx;
+ 	bool was_opened;
+ 	int ret = 0;
+ 
+ 	if (!nvdev || nvdev->destroy)
+ 		return -ENODEV;
+ 
+ 	memset(&orig, 0, sizeof(orig));
+ 	__netvsc_get_ringparam(nvdev, &orig);
+ 
+ 	new_tx = clamp_t(u32, ring->tx_pending,
+ 			 NETVSC_MIN_TX_SECTIONS, orig.tx_max_pending);
+ 	new_rx = clamp_t(u32, ring->rx_pending,
+ 			 NETVSC_MIN_RX_SECTIONS, orig.rx_max_pending);
+ 
+ 	if (new_tx == orig.tx_pending &&
+ 	    new_rx == orig.rx_pending)
+ 		return 0;	 /* no change */
+ 
+ 	memset(&device_info, 0, sizeof(device_info));
+ 	device_info.num_chn = nvdev->num_chn;
+ 	device_info.ring_size = ring_size;
+ 	device_info.send_sections = new_tx;
+ 	device_info.send_section_size = nvdev->send_section_size;
+ 	device_info.recv_sections = new_rx;
+ 	device_info.recv_section_size = nvdev->recv_section_size;
+ 
+ 	netif_device_detach(ndev);
+ 	was_opened = rndis_filter_opened(nvdev);
+ 	if (was_opened)
+ 		rndis_filter_close(nvdev);
+ 
+ 	rndis_filter_device_remove(hdev, nvdev);
+ 
+ 	nvdev = rndis_filter_device_add(hdev, &device_info);
+ 	if (IS_ERR(nvdev)) {
+ 		ret = PTR_ERR(nvdev);
+ 
+ 		device_info.send_sections = orig.tx_pending;
+ 		device_info.recv_sections = orig.rx_pending;
+ 		nvdev = rndis_filter_device_add(hdev, &device_info);
+ 		if (IS_ERR(nvdev)) {
+ 			netdev_err(ndev, "restoring ringparam failed: %ld\n",
+ 				   PTR_ERR(nvdev));
+ 			return ret;
+ 		}
+ 	}
+ 
+ 	if (was_opened)
+ 		rndis_filter_open(nvdev);
+ 	netif_device_attach(ndev);
+ 
+ 	/* We may have missed link change notifications */
+ 	ndevctx->last_reconfig = 0;
+ 	schedule_delayed_work(&ndevctx->dwork, 0);
+ 
+ 	return ret;
++>>>>>>> 0ab09befdbb7 (hv_netvsc: fix send buffer failure on MTU change)
  }
  
  static const struct ethtool_ops ethtool_ops = {
@@@ -1528,20 -1938,35 +1675,32 @@@ static int netvsc_probe(struct hv_devic
  	/* Notify the netvsc driver of the new device */
  	memset(&device_info, 0, sizeof(device_info));
  	device_info.ring_size = ring_size;
++<<<<<<< HEAD
 +	device_info.max_num_vrss_chns = max_num_vrss_chns;
 +	ret = rndis_filter_device_add(dev, &device_info);
 +	if (ret != 0) {
++=======
+ 	device_info.num_chn = VRSS_CHANNEL_DEFAULT;
+ 	device_info.send_sections = NETVSC_DEFAULT_TX;
+ 	device_info.send_section_size = NETVSC_SEND_SECTION_SIZE;
+ 	device_info.recv_sections = NETVSC_DEFAULT_RX;
+ 	device_info.recv_section_size = NETVSC_RECV_SECTION_SIZE;
+ 
+ 	nvdev = rndis_filter_device_add(dev, &device_info);
+ 	if (IS_ERR(nvdev)) {
+ 		ret = PTR_ERR(nvdev);
++>>>>>>> 0ab09befdbb7 (hv_netvsc: fix send buffer failure on MTU change)
  		netdev_err(net, "unable to add netvsc device (ret %d)\n", ret);
 -		goto rndis_failed;
 +		netvsc_free_netdev(net);
 +		hv_set_drvdata(dev, NULL);
 +		return ret;
  	}
 -
  	memcpy(net->dev_addr, device_info.mac_adr, ETH_ALEN);
  
 -	/* hw_features computed in rndis_filter_device_add */
 -	net->features = net->hw_features |
 -		NETIF_F_HIGHDMA | NETIF_F_SG |
 -		NETIF_F_HW_VLAN_CTAG_TX | NETIF_F_HW_VLAN_CTAG_RX;
 -	net->vlan_features = net->features;
 -
 -	netdev_lockdep_set_classes(net);
 -
 -	/* MTU range: 68 - 1500 or 65521 */
 -	net->min_mtu = NETVSC_MTU_MIN;
 -	if (nvdev->nvsp_version >= NVSP_PROTOCOL_VERSION_2)
 -		net->max_mtu = NETVSC_MTU - ETH_HLEN;
 -	else
 -		net->max_mtu = ETH_DATA_LEN;
 +	nvdev = net_device_ctx->nvdev;
 +	netif_set_real_num_tx_queues(net, nvdev->num_chn);
 +	netif_set_real_num_rx_queues(net, nvdev->num_chn);
 +	netif_set_gso_max_size(net, NETVSC_GSO_MAX_SIZE);
  
  	ret = register_netdev(net);
  	if (ret != 0) {
* Unmerged path drivers/net/hyperv/hyperv_net.h
* Unmerged path drivers/net/hyperv/netvsc.c
* Unmerged path drivers/net/hyperv/netvsc_drv.c
