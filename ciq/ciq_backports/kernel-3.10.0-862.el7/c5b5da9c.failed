iommu/amd: Set up data structures for flush queue

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [iommu] amd: Set up data structures for flush queue (Jerry Snitselaar) [1411581]
Rebuild_FUZZ: 93.48%
commit-author Joerg Roedel <jroedel@suse.de>
commit c5b5da9c79bb2d88fa3c5163ccf1a7a9e89cfa49
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/c5b5da9c.failed

The flush queue is the equivalent to defered-flushing in the
Intel VT-d driver. This patch sets up the data structures
needed for this.

	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit c5b5da9c79bb2d88fa3c5163ccf1a7a9e89cfa49)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/amd_iommu.c
diff --cc drivers/iommu/amd_iommu.c
index c9d79e07ea12,38f8a5e461fc..000000000000
--- a/drivers/iommu/amd_iommu.c
+++ b/drivers/iommu/amd_iommu.c
@@@ -2782,20 -2522,51 +2798,66 @@@ static int set_dma_mask(struct device *
  	return 0;
  }
  
 +static struct dma_map_ops amd_iommu_dma_ops = {
 +	.alloc		= alloc_coherent,
 +	.free		= free_coherent,
 +	.map_page	= map_page,
 +	.unmap_page	= unmap_page,
 +	.map_sg		= map_sg,
 +	.unmap_sg	= unmap_sg,
 +	.dma_supported	= amd_iommu_dma_supported,
 +	.set_dma_mask	= set_dma_mask,
 +};
 +
  int __init amd_iommu_init_api(void)
  {
++<<<<<<< HEAD
 +	return bus_set_iommu(&pci_bus_type, &amd_iommu_ops);
++=======
+ 	int ret, cpu, err = 0;
+ 
+ 	ret = iova_cache_get();
+ 	if (ret)
+ 		return ret;
+ 
+ 	ret = init_reserved_iova_ranges();
+ 	if (ret)
+ 		return ret;
+ 
+ 	for_each_possible_cpu(cpu) {
+ 		struct flush_queue *queue = per_cpu_ptr(&flush_queue, cpu);
+ 
+ 		queue->entries = kzalloc(FLUSH_QUEUE_SIZE *
+ 					 sizeof(*queue->entries),
+ 					 GFP_KERNEL);
+ 		if (!queue->entries)
+ 			goto out_put_iova;
+ 
+ 		spin_lock_init(&queue->lock);
+ 	}
+ 
+ 	err = bus_set_iommu(&pci_bus_type, &amd_iommu_ops);
+ 	if (err)
+ 		return err;
+ #ifdef CONFIG_ARM_AMBA
+ 	err = bus_set_iommu(&amba_bustype, &amd_iommu_ops);
+ 	if (err)
+ 		return err;
+ #endif
+ 	err = bus_set_iommu(&platform_bus_type, &amd_iommu_ops);
+ 	if (err)
+ 		return err;
+ 	return 0;
+ 
+ out_put_iova:
+ 	for_each_possible_cpu(cpu) {
+ 		struct flush_queue *queue = per_cpu_ptr(&flush_queue, cpu);
+ 
+ 		kfree(queue->entries);
+ 	}
+ 
+ 	return -ENOMEM;
++>>>>>>> c5b5da9c79bb (iommu/amd: Set up data structures for flush queue)
  }
  
  int __init amd_iommu_init_dma_ops(void)
* Unmerged path drivers/iommu/amd_iommu.c
