net_sched: fix reference counting of tc filter chain

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Cong Wang <xiyou.wangcong@gmail.com>
commit e2ef75445340ca7ec2c4558f84ae6c8c5d650fc8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/e2ef7544.failed

This patch fixes the following ugliness of tc filter chain refcnt:

a) tp proto should hold a refcnt to the chain too. This significantly
   simplifies the logic.

b) Chain 0 is no longer special, it is created with refcnt=1 like any
   other chains. All the ugliness in tcf_chain_put() can be gone!

c) No need to handle the flushing oddly, because block still holds
   chain 0, it can not be released, this guarantees block is the last
   user.

d) The race condition with RCU callbacks is easier to handle with just
   a rcu_barrier(). Much easier to understand, nothing to hide. Thanks
   to the previous patch. Please see also the comments in code.

e) Make the code understandable by humans, much less error-prone.

Fixes: 744a4cf63e52 ("net: sched: fix use after free when tcf_chain_destroy is called multiple times")
Fixes: 5bc1701881e3 ("net: sched: introduce multichain support for filters")
	Cc: Jiri Pirko <jiri@mellanox.com>
	Cc: Jamal Hadi Salim <jhs@mojatatu.com>
	Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
	Acked-by: Jiri Pirko <jiri@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit e2ef75445340ca7ec2c4558f84ae6c8c5d650fc8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sched/cls_api.c
diff --cc net/sched/cls_api.c
index 1dc6d123ed94,d29e79d98a69..000000000000
--- a/net/sched/cls_api.c
+++ b/net/sched/cls_api.c
@@@ -124,7 -109,403 +124,407 @@@ static inline u32 tcf_auto_prio(struct 
  	if (tp)
  		first = tp->prio - 1;
  
++<<<<<<< HEAD
 +	return first;
++=======
+ 	return TC_H_MAJ(first);
+ }
+ 
+ static struct tcf_proto *tcf_proto_create(const char *kind, u32 protocol,
+ 					  u32 prio, u32 parent, struct Qdisc *q,
+ 					  struct tcf_chain *chain)
+ {
+ 	struct tcf_proto *tp;
+ 	int err;
+ 
+ 	tp = kzalloc(sizeof(*tp), GFP_KERNEL);
+ 	if (!tp)
+ 		return ERR_PTR(-ENOBUFS);
+ 
+ 	err = -ENOENT;
+ 	tp->ops = tcf_proto_lookup_ops(kind);
+ 	if (!tp->ops) {
+ #ifdef CONFIG_MODULES
+ 		rtnl_unlock();
+ 		request_module("cls_%s", kind);
+ 		rtnl_lock();
+ 		tp->ops = tcf_proto_lookup_ops(kind);
+ 		/* We dropped the RTNL semaphore in order to perform
+ 		 * the module load. So, even if we succeeded in loading
+ 		 * the module we have to replay the request. We indicate
+ 		 * this using -EAGAIN.
+ 		 */
+ 		if (tp->ops) {
+ 			module_put(tp->ops->owner);
+ 			err = -EAGAIN;
+ 		} else {
+ 			err = -ENOENT;
+ 		}
+ 		goto errout;
+ #endif
+ 	}
+ 	tp->classify = tp->ops->classify;
+ 	tp->protocol = protocol;
+ 	tp->prio = prio;
+ 	tp->classid = parent;
+ 	tp->q = q;
+ 	tp->chain = chain;
+ 
+ 	err = tp->ops->init(tp);
+ 	if (err) {
+ 		module_put(tp->ops->owner);
+ 		goto errout;
+ 	}
+ 	return tp;
+ 
+ errout:
+ 	kfree(tp);
+ 	return ERR_PTR(err);
+ }
+ 
+ static void tcf_proto_destroy(struct tcf_proto *tp)
+ {
+ 	tp->ops->destroy(tp);
+ 	module_put(tp->ops->owner);
+ 	kfree_rcu(tp, rcu);
+ }
+ 
+ static struct tcf_chain *tcf_chain_create(struct tcf_block *block,
+ 					  u32 chain_index)
+ {
+ 	struct tcf_chain *chain;
+ 
+ 	chain = kzalloc(sizeof(*chain), GFP_KERNEL);
+ 	if (!chain)
+ 		return NULL;
+ 	list_add_tail(&chain->list, &block->chain_list);
+ 	chain->block = block;
+ 	chain->index = chain_index;
+ 	chain->refcnt = 1;
+ 	return chain;
+ }
+ 
+ static void tcf_chain_flush(struct tcf_chain *chain)
+ {
+ 	struct tcf_proto *tp;
+ 
+ 	if (chain->p_filter_chain)
+ 		RCU_INIT_POINTER(*chain->p_filter_chain, NULL);
+ 	while ((tp = rtnl_dereference(chain->filter_chain)) != NULL) {
+ 		RCU_INIT_POINTER(chain->filter_chain, tp->next);
+ 		tcf_chain_put(chain);
+ 		tcf_proto_destroy(tp);
+ 	}
+ }
+ 
+ static void tcf_chain_destroy(struct tcf_chain *chain)
+ {
+ 	list_del(&chain->list);
+ 	kfree(chain);
+ }
+ 
+ static void tcf_chain_hold(struct tcf_chain *chain)
+ {
+ 	++chain->refcnt;
+ }
+ 
+ struct tcf_chain *tcf_chain_get(struct tcf_block *block, u32 chain_index,
+ 				bool create)
+ {
+ 	struct tcf_chain *chain;
+ 
+ 	list_for_each_entry(chain, &block->chain_list, list) {
+ 		if (chain->index == chain_index) {
+ 			tcf_chain_hold(chain);
+ 			return chain;
+ 		}
+ 	}
+ 
+ 	return create ? tcf_chain_create(block, chain_index) : NULL;
+ }
+ EXPORT_SYMBOL(tcf_chain_get);
+ 
+ void tcf_chain_put(struct tcf_chain *chain)
+ {
+ 	if (--chain->refcnt == 0)
+ 		tcf_chain_destroy(chain);
+ }
+ EXPORT_SYMBOL(tcf_chain_put);
+ 
+ static void
+ tcf_chain_filter_chain_ptr_set(struct tcf_chain *chain,
+ 			       struct tcf_proto __rcu **p_filter_chain)
+ {
+ 	chain->p_filter_chain = p_filter_chain;
+ }
+ 
+ int tcf_block_get(struct tcf_block **p_block,
+ 		  struct tcf_proto __rcu **p_filter_chain)
+ {
+ 	struct tcf_block *block = kzalloc(sizeof(*block), GFP_KERNEL);
+ 	struct tcf_chain *chain;
+ 	int err;
+ 
+ 	if (!block)
+ 		return -ENOMEM;
+ 	INIT_LIST_HEAD(&block->chain_list);
+ 	/* Create chain 0 by default, it has to be always present. */
+ 	chain = tcf_chain_create(block, 0);
+ 	if (!chain) {
+ 		err = -ENOMEM;
+ 		goto err_chain_create;
+ 	}
+ 	tcf_chain_filter_chain_ptr_set(chain, p_filter_chain);
+ 	*p_block = block;
+ 	return 0;
+ 
+ err_chain_create:
+ 	kfree(block);
+ 	return err;
+ }
+ EXPORT_SYMBOL(tcf_block_get);
+ 
+ void tcf_block_put(struct tcf_block *block)
+ {
+ 	struct tcf_chain *chain, *tmp;
+ 
+ 	if (!block)
+ 		return;
+ 
+ 	/* XXX: Standalone actions are not allowed to jump to any chain, and
+ 	 * bound actions should be all removed after flushing. However,
+ 	 * filters are destroyed in RCU callbacks, we have to flush and wait
+ 	 * for them inside the loop, otherwise we race with RCU callbacks on
+ 	 * this list.
+ 	 */
+ 	list_for_each_entry_safe(chain, tmp, &block->chain_list, list) {
+ 		tcf_chain_flush(chain);
+ 		rcu_barrier();
+ 	}
+ 
+ 	list_for_each_entry_safe(chain, tmp, &block->chain_list, list)
+ 		tcf_chain_put(chain);
+ 	kfree(block);
+ }
+ EXPORT_SYMBOL(tcf_block_put);
+ 
+ /* Main classifier routine: scans classifier chain attached
+  * to this qdisc, (optionally) tests for protocol and asks
+  * specific classifiers.
+  */
+ int tcf_classify(struct sk_buff *skb, const struct tcf_proto *tp,
+ 		 struct tcf_result *res, bool compat_mode)
+ {
+ 	__be16 protocol = tc_skb_protocol(skb);
+ #ifdef CONFIG_NET_CLS_ACT
+ 	const int max_reclassify_loop = 4;
+ 	const struct tcf_proto *orig_tp = tp;
+ 	const struct tcf_proto *first_tp;
+ 	int limit = 0;
+ 
+ reclassify:
+ #endif
+ 	for (; tp; tp = rcu_dereference_bh(tp->next)) {
+ 		int err;
+ 
+ 		if (tp->protocol != protocol &&
+ 		    tp->protocol != htons(ETH_P_ALL))
+ 			continue;
+ 
+ 		err = tp->classify(skb, tp, res);
+ #ifdef CONFIG_NET_CLS_ACT
+ 		if (unlikely(err == TC_ACT_RECLASSIFY && !compat_mode)) {
+ 			first_tp = orig_tp;
+ 			goto reset;
+ 		} else if (unlikely(TC_ACT_EXT_CMP(err, TC_ACT_GOTO_CHAIN))) {
+ 			first_tp = res->goto_tp;
+ 			goto reset;
+ 		}
+ #endif
+ 		if (err >= 0)
+ 			return err;
+ 	}
+ 
+ 	return TC_ACT_UNSPEC; /* signal: continue lookup */
+ #ifdef CONFIG_NET_CLS_ACT
+ reset:
+ 	if (unlikely(limit++ >= max_reclassify_loop)) {
+ 		net_notice_ratelimited("%s: reclassify loop, rule prio %u, protocol %02x\n",
+ 				       tp->q->ops->id, tp->prio & 0xffff,
+ 				       ntohs(tp->protocol));
+ 		return TC_ACT_SHOT;
+ 	}
+ 
+ 	tp = first_tp;
+ 	protocol = tc_skb_protocol(skb);
+ 	goto reclassify;
+ #endif
+ }
+ EXPORT_SYMBOL(tcf_classify);
+ 
+ struct tcf_chain_info {
+ 	struct tcf_proto __rcu **pprev;
+ 	struct tcf_proto __rcu *next;
+ };
+ 
+ static struct tcf_proto *tcf_chain_tp_prev(struct tcf_chain_info *chain_info)
+ {
+ 	return rtnl_dereference(*chain_info->pprev);
+ }
+ 
+ static void tcf_chain_tp_insert(struct tcf_chain *chain,
+ 				struct tcf_chain_info *chain_info,
+ 				struct tcf_proto *tp)
+ {
+ 	if (chain->p_filter_chain &&
+ 	    *chain_info->pprev == chain->filter_chain)
+ 		rcu_assign_pointer(*chain->p_filter_chain, tp);
+ 	RCU_INIT_POINTER(tp->next, tcf_chain_tp_prev(chain_info));
+ 	rcu_assign_pointer(*chain_info->pprev, tp);
+ 	tcf_chain_hold(chain);
+ }
+ 
+ static void tcf_chain_tp_remove(struct tcf_chain *chain,
+ 				struct tcf_chain_info *chain_info,
+ 				struct tcf_proto *tp)
+ {
+ 	struct tcf_proto *next = rtnl_dereference(chain_info->next);
+ 
+ 	if (chain->p_filter_chain && tp == chain->filter_chain)
+ 		RCU_INIT_POINTER(*chain->p_filter_chain, next);
+ 	RCU_INIT_POINTER(*chain_info->pprev, next);
+ 	tcf_chain_put(chain);
+ }
+ 
+ static struct tcf_proto *tcf_chain_tp_find(struct tcf_chain *chain,
+ 					   struct tcf_chain_info *chain_info,
+ 					   u32 protocol, u32 prio,
+ 					   bool prio_allocate)
+ {
+ 	struct tcf_proto **pprev;
+ 	struct tcf_proto *tp;
+ 
+ 	/* Check the chain for existence of proto-tcf with this priority */
+ 	for (pprev = &chain->filter_chain;
+ 	     (tp = rtnl_dereference(*pprev)); pprev = &tp->next) {
+ 		if (tp->prio >= prio) {
+ 			if (tp->prio == prio) {
+ 				if (prio_allocate ||
+ 				    (tp->protocol != protocol && protocol))
+ 					return ERR_PTR(-EINVAL);
+ 			} else {
+ 				tp = NULL;
+ 			}
+ 			break;
+ 		}
+ 	}
+ 	chain_info->pprev = pprev;
+ 	chain_info->next = tp ? tp->next : NULL;
+ 	return tp;
+ }
+ 
+ static int tcf_fill_node(struct net *net, struct sk_buff *skb,
+ 			 struct tcf_proto *tp, void *fh, u32 portid,
+ 			 u32 seq, u16 flags, int event)
+ {
+ 	struct tcmsg *tcm;
+ 	struct nlmsghdr  *nlh;
+ 	unsigned char *b = skb_tail_pointer(skb);
+ 
+ 	nlh = nlmsg_put(skb, portid, seq, event, sizeof(*tcm), flags);
+ 	if (!nlh)
+ 		goto out_nlmsg_trim;
+ 	tcm = nlmsg_data(nlh);
+ 	tcm->tcm_family = AF_UNSPEC;
+ 	tcm->tcm__pad1 = 0;
+ 	tcm->tcm__pad2 = 0;
+ 	tcm->tcm_ifindex = qdisc_dev(tp->q)->ifindex;
+ 	tcm->tcm_parent = tp->classid;
+ 	tcm->tcm_info = TC_H_MAKE(tp->prio, tp->protocol);
+ 	if (nla_put_string(skb, TCA_KIND, tp->ops->kind))
+ 		goto nla_put_failure;
+ 	if (nla_put_u32(skb, TCA_CHAIN, tp->chain->index))
+ 		goto nla_put_failure;
+ 	if (!fh) {
+ 		tcm->tcm_handle = 0;
+ 	} else {
+ 		if (tp->ops->dump && tp->ops->dump(net, tp, fh, skb, tcm) < 0)
+ 			goto nla_put_failure;
+ 	}
+ 	nlh->nlmsg_len = skb_tail_pointer(skb) - b;
+ 	return skb->len;
+ 
+ out_nlmsg_trim:
+ nla_put_failure:
+ 	nlmsg_trim(skb, b);
+ 	return -1;
+ }
+ 
+ static int tfilter_notify(struct net *net, struct sk_buff *oskb,
+ 			  struct nlmsghdr *n, struct tcf_proto *tp,
+ 			  void *fh, int event, bool unicast)
+ {
+ 	struct sk_buff *skb;
+ 	u32 portid = oskb ? NETLINK_CB(oskb).portid : 0;
+ 
+ 	skb = alloc_skb(NLMSG_GOODSIZE, GFP_KERNEL);
+ 	if (!skb)
+ 		return -ENOBUFS;
+ 
+ 	if (tcf_fill_node(net, skb, tp, fh, portid, n->nlmsg_seq,
+ 			  n->nlmsg_flags, event) <= 0) {
+ 		kfree_skb(skb);
+ 		return -EINVAL;
+ 	}
+ 
+ 	if (unicast)
+ 		return netlink_unicast(net->rtnl, skb, portid, MSG_DONTWAIT);
+ 
+ 	return rtnetlink_send(skb, net, portid, RTNLGRP_TC,
+ 			      n->nlmsg_flags & NLM_F_ECHO);
+ }
+ 
+ static int tfilter_del_notify(struct net *net, struct sk_buff *oskb,
+ 			      struct nlmsghdr *n, struct tcf_proto *tp,
+ 			      void *fh, bool unicast, bool *last)
+ {
+ 	struct sk_buff *skb;
+ 	u32 portid = oskb ? NETLINK_CB(oskb).portid : 0;
+ 	int err;
+ 
+ 	skb = alloc_skb(NLMSG_GOODSIZE, GFP_KERNEL);
+ 	if (!skb)
+ 		return -ENOBUFS;
+ 
+ 	if (tcf_fill_node(net, skb, tp, fh, portid, n->nlmsg_seq,
+ 			  n->nlmsg_flags, RTM_DELTFILTER) <= 0) {
+ 		kfree_skb(skb);
+ 		return -EINVAL;
+ 	}
+ 
+ 	err = tp->ops->delete(tp, fh, last);
+ 	if (err) {
+ 		kfree_skb(skb);
+ 		return err;
+ 	}
+ 
+ 	if (unicast)
+ 		return netlink_unicast(net->rtnl, skb, portid, MSG_DONTWAIT);
+ 
+ 	return rtnetlink_send(skb, net, portid, RTNLGRP_TC,
+ 			      n->nlmsg_flags & NLM_F_ECHO);
+ }
+ 
+ static void tfilter_notify_chain(struct net *net, struct sk_buff *oskb,
+ 				 struct nlmsghdr *n,
+ 				 struct tcf_chain *chain, int event)
+ {
+ 	struct tcf_proto *tp;
+ 
+ 	for (tp = rtnl_dereference(chain->filter_chain);
+ 	     tp; tp = rtnl_dereference(tp->next))
+ 		tfilter_notify(net, oskb, n, tp, 0, event, false);
++>>>>>>> e2ef75445340 (net_sched: fix reference counting of tc filter chain)
  }
  
  /* Add/change/delete/get a filter node */
* Unmerged path net/sched/cls_api.c
