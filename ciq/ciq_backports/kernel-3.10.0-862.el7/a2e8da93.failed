net: sched: use newly added classid identity helpers

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [net] sched: use newly added classid identity helpers (Ivan Vecera) [1445420]
Rebuild_FUZZ: 94.95%
commit-author Jiri Pirko <jiri@mellanox.com>
commit a2e8da9378cc09e2e922a0b3d481bd9d07c3d245
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/a2e8da93.failed

Instead of checking handle, which does not have the inner class
information and drivers wrongly assume clsact->egress as ingress, use
the newly introduced classid identification helpers.

	Signed-off-by: Jiri Pirko <jiri@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit a2e8da9378cc09e2e922a0b3d481bd9d07c3d245)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
#	drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_main.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
#	drivers/net/ethernet/mellanox/mlxsw/spectrum.c
#	drivers/net/ethernet/netronome/nfp/bpf/main.c
#	drivers/net/ethernet/netronome/nfp/flower/offload.c
#	net/dsa/slave.c
diff --cc drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
index 7eb2bfa69942,afa6fd688fac..000000000000
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
@@@ -2749,8 -2889,26 +2749,31 @@@ static int cxgb_set_tx_maxrate(struct n
  	return err;
  }
  
++<<<<<<< HEAD
 +static int cxgb_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
 +			 struct tc_to_netdev *tc)
++=======
+ static int cxgb_setup_tc_cls_u32(struct net_device *dev,
+ 				 struct tc_cls_u32_offload *cls_u32)
+ {
+ 	if (is_classid_clsact_ingress(cls_u32->common.classid) ||
+ 	    cls_u32->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (cls_u32->command) {
+ 	case TC_CLSU32_NEW_KNODE:
+ 	case TC_CLSU32_REPLACE_KNODE:
+ 		return cxgb4_config_knode(dev, cls_u32);
+ 	case TC_CLSU32_DELETE_KNODE:
+ 		return cxgb4_delete_knode(dev, cls_u32);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int cxgb_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			 void *type_data)
++>>>>>>> a2e8da9378cc (net: sched: use newly added classid identity helpers)
  {
  	struct port_info *pi = netdev2pinfo(dev);
  	struct adapter *adap = netdev2adap(dev);
diff --cc drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
index c0b8df7cf72a,f9fd8d8f1bef..000000000000
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
@@@ -8564,14 -8793,481 +8564,480 @@@ int ixgbe_setup_tc(struct net_device *d
  	return 0;
  }
  
 -static int ixgbe_delete_clsu32(struct ixgbe_adapter *adapter,
 -			       struct tc_cls_u32_offload *cls)
 +static int __ixgbe_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
 +			    struct tc_to_netdev *tc)
  {
 -	u32 hdl = cls->knode.handle;
 -	u32 uhtid = TC_U32_USERHTID(cls->knode.handle);
 -	u32 loc = cls->knode.handle & 0xfffff;
 -	int err = 0, i, j;
 -	struct ixgbe_jump_table *jump = NULL;
 -
 -	if (loc > IXGBE_MAX_HW_ENTRIES)
 +	/* Only support egress tc setup for now */
 +	if (tc->type != TC_SETUP_MQPRIO)
  		return -EINVAL;
  
++<<<<<<< HEAD
 +	return ixgbe_setup_tc(dev, tc->tc);
++=======
+ 	if ((uhtid != 0x800) && (uhtid >= IXGBE_MAX_LINK_HANDLE))
+ 		return -EINVAL;
+ 
+ 	/* Clear this filter in the link data it is associated with */
+ 	if (uhtid != 0x800) {
+ 		jump = adapter->jump_tables[uhtid];
+ 		if (!jump)
+ 			return -EINVAL;
+ 		if (!test_bit(loc - 1, jump->child_loc_map))
+ 			return -EINVAL;
+ 		clear_bit(loc - 1, jump->child_loc_map);
+ 	}
+ 
+ 	/* Check if the filter being deleted is a link */
+ 	for (i = 1; i < IXGBE_MAX_LINK_HANDLE; i++) {
+ 		jump = adapter->jump_tables[i];
+ 		if (jump && jump->link_hdl == hdl) {
+ 			/* Delete filters in the hardware in the child hash
+ 			 * table associated with this link
+ 			 */
+ 			for (j = 0; j < IXGBE_MAX_HW_ENTRIES; j++) {
+ 				if (!test_bit(j, jump->child_loc_map))
+ 					continue;
+ 				spin_lock(&adapter->fdir_perfect_lock);
+ 				err = ixgbe_update_ethtool_fdir_entry(adapter,
+ 								      NULL,
+ 								      j + 1);
+ 				spin_unlock(&adapter->fdir_perfect_lock);
+ 				clear_bit(j, jump->child_loc_map);
+ 			}
+ 			/* Remove resources for this link */
+ 			kfree(jump->input);
+ 			kfree(jump->mask);
+ 			kfree(jump);
+ 			adapter->jump_tables[i] = NULL;
+ 			return err;
+ 		}
+ 	}
+ 
+ 	spin_lock(&adapter->fdir_perfect_lock);
+ 	err = ixgbe_update_ethtool_fdir_entry(adapter, NULL, loc);
+ 	spin_unlock(&adapter->fdir_perfect_lock);
+ 	return err;
+ }
+ 
+ static int ixgbe_configure_clsu32_add_hnode(struct ixgbe_adapter *adapter,
+ 					    struct tc_cls_u32_offload *cls)
+ {
+ 	u32 uhtid = TC_U32_USERHTID(cls->hnode.handle);
+ 
+ 	if (uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 		return -EINVAL;
+ 
+ 	/* This ixgbe devices do not support hash tables at the moment
+ 	 * so abort when given hash tables.
+ 	 */
+ 	if (cls->hnode.divisor > 0)
+ 		return -EINVAL;
+ 
+ 	set_bit(uhtid - 1, &adapter->tables);
+ 	return 0;
+ }
+ 
+ static int ixgbe_configure_clsu32_del_hnode(struct ixgbe_adapter *adapter,
+ 					    struct tc_cls_u32_offload *cls)
+ {
+ 	u32 uhtid = TC_U32_USERHTID(cls->hnode.handle);
+ 
+ 	if (uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 		return -EINVAL;
+ 
+ 	clear_bit(uhtid - 1, &adapter->tables);
+ 	return 0;
+ }
+ 
+ #ifdef CONFIG_NET_CLS_ACT
+ struct upper_walk_data {
+ 	struct ixgbe_adapter *adapter;
+ 	u64 action;
+ 	int ifindex;
+ 	u8 queue;
+ };
+ 
+ static int get_macvlan_queue(struct net_device *upper, void *_data)
+ {
+ 	if (netif_is_macvlan(upper)) {
+ 		struct macvlan_dev *dfwd = netdev_priv(upper);
+ 		struct ixgbe_fwd_adapter *vadapter = dfwd->fwd_priv;
+ 		struct upper_walk_data *data = _data;
+ 		struct ixgbe_adapter *adapter = data->adapter;
+ 		int ifindex = data->ifindex;
+ 
+ 		if (vadapter && vadapter->netdev->ifindex == ifindex) {
+ 			data->queue = adapter->rx_ring[vadapter->rx_base_queue]->reg_idx;
+ 			data->action = data->queue;
+ 			return 1;
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int handle_redirect_action(struct ixgbe_adapter *adapter, int ifindex,
+ 				  u8 *queue, u64 *action)
+ {
+ 	unsigned int num_vfs = adapter->num_vfs, vf;
+ 	struct upper_walk_data data;
+ 	struct net_device *upper;
+ 
+ 	/* redirect to a SRIOV VF */
+ 	for (vf = 0; vf < num_vfs; ++vf) {
+ 		upper = pci_get_drvdata(adapter->vfinfo[vf].vfdev);
+ 		if (upper->ifindex == ifindex) {
+ 			if (adapter->num_rx_pools > 1)
+ 				*queue = vf * 2;
+ 			else
+ 				*queue = vf * adapter->num_rx_queues_per_pool;
+ 
+ 			*action = vf + 1;
+ 			*action <<= ETHTOOL_RX_FLOW_SPEC_RING_VF_OFF;
+ 			return 0;
+ 		}
+ 	}
+ 
+ 	/* redirect to a offloaded macvlan netdev */
+ 	data.adapter = adapter;
+ 	data.ifindex = ifindex;
+ 	data.action = 0;
+ 	data.queue = 0;
+ 	if (netdev_walk_all_upper_dev_rcu(adapter->netdev,
+ 					  get_macvlan_queue, &data)) {
+ 		*action = data.action;
+ 		*queue = data.queue;
+ 
+ 		return 0;
+ 	}
+ 
+ 	return -EINVAL;
+ }
+ 
+ static int parse_tc_actions(struct ixgbe_adapter *adapter,
+ 			    struct tcf_exts *exts, u64 *action, u8 *queue)
+ {
+ 	const struct tc_action *a;
+ 	LIST_HEAD(actions);
+ 	int err;
+ 
+ 	if (!tcf_exts_has_actions(exts))
+ 		return -EINVAL;
+ 
+ 	tcf_exts_to_list(exts, &actions);
+ 	list_for_each_entry(a, &actions, list) {
+ 
+ 		/* Drop action */
+ 		if (is_tcf_gact_shot(a)) {
+ 			*action = IXGBE_FDIR_DROP_QUEUE;
+ 			*queue = IXGBE_FDIR_DROP_QUEUE;
+ 			return 0;
+ 		}
+ 
+ 		/* Redirect to a VF or a offloaded macvlan */
+ 		if (is_tcf_mirred_egress_redirect(a)) {
+ 			int ifindex = tcf_mirred_ifindex(a);
+ 
+ 			err = handle_redirect_action(adapter, ifindex, queue,
+ 						     action);
+ 			if (err == 0)
+ 				return err;
+ 		}
+ 	}
+ 
+ 	return -EINVAL;
+ }
+ #else
+ static int parse_tc_actions(struct ixgbe_adapter *adapter,
+ 			    struct tcf_exts *exts, u64 *action, u8 *queue)
+ {
+ 	return -EINVAL;
+ }
+ #endif /* CONFIG_NET_CLS_ACT */
+ 
+ static int ixgbe_clsu32_build_input(struct ixgbe_fdir_filter *input,
+ 				    union ixgbe_atr_input *mask,
+ 				    struct tc_cls_u32_offload *cls,
+ 				    struct ixgbe_mat_field *field_ptr,
+ 				    struct ixgbe_nexthdr *nexthdr)
+ {
+ 	int i, j, off;
+ 	__be32 val, m;
+ 	bool found_entry = false, found_jump_field = false;
+ 
+ 	for (i = 0; i < cls->knode.sel->nkeys; i++) {
+ 		off = cls->knode.sel->keys[i].off;
+ 		val = cls->knode.sel->keys[i].val;
+ 		m = cls->knode.sel->keys[i].mask;
+ 
+ 		for (j = 0; field_ptr[j].val; j++) {
+ 			if (field_ptr[j].off == off) {
+ 				field_ptr[j].val(input, mask, val, m);
+ 				input->filter.formatted.flow_type |=
+ 					field_ptr[j].type;
+ 				found_entry = true;
+ 				break;
+ 			}
+ 		}
+ 		if (nexthdr) {
+ 			if (nexthdr->off == cls->knode.sel->keys[i].off &&
+ 			    nexthdr->val == cls->knode.sel->keys[i].val &&
+ 			    nexthdr->mask == cls->knode.sel->keys[i].mask)
+ 				found_jump_field = true;
+ 			else
+ 				continue;
+ 		}
+ 	}
+ 
+ 	if (nexthdr && !found_jump_field)
+ 		return -EINVAL;
+ 
+ 	if (!found_entry)
+ 		return 0;
+ 
+ 	mask->formatted.flow_type = IXGBE_ATR_L4TYPE_IPV6_MASK |
+ 				    IXGBE_ATR_L4TYPE_MASK;
+ 
+ 	if (input->filter.formatted.flow_type == IXGBE_ATR_FLOW_TYPE_IPV4)
+ 		mask->formatted.flow_type &= IXGBE_ATR_L4TYPE_IPV6_MASK;
+ 
+ 	return 0;
+ }
+ 
+ static int ixgbe_configure_clsu32(struct ixgbe_adapter *adapter,
+ 				  struct tc_cls_u32_offload *cls)
+ {
+ 	__be16 protocol = cls->common.protocol;
+ 	u32 loc = cls->knode.handle & 0xfffff;
+ 	struct ixgbe_hw *hw = &adapter->hw;
+ 	struct ixgbe_mat_field *field_ptr;
+ 	struct ixgbe_fdir_filter *input = NULL;
+ 	union ixgbe_atr_input *mask = NULL;
+ 	struct ixgbe_jump_table *jump = NULL;
+ 	int i, err = -EINVAL;
+ 	u8 queue;
+ 	u32 uhtid, link_uhtid;
+ 
+ 	uhtid = TC_U32_USERHTID(cls->knode.handle);
+ 	link_uhtid = TC_U32_USERHTID(cls->knode.link_handle);
+ 
+ 	/* At the moment cls_u32 jumps to network layer and skips past
+ 	 * L2 headers. The canonical method to match L2 frames is to use
+ 	 * negative values. However this is error prone at best but really
+ 	 * just broken because there is no way to "know" what sort of hdr
+ 	 * is in front of the network layer. Fix cls_u32 to support L2
+ 	 * headers when needed.
+ 	 */
+ 	if (protocol != htons(ETH_P_IP))
+ 		return err;
+ 
+ 	if (loc >= ((1024 << adapter->fdir_pballoc) - 2)) {
+ 		e_err(drv, "Location out of range\n");
+ 		return err;
+ 	}
+ 
+ 	/* cls u32 is a graph starting at root node 0x800. The driver tracks
+ 	 * links and also the fields used to advance the parser across each
+ 	 * link (e.g. nexthdr/eat parameters from 'tc'). This way we can map
+ 	 * the u32 graph onto the hardware parse graph denoted in ixgbe_model.h
+ 	 * To add support for new nodes update ixgbe_model.h parse structures
+ 	 * this function _should_ be generic try not to hardcode values here.
+ 	 */
+ 	if (uhtid == 0x800) {
+ 		field_ptr = (adapter->jump_tables[0])->mat;
+ 	} else {
+ 		if (uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 			return err;
+ 		if (!adapter->jump_tables[uhtid])
+ 			return err;
+ 		field_ptr = (adapter->jump_tables[uhtid])->mat;
+ 	}
+ 
+ 	if (!field_ptr)
+ 		return err;
+ 
+ 	/* At this point we know the field_ptr is valid and need to either
+ 	 * build cls_u32 link or attach filter. Because adding a link to
+ 	 * a handle that does not exist is invalid and the same for adding
+ 	 * rules to handles that don't exist.
+ 	 */
+ 
+ 	if (link_uhtid) {
+ 		struct ixgbe_nexthdr *nexthdr = ixgbe_ipv4_jumps;
+ 
+ 		if (link_uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 			return err;
+ 
+ 		if (!test_bit(link_uhtid - 1, &adapter->tables))
+ 			return err;
+ 
+ 		/* Multiple filters as links to the same hash table are not
+ 		 * supported. To add a new filter with the same next header
+ 		 * but different match/jump conditions, create a new hash table
+ 		 * and link to it.
+ 		 */
+ 		if (adapter->jump_tables[link_uhtid] &&
+ 		    (adapter->jump_tables[link_uhtid])->link_hdl) {
+ 			e_err(drv, "Link filter exists for link: %x\n",
+ 			      link_uhtid);
+ 			return err;
+ 		}
+ 
+ 		for (i = 0; nexthdr[i].jump; i++) {
+ 			if (nexthdr[i].o != cls->knode.sel->offoff ||
+ 			    nexthdr[i].s != cls->knode.sel->offshift ||
+ 			    nexthdr[i].m != cls->knode.sel->offmask)
+ 				return err;
+ 
+ 			jump = kzalloc(sizeof(*jump), GFP_KERNEL);
+ 			if (!jump)
+ 				return -ENOMEM;
+ 			input = kzalloc(sizeof(*input), GFP_KERNEL);
+ 			if (!input) {
+ 				err = -ENOMEM;
+ 				goto free_jump;
+ 			}
+ 			mask = kzalloc(sizeof(*mask), GFP_KERNEL);
+ 			if (!mask) {
+ 				err = -ENOMEM;
+ 				goto free_input;
+ 			}
+ 			jump->input = input;
+ 			jump->mask = mask;
+ 			jump->link_hdl = cls->knode.handle;
+ 
+ 			err = ixgbe_clsu32_build_input(input, mask, cls,
+ 						       field_ptr, &nexthdr[i]);
+ 			if (!err) {
+ 				jump->mat = nexthdr[i].jump;
+ 				adapter->jump_tables[link_uhtid] = jump;
+ 				break;
+ 			}
+ 		}
+ 		return 0;
+ 	}
+ 
+ 	input = kzalloc(sizeof(*input), GFP_KERNEL);
+ 	if (!input)
+ 		return -ENOMEM;
+ 	mask = kzalloc(sizeof(*mask), GFP_KERNEL);
+ 	if (!mask) {
+ 		err = -ENOMEM;
+ 		goto free_input;
+ 	}
+ 
+ 	if ((uhtid != 0x800) && (adapter->jump_tables[uhtid])) {
+ 		if ((adapter->jump_tables[uhtid])->input)
+ 			memcpy(input, (adapter->jump_tables[uhtid])->input,
+ 			       sizeof(*input));
+ 		if ((adapter->jump_tables[uhtid])->mask)
+ 			memcpy(mask, (adapter->jump_tables[uhtid])->mask,
+ 			       sizeof(*mask));
+ 
+ 		/* Lookup in all child hash tables if this location is already
+ 		 * filled with a filter
+ 		 */
+ 		for (i = 1; i < IXGBE_MAX_LINK_HANDLE; i++) {
+ 			struct ixgbe_jump_table *link = adapter->jump_tables[i];
+ 
+ 			if (link && (test_bit(loc - 1, link->child_loc_map))) {
+ 				e_err(drv, "Filter exists in location: %x\n",
+ 				      loc);
+ 				err = -EINVAL;
+ 				goto err_out;
+ 			}
+ 		}
+ 	}
+ 	err = ixgbe_clsu32_build_input(input, mask, cls, field_ptr, NULL);
+ 	if (err)
+ 		goto err_out;
+ 
+ 	err = parse_tc_actions(adapter, cls->knode.exts, &input->action,
+ 			       &queue);
+ 	if (err < 0)
+ 		goto err_out;
+ 
+ 	input->sw_idx = loc;
+ 
+ 	spin_lock(&adapter->fdir_perfect_lock);
+ 
+ 	if (hlist_empty(&adapter->fdir_filter_list)) {
+ 		memcpy(&adapter->fdir_mask, mask, sizeof(*mask));
+ 		err = ixgbe_fdir_set_input_mask_82599(hw, mask);
+ 		if (err)
+ 			goto err_out_w_lock;
+ 	} else if (memcmp(&adapter->fdir_mask, mask, sizeof(*mask))) {
+ 		err = -EINVAL;
+ 		goto err_out_w_lock;
+ 	}
+ 
+ 	ixgbe_atr_compute_perfect_hash_82599(&input->filter, mask);
+ 	err = ixgbe_fdir_write_perfect_filter_82599(hw, &input->filter,
+ 						    input->sw_idx, queue);
+ 	if (!err)
+ 		ixgbe_update_ethtool_fdir_entry(adapter, input, input->sw_idx);
+ 	spin_unlock(&adapter->fdir_perfect_lock);
+ 
+ 	if ((uhtid != 0x800) && (adapter->jump_tables[uhtid]))
+ 		set_bit(loc - 1, (adapter->jump_tables[uhtid])->child_loc_map);
+ 
+ 	kfree(mask);
+ 	return err;
+ err_out_w_lock:
+ 	spin_unlock(&adapter->fdir_perfect_lock);
+ err_out:
+ 	kfree(mask);
+ free_input:
+ 	kfree(input);
+ free_jump:
+ 	kfree(jump);
+ 	return err;
+ }
+ 
+ static int ixgbe_setup_tc_cls_u32(struct net_device *dev,
+ 				  struct tc_cls_u32_offload *cls_u32)
+ {
+ 	struct ixgbe_adapter *adapter = netdev_priv(dev);
+ 
+ 	if (is_classid_clsact_ingress(cls_u32->common.classid) ||
+ 	    cls_u32->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (cls_u32->command) {
+ 	case TC_CLSU32_NEW_KNODE:
+ 	case TC_CLSU32_REPLACE_KNODE:
+ 		return ixgbe_configure_clsu32(adapter, cls_u32);
+ 	case TC_CLSU32_DELETE_KNODE:
+ 		return ixgbe_delete_clsu32(adapter, cls_u32);
+ 	case TC_CLSU32_NEW_HNODE:
+ 	case TC_CLSU32_REPLACE_HNODE:
+ 		return ixgbe_configure_clsu32_add_hnode(adapter, cls_u32);
+ 	case TC_CLSU32_DELETE_HNODE:
+ 		return ixgbe_configure_clsu32_del_hnode(adapter, cls_u32);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int ixgbe_setup_tc_mqprio(struct net_device *dev,
+ 				 struct tc_mqprio_qopt *mqprio)
+ {
+ 	mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
+ 	return ixgbe_setup_tc(dev, mqprio->num_tc);
+ }
+ 
+ static int __ixgbe_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			    void *type_data)
+ {
+ 	switch (type) {
+ 	case TC_SETUP_CLSU32:
+ 		return ixgbe_setup_tc_cls_u32(dev, type_data);
+ 	case TC_SETUP_MQPRIO:
+ 		return ixgbe_setup_tc_mqprio(dev, type_data);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
++>>>>>>> a2e8da9378cc (net: sched: use newly added classid identity helpers)
  }
  
  #ifdef CONFIG_PCI_IOV
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index edb21d8194bc,8633ca5af6ed..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@@ -2614,19 -3031,33 +2614,25 @@@ static int mlx5e_ndo_setup_tc(struct ne
  {
  	struct mlx5e_priv *priv = netdev_priv(dev);
  
++<<<<<<< HEAD
 +	if (TC_H_MAJ(handle) != TC_H_MAJ(TC_H_INGRESS))
 +		goto mqprio;
++=======
+ 	if (is_classid_clsact_ingress(cls_flower->common.classid) ||
+ 	    cls_flower->common.chain_index)
+ 		return -EOPNOTSUPP;
++>>>>>>> a2e8da9378cc (net: sched: use newly added classid identity helpers)
  
 -	switch (cls_flower->command) {
 -	case TC_CLSFLOWER_REPLACE:
 -		return mlx5e_configure_flower(priv, cls_flower);
 -	case TC_CLSFLOWER_DESTROY:
 -		return mlx5e_delete_flower(priv, cls_flower);
 -	case TC_CLSFLOWER_STATS:
 -		return mlx5e_stats_flower(priv, cls_flower);
 -	default:
 -		return -EOPNOTSUPP;
 -	}
 -}
 -#endif
 -
 -static int mlx5e_setup_tc(struct net_device *dev, enum tc_setup_type type,
 -			  void *type_data)
 -{
 -	switch (type) {
 -#ifdef CONFIG_MLX5_ESWITCH
 +	switch (tc->type) {
  	case TC_SETUP_CLSFLOWER:
 -		return mlx5e_setup_tc_cls_flower(dev, type_data);
 -#endif
 -	case TC_SETUP_MQPRIO:
 -		return mlx5e_setup_tc_mqprio(dev, type_data);
 +		switch (tc->cls_flower->command) {
 +		case TC_CLSFLOWER_REPLACE:
 +			return mlx5e_configure_flower(priv, proto, tc->cls_flower);
 +		case TC_CLSFLOWER_DESTROY:
 +			return mlx5e_delete_flower(priv, tc->cls_flower);
 +		case TC_CLSFLOWER_STATS:
 +			return mlx5e_stats_flower(priv, tc->cls_flower);
 +		}
  	default:
  		return -EOPNOTSUPP;
  	}
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
index abcb1976163d,f34c00fbf78c..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
@@@ -286,27 -657,36 +286,32 @@@ static int mlx5e_rep_ndo_setup_tc(struc
  {
  	struct mlx5e_priv *priv = netdev_priv(dev);
  
++<<<<<<< HEAD
 +	if (TC_H_MAJ(handle) != TC_H_MAJ(TC_H_INGRESS))
++=======
+ 	if (is_classid_clsact_ingress(cls_flower->common.classid) ||
+ 	    cls_flower->common.chain_index)
++>>>>>>> a2e8da9378cc (net: sched: use newly added classid identity helpers)
  		return -EOPNOTSUPP;
  
 -	if (cls_flower->egress_dev) {
 +	if (type == TC_SETUP_CLSFLOWER && tc->cls_flower->egress_dev) {
  		struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 +		struct net_device *uplink_dev = mlx5_eswitch_get_uplink_netdev(esw);
  
 -		dev = mlx5_eswitch_get_uplink_netdev(esw);
 -		return dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSFLOWER,
 -						     cls_flower);
 -	}
 -
 -	switch (cls_flower->command) {
 -	case TC_CLSFLOWER_REPLACE:
 -		return mlx5e_configure_flower(priv, cls_flower);
 -	case TC_CLSFLOWER_DESTROY:
 -		return mlx5e_delete_flower(priv, cls_flower);
 -	case TC_CLSFLOWER_STATS:
 -		return mlx5e_stats_flower(priv, cls_flower);
 -	default:
 -		return -EOPNOTSUPP;
 +		return uplink_dev->netdev_ops->ndo_setup_tc(uplink_dev, handle,
 +							    proto, tc);
  	}
 -}
  
 -static int mlx5e_rep_setup_tc(struct net_device *dev, enum tc_setup_type type,
 -			      void *type_data)
 -{
 -	switch (type) {
 +	switch (tc->type) {
  	case TC_SETUP_CLSFLOWER:
 -		return mlx5e_rep_setup_tc_cls_flower(dev, type_data);
 +		switch (tc->cls_flower->command) {
 +		case TC_CLSFLOWER_REPLACE:
 +			return mlx5e_configure_flower(priv, proto, tc->cls_flower);
 +		case TC_CLSFLOWER_DESTROY:
 +			return mlx5e_delete_flower(priv, tc->cls_flower);
 +		case TC_CLSFLOWER_STATS:
 +			return mlx5e_stats_flower(priv, tc->cls_flower);
 +		}
  	default:
  		return -EOPNOTSUPP;
  	}
diff --cc drivers/net/ethernet/mellanox/mlxsw/spectrum.c
index c628b7aede0f,a99600333a49..000000000000
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
@@@ -1286,42 -1693,75 +1286,103 @@@ static void mlxsw_sp_port_del_cls_match
  	kfree(mall_tc_entry);
  }
  
++<<<<<<< HEAD
 +static int mlxsw_sp_setup_tc(struct net_device *dev, u32 handle,
 +			     __be16 proto, struct tc_to_netdev *tc)
++=======
+ static int mlxsw_sp_setup_tc_cls_matchall(struct mlxsw_sp_port *mlxsw_sp_port,
+ 					  struct tc_cls_matchall_offload *f)
+ {
+ 	bool ingress;
+ 
+ 	if (is_classid_clsact_ingress(f->common.classid))
+ 		ingress = true;
+ 	else if (is_classid_clsact_egress(f->common.classid))
+ 		ingress = false;
+ 	else
+ 		return -EOPNOTSUPP;
+ 
+ 	if (f->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (f->command) {
+ 	case TC_CLSMATCHALL_REPLACE:
+ 		return mlxsw_sp_port_add_cls_matchall(mlxsw_sp_port, f,
+ 						      ingress);
+ 	case TC_CLSMATCHALL_DESTROY:
+ 		mlxsw_sp_port_del_cls_matchall(mlxsw_sp_port, f);
+ 		return 0;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int
+ mlxsw_sp_setup_tc_cls_flower(struct mlxsw_sp_port *mlxsw_sp_port,
+ 			     struct tc_cls_flower_offload *f)
+ {
+ 	bool ingress;
+ 
+ 	if (is_classid_clsact_ingress(f->common.classid))
+ 		ingress = true;
+ 	else if (is_classid_clsact_egress(f->common.classid))
+ 		ingress = false;
+ 	else
+ 		return -EOPNOTSUPP;
+ 
+ 	if (f->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (f->command) {
+ 	case TC_CLSFLOWER_REPLACE:
+ 		return mlxsw_sp_flower_replace(mlxsw_sp_port, ingress, f);
+ 	case TC_CLSFLOWER_DESTROY:
+ 		mlxsw_sp_flower_destroy(mlxsw_sp_port, ingress, f);
+ 		return 0;
+ 	case TC_CLSFLOWER_STATS:
+ 		return mlxsw_sp_flower_stats(mlxsw_sp_port, ingress, f);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int mlxsw_sp_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			     void *type_data)
++>>>>>>> a2e8da9378cc (net: sched: use newly added classid identity helpers)
  {
  	struct mlxsw_sp_port *mlxsw_sp_port = netdev_priv(dev);
 -
 -	switch (type) {
 -	case TC_SETUP_CLSMATCHALL:
 -		return mlxsw_sp_setup_tc_cls_matchall(mlxsw_sp_port, type_data);
 +	bool ingress = TC_H_MAJ(handle) == TC_H_MAJ(TC_H_INGRESS);
 +
 +	switch (tc->type) {
 +	case TC_SETUP_MATCHALL:
 +		switch (tc->cls_mall->command) {
 +		case TC_CLSMATCHALL_REPLACE:
 +			return mlxsw_sp_port_add_cls_matchall(mlxsw_sp_port,
 +							      proto,
 +							      tc->cls_mall,
 +							      ingress);
 +		case TC_CLSMATCHALL_DESTROY:
 +			mlxsw_sp_port_del_cls_matchall(mlxsw_sp_port,
 +						       tc->cls_mall);
 +			return 0;
 +		default:
 +			return -EINVAL;
 +		}
  	case TC_SETUP_CLSFLOWER:
 -		return mlxsw_sp_setup_tc_cls_flower(mlxsw_sp_port, type_data);
 -	default:
 -		return -EOPNOTSUPP;
 +		switch (tc->cls_flower->command) {
 +		case TC_CLSFLOWER_REPLACE:
 +			return mlxsw_sp_flower_replace(mlxsw_sp_port, ingress,
 +						       proto, tc->cls_flower);
 +		case TC_CLSFLOWER_DESTROY:
 +			mlxsw_sp_flower_destroy(mlxsw_sp_port, ingress,
 +						tc->cls_flower);
 +			return 0;
 +		default:
 +			return -EOPNOTSUPP;
 +		}
  	}
 +
 +	return -EOPNOTSUPP;
  }
  
  static const struct net_device_ops mlxsw_sp_port_netdev_ops = {
diff --cc net/dsa/slave.c
index f3efc3546e20,78e78a6e6833..000000000000
--- a/net/dsa/slave.c
+++ b/net/dsa/slave.c
@@@ -290,12 -688,334 +290,334 @@@ static int dsa_slave_get_sset_count(str
  	return -EOPNOTSUPP;
  }
  
++<<<<<<< HEAD
++=======
+ static void dsa_slave_get_wol(struct net_device *dev, struct ethtool_wolinfo *w)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (ds->ops->get_wol)
+ 		ds->ops->get_wol(ds, p->dp->index, w);
+ }
+ 
+ static int dsa_slave_set_wol(struct net_device *dev, struct ethtool_wolinfo *w)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	int ret = -EOPNOTSUPP;
+ 
+ 	if (ds->ops->set_wol)
+ 		ret = ds->ops->set_wol(ds, p->dp->index, w);
+ 
+ 	return ret;
+ }
+ 
+ static int dsa_slave_set_eee(struct net_device *dev, struct ethtool_eee *e)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	int ret;
+ 
+ 	/* Port's PHY and MAC both need to be EEE capable */
+ 	if (!p->phy)
+ 		return -ENODEV;
+ 
+ 	if (!ds->ops->set_mac_eee)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = ds->ops->set_mac_eee(ds, p->dp->index, e);
+ 	if (ret)
+ 		return ret;
+ 
+ 	if (e->eee_enabled) {
+ 		ret = phy_init_eee(p->phy, 0);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	return phy_ethtool_set_eee(p->phy, e);
+ }
+ 
+ static int dsa_slave_get_eee(struct net_device *dev, struct ethtool_eee *e)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	int ret;
+ 
+ 	/* Port's PHY and MAC both need to be EEE capable */
+ 	if (!p->phy)
+ 		return -ENODEV;
+ 
+ 	if (!ds->ops->get_mac_eee)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = ds->ops->get_mac_eee(ds, p->dp->index, e);
+ 	if (ret)
+ 		return ret;
+ 
+ 	return phy_ethtool_get_eee(p->phy, e);
+ }
+ 
+ #ifdef CONFIG_NET_POLL_CONTROLLER
+ static int dsa_slave_netpoll_setup(struct net_device *dev,
+ 				   struct netpoll_info *ni)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct net_device *master = dsa_master_netdev(p);
+ 	struct netpoll *netpoll;
+ 	int err = 0;
+ 
+ 	netpoll = kzalloc(sizeof(*netpoll), GFP_KERNEL);
+ 	if (!netpoll)
+ 		return -ENOMEM;
+ 
+ 	err = __netpoll_setup(netpoll, master);
+ 	if (err) {
+ 		kfree(netpoll);
+ 		goto out;
+ 	}
+ 
+ 	p->netpoll = netpoll;
+ out:
+ 	return err;
+ }
+ 
+ static void dsa_slave_netpoll_cleanup(struct net_device *dev)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct netpoll *netpoll = p->netpoll;
+ 
+ 	if (!netpoll)
+ 		return;
+ 
+ 	p->netpoll = NULL;
+ 
+ 	__netpoll_free_async(netpoll);
+ }
+ 
+ static void dsa_slave_poll_controller(struct net_device *dev)
+ {
+ }
+ #endif
+ 
+ static int dsa_slave_get_phys_port_name(struct net_device *dev,
+ 					char *name, size_t len)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 
+ 	if (snprintf(name, len, "p%d", p->dp->index) >= len)
+ 		return -EINVAL;
+ 
+ 	return 0;
+ }
+ 
+ static struct dsa_mall_tc_entry *
+ dsa_slave_mall_tc_entry_find(struct dsa_slave_priv *p,
+ 			     unsigned long cookie)
+ {
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 
+ 	list_for_each_entry(mall_tc_entry, &p->mall_tc_list, list)
+ 		if (mall_tc_entry->cookie == cookie)
+ 			return mall_tc_entry;
+ 
+ 	return NULL;
+ }
+ 
+ static int dsa_slave_add_cls_matchall(struct net_device *dev,
+ 				      struct tc_cls_matchall_offload *cls,
+ 				      bool ingress)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 	__be16 protocol = cls->common.protocol;
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	struct net *net = dev_net(dev);
+ 	struct dsa_slave_priv *to_p;
+ 	struct net_device *to_dev;
+ 	const struct tc_action *a;
+ 	int err = -EOPNOTSUPP;
+ 	LIST_HEAD(actions);
+ 	int ifindex;
+ 
+ 	if (!ds->ops->port_mirror_add)
+ 		return err;
+ 
+ 	if (!tcf_exts_has_one_action(cls->exts))
+ 		return err;
+ 
+ 	tcf_exts_to_list(cls->exts, &actions);
+ 	a = list_first_entry(&actions, struct tc_action, list);
+ 
+ 	if (is_tcf_mirred_egress_mirror(a) && protocol == htons(ETH_P_ALL)) {
+ 		struct dsa_mall_mirror_tc_entry *mirror;
+ 
+ 		ifindex = tcf_mirred_ifindex(a);
+ 		to_dev = __dev_get_by_index(net, ifindex);
+ 		if (!to_dev)
+ 			return -EINVAL;
+ 
+ 		if (!dsa_slave_dev_check(to_dev))
+ 			return -EOPNOTSUPP;
+ 
+ 		mall_tc_entry = kzalloc(sizeof(*mall_tc_entry), GFP_KERNEL);
+ 		if (!mall_tc_entry)
+ 			return -ENOMEM;
+ 
+ 		mall_tc_entry->cookie = cls->cookie;
+ 		mall_tc_entry->type = DSA_PORT_MALL_MIRROR;
+ 		mirror = &mall_tc_entry->mirror;
+ 
+ 		to_p = netdev_priv(to_dev);
+ 
+ 		mirror->to_local_port = to_p->dp->index;
+ 		mirror->ingress = ingress;
+ 
+ 		err = ds->ops->port_mirror_add(ds, p->dp->index, mirror,
+ 					       ingress);
+ 		if (err) {
+ 			kfree(mall_tc_entry);
+ 			return err;
+ 		}
+ 
+ 		list_add_tail(&mall_tc_entry->list, &p->mall_tc_list);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void dsa_slave_del_cls_matchall(struct net_device *dev,
+ 				       struct tc_cls_matchall_offload *cls)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (!ds->ops->port_mirror_del)
+ 		return;
+ 
+ 	mall_tc_entry = dsa_slave_mall_tc_entry_find(p, cls->cookie);
+ 	if (!mall_tc_entry)
+ 		return;
+ 
+ 	list_del(&mall_tc_entry->list);
+ 
+ 	switch (mall_tc_entry->type) {
+ 	case DSA_PORT_MALL_MIRROR:
+ 		ds->ops->port_mirror_del(ds, p->dp->index,
+ 					 &mall_tc_entry->mirror);
+ 		break;
+ 	default:
+ 		WARN_ON(1);
+ 	}
+ 
+ 	kfree(mall_tc_entry);
+ }
+ 
+ static int dsa_slave_setup_tc_cls_matchall(struct net_device *dev,
+ 					   struct tc_cls_matchall_offload *cls)
+ {
+ 	bool ingress;
+ 
+ 	if (is_classid_clsact_ingress(cls->common.classid))
+ 		ingress = true;
+ 	else if (is_classid_clsact_egress(cls->common.classid))
+ 		ingress = false;
+ 	else
+ 		return -EOPNOTSUPP;
+ 
+ 	if (cls->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (cls->command) {
+ 	case TC_CLSMATCHALL_REPLACE:
+ 		return dsa_slave_add_cls_matchall(dev, cls, ingress);
+ 	case TC_CLSMATCHALL_DESTROY:
+ 		dsa_slave_del_cls_matchall(dev, cls);
+ 		return 0;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int dsa_slave_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			      void *type_data)
+ {
+ 	switch (type) {
+ 	case TC_SETUP_CLSMATCHALL:
+ 		return dsa_slave_setup_tc_cls_matchall(dev, type_data);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static void dsa_slave_get_stats64(struct net_device *dev,
+ 				  struct rtnl_link_stats64 *stats)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct pcpu_sw_netstats *s;
+ 	unsigned int start;
+ 	int i;
+ 
+ 	netdev_stats_to_stats64(stats, &dev->stats);
+ 	for_each_possible_cpu(i) {
+ 		u64 tx_packets, tx_bytes, rx_packets, rx_bytes;
+ 
+ 		s = per_cpu_ptr(p->stats64, i);
+ 		do {
+ 			start = u64_stats_fetch_begin_irq(&s->syncp);
+ 			tx_packets = s->tx_packets;
+ 			tx_bytes = s->tx_bytes;
+ 			rx_packets = s->rx_packets;
+ 			rx_bytes = s->rx_bytes;
+ 		} while (u64_stats_fetch_retry_irq(&s->syncp, start));
+ 
+ 		stats->tx_packets += tx_packets;
+ 		stats->tx_bytes += tx_bytes;
+ 		stats->rx_packets += rx_packets;
+ 		stats->rx_bytes += rx_bytes;
+ 	}
+ }
+ 
+ void dsa_cpu_port_ethtool_init(struct ethtool_ops *ops)
+ {
+ 	ops->get_sset_count = dsa_cpu_port_get_sset_count;
+ 	ops->get_ethtool_stats = dsa_cpu_port_get_ethtool_stats;
+ 	ops->get_strings = dsa_cpu_port_get_strings;
+ }
+ 
+ static int dsa_slave_get_rxnfc(struct net_device *dev,
+ 			       struct ethtool_rxnfc *nfc, u32 *rule_locs)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (!ds->ops->get_rxnfc)
+ 		return -EOPNOTSUPP;
+ 
+ 	return ds->ops->get_rxnfc(ds, p->dp->index, nfc, rule_locs);
+ }
+ 
+ static int dsa_slave_set_rxnfc(struct net_device *dev,
+ 			       struct ethtool_rxnfc *nfc)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (!ds->ops->set_rxnfc)
+ 		return -EOPNOTSUPP;
+ 
+ 	return ds->ops->set_rxnfc(ds, p->dp->index, nfc);
+ }
+ 
++>>>>>>> a2e8da9378cc (net: sched: use newly added classid identity helpers)
  static const struct ethtool_ops dsa_slave_ethtool_ops = {
 +	.get_settings		= dsa_slave_get_settings,
 +	.set_settings		= dsa_slave_set_settings,
  	.get_drvinfo		= dsa_slave_get_drvinfo,
 -	.get_regs_len		= dsa_slave_get_regs_len,
 -	.get_regs		= dsa_slave_get_regs,
  	.nway_reset		= dsa_slave_nway_reset,
  	.get_link		= dsa_slave_get_link,
 -	.get_eeprom_len		= dsa_slave_get_eeprom_len,
 -	.get_eeprom		= dsa_slave_get_eeprom,
 -	.set_eeprom		= dsa_slave_set_eeprom,
  	.get_strings		= dsa_slave_get_strings,
  	.get_ethtool_stats	= dsa_slave_get_ethtool_stats,
  	.get_sset_count		= dsa_slave_get_sset_count,
* Unmerged path drivers/net/ethernet/netronome/nfp/bpf/main.c
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/offload.c
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
* Unmerged path drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
* Unmerged path drivers/net/ethernet/mellanox/mlxsw/spectrum.c
* Unmerged path drivers/net/ethernet/netronome/nfp/bpf/main.c
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/offload.c
* Unmerged path net/dsa/slave.c
