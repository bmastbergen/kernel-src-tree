cpufreq: intel_pstate: round up min_perf limits

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [cpufreq] intel_pstate: round up min_perf limits (Prarit Bhargava) [1465349]
Rebuild_FUZZ: 89.41%
commit-author Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
commit 46992d6b55b558ac4128c1f846de3cfddfa7cf7c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/46992d6b.failed

In some use cases, user wants to enforce a minimum performance limit on
CPUs. But because of simple division the resultant performance is 100 MHz
less than the desired in some cases.

For example when the maximum frequency is 3.50 GHz, setting
scaling_min_frequency to 1.6 GHz always results in 1.5 GHz minimum. With
simple round up, the frequency can be set to 1.6 GHz to minimum in this
case. This round up is already done to max_policy_pct and max_perf, so do
the same for min_policy_pct and min_perf.

	Signed-off-by: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
(cherry picked from commit 46992d6b55b558ac4128c1f846de3cfddfa7cf7c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/intel_pstate.c
diff --cc drivers/cpufreq/intel_pstate.c
index e7b574938221,e5ef51d7be4e..000000000000
--- a/drivers/cpufreq/intel_pstate.c
+++ b/drivers/cpufreq/intel_pstate.c
@@@ -1385,61 -1515,79 +1385,73 @@@ static int intel_pstate_init_cpu(unsign
  
  	intel_pstate_get_cpu_pstates(cpu);
  
 -	intel_pstate_busy_pid_reset(cpu);
 -
 -	pr_debug("controlling: cpu %d\n", cpunum);
 -
 -	return 0;
 -}
 +	init_timer_deferrable(&cpu->timer);
 +	cpu->timer.data = (unsigned long)cpu;
 +	cpu->timer.expires = jiffies + HZ/100;
  
 -static unsigned int intel_pstate_get(unsigned int cpu_num)
 -{
 -	struct cpudata *cpu = all_cpu_data[cpu_num];
 +	if (!hwp_active)
 +		cpu->timer.function = intel_pstate_timer_func;
 +	else
 +		cpu->timer.function = intel_hwp_timer_func;
  
 -	return cpu ? get_avg_frequency(cpu) : 0;
 -}
 +	intel_pstate_busy_pid_reset(cpu);
 +	intel_pstate_sample(cpu);
  
 -static void intel_pstate_set_update_util_hook(unsigned int cpu_num)
 -{
 -	struct cpudata *cpu = all_cpu_data[cpu_num];
 +	add_timer_on(&cpu->timer, cpunum);
  
 -	if (cpu->update_util_set)
 -		return;
 +	pr_debug("Intel pstate controlling: cpu %d\n", cpunum);
  
 -	/* Prevent intel_pstate_update_util() from using stale data. */
 -	cpu->sample.time = 0;
 -	cpufreq_add_update_util_hook(cpu_num, &cpu->update_util,
 -				     intel_pstate_update_util);
 -	cpu->update_util_set = true;
 +	return 0;
  }
  
 -static void intel_pstate_clear_update_util_hook(unsigned int cpu)
 +static unsigned int intel_pstate_get(unsigned int cpu_num)
  {
 -	struct cpudata *cpu_data = all_cpu_data[cpu];
 -
 -	if (!cpu_data->update_util_set)
 -		return;
 +	struct sample *sample;
 +	struct cpudata *cpu;
  
 -	cpufreq_remove_update_util_hook(cpu);
 -	cpu_data->update_util_set = false;
 -	synchronize_sched();
 +	cpu = all_cpu_data[cpu_num];
 +	if (!cpu)
 +		return 0;
 +	sample = &cpu->sample;
 +	return sample->freq;
  }
  
 -static void intel_pstate_set_performance_limits(struct perf_limits *limits)
 +static int intel_pstate_set_policy(struct cpufreq_policy *policy)
  {
 -	mutex_lock(&intel_pstate_limits_lock);
 -	limits->no_turbo = 0;
 -	limits->turbo_disabled = 0;
 -	limits->max_perf_pct = 100;
 -	limits->max_perf = int_tofp(1);
 -	limits->min_perf_pct = 100;
 -	limits->min_perf = int_tofp(1);
 -	limits->max_policy_pct = 100;
 -	limits->max_sysfs_pct = 100;
 -	limits->min_policy_pct = 0;
 -	limits->min_sysfs_pct = 0;
 -	mutex_unlock(&intel_pstate_limits_lock);
 -}
 +	if (!policy->cpuinfo.max_freq)
 +		return -ENODEV;
  
 -static void intel_pstate_update_perf_limits(struct cpufreq_policy *policy,
 -					    struct perf_limits *limits)
 -{
 +	pr_debug("set_policy cpuinfo.max %u policy->max %u\n",
 +		 policy->cpuinfo.max_freq, policy->max);
  
 -	mutex_lock(&intel_pstate_limits_lock);
 +	if (policy->policy == CPUFREQ_POLICY_PERFORMANCE &&
 +	    policy->max >= policy->cpuinfo.max_freq) {
 +		pr_debug("intel_pstate: set performance\n");
 +		limits = &performance_limits;
 +		if (hwp_active)
 +			intel_pstate_hwp_set(policy->cpus);
 +		return 0;
 +	}
  
 +	pr_debug("intel_pstate: set powersave\n");
 +	limits = &powersave_limits;
 +	limits->min_policy_pct = (policy->min * 100) / policy->cpuinfo.max_freq;
 +	limits->min_policy_pct = clamp_t(int, limits->min_policy_pct, 0 , 100);
  	limits->max_policy_pct = DIV_ROUND_UP(policy->max * 100,
  					      policy->cpuinfo.max_freq);
++<<<<<<< HEAD
 +	limits->max_policy_pct = clamp_t(int, limits->max_policy_pct, 0 , 100);
++=======
+ 	limits->max_policy_pct = clamp_t(int, limits->max_policy_pct, 0, 100);
+ 	if (policy->max == policy->min) {
+ 		limits->min_policy_pct = limits->max_policy_pct;
+ 	} else {
+ 		limits->min_policy_pct = DIV_ROUND_UP(policy->min * 100,
+ 						      policy->cpuinfo.max_freq);
+ 		limits->min_policy_pct = clamp_t(int, limits->min_policy_pct,
+ 						 0, 100);
+ 	}
++>>>>>>> 46992d6b55b5 (cpufreq: intel_pstate: round up min_perf limits)
  
  	/* Normalize user input to [min_policy_pct, max_policy_pct] */
  	limits->min_perf_pct = max(limits->min_policy_pct,
@@@ -1454,14 -1602,74 +1466,15 @@@
  	/* Make sure min_perf_pct <= max_perf_pct */
  	limits->min_perf_pct = min(limits->max_perf_pct, limits->min_perf_pct);
  
 -	limits->min_perf = div_fp(limits->min_perf_pct, 100);
 -	limits->max_perf = div_fp(limits->max_perf_pct, 100);
 +	limits->min_perf = div_fp(int_tofp(limits->min_perf_pct),
 +				  int_tofp(100));
 +	limits->max_perf = div_fp(int_tofp(limits->max_perf_pct),
 +				  int_tofp(100));
  	limits->max_perf = round_up(limits->max_perf, FRAC_BITS);
+ 	limits->min_perf = round_up(limits->min_perf, FRAC_BITS);
  
 -	mutex_unlock(&intel_pstate_limits_lock);
 -
 -	pr_debug("cpu:%d max_perf_pct:%d min_perf_pct:%d\n", policy->cpu,
 -		 limits->max_perf_pct, limits->min_perf_pct);
 -}
 -
 -static int intel_pstate_set_policy(struct cpufreq_policy *policy)
 -{
 -	struct cpudata *cpu;
 -	struct perf_limits *perf_limits = NULL;
 -
 -	if (!policy->cpuinfo.max_freq)
 -		return -ENODEV;
 -
 -	pr_debug("set_policy cpuinfo.max %u policy->max %u\n",
 -		 policy->cpuinfo.max_freq, policy->max);
 -
 -	cpu = all_cpu_data[policy->cpu];
 -	cpu->policy = policy->policy;
 -
 -	if (cpu->pstate.max_pstate_physical > cpu->pstate.max_pstate &&
 -	    policy->max < policy->cpuinfo.max_freq &&
 -	    policy->max > cpu->pstate.max_pstate * cpu->pstate.scaling) {
 -		pr_debug("policy->max > max non turbo frequency\n");
 -		policy->max = policy->cpuinfo.max_freq;
 -	}
 -
 -	if (per_cpu_limits)
 -		perf_limits = cpu->perf_limits;
 -
 -	if (policy->policy == CPUFREQ_POLICY_PERFORMANCE) {
 -		if (!perf_limits) {
 -			limits = &performance_limits;
 -			perf_limits = limits;
 -		}
 -		if (policy->max >= policy->cpuinfo.max_freq) {
 -			pr_debug("set performance\n");
 -			intel_pstate_set_performance_limits(perf_limits);
 -			goto out;
 -		}
 -	} else {
 -		pr_debug("set powersave\n");
 -		if (!perf_limits) {
 -			limits = &powersave_limits;
 -			perf_limits = limits;
 -		}
 -
 -	}
 -
 -	intel_pstate_update_perf_limits(policy, perf_limits);
 - out:
 -	if (cpu->policy == CPUFREQ_POLICY_PERFORMANCE) {
 -		/*
 -		 * NOHZ_FULL CPUs need this as the governor callback may not
 -		 * be invoked on them.
 -		 */
 -		intel_pstate_clear_update_util_hook(policy->cpu);
 -		intel_pstate_max_within_limits(cpu);
 -	}
 -
 -	intel_pstate_set_update_util_hook(policy->cpu);
 -
 -	intel_pstate_hwp_set_policy(policy);
 +	if (hwp_active)
 +		intel_pstate_hwp_set(policy->cpus);
  
  	return 0;
  }
* Unmerged path drivers/cpufreq/intel_pstate.c
