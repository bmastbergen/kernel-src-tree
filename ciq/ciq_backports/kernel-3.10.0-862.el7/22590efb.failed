intel_pstate: Avoid pointless FRAC_BITS shifts under div_fp()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Rafael J. Wysocki <rafael.j.wysocki@intel.com>
commit 22590efb98ae0c84f798a9938c0b6d97bc89adf5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/22590efb.failed

There are multiple places in intel_pstate where int_tofp() is applied
to both arguments of div_fp(), but this is pointless, because int_tofp()
simply shifts its argument to the left by FRAC_BITS which mathematically
is equivalent to multuplication by 2^FRAC_BITS, so if this is done
to both arguments of a division, the extra factors will cancel each
other during that operation anyway.

Drop the pointless int_tofp() applied to div_fp() arguments throughout
the driver.

	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
(cherry picked from commit 22590efb98ae0c84f798a9938c0b6d97bc89adf5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/intel_pstate.c
diff --cc drivers/cpufreq/intel_pstate.c
index 1bbc3643a3bc,8a368d2ee25c..000000000000
--- a/drivers/cpufreq/intel_pstate.c
+++ b/drivers/cpufreq/intel_pstate.c
@@@ -993,15 -1009,9 +991,15 @@@ static inline void intel_pstate_calc_bu
  	struct sample *sample = &cpu->sample;
  	int64_t core_pct;
  
- 	core_pct = int_tofp(sample->aperf) * int_tofp(100);
- 	core_pct = div64_u64(core_pct, int_tofp(sample->mperf));
+ 	core_pct = sample->aperf * int_tofp(100);
+ 	core_pct = div64_u64(core_pct, sample->mperf);
  
 +	sample->freq = fp_toint(
 +		mul_fp(int_tofp(
 +			cpu->pstate.max_pstate_physical *
 +			cpu->pstate.scaling / 100),
 +			core_pct));
 +
  	sample->core_pct_busy = (int32_t)core_pct;
  }
  
@@@ -1112,18 -1118,14 +1110,24 @@@ static inline int32_t get_target_pstate
  	core_busy = mul_fp(core_busy, div_fp(max_pstate, current_pstate));
  
  	/*
 -	 * Since our utilization update callback will not run unless we are
 -	 * in C0, check if the actual elapsed time is significantly greater (3x)
 -	 * than our sample interval.  If it is, then we were idle for a long
 -	 * enough period of time to adjust our busyness.
 +	 * Since we have a deferred timer, it will not fire unless
 +	 * we are in C0.  So, determine if the actual elapsed time
 +	 * is significantly greater (3x) than our sample interval.  If it
 +	 * is, then we were idle for a long enough period of time
 +	 * to adjust our busyness.
  	 */
++<<<<<<< HEAD
 +	sample_time = pid_params.sample_rate_ms  * USEC_PER_MSEC;
 +	duration_us = ktime_us_delta(cpu->sample.time,
 +				     cpu->last_sample_time);
 +	if (duration_us > sample_time * 3) {
 +		sample_ratio = div_fp(int_tofp(sample_time),
 +				      int_tofp(duration_us));
++=======
+ 	duration_ns = cpu->sample.time - cpu->last_sample_time;
+ 	if ((s64)duration_ns > pid_params.sample_rate_ns * 3) {
+ 		sample_ratio = div_fp(pid_params.sample_rate_ns, duration_ns);
++>>>>>>> 22590efb98ae (intel_pstate: Avoid pointless FRAC_BITS shifts under div_fp())
  		core_busy = mul_fp(core_busy, sample_ratio);
  	}
  
@@@ -1303,11 -1325,11 +1307,19 @@@ static int intel_pstate_set_policy(stru
  	/* Make sure min_perf_pct <= max_perf_pct */
  	limits->min_perf_pct = min(limits->max_perf_pct, limits->min_perf_pct);
  
++<<<<<<< HEAD
 +	limits->min_perf = div_fp(int_tofp(limits->min_perf_pct),
 +				  int_tofp(100));
 +	limits->max_perf = div_fp(int_tofp(limits->max_perf_pct),
 +				  int_tofp(100));
 +	limits->max_perf = round_up(limits->max_perf, FRAC_BITS);
++=======
+ 	limits->min_perf = div_fp(limits->min_perf_pct, 100);
+ 	limits->max_perf = div_fp(limits->max_perf_pct, 100);
+ 
+  out:
+ 	intel_pstate_set_update_util_hook(policy->cpu);
++>>>>>>> 22590efb98ae (intel_pstate: Avoid pointless FRAC_BITS shifts under div_fp())
  
  	if (hwp_active)
  		intel_pstate_hwp_set(policy->cpus);
* Unmerged path drivers/cpufreq/intel_pstate.c
