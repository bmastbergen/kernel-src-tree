net-tc: convert tc_at to tc_at_ingress

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [net] tc: convert tc_at to tc_at_ingress (Ivan Vecera) [1445420]
Rebuild_FUZZ: 94.44%
commit-author Willem de Bruijn <willemb@google.com>
commit 8dc07fdbf2054f157e8333f940a1ad728916c786
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/8dc07fdb.failed

Field tc_at is used only within tc actions to distinguish ingress from
egress processing. A single bit is sufficient for this purpose.

	Signed-off-by: Willem de Bruijn <willemb@google.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 8dc07fdbf2054f157e8333f940a1ad728916c786)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/skbuff.h
#	include/net/sch_generic.h
#	net/core/dev.c
#	net/sched/act_mirred.c
diff --cc include/linux/skbuff.h
index 7b6fa7405c56,fab3f87e9bd1..000000000000
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@@ -619,6 -589,8 +619,11 @@@ static inline u32 skb_mstamp_us_delta(c
   *	@pkt_type: Packet class
   *	@fclone: skbuff clone status
   *	@ipvs_property: skbuff is owned by ipvs
++<<<<<<< HEAD
++=======
+  *	@tc_skip_classify: do not classify packet. set by IFB device
+  *	@tc_at_ingress: used within tc_classify to distinguish in/egress
++>>>>>>> 8dc07fdbf205 (net-tc: convert tc_at to tc_at_ingress)
   *	@peeked: this packet has been seen already, so stats have been
   *		done for it, don't do them again
   *	@nf_trace: netfilter packet trace flag
@@@ -694,6 -678,88 +699,91 @@@ struct sk_buff 
  				data_len;
  	__u16			mac_len,
  				hdr_len;
++<<<<<<< HEAD
++=======
+ 
+ 	/* Following fields are _not_ copied in __copy_skb_header()
+ 	 * Note that queue_mapping is here mostly to fill a hole.
+ 	 */
+ 	kmemcheck_bitfield_begin(flags1);
+ 	__u16			queue_mapping;
+ 
+ /* if you move cloned around you also must adapt those constants */
+ #ifdef __BIG_ENDIAN_BITFIELD
+ #define CLONED_MASK	(1 << 7)
+ #else
+ #define CLONED_MASK	1
+ #endif
+ #define CLONED_OFFSET()		offsetof(struct sk_buff, __cloned_offset)
+ 
+ 	__u8			__cloned_offset[0];
+ 	__u8			cloned:1,
+ 				nohdr:1,
+ 				fclone:2,
+ 				peeked:1,
+ 				head_frag:1,
+ 				xmit_more:1,
+ 				__unused:1; /* one bit hole */
+ 	kmemcheck_bitfield_end(flags1);
+ 
+ 	/* fields enclosed in headers_start/headers_end are copied
+ 	 * using a single memcpy() in __copy_skb_header()
+ 	 */
+ 	/* private: */
+ 	__u32			headers_start[0];
+ 	/* public: */
+ 
+ /* if you move pkt_type around you also must adapt those constants */
+ #ifdef __BIG_ENDIAN_BITFIELD
+ #define PKT_TYPE_MAX	(7 << 5)
+ #else
+ #define PKT_TYPE_MAX	7
+ #endif
+ #define PKT_TYPE_OFFSET()	offsetof(struct sk_buff, __pkt_type_offset)
+ 
+ 	__u8			__pkt_type_offset[0];
+ 	__u8			pkt_type:3;
+ 	__u8			pfmemalloc:1;
+ 	__u8			ignore_df:1;
+ 	__u8			nfctinfo:3;
+ 
+ 	__u8			nf_trace:1;
+ 	__u8			ip_summed:2;
+ 	__u8			ooo_okay:1;
+ 	__u8			l4_hash:1;
+ 	__u8			sw_hash:1;
+ 	__u8			wifi_acked_valid:1;
+ 	__u8			wifi_acked:1;
+ 
+ 	__u8			no_fcs:1;
+ 	/* Indicates the inner headers are valid in the skbuff. */
+ 	__u8			encapsulation:1;
+ 	__u8			encap_hdr_csum:1;
+ 	__u8			csum_valid:1;
+ 	__u8			csum_complete_sw:1;
+ 	__u8			csum_level:2;
+ 	__u8			csum_bad:1;
+ 
+ #ifdef CONFIG_IPV6_NDISC_NODETYPE
+ 	__u8			ndisc_nodetype:2;
+ #endif
+ 	__u8			ipvs_property:1;
+ 	__u8			inner_protocol_type:1;
+ 	__u8			remcsum_offload:1;
+ #ifdef CONFIG_NET_SWITCHDEV
+ 	__u8			offload_fwd_mark:1;
+ #endif
+ #ifdef CONFIG_NET_CLS_ACT
+ 	__u8			tc_skip_classify:1;
+ 	__u8			tc_at_ingress:1;
+ 	__u8			tc_from:2;
+ #endif
+ 
+ #ifdef CONFIG_NET_SCHED
+ 	__u16			tc_index;	/* traffic control index */
+ #endif
+ 
++>>>>>>> 8dc07fdbf205 (net-tc: convert tc_at to tc_at_ingress)
  	union {
  		__wsum		csum;
  		struct {
diff --cc include/net/sch_generic.h
index e957def28d63,4bd6d5387209..000000000000
--- a/include/net/sch_generic.h
+++ b/include/net/sch_generic.h
@@@ -410,6 -407,34 +410,37 @@@ void __qdisc_calculate_pkt_len(struct s
  			       const struct qdisc_size_table *stab);
  bool tcf_destroy(struct tcf_proto *tp, bool force);
  void tcf_destroy_chain(struct tcf_proto __rcu **fl);
++<<<<<<< HEAD
++=======
+ int skb_do_redirect(struct sk_buff *);
+ 
+ static inline void skb_reset_tc(struct sk_buff *skb)
+ {
+ #ifdef CONFIG_NET_CLS_ACT
+ 	skb->tc_from = 0;
+ #endif
+ }
+ 
+ static inline bool skb_at_tc_ingress(const struct sk_buff *skb)
+ {
+ #ifdef CONFIG_NET_CLS_ACT
+ 	return skb->tc_at_ingress;
+ #else
+ 	return false;
+ #endif
+ }
+ 
+ static inline bool skb_skip_tc_classify(struct sk_buff *skb)
+ {
+ #ifdef CONFIG_NET_CLS_ACT
+ 	if (skb->tc_skip_classify) {
+ 		skb->tc_skip_classify = 0;
+ 		return true;
+ 	}
+ #endif
+ 	return false;
+ }
++>>>>>>> 8dc07fdbf205 (net-tc: convert tc_at to tc_at_ingress)
  
  /* Reset all TX qdiscs greater then index of a device.  */
  static inline void qdisc_reset_all_tx_gt(struct net_device *dev, unsigned int i)
diff --cc net/core/dev.c
index 54ad82302512,c143f1391117..000000000000
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@@ -3135,6 -3143,47 +3135,50 @@@ int dev_loopback_xmit(struct sock *sk, 
  }
  EXPORT_SYMBOL(dev_loopback_xmit);
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_NET_EGRESS
+ static struct sk_buff *
+ sch_handle_egress(struct sk_buff *skb, int *ret, struct net_device *dev)
+ {
+ 	struct tcf_proto *cl = rcu_dereference_bh(dev->egress_cl_list);
+ 	struct tcf_result cl_res;
+ 
+ 	if (!cl)
+ 		return skb;
+ 
+ 	/* qdisc_skb_cb(skb)->pkt_len was already set by the caller. */
+ 	qdisc_bstats_cpu_update(cl->q, skb);
+ 
+ 	switch (tc_classify(skb, cl, &cl_res, false)) {
+ 	case TC_ACT_OK:
+ 	case TC_ACT_RECLASSIFY:
+ 		skb->tc_index = TC_H_MIN(cl_res.classid);
+ 		break;
+ 	case TC_ACT_SHOT:
+ 		qdisc_qstats_cpu_drop(cl->q);
+ 		*ret = NET_XMIT_DROP;
+ 		kfree_skb(skb);
+ 		return NULL;
+ 	case TC_ACT_STOLEN:
+ 	case TC_ACT_QUEUED:
+ 		*ret = NET_XMIT_SUCCESS;
+ 		consume_skb(skb);
+ 		return NULL;
+ 	case TC_ACT_REDIRECT:
+ 		/* No need to push/pop skb's mac_header here on egress! */
+ 		skb_do_redirect(skb);
+ 		*ret = NET_XMIT_SUCCESS;
+ 		return NULL;
+ 	default:
+ 		break;
+ 	}
+ 
+ 	return skb;
+ }
+ #endif /* CONFIG_NET_EGRESS */
+ 
++>>>>>>> 8dc07fdbf205 (net-tc: convert tc_at to tc_at_ingress)
  static inline int get_xps_queue(struct net_device *dev, struct sk_buff *skb)
  {
  #ifdef CONFIG_XPS
@@@ -3256,6 -3316,17 +3300,20 @@@ int __dev_queue_xmit(struct sk_buff *sk
  
  	skb_update_prio(skb);
  
++<<<<<<< HEAD
++=======
+ 	qdisc_pkt_len_init(skb);
+ #ifdef CONFIG_NET_CLS_ACT
+ 	skb->tc_at_ingress = 0;
+ # ifdef CONFIG_NET_EGRESS
+ 	if (static_key_false(&egress_needed)) {
+ 		skb = sch_handle_egress(skb, &rc, dev);
+ 		if (!skb)
+ 			goto out;
+ 	}
+ # endif
+ #endif
++>>>>>>> 8dc07fdbf205 (net-tc: convert tc_at to tc_at_ingress)
  	/* If device/qdisc don't need skb->dst, release it right now while
  	 * its hot in this cpu cache.
  	 */
@@@ -3809,7 -3918,7 +3867,11 @@@ static inline struct sk_buff *handle_in
  	}
  
  	qdisc_skb_cb(skb)->pkt_len = skb->len;
++<<<<<<< HEAD
 +	skb->tc_verd = SET_TC_AT(skb->tc_verd, AT_INGRESS);
++=======
+ 	skb->tc_at_ingress = 1;
++>>>>>>> 8dc07fdbf205 (net-tc: convert tc_at to tc_at_ingress)
  	qdisc_bstats_cpu_update(cl->q, skb);
  
  	switch (tc_classify(skb, cl, &cl_res, false)) {
diff --cc net/sched/act_mirred.c
index 80554d23769d,e832c62fd705..000000000000
--- a/net/sched/act_mirred.c
+++ b/net/sched/act_mirred.c
@@@ -33,6 -34,25 +33,28 @@@
  static LIST_HEAD(mirred_list);
  static DEFINE_SPINLOCK(mirred_list_lock);
  
++<<<<<<< HEAD
++=======
+ static bool tcf_mirred_is_act_redirect(int action)
+ {
+ 	return action == TCA_EGRESS_REDIR || action == TCA_INGRESS_REDIR;
+ }
+ 
+ static bool tcf_mirred_act_wants_ingress(int action)
+ {
+ 	switch (action) {
+ 	case TCA_EGRESS_REDIR:
+ 	case TCA_EGRESS_MIRROR:
+ 		return false;
+ 	case TCA_INGRESS_REDIR:
+ 	case TCA_INGRESS_MIRROR:
+ 		return true;
+ 	default:
+ 		BUG();
+ 	}
+ }
+ 
++>>>>>>> 8dc07fdbf205 (net-tc: convert tc_at to tc_at_ingress)
  static void tcf_mirred_release(struct tc_action *a, int bind)
  {
  	struct tcf_mirred *m = to_mirred(a);
@@@ -168,18 -194,32 +190,45 @@@ static int tcf_mirred(struct sk_buff *s
  	if (!skb2)
  		goto out;
  
++<<<<<<< HEAD
 +	if (!(at & AT_EGRESS)) {
 +		if (m->tcfm_ok_push)
++=======
+ 	/* If action's target direction differs than filter's direction,
+ 	 * and devices expect a mac header on xmit, then mac push/pull is
+ 	 * needed.
+ 	 */
+ 	if (skb_at_tc_ingress(skb) != tcf_mirred_act_wants_ingress(m_eaction) &&
+ 	    m_mac_header_xmit) {
+ 		if (!skb_at_tc_ingress(skb)) {
+ 			/* caught at egress, act ingress: pull mac */
+ 			mac_len = skb_network_header(skb) - skb_mac_header(skb);
+ 			skb_pull_rcsum(skb2, mac_len);
+ 		} else {
+ 			/* caught at ingress, act egress: push mac */
++>>>>>>> 8dc07fdbf205 (net-tc: convert tc_at to tc_at_ingress)
  			skb_push_rcsum(skb2, skb->mac_len);
 -		}
  	}
  
  	/* mirror is always swallowed */
++<<<<<<< HEAD
 +	if (m->tcfm_eaction != TCA_EGRESS_MIRROR)
 +		skb2->tc_verd = SET_TC_FROM(skb2->tc_verd, at);
 +
 +	skb2->skb_iif = skb->dev->ifindex;
 +	skb2->dev = dev;
 +	err = dev_queue_xmit(skb2);
++=======
+ 	if (tcf_mirred_is_act_redirect(m_eaction))
+ 		skb2->tc_from = skb_at_tc_ingress(skb) ? AT_INGRESS : AT_EGRESS;
+ 
+ 	skb2->skb_iif = skb->dev->ifindex;
+ 	skb2->dev = dev;
+ 	if (!tcf_mirred_act_wants_ingress(m_eaction))
+ 		err = dev_queue_xmit(skb2);
+ 	else
+ 		err = netif_receive_skb(skb2);
++>>>>>>> 8dc07fdbf205 (net-tc: convert tc_at to tc_at_ingress)
  
  	if (err) {
  out:
* Unmerged path include/linux/skbuff.h
* Unmerged path include/net/sch_generic.h
* Unmerged path net/core/dev.c
* Unmerged path net/sched/act_mirred.c
