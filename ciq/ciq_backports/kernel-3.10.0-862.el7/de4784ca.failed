net: sched: get rid of struct tc_to_netdev

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [net] sched: get rid of struct tc_to_netdev (Ivan Vecera) [1445420]
Rebuild_FUZZ: 93.67%
commit-author Jiri Pirko <jiri@mellanox.com>
commit de4784ca030fed17d527dbb2bb4e21328b12de94
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/de4784ca.failed

Get rid of struct tc_to_netdev which is now just unnecessary container
and rather pass per-type structures down to drivers directly.
Along with that, consolidate the naming of per-type structure variables
in cls_*.

	Signed-off-by: Jiri Pirko <jiri@mellanox.com>
	Acked-by: Jamal Hadi Salim <jhs@mojatatu.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit de4784ca030fed17d527dbb2bb4e21328b12de94)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/amd/xgbe/xgbe-drv.c
#	drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c
#	drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h
#	drivers/net/ethernet/broadcom/bnxt/bnxt.c
#	drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
#	drivers/net/ethernet/freescale/dpaa/dpaa_eth.c
#	drivers/net/ethernet/hisilicon/hns3/hns3pf/hns3_enet.c
#	drivers/net/ethernet/intel/fm10k/fm10k_netdev.c
#	drivers/net/ethernet/intel/i40e/i40e_main.c
#	drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
#	drivers/net/ethernet/mellanox/mlx4/en_netdev.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_main.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
#	drivers/net/ethernet/mellanox/mlxsw/spectrum.c
#	drivers/net/ethernet/netronome/nfp/bpf/main.c
#	drivers/net/ethernet/netronome/nfp/flower/main.h
#	drivers/net/ethernet/netronome/nfp/flower/offload.c
#	drivers/net/ethernet/netronome/nfp/nfp_app.h
#	drivers/net/ethernet/netronome/nfp/nfp_port.c
#	drivers/net/ethernet/netronome/nfp/nfp_port.h
#	drivers/net/ethernet/sfc/efx.h
#	drivers/net/ethernet/sfc/falcon/efx.h
#	drivers/net/ethernet/sfc/falcon/tx.c
#	drivers/net/ethernet/sfc/tx.c
#	drivers/net/ethernet/ti/netcp_core.c
#	include/linux/netdevice.h
#	net/dsa/slave.c
#	net/sched/cls_bpf.c
#	net/sched/cls_flower.c
#	net/sched/cls_matchall.c
#	net/sched/cls_u32.c
#	net/sched/sch_mqprio.c
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-drv.c
index a01866542bfd,2fd9b80b39b0..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
@@@ -1852,16 -1918,18 +1852,27 @@@ static void xgbe_poll_controller(struc
  }
  #endif /* End CONFIG_NET_POLL_CONTROLLER */
  
++<<<<<<< HEAD
 +static int xgbe_setup_tc(struct net_device *netdev, u32 handle, __be16 proto,
 +			 struct tc_to_netdev *tc_to_netdev)
++=======
+ static int xgbe_setup_tc(struct net_device *netdev, enum tc_setup_type type,
+ 			 void *type_data)
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  {
  	struct xgbe_prv_data *pdata = netdev_priv(netdev);
+ 	struct tc_mqprio_qopt *mqprio = type_data;
  	u8 tc;
  
 -	if (type != TC_SETUP_MQPRIO)
 -		return -EOPNOTSUPP;
 +	if (tc_to_netdev->type != TC_SETUP_MQPRIO)
 +		return -EINVAL;
  
++<<<<<<< HEAD
 +	tc = tc_to_netdev->tc;
++=======
+ 	mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
+ 	tc = mqprio->num_tc;
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  
  	if (tc > pdata->hw_feat.tc_cnt)
  		return -EINVAL;
diff --cc drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c
index 4810103f310d,1216c1f1e052..000000000000
--- a/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c
+++ b/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c
@@@ -4283,12 -4284,17 +4283,26 @@@ int bnx2x_setup_tc(struct net_device *d
  	return 0;
  }
  
++<<<<<<< HEAD
 +int __bnx2x_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
 +		     struct tc_to_netdev *tc)
 +{
 +	if (tc->type != TC_SETUP_MQPRIO)
 +		return -EINVAL;
 +	return bnx2x_setup_tc(dev, tc->tc);
++=======
+ int __bnx2x_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 		     void *type_data)
+ {
+ 	struct tc_mqprio_qopt *mqprio = type_data;
+ 
+ 	if (type != TC_SETUP_MQPRIO)
+ 		return -EOPNOTSUPP;
+ 
+ 	mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
+ 
+ 	return bnx2x_setup_tc(dev, mqprio->num_tc);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  }
  
  /* called with rtnl_lock */
diff --cc drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h
index 243cb9748d35,a5265e1344f1..000000000000
--- a/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h
+++ b/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h
@@@ -486,8 -486,8 +486,13 @@@ netdev_tx_t bnx2x_start_xmit(struct sk_
  
  /* setup_tc callback */
  int bnx2x_setup_tc(struct net_device *dev, u8 num_tc);
++<<<<<<< HEAD
 +int __bnx2x_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
 +		     struct tc_to_netdev *tc);
++=======
+ int __bnx2x_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 		     void *type_data);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  
  int bnx2x_get_vf_config(struct net_device *dev, int vf,
  			struct ifla_vf_info *ivi);
diff --cc drivers/net/ethernet/broadcom/bnxt/bnxt.c
index bdacd982a1af,6e14fc4fe2c8..000000000000
--- a/drivers/net/ethernet/broadcom/bnxt/bnxt.c
+++ b/drivers/net/ethernet/broadcom/bnxt/bnxt.c
@@@ -6715,13 -7237,17 +6715,27 @@@ int bnxt_setup_mq_tc(struct net_device 
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int bnxt_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
 +			 struct tc_to_netdev *ntc)
 +{
 +	if (ntc->type != TC_SETUP_MQPRIO)
 +		return -EINVAL;
 +
 +	return bnxt_setup_mq_tc(dev, ntc->tc);
++=======
+ static int bnxt_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			 void *type_data)
+ {
+ 	struct tc_mqprio_qopt *mqprio = type_data;
+ 
+ 	if (type != TC_SETUP_MQPRIO)
+ 		return -EOPNOTSUPP;
+ 
+ 	mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
+ 
+ 	return bnxt_setup_mq_tc(dev, mqprio->num_tc);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  }
  
  #ifdef CONFIG_RFS_ACCEL
diff --cc drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
index 7eb2bfa69942,d80b20d695e0..000000000000
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
@@@ -2749,8 -2889,26 +2749,31 @@@ static int cxgb_set_tx_maxrate(struct n
  	return err;
  }
  
++<<<<<<< HEAD
 +static int cxgb_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
 +			 struct tc_to_netdev *tc)
++=======
+ static int cxgb_setup_tc_cls_u32(struct net_device *dev,
+ 				 struct tc_cls_u32_offload *cls_u32)
+ {
+ 	if (TC_H_MAJ(cls_u32->common.handle) != TC_H_MAJ(TC_H_INGRESS) ||
+ 	    cls_u32->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (cls_u32->command) {
+ 	case TC_CLSU32_NEW_KNODE:
+ 	case TC_CLSU32_REPLACE_KNODE:
+ 		return cxgb4_config_knode(dev, cls_u32);
+ 	case TC_CLSU32_DELETE_KNODE:
+ 		return cxgb4_delete_knode(dev, cls_u32);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int cxgb_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			 void *type_data)
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  {
  	struct port_info *pi = netdev2pinfo(dev);
  	struct adapter *adap = netdev2adap(dev);
@@@ -2762,20 -2920,12 +2785,28 @@@
  		return -EINVAL;
  	}
  
++<<<<<<< HEAD
 +	if (TC_H_MAJ(handle) == TC_H_MAJ(TC_H_INGRESS) &&
 +	    tc->type == TC_SETUP_CLSU32) {
 +		switch (tc->cls_u32->command) {
 +		case TC_CLSU32_NEW_KNODE:
 +		case TC_CLSU32_REPLACE_KNODE:
 +			return cxgb4_config_knode(dev, proto, tc->cls_u32);
 +		case TC_CLSU32_DELETE_KNODE:
 +			return cxgb4_delete_knode(dev, proto, tc->cls_u32);
 +		default:
 +			return -EOPNOTSUPP;
 +		}
++=======
+ 	switch (type) {
+ 	case TC_SETUP_CLSU32:
+ 		return cxgb_setup_tc_cls_u32(dev, type_data);
+ 	default:
+ 		return -EOPNOTSUPP;
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  	}
 +
 +	return -EOPNOTSUPP;
  }
  
  static netdev_features_t cxgb_fix_features(struct net_device *dev,
diff --cc drivers/net/ethernet/intel/fm10k/fm10k_netdev.c
index 4afd8bd1bd47,e69d49d91d67..000000000000
--- a/drivers/net/ethernet/intel/fm10k/fm10k_netdev.c
+++ b/drivers/net/ethernet/intel/fm10k/fm10k_netdev.c
@@@ -1236,16 -1265,19 +1236,30 @@@ err_queueing_scheme
  	return err;
  }
  
++<<<<<<< HEAD
 +static int __fm10k_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
 +			    struct tc_to_netdev *tc)
 +{
 +	if (tc->type != TC_SETUP_MQPRIO)
 +		return -EINVAL;
 +
 +	return fm10k_setup_tc(dev, tc->tc);
++=======
+ static int __fm10k_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			    void *type_data)
+ {
+ 	struct tc_mqprio_qopt *mqprio = type_data;
+ 
+ 	if (type != TC_SETUP_MQPRIO)
+ 		return -EOPNOTSUPP;
+ 
+ 	mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
+ 
+ 	return fm10k_setup_tc(dev, mqprio->num_tc);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  }
  
 +#if 0
  static void fm10k_assign_l2_accel(struct fm10k_intfc *interface,
  				  struct fm10k_l2_accel *l2_accel)
  {
diff --cc drivers/net/ethernet/intel/i40e/i40e_main.c
index 807f35d0c136,a7e5a76703e7..000000000000
--- a/drivers/net/ethernet/intel/i40e/i40e_main.c
+++ b/drivers/net/ethernet/intel/i40e/i40e_main.c
@@@ -5610,17 -5656,17 +5610,31 @@@ exit
  	return ret;
  }
  
++<<<<<<< HEAD
 +#ifdef I40E_FCOE
 +int __i40e_setup_tc(struct net_device *netdev, u32 handle, __be16 proto,
 +		    struct tc_to_netdev *tc)
 +#else
 +static int __i40e_setup_tc(struct net_device *netdev, u32 handle, __be16 proto,
 +			   struct tc_to_netdev *tc)
 +#endif
 +{
 +	if (handle != TC_H_ROOT || tc->type != TC_SETUP_MQPRIO)
 +		return -EINVAL;
 +	return i40e_setup_tc(netdev, tc->tc);
++=======
+ static int __i40e_setup_tc(struct net_device *netdev, enum tc_setup_type type,
+ 			   void *type_data)
+ {
+ 	struct tc_mqprio_qopt *mqprio = type_data;
+ 
+ 	if (type != TC_SETUP_MQPRIO)
+ 		return -EOPNOTSUPP;
+ 
+ 	mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
+ 
+ 	return i40e_setup_tc(netdev, mqprio->num_tc);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  }
  
  /**
diff --cc drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
index c0b8df7cf72a,c6b132476de4..000000000000
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
@@@ -8564,14 -8793,481 +8564,492 @@@ int ixgbe_setup_tc(struct net_device *d
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int __ixgbe_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
 +			    struct tc_to_netdev *tc)
 +{
 +	/* Only support egress tc setup for now */
 +	if (tc->type != TC_SETUP_MQPRIO)
 +		return -EINVAL;
 +
 +	return ixgbe_setup_tc(dev, tc->tc);
++=======
+ static int ixgbe_delete_clsu32(struct ixgbe_adapter *adapter,
+ 			       struct tc_cls_u32_offload *cls)
+ {
+ 	u32 hdl = cls->knode.handle;
+ 	u32 uhtid = TC_U32_USERHTID(cls->knode.handle);
+ 	u32 loc = cls->knode.handle & 0xfffff;
+ 	int err = 0, i, j;
+ 	struct ixgbe_jump_table *jump = NULL;
+ 
+ 	if (loc > IXGBE_MAX_HW_ENTRIES)
+ 		return -EINVAL;
+ 
+ 	if ((uhtid != 0x800) && (uhtid >= IXGBE_MAX_LINK_HANDLE))
+ 		return -EINVAL;
+ 
+ 	/* Clear this filter in the link data it is associated with */
+ 	if (uhtid != 0x800) {
+ 		jump = adapter->jump_tables[uhtid];
+ 		if (!jump)
+ 			return -EINVAL;
+ 		if (!test_bit(loc - 1, jump->child_loc_map))
+ 			return -EINVAL;
+ 		clear_bit(loc - 1, jump->child_loc_map);
+ 	}
+ 
+ 	/* Check if the filter being deleted is a link */
+ 	for (i = 1; i < IXGBE_MAX_LINK_HANDLE; i++) {
+ 		jump = adapter->jump_tables[i];
+ 		if (jump && jump->link_hdl == hdl) {
+ 			/* Delete filters in the hardware in the child hash
+ 			 * table associated with this link
+ 			 */
+ 			for (j = 0; j < IXGBE_MAX_HW_ENTRIES; j++) {
+ 				if (!test_bit(j, jump->child_loc_map))
+ 					continue;
+ 				spin_lock(&adapter->fdir_perfect_lock);
+ 				err = ixgbe_update_ethtool_fdir_entry(adapter,
+ 								      NULL,
+ 								      j + 1);
+ 				spin_unlock(&adapter->fdir_perfect_lock);
+ 				clear_bit(j, jump->child_loc_map);
+ 			}
+ 			/* Remove resources for this link */
+ 			kfree(jump->input);
+ 			kfree(jump->mask);
+ 			kfree(jump);
+ 			adapter->jump_tables[i] = NULL;
+ 			return err;
+ 		}
+ 	}
+ 
+ 	spin_lock(&adapter->fdir_perfect_lock);
+ 	err = ixgbe_update_ethtool_fdir_entry(adapter, NULL, loc);
+ 	spin_unlock(&adapter->fdir_perfect_lock);
+ 	return err;
+ }
+ 
+ static int ixgbe_configure_clsu32_add_hnode(struct ixgbe_adapter *adapter,
+ 					    struct tc_cls_u32_offload *cls)
+ {
+ 	u32 uhtid = TC_U32_USERHTID(cls->hnode.handle);
+ 
+ 	if (uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 		return -EINVAL;
+ 
+ 	/* This ixgbe devices do not support hash tables at the moment
+ 	 * so abort when given hash tables.
+ 	 */
+ 	if (cls->hnode.divisor > 0)
+ 		return -EINVAL;
+ 
+ 	set_bit(uhtid - 1, &adapter->tables);
+ 	return 0;
+ }
+ 
+ static int ixgbe_configure_clsu32_del_hnode(struct ixgbe_adapter *adapter,
+ 					    struct tc_cls_u32_offload *cls)
+ {
+ 	u32 uhtid = TC_U32_USERHTID(cls->hnode.handle);
+ 
+ 	if (uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 		return -EINVAL;
+ 
+ 	clear_bit(uhtid - 1, &adapter->tables);
+ 	return 0;
+ }
+ 
+ #ifdef CONFIG_NET_CLS_ACT
+ struct upper_walk_data {
+ 	struct ixgbe_adapter *adapter;
+ 	u64 action;
+ 	int ifindex;
+ 	u8 queue;
+ };
+ 
+ static int get_macvlan_queue(struct net_device *upper, void *_data)
+ {
+ 	if (netif_is_macvlan(upper)) {
+ 		struct macvlan_dev *dfwd = netdev_priv(upper);
+ 		struct ixgbe_fwd_adapter *vadapter = dfwd->fwd_priv;
+ 		struct upper_walk_data *data = _data;
+ 		struct ixgbe_adapter *adapter = data->adapter;
+ 		int ifindex = data->ifindex;
+ 
+ 		if (vadapter && vadapter->netdev->ifindex == ifindex) {
+ 			data->queue = adapter->rx_ring[vadapter->rx_base_queue]->reg_idx;
+ 			data->action = data->queue;
+ 			return 1;
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int handle_redirect_action(struct ixgbe_adapter *adapter, int ifindex,
+ 				  u8 *queue, u64 *action)
+ {
+ 	unsigned int num_vfs = adapter->num_vfs, vf;
+ 	struct upper_walk_data data;
+ 	struct net_device *upper;
+ 
+ 	/* redirect to a SRIOV VF */
+ 	for (vf = 0; vf < num_vfs; ++vf) {
+ 		upper = pci_get_drvdata(adapter->vfinfo[vf].vfdev);
+ 		if (upper->ifindex == ifindex) {
+ 			if (adapter->num_rx_pools > 1)
+ 				*queue = vf * 2;
+ 			else
+ 				*queue = vf * adapter->num_rx_queues_per_pool;
+ 
+ 			*action = vf + 1;
+ 			*action <<= ETHTOOL_RX_FLOW_SPEC_RING_VF_OFF;
+ 			return 0;
+ 		}
+ 	}
+ 
+ 	/* redirect to a offloaded macvlan netdev */
+ 	data.adapter = adapter;
+ 	data.ifindex = ifindex;
+ 	data.action = 0;
+ 	data.queue = 0;
+ 	if (netdev_walk_all_upper_dev_rcu(adapter->netdev,
+ 					  get_macvlan_queue, &data)) {
+ 		*action = data.action;
+ 		*queue = data.queue;
+ 
+ 		return 0;
+ 	}
+ 
+ 	return -EINVAL;
+ }
+ 
+ static int parse_tc_actions(struct ixgbe_adapter *adapter,
+ 			    struct tcf_exts *exts, u64 *action, u8 *queue)
+ {
+ 	const struct tc_action *a;
+ 	LIST_HEAD(actions);
+ 	int err;
+ 
+ 	if (!tcf_exts_has_actions(exts))
+ 		return -EINVAL;
+ 
+ 	tcf_exts_to_list(exts, &actions);
+ 	list_for_each_entry(a, &actions, list) {
+ 
+ 		/* Drop action */
+ 		if (is_tcf_gact_shot(a)) {
+ 			*action = IXGBE_FDIR_DROP_QUEUE;
+ 			*queue = IXGBE_FDIR_DROP_QUEUE;
+ 			return 0;
+ 		}
+ 
+ 		/* Redirect to a VF or a offloaded macvlan */
+ 		if (is_tcf_mirred_egress_redirect(a)) {
+ 			int ifindex = tcf_mirred_ifindex(a);
+ 
+ 			err = handle_redirect_action(adapter, ifindex, queue,
+ 						     action);
+ 			if (err == 0)
+ 				return err;
+ 		}
+ 	}
+ 
+ 	return -EINVAL;
+ }
+ #else
+ static int parse_tc_actions(struct ixgbe_adapter *adapter,
+ 			    struct tcf_exts *exts, u64 *action, u8 *queue)
+ {
+ 	return -EINVAL;
+ }
+ #endif /* CONFIG_NET_CLS_ACT */
+ 
+ static int ixgbe_clsu32_build_input(struct ixgbe_fdir_filter *input,
+ 				    union ixgbe_atr_input *mask,
+ 				    struct tc_cls_u32_offload *cls,
+ 				    struct ixgbe_mat_field *field_ptr,
+ 				    struct ixgbe_nexthdr *nexthdr)
+ {
+ 	int i, j, off;
+ 	__be32 val, m;
+ 	bool found_entry = false, found_jump_field = false;
+ 
+ 	for (i = 0; i < cls->knode.sel->nkeys; i++) {
+ 		off = cls->knode.sel->keys[i].off;
+ 		val = cls->knode.sel->keys[i].val;
+ 		m = cls->knode.sel->keys[i].mask;
+ 
+ 		for (j = 0; field_ptr[j].val; j++) {
+ 			if (field_ptr[j].off == off) {
+ 				field_ptr[j].val(input, mask, val, m);
+ 				input->filter.formatted.flow_type |=
+ 					field_ptr[j].type;
+ 				found_entry = true;
+ 				break;
+ 			}
+ 		}
+ 		if (nexthdr) {
+ 			if (nexthdr->off == cls->knode.sel->keys[i].off &&
+ 			    nexthdr->val == cls->knode.sel->keys[i].val &&
+ 			    nexthdr->mask == cls->knode.sel->keys[i].mask)
+ 				found_jump_field = true;
+ 			else
+ 				continue;
+ 		}
+ 	}
+ 
+ 	if (nexthdr && !found_jump_field)
+ 		return -EINVAL;
+ 
+ 	if (!found_entry)
+ 		return 0;
+ 
+ 	mask->formatted.flow_type = IXGBE_ATR_L4TYPE_IPV6_MASK |
+ 				    IXGBE_ATR_L4TYPE_MASK;
+ 
+ 	if (input->filter.formatted.flow_type == IXGBE_ATR_FLOW_TYPE_IPV4)
+ 		mask->formatted.flow_type &= IXGBE_ATR_L4TYPE_IPV6_MASK;
+ 
+ 	return 0;
+ }
+ 
+ static int ixgbe_configure_clsu32(struct ixgbe_adapter *adapter,
+ 				  struct tc_cls_u32_offload *cls)
+ {
+ 	__be16 protocol = cls->common.protocol;
+ 	u32 loc = cls->knode.handle & 0xfffff;
+ 	struct ixgbe_hw *hw = &adapter->hw;
+ 	struct ixgbe_mat_field *field_ptr;
+ 	struct ixgbe_fdir_filter *input = NULL;
+ 	union ixgbe_atr_input *mask = NULL;
+ 	struct ixgbe_jump_table *jump = NULL;
+ 	int i, err = -EINVAL;
+ 	u8 queue;
+ 	u32 uhtid, link_uhtid;
+ 
+ 	uhtid = TC_U32_USERHTID(cls->knode.handle);
+ 	link_uhtid = TC_U32_USERHTID(cls->knode.link_handle);
+ 
+ 	/* At the moment cls_u32 jumps to network layer and skips past
+ 	 * L2 headers. The canonical method to match L2 frames is to use
+ 	 * negative values. However this is error prone at best but really
+ 	 * just broken because there is no way to "know" what sort of hdr
+ 	 * is in front of the network layer. Fix cls_u32 to support L2
+ 	 * headers when needed.
+ 	 */
+ 	if (protocol != htons(ETH_P_IP))
+ 		return err;
+ 
+ 	if (loc >= ((1024 << adapter->fdir_pballoc) - 2)) {
+ 		e_err(drv, "Location out of range\n");
+ 		return err;
+ 	}
+ 
+ 	/* cls u32 is a graph starting at root node 0x800. The driver tracks
+ 	 * links and also the fields used to advance the parser across each
+ 	 * link (e.g. nexthdr/eat parameters from 'tc'). This way we can map
+ 	 * the u32 graph onto the hardware parse graph denoted in ixgbe_model.h
+ 	 * To add support for new nodes update ixgbe_model.h parse structures
+ 	 * this function _should_ be generic try not to hardcode values here.
+ 	 */
+ 	if (uhtid == 0x800) {
+ 		field_ptr = (adapter->jump_tables[0])->mat;
+ 	} else {
+ 		if (uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 			return err;
+ 		if (!adapter->jump_tables[uhtid])
+ 			return err;
+ 		field_ptr = (adapter->jump_tables[uhtid])->mat;
+ 	}
+ 
+ 	if (!field_ptr)
+ 		return err;
+ 
+ 	/* At this point we know the field_ptr is valid and need to either
+ 	 * build cls_u32 link or attach filter. Because adding a link to
+ 	 * a handle that does not exist is invalid and the same for adding
+ 	 * rules to handles that don't exist.
+ 	 */
+ 
+ 	if (link_uhtid) {
+ 		struct ixgbe_nexthdr *nexthdr = ixgbe_ipv4_jumps;
+ 
+ 		if (link_uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 			return err;
+ 
+ 		if (!test_bit(link_uhtid - 1, &adapter->tables))
+ 			return err;
+ 
+ 		/* Multiple filters as links to the same hash table are not
+ 		 * supported. To add a new filter with the same next header
+ 		 * but different match/jump conditions, create a new hash table
+ 		 * and link to it.
+ 		 */
+ 		if (adapter->jump_tables[link_uhtid] &&
+ 		    (adapter->jump_tables[link_uhtid])->link_hdl) {
+ 			e_err(drv, "Link filter exists for link: %x\n",
+ 			      link_uhtid);
+ 			return err;
+ 		}
+ 
+ 		for (i = 0; nexthdr[i].jump; i++) {
+ 			if (nexthdr[i].o != cls->knode.sel->offoff ||
+ 			    nexthdr[i].s != cls->knode.sel->offshift ||
+ 			    nexthdr[i].m != cls->knode.sel->offmask)
+ 				return err;
+ 
+ 			jump = kzalloc(sizeof(*jump), GFP_KERNEL);
+ 			if (!jump)
+ 				return -ENOMEM;
+ 			input = kzalloc(sizeof(*input), GFP_KERNEL);
+ 			if (!input) {
+ 				err = -ENOMEM;
+ 				goto free_jump;
+ 			}
+ 			mask = kzalloc(sizeof(*mask), GFP_KERNEL);
+ 			if (!mask) {
+ 				err = -ENOMEM;
+ 				goto free_input;
+ 			}
+ 			jump->input = input;
+ 			jump->mask = mask;
+ 			jump->link_hdl = cls->knode.handle;
+ 
+ 			err = ixgbe_clsu32_build_input(input, mask, cls,
+ 						       field_ptr, &nexthdr[i]);
+ 			if (!err) {
+ 				jump->mat = nexthdr[i].jump;
+ 				adapter->jump_tables[link_uhtid] = jump;
+ 				break;
+ 			}
+ 		}
+ 		return 0;
+ 	}
+ 
+ 	input = kzalloc(sizeof(*input), GFP_KERNEL);
+ 	if (!input)
+ 		return -ENOMEM;
+ 	mask = kzalloc(sizeof(*mask), GFP_KERNEL);
+ 	if (!mask) {
+ 		err = -ENOMEM;
+ 		goto free_input;
+ 	}
+ 
+ 	if ((uhtid != 0x800) && (adapter->jump_tables[uhtid])) {
+ 		if ((adapter->jump_tables[uhtid])->input)
+ 			memcpy(input, (adapter->jump_tables[uhtid])->input,
+ 			       sizeof(*input));
+ 		if ((adapter->jump_tables[uhtid])->mask)
+ 			memcpy(mask, (adapter->jump_tables[uhtid])->mask,
+ 			       sizeof(*mask));
+ 
+ 		/* Lookup in all child hash tables if this location is already
+ 		 * filled with a filter
+ 		 */
+ 		for (i = 1; i < IXGBE_MAX_LINK_HANDLE; i++) {
+ 			struct ixgbe_jump_table *link = adapter->jump_tables[i];
+ 
+ 			if (link && (test_bit(loc - 1, link->child_loc_map))) {
+ 				e_err(drv, "Filter exists in location: %x\n",
+ 				      loc);
+ 				err = -EINVAL;
+ 				goto err_out;
+ 			}
+ 		}
+ 	}
+ 	err = ixgbe_clsu32_build_input(input, mask, cls, field_ptr, NULL);
+ 	if (err)
+ 		goto err_out;
+ 
+ 	err = parse_tc_actions(adapter, cls->knode.exts, &input->action,
+ 			       &queue);
+ 	if (err < 0)
+ 		goto err_out;
+ 
+ 	input->sw_idx = loc;
+ 
+ 	spin_lock(&adapter->fdir_perfect_lock);
+ 
+ 	if (hlist_empty(&adapter->fdir_filter_list)) {
+ 		memcpy(&adapter->fdir_mask, mask, sizeof(*mask));
+ 		err = ixgbe_fdir_set_input_mask_82599(hw, mask);
+ 		if (err)
+ 			goto err_out_w_lock;
+ 	} else if (memcmp(&adapter->fdir_mask, mask, sizeof(*mask))) {
+ 		err = -EINVAL;
+ 		goto err_out_w_lock;
+ 	}
+ 
+ 	ixgbe_atr_compute_perfect_hash_82599(&input->filter, mask);
+ 	err = ixgbe_fdir_write_perfect_filter_82599(hw, &input->filter,
+ 						    input->sw_idx, queue);
+ 	if (!err)
+ 		ixgbe_update_ethtool_fdir_entry(adapter, input, input->sw_idx);
+ 	spin_unlock(&adapter->fdir_perfect_lock);
+ 
+ 	if ((uhtid != 0x800) && (adapter->jump_tables[uhtid]))
+ 		set_bit(loc - 1, (adapter->jump_tables[uhtid])->child_loc_map);
+ 
+ 	kfree(mask);
+ 	return err;
+ err_out_w_lock:
+ 	spin_unlock(&adapter->fdir_perfect_lock);
+ err_out:
+ 	kfree(mask);
+ free_input:
+ 	kfree(input);
+ free_jump:
+ 	kfree(jump);
+ 	return err;
+ }
+ 
+ static int ixgbe_setup_tc_cls_u32(struct net_device *dev,
+ 				  struct tc_cls_u32_offload *cls_u32)
+ {
+ 	struct ixgbe_adapter *adapter = netdev_priv(dev);
+ 
+ 	if (TC_H_MAJ(cls_u32->common.handle) != TC_H_MAJ(TC_H_INGRESS) ||
+ 	    cls_u32->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (cls_u32->command) {
+ 	case TC_CLSU32_NEW_KNODE:
+ 	case TC_CLSU32_REPLACE_KNODE:
+ 		return ixgbe_configure_clsu32(adapter, cls_u32);
+ 	case TC_CLSU32_DELETE_KNODE:
+ 		return ixgbe_delete_clsu32(adapter, cls_u32);
+ 	case TC_CLSU32_NEW_HNODE:
+ 	case TC_CLSU32_REPLACE_HNODE:
+ 		return ixgbe_configure_clsu32_add_hnode(adapter, cls_u32);
+ 	case TC_CLSU32_DELETE_HNODE:
+ 		return ixgbe_configure_clsu32_del_hnode(adapter, cls_u32);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int ixgbe_setup_tc_mqprio(struct net_device *dev,
+ 				 struct tc_mqprio_qopt *mqprio)
+ {
+ 	mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
+ 	return ixgbe_setup_tc(dev, mqprio->num_tc);
+ }
+ 
+ static int __ixgbe_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			    void *type_data)
+ {
+ 	switch (type) {
+ 	case TC_SETUP_CLSU32:
+ 		return ixgbe_setup_tc_cls_u32(dev, type_data);
+ 	case TC_SETUP_MQPRIO:
+ 		return ixgbe_setup_tc_mqprio(dev, type_data);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  }
  
  #ifdef CONFIG_PCI_IOV
diff --cc drivers/net/ethernet/mellanox/mlx4/en_netdev.c
index 76d984cbb6d9,6e67ca7aa7f5..000000000000
--- a/drivers/net/ethernet/mellanox/mlx4/en_netdev.c
+++ b/drivers/net/ethernet/mellanox/mlx4/en_netdev.c
@@@ -82,13 -86,64 +82,74 @@@ int mlx4_en_setup_tc(struct net_device 
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int __mlx4_en_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
 +			      struct tc_to_netdev *tc)
 +{
 +	if (tc->type != TC_SETUP_MQPRIO)
 +		return -EINVAL;
 +
 +	return mlx4_en_setup_tc(dev, tc->tc);
++=======
+ int mlx4_en_alloc_tx_queue_per_tc(struct net_device *dev, u8 tc)
+ {
+ 	struct mlx4_en_priv *priv = netdev_priv(dev);
+ 	struct mlx4_en_dev *mdev = priv->mdev;
+ 	struct mlx4_en_port_profile new_prof;
+ 	struct mlx4_en_priv *tmp;
+ 	int port_up = 0;
+ 	int err = 0;
+ 
+ 	tmp = kzalloc(sizeof(*tmp), GFP_KERNEL);
+ 	if (!tmp)
+ 		return -ENOMEM;
+ 
+ 	mutex_lock(&mdev->state_lock);
+ 	memcpy(&new_prof, priv->prof, sizeof(struct mlx4_en_port_profile));
+ 	new_prof.num_up = (tc == 0) ? MLX4_EN_NUM_UP_LOW :
+ 				      MLX4_EN_NUM_UP_HIGH;
+ 	new_prof.tx_ring_num[TX] = new_prof.num_tx_rings_p_up *
+ 				   new_prof.num_up;
+ 	err = mlx4_en_try_alloc_resources(priv, tmp, &new_prof, true);
+ 	if (err)
+ 		goto out;
+ 
+ 	if (priv->port_up) {
+ 		port_up = 1;
+ 		mlx4_en_stop_port(dev, 1);
+ 	}
+ 
+ 	mlx4_en_safe_replace_resources(priv, tmp);
+ 	if (port_up) {
+ 		err = mlx4_en_start_port(dev);
+ 		if (err) {
+ 			en_err(priv, "Failed starting port for setup TC\n");
+ 			goto out;
+ 		}
+ 	}
+ 
+ 	err = mlx4_en_setup_tc(dev, tc);
+ out:
+ 	mutex_unlock(&mdev->state_lock);
+ 	kfree(tmp);
+ 	return err;
+ }
+ 
+ static int __mlx4_en_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			      void *type_data)
+ {
+ 	struct tc_mqprio_qopt *mqprio = type_data;
+ 
+ 	if (type != TC_SETUP_MQPRIO)
+ 		return -EOPNOTSUPP;
+ 
+ 	if (mqprio->num_tc && mqprio->num_tc != MLX4_EN_NUM_UP_HIGH)
+ 		return -EINVAL;
+ 
+ 	mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
+ 
+ 	return mlx4_en_alloc_tx_queue_per_tc(dev, mqprio->num_tc);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  }
  
  #ifdef CONFIG_RFS_ACCEL
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index edb21d8194bc,ae0916238b7b..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@@ -2614,19 -3036,30 +2614,42 @@@ static int mlx5e_ndo_setup_tc(struct ne
  {
  	struct mlx5e_priv *priv = netdev_priv(dev);
  
 -	if (TC_H_MAJ(cls_flower->common.handle) != TC_H_MAJ(TC_H_INGRESS) ||
 -	    cls_flower->common.chain_index)
 -		return -EOPNOTSUPP;
 +	if (TC_H_MAJ(handle) != TC_H_MAJ(TC_H_INGRESS))
 +		goto mqprio;
  
++<<<<<<< HEAD
 +	switch (tc->type) {
 +	case TC_SETUP_CLSFLOWER:
 +		switch (tc->cls_flower->command) {
 +		case TC_CLSFLOWER_REPLACE:
 +			return mlx5e_configure_flower(priv, proto, tc->cls_flower);
 +		case TC_CLSFLOWER_DESTROY:
 +			return mlx5e_delete_flower(priv, tc->cls_flower);
 +		case TC_CLSFLOWER_STATS:
 +			return mlx5e_stats_flower(priv, tc->cls_flower);
 +		}
++=======
+ 	switch (cls_flower->command) {
+ 	case TC_CLSFLOWER_REPLACE:
+ 		return mlx5e_configure_flower(priv, cls_flower);
+ 	case TC_CLSFLOWER_DESTROY:
+ 		return mlx5e_delete_flower(priv, cls_flower);
+ 	case TC_CLSFLOWER_STATS:
+ 		return mlx5e_stats_flower(priv, cls_flower);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int mlx5e_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			  void *type_data)
+ {
+ 	switch (type) {
+ 	case TC_SETUP_CLSFLOWER:
+ 		return mlx5e_setup_tc_cls_flower(dev, type_data);
+ 	case TC_SETUP_MQPRIO:
+ 		return mlx5e_setup_tc_mqprio(dev, type_data);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  	default:
  		return -EOPNOTSUPP;
  	}
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
index abcb1976163d,3df994d1e173..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
@@@ -281,32 -651,42 +281,64 @@@ static int mlx5e_rep_get_phys_port_name
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int mlx5e_rep_ndo_setup_tc(struct net_device *dev, u32 handle,
 +				  __be16 proto, struct tc_to_netdev *tc)
++=======
+ static int
+ mlx5e_rep_setup_tc_cls_flower(struct net_device *dev,
+ 			      struct tc_cls_flower_offload *cls_flower)
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  {
  	struct mlx5e_priv *priv = netdev_priv(dev);
  
 -	if (TC_H_MAJ(cls_flower->common.handle) != TC_H_MAJ(TC_H_INGRESS) ||
 -	    cls_flower->common.chain_index)
 +	if (TC_H_MAJ(handle) != TC_H_MAJ(TC_H_INGRESS))
  		return -EOPNOTSUPP;
  
 -	if (cls_flower->egress_dev) {
 +	if (type == TC_SETUP_CLSFLOWER && tc->cls_flower->egress_dev) {
  		struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 +		struct net_device *uplink_dev = mlx5_eswitch_get_uplink_netdev(esw);
 +
++<<<<<<< HEAD
 +		return uplink_dev->netdev_ops->ndo_setup_tc(uplink_dev, handle,
 +							    proto, tc);
 +	}
  
 +	switch (tc->type) {
 +	case TC_SETUP_CLSFLOWER:
 +		switch (tc->cls_flower->command) {
 +		case TC_CLSFLOWER_REPLACE:
 +			return mlx5e_configure_flower(priv, proto, tc->cls_flower);
 +		case TC_CLSFLOWER_DESTROY:
 +			return mlx5e_delete_flower(priv, tc->cls_flower);
 +		case TC_CLSFLOWER_STATS:
 +			return mlx5e_stats_flower(priv, tc->cls_flower);
 +		}
++=======
+ 		dev = mlx5_eswitch_get_uplink_netdev(esw);
+ 		return dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSFLOWER,
+ 						     cls_flower);
+ 	}
+ 
+ 	switch (cls_flower->command) {
+ 	case TC_CLSFLOWER_REPLACE:
+ 		return mlx5e_configure_flower(priv, cls_flower);
+ 	case TC_CLSFLOWER_DESTROY:
+ 		return mlx5e_delete_flower(priv, cls_flower);
+ 	case TC_CLSFLOWER_STATS:
+ 		return mlx5e_stats_flower(priv, cls_flower);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int mlx5e_rep_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			      void *type_data)
+ {
+ 	switch (type) {
+ 	case TC_SETUP_CLSFLOWER:
+ 		return mlx5e_rep_setup_tc_cls_flower(dev, type_data);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  	default:
  		return -EOPNOTSUPP;
  	}
diff --cc drivers/net/ethernet/mellanox/mlxsw/spectrum.c
index c628b7aede0f,eb7c4549f464..000000000000
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
@@@ -1286,42 -1693,61 +1286,99 @@@ static void mlxsw_sp_port_del_cls_match
  	kfree(mall_tc_entry);
  }
  
++<<<<<<< HEAD
 +static int mlxsw_sp_setup_tc(struct net_device *dev, u32 handle,
 +			     __be16 proto, struct tc_to_netdev *tc)
++=======
+ static int mlxsw_sp_setup_tc_cls_matchall(struct mlxsw_sp_port *mlxsw_sp_port,
+ 					  struct tc_cls_matchall_offload *f)
+ {
+ 	bool ingress = TC_H_MAJ(f->common.handle) == TC_H_MAJ(TC_H_INGRESS);
+ 
+ 	if (f->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (f->command) {
+ 	case TC_CLSMATCHALL_REPLACE:
+ 		return mlxsw_sp_port_add_cls_matchall(mlxsw_sp_port, f,
+ 						      ingress);
+ 	case TC_CLSMATCHALL_DESTROY:
+ 		mlxsw_sp_port_del_cls_matchall(mlxsw_sp_port, f);
+ 		return 0;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int
+ mlxsw_sp_setup_tc_cls_flower(struct mlxsw_sp_port *mlxsw_sp_port,
+ 			     struct tc_cls_flower_offload *f)
+ {
+ 	bool ingress = TC_H_MAJ(f->common.handle) == TC_H_MAJ(TC_H_INGRESS);
+ 
+ 	if (f->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (f->command) {
+ 	case TC_CLSFLOWER_REPLACE:
+ 		return mlxsw_sp_flower_replace(mlxsw_sp_port, ingress, f);
+ 	case TC_CLSFLOWER_DESTROY:
+ 		mlxsw_sp_flower_destroy(mlxsw_sp_port, ingress, f);
+ 		return 0;
+ 	case TC_CLSFLOWER_STATS:
+ 		return mlxsw_sp_flower_stats(mlxsw_sp_port, ingress, f);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int mlxsw_sp_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			     void *type_data)
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  {
  	struct mlxsw_sp_port *mlxsw_sp_port = netdev_priv(dev);
 -
 +	bool ingress = TC_H_MAJ(handle) == TC_H_MAJ(TC_H_INGRESS);
 +
++<<<<<<< HEAD
 +	switch (tc->type) {
 +	case TC_SETUP_MATCHALL:
 +		switch (tc->cls_mall->command) {
 +		case TC_CLSMATCHALL_REPLACE:
 +			return mlxsw_sp_port_add_cls_matchall(mlxsw_sp_port,
 +							      proto,
 +							      tc->cls_mall,
 +							      ingress);
 +		case TC_CLSMATCHALL_DESTROY:
 +			mlxsw_sp_port_del_cls_matchall(mlxsw_sp_port,
 +						       tc->cls_mall);
 +			return 0;
 +		default:
 +			return -EINVAL;
 +		}
 +	case TC_SETUP_CLSFLOWER:
 +		switch (tc->cls_flower->command) {
 +		case TC_CLSFLOWER_REPLACE:
 +			return mlxsw_sp_flower_replace(mlxsw_sp_port, ingress,
 +						       proto, tc->cls_flower);
 +		case TC_CLSFLOWER_DESTROY:
 +			mlxsw_sp_flower_destroy(mlxsw_sp_port, ingress,
 +						tc->cls_flower);
 +			return 0;
 +		default:
 +			return -EOPNOTSUPP;
 +		}
++=======
+ 	switch (type) {
+ 	case TC_SETUP_CLSMATCHALL:
+ 		return mlxsw_sp_setup_tc_cls_matchall(mlxsw_sp_port, type_data);
+ 	case TC_SETUP_CLSFLOWER:
+ 		return mlxsw_sp_setup_tc_cls_flower(mlxsw_sp_port, type_data);
+ 	default:
+ 		return -EOPNOTSUPP;
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  	}
 +
 +	return -EOPNOTSUPP;
  }
  
  static const struct net_device_ops mlxsw_sp_port_netdev_ops = {
diff --cc drivers/net/ethernet/sfc/efx.h
index a0c52e328102,d407adf59610..000000000000
--- a/drivers/net/ethernet/sfc/efx.h
+++ b/drivers/net/ethernet/sfc/efx.h
@@@ -32,8 -32,8 +32,13 @@@ netdev_tx_t efx_hard_start_xmit(struct 
  				struct net_device *net_dev);
  netdev_tx_t efx_enqueue_skb(struct efx_tx_queue *tx_queue, struct sk_buff *skb);
  void efx_xmit_done(struct efx_tx_queue *tx_queue, unsigned int index);
++<<<<<<< HEAD
 +int efx_setup_tc(struct net_device *net_dev, u32 handle, __be16 proto,
 +		 struct tc_to_netdev *tc);
++=======
+ int efx_setup_tc(struct net_device *net_dev, enum tc_setup_type type,
+ 		 void *type_data);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  unsigned int efx_tx_max_skb_descs(struct efx_nic *efx);
  extern unsigned int efx_piobuf_size;
  extern bool efx_separate_tx_channels;
diff --cc drivers/net/ethernet/sfc/falcon/efx.h
index c89456fa148c,4f3bb30661ea..000000000000
--- a/drivers/net/ethernet/sfc/falcon/efx.h
+++ b/drivers/net/ethernet/sfc/falcon/efx.h
@@@ -32,8 -32,8 +32,13 @@@ netdev_tx_t ef4_hard_start_xmit(struct 
  				struct net_device *net_dev);
  netdev_tx_t ef4_enqueue_skb(struct ef4_tx_queue *tx_queue, struct sk_buff *skb);
  void ef4_xmit_done(struct ef4_tx_queue *tx_queue, unsigned int index);
++<<<<<<< HEAD
 +int ef4_setup_tc(struct net_device *net_dev, u32 handle, __be16 proto,
 +		 struct tc_to_netdev *tc);
++=======
+ int ef4_setup_tc(struct net_device *net_dev, enum tc_setup_type type,
+ 		 void *type_data);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  unsigned int ef4_tx_max_skb_descs(struct ef4_nic *efx);
  extern bool ef4_separate_tx_channels;
  
diff --cc drivers/net/ethernet/sfc/falcon/tx.c
index 104fb15a73f2,6a75f4140a4b..000000000000
--- a/drivers/net/ethernet/sfc/falcon/tx.c
+++ b/drivers/net/ethernet/sfc/falcon/tx.c
@@@ -425,23 -425,26 +425,38 @@@ void ef4_init_tx_queue_core_txq(struct 
  				     efx->n_tx_channels : 0));
  }
  
++<<<<<<< HEAD
 +int ef4_setup_tc(struct net_device *net_dev, u32 handle, __be16 proto,
 +		 struct tc_to_netdev *ntc)
++=======
+ int ef4_setup_tc(struct net_device *net_dev, enum tc_setup_type type,
+ 		 void *type_data)
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  {
  	struct ef4_nic *efx = netdev_priv(net_dev);
+ 	struct tc_mqprio_qopt *mqprio = type_data;
  	struct ef4_channel *channel;
  	struct ef4_tx_queue *tx_queue;
  	unsigned tc, num_tc;
  	int rc;
  
 -	if (type != TC_SETUP_MQPRIO)
 -		return -EOPNOTSUPP;
 +	if (ntc->type != TC_SETUP_MQPRIO)
 +		return -EINVAL;
  
++<<<<<<< HEAD
 +	num_tc = ntc->tc;
++=======
+ 	num_tc = mqprio->num_tc;
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  
  	if (ef4_nic_rev(efx) < EF4_REV_FALCON_B0 || num_tc > EF4_MAX_TX_TC)
  		return -EINVAL;
  
++<<<<<<< HEAD
++=======
+ 	mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
+ 
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  	if (num_tc == net_dev->num_tc)
  		return 0;
  
diff --cc drivers/net/ethernet/sfc/tx.c
index ff88d60aa6d5,32bf1fecf864..000000000000
--- a/drivers/net/ethernet/sfc/tx.c
+++ b/drivers/net/ethernet/sfc/tx.c
@@@ -653,23 -653,26 +653,38 @@@ void efx_init_tx_queue_core_txq(struct 
  				     efx->n_tx_channels : 0));
  }
  
++<<<<<<< HEAD
 +int efx_setup_tc(struct net_device *net_dev, u32 handle, __be16 proto,
 +		 struct tc_to_netdev *ntc)
++=======
+ int efx_setup_tc(struct net_device *net_dev, enum tc_setup_type type,
+ 		 void *type_data)
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  {
  	struct efx_nic *efx = netdev_priv(net_dev);
+ 	struct tc_mqprio_qopt *mqprio = type_data;
  	struct efx_channel *channel;
  	struct efx_tx_queue *tx_queue;
  	unsigned tc, num_tc;
  	int rc;
  
 -	if (type != TC_SETUP_MQPRIO)
 -		return -EOPNOTSUPP;
 +	if (ntc->type != TC_SETUP_MQPRIO)
 +		return -EINVAL;
  
++<<<<<<< HEAD
 +	num_tc = ntc->tc;
++=======
+ 	num_tc = mqprio->num_tc;
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  
  	if (num_tc > EFX_MAX_TX_TC)
  		return -EINVAL;
  
++<<<<<<< HEAD
++=======
+ 	mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
+ 
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  	if (num_tc == net_dev->num_tc)
  		return 0;
  
diff --cc include/linux/netdevice.h
index ac042b4e583c,1d238d54c484..000000000000
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@@ -803,134 -771,62 +803,143 @@@ static inline bool netdev_phys_item_id_
  typedef u16 (*select_queue_fallback_t)(struct net_device *dev,
  				       struct sk_buff *skb);
  
++<<<<<<< HEAD
 +/* These structures hold the attributes of qdisc and classifiers
 + * that are being passed to the netdevice through the setup_tc op.
 + */
 +enum {
++=======
+ enum tc_setup_type {
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  	TC_SETUP_MQPRIO,
  	TC_SETUP_CLSU32,
  	TC_SETUP_CLSFLOWER,
 -	TC_SETUP_CLSMATCHALL,
 -	TC_SETUP_CLSBPF,
 -};
 -
 -/* These structures hold the attributes of xdp state that are being passed
 - * to the netdevice through the xdp op.
 - */
 -enum xdp_netdev_command {
 -	/* Set or clear a bpf program used in the earliest stages of packet
 -	 * rx. The prog will have been loaded as BPF_PROG_TYPE_XDP. The callee
 -	 * is responsible for calling bpf_prog_put on any old progs that are
 -	 * stored. In case of error, the callee need not release the new prog
 -	 * reference, but on success it takes ownership and must bpf_prog_put
 -	 * when it is no longer used.
 -	 */
 -	XDP_SETUP_PROG,
 -	XDP_SETUP_PROG_HW,
 -	/* Check if a bpf program is set on the device.  The callee should
 -	 * set @prog_attached to one of XDP_ATTACHED_* values, note that "true"
 -	 * is equivalent to XDP_ATTACHED_DRV.
 -	 */
 -	XDP_QUERY_PROG,
 +	TC_SETUP_MATCHALL,
  };
  
 -struct netlink_ext_ack;
++<<<<<<< HEAD
 +struct tc_cls_u32_offload;
  
 -struct netdev_xdp {
 -	enum xdp_netdev_command command;
 +struct tc_to_netdev {
 +	unsigned int type;
  	union {
 -		/* XDP_SETUP_PROG */
 -		struct {
 -			u32 flags;
 -			struct bpf_prog *prog;
 -			struct netlink_ext_ack *extack;
 -		};
 -		/* XDP_QUERY_PROG */
 -		struct {
 -			u8 prog_attached;
 -			u32 prog_id;
 -		};
 +		u8 tc;
 +		struct tc_cls_u32_offload *cls_u32;
 +		struct tc_cls_flower_offload *cls_flower;
 +		struct tc_cls_matchall_offload *cls_mall;
  	};
  };
  
 -#ifdef CONFIG_XFRM_OFFLOAD
 -struct xfrmdev_ops {
 -	int	(*xdo_dev_state_add) (struct xfrm_state *x);
 -	void	(*xdo_dev_state_delete) (struct xfrm_state *x);
 -	void	(*xdo_dev_state_free) (struct xfrm_state *x);
 -	bool	(*xdo_dev_offload_ok) (struct sk_buff *skb,
 -				       struct xfrm_state *x);
 +/* This structure defines the management hooks for network devices.
 + * It is an extension of net_device_ops. Drivers that want to use any of the
 + * fields defined here must initialize net_device_ops->ndo_size to
 + * sizeof(struct net_device_ops).
 + *
 + * void* (*ndo_dfwd_add_station)(struct net_device *pdev,
 + *				 struct net_device *dev)
 + *	Called by upper layer devices to accelerate switching or other
 + *	station functionality into hardware. 'pdev is the lowerdev
 + *	to use for the offload and 'dev' is the net device that will
 + *	back the offload. Returns a pointer to the private structure
 + *	the upper layer will maintain.
 + * void (*ndo_dfwd_del_station)(struct net_device *pdev, void *priv)
 + *	Called by upper layer device to delete the station created
 + *	by 'ndo_dfwd_add_station'. 'pdev' is the net device backing
 + *	the station and priv is the structure returned by the add
 + *	operation.
 + * int (*ndo_set_tx_maxrate)(struct net_device *dev,
 + *			     int queue_index, u32 maxrate);
 + *	Called when a user wants to set a max-rate limitation of specific
 + *	TX queue.
 + * void (*ndo_set_rx_headroom)(struct net_device *dev, int needed_headroom);
 + *	This function is used to specify the headroom that the skb must
 + *	consider when allocation skb during packet reception. Setting
 + *	appropriate rx headroom value allows avoiding skb head copy on
 + *	forward. Setting a negative value reset the rx headroom to the
 + *	default value.
 + * int (*ndo_fdb_dump)(struct sk_buff *skb, struct netlink_callback *cb,
 + *		       struct net_device *dev, struct net_device *filter_dev,
 + *		       int *idx)
 + *	Used to add FDB entries to dump requests. Implementers should add
 + *	entries to skb and update idx with the number of entries.
 + * void (*ndo_change_proto_down)(struct net_device *dev,
 + *				 bool proto_down);
 + *	This function is used to pass protocol port error state information
 + *	to the switch driver. The switch driver can react to the proto_down
 + *      by doing a phys down on the associated switch port.
 + * void (*ndo_udp_tunnel_add)(struct net_device *dev,
 + *			      struct udp_tunnel_info *ti);
 + *	Called by UDP tunnel to notify a driver about the UDP port and socket
 + *	address family that a UDP tunnel is listnening to. It is called only
 + *	when a new port starts listening. The operation is protected by the
 + *	RTNL.
 + *
 + * void (*ndo_udp_tunnel_del)(struct net_device *dev,
 + *			      struct udp_tunnel_info *ti);
 + *	Called by UDP tunnel to notify the driver about a UDP port and socket
 + *	address family that the UDP tunnel is not listening to anymore. The
 + *	operation is protected by the RTNL.
 + *
 + * int (*ndo_set_vf_vlan)(struct net_device *dev, int vf, u16 vlan,
 + *			  u8 qos, __be16 proto);
 + *
 + * bool (*ndo_has_offload_stats)(const struct net_device *dev, int attr_id)
 + *	Return true if this device supports offload stats of this attr_id.
 + *
 + * int (*ndo_get_offload_stats)(int attr_id, const struct net_device *dev,
 + *	void *attr_data)
 + *	Get statistics for offload operations by attr_id. Write it into the
 + *	attr_data pointer.
++=======
++/* These structures hold the attributes of xdp state that are being passed
++ * to the netdevice through the xdp op.
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
 + */
 +struct net_device_ops_extended {
 +	int			(*ndo_set_vf_trust)(struct net_device *dev,
 +						    int vf, bool setting);
 +	void*			(*ndo_dfwd_add_station)(struct net_device *pdev,
 +							struct net_device *dev);
 +	void			(*ndo_dfwd_del_station)(struct net_device *pdev,
 +							void *priv);
 +	int			(*ndo_set_tx_maxrate)(struct net_device *dev,
 +						      int queue_index,
 +						      u32 maxrate);
 +	void			(*ndo_set_rx_headroom)(struct net_device *dev,
 +						       int needed_headroom);
 +	int			(*ndo_set_vf_guid)(struct net_device *dev,
 +						   int vf, u64 guid,
 +						   int guid_type);
 +	int			(*ndo_fdb_dump_rh73)(struct sk_buff *skb,
 +						struct netlink_callback *cb,
 +						struct net_device *dev,
 +						struct net_device *filter_dev,
 +						int idx);
 +	int			(*ndo_get_phys_port_name)(struct net_device *dev,
 +							  char *name, size_t len);
 +	int			(*ndo_change_proto_down)(struct net_device *dev,
 +							 bool proto_down);
 +	void			(*ndo_udp_tunnel_add)(struct net_device *dev,
 +						      struct udp_tunnel_info *ti);
 +	void			(*ndo_udp_tunnel_del)(struct net_device *dev,
 +						      struct udp_tunnel_info *ti);
 +	int			(*ndo_neigh_construct)(struct net_device *dev,
 +						       struct neighbour *n);
 +	void			(*ndo_neigh_destroy)(struct net_device *dev,
 +						     struct neighbour *n);
 +	int			(*ndo_set_vf_vlan)(struct net_device *dev,
 +						   int vf, u16 vlan, u8 qos,
 +						   __be16 proto);
 +	int			(*ndo_fdb_dump)(struct sk_buff *skb,
 +						struct netlink_callback *cb,
 +						struct net_device *dev,
 +						struct net_device *filter_dev,
 +						int *idx);
 +	bool			(*ndo_has_offload_stats)(const struct net_device *dev, int attr_id);
 +	int			(*ndo_get_offload_stats)(int attr_id,
 +							 const struct net_device *dev,
 +							 void *attr_data);
  };
 -#endif
  
  /*
   * This structure defines the management hooks for network devices.
@@@ -1041,14 -958,15 +1050,23 @@@
   *
   *      Enable or disable the VF ability to query its RSS Redirection Table and
   *      Hash Key. This is needed since on some devices VF share this information
 - *      with PF and querying it may introduce a theoretical security risk.
 + *      with PF and querying it may adduce a theoretical security risk.
   * int (*ndo_set_vf_rss_query_en)(struct net_device *dev, int vf, bool setting);
   * int (*ndo_get_vf_port)(struct net_device *dev, int vf, struct sk_buff *skb);
++<<<<<<< HEAD
 + * int (*ndo_setup_tc)(struct net_device *dev, u8 tc)
 + * 	Called to setup 'tc' number of traffic classes in the net device. This
 + * 	is always called from the stack with the rtnl lock held and netif tx
 + * 	queues stopped. This allows the netdevice to perform queue management
 + * 	safely.
++=======
+  * int (*ndo_setup_tc)(struct net_device *dev, enum tc_setup_type type,
+  *		       void *type_data);
+  *	Called to setup any 'tc' scheduler, classifier or action on @dev.
+  *	This is always called from the stack with the rtnl lock held and netif
+  *	tx queues stopped. This allows the netdevice to perform queue
+  *	management safely.
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
   *
   *	Fiber Channel over Ethernet (FCoE) offload functions.
   * int (*ndo_fcoe_enable)(struct net_device *dev);
@@@ -1260,9 -1203,15 +1278,21 @@@ struct net_device_ops 
  						   struct nlattr *port[]);
  	int			(*ndo_get_vf_port)(struct net_device *dev,
  						   int vf, struct sk_buff *skb);
++<<<<<<< HEAD
 +	RH_KABI_RENAME(int	(*ndo_setup_tc),
 +		       int	(*ndo_setup_tc_rh72))(struct net_device *dev,
 +						      u8 tc);
++=======
+ 	int			(*ndo_set_vf_guid)(struct net_device *dev,
+ 						   int vf, u64 guid,
+ 						   int guid_type);
+ 	int			(*ndo_set_vf_rss_query_en)(
+ 						   struct net_device *dev,
+ 						   int vf, bool setting);
+ 	int			(*ndo_setup_tc)(struct net_device *dev,
+ 						enum tc_setup_type type,
+ 						void *type_data);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  #if IS_ENABLED(CONFIG_FCOE)
  	int			(*ndo_fcoe_enable)(struct net_device *dev);
  	int			(*ndo_fcoe_disable)(struct net_device *dev);
diff --cc net/dsa/slave.c
index f3efc3546e20,c6b5de2fe413..000000000000
--- a/net/dsa/slave.c
+++ b/net/dsa/slave.c
@@@ -290,12 -640,327 +290,327 @@@ static int dsa_slave_get_sset_count(str
  	return -EOPNOTSUPP;
  }
  
++<<<<<<< HEAD
++=======
+ static void dsa_slave_get_wol(struct net_device *dev, struct ethtool_wolinfo *w)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (ds->ops->get_wol)
+ 		ds->ops->get_wol(ds, p->dp->index, w);
+ }
+ 
+ static int dsa_slave_set_wol(struct net_device *dev, struct ethtool_wolinfo *w)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	int ret = -EOPNOTSUPP;
+ 
+ 	if (ds->ops->set_wol)
+ 		ret = ds->ops->set_wol(ds, p->dp->index, w);
+ 
+ 	return ret;
+ }
+ 
+ static int dsa_slave_set_eee(struct net_device *dev, struct ethtool_eee *e)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	int ret;
+ 
+ 	/* Port's PHY and MAC both need to be EEE capable */
+ 	if (!p->phy)
+ 		return -ENODEV;
+ 
+ 	if (!ds->ops->set_mac_eee)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = ds->ops->set_mac_eee(ds, p->dp->index, e);
+ 	if (ret)
+ 		return ret;
+ 
+ 	if (e->eee_enabled) {
+ 		ret = phy_init_eee(p->phy, 0);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	return phy_ethtool_set_eee(p->phy, e);
+ }
+ 
+ static int dsa_slave_get_eee(struct net_device *dev, struct ethtool_eee *e)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	int ret;
+ 
+ 	/* Port's PHY and MAC both need to be EEE capable */
+ 	if (!p->phy)
+ 		return -ENODEV;
+ 
+ 	if (!ds->ops->get_mac_eee)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = ds->ops->get_mac_eee(ds, p->dp->index, e);
+ 	if (ret)
+ 		return ret;
+ 
+ 	return phy_ethtool_get_eee(p->phy, e);
+ }
+ 
+ #ifdef CONFIG_NET_POLL_CONTROLLER
+ static int dsa_slave_netpoll_setup(struct net_device *dev,
+ 				   struct netpoll_info *ni)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct net_device *master = dsa_master_netdev(p);
+ 	struct netpoll *netpoll;
+ 	int err = 0;
+ 
+ 	netpoll = kzalloc(sizeof(*netpoll), GFP_KERNEL);
+ 	if (!netpoll)
+ 		return -ENOMEM;
+ 
+ 	err = __netpoll_setup(netpoll, master);
+ 	if (err) {
+ 		kfree(netpoll);
+ 		goto out;
+ 	}
+ 
+ 	p->netpoll = netpoll;
+ out:
+ 	return err;
+ }
+ 
+ static void dsa_slave_netpoll_cleanup(struct net_device *dev)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct netpoll *netpoll = p->netpoll;
+ 
+ 	if (!netpoll)
+ 		return;
+ 
+ 	p->netpoll = NULL;
+ 
+ 	__netpoll_free_async(netpoll);
+ }
+ 
+ static void dsa_slave_poll_controller(struct net_device *dev)
+ {
+ }
+ #endif
+ 
+ static int dsa_slave_get_phys_port_name(struct net_device *dev,
+ 					char *name, size_t len)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 
+ 	if (snprintf(name, len, "p%d", p->dp->index) >= len)
+ 		return -EINVAL;
+ 
+ 	return 0;
+ }
+ 
+ static struct dsa_mall_tc_entry *
+ dsa_slave_mall_tc_entry_find(struct dsa_slave_priv *p,
+ 			     unsigned long cookie)
+ {
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 
+ 	list_for_each_entry(mall_tc_entry, &p->mall_tc_list, list)
+ 		if (mall_tc_entry->cookie == cookie)
+ 			return mall_tc_entry;
+ 
+ 	return NULL;
+ }
+ 
+ static int dsa_slave_add_cls_matchall(struct net_device *dev,
+ 				      struct tc_cls_matchall_offload *cls,
+ 				      bool ingress)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 	__be16 protocol = cls->common.protocol;
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	struct net *net = dev_net(dev);
+ 	struct dsa_slave_priv *to_p;
+ 	struct net_device *to_dev;
+ 	const struct tc_action *a;
+ 	int err = -EOPNOTSUPP;
+ 	LIST_HEAD(actions);
+ 	int ifindex;
+ 
+ 	if (!ds->ops->port_mirror_add)
+ 		return err;
+ 
+ 	if (!tcf_exts_has_one_action(cls->exts))
+ 		return err;
+ 
+ 	tcf_exts_to_list(cls->exts, &actions);
+ 	a = list_first_entry(&actions, struct tc_action, list);
+ 
+ 	if (is_tcf_mirred_egress_mirror(a) && protocol == htons(ETH_P_ALL)) {
+ 		struct dsa_mall_mirror_tc_entry *mirror;
+ 
+ 		ifindex = tcf_mirred_ifindex(a);
+ 		to_dev = __dev_get_by_index(net, ifindex);
+ 		if (!to_dev)
+ 			return -EINVAL;
+ 
+ 		if (!dsa_slave_dev_check(to_dev))
+ 			return -EOPNOTSUPP;
+ 
+ 		mall_tc_entry = kzalloc(sizeof(*mall_tc_entry), GFP_KERNEL);
+ 		if (!mall_tc_entry)
+ 			return -ENOMEM;
+ 
+ 		mall_tc_entry->cookie = cls->cookie;
+ 		mall_tc_entry->type = DSA_PORT_MALL_MIRROR;
+ 		mirror = &mall_tc_entry->mirror;
+ 
+ 		to_p = netdev_priv(to_dev);
+ 
+ 		mirror->to_local_port = to_p->dp->index;
+ 		mirror->ingress = ingress;
+ 
+ 		err = ds->ops->port_mirror_add(ds, p->dp->index, mirror,
+ 					       ingress);
+ 		if (err) {
+ 			kfree(mall_tc_entry);
+ 			return err;
+ 		}
+ 
+ 		list_add_tail(&mall_tc_entry->list, &p->mall_tc_list);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void dsa_slave_del_cls_matchall(struct net_device *dev,
+ 				       struct tc_cls_matchall_offload *cls)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (!ds->ops->port_mirror_del)
+ 		return;
+ 
+ 	mall_tc_entry = dsa_slave_mall_tc_entry_find(p, cls->cookie);
+ 	if (!mall_tc_entry)
+ 		return;
+ 
+ 	list_del(&mall_tc_entry->list);
+ 
+ 	switch (mall_tc_entry->type) {
+ 	case DSA_PORT_MALL_MIRROR:
+ 		ds->ops->port_mirror_del(ds, p->dp->index,
+ 					 &mall_tc_entry->mirror);
+ 		break;
+ 	default:
+ 		WARN_ON(1);
+ 	}
+ 
+ 	kfree(mall_tc_entry);
+ }
+ 
+ static int dsa_slave_setup_tc_cls_matchall(struct net_device *dev,
+ 					   struct tc_cls_matchall_offload *cls)
+ {
+ 	bool ingress = TC_H_MAJ(cls->common.handle) == TC_H_MAJ(TC_H_INGRESS);
+ 
+ 	if (cls->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (cls->command) {
+ 	case TC_CLSMATCHALL_REPLACE:
+ 		return dsa_slave_add_cls_matchall(dev, cls, ingress);
+ 	case TC_CLSMATCHALL_DESTROY:
+ 		dsa_slave_del_cls_matchall(dev, cls);
+ 		return 0;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int dsa_slave_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			      void *type_data)
+ {
+ 	switch (type) {
+ 	case TC_SETUP_CLSMATCHALL:
+ 		return dsa_slave_setup_tc_cls_matchall(dev, type_data);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static void dsa_slave_get_stats64(struct net_device *dev,
+ 				  struct rtnl_link_stats64 *stats)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct pcpu_sw_netstats *s;
+ 	unsigned int start;
+ 	int i;
+ 
+ 	netdev_stats_to_stats64(stats, &dev->stats);
+ 	for_each_possible_cpu(i) {
+ 		u64 tx_packets, tx_bytes, rx_packets, rx_bytes;
+ 
+ 		s = per_cpu_ptr(p->stats64, i);
+ 		do {
+ 			start = u64_stats_fetch_begin_irq(&s->syncp);
+ 			tx_packets = s->tx_packets;
+ 			tx_bytes = s->tx_bytes;
+ 			rx_packets = s->rx_packets;
+ 			rx_bytes = s->rx_bytes;
+ 		} while (u64_stats_fetch_retry_irq(&s->syncp, start));
+ 
+ 		stats->tx_packets += tx_packets;
+ 		stats->tx_bytes += tx_bytes;
+ 		stats->rx_packets += rx_packets;
+ 		stats->rx_bytes += rx_bytes;
+ 	}
+ }
+ 
+ void dsa_cpu_port_ethtool_init(struct ethtool_ops *ops)
+ {
+ 	ops->get_sset_count = dsa_cpu_port_get_sset_count;
+ 	ops->get_ethtool_stats = dsa_cpu_port_get_ethtool_stats;
+ 	ops->get_strings = dsa_cpu_port_get_strings;
+ }
+ 
+ static int dsa_slave_get_rxnfc(struct net_device *dev,
+ 			       struct ethtool_rxnfc *nfc, u32 *rule_locs)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (!ds->ops->get_rxnfc)
+ 		return -EOPNOTSUPP;
+ 
+ 	return ds->ops->get_rxnfc(ds, p->dp->index, nfc, rule_locs);
+ }
+ 
+ static int dsa_slave_set_rxnfc(struct net_device *dev,
+ 			       struct ethtool_rxnfc *nfc)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (!ds->ops->set_rxnfc)
+ 		return -EOPNOTSUPP;
+ 
+ 	return ds->ops->set_rxnfc(ds, p->dp->index, nfc);
+ }
+ 
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  static const struct ethtool_ops dsa_slave_ethtool_ops = {
 +	.get_settings		= dsa_slave_get_settings,
 +	.set_settings		= dsa_slave_set_settings,
  	.get_drvinfo		= dsa_slave_get_drvinfo,
 -	.get_regs_len		= dsa_slave_get_regs_len,
 -	.get_regs		= dsa_slave_get_regs,
  	.nway_reset		= dsa_slave_nway_reset,
  	.get_link		= dsa_slave_get_link,
 -	.get_eeprom_len		= dsa_slave_get_eeprom_len,
 -	.get_eeprom		= dsa_slave_get_eeprom,
 -	.set_eeprom		= dsa_slave_set_eeprom,
  	.get_strings		= dsa_slave_get_strings,
  	.get_ethtool_stats	= dsa_slave_get_ethtool_stats,
  	.get_sset_count		= dsa_slave_get_sset_count,
diff --cc net/sched/cls_bpf.c
index c13fb5505297,2d4d06e41cd9..000000000000
--- a/net/sched/cls_bpf.c
+++ b/net/sched/cls_bpf.c
@@@ -70,10 -131,102 +70,72 @@@ static int cls_bpf_classify(struct sk_b
  		if (ret < 0)
  			continue;
  
++<<<<<<< HEAD
 +		return ret;
++=======
+ 		break;
+ 	}
+ 	rcu_read_unlock();
+ 
+ 	return ret;
+ }
+ 
+ static bool cls_bpf_is_ebpf(const struct cls_bpf_prog *prog)
+ {
+ 	return !prog->bpf_ops;
+ }
+ 
+ static int cls_bpf_offload_cmd(struct tcf_proto *tp, struct cls_bpf_prog *prog,
+ 			       enum tc_clsbpf_command cmd)
+ {
+ 	struct net_device *dev = tp->q->dev_queue->dev;
+ 	struct tc_cls_bpf_offload cls_bpf = {};
+ 	int err;
+ 
+ 	tc_cls_common_offload_init(&cls_bpf.common, tp);
+ 	cls_bpf.command = cmd;
+ 	cls_bpf.exts = &prog->exts;
+ 	cls_bpf.prog = prog->filter;
+ 	cls_bpf.name = prog->bpf_name;
+ 	cls_bpf.exts_integrated = prog->exts_integrated;
+ 	cls_bpf.gen_flags = prog->gen_flags;
+ 
+ 	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSBPF, &cls_bpf);
+ 	if (!err && (cmd == TC_CLSBPF_ADD || cmd == TC_CLSBPF_REPLACE))
+ 		prog->gen_flags |= TCA_CLS_FLAGS_IN_HW;
+ 
+ 	return err;
+ }
+ 
+ static int cls_bpf_offload(struct tcf_proto *tp, struct cls_bpf_prog *prog,
+ 			   struct cls_bpf_prog *oldprog)
+ {
+ 	struct net_device *dev = tp->q->dev_queue->dev;
+ 	struct cls_bpf_prog *obj = prog;
+ 	enum tc_clsbpf_command cmd;
+ 	bool skip_sw;
+ 	int ret;
+ 
+ 	skip_sw = tc_skip_sw(prog->gen_flags) ||
+ 		(oldprog && tc_skip_sw(oldprog->gen_flags));
+ 
+ 	if (oldprog && oldprog->offloaded) {
+ 		if (tc_should_offload(dev, tp, prog->gen_flags)) {
+ 			cmd = TC_CLSBPF_REPLACE;
+ 		} else if (!tc_skip_sw(prog->gen_flags)) {
+ 			obj = oldprog;
+ 			cmd = TC_CLSBPF_DESTROY;
+ 		} else {
+ 			return -EINVAL;
+ 		}
+ 	} else {
+ 		if (!tc_should_offload(dev, tp, prog->gen_flags))
+ 			return skip_sw ? -EINVAL : 0;
+ 		cmd = TC_CLSBPF_ADD;
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  	}
  
 -	ret = cls_bpf_offload_cmd(tp, obj, cmd);
 -	if (ret)
 -		return skip_sw ? ret : 0;
 -
 -	obj->offloaded = true;
 -	if (oldprog)
 -		oldprog->offloaded = false;
 -
 -	return 0;
 -}
 -
 -static void cls_bpf_stop_offload(struct tcf_proto *tp,
 -				 struct cls_bpf_prog *prog)
 -{
 -	int err;
 -
 -	if (!prog->offloaded)
 -		return;
 -
 -	err = cls_bpf_offload_cmd(tp, prog, TC_CLSBPF_DESTROY);
 -	if (err) {
 -		pr_err("Stopping hardware offload failed: %d\n", err);
 -		return;
 -	}
 -
 -	prog->offloaded = false;
 -}
 -
 -static void cls_bpf_offload_update_stats(struct tcf_proto *tp,
 -					 struct cls_bpf_prog *prog)
 -{
 -	if (!prog->offloaded)
 -		return;
 -
 -	cls_bpf_offload_cmd(tp, prog, TC_CLSBPF_STATS);
 +	return -1;
  }
  
  static int cls_bpf_init(struct tcf_proto *tp)
diff --cc net/sched/cls_flower.c
index 2d81cc7499da,1474bacf4df4..000000000000
--- a/net/sched/cls_flower.c
+++ b/net/sched/cls_flower.c
@@@ -232,14 -230,11 +230,22 @@@ static void fl_hw_destroy_filter(struc
  	if (!tc_can_offload(dev, tp))
  		return;
  
++<<<<<<< HEAD
 +	offload.command = TC_CLSFLOWER_DESTROY;
 +	offload.prio = tp->prio;
 +	offload.cookie = (unsigned long)f;
 +
 +	tc->type = TC_SETUP_CLSFLOWER;
 +	tc->cls_flower = &offload;
 +
 +	dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol, tc);
++=======
+ 	tc_cls_common_offload_init(&cls_flower.common, tp);
+ 	cls_flower.command = TC_CLSFLOWER_DESTROY;
+ 	cls_flower.cookie = (unsigned long) f;
+ 
+ 	dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSFLOWER, &cls_flower);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  }
  
  static int fl_hw_replace_filter(struct tcf_proto *tp,
@@@ -264,19 -258,16 +269,32 @@@
  		f->hw_dev = dev;
  	}
  
++<<<<<<< HEAD
 +	offload.command = TC_CLSFLOWER_REPLACE;
 +	offload.prio = tp->prio;
 +	offload.cookie = (unsigned long)f;
 +	offload.dissector = dissector;
 +	offload.mask = mask;
 +	offload.key = &f->mkey;
 +	offload.exts = &f->exts;
 +
 +	tc->type = TC_SETUP_CLSFLOWER;
 +	tc->cls_flower = &offload;
 +
 +	err = dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol,
 +					    tc);
++=======
+ 	tc_cls_common_offload_init(&cls_flower.common, tp);
+ 	cls_flower.command = TC_CLSFLOWER_REPLACE;
+ 	cls_flower.cookie = (unsigned long) f;
+ 	cls_flower.dissector = dissector;
+ 	cls_flower.mask = mask;
+ 	cls_flower.key = &f->mkey;
+ 	cls_flower.exts = &f->exts;
+ 
+ 	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSFLOWER,
+ 					    &cls_flower);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  	if (!err)
  		f->flags |= TCA_CLS_FLAGS_IN_HW;
  
@@@ -294,15 -284,13 +311,25 @@@ static void fl_hw_update_stats(struct t
  	if (!tc_can_offload(dev, tp))
  		return;
  
++<<<<<<< HEAD
 +	offload.command = TC_CLSFLOWER_STATS;
 +	offload.prio = tp->prio;
 +	offload.cookie = (unsigned long)f;
 +	offload.exts = &f->exts;
 +
 +	tc->type = TC_SETUP_CLSFLOWER;
 +	tc->cls_flower = &offload;
 +
 +	dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol, tc);
++=======
+ 	tc_cls_common_offload_init(&cls_flower.common, tp);
+ 	cls_flower.command = TC_CLSFLOWER_STATS;
+ 	cls_flower.cookie = (unsigned long) f;
+ 	cls_flower.exts = &f->exts;
+ 
+ 	dev->netdev_ops->ndo_setup_tc(dev, TC_CLSFLOWER_STATS,
+ 				      &cls_flower);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  }
  
  static void __fl_delete(struct tcf_proto *tp, struct cls_fl_filter *f)
diff --cc net/sched/cls_matchall.c
index f7bc58777169,c9f6500b8080..000000000000
--- a/net/sched/cls_matchall.c
+++ b/net/sched/cls_matchall.c
@@@ -55,18 -54,16 +55,27 @@@ static int mall_replace_hw_filter(struc
  				  unsigned long cookie)
  {
  	struct net_device *dev = tp->q->dev_queue->dev;
- 	struct tc_to_netdev offload;
- 	struct tc_cls_matchall_offload mall_offload = {0};
+ 	struct tc_cls_matchall_offload cls_mall = {};
  	int err;
  
++<<<<<<< HEAD
 +	offload.type = TC_SETUP_MATCHALL;
 +	offload.cls_mall = &mall_offload;
 +	offload.cls_mall->command = TC_CLSMATCHALL_REPLACE;
 +	offload.cls_mall->exts = &head->exts;
 +	offload.cls_mall->cookie = cookie;
 +
 +	err = dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol,
 +					    &offload);
++=======
+ 	tc_cls_common_offload_init(&cls_mall.common, tp);
+ 	cls_mall.command = TC_CLSMATCHALL_REPLACE;
+ 	cls_mall.exts = &head->exts;
+ 	cls_mall.cookie = cookie;
+ 
+ 	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSMATCHALL,
+ 					    &cls_mall);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  	if (!err)
  		head->flags |= TCA_CLS_FLAGS_IN_HW;
  
@@@ -78,20 -75,16 +87,27 @@@ static void mall_destroy_hw_filter(stru
  				   unsigned long cookie)
  {
  	struct net_device *dev = tp->q->dev_queue->dev;
- 	struct tc_to_netdev offload;
- 	struct tc_cls_matchall_offload mall_offload = {0};
+ 	struct tc_cls_matchall_offload cls_mall = {};
  
++<<<<<<< HEAD
 +	offload.type = TC_SETUP_MATCHALL;
 +	offload.cls_mall = &mall_offload;
 +	offload.cls_mall->command = TC_CLSMATCHALL_DESTROY;
 +	offload.cls_mall->exts = NULL;
 +	offload.cls_mall->cookie = cookie;
 +
 +	dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol,
 +					     &offload);
++=======
+ 	tc_cls_common_offload_init(&cls_mall.common, tp);
+ 	cls_mall.command = TC_CLSMATCHALL_DESTROY;
+ 	cls_mall.cookie = cookie;
+ 
+ 	dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSMATCHALL, &cls_mall);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  }
  
 -static void mall_destroy(struct tcf_proto *tp)
 +static bool mall_destroy(struct tcf_proto *tp, bool force)
  {
  	struct cls_mall_head *head = rtnl_dereference(tp->root);
  	struct net_device *dev = tp->q->dev_queue->dev;
diff --cc net/sched/cls_u32.c
index dfc76f51e07c,4ed51d347d0a..000000000000
--- a/net/sched/cls_u32.c
+++ b/net/sched/cls_u32.c
@@@ -431,18 -431,16 +431,28 @@@ static int u32_delete_key(struct tcf_pr
  static void u32_remove_hw_knode(struct tcf_proto *tp, u32 handle)
  {
  	struct net_device *dev = tp->q->dev_queue->dev;
- 	struct tc_cls_u32_offload u32_offload = {0};
- 	struct tc_to_netdev offload;
+ 	struct tc_cls_u32_offload cls_u32 = {};
  
++<<<<<<< HEAD
 +	offload.type = TC_SETUP_CLSU32;
 +	offload.cls_u32 = &u32_offload;
 +
 +	if (tc_should_offload(dev, tp, 0)) {
 +		offload.cls_u32->command = TC_CLSU32_DELETE_KNODE;
 +		offload.cls_u32->knode.handle = handle;
 +		dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle,
 +					      tp->protocol, &offload);
 +	}
++=======
+ 	if (!tc_should_offload(dev, tp, 0))
+ 		return;
+ 
+ 	tc_cls_common_offload_init(&cls_u32.common, tp);
+ 	cls_u32.command = TC_CLSU32_DELETE_KNODE;
+ 	cls_u32.knode.handle = handle;
+ 
+ 	dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSU32, &cls_u32);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  }
  
  static int u32_replace_hw_hnode(struct tcf_proto *tp, struct tc_u_hnode *h,
@@@ -456,16 -453,13 +465,26 @@@
  	if (!tc_should_offload(dev, tp, flags))
  		return tc_skip_sw(flags) ? -EINVAL : 0;
  
++<<<<<<< HEAD
 +	offload.type = TC_SETUP_CLSU32;
 +	offload.cls_u32 = &u32_offload;
 +
 +	offload.cls_u32->command = TC_CLSU32_NEW_HNODE;
 +	offload.cls_u32->hnode.divisor = h->divisor;
 +	offload.cls_u32->hnode.handle = h->handle;
 +	offload.cls_u32->hnode.prio = h->prio;
 +
 +	err = dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle,
 +					    tp->protocol, &offload);
++=======
+ 	tc_cls_common_offload_init(&cls_u32.common, tp);
+ 	cls_u32.command = TC_CLSU32_NEW_HNODE;
+ 	cls_u32.hnode.divisor = h->divisor;
+ 	cls_u32.hnode.handle = h->handle;
+ 	cls_u32.hnode.prio = h->prio;
+ 
+ 	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSU32, &cls_u32);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  	if (tc_skip_sw(flags))
  		return err;
  
@@@ -475,54 -469,47 +494,79 @@@
  static void u32_clear_hw_hnode(struct tcf_proto *tp, struct tc_u_hnode *h)
  {
  	struct net_device *dev = tp->q->dev_queue->dev;
- 	struct tc_cls_u32_offload u32_offload = {0};
- 	struct tc_to_netdev offload;
+ 	struct tc_cls_u32_offload cls_u32 = {};
  
++<<<<<<< HEAD
 +	offload.type = TC_SETUP_CLSU32;
 +	offload.cls_u32 = &u32_offload;
 +
 +	if (tc_should_offload(dev, tp, 0)) {
 +		offload.cls_u32->command = TC_CLSU32_DELETE_HNODE;
 +		offload.cls_u32->hnode.divisor = h->divisor;
 +		offload.cls_u32->hnode.handle = h->handle;
 +		offload.cls_u32->hnode.prio = h->prio;
 +
 +		dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle,
 +					      tp->protocol, &offload);
 +	}
++=======
+ 	if (!tc_should_offload(dev, tp, 0))
+ 		return;
+ 
+ 	tc_cls_common_offload_init(&cls_u32.common, tp);
+ 	cls_u32.command = TC_CLSU32_DELETE_HNODE;
+ 	cls_u32.hnode.divisor = h->divisor;
+ 	cls_u32.hnode.handle = h->handle;
+ 	cls_u32.hnode.prio = h->prio;
+ 
+ 	dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSU32, &cls_u32);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  }
  
  static int u32_replace_hw_knode(struct tcf_proto *tp, struct tc_u_knode *n,
  				u32 flags)
  {
  	struct net_device *dev = tp->q->dev_queue->dev;
- 	struct tc_cls_u32_offload u32_offload = {0};
- 	struct tc_to_netdev offload;
+ 	struct tc_cls_u32_offload cls_u32 = {};
  	int err;
  
++<<<<<<< HEAD
 +	offload.type = TC_SETUP_CLSU32;
 +	offload.cls_u32 = &u32_offload;
 +
 +	if (!tc_should_offload(dev, tp, flags))
 +		return tc_skip_sw(flags) ? -EINVAL : 0;
 +
 +	offload.cls_u32->command = TC_CLSU32_REPLACE_KNODE;
 +	offload.cls_u32->knode.handle = n->handle;
 +	offload.cls_u32->knode.fshift = n->fshift;
++=======
+ 	if (!tc_should_offload(dev, tp, flags))
+ 		return tc_skip_sw(flags) ? -EINVAL : 0;
+ 
+ 	tc_cls_common_offload_init(&cls_u32.common, tp);
+ 	cls_u32.command = TC_CLSU32_REPLACE_KNODE;
+ 	cls_u32.knode.handle = n->handle;
+ 	cls_u32.knode.fshift = n->fshift;
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  #ifdef CONFIG_CLS_U32_MARK
- 	offload.cls_u32->knode.val = n->val;
- 	offload.cls_u32->knode.mask = n->mask;
+ 	cls_u32.knode.val = n->val;
+ 	cls_u32.knode.mask = n->mask;
  #else
- 	offload.cls_u32->knode.val = 0;
- 	offload.cls_u32->knode.mask = 0;
+ 	cls_u32.knode.val = 0;
+ 	cls_u32.knode.mask = 0;
  #endif
- 	offload.cls_u32->knode.sel = &n->sel;
- 	offload.cls_u32->knode.exts = &n->exts;
+ 	cls_u32.knode.sel = &n->sel;
+ 	cls_u32.knode.exts = &n->exts;
  	if (n->ht_down)
- 		offload.cls_u32->knode.link_handle = n->ht_down->handle;
+ 		cls_u32.knode.link_handle = n->ht_down->handle;
  
++<<<<<<< HEAD
 +	err = dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle,
 +					    tp->protocol, &offload);
++=======
+ 	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSU32, &cls_u32);
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  
  	if (!err)
  		n->flags |= TCA_CLS_FLAGS_IN_HW;
diff --cc net/sched/sch_mqprio.c
index 748ea1bbc507,2165a05994b7..000000000000
--- a/net/sched/sch_mqprio.c
+++ b/net/sched/sch_mqprio.c
@@@ -39,15 -38,13 +39,23 @@@ static void mqprio_destroy(struct Qdis
  		kfree(priv->qdiscs);
  	}
  
++<<<<<<< HEAD
 +	if (priv->hw_owned && (dev->netdev_ops->ndo_setup_tc ||
 +			       dev->netdev_ops->ndo_setup_tc_rh72))
 +		if (dev->netdev_ops->ndo_setup_tc) {
 +			dev->netdev_ops->ndo_setup_tc(dev, sch->handle, 0, &tc);
 +		} else {
 +			dev->netdev_ops->ndo_setup_tc_rh72(dev, 0);
 +		}
 +	else
++=======
+ 	if (priv->hw_offload && dev->netdev_ops->ndo_setup_tc) {
+ 		struct tc_mqprio_qopt mqprio = {};
+ 
+ 		dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_MQPRIO, &mqprio);
+ 	} else {
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  		netdev_set_num_tc(dev, 0);
 -	}
  }
  
  static int mqprio_parse_opt(struct net_device *dev, struct tc_mqprio_qopt *qopt)
@@@ -145,16 -146,14 +153,27 @@@ static int mqprio_init(struct Qdisc *sc
  	 * supplied and verified mapping
  	 */
  	if (qopt->hw) {
++<<<<<<< HEAD
 +		struct tc_to_netdev tc = {.type = TC_SETUP_MQPRIO,
 +					  { .tc = qopt->num_tc }};
 +
 +		priv->hw_owned = 1;
 +		err = dev->netdev_ops->ndo_setup_tc ?
 +			dev->netdev_ops->ndo_setup_tc(dev, sch->handle, 0,
 +						      &tc) :
 +			dev->netdev_ops->ndo_setup_tc_rh72(dev, qopt->num_tc);
 +		if (err)
 +			return err;
++=======
+ 		struct tc_mqprio_qopt mqprio = *qopt;
+ 
+ 		err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_MQPRIO,
+ 						    &mqprio);
+ 		if (err)
+ 			return err;
+ 
+ 		priv->hw_offload = mqprio.hw;
++>>>>>>> de4784ca030f (net: sched: get rid of struct tc_to_netdev)
  	} else {
  		netdev_set_num_tc(dev, qopt->num_tc);
  		for (i = 0; i < qopt->num_tc; i++)
* Unmerged path drivers/net/ethernet/freescale/dpaa/dpaa_eth.c
* Unmerged path drivers/net/ethernet/hisilicon/hns3/hns3pf/hns3_enet.c
* Unmerged path drivers/net/ethernet/netronome/nfp/bpf/main.c
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/main.h
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/offload.c
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_app.h
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_port.c
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_port.h
* Unmerged path drivers/net/ethernet/ti/netcp_core.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-drv.c
* Unmerged path drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c
* Unmerged path drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h
* Unmerged path drivers/net/ethernet/broadcom/bnxt/bnxt.c
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
* Unmerged path drivers/net/ethernet/freescale/dpaa/dpaa_eth.c
* Unmerged path drivers/net/ethernet/hisilicon/hns3/hns3pf/hns3_enet.c
* Unmerged path drivers/net/ethernet/intel/fm10k/fm10k_netdev.c
* Unmerged path drivers/net/ethernet/intel/i40e/i40e_main.c
* Unmerged path drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx4/en_netdev.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
index 34bf903fc886..4de7e72128f8 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
@@ -33,6 +33,8 @@
 #ifndef __MLX5_EN_TC_H__
 #define __MLX5_EN_TC_H__
 
+#include <net/pkt_cls.h>
+
 #define MLX5E_TC_FLOW_ID_MASK 0x0000ffff
 
 int mlx5e_tc_init(struct mlx5e_priv *priv);
* Unmerged path drivers/net/ethernet/mellanox/mlxsw/spectrum.c
* Unmerged path drivers/net/ethernet/netronome/nfp/bpf/main.c
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/main.h
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/offload.c
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_app.h
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_port.c
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_port.h
* Unmerged path drivers/net/ethernet/sfc/efx.h
* Unmerged path drivers/net/ethernet/sfc/falcon/efx.h
* Unmerged path drivers/net/ethernet/sfc/falcon/tx.c
* Unmerged path drivers/net/ethernet/sfc/tx.c
* Unmerged path drivers/net/ethernet/ti/netcp_core.c
* Unmerged path include/linux/netdevice.h
* Unmerged path net/dsa/slave.c
* Unmerged path net/sched/cls_bpf.c
* Unmerged path net/sched/cls_flower.c
* Unmerged path net/sched/cls_matchall.c
* Unmerged path net/sched/cls_u32.c
* Unmerged path net/sched/sch_mqprio.c
