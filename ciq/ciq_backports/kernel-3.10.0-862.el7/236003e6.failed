powerpc/64s: Allow control of RFI flush via debugfs

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [powerpc] 64s: Allow control of RFI flush via debugfs (Mauricio Oliveira) [1543067]
Rebuild_FUZZ: 91.49%
commit-author Michael Ellerman <mpe@ellerman.id.au>
commit 236003e6b5443c45c18e613d2b0d776a9f87540e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/236003e6.failed

Expose the state of the RFI flush (enabled/disabled) via debugfs, and
allow it to be enabled/disabled at runtime.

eg: $ cat /sys/kernel/debug/powerpc/rfi_flush
    1
    $ echo 0 > /sys/kernel/debug/powerpc/rfi_flush
    $ cat /sys/kernel/debug/powerpc/rfi_flush
    0

	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
	Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
(cherry picked from commit 236003e6b5443c45c18e613d2b0d776a9f87540e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/kernel/setup_64.c
diff --cc arch/powerpc/kernel/setup_64.c
index 93417594708c,e67413f4a8f0..000000000000
--- a/arch/powerpc/kernel/setup_64.c
+++ b/arch/powerpc/kernel/setup_64.c
@@@ -767,4 -802,141 +768,145 @@@ static int __init disable_hardlockup_de
  	return 0;
  }
  early_initcall(disable_hardlockup_detector);
++<<<<<<< HEAD
 +#endif
++=======
+ 
+ #ifdef CONFIG_PPC_BOOK3S_64
+ static enum l1d_flush_type enabled_flush_types;
+ static void *l1d_flush_fallback_area;
+ static bool no_rfi_flush;
+ bool rfi_flush;
+ 
+ static int __init handle_no_rfi_flush(char *p)
+ {
+ 	pr_info("rfi-flush: disabled on command line.");
+ 	no_rfi_flush = true;
+ 	return 0;
+ }
+ early_param("no_rfi_flush", handle_no_rfi_flush);
+ 
+ /*
+  * The RFI flush is not KPTI, but because users will see doco that says to use
+  * nopti we hijack that option here to also disable the RFI flush.
+  */
+ static int __init handle_no_pti(char *p)
+ {
+ 	pr_info("rfi-flush: disabling due to 'nopti' on command line.\n");
+ 	handle_no_rfi_flush(NULL);
+ 	return 0;
+ }
+ early_param("nopti", handle_no_pti);
+ 
+ static void do_nothing(void *unused)
+ {
+ 	/*
+ 	 * We don't need to do the flush explicitly, just enter+exit kernel is
+ 	 * sufficient, the RFI exit handlers will do the right thing.
+ 	 */
+ }
+ 
+ void rfi_flush_enable(bool enable)
+ {
+ 	if (rfi_flush == enable)
+ 		return;
+ 
+ 	if (enable) {
+ 		do_rfi_flush_fixups(enabled_flush_types);
+ 		on_each_cpu(do_nothing, NULL, 1);
+ 	} else
+ 		do_rfi_flush_fixups(L1D_FLUSH_NONE);
+ 
+ 	rfi_flush = enable;
+ }
+ 
+ static void init_fallback_flush(void)
+ {
+ 	u64 l1d_size, limit;
+ 	int cpu;
+ 
+ 	l1d_size = ppc64_caches.l1d.size;
+ 	limit = min(safe_stack_limit(), ppc64_rma_size);
+ 
+ 	/*
+ 	 * Align to L1d size, and size it at 2x L1d size, to catch possible
+ 	 * hardware prefetch runoff. We don't have a recipe for load patterns to
+ 	 * reliably avoid the prefetcher.
+ 	 */
+ 	l1d_flush_fallback_area = __va(memblock_alloc_base(l1d_size * 2, l1d_size, limit));
+ 	memset(l1d_flush_fallback_area, 0, l1d_size * 2);
+ 
+ 	for_each_possible_cpu(cpu) {
+ 		/*
+ 		 * The fallback flush is currently coded for 8-way
+ 		 * associativity. Different associativity is possible, but it
+ 		 * will be treated as 8-way and may not evict the lines as
+ 		 * effectively.
+ 		 *
+ 		 * 128 byte lines are mandatory.
+ 		 */
+ 		u64 c = l1d_size / 8;
+ 
+ 		paca[cpu].rfi_flush_fallback_area = l1d_flush_fallback_area;
+ 		paca[cpu].l1d_flush_congruence = c;
+ 		paca[cpu].l1d_flush_sets = c / 128;
+ 	}
+ }
+ 
+ void __init setup_rfi_flush(enum l1d_flush_type types, bool enable)
+ {
+ 	if (types & L1D_FLUSH_FALLBACK) {
+ 		pr_info("rfi-flush: Using fallback displacement flush\n");
+ 		init_fallback_flush();
+ 	}
+ 
+ 	if (types & L1D_FLUSH_ORI)
+ 		pr_info("rfi-flush: Using ori type flush\n");
+ 
+ 	if (types & L1D_FLUSH_MTTRIG)
+ 		pr_info("rfi-flush: Using mttrig type flush\n");
+ 
+ 	enabled_flush_types = types;
+ 
+ 	if (!no_rfi_flush)
+ 		rfi_flush_enable(enable);
+ }
+ 
+ #ifdef CONFIG_DEBUG_FS
+ static int rfi_flush_set(void *data, u64 val)
+ {
+ 	if (val == 1)
+ 		rfi_flush_enable(true);
+ 	else if (val == 0)
+ 		rfi_flush_enable(false);
+ 	else
+ 		return -EINVAL;
+ 
+ 	return 0;
+ }
+ 
+ static int rfi_flush_get(void *data, u64 *val)
+ {
+ 	*val = rfi_flush ? 1 : 0;
+ 	return 0;
+ }
+ 
+ DEFINE_SIMPLE_ATTRIBUTE(fops_rfi_flush, rfi_flush_get, rfi_flush_set, "%llu\n");
+ 
+ static __init int rfi_flush_debugfs_init(void)
+ {
+ 	debugfs_create_file("rfi_flush", 0600, powerpc_debugfs_root, NULL, &fops_rfi_flush);
+ 	return 0;
+ }
+ device_initcall(rfi_flush_debugfs_init);
+ #endif
+ 
+ ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, char *buf)
+ {
+ 	if (rfi_flush)
+ 		return sprintf(buf, "Mitigation: RFI Flush\n");
+ 
+ 	return sprintf(buf, "Vulnerable\n");
+ }
+ #endif /* CONFIG_PPC_BOOK3S_64 */
++>>>>>>> 236003e6b544 (powerpc/64s: Allow control of RFI flush via debugfs)
* Unmerged path arch/powerpc/kernel/setup_64.c
