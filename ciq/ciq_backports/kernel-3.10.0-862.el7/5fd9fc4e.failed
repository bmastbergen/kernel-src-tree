net: sched: push cls related args into cls_common structure

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [net] sched: push cls related args into cls_common structure (Ivan Vecera) [1445420]
Rebuild_FUZZ: 95.58%
commit-author Jiri Pirko <jiri@mellanox.com>
commit 5fd9fc4e207dba0c05cafe78417952b4c4ca02dc
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/5fd9fc4e.failed

As ndo_setup_tc is generic offload op for whole tc subsystem, does not
really make sense to have cls-specific args. So move them under
cls_common structurure which is embedded in all cls structs.

	Signed-off-by: Jiri Pirko <jiri@mellanox.com>
	Acked-by: Jamal Hadi Salim <jhs@mojatatu.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 5fd9fc4e207dba0c05cafe78417952b4c4ca02dc)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/amd/xgbe/xgbe-drv.c
#	drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c
#	drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h
#	drivers/net/ethernet/broadcom/bnxt/bnxt.c
#	drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
#	drivers/net/ethernet/freescale/dpaa/dpaa_eth.c
#	drivers/net/ethernet/hisilicon/hns3/hns3pf/hns3_enet.c
#	drivers/net/ethernet/intel/fm10k/fm10k_netdev.c
#	drivers/net/ethernet/intel/i40e/i40e_main.c
#	drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
#	drivers/net/ethernet/mellanox/mlx4/en_netdev.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_main.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
#	drivers/net/ethernet/mellanox/mlxsw/spectrum.c
#	drivers/net/ethernet/netronome/nfp/bpf/main.c
#	drivers/net/ethernet/netronome/nfp/flower/main.h
#	drivers/net/ethernet/netronome/nfp/flower/offload.c
#	drivers/net/ethernet/netronome/nfp/nfp_app.h
#	drivers/net/ethernet/netronome/nfp/nfp_port.c
#	drivers/net/ethernet/netronome/nfp/nfp_port.h
#	drivers/net/ethernet/sfc/efx.h
#	drivers/net/ethernet/sfc/falcon/efx.h
#	drivers/net/ethernet/sfc/falcon/tx.c
#	drivers/net/ethernet/sfc/tx.c
#	drivers/net/ethernet/ti/netcp_core.c
#	include/linux/netdevice.h
#	include/net/pkt_cls.h
#	net/dsa/slave.c
#	net/sched/cls_bpf.c
#	net/sched/cls_flower.c
#	net/sched/cls_matchall.c
#	net/sched/cls_u32.c
#	net/sched/sch_mqprio.c
diff --cc drivers/net/ethernet/amd/xgbe/xgbe-drv.c
index a01866542bfd,bbb7bfe0be7f..000000000000
--- a/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
+++ b/drivers/net/ethernet/amd/xgbe/xgbe-drv.c
@@@ -1852,7 -1918,7 +1852,11 @@@ static void xgbe_poll_controller(struc
  }
  #endif /* End CONFIG_NET_POLL_CONTROLLER */
  
++<<<<<<< HEAD
 +static int xgbe_setup_tc(struct net_device *netdev, u32 handle, __be16 proto,
++=======
+ static int xgbe_setup_tc(struct net_device *netdev, enum tc_setup_type type,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  			 struct tc_to_netdev *tc_to_netdev)
  {
  	struct xgbe_prv_data *pdata = netdev_priv(netdev);
diff --cc drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c
index 4810103f310d,257cf4be0162..000000000000
--- a/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c
+++ b/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c
@@@ -4283,12 -4284,15 +4283,16 @@@ int bnx2x_setup_tc(struct net_device *d
  	return 0;
  }
  
++<<<<<<< HEAD
 +int __bnx2x_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
++=======
+ int __bnx2x_setup_tc(struct net_device *dev, enum tc_setup_type type,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  		     struct tc_to_netdev *tc)
  {
 -	if (type != TC_SETUP_MQPRIO)
 +	if (tc->type != TC_SETUP_MQPRIO)
  		return -EINVAL;
 -
 -	tc->mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
 -
 -	return bnx2x_setup_tc(dev, tc->mqprio->num_tc);
 +	return bnx2x_setup_tc(dev, tc->tc);
  }
  
  /* called with rtnl_lock */
diff --cc drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h
index 243cb9748d35,04eb95043023..000000000000
--- a/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h
+++ b/drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h
@@@ -486,7 -486,7 +486,11 @@@ netdev_tx_t bnx2x_start_xmit(struct sk_
  
  /* setup_tc callback */
  int bnx2x_setup_tc(struct net_device *dev, u8 num_tc);
++<<<<<<< HEAD
 +int __bnx2x_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
++=======
+ int __bnx2x_setup_tc(struct net_device *dev, enum tc_setup_type type,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  		     struct tc_to_netdev *tc);
  
  int bnx2x_get_vf_config(struct net_device *dev, int vf,
diff --cc drivers/net/ethernet/broadcom/bnxt/bnxt.c
index bdacd982a1af,1545b88c545d..000000000000
--- a/drivers/net/ethernet/broadcom/bnxt/bnxt.c
+++ b/drivers/net/ethernet/broadcom/bnxt/bnxt.c
@@@ -6715,13 -7237,15 +6715,17 @@@ int bnxt_setup_mq_tc(struct net_device 
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int bnxt_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
++=======
+ static int bnxt_setup_tc(struct net_device *dev, enum tc_setup_type type,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  			 struct tc_to_netdev *ntc)
  {
 -	if (type != TC_SETUP_MQPRIO)
 +	if (ntc->type != TC_SETUP_MQPRIO)
  		return -EINVAL;
  
 -	ntc->mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
 -
 -	return bnxt_setup_mq_tc(dev, ntc->mqprio->num_tc);
 +	return bnxt_setup_mq_tc(dev, ntc->tc);
  }
  
  #ifdef CONFIG_RFS_ACCEL
diff --cc drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
index 7eb2bfa69942,13199317c8e0..000000000000
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
@@@ -2749,7 -2889,25 +2749,29 @@@ static int cxgb_set_tx_maxrate(struct n
  	return err;
  }
  
++<<<<<<< HEAD
 +static int cxgb_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
++=======
+ static int cxgb_setup_tc_cls_u32(struct net_device *dev,
+ 				 struct tc_cls_u32_offload *cls_u32)
+ {
+ 	if (TC_H_MAJ(cls_u32->common.handle) != TC_H_MAJ(TC_H_INGRESS) ||
+ 	    cls_u32->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (cls_u32->command) {
+ 	case TC_CLSU32_NEW_KNODE:
+ 	case TC_CLSU32_REPLACE_KNODE:
+ 		return cxgb4_config_knode(dev, cls_u32);
+ 	case TC_CLSU32_DELETE_KNODE:
+ 		return cxgb4_delete_knode(dev, cls_u32);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int cxgb_setup_tc(struct net_device *dev, enum tc_setup_type type,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  			 struct tc_to_netdev *tc)
  {
  	struct port_info *pi = netdev2pinfo(dev);
@@@ -2762,20 -2920,12 +2784,28 @@@
  		return -EINVAL;
  	}
  
++<<<<<<< HEAD
 +	if (TC_H_MAJ(handle) == TC_H_MAJ(TC_H_INGRESS) &&
 +	    tc->type == TC_SETUP_CLSU32) {
 +		switch (tc->cls_u32->command) {
 +		case TC_CLSU32_NEW_KNODE:
 +		case TC_CLSU32_REPLACE_KNODE:
 +			return cxgb4_config_knode(dev, proto, tc->cls_u32);
 +		case TC_CLSU32_DELETE_KNODE:
 +			return cxgb4_delete_knode(dev, proto, tc->cls_u32);
 +		default:
 +			return -EOPNOTSUPP;
 +		}
++=======
+ 	switch (type) {
+ 	case TC_SETUP_CLSU32:
+ 		return cxgb_setup_tc_cls_u32(dev, tc->cls_u32);
+ 	default:
+ 		return -EOPNOTSUPP;
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  	}
 +
 +	return -EOPNOTSUPP;
  }
  
  static netdev_features_t cxgb_fix_features(struct net_device *dev,
diff --cc drivers/net/ethernet/intel/fm10k/fm10k_netdev.c
index 4afd8bd1bd47,71004b8eff95..000000000000
--- a/drivers/net/ethernet/intel/fm10k/fm10k_netdev.c
+++ b/drivers/net/ethernet/intel/fm10k/fm10k_netdev.c
@@@ -1236,16 -1265,17 +1236,20 @@@ err_queueing_scheme
  	return err;
  }
  
++<<<<<<< HEAD
 +static int __fm10k_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
++=======
+ static int __fm10k_setup_tc(struct net_device *dev, enum tc_setup_type type,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  			    struct tc_to_netdev *tc)
  {
 -	if (type != TC_SETUP_MQPRIO)
 +	if (tc->type != TC_SETUP_MQPRIO)
  		return -EINVAL;
  
 -	tc->mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
 -
 -	return fm10k_setup_tc(dev, tc->mqprio->num_tc);
 +	return fm10k_setup_tc(dev, tc->tc);
  }
  
 +#if 0
  static void fm10k_assign_l2_accel(struct fm10k_intfc *interface,
  				  struct fm10k_l2_accel *l2_accel)
  {
diff --cc drivers/net/ethernet/intel/i40e/i40e_main.c
index 807f35d0c136,97d8bb2e8320..000000000000
--- a/drivers/net/ethernet/intel/i40e/i40e_main.c
+++ b/drivers/net/ethernet/intel/i40e/i40e_main.c
@@@ -5610,17 -5656,15 +5610,21 @@@ exit
  	return ret;
  }
  
++<<<<<<< HEAD
 +#ifdef I40E_FCOE
 +int __i40e_setup_tc(struct net_device *netdev, u32 handle, __be16 proto,
 +		    struct tc_to_netdev *tc)
 +#else
 +static int __i40e_setup_tc(struct net_device *netdev, u32 handle, __be16 proto,
++=======
+ static int __i40e_setup_tc(struct net_device *netdev, enum tc_setup_type type,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  			   struct tc_to_netdev *tc)
 +#endif
  {
 -	if (type != TC_SETUP_MQPRIO)
 +	if (handle != TC_H_ROOT || tc->type != TC_SETUP_MQPRIO)
  		return -EINVAL;
 -
 -	tc->mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
 -
 -	return i40e_setup_tc(netdev, tc->mqprio->num_tc);
 +	return i40e_setup_tc(netdev, tc->tc);
  }
  
  /**
diff --cc drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
index c0b8df7cf72a,0a350314d76b..000000000000
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
@@@ -8564,14 -8793,481 +8564,492 @@@ int ixgbe_setup_tc(struct net_device *d
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int __ixgbe_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
 +			    struct tc_to_netdev *tc)
 +{
 +	/* Only support egress tc setup for now */
 +	if (tc->type != TC_SETUP_MQPRIO)
 +		return -EINVAL;
 +
 +	return ixgbe_setup_tc(dev, tc->tc);
++=======
+ static int ixgbe_delete_clsu32(struct ixgbe_adapter *adapter,
+ 			       struct tc_cls_u32_offload *cls)
+ {
+ 	u32 hdl = cls->knode.handle;
+ 	u32 uhtid = TC_U32_USERHTID(cls->knode.handle);
+ 	u32 loc = cls->knode.handle & 0xfffff;
+ 	int err = 0, i, j;
+ 	struct ixgbe_jump_table *jump = NULL;
+ 
+ 	if (loc > IXGBE_MAX_HW_ENTRIES)
+ 		return -EINVAL;
+ 
+ 	if ((uhtid != 0x800) && (uhtid >= IXGBE_MAX_LINK_HANDLE))
+ 		return -EINVAL;
+ 
+ 	/* Clear this filter in the link data it is associated with */
+ 	if (uhtid != 0x800) {
+ 		jump = adapter->jump_tables[uhtid];
+ 		if (!jump)
+ 			return -EINVAL;
+ 		if (!test_bit(loc - 1, jump->child_loc_map))
+ 			return -EINVAL;
+ 		clear_bit(loc - 1, jump->child_loc_map);
+ 	}
+ 
+ 	/* Check if the filter being deleted is a link */
+ 	for (i = 1; i < IXGBE_MAX_LINK_HANDLE; i++) {
+ 		jump = adapter->jump_tables[i];
+ 		if (jump && jump->link_hdl == hdl) {
+ 			/* Delete filters in the hardware in the child hash
+ 			 * table associated with this link
+ 			 */
+ 			for (j = 0; j < IXGBE_MAX_HW_ENTRIES; j++) {
+ 				if (!test_bit(j, jump->child_loc_map))
+ 					continue;
+ 				spin_lock(&adapter->fdir_perfect_lock);
+ 				err = ixgbe_update_ethtool_fdir_entry(adapter,
+ 								      NULL,
+ 								      j + 1);
+ 				spin_unlock(&adapter->fdir_perfect_lock);
+ 				clear_bit(j, jump->child_loc_map);
+ 			}
+ 			/* Remove resources for this link */
+ 			kfree(jump->input);
+ 			kfree(jump->mask);
+ 			kfree(jump);
+ 			adapter->jump_tables[i] = NULL;
+ 			return err;
+ 		}
+ 	}
+ 
+ 	spin_lock(&adapter->fdir_perfect_lock);
+ 	err = ixgbe_update_ethtool_fdir_entry(adapter, NULL, loc);
+ 	spin_unlock(&adapter->fdir_perfect_lock);
+ 	return err;
+ }
+ 
+ static int ixgbe_configure_clsu32_add_hnode(struct ixgbe_adapter *adapter,
+ 					    struct tc_cls_u32_offload *cls)
+ {
+ 	u32 uhtid = TC_U32_USERHTID(cls->hnode.handle);
+ 
+ 	if (uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 		return -EINVAL;
+ 
+ 	/* This ixgbe devices do not support hash tables at the moment
+ 	 * so abort when given hash tables.
+ 	 */
+ 	if (cls->hnode.divisor > 0)
+ 		return -EINVAL;
+ 
+ 	set_bit(uhtid - 1, &adapter->tables);
+ 	return 0;
+ }
+ 
+ static int ixgbe_configure_clsu32_del_hnode(struct ixgbe_adapter *adapter,
+ 					    struct tc_cls_u32_offload *cls)
+ {
+ 	u32 uhtid = TC_U32_USERHTID(cls->hnode.handle);
+ 
+ 	if (uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 		return -EINVAL;
+ 
+ 	clear_bit(uhtid - 1, &adapter->tables);
+ 	return 0;
+ }
+ 
+ #ifdef CONFIG_NET_CLS_ACT
+ struct upper_walk_data {
+ 	struct ixgbe_adapter *adapter;
+ 	u64 action;
+ 	int ifindex;
+ 	u8 queue;
+ };
+ 
+ static int get_macvlan_queue(struct net_device *upper, void *_data)
+ {
+ 	if (netif_is_macvlan(upper)) {
+ 		struct macvlan_dev *dfwd = netdev_priv(upper);
+ 		struct ixgbe_fwd_adapter *vadapter = dfwd->fwd_priv;
+ 		struct upper_walk_data *data = _data;
+ 		struct ixgbe_adapter *adapter = data->adapter;
+ 		int ifindex = data->ifindex;
+ 
+ 		if (vadapter && vadapter->netdev->ifindex == ifindex) {
+ 			data->queue = adapter->rx_ring[vadapter->rx_base_queue]->reg_idx;
+ 			data->action = data->queue;
+ 			return 1;
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int handle_redirect_action(struct ixgbe_adapter *adapter, int ifindex,
+ 				  u8 *queue, u64 *action)
+ {
+ 	unsigned int num_vfs = adapter->num_vfs, vf;
+ 	struct upper_walk_data data;
+ 	struct net_device *upper;
+ 
+ 	/* redirect to a SRIOV VF */
+ 	for (vf = 0; vf < num_vfs; ++vf) {
+ 		upper = pci_get_drvdata(adapter->vfinfo[vf].vfdev);
+ 		if (upper->ifindex == ifindex) {
+ 			if (adapter->num_rx_pools > 1)
+ 				*queue = vf * 2;
+ 			else
+ 				*queue = vf * adapter->num_rx_queues_per_pool;
+ 
+ 			*action = vf + 1;
+ 			*action <<= ETHTOOL_RX_FLOW_SPEC_RING_VF_OFF;
+ 			return 0;
+ 		}
+ 	}
+ 
+ 	/* redirect to a offloaded macvlan netdev */
+ 	data.adapter = adapter;
+ 	data.ifindex = ifindex;
+ 	data.action = 0;
+ 	data.queue = 0;
+ 	if (netdev_walk_all_upper_dev_rcu(adapter->netdev,
+ 					  get_macvlan_queue, &data)) {
+ 		*action = data.action;
+ 		*queue = data.queue;
+ 
+ 		return 0;
+ 	}
+ 
+ 	return -EINVAL;
+ }
+ 
+ static int parse_tc_actions(struct ixgbe_adapter *adapter,
+ 			    struct tcf_exts *exts, u64 *action, u8 *queue)
+ {
+ 	const struct tc_action *a;
+ 	LIST_HEAD(actions);
+ 	int err;
+ 
+ 	if (!tcf_exts_has_actions(exts))
+ 		return -EINVAL;
+ 
+ 	tcf_exts_to_list(exts, &actions);
+ 	list_for_each_entry(a, &actions, list) {
+ 
+ 		/* Drop action */
+ 		if (is_tcf_gact_shot(a)) {
+ 			*action = IXGBE_FDIR_DROP_QUEUE;
+ 			*queue = IXGBE_FDIR_DROP_QUEUE;
+ 			return 0;
+ 		}
+ 
+ 		/* Redirect to a VF or a offloaded macvlan */
+ 		if (is_tcf_mirred_egress_redirect(a)) {
+ 			int ifindex = tcf_mirred_ifindex(a);
+ 
+ 			err = handle_redirect_action(adapter, ifindex, queue,
+ 						     action);
+ 			if (err == 0)
+ 				return err;
+ 		}
+ 	}
+ 
+ 	return -EINVAL;
+ }
+ #else
+ static int parse_tc_actions(struct ixgbe_adapter *adapter,
+ 			    struct tcf_exts *exts, u64 *action, u8 *queue)
+ {
+ 	return -EINVAL;
+ }
+ #endif /* CONFIG_NET_CLS_ACT */
+ 
+ static int ixgbe_clsu32_build_input(struct ixgbe_fdir_filter *input,
+ 				    union ixgbe_atr_input *mask,
+ 				    struct tc_cls_u32_offload *cls,
+ 				    struct ixgbe_mat_field *field_ptr,
+ 				    struct ixgbe_nexthdr *nexthdr)
+ {
+ 	int i, j, off;
+ 	__be32 val, m;
+ 	bool found_entry = false, found_jump_field = false;
+ 
+ 	for (i = 0; i < cls->knode.sel->nkeys; i++) {
+ 		off = cls->knode.sel->keys[i].off;
+ 		val = cls->knode.sel->keys[i].val;
+ 		m = cls->knode.sel->keys[i].mask;
+ 
+ 		for (j = 0; field_ptr[j].val; j++) {
+ 			if (field_ptr[j].off == off) {
+ 				field_ptr[j].val(input, mask, val, m);
+ 				input->filter.formatted.flow_type |=
+ 					field_ptr[j].type;
+ 				found_entry = true;
+ 				break;
+ 			}
+ 		}
+ 		if (nexthdr) {
+ 			if (nexthdr->off == cls->knode.sel->keys[i].off &&
+ 			    nexthdr->val == cls->knode.sel->keys[i].val &&
+ 			    nexthdr->mask == cls->knode.sel->keys[i].mask)
+ 				found_jump_field = true;
+ 			else
+ 				continue;
+ 		}
+ 	}
+ 
+ 	if (nexthdr && !found_jump_field)
+ 		return -EINVAL;
+ 
+ 	if (!found_entry)
+ 		return 0;
+ 
+ 	mask->formatted.flow_type = IXGBE_ATR_L4TYPE_IPV6_MASK |
+ 				    IXGBE_ATR_L4TYPE_MASK;
+ 
+ 	if (input->filter.formatted.flow_type == IXGBE_ATR_FLOW_TYPE_IPV4)
+ 		mask->formatted.flow_type &= IXGBE_ATR_L4TYPE_IPV6_MASK;
+ 
+ 	return 0;
+ }
+ 
+ static int ixgbe_configure_clsu32(struct ixgbe_adapter *adapter,
+ 				  struct tc_cls_u32_offload *cls)
+ {
+ 	__be16 protocol = cls->common.protocol;
+ 	u32 loc = cls->knode.handle & 0xfffff;
+ 	struct ixgbe_hw *hw = &adapter->hw;
+ 	struct ixgbe_mat_field *field_ptr;
+ 	struct ixgbe_fdir_filter *input = NULL;
+ 	union ixgbe_atr_input *mask = NULL;
+ 	struct ixgbe_jump_table *jump = NULL;
+ 	int i, err = -EINVAL;
+ 	u8 queue;
+ 	u32 uhtid, link_uhtid;
+ 
+ 	uhtid = TC_U32_USERHTID(cls->knode.handle);
+ 	link_uhtid = TC_U32_USERHTID(cls->knode.link_handle);
+ 
+ 	/* At the moment cls_u32 jumps to network layer and skips past
+ 	 * L2 headers. The canonical method to match L2 frames is to use
+ 	 * negative values. However this is error prone at best but really
+ 	 * just broken because there is no way to "know" what sort of hdr
+ 	 * is in front of the network layer. Fix cls_u32 to support L2
+ 	 * headers when needed.
+ 	 */
+ 	if (protocol != htons(ETH_P_IP))
+ 		return err;
+ 
+ 	if (loc >= ((1024 << adapter->fdir_pballoc) - 2)) {
+ 		e_err(drv, "Location out of range\n");
+ 		return err;
+ 	}
+ 
+ 	/* cls u32 is a graph starting at root node 0x800. The driver tracks
+ 	 * links and also the fields used to advance the parser across each
+ 	 * link (e.g. nexthdr/eat parameters from 'tc'). This way we can map
+ 	 * the u32 graph onto the hardware parse graph denoted in ixgbe_model.h
+ 	 * To add support for new nodes update ixgbe_model.h parse structures
+ 	 * this function _should_ be generic try not to hardcode values here.
+ 	 */
+ 	if (uhtid == 0x800) {
+ 		field_ptr = (adapter->jump_tables[0])->mat;
+ 	} else {
+ 		if (uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 			return err;
+ 		if (!adapter->jump_tables[uhtid])
+ 			return err;
+ 		field_ptr = (adapter->jump_tables[uhtid])->mat;
+ 	}
+ 
+ 	if (!field_ptr)
+ 		return err;
+ 
+ 	/* At this point we know the field_ptr is valid and need to either
+ 	 * build cls_u32 link or attach filter. Because adding a link to
+ 	 * a handle that does not exist is invalid and the same for adding
+ 	 * rules to handles that don't exist.
+ 	 */
+ 
+ 	if (link_uhtid) {
+ 		struct ixgbe_nexthdr *nexthdr = ixgbe_ipv4_jumps;
+ 
+ 		if (link_uhtid >= IXGBE_MAX_LINK_HANDLE)
+ 			return err;
+ 
+ 		if (!test_bit(link_uhtid - 1, &adapter->tables))
+ 			return err;
+ 
+ 		/* Multiple filters as links to the same hash table are not
+ 		 * supported. To add a new filter with the same next header
+ 		 * but different match/jump conditions, create a new hash table
+ 		 * and link to it.
+ 		 */
+ 		if (adapter->jump_tables[link_uhtid] &&
+ 		    (adapter->jump_tables[link_uhtid])->link_hdl) {
+ 			e_err(drv, "Link filter exists for link: %x\n",
+ 			      link_uhtid);
+ 			return err;
+ 		}
+ 
+ 		for (i = 0; nexthdr[i].jump; i++) {
+ 			if (nexthdr[i].o != cls->knode.sel->offoff ||
+ 			    nexthdr[i].s != cls->knode.sel->offshift ||
+ 			    nexthdr[i].m != cls->knode.sel->offmask)
+ 				return err;
+ 
+ 			jump = kzalloc(sizeof(*jump), GFP_KERNEL);
+ 			if (!jump)
+ 				return -ENOMEM;
+ 			input = kzalloc(sizeof(*input), GFP_KERNEL);
+ 			if (!input) {
+ 				err = -ENOMEM;
+ 				goto free_jump;
+ 			}
+ 			mask = kzalloc(sizeof(*mask), GFP_KERNEL);
+ 			if (!mask) {
+ 				err = -ENOMEM;
+ 				goto free_input;
+ 			}
+ 			jump->input = input;
+ 			jump->mask = mask;
+ 			jump->link_hdl = cls->knode.handle;
+ 
+ 			err = ixgbe_clsu32_build_input(input, mask, cls,
+ 						       field_ptr, &nexthdr[i]);
+ 			if (!err) {
+ 				jump->mat = nexthdr[i].jump;
+ 				adapter->jump_tables[link_uhtid] = jump;
+ 				break;
+ 			}
+ 		}
+ 		return 0;
+ 	}
+ 
+ 	input = kzalloc(sizeof(*input), GFP_KERNEL);
+ 	if (!input)
+ 		return -ENOMEM;
+ 	mask = kzalloc(sizeof(*mask), GFP_KERNEL);
+ 	if (!mask) {
+ 		err = -ENOMEM;
+ 		goto free_input;
+ 	}
+ 
+ 	if ((uhtid != 0x800) && (adapter->jump_tables[uhtid])) {
+ 		if ((adapter->jump_tables[uhtid])->input)
+ 			memcpy(input, (adapter->jump_tables[uhtid])->input,
+ 			       sizeof(*input));
+ 		if ((adapter->jump_tables[uhtid])->mask)
+ 			memcpy(mask, (adapter->jump_tables[uhtid])->mask,
+ 			       sizeof(*mask));
+ 
+ 		/* Lookup in all child hash tables if this location is already
+ 		 * filled with a filter
+ 		 */
+ 		for (i = 1; i < IXGBE_MAX_LINK_HANDLE; i++) {
+ 			struct ixgbe_jump_table *link = adapter->jump_tables[i];
+ 
+ 			if (link && (test_bit(loc - 1, link->child_loc_map))) {
+ 				e_err(drv, "Filter exists in location: %x\n",
+ 				      loc);
+ 				err = -EINVAL;
+ 				goto err_out;
+ 			}
+ 		}
+ 	}
+ 	err = ixgbe_clsu32_build_input(input, mask, cls, field_ptr, NULL);
+ 	if (err)
+ 		goto err_out;
+ 
+ 	err = parse_tc_actions(adapter, cls->knode.exts, &input->action,
+ 			       &queue);
+ 	if (err < 0)
+ 		goto err_out;
+ 
+ 	input->sw_idx = loc;
+ 
+ 	spin_lock(&adapter->fdir_perfect_lock);
+ 
+ 	if (hlist_empty(&adapter->fdir_filter_list)) {
+ 		memcpy(&adapter->fdir_mask, mask, sizeof(*mask));
+ 		err = ixgbe_fdir_set_input_mask_82599(hw, mask);
+ 		if (err)
+ 			goto err_out_w_lock;
+ 	} else if (memcmp(&adapter->fdir_mask, mask, sizeof(*mask))) {
+ 		err = -EINVAL;
+ 		goto err_out_w_lock;
+ 	}
+ 
+ 	ixgbe_atr_compute_perfect_hash_82599(&input->filter, mask);
+ 	err = ixgbe_fdir_write_perfect_filter_82599(hw, &input->filter,
+ 						    input->sw_idx, queue);
+ 	if (!err)
+ 		ixgbe_update_ethtool_fdir_entry(adapter, input, input->sw_idx);
+ 	spin_unlock(&adapter->fdir_perfect_lock);
+ 
+ 	if ((uhtid != 0x800) && (adapter->jump_tables[uhtid]))
+ 		set_bit(loc - 1, (adapter->jump_tables[uhtid])->child_loc_map);
+ 
+ 	kfree(mask);
+ 	return err;
+ err_out_w_lock:
+ 	spin_unlock(&adapter->fdir_perfect_lock);
+ err_out:
+ 	kfree(mask);
+ free_input:
+ 	kfree(input);
+ free_jump:
+ 	kfree(jump);
+ 	return err;
+ }
+ 
+ static int ixgbe_setup_tc_cls_u32(struct net_device *dev,
+ 				  struct tc_cls_u32_offload *cls_u32)
+ {
+ 	struct ixgbe_adapter *adapter = netdev_priv(dev);
+ 
+ 	if (TC_H_MAJ(cls_u32->common.handle) != TC_H_MAJ(TC_H_INGRESS) ||
+ 	    cls_u32->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (cls_u32->command) {
+ 	case TC_CLSU32_NEW_KNODE:
+ 	case TC_CLSU32_REPLACE_KNODE:
+ 		return ixgbe_configure_clsu32(adapter, cls_u32);
+ 	case TC_CLSU32_DELETE_KNODE:
+ 		return ixgbe_delete_clsu32(adapter, cls_u32);
+ 	case TC_CLSU32_NEW_HNODE:
+ 	case TC_CLSU32_REPLACE_HNODE:
+ 		return ixgbe_configure_clsu32_add_hnode(adapter, cls_u32);
+ 	case TC_CLSU32_DELETE_HNODE:
+ 		return ixgbe_configure_clsu32_del_hnode(adapter, cls_u32);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int ixgbe_setup_tc_mqprio(struct net_device *dev,
+ 				 struct tc_mqprio_qopt *mqprio)
+ {
+ 	mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
+ 	return ixgbe_setup_tc(dev, mqprio->num_tc);
+ }
+ 
+ static int __ixgbe_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			    struct tc_to_netdev *tc)
+ {
+ 	switch (type) {
+ 	case TC_SETUP_CLSU32:
+ 		return ixgbe_setup_tc_cls_u32(dev, tc->cls_u32);
+ 	case TC_SETUP_MQPRIO:
+ 		return ixgbe_setup_tc_mqprio(dev, tc->mqprio);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  }
  
  #ifdef CONFIG_PCI_IOV
diff --cc drivers/net/ethernet/mellanox/mlx4/en_netdev.c
index 76d984cbb6d9,e81083e25ba6..000000000000
--- a/drivers/net/ethernet/mellanox/mlx4/en_netdev.c
+++ b/drivers/net/ethernet/mellanox/mlx4/en_netdev.c
@@@ -82,13 -86,62 +82,61 @@@ int mlx4_en_setup_tc(struct net_device 
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int __mlx4_en_setup_tc(struct net_device *dev, u32 handle, __be16 proto,
++=======
+ int mlx4_en_alloc_tx_queue_per_tc(struct net_device *dev, u8 tc)
+ {
+ 	struct mlx4_en_priv *priv = netdev_priv(dev);
+ 	struct mlx4_en_dev *mdev = priv->mdev;
+ 	struct mlx4_en_port_profile new_prof;
+ 	struct mlx4_en_priv *tmp;
+ 	int port_up = 0;
+ 	int err = 0;
+ 
+ 	tmp = kzalloc(sizeof(*tmp), GFP_KERNEL);
+ 	if (!tmp)
+ 		return -ENOMEM;
+ 
+ 	mutex_lock(&mdev->state_lock);
+ 	memcpy(&new_prof, priv->prof, sizeof(struct mlx4_en_port_profile));
+ 	new_prof.num_up = (tc == 0) ? MLX4_EN_NUM_UP_LOW :
+ 				      MLX4_EN_NUM_UP_HIGH;
+ 	new_prof.tx_ring_num[TX] = new_prof.num_tx_rings_p_up *
+ 				   new_prof.num_up;
+ 	err = mlx4_en_try_alloc_resources(priv, tmp, &new_prof, true);
+ 	if (err)
+ 		goto out;
+ 
+ 	if (priv->port_up) {
+ 		port_up = 1;
+ 		mlx4_en_stop_port(dev, 1);
+ 	}
+ 
+ 	mlx4_en_safe_replace_resources(priv, tmp);
+ 	if (port_up) {
+ 		err = mlx4_en_start_port(dev);
+ 		if (err) {
+ 			en_err(priv, "Failed starting port for setup TC\n");
+ 			goto out;
+ 		}
+ 	}
+ 
+ 	err = mlx4_en_setup_tc(dev, tc);
+ out:
+ 	mutex_unlock(&mdev->state_lock);
+ 	kfree(tmp);
+ 	return err;
+ }
+ 
+ static int __mlx4_en_setup_tc(struct net_device *dev, enum tc_setup_type type,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  			      struct tc_to_netdev *tc)
  {
 -	if (type != TC_SETUP_MQPRIO)
 -		return -EINVAL;
 -
 -	if (tc->mqprio->num_tc && tc->mqprio->num_tc != MLX4_EN_NUM_UP_HIGH)
 +	if (tc->type != TC_SETUP_MQPRIO)
  		return -EINVAL;
  
 -	tc->mqprio->hw = TC_MQPRIO_HW_OFFLOAD_TCS;
 -
 -	return mlx4_en_alloc_tx_queue_per_tc(dev, tc->mqprio->num_tc);
 +	return mlx4_en_setup_tc(dev, tc->tc);
  }
  
  #ifdef CONFIG_RFS_ACCEL
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index edb21d8194bc,15f2a942962a..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@@ -2609,24 -3031,35 +2609,56 @@@ static int mlx5e_setup_tc(struct net_de
  	return err;
  }
  
++<<<<<<< HEAD
 +static int mlx5e_ndo_setup_tc(struct net_device *dev, u32 handle,
 +			      __be16 proto, struct tc_to_netdev *tc)
 +{
 +	struct mlx5e_priv *priv = netdev_priv(dev);
 +
 +	if (TC_H_MAJ(handle) != TC_H_MAJ(TC_H_INGRESS))
 +		goto mqprio;
 +
 +	switch (tc->type) {
 +	case TC_SETUP_CLSFLOWER:
 +		switch (tc->cls_flower->command) {
 +		case TC_CLSFLOWER_REPLACE:
 +			return mlx5e_configure_flower(priv, proto, tc->cls_flower);
 +		case TC_CLSFLOWER_DESTROY:
 +			return mlx5e_delete_flower(priv, tc->cls_flower);
 +		case TC_CLSFLOWER_STATS:
 +			return mlx5e_stats_flower(priv, tc->cls_flower);
 +		}
++=======
+ static int mlx5e_setup_tc_cls_flower(struct net_device *dev,
+ 				     struct tc_cls_flower_offload *cls_flower)
+ {
+ 	struct mlx5e_priv *priv = netdev_priv(dev);
+ 
+ 	if (TC_H_MAJ(cls_flower->common.handle) != TC_H_MAJ(TC_H_INGRESS) ||
+ 	    cls_flower->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (cls_flower->command) {
+ 	case TC_CLSFLOWER_REPLACE:
+ 		return mlx5e_configure_flower(priv, cls_flower);
+ 	case TC_CLSFLOWER_DESTROY:
+ 		return mlx5e_delete_flower(priv, cls_flower);
+ 	case TC_CLSFLOWER_STATS:
+ 		return mlx5e_stats_flower(priv, cls_flower);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int mlx5e_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			  struct tc_to_netdev *tc)
+ {
+ 	switch (type) {
+ 	case TC_SETUP_CLSFLOWER:
+ 		return mlx5e_setup_tc_cls_flower(dev, tc->cls_flower);
+ 	case TC_SETUP_MQPRIO:
+ 		return mlx5e_setup_tc_mqprio(dev, tc->mqprio);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  	default:
  		return -EOPNOTSUPP;
  	}
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
index abcb1976163d,e5cf2e7ae052..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
@@@ -281,32 -651,42 +281,68 @@@ static int mlx5e_rep_get_phys_port_name
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int mlx5e_rep_ndo_setup_tc(struct net_device *dev, u32 handle,
 +				  __be16 proto, struct tc_to_netdev *tc)
++=======
+ static int mlx5e_rep_setup_tc_cls_flower(struct net_device *dev,
+ 					 struct tc_to_netdev *tc)
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  {
 -	struct tc_cls_flower_offload *cls_flower = tc->cls_flower;
  	struct mlx5e_priv *priv = netdev_priv(dev);
  
++<<<<<<< HEAD
 +	if (TC_H_MAJ(handle) != TC_H_MAJ(TC_H_INGRESS))
++=======
+ 	if (TC_H_MAJ(cls_flower->common.handle) != TC_H_MAJ(TC_H_INGRESS) ||
+ 	    cls_flower->common.chain_index)
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  		return -EOPNOTSUPP;
  
 -	if (cls_flower->egress_dev) {
 +	if (type == TC_SETUP_CLSFLOWER && tc->cls_flower->egress_dev) {
  		struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 +		struct net_device *uplink_dev = mlx5_eswitch_get_uplink_netdev(esw);
 +
++<<<<<<< HEAD
 +		return uplink_dev->netdev_ops->ndo_setup_tc(uplink_dev, handle,
 +							    proto, tc);
 +	}
  
 +	switch (tc->type) {
 +	case TC_SETUP_CLSFLOWER:
 +		switch (tc->cls_flower->command) {
 +		case TC_CLSFLOWER_REPLACE:
 +			return mlx5e_configure_flower(priv, proto, tc->cls_flower);
 +		case TC_CLSFLOWER_DESTROY:
 +			return mlx5e_delete_flower(priv, tc->cls_flower);
 +		case TC_CLSFLOWER_STATS:
 +			return mlx5e_stats_flower(priv, tc->cls_flower);
 +		}
++=======
+ 		dev = mlx5_eswitch_get_uplink_netdev(esw);
+ 		return dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSFLOWER,
+ 						     tc);
+ 	}
+ 
+ 	switch (cls_flower->command) {
+ 	case TC_CLSFLOWER_REPLACE:
+ 		return mlx5e_configure_flower(priv, cls_flower);
+ 	case TC_CLSFLOWER_DESTROY:
+ 		return mlx5e_delete_flower(priv, cls_flower);
+ 	case TC_CLSFLOWER_STATS:
+ 		return mlx5e_stats_flower(priv, cls_flower);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int mlx5e_rep_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			      struct tc_to_netdev *tc)
+ {
+ 	switch (type) {
+ 	case TC_SETUP_CLSFLOWER:
+ 		return mlx5e_rep_setup_tc_cls_flower(dev, tc);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  	default:
  		return -EOPNOTSUPP;
  	}
diff --cc drivers/net/ethernet/mellanox/mlxsw/spectrum.c
index c628b7aede0f,1ca3204f5543..000000000000
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
@@@ -1218,17 -1571,22 +1218,22 @@@ mlxsw_sp_port_del_cls_matchall_mirror(s
  	mlxsw_sp_span_mirror_remove(mlxsw_sp_port, to_port, span_type);
  }
  
 -static int
 -mlxsw_sp_port_add_cls_matchall_sample(struct mlxsw_sp_port *mlxsw_sp_port,
 -				      struct tc_cls_matchall_offload *cls,
 -				      const struct tc_action *a,
 -				      bool ingress)
 +static int mlxsw_sp_port_add_cls_matchall(struct mlxsw_sp_port *mlxsw_sp_port,
++<<<<<<< HEAD
 +					  __be16 protocol,
 +					  struct tc_cls_matchall_offload *cls,
++=======
++					  struct tc_cls_matchall_offload *f,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
 +					  bool ingress)
  {
 +	struct mlxsw_sp_port_mall_tc_entry *mall_tc_entry;
++	__be16 protocol = f->common.protocol;
 +	const struct tc_action *a;
  	int err;
  
 -	if (!mlxsw_sp_port->sample)
 -		return -EOPNOTSUPP;
 -	if (rtnl_dereference(mlxsw_sp_port->sample->psample_group)) {
 -		netdev_err(mlxsw_sp_port->dev, "sample already active\n");
 -		return -EEXIST;
 -	}
 -	if (tcf_sample_rate(a) > MLXSW_REG_MPSC_RATE_MAX) {
 -		netdev_err(mlxsw_sp_port->dev, "sample rate not supported\n");
 +	if (!tc_single_action(cls->exts)) {
 +		netdev_err(mlxsw_sp_port->dev, "only singular actions are supported\n");
  		return -EOPNOTSUPP;
  	}
  
@@@ -1286,42 -1693,63 +1291,101 @@@ static void mlxsw_sp_port_del_cls_match
  	kfree(mall_tc_entry);
  }
  
++<<<<<<< HEAD
 +static int mlxsw_sp_setup_tc(struct net_device *dev, u32 handle,
 +			     __be16 proto, struct tc_to_netdev *tc)
++=======
+ static int mlxsw_sp_setup_tc_cls_matchall(struct mlxsw_sp_port *mlxsw_sp_port,
+ 					  struct tc_cls_matchall_offload *f)
+ {
+ 	bool ingress = TC_H_MAJ(f->common.handle) == TC_H_MAJ(TC_H_INGRESS);
+ 
+ 	if (f->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (f->command) {
+ 	case TC_CLSMATCHALL_REPLACE:
+ 		return mlxsw_sp_port_add_cls_matchall(mlxsw_sp_port, f,
+ 						      ingress);
+ 	case TC_CLSMATCHALL_DESTROY:
+ 		mlxsw_sp_port_del_cls_matchall(mlxsw_sp_port, f);
+ 		return 0;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int
+ mlxsw_sp_setup_tc_cls_flower(struct mlxsw_sp_port *mlxsw_sp_port,
+ 			     struct tc_cls_flower_offload *f)
+ {
+ 	bool ingress = TC_H_MAJ(f->common.handle) == TC_H_MAJ(TC_H_INGRESS);
+ 
+ 	if (f->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (f->command) {
+ 	case TC_CLSFLOWER_REPLACE:
+ 		return mlxsw_sp_flower_replace(mlxsw_sp_port, ingress, f);
+ 	case TC_CLSFLOWER_DESTROY:
+ 		mlxsw_sp_flower_destroy(mlxsw_sp_port, ingress, f);
+ 		return 0;
+ 	case TC_CLSFLOWER_STATS:
+ 		return mlxsw_sp_flower_stats(mlxsw_sp_port, ingress, f);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int mlxsw_sp_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			     struct tc_to_netdev *tc)
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  {
  	struct mlxsw_sp_port *mlxsw_sp_port = netdev_priv(dev);
 -
 +	bool ingress = TC_H_MAJ(handle) == TC_H_MAJ(TC_H_INGRESS);
 +
++<<<<<<< HEAD
 +	switch (tc->type) {
 +	case TC_SETUP_MATCHALL:
 +		switch (tc->cls_mall->command) {
 +		case TC_CLSMATCHALL_REPLACE:
 +			return mlxsw_sp_port_add_cls_matchall(mlxsw_sp_port,
 +							      proto,
 +							      tc->cls_mall,
 +							      ingress);
 +		case TC_CLSMATCHALL_DESTROY:
 +			mlxsw_sp_port_del_cls_matchall(mlxsw_sp_port,
 +						       tc->cls_mall);
 +			return 0;
 +		default:
 +			return -EINVAL;
 +		}
 +	case TC_SETUP_CLSFLOWER:
 +		switch (tc->cls_flower->command) {
 +		case TC_CLSFLOWER_REPLACE:
 +			return mlxsw_sp_flower_replace(mlxsw_sp_port, ingress,
 +						       proto, tc->cls_flower);
 +		case TC_CLSFLOWER_DESTROY:
 +			mlxsw_sp_flower_destroy(mlxsw_sp_port, ingress,
 +						tc->cls_flower);
 +			return 0;
 +		default:
 +			return -EOPNOTSUPP;
 +		}
++=======
+ 	switch (type) {
+ 	case TC_SETUP_CLSMATCHALL:
+ 		return mlxsw_sp_setup_tc_cls_matchall(mlxsw_sp_port,
+ 						      tc->cls_mall);
+ 	case TC_SETUP_CLSFLOWER:
+ 		return mlxsw_sp_setup_tc_cls_flower(mlxsw_sp_port,
+ 						    tc->cls_flower);
+ 	default:
+ 		return -EOPNOTSUPP;
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  	}
 +
 +	return -EOPNOTSUPP;
  }
  
  static const struct net_device_ops mlxsw_sp_port_netdev_ops = {
diff --cc drivers/net/ethernet/sfc/efx.h
index a0c52e328102,b0c6004db138..000000000000
--- a/drivers/net/ethernet/sfc/efx.h
+++ b/drivers/net/ethernet/sfc/efx.h
@@@ -32,7 -32,7 +32,11 @@@ netdev_tx_t efx_hard_start_xmit(struct 
  				struct net_device *net_dev);
  netdev_tx_t efx_enqueue_skb(struct efx_tx_queue *tx_queue, struct sk_buff *skb);
  void efx_xmit_done(struct efx_tx_queue *tx_queue, unsigned int index);
++<<<<<<< HEAD
 +int efx_setup_tc(struct net_device *net_dev, u32 handle, __be16 proto,
++=======
+ int efx_setup_tc(struct net_device *net_dev, enum tc_setup_type type,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  		 struct tc_to_netdev *tc);
  unsigned int efx_tx_max_skb_descs(struct efx_nic *efx);
  extern unsigned int efx_piobuf_size;
diff --cc drivers/net/ethernet/sfc/falcon/efx.h
index c89456fa148c,4497511fc914..000000000000
--- a/drivers/net/ethernet/sfc/falcon/efx.h
+++ b/drivers/net/ethernet/sfc/falcon/efx.h
@@@ -32,7 -32,7 +32,11 @@@ netdev_tx_t ef4_hard_start_xmit(struct 
  				struct net_device *net_dev);
  netdev_tx_t ef4_enqueue_skb(struct ef4_tx_queue *tx_queue, struct sk_buff *skb);
  void ef4_xmit_done(struct ef4_tx_queue *tx_queue, unsigned int index);
++<<<<<<< HEAD
 +int ef4_setup_tc(struct net_device *net_dev, u32 handle, __be16 proto,
++=======
+ int ef4_setup_tc(struct net_device *net_dev, enum tc_setup_type type,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  		 struct tc_to_netdev *tc);
  unsigned int ef4_tx_max_skb_descs(struct ef4_nic *efx);
  extern bool ef4_separate_tx_channels;
diff --cc drivers/net/ethernet/sfc/falcon/tx.c
index 104fb15a73f2,447519ac3fa4..000000000000
--- a/drivers/net/ethernet/sfc/falcon/tx.c
+++ b/drivers/net/ethernet/sfc/falcon/tx.c
@@@ -425,7 -425,7 +425,11 @@@ void ef4_init_tx_queue_core_txq(struct 
  				     efx->n_tx_channels : 0));
  }
  
++<<<<<<< HEAD
 +int ef4_setup_tc(struct net_device *net_dev, u32 handle, __be16 proto,
++=======
+ int ef4_setup_tc(struct net_device *net_dev, enum tc_setup_type type,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  		 struct tc_to_netdev *ntc)
  {
  	struct ef4_nic *efx = netdev_priv(net_dev);
diff --cc drivers/net/ethernet/sfc/tx.c
index ff88d60aa6d5,d17af918ac50..000000000000
--- a/drivers/net/ethernet/sfc/tx.c
+++ b/drivers/net/ethernet/sfc/tx.c
@@@ -653,7 -653,7 +653,11 @@@ void efx_init_tx_queue_core_txq(struct 
  				     efx->n_tx_channels : 0));
  }
  
++<<<<<<< HEAD
 +int efx_setup_tc(struct net_device *net_dev, u32 handle, __be16 proto,
++=======
+ int efx_setup_tc(struct net_device *net_dev, enum tc_setup_type type,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  		 struct tc_to_netdev *ntc)
  {
  	struct efx_nic *efx = netdev_priv(net_dev);
diff --cc include/linux/netdevice.h
index ac042b4e583c,6e2f7e38cf8e..000000000000
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@@ -1041,14 -973,15 +1041,23 @@@ struct net_device_ops_extended 
   *
   *      Enable or disable the VF ability to query its RSS Redirection Table and
   *      Hash Key. This is needed since on some devices VF share this information
 - *      with PF and querying it may introduce a theoretical security risk.
 + *      with PF and querying it may adduce a theoretical security risk.
   * int (*ndo_set_vf_rss_query_en)(struct net_device *dev, int vf, bool setting);
   * int (*ndo_get_vf_port)(struct net_device *dev, int vf, struct sk_buff *skb);
++<<<<<<< HEAD
 + * int (*ndo_setup_tc)(struct net_device *dev, u8 tc)
 + * 	Called to setup 'tc' number of traffic classes in the net device. This
 + * 	is always called from the stack with the rtnl lock held and netif tx
 + * 	queues stopped. This allows the netdevice to perform queue management
 + * 	safely.
++=======
+  * int (*ndo_setup_tc)(struct net_device *dev, enum tc_setup_type type,
+  *		       struct tc_to_netdev *tc);
+  *	Called to setup any 'tc' scheduler, classifier or action on @dev.
+  *	This is always called from the stack with the rtnl lock held and netif
+  *	tx queues stopped. This allows the netdevice to perform queue
+  *	management safely.
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
   *
   *	Fiber Channel over Ethernet (FCoE) offload functions.
   * int (*ndo_fcoe_enable)(struct net_device *dev);
@@@ -1260,9 -1218,15 +1269,21 @@@ struct net_device_ops 
  						   struct nlattr *port[]);
  	int			(*ndo_get_vf_port)(struct net_device *dev,
  						   int vf, struct sk_buff *skb);
++<<<<<<< HEAD
 +	RH_KABI_RENAME(int	(*ndo_setup_tc),
 +		       int	(*ndo_setup_tc_rh72))(struct net_device *dev,
 +						      u8 tc);
++=======
+ 	int			(*ndo_set_vf_guid)(struct net_device *dev,
+ 						   int vf, u64 guid,
+ 						   int guid_type);
+ 	int			(*ndo_set_vf_rss_query_en)(
+ 						   struct net_device *dev,
+ 						   int vf, bool setting);
+ 	int			(*ndo_setup_tc)(struct net_device *dev,
+ 						enum tc_setup_type type,
+ 						struct tc_to_netdev *tc);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  #if IS_ENABLED(CONFIG_FCOE)
  	int			(*ndo_fcoe_enable)(struct net_device *dev);
  	int			(*ndo_fcoe_disable)(struct net_device *dev);
diff --cc include/net/pkt_cls.h
index db4cec05920e,ffaddf72108e..000000000000
--- a/include/net/pkt_cls.h
+++ b/include/net/pkt_cls.h
@@@ -487,6 -536,23 +505,26 @@@ struct tc_cls_matchall_offload 
  	unsigned long cookie;
  };
  
++<<<<<<< HEAD
++=======
+ enum tc_clsbpf_command {
+ 	TC_CLSBPF_ADD,
+ 	TC_CLSBPF_REPLACE,
+ 	TC_CLSBPF_DESTROY,
+ 	TC_CLSBPF_STATS,
+ };
+ 
+ struct tc_cls_bpf_offload {
+ 	struct tc_cls_common_offload common;
+ 	enum tc_clsbpf_command command;
+ 	struct tcf_exts *exts;
+ 	struct bpf_prog *prog;
+ 	const char *name;
+ 	bool exts_integrated;
+ 	u32 gen_flags;
+ };
+ 
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  
  /* This structure holds cookie structure that is passed from user
   * to the kernel for actions and classifiers
diff --cc net/dsa/slave.c
index f3efc3546e20,5e01e9271619..000000000000
--- a/net/dsa/slave.c
+++ b/net/dsa/slave.c
@@@ -290,12 -640,327 +290,327 @@@ static int dsa_slave_get_sset_count(str
  	return -EOPNOTSUPP;
  }
  
++<<<<<<< HEAD
++=======
+ static void dsa_slave_get_wol(struct net_device *dev, struct ethtool_wolinfo *w)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (ds->ops->get_wol)
+ 		ds->ops->get_wol(ds, p->dp->index, w);
+ }
+ 
+ static int dsa_slave_set_wol(struct net_device *dev, struct ethtool_wolinfo *w)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	int ret = -EOPNOTSUPP;
+ 
+ 	if (ds->ops->set_wol)
+ 		ret = ds->ops->set_wol(ds, p->dp->index, w);
+ 
+ 	return ret;
+ }
+ 
+ static int dsa_slave_set_eee(struct net_device *dev, struct ethtool_eee *e)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	int ret;
+ 
+ 	/* Port's PHY and MAC both need to be EEE capable */
+ 	if (!p->phy)
+ 		return -ENODEV;
+ 
+ 	if (!ds->ops->set_mac_eee)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = ds->ops->set_mac_eee(ds, p->dp->index, e);
+ 	if (ret)
+ 		return ret;
+ 
+ 	if (e->eee_enabled) {
+ 		ret = phy_init_eee(p->phy, 0);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	return phy_ethtool_set_eee(p->phy, e);
+ }
+ 
+ static int dsa_slave_get_eee(struct net_device *dev, struct ethtool_eee *e)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	int ret;
+ 
+ 	/* Port's PHY and MAC both need to be EEE capable */
+ 	if (!p->phy)
+ 		return -ENODEV;
+ 
+ 	if (!ds->ops->get_mac_eee)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = ds->ops->get_mac_eee(ds, p->dp->index, e);
+ 	if (ret)
+ 		return ret;
+ 
+ 	return phy_ethtool_get_eee(p->phy, e);
+ }
+ 
+ #ifdef CONFIG_NET_POLL_CONTROLLER
+ static int dsa_slave_netpoll_setup(struct net_device *dev,
+ 				   struct netpoll_info *ni)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct net_device *master = dsa_master_netdev(p);
+ 	struct netpoll *netpoll;
+ 	int err = 0;
+ 
+ 	netpoll = kzalloc(sizeof(*netpoll), GFP_KERNEL);
+ 	if (!netpoll)
+ 		return -ENOMEM;
+ 
+ 	err = __netpoll_setup(netpoll, master);
+ 	if (err) {
+ 		kfree(netpoll);
+ 		goto out;
+ 	}
+ 
+ 	p->netpoll = netpoll;
+ out:
+ 	return err;
+ }
+ 
+ static void dsa_slave_netpoll_cleanup(struct net_device *dev)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct netpoll *netpoll = p->netpoll;
+ 
+ 	if (!netpoll)
+ 		return;
+ 
+ 	p->netpoll = NULL;
+ 
+ 	__netpoll_free_async(netpoll);
+ }
+ 
+ static void dsa_slave_poll_controller(struct net_device *dev)
+ {
+ }
+ #endif
+ 
+ static int dsa_slave_get_phys_port_name(struct net_device *dev,
+ 					char *name, size_t len)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 
+ 	if (snprintf(name, len, "p%d", p->dp->index) >= len)
+ 		return -EINVAL;
+ 
+ 	return 0;
+ }
+ 
+ static struct dsa_mall_tc_entry *
+ dsa_slave_mall_tc_entry_find(struct dsa_slave_priv *p,
+ 			     unsigned long cookie)
+ {
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 
+ 	list_for_each_entry(mall_tc_entry, &p->mall_tc_list, list)
+ 		if (mall_tc_entry->cookie == cookie)
+ 			return mall_tc_entry;
+ 
+ 	return NULL;
+ }
+ 
+ static int dsa_slave_add_cls_matchall(struct net_device *dev,
+ 				      struct tc_cls_matchall_offload *cls,
+ 				      bool ingress)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 	__be16 protocol = cls->common.protocol;
+ 	struct dsa_switch *ds = p->dp->ds;
+ 	struct net *net = dev_net(dev);
+ 	struct dsa_slave_priv *to_p;
+ 	struct net_device *to_dev;
+ 	const struct tc_action *a;
+ 	int err = -EOPNOTSUPP;
+ 	LIST_HEAD(actions);
+ 	int ifindex;
+ 
+ 	if (!ds->ops->port_mirror_add)
+ 		return err;
+ 
+ 	if (!tcf_exts_has_one_action(cls->exts))
+ 		return err;
+ 
+ 	tcf_exts_to_list(cls->exts, &actions);
+ 	a = list_first_entry(&actions, struct tc_action, list);
+ 
+ 	if (is_tcf_mirred_egress_mirror(a) && protocol == htons(ETH_P_ALL)) {
+ 		struct dsa_mall_mirror_tc_entry *mirror;
+ 
+ 		ifindex = tcf_mirred_ifindex(a);
+ 		to_dev = __dev_get_by_index(net, ifindex);
+ 		if (!to_dev)
+ 			return -EINVAL;
+ 
+ 		if (!dsa_slave_dev_check(to_dev))
+ 			return -EOPNOTSUPP;
+ 
+ 		mall_tc_entry = kzalloc(sizeof(*mall_tc_entry), GFP_KERNEL);
+ 		if (!mall_tc_entry)
+ 			return -ENOMEM;
+ 
+ 		mall_tc_entry->cookie = cls->cookie;
+ 		mall_tc_entry->type = DSA_PORT_MALL_MIRROR;
+ 		mirror = &mall_tc_entry->mirror;
+ 
+ 		to_p = netdev_priv(to_dev);
+ 
+ 		mirror->to_local_port = to_p->dp->index;
+ 		mirror->ingress = ingress;
+ 
+ 		err = ds->ops->port_mirror_add(ds, p->dp->index, mirror,
+ 					       ingress);
+ 		if (err) {
+ 			kfree(mall_tc_entry);
+ 			return err;
+ 		}
+ 
+ 		list_add_tail(&mall_tc_entry->list, &p->mall_tc_list);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void dsa_slave_del_cls_matchall(struct net_device *dev,
+ 				       struct tc_cls_matchall_offload *cls)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (!ds->ops->port_mirror_del)
+ 		return;
+ 
+ 	mall_tc_entry = dsa_slave_mall_tc_entry_find(p, cls->cookie);
+ 	if (!mall_tc_entry)
+ 		return;
+ 
+ 	list_del(&mall_tc_entry->list);
+ 
+ 	switch (mall_tc_entry->type) {
+ 	case DSA_PORT_MALL_MIRROR:
+ 		ds->ops->port_mirror_del(ds, p->dp->index,
+ 					 &mall_tc_entry->mirror);
+ 		break;
+ 	default:
+ 		WARN_ON(1);
+ 	}
+ 
+ 	kfree(mall_tc_entry);
+ }
+ 
+ static int dsa_slave_setup_tc_cls_matchall(struct net_device *dev,
+ 					   struct tc_cls_matchall_offload *cls)
+ {
+ 	bool ingress = TC_H_MAJ(cls->common.handle) == TC_H_MAJ(TC_H_INGRESS);
+ 
+ 	if (cls->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (cls->command) {
+ 	case TC_CLSMATCHALL_REPLACE:
+ 		return dsa_slave_add_cls_matchall(dev, cls, ingress);
+ 	case TC_CLSMATCHALL_DESTROY:
+ 		dsa_slave_del_cls_matchall(dev, cls);
+ 		return 0;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int dsa_slave_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			      struct tc_to_netdev *tc)
+ {
+ 	switch (type) {
+ 	case TC_SETUP_CLSMATCHALL:
+ 		return dsa_slave_setup_tc_cls_matchall(dev, tc->cls_mall);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static void dsa_slave_get_stats64(struct net_device *dev,
+ 				  struct rtnl_link_stats64 *stats)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct pcpu_sw_netstats *s;
+ 	unsigned int start;
+ 	int i;
+ 
+ 	netdev_stats_to_stats64(stats, &dev->stats);
+ 	for_each_possible_cpu(i) {
+ 		u64 tx_packets, tx_bytes, rx_packets, rx_bytes;
+ 
+ 		s = per_cpu_ptr(p->stats64, i);
+ 		do {
+ 			start = u64_stats_fetch_begin_irq(&s->syncp);
+ 			tx_packets = s->tx_packets;
+ 			tx_bytes = s->tx_bytes;
+ 			rx_packets = s->rx_packets;
+ 			rx_bytes = s->rx_bytes;
+ 		} while (u64_stats_fetch_retry_irq(&s->syncp, start));
+ 
+ 		stats->tx_packets += tx_packets;
+ 		stats->tx_bytes += tx_bytes;
+ 		stats->rx_packets += rx_packets;
+ 		stats->rx_bytes += rx_bytes;
+ 	}
+ }
+ 
+ void dsa_cpu_port_ethtool_init(struct ethtool_ops *ops)
+ {
+ 	ops->get_sset_count = dsa_cpu_port_get_sset_count;
+ 	ops->get_ethtool_stats = dsa_cpu_port_get_ethtool_stats;
+ 	ops->get_strings = dsa_cpu_port_get_strings;
+ }
+ 
+ static int dsa_slave_get_rxnfc(struct net_device *dev,
+ 			       struct ethtool_rxnfc *nfc, u32 *rule_locs)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (!ds->ops->get_rxnfc)
+ 		return -EOPNOTSUPP;
+ 
+ 	return ds->ops->get_rxnfc(ds, p->dp->index, nfc, rule_locs);
+ }
+ 
+ static int dsa_slave_set_rxnfc(struct net_device *dev,
+ 			       struct ethtool_rxnfc *nfc)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_switch *ds = p->dp->ds;
+ 
+ 	if (!ds->ops->set_rxnfc)
+ 		return -EOPNOTSUPP;
+ 
+ 	return ds->ops->set_rxnfc(ds, p->dp->index, nfc);
+ }
+ 
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  static const struct ethtool_ops dsa_slave_ethtool_ops = {
 +	.get_settings		= dsa_slave_get_settings,
 +	.set_settings		= dsa_slave_set_settings,
  	.get_drvinfo		= dsa_slave_get_drvinfo,
 -	.get_regs_len		= dsa_slave_get_regs_len,
 -	.get_regs		= dsa_slave_get_regs,
  	.nway_reset		= dsa_slave_nway_reset,
  	.get_link		= dsa_slave_get_link,
 -	.get_eeprom_len		= dsa_slave_get_eeprom_len,
 -	.get_eeprom		= dsa_slave_get_eeprom,
 -	.set_eeprom		= dsa_slave_set_eeprom,
  	.get_strings		= dsa_slave_get_strings,
  	.get_ethtool_stats	= dsa_slave_get_ethtool_stats,
  	.get_sset_count		= dsa_slave_get_sset_count,
diff --cc net/sched/cls_bpf.c
index c13fb5505297,dde8efdcee3b..000000000000
--- a/net/sched/cls_bpf.c
+++ b/net/sched/cls_bpf.c
@@@ -70,10 -131,105 +70,75 @@@ static int cls_bpf_classify(struct sk_b
  		if (ret < 0)
  			continue;
  
++<<<<<<< HEAD
 +		return ret;
++=======
+ 		break;
+ 	}
+ 	rcu_read_unlock();
+ 
+ 	return ret;
+ }
+ 
+ static bool cls_bpf_is_ebpf(const struct cls_bpf_prog *prog)
+ {
+ 	return !prog->bpf_ops;
+ }
+ 
+ static int cls_bpf_offload_cmd(struct tcf_proto *tp, struct cls_bpf_prog *prog,
+ 			       enum tc_clsbpf_command cmd)
+ {
+ 	struct net_device *dev = tp->q->dev_queue->dev;
+ 	struct tc_cls_bpf_offload bpf_offload = {};
+ 	struct tc_to_netdev offload;
+ 	int err;
+ 
+ 	offload.cls_bpf = &bpf_offload;
+ 
+ 	tc_cls_common_offload_init(&bpf_offload.common, tp);
+ 	bpf_offload.command = cmd;
+ 	bpf_offload.exts = &prog->exts;
+ 	bpf_offload.prog = prog->filter;
+ 	bpf_offload.name = prog->bpf_name;
+ 	bpf_offload.exts_integrated = prog->exts_integrated;
+ 	bpf_offload.gen_flags = prog->gen_flags;
+ 
+ 	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSBPF, &offload);
+ 	if (!err && (cmd == TC_CLSBPF_ADD || cmd == TC_CLSBPF_REPLACE))
+ 		prog->gen_flags |= TCA_CLS_FLAGS_IN_HW;
+ 
+ 	return err;
+ }
+ 
+ static int cls_bpf_offload(struct tcf_proto *tp, struct cls_bpf_prog *prog,
+ 			   struct cls_bpf_prog *oldprog)
+ {
+ 	struct net_device *dev = tp->q->dev_queue->dev;
+ 	struct cls_bpf_prog *obj = prog;
+ 	enum tc_clsbpf_command cmd;
+ 	bool skip_sw;
+ 	int ret;
+ 
+ 	skip_sw = tc_skip_sw(prog->gen_flags) ||
+ 		(oldprog && tc_skip_sw(oldprog->gen_flags));
+ 
+ 	if (oldprog && oldprog->offloaded) {
+ 		if (tc_should_offload(dev, tp, prog->gen_flags)) {
+ 			cmd = TC_CLSBPF_REPLACE;
+ 		} else if (!tc_skip_sw(prog->gen_flags)) {
+ 			obj = oldprog;
+ 			cmd = TC_CLSBPF_DESTROY;
+ 		} else {
+ 			return -EINVAL;
+ 		}
+ 	} else {
+ 		if (!tc_should_offload(dev, tp, prog->gen_flags))
+ 			return skip_sw ? -EINVAL : 0;
+ 		cmd = TC_CLSBPF_ADD;
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  	}
  
 -	ret = cls_bpf_offload_cmd(tp, obj, cmd);
 -	if (ret)
 -		return skip_sw ? ret : 0;
 -
 -	obj->offloaded = true;
 -	if (oldprog)
 -		oldprog->offloaded = false;
 -
 -	return 0;
 -}
 -
 -static void cls_bpf_stop_offload(struct tcf_proto *tp,
 -				 struct cls_bpf_prog *prog)
 -{
 -	int err;
 -
 -	if (!prog->offloaded)
 -		return;
 -
 -	err = cls_bpf_offload_cmd(tp, prog, TC_CLSBPF_DESTROY);
 -	if (err) {
 -		pr_err("Stopping hardware offload failed: %d\n", err);
 -		return;
 -	}
 -
 -	prog->offloaded = false;
 -}
 -
 -static void cls_bpf_offload_update_stats(struct tcf_proto *tp,
 -					 struct cls_bpf_prog *prog)
 -{
 -	if (!prog->offloaded)
 -		return;
 -
 -	cls_bpf_offload_cmd(tp, prog, TC_CLSBPF_STATS);
 +	return -1;
  }
  
  static int cls_bpf_init(struct tcf_proto *tp)
diff --cc net/sched/cls_flower.c
index 2d81cc7499da,1fdf2889ba9f..000000000000
--- a/net/sched/cls_flower.c
+++ b/net/sched/cls_flower.c
@@@ -236,10 -237,9 +237,14 @@@ static void fl_hw_destroy_filter(struc
  	offload.prio = tp->prio;
  	offload.cookie = (unsigned long)f;
  
 +	tc->type = TC_SETUP_CLSFLOWER;
  	tc->cls_flower = &offload;
  
++<<<<<<< HEAD
 +	dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol, tc);
++=======
+ 	dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSFLOWER, tc);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  }
  
  static int fl_hw_replace_filter(struct tcf_proto *tp,
@@@ -272,11 -273,9 +278,15 @@@
  	offload.key = &f->mkey;
  	offload.exts = &f->exts;
  
 +	tc->type = TC_SETUP_CLSFLOWER;
  	tc->cls_flower = &offload;
  
++<<<<<<< HEAD
 +	err = dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol,
 +					    tc);
++=======
+ 	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSFLOWER, tc);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  	if (!err)
  		f->flags |= TCA_CLS_FLAGS_IN_HW;
  
@@@ -299,10 -299,9 +310,14 @@@ static void fl_hw_update_stats(struct t
  	offload.cookie = (unsigned long)f;
  	offload.exts = &f->exts;
  
 +	tc->type = TC_SETUP_CLSFLOWER;
  	tc->cls_flower = &offload;
  
++<<<<<<< HEAD
 +	dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol, tc);
++=======
+ 	dev->netdev_ops->ndo_setup_tc(dev, TC_CLSFLOWER_STATS, tc);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  }
  
  static void __fl_delete(struct tcf_proto *tp, struct cls_fl_filter *f)
diff --cc net/sched/cls_matchall.c
index f7bc58777169,174c700160ca..000000000000
--- a/net/sched/cls_matchall.c
+++ b/net/sched/cls_matchall.c
@@@ -59,13 -58,13 +59,21 @@@ static int mall_replace_hw_filter(struc
  	struct tc_cls_matchall_offload mall_offload = {0};
  	int err;
  
++<<<<<<< HEAD
 +	offload.type = TC_SETUP_MATCHALL;
++=======
+ 	tc_cls_common_offload_init(&mall_offload.common, tp);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  	offload.cls_mall = &mall_offload;
  	offload.cls_mall->command = TC_CLSMATCHALL_REPLACE;
  	offload.cls_mall->exts = &head->exts;
  	offload.cls_mall->cookie = cookie;
  
++<<<<<<< HEAD
 +	err = dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol,
++=======
+ 	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSMATCHALL,
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  					    &offload);
  	if (!err)
  		head->flags |= TCA_CLS_FLAGS_IN_HW;
@@@ -81,17 -80,16 +89,25 @@@ static void mall_destroy_hw_filter(stru
  	struct tc_to_netdev offload;
  	struct tc_cls_matchall_offload mall_offload = {0};
  
++<<<<<<< HEAD
 +	offload.type = TC_SETUP_MATCHALL;
++=======
+ 	tc_cls_common_offload_init(&mall_offload.common, tp);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  	offload.cls_mall = &mall_offload;
  	offload.cls_mall->command = TC_CLSMATCHALL_DESTROY;
  	offload.cls_mall->exts = NULL;
  	offload.cls_mall->cookie = cookie;
  
++<<<<<<< HEAD
 +	dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle, tp->protocol,
 +					     &offload);
++=======
+ 	dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSMATCHALL, &offload);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  }
  
 -static void mall_destroy(struct tcf_proto *tp)
 +static bool mall_destroy(struct tcf_proto *tp, bool force)
  {
  	struct cls_mall_head *head = rtnl_dereference(tp->root);
  	struct net_device *dev = tp->q->dev_queue->dev;
diff --cc net/sched/cls_u32.c
index dfc76f51e07c,c0f59c471523..000000000000
--- a/net/sched/cls_u32.c
+++ b/net/sched/cls_u32.c
@@@ -438,10 -437,10 +438,15 @@@ static void u32_remove_hw_knode(struct 
  	offload.cls_u32 = &u32_offload;
  
  	if (tc_should_offload(dev, tp, 0)) {
+ 		tc_cls_common_offload_init(&u32_offload.common, tp);
  		offload.cls_u32->command = TC_CLSU32_DELETE_KNODE;
  		offload.cls_u32->knode.handle = handle;
++<<<<<<< HEAD
 +		dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle,
 +					      tp->protocol, &offload);
++=======
+ 		dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSU32, &offload);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  	}
  }
  
@@@ -456,16 -455,15 +461,21 @@@ static int u32_replace_hw_hnode(struct 
  	if (!tc_should_offload(dev, tp, flags))
  		return tc_skip_sw(flags) ? -EINVAL : 0;
  
 +	offload.type = TC_SETUP_CLSU32;
  	offload.cls_u32 = &u32_offload;
  
+ 	tc_cls_common_offload_init(&u32_offload.common, tp);
  	offload.cls_u32->command = TC_CLSU32_NEW_HNODE;
  	offload.cls_u32->hnode.divisor = h->divisor;
  	offload.cls_u32->hnode.handle = h->handle;
  	offload.cls_u32->hnode.prio = h->prio;
  
++<<<<<<< HEAD
 +	err = dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle,
 +					    tp->protocol, &offload);
++=======
+ 	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSU32, &offload);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  	if (tc_skip_sw(flags))
  		return err;
  
@@@ -487,8 -485,7 +498,12 @@@ static void u32_clear_hw_hnode(struct t
  		offload.cls_u32->hnode.handle = h->handle;
  		offload.cls_u32->hnode.prio = h->prio;
  
++<<<<<<< HEAD
 +		dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle,
 +					      tp->protocol, &offload);
++=======
+ 		dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSU32, &offload);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  	}
  }
  
@@@ -521,8 -518,7 +537,12 @@@ static int u32_replace_hw_knode(struct 
  	if (n->ht_down)
  		offload.cls_u32->knode.link_handle = n->ht_down->handle;
  
++<<<<<<< HEAD
 +	err = dev->netdev_ops->ndo_setup_tc(dev, tp->q->handle,
 +					    tp->protocol, &offload);
++=======
+ 	err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSU32, &offload);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  
  	if (!err)
  		n->flags |= TCA_CLS_FLAGS_IN_HW;
diff --cc net/sched/sch_mqprio.c
index 748ea1bbc507,09b577dde49c..000000000000
--- a/net/sched/sch_mqprio.c
+++ b/net/sched/sch_mqprio.c
@@@ -39,15 -38,14 +39,24 @@@ static void mqprio_destroy(struct Qdis
  		kfree(priv->qdiscs);
  	}
  
++<<<<<<< HEAD
 +	if (priv->hw_owned && (dev->netdev_ops->ndo_setup_tc ||
 +			       dev->netdev_ops->ndo_setup_tc_rh72))
 +		if (dev->netdev_ops->ndo_setup_tc) {
 +			dev->netdev_ops->ndo_setup_tc(dev, sch->handle, 0, &tc);
 +		} else {
 +			dev->netdev_ops->ndo_setup_tc_rh72(dev, 0);
 +		}
 +	else
++=======
+ 	if (priv->hw_offload && dev->netdev_ops->ndo_setup_tc) {
+ 		struct tc_mqprio_qopt offload = { 0 };
+ 		struct tc_to_netdev tc = { { .mqprio = &offload } };
+ 
+ 		dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_MQPRIO, &tc);
+ 	} else {
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  		netdev_set_num_tc(dev, 0);
 -	}
  }
  
  static int mqprio_parse_opt(struct net_device *dev, struct tc_mqprio_qopt *qopt)
@@@ -145,16 -147,14 +154,20 @@@ static int mqprio_init(struct Qdisc *sc
  	 * supplied and verified mapping
  	 */
  	if (qopt->hw) {
 -		struct tc_mqprio_qopt offload = *qopt;
 -		struct tc_to_netdev tc = { { .mqprio = &offload } };
 -
 +		struct tc_to_netdev tc = {.type = TC_SETUP_MQPRIO,
 +					  { .tc = qopt->num_tc }};
 +
++<<<<<<< HEAD
 +		priv->hw_owned = 1;
 +		err = dev->netdev_ops->ndo_setup_tc ?
 +			dev->netdev_ops->ndo_setup_tc(dev, sch->handle, 0,
 +						      &tc) :
 +			dev->netdev_ops->ndo_setup_tc_rh72(dev, qopt->num_tc);
++=======
+ 		err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_MQPRIO, &tc);
++>>>>>>> 5fd9fc4e207d (net: sched: push cls related args into cls_common structure)
  		if (err)
  			return err;
 -
 -		priv->hw_offload = offload.hw;
  	} else {
  		netdev_set_num_tc(dev, qopt->num_tc);
  		for (i = 0; i < qopt->num_tc; i++)
* Unmerged path drivers/net/ethernet/freescale/dpaa/dpaa_eth.c
* Unmerged path drivers/net/ethernet/hisilicon/hns3/hns3pf/hns3_enet.c
* Unmerged path drivers/net/ethernet/netronome/nfp/bpf/main.c
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/main.h
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/offload.c
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_app.h
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_port.c
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_port.h
* Unmerged path drivers/net/ethernet/ti/netcp_core.c
* Unmerged path drivers/net/ethernet/amd/xgbe/xgbe-drv.c
* Unmerged path drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.c
* Unmerged path drivers/net/ethernet/broadcom/bnx2x/bnx2x_cmn.h
* Unmerged path drivers/net/ethernet/broadcom/bnxt/bnxt.c
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_u32.c b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_u32.c
index 82a33ea38f03..f294449538b2 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_u32.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_u32.c
@@ -145,11 +145,11 @@ static int fill_action_fields(struct adapter *adap,
 	return 0;
 }
 
-int cxgb4_config_knode(struct net_device *dev, __be16 protocol,
-		       struct tc_cls_u32_offload *cls)
+int cxgb4_config_knode(struct net_device *dev, struct tc_cls_u32_offload *cls)
 {
 	const struct cxgb4_match_field *start, *link_start = NULL;
 	struct adapter *adapter = netdev2adap(dev);
+	__be16 protocol = cls->common.protocol;
 	struct ch_filter_specification fs;
 	struct cxgb4_tc_u32_table *t;
 	struct cxgb4_link *link;
@@ -337,8 +337,7 @@ out:
 	return ret;
 }
 
-int cxgb4_delete_knode(struct net_device *dev, __be16 protocol,
-		       struct tc_cls_u32_offload *cls)
+int cxgb4_delete_knode(struct net_device *dev, struct tc_cls_u32_offload *cls)
 {
 	struct adapter *adapter = netdev2adap(dev);
 	unsigned int filter_id, max_tids, i, j;
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_u32.h b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_u32.h
index 021261a41c13..70a07b7cca56 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_u32.h
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_u32.h
@@ -44,10 +44,8 @@ static inline bool can_tc_u32_offload(struct net_device *dev)
 	return (dev->features & NETIF_F_HW_TC) && adap->tc_u32 ? true : false;
 }
 
-int cxgb4_config_knode(struct net_device *dev, __be16 protocol,
-		       struct tc_cls_u32_offload *cls);
-int cxgb4_delete_knode(struct net_device *dev, __be16 protocol,
-		       struct tc_cls_u32_offload *cls);
+int cxgb4_config_knode(struct net_device *dev, struct tc_cls_u32_offload *cls);
+int cxgb4_delete_knode(struct net_device *dev, struct tc_cls_u32_offload *cls);
 
 void cxgb4_cleanup_tc_u32(struct adapter *adapter);
 struct cxgb4_tc_u32_table *cxgb4_init_tc_u32(struct adapter *adap);
* Unmerged path drivers/net/ethernet/freescale/dpaa/dpaa_eth.c
* Unmerged path drivers/net/ethernet/hisilicon/hns3/hns3pf/hns3_enet.c
* Unmerged path drivers/net/ethernet/intel/fm10k/fm10k_netdev.c
* Unmerged path drivers/net/ethernet/intel/i40e/i40e_main.c
* Unmerged path drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx4/en_netdev.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index 7ecb54e0e3be..4e4d3e3be40d 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@ -1162,7 +1162,7 @@ static int parse_tc_fdb_actions(struct mlx5e_priv *priv, struct tcf_exts *exts,
 	return 0;
 }
 
-int mlx5e_configure_flower(struct mlx5e_priv *priv, __be16 protocol,
+int mlx5e_configure_flower(struct mlx5e_priv *priv,
 			   struct tc_cls_flower_offload *f)
 {
 	struct mlx5e_tc_table *tc = &priv->fs.tc;
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
index 34bf903fc886..19bac7939bc9 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
@@ -38,7 +38,7 @@
 int mlx5e_tc_init(struct mlx5e_priv *priv);
 void mlx5e_tc_cleanup(struct mlx5e_priv *priv);
 
-int mlx5e_configure_flower(struct mlx5e_priv *priv, __be16 protocol,
+int mlx5e_configure_flower(struct mlx5e_priv *priv,
 			   struct tc_cls_flower_offload *f);
 int mlx5e_delete_flower(struct mlx5e_priv *priv,
 			struct tc_cls_flower_offload *f);
* Unmerged path drivers/net/ethernet/mellanox/mlxsw/spectrum.c
diff --git a/drivers/net/ethernet/mellanox/mlxsw/spectrum.h b/drivers/net/ethernet/mellanox/mlxsw/spectrum.h
index 36aedb994b88..1e1d4d76f2b7 100644
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum.h
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum.h
@@ -691,7 +691,7 @@ void mlxsw_sp_acl_fini(struct mlxsw_sp *mlxsw_sp);
 extern const struct mlxsw_sp_acl_ops mlxsw_sp_acl_tcam_ops;
 
 int mlxsw_sp_flower_replace(struct mlxsw_sp_port *mlxsw_sp_port, bool ingress,
-			    __be16 protocol, struct tc_cls_flower_offload *f);
+			    struct tc_cls_flower_offload *f);
 void mlxsw_sp_flower_destroy(struct mlxsw_sp_port *mlxsw_sp_port, bool ingress,
 			     struct tc_cls_flower_offload *f);
 
diff --git a/drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c b/drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c
index c668b6dd906d..1baedcf43763 100644
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum_flower.c
@@ -246,7 +246,7 @@ static int mlxsw_sp_flower_parse(struct mlxsw_sp *mlxsw_sp,
 }
 
 int mlxsw_sp_flower_replace(struct mlxsw_sp_port *mlxsw_sp_port, bool ingress,
-			    __be16 protocol, struct tc_cls_flower_offload *f)
+			    struct tc_cls_flower_offload *f)
 {
 	struct mlxsw_sp *mlxsw_sp = mlxsw_sp_port->mlxsw_sp;
 	struct net_device *dev = mlxsw_sp_port->dev;
* Unmerged path drivers/net/ethernet/netronome/nfp/bpf/main.c
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/main.h
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/offload.c
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_app.h
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_port.c
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_port.h
* Unmerged path drivers/net/ethernet/sfc/efx.h
* Unmerged path drivers/net/ethernet/sfc/falcon/efx.h
* Unmerged path drivers/net/ethernet/sfc/falcon/tx.c
* Unmerged path drivers/net/ethernet/sfc/tx.c
* Unmerged path drivers/net/ethernet/ti/netcp_core.c
* Unmerged path include/linux/netdevice.h
* Unmerged path include/net/pkt_cls.h
* Unmerged path net/dsa/slave.c
* Unmerged path net/sched/cls_bpf.c
* Unmerged path net/sched/cls_flower.c
* Unmerged path net/sched/cls_matchall.c
* Unmerged path net/sched/cls_u32.c
* Unmerged path net/sched/sch_mqprio.c
