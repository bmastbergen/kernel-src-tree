iommu/vt-d: per-cpu deferred invalidation queues

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [iommu] vt-d: per-cpu deferred invalidation queues (Jerry Snitselaar) [1499325]
Rebuild_FUZZ: 93.33%
commit-author Omer Peleg <omer@cs.technion.ac.il>
commit aa4732406e1290dd18a8d2078977996c152a4be7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/aa473240.failed

The IOMMU's IOTLB invalidation is a costly process.  When iommu mode
is not set to "strict", it is done asynchronously. Current code
amortizes the cost of invalidating IOTLB entries by batching all the
invalidations in the system and performing a single global invalidation
instead. The code queues pending invalidations in a global queue that
is accessed under the global "async_umap_flush_lock" spinlock, which
can result is significant spinlock contention.

This patch splits this deferred queue into multiple per-cpu deferred
queues, and thus gets rid of the "async_umap_flush_lock" and its
contention.  To keep existing deferred invalidation behavior, it still
invalidates the pending invalidations of all CPUs whenever a CPU
reaches its watermark or a timeout occurs.

	Signed-off-by: Omer Peleg <omer@cs.technion.ac.il>
[mad@cs.technion.ac.il: rebased, cleaned up and reworded the commit message]
	Signed-off-by: Adam Morrison <mad@cs.technion.ac.il>
	Reviewed-by: Shaohua Li <shli@fb.com>
	Reviewed-by: Ben Serebrin <serebrin@google.com>
	Signed-off-by: David Woodhouse <David.Woodhouse@intel.com>
(cherry picked from commit aa4732406e1290dd18a8d2078977996c152a4be7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/intel-iommu.c
diff --cc drivers/iommu/intel-iommu.c
index 2cb3c26dda40,a64b6f3b9a66..000000000000
--- a/drivers/iommu/intel-iommu.c
+++ b/drivers/iommu/intel-iommu.c
@@@ -4424,14 -4542,23 +4458,34 @@@ static struct notifier_block intel_iomm
  	.priority = 0
  };
  
++<<<<<<< HEAD
 +static void intel_disable_iommus(void)
 +{
 +	struct intel_iommu *iommu = NULL;
 +	struct dmar_drhd_unit *drhd;
 +
 +	for_each_iommu(iommu, drhd)
 +		iommu_disable_translation(iommu);
 +}
++=======
+ static int intel_iommu_cpu_notifier(struct notifier_block *nfb,
+ 				    unsigned long action, void *v)
+ {
+ 	unsigned int cpu = (unsigned long)v;
+ 
+ 	switch (action) {
+ 	case CPU_DEAD:
+ 	case CPU_DEAD_FROZEN:
+ 		flush_unmaps_timeout(cpu);
+ 		break;
+ 	}
+ 	return NOTIFY_OK;
+ }
+ 
+ static struct notifier_block intel_iommu_cpu_nb = {
+ 	.notifier_call = intel_iommu_cpu_notifier,
+ };
++>>>>>>> aa4732406e12 (iommu/vt-d: per-cpu deferred invalidation queues)
  
  static ssize_t intel_iommu_show_version(struct device *dev,
  					struct device_attribute *attr,
* Unmerged path drivers/iommu/intel-iommu.c
