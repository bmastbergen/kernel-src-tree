sched: don't use skb queue helpers

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Florian Westphal <fw@strlen.de>
commit 97d0678f913369af0dc8b510a682a641654ab743
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/97d0678f.failed

A followup change will replace the sk_buff_head in the qdisc
struct with a slightly different list.

Use of the sk_buff_head helpers will thus cause compiler
warnings.

Open-code these accesses in an extra change to ease review.

	Signed-off-by: Florian Westphal <fw@strlen.de>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 97d0678f913369af0dc8b510a682a641654ab743)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sched/sch_netem.c
diff --cc net/sched/sch_netem.c
index 759dca493346,1832d7732dbc..000000000000
--- a/net/sched/sch_netem.c
+++ b/net/sched/sch_netem.c
@@@ -509,8 -502,8 +509,13 @@@ static int netem_enqueue(struct sk_buf
  			1<<(prandom_u32() % 8);
  	}
  
++<<<<<<< HEAD
 +	if (unlikely(skb_queue_len(&sch->q) >= sch->limit))
 +		return qdisc_drop(skb, sch);
++=======
+ 	if (unlikely(sch->q.qlen >= sch->limit))
+ 		return qdisc_drop(skb, sch, to_free);
++>>>>>>> 97d0678f9133 (sched: don't use skb queue helpers)
  
  	qdisc_qstats_backlog_inc(sch, skb);
  
diff --git a/net/sched/sch_fifo.c b/net/sched/sch_fifo.c
index 30a985400f73..d1364903387e 100644
--- a/net/sched/sch_fifo.c
+++ b/net/sched/sch_fifo.c
@@ -29,7 +29,7 @@ static int bfifo_enqueue(struct sk_buff *skb, struct Qdisc *sch)
 
 static int pfifo_enqueue(struct sk_buff *skb, struct Qdisc *sch)
 {
-	if (likely(skb_queue_len(&sch->q) < sch->limit))
+	if (likely(sch->q.qlen < sch->limit))
 		return qdisc_enqueue_tail(skb, sch);
 
 	return qdisc_drop(skb, sch);
@@ -39,7 +39,7 @@ static int pfifo_tail_enqueue(struct sk_buff *skb, struct Qdisc *sch)
 {
 	unsigned int prev_backlog;
 
-	if (likely(skb_queue_len(&sch->q) < sch->limit))
+	if (likely(sch->q.qlen < sch->limit))
 		return qdisc_enqueue_tail(skb, sch);
 
 	prev_backlog = sch->qstats.backlog;
diff --git a/net/sched/sch_generic.c b/net/sched/sch_generic.c
index 57cbfa322683..d01a7f75d23b 100644
--- a/net/sched/sch_generic.c
+++ b/net/sched/sch_generic.c
@@ -474,7 +474,7 @@ static inline struct sk_buff_head *band2list(struct pfifo_fast_priv *priv,
 
 static int pfifo_fast_enqueue(struct sk_buff *skb, struct Qdisc *qdisc)
 {
-	if (skb_queue_len(&qdisc->q) < qdisc_dev(qdisc)->tx_queue_len) {
+	if (qdisc->q.qlen < qdisc_dev(qdisc)->tx_queue_len) {
 		int band = prio2band[skb->priority & TC_PRIO_MAX];
 		struct pfifo_fast_priv *priv = qdisc_priv(qdisc);
 		struct sk_buff_head *list = band2list(priv, band);
* Unmerged path net/sched/sch_netem.c
