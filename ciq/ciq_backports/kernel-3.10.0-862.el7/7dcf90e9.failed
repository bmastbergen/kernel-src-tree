PCI: hv: Use vPCI protocol version 1.2

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [pci] hv: Use vPCI protocol version 1.2 (Vitaly Kuznetsov) [1459202]
Rebuild_FUZZ: 92.96%
commit-author Jork Loeser <jloeser@microsoft.com>
commit 7dcf90e9e032432e91ce77dd872d2227e9d5b741
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/7dcf90e9.failed

Update the Hyper-V vPCI driver to use the Server-2016 version of the vPCI
protocol, fixing MSI creation and retargeting issues.

	Signed-off-by: Jork Loeser <jloeser@microsoft.com>
	Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
	Reviewed-by: K. Y. Srinivasan <kys@microsoft.com>
	Acked-by: K. Y. Srinivasan <kys@microsoft.com>
(cherry picked from commit 7dcf90e9e032432e91ce77dd872d2227e9d5b741)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/uapi/asm/hyperv.h
#	drivers/pci/pci-hyperv.c
diff --cc arch/x86/include/uapi/asm/hyperv.h
index ef57dccc61ca,237ec6cda206..000000000000
--- a/arch/x86/include/uapi/asm/hyperv.h
+++ b/arch/x86/include/uapi/asm/hyperv.h
@@@ -142,6 -147,22 +142,25 @@@
   */
  #define HV_X64_RELAXED_TIMING_RECOMMENDED	(1 << 5)
  
++<<<<<<< HEAD
++=======
+ /*
+  * Virtual APIC support
+  */
+ #define HV_X64_DEPRECATING_AEOI_RECOMMENDED	(1 << 9)
+ 
+ /*
+  * HV_VP_SET available
+  */
+ #define HV_X64_EX_PROCESSOR_MASKS_RECOMMENDED	(1 << 11)
+ 
+ 
+ /*
+  * Crash notification flag.
+  */
+ #define HV_CRASH_CTL_CRASH_NOTIFY (1ULL << 63)
+ 
++>>>>>>> 7dcf90e9e032 (PCI: hv: Use vPCI protocol version 1.2)
  /* MSR used to identify the guest OS. */
  #define HV_X64_MSR_GUEST_OS_ID			0x40000000
  
diff --cc drivers/pci/pci-hyperv.c
index 61c7f8142d81,415dcc69a502..000000000000
--- a/drivers/pci/pci-hyperv.c
+++ b/drivers/pci/pci-hyperv.c
@@@ -722,17 -892,40 +790,24 @@@ static int hv_set_affinity(struct irq_d
  	struct irq_cfg *cfg = irqd_cfg(data);
  	struct retarget_msi_interrupt *params;
  	struct hv_pcibus_device *hbus;
 -	struct cpumask *dest;
  	struct pci_bus *pbus;
  	struct pci_dev *pdev;
++<<<<<<< HEAD:drivers/pci/pci-hyperv.c
 +	int cpu, ret;
 +	unsigned int dest_id;
++=======
++>>>>>>> 7dcf90e9e032 (PCI: hv: Use vPCI protocol version 1.2):drivers/pci/host/pci-hyperv.c
  	unsigned long flags;
+ 	u32 var_size = 0;
+ 	int cpu_vmbus;
+ 	int cpu;
+ 	u64 res;
  
 -	dest = irq_data_get_affinity_mask(data);
 -	pdev = msi_desc_to_pci_dev(msi_desc);
 +	ret = __ioapic_set_affinity(data, dest, &dest_id);
 +	if (ret)
 +		return ret;
 +
 +	pdev = msi_desc_to_pci_dev(data->msi_desc);
  	pbus = pdev->bus;
  	hbus = container_of(pbus->sysdata, struct hv_pcibus_device, sysdata);
  
@@@ -741,52 -934,75 +816,120 @@@
  	params = &hbus->retarget_msi_interrupt_params;
  	memset(params, 0, sizeof(*params));
  	params->partition_id = HV_PARTITION_ID_SELF;
++<<<<<<< HEAD:drivers/pci/pci-hyperv.c
 +	params->source = 1; /* MSI(-X) */
 +	params->address = data->msi_desc->msg.address_lo;
 +	params->data = data->msi_desc->msg.data;
++=======
+ 	params->int_entry.source = 1; /* MSI(-X) */
+ 	params->int_entry.address = msi_desc->msg.address_lo;
+ 	params->int_entry.data = msi_desc->msg.data;
++>>>>>>> 7dcf90e9e032 (PCI: hv: Use vPCI protocol version 1.2):drivers/pci/host/pci-hyperv.c
  	params->device_id = (hbus->hdev->dev_instance.b[5] << 24) |
  			   (hbus->hdev->dev_instance.b[4] << 16) |
  			   (hbus->hdev->dev_instance.b[7] << 8) |
  			   (hbus->hdev->dev_instance.b[6] & 0xf8) |
  			   PCI_FUNC(pdev->devfn);
- 	params->vector = cfg->vector;
+ 	params->int_target.vector = cfg->vector;
  
++<<<<<<< HEAD:drivers/pci/pci-hyperv.c
 +	for_each_cpu_and(cpu, dest, cpu_online_mask)
 +		params->vp_mask |= (1ULL << vmbus_cpu_number_to_vp_number(cpu));
 +
 +	hv_do_hypercall(HVCALL_RETARGET_INTERRUPT, params, NULL);
 +	spin_unlock_irqrestore(&hbus->retarget_msi_interrupt_lock, flags);
 +
 +	return 0;
 +}
 +
 +int hv_setup_msi_irqs(struct pci_dev *pdev, int nvec, int type)
 +{
 +	struct msi_desc *msidesc;
 +	struct irq_chip *chip;
 +	int ret;
 +
 +	/*
 +	 * Call the base function which will do everything related to setting up
 +	 * the tracking structures.
 +	 */
 +
 +	ret = hv_msi.setup_msi_irqs(pdev, nvec, type);
 +	if (ret)
 +		return ret;
 +
 +	list_for_each_entry(msidesc, &pdev->msi_list, list) {
 +		if (msidesc->irq) {
 +			chip = irq_get_chip(msidesc->irq);
 +			/*
 +			 * Replace the affinity callback so that it doesn't
 +			 * rearrage the message in the hardware.
 +			 */
 +			chip->irq_set_affinity = hv_set_affinity;
 +		}
 +	}
 +
 +	return 0;
++=======
+ 	/*
+ 	 * Honoring apic->irq_delivery_mode set to dest_Fixed by
+ 	 * setting the HV_DEVICE_INTERRUPT_TARGET_MULTICAST flag results in a
+ 	 * spurious interrupt storm. Not doing so does not seem to have a
+ 	 * negative effect (yet?).
+ 	 */
+ 
+ 	if (pci_protocol_version >= PCI_PROTOCOL_VERSION_1_2) {
+ 		/*
+ 		 * PCI_PROTOCOL_VERSION_1_2 supports the VP_SET version of the
+ 		 * HVCALL_RETARGET_INTERRUPT hypercall, which also coincides
+ 		 * with >64 VP support.
+ 		 * ms_hyperv.hints & HV_X64_EX_PROCESSOR_MASKS_RECOMMENDED
+ 		 * is not sufficient for this hypercall.
+ 		 */
+ 		params->int_target.flags |=
+ 			HV_DEVICE_INTERRUPT_TARGET_PROCESSOR_SET;
+ 		params->int_target.vp_set.valid_banks =
+ 			(1ull << HV_VP_SET_BANK_COUNT_MAX) - 1;
+ 
+ 		/*
+ 		 * var-sized hypercall, var-size starts after vp_mask (thus
+ 		 * vp_set.format does not count, but vp_set.valid_banks does).
+ 		 */
+ 		var_size = 1 + HV_VP_SET_BANK_COUNT_MAX;
+ 
+ 		for_each_cpu_and(cpu, dest, cpu_online_mask) {
+ 			cpu_vmbus = hv_tmp_cpu_nr_to_vp_nr(cpu);
+ 
+ 			if (cpu_vmbus >= HV_VP_SET_BANK_COUNT_MAX * 64) {
+ 				dev_err(&hbus->hdev->device,
+ 					"too high CPU %d", cpu_vmbus);
+ 				res = 1;
+ 				goto exit_unlock;
+ 			}
+ 
+ 			params->int_target.vp_set.masks[cpu_vmbus / 64] |=
+ 				(1ULL << (cpu_vmbus & 63));
+ 		}
+ 	} else {
+ 		for_each_cpu_and(cpu, dest, cpu_online_mask) {
+ 			params->int_target.vp_mask |=
+ 				(1ULL << hv_tmp_cpu_nr_to_vp_nr(cpu));
+ 		}
+ 	}
+ 
+ 	res = hv_do_hypercall(HVCALL_RETARGET_INTERRUPT | (var_size << 17),
+ 			      params, NULL);
+ 
+ exit_unlock:
+ 	spin_unlock_irqrestore(&hbus->retarget_msi_interrupt_lock, flags);
+ 
+ 	if (res) {
+ 		dev_err(&hbus->hdev->device,
+ 			"%s() failed: %#llx", __func__, res);
+ 		return;
+ 	}
+ 
+ 	pci_msi_unmask_irq(data);
++>>>>>>> 7dcf90e9e032 (PCI: hv: Use vPCI protocol version 1.2):drivers/pci/host/pci-hyperv.c
  }
  
  struct compose_comp_ctxt {
@@@ -806,8 -1022,57 +949,55 @@@ static void hv_pci_compose_compl(void *
  	complete(&comp_pkt->comp_pkt.host_event);
  }
  
+ static u32 hv_compose_msi_req_v1(
+ 	struct pci_create_interrupt *int_pkt, struct cpumask *affinity,
+ 	u32 slot, u8 vector)
+ {
+ 	int_pkt->message_type.type = PCI_CREATE_INTERRUPT_MESSAGE;
+ 	int_pkt->wslot.slot = slot;
+ 	int_pkt->int_desc.vector = vector;
+ 	int_pkt->int_desc.vector_count = 1;
+ 	int_pkt->int_desc.delivery_mode =
+ 		(apic->irq_delivery_mode == dest_LowestPrio) ?
+ 			dest_LowestPrio : dest_Fixed;
+ 
+ 	/*
+ 	 * Create MSI w/ dummy vCPU set, overwritten by subsequent retarget in
+ 	 * hv_irq_unmask().
+ 	 */
+ 	int_pkt->int_desc.cpu_mask = CPU_AFFINITY_ALL;
+ 
+ 	return sizeof(*int_pkt);
+ }
+ 
+ static u32 hv_compose_msi_req_v2(
+ 	struct pci_create_interrupt2 *int_pkt, struct cpumask *affinity,
+ 	u32 slot, u8 vector)
+ {
+ 	int cpu;
+ 
+ 	int_pkt->message_type.type = PCI_CREATE_INTERRUPT_MESSAGE2;
+ 	int_pkt->wslot.slot = slot;
+ 	int_pkt->int_desc.vector = vector;
+ 	int_pkt->int_desc.vector_count = 1;
+ 	int_pkt->int_desc.delivery_mode =
+ 		(apic->irq_delivery_mode == dest_LowestPrio) ?
+ 			dest_LowestPrio : dest_Fixed;
+ 
+ 	/*
+ 	 * Create MSI w/ dummy vCPU set targeting just one vCPU, overwritten
+ 	 * by subsequent retarget in hv_irq_unmask().
+ 	 */
+ 	cpu = cpumask_first_and(affinity, cpu_online_mask);
+ 	int_pkt->int_desc.processor_array[0] =
+ 		hv_tmp_cpu_nr_to_vp_nr(cpu);
+ 	int_pkt->int_desc.processor_count = 1;
+ 
+ 	return sizeof(*int_pkt);
+ }
+ 
  /**
   * hv_compose_msi_msg() - Supplies a valid MSI address/data
 - * @data:	Everything about this MSI
 - * @msg:	Buffer that is filled in by this function
   *
   * This function unpacks the IRQ looking for target CPU set, IDT
   * vector and mode and sends a message to the parent partition
@@@ -823,16 -1086,21 +1013,24 @@@ static void hv_compose_msi_msg(struct p
  	struct hv_pcibus_device *hbus;
  	struct hv_pci_dev *hpdev;
  	struct pci_bus *pbus;
++<<<<<<< HEAD:drivers/pci/pci-hyperv.c
 +	struct pci_create_interrupt *int_pkt;
++=======
+ 	struct pci_dev *pdev;
++>>>>>>> 7dcf90e9e032 (PCI: hv: Use vPCI protocol version 1.2):drivers/pci/host/pci-hyperv.c
  	struct compose_comp_ctxt comp;
  	struct tran_int_desc *int_desc;
  	struct {
- 		struct pci_packet pkt;
- 		u8 buffer[sizeof(struct pci_create_interrupt)];
- 	} ctxt;
- 	int cpu;
+ 		struct pci_packet pci_pkt;
+ 		union {
+ 			struct pci_create_interrupt v1;
+ 			struct pci_create_interrupt2 v2;
+ 		} int_pkts;
+ 	} __packed ctxt;
+ 
+ 	u32 size;
  	int ret;
  
 -	pdev = msi_desc_to_pci_dev(irq_data_get_msi_desc(data));
  	pbus = pdev->bus;
  	hbus = container_of(pbus->sysdata, struct hv_pcibus_device, sysdata);
  	hpdev = get_pcichild_wslot(hbus, devfn_to_wslot(pdev->devfn));
@@@ -845,35 -1120,44 +1043,58 @@@
  
  	memset(&ctxt, 0, sizeof(ctxt));
  	init_completion(&comp.comp_pkt.host_event);
- 	ctxt.pkt.completion_func = hv_pci_compose_compl;
- 	ctxt.pkt.compl_ctxt = &comp;
- 	int_pkt = (struct pci_create_interrupt *)&ctxt.pkt.message;
- 	int_pkt->message_type.type = PCI_CREATE_INTERRUPT_MESSAGE;
- 	int_pkt->wslot.slot = hpdev->desc.win_slot.slot;
- 	int_pkt->int_desc.vector = cfg->vector;
- 	int_pkt->int_desc.vector_count = 1;
- 	int_pkt->int_desc.delivery_mode =
- 		(apic->irq_delivery_mode == dest_LowestPrio) ? 1 : 0;
+ 	ctxt.pci_pkt.completion_func = hv_pci_compose_compl;
+ 	ctxt.pci_pkt.compl_ctxt = &comp;
  
++<<<<<<< HEAD:drivers/pci/pci-hyperv.c
 +	/*
 +	 * This bit doesn't have to work on machines with more than 64
 +	 * processors because Hyper-V only supports 64 in a guest.
 +	 */
 +	if (cpumask_weight(cfg->domain) >= 32) {
 +		int_pkt->int_desc.cpu_mask = CPU_AFFINITY_ALL;
 +	} else {
 +		for_each_cpu_and(cpu, cfg->domain, cpu_online_mask) {
 +			int_pkt->int_desc.cpu_mask |=
 +				(1ULL << vmbus_cpu_number_to_vp_number(cpu));
 +		}
++=======
+ 	switch (pci_protocol_version) {
+ 	case PCI_PROTOCOL_VERSION_1_1:
+ 		size = hv_compose_msi_req_v1(&ctxt.int_pkts.v1,
+ 					irq_data_get_affinity_mask(data),
+ 					hpdev->desc.win_slot.slot,
+ 					cfg->vector);
+ 		break;
+ 
+ 	case PCI_PROTOCOL_VERSION_1_2:
+ 		size = hv_compose_msi_req_v2(&ctxt.int_pkts.v2,
+ 					irq_data_get_affinity_mask(data),
+ 					hpdev->desc.win_slot.slot,
+ 					cfg->vector);
+ 		break;
+ 
+ 	default:
+ 		/* As we only negotiate protocol versions known to this driver,
+ 		 * this path should never hit. However, this is it not a hot
+ 		 * path so we print a message to aid future updates.
+ 		 */
+ 		dev_err(&hbus->hdev->device,
+ 			"Unexpected vPCI protocol, update driver.");
+ 		goto free_int_desc;
++>>>>>>> 7dcf90e9e032 (PCI: hv: Use vPCI protocol version 1.2):drivers/pci/host/pci-hyperv.c
  	}
  
- 	ret = vmbus_sendpacket(hpdev->hbus->hdev->channel, int_pkt,
- 			       sizeof(*int_pkt), (unsigned long)&ctxt.pkt,
+ 	ret = vmbus_sendpacket(hpdev->hbus->hdev->channel, &ctxt.int_pkts,
+ 			       size, (unsigned long)&ctxt.pci_pkt,
  			       VM_PKT_DATA_INBAND,
  			       VMBUS_DATA_PACKET_FLAG_COMPLETION_REQUESTED);
- 	if (ret)
+ 	if (ret) {
+ 		dev_err(&hbus->hdev->device,
+ 			"Sending request for interrupt failed: 0x%x",
+ 			comp.comp_pkt.completion_status);
  		goto free_int_desc;
+ 	}
  
  	wait_for_completion(&comp.comp_pkt.host_event);
  
* Unmerged path arch/x86/include/uapi/asm/hyperv.h
* Unmerged path drivers/pci/pci-hyperv.c
