iommu/amd: Don't copy GCR3 table root pointer

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [iommu] amd: Don't copy GCR3 table root pointer (Jerry Snitselaar) [1062729]
Rebuild_FUZZ: 92.86%
commit-author Baoquan He <bhe@redhat.com>
commit daae2d25a4779b272a66ddd01f5810bcee822b9e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/daae2d25.failed

When iommu is pre_enabled in kdump kernel, if a device is set up with
guest translations (DTE.GV=1), then don't copy GCR3 table root pointer
but move the device over to an empty guest-cr3 table and handle the
faults in the PPR log (which answer them with INVALID). After all these
PPR faults are recoverable for the device and we should not allow the
device to change old-kernels data when we don't have to.

	Signed-off-by: Baoquan He <bhe@redhat.com>
	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit daae2d25a4779b272a66ddd01f5810bcee822b9e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/amd_iommu.c
#	drivers/iommu/amd_iommu_init.c
#	drivers/iommu/amd_iommu_proto.h
diff --cc drivers/iommu/amd_iommu.c
index e80343c1de99,9e8ea1907796..000000000000
--- a/drivers/iommu/amd_iommu.c
+++ b/drivers/iommu/amd_iommu.c
@@@ -81,30 -100,9 +81,33 @@@ static struct iommu_ops amd_iommu_ops
  static ATOMIC_NOTIFIER_HEAD(ppr_notifier);
  int amd_iommu_max_glx_val = -1;
  
 -static const struct dma_map_ops amd_iommu_dma_ops;
 +static struct dma_map_ops amd_iommu_dma_ops;
 +
 +/*
++<<<<<<< HEAD
 + * This struct contains device specific data for the IOMMU
 + */
 +struct iommu_dev_data {
 +	struct list_head list;		  /* For domain->dev_list */
 +	struct list_head dev_data_list;	  /* For global dev_data_list */
 +	struct list_head alias_list;      /* Link alias-groups together */
 +	struct iommu_dev_data *alias_data;/* The alias dev_data */
 +	struct protection_domain *domain; /* Domain the device is bound to */
 +	u16 devid;			  /* PCI Device ID */
 +	bool iommu_v2;			  /* Device can make use of IOMMUv2 */
 +	bool passthrough;		  /* Device is identity mapped */
 +	struct {
 +		bool enabled;
 +		int qdep;
 +	} ats;				  /* ATS state */
 +	bool pri_tlp;			  /* PASID TLB required for
 +					     PPR completions */
 +	u32 errata;			  /* Bitmap for errata to apply */
 +};
  
  /*
++=======
++>>>>>>> daae2d25a477 (iommu/amd: Don't copy GCR3 table root pointer)
   * general struct to manage commands send to an IOMMU
   */
  struct iommu_cmd {
@@@ -229,14 -358,11 +232,18 @@@ static struct iommu_dev_data *find_dev_
  	return dev_data;
  }
  
++<<<<<<< HEAD
 +static inline u16 get_device_id(struct device *dev)
 +{
 +	struct pci_dev *pdev = to_pci_dev(dev);
 +
 +	return PCI_DEVID(pdev->bus->number, pdev->devfn);
 +}
 +
 +static struct iommu_dev_data *get_dev_data(struct device *dev)
++=======
+ struct iommu_dev_data *get_dev_data(struct device *dev)
++>>>>>>> daae2d25a477 (iommu/amd: Don't copy GCR3 table root pointer)
  {
  	return dev->archdata.iommu;
  }
@@@ -2527,6 -2506,18 +2535,21 @@@ static void update_domain(struct protec
  	domain->updated = false;
  }
  
++<<<<<<< HEAD
++=======
+ static int dir2prot(enum dma_data_direction direction)
+ {
+ 	if (direction == DMA_TO_DEVICE)
+ 		return IOMMU_PROT_IR;
+ 	else if (direction == DMA_FROM_DEVICE)
+ 		return IOMMU_PROT_IW;
+ 	else if (direction == DMA_BIDIRECTIONAL)
+ 		return IOMMU_PROT_IW | IOMMU_PROT_IR;
+ 	else
+ 		return 0;
+ }
+ 
++>>>>>>> daae2d25a477 (iommu/amd: Don't copy GCR3 table root pointer)
  /*
   * This function contains common code for mapping of a physically
   * contiguous memory region into DMA address space. It is used by all
diff --cc drivers/iommu/amd_iommu_init.c
index 326f501de681,88e7a6e950ae..000000000000
--- a/drivers/iommu/amd_iommu_init.c
+++ b/drivers/iommu/amd_iommu_init.c
@@@ -249,6 -264,28 +250,31 @@@ static int amd_iommu_enable_interrupts(
  static int __init iommu_go_to_state(enum iommu_init_state state);
  static void init_device_table_dma(void);
  
++<<<<<<< HEAD
++=======
+ static bool __initdata amd_iommu_pre_enabled = true;
+ 
+ bool translation_pre_enabled(struct amd_iommu *iommu)
+ {
+ 	return (iommu->flags & AMD_IOMMU_FLAG_TRANS_PRE_ENABLED);
+ }
+ EXPORT_SYMBOL(translation_pre_enabled);
+ 
+ static void clear_translation_pre_enabled(struct amd_iommu *iommu)
+ {
+ 	iommu->flags &= ~AMD_IOMMU_FLAG_TRANS_PRE_ENABLED;
+ }
+ 
+ static void init_translation_status(struct amd_iommu *iommu)
+ {
+ 	u32 ctrl;
+ 
+ 	ctrl = readl(iommu->mmio_base + MMIO_CONTROL_OFFSET);
+ 	if (ctrl & (1<<CONTROL_IOMMU_EN))
+ 		iommu->flags |= AMD_IOMMU_FLAG_TRANS_PRE_ENABLED;
+ }
+ 
++>>>>>>> daae2d25a477 (iommu/amd: Don't copy GCR3 table root pointer)
  static inline void update_last_devid(u16 devid)
  {
  	if (devid > amd_iommu_last_bdf)
@@@ -700,11 -857,14 +726,12 @@@ static bool copy_device_table(void
  	struct dev_table_entry *old_devtb = NULL;
  	u32 lo, hi, devid, old_devtb_size;
  	phys_addr_t old_devtb_phys;
 +	u64 entry, last_entry = 0;
  	struct amd_iommu *iommu;
 -	u16 dom_id, dte_v, irq_v;
 +	u16 dom_id, dte_v;
  	gfp_t gfp_flag;
+ 	u64 tmp;
  
 -	if (!amd_iommu_pre_enabled)
 -		return false;
  
  	pr_warn("Translation is already enabled - trying to copy translation structures\n");
  	for_each_iommu(iommu) {
@@@ -748,8 -908,34 +775,34 @@@
  		old_dev_tbl_cpy[devid] = old_devtb[devid];
  		dom_id = old_devtb[devid].data[1] & DEV_DOMID_MASK;
  		dte_v = old_devtb[devid].data[0] & DTE_FLAG_V;
 -
 -		if (dte_v && dom_id) {
 -			old_dev_tbl_cpy[devid].data[0] = old_devtb[devid].data[0];
 -			old_dev_tbl_cpy[devid].data[1] = old_devtb[devid].data[1];
 +		if (dte_v && dom_id)
  			__set_bit(dom_id, amd_iommu_pd_alloc_bitmap);
++<<<<<<< HEAD
++=======
+ 			/* If gcr3 table existed, mask it out */
+ 			if (old_devtb[devid].data[0] & DTE_FLAG_GV) {
+ 				tmp = DTE_GCR3_VAL_B(~0ULL) << DTE_GCR3_SHIFT_B;
+ 				tmp |= DTE_GCR3_VAL_C(~0ULL) << DTE_GCR3_SHIFT_C;
+ 				old_dev_tbl_cpy[devid].data[1] &= ~tmp;
+ 				tmp = DTE_GCR3_VAL_A(~0ULL) << DTE_GCR3_SHIFT_A;
+ 				tmp |= DTE_FLAG_GV;
+ 				old_dev_tbl_cpy[devid].data[0] &= ~tmp;
+ 			}
+ 		}
+ 
+ 		irq_v = old_devtb[devid].data[2] & DTE_IRQ_REMAP_ENABLE;
+ 		int_ctl = old_devtb[devid].data[2] & DTE_IRQ_REMAP_INTCTL_MASK;
+ 		int_tab_len = old_devtb[devid].data[2] & DTE_IRQ_TABLE_LEN_MASK;
+ 		if (irq_v && (int_ctl || int_tab_len)) {
+ 			if ((int_ctl != DTE_IRQ_REMAP_INTCTL) ||
+ 			    (int_tab_len != DTE_IRQ_TABLE_LEN)) {
+ 				pr_err("Wrong old irq remapping flag: %#x\n", devid);
+ 				return false;
+ 			}
+ 
+ 		        old_dev_tbl_cpy[devid].data[2] = old_devtb[devid].data[2];
+ 		}
++>>>>>>> daae2d25a477 (iommu/amd: Don't copy GCR3 table root pointer)
  	}
  	memunmap(old_devtb);
  
diff --cc drivers/iommu/amd_iommu_proto.h
index a3b5a778d824,90e62e9b01c5..000000000000
--- a/drivers/iommu/amd_iommu_proto.h
+++ b/drivers/iommu/amd_iommu_proto.h
@@@ -76,4 -87,6 +76,9 @@@ static inline bool iommu_feature(struc
  	return !!(iommu->features & f);
  }
  
++<<<<<<< HEAD
++=======
+ extern bool translation_pre_enabled(struct amd_iommu *iommu);
+ extern struct iommu_dev_data *get_dev_data(struct device *dev);
++>>>>>>> daae2d25a477 (iommu/amd: Don't copy GCR3 table root pointer)
  #endif /* _ASM_X86_AMD_IOMMU_PROTO_H  */
* Unmerged path drivers/iommu/amd_iommu.c
* Unmerged path drivers/iommu/amd_iommu_init.c
* Unmerged path drivers/iommu/amd_iommu_proto.h
diff --git a/drivers/iommu/amd_iommu_types.h b/drivers/iommu/amd_iommu_types.h
index e448daa671af..c311f88b3f0d 100644
--- a/drivers/iommu/amd_iommu_types.h
+++ b/drivers/iommu/amd_iommu_types.h
@@ -534,6 +534,30 @@ struct devid_map {
 	bool cmd_line;
 };
 
+/*
+ * This struct contains device specific data for the IOMMU
+ */
+struct iommu_dev_data {
+	struct list_head list;		  /* For domain->dev_list */
+	struct list_head dev_data_list;	  /* For global dev_data_list */
+	struct protection_domain *domain; /* Domain the device is bound to */
+	u16 devid;			  /* PCI Device ID */
+	u16 alias;			  /* Alias Device ID */
+	bool iommu_v2;			  /* Device can make use of IOMMUv2 */
+	bool passthrough;		  /* Device is identity mapped */
+	struct {
+		bool enabled;
+		int qdep;
+	} ats;				  /* ATS state */
+	bool pri_tlp;			  /* PASID TLB required for
+					     PPR completions */
+	u32 errata;			  /* Bitmap for errata to apply */
+	bool use_vapic;			  /* Enable device to use vapic mode */
+	bool defer_attach;
+
+	struct ratelimit_state rs;        /* Ratelimit IOPF messages */
+};
+
 /* Map HPET and IOAPIC ids to the devid used by the IOMMU */
 extern struct list_head ioapic_map;
 extern struct list_head hpet_map;
diff --git a/drivers/iommu/amd_iommu_v2.c b/drivers/iommu/amd_iommu_v2.c
index 9b539a79cc08..f84b6cf42c5f 100644
--- a/drivers/iommu/amd_iommu_v2.c
+++ b/drivers/iommu/amd_iommu_v2.c
@@ -564,14 +564,30 @@ static int ppr_notifier(struct notifier_block *nb, unsigned long e, void *data)
 	unsigned long flags;
 	struct fault *fault;
 	bool finish;
-	u16 tag;
+	u16 tag, devid;
 	int ret;
+	struct iommu_dev_data *dev_data;
+	struct pci_dev *pdev = NULL;
 
 	iommu_fault = data;
 	tag         = iommu_fault->tag & 0x1ff;
 	finish      = (iommu_fault->tag >> 9) & 1;
 
+	devid = iommu_fault->device_id;
+	pdev = pci_get_bus_and_slot(PCI_BUS_NUM(devid), devid & 0xff);
+	if (!pdev)
+		return -ENODEV;
+	dev_data = get_dev_data(&pdev->dev);
+
+	/* In kdump kernel pci dev is not initialized yet -> send INVALID */
 	ret = NOTIFY_DONE;
+	if (translation_pre_enabled(amd_iommu_rlookup_table[devid])
+		&& dev_data->defer_attach) {
+		amd_iommu_complete_ppr(pdev, iommu_fault->pasid,
+				       PPR_INVALID, tag);
+		goto out;
+	}
+
 	dev_state = get_device_state(iommu_fault->device_id);
 	if (dev_state == NULL)
 		goto out;
