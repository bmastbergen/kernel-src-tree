cpufreq: intel_pstate: Set EPP/EPB to 0 in performance mode

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [cpufreq] intel_pstate: Set EPP/EPB to 0 in performance mode (Prarit Bhargava) [1465349]
Rebuild_FUZZ: 91.74%
commit-author Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
commit 8442885fca09b2d26375b9fe507759879a6f661e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/8442885f.failed

When user has selected performance policy, then set the EPP (Energy
Performance Preference) or EPB (Energy Performance Bias) to maximum
performance mode.

Also when user switch back to powersave, then restore EPP/EPB to last
EPP/EPB value before entering performance mode. If user has not changed
EPP/EPB manually then it will be power on default value.

	Signed-off-by: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
(cherry picked from commit 8442885fca09b2d26375b9fe507759879a6f661e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/intel_pstate.c
diff --cc drivers/cpufreq/intel_pstate.c
index e7b574938221,0b90a63de46d..000000000000
--- a/drivers/cpufreq/intel_pstate.c
+++ b/drivers/cpufreq/intel_pstate.c
@@@ -175,8 -244,14 +175,11 @@@ struct _pid 
   * @prev_cummulative_iowait: IO Wait time difference from last and
   *			current sample
   * @sample:		Storage for storing last Sample data
 - * @perf_limits:	Pointer to perf_limit unique to this CPU
 - *			Not all field in the structure are applicable
 - *			when per cpu controls are enforced
   * @acpi_perf_data:	Stores ACPI perf information read from _PSS
   * @valid_pss_table:	Set to true for valid ACPI _PSS entries found
+  * @epp_saved:		Last saved HWP energy performance preference
+  *			(EPP) or energy performance bias (EPB)
+  * @epp_policy:		Last saved policy used to set EPP/EPB
   *
   * This structure stores per CPU instance data for all CPUs.
   */
@@@ -199,6 -278,9 +202,12 @@@ struct cpudata 
  	struct acpi_processor_performance acpi_perf_data;
  	bool valid_pss_table;
  #endif
++<<<<<<< HEAD
++=======
+ 	unsigned int iowait_boost;
+ 	s16 epp_saved;
+ 	s16 epp_policy;
++>>>>>>> 8442885fca09 (cpufreq: intel_pstate: Set EPP/EPB to 0 in performance mode)
  };
  
  static struct cpudata **all_cpu_data;
@@@ -557,6 -627,14 +608,16 @@@ static void intel_pstate_hwp_set(const 
  	u64 value, cap;
  
  	for_each_cpu(cpu, cpumask) {
++<<<<<<< HEAD
++=======
+ 		int max_perf_pct, min_perf_pct;
+ 		struct cpudata *cpu_data = all_cpu_data[cpu];
+ 		s16 epp;
+ 
+ 		if (per_cpu_limits)
+ 			perf_limits = all_cpu_data[cpu]->perf_limits;
+ 
++>>>>>>> 8442885fca09 (cpufreq: intel_pstate: Set EPP/EPB to 0 in performance mode)
  		rdmsrl_on_cpu(cpu, MSR_HWP_CAPABILITIES, &cap);
  		hw_min = HWP_LOWEST_PERF(cap);
  		hw_max = HWP_HIGHEST_PERF(cap);
@@@ -582,6 -705,25 +685,28 @@@ skip_epp
  	}
  }
  
++<<<<<<< HEAD
++=======
+ static int intel_pstate_hwp_set_policy(struct cpufreq_policy *policy)
+ {
+ 	if (hwp_active)
+ 		intel_pstate_hwp_set(policy->cpus);
+ 
+ 	return 0;
+ }
+ 
+ static int intel_pstate_resume(struct cpufreq_policy *policy)
+ {
+ 	if (!hwp_active)
+ 		return 0;
+ 
+ 	all_cpu_data[policy->cpu]->epp_policy = 0;
+ 	all_cpu_data[policy->cpu]->epp_saved = -EINVAL;
+ 
+ 	return intel_pstate_hwp_set_policy(policy);
+ }
+ 
++>>>>>>> 8442885fca09 (cpufreq: intel_pstate: Set EPP/EPB to 0 in performance mode)
  static void intel_pstate_hwp_set_online_cpus(void)
  {
  	get_online_cpus();
@@@ -806,27 -974,10 +931,29 @@@ static void intel_pstate_hwp_enable(str
  		wrmsrl_on_cpu(cpudata->cpu, MSR_HWP_INTERRUPT, 0x00);
  
  	wrmsrl_on_cpu(cpudata->cpu, MSR_PM_ENABLE, 0x1);
+ 	cpudata->epp_policy = 0;
+ 	cpudata->epp_saved = -EINVAL;
  }
  
 +#define MSR_IA32_POWER_CTL_BIT_EE	19
 +
 +/* Disable energy efficiency optimization */
 +static void intel_pstate_disable_ee(int cpu)
 +{
 +	u64 power_ctl;
 +	int ret;
 +
 +	ret = rdmsrl_on_cpu(cpu, MSR_IA32_POWER_CTL, &power_ctl);
 +	if (ret)
 +		return;
 +
 +	if (!(power_ctl & BIT(MSR_IA32_POWER_CTL_BIT_EE))) {
 +		pr_info("Disabling energy efficiency optimization\n");
 +		power_ctl |= BIT(MSR_IA32_POWER_CTL_BIT_EE);
 +		wrmsrl_on_cpu(cpu, MSR_IA32_POWER_CTL, power_ctl);
 +	}
 +}
 +
  static int atom_get_min_pstate(void)
  {
  	u64 value;
@@@ -1535,6 -1871,7 +1662,10 @@@ static struct cpufreq_driver intel_psta
  	.flags		= CPUFREQ_CONST_LOOPS,
  	.verify		= intel_pstate_verify_policy,
  	.setpolicy	= intel_pstate_set_policy,
++<<<<<<< HEAD
++=======
+ 	.resume		= intel_pstate_resume,
++>>>>>>> 8442885fca09 (cpufreq: intel_pstate: Set EPP/EPB to 0 in performance mode)
  	.get		= intel_pstate_get,
  	.init		= intel_pstate_cpu_init,
  	.exit		= intel_pstate_cpu_exit,
* Unmerged path drivers/cpufreq/intel_pstate.c
