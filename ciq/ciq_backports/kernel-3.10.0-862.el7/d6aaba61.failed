x86/intel_rdt/cqm: Add tasks file support

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [x86] intel_rdt/cqm: Add tasks file support (Jiri Olsa) [1457533]
Rebuild_FUZZ: 94.87%
commit-author Vikas Shivappa <vikas.shivappa@linux.intel.com>
commit d6aaba615a482ce7d3ec218cf7b8d02d0d5753b8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/d6aaba61.failed

The root directory, ctrl_mon and monitor groups are populated
with a read/write file named "tasks". When read, it shows all the task
IDs assigned to the resource group.

Tasks can be added to groups by writing the PID to the file. A task can
be present in one "ctrl_mon" group "and" one "monitor" group. IOW a
PID_x can be seen in a ctrl_mon group and a monitor group at the same
time. When a task is added to a ctrl_mon group, it is automatically
removed from the previous ctrl_mon group where it belonged. Similarly if
a task is moved to a monitor group it is removed from the previous
monitor group . Also since the monitor groups can only have subset of
tasks of parent ctrl_mon group, a task can be moved to a monitor group
only if its already present in the parent ctrl_mon group.

Task membership is indicated by a new field in the task_struct "u32
rmid" which holds the RMID for the task. RMID=0 is reserved for the
default root group where the tasks belong to at mount.

[tony: zero the rmid if rdtgroup was deleted when task was being moved]

	Signed-off-by: Tony Luck <tony.luck@linux.intel.com>
	Signed-off-by: Vikas Shivappa <vikas.shivappa@linux.intel.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: ravi.v.shankar@intel.com
	Cc: tony.luck@intel.com
	Cc: fenghua.yu@intel.com
	Cc: peterz@infradead.org
	Cc: eranian@google.com
	Cc: vikas.shivappa@intel.com
	Cc: ak@linux.intel.com
	Cc: davidcc@google.com
	Cc: reinette.chatre@intel.com
Link: http://lkml.kernel.org/r/1501017287-28083-16-git-send-email-vikas.shivappa@linux.intel.com

(cherry picked from commit d6aaba615a482ce7d3ec218cf7b8d02d0d5753b8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/sched.h
diff --cc include/linux/sched.h
index 17d2f0bc1bf5,067a41ac5fd4..000000000000
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@@ -1544,73 -820,90 +1544,84 @@@ struct task_struct 
  #endif
  
  #ifdef CONFIG_DEBUG_MUTEXES
 -	/* Mutex deadlock detection: */
 -	struct mutex_waiter		*blocked_on;
 +	/* mutex deadlock detection */
 +	struct mutex_waiter *blocked_on;
  #endif
 -
  #ifdef CONFIG_TRACE_IRQFLAGS
 -	unsigned int			irq_events;
 -	unsigned long			hardirq_enable_ip;
 -	unsigned long			hardirq_disable_ip;
 -	unsigned int			hardirq_enable_event;
 -	unsigned int			hardirq_disable_event;
 -	int				hardirqs_enabled;
 -	int				hardirq_context;
 -	unsigned long			softirq_disable_ip;
 -	unsigned long			softirq_enable_ip;
 -	unsigned int			softirq_disable_event;
 -	unsigned int			softirq_enable_event;
 -	int				softirqs_enabled;
 -	int				softirq_context;
 +	unsigned int irq_events;
 +	unsigned long hardirq_enable_ip;
 +	unsigned long hardirq_disable_ip;
 +	unsigned int hardirq_enable_event;
 +	unsigned int hardirq_disable_event;
 +	int hardirqs_enabled;
 +	int hardirq_context;
 +	unsigned long softirq_disable_ip;
 +	unsigned long softirq_enable_ip;
 +	unsigned int softirq_disable_event;
 +	unsigned int softirq_enable_event;
 +	int softirqs_enabled;
 +	int softirq_context;
  #endif
 -
  #ifdef CONFIG_LOCKDEP
 -# define MAX_LOCK_DEPTH			48UL
 -	u64				curr_chain_key;
 -	int				lockdep_depth;
 -	unsigned int			lockdep_recursion;
 -	struct held_lock		held_locks[MAX_LOCK_DEPTH];
 -	gfp_t				lockdep_reclaim_gfp;
 -#endif
 -
 -#ifdef CONFIG_UBSAN
 -	unsigned int			in_ubsan;
 +# define MAX_LOCK_DEPTH 48UL
 +	u64 curr_chain_key;
 +	int lockdep_depth;
 +	unsigned int lockdep_recursion;
 +	struct held_lock held_locks[MAX_LOCK_DEPTH];
 +	gfp_t lockdep_reclaim_gfp;
  #endif
  
 -	/* Journalling filesystem info: */
 -	void				*journal_info;
 +/* journalling filesystem info */
 +	void *journal_info;
  
 -	/* Stacked block device info: */
 -	struct bio_list			*bio_list;
 +/* stacked block device info */
 +	struct bio_list *bio_list;
  
  #ifdef CONFIG_BLOCK
 -	/* Stack plugging: */
 -	struct blk_plug			*plug;
 +/* stack plugging */
 +	struct blk_plug *plug;
  #endif
  
 -	/* VM state: */
 -	struct reclaim_state		*reclaim_state;
 -
 -	struct backing_dev_info		*backing_dev_info;
 +/* VM state */
 +	struct reclaim_state *reclaim_state;
  
 -	struct io_context		*io_context;
 +	struct backing_dev_info *backing_dev_info;
  
 -	/* Ptrace state: */
 -	unsigned long			ptrace_message;
 -	siginfo_t			*last_siginfo;
 +	struct io_context *io_context;
  
 -	struct task_io_accounting	ioac;
 -#ifdef CONFIG_TASK_XACCT
 -	/* Accumulated RSS usage: */
 -	u64				acct_rss_mem1;
 -	/* Accumulated virtual memory usage: */
 -	u64				acct_vm_mem1;
 -	/* stime + utime since last update: */
 -	u64				acct_timexpd;
 +	unsigned long ptrace_message;
 +	siginfo_t *last_siginfo; /* For ptrace use.  */
 +	struct task_io_accounting ioac;
 +#if defined(CONFIG_TASK_XACCT)
 +	u64 acct_rss_mem1;	/* accumulated rss usage */
 +	u64 acct_vm_mem1;	/* accumulated virtual memory usage */
 +	cputime_t acct_timexpd;	/* stime + utime since last update */
  #endif
  #ifdef CONFIG_CPUSETS
 -	/* Protected by ->alloc_lock: */
 -	nodemask_t			mems_allowed;
 -	/* Seqence number to catch updates: */
 -	seqcount_t			mems_allowed_seq;
 -	int				cpuset_mem_spread_rotor;
 -	int				cpuset_slab_spread_rotor;
 +	nodemask_t mems_allowed;	/* Protected by alloc_lock */
 +	seqcount_t mems_allowed_seq;	/* Seqence no to catch updates */
 +	int cpuset_mem_spread_rotor;
 +	int cpuset_slab_spread_rotor;
  #endif
  #ifdef CONFIG_CGROUPS
++<<<<<<< HEAD
 +	/* Control Group info protected by css_set_lock */
 +	struct css_set __rcu *cgroups;
 +	/* cg_list protected by css_set_lock and tsk->alloc_lock */
 +	struct list_head cg_list;
++=======
+ 	/* Control Group info protected by css_set_lock: */
+ 	struct css_set __rcu		*cgroups;
+ 	/* cg_list protected by css_set_lock and tsk->alloc_lock: */
+ 	struct list_head		cg_list;
+ #endif
+ #ifdef CONFIG_INTEL_RDT
+ 	u32				closid;
+ 	u32				rmid;
++>>>>>>> d6aaba615a48 (x86/intel_rdt/cqm: Add tasks file support)
  #endif
  #ifdef CONFIG_FUTEX
 -	struct robust_list_head __user	*robust_list;
 +	struct robust_list_head __user *robust_list;
  #ifdef CONFIG_COMPAT
  	struct compat_robust_list_head __user *compat_robust_list;
  #endif
diff --git a/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c b/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c
index 1c3603d97e9d..dd588cc8e0e3 100644
--- a/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c
+++ b/arch/x86/kernel/cpu/intel_rdt_rdtgroup.c
@@ -335,6 +335,7 @@ static void move_myself(struct callback_head *head)
 	if (atomic_dec_and_test(&rdtgrp->waitcount) &&
 	    (rdtgrp->flags & RDT_DELETED)) {
 		current->closid = 0;
+		current->rmid = 0;
 		kfree(rdtgrp);
 	}
 
@@ -373,7 +374,20 @@ static int __rdtgroup_move_task(struct task_struct *tsk,
 		atomic_dec(&rdtgrp->waitcount);
 		kfree(callback);
 	} else {
-		tsk->closid = rdtgrp->closid;
+		/*
+		 * For ctrl_mon groups move both closid and rmid.
+		 * For monitor groups, can move the tasks only from
+		 * their parent CTRL group.
+		 */
+		if (rdtgrp->type == RDTCTRL_GROUP) {
+			tsk->closid = rdtgrp->closid;
+			tsk->rmid = rdtgrp->mon.rmid;
+		} else if (rdtgrp->type == RDTMON_GROUP) {
+			if (rdtgrp->mon.parent->closid == tsk->closid)
+				tsk->rmid = rdtgrp->mon.rmid;
+			else
+				ret = -EINVAL;
+		}
 	}
 	return ret;
 }
@@ -453,7 +467,8 @@ static void show_rdt_tasks(struct rdtgroup *r, struct seq_file *s)
 
 	rcu_read_lock();
 	for_each_process_thread(p, t) {
-		if (t->closid == r->closid)
+		if ((r->type == RDTCTRL_GROUP && t->closid == r->closid) ||
+		    (r->type == RDTMON_GROUP && t->rmid == r->mon.rmid))
 			seq_printf(s, "%d\n", t->pid);
 	}
 	rcu_read_unlock();
* Unmerged path include/linux/sched.h
