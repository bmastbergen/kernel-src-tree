genirq: Introduce IRQD_AFFINITY_MANAGED flag

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 9c2555835bb3d34dfac52a0be943dcc4bedd650f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/9c255583.failed

Interupts marked with this flag are excluded from user space interrupt
affinity changes. Contrary to the IRQ_NO_BALANCING flag, the kernel internal
affinity mechanism is not blocked.

This flag will be used for multi-queue device interrupts.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: Christoph Hellwig <hch@lst.de>
	Cc: linux-block@vger.kernel.org
	Cc: linux-pci@vger.kernel.org
	Cc: linux-nvme@lists.infradead.org
	Cc: axboe@fb.com
	Cc: agordeev@redhat.com
Link: http://lkml.kernel.org/r/1467621574-8277-3-git-send-email-hch@lst.de
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

(cherry picked from commit 9c2555835bb3d34dfac52a0be943dcc4bedd650f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/irq.h
diff --cc include/linux/irq.h
index bc8b8f8d4560,f6074813688d..000000000000
--- a/include/linux/irq.h
+++ b/include/linux/irq.h
@@@ -166,6 -195,9 +166,12 @@@ struct irq_data 
   * IRQD_IRQ_DISABLED		- Disabled state of the interrupt
   * IRQD_IRQ_MASKED		- Masked state of the interrupt
   * IRQD_IRQ_INPROGRESS		- In progress state of the interrupt
++<<<<<<< HEAD
++=======
+  * IRQD_WAKEUP_ARMED		- Wakeup mode armed
+  * IRQD_FORWARDED_TO_VCPU	- The interrupt is forwarded to a VCPU
+  * IRQD_AFFINITY_MANAGED	- Affinity is auto-managed by the kernel
++>>>>>>> 9c2555835bb3 (genirq: Introduce IRQD_AFFINITY_MANAGED flag)
   */
  enum {
  	IRQD_TRIGGER_MASK		= 0xf,
@@@ -179,11 -211,16 +185,17 @@@
  	IRQD_IRQ_DISABLED		= (1 << 16),
  	IRQD_IRQ_MASKED			= (1 << 17),
  	IRQD_IRQ_INPROGRESS		= (1 << 18),
++<<<<<<< HEAD
++=======
+ 	IRQD_WAKEUP_ARMED		= (1 << 19),
+ 	IRQD_FORWARDED_TO_VCPU		= (1 << 20),
+ 	IRQD_AFFINITY_MANAGED		= (1 << 21),
++>>>>>>> 9c2555835bb3 (genirq: Introduce IRQD_AFFINITY_MANAGED flag)
  };
  
 -#define __irqd_to_state(d) ACCESS_PRIVATE((d)->common, state_use_accessors)
 -
  static inline bool irqd_is_setaffinity_pending(struct irq_data *d)
  {
 -	return __irqd_to_state(d) & IRQD_SETAFFINITY_PENDING;
 +	return d->state_use_accessors & IRQD_SETAFFINITY_PENDING;
  }
  
  static inline bool irqd_is_per_cpu(struct irq_data *d)
@@@ -247,24 -284,36 +259,44 @@@ static inline bool irqd_irq_masked(stru
  
  static inline bool irqd_irq_inprogress(struct irq_data *d)
  {
 -	return __irqd_to_state(d) & IRQD_IRQ_INPROGRESS;
 +	return d->state_use_accessors & IRQD_IRQ_INPROGRESS;
  }
  
 -static inline bool irqd_is_wakeup_armed(struct irq_data *d)
 +/*
 + * Functions for chained handlers which can be enabled/disabled by the
 + * standard disable_irq/enable_irq calls. Must be called with
 + * irq_desc->lock held.
 + */
 +static inline void irqd_set_chained_irq_inprogress(struct irq_data *d)
  {
 -	return __irqd_to_state(d) & IRQD_WAKEUP_ARMED;
 +	d->state_use_accessors |= IRQD_IRQ_INPROGRESS;
  }
  
 -static inline bool irqd_is_forwarded_to_vcpu(struct irq_data *d)
 +static inline void irqd_clr_chained_irq_inprogress(struct irq_data *d)
  {
 -	return __irqd_to_state(d) & IRQD_FORWARDED_TO_VCPU;
 +	d->state_use_accessors &= ~IRQD_IRQ_INPROGRESS;
  }
  
++<<<<<<< HEAD
++=======
+ static inline void irqd_set_forwarded_to_vcpu(struct irq_data *d)
+ {
+ 	__irqd_to_state(d) |= IRQD_FORWARDED_TO_VCPU;
+ }
+ 
+ static inline void irqd_clr_forwarded_to_vcpu(struct irq_data *d)
+ {
+ 	__irqd_to_state(d) &= ~IRQD_FORWARDED_TO_VCPU;
+ }
+ 
+ static inline bool irqd_affinity_is_managed(struct irq_data *d)
+ {
+ 	return __irqd_to_state(d) & IRQD_AFFINITY_MANAGED;
+ }
+ 
+ #undef __irqd_to_state
+ 
++>>>>>>> 9c2555835bb3 (genirq: Introduce IRQD_AFFINITY_MANAGED flag)
  static inline irq_hw_number_t irqd_to_hwirq(struct irq_data *d)
  {
  	return d->hwirq;
* Unmerged path include/linux/irq.h
diff --git a/kernel/irq/internals.h b/kernel/irq/internals.h
index f77bee90c467..4ba6bbb36d4d 100644
--- a/kernel/irq/internals.h
+++ b/kernel/irq/internals.h
@@ -98,6 +98,8 @@ static inline void unregister_handler_proc(unsigned int irq,
 					   struct irqaction *action) { }
 #endif
 
+extern bool irq_can_set_affinity_usr(unsigned int irq);
+
 extern int irq_select_affinity_usr(unsigned int irq, struct cpumask *mask);
 
 extern void irq_set_thread_affinity(struct irq_desc *desc);
diff --git a/kernel/irq/manage.c b/kernel/irq/manage.c
index 039e1265e89e..345d51898574 100644
--- a/kernel/irq/manage.c
+++ b/kernel/irq/manage.c
@@ -109,12 +109,12 @@ EXPORT_SYMBOL(synchronize_irq);
 #ifdef CONFIG_SMP
 cpumask_var_t irq_default_affinity;
 
-static int __irq_can_set_affinity(struct irq_desc *desc)
+static bool __irq_can_set_affinity(struct irq_desc *desc)
 {
 	if (!desc || !irqd_can_balance(&desc->irq_data) ||
 	    !desc->irq_data.chip || !desc->irq_data.chip->irq_set_affinity)
-		return 0;
-	return 1;
+		return false;
+	return true;
 }
 
 /**
@@ -127,6 +127,21 @@ int irq_can_set_affinity(unsigned int irq)
 	return __irq_can_set_affinity(irq_to_desc(irq));
 }
 
+/**
+ * irq_can_set_affinity_usr - Check if affinity of a irq can be set from user space
+ * @irq:	Interrupt to check
+ *
+ * Like irq_can_set_affinity() above, but additionally checks for the
+ * AFFINITY_MANAGED flag.
+ */
+bool irq_can_set_affinity_usr(unsigned int irq)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+
+	return __irq_can_set_affinity(desc) &&
+		!irqd_affinity_is_managed(&desc->irq_data);
+}
+
 /**
  *	irq_set_thread_affinity - Notify irq threads to adjust affinity
  *	@desc:		irq descriptor which has affitnity changed
diff --git a/kernel/irq/proc.c b/kernel/irq/proc.c
index 19ed5c425c3b..5490c47fa4b5 100644
--- a/kernel/irq/proc.c
+++ b/kernel/irq/proc.c
@@ -80,7 +80,7 @@ static ssize_t write_irq_affinity(int type, struct file *file,
 	cpumask_var_t new_value;
 	int err;
 
-	if (!irq_can_set_affinity(irq) || no_irq_affinity)
+	if (!irq_can_set_affinity_usr(irq) || no_irq_affinity)
 		return -EIO;
 
 	if (!alloc_cpumask_var(&new_value, GFP_KERNEL))
