dma-mapping: cosolidate dma_mapping_error

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Christoph Hellwig <hch@lst.de>
commit efa21e432c7b3c8ae976039d614a017799b6e874
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/efa21e43.failed

Currently there are three valid implementations of dma_mapping_error:

 (1) call ->mapping_error
 (2) check for a hardcoded error code
 (3) always return 0

This patch provides a common implementation that calls ->mapping_error
if present, then checks for DMA_ERROR_CODE if defined or otherwise
returns 0.

[jcmvbkbc@gmail.com: fix xtensa]
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Cc: Arnd Bergmann <arnd@arndb.de>
	Cc: Russell King <linux@arm.linux.org.uk>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Will Deacon <will.deacon@arm.com>
	Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
	Cc: Michal Simek <monstr@monstr.eu>
	Cc: Jonas Bonn <jonas@southpole.se>
	Cc: Chris Metcalf <cmetcalf@ezchip.com>
	Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
	Cc: Ralf Baechle <ralf@linux-mips.org>
	Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
	Cc: Ingo Molnar <mingo@elte.hu>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Andy Shevchenko <andy.shevchenko@gmail.com>
	Signed-off-by: Max Filippov <jcmvbkbc@gmail.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit efa21e432c7b3c8ae976039d614a017799b6e874)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/alpha/include/asm/dma-mapping.h
#	arch/arm/include/asm/dma-mapping.h
#	arch/h8300/include/asm/dma-mapping.h
#	arch/hexagon/include/asm/dma-mapping.h
#	arch/microblaze/include/asm/dma-mapping.h
#	arch/powerpc/include/asm/dma-mapping.h
#	arch/s390/include/asm/dma-mapping.h
#	arch/sh/include/asm/dma-mapping.h
#	arch/sparc/include/asm/dma-mapping.h
#	arch/x86/include/asm/dma-mapping.h
#	arch/xtensa/include/asm/dma-mapping.h
#	include/asm-generic/dma-mapping-common.h
diff --cc arch/alpha/include/asm/dma-mapping.h
index dfa32f061320,80ac3e835efe..000000000000
--- a/arch/alpha/include/asm/dma-mapping.h
+++ b/arch/alpha/include/asm/dma-mapping.h
@@@ -12,29 -12,6 +12,32 @@@ static inline struct dma_map_ops *get_d
  
  #include <asm-generic/dma-mapping-common.h>
  
++<<<<<<< HEAD
 +#define dma_alloc_coherent(d,s,h,f)	dma_alloc_attrs(d,s,h,f,NULL)
 +
 +static inline void *dma_alloc_attrs(struct device *dev, size_t size,
 +				    dma_addr_t *dma_handle, gfp_t gfp,
 +				    struct dma_attrs *attrs)
 +{
 +	return get_dma_ops(dev)->alloc(dev, size, dma_handle, gfp, attrs);
 +}
 +
 +#define dma_free_coherent(d,s,c,h) dma_free_attrs(d,s,c,h,NULL)
 +
 +static inline void dma_free_attrs(struct device *dev, size_t size,
 +				  void *vaddr, dma_addr_t dma_handle,
 +				  struct dma_attrs *attrs)
 +{
 +	get_dma_ops(dev)->free(dev, size, vaddr, dma_handle, attrs);
 +}
 +
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	return get_dma_ops(dev)->mapping_error(dev, dma_addr);
 +}
 +
++=======
++>>>>>>> efa21e432c7b (dma-mapping: cosolidate dma_mapping_error)
  static inline int dma_supported(struct device *dev, u64 mask)
  {
  	return get_dma_ops(dev)->dma_supported(dev, mask);
diff --cc arch/arm/include/asm/dma-mapping.h
index 5b579b951503,9bef3c541c39..000000000000
--- a/arch/arm/include/asm/dma-mapping.h
+++ b/arch/arm/include/asm/dma-mapping.h
@@@ -86,30 -119,59 +86,86 @@@ static inline dma_addr_t virt_to_dma(st
  }
  #endif
  
++<<<<<<< HEAD
 +/*
 + * DMA errors are defined by all-bits-set in the DMA address.
 + */
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	debug_dma_mapping_error(dev, dma_addr);
 +	return dma_addr == DMA_ERROR_CODE;
 +}
 +
 +/*
 + * Dummy noncoherent implementation.  We don't provide a dma_cache_sync
 + * function so drivers using this API are highlighted with build warnings.
 + */
 +static inline void *dma_alloc_noncoherent(struct device *dev, size_t size,
 +		dma_addr_t *handle, gfp_t gfp)
 +{
 +	return NULL;
 +}
 +
 +static inline void dma_free_noncoherent(struct device *dev, size_t size,
 +		void *cpu_addr, dma_addr_t handle)
 +{
 +}
 +
++=======
+ /* The ARM override for dma_max_pfn() */
+ static inline unsigned long dma_max_pfn(struct device *dev)
+ {
+ 	return PHYS_PFN_OFFSET + dma_to_pfn(dev, *dev->dma_mask);
+ }
+ #define dma_max_pfn(dev) dma_max_pfn(dev)
+ 
+ #define arch_setup_dma_ops arch_setup_dma_ops
+ extern void arch_setup_dma_ops(struct device *dev, u64 dma_base, u64 size,
+ 			       struct iommu_ops *iommu, bool coherent);
+ 
+ #define arch_teardown_dma_ops arch_teardown_dma_ops
+ extern void arch_teardown_dma_ops(struct device *dev);
+ 
+ /* do not use this function in a driver */
+ static inline bool is_device_dma_coherent(struct device *dev)
+ {
+ 	return dev->archdata.dma_coherent;
+ }
+ 
+ static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)
+ {
+ 	unsigned int offset = paddr & ~PAGE_MASK;
+ 	return pfn_to_dma(dev, __phys_to_pfn(paddr)) + offset;
+ }
+ 
+ static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t dev_addr)
+ {
+ 	unsigned int offset = dev_addr & ~PAGE_MASK;
+ 	return __pfn_to_phys(dma_to_pfn(dev, dev_addr)) + offset;
+ }
+ 
+ static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)
+ {
+ 	u64 limit, mask;
+ 
+ 	if (!dev->dma_mask)
+ 		return 0;
+ 
+ 	mask = *dev->dma_mask;
+ 
+ 	limit = (mask + 1) & ~mask;
+ 	if (limit && size > limit)
+ 		return 0;
+ 
+ 	if ((addr | (addr + size - 1)) & ~mask)
+ 		return 0;
+ 
+ 	return 1;
+ }
+ 
+ static inline void dma_mark_clean(void *addr, size_t size) { }
+ 
++>>>>>>> efa21e432c7b (dma-mapping: cosolidate dma_mapping_error)
  extern int dma_supported(struct device *dev, u64 mask);
  
  extern int arm_dma_set_mask(struct device *dev, u64 dma_mask);
diff --cc arch/hexagon/include/asm/dma-mapping.h
index 85e9935660cb,e66119290eca..000000000000
--- a/arch/hexagon/include/asm/dma-mapping.h
+++ b/arch/hexagon/include/asm/dma-mapping.h
@@@ -61,47 -58,4 +62,50 @@@ static inline bool dma_capable(struct d
  	return addr + size - 1 <= *dev->dma_mask;
  }
  
++<<<<<<< HEAD
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	struct dma_map_ops *dma_ops = get_dma_ops(dev);
 +
 +	if (dma_ops->mapping_error)
 +		return dma_ops->mapping_error(dev, dma_addr);
 +
 +	return (dma_addr == bad_dma_address);
 +}
 +
 +#define dma_alloc_coherent(d,s,h,f)	dma_alloc_attrs(d,s,h,f,NULL)
 +
 +static inline void *dma_alloc_attrs(struct device *dev, size_t size,
 +				    dma_addr_t *dma_handle, gfp_t flag,
 +				    struct dma_attrs *attrs)
 +{
 +	void *ret;
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +
 +	BUG_ON(!dma_ops);
 +
 +	ret = ops->alloc(dev, size, dma_handle, flag, attrs);
 +
 +	debug_dma_alloc_coherent(dev, size, *dma_handle, ret);
 +
 +	return ret;
 +}
 +
 +#define dma_free_coherent(d,s,c,h) dma_free_attrs(d,s,c,h,NULL)
 +
 +static inline void dma_free_attrs(struct device *dev, size_t size,
 +				  void *cpu_addr, dma_addr_t dma_handle,
 +				  struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *dma_ops = get_dma_ops(dev);
 +
 +	BUG_ON(!dma_ops);
 +
 +	dma_ops->free(dev, size, cpu_addr, dma_handle, attrs);
 +
 +	debug_dma_free_coherent(dev, size, cpu_addr, dma_handle);
 +}
 +
++=======
++>>>>>>> efa21e432c7b (dma-mapping: cosolidate dma_mapping_error)
  #endif
diff --cc arch/microblaze/include/asm/dma-mapping.h
index 46460f1c49c4,e5b843839263..000000000000
--- a/arch/microblaze/include/asm/dma-mapping.h
+++ b/arch/microblaze/include/asm/dma-mapping.h
@@@ -111,50 -87,6 +111,53 @@@ static inline void __dma_sync(unsigned 
  	}
  }
  
++<<<<<<< HEAD
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +
 +	debug_dma_mapping_error(dev, dma_addr);
 +	if (ops->mapping_error)
 +		return ops->mapping_error(dev, dma_addr);
 +
 +	return (dma_addr == DMA_ERROR_CODE);
 +}
 +
 +#define dma_alloc_noncoherent(d, s, h, f) dma_alloc_coherent(d, s, h, f)
 +#define dma_free_noncoherent(d, s, v, h) dma_free_coherent(d, s, v, h)
 +
 +#define dma_alloc_coherent(d, s, h, f) dma_alloc_attrs(d, s, h, f, NULL)
 +
 +static inline void *dma_alloc_attrs(struct device *dev, size_t size,
 +				    dma_addr_t *dma_handle, gfp_t flag,
 +				    struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +	void *memory;
 +
 +	BUG_ON(!ops);
 +
 +	memory = ops->alloc(dev, size, dma_handle, flag, attrs);
 +
 +	debug_dma_alloc_coherent(dev, size, *dma_handle, memory);
 +	return memory;
 +}
 +
 +#define dma_free_coherent(d,s,c,h) dma_free_attrs(d, s, c, h, NULL)
 +
 +static inline void dma_free_attrs(struct device *dev, size_t size,
 +				  void *cpu_addr, dma_addr_t dma_handle,
 +				  struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +
 +	BUG_ON(!ops);
 +	debug_dma_free_coherent(dev, size, cpu_addr, dma_handle);
 +	ops->free(dev, size, cpu_addr, dma_handle, attrs);
 +}
 +
++=======
++>>>>>>> efa21e432c7b (dma-mapping: cosolidate dma_mapping_error)
  static inline void dma_cache_sync(struct device *dev, void *vaddr, size_t size,
  		enum dma_data_direction direction)
  {
diff --cc arch/powerpc/include/asm/dma-mapping.h
index c6f39b7c9f40,712d5afc055a..000000000000
--- a/arch/powerpc/include/asm/dma-mapping.h
+++ b/arch/powerpc/include/asm/dma-mapping.h
@@@ -137,54 -139,6 +139,57 @@@ extern int dma_set_mask(struct device *
  extern int __dma_set_mask(struct device *dev, u64 dma_mask);
  extern u64 __dma_get_required_mask(struct device *dev);
  
++<<<<<<< HEAD
 +#define dma_alloc_coherent(d,s,h,f)	dma_alloc_attrs(d,s,h,f,NULL)
 +
 +static inline void *dma_alloc_attrs(struct device *dev, size_t size,
 +				    dma_addr_t *dma_handle, gfp_t flag,
 +				    struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *dma_ops = get_dma_ops(dev);
 +	void *cpu_addr;
 +
 +	BUG_ON(!dma_ops);
 +
 +	cpu_addr = dma_ops->alloc(dev, size, dma_handle, flag, attrs);
 +
 +	debug_dma_alloc_coherent(dev, size, *dma_handle, cpu_addr);
 +
 +	return cpu_addr;
 +}
 +
 +#define dma_free_coherent(d,s,c,h) dma_free_attrs(d,s,c,h,NULL)
 +
 +static inline void dma_free_attrs(struct device *dev, size_t size,
 +				  void *cpu_addr, dma_addr_t dma_handle,
 +				  struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *dma_ops = get_dma_ops(dev);
 +
 +	BUG_ON(!dma_ops);
 +
 +	debug_dma_free_coherent(dev, size, cpu_addr, dma_handle);
 +
 +	dma_ops->free(dev, size, cpu_addr, dma_handle, attrs);
 +}
 +
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	struct dma_map_ops *dma_ops = get_dma_ops(dev);
 +
 +	debug_dma_mapping_error(dev, dma_addr);
 +	if (dma_ops->mapping_error)
 +		return dma_ops->mapping_error(dev, dma_addr);
 +
 +#ifdef CONFIG_PPC64
 +	return (dma_addr == DMA_ERROR_CODE);
 +#else
 +	return 0;
 +#endif
 +}
 +
++=======
++>>>>>>> efa21e432c7b (dma-mapping: cosolidate dma_mapping_error)
  static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)
  {
  #ifdef CONFIG_SWIOTLB
diff --cc arch/s390/include/asm/dma-mapping.h
index 3f2d5669375a,3c293291319b..000000000000
--- a/arch/s390/include/asm/dma-mapping.h
+++ b/arch/s390/include/asm/dma-mapping.h
@@@ -48,45 -43,4 +48,48 @@@ static inline bool dma_capable(struct d
  	return addr + size - 1 <= *dev->dma_mask;
  }
  
++<<<<<<< HEAD
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	struct dma_map_ops *dma_ops = get_dma_ops(dev);
 +
 +	debug_dma_mapping_error(dev, dma_addr);
 +	if (dma_ops->mapping_error)
 +		return dma_ops->mapping_error(dev, dma_addr);
 +	return dma_addr == DMA_ERROR_CODE;
 +}
 +
 +#define dma_alloc_coherent(d, s, h, f) dma_alloc_attrs(d, s, h, f, NULL)
 +
 +static inline void *dma_alloc_attrs(struct device *dev, size_t size,
 +				    dma_addr_t *dma_handle, gfp_t flags,
 +				    struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +	void *cpu_addr;
 +
 +	BUG_ON(!ops);
 +
 +	cpu_addr = ops->alloc(dev, size, dma_handle, flags, attrs);
 +	debug_dma_alloc_coherent(dev, size, *dma_handle, cpu_addr);
 +
 +	return cpu_addr;
 +}
 +
 +#define dma_free_coherent(d, s, c, h) dma_free_attrs(d, s, c, h, NULL)
 +
 +static inline void dma_free_attrs(struct device *dev, size_t size,
 +				  void *cpu_addr, dma_addr_t dma_handle,
 +				  struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +
 +	BUG_ON(!ops);
 +
 +	debug_dma_free_coherent(dev, size, cpu_addr, dma_handle);
 +	ops->free(dev, size, cpu_addr, dma_handle, attrs);
 +}
 +
++=======
++>>>>>>> efa21e432c7b (dma-mapping: cosolidate dma_mapping_error)
  #endif /* _ASM_S390_DMA_MAPPING_H */
diff --cc arch/sh/include/asm/dma-mapping.h
index b437f2c780b8,98308c497162..000000000000
--- a/arch/sh/include/asm/dma-mapping.h
+++ b/arch/sh/include/asm/dma-mapping.h
@@@ -9,7 -9,8 +9,12 @@@ static inline struct dma_map_ops *get_d
  	return dma_ops;
  }
  
++<<<<<<< HEAD
 +#include <asm-generic/dma-coherent.h>
++=======
+ #define DMA_ERROR_CODE 0
+ 
++>>>>>>> efa21e432c7b (dma-mapping: cosolidate dma_mapping_error)
  #include <asm-generic/dma-mapping-common.h>
  
  static inline int dma_supported(struct device *dev, u64 mask)
@@@ -39,56 -40,6 +44,59 @@@ static inline int dma_set_mask(struct d
  void dma_cache_sync(struct device *dev, void *vaddr, size_t size,
  		    enum dma_data_direction dir);
  
++<<<<<<< HEAD
 +#define dma_alloc_noncoherent(d, s, h, f) dma_alloc_coherent(d, s, h, f)
 +#define dma_free_noncoherent(d, s, v, h) dma_free_coherent(d, s, v, h)
 +
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +
 +	debug_dma_mapping_error(dev, dma_addr);
 +	if (ops->mapping_error)
 +		return ops->mapping_error(dev, dma_addr);
 +
 +	return dma_addr == 0;
 +}
 +
 +#define dma_alloc_coherent(d,s,h,f)	dma_alloc_attrs(d,s,h,f,NULL)
 +
 +static inline void *dma_alloc_attrs(struct device *dev, size_t size,
 +				    dma_addr_t *dma_handle, gfp_t gfp,
 +				    struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +	void *memory;
 +
 +	if (dma_alloc_from_coherent(dev, size, dma_handle, &memory))
 +		return memory;
 +	if (!ops->alloc)
 +		return NULL;
 +
 +	memory = ops->alloc(dev, size, dma_handle, gfp, attrs);
 +	debug_dma_alloc_coherent(dev, size, *dma_handle, memory);
 +
 +	return memory;
 +}
 +
 +#define dma_free_coherent(d,s,c,h) dma_free_attrs(d,s,c,h,NULL)
 +
 +static inline void dma_free_attrs(struct device *dev, size_t size,
 +				  void *vaddr, dma_addr_t dma_handle,
 +				  struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +
 +	if (dma_release_from_coherent(dev, get_order(size), vaddr))
 +		return;
 +
 +	debug_dma_free_coherent(dev, size, vaddr, dma_handle);
 +	if (ops->free)
 +		ops->free(dev, size, vaddr, dma_handle, attrs);
 +}
 +
++=======
++>>>>>>> efa21e432c7b (dma-mapping: cosolidate dma_mapping_error)
  /* arch/sh/mm/consistent.c */
  extern void *dma_generic_alloc_coherent(struct device *dev, size_t size,
  					dma_addr_t *dma_addr, gfp_t flag,
diff --cc arch/sparc/include/asm/dma-mapping.h
index 05fe53f5346e,5069d137453b..000000000000
--- a/arch/sparc/include/asm/dma-mapping.h
+++ b/arch/sparc/include/asm/dma-mapping.h
@@@ -31,38 -38,6 +31,41 @@@ static inline struct dma_map_ops *get_d
  
  #include <asm-generic/dma-mapping-common.h>
  
++<<<<<<< HEAD
 +#define dma_alloc_coherent(d,s,h,f)	dma_alloc_attrs(d,s,h,f,NULL)
 +
 +static inline void *dma_alloc_attrs(struct device *dev, size_t size,
 +				    dma_addr_t *dma_handle, gfp_t flag,
 +				    struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +	void *cpu_addr;
 +
 +	cpu_addr = ops->alloc(dev, size, dma_handle, flag, attrs);
 +	debug_dma_alloc_coherent(dev, size, *dma_handle, cpu_addr);
 +	return cpu_addr;
 +}
 +
 +#define dma_free_coherent(d,s,c,h) dma_free_attrs(d,s,c,h,NULL)
 +
 +static inline void dma_free_attrs(struct device *dev, size_t size,
 +				  void *cpu_addr, dma_addr_t dma_handle,
 +				  struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +
 +	debug_dma_free_coherent(dev, size, cpu_addr, dma_handle);
 +	ops->free(dev, size, cpu_addr, dma_handle, attrs);
 +}
 +
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	debug_dma_mapping_error(dev, dma_addr);
 +	return (dma_addr == DMA_ERROR_CODE);
 +}
 +
++=======
++>>>>>>> efa21e432c7b (dma-mapping: cosolidate dma_mapping_error)
  static inline int dma_set_mask(struct device *dev, u64 mask)
  {
  #ifdef CONFIG_PCI
diff --cc arch/x86/include/asm/dma-mapping.h
index 1f5b7287d1ad,bbca62e3e43f..000000000000
--- a/arch/x86/include/asm/dma-mapping.h
+++ b/arch/x86/include/asm/dma-mapping.h
@@@ -41,22 -40,11 +41,25 @@@ static inline struct dma_map_ops *get_d
  #endif
  }
  
 -bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp);
 -#define arch_dma_alloc_attrs arch_dma_alloc_attrs
 -
  #include <asm-generic/dma-mapping-common.h>
  
++<<<<<<< HEAD
 +/* Make sure we keep the same behaviour */
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +	debug_dma_mapping_error(dev, dma_addr);
 +	if (ops->mapping_error)
 +		return ops->mapping_error(dev, dma_addr);
 +
 +	return (dma_addr == DMA_ERROR_CODE);
 +}
 +
 +#define dma_alloc_noncoherent(d, s, h, f) dma_alloc_coherent(d, s, h, f)
 +#define dma_free_noncoherent(d, s, v, h) dma_free_coherent(d, s, v, h)
 +
++=======
++>>>>>>> efa21e432c7b (dma-mapping: cosolidate dma_mapping_error)
  extern int dma_supported(struct device *hwdev, u64 mask);
  extern int dma_set_mask(struct device *dev, u64 mask);
  
diff --cc arch/xtensa/include/asm/dma-mapping.h
index 172a02a6ad14,21925bfdaff7..000000000000
--- a/arch/xtensa/include/asm/dma-mapping.h
+++ b/arch/xtensa/include/asm/dma-mapping.h
@@@ -18,135 -20,19 +18,138 @@@
  
  #define DMA_ERROR_CODE		(~(dma_addr_t)0x0)
  
 -extern struct dma_map_ops xtensa_dma_map_ops;
 +/*
 + * DMA-consistent mapping functions.
 + */
 +
 +extern void *consistent_alloc(int, size_t, dma_addr_t, unsigned long);
 +extern void consistent_free(void*, size_t, dma_addr_t);
 +extern void consistent_sync(void*, size_t, int);
 +
 +#define dma_alloc_noncoherent(d, s, h, f) dma_alloc_coherent(d, s, h, f)
 +#define dma_free_noncoherent(d, s, v, h) dma_free_coherent(d, s, v, h)
 +
 +void *dma_alloc_coherent(struct device *dev, size_t size,
 +			   dma_addr_t *dma_handle, gfp_t flag);
 +
 +void dma_free_coherent(struct device *dev, size_t size,
 +			 void *vaddr, dma_addr_t dma_handle);
 +
 +static inline dma_addr_t
 +dma_map_single(struct device *dev, void *ptr, size_t size,
 +	       enum dma_data_direction direction)
 +{
 +	BUG_ON(direction == DMA_NONE);
 +	consistent_sync(ptr, size, direction);
 +	return virt_to_phys(ptr);
 +}
 +
 +static inline void
 +dma_unmap_single(struct device *dev, dma_addr_t dma_addr, size_t size,
 +		 enum dma_data_direction direction)
 +{
 +	BUG_ON(direction == DMA_NONE);
 +}
 +
 +static inline int
++<<<<<<< HEAD
 +dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,
 +	   enum dma_data_direction direction)
 +{
 +	int i;
 +
 +	BUG_ON(direction == DMA_NONE);
 +
 +	for (i = 0; i < nents; i++, sg++ ) {
 +		BUG_ON(!sg_page(sg));
 +
 +		sg->dma_address = sg_phys(sg);
 +		consistent_sync(sg_virt(sg), sg->length, direction);
 +	}
 +
 +	return nents;
 +}
 +
 +static inline dma_addr_t
 +dma_map_page(struct device *dev, struct page *page, unsigned long offset,
 +	     size_t size, enum dma_data_direction direction)
 +{
 +	BUG_ON(direction == DMA_NONE);
 +	return (dma_addr_t)(page_to_pfn(page)) * PAGE_SIZE + offset;
 +}
 +
 +static inline void
 +dma_unmap_page(struct device *dev, dma_addr_t dma_address, size_t size,
 +	       enum dma_data_direction direction)
 +{
 +	BUG_ON(direction == DMA_NONE);
 +}
 +
  
 -static inline struct dma_map_ops *get_dma_ops(struct device *dev)
 +static inline void
 +dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nhwentries,
 +	     enum dma_data_direction direction)
  {
 -	if (dev && dev->archdata.dma_ops)
 -		return dev->archdata.dma_ops;
 -	else
 -		return &xtensa_dma_map_ops;
 +	BUG_ON(direction == DMA_NONE);
  }
  
 -#include <asm-generic/dma-mapping-common.h>
 +static inline void
 +dma_sync_single_for_cpu(struct device *dev, dma_addr_t dma_handle, size_t size,
 +		enum dma_data_direction direction)
 +{
 +	consistent_sync((void *)bus_to_virt(dma_handle), size, direction);
 +}
 +
 +static inline void
 +dma_sync_single_for_device(struct device *dev, dma_addr_t dma_handle,
 +		           size_t size, enum dma_data_direction direction)
 +{
 +	consistent_sync((void *)bus_to_virt(dma_handle), size, direction);
 +}
 +
 +static inline void
 +dma_sync_single_range_for_cpu(struct device *dev, dma_addr_t dma_handle,
 +		      unsigned long offset, size_t size,
 +		      enum dma_data_direction direction)
 +{
 +
 +	consistent_sync((void *)bus_to_virt(dma_handle)+offset,size,direction);
 +}
 +
 +static inline void
 +dma_sync_single_range_for_device(struct device *dev, dma_addr_t dma_handle,
 +		      unsigned long offset, size_t size,
 +		      enum dma_data_direction direction)
 +{
 +
 +	consistent_sync((void *)bus_to_virt(dma_handle)+offset,size,direction);
 +}
 +static inline void
 +dma_sync_sg_for_cpu(struct device *dev, struct scatterlist *sg, int nelems,
 +		 enum dma_data_direction dir)
 +{
 +	int i;
 +	for (i = 0; i < nelems; i++, sg++)
 +		consistent_sync(sg_virt(sg), sg->length, dir);
 +}
 +
 +static inline void
 +dma_sync_sg_for_device(struct device *dev, struct scatterlist *sg, int nelems,
 +		 enum dma_data_direction dir)
 +{
 +	int i;
 +	for (i = 0; i < nelems; i++, sg++)
 +		consistent_sync(sg_virt(sg), sg->length, dir);
 +}
 +static inline int
 +dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	return 0;
 +}
  
  static inline int
++=======
++>>>>>>> efa21e432c7b (dma-mapping: cosolidate dma_mapping_error)
  dma_supported(struct device *dev, u64 mask)
  {
  	return 1;
diff --cc include/asm-generic/dma-mapping-common.h
index de8bf89940f8,cdaa24193d4c..000000000000
--- a/include/asm-generic/dma-mapping-common.h
+++ b/include/asm-generic/dma-mapping-common.h
@@@ -231,4 -238,93 +231,96 @@@ dma_get_sgtable_attrs(struct device *de
  
  #define dma_get_sgtable(d, t, v, h, s) dma_get_sgtable_attrs(d, t, v, h, s, NULL)
  
++<<<<<<< HEAD
++=======
+ #ifndef arch_dma_alloc_attrs
+ #define arch_dma_alloc_attrs(dev, flag)	(true)
+ #endif
+ 
+ static inline void *dma_alloc_attrs(struct device *dev, size_t size,
+ 				       dma_addr_t *dma_handle, gfp_t flag,
+ 				       struct dma_attrs *attrs)
+ {
+ 	struct dma_map_ops *ops = get_dma_ops(dev);
+ 	void *cpu_addr;
+ 
+ 	BUG_ON(!ops);
+ 
+ 	if (dma_alloc_from_coherent(dev, size, dma_handle, &cpu_addr))
+ 		return cpu_addr;
+ 
+ 	if (!arch_dma_alloc_attrs(&dev, &flag))
+ 		return NULL;
+ 	if (!ops->alloc)
+ 		return NULL;
+ 
+ 	cpu_addr = ops->alloc(dev, size, dma_handle, flag, attrs);
+ 	debug_dma_alloc_coherent(dev, size, *dma_handle, cpu_addr);
+ 	return cpu_addr;
+ }
+ 
+ static inline void dma_free_attrs(struct device *dev, size_t size,
+ 				     void *cpu_addr, dma_addr_t dma_handle,
+ 				     struct dma_attrs *attrs)
+ {
+ 	struct dma_map_ops *ops = get_dma_ops(dev);
+ 
+ 	BUG_ON(!ops);
+ 	WARN_ON(irqs_disabled());
+ 
+ 	if (dma_release_from_coherent(dev, get_order(size), cpu_addr))
+ 		return;
+ 
+ 	if (!ops->free)
+ 		return;
+ 
+ 	debug_dma_free_coherent(dev, size, cpu_addr, dma_handle);
+ 	ops->free(dev, size, cpu_addr, dma_handle, attrs);
+ }
+ 
+ static inline void *dma_alloc_coherent(struct device *dev, size_t size,
+ 		dma_addr_t *dma_handle, gfp_t flag)
+ {
+ 	return dma_alloc_attrs(dev, size, dma_handle, flag, NULL);
+ }
+ 
+ static inline void dma_free_coherent(struct device *dev, size_t size,
+ 		void *cpu_addr, dma_addr_t dma_handle)
+ {
+ 	return dma_free_attrs(dev, size, cpu_addr, dma_handle, NULL);
+ }
+ 
+ static inline void *dma_alloc_noncoherent(struct device *dev, size_t size,
+ 		dma_addr_t *dma_handle, gfp_t gfp)
+ {
+ 	DEFINE_DMA_ATTRS(attrs);
+ 
+ 	dma_set_attr(DMA_ATTR_NON_CONSISTENT, &attrs);
+ 	return dma_alloc_attrs(dev, size, dma_handle, gfp, &attrs);
+ }
+ 
+ static inline void dma_free_noncoherent(struct device *dev, size_t size,
+ 		void *cpu_addr, dma_addr_t dma_handle)
+ {
+ 	DEFINE_DMA_ATTRS(attrs);
+ 
+ 	dma_set_attr(DMA_ATTR_NON_CONSISTENT, &attrs);
+ 	dma_free_attrs(dev, size, cpu_addr, dma_handle, &attrs);
+ }
+ 
+ static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
+ {
+ 	debug_dma_mapping_error(dev, dma_addr);
+ 
+ 	if (get_dma_ops(dev)->mapping_error)
+ 		return get_dma_ops(dev)->mapping_error(dev, dma_addr);
+ 
+ #ifdef DMA_ERROR_CODE
+ 	return dma_addr == DMA_ERROR_CODE;
+ #else
+ 	return 0;
+ #endif
+ }
+ 
++>>>>>>> efa21e432c7b (dma-mapping: cosolidate dma_mapping_error)
  #endif
* Unmerged path arch/h8300/include/asm/dma-mapping.h
* Unmerged path arch/alpha/include/asm/dma-mapping.h
* Unmerged path arch/arm/include/asm/dma-mapping.h
diff --git a/arch/arm64/include/asm/dma-mapping.h b/arch/arm64/include/asm/dma-mapping.h
index 994776894198..ddc53d712ba3 100644
--- a/arch/arm64/include/asm/dma-mapping.h
+++ b/arch/arm64/include/asm/dma-mapping.h
@@ -47,13 +47,6 @@ static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t dev_addr)
 	return (phys_addr_t)dev_addr;
 }
 
-static inline int dma_mapping_error(struct device *dev, dma_addr_t dev_addr)
-{
-	struct dma_map_ops *ops = get_dma_ops(dev);
-	debug_dma_mapping_error(dev, dev_addr);
-	return ops->mapping_error(dev, dev_addr);
-}
-
 static inline int dma_supported(struct device *dev, u64 mask)
 {
 	struct dma_map_ops *ops = get_dma_ops(dev);
* Unmerged path arch/h8300/include/asm/dma-mapping.h
* Unmerged path arch/hexagon/include/asm/dma-mapping.h
diff --git a/arch/ia64/include/asm/dma-mapping.h b/arch/ia64/include/asm/dma-mapping.h
index cf3ab7e784b5..d1a1d2394862 100644
--- a/arch/ia64/include/asm/dma-mapping.h
+++ b/arch/ia64/include/asm/dma-mapping.h
@@ -55,13 +55,6 @@ static inline void dma_free_attrs(struct device *dev, size_t size,
 
 #include <asm-generic/dma-mapping-common.h>
 
-static inline int dma_mapping_error(struct device *dev, dma_addr_t daddr)
-{
-	struct dma_map_ops *ops = platform_dma_get_ops(dev);
-	debug_dma_mapping_error(dev, daddr);
-	return ops->mapping_error(dev, daddr);
-}
-
 static inline int dma_supported(struct device *dev, u64 mask)
 {
 	struct dma_map_ops *ops = platform_dma_get_ops(dev);
* Unmerged path arch/microblaze/include/asm/dma-mapping.h
diff --git a/arch/mips/include/asm/dma-mapping.h b/arch/mips/include/asm/dma-mapping.h
index 84238c574d5e..b9f1fcbabd5f 100644
--- a/arch/mips/include/asm/dma-mapping.h
+++ b/arch/mips/include/asm/dma-mapping.h
@@ -38,14 +38,6 @@ static inline int dma_supported(struct device *dev, u64 mask)
 	return ops->dma_supported(dev, mask);
 }
 
-static inline int dma_mapping_error(struct device *dev, u64 mask)
-{
-	struct dma_map_ops *ops = get_dma_ops(dev);
-
-	debug_dma_mapping_error(dev, mask);
-	return ops->mapping_error(dev, mask);
-}
-
 static inline int
 dma_set_mask(struct device *dev, u64 mask)
 {
diff --git a/arch/openrisc/include/asm/dma-mapping.h b/arch/openrisc/include/asm/dma-mapping.h
index fab8628e1b6e..f395aaf3c330 100644
--- a/arch/openrisc/include/asm/dma-mapping.h
+++ b/arch/openrisc/include/asm/dma-mapping.h
@@ -93,11 +93,6 @@ static inline int dma_supported(struct device *dev, u64 dma_mask)
 	return dma_mask == DMA_BIT_MASK(32);
 }
 
-static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
-{
-	return 0;
-}
-
 static inline int dma_set_mask(struct device *dev, u64 dma_mask)
 {
 	if (!dev->dma_mask || !dma_supported(dev, dma_mask))
* Unmerged path arch/powerpc/include/asm/dma-mapping.h
* Unmerged path arch/s390/include/asm/dma-mapping.h
* Unmerged path arch/sh/include/asm/dma-mapping.h
* Unmerged path arch/sparc/include/asm/dma-mapping.h
diff --git a/arch/tile/include/asm/dma-mapping.h b/arch/tile/include/asm/dma-mapping.h
index f2ff191376b4..37aaaa86f931 100644
--- a/arch/tile/include/asm/dma-mapping.h
+++ b/arch/tile/include/asm/dma-mapping.h
@@ -69,13 +69,6 @@ static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)
 	return addr + size - 1 <= *dev->dma_mask;
 }
 
-static inline int
-dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
-{
-	debug_dma_mapping_error(dev, dma_addr);
-	return get_dma_ops(dev)->mapping_error(dev, dma_addr);
-}
-
 static inline int
 dma_supported(struct device *dev, u64 mask)
 {
diff --git a/arch/unicore32/include/asm/dma-mapping.h b/arch/unicore32/include/asm/dma-mapping.h
index 366460a81796..2b0519ffe443 100644
--- a/arch/unicore32/include/asm/dma-mapping.h
+++ b/arch/unicore32/include/asm/dma-mapping.h
@@ -40,16 +40,6 @@ static inline int dma_supported(struct device *dev, u64 mask)
 	return dma_ops->dma_supported(dev, mask);
 }
 
-static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
-{
-	struct dma_map_ops *dma_ops = get_dma_ops(dev);
-
-	if (dma_ops->mapping_error)
-		return dma_ops->mapping_error(dev, dma_addr);
-
-	return 0;
-}
-
 #include <asm-generic/dma-mapping-common.h>
 
 static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)
* Unmerged path arch/x86/include/asm/dma-mapping.h
* Unmerged path arch/xtensa/include/asm/dma-mapping.h
* Unmerged path include/asm-generic/dma-mapping-common.h
