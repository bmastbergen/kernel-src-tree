nfp: add control vNIC datapath

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Jakub Kicinski <jakub.kicinski@netronome.com>
commit 77ece8d5f1960f82d66b68fbc0c92938cdfa2688
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/77ece8d5.failed

Since control vNICs don't have a netdev, they can't use napi and
queuing stack provides.  Add simple tasklet-based data receive
and send of control messages with queuing on a skb_list.

	Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 77ece8d5f1960f82d66b68fbc0c92938cdfa2688)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/netronome/nfp/nfp_app.h
#	drivers/net/ethernet/netronome/nfp/nfp_net.h
#	drivers/net/ethernet/netronome/nfp/nfp_net_common.c
#	drivers/net/ethernet/netronome/nfp/nfp_net_ctrl.h
diff --cc drivers/net/ethernet/netronome/nfp/nfp_net.h
index 600c79f39fe0,eb849d26f4dd..000000000000
--- a/drivers/net/ethernet/netronome/nfp/nfp_net.h
+++ b/drivers/net/ethernet/netronome/nfp/nfp_net.h
@@@ -730,6 -812,22 +737,25 @@@ static inline u32 nfp_qcp_wr_ptr_read(u
  	return _nfp_qcp_read(q, NFP_QCP_WRITE_PTR);
  }
  
++<<<<<<< HEAD
++=======
+ static inline bool nfp_net_is_data_vnic(struct nfp_net *nn)
+ {
+ 	WARN_ON_ONCE(!nn->dp.netdev && nn->port);
+ 	return !!nn->dp.netdev;
+ }
+ 
+ static inline bool nfp_net_running(struct nfp_net *nn)
+ {
+ 	return nn->dp.ctrl & NFP_NET_CFG_CTRL_ENABLE;
+ }
+ 
+ static inline const char *nfp_net_name(struct nfp_net *nn)
+ {
+ 	return nn->dp.netdev ? nn->dp.netdev->name : "ctrl";
+ }
+ 
++>>>>>>> 77ece8d5f196 (nfp: add control vNIC datapath)
  /* Globals */
  extern const char nfp_driver_version[];
  
@@@ -738,11 -843,16 +764,24 @@@ void nfp_net_get_fw_version(struct nfp_
  			    void __iomem *ctrl_bar);
  
  struct nfp_net *
++<<<<<<< HEAD
 +nfp_net_netdev_alloc(struct pci_dev *pdev,
 +		     unsigned int max_tx_rings, unsigned int max_rx_rings);
 +void nfp_net_netdev_free(struct nfp_net *nn);
 +int nfp_net_netdev_init(struct net_device *netdev);
 +void nfp_net_netdev_clean(struct net_device *netdev);
++=======
+ nfp_net_alloc(struct pci_dev *pdev, bool needs_netdev,
+ 	      unsigned int max_tx_rings, unsigned int max_rx_rings);
+ void nfp_net_free(struct nfp_net *nn);
+ 
+ int nfp_net_init(struct nfp_net *nn);
+ void nfp_net_clean(struct nfp_net *nn);
+ 
+ int nfp_ctrl_open(struct nfp_net *nn);
+ void nfp_ctrl_close(struct nfp_net *nn);
+ 
++>>>>>>> 77ece8d5f196 (nfp: add control vNIC datapath)
  void nfp_net_set_ethtool_ops(struct net_device *netdev);
  void nfp_net_info(struct nfp_net *nn);
  int nfp_net_reconfig(struct nfp_net *nn, u32 update);
diff --cc drivers/net/ethernet/netronome/nfp/nfp_net_common.c
index 5094c56dbda7,59f1764242a0..000000000000
--- a/drivers/net/ethernet/netronome/nfp/nfp_net_common.c
+++ b/drivers/net/ethernet/netronome/nfp/nfp_net_common.c
@@@ -370,17 -392,13 +370,27 @@@ static irqreturn_t nfp_net_irq_rxtx(in
  	return IRQ_HANDLED;
  }
  
++<<<<<<< HEAD
 +bool nfp_net_link_changed_read_clear(struct nfp_net *nn)
 +{
 +	unsigned long flags;
 +	bool ret;
 +
 +	spin_lock_irqsave(&nn->link_status_lock, flags);
 +	ret = nn->link_changed;
 +	nn->link_changed = false;
 +	spin_unlock_irqrestore(&nn->link_status_lock, flags);
 +
 +	return ret;
++=======
+ static irqreturn_t nfp_ctrl_irq_rxtx(int irq, void *data)
+ {
+ 	struct nfp_net_r_vector *r_vec = data;
+ 
+ 	tasklet_schedule(&r_vec->tasklet);
+ 
+ 	return IRQ_HANDLED;
++>>>>>>> 77ece8d5f196 (nfp: add control vNIC datapath)
  }
  
  /**
@@@ -541,7 -532,7 +551,11 @@@ nfp_net_aux_irq_request(struct nfp_net 
  
  	entry = &nn->irq_entries[vector_idx];
  
++<<<<<<< HEAD
 +	snprintf(name, name_sz, format, netdev_name(nn->netdev));
++=======
+ 	snprintf(name, name_sz, format, nfp_net_name(nn));
++>>>>>>> 77ece8d5f196 (nfp: add control vNIC datapath)
  	err = request_irq(entry->vector, handler, 0, name, nn);
  	if (err) {
  		nn_err(nn, "Failed to request IRQ %d (err=%d).\n",
@@@ -956,7 -952,10 +970,14 @@@ static void nfp_net_tx_complete(struct 
  	r_vec->tx_pkts += done_pkts;
  	u64_stats_update_end(&r_vec->tx_sync);
  
++<<<<<<< HEAD
 +	nd_q = netdev_get_tx_queue(nn->netdev, tx_ring->idx);
++=======
+ 	if (!dp->netdev)
+ 		return;
+ 
+ 	nd_q = netdev_get_tx_queue(dp->netdev, tx_ring->idx);
++>>>>>>> 77ece8d5f196 (nfp: add control vNIC datapath)
  	netdev_tx_completed_queue(nd_q, done_pkts, done_bytes);
  	if (nfp_net_tx_ring_should_wake(tx_ring)) {
  		/* Make sure TX thread will see updated tx_ring->rd_p */
@@@ -1025,7 -1064,10 +1046,14 @@@ nfp_net_tx_ring_reset(struct nfp_net *n
  	tx_ring->qcp_rd_p = 0;
  	tx_ring->wr_ptr_add = 0;
  
++<<<<<<< HEAD
 +	nd_q = netdev_get_tx_queue(nn->netdev, tx_ring->idx);
++=======
+ 	if (tx_ring->is_xdp || !dp->netdev)
+ 		return;
+ 
+ 	nd_q = netdev_get_tx_queue(dp->netdev, tx_ring->idx);
++>>>>>>> 77ece8d5f196 (nfp: add control vNIC datapath)
  	netdev_tx_reset_queue(nd_q);
  }
  
@@@ -1502,6 -1983,44 +1755,47 @@@ static void nfp_ctrl_poll(unsigned lon
   */
  
  /**
++<<<<<<< HEAD
++=======
+  * nfp_net_vecs_init() - Assign IRQs and setup rvecs.
+  * @nn:		NFP Network structure
+  */
+ static void nfp_net_vecs_init(struct nfp_net *nn)
+ {
+ 	struct nfp_net_r_vector *r_vec;
+ 	int r;
+ 
+ 	nn->lsc_handler = nfp_net_irq_lsc;
+ 	nn->exn_handler = nfp_net_irq_exn;
+ 
+ 	for (r = 0; r < nn->max_r_vecs; r++) {
+ 		struct msix_entry *entry;
+ 
+ 		entry = &nn->irq_entries[NFP_NET_NON_Q_VECTORS + r];
+ 
+ 		r_vec = &nn->r_vecs[r];
+ 		r_vec->nfp_net = nn;
+ 		r_vec->irq_entry = entry->entry;
+ 		r_vec->irq_vector = entry->vector;
+ 
+ 		if (nn->dp.netdev) {
+ 			r_vec->handler = nfp_net_irq_rxtx;
+ 		} else {
+ 			r_vec->handler = nfp_ctrl_irq_rxtx;
+ 
+ 			__skb_queue_head_init(&r_vec->queue);
+ 			spin_lock_init(&r_vec->lock);
+ 			tasklet_init(&r_vec->tasklet, nfp_ctrl_poll,
+ 				     (unsigned long)r_vec);
+ 			tasklet_disable(&r_vec->tasklet);
+ 		}
+ 
+ 		cpumask_set_cpu(r, &r_vec->affinity_mask);
+ 	}
+ }
+ 
+ /**
++>>>>>>> 77ece8d5f196 (nfp: add control vNIC datapath)
   * nfp_net_tx_ring_free() - Free resources allocated to a TX ring
   * @tx_ring:   TX ring to free
   */
@@@ -1760,11 -2282,14 +2054,22 @@@ nfp_net_prepare_vector(struct nfp_net *
  	int err;
  
  	/* Setup NAPI */
 -	if (nn->dp.netdev)
++<<<<<<< HEAD
 +	netif_napi_add(nn->netdev, &r_vec->napi,
 +		       nfp_net_poll, NAPI_POLL_WEIGHT);
 +
 +	snprintf(r_vec->name, sizeof(r_vec->name),
 +		 "%s-rxtx-%d", nn->netdev->name, idx);
++=======
++	if (nn->dp.netdev)
+ 		netif_napi_add(nn->dp.netdev, &r_vec->napi,
+ 			       nfp_net_poll, NAPI_POLL_WEIGHT);
+ 	else
+ 		tasklet_enable(&r_vec->tasklet);
+ 
+ 	snprintf(r_vec->name, sizeof(r_vec->name),
+ 		 "%s-rxtx-%d", nfp_net_name(nn), idx);
++>>>>>>> 77ece8d5f196 (nfp: add control vNIC datapath)
  	err = request_irq(r_vec->irq_vector, r_vec->handler, 0, r_vec->name,
  			  r_vec);
  	if (err) {
@@@ -2194,6 -2597,168 +2507,171 @@@ static int nfp_net_netdev_close(struct 
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ void nfp_ctrl_close(struct nfp_net *nn)
+ {
+ 	int r;
+ 
+ 	rtnl_lock();
+ 
+ 	for (r = 0; r < nn->dp.num_r_vecs; r++) {
+ 		disable_irq(nn->r_vecs[r].irq_vector);
+ 		tasklet_disable(&nn->r_vecs[r].tasklet);
+ 	}
+ 
+ 	nfp_net_clear_config_and_disable(nn);
+ 
+ 	nfp_net_close_free_all(nn);
+ 
+ 	rtnl_unlock();
+ }
+ 
+ /**
+  * nfp_net_open_stack() - Start the device from stack's perspective
+  * @nn:      NFP Net device to reconfigure
+  */
+ static void nfp_net_open_stack(struct nfp_net *nn)
+ {
+ 	unsigned int r;
+ 
+ 	for (r = 0; r < nn->dp.num_r_vecs; r++) {
+ 		napi_enable(&nn->r_vecs[r].napi);
+ 		enable_irq(nn->r_vecs[r].irq_vector);
+ 	}
+ 
+ 	netif_tx_wake_all_queues(nn->dp.netdev);
+ 
+ 	enable_irq(nn->irq_entries[NFP_NET_IRQ_LSC_IDX].vector);
+ 	nfp_net_read_link_status(nn);
+ }
+ 
+ static int nfp_net_open_alloc_all(struct nfp_net *nn)
+ {
+ 	int err, r;
+ 
+ 	err = nfp_net_aux_irq_request(nn, NFP_NET_CFG_EXN, "%s-exn",
+ 				      nn->exn_name, sizeof(nn->exn_name),
+ 				      NFP_NET_IRQ_EXN_IDX, nn->exn_handler);
+ 	if (err)
+ 		return err;
+ 	err = nfp_net_aux_irq_request(nn, NFP_NET_CFG_LSC, "%s-lsc",
+ 				      nn->lsc_name, sizeof(nn->lsc_name),
+ 				      NFP_NET_IRQ_LSC_IDX, nn->lsc_handler);
+ 	if (err)
+ 		goto err_free_exn;
+ 	disable_irq(nn->irq_entries[NFP_NET_IRQ_LSC_IDX].vector);
+ 
+ 	for (r = 0; r < nn->dp.num_r_vecs; r++) {
+ 		err = nfp_net_prepare_vector(nn, &nn->r_vecs[r], r);
+ 		if (err)
+ 			goto err_cleanup_vec_p;
+ 	}
+ 
+ 	err = nfp_net_rx_rings_prepare(nn, &nn->dp);
+ 	if (err)
+ 		goto err_cleanup_vec;
+ 
+ 	err = nfp_net_tx_rings_prepare(nn, &nn->dp);
+ 	if (err)
+ 		goto err_free_rx_rings;
+ 
+ 	for (r = 0; r < nn->max_r_vecs; r++)
+ 		nfp_net_vector_assign_rings(&nn->dp, &nn->r_vecs[r], r);
+ 
+ 	return 0;
+ 
+ err_free_rx_rings:
+ 	nfp_net_rx_rings_free(&nn->dp);
+ err_cleanup_vec:
+ 	r = nn->dp.num_r_vecs;
+ err_cleanup_vec_p:
+ 	while (r--)
+ 		nfp_net_cleanup_vector(nn, &nn->r_vecs[r]);
+ 	nfp_net_aux_irq_free(nn, NFP_NET_CFG_LSC, NFP_NET_IRQ_LSC_IDX);
+ err_free_exn:
+ 	nfp_net_aux_irq_free(nn, NFP_NET_CFG_EXN, NFP_NET_IRQ_EXN_IDX);
+ 	return err;
+ }
+ 
+ static int nfp_net_netdev_open(struct net_device *netdev)
+ {
+ 	struct nfp_net *nn = netdev_priv(netdev);
+ 	int err;
+ 
+ 	/* Step 1: Allocate resources for rings and the like
+ 	 * - Request interrupts
+ 	 * - Allocate RX and TX ring resources
+ 	 * - Setup initial RSS table
+ 	 */
+ 	err = nfp_net_open_alloc_all(nn);
+ 	if (err)
+ 		return err;
+ 
+ 	err = netif_set_real_num_tx_queues(netdev, nn->dp.num_stack_tx_rings);
+ 	if (err)
+ 		goto err_free_all;
+ 
+ 	err = netif_set_real_num_rx_queues(netdev, nn->dp.num_rx_rings);
+ 	if (err)
+ 		goto err_free_all;
+ 
+ 	/* Step 2: Configure the NFP
+ 	 * - Enable rings from 0 to tx_rings/rx_rings - 1.
+ 	 * - Write MAC address (in case it changed)
+ 	 * - Set the MTU
+ 	 * - Set the Freelist buffer size
+ 	 * - Enable the FW
+ 	 */
+ 	err = nfp_net_set_config_and_enable(nn);
+ 	if (err)
+ 		goto err_free_all;
+ 
+ 	/* Step 3: Enable for kernel
+ 	 * - put some freelist descriptors on each RX ring
+ 	 * - enable NAPI on each ring
+ 	 * - enable all TX queues
+ 	 * - set link state
+ 	 */
+ 	nfp_net_open_stack(nn);
+ 
+ 	return 0;
+ 
+ err_free_all:
+ 	nfp_net_close_free_all(nn);
+ 	return err;
+ }
+ 
+ int nfp_ctrl_open(struct nfp_net *nn)
+ {
+ 	int err, r;
+ 
+ 	/* ring dumping depends on vNICs being opened/closed under rtnl */
+ 	rtnl_lock();
+ 
+ 	err = nfp_net_open_alloc_all(nn);
+ 	if (err)
+ 		goto err_unlock;
+ 
+ 	err = nfp_net_set_config_and_enable(nn);
+ 	if (err)
+ 		goto err_free_all;
+ 
+ 	for (r = 0; r < nn->dp.num_r_vecs; r++)
+ 		enable_irq(nn->r_vecs[r].irq_vector);
+ 
+ 	rtnl_unlock();
+ 
+ 	return 0;
+ 
+ err_free_all:
+ 	nfp_net_close_free_all(nn);
+ err_unlock:
+ 	rtnl_unlock();
+ 	return err;
+ }
+ 
++>>>>>>> 77ece8d5f196 (nfp: add control vNIC datapath)
  static void nfp_net_set_rx_mode(struct net_device *netdev)
  {
  	struct nfp_net *nn = netdev_priv(netdev);
@@@ -2820,9 -3546,75 +3298,76 @@@ int nfp_net_netdev_init(struct net_devi
  
  	netdev->features = netdev->hw_features;
  
 -	if (nfp_app_has_tc(nn->app))
 -		netdev->hw_features |= NETIF_F_HW_TC;
 -
  	/* Advertise but disable TSO by default. */
  	netdev->features &= ~(NETIF_F_TSO | NETIF_F_TSO6);
++<<<<<<< HEAD
 +	nn->dp.ctrl &= ~NFP_NET_CFG_CTRL_LSO;
++=======
+ 	nn->dp.ctrl &= ~NFP_NET_CFG_CTRL_LSO_ANY;
+ 
+ 	/* Finalise the netdev setup */
+ 	netdev->netdev_ops = &nfp_net_netdev_ops;
+ 	netdev->watchdog_timeo = msecs_to_jiffies(5 * 1000);
+ 
+ 	/* MTU range: 68 - hw-specific max */
+ 	netdev->min_mtu = ETH_MIN_MTU;
+ 	netdev->max_mtu = nn->max_mtu;
+ 
+ 	netif_carrier_off(netdev);
+ 
+ 	nfp_net_set_ethtool_ops(netdev);
+ }
+ 
+ /**
+  * nfp_net_init() - Initialise/finalise the nfp_net structure
+  * @nn:		NFP Net device structure
+  *
+  * Return: 0 on success or negative errno on error.
+  */
+ int nfp_net_init(struct nfp_net *nn)
+ {
+ 	int err;
+ 
+ 	nn->dp.rx_dma_dir = DMA_FROM_DEVICE;
+ 
+ 	/* Get some of the read-only fields from the BAR */
+ 	nn->cap = nn_readl(nn, NFP_NET_CFG_CAP);
+ 	nn->max_mtu = nn_readl(nn, NFP_NET_CFG_MAX_MTU);
+ 
+ 	/* Chained metadata is signalled by capabilities except in version 4 */
+ 	nn->dp.chained_metadata_format = nn->fw_ver.major == 4 ||
+ 					 !nn->dp.netdev ||
+ 					 nn->cap & NFP_NET_CFG_CTRL_CHAIN_META;
+ 	if (nn->dp.chained_metadata_format && nn->fw_ver.major != 4)
+ 		nn->cap &= ~NFP_NET_CFG_CTRL_RSS;
+ 
+ 	/* Determine RX packet/metadata boundary offset */
+ 	if (nn->fw_ver.major >= 2) {
+ 		u32 reg;
+ 
+ 		reg = nn_readl(nn, NFP_NET_CFG_RX_OFFSET);
+ 		if (reg > NFP_NET_MAX_PREPEND) {
+ 			nn_err(nn, "Invalid rx offset: %d\n", reg);
+ 			return -EINVAL;
+ 		}
+ 		nn->dp.rx_offset = reg;
+ 	} else {
+ 		nn->dp.rx_offset = NFP_NET_RX_OFFSET;
+ 	}
+ 
+ 	/* Set default MTU and Freelist buffer size */
+ 	if (nn->max_mtu < NFP_NET_DEFAULT_MTU)
+ 		nn->dp.mtu = nn->max_mtu;
+ 	else
+ 		nn->dp.mtu = NFP_NET_DEFAULT_MTU;
+ 	nn->dp.fl_bufsz = nfp_net_calc_fl_bufsz(&nn->dp);
+ 
+ 	if (nn->cap & NFP_NET_CFG_CTRL_RSS_ANY) {
+ 		nfp_net_rss_init(nn);
+ 		nn->dp.ctrl |= nn->cap & NFP_NET_CFG_CTRL_RSS2 ?:
+ 					 NFP_NET_CFG_CTRL_RSS;
+ 	}
++>>>>>>> 77ece8d5f196 (nfp: add control vNIC datapath)
  
  	/* Allow L2 Broadcast and Multicast through by default, if supported */
  	if (nn->cap & NFP_NET_CFG_CTRL_L2BC)
diff --cc drivers/net/ethernet/netronome/nfp/nfp_net_ctrl.h
index 92d76a860c19,48a8bf97645e..000000000000
--- a/drivers/net/ethernet/netronome/nfp/nfp_net_ctrl.h
+++ b/drivers/net/ethernet/netronome/nfp/nfp_net_ctrl.h
@@@ -66,6 -66,17 +66,20 @@@
  #define NFP_NET_LSO_MAX_HDR_SZ		255
  
  /**
++<<<<<<< HEAD
++=======
+  * Prepend field types
+  */
+ #define NFP_NET_META_FIELD_SIZE		4
+ #define NFP_NET_META_HASH		1 /* next field carries hash type */
+ #define NFP_NET_META_MARK		2
+ #define NFP_NET_META_PORTID		5
+ #define NFP_NET_META_CSUM		6 /* checksum complete type */
+ 
+ #define	NFP_META_PORT_ID_CTRL		~0U
+ 
+ /**
++>>>>>>> 77ece8d5f196 (nfp: add control vNIC datapath)
   * Hash type pre-pended when a RSS hash was computed
   */
  #define NFP_NET_RSS_NONE                0
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_app.h
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_app.h
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_net.h
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_net_common.c
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_net_ctrl.h
