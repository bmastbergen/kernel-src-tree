net/mlx5: PTP code migration to driver core section

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [netdrv] mlx5: PTP code migration to driver core section (Kamal Heib) [1456694]
Rebuild_FUZZ: 95.92%
commit-author Feras Daoud <ferasda@mellanox.com>
commit 7c39afb394c79e72c3795b4a42d55155b34ee073
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/7c39afb3.failed

PTP code is moved to core section of mlx5 driver in order to share
it between ethernet and infiniband. This movement involves the following
changes:
- Change mlx5e_ prefix to be mlx5_
- Add clock structs to Core
- Add clock object to mlx5_core_dev
- Call Init/Uninit clock from core init/cleanup
- Rename mlx5e_tstamp to be mlx5_clock

	Signed-off-by: Feras Daoud <ferasda@mellanox.com>
	Signed-off-by: Eitan Rabin <rabin@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 7c39afb394c79e72c3795b4a42d55155b34ee073)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/clock.h
#	drivers/net/ethernet/mellanox/mlx5/core/en.h
#	drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_main.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_tx.c
#	drivers/net/ethernet/mellanox/mlx5/core/ipoib/ipoib.c
#	drivers/net/ethernet/mellanox/mlx5/core/main.c
#	drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en.h
index a1e4cf7321f0,2059122eb089..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en.h
@@@ -254,23 -267,8 +254,26 @@@ struct mlx5e_dcbx 
  };
  #endif
  
++<<<<<<< HEAD
 +struct mlx5e_tstamp {
 +	rwlock_t                   lock;
 +	struct cyclecounter        cycles;
 +	struct timecounter         clock;
 +	struct hwtstamp_config     hwtstamp_config;
 +	u32                        nominal_c_mult;
 +	unsigned long              overflow_period;
 +	struct delayed_work        overflow_work;
 +	struct mlx5_core_dev      *mdev;
 +	struct ptp_clock          *ptp;
 +	struct ptp_clock_info      ptp_info;
 +	u8                        *pps_pin_caps;
 +};
 +
++=======
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  enum {
  	MLX5E_RQ_STATE_ENABLED,
 +	MLX5E_RQ_STATE_UMR_WQE_IN_PROGRESS,
  	MLX5E_RQ_STATE_AM,
  };
  
@@@ -296,13 -295,136 +299,138 @@@ struct mlx5e_cq 
  	struct mlx5_frag_wq_ctrl   wq_ctrl;
  } ____cacheline_aligned_in_smp;
  
 -struct mlx5e_tx_wqe_info {
 -	struct sk_buff *skb;
 -	u32 num_bytes;
 -	u8  num_wqebbs;
 -	u8  num_dma;
 -};
 -
 +struct mlx5e_rq;
 +typedef void (*mlx5e_fp_handle_rx_cqe)(struct mlx5e_rq *rq,
 +				       struct mlx5_cqe64 *cqe);
 +typedef int (*mlx5e_fp_alloc_wqe)(struct mlx5e_rq *rq, struct mlx5e_rx_wqe *wqe,
 +				  u16 ix);
 +
++<<<<<<< HEAD
 +typedef void (*mlx5e_fp_dealloc_wqe)(struct mlx5e_rq *rq, u16 ix);
++=======
+ enum mlx5e_dma_map_type {
+ 	MLX5E_DMA_MAP_SINGLE,
+ 	MLX5E_DMA_MAP_PAGE
+ };
+ 
+ struct mlx5e_sq_dma {
+ 	dma_addr_t              addr;
+ 	u32                     size;
+ 	enum mlx5e_dma_map_type type;
+ };
+ 
+ enum {
+ 	MLX5E_SQ_STATE_ENABLED,
+ 	MLX5E_SQ_STATE_IPSEC,
+ };
+ 
+ struct mlx5e_sq_wqe_info {
+ 	u8  opcode;
+ };
+ 
+ struct mlx5e_txqsq {
+ 	/* data path */
+ 
+ 	/* dirtied @completion */
+ 	u16                        cc;
+ 	u32                        dma_fifo_cc;
+ 
+ 	/* dirtied @xmit */
+ 	u16                        pc ____cacheline_aligned_in_smp;
+ 	u32                        dma_fifo_pc;
+ 	struct mlx5e_sq_stats      stats;
+ 
+ 	struct mlx5e_cq            cq;
+ 
+ 	/* write@xmit, read@completion */
+ 	struct {
+ 		struct mlx5e_sq_dma       *dma_fifo;
+ 		struct mlx5e_tx_wqe_info  *wqe_info;
+ 	} db;
+ 
+ 	/* read only */
+ 	struct mlx5_wq_cyc         wq;
+ 	u32                        dma_fifo_mask;
+ 	void __iomem              *uar_map;
+ 	struct netdev_queue       *txq;
+ 	u32                        sqn;
+ 	u16                        max_inline;
+ 	u8                         min_inline_mode;
+ 	u16                        edge;
+ 	struct device             *pdev;
+ 	__be32                     mkey_be;
+ 	unsigned long              state;
+ 	struct hwtstamp_config    *tstamp;
+ 	struct mlx5_clock         *clock;
+ 
+ 	/* control path */
+ 	struct mlx5_wq_ctrl        wq_ctrl;
+ 	struct mlx5e_channel      *channel;
+ 	int                        txq_ix;
+ 	u32                        rate_limit;
+ } ____cacheline_aligned_in_smp;
+ 
+ struct mlx5e_xdpsq {
+ 	/* data path */
+ 
+ 	/* dirtied @rx completion */
+ 	u16                        cc;
+ 	u16                        pc;
+ 
+ 	struct mlx5e_cq            cq;
+ 
+ 	/* write@xmit, read@completion */
+ 	struct {
+ 		struct mlx5e_dma_info     *di;
+ 		bool                       doorbell;
+ 	} db;
+ 
+ 	/* read only */
+ 	struct mlx5_wq_cyc         wq;
+ 	void __iomem              *uar_map;
+ 	u32                        sqn;
+ 	struct device             *pdev;
+ 	__be32                     mkey_be;
+ 	u8                         min_inline_mode;
+ 	unsigned long              state;
+ 
+ 	/* control path */
+ 	struct mlx5_wq_ctrl        wq_ctrl;
+ 	struct mlx5e_channel      *channel;
+ } ____cacheline_aligned_in_smp;
+ 
+ struct mlx5e_icosq {
+ 	/* data path */
+ 
+ 	/* dirtied @xmit */
+ 	u16                        pc ____cacheline_aligned_in_smp;
+ 
+ 	struct mlx5e_cq            cq;
+ 
+ 	/* write@xmit, read@completion */
+ 	struct {
+ 		struct mlx5e_sq_wqe_info *ico_wqe;
+ 	} db;
+ 
+ 	/* read only */
+ 	struct mlx5_wq_cyc         wq;
+ 	void __iomem              *uar_map;
+ 	u32                        sqn;
+ 	u16                        edge;
+ 	__be32                     mkey_be;
+ 	unsigned long              state;
+ 
+ 	/* control path */
+ 	struct mlx5_wq_ctrl        wq_ctrl;
+ 	struct mlx5e_channel      *channel;
+ } ____cacheline_aligned_in_smp;
+ 
+ static inline bool
+ mlx5e_wqc_has_room_for(struct mlx5_wq_cyc *wq, u16 cc, u16 pc, u16 n)
+ {
+ 	return (((wq->sz_m1 & (cc - pc)) >= n) || (cc == pc));
+ }
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  
  struct mlx5e_dma_info {
  	struct page	*page;
@@@ -359,20 -511,25 +487,21 @@@ struct mlx5e_rq 
  		} mpwqe;
  	};
  	struct {
 -		u16            headroom;
  		u8             page_order;
 -		u8             map_dir;   /* dma map direction */
 +		u32            wqe_sz;    /* wqe data buffer size */
  	} buff;
 +	__be32                 mkey_be;
  
 -	struct mlx5e_channel  *channel;
  	struct device         *pdev;
  	struct net_device     *netdev;
- 	struct mlx5e_tstamp   *tstamp;
  	struct mlx5e_rq_stats  stats;
  	struct mlx5e_cq        cq;
  	struct mlx5e_page_cache page_cache;
+ 	struct hwtstamp_config *tstamp;
+ 	struct mlx5_clock      *clock;
  
  	mlx5e_fp_handle_rx_cqe handle_rx_cqe;
 -	mlx5e_fp_post_rx_wqes  post_wqes;
 +	mlx5e_fp_alloc_wqe     alloc_wqe;
  	mlx5e_fp_dealloc_wqe   dealloc_wqe;
  
  	unsigned long          state;
@@@ -511,8 -567,15 +640,13 @@@ struct mlx5e_channel 
  
  	/* control */
  	struct mlx5e_priv         *priv;
++<<<<<<< HEAD
++=======
+ 	struct mlx5_core_dev      *mdev;
+ 	struct hwtstamp_config    *tstamp;
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  	int                        ix;
 -};
 -
 -struct mlx5e_channels {
 -	struct mlx5e_channel **c;
 -	unsigned int           num;
 -	struct mlx5e_params    params;
 +	int                        cpu;
  };
  
  enum mlx5e_traffic_types {
@@@ -774,15 -853,9 +908,21 @@@ void mlx5e_ethtool_init_steering(struc
  void mlx5e_ethtool_cleanup_steering(struct mlx5e_priv *priv);
  void mlx5e_set_rx_mode_work(struct work_struct *work);
  
++<<<<<<< HEAD
 +void mlx5e_fill_hwstamp(struct mlx5e_tstamp *clock, u64 timestamp,
 +			struct skb_shared_hwtstamps *hwts);
 +void mlx5e_timestamp_init(struct mlx5e_priv *priv);
 +void mlx5e_timestamp_cleanup(struct mlx5e_priv *priv);
 +void mlx5e_pps_event_handler(struct mlx5e_priv *priv,
 +			     struct ptp_clock_event *event);
 +int mlx5e_hwstamp_set(struct net_device *dev, struct ifreq *ifr);
 +int mlx5e_hwstamp_get(struct net_device *dev, struct ifreq *ifr);
 +void mlx5e_modify_rx_cqe_compression_locked(struct mlx5e_priv *priv, bool val);
++=======
+ int mlx5e_hwstamp_set(struct mlx5e_priv *priv, struct ifreq *ifr);
+ int mlx5e_hwstamp_get(struct mlx5e_priv *priv, struct ifreq *ifr);
+ int mlx5e_modify_rx_cqe_compression_locked(struct mlx5e_priv *priv, bool val);
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  
  int mlx5e_vlan_rx_add_vid(struct net_device *dev, __always_unused __be16 proto,
  			  u16 vid);
@@@ -790,12 -863,24 +930,13 @@@ int mlx5e_vlan_rx_kill_vid(struct net_d
  			   u16 vid);
  void mlx5e_enable_vlan_filter(struct mlx5e_priv *priv);
  void mlx5e_disable_vlan_filter(struct mlx5e_priv *priv);
+ void mlx5e_timestamp_set(struct mlx5e_priv *priv);
  
 -struct mlx5e_redirect_rqt_param {
 -	bool is_rss;
 -	union {
 -		u32 rqn; /* Direct RQN (Non-RSS) */
 -		struct {
 -			u8 hfunc;
 -			struct mlx5e_channels *channels;
 -		} rss; /* RSS data */
 -	};
 -};
 +int mlx5e_modify_rqs_vsd(struct mlx5e_priv *priv, bool vsd);
  
 -int mlx5e_redirect_rqt(struct mlx5e_priv *priv, u32 rqtn, int sz,
 -		       struct mlx5e_redirect_rqt_param rrp);
 -void mlx5e_build_indir_tir_ctx_hash(struct mlx5e_params *params,
 -				    enum mlx5e_traffic_types tt,
 -				    void *tirc, bool inner);
 +int mlx5e_redirect_rqt(struct mlx5e_priv *priv, u32 rqtn, int sz, int ix);
 +void mlx5e_build_indir_tir_ctx_hash(struct mlx5e_priv *priv, void *tirc,
 +				    enum mlx5e_traffic_types tt);
  
  int mlx5e_open_locked(struct net_device *netdev);
  int mlx5e_close_locked(struct net_device *netdev);
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
index 59f20ba95c86,fa8aed62b231..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
@@@ -48,119 -48,76 +48,180 @@@ enum 
  };
  
  enum {
- 	MLX5E_EVENT_MODE_DISABLE	= 0x0,
- 	MLX5E_EVENT_MODE_REPETETIVE	= 0x1,
- 	MLX5E_EVENT_MODE_ONCE_TILL_ARM	= 0x2,
+ 	MLX5_EVENT_MODE_DISABLE	= 0x0,
+ 	MLX5_EVENT_MODE_REPETETIVE	= 0x1,
+ 	MLX5_EVENT_MODE_ONCE_TILL_ARM	= 0x2,
  };
  
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +void mlx5e_fill_hwstamp(struct mlx5e_tstamp *tstamp, u64 timestamp,
 +			struct skb_shared_hwtstamps *hwts)
- {
- 	u64 nsec;
++=======
+ enum {
+ 	MLX5_MTPPS_FS_ENABLE			= BIT(0x0),
+ 	MLX5_MTPPS_FS_PATTERN			= BIT(0x2),
+ 	MLX5_MTPPS_FS_PIN_MODE			= BIT(0x3),
+ 	MLX5_MTPPS_FS_TIME_STAMP		= BIT(0x4),
+ 	MLX5_MTPPS_FS_OUT_PULSE_DURATION	= BIT(0x5),
+ 	MLX5_MTPPS_FS_ENH_OUT_PER_ADJ		= BIT(0x7),
+ };
  
- 	read_lock(&tstamp->lock);
- 	nsec = timecounter_cyc2time(&tstamp->clock, timestamp);
- 	read_unlock(&tstamp->lock);
+ static u64 read_internal_timer(const struct cyclecounter *cc)
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
+ {
+ 	struct mlx5_clock *clock = container_of(cc, struct mlx5_clock, cycles);
+ 	struct mlx5_core_dev *mdev = container_of(clock, struct mlx5_core_dev,
+ 						  clock);
  
- 	hwts->hwtstamp = ns_to_ktime(nsec);
+ 	return mlx5_read_internal_timer(mdev) & cc->mask;
  }
  
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +static cycle_t mlx5e_read_internal_timer(const struct cyclecounter *cc)
 +{
 +	struct mlx5e_tstamp *tstamp = container_of(cc, struct mlx5e_tstamp,
 +						   cycles);
 +
 +	return mlx5_read_internal_timer(tstamp->mdev) & cc->mask;
 +}
 +
 +static void mlx5e_timestamp_overflow(struct work_struct *work)
 +{
 +	struct delayed_work *dwork = to_delayed_work(work);
 +	struct mlx5e_tstamp *tstamp = container_of(dwork, struct mlx5e_tstamp,
 +						   overflow_work);
 +	unsigned long flags;
 +
 +	write_lock_irqsave(&tstamp->lock, flags);
 +	timecounter_read(&tstamp->clock);
 +	write_unlock_irqrestore(&tstamp->lock, flags);
 +	schedule_delayed_work(&tstamp->overflow_work,
 +			      msecs_to_jiffies(tstamp->overflow_period * 1000));
 +}
 +
 +int mlx5e_hwstamp_set(struct net_device *dev, struct ifreq *ifr)
 +{
 +	struct mlx5e_priv *priv = netdev_priv(dev);
 +	struct hwtstamp_config config;
 +
 +	if (!MLX5_CAP_GEN(priv->mdev, device_frequency_khz))
 +		return -EOPNOTSUPP;
 +
 +	if (copy_from_user(&config, ifr->ifr_data, sizeof(config)))
 +		return -EFAULT;
 +
 +	/* TX HW timestamp */
 +	switch (config.tx_type) {
 +	case HWTSTAMP_TX_OFF:
 +	case HWTSTAMP_TX_ON:
 +		break;
 +	default:
 +		return -ERANGE;
 +	}
 +
 +	mutex_lock(&priv->state_lock);
 +	/* RX HW timestamp */
 +	switch (config.rx_filter) {
 +	case HWTSTAMP_FILTER_NONE:
 +		/* Reset CQE compression to Admin default */
 +		mlx5e_modify_rx_cqe_compression_locked(priv, priv->params.rx_cqe_compress_def);
 +		break;
 +	case HWTSTAMP_FILTER_ALL:
 +	case HWTSTAMP_FILTER_SOME:
 +	case HWTSTAMP_FILTER_PTP_V1_L4_EVENT:
 +	case HWTSTAMP_FILTER_PTP_V1_L4_SYNC:
 +	case HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:
 +	case HWTSTAMP_FILTER_PTP_V2_L4_EVENT:
 +	case HWTSTAMP_FILTER_PTP_V2_L4_SYNC:
 +	case HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:
 +	case HWTSTAMP_FILTER_PTP_V2_L2_EVENT:
 +	case HWTSTAMP_FILTER_PTP_V2_L2_SYNC:
 +	case HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ:
 +	case HWTSTAMP_FILTER_PTP_V2_EVENT:
 +	case HWTSTAMP_FILTER_PTP_V2_SYNC:
 +	case HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:
 +		/* Disable CQE compression */
 +		netdev_warn(dev, "Disabling cqe compression");
 +		mlx5e_modify_rx_cqe_compression_locked(priv, false);
 +		config.rx_filter = HWTSTAMP_FILTER_ALL;
 +		break;
 +	default:
 +		mutex_unlock(&priv->state_lock);
 +		return -ERANGE;
 +	}
 +
 +	memcpy(&priv->tstamp.hwtstamp_config, &config, sizeof(config));
 +	mutex_unlock(&priv->state_lock);
 +
 +	return copy_to_user(ifr->ifr_data, &config,
 +			    sizeof(config)) ? -EFAULT : 0;
 +}
 +
 +int mlx5e_hwstamp_get(struct net_device *dev, struct ifreq *ifr)
 +{
 +	struct mlx5e_priv *priv = netdev_priv(dev);
 +	struct hwtstamp_config *cfg = &priv->tstamp.hwtstamp_config;
 +
 +	if (!MLX5_CAP_GEN(priv->mdev, device_frequency_khz))
 +		return -EOPNOTSUPP;
 +
 +	return copy_to_user(ifr->ifr_data, cfg, sizeof(*cfg)) ? -EFAULT : 0;
 +}
 +
 +static int mlx5e_ptp_settime(struct ptp_clock_info *ptp,
 +			     const struct timespec64 *ts)
 +{
 +	struct mlx5e_tstamp *tstamp = container_of(ptp, struct mlx5e_tstamp,
 +						   ptp_info);
++=======
+ static void mlx5_pps_out(struct work_struct *work)
+ {
+ 	struct mlx5_pps *pps_info = container_of(work, struct mlx5_pps,
+ 						 out_work);
+ 	struct mlx5_clock *clock = container_of(pps_info, struct mlx5_clock,
+ 						pps_info);
+ 	struct mlx5_core_dev *mdev = container_of(clock, struct mlx5_core_dev,
+ 						  clock);
+ 	u32 in[MLX5_ST_SZ_DW(mtpps_reg)] = {0};
+ 	unsigned long flags;
+ 	int i;
+ 
+ 	for (i = 0; i < clock->ptp_info.n_pins; i++) {
+ 		u64 tstart;
+ 
+ 		write_lock_irqsave(&clock->lock, flags);
+ 		tstart = clock->pps_info.start[i];
+ 		clock->pps_info.start[i] = 0;
+ 		write_unlock_irqrestore(&clock->lock, flags);
+ 		if (!tstart)
+ 			continue;
+ 
+ 		MLX5_SET(mtpps_reg, in, pin, i);
+ 		MLX5_SET64(mtpps_reg, in, time_stamp, tstart);
+ 		MLX5_SET(mtpps_reg, in, field_select, MLX5_MTPPS_FS_TIME_STAMP);
+ 		mlx5_set_mtpps(mdev, in, sizeof(in));
+ 	}
+ }
+ 
+ static void mlx5_timestamp_overflow(struct work_struct *work)
+ {
+ 	struct delayed_work *dwork = to_delayed_work(work);
+ 	struct mlx5_clock *clock = container_of(dwork, struct mlx5_clock,
+ 						overflow_work);
+ 	unsigned long flags;
+ 
+ 	write_lock_irqsave(&clock->lock, flags);
+ 	timecounter_read(&clock->tc);
+ 	write_unlock_irqrestore(&clock->lock, flags);
+ 	schedule_delayed_work(&clock->overflow_work, clock->overflow_period);
+ }
+ 
+ static int mlx5_ptp_settime(struct ptp_clock_info *ptp,
+ 			    const struct timespec64 *ts)
+ {
+ 	struct mlx5_clock *clock = container_of(ptp, struct mlx5_clock,
+ 						 ptp_info);
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
  	u64 ns = timespec64_to_ns(ts);
  	unsigned long flags;
  
@@@ -207,20 -163,8 +267,25 @@@ static int mlx5_ptp_adjfreq(struct ptp_
  	u32 diff;
  	unsigned long flags;
  	int neg_adj = 0;
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +	struct mlx5e_tstamp *tstamp = container_of(ptp, struct mlx5e_tstamp,
 +						  ptp_info);
 +	struct mlx5e_priv *priv =
 +		container_of(tstamp, struct mlx5e_priv, tstamp);
 +
 +	if (MLX5_CAP_GEN(priv->mdev, pps_modify)) {
 +		u32 in[MLX5_ST_SZ_DW(mtpps_reg)] = {0};
 +
 +		/* For future use need to add a loop for finding all 1PPS out pins */
 +		MLX5_SET(mtpps_reg, in, pin_mode, MLX5E_PIN_MODE_OUT);
 +		MLX5_SET(mtpps_reg, in, out_periodic_adjustment, delta & 0xFFFF);
 +
 +		mlx5_set_mtpps(priv->mdev, in, sizeof(in));
 +	}
++=======
+ 	struct mlx5_clock *clock = container_of(ptp, struct mlx5_clock,
+ 						ptp_info);
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
  
  	if (delta < 0) {
  		neg_adj = 1;
@@@ -240,68 -184,79 +305,87 @@@
  	return 0;
  }
  
- static int mlx5e_extts_configure(struct ptp_clock_info *ptp,
- 				 struct ptp_clock_request *rq,
- 				 int on)
+ static int mlx5_extts_configure(struct ptp_clock_info *ptp,
+ 				struct ptp_clock_request *rq,
+ 				int on)
  {
- 	struct mlx5e_tstamp *tstamp =
- 		container_of(ptp, struct mlx5e_tstamp, ptp_info);
- 	struct mlx5e_priv *priv =
- 		container_of(tstamp, struct mlx5e_priv, tstamp);
+ 	struct mlx5_clock *clock =
+ 			container_of(ptp, struct mlx5_clock, ptp_info);
+ 	struct mlx5_core_dev *mdev =
+ 			container_of(clock, struct mlx5_core_dev, clock);
  	u32 in[MLX5_ST_SZ_DW(mtpps_reg)] = {0};
 -	u32 field_select = 0;
 -	u8 pin_mode = 0;
  	u8 pattern = 0;
  	int pin = -1;
  	int err = 0;
  
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +	if (!MLX5_CAP_GEN(priv->mdev, pps) ||
 +	    !MLX5_CAP_GEN(priv->mdev, pps_modify))
++=======
+ 	if (!MLX5_PPS_CAP(mdev))
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
  		return -EOPNOTSUPP;
  
- 	if (rq->extts.index >= tstamp->ptp_info.n_pins)
+ 	if (rq->extts.index >= clock->ptp_info.n_pins)
  		return -EINVAL;
  
  	if (on) {
- 		pin = ptp_find_pin(tstamp->ptp, PTP_PF_EXTTS, rq->extts.index);
+ 		pin = ptp_find_pin(clock->ptp, PTP_PF_EXTTS, rq->extts.index);
  		if (pin < 0)
  			return -EBUSY;
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
++=======
+ 		pin_mode = MLX5_PIN_MODE_IN;
+ 		pattern = !!(rq->extts.flags & PTP_FALLING_EDGE);
+ 		field_select = MLX5_MTPPS_FS_PIN_MODE |
+ 			       MLX5_MTPPS_FS_PATTERN |
+ 			       MLX5_MTPPS_FS_ENABLE;
+ 	} else {
+ 		pin = rq->extts.index;
+ 		field_select = MLX5_MTPPS_FS_ENABLE;
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
  	}
  
 +	if (rq->extts.flags & PTP_FALLING_EDGE)
 +		pattern = 1;
 +
  	MLX5_SET(mtpps_reg, in, pin, pin);
 -	MLX5_SET(mtpps_reg, in, pin_mode, pin_mode);
 +	MLX5_SET(mtpps_reg, in, pin_mode, MLX5E_PIN_MODE_IN);
  	MLX5_SET(mtpps_reg, in, pattern, pattern);
  	MLX5_SET(mtpps_reg, in, enable, on);
 -	MLX5_SET(mtpps_reg, in, field_select, field_select);
  
- 	err = mlx5_set_mtpps(priv->mdev, in, sizeof(in));
+ 	err = mlx5_set_mtpps(mdev, in, sizeof(in));
  	if (err)
  		return err;
  
- 	return mlx5_set_mtppse(priv->mdev, pin, 0,
- 			       MLX5E_EVENT_MODE_REPETETIVE & on);
+ 	return mlx5_set_mtppse(mdev, pin, 0,
+ 			       MLX5_EVENT_MODE_REPETETIVE & on);
  }
  
- static int mlx5e_perout_configure(struct ptp_clock_info *ptp,
- 				  struct ptp_clock_request *rq,
- 				  int on)
+ static int mlx5_perout_configure(struct ptp_clock_info *ptp,
+ 				 struct ptp_clock_request *rq,
+ 				 int on)
  {
- 	struct mlx5e_tstamp *tstamp =
- 		container_of(ptp, struct mlx5e_tstamp, ptp_info);
- 	struct mlx5e_priv *priv =
- 		container_of(tstamp, struct mlx5e_priv, tstamp);
+ 	struct mlx5_clock *clock =
+ 			container_of(ptp, struct mlx5_clock, ptp_info);
+ 	struct mlx5_core_dev *mdev =
+ 			container_of(clock, struct mlx5_core_dev, clock);
  	u32 in[MLX5_ST_SZ_DW(mtpps_reg)] = {0};
 -	u64 nsec_now, nsec_delta, time_stamp = 0;
 +	u64 nsec_now, nsec_delta, time_stamp;
  	u64 cycles_now, cycles_delta;
  	struct timespec64 ts;
  	unsigned long flags;
 -	u32 field_select = 0;
 -	u8 pin_mode = 0;
 -	u8 pattern = 0;
  	int pin = -1;
 -	int err = 0;
  	s64 ns;
  
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +	if (!MLX5_CAP_GEN(priv->mdev, pps_modify))
++=======
+ 	if (!MLX5_PPS_CAP(mdev))
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
  		return -EOPNOTSUPP;
  
- 	if (rq->perout.index >= tstamp->ptp_info.n_pins)
+ 	if (rq->perout.index >= clock->ptp_info.n_pins)
  		return -EINVAL;
  
  	if (on) {
@@@ -309,43 -264,73 +393,100 @@@
  				   rq->perout.index);
  		if (pin < 0)
  			return -EBUSY;
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
++=======
+ 
+ 		pin_mode = MLX5_PIN_MODE_OUT;
+ 		pattern = MLX5_OUT_PATTERN_PERIODIC;
+ 		ts.tv_sec = rq->perout.period.sec;
+ 		ts.tv_nsec = rq->perout.period.nsec;
+ 		ns = timespec64_to_ns(&ts);
+ 
+ 		if ((ns >> 1) != 500000000LL)
+ 			return -EINVAL;
+ 
+ 		ts.tv_sec = rq->perout.start.sec;
+ 		ts.tv_nsec = rq->perout.start.nsec;
+ 		ns = timespec64_to_ns(&ts);
+ 		cycles_now = mlx5_read_internal_timer(mdev);
+ 		write_lock_irqsave(&clock->lock, flags);
+ 		nsec_now = timecounter_cyc2time(&clock->tc, cycles_now);
+ 		nsec_delta = ns - nsec_now;
+ 		cycles_delta = div64_u64(nsec_delta << clock->cycles.shift,
+ 					 clock->cycles.mult);
+ 		write_unlock_irqrestore(&clock->lock, flags);
+ 		time_stamp = cycles_now + cycles_delta;
+ 		field_select = MLX5_MTPPS_FS_PIN_MODE |
+ 			       MLX5_MTPPS_FS_PATTERN |
+ 			       MLX5_MTPPS_FS_ENABLE |
+ 			       MLX5_MTPPS_FS_TIME_STAMP;
+ 	} else {
+ 		pin = rq->perout.index;
+ 		field_select = MLX5_MTPPS_FS_ENABLE;
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
  	}
  
 +	ts.tv_sec = rq->perout.period.sec;
 +	ts.tv_nsec = rq->perout.period.nsec;
 +	ns = timespec64_to_ns(&ts);
 +	if (on)
 +		if ((ns >> 1) != 500000000LL)
 +			return -EINVAL;
 +	ts.tv_sec = rq->perout.start.sec;
 +	ts.tv_nsec = rq->perout.start.nsec;
 +	ns = timespec64_to_ns(&ts);
 +	cycles_now = mlx5_read_internal_timer(tstamp->mdev);
 +	write_lock_irqsave(&tstamp->lock, flags);
 +	nsec_now = timecounter_cyc2time(&tstamp->clock, cycles_now);
 +	nsec_delta = ns - nsec_now;
 +	cycles_delta = div64_u64(nsec_delta << tstamp->cycles.shift,
 +				 tstamp->cycles.mult);
 +	write_unlock_irqrestore(&tstamp->lock, flags);
 +	time_stamp = cycles_now + cycles_delta;
  	MLX5_SET(mtpps_reg, in, pin, pin);
 -	MLX5_SET(mtpps_reg, in, pin_mode, pin_mode);
 -	MLX5_SET(mtpps_reg, in, pattern, pattern);
 +	MLX5_SET(mtpps_reg, in, pin_mode, MLX5E_PIN_MODE_OUT);
 +	MLX5_SET(mtpps_reg, in, pattern, MLX5E_OUT_PATTERN_PERIODIC);
  	MLX5_SET(mtpps_reg, in, enable, on);
  	MLX5_SET64(mtpps_reg, in, time_stamp, time_stamp);
 -	MLX5_SET(mtpps_reg, in, field_select, field_select);
  
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +	return mlx5_set_mtpps(priv->mdev, in, sizeof(in));
++=======
+ 	err = mlx5_set_mtpps(mdev, in, sizeof(in));
+ 	if (err)
+ 		return err;
+ 
+ 	return mlx5_set_mtppse(mdev, pin, 0,
+ 			       MLX5_EVENT_MODE_REPETETIVE & on);
  }
  
- static int mlx5e_ptp_enable(struct ptp_clock_info *ptp,
- 			    struct ptp_clock_request *rq,
- 			    int on)
+ static int mlx5_pps_configure(struct ptp_clock_info *ptp,
+ 			      struct ptp_clock_request *rq,
+ 			      int on)
+ {
+ 	struct mlx5_clock *clock =
+ 			container_of(ptp, struct mlx5_clock, ptp_info);
+ 
+ 	clock->pps_info.enabled = !!on;
+ 	return 0;
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
+ }
+ 
+ static int mlx5_ptp_enable(struct ptp_clock_info *ptp,
+ 			   struct ptp_clock_request *rq,
+ 			   int on)
  {
  	switch (rq->type) {
  	case PTP_CLK_REQ_EXTTS:
- 		return mlx5e_extts_configure(ptp, rq, on);
+ 		return mlx5_extts_configure(ptp, rq, on);
  	case PTP_CLK_REQ_PEROUT:
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +		return mlx5e_perout_configure(ptp, rq, on);
++=======
+ 		return mlx5_perout_configure(ptp, rq, on);
+ 	case PTP_CLK_REQ_PPS:
+ 		return mlx5_pps_configure(ptp, rq, on);
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
  	default:
  		return -EOPNOTSUPP;
  	}
@@@ -384,61 -364,96 +520,118 @@@ static int mlx5_init_pin_config(struct 
  {
  	int i;
  
- 	tstamp->ptp_info.pin_config =
- 		kzalloc(sizeof(*tstamp->ptp_info.pin_config) *
- 			       tstamp->ptp_info.n_pins, GFP_KERNEL);
- 	if (!tstamp->ptp_info.pin_config)
+ 	clock->ptp_info.pin_config =
+ 			kzalloc(sizeof(*clock->ptp_info.pin_config) *
+ 				clock->ptp_info.n_pins, GFP_KERNEL);
+ 	if (!clock->ptp_info.pin_config)
  		return -ENOMEM;
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +	tstamp->ptp_info.enable = mlx5e_ptp_enable;
 +	tstamp->ptp_info.verify = mlx5e_ptp_verify;
- 
- 	for (i = 0; i < tstamp->ptp_info.n_pins; i++) {
- 		snprintf(tstamp->ptp_info.pin_config[i].name,
- 			 sizeof(tstamp->ptp_info.pin_config[i].name),
++=======
+ 	clock->ptp_info.enable = mlx5_ptp_enable;
+ 	clock->ptp_info.verify = mlx5_ptp_verify;
+ 	clock->ptp_info.pps = 1;
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
+ 
+ 	for (i = 0; i < clock->ptp_info.n_pins; i++) {
+ 		snprintf(clock->ptp_info.pin_config[i].name,
+ 			 sizeof(clock->ptp_info.pin_config[i].name),
  			 "mlx5_pps%d", i);
- 		tstamp->ptp_info.pin_config[i].index = i;
- 		tstamp->ptp_info.pin_config[i].func = PTP_PF_NONE;
- 		tstamp->ptp_info.pin_config[i].chan = i;
+ 		clock->ptp_info.pin_config[i].index = i;
+ 		clock->ptp_info.pin_config[i].func = PTP_PF_NONE;
+ 		clock->ptp_info.pin_config[i].chan = i;
  	}
  
  	return 0;
  }
  
- static void mlx5e_get_pps_caps(struct mlx5e_priv *priv,
- 			       struct mlx5e_tstamp *tstamp)
+ static void mlx5_get_pps_caps(struct mlx5_core_dev *mdev)
  {
+ 	struct mlx5_clock *clock = &mdev->clock;
  	u32 out[MLX5_ST_SZ_DW(mtpps_reg)] = {0};
  
- 	mlx5_query_mtpps(priv->mdev, out, sizeof(out));
+ 	mlx5_query_mtpps(mdev, out, sizeof(out));
  
- 	tstamp->ptp_info.n_pins = MLX5_GET(mtpps_reg, out,
- 					   cap_number_of_pps_pins);
- 	tstamp->ptp_info.n_ext_ts = MLX5_GET(mtpps_reg, out,
- 					     cap_max_num_of_pps_in_pins);
- 	tstamp->ptp_info.n_per_out = MLX5_GET(mtpps_reg, out,
- 					      cap_max_num_of_pps_out_pins);
+ 	clock->ptp_info.n_pins = MLX5_GET(mtpps_reg, out,
+ 					  cap_number_of_pps_pins);
+ 	clock->ptp_info.n_ext_ts = MLX5_GET(mtpps_reg, out,
+ 					    cap_max_num_of_pps_in_pins);
+ 	clock->ptp_info.n_per_out = MLX5_GET(mtpps_reg, out,
+ 					     cap_max_num_of_pps_out_pins);
  
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +	tstamp->pps_pin_caps[0] = MLX5_GET(mtpps_reg, out, cap_pin_0_mode);
 +	tstamp->pps_pin_caps[1] = MLX5_GET(mtpps_reg, out, cap_pin_1_mode);
 +	tstamp->pps_pin_caps[2] = MLX5_GET(mtpps_reg, out, cap_pin_2_mode);
 +	tstamp->pps_pin_caps[3] = MLX5_GET(mtpps_reg, out, cap_pin_3_mode);
 +	tstamp->pps_pin_caps[4] = MLX5_GET(mtpps_reg, out, cap_pin_4_mode);
 +	tstamp->pps_pin_caps[5] = MLX5_GET(mtpps_reg, out, cap_pin_5_mode);
 +	tstamp->pps_pin_caps[6] = MLX5_GET(mtpps_reg, out, cap_pin_6_mode);
 +	tstamp->pps_pin_caps[7] = MLX5_GET(mtpps_reg, out, cap_pin_7_mode);
++=======
+ 	clock->pps_info.pin_caps[0] = MLX5_GET(mtpps_reg, out, cap_pin_0_mode);
+ 	clock->pps_info.pin_caps[1] = MLX5_GET(mtpps_reg, out, cap_pin_1_mode);
+ 	clock->pps_info.pin_caps[2] = MLX5_GET(mtpps_reg, out, cap_pin_2_mode);
+ 	clock->pps_info.pin_caps[3] = MLX5_GET(mtpps_reg, out, cap_pin_3_mode);
+ 	clock->pps_info.pin_caps[4] = MLX5_GET(mtpps_reg, out, cap_pin_4_mode);
+ 	clock->pps_info.pin_caps[5] = MLX5_GET(mtpps_reg, out, cap_pin_5_mode);
+ 	clock->pps_info.pin_caps[6] = MLX5_GET(mtpps_reg, out, cap_pin_6_mode);
+ 	clock->pps_info.pin_caps[7] = MLX5_GET(mtpps_reg, out, cap_pin_7_mode);
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
  }
  
- void mlx5e_pps_event_handler(struct mlx5e_priv *priv,
- 			     struct ptp_clock_event *event)
+ void mlx5_pps_event(struct mlx5_core_dev *mdev,
+ 		    struct mlx5_eqe *eqe)
  {
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +	struct mlx5e_tstamp *tstamp = &priv->tstamp;
 +
 +	ptp_clock_event(tstamp->ptp, event);
++=======
+ 	struct mlx5_clock *clock = &mdev->clock;
+ 	struct ptp_clock_event ptp_event;
+ 	struct timespec64 ts;
+ 	u64 nsec_now, nsec_delta;
+ 	u64 cycles_now, cycles_delta;
+ 	int pin = eqe->data.pps.pin;
+ 	s64 ns;
+ 	unsigned long flags;
+ 
+ 	switch (clock->ptp_info.pin_config[pin].func) {
+ 	case PTP_PF_EXTTS:
+ 		if (clock->pps_info.enabled) {
+ 			ptp_event.type = PTP_CLOCK_PPSUSR;
+ 			ptp_event.pps_times.ts_real = ns_to_timespec64(eqe->data.pps.time_stamp);
+ 		} else {
+ 			ptp_event.type = PTP_CLOCK_EXTTS;
+ 		}
+ 		ptp_clock_event(clock->ptp, &ptp_event);
+ 		break;
+ 	case PTP_PF_PEROUT:
+ 		mlx5_ptp_gettime(&clock->ptp_info, &ts);
+ 		cycles_now = mlx5_read_internal_timer(mdev);
+ 		ts.tv_sec += 1;
+ 		ts.tv_nsec = 0;
+ 		ns = timespec64_to_ns(&ts);
+ 		write_lock_irqsave(&clock->lock, flags);
+ 		nsec_now = timecounter_cyc2time(&clock->tc, cycles_now);
+ 		nsec_delta = ns - nsec_now;
+ 		cycles_delta = div64_u64(nsec_delta << clock->cycles.shift,
+ 					 clock->cycles.mult);
+ 		clock->pps_info.start[pin] = cycles_now + cycles_delta;
+ 		schedule_work(&clock->pps_info.out_work);
+ 		write_unlock_irqrestore(&clock->lock, flags);
+ 		break;
+ 	default:
+ 		mlx5_core_err(mdev, " Unhandled event\n");
+ 	}
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
  }
  
- void mlx5e_timestamp_init(struct mlx5e_priv *priv)
+ void mlx5_init_clock(struct mlx5_core_dev *mdev)
  {
- 	struct mlx5e_tstamp *tstamp = &priv->tstamp;
+ 	struct mlx5_clock *clock = &mdev->clock;
  	u64 ns;
  	u64 frac = 0;
  	u32 dev_freq;
@@@ -464,56 -477,49 +655,75 @@@
  	/* Calculate period in seconds to call the overflow watchdog - to make
  	 * sure counter is checked at least once every wrap around.
  	 */
- 	ns = cyclecounter_cyc2ns(&tstamp->cycles, tstamp->cycles.mask,
+ 	ns = cyclecounter_cyc2ns(&clock->cycles, clock->cycles.mask,
  				 frac, &frac);
  	do_div(ns, NSEC_PER_SEC / 2 / HZ);
- 	tstamp->overflow_period = ns;
+ 	clock->overflow_period = ns;
  
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +	INIT_DELAYED_WORK(&tstamp->overflow_work, mlx5e_timestamp_overflow);
 +	if (tstamp->overflow_period)
 +		schedule_delayed_work(&tstamp->overflow_work, 0);
++=======
+ 	INIT_WORK(&clock->pps_info.out_work, mlx5_pps_out);
+ 	INIT_DELAYED_WORK(&clock->overflow_work, mlx5_timestamp_overflow);
+ 	if (clock->overflow_period)
+ 		schedule_delayed_work(&clock->overflow_work, 0);
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
  	else
- 		mlx5_core_warn(priv->mdev, "invalid overflow period, overflow_work is not scheduled\n");
+ 		mlx5_core_warn(mdev, "invalid overflow period, overflow_work is not scheduled\n");
  
  	/* Configure the PHC */
- 	tstamp->ptp_info = mlx5e_ptp_clock_info;
- 	snprintf(tstamp->ptp_info.name, 16, "mlx5 ptp");
+ 	clock->ptp_info = mlx5_ptp_clock_info;
  
  	/* Initialize 1PPS data structures */
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +#define MAX_PIN_NUM	8
 +	tstamp->pps_pin_caps = kzalloc(sizeof(u8) * MAX_PIN_NUM, GFP_KERNEL);
 +	if (tstamp->pps_pin_caps) {
 +		if (MLX5_CAP_GEN(priv->mdev, pps))
 +			mlx5e_get_pps_caps(priv, tstamp);
 +		if (tstamp->ptp_info.n_pins)
 +			mlx5e_init_pin_config(tstamp);
 +	} else {
 +		mlx5_core_warn(priv->mdev, "1PPS initialization failed\n");
 +	}
- 
- 	tstamp->ptp = ptp_clock_register(&tstamp->ptp_info,
- 					 &priv->mdev->pdev->dev);
- 	if (IS_ERR(tstamp->ptp)) {
- 		mlx5_core_warn(priv->mdev, "ptp_clock_register failed %ld\n",
- 			       PTR_ERR(tstamp->ptp));
- 		tstamp->ptp = NULL;
++=======
+ 	if (MLX5_PPS_CAP(mdev))
+ 		mlx5_get_pps_caps(mdev);
+ 	if (clock->ptp_info.n_pins)
+ 		mlx5_init_pin_config(clock);
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
+ 
+ 	clock->ptp = ptp_clock_register(&clock->ptp_info,
+ 					&mdev->pdev->dev);
+ 	if (IS_ERR(clock->ptp)) {
+ 		mlx5_core_warn(mdev, "ptp_clock_register failed %ld\n",
+ 			       PTR_ERR(clock->ptp));
+ 		clock->ptp = NULL;
  	}
  }
  
- void mlx5e_timestamp_cleanup(struct mlx5e_priv *priv)
+ void mlx5_cleanup_clock(struct mlx5_core_dev *mdev)
  {
- 	struct mlx5e_tstamp *tstamp = &priv->tstamp;
+ 	struct mlx5_clock *clock = &mdev->clock;
  
- 	if (!MLX5_CAP_GEN(priv->mdev, device_frequency_khz))
+ 	if (!MLX5_CAP_GEN(mdev, device_frequency_khz))
  		return;
  
- 	if (priv->tstamp.ptp) {
- 		ptp_clock_unregister(priv->tstamp.ptp);
- 		priv->tstamp.ptp = NULL;
+ 	if (clock->ptp) {
+ 		ptp_clock_unregister(clock->ptp);
+ 		clock->ptp = NULL;
  	}
  
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
 +	kfree(tstamp->pps_pin_caps);
 +	kfree(tstamp->ptp_info.pin_config);
 +
 +	cancel_delayed_work_sync(&tstamp->overflow_work);
++=======
+ 	cancel_work_sync(&clock->pps_info.out_work);
+ 	cancel_delayed_work_sync(&clock->overflow_work);
+ 	kfree(clock->ptp_info.pin_config);
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section):drivers/net/ethernet/mellanox/mlx5/core/lib/clock.c
  }
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
index a12add73652e,81a112e40fe3..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
@@@ -1287,13 -1414,13 +1287,17 @@@ static int mlx5e_set_pauseparam(struct 
  	return err;
  }
  
 -int mlx5e_ethtool_get_ts_info(struct mlx5e_priv *priv,
 -			      struct ethtool_ts_info *info)
 +static int mlx5e_get_ts_info(struct net_device *dev,
 +			     struct ethtool_ts_info *info)
  {
++<<<<<<< HEAD
 +	struct mlx5e_priv *priv = netdev_priv(dev);
++=======
+ 	struct mlx5_core_dev *mdev = priv->mdev;
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  	int ret;
  
 -	ret = ethtool_op_get_ts_info(priv->netdev, info);
 +	ret = ethtool_op_get_ts_info(dev, info);
  	if (ret)
  		return ret;
  
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index 9035c90d5238,6df00dd9745a..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@@ -362,15 -382,6 +360,18 @@@ static void mlx5e_async_event(struct ml
  	case MLX5_DEV_EVENT_PORT_DOWN:
  		queue_work(priv->wq, &priv->update_carrier_work);
  		break;
++<<<<<<< HEAD
 +	case MLX5_DEV_EVENT_PPS:
 +		eqe = (struct mlx5_eqe *)param;
 +		ptp_event.type = PTP_CLOCK_EXTTS;
 +		ptp_event.index = eqe->data.pps.pin;
 +		ptp_event.timestamp =
 +			timecounter_cyc2time(&priv->tstamp.clock,
 +					     be64_to_cpu(eqe->data.pps.time_stamp));
 +		mlx5e_pps_event_handler(vpriv, &ptp_event);
 +		break;
++=======
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  	default:
  		break;
  	}
@@@ -563,18 -571,42 +564,23 @@@ static int mlx5e_create_rq(struct mlx5e
  
  	wq_sz = mlx5_wq_ll_get_size(&rq->wq);
  
 -	rq->wq_type = params->rq_wq_type;
 +	rq->wq_type = priv->params.rq_wq_type;
  	rq->pdev    = c->pdev;
  	rq->netdev  = c->netdev;
++<<<<<<< HEAD
 +	rq->tstamp  = &priv->tstamp;
++=======
+ 	rq->tstamp  = c->tstamp;
+ 	rq->clock   = &mdev->clock;
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  	rq->channel = c;
  	rq->ix      = c->ix;
 -	rq->mdev    = mdev;
 -
 -	rq->xdp_prog = params->xdp_prog ? bpf_prog_inc(params->xdp_prog) : NULL;
 -	if (IS_ERR(rq->xdp_prog)) {
 -		err = PTR_ERR(rq->xdp_prog);
 -		rq->xdp_prog = NULL;
 -		goto err_rq_wq_destroy;
 -	}
 +	rq->priv    = c->priv;
  
 -	rq->buff.map_dir = rq->xdp_prog ? DMA_BIDIRECTIONAL : DMA_FROM_DEVICE;
 -	rq->buff.headroom = params->rq_headroom;
 -
 -	switch (rq->wq_type) {
 +	switch (priv->params.rq_wq_type) {
  	case MLX5_WQ_TYPE_LINKED_LIST_STRIDING_RQ:
 -
 -		rq->post_wqes = mlx5e_post_rx_mpwqes;
 -		rq->dealloc_wqe = mlx5e_dealloc_rx_mpwqe;
 -
 -		rq->handle_rx_cqe = c->priv->profile->rx_handlers.handle_rx_cqe_mpwqe;
 -#ifdef CONFIG_MLX5_EN_IPSEC
 -		if (MLX5_IPSEC_DEV(mdev)) {
 +		if (mlx5e_is_vf_vport_rep(priv)) {
  			err = -EINVAL;
 -			netdev_err(c->netdev, "MPWQE RQ with IPSec offload not supported\n");
 -			goto err_rq_wq_destroy;
 -		}
 -#endif
 -		if (!rq->handle_rx_cqe) {
 -			err = -EINVAL;
 -			netdev_err(c->netdev, "RX handler of MPWQE RQ is not set, err %d\n", err);
  			goto err_rq_wq_destroy;
  		}
  
@@@ -920,76 -1102,35 +926,81 @@@ static int mlx5e_alloc_sq_txq_db(struc
  	return 0;
  }
  
 -static int mlx5e_alloc_txqsq(struct mlx5e_channel *c,
 -			     int txq_ix,
 -			     struct mlx5e_params *params,
 -			     struct mlx5e_sq_param *param,
 -			     struct mlx5e_txqsq *sq)
 +static void mlx5e_free_sq_db(struct mlx5e_sq *sq)
  {
 -	void *sqc_wq               = MLX5_ADDR_OF(sqc, param->sqc, wq);
 -	struct mlx5_core_dev *mdev = c->mdev;
 +	switch (sq->type) {
 +	case MLX5E_SQ_TXQ:
 +		mlx5e_free_sq_txq_db(sq);
 +		break;
 +	case MLX5E_SQ_ICO:
 +		mlx5e_free_sq_ico_db(sq);
 +		break;
 +	}
 +}
 +
 +static int mlx5e_alloc_sq_db(struct mlx5e_sq *sq, int numa)
 +{
 +	switch (sq->type) {
 +	case MLX5E_SQ_TXQ:
 +		return mlx5e_alloc_sq_txq_db(sq, numa);
 +	case MLX5E_SQ_ICO:
 +		return mlx5e_alloc_sq_ico_db(sq, numa);
 +	}
 +
 +	return 0;
 +}
 +
 +static int mlx5e_create_sq(struct mlx5e_channel *c,
 +			   int tc,
 +			   struct mlx5e_sq_param *param,
 +			   struct mlx5e_sq *sq)
 +{
 +	struct mlx5e_priv *priv = c->priv;
 +	struct mlx5_core_dev *mdev = priv->mdev;
 +
 +	void *sqc = param->sqc;
 +	void *sqc_wq = MLX5_ADDR_OF(sqc, sqc, wq);
 +	u16 sq_max_wqebbs;
  	int err;
  
 +	sq->type      = param->type;
  	sq->pdev      = c->pdev;
++<<<<<<< HEAD
 +	sq->tstamp    = &priv->tstamp;
++=======
+ 	sq->tstamp    = c->tstamp;
+ 	sq->clock     = &mdev->clock;
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  	sq->mkey_be   = c->mkey_be;
  	sq->channel   = c;
 -	sq->txq_ix    = txq_ix;
 -	sq->uar_map   = mdev->mlx5e_res.bfreg.map;
 -	sq->max_inline      = params->tx_max_inline;
 -	sq->min_inline_mode = params->tx_min_inline_mode;
 -	if (MLX5_IPSEC_DEV(c->priv->mdev))
 -		set_bit(MLX5E_SQ_STATE_IPSEC, &sq->state);
 -
 -	param->wq.db_numa_node = mlx5e_get_node(c->priv, c->ix);
 -	err = mlx5_wq_cyc_create(mdev, &param->wq, sqc_wq, &sq->wq, &sq->wq_ctrl);
 +	sq->tc        = tc;
 +
 +	err = mlx5_alloc_map_uar(mdev, &sq->uar, !!MLX5_CAP_GEN(mdev, bf));
  	if (err)
  		return err;
 -	sq->wq.db    = &sq->wq.db[MLX5_SND_DBR];
  
 -	err = mlx5e_alloc_txqsq_db(sq, mlx5e_get_node(c->priv, c->ix));
 +	sq->uar_map = sq->bfreg.map;
 +	param->wq.db_numa_node = cpu_to_node(c->cpu);
 +
 +	err = mlx5_wq_cyc_create(mdev, &param->wq, sqc_wq, &sq->wq,
 +				 &sq->wq_ctrl);
 +	if (err)
 +		goto err_unmap_free_uar;
 +
 +	sq->wq.db       = &sq->wq.db[MLX5_SND_DBR];
 +	if (sq->uar.bf_map) {
 +		set_bit(MLX5E_SQ_STATE_BF_ENABLE, &sq->state);
 +		sq->uar_map = sq->uar.bf_map;
 +	} else {
 +		sq->uar_map = sq->uar.map;
 +	}
 +	sq->bf_buf_size = (1 << MLX5_CAP_GEN(mdev, log_bf_reg_size)) / 2;
 +	sq->max_inline  = param->max_inline;
 +	sq->min_inline_mode =
 +		MLX5_CAP_ETH(mdev, wqe_inline_mode) == MLX5_CAP_INLINE_MODE_VPORT_CONTEXT ?
 +		param->min_inline_mode : 0;
 +
 +	err = mlx5e_alloc_sq_db(sq, cpu_to_node(c->cpu));
  	if (err)
  		goto err_sq_wq_destroy;
  
@@@ -2207,6 -2584,98 +2218,101 @@@ static void mlx5e_netdev_set_tcs(struc
  		netdev_set_tc_queue(netdev, tc, nch, 0);
  }
  
++<<<<<<< HEAD
++=======
+ static void mlx5e_build_channels_tx_maps(struct mlx5e_priv *priv)
+ {
+ 	struct mlx5e_channel *c;
+ 	struct mlx5e_txqsq *sq;
+ 	int i, tc;
+ 
+ 	for (i = 0; i < priv->channels.num; i++)
+ 		for (tc = 0; tc < priv->profile->max_tc; tc++)
+ 			priv->channel_tc2txq[i][tc] = i + tc * priv->channels.num;
+ 
+ 	for (i = 0; i < priv->channels.num; i++) {
+ 		c = priv->channels.c[i];
+ 		for (tc = 0; tc < c->num_tc; tc++) {
+ 			sq = &c->sq[tc];
+ 			priv->txq2sq[sq->txq_ix] = sq;
+ 		}
+ 	}
+ }
+ 
+ void mlx5e_activate_priv_channels(struct mlx5e_priv *priv)
+ {
+ 	int num_txqs = priv->channels.num * priv->channels.params.num_tc;
+ 	struct net_device *netdev = priv->netdev;
+ 
+ 	mlx5e_netdev_set_tcs(netdev);
+ 	netif_set_real_num_tx_queues(netdev, num_txqs);
+ 	netif_set_real_num_rx_queues(netdev, priv->channels.num);
+ 
+ 	mlx5e_build_channels_tx_maps(priv);
+ 	mlx5e_activate_channels(&priv->channels);
+ 	netif_tx_start_all_queues(priv->netdev);
+ 
+ 	if (MLX5_VPORT_MANAGER(priv->mdev))
+ 		mlx5e_add_sqs_fwd_rules(priv);
+ 
+ 	mlx5e_wait_channels_min_rx_wqes(&priv->channels);
+ 	mlx5e_redirect_rqts_to_channels(priv, &priv->channels);
+ }
+ 
+ void mlx5e_deactivate_priv_channels(struct mlx5e_priv *priv)
+ {
+ 	mlx5e_redirect_rqts_to_drop(priv);
+ 
+ 	if (MLX5_VPORT_MANAGER(priv->mdev))
+ 		mlx5e_remove_sqs_fwd_rules(priv);
+ 
+ 	/* FIXME: This is a W/A only for tx timeout watch dog false alarm when
+ 	 * polling for inactive tx queues.
+ 	 */
+ 	netif_tx_stop_all_queues(priv->netdev);
+ 	netif_tx_disable(priv->netdev);
+ 	mlx5e_deactivate_channels(&priv->channels);
+ }
+ 
+ void mlx5e_switch_priv_channels(struct mlx5e_priv *priv,
+ 				struct mlx5e_channels *new_chs,
+ 				mlx5e_fp_hw_modify hw_modify)
+ {
+ 	struct net_device *netdev = priv->netdev;
+ 	int new_num_txqs;
+ 	int carrier_ok;
+ 	new_num_txqs = new_chs->num * new_chs->params.num_tc;
+ 
+ 	carrier_ok = netif_carrier_ok(netdev);
+ 	netif_carrier_off(netdev);
+ 
+ 	if (new_num_txqs < netdev->real_num_tx_queues)
+ 		netif_set_real_num_tx_queues(netdev, new_num_txqs);
+ 
+ 	mlx5e_deactivate_priv_channels(priv);
+ 	mlx5e_close_channels(&priv->channels);
+ 
+ 	priv->channels = *new_chs;
+ 
+ 	/* New channels are ready to roll, modify HW settings if needed */
+ 	if (hw_modify)
+ 		hw_modify(priv);
+ 
+ 	mlx5e_refresh_tirs(priv, false);
+ 	mlx5e_activate_priv_channels(priv);
+ 
+ 	/* return carrier back if needed */
+ 	if (carrier_ok)
+ 		netif_carrier_on(netdev);
+ }
+ 
+ void mlx5e_timestamp_set(struct mlx5e_priv *priv)
+ {
+ 	priv->tstamp.tx_type   = HWTSTAMP_TX_OFF;
+ 	priv->tstamp.rx_filter = HWTSTAMP_FILTER_NONE;
+ }
+ 
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  int mlx5e_open_locked(struct net_device *netdev)
  {
  	struct mlx5e_priv *priv = netdev_priv(netdev);
@@@ -2216,29 -2683,15 +2322,37 @@@
  
  	set_bit(MLX5E_STATE_OPENED, &priv->state);
  
 -	err = mlx5e_open_channels(priv, &priv->channels);
 -	if (err)
 +	mlx5e_netdev_set_tcs(netdev);
 +
++<<<<<<< HEAD
 +	num_txqs = priv->params.num_channels * priv->params.num_tc;
 +	netif_set_real_num_tx_queues(netdev, num_txqs);
 +	netif_set_real_num_rx_queues(netdev, priv->params.num_channels);
 +
 +	err = mlx5e_open_channels(priv);
 +	if (err) {
 +		netdev_err(netdev, "%s: mlx5e_open_channels failed, %d\n",
 +			   __func__, err);
  		goto err_clear_state_opened_flag;
 +	}
 +
 +	err = mlx5e_refresh_tirs_self_loopback(priv->mdev, false);
 +	if (err) {
 +		netdev_err(netdev, "%s: mlx5e_refresh_tirs_self_loopback_enable failed, %d\n",
 +			   __func__, err);
 +		goto err_close_channels;
 +	}
  
 +	mlx5e_redirect_rqts(priv);
 +	mlx5e_update_carrier(priv);
 +	mlx5e_timestamp_init(priv);
++=======
+ 	mlx5e_refresh_tirs(priv, false);
+ 	mlx5e_activate_priv_channels(priv);
+ 	if (priv->profile->update_carrier)
+ 		priv->profile->update_carrier(priv);
+ 	mlx5e_timestamp_set(priv);
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  
  	if (priv->profile->update_stats)
  		queue_delayed_work(priv->wq, &priv->update_stats_work, 0);
@@@ -2282,13 -2729,9 +2396,16 @@@ int mlx5e_close_locked(struct net_devic
  
  	clear_bit(MLX5E_STATE_OPENED, &priv->state);
  
++<<<<<<< HEAD
 +	if (MLX5_CAP_GEN(mdev, vport_group_manager))
 +		mlx5e_remove_sqs_fwd_rules(priv);
 +
 +	mlx5e_timestamp_cleanup(priv);
++=======
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  	netif_carrier_off(priv->netdev);
 -	mlx5e_deactivate_priv_channels(priv);
 -	mlx5e_close_channels(&priv->channels);
 +	mlx5e_redirect_rqts(priv);
 +	mlx5e_close_channels(priv);
  
  	return 0;
  }
@@@ -2910,13 -3400,89 +3027,87 @@@ static int mlx5e_change_mtu(struct net_
  	return err;
  }
  
+ int mlx5e_hwstamp_set(struct mlx5e_priv *priv, struct ifreq *ifr)
+ {
+ 	struct hwtstamp_config config;
+ 	int err;
+ 
+ 	if (!MLX5_CAP_GEN(priv->mdev, device_frequency_khz))
+ 		return -EOPNOTSUPP;
+ 
+ 	if (copy_from_user(&config, ifr->ifr_data, sizeof(config)))
+ 		return -EFAULT;
+ 
+ 	/* TX HW timestamp */
+ 	switch (config.tx_type) {
+ 	case HWTSTAMP_TX_OFF:
+ 	case HWTSTAMP_TX_ON:
+ 		break;
+ 	default:
+ 		return -ERANGE;
+ 	}
+ 
+ 	mutex_lock(&priv->state_lock);
+ 	/* RX HW timestamp */
+ 	switch (config.rx_filter) {
+ 	case HWTSTAMP_FILTER_NONE:
+ 		/* Reset CQE compression to Admin default */
+ 		mlx5e_modify_rx_cqe_compression_locked(priv, priv->channels.params.rx_cqe_compress_def);
+ 		break;
+ 	case HWTSTAMP_FILTER_ALL:
+ 	case HWTSTAMP_FILTER_SOME:
+ 	case HWTSTAMP_FILTER_PTP_V1_L4_EVENT:
+ 	case HWTSTAMP_FILTER_PTP_V1_L4_SYNC:
+ 	case HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:
+ 	case HWTSTAMP_FILTER_PTP_V2_L4_EVENT:
+ 	case HWTSTAMP_FILTER_PTP_V2_L4_SYNC:
+ 	case HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:
+ 	case HWTSTAMP_FILTER_PTP_V2_L2_EVENT:
+ 	case HWTSTAMP_FILTER_PTP_V2_L2_SYNC:
+ 	case HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ:
+ 	case HWTSTAMP_FILTER_PTP_V2_EVENT:
+ 	case HWTSTAMP_FILTER_PTP_V2_SYNC:
+ 	case HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:
+ 	case HWTSTAMP_FILTER_NTP_ALL:
+ 		/* Disable CQE compression */
+ 		netdev_warn(priv->netdev, "Disabling cqe compression");
+ 		err = mlx5e_modify_rx_cqe_compression_locked(priv, false);
+ 		if (err) {
+ 			netdev_err(priv->netdev, "Failed disabling cqe compression err=%d\n", err);
+ 			mutex_unlock(&priv->state_lock);
+ 			return err;
+ 		}
+ 		config.rx_filter = HWTSTAMP_FILTER_ALL;
+ 		break;
+ 	default:
+ 		mutex_unlock(&priv->state_lock);
+ 		return -ERANGE;
+ 	}
+ 
+ 	memcpy(&priv->tstamp, &config, sizeof(config));
+ 	mutex_unlock(&priv->state_lock);
+ 
+ 	return copy_to_user(ifr->ifr_data, &config,
+ 			    sizeof(config)) ? -EFAULT : 0;
+ }
+ 
+ int mlx5e_hwstamp_get(struct mlx5e_priv *priv, struct ifreq *ifr)
+ {
+ 	struct hwtstamp_config *cfg = &priv->tstamp;
+ 
+ 	if (!MLX5_CAP_GEN(priv->mdev, device_frequency_khz))
+ 		return -EOPNOTSUPP;
+ 
+ 	return copy_to_user(ifr->ifr_data, cfg, sizeof(*cfg)) ? -EFAULT : 0;
+ }
+ 
  static int mlx5e_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
  {
 -	struct mlx5e_priv *priv = netdev_priv(dev);
 -
  	switch (cmd) {
  	case SIOCSHWTSTAMP:
 -		return mlx5e_hwstamp_set(priv, ifr);
 +		return mlx5e_hwstamp_set(dev, ifr);
  	case SIOCGHWTSTAMP:
 -		return mlx5e_hwstamp_get(priv, ifr);
 +		return mlx5e_hwstamp_get(dev, ifr);
  	default:
  		return -EOPNOTSUPP;
  	}
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
index d6a4d3219a46,7e3bfe62ef6e..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
@@@ -38,11 -39,14 +38,18 @@@
  #include "en.h"
  #include "en_tc.h"
  #include "eswitch.h"
++<<<<<<< HEAD
 +#include "ipoib.h"
- 
- static inline bool mlx5e_rx_hw_stamp(struct mlx5e_tstamp *tstamp)
++=======
+ #include "en_rep.h"
+ #include "ipoib/ipoib.h"
+ #include "en_accel/ipsec_rxtx.h"
+ #include "lib/clock.h"
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
+ 
+ static inline bool mlx5e_rx_hw_stamp(struct hwtstamp_config *config)
  {
- 	return tstamp->hwtstamp_config.rx_filter == HWTSTAMP_FILTER_ALL;
+ 	return config->rx_filter == HWTSTAMP_FILTER_ALL;
  }
  
  static inline void mlx5e_read_cqe_slot(struct mlx5e_cq *cq, u32 cqcc,
@@@ -841,3 -1080,202 +848,205 @@@ int mlx5e_poll_rx_cq(struct mlx5e_cq *c
  
  	return work_done;
  }
++<<<<<<< HEAD
++=======
+ 
+ bool mlx5e_poll_xdpsq_cq(struct mlx5e_cq *cq)
+ {
+ 	struct mlx5e_xdpsq *sq;
+ 	struct mlx5_cqe64 *cqe;
+ 	struct mlx5e_rq *rq;
+ 	u16 sqcc;
+ 	int i;
+ 
+ 	sq = container_of(cq, struct mlx5e_xdpsq, cq);
+ 
+ 	if (unlikely(!MLX5E_TEST_BIT(sq->state, MLX5E_SQ_STATE_ENABLED)))
+ 		return false;
+ 
+ 	cqe = mlx5_cqwq_get_cqe(&cq->wq);
+ 	if (!cqe)
+ 		return false;
+ 
+ 	rq = container_of(sq, struct mlx5e_rq, xdpsq);
+ 
+ 	/* sq->cc must be updated only after mlx5_cqwq_update_db_record(),
+ 	 * otherwise a cq overrun may occur
+ 	 */
+ 	sqcc = sq->cc;
+ 
+ 	i = 0;
+ 	do {
+ 		u16 wqe_counter;
+ 		bool last_wqe;
+ 
+ 		mlx5_cqwq_pop(&cq->wq);
+ 
+ 		wqe_counter = be16_to_cpu(cqe->wqe_counter);
+ 
+ 		do {
+ 			struct mlx5e_dma_info *di;
+ 			u16 ci;
+ 
+ 			last_wqe = (sqcc == wqe_counter);
+ 
+ 			ci = sqcc & sq->wq.sz_m1;
+ 			di = &sq->db.di[ci];
+ 
+ 			sqcc++;
+ 			/* Recycle RX page */
+ 			mlx5e_page_release(rq, di, true);
+ 		} while (!last_wqe);
+ 	} while ((++i < MLX5E_TX_CQ_POLL_BUDGET) && (cqe = mlx5_cqwq_get_cqe(&cq->wq)));
+ 
+ 	mlx5_cqwq_update_db_record(&cq->wq);
+ 
+ 	/* ensure cq space is freed before enabling more cqes */
+ 	wmb();
+ 
+ 	sq->cc = sqcc;
+ 	return (i == MLX5E_TX_CQ_POLL_BUDGET);
+ }
+ 
+ void mlx5e_free_xdpsq_descs(struct mlx5e_xdpsq *sq)
+ {
+ 	struct mlx5e_rq *rq = container_of(sq, struct mlx5e_rq, xdpsq);
+ 	struct mlx5e_dma_info *di;
+ 	u16 ci;
+ 
+ 	while (sq->cc != sq->pc) {
+ 		ci = sq->cc & sq->wq.sz_m1;
+ 		di = &sq->db.di[ci];
+ 		sq->cc++;
+ 
+ 		mlx5e_page_release(rq, di, false);
+ 	}
+ }
+ 
+ #ifdef CONFIG_MLX5_CORE_IPOIB
+ 
+ #define MLX5_IB_GRH_DGID_OFFSET 24
+ #define MLX5_GID_SIZE           16
+ 
+ static inline void mlx5i_complete_rx_cqe(struct mlx5e_rq *rq,
+ 					 struct mlx5_cqe64 *cqe,
+ 					 u32 cqe_bcnt,
+ 					 struct sk_buff *skb)
+ {
+ 	struct net_device *netdev = rq->netdev;
+ 	char *pseudo_header;
+ 	u8 *dgid;
+ 	u8 g;
+ 
+ 	g = (be32_to_cpu(cqe->flags_rqpn) >> 28) & 3;
+ 	dgid = skb->data + MLX5_IB_GRH_DGID_OFFSET;
+ 	if ((!g) || dgid[0] != 0xff)
+ 		skb->pkt_type = PACKET_HOST;
+ 	else if (memcmp(dgid, netdev->broadcast + 4, MLX5_GID_SIZE) == 0)
+ 		skb->pkt_type = PACKET_BROADCAST;
+ 	else
+ 		skb->pkt_type = PACKET_MULTICAST;
+ 
+ 	/* TODO: IB/ipoib: Allow mcast packets from other VFs
+ 	 * 68996a6e760e5c74654723eeb57bf65628ae87f4
+ 	 */
+ 
+ 	skb_pull(skb, MLX5_IB_GRH_BYTES);
+ 
+ 	skb->protocol = *((__be16 *)(skb->data));
+ 
+ 	skb->ip_summed = CHECKSUM_COMPLETE;
+ 	skb->csum = csum_unfold((__force __sum16)cqe->check_sum);
+ 
+ 	if (unlikely(mlx5e_rx_hw_stamp(rq->tstamp)))
+ 		skb_hwtstamps(skb)->hwtstamp =
+ 				mlx5_timecounter_cyc2time(rq->clock, get_cqe_ts(cqe));
+ 
+ 	skb_record_rx_queue(skb, rq->ix);
+ 
+ 	if (likely(netdev->features & NETIF_F_RXHASH))
+ 		mlx5e_skb_set_hash(cqe, skb);
+ 
+ 	/* 20 bytes of ipoib header and 4 for encap existing */
+ 	pseudo_header = skb_push(skb, MLX5_IPOIB_PSEUDO_LEN);
+ 	memset(pseudo_header, 0, MLX5_IPOIB_PSEUDO_LEN);
+ 	skb_reset_mac_header(skb);
+ 	skb_pull(skb, MLX5_IPOIB_HARD_LEN);
+ 
+ 	skb->dev = netdev;
+ 
+ 	rq->stats.csum_complete++;
+ 	rq->stats.packets++;
+ 	rq->stats.bytes += cqe_bcnt;
+ }
+ 
+ void mlx5i_handle_rx_cqe(struct mlx5e_rq *rq, struct mlx5_cqe64 *cqe)
+ {
+ 	struct mlx5e_wqe_frag_info *wi;
+ 	struct mlx5e_rx_wqe *wqe;
+ 	__be16 wqe_counter_be;
+ 	struct sk_buff *skb;
+ 	u16 wqe_counter;
+ 	u32 cqe_bcnt;
+ 
+ 	wqe_counter_be = cqe->wqe_counter;
+ 	wqe_counter    = be16_to_cpu(wqe_counter_be);
+ 	wqe            = mlx5_wq_ll_get_wqe(&rq->wq, wqe_counter);
+ 	wi             = &rq->wqe.frag_info[wqe_counter];
+ 	cqe_bcnt       = be32_to_cpu(cqe->byte_cnt);
+ 
+ 	skb = skb_from_cqe(rq, cqe, wi, cqe_bcnt);
+ 	if (!skb)
+ 		goto wq_free_wqe;
+ 
+ 	mlx5i_complete_rx_cqe(rq, cqe, cqe_bcnt, skb);
+ 	napi_gro_receive(rq->cq.napi, skb);
+ 
+ wq_free_wqe:
+ 	mlx5e_free_rx_wqe_reuse(rq, wi);
+ 	mlx5_wq_ll_pop(&rq->wq, wqe_counter_be,
+ 		       &wqe->next.next_wqe_index);
+ }
+ 
+ #endif /* CONFIG_MLX5_CORE_IPOIB */
+ 
+ #ifdef CONFIG_MLX5_EN_IPSEC
+ 
+ void mlx5e_ipsec_handle_rx_cqe(struct mlx5e_rq *rq, struct mlx5_cqe64 *cqe)
+ {
+ 	struct mlx5e_wqe_frag_info *wi;
+ 	struct mlx5e_rx_wqe *wqe;
+ 	__be16 wqe_counter_be;
+ 	struct sk_buff *skb;
+ 	u16 wqe_counter;
+ 	u32 cqe_bcnt;
+ 
+ 	wqe_counter_be = cqe->wqe_counter;
+ 	wqe_counter    = be16_to_cpu(wqe_counter_be);
+ 	wqe            = mlx5_wq_ll_get_wqe(&rq->wq, wqe_counter);
+ 	wi             = &rq->wqe.frag_info[wqe_counter];
+ 	cqe_bcnt       = be32_to_cpu(cqe->byte_cnt);
+ 
+ 	skb = skb_from_cqe(rq, cqe, wi, cqe_bcnt);
+ 	if (unlikely(!skb)) {
+ 		/* a DROP, save the page-reuse checks */
+ 		mlx5e_free_rx_wqe(rq, wi);
+ 		goto wq_ll_pop;
+ 	}
+ 	skb = mlx5e_ipsec_handle_rx_skb(rq->netdev, skb);
+ 	if (unlikely(!skb)) {
+ 		mlx5e_free_rx_wqe(rq, wi);
+ 		goto wq_ll_pop;
+ 	}
+ 
+ 	mlx5e_complete_rx_cqe(rq, cqe, cqe_bcnt, skb);
+ 	napi_gro_receive(rq->cq.napi, skb);
+ 
+ 	mlx5e_free_rx_wqe_reuse(rq, wi);
+ wq_ll_pop:
+ 	mlx5_wq_ll_pop(&rq->wq, wqe_counter_be,
+ 		       &wqe->next.next_wqe_index);
+ }
+ 
+ #endif /* CONFIG_MLX5_EN_IPSEC */
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tx.c
index 46d0d61188dc,a7c208a1ad83..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tx.c
@@@ -33,7 -33,9 +33,13 @@@
  #include <linux/tcp.h>
  #include <linux/if_vlan.h>
  #include "en.h"
++<<<<<<< HEAD
 +#include "ipoib.h"
++=======
+ #include "ipoib/ipoib.h"
+ #include "en_accel/ipsec_rxtx.h"
+ #include "lib/clock.h"
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  
  #define MLX5E_SQ_NOPS_ROOM  MLX5_SEND_WQE_MAX_WQEBBS
  #define MLX5E_SQ_STOP_ROOM (MLX5_SEND_WQE_MAX_WQEBBS +\
diff --cc drivers/net/ethernet/mellanox/mlx5/core/main.c
index 83ed808b199e,ecbe9fad22d8..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/main.c
@@@ -53,9 -54,12 +53,16 @@@
  #include <net/devlink.h>
  #include "mlx5_core.h"
  #include "fs_core.h"
 -#include "lib/mpfs.h"
 +#ifdef CONFIG_MLX5_CORE_EN
  #include "eswitch.h"
++<<<<<<< HEAD
 +#endif
++=======
+ #include "lib/mlx5.h"
+ #include "fpga/core.h"
+ #include "accel/ipsec.h"
+ #include "lib/clock.h"
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  
  MODULE_AUTHOR("Eli Cohen <eli@mellanox.com>");
  MODULE_DESCRIPTION("Mellanox Connect-IB, ConnectX-4 core driver");
@@@ -918,6 -888,10 +925,13 @@@ static int mlx5_init_once(struct mlx5_c
  
  	mlx5_init_mkey_table(dev);
  
++<<<<<<< HEAD
++=======
+ 	mlx5_init_reserved_gids(dev);
+ 
+ 	mlx5_init_clock(dev);
+ 
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  	err = mlx5_init_rl_table(dev);
  	if (err) {
  		dev_err(&pdev->dev, "Failed to init rate limiting\n");
@@@ -963,11 -947,13 +977,16 @@@ out
  
  static void mlx5_cleanup_once(struct mlx5_core_dev *dev)
  {
 -	mlx5_fpga_cleanup(dev);
  	mlx5_sriov_cleanup(dev);
 +#ifdef CONFIG_MLX5_CORE_EN
  	mlx5_eswitch_cleanup(dev->priv.eswitch);
 -	mlx5_mpfs_cleanup(dev);
 +#endif
  	mlx5_cleanup_rl_table(dev);
++<<<<<<< HEAD
++=======
+ 	mlx5_cleanup_clock(dev);
+ 	mlx5_cleanup_reserved_gids(dev);
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  	mlx5_cleanup_mkey_table(dev);
  	mlx5_cleanup_srq_table(dev);
  	mlx5_cleanup_qp_table(dev);
diff --cc drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
index 19ef644f882e,8f00de2fe283..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
@@@ -84,10 -88,14 +84,16 @@@ int mlx5_query_hca_caps(struct mlx5_cor
  int mlx5_query_board_id(struct mlx5_core_dev *dev);
  int mlx5_cmd_init_hca(struct mlx5_core_dev *dev);
  int mlx5_cmd_teardown_hca(struct mlx5_core_dev *dev);
 -int mlx5_cmd_force_teardown_hca(struct mlx5_core_dev *dev);
  void mlx5_core_event(struct mlx5_core_dev *dev, enum mlx5_dev_event event,
  		     unsigned long param);
++<<<<<<< HEAD
++=======
+ void mlx5_core_page_fault(struct mlx5_core_dev *dev,
+ 			  struct mlx5_pagefault *pfault);
+ void mlx5_pps_event(struct mlx5_core_dev *dev, struct mlx5_eqe *eqe);
++>>>>>>> 7c39afb394c7 (net/mlx5: PTP code migration to driver core section)
  void mlx5_port_module_event(struct mlx5_core_dev *dev, struct mlx5_eqe *eqe);
 -void mlx5_enter_error_state(struct mlx5_core_dev *dev, bool force);
 +void mlx5_enter_error_state(struct mlx5_core_dev *dev);
  void mlx5_disable_device(struct mlx5_core_dev *dev);
  void mlx5_recover_device(struct mlx5_core_dev *dev);
  int mlx5_sriov_init(struct mlx5_core_dev *dev);
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/clock.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/ipoib/ipoib.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/clock.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_clock.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tx.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/eq.c b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
index e96faecb3e7d..34ae4bd028f1 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/eq.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
@@ -296,8 +296,7 @@ static int mlx5_eq_int(struct mlx5_core_dev *dev, struct mlx5_eq *eq)
 			break;
 
 		case MLX5_EVENT_TYPE_PPS_EVENT:
-			if (dev->event)
-				dev->event(dev, MLX5_DEV_EVENT_PPS, (unsigned long)eqe);
+			mlx5_pps_event(dev, eqe);
 			break;
 		default:
 			mlx5_core_warn(dev, "Unhandled event 0x%x on EQ 0x%x\n",
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/ipoib/ipoib.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/mlx5_core.h
diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index 2c536d21ca92..3ed1d6eb470d 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -47,6 +47,8 @@
 #include <linux/mlx5/device.h>
 #include <linux/mlx5/doorbell.h>
 #include <linux/mlx5/srq.h>
+#include <linux/timecounter.h>
+#include <linux/ptp_clock_kernel.h>
 
 enum {
 	MLX5_BOARD_ID_LEN = 64,
@@ -653,6 +655,27 @@ struct mlx5e_resources {
 	struct mlx5_core_mkey      mkey;
 };
 
+#define MAX_PIN_NUM	8
+struct mlx5_pps {
+	u8                         pin_caps[MAX_PIN_NUM];
+	struct work_struct         out_work;
+	u64                        start[MAX_PIN_NUM];
+	u8                         enabled;
+};
+
+struct mlx5_clock {
+	rwlock_t                   lock;
+	struct cyclecounter        cycles;
+	struct timecounter         tc;
+	struct hwtstamp_config     hwtstamp_config;
+	u32                        nominal_c_mult;
+	unsigned long              overflow_period;
+	struct delayed_work        overflow_work;
+	struct ptp_clock          *ptp;
+	struct ptp_clock_info      ptp_info;
+	struct mlx5_pps            pps_info;
+};
+
 struct mlx5_core_dev {
 	struct pci_dev	       *pdev;
 	/* sync pci state */
@@ -685,6 +708,7 @@ struct mlx5_core_dev {
 #ifdef CONFIG_RFS_ACCEL
 	struct cpu_rmap         *rmap;
 #endif
+	struct mlx5_clock        clock;
 };
 
 struct mlx5_db {
