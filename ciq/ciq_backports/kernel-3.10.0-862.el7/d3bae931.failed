scsi: qla2xxx: Send FC4 type NVMe to the management server

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [scsi] qla2xxx: Send FC4 type NVMe to the management server (Himanshu Madhani) [1316281]
Rebuild_FUZZ: 94.55%
commit-author Duane Grigsby <duane.grigsby@cavium.com>
commit d3bae931172eb94af7d21b05f6e9bf79cccf8fa0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/d3bae931.failed

This patch adds switch command support for FC-4 type of FC-NVMe (0x28)
for resgistering HBA port to the management server. RFT_ID command is
used to register FC-4 type of 0x28 and RFF_ID is used to register FC-4
features bits for FC-NVMe port.

	Signed-off-by: Darren Trapp <darren.trapp@cavium.com>
	Signed-off-by: Duane Grigsby <duane.grigsby@cavium.com>
	Signed-off-by: Anil Gurumurthy <anil.gurumurhty@cavium.com>
	Signed-off-by: Giridhar Malavali <giridhar.malavali@cavium.com>
	Signed-off-by: Himanshu Madhani <himanshu.madhani@cavium.com>
Reviewed-By: James Smart <james.smart@broadcom.com>
	Reviewed-by: Hannes Reinecke <hare@suse.com>
	Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit d3bae931172eb94af7d21b05f6e9bf79cccf8fa0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/qla2xxx/qla_gbl.h
#	drivers/scsi/qla2xxx/qla_gs.c
#	drivers/scsi/qla2xxx/qla_init.c
diff --cc drivers/scsi/qla2xxx/qla_gbl.h
index c4f068539cd6,cadb6e3baacc..000000000000
--- a/drivers/scsi/qla2xxx/qla_gbl.h
+++ b/drivers/scsi/qla2xxx/qla_gbl.h
@@@ -10,6 -10,17 +10,20 @@@
  #include <linux/interrupt.h>
  
  /*
++<<<<<<< HEAD
++=======
+  * Global functions prototype in qla_nvme.c source file.
+  */
+ extern void qla_nvme_register_hba(scsi_qla_host_t *);
+ extern int  qla_nvme_register_remote(scsi_qla_host_t *, fc_port_t *);
+ extern void qla_nvme_delete(scsi_qla_host_t *);
+ extern void qla_nvme_abort(struct qla_hw_data *, srb_t *sp);
+ extern void qla24xx_nvme_ls4_iocb(scsi_qla_host_t *, struct pt_ls4_request *,
+     struct req_que *);
+ extern void qla24xx_async_gffid_sp_done(void *, int);
+ 
+ /*
++>>>>>>> d3bae931172e (scsi: qla2xxx: Send FC4 type NVMe to the management server)
   * Global Function Prototypes in qla_init.c source file.
   */
  extern int qla2x00_initialize_adapter(scsi_qla_host_t *);
@@@ -578,7 -628,25 +592,29 @@@ extern int qla2x00_fdmi_register(scsi_q
  extern int qla2x00_gfpn_id(scsi_qla_host_t *, sw_info_t *);
  extern int qla2x00_gpsc(scsi_qla_host_t *, sw_info_t *);
  extern void qla2x00_get_sym_node_name(scsi_qla_host_t *, uint8_t *, size_t);
- 
++<<<<<<< HEAD
++
++=======
+ extern int qla2x00_chk_ms_status(scsi_qla_host_t *, ms_iocb_entry_t *,
+ 	struct ct_sns_rsp *, const char *);
+ extern void qla2x00_async_iocb_timeout(void *data);
+ extern int qla24xx_async_gidpn(scsi_qla_host_t *, fc_port_t *);
+ int qla24xx_post_gidpn_work(struct scsi_qla_host *, fc_port_t *);
+ void qla24xx_handle_gidpn_event(scsi_qla_host_t *, struct event_arg *);
+ 
+ extern void qla2x00_free_fcport(fc_port_t *);
+ 
+ extern int qla24xx_post_gpnid_work(struct scsi_qla_host *, port_id_t *);
+ extern int qla24xx_async_gpnid(scsi_qla_host_t *, port_id_t *);
+ void qla24xx_async_gpnid_done(scsi_qla_host_t *, srb_t*);
+ void qla24xx_handle_gpnid_event(scsi_qla_host_t *, struct event_arg *);
+ 
+ int qla24xx_post_gpsc_work(struct scsi_qla_host *, fc_port_t *);
+ int qla24xx_async_gpsc(scsi_qla_host_t *, fc_port_t *);
+ int qla2x00_mgmt_svr_login(scsi_qla_host_t *);
+ void qla24xx_handle_gffid_event(scsi_qla_host_t *vha, struct event_arg *ea);
+ int qla24xx_async_gffid(scsi_qla_host_t *vha, fc_port_t *fcport);
++>>>>>>> d3bae931172e (scsi: qla2xxx: Send FC4 type NVMe to the management server)
  /*
   * Global Function Prototypes in qla_attr.c source file.
   */
diff --cc drivers/scsi/qla2xxx/qla_gs.c
index 96c51e2a6964,c91478529b51..000000000000
--- a/drivers/scsi/qla2xxx/qla_gs.c
+++ b/drivers/scsi/qla2xxx/qla_gs.c
@@@ -2708,3 -2767,655 +2714,658 @@@ qla2x00_gff_id(scsi_qla_host_t *vha, sw
  			break;
  	}
  }
++<<<<<<< HEAD
++=======
+ 
+ /* GID_PN completion processing. */
+ void qla24xx_handle_gidpn_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	fc_port_t *fcport = ea->fcport;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x201d,
+ 	    "%s %8phC login state %d\n",
+ 	    __func__, fcport->port_name, fcport->fw_login_state);
+ 
+ 	if (ea->sp->gen2 != fcport->login_gen) {
+ 		/* PLOGI/PRLI/LOGO came in while cmd was out.*/
+ 		ql_dbg(ql_dbg_disc, vha, 0x201e,
+ 		    "%s %8phC generation changed rscn %d|%d login %d|%d \n",
+ 		    __func__, fcport->port_name, fcport->last_rscn_gen,
+ 		    fcport->rscn_gen, fcport->last_login_gen, fcport->login_gen);
+ 		return;
+ 	}
+ 
+ 	if (!ea->rc) {
+ 		if (ea->sp->gen1 == fcport->rscn_gen) {
+ 			fcport->scan_state = QLA_FCPORT_FOUND;
+ 			fcport->flags |= FCF_FABRIC_DEVICE;
+ 
+ 			if (fcport->d_id.b24 == ea->id.b24) {
+ 				/* cable plugged into the same place */
+ 				switch (vha->host->active_mode) {
+ 				case MODE_TARGET:
+ 					/* NOOP. let the other guy login to us.*/
+ 					break;
+ 				case MODE_INITIATOR:
+ 				case MODE_DUAL:
+ 				default:
+ 					if (atomic_read(&fcport->state) ==
+ 					    FCS_ONLINE)
+ 						break;
+ 					ql_dbg(ql_dbg_disc, vha, 0x201f,
+ 					    "%s %d %8phC post gnl\n",
+ 					    __func__, __LINE__, fcport->port_name);
+ 					qla24xx_post_gnl_work(vha, fcport);
+ 					break;
+ 				}
+ 			} else { /* fcport->d_id.b24 != ea->id.b24 */
+ 				fcport->d_id.b24 = ea->id.b24;
+ 				if (fcport->deleted == QLA_SESS_DELETED) {
+ 					ql_dbg(ql_dbg_disc, vha, 0x2021,
+ 					    "%s %d %8phC post del sess\n",
+ 					    __func__, __LINE__, fcport->port_name);
+ 					qlt_schedule_sess_for_deletion_lock(fcport);
+ 				}
+ 			}
+ 		} else { /* ea->sp->gen1 != fcport->rscn_gen */
+ 			ql_dbg(ql_dbg_disc, vha, 0x2022,
+ 			    "%s %d %8phC post gidpn\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			/* rscn came in while cmd was out */
+ 			qla24xx_post_gidpn_work(vha, fcport);
+ 		}
+ 	} else { /* ea->rc */
+ 		/* cable pulled */
+ 		if (ea->sp->gen1 == fcport->rscn_gen) {
+ 			if (ea->sp->gen2 == fcport->login_gen) {
+ 				ql_dbg(ql_dbg_disc, vha, 0x2042,
+ 				    "%s %d %8phC post del sess\n", __func__,
+ 				    __LINE__, fcport->port_name);
+ 				qlt_schedule_sess_for_deletion_lock(fcport);
+ 			} else {
+ 				ql_dbg(ql_dbg_disc, vha, 0x2045,
+ 				    "%s %d %8phC login\n", __func__, __LINE__,
+ 				    fcport->port_name);
+ 				qla24xx_fcport_handle_login(vha, fcport);
+ 			}
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, vha, 0x2049,
+ 			    "%s %d %8phC post gidpn\n", __func__, __LINE__,
+ 			    fcport->port_name);
+ 			qla24xx_post_gidpn_work(vha, fcport);
+ 		}
+ 	}
+ } /* gidpn_event */
+ 
+ static void qla2x00_async_gidpn_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	fc_port_t *fcport = sp->fcport;
+ 	u8 *id = fcport->ct_desc.ct_sns->p.rsp.rsp.gid_pn.port_id;
+ 	struct event_arg ea;
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.fcport = fcport;
+ 	ea.id.b.domain = id[0];
+ 	ea.id.b.area = id[1];
+ 	ea.id.b.al_pa = id[2];
+ 	ea.sp = sp;
+ 	ea.rc = res;
+ 	ea.event = FCME_GIDPN_DONE;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x204f,
+ 	    "Async done-%s res %x, WWPN %8phC ID %3phC \n",
+ 	    sp->name, res, fcport->port_name, id);
+ 
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_gidpn(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online)
+ 		goto done;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	fcport->disc_state = DSC_GID_PN;
+ 	fcport->scan_state = QLA_FCPORT_SCAN;
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_ATOMIC);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gidpn";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(fcport->ct_desc.ct_sns, GID_PN_CMD,
+ 		GID_PN_RSP_SIZE);
+ 
+ 	/* GIDPN req */
+ 	memcpy(ct_req->req.gid_pn.port_name, fcport->port_name,
+ 		WWN_SIZE);
+ 
+ 	/* req & rsp use the same buffer */
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GID_PN_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GID_PN_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_gidpn_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20a4,
+ 	    "Async-%s - %8phC hdl=%x loopid=%x portid %02x%02x%02x.\n",
+ 	    sp->name, fcport->port_name,
+ 	    sp->handle, fcport->loop_id, fcport->d_id.b.domain,
+ 	    fcport->d_id.b.area, fcport->d_id.b.al_pa);
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ done:
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gidpn_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 	int ls;
+ 
+ 	ls = atomic_read(&vha->loop_state);
+ 	if (((ls != LOOP_READY) && (ls != LOOP_UP)) ||
+ 		test_bit(UNLOADING, &vha->dpc_flags))
+ 		return 0;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GIDPN);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ int qla24xx_post_gpsc_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GPSC);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ static void qla24xx_async_gpsc_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	fc_port_t *fcport = sp->fcport;
+ 	struct ct_sns_rsp       *ct_rsp;
+ 	struct event_arg ea;
+ 
+ 	ct_rsp = &fcport->ct_desc.ct_sns->p.rsp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2053,
+ 	    "Async done-%s res %x, WWPN %8phC \n",
+ 	    sp->name, res, fcport->port_name);
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 
+ 	if (res == (DID_ERROR << 16)) {
+ 		/* entry status error */
+ 		goto done;
+ 	} else if (res) {
+ 		if ((ct_rsp->header.reason_code ==
+ 			 CT_REASON_INVALID_COMMAND_CODE) ||
+ 			(ct_rsp->header.reason_code ==
+ 			CT_REASON_COMMAND_UNSUPPORTED)) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x2019,
+ 			    "GPSC command unsupported, disabling query.\n");
+ 			ha->flags.gpsc_supported = 0;
+ 			res = QLA_SUCCESS;
+ 		}
+ 	} else {
+ 		switch (be16_to_cpu(ct_rsp->rsp.gpsc.speed)) {
+ 		case BIT_15:
+ 			fcport->fp_speed = PORT_SPEED_1GB;
+ 			break;
+ 		case BIT_14:
+ 			fcport->fp_speed = PORT_SPEED_2GB;
+ 			break;
+ 		case BIT_13:
+ 			fcport->fp_speed = PORT_SPEED_4GB;
+ 			break;
+ 		case BIT_12:
+ 			fcport->fp_speed = PORT_SPEED_10GB;
+ 			break;
+ 		case BIT_11:
+ 			fcport->fp_speed = PORT_SPEED_8GB;
+ 			break;
+ 		case BIT_10:
+ 			fcport->fp_speed = PORT_SPEED_16GB;
+ 			break;
+ 		case BIT_8:
+ 			fcport->fp_speed = PORT_SPEED_32GB;
+ 			break;
+ 		}
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0x2054,
+ 		    "Async-%s OUT WWPN %8phC speeds=%04x speed=%04x.\n",
+ 		    sp->name, fcport->fabric_port_name,
+ 		    be16_to_cpu(ct_rsp->rsp.gpsc.speeds),
+ 		    be16_to_cpu(ct_rsp->rsp.gpsc.speed));
+ 	}
+ done:
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.event = FCME_GPSC_DONE;
+ 	ea.rc = res;
+ 	ea.fcport = fcport;
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_gpsc(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online)
+ 		goto done;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gpsc";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla24xx_prep_ct_fm_req(fcport->ct_desc.ct_sns, GPSC_CMD,
+ 		GPSC_RSP_SIZE);
+ 
+ 	/* GPSC req */
+ 	memcpy(ct_req->req.gpsc.port_name, fcport->port_name,
+ 		WWN_SIZE);
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GPSC_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GPSC_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = vha->mgmt_svr_loop_id;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla24xx_async_gpsc_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x205e,
+ 	    "Async-%s %8phC hdl=%x loopid=%x portid=%02x%02x%02x.\n",
+ 	    sp->name, fcport->port_name, sp->handle,
+ 	    fcport->loop_id, fcport->d_id.b.domain,
+ 	    fcport->d_id.b.area, fcport->d_id.b.al_pa);
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ done:
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gpnid_work(struct scsi_qla_host *vha, port_id_t *id)
+ {
+ 	struct qla_work_evt *e;
+ 
+ 	if (test_bit(UNLOADING, &vha->dpc_flags))
+ 		return 0;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GPNID);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.gpnid.id = *id;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ void qla24xx_async_gpnid_done(scsi_qla_host_t *vha, srb_t *sp)
+ {
+ 	if (sp->u.iocb_cmd.u.ctarg.req) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 			sizeof(struct ct_sns_pkt),
+ 			sp->u.iocb_cmd.u.ctarg.req,
+ 			sp->u.iocb_cmd.u.ctarg.req_dma);
+ 		sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 	}
+ 	if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 			sizeof(struct ct_sns_pkt),
+ 			sp->u.iocb_cmd.u.ctarg.rsp,
+ 			sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 		sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 	}
+ 
+ 	sp->free(sp);
+ }
+ 
+ void qla24xx_handle_gpnid_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	fc_port_t *fcport;
+ 	unsigned long flags;
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 	fcport = qla2x00_find_fcport_by_wwpn(vha, ea->port_name, 1);
+ 	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 
+ 	if (fcport) {
+ 		/* cable moved. just plugged in */
+ 		fcport->rscn_gen++;
+ 		fcport->d_id = ea->id;
+ 		fcport->scan_state = QLA_FCPORT_FOUND;
+ 		fcport->flags |= FCF_FABRIC_DEVICE;
+ 
+ 		switch (fcport->disc_state) {
+ 		case DSC_DELETED:
+ 			ql_dbg(ql_dbg_disc, vha, 0x210d,
+ 			    "%s %d %8phC login\n", __func__, __LINE__,
+ 			    fcport->port_name);
+ 			qla24xx_fcport_handle_login(vha, fcport);
+ 			break;
+ 		case DSC_DELETE_PEND:
+ 			break;
+ 		default:
+ 			ql_dbg(ql_dbg_disc, vha, 0x2064,
+ 			    "%s %d %8phC post del sess\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			qlt_schedule_sess_for_deletion_lock(fcport);
+ 			break;
+ 		}
+ 	} else {
+ 		/* create new fcport */
+ 		ql_dbg(ql_dbg_disc, vha, 0x2065,
+ 		    "%s %d %8phC post new sess\n",
+ 		    __func__, __LINE__, ea->port_name);
+ 
+ 		qla24xx_post_newsess_work(vha, &ea->id, ea->port_name, NULL);
+ 	}
+ }
+ 
+ static void qla2x00_async_gpnid_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	struct ct_sns_req *ct_req =
+ 	    (struct ct_sns_req *)sp->u.iocb_cmd.u.ctarg.req;
+ 	struct ct_sns_rsp *ct_rsp =
+ 	    (struct ct_sns_rsp *)sp->u.iocb_cmd.u.ctarg.rsp;
+ 	struct event_arg ea;
+ 	struct qla_work_evt *e;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2066,
+ 	    "Async done-%s res %x ID %3phC. %8phC\n",
+ 	    sp->name, res, ct_req->req.port_id.port_id,
+ 	    ct_rsp->rsp.gpn_id.port_name);
+ 
+ 	memset(&ea, 0, sizeof(ea));
+ 	memcpy(ea.port_name, ct_rsp->rsp.gpn_id.port_name, WWN_SIZE);
+ 	ea.sp = sp;
+ 	ea.id.b.domain = ct_req->req.port_id.port_id[0];
+ 	ea.id.b.area = ct_req->req.port_id.port_id[1];
+ 	ea.id.b.al_pa = ct_req->req.port_id.port_id[2];
+ 	ea.rc = res;
+ 	ea.event = FCME_GPNID_DONE;
+ 
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GPNID_DONE);
+ 	if (!e) {
+ 		/* please ignore kernel warning. otherwise, we have mem leak. */
+ 		if (sp->u.iocb_cmd.u.ctarg.req) {
+ 			dma_free_coherent(&vha->hw->pdev->dev,
+ 				sizeof(struct ct_sns_pkt),
+ 				sp->u.iocb_cmd.u.ctarg.req,
+ 				sp->u.iocb_cmd.u.ctarg.req_dma);
+ 			sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 		}
+ 		if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 			dma_free_coherent(&vha->hw->pdev->dev,
+ 				sizeof(struct ct_sns_pkt),
+ 				sp->u.iocb_cmd.u.ctarg.rsp,
+ 				sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 			sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 		}
+ 
+ 		sp->free(sp);
+ 		return;
+ 	}
+ 
+ 	e->u.iosb.sp = sp;
+ 	qla2x00_post_work(vha, e);
+ }
+ 
+ /* Get WWPN with Nport ID. */
+ int qla24xx_async_gpnid(scsi_qla_host_t *vha, port_id_t *id)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 	struct ct_sns_pkt *ct_sns;
+ 
+ 	if (!vha->flags.online)
+ 		goto done;
+ 
+ 	sp = qla2x00_get_sp(vha, NULL, GFP_KERNEL);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gpnid";
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req = dma_alloc_coherent(&vha->hw->pdev->dev,
+ 		sizeof(struct ct_sns_pkt), &sp->u.iocb_cmd.u.ctarg.req_dma,
+ 		GFP_KERNEL);
+ 	if (!sp->u.iocb_cmd.u.ctarg.req) {
+ 		ql_log(ql_log_warn, vha, 0xd041,
+ 		    "Failed to allocate ct_sns request.\n");
+ 		goto done_free_sp;
+ 	}
+ 
+ 	sp->u.iocb_cmd.u.ctarg.rsp = dma_alloc_coherent(&vha->hw->pdev->dev,
+ 		sizeof(struct ct_sns_pkt), &sp->u.iocb_cmd.u.ctarg.rsp_dma,
+ 		GFP_KERNEL);
+ 	if (!sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		ql_log(ql_log_warn, vha, 0xd042,
+ 		    "Failed to allocate ct_sns request.\n");
+ 		goto done_free_sp;
+ 	}
+ 
+ 	ct_sns = (struct ct_sns_pkt *)sp->u.iocb_cmd.u.ctarg.rsp;
+ 	memset(ct_sns, 0, sizeof(*ct_sns));
+ 
+ 	ct_sns = (struct ct_sns_pkt *)sp->u.iocb_cmd.u.ctarg.req;
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(ct_sns, GPN_ID_CMD, GPN_ID_RSP_SIZE);
+ 
+ 	/* GPN_ID req */
+ 	ct_req->req.port_id.port_id[0] = id->b.domain;
+ 	ct_req->req.port_id.port_id[1] = id->b.area;
+ 	ct_req->req.port_id.port_id[2] = id->b.al_pa;
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GPN_ID_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GPN_ID_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_gpnid_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2067,
+ 	    "Async-%s hdl=%x ID %3phC.\n", sp->name,
+ 	    sp->handle, ct_req->req.port_id.port_id);
+ 	return rval;
+ 
+ done_free_sp:
+ 	if (sp->u.iocb_cmd.u.ctarg.req) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 			sizeof(struct ct_sns_pkt),
+ 			sp->u.iocb_cmd.u.ctarg.req,
+ 			sp->u.iocb_cmd.u.ctarg.req_dma);
+ 		sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 	}
+ 	if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 			sizeof(struct ct_sns_pkt),
+ 			sp->u.iocb_cmd.u.ctarg.rsp,
+ 			sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 		sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 	}
+ 
+ 	sp->free(sp);
+ done:
+ 	return rval;
+ }
+ 
+ void qla24xx_handle_gffid_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+        fc_port_t *fcport = ea->fcport;
+ 
+        qla24xx_post_gnl_work(vha, fcport);
+ }
+ 
+ void qla24xx_async_gffid_sp_done(void *s, int res)
+ {
+        struct srb *sp = s;
+        struct scsi_qla_host *vha = sp->vha;
+        fc_port_t *fcport = sp->fcport;
+        struct ct_sns_rsp *ct_rsp;
+        struct event_arg ea;
+ 
+        ql_dbg(ql_dbg_disc, vha, 0x2133,
+ 	   "Async done-%s res %x ID %x. %8phC\n",
+ 	   sp->name, res, fcport->d_id.b24, fcport->port_name);
+ 
+        fcport->flags &= ~FCF_ASYNC_SENT;
+        ct_rsp = &fcport->ct_desc.ct_sns->p.rsp;
+        /*
+ 	* FC-GS-7, 5.2.3.12 FC-4 Features - format
+ 	* The format of the FC-4 Features object, as defined by the FC-4,
+ 	* Shall be an array of 4-bit values, one for each type code value
+ 	*/
+        if (!res) {
+ 	       if (ct_rsp->rsp.gff_id.fc4_features[GFF_FCP_SCSI_OFFSET] & 0xf) {
+ 		       /* w1 b00:03 */
+ 		       fcport->fc4_type =
+ 			   ct_rsp->rsp.gff_id.fc4_features[GFF_FCP_SCSI_OFFSET];
+ 		       fcport->fc4_type &= 0xf;
+ 	       }
+ 
+ 	       if (ct_rsp->rsp.gff_id.fc4_features[GFF_NVME_OFFSET] & 0xf) {
+ 		       /* w5 [00:03]/28h */
+ 		       fcport->fc4f_nvme =
+ 			   ct_rsp->rsp.gff_id.fc4_features[GFF_NVME_OFFSET];
+ 		       fcport->fc4f_nvme &= 0xf;
+ 	       }
+        }
+ 
+        memset(&ea, 0, sizeof(ea));
+        ea.sp = sp;
+        ea.fcport = sp->fcport;
+        ea.rc = res;
+        ea.event = FCME_GFFID_DONE;
+ 
+        qla2x00_fcport_event_handler(vha, &ea);
+        sp->free(sp);
+ }
+ 
+ /* Get FC4 Feature with Nport ID. */
+ int qla24xx_async_gffid(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online)
+ 		return rval;
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		return rval;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gffid";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(fcport->ct_desc.ct_sns, GFF_ID_CMD,
+ 	    GFF_ID_RSP_SIZE);
+ 
+ 	ct_req->req.gff_id.port_id[0] = fcport->d_id.b.domain;
+ 	ct_req->req.gff_id.port_id[1] = fcport->d_id.b.area;
+ 	ct_req->req.gff_id.port_id[2] = fcport->d_id.b.al_pa;
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GFF_ID_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GFF_ID_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla24xx_async_gffid_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2132,
+ 	    "Async-%s hdl=%x  %8phC.\n", sp->name,
+ 	    sp->handle, fcport->port_name);
+ 
+ 	return rval;
+ done_free_sp:
+ 	sp->free(sp);
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
++>>>>>>> d3bae931172e (scsi: qla2xxx: Send FC4 type NVMe to the management server)
diff --cc drivers/scsi/qla2xxx/qla_init.c
index 998b579c233c,8a5f5ef069ae..000000000000
--- a/drivers/scsi/qla2xxx/qla_init.c
+++ b/drivers/scsi/qla2xxx/qla_init.c
@@@ -274,6 -325,937 +274,939 @@@ done
  	return rval;
  }
  
++<<<<<<< HEAD
++=======
+ static void qla24xx_handle_gnl_done_event(scsi_qla_host_t *vha,
+ 	struct event_arg *ea)
+ {
+ 	fc_port_t *fcport, *conflict_fcport;
+ 	struct get_name_list_extended *e;
+ 	u16 i, n, found = 0, loop_id;
+ 	port_id_t id;
+ 	u64 wwn;
+ 	u8 opt = 0, current_login_state;
+ 
+ 	fcport = ea->fcport;
+ 
+ 	if (ea->rc) { /* rval */
+ 		if (fcport->login_retry == 0) {
+ 			fcport->login_retry = vha->hw->login_retry_count;
+ 			ql_dbg(ql_dbg_disc, vha, 0x20de,
+ 			    "GNL failed Port login retry %8phN, retry cnt=%d.\n",
+ 			    fcport->port_name, fcport->login_retry);
+ 		}
+ 		return;
+ 	}
+ 
+ 	if (fcport->last_rscn_gen != fcport->rscn_gen) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20df,
+ 		    "%s %8phC rscn gen changed rscn %d|%d \n",
+ 		    __func__, fcport->port_name,
+ 		    fcport->last_rscn_gen, fcport->rscn_gen);
+ 		qla24xx_post_gidpn_work(vha, fcport);
+ 		return;
+ 	} else if (fcport->last_login_gen != fcport->login_gen) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20e0,
+ 		    "%s %8phC login gen changed login %d|%d\n",
+ 		    __func__, fcport->port_name,
+ 		    fcport->last_login_gen, fcport->login_gen);
+ 		return;
+ 	}
+ 
+ 	n = ea->data[0] / sizeof(struct get_name_list_extended);
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20e1,
+ 	    "%s %d %8phC n %d %02x%02x%02x lid %d \n",
+ 	    __func__, __LINE__, fcport->port_name, n,
+ 	    fcport->d_id.b.domain, fcport->d_id.b.area,
+ 	    fcport->d_id.b.al_pa, fcport->loop_id);
+ 
+ 	for (i = 0; i < n; i++) {
+ 		e = &vha->gnl.l[i];
+ 		wwn = wwn_to_u64(e->port_name);
+ 
+ 		if (memcmp((u8 *)&wwn, fcport->port_name, WWN_SIZE))
+ 			continue;
+ 
+ 		found = 1;
+ 		id.b.domain = e->port_id[2];
+ 		id.b.area = e->port_id[1];
+ 		id.b.al_pa = e->port_id[0];
+ 		id.b.rsvd_1 = 0;
+ 
+ 		loop_id = le16_to_cpu(e->nport_handle);
+ 		loop_id = (loop_id & 0x7fff);
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0x20e2,
+ 		    "%s found %8phC CLS [%d|%d] ID[%02x%02x%02x|%02x%02x%02x] lid[%d|%d]\n",
+ 		    __func__, fcport->port_name,
+ 		    e->current_login_state, fcport->fw_login_state,
+ 		    id.b.domain, id.b.area, id.b.al_pa,
+ 		    fcport->d_id.b.domain, fcport->d_id.b.area,
+ 		    fcport->d_id.b.al_pa, loop_id, fcport->loop_id);
+ 
+ 		if ((id.b24 != fcport->d_id.b24) ||
+ 		    ((fcport->loop_id != FC_NO_LOOP_ID) &&
+ 			(fcport->loop_id != loop_id))) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20e3,
+ 			    "%s %d %8phC post del sess\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			qlt_schedule_sess_for_deletion(fcport, 1);
+ 			return;
+ 		}
+ 
+ 		fcport->loop_id = loop_id;
+ 
+ 		wwn = wwn_to_u64(fcport->port_name);
+ 		qlt_find_sess_invalidate_other(vha, wwn,
+ 			id, loop_id, &conflict_fcport);
+ 
+ 		if (conflict_fcport) {
+ 			/*
+ 			 * Another share fcport share the same loop_id &
+ 			 * nport id. Conflict fcport needs to finish
+ 			 * cleanup before this fcport can proceed to login.
+ 			 */
+ 			conflict_fcport->conflict = fcport;
+ 			fcport->login_pause = 1;
+ 		}
+ 
+ 		if  (fcport->fc4f_nvme)
+ 			current_login_state = e->current_login_state >> 4;
+ 		else
+ 			current_login_state = e->current_login_state & 0xf;
+ 
+ 		switch (current_login_state) {
+ 		case DSC_LS_PRLI_COMP:
+ 			ql_dbg(ql_dbg_disc, vha, 0x20e4,
+ 			    "%s %d %8phC post gpdb\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			opt = PDO_FORCE_ADISC;
+ 			qla24xx_post_gpdb_work(vha, fcport, opt);
+ 			break;
+ 		case DSC_LS_PORT_UNAVAIL:
+ 		default:
+ 			if (fcport->loop_id == FC_NO_LOOP_ID) {
+ 				qla2x00_find_new_loop_id(vha, fcport);
+ 				fcport->fw_login_state = DSC_LS_PORT_UNAVAIL;
+ 			}
+ 			ql_dbg(ql_dbg_disc, vha, 0x20e5,
+ 			    "%s %d %8phC\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			qla24xx_fcport_handle_login(vha, fcport);
+ 			break;
+ 		}
+ 	}
+ 
+ 	if (!found) {
+ 		/* fw has no record of this port */
+ 		if (fcport->loop_id == FC_NO_LOOP_ID) {
+ 			qla2x00_find_new_loop_id(vha, fcport);
+ 			fcport->fw_login_state = DSC_LS_PORT_UNAVAIL;
+ 		} else {
+ 			for (i = 0; i < n; i++) {
+ 				e = &vha->gnl.l[i];
+ 				id.b.domain = e->port_id[0];
+ 				id.b.area = e->port_id[1];
+ 				id.b.al_pa = e->port_id[2];
+ 				id.b.rsvd_1 = 0;
+ 				loop_id = le16_to_cpu(e->nport_handle);
+ 
+ 				if (fcport->d_id.b24 == id.b24) {
+ 					conflict_fcport =
+ 					    qla2x00_find_fcport_by_wwpn(vha,
+ 						e->port_name, 0);
+ 
+ 					ql_dbg(ql_dbg_disc, vha, 0x20e6,
+ 					    "%s %d %8phC post del sess\n",
+ 					    __func__, __LINE__,
+ 					    conflict_fcport->port_name);
+ 					qlt_schedule_sess_for_deletion
+ 						(conflict_fcport, 1);
+ 				}
+ 
+ 				if (fcport->loop_id == loop_id) {
+ 					/* FW already picked this loop id for another fcport */
+ 					qla2x00_find_new_loop_id(vha, fcport);
+ 				}
+ 			}
+ 		}
+ 		qla24xx_fcport_handle_login(vha, fcport);
+ 	}
+ } /* gnl_event */
+ 
+ static void
+ qla24xx_async_gnl_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	unsigned long flags;
+ 	struct fc_port *fcport = NULL, *tf;
+ 	u16 i, n = 0, loop_id;
+ 	struct event_arg ea;
+ 	struct get_name_list_extended *e;
+ 	u64 wwn;
+ 	struct list_head h;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20e7,
+ 	    "Async done-%s res %x mb[1]=%x mb[2]=%x \n",
+ 	    sp->name, res, sp->u.iocb_cmd.u.mbx.in_mb[1],
+ 	    sp->u.iocb_cmd.u.mbx.in_mb[2]);
+ 
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.sp = sp;
+ 	ea.rc = res;
+ 	ea.event = FCME_GNL_DONE;
+ 
+ 	if (sp->u.iocb_cmd.u.mbx.in_mb[1] >=
+ 	    sizeof(struct get_name_list_extended)) {
+ 		n = sp->u.iocb_cmd.u.mbx.in_mb[1] /
+ 		    sizeof(struct get_name_list_extended);
+ 		ea.data[0] = sp->u.iocb_cmd.u.mbx.in_mb[1]; /* amnt xfered */
+ 	}
+ 
+ 	for (i = 0; i < n; i++) {
+ 		e = &vha->gnl.l[i];
+ 		loop_id = le16_to_cpu(e->nport_handle);
+ 		/* mask out reserve bit */
+ 		loop_id = (loop_id & 0x7fff);
+ 		set_bit(loop_id, vha->hw->loop_id_map);
+ 		wwn = wwn_to_u64(e->port_name);
+ 
+ 		ql_dbg(ql_dbg_disc + ql_dbg_verbose, vha, 0x20e8,
+ 		    "%s %8phC %02x:%02x:%02x state %d/%d lid %x \n",
+ 		    __func__, (void *)&wwn, e->port_id[2], e->port_id[1],
+ 		    e->port_id[0], e->current_login_state, e->last_login_state,
+ 		    (loop_id & 0x7fff));
+ 	}
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 	vha->gnl.sent = 0;
+ 
+ 	INIT_LIST_HEAD(&h);
+ 	fcport = tf = NULL;
+ 	if (!list_empty(&vha->gnl.fcports))
+ 		list_splice_init(&vha->gnl.fcports, &h);
+ 
+ 	list_for_each_entry_safe(fcport, tf, &h, gnl_entry) {
+ 		list_del_init(&fcport->gnl_entry);
+ 		fcport->flags &= ~FCF_ASYNC_SENT;
+ 		ea.fcport = fcport;
+ 
+ 		qla2x00_fcport_event_handler(vha, &ea);
+ 	}
+ 
+ 	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_gnl(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	srb_t *sp;
+ 	struct srb_iocb *mbx;
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	unsigned long flags;
+ 	u16 *mb;
+ 
+ 	if (!vha->flags.online)
+ 		goto done;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20d9,
+ 	    "Async-gnlist WWPN %8phC \n", fcport->port_name);
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	fcport->disc_state = DSC_GNL;
+ 	fcport->last_rscn_gen = fcport->rscn_gen;
+ 	fcport->last_login_gen = fcport->login_gen;
+ 
+ 	list_add_tail(&fcport->gnl_entry, &vha->gnl.fcports);
+ 	if (vha->gnl.sent) {
+ 		spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 		rval = QLA_SUCCESS;
+ 		goto done;
+ 	}
+ 	vha->gnl.sent = 1;
+ 	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		goto done;
+ 	sp->type = SRB_MB_IOCB;
+ 	sp->name = "gnlist";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha)+2);
+ 
+ 	mb = sp->u.iocb_cmd.u.mbx.out_mb;
+ 	mb[0] = MBC_PORT_NODE_NAME_LIST;
+ 	mb[1] = BIT_2 | BIT_3;
+ 	mb[2] = MSW(vha->gnl.ldma);
+ 	mb[3] = LSW(vha->gnl.ldma);
+ 	mb[6] = MSW(MSD(vha->gnl.ldma));
+ 	mb[7] = LSW(MSD(vha->gnl.ldma));
+ 	mb[8] = vha->gnl.size;
+ 	mb[9] = vha->vp_idx;
+ 
+ 	mbx = &sp->u.iocb_cmd;
+ 	mbx->timeout = qla2x00_async_iocb_timeout;
+ 
+ 	sp->done = qla24xx_async_gnl_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20da,
+ 	    "Async-%s - OUT WWPN %8phC hndl %x\n",
+ 	    sp->name, fcport->port_name, sp->handle);
+ 
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ done:
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gnl_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GNL);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ static
+ void qla24xx_async_gpdb_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	struct port_database_24xx *pd;
+ 	fc_port_t *fcport = sp->fcport;
+ 	u16 *mb = sp->u.iocb_cmd.u.mbx.in_mb;
+ 	int rval = QLA_SUCCESS;
+ 	struct event_arg ea;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20db,
+ 	    "Async done-%s res %x, WWPN %8phC mb[1]=%x mb[2]=%x \n",
+ 	    sp->name, res, fcport->port_name, mb[1], mb[2]);
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 
+ 	if (res) {
+ 		rval = res;
+ 		goto gpd_error_out;
+ 	}
+ 
+ 	pd = (struct port_database_24xx *)sp->u.iocb_cmd.u.mbx.in;
+ 
+ 	rval = __qla24xx_parse_gpdb(vha, fcport, pd);
+ 
+ gpd_error_out:
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.event = FCME_GPDB_DONE;
+ 	ea.rc = rval;
+ 	ea.fcport = fcport;
+ 	ea.sp = sp;
+ 
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	dma_pool_free(ha->s_dma_pool, sp->u.iocb_cmd.u.mbx.in,
+ 		sp->u.iocb_cmd.u.mbx.in_dma);
+ 
+ 	sp->free(sp);
+ }
+ 
+ static int qla24xx_post_prli_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_PRLI);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ static void
+ qla2x00_async_prli_sp_done(void *ptr, int res)
+ {
+ 	srb_t *sp = ptr;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	struct srb_iocb *lio = &sp->u.iocb_cmd;
+ 	struct event_arg ea;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2129,
+ 	    "%s %8phC res %d \n", __func__,
+ 	    sp->fcport->port_name, res);
+ 
+ 	sp->fcport->flags &= ~FCF_ASYNC_SENT;
+ 
+ 	if (!test_bit(UNLOADING, &vha->dpc_flags)) {
+ 		memset(&ea, 0, sizeof(ea));
+ 		ea.event = FCME_PRLI_DONE;
+ 		ea.fcport = sp->fcport;
+ 		ea.data[0] = lio->u.logio.data[0];
+ 		ea.data[1] = lio->u.logio.data[1];
+ 		ea.iop[0] = lio->u.logio.iop[0];
+ 		ea.iop[1] = lio->u.logio.iop[1];
+ 		ea.sp = sp;
+ 
+ 		qla2x00_fcport_event_handler(vha, &ea);
+ 	}
+ 
+ 	sp->free(sp);
+ }
+ 
+ int
+ qla24xx_async_prli(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	srb_t *sp;
+ 	struct srb_iocb *lio;
+ 	int rval = QLA_FUNCTION_FAILED;
+ 
+ 	if (!vha->flags.online)
+ 		return rval;
+ 
+ 	if (fcport->fw_login_state == DSC_LS_PLOGI_PEND ||
+ 	    fcport->fw_login_state == DSC_LS_PLOGI_COMP ||
+ 	    fcport->fw_login_state == DSC_LS_PRLI_PEND)
+ 		return rval;
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		return rval;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	fcport->logout_completed = 0;
+ 
+ 	sp->type = SRB_PRLI_CMD;
+ 	sp->name = "prli";
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	lio = &sp->u.iocb_cmd;
+ 	lio->timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_prli_sp_done;
+ 	lio->u.logio.flags = 0;
+ 
+ 	if  (fcport->fc4f_nvme)
+ 		lio->u.logio.flags |= SRB_LOGIN_NVME_PRLI;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS) {
+ 		fcport->flags &= ~FCF_ASYNC_SENT;
+ 		fcport->flags |= FCF_LOGIN_NEEDED;
+ 		set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
+ 		goto done_free_sp;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x211b,
+ 	    "Async-prli - %8phC hdl=%x, loopid=%x portid=%06x retries=%d.\n",
+ 	    fcport->port_name, sp->handle, fcport->loop_id,
+ 	    fcport->d_id.b24, fcport->login_retry);
+ 
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ static int qla24xx_post_gpdb_work(struct scsi_qla_host *vha, fc_port_t *fcport,
+     u8 opt)
+ {
+ 	struct qla_work_evt *e;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GPDB);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	e->u.fcport.opt = opt;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ int qla24xx_async_gpdb(struct scsi_qla_host *vha, fc_port_t *fcport, u8 opt)
+ {
+ 	srb_t *sp;
+ 	struct srb_iocb *mbx;
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	u16 *mb;
+ 	dma_addr_t pd_dma;
+ 	struct port_database_24xx *pd;
+ 	struct qla_hw_data *ha = vha->hw;
+ 
+ 	if (!vha->flags.online)
+ 		goto done;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	fcport->disc_state = DSC_GPDB;
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	pd = dma_pool_alloc(ha->s_dma_pool, GFP_KERNEL, &pd_dma);
+ 	if (pd == NULL) {
+ 		ql_log(ql_log_warn, vha, 0xd043,
+ 		    "Failed to allocate port database structure.\n");
+ 		goto done_free_sp;
+ 	}
+ 	memset(pd, 0, max(PORT_DATABASE_SIZE, PORT_DATABASE_24XX_SIZE));
+ 
+ 	sp->type = SRB_MB_IOCB;
+ 	sp->name = "gpdb";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	mb = sp->u.iocb_cmd.u.mbx.out_mb;
+ 	mb[0] = MBC_GET_PORT_DATABASE;
+ 	mb[1] = fcport->loop_id;
+ 	mb[2] = MSW(pd_dma);
+ 	mb[3] = LSW(pd_dma);
+ 	mb[6] = MSW(MSD(pd_dma));
+ 	mb[7] = LSW(MSD(pd_dma));
+ 	mb[9] = vha->vp_idx;
+ 	mb[10] = opt;
+ 
+ 	mbx = &sp->u.iocb_cmd;
+ 	mbx->timeout = qla2x00_async_iocb_timeout;
+ 	mbx->u.mbx.in = (void *)pd;
+ 	mbx->u.mbx.in_dma = pd_dma;
+ 
+ 	sp->done = qla24xx_async_gpdb_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20dc,
+ 	    "Async-%s %8phC hndl %x opt %x\n",
+ 	    sp->name, fcport->port_name, sp->handle, opt);
+ 
+ 	return rval;
+ 
+ done_free_sp:
+ 	if (pd)
+ 		dma_pool_free(ha->s_dma_pool, pd, pd_dma);
+ 
+ 	sp->free(sp);
+ done:
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	qla24xx_post_gpdb_work(vha, fcport, opt);
+ 	return rval;
+ }
+ 
+ static
+ void qla24xx_handle_gpdb_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	int rval = ea->rc;
+ 	fc_port_t *fcport = ea->fcport;
+ 	unsigned long flags;
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20d2,
+ 	    "%s %8phC DS %d LS %d rval %d\n", __func__, fcport->port_name,
+ 	    fcport->disc_state, fcport->fw_login_state, rval);
+ 
+ 	if (ea->sp->gen2 != fcport->login_gen) {
+ 		/* target side must have changed it. */
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d3,
+ 		    "%s %8phC generation changed rscn %d|%d login %d|%d \n",
+ 		    __func__, fcport->port_name, fcport->last_rscn_gen,
+ 		    fcport->rscn_gen, fcport->last_login_gen,
+ 		    fcport->login_gen);
+ 		return;
+ 	} else if (ea->sp->gen1 != fcport->rscn_gen) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d4, "%s %d %8phC post gidpn\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 		qla24xx_post_gidpn_work(vha, fcport);
+ 		return;
+ 	}
+ 
+ 	if (rval != QLA_SUCCESS) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d5, "%s %d %8phC post del sess\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 		qlt_schedule_sess_for_deletion_lock(fcport);
+ 		return;
+ 	}
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 	ea->fcport->login_gen++;
+ 	ea->fcport->deleted = 0;
+ 	ea->fcport->logout_on_delete = 1;
+ 
+ 	if (!ea->fcport->login_succ && !IS_SW_RESV_ADDR(ea->fcport->d_id)) {
+ 		vha->fcport_count++;
+ 		ea->fcport->login_succ = 1;
+ 
+ 		if (!IS_IIDMA_CAPABLE(vha->hw) ||
+ 		    !vha->hw->flags.gpsc_supported) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20d6,
+ 			    "%s %d %8phC post upd_fcport fcp_cnt %d\n",
+ 			    __func__, __LINE__, fcport->port_name,
+ 			    vha->fcport_count);
+ 
+ 			qla24xx_post_upd_fcport_work(vha, fcport);
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20d7,
+ 			    "%s %d %8phC post gpsc fcp_cnt %d\n",
+ 			    __func__, __LINE__, fcport->port_name,
+ 			    vha->fcport_count);
+ 
+ 			qla24xx_post_gpsc_work(vha, fcport);
+ 		}
+ 	}
+ 	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ } /* gpdb event */
+ 
+ int qla24xx_fcport_handle_login(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	if (fcport->login_retry == 0)
+ 		return 0;
+ 
+ 	if (fcport->scan_state != QLA_FCPORT_FOUND)
+ 		return 0;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20d8,
+ 	    "%s %8phC DS %d LS %d P %d fl %x confl %p rscn %d|%d login %d|%d retry %d lid %d\n",
+ 	    __func__, fcport->port_name, fcport->disc_state,
+ 	    fcport->fw_login_state, fcport->login_pause, fcport->flags,
+ 	    fcport->conflict, fcport->last_rscn_gen, fcport->rscn_gen,
+ 	    fcport->last_login_gen, fcport->login_gen, fcport->login_retry,
+ 	    fcport->loop_id);
+ 
+ 	fcport->login_retry--;
+ 
+ 	if ((fcport->fw_login_state == DSC_LS_PLOGI_PEND) ||
+ 	    (fcport->fw_login_state == DSC_LS_PRLI_PEND))
+ 		return 0;
+ 
+ 	if (fcport->fw_login_state == DSC_LS_PLOGI_COMP) {
+ 		if (time_before_eq(jiffies, fcport->plogi_nack_done_deadline))
+ 			return 0;
+ 	}
+ 
+ 	/* for pure Target Mode. Login will not be initiated */
+ 	if (vha->host->active_mode == MODE_TARGET)
+ 		return 0;
+ 
+ 	if (fcport->flags & FCF_ASYNC_SENT) {
+ 		set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
+ 		return 0;
+ 	}
+ 
+ 	switch (fcport->disc_state) {
+ 	case DSC_DELETED:
+ 		if (fcport->loop_id == FC_NO_LOOP_ID) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20bd,
+ 			    "%s %d %8phC post gnl\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			qla24xx_async_gnl(vha, fcport);
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20bf,
+ 			    "%s %d %8phC post login\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			fcport->disc_state = DSC_LOGIN_PEND;
+ 			qla2x00_post_async_login_work(vha, fcport, NULL);
+ 		}
+ 		break;
+ 
+ 	case DSC_GNL:
+ 		if (fcport->login_pause) {
+ 			fcport->last_rscn_gen = fcport->rscn_gen;
+ 			fcport->last_login_gen = fcport->login_gen;
+ 			set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
+ 			break;
+ 		}
+ 
+ 		if (fcport->flags & FCF_FCP2_DEVICE) {
+ 			u8 opt = PDO_FORCE_ADISC;
+ 
+ 			ql_dbg(ql_dbg_disc, vha, 0x20c9,
+ 			    "%s %d %8phC post gpdb\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 
+ 			fcport->disc_state = DSC_GPDB;
+ 			qla24xx_post_gpdb_work(vha, fcport, opt);
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20cf,
+ 			    "%s %d %8phC post login\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			fcport->disc_state = DSC_LOGIN_PEND;
+ 			qla2x00_post_async_login_work(vha, fcport, NULL);
+ 		}
+ 
+ 		break;
+ 
+ 	case DSC_LOGIN_FAILED:
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d0,
+ 		    "%s %d %8phC post gidpn\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 
+ 		qla24xx_post_gidpn_work(vha, fcport);
+ 		break;
+ 
+ 	case DSC_LOGIN_COMPLETE:
+ 		/* recheck login state */
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d1,
+ 		    "%s %d %8phC post gpdb\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 
+ 		qla24xx_post_gpdb_work(vha, fcport, PDO_FORCE_ADISC);
+ 		break;
+ 
+ 	default:
+ 		break;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static
+ void qla24xx_handle_rscn_event(fc_port_t *fcport, struct event_arg *ea)
+ {
+ 	fcport->rscn_gen++;
+ 
+ 	ql_dbg(ql_dbg_disc, fcport->vha, 0x210c,
+ 	    "%s %8phC DS %d LS %d\n",
+ 	    __func__, fcport->port_name, fcport->disc_state,
+ 	    fcport->fw_login_state);
+ 
+ 	if (fcport->flags & FCF_ASYNC_SENT)
+ 		return;
+ 
+ 	switch (fcport->disc_state) {
+ 	case DSC_DELETED:
+ 	case DSC_LOGIN_COMPLETE:
+ 		qla24xx_post_gidpn_work(fcport->vha, fcport);
+ 		break;
+ 
+ 	default:
+ 		break;
+ 	}
+ }
+ 
+ int qla24xx_post_newsess_work(struct scsi_qla_host *vha, port_id_t *id,
+ 	u8 *port_name, void *pla)
+ {
+ 	struct qla_work_evt *e;
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_NEW_SESS);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.new_sess.id = *id;
+ 	e->u.new_sess.pla = pla;
+ 	memcpy(e->u.new_sess.port_name, port_name, WWN_SIZE);
+ 
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ static
+ int qla24xx_handle_delete_done_event(scsi_qla_host_t *vha,
+ 	struct event_arg *ea)
+ {
+ 	fc_port_t *fcport = ea->fcport;
+ 
+ 	if (test_bit(UNLOADING, &vha->dpc_flags))
+ 		return 0;
+ 
+ 	switch (vha->host->active_mode) {
+ 	case MODE_INITIATOR:
+ 	case MODE_DUAL:
+ 		if (fcport->scan_state == QLA_FCPORT_FOUND)
+ 			qla24xx_fcport_handle_login(vha, fcport);
+ 		break;
+ 
+ 	case MODE_TARGET:
+ 	default:
+ 		/* no-op */
+ 		break;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static
+ void qla24xx_handle_relogin_event(scsi_qla_host_t *vha,
+ 	struct event_arg *ea)
+ {
+ 	fc_port_t *fcport = ea->fcport;
+ 
+ 	if (fcport->scan_state != QLA_FCPORT_FOUND) {
+ 		fcport->login_retry++;
+ 		return;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2102,
+ 	    "%s %8phC DS %d LS %d P %d del %d cnfl %p rscn %d|%d login %d|%d fl %x\n",
+ 	    __func__, fcport->port_name, fcport->disc_state,
+ 	    fcport->fw_login_state, fcport->login_pause,
+ 	    fcport->deleted, fcport->conflict,
+ 	    fcport->last_rscn_gen, fcport->rscn_gen,
+ 	    fcport->last_login_gen, fcport->login_gen,
+ 	    fcport->flags);
+ 
+ 	if ((fcport->fw_login_state == DSC_LS_PLOGI_PEND) ||
+ 	    (fcport->fw_login_state == DSC_LS_PRLI_PEND))
+ 		return;
+ 
+ 	if (fcport->fw_login_state == DSC_LS_PLOGI_COMP) {
+ 		if (time_before_eq(jiffies, fcport->plogi_nack_done_deadline))
+ 			return;
+ 	}
+ 
+ 	if (fcport->flags & FCF_ASYNC_SENT) {
+ 		fcport->login_retry++;
+ 		set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
+ 		return;
+ 	}
+ 
+ 	if (fcport->disc_state == DSC_DELETE_PEND) {
+ 		fcport->login_retry++;
+ 		return;
+ 	}
+ 
+ 	if (fcport->last_rscn_gen != fcport->rscn_gen) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20e9, "%s %d %8phC post gidpn\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 
+ 		qla24xx_async_gidpn(vha, fcport);
+ 		return;
+ 	}
+ 
+ 	qla24xx_fcport_handle_login(vha, fcport);
+ }
+ 
+ void qla2x00_fcport_event_handler(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	fc_port_t *fcport, *f, *tf;
+ 	uint32_t id = 0, mask, rid;
+ 	int rc;
+ 
+ 	switch (ea->event) {
+ 	case FCME_RELOGIN:
+ 	case FCME_RSCN:
+ 	case FCME_GIDPN_DONE:
+ 	case FCME_GPSC_DONE:
+ 	case FCME_GPNID_DONE:
+ 		if (test_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags) ||
+ 		    test_bit(LOOP_RESYNC_ACTIVE, &vha->dpc_flags))
+ 			return;
+ 		break;
+ 	default:
+ 		break;
+ 	}
+ 
+ 	switch (ea->event) {
+ 	case FCME_RELOGIN:
+ 		if (test_bit(UNLOADING, &vha->dpc_flags))
+ 			return;
+ 
+ 		qla24xx_handle_relogin_event(vha, ea);
+ 		break;
+ 	case FCME_RSCN:
+ 		if (test_bit(UNLOADING, &vha->dpc_flags))
+ 			return;
+ 		switch (ea->id.b.rsvd_1) {
+ 		case RSCN_PORT_ADDR:
+ 			fcport = qla2x00_find_fcport_by_nportid(vha, &ea->id, 1);
+ 			if (!fcport) {
+ 				/* cable moved */
+ 				rc = qla24xx_post_gpnid_work(vha, &ea->id);
+ 				if (rc) {
+ 					ql_log(ql_log_warn, vha, 0xd044,
+ 					    "RSCN GPNID work failed %02x%02x%02x\n",
+ 					    ea->id.b.domain, ea->id.b.area,
+ 					    ea->id.b.al_pa);
+ 				}
+ 			} else {
+ 				ea->fcport = fcport;
+ 				qla24xx_handle_rscn_event(fcport, ea);
+ 			}
+ 			break;
+ 		case RSCN_AREA_ADDR:
+ 		case RSCN_DOM_ADDR:
+ 			if (ea->id.b.rsvd_1 == RSCN_AREA_ADDR) {
+ 				mask = 0xffff00;
+ 				ql_dbg(ql_dbg_async, vha, 0x5044,
+ 				    "RSCN: Area 0x%06x was affected\n",
+ 				    ea->id.b24);
+ 			} else {
+ 				mask = 0xff0000;
+ 				ql_dbg(ql_dbg_async, vha, 0x507a,
+ 				    "RSCN: Domain 0x%06x was affected\n",
+ 				    ea->id.b24);
+ 			}
+ 
+ 			rid = ea->id.b24 & mask;
+ 			list_for_each_entry_safe(f, tf, &vha->vp_fcports,
+ 			    list) {
+ 				id = f->d_id.b24 & mask;
+ 				if (rid == id) {
+ 					ea->fcport = f;
+ 					qla24xx_handle_rscn_event(f, ea);
+ 				}
+ 			}
+ 			break;
+ 		case RSCN_FAB_ADDR:
+ 		default:
+ 			ql_log(ql_log_warn, vha, 0xd045,
+ 			    "RSCN: Fabric was affected. Addr format %d\n",
+ 			    ea->id.b.rsvd_1);
+ 			qla2x00_mark_all_devices_lost(vha, 1);
+ 			set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 			set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 		}
+ 		break;
+ 	case FCME_GIDPN_DONE:
+ 		qla24xx_handle_gidpn_event(vha, ea);
+ 		break;
+ 	case FCME_GNL_DONE:
+ 		qla24xx_handle_gnl_done_event(vha, ea);
+ 		break;
+ 	case FCME_GPSC_DONE:
+ 		qla24xx_post_upd_fcport_work(vha, ea->fcport);
+ 		break;
+ 	case FCME_PLOGI_DONE:	/* Initiator side sent LLIOCB */
+ 		qla24xx_handle_plogi_done_event(vha, ea);
+ 		break;
+ 	case FCME_PRLI_DONE:
+ 		qla24xx_handle_prli_done_event(vha, ea);
+ 		break;
+ 	case FCME_GPDB_DONE:
+ 		qla24xx_handle_gpdb_event(vha, ea);
+ 		break;
+ 	case FCME_GPNID_DONE:
+ 		qla24xx_handle_gpnid_event(vha, ea);
+ 		break;
+ 	case FCME_GFFID_DONE:
+ 		qla24xx_handle_gffid_event(vha, ea);
+ 		break;
+ 	case FCME_DELETE_DONE:
+ 		qla24xx_handle_delete_done_event(vha, ea);
+ 		break;
+ 	default:
+ 		BUG_ON(1);
+ 		break;
+ 	}
+ }
+ 
++>>>>>>> d3bae931172e (scsi: qla2xxx: Send FC4 type NVMe to the management server)
  static void
  qla2x00_tmf_iocb_timeout(void *data)
  {
@@@ -3455,22 -4630,39 +4388,28 @@@ qla2x00_configure_fabric(scsi_qla_host_
  		if (test_and_clear_bit(REGISTER_FC4_NEEDED, &vha->dpc_flags)) {
  			if (qla2x00_rft_id(vha)) {
  				/* EMPTY */
 -				ql_dbg(ql_dbg_disc, vha, 0x20a2,
 +				ql_dbg(ql_dbg_disc, vha, 0x2045,
  				    "Register FC-4 TYPE failed.\n");
 -				if (test_bit(LOOP_RESYNC_NEEDED,
 -				    &vha->dpc_flags))
 -					break;
  			}
- 			if (qla2x00_rff_id(vha)) {
+ 			if (qla2x00_rff_id(vha, FC4_TYPE_FCP_SCSI)) {
  				/* EMPTY */
 -				ql_dbg(ql_dbg_disc, vha, 0x209a,
 +				ql_dbg(ql_dbg_disc, vha, 0x2049,
  				    "Register FC-4 Features failed.\n");
 -				if (test_bit(LOOP_RESYNC_NEEDED,
 -				    &vha->dpc_flags))
 -					break;
  			}
+ 			if (vha->flags.nvme_enabled) {
+ 				if (qla2x00_rff_id(vha, FC_TYPE_NVME)) {
+ 					ql_dbg(ql_dbg_disc, vha, 0x2049,
+ 					    "Register NVME FC Type Features failed.\n");
+ 				}
+ 			}
  			if (qla2x00_rnn_id(vha)) {
  				/* EMPTY */
 -				ql_dbg(ql_dbg_disc, vha, 0x2104,
 +				ql_dbg(ql_dbg_disc, vha, 0x204f,
  				    "Register Node Name failed.\n");
 -				if (test_bit(LOOP_RESYNC_NEEDED,
 -				    &vha->dpc_flags))
 -					break;
  			} else if (qla2x00_rsnn_nn(vha)) {
  				/* EMPTY */
 -				ql_dbg(ql_dbg_disc, vha, 0x209b,
 +				ql_dbg(ql_dbg_disc, vha, 0x2053,
  				    "Register Symobilic Node Name failed.\n");
 -				if (test_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags))
 -					break;
  			}
  		}
  
diff --git a/drivers/scsi/qla2xxx/qla_def.h b/drivers/scsi/qla2xxx/qla_def.h
index 3f28536dc812..febe984df0ff 100644
--- a/drivers/scsi/qla2xxx/qla_def.h
+++ b/drivers/scsi/qla2xxx/qla_def.h
@@ -2534,6 +2534,7 @@ struct ct_sns_rsp {
 		} gpsc;
 
 #define GFF_FCP_SCSI_OFFSET	7
+#define GFF_NVME_OFFSET		23 /* type = 28h */
 		struct {
 			uint8_t fc4_features[128];
 		} gff_id;
* Unmerged path drivers/scsi/qla2xxx/qla_gbl.h
* Unmerged path drivers/scsi/qla2xxx/qla_gs.c
* Unmerged path drivers/scsi/qla2xxx/qla_init.c
