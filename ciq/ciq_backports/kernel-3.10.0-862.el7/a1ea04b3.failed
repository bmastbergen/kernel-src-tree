scsi: cxlflash: Flush pending commands in cleanup path

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [scsi] cxlflash: Flush pending commands in cleanup path (Gustavo Duarte) [1456494]
Rebuild_FUZZ: 94.12%
commit-author Uma Krishnan <ukrishn@linux.vnet.ibm.com>
commit a1ea04b3ebd9ae5c1cd5bf48be37aba0d93c1acc
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/a1ea04b3.failed

When the AFU is reset in an error path, pending scsi commands can be
silently dropped without completion or a formal abort. This puts the onus
on the cxlflash driver to notify mid-layer and indicating that the command
can be retried.

Once the card has been quiesced, the hardware send queue lock is acquired
to prevent any data movement while the pending commands are processed.

	Signed-off-by: Uma Krishnan <ukrishn@linux.vnet.ibm.com>
	Acked-by: Matthew R. Ochs <mrochs@linux.vnet.ibm.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit a1ea04b3ebd9ae5c1cd5bf48be37aba0d93c1acc)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/cxlflash/common.h
#	drivers/scsi/cxlflash/main.c
diff --cc drivers/scsi/cxlflash/common.h
index 811927d91c5c,11a5b0a10a34..000000000000
--- a/drivers/scsi/cxlflash/common.h
+++ b/drivers/scsi/cxlflash/common.h
@@@ -132,13 -151,16 +132,20 @@@ struct cxlflash_cfg 
  struct afu_cmd {
  	struct sisl_ioarcb rcb;	/* IOARCB (cache line aligned) */
  	struct sisl_ioasa sa;	/* IOASA must follow IOARCB */
 -	struct afu *parent;
 -	struct scsi_cmnd *scp;
 +	spinlock_t slock;
  	struct completion cevent;
 -	struct list_head queue;
 -	u32 hwq_index;
 +	struct afu *parent;
 +	int slot;
 +	atomic_t free;
  
++<<<<<<< HEAD
 +	u8 cmd_tmf:1;
++=======
+ 	u8 cmd_tmf:1,
+ 	   cmd_aborted:1;
+ 
+ 	struct list_head list;	/* Pending commands link */
++>>>>>>> a1ea04b3ebd9 (scsi: cxlflash: Flush pending commands in cleanup path)
  
  	/* As per the SISLITE spec the IOARCB EA has to be 16-byte aligned.
  	 * However for performance reasons the IOARCB/IOASA should be
@@@ -146,14 -168,24 +153,32 @@@
  	 */
  } __aligned(cache_line_size());
  
++<<<<<<< HEAD
 +struct afu {
++=======
+ static inline struct afu_cmd *sc_to_afuc(struct scsi_cmnd *sc)
+ {
+ 	return PTR_ALIGN(scsi_cmd_priv(sc), __alignof__(struct afu_cmd));
+ }
+ 
+ static inline struct afu_cmd *sc_to_afucz(struct scsi_cmnd *sc)
+ {
+ 	struct afu_cmd *afuc = sc_to_afuc(sc);
+ 
+ 	memset(afuc, 0, sizeof(*afuc));
+ 	INIT_LIST_HEAD(&afuc->queue);
+ 	return afuc;
+ }
+ 
+ struct hwq {
++>>>>>>> a1ea04b3ebd9 (scsi: cxlflash: Flush pending commands in cleanup path)
  	/* Stuff requiring alignment go first. */
 -	struct sisl_ioarcb sq[NUM_SQ_ENTRY];		/* 16K SQ */
 -	u64 rrq_entry[NUM_RRQ_ENTRY];			/* 2K RRQ */
 +
 +	u64 rrq_entry[NUM_RRQ_ENTRY];	/* 2K RRQ */
 +	/*
 +	 * Command & data for AFU commands.
 +	 */
 +	struct afu_cmd cmd[CXLFLASH_NUM_CMDS];
  
  	/* Beware of alignment till here. Preferably introduce new
  	 * fields after this point
diff --cc drivers/scsi/cxlflash/main.c
index c68badcfa77f,0a3de42310ec..000000000000
--- a/drivers/scsi/cxlflash/main.c
+++ b/drivers/scsi/cxlflash/main.c
@@@ -253,38 -194,60 +253,74 @@@ static void cmd_complete(struct afu_cm
  }
  
  /**
++<<<<<<< HEAD
 + * context_reset() - timeout handler for AFU commands
 + * @cmd:	AFU command that timed out.
++=======
+  * flush_pending_cmds() - flush all pending commands on this hardware queue
+  * @hwq:	Hardware queue to flush.
+  *
+  * The hardware send queue lock associated with this hardware queue must be
+  * held when calling this routine.
+  */
+ static void flush_pending_cmds(struct hwq *hwq)
+ {
+ 	struct afu_cmd *cmd, *tmp;
+ 	struct scsi_cmnd *scp;
+ 
+ 	list_for_each_entry_safe(cmd, tmp, &hwq->pending_cmds, list) {
+ 		/* Bypass command when on a doneq, cmd_complete() will handle */
+ 		if (!list_empty(&cmd->queue))
+ 			continue;
+ 
+ 		list_del(&cmd->list);
+ 
+ 		if (cmd->scp) {
+ 			scp = cmd->scp;
+ 			scp->result = (DID_IMM_RETRY << 16);
+ 			scp->scsi_done(scp);
+ 		} else {
+ 			cmd->cmd_aborted = true;
+ 			complete(&cmd->cevent);
+ 		}
+ 	}
+ }
+ 
+ /**
+  * context_reset() - reset context via specified register
+  * @hwq:	Hardware queue owning the context to be reset.
+  * @reset_reg:	MMIO register to perform reset.
++>>>>>>> a1ea04b3ebd9 (scsi: cxlflash: Flush pending commands in cleanup path)
   *
 - * Return: 0 on success, -errno on failure
 + * Sends a reset to the AFU.
   */
 -static int context_reset(struct hwq *hwq, __be64 __iomem *reset_reg)
 +static void context_reset(struct afu_cmd *cmd)
  {
 -	struct cxlflash_cfg *cfg = hwq->afu->parent;
 -	struct device *dev = &cfg->dev->dev;
 -	int rc = -ETIMEDOUT;
  	int nretry = 0;
 -	u64 val = 0x1;
 +	u64 rrin = 0x1;
 +	struct afu *afu = cmd->parent;
 +	struct cxlflash_cfg *cfg = afu->parent;
 +	struct device *dev = &cfg->dev->dev;
 +	ulong lock_flags;
 +
 +	pr_debug("%s: cmd=%p\n", __func__, cmd);
 +
 +	spin_lock_irqsave(&cmd->slock, lock_flags);
 +
 +	/* Already completed? */
 +	if (cmd->sa.host_use_b[0] & B_DONE) {
 +		spin_unlock_irqrestore(&cmd->slock, lock_flags);
 +		return;
 +	}
  
 -	dev_dbg(dev, "%s: hwq=%p\n", __func__, hwq);
 +	cmd->sa.host_use_b[0] |= (B_DONE | B_ERROR | B_TIMEOUT);
 +	spin_unlock_irqrestore(&cmd->slock, lock_flags);
  
 -	writeq_be(val, reset_reg);
 +	writeq_be(rrin, &afu->host_map->ioarrin);
  	do {
 -		val = readq_be(reset_reg);
 -		if ((val & 0x1) == 0x0) {
 -			rc = 0;
 +		rrin = readq_be(&afu->host_map->ioarrin);
 +		if (rrin != 0x1)
  			break;
 -		}
 -
  		/* Double delay each time */
  		udelay(1 << nretry);
  	} while (nretry++ < MC_ROOM_RETRY_CNT);
@@@ -346,13 -385,55 +382,63 @@@ static void wait_resp(struct afu *afu, 
  
  	timeout = wait_for_completion_timeout(&cmd->cevent, timeout);
  	if (!timeout)
 -		rc = -ETIMEDOUT;
 -
 +		context_reset(cmd);
 +
++<<<<<<< HEAD
 +	if (unlikely(cmd->sa.ioasc != 0))
 +		pr_err("%s: CMD 0x%X failed, IOASC: flags 0x%X, afu_rc 0x%X, "
 +		       "scsi_rc 0x%X, fc_rc 0x%X\n", __func__, cmd->rcb.cdb[0],
 +		       cmd->sa.rc.flags, cmd->sa.rc.afu_rc, cmd->sa.rc.scsi_rc,
 +		       cmd->sa.rc.fc_rc);
++=======
+ 	if (cmd->cmd_aborted)
+ 		rc = -EAGAIN;
+ 
+ 	if (unlikely(cmd->sa.ioasc != 0)) {
+ 		dev_err(dev, "%s: cmd %02x failed, ioasc=%08x\n",
+ 			__func__, cmd->rcb.cdb[0], cmd->sa.ioasc);
+ 		rc = -EIO;
+ 	}
+ 
+ 	return rc;
+ }
+ 
+ /**
+  * cmd_to_target_hwq() - selects a target hardware queue for a SCSI command
+  * @host:	SCSI host associated with device.
+  * @scp:	SCSI command to send.
+  * @afu:	SCSI command to send.
+  *
+  * Hashes a command based upon the hardware queue mode.
+  *
+  * Return: Trusted index of target hardware queue
+  */
+ static u32 cmd_to_target_hwq(struct Scsi_Host *host, struct scsi_cmnd *scp,
+ 			     struct afu *afu)
+ {
+ 	u32 tag;
+ 	u32 hwq = 0;
+ 
+ 	if (afu->num_hwqs == 1)
+ 		return 0;
+ 
+ 	switch (afu->hwq_mode) {
+ 	case HWQ_MODE_RR:
+ 		hwq = afu->hwq_rr_count++ % afu->num_hwqs;
+ 		break;
+ 	case HWQ_MODE_TAG:
+ 		tag = blk_mq_unique_tag(scp->request);
+ 		hwq = blk_mq_unique_tag_to_hwq(tag);
+ 		break;
+ 	case HWQ_MODE_CPU:
+ 		hwq = smp_processor_id() % afu->num_hwqs;
+ 		break;
+ 	default:
+ 		WARN_ON_ONCE(1);
+ 	}
+ 
+ 	return hwq;
++>>>>>>> a1ea04b3ebd9 (scsi: cxlflash: Flush pending commands in cleanup path)
  }
  
  /**
@@@ -660,20 -730,33 +746,43 @@@ static void term_intr(struct cxlflash_c
   *
   * Safe to call with AFU/MC in partially allocated/initialized state.
   */
 -static void term_mc(struct cxlflash_cfg *cfg, u32 index)
 +static void term_mc(struct cxlflash_cfg *cfg)
  {
 +	int rc = 0;
  	struct afu *afu = cfg->afu;
  	struct device *dev = &cfg->dev->dev;
++<<<<<<< HEAD
++=======
+ 	struct hwq *hwq;
+ 	ulong lock_flags;
++>>>>>>> a1ea04b3ebd9 (scsi: cxlflash: Flush pending commands in cleanup path)
  
 -	if (!afu) {
 -		dev_err(dev, "%s: returning with NULL afu\n", __func__);
 +	if (!afu || !cfg->mcctx) {
 +		dev_err(dev, "%s: returning with NULL afu or MC\n", __func__);
  		return;
  	}
  
++<<<<<<< HEAD
 +	rc = cxl_stop_context(cfg->mcctx);
 +	WARN_ON(rc);
 +	cfg->mcctx = NULL;
++=======
+ 	hwq = get_hwq(afu, index);
+ 
+ 	if (!hwq->ctx) {
+ 		dev_err(dev, "%s: returning with NULL MC\n", __func__);
+ 		return;
+ 	}
+ 
+ 	WARN_ON(cxl_stop_context(hwq->ctx));
+ 	if (index != PRIMARY_HWQ)
+ 		WARN_ON(cxl_release_context(hwq->ctx));
+ 	hwq->ctx = NULL;
+ 
+ 	spin_lock_irqsave(&hwq->hsq_slock, lock_flags);
+ 	flush_pending_cmds(hwq);
+ 	spin_unlock_irqrestore(&hwq->hsq_slock, lock_flags);
++>>>>>>> a1ea04b3ebd9 (scsi: cxlflash: Flush pending commands in cleanup path)
  }
  
  /**
@@@ -1813,27 -2192,29 +1922,39 @@@ int cxlflash_afu_sync(struct afu *afu, 
  	}
  
  	mutex_lock(&sync_active);
++<<<<<<< HEAD
 +	buf = kzalloc(sizeof(*cmd) + __alignof__(*cmd) - 1, GFP_KERNEL);
++=======
+ 	atomic_inc(&afu->cmds_active);
+ 	buf = kmalloc(sizeof(*cmd) + __alignof__(*cmd) - 1, GFP_KERNEL);
++>>>>>>> a1ea04b3ebd9 (scsi: cxlflash: Flush pending commands in cleanup path)
  	if (unlikely(!buf)) {
  		dev_err(dev, "%s: no memory for command\n", __func__);
 -		rc = -ENOMEM;
 +		rc = -1;
  		goto out;
  	}
  
  	cmd = (struct afu_cmd *)PTR_ALIGN(buf, __alignof__(*cmd));
++<<<<<<< HEAD
++=======
+ 
+ retry:
+ 	memset(cmd, 0, sizeof(*cmd));
+ 	INIT_LIST_HEAD(&cmd->queue);
++>>>>>>> a1ea04b3ebd9 (scsi: cxlflash: Flush pending commands in cleanup path)
  	init_completion(&cmd->cevent);
 +	spin_lock_init(&cmd->slock);
  	cmd->parent = afu;
 -	cmd->hwq_index = hwq->index;
  
 -	dev_dbg(dev, "%s: afu=%p cmd=%p ctx=%d nretry=%d\n",
 -		__func__, afu, cmd, ctx_hndl_u, nretry);
 +	pr_debug("%s: afu=%p cmd=%p %d\n", __func__, afu, cmd, ctx_hndl_u);
  
  	cmd->rcb.req_flags = SISL_REQ_FLAGS_AFU_CMD;
 -	cmd->rcb.ctx_id = hwq->ctx_hndl;
 +	cmd->rcb.ctx_id = afu->ctx_hndl;
  	cmd->rcb.msi = SISL_MSI_RRQ_UPDATED;
 +	cmd->rcb.port_sel = 0x0;	/* NA */
 +	cmd->rcb.lun_id = 0x0;	/* NA */
 +	cmd->rcb.data_len = 0x0;
 +	cmd->rcb.data_ea = 0x0;
  	cmd->rcb.timeout = MC_AFU_SYNC_TIMEOUT;
  
  	cmd->rcb.cdb[0] = 0xC0;	/* AFU Sync */
@@@ -1843,41 -2224,34 +1964,60 @@@
  	*((__be16 *)&cmd->rcb.cdb[2]) = cpu_to_be16(ctx_hndl_u);
  	*((__be32 *)&cmd->rcb.cdb[4]) = cpu_to_be32(res_hndl_u);
  
 -	rc = afu->send_cmd(afu, cmd);
 -	if (unlikely(rc)) {
 -		rc = -ENOBUFS;
 +	rc = send_cmd(afu, cmd);
 +	if (unlikely(rc))
  		goto out;
 -	}
  
++<<<<<<< HEAD
 +	wait_resp(afu, cmd);
++=======
+ 	rc = wait_resp(afu, cmd);
+ 	switch (rc) {
+ 	case -ETIMEDOUT:
+ 		rc = afu->context_reset(hwq);
+ 		if (rc) {
+ 			cxlflash_schedule_async_reset(cfg);
+ 			break;
+ 		}
+ 		/* fall through to retry */
+ 	case -EAGAIN:
+ 		if (++nretry < 2)
+ 			goto retry;
+ 		/* fall through to exit */
+ 	default:
+ 		break;
+ 	}
++>>>>>>> a1ea04b3ebd9 (scsi: cxlflash: Flush pending commands in cleanup path)
  
 +	/* Set on timeout */
 +	if (unlikely((cmd->sa.ioasc != 0) ||
 +		     (cmd->sa.host_use_b[0] & B_ERROR)))
 +		rc = -1;
  out:
 -	atomic_dec(&afu->cmds_active);
  	mutex_unlock(&sync_active);
  	kfree(buf);
 -	dev_dbg(dev, "%s: returning rc=%d\n", __func__, rc);
 +	pr_debug("%s: returning rc=%d\n", __func__, rc);
 +	return rc;
 +}
 +
 +/**
 + * afu_reset() - resets the AFU
 + * @cfg:	Internal structure associated with the host.
 + *
 + * Return: 0 on success, -errno on failure
 + */
 +static int afu_reset(struct cxlflash_cfg *cfg)
 +{
 +	int rc = 0;
 +	/* Stop the context before the reset. Since the context is
 +	 * no longer available restart it after the reset is complete
 +	 */
 +
 +	term_afu(cfg);
 +
 +	rc = init_afu(cfg);
 +
 +	pr_debug("%s: returning rc=%d\n", __func__, rc);
  	return rc;
  }
  
* Unmerged path drivers/scsi/cxlflash/common.h
* Unmerged path drivers/scsi/cxlflash/main.c
