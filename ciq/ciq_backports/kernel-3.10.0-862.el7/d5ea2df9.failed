IB/mlx5: Add helper mlx5_ib_post_send_wait

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Binoy Jayan <binoy.jayan@linaro.org>
commit d5ea2df9cefa9c81a66021b5bb89562d02bbc2f7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/d5ea2df9.failed

Clean up the following common code (to post a list of work requests to the
send queue of the specified QP) at various places and add a helper function
'mlx5_ib_post_send_wait' to implement the same.

 - Initialize 'mlx5_ib_umr_context' on stack
 - Assign "mlx5_umr_wr:wr:wr_cqe to umr_context.cqe
 - Acquire the semaphore
 - call ib_post_send with a single ib_send_wr
 - wait_for_completion()
 - Check for umr_context.status
 - Release the semaphore

	Signed-off-by: Binoy Jayan <binoy.jayan@linaro.org>
	Signed-off-by: Leon Romanovsky <leon@kernel.org>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit d5ea2df9cefa9c81a66021b5bb89562d02bbc2f7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/mr.c
diff --cc drivers/infiniband/hw/mlx5/mr.c
index 87ca81b85fd0,7ab9b67ce43b..000000000000
--- a/drivers/infiniband/hw/mlx5/mr.c
+++ b/drivers/infiniband/hw/mlx5/mr.c
@@@ -896,11 -923,8 +923,14 @@@ static struct mlx5_ib_mr *reg_umr(struc
  				  int page_shift, int order, int access_flags)
  {
  	struct mlx5_ib_dev *dev = to_mdev(pd->device);
++<<<<<<< HEAD
 +	struct device *ddev = dev->ib_dev.dev.parent;
 +	struct umr_common *umrc = &dev->umrc;
 +	struct mlx5_ib_umr_context umr_context;
++=======
+ 	struct device *ddev = dev->ib_dev.dma_device;
++>>>>>>> d5ea2df9cefa (IB/mlx5: Add helper mlx5_ib_post_send_wait)
  	struct mlx5_umr_wr umrwr = {};
- 	struct ib_send_wr *bad;
  	struct mlx5_ib_mr *mr;
  	struct ib_sge sg;
  	int size;
@@@ -974,9 -985,7 +991,13 @@@ int mlx5_ib_update_mtt(struct mlx5_ib_m
  		       int zap)
  {
  	struct mlx5_ib_dev *dev = mr->dev;
++<<<<<<< HEAD
 +	struct device *ddev = dev->ib_dev.dev.parent;
 +	struct umr_common *umrc = &dev->umrc;
 +	struct mlx5_ib_umr_context umr_context;
++=======
+ 	struct device *ddev = dev->ib_dev.dma_device;
++>>>>>>> d5ea2df9cefa (IB/mlx5: Add helper mlx5_ib_post_send_wait)
  	struct ib_umem *umem = mr->umem;
  	int size;
  	__be64 *pas;
@@@ -1288,12 -1256,9 +1268,15 @@@ static int rereg_umr(struct ib_pd *pd, 
  		     int access_flags, int flags)
  {
  	struct mlx5_ib_dev *dev = to_mdev(pd->device);
++<<<<<<< HEAD
 +	struct device *ddev = dev->ib_dev.dev.parent;
 +	struct mlx5_ib_umr_context umr_context;
 +	struct ib_send_wr *bad;
++=======
+ 	struct device *ddev = dev->ib_dev.dma_device;
++>>>>>>> d5ea2df9cefa (IB/mlx5: Add helper mlx5_ib_post_send_wait)
  	struct mlx5_umr_wr umrwr = {};
  	struct ib_sge sg;
- 	struct umr_common *umrc = &dev->umrc;
  	dma_addr_t dma = 0;
  	__be64 *mr_pas = NULL;
  	int size;
* Unmerged path drivers/infiniband/hw/mlx5/mr.c
