userfaultfd: shmem: add shmem_mfill_zeropage_pte for userfaultfd support

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Mike Rapoport <rppt@linux.vnet.ibm.com>
commit 8d10396342063c79e92c4e46215370ab7b988569
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/8d103963.failed

shmem_mfill_zeropage_pte is the low level routine that implements the
userfaultfd UFFDIO_ZEROPAGE command.  Since for shmem mappings zero
pages are always allocated and accounted, the new method is a slight
extension of the existing shmem_mcopy_atomic_pte.

Link: http://lkml.kernel.org/r/1497939652-16528-4-git-send-email-rppt@linux.vnet.ibm.com
	Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
	Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
	Cc: Andrea Arcangeli <aarcange@redhat.com>
	Cc: Hillf Danton <hillf.zj@alibaba-inc.com>
	Cc: Hugh Dickins <hughd@google.com>
	Cc: Pavel Emelyanov <xemul@virtuozzo.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 8d10396342063c79e92c4e46215370ab7b988569)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/shmem.c
diff --cc mm/shmem.c
index 570b71564183,64bdc91187f7..000000000000
--- a/mm/shmem.c
+++ b/mm/shmem.c
@@@ -1548,15 -2204,16 +1548,16 @@@ static struct inode *shmem_get_inode(st
  
  bool shmem_mapping(struct address_space *mapping)
  {
 -	return mapping->a_ops == &shmem_aops;
 +	return mapping->backing_dev_info == &shmem_backing_dev_info;
  }
  
- int shmem_mcopy_atomic_pte(struct mm_struct *dst_mm,
- 			   pmd_t *dst_pmd,
- 			   struct vm_area_struct *dst_vma,
- 			   unsigned long dst_addr,
- 			   unsigned long src_addr,
- 			   struct page **pagep)
+ static int shmem_mfill_atomic_pte(struct mm_struct *dst_mm,
+ 				  pmd_t *dst_pmd,
+ 				  struct vm_area_struct *dst_vma,
+ 				  unsigned long dst_addr,
+ 				  unsigned long src_addr,
+ 				  bool zeropage,
+ 				  struct page **pagep)
  {
  	struct inode *inode = file_inode(dst_vma->vm_file);
  	struct shmem_inode_info *info = SHMEM_I(inode);
@@@ -1583,21 -2234,24 +1584,35 @@@
  	if (!*pagep) {
  		page = shmem_alloc_page(gfp, info, pgoff);
  		if (!page)
 -			goto out_unacct_blocks;
 +			goto out_dec_used_blocks;
  
- 		page_kaddr = kmap_atomic(page);
- 		ret = copy_from_user(page_kaddr, (const void __user *)src_addr,
- 				     PAGE_SIZE);
- 		kunmap_atomic(page_kaddr);
+ 		if (!zeropage) {	/* mcopy_atomic */
+ 			page_kaddr = kmap_atomic(page);
+ 			ret = copy_from_user(page_kaddr,
+ 					     (const void __user *)src_addr,
+ 					     PAGE_SIZE);
+ 			kunmap_atomic(page_kaddr);
  
++<<<<<<< HEAD
 +		/* fallback to copy_from_user outside mmap_sem */
 +		if (unlikely(ret)) {
 +			*pagep = page;
 +			if (sbinfo->max_blocks)
 +				percpu_counter_add(&sbinfo->used_blocks, -1);
 +			shmem_unacct_blocks(info->flags, 1);
 +			/* don't free the page */
 +			return -EFAULT;
++=======
+ 			/* fallback to copy_from_user outside mmap_sem */
+ 			if (unlikely(ret)) {
+ 				*pagep = page;
+ 				shmem_inode_unacct_blocks(inode, 1);
+ 				/* don't free the page */
+ 				return -EFAULT;
+ 			}
+ 		} else {		/* mfill_zeropage_atomic */
+ 			clear_highpage(page);
++>>>>>>> 8d1039634206 (userfaultfd: shmem: add shmem_mfill_zeropage_pte for userfaultfd support)
  		}
  	} else {
  		page = *pagep;
diff --git a/include/linux/shmem_fs.h b/include/linux/shmem_fs.h
index 5152fdf862ab..284da6c2483a 100644
--- a/include/linux/shmem_fs.h
+++ b/include/linux/shmem_fs.h
@@ -92,9 +92,15 @@ extern int shmem_mcopy_atomic_pte(struct mm_struct *dst_mm, pmd_t *dst_pmd,
 				  unsigned long dst_addr,
 				  unsigned long src_addr,
 				  struct page **pagep);
+extern int shmem_mfill_zeropage_pte(struct mm_struct *dst_mm,
+				    pmd_t *dst_pmd,
+				    struct vm_area_struct *dst_vma,
+				    unsigned long dst_addr);
 #else
 #define shmem_mcopy_atomic_pte(dst_mm, dst_pte, dst_vma, dst_addr, \
 			       src_addr, pagep)        ({ BUG(); 0; })
+#define shmem_mfill_zeropage_pte(dst_mm, dst_pmd, dst_vma, \
+				 dst_addr)      ({ BUG(); 0; })
 #endif
 
 #endif
* Unmerged path mm/shmem.c
