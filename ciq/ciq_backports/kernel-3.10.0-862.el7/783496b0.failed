nfp: pass new data path to ring reconfig

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Jakub Kicinski <jakub.kicinski@netronome.com>
commit 783496b0ddc2bd4ad561864138596ebb336a7100
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/783496b0.failed

Make callers of nfp_net_ring_reconfig() pass newly allocated data
path structure.  We will gradually make use of that structure
instead of passing parameters around to all the allocation functions.
This commit adds allocation and propagation of new data path struct,
no parameters are converted, yet.

	Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 783496b0ddc2bd4ad561864138596ebb336a7100)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/netronome/nfp/nfp_net.h
#	drivers/net/ethernet/netronome/nfp/nfp_net_common.c
#	drivers/net/ethernet/netronome/nfp/nfp_net_ethtool.c
diff --cc drivers/net/ethernet/netronome/nfp/nfp_net.h
index 1826ee93d1da,74f6d485351f..000000000000
--- a/drivers/net/ethernet/netronome/nfp/nfp_net.h
+++ b/drivers/net/ethernet/netronome/nfp/nfp_net.h
@@@ -755,9 -812,12 +755,17 @@@ void nfp_net_irqs_disable(struct pci_de
  void
  nfp_net_irqs_assign(struct nfp_net *nn, struct msix_entry *irq_entries,
  		    unsigned int n);
+ 
+ struct nfp_net_dp *nfp_net_clone_dp(struct nfp_net *nn);
  int
++<<<<<<< HEAD
 +nfp_net_ring_reconfig(struct nfp_net *nn, struct nfp_net_ring_set *rx,
 +		      struct nfp_net_ring_set *tx);
++=======
+ nfp_net_ring_reconfig(struct nfp_net *nn, struct nfp_net_dp *new,
+ 		      struct bpf_prog **xdp_prog,
+ 		      struct nfp_net_ring_set *rx, struct nfp_net_ring_set *tx);
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  
  #ifdef CONFIG_NFP_DEBUG
  void nfp_net_debugfs_create(void);
diff --cc drivers/net/ethernet/netronome/nfp/nfp_net_common.c
index e0a7eb1db7a9,7afefb44b642..000000000000
--- a/drivers/net/ethernet/netronome/nfp/nfp_net_common.c
+++ b/drivers/net/ethernet/netronome/nfp/nfp_net_common.c
@@@ -1048,8 -1116,18 +1048,9 @@@ nfp_net_calc_fl_bufsz(struct nfp_net *n
  	return fl_bufsz;
  }
  
 -static void
 -nfp_net_free_frag(void *frag, bool xdp)
 -{
 -	if (!xdp)
 -		skb_free_frag(frag);
 -	else
 -		__free_page(virt_to_page(frag));
 -}
 -
  /**
   * nfp_net_rx_alloc_one() - Allocate and map page frag for RX
+  * @dp:		NFP Net data path struct
   * @rx_ring:	RX ring structure of the skb
   * @dma_addr:	Pointer to storage for DMA address (output param)
   * @fl_bufsz:	size of freelist buffers
@@@ -1059,15 -1138,19 +1060,23 @@@
   * Return: allocated page frag or NULL on failure.
   */
  static void *
++<<<<<<< HEAD
 +nfp_net_rx_alloc_one(struct nfp_net_rx_ring *rx_ring, dma_addr_t *dma_addr,
 +		     unsigned int fl_bufsz)
 +{
 +	struct nfp_net *nn = rx_ring->r_vec->nfp_net;
++=======
+ nfp_net_rx_alloc_one(struct nfp_net_dp *dp,
+ 		     struct nfp_net_rx_ring *rx_ring, dma_addr_t *dma_addr,
+ 		     unsigned int fl_bufsz, bool xdp)
+ {
+ 	int direction;
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  	void *frag;
  
 -	if (!xdp)
 -		frag = netdev_alloc_frag(fl_bufsz);
 -	else
 -		frag = page_address(alloc_page(GFP_KERNEL | __GFP_COLD));
 +	frag = netdev_alloc_frag(fl_bufsz);
  	if (!frag) {
 -		nn_dp_warn(dp, "Failed to alloc receive page frag\n");
 +		nn_warn_ratelimit(nn, "Failed to alloc receive page frag\n");
  		return NULL;
  	}
  
@@@ -1205,10 -1300,10 +1214,15 @@@ nfp_net_rx_ring_bufs_alloc(struct nfp_n
  
  	for (i = 0; i < rx_ring->cnt - 1; i++) {
  		rxbufs[i].frag =
++<<<<<<< HEAD
 +			nfp_net_rx_alloc_one(rx_ring, &rxbufs[i].dma_addr,
 +					     rx_ring->bufsz);
++=======
+ 			nfp_net_rx_alloc_one(dp, rx_ring, &rxbufs[i].dma_addr,
+ 					     rx_ring->bufsz, xdp);
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  		if (!rxbufs[i].frag) {
 -			nfp_net_rx_ring_bufs_free(dp, rx_ring, xdp);
 +			nfp_net_rx_ring_bufs_free(nn, rx_ring);
  			return -ENOMEM;
  		}
  	}
@@@ -1551,7 -1785,9 +1565,13 @@@ err_alloc
  }
  
  static struct nfp_net_tx_ring *
++<<<<<<< HEAD
 +nfp_net_tx_ring_set_prepare(struct nfp_net *nn, struct nfp_net_ring_set *s)
++=======
+ nfp_net_tx_ring_set_prepare(struct nfp_net *nn, struct nfp_net_dp *dp,
+ 			    struct nfp_net_ring_set *s,
+ 			    unsigned int num_stack_tx_rings)
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  {
  	struct nfp_net_tx_ring *rings;
  	unsigned int r;
@@@ -1668,9 -1902,10 +1688,16 @@@ err_alloc
  }
  
  static struct nfp_net_rx_ring *
++<<<<<<< HEAD
 +nfp_net_rx_ring_set_prepare(struct nfp_net *nn, struct nfp_net_ring_set *s)
 +{
 +	unsigned int fl_bufsz =	nfp_net_calc_fl_bufsz(nn, s->mtu);
++=======
+ nfp_net_rx_ring_set_prepare(struct nfp_net *nn, struct nfp_net_dp *dp,
+ 			    struct nfp_net_ring_set *s, bool xdp)
+ {
+ 	unsigned int fl_bufsz =	nfp_net_calc_fl_bufsz(dp, s->mtu);
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  	struct nfp_net_rx_ring *rings;
  	unsigned int r;
  
@@@ -1684,7 -1919,7 +1711,11 @@@
  		if (nfp_net_rx_ring_alloc(&rings[r], fl_bufsz, s->dcnt))
  			goto err_free_prev;
  
++<<<<<<< HEAD
 +		if (nfp_net_rx_ring_bufs_alloc(nn, &rings[r]))
++=======
+ 		if (nfp_net_rx_ring_bufs_alloc(dp, &rings[r], xdp))
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  			goto err_free_ring;
  	}
  
@@@ -1692,7 -1927,7 +1723,11 @@@
  
  err_free_prev:
  	while (r--) {
++<<<<<<< HEAD
 +		nfp_net_rx_ring_bufs_free(nn, &rings[r]);
++=======
+ 		nfp_net_rx_ring_bufs_free(dp, &rings[r], xdp);
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  err_free_ring:
  		nfp_net_rx_ring_free(&rings[r]);
  	}
@@@ -2057,14 -2297,16 +2092,26 @@@ static int nfp_net_netdev_open(struct n
  			goto err_cleanup_vec_p;
  	}
  
++<<<<<<< HEAD
 +	nn->rx_rings = nfp_net_rx_ring_set_prepare(nn, &rx);
 +	if (!nn->rx_rings) {
++=======
+ 	nn->dp.rx_rings = nfp_net_rx_ring_set_prepare(nn, &nn->dp, &rx,
+ 						      nn->dp.xdp_prog);
+ 	if (!nn->dp.rx_rings) {
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  		err = -ENOMEM;
  		goto err_cleanup_vec;
  	}
  
++<<<<<<< HEAD
 +	nn->tx_rings = nfp_net_tx_ring_set_prepare(nn, &tx);
 +	if (!nn->tx_rings) {
++=======
+ 	nn->dp.tx_rings = nfp_net_tx_ring_set_prepare(nn, &nn->dp, &tx,
+ 						      nn->dp.num_stack_tx_rings);
+ 	if (!nn->dp.tx_rings) {
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  		err = -ENOMEM;
  		goto err_free_rx_rings;
  	}
@@@ -2224,7 -2467,10 +2271,14 @@@ static void nfp_net_rss_init_itbl(struc
  }
  
  static int
++<<<<<<< HEAD
 +nfp_net_ring_swap_enable(struct nfp_net *nn, unsigned int *num_vecs,
++=======
+ nfp_net_ring_swap_enable(struct nfp_net *nn, struct nfp_net_dp *dp,
+ 			 unsigned int *num_vecs,
+ 			 unsigned int *stack_tx_rings,
+ 			 struct bpf_prog **xdp_prog,
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  			 struct nfp_net_ring_set *rx,
  			 struct nfp_net_ring_set *tx)
  {
@@@ -2259,37 -2506,90 +2313,107 @@@
  	return __nfp_net_set_config_and_enable(nn);
  }
  
++<<<<<<< HEAD
 +static void
 +nfp_net_ring_reconfig_down(struct nfp_net *nn,
++=======
+ struct nfp_net_dp *nfp_net_clone_dp(struct nfp_net *nn)
+ {
+ 	struct nfp_net_dp *new;
+ 
+ 	new = kmalloc(sizeof(*new), GFP_KERNEL);
+ 	if (!new)
+ 		return NULL;
+ 
+ 	*new = nn->dp;
+ 
+ 	/* Clear things which need to be recomputed */
+ 	new->fl_bufsz = 0;
+ 	new->tx_rings = NULL;
+ 	new->rx_rings = NULL;
+ 	new->num_r_vecs = 0;
+ 	new->num_stack_tx_rings = 0;
+ 
+ 	return new;
+ }
+ 
+ static int
+ nfp_net_check_config(struct nfp_net *nn, struct nfp_net_dp *dp,
+ 		     struct bpf_prog *xdp_prog,
+ 		     struct nfp_net_ring_set *rx, struct nfp_net_ring_set *tx)
+ {
+ 	/* XDP-enabled tests */
+ 	if (!xdp_prog)
+ 		return 0;
+ 	if (rx && nfp_net_calc_fl_bufsz(dp, rx->mtu) > PAGE_SIZE) {
+ 		nn_warn(nn, "MTU too large w/ XDP enabled\n");
+ 		return -EINVAL;
+ 	}
+ 	if (tx && tx->n_rings > nn->max_tx_rings) {
+ 		nn_warn(nn, "Insufficient number of TX rings w/ XDP enabled\n");
+ 		return -EINVAL;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void
+ nfp_net_ring_reconfig_down(struct nfp_net *nn, struct nfp_net_dp *dp,
+ 			   struct bpf_prog **xdp_prog,
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  			   struct nfp_net_ring_set *rx,
  			   struct nfp_net_ring_set *tx,
 -			   unsigned int stack_tx_rings, unsigned int num_vecs)
 -{
 -	nn->dp.netdev->mtu = rx ? rx->mtu : nn->dp.netdev->mtu;
 -	nn->dp.fl_bufsz = nfp_net_calc_fl_bufsz(&nn->dp, nn->dp.netdev->mtu);
 -	nn->dp.rxd_cnt = rx ? rx->dcnt : nn->dp.rxd_cnt;
 -	nn->dp.txd_cnt = tx ? tx->dcnt : nn->dp.txd_cnt;
 -	nn->dp.num_rx_rings = rx ? rx->n_rings : nn->dp.num_rx_rings;
 -	nn->dp.num_tx_rings = tx ? tx->n_rings : nn->dp.num_tx_rings;
 -	nn->dp.num_stack_tx_rings = stack_tx_rings;
 -	nn->dp.num_r_vecs = num_vecs;
 -	*xdp_prog = xchg(&nn->dp.xdp_prog, *xdp_prog);
 -
 -	if (!netif_is_rxfh_configured(nn->dp.netdev))
 +			   unsigned int num_vecs)
 +{
 +	nn->netdev->mtu = rx ? rx->mtu : nn->netdev->mtu;
 +	nn->fl_bufsz = nfp_net_calc_fl_bufsz(nn, nn->netdev->mtu);
 +	nn->rxd_cnt = rx ? rx->dcnt : nn->rxd_cnt;
 +	nn->txd_cnt = tx ? tx->dcnt : nn->txd_cnt;
 +	nn->num_rx_rings = rx ? rx->n_rings : nn->num_rx_rings;
 +	nn->num_tx_rings = tx ? tx->n_rings : nn->num_tx_rings;
 +	nn->num_r_vecs = num_vecs;
 +
 +	if (!netif_is_rxfh_configured(nn->netdev))
  		nfp_net_rss_init_itbl(nn);
  }
  
  int
++<<<<<<< HEAD
 +nfp_net_ring_reconfig(struct nfp_net *nn, struct nfp_net_ring_set *rx,
 +		      struct nfp_net_ring_set *tx)
++=======
+ nfp_net_ring_reconfig(struct nfp_net *nn, struct nfp_net_dp *dp,
+ 		      struct bpf_prog **xdp_prog,
+ 		      struct nfp_net_ring_set *rx, struct nfp_net_ring_set *tx)
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  {
 -	unsigned int stack_tx_rings, num_vecs, r;
 +	unsigned int num_vecs, r;
  	int err;
  
++<<<<<<< HEAD
 +	num_vecs = max(rx ? rx->n_rings : nn->num_rx_rings,
 +		       tx ? tx->n_rings : nn->num_tx_rings);
 +
 +	if (!netif_running(nn->netdev)) {
 +		nfp_net_ring_reconfig_down(nn, rx, tx, num_vecs);
 +		return 0;
++=======
+ 	stack_tx_rings = tx ? tx->n_rings : dp->num_tx_rings;
+ 	if (*xdp_prog)
+ 		stack_tx_rings -= rx ? rx->n_rings : dp->num_rx_rings;
+ 
+ 	num_vecs = max(rx ? rx->n_rings : dp->num_rx_rings, stack_tx_rings);
+ 
+ 	err = nfp_net_check_config(nn, dp, *xdp_prog, rx, tx);
+ 	if (err)
+ 		goto exit_free_dp;
+ 
+ 	if (!netif_running(dp->netdev)) {
+ 		nfp_net_ring_reconfig_down(nn, dp, xdp_prog, rx, tx,
+ 					   stack_tx_rings, num_vecs);
+ 		err = 0;
+ 		goto exit_free_dp;
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  	}
  
  	/* Prepare new rings */
@@@ -2301,13 -2601,13 +2425,21 @@@
  		}
  	}
  	if (rx) {
++<<<<<<< HEAD
 +		if (!nfp_net_rx_ring_set_prepare(nn, rx)) {
++=======
+ 		if (!nfp_net_rx_ring_set_prepare(nn, dp, rx, *xdp_prog)) {
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  			err = -ENOMEM;
  			goto err_cleanup_vecs;
  		}
  	}
  	if (tx) {
++<<<<<<< HEAD
 +		if (!nfp_net_tx_ring_set_prepare(nn, tx)) {
++=======
+ 		if (!nfp_net_tx_ring_set_prepare(nn, dp, tx, stack_tx_rings)) {
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  			err = -ENOMEM;
  			goto err_free_rx;
  		}
@@@ -2317,14 -2617,17 +2449,25 @@@
  	nfp_net_close_stack(nn);
  	nfp_net_clear_config_and_disable(nn);
  
++<<<<<<< HEAD
 +	err = nfp_net_ring_swap_enable(nn, &num_vecs, rx, tx);
++=======
+ 	err = nfp_net_ring_swap_enable(nn, dp, &num_vecs, &stack_tx_rings,
+ 				       xdp_prog, rx, tx);
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  	if (err) {
  		int err2;
  
  		nfp_net_clear_config_and_disable(nn);
  
  		/* Try with old configuration and old rings */
++<<<<<<< HEAD
 +		err2 = nfp_net_ring_swap_enable(nn, &num_vecs, rx, tx);
++=======
+ 		err2 = nfp_net_ring_swap_enable(nn, dp, &num_vecs,
+ 						&stack_tx_rings,
+ 						xdp_prog, rx, tx);
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  		if (err2)
  			nn_err(nn, "Can't restore ring config - FW communication failed (%d,%d)\n",
  			       err, err2);
@@@ -2333,20 -2636,23 +2476,31 @@@
  		nfp_net_cleanup_vector(nn, &nn->r_vecs[r]);
  
  	if (rx)
++<<<<<<< HEAD
 +		nfp_net_rx_ring_set_free(nn, rx);
++=======
+ 		nfp_net_rx_ring_set_free(dp, rx, *xdp_prog);
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  	if (tx)
 -		nfp_net_tx_ring_set_free(tx);
 +		nfp_net_tx_ring_set_free(nn, tx);
  
  	nfp_net_open_stack(nn);
+ exit_free_dp:
+ 	kfree(dp);
  
  	return err;
  
  err_free_rx:
  	if (rx)
++<<<<<<< HEAD
 +		nfp_net_rx_ring_set_free(nn, rx);
++=======
+ 		nfp_net_rx_ring_set_free(dp, rx, *xdp_prog);
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  err_cleanup_vecs:
 -	for (r = num_vecs - 1; r >= nn->dp.num_r_vecs; r--)
 +	for (r = num_vecs - 1; r >= nn->num_r_vecs; r--)
  		nfp_net_cleanup_vector(nn, &nn->r_vecs[r]);
+ 	kfree(dp);
  	return err;
  }
  
@@@ -2354,16 -2660,21 +2508,25 @@@ static int nfp_net_change_mtu(struct ne
  {
  	struct nfp_net *nn = netdev_priv(netdev);
  	struct nfp_net_ring_set rx = {
 -		.n_rings = nn->dp.num_rx_rings,
 +		.n_rings = nn->num_rx_rings,
  		.mtu = new_mtu,
 -		.dcnt = nn->dp.rxd_cnt,
 +		.dcnt = nn->rxd_cnt,
  	};
+ 	struct nfp_net_dp *dp;
  
++<<<<<<< HEAD
 +	return nfp_net_ring_reconfig(nn, &rx, NULL);
++=======
+ 	dp = nfp_net_clone_dp(nn);
+ 	if (!dp)
+ 		return -ENOMEM;
+ 
+ 	return nfp_net_ring_reconfig(nn, dp, &nn->dp.xdp_prog, &rx, NULL);
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  }
  
 -static void nfp_net_stat64(struct net_device *netdev,
 -			   struct rtnl_link_stats64 *stats)
 +static struct rtnl_link_stats64 *nfp_net_stat64(struct net_device *netdev,
 +						struct rtnl_link_stats64 *stats)
  {
  	struct nfp_net *nn = netdev_priv(netdev);
  	int r;
@@@ -2595,8 -2958,97 +2758,101 @@@ static void nfp_net_del_vxlan_port(stru
  		nfp_net_set_vxlan_port(nn, idx, 0);
  }
  
++<<<<<<< HEAD
++=======
+ static int nfp_net_xdp_offload(struct nfp_net *nn, struct bpf_prog *prog)
+ {
+ 	struct tc_cls_bpf_offload cmd = {
+ 		.prog = prog,
+ 	};
+ 	int ret;
+ 
+ 	if (!nfp_net_ebpf_capable(nn))
+ 		return -EINVAL;
+ 
+ 	if (nn->dp.ctrl & NFP_NET_CFG_CTRL_BPF) {
+ 		if (!nn->dp.bpf_offload_xdp)
+ 			return prog ? -EBUSY : 0;
+ 		cmd.command = prog ? TC_CLSBPF_REPLACE : TC_CLSBPF_DESTROY;
+ 	} else {
+ 		if (!prog)
+ 			return 0;
+ 		cmd.command = TC_CLSBPF_ADD;
+ 	}
+ 
+ 	ret = nfp_net_bpf_offload(nn, &cmd);
+ 	/* Stop offload if replace not possible */
+ 	if (ret && cmd.command == TC_CLSBPF_REPLACE)
+ 		nfp_net_xdp_offload(nn, NULL);
+ 	nn->dp.bpf_offload_xdp = prog && !ret;
+ 	return ret;
+ }
+ 
+ static int nfp_net_xdp_setup(struct nfp_net *nn, struct bpf_prog *prog)
+ {
+ 	struct nfp_net_ring_set rx = {
+ 		.n_rings = nn->dp.num_rx_rings,
+ 		.mtu = nn->dp.netdev->mtu,
+ 		.dcnt = nn->dp.rxd_cnt,
+ 	};
+ 	struct nfp_net_ring_set tx = {
+ 		.n_rings = nn->dp.num_tx_rings,
+ 		.dcnt = nn->dp.txd_cnt,
+ 	};
+ 	struct nfp_net_dp *dp;
+ 	int err;
+ 
+ 	if (prog && prog->xdp_adjust_head) {
+ 		nn_err(nn, "Does not support bpf_xdp_adjust_head()\n");
+ 		return -EOPNOTSUPP;
+ 	}
+ 	if (!prog && !nn->dp.xdp_prog)
+ 		return 0;
+ 	if (prog && nn->dp.xdp_prog) {
+ 		prog = xchg(&nn->dp.xdp_prog, prog);
+ 		bpf_prog_put(prog);
+ 		nfp_net_xdp_offload(nn, nn->dp.xdp_prog);
+ 		return 0;
+ 	}
+ 
+ 	dp = nfp_net_clone_dp(nn);
+ 	if (!dp)
+ 		return -ENOMEM;
+ 
+ 	tx.n_rings += prog ? nn->dp.num_rx_rings : -nn->dp.num_rx_rings;
+ 
+ 	/* We need RX reconfig to remap the buffers (BIDIR vs FROM_DEV) */
+ 	err = nfp_net_ring_reconfig(nn, dp, &prog, &rx, &tx);
+ 	if (err)
+ 		return err;
+ 
+ 	/* @prog got swapped and is now the old one */
+ 	if (prog)
+ 		bpf_prog_put(prog);
+ 
+ 	nfp_net_xdp_offload(nn, nn->dp.xdp_prog);
+ 
+ 	return 0;
+ }
+ 
+ static int nfp_net_xdp(struct net_device *netdev, struct netdev_xdp *xdp)
+ {
+ 	struct nfp_net *nn = netdev_priv(netdev);
+ 
+ 	switch (xdp->command) {
+ 	case XDP_SETUP_PROG:
+ 		return nfp_net_xdp_setup(nn, xdp->prog);
+ 	case XDP_QUERY_PROG:
+ 		xdp->prog_attached = !!nn->dp.xdp_prog;
+ 		return 0;
+ 	default:
+ 		return -EINVAL;
+ 	}
+ }
+ 
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  static const struct net_device_ops nfp_net_netdev_ops = {
 +	.ndo_size		= sizeof(struct net_device_ops),
  	.ndo_open		= nfp_net_netdev_open,
  	.ndo_stop		= nfp_net_netdev_close,
  	.ndo_start_xmit		= nfp_net_tx,
diff --cc drivers/net/ethernet/netronome/nfp/nfp_net_ethtool.c
index dfbf6b94ff5b,326ccd74a4bf..000000000000
--- a/drivers/net/ethernet/netronome/nfp/nfp_net_ethtool.c
+++ b/drivers/net/ethernet/netronome/nfp/nfp_net_ethtool.c
@@@ -180,16 -193,22 +180,26 @@@ static int nfp_net_set_ring_size(struc
  		.dcnt = rxd_cnt,
  	};
  	struct nfp_net_ring_set tx = {
 -		.n_rings = nn->dp.num_tx_rings,
 +		.n_rings = nn->num_tx_rings,
  		.dcnt = txd_cnt,
  	};
+ 	struct nfp_net_dp *dp;
  
 -	if (nn->dp.rxd_cnt != rxd_cnt)
 +	if (nn->rxd_cnt != rxd_cnt)
  		reconfig_rx = &rx;
 -	if (nn->dp.txd_cnt != txd_cnt)
 +	if (nn->txd_cnt != txd_cnt)
  		reconfig_tx = &tx;
  
++<<<<<<< HEAD
 +	return nfp_net_ring_reconfig(nn, reconfig_rx, reconfig_tx);
++=======
+ 	dp = nfp_net_clone_dp(nn);
+ 	if (!dp)
+ 		return -ENOMEM;
+ 
+ 	return nfp_net_ring_reconfig(nn, dp, &nn->dp.xdp_prog,
+ 				     reconfig_rx, reconfig_tx);
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  }
  
  static int nfp_net_set_ringparam(struct net_device *netdev,
@@@ -743,15 -775,26 +753,29 @@@ static int nfp_net_set_num_rings(struc
  	};
  	struct nfp_net_ring_set tx = {
  		.n_rings = total_tx,
 -		.dcnt = nn->dp.txd_cnt,
 +		.dcnt = nn->txd_cnt,
  	};
+ 	struct nfp_net_dp *dp;
  
 -	if (nn->dp.num_rx_rings != total_rx)
 +	if (nn->num_rx_rings != total_rx)
  		reconfig_rx = &rx;
 -	if (nn->dp.num_stack_tx_rings != total_tx ||
 -	    (nn->dp.xdp_prog && reconfig_rx))
 +	if (nn->num_tx_rings != total_tx)
  		reconfig_tx = &tx;
  
++<<<<<<< HEAD
 +	return nfp_net_ring_reconfig(nn, reconfig_rx, reconfig_tx);
++=======
+ 	/* nfp_net_check_config() will catch tx.n_rings > nn->max_tx_rings */
+ 	if (nn->dp.xdp_prog)
+ 		tx.n_rings += total_rx;
+ 
+ 	dp = nfp_net_clone_dp(nn);
+ 	if (!dp)
+ 		return -ENOMEM;
+ 
+ 	return nfp_net_ring_reconfig(nn, dp, &nn->dp.xdp_prog,
+ 				     reconfig_rx, reconfig_tx);
++>>>>>>> 783496b0ddc2 (nfp: pass new data path to ring reconfig)
  }
  
  static int nfp_net_set_channels(struct net_device *netdev,
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_net.h
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_net_common.c
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_net_ethtool.c
