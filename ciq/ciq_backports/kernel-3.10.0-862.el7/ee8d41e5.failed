pci/msi: Retrieve affinity for a vector

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Thomas Gleixner <tglx@linutronix.de>
commit ee8d41e53efe14bfc5ea5866e1178b06d78a7c95
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/ee8d41e5.failed

Add a helper to get the affinity mask for a given PCI irq vector.  For MSI or
MSI-X vectors these are stored by the IRQ core, while for legacy interrupts
we will always return cpu_possible_map.

[hch: updated to follow the style of pci_irq_vector()]

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Cc: axboe@fb.com
	Cc: keith.busch@intel.com
	Cc: agordeev@redhat.com
	Cc: linux-block@vger.kernel.org
Link: http://lkml.kernel.org/r/1473862739-15032-6-git-send-email-hch@lst.de
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

(cherry picked from commit ee8d41e53efe14bfc5ea5866e1178b06d78a7c95)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/pci/msi.c
#	include/linux/pci.h
diff --cc drivers/pci/msi.c
index 3127b0433131,9da5ecb41f0b..000000000000
--- a/drivers/pci/msi.c
+++ b/drivers/pci/msi.c
@@@ -1142,25 -1172,401 +1142,421 @@@ EXPORT_SYMBOL(pci_enable_msi_range)
   * with new allocated MSI-X interrupts.
   **/
  int pci_enable_msix_range(struct pci_dev *dev, struct msix_entry *entries,
 -		int minvec, int maxvec)
 +			       int minvec, int maxvec)
  {
 -	return __pci_enable_msix_range(dev, entries, minvec, maxvec, 0);
 +	int nvec = maxvec;
 +	int rc;
 +
 +	if (maxvec < minvec)
 +		return -ERANGE;
 +
 +	do {
 +		rc = pci_enable_msix(dev, entries, nvec);
 +		if (rc < 0) {
 +			return rc;
 +		} else if (rc > 0) {
 +			if (rc < minvec)
 +				return -ENOSPC;
 +			nvec = rc;
 +		}
 +	} while (rc);
 +
 +	return nvec;
  }
  EXPORT_SYMBOL(pci_enable_msix_range);
++<<<<<<< HEAD
++=======
+ 
+ /**
+  * pci_alloc_irq_vectors - allocate multiple IRQs for a device
+  * @dev:		PCI device to operate on
+  * @min_vecs:		minimum number of vectors required (must be >= 1)
+  * @max_vecs:		maximum (desired) number of vectors
+  * @flags:		flags or quirks for the allocation
+  *
+  * Allocate up to @max_vecs interrupt vectors for @dev, using MSI-X or MSI
+  * vectors if available, and fall back to a single legacy vector
+  * if neither is available.  Return the number of vectors allocated,
+  * (which might be smaller than @max_vecs) if successful, or a negative
+  * error code on error. If less than @min_vecs interrupt vectors are
+  * available for @dev the function will fail with -ENOSPC.
+  *
+  * To get the Linux IRQ number used for a vector that can be passed to
+  * request_irq() use the pci_irq_vector() helper.
+  */
+ int pci_alloc_irq_vectors(struct pci_dev *dev, unsigned int min_vecs,
+ 		unsigned int max_vecs, unsigned int flags)
+ {
+ 	int vecs = -ENOSPC;
+ 
+ 	if (flags & PCI_IRQ_MSIX) {
+ 		vecs = __pci_enable_msix_range(dev, NULL, min_vecs, max_vecs,
+ 				flags);
+ 		if (vecs > 0)
+ 			return vecs;
+ 	}
+ 
+ 	if (flags & PCI_IRQ_MSI) {
+ 		vecs = __pci_enable_msi_range(dev, min_vecs, max_vecs, flags);
+ 		if (vecs > 0)
+ 			return vecs;
+ 	}
+ 
+ 	/* use legacy irq if allowed */
+ 	if ((flags & PCI_IRQ_LEGACY) && min_vecs == 1) {
+ 		pci_intx(dev, 1);
+ 		return 1;
+ 	}
+ 
+ 	return vecs;
+ }
+ EXPORT_SYMBOL(pci_alloc_irq_vectors);
+ 
+ /**
+  * pci_free_irq_vectors - free previously allocated IRQs for a device
+  * @dev:		PCI device to operate on
+  *
+  * Undoes the allocations and enabling in pci_alloc_irq_vectors().
+  */
+ void pci_free_irq_vectors(struct pci_dev *dev)
+ {
+ 	pci_disable_msix(dev);
+ 	pci_disable_msi(dev);
+ }
+ EXPORT_SYMBOL(pci_free_irq_vectors);
+ 
+ /**
+  * pci_irq_vector - return Linux IRQ number of a device vector
+  * @dev: PCI device to operate on
+  * @nr: device-relative interrupt vector index (0-based).
+  */
+ int pci_irq_vector(struct pci_dev *dev, unsigned int nr)
+ {
+ 	if (dev->msix_enabled) {
+ 		struct msi_desc *entry;
+ 		int i = 0;
+ 
+ 		for_each_pci_msi_entry(entry, dev) {
+ 			if (i == nr)
+ 				return entry->irq;
+ 			i++;
+ 		}
+ 		WARN_ON_ONCE(1);
+ 		return -EINVAL;
+ 	}
+ 
+ 	if (dev->msi_enabled) {
+ 		struct msi_desc *entry = first_pci_msi_entry(dev);
+ 
+ 		if (WARN_ON_ONCE(nr >= entry->nvec_used))
+ 			return -EINVAL;
+ 	} else {
+ 		if (WARN_ON_ONCE(nr > 0))
+ 			return -EINVAL;
+ 	}
+ 
+ 	return dev->irq + nr;
+ }
+ EXPORT_SYMBOL(pci_irq_vector);
+ 
+ /**
+  * pci_irq_get_affinity - return the affinity of a particular msi vector
+  * @dev:	PCI device to operate on
+  * @nr:		device-relative interrupt vector index (0-based).
+  */
+ const struct cpumask *pci_irq_get_affinity(struct pci_dev *dev, int nr)
+ {
+ 	if (dev->msix_enabled) {
+ 		struct msi_desc *entry;
+ 		int i = 0;
+ 
+ 		for_each_pci_msi_entry(entry, dev) {
+ 			if (i == nr)
+ 				return entry->affinity;
+ 			i++;
+ 		}
+ 		WARN_ON_ONCE(1);
+ 		return NULL;
+ 	} else if (dev->msi_enabled) {
+ 		struct msi_desc *entry = first_pci_msi_entry(dev);
+ 
+ 		if (WARN_ON_ONCE(!entry || nr >= entry->nvec_used))
+ 			return NULL;
+ 
+ 		return &entry->affinity[nr];
+ 	} else {
+ 		return cpu_possible_mask;
+ 	}
+ }
+ EXPORT_SYMBOL(pci_irq_get_affinity);
+ 
+ struct pci_dev *msi_desc_to_pci_dev(struct msi_desc *desc)
+ {
+ 	return to_pci_dev(desc->dev);
+ }
+ EXPORT_SYMBOL(msi_desc_to_pci_dev);
+ 
+ void *msi_desc_to_pci_sysdata(struct msi_desc *desc)
+ {
+ 	struct pci_dev *dev = msi_desc_to_pci_dev(desc);
+ 
+ 	return dev->bus->sysdata;
+ }
+ EXPORT_SYMBOL_GPL(msi_desc_to_pci_sysdata);
+ 
+ #ifdef CONFIG_PCI_MSI_IRQ_DOMAIN
+ /**
+  * pci_msi_domain_write_msg - Helper to write MSI message to PCI config space
+  * @irq_data:	Pointer to interrupt data of the MSI interrupt
+  * @msg:	Pointer to the message
+  */
+ void pci_msi_domain_write_msg(struct irq_data *irq_data, struct msi_msg *msg)
+ {
+ 	struct msi_desc *desc = irq_data_get_msi_desc(irq_data);
+ 
+ 	/*
+ 	 * For MSI-X desc->irq is always equal to irq_data->irq. For
+ 	 * MSI only the first interrupt of MULTI MSI passes the test.
+ 	 */
+ 	if (desc->irq == irq_data->irq)
+ 		__pci_write_msi_msg(desc, msg);
+ }
+ 
+ /**
+  * pci_msi_domain_calc_hwirq - Generate a unique ID for an MSI source
+  * @dev:	Pointer to the PCI device
+  * @desc:	Pointer to the msi descriptor
+  *
+  * The ID number is only used within the irqdomain.
+  */
+ irq_hw_number_t pci_msi_domain_calc_hwirq(struct pci_dev *dev,
+ 					  struct msi_desc *desc)
+ {
+ 	return (irq_hw_number_t)desc->msi_attrib.entry_nr |
+ 		PCI_DEVID(dev->bus->number, dev->devfn) << 11 |
+ 		(pci_domain_nr(dev->bus) & 0xFFFFFFFF) << 27;
+ }
+ 
+ static inline bool pci_msi_desc_is_multi_msi(struct msi_desc *desc)
+ {
+ 	return !desc->msi_attrib.is_msix && desc->nvec_used > 1;
+ }
+ 
+ /**
+  * pci_msi_domain_check_cap - Verify that @domain supports the capabilities for @dev
+  * @domain:	The interrupt domain to check
+  * @info:	The domain info for verification
+  * @dev:	The device to check
+  *
+  * Returns:
+  *  0 if the functionality is supported
+  *  1 if Multi MSI is requested, but the domain does not support it
+  *  -ENOTSUPP otherwise
+  */
+ int pci_msi_domain_check_cap(struct irq_domain *domain,
+ 			     struct msi_domain_info *info, struct device *dev)
+ {
+ 	struct msi_desc *desc = first_pci_msi_entry(to_pci_dev(dev));
+ 
+ 	/* Special handling to support pci_enable_msi_range() */
+ 	if (pci_msi_desc_is_multi_msi(desc) &&
+ 	    !(info->flags & MSI_FLAG_MULTI_PCI_MSI))
+ 		return 1;
+ 	else if (desc->msi_attrib.is_msix && !(info->flags & MSI_FLAG_PCI_MSIX))
+ 		return -ENOTSUPP;
+ 
+ 	return 0;
+ }
+ 
+ static int pci_msi_domain_handle_error(struct irq_domain *domain,
+ 				       struct msi_desc *desc, int error)
+ {
+ 	/* Special handling to support pci_enable_msi_range() */
+ 	if (pci_msi_desc_is_multi_msi(desc) && error == -ENOSPC)
+ 		return 1;
+ 
+ 	return error;
+ }
+ 
+ #ifdef GENERIC_MSI_DOMAIN_OPS
+ static void pci_msi_domain_set_desc(msi_alloc_info_t *arg,
+ 				    struct msi_desc *desc)
+ {
+ 	arg->desc = desc;
+ 	arg->hwirq = pci_msi_domain_calc_hwirq(msi_desc_to_pci_dev(desc),
+ 					       desc);
+ }
+ #else
+ #define pci_msi_domain_set_desc		NULL
+ #endif
+ 
+ static struct msi_domain_ops pci_msi_domain_ops_default = {
+ 	.set_desc	= pci_msi_domain_set_desc,
+ 	.msi_check	= pci_msi_domain_check_cap,
+ 	.handle_error	= pci_msi_domain_handle_error,
+ };
+ 
+ static void pci_msi_domain_update_dom_ops(struct msi_domain_info *info)
+ {
+ 	struct msi_domain_ops *ops = info->ops;
+ 
+ 	if (ops == NULL) {
+ 		info->ops = &pci_msi_domain_ops_default;
+ 	} else {
+ 		if (ops->set_desc == NULL)
+ 			ops->set_desc = pci_msi_domain_set_desc;
+ 		if (ops->msi_check == NULL)
+ 			ops->msi_check = pci_msi_domain_check_cap;
+ 		if (ops->handle_error == NULL)
+ 			ops->handle_error = pci_msi_domain_handle_error;
+ 	}
+ }
+ 
+ static void pci_msi_domain_update_chip_ops(struct msi_domain_info *info)
+ {
+ 	struct irq_chip *chip = info->chip;
+ 
+ 	BUG_ON(!chip);
+ 	if (!chip->irq_write_msi_msg)
+ 		chip->irq_write_msi_msg = pci_msi_domain_write_msg;
+ 	if (!chip->irq_mask)
+ 		chip->irq_mask = pci_msi_mask_irq;
+ 	if (!chip->irq_unmask)
+ 		chip->irq_unmask = pci_msi_unmask_irq;
+ }
+ 
+ /**
+  * pci_msi_create_irq_domain - Create a MSI interrupt domain
+  * @fwnode:	Optional fwnode of the interrupt controller
+  * @info:	MSI domain info
+  * @parent:	Parent irq domain
+  *
+  * Updates the domain and chip ops and creates a MSI interrupt domain.
+  *
+  * Returns:
+  * A domain pointer or NULL in case of failure.
+  */
+ struct irq_domain *pci_msi_create_irq_domain(struct fwnode_handle *fwnode,
+ 					     struct msi_domain_info *info,
+ 					     struct irq_domain *parent)
+ {
+ 	struct irq_domain *domain;
+ 
+ 	if (info->flags & MSI_FLAG_USE_DEF_DOM_OPS)
+ 		pci_msi_domain_update_dom_ops(info);
+ 	if (info->flags & MSI_FLAG_USE_DEF_CHIP_OPS)
+ 		pci_msi_domain_update_chip_ops(info);
+ 
+ 	info->flags |= MSI_FLAG_ACTIVATE_EARLY;
+ 
+ 	domain = msi_create_irq_domain(fwnode, info, parent);
+ 	if (!domain)
+ 		return NULL;
+ 
+ 	domain->bus_token = DOMAIN_BUS_PCI_MSI;
+ 	return domain;
+ }
+ EXPORT_SYMBOL_GPL(pci_msi_create_irq_domain);
+ 
+ /**
+  * pci_msi_domain_alloc_irqs - Allocate interrupts for @dev in @domain
+  * @domain:	The interrupt domain to allocate from
+  * @dev:	The device for which to allocate
+  * @nvec:	The number of interrupts to allocate
+  * @type:	Unused to allow simpler migration from the arch_XXX interfaces
+  *
+  * Returns:
+  * A virtual interrupt number or an error code in case of failure
+  */
+ int pci_msi_domain_alloc_irqs(struct irq_domain *domain, struct pci_dev *dev,
+ 			      int nvec, int type)
+ {
+ 	return msi_domain_alloc_irqs(domain, &dev->dev, nvec);
+ }
+ 
+ /**
+  * pci_msi_domain_free_irqs - Free interrupts for @dev in @domain
+  * @domain:	The interrupt domain
+  * @dev:	The device for which to free interrupts
+  */
+ void pci_msi_domain_free_irqs(struct irq_domain *domain, struct pci_dev *dev)
+ {
+ 	msi_domain_free_irqs(domain, &dev->dev);
+ }
+ 
+ /**
+  * pci_msi_create_default_irq_domain - Create a default MSI interrupt domain
+  * @fwnode:	Optional fwnode of the interrupt controller
+  * @info:	MSI domain info
+  * @parent:	Parent irq domain
+  *
+  * Returns: A domain pointer or NULL in case of failure. If successful
+  * the default PCI/MSI irqdomain pointer is updated.
+  */
+ struct irq_domain *pci_msi_create_default_irq_domain(struct fwnode_handle *fwnode,
+ 		struct msi_domain_info *info, struct irq_domain *parent)
+ {
+ 	struct irq_domain *domain;
+ 
+ 	mutex_lock(&pci_msi_domain_lock);
+ 	if (pci_msi_default_domain) {
+ 		pr_err("PCI: default irq domain for PCI MSI has already been created.\n");
+ 		domain = NULL;
+ 	} else {
+ 		domain = pci_msi_create_irq_domain(fwnode, info, parent);
+ 		pci_msi_default_domain = domain;
+ 	}
+ 	mutex_unlock(&pci_msi_domain_lock);
+ 
+ 	return domain;
+ }
+ 
+ static int get_msi_id_cb(struct pci_dev *pdev, u16 alias, void *data)
+ {
+ 	u32 *pa = data;
+ 
+ 	*pa = alias;
+ 	return 0;
+ }
+ /**
+  * pci_msi_domain_get_msi_rid - Get the MSI requester id (RID)
+  * @domain:	The interrupt domain
+  * @pdev:	The PCI device.
+  *
+  * The RID for a device is formed from the alias, with a firmware
+  * supplied mapping applied
+  *
+  * Returns: The RID.
+  */
+ u32 pci_msi_domain_get_msi_rid(struct irq_domain *domain, struct pci_dev *pdev)
+ {
+ 	struct device_node *of_node;
+ 	u32 rid = 0;
+ 
+ 	pci_for_each_dma_alias(pdev, get_msi_id_cb, &rid);
+ 
+ 	of_node = irq_domain_get_of_node(domain);
+ 	if (of_node)
+ 		rid = of_msi_map_rid(&pdev->dev, of_node, rid);
+ 
+ 	return rid;
+ }
+ 
+ /**
+  * pci_msi_get_device_domain - Get the MSI domain for a given PCI device
+  * @pdev:	The PCI device
+  *
+  * Use the firmware data to find a device-specific MSI domain
+  * (i.e. not one that is ste as a default).
+  *
+  * Returns: The coresponding MSI domain or NULL if none has been found.
+  */
+ struct irq_domain *pci_msi_get_device_domain(struct pci_dev *pdev)
+ {
+ 	u32 rid = 0;
+ 
+ 	pci_for_each_dma_alias(pdev, get_msi_id_cb, &rid);
+ 	return of_msi_map_get_device_domain(&pdev->dev, rid);
+ }
+ #endif /* CONFIG_PCI_MSI_IRQ_DOMAIN */
++>>>>>>> ee8d41e53efe (pci/msi: Retrieve affinity for a vector)
diff --cc include/linux/pci.h
index 20e2942c01d7,3b0a8004f313..000000000000
--- a/include/linux/pci.h
+++ b/include/linux/pci.h
@@@ -1303,10 -1296,14 +1303,19 @@@ static inline int pci_enable_msix_exact
  		return rc;
  	return 0;
  }
++<<<<<<< HEAD
++=======
+ int pci_alloc_irq_vectors(struct pci_dev *dev, unsigned int min_vecs,
+ 		unsigned int max_vecs, unsigned int flags);
+ void pci_free_irq_vectors(struct pci_dev *dev);
+ int pci_irq_vector(struct pci_dev *dev, unsigned int nr);
+ const struct cpumask *pci_irq_get_affinity(struct pci_dev *pdev, int vec);
+ 
++>>>>>>> ee8d41e53efe (pci/msi: Retrieve affinity for a vector)
  #else
  static inline int pci_msi_vec_count(struct pci_dev *dev) { return -ENOSYS; }
 +static inline int pci_enable_msi_block(struct pci_dev *dev, int nvec)
 +{ return -ENOSYS; }
  static inline void pci_msi_shutdown(struct pci_dev *dev) { }
  static inline void pci_disable_msi(struct pci_dev *dev) { }
  static inline int pci_msix_vec_count(struct pci_dev *dev) { return -ENOSYS; }
@@@ -1328,6 -1325,29 +1337,32 @@@ static inline int pci_enable_msix_range
  static inline int pci_enable_msix_exact(struct pci_dev *dev,
  		      struct msix_entry *entries, int nvec)
  { return -ENOSYS; }
++<<<<<<< HEAD
++=======
+ static inline int pci_alloc_irq_vectors(struct pci_dev *dev,
+ 		unsigned int min_vecs, unsigned int max_vecs,
+ 		unsigned int flags)
+ {
+ 	if (min_vecs > 1)
+ 		return -EINVAL;
+ 	return 1;
+ }
+ static inline void pci_free_irq_vectors(struct pci_dev *dev)
+ {
+ }
+ 
+ static inline int pci_irq_vector(struct pci_dev *dev, unsigned int nr)
+ {
+ 	if (WARN_ON_ONCE(nr > 0))
+ 		return -EINVAL;
+ 	return dev->irq;
+ }
+ static inline const struct cpumask *pci_irq_get_affinity(struct pci_dev *pdev,
+ 		int vec)
+ {
+ 	return cpu_possible_mask;
+ }
++>>>>>>> ee8d41e53efe (pci/msi: Retrieve affinity for a vector)
  #endif
  
  #ifdef CONFIG_PCIEPORTBUS
* Unmerged path drivers/pci/msi.c
* Unmerged path include/linux/pci.h
