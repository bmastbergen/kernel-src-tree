vmbus: introduce in-place packet iterator

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author stephen hemminger <stephen@networkplumber.org>
commit f3dd3f4797652c311df9c074436d420f1ad3566e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/f3dd3f47.failed

This is mostly just a refactoring of previous functions
(get_pkt_next_raw, put_pkt_raw and commit_rd_index) to make it easier
to use for other drivers and NAPI.

	Signed-off-by: Stephen Hemminger <sthemmin@microsoft.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit f3dd3f4797652c311df9c074436d420f1ad3566e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/hv/ring_buffer.c
#	drivers/net/hyperv/netvsc.c
#	include/linux/hyperv.h
diff --cc drivers/hv/ring_buffer.c
index 71b35206ab89,c3f1a9e33cef..000000000000
--- a/drivers/hv/ring_buffer.c
+++ b/drivers/hv/ring_buffer.c
@@@ -32,25 -32,7 +32,29 @@@
  
  #include "hyperv_vmbus.h"
  
++<<<<<<< HEAD
 +void hv_begin_read(struct hv_ring_buffer_info *rbi)
 +{
 +	rbi->ring_buffer->interrupt_mask = 1;
 +	mb();
 +}
 +
 +u32 hv_end_read(struct hv_ring_buffer_info *rbi)
 +{
 +
 +	rbi->ring_buffer->interrupt_mask = 0;
 +	mb();
 +
 +	/*
 +	 * Now check to see if the ring buffer is still empty.
 +	 * If it is not, we raced and we need to process new
 +	 * incoming messages.
 +	 */
 +	return hv_get_bytes_to_read(rbi);
 +}
++=======
+ #define VMBUS_PKT_TRAILER	8
++>>>>>>> f3dd3f479765 (vmbus: introduce in-place packet iterator)
  
  /*
   * When we write to the ring buffer, check if the host needs to
@@@ -384,10 -371,11 +394,11 @@@ int hv_ringbuffer_read(struct vmbus_cha
  		 * No error is set when there is even no header, drivers are
  		 * supposed to analyze buffer_actual_len.
  		 */
 -		return ret;
 +		return 0;
  	}
  
- 	init_cached_read_index(channel);
+ 	init_cached_read_index(inring_info);
+ 
  	next_read_location = hv_get_next_read_location(inring_info);
  	next_read_location = hv_copyfrom_ringbuffer(inring_info, &desc,
  						    sizeof(desc),
@@@ -429,5 -417,88 +440,88 @@@
  
  	hv_signal_on_read(channel);
  
 -	return ret;
 +	return 0;
  }
+ 
+ /*
+  * Determine number of bytes available in ring buffer after
+  * the current iterator (priv_read_index) location.
+  *
+  * This is similar to hv_get_bytes_to_read but with private
+  * read index instead.
+  */
+ static u32 hv_pkt_iter_avail(const struct hv_ring_buffer_info *rbi)
+ {
+ 	u32 priv_read_loc = rbi->priv_read_index;
+ 	u32 write_loc = READ_ONCE(rbi->ring_buffer->write_index);
+ 
+ 	if (write_loc >= priv_read_loc)
+ 		return write_loc - priv_read_loc;
+ 	else
+ 		return (rbi->ring_datasize - priv_read_loc) + write_loc;
+ }
+ 
+ /*
+  * Get first vmbus packet from ring buffer after read_index
+  *
+  * If ring buffer is empty, returns NULL and no other action needed.
+  */
+ struct vmpacket_descriptor *hv_pkt_iter_first(struct vmbus_channel *channel)
+ {
+ 	struct hv_ring_buffer_info *rbi = &channel->inbound;
+ 
+ 	/* set state for later hv_signal_on_read() */
+ 	init_cached_read_index(rbi);
+ 
+ 	if (hv_pkt_iter_avail(rbi) < sizeof(struct vmpacket_descriptor))
+ 		return NULL;
+ 
+ 	return hv_get_ring_buffer(rbi) + rbi->priv_read_index;
+ }
+ EXPORT_SYMBOL_GPL(hv_pkt_iter_first);
+ 
+ /*
+  * Get next vmbus packet from ring buffer.
+  *
+  * Advances the current location (priv_read_index) and checks for more
+  * data. If the end of the ring buffer is reached, then return NULL.
+  */
+ struct vmpacket_descriptor *
+ __hv_pkt_iter_next(struct vmbus_channel *channel,
+ 		   const struct vmpacket_descriptor *desc)
+ {
+ 	struct hv_ring_buffer_info *rbi = &channel->inbound;
+ 	u32 packetlen = desc->len8 << 3;
+ 	u32 dsize = rbi->ring_datasize;
+ 
+ 	/* bump offset to next potential packet */
+ 	rbi->priv_read_index += packetlen + VMBUS_PKT_TRAILER;
+ 	if (rbi->priv_read_index >= dsize)
+ 		rbi->priv_read_index -= dsize;
+ 
+ 	/* more data? */
+ 	if (hv_pkt_iter_avail(rbi) < sizeof(struct vmpacket_descriptor))
+ 		return NULL;
+ 	else
+ 		return hv_get_ring_buffer(rbi) + rbi->priv_read_index;
+ }
+ EXPORT_SYMBOL_GPL(__hv_pkt_iter_next);
+ 
+ /*
+  * Update host ring buffer after iterating over packets.
+  */
+ void hv_pkt_iter_close(struct vmbus_channel *channel)
+ {
+ 	struct hv_ring_buffer_info *rbi = &channel->inbound;
+ 
+ 	/*
+ 	 * Make sure all reads are done before we update the read index since
+ 	 * the writer may start writing to the read area once the read index
+ 	 * is updated.
+ 	 */
+ 	virt_rmb();
+ 	rbi->ring_buffer->read_index = rbi->priv_read_index;
+ 
+ 	hv_signal_on_read(channel);
+ }
+ EXPORT_SYMBOL_GPL(hv_pkt_iter_close);
diff --cc drivers/net/hyperv/netvsc.c
index 2adfe0ec4fe2,3681fb59bdbe..000000000000
--- a/drivers/net/hyperv/netvsc.c
+++ b/drivers/net/hyperv/netvsc.c
@@@ -1246,88 -1216,29 +1241,96 @@@ void netvsc_channel_cb(void *context
  	u16 q_idx = channel->offermsg.offer.sub_channel_index;
  	struct hv_device *device;
  	struct netvsc_device *net_device;
 +	u32 bytes_recvd;
 +	u64 request_id;
  	struct vmpacket_descriptor *desc;
 +	unsigned char *buffer;
 +	int bufferlen = NETVSC_PACKET_SIZE;
  	struct net_device *ndev;
- 	bool need_to_commit = false;
  
  	if (channel->primary_channel != NULL)
  		device = channel->primary_channel->device_obj;
  	else
  		device = channel->device_obj;
  
 -	ndev = hv_get_drvdata(device);
 -	if (unlikely(!ndev))
 +	net_device = get_inbound_net_device(device);
 +	if (!net_device)
  		return;
 +	ndev = hv_get_drvdata(device);
 +	buffer = get_per_channel_state(channel);
 +
++<<<<<<< HEAD
 +	/* commit_rd_index() -> hv_signal_on_read() needs this. */
 +	init_cached_read_index(channel);
 +
 +	do {
 +		desc = get_next_pkt_raw(channel);
 +		if (desc != NULL) {
 +			netvsc_process_raw_pkt(device,
 +					       channel,
 +					       net_device,
 +					       ndev,
 +					       desc->trans_id,
 +					       desc);
 +
 +			put_pkt_raw(channel, desc);
 +			need_to_commit = true;
 +			continue;
 +		}
 +		if (need_to_commit) {
 +			need_to_commit = false;
 +			commit_rd_index(channel);
 +		}
  
 -	net_device = net_device_to_netvsc_device(ndev);
 -	if (unlikely(net_device->destroy) &&
 -	    netvsc_channel_idle(net_device, q_idx))
 -		return;
 +		ret = vmbus_recvpacket_raw(channel, buffer, bufferlen,
 +					   &bytes_recvd, &request_id);
 +		if (ret == 0) {
 +			if (bytes_recvd > 0) {
 +				desc = (struct vmpacket_descriptor *)buffer;
 +				netvsc_process_raw_pkt(device,
 +						       channel,
 +						       net_device,
 +						       ndev,
 +						       request_id,
 +						       desc);
 +			} else {
 +				/*
 +				 * We are done for this pass.
 +				 */
 +				break;
 +			}
 +
 +		} else if (ret == -ENOBUFS) {
 +			if (bufferlen > NETVSC_PACKET_SIZE)
 +				kfree(buffer);
 +			/* Handle large packet */
 +			buffer = kmalloc(bytes_recvd, GFP_ATOMIC);
 +			if (buffer == NULL) {
 +				/* Try again next time around */
 +				netdev_err(ndev,
 +					   "unable to allocate buffer of size "
 +					   "(%d)!!\n", bytes_recvd);
 +				break;
 +			}
 +
 +			bufferlen = bytes_recvd;
 +		}
 +
 +		init_cached_read_index(channel);
  
 +	} while (1);
 +
 +	if (bufferlen > NETVSC_PACKET_SIZE)
 +		kfree(buffer);
 +
++=======
+ 	foreach_vmbus_pkt(desc, channel) {
+ 		netvsc_process_raw_pkt(device, channel, net_device,
+ 				       ndev, desc->trans_id, desc);
+ 
+ 	}
+ 
++>>>>>>> f3dd3f479765 (vmbus: introduce in-place packet iterator)
  	netvsc_chk_recv_comp(net_device, channel, q_idx);
  }
  
diff --cc include/linux/hyperv.h
index 5c0043b7dddc,36162485d663..000000000000
--- a/include/linux/hyperv.h
+++ b/include/linux/hyperv.h
@@@ -1541,89 -1500,85 +1541,103 @@@ static inline  void hv_signal_on_read(s
  	cached_write_sz = hv_get_cached_bytes_to_write(rbi);
  	if (cached_write_sz < pending_sz)
  		vmbus_setevent(channel);
 -
 -	return;
 -}
 -
 -/*
 - * Mask off host interrupt callback notifications
 - */
 -static inline void hv_begin_read(struct hv_ring_buffer_info *rbi)
 -{
 -	rbi->ring_buffer->interrupt_mask = 1;
 -
 -	/* make sure mask update is not reordered */
 -	virt_mb();
 -}
 -
 -/*
 - * Re-enable host callback and return number of outstanding bytes
 - */
 -static inline u32 hv_end_read(struct hv_ring_buffer_info *rbi)
 -{
 -
 -	rbi->ring_buffer->interrupt_mask = 0;
 -
 -	/* make sure mask update is not reordered */
 -	virt_mb();
 -
 -	/*
 -	 * Now check to see if the ring buffer is still empty.
 -	 * If it is not, we raced and we need to process new
 -	 * incoming messages.
 -	 */
 -	return hv_get_bytes_to_read(rbi);
  }
  
- static inline void
- init_cached_read_index(struct vmbus_channel *channel)
+ /*
+  * An API to support in-place processing of incoming VMBUS packets.
+  */
+ 
+ /* Get data payload associated with descriptor */
+ static inline void *hv_pkt_data(const struct vmpacket_descriptor *desc)
  {
- 	struct hv_ring_buffer_info *rbi = &channel->inbound;
+ 	return (void *)((unsigned long)desc + (desc->offset8 << 3));
+ }
  
- 	rbi->cached_read_index = rbi->ring_buffer->read_index;
+ /* Get data size associated with descriptor */
+ static inline u32 hv_pkt_datalen(const struct vmpacket_descriptor *desc)
+ {
+ 	return (desc->len8 << 3) - (desc->offset8 << 3);
  }
  
+ 
+ struct vmpacket_descriptor *
+ hv_pkt_iter_first(struct vmbus_channel *channel);
+ 
+ struct vmpacket_descriptor *
+ __hv_pkt_iter_next(struct vmbus_channel *channel,
+ 		   const struct vmpacket_descriptor *pkt);
+ 
+ void hv_pkt_iter_close(struct vmbus_channel *channel);
+ 
  /*
-  * An API to support in-place processing of incoming VMBUS packets.
+  * Get next packet descriptor from iterator
+  * If at end of list, return NULL and update host.
   */
- #define VMBUS_PKT_TRAILER	8
- 
  static inline struct vmpacket_descriptor *
- get_next_pkt_raw(struct vmbus_channel *channel)
+ hv_pkt_iter_next(struct vmbus_channel *channel,
+ 		 const struct vmpacket_descriptor *pkt)
  {
- 	struct hv_ring_buffer_info *ring_info = &channel->inbound;
- 	u32 priv_read_loc = ring_info->priv_read_index;
- 	void *ring_buffer = hv_get_ring_buffer(ring_info);
- 	u32 dsize = ring_info->ring_datasize;
- 	/*
- 	 * delta is the difference between what is available to read and
- 	 * what was already consumed in place. We commit read index after
- 	 * the whole batch is processed.
- 	 */
- 	u32 delta = priv_read_loc >= ring_info->ring_buffer->read_index ?
- 		priv_read_loc - ring_info->ring_buffer->read_index :
- 		(dsize - ring_info->ring_buffer->read_index) + priv_read_loc;
- 	u32 bytes_avail_toread = (hv_get_bytes_to_read(ring_info) - delta);
+ 	struct vmpacket_descriptor *nxt;
  
- 	if (bytes_avail_toread < sizeof(struct vmpacket_descriptor))
- 		return NULL;
+ 	nxt = __hv_pkt_iter_next(channel, pkt);
+ 	if (!nxt)
+ 		hv_pkt_iter_close(channel);
  
++<<<<<<< HEAD
 +	return ring_buffer + priv_read_loc;
 +}
 +
 +/*
 + * A helper function to step through packets "in-place"
 + * This API is to be called after each successful call
 + * get_next_pkt_raw().
 + */
 +static inline void put_pkt_raw(struct vmbus_channel *channel,
 +				struct vmpacket_descriptor *desc)
 +{
 +	struct hv_ring_buffer_info *ring_info = &channel->inbound;
 +	u32 packetlen = desc->len8 << 3;
 +	u32 dsize = ring_info->ring_datasize;
 +
 +	/*
 +	 * Include the packet trailer.
 +	 */
 +	ring_info->priv_read_index += packetlen + VMBUS_PKT_TRAILER;
 +	ring_info->priv_read_index %= dsize;
 +}
 +
 +/*
 + * This call commits the read index and potentially signals the host.
 + * Here is the pattern for using the "in-place" consumption APIs:
 + *
 + * init_cached_read_index();
 + *
 + * while (get_next_pkt_raw() {
 + *	process the packet "in-place";
 + *	put_pkt_raw();
 + * }
 + * if (packets processed in place)
 + *	commit_rd_index();
 + */
 +static inline void commit_rd_index(struct vmbus_channel *channel)
 +{
 +	struct hv_ring_buffer_info *ring_info = &channel->inbound;
 +	/*
 +	 * Make sure all reads are done before we update the read index since
 +	 * the writer may start writing to the read area once the read index
 +	 * is updated.
 +	 */
 +	rmb();
 +	ring_info->ring_buffer->read_index = ring_info->priv_read_index;
 +
 +	hv_signal_on_read(channel);
++=======
+ 	return nxt;
++>>>>>>> f3dd3f479765 (vmbus: introduce in-place packet iterator)
  }
  
+ #define foreach_vmbus_pkt(pkt, channel) \
+ 	for (pkt = hv_pkt_iter_first(channel); pkt; \
+ 	    pkt = hv_pkt_iter_next(channel, pkt))
  
  #endif /* _HYPERV_H */
* Unmerged path drivers/hv/ring_buffer.c
* Unmerged path drivers/net/hyperv/netvsc.c
* Unmerged path include/linux/hyperv.h
