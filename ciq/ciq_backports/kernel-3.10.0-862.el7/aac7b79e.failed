x86/mm/pat: Set write-protect cache mode for full PAT support

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [x86] mm/pat: Set write-protect cache mode for full PAT support (Suravee Suthikulpanit) [1361287]
Rebuild_FUZZ: 96.61%
commit-author Tom Lendacky <thomas.lendacky@amd.com>
commit aac7b79eea6118dee3da9b99dcd564471672806d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/aac7b79e.failed

For processors that support PAT, set the write-protect cache mode
(_PAGE_CACHE_MODE_WP) entry to the actual write-protect value (x05).

	Signed-off-by: Tom Lendacky <thomas.lendacky@amd.com>
	Reviewed-by: Thomas Gleixner <tglx@linutronix.de>
	Acked-by: Borislav Petkov <bp@suse.de>
	Cc: Alexander Potapenko <glider@google.com>
	Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Arnd Bergmann <arnd@arndb.de>
	Cc: Borislav Petkov <bp@alien8.de>
	Cc: Brijesh Singh <brijesh.singh@amd.com>
	Cc: Dave Young <dyoung@redhat.com>
	Cc: Dmitry Vyukov <dvyukov@google.com>
	Cc: Jonathan Corbet <corbet@lwn.net>
	Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
	Cc: Larry Woodman <lwoodman@redhat.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Matt Fleming <matt@codeblueprint.co.uk>
	Cc: Michael S. Tsirkin <mst@redhat.com>
	Cc: Paolo Bonzini <pbonzini@redhat.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Radim Krčmář <rkrcmar@redhat.com>
	Cc: Rik van Riel <riel@redhat.com>
	Cc: Toshimitsu Kani <toshi.kani@hpe.com>
	Cc: kasan-dev@googlegroups.com
	Cc: kvm@vger.kernel.org
	Cc: linux-arch@vger.kernel.org
	Cc: linux-doc@vger.kernel.org
	Cc: linux-efi@vger.kernel.org
	Cc: linux-mm@kvack.org
Link: http://lkml.kernel.org/r/ade53b63d4dbffbfc3cb08fb62024647059c8688.1500319216.git.thomas.lendacky@amd.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit aac7b79eea6118dee3da9b99dcd564471672806d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/mm/pat.c
diff --cc arch/x86/mm/pat.c
index 59c76de65d5c,88990ab87961..000000000000
--- a/arch/x86/mm/pat.c
+++ b/arch/x86/mm/pat.c
@@@ -73,60 -158,217 +73,210 @@@ enum 
  	PAT_WT = 4,		/* Write Through */
  	PAT_WP = 5,		/* Write Protected */
  	PAT_WB = 6,		/* Write Back (default) */
 -	PAT_UC_MINUS = 7,	/* UC, but can be overridden by MTRR */
 +	PAT_UC_MINUS = 7,	/* UC, but can be overriden by MTRR */
  };
  
 -#define CM(c) (_PAGE_CACHE_MODE_ ## c)
 -
 -static enum page_cache_mode pat_get_cache_mode(unsigned pat_val, char *msg)
 -{
 -	enum page_cache_mode cache;
 -	char *cache_mode;
 -
 -	switch (pat_val) {
 -	case PAT_UC:       cache = CM(UC);       cache_mode = "UC  "; break;
 -	case PAT_WC:       cache = CM(WC);       cache_mode = "WC  "; break;
 -	case PAT_WT:       cache = CM(WT);       cache_mode = "WT  "; break;
 -	case PAT_WP:       cache = CM(WP);       cache_mode = "WP  "; break;
 -	case PAT_WB:       cache = CM(WB);       cache_mode = "WB  "; break;
 -	case PAT_UC_MINUS: cache = CM(UC_MINUS); cache_mode = "UC- "; break;
 -	default:           cache = CM(WB);       cache_mode = "WB  "; break;
 -	}
 -
 -	memcpy(msg, cache_mode, 4);
 -
 -	return cache;
 -}
 -
 -#undef CM
 -
 -/*
 - * Update the cache mode to pgprot translation tables according to PAT
 - * configuration.
 - * Using lower indices is preferred, so we start with highest index.
 - */
 -static void __init_cache_modes(u64 pat)
 -{
 -	enum page_cache_mode cache;
 -	char pat_msg[33];
 -	int i;
 -
 -	pat_msg[32] = 0;
 -	for (i = 7; i >= 0; i--) {
 -		cache = pat_get_cache_mode((pat >> (i * 8)) & 7,
 -					   pat_msg + 4 * i);
 -		update_cache_mode_entry(i, cache);
 -	}
 -	pr_info("x86/PAT: Configuration [0-7]: %s\n", pat_msg);
 -
 -	init_cm_done = true;
 -}
 -
  #define PAT(x, y)	((u64)PAT_ ## y << ((x)*8))
  
++<<<<<<< HEAD
++=======
+ static void pat_bsp_init(u64 pat)
+ {
+ 	u64 tmp_pat;
+ 
+ 	if (!boot_cpu_has(X86_FEATURE_PAT)) {
+ 		pat_disable("PAT not supported by CPU.");
+ 		return;
+ 	}
+ 
+ 	rdmsrl(MSR_IA32_CR_PAT, tmp_pat);
+ 	if (!tmp_pat) {
+ 		pat_disable("PAT MSR is 0, disabled.");
+ 		return;
+ 	}
+ 
+ 	wrmsrl(MSR_IA32_CR_PAT, pat);
+ 	pat_initialized = true;
+ 
+ 	__init_cache_modes(pat);
+ }
+ 
+ static void pat_ap_init(u64 pat)
+ {
+ 	if (!boot_cpu_has(X86_FEATURE_PAT)) {
+ 		/*
+ 		 * If this happens we are on a secondary CPU, but switched to
+ 		 * PAT on the boot CPU. We have no way to undo PAT.
+ 		 */
+ 		panic("x86/PAT: PAT enabled, but not supported by secondary CPU\n");
+ 	}
+ 
+ 	wrmsrl(MSR_IA32_CR_PAT, pat);
+ }
+ 
+ void init_cache_modes(void)
+ {
+ 	u64 pat = 0;
+ 
+ 	if (init_cm_done)
+ 		return;
+ 
+ 	if (boot_cpu_has(X86_FEATURE_PAT)) {
+ 		/*
+ 		 * CPU supports PAT. Set PAT table to be consistent with
+ 		 * PAT MSR. This case supports "nopat" boot option, and
+ 		 * virtual machine environments which support PAT without
+ 		 * MTRRs. In specific, Xen has unique setup to PAT MSR.
+ 		 *
+ 		 * If PAT MSR returns 0, it is considered invalid and emulates
+ 		 * as No PAT.
+ 		 */
+ 		rdmsrl(MSR_IA32_CR_PAT, pat);
+ 	}
+ 
+ 	if (!pat) {
+ 		/*
+ 		 * No PAT. Emulate the PAT table that corresponds to the two
+ 		 * cache bits, PWT (Write Through) and PCD (Cache Disable).
+ 		 * This setup is also the same as the BIOS default setup.
+ 		 *
+ 		 * PTE encoding:
+ 		 *
+ 		 *       PCD
+ 		 *       |PWT  PAT
+ 		 *       ||    slot
+ 		 *       00    0    WB : _PAGE_CACHE_MODE_WB
+ 		 *       01    1    WT : _PAGE_CACHE_MODE_WT
+ 		 *       10    2    UC-: _PAGE_CACHE_MODE_UC_MINUS
+ 		 *       11    3    UC : _PAGE_CACHE_MODE_UC
+ 		 *
+ 		 * NOTE: When WC or WP is used, it is redirected to UC- per
+ 		 * the default setup in __cachemode2pte_tbl[].
+ 		 */
+ 		pat = PAT(0, WB) | PAT(1, WT) | PAT(2, UC_MINUS) | PAT(3, UC) |
+ 		      PAT(4, WB) | PAT(5, WT) | PAT(6, UC_MINUS) | PAT(7, UC);
+ 	}
+ 
+ 	__init_cache_modes(pat);
+ }
+ 
+ /**
+  * pat_init - Initialize PAT MSR and PAT table
+  *
+  * This function initializes PAT MSR and PAT table with an OS-defined value
+  * to enable additional cache attributes, WC, WT and WP.
+  *
+  * This function must be called on all CPUs using the specific sequence of
+  * operations defined in Intel SDM. mtrr_rendezvous_handler() provides this
+  * procedure for PAT.
+  */
++>>>>>>> aac7b79eea61 (x86/mm/pat: Set write-protect cache mode for full PAT support)
  void pat_init(void)
  {
  	u64 pat;
 -	struct cpuinfo_x86 *c = &boot_cpu_data;
 +	bool boot_cpu = !boot_pat_state;
  
 -	if (pat_disabled)
 +	if (!pat_enabled)
  		return;
  
++<<<<<<< HEAD
 +	if (!cpu_has_pat) {
 +		if (!boot_pat_state) {
 +			pat_disable("PAT not supported by CPU.");
 +			return;
 +		} else {
 +			/*
 +			 * If this happens we are on a secondary CPU, but
 +			 * switched to PAT on the boot CPU. We have no way to
 +			 * undo PAT.
 +			 */
 +			printk(KERN_ERR "PAT enabled, "
 +			       "but not supported by secondary CPU\n");
 +			BUG();
 +		}
++=======
+ 	if ((c->x86_vendor == X86_VENDOR_INTEL) &&
+ 	    (((c->x86 == 0x6) && (c->x86_model <= 0xd)) ||
+ 	     ((c->x86 == 0xf) && (c->x86_model <= 0x6)))) {
+ 		/*
+ 		 * PAT support with the lower four entries. Intel Pentium 2,
+ 		 * 3, M, and 4 are affected by PAT errata, which makes the
+ 		 * upper four entries unusable. To be on the safe side, we don't
+ 		 * use those.
+ 		 *
+ 		 *  PTE encoding:
+ 		 *      PAT
+ 		 *      |PCD
+ 		 *      ||PWT  PAT
+ 		 *      |||    slot
+ 		 *      000    0    WB : _PAGE_CACHE_MODE_WB
+ 		 *      001    1    WC : _PAGE_CACHE_MODE_WC
+ 		 *      010    2    UC-: _PAGE_CACHE_MODE_UC_MINUS
+ 		 *      011    3    UC : _PAGE_CACHE_MODE_UC
+ 		 * PAT bit unused
+ 		 *
+ 		 * NOTE: When WT or WP is used, it is redirected to UC- per
+ 		 * the default setup in __cachemode2pte_tbl[].
+ 		 */
+ 		pat = PAT(0, WB) | PAT(1, WC) | PAT(2, UC_MINUS) | PAT(3, UC) |
+ 		      PAT(4, WB) | PAT(5, WC) | PAT(6, UC_MINUS) | PAT(7, UC);
+ 	} else {
+ 		/*
+ 		 * Full PAT support.  We put WT in slot 7 to improve
+ 		 * robustness in the presence of errata that might cause
+ 		 * the high PAT bit to be ignored.  This way, a buggy slot 7
+ 		 * access will hit slot 3, and slot 3 is UC, so at worst
+ 		 * we lose performance without causing a correctness issue.
+ 		 * Pentium 4 erratum N46 is an example for such an erratum,
+ 		 * although we try not to use PAT at all on affected CPUs.
+ 		 *
+ 		 *  PTE encoding:
+ 		 *      PAT
+ 		 *      |PCD
+ 		 *      ||PWT  PAT
+ 		 *      |||    slot
+ 		 *      000    0    WB : _PAGE_CACHE_MODE_WB
+ 		 *      001    1    WC : _PAGE_CACHE_MODE_WC
+ 		 *      010    2    UC-: _PAGE_CACHE_MODE_UC_MINUS
+ 		 *      011    3    UC : _PAGE_CACHE_MODE_UC
+ 		 *      100    4    WB : Reserved
+ 		 *      101    5    WP : _PAGE_CACHE_MODE_WP
+ 		 *      110    6    UC-: Reserved
+ 		 *      111    7    WT : _PAGE_CACHE_MODE_WT
+ 		 *
+ 		 * The reserved slots are unused, but mapped to their
+ 		 * corresponding types in the presence of PAT errata.
+ 		 */
+ 		pat = PAT(0, WB) | PAT(1, WC) | PAT(2, UC_MINUS) | PAT(3, UC) |
+ 		      PAT(4, WB) | PAT(5, WP) | PAT(6, UC_MINUS) | PAT(7, WT);
++>>>>>>> aac7b79eea61 (x86/mm/pat: Set write-protect cache mode for full PAT support)
  	}
  
 -	if (!boot_cpu_done) {
 -		pat_bsp_init(pat);
 -		boot_cpu_done = true;
 -	} else {
 -		pat_ap_init(pat);
 -	}
 +	/* Set PWT to Write-Combining. All other bits stay the same */
 +	/*
 +	 * PTE encoding used in Linux:
 +	 *      PAT
 +	 *      |PCD
 +	 *      ||PWT
 +	 *      |||
 +	 *      000 WB		_PAGE_CACHE_WB
 +	 *      001 WC		_PAGE_CACHE_WC
 +	 *      010 UC-		_PAGE_CACHE_UC_MINUS
 +	 *      011 UC		_PAGE_CACHE_UC
 +	 * PAT bit unused
 +	 */
 +	pat = PAT(0, WB) | PAT(1, WC) | PAT(2, UC_MINUS) | PAT(3, UC) |
 +	      PAT(4, WB) | PAT(5, WC) | PAT(6, UC_MINUS) | PAT(7, UC);
 +
 +	/* Boot CPU check */
 +	if (!boot_pat_state)
 +		rdmsrl(MSR_IA32_CR_PAT, boot_pat_state);
 +
 +	wrmsrl(MSR_IA32_CR_PAT, pat);
 +
 +	if (boot_cpu)
 +		printk(KERN_INFO "x86 PAT enabled: cpu %d, old 0x%Lx, new 0x%Lx\n",
 +		       smp_processor_id(), boot_pat_state, pat);
  }
  
  #undef PAT
* Unmerged path arch/x86/mm/pat.c
