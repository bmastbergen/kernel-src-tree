nvme: make nvme_error_status private

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [nvme] make nvme_error_status private (David Milburn) [1457880 1456486 1454365]
Rebuild_FUZZ: 90.91%
commit-author Christoph Hellwig <hch@lst.de>
commit 65ba6b54e7c1fe7751388f5da6ad87c2d1bee3ae
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/65ba6b54.failed

Currently it's used by the lighnvm passthrough ioctl, but we'd like to make
it private in preparation of block layer specific error code.  Lighnvm already
returns the real NVMe status anyway, so I think we can just limit it to
returning -EIO for any status set.

This will need a careful audit from the lightnvm folks, though.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 65ba6b54e7c1fe7751388f5da6ad87c2d1bee3ae)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/core.c
#	drivers/nvme/host/lightnvm.c
#	drivers/nvme/host/nvme.h
diff --cc drivers/nvme/host/core.c
index bd223cb63595,805f250315ec..000000000000
--- a/drivers/nvme/host/core.c
+++ b/drivers/nvme/host/core.c
@@@ -61,6 -66,43 +61,46 @@@ static DEFINE_SPINLOCK(dev_list_lock)
  
  static struct class *nvme_class;
  
++<<<<<<< HEAD
++=======
+ static int nvme_error_status(struct request *req)
+ {
+ 	switch (nvme_req(req)->status & 0x7ff) {
+ 	case NVME_SC_SUCCESS:
+ 		return 0;
+ 	case NVME_SC_CAP_EXCEEDED:
+ 		return -ENOSPC;
+ 	default:
+ 		return -EIO;
+ 	}
+ }
+ 
+ static inline bool nvme_req_needs_retry(struct request *req)
+ {
+ 	if (blk_noretry_request(req))
+ 		return false;
+ 	if (nvme_req(req)->status & NVME_SC_DNR)
+ 		return false;
+ 	if (jiffies - req->start_time >= req->timeout)
+ 		return false;
+ 	if (nvme_req(req)->retries >= nvme_max_retries)
+ 		return false;
+ 	return true;
+ }
+ 
+ void nvme_complete_rq(struct request *req)
+ {
+ 	if (unlikely(nvme_req(req)->status && nvme_req_needs_retry(req))) {
+ 		nvme_req(req)->retries++;
+ 		blk_mq_requeue_request(req, !blk_mq_queue_stopped(req->q));
+ 		return;
+ 	}
+ 
+ 	blk_mq_end_request(req, nvme_error_status(req));
+ }
+ EXPORT_SYMBOL_GPL(nvme_complete_rq);
+ 
++>>>>>>> 65ba6b54e7c1 (nvme: make nvme_error_status private)
  void nvme_cancel_request(struct request *req, void *data, bool reserved)
  {
  	int status;
diff --cc drivers/nvme/host/nvme.h
index edb3488b21b7,550037f5efea..000000000000
--- a/drivers/nvme/host/nvme.h
+++ b/drivers/nvme/host/nvme.h
@@@ -219,39 -236,25 +219,43 @@@ static inline u64 nvme_block_nr(struct 
  	return (sector >> (ns->lba_shift - 9));
  }
  
 +static inline unsigned nvme_map_len(struct request *rq)
 +{
 +	if (rq->cmd_flags & REQ_DISCARD)
 +		return sizeof(struct nvme_dsm_range);
 +	else
 +		return blk_rq_bytes(rq);
 +}
 +
  static inline void nvme_cleanup_cmd(struct request *req)
  {
 -	if (req->rq_flags & RQF_SPECIAL_PAYLOAD) {
 -		kfree(page_address(req->special_vec.bv_page) +
 -		      req->special_vec.bv_offset);
 -	}
 +	if (req->cmd_flags & REQ_DISCARD)
 +		kfree(req->completion_data);
  }
  
 -static inline void nvme_end_request(struct request *req, __le16 status,
 -		union nvme_result result)
 +static inline int nvme_error_status(u16 status)
  {
 -	struct nvme_request *rq = nvme_req(req);
 +	switch (status & 0x7ff) {
 +	case NVME_SC_SUCCESS:
 +		return 0;
 +	case NVME_SC_CAP_EXCEEDED:
 +		return -ENOSPC;
 +	default:
 +		return -EIO;
 +	}
 +}
  
 -	rq->status = le16_to_cpu(status) >> 1;
 -	rq->result = result;
 -	blk_mq_complete_request(req, 0);
 +static inline bool nvme_req_needs_retry(struct request *req, u16 status)
 +{
 +	return !(status & NVME_SC_DNR || blk_noretry_request(req)) &&
 +		(jiffies - req->start_time) < req->timeout &&
 +		req->retries < nvme_max_retries;
  }
  
++<<<<<<< HEAD
++=======
+ void nvme_complete_rq(struct request *req);
++>>>>>>> 65ba6b54e7c1 (nvme: make nvme_error_status private)
  void nvme_cancel_request(struct request *req, void *data, bool reserved);
  bool nvme_change_ctrl_state(struct nvme_ctrl *ctrl,
  		enum nvme_ctrl_state new_state);
* Unmerged path drivers/nvme/host/lightnvm.c
* Unmerged path drivers/nvme/host/core.c
* Unmerged path drivers/nvme/host/lightnvm.c
* Unmerged path drivers/nvme/host/nvme.h
