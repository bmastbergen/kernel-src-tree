blk-mq: add tag allocation policy

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Shaohua Li <shli@fb.com>
commit 24391c0dc57c3756a219defaa781e68637d6ab7d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/24391c0d.failed

This is the blk-mq part to support tag allocation policy. The default
allocation policy isn't changed (though it's not a strict FIFO). The new
policy is round-robin for libata. But it's a try-best implementation. If
multiple tasks are competing, the tags returned will be mixed (which is
unavoidable even with !mq, as requests from different tasks can be
mixed in queue)

	Cc: Jens Axboe <axboe@fb.com>
	Cc: Tejun Heo <tj@kernel.org>
	Cc: Christoph Hellwig <hch@infradead.org>
	Signed-off-by: Shaohua Li <shli@fb.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 24391c0dc57c3756a219defaa781e68637d6ab7d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq-tag.h
#	drivers/scsi/scsi_lib.c
#	include/linux/blk-mq.h
diff --cc block/blk-mq-tag.h
index 5cdeb865c8ff,90767b370308..000000000000
--- a/block/blk-mq-tag.h
+++ b/block/blk-mq-tag.h
@@@ -43,7 -43,7 +43,11 @@@ struct blk_mq_tags 
  	struct request **rqs;
  	struct list_head page_list;
  
++<<<<<<< HEAD
 +	cpumask_var_t cpumask;
++=======
+ 	int alloc_policy;
++>>>>>>> 24391c0dc57c (blk-mq: add tag allocation policy)
  };
  
  
diff --cc drivers/scsi/scsi_lib.c
index 09ae8ec23494,49ab11508286..000000000000
--- a/drivers/scsi/scsi_lib.c
+++ b/drivers/scsi/scsi_lib.c
@@@ -2034,19 -2181,18 +2034,32 @@@ int scsi_mq_setup_tags(struct Scsi_Hos
  	if (scsi_host_get_prot(shost))
  		cmd_size += sizeof(struct scsi_data_buffer) + sgl_size;
  
++<<<<<<< HEAD
 +	shost->tag_set = kzalloc(sizeof(*shost->tag_set), GFP_KERNEL);
 +	if (!shost->tag_set)
 +		return -ENOMEM;
++=======
+ 	memset(&shost->tag_set, 0, sizeof(shost->tag_set));
+ 	shost->tag_set.ops = &scsi_mq_ops;
+ 	shost->tag_set.nr_hw_queues = shost->nr_hw_queues ? : 1;
+ 	shost->tag_set.queue_depth = shost->can_queue;
+ 	shost->tag_set.cmd_size = cmd_size;
+ 	shost->tag_set.numa_node = NUMA_NO_NODE;
+ 	shost->tag_set.flags = BLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_SG_MERGE;
+ 	shost->tag_set.flags |=
+ 		BLK_ALLOC_POLICY_TO_MQ_FLAG(shost->hostt->tag_alloc_policy);
+ 	shost->tag_set.driver_data = shost;
++>>>>>>> 24391c0dc57c (blk-mq: add tag allocation policy)
  
 -	return blk_mq_alloc_tag_set(&shost->tag_set);
 +	shost->tag_set->ops = &scsi_mq_ops;
 +	shost->tag_set->nr_hw_queues = shost->nr_hw_queues ? : 1;
 +	shost->tag_set->queue_depth = shost->can_queue;
 +	shost->tag_set->cmd_size = cmd_size;
 +	shost->tag_set->numa_node = NUMA_NO_NODE;
 +	shost->tag_set->flags = BLK_MQ_F_SHOULD_MERGE | BLK_MQ_F_SG_MERGE;
 +	shost->tag_set->driver_data = shost;
 +
 +	return blk_mq_alloc_tag_set(shost->tag_set);
  }
  
  void scsi_mq_destroy_tags(struct Scsi_Host *shost)
diff --cc include/linux/blk-mq.h
index 7a19eb11b858,86b08b1a5eba..000000000000
--- a/include/linux/blk-mq.h
+++ b/include/linux/blk-mq.h
@@@ -200,11 -143,12 +200,20 @@@ enum 
  	BLK_MQ_RQ_QUEUE_ERROR	= 2,	/* end IO with error */
  
  	BLK_MQ_F_SHOULD_MERGE	= 1 << 0,
++<<<<<<< HEAD
 +	BLK_MQ_F_SHOULD_SORT	= 1 << 1,
 +	BLK_MQ_F_TAG_SHARED	= 1 << 2,
 +	BLK_MQ_F_SG_MERGE	= 1 << 3,
 +	BLK_MQ_F_DEFER_ISSUE	= 1 << 5,
 +	BLK_MQ_F_BLOCKING	= 1 << 6,
++=======
+ 	BLK_MQ_F_TAG_SHARED	= 1 << 1,
+ 	BLK_MQ_F_SG_MERGE	= 1 << 2,
+ 	BLK_MQ_F_SYSFS_UP	= 1 << 3,
+ 	BLK_MQ_F_DEFER_ISSUE	= 1 << 4,
+ 	BLK_MQ_F_ALLOC_POLICY_START_BIT = 8,
+ 	BLK_MQ_F_ALLOC_POLICY_BITS = 1,
++>>>>>>> 24391c0dc57c (blk-mq: add tag allocation policy)
  
  	BLK_MQ_S_STOPPED	= 0,
  	BLK_MQ_S_TAG_ACTIVE	= 1,
@@@ -213,10 -157,15 +222,16 @@@
  
  	BLK_MQ_CPU_WORK_BATCH	= 8,
  };
+ #define BLK_MQ_FLAG_TO_ALLOC_POLICY(flags) \
+ 	((flags >> BLK_MQ_F_ALLOC_POLICY_START_BIT) & \
+ 		((1 << BLK_MQ_F_ALLOC_POLICY_BITS) - 1))
+ #define BLK_ALLOC_POLICY_TO_MQ_FLAG(policy) \
+ 	((policy & ((1 << BLK_MQ_F_ALLOC_POLICY_BITS) - 1)) \
+ 		<< BLK_MQ_F_ALLOC_POLICY_START_BIT)
  
  struct request_queue *blk_mq_init_queue(struct blk_mq_tag_set *);
 -void blk_mq_finish_init(struct request_queue *q);
 +struct request_queue *blk_mq_init_allocated_queue(struct blk_mq_tag_set *set,
 +						  struct request_queue *q);
  int blk_mq_register_disk(struct gendisk *);
  void blk_mq_unregister_disk(struct gendisk *);
  
diff --git a/block/blk-mq-tag.c b/block/blk-mq-tag.c
index 7e6885bccaac..68f1b5abe26c 100644
--- a/block/blk-mq-tag.c
+++ b/block/blk-mq-tag.c
@@ -144,7 +144,8 @@ static inline bool hctx_may_queue(struct blk_mq_hw_ctx *hctx,
 	return atomic_read(&hctx->nr_active) < depth;
 }
 
-static int __bt_get_word(struct blk_align_bitmap *bm, unsigned int last_tag)
+static int __bt_get_word(struct blk_align_bitmap *bm, unsigned int last_tag,
+			 bool nowrap)
 {
 	int tag, org_last_tag = last_tag;
 
@@ -156,7 +157,7 @@ static int __bt_get_word(struct blk_align_bitmap *bm, unsigned int last_tag)
 			 * offset to 0 in a failure case, so start from 0 to
 			 * exhaust the map.
 			 */
-			if (org_last_tag && last_tag) {
+			if (org_last_tag && last_tag && !nowrap) {
 				last_tag = org_last_tag = 0;
 				continue;
 			}
@@ -174,6 +175,8 @@ static int __bt_get_word(struct blk_align_bitmap *bm, unsigned int last_tag)
 	return tag;
 }
 
+#define BT_ALLOC_RR(tags) (tags->alloc_policy == BLK_TAG_ALLOC_RR)
+
 /*
  * Straight forward bitmap tag implementation, where each bit is a tag
  * (cleared == free, and set == busy). The small twist is using per-cpu
@@ -186,7 +189,7 @@ static int __bt_get_word(struct blk_align_bitmap *bm, unsigned int last_tag)
  * until the map is exhausted.
  */
 static int __bt_get(struct blk_mq_hw_ctx *hctx, struct blk_mq_bitmap_tags *bt,
-		    unsigned int *tag_cache)
+		    unsigned int *tag_cache, struct blk_mq_tags *tags)
 {
 	unsigned int last_tag, org_last_tag;
 	int index, i, tag;
@@ -198,7 +201,8 @@ static int __bt_get(struct blk_mq_hw_ctx *hctx, struct blk_mq_bitmap_tags *bt,
 	index = TAG_TO_INDEX(bt, last_tag);
 
 	for (i = 0; i < bt->map_nr; i++) {
-		tag = __bt_get_word(&bt->map[index], TAG_TO_BIT(bt, last_tag));
+		tag = __bt_get_word(&bt->map[index], TAG_TO_BIT(bt, last_tag),
+				    BT_ALLOC_RR(tags));
 		if (tag != -1) {
 			tag += (index << bt->bits_per_word);
 			goto done;
@@ -225,7 +229,7 @@ static int __bt_get(struct blk_mq_hw_ctx *hctx, struct blk_mq_bitmap_tags *bt,
 	 * up using the specific cached tag.
 	 */
 done:
-	if (tag == org_last_tag) {
+	if (tag == org_last_tag || unlikely(BT_ALLOC_RR(tags))) {
 		last_tag = tag + 1;
 		if (last_tag >= bt->depth - 1)
 			last_tag = 0;
@@ -254,13 +258,13 @@ static struct bt_wait_state *bt_wait_ptr(struct blk_mq_bitmap_tags *bt,
 static int bt_get(struct blk_mq_alloc_data *data,
 		struct blk_mq_bitmap_tags *bt,
 		struct blk_mq_hw_ctx *hctx,
-		unsigned int *last_tag)
+		unsigned int *last_tag, struct blk_mq_tags *tags)
 {
 	struct bt_wait_state *bs;
 	DEFINE_WAIT(wait);
 	int tag;
 
-	tag = __bt_get(hctx, bt, last_tag);
+	tag = __bt_get(hctx, bt, last_tag, tags);
 	if (tag != -1)
 		return tag;
 
@@ -271,7 +275,7 @@ static int bt_get(struct blk_mq_alloc_data *data,
 	do {
 		prepare_to_wait(&bs->wait, &wait, TASK_UNINTERRUPTIBLE);
 
-		tag = __bt_get(hctx, bt, last_tag);
+		tag = __bt_get(hctx, bt, last_tag, tags);
 		if (tag != -1)
 			break;
 
@@ -288,7 +292,7 @@ static int bt_get(struct blk_mq_alloc_data *data,
 		 * Retry tag allocation after running the hardware queue,
 		 * as running the queue may also have found completions.
 		 */
-		tag = __bt_get(hctx, bt, last_tag);
+		tag = __bt_get(hctx, bt, last_tag, tags);
 		if (tag != -1)
 			break;
 
@@ -319,7 +323,7 @@ static unsigned int __blk_mq_get_tag(struct blk_mq_alloc_data *data)
 	int tag;
 
 	tag = bt_get(data, &data->hctx->tags->bitmap_tags, data->hctx,
-			&data->ctx->last_tag);
+			&data->ctx->last_tag, data->hctx->tags);
 	if (tag >= 0)
 		return tag + data->hctx->tags->nr_reserved_tags;
 
@@ -335,7 +339,8 @@ static unsigned int __blk_mq_get_reserved_tag(struct blk_mq_alloc_data *data)
 		return BLK_MQ_TAG_FAIL;
 	}
 
-	tag = bt_get(data, &data->hctx->tags->breserved_tags, NULL, &zero);
+	tag = bt_get(data, &data->hctx->tags->breserved_tags, NULL, &zero,
+		data->hctx->tags);
 	if (tag < 0)
 		return BLK_MQ_TAG_FAIL;
 
@@ -406,7 +411,8 @@ void blk_mq_put_tag(struct blk_mq_hw_ctx *hctx, unsigned int tag,
 
 		BUG_ON(real_tag >= tags->nr_tags);
 		bt_clear_tag(&tags->bitmap_tags, real_tag);
-		*last_tag = real_tag;
+		if (likely(tags->alloc_policy == BLK_TAG_ALLOC_FIFO))
+			*last_tag = real_tag;
 	} else {
 		BUG_ON(tag >= tags->nr_reserved_tags);
 		bt_clear_tag(&tags->breserved_tags, tag);
@@ -630,10 +636,12 @@ static void bt_free(struct blk_mq_bitmap_tags *bt)
 }
 
 static struct blk_mq_tags *blk_mq_init_bitmap_tags(struct blk_mq_tags *tags,
-						   int node)
+						   int node, int alloc_policy)
 {
 	unsigned int depth = tags->nr_tags - tags->nr_reserved_tags;
 
+	tags->alloc_policy = alloc_policy;
+
 	if (bt_alloc(&tags->bitmap_tags, depth, node, false))
 		goto enomem;
 	if (bt_alloc(&tags->breserved_tags, tags->nr_reserved_tags, node, true))
@@ -647,7 +655,8 @@ enomem:
 }
 
 struct blk_mq_tags *blk_mq_init_tags(unsigned int total_tags,
-				     unsigned int reserved_tags, int node)
+				     unsigned int reserved_tags,
+				     int node, int alloc_policy)
 {
 	struct blk_mq_tags *tags;
 
@@ -668,7 +677,7 @@ struct blk_mq_tags *blk_mq_init_tags(unsigned int total_tags,
 	tags->nr_tags = total_tags;
 	tags->nr_reserved_tags = reserved_tags;
 
-	return blk_mq_init_bitmap_tags(tags, node);
+	return blk_mq_init_bitmap_tags(tags, node, alloc_policy);
 }
 
 void blk_mq_free_tags(struct blk_mq_tags *tags)
* Unmerged path block/blk-mq-tag.h
diff --git a/block/blk-mq.c b/block/blk-mq.c
index 49418900af65..5fd9c28bfe3a 100644
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@ -1594,7 +1594,8 @@ static struct blk_mq_tags *blk_mq_init_rq_map(struct blk_mq_tag_set *set,
 	size_t rq_size, left;
 
 	tags = blk_mq_init_tags(set->queue_depth, set->reserved_tags,
-				set->numa_node);
+				set->numa_node,
+				BLK_MQ_FLAG_TO_ALLOC_POLICY(set->flags));
 	if (!tags)
 		return NULL;
 
* Unmerged path drivers/scsi/scsi_lib.c
* Unmerged path include/linux/blk-mq.h
