mlxsw: spectrum_router: Keep nexthops in a linked list

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Arkadi Sharshevsky <arkadis@mellanox.com>
commit dbe4598c1e929a24dc352a7dc523a3cc22a093f2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/dbe4598c.failed

Keep nexthops in a linked list for easy access.

	Signed-off-by: Arkadi Sharshevsky <arkadis@mellanox.com>
	Signed-off-by: Jiri Pirko <jiri@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit dbe4598c1e929a24dc352a7dc523a3cc22a093f2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c
diff --cc drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c
index 6908726c154c,0cd4b2a7d9d0..000000000000
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c
@@@ -50,6 -62,40 +50,43 @@@
  #include "spectrum.h"
  #include "core.h"
  #include "reg.h"
++<<<<<<< HEAD
++=======
+ #include "spectrum_cnt.h"
+ #include "spectrum_dpipe.h"
+ #include "spectrum_ipip.h"
+ #include "spectrum_router.h"
+ 
+ struct mlxsw_sp_vr;
+ struct mlxsw_sp_lpm_tree;
+ struct mlxsw_sp_rif_ops;
+ 
+ struct mlxsw_sp_router {
+ 	struct mlxsw_sp *mlxsw_sp;
+ 	struct mlxsw_sp_rif **rifs;
+ 	struct mlxsw_sp_vr *vrs;
+ 	struct rhashtable neigh_ht;
+ 	struct rhashtable nexthop_group_ht;
+ 	struct rhashtable nexthop_ht;
+ 	struct list_head nexthop_list;
+ 	struct {
+ 		struct mlxsw_sp_lpm_tree *trees;
+ 		unsigned int tree_count;
+ 	} lpm;
+ 	struct {
+ 		struct delayed_work dw;
+ 		unsigned long interval;	/* ms */
+ 	} neighs_update;
+ 	struct delayed_work nexthop_probe_dw;
+ #define MLXSW_SP_UNRESOLVED_NH_PROBE_INTERVAL 5000 /* ms */
+ 	struct list_head nexthop_neighs_list;
+ 	struct list_head ipip_list;
+ 	bool aborted;
+ 	struct notifier_block fib_nb;
+ 	const struct mlxsw_sp_rif_ops **rif_ops_arr;
+ 	const struct mlxsw_sp_ipip_ops **ipip_ops_arr;
+ };
++>>>>>>> dbe4598c1e92 (mlxsw: spectrum_router: Keep nexthops in a linked list)
  
  struct mlxsw_sp_rif {
  	struct list_head nexthop_list;
@@@ -978,1270 -1393,2769 +1015,1278 @@@ mlxsw_sp_router_neigh_entry_op4(struct 
  }
  
  static void
 -mlxsw_sp_neigh_entry_remove(struct mlxsw_sp *mlxsw_sp,
 -			    struct mlxsw_sp_neigh_entry *neigh_entry)
 -{
 -	rhashtable_remove_fast(&mlxsw_sp->router->neigh_ht,
 -			       &neigh_entry->ht_node,
 -			       mlxsw_sp_neigh_ht_params);
 -}
 -
 -static bool
 -mlxsw_sp_neigh_counter_should_alloc(struct mlxsw_sp *mlxsw_sp,
 -				    struct mlxsw_sp_neigh_entry *neigh_entry)
 -{
 -	struct devlink *devlink;
 -	const char *table_name;
 -
 -	switch (mlxsw_sp_neigh_entry_type(neigh_entry)) {
 -	case AF_INET:
 -		table_name = MLXSW_SP_DPIPE_TABLE_NAME_HOST4;
 -		break;
 -	case AF_INET6:
 -		table_name = MLXSW_SP_DPIPE_TABLE_NAME_HOST6;
 -		break;
 -	default:
 -		WARN_ON(1);
 -		return false;
 -	}
 -
 -	devlink = priv_to_devlink(mlxsw_sp->core);
 -	return devlink_dpipe_table_counter_enabled(devlink, table_name);
 -}
 -
 -static void
 -mlxsw_sp_neigh_counter_alloc(struct mlxsw_sp *mlxsw_sp,
 -			     struct mlxsw_sp_neigh_entry *neigh_entry)
 +mlxsw_sp_neigh_entry_update(struct mlxsw_sp *mlxsw_sp,
 +			    struct mlxsw_sp_neigh_entry *neigh_entry,
 +			    bool adding)
  {
 -	if (!mlxsw_sp_neigh_counter_should_alloc(mlxsw_sp, neigh_entry))
 -		return;
 -
 -	if (mlxsw_sp_flow_counter_alloc(mlxsw_sp, &neigh_entry->counter_index))
 +	if (!adding && !neigh_entry->connected)
  		return;
 -
 -	neigh_entry->counter_valid = true;
 +	neigh_entry->connected = adding;
 +	if (neigh_entry->key.n->tbl == &arp_tbl)
 +		mlxsw_sp_router_neigh_entry_op4(mlxsw_sp, neigh_entry,
 +						mlxsw_sp_rauht_op(adding));
 +	else
 +		WARN_ON_ONCE(1);
  }
  
 -static void
 -mlxsw_sp_neigh_counter_free(struct mlxsw_sp *mlxsw_sp,
 -			    struct mlxsw_sp_neigh_entry *neigh_entry)
 -{
 -	if (!neigh_entry->counter_valid)
 -		return;
 -	mlxsw_sp_flow_counter_free(mlxsw_sp,
 -				   neigh_entry->counter_index);
 -	neigh_entry->counter_valid = false;
 -}
 +struct mlxsw_sp_neigh_event_work {
 +	struct work_struct work;
 +	struct mlxsw_sp *mlxsw_sp;
 +	struct neighbour *n;
 +};
  
 -static struct mlxsw_sp_neigh_entry *
 -mlxsw_sp_neigh_entry_create(struct mlxsw_sp *mlxsw_sp, struct neighbour *n)
 +static void mlxsw_sp_router_neigh_event_work(struct work_struct *work)
  {
 +	struct mlxsw_sp_neigh_event_work *neigh_work =
 +		container_of(work, struct mlxsw_sp_neigh_event_work, work);
 +	struct mlxsw_sp *mlxsw_sp = neigh_work->mlxsw_sp;
  	struct mlxsw_sp_neigh_entry *neigh_entry;
 -	struct mlxsw_sp_rif *rif;
 -	int err;
 -
 -	rif = mlxsw_sp_rif_find_by_dev(mlxsw_sp, n->dev);
 -	if (!rif)
 -		return ERR_PTR(-EINVAL);
 +	struct neighbour *n = neigh_work->n;
 +	unsigned char ha[ETH_ALEN];
 +	bool entry_connected;
 +	u8 nud_state, dead;
  
 -	neigh_entry = mlxsw_sp_neigh_entry_alloc(mlxsw_sp, n, rif->rif_index);
 -	if (!neigh_entry)
 -		return ERR_PTR(-ENOMEM);
 +	/* If these parameters are changed after we release the lock,
 +	 * then we are guaranteed to receive another event letting us
 +	 * know about it.
 +	 */
 +	read_lock_bh(&n->lock);
 +	memcpy(ha, n->ha, ETH_ALEN);
 +	nud_state = n->nud_state;
 +	dead = n->dead;
 +	read_unlock_bh(&n->lock);
  
 -	err = mlxsw_sp_neigh_entry_insert(mlxsw_sp, neigh_entry);
 -	if (err)
 -		goto err_neigh_entry_insert;
 +	rtnl_lock();
 +	entry_connected = nud_state & NUD_VALID && !dead;
 +	neigh_entry = mlxsw_sp_neigh_entry_lookup(mlxsw_sp, n);
 +	if (!entry_connected && !neigh_entry)
 +		goto out;
 +	if (!neigh_entry) {
 +		neigh_entry = mlxsw_sp_neigh_entry_create(mlxsw_sp, n);
 +		if (IS_ERR(neigh_entry))
 +			goto out;
 +	}
  
 -	mlxsw_sp_neigh_counter_alloc(mlxsw_sp, neigh_entry);
 -	list_add(&neigh_entry->rif_list_node, &rif->neigh_list);
 +	memcpy(neigh_entry->ha, ha, ETH_ALEN);
 +	mlxsw_sp_neigh_entry_update(mlxsw_sp, neigh_entry, entry_connected);
 +	mlxsw_sp_nexthop_neigh_update(mlxsw_sp, neigh_entry, !entry_connected);
  
 -	return neigh_entry;
 +	if (!neigh_entry->connected && list_empty(&neigh_entry->nexthop_list))
 +		mlxsw_sp_neigh_entry_destroy(mlxsw_sp, neigh_entry);
  
 -err_neigh_entry_insert:
 -	mlxsw_sp_neigh_entry_free(neigh_entry);
 -	return ERR_PTR(err);
 +out:
 +	rtnl_unlock();
 +	neigh_release(n);
 +	kfree(neigh_work);
  }
  
 -static void
 -mlxsw_sp_neigh_entry_destroy(struct mlxsw_sp *mlxsw_sp,
 -			     struct mlxsw_sp_neigh_entry *neigh_entry)
 +int mlxsw_sp_router_netevent_event(struct notifier_block *unused,
 +				   unsigned long event, void *ptr)
  {
 -	list_del(&neigh_entry->rif_list_node);
 -	mlxsw_sp_neigh_counter_free(mlxsw_sp, neigh_entry);
 -	mlxsw_sp_neigh_entry_remove(mlxsw_sp, neigh_entry);
 -	mlxsw_sp_neigh_entry_free(neigh_entry);
 -}
 +	struct mlxsw_sp_neigh_event_work *neigh_work;
 +	struct mlxsw_sp_port *mlxsw_sp_port;
 +	struct mlxsw_sp *mlxsw_sp;
 +	unsigned long interval;
 +	struct neigh_parms *p;
 +	struct neighbour *n;
  
 -static struct mlxsw_sp_neigh_entry *
 -mlxsw_sp_neigh_entry_lookup(struct mlxsw_sp *mlxsw_sp, struct neighbour *n)
 -{
 -	struct mlxsw_sp_neigh_key key;
 +	switch (event) {
 +	case NETEVENT_DELAY_PROBE_TIME_UPDATE:
 +		p = ptr;
  
 -	key.n = n;
 -	return rhashtable_lookup_fast(&mlxsw_sp->router->neigh_ht,
 -				      &key, mlxsw_sp_neigh_ht_params);
 -}
 +		/* We don't care about changes in the default table. */
 +		if (!p->dev || p->tbl != &arp_tbl)
 +			return NOTIFY_DONE;
  
 -static void
 -mlxsw_sp_router_neighs_update_interval_init(struct mlxsw_sp *mlxsw_sp)
 -{
 -	unsigned long interval;
 +		/* We are in atomic context and can't take RTNL mutex,
 +		 * so use RCU variant to walk the device chain.
 +		 */
 +		mlxsw_sp_port = mlxsw_sp_port_lower_dev_hold(p->dev);
 +		if (!mlxsw_sp_port)
 +			return NOTIFY_DONE;
  
 -#if IS_ENABLED(CONFIG_IPV6)
 -	interval = min_t(unsigned long,
 -			 NEIGH_VAR(&arp_tbl.parms, DELAY_PROBE_TIME),
 -			 NEIGH_VAR(&nd_tbl.parms, DELAY_PROBE_TIME));
 -#else
 -	interval = NEIGH_VAR(&arp_tbl.parms, DELAY_PROBE_TIME);
 -#endif
 -	mlxsw_sp->router->neighs_update.interval = jiffies_to_msecs(interval);
 -}
 +		mlxsw_sp = mlxsw_sp_port->mlxsw_sp;
 +		interval = jiffies_to_msecs(NEIGH_VAR(p, DELAY_PROBE_TIME));
 +		mlxsw_sp->router.neighs_update.interval = interval;
  
 -static void mlxsw_sp_router_neigh_ent_ipv4_process(struct mlxsw_sp *mlxsw_sp,
 -						   char *rauhtd_pl,
 -						   int ent_index)
 -{
 -	struct net_device *dev;
 -	struct neighbour *n;
 -	__be32 dipn;
 -	u32 dip;
 -	u16 rif;
 +		mlxsw_sp_port_dev_put(mlxsw_sp_port);
 +		break;
 +	case NETEVENT_NEIGH_UPDATE:
 +		n = ptr;
  
 -	mlxsw_reg_rauhtd_ent_ipv4_unpack(rauhtd_pl, ent_index, &rif, &dip);
 +		if (n->tbl != &arp_tbl)
 +			return NOTIFY_DONE;
  
 -	if (!mlxsw_sp->router->rifs[rif]) {
 -		dev_err_ratelimited(mlxsw_sp->bus_info->dev, "Incorrect RIF in neighbour entry\n");
 -		return;
 -	}
 +		mlxsw_sp_port = mlxsw_sp_port_lower_dev_hold(n->dev);
 +		if (!mlxsw_sp_port)
 +			return NOTIFY_DONE;
  
 -	dipn = htonl(dip);
 -	dev = mlxsw_sp->router->rifs[rif]->dev;
 -	n = neigh_lookup(&arp_tbl, &dipn, dev);
 -	if (!n) {
 -		netdev_err(dev, "Failed to find matching neighbour for IP=%pI4h\n",
 -			   &dip);
 -		return;
 +		neigh_work = kzalloc(sizeof(*neigh_work), GFP_ATOMIC);
 +		if (!neigh_work) {
 +			mlxsw_sp_port_dev_put(mlxsw_sp_port);
 +			return NOTIFY_BAD;
 +		}
 +
 +		INIT_WORK(&neigh_work->work, mlxsw_sp_router_neigh_event_work);
 +		neigh_work->mlxsw_sp = mlxsw_sp_port->mlxsw_sp;
 +		neigh_work->n = n;
 +
 +		/* Take a reference to ensure the neighbour won't be
 +		 * destructed until we drop the reference in delayed
 +		 * work.
 +		 */
 +		neigh_clone(n);
 +		mlxsw_core_schedule_work(&neigh_work->work);
 +		mlxsw_sp_port_dev_put(mlxsw_sp_port);
 +		break;
  	}
  
 -	netdev_dbg(dev, "Updating neighbour with IP=%pI4h\n", &dip);
 -	neigh_event_send(n, NULL);
 -	neigh_release(n);
 +	return NOTIFY_DONE;
  }
  
 -#if IS_ENABLED(CONFIG_IPV6)
 -static void mlxsw_sp_router_neigh_ent_ipv6_process(struct mlxsw_sp *mlxsw_sp,
 -						   char *rauhtd_pl,
 -						   int rec_index)
 +static int mlxsw_sp_neigh_init(struct mlxsw_sp *mlxsw_sp)
  {
 -	struct net_device *dev;
 -	struct neighbour *n;
 -	struct in6_addr dip;
 -	u16 rif;
 -
 -	mlxsw_reg_rauhtd_ent_ipv6_unpack(rauhtd_pl, rec_index, &rif,
 -					 (char *) &dip);
 +	int err;
  
 -	if (!mlxsw_sp->router->rifs[rif]) {
 -		dev_err_ratelimited(mlxsw_sp->bus_info->dev, "Incorrect RIF in neighbour entry\n");
 -		return;
 -	}
 +	err = rhashtable_init(&mlxsw_sp->router.neigh_ht,
 +			      &mlxsw_sp_neigh_ht_params);
 +	if (err)
 +		return err;
  
 -	dev = mlxsw_sp->router->rifs[rif]->dev;
 -	n = neigh_lookup(&nd_tbl, &dip, dev);
 -	if (!n) {
 -		netdev_err(dev, "Failed to find matching neighbour for IP=%pI6c\n",
 -			   &dip);
 -		return;
 -	}
 +	/* Initialize the polling interval according to the default
 +	 * table.
 +	 */
 +	mlxsw_sp_router_neighs_update_interval_init(mlxsw_sp);
  
 -	netdev_dbg(dev, "Updating neighbour with IP=%pI6c\n", &dip);
 -	neigh_event_send(n, NULL);
 -	neigh_release(n);
 +	/* Create the delayed works for the activity_update */
 +	INIT_DELAYED_WORK(&mlxsw_sp->router.neighs_update.dw,
 +			  mlxsw_sp_router_neighs_update_work);
 +	INIT_DELAYED_WORK(&mlxsw_sp->router.nexthop_probe_dw,
 +			  mlxsw_sp_router_probe_unresolved_nexthops);
 +	mlxsw_core_schedule_dw(&mlxsw_sp->router.neighs_update.dw, 0);
 +	mlxsw_core_schedule_dw(&mlxsw_sp->router.nexthop_probe_dw, 0);
 +	return 0;
  }
 -#else
 -static void mlxsw_sp_router_neigh_ent_ipv6_process(struct mlxsw_sp *mlxsw_sp,
 -						   char *rauhtd_pl,
 -						   int rec_index)
 +
 +static void mlxsw_sp_neigh_fini(struct mlxsw_sp *mlxsw_sp)
  {
 +	cancel_delayed_work_sync(&mlxsw_sp->router.neighs_update.dw);
 +	cancel_delayed_work_sync(&mlxsw_sp->router.nexthop_probe_dw);
 +	rhashtable_destroy(&mlxsw_sp->router.neigh_ht);
  }
 -#endif
  
 -static void mlxsw_sp_router_neigh_rec_ipv4_process(struct mlxsw_sp *mlxsw_sp,
 -						   char *rauhtd_pl,
 -						   int rec_index)
 +static int mlxsw_sp_neigh_rif_flush(struct mlxsw_sp *mlxsw_sp,
 +				    const struct mlxsw_sp_rif *r)
  {
 -	u8 num_entries;
 -	int i;
 -
 -	num_entries = mlxsw_reg_rauhtd_ipv4_rec_num_entries_get(rauhtd_pl,
 -								rec_index);
 -	/* Hardware starts counting at 0, so add 1. */
 -	num_entries++;
 +	char rauht_pl[MLXSW_REG_RAUHT_LEN];
  
 -	/* Each record consists of several neighbour entries. */
 -	for (i = 0; i < num_entries; i++) {
 -		int ent_index;
 +	mlxsw_reg_rauht_pack(rauht_pl, MLXSW_REG_RAUHT_OP_WRITE_DELETE_ALL,
 +			     r->rif, r->addr);
 +	return mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(rauht), rauht_pl);
 +}
  
 -		ent_index = rec_index * MLXSW_REG_RAUHTD_IPV4_ENT_PER_REC + i;
 -		mlxsw_sp_router_neigh_ent_ipv4_process(mlxsw_sp, rauhtd_pl,
 -						       ent_index);
 -	}
 +static void mlxsw_sp_neigh_rif_gone_sync(struct mlxsw_sp *mlxsw_sp,
 +					 struct mlxsw_sp_rif *r)
 +{
 +	struct mlxsw_sp_neigh_entry *neigh_entry, *tmp;
  
 +	mlxsw_sp_neigh_rif_flush(mlxsw_sp, r);
 +	list_for_each_entry_safe(neigh_entry, tmp, &r->neigh_list,
 +				 rif_list_node)
 +		mlxsw_sp_neigh_entry_destroy(mlxsw_sp, neigh_entry);
  }
  
 -static void mlxsw_sp_router_neigh_rec_ipv6_process(struct mlxsw_sp *mlxsw_sp,
 -						   char *rauhtd_pl,
 -						   int rec_index)
 -{
 -	/* One record contains one entry. */
 -	mlxsw_sp_router_neigh_ent_ipv6_process(mlxsw_sp, rauhtd_pl,
 -					       rec_index);
 -}
 -
 -static void mlxsw_sp_router_neigh_rec_process(struct mlxsw_sp *mlxsw_sp,
 -					      char *rauhtd_pl, int rec_index)
 -{
 -	switch (mlxsw_reg_rauhtd_rec_type_get(rauhtd_pl, rec_index)) {
 -	case MLXSW_REG_RAUHTD_TYPE_IPV4:
 -		mlxsw_sp_router_neigh_rec_ipv4_process(mlxsw_sp, rauhtd_pl,
 -						       rec_index);
 -		break;
 -	case MLXSW_REG_RAUHTD_TYPE_IPV6:
 -		mlxsw_sp_router_neigh_rec_ipv6_process(mlxsw_sp, rauhtd_pl,
 -						       rec_index);
 -		break;
 -	}
 -}
 -
 -static bool mlxsw_sp_router_rauhtd_is_full(char *rauhtd_pl)
 -{
 -	u8 num_rec, last_rec_index, num_entries;
 -
 -	num_rec = mlxsw_reg_rauhtd_num_rec_get(rauhtd_pl);
 -	last_rec_index = num_rec - 1;
 -
 -	if (num_rec < MLXSW_REG_RAUHTD_REC_MAX_NUM)
 -		return false;
 -	if (mlxsw_reg_rauhtd_rec_type_get(rauhtd_pl, last_rec_index) ==
 -	    MLXSW_REG_RAUHTD_TYPE_IPV6)
 -		return true;
 -
 -	num_entries = mlxsw_reg_rauhtd_ipv4_rec_num_entries_get(rauhtd_pl,
 -								last_rec_index);
 -	if (++num_entries == MLXSW_REG_RAUHTD_IPV4_ENT_PER_REC)
 -		return true;
 -	return false;
 -}
 -
 -static int
 -__mlxsw_sp_router_neighs_update_rauhtd(struct mlxsw_sp *mlxsw_sp,
 -				       char *rauhtd_pl,
 -				       enum mlxsw_reg_rauhtd_type type)
 -{
 -	int i, num_rec;
 -	int err;
 -
 -	/* Make sure the neighbour's netdev isn't removed in the
 -	 * process.
 -	 */
 -	rtnl_lock();
 -	do {
 -		mlxsw_reg_rauhtd_pack(rauhtd_pl, type);
 -		err = mlxsw_reg_query(mlxsw_sp->core, MLXSW_REG(rauhtd),
 -				      rauhtd_pl);
 -		if (err) {
 -			dev_err_ratelimited(mlxsw_sp->bus_info->dev, "Failed to dump neighbour talbe\n");
 -			break;
 -		}
 -		num_rec = mlxsw_reg_rauhtd_num_rec_get(rauhtd_pl);
 -		for (i = 0; i < num_rec; i++)
 -			mlxsw_sp_router_neigh_rec_process(mlxsw_sp, rauhtd_pl,
 -							  i);
 -	} while (mlxsw_sp_router_rauhtd_is_full(rauhtd_pl));
 -	rtnl_unlock();
 -
 -	return err;
 -}
 -
 -static int mlxsw_sp_router_neighs_update_rauhtd(struct mlxsw_sp *mlxsw_sp)
 -{
 -	enum mlxsw_reg_rauhtd_type type;
 -	char *rauhtd_pl;
 -	int err;
 -
 -	rauhtd_pl = kmalloc(MLXSW_REG_RAUHTD_LEN, GFP_KERNEL);
 -	if (!rauhtd_pl)
 -		return -ENOMEM;
 -
 -	type = MLXSW_REG_RAUHTD_TYPE_IPV4;
 -	err = __mlxsw_sp_router_neighs_update_rauhtd(mlxsw_sp, rauhtd_pl, type);
 -	if (err)
 -		goto out;
 -
 -	type = MLXSW_REG_RAUHTD_TYPE_IPV6;
 -	err = __mlxsw_sp_router_neighs_update_rauhtd(mlxsw_sp, rauhtd_pl, type);
 -out:
 -	kfree(rauhtd_pl);
 -	return err;
 -}
 -
 -static void mlxsw_sp_router_neighs_update_nh(struct mlxsw_sp *mlxsw_sp)
 -{
 -	struct mlxsw_sp_neigh_entry *neigh_entry;
 -
 -	/* Take RTNL mutex here to prevent lists from changes */
 -	rtnl_lock();
 -	list_for_each_entry(neigh_entry, &mlxsw_sp->router->nexthop_neighs_list,
 -			    nexthop_neighs_list_node)
 -		/* If this neigh have nexthops, make the kernel think this neigh
 -		 * is active regardless of the traffic.
 -		 */
 -		neigh_event_send(neigh_entry->key.n, NULL);
 -	rtnl_unlock();
 -}
 -
 -static void
 -mlxsw_sp_router_neighs_update_work_schedule(struct mlxsw_sp *mlxsw_sp)
 -{
 -	unsigned long interval = mlxsw_sp->router->neighs_update.interval;
 -
 -	mlxsw_core_schedule_dw(&mlxsw_sp->router->neighs_update.dw,
 -			       msecs_to_jiffies(interval));
 -}
 -
 -static void mlxsw_sp_router_neighs_update_work(struct work_struct *work)
 -{
 -	struct mlxsw_sp_router *router;
 -	int err;
 -
 -	router = container_of(work, struct mlxsw_sp_router,
 -			      neighs_update.dw.work);
 -	err = mlxsw_sp_router_neighs_update_rauhtd(router->mlxsw_sp);
 -	if (err)
 -		dev_err(router->mlxsw_sp->bus_info->dev, "Could not update kernel for neigh activity");
 -
 -	mlxsw_sp_router_neighs_update_nh(router->mlxsw_sp);
 -
 -	mlxsw_sp_router_neighs_update_work_schedule(router->mlxsw_sp);
 -}
 -
 -static void mlxsw_sp_router_probe_unresolved_nexthops(struct work_struct *work)
 -{
 -	struct mlxsw_sp_neigh_entry *neigh_entry;
 -	struct mlxsw_sp_router *router;
 -
 -	router = container_of(work, struct mlxsw_sp_router,
 -			      nexthop_probe_dw.work);
 -	/* Iterate over nexthop neighbours, find those who are unresolved and
 -	 * send arp on them. This solves the chicken-egg problem when
 -	 * the nexthop wouldn't get offloaded until the neighbor is resolved
 -	 * but it wouldn't get resolved ever in case traffic is flowing in HW
 -	 * using different nexthop.
 -	 *
 -	 * Take RTNL mutex here to prevent lists from changes.
 -	 */
 -	rtnl_lock();
 -	list_for_each_entry(neigh_entry, &router->nexthop_neighs_list,
 -			    nexthop_neighs_list_node)
 -		if (!neigh_entry->connected)
 -			neigh_event_send(neigh_entry->key.n, NULL);
 -	rtnl_unlock();
 -
 -	mlxsw_core_schedule_dw(&router->nexthop_probe_dw,
 -			       MLXSW_SP_UNRESOLVED_NH_PROBE_INTERVAL);
 -}
 -
 -static void
 -mlxsw_sp_nexthop_neigh_update(struct mlxsw_sp *mlxsw_sp,
 -			      struct mlxsw_sp_neigh_entry *neigh_entry,
 -			      bool removing);
 -
 -static enum mlxsw_reg_rauht_op mlxsw_sp_rauht_op(bool adding)
 -{
 -	return adding ? MLXSW_REG_RAUHT_OP_WRITE_ADD :
 -			MLXSW_REG_RAUHT_OP_WRITE_DELETE;
 -}
 -
 -static void
 -mlxsw_sp_router_neigh_entry_op4(struct mlxsw_sp *mlxsw_sp,
 -				struct mlxsw_sp_neigh_entry *neigh_entry,
 -				enum mlxsw_reg_rauht_op op)
 -{
 -	struct neighbour *n = neigh_entry->key.n;
 -	u32 dip = ntohl(*((__be32 *) n->primary_key));
 -	char rauht_pl[MLXSW_REG_RAUHT_LEN];
 -
 -	mlxsw_reg_rauht_pack4(rauht_pl, op, neigh_entry->rif, neigh_entry->ha,
 -			      dip);
 -	if (neigh_entry->counter_valid)
 -		mlxsw_reg_rauht_pack_counter(rauht_pl,
 -					     neigh_entry->counter_index);
 -	mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(rauht), rauht_pl);
 -}
 -
 -static void
 -mlxsw_sp_router_neigh_entry_op6(struct mlxsw_sp *mlxsw_sp,
 -				struct mlxsw_sp_neigh_entry *neigh_entry,
 -				enum mlxsw_reg_rauht_op op)
 -{
 -	struct neighbour *n = neigh_entry->key.n;
 -	char rauht_pl[MLXSW_REG_RAUHT_LEN];
 -	const char *dip = n->primary_key;
 -
 -	mlxsw_reg_rauht_pack6(rauht_pl, op, neigh_entry->rif, neigh_entry->ha,
 -			      dip);
 -	if (neigh_entry->counter_valid)
 -		mlxsw_reg_rauht_pack_counter(rauht_pl,
 -					     neigh_entry->counter_index);
 -	mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(rauht), rauht_pl);
 -}
 -
 -bool mlxsw_sp_neigh_ipv6_ignore(struct mlxsw_sp_neigh_entry *neigh_entry)
 -{
 -	struct neighbour *n = neigh_entry->key.n;
 -
 -	/* Packets with a link-local destination address are trapped
 -	 * after LPM lookup and never reach the neighbour table, so
 -	 * there is no need to program such neighbours to the device.
 -	 */
 -	if (ipv6_addr_type((struct in6_addr *) &n->primary_key) &
 -	    IPV6_ADDR_LINKLOCAL)
 -		return true;
 -	return false;
 -}
 -
 -static void
 -mlxsw_sp_neigh_entry_update(struct mlxsw_sp *mlxsw_sp,
 -			    struct mlxsw_sp_neigh_entry *neigh_entry,
 -			    bool adding)
 -{
 -	if (!adding && !neigh_entry->connected)
 -		return;
 -	neigh_entry->connected = adding;
 -	if (neigh_entry->key.n->tbl->family == AF_INET) {
 -		mlxsw_sp_router_neigh_entry_op4(mlxsw_sp, neigh_entry,
 -						mlxsw_sp_rauht_op(adding));
 -	} else if (neigh_entry->key.n->tbl->family == AF_INET6) {
 -		if (mlxsw_sp_neigh_ipv6_ignore(neigh_entry))
 -			return;
 -		mlxsw_sp_router_neigh_entry_op6(mlxsw_sp, neigh_entry,
 -						mlxsw_sp_rauht_op(adding));
 -	} else {
 -		WARN_ON_ONCE(1);
 -	}
 -}
 -
 -void
 -mlxsw_sp_neigh_entry_counter_update(struct mlxsw_sp *mlxsw_sp,
 -				    struct mlxsw_sp_neigh_entry *neigh_entry,
 -				    bool adding)
 -{
 -	if (adding)
 -		mlxsw_sp_neigh_counter_alloc(mlxsw_sp, neigh_entry);
 -	else
 -		mlxsw_sp_neigh_counter_free(mlxsw_sp, neigh_entry);
 -	mlxsw_sp_neigh_entry_update(mlxsw_sp, neigh_entry, true);
 -}
 -
 -struct mlxsw_sp_neigh_event_work {
 -	struct work_struct work;
 -	struct mlxsw_sp *mlxsw_sp;
 -	struct neighbour *n;
 +struct mlxsw_sp_nexthop_key {
 +	struct fib_nh *fib_nh;
  };
  
 -static void mlxsw_sp_router_neigh_event_work(struct work_struct *work)
 -{
 -	struct mlxsw_sp_neigh_event_work *neigh_work =
 -		container_of(work, struct mlxsw_sp_neigh_event_work, work);
 -	struct mlxsw_sp *mlxsw_sp = neigh_work->mlxsw_sp;
 +struct mlxsw_sp_nexthop {
 +	struct list_head neigh_list_node; /* member of neigh entry list */
 +	struct list_head rif_list_node;
++	struct list_head router_list_node;
 +	struct mlxsw_sp_nexthop_group *nh_grp; /* pointer back to the group
 +						* this belongs to
 +						*/
 +	struct rhash_head ht_node;
 +	struct mlxsw_sp_nexthop_key key;
 +	struct mlxsw_sp_rif *r;
 +	u8 should_offload:1, /* set indicates this neigh is connected and
 +			      * should be put to KVD linear area of this group.
 +			      */
 +	   offloaded:1, /* set in case the neigh is actually put into
 +			 * KVD linear area of this group.
 +			 */
 +	   update:1; /* set indicates that MAC of this neigh should be
 +		      * updated in HW
 +		      */
  	struct mlxsw_sp_neigh_entry *neigh_entry;
 -	struct neighbour *n = neigh_work->n;
 -	unsigned char ha[ETH_ALEN];
 -	bool entry_connected;
 -	u8 nud_state, dead;
 -
 -	/* If these parameters are changed after we release the lock,
 -	 * then we are guaranteed to receive another event letting us
 -	 * know about it.
 -	 */
 -	read_lock_bh(&n->lock);
 -	memcpy(ha, n->ha, ETH_ALEN);
 -	nud_state = n->nud_state;
 -	dead = n->dead;
 -	read_unlock_bh(&n->lock);
 -
 -	rtnl_lock();
 -	entry_connected = nud_state & NUD_VALID && !dead;
 -	neigh_entry = mlxsw_sp_neigh_entry_lookup(mlxsw_sp, n);
 -	if (!entry_connected && !neigh_entry)
 -		goto out;
 -	if (!neigh_entry) {
 -		neigh_entry = mlxsw_sp_neigh_entry_create(mlxsw_sp, n);
 -		if (IS_ERR(neigh_entry))
 -			goto out;
 -	}
 -
 -	memcpy(neigh_entry->ha, ha, ETH_ALEN);
 -	mlxsw_sp_neigh_entry_update(mlxsw_sp, neigh_entry, entry_connected);
 -	mlxsw_sp_nexthop_neigh_update(mlxsw_sp, neigh_entry, !entry_connected);
 -
 -	if (!neigh_entry->connected && list_empty(&neigh_entry->nexthop_list))
 -		mlxsw_sp_neigh_entry_destroy(mlxsw_sp, neigh_entry);
 -
 -out:
 -	rtnl_unlock();
 -	neigh_release(n);
 -	kfree(neigh_work);
 -}
 -
 -int mlxsw_sp_router_netevent_event(struct notifier_block *unused,
 -				   unsigned long event, void *ptr)
 -{
 -	struct mlxsw_sp_neigh_event_work *neigh_work;
 -	struct mlxsw_sp_port *mlxsw_sp_port;
 -	struct mlxsw_sp *mlxsw_sp;
 -	unsigned long interval;
 -	struct neigh_parms *p;
 -	struct neighbour *n;
 -
 -	switch (event) {
 -	case NETEVENT_DELAY_PROBE_TIME_UPDATE:
 -		p = ptr;
 -
 -		/* We don't care about changes in the default table. */
 -		if (!p->dev || (p->tbl->family != AF_INET &&
 -				p->tbl->family != AF_INET6))
 -			return NOTIFY_DONE;
 -
 -		/* We are in atomic context and can't take RTNL mutex,
 -		 * so use RCU variant to walk the device chain.
 -		 */
 -		mlxsw_sp_port = mlxsw_sp_port_lower_dev_hold(p->dev);
 -		if (!mlxsw_sp_port)
 -			return NOTIFY_DONE;
 -
 -		mlxsw_sp = mlxsw_sp_port->mlxsw_sp;
 -		interval = jiffies_to_msecs(NEIGH_VAR(p, DELAY_PROBE_TIME));
 -		mlxsw_sp->router->neighs_update.interval = interval;
 -
 -		mlxsw_sp_port_dev_put(mlxsw_sp_port);
 -		break;
 -	case NETEVENT_NEIGH_UPDATE:
 -		n = ptr;
 -
 -		if (n->tbl->family != AF_INET && n->tbl->family != AF_INET6)
 -			return NOTIFY_DONE;
 -
 -		mlxsw_sp_port = mlxsw_sp_port_lower_dev_hold(n->dev);
 -		if (!mlxsw_sp_port)
 -			return NOTIFY_DONE;
 -
 -		neigh_work = kzalloc(sizeof(*neigh_work), GFP_ATOMIC);
 -		if (!neigh_work) {
 -			mlxsw_sp_port_dev_put(mlxsw_sp_port);
 -			return NOTIFY_BAD;
 -		}
 -
 -		INIT_WORK(&neigh_work->work, mlxsw_sp_router_neigh_event_work);
 -		neigh_work->mlxsw_sp = mlxsw_sp_port->mlxsw_sp;
 -		neigh_work->n = n;
 -
 -		/* Take a reference to ensure the neighbour won't be
 -		 * destructed until we drop the reference in delayed
 -		 * work.
 -		 */
 -		neigh_clone(n);
 -		mlxsw_core_schedule_work(&neigh_work->work);
 -		mlxsw_sp_port_dev_put(mlxsw_sp_port);
 -		break;
 -	}
 -
 -	return NOTIFY_DONE;
 -}
 -
 -static int mlxsw_sp_neigh_init(struct mlxsw_sp *mlxsw_sp)
 -{
 -	int err;
 -
 -	err = rhashtable_init(&mlxsw_sp->router->neigh_ht,
 -			      &mlxsw_sp_neigh_ht_params);
 -	if (err)
 -		return err;
 -
 -	/* Initialize the polling interval according to the default
 -	 * table.
 -	 */
 -	mlxsw_sp_router_neighs_update_interval_init(mlxsw_sp);
 -
 -	/* Create the delayed works for the activity_update */
 -	INIT_DELAYED_WORK(&mlxsw_sp->router->neighs_update.dw,
 -			  mlxsw_sp_router_neighs_update_work);
 -	INIT_DELAYED_WORK(&mlxsw_sp->router->nexthop_probe_dw,
 -			  mlxsw_sp_router_probe_unresolved_nexthops);
 -	mlxsw_core_schedule_dw(&mlxsw_sp->router->neighs_update.dw, 0);
 -	mlxsw_core_schedule_dw(&mlxsw_sp->router->nexthop_probe_dw, 0);
 -	return 0;
 -}
 -
 -static void mlxsw_sp_neigh_fini(struct mlxsw_sp *mlxsw_sp)
 -{
 -	cancel_delayed_work_sync(&mlxsw_sp->router->neighs_update.dw);
 -	cancel_delayed_work_sync(&mlxsw_sp->router->nexthop_probe_dw);
 -	rhashtable_destroy(&mlxsw_sp->router->neigh_ht);
 -}
 -
 -static void mlxsw_sp_neigh_rif_gone_sync(struct mlxsw_sp *mlxsw_sp,
 -					 struct mlxsw_sp_rif *rif)
 -{
 -	struct mlxsw_sp_neigh_entry *neigh_entry, *tmp;
 -
 -	list_for_each_entry_safe(neigh_entry, tmp, &rif->neigh_list,
 -				 rif_list_node) {
 -		mlxsw_sp_neigh_entry_update(mlxsw_sp, neigh_entry, false);
 -		mlxsw_sp_neigh_entry_destroy(mlxsw_sp, neigh_entry);
 -	}
 -}
 -
 -enum mlxsw_sp_nexthop_type {
 -	MLXSW_SP_NEXTHOP_TYPE_ETH,
 -	MLXSW_SP_NEXTHOP_TYPE_IPIP,
 -};
 -
 -struct mlxsw_sp_nexthop_key {
 -	struct fib_nh *fib_nh;
 -};
 -
 -struct mlxsw_sp_nexthop {
 -	struct list_head neigh_list_node; /* member of neigh entry list */
 -	struct list_head rif_list_node;
 -	struct list_head router_list_node;
 -	struct mlxsw_sp_nexthop_group *nh_grp; /* pointer back to the group
 -						* this belongs to
 -						*/
 -	struct rhash_head ht_node;
 -	struct mlxsw_sp_nexthop_key key;
 -	unsigned char gw_addr[sizeof(struct in6_addr)];
 -	int ifindex;
 -	struct mlxsw_sp_rif *rif;
 -	u8 should_offload:1, /* set indicates this neigh is connected and
 -			      * should be put to KVD linear area of this group.
 -			      */
 -	   offloaded:1, /* set in case the neigh is actually put into
 -			 * KVD linear area of this group.
 -			 */
 -	   update:1; /* set indicates that MAC of this neigh should be
 -		      * updated in HW
 -		      */
 -	enum mlxsw_sp_nexthop_type type;
 -	union {
 -		struct mlxsw_sp_neigh_entry *neigh_entry;
 -		struct mlxsw_sp_ipip_entry *ipip_entry;
 -	};
 -};
 -
 -struct mlxsw_sp_nexthop_group {
 -	void *priv;
 -	struct rhash_head ht_node;
 -	struct list_head fib_list; /* list of fib entries that use this group */
 -	struct neigh_table *neigh_tbl;
 -	u8 adj_index_valid:1,
 -	   gateway:1; /* routes using the group use a gateway */
 -	u32 adj_index;
 -	u16 ecmp_size;
 -	u16 count;
 -	struct mlxsw_sp_nexthop nexthops[0];
 -#define nh_rif	nexthops[0].rif
 -};
 -
 -static struct fib_info *
 -mlxsw_sp_nexthop4_group_fi(const struct mlxsw_sp_nexthop_group *nh_grp)
 -{
 -	return nh_grp->priv;
 -}
 -
 -struct mlxsw_sp_nexthop_group_cmp_arg {
 -	enum mlxsw_sp_l3proto proto;
 -	union {
 -		struct fib_info *fi;
 -		struct mlxsw_sp_fib6_entry *fib6_entry;
 -	};
 -};
 -
 -static bool
 -mlxsw_sp_nexthop6_group_has_nexthop(const struct mlxsw_sp_nexthop_group *nh_grp,
 -				    const struct in6_addr *gw, int ifindex)
 -{
 -	int i;
 -
 -	for (i = 0; i < nh_grp->count; i++) {
 -		const struct mlxsw_sp_nexthop *nh;
 -
 -		nh = &nh_grp->nexthops[i];
 -		if (nh->ifindex == ifindex &&
 -		    ipv6_addr_equal(gw, (struct in6_addr *) nh->gw_addr))
 -			return true;
 -	}
 -
 -	return false;
 -}
 -
 -static bool
 -mlxsw_sp_nexthop6_group_cmp(const struct mlxsw_sp_nexthop_group *nh_grp,
 -			    const struct mlxsw_sp_fib6_entry *fib6_entry)
 -{
 -	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
 -
 -	if (nh_grp->count != fib6_entry->nrt6)
 -		return false;
 -
 -	list_for_each_entry(mlxsw_sp_rt6, &fib6_entry->rt6_list, list) {
 -		struct in6_addr *gw;
 -		int ifindex;
 -
 -		ifindex = mlxsw_sp_rt6->rt->dst.dev->ifindex;
 -		gw = &mlxsw_sp_rt6->rt->rt6i_gateway;
 -		if (!mlxsw_sp_nexthop6_group_has_nexthop(nh_grp, gw, ifindex))
 -			return false;
 -	}
 -
 -	return true;
 -}
 -
 -static int
 -mlxsw_sp_nexthop_group_cmp(struct rhashtable_compare_arg *arg, const void *ptr)
 -{
 -	const struct mlxsw_sp_nexthop_group_cmp_arg *cmp_arg = arg->key;
 -	const struct mlxsw_sp_nexthop_group *nh_grp = ptr;
 -
 -	switch (cmp_arg->proto) {
 -	case MLXSW_SP_L3_PROTO_IPV4:
 -		return cmp_arg->fi != mlxsw_sp_nexthop4_group_fi(nh_grp);
 -	case MLXSW_SP_L3_PROTO_IPV6:
 -		return !mlxsw_sp_nexthop6_group_cmp(nh_grp,
 -						    cmp_arg->fib6_entry);
 -	default:
 -		WARN_ON(1);
 -		return 1;
 -	}
 -}
 -
 -static int
 -mlxsw_sp_nexthop_group_type(const struct mlxsw_sp_nexthop_group *nh_grp)
 -{
 -	return nh_grp->neigh_tbl->family;
 -}
 -
 -static u32 mlxsw_sp_nexthop_group_hash_obj(const void *data, u32 len, u32 seed)
 -{
 -	const struct mlxsw_sp_nexthop_group *nh_grp = data;
 -	const struct mlxsw_sp_nexthop *nh;
 -	struct fib_info *fi;
 -	unsigned int val;
 -	int i;
 -
 -	switch (mlxsw_sp_nexthop_group_type(nh_grp)) {
 -	case AF_INET:
 -		fi = mlxsw_sp_nexthop4_group_fi(nh_grp);
 -		return jhash(&fi, sizeof(fi), seed);
 -	case AF_INET6:
 -		val = nh_grp->count;
 -		for (i = 0; i < nh_grp->count; i++) {
 -			nh = &nh_grp->nexthops[i];
 -			val ^= nh->ifindex;
 -		}
 -		return jhash(&val, sizeof(val), seed);
 -	default:
 -		WARN_ON(1);
 -		return 0;
 -	}
 -}
 -
 -static u32
 -mlxsw_sp_nexthop6_group_hash(struct mlxsw_sp_fib6_entry *fib6_entry, u32 seed)
 -{
 -	unsigned int val = fib6_entry->nrt6;
 -	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
 -	struct net_device *dev;
 -
 -	list_for_each_entry(mlxsw_sp_rt6, &fib6_entry->rt6_list, list) {
 -		dev = mlxsw_sp_rt6->rt->dst.dev;
 -		val ^= dev->ifindex;
 -	}
 -
 -	return jhash(&val, sizeof(val), seed);
 -}
 -
 -static u32
 -mlxsw_sp_nexthop_group_hash(const void *data, u32 len, u32 seed)
 -{
 -	const struct mlxsw_sp_nexthop_group_cmp_arg *cmp_arg = data;
 -
 -	switch (cmp_arg->proto) {
 -	case MLXSW_SP_L3_PROTO_IPV4:
 -		return jhash(&cmp_arg->fi, sizeof(cmp_arg->fi), seed);
 -	case MLXSW_SP_L3_PROTO_IPV6:
 -		return mlxsw_sp_nexthop6_group_hash(cmp_arg->fib6_entry, seed);
 -	default:
 -		WARN_ON(1);
 -		return 0;
 -	}
 -}
 -
 -static const struct rhashtable_params mlxsw_sp_nexthop_group_ht_params = {
 -	.head_offset = offsetof(struct mlxsw_sp_nexthop_group, ht_node),
 -	.hashfn	     = mlxsw_sp_nexthop_group_hash,
 -	.obj_hashfn  = mlxsw_sp_nexthop_group_hash_obj,
 -	.obj_cmpfn   = mlxsw_sp_nexthop_group_cmp,
  };
  
 -static int mlxsw_sp_nexthop_group_insert(struct mlxsw_sp *mlxsw_sp,
 -					 struct mlxsw_sp_nexthop_group *nh_grp)
 -{
 -	if (mlxsw_sp_nexthop_group_type(nh_grp) == AF_INET6 &&
 -	    !nh_grp->gateway)
 -		return 0;
 -
 -	return rhashtable_insert_fast(&mlxsw_sp->router->nexthop_group_ht,
 -				      &nh_grp->ht_node,
 -				      mlxsw_sp_nexthop_group_ht_params);
 -}
 -
 -static void mlxsw_sp_nexthop_group_remove(struct mlxsw_sp *mlxsw_sp,
 -					  struct mlxsw_sp_nexthop_group *nh_grp)
 -{
 -	if (mlxsw_sp_nexthop_group_type(nh_grp) == AF_INET6 &&
 -	    !nh_grp->gateway)
 -		return;
 -
 -	rhashtable_remove_fast(&mlxsw_sp->router->nexthop_group_ht,
 -			       &nh_grp->ht_node,
 -			       mlxsw_sp_nexthop_group_ht_params);
 -}
 -
 -static struct mlxsw_sp_nexthop_group *
 -mlxsw_sp_nexthop4_group_lookup(struct mlxsw_sp *mlxsw_sp,
 -			       struct fib_info *fi)
 -{
 -	struct mlxsw_sp_nexthop_group_cmp_arg cmp_arg;
 -
 -	cmp_arg.proto = MLXSW_SP_L3_PROTO_IPV4;
 -	cmp_arg.fi = fi;
 -	return rhashtable_lookup_fast(&mlxsw_sp->router->nexthop_group_ht,
 -				      &cmp_arg,
 -				      mlxsw_sp_nexthop_group_ht_params);
 -}
 -
 -static struct mlxsw_sp_nexthop_group *
 -mlxsw_sp_nexthop6_group_lookup(struct mlxsw_sp *mlxsw_sp,
 -			       struct mlxsw_sp_fib6_entry *fib6_entry)
 -{
 -	struct mlxsw_sp_nexthop_group_cmp_arg cmp_arg;
 -
 -	cmp_arg.proto = MLXSW_SP_L3_PROTO_IPV6;
 -	cmp_arg.fib6_entry = fib6_entry;
 -	return rhashtable_lookup_fast(&mlxsw_sp->router->nexthop_group_ht,
 -				      &cmp_arg,
 -				      mlxsw_sp_nexthop_group_ht_params);
 -}
 -
 -static const struct rhashtable_params mlxsw_sp_nexthop_ht_params = {
 -	.key_offset = offsetof(struct mlxsw_sp_nexthop, key),
 -	.head_offset = offsetof(struct mlxsw_sp_nexthop, ht_node),
 -	.key_len = sizeof(struct mlxsw_sp_nexthop_key),
 -};
 -
 -static int mlxsw_sp_nexthop_insert(struct mlxsw_sp *mlxsw_sp,
 -				   struct mlxsw_sp_nexthop *nh)
 -{
 -	return rhashtable_insert_fast(&mlxsw_sp->router->nexthop_ht,
 -				      &nh->ht_node, mlxsw_sp_nexthop_ht_params);
 -}
 -
 -static void mlxsw_sp_nexthop_remove(struct mlxsw_sp *mlxsw_sp,
 -				    struct mlxsw_sp_nexthop *nh)
 -{
 -	rhashtable_remove_fast(&mlxsw_sp->router->nexthop_ht, &nh->ht_node,
 -			       mlxsw_sp_nexthop_ht_params);
 -}
 -
 -static struct mlxsw_sp_nexthop *
 -mlxsw_sp_nexthop_lookup(struct mlxsw_sp *mlxsw_sp,
 -			struct mlxsw_sp_nexthop_key key)
 -{
 -	return rhashtable_lookup_fast(&mlxsw_sp->router->nexthop_ht, &key,
 -				      mlxsw_sp_nexthop_ht_params);
 -}
 -
 -static int mlxsw_sp_adj_index_mass_update_vr(struct mlxsw_sp *mlxsw_sp,
 -					     const struct mlxsw_sp_fib *fib,
 -					     u32 adj_index, u16 ecmp_size,
 -					     u32 new_adj_index,
 -					     u16 new_ecmp_size)
 -{
 -	char raleu_pl[MLXSW_REG_RALEU_LEN];
 -
 -	mlxsw_reg_raleu_pack(raleu_pl,
 -			     (enum mlxsw_reg_ralxx_protocol) fib->proto,
 -			     fib->vr->id, adj_index, ecmp_size, new_adj_index,
 -			     new_ecmp_size);
 -	return mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(raleu), raleu_pl);
 -}
 -
 -static int mlxsw_sp_adj_index_mass_update(struct mlxsw_sp *mlxsw_sp,
 -					  struct mlxsw_sp_nexthop_group *nh_grp,
 -					  u32 old_adj_index, u16 old_ecmp_size)
 -{
 -	struct mlxsw_sp_fib_entry *fib_entry;
 -	struct mlxsw_sp_fib *fib = NULL;
 -	int err;
 -
 -	list_for_each_entry(fib_entry, &nh_grp->fib_list, nexthop_group_node) {
 -		if (fib == fib_entry->fib_node->fib)
 -			continue;
 -		fib = fib_entry->fib_node->fib;
 -		err = mlxsw_sp_adj_index_mass_update_vr(mlxsw_sp, fib,
 -							old_adj_index,
 -							old_ecmp_size,
 -							nh_grp->adj_index,
 -							nh_grp->ecmp_size);
 -		if (err)
 -			return err;
 -	}
 -	return 0;
 -}
 -
 -static int mlxsw_sp_nexthop_mac_update(struct mlxsw_sp *mlxsw_sp, u32 adj_index,
 -				       struct mlxsw_sp_nexthop *nh)
 -{
 -	struct mlxsw_sp_neigh_entry *neigh_entry = nh->neigh_entry;
 -	char ratr_pl[MLXSW_REG_RATR_LEN];
 -
 -	mlxsw_reg_ratr_pack(ratr_pl, MLXSW_REG_RATR_OP_WRITE_WRITE_ENTRY,
 -			    true, MLXSW_REG_RATR_TYPE_ETHERNET,
 -			    adj_index, neigh_entry->rif);
 -	mlxsw_reg_ratr_eth_entry_pack(ratr_pl, neigh_entry->ha);
 -	return mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ratr), ratr_pl);
 -}
 -
 -static int mlxsw_sp_nexthop_ipip_update(struct mlxsw_sp *mlxsw_sp,
 -					u32 adj_index,
 -					struct mlxsw_sp_nexthop *nh)
 -{
 -	const struct mlxsw_sp_ipip_ops *ipip_ops;
 -
 -	ipip_ops = mlxsw_sp->router->ipip_ops_arr[nh->ipip_entry->ipipt];
 -	return ipip_ops->nexthop_update(mlxsw_sp, adj_index, nh->ipip_entry);
 -}
 -
 -static int
 -mlxsw_sp_nexthop_group_update(struct mlxsw_sp *mlxsw_sp,
 -			      struct mlxsw_sp_nexthop_group *nh_grp,
 -			      bool reallocate)
 -{
 -	u32 adj_index = nh_grp->adj_index; /* base */
 -	struct mlxsw_sp_nexthop *nh;
 -	int i;
 -	int err;
 -
 -	for (i = 0; i < nh_grp->count; i++) {
 -		nh = &nh_grp->nexthops[i];
 -
 -		if (!nh->should_offload) {
 -			nh->offloaded = 0;
 -			continue;
 -		}
 -
 -		if (nh->update || reallocate) {
 -			switch (nh->type) {
 -			case MLXSW_SP_NEXTHOP_TYPE_ETH:
 -				err = mlxsw_sp_nexthop_mac_update
 -					    (mlxsw_sp, adj_index, nh);
 -				break;
 -			case MLXSW_SP_NEXTHOP_TYPE_IPIP:
 -				err = mlxsw_sp_nexthop_ipip_update
 -					    (mlxsw_sp, adj_index, nh);
 -				break;
 -			}
 -			if (err)
 -				return err;
 -			nh->update = 0;
 -			nh->offloaded = 1;
 -		}
 -		adj_index++;
 -	}
 -	return 0;
 -}
 -
 -static bool
 -mlxsw_sp_fib_node_entry_is_first(const struct mlxsw_sp_fib_node *fib_node,
 -				 const struct mlxsw_sp_fib_entry *fib_entry);
 -
 -static int
 -mlxsw_sp_nexthop_fib_entries_update(struct mlxsw_sp *mlxsw_sp,
 -				    struct mlxsw_sp_nexthop_group *nh_grp)
 -{
 -	struct mlxsw_sp_fib_entry *fib_entry;
 -	int err;
 -
 -	list_for_each_entry(fib_entry, &nh_grp->fib_list, nexthop_group_node) {
 -		if (!mlxsw_sp_fib_node_entry_is_first(fib_entry->fib_node,
 -						      fib_entry))
 -			continue;
 -		err = mlxsw_sp_fib_entry_update(mlxsw_sp, fib_entry);
 -		if (err)
 -			return err;
 -	}
 -	return 0;
 -}
 -
 -static void
 -mlxsw_sp_fib_entry_offload_refresh(struct mlxsw_sp_fib_entry *fib_entry,
 -				   enum mlxsw_reg_ralue_op op, int err);
 -
 -static void
 -mlxsw_sp_nexthop_fib_entries_refresh(struct mlxsw_sp_nexthop_group *nh_grp)
 -{
 -	enum mlxsw_reg_ralue_op op = MLXSW_REG_RALUE_OP_WRITE_WRITE;
 -	struct mlxsw_sp_fib_entry *fib_entry;
 -
 -	list_for_each_entry(fib_entry, &nh_grp->fib_list, nexthop_group_node) {
 -		if (!mlxsw_sp_fib_node_entry_is_first(fib_entry->fib_node,
 -						      fib_entry))
 -			continue;
 -		mlxsw_sp_fib_entry_offload_refresh(fib_entry, op, 0);
 -	}
 -}
 -
 -static void
 -mlxsw_sp_nexthop_group_refresh(struct mlxsw_sp *mlxsw_sp,
 -			       struct mlxsw_sp_nexthop_group *nh_grp)
 -{
 -	struct mlxsw_sp_nexthop *nh;
 -	bool offload_change = false;
 -	u32 adj_index;
 -	u16 ecmp_size = 0;
 -	bool old_adj_index_valid;
 -	u32 old_adj_index;
 -	u16 old_ecmp_size;
 -	int i;
 -	int err;
 -
 -	if (!nh_grp->gateway) {
 -		mlxsw_sp_nexthop_fib_entries_update(mlxsw_sp, nh_grp);
 -		return;
 -	}
 -
 -	for (i = 0; i < nh_grp->count; i++) {
 -		nh = &nh_grp->nexthops[i];
 -
 -		if (nh->should_offload != nh->offloaded) {
 -			offload_change = true;
 -			if (nh->should_offload)
 -				nh->update = 1;
 -		}
 -		if (nh->should_offload)
 -			ecmp_size++;
 -	}
 -	if (!offload_change) {
 -		/* Nothing was added or removed, so no need to reallocate. Just
 -		 * update MAC on existing adjacency indexes.
 -		 */
 -		err = mlxsw_sp_nexthop_group_update(mlxsw_sp, nh_grp, false);
 -		if (err) {
 -			dev_warn(mlxsw_sp->bus_info->dev, "Failed to update neigh MAC in adjacency table.\n");
 -			goto set_trap;
 -		}
 -		return;
 -	}
 -	if (!ecmp_size)
 -		/* No neigh of this group is connected so we just set
 -		 * the trap and let everthing flow through kernel.
 -		 */
 -		goto set_trap;
 -
 -	err = mlxsw_sp_kvdl_alloc(mlxsw_sp, ecmp_size, &adj_index);
 -	if (err) {
 -		/* We ran out of KVD linear space, just set the
 -		 * trap and let everything flow through kernel.
 -		 */
 -		dev_warn(mlxsw_sp->bus_info->dev, "Failed to allocate KVD linear area for nexthop group.\n");
 -		goto set_trap;
 -	}
 -	old_adj_index_valid = nh_grp->adj_index_valid;
 -	old_adj_index = nh_grp->adj_index;
 -	old_ecmp_size = nh_grp->ecmp_size;
 -	nh_grp->adj_index_valid = 1;
 -	nh_grp->adj_index = adj_index;
 -	nh_grp->ecmp_size = ecmp_size;
 -	err = mlxsw_sp_nexthop_group_update(mlxsw_sp, nh_grp, true);
 -	if (err) {
 -		dev_warn(mlxsw_sp->bus_info->dev, "Failed to update neigh MAC in adjacency table.\n");
 -		goto set_trap;
 -	}
 -
 -	if (!old_adj_index_valid) {
 -		/* The trap was set for fib entries, so we have to call
 -		 * fib entry update to unset it and use adjacency index.
 -		 */
 -		err = mlxsw_sp_nexthop_fib_entries_update(mlxsw_sp, nh_grp);
 -		if (err) {
 -			dev_warn(mlxsw_sp->bus_info->dev, "Failed to add adjacency index to fib entries.\n");
 -			goto set_trap;
 -		}
 -		return;
 -	}
 -
 -	err = mlxsw_sp_adj_index_mass_update(mlxsw_sp, nh_grp,
 -					     old_adj_index, old_ecmp_size);
 -	mlxsw_sp_kvdl_free(mlxsw_sp, old_adj_index);
 -	if (err) {
 -		dev_warn(mlxsw_sp->bus_info->dev, "Failed to mass-update adjacency index for nexthop group.\n");
 -		goto set_trap;
 -	}
 -
 -	/* Offload state within the group changed, so update the flags. */
 -	mlxsw_sp_nexthop_fib_entries_refresh(nh_grp);
 -
 -	return;
 -
 -set_trap:
 -	old_adj_index_valid = nh_grp->adj_index_valid;
 -	nh_grp->adj_index_valid = 0;
 -	for (i = 0; i < nh_grp->count; i++) {
 -		nh = &nh_grp->nexthops[i];
 -		nh->offloaded = 0;
 -	}
 -	err = mlxsw_sp_nexthop_fib_entries_update(mlxsw_sp, nh_grp);
 -	if (err)
 -		dev_warn(mlxsw_sp->bus_info->dev, "Failed to set traps for fib entries.\n");
 -	if (old_adj_index_valid)
 -		mlxsw_sp_kvdl_free(mlxsw_sp, nh_grp->adj_index);
 -}
 -
 -static void __mlxsw_sp_nexthop_neigh_update(struct mlxsw_sp_nexthop *nh,
 -					    bool removing)
 -{
 -	if (!removing)
 -		nh->should_offload = 1;
 -	else if (nh->offloaded)
 -		nh->should_offload = 0;
 -	nh->update = 1;
 -}
 -
 -static void
 -mlxsw_sp_nexthop_neigh_update(struct mlxsw_sp *mlxsw_sp,
 -			      struct mlxsw_sp_neigh_entry *neigh_entry,
 -			      bool removing)
 -{
 -	struct mlxsw_sp_nexthop *nh;
 -
 -	list_for_each_entry(nh, &neigh_entry->nexthop_list,
 -			    neigh_list_node) {
 -		__mlxsw_sp_nexthop_neigh_update(nh, removing);
 -		mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh->nh_grp);
 -	}
 -}
 -
 -static void mlxsw_sp_nexthop_rif_init(struct mlxsw_sp_nexthop *nh,
 -				      struct mlxsw_sp_rif *rif)
 -{
 -	if (nh->rif)
 -		return;
 -
 -	nh->rif = rif;
 -	list_add(&nh->rif_list_node, &rif->nexthop_list);
 -}
 -
 -static void mlxsw_sp_nexthop_rif_fini(struct mlxsw_sp_nexthop *nh)
 -{
 -	if (!nh->rif)
 -		return;
 -
 -	list_del(&nh->rif_list_node);
 -	nh->rif = NULL;
 -}
 -
 -static int mlxsw_sp_nexthop_neigh_init(struct mlxsw_sp *mlxsw_sp,
 -				       struct mlxsw_sp_nexthop *nh)
 -{
 -	struct mlxsw_sp_neigh_entry *neigh_entry;
 -	struct neighbour *n;
 -	u8 nud_state, dead;
 -	int err;
 -
 -	if (!nh->nh_grp->gateway || nh->neigh_entry)
 -		return 0;
 -
 -	/* Take a reference of neigh here ensuring that neigh would
 -	 * not be destructed before the nexthop entry is finished.
 -	 * The reference is taken either in neigh_lookup() or
 -	 * in neigh_create() in case n is not found.
 -	 */
 -	n = neigh_lookup(nh->nh_grp->neigh_tbl, &nh->gw_addr, nh->rif->dev);
 -	if (!n) {
 -		n = neigh_create(nh->nh_grp->neigh_tbl, &nh->gw_addr,
 -				 nh->rif->dev);
 -		if (IS_ERR(n))
 -			return PTR_ERR(n);
 -		neigh_event_send(n, NULL);
 -	}
 -	neigh_entry = mlxsw_sp_neigh_entry_lookup(mlxsw_sp, n);
 -	if (!neigh_entry) {
 -		neigh_entry = mlxsw_sp_neigh_entry_create(mlxsw_sp, n);
 -		if (IS_ERR(neigh_entry)) {
 -			err = -EINVAL;
 -			goto err_neigh_entry_create;
 -		}
 -	}
 -
 -	/* If that is the first nexthop connected to that neigh, add to
 -	 * nexthop_neighs_list
 -	 */
 -	if (list_empty(&neigh_entry->nexthop_list))
 -		list_add_tail(&neigh_entry->nexthop_neighs_list_node,
 -			      &mlxsw_sp->router->nexthop_neighs_list);
 -
 -	nh->neigh_entry = neigh_entry;
 -	list_add_tail(&nh->neigh_list_node, &neigh_entry->nexthop_list);
 -	read_lock_bh(&n->lock);
 -	nud_state = n->nud_state;
 -	dead = n->dead;
 -	read_unlock_bh(&n->lock);
 -	__mlxsw_sp_nexthop_neigh_update(nh, !(nud_state & NUD_VALID && !dead));
 -
 -	return 0;
 -
 -err_neigh_entry_create:
 -	neigh_release(n);
 -	return err;
 -}
 -
 -static void mlxsw_sp_nexthop_neigh_fini(struct mlxsw_sp *mlxsw_sp,
 -					struct mlxsw_sp_nexthop *nh)
 -{
 -	struct mlxsw_sp_neigh_entry *neigh_entry = nh->neigh_entry;
 -	struct neighbour *n;
 -
 -	if (!neigh_entry)
 -		return;
 -	n = neigh_entry->key.n;
 -
 -	__mlxsw_sp_nexthop_neigh_update(nh, true);
 -	list_del(&nh->neigh_list_node);
 -	nh->neigh_entry = NULL;
 -
 -	/* If that is the last nexthop connected to that neigh, remove from
 -	 * nexthop_neighs_list
 -	 */
 -	if (list_empty(&neigh_entry->nexthop_list))
 -		list_del(&neigh_entry->nexthop_neighs_list_node);
 -
 -	if (!neigh_entry->connected && list_empty(&neigh_entry->nexthop_list))
 -		mlxsw_sp_neigh_entry_destroy(mlxsw_sp, neigh_entry);
 -
 -	neigh_release(n);
 -}
 -
 -static bool mlxsw_sp_netdev_ipip_type(const struct mlxsw_sp *mlxsw_sp,
 -				      const struct net_device *dev,
 -				      enum mlxsw_sp_ipip_type *p_type)
 -{
 -	struct mlxsw_sp_router *router = mlxsw_sp->router;
 -	const struct mlxsw_sp_ipip_ops *ipip_ops;
 -	enum mlxsw_sp_ipip_type ipipt;
 -
 -	for (ipipt = 0; ipipt < MLXSW_SP_IPIP_TYPE_MAX; ++ipipt) {
 -		ipip_ops = router->ipip_ops_arr[ipipt];
 -		if (dev->type == ipip_ops->dev_type) {
 -			if (p_type)
 -				*p_type = ipipt;
 -			return true;
 -		}
 -	}
 -	return false;
 -}
 -
 -static int mlxsw_sp_nexthop_ipip_init(struct mlxsw_sp *mlxsw_sp,
 -				      enum mlxsw_sp_ipip_type ipipt,
 -				      struct mlxsw_sp_nexthop *nh,
 -				      struct net_device *ol_dev)
 -{
 -	if (!nh->nh_grp->gateway || nh->ipip_entry)
 -		return 0;
 -
 -	nh->ipip_entry = mlxsw_sp_ipip_entry_get(mlxsw_sp, ipipt, ol_dev);
 -	if (IS_ERR(nh->ipip_entry))
 -		return PTR_ERR(nh->ipip_entry);
 -
 -	__mlxsw_sp_nexthop_neigh_update(nh, false);
 -	return 0;
 -}
 -
 -static void mlxsw_sp_nexthop_ipip_fini(struct mlxsw_sp *mlxsw_sp,
 -				       struct mlxsw_sp_nexthop *nh)
 -{
 -	struct mlxsw_sp_ipip_entry *ipip_entry = nh->ipip_entry;
 -
 -	if (!ipip_entry)
 -		return;
 -
 -	__mlxsw_sp_nexthop_neigh_update(nh, true);
 -	mlxsw_sp_ipip_entry_put(mlxsw_sp, ipip_entry);
 -	nh->ipip_entry = NULL;
 -}
 -
 -static bool mlxsw_sp_nexthop4_ipip_type(const struct mlxsw_sp *mlxsw_sp,
 -					const struct fib_nh *fib_nh,
 -					enum mlxsw_sp_ipip_type *p_ipipt)
 -{
 -	struct net_device *dev = fib_nh->nh_dev;
 -
 -	return dev &&
 -	       fib_nh->nh_parent->fib_type == RTN_UNICAST &&
 -	       mlxsw_sp_netdev_ipip_type(mlxsw_sp, dev, p_ipipt);
 -}
 -
 -static void mlxsw_sp_nexthop_type_fini(struct mlxsw_sp *mlxsw_sp,
 -				       struct mlxsw_sp_nexthop *nh)
 -{
 -	switch (nh->type) {
 -	case MLXSW_SP_NEXTHOP_TYPE_ETH:
 -		mlxsw_sp_nexthop_neigh_fini(mlxsw_sp, nh);
 -		mlxsw_sp_nexthop_rif_fini(nh);
 -		break;
 -	case MLXSW_SP_NEXTHOP_TYPE_IPIP:
 -		mlxsw_sp_nexthop_ipip_fini(mlxsw_sp, nh);
 -		break;
 -	}
 -}
 -
 -static int mlxsw_sp_nexthop4_type_init(struct mlxsw_sp *mlxsw_sp,
 -				       struct mlxsw_sp_nexthop *nh,
 -				       struct fib_nh *fib_nh)
 -{
 -	struct mlxsw_sp_router *router = mlxsw_sp->router;
 -	struct net_device *dev = fib_nh->nh_dev;
 -	enum mlxsw_sp_ipip_type ipipt;
 -	struct mlxsw_sp_rif *rif;
 -	int err;
 -
 -	if (mlxsw_sp_nexthop4_ipip_type(mlxsw_sp, fib_nh, &ipipt) &&
 -	    router->ipip_ops_arr[ipipt]->can_offload(mlxsw_sp, dev,
 -						     MLXSW_SP_L3_PROTO_IPV4)) {
 -		nh->type = MLXSW_SP_NEXTHOP_TYPE_IPIP;
 -		return mlxsw_sp_nexthop_ipip_init(mlxsw_sp, ipipt, nh, dev);
 -	}
 -
 -	nh->type = MLXSW_SP_NEXTHOP_TYPE_ETH;
 -	rif = mlxsw_sp_rif_find_by_dev(mlxsw_sp, dev);
 -	if (!rif)
 -		return 0;
 -
 -	mlxsw_sp_nexthop_rif_init(nh, rif);
 -	err = mlxsw_sp_nexthop_neigh_init(mlxsw_sp, nh);
 -	if (err)
 -		goto err_neigh_init;
 -
 -	return 0;
 -
 -err_neigh_init:
 -	mlxsw_sp_nexthop_rif_fini(nh);
 -	return err;
 -}
 -
 -static void mlxsw_sp_nexthop4_type_fini(struct mlxsw_sp *mlxsw_sp,
 -					struct mlxsw_sp_nexthop *nh)
 -{
 -	mlxsw_sp_nexthop_type_fini(mlxsw_sp, nh);
 -}
 -
 -static int mlxsw_sp_nexthop4_init(struct mlxsw_sp *mlxsw_sp,
 -				  struct mlxsw_sp_nexthop_group *nh_grp,
 -				  struct mlxsw_sp_nexthop *nh,
 -				  struct fib_nh *fib_nh)
 -{
 -	struct net_device *dev = fib_nh->nh_dev;
 -	struct in_device *in_dev;
 -	int err;
 -
 -	nh->nh_grp = nh_grp;
 -	nh->key.fib_nh = fib_nh;
 -	memcpy(&nh->gw_addr, &fib_nh->nh_gw, sizeof(fib_nh->nh_gw));
 -	err = mlxsw_sp_nexthop_insert(mlxsw_sp, nh);
 -	if (err)
 -		return err;
 -
 -	list_add_tail(&nh->router_list_node, &mlxsw_sp->router->nexthop_list);
 -
 -	if (!dev)
 -		return 0;
 -
 -	in_dev = __in_dev_get_rtnl(dev);
 -	if (in_dev && IN_DEV_IGNORE_ROUTES_WITH_LINKDOWN(in_dev) &&
 -	    fib_nh->nh_flags & RTNH_F_LINKDOWN)
 -		return 0;
 -
 -	err = mlxsw_sp_nexthop4_type_init(mlxsw_sp, nh, fib_nh);
 -	if (err)
 -		goto err_nexthop_neigh_init;
 -
 -	return 0;
 -
 -err_nexthop_neigh_init:
 -	mlxsw_sp_nexthop_remove(mlxsw_sp, nh);
 -	return err;
 -}
 -
 -static void mlxsw_sp_nexthop4_fini(struct mlxsw_sp *mlxsw_sp,
 -				   struct mlxsw_sp_nexthop *nh)
 -{
 -	mlxsw_sp_nexthop4_type_fini(mlxsw_sp, nh);
 -	list_del(&nh->router_list_node);
 -	mlxsw_sp_nexthop_remove(mlxsw_sp, nh);
 -}
 -
 -static void mlxsw_sp_nexthop4_event(struct mlxsw_sp *mlxsw_sp,
 -				    unsigned long event, struct fib_nh *fib_nh)
 -{
 -	struct mlxsw_sp_nexthop_key key;
 -	struct mlxsw_sp_nexthop *nh;
 -
 -	if (mlxsw_sp->router->aborted)
 -		return;
 -
 -	key.fib_nh = fib_nh;
 -	nh = mlxsw_sp_nexthop_lookup(mlxsw_sp, key);
 -	if (WARN_ON_ONCE(!nh))
 -		return;
 -
 -	switch (event) {
 -	case FIB_EVENT_NH_ADD:
 -		mlxsw_sp_nexthop4_type_init(mlxsw_sp, nh, fib_nh);
 -		break;
 -	case FIB_EVENT_NH_DEL:
 -		mlxsw_sp_nexthop4_type_fini(mlxsw_sp, nh);
 -		break;
 -	}
 -
 -	mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh->nh_grp);
 -}
 -
 -static void mlxsw_sp_nexthop_rif_gone_sync(struct mlxsw_sp *mlxsw_sp,
 -					   struct mlxsw_sp_rif *rif)
 -{
 -	struct mlxsw_sp_nexthop *nh, *tmp;
 -
 -	list_for_each_entry_safe(nh, tmp, &rif->nexthop_list, rif_list_node) {
 -		mlxsw_sp_nexthop_type_fini(mlxsw_sp, nh);
 -		mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh->nh_grp);
 -	}
 -}
 -
 -static bool mlxsw_sp_fi_is_gateway(const struct mlxsw_sp *mlxsw_sp,
 -				   const struct fib_info *fi)
 -{
 -	return fi->fib_nh->nh_scope == RT_SCOPE_LINK ||
 -	       mlxsw_sp_nexthop4_ipip_type(mlxsw_sp, fi->fib_nh, NULL);
 -}
 -
 -static struct mlxsw_sp_nexthop_group *
 -mlxsw_sp_nexthop4_group_create(struct mlxsw_sp *mlxsw_sp, struct fib_info *fi)
 -{
 -	struct mlxsw_sp_nexthop_group *nh_grp;
 -	struct mlxsw_sp_nexthop *nh;
 -	struct fib_nh *fib_nh;
 -	size_t alloc_size;
 -	int i;
 -	int err;
 -
 -	alloc_size = sizeof(*nh_grp) +
 -		     fi->fib_nhs * sizeof(struct mlxsw_sp_nexthop);
 -	nh_grp = kzalloc(alloc_size, GFP_KERNEL);
 -	if (!nh_grp)
 -		return ERR_PTR(-ENOMEM);
 -	nh_grp->priv = fi;
 -	INIT_LIST_HEAD(&nh_grp->fib_list);
 -	nh_grp->neigh_tbl = &arp_tbl;
 -
 -	nh_grp->gateway = mlxsw_sp_fi_is_gateway(mlxsw_sp, fi);
 -	nh_grp->count = fi->fib_nhs;
 -	fib_info_hold(fi);
 -	for (i = 0; i < nh_grp->count; i++) {
 -		nh = &nh_grp->nexthops[i];
 -		fib_nh = &fi->fib_nh[i];
 -		err = mlxsw_sp_nexthop4_init(mlxsw_sp, nh_grp, nh, fib_nh);
 -		if (err)
 -			goto err_nexthop4_init;
 -	}
 -	err = mlxsw_sp_nexthop_group_insert(mlxsw_sp, nh_grp);
 -	if (err)
 -		goto err_nexthop_group_insert;
 -	mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh_grp);
 -	return nh_grp;
 -
 -err_nexthop_group_insert:
 -err_nexthop4_init:
 -	for (i--; i >= 0; i--) {
 -		nh = &nh_grp->nexthops[i];
 -		mlxsw_sp_nexthop4_fini(mlxsw_sp, nh);
 -	}
 -	fib_info_put(fi);
 -	kfree(nh_grp);
 -	return ERR_PTR(err);
 -}
 -
 -static void
 -mlxsw_sp_nexthop4_group_destroy(struct mlxsw_sp *mlxsw_sp,
 -				struct mlxsw_sp_nexthop_group *nh_grp)
 -{
 -	struct mlxsw_sp_nexthop *nh;
 -	int i;
 -
 -	mlxsw_sp_nexthop_group_remove(mlxsw_sp, nh_grp);
 -	for (i = 0; i < nh_grp->count; i++) {
 -		nh = &nh_grp->nexthops[i];
 -		mlxsw_sp_nexthop4_fini(mlxsw_sp, nh);
 -	}
 -	mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh_grp);
 -	WARN_ON_ONCE(nh_grp->adj_index_valid);
 -	fib_info_put(mlxsw_sp_nexthop4_group_fi(nh_grp));
 -	kfree(nh_grp);
 -}
 -
 -static int mlxsw_sp_nexthop4_group_get(struct mlxsw_sp *mlxsw_sp,
 -				       struct mlxsw_sp_fib_entry *fib_entry,
 -				       struct fib_info *fi)
 -{
 -	struct mlxsw_sp_nexthop_group *nh_grp;
 -
 -	nh_grp = mlxsw_sp_nexthop4_group_lookup(mlxsw_sp, fi);
 -	if (!nh_grp) {
 -		nh_grp = mlxsw_sp_nexthop4_group_create(mlxsw_sp, fi);
 -		if (IS_ERR(nh_grp))
 -			return PTR_ERR(nh_grp);
 -	}
 -	list_add_tail(&fib_entry->nexthop_group_node, &nh_grp->fib_list);
 -	fib_entry->nh_group = nh_grp;
 -	return 0;
 -}
 -
 -static void mlxsw_sp_nexthop4_group_put(struct mlxsw_sp *mlxsw_sp,
 -					struct mlxsw_sp_fib_entry *fib_entry)
 -{
 -	struct mlxsw_sp_nexthop_group *nh_grp = fib_entry->nh_group;
 -
 -	list_del(&fib_entry->nexthop_group_node);
 -	if (!list_empty(&nh_grp->fib_list))
 -		return;
 -	mlxsw_sp_nexthop4_group_destroy(mlxsw_sp, nh_grp);
 -}
 -
 -static bool
 -mlxsw_sp_fib4_entry_should_offload(const struct mlxsw_sp_fib_entry *fib_entry)
 -{
 -	struct mlxsw_sp_fib4_entry *fib4_entry;
 -
 -	fib4_entry = container_of(fib_entry, struct mlxsw_sp_fib4_entry,
 -				  common);
 -	return !fib4_entry->tos;
 -}
 -
 -static bool
 -mlxsw_sp_fib_entry_should_offload(const struct mlxsw_sp_fib_entry *fib_entry)
 -{
 -	struct mlxsw_sp_nexthop_group *nh_group = fib_entry->nh_group;
 -
 -	switch (fib_entry->fib_node->fib->proto) {
 -	case MLXSW_SP_L3_PROTO_IPV4:
 -		if (!mlxsw_sp_fib4_entry_should_offload(fib_entry))
 -			return false;
 -		break;
 -	case MLXSW_SP_L3_PROTO_IPV6:
 -		break;
 -	}
 -
 -	switch (fib_entry->type) {
 -	case MLXSW_SP_FIB_ENTRY_TYPE_REMOTE:
 -		return !!nh_group->adj_index_valid;
 -	case MLXSW_SP_FIB_ENTRY_TYPE_LOCAL:
 -		return !!nh_group->nh_rif;
 -	case MLXSW_SP_FIB_ENTRY_TYPE_IPIP_DECAP:
 -		return true;
 -	default:
 -		return false;
 -	}
 -}
 -
 -static struct mlxsw_sp_nexthop *
 -mlxsw_sp_rt6_nexthop(struct mlxsw_sp_nexthop_group *nh_grp,
 -		     const struct mlxsw_sp_rt6 *mlxsw_sp_rt6)
 -{
 -	int i;
 -
 -	for (i = 0; i < nh_grp->count; i++) {
 -		struct mlxsw_sp_nexthop *nh = &nh_grp->nexthops[i];
 -		struct rt6_info *rt = mlxsw_sp_rt6->rt;
 -
 -		if (nh->rif && nh->rif->dev == rt->dst.dev &&
 -		    ipv6_addr_equal((const struct in6_addr *) &nh->gw_addr,
 -				    &rt->rt6i_gateway))
 -			return nh;
 -		continue;
 -	}
 -
 -	return NULL;
 -}
 -
 -static void
 -mlxsw_sp_fib4_entry_offload_set(struct mlxsw_sp_fib_entry *fib_entry)
 -{
 -	struct mlxsw_sp_nexthop_group *nh_grp = fib_entry->nh_group;
 -	int i;
 -
 -	if (fib_entry->type == MLXSW_SP_FIB_ENTRY_TYPE_LOCAL ||
 -	    fib_entry->type == MLXSW_SP_FIB_ENTRY_TYPE_IPIP_DECAP) {
 -		nh_grp->nexthops->key.fib_nh->nh_flags |= RTNH_F_OFFLOAD;
 -		return;
 -	}
 -
 -	for (i = 0; i < nh_grp->count; i++) {
 -		struct mlxsw_sp_nexthop *nh = &nh_grp->nexthops[i];
 -
 -		if (nh->offloaded)
 -			nh->key.fib_nh->nh_flags |= RTNH_F_OFFLOAD;
 -		else
 -			nh->key.fib_nh->nh_flags &= ~RTNH_F_OFFLOAD;
 -	}
 -}
 -
 -static void
 -mlxsw_sp_fib4_entry_offload_unset(struct mlxsw_sp_fib_entry *fib_entry)
 -{
 -	struct mlxsw_sp_nexthop_group *nh_grp = fib_entry->nh_group;
 -	int i;
 -
 -	for (i = 0; i < nh_grp->count; i++) {
 -		struct mlxsw_sp_nexthop *nh = &nh_grp->nexthops[i];
 -
 -		nh->key.fib_nh->nh_flags &= ~RTNH_F_OFFLOAD;
 -	}
 -}
 -
 -static void
 -mlxsw_sp_fib6_entry_offload_set(struct mlxsw_sp_fib_entry *fib_entry)
 -{
 -	struct mlxsw_sp_fib6_entry *fib6_entry;
 -	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
 -
 -	fib6_entry = container_of(fib_entry, struct mlxsw_sp_fib6_entry,
 -				  common);
 -
 -	if (fib_entry->type == MLXSW_SP_FIB_ENTRY_TYPE_LOCAL) {
 -		list_first_entry(&fib6_entry->rt6_list, struct mlxsw_sp_rt6,
 -				 list)->rt->rt6i_nh_flags |= RTNH_F_OFFLOAD;
 -		return;
 -	}
 -
 -	list_for_each_entry(mlxsw_sp_rt6, &fib6_entry->rt6_list, list) {
 -		struct mlxsw_sp_nexthop_group *nh_grp = fib_entry->nh_group;
 -		struct mlxsw_sp_nexthop *nh;
 -
 -		nh = mlxsw_sp_rt6_nexthop(nh_grp, mlxsw_sp_rt6);
 -		if (nh && nh->offloaded)
 -			mlxsw_sp_rt6->rt->rt6i_nh_flags |= RTNH_F_OFFLOAD;
 -		else
 -			mlxsw_sp_rt6->rt->rt6i_nh_flags &= ~RTNH_F_OFFLOAD;
 -	}
 -}
 -
 -static void
 -mlxsw_sp_fib6_entry_offload_unset(struct mlxsw_sp_fib_entry *fib_entry)
 -{
 -	struct mlxsw_sp_fib6_entry *fib6_entry;
 -	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
 -
 -	fib6_entry = container_of(fib_entry, struct mlxsw_sp_fib6_entry,
 -				  common);
 -	list_for_each_entry(mlxsw_sp_rt6, &fib6_entry->rt6_list, list) {
 -		struct rt6_info *rt = mlxsw_sp_rt6->rt;
 -
 -		rt->rt6i_nh_flags &= ~RTNH_F_OFFLOAD;
 -	}
 -}
 -
 -static void mlxsw_sp_fib_entry_offload_set(struct mlxsw_sp_fib_entry *fib_entry)
 -{
 -	switch (fib_entry->fib_node->fib->proto) {
 -	case MLXSW_SP_L3_PROTO_IPV4:
 -		mlxsw_sp_fib4_entry_offload_set(fib_entry);
 -		break;
 -	case MLXSW_SP_L3_PROTO_IPV6:
 -		mlxsw_sp_fib6_entry_offload_set(fib_entry);
 -		break;
 -	}
 -}
 -
 -static void
 -mlxsw_sp_fib_entry_offload_unset(struct mlxsw_sp_fib_entry *fib_entry)
 -{
 -	switch (fib_entry->fib_node->fib->proto) {
 -	case MLXSW_SP_L3_PROTO_IPV4:
 -		mlxsw_sp_fib4_entry_offload_unset(fib_entry);
 -		break;
 -	case MLXSW_SP_L3_PROTO_IPV6:
 -		mlxsw_sp_fib6_entry_offload_unset(fib_entry);
 -		break;
 -	}
 -}
 -
 -static void
 -mlxsw_sp_fib_entry_offload_refresh(struct mlxsw_sp_fib_entry *fib_entry,
 -				   enum mlxsw_reg_ralue_op op, int err)
 -{
 -	switch (op) {
 -	case MLXSW_REG_RALUE_OP_WRITE_DELETE:
 -		return mlxsw_sp_fib_entry_offload_unset(fib_entry);
 -	case MLXSW_REG_RALUE_OP_WRITE_WRITE:
 -		if (err)
 -			return;
 -		if (mlxsw_sp_fib_entry_should_offload(fib_entry))
 -			mlxsw_sp_fib_entry_offload_set(fib_entry);
 -		else if (!mlxsw_sp_fib_entry_should_offload(fib_entry))
 -			mlxsw_sp_fib_entry_offload_unset(fib_entry);
 -		return;
 -	default:
 -		return;
 -	}
 -}
 -
 -static void
 -mlxsw_sp_fib_entry_ralue_pack(char *ralue_pl,
 -			      const struct mlxsw_sp_fib_entry *fib_entry,
 -			      enum mlxsw_reg_ralue_op op)
 -{
 -	struct mlxsw_sp_fib *fib = fib_entry->fib_node->fib;
 -	enum mlxsw_reg_ralxx_protocol proto;
 -	u32 *p_dip;
 -
 -	proto = (enum mlxsw_reg_ralxx_protocol) fib->proto;
 -
 -	switch (fib->proto) {
 -	case MLXSW_SP_L3_PROTO_IPV4:
 -		p_dip = (u32 *) fib_entry->fib_node->key.addr;
 -		mlxsw_reg_ralue_pack4(ralue_pl, proto, op, fib->vr->id,
 -				      fib_entry->fib_node->key.prefix_len,
 -				      *p_dip);
 -		break;
 -	case MLXSW_SP_L3_PROTO_IPV6:
 -		mlxsw_reg_ralue_pack6(ralue_pl, proto, op, fib->vr->id,
 -				      fib_entry->fib_node->key.prefix_len,
 -				      fib_entry->fib_node->key.addr);
 -		break;
 -	}
 -}
 -
 -static int mlxsw_sp_fib_entry_op_remote(struct mlxsw_sp *mlxsw_sp,
 -					struct mlxsw_sp_fib_entry *fib_entry,
 -					enum mlxsw_reg_ralue_op op)
 -{
 -	char ralue_pl[MLXSW_REG_RALUE_LEN];
 -	enum mlxsw_reg_ralue_trap_action trap_action;
 -	u16 trap_id = 0;
 -	u32 adjacency_index = 0;
 -	u16 ecmp_size = 0;
 -
 -	/* In case the nexthop group adjacency index is valid, use it
 -	 * with provided ECMP size. Otherwise, setup trap and pass
 -	 * traffic to kernel.
 -	 */
 -	if (mlxsw_sp_fib_entry_should_offload(fib_entry)) {
 -		trap_action = MLXSW_REG_RALUE_TRAP_ACTION_NOP;
 -		adjacency_index = fib_entry->nh_group->adj_index;
 -		ecmp_size = fib_entry->nh_group->ecmp_size;
 -	} else {
 -		trap_action = MLXSW_REG_RALUE_TRAP_ACTION_TRAP;
 -		trap_id = MLXSW_TRAP_ID_RTR_INGRESS0;
 -	}
 -
 -	mlxsw_sp_fib_entry_ralue_pack(ralue_pl, fib_entry, op);
 -	mlxsw_reg_ralue_act_remote_pack(ralue_pl, trap_action, trap_id,
 -					adjacency_index, ecmp_size);
 -	return mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ralue), ralue_pl);
 -}
 -
 -static int mlxsw_sp_fib_entry_op_local(struct mlxsw_sp *mlxsw_sp,
 -				       struct mlxsw_sp_fib_entry *fib_entry,
 -				       enum mlxsw_reg_ralue_op op)
 -{
 -	struct mlxsw_sp_rif *rif = fib_entry->nh_group->nh_rif;
 -	enum mlxsw_reg_ralue_trap_action trap_action;
 -	char ralue_pl[MLXSW_REG_RALUE_LEN];
 -	u16 trap_id = 0;
 -	u16 rif_index = 0;
 -
 -	if (mlxsw_sp_fib_entry_should_offload(fib_entry)) {
 -		trap_action = MLXSW_REG_RALUE_TRAP_ACTION_NOP;
 -		rif_index = rif->rif_index;
 -	} else {
 -		trap_action = MLXSW_REG_RALUE_TRAP_ACTION_TRAP;
 -		trap_id = MLXSW_TRAP_ID_RTR_INGRESS0;
 -	}
 -
 -	mlxsw_sp_fib_entry_ralue_pack(ralue_pl, fib_entry, op);
 -	mlxsw_reg_ralue_act_local_pack(ralue_pl, trap_action, trap_id,
 -				       rif_index);
 -	return mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ralue), ralue_pl);
 -}
 +struct mlxsw_sp_nexthop_group_key {
 +	struct fib_info *fi;
 +};
  
 -static int mlxsw_sp_fib_entry_op_trap(struct mlxsw_sp *mlxsw_sp,
 -				      struct mlxsw_sp_fib_entry *fib_entry,
 -				      enum mlxsw_reg_ralue_op op)
 -{
 -	char ralue_pl[MLXSW_REG_RALUE_LEN];
 +struct mlxsw_sp_nexthop_group {
 +	struct rhash_head ht_node;
 +	struct list_head fib_list; /* list of fib entries that use this group */
 +	struct mlxsw_sp_nexthop_group_key key;
 +	u8 adj_index_valid:1,
 +	   gateway:1; /* routes using the group use a gateway */
 +	u32 adj_index;
 +	u16 ecmp_size;
 +	u16 count;
 +	struct mlxsw_sp_nexthop nexthops[0];
 +#define nh_rif	nexthops[0].r
 +};
  
 -	mlxsw_sp_fib_entry_ralue_pack(ralue_pl, fib_entry, op);
 -	mlxsw_reg_ralue_act_ip2me_pack(ralue_pl);
 -	return mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ralue), ralue_pl);
 -}
 +static const struct rhashtable_params mlxsw_sp_nexthop_group_ht_params = {
 +	.key_offset = offsetof(struct mlxsw_sp_nexthop_group, key),
 +	.head_offset = offsetof(struct mlxsw_sp_nexthop_group, ht_node),
 +	.key_len = sizeof(struct mlxsw_sp_nexthop_group_key),
 +};
  
 -static int
 -mlxsw_sp_fib_entry_op_ipip_decap(struct mlxsw_sp *mlxsw_sp,
 -				 struct mlxsw_sp_fib_entry *fib_entry,
 -				 enum mlxsw_reg_ralue_op op)
 +static int mlxsw_sp_nexthop_group_insert(struct mlxsw_sp *mlxsw_sp,
 +					 struct mlxsw_sp_nexthop_group *nh_grp)
  {
 -	struct mlxsw_sp_ipip_entry *ipip_entry = fib_entry->decap.ipip_entry;
 -	const struct mlxsw_sp_ipip_ops *ipip_ops;
 -
 -	if (WARN_ON(!ipip_entry))
 -		return -EINVAL;
 -
 -	ipip_ops = mlxsw_sp->router->ipip_ops_arr[ipip_entry->ipipt];
 -	return ipip_ops->fib_entry_op(mlxsw_sp, ipip_entry, op,
 -				      fib_entry->decap.tunnel_index);
 +	return rhashtable_insert_fast(&mlxsw_sp->router.nexthop_group_ht,
 +				      &nh_grp->ht_node,
 +				      mlxsw_sp_nexthop_group_ht_params);
  }
  
 -static int __mlxsw_sp_fib_entry_op(struct mlxsw_sp *mlxsw_sp,
 -				   struct mlxsw_sp_fib_entry *fib_entry,
 -				   enum mlxsw_reg_ralue_op op)
 +static void mlxsw_sp_nexthop_group_remove(struct mlxsw_sp *mlxsw_sp,
 +					  struct mlxsw_sp_nexthop_group *nh_grp)
  {
 -	switch (fib_entry->type) {
 -	case MLXSW_SP_FIB_ENTRY_TYPE_REMOTE:
 -		return mlxsw_sp_fib_entry_op_remote(mlxsw_sp, fib_entry, op);
 -	case MLXSW_SP_FIB_ENTRY_TYPE_LOCAL:
 -		return mlxsw_sp_fib_entry_op_local(mlxsw_sp, fib_entry, op);
 -	case MLXSW_SP_FIB_ENTRY_TYPE_TRAP:
 -		return mlxsw_sp_fib_entry_op_trap(mlxsw_sp, fib_entry, op);
 -	case MLXSW_SP_FIB_ENTRY_TYPE_IPIP_DECAP:
 -		return mlxsw_sp_fib_entry_op_ipip_decap(mlxsw_sp,
 -							fib_entry, op);
 -	}
 -	return -EINVAL;
 +	rhashtable_remove_fast(&mlxsw_sp->router.nexthop_group_ht,
 +			       &nh_grp->ht_node,
 +			       mlxsw_sp_nexthop_group_ht_params);
  }
  
 -static int mlxsw_sp_fib_entry_op(struct mlxsw_sp *mlxsw_sp,
 -				 struct mlxsw_sp_fib_entry *fib_entry,
 -				 enum mlxsw_reg_ralue_op op)
 +static struct mlxsw_sp_nexthop_group *
 +mlxsw_sp_nexthop_group_lookup(struct mlxsw_sp *mlxsw_sp,
 +			      struct mlxsw_sp_nexthop_group_key key)
  {
 -	int err = __mlxsw_sp_fib_entry_op(mlxsw_sp, fib_entry, op);
 +	return rhashtable_lookup_fast(&mlxsw_sp->router.nexthop_group_ht, &key,
 +				      mlxsw_sp_nexthop_group_ht_params);
 +}
  
 -	mlxsw_sp_fib_entry_offload_refresh(fib_entry, op, err);
 +static const struct rhashtable_params mlxsw_sp_nexthop_ht_params = {
 +	.key_offset = offsetof(struct mlxsw_sp_nexthop, key),
 +	.head_offset = offsetof(struct mlxsw_sp_nexthop, ht_node),
 +	.key_len = sizeof(struct mlxsw_sp_nexthop_key),
 +};
  
 -	return err;
 +static int mlxsw_sp_nexthop_insert(struct mlxsw_sp *mlxsw_sp,
 +				   struct mlxsw_sp_nexthop *nh)
 +{
 +	return rhashtable_insert_fast(&mlxsw_sp->router.nexthop_ht,
 +				      &nh->ht_node, mlxsw_sp_nexthop_ht_params);
  }
  
 -static int mlxsw_sp_fib_entry_update(struct mlxsw_sp *mlxsw_sp,
 -				     struct mlxsw_sp_fib_entry *fib_entry)
 +static void mlxsw_sp_nexthop_remove(struct mlxsw_sp *mlxsw_sp,
 +				    struct mlxsw_sp_nexthop *nh)
  {
 -	return mlxsw_sp_fib_entry_op(mlxsw_sp, fib_entry,
 -				     MLXSW_REG_RALUE_OP_WRITE_WRITE);
 +	rhashtable_remove_fast(&mlxsw_sp->router.nexthop_ht, &nh->ht_node,
 +			       mlxsw_sp_nexthop_ht_params);
  }
  
 -static int mlxsw_sp_fib_entry_del(struct mlxsw_sp *mlxsw_sp,
 -				  struct mlxsw_sp_fib_entry *fib_entry)
 +static struct mlxsw_sp_nexthop *
 +mlxsw_sp_nexthop_lookup(struct mlxsw_sp *mlxsw_sp,
 +			struct mlxsw_sp_nexthop_key key)
  {
 -	return mlxsw_sp_fib_entry_op(mlxsw_sp, fib_entry,
 -				     MLXSW_REG_RALUE_OP_WRITE_DELETE);
 +	return rhashtable_lookup_fast(&mlxsw_sp->router.nexthop_ht, &key,
 +				      mlxsw_sp_nexthop_ht_params);
  }
  
 -static int
 -mlxsw_sp_fib4_entry_type_set(struct mlxsw_sp *mlxsw_sp,
 -			     const struct fib_entry_notifier_info *fen_info,
 -			     struct mlxsw_sp_fib_entry *fib_entry)
 +static int mlxsw_sp_adj_index_mass_update_vr(struct mlxsw_sp *mlxsw_sp,
 +					     const struct mlxsw_sp_fib *fib,
 +					     u32 adj_index, u16 ecmp_size,
 +					     u32 new_adj_index,
 +					     u16 new_ecmp_size)
  {
 -	union mlxsw_sp_l3addr dip = { .addr4 = htonl(fen_info->dst) };
 -	struct net_device *dev = fen_info->fi->fib_dev;
 -	struct mlxsw_sp_ipip_entry *ipip_entry;
 -	struct fib_info *fi = fen_info->fi;
 +	char raleu_pl[MLXSW_REG_RALEU_LEN];
  
 -	switch (fen_info->type) {
 -	case RTN_LOCAL:
 -		ipip_entry = mlxsw_sp_ipip_entry_find_by_decap(mlxsw_sp, dev,
 -						 MLXSW_SP_L3_PROTO_IPV4, dip);
 -		if (ipip_entry) {
 -			fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_IPIP_DECAP;
 -			return mlxsw_sp_fib_entry_decap_init(mlxsw_sp,
 -							     fib_entry,
 -							     ipip_entry);
 -		}
 -		/* fall through */
 -	case RTN_BROADCAST:
 -		fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_TRAP;
 -		return 0;
 -	case RTN_UNREACHABLE: /* fall through */
 -	case RTN_BLACKHOLE: /* fall through */
 -	case RTN_PROHIBIT:
 -		/* Packets hitting these routes need to be trapped, but
 -		 * can do so with a lower priority than packets directed
 -		 * at the host, so use action type local instead of trap.
 -		 */
 -		fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_LOCAL;
 -		return 0;
 -	case RTN_UNICAST:
 -		if (mlxsw_sp_fi_is_gateway(mlxsw_sp, fi))
 -			fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_REMOTE;
 -		else
 -			fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_LOCAL;
 -		return 0;
 -	default:
 -		return -EINVAL;
 -	}
 +	mlxsw_reg_raleu_pack(raleu_pl,
 +			     (enum mlxsw_reg_ralxx_protocol) fib->proto,
 +			     fib->vr->id, adj_index, ecmp_size, new_adj_index,
 +			     new_ecmp_size);
 +	return mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(raleu), raleu_pl);
  }
  
 -static struct mlxsw_sp_fib4_entry *
 -mlxsw_sp_fib4_entry_create(struct mlxsw_sp *mlxsw_sp,
 -			   struct mlxsw_sp_fib_node *fib_node,
 -			   const struct fib_entry_notifier_info *fen_info)
 +static int mlxsw_sp_adj_index_mass_update(struct mlxsw_sp *mlxsw_sp,
 +					  struct mlxsw_sp_nexthop_group *nh_grp,
 +					  u32 old_adj_index, u16 old_ecmp_size)
  {
 -	struct mlxsw_sp_fib4_entry *fib4_entry;
  	struct mlxsw_sp_fib_entry *fib_entry;
 +	struct mlxsw_sp_fib *fib = NULL;
  	int err;
  
 -	fib4_entry = kzalloc(sizeof(*fib4_entry), GFP_KERNEL);
 -	if (!fib4_entry)
 -		return ERR_PTR(-ENOMEM);
 -	fib_entry = &fib4_entry->common;
 -
 -	err = mlxsw_sp_fib4_entry_type_set(mlxsw_sp, fen_info, fib_entry);
 -	if (err)
 -		goto err_fib4_entry_type_set;
 -
 -	err = mlxsw_sp_nexthop4_group_get(mlxsw_sp, fib_entry, fen_info->fi);
 -	if (err)
 -		goto err_nexthop4_group_get;
 -
 -	fib4_entry->prio = fen_info->fi->fib_priority;
 -	fib4_entry->tb_id = fen_info->tb_id;
 -	fib4_entry->type = fen_info->type;
 -	fib4_entry->tos = fen_info->tos;
 -
 -	fib_entry->fib_node = fib_node;
 -
 -	return fib4_entry;
 -
 -err_nexthop4_group_get:
 -err_fib4_entry_type_set:
 -	kfree(fib4_entry);
 -	return ERR_PTR(err);
 +	list_for_each_entry(fib_entry, &nh_grp->fib_list, nexthop_group_node) {
 +		if (fib == fib_entry->fib_node->fib)
 +			continue;
 +		fib = fib_entry->fib_node->fib;
 +		err = mlxsw_sp_adj_index_mass_update_vr(mlxsw_sp, fib,
 +							old_adj_index,
 +							old_ecmp_size,
 +							nh_grp->adj_index,
 +							nh_grp->ecmp_size);
 +		if (err)
 +			return err;
 +	}
 +	return 0;
  }
  
 -static void mlxsw_sp_fib4_entry_destroy(struct mlxsw_sp *mlxsw_sp,
 -					struct mlxsw_sp_fib4_entry *fib4_entry)
 +static int mlxsw_sp_nexthop_mac_update(struct mlxsw_sp *mlxsw_sp, u32 adj_index,
 +				       struct mlxsw_sp_nexthop *nh)
  {
 -	mlxsw_sp_nexthop4_group_put(mlxsw_sp, &fib4_entry->common);
 -	kfree(fib4_entry);
 +	struct mlxsw_sp_neigh_entry *neigh_entry = nh->neigh_entry;
 +	char ratr_pl[MLXSW_REG_RATR_LEN];
 +
 +	mlxsw_reg_ratr_pack(ratr_pl, MLXSW_REG_RATR_OP_WRITE_WRITE_ENTRY,
 +			    true, MLXSW_REG_RATR_TYPE_ETHERNET,
 +			    adj_index, neigh_entry->rif);
 +	mlxsw_reg_ratr_eth_entry_pack(ratr_pl, neigh_entry->ha);
 +	return mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ratr), ratr_pl);
  }
  
 -static struct mlxsw_sp_fib4_entry *
 -mlxsw_sp_fib4_entry_lookup(struct mlxsw_sp *mlxsw_sp,
 -			   const struct fib_entry_notifier_info *fen_info)
 +static int
 +mlxsw_sp_nexthop_group_mac_update(struct mlxsw_sp *mlxsw_sp,
 +				  struct mlxsw_sp_nexthop_group *nh_grp,
 +				  bool reallocate)
  {
 -	struct mlxsw_sp_fib4_entry *fib4_entry;
 -	struct mlxsw_sp_fib_node *fib_node;
 -	struct mlxsw_sp_fib *fib;
 -	struct mlxsw_sp_vr *vr;
 +	u32 adj_index = nh_grp->adj_index; /* base */
 +	struct mlxsw_sp_nexthop *nh;
 +	int i;
 +	int err;
  
 -	vr = mlxsw_sp_vr_find(mlxsw_sp, fen_info->tb_id);
 -	if (!vr)
 -		return NULL;
 -	fib = mlxsw_sp_vr_fib(vr, MLXSW_SP_L3_PROTO_IPV4);
 +	for (i = 0; i < nh_grp->count; i++) {
 +		nh = &nh_grp->nexthops[i];
  
 -	fib_node = mlxsw_sp_fib_node_lookup(fib, &fen_info->dst,
 -					    sizeof(fen_info->dst),
 -					    fen_info->dst_len);
 -	if (!fib_node)
 -		return NULL;
 +		if (!nh->should_offload) {
 +			nh->offloaded = 0;
 +			continue;
 +		}
  
 -	list_for_each_entry(fib4_entry, &fib_node->entry_list, common.list) {
 -		if (fib4_entry->tb_id == fen_info->tb_id &&
 -		    fib4_entry->tos == fen_info->tos &&
 -		    fib4_entry->type == fen_info->type &&
 -		    mlxsw_sp_nexthop4_group_fi(fib4_entry->common.nh_group) ==
 -		    fen_info->fi) {
 -			return fib4_entry;
 +		if (nh->update || reallocate) {
 +			err = mlxsw_sp_nexthop_mac_update(mlxsw_sp,
 +							  adj_index, nh);
 +			if (err)
 +				return err;
 +			nh->update = 0;
 +			nh->offloaded = 1;
  		}
 +		adj_index++;
  	}
 -
 -	return NULL;
 -}
 -
 -static const struct rhashtable_params mlxsw_sp_fib_ht_params = {
 -	.key_offset = offsetof(struct mlxsw_sp_fib_node, key),
 -	.head_offset = offsetof(struct mlxsw_sp_fib_node, ht_node),
 -	.key_len = sizeof(struct mlxsw_sp_fib_key),
 -	.automatic_shrinking = true,
 -};
 -
 -static int mlxsw_sp_fib_node_insert(struct mlxsw_sp_fib *fib,
 -				    struct mlxsw_sp_fib_node *fib_node)
 -{
 -	return rhashtable_insert_fast(&fib->ht, &fib_node->ht_node,
 -				      mlxsw_sp_fib_ht_params);
 -}
 -
 -static void mlxsw_sp_fib_node_remove(struct mlxsw_sp_fib *fib,
 -				     struct mlxsw_sp_fib_node *fib_node)
 -{
 -	rhashtable_remove_fast(&fib->ht, &fib_node->ht_node,
 -			       mlxsw_sp_fib_ht_params);
 +	return 0;
  }
  
 -static struct mlxsw_sp_fib_node *
 -mlxsw_sp_fib_node_lookup(struct mlxsw_sp_fib *fib, const void *addr,
 -			 size_t addr_len, unsigned char prefix_len)
 -{
 -	struct mlxsw_sp_fib_key key;
 +static int mlxsw_sp_fib_entry_update(struct mlxsw_sp *mlxsw_sp,
 +				     struct mlxsw_sp_fib_entry *fib_entry);
  
 -	memset(&key, 0, sizeof(key));
 -	memcpy(key.addr, addr, addr_len);
 -	key.prefix_len = prefix_len;
 -	return rhashtable_lookup_fast(&fib->ht, &key, mlxsw_sp_fib_ht_params);
 -}
 +static bool
 +mlxsw_sp_fib_node_entry_is_first(const struct mlxsw_sp_fib_node *fib_node,
 +				 const struct mlxsw_sp_fib_entry *fib_entry);
  
 -static struct mlxsw_sp_fib_node *
 -mlxsw_sp_fib_node_create(struct mlxsw_sp_fib *fib, const void *addr,
 -			 size_t addr_len, unsigned char prefix_len)
 +static int
 +mlxsw_sp_nexthop_fib_entries_update(struct mlxsw_sp *mlxsw_sp,
 +				    struct mlxsw_sp_nexthop_group *nh_grp)
  {
 -	struct mlxsw_sp_fib_node *fib_node;
 -
 -	fib_node = kzalloc(sizeof(*fib_node), GFP_KERNEL);
 -	if (!fib_node)
 -		return NULL;
 -
 -	INIT_LIST_HEAD(&fib_node->entry_list);
 -	list_add(&fib_node->list, &fib->node_list);
 -	memcpy(fib_node->key.addr, addr, addr_len);
 -	fib_node->key.prefix_len = prefix_len;
 +	struct mlxsw_sp_fib_entry *fib_entry;
 +	int err;
  
 -	return fib_node;
 +	list_for_each_entry(fib_entry, &nh_grp->fib_list, nexthop_group_node) {
 +		if (!mlxsw_sp_fib_node_entry_is_first(fib_entry->fib_node,
 +						      fib_entry))
 +			continue;
 +		err = mlxsw_sp_fib_entry_update(mlxsw_sp, fib_entry);
 +		if (err)
 +			return err;
 +	}
 +	return 0;
  }
  
 -static void mlxsw_sp_fib_node_destroy(struct mlxsw_sp_fib_node *fib_node)
 -{
 -	list_del(&fib_node->list);
 -	WARN_ON(!list_empty(&fib_node->entry_list));
 -	kfree(fib_node);
 -}
 +static void
 +mlxsw_sp_fib_entry_offload_refresh(struct mlxsw_sp_fib_entry *fib_entry,
 +				   enum mlxsw_reg_ralue_op op, int err);
  
 -static bool
 -mlxsw_sp_fib_node_entry_is_first(const struct mlxsw_sp_fib_node *fib_node,
 -				 const struct mlxsw_sp_fib_entry *fib_entry)
 +static void
 +mlxsw_sp_nexthop_fib_entries_refresh(struct mlxsw_sp_nexthop_group *nh_grp)
  {
 -	return list_first_entry(&fib_node->entry_list,
 -				struct mlxsw_sp_fib_entry, list) == fib_entry;
 +	enum mlxsw_reg_ralue_op op = MLXSW_REG_RALUE_OP_WRITE_WRITE;
 +	struct mlxsw_sp_fib_entry *fib_entry;
 +
 +	list_for_each_entry(fib_entry, &nh_grp->fib_list, nexthop_group_node) {
 +		if (!mlxsw_sp_fib_node_entry_is_first(fib_entry->fib_node,
 +						      fib_entry))
 +			continue;
 +		mlxsw_sp_fib_entry_offload_refresh(fib_entry, op, 0);
 +	}
  }
  
 -static int mlxsw_sp_fib_lpm_tree_link(struct mlxsw_sp *mlxsw_sp,
 -				      struct mlxsw_sp_fib *fib,
 -				      struct mlxsw_sp_fib_node *fib_node)
 +static void
 +mlxsw_sp_nexthop_group_refresh(struct mlxsw_sp *mlxsw_sp,
 +			       struct mlxsw_sp_nexthop_group *nh_grp)
  {
 -	struct mlxsw_sp_prefix_usage req_prefix_usage = {{ 0 } };
 -	struct mlxsw_sp_lpm_tree *lpm_tree;
 +	struct mlxsw_sp_nexthop *nh;
 +	bool offload_change = false;
 +	u32 adj_index;
 +	u16 ecmp_size = 0;
 +	bool old_adj_index_valid;
 +	u32 old_adj_index;
 +	u16 old_ecmp_size;
 +	int i;
  	int err;
  
 -	/* Since the tree is shared between all virtual routers we must
 -	 * make sure it contains all the required prefix lengths. This
 -	 * can be computed by either adding the new prefix length to the
 -	 * existing prefix usage of a bound tree, or by aggregating the
 -	 * prefix lengths across all virtual routers and adding the new
 -	 * one as well.
 -	 */
 -	if (fib->lpm_tree)
 -		mlxsw_sp_prefix_usage_cpy(&req_prefix_usage,
 -					  &fib->lpm_tree->prefix_usage);
 -	else
 -		mlxsw_sp_vrs_prefixes(mlxsw_sp, fib->proto, &req_prefix_usage);
 -	mlxsw_sp_prefix_usage_set(&req_prefix_usage, fib_node->key.prefix_len);
 +	if (!nh_grp->gateway) {
 +		mlxsw_sp_nexthop_fib_entries_update(mlxsw_sp, nh_grp);
 +		return;
 +	}
  
 -	lpm_tree = mlxsw_sp_lpm_tree_get(mlxsw_sp, &req_prefix_usage,
 -					 fib->proto);
 -	if (IS_ERR(lpm_tree))
 -		return PTR_ERR(lpm_tree);
 +	for (i = 0; i < nh_grp->count; i++) {
 +		nh = &nh_grp->nexthops[i];
  
 -	if (fib->lpm_tree && fib->lpm_tree->id == lpm_tree->id)
 -		return 0;
 +		if (nh->should_offload != nh->offloaded) {
 +			offload_change = true;
 +			if (nh->should_offload)
 +				nh->update = 1;
 +		}
 +		if (nh->should_offload)
 +			ecmp_size++;
 +	}
 +	if (!offload_change) {
 +		/* Nothing was added or removed, so no need to reallocate. Just
 +		 * update MAC on existing adjacency indexes.
 +		 */
 +		err = mlxsw_sp_nexthop_group_mac_update(mlxsw_sp, nh_grp,
 +							false);
 +		if (err) {
 +			dev_warn(mlxsw_sp->bus_info->dev, "Failed to update neigh MAC in adjacency table.\n");
 +			goto set_trap;
 +		}
 +		return;
 +	}
 +	if (!ecmp_size)
 +		/* No neigh of this group is connected so we just set
 +		 * the trap and let everthing flow through kernel.
 +		 */
 +		goto set_trap;
  
 -	err = mlxsw_sp_vrs_lpm_tree_replace(mlxsw_sp, fib, lpm_tree);
 -	if (err)
 -		return err;
 +	err = mlxsw_sp_kvdl_alloc(mlxsw_sp, ecmp_size, &adj_index);
 +	if (err) {
 +		/* We ran out of KVD linear space, just set the
 +		 * trap and let everything flow through kernel.
 +		 */
 +		dev_warn(mlxsw_sp->bus_info->dev, "Failed to allocate KVD linear area for nexthop group.\n");
 +		goto set_trap;
 +	}
 +	old_adj_index_valid = nh_grp->adj_index_valid;
 +	old_adj_index = nh_grp->adj_index;
 +	old_ecmp_size = nh_grp->ecmp_size;
 +	nh_grp->adj_index_valid = 1;
 +	nh_grp->adj_index = adj_index;
 +	nh_grp->ecmp_size = ecmp_size;
 +	err = mlxsw_sp_nexthop_group_mac_update(mlxsw_sp, nh_grp, true);
 +	if (err) {
 +		dev_warn(mlxsw_sp->bus_info->dev, "Failed to update neigh MAC in adjacency table.\n");
 +		goto set_trap;
 +	}
  
 -	return 0;
 -}
 +	if (!old_adj_index_valid) {
 +		/* The trap was set for fib entries, so we have to call
 +		 * fib entry update to unset it and use adjacency index.
 +		 */
 +		err = mlxsw_sp_nexthop_fib_entries_update(mlxsw_sp, nh_grp);
 +		if (err) {
 +			dev_warn(mlxsw_sp->bus_info->dev, "Failed to add adjacency index to fib entries.\n");
 +			goto set_trap;
 +		}
 +		return;
 +	}
  
 -static void mlxsw_sp_fib_lpm_tree_unlink(struct mlxsw_sp *mlxsw_sp,
 -					 struct mlxsw_sp_fib *fib)
 -{
 -	struct mlxsw_sp_prefix_usage req_prefix_usage = {{ 0 } };
 -	struct mlxsw_sp_lpm_tree *lpm_tree;
 +	err = mlxsw_sp_adj_index_mass_update(mlxsw_sp, nh_grp,
 +					     old_adj_index, old_ecmp_size);
 +	mlxsw_sp_kvdl_free(mlxsw_sp, old_adj_index);
 +	if (err) {
 +		dev_warn(mlxsw_sp->bus_info->dev, "Failed to mass-update adjacency index for nexthop group.\n");
 +		goto set_trap;
 +	}
  
 -	/* Aggregate prefix lengths across all virtual routers to make
 -	 * sure we only have used prefix lengths in the LPM tree.
 -	 */
 -	mlxsw_sp_vrs_prefixes(mlxsw_sp, fib->proto, &req_prefix_usage);
 -	lpm_tree = mlxsw_sp_lpm_tree_get(mlxsw_sp, &req_prefix_usage,
 -					 fib->proto);
 -	if (IS_ERR(lpm_tree))
 -		goto err_tree_get;
 -	mlxsw_sp_vrs_lpm_tree_replace(mlxsw_sp, fib, lpm_tree);
 +	/* Offload state within the group changed, so update the flags. */
 +	mlxsw_sp_nexthop_fib_entries_refresh(nh_grp);
  
 -err_tree_get:
 -	if (!mlxsw_sp_prefix_usage_none(&fib->prefix_usage))
 -		return;
 -	mlxsw_sp_vr_lpm_tree_unbind(mlxsw_sp, fib);
 -	mlxsw_sp_lpm_tree_put(mlxsw_sp, fib->lpm_tree);
 -	fib->lpm_tree = NULL;
 +	return;
 +
 +set_trap:
 +	old_adj_index_valid = nh_grp->adj_index_valid;
 +	nh_grp->adj_index_valid = 0;
 +	for (i = 0; i < nh_grp->count; i++) {
 +		nh = &nh_grp->nexthops[i];
 +		nh->offloaded = 0;
 +	}
 +	err = mlxsw_sp_nexthop_fib_entries_update(mlxsw_sp, nh_grp);
 +	if (err)
 +		dev_warn(mlxsw_sp->bus_info->dev, "Failed to set traps for fib entries.\n");
 +	if (old_adj_index_valid)
 +		mlxsw_sp_kvdl_free(mlxsw_sp, nh_grp->adj_index);
  }
  
 -static void mlxsw_sp_fib_node_prefix_inc(struct mlxsw_sp_fib_node *fib_node)
 +static void __mlxsw_sp_nexthop_neigh_update(struct mlxsw_sp_nexthop *nh,
 +					    bool removing)
  {
 -	unsigned char prefix_len = fib_node->key.prefix_len;
 -	struct mlxsw_sp_fib *fib = fib_node->fib;
 -
 -	if (fib->prefix_ref_count[prefix_len]++ == 0)
 -		mlxsw_sp_prefix_usage_set(&fib->prefix_usage, prefix_len);
 +	if (!removing && !nh->should_offload)
 +		nh->should_offload = 1;
 +	else if (removing && nh->offloaded)
 +		nh->should_offload = 0;
 +	nh->update = 1;
  }
  
 -static void mlxsw_sp_fib_node_prefix_dec(struct mlxsw_sp_fib_node *fib_node)
 +static void
 +mlxsw_sp_nexthop_neigh_update(struct mlxsw_sp *mlxsw_sp,
 +			      struct mlxsw_sp_neigh_entry *neigh_entry,
 +			      bool removing)
  {
 -	unsigned char prefix_len = fib_node->key.prefix_len;
 -	struct mlxsw_sp_fib *fib = fib_node->fib;
 +	struct mlxsw_sp_nexthop *nh;
  
 -	if (--fib->prefix_ref_count[prefix_len] == 0)
 -		mlxsw_sp_prefix_usage_clear(&fib->prefix_usage, prefix_len);
 +	list_for_each_entry(nh, &neigh_entry->nexthop_list,
 +			    neigh_list_node) {
 +		__mlxsw_sp_nexthop_neigh_update(nh, removing);
 +		mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh->nh_grp);
 +	}
  }
  
 -static int mlxsw_sp_fib_node_init(struct mlxsw_sp *mlxsw_sp,
 -				  struct mlxsw_sp_fib_node *fib_node,
 -				  struct mlxsw_sp_fib *fib)
 +static void mlxsw_sp_nexthop_rif_init(struct mlxsw_sp_nexthop *nh,
 +				      struct mlxsw_sp_rif *r)
  {
 -	int err;
 -
 -	err = mlxsw_sp_fib_node_insert(fib, fib_node);
 -	if (err)
 -		return err;
 -	fib_node->fib = fib;
 -
 -	err = mlxsw_sp_fib_lpm_tree_link(mlxsw_sp, fib, fib_node);
 -	if (err)
 -		goto err_fib_lpm_tree_link;
 -
 -	mlxsw_sp_fib_node_prefix_inc(fib_node);
 -
 -	return 0;
 +	if (nh->r)
 +		return;
  
 -err_fib_lpm_tree_link:
 -	fib_node->fib = NULL;
 -	mlxsw_sp_fib_node_remove(fib, fib_node);
 -	return err;
 +	nh->r = r;
 +	list_add(&nh->rif_list_node, &r->nexthop_list);
  }
  
 -static void mlxsw_sp_fib_node_fini(struct mlxsw_sp *mlxsw_sp,
 -				   struct mlxsw_sp_fib_node *fib_node)
 +static void mlxsw_sp_nexthop_rif_fini(struct mlxsw_sp_nexthop *nh)
  {
 -	struct mlxsw_sp_fib *fib = fib_node->fib;
 +	if (!nh->r)
 +		return;
  
 -	mlxsw_sp_fib_node_prefix_dec(fib_node);
 -	mlxsw_sp_fib_lpm_tree_unlink(mlxsw_sp, fib);
 -	fib_node->fib = NULL;
 -	mlxsw_sp_fib_node_remove(fib, fib_node);
 +	list_del(&nh->rif_list_node);
 +	nh->r = NULL;
  }
  
 -static struct mlxsw_sp_fib_node *
 -mlxsw_sp_fib_node_get(struct mlxsw_sp *mlxsw_sp, u32 tb_id, const void *addr,
 -		      size_t addr_len, unsigned char prefix_len,
 -		      enum mlxsw_sp_l3proto proto)
 +static int mlxsw_sp_nexthop_neigh_init(struct mlxsw_sp *mlxsw_sp,
 +				       struct mlxsw_sp_nexthop *nh)
  {
 -	struct mlxsw_sp_fib_node *fib_node;
 -	struct mlxsw_sp_fib *fib;
 -	struct mlxsw_sp_vr *vr;
 +	struct mlxsw_sp_neigh_entry *neigh_entry;
 +	struct fib_nh *fib_nh = nh->key.fib_nh;
 +	struct neighbour *n;
 +	u8 nud_state, dead;
  	int err;
  
 -	vr = mlxsw_sp_vr_get(mlxsw_sp, tb_id);
 -	if (IS_ERR(vr))
 -		return ERR_CAST(vr);
 -	fib = mlxsw_sp_vr_fib(vr, proto);
 -
 -	fib_node = mlxsw_sp_fib_node_lookup(fib, addr, addr_len, prefix_len);
 -	if (fib_node)
 -		return fib_node;
 +	if (!nh->nh_grp->gateway || nh->neigh_entry)
 +		return 0;
  
 -	fib_node = mlxsw_sp_fib_node_create(fib, addr, addr_len, prefix_len);
 -	if (!fib_node) {
 -		err = -ENOMEM;
 -		goto err_fib_node_create;
 +	/* Take a reference of neigh here ensuring that neigh would
 +	 * not be destructed before the nexthop entry is finished.
 +	 * The reference is taken either in neigh_lookup() or
 +	 * in neigh_create() in case n is not found.
 +	 */
 +	n = neigh_lookup(&arp_tbl, &fib_nh->nh_gw, fib_nh->nh_dev);
 +	if (!n) {
 +		n = neigh_create(&arp_tbl, &fib_nh->nh_gw, fib_nh->nh_dev);
 +		if (IS_ERR(n))
 +			return PTR_ERR(n);
 +		neigh_event_send(n, NULL);
 +	}
 +	neigh_entry = mlxsw_sp_neigh_entry_lookup(mlxsw_sp, n);
 +	if (!neigh_entry) {
 +		neigh_entry = mlxsw_sp_neigh_entry_create(mlxsw_sp, n);
 +		if (IS_ERR(neigh_entry)) {
 +			err = -EINVAL;
 +			goto err_neigh_entry_create;
 +		}
  	}
  
 -	err = mlxsw_sp_fib_node_init(mlxsw_sp, fib_node, fib);
 -	if (err)
 -		goto err_fib_node_init;
 -
 -	return fib_node;
 +	/* If that is the first nexthop connected to that neigh, add to
 +	 * nexthop_neighs_list
 +	 */
 +	if (list_empty(&neigh_entry->nexthop_list))
 +		list_add_tail(&neigh_entry->nexthop_neighs_list_node,
 +			      &mlxsw_sp->router.nexthop_neighs_list);
  
 -err_fib_node_init:
 -	mlxsw_sp_fib_node_destroy(fib_node);
 -err_fib_node_create:
 -	mlxsw_sp_vr_put(vr);
 -	return ERR_PTR(err);
 -}
 +	nh->neigh_entry = neigh_entry;
 +	list_add_tail(&nh->neigh_list_node, &neigh_entry->nexthop_list);
 +	read_lock_bh(&n->lock);
 +	nud_state = n->nud_state;
 +	dead = n->dead;
 +	read_unlock_bh(&n->lock);
 +	__mlxsw_sp_nexthop_neigh_update(nh, !(nud_state & NUD_VALID && !dead));
  
 -static void mlxsw_sp_fib_node_put(struct mlxsw_sp *mlxsw_sp,
 -				  struct mlxsw_sp_fib_node *fib_node)
 -{
 -	struct mlxsw_sp_vr *vr = fib_node->fib->vr;
 +	return 0;
  
 -	if (!list_empty(&fib_node->entry_list))
 -		return;
 -	mlxsw_sp_fib_node_fini(mlxsw_sp, fib_node);
 -	mlxsw_sp_fib_node_destroy(fib_node);
 -	mlxsw_sp_vr_put(vr);
 +err_neigh_entry_create:
 +	neigh_release(n);
 +	return err;
  }
  
 -static struct mlxsw_sp_fib4_entry *
 -mlxsw_sp_fib4_node_entry_find(const struct mlxsw_sp_fib_node *fib_node,
 -			      const struct mlxsw_sp_fib4_entry *new4_entry)
 +static void mlxsw_sp_nexthop_neigh_fini(struct mlxsw_sp *mlxsw_sp,
 +					struct mlxsw_sp_nexthop *nh)
  {
 -	struct mlxsw_sp_fib4_entry *fib4_entry;
 -
 -	list_for_each_entry(fib4_entry, &fib_node->entry_list, common.list) {
 -		if (fib4_entry->tb_id > new4_entry->tb_id)
 -			continue;
 -		if (fib4_entry->tb_id != new4_entry->tb_id)
 -			break;
 -		if (fib4_entry->tos > new4_entry->tos)
 -			continue;
 -		if (fib4_entry->prio >= new4_entry->prio ||
 -		    fib4_entry->tos < new4_entry->tos)
 -			return fib4_entry;
 -	}
 +	struct mlxsw_sp_neigh_entry *neigh_entry = nh->neigh_entry;
 +	struct neighbour *n;
  
 -	return NULL;
 -}
 +	if (!neigh_entry)
 +		return;
 +	n = neigh_entry->key.n;
  
 -static int
 -mlxsw_sp_fib4_node_list_append(struct mlxsw_sp_fib4_entry *fib4_entry,
 -			       struct mlxsw_sp_fib4_entry *new4_entry)
 -{
 -	struct mlxsw_sp_fib_node *fib_node;
 +	__mlxsw_sp_nexthop_neigh_update(nh, true);
 +	list_del(&nh->neigh_list_node);
 +	nh->neigh_entry = NULL;
  
 -	if (WARN_ON(!fib4_entry))
 -		return -EINVAL;
 +	/* If that is the last nexthop connected to that neigh, remove from
 +	 * nexthop_neighs_list
 +	 */
 +	if (list_empty(&neigh_entry->nexthop_list))
 +		list_del(&neigh_entry->nexthop_neighs_list_node);
  
 -	fib_node = fib4_entry->common.fib_node;
 -	list_for_each_entry_from(fib4_entry, &fib_node->entry_list,
 -				 common.list) {
 -		if (fib4_entry->tb_id != new4_entry->tb_id ||
 -		    fib4_entry->tos != new4_entry->tos ||
 -		    fib4_entry->prio != new4_entry->prio)
 -			break;
 -	}
 +	if (!neigh_entry->connected && list_empty(&neigh_entry->nexthop_list))
 +		mlxsw_sp_neigh_entry_destroy(mlxsw_sp, neigh_entry);
  
 -	list_add_tail(&new4_entry->common.list, &fib4_entry->common.list);
 -	return 0;
 +	neigh_release(n);
  }
  
 -static int
 -mlxsw_sp_fib4_node_list_insert(struct mlxsw_sp_fib4_entry *new4_entry,
 -			       bool replace, bool append)
 +static int mlxsw_sp_nexthop_init(struct mlxsw_sp *mlxsw_sp,
 +				 struct mlxsw_sp_nexthop_group *nh_grp,
 +				 struct mlxsw_sp_nexthop *nh,
 +				 struct fib_nh *fib_nh)
  {
 -	struct mlxsw_sp_fib_node *fib_node = new4_entry->common.fib_node;
 -	struct mlxsw_sp_fib4_entry *fib4_entry;
 +	struct net_device *dev = fib_nh->nh_dev;
 +	struct in_device *in_dev;
 +	struct mlxsw_sp_rif *r;
 +	int err;
  
 -	fib4_entry = mlxsw_sp_fib4_node_entry_find(fib_node, new4_entry);
 +	nh->nh_grp = nh_grp;
 +	nh->key.fib_nh = fib_nh;
 +	err = mlxsw_sp_nexthop_insert(mlxsw_sp, nh);
 +	if (err)
 +		return err;
  
 -	if (append)
 -		return mlxsw_sp_fib4_node_list_append(fib4_entry, new4_entry);
 -	if (replace && WARN_ON(!fib4_entry))
 -		return -EINVAL;
++	list_add_tail(&nh->router_list_node, &mlxsw_sp->router->nexthop_list);
+ 
 -	/* Insert new entry before replaced one, so that we can later
 -	 * remove the second.
 -	 */
 -	if (fib4_entry) {
 -		list_add_tail(&new4_entry->common.list,
 -			      &fib4_entry->common.list);
 -	} else {
 -		struct mlxsw_sp_fib4_entry *last;
 +	if (!dev)
 +		return 0;
  
 -		list_for_each_entry(last, &fib_node->entry_list, common.list) {
 -			if (new4_entry->tb_id > last->tb_id)
 -				break;
 -			fib4_entry = last;
 -		}
 +	in_dev = __in_dev_get_rtnl(dev);
 +#if 0 /* RHEL does not support LINKDOWN yet - the condition is always false */
 +	if (in_dev && IN_DEV_IGNORE_ROUTES_WITH_LINKDOWN(in_dev) &&
 +	    fib_nh->nh_flags & RTNH_F_LINKDOWN)
 +		return 0;
 +#endif
  
 -		if (fib4_entry)
 -			list_add(&new4_entry->common.list,
 -				 &fib4_entry->common.list);
 -		else
 -			list_add(&new4_entry->common.list,
 -				 &fib_node->entry_list);
 -	}
 +	r = mlxsw_sp_rif_find_by_dev(mlxsw_sp, dev);
 +	if (!r)
 +		return 0;
 +	mlxsw_sp_nexthop_rif_init(nh, r);
 +
 +	err = mlxsw_sp_nexthop_neigh_init(mlxsw_sp, nh);
 +	if (err)
 +		goto err_nexthop_neigh_init;
  
  	return 0;
 +
 +err_nexthop_neigh_init:
 +	mlxsw_sp_nexthop_rif_fini(nh);
 +	mlxsw_sp_nexthop_remove(mlxsw_sp, nh);
 +	return err;
  }
  
 -static void
 -mlxsw_sp_fib4_node_list_remove(struct mlxsw_sp_fib4_entry *fib4_entry)
 +static void mlxsw_sp_nexthop_fini(struct mlxsw_sp *mlxsw_sp,
 +				  struct mlxsw_sp_nexthop *nh)
  {
 -	list_del(&fib4_entry->common.list);
++<<<<<<< HEAD
 +	mlxsw_sp_nexthop_neigh_fini(mlxsw_sp, nh);
 +	mlxsw_sp_nexthop_rif_fini(nh);
++=======
++	mlxsw_sp_nexthop4_type_fini(mlxsw_sp, nh);
++	list_del(&nh->router_list_node);
++>>>>>>> dbe4598c1e92 (mlxsw: spectrum_router: Keep nexthops in a linked list)
 +	mlxsw_sp_nexthop_remove(mlxsw_sp, nh);
  }
  
 -static int mlxsw_sp_fib_node_entry_add(struct mlxsw_sp *mlxsw_sp,
 -				       struct mlxsw_sp_fib_entry *fib_entry)
 +static void mlxsw_sp_nexthop_event(struct mlxsw_sp *mlxsw_sp,
 +				   unsigned long event, struct fib_nh *fib_nh)
  {
 -	struct mlxsw_sp_fib_node *fib_node = fib_entry->fib_node;
 +	struct mlxsw_sp_nexthop_key key;
 +	struct mlxsw_sp_nexthop *nh;
 +	struct mlxsw_sp_rif *r;
  
 -	if (!mlxsw_sp_fib_node_entry_is_first(fib_node, fib_entry))
 -		return 0;
 +	if (mlxsw_sp->router.aborted)
 +		return;
  
 -	/* To prevent packet loss, overwrite the previously offloaded
 -	 * entry.
 -	 */
 -	if (!list_is_singular(&fib_node->entry_list)) {
 -		enum mlxsw_reg_ralue_op op = MLXSW_REG_RALUE_OP_WRITE_DELETE;
 -		struct mlxsw_sp_fib_entry *n = list_next_entry(fib_entry, list);
 +	key.fib_nh = fib_nh;
 +	nh = mlxsw_sp_nexthop_lookup(mlxsw_sp, key);
 +	if (WARN_ON_ONCE(!nh))
 +		return;
  
 -		mlxsw_sp_fib_entry_offload_refresh(n, op, 0);
 +	r = mlxsw_sp_rif_find_by_dev(mlxsw_sp, fib_nh->nh_dev);
 +	if (!r)
 +		return;
 +
 +	switch (event) {
 +	case FIB_EVENT_NH_ADD:
 +		mlxsw_sp_nexthop_rif_init(nh, r);
 +		mlxsw_sp_nexthop_neigh_init(mlxsw_sp, nh);
 +		break;
 +	case FIB_EVENT_NH_DEL:
 +		mlxsw_sp_nexthop_neigh_fini(mlxsw_sp, nh);
 +		mlxsw_sp_nexthop_rif_fini(nh);
 +		break;
  	}
  
 -	return mlxsw_sp_fib_entry_update(mlxsw_sp, fib_entry);
 +	mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh->nh_grp);
  }
  
 -static void mlxsw_sp_fib_node_entry_del(struct mlxsw_sp *mlxsw_sp,
 -					struct mlxsw_sp_fib_entry *fib_entry)
 +static void mlxsw_sp_nexthop_rif_gone_sync(struct mlxsw_sp *mlxsw_sp,
 +					   struct mlxsw_sp_rif *r)
  {
 -	struct mlxsw_sp_fib_node *fib_node = fib_entry->fib_node;
 +	struct mlxsw_sp_nexthop *nh, *tmp;
  
 -	if (!mlxsw_sp_fib_node_entry_is_first(fib_node, fib_entry))
 -		return;
 +	list_for_each_entry_safe(nh, tmp, &r->nexthop_list, rif_list_node) {
 +		mlxsw_sp_nexthop_neigh_fini(mlxsw_sp, nh);
 +		mlxsw_sp_nexthop_rif_fini(nh);
 +		mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh->nh_grp);
 +	}
 +}
  
 -	/* Promote the next entry by overwriting the deleted entry */
 -	if (!list_is_singular(&fib_node->entry_list)) {
 -		struct mlxsw_sp_fib_entry *n = list_next_entry(fib_entry, list);
 -		enum mlxsw_reg_ralue_op op = MLXSW_REG_RALUE_OP_WRITE_DELETE;
 +static struct mlxsw_sp_nexthop_group *
 +mlxsw_sp_nexthop_group_create(struct mlxsw_sp *mlxsw_sp, struct fib_info *fi)
 +{
 +	struct mlxsw_sp_nexthop_group *nh_grp;
 +	struct mlxsw_sp_nexthop *nh;
 +	struct fib_nh *fib_nh;
 +	size_t alloc_size;
 +	int i;
 +	int err;
  
 -		mlxsw_sp_fib_entry_update(mlxsw_sp, n);
 -		mlxsw_sp_fib_entry_offload_refresh(fib_entry, op, 0);
 -		return;
 +	alloc_size = sizeof(*nh_grp) +
 +		     fi->fib_nhs * sizeof(struct mlxsw_sp_nexthop);
 +	nh_grp = kzalloc(alloc_size, GFP_KERNEL);
 +	if (!nh_grp)
 +		return ERR_PTR(-ENOMEM);
 +	INIT_LIST_HEAD(&nh_grp->fib_list);
 +	nh_grp->gateway = fi->fib_nh->nh_scope == RT_SCOPE_LINK;
 +	nh_grp->count = fi->fib_nhs;
 +	nh_grp->key.fi = fi;
 +	fib_info_hold(fi);
 +	for (i = 0; i < nh_grp->count; i++) {
 +		nh = &nh_grp->nexthops[i];
 +		fib_nh = &fi->fib_nh[i];
 +		err = mlxsw_sp_nexthop_init(mlxsw_sp, nh_grp, nh, fib_nh);
 +		if (err)
 +			goto err_nexthop_init;
  	}
 +	err = mlxsw_sp_nexthop_group_insert(mlxsw_sp, nh_grp);
 +	if (err)
 +		goto err_nexthop_group_insert;
 +	mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh_grp);
 +	return nh_grp;
  
 -	mlxsw_sp_fib_entry_del(mlxsw_sp, fib_entry);
 +err_nexthop_group_insert:
 +err_nexthop_init:
 +	for (i--; i >= 0; i--) {
 +		nh = &nh_grp->nexthops[i];
 +		mlxsw_sp_nexthop_fini(mlxsw_sp, nh);
 +	}
 +	fib_info_put(nh_grp->key.fi);
 +	kfree(nh_grp);
 +	return ERR_PTR(err);
  }
  
 -static int mlxsw_sp_fib4_node_entry_link(struct mlxsw_sp *mlxsw_sp,
 -					 struct mlxsw_sp_fib4_entry *fib4_entry,
 -					 bool replace, bool append)
 +static void
 +mlxsw_sp_nexthop_group_destroy(struct mlxsw_sp *mlxsw_sp,
 +			       struct mlxsw_sp_nexthop_group *nh_grp)
  {
 -	int err;
 +	struct mlxsw_sp_nexthop *nh;
 +	int i;
  
 -	err = mlxsw_sp_fib4_node_list_insert(fib4_entry, replace, append);
 -	if (err)
 -		return err;
 +	mlxsw_sp_nexthop_group_remove(mlxsw_sp, nh_grp);
 +	for (i = 0; i < nh_grp->count; i++) {
 +		nh = &nh_grp->nexthops[i];
 +		mlxsw_sp_nexthop_fini(mlxsw_sp, nh);
 +	}
 +	mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh_grp);
 +	WARN_ON_ONCE(nh_grp->adj_index_valid);
 +	fib_info_put(nh_grp->key.fi);
 +	kfree(nh_grp);
 +}
  
 -	err = mlxsw_sp_fib_node_entry_add(mlxsw_sp, &fib4_entry->common);
 -	if (err)
 -		goto err_fib_node_entry_add;
 +static int mlxsw_sp_nexthop_group_get(struct mlxsw_sp *mlxsw_sp,
 +				      struct mlxsw_sp_fib_entry *fib_entry,
 +				      struct fib_info *fi)
 +{
 +	struct mlxsw_sp_nexthop_group_key key;
 +	struct mlxsw_sp_nexthop_group *nh_grp;
  
 +	key.fi = fi;
 +	nh_grp = mlxsw_sp_nexthop_group_lookup(mlxsw_sp, key);
 +	if (!nh_grp) {
 +		nh_grp = mlxsw_sp_nexthop_group_create(mlxsw_sp, fi);
 +		if (IS_ERR(nh_grp))
 +			return PTR_ERR(nh_grp);
 +	}
 +	list_add_tail(&fib_entry->nexthop_group_node, &nh_grp->fib_list);
 +	fib_entry->nh_group = nh_grp;
  	return 0;
 +}
  
 -err_fib_node_entry_add:
 -	mlxsw_sp_fib4_node_list_remove(fib4_entry);
 -	return err;
 +static void mlxsw_sp_nexthop_group_put(struct mlxsw_sp *mlxsw_sp,
 +				       struct mlxsw_sp_fib_entry *fib_entry)
 +{
 +	struct mlxsw_sp_nexthop_group *nh_grp = fib_entry->nh_group;
 +
 +	list_del(&fib_entry->nexthop_group_node);
 +	if (!list_empty(&nh_grp->fib_list))
 +		return;
 +	mlxsw_sp_nexthop_group_destroy(mlxsw_sp, nh_grp);
  }
  
 -static void
 -mlxsw_sp_fib4_node_entry_unlink(struct mlxsw_sp *mlxsw_sp,
 -				struct mlxsw_sp_fib4_entry *fib4_entry)
 +static bool
 +mlxsw_sp_fib_entry_should_offload(const struct mlxsw_sp_fib_entry *fib_entry)
  {
 -	mlxsw_sp_fib_node_entry_del(mlxsw_sp, &fib4_entry->common);
 -	mlxsw_sp_fib4_node_list_remove(fib4_entry);
 +	struct mlxsw_sp_nexthop_group *nh_group = fib_entry->nh_group;
 +
 +	if (fib_entry->params.tos)
 +		return false;
  
 -	if (fib4_entry->common.type == MLXSW_SP_FIB_ENTRY_TYPE_IPIP_DECAP)
 -		mlxsw_sp_fib_entry_decap_fini(mlxsw_sp, &fib4_entry->common);
 +	switch (fib_entry->type) {
 +	case MLXSW_SP_FIB_ENTRY_TYPE_REMOTE:
 +		return !!nh_group->adj_index_valid;
 +	case MLXSW_SP_FIB_ENTRY_TYPE_LOCAL:
 +		return !!nh_group->nh_rif;
 +	default:
 +		return false;
 +	}
  }
  
 -static void mlxsw_sp_fib4_entry_replace(struct mlxsw_sp *mlxsw_sp,
 -					struct mlxsw_sp_fib4_entry *fib4_entry,
 -					bool replace)
 +static void
 +mlxsw_sp_fib4_entry_offload_set(struct mlxsw_sp_fib_entry *fib_entry)
  {
 -	struct mlxsw_sp_fib_node *fib_node = fib4_entry->common.fib_node;
 -	struct mlxsw_sp_fib4_entry *replaced;
 +	struct mlxsw_sp_nexthop_group *nh_grp = fib_entry->nh_group;
 +	int i;
  
 -	if (!replace)
 +	if (fib_entry->type == MLXSW_SP_FIB_ENTRY_TYPE_LOCAL) {
 +		nh_grp->nexthops->key.fib_nh->nh_flags |= RTNH_F_OFFLOAD;
  		return;
 +	}
  
 -	/* We inserted the new entry before replaced one */
 -	replaced = list_next_entry(fib4_entry, common.list);
 +	for (i = 0; i < nh_grp->count; i++) {
 +		struct mlxsw_sp_nexthop *nh = &nh_grp->nexthops[i];
  
 -	mlxsw_sp_fib4_node_entry_unlink(mlxsw_sp, replaced);
 -	mlxsw_sp_fib4_entry_destroy(mlxsw_sp, replaced);
 -	mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
 +		if (nh->offloaded)
 +			nh->key.fib_nh->nh_flags |= RTNH_F_OFFLOAD;
 +		else
 +			nh->key.fib_nh->nh_flags &= ~RTNH_F_OFFLOAD;
 +	}
  }
  
 -static int
 -mlxsw_sp_router_fib4_add(struct mlxsw_sp *mlxsw_sp,
 -			 const struct fib_entry_notifier_info *fen_info,
 -			 bool replace, bool append)
 +static void
 +mlxsw_sp_fib4_entry_offload_unset(struct mlxsw_sp_fib_entry *fib_entry)
  {
 -	struct mlxsw_sp_fib4_entry *fib4_entry;
 -	struct mlxsw_sp_fib_node *fib_node;
 -	int err;
 +	struct mlxsw_sp_nexthop_group *nh_grp = fib_entry->nh_group;
 +	int i;
  
 -	if (mlxsw_sp->router->aborted)
 -		return 0;
 +	for (i = 0; i < nh_grp->count; i++) {
 +		struct mlxsw_sp_nexthop *nh = &nh_grp->nexthops[i];
  
 -	fib_node = mlxsw_sp_fib_node_get(mlxsw_sp, fen_info->tb_id,
 -					 &fen_info->dst, sizeof(fen_info->dst),
 -					 fen_info->dst_len,
 -					 MLXSW_SP_L3_PROTO_IPV4);
 -	if (IS_ERR(fib_node)) {
 -		dev_warn(mlxsw_sp->bus_info->dev, "Failed to get FIB node\n");
 -		return PTR_ERR(fib_node);
 +		nh->key.fib_nh->nh_flags &= ~RTNH_F_OFFLOAD;
  	}
 +}
  
 -	fib4_entry = mlxsw_sp_fib4_entry_create(mlxsw_sp, fib_node, fen_info);
 -	if (IS_ERR(fib4_entry)) {
 -		dev_warn(mlxsw_sp->bus_info->dev, "Failed to create FIB entry\n");
 -		err = PTR_ERR(fib4_entry);
 -		goto err_fib4_entry_create;
 -	}
 +static void mlxsw_sp_fib_entry_offload_set(struct mlxsw_sp_fib_entry *fib_entry)
 +{
 +	fib_entry->offloaded = true;
  
 -	err = mlxsw_sp_fib4_node_entry_link(mlxsw_sp, fib4_entry, replace,
 -					    append);
 -	if (err) {
 -		dev_warn(mlxsw_sp->bus_info->dev, "Failed to link FIB entry to node\n");
 -		goto err_fib4_node_entry_link;
 +	switch (fib_entry->fib_node->fib->proto) {
 +	case MLXSW_SP_L3_PROTO_IPV4:
 +		mlxsw_sp_fib4_entry_offload_set(fib_entry);
 +		break;
 +	case MLXSW_SP_L3_PROTO_IPV6:
 +		WARN_ON_ONCE(1);
  	}
 +}
  
 -	mlxsw_sp_fib4_entry_replace(mlxsw_sp, fib4_entry, replace);
 -
 -	return 0;
 +static void
 +mlxsw_sp_fib_entry_offload_unset(struct mlxsw_sp_fib_entry *fib_entry)
 +{
 +	switch (fib_entry->fib_node->fib->proto) {
 +	case MLXSW_SP_L3_PROTO_IPV4:
 +		mlxsw_sp_fib4_entry_offload_unset(fib_entry);
 +		break;
 +	case MLXSW_SP_L3_PROTO_IPV6:
 +		WARN_ON_ONCE(1);
 +	}
  
 -err_fib4_node_entry_link:
 -	mlxsw_sp_fib4_entry_destroy(mlxsw_sp, fib4_entry);
 -err_fib4_entry_create:
 -	mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
 -	return err;
 +	fib_entry->offloaded = false;
  }
  
 -static void mlxsw_sp_router_fib4_del(struct mlxsw_sp *mlxsw_sp,
 -				     struct fib_entry_notifier_info *fen_info)
 +static void
 +mlxsw_sp_fib_entry_offload_refresh(struct mlxsw_sp_fib_entry *fib_entry,
 +				   enum mlxsw_reg_ralue_op op, int err)
  {
 -	struct mlxsw_sp_fib4_entry *fib4_entry;
 -	struct mlxsw_sp_fib_node *fib_node;
 -
 -	if (mlxsw_sp->router->aborted)
 +	switch (op) {
 +	case MLXSW_REG_RALUE_OP_WRITE_DELETE:
 +		if (!fib_entry->offloaded)
 +			return;
 +		return mlxsw_sp_fib_entry_offload_unset(fib_entry);
 +	case MLXSW_REG_RALUE_OP_WRITE_WRITE:
 +		if (err)
 +			return;
 +		if (mlxsw_sp_fib_entry_should_offload(fib_entry) &&
 +		    !fib_entry->offloaded)
 +			mlxsw_sp_fib_entry_offload_set(fib_entry);
 +		else if (!mlxsw_sp_fib_entry_should_offload(fib_entry) &&
 +			 fib_entry->offloaded)
 +			mlxsw_sp_fib_entry_offload_unset(fib_entry);
  		return;
 -
 -	fib4_entry = mlxsw_sp_fib4_entry_lookup(mlxsw_sp, fen_info);
 -	if (WARN_ON(!fib4_entry))
 +	default:
  		return;
 -	fib_node = fib4_entry->common.fib_node;
 -
 -	mlxsw_sp_fib4_node_entry_unlink(mlxsw_sp, fib4_entry);
 -	mlxsw_sp_fib4_entry_destroy(mlxsw_sp, fib4_entry);
 -	mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
 +	}
  }
  
 -static bool mlxsw_sp_fib6_rt_should_ignore(const struct rt6_info *rt)
 +static int mlxsw_sp_fib_entry_op4_remote(struct mlxsw_sp *mlxsw_sp,
 +					 struct mlxsw_sp_fib_entry *fib_entry,
 +					 enum mlxsw_reg_ralue_op op)
  {
 -	/* Packets with link-local destination IP arriving to the router
 -	 * are trapped to the CPU, so no need to program specific routes
 -	 * for them.
 -	 */
 -	if (ipv6_addr_type(&rt->rt6i_dst.addr) & IPV6_ADDR_LINKLOCAL)
 -		return true;
 +	char ralue_pl[MLXSW_REG_RALUE_LEN];
 +	struct mlxsw_sp_fib *fib = fib_entry->fib_node->fib;
 +	u32 *p_dip = (u32 *) fib_entry->fib_node->key.addr;
 +	enum mlxsw_reg_ralue_trap_action trap_action;
 +	u16 trap_id = 0;
 +	u32 adjacency_index = 0;
 +	u16 ecmp_size = 0;
  
 -	/* Multicast routes aren't supported, so ignore them. Neighbour
 -	 * Discovery packets are specifically trapped.
 +	/* In case the nexthop group adjacency index is valid, use it
 +	 * with provided ECMP size. Otherwise, setup trap and pass
 +	 * traffic to kernel.
  	 */
 -	if (ipv6_addr_type(&rt->rt6i_dst.addr) & IPV6_ADDR_MULTICAST)
 -		return true;
 -
 -	/* Cloned routes are irrelevant in the forwarding path. */
 -	if (rt->rt6i_flags & RTF_CACHE)
 -		return true;
 +	if (mlxsw_sp_fib_entry_should_offload(fib_entry)) {
 +		trap_action = MLXSW_REG_RALUE_TRAP_ACTION_NOP;
 +		adjacency_index = fib_entry->nh_group->adj_index;
 +		ecmp_size = fib_entry->nh_group->ecmp_size;
 +	} else {
 +		trap_action = MLXSW_REG_RALUE_TRAP_ACTION_TRAP;
 +		trap_id = MLXSW_TRAP_ID_RTR_INGRESS0;
 +	}
  
 -	return false;
 +	mlxsw_reg_ralue_pack4(ralue_pl,
 +			      (enum mlxsw_reg_ralxx_protocol) fib->proto, op,
 +			      fib->vr->id, fib_entry->fib_node->key.prefix_len,
 +			      *p_dip);
 +	mlxsw_reg_ralue_act_remote_pack(ralue_pl, trap_action, trap_id,
 +					adjacency_index, ecmp_size);
 +	return mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ralue), ralue_pl);
  }
  
 -static struct mlxsw_sp_rt6 *mlxsw_sp_rt6_create(struct rt6_info *rt)
 +static int mlxsw_sp_fib_entry_op4_local(struct mlxsw_sp *mlxsw_sp,
 +					struct mlxsw_sp_fib_entry *fib_entry,
 +					enum mlxsw_reg_ralue_op op)
  {
 -	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
 -
 -	mlxsw_sp_rt6 = kzalloc(sizeof(*mlxsw_sp_rt6), GFP_KERNEL);
 -	if (!mlxsw_sp_rt6)
 -		return ERR_PTR(-ENOMEM);
 -
 -	/* In case of route replace, replaced route is deleted with
 -	 * no notification. Take reference to prevent accessing freed
 -	 * memory.
 -	 */
 -	mlxsw_sp_rt6->rt = rt;
 -	rt6_hold(rt);
 +	struct mlxsw_sp_rif *r = fib_entry->nh_group->nh_rif;
 +	struct mlxsw_sp_fib *fib = fib_entry->fib_node->fib;
 +	enum mlxsw_reg_ralue_trap_action trap_action;
 +	char ralue_pl[MLXSW_REG_RALUE_LEN];
 +	u32 *p_dip = (u32 *) fib_entry->fib_node->key.addr;
 +	u16 trap_id = 0;
 +	u16 rif = 0;
  
 -	return mlxsw_sp_rt6;
 -}
 +	if (mlxsw_sp_fib_entry_should_offload(fib_entry)) {
 +		trap_action = MLXSW_REG_RALUE_TRAP_ACTION_NOP;
 +		rif = r->rif;
 +	} else {
 +		trap_action = MLXSW_REG_RALUE_TRAP_ACTION_TRAP;
 +		trap_id = MLXSW_TRAP_ID_RTR_INGRESS0;
 +	}
  
 -#if IS_ENABLED(CONFIG_IPV6)
 -static void mlxsw_sp_rt6_release(struct rt6_info *rt)
 -{
 -	rt6_release(rt);
 -}
 -#else
 -static void mlxsw_sp_rt6_release(struct rt6_info *rt)
 -{
 +	mlxsw_reg_ralue_pack4(ralue_pl,
 +			      (enum mlxsw_reg_ralxx_protocol) fib->proto, op,
 +			      fib->vr->id, fib_entry->fib_node->key.prefix_len,
 +			      *p_dip);
 +	mlxsw_reg_ralue_act_local_pack(ralue_pl, trap_action, trap_id, rif);
 +	return mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ralue), ralue_pl);
  }
 -#endif
  
 -static void mlxsw_sp_rt6_destroy(struct mlxsw_sp_rt6 *mlxsw_sp_rt6)
 +static int mlxsw_sp_fib_entry_op4_trap(struct mlxsw_sp *mlxsw_sp,
 +				       struct mlxsw_sp_fib_entry *fib_entry,
 +				       enum mlxsw_reg_ralue_op op)
  {
 -	mlxsw_sp_rt6_release(mlxsw_sp_rt6->rt);
 -	kfree(mlxsw_sp_rt6);
 -}
 +	struct mlxsw_sp_fib *fib = fib_entry->fib_node->fib;
 +	char ralue_pl[MLXSW_REG_RALUE_LEN];
 +	u32 *p_dip = (u32 *) fib_entry->fib_node->key.addr;
  
 -static bool mlxsw_sp_fib6_rt_can_mp(const struct rt6_info *rt)
 -{
 -	/* RTF_CACHE routes are ignored */
 -	return (rt->rt6i_flags & (RTF_GATEWAY | RTF_ADDRCONF)) == RTF_GATEWAY;
 +	mlxsw_reg_ralue_pack4(ralue_pl,
 +			      (enum mlxsw_reg_ralxx_protocol) fib->proto, op,
 +			      fib->vr->id, fib_entry->fib_node->key.prefix_len,
 +			      *p_dip);
 +	mlxsw_reg_ralue_act_ip2me_pack(ralue_pl);
 +	return mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ralue), ralue_pl);
  }
  
 -static struct rt6_info *
 -mlxsw_sp_fib6_entry_rt(const struct mlxsw_sp_fib6_entry *fib6_entry)
 +static int mlxsw_sp_fib_entry_op4(struct mlxsw_sp *mlxsw_sp,
 +				  struct mlxsw_sp_fib_entry *fib_entry,
 +				  enum mlxsw_reg_ralue_op op)
  {
 -	return list_first_entry(&fib6_entry->rt6_list, struct mlxsw_sp_rt6,
 -				list)->rt;
 +	switch (fib_entry->type) {
 +	case MLXSW_SP_FIB_ENTRY_TYPE_REMOTE:
 +		return mlxsw_sp_fib_entry_op4_remote(mlxsw_sp, fib_entry, op);
 +	case MLXSW_SP_FIB_ENTRY_TYPE_LOCAL:
 +		return mlxsw_sp_fib_entry_op4_local(mlxsw_sp, fib_entry, op);
 +	case MLXSW_SP_FIB_ENTRY_TYPE_TRAP:
 +		return mlxsw_sp_fib_entry_op4_trap(mlxsw_sp, fib_entry, op);
 +	}
 +	return -EINVAL;
  }
  
 -static struct mlxsw_sp_fib6_entry *
 -mlxsw_sp_fib6_node_mp_entry_find(const struct mlxsw_sp_fib_node *fib_node,
 -				 const struct rt6_info *nrt, bool replace)
 +static int mlxsw_sp_fib_entry_op(struct mlxsw_sp *mlxsw_sp,
 +				 struct mlxsw_sp_fib_entry *fib_entry,
 +				 enum mlxsw_reg_ralue_op op)
  {
 -	struct mlxsw_sp_fib6_entry *fib6_entry;
 -
 -	if (!mlxsw_sp_fib6_rt_can_mp(nrt) || replace)
 -		return NULL;
 -
 -	list_for_each_entry(fib6_entry, &fib_node->entry_list, common.list) {
 -		struct rt6_info *rt = mlxsw_sp_fib6_entry_rt(fib6_entry);
 +	int err = -EINVAL;
  
 -		/* RT6_TABLE_LOCAL and RT6_TABLE_MAIN share the same
 -		 * virtual router.
 -		 */
 -		if (rt->rt6i_table->tb6_id > nrt->rt6i_table->tb6_id)
 -			continue;
 -		if (rt->rt6i_table->tb6_id != nrt->rt6i_table->tb6_id)
 -			break;
 -		if (rt->rt6i_metric < nrt->rt6i_metric)
 -			continue;
 -		if (rt->rt6i_metric == nrt->rt6i_metric &&
 -		    mlxsw_sp_fib6_rt_can_mp(rt))
 -			return fib6_entry;
 -		if (rt->rt6i_metric > nrt->rt6i_metric)
 -			break;
 +	switch (fib_entry->fib_node->fib->proto) {
 +	case MLXSW_SP_L3_PROTO_IPV4:
 +		err = mlxsw_sp_fib_entry_op4(mlxsw_sp, fib_entry, op);
 +		break;
 +	case MLXSW_SP_L3_PROTO_IPV6:
 +		return err;
  	}
 -
 -	return NULL;
 +	mlxsw_sp_fib_entry_offload_refresh(fib_entry, op, err);
 +	return err;
  }
  
 -static struct mlxsw_sp_rt6 *
 -mlxsw_sp_fib6_entry_rt_find(const struct mlxsw_sp_fib6_entry *fib6_entry,
 -			    const struct rt6_info *rt)
 +static int mlxsw_sp_fib_entry_update(struct mlxsw_sp *mlxsw_sp,
 +				     struct mlxsw_sp_fib_entry *fib_entry)
  {
 -	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
 -
 -	list_for_each_entry(mlxsw_sp_rt6, &fib6_entry->rt6_list, list) {
 -		if (mlxsw_sp_rt6->rt == rt)
 -			return mlxsw_sp_rt6;
 -	}
 +	return mlxsw_sp_fib_entry_op(mlxsw_sp, fib_entry,
 +				     MLXSW_REG_RALUE_OP_WRITE_WRITE);
 +}
  
 -	return NULL;
 +static int mlxsw_sp_fib_entry_del(struct mlxsw_sp *mlxsw_sp,
 +				  struct mlxsw_sp_fib_entry *fib_entry)
 +{
 +	return mlxsw_sp_fib_entry_op(mlxsw_sp, fib_entry,
 +				     MLXSW_REG_RALUE_OP_WRITE_DELETE);
  }
  
 -static bool mlxsw_sp_nexthop6_ipip_type(const struct mlxsw_sp *mlxsw_sp,
 -					const struct rt6_info *rt,
 -					enum mlxsw_sp_ipip_type *ret)
 +static int
 +mlxsw_sp_fib4_entry_type_set(struct mlxsw_sp *mlxsw_sp,
 +			     const struct fib_entry_notifier_info *fen_info,
 +			     struct mlxsw_sp_fib_entry *fib_entry)
  {
 -	return rt->dst.dev &&
 -	       mlxsw_sp_netdev_ipip_type(mlxsw_sp, rt->dst.dev, ret);
 +	struct fib_info *fi = fen_info->fi;
 +
 +	switch (fen_info->type) {
 +	case RTN_BROADCAST: /* fall through */
 +	case RTN_LOCAL:
 +		fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_TRAP;
 +		return 0;
 +	case RTN_UNREACHABLE: /* fall through */
 +	case RTN_BLACKHOLE: /* fall through */
 +	case RTN_PROHIBIT:
 +		/* Packets hitting these routes need to be trapped, but
 +		 * can do so with a lower priority than packets directed
 +		 * at the host, so use action type local instead of trap.
 +		 */
 +		fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_LOCAL;
 +		return 0;
 +	case RTN_UNICAST:
 +		if (fi->fib_nh->nh_scope != RT_SCOPE_LINK)
 +			fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_LOCAL;
 +		else
 +			fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_REMOTE;
 +		return 0;
 +	default:
 +		return -EINVAL;
 +	}
  }
  
 -static int mlxsw_sp_nexthop6_type_init(struct mlxsw_sp *mlxsw_sp,
 -				       struct mlxsw_sp_nexthop_group *nh_grp,
 -				       struct mlxsw_sp_nexthop *nh,
 -				       const struct rt6_info *rt)
 +static struct mlxsw_sp_fib_entry *
 +mlxsw_sp_fib4_entry_create(struct mlxsw_sp *mlxsw_sp,
 +			   struct mlxsw_sp_fib_node *fib_node,
 +			   const struct fib_entry_notifier_info *fen_info)
  {
 -	struct mlxsw_sp_router *router = mlxsw_sp->router;
 -	struct net_device *dev = rt->dst.dev;
 -	enum mlxsw_sp_ipip_type ipipt;
 -	struct mlxsw_sp_rif *rif;
 +	struct mlxsw_sp_fib_entry *fib_entry;
  	int err;
  
 -	if (mlxsw_sp_nexthop6_ipip_type(mlxsw_sp, rt, &ipipt) &&
 -	    router->ipip_ops_arr[ipipt]->can_offload(mlxsw_sp, dev,
 -						     MLXSW_SP_L3_PROTO_IPV6)) {
 -		nh->type = MLXSW_SP_NEXTHOP_TYPE_IPIP;
 -		return mlxsw_sp_nexthop_ipip_init(mlxsw_sp, ipipt, nh, dev);
 +	fib_entry = kzalloc(sizeof(*fib_entry), GFP_KERNEL);
 +	if (!fib_entry) {
 +		err = -ENOMEM;
 +		goto err_fib_entry_alloc;
  	}
  
 -	nh->type = MLXSW_SP_NEXTHOP_TYPE_ETH;
 -	rif = mlxsw_sp_rif_find_by_dev(mlxsw_sp, dev);
 -	if (!rif)
 -		return 0;
 -	mlxsw_sp_nexthop_rif_init(nh, rif);
 +	err = mlxsw_sp_fib4_entry_type_set(mlxsw_sp, fen_info, fib_entry);
 +	if (err)
 +		goto err_fib4_entry_type_set;
  
 -	err = mlxsw_sp_nexthop_neigh_init(mlxsw_sp, nh);
 +	err = mlxsw_sp_nexthop_group_get(mlxsw_sp, fib_entry, fen_info->fi);
  	if (err)
 -		goto err_nexthop_neigh_init;
 +		goto err_nexthop_group_get;
  
 -	return 0;
 +	fib_entry->params.prio = fen_info->fi->fib_priority;
 +	fib_entry->params.tb_id = fen_info->tb_id;
 +	fib_entry->params.type = fen_info->type;
 +	fib_entry->params.tos = fen_info->tos;
  
 -err_nexthop_neigh_init:
 -	mlxsw_sp_nexthop_rif_fini(nh);
 -	return err;
 +	fib_entry->fib_node = fib_node;
 +
 +	return fib_entry;
 +
 +err_nexthop_group_get:
 +err_fib4_entry_type_set:
 +	kfree(fib_entry);
 +err_fib_entry_alloc:
 +	return ERR_PTR(err);
  }
  
 -static void mlxsw_sp_nexthop6_type_fini(struct mlxsw_sp *mlxsw_sp,
 -					struct mlxsw_sp_nexthop *nh)
 +static void mlxsw_sp_fib4_entry_destroy(struct mlxsw_sp *mlxsw_sp,
 +					struct mlxsw_sp_fib_entry *fib_entry)
  {
 -	mlxsw_sp_nexthop_type_fini(mlxsw_sp, nh);
 +	mlxsw_sp_nexthop_group_put(mlxsw_sp, fib_entry);
 +	kfree(fib_entry);
  }
  
 -static int mlxsw_sp_nexthop6_init(struct mlxsw_sp *mlxsw_sp,
 -				  struct mlxsw_sp_nexthop_group *nh_grp,
 -				  struct mlxsw_sp_nexthop *nh,
 -				  const struct rt6_info *rt)
 +static struct mlxsw_sp_fib_node *
 +mlxsw_sp_fib_node_lookup(struct mlxsw_sp_fib *fib, const void *addr,
 +			 size_t addr_len, unsigned char prefix_len);
 +
 +static struct mlxsw_sp_fib_entry *
 +mlxsw_sp_fib4_entry_lookup(struct mlxsw_sp *mlxsw_sp,
 +			   const struct fib_entry_notifier_info *fen_info)
  {
 -	struct net_device *dev = rt->dst.dev;
 +	struct mlxsw_sp_fib_entry *fib_entry;
 +	struct mlxsw_sp_fib_node *fib_node;
 +	struct mlxsw_sp_fib *fib;
 +	struct mlxsw_sp_vr *vr;
  
 -	nh->nh_grp = nh_grp;
 -	memcpy(&nh->gw_addr, &rt->rt6i_gateway, sizeof(nh->gw_addr));
 +	vr = mlxsw_sp_vr_find(mlxsw_sp, fen_info->tb_id);
 +	if (!vr)
 +		return NULL;
 +	fib = mlxsw_sp_vr_fib(vr, MLXSW_SP_L3_PROTO_IPV4);
  
 -	list_add_tail(&nh->router_list_node, &mlxsw_sp->router->nexthop_list);
 +	fib_node = mlxsw_sp_fib_node_lookup(fib, &fen_info->dst,
 +					    sizeof(fen_info->dst),
 +					    fen_info->dst_len);
 +	if (!fib_node)
 +		return NULL;
  
 -	if (!dev)
 -		return 0;
 -	nh->ifindex = dev->ifindex;
 +	list_for_each_entry(fib_entry, &fib_node->entry_list, list) {
 +		if (fib_entry->params.tb_id == fen_info->tb_id &&
 +		    fib_entry->params.tos == fen_info->tos &&
 +		    fib_entry->params.type == fen_info->type &&
 +		    fib_entry->nh_group->key.fi == fen_info->fi) {
 +			return fib_entry;
 +		}
 +	}
  
 -	return mlxsw_sp_nexthop6_type_init(mlxsw_sp, nh_grp, nh, rt);
 +	return NULL;
  }
  
 -static void mlxsw_sp_nexthop6_fini(struct mlxsw_sp *mlxsw_sp,
 -				   struct mlxsw_sp_nexthop *nh)
 +static const struct rhashtable_params mlxsw_sp_fib_ht_params = {
 +	.key_offset = offsetof(struct mlxsw_sp_fib_node, key),
 +	.head_offset = offsetof(struct mlxsw_sp_fib_node, ht_node),
 +	.key_len = sizeof(struct mlxsw_sp_fib_key),
 +	.automatic_shrinking = true,
 +};
 +
 +static int mlxsw_sp_fib_node_insert(struct mlxsw_sp_fib *fib,
 +				    struct mlxsw_sp_fib_node *fib_node)
  {
 -	mlxsw_sp_nexthop6_type_fini(mlxsw_sp, nh);
 -	list_del(&nh->router_list_node);
 +	return rhashtable_insert_fast(&fib->ht, &fib_node->ht_node,
 +				      mlxsw_sp_fib_ht_params);
  }
  
 -static bool mlxsw_sp_rt6_is_gateway(const struct mlxsw_sp *mlxsw_sp,
 -				    const struct rt6_info *rt)
 +static void mlxsw_sp_fib_node_remove(struct mlxsw_sp_fib *fib,
 +				     struct mlxsw_sp_fib_node *fib_node)
  {
 -	return rt->rt6i_flags & RTF_GATEWAY ||
 -	       mlxsw_sp_nexthop6_ipip_type(mlxsw_sp, rt, NULL);
 +	rhashtable_remove_fast(&fib->ht, &fib_node->ht_node,
 +			       mlxsw_sp_fib_ht_params);
  }
  
 -static struct mlxsw_sp_nexthop_group *
 -mlxsw_sp_nexthop6_group_create(struct mlxsw_sp *mlxsw_sp,
 -			       struct mlxsw_sp_fib6_entry *fib6_entry)
 +static struct mlxsw_sp_fib_node *
 +mlxsw_sp_fib_node_lookup(struct mlxsw_sp_fib *fib, const void *addr,
 +			 size_t addr_len, unsigned char prefix_len)
  {
 -	struct mlxsw_sp_nexthop_group *nh_grp;
 -	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
 -	struct mlxsw_sp_nexthop *nh;
 -	size_t alloc_size;
 -	int i = 0;
 -	int err;
 +	struct mlxsw_sp_fib_key key;
  
 -	alloc_size = sizeof(*nh_grp) +
 -		     fib6_entry->nrt6 * sizeof(struct mlxsw_sp_nexthop);
 -	nh_grp = kzalloc(alloc_size, GFP_KERNEL);
 -	if (!nh_grp)
 -		return ERR_PTR(-ENOMEM);
 -	INIT_LIST_HEAD(&nh_grp->fib_list);
 -#if IS_ENABLED(CONFIG_IPV6)
 -	nh_grp->neigh_tbl = &nd_tbl;
 -#endif
 -	mlxsw_sp_rt6 = list_first_entry(&fib6_entry->rt6_list,
 -					struct mlxsw_sp_rt6, list);
 -	nh_grp->gateway = mlxsw_sp_rt6_is_gateway(mlxsw_sp, mlxsw_sp_rt6->rt);
 -	nh_grp->count = fib6_entry->nrt6;
 -	for (i = 0; i < nh_grp->count; i++) {
 -		struct rt6_info *rt = mlxsw_sp_rt6->rt;
 +	memset(&key, 0, sizeof(key));
 +	memcpy(key.addr, addr, addr_len);
 +	key.prefix_len = prefix_len;
 +	return rhashtable_lookup_fast(&fib->ht, &key, mlxsw_sp_fib_ht_params);
 +}
  
 -		nh = &nh_grp->nexthops[i];
 -		err = mlxsw_sp_nexthop6_init(mlxsw_sp, nh_grp, nh, rt);
 -		if (err)
 -			goto err_nexthop6_init;
 -		mlxsw_sp_rt6 = list_next_entry(mlxsw_sp_rt6, list);
 -	}
 +static struct mlxsw_sp_fib_node *
 +mlxsw_sp_fib_node_create(struct mlxsw_sp_fib *fib, const void *addr,
 +			 size_t addr_len, unsigned char prefix_len)
 +{
 +	struct mlxsw_sp_fib_node *fib_node;
  
 -	err = mlxsw_sp_nexthop_group_insert(mlxsw_sp, nh_grp);
 -	if (err)
 -		goto err_nexthop_group_insert;
 +	fib_node = kzalloc(sizeof(*fib_node), GFP_KERNEL);
 +	if (!fib_node)
 +		return NULL;
  
 -	mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh_grp);
 -	return nh_grp;
 +	INIT_LIST_HEAD(&fib_node->entry_list);
 +	list_add(&fib_node->list, &fib->node_list);
 +	memcpy(fib_node->key.addr, addr, addr_len);
 +	fib_node->key.prefix_len = prefix_len;
  
 -err_nexthop_group_insert:
 -err_nexthop6_init:
 -	for (i--; i >= 0; i--) {
 -		nh = &nh_grp->nexthops[i];
 -		mlxsw_sp_nexthop6_fini(mlxsw_sp, nh);
 -	}
 -	kfree(nh_grp);
 -	return ERR_PTR(err);
 +	return fib_node;
  }
  
 -static void
 -mlxsw_sp_nexthop6_group_destroy(struct mlxsw_sp *mlxsw_sp,
 -				struct mlxsw_sp_nexthop_group *nh_grp)
 +static void mlxsw_sp_fib_node_destroy(struct mlxsw_sp_fib_node *fib_node)
  {
 -	struct mlxsw_sp_nexthop *nh;
 -	int i = nh_grp->count;
 +	list_del(&fib_node->list);
 +	WARN_ON(!list_empty(&fib_node->entry_list));
 +	kfree(fib_node);
 +}
  
 -	mlxsw_sp_nexthop_group_remove(mlxsw_sp, nh_grp);
 -	for (i--; i >= 0; i--) {
 -		nh = &nh_grp->nexthops[i];
 -		mlxsw_sp_nexthop6_fini(mlxsw_sp, nh);
 -	}
 -	mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh_grp);
 -	WARN_ON(nh_grp->adj_index_valid);
 -	kfree(nh_grp);
 +static bool
 +mlxsw_sp_fib_node_entry_is_first(const struct mlxsw_sp_fib_node *fib_node,
 +				 const struct mlxsw_sp_fib_entry *fib_entry)
 +{
 +	return list_first_entry(&fib_node->entry_list,
 +				struct mlxsw_sp_fib_entry, list) == fib_entry;
  }
  
 -static int mlxsw_sp_nexthop6_group_get(struct mlxsw_sp *mlxsw_sp,
 -				       struct mlxsw_sp_fib6_entry *fib6_entry)
 +static int mlxsw_sp_fib_lpm_tree_link(struct mlxsw_sp *mlxsw_sp,
 +				      struct mlxsw_sp_fib *fib,
 +				      struct mlxsw_sp_fib_node *fib_node)
  {
 -	struct mlxsw_sp_nexthop_group *nh_grp;
 +	struct mlxsw_sp_prefix_usage req_prefix_usage = {{ 0 } };
 +	struct mlxsw_sp_lpm_tree *lpm_tree;
 +	int err;
 +
 +	/* Since the tree is shared between all virtual routers we must
 +	 * make sure it contains all the required prefix lengths. This
 +	 * can be computed by either adding the new prefix length to the
 +	 * existing prefix usage of a bound tree, or by aggregating the
 +	 * prefix lengths across all virtual routers and adding the new
 +	 * one as well.
 +	 */
 +	if (fib->lpm_tree)
 +		mlxsw_sp_prefix_usage_cpy(&req_prefix_usage,
 +					  &fib->lpm_tree->prefix_usage);
 +	else
 +		mlxsw_sp_vrs_prefixes(mlxsw_sp, fib->proto, &req_prefix_usage);
 +	mlxsw_sp_prefix_usage_set(&req_prefix_usage, fib_node->key.prefix_len);
 +
 +	lpm_tree = mlxsw_sp_lpm_tree_get(mlxsw_sp, &req_prefix_usage,
 +					 fib->proto);
 +	if (IS_ERR(lpm_tree))
 +		return PTR_ERR(lpm_tree);
  
 -	nh_grp = mlxsw_sp_nexthop6_group_lookup(mlxsw_sp, fib6_entry);
 -	if (!nh_grp) {
 -		nh_grp = mlxsw_sp_nexthop6_group_create(mlxsw_sp, fib6_entry);
 -		if (IS_ERR(nh_grp))
 -			return PTR_ERR(nh_grp);
 -	}
 +	if (fib->lpm_tree && fib->lpm_tree->id == lpm_tree->id)
 +		return 0;
  
 -	list_add_tail(&fib6_entry->common.nexthop_group_node,
 -		      &nh_grp->fib_list);
 -	fib6_entry->common.nh_group = nh_grp;
 +	err = mlxsw_sp_vrs_lpm_tree_replace(mlxsw_sp, fib, lpm_tree);
 +	if (err)
 +		return err;
  
  	return 0;
  }
@@@ -2583,233 -4542,714 +2628,667 @@@ err_fib4_entry_create
  	return err;
  }
  
 -static void mlxsw_sp_router_fib6_del(struct mlxsw_sp *mlxsw_sp,
 -				     struct rt6_info *rt)
 +static void mlxsw_sp_router_fib4_del(struct mlxsw_sp *mlxsw_sp,
 +				     struct fib_entry_notifier_info *fen_info)
  {
 -	struct mlxsw_sp_fib6_entry *fib6_entry;
++<<<<<<< HEAD
++=======
++	struct mlxsw_sp_fib4_entry *fib4_entry;
+ 	struct mlxsw_sp_fib_node *fib_node;
+ 
+ 	if (mlxsw_sp->router->aborted)
+ 		return;
+ 
 -	if (mlxsw_sp_fib6_rt_should_ignore(rt))
++	fib4_entry = mlxsw_sp_fib4_entry_lookup(mlxsw_sp, fen_info);
++	if (WARN_ON(!fib4_entry))
+ 		return;
++	fib_node = fib4_entry->common.fib_node;
+ 
 -	fib6_entry = mlxsw_sp_fib6_entry_lookup(mlxsw_sp, rt);
 -	if (WARN_ON(!fib6_entry))
 -		return;
++	mlxsw_sp_fib4_node_entry_unlink(mlxsw_sp, fib4_entry);
++	mlxsw_sp_fib4_entry_destroy(mlxsw_sp, fib4_entry);
++	mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
++}
+ 
 -	/* If route is part of a multipath entry, but not the last one
 -	 * removed, then only reduce its nexthop group.
++static bool mlxsw_sp_fib6_rt_should_ignore(const struct rt6_info *rt)
++{
++	/* Packets with link-local destination IP arriving to the router
++	 * are trapped to the CPU, so no need to program specific routes
++	 * for them.
+ 	 */
 -	if (!list_is_singular(&fib6_entry->rt6_list)) {
 -		mlxsw_sp_fib6_entry_nexthop_del(mlxsw_sp, fib6_entry, rt);
 -		return;
 -	}
++	if (ipv6_addr_type(&rt->rt6i_dst.addr) & IPV6_ADDR_LINKLOCAL)
++		return true;
+ 
 -	fib_node = fib6_entry->common.fib_node;
++	/* Multicast routes aren't supported, so ignore them. Neighbour
++	 * Discovery packets are specifically trapped.
++	 */
++	if (ipv6_addr_type(&rt->rt6i_dst.addr) & IPV6_ADDR_MULTICAST)
++		return true;
+ 
 -	mlxsw_sp_fib6_node_entry_unlink(mlxsw_sp, fib6_entry);
 -	mlxsw_sp_fib6_entry_destroy(mlxsw_sp, fib6_entry);
 -	mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
++	/* Cloned routes are irrelevant in the forwarding path. */
++	if (rt->rt6i_flags & RTF_CACHE)
++		return true;
++
++	return false;
+ }
+ 
 -static int __mlxsw_sp_router_set_abort_trap(struct mlxsw_sp *mlxsw_sp,
 -					    enum mlxsw_reg_ralxx_protocol proto,
 -					    u8 tree_id)
++static struct mlxsw_sp_rt6 *mlxsw_sp_rt6_create(struct rt6_info *rt)
+ {
 -	char ralta_pl[MLXSW_REG_RALTA_LEN];
 -	char ralst_pl[MLXSW_REG_RALST_LEN];
 -	int i, err;
++	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
+ 
 -	mlxsw_reg_ralta_pack(ralta_pl, true, proto, tree_id);
 -	err = mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ralta), ralta_pl);
 -	if (err)
 -		return err;
++	mlxsw_sp_rt6 = kzalloc(sizeof(*mlxsw_sp_rt6), GFP_KERNEL);
++	if (!mlxsw_sp_rt6)
++		return ERR_PTR(-ENOMEM);
+ 
 -	mlxsw_reg_ralst_pack(ralst_pl, 0xff, tree_id);
 -	err = mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ralst), ralst_pl);
 -	if (err)
 -		return err;
++	/* In case of route replace, replaced route is deleted with
++	 * no notification. Take reference to prevent accessing freed
++	 * memory.
++	 */
++	mlxsw_sp_rt6->rt = rt;
++	rt6_hold(rt);
+ 
 -	for (i = 0; i < MLXSW_CORE_RES_GET(mlxsw_sp->core, MAX_VRS); i++) {
 -		struct mlxsw_sp_vr *vr = &mlxsw_sp->router->vrs[i];
 -		char raltb_pl[MLXSW_REG_RALTB_LEN];
 -		char ralue_pl[MLXSW_REG_RALUE_LEN];
++	return mlxsw_sp_rt6;
++}
+ 
 -		mlxsw_reg_raltb_pack(raltb_pl, vr->id, proto, tree_id);
 -		err = mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(raltb),
 -				      raltb_pl);
 -		if (err)
 -			return err;
++#if IS_ENABLED(CONFIG_IPV6)
++static void mlxsw_sp_rt6_release(struct rt6_info *rt)
++{
++	rt6_release(rt);
++}
++#else
++static void mlxsw_sp_rt6_release(struct rt6_info *rt)
++{
++}
++#endif
+ 
 -		mlxsw_reg_ralue_pack(ralue_pl, proto,
 -				     MLXSW_REG_RALUE_OP_WRITE_WRITE, vr->id, 0);
 -		mlxsw_reg_ralue_act_ip2me_pack(ralue_pl);
 -		err = mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ralue),
 -				      ralue_pl);
 -		if (err)
 -			return err;
++static void mlxsw_sp_rt6_destroy(struct mlxsw_sp_rt6 *mlxsw_sp_rt6)
++{
++	mlxsw_sp_rt6_release(mlxsw_sp_rt6->rt);
++	kfree(mlxsw_sp_rt6);
++}
++
++static bool mlxsw_sp_fib6_rt_can_mp(const struct rt6_info *rt)
++{
++	/* RTF_CACHE routes are ignored */
++	return (rt->rt6i_flags & (RTF_GATEWAY | RTF_ADDRCONF)) == RTF_GATEWAY;
++}
++
++static struct rt6_info *
++mlxsw_sp_fib6_entry_rt(const struct mlxsw_sp_fib6_entry *fib6_entry)
++{
++	return list_first_entry(&fib6_entry->rt6_list, struct mlxsw_sp_rt6,
++				list)->rt;
++}
++
++static struct mlxsw_sp_fib6_entry *
++mlxsw_sp_fib6_node_mp_entry_find(const struct mlxsw_sp_fib_node *fib_node,
++				 const struct rt6_info *nrt, bool replace)
++{
++	struct mlxsw_sp_fib6_entry *fib6_entry;
++
++	if (!mlxsw_sp_fib6_rt_can_mp(nrt) || replace)
++		return NULL;
++
++	list_for_each_entry(fib6_entry, &fib_node->entry_list, common.list) {
++		struct rt6_info *rt = mlxsw_sp_fib6_entry_rt(fib6_entry);
++
++		/* RT6_TABLE_LOCAL and RT6_TABLE_MAIN share the same
++		 * virtual router.
++		 */
++		if (rt->rt6i_table->tb6_id > nrt->rt6i_table->tb6_id)
++			continue;
++		if (rt->rt6i_table->tb6_id != nrt->rt6i_table->tb6_id)
++			break;
++		if (rt->rt6i_metric < nrt->rt6i_metric)
++			continue;
++		if (rt->rt6i_metric == nrt->rt6i_metric &&
++		    mlxsw_sp_fib6_rt_can_mp(rt))
++			return fib6_entry;
++		if (rt->rt6i_metric > nrt->rt6i_metric)
++			break;
+ 	}
+ 
 -	return 0;
++	return NULL;
+ }
+ 
 -static int mlxsw_sp_router_set_abort_trap(struct mlxsw_sp *mlxsw_sp)
++static struct mlxsw_sp_rt6 *
++mlxsw_sp_fib6_entry_rt_find(const struct mlxsw_sp_fib6_entry *fib6_entry,
++			    const struct rt6_info *rt)
+ {
 -	enum mlxsw_reg_ralxx_protocol proto = MLXSW_REG_RALXX_PROTOCOL_IPV4;
 -	int err;
++	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
+ 
 -	err = __mlxsw_sp_router_set_abort_trap(mlxsw_sp, proto,
 -					       MLXSW_SP_LPM_TREE_MIN);
 -	if (err)
 -		return err;
++	list_for_each_entry(mlxsw_sp_rt6, &fib6_entry->rt6_list, list) {
++		if (mlxsw_sp_rt6->rt == rt)
++			return mlxsw_sp_rt6;
++	}
+ 
 -	proto = MLXSW_REG_RALXX_PROTOCOL_IPV6;
 -	return __mlxsw_sp_router_set_abort_trap(mlxsw_sp, proto,
 -						MLXSW_SP_LPM_TREE_MIN + 1);
++	return NULL;
+ }
+ 
 -static void mlxsw_sp_fib4_node_flush(struct mlxsw_sp *mlxsw_sp,
 -				     struct mlxsw_sp_fib_node *fib_node)
++static bool mlxsw_sp_nexthop6_ipip_type(const struct mlxsw_sp *mlxsw_sp,
++					const struct rt6_info *rt,
++					enum mlxsw_sp_ipip_type *ret)
+ {
 -	struct mlxsw_sp_fib4_entry *fib4_entry, *tmp;
++	return rt->dst.dev &&
++	       mlxsw_sp_netdev_ipip_type(mlxsw_sp, rt->dst.dev, ret);
++}
+ 
 -	list_for_each_entry_safe(fib4_entry, tmp, &fib_node->entry_list,
 -				 common.list) {
 -		bool do_break = &tmp->common.list == &fib_node->entry_list;
++static int mlxsw_sp_nexthop6_type_init(struct mlxsw_sp *mlxsw_sp,
++				       struct mlxsw_sp_nexthop_group *nh_grp,
++				       struct mlxsw_sp_nexthop *nh,
++				       const struct rt6_info *rt)
++{
++	struct mlxsw_sp_router *router = mlxsw_sp->router;
++	struct net_device *dev = rt->dst.dev;
++	enum mlxsw_sp_ipip_type ipipt;
++	struct mlxsw_sp_rif *rif;
++	int err;
+ 
 -		mlxsw_sp_fib4_node_entry_unlink(mlxsw_sp, fib4_entry);
 -		mlxsw_sp_fib4_entry_destroy(mlxsw_sp, fib4_entry);
 -		mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
 -		/* Break when entry list is empty and node was freed.
 -		 * Otherwise, we'll access freed memory in the next
 -		 * iteration.
 -		 */
 -		if (do_break)
 -			break;
++	if (mlxsw_sp_nexthop6_ipip_type(mlxsw_sp, rt, &ipipt) &&
++	    router->ipip_ops_arr[ipipt]->can_offload(mlxsw_sp, dev,
++						     MLXSW_SP_L3_PROTO_IPV6)) {
++		nh->type = MLXSW_SP_NEXTHOP_TYPE_IPIP;
++		return mlxsw_sp_nexthop_ipip_init(mlxsw_sp, ipipt, nh, dev);
+ 	}
 -}
+ 
 -static void mlxsw_sp_fib6_node_flush(struct mlxsw_sp *mlxsw_sp,
 -				     struct mlxsw_sp_fib_node *fib_node)
 -{
 -	struct mlxsw_sp_fib6_entry *fib6_entry, *tmp;
++	nh->type = MLXSW_SP_NEXTHOP_TYPE_ETH;
++	rif = mlxsw_sp_rif_find_by_dev(mlxsw_sp, dev);
++	if (!rif)
++		return 0;
++	mlxsw_sp_nexthop_rif_init(nh, rif);
+ 
 -	list_for_each_entry_safe(fib6_entry, tmp, &fib_node->entry_list,
 -				 common.list) {
 -		bool do_break = &tmp->common.list == &fib_node->entry_list;
++	err = mlxsw_sp_nexthop_neigh_init(mlxsw_sp, nh);
++	if (err)
++		goto err_nexthop_neigh_init;
+ 
 -		mlxsw_sp_fib6_node_entry_unlink(mlxsw_sp, fib6_entry);
 -		mlxsw_sp_fib6_entry_destroy(mlxsw_sp, fib6_entry);
 -		mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
 -		if (do_break)
 -			break;
 -	}
 -}
++	return 0;
+ 
 -static void mlxsw_sp_fib_node_flush(struct mlxsw_sp *mlxsw_sp,
 -				    struct mlxsw_sp_fib_node *fib_node)
 -{
 -	switch (fib_node->fib->proto) {
 -	case MLXSW_SP_L3_PROTO_IPV4:
 -		mlxsw_sp_fib4_node_flush(mlxsw_sp, fib_node);
 -		break;
 -	case MLXSW_SP_L3_PROTO_IPV6:
 -		mlxsw_sp_fib6_node_flush(mlxsw_sp, fib_node);
 -		break;
 -	}
++err_nexthop_neigh_init:
++	mlxsw_sp_nexthop_rif_fini(nh);
++	return err;
+ }
+ 
 -static void mlxsw_sp_vr_fib_flush(struct mlxsw_sp *mlxsw_sp,
 -				  struct mlxsw_sp_vr *vr,
 -				  enum mlxsw_sp_l3proto proto)
++static void mlxsw_sp_nexthop6_type_fini(struct mlxsw_sp *mlxsw_sp,
++					struct mlxsw_sp_nexthop *nh)
+ {
 -	struct mlxsw_sp_fib *fib = mlxsw_sp_vr_fib(vr, proto);
 -	struct mlxsw_sp_fib_node *fib_node, *tmp;
 -
 -	list_for_each_entry_safe(fib_node, tmp, &fib->node_list, list) {
 -		bool do_break = &tmp->list == &fib->node_list;
 -
 -		mlxsw_sp_fib_node_flush(mlxsw_sp, fib_node);
 -		if (do_break)
 -			break;
 -	}
++	mlxsw_sp_nexthop_type_fini(mlxsw_sp, nh);
+ }
+ 
 -static void mlxsw_sp_router_fib_flush(struct mlxsw_sp *mlxsw_sp)
++static int mlxsw_sp_nexthop6_init(struct mlxsw_sp *mlxsw_sp,
++				  struct mlxsw_sp_nexthop_group *nh_grp,
++				  struct mlxsw_sp_nexthop *nh,
++				  const struct rt6_info *rt)
+ {
 -	int i;
++	struct net_device *dev = rt->dst.dev;
+ 
 -	for (i = 0; i < MLXSW_CORE_RES_GET(mlxsw_sp->core, MAX_VRS); i++) {
 -		struct mlxsw_sp_vr *vr = &mlxsw_sp->router->vrs[i];
++	nh->nh_grp = nh_grp;
++	memcpy(&nh->gw_addr, &rt->rt6i_gateway, sizeof(nh->gw_addr));
+ 
 -		if (!mlxsw_sp_vr_is_used(vr))
 -			continue;
 -		mlxsw_sp_vr_fib_flush(mlxsw_sp, vr, MLXSW_SP_L3_PROTO_IPV4);
++	list_add_tail(&nh->router_list_node, &mlxsw_sp->router->nexthop_list);
+ 
 -		/* If virtual router was only used for IPv4, then it's no
 -		 * longer used.
 -		 */
 -		if (!mlxsw_sp_vr_is_used(vr))
 -			continue;
 -		mlxsw_sp_vr_fib_flush(mlxsw_sp, vr, MLXSW_SP_L3_PROTO_IPV6);
 -	}
++	if (!dev)
++		return 0;
++	nh->ifindex = dev->ifindex;
++
++	return mlxsw_sp_nexthop6_type_init(mlxsw_sp, nh_grp, nh, rt);
+ }
+ 
 -static void mlxsw_sp_router_fib_abort(struct mlxsw_sp *mlxsw_sp)
++static void mlxsw_sp_nexthop6_fini(struct mlxsw_sp *mlxsw_sp,
++				   struct mlxsw_sp_nexthop *nh)
+ {
 -	int err;
 -
 -	if (mlxsw_sp->router->aborted)
 -		return;
 -	dev_warn(mlxsw_sp->bus_info->dev, "FIB abort triggered. Note that FIB entries are no longer being offloaded to this device.\n");
 -	mlxsw_sp_router_fib_flush(mlxsw_sp);
 -	mlxsw_sp->router->aborted = true;
 -	err = mlxsw_sp_router_set_abort_trap(mlxsw_sp);
 -	if (err)
 -		dev_warn(mlxsw_sp->bus_info->dev, "Failed to set abort trap.\n");
++	mlxsw_sp_nexthop6_type_fini(mlxsw_sp, nh);
++	list_del(&nh->router_list_node);
+ }
+ 
 -struct mlxsw_sp_fib_event_work {
 -	struct work_struct work;
 -	union {
 -		struct fib6_entry_notifier_info fen6_info;
 -		struct fib_entry_notifier_info fen_info;
 -		struct fib_rule_notifier_info fr_info;
 -		struct fib_nh_notifier_info fnh_info;
 -	};
 -	struct mlxsw_sp *mlxsw_sp;
 -	unsigned long event;
 -};
 -
 -static void mlxsw_sp_router_fib4_event_work(struct work_struct *work)
++static bool mlxsw_sp_rt6_is_gateway(const struct mlxsw_sp *mlxsw_sp,
++				    const struct rt6_info *rt)
+ {
 -	struct mlxsw_sp_fib_event_work *fib_work =
 -		container_of(work, struct mlxsw_sp_fib_event_work, work);
 -	struct mlxsw_sp *mlxsw_sp = fib_work->mlxsw_sp;
 -	struct fib_rule *rule;
 -	bool replace, append;
 -	int err;
 -
 -	/* Protect internal structures from changes */
 -	rtnl_lock();
 -	switch (fib_work->event) {
 -	case FIB_EVENT_ENTRY_REPLACE: /* fall through */
 -	case FIB_EVENT_ENTRY_APPEND: /* fall through */
 -	case FIB_EVENT_ENTRY_ADD:
 -		replace = fib_work->event == FIB_EVENT_ENTRY_REPLACE;
 -		append = fib_work->event == FIB_EVENT_ENTRY_APPEND;
 -		err = mlxsw_sp_router_fib4_add(mlxsw_sp, &fib_work->fen_info,
 -					       replace, append);
 -		if (err)
 -			mlxsw_sp_router_fib_abort(mlxsw_sp);
 -		fib_info_put(fib_work->fen_info.fi);
 -		break;
 -	case FIB_EVENT_ENTRY_DEL:
 -		mlxsw_sp_router_fib4_del(mlxsw_sp, &fib_work->fen_info);
 -		fib_info_put(fib_work->fen_info.fi);
 -		break;
 -	case FIB_EVENT_RULE_ADD: /* fall through */
 -	case FIB_EVENT_RULE_DEL:
 -		rule = fib_work->fr_info.rule;
 -		if (!fib4_rule_default(rule) && !rule->l3mdev)
 -			mlxsw_sp_router_fib_abort(mlxsw_sp);
 -		fib_rule_put(rule);
 -		break;
 -	case FIB_EVENT_NH_ADD: /* fall through */
 -	case FIB_EVENT_NH_DEL:
 -		mlxsw_sp_nexthop4_event(mlxsw_sp, fib_work->event,
 -					fib_work->fnh_info.fib_nh);
 -		fib_info_put(fib_work->fnh_info.fib_nh->nh_parent);
 -		break;
 -	}
 -	rtnl_unlock();
 -	kfree(fib_work);
++	return rt->rt6i_flags & RTF_GATEWAY ||
++	       mlxsw_sp_nexthop6_ipip_type(mlxsw_sp, rt, NULL);
+ }
+ 
 -static void mlxsw_sp_router_fib6_event_work(struct work_struct *work)
++static struct mlxsw_sp_nexthop_group *
++mlxsw_sp_nexthop6_group_create(struct mlxsw_sp *mlxsw_sp,
++			       struct mlxsw_sp_fib6_entry *fib6_entry)
+ {
 -	struct mlxsw_sp_fib_event_work *fib_work =
 -		container_of(work, struct mlxsw_sp_fib_event_work, work);
 -	struct mlxsw_sp *mlxsw_sp = fib_work->mlxsw_sp;
 -	struct fib_rule *rule;
 -	bool replace;
++	struct mlxsw_sp_nexthop_group *nh_grp;
++	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
++	struct mlxsw_sp_nexthop *nh;
++	size_t alloc_size;
++	int i = 0;
+ 	int err;
+ 
 -	rtnl_lock();
 -	switch (fib_work->event) {
 -	case FIB_EVENT_ENTRY_REPLACE: /* fall through */
 -	case FIB_EVENT_ENTRY_ADD:
 -		replace = fib_work->event == FIB_EVENT_ENTRY_REPLACE;
 -		err = mlxsw_sp_router_fib6_add(mlxsw_sp,
 -					       fib_work->fen6_info.rt, replace);
++	alloc_size = sizeof(*nh_grp) +
++		     fib6_entry->nrt6 * sizeof(struct mlxsw_sp_nexthop);
++	nh_grp = kzalloc(alloc_size, GFP_KERNEL);
++	if (!nh_grp)
++		return ERR_PTR(-ENOMEM);
++	INIT_LIST_HEAD(&nh_grp->fib_list);
++#if IS_ENABLED(CONFIG_IPV6)
++	nh_grp->neigh_tbl = &nd_tbl;
++#endif
++	mlxsw_sp_rt6 = list_first_entry(&fib6_entry->rt6_list,
++					struct mlxsw_sp_rt6, list);
++	nh_grp->gateway = mlxsw_sp_rt6_is_gateway(mlxsw_sp, mlxsw_sp_rt6->rt);
++	nh_grp->count = fib6_entry->nrt6;
++	for (i = 0; i < nh_grp->count; i++) {
++		struct rt6_info *rt = mlxsw_sp_rt6->rt;
++
++		nh = &nh_grp->nexthops[i];
++		err = mlxsw_sp_nexthop6_init(mlxsw_sp, nh_grp, nh, rt);
+ 		if (err)
 -			mlxsw_sp_router_fib_abort(mlxsw_sp);
 -		mlxsw_sp_rt6_release(fib_work->fen6_info.rt);
 -		break;
 -	case FIB_EVENT_ENTRY_DEL:
 -		mlxsw_sp_router_fib6_del(mlxsw_sp, fib_work->fen6_info.rt);
 -		mlxsw_sp_rt6_release(fib_work->fen6_info.rt);
 -		break;
 -	case FIB_EVENT_RULE_ADD: /* fall through */
 -	case FIB_EVENT_RULE_DEL:
 -		rule = fib_work->fr_info.rule;
 -		if (!fib6_rule_default(rule) && !rule->l3mdev)
 -			mlxsw_sp_router_fib_abort(mlxsw_sp);
 -		fib_rule_put(rule);
 -		break;
++			goto err_nexthop6_init;
++		mlxsw_sp_rt6 = list_next_entry(mlxsw_sp_rt6, list);
+ 	}
 -	rtnl_unlock();
 -	kfree(fib_work);
 -}
+ 
 -static void mlxsw_sp_router_fib4_event(struct mlxsw_sp_fib_event_work *fib_work,
 -				       struct fib_notifier_info *info)
 -{
 -	switch (fib_work->event) {
 -	case FIB_EVENT_ENTRY_REPLACE: /* fall through */
 -	case FIB_EVENT_ENTRY_APPEND: /* fall through */
 -	case FIB_EVENT_ENTRY_ADD: /* fall through */
 -	case FIB_EVENT_ENTRY_DEL:
 -		memcpy(&fib_work->fen_info, info, sizeof(fib_work->fen_info));
 -		/* Take referece on fib_info to prevent it from being
 -		 * freed while work is queued. Release it afterwards.
 -		 */
 -		fib_info_hold(fib_work->fen_info.fi);
 -		break;
 -	case FIB_EVENT_RULE_ADD: /* fall through */
 -	case FIB_EVENT_RULE_DEL:
 -		memcpy(&fib_work->fr_info, info, sizeof(fib_work->fr_info));
 -		fib_rule_get(fib_work->fr_info.rule);
 -		break;
 -	case FIB_EVENT_NH_ADD: /* fall through */
 -	case FIB_EVENT_NH_DEL:
 -		memcpy(&fib_work->fnh_info, info, sizeof(fib_work->fnh_info));
 -		fib_info_hold(fib_work->fnh_info.fib_nh->nh_parent);
 -		break;
++	err = mlxsw_sp_nexthop_group_insert(mlxsw_sp, nh_grp);
++	if (err)
++		goto err_nexthop_group_insert;
++
++	mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh_grp);
++	return nh_grp;
++
++err_nexthop_group_insert:
++err_nexthop6_init:
++	for (i--; i >= 0; i--) {
++		nh = &nh_grp->nexthops[i];
++		mlxsw_sp_nexthop6_fini(mlxsw_sp, nh);
+ 	}
++	kfree(nh_grp);
++	return ERR_PTR(err);
+ }
+ 
 -static void mlxsw_sp_router_fib6_event(struct mlxsw_sp_fib_event_work *fib_work,
 -				       struct fib_notifier_info *info)
++static void
++mlxsw_sp_nexthop6_group_destroy(struct mlxsw_sp *mlxsw_sp,
++				struct mlxsw_sp_nexthop_group *nh_grp)
+ {
 -	switch (fib_work->event) {
 -	case FIB_EVENT_ENTRY_REPLACE: /* fall through */
 -	case FIB_EVENT_ENTRY_ADD: /* fall through */
 -	case FIB_EVENT_ENTRY_DEL:
 -		memcpy(&fib_work->fen6_info, info, sizeof(fib_work->fen6_info));
 -		rt6_hold(fib_work->fen6_info.rt);
 -		break;
 -	case FIB_EVENT_RULE_ADD: /* fall through */
 -	case FIB_EVENT_RULE_DEL:
 -		memcpy(&fib_work->fr_info, info, sizeof(fib_work->fr_info));
 -		fib_rule_get(fib_work->fr_info.rule);
 -		break;
++	struct mlxsw_sp_nexthop *nh;
++	int i = nh_grp->count;
++
++	mlxsw_sp_nexthop_group_remove(mlxsw_sp, nh_grp);
++	for (i--; i >= 0; i--) {
++		nh = &nh_grp->nexthops[i];
++		mlxsw_sp_nexthop6_fini(mlxsw_sp, nh);
+ 	}
++	mlxsw_sp_nexthop_group_refresh(mlxsw_sp, nh_grp);
++	WARN_ON(nh_grp->adj_index_valid);
++	kfree(nh_grp);
+ }
+ 
 -/* Called with rcu_read_lock() */
 -static int mlxsw_sp_router_fib_event(struct notifier_block *nb,
 -				     unsigned long event, void *ptr)
++static int mlxsw_sp_nexthop6_group_get(struct mlxsw_sp *mlxsw_sp,
++				       struct mlxsw_sp_fib6_entry *fib6_entry)
+ {
 -	struct mlxsw_sp_fib_event_work *fib_work;
 -	struct fib_notifier_info *info = ptr;
 -	struct mlxsw_sp_router *router;
 -
 -	if (!net_eq(info->net, &init_net) ||
 -	    (info->family != AF_INET && info->family != AF_INET6))
 -		return NOTIFY_DONE;
 -
 -	fib_work = kzalloc(sizeof(*fib_work), GFP_ATOMIC);
 -	if (WARN_ON(!fib_work))
 -		return NOTIFY_BAD;
 -
 -	router = container_of(nb, struct mlxsw_sp_router, fib_nb);
 -	fib_work->mlxsw_sp = router->mlxsw_sp;
 -	fib_work->event = event;
++	struct mlxsw_sp_nexthop_group *nh_grp;
+ 
 -	switch (info->family) {
 -	case AF_INET:
 -		INIT_WORK(&fib_work->work, mlxsw_sp_router_fib4_event_work);
 -		mlxsw_sp_router_fib4_event(fib_work, info);
 -		break;
 -	case AF_INET6:
 -		INIT_WORK(&fib_work->work, mlxsw_sp_router_fib6_event_work);
 -		mlxsw_sp_router_fib6_event(fib_work, info);
 -		break;
++	nh_grp = mlxsw_sp_nexthop6_group_lookup(mlxsw_sp, fib6_entry);
++	if (!nh_grp) {
++		nh_grp = mlxsw_sp_nexthop6_group_create(mlxsw_sp, fib6_entry);
++		if (IS_ERR(nh_grp))
++			return PTR_ERR(nh_grp);
+ 	}
+ 
 -	mlxsw_core_schedule_work(&fib_work->work);
++	list_add_tail(&fib6_entry->common.nexthop_group_node,
++		      &nh_grp->fib_list);
++	fib6_entry->common.nh_group = nh_grp;
+ 
 -	return NOTIFY_DONE;
++	return 0;
+ }
+ 
 -static struct mlxsw_sp_rif *
 -mlxsw_sp_rif_find_by_dev(const struct mlxsw_sp *mlxsw_sp,
 -			 const struct net_device *dev)
++static void mlxsw_sp_nexthop6_group_put(struct mlxsw_sp *mlxsw_sp,
++					struct mlxsw_sp_fib_entry *fib_entry)
+ {
 -	int i;
 -
 -	for (i = 0; i < MLXSW_CORE_RES_GET(mlxsw_sp->core, MAX_RIFS); i++)
 -		if (mlxsw_sp->router->rifs[i] &&
 -		    mlxsw_sp->router->rifs[i]->dev == dev)
 -			return mlxsw_sp->router->rifs[i];
++	struct mlxsw_sp_nexthop_group *nh_grp = fib_entry->nh_group;
+ 
 -	return NULL;
++	list_del(&fib_entry->nexthop_group_node);
++	if (!list_empty(&nh_grp->fib_list))
++		return;
++	mlxsw_sp_nexthop6_group_destroy(mlxsw_sp, nh_grp);
+ }
+ 
 -static int mlxsw_sp_router_rif_disable(struct mlxsw_sp *mlxsw_sp, u16 rif)
++static int
++mlxsw_sp_nexthop6_group_update(struct mlxsw_sp *mlxsw_sp,
++			       struct mlxsw_sp_fib6_entry *fib6_entry)
+ {
 -	char ritr_pl[MLXSW_REG_RITR_LEN];
++	struct mlxsw_sp_nexthop_group *old_nh_grp = fib6_entry->common.nh_group;
+ 	int err;
+ 
 -	mlxsw_reg_ritr_rif_pack(ritr_pl, rif);
 -	err = mlxsw_reg_query(mlxsw_sp->core, MLXSW_REG(ritr), ritr_pl);
 -	if (WARN_ON_ONCE(err))
 -		return err;
 -
 -	mlxsw_reg_ritr_enable_set(ritr_pl, false);
 -	return mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ritr), ritr_pl);
 -}
 -
 -static void mlxsw_sp_router_rif_gone_sync(struct mlxsw_sp *mlxsw_sp,
 -					  struct mlxsw_sp_rif *rif)
 -{
 -	mlxsw_sp_router_rif_disable(mlxsw_sp, rif->rif_index);
 -	mlxsw_sp_nexthop_rif_gone_sync(mlxsw_sp, rif);
 -	mlxsw_sp_neigh_rif_gone_sync(mlxsw_sp, rif);
 -}
++	fib6_entry->common.nh_group = NULL;
++	list_del(&fib6_entry->common.nexthop_group_node);
+ 
 -static bool
 -mlxsw_sp_rif_should_config(struct mlxsw_sp_rif *rif, struct net_device *dev,
 -			   unsigned long event)
 -{
 -	struct inet6_dev *inet6_dev;
 -	bool addr_list_empty = true;
 -	struct in_device *idev;
++	err = mlxsw_sp_nexthop6_group_get(mlxsw_sp, fib6_entry);
++	if (err)
++		goto err_nexthop6_group_get;
+ 
 -	switch (event) {
 -	case NETDEV_UP:
 -		return rif == NULL;
 -	case NETDEV_DOWN:
 -		idev = __in_dev_get_rtnl(dev);
 -		if (idev && idev->ifa_list)
 -			addr_list_empty = false;
++	/* In case this entry is offloaded, then the adjacency index
++	 * currently associated with it in the device's table is that
++	 * of the old group. Start using the new one instead.
++	 */
++	err = mlxsw_sp_fib_node_entry_add(mlxsw_sp, &fib6_entry->common);
++	if (err)
++		goto err_fib_node_entry_add;
+ 
 -		inet6_dev = __in6_dev_get(dev);
 -		if (addr_list_empty && inet6_dev &&
 -		    !list_empty(&inet6_dev->addr_list))
 -			addr_list_empty = false;
++	if (list_empty(&old_nh_grp->fib_list))
++		mlxsw_sp_nexthop6_group_destroy(mlxsw_sp, old_nh_grp);
+ 
 -		if (rif && addr_list_empty &&
 -		    !netif_is_l3_slave(rif->dev))
 -			return true;
 -		/* It is possible we already removed the RIF ourselves
 -		 * if it was assigned to a netdev that is now a bridge
 -		 * or LAG slave.
 -		 */
 -		return false;
 -	}
++	return 0;
+ 
 -	return false;
++err_fib_node_entry_add:
++	mlxsw_sp_nexthop6_group_put(mlxsw_sp, &fib6_entry->common);
++err_nexthop6_group_get:
++	list_add_tail(&fib6_entry->common.nexthop_group_node,
++		      &old_nh_grp->fib_list);
++	fib6_entry->common.nh_group = old_nh_grp;
++	return err;
+ }
+ 
 -static enum mlxsw_sp_rif_type
 -mlxsw_sp_dev_rif_type(const struct mlxsw_sp *mlxsw_sp,
 -		      const struct net_device *dev)
++static int
++mlxsw_sp_fib6_entry_nexthop_add(struct mlxsw_sp *mlxsw_sp,
++				struct mlxsw_sp_fib6_entry *fib6_entry,
++				struct rt6_info *rt)
+ {
 -	enum mlxsw_sp_fid_type type;
 -
 -	if (mlxsw_sp_netdev_ipip_type(mlxsw_sp, dev, NULL))
 -		return MLXSW_SP_RIF_TYPE_IPIP_LB;
++	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
++	int err;
+ 
 -	/* Otherwise RIF type is derived from the type of the underlying FID. */
 -	if (is_vlan_dev(dev) && netif_is_bridge_master(vlan_dev_real_dev(dev)))
 -		type = MLXSW_SP_FID_TYPE_8021Q;
 -	else if (netif_is_bridge_master(dev) && br_vlan_enabled(dev))
 -		type = MLXSW_SP_FID_TYPE_8021Q;
 -	else if (netif_is_bridge_master(dev))
 -		type = MLXSW_SP_FID_TYPE_8021D;
 -	else
 -		type = MLXSW_SP_FID_TYPE_RFID;
++	mlxsw_sp_rt6 = mlxsw_sp_rt6_create(rt);
++	if (IS_ERR(mlxsw_sp_rt6))
++		return PTR_ERR(mlxsw_sp_rt6);
+ 
 -	return mlxsw_sp_fid_type_rif_type(mlxsw_sp, type);
 -}
++	list_add_tail(&mlxsw_sp_rt6->list, &fib6_entry->rt6_list);
++	fib6_entry->nrt6++;
+ 
 -static int mlxsw_sp_rif_index_alloc(struct mlxsw_sp *mlxsw_sp, u16 *p_rif_index)
 -{
 -	int i;
++	err = mlxsw_sp_nexthop6_group_update(mlxsw_sp, fib6_entry);
++	if (err)
++		goto err_nexthop6_group_update;
+ 
 -	for (i = 0; i < MLXSW_CORE_RES_GET(mlxsw_sp->core, MAX_RIFS); i++) {
 -		if (!mlxsw_sp->router->rifs[i]) {
 -			*p_rif_index = i;
 -			return 0;
 -		}
 -	}
++	return 0;
+ 
 -	return -ENOBUFS;
++err_nexthop6_group_update:
++	fib6_entry->nrt6--;
++	list_del(&mlxsw_sp_rt6->list);
++	mlxsw_sp_rt6_destroy(mlxsw_sp_rt6);
++	return err;
+ }
+ 
 -static struct mlxsw_sp_rif *mlxsw_sp_rif_alloc(size_t rif_size, u16 rif_index,
 -					       u16 vr_id,
 -					       struct net_device *l3_dev)
++static void
++mlxsw_sp_fib6_entry_nexthop_del(struct mlxsw_sp *mlxsw_sp,
++				struct mlxsw_sp_fib6_entry *fib6_entry,
++				struct rt6_info *rt)
+ {
 -	struct mlxsw_sp_rif *rif;
 -
 -	rif = kzalloc(rif_size, GFP_KERNEL);
 -	if (!rif)
 -		return NULL;
++	struct mlxsw_sp_rt6 *mlxsw_sp_rt6;
+ 
 -	INIT_LIST_HEAD(&rif->nexthop_list);
 -	INIT_LIST_HEAD(&rif->neigh_list);
 -	ether_addr_copy(rif->addr, l3_dev->dev_addr);
 -	rif->mtu = l3_dev->mtu;
 -	rif->vr_id = vr_id;
 -	rif->dev = l3_dev;
 -	rif->rif_index = rif_index;
++	mlxsw_sp_rt6 = mlxsw_sp_fib6_entry_rt_find(fib6_entry, rt);
++	if (WARN_ON(!mlxsw_sp_rt6))
++		return;
+ 
 -	return rif;
++	fib6_entry->nrt6--;
++	list_del(&mlxsw_sp_rt6->list);
++	mlxsw_sp_nexthop6_group_update(mlxsw_sp, fib6_entry);
++	mlxsw_sp_rt6_destroy(mlxsw_sp_rt6);
+ }
+ 
 -struct mlxsw_sp_rif *mlxsw_sp_rif_by_index(const struct mlxsw_sp *mlxsw_sp,
 -					   u16 rif_index)
++static void mlxsw_sp_fib6_entry_type_set(struct mlxsw_sp *mlxsw_sp,
++					 struct mlxsw_sp_fib_entry *fib_entry,
++					 const struct rt6_info *rt)
+ {
 -	return mlxsw_sp->router->rifs[rif_index];
++	/* Packets hitting RTF_REJECT routes need to be discarded by the
++	 * stack. We can rely on their destination device not having a
++	 * RIF (it's the loopback device) and can thus use action type
++	 * local, which will cause them to be trapped with a lower
++	 * priority than packets that need to be locally received.
++	 */
++	if (rt->rt6i_flags & (RTF_LOCAL | RTF_ANYCAST))
++		fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_TRAP;
++	else if (rt->rt6i_flags & RTF_REJECT)
++		fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_LOCAL;
++	else if (mlxsw_sp_rt6_is_gateway(mlxsw_sp, rt))
++		fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_REMOTE;
++	else
++		fib_entry->type = MLXSW_SP_FIB_ENTRY_TYPE_LOCAL;
+ }
+ 
 -u16 mlxsw_sp_rif_index(const struct mlxsw_sp_rif *rif)
++static void
++mlxsw_sp_fib6_entry_rt_destroy_all(struct mlxsw_sp_fib6_entry *fib6_entry)
+ {
 -	return rif->rif_index;
 -}
++	struct mlxsw_sp_rt6 *mlxsw_sp_rt6, *tmp;
+ 
 -u16 mlxsw_sp_ipip_lb_rif_index(const struct mlxsw_sp_rif_ipip_lb *lb_rif)
 -{
 -	return lb_rif->common.rif_index;
++	list_for_each_entry_safe(mlxsw_sp_rt6, tmp, &fib6_entry->rt6_list,
++				 list) {
++		fib6_entry->nrt6--;
++		list_del(&mlxsw_sp_rt6->list);
++		mlxsw_sp_rt6_destroy(mlxsw_sp_rt6);
++	}
+ }
+ 
 -u16 mlxsw_sp_ipip_lb_ul_vr_id(const struct mlxsw_sp_rif_ipip_lb *lb_rif)
++static struct mlxsw_sp_fib6_entry *
++mlxsw_sp_fib6_entry_create(struct mlxsw_sp *mlxsw_sp,
++			   struct mlxsw_sp_fib_node *fib_node,
++			   struct rt6_info *rt)
+ {
 -	return lb_rif->ul_vr_id;
 -}
++	struct mlxsw_sp_fib6_entry *fib6_entry;
++>>>>>>> dbe4598c1e92 (mlxsw: spectrum_router: Keep nexthops in a linked list)
 +	struct mlxsw_sp_fib_entry *fib_entry;
 +	struct mlxsw_sp_fib_node *fib_node;
  
 -int mlxsw_sp_rif_dev_ifindex(const struct mlxsw_sp_rif *rif)
 -{
 -	return rif->dev->ifindex;
 -}
 +	if (mlxsw_sp->router.aborted)
 +		return;
  
 -const struct net_device *mlxsw_sp_rif_dev(const struct mlxsw_sp_rif *rif)
 -{
 -	return rif->dev;
 +	fib_entry = mlxsw_sp_fib4_entry_lookup(mlxsw_sp, fen_info);
 +	if (WARN_ON(!fib_entry))
 +		return;
 +	fib_node = fib_entry->fib_node;
 +
 +	mlxsw_sp_fib4_node_entry_unlink(mlxsw_sp, fib_entry);
 +	mlxsw_sp_fib4_entry_destroy(mlxsw_sp, fib_entry);
 +	mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
  }
  
 -static struct mlxsw_sp_rif *
 -mlxsw_sp_rif_create(struct mlxsw_sp *mlxsw_sp,
 -		    const struct mlxsw_sp_rif_params *params)
 +static int mlxsw_sp_router_set_abort_trap(struct mlxsw_sp *mlxsw_sp)
  {
 -	u32 tb_id = l3mdev_fib_table(params->dev);
 -	const struct mlxsw_sp_rif_ops *ops;
 -	struct mlxsw_sp_fid *fid = NULL;
 -	enum mlxsw_sp_rif_type type;
 -	struct mlxsw_sp_rif *rif;
 -	struct mlxsw_sp_vr *vr;
 -	u16 rif_index;
 -	int err;
 -
 -	type = mlxsw_sp_dev_rif_type(mlxsw_sp, params->dev);
 -	ops = mlxsw_sp->router->rif_ops_arr[type];
 -
 -	vr = mlxsw_sp_vr_get(mlxsw_sp, tb_id ? : RT_TABLE_MAIN);
 -	if (IS_ERR(vr))
 -		return ERR_CAST(vr);
 +	char ralta_pl[MLXSW_REG_RALTA_LEN];
 +	char ralst_pl[MLXSW_REG_RALST_LEN];
 +	int i, err;
  
 -	err = mlxsw_sp_rif_index_alloc(mlxsw_sp, &rif_index);
 +	mlxsw_reg_ralta_pack(ralta_pl, true, MLXSW_REG_RALXX_PROTOCOL_IPV4,
 +			     MLXSW_SP_LPM_TREE_MIN);
 +	err = mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ralta), ralta_pl);
  	if (err)
 -		goto err_rif_index_alloc;
 +		return err;
  
 -	rif = mlxsw_sp_rif_alloc(ops->rif_size, rif_index, vr->id, params->dev);
 -	if (!rif) {
 -		err = -ENOMEM;
 -		goto err_rif_alloc;
 -	}
 -	rif->mlxsw_sp = mlxsw_sp;
 -	rif->ops = ops;
 -
 -	if (ops->fid_get) {
 -		fid = ops->fid_get(rif);
 -		if (IS_ERR(fid)) {
 -			err = PTR_ERR(fid);
 -			goto err_fid_get;
 -		}
 -		rif->fid = fid;
 -	}
 +	mlxsw_reg_ralst_pack(ralst_pl, 0xff, MLXSW_SP_LPM_TREE_MIN);
 +	err = mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ralst), ralst_pl);
 +	if (err)
 +		return err;
  
 -	if (ops->setup)
 -		ops->setup(rif, params);
 +	for (i = 0; i < MLXSW_CORE_RES_GET(mlxsw_sp->core, MAX_VRS); i++) {
 +		struct mlxsw_sp_vr *vr = &mlxsw_sp->router.vrs[i];
 +		char raltb_pl[MLXSW_REG_RALTB_LEN];
 +		char ralue_pl[MLXSW_REG_RALUE_LEN];
  
 -	err = ops->configure(rif);
 -	if (err)
 -		goto err_configure;
 +		if (!mlxsw_sp_vr_is_used(vr))
 +			continue;
  
 -	mlxsw_sp_rif_counters_alloc(rif);
 -	mlxsw_sp->router->rifs[rif_index] = rif;
 -	vr->rif_count++;
 +		mlxsw_reg_raltb_pack(raltb_pl, vr->id,
 +				     MLXSW_REG_RALXX_PROTOCOL_IPV4,
 +				     MLXSW_SP_LPM_TREE_MIN);
 +		err = mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(raltb),
 +				      raltb_pl);
 +		if (err)
 +			return err;
  
 -	return rif;
 +		mlxsw_reg_ralue_pack4(ralue_pl, MLXSW_SP_L3_PROTO_IPV4,
 +				      MLXSW_REG_RALUE_OP_WRITE_WRITE, vr->id, 0,
 +				      0);
 +		mlxsw_reg_ralue_act_ip2me_pack(ralue_pl);
 +		err = mlxsw_reg_write(mlxsw_sp->core, MLXSW_REG(ralue),
 +				      ralue_pl);
 +		if (err)
 +			return err;
 +	}
  
 -err_configure:
 -	if (fid)
 -		mlxsw_sp_fid_put(fid);
 -err_fid_get:
 -	kfree(rif);
 -err_rif_alloc:
 -err_rif_index_alloc:
 -	mlxsw_sp_vr_put(vr);
 -	return ERR_PTR(err);
 +	return 0;
  }
  
 -void mlxsw_sp_rif_destroy(struct mlxsw_sp_rif *rif)
 +static void mlxsw_sp_fib4_node_flush(struct mlxsw_sp *mlxsw_sp,
 +				     struct mlxsw_sp_fib_node *fib_node)
  {
 -	const struct mlxsw_sp_rif_ops *ops = rif->ops;
 -	struct mlxsw_sp *mlxsw_sp = rif->mlxsw_sp;
 -	struct mlxsw_sp_fid *fid = rif->fid;
 -	struct mlxsw_sp_vr *vr;
 +	struct mlxsw_sp_fib_entry *fib_entry, *tmp;
  
 -	mlxsw_sp_router_rif_gone_sync(mlxsw_sp, rif);
 -	vr = &mlxsw_sp->router->vrs[rif->vr_id];
 +	list_for_each_entry_safe(fib_entry, tmp, &fib_node->entry_list, list) {
 +		bool do_break = &tmp->list == &fib_node->entry_list;
  
 -	vr->rif_count--;
 -	mlxsw_sp->router->rifs[rif->rif_index] = NULL;
 -	mlxsw_sp_rif_counters_free(rif);
 -	ops->deconfigure(rif);
 -	if (fid)
 -		/* Loopback RIFs are not associated with a FID. */
 -		mlxsw_sp_fid_put(fid);
 -	kfree(rif);
 -	mlxsw_sp_vr_put(vr);
 +		mlxsw_sp_fib4_node_entry_unlink(mlxsw_sp, fib_entry);
 +		mlxsw_sp_fib4_entry_destroy(mlxsw_sp, fib_entry);
 +		mlxsw_sp_fib_node_put(mlxsw_sp, fib_node);
 +		/* Break when entry list is empty and node was freed.
 +		 * Otherwise, we'll access freed memory in the next
 +		 * iteration.
 +		 */
 +		if (do_break)
 +			break;
 +	}
  }
  
 -static void
 -mlxsw_sp_rif_subport_params_init(struct mlxsw_sp_rif_params *params,
 -				 struct mlxsw_sp_port_vlan *mlxsw_sp_port_vlan)
 +static void mlxsw_sp_fib_node_flush(struct mlxsw_sp *mlxsw_sp,
 +				    struct mlxsw_sp_fib_node *fib_node)
  {
 -	struct mlxsw_sp_port *mlxsw_sp_port = mlxsw_sp_port_vlan->mlxsw_sp_port;
 -
 -	params->vid = mlxsw_sp_port_vlan->vid;
 -	params->lag = mlxsw_sp_port->lagged;
 -	if (params->lag)
 -		params->lag_id = mlxsw_sp_port->lag_id;
 -	else
 -		params->system_port = mlxsw_sp_port->local_port;
 +	switch (fib_node->fib->proto) {
 +	case MLXSW_SP_L3_PROTO_IPV4:
 +		mlxsw_sp_fib4_node_flush(mlxsw_sp, fib_node);
 +		break;
 +	case MLXSW_SP_L3_PROTO_IPV6:
 +		WARN_ON_ONCE(1);
 +		break;
 +	}
  }
  
 -static int
 -mlxsw_sp_port_vlan_router_join(struct mlxsw_sp_port_vlan *mlxsw_sp_port_vlan,
 -			       struct net_device *l3_dev)
 +static void mlxsw_sp_vr_fib_flush(struct mlxsw_sp *mlxsw_sp,
 +				  struct mlxsw_sp_vr *vr,
 +				  enum mlxsw_sp_l3proto proto)
  {
 -	struct mlxsw_sp_port *mlxsw_sp_port = mlxsw_sp_port_vlan->mlxsw_sp_port;
 -	struct mlxsw_sp *mlxsw_sp = mlxsw_sp_port->mlxsw_sp;
 -	u16 vid = mlxsw_sp_port_vlan->vid;
 -	struct mlxsw_sp_rif *rif;
 -	struct mlxsw_sp_fid *fid;
 -	int err;
 +	struct mlxsw_sp_fib *fib = mlxsw_sp_vr_fib(vr, proto);
 +	struct mlxsw_sp_fib_node *fib_node, *tmp;
  
 -	rif = mlxsw_sp_rif_find_by_dev(mlxsw_sp, l3_dev);
 -	if (!rif) {
 -		struct mlxsw_sp_rif_params params = {
 -			.dev = l3_dev,
 -		};
 +	list_for_each_entry_safe(fib_node, tmp, &fib->node_list, list) {
 +		bool do_break = &tmp->list == &fib->node_list;
  
 -		mlxsw_sp_rif_subport_params_init(&params, mlxsw_sp_port_vlan);
 -		rif = mlxsw_sp_rif_create(mlxsw_sp, &params);
 -		if (IS_ERR(rif))
 -			return PTR_ERR(rif);
 +		mlxsw_sp_fib_node_flush(mlxsw_sp, fib_node);
 +		if (do_break)
 +			break;
  	}
 +}
  
 -	/* FID was already created, just take a reference */
 -	fid = rif->ops->fid_get(rif);
 -	err = mlxsw_sp_fid_port_vid_map(fid, mlxsw_sp_port, vid);
 -	if (err)
 -		goto err_fid_port_vid_map;
 +static void mlxsw_sp_router_fib_flush(struct mlxsw_sp *mlxsw_sp)
 +{
 +	int i;
 +
 +	for (i = 0; i < MLXSW_CORE_RES_GET(mlxsw_sp->core, MAX_VRS); i++) {
 +		struct mlxsw_sp_vr *vr = &mlxsw_sp->router.vrs[i];
 +
 +		if (!mlxsw_sp_vr_is_used(vr))
 +			continue;
 +		mlxsw_sp_vr_fib_flush(mlxsw_sp, vr, MLXSW_SP_L3_PROTO_IPV4);
 +	}
 +}
  
 -	err = mlxsw_sp_port_vid_learning_set(mlxsw_sp_port, vid, false);
 -	if (err)
 -		goto err_port_vid_learning_set;
 +static void mlxsw_sp_router_fib4_abort(struct mlxsw_sp *mlxsw_sp)
 +{
 +	int err;
  
 -	err = mlxsw_sp_port_vid_stp_set(mlxsw_sp_port, vid,
 -					BR_STATE_FORWARDING);
 +	if (mlxsw_sp->router.aborted)
 +		return;
 +	dev_warn(mlxsw_sp->bus_info->dev, "FIB abort triggered. Note that FIB entries are no longer being offloaded to this device.\n");
 +	mlxsw_sp_router_fib_flush(mlxsw_sp);
 +	mlxsw_sp->router.aborted = true;
 +	err = mlxsw_sp_router_set_abort_trap(mlxsw_sp);
  	if (err)
 -		goto err_port_vid_stp_set;
 +		dev_warn(mlxsw_sp->bus_info->dev, "Failed to set abort trap.\n");
 +}
  
 -	mlxsw_sp_port_vlan->fid = fid;
 +struct mlxsw_sp_fib_event_work {
 +	struct work_struct work;
 +	union {
 +		struct fib_entry_notifier_info fen_info;
 +		struct fib_nh_notifier_info fnh_info;
 +	};
 +	struct mlxsw_sp *mlxsw_sp;
 +	unsigned long event;
 +};
  
 -	return 0;
 +static void mlxsw_sp_router_fib_event_work(struct work_struct *work)
 +{
 +	struct mlxsw_sp_fib_event_work *fib_work =
 +		container_of(work, struct mlxsw_sp_fib_event_work, work);
 +	struct mlxsw_sp *mlxsw_sp = fib_work->mlxsw_sp;
 +	bool replace, append;
 +	int err;
  
 -err_port_vid_stp_set:
 -	mlxsw_sp_port_vid_learning_set(mlxsw_sp_port, vid, true);
 -err_port_vid_learning_set:
 -	mlxsw_sp_fid_port_vid_unmap(fid, mlxsw_sp_port, vid);
 -err_fid_port_vid_map:
 -	mlxsw_sp_fid_put(fid);
 -	return err;
 +	/* Protect internal structures from changes */
 +	rtnl_lock();
 +	switch (fib_work->event) {
 +	case FIB_EVENT_ENTRY_REPLACE: /* fall through */
 +	case FIB_EVENT_ENTRY_APPEND: /* fall through */
 +	case FIB_EVENT_ENTRY_ADD:
 +		replace = fib_work->event == FIB_EVENT_ENTRY_REPLACE;
 +		append = fib_work->event == FIB_EVENT_ENTRY_APPEND;
 +		err = mlxsw_sp_router_fib4_add(mlxsw_sp, &fib_work->fen_info,
 +					       replace, append);
 +		if (err)
 +			mlxsw_sp_router_fib4_abort(mlxsw_sp);
 +		fib_info_put(fib_work->fen_info.fi);
 +		break;
 +	case FIB_EVENT_ENTRY_DEL:
 +		mlxsw_sp_router_fib4_del(mlxsw_sp, &fib_work->fen_info);
 +		fib_info_put(fib_work->fen_info.fi);
 +		break;
 +	case FIB_EVENT_RULE_ADD: /* fall through */
 +	case FIB_EVENT_RULE_DEL:
 +		mlxsw_sp_router_fib4_abort(mlxsw_sp);
 +		break;
 +	case FIB_EVENT_NH_ADD: /* fall through */
 +	case FIB_EVENT_NH_DEL:
 +		mlxsw_sp_nexthop_event(mlxsw_sp, fib_work->event,
 +				       fib_work->fnh_info.fib_nh);
 +		fib_info_put(fib_work->fnh_info.fib_nh->nh_parent);
 +		break;
 +	}
 +	rtnl_unlock();
 +	kfree(fib_work);
  }
  
 -void
 -mlxsw_sp_port_vlan_router_leave(struct mlxsw_sp_port_vlan *mlxsw_sp_port_vlan)
 +/* Called with rcu_read_lock() */
 +static int mlxsw_sp_router_fib_event(struct notifier_block *nb,
 +				     unsigned long event, void *ptr)
  {
 -	struct mlxsw_sp_port *mlxsw_sp_port = mlxsw_sp_port_vlan->mlxsw_sp_port;
 -	struct mlxsw_sp_fid *fid = mlxsw_sp_port_vlan->fid;
 -	u16 vid = mlxsw_sp_port_vlan->vid;
 -
 -	if (WARN_ON(mlxsw_sp_fid_type(fid) != MLXSW_SP_FID_TYPE_RFID))
 -		return;
 +	struct mlxsw_sp *mlxsw_sp = container_of(nb, struct mlxsw_sp, fib_nb);
 +	struct mlxsw_sp_fib_event_work *fib_work;
 +	struct fib_notifier_info *info = ptr;
  
 -	mlxsw_sp_port_vlan->fid = NULL;
 -	mlxsw_sp_port_vid_stp_set(mlxsw_sp_port, vid, BR_STATE_BLOCKING);
 -	mlxsw_sp_port_vid_learning_set(mlxsw_sp_port, vid, true);
 -	mlxsw_sp_fid_port_vid_unmap(fid, mlxsw_sp_port, vid);
 -	/* If router port holds the last reference on the rFID, then the
 -	 * associated Sub-port RIF will be destroyed.
 -	 */
 -	mlxsw_sp_fid_put(fid);
 -}
 +	if (!net_eq(info->net, &init_net) ||
 +	    (info->family != AF_INET && info->family != AF_INET6))
 +		return NOTIFY_DONE;
  
 -static int mlxsw_sp_inetaddr_port_vlan_event(struct net_device *l3_dev,
 -					     struct net_device *port_dev,
 -					     unsigned long event, u16 vid)
 -{
 -	struct mlxsw_sp_port *mlxsw_sp_port = netdev_priv(port_dev);
 -	struct mlxsw_sp_port_vlan *mlxsw_sp_port_vlan;
 +	fib_work = kzalloc(sizeof(*fib_work), GFP_ATOMIC);
 +	if (WARN_ON(!fib_work))
 +		return NOTIFY_BAD;
  
 -	mlxsw_sp_port_vlan = mlxsw_sp_port_vlan_find_by_vid(mlxsw_sp_port, vid);
 -	if (WARN_ON(!mlxsw_sp_port_vlan))
 -		return -EINVAL;
 +	INIT_WORK(&fib_work->work, mlxsw_sp_router_fib_event_work);
 +	fib_work->mlxsw_sp = mlxsw_sp;
 +	fib_work->event = event;
  
  	switch (event) {
 -	case NETDEV_UP:
 -		return mlxsw_sp_port_vlan_router_join(mlxsw_sp_port_vlan,
 -						      l3_dev);
 -	case NETDEV_DOWN:
 -		mlxsw_sp_port_vlan_router_leave(mlxsw_sp_port_vlan);
 +	case FIB_EVENT_ENTRY_REPLACE: /* fall through */
 +	case FIB_EVENT_ENTRY_APPEND: /* fall through */
 +	case FIB_EVENT_ENTRY_ADD: /* fall through */
 +	case FIB_EVENT_ENTRY_DEL:
 +		memcpy(&fib_work->fen_info, ptr, sizeof(fib_work->fen_info));
 +		/* Take referece on fib_info to prevent it from being
 +		 * freed while work is queued. Release it afterwards.
 +		 */
 +		fib_info_hold(fib_work->fen_info.fi);
 +		break;
 +	case FIB_EVENT_NH_ADD: /* fall through */
 +	case FIB_EVENT_NH_DEL:
 +		memcpy(&fib_work->fnh_info, ptr, sizeof(fib_work->fnh_info));
 +		fib_info_hold(fib_work->fnh_info.fib_nh->nh_parent);
  		break;
  	}
  
* Unmerged path drivers/net/ethernet/mellanox/mlxsw/spectrum_router.c
