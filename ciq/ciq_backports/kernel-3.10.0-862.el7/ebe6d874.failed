nvme: move protection information check into nvme_setup_rw

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [nvme] move protection information check into nvme_setup_rw (David Milburn) [1457880 1456486 1454365]
Rebuild_FUZZ: 94.55%
commit-author Christoph Hellwig <hch@lst.de>
commit ebe6d874cdb27d47f506a43ea95f1c0ef03aa246
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/ebe6d874.failed

It only applies to read/write commands, and this way non-PCIe drivers
get the check as well instead of having to duplicate it when adding
metadata support.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Keith Busch <keith.busch@intel.com>
	Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
(cherry picked from commit ebe6d874cdb27d47f506a43ea95f1c0ef03aa246)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/core.c
#	drivers/nvme/host/pci.c
diff --cc drivers/nvme/host/core.c
index f3660f9b6cc7,b14c3ea7e6c4..000000000000
--- a/drivers/nvme/host/core.c
+++ b/drivers/nvme/host/core.c
@@@ -258,26 -314,19 +258,26 @@@ static inline int nvme_setup_discard(st
  	memset(cmnd, 0, sizeof(*cmnd));
  	cmnd->dsm.opcode = nvme_cmd_dsm;
  	cmnd->dsm.nsid = cpu_to_le32(ns->ns_id);
 -	cmnd->dsm.nr = cpu_to_le32(segments - 1);
 +	cmnd->dsm.nr = 0;
  	cmnd->dsm.attributes = cpu_to_le32(NVME_DSMGMT_AD);
  
 -	req->special_vec.bv_page = virt_to_page(range);
 -	req->special_vec.bv_offset = offset_in_page(range);
 -	req->special_vec.bv_len = sizeof(*range) * segments;
 -	req->rq_flags |= RQF_SPECIAL_PAYLOAD;
 +	req->completion_data = range;
 +	page = virt_to_page(range);
 +	offset = offset_in_page(range);
 +	blk_add_request_payload(req, page, offset, sizeof(*range));
  
 -	return BLK_STS_OK;
 +	/*
 +	 * we set __data_len back to the size of the area to be discarded
 +	 * on disk. This allows us to report completion on the full amount
 +	 * of blocks described by the request.
 +	 */
 +	req->__data_len = nr_bytes;
 +
 +	return BLK_MQ_RQ_QUEUE_OK;
  }
  
- static inline void nvme_setup_rw(struct nvme_ns *ns, struct request *req,
- 		struct nvme_command *cmnd)
+ static inline blk_status_t nvme_setup_rw(struct nvme_ns *ns,
+ 		struct request *req, struct nvme_command *cmnd)
  {
  	u16 control = 0;
  	u32 dsmgmt = 0;
@@@ -303,24 -373,43 +312,37 @@@
  
  	cmnd->rw.control = cpu_to_le16(control);
  	cmnd->rw.dsmgmt = cpu_to_le32(dsmgmt);
+ 	return 0;
  }
  
 -blk_status_t nvme_setup_cmd(struct nvme_ns *ns, struct request *req,
 +int nvme_setup_cmd(struct nvme_ns *ns, struct request *req,
  		struct nvme_command *cmd)
  {
 -	blk_status_t ret = BLK_STS_OK;
 -
 -	if (!(req->rq_flags & RQF_DONTPREP)) {
 -		nvme_req(req)->retries = 0;
 -		nvme_req(req)->flags = 0;
 -		req->rq_flags |= RQF_DONTPREP;
 -	}
 +	int ret = BLK_MQ_RQ_QUEUE_OK;
  
 -	switch (req_op(req)) {
 -	case REQ_OP_DRV_IN:
 -	case REQ_OP_DRV_OUT:
 +	if (req->cmd_type == REQ_TYPE_DRV_PRIV)
  		memcpy(cmd, nvme_req(req)->cmd, sizeof(*cmd));
 -		break;
 -	case REQ_OP_FLUSH:
 +	else if (req->cmd_flags & REQ_FLUSH)
  		nvme_setup_flush(ns, cmd);
 -		break;
 -	case REQ_OP_WRITE_ZEROES:
 -		/* currently only aliased to deallocate for a few ctrls: */
 -	case REQ_OP_DISCARD:
 +	else if (req->cmd_flags & REQ_DISCARD)
  		ret = nvme_setup_discard(ns, req, cmd);
++<<<<<<< HEAD
 +	else
 +		nvme_setup_rw(ns, req, cmd);
++=======
+ 		break;
+ 	case REQ_OP_READ:
+ 	case REQ_OP_WRITE:
+ 		ret = nvme_setup_rw(ns, req, cmd);
+ 		break;
+ 	default:
+ 		WARN_ON_ONCE(1);
+ 		return BLK_STS_IOERR;
+ 	}
++>>>>>>> ebe6d874cdb2 (nvme: move protection information check into nvme_setup_rw)
  
  	cmd->common.command_id = req->tag;
 +
  	return ret;
  }
  EXPORT_SYMBOL_GPL(nvme_setup_cmd);
diff --cc drivers/nvme/host/pci.c
index f136fc3284bb,60e1088f487e..000000000000
--- a/drivers/nvme/host/pci.c
+++ b/drivers/nvme/host/pci.c
@@@ -507,36 -694,21 +507,40 @@@ static int nvme_queue_rq(struct blk_mq_
  	struct nvme_dev *dev = nvmeq->dev;
  	struct request *req = bd->rq;
  	struct nvme_command cmnd;
++<<<<<<< HEAD
 +	unsigned map_len;
 +	int ret = BLK_MQ_RQ_QUEUE_OK;
 +
 +	/*
 +	 * If formated with metadata, require the block layer provide a buffer
 +	 * unless this namespace is formated such that the metadata can be
 +	 * stripped/generated by the controller with PRACT=1.
 +	 */
 +	if (ns && ns->ms && !blk_integrity_rq(req)) {
 +		if (!(ns->pi_type && ns->ms == 8) &&
 +					req->cmd_type != REQ_TYPE_DRV_PRIV) {
 +			blk_mq_end_request(req, -EFAULT);
 +			return BLK_MQ_RQ_QUEUE_OK;
 +		}
 +	}
++=======
+ 	blk_status_t ret;
++>>>>>>> ebe6d874cdb2 (nvme: move protection information check into nvme_setup_rw)
  
 -	ret = nvme_setup_cmd(ns, req, &cmnd);
 -	if (ret)
 +	map_len = nvme_map_len(req);
 +	ret = nvme_init_iod(req, map_len, dev);
 +	if (ret != BLK_MQ_RQ_QUEUE_OK)
  		return ret;
  
 -	ret = nvme_init_iod(req, dev);
 -	if (ret)
 -		goto out_free_cmd;
 +	ret = nvme_setup_cmd(ns, req, &cmnd);
 +	if (ret != BLK_MQ_RQ_QUEUE_OK)
 +		goto out;
 +
 +	if (req->nr_phys_segments)
 +		ret = nvme_map_data(dev, req, map_len, &cmnd);
  
 -	if (blk_rq_nr_phys_segments(req)) {
 -		ret = nvme_map_data(dev, req, &cmnd);
 -		if (ret)
 -			goto out_cleanup_iod;
 -	}
 +	if (ret != BLK_MQ_RQ_QUEUE_OK)
 +		goto out;
  
  	blk_mq_start_request(req);
  
* Unmerged path drivers/nvme/host/core.c
* Unmerged path drivers/nvme/host/pci.c
