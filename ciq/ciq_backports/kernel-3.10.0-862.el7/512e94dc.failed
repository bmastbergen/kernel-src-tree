nfp: use dp to carry number of stack tx rings and vectors

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Jakub Kicinski <jakub.kicinski@netronome.com>
commit 512e94dc3229a824190e310c899a3f6d08216477
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/512e94dc.failed

Instead of passing variables around use dp to store number of tx rings
for the stack and number of IRQ vectors.

	Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 512e94dc3229a824190e310c899a3f6d08216477)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/netronome/nfp/nfp_net_common.c
diff --cc drivers/net/ethernet/netronome/nfp/nfp_net_common.c
index e0a7eb1db7a9,52f0e9dfd15a..000000000000
--- a/drivers/net/ethernet/netronome/nfp/nfp_net_common.c
+++ b/drivers/net/ethernet/netronome/nfp/nfp_net_common.c
@@@ -1551,7 -1785,8 +1551,12 @@@ err_alloc
  }
  
  static struct nfp_net_tx_ring *
++<<<<<<< HEAD
 +nfp_net_tx_ring_set_prepare(struct nfp_net *nn, struct nfp_net_ring_set *s)
++=======
+ nfp_net_tx_ring_set_prepare(struct nfp_net *nn, struct nfp_net_dp *dp,
+ 			    struct nfp_net_ring_set *s)
++>>>>>>> 512e94dc3229 (nfp: use dp to carry number of stack tx rings and vectors)
  {
  	struct nfp_net_tx_ring *rings;
  	unsigned int r;
@@@ -1561,9 -1796,14 +1566,18 @@@
  		return NULL;
  
  	for (r = 0; r < s->n_rings; r++) {
 -		int bias = 0;
 +		nfp_net_tx_ring_init(&rings[r], &nn->r_vecs[r], r);
  
++<<<<<<< HEAD
 +		if (nfp_net_tx_ring_alloc(&rings[r], s->dcnt))
++=======
+ 		if (r >= dp->num_stack_tx_rings)
+ 			bias = dp->num_stack_tx_rings;
+ 
+ 		nfp_net_tx_ring_init(&rings[r], &nn->r_vecs[r - bias], r);
+ 
+ 		if (nfp_net_tx_ring_alloc(&rings[r], s->dcnt, bias))
++>>>>>>> 512e94dc3229 (nfp: use dp to carry number of stack tx rings and vectors)
  			goto err_free_prev;
  	}
  
@@@ -2063,8 -2303,8 +2077,13 @@@ static int nfp_net_netdev_open(struct n
  		goto err_cleanup_vec;
  	}
  
++<<<<<<< HEAD
 +	nn->tx_rings = nfp_net_tx_ring_set_prepare(nn, &tx);
 +	if (!nn->tx_rings) {
++=======
+ 	nn->dp.tx_rings = nfp_net_tx_ring_set_prepare(nn, &nn->dp, &tx);
+ 	if (!nn->dp.tx_rings) {
++>>>>>>> 512e94dc3229 (nfp: use dp to carry number of stack tx rings and vectors)
  		err = -ENOMEM;
  		goto err_free_rx_rings;
  	}
@@@ -2220,11 -2461,20 +2239,24 @@@ static void nfp_net_rss_init_itbl(struc
  
  	for (i = 0; i < sizeof(nn->rss_itbl); i++)
  		nn->rss_itbl[i] =
 -			ethtool_rxfh_indir_default(i, nn->dp.num_rx_rings);
 +			ethtool_rxfh_indir_default(i, nn->num_rx_rings);
  }
  
+ static void nfp_net_dp_swap(struct nfp_net *nn, struct nfp_net_dp *dp)
+ {
+ 	struct nfp_net_dp new_dp = *dp;
+ 
+ 	*dp = nn->dp;
+ 	nn->dp = new_dp;
+ }
+ 
  static int
++<<<<<<< HEAD
 +nfp_net_ring_swap_enable(struct nfp_net *nn, unsigned int *num_vecs,
++=======
+ nfp_net_ring_swap_enable(struct nfp_net *nn, struct nfp_net_dp *dp,
+ 			 struct bpf_prog **xdp_prog,
++>>>>>>> 512e94dc3229 (nfp: use dp to carry number of stack tx rings and vectors)
  			 struct nfp_net_ring_set *rx,
  			 struct nfp_net_ring_set *tx)
  {
@@@ -2236,16 -2486,17 +2268,22 @@@
  	if (tx)
  		nfp_net_tx_ring_set_swap(nn, tx);
  
++<<<<<<< HEAD
 +	swap(*num_vecs, nn->num_r_vecs);
++=======
+ 	swap(dp->num_r_vecs, nn->dp.num_r_vecs);
+ 	swap(dp->num_stack_tx_rings, nn->dp.num_stack_tx_rings);
+ 	*xdp_prog = xchg(&nn->dp.xdp_prog, *xdp_prog);
++>>>>>>> 512e94dc3229 (nfp: use dp to carry number of stack tx rings and vectors)
  
  	for (r = 0; r <	nn->max_r_vecs; r++)
 -		nfp_net_vector_assign_rings(&nn->dp, &nn->r_vecs[r], r);
 +		nfp_net_vector_assign_rings(nn, &nn->r_vecs[r], r);
  
 -	if (!netif_is_rxfh_configured(nn->dp.netdev))
 +	if (!netif_is_rxfh_configured(nn->netdev))
  		nfp_net_rss_init_itbl(nn);
  
 -	err = netif_set_real_num_rx_queues(nn->dp.netdev, nn->dp.num_rx_rings);
 +	err = netif_set_real_num_rx_queues(nn->netdev,
 +					   nn->num_rx_rings);
  	if (err)
  		return err;
  
@@@ -2259,44 -2510,96 +2297,83 @@@
  	return __nfp_net_set_config_and_enable(nn);
  }
  
 -struct nfp_net_dp *nfp_net_clone_dp(struct nfp_net *nn)
 -{
 -	struct nfp_net_dp *new;
 -
 -	new = kmalloc(sizeof(*new), GFP_KERNEL);
 -	if (!new)
 -		return NULL;
 -
 -	*new = nn->dp;
 -
 -	/* Clear things which need to be recomputed */
 -	new->fl_bufsz = 0;
 -	new->tx_rings = NULL;
 -	new->rx_rings = NULL;
 -	new->num_r_vecs = 0;
 -	new->num_stack_tx_rings = 0;
 -
 -	return new;
 -}
 -
 -static int
 -nfp_net_check_config(struct nfp_net *nn, struct nfp_net_dp *dp,
 -		     struct bpf_prog *xdp_prog,
 -		     struct nfp_net_ring_set *rx, struct nfp_net_ring_set *tx)
 -{
 -	/* XDP-enabled tests */
 -	if (!xdp_prog)
 -		return 0;
 -	if (rx && nfp_net_calc_fl_bufsz(dp, rx->mtu) > PAGE_SIZE) {
 -		nn_warn(nn, "MTU too large w/ XDP enabled\n");
 -		return -EINVAL;
 -	}
 -	if (tx && tx->n_rings > nn->max_tx_rings) {
 -		nn_warn(nn, "Insufficient number of TX rings w/ XDP enabled\n");
 -		return -EINVAL;
 -	}
 -
 -	return 0;
 -}
 -
  static void
 -nfp_net_ring_reconfig_down(struct nfp_net *nn, struct nfp_net_dp *dp,
 -			   struct bpf_prog **xdp_prog,
 +nfp_net_ring_reconfig_down(struct nfp_net *nn,
  			   struct nfp_net_ring_set *rx,
++<<<<<<< HEAD
 +			   struct nfp_net_ring_set *tx,
 +			   unsigned int num_vecs)
 +{
 +	nn->netdev->mtu = rx ? rx->mtu : nn->netdev->mtu;
 +	nn->fl_bufsz = nfp_net_calc_fl_bufsz(nn, nn->netdev->mtu);
 +	nn->rxd_cnt = rx ? rx->dcnt : nn->rxd_cnt;
 +	nn->txd_cnt = tx ? tx->dcnt : nn->txd_cnt;
 +	nn->num_rx_rings = rx ? rx->n_rings : nn->num_rx_rings;
 +	nn->num_tx_rings = tx ? tx->n_rings : nn->num_tx_rings;
 +	nn->num_r_vecs = num_vecs;
++=======
+ 			   struct nfp_net_ring_set *tx)
+ {
+ 	nfp_net_dp_swap(nn, dp);
+ 
+ 	nn->dp.netdev->mtu = rx ? rx->mtu : nn->dp.netdev->mtu;
+ 	nn->dp.fl_bufsz = nfp_net_calc_fl_bufsz(&nn->dp, nn->dp.netdev->mtu);
+ 	nn->dp.rxd_cnt = rx ? rx->dcnt : nn->dp.rxd_cnt;
+ 	nn->dp.txd_cnt = tx ? tx->dcnt : nn->dp.txd_cnt;
+ 	nn->dp.num_rx_rings = rx ? rx->n_rings : nn->dp.num_rx_rings;
+ 	nn->dp.num_tx_rings = tx ? tx->n_rings : nn->dp.num_tx_rings;
+ 	*xdp_prog = xchg(&nn->dp.xdp_prog, *xdp_prog);
++>>>>>>> 512e94dc3229 (nfp: use dp to carry number of stack tx rings and vectors)
  
 -	if (!netif_is_rxfh_configured(nn->dp.netdev))
 +	if (!netif_is_rxfh_configured(nn->netdev))
  		nfp_net_rss_init_itbl(nn);
  }
  
  int
 -nfp_net_ring_reconfig(struct nfp_net *nn, struct nfp_net_dp *dp,
 -		      struct bpf_prog **xdp_prog,
 -		      struct nfp_net_ring_set *rx, struct nfp_net_ring_set *tx)
 +nfp_net_ring_reconfig(struct nfp_net *nn, struct nfp_net_ring_set *rx,
 +		      struct nfp_net_ring_set *tx)
  {
++<<<<<<< HEAD
 +	unsigned int num_vecs, r;
 +	int err;
 +
 +	num_vecs = max(rx ? rx->n_rings : nn->num_rx_rings,
 +		       tx ? tx->n_rings : nn->num_tx_rings);
 +
 +	if (!netif_running(nn->netdev)) {
 +		nfp_net_ring_reconfig_down(nn, rx, tx, num_vecs);
 +		return 0;
 +	}
 +
 +	/* Prepare new rings */
 +	for (r = nn->num_r_vecs; r < num_vecs; r++) {
++=======
+ 	int r, err;
+ 
+ 	dp->num_stack_tx_rings = tx ? tx->n_rings : dp->num_tx_rings;
+ 	if (*xdp_prog)
+ 		dp->num_stack_tx_rings -= rx ? rx->n_rings : dp->num_rx_rings;
+ 
+ 	dp->num_r_vecs = max(rx ? rx->n_rings : dp->num_rx_rings,
+ 			     dp->num_stack_tx_rings);
+ 
+ 	err = nfp_net_check_config(nn, dp, *xdp_prog, rx, tx);
+ 	if (err)
+ 		goto exit_free_dp;
+ 
+ 	if (!netif_running(dp->netdev)) {
+ 		nfp_net_ring_reconfig_down(nn, dp, xdp_prog, rx, tx);
+ 
+ 		err = 0;
+ 		goto exit_free_dp;
+ 	}
+ 
+ 	/* Prepare new rings */
+ 	for (r = nn->dp.num_r_vecs; r < dp->num_r_vecs; r++) {
++>>>>>>> 512e94dc3229 (nfp: use dp to carry number of stack tx rings and vectors)
  		err = nfp_net_prepare_vector(nn, &nn->r_vecs[r], r);
  		if (err) {
- 			num_vecs = r;
+ 			dp->num_r_vecs = r;
  			goto err_cleanup_vecs;
  		}
  	}
@@@ -2307,7 -2610,7 +2384,11 @@@
  		}
  	}
  	if (tx) {
++<<<<<<< HEAD
 +		if (!nfp_net_tx_ring_set_prepare(nn, tx)) {
++=======
+ 		if (!nfp_net_tx_ring_set_prepare(nn, dp, tx)) {
++>>>>>>> 512e94dc3229 (nfp: use dp to carry number of stack tx rings and vectors)
  			err = -ENOMEM;
  			goto err_free_rx;
  		}
@@@ -2317,19 -2620,19 +2398,31 @@@
  	nfp_net_close_stack(nn);
  	nfp_net_clear_config_and_disable(nn);
  
++<<<<<<< HEAD
 +	err = nfp_net_ring_swap_enable(nn, &num_vecs, rx, tx);
++=======
+ 	err = nfp_net_ring_swap_enable(nn, dp, xdp_prog, rx, tx);
++>>>>>>> 512e94dc3229 (nfp: use dp to carry number of stack tx rings and vectors)
  	if (err) {
  		int err2;
  
  		nfp_net_clear_config_and_disable(nn);
  
  		/* Try with old configuration and old rings */
++<<<<<<< HEAD
 +		err2 = nfp_net_ring_swap_enable(nn, &num_vecs, rx, tx);
++=======
+ 		err2 = nfp_net_ring_swap_enable(nn, dp, xdp_prog, rx, tx);
++>>>>>>> 512e94dc3229 (nfp: use dp to carry number of stack tx rings and vectors)
  		if (err2)
  			nn_err(nn, "Can't restore ring config - FW communication failed (%d,%d)\n",
  			       err, err2);
  	}
++<<<<<<< HEAD
 +	for (r = num_vecs - 1; r >= nn->num_r_vecs; r--)
++=======
+ 	for (r = dp->num_r_vecs - 1; r >= nn->dp.num_r_vecs; r--)
++>>>>>>> 512e94dc3229 (nfp: use dp to carry number of stack tx rings and vectors)
  		nfp_net_cleanup_vector(nn, &nn->r_vecs[r]);
  
  	if (rx)
@@@ -2343,10 -2648,11 +2436,14 @@@
  
  err_free_rx:
  	if (rx)
 -		nfp_net_rx_ring_set_free(dp, rx, *xdp_prog);
 +		nfp_net_rx_ring_set_free(nn, rx);
  err_cleanup_vecs:
++<<<<<<< HEAD
 +	for (r = num_vecs - 1; r >= nn->num_r_vecs; r--)
++=======
+ 	for (r = dp->num_r_vecs - 1; r >= nn->dp.num_r_vecs; r--)
++>>>>>>> 512e94dc3229 (nfp: use dp to carry number of stack tx rings and vectors)
  		nfp_net_cleanup_vector(nn, &nn->r_vecs[r]);
 -	kfree(dp);
  	return err;
  }
  
* Unmerged path drivers/net/ethernet/netronome/nfp/nfp_net_common.c
