net_sched: get rid of tcfa_rcu

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Cong Wang <xiyou.wangcong@gmail.com>
commit d7fb60b9cafb982cb2e46a267646a8dfd4f2e5da
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/d7fb60b9.failed

gen estimator has been rewritten in commit 1c0d32fde5bd
("net_sched: gen_estimator: complete rewrite of rate estimators"),
the caller is no longer needed to wait for a grace period.
So this patch gets rid of it.

This also completely closes a race condition between action free
path and filter chain add/remove path for the following patch.
Because otherwise the nested RCU callback can't be caught by
rcu_barrier().

Please see also the comments in code.

	Cc: Jiri Pirko <jiri@mellanox.com>
	Cc: Jamal Hadi Salim <jhs@mojatatu.com>
	Cc: Eric Dumazet <edumazet@google.com>
	Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit d7fb60b9cafb982cb2e46a267646a8dfd4f2e5da)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/act_api.h
#	net/sched/act_api.c
diff --cc include/net/act_api.h
index 7eba1aba336b,b944e0eb93be..000000000000
--- a/include/net/act_api.h
+++ b/include/net/act_api.h
@@@ -7,64 -7,48 +7,104 @@@
  
  #include <net/sch_generic.h>
  #include <net/pkt_sched.h>
 -#include <net/net_namespace.h>
 -#include <net/netns/generic.h>
  
++<<<<<<< HEAD
 +struct tcf_common {
 +	struct hlist_node		tcfc_head;
 +	u32				tcfc_index;
 +	int				tcfc_refcnt;
 +	int				tcfc_bindcnt;
 +	u32				tcfc_capab;
 +	int				tcfc_action;
 +	struct tcf_t			tcfc_tm;
 +	struct gnet_stats_basic_packed	tcfc_bstats;
 +	struct gnet_stats_queue		tcfc_qstats;
 +	struct gnet_stats_rate_est64	tcfc_rate_est;
 +	spinlock_t			tcfc_lock;
 +	struct rcu_head			tcfc_rcu;
++=======
+ struct tcf_idrinfo {
+ 	spinlock_t	lock;
+ 	struct idr	action_idr;
+ };
+ 
+ struct tc_action_ops;
+ 
+ struct tc_action {
+ 	const struct tc_action_ops	*ops;
+ 	__u32				type; /* for backward compat(TCA_OLD_COMPAT) */
+ 	__u32				order;
+ 	struct list_head		list;
+ 	struct tcf_idrinfo		*idrinfo;
+ 
+ 	u32				tcfa_index;
+ 	int				tcfa_refcnt;
+ 	int				tcfa_bindcnt;
+ 	u32				tcfa_capab;
+ 	int				tcfa_action;
+ 	struct tcf_t			tcfa_tm;
+ 	struct gnet_stats_basic_packed	tcfa_bstats;
+ 	struct gnet_stats_queue		tcfa_qstats;
+ 	struct net_rate_estimator __rcu *tcfa_rate_est;
+ 	spinlock_t			tcfa_lock;
++>>>>>>> d7fb60b9cafb (net_sched: get rid of tcfa_rcu)
  	struct gnet_stats_basic_cpu __percpu *cpu_bstats;
  	struct gnet_stats_queue __percpu *cpu_qstats;
  	struct tc_cookie	*act_cookie;
 -	struct tcf_chain	*goto_chain;
  };
++<<<<<<< HEAD
 +#define tcf_head	common.tcfc_head
 +#define tcf_index	common.tcfc_index
 +#define tcf_refcnt	common.tcfc_refcnt
 +#define tcf_bindcnt	common.tcfc_bindcnt
 +#define tcf_capab	common.tcfc_capab
 +#define tcf_action	common.tcfc_action
 +#define tcf_tm		common.tcfc_tm
 +#define tcf_bstats	common.tcfc_bstats
 +#define tcf_qstats	common.tcfc_qstats
 +#define tcf_rate_est	common.tcfc_rate_est
 +#define tcf_lock	common.tcfc_lock
 +#define tcf_rcu		common.tcfc_rcu
 +
 +struct tcf_hashinfo {
 +	struct hlist_head	*htab;
 +	unsigned int		hmask;
 +	spinlock_t		lock;
 +	u32			index;
 +};
 +
 +static inline unsigned int tcf_hash(u32 index, unsigned int hmask)
 +{
 +	return index & hmask;
 +}
 +
 +static inline int tcf_hashinfo_init(struct tcf_hashinfo *hf, unsigned int mask)
 +{
 +	int i;
 +
 +	spin_lock_init(&hf->lock);
 +	hf->index = 0;
 +	hf->hmask = mask;
 +	hf->htab = kzalloc((mask + 1) * sizeof(struct hlist_head),
 +			   GFP_KERNEL);
 +	if (!hf->htab)
 +		return -ENOMEM;
 +	for (i = 0; i < mask + 1; i++)
 +		INIT_HLIST_HEAD(&hf->htab[i]);
 +	return 0;
 +}
++=======
+ #define tcf_index	common.tcfa_index
+ #define tcf_refcnt	common.tcfa_refcnt
+ #define tcf_bindcnt	common.tcfa_bindcnt
+ #define tcf_capab	common.tcfa_capab
+ #define tcf_action	common.tcfa_action
+ #define tcf_tm		common.tcfa_tm
+ #define tcf_bstats	common.tcfa_bstats
+ #define tcf_qstats	common.tcfa_qstats
+ #define tcf_rate_est	common.tcfa_rate_est
+ #define tcf_lock	common.tcfa_lock
++>>>>>>> d7fb60b9cafb (net_sched: get rid of tcfa_rcu)
  
  /* Update lastuse only if needed, to avoid dirtying a cache line.
   * We use a temp variable to avoid fetching jiffies twice.
diff --cc net/sched/act_api.c
index f6d266c05d33,fcd7dc7b807a..000000000000
--- a/net/sched/act_api.c
+++ b/net/sched/act_api.c
@@@ -28,10 -28,38 +28,45 @@@
  #include <net/act_api.h>
  #include <net/netlink.h>
  
++<<<<<<< HEAD
 +static void free_tcf(struct rcu_head *head)
 +{
 +	struct tcf_common *p = container_of(head, struct tcf_common, tcfc_rcu);
 +
++=======
+ static int tcf_action_goto_chain_init(struct tc_action *a, struct tcf_proto *tp)
+ {
+ 	u32 chain_index = a->tcfa_action & TC_ACT_EXT_VAL_MASK;
+ 
+ 	if (!tp)
+ 		return -EINVAL;
+ 	a->goto_chain = tcf_chain_get(tp->chain->block, chain_index, true);
+ 	if (!a->goto_chain)
+ 		return -ENOMEM;
+ 	return 0;
+ }
+ 
+ static void tcf_action_goto_chain_fini(struct tc_action *a)
+ {
+ 	tcf_chain_put(a->goto_chain);
+ }
+ 
+ static void tcf_action_goto_chain_exec(const struct tc_action *a,
+ 				       struct tcf_result *res)
+ {
+ 	const struct tcf_chain *chain = a->goto_chain;
+ 
+ 	res->goto_tp = rcu_dereference_bh(chain->filter_chain);
+ }
+ 
+ /* XXX: For standalone actions, we don't need a RCU grace period either, because
+  * actions are always connected to filters and filters are already destroyed in
+  * RCU callbacks, so after a RCU grace period actions are already disconnected
+  * from filters. Readers later can not find us.
+  */
+ static void free_tcf(struct tc_action *p)
+ {
++>>>>>>> d7fb60b9cafb (net_sched: get rid of tcfa_rcu)
  	free_percpu(p->cpu_bstats);
  	free_percpu(p->cpu_qstats);
  
@@@ -43,26 -73,17 +78,34 @@@
  	kfree(p);
  }
  
 -static void tcf_idr_remove(struct tcf_idrinfo *idrinfo, struct tc_action *p)
 +static void tcf_hash_destroy(struct tc_action *a)
  {
++<<<<<<< HEAD
 +	struct tcf_common *p = a->priv;
 +	struct tcf_hashinfo *hinfo = a->ops->hinfo;
 +
 +	spin_lock_bh(&hinfo->lock);
 +	hlist_del(&p->tcfc_head);
 +	spin_unlock_bh(&hinfo->lock);
 +	gen_kill_estimator(&p->tcfc_bstats,
 +			   &p->tcfc_rate_est);
 +	/*
 +	 * gen_estimator est_timer() might access p->tcfc_lock
 +	 * or bstats, wait a RCU grace period before freeing p
 +	 */
 +	call_rcu(&p->tcfc_rcu, free_tcf);
++=======
+ 	spin_lock_bh(&idrinfo->lock);
+ 	idr_remove_ext(&idrinfo->action_idr, p->tcfa_index);
+ 	spin_unlock_bh(&idrinfo->lock);
+ 	gen_kill_estimator(&p->tcfa_rate_est);
+ 	free_tcf(p);
++>>>>>>> d7fb60b9cafb (net_sched: get rid of tcfa_rcu)
  }
  
 -int __tcf_idr_release(struct tc_action *p, bool bind, bool strict)
 +int __tcf_hash_release(struct tc_action *a, bool bind, bool strict)
  {
 +	struct tcf_common *p = a->priv;
  	int ret = 0;
  
  	if (p) {
@@@ -223,39 -235,42 +266,44 @@@ int tcf_hash_search(struct tc_action *a
  	}
  	return 0;
  }
 -EXPORT_SYMBOL(tcf_idr_search);
 +EXPORT_SYMBOL(tcf_hash_search);
  
 -bool tcf_idr_check(struct tc_action_net *tn, u32 index, struct tc_action **a,
 -		   int bind)
 +int tcf_hash_check(u32 index, struct tc_action *a, int bind)
  {
 -	struct tcf_idrinfo *idrinfo = tn->idrinfo;
 -	struct tc_action *p = tcf_idr_lookup(index, idrinfo);
 -
 -	if (index && p) {
 +	struct tcf_hashinfo *hinfo = a->ops->hinfo;
 +	struct tcf_common *p = NULL;
 +	if (index && (p = tcf_hash_lookup(index, hinfo)) != NULL) {
  		if (bind)
 -			p->tcfa_bindcnt++;
 -		p->tcfa_refcnt++;
 -		*a = p;
 -		return true;
 +			p->tcfc_bindcnt++;
 +		p->tcfc_refcnt++;
 +		a->priv = p;
 +		return 1;
  	}
 -	return false;
 +	return 0;
  }
 -EXPORT_SYMBOL(tcf_idr_check);
 +EXPORT_SYMBOL(tcf_hash_check);
  
 -void tcf_idr_cleanup(struct tc_action *a, struct nlattr *est)
 +void tcf_hash_cleanup(struct tc_action *a, struct nlattr *est)
  {
 +	struct tcf_common *pc = a->priv;
  	if (est)
++<<<<<<< HEAD
 +		gen_kill_estimator(&pc->tcfc_bstats,
 +				   &pc->tcfc_rate_est);
 +	call_rcu(&pc->tcfc_rcu, free_tcf);
++=======
+ 		gen_kill_estimator(&a->tcfa_rate_est);
+ 	free_tcf(a);
++>>>>>>> d7fb60b9cafb (net_sched: get rid of tcfa_rcu)
  }
 -EXPORT_SYMBOL(tcf_idr_cleanup);
 +EXPORT_SYMBOL(tcf_hash_cleanup);
  
 -int tcf_idr_create(struct tc_action_net *tn, u32 index, struct nlattr *est,
 -		   struct tc_action **a, const struct tc_action_ops *ops,
 -		   int bind, bool cpustats)
 +int tcf_hash_create(u32 index, struct nlattr *est, struct tc_action *a,
 +		    int size, int bind, bool cpustats)
  {
 -	struct tc_action *p = kzalloc(ops->size, GFP_KERNEL);
 -	struct tcf_idrinfo *idrinfo = tn->idrinfo;
 -	struct idr *idr = &idrinfo->action_idr;
 +	struct tcf_hashinfo *hinfo = a->ops->hinfo;
 +	struct tcf_common *p = kzalloc(size, GFP_KERNEL);
  	int err = -ENOMEM;
 -	unsigned long idr_index;
  
  	if (unlikely(!p))
  		return -ENOMEM;
* Unmerged path include/net/act_api.h
* Unmerged path net/sched/act_api.c
