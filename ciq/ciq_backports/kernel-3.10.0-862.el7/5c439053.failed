cpufreq: intel_pstate: Initialize pid_params statically

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [cpufreq] intel_pstate: Initialize pid_params statically (Prarit Bhargava) [1465349]
Rebuild_FUZZ: 91.09%
commit-author Rafael J. Wysocki <rafael.j.wysocki@intel.com>
commit 5c43905369bb85fd518363e743b68e2407d83f7c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/5c439053.failed

Notice that both the existing struct cpu_defaults instances in which
PID parameters are actually initialized use the same values of those
parameters, so it is not really necessary to copy them over to
pid_params dynamically.

Instead, initialize pid_params statically with those values and
drop the unused pid_policy member from struct cpu_defaults along
with copy_pid_params() used for initializing it.

	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
(cherry picked from commit 5c43905369bb85fd518363e743b68e2407d83f7c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/intel_pstate.c
diff --cc drivers/cpufreq/intel_pstate.c
index 9b85edc571c0,01f8f289b882..000000000000
--- a/drivers/cpufreq/intel_pstate.c
+++ b/drivers/cpufreq/intel_pstate.c
@@@ -262,9 -330,21 +260,18 @@@ struct cpu_defaults 
  static inline int32_t get_target_pstate_use_performance(struct cpudata *cpu);
  static inline int32_t get_target_pstate_use_cpu_load(struct cpudata *cpu);
  
- static struct pstate_adjust_policy pid_params __read_mostly;
  static struct pstate_funcs pstate_funcs __read_mostly;
+ static struct pstate_adjust_policy pid_params __read_mostly = {
+ 	.sample_rate_ms = 10,
+ 	.sample_rate_ns = 10 * NSEC_PER_MSEC,
+ 	.deadband = 0,
+ 	.setpoint = 97,
+ 	.p_gain_pct = 20,
+ 	.d_gain_pct = 0,
+ 	.i_gain_pct = 0,
+ };
+ 
  static int hwp_active __read_mostly;
 -static bool per_cpu_limits __read_mostly;
 -
 -static bool driver_registered __read_mostly;
  
  #ifdef CONFIG_ACPI
  static bool acpi_ppc;
@@@ -1070,15 -1551,20 +1069,32 @@@ static struct cpu_defaults atom_params 
  	},
  };
  
++<<<<<<< HEAD
 +static struct cpu_defaults knl_params = {
 +	.pid_policy = {
 +		.sample_rate_ms = 10,
 +		.deadband = 0,
 +		.setpoint = 97,
 +		.p_gain_pct = 20,
 +		.d_gain_pct = 0,
 +		.i_gain_pct = 0,
 +	},
++=======
+ static const struct cpu_defaults airmont_params = {
+ 	.funcs = {
+ 		.get_max = atom_get_max_pstate,
+ 		.get_max_physical = atom_get_max_pstate,
+ 		.get_min = atom_get_min_pstate,
+ 		.get_turbo = atom_get_turbo_pstate,
+ 		.get_val = atom_get_val,
+ 		.get_scaling = airmont_get_scaling,
+ 		.get_vid = atom_get_vid,
+ 		.get_target_pstate = get_target_pstate_use_cpu_load,
+ 	},
+ };
+ 
+ static const struct cpu_defaults knl_params = {
++>>>>>>> 5c43905369bb (cpufreq: intel_pstate: Initialize pid_params statically)
  	.funcs = {
  		.get_max = core_get_max_pstate,
  		.get_max_physical = core_get_max_pstate_physical,
@@@ -1589,17 -2403,26 +1605,40 @@@ static int intel_pstate_msrs_not_valid(
  	return 0;
  }
  
++<<<<<<< HEAD
 +static void copy_pid_params(struct pstate_adjust_policy *policy)
 +{
 +	pid_params.sample_rate_ms = policy->sample_rate_ms;
 +	pid_params.p_gain_pct = policy->p_gain_pct;
 +	pid_params.i_gain_pct = policy->i_gain_pct;
 +	pid_params.d_gain_pct = policy->d_gain_pct;
 +	pid_params.deadband = policy->deadband;
 +	pid_params.setpoint = policy->setpoint;
 +}
 +
 +static void copy_cpu_funcs(struct pstate_funcs *funcs)
++=======
+ #ifdef CONFIG_ACPI
+ static void intel_pstate_use_acpi_profile(void)
+ {
+ 	switch (acpi_gbl_FADT.preferred_profile) {
+ 	case PM_MOBILE:
+ 	case PM_TABLET:
+ 	case PM_APPLIANCE_PC:
+ 	case PM_DESKTOP:
+ 	case PM_WORKSTATION:
+ 		pstate_funcs.get_target_pstate =
+ 				get_target_pstate_use_cpu_load;
+ 	}
+ }
+ #else
+ static void intel_pstate_use_acpi_profile(void)
+ {
+ }
+ #endif
+ 
+ static void __init copy_cpu_funcs(struct pstate_funcs *funcs)
++>>>>>>> 5c43905369bb (cpufreq: intel_pstate: Initialize pid_params statically)
  {
  	pstate_funcs.get_max   = funcs->get_max;
  	pstate_funcs.get_max_physical = funcs->get_max_physical;
@@@ -1753,21 -2575,27 +1792,41 @@@ static int __init intel_pstate_init(voi
  	if (no_load)
  		return -ENODEV;
  
 -	if (x86_match_cpu(hwp_support_ids)) {
 +	if (x86_match_cpu(hwp_support_ids) && !no_hwp) {
  		copy_cpu_funcs(&core_params.funcs);
++<<<<<<< HEAD
 +		hwp_active++;
 +		goto hwp_cpu_matched;
++=======
+ 		if (no_hwp) {
+ 			pstate_funcs.get_target_pstate = get_target_pstate_use_cpu_load;
+ 		} else {
+ 			hwp_active++;
+ 			intel_pstate.attr = hwp_cpufreq_attrs;
+ 			goto hwp_cpu_matched;
+ 		}
+ 	} else {
+ 		const struct x86_cpu_id *id;
+ 		struct cpu_defaults *cpu_def;
+ 
+ 		id = x86_match_cpu(intel_pstate_cpu_ids);
+ 		if (!id)
+ 			return -ENODEV;
+ 
+ 		cpu_def = (struct cpu_defaults *)id->driver_data;
+ 		copy_cpu_funcs(&cpu_def->funcs);
++>>>>>>> 5c43905369bb (cpufreq: intel_pstate: Initialize pid_params statically)
  	}
  
 +	id = x86_match_cpu(intel_pstate_cpu_ids);
 +	if (!id)
 +		return -ENODEV;
 +
 +	cpu_info = (struct cpu_defaults *)id->driver_data;
 +
 +	copy_pid_params(&cpu_info->pid_policy);
 +	copy_cpu_funcs(&cpu_info->funcs);
 +
  	if (intel_pstate_msrs_not_valid())
  		return -ENODEV;
  
* Unmerged path drivers/cpufreq/intel_pstate.c
