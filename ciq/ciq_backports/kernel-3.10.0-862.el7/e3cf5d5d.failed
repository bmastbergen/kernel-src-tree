ext4: prepare to drop EXT4_STATE_DELALLOC_RESERVED

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Theodore Ts'o <tytso@mit.edu>
commit e3cf5d5d9a86df1c5e413bdd3725c25a16ff854c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/e3cf5d5d.failed

The EXT4_STATE_DELALLOC_RESERVED flag was originally implemented
because it was too hard to make sure the mballoc and get_block flags
could be reliably passed down through all of the codepaths that end up
calling ext4_mb_new_blocks().

Since then, we have mb_flags passed down through most of the code
paths, so getting rid of EXT4_STATE_DELALLOC_RESERVED isn't as tricky
as it used to.

This commit plumbs in the last of what is required, and then adds a
WARN_ON check to make sure we haven't missed anything.  If this passes
a full regression test run, we can then drop
EXT4_STATE_DELALLOC_RESERVED.

	Signed-off-by: Theodore Ts'o <tytso@mit.edu>
	Reviewed-by: Jan Kara <jack@suse.cz>
(cherry picked from commit e3cf5d5d9a86df1c5e413bdd3725c25a16ff854c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/ext4/balloc.c
diff --cc fs/ext4/balloc.c
index 9654a4106044,d70f154f6da3..000000000000
--- a/fs/ext4/balloc.c
+++ b/fs/ext4/balloc.c
@@@ -643,8 -636,9 +643,14 @@@ ext4_fsblk_t ext4_new_meta_blocks(handl
  	 * Account for the allocated meta blocks.  We will never
  	 * fail EDQUOT for metdata, but we do account for it.
  	 */
++<<<<<<< HEAD
 +	if (!(*errp) &&
 +	    ext4_test_inode_state(inode, EXT4_STATE_DELALLOC_RESERVED)) {
++=======
+ 	if (!(*errp) && (flags & EXT4_MB_DELALLOC_RESERVED)) {
+ 		spin_lock(&EXT4_I(inode)->i_block_reservation_lock);
+ 		spin_unlock(&EXT4_I(inode)->i_block_reservation_lock);
++>>>>>>> e3cf5d5d9a86 (ext4: prepare to drop EXT4_STATE_DELALLOC_RESERVED)
  		dquot_alloc_block_nofail(inode,
  				EXT4_C2B(EXT4_SB(inode->i_sb), ar.len));
  	}
* Unmerged path fs/ext4/balloc.c
diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c
index c4b848721a8c..3b320220b080 100644
--- a/fs/ext4/extents.c
+++ b/fs/ext4/extents.c
@@ -1903,6 +1903,8 @@ int ext4_ext_insert_extent(handle_t *handle, struct inode *inode,
 	ext4_lblk_t next;
 	int mb_flags = 0, unwritten;
 
+	if (gb_flags & EXT4_GET_BLOCKS_DELALLOC_RESERVE)
+		mb_flags |= EXT4_MB_DELALLOC_RESERVED;
 	if (unlikely(ext4_ext_get_actual_len(newext) == 0)) {
 		EXT4_ERROR_INODE(inode, "ext4_ext_get_actual_len(newext) == 0");
 		return -EIO;
@@ -2024,7 +2026,7 @@ prepend:
 	 * We're gonna add a new leaf in the tree.
 	 */
 	if (gb_flags & EXT4_GET_BLOCKS_METADATA_NOFAIL)
-		mb_flags = EXT4_MB_USE_RESERVED;
+		mb_flags |= EXT4_MB_USE_RESERVED;
 	err = ext4_ext_create_new_leaf(handle, inode, mb_flags, gb_flags,
 				       path, newext);
 	if (err)
@@ -4483,6 +4485,8 @@ int ext4_ext_map_blocks(handle_t *handle, struct inode *inode,
 		ar.flags = 0;
 	if (flags & EXT4_GET_BLOCKS_NO_NORMALIZE)
 		ar.flags |= EXT4_MB_HINT_NOPREALLOC;
+	if (flags & EXT4_GET_BLOCKS_DELALLOC_RESERVE)
+		ar.flags |= EXT4_MB_DELALLOC_RESERVED;
 	newblock = ext4_mb_new_blocks(handle, &ar, &err);
 	if (!newblock)
 		goto out2;
diff --git a/fs/ext4/indirect.c b/fs/ext4/indirect.c
index 2d387b9c2966..cc55180d674a 100644
--- a/fs/ext4/indirect.c
+++ b/fs/ext4/indirect.c
@@ -334,7 +334,9 @@ static int ext4_alloc_branch(handle_t *handle,
 			new_blocks[i] = ext4_mb_new_blocks(handle, ar, &err);
 		} else
 			ar->goal = new_blocks[i] = ext4_new_meta_blocks(handle,
-				    ar->inode, ar->goal, 0, NULL, &err);
+					ar->inode, ar->goal,
+					ar->flags & EXT4_MB_DELALLOC_RESERVED,
+					NULL, &err);
 		if (err) {
 			i--;
 			goto failed;
@@ -588,6 +590,8 @@ int ext4_ind_map_blocks(handle_t *handle, struct inode *inode,
 	ar.logical = map->m_lblk;
 	if (S_ISREG(inode->i_mode))
 		ar.flags = EXT4_MB_HINT_DATA;
+	if (flags & EXT4_GET_BLOCKS_DELALLOC_RESERVE)
+		ar.flags |= EXT4_MB_DELALLOC_RESERVED;
 
 	ar.goal = ext4_find_goal(inode, map->m_lblk, partial);
 
diff --git a/fs/ext4/mballoc.c b/fs/ext4/mballoc.c
index 343f1ad2e4b3..9c7df47f3db4 100644
--- a/fs/ext4/mballoc.c
+++ b/fs/ext4/mballoc.c
@@ -4422,9 +4422,12 @@ ext4_fsblk_t ext4_mb_new_blocks(handle_t *handle,
 	 * EDQUOT check, as blocks and quotas have been already
 	 * reserved when data being copied into pagecache.
 	 */
-	if (ext4_test_inode_state(ar->inode, EXT4_STATE_DELALLOC_RESERVED))
+	if (ext4_test_inode_state(ar->inode, EXT4_STATE_DELALLOC_RESERVED)) {
+		WARN_ON((ar->flags & EXT4_MB_DELALLOC_RESERVED) == 0);
 		ar->flags |= EXT4_MB_DELALLOC_RESERVED;
-	else {
+	}
+
+	if ((ar->flags & EXT4_MB_DELALLOC_RESERVED) == 0) {
 		/* Without delayed allocation we need to verify
 		 * there is enough free blocks to do block allocation
 		 * and verify allocation doesn't exceed the quota limits.
@@ -4524,8 +4527,7 @@ out:
 	if (inquota && ar->len < inquota)
 		dquot_free_block(ar->inode, EXT4_C2B(sbi, inquota - ar->len));
 	if (!ar->len) {
-		if (!ext4_test_inode_state(ar->inode,
-					   EXT4_STATE_DELALLOC_RESERVED))
+		if ((ar->flags & EXT4_MB_DELALLOC_RESERVED) == 0)
 			/* release all the reserved blocks if non delalloc */
 			percpu_counter_sub(&sbi->s_dirtyclusters_counter,
 						reserv_clstrs);
diff --git a/fs/ext4/xattr.c b/fs/ext4/xattr.c
index 6ab956a774f8..d7ce9e3d8174 100644
--- a/fs/ext4/xattr.c
+++ b/fs/ext4/xattr.c
@@ -905,14 +905,8 @@ inserted:
 			if (!(ext4_test_inode_flag(inode, EXT4_INODE_EXTENTS)))
 				goal = goal & EXT4_MAX_BLOCK_FILE_PHYS;
 
-			/*
-			 * take i_data_sem because we will test
-			 * i_delalloc_reserved_flag in ext4_mb_new_blocks
-			 */
-			down_read(&EXT4_I(inode)->i_data_sem);
 			block = ext4_new_meta_blocks(handle, inode, goal, 0,
 						     NULL, &error);
-			up_read((&EXT4_I(inode)->i_data_sem));
 			if (error)
 				goto cleanup;
 
