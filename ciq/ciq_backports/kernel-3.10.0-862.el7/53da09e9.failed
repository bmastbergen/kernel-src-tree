ibmvnic: Add set_link_state routine for setting adapter link state

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Nathan Fontenot <nfont@linux.vnet.ibm.com>
commit 53da09e92910f675ebb93921007428a3c2a024fb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/53da09e9.failed

Create a common routine for setting the link state for the vnic adapter.
This update moves the sending of the crq and waiting for the link state
response to a common place. The new routine also adds handling of
resending the crq in cases of getting a partial success response.

	Signed-off-by: Nathan Fontenot <nfont@linux.vnet.ibm.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 53da09e92910f675ebb93921007428a3c2a024fb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/ibm/ibmvnic.c
diff --cc drivers/net/ethernet/ibm/ibmvnic.c
index a82f95caef8d,115f21694994..000000000000
--- a/drivers/net/ethernet/ibm/ibmvnic.c
+++ b/drivers/net/ethernet/ibm/ibmvnic.c
@@@ -442,20 -499,183 +442,182 @@@ static int ibmvnic_open(struct net_devi
  		tx_pool->consumer_index = 0;
  		tx_pool->producer_index = 0;
  	}
 -
 -	return 0;
 -}
 -
 -static void release_error_buffers(struct ibmvnic_adapter *adapter)
 -{
 -	struct device *dev = &adapter->vdev->dev;
 -	struct ibmvnic_error_buff *error_buff, *tmp;
 -	unsigned long flags;
 -
 -	spin_lock_irqsave(&adapter->error_list_lock, flags);
 -	list_for_each_entry_safe(error_buff, tmp, &adapter->errors, list) {
 -		list_del(&error_buff->list);
 -		dma_unmap_single(dev, error_buff->dma, error_buff->len,
 -				 DMA_FROM_DEVICE);
 -		kfree(error_buff->buff);
 -		kfree(error_buff);
 +	adapter->bounce_buffer_size =
 +	    (netdev->mtu + ETH_HLEN - 1) / PAGE_SIZE + 1;
 +	adapter->bounce_buffer = kmalloc(adapter->bounce_buffer_size,
 +					 GFP_KERNEL);
 +	if (!adapter->bounce_buffer)
 +		goto bounce_alloc_failed;
 +
 +	adapter->bounce_buffer_dma = dma_map_single(dev, adapter->bounce_buffer,
 +						    adapter->bounce_buffer_size,
 +						    DMA_TO_DEVICE);
 +	if (dma_mapping_error(dev, adapter->bounce_buffer_dma)) {
 +		dev_err(dev, "Couldn't map tx bounce buffer\n");
 +		goto bounce_map_failed;
  	}
++<<<<<<< HEAD
++=======
+ 	spin_unlock_irqrestore(&adapter->error_list_lock, flags);
+ }
+ 
+ static int ibmvnic_login(struct net_device *netdev)
+ {
+ 	struct ibmvnic_adapter *adapter = netdev_priv(netdev);
+ 	unsigned long timeout = msecs_to_jiffies(30000);
+ 	struct device *dev = &adapter->vdev->dev;
+ 
+ 	do {
+ 		if (adapter->renegotiate) {
+ 			adapter->renegotiate = false;
+ 			release_sub_crqs(adapter);
+ 
+ 			reinit_completion(&adapter->init_done);
+ 			send_cap_queries(adapter);
+ 			if (!wait_for_completion_timeout(&adapter->init_done,
+ 							 timeout)) {
+ 				dev_err(dev, "Capabilities query timeout\n");
+ 				return -1;
+ 			}
+ 		}
+ 
+ 		reinit_completion(&adapter->init_done);
+ 		send_login(adapter);
+ 		if (!wait_for_completion_timeout(&adapter->init_done,
+ 						 timeout)) {
+ 			dev_err(dev, "Login timeout\n");
+ 			return -1;
+ 		}
+ 	} while (adapter->renegotiate);
+ 
+ 	return 0;
+ }
+ 
+ static void release_resources(struct ibmvnic_adapter *adapter)
+ {
+ 	release_tx_pools(adapter);
+ 	release_rx_pools(adapter);
+ 
+ 	release_stats_token(adapter);
+ 	release_error_buffers(adapter);
+ }
+ 
+ static int set_link_state(struct ibmvnic_adapter *adapter, u8 link_state)
+ {
+ 	struct net_device *netdev = adapter->netdev;
+ 	unsigned long timeout = msecs_to_jiffies(30000);
+ 	union ibmvnic_crq crq;
+ 	bool resend;
+ 	int rc;
+ 
+ 	if (adapter->logical_link_state == link_state) {
+ 		netdev_dbg(netdev, "Link state already %d\n", link_state);
+ 		return 0;
+ 	}
+ 
+ 	netdev_err(netdev, "setting link state %d\n", link_state);
+ 	memset(&crq, 0, sizeof(crq));
+ 	crq.logical_link_state.first = IBMVNIC_CRQ_CMD;
+ 	crq.logical_link_state.cmd = LOGICAL_LINK_STATE;
+ 	crq.logical_link_state.link_state = link_state;
+ 
+ 	do {
+ 		resend = false;
+ 
+ 		reinit_completion(&adapter->init_done);
+ 		rc = ibmvnic_send_crq(adapter, &crq);
+ 		if (rc) {
+ 			netdev_err(netdev, "Failed to set link state\n");
+ 			return rc;
+ 		}
+ 
+ 		if (!wait_for_completion_timeout(&adapter->init_done,
+ 						 timeout)) {
+ 			netdev_err(netdev, "timeout setting link state\n");
+ 			return -1;
+ 		}
+ 
+ 		if (adapter->init_done_rc == 1) {
+ 			/* Partuial success, delay and re-send */
+ 			mdelay(1000);
+ 			resend = true;
+ 		}
+ 	} while (resend);
+ 
+ 	return 0;
+ }
+ 
+ static int set_real_num_queues(struct net_device *netdev)
+ {
+ 	struct ibmvnic_adapter *adapter = netdev_priv(netdev);
+ 	int rc;
+ 
+ 	rc = netif_set_real_num_tx_queues(netdev, adapter->req_tx_queues);
+ 	if (rc) {
+ 		netdev_err(netdev, "failed to set the number of tx queues\n");
+ 		return rc;
+ 	}
+ 
+ 	rc = netif_set_real_num_rx_queues(netdev, adapter->req_rx_queues);
+ 	if (rc)
+ 		netdev_err(netdev, "failed to set the number of rx queues\n");
+ 
+ 	return rc;
+ }
+ 
+ static int ibmvnic_open(struct net_device *netdev)
+ {
+ 	struct ibmvnic_adapter *adapter = netdev_priv(netdev);
+ 	struct device *dev = &adapter->vdev->dev;
+ 	int rc = 0;
+ 	int i;
+ 
+ 	if (adapter->is_closed) {
+ 		rc = ibmvnic_init(adapter);
+ 		if (rc)
+ 			return rc;
+ 	}
+ 
+ 	rc = ibmvnic_login(netdev);
+ 	if (rc)
+ 		return rc;
+ 
+ 	rc = set_real_num_queues(netdev);
+ 	if (rc)
+ 		return rc;
+ 
+ 	rc = init_sub_crq_irqs(adapter);
+ 	if (rc) {
+ 		dev_err(dev, "failed to initialize sub crq irqs\n");
+ 		return -1;
+ 	}
+ 
+ 	rc = init_stats_token(adapter);
+ 	if (rc)
+ 		return rc;
+ 
+ 	adapter->map_id = 1;
+ 	adapter->napi = kcalloc(adapter->req_rx_queues,
+ 				sizeof(struct napi_struct), GFP_KERNEL);
+ 	if (!adapter->napi)
+ 		goto ibmvnic_open_fail;
+ 	for (i = 0; i < adapter->req_rx_queues; i++) {
+ 		netif_napi_add(netdev, &adapter->napi[i], ibmvnic_poll,
+ 			       NAPI_POLL_WEIGHT);
+ 		napi_enable(&adapter->napi[i]);
+ 	}
+ 
+ 	send_map_query(adapter);
+ 
+ 	rc = init_rx_pools(netdev);
+ 	if (rc)
+ 		goto ibmvnic_open_fail;
+ 
+ 	rc = init_tx_pools(netdev);
+ 	if (rc)
+ 		goto ibmvnic_open_fail;
+ 
++>>>>>>> 53da09e92910 (ibmvnic: Add set_link_state routine for setting adapter link state)
  	replenish_pools(adapter);
  
  	/* We're ready to receive frames, enable the sub-crq interrupts and
@@@ -467,13 -687,12 +629,11 @@@
  	for (i = 0; i < adapter->req_tx_queues; i++)
  		enable_scrq_irq(adapter, adapter->tx_scrq[i]);
  
- 	memset(&crq, 0, sizeof(crq));
- 	crq.logical_link_state.first = IBMVNIC_CRQ_CMD;
- 	crq.logical_link_state.cmd = LOGICAL_LINK_STATE;
- 	crq.logical_link_state.link_state = IBMVNIC_LOGICAL_LNK_UP;
- 	ibmvnic_send_crq(adapter, &crq);
+ 	rc = set_link_state(adapter, IBMVNIC_LOGICAL_LNK_UP);
+ 	if (rc)
+ 		goto ibmvnic_open_fail;
  
  	netif_tx_start_all_queues(netdev);
 -	adapter->is_closed = false;
  
  	return 0;
  
@@@ -532,8 -723,7 +692,12 @@@ static void disable_sub_crqs(struct ibm
  static int ibmvnic_close(struct net_device *netdev)
  {
  	struct ibmvnic_adapter *adapter = netdev_priv(netdev);
++<<<<<<< HEAD
 +	struct device *dev = &adapter->vdev->dev;
 +	union ibmvnic_crq crq;
++=======
+ 	int rc = 0;
++>>>>>>> 53da09e92910 (ibmvnic: Add set_link_state routine for setting adapter link state)
  	int i;
  
  	adapter->closing = true;
@@@ -545,46 -735,13 +709,54 @@@
  	if (!adapter->failover)
  		netif_tx_stop_all_queues(netdev);
  
++<<<<<<< HEAD
 +	if (adapter->bounce_buffer) {
 +		if (!dma_mapping_error(dev, adapter->bounce_buffer_dma)) {
 +			dma_unmap_single(&adapter->vdev->dev,
 +					 adapter->bounce_buffer_dma,
 +					 adapter->bounce_buffer_size,
 +					 DMA_BIDIRECTIONAL);
 +			adapter->bounce_buffer_dma = DMA_ERROR_CODE;
 +		}
 +		kfree(adapter->bounce_buffer);
 +		adapter->bounce_buffer = NULL;
 +	}
 +
 +	memset(&crq, 0, sizeof(crq));
 +	crq.logical_link_state.first = IBMVNIC_CRQ_CMD;
 +	crq.logical_link_state.cmd = LOGICAL_LINK_STATE;
 +	crq.logical_link_state.link_state = IBMVNIC_LOGICAL_LNK_DN;
 +	ibmvnic_send_crq(adapter, &crq);
++=======
+ 	rc = set_link_state(adapter, IBMVNIC_LOGICAL_LNK_DN);
++>>>>>>> 53da09e92910 (ibmvnic: Add set_link_state routine for setting adapter link state)
 +
 +	for (i = 0; i < be32_to_cpu(adapter->login_rsp_buf->num_txsubm_subcrqs);
 +	     i++) {
 +		kfree(adapter->tx_pool[i].tx_buff);
 +		free_long_term_buff(adapter,
 +				    &adapter->tx_pool[i].long_term_buff);
 +		kfree(adapter->tx_pool[i].free_map);
 +	}
 +	kfree(adapter->tx_pool);
 +	adapter->tx_pool = NULL;
  
 -	release_resources(adapter);
 +	for (i = 0; i < be32_to_cpu(adapter->login_rsp_buf->num_rxadd_subcrqs);
 +	     i++) {
 +		free_rx_pool(adapter, &adapter->rx_pool[i]);
 +		free_long_term_buff(adapter,
 +				    &adapter->rx_pool[i].long_term_buff);
 +	}
 +	kfree(adapter->rx_pool);
 +	adapter->rx_pool = NULL;
  
 -	adapter->is_closed = true;
  	adapter->closing = false;
++<<<<<<< HEAD
 +
 +	return 0;
++=======
+ 	return rc;
++>>>>>>> 53da09e92910 (ibmvnic: Add set_link_state routine for setting adapter link state)
  }
  
  /**
* Unmerged path drivers/net/ethernet/ibm/ibmvnic.c
diff --git a/drivers/net/ethernet/ibm/ibmvnic.h b/drivers/net/ethernet/ibm/ibmvnic.h
index 91a20189cdae..4ea0ee3debac 100644
--- a/drivers/net/ethernet/ibm/ibmvnic.h
+++ b/drivers/net/ethernet/ibm/ibmvnic.h
@@ -992,6 +992,7 @@ struct ibmvnic_adapter {
 	struct ibmvnic_tx_pool *tx_pool;
 	bool closing;
 	struct completion init_done;
+	int init_done_rc;
 
 	struct list_head errors;
 	spinlock_t error_list_lock;
