cpufreq: intel_pstate: Set P-state upfront in performance mode

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [cpufreq] intel_pstate: Set P-state upfront in performance mode (Prarit Bhargava) [1465349]
Rebuild_FUZZ: 92.17%
commit-author Rafael J. Wysocki <rafael.j.wysocki@intel.com>
commit a6c6ead14183ea4ec8ce7551e1f3451024b9c4db
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/a6c6ead1.failed

After commit a4675fbc4a7a (cpufreq: intel_pstate: Replace timers with
utilization update callbacks) the cpufreq governor callbacks may not
be invoked on NOHZ_FULL CPUs and, in particular, switching to the
"performance" policy via sysfs may not have any effect on them.  That
is a problem, because it usually is desirable to squeeze the last
bit of performance out of those CPUs, so work around it by setting
the maximum P-state (within the limits) in intel_pstate_set_policy()
upfront when the policy is CPUFREQ_POLICY_PERFORMANCE.

Fixes: a4675fbc4a7a (cpufreq: intel_pstate: Replace timers with utilization update callbacks)
	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
	Acked-by: Srinivas Pandruvada <srinivas.pandruvada@linux.intel.com>
(cherry picked from commit a6c6ead14183ea4ec8ce7551e1f3451024b9c4db)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/intel_pstate.c
diff --cc drivers/cpufreq/intel_pstate.c
index 2849fe3729b8,ac7c58d20b58..000000000000
--- a/drivers/cpufreq/intel_pstate.c
+++ b/drivers/cpufreq/intel_pstate.c
@@@ -1096,24 -1144,31 +1096,41 @@@ static void intel_pstate_get_min_max(st
  
  static void intel_pstate_set_pstate(struct cpudata *cpu, int pstate)
  {
++<<<<<<< HEAD
 +	int max_perf, min_perf;
 +
 +	update_turbo_state();
 +
 +	intel_pstate_get_min_max(cpu, &min_perf, &max_perf);
 +
 +	pstate = clamp_t(int, pstate, min_perf, max_perf);
 +
 +	if (pstate == cpu->pstate.current_pstate)
 +		return;
 +
++=======
++>>>>>>> a6c6ead14183 (cpufreq: intel_pstate: Set P-state upfront in performance mode)
  	trace_cpu_frequency(pstate * cpu->pstate.scaling, cpu->cpu);
 +
  	cpu->pstate.current_pstate = pstate;
 -	/*
 -	 * Generally, there is no guarantee that this code will always run on
 -	 * the CPU being updated, so force the register update to run on the
 -	 * right CPU.
 -	 */
 -	wrmsrl_on_cpu(cpu->cpu, MSR_IA32_PERF_CTL,
 -		      pstate_funcs.get_val(cpu, pstate));
 +
 +	pstate_funcs.set(cpu, pstate);
  }
  
+ static void intel_pstate_set_min_pstate(struct cpudata *cpu)
+ {
+ 	intel_pstate_set_pstate(cpu, cpu->pstate.min_pstate);
+ }
+ 
+ static void intel_pstate_max_within_limits(struct cpudata *cpu)
+ {
+ 	int min_pstate, max_pstate;
+ 
+ 	update_turbo_state();
+ 	intel_pstate_get_min_max(cpu, &min_pstate, &max_pstate);
+ 	intel_pstate_set_pstate(cpu, max_pstate);
+ }
+ 
  static void intel_pstate_get_cpu_pstates(struct cpudata *cpu)
  {
  	cpu->pstate.min_pstate = pstate_funcs.get_min();
@@@ -1424,17 -1503,26 +1441,29 @@@ static int intel_pstate_set_policy(stru
  	pr_debug("set_policy cpuinfo.max %u policy->max %u\n",
  		 policy->cpuinfo.max_freq, policy->max);
  
++<<<<<<< HEAD
 +	if (policy->policy == CPUFREQ_POLICY_PERFORMANCE &&
 +	    policy->max >= policy->cpuinfo.max_freq) {
 +		pr_debug("intel_pstate: set performance\n");
++=======
+ 	cpu = all_cpu_data[policy->cpu];
+ 	if (cpu->pstate.max_pstate_physical > cpu->pstate.max_pstate &&
+ 	    policy->max < policy->cpuinfo.max_freq &&
+ 	    policy->max > cpu->pstate.max_pstate * cpu->pstate.scaling) {
+ 		pr_debug("policy->max > max non turbo frequency\n");
+ 		policy->max = policy->cpuinfo.max_freq;
+ 	}
+ 
+ 	if (policy->policy == CPUFREQ_POLICY_PERFORMANCE) {
++>>>>>>> a6c6ead14183 (cpufreq: intel_pstate: Set P-state upfront in performance mode)
  		limits = &performance_limits;
 -		if (policy->max >= policy->cpuinfo.max_freq) {
 -			pr_debug("set performance\n");
 -			intel_pstate_set_performance_limits(limits);
 -			goto out;
 -		}
 -	} else {
 -		pr_debug("set powersave\n");
 -		limits = &powersave_limits;
 +		if (hwp_active)
 +			intel_pstate_hwp_set(policy->cpus);
 +		return 0;
  	}
  
 +	pr_debug("intel_pstate: set powersave\n");
 +	limits = &powersave_limits;
  	limits->min_policy_pct = (policy->min * 100) / policy->cpuinfo.max_freq;
  	limits->min_policy_pct = clamp_t(int, limits->min_policy_pct, 0 , 100);
  	limits->max_policy_pct = DIV_ROUND_UP(policy->max * 100,
@@@ -1454,14 -1542,23 +1483,30 @@@
  	/* Make sure min_perf_pct <= max_perf_pct */
  	limits->min_perf_pct = min(limits->max_perf_pct, limits->min_perf_pct);
  
 -	limits->min_perf = div_fp(limits->min_perf_pct, 100);
 -	limits->max_perf = div_fp(limits->max_perf_pct, 100);
 +	limits->min_perf = div_fp(int_tofp(limits->min_perf_pct),
 +				  int_tofp(100));
 +	limits->max_perf = div_fp(int_tofp(limits->max_perf_pct),
 +				  int_tofp(100));
  	limits->max_perf = round_up(limits->max_perf, FRAC_BITS);
  
++<<<<<<< HEAD
 +	if (hwp_active)
 +		intel_pstate_hwp_set(policy->cpus);
++=======
+  out:
+ 	if (policy->policy == CPUFREQ_POLICY_PERFORMANCE) {
+ 		/*
+ 		 * NOHZ_FULL CPUs need this as the governor callback may not
+ 		 * be invoked on them.
+ 		 */
+ 		intel_pstate_clear_update_util_hook(policy->cpu);
+ 		intel_pstate_max_within_limits(cpu);
+ 	}
+ 
+ 	intel_pstate_set_update_util_hook(policy->cpu);
+ 
+ 	intel_pstate_hwp_set_policy(policy);
++>>>>>>> a6c6ead14183 (cpufreq: intel_pstate: Set P-state upfront in performance mode)
  
  	return 0;
  }
* Unmerged path drivers/cpufreq/intel_pstate.c
