SUNRPC: Don't hold the transport lock across socket copy operations

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Trond Myklebust <trond.myklebust@primarydata.com>
commit 729749bb8da186e68d97d1b0439f0b1e0059c41d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/729749bb.failed

Instead add a mechanism to ensure that the request doesn't disappear
from underneath us while copying from the socket. We do this by
preventing xprt_release() from freeing the XDR buffers until the
flag RPC_TASK_MSG_RECV has been cleared from the request.

	Signed-off-by: Trond Myklebust <trond.myklebust@primarydata.com>
	Reviewed-by: Chuck Lever <chuck.lever@oracle.com>
(cherry picked from commit 729749bb8da186e68d97d1b0439f0b1e0059c41d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sunrpc/xprtsock.c
diff --cc net/sunrpc/xprtsock.c
index e4ae7a2afb1e,04dbc7027712..000000000000
--- a/net/sunrpc/xprtsock.c
+++ b/net/sunrpc/xprtsock.c
@@@ -1040,15 -1068,18 +1047,23 @@@ static void xs_udp_data_read_skb(struc
  
  	/* Suck it into the iovec, verify checksum if not done by hw. */
  	if (csum_partial_copy_to_xdr(&rovr->rq_private_buf, skb)) {
++<<<<<<< HEAD
 +		UDPX_INC_STATS_BH(sk, UDP_MIB_INERRORS);
 +		goto out_unlock;
++=======
+ 		__UDPX_INC_STATS(sk, UDP_MIB_INERRORS);
+ 		spin_lock_bh(&xprt->transport_lock);
+ 		goto out_unpin;
++>>>>>>> 729749bb8da1 (SUNRPC: Don't hold the transport lock across socket copy operations)
  	}
  
 -	__UDPX_INC_STATS(sk, UDP_MIB_INDATAGRAMS);
 +	UDPX_INC_STATS_BH(sk, UDP_MIB_INDATAGRAMS);
  
+ 	spin_lock_bh(&xprt->transport_lock);
  	xprt_adjust_cwnd(xprt, task, copied);
  	xprt_complete_rqst(task, copied);
- 
+ out_unpin:
+ 	xprt_unpin_rqst(rovr);
   out_unlock:
  	spin_unlock_bh(&xprt->transport_lock);
  }
diff --git a/include/linux/sunrpc/sched.h b/include/linux/sunrpc/sched.h
index cc083a9d0627..3798c5d23e22 100644
--- a/include/linux/sunrpc/sched.h
+++ b/include/linux/sunrpc/sched.h
@@ -139,6 +139,8 @@ struct rpc_task_setup {
 #define RPC_TASK_RUNNING	0
 #define RPC_TASK_QUEUED		1
 #define RPC_TASK_ACTIVE		2
+#define RPC_TASK_MSG_RECV	3
+#define RPC_TASK_MSG_RECV_WAIT	4
 
 #define RPC_IS_RUNNING(t)	test_bit(RPC_TASK_RUNNING, &(t)->tk_runstate)
 #define rpc_set_running(t)	set_bit(RPC_TASK_RUNNING, &(t)->tk_runstate)
diff --git a/include/linux/sunrpc/xprt.h b/include/linux/sunrpc/xprt.h
index 184611330b55..02f85a6b7858 100644
--- a/include/linux/sunrpc/xprt.h
+++ b/include/linux/sunrpc/xprt.h
@@ -368,6 +368,8 @@ void			xprt_write_space(struct rpc_xprt *xprt);
 void			xprt_adjust_cwnd(struct rpc_xprt *xprt, struct rpc_task *task, int result);
 struct rpc_rqst *	xprt_lookup_rqst(struct rpc_xprt *xprt, __be32 xid);
 void			xprt_complete_rqst(struct rpc_task *task, int copied);
+void			xprt_pin_rqst(struct rpc_rqst *req);
+void			xprt_unpin_rqst(struct rpc_rqst *req);
 void			xprt_release_rqst_cong(struct rpc_task *task);
 void			xprt_disconnect_done(struct rpc_xprt *xprt);
 void			xprt_force_disconnect(struct rpc_xprt *xprt);
diff --git a/net/sunrpc/xprt.c b/net/sunrpc/xprt.c
index e83aa477fea7..57e8dc628a4c 100644
--- a/net/sunrpc/xprt.c
+++ b/net/sunrpc/xprt.c
@@ -844,6 +844,48 @@ struct rpc_rqst *xprt_lookup_rqst(struct rpc_xprt *xprt, __be32 xid)
 }
 EXPORT_SYMBOL_GPL(xprt_lookup_rqst);
 
+/**
+ * xprt_pin_rqst - Pin a request on the transport receive list
+ * @req: Request to pin
+ *
+ * Caller must ensure this is atomic with the call to xprt_lookup_rqst()
+ * so should be holding the xprt transport lock.
+ */
+void xprt_pin_rqst(struct rpc_rqst *req)
+{
+	set_bit(RPC_TASK_MSG_RECV, &req->rq_task->tk_runstate);
+}
+
+/**
+ * xprt_unpin_rqst - Unpin a request on the transport receive list
+ * @req: Request to pin
+ *
+ * Caller should be holding the xprt transport lock.
+ */
+void xprt_unpin_rqst(struct rpc_rqst *req)
+{
+	struct rpc_task *task = req->rq_task;
+
+	clear_bit(RPC_TASK_MSG_RECV, &task->tk_runstate);
+	if (test_bit(RPC_TASK_MSG_RECV_WAIT, &task->tk_runstate))
+		wake_up_bit(&task->tk_runstate, RPC_TASK_MSG_RECV);
+}
+
+static void xprt_wait_on_pinned_rqst(struct rpc_rqst *req)
+__must_hold(&req->rq_xprt->transport_lock)
+{
+	struct rpc_task *task = req->rq_task;
+	
+	if (task && test_bit(RPC_TASK_MSG_RECV, &task->tk_runstate)) {
+		spin_unlock_bh(&req->rq_xprt->transport_lock);
+		set_bit(RPC_TASK_MSG_RECV_WAIT, &task->tk_runstate);
+		wait_on_bit(&task->tk_runstate, RPC_TASK_MSG_RECV,
+				TASK_UNINTERRUPTIBLE);
+		clear_bit(RPC_TASK_MSG_RECV_WAIT, &task->tk_runstate);
+		spin_lock_bh(&req->rq_xprt->transport_lock);
+	}
+}
+
 static void xprt_update_rtt(struct rpc_task *task)
 {
 	struct rpc_rqst *req = task->tk_rqstp;
@@ -1293,6 +1335,7 @@ void xprt_release(struct rpc_task *task)
 		list_del(&req->rq_list);
 	xprt->last_used = jiffies;
 	xprt_schedule_autodisconnect(xprt);
+	xprt_wait_on_pinned_rqst(req);
 	spin_unlock_bh(&xprt->transport_lock);
 	if (req->rq_buffer)
 		xprt->ops->buf_free(task);
* Unmerged path net/sunrpc/xprtsock.c
