sched/topology: Remove FORCE_SD_OVERLAP

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Peter Zijlstra <peterz@infradead.org>
commit af85596c74de2fd9abb87501ae280038ac28a3f4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/af85596c.failed

Its an obsolete debug mechanism and future code wants to rely on
properties this undermines.

Namely, it would be good to assume that SD_OVERLAP domains have
children, but if we build the entire hierarchy with SD_OVERLAP this is
obviously false.

	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Mike Galbraith <efault@gmx.de>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: linux-kernel@vger.kernel.org
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit af85596c74de2fd9abb87501ae280038ac28a3f4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/features.h
#	kernel/sched/topology.c
diff --cc kernel/sched/features.h
index 5716929a2e3a,dc4d1483b038..000000000000
--- a/kernel/sched/features.h
+++ b/kernel/sched/features.h
@@@ -56,30 -51,32 +56,58 @@@ SCHED_FEAT(NONTASK_POWER, true
   */
  SCHED_FEAT(TTWU_QUEUE, true)
  
++<<<<<<< HEAD
 +SCHED_FEAT(FORCE_SD_OVERLAP, false)
++=======
+ /*
+  * When doing wakeups, attempt to limit superfluous scans of the LLC domain.
+  */
+ SCHED_FEAT(SIS_AVG_CPU, false)
+ 
+ /*
+  * Issue a WARN when we do multiple update_rq_clock() calls
+  * in a single rq->lock section. Default disabled because the
+  * annotations are not complete.
+  */
+ SCHED_FEAT(WARN_DOUBLE_CLOCK, false)
+ 
+ #ifdef HAVE_RT_PUSH_IPI
+ /*
+  * In order to avoid a thundering herd attack of CPUs that are
+  * lowering their priorities at the same time, and there being
+  * a single CPU that has an RT task that can migrate and is waiting
+  * to run, where the other CPUs will try to take that CPUs
+  * rq lock and possibly create a large contention, sending an
+  * IPI to that CPU and let that CPU push the RT task to where
+  * it should go may be a better scenario.
+  */
+ SCHED_FEAT(RT_PUSH_IPI, true)
+ #endif
+ 
++>>>>>>> af85596c74de (sched/topology: Remove FORCE_SD_OVERLAP)
  SCHED_FEAT(RT_RUNTIME_SHARE, true)
  SCHED_FEAT(LB_MIN, false)
 -SCHED_FEAT(ATTACH_AGE_LOAD, true)
  
 +/*
 + * Apply the automatic NUMA scheduling policy. Enabled automatically
 + * at runtime if running on a NUMA machine. Can be controlled via
 + * numa_balancing=
 + */
 +#ifdef CONFIG_NUMA_BALANCING
 +SCHED_FEAT(NUMA,	false)
 +
 +/*
 + * NUMA_FAVOUR_HIGHER will favor moving tasks towards nodes where a
 + * higher number of hinting faults are recorded during active load
 + * balancing.
 + */
 +SCHED_FEAT(NUMA_FAVOUR_HIGHER, true)
 +
 +/*
 + * NUMA_RESIST_LOWER will resist moving tasks towards nodes where a
 + * lower number of hinting faults have been recorded. As this has
 + * the potential to prevent a task ever migrating to a new node
 + * due to CPU overload it is disabled by default.
 + */
 +SCHED_FEAT(NUMA_RESIST_LOWER, false)
 +#endif
* Unmerged path kernel/sched/topology.c
* Unmerged path kernel/sched/features.h
* Unmerged path kernel/sched/topology.c
