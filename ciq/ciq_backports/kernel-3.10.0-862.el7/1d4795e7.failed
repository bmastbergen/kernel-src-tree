xfs: (re-)implement FIEMAP_FLAG_XATTR

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Christoph Hellwig <hch@lst.de>
commit 1d4795e7bde075588c90df2175349bb2251802d5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/1d4795e7.failed

Use a special read-only iomap_ops implementation to support fiemap on
the attr fork.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Dave Chinner <dchinner@redhat.com>
	Signed-off-by: Dave Chinner <david@fromorbit.com>


(cherry picked from commit 1d4795e7bde075588c90df2175349bb2251802d5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/xfs_iomap.c
#	fs/xfs/xfs_iomap.h
diff --cc fs/xfs/xfs_iomap.c
index 2f3719461cbd,697c8fd4200f..000000000000
--- a/fs/xfs/xfs_iomap.c
+++ b/fs/xfs/xfs_iomap.c
@@@ -967,3 -968,186 +967,189 @@@ xfs_bmbt_to_iomap
  	iomap->length = XFS_FSB_TO_B(mp, imap->br_blockcount);
  	iomap->bdev = xfs_find_bdev_for_inode(VFS_I(ip));
  }
++<<<<<<< HEAD
++=======
+ 
+ static inline bool imap_needs_alloc(struct xfs_bmbt_irec *imap, int nimaps)
+ {
+ 	return !nimaps ||
+ 		imap->br_startblock == HOLESTARTBLOCK ||
+ 		imap->br_startblock == DELAYSTARTBLOCK;
+ }
+ 
+ static int
+ xfs_file_iomap_begin(
+ 	struct inode		*inode,
+ 	loff_t			offset,
+ 	loff_t			length,
+ 	unsigned		flags,
+ 	struct iomap		*iomap)
+ {
+ 	struct xfs_inode	*ip = XFS_I(inode);
+ 	struct xfs_mount	*mp = ip->i_mount;
+ 	struct xfs_bmbt_irec	imap;
+ 	xfs_fileoff_t		offset_fsb, end_fsb;
+ 	int			nimaps = 1, error = 0;
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		return -EIO;
+ 
+ 	xfs_ilock(ip, XFS_ILOCK_EXCL);
+ 
+ 	ASSERT(offset <= mp->m_super->s_maxbytes);
+ 	if ((xfs_fsize_t)offset + length > mp->m_super->s_maxbytes)
+ 		length = mp->m_super->s_maxbytes - offset;
+ 	offset_fsb = XFS_B_TO_FSBT(mp, offset);
+ 	end_fsb = XFS_B_TO_FSB(mp, offset + length);
+ 
+ 	error = xfs_bmapi_read(ip, offset_fsb, end_fsb - offset_fsb, &imap,
+ 			       &nimaps, XFS_BMAPI_ENTIRE);
+ 	if (error) {
+ 		xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 		return error;
+ 	}
+ 
+ 	if ((flags & IOMAP_WRITE) && imap_needs_alloc(&imap, nimaps)) {
+ 		/*
+ 		 * We cap the maximum length we map here to MAX_WRITEBACK_PAGES
+ 		 * pages to keep the chunks of work done where somewhat symmetric
+ 		 * with the work writeback does. This is a completely arbitrary
+ 		 * number pulled out of thin air as a best guess for initial
+ 		 * testing.
+ 		 *
+ 		 * Note that the values needs to be less than 32-bits wide until
+ 		 * the lower level functions are updated.
+ 		 */
+ 		length = min_t(loff_t, length, 1024 * PAGE_SIZE);
+ 		if (xfs_get_extsz_hint(ip)) {
+ 			/*
+ 			 * xfs_iomap_write_direct() expects the shared lock. It
+ 			 * is unlocked on return.
+ 			 */
+ 			xfs_ilock_demote(ip, XFS_ILOCK_EXCL);
+ 			error = xfs_iomap_write_direct(ip, offset, length, &imap,
+ 					nimaps);
+ 		} else {
+ 			error = xfs_iomap_write_delay(ip, offset, length, &imap);
+ 			xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 		}
+ 
+ 		if (error)
+ 			return error;
+ 
+ 		trace_xfs_iomap_alloc(ip, offset, length, 0, &imap);
+ 	} else {
+ 		ASSERT(nimaps);
+ 
+ 		xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 		trace_xfs_iomap_found(ip, offset, length, 0, &imap);
+ 	}
+ 
+ 	xfs_bmbt_to_iomap(ip, iomap, &imap);
+ 	return 0;
+ }
+ 
+ static int
+ xfs_file_iomap_end_delalloc(
+ 	struct xfs_inode	*ip,
+ 	loff_t			offset,
+ 	loff_t			length,
+ 	ssize_t			written)
+ {
+ 	struct xfs_mount	*mp = ip->i_mount;
+ 	xfs_fileoff_t		start_fsb;
+ 	xfs_fileoff_t		end_fsb;
+ 	int			error = 0;
+ 
+ 	start_fsb = XFS_B_TO_FSB(mp, offset + written);
+ 	end_fsb = XFS_B_TO_FSB(mp, offset + length);
+ 
+ 	/*
+ 	 * Trim back delalloc blocks if we didn't manage to write the whole
+ 	 * range reserved.
+ 	 *
+ 	 * We don't need to care about racing delalloc as we hold i_mutex
+ 	 * across the reserve/allocate/unreserve calls. If there are delalloc
+ 	 * blocks in the range, they are ours.
+ 	 */
+ 	if (start_fsb < end_fsb) {
+ 		xfs_ilock(ip, XFS_ILOCK_EXCL);
+ 		error = xfs_bmap_punch_delalloc_range(ip, start_fsb,
+ 					       end_fsb - start_fsb);
+ 		xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 
+ 		if (error && !XFS_FORCED_SHUTDOWN(mp)) {
+ 			xfs_alert(mp, "%s: unable to clean up ino %lld",
+ 				__func__, ip->i_ino);
+ 			return error;
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int
+ xfs_file_iomap_end(
+ 	struct inode		*inode,
+ 	loff_t			offset,
+ 	loff_t			length,
+ 	ssize_t			written,
+ 	unsigned		flags,
+ 	struct iomap		*iomap)
+ {
+ 	if ((flags & IOMAP_WRITE) && iomap->type == IOMAP_DELALLOC)
+ 		return xfs_file_iomap_end_delalloc(XFS_I(inode), offset,
+ 				length, written);
+ 	return 0;
+ }
+ 
+ struct iomap_ops xfs_iomap_ops = {
+ 	.iomap_begin		= xfs_file_iomap_begin,
+ 	.iomap_end		= xfs_file_iomap_end,
+ };
+ 
+ static int
+ xfs_xattr_iomap_begin(
+ 	struct inode		*inode,
+ 	loff_t			offset,
+ 	loff_t			length,
+ 	unsigned		flags,
+ 	struct iomap		*iomap)
+ {
+ 	struct xfs_inode	*ip = XFS_I(inode);
+ 	struct xfs_mount	*mp = ip->i_mount;
+ 	xfs_fileoff_t		offset_fsb = XFS_B_TO_FSBT(mp, offset);
+ 	xfs_fileoff_t		end_fsb = XFS_B_TO_FSB(mp, offset + length);
+ 	struct xfs_bmbt_irec	imap;
+ 	int			nimaps = 1, error = 0;
+ 	unsigned		lockmode;
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		return -EIO;
+ 
+ 	lockmode = xfs_ilock_data_map_shared(ip);
+ 
+ 	/* if there are no attribute fork or extents, return ENOENT */
+ 	if (XFS_IFORK_Q(ip) || !ip->i_d.di_anextents) {
+ 		error = -ENOENT;
+ 		goto out_unlock;
+ 	}
+ 
+ 	ASSERT(ip->i_d.di_aformat != XFS_DINODE_FMT_LOCAL);
+ 	error = xfs_bmapi_read(ip, offset_fsb, end_fsb - offset_fsb, &imap,
+ 			       &nimaps, XFS_BMAPI_ENTIRE | XFS_BMAPI_ATTRFORK);
+ out_unlock:
+ 	xfs_iunlock(ip, lockmode);
+ 
+ 	if (!error) {
+ 		ASSERT(nimaps);
+ 		xfs_bmbt_to_iomap(ip, iomap, &imap);
+ 	}
+ 
+ 	return error;
+ }
+ 
+ struct iomap_ops xfs_xattr_iomap_ops = {
+ 	.iomap_begin		= xfs_xattr_iomap_begin,
+ };
++>>>>>>> 1d4795e7bde0 (xfs: (re-)implement FIEMAP_FLAG_XATTR)
diff --cc fs/xfs/xfs_iomap.h
index 718f07c5c0d2,fb8aca3d69ab..000000000000
--- a/fs/xfs/xfs_iomap.h
+++ b/fs/xfs/xfs_iomap.h
@@@ -33,4 -34,7 +33,10 @@@ int xfs_iomap_write_unwritten(struct xf
  void xfs_bmbt_to_iomap(struct xfs_inode *, struct iomap *,
  		struct xfs_bmbt_irec *);
  
++<<<<<<< HEAD
++=======
+ extern struct iomap_ops xfs_iomap_ops;
+ extern struct iomap_ops xfs_xattr_iomap_ops;
+ 
++>>>>>>> 1d4795e7bde0 (xfs: (re-)implement FIEMAP_FLAG_XATTR)
  #endif /* __XFS_IOMAP_H__*/
* Unmerged path fs/xfs/xfs_iomap.c
* Unmerged path fs/xfs/xfs_iomap.h
diff --git a/fs/xfs/xfs_iops.c b/fs/xfs/xfs_iops.c
index 4c6e1d5b88f5..f9881e631eb8 100644
--- a/fs/xfs/xfs_iops.c
+++ b/fs/xfs/xfs_iops.c
@@ -997,7 +997,14 @@ xfs_vn_fiemap(
 	int			error;
 
 	xfs_ilock(XFS_I(inode), XFS_IOLOCK_SHARED);
-	error = iomap_fiemap(inode, fieinfo, start, length, &xfs_iomap_ops);
+	if (fieinfo->fi_flags & FIEMAP_FLAG_XATTR) {
+		fieinfo->fi_flags &= ~FIEMAP_FLAG_XATTR;
+		error = iomap_fiemap(inode, fieinfo, start, length,
+				&xfs_xattr_iomap_ops);
+	} else {
+		error = iomap_fiemap(inode, fieinfo, start, length,
+				&xfs_iomap_ops);
+	}
 	xfs_iunlock(XFS_I(inode), XFS_IOLOCK_SHARED);
 
 	return error;
