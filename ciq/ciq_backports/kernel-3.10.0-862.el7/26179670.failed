x86/boot/64: Put __startup_64() into .head.text

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [x86] boot/64: Put __startup_64() into .head.text (Suravee Suthikulpanit) [1361287]
Rebuild_FUZZ: 95.56%
commit-author Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
commit 26179670a68b7b365fbfe38afb043dcd2e1a4678
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/26179670.failed

Put __startup_64() and fixup_pointer() into .head.text section to make
sure it's always near startup_64() and always callable.

	Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: kernel test robot <fengguang.wu@intel.com>
	Cc: wfg@linux.intel.com
Link: http://lkml.kernel.org/r/20170616113024.ajmif63cmcszry5a@black.fi.intel.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 26179670a68b7b365fbfe38afb043dcd2e1a4678)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/head64.c
diff --cc arch/x86/kernel/head64.c
index 39ad3cdc4c78,46c3c73e7f43..000000000000
--- a/arch/x86/kernel/head64.c
+++ b/arch/x86/kernel/head64.c
@@@ -31,11 -33,114 +31,117 @@@
  /*
   * Manage page tables very early on.
   */
 -extern pgd_t early_top_pgt[PTRS_PER_PGD];
 +extern pgd_t early_level4_pgt[PTRS_PER_PGD];
  extern pmd_t early_dynamic_pgts[EARLY_DYNAMIC_PAGE_TABLES][PTRS_PER_PMD];
 -static unsigned int __initdata next_early_pgt;
 +static unsigned int __initdata next_early_pgt = 2;
  pmdval_t early_pmd_flags = __PAGE_KERNEL_LARGE & ~(_PAGE_GLOBAL | _PAGE_NX);
  
++<<<<<<< HEAD
++=======
+ #define __head	__section(.head.text)
+ 
+ static void __head *fixup_pointer(void *ptr, unsigned long physaddr)
+ {
+ 	return ptr - (void *)_text + (void *)physaddr;
+ }
+ 
+ void __head __startup_64(unsigned long physaddr)
+ {
+ 	unsigned long load_delta, *p;
+ 	pgdval_t *pgd;
+ 	p4dval_t *p4d;
+ 	pudval_t *pud;
+ 	pmdval_t *pmd, pmd_entry;
+ 	int i;
+ 
+ 	/* Is the address too large? */
+ 	if (physaddr >> MAX_PHYSMEM_BITS)
+ 		for (;;);
+ 
+ 	/*
+ 	 * Compute the delta between the address I am compiled to run at
+ 	 * and the address I am actually running at.
+ 	 */
+ 	load_delta = physaddr - (unsigned long)(_text - __START_KERNEL_map);
+ 
+ 	/* Is the address not 2M aligned? */
+ 	if (load_delta & ~PMD_PAGE_MASK)
+ 		for (;;);
+ 
+ 	/* Fixup the physical addresses in the page table */
+ 
+ 	pgd = fixup_pointer(&early_top_pgt, physaddr);
+ 	pgd[pgd_index(__START_KERNEL_map)] += load_delta;
+ 
+ 	if (IS_ENABLED(CONFIG_X86_5LEVEL)) {
+ 		p4d = fixup_pointer(&level4_kernel_pgt, physaddr);
+ 		p4d[511] += load_delta;
+ 	}
+ 
+ 	pud = fixup_pointer(&level3_kernel_pgt, physaddr);
+ 	pud[510] += load_delta;
+ 	pud[511] += load_delta;
+ 
+ 	pmd = fixup_pointer(level2_fixmap_pgt, physaddr);
+ 	pmd[506] += load_delta;
+ 
+ 	/*
+ 	 * Set up the identity mapping for the switchover.  These
+ 	 * entries should *NOT* have the global bit set!  This also
+ 	 * creates a bunch of nonsense entries but that is fine --
+ 	 * it avoids problems around wraparound.
+ 	 */
+ 
+ 	pud = fixup_pointer(early_dynamic_pgts[next_early_pgt++], physaddr);
+ 	pmd = fixup_pointer(early_dynamic_pgts[next_early_pgt++], physaddr);
+ 
+ 	if (IS_ENABLED(CONFIG_X86_5LEVEL)) {
+ 		p4d = fixup_pointer(early_dynamic_pgts[next_early_pgt++], physaddr);
+ 
+ 		i = (physaddr >> PGDIR_SHIFT) % PTRS_PER_PGD;
+ 		pgd[i + 0] = (pgdval_t)p4d + _KERNPG_TABLE;
+ 		pgd[i + 1] = (pgdval_t)p4d + _KERNPG_TABLE;
+ 
+ 		i = (physaddr >> P4D_SHIFT) % PTRS_PER_P4D;
+ 		p4d[i + 0] = (pgdval_t)pud + _KERNPG_TABLE;
+ 		p4d[i + 1] = (pgdval_t)pud + _KERNPG_TABLE;
+ 	} else {
+ 		i = (physaddr >> PGDIR_SHIFT) % PTRS_PER_PGD;
+ 		pgd[i + 0] = (pgdval_t)pud + _KERNPG_TABLE;
+ 		pgd[i + 1] = (pgdval_t)pud + _KERNPG_TABLE;
+ 	}
+ 
+ 	i = (physaddr >> PUD_SHIFT) % PTRS_PER_PUD;
+ 	pud[i + 0] = (pudval_t)pmd + _KERNPG_TABLE;
+ 	pud[i + 1] = (pudval_t)pmd + _KERNPG_TABLE;
+ 
+ 	pmd_entry = __PAGE_KERNEL_LARGE_EXEC & ~_PAGE_GLOBAL;
+ 	pmd_entry +=  physaddr;
+ 
+ 	for (i = 0; i < DIV_ROUND_UP(_end - _text, PMD_SIZE); i++) {
+ 		int idx = i + (physaddr >> PMD_SHIFT) % PTRS_PER_PMD;
+ 		pmd[idx] = pmd_entry + i * PMD_SIZE;
+ 	}
+ 
+ 	/*
+ 	 * Fixup the kernel text+data virtual addresses. Note that
+ 	 * we might write invalid pmds, when the kernel is relocated
+ 	 * cleanup_highmap() fixes this up along with the mappings
+ 	 * beyond _end.
+ 	 */
+ 
+ 	pmd = fixup_pointer(level2_kernel_pgt, physaddr);
+ 	for (i = 0; i < PTRS_PER_PMD; i++) {
+ 		if (pmd[i] & _PAGE_PRESENT)
+ 			pmd[i] += load_delta;
+ 	}
+ 
+ 	/* Fixup phys_base */
+ 	p = fixup_pointer(&phys_base, physaddr);
+ 	*p += load_delta;
+ }
+ 
++>>>>>>> 26179670a68b (x86/boot/64: Put __startup_64() into .head.text)
  /* Wipe all early page tables except for the kernel symbol map */
  static void __init reset_early_page_tables(void)
  {
* Unmerged path arch/x86/kernel/head64.c
