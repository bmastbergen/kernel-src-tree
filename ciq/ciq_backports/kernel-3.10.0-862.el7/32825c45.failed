blk-mq-sched: fix performance regression of mq-deadline

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Ming Lei <ming.lei@redhat.com>
commit 32825c45ff8f4cce937ab85b030dc693ceb1aa0a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/32825c45.failed

When mq-deadline is taken, IOPS of sequential read and
seqential write is observed more than 20% drop on sata(scsi-mq)
devices, compared with using 'none' scheduler.

The reason is that the default nr_requests for scheduler is
too big for small queuedepth devices, and latency is increased
much.

Since the principle of taking 256 requests for mq scheduler
is based on 128 queue depth, this patch changes into
double size of min(hw queue_depth, 128).

	Signed-off-by: Ming Lei <ming.lei@redhat.com>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 32825c45ff8f4cce937ab85b030dc693ceb1aa0a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq-sched.c
* Unmerged path block/blk-mq-sched.c
* Unmerged path block/blk-mq-sched.c
