dma-mapping: consolidate dma_set_mask

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Christoph Hellwig <hch@lst.de>
commit 452e06af1f0149b01201f94264d452cd7a95db7a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/452e06af.failed

Almost everyone implements dma_set_mask the same way, although some time
that's hidden in ->set_dma_mask methods.

This patch consolidates those into a common implementation that either
calls ->set_dma_mask if present or otherwise uses the default
implementation.  Some architectures used to only call ->set_dma_mask
after the initial checks, and those instance have been fixed to do the
full work.  h8300 implemented dma_set_mask bogusly as a no-ops and has
been fixed.

Unfortunately some architectures overload unrelated semantics like changing
the dma_ops into it so we still need to allow for an architecture override
for now.

[jcmvbkbc@gmail.com: fix xtensa]
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Cc: Arnd Bergmann <arnd@arndb.de>
	Cc: Russell King <linux@arm.linux.org.uk>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Will Deacon <will.deacon@arm.com>
	Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
	Cc: Michal Simek <monstr@monstr.eu>
	Cc: Jonas Bonn <jonas@southpole.se>
	Cc: Chris Metcalf <cmetcalf@ezchip.com>
	Cc: Guan Xuetao <gxt@mprc.pku.edu.cn>
	Cc: Ralf Baechle <ralf@linux-mips.org>
	Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
	Cc: Ingo Molnar <mingo@elte.hu>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Andy Shevchenko <andy.shevchenko@gmail.com>
	Signed-off-by: Max Filippov <jcmvbkbc@gmail.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 452e06af1f0149b01201f94264d452cd7a95db7a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/alpha/include/asm/dma-mapping.h
#	arch/arm64/include/asm/dma-mapping.h
#	arch/h8300/include/asm/dma-mapping.h
#	arch/ia64/include/asm/dma-mapping.h
#	arch/microblaze/include/asm/dma-mapping.h
#	arch/mips/include/asm/dma-mapping.h
#	arch/mips/loongson64/common/dma-swiotlb.c
#	arch/powerpc/include/asm/dma-mapping.h
#	arch/s390/pci/pci_dma.c
#	arch/sh/include/asm/dma-mapping.h
#	arch/unicore32/include/asm/dma-mapping.h
#	arch/x86/include/asm/dma-mapping.h
#	arch/xtensa/include/asm/dma-mapping.h
#	include/asm-generic/dma-mapping-common.h
diff --cc arch/alpha/include/asm/dma-mapping.h
index dfa32f061320,72a8ca7796d9..000000000000
--- a/arch/alpha/include/asm/dma-mapping.h
+++ b/arch/alpha/include/asm/dma-mapping.h
@@@ -12,42 -12,6 +12,45 @@@ static inline struct dma_map_ops *get_d
  
  #include <asm-generic/dma-mapping-common.h>
  
++<<<<<<< HEAD
 +#define dma_alloc_coherent(d,s,h,f)	dma_alloc_attrs(d,s,h,f,NULL)
 +
 +static inline void *dma_alloc_attrs(struct device *dev, size_t size,
 +				    dma_addr_t *dma_handle, gfp_t gfp,
 +				    struct dma_attrs *attrs)
 +{
 +	return get_dma_ops(dev)->alloc(dev, size, dma_handle, gfp, attrs);
 +}
 +
 +#define dma_free_coherent(d,s,c,h) dma_free_attrs(d,s,c,h,NULL)
 +
 +static inline void dma_free_attrs(struct device *dev, size_t size,
 +				  void *vaddr, dma_addr_t dma_handle,
 +				  struct dma_attrs *attrs)
 +{
 +	get_dma_ops(dev)->free(dev, size, vaddr, dma_handle, attrs);
 +}
 +
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	return get_dma_ops(dev)->mapping_error(dev, dma_addr);
 +}
 +
 +static inline int dma_supported(struct device *dev, u64 mask)
 +{
 +	return get_dma_ops(dev)->dma_supported(dev, mask);
 +}
 +
 +static inline int dma_set_mask(struct device *dev, u64 mask)
 +{
 +	return get_dma_ops(dev)->set_dma_mask(dev, mask);
 +}
 +
 +#define dma_alloc_noncoherent(d, s, h, f)	dma_alloc_coherent(d, s, h, f)
 +#define dma_free_noncoherent(d, s, v, h)	dma_free_coherent(d, s, v, h)
 +
++=======
++>>>>>>> 452e06af1f01 (dma-mapping: consolidate dma_set_mask)
  #define dma_cache_sync(dev, va, size, dir)		  ((void)0)
  
  #endif	/* _ALPHA_DMA_MAPPING_H */
diff --cc arch/arm64/include/asm/dma-mapping.h
index 994776894198,cfdb34bedbcd..000000000000
--- a/arch/arm64/include/asm/dma-mapping.h
+++ b/arch/arm64/include/asm/dma-mapping.h
@@@ -21,54 -21,69 +21,57 @@@
  #include <linux/types.h>
  #include <linux/vmalloc.h>
  
 -#include <xen/xen.h>
 -#include <asm/xen/hypervisor.h>
 +#include <asm-generic/dma-coherent.h>
 +
 +#define ARCH_HAS_DMA_GET_REQUIRED_MASK
  
 -#define DMA_ERROR_CODE	(~(dma_addr_t)0)
  extern struct dma_map_ops *dma_ops;
 -extern struct dma_map_ops dummy_dma_ops;
  
 -static inline struct dma_map_ops *__generic_dma_ops(struct device *dev)
 +static inline struct dma_map_ops *get_dma_ops(struct device *dev)
  {
 -	if (unlikely(!dev))
 +	if (unlikely(!dev) || !dev->archdata.dma_ops)
  		return dma_ops;
 -	else if (dev->archdata.dma_ops)
 +	else
  		return dev->archdata.dma_ops;
 -	else if (acpi_disabled)
 -		return dma_ops;
 -
 -	/*
 -	 * When ACPI is enabled, if arch_set_dma_ops is not called,
 -	 * we will disable device DMA capability by setting it
 -	 * to dummy_dma_ops.
 -	 */
 -	return &dummy_dma_ops;
  }
  
 -static inline struct dma_map_ops *get_dma_ops(struct device *dev)
 +#include <asm-generic/dma-mapping-common.h>
 +
 +static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)
  {
 -	if (xen_initial_domain())
 -		return xen_dma_ops;
 -	else
 -		return __generic_dma_ops(dev);
 +	return (dma_addr_t)paddr;
  }
  
 -static inline void arch_setup_dma_ops(struct device *dev, u64 dma_base, u64 size,
 -				      struct iommu_ops *iommu, bool coherent)
 +static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t dev_addr)
  {
 -	if (!acpi_disabled && !dev->archdata.dma_ops)
 -		dev->archdata.dma_ops = dma_ops;
 -
 -	dev->archdata.dma_coherent = coherent;
 +	return (phys_addr_t)dev_addr;
  }
 -#define arch_setup_dma_ops	arch_setup_dma_ops
  
 -/* do not use this function in a driver */
 -static inline bool is_device_dma_coherent(struct device *dev)
++<<<<<<< HEAD
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t dev_addr)
  {
 -	if (!dev)
 -		return false;
 -	return dev->archdata.dma_coherent;
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +	debug_dma_mapping_error(dev, dev_addr);
 +	return ops->mapping_error(dev, dev_addr);
  }
  
 -#include <asm-generic/dma-mapping-common.h>
 -
 -static inline dma_addr_t phys_to_dma(struct device *dev, phys_addr_t paddr)
 +static inline int dma_supported(struct device *dev, u64 mask)
  {
 -	return (dma_addr_t)paddr;
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +	return ops->dma_supported(dev, mask);
  }
  
 -static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t dev_addr)
 +static inline int dma_set_mask(struct device *dev, u64 mask)
  {
 -	return (phys_addr_t)dev_addr;
 +	if (!dev->dma_mask || !dma_supported(dev, mask))
 +		return -EIO;
 +	*dev->dma_mask = mask;
 +
 +	return 0;
  }
  
++=======
++>>>>>>> 452e06af1f01 (dma-mapping: consolidate dma_set_mask)
  static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)
  {
  	if (!dev->dma_mask)
diff --cc arch/ia64/include/asm/dma-mapping.h
index cf3ab7e784b5,9beccf8010bd..000000000000
--- a/arch/ia64/include/asm/dma-mapping.h
+++ b/arch/ia64/include/asm/dma-mapping.h
@@@ -55,28 -27,6 +55,31 @@@ static inline void dma_free_attrs(struc
  
  #include <asm-generic/dma-mapping-common.h>
  
++<<<<<<< HEAD
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t daddr)
 +{
 +	struct dma_map_ops *ops = platform_dma_get_ops(dev);
 +	debug_dma_mapping_error(dev, daddr);
 +	return ops->mapping_error(dev, daddr);
 +}
 +
 +static inline int dma_supported(struct device *dev, u64 mask)
 +{
 +	struct dma_map_ops *ops = platform_dma_get_ops(dev);
 +	return ops->dma_supported(dev, mask);
 +}
 +
 +static inline int
 +dma_set_mask (struct device *dev, u64 mask)
 +{
 +	if (!dev->dma_mask || !dma_supported(dev, mask))
 +		return -EIO;
 +	*dev->dma_mask = mask;
 +	return 0;
 +}
 +
++=======
++>>>>>>> 452e06af1f01 (dma-mapping: consolidate dma_set_mask)
  static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)
  {
  	if (!dev->dma_mask)
diff --cc arch/microblaze/include/asm/dma-mapping.h
index 46460f1c49c4,24b12970c9cf..000000000000
--- a/arch/microblaze/include/asm/dma-mapping.h
+++ b/arch/microblaze/include/asm/dma-mapping.h
@@@ -52,49 -41,11 +52,52 @@@ extern struct dma_map_ops dma_direct_op
  
  static inline struct dma_map_ops *get_dma_ops(struct device *dev)
  {
 -	return &dma_direct_ops;
 +	/* We don't handle the NULL dev case for ISA for now. We could
 +	 * do it via an out of line call but it is not needed for now. The
 +	 * only ISA DMA device we support is the floppy and we have a hack
 +	 * in the floppy driver directly to get a device for us.
 +	 */
 +	if (unlikely(!dev) || !dev->archdata.dma_ops)
 +		return NULL;
 +
 +	return dev->archdata.dma_ops;
 +}
 +
 +static inline void set_dma_ops(struct device *dev, struct dma_map_ops *ops)
 +{
 +	dev->archdata.dma_ops = ops;
 +}
 +
 +static inline int dma_supported(struct device *dev, u64 mask)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +
 +	if (unlikely(!ops))
 +		return 0;
 +	if (!ops->dma_supported)
 +		return 1;
 +	return ops->dma_supported(dev, mask);
 +}
 +
++<<<<<<< HEAD
 +static inline int dma_set_mask(struct device *dev, u64 dma_mask)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +
 +	if (unlikely(ops == NULL))
 +		return -EIO;
 +	if (ops->set_dma_mask)
 +		return ops->set_dma_mask(dev, dma_mask);
 +	if (!dev->dma_mask || !dma_supported(dev, dma_mask))
 +		return -EIO;
 +	*dev->dma_mask = dma_mask;
 +	return 0;
  }
  
  #include <asm-generic/dma-mapping-common.h>
  
++=======
++>>>>>>> 452e06af1f01 (dma-mapping: consolidate dma_set_mask)
  static inline void __dma_sync(unsigned long paddr,
  			      size_t size, enum dma_data_direction direction)
  {
diff --cc arch/mips/include/asm/dma-mapping.h
index 84238c574d5e,e604f760c4a0..000000000000
--- a/arch/mips/include/asm/dma-mapping.h
+++ b/arch/mips/include/asm/dma-mapping.h
@@@ -32,31 -31,6 +32,34 @@@ static inline void dma_mark_clean(void 
  
  #include <asm-generic/dma-mapping-common.h>
  
++<<<<<<< HEAD
 +static inline int dma_supported(struct device *dev, u64 mask)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +	return ops->dma_supported(dev, mask);
 +}
 +
 +static inline int dma_mapping_error(struct device *dev, u64 mask)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +
 +	debug_dma_mapping_error(dev, mask);
 +	return ops->mapping_error(dev, mask);
 +}
 +
 +static inline int
 +dma_set_mask(struct device *dev, u64 mask)
 +{
 +	if(!dev->dma_mask || !dma_supported(dev, mask))
 +		return -EIO;
 +
 +	*dev->dma_mask = mask;
 +
 +	return 0;
 +}
 +
++=======
++>>>>>>> 452e06af1f01 (dma-mapping: consolidate dma_set_mask)
  extern void dma_cache_sync(struct device *dev, void *vaddr, size_t size,
  	       enum dma_data_direction direction);
  
diff --cc arch/powerpc/include/asm/dma-mapping.h
index c6f39b7c9f40,7f522c021dc3..000000000000
--- a/arch/powerpc/include/asm/dma-mapping.h
+++ b/arch/powerpc/include/asm/dma-mapping.h
@@@ -120,20 -122,11 +120,26 @@@ static inline void set_dma_offset(struc
  /* this will be removed soon */
  #define flush_write_buffers()
  
+ #define HAVE_ARCH_DMA_SET_MASK 1
+ extern int dma_set_mask(struct device *dev, u64 dma_mask);
+ 
  #include <asm-generic/dma-mapping-common.h>
  
++<<<<<<< HEAD
 +static inline int dma_supported(struct device *dev, u64 mask)
 +{
 +	struct dma_map_ops *dma_ops = get_dma_ops(dev);
 +
 +	if (unlikely(dma_ops == NULL))
 +		return 0;
 +	if (dma_ops->dma_supported == NULL)
 +		return 1;
 +	return dma_ops->dma_supported(dev, mask);
 +}
 +
 +extern int dma_set_mask(struct device *dev, u64 dma_mask);
++=======
++>>>>>>> 452e06af1f01 (dma-mapping: consolidate dma_set_mask)
  extern int __dma_set_mask(struct device *dev, u64 dma_mask);
  extern u64 __dma_get_required_mask(struct device *dev);
  
diff --cc arch/s390/pci/pci_dma.c
index 115b5e43452a,37505b8b4093..000000000000
--- a/arch/s390/pci/pci_dma.c
+++ b/arch/s390/pci/pci_dma.c
@@@ -275,26 -262,6 +275,29 @@@ out
  	spin_unlock_irqrestore(&zdev->iommu_bitmap_lock, flags);
  }
  
++<<<<<<< HEAD
 +int dma_set_mask(struct device *dev, u64 mask)
 +{
 +	if (!dev->dma_mask || !dma_supported(dev, mask))
 +		return -EIO;
 +
 +	*dev->dma_mask = mask;
 +	return 0;
 +}
 +EXPORT_SYMBOL_GPL(dma_set_mask);
 +
 +static inline void zpci_err_dma(unsigned long rc, unsigned long addr)
 +{
 +	struct {
 +		unsigned long rc;
 +		unsigned long addr;
 +	} __packed data = {rc, addr};
 +
 +	zpci_err_hex(&data, sizeof(data));
 +}
 +
++=======
++>>>>>>> 452e06af1f01 (dma-mapping: consolidate dma_set_mask)
  static dma_addr_t s390_dma_map_pages(struct device *dev, struct page *page,
  				     unsigned long offset, size_t size,
  				     enum dma_data_direction direction,
diff --cc arch/sh/include/asm/dma-mapping.h
index b437f2c780b8,a3745a3fe029..000000000000
--- a/arch/sh/include/asm/dma-mapping.h
+++ b/arch/sh/include/asm/dma-mapping.h
@@@ -9,33 -9,10 +9,36 @@@ static inline struct dma_map_ops *get_d
  	return dma_ops;
  }
  
 -#define DMA_ERROR_CODE 0
 -
 +#include <asm-generic/dma-coherent.h>
  #include <asm-generic/dma-mapping-common.h>
  
++<<<<<<< HEAD
 +static inline int dma_supported(struct device *dev, u64 mask)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +
 +	if (ops->dma_supported)
 +		return ops->dma_supported(dev, mask);
 +
 +	return 1;
 +}
 +
 +static inline int dma_set_mask(struct device *dev, u64 mask)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +
 +	if (!dev->dma_mask || !dma_supported(dev, mask))
 +		return -EIO;
 +	if (ops->set_dma_mask)
 +		return ops->set_dma_mask(dev, mask);
 +
 +	*dev->dma_mask = mask;
 +
 +	return 0;
 +}
 +
++=======
++>>>>>>> 452e06af1f01 (dma-mapping: consolidate dma_set_mask)
  void dma_cache_sync(struct device *dev, void *vaddr, size_t size,
  		    enum dma_data_direction dir);
  
diff --cc arch/unicore32/include/asm/dma-mapping.h
index 366460a81796,8140e053ccd3..000000000000
--- a/arch/unicore32/include/asm/dma-mapping.h
+++ b/arch/unicore32/include/asm/dma-mapping.h
@@@ -72,41 -50,6 +72,44 @@@ static inline phys_addr_t dma_to_phys(s
  
  static inline void dma_mark_clean(void *addr, size_t size) {}
  
++<<<<<<< HEAD
 +static inline int dma_set_mask(struct device *dev, u64 dma_mask)
 +{
 +	if (!dev->dma_mask || !dma_supported(dev, dma_mask))
 +		return -EIO;
 +
 +	*dev->dma_mask = dma_mask;
 +
 +	return 0;
 +}
 +
 +#define dma_alloc_coherent(d,s,h,f)	dma_alloc_attrs(d,s,h,f,NULL)
 +
 +static inline void *dma_alloc_attrs(struct device *dev, size_t size,
 +				    dma_addr_t *dma_handle, gfp_t flag,
 +				    struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *dma_ops = get_dma_ops(dev);
 +
 +	return dma_ops->alloc(dev, size, dma_handle, flag, attrs);
 +}
 +
 +#define dma_free_coherent(d,s,c,h) dma_free_attrs(d,s,c,h,NULL)
 +
 +static inline void dma_free_attrs(struct device *dev, size_t size,
 +				  void *cpu_addr, dma_addr_t dma_handle,
 +				  struct dma_attrs *attrs)
 +{
 +	struct dma_map_ops *dma_ops = get_dma_ops(dev);
 +
 +	dma_ops->free(dev, size, cpu_addr, dma_handle, attrs);
 +}
 +
 +#define dma_alloc_noncoherent(d, s, h, f) dma_alloc_coherent(d, s, h, f)
 +#define dma_free_noncoherent(d, s, v, h) dma_free_coherent(d, s, v, h)
 +
++=======
++>>>>>>> 452e06af1f01 (dma-mapping: consolidate dma_set_mask)
  static inline void dma_cache_sync(struct device *dev, void *vaddr,
  		size_t size, enum dma_data_direction direction)
  {
diff --cc arch/x86/include/asm/dma-mapping.h
index 1f5b7287d1ad,953b7263f844..000000000000
--- a/arch/x86/include/asm/dma-mapping.h
+++ b/arch/x86/include/asm/dma-mapping.h
@@@ -41,25 -40,14 +41,28 @@@ static inline struct dma_map_ops *get_d
  #endif
  }
  
 -bool arch_dma_alloc_attrs(struct device **dev, gfp_t *gfp);
 -#define arch_dma_alloc_attrs arch_dma_alloc_attrs
 +#include <asm-generic/dma-mapping-common.h>
  
 -#define HAVE_ARCH_DMA_SUPPORTED 1
 -extern int dma_supported(struct device *hwdev, u64 mask);
++<<<<<<< HEAD
 +/* Make sure we keep the same behaviour */
 +static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	struct dma_map_ops *ops = get_dma_ops(dev);
 +	debug_dma_mapping_error(dev, dma_addr);
 +	if (ops->mapping_error)
 +		return ops->mapping_error(dev, dma_addr);
  
 -#include <asm-generic/dma-mapping-common.h>
 +	return (dma_addr == DMA_ERROR_CODE);
 +}
 +
 +#define dma_alloc_noncoherent(d, s, h, f) dma_alloc_coherent(d, s, h, f)
 +#define dma_free_noncoherent(d, s, v, h) dma_free_coherent(d, s, v, h)
  
 +extern int dma_supported(struct device *hwdev, u64 mask);
 +extern int dma_set_mask(struct device *dev, u64 mask);
 +
++=======
++>>>>>>> 452e06af1f01 (dma-mapping: consolidate dma_set_mask)
  extern void *dma_generic_alloc_coherent(struct device *dev, size_t size,
  					dma_addr_t *dma_addr, gfp_t flag,
  					struct dma_attrs *attrs);
diff --cc arch/xtensa/include/asm/dma-mapping.h
index 172a02a6ad14,4427f38b634e..000000000000
--- a/arch/xtensa/include/asm/dma-mapping.h
+++ b/arch/xtensa/include/asm/dma-mapping.h
@@@ -18,171 -20,19 +18,176 @@@
  
  #define DMA_ERROR_CODE		(~(dma_addr_t)0x0)
  
 -extern struct dma_map_ops xtensa_dma_map_ops;
 +/*
 + * DMA-consistent mapping functions.
 + */
 +
 +extern void *consistent_alloc(int, size_t, dma_addr_t, unsigned long);
 +extern void consistent_free(void*, size_t, dma_addr_t);
 +extern void consistent_sync(void*, size_t, int);
 +
 +#define dma_alloc_noncoherent(d, s, h, f) dma_alloc_coherent(d, s, h, f)
 +#define dma_free_noncoherent(d, s, v, h) dma_free_coherent(d, s, v, h)
 +
 +void *dma_alloc_coherent(struct device *dev, size_t size,
 +			   dma_addr_t *dma_handle, gfp_t flag);
 +
 +void dma_free_coherent(struct device *dev, size_t size,
 +			 void *vaddr, dma_addr_t dma_handle);
  
 -static inline struct dma_map_ops *get_dma_ops(struct device *dev)
 +static inline dma_addr_t
 +dma_map_single(struct device *dev, void *ptr, size_t size,
 +	       enum dma_data_direction direction)
  {
 -	if (dev && dev->archdata.dma_ops)
 -		return dev->archdata.dma_ops;
 -	else
 -		return &xtensa_dma_map_ops;
 +	BUG_ON(direction == DMA_NONE);
 +	consistent_sync(ptr, size, direction);
 +	return virt_to_phys(ptr);
  }
  
 -#include <asm-generic/dma-mapping-common.h>
 +static inline void
 +dma_unmap_single(struct device *dev, dma_addr_t dma_addr, size_t size,
 +		 enum dma_data_direction direction)
 +{
 +	BUG_ON(direction == DMA_NONE);
 +}
 +
 +static inline int
 +dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,
 +	   enum dma_data_direction direction)
 +{
 +	int i;
  
 +	BUG_ON(direction == DMA_NONE);
 +
 +	for (i = 0; i < nents; i++, sg++ ) {
 +		BUG_ON(!sg_page(sg));
 +
 +		sg->dma_address = sg_phys(sg);
 +		consistent_sync(sg_virt(sg), sg->length, direction);
 +	}
 +
 +	return nents;
 +}
 +
 +static inline dma_addr_t
 +dma_map_page(struct device *dev, struct page *page, unsigned long offset,
 +	     size_t size, enum dma_data_direction direction)
 +{
 +	BUG_ON(direction == DMA_NONE);
 +	return (dma_addr_t)(page_to_pfn(page)) * PAGE_SIZE + offset;
 +}
 +
 +static inline void
 +dma_unmap_page(struct device *dev, dma_addr_t dma_address, size_t size,
 +	       enum dma_data_direction direction)
 +{
 +	BUG_ON(direction == DMA_NONE);
 +}
 +
 +
 +static inline void
 +dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nhwentries,
 +	     enum dma_data_direction direction)
 +{
 +	BUG_ON(direction == DMA_NONE);
 +}
 +
 +static inline void
 +dma_sync_single_for_cpu(struct device *dev, dma_addr_t dma_handle, size_t size,
 +		enum dma_data_direction direction)
 +{
 +	consistent_sync((void *)bus_to_virt(dma_handle), size, direction);
 +}
 +
 +static inline void
 +dma_sync_single_for_device(struct device *dev, dma_addr_t dma_handle,
 +		           size_t size, enum dma_data_direction direction)
 +{
 +	consistent_sync((void *)bus_to_virt(dma_handle), size, direction);
 +}
 +
 +static inline void
 +dma_sync_single_range_for_cpu(struct device *dev, dma_addr_t dma_handle,
 +		      unsigned long offset, size_t size,
 +		      enum dma_data_direction direction)
 +{
 +
 +	consistent_sync((void *)bus_to_virt(dma_handle)+offset,size,direction);
 +}
 +
 +static inline void
 +dma_sync_single_range_for_device(struct device *dev, dma_addr_t dma_handle,
 +		      unsigned long offset, size_t size,
 +		      enum dma_data_direction direction)
 +{
 +
 +	consistent_sync((void *)bus_to_virt(dma_handle)+offset,size,direction);
 +}
 +static inline void
 +dma_sync_sg_for_cpu(struct device *dev, struct scatterlist *sg, int nelems,
 +		 enum dma_data_direction dir)
 +{
 +	int i;
 +	for (i = 0; i < nelems; i++, sg++)
 +		consistent_sync(sg_virt(sg), sg->length, dir);
 +}
 +
 +static inline void
 +dma_sync_sg_for_device(struct device *dev, struct scatterlist *sg, int nelems,
 +		 enum dma_data_direction dir)
 +{
 +	int i;
 +	for (i = 0; i < nelems; i++, sg++)
 +		consistent_sync(sg_virt(sg), sg->length, dir);
 +}
 +static inline int
 +dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 +{
 +	return 0;
 +}
 +
 +static inline int
 +dma_supported(struct device *dev, u64 mask)
 +{
 +	return 1;
 +}
 +
++<<<<<<< HEAD
 +static inline int
 +dma_set_mask(struct device *dev, u64 mask)
 +{
 +	if(!dev->dma_mask || !dma_supported(dev, mask))
 +		return -EIO;
 +
 +	*dev->dma_mask = mask;
 +
 +	return 0;
 +}
 +
 +static inline void
 +dma_cache_sync(struct device *dev, void *vaddr, size_t size,
 +	       enum dma_data_direction direction)
 +{
 +	consistent_sync(vaddr, size, direction);
 +}
 +
 +/* Not supported for now */
 +static inline int dma_mmap_coherent(struct device *dev,
 +				    struct vm_area_struct *vma, void *cpu_addr,
 +				    dma_addr_t dma_addr, size_t size)
 +{
 +	return -EINVAL;
 +}
 +
 +static inline int dma_get_sgtable(struct device *dev, struct sg_table *sgt,
 +				  void *cpu_addr, dma_addr_t dma_addr,
 +				  size_t size)
 +{
 +	return -EINVAL;
 +}
++=======
+ void dma_cache_sync(struct device *dev, void *vaddr, size_t size,
+ 		    enum dma_data_direction direction);
++>>>>>>> 452e06af1f01 (dma-mapping: consolidate dma_set_mask)
  
  #endif	/* _XTENSA_DMA_MAPPING_H */
diff --cc include/asm-generic/dma-mapping-common.h
index de8bf89940f8,b1bc954eccf3..000000000000
--- a/include/asm-generic/dma-mapping-common.h
+++ b/include/asm-generic/dma-mapping-common.h
@@@ -231,4 -238,121 +231,124 @@@ dma_get_sgtable_attrs(struct device *de
  
  #define dma_get_sgtable(d, t, v, h, s) dma_get_sgtable_attrs(d, t, v, h, s, NULL)
  
++<<<<<<< HEAD
++=======
+ #ifndef arch_dma_alloc_attrs
+ #define arch_dma_alloc_attrs(dev, flag)	(true)
+ #endif
+ 
+ static inline void *dma_alloc_attrs(struct device *dev, size_t size,
+ 				       dma_addr_t *dma_handle, gfp_t flag,
+ 				       struct dma_attrs *attrs)
+ {
+ 	struct dma_map_ops *ops = get_dma_ops(dev);
+ 	void *cpu_addr;
+ 
+ 	BUG_ON(!ops);
+ 
+ 	if (dma_alloc_from_coherent(dev, size, dma_handle, &cpu_addr))
+ 		return cpu_addr;
+ 
+ 	if (!arch_dma_alloc_attrs(&dev, &flag))
+ 		return NULL;
+ 	if (!ops->alloc)
+ 		return NULL;
+ 
+ 	cpu_addr = ops->alloc(dev, size, dma_handle, flag, attrs);
+ 	debug_dma_alloc_coherent(dev, size, *dma_handle, cpu_addr);
+ 	return cpu_addr;
+ }
+ 
+ static inline void dma_free_attrs(struct device *dev, size_t size,
+ 				     void *cpu_addr, dma_addr_t dma_handle,
+ 				     struct dma_attrs *attrs)
+ {
+ 	struct dma_map_ops *ops = get_dma_ops(dev);
+ 
+ 	BUG_ON(!ops);
+ 	WARN_ON(irqs_disabled());
+ 
+ 	if (dma_release_from_coherent(dev, get_order(size), cpu_addr))
+ 		return;
+ 
+ 	if (!ops->free)
+ 		return;
+ 
+ 	debug_dma_free_coherent(dev, size, cpu_addr, dma_handle);
+ 	ops->free(dev, size, cpu_addr, dma_handle, attrs);
+ }
+ 
+ static inline void *dma_alloc_coherent(struct device *dev, size_t size,
+ 		dma_addr_t *dma_handle, gfp_t flag)
+ {
+ 	return dma_alloc_attrs(dev, size, dma_handle, flag, NULL);
+ }
+ 
+ static inline void dma_free_coherent(struct device *dev, size_t size,
+ 		void *cpu_addr, dma_addr_t dma_handle)
+ {
+ 	return dma_free_attrs(dev, size, cpu_addr, dma_handle, NULL);
+ }
+ 
+ static inline void *dma_alloc_noncoherent(struct device *dev, size_t size,
+ 		dma_addr_t *dma_handle, gfp_t gfp)
+ {
+ 	DEFINE_DMA_ATTRS(attrs);
+ 
+ 	dma_set_attr(DMA_ATTR_NON_CONSISTENT, &attrs);
+ 	return dma_alloc_attrs(dev, size, dma_handle, gfp, &attrs);
+ }
+ 
+ static inline void dma_free_noncoherent(struct device *dev, size_t size,
+ 		void *cpu_addr, dma_addr_t dma_handle)
+ {
+ 	DEFINE_DMA_ATTRS(attrs);
+ 
+ 	dma_set_attr(DMA_ATTR_NON_CONSISTENT, &attrs);
+ 	dma_free_attrs(dev, size, cpu_addr, dma_handle, &attrs);
+ }
+ 
+ static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
+ {
+ 	debug_dma_mapping_error(dev, dma_addr);
+ 
+ 	if (get_dma_ops(dev)->mapping_error)
+ 		return get_dma_ops(dev)->mapping_error(dev, dma_addr);
+ 
+ #ifdef DMA_ERROR_CODE
+ 	return dma_addr == DMA_ERROR_CODE;
+ #else
+ 	return 0;
+ #endif
+ }
+ 
+ #ifndef HAVE_ARCH_DMA_SUPPORTED
+ static inline int dma_supported(struct device *dev, u64 mask)
+ {
+ 	struct dma_map_ops *ops = get_dma_ops(dev);
+ 
+ 	if (!ops)
+ 		return 0;
+ 	if (!ops->dma_supported)
+ 		return 1;
+ 	return ops->dma_supported(dev, mask);
+ }
+ #endif
+ 
+ #ifndef HAVE_ARCH_DMA_SET_MASK
+ static inline int dma_set_mask(struct device *dev, u64 mask)
+ {
+ 	struct dma_map_ops *ops = get_dma_ops(dev);
+ 
+ 	if (ops->set_dma_mask)
+ 		return ops->set_dma_mask(dev, mask);
+ 
+ 	if (!dev->dma_mask || !dma_supported(dev, mask))
+ 		return -EIO;
+ 	*dev->dma_mask = mask;
+ 	return 0;
+ }
+ #endif
+ 
++>>>>>>> 452e06af1f01 (dma-mapping: consolidate dma_set_mask)
  #endif
* Unmerged path arch/h8300/include/asm/dma-mapping.h
* Unmerged path arch/mips/loongson64/common/dma-swiotlb.c
* Unmerged path arch/alpha/include/asm/dma-mapping.h
diff --git a/arch/alpha/kernel/pci-noop.c b/arch/alpha/kernel/pci-noop.c
index df24b76f9246..2b1f4a1e9272 100644
--- a/arch/alpha/kernel/pci-noop.c
+++ b/arch/alpha/kernel/pci-noop.c
@@ -166,15 +166,6 @@ static int alpha_noop_supported(struct device *dev, u64 mask)
 	return mask < 0x00ffffffUL ? 0 : 1;
 }
 
-static int alpha_noop_set_mask(struct device *dev, u64 mask)
-{
-	if (!dev->dma_mask || !dma_supported(dev, mask))
-		return -EIO;
-
-	*dev->dma_mask = mask;
-	return 0;
-}
-
 struct dma_map_ops alpha_noop_ops = {
 	.alloc			= alpha_noop_alloc_coherent,
 	.free			= alpha_noop_free_coherent,
@@ -182,7 +173,6 @@ struct dma_map_ops alpha_noop_ops = {
 	.map_sg			= alpha_noop_map_sg,
 	.mapping_error		= alpha_noop_mapping_error,
 	.dma_supported		= alpha_noop_supported,
-	.set_dma_mask		= alpha_noop_set_mask,
 };
 
 struct dma_map_ops *dma_ops = &alpha_noop_ops;
diff --git a/arch/alpha/kernel/pci_iommu.c b/arch/alpha/kernel/pci_iommu.c
index a21d0ab3b19e..bcfeb704cfa0 100644
--- a/arch/alpha/kernel/pci_iommu.c
+++ b/arch/alpha/kernel/pci_iommu.c
@@ -939,16 +939,6 @@ static int alpha_pci_mapping_error(struct device *dev, dma_addr_t dma_addr)
 	return dma_addr == 0;
 }
 
-static int alpha_pci_set_mask(struct device *dev, u64 mask)
-{
-	if (!dev->dma_mask ||
-	    !pci_dma_supported(alpha_gendev_to_pci(dev), mask))
-		return -EIO;
-
-	*dev->dma_mask = mask;
-	return 0;
-}
-
 struct dma_map_ops alpha_pci_ops = {
 	.alloc			= alpha_pci_alloc_coherent,
 	.free			= alpha_pci_free_coherent,
@@ -958,7 +948,6 @@ struct dma_map_ops alpha_pci_ops = {
 	.unmap_sg		= alpha_pci_unmap_sg,
 	.mapping_error		= alpha_pci_mapping_error,
 	.dma_supported		= alpha_pci_supported,
-	.set_dma_mask		= alpha_pci_set_mask,
 };
 
 struct dma_map_ops *dma_ops = &alpha_pci_ops;
diff --git a/arch/arm/include/asm/dma-mapping.h b/arch/arm/include/asm/dma-mapping.h
index 5b579b951503..dcda4c151eb5 100644
--- a/arch/arm/include/asm/dma-mapping.h
+++ b/arch/arm/include/asm/dma-mapping.h
@@ -30,11 +30,6 @@ static inline void set_dma_ops(struct device *dev, struct dma_map_ops *ops)
 
 #include <asm-generic/dma-mapping-common.h>
 
-static inline int dma_set_mask(struct device *dev, u64 mask)
-{
-	return get_dma_ops(dev)->set_dma_mask(dev, mask);
-}
-
 #ifdef __arch_page_to_dma
 #error Please update to __arch_pfn_to_dma
 #endif
* Unmerged path arch/arm64/include/asm/dma-mapping.h
* Unmerged path arch/h8300/include/asm/dma-mapping.h
diff --git a/arch/hexagon/include/asm/dma-mapping.h b/arch/hexagon/include/asm/dma-mapping.h
index 85e9935660cb..bba63384ccdc 100644
--- a/arch/hexagon/include/asm/dma-mapping.h
+++ b/arch/hexagon/include/asm/dma-mapping.h
@@ -47,7 +47,6 @@ static inline struct dma_map_ops *get_dma_ops(struct device *dev)
 }
 
 extern int dma_supported(struct device *dev, u64 mask);
-extern int dma_set_mask(struct device *dev, u64 mask);
 extern int dma_is_consistent(struct device *dev, dma_addr_t dma_handle);
 extern void dma_cache_sync(struct device *dev, void *vaddr, size_t size,
 			   enum dma_data_direction direction);
diff --git a/arch/hexagon/kernel/dma.c b/arch/hexagon/kernel/dma.c
index b74f9bae31a3..9e3ddf792bd3 100644
--- a/arch/hexagon/kernel/dma.c
+++ b/arch/hexagon/kernel/dma.c
@@ -44,17 +44,6 @@ int dma_supported(struct device *dev, u64 mask)
 }
 EXPORT_SYMBOL(dma_supported);
 
-int dma_set_mask(struct device *dev, u64 mask)
-{
-	if (!dev->dma_mask || !dma_supported(dev, mask))
-		return -EIO;
-
-	*dev->dma_mask = mask;
-
-	return 0;
-}
-EXPORT_SYMBOL(dma_set_mask);
-
 static struct gen_pool *coherent_pool;
 
 
* Unmerged path arch/ia64/include/asm/dma-mapping.h
* Unmerged path arch/microblaze/include/asm/dma-mapping.h
* Unmerged path arch/mips/include/asm/dma-mapping.h
* Unmerged path arch/mips/loongson64/common/dma-swiotlb.c
diff --git a/arch/openrisc/include/asm/dma-mapping.h b/arch/openrisc/include/asm/dma-mapping.h
index fab8628e1b6e..8f79d3916419 100644
--- a/arch/openrisc/include/asm/dma-mapping.h
+++ b/arch/openrisc/include/asm/dma-mapping.h
@@ -98,13 +98,4 @@ static inline int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 	return 0;
 }
 
-static inline int dma_set_mask(struct device *dev, u64 dma_mask)
-{
-	if (!dev->dma_mask || !dma_supported(dev, dma_mask))
-		return -EIO;
-
-	*dev->dma_mask = dma_mask;
-
-	return 0;
-}
 #endif	/* __ASM_OPENRISC_DMA_MAPPING_H */
* Unmerged path arch/powerpc/include/asm/dma-mapping.h
diff --git a/arch/s390/include/asm/dma-mapping.h b/arch/s390/include/asm/dma-mapping.h
index 3f2d5669375a..82855c137957 100644
--- a/arch/s390/include/asm/dma-mapping.h
+++ b/arch/s390/include/asm/dma-mapping.h
@@ -20,8 +20,6 @@ static inline struct dma_map_ops *get_dma_ops(struct device *dev)
 	return &dma_noop_ops;
 }
 
-extern int dma_set_mask(struct device *dev, u64 mask);
-
 static inline void dma_cache_sync(struct device *dev, void *vaddr, size_t size,
 				  enum dma_data_direction direction)
 {
* Unmerged path arch/s390/pci/pci_dma.c
* Unmerged path arch/sh/include/asm/dma-mapping.h
diff --git a/arch/sparc/include/asm/dma-mapping.h b/arch/sparc/include/asm/dma-mapping.h
index 05fe53f5346e..cfb51e5b76e0 100644
--- a/arch/sparc/include/asm/dma-mapping.h
+++ b/arch/sparc/include/asm/dma-mapping.h
@@ -29,7 +29,7 @@ static inline struct dma_map_ops *get_dma_ops(struct device *dev)
 	return dma_ops;
 }
 
-#include <asm-generic/dma-mapping-common.h>
+#define HAVE_ARCH_DMA_SET_MASK 1
 
 #define dma_alloc_coherent(d,s,h,f)	dma_alloc_attrs(d,s,h,f,NULL)
 
@@ -76,4 +76,6 @@ static inline int dma_set_mask(struct device *dev, u64 mask)
 	return -EINVAL;
 }
 
+#include <asm-generic/dma-mapping-common.h>
+
 #endif
diff --git a/arch/tile/include/asm/dma-mapping.h b/arch/tile/include/asm/dma-mapping.h
index f2ff191376b4..51c9f952f36f 100644
--- a/arch/tile/include/asm/dma-mapping.h
+++ b/arch/tile/include/asm/dma-mapping.h
@@ -54,8 +54,6 @@ static inline phys_addr_t dma_to_phys(struct device *dev, dma_addr_t daddr)
 
 static inline void dma_mark_clean(void *addr, size_t size) {}
 
-#include <asm-generic/dma-mapping-common.h>
-
 static inline void set_dma_ops(struct device *dev, struct dma_map_ops *ops)
 {
 	dev->archdata.dma_ops = ops;
@@ -69,6 +67,10 @@ static inline bool dma_capable(struct device *dev, dma_addr_t addr, size_t size)
 	return addr + size - 1 <= *dev->dma_mask;
 }
 
+#define HAVE_ARCH_DMA_SET_MASK 1
+
+#include <asm-generic/dma-mapping-common.h>
+
 static inline int
 dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 {
* Unmerged path arch/unicore32/include/asm/dma-mapping.h
* Unmerged path arch/x86/include/asm/dma-mapping.h
diff --git a/arch/x86/kernel/pci-dma.c b/arch/x86/kernel/pci-dma.c
index b09eae608519..0ab62b1f70e0 100644
--- a/arch/x86/kernel/pci-dma.c
+++ b/arch/x86/kernel/pci-dma.c
@@ -58,17 +58,6 @@ EXPORT_SYMBOL(x86_dma_fallback_dev);
 /* Number of entries preallocated for DMA-API debugging */
 #define PREALLOC_DMA_DEBUG_ENTRIES       65536
 
-int dma_set_mask(struct device *dev, u64 mask)
-{
-	if (!dev->dma_mask || !dma_supported(dev, mask))
-		return -EIO;
-
-	*dev->dma_mask = mask;
-
-	return 0;
-}
-EXPORT_SYMBOL(dma_set_mask);
-
 void __init pci_iommu_alloc(void)
 {
 	struct iommu_table_entry *p;
* Unmerged path arch/xtensa/include/asm/dma-mapping.h
* Unmerged path include/asm-generic/dma-mapping-common.h
