kvm: nVMX: Split VMCS checks from nested_vmx_run()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Jim Mattson <jmattson@google.com>
commit ca0bde28f2ed66c2229ecfb7f4bfa0defa3da4b5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/ca0bde28.failed

The checks performed on the contents of the vmcs12 are extracted from
nested_vmx_run so that they can be used to validate a vmcs12 that has
been restored from a checkpoint.

	Signed-off-by: Jim Mattson <jmattson@google.com>
[Change prepare_vmcs02 and nested_vmx_load_cr3's last argument to u32,
 to match check_vmentry_postreqs.  Update comments for singlestep
 handling. - Paolo]
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit ca0bde28f2ed66c2229ecfb7f4bfa0defa3da4b5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/vmx.c
diff --cc arch/x86/kvm/vmx.c
index 72c1c1c3db0f,71df7411959f..000000000000
--- a/arch/x86/kvm/vmx.c
+++ b/arch/x86/kvm/vmx.c
@@@ -9638,7 -10075,7 +9638,11 @@@ static int nested_vmx_load_cr3(struct k
   * is assigned to entry_failure_code on failure.
   */
  static int prepare_vmcs02(struct kvm_vcpu *vcpu, struct vmcs12 *vmcs12,
++<<<<<<< HEAD
 +			  unsigned long *entry_failure_code)
++=======
+ 			  bool from_vmentry, u32 *entry_failure_code)
++>>>>>>> ca0bde28f2ed (kvm: nVMX: Split VMCS checks from nested_vmx_run())
  {
  	struct vcpu_vmx *vmx = to_vmx(vcpu);
  	u32 exec_control;
@@@ -10014,98 -10555,20 +10114,78 @@@ static int nested_vmx_run(struct kvm_vc
  		goto out;
  	}
  
++<<<<<<< HEAD
 +	if (nested_vmx_check_msr_bitmap_controls(vcpu, vmcs12)) {
 +		nested_vmx_failValid(vcpu, VMXERR_ENTRY_INVALID_CONTROL_FIELD);
 +		goto out;
 +	}
 +
 +	if (nested_vmx_check_apicv_controls(vcpu, vmcs12)) {
 +		nested_vmx_failValid(vcpu, VMXERR_ENTRY_INVALID_CONTROL_FIELD);
 +		goto out;
 +	}
 +
 +	if (nested_vmx_check_msr_switch_controls(vcpu, vmcs12)) {
 +		nested_vmx_failValid(vcpu, VMXERR_ENTRY_INVALID_CONTROL_FIELD);
 +		goto out;
 +	}
 +
 +	if (!vmx_control_verify(vmcs12->cpu_based_vm_exec_control,
 +				vmx->nested.nested_vmx_true_procbased_ctls_low,
 +				vmx->nested.nested_vmx_procbased_ctls_high) ||
 +	    !vmx_control_verify(vmcs12->secondary_vm_exec_control,
 +				vmx->nested.nested_vmx_secondary_ctls_low,
 +				vmx->nested.nested_vmx_secondary_ctls_high) ||
 +	    !vmx_control_verify(vmcs12->pin_based_vm_exec_control,
 +				vmx->nested.nested_vmx_pinbased_ctls_low,
 +				vmx->nested.nested_vmx_pinbased_ctls_high) ||
 +	    !vmx_control_verify(vmcs12->vm_exit_controls,
 +				vmx->nested.nested_vmx_true_exit_ctls_low,
 +				vmx->nested.nested_vmx_exit_ctls_high) ||
 +	    !vmx_control_verify(vmcs12->vm_entry_controls,
 +				vmx->nested.nested_vmx_true_entry_ctls_low,
 +				vmx->nested.nested_vmx_entry_ctls_high))
 +	{
 +		nested_vmx_failValid(vcpu, VMXERR_ENTRY_INVALID_CONTROL_FIELD);
 +		goto out;
 +	}
 +
 +	if (((vmcs12->host_cr0 & VMXON_CR0_ALWAYSON) != VMXON_CR0_ALWAYSON) ||
 +	    ((vmcs12->host_cr4 & VMXON_CR4_ALWAYSON) != VMXON_CR4_ALWAYSON) ||
 +	    !nested_cr3_valid(vcpu, vmcs12->host_cr3)) {
 +		nested_vmx_failValid(vcpu,
 +			VMXERR_ENTRY_INVALID_HOST_STATE_FIELD);
 +		goto out;
 +	}
 +
 +	if (!nested_cr0_valid(vcpu, vmcs12->guest_cr0) ||
 +	    ((vmcs12->guest_cr4 & VMXON_CR4_ALWAYSON) != VMXON_CR4_ALWAYSON)) {
 +		nested_vmx_entry_failure(vcpu, vmcs12,
 +			EXIT_REASON_INVALID_STATE, ENTRY_FAIL_DEFAULT);
 +		return 1;
 +	}
 +	if (vmcs12->vmcs_link_pointer != -1ull) {
 +		nested_vmx_entry_failure(vcpu, vmcs12,
 +			EXIT_REASON_INVALID_STATE, ENTRY_FAIL_VMCS_LINK_PTR);
 +		return 1;
 +	}
 +
++=======
++>>>>>>> ca0bde28f2ed (kvm: nVMX: Split VMCS checks from nested_vmx_run())
  	/*
- 	 * If the load IA32_EFER VM-entry control is 1, the following checks
- 	 * are performed on the field for the IA32_EFER MSR:
- 	 * - Bits reserved in the IA32_EFER MSR must be 0.
- 	 * - Bit 10 (corresponding to IA32_EFER.LMA) must equal the value of
- 	 *   the IA-32e mode guest VM-exit control. It must also be identical
- 	 *   to bit 8 (LME) if bit 31 in the CR0 field (corresponding to
- 	 *   CR0.PG) is 1.
+ 	 * After this point, the trap flag no longer triggers a singlestep trap
+ 	 * on the vm entry instructions; don't call kvm_skip_emulated_instruction.
+ 	 * This is not 100% correct; for performance reasons, we delegate most
+ 	 * of the checks on host state to the processor.  If those fail,
+ 	 * the singlestep trap is missed.
  	 */
- 	if (vmcs12->vm_entry_controls & VM_ENTRY_LOAD_IA32_EFER) {
- 		ia32e = (vmcs12->vm_entry_controls & VM_ENTRY_IA32E_MODE) != 0;
- 		if (!kvm_valid_efer(vcpu, vmcs12->guest_ia32_efer) ||
- 		    ia32e != !!(vmcs12->guest_ia32_efer & EFER_LMA) ||
- 		    ((vmcs12->guest_cr0 & X86_CR0_PG) &&
- 		     ia32e != !!(vmcs12->guest_ia32_efer & EFER_LME))) {
- 			nested_vmx_entry_failure(vcpu, vmcs12,
- 				EXIT_REASON_INVALID_STATE, ENTRY_FAIL_DEFAULT);
- 			return 1;
- 		}
- 	}
+ 	skip_emulated_instruction(vcpu);
  
- 	/*
- 	 * If the load IA32_EFER VM-exit control is 1, bits reserved in the
- 	 * IA32_EFER MSR must be 0 in the field for that register. In addition,
- 	 * the values of the LMA and LME bits in the field must each be that of
- 	 * the host address-space size VM-exit control.
- 	 */
- 	if (vmcs12->vm_exit_controls & VM_EXIT_LOAD_IA32_EFER) {
- 		ia32e = (vmcs12->vm_exit_controls &
- 			 VM_EXIT_HOST_ADDR_SPACE_SIZE) != 0;
- 		if (!kvm_valid_efer(vcpu, vmcs12->host_ia32_efer) ||
- 		    ia32e != !!(vmcs12->host_ia32_efer & EFER_LMA) ||
- 		    ia32e != !!(vmcs12->host_ia32_efer & EFER_LME)) {
- 			nested_vmx_entry_failure(vcpu, vmcs12,
- 				EXIT_REASON_INVALID_STATE, ENTRY_FAIL_DEFAULT);
- 			return 1;
- 		}
+ 	ret = check_vmentry_postreqs(vcpu, vmcs12, &exit_qual);
+ 	if (ret) {
+ 		nested_vmx_entry_failure(vcpu, vmcs12,
+ 					 EXIT_REASON_INVALID_STATE, exit_qual);
+ 		return 1;
  	}
  
  	/*
@@@ -10117,7 -10580,6 +10197,10 @@@
  	if (!vmcs02)
  		return -ENOMEM;
  
++<<<<<<< HEAD
 +	skip_emulated_instruction(vcpu);
++=======
++>>>>>>> ca0bde28f2ed (kvm: nVMX: Split VMCS checks from nested_vmx_run())
  	enter_guest_mode(vcpu);
  
  	if (!(vmcs12->vm_entry_controls & VM_ENTRY_LOAD_DEBUG_CONTROLS))
@@@ -10132,7 -10594,7 +10215,11 @@@
  
  	vmx_segment_cache_clear(vmx);
  
++<<<<<<< HEAD
 +	if (prepare_vmcs02(vcpu, vmcs12, &exit_qualification)) {
++=======
+ 	if (prepare_vmcs02(vcpu, vmcs12, true, &exit_qual)) {
++>>>>>>> ca0bde28f2ed (kvm: nVMX: Split VMCS checks from nested_vmx_run())
  		leave_guest_mode(vcpu);
  		vmx_load_vmcs01(vcpu);
  		nested_vmx_entry_failure(vcpu, vmcs12,
* Unmerged path arch/x86/kvm/vmx.c
