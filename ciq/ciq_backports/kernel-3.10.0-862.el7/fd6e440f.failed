powerpc/64s: Wire up cpu_show_meltdown()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [powerpc] 64s: Wire up cpu_show_meltdown() (Mauricio Oliveira) [1543067]
Rebuild_FUZZ: 88.89%
commit-author Michael Ellerman <mpe@ellerman.id.au>
commit fd6e440f20b1a4304553775fc55938848ff617c9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/fd6e440f.failed

The recent commit 87590ce6e373 ("sysfs/cpu: Add vulnerability folder")
added a generic folder and set of files for reporting information on
CPU vulnerabilities. One of those was for meltdown:

  /sys/devices/system/cpu/vulnerabilities/meltdown

This commit wires up that file for 64-bit Book3S powerpc.

For now we default to "Vulnerable" unless the RFI flush is enabled.
That may not actually be true on all hardware, further patches will
refine the reporting based on the CPU/platform etc. But for now we
default to being pessimists.

	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
(cherry picked from commit fd6e440f20b1a4304553775fc55938848ff617c9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/Kconfig
#	arch/powerpc/kernel/setup_64.c
diff --cc arch/powerpc/Kconfig
index cae2cf0c3760,2ed525a44734..000000000000
--- a/arch/powerpc/Kconfig
+++ b/arch/powerpc/Kconfig
@@@ -126,72 -131,112 +126,145 @@@ config ARCH_HAS_DMA_SET_COHERENT_MAS
  config PPC
  	bool
  	default y
 -	#
 -	# Please keep this list sorted alphabetically.
 -	#
 -	select ARCH_HAS_DEVMEM_IS_ALLOWED
 -	select ARCH_HAS_DMA_SET_COHERENT_MASK
 -	select ARCH_HAS_ELF_RANDOMIZE
 -	select ARCH_HAS_FORTIFY_SOURCE
 -	select ARCH_HAS_GCOV_PROFILE_ALL
 -	select ARCH_HAS_PMEM_API                if PPC64
 -	select ARCH_HAS_SCALED_CPUTIME		if VIRT_CPU_ACCOUNTING_NATIVE
 -	select ARCH_HAS_SG_CHAIN
 -	select ARCH_HAS_TICK_BROADCAST		if GENERIC_CLOCKEVENTS_BROADCAST
 -	select ARCH_HAS_UACCESS_FLUSHCACHE	if PPC64
 -	select ARCH_HAS_UBSAN_SANITIZE_ALL
 -	select ARCH_HAS_ZONE_DEVICE		if PPC_BOOK3S_64
 -	select ARCH_HAVE_NMI_SAFE_CMPXCHG
  	select ARCH_MIGHT_HAVE_PC_PARPORT
 -	select ARCH_MIGHT_HAVE_PC_SERIO
 -	select ARCH_SUPPORTS_ATOMIC_RMW
 -	select ARCH_SUPPORTS_DEFERRED_STRUCT_PAGE_INIT
 -	select ARCH_USE_BUILTIN_BSWAP
 -	select ARCH_USE_CMPXCHG_LOCKREF		if PPC64
 -	select ARCH_WANT_IPC_PARSE_VERSION
 -	select ARCH_WEAK_RELEASE_ACQUIRE
  	select BINFMT_ELF
++<<<<<<< HEAD
 +	select ARCH_HAS_ELF_RANDOMIZE
++=======
+ 	select BUILDTIME_EXTABLE_SORT
+ 	select CLONE_BACKWARDS
+ 	select DCACHE_WORD_ACCESS		if PPC64 && CPU_LITTLE_ENDIAN
+ 	select EDAC_ATOMIC_SCRUB
+ 	select EDAC_SUPPORT
+ 	select GENERIC_ATOMIC64			if PPC32
+ 	select GENERIC_CLOCKEVENTS
+ 	select GENERIC_CLOCKEVENTS_BROADCAST	if SMP
+ 	select GENERIC_CMOS_UPDATE
+ 	select GENERIC_CPU_AUTOPROBE
+ 	select GENERIC_CPU_VULNERABILITIES	if PPC_BOOK3S_64
+ 	select GENERIC_IRQ_SHOW
+ 	select GENERIC_IRQ_SHOW_LEVEL
+ 	select GENERIC_SMP_IDLE_THREAD
+ 	select GENERIC_STRNCPY_FROM_USER
+ 	select GENERIC_STRNLEN_USER
+ 	select GENERIC_TIME_VSYSCALL
+ 	select HAVE_ARCH_AUDITSYSCALL
+ 	select HAVE_ARCH_JUMP_LABEL
+ 	select HAVE_ARCH_KGDB
+ 	select HAVE_ARCH_MMAP_RND_BITS
+ 	select HAVE_ARCH_MMAP_RND_COMPAT_BITS	if COMPAT
+ 	select HAVE_ARCH_SECCOMP_FILTER
+ 	select HAVE_ARCH_TRACEHOOK
+ 	select ARCH_HAS_STRICT_KERNEL_RWX	if ((PPC_BOOK3S_64 || PPC32) && !RELOCATABLE && !HIBERNATION)
+ 	select ARCH_OPTIONAL_KERNEL_RWX		if ARCH_HAS_STRICT_KERNEL_RWX
+ 	select HAVE_CBPF_JIT			if !PPC64
+ 	select HAVE_CONTEXT_TRACKING		if PPC64
+ 	select HAVE_DEBUG_KMEMLEAK
+ 	select HAVE_DEBUG_STACKOVERFLOW
+ 	select HAVE_DMA_API_DEBUG
+ 	select HAVE_DYNAMIC_FTRACE
+ 	select HAVE_DYNAMIC_FTRACE_WITH_REGS	if MPROFILE_KERNEL
+ 	select HAVE_EBPF_JIT			if PPC64
+ 	select HAVE_EFFICIENT_UNALIGNED_ACCESS	if !(CPU_LITTLE_ENDIAN && POWER7_CPU)
+ 	select HAVE_FTRACE_MCOUNT_RECORD
+ 	select HAVE_FUNCTION_GRAPH_TRACER
+ 	select HAVE_FUNCTION_TRACER
+ 	select HAVE_GCC_PLUGINS
+ 	select HAVE_GENERIC_GUP
+ 	select HAVE_HW_BREAKPOINT		if PERF_EVENTS && (PPC_BOOK3S || PPC_8xx)
+ 	select HAVE_IDE
+ 	select HAVE_IOREMAP_PROT
+ 	select HAVE_IRQ_EXIT_ON_IRQ_STACK
+ 	select HAVE_KERNEL_GZIP
+ 	select HAVE_KPROBES
+ 	select HAVE_KPROBES_ON_FTRACE
+ 	select HAVE_KRETPROBES
+ 	select HAVE_LIVEPATCH			if HAVE_DYNAMIC_FTRACE_WITH_REGS
+ 	select HAVE_MEMBLOCK
+ 	select HAVE_MEMBLOCK_NODE_MAP
+ 	select HAVE_MOD_ARCH_SPECIFIC
+ 	select HAVE_NMI				if PERF_EVENTS || (PPC64 && PPC_BOOK3S)
+ 	select HAVE_HARDLOCKUP_DETECTOR_ARCH	if (PPC64 && PPC_BOOK3S)
+ 	select HAVE_OPROFILE
+ 	select HAVE_OPTPROBES			if PPC64
+ 	select HAVE_PERF_EVENTS
+ 	select HAVE_PERF_EVENTS_NMI		if PPC64
+ 	select HAVE_HARDLOCKUP_DETECTOR_PERF	if PERF_EVENTS && HAVE_PERF_EVENTS_NMI && !HAVE_HARDLOCKUP_DETECTOR_ARCH
+ 	select HAVE_PERF_REGS
+ 	select HAVE_PERF_USER_STACK_DUMP
+ 	select HAVE_RCU_TABLE_FREE		if SMP
+ 	select HAVE_REGS_AND_STACK_ACCESS_API
+ 	select HAVE_SYSCALL_TRACEPOINTS
+ 	select HAVE_VIRT_CPU_ACCOUNTING
+ 	select HAVE_IRQ_TIME_ACCOUNTING
+ 	select IRQ_DOMAIN
+ 	select IRQ_FORCED_THREADING
+ 	select MODULES_USE_ELF_RELA
+ 	select NO_BOOTMEM
++>>>>>>> fd6e440f20b1 (powerpc/64s: Wire up cpu_show_meltdown())
  	select OF
  	select OF_EARLY_FLATTREE
 -	select OF_RESERVED_MEM
 -	select OLD_SIGACTION			if PPC32
 -	select OLD_SIGSUSPEND
 -	select SPARSE_IRQ
 +	select HAVE_FTRACE_MCOUNT_RECORD
 +	select HAVE_ARCH_MMAP_RND_BITS
 +	select HAVE_ARCH_MMAP_RND_COMPAT_BITS	if COMPAT
 +	select HAVE_DYNAMIC_FTRACE
 +	select HAVE_FUNCTION_TRACER
 +	select HAVE_FUNCTION_GRAPH_TRACER
  	select SYSCTL_EXCEPTION_TRACE
 -	select VIRT_TO_BUS			if !PPC64
 -	#
 -	# Please keep this list sorted alphabetically.
 -	#
 +	select ARCH_WANT_OPTIONAL_GPIOLIB
 +	select VIRT_TO_BUS if !PPC64
 +	select HAVE_IDE
 +	select HAVE_IOREMAP_PROT
 +	select HAVE_EFFICIENT_UNALIGNED_ACCESS if !CPU_LITTLE_ENDIAN
 +	select HAVE_KPROBES
 +	select HAVE_ARCH_KGDB
 +	select HAVE_KRETPROBES
 +	select HAVE_ARCH_TRACEHOOK
 +	select HAVE_MEMBLOCK
 +	select HAVE_MEMBLOCK_NODE_MAP
 +	select HAVE_DMA_ATTRS
 +	select HAVE_DMA_API_DEBUG
 +	select USE_GENERIC_SMP_HELPERS if SMP
 +	select HAVE_OPROFILE
 +	select HAVE_DEBUG_KMEMLEAK
 +	select GENERIC_ATOMIC64 if PPC32
 +	select ARCH_HAS_ATOMIC64_DEC_IF_POSITIVE
 +	select HAVE_PERF_EVENTS
 +	select HAVE_PERF_REGS
 +	select HAVE_PERF_USER_STACK_DUMP
 +	select HAVE_REGS_AND_STACK_ACCESS_API
 +	select HAVE_HW_BREAKPOINT if PERF_EVENTS && PPC_BOOK3S_64
 +	select HAVE_GENERIC_HARDIRQS
 +	select ARCH_WANT_IPC_PARSE_VERSION
 +	select SPARSE_IRQ
 +	select IRQ_DOMAIN
 +	select GENERIC_IRQ_SHOW
 +	select GENERIC_IRQ_SHOW_LEVEL
 +	select IRQ_FORCED_THREADING
 +	select HAVE_RCU_TABLE_FREE if SMP
 +	select HAVE_SYSCALL_TRACEPOINTS
 +	select HAVE_BPF_JIT if (PPC64 && CPU_BIG_ENDIAN)
 +	select HAVE_ARCH_JUMP_LABEL
 +	select ARCH_HAVE_NMI_SAFE_CMPXCHG
 +	select GENERIC_SMP_IDLE_THREAD
 +	select GENERIC_CMOS_UPDATE
 +	select GENERIC_TIME_VSYSCALL_OLD
 +	select GENERIC_CLOCKEVENTS
 +	select GENERIC_CLOCKEVENTS_BROADCAST if SMP
 +	select ARCH_HAS_TICK_BROADCAST if GENERIC_CLOCKEVENTS_BROADCAST
 +	select GENERIC_STRNCPY_FROM_USER
 +	select GENERIC_STRNLEN_USER
 +	select HAVE_MOD_ARCH_SPECIFIC
 +	select MODULES_USE_ELF_RELA
 +	select CLONE_BACKWARDS
 +	select ARCH_USE_BUILTIN_BSWAP
 +	select OLD_SIGSUSPEND
 +	select OLD_SIGACTION if PPC32
 +	select HAVE_IRQ_EXIT_ON_IRQ_STACK
 +	select ARCH_USE_CMPXCHG_LOCKREF if PPC64
 +	select ARCH_HAS_DMA_SET_COHERENT_MASK
 +	select HAVE_ARCH_SECCOMP_FILTER
 +	select HAVE_PERF_EVENTS_NMI if PPC64
  
  config GENERIC_CSUM
  	def_bool n
diff --cc arch/powerpc/kernel/setup_64.c
index 93417594708c,624d2a62d05d..000000000000
--- a/arch/powerpc/kernel/setup_64.c
+++ b/arch/powerpc/kernel/setup_64.c
@@@ -767,4 -801,112 +767,116 @@@ static int __init disable_hardlockup_de
  	return 0;
  }
  early_initcall(disable_hardlockup_detector);
++<<<<<<< HEAD
 +#endif
++=======
+ 
+ #ifdef CONFIG_PPC_BOOK3S_64
+ static enum l1d_flush_type enabled_flush_types;
+ static void *l1d_flush_fallback_area;
+ static bool no_rfi_flush;
+ bool rfi_flush;
+ 
+ static int __init handle_no_rfi_flush(char *p)
+ {
+ 	pr_info("rfi-flush: disabled on command line.");
+ 	no_rfi_flush = true;
+ 	return 0;
+ }
+ early_param("no_rfi_flush", handle_no_rfi_flush);
+ 
+ /*
+  * The RFI flush is not KPTI, but because users will see doco that says to use
+  * nopti we hijack that option here to also disable the RFI flush.
+  */
+ static int __init handle_no_pti(char *p)
+ {
+ 	pr_info("rfi-flush: disabling due to 'nopti' on command line.\n");
+ 	handle_no_rfi_flush(NULL);
+ 	return 0;
+ }
+ early_param("nopti", handle_no_pti);
+ 
+ static void do_nothing(void *unused)
+ {
+ 	/*
+ 	 * We don't need to do the flush explicitly, just enter+exit kernel is
+ 	 * sufficient, the RFI exit handlers will do the right thing.
+ 	 */
+ }
+ 
+ void rfi_flush_enable(bool enable)
+ {
+ 	if (rfi_flush == enable)
+ 		return;
+ 
+ 	if (enable) {
+ 		do_rfi_flush_fixups(enabled_flush_types);
+ 		on_each_cpu(do_nothing, NULL, 1);
+ 	} else
+ 		do_rfi_flush_fixups(L1D_FLUSH_NONE);
+ 
+ 	rfi_flush = enable;
+ }
+ 
+ static void init_fallback_flush(void)
+ {
+ 	u64 l1d_size, limit;
+ 	int cpu;
+ 
+ 	l1d_size = ppc64_caches.l1d.size;
+ 	limit = min(safe_stack_limit(), ppc64_rma_size);
+ 
+ 	/*
+ 	 * Align to L1d size, and size it at 2x L1d size, to catch possible
+ 	 * hardware prefetch runoff. We don't have a recipe for load patterns to
+ 	 * reliably avoid the prefetcher.
+ 	 */
+ 	l1d_flush_fallback_area = __va(memblock_alloc_base(l1d_size * 2, l1d_size, limit));
+ 	memset(l1d_flush_fallback_area, 0, l1d_size * 2);
+ 
+ 	for_each_possible_cpu(cpu) {
+ 		/*
+ 		 * The fallback flush is currently coded for 8-way
+ 		 * associativity. Different associativity is possible, but it
+ 		 * will be treated as 8-way and may not evict the lines as
+ 		 * effectively.
+ 		 *
+ 		 * 128 byte lines are mandatory.
+ 		 */
+ 		u64 c = l1d_size / 8;
+ 
+ 		paca[cpu].rfi_flush_fallback_area = l1d_flush_fallback_area;
+ 		paca[cpu].l1d_flush_congruence = c;
+ 		paca[cpu].l1d_flush_sets = c / 128;
+ 	}
+ }
+ 
+ void __init setup_rfi_flush(enum l1d_flush_type types, bool enable)
+ {
+ 	if (types & L1D_FLUSH_FALLBACK) {
+ 		pr_info("rfi-flush: Using fallback displacement flush\n");
+ 		init_fallback_flush();
+ 	}
+ 
+ 	if (types & L1D_FLUSH_ORI)
+ 		pr_info("rfi-flush: Using ori type flush\n");
+ 
+ 	if (types & L1D_FLUSH_MTTRIG)
+ 		pr_info("rfi-flush: Using mttrig type flush\n");
+ 
+ 	enabled_flush_types = types;
+ 
+ 	if (!no_rfi_flush)
+ 		rfi_flush_enable(enable);
+ }
+ 
+ ssize_t cpu_show_meltdown(struct device *dev, struct device_attribute *attr, char *buf)
+ {
+ 	if (rfi_flush)
+ 		return sprintf(buf, "Mitigation: RFI Flush\n");
+ 
+ 	return sprintf(buf, "Vulnerable\n");
+ }
+ #endif /* CONFIG_PPC_BOOK3S_64 */
++>>>>>>> fd6e440f20b1 (powerpc/64s: Wire up cpu_show_meltdown())
* Unmerged path arch/powerpc/Kconfig
* Unmerged path arch/powerpc/kernel/setup_64.c
