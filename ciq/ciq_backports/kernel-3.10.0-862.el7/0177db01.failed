s390/crypto: simplify return code handling

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [s390] crypto: simplify return code handling (Hendrik Brueckner) [1380349]
Rebuild_FUZZ: 93.67%
commit-author Martin Schwidefsky <schwidefsky@de.ibm.com>
commit 0177db01adf26cf9c5dfe1feaf17087de4b9e40e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/0177db01.failed

The CPACF instructions can complete with three different condition codes:
CC=0 for successful completion, CC=1 if the protected key verification
failed, and CC=3 for partial completion.

The inline functions will restart the CPACF instruction for partial
completion, this removes the CC=3 case. The CC=1 case is only relevant
for the protected key functions of the KM, KMC, KMAC and KMCTR
instructions. As the protected key functions are not used by the
current code, there is no need for any kind of return code handling.

	Reviewed-by: Harald Freudenberger <freude@linux.vnet.ibm.com>
	Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
(cherry picked from commit 0177db01adf26cf9c5dfe1feaf17087de4b9e40e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/s390/crypto/aes_s390.c
#	arch/s390/crypto/des_s390.c
#	arch/s390/crypto/ghash_s390.c
#	arch/s390/crypto/prng.c
#	arch/s390/crypto/sha_common.c
#	arch/s390/include/asm/cpacf.h
diff --cc arch/s390/crypto/aes_s390.c
index 25567fe0d72c,4eb8de417419..000000000000
--- a/arch/s390/crypto/aes_s390.c
+++ b/arch/s390/crypto/aes_s390.c
@@@ -325,9 -324,7 +325,13 @@@ static int ecb_aes_crypt(struct blkciph
  		u8 *out = walk->dst.virt.addr;
  		u8 *in = walk->src.virt.addr;
  
++<<<<<<< HEAD
 +		ret = crypt_s390_km(func, param, out, in, n);
 +		if (ret < 0 || ret != n)
 +			return -EIO;
++=======
+ 		cpacf_km(func, param, out, in, n);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  		nbytes &= AES_BLOCK_SIZE - 1;
  		ret = blkcipher_walk_done(desc, walk, nbytes);
@@@ -464,9 -458,7 +468,13 @@@ static int cbc_aes_crypt(struct blkciph
  		u8 *out = walk->dst.virt.addr;
  		u8 *in = walk->src.virt.addr;
  
++<<<<<<< HEAD
 +		ret = crypt_s390_kmc(func, &param, out, in, n);
 +		if (ret < 0 || ret != n)
 +			return -EIO;
++=======
+ 		cpacf_kmc(func, &param, out, in, n);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  		nbytes &= AES_BLOCK_SIZE - 1;
  		ret = blkcipher_walk_done(desc, walk, nbytes);
@@@ -642,9 -635,8 +650,14 @@@ static int xts_aes_crypt(struct blkciph
  	memset(pcc_param.xts, 0, sizeof(pcc_param.xts));
  	memcpy(pcc_param.tweak, walk->iv, sizeof(pcc_param.tweak));
  	memcpy(pcc_param.key, xts_ctx->pcc_key, 32);
++<<<<<<< HEAD
 +	ret = crypt_s390_pcc(func, &pcc_param.key[offset]);
 +	if (ret < 0)
 +		return -EIO;
++=======
+ 	/* remove decipher modifier bit from 'func' and call PCC */
+ 	cpacf_pcc(func & 0x7f, &pcc_param.key[offset]);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  	memcpy(xts_param.key, xts_ctx->key, 32);
  	memcpy(xts_param.init, pcc_param.xts, 16);
@@@ -654,9 -646,7 +667,13 @@@
  		out = walk->dst.virt.addr;
  		in = walk->src.virt.addr;
  
++<<<<<<< HEAD
 +		ret = crypt_s390_km(func, &xts_param.key[offset], out, in, n);
 +		if (ret < 0 || ret != n)
 +			return -EIO;
++=======
+ 		cpacf_km(func, &xts_param.key[offset], out, in, n);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  		nbytes &= AES_BLOCK_SIZE - 1;
  		ret = blkcipher_walk_done(desc, walk, nbytes);
@@@ -803,13 -790,7 +820,17 @@@ static int ctr_aes_crypt(struct blkciph
  				n = __ctrblk_init(ctrptr, nbytes);
  			else
  				n = AES_BLOCK_SIZE;
++<<<<<<< HEAD
 +			ret = crypt_s390_kmctr(func, sctx->key, out, in,
 +					       n, ctrptr);
 +			if (ret < 0 || ret != n) {
 +				if (ctrptr == ctrblk)
 +					spin_unlock(&ctrblk_lock);
 +				return -EIO;
 +			}
++=======
+ 			cpacf_kmctr(func, sctx->key, out, in, n, ctrptr);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  			if (n > AES_BLOCK_SIZE)
  				memcpy(ctrptr, ctrptr + n - AES_BLOCK_SIZE,
  				       AES_BLOCK_SIZE);
@@@ -836,10 -817,7 +857,14 @@@
  	if (nbytes) {
  		out = walk->dst.virt.addr;
  		in = walk->src.virt.addr;
++<<<<<<< HEAD
 +		ret = crypt_s390_kmctr(func, sctx->key, buf, in,
 +				       AES_BLOCK_SIZE, ctrbuf);
 +		if (ret < 0 || ret != AES_BLOCK_SIZE)
 +			return -EIO;
++=======
+ 		cpacf_kmctr(func, sctx->key, buf, in, AES_BLOCK_SIZE, ctrbuf);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  		memcpy(out, buf, nbytes);
  		crypto_inc(ctrbuf, AES_BLOCK_SIZE);
  		ret = blkcipher_walk_done(desc, walk, 0);
diff --cc arch/s390/crypto/des_s390.c
index a89feffb22b5,999878597331..000000000000
--- a/arch/s390/crypto/des_s390.c
+++ b/arch/s390/crypto/des_s390.c
@@@ -94,9 -95,7 +94,13 @@@ static int ecb_desall_crypt(struct blkc
  		u8 *out = walk->dst.virt.addr;
  		u8 *in = walk->src.virt.addr;
  
++<<<<<<< HEAD
 +		ret = crypt_s390_km(func, key, out, in, n);
 +		if (ret < 0 || ret != n)
 +			return -EIO;
++=======
+ 		cpacf_km(func, key, out, in, n);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  		nbytes &= DES_BLOCK_SIZE - 1;
  		ret = blkcipher_walk_done(desc, walk, nbytes);
@@@ -127,9 -126,7 +131,13 @@@ static int cbc_desall_crypt(struct blkc
  		u8 *out = walk->dst.virt.addr;
  		u8 *in = walk->src.virt.addr;
  
++<<<<<<< HEAD
 +		ret = crypt_s390_kmc(func, &param, out, in, n);
 +		if (ret < 0 || ret != n)
 +			return -EIO;
++=======
+ 		cpacf_kmc(func, &param, out, in, n);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  		nbytes &= DES_BLOCK_SIZE - 1;
  		ret = blkcipher_walk_done(desc, walk, nbytes);
@@@ -406,13 -407,7 +414,17 @@@ static int ctr_desall_crypt(struct blkc
  				n = __ctrblk_init(ctrptr, nbytes);
  			else
  				n = DES_BLOCK_SIZE;
++<<<<<<< HEAD
 +			ret = crypt_s390_kmctr(func, ctx->key, out, in,
 +					       n, ctrptr);
 +			if (ret < 0 || ret != n) {
 +				if (ctrptr == ctrblk)
 +					spin_unlock(&ctrblk_lock);
 +				return -EIO;
 +			}
++=======
+ 			cpacf_kmctr(func, ctx->key, out, in, n, ctrptr);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  			if (n > DES_BLOCK_SIZE)
  				memcpy(ctrptr, ctrptr + n - DES_BLOCK_SIZE,
  				       DES_BLOCK_SIZE);
@@@ -437,10 -432,7 +449,14 @@@
  	if (nbytes) {
  		out = walk->dst.virt.addr;
  		in = walk->src.virt.addr;
++<<<<<<< HEAD
 +		ret = crypt_s390_kmctr(func, ctx->key, buf, in,
 +				       DES_BLOCK_SIZE, ctrbuf);
 +		if (ret < 0 || ret != DES_BLOCK_SIZE)
 +			return -EIO;
++=======
+ 		cpacf_kmctr(func, ctx->key, buf, in, DES_BLOCK_SIZE, ctrbuf);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  		memcpy(out, buf, nbytes);
  		crypto_inc(ctrbuf, DES_BLOCK_SIZE);
  		ret = blkcipher_walk_done(desc, walk, 0);
diff --cc arch/s390/crypto/ghash_s390.c
index b258110da952,8e87f5176799..000000000000
--- a/arch/s390/crypto/ghash_s390.c
+++ b/arch/s390/crypto/ghash_s390.c
@@@ -71,18 -70,14 +70,27 @@@ static int ghash_update(struct shash_de
  		src += n;
  
  		if (!dctx->bytes) {
++<<<<<<< HEAD
 +			ret = crypt_s390_kimd(KIMD_GHASH, dctx, buf,
 +					      GHASH_BLOCK_SIZE);
 +			if (ret != GHASH_BLOCK_SIZE)
 +				return -EIO;
++=======
+ 			cpacf_kimd(CPACF_KIMD_GHASH, dctx, buf,
+ 				   GHASH_BLOCK_SIZE);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  		}
  	}
  
  	n = srclen & ~(GHASH_BLOCK_SIZE - 1);
  	if (n) {
++<<<<<<< HEAD
 +		ret = crypt_s390_kimd(KIMD_GHASH, dctx, src, n);
 +		if (ret != n)
 +			return -EIO;
++=======
+ 		cpacf_kimd(CPACF_KIMD_GHASH, dctx, src, n);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  		src += n;
  		srclen -= n;
  	}
@@@ -104,11 -98,7 +111,15 @@@ static int ghash_flush(struct ghash_des
  		u8 *pos = buf + (GHASH_BLOCK_SIZE - dctx->bytes);
  
  		memset(pos, 0, dctx->bytes);
++<<<<<<< HEAD
 +
 +		ret = crypt_s390_kimd(KIMD_GHASH, dctx, buf, GHASH_BLOCK_SIZE);
 +		if (ret != GHASH_BLOCK_SIZE)
 +			return -EIO;
 +
++=======
+ 		cpacf_kimd(CPACF_KIMD_GHASH, dctx, buf, GHASH_BLOCK_SIZE);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  		dctx->bytes = 0;
  	}
  
diff --cc arch/s390/crypto/prng.c
index 9d5192c94963,bbf2af74c549..000000000000
--- a/arch/s390/crypto/prng.c
+++ b/arch/s390/crypto/prng.c
@@@ -135,12 -135,7 +135,16 @@@ static int generate_entropy(u8 *ebuf, s
  		else
  			h = ebuf;
  		/* generate sha256 from this page */
++<<<<<<< HEAD
 +		if (crypt_s390_kimd(KIMD_SHA_256, h,
 +				    pg, PAGE_SIZE) != PAGE_SIZE) {
 +			prng_errorflag = PRNG_GEN_ENTROPY_FAILED;
 +			ret = -EIO;
 +			goto out;
 +		}
++=======
+ 		cpacf_kimd(CPACF_KIMD_SHA_256, h, pg, PAGE_SIZE);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  		if (n < sizeof(hash))
  			memcpy(ebuf, hash, n);
  		ret += n;
@@@ -160,13 -154,11 +163,18 @@@ static void prng_tdes_add_entropy(void
  {
  	__u64 entropy[4];
  	unsigned int i;
- 	int ret;
  
  	for (i = 0; i < 16; i++) {
++<<<<<<< HEAD
 +		ret = crypt_s390_kmc(KMC_PRNG, prng_data->prngws.parm_block,
 +				     (char *)entropy, (char *)entropy,
 +				     sizeof(entropy));
 +		BUG_ON(ret < 0 || ret != sizeof(entropy));
++=======
+ 		cpacf_kmc(CPACF_KMC_PRNG, prng_data->prngws.parm_block,
+ 			  (char *) entropy, (char *) entropy,
+ 			  sizeof(entropy));
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  		memcpy(prng_data->prngws.parm_block, entropy, sizeof(entropy));
  	}
  }
@@@ -310,15 -301,8 +317,20 @@@ static int __init prng_sha512_selftest(
  	memset(&ws, 0, sizeof(ws));
  
  	/* initial seed */
++<<<<<<< HEAD
 +	ret = crypt_s390_ppno(PPNO_SHA512_DRNG_SEED,
 +			      &ws, NULL, 0,
 +			      seed, sizeof(seed));
 +	if (ret < 0) {
 +		pr_err("The prng self test seed operation for the "
 +		       "SHA-512 mode failed with rc=%d\n", ret);
 +		prng_errorflag = PRNG_SELFTEST_FAILED;
 +		return -EIO;
 +	}
++=======
+ 	cpacf_ppno(CPACF_PPNO_SHA512_DRNG_SEED,
+ 		   &ws, NULL, 0, seed, sizeof(seed));
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  	/* check working states V and C */
  	if (memcmp(ws.V, V0, sizeof(V0)) != 0
@@@ -330,24 -314,10 +342,31 @@@
  	}
  
  	/* generate random bytes */
++<<<<<<< HEAD
 +	ret = crypt_s390_ppno(PPNO_SHA512_DRNG_GEN,
 +			      &ws, buf, sizeof(buf),
 +			      NULL, 0);
 +	if (ret < 0) {
 +		pr_err("The prng self test generate operation for "
 +		       "the SHA-512 mode failed with rc=%d\n", ret);
 +		prng_errorflag = PRNG_SELFTEST_FAILED;
 +		return -EIO;
 +	}
 +	ret = crypt_s390_ppno(PPNO_SHA512_DRNG_GEN,
 +			      &ws, buf, sizeof(buf),
 +			      NULL, 0);
 +	if (ret < 0) {
 +		pr_err("The prng self test generate operation for "
 +		       "the SHA-512 mode failed with rc=%d\n", ret);
 +		prng_errorflag = PRNG_SELFTEST_FAILED;
 +		return -EIO;
 +	}
++=======
+ 	cpacf_ppno(CPACF_PPNO_SHA512_DRNG_GEN,
+ 		   &ws, buf, sizeof(buf), NULL, 0);
+ 	cpacf_ppno(CPACF_PPNO_SHA512_DRNG_GEN,
+ 		   &ws, buf, sizeof(buf), NULL, 0);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  	/* check against expected data */
  	if (memcmp(buf, random, sizeof(random)) != 0) {
@@@ -395,29 -365,16 +414,40 @@@ static int __init prng_sha512_instantia
  	get_tod_clock_ext(seed + 48);
  
  	/* initial seed of the ppno drng */
++<<<<<<< HEAD
 +	ret = crypt_s390_ppno(PPNO_SHA512_DRNG_SEED,
 +			      &prng_data->ppnows, NULL, 0,
 +			      seed, sizeof(seed));
 +	if (ret < 0) {
 +		prng_errorflag = PRNG_SEED_FAILED;
 +		ret = -EIO;
 +		goto outfree;
 +	}
++=======
+ 	cpacf_ppno(CPACF_PPNO_SHA512_DRNG_SEED,
+ 		   &prng_data->ppnows, NULL, 0, seed, sizeof(seed));
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  	/* if fips mode is enabled, generate a first block of random
  	   bytes for the FIPS 140-2 Conditional Self Test */
  	if (fips_enabled) {
  		prng_data->prev = prng_data->buf + prng_chunk_size;
++<<<<<<< HEAD
 +		ret = crypt_s390_ppno(PPNO_SHA512_DRNG_GEN,
 +				      &prng_data->ppnows,
 +				      prng_data->prev,
 +				      prng_chunk_size,
 +				      NULL, 0);
 +		if (ret < 0 || ret != prng_chunk_size) {
 +			prng_errorflag = PRNG_GEN_FAILED;
 +			ret = -EIO;
 +			goto outfree;
 +		}
++=======
+ 		cpacf_ppno(CPACF_PPNO_SHA512_DRNG_GEN,
+ 			   &prng_data->ppnows,
+ 			   prng_data->prev, prng_chunk_size, NULL, 0);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  	}
  
  	return 0;
@@@ -446,13 -403,8 +476,18 @@@ static int prng_sha512_reseed(void
  		return ret;
  
  	/* do a reseed of the ppno drng with this bytestring */
++<<<<<<< HEAD
 +	ret = crypt_s390_ppno(PPNO_SHA512_DRNG_SEED,
 +			      &prng_data->ppnows, NULL, 0,
 +			      seed, sizeof(seed));
 +	if (ret) {
 +		prng_errorflag = PRNG_RESEED_FAILED;
 +		return -EIO;
 +	}
++=======
+ 	cpacf_ppno(CPACF_PPNO_SHA512_DRNG_SEED,
+ 		   &prng_data->ppnows, NULL, 0, seed, sizeof(seed));
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  	return 0;
  }
@@@ -470,13 -422,8 +505,18 @@@ static int prng_sha512_generate(u8 *buf
  	}
  
  	/* PPNO generate */
++<<<<<<< HEAD
 +	ret = crypt_s390_ppno(PPNO_SHA512_DRNG_GEN,
 +			      &prng_data->ppnows, buf, nbytes,
 +			      NULL, 0);
 +	if (ret < 0 || ret != nbytes) {
 +		prng_errorflag = PRNG_GEN_FAILED;
 +		return -EIO;
 +	}
++=======
+ 	cpacf_ppno(CPACF_PPNO_SHA512_DRNG_GEN,
+ 		   &prng_data->ppnows, buf, nbytes, NULL, 0);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  	/* FIPS 140-2 Conditional Self Test */
  	if (fips_enabled) {
@@@ -553,13 -500,9 +593,19 @@@ static ssize_t prng_tdes_read(struct fi
  		 *
  		 * Note: you can still get strict X9.17 conformity by setting
  		 * prng_chunk_size to 8 bytes.
++<<<<<<< HEAD
 +		*/
 +		tmp = crypt_s390_kmc(KMC_PRNG, prng_data->prngws.parm_block,
 +				     prng_data->buf, prng_data->buf, n);
 +		if (tmp < 0 || tmp != n) {
 +			ret = -EIO;
 +			break;
 +		}
++=======
+ 		 */
+ 		cpacf_kmc(CPACF_KMC_PRNG, prng_data->prngws.parm_block,
+ 			  prng_data->buf, prng_data->buf, n);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  		prng_data->prngws.byte_counter += n;
  		prng_data->prngws.reseed_counter += n;
diff --cc arch/s390/crypto/sha_common.c
index 8620b0ec9c42,c740f77285b2..000000000000
--- a/arch/s390/crypto/sha_common.c
+++ b/arch/s390/crypto/sha_common.c
@@@ -35,9 -34,7 +34,13 @@@ int s390_sha_update(struct shash_desc *
  	/* process one stored block */
  	if (index) {
  		memcpy(ctx->buf + index, data, bsize - index);
++<<<<<<< HEAD
 +		ret = crypt_s390_kimd(ctx->func, ctx->state, ctx->buf, bsize);
 +		if (ret != bsize)
 +			return -EIO;
++=======
+ 		cpacf_kimd(ctx->func, ctx->state, ctx->buf, bsize);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  		data += bsize - index;
  		len -= bsize - index;
  		index = 0;
@@@ -45,12 -42,10 +48,19 @@@
  
  	/* process as many blocks as possible */
  	if (len >= bsize) {
++<<<<<<< HEAD
 +		ret = crypt_s390_kimd(ctx->func, ctx->state, data,
 +				      len & ~(bsize - 1));
 +		if (ret != (len & ~(bsize - 1)))
 +			return -EIO;
 +		data += ret;
 +		len -= ret;
++=======
+ 		n = len & ~(bsize - 1);
+ 		cpacf_kimd(ctx->func, ctx->state, data, n);
+ 		data += n;
+ 		len -= n;
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  	}
  store:
  	if (len)
@@@ -88,10 -82,7 +97,14 @@@ int s390_sha_final(struct shash_desc *d
  	 */
  	bits = ctx->count * 8;
  	memcpy(ctx->buf + end - 8, &bits, sizeof(bits));
++<<<<<<< HEAD
 +
 +	ret = crypt_s390_kimd(ctx->func, ctx->state, ctx->buf, end);
 +	if (ret != end)
 +		return -EIO;
++=======
+ 	cpacf_kimd(ctx->func, ctx->state, ctx->buf, end);
++>>>>>>> 0177db01adf2 (s390/crypto: simplify return code handling)
  
  	/* copy digest to out */
  	memcpy(out, ctx->state, crypto_shash_digestsize(desc->tfm));
* Unmerged path arch/s390/include/asm/cpacf.h
* Unmerged path arch/s390/crypto/aes_s390.c
* Unmerged path arch/s390/crypto/des_s390.c
* Unmerged path arch/s390/crypto/ghash_s390.c
* Unmerged path arch/s390/crypto/prng.c
* Unmerged path arch/s390/crypto/sha_common.c
* Unmerged path arch/s390/include/asm/cpacf.h
