IB/mlx5: fix debugfs cleanup

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Sudip Mukherjee <sudipm.mukherjee@gmail.com>
commit cbafad87e1507044c7d442087d41d5e3d432cc4e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/cbafad87.failed

If delay_drop_debugfs_init() fails in any of the operations to create
debugfs, it is calling delay_drop_debugfs_cleanup() as part of its
cleanup. But delay_drop_debugfs_cleanup() checks for 'dbg' and since
we have not yet pointed 'dbg' to the debugfs we need to cleanup, the
cleanup fails and we are left with stray debugfs elements and also a
memory leak.

Fixes: 4a5fd5d2965c ("IB/mlx5: Add necessary delay drop assignment")
	Signed-off-by: Sudip Mukherjee <sudipm.mukherjee@gmail.com>
	Acked-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit cbafad87e1507044c7d442087d41d5e3d432cc4e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/main.c
diff --cc drivers/infiniband/hw/mlx5/main.c
index 56dae696542d,05fb4bdff6a0..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -3359,6 -3642,263 +3359,266 @@@ dealloc_counters
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ static struct rdma_hw_stats *mlx5_ib_alloc_hw_stats(struct ib_device *ibdev,
+ 						    u8 port_num)
+ {
+ 	struct mlx5_ib_dev *dev = to_mdev(ibdev);
+ 	struct mlx5_ib_port *port = &dev->port[port_num - 1];
+ 
+ 	/* We support only per port stats */
+ 	if (port_num == 0)
+ 		return NULL;
+ 
+ 	return rdma_alloc_hw_stats_struct(port->cnts.names,
+ 					  port->cnts.num_q_counters +
+ 					  port->cnts.num_cong_counters,
+ 					  RDMA_HW_STATS_DEFAULT_LIFESPAN);
+ }
+ 
+ static int mlx5_ib_query_q_counters(struct mlx5_ib_dev *dev,
+ 				    struct mlx5_ib_port *port,
+ 				    struct rdma_hw_stats *stats)
+ {
+ 	int outlen = MLX5_ST_SZ_BYTES(query_q_counter_out);
+ 	void *out;
+ 	__be32 val;
+ 	int ret, i;
+ 
+ 	out = kvzalloc(outlen, GFP_KERNEL);
+ 	if (!out)
+ 		return -ENOMEM;
+ 
+ 	ret = mlx5_core_query_q_counter(dev->mdev,
+ 					port->cnts.set_id, 0,
+ 					out, outlen);
+ 	if (ret)
+ 		goto free;
+ 
+ 	for (i = 0; i < port->cnts.num_q_counters; i++) {
+ 		val = *(__be32 *)(out + port->cnts.offsets[i]);
+ 		stats->value[i] = (u64)be32_to_cpu(val);
+ 	}
+ 
+ free:
+ 	kvfree(out);
+ 	return ret;
+ }
+ 
+ static int mlx5_ib_query_cong_counters(struct mlx5_ib_dev *dev,
+ 				       struct mlx5_ib_port *port,
+ 				       struct rdma_hw_stats *stats)
+ {
+ 	int outlen = MLX5_ST_SZ_BYTES(query_cong_statistics_out);
+ 	void *out;
+ 	int ret, i;
+ 	int offset = port->cnts.num_q_counters;
+ 
+ 	out = kvzalloc(outlen, GFP_KERNEL);
+ 	if (!out)
+ 		return -ENOMEM;
+ 
+ 	ret = mlx5_cmd_query_cong_counter(dev->mdev, false, out, outlen);
+ 	if (ret)
+ 		goto free;
+ 
+ 	for (i = 0; i < port->cnts.num_cong_counters; i++) {
+ 		stats->value[i + offset] =
+ 			be64_to_cpup((__be64 *)(out +
+ 				     port->cnts.offsets[i + offset]));
+ 	}
+ 
+ free:
+ 	kvfree(out);
+ 	return ret;
+ }
+ 
+ static int mlx5_ib_get_hw_stats(struct ib_device *ibdev,
+ 				struct rdma_hw_stats *stats,
+ 				u8 port_num, int index)
+ {
+ 	struct mlx5_ib_dev *dev = to_mdev(ibdev);
+ 	struct mlx5_ib_port *port = &dev->port[port_num - 1];
+ 	int ret, num_counters;
+ 
+ 	if (!stats)
+ 		return -EINVAL;
+ 
+ 	ret = mlx5_ib_query_q_counters(dev, port, stats);
+ 	if (ret)
+ 		return ret;
+ 	num_counters = port->cnts.num_q_counters;
+ 
+ 	if (MLX5_CAP_GEN(dev->mdev, cc_query_allowed)) {
+ 		ret = mlx5_ib_query_cong_counters(dev, port, stats);
+ 		if (ret)
+ 			return ret;
+ 		num_counters += port->cnts.num_cong_counters;
+ 	}
+ 
+ 	return num_counters;
+ }
+ 
+ static void mlx5_ib_free_rdma_netdev(struct net_device *netdev)
+ {
+ 	return mlx5_rdma_netdev_free(netdev);
+ }
+ 
+ static struct net_device*
+ mlx5_ib_alloc_rdma_netdev(struct ib_device *hca,
+ 			  u8 port_num,
+ 			  enum rdma_netdev_t type,
+ 			  const char *name,
+ 			  unsigned char name_assign_type,
+ 			  void (*setup)(struct net_device *))
+ {
+ 	struct net_device *netdev;
+ 	struct rdma_netdev *rn;
+ 
+ 	if (type != RDMA_NETDEV_IPOIB)
+ 		return ERR_PTR(-EOPNOTSUPP);
+ 
+ 	netdev = mlx5_rdma_netdev_alloc(to_mdev(hca)->mdev, hca,
+ 					name, setup);
+ 	if (likely(!IS_ERR_OR_NULL(netdev))) {
+ 		rn = netdev_priv(netdev);
+ 		rn->free_rdma_netdev = mlx5_ib_free_rdma_netdev;
+ 	}
+ 	return netdev;
+ }
+ 
+ static void delay_drop_debugfs_cleanup(struct mlx5_ib_dev *dev)
+ {
+ 	if (!dev->delay_drop.dbg)
+ 		return;
+ 	debugfs_remove_recursive(dev->delay_drop.dbg->dir_debugfs);
+ 	kfree(dev->delay_drop.dbg);
+ 	dev->delay_drop.dbg = NULL;
+ }
+ 
+ static void cancel_delay_drop(struct mlx5_ib_dev *dev)
+ {
+ 	if (!(dev->ib_dev.attrs.raw_packet_caps & IB_RAW_PACKET_CAP_DELAY_DROP))
+ 		return;
+ 
+ 	cancel_work_sync(&dev->delay_drop.delay_drop_work);
+ 	delay_drop_debugfs_cleanup(dev);
+ }
+ 
+ static ssize_t delay_drop_timeout_read(struct file *filp, char __user *buf,
+ 				       size_t count, loff_t *pos)
+ {
+ 	struct mlx5_ib_delay_drop *delay_drop = filp->private_data;
+ 	char lbuf[20];
+ 	int len;
+ 
+ 	len = snprintf(lbuf, sizeof(lbuf), "%u\n", delay_drop->timeout);
+ 	return simple_read_from_buffer(buf, count, pos, lbuf, len);
+ }
+ 
+ static ssize_t delay_drop_timeout_write(struct file *filp, const char __user *buf,
+ 					size_t count, loff_t *pos)
+ {
+ 	struct mlx5_ib_delay_drop *delay_drop = filp->private_data;
+ 	u32 timeout;
+ 	u32 var;
+ 
+ 	if (kstrtouint_from_user(buf, count, 0, &var))
+ 		return -EFAULT;
+ 
+ 	timeout = min_t(u32, roundup(var, 100), MLX5_MAX_DELAY_DROP_TIMEOUT_MS *
+ 			1000);
+ 	if (timeout != var)
+ 		mlx5_ib_dbg(delay_drop->dev, "Round delay drop timeout to %u usec\n",
+ 			    timeout);
+ 
+ 	delay_drop->timeout = timeout;
+ 
+ 	return count;
+ }
+ 
+ static const struct file_operations fops_delay_drop_timeout = {
+ 	.owner	= THIS_MODULE,
+ 	.open	= simple_open,
+ 	.write	= delay_drop_timeout_write,
+ 	.read	= delay_drop_timeout_read,
+ };
+ 
+ static int delay_drop_debugfs_init(struct mlx5_ib_dev *dev)
+ {
+ 	struct mlx5_ib_dbg_delay_drop *dbg;
+ 
+ 	if (!mlx5_debugfs_root)
+ 		return 0;
+ 
+ 	dbg = kzalloc(sizeof(*dbg), GFP_KERNEL);
+ 	if (!dbg)
+ 		return -ENOMEM;
+ 
+ 	dev->delay_drop.dbg = dbg;
+ 
+ 	dbg->dir_debugfs =
+ 		debugfs_create_dir("delay_drop",
+ 				   dev->mdev->priv.dbg_root);
+ 	if (!dbg->dir_debugfs)
+ 		goto out_debugfs;
+ 
+ 	dbg->events_cnt_debugfs =
+ 		debugfs_create_atomic_t("num_timeout_events", 0400,
+ 					dbg->dir_debugfs,
+ 					&dev->delay_drop.events_cnt);
+ 	if (!dbg->events_cnt_debugfs)
+ 		goto out_debugfs;
+ 
+ 	dbg->rqs_cnt_debugfs =
+ 		debugfs_create_atomic_t("num_rqs", 0400,
+ 					dbg->dir_debugfs,
+ 					&dev->delay_drop.rqs_cnt);
+ 	if (!dbg->rqs_cnt_debugfs)
+ 		goto out_debugfs;
+ 
+ 	dbg->timeout_debugfs =
+ 		debugfs_create_file("timeout", 0600,
+ 				    dbg->dir_debugfs,
+ 				    &dev->delay_drop,
+ 				    &fops_delay_drop_timeout);
+ 	if (!dbg->timeout_debugfs)
+ 		goto out_debugfs;
+ 
+ 	return 0;
+ 
+ out_debugfs:
+ 	delay_drop_debugfs_cleanup(dev);
+ 	return -ENOMEM;
+ }
+ 
+ static void init_delay_drop(struct mlx5_ib_dev *dev)
+ {
+ 	if (!(dev->ib_dev.attrs.raw_packet_caps & IB_RAW_PACKET_CAP_DELAY_DROP))
+ 		return;
+ 
+ 	mutex_init(&dev->delay_drop.lock);
+ 	dev->delay_drop.dev = dev;
+ 	dev->delay_drop.activate = false;
+ 	dev->delay_drop.timeout = MLX5_MAX_DELAY_DROP_TIMEOUT_MS * 1000;
+ 	INIT_WORK(&dev->delay_drop.delay_drop_work, delay_drop_handler);
+ 	atomic_set(&dev->delay_drop.rqs_cnt, 0);
+ 	atomic_set(&dev->delay_drop.events_cnt, 0);
+ 
+ 	if (delay_drop_debugfs_init(dev))
+ 		mlx5_ib_warn(dev, "Failed to init delay drop debugfs\n");
+ }
+ 
+ static const struct cpumask *
+ mlx5_ib_get_vector_affinity(struct ib_device *ibdev, int comp_vector)
+ {
+ 	struct mlx5_ib_dev *dev = to_mdev(ibdev);
+ 
+ 	return mlx5_get_vector_affinity(dev->mdev, comp_vector);
+ }
+ 
++>>>>>>> cbafad87e150 (IB/mlx5: fix debugfs cleanup)
  static void *mlx5_ib_add(struct mlx5_core_dev *mdev)
  {
  	struct mlx5_ib_dev *dev;
* Unmerged path drivers/infiniband/hw/mlx5/main.c
