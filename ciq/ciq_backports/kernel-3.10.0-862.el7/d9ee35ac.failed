x86/mm: Disable 1GB direct mappings when disabling 2MB mappings

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Vlastimil Babka <vbabka@suse.cz>
commit d9ee35acfabbc909c3be4360cd5655a006628b2e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/d9ee35ac.failed

The kmemleak and debug_pagealloc features both disable using huge pages for
direct mappings so they can do cpa() on page level granularity in any context.

However they only do that for 2MB pages, which means 1GB pages can still be
used if the CPU supports it, unless disabled by a boot param, which is
non-obvious. Disable also 1GB pages when disabling 2MB pages.

	Signed-off-by: Vlastimil Babka <vbabka@suse.cz>
	Cc: Christian Borntraeger <borntraeger@de.ibm.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Pekka Enberg <penberg@kernel.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Vegard Nossum <vegardno@ifi.uio.no>
	Cc: linux-mm@kvack.org
Link: http://lkml.kernel.org/r/2be70c78-6130-855d-3dfa-d87bd1dd4fda@suse.cz
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit d9ee35acfabbc909c3be4360cd5655a006628b2e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/mm/init.c
diff --cc arch/x86/mm/init.c
index 5223743762dc,9b3f9fa5b283..000000000000
--- a/arch/x86/mm/init.c
+++ b/arch/x86/mm/init.c
@@@ -167,28 -161,34 +167,36 @@@ static int page_size_mask
  
  static void __init probe_page_size_mask(void)
  {
++<<<<<<< HEAD
 +	init_gbpages();
 +
 +#if !defined(CONFIG_DEBUG_PAGEALLOC) && !defined(CONFIG_KMEMCHECK)
++=======
++>>>>>>> d9ee35acfabb (x86/mm: Disable 1GB direct mappings when disabling 2MB mappings)
  	/*
 -	 * For CONFIG_KMEMCHECK or pagealloc debugging, identity mapping will
 -	 * use small pages.
 +	 * For CONFIG_DEBUG_PAGEALLOC, identity mapping will use small pages.
  	 * This will simplify cpa(), which otherwise needs to support splitting
  	 * large pages into small in interrupt context, etc.
  	 */
++<<<<<<< HEAD
 +	if (direct_gbpages)
 +		page_size_mask |= 1 << PG_LEVEL_1G;
 +	if (cpu_has_pse)
++=======
+ 	if (boot_cpu_has(X86_FEATURE_PSE) && !debug_pagealloc_enabled() && !IS_ENABLED(CONFIG_KMEMCHECK))
++>>>>>>> d9ee35acfabb (x86/mm: Disable 1GB direct mappings when disabling 2MB mappings)
  		page_size_mask |= 1 << PG_LEVEL_2M;
- #endif
+ 	else
+ 		direct_gbpages = 0;
  
  	/* Enable PSE if available */
 -	if (boot_cpu_has(X86_FEATURE_PSE))
 -		cr4_set_bits_and_update_boot(X86_CR4_PSE);
 +	if (cpu_has_pse)
 +		set_in_cr4(X86_CR4_PSE);
  
  	/* Enable PGE if available */
 -	if (boot_cpu_has(X86_FEATURE_PGE)) {
 -		cr4_set_bits_and_update_boot(X86_CR4_PGE);
 +	if (cpu_has_pge) {
 +		set_in_cr4(X86_CR4_PGE);
  		__supported_pte_mask |= _PAGE_GLOBAL;
 -	} else
 -		__supported_pte_mask &= ~_PAGE_GLOBAL;
 -
 -	/* Enable 1 GB linear kernel mappings if available: */
 -	if (direct_gbpages && boot_cpu_has(X86_FEATURE_GBPAGES)) {
 -		printk(KERN_INFO "Using GB pages for direct mapping\n");
 -		page_size_mask |= 1 << PG_LEVEL_1G;
 -	} else {
 -		direct_gbpages = 0;
  	}
  }
  
* Unmerged path arch/x86/mm/init.c
