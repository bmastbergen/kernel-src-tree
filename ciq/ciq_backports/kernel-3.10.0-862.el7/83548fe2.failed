scsi: qla2xxx: Cleanup debug message IDs

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [scsi] qla2xxx: Cleanup debug message IDs (Himanshu Madhani) [1460030]
Rebuild_FUZZ: 91.89%
commit-author Quinn Tran <quinn.tran@cavium.com>
commit 83548fe2fcbb78a233e8156feff4e167f1d0831e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/83548fe2.failed

Assign unique id to all traces and logs for debug purpose.

	Signed-off-by: Quinn Tran <quinn.tran@cavium.com>
	Signed-off-by: Himanshu Madhani <himanshu.madhani@cavium.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit 83548fe2fcbb78a233e8156feff4e167f1d0831e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/qla2xxx/qla_attr.c
#	drivers/scsi/qla2xxx/qla_dbg.c
#	drivers/scsi/qla2xxx/qla_dfs.c
#	drivers/scsi/qla2xxx/qla_gs.c
#	drivers/scsi/qla2xxx/qla_init.c
#	drivers/scsi/qla2xxx/qla_isr.c
#	drivers/scsi/qla2xxx/qla_mbx.c
#	drivers/scsi/qla2xxx/qla_os.c
#	drivers/scsi/qla2xxx/qla_target.c
diff --cc drivers/scsi/qla2xxx/qla_attr.c
index 23b15e5afee2,a93eb42718e5..000000000000
--- a/drivers/scsi/qla2xxx/qla_attr.c
+++ b/drivers/scsi/qla2xxx/qla_attr.c
@@@ -754,6 -754,40 +754,43 @@@ static struct bin_attribute sysfs_reset
  };
  
  static ssize_t
++<<<<<<< HEAD
++=======
+ qla2x00_issue_logo(struct file *filp, struct kobject *kobj,
+ 			struct bin_attribute *bin_attr,
+ 			char *buf, loff_t off, size_t count)
+ {
+ 	struct scsi_qla_host *vha = shost_priv(dev_to_shost(container_of(kobj,
+ 	    struct device, kobj)));
+ 	int type;
+ 	port_id_t did;
+ 
+ 	type = simple_strtol(buf, NULL, 10);
+ 
+ 	did.b.domain = (type & 0x00ff0000) >> 16;
+ 	did.b.area = (type & 0x0000ff00) >> 8;
+ 	did.b.al_pa = (type & 0x000000ff);
+ 
+ 	ql_log(ql_log_info, vha, 0xd04d, "portid=%02x%02x%02x done\n",
+ 	    did.b.domain, did.b.area, did.b.al_pa);
+ 
+ 	ql_log(ql_log_info, vha, 0x70e4, "%s: %d\n", __func__, type);
+ 
+ 	qla24xx_els_dcmd_iocb(vha, ELS_DCMD_LOGO, did);
+ 	return count;
+ }
+ 
+ static struct bin_attribute sysfs_issue_logo_attr = {
+ 	.attr = {
+ 		.name = "issue_logo",
+ 		.mode = S_IWUSR,
+ 	},
+ 	.size = 0,
+ 	.write = qla2x00_issue_logo,
+ };
+ 
+ static ssize_t
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  qla2x00_sysfs_read_xgmac_stats(struct file *filp, struct kobject *kobj,
  		       struct bin_attribute *bin_attr,
  		       char *buf, loff_t off, size_t count)
diff --cc drivers/scsi/qla2xxx/qla_dbg.c
index bb8f9db626de,11e097e123bd..000000000000
--- a/drivers/scsi/qla2xxx/qla_dbg.c
+++ b/drivers/scsi/qla2xxx/qla_dbg.c
@@@ -62,17 -59,13 +62,23 @@@
   * |                              |                    | 0xb13c-0xb140  |
   * |                              |                    | 0xb149		|
   * | MultiQ                       |       0xc010       |		|
 - * | Misc                         |       0xd301       | 0xd031-0xd0ff	|
 + * | Misc                         |       0xd300       | 0xd016-0xd017	|
 + * |                              |                    | 0xd021,0xd024	|
 + * |                              |                    | 0xd025,0xd029	|
 + * |                              |                    | 0xd02a,0xd02e	|
 + * |                              |                    | 0xd031-0xd0ff	|
   * |                              |                    | 0xd101-0xd1fe	|
++<<<<<<< HEAD
 + * |                              |                    | 0xd213-0xd2fe	|
 + * | Target Mode		  |	  0xe070       | 0xe021		|
 + * | Target Mode Management	  |	  0xf072       | 0xf002-0xf003	|
++=======
+  * |                              |                    | 0xd214-0xd2fe	|
+  * | Target Mode		  |	  0xe081       |		|
+  * | Target Mode Management	  |	  0xf09b       | 0xf002		|
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
   * |                              |                    | 0xf046-0xf049  |
 - * | Target Mode Task Management  |	  0x1000d      |		|
 + * | Target Mode Task Management  |	  0x1000b      |		|
   * ----------------------------------------------------------------------
   */
  
diff --cc drivers/scsi/qla2xxx/qla_dfs.c
index 2ca39b8e7166,391c50be2297..000000000000
--- a/drivers/scsi/qla2xxx/qla_dfs.c
+++ b/drivers/scsi/qla2xxx/qla_dfs.c
@@@ -13,6 -13,211 +13,214 @@@ static struct dentry *qla2x00_dfs_root
  static atomic_t qla2x00_dfs_root_count;
  
  static int
++<<<<<<< HEAD
++=======
+ qla2x00_dfs_tgt_sess_show(struct seq_file *s, void *unused)
+ {
+ 	scsi_qla_host_t *vha = s->private;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	unsigned long flags;
+ 	struct fc_port *sess = NULL;
+ 	struct qla_tgt *tgt = vha->vha_tgt.qla_tgt;
+ 
+ 	seq_printf(s, "%s\n", vha->host_str);
+ 	if (tgt) {
+ 		seq_puts(s, "Port ID   Port Name                Handle\n");
+ 
+ 		spin_lock_irqsave(&ha->tgt.sess_lock, flags);
+ 		list_for_each_entry(sess, &vha->vp_fcports, list)
+ 			seq_printf(s, "%02x:%02x:%02x  %8phC  %d\n",
+ 			    sess->d_id.b.domain, sess->d_id.b.area,
+ 			    sess->d_id.b.al_pa, sess->port_name,
+ 			    sess->loop_id);
+ 		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int
+ qla2x00_dfs_tgt_sess_open(struct inode *inode, struct file *file)
+ {
+ 	scsi_qla_host_t *vha = inode->i_private;
+ 	return single_open(file, qla2x00_dfs_tgt_sess_show, vha);
+ }
+ 
+ static const struct file_operations dfs_tgt_sess_ops = {
+ 	.open		= qla2x00_dfs_tgt_sess_open,
+ 	.read		= seq_read,
+ 	.llseek		= seq_lseek,
+ 	.release	= single_release,
+ };
+ 
+ static int
+ qla2x00_dfs_tgt_port_database_show(struct seq_file *s, void *unused)
+ {
+ 	scsi_qla_host_t *vha = s->private;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	struct gid_list_info *gid_list;
+ 	dma_addr_t gid_list_dma;
+ 	fc_port_t fc_port;
+ 	char *id_iter;
+ 	int rc, i;
+ 	uint16_t entries, loop_id;
+ 	struct qla_tgt *tgt = vha->vha_tgt.qla_tgt;
+ 
+ 	seq_printf(s, "%s\n", vha->host_str);
+ 	if (tgt) {
+ 		gid_list = dma_alloc_coherent(&ha->pdev->dev,
+ 		    qla2x00_gid_list_size(ha),
+ 		    &gid_list_dma, GFP_KERNEL);
+ 		if (!gid_list) {
+ 			ql_dbg(ql_dbg_user, vha, 0x7018,
+ 			    "DMA allocation failed for %u\n",
+ 			     qla2x00_gid_list_size(ha));
+ 			return 0;
+ 		}
+ 
+ 		rc = qla24xx_gidlist_wait(vha, gid_list, gid_list_dma,
+ 		    &entries);
+ 		if (rc != QLA_SUCCESS)
+ 			goto out_free_id_list;
+ 
+ 		id_iter = (char *)gid_list;
+ 
+ 		seq_puts(s, "Port Name	Port ID 	Loop ID\n");
+ 
+ 		for (i = 0; i < entries; i++) {
+ 			struct gid_list_info *gid =
+ 			    (struct gid_list_info *)id_iter;
+ 			loop_id = le16_to_cpu(gid->loop_id);
+ 			memset(&fc_port, 0, sizeof(fc_port_t));
+ 
+ 			fc_port.loop_id = loop_id;
+ 
+ 			rc = qla24xx_gpdb_wait(vha, &fc_port, 0);
+ 			seq_printf(s, "%8phC  %02x%02x%02x  %d\n",
+ 				fc_port.port_name, fc_port.d_id.b.domain,
+ 				fc_port.d_id.b.area, fc_port.d_id.b.al_pa,
+ 				fc_port.loop_id);
+ 			id_iter += ha->gid_list_info_size;
+ 		}
+ out_free_id_list:
+ 		dma_free_coherent(&ha->pdev->dev, qla2x00_gid_list_size(ha),
+ 		    gid_list, gid_list_dma);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int
+ qla2x00_dfs_tgt_port_database_open(struct inode *inode, struct file *file)
+ {
+ 	scsi_qla_host_t *vha = inode->i_private;
+ 
+ 	return single_open(file, qla2x00_dfs_tgt_port_database_show, vha);
+ }
+ 
+ static const struct file_operations dfs_tgt_port_database_ops = {
+ 	.open		= qla2x00_dfs_tgt_port_database_open,
+ 	.read		= seq_read,
+ 	.llseek		= seq_lseek,
+ 	.release	= single_release,
+ };
+ 
+ static int
+ qla_dfs_fw_resource_cnt_show(struct seq_file *s, void *unused)
+ {
+ 	struct scsi_qla_host *vha = s->private;
+ 	struct qla_hw_data *ha = vha->hw;
+ 
+ 	seq_puts(s, "FW Resource count\n\n");
+ 	seq_printf(s, "Original TGT exchg count[%d]\n",
+ 	    ha->orig_fw_tgt_xcb_count);
+ 	seq_printf(s, "current TGT exchg count[%d]\n",
+ 	    ha->cur_fw_tgt_xcb_count);
+ 	seq_printf(s, "original Initiator Exchange count[%d]\n",
+ 	    ha->orig_fw_xcb_count);
+ 	seq_printf(s, "Current Initiator Exchange count[%d]\n",
+ 	    ha->cur_fw_xcb_count);
+ 	seq_printf(s, "Original IOCB count[%d]\n", ha->orig_fw_iocb_count);
+ 	seq_printf(s, "Current IOCB count[%d]\n", ha->cur_fw_iocb_count);
+ 	seq_printf(s, "MAX VP count[%d]\n", ha->max_npiv_vports);
+ 	seq_printf(s, "MAX FCF count[%d]\n", ha->fw_max_fcf_count);
+ 
+ 	return 0;
+ }
+ 
+ static int
+ qla_dfs_fw_resource_cnt_open(struct inode *inode, struct file *file)
+ {
+ 	struct scsi_qla_host *vha = inode->i_private;
+ 	return single_open(file, qla_dfs_fw_resource_cnt_show, vha);
+ }
+ 
+ static const struct file_operations dfs_fw_resource_cnt_ops = {
+ 	.open           = qla_dfs_fw_resource_cnt_open,
+ 	.read           = seq_read,
+ 	.llseek         = seq_lseek,
+ 	.release        = single_release,
+ };
+ 
+ static int
+ qla_dfs_tgt_counters_show(struct seq_file *s, void *unused)
+ {
+ 	struct scsi_qla_host *vha = s->private;
+ 
+ 	seq_puts(s, "Target Counters\n");
+ 	seq_printf(s, "qla_core_sbt_cmd = %lld\n",
+ 		vha->tgt_counters.qla_core_sbt_cmd);
+ 	seq_printf(s, "qla_core_ret_sta_ctio = %lld\n",
+ 		vha->tgt_counters.qla_core_ret_sta_ctio);
+ 	seq_printf(s, "qla_core_ret_ctio = %lld\n",
+ 		vha->tgt_counters.qla_core_ret_ctio);
+ 	seq_printf(s, "core_qla_que_buf = %lld\n",
+ 		vha->tgt_counters.core_qla_que_buf);
+ 	seq_printf(s, "core_qla_snd_status = %lld\n",
+ 		vha->tgt_counters.core_qla_snd_status);
+ 	seq_printf(s, "core_qla_free_cmd = %lld\n",
+ 		vha->tgt_counters.core_qla_free_cmd);
+ 	seq_printf(s, "num alloc iocb failed = %lld\n",
+ 		vha->tgt_counters.num_alloc_iocb_failed);
+ 	seq_printf(s, "num term exchange sent = %lld\n",
+ 		vha->tgt_counters.num_term_xchg_sent);
+ 	seq_printf(s, "num Q full sent = %lld\n",
+ 		vha->tgt_counters.num_q_full_sent);
+ 
+ 	/* DIF stats */
+ 	seq_printf(s, "DIF Inp Bytes = %lld\n",
+ 		vha->qla_stats.qla_dif_stats.dif_input_bytes);
+ 	seq_printf(s, "DIF Outp Bytes = %lld\n",
+ 		vha->qla_stats.qla_dif_stats.dif_output_bytes);
+ 	seq_printf(s, "DIF Inp Req = %lld\n",
+ 		vha->qla_stats.qla_dif_stats.dif_input_requests);
+ 	seq_printf(s, "DIF Outp Req = %lld\n",
+ 		vha->qla_stats.qla_dif_stats.dif_output_requests);
+ 	seq_printf(s, "DIF Guard err = %d\n",
+ 		vha->qla_stats.qla_dif_stats.dif_guard_err);
+ 	seq_printf(s, "DIF Ref tag err = %d\n",
+ 		vha->qla_stats.qla_dif_stats.dif_ref_tag_err);
+ 	seq_printf(s, "DIF App tag err = %d\n",
+ 		vha->qla_stats.qla_dif_stats.dif_app_tag_err);
+ 	return 0;
+ }
+ 
+ static int
+ qla_dfs_tgt_counters_open(struct inode *inode, struct file *file)
+ {
+ 	struct scsi_qla_host *vha = inode->i_private;
+ 	return single_open(file, qla_dfs_tgt_counters_show, vha);
+ }
+ 
+ static const struct file_operations dfs_tgt_counters_ops = {
+ 	.open           = qla_dfs_tgt_counters_open,
+ 	.read           = seq_read,
+ 	.llseek         = seq_lseek,
+ 	.release        = single_release,
+ };
+ 
+ static int
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  qla2x00_dfs_fce_show(struct seq_file *s, void *unused)
  {
  	scsi_qla_host_t *vha = s->private;
@@@ -146,6 -351,30 +354,33 @@@ create_dir
  	atomic_inc(&qla2x00_dfs_root_count);
  
  create_nodes:
++<<<<<<< HEAD
++=======
+ 	ha->dfs_fw_resource_cnt = debugfs_create_file("fw_resource_count",
+ 	    S_IRUSR, ha->dfs_dir, vha, &dfs_fw_resource_cnt_ops);
+ 	if (!ha->dfs_fw_resource_cnt) {
+ 		ql_log(ql_log_warn, vha, 0x00fd,
+ 		    "Unable to create debugFS fw_resource_count node.\n");
+ 		goto out;
+ 	}
+ 
+ 	ha->dfs_tgt_counters = debugfs_create_file("tgt_counters", S_IRUSR,
+ 	    ha->dfs_dir, vha, &dfs_tgt_counters_ops);
+ 	if (!ha->dfs_tgt_counters) {
+ 		ql_log(ql_log_warn, vha, 0xd301,
+ 		    "Unable to create debugFS tgt_counters node.\n");
+ 		goto out;
+ 	}
+ 
+ 	ha->tgt.dfs_tgt_port_database = debugfs_create_file("tgt_port_database",
+ 	    S_IRUSR,  ha->dfs_dir, vha, &dfs_tgt_port_database_ops);
+ 	if (!ha->tgt.dfs_tgt_port_database) {
+ 		ql_log(ql_log_warn, vha, 0xd03f,
+ 		    "Unable to create debugFS tgt_port_database node.\n");
+ 		goto out;
+ 	}
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	ha->dfs_fce = debugfs_create_file("fce", S_IRUSR, ha->dfs_dir, vha,
  	    &dfs_fce_ops);
  	if (!ha->dfs_fce) {
@@@ -153,6 -382,15 +388,18 @@@
  		    "Unable to create debugfs fce node.\n");
  		goto out;
  	}
++<<<<<<< HEAD
++=======
+ 
+ 	ha->tgt.dfs_tgt_sess = debugfs_create_file("tgt_sess",
+ 		S_IRUSR, ha->dfs_dir, vha, &dfs_tgt_sess_ops);
+ 	if (!ha->tgt.dfs_tgt_sess) {
+ 		ql_log(ql_log_warn, vha, 0xd040,
+ 		    "Unable to create debugFS tgt_sess node.\n");
+ 		goto out;
+ 	}
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  out:
  	return 0;
  }
diff --cc drivers/scsi/qla2xxx/qla_gs.c
index 54827d74afb8,540fec524ccb..000000000000
--- a/drivers/scsi/qla2xxx/qla_gs.c
+++ b/drivers/scsi/qla2xxx/qla_gs.c
@@@ -2692,3 -2761,547 +2692,550 @@@ qla2x00_gff_id(scsi_qla_host_t *vha, sw
  			break;
  	}
  }
++<<<<<<< HEAD
++=======
+ 
+ /* GID_PN completion processing. */
+ void qla24xx_handle_gidpn_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	fc_port_t *fcport = ea->fcport;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x201d,
+ 	    "%s %8phC login state %d\n",
+ 	    __func__, fcport->port_name, fcport->fw_login_state);
+ 
+ 	if (ea->sp->gen2 != fcport->login_gen) {
+ 		/* PLOGI/PRLI/LOGO came in while cmd was out.*/
+ 		ql_dbg(ql_dbg_disc, vha, 0x201e,
+ 		    "%s %8phC generation changed rscn %d|%d login %d|%d \n",
+ 		    __func__, fcport->port_name, fcport->last_rscn_gen,
+ 		    fcport->rscn_gen, fcport->last_login_gen, fcport->login_gen);
+ 		return;
+ 	}
+ 
+ 	if (!ea->rc) {
+ 		if (ea->sp->gen1 == fcport->rscn_gen) {
+ 			fcport->scan_state = QLA_FCPORT_FOUND;
+ 			fcport->flags |= FCF_FABRIC_DEVICE;
+ 
+ 			if (fcport->d_id.b24 == ea->id.b24) {
+ 				/* cable plugged into the same place */
+ 				switch (vha->host->active_mode) {
+ 				case MODE_TARGET:
+ 					/* NOOP. let the other guy login to us.*/
+ 					break;
+ 				case MODE_INITIATOR:
+ 				case MODE_DUAL:
+ 				default:
+ 					if (atomic_read(&fcport->state) ==
+ 					    FCS_ONLINE)
+ 						break;
+ 					ql_dbg(ql_dbg_disc, vha, 0x201f,
+ 					    "%s %d %8phC post gnl\n",
+ 					    __func__, __LINE__, fcport->port_name);
+ 					qla24xx_post_gnl_work(vha, fcport);
+ 					break;
+ 				}
+ 			} else { /* fcport->d_id.b24 != ea->id.b24 */
+ 				fcport->d_id.b24 = ea->id.b24;
+ 				if (fcport->deleted == QLA_SESS_DELETED) {
+ 					ql_dbg(ql_dbg_disc, vha, 0x2021,
+ 					    "%s %d %8phC post del sess\n",
+ 					    __func__, __LINE__, fcport->port_name);
+ 					qlt_schedule_sess_for_deletion_lock(fcport);
+ 				}
+ 			}
+ 		} else { /* ea->sp->gen1 != fcport->rscn_gen */
+ 			ql_dbg(ql_dbg_disc, vha, 0x2022,
+ 			    "%s %d %8phC post gidpn\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			/* rscn came in while cmd was out */
+ 			qla24xx_post_gidpn_work(vha, fcport);
+ 		}
+ 	} else { /* ea->rc */
+ 		/* cable pulled */
+ 		if (ea->sp->gen1 == fcport->rscn_gen) {
+ 			if (ea->sp->gen2 == fcport->login_gen) {
+ 				ql_dbg(ql_dbg_disc, vha, 0x2042,
+ 				    "%s %d %8phC post del sess\n", __func__,
+ 				    __LINE__, fcport->port_name);
+ 				qlt_schedule_sess_for_deletion_lock(fcport);
+ 			} else {
+ 				ql_dbg(ql_dbg_disc, vha, 0x2045,
+ 				    "%s %d %8phC login\n", __func__, __LINE__,
+ 				    fcport->port_name);
+ 				qla24xx_fcport_handle_login(vha, fcport);
+ 			}
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, vha, 0x2049,
+ 			    "%s %d %8phC post gidpn\n", __func__, __LINE__,
+ 			    fcport->port_name);
+ 			qla24xx_post_gidpn_work(vha, fcport);
+ 		}
+ 	}
+ } /* gidpn_event */
+ 
+ static void qla2x00_async_gidpn_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	fc_port_t *fcport = sp->fcport;
+ 	u8 *id = fcport->ct_desc.ct_sns->p.rsp.rsp.gid_pn.port_id;
+ 	struct event_arg ea;
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.fcport = fcport;
+ 	ea.id.b.domain = id[0];
+ 	ea.id.b.area = id[1];
+ 	ea.id.b.al_pa = id[2];
+ 	ea.sp = sp;
+ 	ea.rc = res;
+ 	ea.event = FCME_GIDPN_DONE;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x204f,
+ 	    "Async done-%s res %x, WWPN %8phC ID %3phC \n",
+ 	    sp->name, res, fcport->port_name, id);
+ 
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_gidpn(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online)
+ 		goto done;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	fcport->disc_state = DSC_GID_PN;
+ 	fcport->scan_state = QLA_FCPORT_SCAN;
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_ATOMIC);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gidpn";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(fcport->ct_desc.ct_sns, GID_PN_CMD,
+ 		GID_PN_RSP_SIZE);
+ 
+ 	/* GIDPN req */
+ 	memcpy(ct_req->req.gid_pn.port_name, fcport->port_name,
+ 		WWN_SIZE);
+ 
+ 	/* req & rsp use the same buffer */
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GID_PN_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GID_PN_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_gidpn_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20a4,
+ 	    "Async-%s - %8phC hdl=%x loopid=%x portid %02x%02x%02x.\n",
+ 	    sp->name, fcport->port_name,
+ 	    sp->handle, fcport->loop_id, fcport->d_id.b.domain,
+ 	    fcport->d_id.b.area, fcport->d_id.b.al_pa);
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ done:
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gidpn_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 	int ls;
+ 
+ 	ls = atomic_read(&vha->loop_state);
+ 	if (((ls != LOOP_READY) && (ls != LOOP_UP)) ||
+ 		test_bit(UNLOADING, &vha->dpc_flags))
+ 		return 0;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GIDPN);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ int qla24xx_post_gpsc_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GPSC);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ static void qla24xx_async_gpsc_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	fc_port_t *fcport = sp->fcport;
+ 	struct ct_sns_rsp       *ct_rsp;
+ 	struct event_arg ea;
+ 
+ 	ct_rsp = &fcport->ct_desc.ct_sns->p.rsp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2053,
+ 	    "Async done-%s res %x, WWPN %8phC \n",
+ 	    sp->name, res, fcport->port_name);
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 
+ 	if (res == (DID_ERROR << 16)) {
+ 		/* entry status error */
+ 		goto done;
+ 	} else if (res) {
+ 		if ((ct_rsp->header.reason_code ==
+ 			 CT_REASON_INVALID_COMMAND_CODE) ||
+ 			(ct_rsp->header.reason_code ==
+ 			CT_REASON_COMMAND_UNSUPPORTED)) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x2019,
+ 			    "GPSC command unsupported, disabling query.\n");
+ 			ha->flags.gpsc_supported = 0;
+ 			res = QLA_SUCCESS;
+ 		}
+ 	} else {
+ 		switch (be16_to_cpu(ct_rsp->rsp.gpsc.speed)) {
+ 		case BIT_15:
+ 			fcport->fp_speed = PORT_SPEED_1GB;
+ 			break;
+ 		case BIT_14:
+ 			fcport->fp_speed = PORT_SPEED_2GB;
+ 			break;
+ 		case BIT_13:
+ 			fcport->fp_speed = PORT_SPEED_4GB;
+ 			break;
+ 		case BIT_12:
+ 			fcport->fp_speed = PORT_SPEED_10GB;
+ 			break;
+ 		case BIT_11:
+ 			fcport->fp_speed = PORT_SPEED_8GB;
+ 			break;
+ 		case BIT_10:
+ 			fcport->fp_speed = PORT_SPEED_16GB;
+ 			break;
+ 		case BIT_8:
+ 			fcport->fp_speed = PORT_SPEED_32GB;
+ 			break;
+ 		}
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0x2054,
+ 		    "Async-%s OUT WWPN %8phC speeds=%04x speed=%04x.\n",
+ 		    sp->name, fcport->fabric_port_name,
+ 		    be16_to_cpu(ct_rsp->rsp.gpsc.speeds),
+ 		    be16_to_cpu(ct_rsp->rsp.gpsc.speed));
+ 	}
+ done:
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.event = FCME_GPSC_DONE;
+ 	ea.rc = res;
+ 	ea.fcport = fcport;
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_gpsc(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online)
+ 		goto done;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gpsc";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla24xx_prep_ct_fm_req(fcport->ct_desc.ct_sns, GPSC_CMD,
+ 		GPSC_RSP_SIZE);
+ 
+ 	/* GPSC req */
+ 	memcpy(ct_req->req.gpsc.port_name, fcport->port_name,
+ 		WWN_SIZE);
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GPSC_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GPSC_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = vha->mgmt_svr_loop_id;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla24xx_async_gpsc_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x205e,
+ 	    "Async-%s %8phC hdl=%x loopid=%x portid=%02x%02x%02x.\n",
+ 	    sp->name, fcport->port_name, sp->handle,
+ 	    fcport->loop_id, fcport->d_id.b.domain,
+ 	    fcport->d_id.b.area, fcport->d_id.b.al_pa);
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ done:
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gpnid_work(struct scsi_qla_host *vha, port_id_t *id)
+ {
+ 	struct qla_work_evt *e;
+ 
+ 	if (test_bit(UNLOADING, &vha->dpc_flags))
+ 		return 0;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GPNID);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.gpnid.id = *id;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ void qla24xx_async_gpnid_done(scsi_qla_host_t *vha, srb_t *sp)
+ {
+ 	if (sp->u.iocb_cmd.u.ctarg.req) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 			sizeof(struct ct_sns_pkt),
+ 			sp->u.iocb_cmd.u.ctarg.req,
+ 			sp->u.iocb_cmd.u.ctarg.req_dma);
+ 		sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 	}
+ 	if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 			sizeof(struct ct_sns_pkt),
+ 			sp->u.iocb_cmd.u.ctarg.rsp,
+ 			sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 		sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 	}
+ 
+ 	sp->free(sp);
+ }
+ 
+ void qla24xx_handle_gpnid_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	fc_port_t *fcport;
+ 	unsigned long flags;
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 	fcport = qla2x00_find_fcport_by_wwpn(vha, ea->port_name, 1);
+ 	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 
+ 	if (fcport) {
+ 		/* cable moved. just plugged in */
+ 		fcport->rscn_gen++;
+ 		fcport->d_id = ea->id;
+ 		fcport->scan_state = QLA_FCPORT_FOUND;
+ 		fcport->flags |= FCF_FABRIC_DEVICE;
+ 
+ 		switch (fcport->disc_state) {
+ 		case DSC_DELETED:
+ 			ql_dbg(ql_dbg_disc, vha, 0x210d,
+ 			    "%s %d %8phC login\n", __func__, __LINE__,
+ 			    fcport->port_name);
+ 			qla24xx_fcport_handle_login(vha, fcport);
+ 			break;
+ 		case DSC_DELETE_PEND:
+ 			break;
+ 		default:
+ 			ql_dbg(ql_dbg_disc, vha, 0x2064,
+ 			    "%s %d %8phC post del sess\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			qlt_schedule_sess_for_deletion_lock(fcport);
+ 			break;
+ 		}
+ 	} else {
+ 		/* create new fcport */
+ 		ql_dbg(ql_dbg_disc, vha, 0x2065,
+ 		    "%s %d %8phC post new sess\n",
+ 		    __func__, __LINE__, ea->port_name);
+ 
+ 		qla24xx_post_newsess_work(vha, &ea->id, ea->port_name, NULL);
+ 	}
+ }
+ 
+ static void qla2x00_async_gpnid_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	struct ct_sns_req *ct_req =
+ 	    (struct ct_sns_req *)sp->u.iocb_cmd.u.ctarg.req;
+ 	struct ct_sns_rsp *ct_rsp =
+ 	    (struct ct_sns_rsp *)sp->u.iocb_cmd.u.ctarg.rsp;
+ 	struct event_arg ea;
+ 	struct qla_work_evt *e;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2066,
+ 	    "Async done-%s res %x ID %3phC. %8phC\n",
+ 	    sp->name, res, ct_req->req.port_id.port_id,
+ 	    ct_rsp->rsp.gpn_id.port_name);
+ 
+ 	memset(&ea, 0, sizeof(ea));
+ 	memcpy(ea.port_name, ct_rsp->rsp.gpn_id.port_name, WWN_SIZE);
+ 	ea.sp = sp;
+ 	ea.id.b.domain = ct_req->req.port_id.port_id[0];
+ 	ea.id.b.area = ct_req->req.port_id.port_id[1];
+ 	ea.id.b.al_pa = ct_req->req.port_id.port_id[2];
+ 	ea.rc = res;
+ 	ea.event = FCME_GPNID_DONE;
+ 
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GPNID_DONE);
+ 	if (!e) {
+ 		/* please ignore kernel warning. otherwise, we have mem leak. */
+ 		if (sp->u.iocb_cmd.u.ctarg.req) {
+ 			dma_free_coherent(&vha->hw->pdev->dev,
+ 				sizeof(struct ct_sns_pkt),
+ 				sp->u.iocb_cmd.u.ctarg.req,
+ 				sp->u.iocb_cmd.u.ctarg.req_dma);
+ 			sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 		}
+ 		if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 			dma_free_coherent(&vha->hw->pdev->dev,
+ 				sizeof(struct ct_sns_pkt),
+ 				sp->u.iocb_cmd.u.ctarg.rsp,
+ 				sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 			sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 		}
+ 
+ 		sp->free(sp);
+ 		return;
+ 	}
+ 
+ 	e->u.iosb.sp = sp;
+ 	qla2x00_post_work(vha, e);
+ }
+ 
+ /* Get WWPN with Nport ID. */
+ int qla24xx_async_gpnid(scsi_qla_host_t *vha, port_id_t *id)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 	struct ct_sns_pkt *ct_sns;
+ 
+ 	if (!vha->flags.online)
+ 		goto done;
+ 
+ 	sp = qla2x00_get_sp(vha, NULL, GFP_KERNEL);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gpnid";
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req = dma_alloc_coherent(&vha->hw->pdev->dev,
+ 		sizeof(struct ct_sns_pkt), &sp->u.iocb_cmd.u.ctarg.req_dma,
+ 		GFP_KERNEL);
+ 	if (!sp->u.iocb_cmd.u.ctarg.req) {
+ 		ql_log(ql_log_warn, vha, 0xd041,
+ 		    "Failed to allocate ct_sns request.\n");
+ 		goto done_free_sp;
+ 	}
+ 
+ 	sp->u.iocb_cmd.u.ctarg.rsp = dma_alloc_coherent(&vha->hw->pdev->dev,
+ 		sizeof(struct ct_sns_pkt), &sp->u.iocb_cmd.u.ctarg.rsp_dma,
+ 		GFP_KERNEL);
+ 	if (!sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		ql_log(ql_log_warn, vha, 0xd042,
+ 		    "Failed to allocate ct_sns request.\n");
+ 		goto done_free_sp;
+ 	}
+ 
+ 	ct_sns = (struct ct_sns_pkt *)sp->u.iocb_cmd.u.ctarg.rsp;
+ 	memset(ct_sns, 0, sizeof(*ct_sns));
+ 
+ 	ct_sns = (struct ct_sns_pkt *)sp->u.iocb_cmd.u.ctarg.req;
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(ct_sns, GPN_ID_CMD, GPN_ID_RSP_SIZE);
+ 
+ 	/* GPN_ID req */
+ 	ct_req->req.port_id.port_id[0] = id->b.domain;
+ 	ct_req->req.port_id.port_id[1] = id->b.area;
+ 	ct_req->req.port_id.port_id[2] = id->b.al_pa;
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GPN_ID_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GPN_ID_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_gpnid_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2067,
+ 	    "Async-%s hdl=%x ID %3phC.\n", sp->name,
+ 	    sp->handle, ct_req->req.port_id.port_id);
+ 	return rval;
+ 
+ done_free_sp:
+ 	if (sp->u.iocb_cmd.u.ctarg.req) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 			sizeof(struct ct_sns_pkt),
+ 			sp->u.iocb_cmd.u.ctarg.req,
+ 			sp->u.iocb_cmd.u.ctarg.req_dma);
+ 		sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 	}
+ 	if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 			sizeof(struct ct_sns_pkt),
+ 			sp->u.iocb_cmd.u.ctarg.rsp,
+ 			sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 		sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 	}
+ 
+ 	sp->free(sp);
+ done:
+ 	return rval;
+ }
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
diff --cc drivers/scsi/qla2xxx/qla_init.c
index b9189cae77e5,c425d061cd80..000000000000
--- a/drivers/scsi/qla2xxx/qla_init.c
+++ b/drivers/scsi/qla2xxx/qla_init.c
@@@ -119,16 -134,30 +119,36 @@@ qla2x00_async_iocb_timeout(void *data
  }
  
  static void
 -qla2x00_async_login_sp_done(void *ptr, int res)
 +qla2x00_async_login_sp_done(void *data, void *ptr, int res)
  {
 -	srb_t *sp = ptr;
 -	struct scsi_qla_host *vha = sp->vha;
 +	srb_t *sp = (srb_t *)ptr;
  	struct srb_iocb *lio = &sp->u.iocb_cmd;
 -	struct event_arg ea;
 +	struct scsi_qla_host *vha = (scsi_qla_host_t *)data;
  
++<<<<<<< HEAD
 +	if (!test_bit(UNLOADING, &vha->dpc_flags))
 +		qla2x00_post_async_login_done_work(sp->fcport->vha, sp->fcport,
 +		    lio->u.logio.data);
 +	sp->free(sp->fcport->vha, sp);
++=======
+ 	ql_dbg(ql_dbg_disc, vha, 0x20dd,
+ 	    "%s %8phC res %d \n", __func__, sp->fcport->port_name, res);
+ 
+ 	sp->fcport->flags &= ~FCF_ASYNC_SENT;
+ 	if (!test_bit(UNLOADING, &vha->dpc_flags)) {
+ 		memset(&ea, 0, sizeof(ea));
+ 		ea.event = FCME_PLOGI_DONE;
+ 		ea.fcport = sp->fcport;
+ 		ea.data[0] = lio->u.logio.data[0];
+ 		ea.data[1] = lio->u.logio.data[1];
+ 		ea.iop[0] = lio->u.logio.iop[0];
+ 		ea.iop[1] = lio->u.logio.iop[1];
+ 		ea.sp = sp;
+ 		qla2x00_fcport_event_handler(vha, &ea);
+ 	}
+ 
+ 	sp->free(sp);
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  }
  
  int
@@@ -274,6 -318,829 +294,831 @@@ done
  	return rval;
  }
  
++<<<<<<< HEAD
++=======
+ static void qla24xx_handle_gnl_done_event(scsi_qla_host_t *vha,
+ 	struct event_arg *ea)
+ {
+ 	fc_port_t *fcport, *conflict_fcport;
+ 	struct get_name_list_extended *e;
+ 	u16 i, n, found = 0, loop_id;
+ 	port_id_t id;
+ 	u64 wwn;
+ 	u8 opt = 0;
+ 
+ 	fcport = ea->fcport;
+ 
+ 	if (ea->rc) { /* rval */
+ 		if (fcport->login_retry == 0) {
+ 			fcport->login_retry = vha->hw->login_retry_count;
+ 			ql_dbg(ql_dbg_disc, vha, 0x20de,
+ 			    "GNL failed Port login retry %8phN, retry cnt=%d.\n",
+ 			    fcport->port_name, fcport->login_retry);
+ 		}
+ 		return;
+ 	}
+ 
+ 	if (fcport->last_rscn_gen != fcport->rscn_gen) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20df,
+ 		    "%s %8phC rscn gen changed rscn %d|%d \n",
+ 		    __func__, fcport->port_name,
+ 		    fcport->last_rscn_gen, fcport->rscn_gen);
+ 		qla24xx_post_gidpn_work(vha, fcport);
+ 		return;
+ 	} else if (fcport->last_login_gen != fcport->login_gen) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20e0,
+ 		    "%s %8phC login gen changed login %d|%d\n",
+ 		    __func__, fcport->port_name,
+ 		    fcport->last_login_gen, fcport->login_gen);
+ 		return;
+ 	}
+ 
+ 	n = ea->data[0] / sizeof(struct get_name_list_extended);
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20e1,
+ 	    "%s %d %8phC n %d %02x%02x%02x lid %d \n",
+ 	    __func__, __LINE__, fcport->port_name, n,
+ 	    fcport->d_id.b.domain, fcport->d_id.b.area,
+ 	    fcport->d_id.b.al_pa, fcport->loop_id);
+ 
+ 	for (i = 0; i < n; i++) {
+ 		e = &vha->gnl.l[i];
+ 		wwn = wwn_to_u64(e->port_name);
+ 
+ 		if (memcmp((u8 *)&wwn, fcport->port_name, WWN_SIZE))
+ 			continue;
+ 
+ 		found = 1;
+ 		id.b.domain = e->port_id[2];
+ 		id.b.area = e->port_id[1];
+ 		id.b.al_pa = e->port_id[0];
+ 		id.b.rsvd_1 = 0;
+ 
+ 		loop_id = le16_to_cpu(e->nport_handle);
+ 		loop_id = (loop_id & 0x7fff);
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0x20e2,
+ 		    "%s found %8phC CLS [%d|%d] ID[%02x%02x%02x|%02x%02x%02x] lid[%d|%d]\n",
+ 		    __func__, fcport->port_name,
+ 		    e->current_login_state, fcport->fw_login_state,
+ 		    id.b.domain, id.b.area, id.b.al_pa,
+ 		    fcport->d_id.b.domain, fcport->d_id.b.area,
+ 		    fcport->d_id.b.al_pa, loop_id, fcport->loop_id);
+ 
+ 		if ((id.b24 != fcport->d_id.b24) ||
+ 		    ((fcport->loop_id != FC_NO_LOOP_ID) &&
+ 			(fcport->loop_id != loop_id))) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20e3,
+ 			    "%s %d %8phC post del sess\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			qlt_schedule_sess_for_deletion(fcport, 1);
+ 			return;
+ 		}
+ 
+ 		fcport->loop_id = loop_id;
+ 
+ 		wwn = wwn_to_u64(fcport->port_name);
+ 		qlt_find_sess_invalidate_other(vha, wwn,
+ 			id, loop_id, &conflict_fcport);
+ 
+ 		if (conflict_fcport) {
+ 			/*
+ 			 * Another share fcport share the same loop_id &
+ 			 * nport id. Conflict fcport needs to finish
+ 			 * cleanup before this fcport can proceed to login.
+ 			 */
+ 			conflict_fcport->conflict = fcport;
+ 			fcport->login_pause = 1;
+ 		}
+ 
+ 		switch (e->current_login_state) {
+ 		case DSC_LS_PRLI_COMP:
+ 			ql_dbg(ql_dbg_disc, vha, 0x20e4,
+ 			    "%s %d %8phC post gpdb\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			opt = PDO_FORCE_ADISC;
+ 			qla24xx_post_gpdb_work(vha, fcport, opt);
+ 			break;
+ 
+ 		case DSC_LS_PORT_UNAVAIL:
+ 		default:
+ 			if (fcport->loop_id == FC_NO_LOOP_ID) {
+ 				qla2x00_find_new_loop_id(vha, fcport);
+ 				fcport->fw_login_state = DSC_LS_PORT_UNAVAIL;
+ 			}
+ 			ql_dbg(ql_dbg_disc, vha, 0x20e5,
+ 			    "%s %d %8phC\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			qla24xx_fcport_handle_login(vha, fcport);
+ 			break;
+ 		}
+ 	}
+ 
+ 	if (!found) {
+ 		/* fw has no record of this port */
+ 		if (fcport->loop_id == FC_NO_LOOP_ID) {
+ 			qla2x00_find_new_loop_id(vha, fcport);
+ 			fcport->fw_login_state = DSC_LS_PORT_UNAVAIL;
+ 		} else {
+ 			for (i = 0; i < n; i++) {
+ 				e = &vha->gnl.l[i];
+ 				id.b.domain = e->port_id[0];
+ 				id.b.area = e->port_id[1];
+ 				id.b.al_pa = e->port_id[2];
+ 				id.b.rsvd_1 = 0;
+ 				loop_id = le16_to_cpu(e->nport_handle);
+ 
+ 				if (fcport->d_id.b24 == id.b24) {
+ 					conflict_fcport =
+ 					    qla2x00_find_fcport_by_wwpn(vha,
+ 						e->port_name, 0);
+ 
+ 					ql_dbg(ql_dbg_disc, vha, 0x20e6,
+ 					    "%s %d %8phC post del sess\n",
+ 					    __func__, __LINE__,
+ 					    conflict_fcport->port_name);
+ 					qlt_schedule_sess_for_deletion
+ 						(conflict_fcport, 1);
+ 				}
+ 
+ 				if (fcport->loop_id == loop_id) {
+ 					/* FW already picked this loop id for another fcport */
+ 					qla2x00_find_new_loop_id(vha, fcport);
+ 				}
+ 			}
+ 		}
+ 		qla24xx_fcport_handle_login(vha, fcport);
+ 	}
+ } /* gnl_event */
+ 
+ static void
+ qla24xx_async_gnl_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	unsigned long flags;
+ 	struct fc_port *fcport = NULL, *tf;
+ 	u16 i, n = 0, loop_id;
+ 	struct event_arg ea;
+ 	struct get_name_list_extended *e;
+ 	u64 wwn;
+ 	struct list_head h;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20e7,
+ 	    "Async done-%s res %x mb[1]=%x mb[2]=%x \n",
+ 	    sp->name, res, sp->u.iocb_cmd.u.mbx.in_mb[1],
+ 	    sp->u.iocb_cmd.u.mbx.in_mb[2]);
+ 
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.sp = sp;
+ 	ea.rc = res;
+ 	ea.event = FCME_GNL_DONE;
+ 
+ 	if (sp->u.iocb_cmd.u.mbx.in_mb[1] >=
+ 	    sizeof(struct get_name_list_extended)) {
+ 		n = sp->u.iocb_cmd.u.mbx.in_mb[1] /
+ 		    sizeof(struct get_name_list_extended);
+ 		ea.data[0] = sp->u.iocb_cmd.u.mbx.in_mb[1]; /* amnt xfered */
+ 	}
+ 
+ 	for (i = 0; i < n; i++) {
+ 		e = &vha->gnl.l[i];
+ 		loop_id = le16_to_cpu(e->nport_handle);
+ 		/* mask out reserve bit */
+ 		loop_id = (loop_id & 0x7fff);
+ 		set_bit(loop_id, vha->hw->loop_id_map);
+ 		wwn = wwn_to_u64(e->port_name);
+ 
+ 		ql_dbg(ql_dbg_disc + ql_dbg_verbose, vha, 0x20e8,
+ 		    "%s %8phC %02x:%02x:%02x state %d/%d lid %x \n",
+ 		    __func__, (void *)&wwn, e->port_id[2], e->port_id[1],
+ 		    e->port_id[0], e->current_login_state, e->last_login_state,
+ 		    (loop_id & 0x7fff));
+ 	}
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 	vha->gnl.sent = 0;
+ 
+ 	INIT_LIST_HEAD(&h);
+ 	fcport = tf = NULL;
+ 	if (!list_empty(&vha->gnl.fcports))
+ 		list_splice_init(&vha->gnl.fcports, &h);
+ 
+ 	list_for_each_entry_safe(fcport, tf, &h, gnl_entry) {
+ 		list_del_init(&fcport->gnl_entry);
+ 		fcport->flags &= ~FCF_ASYNC_SENT;
+ 		ea.fcport = fcport;
+ 
+ 		qla2x00_fcport_event_handler(vha, &ea);
+ 	}
+ 
+ 	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_gnl(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	srb_t *sp;
+ 	struct srb_iocb *mbx;
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	unsigned long flags;
+ 	u16 *mb;
+ 
+ 	if (!vha->flags.online)
+ 		goto done;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20d9,
+ 	    "Async-gnlist WWPN %8phC \n", fcport->port_name);
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	fcport->disc_state = DSC_GNL;
+ 	fcport->last_rscn_gen = fcport->rscn_gen;
+ 	fcport->last_login_gen = fcport->login_gen;
+ 
+ 	list_add_tail(&fcport->gnl_entry, &vha->gnl.fcports);
+ 	if (vha->gnl.sent) {
+ 		spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 		rval = QLA_SUCCESS;
+ 		goto done;
+ 	}
+ 	vha->gnl.sent = 1;
+ 	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		goto done;
+ 	sp->type = SRB_MB_IOCB;
+ 	sp->name = "gnlist";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha)+2);
+ 
+ 	mb = sp->u.iocb_cmd.u.mbx.out_mb;
+ 	mb[0] = MBC_PORT_NODE_NAME_LIST;
+ 	mb[1] = BIT_2 | BIT_3;
+ 	mb[2] = MSW(vha->gnl.ldma);
+ 	mb[3] = LSW(vha->gnl.ldma);
+ 	mb[6] = MSW(MSD(vha->gnl.ldma));
+ 	mb[7] = LSW(MSD(vha->gnl.ldma));
+ 	mb[8] = vha->gnl.size;
+ 	mb[9] = vha->vp_idx;
+ 
+ 	mbx = &sp->u.iocb_cmd;
+ 	mbx->timeout = qla2x00_async_iocb_timeout;
+ 
+ 	sp->done = qla24xx_async_gnl_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20da,
+ 	    "Async-%s - OUT WWPN %8phC hndl %x\n",
+ 	    sp->name, fcport->port_name, sp->handle);
+ 
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ done:
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gnl_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GNL);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ static
+ void qla24xx_async_gpdb_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	struct port_database_24xx *pd;
+ 	fc_port_t *fcport = sp->fcport;
+ 	u16 *mb = sp->u.iocb_cmd.u.mbx.in_mb;
+ 	int rval = QLA_SUCCESS;
+ 	struct event_arg ea;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20db,
+ 	    "Async done-%s res %x, WWPN %8phC mb[1]=%x mb[2]=%x \n",
+ 	    sp->name, res, fcport->port_name, mb[1], mb[2]);
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 
+ 	if (res) {
+ 		rval = res;
+ 		goto gpd_error_out;
+ 	}
+ 
+ 	pd = (struct port_database_24xx *)sp->u.iocb_cmd.u.mbx.in;
+ 
+ 	rval = __qla24xx_parse_gpdb(vha, fcport, pd);
+ 
+ gpd_error_out:
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.event = FCME_GPDB_DONE;
+ 	ea.rc = rval;
+ 	ea.fcport = fcport;
+ 	ea.sp = sp;
+ 
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	dma_pool_free(ha->s_dma_pool, sp->u.iocb_cmd.u.mbx.in,
+ 		sp->u.iocb_cmd.u.mbx.in_dma);
+ 
+ 	sp->free(sp);
+ }
+ 
+ static int qla24xx_post_gpdb_work(struct scsi_qla_host *vha, fc_port_t *fcport,
+     u8 opt)
+ {
+ 	struct qla_work_evt *e;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GPDB);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	e->u.fcport.opt = opt;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ int qla24xx_async_gpdb(struct scsi_qla_host *vha, fc_port_t *fcport, u8 opt)
+ {
+ 	srb_t *sp;
+ 	struct srb_iocb *mbx;
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	u16 *mb;
+ 	dma_addr_t pd_dma;
+ 	struct port_database_24xx *pd;
+ 	struct qla_hw_data *ha = vha->hw;
+ 
+ 	if (!vha->flags.online)
+ 		goto done;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	fcport->disc_state = DSC_GPDB;
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	pd = dma_pool_alloc(ha->s_dma_pool, GFP_KERNEL, &pd_dma);
+ 	if (pd == NULL) {
+ 		ql_log(ql_log_warn, vha, 0xd043,
+ 		    "Failed to allocate port database structure.\n");
+ 		goto done_free_sp;
+ 	}
+ 	memset(pd, 0, max(PORT_DATABASE_SIZE, PORT_DATABASE_24XX_SIZE));
+ 
+ 	sp->type = SRB_MB_IOCB;
+ 	sp->name = "gpdb";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	mb = sp->u.iocb_cmd.u.mbx.out_mb;
+ 	mb[0] = MBC_GET_PORT_DATABASE;
+ 	mb[1] = fcport->loop_id;
+ 	mb[2] = MSW(pd_dma);
+ 	mb[3] = LSW(pd_dma);
+ 	mb[6] = MSW(MSD(pd_dma));
+ 	mb[7] = LSW(MSD(pd_dma));
+ 	mb[9] = vha->vp_idx;
+ 	mb[10] = opt;
+ 
+ 	mbx = &sp->u.iocb_cmd;
+ 	mbx->timeout = qla2x00_async_iocb_timeout;
+ 	mbx->u.mbx.in = (void *)pd;
+ 	mbx->u.mbx.in_dma = pd_dma;
+ 
+ 	sp->done = qla24xx_async_gpdb_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20dc,
+ 	    "Async-%s %8phC hndl %x opt %x\n",
+ 	    sp->name, fcport->port_name, sp->handle, opt);
+ 
+ 	return rval;
+ 
+ done_free_sp:
+ 	if (pd)
+ 		dma_pool_free(ha->s_dma_pool, pd, pd_dma);
+ 
+ 	sp->free(sp);
+ done:
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	qla24xx_post_gpdb_work(vha, fcport, opt);
+ 	return rval;
+ }
+ 
+ static
+ void qla24xx_handle_gpdb_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	int rval = ea->rc;
+ 	fc_port_t *fcport = ea->fcport;
+ 	unsigned long flags;
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20d2,
+ 	    "%s %8phC DS %d LS %d rval %d\n", __func__, fcport->port_name,
+ 	    fcport->disc_state, fcport->fw_login_state, rval);
+ 
+ 	if (ea->sp->gen2 != fcport->login_gen) {
+ 		/* target side must have changed it. */
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d3,
+ 		    "%s %8phC generation changed rscn %d|%d login %d|%d \n",
+ 		    __func__, fcport->port_name, fcport->last_rscn_gen,
+ 		    fcport->rscn_gen, fcport->last_login_gen,
+ 		    fcport->login_gen);
+ 		return;
+ 	} else if (ea->sp->gen1 != fcport->rscn_gen) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d4, "%s %d %8phC post gidpn\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 		qla24xx_post_gidpn_work(vha, fcport);
+ 		return;
+ 	}
+ 
+ 	if (rval != QLA_SUCCESS) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d5, "%s %d %8phC post del sess\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 		qlt_schedule_sess_for_deletion_lock(fcport);
+ 		return;
+ 	}
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 	ea->fcport->login_gen++;
+ 	ea->fcport->deleted = 0;
+ 	ea->fcport->logout_on_delete = 1;
+ 
+ 	if (!ea->fcport->login_succ && !IS_SW_RESV_ADDR(ea->fcport->d_id)) {
+ 		vha->fcport_count++;
+ 		ea->fcport->login_succ = 1;
+ 
+ 		if (!IS_IIDMA_CAPABLE(vha->hw) ||
+ 		    !vha->hw->flags.gpsc_supported) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20d6,
+ 			    "%s %d %8phC post upd_fcport fcp_cnt %d\n",
+ 			    __func__, __LINE__, fcport->port_name,
+ 			    vha->fcport_count);
+ 
+ 			qla24xx_post_upd_fcport_work(vha, fcport);
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20d7,
+ 			    "%s %d %8phC post gpsc fcp_cnt %d\n",
+ 			    __func__, __LINE__, fcport->port_name,
+ 			    vha->fcport_count);
+ 
+ 			qla24xx_post_gpsc_work(vha, fcport);
+ 		}
+ 	}
+ 	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ } /* gpdb event */
+ 
+ int qla24xx_fcport_handle_login(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	if (fcport->login_retry == 0)
+ 		return 0;
+ 
+ 	if (fcport->scan_state != QLA_FCPORT_FOUND)
+ 		return 0;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20d8,
+ 	    "%s %8phC DS %d LS %d P %d fl %x confl %p rscn %d|%d login %d|%d retry %d lid %d\n",
+ 	    __func__, fcport->port_name, fcport->disc_state,
+ 	    fcport->fw_login_state, fcport->login_pause, fcport->flags,
+ 	    fcport->conflict, fcport->last_rscn_gen, fcport->rscn_gen,
+ 	    fcport->last_login_gen, fcport->login_gen, fcport->login_retry,
+ 	    fcport->loop_id);
+ 
+ 	fcport->login_retry--;
+ 
+ 	if ((fcport->fw_login_state == DSC_LS_PLOGI_PEND) ||
+ 	    (fcport->fw_login_state == DSC_LS_PRLI_PEND))
+ 		return 0;
+ 
+ 	if (fcport->fw_login_state == DSC_LS_PLOGI_COMP) {
+ 		if (time_before_eq(jiffies, fcport->plogi_nack_done_deadline))
+ 			return 0;
+ 	}
+ 
+ 	/* for pure Target Mode. Login will not be initiated */
+ 	if (vha->host->active_mode == MODE_TARGET)
+ 		return 0;
+ 
+ 	if (fcport->flags & FCF_ASYNC_SENT) {
+ 		set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
+ 		return 0;
+ 	}
+ 
+ 	switch (fcport->disc_state) {
+ 	case DSC_DELETED:
+ 		if (fcport->loop_id == FC_NO_LOOP_ID) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20bd,
+ 			    "%s %d %8phC post gnl\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			qla24xx_async_gnl(vha, fcport);
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20bf,
+ 			    "%s %d %8phC post login\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			fcport->disc_state = DSC_LOGIN_PEND;
+ 			qla2x00_post_async_login_work(vha, fcport, NULL);
+ 		}
+ 		break;
+ 
+ 	case DSC_GNL:
+ 		if (fcport->login_pause) {
+ 			fcport->last_rscn_gen = fcport->rscn_gen;
+ 			fcport->last_login_gen = fcport->login_gen;
+ 			set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
+ 			break;
+ 		}
+ 
+ 		if (fcport->flags & FCF_FCP2_DEVICE) {
+ 			u8 opt = PDO_FORCE_ADISC;
+ 
+ 			ql_dbg(ql_dbg_disc, vha, 0x20c9,
+ 			    "%s %d %8phC post gpdb\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 
+ 			fcport->disc_state = DSC_GPDB;
+ 			qla24xx_post_gpdb_work(vha, fcport, opt);
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20cf,
+ 			    "%s %d %8phC post login\n",
+ 			    __func__, __LINE__, fcport->port_name);
+ 			fcport->disc_state = DSC_LOGIN_PEND;
+ 			qla2x00_post_async_login_work(vha, fcport, NULL);
+ 		}
+ 
+ 		break;
+ 
+ 	case DSC_LOGIN_FAILED:
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d0,
+ 		    "%s %d %8phC post gidpn\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 
+ 		qla24xx_post_gidpn_work(vha, fcport);
+ 		break;
+ 
+ 	case DSC_LOGIN_COMPLETE:
+ 		/* recheck login state */
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d1,
+ 		    "%s %d %8phC post gpdb\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 
+ 		qla24xx_post_gpdb_work(vha, fcport, PDO_FORCE_ADISC);
+ 		break;
+ 
+ 	default:
+ 		break;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static
+ void qla24xx_handle_rscn_event(fc_port_t *fcport, struct event_arg *ea)
+ {
+ 	fcport->rscn_gen++;
+ 
+ 	ql_dbg(ql_dbg_disc, fcport->vha, 0x210c,
+ 	    "%s %8phC DS %d LS %d\n",
+ 	    __func__, fcport->port_name, fcport->disc_state,
+ 	    fcport->fw_login_state);
+ 
+ 	if (fcport->flags & FCF_ASYNC_SENT)
+ 		return;
+ 
+ 	switch (fcport->disc_state) {
+ 	case DSC_DELETED:
+ 	case DSC_LOGIN_COMPLETE:
+ 		qla24xx_post_gidpn_work(fcport->vha, fcport);
+ 		break;
+ 
+ 	default:
+ 		break;
+ 	}
+ }
+ 
+ int qla24xx_post_newsess_work(struct scsi_qla_host *vha, port_id_t *id,
+ 	u8 *port_name, void *pla)
+ {
+ 	struct qla_work_evt *e;
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_NEW_SESS);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.new_sess.id = *id;
+ 	e->u.new_sess.pla = pla;
+ 	memcpy(e->u.new_sess.port_name, port_name, WWN_SIZE);
+ 
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ static
+ int qla24xx_handle_delete_done_event(scsi_qla_host_t *vha,
+ 	struct event_arg *ea)
+ {
+ 	fc_port_t *fcport = ea->fcport;
+ 
+ 	if (test_bit(UNLOADING, &vha->dpc_flags))
+ 		return 0;
+ 
+ 	switch (vha->host->active_mode) {
+ 	case MODE_INITIATOR:
+ 	case MODE_DUAL:
+ 		if (fcport->scan_state == QLA_FCPORT_FOUND)
+ 			qla24xx_fcport_handle_login(vha, fcport);
+ 		break;
+ 
+ 	case MODE_TARGET:
+ 	default:
+ 		/* no-op */
+ 		break;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static
+ void qla24xx_handle_relogin_event(scsi_qla_host_t *vha,
+ 	struct event_arg *ea)
+ {
+ 	fc_port_t *fcport = ea->fcport;
+ 
+ 	if (fcport->scan_state != QLA_FCPORT_FOUND) {
+ 		fcport->login_retry++;
+ 		return;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2102,
+ 	    "%s %8phC DS %d LS %d P %d del %d cnfl %p rscn %d|%d login %d|%d fl %x\n",
+ 	    __func__, fcport->port_name, fcport->disc_state,
+ 	    fcport->fw_login_state, fcport->login_pause,
+ 	    fcport->deleted, fcport->conflict,
+ 	    fcport->last_rscn_gen, fcport->rscn_gen,
+ 	    fcport->last_login_gen, fcport->login_gen,
+ 	    fcport->flags);
+ 
+ 	if ((fcport->fw_login_state == DSC_LS_PLOGI_PEND) ||
+ 	    (fcport->fw_login_state == DSC_LS_PRLI_PEND))
+ 		return;
+ 
+ 	if (fcport->fw_login_state == DSC_LS_PLOGI_COMP) {
+ 		if (time_before_eq(jiffies, fcport->plogi_nack_done_deadline))
+ 			return;
+ 	}
+ 
+ 	if (fcport->flags & FCF_ASYNC_SENT) {
+ 		fcport->login_retry++;
+ 		set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
+ 		return;
+ 	}
+ 
+ 	if (fcport->disc_state == DSC_DELETE_PEND) {
+ 		fcport->login_retry++;
+ 		return;
+ 	}
+ 
+ 	if (fcport->last_rscn_gen != fcport->rscn_gen) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20e9, "%s %d %8phC post gidpn\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 
+ 		qla24xx_async_gidpn(vha, fcport);
+ 		return;
+ 	}
+ 
+ 	qla24xx_fcport_handle_login(vha, fcport);
+ }
+ 
+ void qla2x00_fcport_event_handler(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	fc_port_t *fcport, *f, *tf;
+ 	uint32_t id = 0, mask, rid;
+ 	int rc;
+ 
+ 	switch (ea->event) {
+ 	case FCME_RELOGIN:
+ 	case FCME_RSCN:
+ 	case FCME_GIDPN_DONE:
+ 	case FCME_GPSC_DONE:
+ 	case FCME_GPNID_DONE:
+ 		if (test_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags) ||
+ 		    test_bit(LOOP_RESYNC_ACTIVE, &vha->dpc_flags))
+ 			return;
+ 		break;
+ 	default:
+ 		break;
+ 	}
+ 
+ 	switch (ea->event) {
+ 	case FCME_RELOGIN:
+ 		if (test_bit(UNLOADING, &vha->dpc_flags))
+ 			return;
+ 
+ 		qla24xx_handle_relogin_event(vha, ea);
+ 		break;
+ 	case FCME_RSCN:
+ 		if (test_bit(UNLOADING, &vha->dpc_flags))
+ 			return;
+ 		switch (ea->id.b.rsvd_1) {
+ 		case RSCN_PORT_ADDR:
+ 			fcport = qla2x00_find_fcport_by_nportid(vha, &ea->id, 1);
+ 			if (!fcport) {
+ 				/* cable moved */
+ 				rc = qla24xx_post_gpnid_work(vha, &ea->id);
+ 				if (rc) {
+ 					ql_log(ql_log_warn, vha, 0xd044,
+ 					    "RSCN GPNID work failed %02x%02x%02x\n",
+ 					    ea->id.b.domain, ea->id.b.area,
+ 					    ea->id.b.al_pa);
+ 				}
+ 			} else {
+ 				ea->fcport = fcport;
+ 				qla24xx_handle_rscn_event(fcport, ea);
+ 			}
+ 			break;
+ 		case RSCN_AREA_ADDR:
+ 		case RSCN_DOM_ADDR:
+ 			if (ea->id.b.rsvd_1 == RSCN_AREA_ADDR) {
+ 				mask = 0xffff00;
+ 				ql_dbg(ql_dbg_async, vha, 0x5044,
+ 				    "RSCN: Area 0x%06x was affected\n",
+ 				    ea->id.b24);
+ 			} else {
+ 				mask = 0xff0000;
+ 				ql_dbg(ql_dbg_async, vha, 0x507a,
+ 				    "RSCN: Domain 0x%06x was affected\n",
+ 				    ea->id.b24);
+ 			}
+ 
+ 			rid = ea->id.b24 & mask;
+ 			list_for_each_entry_safe(f, tf, &vha->vp_fcports,
+ 			    list) {
+ 				id = f->d_id.b24 & mask;
+ 				if (rid == id) {
+ 					ea->fcport = f;
+ 					qla24xx_handle_rscn_event(f, ea);
+ 				}
+ 			}
+ 			break;
+ 		case RSCN_FAB_ADDR:
+ 		default:
+ 			ql_log(ql_log_warn, vha, 0xd045,
+ 			    "RSCN: Fabric was affected. Addr format %d\n",
+ 			    ea->id.b.rsvd_1);
+ 			qla2x00_mark_all_devices_lost(vha, 1);
+ 			set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 			set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 		}
+ 		break;
+ 	case FCME_GIDPN_DONE:
+ 		qla24xx_handle_gidpn_event(vha, ea);
+ 		break;
+ 	case FCME_GNL_DONE:
+ 		qla24xx_handle_gnl_done_event(vha, ea);
+ 		break;
+ 	case FCME_GPSC_DONE:
+ 		qla24xx_post_upd_fcport_work(vha, ea->fcport);
+ 		break;
+ 	case FCME_PLOGI_DONE:	/* Initiator side sent LLIOCB */
+ 		qla24xx_handle_plogi_done_event(vha, ea);
+ 		break;
+ 	case FCME_GPDB_DONE:
+ 		qla24xx_handle_gpdb_event(vha, ea);
+ 		break;
+ 	case FCME_GPNID_DONE:
+ 		qla24xx_handle_gpnid_event(vha, ea);
+ 		break;
+ 	case FCME_DELETE_DONE:
+ 		qla24xx_handle_delete_done_event(vha, ea);
+ 		break;
+ 	default:
+ 		BUG_ON(1);
+ 		break;
+ 	}
+ }
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  static void
  qla2x00_tmf_iocb_timeout(void *data)
  {
@@@ -452,46 -1319,53 +1297,96 @@@ qla2x00_async_login_done(struct scsi_ql
  		 * force a relogin attempt via implicit LOGO, PLOGI, and PRLI
  		 * requests.
  		 */
++<<<<<<< HEAD
 +		rval = qla2x00_get_port_database(vha, fcport, 0);
 +		if (rval == QLA_NOT_LOGGED_IN) {
 +			fcport->flags &= ~FCF_ASYNC_SENT;
 +			fcport->flags |= FCF_LOGIN_NEEDED;
 +			set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
 +			break;
 +		}
 +
 +		if (rval != QLA_SUCCESS) {
 +			qla2x00_post_async_logout_work(vha, fcport, NULL);
 +			qla2x00_post_async_login_work(vha, fcport, NULL);
 +			break;
 +		}
 +		if (fcport->flags & FCF_FCP2_DEVICE) {
 +			qla2x00_post_async_adisc_work(vha, fcport, data);
 +			break;
 +		}
 +		qla2x00_update_fcport(vha, fcport);
 +		break;
 +	case MBS_COMMAND_ERROR:
 +		fcport->flags &= ~FCF_ASYNC_SENT;
 +		if (data[1] & QLA_LOGIO_LOGIN_RETRIED)
 +			set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
 +		else
 +			qla2x00_mark_device_lost(vha, fcport, 1, 0);
 +		break;
 +	case MBS_PORT_ID_USED:
 +		fcport->loop_id = data[1];
 +		qla2x00_post_async_logout_work(vha, fcport, NULL);
 +		qla2x00_post_async_login_work(vha, fcport, NULL);
 +		break;
 +	case MBS_LOOP_ID_USED:
 +		fcport->loop_id++;
 +		rval = qla2x00_find_new_loop_id(vha, fcport);
 +		if (rval != QLA_SUCCESS) {
 +			fcport->flags &= ~FCF_ASYNC_SENT;
 +			qla2x00_mark_device_lost(vha, fcport, 1, 0);
 +			break;
 +		}
 +		qla2x00_post_async_login_work(vha, fcport, NULL);
++=======
+ 		ql_dbg(ql_dbg_disc, vha, 0x20ea,
+ 		    "%s %d %8phC post gpdb\n",
+ 		    __func__, __LINE__, ea->fcport->port_name);
+ 		ea->fcport->chip_reset = vha->hw->chip_reset;
+ 		ea->fcport->logout_on_delete = 1;
+ 		qla24xx_post_gpdb_work(vha, ea->fcport, 0);
+ 		break;
+ 	case MBS_COMMAND_ERROR:
+ 		ql_dbg(ql_dbg_disc, vha, 0x20eb, "%s %d %8phC cmd error %x\n",
+ 		    __func__, __LINE__, ea->fcport->port_name, ea->data[1]);
+ 
+ 		ea->fcport->flags &= ~FCF_ASYNC_SENT;
+ 		ea->fcport->disc_state = DSC_LOGIN_FAILED;
+ 		if (ea->data[1] & QLA_LOGIO_LOGIN_RETRIED)
+ 			set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
+ 		else
+ 			qla2x00_mark_device_lost(vha, ea->fcport, 1, 0);
+ 		break;
+ 	case MBS_LOOP_ID_USED:
+ 		/* data[1] = IO PARAM 1 = nport ID  */
+ 		cid.b.domain = (ea->iop[1] >> 16) & 0xff;
+ 		cid.b.area   = (ea->iop[1] >>  8) & 0xff;
+ 		cid.b.al_pa  = ea->iop[1] & 0xff;
+ 		cid.b.rsvd_1 = 0;
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0x20ec,
+ 		    "%s %d %8phC LoopID 0x%x in use post gnl\n",
+ 		    __func__, __LINE__, ea->fcport->port_name,
+ 		    ea->fcport->loop_id);
+ 
+ 		if (IS_SW_RESV_ADDR(cid)) {
+ 			set_bit(ea->fcport->loop_id, vha->hw->loop_id_map);
+ 			ea->fcport->loop_id = FC_NO_LOOP_ID;
+ 		} else {
+ 			qla2x00_clear_loop_id(ea->fcport);
+ 		}
+ 		qla24xx_post_gnl_work(vha, ea->fcport);
+ 		break;
+ 	case MBS_PORT_ID_USED:
+ 		ql_dbg(ql_dbg_disc, vha, 0x20ed,
+ 		    "%s %d %8phC NPortId %02x%02x%02x inuse post gidpn\n",
+ 		    __func__, __LINE__, ea->fcport->port_name,
+ 		    ea->fcport->d_id.b.domain, ea->fcport->d_id.b.area,
+ 		    ea->fcport->d_id.b.al_pa);
+ 
+ 		qla2x00_clear_loop_id(ea->fcport);
+ 		qla24xx_post_gidpn_work(vha, ea->fcport);
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  		break;
  	}
  	return;
@@@ -2076,14 -2959,24 +2971,25 @@@ qla24xx_update_fw_options(scsi_qla_host
  			__func__, ha->fw_options[2]);
  	}
  
 -	/* Move PUREX, ABTS RX & RIDA to ATIOQ */
 -	if (ql2xmvasynctoatio &&
 -	    (IS_QLA83XX(ha) || IS_QLA27XX(ha))) {
 -		if (qla_tgt_mode_enabled(vha) ||
 -		    qla_dual_mode_enabled(vha))
 -			ha->fw_options[2] |= BIT_11;
 -		else
 -			ha->fw_options[2] &= ~BIT_11;
 +	/* Set Retry FLOGI in case of P2P connection */
 +	if (ha->operating_mode == P2P) {
 +		ha->fw_options[2] |= BIT_3;
 +		ql_dbg(ql_dbg_disc, vha, 0x2101,
 +		    "(%s): Setting FLOGI retry BIT in fw_options[2]: 0x%x\n",
 +			__func__, ha->fw_options[2]);
  	}
  
++<<<<<<< HEAD
++=======
+ 	ql_dbg(ql_dbg_init, vha, 0x00e8,
+ 	    "%s, add FW options 1-3 = 0x%04x 0x%04x 0x%04x mode %x\n",
+ 	    __func__, ha->fw_options[1], ha->fw_options[2],
+ 	    ha->fw_options[3], vha->host->active_mode);
+ 
+ 	if (ha->fw_options[1] || ha->fw_options[2] || ha->fw_options[3])
+ 		qla2x00_set_fw_options(vha, ha->fw_options);
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	/* Update Serial Link options. */
  	if ((le16_to_cpu(ha->fw_seriallink_options24[0]) & BIT_0) == 0)
  		return;
@@@ -2966,12 -3857,12 +3872,20 @@@ qla2x00_rport_del(void *data
  	fcport->drport = NULL;
  	spin_unlock_irqrestore(fcport->vha->host->host_lock, flags);
  	if (rport) {
++<<<<<<< HEAD
++=======
+ 		ql_dbg(ql_dbg_disc, fcport->vha, 0x210b,
+ 		    "%s %8phN. rport %p roles %x\n",
+ 		    __func__, fcport->port_name, rport,
+ 		    rport->roles);
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  		fc_remote_port_delete(rport);
 +		/*
 +		 * Release the target mode FC NEXUS in qla_target.c code
 +		 * if target mod is enabled.
 +		 */
 +		qlt_fc_port_deleted(vha, fcport);
  	}
  }
  
@@@ -2998,6 -3889,26 +3912,29 @@@ qla2x00_alloc_fcport(scsi_qla_host_t *v
  	qla2x00_set_fcport_state(fcport, FCS_UNCONFIGURED);
  	fcport->supported_classes = FC_COS_UNSPECIFIED;
  
++<<<<<<< HEAD
++=======
+ 	fcport->ct_desc.ct_sns = dma_alloc_coherent(&vha->hw->pdev->dev,
+ 		sizeof(struct ct_sns_pkt), &fcport->ct_desc.ct_sns_dma,
+ 		flags);
+ 	fcport->disc_state = DSC_DELETED;
+ 	fcport->fw_login_state = DSC_LS_PORT_UNAVAIL;
+ 	fcport->deleted = QLA_SESS_DELETED;
+ 	fcport->login_retry = vha->hw->login_retry_count;
+ 	fcport->login_retry = 5;
+ 	fcport->logout_on_delete = 1;
+ 
+ 	if (!fcport->ct_desc.ct_sns) {
+ 		ql_log(ql_log_warn, vha, 0xd049,
+ 		    "Failed to allocate ct_sns request.\n");
+ 		kfree(fcport);
+ 		fcport = NULL;
+ 	}
+ 	INIT_WORK(&fcport->del_work, qla24xx_delete_sess_fn);
+ 	INIT_LIST_HEAD(&fcport->gnl_entry);
+ 	INIT_LIST_HEAD(&fcport->list);
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	return fcport;
  }
  
@@@ -3220,9 -4168,10 +4157,9 @@@ qla2x00_configure_local_loop(scsi_qla_h
  		new_fcport->d_id.b.area = area;
  		new_fcport->d_id.b.al_pa = al_pa;
  		new_fcport->loop_id = loop_id;
 -
  		rval2 = qla2x00_get_port_database(vha, new_fcport, 0);
  		if (rval2 != QLA_SUCCESS) {
- 			ql_dbg(ql_dbg_disc, vha, 0x201a,
+ 			ql_dbg(ql_dbg_disc, vha, 0x2097,
  			    "Failed to retrieve fcport information "
  			    "-- get_port_database=%x, loop_id=0x%04x.\n",
  			    rval2, new_fcport->loop_id);
@@@ -3257,9 -4213,18 +4194,9 @@@
  
  			/* Allocate a new replacement fcport. */
  			fcport = new_fcport;
 -			if (!fcport->login_succ) {
 -				vha->fcport_count++;
 -				fcport->login_succ = 1;
 -				fcport->disc_state = DSC_LOGIN_COMPLETE;
 -			}
 -
 -			spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
 -
  			new_fcport = qla2x00_alloc_fcport(vha, GFP_KERNEL);
 -
  			if (new_fcport == NULL) {
- 				ql_log(ql_log_warn, vha, 0x201c,
+ 				ql_log(ql_log_warn, vha, 0xd031,
  				    "Failed to allocate memory for fcport.\n");
  				rval = QLA_MEMORY_ALLOC_FAILED;
  				goto cleanup_allocation;
@@@ -3352,6 -4316,12 +4289,15 @@@ qla2x00_reg_remote_port(scsi_qla_host_
  		rport_ids.roles |= FC_RPORT_ROLE_FCP_INITIATOR;
  	if (fcport->port_type == FCT_TARGET)
  		rport_ids.roles |= FC_RPORT_ROLE_FCP_TARGET;
++<<<<<<< HEAD
++=======
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20ee,
+ 	    "%s %8phN. rport %p is %s mode\n",
+ 	    __func__, fcport->port_name, rport,
+ 	    (fcport->port_type == FCT_TARGET) ? "tgt" : "ini");
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	fc_remote_port_rolechg(rport, rport_ids.roles);
  }
  
@@@ -3375,10 -4345,15 +4321,19 @@@ qla2x00_update_fcport(scsi_qla_host_t *
  {
  	fcport->vha = vha;
  
++<<<<<<< HEAD
++=======
+ 	if (IS_SW_RESV_ADDR(fcport->d_id))
+ 		return;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20ef, "%s %8phC\n",
+ 	    __func__, fcport->port_name);
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	if (IS_QLAFX00(vha->hw)) {
  		qla2x00_set_fcport_state(fcport, FCS_ONLINE);
 -		goto reg_port;
 +		qla2x00_reg_remote_port(vha, fcport);
 +		return;
  	}
  	fcport->login_retry = 0;
  	fcport->flags &= ~(FCF_LOGIN_NEEDED | FCF_ASYNC_SENT);
@@@ -3455,22 -4463,33 +4410,22 @@@ qla2x00_configure_fabric(scsi_qla_host_
  		if (test_and_clear_bit(REGISTER_FC4_NEEDED, &vha->dpc_flags)) {
  			if (qla2x00_rft_id(vha)) {
  				/* EMPTY */
- 				ql_dbg(ql_dbg_disc, vha, 0x2045,
+ 				ql_dbg(ql_dbg_disc, vha, 0x20a2,
  				    "Register FC-4 TYPE failed.\n");
 -				if (test_bit(LOOP_RESYNC_NEEDED,
 -				    &vha->dpc_flags))
 -					break;
  			}
  			if (qla2x00_rff_id(vha)) {
  				/* EMPTY */
- 				ql_dbg(ql_dbg_disc, vha, 0x2049,
+ 				ql_dbg(ql_dbg_disc, vha, 0x209a,
  				    "Register FC-4 Features failed.\n");
 -				if (test_bit(LOOP_RESYNC_NEEDED,
 -				    &vha->dpc_flags))
 -					break;
  			}
  			if (qla2x00_rnn_id(vha)) {
  				/* EMPTY */
- 				ql_dbg(ql_dbg_disc, vha, 0x204f,
+ 				ql_dbg(ql_dbg_disc, vha, 0x2104,
  				    "Register Node Name failed.\n");
 -				if (test_bit(LOOP_RESYNC_NEEDED,
 -				    &vha->dpc_flags))
 -					break;
  			} else if (qla2x00_rsnn_nn(vha)) {
  				/* EMPTY */
- 				ql_dbg(ql_dbg_disc, vha, 0x2053,
+ 				ql_dbg(ql_dbg_disc, vha, 0x209b,
  				    "Register Symobilic Node Name failed.\n");
 -				if (test_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags))
 -					break;
  			}
  		}
  
@@@ -3694,14 -4636,9 +4649,14 @@@ qla2x00_find_all_fabric_devs(scsi_qla_h
  			/* Send GA_NXT to the switch */
  			rval = qla2x00_ga_nxt(vha, new_fcport);
  			if (rval != QLA_SUCCESS) {
- 				ql_log(ql_log_warn, vha, 0x2064,
+ 				ql_log(ql_log_warn, vha, 0x209e,
  				    "SNS scan failed -- assuming "
  				    "zero-entry result.\n");
 +				list_for_each_entry_safe(fcport, fcptemp,
 +				    new_fcports, list) {
 +					list_del(&fcport->list);
 +					kfree(fcport);
 +				}
  				rval = QLA_SUCCESS;
  				break;
  			}
@@@ -3818,8 -4769,44 +4773,47 @@@
  		new_fcport->d_id.b24 = nxt_d_id.b24;
  	}
  
 -	qla2x00_free_fcport(new_fcport);
 +	kfree(new_fcport);
  
++<<<<<<< HEAD
++=======
+ 	/*
+ 	 * Logout all previous fabric dev marked lost, except FCP2 devices.
+ 	 */
+ 	list_for_each_entry(fcport, &vha->vp_fcports, list) {
+ 		if (test_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags))
+ 			break;
+ 
+ 		if ((fcport->flags & FCF_FABRIC_DEVICE) == 0 ||
+ 		    (fcport->flags & FCF_LOGIN_NEEDED) == 0)
+ 			continue;
+ 
+ 		if (fcport->scan_state == QLA_FCPORT_SCAN) {
+ 			if ((qla_dual_mode_enabled(vha) ||
+ 			    qla_ini_mode_enabled(vha)) &&
+ 			    atomic_read(&fcport->state) == FCS_ONLINE) {
+ 				qla2x00_mark_device_lost(vha, fcport,
+ 					ql2xplogiabsentdevice, 0);
+ 				if (fcport->loop_id != FC_NO_LOOP_ID &&
+ 				    (fcport->flags & FCF_FCP2_DEVICE) == 0 &&
+ 				    fcport->port_type != FCT_INITIATOR &&
+ 				    fcport->port_type != FCT_BROADCAST) {
+ 					ql_dbg(ql_dbg_disc, vha, 0x20f0,
+ 					    "%s %d %8phC post del sess\n",
+ 					    __func__, __LINE__,
+ 					    fcport->port_name);
+ 
+ 					qlt_schedule_sess_for_deletion_lock
+ 						(fcport);
+ 					continue;
+ 				}
+ 			}
+ 		}
+ 
+ 		if (fcport->scan_state == QLA_FCPORT_FOUND)
+ 			qla24xx_fcport_handle_login(vha, fcport);
+ 	}
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	return (rval);
  }
  
@@@ -6416,21 -7352,26 +7410,34 @@@ qla81xx_update_fw_options(scsi_qla_host
  			__func__, ha->fw_options[2]);
  	}
  
 -	/* Move PUREX, ABTS RX & RIDA to ATIOQ */
 -	if (ql2xmvasynctoatio) {
 -		if (qla_tgt_mode_enabled(vha) ||
 -		    qla_dual_mode_enabled(vha))
 -			ha->fw_options[2] |= BIT_11;
 -		else
 -			ha->fw_options[2] &= ~BIT_11;
 +	/* Set Retry FLOGI in case of P2P connection */
 +	if (ha->operating_mode == P2P) {
 +		ha->fw_options[2] |= BIT_3;
 +		ql_dbg(ql_dbg_disc, vha, 0x2103,
 +		    "(%s): Setting FLOGI retry BIT in fw_options[2]: 0x%x\n",
 +			__func__, ha->fw_options[2]);
  	}
  
++<<<<<<< HEAD
 +	if (!ql2xetsenable)
 +		goto out;
++=======
+ 	if (ql2xetsenable) {
+ 		/* Enable ETS Burst. */
+ 		memset(ha->fw_options, 0, sizeof(ha->fw_options));
+ 		ha->fw_options[2] |= BIT_9;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_init, vha, 0x00e9,
+ 	    "%s, add FW options 1-3 = 0x%04x 0x%04x 0x%04x mode %x\n",
+ 	    __func__, ha->fw_options[1], ha->fw_options[2],
+ 	    ha->fw_options[3], vha->host->active_mode);
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  
 +	/* Enable ETS Burst. */
 +	memset(ha->fw_options, 0, sizeof(ha->fw_options));
 +	ha->fw_options[2] |= BIT_9;
 +out:
  	qla2x00_set_fw_options(vha, ha->fw_options);
  }
  
diff --cc drivers/scsi/qla2xxx/qla_isr.c
index d71223f09c1c,2984abcc29e7..000000000000
--- a/drivers/scsi/qla2xxx/qla_isr.c
+++ b/drivers/scsi/qla2xxx/qla_isr.c
@@@ -1571,6 -1704,32 +1571,35 @@@ qla24xx_logio_entry(scsi_qla_host_t *vh
  	case LSC_SCODE_NPORT_USED:
  		data[0] = MBS_LOOP_ID_USED;
  		break;
++<<<<<<< HEAD
++=======
+ 	case LSC_SCODE_CMD_FAILED:
+ 		if (iop[1] == 0x0606) {
+ 			/*
+ 			 * PLOGI/PRLI Completed. We must have Recv PLOGI/PRLI,
+ 			 * Target side acked.
+ 			 */
+ 			data[0] = MBS_COMMAND_COMPLETE;
+ 			goto logio_done;
+ 		}
+ 		data[0] = MBS_COMMAND_ERROR;
+ 		break;
+ 	case LSC_SCODE_NOXCB:
+ 		vha->hw->exch_starvation++;
+ 		if (vha->hw->exch_starvation > 5) {
+ 			ql_log(ql_log_warn, vha, 0xd046,
+ 			    "Exchange starvation. Resetting RISC\n");
+ 
+ 			vha->hw->exch_starvation = 0;
+ 
+ 			if (IS_P3P_TYPE(vha->hw))
+ 				set_bit(FCOE_CTX_RESET_NEEDED, &vha->dpc_flags);
+ 			else
+ 				set_bit(ISP_ABORT_NEEDED, &vha->dpc_flags);
+ 			qla2xxx_wake_dpc(vha);
+ 		}
+ 		/* drop through */
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	default:
  		data[0] = MBS_COMMAND_ERROR;
  		break;
diff --cc drivers/scsi/qla2xxx/qla_mbx.c
index 21eee93873e8,5e74600b99c2..000000000000
--- a/drivers/scsi/qla2xxx/qla_mbx.c
+++ b/drivers/scsi/qla2xxx/qla_mbx.c
@@@ -101,12 -123,13 +101,19 @@@ qla2x00_mailbox_command(scsi_qla_host_
  		return QLA_FUNCTION_TIMEOUT;
  	}
  
++<<<<<<< HEAD
 +	 /* if PCI error, then avoid mbx processing.*/
 +	 if (test_bit(PCI_ERR, &base_vha->dpc_flags)) {
 +		ql_log(ql_log_warn, vha, 0x1191,
++=======
+ 	/* if PCI error, then avoid mbx processing.*/
+ 	if (test_bit(PFLG_DISCONNECTED, &base_vha->dpc_flags) &&
+ 	    test_bit(UNLOADING, &base_vha->dpc_flags)) {
+ 		ql_log(ql_log_warn, vha, 0xd04e,
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  		    "PCI error, exiting.\n");
  		return QLA_FUNCTION_TIMEOUT;
 -	}
 +	 }
  
  	reg = ha->iobase;
  	io_lock_on = base_vha->flags.init_done;
@@@ -3499,62 -3658,77 +3506,83 @@@ qla24xx_report_id_acquisition(scsi_qla_
  		    rptid_entry->port_id[0]);
  
  		/* buffer to buffer credit flag */
 -		vha->flags.bbcr_enable = (rptid_entry->u.f1.bbcr & 0xf) != 0;
 -
 -		if (rptid_entry->vp_idx == 0) {
 -			if (rptid_entry->vp_status == VP_STAT_COMPL) {
 -				/* FA-WWN is only for physical port */
 -				if (qla_ini_mode_enabled(vha) &&
 -				    ha->flags.fawwpn_enabled &&
 -				    (rptid_entry->u.f1.flags &
 -				     VP_FLAGS_NAME_VALID)) {
 -					memcpy(vha->port_name,
 -					    rptid_entry->u.f1.port_name,
 -					    WWN_SIZE);
 -				}
 +		vha->flags.bbcr_enable = (rptid_entry->bbcr & 0xf) != 0;
  
 -				qlt_update_host_map(vha, id);
 -			}
 +		/* FA-WWN is only for physical port */
 +		if (!vp_idx) {
 +			void *wwpn = ha->init_cb->port_name;
  
 -			set_bit(REGISTER_FC4_NEEDED, &vha->dpc_flags);
 -			set_bit(REGISTER_FDMI_NEEDED, &vha->dpc_flags);
 -		} else {
 -			if (rptid_entry->vp_status != VP_STAT_COMPL &&
 -				rptid_entry->vp_status != VP_STAT_ID_CHG) {
 -				ql_dbg(ql_dbg_mbx, vha, 0x10ba,
 -				    "Could not acquire ID for VP[%d].\n",
 -				    rptid_entry->vp_idx);
 -				return;
 +			if (!MSB(stat)) {
 +				if (rptid_entry->vp_idx_map[1] & BIT_6)
 +					wwpn = rptid_entry->reserved_4 + 8;
  			}
 +			memcpy(vha->port_name, wwpn, WWN_SIZE);
 +			fc_host_port_name(vha->host) =
 +			    wwn_to_u64(vha->port_name);
 +			ql_dbg(ql_dbg_mbx, vha, 0x1018,
 +			    "FA-WWN portname %016llx (%x)\n",
 +			    fc_host_port_name(vha->host), MSB(stat));
 +		}
  
 -			found = 0;
 -			spin_lock_irqsave(&ha->vport_slock, flags);
 -			list_for_each_entry(vp, &ha->vp_list, list) {
 -				if (rptid_entry->vp_idx == vp->vp_idx) {
 -					found = 1;
 -					break;
 -				}
 +		vp = vha;
 +		if (vp_idx == 0)
 +			goto reg_needed;
 +
 +		if (MSB(stat) != 0 && MSB(stat) != 2) {
 +			ql_dbg(ql_dbg_mbx, vha, 0x10ba,
 +			    "Could not acquire ID for VP[%d].\n", vp_idx);
 +			return;
 +		}
 +
 +		found = 0;
 +		spin_lock_irqsave(&ha->vport_slock, flags);
 +		list_for_each_entry(vp, &ha->vp_list, list) {
 +			if (vp_idx == vp->vp_idx) {
 +				found = 1;
 +				break;
  			}
 -			spin_unlock_irqrestore(&ha->vport_slock, flags);
 +		}
 +		spin_unlock_irqrestore(&ha->vport_slock, flags);
  
 -			if (!found)
 -				return;
 +		if (!found)
 +			return;
  
 -			qlt_update_host_map(vp, id);
 +		vp->d_id.b.domain = rptid_entry->port_id[2];
 +		vp->d_id.b.area =  rptid_entry->port_id[1];
 +		vp->d_id.b.al_pa = rptid_entry->port_id[0];
  
 -			/*
 -			 * Cannot configure here as we are still sitting on the
 -			 * response queue. Handle it in dpc context.
 -			 */
 -			set_bit(VP_IDX_ACQUIRED, &vp->vp_flags);
 -			set_bit(REGISTER_FC4_NEEDED, &vp->dpc_flags);
 -			set_bit(REGISTER_FDMI_NEEDED, &vp->dpc_flags);
 -		}
 +		/*
 +		 * Cannot configure here as we are still sitting on the
 +		 * response queue. Handle it in dpc context.
 +		 */
 +		set_bit(VP_IDX_ACQUIRED, &vp->vp_flags);
 +
 +reg_needed:
 +		set_bit(REGISTER_FC4_NEEDED, &vp->dpc_flags);
 +		set_bit(REGISTER_FDMI_NEEDED, &vp->dpc_flags);
  		set_bit(VP_DPC_NEEDED, &vha->dpc_flags);
  		qla2xxx_wake_dpc(vha);
++<<<<<<< HEAD
++=======
+ 	} else if (rptid_entry->format == 2) {
+ 		ql_dbg(ql_dbg_async, vha, 0x505f,
+ 		    "RIDA: format 2/N2N Primary port id %02x%02x%02x.\n",
+ 		    rptid_entry->port_id[2], rptid_entry->port_id[1],
+ 		    rptid_entry->port_id[0]);
+ 
+ 		ql_dbg(ql_dbg_async, vha, 0x5075,
+ 		    "N2N: Remote WWPN %8phC.\n",
+ 		    rptid_entry->u.f2.port_name);
+ 
+ 		/* N2N.  direct connect */
+ 		vha->d_id.b.domain = rptid_entry->port_id[2];
+ 		vha->d_id.b.area = rptid_entry->port_id[1];
+ 		vha->d_id.b.al_pa = rptid_entry->port_id[0];
+ 
+ 		spin_lock_irqsave(&ha->vport_slock, flags);
+ 		qlt_update_vp_map(vha, SET_AL_PA);
+ 		spin_unlock_irqrestore(&ha->vport_slock, flags);
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	}
  }
  
@@@ -5653,3 -5827,225 +5681,228 @@@ qla26xx_dport_diagnostics(scsi_qla_host
  
  	return rval;
  }
++<<<<<<< HEAD
++=======
+ 
+ static void qla2x00_async_mb_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 
+ 	sp->u.iocb_cmd.u.mbx.rc = res;
+ 
+ 	complete(&sp->u.iocb_cmd.u.mbx.comp);
+ 	/* don't free sp here. Let the caller do the free */
+ }
+ 
+ /*
+  * This mailbox uses the iocb interface to send MB command.
+  * This allows non-critial (non chip setup) command to go
+  * out in parrallel.
+  */
+ int qla24xx_send_mb_cmd(struct scsi_qla_host *vha, mbx_cmd_t *mcp)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	srb_t *sp;
+ 	struct srb_iocb *c;
+ 
+ 	if (!vha->hw->flags.fw_started)
+ 		goto done;
+ 
+ 	sp = qla2x00_get_sp(vha, NULL, GFP_KERNEL);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	sp->type = SRB_MB_IOCB;
+ 	sp->name = mb_to_str(mcp->mb[0]);
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	memcpy(sp->u.iocb_cmd.u.mbx.out_mb, mcp->mb, SIZEOF_IOCB_MB_REG);
+ 
+ 	c = &sp->u.iocb_cmd;
+ 	c->timeout = qla2x00_async_iocb_timeout;
+ 	init_completion(&c->u.mbx.comp);
+ 
+ 	sp->done = qla2x00_async_mb_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS) {
+ 		ql_dbg(ql_dbg_mbx, vha, 0x1018,
+ 		    "%s: %s Failed submission. %x.\n",
+ 		    __func__, sp->name, rval);
+ 		goto done_free_sp;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_mbx, vha, 0x113f, "MB:%s hndl %x submitted\n",
+ 	    sp->name, sp->handle);
+ 
+ 	wait_for_completion(&c->u.mbx.comp);
+ 	memcpy(mcp->mb, sp->u.iocb_cmd.u.mbx.in_mb, SIZEOF_IOCB_MB_REG);
+ 
+ 	rval = c->u.mbx.rc;
+ 	switch (rval) {
+ 	case QLA_FUNCTION_TIMEOUT:
+ 		ql_dbg(ql_dbg_mbx, vha, 0x1140, "%s: %s Timeout. %x.\n",
+ 		    __func__, sp->name, rval);
+ 		break;
+ 	case  QLA_SUCCESS:
+ 		ql_dbg(ql_dbg_mbx, vha, 0x119d, "%s: %s done.\n",
+ 		    __func__, sp->name);
+ 		sp->free(sp);
+ 		break;
+ 	default:
+ 		ql_dbg(ql_dbg_mbx, vha, 0x119e, "%s: %s Failed. %x.\n",
+ 		    __func__, sp->name, rval);
+ 		sp->free(sp);
+ 		break;
+ 	}
+ 
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ done:
+ 	return rval;
+ }
+ 
+ /*
+  * qla24xx_gpdb_wait
+  * NOTE: Do not call this routine from DPC thread
+  */
+ int qla24xx_gpdb_wait(struct scsi_qla_host *vha, fc_port_t *fcport, u8 opt)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	dma_addr_t pd_dma;
+ 	struct port_database_24xx *pd;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	mbx_cmd_t mc;
+ 
+ 	if (!vha->hw->flags.fw_started)
+ 		goto done;
+ 
+ 	pd = dma_pool_alloc(ha->s_dma_pool, GFP_KERNEL, &pd_dma);
+ 	if (pd  == NULL) {
+ 		ql_log(ql_log_warn, vha, 0xd047,
+ 		    "Failed to allocate port database structure.\n");
+ 		goto done_free_sp;
+ 	}
+ 	memset(pd, 0, max(PORT_DATABASE_SIZE, PORT_DATABASE_24XX_SIZE));
+ 
+ 	memset(&mc, 0, sizeof(mc));
+ 	mc.mb[0] = MBC_GET_PORT_DATABASE;
+ 	mc.mb[1] = cpu_to_le16(fcport->loop_id);
+ 	mc.mb[2] = MSW(pd_dma);
+ 	mc.mb[3] = LSW(pd_dma);
+ 	mc.mb[6] = MSW(MSD(pd_dma));
+ 	mc.mb[7] = LSW(MSD(pd_dma));
+ 	mc.mb[9] = cpu_to_le16(vha->vp_idx);
+ 	mc.mb[10] = cpu_to_le16((uint16_t)opt);
+ 
+ 	rval = qla24xx_send_mb_cmd(vha, &mc);
+ 	if (rval != QLA_SUCCESS) {
+ 		ql_dbg(ql_dbg_mbx, vha, 0x1193,
+ 		    "%s: %8phC fail\n", __func__, fcport->port_name);
+ 		goto done_free_sp;
+ 	}
+ 
+ 	rval = __qla24xx_parse_gpdb(vha, fcport, pd);
+ 
+ 	ql_dbg(ql_dbg_mbx, vha, 0x1197, "%s: %8phC done\n",
+ 	    __func__, fcport->port_name);
+ 
+ done_free_sp:
+ 	if (pd)
+ 		dma_pool_free(ha->s_dma_pool, pd, pd_dma);
+ done:
+ 	return rval;
+ }
+ 
+ int __qla24xx_parse_gpdb(struct scsi_qla_host *vha, fc_port_t *fcport,
+     struct port_database_24xx *pd)
+ {
+ 	int rval = QLA_SUCCESS;
+ 	uint64_t zero = 0;
+ 
+ 	/* Check for logged in state. */
+ 	if (pd->current_login_state != PDS_PRLI_COMPLETE &&
+ 		pd->last_login_state != PDS_PRLI_COMPLETE) {
+ 		ql_dbg(ql_dbg_mbx, vha, 0x119a,
+ 		    "Unable to verify login-state (%x/%x) for loop_id %x.\n",
+ 		    pd->current_login_state, pd->last_login_state,
+ 		    fcport->loop_id);
+ 		rval = QLA_FUNCTION_FAILED;
+ 		goto gpd_error_out;
+ 	}
+ 
+ 	if (fcport->loop_id == FC_NO_LOOP_ID ||
+ 	    (memcmp(fcport->port_name, (uint8_t *)&zero, 8) &&
+ 	     memcmp(fcport->port_name, pd->port_name, 8))) {
+ 		/* We lost the device mid way. */
+ 		rval = QLA_NOT_LOGGED_IN;
+ 		goto gpd_error_out;
+ 	}
+ 
+ 	/* Names are little-endian. */
+ 	memcpy(fcport->node_name, pd->node_name, WWN_SIZE);
+ 	memcpy(fcport->port_name, pd->port_name, WWN_SIZE);
+ 
+ 	/* Get port_id of device. */
+ 	fcport->d_id.b.domain = pd->port_id[0];
+ 	fcport->d_id.b.area = pd->port_id[1];
+ 	fcport->d_id.b.al_pa = pd->port_id[2];
+ 	fcport->d_id.b.rsvd_1 = 0;
+ 
+ 	/* If not target must be initiator or unknown type. */
+ 	if ((pd->prli_svc_param_word_3[0] & BIT_4) == 0)
+ 		fcport->port_type = FCT_INITIATOR;
+ 	else
+ 		fcport->port_type = FCT_TARGET;
+ 
+ 	/* Passback COS information. */
+ 	fcport->supported_classes = (pd->flags & PDF_CLASS_2) ?
+ 		FC_COS_CLASS2 : FC_COS_CLASS3;
+ 
+ 	if (pd->prli_svc_param_word_3[0] & BIT_7) {
+ 		fcport->flags |= FCF_CONF_COMP_SUPPORTED;
+ 		fcport->conf_compl_supported = 1;
+ 	}
+ 
+ gpd_error_out:
+ 	return rval;
+ }
+ 
+ /*
+  * qla24xx_gidlist__wait
+  * NOTE: don't call this routine from DPC thread.
+  */
+ int qla24xx_gidlist_wait(struct scsi_qla_host *vha,
+ 	void *id_list, dma_addr_t id_list_dma, uint16_t *entries)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	mbx_cmd_t mc;
+ 
+ 	if (!vha->hw->flags.fw_started)
+ 		goto done;
+ 
+ 	memset(&mc, 0, sizeof(mc));
+ 	mc.mb[0] = MBC_GET_ID_LIST;
+ 	mc.mb[2] = MSW(id_list_dma);
+ 	mc.mb[3] = LSW(id_list_dma);
+ 	mc.mb[6] = MSW(MSD(id_list_dma));
+ 	mc.mb[7] = LSW(MSD(id_list_dma));
+ 	mc.mb[8] = 0;
+ 	mc.mb[9] = cpu_to_le16(vha->vp_idx);
+ 
+ 	rval = qla24xx_send_mb_cmd(vha, &mc);
+ 	if (rval != QLA_SUCCESS) {
+ 		ql_dbg(ql_dbg_mbx, vha, 0x119b,
+ 		    "%s:  fail\n", __func__);
+ 	} else {
+ 		*entries = mc.mb[1];
+ 		ql_dbg(ql_dbg_mbx, vha, 0x119c,
+ 		    "%s:  done\n", __func__);
+ 	}
+ done:
+ 	return rval;
+ }
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
diff --cc drivers/scsi/qla2xxx/qla_os.c
index 4e0d0a2f9461,cca6acaed087..000000000000
--- a/drivers/scsi/qla2xxx/qla_os.c
+++ b/drivers/scsi/qla2xxx/qla_os.c
@@@ -1020,6 -1055,34 +1020,37 @@@ qla2x00_wait_for_hba_online(scsi_qla_ho
  	return (return_status);
  }
  
++<<<<<<< HEAD
++=======
+ static inline int test_fcport_count(scsi_qla_host_t *vha)
+ {
+ 	struct qla_hw_data *ha = vha->hw;
+ 	unsigned long flags;
+ 	int res;
+ 
+ 	spin_lock_irqsave(&ha->tgt.sess_lock, flags);
+ 	ql_dbg(ql_dbg_init, vha, 0x00ec,
+ 	    "tgt %p, fcport_count=%d\n",
+ 	    vha, vha->fcport_count);
+ 	res = (vha->fcport_count == 0);
+ 	spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 
+ 	return res;
+ }
+ 
+ /*
+  * qla2x00_wait_for_sess_deletion can only be called from remove_one.
+  * it has dependency on UNLOADING flag to stop device discovery
+  */
+ static void
+ qla2x00_wait_for_sess_deletion(scsi_qla_host_t *vha)
+ {
+ 	qla2x00_mark_all_devices_lost(vha, 0);
+ 
+ 	wait_event(vha->fcport_waitQ, test_fcport_count(vha));
+ }
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  /*
   * qla2x00_wait_for_hba_ready
   * Wait till the HBA is ready before doing driver unload
@@@ -3583,8 -3598,16 +3614,20 @@@ qla2x00_schedule_rport_del(struct scsi_
  		set_bit(FCPORT_UPDATE_NEEDED, &base_vha->dpc_flags);
  		qla2xxx_wake_dpc(base_vha);
  	} else {
++<<<<<<< HEAD
 +		fc_remote_port_delete(rport);
 +		qlt_fc_port_deleted(vha, fcport);
++=======
+ 		int now;
+ 		if (rport) {
+ 			ql_dbg(ql_dbg_disc, fcport->vha, 0x2109,
+ 			    "%s %8phN. rport %p roles %x\n",
+ 			    __func__, fcport->port_name, rport,
+ 			    rport->roles);
+ 			fc_remote_port_delete(rport);
+ 		}
+ 		qlt_do_generation_tick(vha, &now);
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	}
  }
  
@@@ -3626,8 -3649,8 +3669,13 @@@ void qla2x00_mark_device_lost(scsi_qla_
  	if (fcport->login_retry == 0) {
  		fcport->login_retry = vha->hw->login_retry_count;
  
++<<<<<<< HEAD
 +		ql_dbg(ql_dbg_disc, vha, 0x2067,
 +		    "Port login retry %8phN, id = 0x%04x retry cnt=%d.\n",
++=======
+ 		ql_dbg(ql_dbg_disc, vha, 0x20a3,
+ 		    "Port login retry %8phN, lid 0x%04x retry cnt=%d.\n",
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  		    fcport->port_name, fcport->loop_id, fcport->login_retry);
  	}
  }
@@@ -3650,7 -3673,13 +3698,13 @@@ qla2x00_mark_all_devices_lost(scsi_qla_
  {
  	fc_port_t *fcport;
  
++<<<<<<< HEAD
++=======
+ 	ql_dbg(ql_dbg_disc, vha, 0x20f1,
+ 	    "Mark all dev lost\n");
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	list_for_each_entry(fcport, &vha->vp_fcports, list) {
 -		fcport->scan_state = 0;
 -		qlt_schedule_sess_for_deletion_lock(fcport);
 -
  		if (vha->vp_idx != 0 && vha->vp_idx != fcport->vha->vp_idx)
  			continue;
  
@@@ -3946,6 -3975,140 +4000,143 @@@ fail
  	return -ENOMEM;
  }
  
++<<<<<<< HEAD
++=======
+ int
+ qla2x00_set_exlogins_buffer(scsi_qla_host_t *vha)
+ {
+ 	int rval;
+ 	uint16_t	size, max_cnt, temp;
+ 	struct qla_hw_data *ha = vha->hw;
+ 
+ 	/* Return if we don't need to alloacate any extended logins */
+ 	if (!ql2xexlogins)
+ 		return QLA_SUCCESS;
+ 
+ 	ql_log(ql_log_info, vha, 0xd021, "EXLOGIN count: %d.\n", ql2xexlogins);
+ 	max_cnt = 0;
+ 	rval = qla_get_exlogin_status(vha, &size, &max_cnt);
+ 	if (rval != QLA_SUCCESS) {
+ 		ql_log_pci(ql_log_fatal, ha->pdev, 0xd029,
+ 		    "Failed to get exlogin status.\n");
+ 		return rval;
+ 	}
+ 
+ 	temp = (ql2xexlogins > max_cnt) ? max_cnt : ql2xexlogins;
+ 	ha->exlogin_size = (size * temp);
+ 	ql_log(ql_log_info, vha, 0xd024,
+ 		"EXLOGIN: max_logins=%d, portdb=0x%x, total=%d.\n",
+ 		max_cnt, size, temp);
+ 
+ 	ql_log(ql_log_info, vha, 0xd025, "EXLOGIN: requested size=0x%x\n",
+ 		ha->exlogin_size);
+ 
+ 	/* Get consistent memory for extended logins */
+ 	ha->exlogin_buf = dma_alloc_coherent(&ha->pdev->dev,
+ 	    ha->exlogin_size, &ha->exlogin_buf_dma, GFP_KERNEL);
+ 	if (!ha->exlogin_buf) {
+ 		ql_log_pci(ql_log_fatal, ha->pdev, 0xd02a,
+ 		    "Failed to allocate memory for exlogin_buf_dma.\n");
+ 		return -ENOMEM;
+ 	}
+ 
+ 	/* Now configure the dma buffer */
+ 	rval = qla_set_exlogin_mem_cfg(vha, ha->exlogin_buf_dma);
+ 	if (rval) {
+ 		ql_log(ql_log_fatal, vha, 0xd033,
+ 		    "Setup extended login buffer  ****FAILED****.\n");
+ 		qla2x00_free_exlogin_buffer(ha);
+ 	}
+ 
+ 	return rval;
+ }
+ 
+ /*
+ * qla2x00_free_exlogin_buffer
+ *
+ * Input:
+ *	ha = adapter block pointer
+ */
+ void
+ qla2x00_free_exlogin_buffer(struct qla_hw_data *ha)
+ {
+ 	if (ha->exlogin_buf) {
+ 		dma_free_coherent(&ha->pdev->dev, ha->exlogin_size,
+ 		    ha->exlogin_buf, ha->exlogin_buf_dma);
+ 		ha->exlogin_buf = NULL;
+ 		ha->exlogin_size = 0;
+ 	}
+ }
+ 
+ int
+ qla2x00_set_exchoffld_buffer(scsi_qla_host_t *vha)
+ {
+ 	int rval;
+ 	uint16_t	size, max_cnt, temp;
+ 	struct qla_hw_data *ha = vha->hw;
+ 
+ 	/* Return if we don't need to alloacate any extended logins */
+ 	if (!ql2xexchoffld)
+ 		return QLA_SUCCESS;
+ 
+ 	ql_log(ql_log_info, vha, 0xd014,
+ 	    "Exchange offload count: %d.\n", ql2xexlogins);
+ 
+ 	max_cnt = 0;
+ 	rval = qla_get_exchoffld_status(vha, &size, &max_cnt);
+ 	if (rval != QLA_SUCCESS) {
+ 		ql_log_pci(ql_log_fatal, ha->pdev, 0xd012,
+ 		    "Failed to get exlogin status.\n");
+ 		return rval;
+ 	}
+ 
+ 	temp = (ql2xexchoffld > max_cnt) ? max_cnt : ql2xexchoffld;
+ 	ha->exchoffld_size = (size * temp);
+ 	ql_log(ql_log_info, vha, 0xd016,
+ 		"Exchange offload: max_count=%d, buffers=0x%x, total=%d.\n",
+ 		max_cnt, size, temp);
+ 
+ 	ql_log(ql_log_info, vha, 0xd017,
+ 	    "Exchange Buffers requested size = 0x%x\n", ha->exchoffld_size);
+ 
+ 	/* Get consistent memory for extended logins */
+ 	ha->exchoffld_buf = dma_alloc_coherent(&ha->pdev->dev,
+ 	    ha->exchoffld_size, &ha->exchoffld_buf_dma, GFP_KERNEL);
+ 	if (!ha->exchoffld_buf) {
+ 		ql_log_pci(ql_log_fatal, ha->pdev, 0xd013,
+ 		    "Failed to allocate memory for exchoffld_buf_dma.\n");
+ 		return -ENOMEM;
+ 	}
+ 
+ 	/* Now configure the dma buffer */
+ 	rval = qla_set_exchoffld_mem_cfg(vha, ha->exchoffld_buf_dma);
+ 	if (rval) {
+ 		ql_log(ql_log_fatal, vha, 0xd02e,
+ 		    "Setup exchange offload buffer ****FAILED****.\n");
+ 		qla2x00_free_exchoffld_buffer(ha);
+ 	}
+ 
+ 	return rval;
+ }
+ 
+ /*
+ * qla2x00_free_exchoffld_buffer
+ *
+ * Input:
+ *	ha = adapter block pointer
+ */
+ void
+ qla2x00_free_exchoffld_buffer(struct qla_hw_data *ha)
+ {
+ 	if (ha->exchoffld_buf) {
+ 		dma_free_coherent(&ha->pdev->dev, ha->exchoffld_size,
+ 		    ha->exchoffld_buf, ha->exchoffld_buf_dma);
+ 		ha->exchoffld_buf = NULL;
+ 		ha->exchoffld_size = 0;
+ 	}
+ }
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  /*
  * qla2x00_free_fw_dump
  *	Frees fw dump stuff.
@@@ -4124,11 -4286,29 +4315,25 @@@ struct scsi_qla_host *qla2x00_create_ho
  	INIT_LIST_HEAD(&vha->vp_fcports);
  	INIT_LIST_HEAD(&vha->work_list);
  	INIT_LIST_HEAD(&vha->list);
 -	INIT_LIST_HEAD(&vha->qla_cmd_list);
 -	INIT_LIST_HEAD(&vha->qla_sess_op_cmd_list);
 -	INIT_LIST_HEAD(&vha->logo_list);
 -	INIT_LIST_HEAD(&vha->plogi_ack_list);
  	INIT_LIST_HEAD(&vha->qp_list);
 -	INIT_LIST_HEAD(&vha->gnl.fcports);
  
  	spin_lock_init(&vha->work_lock);
 -	spin_lock_init(&vha->cmd_list_lock);
 -	init_waitqueue_head(&vha->fcport_waitQ);
  	init_waitqueue_head(&vha->vref_waitq);
  
++<<<<<<< HEAD
++=======
+ 	vha->gnl.size = sizeof(struct get_name_list_extended) *
+ 			(ha->max_loop_id + 1);
+ 	vha->gnl.l = dma_alloc_coherent(&ha->pdev->dev,
+ 	    vha->gnl.size, &vha->gnl.ldma, GFP_KERNEL);
+ 	if (!vha->gnl.l) {
+ 		ql_log(ql_log_fatal, vha, 0xd04a,
+ 		    "Alloc failed for name list.\n");
+ 		scsi_remove_host(vha->host);
+ 		return NULL;
+ 	}
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	sprintf(vha->host_str, "%s_%ld", QLA2XXX_DRIVER_NAME, vha->host_no);
  	ql_dbg(ql_dbg_init, vha, 0x0041,
  	    "Allocated the host=%p hw=%p vha=%p dev_name=%s",
@@@ -4357,77 -4620,38 +4562,106 @@@ void qla2x00_relogin(struct scsi_qla_ho
  		    fcport->login_retry && !(fcport->flags & FCF_ASYNC_SENT)) {
  			fcport->login_retry--;
  			if (fcport->flags & FCF_FABRIC_DEVICE) {
++<<<<<<< HEAD
 +				if (fcport->flags & FCF_FCP2_DEVICE)
 +					ha->isp_ops->fabric_logout(vha,
 +							fcport->loop_id,
 +							fcport->d_id.b.domain,
 +							fcport->d_id.b.area,
 +							fcport->d_id.b.al_pa);
 +
 +				if (fcport->loop_id == FC_NO_LOOP_ID) {
 +					fcport->loop_id = next_loopid =
 +					    ha->min_external_loopid;
 +					status = qla2x00_find_new_loop_id(
 +					    vha, fcport);
 +					if (status != QLA_SUCCESS) {
 +						/* Ran out of IDs to use */
 +						break;
 +					}
++=======
+ 				ql_dbg(ql_dbg_disc, fcport->vha, 0x2108,
+ 				    "%s %8phC DS %d LS %d\n", __func__,
+ 				    fcport->port_name, fcport->disc_state,
+ 				    fcport->fw_login_state);
+ 				memset(&ea, 0, sizeof(ea));
+ 				ea.event = FCME_RELOGIN;
+ 				ea.fcport = fcport;
+ 				qla2x00_fcport_event_handler(vha, &ea);
+ 			} else {
+ 				status = qla2x00_local_device_login(vha,
+ 								fcport);
+ 				if (status == QLA_SUCCESS) {
+ 					fcport->old_loop_id = fcport->loop_id;
+ 					ql_dbg(ql_dbg_disc, vha, 0x2003,
+ 					    "Port login OK: logged in ID 0x%x.\n",
+ 					    fcport->loop_id);
+ 					qla2x00_update_fcport(vha, fcport);
+ 				} else if (status == 1) {
+ 					set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
+ 					/* retry the login again */
+ 					ql_dbg(ql_dbg_disc, vha, 0x2007,
+ 					    "Retrying %d login again loop_id 0x%x.\n",
+ 					    fcport->login_retry,
+ 					    fcport->loop_id);
+ 				} else {
+ 					fcport->login_retry = 0;
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
 +				}
 +
 +				if (IS_ALOGIO_CAPABLE(ha)) {
 +					fcport->flags |= FCF_ASYNC_SENT;
 +					data[0] = 0;
 +					data[1] = QLA_LOGIO_LOGIN_RETRIED;
 +					status = qla2x00_post_async_login_work(
 +					    vha, fcport, data);
 +					if (status == QLA_SUCCESS)
 +						continue;
 +					/* Attempt a retry. */
 +					status = 1;
 +				} else {
 +					status = qla2x00_fabric_login(vha,
 +					    fcport, &next_loopid);
 +					if (status ==  QLA_SUCCESS) {
 +						int status2;
 +						uint8_t opts;
 +
 +						opts = 0;
 +						if (fcport->flags &
 +						    FCF_FCP2_DEVICE)
 +							opts |= BIT_1;
 +						status2 =
 +						    qla2x00_get_port_database(
 +							vha, fcport, opts);
 +						if (status2 != QLA_SUCCESS)
 +							status = 1;
 +					}
  				}
 +			} else
 +				status = qla2x00_local_device_login(vha,
 +								fcport);
  
 -				if (fcport->login_retry == 0 &&
 -				    status != QLA_SUCCESS)
 -					qla2x00_clear_loop_id(fcport);
 +			if (status == QLA_SUCCESS) {
 +				fcport->old_loop_id = fcport->loop_id;
 +
 +				ql_dbg(ql_dbg_disc, vha, 0x2003,
 +				    "Port login OK: logged in ID 0x%x.\n",
 +				    fcport->loop_id);
 +
 +				qla2x00_update_fcport(vha, fcport);
 +
 +			} else if (status == 1) {
 +				set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
 +				/* retry the login again */
 +				ql_dbg(ql_dbg_disc, vha, 0x2007,
 +				    "Retrying %d login again loop_id 0x%x.\n",
 +				    fcport->login_retry, fcport->loop_id);
 +			} else {
 +				fcport->login_retry = 0;
  			}
 +
 +			if (fcport->login_retry == 0 && status != QLA_SUCCESS)
 +				qla2x00_clear_loop_id(fcport);
  		}
  		if (test_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags))
  			break;
diff --cc drivers/scsi/qla2xxx/qla_target.c
index f10c075d97ef,4ad09584d4a8..000000000000
--- a/drivers/scsi/qla2xxx/qla_target.c
+++ b/drivers/scsi/qla2xxx/qla_target.c
@@@ -146,21 -187,23 +146,30 @@@ static inlin
  struct scsi_qla_host *qlt_find_host_by_d_id(struct scsi_qla_host *vha,
  	uint8_t *d_id)
  {
 -	struct scsi_qla_host *host;
 -	uint32_t key = 0;
 +	struct qla_hw_data *ha = vha->hw;
 +	uint8_t vp_idx;
 +
 +	if ((vha->d_id.b.area != d_id[1]) || (vha->d_id.b.domain != d_id[0]))
 +		return NULL;
  
 -	if ((vha->d_id.b.area == d_id[1]) && (vha->d_id.b.domain == d_id[0]) &&
 -	    (vha->d_id.b.al_pa == d_id[2]))
 +	if (vha->d_id.b.al_pa == d_id[2])
  		return vha;
  
 -	key  = (uint32_t)d_id[0] << 16;
 -	key |= (uint32_t)d_id[1] <<  8;
 -	key |= (uint32_t)d_id[2];
 +	BUG_ON(ha->tgt.tgt_vp_map == NULL);
 +	vp_idx = ha->tgt.tgt_vp_map[d_id[2]].idx;
 +	if (likely(test_bit(vp_idx, ha->vp_idx_map)))
 +		return ha->tgt.tgt_vp_map[vp_idx].vha;
  
++<<<<<<< HEAD
 +	return NULL;
++=======
+ 	host = btree_lookup32(&vha->hw->tgt.host_map, key);
+ 	if (!host)
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf005,
+ 		    "Unable to find host %06x\n", key);
+ 
+ 	return host;
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  }
  
  static inline
@@@ -179,9 -222,129 +188,133 @@@ struct scsi_qla_host *qlt_find_host_by_
  	return NULL;
  }
  
 -static inline void qlt_incr_num_pend_cmds(struct scsi_qla_host *vha)
 +void qlt_24xx_atio_pkt_all_vps(struct scsi_qla_host *vha,
 +	struct atio_from_isp *atio)
  {
++<<<<<<< HEAD
++=======
+ 	unsigned long flags;
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.q_full_lock, flags);
+ 
+ 	vha->hw->tgt.num_pend_cmds++;
+ 	if (vha->hw->tgt.num_pend_cmds > vha->qla_stats.stat_max_pend_cmds)
+ 		vha->qla_stats.stat_max_pend_cmds =
+ 			vha->hw->tgt.num_pend_cmds;
+ 	spin_unlock_irqrestore(&vha->hw->tgt.q_full_lock, flags);
+ }
+ static inline void qlt_decr_num_pend_cmds(struct scsi_qla_host *vha)
+ {
+ 	unsigned long flags;
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.q_full_lock, flags);
+ 	vha->hw->tgt.num_pend_cmds--;
+ 	spin_unlock_irqrestore(&vha->hw->tgt.q_full_lock, flags);
+ }
+ 
+ 
+ static void qlt_queue_unknown_atio(scsi_qla_host_t *vha,
+ 	struct atio_from_isp *atio,	uint8_t ha_locked)
+ {
+ 	struct qla_tgt_sess_op *u;
+ 	struct qla_tgt *tgt = vha->vha_tgt.qla_tgt;
+ 	unsigned long flags;
+ 
+ 	if (tgt->tgt_stop) {
+ 		ql_dbg(ql_dbg_async, vha, 0x502c,
+ 		    "qla_target(%d): dropping unknown ATIO_TYPE7, because tgt is being stopped",
+ 		    vha->vp_idx);
+ 		goto out_term;
+ 	}
+ 
+ 	u = kzalloc(sizeof(*u), GFP_ATOMIC);
+ 	if (u == NULL)
+ 		goto out_term;
+ 
+ 	u->vha = vha;
+ 	memcpy(&u->atio, atio, sizeof(*atio));
+ 	INIT_LIST_HEAD(&u->cmd_list);
+ 
+ 	spin_lock_irqsave(&vha->cmd_list_lock, flags);
+ 	list_add_tail(&u->cmd_list, &vha->unknown_atio_list);
+ 	spin_unlock_irqrestore(&vha->cmd_list_lock, flags);
+ 
+ 	schedule_delayed_work(&vha->unknown_atio_work, 1);
+ 
+ out:
+ 	return;
+ 
+ out_term:
+ 	qlt_send_term_exchange(vha, NULL, atio, ha_locked, 0);
+ 	goto out;
+ }
+ 
+ static void qlt_try_to_dequeue_unknown_atios(struct scsi_qla_host *vha,
+ 	uint8_t ha_locked)
+ {
+ 	struct qla_tgt_sess_op *u, *t;
+ 	scsi_qla_host_t *host;
+ 	struct qla_tgt *tgt = vha->vha_tgt.qla_tgt;
+ 	unsigned long flags;
+ 	uint8_t queued = 0;
+ 
+ 	list_for_each_entry_safe(u, t, &vha->unknown_atio_list, cmd_list) {
+ 		if (u->aborted) {
+ 			ql_dbg(ql_dbg_async, vha, 0x502e,
+ 			    "Freeing unknown %s %p, because of Abort\n",
+ 			    "ATIO_TYPE7", u);
+ 			qlt_send_term_exchange(vha, NULL, &u->atio,
+ 			    ha_locked, 0);
+ 			goto abort;
+ 		}
+ 
+ 		host = qlt_find_host_by_d_id(vha, u->atio.u.isp24.fcp_hdr.d_id);
+ 		if (host != NULL) {
+ 			ql_dbg(ql_dbg_async, vha, 0x502f,
+ 			    "Requeuing unknown ATIO_TYPE7 %p\n", u);
+ 			qlt_24xx_atio_pkt(host, &u->atio, ha_locked);
+ 		} else if (tgt->tgt_stop) {
+ 			ql_dbg(ql_dbg_async, vha, 0x503a,
+ 			    "Freeing unknown %s %p, because tgt is being stopped\n",
+ 			    "ATIO_TYPE7", u);
+ 			qlt_send_term_exchange(vha, NULL, &u->atio,
+ 			    ha_locked, 0);
+ 		} else {
+ 			ql_dbg(ql_dbg_async, vha, 0x503d,
+ 			    "Reschedule u %p, vha %p, host %p\n", u, vha, host);
+ 			if (!queued) {
+ 				queued = 1;
+ 				schedule_delayed_work(&vha->unknown_atio_work,
+ 				    1);
+ 			}
+ 			continue;
+ 		}
+ 
+ abort:
+ 		spin_lock_irqsave(&vha->cmd_list_lock, flags);
+ 		list_del(&u->cmd_list);
+ 		spin_unlock_irqrestore(&vha->cmd_list_lock, flags);
+ 		kfree(u);
+ 	}
+ }
+ 
+ void qlt_unknown_atio_work_fn(struct work_struct *work)
+ {
+ 	struct scsi_qla_host *vha = container_of(to_delayed_work(work),
+ 	    struct scsi_qla_host, unknown_atio_work);
+ 
+ 	qlt_try_to_dequeue_unknown_atios(vha, 0);
+ }
+ 
+ static bool qlt_24xx_atio_pkt_all_vps(struct scsi_qla_host *vha,
+ 	struct atio_from_isp *atio, uint8_t ha_locked)
+ {
+ 	ql_dbg(ql_dbg_tgt, vha, 0xe072,
+ 		"%s: qla_target(%d): type %x ox_id %04x\n",
+ 		__func__, vha->vp_idx, atio->u.raw.entry_type,
+ 		be16_to_cpu(atio->u.isp24.fcp_hdr.ox_id));
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	switch (atio->u.raw.entry_type) {
  	case ATIO_TYPE7:
  	{
@@@ -223,6 -392,36 +356,39 @@@
  		break;
  	}
  
++<<<<<<< HEAD
++=======
+ 	case VP_RPT_ID_IOCB_TYPE:
+ 		qla24xx_report_id_acquisition(vha,
+ 			(struct vp_rpt_id_entry_24xx *)atio);
+ 		break;
+ 
+ 	case ABTS_RECV_24XX:
+ 	{
+ 		struct abts_recv_from_24xx *entry =
+ 			(struct abts_recv_from_24xx *)atio;
+ 		struct scsi_qla_host *host = qlt_find_host_by_vp_idx(vha,
+ 			entry->vp_index);
+ 		unsigned long flags;
+ 
+ 		if (unlikely(!host)) {
+ 			ql_dbg(ql_dbg_tgt, vha, 0xe00a,
+ 			    "qla_target(%d): Response pkt (ABTS_RECV_24XX) "
+ 			    "received, with unknown vp_index %d\n",
+ 			    vha->vp_idx, entry->vp_index);
+ 			break;
+ 		}
+ 		if (!ha_locked)
+ 			spin_lock_irqsave(&host->hw->hardware_lock, flags);
+ 		qlt_24xx_handle_abts(host, (struct abts_recv_from_24xx *)atio);
+ 		if (!ha_locked)
+ 			spin_unlock_irqrestore(&host->hw->hardware_lock, flags);
+ 		break;
+ 	}
+ 
+ 	/* case PUREX_IOCB_TYPE: ql2xmvasynctoatio */
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	default:
  		ql_dbg(ql_dbg_tgt, vha, 0xe040,
  		    "qla_target(%d): Received unknown ATIO atio "
@@@ -333,9 -536,405 +499,408 @@@ void qlt_response_pkt_all_vps(struct sc
  
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * All qlt_plogi_ack_t operations are protected by hardware_lock
+  */
+ static int qla24xx_post_nack_work(struct scsi_qla_host *vha, fc_port_t *fcport,
+ 	struct imm_ntfy_from_isp *ntfy, int type)
+ {
+ 	struct qla_work_evt *e;
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_NACK);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.nack.fcport = fcport;
+ 	e->u.nack.type = type;
+ 	memcpy(e->u.nack.iocb, ntfy, sizeof(struct imm_ntfy_from_isp));
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ static
+ void qla2x00_async_nack_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = (struct srb *)s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	unsigned long flags;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20f2,
+ 	    "Async done-%s res %x %8phC  type %d\n",
+ 	    sp->name, res, sp->fcport->port_name, sp->type);
+ 
+ 	spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 	sp->fcport->flags &= ~FCF_ASYNC_SENT;
+ 	sp->fcport->chip_reset = vha->hw->chip_reset;
+ 
+ 	switch (sp->type) {
+ 	case SRB_NACK_PLOGI:
+ 		sp->fcport->login_gen++;
+ 		sp->fcport->fw_login_state = DSC_LS_PLOGI_COMP;
+ 		sp->fcport->logout_on_delete = 1;
+ 		sp->fcport->plogi_nack_done_deadline = jiffies + HZ;
+ 		break;
+ 
+ 	case SRB_NACK_PRLI:
+ 		sp->fcport->fw_login_state = DSC_LS_PRLI_COMP;
+ 		sp->fcport->deleted = 0;
+ 
+ 		if (!sp->fcport->login_succ &&
+ 		    !IS_SW_RESV_ADDR(sp->fcport->d_id)) {
+ 			sp->fcport->login_succ = 1;
+ 
+ 			vha->fcport_count++;
+ 
+ 			if (!IS_IIDMA_CAPABLE(vha->hw) ||
+ 			    !vha->hw->flags.gpsc_supported) {
+ 				ql_dbg(ql_dbg_disc, vha, 0x20f3,
+ 				    "%s %d %8phC post upd_fcport fcp_cnt %d\n",
+ 				    __func__, __LINE__,
+ 				    sp->fcport->port_name,
+ 				    vha->fcport_count);
+ 
+ 				qla24xx_post_upd_fcport_work(vha, sp->fcport);
+ 			} else {
+ 				ql_dbg(ql_dbg_disc, vha, 0x20f5,
+ 				    "%s %d %8phC post gpsc fcp_cnt %d\n",
+ 				    __func__, __LINE__,
+ 				    sp->fcport->port_name,
+ 				    vha->fcport_count);
+ 
+ 				qla24xx_post_gpsc_work(vha, sp->fcport);
+ 			}
+ 		}
+ 		break;
+ 
+ 	case SRB_NACK_LOGO:
+ 		sp->fcport->login_gen++;
+ 		sp->fcport->fw_login_state = DSC_LS_PORT_UNAVAIL;
+ 		qlt_logo_completion_handler(sp->fcport, MBS_COMMAND_COMPLETE);
+ 		break;
+ 	}
+ 	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_notify_ack(scsi_qla_host_t *vha, fc_port_t *fcport,
+ 	struct imm_ntfy_from_isp *ntfy, int type)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	srb_t *sp;
+ 	char *c = NULL;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	switch (type) {
+ 	case SRB_NACK_PLOGI:
+ 		fcport->fw_login_state = DSC_LS_PLOGI_PEND;
+ 		c = "PLOGI";
+ 		break;
+ 	case SRB_NACK_PRLI:
+ 		fcport->fw_login_state = DSC_LS_PRLI_PEND;
+ 		fcport->deleted = 0;
+ 		c = "PRLI";
+ 		break;
+ 	case SRB_NACK_LOGO:
+ 		fcport->fw_login_state = DSC_LS_LOGO_PEND;
+ 		c = "LOGO";
+ 		break;
+ 	}
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_ATOMIC);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	sp->type = type;
+ 	sp->name = "nack";
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha)+2);
+ 
+ 	sp->u.iocb_cmd.u.nack.ntfy = ntfy;
+ 
+ 	sp->done = qla2x00_async_nack_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20f4,
+ 	    "Async-%s %8phC hndl %x %s\n",
+ 	    sp->name, fcport->port_name, sp->handle, c);
+ 
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ done:
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ void qla24xx_do_nack_work(struct scsi_qla_host *vha, struct qla_work_evt *e)
+ {
+ 	fc_port_t *t;
+ 	unsigned long flags;
+ 
+ 	switch (e->u.nack.type) {
+ 	case SRB_NACK_PRLI:
+ 		mutex_lock(&vha->vha_tgt.tgt_mutex);
+ 		t = qlt_create_sess(vha, e->u.nack.fcport, 0);
+ 		mutex_unlock(&vha->vha_tgt.tgt_mutex);
+ 		if (t) {
+ 			ql_log(ql_log_info, vha, 0xd034,
+ 			    "%s create sess success %p", __func__, t);
+ 			spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 			/* create sess has an extra kref */
+ 			vha->hw->tgt.tgt_ops->put_sess(e->u.nack.fcport);
+ 			spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 		}
+ 		break;
+ 	}
+ 	qla24xx_async_notify_ack(vha, e->u.nack.fcport,
+ 	    (struct imm_ntfy_from_isp*)e->u.nack.iocb, e->u.nack.type);
+ }
+ 
+ void qla24xx_delete_sess_fn(struct work_struct *work)
+ {
+ 	fc_port_t *fcport = container_of(work, struct fc_port, del_work);
+ 	struct qla_hw_data *ha = fcport->vha->hw;
+ 	unsigned long flags;
+ 
+ 	spin_lock_irqsave(&ha->tgt.sess_lock, flags);
+ 
+ 	if (fcport->se_sess) {
+ 		ha->tgt.tgt_ops->shutdown_sess(fcport);
+ 		ha->tgt.tgt_ops->put_sess(fcport);
+ 	} else {
+ 		qlt_unreg_sess(fcport);
+ 	}
+ 	spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ }
+ 
+ /*
+  * Called from qla2x00_reg_remote_port()
+  */
+ void qlt_fc_port_added(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_hw_data *ha = vha->hw;
+ 	struct qla_tgt *tgt = vha->vha_tgt.qla_tgt;
+ 	struct fc_port *sess = fcport;
+ 	unsigned long flags;
+ 
+ 	if (!vha->hw->tgt.tgt_ops)
+ 		return;
+ 
+ 	spin_lock_irqsave(&ha->tgt.sess_lock, flags);
+ 	if (tgt->tgt_stop) {
+ 		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 		return;
+ 	}
+ 
+ 	if (fcport->disc_state == DSC_DELETE_PEND) {
+ 		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 		return;
+ 	}
+ 
+ 	if (!sess->se_sess) {
+ 		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 
+ 		mutex_lock(&vha->vha_tgt.tgt_mutex);
+ 		sess = qlt_create_sess(vha, fcport, false);
+ 		mutex_unlock(&vha->vha_tgt.tgt_mutex);
+ 
+ 		spin_lock_irqsave(&ha->tgt.sess_lock, flags);
+ 	} else {
+ 		if (fcport->fw_login_state == DSC_LS_PRLI_COMP) {
+ 			spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 			return;
+ 		}
+ 
+ 		if (!kref_get_unless_zero(&sess->sess_kref)) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x2107,
+ 			    "%s: kref_get fail sess %8phC \n",
+ 			    __func__, sess->port_name);
+ 			spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 			return;
+ 		}
+ 
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf04c,
+ 		    "qla_target(%u): %ssession for port %8phC "
+ 		    "(loop ID %d) reappeared\n", vha->vp_idx,
+ 		    sess->local ? "local " : "", sess->port_name, sess->loop_id);
+ 
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf007,
+ 		    "Reappeared sess %p\n", sess);
+ 
+ 		ha->tgt.tgt_ops->update_sess(sess, fcport->d_id,
+ 		    fcport->loop_id,
+ 		    (fcport->flags & FCF_CONF_COMP_SUPPORTED));
+ 	}
+ 
+ 	if (sess && sess->local) {
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf04d,
+ 		    "qla_target(%u): local session for "
+ 		    "port %8phC (loop ID %d) became global\n", vha->vp_idx,
+ 		    fcport->port_name, sess->loop_id);
+ 		sess->local = 0;
+ 	}
+ 	ha->tgt.tgt_ops->put_sess(sess);
+ 	spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ }
+ 
+ /*
+  * This is a zero-base ref-counting solution, since hardware_lock
+  * guarantees that ref_count is not modified concurrently.
+  * Upon successful return content of iocb is undefined
+  */
+ static struct qlt_plogi_ack_t *
+ qlt_plogi_ack_find_add(struct scsi_qla_host *vha, port_id_t *id,
+ 		       struct imm_ntfy_from_isp *iocb)
+ {
+ 	struct qlt_plogi_ack_t *pla;
+ 
+ 	list_for_each_entry(pla, &vha->plogi_ack_list, list) {
+ 		if (pla->id.b24 == id->b24) {
+ 			qlt_send_term_imm_notif(vha, &pla->iocb, 1);
+ 			memcpy(&pla->iocb, iocb, sizeof(pla->iocb));
+ 			return pla;
+ 		}
+ 	}
+ 
+ 	pla = kmem_cache_zalloc(qla_tgt_plogi_cachep, GFP_ATOMIC);
+ 	if (!pla) {
+ 		ql_dbg(ql_dbg_async, vha, 0x5088,
+ 		       "qla_target(%d): Allocation of plogi_ack failed\n",
+ 		       vha->vp_idx);
+ 		return NULL;
+ 	}
+ 
+ 	memcpy(&pla->iocb, iocb, sizeof(pla->iocb));
+ 	pla->id = *id;
+ 	list_add_tail(&pla->list, &vha->plogi_ack_list);
+ 
+ 	return pla;
+ }
+ 
+ void qlt_plogi_ack_unref(struct scsi_qla_host *vha,
+     struct qlt_plogi_ack_t *pla)
+ {
+ 	struct imm_ntfy_from_isp *iocb = &pla->iocb;
+ 	port_id_t port_id;
+ 	uint16_t loop_id;
+ 	fc_port_t *fcport = pla->fcport;
+ 
+ 	BUG_ON(!pla->ref_count);
+ 	pla->ref_count--;
+ 
+ 	if (pla->ref_count)
+ 		return;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x5089,
+ 	    "Sending PLOGI ACK to wwn %8phC s_id %02x:%02x:%02x loop_id %#04x"
+ 	    " exch %#x ox_id %#x\n", iocb->u.isp24.port_name,
+ 	    iocb->u.isp24.port_id[2], iocb->u.isp24.port_id[1],
+ 	    iocb->u.isp24.port_id[0],
+ 	    le16_to_cpu(iocb->u.isp24.nport_handle),
+ 	    iocb->u.isp24.exchange_address, iocb->ox_id);
+ 
+ 	port_id.b.domain = iocb->u.isp24.port_id[2];
+ 	port_id.b.area   = iocb->u.isp24.port_id[1];
+ 	port_id.b.al_pa  = iocb->u.isp24.port_id[0];
+ 	port_id.b.rsvd_1 = 0;
+ 
+ 	loop_id = le16_to_cpu(iocb->u.isp24.nport_handle);
+ 
+ 	fcport->loop_id = loop_id;
+ 	fcport->d_id = port_id;
+ 	qla24xx_post_nack_work(vha, fcport, iocb, SRB_NACK_PLOGI);
+ 
+ 	list_for_each_entry(fcport, &vha->vp_fcports, list) {
+ 		if (fcport->plogi_link[QLT_PLOGI_LINK_SAME_WWN] == pla)
+ 			fcport->plogi_link[QLT_PLOGI_LINK_SAME_WWN] = NULL;
+ 		if (fcport->plogi_link[QLT_PLOGI_LINK_CONFLICT] == pla)
+ 			fcport->plogi_link[QLT_PLOGI_LINK_CONFLICT] = NULL;
+ 	}
+ 
+ 	list_del(&pla->list);
+ 	kmem_cache_free(qla_tgt_plogi_cachep, pla);
+ }
+ 
+ void
+ qlt_plogi_ack_link(struct scsi_qla_host *vha, struct qlt_plogi_ack_t *pla,
+     struct fc_port *sess, enum qlt_plogi_link_t link)
+ {
+ 	struct imm_ntfy_from_isp *iocb = &pla->iocb;
+ 	/* Inc ref_count first because link might already be pointing at pla */
+ 	pla->ref_count++;
+ 
+ 	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf097,
+ 		"Linking sess %p [%d] wwn %8phC with PLOGI ACK to wwn %8phC"
+ 		" s_id %02x:%02x:%02x, ref=%d pla %p link %d\n",
+ 		sess, link, sess->port_name,
+ 		iocb->u.isp24.port_name, iocb->u.isp24.port_id[2],
+ 		iocb->u.isp24.port_id[1], iocb->u.isp24.port_id[0],
+ 		pla->ref_count, pla, link);
+ 
+ 	if (sess->plogi_link[link])
+ 		qlt_plogi_ack_unref(vha, sess->plogi_link[link]);
+ 
+ 	if (link == QLT_PLOGI_LINK_SAME_WWN)
+ 		pla->fcport = sess;
+ 
+ 	sess->plogi_link[link] = pla;
+ }
+ 
+ typedef struct {
+ 	/* These fields must be initialized by the caller */
+ 	port_id_t id;
+ 	/*
+ 	 * number of cmds dropped while we were waiting for
+ 	 * initiator to ack LOGO initialize to 1 if LOGO is
+ 	 * triggered by a command, otherwise, to 0
+ 	 */
+ 	int cmd_count;
+ 
+ 	/* These fields are used by callee */
+ 	struct list_head list;
+ } qlt_port_logo_t;
+ 
+ static void
+ qlt_send_first_logo(struct scsi_qla_host *vha, qlt_port_logo_t *logo)
+ {
+ 	qlt_port_logo_t *tmp;
+ 	int res;
+ 
+ 	mutex_lock(&vha->vha_tgt.tgt_mutex);
+ 
+ 	list_for_each_entry(tmp, &vha->logo_list, list) {
+ 		if (tmp->id.b24 == logo->id.b24) {
+ 			tmp->cmd_count += logo->cmd_count;
+ 			mutex_unlock(&vha->vha_tgt.tgt_mutex);
+ 			return;
+ 		}
+ 	}
+ 
+ 	list_add_tail(&logo->list, &vha->logo_list);
+ 
+ 	mutex_unlock(&vha->vha_tgt.tgt_mutex);
+ 
+ 	res = qla24xx_els_dcmd_iocb(vha, ELS_DCMD_LOGO, logo->id);
+ 
+ 	mutex_lock(&vha->vha_tgt.tgt_mutex);
+ 	list_del(&logo->list);
+ 	mutex_unlock(&vha->vha_tgt.tgt_mutex);
+ 
+ 	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf098,
+ 	    "Finished LOGO to %02x:%02x:%02x, dropped %d cmds, res = %#x\n",
+ 	    logo->id.b.domain, logo->id.b.area, logo->id.b.al_pa,
+ 	    logo->cmd_count, res);
+ }
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  static void qlt_free_session_done(struct work_struct *work)
  {
 -	struct fc_port *sess = container_of(work, struct fc_port,
 +	struct qla_tgt_sess *sess = container_of(work, struct qla_tgt_sess,
  	    free_work);
  	struct qla_tgt *tgt = sess->tgt;
  	struct scsi_qla_host *vha = sess->vha;
@@@ -366,11 -1093,19 +931,17 @@@ void qlt_unreg_sess(struct qla_tgt_ses
  {
  	struct scsi_qla_host *vha = sess->vha;
  
++<<<<<<< HEAD
 +	vha->hw->tgt.tgt_ops->clear_nacl_from_fcport_map(sess);
++=======
+ 	ql_dbg(ql_dbg_disc, sess->vha, 0x210a,
+ 	    "%s sess %p for deletion %8phC\n",
+ 	    __func__, sess, sess->port_name);
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  
 -	if (sess->se_sess)
 -		vha->hw->tgt.tgt_ops->clear_nacl_from_fcport_map(sess);
 -
 -	qla2x00_mark_device_lost(vha, sess, 1, 1);
 -
 -	sess->deleted = QLA_SESS_DELETION_IN_PROGRESS;
 -	sess->disc_state = DSC_DELETE_PEND;
 -	sess->last_rscn_gen = sess->rscn_gen;
 -	sess->last_login_gen = sess->login_gen;
 +	list_del(&sess->sess_list_entry);
 +	if (sess->deleted)
 +		list_del(&sess->del_list_entry);
  
  	INIT_WORK(&sess->free_work, qlt_free_session_done);
  	schedule_work(&sess->free_work);
@@@ -709,87 -1275,65 +1280,136 @@@ static struct qla_tgt_sess *qlt_create_
  	bool local)
  {
  	struct qla_hw_data *ha = vha->hw;
 -	struct fc_port *sess = fcport;
 +	struct qla_tgt_sess *sess;
  	unsigned long flags;
 +	unsigned char be_sid[3];
  
 -	if (vha->vha_tgt.qla_tgt->tgt_stop)
 -		return NULL;
 +	/* Check to avoid double sessions */
 +	spin_lock_irqsave(&ha->hardware_lock, flags);
 +	list_for_each_entry(sess, &ha->tgt.qla_tgt->sess_list,
 +				sess_list_entry) {
 +		if (!memcmp(sess->port_name, fcport->port_name, WWN_SIZE)) {
 +			ql_dbg(ql_dbg_tgt_mgt, vha, 0xf005,
 +			    "Double sess %p found (s_id %x:%x:%x, "
 +			    "loop_id %d), updating to d_id %x:%x:%x, "
 +			    "loop_id %d", sess, sess->s_id.b.domain,
 +			    sess->s_id.b.al_pa, sess->s_id.b.area,
 +			    sess->loop_id, fcport->d_id.b.domain,
 +			    fcport->d_id.b.al_pa, fcport->d_id.b.area,
 +			    fcport->loop_id);
 +
++<<<<<<< HEAD
 +			if (sess->deleted)
 +				qlt_undelete_sess(sess);
 +
 +			kref_get(&sess->se_sess->sess_kref);
 +			ha->tgt.tgt_ops->update_sess(sess, fcport->d_id, fcport->loop_id,
 +						(fcport->flags & FCF_CONF_COMP_SUPPORTED));
 +
 +			if (sess->local && !local)
 +				sess->local = 0;
 +			spin_unlock_irqrestore(&ha->hardware_lock, flags);
  
 +			return sess;
++=======
+ 	if (fcport->se_sess) {
+ 		if (!kref_get_unless_zero(&sess->sess_kref)) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20f6,
+ 			    "%s: kref_get_unless_zero failed for %8phC\n",
+ 			    __func__, sess->port_name);
+ 			return NULL;
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  		}
 -		return fcport;
  	}
 -	sess->tgt = vha->vha_tgt.qla_tgt;
 +	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 +
 +	sess = kzalloc(sizeof(*sess), GFP_KERNEL);
 +	if (!sess) {
 +		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf04a,
 +		    "qla_target(%u): session allocation failed, all commands "
 +		    "from port %8phC will be refused", vha->vp_idx,
 +		    fcport->port_name);
 +
 +		return NULL;
 +	}
 +	sess->tgt = ha->tgt.qla_tgt;
 +	sess->vha = vha;
 +	sess->s_id = fcport->d_id;
 +	sess->loop_id = fcport->loop_id;
  	sess->local = local;
  
++<<<<<<< HEAD
++=======
+ 	/*
+ 	 * Under normal circumstances we want to logout from firmware when
+ 	 * session eventually ends and release corresponding nport handle.
+ 	 * In the exception cases (e.g. when new PLOGI is waiting) corresponding
+ 	 * code will adjust these flags as necessary.
+ 	 */
+ 	sess->logout_on_delete = 1;
+ 	sess->keep_nport_handle = 0;
+ 	sess->logout_completed = 0;
+ 
+ 	if (ha->tgt.tgt_ops->check_initiator_node_acl(vha,
+ 	    &fcport->port_name[0], sess) < 0) {
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf015,
+ 		    "(%d) %8phC check_initiator_node_acl failed\n",
+ 		    vha->vp_idx, fcport->port_name);
+ 		return NULL;
+ 	} else {
+ 		kref_init(&fcport->sess_kref);
+ 		/*
+ 		 * Take an extra reference to ->sess_kref here to handle
+ 		 * fc_port access across ->tgt.sess_lock reaquire.
+ 		 */
+ 		if (!kref_get_unless_zero(&sess->sess_kref)) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20f7,
+ 			    "%s: kref_get_unless_zero failed for %8phC\n",
+ 			    __func__, sess->port_name);
+ 			return NULL;
+ 		}
+ 
+ 		spin_lock_irqsave(&ha->tgt.sess_lock, flags);
+ 		if (!IS_SW_RESV_ADDR(sess->d_id))
+ 			vha->vha_tgt.qla_tgt->sess_count++;
+ 
+ 		qlt_do_generation_tick(vha, &sess->generation);
+ 		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
+ 	}
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf006,
 -	    "Adding sess %p se_sess %p  to tgt %p sess_count %d\n",
 -	    sess, sess->se_sess, vha->vha_tgt.qla_tgt,
 -	    vha->vha_tgt.qla_tgt->sess_count);
 +	    "Adding sess %p to tgt %p via ->check_initiator_node_acl()\n",
 +	    sess, ha->tgt.qla_tgt);
 +
 +	be_sid[0] = sess->s_id.b.domain;
 +	be_sid[1] = sess->s_id.b.area;
 +	be_sid[2] = sess->s_id.b.al_pa;
 +	/*
 +	 * Determine if this fc_port->port_name is allowed to access
 +	 * target mode using explict NodeACLs+MappedLUNs, or using
 +	 * TPG demo mode.  If this is successful a target mode FC nexus
 +	 * is created.
 +	 */
 +	if (ha->tgt.tgt_ops->check_initiator_node_acl(vha,
 +	    &fcport->port_name[0], sess, &be_sid[0], fcport->loop_id) < 0) {
 +		kfree(sess);
 +		return NULL;
 +	}
 +	/*
 +	 * Take an extra reference to ->sess_kref here to handle qla_tgt_sess
 +	 * access across ->hardware_lock reaquire.
 +	 */
 +	kref_get(&sess->se_sess->sess_kref);
 +
 +	sess->conf_compl_supported = (fcport->flags & FCF_CONF_COMP_SUPPORTED);
 +	BUILD_BUG_ON(sizeof(sess->port_name) != sizeof(fcport->port_name));
 +	memcpy(sess->port_name, fcport->port_name, sizeof(sess->port_name));
 +
 +	spin_lock_irqsave(&ha->hardware_lock, flags);
 +	list_add_tail(&sess->sess_list_entry, &ha->tgt.qla_tgt->sess_list);
 +	ha->tgt.qla_tgt->sess_count++;
 +	spin_unlock_irqrestore(&ha->hardware_lock, flags);
  
  	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf04b,
  	    "qla_target(%d): %ssession for wwn %8phC (loop_id %d, "
@@@ -1423,10 -2112,38 +2043,45 @@@ void qlt_xmit_tm_rsp(struct qla_tgt_mgm
  	    mcmd, mcmd->fc_tm_rsp, mcmd->flags);
  
  	spin_lock_irqsave(&ha->hardware_lock, flags);
++<<<<<<< HEAD
 +	if (mcmd->flags == QLA24XX_MGMT_SEND_NACK)
 +		qlt_send_notify_ack(vha, &mcmd->orig_iocb.imm_ntfy,
 +		    0, 0, 0, 0, 0, 0);
 +	else {
++=======
+ 
+ 	if (!vha->flags.online || mcmd->reset_count != ha->chip_reset) {
+ 		/*
+ 		 * Either the port is not online or this request was from
+ 		 * previous life, just abort the processing.
+ 		 */
+ 		ql_dbg(ql_dbg_async, vha, 0xe100,
+ 			"RESET-TMR online/active/old-count/new-count = %d/%d/%d/%d.\n",
+ 			vha->flags.online, qla2x00_reset_active(vha),
+ 			mcmd->reset_count, ha->chip_reset);
+ 		ha->tgt.tgt_ops->free_mcmd(mcmd);
+ 		spin_unlock_irqrestore(&ha->hardware_lock, flags);
+ 		return;
+ 	}
+ 
+ 	if (mcmd->flags == QLA24XX_MGMT_SEND_NACK) {
+ 		if (mcmd->orig_iocb.imm_ntfy.u.isp24.status_subcode ==
+ 		    ELS_LOGO ||
+ 		    mcmd->orig_iocb.imm_ntfy.u.isp24.status_subcode ==
+ 		    ELS_PRLO ||
+ 		    mcmd->orig_iocb.imm_ntfy.u.isp24.status_subcode ==
+ 		    ELS_TPRLO) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x2106,
+ 			    "TM response logo %phC status %#x state %#x",
+ 			    mcmd->sess->port_name, mcmd->fc_tm_rsp,
+ 			    mcmd->flags);
+ 			qlt_schedule_sess_for_deletion_lock(mcmd->sess);
+ 		} else {
+ 			qlt_send_notify_ack(vha, &mcmd->orig_iocb.imm_ntfy,
+ 				0, 0, 0, 0, 0, 0);
+ 		}
+ 	} else {
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  		if (mcmd->orig_iocb.atio.u.raw.entry_type == ABTS_RECV_24XX)
  			qlt_24xx_send_abts_resp(vha, &mcmd->orig_iocb.abts,
  			    mcmd->fc_tm_rsp, false);
@@@ -1749,6 -2480,50 +2404,53 @@@ static inline int qlt_has_data(struct q
  	return cmd->bufflen > 0;
  }
  
++<<<<<<< HEAD
++=======
+ static void qlt_print_dif_err(struct qla_tgt_prm *prm)
+ {
+ 	struct qla_tgt_cmd *cmd;
+ 	struct scsi_qla_host *vha;
+ 
+ 	/* asc 0x10=dif error */
+ 	if (prm->sense_buffer && (prm->sense_buffer[12] == 0x10)) {
+ 		cmd = prm->cmd;
+ 		vha = cmd->vha;
+ 		/* ASCQ */
+ 		switch (prm->sense_buffer[13]) {
+ 		case 1:
+ 			ql_dbg(ql_dbg_tgt_dif, vha, 0xe00b,
+ 			    "BE detected Guard TAG ERR: lba[0x%llx|%lld] len[0x%x] "
+ 			    "se_cmd=%p tag[%x]",
+ 			    cmd->lba, cmd->lba, cmd->num_blks, &cmd->se_cmd,
+ 			    cmd->atio.u.isp24.exchange_addr);
+ 			break;
+ 		case 2:
+ 			ql_dbg(ql_dbg_tgt_dif, vha, 0xe00c,
+ 			    "BE detected APP TAG ERR: lba[0x%llx|%lld] len[0x%x] "
+ 			    "se_cmd=%p tag[%x]",
+ 			    cmd->lba, cmd->lba, cmd->num_blks, &cmd->se_cmd,
+ 			    cmd->atio.u.isp24.exchange_addr);
+ 			break;
+ 		case 3:
+ 			ql_dbg(ql_dbg_tgt_dif, vha, 0xe00f,
+ 			    "BE detected REF TAG ERR: lba[0x%llx|%lld] len[0x%x] "
+ 			    "se_cmd=%p tag[%x]",
+ 			    cmd->lba, cmd->lba, cmd->num_blks, &cmd->se_cmd,
+ 			    cmd->atio.u.isp24.exchange_addr);
+ 			break;
+ 		default:
+ 			ql_dbg(ql_dbg_tgt_dif, vha, 0xe010,
+ 			    "BE detected Dif ERR: lba[%llx|%lld] len[%x] "
+ 			    "se_cmd=%p tag[%x]",
+ 			    cmd->lba, cmd->lba, cmd->num_blks, &cmd->se_cmd,
+ 			    cmd->atio.u.isp24.exchange_addr);
+ 			break;
+ 		}
+ 		ql_dump_buffer(ql_dbg_tgt_dif, vha, 0xe011, cmd->cdb, 16);
+ 	}
+ }
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  /*
   * Called without ha->hardware_lock held
   */
@@@ -2160,42 -3192,255 +2862,236 @@@ int qlt_rdy_to_xfer(struct qla_tgt_cmd 
  	if (qlt_pci_map_calc_cnt(&prm) != 0)
  		return -EAGAIN;
  
- 	spin_lock_irqsave(&ha->hardware_lock, flags);
+ 	spin_lock_irqsave(&ha->hardware_lock, flags);
+ 
 -	if (!ha->flags.fw_started || (cmd->reset_count != ha->chip_reset) ||
 -	    (cmd->sess && cmd->sess->deleted)) {
 -		/*
 -		 * Either the port is not online or this request was from
 -		 * previous life, just abort the processing.
 -		 */
 -		cmd->state = QLA_TGT_STATE_NEED_DATA;
 -		qlt_abort_cmd_on_host_reset(cmd->vha, cmd);
 -		ql_dbg(ql_dbg_async, vha, 0xe102,
 -			"RESET-XFR online/active/old-count/new-count = %d/%d/%d/%d.\n",
 -			vha->flags.online, qla2x00_reset_active(vha),
 -			cmd->reset_count, ha->chip_reset);
 -		spin_unlock_irqrestore(&ha->hardware_lock, flags);
 -		return 0;
 -	}
 -
+ 	/* Does F/W have an IOCBs for this request */
+ 	res = qlt_check_reserve_free_req(vha, prm.req_cnt);
+ 	if (res != 0)
+ 		goto out_unlock_free_unmap;
 -	if (cmd->se_cmd.prot_op)
 -		res = qlt_build_ctio_crc2_pkt(&prm, vha);
 -	else
 -		res = qlt_24xx_build_ctio_pkt(&prm, vha);
+ 
 -	if (unlikely(res != 0)) {
 -		vha->req->cnt += prm.req_cnt;
++	res = qlt_24xx_build_ctio_pkt(&prm, vha);
++	if (unlikely(res != 0))
+ 		goto out_unlock_free_unmap;
 -	}
 -
+ 	pkt = (struct ctio7_to_24xx *)prm.pkt;
+ 	pkt->u.status0.flags |= cpu_to_le16(CTIO7_FLAGS_DATA_OUT |
+ 	    CTIO7_FLAGS_STATUS_MODE_0);
 -
 -	if (cmd->se_cmd.prot_op == TARGET_PROT_NORMAL)
 -		qlt_load_data_segments(&prm, vha);
++	qlt_load_data_segments(&prm, vha);
+ 
+ 	cmd->state = QLA_TGT_STATE_NEED_DATA;
 -	cmd->cmd_sent_to_fw = 1;
+ 
+ 	/* Memory Barrier */
+ 	wmb();
+ 	qla2x00_start_iocbs(vha, vha->req);
+ 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+ 
+ 	return res;
+ 
+ out_unlock_free_unmap:
 -	qlt_unmap_sg(vha, cmd);
++	if (cmd->sg_mapped)
++		qlt_unmap_sg(vha, cmd);
+ 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+ 
+ 	return res;
+ }
+ EXPORT_SYMBOL(qlt_rdy_to_xfer);
+ 
+ 
++<<<<<<< HEAD
++/* If hardware_lock held on entry, might drop it, then reaquire */
++/* This function sends the appropriate CTIO to ISP 2xxx or 24xx */
++=======
+ /*
+  * it is assumed either hardware_lock or qpair lock is held.
+  */
+ static void
+ qlt_handle_dif_error(struct scsi_qla_host *vha, struct qla_tgt_cmd *cmd,
+ 	struct ctio_crc_from_fw *sts)
+ {
+ 	uint8_t		*ap = &sts->actual_dif[0];
+ 	uint8_t		*ep = &sts->expected_dif[0];
+ 	uint64_t	lba = cmd->se_cmd.t_task_lba;
+ 	uint8_t scsi_status, sense_key, asc, ascq;
+ 	unsigned long flags;
+ 
+ 	cmd->trc_flags |= TRC_DIF_ERR;
+ 
+ 	cmd->a_guard   = be16_to_cpu(*(uint16_t *)(ap + 0));
+ 	cmd->a_app_tag = be16_to_cpu(*(uint16_t *)(ap + 2));
+ 	cmd->a_ref_tag = be32_to_cpu(*(uint32_t *)(ap + 4));
+ 
+ 	cmd->e_guard   = be16_to_cpu(*(uint16_t *)(ep + 0));
+ 	cmd->e_app_tag = be16_to_cpu(*(uint16_t *)(ep + 2));
+ 	cmd->e_ref_tag = be32_to_cpu(*(uint32_t *)(ep + 4));
+ 
+ 	ql_dbg(ql_dbg_tgt_dif, vha, 0xf075,
+ 	    "%s: aborted %d state %d\n", __func__, cmd->aborted, cmd->state);
+ 
+ 	scsi_status = sense_key = asc = ascq = 0;
+ 
+ 	/* check appl tag */
+ 	if (cmd->e_app_tag != cmd->a_app_tag) {
+ 		ql_dbg(ql_dbg_tgt_dif, vha, 0xe00d,
+ 		    "App Tag ERR: cdb[%x] lba[%llx %llx] blks[%x] [Actual|Expected] Ref[%x|%x], App[%x|%x], Guard [%x|%x] cmd=%p ox_id[%04x]",
+ 		    cmd->cdb[0], lba, (lba+cmd->num_blks), cmd->num_blks,
+ 		    cmd->a_ref_tag, cmd->e_ref_tag, cmd->a_app_tag,
+ 		    cmd->e_app_tag, cmd->a_guard, cmd->e_guard, cmd,
+ 		    cmd->atio.u.isp24.fcp_hdr.ox_id);
+ 
+ 		cmd->dif_err_code = DIF_ERR_APP;
+ 		scsi_status = SAM_STAT_CHECK_CONDITION;
+ 		sense_key = ABORTED_COMMAND;
+ 		asc = 0x10;
+ 		ascq = 0x2;
+ 	}
+ 
+ 	/* check ref tag */
+ 	if (cmd->e_ref_tag != cmd->a_ref_tag) {
+ 		ql_dbg(ql_dbg_tgt_dif, vha, 0xe00e,
+ 		    "Ref Tag ERR: cdb[%x] lba[%llx %llx] blks[%x] [Actual|Expected] Ref[%x|%x], App[%x|%x], Guard[%x|%x] cmd=%p ox_id[%04x] ",
+ 		    cmd->cdb[0], lba, (lba+cmd->num_blks), cmd->num_blks,
+ 		    cmd->a_ref_tag, cmd->e_ref_tag, cmd->a_app_tag,
+ 		    cmd->e_app_tag, cmd->a_guard, cmd->e_guard, cmd,
+ 		    cmd->atio.u.isp24.fcp_hdr.ox_id);
+ 
+ 		cmd->dif_err_code = DIF_ERR_REF;
+ 		scsi_status = SAM_STAT_CHECK_CONDITION;
+ 		sense_key = ABORTED_COMMAND;
+ 		asc = 0x10;
+ 		ascq = 0x3;
+ 		goto out;
+ 	}
+ 
+ 	/* check guard */
+ 	if (cmd->e_guard != cmd->a_guard) {
+ 		ql_dbg(ql_dbg_tgt_dif, vha, 0xe012,
+ 		    "Guard ERR: cdb[%x] lba[%llx %llx] blks[%x] [Actual|Expected] Ref[%x|%x], App[%x|%x], Guard [%x|%x] cmd=%p ox_id[%04x]",
+ 		    cmd->cdb[0], lba, (lba+cmd->num_blks), cmd->num_blks,
+ 		    cmd->a_ref_tag, cmd->e_ref_tag, cmd->a_app_tag,
+ 		    cmd->e_app_tag, cmd->a_guard, cmd->e_guard, cmd,
+ 		    cmd->atio.u.isp24.fcp_hdr.ox_id);
+ 
+ 		cmd->dif_err_code = DIF_ERR_GRD;
+ 		scsi_status = SAM_STAT_CHECK_CONDITION;
+ 		sense_key = ABORTED_COMMAND;
+ 		asc = 0x10;
+ 		ascq = 0x1;
+ 	}
+ out:
+ 	switch (cmd->state) {
+ 	case QLA_TGT_STATE_NEED_DATA:
+ 		/* handle_data will load DIF error code  */
+ 		cmd->state = QLA_TGT_STATE_DATA_IN;
+ 		vha->hw->tgt.tgt_ops->handle_data(cmd);
+ 		break;
+ 	default:
+ 		spin_lock_irqsave(&cmd->cmd_lock, flags);
+ 		if (cmd->aborted) {
+ 			spin_unlock_irqrestore(&cmd->cmd_lock, flags);
+ 			vha->hw->tgt.tgt_ops->free_cmd(cmd);
+ 			break;
+ 		}
+ 		spin_unlock_irqrestore(&cmd->cmd_lock, flags);
+ 
+ 		qlt_send_resp_ctio(vha, cmd, scsi_status, sense_key, asc, ascq);
+ 		/* assume scsi status gets out on the wire.
+ 		 * Will not wait for completion.
+ 		 */
+ 		vha->hw->tgt.tgt_ops->free_cmd(cmd);
+ 		break;
+ 	}
+ }
+ 
+ /* If hardware_lock held on entry, might drop it, then reaquire */
+ /* This function sends the appropriate CTIO to ISP 2xxx or 24xx */
+ static int __qlt_send_term_imm_notif(struct scsi_qla_host *vha,
+ 	struct imm_ntfy_from_isp *ntfy)
+ {
+ 	struct nack_to_isp *nack;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	request_t *pkt;
+ 	int ret = 0;
+ 
+ 	ql_dbg(ql_dbg_tgt_tmr, vha, 0xe01c,
+ 	    "Sending TERM ELS CTIO (ha=%p)\n", ha);
+ 
+ 	pkt = (request_t *)qla2x00_alloc_iocbs(vha, NULL);
+ 	if (pkt == NULL) {
+ 		ql_dbg(ql_dbg_tgt, vha, 0xe080,
+ 		    "qla_target(%d): %s failed: unable to allocate "
+ 		    "request packet\n", vha->vp_idx, __func__);
+ 		return -ENOMEM;
+ 	}
+ 
+ 	pkt->entry_type = NOTIFY_ACK_TYPE;
+ 	pkt->entry_count = 1;
+ 	pkt->handle = QLA_TGT_SKIP_HANDLE;
+ 
+ 	nack = (struct nack_to_isp *)pkt;
+ 	nack->ox_id = ntfy->ox_id;
+ 
+ 	nack->u.isp24.nport_handle = ntfy->u.isp24.nport_handle;
+ 	if (le16_to_cpu(ntfy->u.isp24.status) == IMM_NTFY_ELS) {
+ 		nack->u.isp24.flags = ntfy->u.isp24.flags &
+ 			__constant_cpu_to_le32(NOTIFY24XX_FLAGS_PUREX_IOCB);
+ 	}
+ 
+ 	/* terminate */
+ 	nack->u.isp24.flags |=
+ 		__constant_cpu_to_le16(NOTIFY_ACK_FLAGS_TERMINATE);
+ 
+ 	nack->u.isp24.srr_rx_id = ntfy->u.isp24.srr_rx_id;
+ 	nack->u.isp24.status = ntfy->u.isp24.status;
+ 	nack->u.isp24.status_subcode = ntfy->u.isp24.status_subcode;
+ 	nack->u.isp24.fw_handle = ntfy->u.isp24.fw_handle;
+ 	nack->u.isp24.exchange_address = ntfy->u.isp24.exchange_address;
+ 	nack->u.isp24.srr_rel_offs = ntfy->u.isp24.srr_rel_offs;
+ 	nack->u.isp24.srr_ui = ntfy->u.isp24.srr_ui;
+ 	nack->u.isp24.vp_index = ntfy->u.isp24.vp_index;
+ 
+ 	qla2x00_start_iocbs(vha, vha->req);
+ 	return ret;
+ }
  
- 	/* Does F/W have an IOCBs for this request */
- 	res = qlt_check_reserve_free_req(vha, prm.req_cnt);
- 	if (res != 0)
- 		goto out_unlock_free_unmap;
+ static void qlt_send_term_imm_notif(struct scsi_qla_host *vha,
+ 	struct imm_ntfy_from_isp *imm, int ha_locked)
+ {
+ 	unsigned long flags = 0;
+ 	int rc;
  
- 	res = qlt_24xx_build_ctio_pkt(&prm, vha);
- 	if (unlikely(res != 0))
- 		goto out_unlock_free_unmap;
- 	pkt = (struct ctio7_to_24xx *)prm.pkt;
- 	pkt->u.status0.flags |= cpu_to_le16(CTIO7_FLAGS_DATA_OUT |
- 	    CTIO7_FLAGS_STATUS_MODE_0);
- 	qlt_load_data_segments(&prm, vha);
+ 	if (qlt_issue_marker(vha, ha_locked) < 0)
+ 		return;
  
- 	cmd->state = QLA_TGT_STATE_NEED_DATA;
+ 	if (ha_locked) {
+ 		rc = __qlt_send_term_imm_notif(vha, imm);
  
- 	/* Memory Barrier */
- 	wmb();
- 	qla2x00_start_iocbs(vha, vha->req);
- 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+ #if 0	/* Todo  */
+ 		if (rc == -ENOMEM)
+ 			qlt_alloc_qfull_cmd(vha, imm, 0, 0);
+ #else
+ 		if (rc) {
+ 		}
+ #endif
+ 		goto done;
+ 	}
  
- 	return res;
+ 	spin_lock_irqsave(&vha->hw->hardware_lock, flags);
+ 	rc = __qlt_send_term_imm_notif(vha, imm);
  
- out_unlock_free_unmap:
- 	if (cmd->sg_mapped)
- 		qlt_unmap_sg(vha, cmd);
- 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+ #if 0	/* Todo */
+ 	if (rc == -ENOMEM)
+ 		qlt_alloc_qfull_cmd(vha, imm, 0, 0);
+ #endif
  
- 	return res;
+ done:
+ 	if (!ha_locked)
+ 		spin_unlock_irqrestore(&vha->hw->hardware_lock, flags);
  }
- EXPORT_SYMBOL(qlt_rdy_to_xfer);
- 
  
- /* If hardware_lock held on entry, might drop it, then reaquire */
- /* This function sends the appropriate CTIO to ISP 2xxx or 24xx */
+ /*
+  * If hardware_lock held on entry, might drop it, then reaquire
+  * This function sends the appropriate CTIO to ISP 2xxx or 24xx
+  */
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  static int __qlt_send_term_exchange(struct scsi_qla_host *vha,
  	struct qla_tgt_cmd *cmd,
  	struct atio_from_isp *atio)
@@@ -2204,10 -3449,11 +3100,10 @@@
  	struct qla_hw_data *ha = vha->hw;
  	request_t *pkt;
  	int ret = 0;
 -	uint16_t temp;
  
- 	ql_dbg(ql_dbg_tgt, vha, 0xe01c, "Sending TERM EXCH CTIO (ha=%p)\n", ha);
+ 	ql_dbg(ql_dbg_tgt, vha, 0xe009, "Sending TERM EXCH CTIO (ha=%p)\n", ha);
  
 -	pkt = (request_t *)qla2x00_alloc_iocbs_ready(vha, NULL);
 +	pkt = (request_t *)qla2x00_alloc_iocbs(vha, NULL);
  	if (pkt == NULL) {
  		ql_dbg(ql_dbg_tgt, vha, 0xe050,
  		    "qla_target(%d): %s failed: unable to allocate "
@@@ -2292,99 -3533,122 +3188,184 @@@ done
  	return;
  }
  
++<<<<<<< HEAD
++=======
+ static void qlt_init_term_exchange(struct scsi_qla_host *vha)
+ {
+ 	struct list_head free_list;
+ 	struct qla_tgt_cmd *cmd, *tcmd;
+ 
+ 	vha->hw->tgt.leak_exchg_thresh_hold =
+ 	    (vha->hw->cur_fw_xcb_count/100) * LEAK_EXCHG_THRESH_HOLD_PERCENT;
+ 
+ 	cmd = tcmd = NULL;
+ 	if (!list_empty(&vha->hw->tgt.q_full_list)) {
+ 		INIT_LIST_HEAD(&free_list);
+ 		list_splice_init(&vha->hw->tgt.q_full_list, &free_list);
+ 
+ 		list_for_each_entry_safe(cmd, tcmd, &free_list, cmd_list) {
+ 			list_del(&cmd->cmd_list);
+ 			/* This cmd was never sent to TCM.  There is no need
+ 			 * to schedule free or call free_cmd
+ 			 */
+ 			qlt_free_cmd(cmd);
+ 			vha->hw->tgt.num_qfull_cmds_alloc--;
+ 		}
+ 	}
+ 	vha->hw->tgt.num_qfull_cmds_dropped = 0;
+ }
+ 
+ static void qlt_chk_exch_leak_thresh_hold(struct scsi_qla_host *vha)
+ {
+ 	uint32_t total_leaked;
+ 
+ 	total_leaked = vha->hw->tgt.num_qfull_cmds_dropped;
+ 
+ 	if (vha->hw->tgt.leak_exchg_thresh_hold &&
+ 	    (total_leaked > vha->hw->tgt.leak_exchg_thresh_hold)) {
+ 
+ 		ql_dbg(ql_dbg_tgt, vha, 0xe079,
+ 		    "Chip reset due to exchange starvation: %d/%d.\n",
+ 		    total_leaked, vha->hw->cur_fw_xcb_count);
+ 
+ 		if (IS_P3P_TYPE(vha->hw))
+ 			set_bit(FCOE_CTX_RESET_NEEDED, &vha->dpc_flags);
+ 		else
+ 			set_bit(ISP_ABORT_NEEDED, &vha->dpc_flags);
+ 		qla2xxx_wake_dpc(vha);
+ 	}
+ 
+ }
+ 
+ int qlt_abort_cmd(struct qla_tgt_cmd *cmd)
+ {
+ 	struct qla_tgt *tgt = cmd->tgt;
+ 	struct scsi_qla_host *vha = tgt->vha;
+ 	struct se_cmd *se_cmd = &cmd->se_cmd;
+ 	unsigned long flags;
+ 
+ 	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf014,
+ 	    "qla_target(%d): terminating exchange for aborted cmd=%p "
+ 	    "(se_cmd=%p, tag=%llu)", vha->vp_idx, cmd, &cmd->se_cmd,
+ 	    se_cmd->tag);
+ 
+ 	spin_lock_irqsave(&cmd->cmd_lock, flags);
+ 	if (cmd->aborted) {
+ 		spin_unlock_irqrestore(&cmd->cmd_lock, flags);
+ 		/*
+ 		 * It's normal to see 2 calls in this path:
+ 		 *  1) XFER Rdy completion + CMD_T_ABORT
+ 		 *  2) TCM TMR - drain_state_list
+ 		 */
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf016,
+ 		    "multiple abort. %p transport_state %x, t_state %x, "
+ 		    "se_cmd_flags %x\n", cmd, cmd->se_cmd.transport_state,
+ 		    cmd->se_cmd.t_state, cmd->se_cmd.se_cmd_flags);
+ 		return EIO;
+ 	}
+ 	cmd->aborted = 1;
+ 	cmd->trc_flags |= TRC_ABORT;
+ 	spin_unlock_irqrestore(&cmd->cmd_lock, flags);
+ 
+ 	qlt_send_term_exchange(vha, cmd, &cmd->atio, 0, 1);
+ 	return 0;
+ }
+ EXPORT_SYMBOL(qlt_abort_cmd);
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  void qlt_free_cmd(struct qla_tgt_cmd *cmd)
  {
 -	struct fc_port *sess = cmd->sess;
 +	BUG_ON(cmd->sg_mapped);
 +
 +	if (unlikely(cmd->free_sg))
 +		kfree(cmd->sg);
 +	kmem_cache_free(qla_tgt_cmd_cachep, cmd);
 +}
 +EXPORT_SYMBOL(qlt_free_cmd);
 +
 +/* ha->hardware_lock supposed to be held on entry */
 +static int qlt_prepare_srr_ctio(struct scsi_qla_host *vha,
 +	struct qla_tgt_cmd *cmd, void *ctio)
 +{
 +	struct qla_tgt_srr_ctio *sc;
 +	struct qla_hw_data *ha = vha->hw;
 +	struct qla_tgt *tgt = ha->tgt.qla_tgt;
 +	struct qla_tgt_srr_imm *imm;
  
 -	ql_dbg(ql_dbg_tgt, cmd->vha, 0xe074,
 -	    "%s: se_cmd[%p] ox_id %04x\n",
 -	    __func__, &cmd->se_cmd,
 -	    be16_to_cpu(cmd->atio.u.isp24.fcp_hdr.ox_id));
 +	tgt->ctio_srr_id++;
  
 -	BUG_ON(cmd->cmd_in_wq);
 +	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf019,
 +	    "qla_target(%d): CTIO with SRR status received\n", vha->vp_idx);
  
 -	if (cmd->sg_mapped)
 -		qlt_unmap_sg(cmd->vha, cmd);
 +	if (!ctio) {
 +		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf055,
 +		    "qla_target(%d): SRR CTIO, but ctio is NULL\n",
 +		    vha->vp_idx);
 +		return -EINVAL;
 +	}
  
 -	if (!cmd->q_full)
 -		qlt_decr_num_pend_cmds(cmd->vha);
 +	sc = kzalloc(sizeof(*sc), GFP_ATOMIC);
 +	if (sc != NULL) {
 +		sc->cmd = cmd;
 +		/* IRQ is already OFF */
 +		spin_lock(&tgt->srr_lock);
 +		sc->srr_id = tgt->ctio_srr_id;
 +		list_add_tail(&sc->srr_list_entry,
 +		    &tgt->srr_ctio_list);
 +		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf01a,
 +		    "CTIO SRR %p added (id %d)\n", sc, sc->srr_id);
 +		if (tgt->imm_srr_id == tgt->ctio_srr_id) {
 +			int found = 0;
 +			list_for_each_entry(imm, &tgt->srr_imm_list,
 +			    srr_list_entry) {
 +				if (imm->srr_id == sc->srr_id) {
 +					found = 1;
 +					break;
 +				}
 +			}
 +			if (found) {
 +				ql_dbg(ql_dbg_tgt_mgt, vha, 0xf01b,
 +				    "Scheduling srr work\n");
 +				schedule_work(&tgt->srr_work);
 +			} else {
 +				ql_dbg(ql_dbg_tgt_mgt, vha, 0xf056,
 +				    "qla_target(%d): imm_srr_id "
 +				    "== ctio_srr_id (%d), but there is no "
 +				    "corresponding SRR IMM, deleting CTIO "
 +				    "SRR %p\n", vha->vp_idx,
 +				    tgt->ctio_srr_id, sc);
 +				list_del(&sc->srr_list_entry);
 +				spin_unlock(&tgt->srr_lock);
 +
 +				kfree(sc);
 +				return -EINVAL;
 +			}
 +		}
 +		spin_unlock(&tgt->srr_lock);
 +	} else {
 +		struct qla_tgt_srr_imm *ti;
  
 -	BUG_ON(cmd->sg_mapped);
 -	cmd->jiffies_at_free = get_jiffies_64();
 -	if (unlikely(cmd->free_sg))
 -		kfree(cmd->sg);
 +		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf057,
 +		    "qla_target(%d): Unable to allocate SRR CTIO entry\n",
 +		    vha->vp_idx);
 +		spin_lock(&tgt->srr_lock);
 +		list_for_each_entry_safe(imm, ti, &tgt->srr_imm_list,
 +		    srr_list_entry) {
 +			if (imm->srr_id == tgt->ctio_srr_id) {
 +				ql_dbg(ql_dbg_tgt_mgt, vha, 0xf01c,
 +				    "IMM SRR %p deleted (id %d)\n",
 +				    imm, imm->srr_id);
 +				list_del(&imm->srr_list_entry);
 +				qlt_reject_free_srr_imm(vha, imm, 1);
 +			}
 +		}
 +		spin_unlock(&tgt->srr_lock);
  
 -	if (!sess || !sess->se_sess) {
 -		WARN_ON(1);
 -		return;
 +		return -ENOMEM;
  	}
 -	cmd->jiffies_at_free = get_jiffies_64();
 -	percpu_ida_free(&sess->se_sess->sess_tag_pool, cmd->se_cmd.map_tag);
 +
 +	return 0;
  }
 -EXPORT_SYMBOL(qlt_free_cmd);
  
  /*
   * ha->hardware_lock supposed to be held on entry. Might drop it, then reaquire
@@@ -2394,6 -3658,16 +3375,19 @@@ static int qlt_term_ctio_exchange(struc
  {
  	int term = 0;
  
++<<<<<<< HEAD
++=======
+ 	if (cmd->se_cmd.prot_op)
+ 		ql_dbg(ql_dbg_tgt_dif, vha, 0xe013,
+ 		    "Term DIF cmd: lba[0x%llx|%lld] len[0x%x] "
+ 		    "se_cmd=%p tag[%x] op %#x/%s",
+ 		     cmd->lba, cmd->lba,
+ 		     cmd->num_blks, &cmd->se_cmd,
+ 		     cmd->atio.u.isp24.exchange_addr,
+ 		     cmd->se_cmd.prot_op,
+ 		     prot_op_str(cmd->se_cmd.prot_op));
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	if (ctio != NULL) {
  		struct ctio7_from_24xx *c = (struct ctio7_from_24xx *)ctio;
  		term = !(c->flags &
@@@ -2518,27 -3856,48 +3512,44 @@@ static void qlt_do_ctio_completion(stru
  
  		case CTIO_PORT_LOGGED_OUT:
  		case CTIO_PORT_UNAVAILABLE:
 -		{
 -			int logged_out =
 -				(status & 0xFFFF) == CTIO_PORT_LOGGED_OUT;
 -
  			ql_dbg(ql_dbg_tgt_mgt, vha, 0xf059,
 -			    "qla_target(%d): CTIO with %s status %x "
 +			    "qla_target(%d): CTIO with PORT LOGGED "
 +			    "OUT (29) or PORT UNAVAILABLE (28) status %x "
  			    "received (state %x, se_cmd %p)\n", vha->vp_idx,
 -			    logged_out ? "PORT LOGGED OUT" : "PORT UNAVAILABLE",
  			    status, cmd->state, se_cmd);
++<<<<<<< HEAD
++=======
+ 
+ 			if (logged_out && cmd->sess) {
+ 				/*
+ 				 * Session is already logged out, but we need
+ 				 * to notify initiator, who's not aware of this
+ 				 */
+ 				cmd->sess->logout_on_delete = 0;
+ 				cmd->sess->send_els_logo = 1;
+ 				ql_dbg(ql_dbg_disc, vha, 0x20f8,
+ 				    "%s %d %8phC post del sess\n",
+ 				    __func__, __LINE__, cmd->sess->port_name);
+ 
+ 				qlt_schedule_sess_for_deletion_lock(cmd->sess);
+ 			}
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  			break;
 -		}
 -		case CTIO_DIF_ERROR: {
 -			struct ctio_crc_from_fw *crc =
 -				(struct ctio_crc_from_fw *)ctio;
 -			ql_dbg(ql_dbg_tgt_mgt, vha, 0xf073,
 -			    "qla_target(%d): CTIO with DIF_ERROR status %x "
 -			    "received (state %x, ulp_cmd %p) actual_dif[0x%llx] "
 -			    "expect_dif[0x%llx]\n",
 -			    vha->vp_idx, status, cmd->state, se_cmd,
 -			    *((u64 *)&crc->actual_dif[0]),
 -			    *((u64 *)&crc->expected_dif[0]));
 -
 -			qlt_handle_dif_error(vha, cmd, ctio);
 -			return;
 -		}
 +
 +		case CTIO_SRR_RECEIVED:
 +			ql_dbg(ql_dbg_tgt_mgt, vha, 0xf05a,
 +			    "qla_target(%d): CTIO with SRR_RECEIVED"
 +			    " status %x received (state %x, se_cmd %p)\n",
 +			    vha->vp_idx, status, cmd->state, se_cmd);
 +			if (qlt_prepare_srr_ctio(vha, cmd, ctio) != 0)
 +				break;
 +			else
 +				return;
 +
  		default:
  			ql_dbg(ql_dbg_tgt_mgt, vha, 0xf05b,
 -			    "qla_target(%d): CTIO with error status 0x%x received (state %x, se_cmd %p\n",
 +			    "qla_target(%d): CTIO with error status "
 +			    "0x%x received (state %x, se_cmd %p\n",
  			    vha->vp_idx, status, cmd->state, se_cmd);
  			break;
  		}
@@@ -2737,10 -4194,52 +3748,53 @@@ static int qlt_handle_cmd_for_atio(stru
  		return -EFAULT;
  	}
  
++<<<<<<< HEAD
 +	cmd = kmem_cache_zalloc(qla_tgt_cmd_cachep, GFP_ATOMIC);
++=======
+ 	sess = ha->tgt.tgt_ops->find_sess_by_s_id(vha, atio->u.isp24.fcp_hdr.s_id);
+ 	if (unlikely(!sess)) {
+ 		struct qla_tgt_sess_op *op = kzalloc(sizeof(struct qla_tgt_sess_op),
+ 						     GFP_ATOMIC);
+ 		if (!op)
+ 			return -ENOMEM;
+ 
+ 		memcpy(&op->atio, atio, sizeof(*atio));
+ 		op->vha = vha;
+ 
+ 		spin_lock_irqsave(&vha->cmd_list_lock, flags);
+ 		list_add_tail(&op->cmd_list, &vha->qla_sess_op_cmd_list);
+ 		spin_unlock_irqrestore(&vha->cmd_list_lock, flags);
+ 
+ 		INIT_WORK(&op->work, qlt_create_sess_from_atio);
+ 		queue_work(qla_tgt_wq, &op->work);
+ 		return 0;
+ 	}
+ 
+ 	/* Another WWN used to have our s_id. Our PLOGI scheduled its
+ 	 * session deletion, but it's still in sess_del_work wq */
+ 	if (sess->deleted) {
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf002,
+ 		    "New command while old session %p is being deleted\n",
+ 		    sess);
+ 		return -EFAULT;
+ 	}
+ 
+ 	/*
+ 	 * Do kref_get() before returning + dropping qla_hw_data->hardware_lock.
+ 	 */
+ 	if (!kref_get_unless_zero(&sess->sess_kref)) {
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf004,
+ 		    "%s: kref_get fail, %8phC oxid %x \n",
+ 		    __func__, sess->port_name,
+ 		     be16_to_cpu(atio->u.isp24.fcp_hdr.ox_id));
+ 		return -EFAULT;
+ 	}
+ 
+ 	cmd = qlt_get_tag(vha, sess, atio);
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	if (!cmd) {
 -		ql_dbg(ql_dbg_io, vha, 0x3062,
 +		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf05e,
  		    "qla_target(%d): Allocation of cmd failed\n", vha->vp_idx);
 -		spin_lock_irqsave(&ha->tgt.sess_lock, flags);
 -		ha->tgt.tgt_ops->put_sess(sess);
 -		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
  		return -ENOMEM;
  	}
  
@@@ -2955,26 -4418,386 +4009,363 @@@ static int qlt_abort_task(struct scsi_q
  	return __qlt_abort_task(vha, iocb, sess);
  }
  
++<<<<<<< HEAD
++=======
+ void qlt_logo_completion_handler(fc_port_t *fcport, int rc)
+ {
+ 	if (rc != MBS_COMMAND_COMPLETE) {
+ 		ql_dbg(ql_dbg_tgt_mgt, fcport->vha, 0xf093,
+ 			"%s: se_sess %p / sess %p from"
+ 			" port %8phC loop_id %#04x s_id %02x:%02x:%02x"
+ 			" LOGO failed: %#x\n",
+ 			__func__,
+ 			fcport->se_sess,
+ 			fcport,
+ 			fcport->port_name, fcport->loop_id,
+ 			fcport->d_id.b.domain, fcport->d_id.b.area,
+ 			fcport->d_id.b.al_pa, rc);
+ 	}
+ 
+ 	fcport->logout_completed = 1;
+ }
+ 
+ /*
+ * ha->hardware_lock supposed to be held on entry (to protect tgt->sess_list)
+ *
+ * Schedules sessions with matching port_id/loop_id but different wwn for
+ * deletion. Returns existing session with matching wwn if present.
+ * Null otherwise.
+ */
+ struct fc_port *
+ qlt_find_sess_invalidate_other(scsi_qla_host_t *vha, uint64_t wwn,
+     port_id_t port_id, uint16_t loop_id, struct fc_port **conflict_sess)
+ {
+ 	struct fc_port *sess = NULL, *other_sess;
+ 	uint64_t other_wwn;
+ 
+ 	*conflict_sess = NULL;
+ 
+ 	list_for_each_entry(other_sess, &vha->vp_fcports, list) {
+ 
+ 		other_wwn = wwn_to_u64(other_sess->port_name);
+ 
+ 		if (wwn == other_wwn) {
+ 			WARN_ON(sess);
+ 			sess = other_sess;
+ 			continue;
+ 		}
+ 
+ 		/* find other sess with nport_id collision */
+ 		if (port_id.b24 == other_sess->d_id.b24) {
+ 			if (loop_id != other_sess->loop_id) {
+ 				ql_dbg(ql_dbg_tgt_tmr, vha, 0x1000c,
+ 				    "Invalidating sess %p loop_id %d wwn %llx.\n",
+ 				    other_sess, other_sess->loop_id, other_wwn);
+ 
+ 				/*
+ 				 * logout_on_delete is set by default, but another
+ 				 * session that has the same s_id/loop_id combo
+ 				 * might have cleared it when requested this session
+ 				 * deletion, so don't touch it
+ 				 */
+ 				qlt_schedule_sess_for_deletion(other_sess, true);
+ 			} else {
+ 				/*
+ 				 * Another wwn used to have our s_id/loop_id
+ 				 * kill the session, but don't free the loop_id
+ 				 */
+ 				ql_dbg(ql_dbg_tgt_tmr, vha, 0xf01b,
+ 				    "Invalidating sess %p loop_id %d wwn %llx.\n",
+ 				    other_sess, other_sess->loop_id, other_wwn);
+ 
+ 
+ 				other_sess->keep_nport_handle = 1;
+ 				*conflict_sess = other_sess;
+ 				qlt_schedule_sess_for_deletion(other_sess,
+ 				    true);
+ 			}
+ 			continue;
+ 		}
+ 
+ 		/* find other sess with nport handle collision */
+ 		if ((loop_id == other_sess->loop_id) &&
+ 			(loop_id != FC_NO_LOOP_ID)) {
+ 			ql_dbg(ql_dbg_tgt_tmr, vha, 0x1000d,
+ 			       "Invalidating sess %p loop_id %d wwn %llx.\n",
+ 			       other_sess, other_sess->loop_id, other_wwn);
+ 
+ 			/* Same loop_id but different s_id
+ 			 * Ok to kill and logout */
+ 			qlt_schedule_sess_for_deletion(other_sess, true);
+ 		}
+ 	}
+ 
+ 	return sess;
+ }
+ 
+ /* Abort any commands for this s_id waiting on qla_tgt_wq workqueue */
+ static int abort_cmds_for_s_id(struct scsi_qla_host *vha, port_id_t *s_id)
+ {
+ 	struct qla_tgt_sess_op *op;
+ 	struct qla_tgt_cmd *cmd;
+ 	uint32_t key;
+ 	int count = 0;
+ 	unsigned long flags;
+ 
+ 	key = (((u32)s_id->b.domain << 16) |
+ 	       ((u32)s_id->b.area   <<  8) |
+ 	       ((u32)s_id->b.al_pa));
+ 
+ 	spin_lock_irqsave(&vha->cmd_list_lock, flags);
+ 	list_for_each_entry(op, &vha->qla_sess_op_cmd_list, cmd_list) {
+ 		uint32_t op_key = sid_to_key(op->atio.u.isp24.fcp_hdr.s_id);
+ 
+ 		if (op_key == key) {
+ 			op->aborted = true;
+ 			count++;
+ 		}
+ 	}
+ 
+ 	list_for_each_entry(op, &vha->unknown_atio_list, cmd_list) {
+ 		uint32_t op_key = sid_to_key(op->atio.u.isp24.fcp_hdr.s_id);
+ 		if (op_key == key) {
+ 			op->aborted = true;
+ 			count++;
+ 		}
+ 	}
+ 
+ 	list_for_each_entry(cmd, &vha->qla_cmd_list, cmd_list) {
+ 		uint32_t cmd_key = sid_to_key(cmd->atio.u.isp24.fcp_hdr.s_id);
+ 		if (cmd_key == key) {
+ 			cmd->aborted = 1;
+ 			count++;
+ 		}
+ 	}
+ 	spin_unlock_irqrestore(&vha->cmd_list_lock, flags);
+ 
+ 	return count;
+ }
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  /*
   * ha->hardware_lock supposed to be held on entry. Might drop it, then reaquire
   */
  static int qlt_24xx_handle_els(struct scsi_qla_host *vha,
  	struct imm_ntfy_from_isp *iocb)
  {
 -	struct qla_tgt *tgt = vha->vha_tgt.qla_tgt;
  	struct qla_hw_data *ha = vha->hw;
 -	struct fc_port *sess = NULL, *conflict_sess = NULL;
 -	uint64_t wwn;
 -	port_id_t port_id;
 -	uint16_t loop_id;
 -	uint16_t wd3_lo;
  	int res = 0;
 -	struct qlt_plogi_ack_t *pla;
 -	unsigned long flags;
 -
 -	wwn = wwn_to_u64(iocb->u.isp24.port_name);
 -
 -	port_id.b.domain = iocb->u.isp24.port_id[2];
 -	port_id.b.area   = iocb->u.isp24.port_id[1];
 -	port_id.b.al_pa  = iocb->u.isp24.port_id[0];
 -	port_id.b.rsvd_1 = 0;
  
 -	loop_id = le16_to_cpu(iocb->u.isp24.nport_handle);
 -
 -	ql_dbg(ql_dbg_disc, vha, 0xf026,
 -	    "qla_target(%d): Port ID: %02x:%02x:%02x ELS opcode: 0x%02x lid %d %8phC\n",
 -	    vha->vp_idx, iocb->u.isp24.port_id[2],
 -		iocb->u.isp24.port_id[1], iocb->u.isp24.port_id[0],
 -		   iocb->u.isp24.status_subcode, loop_id,
 -		iocb->u.isp24.port_name);
 +	ql_dbg(ql_dbg_tgt_mgt, vha, 0xf026,
 +	    "qla_target(%d): Port ID: 0x%3phC ELS opcode: 0x%02x\n",
 +	    vha->vp_idx, iocb->u.isp24.port_id, iocb->u.isp24.status_subcode);
  
 -	/* res = 1 means ack at the end of thread
 -	 * res = 0 means ack async/later.
 -	 */
  	switch (iocb->u.isp24.status_subcode) {
  	case ELS_PLOGI:
++<<<<<<< HEAD
 +	case ELS_FLOGI:
 +	case ELS_PRLI:
++=======
+ 
+ 		/* Mark all stale commands in qla_tgt_wq for deletion */
+ 		abort_cmds_for_s_id(vha, &port_id);
+ 
+ 		if (wwn) {
+ 			spin_lock_irqsave(&tgt->ha->tgt.sess_lock, flags);
+ 			sess = qlt_find_sess_invalidate_other(vha, wwn,
+ 				port_id, loop_id, &conflict_sess);
+ 			spin_unlock_irqrestore(&tgt->ha->tgt.sess_lock, flags);
+ 		}
+ 
+ 		if (IS_SW_RESV_ADDR(port_id)) {
+ 			res = 1;
+ 			break;
+ 		}
+ 
+ 		pla = qlt_plogi_ack_find_add(vha, &port_id, iocb);
+ 		if (!pla) {
+ 			qlt_send_term_imm_notif(vha, iocb, 1);
+ 			break;
+ 		}
+ 
+ 		res = 0;
+ 
+ 		if (conflict_sess) {
+ 			conflict_sess->login_gen++;
+ 			qlt_plogi_ack_link(vha, pla, conflict_sess,
+ 				QLT_PLOGI_LINK_CONFLICT);
+ 		}
+ 
+ 		if (!sess) {
+ 			pla->ref_count++;
+ 			qla24xx_post_newsess_work(vha, &port_id,
+ 				iocb->u.isp24.port_name, pla);
+ 			res = 0;
+ 			break;
+ 		}
+ 
+ 		qlt_plogi_ack_link(vha, pla, sess, QLT_PLOGI_LINK_SAME_WWN);
+ 		sess->fw_login_state = DSC_LS_PLOGI_PEND;
+ 		sess->d_id = port_id;
+ 		sess->login_gen++;
+ 
+ 		switch (sess->disc_state) {
+ 		case DSC_DELETED:
+ 			qlt_plogi_ack_unref(vha, pla);
+ 			break;
+ 
+ 		default:
+ 			/*
+ 			 * Under normal circumstances we want to release nport handle
+ 			 * during LOGO process to avoid nport handle leaks inside FW.
+ 			 * The exception is when LOGO is done while another PLOGI with
+ 			 * the same nport handle is waiting as might be the case here.
+ 			 * Note: there is always a possibily of a race where session
+ 			 * deletion has already started for other reasons (e.g. ACL
+ 			 * removal) and now PLOGI arrives:
+ 			 * 1. if PLOGI arrived in FW after nport handle has been freed,
+ 			 *    FW must have assigned this PLOGI a new/same handle and we
+ 			 *    can proceed ACK'ing it as usual when session deletion
+ 			 *    completes.
+ 			 * 2. if PLOGI arrived in FW before LOGO with LCF_FREE_NPORT
+ 			 *    bit reached it, the handle has now been released. We'll
+ 			 *    get an error when we ACK this PLOGI. Nothing will be sent
+ 			 *    back to initiator. Initiator should eventually retry
+ 			 *    PLOGI and situation will correct itself.
+ 			 */
+ 			sess->keep_nport_handle = ((sess->loop_id == loop_id) &&
+ 			   (sess->d_id.b24 == port_id.b24));
+ 
+ 			ql_dbg(ql_dbg_disc, vha, 0x20f9,
+ 			    "%s %d %8phC post del sess\n",
+ 			    __func__, __LINE__, sess->port_name);
+ 
+ 
+ 			qlt_schedule_sess_for_deletion_lock(sess);
+ 			break;
+ 		}
+ 
+ 		break;
+ 
+ 	case ELS_PRLI:
+ 		wd3_lo = le16_to_cpu(iocb->u.isp24.u.prli.wd3_lo);
+ 
+ 		if (wwn) {
+ 			spin_lock_irqsave(&tgt->ha->tgt.sess_lock, flags);
+ 			sess = qlt_find_sess_invalidate_other(vha, wwn, port_id,
+ 				loop_id, &conflict_sess);
+ 			spin_unlock_irqrestore(&tgt->ha->tgt.sess_lock, flags);
+ 		}
+ 
+ 		if (conflict_sess) {
+ 			ql_dbg(ql_dbg_tgt_mgt, vha, 0xf09b,
+ 			    "PRLI with conflicting sess %p port %8phC\n",
+ 			    conflict_sess, conflict_sess->port_name);
+ 			qlt_send_term_imm_notif(vha, iocb, 1);
+ 			res = 0;
+ 			break;
+ 		}
+ 
+ 		if (sess != NULL) {
+ 			if (sess->fw_login_state != DSC_LS_PLOGI_PEND &&
+ 			    sess->fw_login_state != DSC_LS_PLOGI_COMP) {
+ 				/*
+ 				 * Impatient initiator sent PRLI before last
+ 				 * PLOGI could finish. Will force him to re-try,
+ 				 * while last one finishes.
+ 				 */
+ 				ql_log(ql_log_warn, sess->vha, 0xf095,
+ 				    "sess %p PRLI received, before plogi ack.\n",
+ 				    sess);
+ 				qlt_send_term_imm_notif(vha, iocb, 1);
+ 				res = 0;
+ 				break;
+ 			}
+ 
+ 			/*
+ 			 * This shouldn't happen under normal circumstances,
+ 			 * since we have deleted the old session during PLOGI
+ 			 */
+ 			ql_dbg(ql_dbg_tgt_mgt, vha, 0xf096,
+ 			    "PRLI (loop_id %#04x) for existing sess %p (loop_id %#04x)\n",
+ 			    sess->loop_id, sess, iocb->u.isp24.nport_handle);
+ 
+ 			sess->local = 0;
+ 			sess->loop_id = loop_id;
+ 			sess->d_id = port_id;
+ 			sess->fw_login_state = DSC_LS_PRLI_PEND;
+ 
+ 			if (wd3_lo & BIT_7)
+ 				sess->conf_compl_supported = 1;
+ 
+ 			if ((wd3_lo & BIT_4) == 0)
+ 				sess->port_type = FCT_INITIATOR;
+ 			else
+ 				sess->port_type = FCT_TARGET;
+ 		}
+ 		res = 1; /* send notify ack */
+ 
+ 		/* Make session global (not used in fabric mode) */
+ 		if (ha->current_topology != ISP_CFG_F) {
+ 			if (sess) {
+ 				ql_dbg(ql_dbg_disc, vha, 0x20fa,
+ 				    "%s %d %8phC post nack\n",
+ 				    __func__, __LINE__, sess->port_name);
+ 				qla24xx_post_nack_work(vha, sess, iocb,
+ 					SRB_NACK_PRLI);
+ 				res = 0;
+ 			} else {
+ 				set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 				set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 				qla2xxx_wake_dpc(vha);
+ 			}
+ 		} else {
+ 			if (sess) {
+ 				ql_dbg(ql_dbg_disc, vha, 0x20fb,
+ 				    "%s %d %8phC post nack\n",
+ 				    __func__, __LINE__, sess->port_name);
+ 				qla24xx_post_nack_work(vha, sess, iocb,
+ 					SRB_NACK_PRLI);
+ 				res = 0;
+ 			}
+ 		}
+ 		break;
+ 
+ 	case ELS_TPRLO:
+ 		if (le16_to_cpu(iocb->u.isp24.flags) &
+ 			NOTIFY24XX_FLAGS_GLOBAL_TPRLO) {
+ 			loop_id = 0xFFFF;
+ 			qlt_reset(vha, iocb, QLA_TGT_NEXUS_LOSS);
+ 			res = 1;
+ 			break;
+ 		}
+ 		/* drop through */
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	case ELS_LOGO:
  	case ELS_PRLO:
 -		spin_lock_irqsave(&ha->tgt.sess_lock, flags);
 -		sess = qla2x00_find_fcport_by_loopid(vha, loop_id);
 -		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
 -
 -		if (sess) {
 -			sess->login_gen++;
 -			sess->fw_login_state = DSC_LS_LOGO_PEND;
 -			sess->logo_ack_needed = 1;
 -			memcpy(sess->iocb, iocb, IOCB_SIZE);
 -		}
 -
  		res = qlt_reset(vha, iocb, QLA_TGT_NEXUS_LOSS_SESS);
++<<<<<<< HEAD
++=======
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0x20fc,
+ 		    "%s: logo %llx res %d sess %p ",
+ 		    __func__, wwn, res, sess);
+ 		if (res == 0) {
+ 			/*
+ 			 * cmd went upper layer, look for qlt_xmit_tm_rsp()
+ 			 * for LOGO_ACK & sess delete
+ 			 */
+ 			BUG_ON(!sess);
+ 			res = 0;
+ 		} else {
+ 			/* cmd did not go to upper layer. */
+ 			if (sess) {
+ 				qlt_schedule_sess_for_deletion_lock(sess);
+ 				res = 0;
+ 			}
+ 			/* else logo will be ack */
+ 		}
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  		break;
  	case ELS_PDISC:
  	case ELS_ADISC:
@@@ -2985,6 -4808,16 +4376,19 @@@
  			    0, 0, 0, 0, 0, 0);
  			tgt->link_reinit_iocb_pending = 0;
  		}
++<<<<<<< HEAD
++=======
+ 
+ 		sess = qla2x00_find_fcport_by_wwpn(vha,
+ 		    iocb->u.isp24.port_name, 1);
+ 		if (sess) {
+ 			ql_dbg(ql_dbg_disc, vha, 0x20fd,
+ 				"sess %p lid %d|%d DS %d LS %d\n",
+ 				sess, sess->loop_id, loop_id,
+ 				sess->disc_state, sess->fw_login_state);
+ 		}
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  		res = 1; /* send notify ack */
  		break;
  	}
@@@ -4014,6 -5585,32 +5418,35 @@@ void qlt_async_event(uint16_t code, str
  		    le16_to_cpu(mailbox[2]), le16_to_cpu(mailbox[3]));
  		break;
  
++<<<<<<< HEAD
++=======
+ 	case MBA_REJECTED_FCP_CMD:
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf017,
+ 		    "qla_target(%d): Async event LS_REJECT occurred (m[0]=%x, m[1]=%x, m[2]=%x, m[3]=%x)",
+ 		    vha->vp_idx,
+ 		    le16_to_cpu(mailbox[0]), le16_to_cpu(mailbox[1]),
+ 		    le16_to_cpu(mailbox[2]), le16_to_cpu(mailbox[3]));
+ 
+ 		if (le16_to_cpu(mailbox[3]) == 1) {
+ 			/* exchange starvation. */
+ 			vha->hw->exch_starvation++;
+ 			if (vha->hw->exch_starvation > 5) {
+ 				ql_log(ql_log_warn, vha, 0xd03a,
+ 				    "Exchange starvation-. Resetting RISC\n");
+ 
+ 				vha->hw->exch_starvation = 0;
+ 				if (IS_P3P_TYPE(vha->hw))
+ 					set_bit(FCOE_CTX_RESET_NEEDED,
+ 					    &vha->dpc_flags);
+ 				else
+ 					set_bit(ISP_ABORT_NEEDED,
+ 					    &vha->dpc_flags);
+ 				qla2xxx_wake_dpc(vha);
+ 			}
+ 		}
+ 		break;
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	case MBA_PORT_UPDATE:
  		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf03d,
  		    "qla_target(%d): Port update async event %#x "
@@@ -4071,6 -5663,59 +5504,62 @@@ static fc_port_t *qlt_get_port_database
  		return NULL;
  	}
  
++<<<<<<< HEAD
++=======
+ 	del = NULL;
+ 	spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 	tfcp = qla2x00_find_fcport_by_wwpn(vha, fcport->port_name, 1);
+ 
+ 	if (tfcp) {
+ 		tfcp->d_id = fcport->d_id;
+ 		tfcp->port_type = fcport->port_type;
+ 		tfcp->supported_classes = fcport->supported_classes;
+ 		tfcp->flags |= fcport->flags;
+ 
+ 		del = fcport;
+ 		fcport = tfcp;
+ 	} else {
+ 		if (vha->hw->current_topology == ISP_CFG_F)
+ 			fcport->flags |= FCF_FABRIC_DEVICE;
+ 
+ 		list_add_tail(&fcport->list, &vha->vp_fcports);
+ 		if (!IS_SW_RESV_ADDR(fcport->d_id))
+ 		   vha->fcport_count++;
+ 		fcport->login_gen++;
+ 		fcport->disc_state = DSC_LOGIN_COMPLETE;
+ 		fcport->login_succ = 1;
+ 		newfcport = 1;
+ 	}
+ 
+ 	fcport->deleted = 0;
+ 	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 
+ 	switch (vha->host->active_mode) {
+ 	case MODE_INITIATOR:
+ 	case MODE_DUAL:
+ 		if (newfcport) {
+ 			if (!IS_IIDMA_CAPABLE(vha->hw) || !vha->hw->flags.gpsc_supported) {
+ 				ql_dbg(ql_dbg_disc, vha, 0x20fe,
+ 				   "%s %d %8phC post upd_fcport fcp_cnt %d\n",
+ 				   __func__, __LINE__, fcport->port_name, vha->fcport_count);
+ 				qla24xx_post_upd_fcport_work(vha, fcport);
+ 			} else {
+ 				ql_dbg(ql_dbg_disc, vha, 0x20ff,
+ 				   "%s %d %8phC post gpsc fcp_cnt %d\n",
+ 				   __func__, __LINE__, fcport->port_name, vha->fcport_count);
+ 				qla24xx_post_gpsc_work(vha, fcport);
+ 			}
+ 		}
+ 		break;
+ 
+ 	case MODE_TARGET:
+ 	default:
+ 		break;
+ 	}
+ 	if (del)
+ 		qla2x00_free_fcport(del);
+ 
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	return fcport;
  }
  
@@@ -4150,36 -5812,46 +5639,51 @@@ static void qlt_abort_work(struct qla_t
  	sess = ha->tgt.tgt_ops->find_sess_by_s_id(vha,
  	    (unsigned char *)&be_s_id);
  	if (!sess) {
 -		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags2);
 +		spin_unlock_irqrestore(&ha->hardware_lock, flags);
  
 +		mutex_lock(&ha->tgt.tgt_mutex);
  		sess = qlt_make_local_sess(vha, s_id);
  		/* sess has got an extra creation ref */
 +		mutex_unlock(&ha->tgt.tgt_mutex);
  
 -		spin_lock_irqsave(&ha->tgt.sess_lock, flags2);
 +		spin_lock_irqsave(&ha->hardware_lock, flags);
  		if (!sess)
 -			goto out_term2;
 +			goto out_term;
  	} else {
++<<<<<<< HEAD
 +		kref_get(&sess->se_sess->sess_kref);
++=======
+ 		if (sess->deleted) {
+ 			sess = NULL;
+ 			goto out_term2;
+ 		}
+ 
+ 		if (!kref_get_unless_zero(&sess->sess_kref)) {
+ 			ql_dbg(ql_dbg_tgt_tmr, vha, 0xf01c,
+ 			    "%s: kref_get fail %8phC \n",
+ 			     __func__, sess->port_name);
+ 			sess = NULL;
+ 			goto out_term2;
+ 		}
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	}
  
 -	rc = __qlt_24xx_handle_abts(vha, &prm->abts, sess);
 -	ha->tgt.tgt_ops->put_sess(sess);
 -	spin_unlock_irqrestore(&ha->tgt.sess_lock, flags2);
 +	if (tgt->tgt_stop)
 +		goto out_term;
  
 +	rc = __qlt_24xx_handle_abts(vha, &prm->abts, sess);
  	if (rc != 0)
  		goto out_term;
 -	return;
 +	spin_unlock_irqrestore(&ha->hardware_lock, flags);
  
 -out_term2:
 -	if (sess)
 -		ha->tgt.tgt_ops->put_sess(sess);
 -	spin_unlock_irqrestore(&ha->tgt.sess_lock, flags2);
 +	ha->tgt.tgt_ops->put_sess(sess);
 +	return;
  
  out_term:
 -	spin_lock_irqsave(&ha->hardware_lock, flags);
  	qlt_24xx_send_abts_resp(vha, &prm->abts, FCP_TMF_REJECTED, false);
  	spin_unlock_irqrestore(&ha->hardware_lock, flags);
 +	if (sess)
 +		ha->tgt.tgt_ops->put_sess(sess);
  }
  
  static void qlt_tmr_work(struct qla_tgt *tgt,
@@@ -4204,18 -5876,27 +5708,33 @@@
  	s_id = prm->tm_iocb2.u.isp24.fcp_hdr.s_id;
  	sess = ha->tgt.tgt_ops->find_sess_by_s_id(vha, s_id);
  	if (!sess) {
 -		spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
 +		spin_unlock_irqrestore(&ha->hardware_lock, flags);
  
 +		mutex_lock(&ha->tgt.tgt_mutex);
  		sess = qlt_make_local_sess(vha, s_id);
  		/* sess has got an extra creation ref */
 +		mutex_unlock(&ha->tgt.tgt_mutex);
  
 -		spin_lock_irqsave(&ha->tgt.sess_lock, flags);
 +		spin_lock_irqsave(&ha->hardware_lock, flags);
  		if (!sess)
 -			goto out_term2;
 +			goto out_term;
  	} else {
++<<<<<<< HEAD
 +		kref_get(&sess->se_sess->sess_kref);
++=======
+ 		if (sess->deleted) {
+ 			sess = NULL;
+ 			goto out_term2;
+ 		}
+ 
+ 		if (!kref_get_unless_zero(&sess->sess_kref)) {
+ 			ql_dbg(ql_dbg_tgt_tmr, vha, 0xf020,
+ 			    "%s: kref_get fail %8phC\n",
+ 			     __func__, sess->port_name);
+ 			sess = NULL;
+ 			goto out_term2;
+ 		}
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  	}
  
  	iocb = a;
@@@ -4544,9 -6235,25 +6063,31 @@@ qlt_enable_vha(struct scsi_qla_host *vh
  	qlt_set_mode(vha);
  	spin_unlock_irqrestore(&ha->hardware_lock, flags);
  
++<<<<<<< HEAD
 +	set_bit(ISP_ABORT_NEEDED, &vha->dpc_flags);
 +	qla2xxx_wake_dpc(vha);
 +	qla2x00_wait_for_hba_online(vha);
++=======
+ 	if (vha->vp_idx) {
+ 		qla24xx_disable_vp(vha);
+ 		qla24xx_enable_vp(vha);
+ 	} else {
+ 		if (ha->msix_entries) {
+ 			ql_dbg(ql_dbg_tgt, vha, 0xe081,
+ 			    "%s: host%ld : vector %d cpu %d\n",
+ 			    __func__, vha->host_no,
+ 			    ha->msix_entries[rspq_ent].vector,
+ 			    ha->msix_entries[rspq_ent].cpuid);
+ 
+ 			ha->tgt.rspq_vector_cpuid =
+ 			    ha->msix_entries[rspq_ent].cpuid;
+ 		}
+ 
+ 		set_bit(ISP_ABORT_NEEDED, &base_vha->dpc_flags);
+ 		qla2xxx_wake_dpc(base_vha);
+ 		qla2x00_wait_for_hba_online(base_vha);
+ 	}
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  }
  EXPORT_SYMBOL(qlt_enable_vha);
  
@@@ -4664,7 -6370,24 +6205,28 @@@ qlt_24xx_process_atio_queue(struct scsi
  		pkt = (struct atio_from_isp *)ha->tgt.atio_ring_ptr;
  		cnt = pkt->u.raw.entry_count;
  
++<<<<<<< HEAD
 +		qlt_24xx_atio_pkt_all_vps(vha, (struct atio_from_isp *)pkt);
++=======
+ 		if (unlikely(fcpcmd_is_corrupted(ha->tgt.atio_ring_ptr))) {
+ 			/*
+ 			 * This packet is corrupted. The header + payload
+ 			 * can not be trusted. There is no point in passing
+ 			 * it further up.
+ 			 */
+ 			ql_log(ql_log_warn, vha, 0xd03c,
+ 			    "corrupted fcp frame SID[%3phN] OXID[%04x] EXCG[%x] %64phN\n",
+ 			    pkt->u.isp24.fcp_hdr.s_id,
+ 			    be16_to_cpu(pkt->u.isp24.fcp_hdr.ox_id),
+ 			    le32_to_cpu(pkt->u.isp24.exchange_addr), pkt);
+ 
+ 			adjust_corrupted_atio(pkt);
+ 			qlt_send_term_exchange(vha, NULL, pkt, ha_locked, 0);
+ 		} else {
+ 			qlt_24xx_atio_pkt_all_vps(vha,
+ 			    (struct atio_from_isp *)pkt, ha_locked);
+ 		}
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  
  		for (i = 0; i < cnt; i++) {
  			ha->tgt.atio_ring_index++;
@@@ -4936,9 -6722,21 +6498,19 @@@ qlt_probe_one_stage1(struct scsi_qla_ho
  		ISP_ATIO_Q_OUT(base_vha) = &ha->iobase->isp24.atio_q_out;
  	}
  
 -	mutex_init(&base_vha->vha_tgt.tgt_mutex);
 -	mutex_init(&base_vha->vha_tgt.tgt_host_action_mutex);
 -
 -	INIT_LIST_HEAD(&base_vha->unknown_atio_list);
 -	INIT_DELAYED_WORK(&base_vha->unknown_atio_work,
 -	    qlt_unknown_atio_work_fn);
 -
 +	mutex_init(&ha->tgt.tgt_mutex);
 +	mutex_init(&ha->tgt.tgt_host_action_mutex);
  	qlt_clear_mode(base_vha);
++<<<<<<< HEAD
++=======
+ 
+ 	rc = btree_init32(&ha->tgt.host_map);
+ 	if (rc)
+ 		ql_log(ql_log_info, base_vha, 0xd03d,
+ 		    "Unable to initialize ha->host_map btree\n");
+ 
+ 	qlt_update_vp_map(base_vha, SET_VP_IDX);
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  }
  
  irqreturn_t
@@@ -5010,13 -6859,32 +6582,40 @@@ qlt_update_vp_map(struct scsi_qla_host 
  		vha->hw->tgt.tgt_vp_map[vha->vp_idx].vha = vha;
  		break;
  	case SET_AL_PA:
++<<<<<<< HEAD
 +		vha->hw->tgt.tgt_vp_map[vha->d_id.b.al_pa].idx = vha->vp_idx;
++=======
+ 		slot = btree_lookup32(&vha->hw->tgt.host_map, key);
+ 		if (!slot) {
+ 			ql_dbg(ql_dbg_tgt_mgt, vha, 0xf018,
+ 			    "Save vha in host_map %p %06x\n", vha, key);
+ 			rc = btree_insert32(&vha->hw->tgt.host_map,
+ 				key, vha, GFP_ATOMIC);
+ 			if (rc)
+ 				ql_log(ql_log_info, vha, 0xd03e,
+ 				    "Unable to insert s_id into host_map: %06x\n",
+ 				    key);
+ 			return;
+ 		}
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf019,
+ 		    "replace existing vha in host_map %p %06x\n", vha, key);
+ 		btree_update32(&vha->hw->tgt.host_map, key, vha);
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  		break;
  	case RESET_VP_IDX:
  		vha->hw->tgt.tgt_vp_map[vha->vp_idx].vha = NULL;
  		break;
  	case RESET_AL_PA:
++<<<<<<< HEAD
 +		vha->hw->tgt.tgt_vp_map[vha->d_id.b.al_pa].idx = 0;
++=======
+ 		ql_dbg(ql_dbg_tgt_mgt, vha, 0xf01a,
+ 		   "clear vha in host_map %p %06x\n", vha, key);
+ 		slot = btree_lookup32(&vha->hw->tgt.host_map, key);
+ 		if (slot)
+ 			btree_remove32(&vha->hw->tgt.host_map, key);
+ 		vha->d_id.b24 = 0;
++>>>>>>> 83548fe2fcbb (scsi: qla2xxx: Cleanup debug message IDs)
  		break;
  	}
  }
@@@ -5061,10 -6941,20 +6660,10 @@@ int __init qlt_init(void
  	    sizeof(struct qla_tgt_mgmt_cmd), __alignof__(struct
  	    qla_tgt_mgmt_cmd), 0, NULL);
  	if (!qla_tgt_mgmt_cmd_cachep) {
- 		ql_log(ql_log_fatal, NULL, 0xe06d,
+ 		ql_log(ql_log_fatal, NULL, 0xd04b,
  		    "kmem_cache_create for qla_tgt_mgmt_cmd_cachep failed\n");
 -		return -ENOMEM;
 -	}
 -
 -	qla_tgt_plogi_cachep = kmem_cache_create("qla_tgt_plogi_cachep",
 -	    sizeof(struct qlt_plogi_ack_t), __alignof__(struct qlt_plogi_ack_t),
 -	    0, NULL);
 -
 -	if (!qla_tgt_plogi_cachep) {
 -		ql_log(ql_log_fatal, NULL, 0xe06d,
 -		    "kmem_cache_create for qla_tgt_plogi_cachep failed\n");
  		ret = -ENOMEM;
 -		goto out_mgmt_cmd_cachep;
 +		goto out;
  	}
  
  	qla_tgt_mgmt_cmd_mempool = mempool_create(25, mempool_alloc_slab,
* Unmerged path drivers/scsi/qla2xxx/qla_attr.c
diff --git a/drivers/scsi/qla2xxx/qla_bsg.c b/drivers/scsi/qla2xxx/qla_bsg.c
index f25c5e89826a..3f3c219414c3 100644
--- a/drivers/scsi/qla2xxx/qla_bsg.c
+++ b/drivers/scsi/qla2xxx/qla_bsg.c
@@ -2091,7 +2091,7 @@ qla8044_serdes_op(struct fc_bsg_job *bsg_job)
 		bsg_job->reply->reply_payload_rcv_len = sizeof(sr);
 		break;
 	default:
-		ql_dbg(ql_dbg_user, vha, 0x70cf,
+		ql_dbg(ql_dbg_user, vha, 0x7020,
 		    "Unknown serdes cmd %x.\n", sr.cmd);
 		rval = -EINVAL;
 		break;
* Unmerged path drivers/scsi/qla2xxx/qla_dbg.c
* Unmerged path drivers/scsi/qla2xxx/qla_dfs.c
* Unmerged path drivers/scsi/qla2xxx/qla_gs.c
* Unmerged path drivers/scsi/qla2xxx/qla_init.c
* Unmerged path drivers/scsi/qla2xxx/qla_isr.c
* Unmerged path drivers/scsi/qla2xxx/qla_mbx.c
* Unmerged path drivers/scsi/qla2xxx/qla_os.c
* Unmerged path drivers/scsi/qla2xxx/qla_target.c
