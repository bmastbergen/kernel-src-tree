KVM: lapic: reorganize restart_apic_timer

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Paolo Bonzini <pbonzini@redhat.com>
commit a749e247f745f609fd1106f1400ea063fe9b18ba
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/a749e247.failed

Move the code to cancel the hv timer into the caller, just before
it starts the hrtimer.  Check availability of the hv timer in
start_hv_timer.

	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit a749e247f745f609fd1106f1400ea063fe9b18ba)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/lapic.c
#	arch/x86/kvm/lapic.h
#	arch/x86/kvm/x86.c
diff --cc arch/x86/kvm/lapic.c
index 0e8704ed991e,a80e5a5d6f2f..000000000000
--- a/arch/x86/kvm/lapic.c
+++ b/arch/x86/kvm/lapic.c
@@@ -1373,53 -1411,197 +1373,246 @@@ static void start_sw_tscdeadline(struc
  	local_irq_restore(flags);
  }
  
++<<<<<<< HEAD
++=======
+ static void start_sw_period(struct kvm_lapic *apic)
+ {
+ 	if (!apic->lapic_timer.period)
+ 		return;
+ 
+ 	if (apic_lvtt_oneshot(apic) &&
+ 	    ktime_after(ktime_get(),
+ 			apic->lapic_timer.target_expiration)) {
+ 		apic_timer_expired(apic);
+ 		return;
+ 	}
+ 
+ 	hrtimer_start(&apic->lapic_timer.timer,
+ 		apic->lapic_timer.target_expiration,
+ 		HRTIMER_MODE_ABS_PINNED);
+ }
+ 
+ static bool set_target_expiration(struct kvm_lapic *apic)
+ {
+ 	ktime_t now;
+ 	u64 tscl = rdtsc();
+ 
+ 	now = ktime_get();
+ 	apic->lapic_timer.period = (u64)kvm_lapic_get_reg(apic, APIC_TMICT)
+ 		* APIC_BUS_CYCLE_NS * apic->divide_count;
+ 
+ 	if (!apic->lapic_timer.period)
+ 		return false;
+ 
+ 	/*
+ 	 * Do not allow the guest to program periodic timers with small
+ 	 * interval, since the hrtimers are not throttled by the host
+ 	 * scheduler.
+ 	 */
+ 	if (apic_lvtt_period(apic)) {
+ 		s64 min_period = min_timer_period_us * 1000LL;
+ 
+ 		if (apic->lapic_timer.period < min_period) {
+ 			pr_info_ratelimited(
+ 			    "kvm: vcpu %i: requested %lld ns "
+ 			    "lapic timer period limited to %lld ns\n",
+ 			    apic->vcpu->vcpu_id,
+ 			    apic->lapic_timer.period, min_period);
+ 			apic->lapic_timer.period = min_period;
+ 		}
+ 	}
+ 
+ 	apic_debug("%s: bus cycle is %" PRId64 "ns, now 0x%016"
+ 		   PRIx64 ", "
+ 		   "timer initial count 0x%x, period %lldns, "
+ 		   "expire @ 0x%016" PRIx64 ".\n", __func__,
+ 		   APIC_BUS_CYCLE_NS, ktime_to_ns(now),
+ 		   kvm_lapic_get_reg(apic, APIC_TMICT),
+ 		   apic->lapic_timer.period,
+ 		   ktime_to_ns(ktime_add_ns(now,
+ 				apic->lapic_timer.period)));
+ 
+ 	apic->lapic_timer.tscdeadline = kvm_read_l1_tsc(apic->vcpu, tscl) +
+ 		nsec_to_cycles(apic->vcpu, apic->lapic_timer.period);
+ 	apic->lapic_timer.target_expiration = ktime_add_ns(now, apic->lapic_timer.period);
+ 
+ 	return true;
+ }
+ 
+ static void advance_periodic_target_expiration(struct kvm_lapic *apic)
+ {
+ 	apic->lapic_timer.tscdeadline +=
+ 		nsec_to_cycles(apic->vcpu, apic->lapic_timer.period);
+ 	apic->lapic_timer.target_expiration =
+ 		ktime_add_ns(apic->lapic_timer.target_expiration,
+ 				apic->lapic_timer.period);
+ }
+ 
+ bool kvm_lapic_hv_timer_in_use(struct kvm_vcpu *vcpu)
+ {
+ 	if (!lapic_in_kernel(vcpu))
+ 		return false;
+ 
+ 	return vcpu->arch.apic->lapic_timer.hv_timer_in_use;
+ }
+ EXPORT_SYMBOL_GPL(kvm_lapic_hv_timer_in_use);
+ 
+ static void cancel_hv_timer(struct kvm_lapic *apic)
+ {
+ 	WARN_ON(!apic->lapic_timer.hv_timer_in_use);
+ 	preempt_disable();
+ 	kvm_x86_ops->cancel_hv_timer(apic->vcpu);
+ 	apic->lapic_timer.hv_timer_in_use = false;
+ 	preempt_enable();
+ }
+ 
+ static bool start_hv_timer(struct kvm_lapic *apic)
+ {
+ 	struct kvm_timer *ktimer = &apic->lapic_timer;
+ 	int r;
+ 
+ 	if (!kvm_x86_ops->set_hv_timer)
+ 		return false;
+ 
+ 	if (!apic_lvtt_period(apic) && atomic_read(&ktimer->pending))
+ 		return false;
+ 
+ 	r = kvm_x86_ops->set_hv_timer(apic->vcpu, ktimer->tscdeadline);
+ 	if (r < 0)
+ 		return false;
+ 
+ 	ktimer->hv_timer_in_use = true;
+ 	hrtimer_cancel(&ktimer->timer);
+ 
+ 	/*
+ 	 * Also recheck ktimer->pending, in case the sw timer triggered in
+ 	 * the window.  For periodic timer, leave the hv timer running for
+ 	 * simplicity, and the deadline will be recomputed on the next vmexit.
+ 	 */
+ 	if (!apic_lvtt_period(apic) && atomic_read(&ktimer->pending))
+ 		return false;
+ 
+ 	trace_kvm_hv_timer_state(apic->vcpu->vcpu_id, true);
+ 	return true;
+ }
+ 
+ static void start_sw_timer(struct kvm_lapic *apic)
+ {
+ 	struct kvm_timer *ktimer = &apic->lapic_timer;
+ 	if (apic->lapic_timer.hv_timer_in_use)
+ 		cancel_hv_timer(apic);
+ 	if (!apic_lvtt_period(apic) && atomic_read(&ktimer->pending))
+ 		return;
+ 
+ 	if (apic_lvtt_period(apic) || apic_lvtt_oneshot(apic))
+ 		start_sw_period(apic);
+ 	else if (apic_lvtt_tscdeadline(apic))
+ 		start_sw_tscdeadline(apic);
+ 	trace_kvm_hv_timer_state(apic->vcpu->vcpu_id, false);
+ }
+ 
+ static void restart_apic_timer(struct kvm_lapic *apic)
+ {
+ 	if (!start_hv_timer(apic))
+ 		start_sw_timer(apic);
+ }
+ 
+ void kvm_lapic_expired_hv_timer(struct kvm_vcpu *vcpu)
+ {
+ 	struct kvm_lapic *apic = vcpu->arch.apic;
+ 
+ 	WARN_ON(!apic->lapic_timer.hv_timer_in_use);
+ 	WARN_ON(swait_active(&vcpu->wq));
+ 	cancel_hv_timer(apic);
+ 	apic_timer_expired(apic);
+ 
+ 	if (apic_lvtt_period(apic) && apic->lapic_timer.period) {
+ 		advance_periodic_target_expiration(apic);
+ 		restart_apic_timer(apic);
+ 	}
+ }
+ EXPORT_SYMBOL_GPL(kvm_lapic_expired_hv_timer);
+ 
+ void kvm_lapic_switch_to_hv_timer(struct kvm_vcpu *vcpu)
+ {
+ 	restart_apic_timer(vcpu->arch.apic);
+ }
+ EXPORT_SYMBOL_GPL(kvm_lapic_switch_to_hv_timer);
+ 
+ void kvm_lapic_switch_to_sw_timer(struct kvm_vcpu *vcpu)
+ {
+ 	struct kvm_lapic *apic = vcpu->arch.apic;
+ 
+ 	/* Possibly the TSC deadline timer is not enabled yet */
+ 	if (apic->lapic_timer.hv_timer_in_use)
+ 		start_sw_timer(apic);
+ }
+ EXPORT_SYMBOL_GPL(kvm_lapic_switch_to_sw_timer);
+ 
+ void kvm_lapic_restart_hv_timer(struct kvm_vcpu *vcpu)
+ {
+ 	struct kvm_lapic *apic = vcpu->arch.apic;
+ 
+ 	WARN_ON(!apic->lapic_timer.hv_timer_in_use);
+ 	restart_apic_timer(apic);
+ }
+ 
++>>>>>>> a749e247f745 (KVM: lapic: reorganize restart_apic_timer)
  static void start_apic_timer(struct kvm_lapic *apic)
  {
 +	ktime_t now;
  	atomic_set(&apic->lapic_timer.pending, 0);
  
++<<<<<<< HEAD
 +	if (apic_lvtt_period(apic) || apic_lvtt_oneshot(apic)) {
 +		/* lapic timer in oneshot or periodic mode */
 +		now = apic->lapic_timer.timer.base->get_time();
 +		apic->lapic_timer.period = (u64)kvm_lapic_get_reg(apic, APIC_TMICT)
 +			    * APIC_BUS_CYCLE_NS * apic->divide_count;
 +
 +		if (!apic->lapic_timer.period)
 +			return;
 +		/*
 +		 * Do not allow the guest to program periodic timers with small
 +		 * interval, since the hrtimers are not throttled by the host
 +		 * scheduler.
 +		 */
 +		if (apic_lvtt_period(apic)) {
 +			s64 min_period = min_timer_period_us * 1000LL;
 +
 +			if (apic->lapic_timer.period < min_period) {
 +				pr_info_ratelimited(
 +				    "kvm: vcpu %i: requested %lld ns "
 +				    "lapic timer period limited to %lld ns\n",
 +				    apic->vcpu->vcpu_id,
 +				    apic->lapic_timer.period, min_period);
 +				apic->lapic_timer.period = min_period;
 +			}
 +		}
 +
 +		hrtimer_start(&apic->lapic_timer.timer,
 +			      ktime_add_ns(now, apic->lapic_timer.period),
 +			      HRTIMER_MODE_ABS_PINNED);
 +
 +		apic_debug("%s: bus cycle is %" PRId64 "ns, now 0x%016"
 +			   PRIx64 ", "
 +			   "timer initial count 0x%x, period %lldns, "
 +			   "expire @ 0x%016" PRIx64 ".\n", __func__,
 +			   APIC_BUS_CYCLE_NS, ktime_to_ns(now),
 +			   kvm_lapic_get_reg(apic, APIC_TMICT),
 +			   apic->lapic_timer.period,
 +			   ktime_to_ns(ktime_add_ns(now,
 +					apic->lapic_timer.period)));
 +	} else if (apic_lvtt_tscdeadline(apic)) {
 +		start_sw_tscdeadline(apic);
 +	}
++=======
+ 	if ((apic_lvtt_period(apic) || apic_lvtt_oneshot(apic))
+ 	    && !set_target_expiration(apic))
+ 		return;
+ 
+ 	restart_apic_timer(apic);
++>>>>>>> a749e247f745 (KVM: lapic: reorganize restart_apic_timer)
  }
  
  static void apic_manage_nmi_watchdog(struct kvm_lapic *apic, u32 lvt0_val)
@@@ -1650,7 -1832,6 +1843,10 @@@ void kvm_free_lapic(struct kvm_vcpu *vc
   * LAPIC interface
   *----------------------------------------------------------------------
   */
++<<<<<<< HEAD
 +
++=======
++>>>>>>> a749e247f745 (KVM: lapic: reorganize restart_apic_timer)
  u64 kvm_get_lapic_tscdeadline_msr(struct kvm_vcpu *vcpu)
  {
  	struct kvm_lapic *apic = vcpu->arch.apic;
diff --cc arch/x86/kvm/lapic.h
index 5761180667d2,29caa2c3dff9..000000000000
--- a/arch/x86/kvm/lapic.h
+++ b/arch/x86/kvm/lapic.h
@@@ -208,4 -211,9 +208,12 @@@ bool kvm_intr_is_single_vcpu_fast(struc
  			struct kvm_vcpu **dest_vcpu);
  int kvm_vector_to_index(u32 vector, u32 dest_vcpus,
  			const unsigned long *bitmap, u32 bitmap_size);
++<<<<<<< HEAD
++=======
+ void kvm_lapic_switch_to_sw_timer(struct kvm_vcpu *vcpu);
+ void kvm_lapic_switch_to_hv_timer(struct kvm_vcpu *vcpu);
+ void kvm_lapic_expired_hv_timer(struct kvm_vcpu *vcpu);
+ bool kvm_lapic_hv_timer_in_use(struct kvm_vcpu *vcpu);
+ void kvm_lapic_restart_hv_timer(struct kvm_vcpu *vcpu);
++>>>>>>> a749e247f745 (KVM: lapic: reorganize restart_apic_timer)
  #endif
diff --cc arch/x86/kvm/x86.c
index db49db518a51,81aa9c321be3..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -2787,6 -2841,10 +2787,13 @@@ void kvm_arch_vcpu_load(struct kvm_vcp
  			kvm_vcpu_write_tsc_offset(vcpu, offset);
  			vcpu->arch.tsc_catchup = 1;
  		}
++<<<<<<< HEAD
++=======
+ 
+ 		if (kvm_lapic_hv_timer_in_use(vcpu))
+ 			kvm_lapic_restart_hv_timer(vcpu);
+ 
++>>>>>>> a749e247f745 (KVM: lapic: reorganize restart_apic_timer)
  		/*
  		 * On a host with synchronized TSC, there is no need to update
  		 * kvmclock on vcpu->cpu migration
* Unmerged path arch/x86/kvm/lapic.c
* Unmerged path arch/x86/kvm/lapic.h
* Unmerged path arch/x86/kvm/x86.c
