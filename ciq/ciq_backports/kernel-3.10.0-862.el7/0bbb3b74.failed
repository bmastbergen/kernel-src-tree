IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Bart Van Assche <bart.vanassche@sandisk.com>
commit 0bbb3b7496eabb6779962a998a8a91f4a8e589ff
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/0bbb3b74.failed

Make the rxe and rdmavt drivers use dma_virt_ops. Update the
comments that refer to the source files removed by this patch.
Remove struct ib_dma_mapping_ops. Remove ib_device.dma_ops.

	Signed-off-by: Bart Van Assche <bart.vanassche@sandisk.com>
	Cc: Andrew Boyer <andrew.boyer@dell.com>
	Cc: Dennis Dalessandro <dennis.dalessandro@intel.com>
	Cc: Jonathan Toppins <jtoppins@redhat.com>
	Cc: Alex Estrin <alex.estrin@intel.com>
	Cc: Leon Romanovsky <leonro@mellanox.com>
	Reviewed-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit 0bbb3b7496eabb6779962a998a8a91f4a8e589ff)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/sw/rdmavt/Kconfig
#	drivers/infiniband/sw/rdmavt/dma.c
#	drivers/infiniband/sw/rxe/Kconfig
#	drivers/infiniband/sw/rxe/rxe_dma.c
#	include/rdma/ib_verbs.h
diff --cc drivers/infiniband/sw/rdmavt/Kconfig
index 11aa6a34bd71,fdd001ce13d8..000000000000
--- a/drivers/infiniband/sw/rdmavt/Kconfig
+++ b/drivers/infiniband/sw/rdmavt/Kconfig
@@@ -1,6 -1,6 +1,10 @@@
  config INFINIBAND_RDMAVT
  	tristate "RDMA verbs transport library"
  	depends on 64BIT
++<<<<<<< HEAD
 +	default m
++=======
+ 	select DMA_VIRT_OPS
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  	---help---
  	This is a common software verbs provider for RDMA networks.
diff --cc drivers/infiniband/sw/rxe/Kconfig
index b922371613bd,7d1ac27ed251..000000000000
--- a/drivers/infiniband/sw/rxe/Kconfig
+++ b/drivers/infiniband/sw/rxe/Kconfig
@@@ -2,7 -2,7 +2,11 @@@ config RDMA_RX
  	tristate "Software RDMA over Ethernet (RoCE) driver"
  	depends on INET && PCI && INFINIBAND
  	depends on NET_UDP_TUNNEL
++<<<<<<< HEAD
 +	default n
++=======
+ 	select DMA_VIRT_OPS
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  	---help---
  	This driver implements the InfiniBand RDMA transport over
  	the Linux network stack. It enables a system with a
diff --cc include/rdma/ib_verbs.h
index 6716ea884d52,f199c42b9a86..000000000000
--- a/include/rdma/ib_verbs.h
+++ b/include/rdma/ib_verbs.h
@@@ -1829,55 -1781,9 +1829,58 @@@ struct ib_cache 
  	struct ib_pkey_cache  **pkey_cache;
  	struct ib_gid_table   **gid_cache;
  	u8                     *lmc_cache;
 -	enum ib_port_state     *port_state_cache;
  };
  
++<<<<<<< HEAD
 +struct ib_dma_mapping_ops {
 +	int		(*mapping_error)(struct ib_device *dev,
 +					 u64 dma_addr);
 +	u64		(*map_single)(struct ib_device *dev,
 +				      void *ptr, size_t size,
 +				      enum dma_data_direction direction);
 +	void		(*unmap_single)(struct ib_device *dev,
 +					u64 addr, size_t size,
 +					enum dma_data_direction direction);
 +	u64		(*map_page)(struct ib_device *dev,
 +				    struct page *page, unsigned long offset,
 +				    size_t size,
 +				    enum dma_data_direction direction);
 +	void		(*unmap_page)(struct ib_device *dev,
 +				      u64 addr, size_t size,
 +				      enum dma_data_direction direction);
 +	int		(*map_sg)(struct ib_device *dev,
 +				  struct scatterlist *sg, int nents,
 +				  enum dma_data_direction direction);
 +	void		(*unmap_sg)(struct ib_device *dev,
 +				    struct scatterlist *sg, int nents,
 +				    enum dma_data_direction direction);
 +	int		(*map_sg_attrs)(struct ib_device *dev,
 +					struct scatterlist *sg, int nents,
 +					enum dma_data_direction direction,
 +					struct dma_attrs *attrs);
 +	void		(*unmap_sg_attrs)(struct ib_device *dev,
 +					  struct scatterlist *sg, int nents,
 +					  enum dma_data_direction direction,
 +					  struct dma_attrs *attrs);
 +	void		(*sync_single_for_cpu)(struct ib_device *dev,
 +					       u64 dma_handle,
 +					       size_t size,
 +					       enum dma_data_direction dir);
 +	void		(*sync_single_for_device)(struct ib_device *dev,
 +						  u64 dma_handle,
 +						  size_t size,
 +						  enum dma_data_direction dir);
 +	void		*(*alloc_coherent)(struct ib_device *dev,
 +					   size_t size,
 +					   u64 *dma_handle,
 +					   gfp_t flag);
 +	void		(*free_coherent)(struct ib_device *dev,
 +					 size_t size, void *cpu_addr,
 +					 u64 dma_handle);
 +};
 +
++=======
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  struct iw_cm_verbs;
  
  struct ib_port_immutable {
@@@ -2137,10 -2043,6 +2140,13 @@@ struct ib_device 
  							   struct ib_rwq_ind_table_init_attr *init_attr,
  							   struct ib_udata *udata);
  	int                        (*destroy_rwq_ind_table)(struct ib_rwq_ind_table *wq_ind_table);
++<<<<<<< HEAD
 +	void			   (*drain_rq)(struct ib_qp *qp);
 +	void			   (*drain_sq)(struct ib_qp *qp);
 +
 +	struct ib_dma_mapping_ops   *dma_ops;
++=======
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  
  	struct module               *owner;
  	struct device                dev;
@@@ -3015,9 -2917,7 +3021,13 @@@ static inline int ib_req_ncomp_notif(st
   */
  static inline int ib_dma_mapping_error(struct ib_device *dev, u64 dma_addr)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops)
 +		return dev->dma_ops->mapping_error(dev, dma_addr);
 +	return dma_mapping_error(dev->dma_device, dma_addr);
++=======
+ 	return dma_mapping_error(&dev->dev, dma_addr);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  
  /**
@@@ -3031,9 -2931,7 +3041,13 @@@ static inline u64 ib_dma_map_single(str
  				    void *cpu_addr, size_t size,
  				    enum dma_data_direction direction)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops)
 +		return dev->dma_ops->map_single(dev, cpu_addr, size, direction);
 +	return dma_map_single(dev->dma_device, cpu_addr, size, direction);
++=======
+ 	return dma_map_single(&dev->dev, cpu_addr, size, direction);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  
  /**
@@@ -3047,28 -2945,7 +3061,32 @@@ static inline void ib_dma_unmap_single(
  				       u64 addr, size_t size,
  				       enum dma_data_direction direction)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops)
 +		dev->dma_ops->unmap_single(dev, addr, size, direction);
 +	else
 +		dma_unmap_single(dev->dma_device, addr, size, direction);
 +}
 +
 +static inline u64 ib_dma_map_single_attrs(struct ib_device *dev,
 +					  void *cpu_addr, size_t size,
 +					  enum dma_data_direction direction,
 +					  struct dma_attrs *attrs)
 +{
 +	return dma_map_single_attrs(dev->dma_device, cpu_addr, size,
 +				    direction, attrs);
 +}
 +
 +static inline void ib_dma_unmap_single_attrs(struct ib_device *dev,
 +					     u64 addr, size_t size,
 +					     enum dma_data_direction direction,
 +					     struct dma_attrs *attrs)
 +{
 +	return dma_unmap_single_attrs(dev->dma_device, addr, size,
 +				      direction, attrs);
++=======
+ 	dma_unmap_single(&dev->dev, addr, size, direction);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  
  /**
@@@ -3085,9 -2962,7 +3103,13 @@@ static inline u64 ib_dma_map_page(struc
  				  size_t size,
  					 enum dma_data_direction direction)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops)
 +		return dev->dma_ops->map_page(dev, page, offset, size, direction);
 +	return dma_map_page(dev->dma_device, page, offset, size, direction);
++=======
+ 	return dma_map_page(&dev->dev, page, offset, size, direction);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  
  /**
@@@ -3101,10 -2976,7 +3123,14 @@@ static inline void ib_dma_unmap_page(st
  				     u64 addr, size_t size,
  				     enum dma_data_direction direction)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops)
 +		dev->dma_ops->unmap_page(dev, addr, size, direction);
 +	else
 +		dma_unmap_page(dev->dma_device, addr, size, direction);
++=======
+ 	dma_unmap_page(&dev->dev, addr, size, direction);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  
  /**
@@@ -3118,9 -2990,7 +3144,13 @@@ static inline int ib_dma_map_sg(struct 
  				struct scatterlist *sg, int nents,
  				enum dma_data_direction direction)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops)
 +		return dev->dma_ops->map_sg(dev, sg, nents, direction);
 +	return dma_map_sg(dev->dma_device, sg, nents, direction);
++=======
+ 	return dma_map_sg(&dev->dev, sg, nents, direction);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  
  /**
@@@ -3134,36 -3004,23 +3164,48 @@@ static inline void ib_dma_unmap_sg(stru
  				   struct scatterlist *sg, int nents,
  				   enum dma_data_direction direction)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops)
 +		dev->dma_ops->unmap_sg(dev, sg, nents, direction);
 +	else
 +		dma_unmap_sg(dev->dma_device, sg, nents, direction);
++=======
+ 	dma_unmap_sg(&dev->dev, sg, nents, direction);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  
  static inline int ib_dma_map_sg_attrs(struct ib_device *dev,
  				      struct scatterlist *sg, int nents,
  				      enum dma_data_direction direction,
 -				      unsigned long dma_attrs)
 +				      struct dma_attrs *attrs)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops)
 +		return dev->dma_ops->map_sg_attrs(dev, sg, nents, direction,
 +						  attrs);
 +	else
 +		return dma_map_sg_attrs(dev->dma_device, sg, nents, direction,
 +					attrs);
++=======
+ 	return dma_map_sg_attrs(&dev->dev, sg, nents, direction, dma_attrs);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  
  static inline void ib_dma_unmap_sg_attrs(struct ib_device *dev,
  					 struct scatterlist *sg, int nents,
  					 enum dma_data_direction direction,
 -					 unsigned long dma_attrs)
 +					 struct dma_attrs *attrs)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops)
 +		return dev->dma_ops->unmap_sg_attrs(dev, sg, nents, direction,
 +						    attrs);
 +	else
 +		dma_unmap_sg_attrs(dev->dma_device, sg, nents, direction,
 +				   attrs);
++=======
+ 	dma_unmap_sg_attrs(&dev->dev, sg, nents, direction, dma_attrs);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  /**
   * ib_sg_dma_address - Return the DMA address from a scatter/gather entry
@@@ -3205,10 -3062,7 +3247,14 @@@ static inline void ib_dma_sync_single_f
  					      size_t size,
  					      enum dma_data_direction dir)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops)
 +		dev->dma_ops->sync_single_for_cpu(dev, addr, size, dir);
 +	else
 +		dma_sync_single_for_cpu(dev->dma_device, addr, size, dir);
++=======
+ 	dma_sync_single_for_cpu(&dev->dev, addr, size, dir);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  
  /**
@@@ -3223,10 -3077,7 +3269,14 @@@ static inline void ib_dma_sync_single_f
  						 size_t size,
  						 enum dma_data_direction dir)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops)
 +		dev->dma_ops->sync_single_for_device(dev, addr, size, dir);
 +	else
 +		dma_sync_single_for_device(dev->dma_device, addr, size, dir);
++=======
+ 	dma_sync_single_for_device(&dev->dev, addr, size, dir);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  
  /**
@@@ -3241,15 -3092,7 +3291,19 @@@ static inline void *ib_dma_alloc_cohere
  					   dma_addr_t *dma_handle,
  					   gfp_t flag)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops) {
 +		u64 handle;
 +		void *ret;
 +
 +		ret = dev->dma_ops->alloc_coherent(dev, size, &handle, flag);
 +		*dma_handle = handle;
 +		return ret;
 +	}
 +	return dma_alloc_coherent(dev->dma_device, size, dma_handle, flag);
++=======
+ 	return dma_alloc_coherent(&dev->dev, size, dma_handle, flag);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  
  /**
@@@ -3263,10 -3106,7 +3317,14 @@@ static inline void ib_dma_free_coherent
  					size_t size, void *cpu_addr,
  					dma_addr_t dma_handle)
  {
++<<<<<<< HEAD
 +	if (dev->dma_ops)
 +		dev->dma_ops->free_coherent(dev, size, cpu_addr, dma_handle);
 +	else
 +		dma_free_coherent(dev->dma_device, size, cpu_addr, dma_handle);
++=======
+ 	dma_free_coherent(&dev->dev, size, cpu_addr, dma_handle);
++>>>>>>> 0bbb3b7496ea (IB/rxe, IB/rdmavt: Use dma_virt_ops instead of duplicating it)
  }
  
  /**
* Unmerged path drivers/infiniband/sw/rdmavt/dma.c
* Unmerged path drivers/infiniband/sw/rxe/rxe_dma.c
* Unmerged path drivers/infiniband/sw/rdmavt/Kconfig
diff --git a/drivers/infiniband/sw/rdmavt/Makefile b/drivers/infiniband/sw/rdmavt/Makefile
index ccaa7992ac97..2a821d2fb569 100644
--- a/drivers/infiniband/sw/rdmavt/Makefile
+++ b/drivers/infiniband/sw/rdmavt/Makefile
@@ -7,7 +7,7 @@
 #
 obj-$(CONFIG_INFINIBAND_RDMAVT) += rdmavt.o
 
-rdmavt-y := vt.o ah.o cq.o dma.o mad.o mcast.o mmap.o mr.o pd.o qp.o srq.o \
+rdmavt-y := vt.o ah.o cq.o mad.o mcast.o mmap.o mr.o pd.o qp.o srq.o \
 	trace.o
 
 CFLAGS_trace.o = -I$(src)
* Unmerged path drivers/infiniband/sw/rdmavt/dma.c
diff --git a/drivers/infiniband/sw/rdmavt/dma.h b/drivers/infiniband/sw/rdmavt/dma.h
deleted file mode 100644
index 979f07e09195..000000000000
--- a/drivers/infiniband/sw/rdmavt/dma.h
+++ /dev/null
@@ -1,53 +0,0 @@
-#ifndef DEF_RDMAVTDMA_H
-#define DEF_RDMAVTDMA_H
-
-/*
- * Copyright(c) 2016 Intel Corporation.
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * BSD LICENSE
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *  - Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- *  - Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in
- *    the documentation and/or other materials provided with the
- *    distribution.
- *  - Neither the name of Intel Corporation nor the names of its
- *    contributors may be used to endorse or promote products derived
- *    from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- */
-
-extern struct ib_dma_mapping_ops rvt_default_dma_mapping_ops;
-
-#endif          /* DEF_RDMAVTDMA_H */
diff --git a/drivers/infiniband/sw/rdmavt/mr.c b/drivers/infiniband/sw/rdmavt/mr.c
index 52fd15276ee6..14d0ac6efd08 100644
--- a/drivers/infiniband/sw/rdmavt/mr.c
+++ b/drivers/infiniband/sw/rdmavt/mr.c
@@ -305,8 +305,8 @@ static void __rvt_free_mr(struct rvt_mr *mr)
  * @acc: access flags
  *
  * Return: the memory region on success, otherwise returns an errno.
- * Note that all DMA addresses should be created via the
- * struct ib_dma_mapping_ops functions (see dma.c).
+ * Note that all DMA addresses should be created via the functions in
+ * struct dma_virt_ops.
  */
 struct ib_mr *rvt_get_dma_mr(struct ib_pd *pd, int acc)
 {
@@ -782,7 +782,7 @@ int rvt_lkey_ok(struct rvt_lkey_table *rkt, struct rvt_pd *pd,
 
 	/*
 	 * We use LKEY == zero for kernel virtual addresses
-	 * (see rvt_get_dma_mr and dma.c).
+	 * (see rvt_get_dma_mr() and dma_virt_ops).
 	 */
 	rcu_read_lock();
 	if (sge->lkey == 0) {
@@ -880,7 +880,7 @@ int rvt_rkey_ok(struct rvt_qp *qp, struct rvt_sge *sge,
 
 	/*
 	 * We use RKEY == zero for kernel virtual addresses
-	 * (see rvt_get_dma_mr and dma.c).
+	 * (see rvt_get_dma_mr() and dma_virt_ops).
 	 */
 	rcu_read_lock();
 	if (rkey == 0) {
diff --git a/drivers/infiniband/sw/rdmavt/vt.c b/drivers/infiniband/sw/rdmavt/vt.c
index d430c2f7cec4..19666e52b3b1 100644
--- a/drivers/infiniband/sw/rdmavt/vt.c
+++ b/drivers/infiniband/sw/rdmavt/vt.c
@@ -47,6 +47,7 @@
 
 #include <linux/module.h>
 #include <linux/kernel.h>
+#include <linux/dma-mapping.h>
 #include "vt.h"
 #include "trace.h"
 
@@ -777,8 +778,7 @@ int rvt_register_device(struct rvt_dev_info *rdi)
 	}
 
 	/* DMA Operations */
-	rdi->ibdev.dma_ops =
-		rdi->ibdev.dma_ops ? : &rvt_default_dma_mapping_ops;
+	rdi->ibdev.dev.dma_ops = rdi->ibdev.dev.dma_ops ? : &dma_virt_ops;
 
 	/* Protection Domain */
 	spin_lock_init(&rdi->n_pds_lock);
diff --git a/drivers/infiniband/sw/rdmavt/vt.h b/drivers/infiniband/sw/rdmavt/vt.h
index 6b01eaa4461b..f363505312be 100644
--- a/drivers/infiniband/sw/rdmavt/vt.h
+++ b/drivers/infiniband/sw/rdmavt/vt.h
@@ -50,7 +50,6 @@
 
 #include <rdma/rdma_vt.h>
 #include <linux/pci.h>
-#include "dma.h"
 #include "pd.h"
 #include "qp.h"
 #include "ah.h"
* Unmerged path drivers/infiniband/sw/rxe/Kconfig
diff --git a/drivers/infiniband/sw/rxe/Makefile b/drivers/infiniband/sw/rxe/Makefile
index 3b3fb9d1c470..ec35ff022a42 100644
--- a/drivers/infiniband/sw/rxe/Makefile
+++ b/drivers/infiniband/sw/rxe/Makefile
@@ -14,7 +14,6 @@ rdma_rxe-y := \
 	rxe_qp.o \
 	rxe_cq.o \
 	rxe_mr.o \
-	rxe_dma.o \
 	rxe_opcode.o \
 	rxe_mmap.o \
 	rxe_icrc.o \
* Unmerged path drivers/infiniband/sw/rxe/rxe_dma.c
diff --git a/drivers/infiniband/sw/rxe/rxe_loc.h b/drivers/infiniband/sw/rxe/rxe_loc.h
index 83d5eacbab11..b04a38b4b506 100644
--- a/drivers/infiniband/sw/rxe/rxe_loc.h
+++ b/drivers/infiniband/sw/rxe/rxe_loc.h
@@ -237,8 +237,6 @@ int rxe_srq_from_attr(struct rxe_dev *rxe, struct rxe_srq *srq,
 		      struct ib_srq_attr *attr, enum ib_srq_attr_mask mask,
 		      struct ib_udata *udata);
 
-extern struct ib_dma_mapping_ops rxe_dma_mapping_ops;
-
 void rxe_release(struct kref *kref);
 
 int rxe_completer(void *arg);
diff --git a/drivers/infiniband/sw/rxe/rxe_verbs.c b/drivers/infiniband/sw/rxe/rxe_verbs.c
index ace58ef8538e..321cca6cf4cd 100644
--- a/drivers/infiniband/sw/rxe/rxe_verbs.c
+++ b/drivers/infiniband/sw/rxe/rxe_verbs.c
@@ -31,6 +31,7 @@
  * SOFTWARE.
  */
 
+#include <linux/dma-mapping.h>
 #include "rxe.h"
 #include "rxe_loc.h"
 #include "rxe_queue.h"
@@ -1235,7 +1236,7 @@ int rxe_register_device(struct rxe_dev *rxe)
 	dev->dev.parent = rxe_dma_device(rxe);
 	dev->local_dma_lkey = 0;
 	dev->node_guid = rxe_node_guid(rxe);
-	dev->dma_ops = &rxe_dma_mapping_ops;
+	dev->dev.dma_ops = &dma_virt_ops;
 
 	dev->uverbs_abi_ver = RXE_UVERBS_ABI_VERSION;
 	dev->uverbs_cmd_mask = BIT_ULL(IB_USER_VERBS_CMD_GET_CONTEXT)
* Unmerged path include/rdma/ib_verbs.h
