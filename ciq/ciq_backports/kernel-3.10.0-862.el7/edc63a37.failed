s390/crypto: cleanup cpacf function codes

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [s390] crypto: cleanup cpacf function codes (Hendrik Brueckner) [1380349]
Rebuild_FUZZ: 93.51%
commit-author Martin Schwidefsky <schwidefsky@de.ibm.com>
commit edc63a3785b48455e05793e848f0174e21f38d09
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/edc63a37.failed

Use a separate define for the decryption modifier bit instead of
duplicating the function codes for encryption / decrypton.
In addition use an unsigned type for the function code.

	Reviewed-by: Harald Freudenberger <freude@linux.vnet.ibm.com>
	Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
(cherry picked from commit edc63a3785b48455e05793e848f0174e21f38d09)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/s390/crypto/aes_s390.c
#	arch/s390/crypto/des_s390.c
#	arch/s390/include/asm/cpacf.h
diff --cc arch/s390/crypto/aes_s390.c
index 25567fe0d72c,9da54698b87a..000000000000
--- a/arch/s390/crypto/aes_s390.c
+++ b/arch/s390/crypto/aes_s390.c
@@@ -39,11 -41,10 +39,10 @@@ static char keylen_flag
  
  struct s390_aes_ctx {
  	u8 key[AES_MAX_KEY_SIZE];
- 	long enc;
- 	long dec;
  	int key_len;
+ 	unsigned long fc;
  	union {
 -		struct crypto_skcipher *blk;
 +		struct crypto_blkcipher *blk;
  		struct crypto_cipher *cip;
  	} fallback;
  };
@@@ -59,10 -60,9 +58,13 @@@ struct pcc_param 
  struct s390_xts_ctx {
  	u8 key[32];
  	u8 pcc_key[32];
- 	long enc;
- 	long dec;
  	int key_len;
++<<<<<<< HEAD
 +	struct crypto_blkcipher *fallback;
++=======
+ 	unsigned long fc;
+ 	struct crypto_skcipher *fallback;
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  };
  
  /*
@@@ -144,16 -144,16 +146,29 @@@ static void aes_encrypt(struct crypto_t
  
  	switch (sctx->key_len) {
  	case 16:
++<<<<<<< HEAD
 +		crypt_s390_km(KM_AES_128_ENCRYPT, &sctx->key, out, in,
 +			      AES_BLOCK_SIZE);
 +		break;
 +	case 24:
 +		crypt_s390_km(KM_AES_192_ENCRYPT, &sctx->key, out, in,
 +			      AES_BLOCK_SIZE);
 +		break;
 +	case 32:
 +		crypt_s390_km(KM_AES_256_ENCRYPT, &sctx->key, out, in,
 +			      AES_BLOCK_SIZE);
++=======
+ 		cpacf_km(CPACF_KM_AES_128,
+ 			 &sctx->key, out, in, AES_BLOCK_SIZE);
+ 		break;
+ 	case 24:
+ 		cpacf_km(CPACF_KM_AES_192,
+ 			 &sctx->key, out, in, AES_BLOCK_SIZE);
+ 		break;
+ 	case 32:
+ 		cpacf_km(CPACF_KM_AES_256,
+ 			 &sctx->key, out, in, AES_BLOCK_SIZE);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  		break;
  	}
  }
@@@ -169,16 -169,16 +184,29 @@@ static void aes_decrypt(struct crypto_t
  
  	switch (sctx->key_len) {
  	case 16:
++<<<<<<< HEAD
 +		crypt_s390_km(KM_AES_128_DECRYPT, &sctx->key, out, in,
 +			      AES_BLOCK_SIZE);
 +		break;
 +	case 24:
 +		crypt_s390_km(KM_AES_192_DECRYPT, &sctx->key, out, in,
 +			      AES_BLOCK_SIZE);
 +		break;
 +	case 32:
 +		crypt_s390_km(KM_AES_256_DECRYPT, &sctx->key, out, in,
 +			      AES_BLOCK_SIZE);
++=======
+ 		cpacf_km(CPACF_KM_AES_128 | CPACF_DECRYPT,
+ 			 &sctx->key, out, in, AES_BLOCK_SIZE);
+ 		break;
+ 	case 24:
+ 		cpacf_km(CPACF_KM_AES_192 | CPACF_DECRYPT,
+ 			 &sctx->key, out, in, AES_BLOCK_SIZE);
+ 		break;
+ 	case 32:
+ 		cpacf_km(CPACF_KM_AES_256 | CPACF_DECRYPT,
+ 			 &sctx->key, out, in, AES_BLOCK_SIZE);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  		break;
  	}
  }
@@@ -297,16 -299,13 +325,26 @@@ static int ecb_aes_set_key(struct crypt
  
  	switch (key_len) {
  	case 16:
++<<<<<<< HEAD
 +		sctx->enc = KM_AES_128_ENCRYPT;
 +		sctx->dec = KM_AES_128_DECRYPT;
 +		break;
 +	case 24:
 +		sctx->enc = KM_AES_192_ENCRYPT;
 +		sctx->dec = KM_AES_192_DECRYPT;
 +		break;
 +	case 32:
 +		sctx->enc = KM_AES_256_ENCRYPT;
 +		sctx->dec = KM_AES_256_DECRYPT;
++=======
+ 		sctx->fc = CPACF_KM_AES_128;
+ 		break;
+ 	case 24:
+ 		sctx->fc = CPACF_KM_AES_192;
+ 		break;
+ 	case 32:
+ 		sctx->fc = CPACF_KM_AES_256;
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  		break;
  	}
  
@@@ -426,16 -425,13 +464,26 @@@ static int cbc_aes_set_key(struct crypt
  
  	switch (key_len) {
  	case 16:
++<<<<<<< HEAD
 +		sctx->enc = KMC_AES_128_ENCRYPT;
 +		sctx->dec = KMC_AES_128_DECRYPT;
 +		break;
 +	case 24:
 +		sctx->enc = KMC_AES_192_ENCRYPT;
 +		sctx->dec = KMC_AES_192_DECRYPT;
 +		break;
 +	case 32:
 +		sctx->enc = KMC_AES_256_ENCRYPT;
 +		sctx->dec = KMC_AES_256_DECRYPT;
++=======
+ 		sctx->fc = CPACF_KMC_AES_128;
+ 		break;
+ 	case 24:
+ 		sctx->fc = CPACF_KMC_AES_192;
+ 		break;
+ 	case 32:
+ 		sctx->fc = CPACF_KMC_AES_256;
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  		break;
  	}
  
@@@ -595,8 -595,7 +643,12 @@@ static int xts_aes_set_key(struct crypt
  
  	switch (key_len) {
  	case 32:
++<<<<<<< HEAD
 +		xts_ctx->enc = KM_XTS_128_ENCRYPT;
 +		xts_ctx->dec = KM_XTS_128_DECRYPT;
++=======
+ 		xts_ctx->fc = CPACF_KM_XTS_128;
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  		memcpy(xts_ctx->key + 16, in_key, 16);
  		memcpy(xts_ctx->pcc_key + 16, in_key + 16, 16);
  		break;
@@@ -606,8 -604,7 +657,12 @@@
  		xts_fallback_setkey(tfm, in_key, key_len);
  		break;
  	case 64:
++<<<<<<< HEAD
 +		xts_ctx->enc = KM_XTS_256_ENCRYPT;
 +		xts_ctx->dec = KM_XTS_256_DECRYPT;
++=======
+ 		xts_ctx->fc = CPACF_KM_XTS_256;
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  		memcpy(xts_ctx->key, in_key, 32);
  		memcpy(xts_ctx->pcc_key, in_key + 32, 32);
  		break;
@@@ -750,16 -748,13 +805,26 @@@ static int ctr_aes_set_key(struct crypt
  
  	switch (key_len) {
  	case 16:
++<<<<<<< HEAD
 +		sctx->enc = KMCTR_AES_128_ENCRYPT;
 +		sctx->dec = KMCTR_AES_128_DECRYPT;
 +		break;
 +	case 24:
 +		sctx->enc = KMCTR_AES_192_ENCRYPT;
 +		sctx->dec = KMCTR_AES_192_DECRYPT;
 +		break;
 +	case 32:
 +		sctx->enc = KMCTR_AES_256_ENCRYPT;
 +		sctx->dec = KMCTR_AES_256_DECRYPT;
++=======
+ 		sctx->fc = CPACF_KMCTR_AES_128;
+ 		break;
+ 	case 24:
+ 		sctx->fc = CPACF_KMCTR_AES_192;
+ 		break;
+ 	case 32:
+ 		sctx->fc = CPACF_KMCTR_AES_256;
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  		break;
  	}
  
@@@ -898,11 -892,11 +963,19 @@@ static int __init aes_s390_init(void
  {
  	int ret;
  
++<<<<<<< HEAD
 +	if (crypt_s390_func_available(KM_AES_128_ENCRYPT, CRYPT_S390_MSA))
 +		keylen_flag |= AES_KEYLEN_128;
 +	if (crypt_s390_func_available(KM_AES_192_ENCRYPT, CRYPT_S390_MSA))
 +		keylen_flag |= AES_KEYLEN_192;
 +	if (crypt_s390_func_available(KM_AES_256_ENCRYPT, CRYPT_S390_MSA))
++=======
+ 	if (cpacf_query(CPACF_KM, CPACF_KM_AES_128))
+ 		keylen_flag |= AES_KEYLEN_128;
+ 	if (cpacf_query(CPACF_KM, CPACF_KM_AES_192))
+ 		keylen_flag |= AES_KEYLEN_192;
+ 	if (cpacf_query(CPACF_KM, CPACF_KM_AES_256))
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  		keylen_flag |= AES_KEYLEN_256;
  
  	if (!keylen_flag)
@@@ -925,22 -919,17 +998,33 @@@
  	if (ret)
  		goto cbc_aes_err;
  
++<<<<<<< HEAD
 +	if (crypt_s390_func_available(KM_XTS_128_ENCRYPT,
 +			CRYPT_S390_MSA | CRYPT_S390_MSA4) &&
 +	    crypt_s390_func_available(KM_XTS_256_ENCRYPT,
 +			CRYPT_S390_MSA | CRYPT_S390_MSA4)) {
++=======
+ 	if (cpacf_query(CPACF_KM, CPACF_KM_XTS_128) &&
+ 	    cpacf_query(CPACF_KM, CPACF_KM_XTS_256)) {
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  		ret = crypto_register_alg(&xts_aes_alg);
  		if (ret)
  			goto xts_aes_err;
  		xts_aes_alg_reg = 1;
  	}
  
++<<<<<<< HEAD
 +	if (crypt_s390_func_available(KMCTR_AES_128_ENCRYPT,
 +				CRYPT_S390_MSA | CRYPT_S390_MSA4) &&
 +	    crypt_s390_func_available(KMCTR_AES_192_ENCRYPT,
 +				CRYPT_S390_MSA | CRYPT_S390_MSA4) &&
 +	    crypt_s390_func_available(KMCTR_AES_256_ENCRYPT,
 +				CRYPT_S390_MSA | CRYPT_S390_MSA4)) {
++=======
+ 	if (cpacf_query(CPACF_KMCTR, CPACF_KMCTR_AES_128) &&
+ 	    cpacf_query(CPACF_KMCTR, CPACF_KMCTR_AES_192) &&
+ 	    cpacf_query(CPACF_KMCTR, CPACF_KMCTR_AES_256)) {
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  		ctrblk = (u8 *) __get_free_page(GFP_KERNEL);
  		if (!ctrblk) {
  			ret = -ENOMEM;
diff --cc arch/s390/crypto/des_s390.c
index a89feffb22b5,fadd474bf8bb..000000000000
--- a/arch/s390/crypto/des_s390.c
+++ b/arch/s390/crypto/des_s390.c
@@@ -53,14 -53,15 +53,23 @@@ static void des_encrypt(struct crypto_t
  {
  	struct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);
  
++<<<<<<< HEAD
 +	crypt_s390_km(KM_DEA_ENCRYPT, ctx->key, out, in, DES_BLOCK_SIZE);
++=======
+ 	cpacf_km(CPACF_KM_DEA, ctx->key, out, in, DES_BLOCK_SIZE);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static void des_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)
  {
  	struct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);
  
++<<<<<<< HEAD
 +	crypt_s390_km(KM_DEA_DECRYPT, ctx->key, out, in, DES_BLOCK_SIZE);
++=======
+ 	cpacf_km(CPACF_KM_DEA | CPACF_DECRYPT,
+ 		 ctx->key, out, in, DES_BLOCK_SIZE);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static struct crypto_alg des_alg = {
@@@ -148,7 -149,7 +157,11 @@@ static int ecb_des_encrypt(struct blkci
  	struct blkcipher_walk walk;
  
  	blkcipher_walk_init(&walk, dst, src, nbytes);
++<<<<<<< HEAD
 +	return ecb_desall_crypt(desc, KM_DEA_ENCRYPT, ctx->key, &walk);
++=======
+ 	return ecb_desall_crypt(desc, CPACF_KM_DEA, ctx->key, &walk);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static int ecb_des_decrypt(struct blkcipher_desc *desc,
@@@ -159,7 -160,8 +172,12 @@@
  	struct blkcipher_walk walk;
  
  	blkcipher_walk_init(&walk, dst, src, nbytes);
++<<<<<<< HEAD
 +	return ecb_desall_crypt(desc, KM_DEA_DECRYPT, ctx->key, &walk);
++=======
+ 	return ecb_desall_crypt(desc, CPACF_KM_DEA | CPACF_DECRYPT,
+ 				ctx->key, &walk);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static struct crypto_alg ecb_des_alg = {
@@@ -189,7 -191,7 +207,11 @@@ static int cbc_des_encrypt(struct blkci
  	struct blkcipher_walk walk;
  
  	blkcipher_walk_init(&walk, dst, src, nbytes);
++<<<<<<< HEAD
 +	return cbc_desall_crypt(desc, KMC_DEA_ENCRYPT, &walk);
++=======
+ 	return cbc_desall_crypt(desc, CPACF_KMC_DEA, &walk);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static int cbc_des_decrypt(struct blkcipher_desc *desc,
@@@ -199,7 -201,7 +221,11 @@@
  	struct blkcipher_walk walk;
  
  	blkcipher_walk_init(&walk, dst, src, nbytes);
++<<<<<<< HEAD
 +	return cbc_desall_crypt(desc, KMC_DEA_DECRYPT, &walk);
++=======
+ 	return cbc_desall_crypt(desc, CPACF_KMC_DEA | CPACF_DECRYPT, &walk);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static struct crypto_alg cbc_des_alg = {
@@@ -257,14 -259,15 +283,23 @@@ static void des3_encrypt(struct crypto_
  {
  	struct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);
  
++<<<<<<< HEAD
 +	crypt_s390_km(KM_TDEA_192_ENCRYPT, ctx->key, dst, src, DES_BLOCK_SIZE);
++=======
+ 	cpacf_km(CPACF_KM_TDEA_192, ctx->key, dst, src, DES_BLOCK_SIZE);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static void des3_decrypt(struct crypto_tfm *tfm, u8 *dst, const u8 *src)
  {
  	struct s390_des_ctx *ctx = crypto_tfm_ctx(tfm);
  
++<<<<<<< HEAD
 +	crypt_s390_km(KM_TDEA_192_DECRYPT, ctx->key, dst, src, DES_BLOCK_SIZE);
++=======
+ 	cpacf_km(CPACF_KM_TDEA_192 | CPACF_DECRYPT,
+ 		 ctx->key, dst, src, DES_BLOCK_SIZE);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static struct crypto_alg des3_alg = {
@@@ -294,7 -297,7 +329,11 @@@ static int ecb_des3_encrypt(struct blkc
  	struct blkcipher_walk walk;
  
  	blkcipher_walk_init(&walk, dst, src, nbytes);
++<<<<<<< HEAD
 +	return ecb_desall_crypt(desc, KM_TDEA_192_ENCRYPT, ctx->key, &walk);
++=======
+ 	return ecb_desall_crypt(desc, CPACF_KM_TDEA_192, ctx->key, &walk);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static int ecb_des3_decrypt(struct blkcipher_desc *desc,
@@@ -305,7 -308,8 +344,12 @@@
  	struct blkcipher_walk walk;
  
  	blkcipher_walk_init(&walk, dst, src, nbytes);
++<<<<<<< HEAD
 +	return ecb_desall_crypt(desc, KM_TDEA_192_DECRYPT, ctx->key, &walk);
++=======
+ 	return ecb_desall_crypt(desc, CPACF_KM_TDEA_192 | CPACF_DECRYPT,
+ 				ctx->key, &walk);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static struct crypto_alg ecb_des3_alg = {
@@@ -335,7 -339,7 +379,11 @@@ static int cbc_des3_encrypt(struct blkc
  	struct blkcipher_walk walk;
  
  	blkcipher_walk_init(&walk, dst, src, nbytes);
++<<<<<<< HEAD
 +	return cbc_desall_crypt(desc, KMC_TDEA_192_ENCRYPT, &walk);
++=======
+ 	return cbc_desall_crypt(desc, CPACF_KMC_TDEA_192, &walk);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static int cbc_des3_decrypt(struct blkcipher_desc *desc,
@@@ -345,7 -349,8 +393,12 @@@
  	struct blkcipher_walk walk;
  
  	blkcipher_walk_init(&walk, dst, src, nbytes);
++<<<<<<< HEAD
 +	return cbc_desall_crypt(desc, KMC_TDEA_192_DECRYPT, &walk);
++=======
+ 	return cbc_desall_crypt(desc, CPACF_KMC_TDEA_192 | CPACF_DECRYPT,
+ 				&walk);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static struct crypto_alg cbc_des3_alg = {
@@@ -457,7 -461,7 +510,11 @@@ static int ctr_des_encrypt(struct blkci
  	struct blkcipher_walk walk;
  
  	blkcipher_walk_init(&walk, dst, src, nbytes);
++<<<<<<< HEAD
 +	return ctr_desall_crypt(desc, KMCTR_DEA_ENCRYPT, ctx, &walk);
++=======
+ 	return ctr_desall_crypt(desc, CPACF_KMCTR_DEA, ctx, &walk);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static int ctr_des_decrypt(struct blkcipher_desc *desc,
@@@ -468,7 -472,8 +525,12 @@@
  	struct blkcipher_walk walk;
  
  	blkcipher_walk_init(&walk, dst, src, nbytes);
++<<<<<<< HEAD
 +	return ctr_desall_crypt(desc, KMCTR_DEA_DECRYPT, ctx, &walk);
++=======
+ 	return ctr_desall_crypt(desc, CPACF_KMCTR_DEA | CPACF_DECRYPT,
+ 				ctx, &walk);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static struct crypto_alg ctr_des_alg = {
@@@ -500,7 -505,7 +562,11 @@@ static int ctr_des3_encrypt(struct blkc
  	struct blkcipher_walk walk;
  
  	blkcipher_walk_init(&walk, dst, src, nbytes);
++<<<<<<< HEAD
 +	return ctr_desall_crypt(desc, KMCTR_TDEA_192_ENCRYPT, ctx, &walk);
++=======
+ 	return ctr_desall_crypt(desc, CPACF_KMCTR_TDEA_192, ctx, &walk);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static int ctr_des3_decrypt(struct blkcipher_desc *desc,
@@@ -511,7 -516,8 +577,12 @@@
  	struct blkcipher_walk walk;
  
  	blkcipher_walk_init(&walk, dst, src, nbytes);
++<<<<<<< HEAD
 +	return ctr_desall_crypt(desc, KMCTR_TDEA_192_DECRYPT, ctx, &walk);
++=======
+ 	return ctr_desall_crypt(desc, CPACF_KMCTR_TDEA_192 | CPACF_DECRYPT,
+ 				ctx, &walk);
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  }
  
  static struct crypto_alg ctr_des3_alg = {
@@@ -539,8 -545,8 +610,13 @@@ static int __init des_s390_init(void
  {
  	int ret;
  
++<<<<<<< HEAD
 +	if (!crypt_s390_func_available(KM_DEA_ENCRYPT, CRYPT_S390_MSA) ||
 +	    !crypt_s390_func_available(KM_TDEA_192_ENCRYPT, CRYPT_S390_MSA))
++=======
+ 	if (!cpacf_query(CPACF_KM, CPACF_KM_DEA) ||
+ 	    !cpacf_query(CPACF_KM, CPACF_KM_TDEA_192))
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  		return -EOPNOTSUPP;
  
  	ret = crypto_register_alg(&des_alg);
@@@ -562,10 -568,8 +638,15 @@@
  	if (ret)
  		goto cbc_des3_err;
  
++<<<<<<< HEAD
 +	if (crypt_s390_func_available(KMCTR_DEA_ENCRYPT,
 +			CRYPT_S390_MSA | CRYPT_S390_MSA4) &&
 +	    crypt_s390_func_available(KMCTR_TDEA_192_ENCRYPT,
 +			CRYPT_S390_MSA | CRYPT_S390_MSA4)) {
++=======
+ 	if (cpacf_query(CPACF_KMCTR, CPACF_KMCTR_DEA) &&
+ 	    cpacf_query(CPACF_KMCTR, CPACF_KMCTR_TDEA_192)) {
++>>>>>>> edc63a3785b4 (s390/crypto: cleanup cpacf function codes)
  		ret = crypto_register_alg(&ctr_des_alg);
  		if (ret)
  			goto ctr_des_err;
* Unmerged path arch/s390/include/asm/cpacf.h
* Unmerged path arch/s390/crypto/aes_s390.c
* Unmerged path arch/s390/crypto/des_s390.c
* Unmerged path arch/s390/include/asm/cpacf.h
