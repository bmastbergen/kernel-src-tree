scsi: smartpqi: update device offline

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [scsi] smartpqi: update device offline (Don Brace) [1457414]
Rebuild_FUZZ: 91.18%
commit-author Kevin Barnett <kevin.barnett@microsemi.com>
commit 03b288cf3d92202b950245e931576bb573930c70
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/03b288cf.failed

- Improve handling of offline devices.

	Reviewed-by: Scott Benesh <scott.benesh@microsemi.com>
	Signed-off-by: Kevin Barnett <kevin.barnett@microsemi.com>
	Signed-off-by: Don Brace <don.brace@microsemi.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit 03b288cf3d92202b950245e931576bb573930c70)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/smartpqi/smartpqi_init.c
diff --cc drivers/scsi/smartpqi/smartpqi_init.c
index a3837a6f86ae,f36aaceacae4..000000000000
--- a/drivers/scsi/smartpqi/smartpqi_init.c
+++ b/drivers/scsi/smartpqi/smartpqi_init.c
@@@ -2439,15 -2404,17 +2444,29 @@@ static inline void pqi_take_device_offl
  	struct pqi_ctrl_info *ctrl_info;
  	struct pqi_scsi_dev *device;
  
++<<<<<<< HEAD
 +	if (scsi_device_online(sdev)) {
 +		scsi_device_set_state(sdev, SDEV_OFFLINE);
 +		ctrl_info = shost_to_hba(sdev->host);
 +		schedule_delayed_work(&ctrl_info->rescan_work, 0);
 +		device = sdev->hostdata;
 +		dev_err(&ctrl_info->pci_dev->dev, "offlined scsi %d:%d:%d:%d\n",
 +			ctrl_info->scsi_host->host_no, device->bus,
 +			device->target, device->lun);
 +	}
++=======
+ 	device = sdev->hostdata;
+ 	if (device->device_offline)
+ 		return;
+ 
+ 	device->device_offline = true;
+ 	scsi_device_set_state(sdev, SDEV_OFFLINE);
+ 	ctrl_info = shost_to_hba(sdev->host);
+ 	pqi_schedule_rescan_worker(ctrl_info);
+ 	dev_err(&ctrl_info->pci_dev->dev, "offlined %s scsi %d:%d:%d:%d\n",
+ 		path, ctrl_info->scsi_host->host_no, device->bus,
+ 		device->target, device->lun);
++>>>>>>> 03b288cf3d92 (scsi: smartpqi: update device offline)
  }
  
  static void pqi_process_raid_io_error(struct pqi_io_request *io_request)
@@@ -4605,6 -4584,188 +4624,191 @@@ static int pqi_raid_submit_scsi_cmd(str
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static inline int pqi_raid_submit_scsi_cmd(struct pqi_ctrl_info *ctrl_info,
+ 	struct pqi_scsi_dev *device, struct scsi_cmnd *scmd,
+ 	struct pqi_queue_group *queue_group)
+ {
+ 	struct pqi_io_request *io_request;
+ 
+ 	io_request = pqi_alloc_io_request(ctrl_info);
+ 
+ 	return pqi_raid_submit_scsi_cmd_with_io_request(ctrl_info, io_request,
+ 		device, scmd, queue_group);
+ }
+ 
+ static inline void pqi_schedule_bypass_retry(struct pqi_ctrl_info *ctrl_info)
+ {
+ 	if (!pqi_ctrl_blocked(ctrl_info))
+ 		schedule_work(&ctrl_info->raid_bypass_retry_work);
+ }
+ 
+ static bool pqi_raid_bypass_retry_needed(struct pqi_io_request *io_request)
+ {
+ 	struct scsi_cmnd *scmd;
+ 	struct pqi_scsi_dev *device;
+ 	struct pqi_ctrl_info *ctrl_info;
+ 
+ 	if (!io_request->raid_bypass)
+ 		return false;
+ 
+ 	scmd = io_request->scmd;
+ 	if ((scmd->result & 0xff) == SAM_STAT_GOOD)
+ 		return false;
+ 	if (host_byte(scmd->result) == DID_NO_CONNECT)
+ 		return false;
+ 
+ 	device = scmd->device->hostdata;
+ 	if (pqi_device_offline(device))
+ 		return false;
+ 
+ 	ctrl_info = shost_to_hba(scmd->device->host);
+ 	if (pqi_ctrl_offline(ctrl_info))
+ 		return false;
+ 
+ 	return true;
+ }
+ 
+ static inline void pqi_add_to_raid_bypass_retry_list(
+ 	struct pqi_ctrl_info *ctrl_info,
+ 	struct pqi_io_request *io_request, bool at_head)
+ {
+ 	unsigned long flags;
+ 
+ 	spin_lock_irqsave(&ctrl_info->raid_bypass_retry_list_lock, flags);
+ 	if (at_head)
+ 		list_add(&io_request->request_list_entry,
+ 			&ctrl_info->raid_bypass_retry_list);
+ 	else
+ 		list_add_tail(&io_request->request_list_entry,
+ 			&ctrl_info->raid_bypass_retry_list);
+ 	spin_unlock_irqrestore(&ctrl_info->raid_bypass_retry_list_lock, flags);
+ }
+ 
+ static void pqi_queued_raid_bypass_complete(struct pqi_io_request *io_request,
+ 	void *context)
+ {
+ 	struct scsi_cmnd *scmd;
+ 
+ 	scmd = io_request->scmd;
+ 	pqi_free_io_request(io_request);
+ 	pqi_scsi_done(scmd);
+ }
+ 
+ static void pqi_queue_raid_bypass_retry(struct pqi_io_request *io_request)
+ {
+ 	struct scsi_cmnd *scmd;
+ 	struct pqi_ctrl_info *ctrl_info;
+ 
+ 	io_request->io_complete_callback = pqi_queued_raid_bypass_complete;
+ 	scmd = io_request->scmd;
+ 	scmd->result = 0;
+ 	ctrl_info = shost_to_hba(scmd->device->host);
+ 
+ 	pqi_add_to_raid_bypass_retry_list(ctrl_info, io_request, false);
+ 	pqi_schedule_bypass_retry(ctrl_info);
+ }
+ 
+ static int pqi_retry_raid_bypass(struct pqi_io_request *io_request)
+ {
+ 	struct scsi_cmnd *scmd;
+ 	struct pqi_scsi_dev *device;
+ 	struct pqi_ctrl_info *ctrl_info;
+ 	struct pqi_queue_group *queue_group;
+ 
+ 	scmd = io_request->scmd;
+ 	device = scmd->device->hostdata;
+ 	if (pqi_device_in_reset(device)) {
+ 		pqi_free_io_request(io_request);
+ 		set_host_byte(scmd, DID_RESET);
+ 		pqi_scsi_done(scmd);
+ 		return 0;
+ 	}
+ 
+ 	ctrl_info = shost_to_hba(scmd->device->host);
+ 	queue_group = io_request->queue_group;
+ 
+ 	pqi_reinit_io_request(io_request);
+ 
+ 	return pqi_raid_submit_scsi_cmd_with_io_request(ctrl_info, io_request,
+ 		device, scmd, queue_group);
+ }
+ 
+ static inline struct pqi_io_request *pqi_next_queued_raid_bypass_request(
+ 	struct pqi_ctrl_info *ctrl_info)
+ {
+ 	unsigned long flags;
+ 	struct pqi_io_request *io_request;
+ 
+ 	spin_lock_irqsave(&ctrl_info->raid_bypass_retry_list_lock, flags);
+ 	io_request = list_first_entry_or_null(
+ 		&ctrl_info->raid_bypass_retry_list,
+ 		struct pqi_io_request, request_list_entry);
+ 	if (io_request)
+ 		list_del(&io_request->request_list_entry);
+ 	spin_unlock_irqrestore(&ctrl_info->raid_bypass_retry_list_lock, flags);
+ 
+ 	return io_request;
+ }
+ 
+ static void pqi_retry_raid_bypass_requests(struct pqi_ctrl_info *ctrl_info)
+ {
+ 	int rc;
+ 	struct pqi_io_request *io_request;
+ 
+ 	pqi_ctrl_busy(ctrl_info);
+ 
+ 	while (1) {
+ 		if (pqi_ctrl_blocked(ctrl_info))
+ 			break;
+ 		io_request = pqi_next_queued_raid_bypass_request(ctrl_info);
+ 		if (!io_request)
+ 			break;
+ 		rc = pqi_retry_raid_bypass(io_request);
+ 		if (rc) {
+ 			pqi_add_to_raid_bypass_retry_list(ctrl_info, io_request,
+ 				true);
+ 			pqi_schedule_bypass_retry(ctrl_info);
+ 			break;
+ 		}
+ 	}
+ 
+ 	pqi_ctrl_unbusy(ctrl_info);
+ }
+ 
+ static void pqi_raid_bypass_retry_worker(struct work_struct *work)
+ {
+ 	struct pqi_ctrl_info *ctrl_info;
+ 
+ 	ctrl_info = container_of(work, struct pqi_ctrl_info,
+ 		raid_bypass_retry_work);
+ 	pqi_retry_raid_bypass_requests(ctrl_info);
+ }
+ 
+ static void pqi_complete_all_queued_raid_bypass_retries(
+ 	struct pqi_ctrl_info *ctrl_info, int result)
+ {
+ 	unsigned long flags;
+ 	struct pqi_io_request *io_request;
+ 	struct pqi_io_request *next;
+ 	struct scsi_cmnd *scmd;
+ 
+ 	spin_lock_irqsave(&ctrl_info->raid_bypass_retry_list_lock, flags);
+ 
+ 	list_for_each_entry_safe(io_request, next,
+ 		&ctrl_info->raid_bypass_retry_list, request_list_entry) {
+ 		list_del(&io_request->request_list_entry);
+ 		scmd = io_request->scmd;
+ 		pqi_free_io_request(io_request);
+ 		scmd->result = result;
+ 		pqi_scsi_done(scmd);
+ 	}
+ 
+ 	spin_unlock_irqrestore(&ctrl_info->raid_bypass_retry_list_lock, flags);
+ }
+ 
++>>>>>>> 03b288cf3d92 (scsi: smartpqi: update device offline)
  static void pqi_aio_io_complete(struct pqi_io_request *io_request,
  	void *context)
  {
* Unmerged path drivers/scsi/smartpqi/smartpqi_init.c
