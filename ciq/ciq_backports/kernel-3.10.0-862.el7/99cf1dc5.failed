blk-mq: release driver tag on a requeue event

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Jens Axboe <axboe@fb.com>
commit 99cf1dc580f0766825395aae4f60ec1d8438f011
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/99cf1dc5.failed

We don't want to hold on to this resource when we have a scheduler
attached.

	Signed-off-by: Jens Axboe <axboe@fb.com>
	Reviewed-by: Omar Sandoval <osandov@fb.com>
	Tested-by: Hannes Reinecke <hare@suse.com>
(cherry picked from commit 99cf1dc580f0766825395aae4f60ec1d8438f011)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq.c
diff --cc block/blk-mq.c
index 3b21482b7f01,711883384585..000000000000
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@@ -824,6 -846,78 +824,81 @@@ static inline unsigned int queued_to_in
  	return min(BLK_MQ_MAX_DISPATCH_ORDER - 1, ilog2(queued) + 1);
  }
  
++<<<<<<< HEAD
++=======
+ static bool blk_mq_get_driver_tag(struct request *rq,
+ 				  struct blk_mq_hw_ctx **hctx, bool wait)
+ {
+ 	struct blk_mq_alloc_data data = {
+ 		.q = rq->q,
+ 		.ctx = rq->mq_ctx,
+ 		.hctx = blk_mq_map_queue(rq->q, rq->mq_ctx->cpu),
+ 		.flags = wait ? 0 : BLK_MQ_REQ_NOWAIT,
+ 	};
+ 
+ 	if (blk_mq_hctx_stopped(data.hctx))
+ 		return false;
+ 
+ 	if (rq->tag != -1) {
+ done:
+ 		if (hctx)
+ 			*hctx = data.hctx;
+ 		return true;
+ 	}
+ 
+ 	rq->tag = blk_mq_get_tag(&data);
+ 	if (rq->tag >= 0) {
+ 		if (blk_mq_tag_busy(data.hctx)) {
+ 			rq->rq_flags |= RQF_MQ_INFLIGHT;
+ 			atomic_inc(&data.hctx->nr_active);
+ 		}
+ 		data.hctx->tags->rqs[rq->tag] = rq;
+ 		goto done;
+ 	}
+ 
+ 	return false;
+ }
+ 
+ static void blk_mq_put_driver_tag(struct blk_mq_hw_ctx *hctx,
+ 				  struct request *rq)
+ {
+ 	if (rq->tag == -1 || rq->internal_tag == -1)
+ 		return;
+ 
+ 	blk_mq_put_tag(hctx, hctx->tags, rq->mq_ctx, rq->tag);
+ 	rq->tag = -1;
+ 
+ 	if (rq->rq_flags & RQF_MQ_INFLIGHT) {
+ 		rq->rq_flags &= ~RQF_MQ_INFLIGHT;
+ 		atomic_dec(&hctx->nr_active);
+ 	}
+ }
+ 
+ /*
+  * If we fail getting a driver tag because all the driver tags are already
+  * assigned and on the dispatch list, BUT the first entry does not have a
+  * tag, then we could deadlock. For that case, move entries with assigned
+  * driver tags to the front, leaving the set of tagged requests in the
+  * same order, and the untagged set in the same order.
+  */
+ static bool reorder_tags_to_front(struct list_head *list)
+ {
+ 	struct request *rq, *tmp, *first = NULL;
+ 
+ 	list_for_each_entry_safe_reverse(rq, tmp, list, queuelist) {
+ 		if (rq == first)
+ 			break;
+ 		if (rq->tag != -1) {
+ 			list_move(&rq->queuelist, list);
+ 			if (!first)
+ 				first = rq;
+ 		}
+ 	}
+ 
+ 	return first != NULL;
+ }
+ 
++>>>>>>> 99cf1dc580f0 (blk-mq: release driver tag on a requeue event)
  bool blk_mq_dispatch_rq_list(struct blk_mq_hw_ctx *hctx, struct list_head *list)
  {
  	struct request_queue *q = hctx->queue;
* Unmerged path block/blk-mq.c
