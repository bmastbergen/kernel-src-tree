s390/zcrypt: add multi domain support

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [s390] zcrypt: add multi domain support (Hendrik Brueckner) [1380349]
Rebuild_FUZZ: 92.75%
commit-author Ingo Tuchscherer <ingo.tuchscherer@linux.vnet.ibm.com>
commit e28d2af43614eb86f59812e7221735fc221bbc10
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/e28d2af4.failed

Currently the ap infrastructure only supports one domain at a time.
This feature extends the generic cryptographic device driver to
support multiple cryptographic domains simultaneously.

There are now card and queue devices on the AP bus with independent
card and queue drivers. The new /sys layout is as follows:

/sys/bus/ap
    devices
        <xx>.<yyyy> -> ../../../devices/ap/card<xx>/<xx>.<yyyy>
        ...
        card<xx> -> ../../../devices/ap/card<xx>
        ...
    drivers
        <drv>card
            card<xx> -> ../../../../devices/ap/card<xx>
        <drv>queue
            <xx>.<yyyy> -> ../../../../devices/ap/card<xx>/<xx>.<yyyy>
            ...

/sys/devices/ap
    card<xx>
        <xx>.<yyyy>
            driver -> ../../../../bus/ap/drivers/<zzz>queue
            ...
        driver -> ../../../bus/ap/drivers/<drv>card
        ...

The two digit <xx> field is the card number, the four digit <yyyy>
field is the queue number and <drv> is the name of the device driver,
e.g. "cex4".

For compatability /sys/bus/ap/card<xx> for the old layout has to exist,
including the attributes that used to reside there.

With additional contributions from Harald Freudenberger and
Martin Schwidefsky.

	Signed-off-by: Ingo Tuchscherer <ingo.tuchscherer@linux.vnet.ibm.com>
	Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
(cherry picked from commit e28d2af43614eb86f59812e7221735fc221bbc10)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/s390/crypto/Makefile
#	drivers/s390/crypto/ap_bus.c
#	drivers/s390/crypto/ap_bus.h
#	drivers/s390/crypto/zcrypt_api.c
#	drivers/s390/crypto/zcrypt_api.h
#	drivers/s390/crypto/zcrypt_cex2a.c
#	drivers/s390/crypto/zcrypt_cex4.c
#	drivers/s390/crypto/zcrypt_msgtype50.c
#	drivers/s390/crypto/zcrypt_msgtype6.c
#	drivers/s390/crypto/zcrypt_msgtype6.h
#	drivers/s390/crypto/zcrypt_pcixcc.c
diff --cc drivers/s390/crypto/Makefile
index 771faf7094d6,0a7fb83f35e5..000000000000
--- a/drivers/s390/crypto/Makefile
+++ b/drivers/s390/crypto/Makefile
@@@ -2,7 -2,11 +2,18 @@@
  # S/390 crypto devices
  #
  
++<<<<<<< HEAD
 +ap-objs := ap_bus.o
 +obj-$(CONFIG_ZCRYPT) += ap.o zcrypt_api.o zcrypt_pcicc.o zcrypt_pcixcc.o
 +obj-$(CONFIG_ZCRYPT) += zcrypt_pcica.o zcrypt_cex2a.o zcrypt_cex4.o
 +obj-$(CONFIG_ZCRYPT) += zcrypt_msgtype6.o zcrypt_msgtype50.o
++=======
+ ap-objs := ap_bus.o ap_card.o ap_queue.o
+ obj-$(subst m,y,$(CONFIG_ZCRYPT)) += ap.o
+ # zcrypt_api.o and zcrypt_msgtype*.o depend on ap.o
+ zcrypt-objs := zcrypt_api.o zcrypt_card.o zcrypt_queue.o
+ zcrypt-objs += zcrypt_msgtype6.o zcrypt_msgtype50.o
+ obj-$(CONFIG_ZCRYPT) += zcrypt.o
+ # adapter drivers depend on ap.o and zcrypt.o
+ obj-$(CONFIG_ZCRYPT) += zcrypt_pcixcc.o zcrypt_cex2a.o zcrypt_cex4.o
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
diff --cc drivers/s390/crypto/ap_bus.c
index 5386d81f8cd3,ac6c258300cf..000000000000
--- a/drivers/s390/crypto/ap_bus.c
+++ b/drivers/s390/crypto/ap_bus.c
@@@ -45,25 -46,10 +45,26 @@@
  #include <linux/ktime.h>
  #include <asm/facility.h>
  #include <linux/crypto.h>
+ #include <linux/mod_devicetable.h>
  
  #include "ap_bus.h"
 -#include "ap_asm.h"
 +
 +/* Some prototypes. */
 +static void ap_scan_bus(struct work_struct *);
 +static void ap_poll_all(unsigned long);
 +static enum hrtimer_restart ap_poll_timeout(struct hrtimer *);
 +static int ap_poll_thread_start(void);
 +static void ap_poll_thread_stop(void);
 +static void ap_request_timeout(unsigned long);
 +static inline void ap_schedule_poll_timer(void);
 +static int __ap_poll_device(struct ap_device *ap_dev, unsigned long *flags);
 +static int ap_device_remove(struct device *dev);
 +static int ap_device_probe(struct device *dev);
 +static void ap_interrupt_handler(struct airq_struct *airq);
 +static void ap_reset(struct ap_device *ap_dev, unsigned long *flags);
 +static void ap_config_timeout(unsigned long ptr);
 +static int ap_select_domain(void);
 +static void ap_query_configuration(void);
  
  /*
   * Module description.
@@@ -86,23 -73,21 +87,33 @@@ static int ap_thread_flag = 0
  module_param_named(poll_thread, ap_thread_flag, int, S_IRUSR|S_IRGRP);
  MODULE_PARM_DESC(poll_thread, "Turn on/off poll thread, default is 0 (off).");
  
++<<<<<<< HEAD
 +int ap_hwrng_seed = 1;
 +EXPORT_SYMBOL(ap_hwrng_seed);
 +module_param_named(hwrng_seed, ap_hwrng_seed, int, S_IRUSR|S_IRGRP);
 +MODULE_PARM_DESC(hwrng_seed, "Turn on/off hwrng auto seed, default is 1 (on).");
 +
 +static struct device *ap_root_device = NULL;
 +static struct ap_config_info *ap_configuration;
 +static DEFINE_SPINLOCK(ap_device_list_lock);
 +static LIST_HEAD(ap_device_list);
++=======
+ static struct device *ap_root_device;
+ 
+ DEFINE_SPINLOCK(ap_list_lock);
+ LIST_HEAD(ap_card_list);
+ 
+ static struct ap_config_info *ap_configuration;
+ static bool initialised;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  
  /*
 - * Workqueue timer for bus rescan.
 + * Workqueue & timer for bus rescan.
   */
 +static struct workqueue_struct *ap_work_queue;
  static struct timer_list ap_config_timer;
  static int ap_config_time = AP_CONFIG_TIME;
 -static void ap_scan_bus(struct work_struct *);
 -static DECLARE_WORK(ap_scan_work, ap_scan_bus);
 +static DECLARE_WORK(ap_config_work, ap_scan_bus);
  
  /*
   * Tasklet & timer for AP request polling and interrupts
@@@ -144,23 -133,17 +155,37 @@@ static inline int ap_using_interrupts(v
  }
  
  /**
++<<<<<<< HEAD
 + * ap_intructions_available() - Test if AP instructions are available.
 + *
 + * Returns 0 if the AP instructions are installed.
 + */
 +static inline int ap_instructions_available(void)
 +{
 +	register unsigned long reg0 asm ("0") = AP_MKQID(0,0);
 +	register unsigned long reg1 asm ("1") = -ENODEV;
 +	register unsigned long reg2 asm ("2") = 0UL;
 +
 +	asm volatile(
 +		"   .long 0xb2af0000\n"		/* PQAP(TAPQ) */
 +		"0: la    %1,0\n"
 +		"1:\n"
 +		EX_TABLE(0b, 1b)
 +		: "+d" (reg0), "+d" (reg1), "+d" (reg2) : : "cc" );
 +	return reg1;
++=======
+  * ap_airq_ptr() - Get the address of the adapter interrupt indicator
+  *
+  * Returns the address of the local-summary-indicator of the adapter
+  * interrupt handler for AP, or NULL if adapter interrupts are not
+  * available.
+  */
+ void *ap_airq_ptr(void)
+ {
+ 	if (ap_using_interrupts())
+ 		return ap_airq.lsi_ptr;
+ 	return NULL;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  }
  
  /**
@@@ -227,326 -190,89 +252,336 @@@ static inline unsigned long ap_query_fa
  }
  
  /**
 - * ap_init_configuration(): Allocate and query configuration array.
 + * ap_reset_queue(): Reset adjunct processor queue.
 + * @qid: The AP queue number
 + *
 + * Returns AP queue status structure.
   */
 -static void ap_init_configuration(void)
 +static inline struct ap_queue_status ap_reset_queue(ap_qid_t qid)
  {
 -	if (!ap_configuration_available())
 -		return;
 +	register unsigned long reg0 asm ("0") = qid | 0x01000000UL;
 +	register struct ap_queue_status reg1 asm ("1");
 +	register unsigned long reg2 asm ("2") = 0UL;
 +
 +	asm volatile(
 +		".long 0xb2af0000"		/* PQAP(RAPQ) */
 +		: "+d" (reg0), "=d" (reg1), "+d" (reg2) : : "cc");
 +	return reg1;
 +}
  
 -	ap_configuration = kzalloc(sizeof(*ap_configuration), GFP_KERNEL);
 -	if (!ap_configuration)
 -		return;
 -	if (ap_query_configuration() != 0) {
 -		kfree(ap_configuration);
 -		ap_configuration = NULL;
 -		return;
 +#ifdef CONFIG_64BIT
 +/**
 + * ap_queue_interruption_control(): Enable interruption for a specific AP.
 + * @qid: The AP queue number
 + * @ind: The notification indicator byte
 + *
 + * Returns AP queue status.
 + */
 +static inline struct ap_queue_status
 +ap_queue_interruption_control(ap_qid_t qid, void *ind)
 +{
 +	register unsigned long reg0 asm ("0") = qid | 0x03000000UL;
 +	register unsigned long reg1_in asm ("1") = 0x0000800000000000UL | AP_ISC;
 +	register struct ap_queue_status reg1_out asm ("1");
 +	register void *reg2 asm ("2") = ind;
 +	asm volatile(
 +		".long 0xb2af0000"		/* PQAP(AQIC) */
 +		: "+d" (reg0), "+d" (reg1_in), "=d" (reg1_out), "+d" (reg2)
 +		:
 +		: "cc" );
 +	return reg1_out;
 +}
 +#endif
 +
 +#ifdef CONFIG_64BIT
 +static inline struct ap_queue_status
 +__ap_query_functions(ap_qid_t qid, unsigned int *functions)
 +{
 +	register unsigned long reg0 asm ("0") = 0UL | qid | (1UL << 23);
 +	register struct ap_queue_status reg1 asm ("1") = AP_QUEUE_STATUS_INVALID;
 +	register unsigned long reg2 asm ("2");
 +
 +	asm volatile(
 +		".long 0xb2af0000\n"		/* PQAP(TAPQ) */
 +		"0:\n"
 +		EX_TABLE(0b, 0b)
 +		: "+d" (reg0), "+d" (reg1), "=d" (reg2)
 +		:
 +		: "cc");
 +
 +	*functions = (unsigned int)(reg2 >> 32);
 +	return reg1;
 +}
 +#endif
 +
 +#ifdef CONFIG_64BIT
 +static inline int __ap_query_configuration(struct ap_config_info *config)
 +{
 +	register unsigned long reg0 asm ("0") = 0x04000000UL;
 +	register unsigned long reg1 asm ("1") = -EINVAL;
 +	register unsigned char *reg2 asm ("2") = (unsigned char *)config;
 +
 +	asm volatile(
 +		".long 0xb2af0000\n"		/* PQAP(QCI) */
 +		"0: la    %1,0\n"
 +		"1:\n"
 +		EX_TABLE(0b, 1b)
 +		: "+d" (reg0), "+d" (reg1), "+d" (reg2)
 +		:
 +		: "cc");
 +
 +	return reg1;
 +}
 +#endif
 +
 +/**
 + * ap_query_functions(): Query supported functions.
 + * @qid: The AP queue number
 + * @functions: Pointer to functions field.
 + *
 + * Returns
 + *   0	     on success.
 + *   -ENODEV  if queue not valid.
 + *   -EBUSY   if device busy.
 + *   -EINVAL  if query function is not supported
 + */
 +static int ap_query_functions(ap_qid_t qid, unsigned int *functions)
 +{
 +#ifdef CONFIG_64BIT
 +	struct ap_queue_status status;
 +
 +	status = __ap_query_functions(qid, functions);
 +
 +	if (ap_queue_status_invalid_test(&status))
 +		return -ENODEV;
 +
 +	switch (status.response_code) {
 +	case AP_RESPONSE_NORMAL:
 +		return 0;
 +	case AP_RESPONSE_Q_NOT_AVAIL:
 +	case AP_RESPONSE_DECONFIGURED:
 +	case AP_RESPONSE_CHECKSTOPPED:
 +	case AP_RESPONSE_INVALID_ADDRESS:
 +		return -ENODEV;
 +	case AP_RESPONSE_RESET_IN_PROGRESS:
 +	case AP_RESPONSE_BUSY:
 +	case AP_RESPONSE_OTHERWISE_CHANGED:
 +	default:
 +		return -EBUSY;
  	}
 +#else
 +	return -EINVAL;
 +#endif
  }
  
 -/*
 - * ap_test_config(): helper function to extract the nrth bit
 - *		     within the unsigned int array field.
 +/**
++<<<<<<< HEAD
 + * ap_queue_enable_interruption(): Enable interruption on an AP.
 + * @qid: The AP queue number
 + * @ind: the notification indicator byte
 + *
 + * Enables interruption on AP queue via ap_queue_interruption_control(). Based
 + * on the return value it waits a while and tests the AP queue if interrupts
 + * have been switched on using ap_test_queue().
   */
 -static inline int ap_test_config(unsigned int *field, unsigned int nr)
 +static int ap_queue_enable_interruption(struct ap_device *ap_dev, void *ind)
  {
 -	return ap_test_bit((field + (nr >> 5)), (nr & 0x1f));
 +#ifdef CONFIG_64BIT
 +	struct ap_queue_status status;
 +
 +	status = ap_queue_interruption_control(ap_dev->qid, ind);
 +	switch (status.response_code) {
 +	case AP_RESPONSE_NORMAL:
 +	case AP_RESPONSE_OTHERWISE_CHANGED:
 +		return 0;
 +	case AP_RESPONSE_Q_NOT_AVAIL:
 +	case AP_RESPONSE_DECONFIGURED:
 +	case AP_RESPONSE_CHECKSTOPPED:
 +	case AP_RESPONSE_INVALID_ADDRESS:
 +		return -ENODEV;
 +	case AP_RESPONSE_RESET_IN_PROGRESS:
 +	case AP_RESPONSE_BUSY:
 +	default:
 +		return -EBUSY;
 +	}
 +#else
 +	return -EINVAL;
 +#endif
  }
  
 -/*
 - * ap_test_config_card_id(): Test, whether an AP card ID is configured.
 - * @id AP card ID
 +/**
 + * __ap_send(): Send message to adjunct processor queue.
 + * @qid: The AP queue number
 + * @psmid: The program supplied message identifier
 + * @msg: The message text
 + * @length: The message length
 + * @special: Special Bit
   *
 - * Returns 0 if the card is not configured
 - *	   1 if the card is configured or
 - *	     if the configuration information is not available
 + * Returns AP queue status structure.
 + * Condition code 1 on NQAP can't happen because the L bit is 1.
 + * Condition code 2 on NQAP also means the send is incomplete,
 + * because a segment boundary was reached. The NQAP is repeated.
   */
 -static inline int ap_test_config_card_id(unsigned int id)
 +static inline struct ap_queue_status
 +__ap_send(ap_qid_t qid, unsigned long long psmid, void *msg, size_t length,
 +	  unsigned int special)
  {
 -	if (!ap_configuration)	/* QCI not supported */
 -		return 1;
 -	return ap_test_config(ap_configuration->apm, id);
 +	typedef struct { char _[length]; } msgblock;
 +	register unsigned long reg0 asm ("0") = qid | 0x40000000UL;
 +	register struct ap_queue_status reg1 asm ("1");
 +	register unsigned long reg2 asm ("2") = (unsigned long) msg;
 +	register unsigned long reg3 asm ("3") = (unsigned long) length;
 +	register unsigned long reg4 asm ("4") = (unsigned int) (psmid >> 32);
 +	register unsigned long reg5 asm ("5") = (unsigned int) psmid;
 +
 +	if (special == 1)
 +		reg0 |= 0x400000UL;
 +
 +	asm volatile (
 +		"0: .long 0xb2ad0042\n"		/* NQAP */
 +		"   brc   2,0b"
 +		: "+d" (reg0), "=d" (reg1), "+d" (reg2), "+d" (reg3)
 +		: "d" (reg4), "d" (reg5), "m" (*(msgblock *) msg)
 +		: "cc" );
 +	return reg1;
  }
  
 -/*
 - * ap_test_config_domain(): Test, whether an AP usage domain is configured.
 - * @domain AP usage domain ID
 +int ap_send(ap_qid_t qid, unsigned long long psmid, void *msg, size_t length)
 +{
 +	struct ap_queue_status status;
 +
 +	status = __ap_send(qid, psmid, msg, length, 0);
 +	switch (status.response_code) {
 +	case AP_RESPONSE_NORMAL:
 +		return 0;
 +	case AP_RESPONSE_Q_FULL:
 +	case AP_RESPONSE_RESET_IN_PROGRESS:
 +		return -EBUSY;
 +	case AP_RESPONSE_REQ_FAC_NOT_INST:
 +		return -EINVAL;
 +	default:	/* Device is gone. */
 +		return -ENODEV;
 +	}
 +}
 +EXPORT_SYMBOL(ap_send);
 +
 +/**
 + * __ap_recv(): Receive message from adjunct processor queue.
 + * @qid: The AP queue number
 + * @psmid: Pointer to program supplied message identifier
 + * @msg: The message text
 + * @length: The message length
   *
 - * Returns 0 if the usage domain is not configured
 - *	   1 if the usage domain is configured or
 - *	     if the configuration information is not available
 + * Returns AP queue status structure.
 + * Condition code 1 on DQAP means the receive has taken place
 + * but only partially.	The response is incomplete, hence the
 + * DQAP is repeated.
 + * Condition code 2 on DQAP also means the receive is incomplete,
 + * this time because a segment boundary was reached. Again, the
 + * DQAP is repeated.
 + * Note that gpr2 is used by the DQAP instruction to keep track of
 + * any 'residual' length, in case the instruction gets interrupted.
 + * Hence it gets zeroed before the instruction.
   */
 -static inline int ap_test_config_domain(unsigned int domain)
 +static inline struct ap_queue_status
 +__ap_recv(ap_qid_t qid, unsigned long long *psmid, void *msg, size_t length)
  {
 -	if (!ap_configuration)	/* QCI not supported */
 -		return domain < 16;
 -	return ap_test_config(ap_configuration->aqm, domain);
 +	typedef struct { char _[length]; } msgblock;
 +	register unsigned long reg0 asm("0") = qid | 0x80000000UL;
 +	register struct ap_queue_status reg1 asm ("1");
 +	register unsigned long reg2 asm("2") = 0UL;
 +	register unsigned long reg4 asm("4") = (unsigned long) msg;
 +	register unsigned long reg5 asm("5") = (unsigned long) length;
 +	register unsigned long reg6 asm("6") = 0UL;
 +	register unsigned long reg7 asm("7") = 0UL;
 +
 +
 +	asm volatile(
 +		"0: .long 0xb2ae0064\n"		/* DQAP */
 +		"   brc   6,0b\n"
 +		: "+d" (reg0), "=d" (reg1), "+d" (reg2),
 +		"+d" (reg4), "+d" (reg5), "+d" (reg6), "+d" (reg7),
 +		"=m" (*(msgblock *) msg) : : "cc" );
 +	*psmid = (((unsigned long long) reg6) << 32) + reg7;
 +	return reg1;
 +}
 +
 +int ap_recv(ap_qid_t qid, unsigned long long *psmid, void *msg, size_t length)
 +{
 +	struct ap_queue_status status;
 +
 +	status = __ap_recv(qid, psmid, msg, length);
 +	switch (status.response_code) {
 +	case AP_RESPONSE_NORMAL:
 +		return 0;
 +	case AP_RESPONSE_NO_PENDING_REPLY:
 +		if (status.queue_empty)
 +			return -ENOENT;
 +		return -EBUSY;
 +	case AP_RESPONSE_RESET_IN_PROGRESS:
 +		return -EBUSY;
 +	default:
 +		return -ENODEV;
 +	}
  }
 +EXPORT_SYMBOL(ap_recv);
 +
 +/**
 + * __ap_schedule_poll_timer(): Schedule poll timer.
 + *
 + * Set up the timer to run the poll tasklet
 + */
 +static inline void __ap_schedule_poll_timer(void)
 +{
 +	ktime_t hr_time;
 +
 +	spin_lock_bh(&ap_poll_timer_lock);
 +	if (!hrtimer_is_queued(&ap_poll_timer) && !ap_suspend_flag) {
 +		hr_time = ktime_set(0, poll_timeout);
 +		hrtimer_forward_now(&ap_poll_timer, hr_time);
 +		hrtimer_restart(&ap_poll_timer);
 +	}
 +	spin_unlock_bh(&ap_poll_timer_lock);
 +}
 +
 +/**
 + * ap_schedule_poll_timer(): Schedule poll timer.
 + *
 + * Set up the timer to run the poll tasklet
 + */
 +static inline void ap_schedule_poll_timer(void)
 +{
 +	if (ap_using_interrupts())
 +		return;
 +	__ap_schedule_poll_timer();
 +}
 +
  
  /**
++=======
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
   * ap_query_queue(): Check if an AP queue is available.
   * @qid: The AP queue number
   * @queue_depth: Pointer to queue depth value
   * @device_type: Pointer to device type value
 - * @facilities: Pointer to facility indicator
   */
 -static int ap_query_queue(ap_qid_t qid, int *queue_depth, int *device_type,
 -			  unsigned int *facilities)
 +static int ap_query_queue(ap_qid_t qid, int *queue_depth, int *device_type)
  {
  	struct ap_queue_status status;
 -	unsigned long info;
 -	int nd;
 +	int t_depth, t_device_type;
  
++<<<<<<< HEAD
 +	status = ap_test_queue(qid, &t_depth, &t_device_type);
++=======
+ 	if (!ap_test_config_card_id(AP_QID_CARD(qid)))
+ 		return -ENODEV;
+ 
+ 	status = ap_test_queue(qid, &info);
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	switch (status.response_code) {
  	case AP_RESPONSE_NORMAL:
 -		*queue_depth = (int)(info & 0xff);
 -		*device_type = (int)((info >> 24) & 0xff);
 -		*facilities = (unsigned int)(info >> 32);
 -		/* Update maximum domain id */
 -		nd = (info >> 16) & 0xff;
 -		if ((info & (1UL << 57)) && nd > 0)
 -			ap_max_domain_id = nd;
 +		*queue_depth = t_depth + 1;
 +		*device_type = t_device_type;
  		return 0;
  	case AP_RESPONSE_Q_NOT_AVAIL:
  	case AP_RESPONSE_DECONFIGURED:
@@@ -562,234 -288,189 +597,420 @@@
  	}
  }
  
++<<<<<<< HEAD
 +/**
 + * ap_init_queue(): Reset an AP queue.
 + * @qid: The AP queue number
 + *
 + * Submit the Reset command to an AP queue.
 + * Since the reset is asynchron set the state to 'RESET_IN_PROGRESS'
 + * and check later via ap_poll_queue() if the reset is done.
 + */
 +static int ap_init_queue(struct ap_device *ap_dev)
 +{
 +	struct ap_queue_status status;
 +
 +	status = ap_reset_queue(ap_dev->qid);
 +	switch (status.response_code) {
 +	case AP_RESPONSE_NORMAL:
 +		ap_dev->interrupt = AP_INTR_DISABLED;
 +		ap_dev->reset = AP_RESET_IN_PROGRESS;
 +		return 0;
 +	case AP_RESPONSE_RESET_IN_PROGRESS:
 +	case AP_RESPONSE_BUSY:
 +		return -EBUSY;
 +	case AP_RESPONSE_Q_NOT_AVAIL:
 +	case AP_RESPONSE_DECONFIGURED:
 +	case AP_RESPONSE_CHECKSTOPPED:
 +	default:
 +		return -ENODEV;
 +	}
 +}
 +
 +/**
 + * ap_increase_queue_count(): Arm request timeout.
 + * @ap_dev: Pointer to an AP device.
 + *
 + * Arm request timeout if an AP device was idle and a new request is submitted.
 + */
 +static void ap_increase_queue_count(struct ap_device *ap_dev)
 +{
 +	int timeout = ap_dev->drv->request_timeout;
 +
 +	ap_dev->queue_count++;
 +	if (ap_dev->queue_count == 1) {
 +		mod_timer(&ap_dev->timeout, jiffies + timeout);
 +		ap_dev->reset = AP_RESET_ARMED;
 +	}
 +}
 +
 +/**
 + * ap_decrease_queue_count(): Decrease queue count.
 + * @ap_dev: Pointer to an AP device.
 + *
 + * If AP device is still alive, re-schedule request timeout if there are still
 + * pending requests.
 + */
 +static void ap_decrease_queue_count(struct ap_device *ap_dev)
 +{
 +	int timeout = ap_dev->drv->request_timeout;
 +
 +	ap_dev->queue_count--;
 +	if (ap_dev->queue_count > 0)
 +		mod_timer(&ap_dev->timeout, jiffies + timeout);
 +	else
 +		/*
 +		 * The timeout timer should to be disabled now - since
 +		 * del_timer_sync() is very expensive, we just tell via the
 +		 * reset flag to ignore the pending timeout timer.
 +		 */
 +		ap_dev->reset = AP_RESET_IGNORE;
 +}
 +
 +/*
 + * AP device related attributes.
 + */
 +static ssize_t ap_hwtype_show(struct device *dev,
 +			      struct device_attribute *attr, char *buf)
 +{
 +	struct ap_device *ap_dev = to_ap_dev(dev);
 +	return snprintf(buf, PAGE_SIZE, "%d\n", ap_dev->device_type);
 +}
 +
 +static DEVICE_ATTR(hwtype, 0444, ap_hwtype_show, NULL);
 +
 +static ssize_t ap_raw_hwtype_show(struct device *dev,
 +			      struct device_attribute *attr, char *buf)
 +{
 +	struct ap_device *ap_dev = to_ap_dev(dev);
 +
 +	return snprintf(buf, PAGE_SIZE, "%d\n", ap_dev->raw_hwtype);
 +}
 +
 +static DEVICE_ATTR(raw_hwtype, 0444, ap_raw_hwtype_show, NULL);
 +
 +static ssize_t ap_depth_show(struct device *dev, struct device_attribute *attr,
 +			     char *buf)
 +{
 +	struct ap_device *ap_dev = to_ap_dev(dev);
 +	return snprintf(buf, PAGE_SIZE, "%d\n", ap_dev->queue_depth);
 +}
 +
 +static DEVICE_ATTR(depth, 0444, ap_depth_show, NULL);
 +static ssize_t ap_request_count_show(struct device *dev,
 +				     struct device_attribute *attr,
 +				     char *buf)
 +{
 +	struct ap_device *ap_dev = to_ap_dev(dev);
 +	int rc;
 +
 +	spin_lock_bh(&ap_dev->lock);
 +	rc = snprintf(buf, PAGE_SIZE, "%d\n", ap_dev->total_request_count);
 +	spin_unlock_bh(&ap_dev->lock);
 +	return rc;
 +}
 +
 +static DEVICE_ATTR(request_count, 0444, ap_request_count_show, NULL);
 +
 +static ssize_t ap_requestq_count_show(struct device *dev,
 +				      struct device_attribute *attr, char *buf)
 +{
 +	struct ap_device *ap_dev = to_ap_dev(dev);
 +	int rc;
 +
 +	spin_lock_bh(&ap_dev->lock);
 +	rc = snprintf(buf, PAGE_SIZE, "%d\n", ap_dev->requestq_count);
 +	spin_unlock_bh(&ap_dev->lock);
 +	return rc;
 +}
 +
 +static DEVICE_ATTR(requestq_count, 0444, ap_requestq_count_show, NULL);
 +
 +static ssize_t ap_pendingq_count_show(struct device *dev,
 +				      struct device_attribute *attr, char *buf)
 +{
 +	struct ap_device *ap_dev = to_ap_dev(dev);
 +	int rc;
 +
 +	spin_lock_bh(&ap_dev->lock);
 +	rc = snprintf(buf, PAGE_SIZE, "%d\n", ap_dev->pendingq_count);
 +	spin_unlock_bh(&ap_dev->lock);
 +	return rc;
 +}
 +
 +static DEVICE_ATTR(pendingq_count, 0444, ap_pendingq_count_show, NULL);
 +
 +static ssize_t ap_reset_show(struct device *dev,
 +				      struct device_attribute *attr, char *buf)
 +{
 +	struct ap_device *ap_dev = to_ap_dev(dev);
 +	int rc = 0;
 +
 +	spin_lock_bh(&ap_dev->lock);
 +	switch (ap_dev->reset) {
 +	case AP_RESET_IGNORE:
 +		rc = snprintf(buf, PAGE_SIZE, "No Reset Timer set.\n");
 +		break;
 +	case AP_RESET_ARMED:
 +		rc = snprintf(buf, PAGE_SIZE, "Reset Timer armed.\n");
 +		break;
 +	case AP_RESET_DO:
 +		rc = snprintf(buf, PAGE_SIZE, "Reset Timer expired.\n");
 +		break;
 +	case AP_RESET_IN_PROGRESS:
 +		rc = snprintf(buf, PAGE_SIZE, "Reset in progress.\n");
 +		break;
 +	default:
 +		break;
 +	}
 +	spin_unlock_bh(&ap_dev->lock);
 +	return rc;
 +}
 +
 +static DEVICE_ATTR(reset, 0444, ap_reset_show, NULL);
 +
 +static ssize_t ap_interrupt_show(struct device *dev,
 +				      struct device_attribute *attr, char *buf)
 +{
 +	struct ap_device *ap_dev = to_ap_dev(dev);
 +	int rc = 0;
 +
 +	spin_lock_bh(&ap_dev->lock);
 +	switch (ap_dev->interrupt) {
 +	case AP_INTR_DISABLED:
 +		rc = snprintf(buf, PAGE_SIZE, "Interrupts disabled.\n");
 +		break;
 +	case AP_INTR_ENABLED:
 +		rc = snprintf(buf, PAGE_SIZE, "Interrupts enabled.\n");
 +		break;
 +	case AP_INTR_IN_PROGRESS:
 +		rc = snprintf(buf, PAGE_SIZE, "Enable Interrupt pending.\n");
 +		break;
 +	}
 +	spin_unlock_bh(&ap_dev->lock);
 +	return rc;
 +}
 +
 +static DEVICE_ATTR(interrupt, 0444, ap_interrupt_show, NULL);
 +
 +static ssize_t ap_modalias_show(struct device *dev,
 +				struct device_attribute *attr, char *buf)
 +{
 +	return sprintf(buf, "ap:t%02X\n", to_ap_dev(dev)->device_type);
 +}
 +
 +static DEVICE_ATTR(modalias, 0444, ap_modalias_show, NULL);
 +
 +static ssize_t ap_functions_show(struct device *dev,
 +				 struct device_attribute *attr, char *buf)
 +{
 +	struct ap_device *ap_dev = to_ap_dev(dev);
 +	return snprintf(buf, PAGE_SIZE, "0x%08X\n", ap_dev->functions);
 +}
 +
 +static DEVICE_ATTR(ap_functions, 0444, ap_functions_show, NULL);
 +
 +static struct attribute *ap_dev_attrs[] = {
 +	&dev_attr_hwtype.attr,
 +	&dev_attr_raw_hwtype.attr,
 +	&dev_attr_depth.attr,
 +	&dev_attr_request_count.attr,
 +	&dev_attr_requestq_count.attr,
 +	&dev_attr_pendingq_count.attr,
 +	&dev_attr_reset.attr,
 +	&dev_attr_interrupt.attr,
 +	&dev_attr_modalias.attr,
 +	&dev_attr_ap_functions.attr,
 +	NULL
 +};
 +static struct attribute_group ap_dev_attr_group = {
 +	.attrs = ap_dev_attrs
 +};
++=======
+ void ap_wait(enum ap_wait wait)
+ {
+ 	ktime_t hr_time;
+ 
+ 	switch (wait) {
+ 	case AP_WAIT_AGAIN:
+ 	case AP_WAIT_INTERRUPT:
+ 		if (ap_using_interrupts())
+ 			break;
+ 		if (ap_poll_kthread) {
+ 			wake_up(&ap_poll_wait);
+ 			break;
+ 		}
+ 		/* Fall through */
+ 	case AP_WAIT_TIMEOUT:
+ 		spin_lock_bh(&ap_poll_timer_lock);
+ 		if (!hrtimer_is_queued(&ap_poll_timer)) {
+ 			hr_time = ktime_set(0, poll_timeout);
+ 			hrtimer_forward_now(&ap_poll_timer, hr_time);
+ 			hrtimer_restart(&ap_poll_timer);
+ 		}
+ 		spin_unlock_bh(&ap_poll_timer_lock);
+ 		break;
+ 	case AP_WAIT_NONE:
+ 	default:
+ 		break;
+ 	}
+ }
+ 
+ /**
+  * ap_request_timeout(): Handling of request timeouts
+  * @data: Holds the AP device.
+  *
+  * Handles request timeouts.
+  */
+ void ap_request_timeout(unsigned long data)
+ {
+ 	struct ap_queue *aq = (struct ap_queue *) data;
+ 
+ 	if (ap_suspend_flag)
+ 		return;
+ 	spin_lock_bh(&aq->lock);
+ 	ap_wait(ap_sm_event(aq, AP_EVENT_TIMEOUT));
+ 	spin_unlock_bh(&aq->lock);
+ }
+ 
+ /**
+  * ap_poll_timeout(): AP receive polling for finished AP requests.
+  * @unused: Unused pointer.
+  *
+  * Schedules the AP tasklet using a high resolution timer.
+  */
+ static enum hrtimer_restart ap_poll_timeout(struct hrtimer *unused)
+ {
+ 	if (!ap_suspend_flag)
+ 		tasklet_schedule(&ap_tasklet);
+ 	return HRTIMER_NORESTART;
+ }
+ 
+ /**
+  * ap_interrupt_handler() - Schedule ap_tasklet on interrupt
+  * @airq: pointer to adapter interrupt descriptor
+  */
+ static void ap_interrupt_handler(struct airq_struct *airq)
+ {
+ 	inc_irq_stat(IRQIO_APB);
+ 	if (!ap_suspend_flag)
+ 		tasklet_schedule(&ap_tasklet);
+ }
+ 
+ /**
+  * ap_tasklet_fn(): Tasklet to poll all AP devices.
+  * @dummy: Unused variable
+  *
+  * Poll all AP devices on the bus.
+  */
+ static void ap_tasklet_fn(unsigned long dummy)
+ {
+ 	struct ap_card *ac;
+ 	struct ap_queue *aq;
+ 	enum ap_wait wait = AP_WAIT_NONE;
+ 
+ 	/* Reset the indicator if interrupts are used. Thus new interrupts can
+ 	 * be received. Doing it in the beginning of the tasklet is therefor
+ 	 * important that no requests on any AP get lost.
+ 	 */
+ 	if (ap_using_interrupts())
+ 		xchg(ap_airq.lsi_ptr, 0);
+ 
+ 	spin_lock_bh(&ap_list_lock);
+ 	for_each_ap_card(ac) {
+ 		for_each_ap_queue(aq, ac) {
+ 			spin_lock_bh(&aq->lock);
+ 			wait = min(wait, ap_sm_event_loop(aq, AP_EVENT_POLL));
+ 			spin_unlock_bh(&aq->lock);
+ 		}
+ 	}
+ 	spin_unlock_bh(&ap_list_lock);
+ 
+ 	ap_wait(wait);
+ }
+ 
+ static int ap_pending_requests(void)
+ {
+ 	struct ap_card *ac;
+ 	struct ap_queue *aq;
+ 
+ 	spin_lock_bh(&ap_list_lock);
+ 	for_each_ap_card(ac) {
+ 		for_each_ap_queue(aq, ac) {
+ 			if (aq->queue_count == 0)
+ 				continue;
+ 			spin_unlock_bh(&ap_list_lock);
+ 			return 1;
+ 		}
+ 	}
+ 	spin_unlock_bh(&ap_list_lock);
+ 	return 0;
+ }
+ 
+ /**
+  * ap_poll_thread(): Thread that polls for finished requests.
+  * @data: Unused pointer
+  *
+  * AP bus poll thread. The purpose of this thread is to poll for
+  * finished requests in a loop if there is a "free" cpu - that is
+  * a cpu that doesn't have anything better to do. The polling stops
+  * as soon as there is another task or if all messages have been
+  * delivered.
+  */
+ static int ap_poll_thread(void *data)
+ {
+ 	DECLARE_WAITQUEUE(wait, current);
+ 
+ 	set_user_nice(current, MAX_NICE);
+ 	set_freezable();
+ 	while (!kthread_should_stop()) {
+ 		add_wait_queue(&ap_poll_wait, &wait);
+ 		set_current_state(TASK_INTERRUPTIBLE);
+ 		if (ap_suspend_flag || !ap_pending_requests()) {
+ 			schedule();
+ 			try_to_freeze();
+ 		}
+ 		set_current_state(TASK_RUNNING);
+ 		remove_wait_queue(&ap_poll_wait, &wait);
+ 		if (need_resched()) {
+ 			schedule();
+ 			try_to_freeze();
+ 			continue;
+ 		}
+ 		ap_tasklet_fn(0);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int ap_poll_thread_start(void)
+ {
+ 	int rc;
+ 
+ 	if (ap_using_interrupts() || ap_poll_kthread)
+ 		return 0;
+ 	mutex_lock(&ap_poll_thread_mutex);
+ 	ap_poll_kthread = kthread_run(ap_poll_thread, NULL, "appoll");
+ 	rc = PTR_RET(ap_poll_kthread);
+ 	if (rc)
+ 		ap_poll_kthread = NULL;
+ 	mutex_unlock(&ap_poll_thread_mutex);
+ 	return rc;
+ }
+ 
+ static void ap_poll_thread_stop(void)
+ {
+ 	if (!ap_poll_kthread)
+ 		return;
+ 	mutex_lock(&ap_poll_thread_mutex);
+ 	kthread_stop(ap_poll_kthread);
+ 	ap_poll_kthread = NULL;
+ 	mutex_unlock(&ap_poll_thread_mutex);
+ }
+ 
+ #define is_card_dev(x) ((x)->parent == ap_root_device)
+ #define is_queue_dev(x) ((x)->parent != ap_root_device)
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  
  /**
   * ap_bus_match()
@@@ -844,92 -528,110 +1068,165 @@@ static int ap_uevent (struct device *de
  	return retval;
  }
  
 -static int ap_dev_suspend(struct device *dev)
 +static int ap_bus_suspend(struct device *dev, pm_message_t state)
  {
  	struct ap_device *ap_dev = to_ap_dev(dev);
 +	unsigned long flags;
 +
++<<<<<<< HEAD
 +	if (!ap_suspend_flag) {
 +		ap_suspend_flag = 1;
  
 +		/* Disable scanning for devices, thus we do not want to scan
 +		 * for them after removing.
 +		 */
 +		del_timer_sync(&ap_config_timer);
 +		if (ap_work_queue != NULL) {
 +			destroy_workqueue(ap_work_queue);
 +			ap_work_queue = NULL;
 +		}
 +
 +		tasklet_disable(&ap_tasklet);
 +	}
 +	/* Poll on the device until all requests are finished. */
 +	do {
 +		flags = 0;
 +		spin_lock_bh(&ap_dev->lock);
 +		__ap_poll_device(ap_dev, &flags);
 +		spin_unlock_bh(&ap_dev->lock);
 +	} while ((flags & 1) || (flags & 2));
 +
 +	spin_lock_bh(&ap_dev->lock);
 +	ap_dev->unregistered = AP_DEV_UNREGISTERED;
 +	spin_unlock_bh(&ap_dev->lock);
 +
 +	return 0;
 +}
 +
 +static int ap_bus_resume(struct device *dev)
++=======
+ 	if (ap_dev->drv && ap_dev->drv->suspend)
+ 		ap_dev->drv->suspend(ap_dev);
+ 	return 0;
+ }
+ 
+ static int ap_dev_resume(struct device *dev)
+ {
+ 	struct ap_device *ap_dev = to_ap_dev(dev);
+ 
+ 	if (ap_dev->drv && ap_dev->drv->resume)
+ 		ap_dev->drv->resume(ap_dev);
+ 	return 0;
+ }
+ 
+ static void ap_bus_suspend(void)
+ {
+ 	ap_suspend_flag = 1;
+ 	/*
+ 	 * Disable scanning for devices, thus we do not want to scan
+ 	 * for them after removing.
+ 	 */
+ 	flush_work(&ap_scan_work);
+ 	tasklet_disable(&ap_tasklet);
+ }
+ 
+ static int __ap_card_devices_unregister(struct device *dev, void *dummy)
+ {
+ 	if (is_card_dev(dev))
+ 		device_unregister(dev);
+ 	return 0;
+ }
+ 
+ static int __ap_queue_devices_unregister(struct device *dev, void *dummy)
+ {
+ 	if (is_queue_dev(dev))
+ 		device_unregister(dev);
+ 	return 0;
+ }
+ 
+ static int __ap_queue_devices_with_id_unregister(struct device *dev, void *data)
+ {
+ 	if (is_queue_dev(dev) &&
+ 	    AP_QID_CARD(to_ap_queue(dev)->qid) == (int)(long) data)
+ 		device_unregister(dev);
+ 	return 0;
+ }
+ 
+ static void ap_bus_resume(void)
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  {
 +	struct ap_device *ap_dev = to_ap_dev(dev);
  	int rc;
  
++<<<<<<< HEAD
 +	if (ap_suspend_flag) {
 +		ap_suspend_flag = 0;
 +		if (ap_interrupts_available()) {
 +			if (!ap_using_interrupts()) {
 +				rc = register_adapter_interrupt(&ap_airq);
 +				ap_airq_flag = (rc == 0);
 +			}
 +		} else {
 +			if (ap_using_interrupts()) {
 +				unregister_adapter_interrupt(&ap_airq);
 +				ap_airq_flag = 0;
 +			}
 +		}
 +		ap_query_configuration();
 +		if (!user_set_domain) {
 +			ap_domain_index = -1;
 +			ap_select_domain();
 +		}
 +		init_timer(&ap_config_timer);
 +		ap_config_timer.function = ap_config_timeout;
 +		ap_config_timer.data = 0;
 +		ap_config_timer.expires = jiffies + ap_config_time * HZ;
 +		add_timer(&ap_config_timer);
 +		ap_work_queue = create_singlethread_workqueue("kapwork");
 +		if (!ap_work_queue)
 +			return -ENOMEM;
 +		tasklet_enable(&ap_tasklet);
 +		if (!ap_using_interrupts())
 +			ap_schedule_poll_timer();
 +		else
 +			tasklet_schedule(&ap_tasklet);
 +		if (ap_thread_flag)
 +			rc = ap_poll_thread_start();
 +		else
 +			rc = 0;
 +	} else
 +		rc = 0;
 +	if (AP_QID_QUEUE(ap_dev->qid) != ap_domain_index) {
 +		spin_lock_bh(&ap_dev->lock);
 +		ap_dev->qid = AP_MKQID(AP_QID_DEVICE(ap_dev->qid),
 +				       ap_domain_index);
 +		spin_unlock_bh(&ap_dev->lock);
++=======
+ 	/* remove all queue devices */
+ 	bus_for_each_dev(&ap_bus_type, NULL, NULL,
+ 			 __ap_queue_devices_unregister);
+ 	/* remove all card devices */
+ 	bus_for_each_dev(&ap_bus_type, NULL, NULL,
+ 			 __ap_card_devices_unregister);
+ 
+ 	/* Reset thin interrupt setting */
+ 	if (ap_interrupts_available() && !ap_using_interrupts()) {
+ 		rc = register_adapter_interrupt(&ap_airq);
+ 		ap_airq_flag = (rc == 0);
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	}
 -	if (!ap_interrupts_available() && ap_using_interrupts()) {
 -		unregister_adapter_interrupt(&ap_airq);
 -		ap_airq_flag = 0;
 -	}
 -	/* Reset domain */
 -	if (!user_set_domain)
 -		ap_domain_index = -1;
 -	/* Get things going again */
 -	ap_suspend_flag = 0;
 -	if (ap_airq_flag)
 -		xchg(ap_airq.lsi_ptr, 0);
 -	tasklet_enable(&ap_tasklet);
 -	queue_work(system_long_wq, &ap_scan_work);
 -}
 +	queue_work(ap_work_queue, &ap_config_work);
  
 -static int ap_power_event(struct notifier_block *this, unsigned long event,
 -			  void *ptr)
 -{
 -	switch (event) {
 -	case PM_HIBERNATION_PREPARE:
 -	case PM_SUSPEND_PREPARE:
 -		ap_bus_suspend();
 -		break;
 -	case PM_POST_HIBERNATION:
 -	case PM_POST_SUSPEND:
 -		ap_bus_resume();
 -		break;
 -	default:
 -		break;
 -	}
 -	return NOTIFY_DONE;
 +	return rc;
  }
++<<<<<<< HEAD
++=======
+ static struct notifier_block ap_power_notifier = {
+ 	.notifier_call = ap_power_event,
+ };
+ 
+ static SIMPLE_DEV_PM_OPS(ap_bus_pm_ops, ap_dev_suspend, ap_dev_resume);
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  
  static struct bus_type ap_bus_type = {
  	.name = "ap",
@@@ -964,51 -653,19 +1261,55 @@@ static int ap_device_probe(struct devic
  	return rc;
  }
  
++<<<<<<< HEAD
 +/**
 + * __ap_flush_queue(): Flush requests.
 + * @ap_dev: Pointer to the AP device
 + *
 + * Flush all requests from the request/pending queue of an AP device.
 + */
 +static void __ap_flush_queue(struct ap_device *ap_dev)
 +{
 +	struct ap_message *ap_msg, *next;
 +
 +	list_for_each_entry_safe(ap_msg, next, &ap_dev->pendingq, list) {
 +		list_del_init(&ap_msg->list);
 +		ap_dev->pendingq_count--;
 +		ap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));
 +	}
 +	list_for_each_entry_safe(ap_msg, next, &ap_dev->requestq, list) {
 +		list_del_init(&ap_msg->list);
 +		ap_dev->requestq_count--;
 +		ap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));
 +	}
 +}
 +
 +void ap_flush_queue(struct ap_device *ap_dev)
 +{
 +	spin_lock_bh(&ap_dev->lock);
 +	__ap_flush_queue(ap_dev);
 +	spin_unlock_bh(&ap_dev->lock);
 +}
 +EXPORT_SYMBOL(ap_flush_queue);
 +
++=======
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  static int ap_device_remove(struct device *dev)
  {
  	struct ap_device *ap_dev = to_ap_dev(dev);
  	struct ap_driver *ap_drv = ap_dev->drv;
  
- 	ap_flush_queue(ap_dev);
- 	del_timer_sync(&ap_dev->timeout);
- 	spin_lock_bh(&ap_device_list_lock);
- 	list_del_init(&ap_dev->list);
- 	spin_unlock_bh(&ap_device_list_lock);
+ 	spin_lock_bh(&ap_list_lock);
+ 	if (is_card_dev(dev))
+ 		list_del_init(&to_ap_card(dev)->list);
+ 	else
+ 		list_del_init(&to_ap_queue(dev)->list);
+ 	spin_unlock_bh(&ap_list_lock);
  	if (ap_drv->remove)
  		ap_drv->remove(ap_dev);
 +	spin_lock_bh(&ap_dev->lock);
 +	atomic_sub(ap_dev->queue_count, &ap_poll_requests);
 +	spin_unlock_bh(&ap_dev->lock);
  	return 0;
  }
  
@@@ -1099,10 -729,11 +1400,18 @@@ static BUS_ATTR(ap_domain, 0444, ap_dom
  
  static ssize_t ap_control_domain_mask_show(struct bus_type *bus, char *buf)
  {
++<<<<<<< HEAD
 +	if (ap_configuration != NULL) { /* QCI not supported */
 +		if (test_facility(76)) { /* format 1 - 256 bit domain field */
 +			return snprintf(buf, PAGE_SIZE,
 +				"0x%08x%08x%08x%08x%08x%08x%08x%08x\n",
++=======
+ 	if (!ap_configuration)	/* QCI not supported */
+ 		return snprintf(buf, PAGE_SIZE, "not supported\n");
+ 
+ 	return snprintf(buf, PAGE_SIZE,
+ 			"0x%08x%08x%08x%08x%08x%08x%08x%08x\n",
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  			ap_configuration->adm[0], ap_configuration->adm[1],
  			ap_configuration->adm[2], ap_configuration->adm[3],
  			ap_configuration->adm[4], ap_configuration->adm[5],
@@@ -1321,693 -912,172 +1647,849 @@@ static int ap_select_domain(void
  	return -ENODEV;
  }
  
++<<<<<<< HEAD
 +/**
 + * ap_probe_device_type(): Find the device type of an AP.
 + * @ap_dev: pointer to the AP device.
 + *
 + * Find the device type if query queue returned a device type of 0.
 + */
 +static int ap_probe_device_type(struct ap_device *ap_dev)
 +{
 +	static unsigned char msg[] = {
 +		0x00,0x06,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x58,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x01,0x00,0x43,0x43,0x41,0x2d,0x41,0x50,
 +		0x50,0x4c,0x20,0x20,0x20,0x01,0x01,0x01,
 +		0x00,0x00,0x00,0x00,0x50,0x4b,0x00,0x00,
 +		0x00,0x00,0x01,0x1c,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x05,0xb8,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x70,0x00,0x41,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x54,0x32,0x01,0x00,0xa0,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0xb8,0x05,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x0a,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
 +		0x00,0x00,0x00,0x00,0x00,0x00,0x08,0x00,
 +		0x49,0x43,0x53,0x46,0x20,0x20,0x20,0x20,
 +		0x50,0x4b,0x0a,0x00,0x50,0x4b,0x43,0x53,
 +		0x2d,0x31,0x2e,0x32,0x37,0x00,0x11,0x22,
 +		0x33,0x44,0x55,0x66,0x77,0x88,0x99,0x00,
 +		0x11,0x22,0x33,0x44,0x55,0x66,0x77,0x88,
 +		0x99,0x00,0x11,0x22,0x33,0x44,0x55,0x66,
 +		0x77,0x88,0x99,0x00,0x11,0x22,0x33,0x44,
 +		0x55,0x66,0x77,0x88,0x99,0x00,0x11,0x22,
 +		0x33,0x44,0x55,0x66,0x77,0x88,0x99,0x00,
 +		0x11,0x22,0x33,0x5d,0x00,0x5b,0x00,0x77,
 +		0x88,0x1e,0x00,0x00,0x57,0x00,0x00,0x00,
 +		0x00,0x04,0x00,0x00,0x4f,0x00,0x00,0x00,
 +		0x03,0x02,0x00,0x00,0x40,0x01,0x00,0x01,
 +		0xce,0x02,0x68,0x2d,0x5f,0xa9,0xde,0x0c,
 +		0xf6,0xd2,0x7b,0x58,0x4b,0xf9,0x28,0x68,
 +		0x3d,0xb4,0xf4,0xef,0x78,0xd5,0xbe,0x66,
 +		0x63,0x42,0xef,0xf8,0xfd,0xa4,0xf8,0xb0,
 +		0x8e,0x29,0xc2,0xc9,0x2e,0xd8,0x45,0xb8,
 +		0x53,0x8c,0x6f,0x4e,0x72,0x8f,0x6c,0x04,
 +		0x9c,0x88,0xfc,0x1e,0xc5,0x83,0x55,0x57,
 +		0xf7,0xdd,0xfd,0x4f,0x11,0x36,0x95,0x5d,
 +	};
 +	struct ap_queue_status status;
 +	unsigned long long psmid;
 +	char *reply;
 +	int rc, i;
 +
 +	reply = (void *) get_zeroed_page(GFP_KERNEL);
 +	if (!reply) {
 +		rc = -ENOMEM;
 +		goto out;
 +	}
 +
 +	status = __ap_send(ap_dev->qid, 0x0102030405060708ULL,
 +			   msg, sizeof(msg), 0);
 +	if (status.response_code != AP_RESPONSE_NORMAL) {
 +		rc = -ENODEV;
 +		goto out_free;
 +	}
 +
 +	/* Wait for the test message to complete. */
 +	for (i = 0; i < 6; i++) {
 +		mdelay(300);
 +		status = __ap_recv(ap_dev->qid, &psmid, reply, 4096);
 +		if (status.response_code == AP_RESPONSE_NORMAL &&
 +		    psmid == 0x0102030405060708ULL)
 +			break;
 +	}
 +	if (i < 6) {
 +		/* Got an answer. */
 +		if (reply[0] == 0x00 && reply[1] == 0x86)
 +			ap_dev->device_type = AP_DEVICE_TYPE_PCICC;
 +		else
 +			ap_dev->device_type = AP_DEVICE_TYPE_PCICA;
 +		rc = 0;
 +	} else
 +		rc = -ENODEV;
 +
 +out_free:
 +	free_page((unsigned long) reply);
 +out:
 +	return rc;
 +}
 +
 +static void ap_interrupt_handler(struct airq_struct *airq)
 +{
 +	inc_irq_stat(IRQIO_APB);
 +	tasklet_schedule(&ap_tasklet);
 +}
 +
 +/**
 + * __ap_scan_bus(): Scan the AP bus.
 + * @dev: Pointer to device
 + * @data: Pointer to data
 + *
 + * Scan the AP bus for new devices.
++=======
+ /*
+  * helper function to be used with bus_find_dev
+  * matches for the card device with the given id
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
   */
- static int __ap_scan_bus(struct device *dev, void *data)
+ static int __match_card_device_with_id(struct device *dev, void *data)
  {
- 	return to_ap_dev(dev)->qid == (ap_qid_t)(unsigned long) data;
 -	return is_card_dev(dev) && to_ap_card(dev)->id == (int)(long) data;
++	return is_card_dev(dev) && to_ap_card(dev)->id == (int)(long) data;
 +}
 +
++<<<<<<< HEAD
 +static void ap_device_release(struct device *dev)
 +{
 +	struct ap_device *ap_dev = to_ap_dev(dev);
 +
 +	kfree(ap_dev);
  }
  
++=======
+ /* helper function to be used with bus_find_dev
+  * matches for the queue device with a given qid
+  */
+ static int __match_queue_device_with_qid(struct device *dev, void *data)
+ {
+ 	return is_queue_dev(dev) && to_ap_queue(dev)->qid == (int)(long) data;
+ }
+ 
+ /**
+  * ap_scan_bus(): Scan the AP bus for new devices
+  * Runs periodically, workqueue timer (ap_config_time)
+  */
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  static void ap_scan_bus(struct work_struct *unused)
  {
- 	struct ap_device *ap_dev;
+ 	struct ap_queue *aq;
+ 	struct ap_card *ac;
  	struct device *dev;
  	ap_qid_t qid;
++<<<<<<< HEAD
 +	int queue_depth = 0, device_type = 0;
 +	unsigned int device_functions;
 +	int rc, i;
 +
 +	ap_query_configuration();
 +	if (ap_select_domain() != 0) {
 +		return;
 +	}
 +	for (i = 0; i < AP_DEVICES; i++) {
 +		qid = AP_MKQID(i, ap_domain_index);
 +		dev = bus_find_device(&ap_bus_type, NULL,
 +				      (void *)(unsigned long)qid,
 +				      __ap_scan_bus);
 +		if (ap_test_config_card_id(i))
 +			rc = ap_query_queue(qid, &queue_depth, &device_type);
 +		else
 +			rc = -ENODEV;
 +		if (dev) {
 +			ap_dev = to_ap_dev(dev);
 +			spin_lock_bh(&ap_dev->lock);
 +			if (rc == -ENODEV ||
 +			    ap_dev->unregistered == AP_DEV_UNREGISTERED) {
 +				spin_unlock_bh(&ap_dev->lock);
 +				if (ap_dev->unregistered == AP_DEV_UNREGISTERED)
 +					i--;
 +				device_unregister(dev);
 +				put_device(dev);
 +				continue;
 +			}
 +			spin_unlock_bh(&ap_dev->lock);
 +			put_device(dev);
 +			continue;
 +		}
 +		if (rc)
 +			continue;
 +		ap_dev = kzalloc(sizeof(*ap_dev), GFP_KERNEL);
 +		if (!ap_dev)
 +			break;
 +		ap_dev->qid = qid;
 +		rc = ap_init_queue(ap_dev);
 +		if ((rc != 0) && (rc != -EBUSY)) {
 +			kfree(ap_dev);
 +			continue;
 +		}
 +		ap_dev->queue_depth = queue_depth;
 +		ap_dev->unregistered = AP_DEV_REGIST_IN_PROGRESS;
 +		spin_lock_init(&ap_dev->lock);
 +		INIT_LIST_HEAD(&ap_dev->pendingq);
 +		INIT_LIST_HEAD(&ap_dev->requestq);
 +		INIT_LIST_HEAD(&ap_dev->list);
 +		setup_timer(&ap_dev->timeout, ap_request_timeout,
 +			    (unsigned long) ap_dev);
 +		switch (device_type) {
 +		case 0:
 +			/* device type probing for old cards */
 +			if (ap_probe_device_type(ap_dev)) {
 +				kfree(ap_dev);
 +				continue;
 +			}
 +			break;
 +		default:
 +			ap_dev->device_type = device_type;
 +		}
 +		ap_dev->raw_hwtype = device_type;
 +		/* CEX6 toleration: map to CEX5 */
 +		if (device_type == AP_DEVICE_TYPE_CEX6)
 +			ap_dev->device_type = AP_DEVICE_TYPE_CEX5;
 +
 +		rc = ap_query_functions(qid, &device_functions);
 +		if (!rc)
 +			ap_dev->functions = device_functions;
 +		else
 +			ap_dev->functions = 0u;
 +
 +		ap_dev->device.bus = &ap_bus_type;
 +		ap_dev->device.parent = ap_root_device;
 +		if (dev_set_name(&ap_dev->device, "card%02x",
 +				 AP_QID_DEVICE(ap_dev->qid))) {
 +			kfree(ap_dev);
 +			continue;
 +		}
 +		ap_dev->device.release = ap_device_release;
 +		rc = device_register(&ap_dev->device);
 +		if (rc) {
 +			put_device(&ap_dev->device);
 +			continue;
 +		}
 +		/* Add device attributes. */
 +		rc = sysfs_create_group(&ap_dev->device.kobj,
 +					&ap_dev_attr_group);
 +		if (!rc) {
 +			spin_lock_bh(&ap_dev->lock);
 +			ap_dev->unregistered = AP_DEV_REGISTERED;
 +			spin_unlock_bh(&ap_dev->lock);
 +		}
 +		else
 +			device_unregister(&ap_dev->device);
 +	}
++=======
+ 	int depth = 0, type = 0;
+ 	unsigned int functions = 0;
+ 	int rc, id, dom, borked, domains;
+ 
+ 	ap_query_configuration();
+ 	if (ap_select_domain() != 0)
+ 		goto out;
+ 
+ 	for (id = 0; id < AP_DEVICES; id++) {
+ 		/* check if device is registered */
+ 		dev = bus_find_device(&ap_bus_type, NULL,
+ 				      (void *)(long) id,
+ 				      __match_card_device_with_id);
+ 		ac = dev ? to_ap_card(dev) : NULL;
+ 		if (!ap_test_config_card_id(id)) {
+ 			if (dev) {
+ 				/* Card device has been removed from
+ 				 * configuration, remove the belonging
+ 				 * queue devices.
+ 				 */
+ 				bus_for_each_dev(&ap_bus_type, NULL,
+ 					(void *)(long) id,
+ 					__ap_queue_devices_with_id_unregister);
+ 				/* now remove the card device */
+ 				device_unregister(dev);
+ 				put_device(dev);
+ 			}
+ 			continue;
+ 		}
+ 		/* According to the configuration there should be a card
+ 		 * device, so check if there is at least one valid queue
+ 		 * and maybe create queue devices and the card device.
+ 		 */
+ 		domains = 0;
+ 		for (dom = 0; dom < AP_DOMAINS; dom++) {
+ 			qid = AP_MKQID(id, dom);
+ 			dev = bus_find_device(&ap_bus_type, NULL,
+ 					      (void *)(long) qid,
+ 					      __match_queue_device_with_qid);
+ 			aq = dev ? to_ap_queue(dev) : NULL;
+ 			if (!ap_test_config_domain(dom)) {
+ 				if (dev) {
+ 					/* Queue device exists but has been
+ 					 * removed from configuration.
+ 					 */
+ 					device_unregister(dev);
+ 					put_device(dev);
+ 				}
+ 				continue;
+ 			}
+ 			rc = ap_query_queue(qid, &depth, &type, &functions);
+ 			if (dev) {
+ 				spin_lock_bh(&aq->lock);
+ 				if (rc == -ENODEV ||
+ 				    /* adapter reconfiguration */
+ 				    (ac && ac->functions != functions))
+ 					aq->state = AP_STATE_BORKED;
+ 				borked = aq->state == AP_STATE_BORKED;
+ 				spin_unlock_bh(&aq->lock);
+ 				if (borked)	/* Remove broken device */
+ 					device_unregister(dev);
+ 				put_device(dev);
+ 				if (!borked) {
+ 					domains++;
+ 					continue;
+ 				}
+ 			}
+ 			if (rc)
+ 				continue;
+ 			/* new queue device needed */
+ 			if (!ac) {
+ 				/* but first create the card device */
+ 				ac = ap_card_create(id, depth,
+ 						    type, functions);
+ 				if (!ac)
+ 					continue;
+ 				ac->ap_dev.device.bus = &ap_bus_type;
+ 				ac->ap_dev.device.parent = ap_root_device;
+ 				dev_set_name(&ac->ap_dev.device,
+ 					     "card%02x", id);
+ 				/* Register card with AP bus */
+ 				rc = device_register(&ac->ap_dev.device);
+ 				if (rc) {
+ 					put_device(&ac->ap_dev.device);
+ 					ac = NULL;
+ 					break;
+ 				}
+ 				/* get it and thus adjust reference counter */
+ 				get_device(&ac->ap_dev.device);
+ 				/* Add card device to card list */
+ 				spin_lock_bh(&ap_list_lock);
+ 				list_add(&ac->list, &ap_card_list);
+ 				spin_unlock_bh(&ap_list_lock);
+ 			}
+ 			/* now create the new queue device */
+ 			aq = ap_queue_create(qid, type);
+ 			if (!aq)
+ 				continue;
+ 			aq->card = ac;
+ 			aq->ap_dev.device.bus = &ap_bus_type;
+ 			aq->ap_dev.device.parent = &ac->ap_dev.device;
+ 			dev_set_name(&aq->ap_dev.device,
+ 				     "%02x.%04x", id, dom);
+ 			/* Add queue device to card queue list */
+ 			spin_lock_bh(&ap_list_lock);
+ 			list_add(&aq->list, &ac->queues);
+ 			spin_unlock_bh(&ap_list_lock);
+ 			/* Start with a device reset */
+ 			spin_lock_bh(&aq->lock);
+ 			ap_wait(ap_sm_event(aq, AP_EVENT_POLL));
+ 			spin_unlock_bh(&aq->lock);
+ 			/* Register device */
+ 			rc = device_register(&aq->ap_dev.device);
+ 			if (rc) {
+ 				spin_lock_bh(&ap_list_lock);
+ 				list_del_init(&aq->list);
+ 				spin_unlock_bh(&ap_list_lock);
+ 				put_device(&aq->ap_dev.device);
+ 				continue;
+ 			}
+ 			domains++;
+ 		} /* end domain loop */
+ 		if (ac) {
+ 			/* remove card dev if there are no queue devices */
+ 			if (!domains)
+ 				device_unregister(&ac->ap_dev.device);
+ 			put_device(&ac->ap_dev.device);
+ 		}
+ 	} /* end device loop */
+ out:
+ 	mod_timer(&ap_config_timer, jiffies + ap_config_time * HZ);
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  }
  
 -static void ap_config_timeout(unsigned long ptr)
 +static void
 +ap_config_timeout(unsigned long ptr)
  {
 -	if (ap_suspend_flag)
 -		return;
 -	queue_work(system_long_wq, &ap_scan_work);
 +	queue_work(ap_work_queue, &ap_config_work);
 +	ap_config_timer.expires = jiffies + ap_config_time * HZ;
 +	add_timer(&ap_config_timer);
 +}
 +
 +/**
 + * ap_poll_read(): Receive pending reply messages from an AP device.
 + * @ap_dev: pointer to the AP device
 + * @flags: pointer to control flags, bit 2^0 is set if another poll is
 + *	   required, bit 2^1 is set if the poll timer needs to get armed
 + *
 + * Returns 0 if the device is still present, -ENODEV if not.
 + */
 +static int ap_poll_read(struct ap_device *ap_dev, unsigned long *flags)
 +{
 +	struct ap_queue_status status;
 +	struct ap_message *ap_msg;
 +
 +	if (ap_dev->queue_count <= 0)
 +		return 0;
 +	status = __ap_recv(ap_dev->qid, &ap_dev->reply->psmid,
 +			   ap_dev->reply->message, ap_dev->reply->length);
 +	switch (status.response_code) {
 +	case AP_RESPONSE_NORMAL:
 +		ap_dev->interrupt = status.int_enabled;
 +		atomic_dec(&ap_poll_requests);
 +		ap_decrease_queue_count(ap_dev);
 +		list_for_each_entry(ap_msg, &ap_dev->pendingq, list) {
 +			if (ap_msg->psmid != ap_dev->reply->psmid)
 +				continue;
 +			list_del_init(&ap_msg->list);
 +			ap_dev->pendingq_count--;
 +			ap_msg->receive(ap_dev, ap_msg, ap_dev->reply);
 +			break;
 +		}
 +		if (ap_dev->queue_count > 0)
 +			*flags |= 1;
 +		break;
 +	case AP_RESPONSE_NO_PENDING_REPLY:
 +		ap_dev->interrupt = status.int_enabled;
 +		if (status.queue_empty) {
 +			/* The card shouldn't forget requests but who knows. */
 +			atomic_sub(ap_dev->queue_count, &ap_poll_requests);
 +			ap_dev->queue_count = 0;
 +			list_splice_init(&ap_dev->pendingq, &ap_dev->requestq);
 +			ap_dev->requestq_count += ap_dev->pendingq_count;
 +			ap_dev->pendingq_count = 0;
 +		} else
 +			*flags |= 2;
 +		break;
 +	default:
 +		return -ENODEV;
 +	}
 +	return 0;
 +}
 +
 +/**
 + * ap_poll_write(): Send messages from the request queue to an AP device.
 + * @ap_dev: pointer to the AP device
 + * @flags: pointer to control flags, bit 2^0 is set if another poll is
 + *	   required, bit 2^1 is set if the poll timer needs to get armed
 + *
 + * Returns 0 if the device is still present, -ENODEV if not.
 + */
 +static int ap_poll_write(struct ap_device *ap_dev, unsigned long *flags)
 +{
 +	struct ap_queue_status status;
 +	struct ap_message *ap_msg;
 +
 +	if (ap_dev->requestq_count <= 0 ||
 +	    (ap_dev->queue_count >= ap_dev->queue_depth) ||
 +	    (ap_dev->reset == AP_RESET_IN_PROGRESS))
 +		return 0;
 +	/* Start the next request on the queue. */
 +	ap_msg = list_entry(ap_dev->requestq.next, struct ap_message, list);
 +	status = __ap_send(ap_dev->qid, ap_msg->psmid,
 +			   ap_msg->message, ap_msg->length, ap_msg->special);
 +	switch (status.response_code) {
 +	case AP_RESPONSE_NORMAL:
 +		atomic_inc(&ap_poll_requests);
 +		ap_increase_queue_count(ap_dev);
 +		list_move_tail(&ap_msg->list, &ap_dev->pendingq);
 +		ap_dev->requestq_count--;
 +		ap_dev->pendingq_count++;
 +		if (ap_dev->queue_count < ap_dev->queue_depth &&
 +		    ap_dev->requestq_count > 0)
 +			*flags |= 1;
 +		*flags |= 2;
 +		break;
 +	case AP_RESPONSE_RESET_IN_PROGRESS:
 +		__ap_schedule_poll_timer();
 +	case AP_RESPONSE_Q_FULL:
 +		*flags |= 2;
 +		break;
 +	case AP_RESPONSE_MESSAGE_TOO_BIG:
 +	case AP_RESPONSE_REQ_FAC_NOT_INST:
 +		return -EINVAL;
 +	default:
 +		return -ENODEV;
 +	}
 +	return 0;
 +}
 +
 +/**
 + * ap_poll_queue(): Poll AP device for pending replies and send new messages.
 + * Check if the queue has a pending reset. In case it's done re-enable
 + * interrupts, otherwise reschedule the poll_timer for another attempt.
 + * @ap_dev: pointer to the bus device
 + * @flags: pointer to control flags, bit 2^0 is set if another poll is
 + *	   required, bit 2^1 is set if the poll timer needs to get armed
 + *
 + * Poll AP device for pending replies and send new messages. If either
 + * ap_poll_read or ap_poll_write returns -ENODEV unregister the device.
 + * Returns 0.
 + */
 +static inline int ap_poll_queue(struct ap_device *ap_dev, unsigned long *flags)
 +{
 +	int rc, depth, type;
 +	struct ap_queue_status status;
 +
 +
 +	if (ap_dev->reset == AP_RESET_IN_PROGRESS) {
 +		status = ap_test_queue(ap_dev->qid, &depth, &type);
 +		switch (status.response_code) {
 +		case AP_RESPONSE_NORMAL:
 +			ap_dev->reset = AP_RESET_IGNORE;
 +			if (ap_using_interrupts()) {
 +				rc = ap_queue_enable_interruption(
 +					ap_dev, ap_airq.lsi_ptr);
 +				if (!rc)
 +					ap_dev->interrupt = AP_INTR_IN_PROGRESS;
 +				else if (rc == -ENODEV) {
 +					pr_err("Registering adapter interrupts for "
 +					"AP %d failed\n", AP_QID_DEVICE(ap_dev->qid));
 +					return rc;
 +				}
 +			}
 +			/* fall through */
 +		case AP_RESPONSE_BUSY:
 +		case AP_RESPONSE_RESET_IN_PROGRESS:
 +			*flags |= AP_POLL_AFTER_TIMEOUT;
 +			break;
 +		case AP_RESPONSE_Q_NOT_AVAIL:
 +		case AP_RESPONSE_DECONFIGURED:
 +		case AP_RESPONSE_CHECKSTOPPED:
 +			return -ENODEV;
 +		default:
 +			break;
 +		}
 +	}
 +
 +	if ((ap_dev->reset != AP_RESET_IN_PROGRESS) &&
 +		(ap_dev->interrupt == AP_INTR_IN_PROGRESS)) {
 +		status = ap_test_queue(ap_dev->qid, &depth, &type);
 +		if (ap_using_interrupts()) {
 +			if (status.int_enabled == 1)
 +				ap_dev->interrupt = AP_INTR_ENABLED;
 +			else
 +				*flags |= AP_POLL_AFTER_TIMEOUT;
 +		} else
 +			ap_dev->interrupt = AP_INTR_DISABLED;
 +	}
 +
 +	rc = ap_poll_read(ap_dev, flags);
 +	if (rc)
 +		return rc;
 +	return ap_poll_write(ap_dev, flags);
 +}
 +
 +/**
 + * __ap_queue_message(): Queue a message to a device.
 + * @ap_dev: pointer to the AP device
 + * @ap_msg: the message to be queued
 + *
 + * Queue a message to a device. Returns 0 if successful.
 + */
 +static int __ap_queue_message(struct ap_device *ap_dev, struct ap_message *ap_msg)
 +{
 +	struct ap_queue_status status;
 +
 +	if (list_empty(&ap_dev->requestq) &&
 +	    (ap_dev->queue_count < ap_dev->queue_depth) &&
 +	    (ap_dev->reset != AP_RESET_IN_PROGRESS)) {
 +		status = __ap_send(ap_dev->qid, ap_msg->psmid,
 +				   ap_msg->message, ap_msg->length,
 +				   ap_msg->special);
 +		switch (status.response_code) {
 +		case AP_RESPONSE_NORMAL:
 +			list_add_tail(&ap_msg->list, &ap_dev->pendingq);
 +			atomic_inc(&ap_poll_requests);
 +			ap_dev->pendingq_count++;
 +			ap_increase_queue_count(ap_dev);
 +			ap_dev->total_request_count++;
 +			break;
 +		case AP_RESPONSE_Q_FULL:
 +		case AP_RESPONSE_RESET_IN_PROGRESS:
 +			list_add_tail(&ap_msg->list, &ap_dev->requestq);
 +			ap_dev->requestq_count++;
 +			ap_dev->total_request_count++;
 +			return -EBUSY;
 +		case AP_RESPONSE_REQ_FAC_NOT_INST:
 +		case AP_RESPONSE_MESSAGE_TOO_BIG:
 +			ap_msg->receive(ap_dev, ap_msg, ERR_PTR(-EINVAL));
 +			return -EINVAL;
 +		default:	/* Device is gone. */
 +			ap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));
 +			return -ENODEV;
 +		}
 +	} else {
 +		list_add_tail(&ap_msg->list, &ap_dev->requestq);
 +		ap_dev->requestq_count++;
 +		ap_dev->total_request_count++;
 +		return -EBUSY;
 +	}
 +	ap_schedule_poll_timer();
 +	return 0;
 +}
 +
 +void ap_queue_message(struct ap_device *ap_dev, struct ap_message *ap_msg)
 +{
 +	unsigned long flags;
 +	int rc;
 +
 +	/* For asynchronous message handling a valid receive-callback
 +	 * is required. */
 +	BUG_ON(!ap_msg->receive);
 +
 +	spin_lock_bh(&ap_dev->lock);
 +	if (!ap_dev->unregistered) {
 +		/* Make room on the queue by polling for finished requests. */
 +		rc = ap_poll_queue(ap_dev, &flags);
 +		if (!rc)
 +			rc = __ap_queue_message(ap_dev, ap_msg);
 +		if (!rc)
 +			wake_up(&ap_poll_wait);
 +		if (rc == -ENODEV) {
 +			ap_dev->unregistered = AP_DEV_UNREGISTERED;
 +			ap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));
 +		}
 +	} else if (ap_dev->unregistered == AP_DEV_UNREGISTERED) {
 +		ap_msg->receive(ap_dev, ap_msg, ERR_PTR(-ENODEV));
 +		rc = -ENODEV;
 +	} else { /* device registration in progress */
 +		ap_msg->receive(ap_dev, ap_msg, ERR_PTR(-EBUSY));
 +		rc = -EBUSY;
 +	}
 +	spin_unlock_bh(&ap_dev->lock);
 +
 +	/* no device_unregister(), let ap_scan_bus() do the job */
 +}
 +EXPORT_SYMBOL(ap_queue_message);
 +
 +/**
 + * ap_cancel_message(): Cancel a crypto request.
 + * @ap_dev: The AP device that has the message queued
 + * @ap_msg: The message that is to be removed
 + *
 + * Cancel a crypto request. This is done by removing the request
 + * from the device pending or request queue. Note that the
 + * request stays on the AP queue. When it finishes the message
 + * reply will be discarded because the psmid can't be found.
 + */
 +void ap_cancel_message(struct ap_device *ap_dev, struct ap_message *ap_msg)
 +{
 +	struct ap_message *tmp;
 +
 +	spin_lock_bh(&ap_dev->lock);
 +	if (!list_empty(&ap_msg->list)) {
 +		list_for_each_entry(tmp, &ap_dev->pendingq, list)
 +			if (tmp->psmid == ap_msg->psmid) {
 +				ap_dev->pendingq_count--;
 +				goto found;
 +			}
 +		ap_dev->requestq_count--;
 +	found:
 +		list_del_init(&ap_msg->list);
 +	}
 +	spin_unlock_bh(&ap_dev->lock);
 +}
 +EXPORT_SYMBOL(ap_cancel_message);
 +
 +/**
 + * ap_poll_timeout(): AP receive polling for finished AP requests.
 + * @unused: Unused pointer.
 + *
 + * Schedules the AP tasklet using a high resolution timer.
 + */
 +static enum hrtimer_restart ap_poll_timeout(struct hrtimer *unused)
 +{
 +	tasklet_schedule(&ap_tasklet);
 +	return HRTIMER_NORESTART;
 +}
 +
 +/**
 + * ap_reset(): Reset a not responding AP device.
 + * @ap_dev: Pointer to the AP device
 + *
 + * Reset a not responding AP device and move all requests from the
 + * pending queue to the request queue.
 + */
 +static void ap_reset(struct ap_device *ap_dev, unsigned long *flags)
 +{
 +	int rc;
 +
 +	atomic_sub(ap_dev->queue_count, &ap_poll_requests);
 +	ap_dev->queue_count = 0;
 +	list_splice_init(&ap_dev->pendingq, &ap_dev->requestq);
 +	ap_dev->requestq_count += ap_dev->pendingq_count;
 +	ap_dev->pendingq_count = 0;
 +	rc = ap_init_queue(ap_dev);
 +	if (rc == -ENODEV)
 +		ap_dev->unregistered = AP_DEV_UNREGISTERED;
 +	else
 +		*flags |= AP_POLL_AFTER_TIMEOUT;
 +}
 +
 +static int __ap_poll_device(struct ap_device *ap_dev, unsigned long *flags)
 +{
 +	int rc;
 +
 +	if (!ap_dev->unregistered) {
 +		rc = ap_poll_queue(ap_dev, flags);
 +		if (rc == -ENODEV)
 +			ap_dev->unregistered = AP_DEV_UNREGISTERED;
 +		if (ap_dev->reset == AP_RESET_DO)
 +			ap_reset(ap_dev, flags);
 +	}
 +	return 0;
 +}
 +
 +/**
 + * ap_poll_all(): Poll all AP devices.
 + * @dummy: Unused variable
 + *
 + * Poll all AP devices on the bus in a round robin fashion. Continue
 + * polling until bit 2^0 of the control flags is not set. If bit 2^1
 + * of the control flags has been set arm the poll timer.
 + */
 +static void ap_poll_all(unsigned long dummy)
 +{
 +	unsigned long flags;
 +	struct ap_device *ap_dev;
 +
 +	/* Reset the indicator if interrupts are used. Thus new interrupts can
 +	 * be received. Doing it in the beginning of the tasklet is therefor
 +	 * important that no requests on any AP get lost.
 +	 */
 +	if (ap_using_interrupts())
 +		xchg(ap_airq.lsi_ptr, 0);
 +	do {
 +		flags = 0;
 +		spin_lock(&ap_device_list_lock);
 +		list_for_each_entry(ap_dev, &ap_device_list, list) {
 +			spin_lock(&ap_dev->lock);
 +			__ap_poll_device(ap_dev, &flags);
 +			spin_unlock(&ap_dev->lock);
 +		}
 +		spin_unlock(&ap_device_list_lock);
 +	} while (flags & AP_POLL_IMMEDIATELY);
 +	if (flags & AP_POLL_AFTER_TIMEOUT)
 +		__ap_schedule_poll_timer();
 +}
 +
 +/**
 + * ap_poll_thread(): Thread that polls for finished requests.
 + * @data: Unused pointer
 + *
 + * AP bus poll thread. The purpose of this thread is to poll for
 + * finished requests in a loop if there is a "free" cpu - that is
 + * a cpu that doesn't have anything better to do. The polling stops
 + * as soon as there is another task or if all messages have been
 + * delivered.
 + */
 +static int ap_poll_thread(void *data)
 +{
 +	DECLARE_WAITQUEUE(wait, current);
 +	unsigned long flags;
 +	int requests;
 +	struct ap_device *ap_dev;
 +
 +	set_user_nice(current, 19);
 +	while (1) {
 +		if (ap_suspend_flag)
 +			return 0;
 +		if (need_resched()) {
 +			schedule();
 +			continue;
 +		}
 +		add_wait_queue(&ap_poll_wait, &wait);
 +		set_current_state(TASK_INTERRUPTIBLE);
 +		if (kthread_should_stop())
 +			break;
 +		requests = atomic_read(&ap_poll_requests);
 +		if (requests <= 0)
 +			schedule();
 +		set_current_state(TASK_RUNNING);
 +		remove_wait_queue(&ap_poll_wait, &wait);
 +
 +		flags = 0;
 +		spin_lock_bh(&ap_device_list_lock);
 +		list_for_each_entry(ap_dev, &ap_device_list, list) {
 +			spin_lock(&ap_dev->lock);
 +			__ap_poll_device(ap_dev, &flags);
 +			spin_unlock(&ap_dev->lock);
 +		}
 +		spin_unlock_bh(&ap_device_list_lock);
 +	}
 +	set_current_state(TASK_RUNNING);
 +	remove_wait_queue(&ap_poll_wait, &wait);
 +	return 0;
 +}
 +
 +static int ap_poll_thread_start(void)
 +{
 +	int rc;
 +
 +	if (ap_using_interrupts() || ap_suspend_flag)
 +		return 0;
 +	mutex_lock(&ap_poll_thread_mutex);
 +	if (!ap_poll_kthread) {
 +		ap_poll_kthread = kthread_run(ap_poll_thread, NULL, "appoll");
 +		rc = IS_ERR(ap_poll_kthread) ? PTR_ERR(ap_poll_kthread) : 0;
 +		if (rc)
 +			ap_poll_kthread = NULL;
 +	}
 +	else
 +		rc = 0;
 +	mutex_unlock(&ap_poll_thread_mutex);
 +	return rc;
 +}
 +
 +static void ap_poll_thread_stop(void)
 +{
 +	mutex_lock(&ap_poll_thread_mutex);
 +	if (ap_poll_kthread) {
 +		kthread_stop(ap_poll_kthread);
 +		ap_poll_kthread = NULL;
 +	}
 +	mutex_unlock(&ap_poll_thread_mutex);
 +}
 +
 +/**
 + * ap_request_timeout(): Handling of request timeouts
 + * @data: Holds the AP device.
 + *
 + * Handles request timeouts.
 + */
 +static void ap_request_timeout(unsigned long data)
 +{
 +	struct ap_device *ap_dev = (struct ap_device *) data;
 +
 +	if (ap_dev->reset == AP_RESET_ARMED) {
 +		ap_dev->reset = AP_RESET_DO;
 +
 +		if (ap_using_interrupts())
 +			tasklet_schedule(&ap_tasklet);
 +	}
  }
  
  static void ap_reset_domain(void)
@@@ -2157,18 -1227,22 +2639,30 @@@ void ap_module_exit(void
  	ap_poll_thread_stop();
  	del_timer_sync(&ap_config_timer);
  	hrtimer_cancel(&ap_poll_timer);
 +	destroy_workqueue(ap_work_queue);
  	tasklet_kill(&ap_tasklet);
++<<<<<<< HEAD
 +	while ((dev = bus_find_device(&ap_bus_type, NULL, NULL,
 +		    __ap_match_all)))
 +	{
 +		device_unregister(dev);
 +		put_device(dev);
 +	}
++=======
+ 
+ 	/* first remove queue devices */
+ 	bus_for_each_dev(&ap_bus_type, NULL, NULL,
+ 			 __ap_queue_devices_unregister);
+ 	/* now remove the card devices */
+ 	bus_for_each_dev(&ap_bus_type, NULL, NULL,
+ 			 __ap_card_devices_unregister);
+ 
+ 	/* remove bus attributes */
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	for (i = 0; ap_bus_attrs[i]; i++)
  		bus_remove_file(&ap_bus_type, ap_bus_attrs[i]);
 -	unregister_pm_notifier(&ap_power_notifier);
  	root_device_unregister(ap_root_device);
  	bus_unregister(&ap_bus_type);
 -	kfree(ap_configuration);
  	unregister_reset_call(&ap_reset_call);
  	if (ap_using_interrupts())
  		unregister_adapter_interrupt(&ap_airq);
diff --cc drivers/s390/crypto/ap_bus.h
index 2da8ecdc7a5f,54b17e142792..000000000000
--- a/drivers/s390/crypto/ap_bus.h
+++ b/drivers/s390/crypto/ap_bus.h
@@@ -36,15 -35,14 +35,18 @@@
  #define AP_CONFIG_TIME 30	/* Time in seconds between AP bus rescans. */
  #define AP_POLL_TIME 1		/* Time in ticks between receive polls. */
  
 +#define AP_POLL_IMMEDIATELY	1 /* continue running poll tasklet */
 +#define AP_POLL_AFTER_TIMEOUT	2 /* run poll tasklet again after timout */
 +
  extern int ap_domain_index;
 +extern int ap_hwrng_seed;
  
+ extern spinlock_t ap_list_lock;
+ extern struct list_head ap_card_list;
+ 
  /**
   * The ap_qid_t identifier of an ap queue. It contains a
-  * 6 bit device index and a 4 bit queue index (domain).
+  * 6 bit card index and a 4 bit queue index (domain).
   */
  typedef unsigned int ap_qid_t;
  
@@@ -175,30 -181,7 +178,34 @@@ void ap_driver_unregister(struct ap_dri
  struct ap_device {
  	struct device device;
  	struct ap_driver *drv;		/* Pointer to AP device driver. */
++<<<<<<< HEAD
 +	spinlock_t lock;		/* Per device lock. */
 +	struct list_head list;		/* private list of all AP devices. */
 +
 +	ap_qid_t qid;			/* AP queue id. */
 +	int queue_depth;		/* AP queue depth.*/
 +	int device_type;		/* AP device type. */
 +	int raw_hwtype;			/* AP raw hardware type. */
 +	unsigned int functions;		/* AP device function bitfield. */
 +	int unregistered;		/* marks AP device as unregistered */
 +	struct timer_list timeout;	/* Timer for request timeouts. */
 +	int reset;			/* Reset required after req. timeout. */
 +
 +	int interrupt;			/* indicate if interrupts are enabled */
 +	int queue_count;		/* # messages currently on AP queue. */
 +
 +	struct list_head pendingq;	/* List of message sent to AP queue. */
 +	int pendingq_count;		/* # requests on pendingq list. */
 +	struct list_head requestq;	/* List of message yet to be sent. */
 +	int requestq_count;		/* # requests on requestq list. */
 +	int total_request_count;	/* # requests ever for this AP device. */
 +
 +	struct ap_message *reply;	/* Per device reply message. */
 +
 +	void *private;			/* ap driver private pointer. */
++=======
+ 	int device_type;		/* AP device type. */
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  };
  
  #define to_ap_dev(x) container_of((x), struct ap_device, device)
@@@ -252,10 -276,26 +298,29 @@@ static inline void ap_init_message(stru
  int ap_send(ap_qid_t, unsigned long long, void *, size_t);
  int ap_recv(ap_qid_t, unsigned long long *, void *, size_t);
  
- void ap_queue_message(struct ap_device *ap_dev, struct ap_message *ap_msg);
- void ap_cancel_message(struct ap_device *ap_dev, struct ap_message *ap_msg);
- void ap_flush_queue(struct ap_device *ap_dev);
+ enum ap_wait ap_sm_event(struct ap_queue *aq, enum ap_event event);
+ enum ap_wait ap_sm_event_loop(struct ap_queue *aq, enum ap_event event);
+ 
+ void ap_queue_message(struct ap_queue *aq, struct ap_message *ap_msg);
+ void ap_cancel_message(struct ap_queue *aq, struct ap_message *ap_msg);
+ void ap_flush_queue(struct ap_queue *aq);
+ 
+ void *ap_airq_ptr(void);
+ void ap_wait(enum ap_wait wait);
+ void ap_request_timeout(unsigned long data);
  void ap_bus_force_rescan(void);
++<<<<<<< HEAD
++=======
+ 
+ void ap_queue_init_reply(struct ap_queue *aq, struct ap_message *ap_msg);
+ struct ap_queue *ap_queue_create(ap_qid_t qid, int device_type);
+ void ap_queue_remove(struct ap_queue *aq);
+ void ap_queue_suspend(struct ap_device *ap_dev);
+ void ap_queue_resume(struct ap_device *ap_dev);
+ 
+ struct ap_card *ap_card_create(int id, int queue_depth, int device_type,
+ 			       unsigned int device_functions);
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  
  int ap_module_init(void);
  void ap_module_exit(void);
diff --cc drivers/s390/crypto/zcrypt_api.c
index aac1d13c55dd,fd0ae8cd2bee..000000000000
--- a/drivers/s390/crypto/zcrypt_api.c
+++ b/drivers/s390/crypto/zcrypt_api.c
@@@ -54,72 -55,26 +54,39 @@@ MODULE_DESCRIPTION("Cryptographic Copro
  		   "Copyright IBM Corp. 2001, 2012");
  MODULE_LICENSE("GPL");
  
++<<<<<<< HEAD
 +static DEFINE_SPINLOCK(zcrypt_device_lock);
 +static LIST_HEAD(zcrypt_device_list);
 +static int zcrypt_device_count = 0;
++=======
+ static int zcrypt_hwrng_seed = 1;
+ module_param_named(hwrng_seed, zcrypt_hwrng_seed, int, S_IRUSR|S_IRGRP);
+ MODULE_PARM_DESC(hwrng_seed, "Turn on/off hwrng auto seed, default is 1 (on).");
+ 
+ DEFINE_SPINLOCK(zcrypt_list_lock);
+ LIST_HEAD(zcrypt_card_list);
+ int zcrypt_device_count;
+ 
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  static atomic_t zcrypt_open_count = ATOMIC_INIT(0);
  static atomic_t zcrypt_rescan_count = ATOMIC_INIT(0);
  
  atomic_t zcrypt_rescan_req = ATOMIC_INIT(0);
  EXPORT_SYMBOL(zcrypt_rescan_req);
  
++<<<<<<< HEAD
 +static int zcrypt_rng_device_add(void);
 +static void zcrypt_rng_device_remove(void);
 +
 +static DEFINE_SPINLOCK(zcrypt_ops_list_lock);
++=======
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  static LIST_HEAD(zcrypt_ops_list);
  
- static debug_info_t *zcrypt_dbf_common;
- static debug_info_t *zcrypt_dbf_devices;
  static struct dentry *debugfs_root;
- 
- /*
-  * Device attributes common for all crypto devices.
-  */
- static ssize_t zcrypt_type_show(struct device *dev,
- 				struct device_attribute *attr, char *buf)
- {
- 	struct zcrypt_device *zdev = to_ap_dev(dev)->private;
- 	return snprintf(buf, PAGE_SIZE, "%s\n", zdev->type_string);
- }
- 
- static DEVICE_ATTR(type, 0444, zcrypt_type_show, NULL);
- 
- static ssize_t zcrypt_online_show(struct device *dev,
- 				  struct device_attribute *attr, char *buf)
- {
- 	struct zcrypt_device *zdev = to_ap_dev(dev)->private;
- 	return snprintf(buf, PAGE_SIZE, "%d\n", zdev->online);
- }
- 
- static ssize_t zcrypt_online_store(struct device *dev,
- 				   struct device_attribute *attr,
- 				   const char *buf, size_t count)
- {
- 	struct zcrypt_device *zdev = to_ap_dev(dev)->private;
- 	int online;
- 
- 	if (sscanf(buf, "%d\n", &online) != 1 || online < 0 || online > 1)
- 		return -EINVAL;
- 	zdev->online = online;
- 	ZCRYPT_DBF_DEV(DBF_INFO, zdev, "dev%04xo%dman", zdev->ap_dev->qid,
- 		       zdev->online);
- 	if (!online)
- 		ap_flush_queue(zdev->ap_dev);
- 	return count;
- }
- 
- static DEVICE_ATTR(online, 0644, zcrypt_online_show, zcrypt_online_store);
- 
- static struct attribute * zcrypt_device_attrs[] = {
- 	&dev_attr_type.attr,
- 	&dev_attr_online.attr,
- 	NULL,
- };
- 
- static struct attribute_group zcrypt_device_attr_group = {
- 	.attrs = zcrypt_device_attrs,
- };
+ debug_info_t *zcrypt_dbf_common;
+ debug_info_t *zcrypt_dbf_devices;
+ debug_info_t *zcrypt_dbf_cards;
  
  /**
   * Process a rescan of the transport layer.
@@@ -139,187 -94,10 +106,190 @@@ static inline int zcrypt_process_rescan
  	return 0;
  }
  
++<<<<<<< HEAD
 +/**
 + * __zcrypt_increase_preference(): Increase preference of a crypto device.
 + * @zdev: Pointer the crypto device
 + *
 + * Move the device towards the head of the device list.
 + * Need to be called while holding the zcrypt device list lock.
 + * Note: cards with speed_rating of 0 are kept at the end of the list.
 + */
 +static void __zcrypt_increase_preference(struct zcrypt_device *zdev)
 +{
 +	struct zcrypt_device *tmp;
 +	struct list_head *l;
 +
 +	if (zdev->speed_rating == 0)
 +		return;
 +	for (l = zdev->list.prev; l != &zcrypt_device_list; l = l->prev) {
 +		tmp = list_entry(l, struct zcrypt_device, list);
 +		if ((tmp->request_count + 1) * tmp->speed_rating <=
 +		    (zdev->request_count + 1) * zdev->speed_rating &&
 +		    tmp->speed_rating != 0)
 +			break;
 +	}
 +	if (l == zdev->list.prev)
 +		return;
 +	/* Move zdev behind l */
 +	list_move(&zdev->list, l);
 +}
 +
 +/**
 + * __zcrypt_decrease_preference(): Decrease preference of a crypto device.
 + * @zdev: Pointer to a crypto device.
 + *
 + * Move the device towards the tail of the device list.
 + * Need to be called while holding the zcrypt device list lock.
 + * Note: cards with speed_rating of 0 are kept at the end of the list.
 + */
 +static void __zcrypt_decrease_preference(struct zcrypt_device *zdev)
 +{
 +	struct zcrypt_device *tmp;
 +	struct list_head *l;
 +
 +	if (zdev->speed_rating == 0)
 +		return;
 +	for (l = zdev->list.next; l != &zcrypt_device_list; l = l->next) {
 +		tmp = list_entry(l, struct zcrypt_device, list);
 +		if ((tmp->request_count + 1) * tmp->speed_rating >
 +		    (zdev->request_count + 1) * zdev->speed_rating ||
 +		    tmp->speed_rating == 0)
 +			break;
 +	}
 +	if (l == zdev->list.next)
 +		return;
 +	/* Move zdev before l */
 +	list_move_tail(&zdev->list, l);
 +}
 +
 +static void zcrypt_device_release(struct kref *kref)
 +{
 +	struct zcrypt_device *zdev =
 +		container_of(kref, struct zcrypt_device, refcount);
 +	zcrypt_device_free(zdev);
 +}
 +
 +void zcrypt_device_get(struct zcrypt_device *zdev)
 +{
 +	kref_get(&zdev->refcount);
 +}
 +EXPORT_SYMBOL(zcrypt_device_get);
 +
 +int zcrypt_device_put(struct zcrypt_device *zdev)
 +{
 +	return kref_put(&zdev->refcount, zcrypt_device_release);
 +}
 +EXPORT_SYMBOL(zcrypt_device_put);
 +
 +struct zcrypt_device *zcrypt_device_alloc(size_t max_response_size)
 +{
 +	struct zcrypt_device *zdev;
 +
 +	zdev = kzalloc(sizeof(struct zcrypt_device), GFP_KERNEL);
 +	if (!zdev)
 +		return NULL;
 +	zdev->reply.message = kmalloc(max_response_size, GFP_KERNEL);
 +	if (!zdev->reply.message)
 +		goto out_free;
 +	zdev->reply.length = max_response_size;
 +	spin_lock_init(&zdev->lock);
 +	INIT_LIST_HEAD(&zdev->list);
 +	zdev->dbf_area = zcrypt_dbf_devices;
 +	return zdev;
 +
 +out_free:
 +	kfree(zdev);
 +	return NULL;
 +}
 +EXPORT_SYMBOL(zcrypt_device_alloc);
 +
 +void zcrypt_device_free(struct zcrypt_device *zdev)
 +{
 +	kfree(zdev->reply.message);
 +	kfree(zdev);
 +}
 +EXPORT_SYMBOL(zcrypt_device_free);
 +
 +/**
 + * zcrypt_device_register() - Register a crypto device.
 + * @zdev: Pointer to a crypto device
 + *
 + * Register a crypto device. Returns 0 if successful.
 + */
 +int zcrypt_device_register(struct zcrypt_device *zdev)
 +{
 +	int rc;
 +
 +	if (!zdev->ops)
 +		return -ENODEV;
 +	rc = sysfs_create_group(&zdev->ap_dev->device.kobj,
 +				&zcrypt_device_attr_group);
 +	if (rc)
 +		goto out;
 +	get_device(&zdev->ap_dev->device);
 +	kref_init(&zdev->refcount);
 +	spin_lock_bh(&zcrypt_device_lock);
 +	zdev->online = 1;	/* New devices are online by default. */
 +	ZCRYPT_DBF_DEV(DBF_INFO, zdev, "dev%04xo%dreg", zdev->ap_dev->qid,
 +		       zdev->online);
 +	list_add_tail(&zdev->list, &zcrypt_device_list);
 +	__zcrypt_increase_preference(zdev);
 +	zcrypt_device_count++;
 +	spin_unlock_bh(&zcrypt_device_lock);
 +	if (zdev->ops->rng) {
 +		rc = zcrypt_rng_device_add();
 +		if (rc)
 +			goto out_unregister;
 +	}
 +	return 0;
 +
 +out_unregister:
 +	spin_lock_bh(&zcrypt_device_lock);
 +	zcrypt_device_count--;
 +	list_del_init(&zdev->list);
 +	spin_unlock_bh(&zcrypt_device_lock);
 +	sysfs_remove_group(&zdev->ap_dev->device.kobj,
 +			   &zcrypt_device_attr_group);
 +	put_device(&zdev->ap_dev->device);
 +	zcrypt_device_put(zdev);
 +out:
 +	return rc;
 +}
 +EXPORT_SYMBOL(zcrypt_device_register);
 +
 +/**
 + * zcrypt_device_unregister(): Unregister a crypto device.
 + * @zdev: Pointer to crypto device
 + *
 + * Unregister a crypto device.
 + */
 +void zcrypt_device_unregister(struct zcrypt_device *zdev)
 +{
 +	if (zdev->ops->rng)
 +		zcrypt_rng_device_remove();
 +	spin_lock_bh(&zcrypt_device_lock);
 +	zcrypt_device_count--;
 +	list_del_init(&zdev->list);
 +	spin_unlock_bh(&zcrypt_device_lock);
 +	sysfs_remove_group(&zdev->ap_dev->device.kobj,
 +			   &zcrypt_device_attr_group);
 +	put_device(&zdev->ap_dev->device);
 +	zcrypt_device_put(zdev);
 +}
 +EXPORT_SYMBOL(zcrypt_device_unregister);
 +
++=======
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  void zcrypt_msgtype_register(struct zcrypt_ops *zops)
  {
 -	list_add_tail(&zops->list, &zcrypt_ops_list);
 +	if (zops->owner) {
 +		spin_lock_bh(&zcrypt_ops_list_lock);
 +		list_add_tail(&zops->list, &zcrypt_ops_list);
 +		spin_unlock_bh(&zcrypt_ops_list_lock);
 +	}
  }
 +EXPORT_SYMBOL(zcrypt_msgtype_register);
  
  void zcrypt_msgtype_unregister(struct zcrypt_ops *zops)
  {
@@@ -420,7 -193,10 +418,14 @@@ static inline void zcrypt_drop_queue(st
   */
  static long zcrypt_rsa_modexpo(struct ica_rsa_modexpo *mex)
  {
++<<<<<<< HEAD
 +	struct zcrypt_device *zdev;
++=======
+ 	struct zcrypt_card *zc, *pref_zc;
+ 	struct zcrypt_queue *zq, *pref_zq;
+ 	unsigned int weight, pref_weight;
+ 	unsigned int func_code;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	int rc;
  
  	if (mex->outputdatalength < mex->inputdatalength)
@@@ -432,41 -208,60 +437,97 @@@
  	 */
  	mex->outputdatalength = mex->inputdatalength;
  
++<<<<<<< HEAD
 +	spin_lock_bh(&zcrypt_device_lock);
 +	list_for_each_entry(zdev, &zcrypt_device_list, list) {
 +		if (!zdev->online ||
 +		    !zdev->ops->rsa_modexpo ||
 +		    zdev->min_mod_size > mex->inputdatalength ||
 +		    zdev->max_mod_size < mex->inputdatalength)
 +			continue;
 +		zcrypt_device_get(zdev);
 +		get_device(&zdev->ap_dev->device);
 +		zdev->request_count++;
 +		__zcrypt_decrease_preference(zdev);
 +		if (try_module_get(zdev->ap_dev->drv->driver.owner)) {
 +			spin_unlock_bh(&zcrypt_device_lock);
 +			rc = zdev->ops->rsa_modexpo(zdev, mex);
 +			spin_lock_bh(&zcrypt_device_lock);
 +			module_put(zdev->ap_dev->drv->driver.owner);
 +		}
 +		else
 +			rc = -EAGAIN;
 +		zdev->request_count--;
 +		__zcrypt_increase_preference(zdev);
 +		put_device(&zdev->ap_dev->device);
 +		zcrypt_device_put(zdev);
 +		spin_unlock_bh(&zcrypt_device_lock);
 +		return rc;
 +	}
 +	spin_unlock_bh(&zcrypt_device_lock);
 +	return -ENODEV;
++=======
+ 	rc = get_rsa_modex_fc(mex, &func_code);
+ 	if (rc)
+ 		return rc;
+ 
+ 	pref_zc = NULL;
+ 	pref_zq = NULL;
+ 	spin_lock(&zcrypt_list_lock);
+ 	for_each_zcrypt_card(zc) {
+ 		/* Check for online accelarator and CCA cards */
+ 		if (!zc->online || !(zc->card->functions & 0x18000000))
+ 			continue;
+ 		/* Check for size limits */
+ 		if (zc->min_mod_size > mex->inputdatalength ||
+ 		    zc->max_mod_size < mex->inputdatalength)
+ 			continue;
+ 		/* get weight index of the card device	*/
+ 		weight = zc->speed_rating[func_code];
+ 		if (pref_zc && atomic_read(&zc->load) + weight >=
+ 		    atomic_read(&pref_zc->load) + pref_weight)
+ 			continue;
+ 		for_each_zcrypt_queue(zq, zc) {
+ 			/* check if device is online and eligible */
+ 			if (!zq->online)
+ 				continue;
+ 			if (pref_zq && atomic_read(&zq->load) + weight >=
+ 			    atomic_read(&pref_zq->load) + pref_weight)
+ 				continue;
+ 			pref_zc = zc;
+ 			pref_zq = zq;
+ 			pref_weight = weight;
+ 		}
+ 	}
+ 	pref_zq = zcrypt_pick_queue(pref_zc, pref_zq, weight);
+ 	spin_unlock(&zcrypt_list_lock);
+ 
+ 	if (!pref_zq)
+ 		return -ENODEV;
+ 
+ 	rc = pref_zq->ops->rsa_modexpo(pref_zq, mex);
+ 
+ 	spin_lock(&zcrypt_list_lock);
+ 	zcrypt_drop_queue(pref_zc, pref_zq, weight);
+ 	spin_unlock(&zcrypt_list_lock);
+ 
+ 	return rc;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  }
  
  static long zcrypt_rsa_crt(struct ica_rsa_modexpo_crt *crt)
  {
++<<<<<<< HEAD
 +	struct zcrypt_device *zdev;
 +	unsigned long long z1, z2, z3;
 +	int rc, copied;
++=======
+ 	struct zcrypt_card *zc, *pref_zc;
+ 	struct zcrypt_queue *zq, *pref_zq;
+ 	unsigned int weight, pref_weight;
+ 	unsigned int func_code;
+ 	int rc;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  
  	if (crt->outputdatalength < crt->inputdatalength)
  		return -EINVAL;
@@@ -477,223 -272,271 +538,403 @@@
  	 */
  	crt->outputdatalength = crt->inputdatalength;
  
++<<<<<<< HEAD
 +	copied = 0;
 + restart:
 +	spin_lock_bh(&zcrypt_device_lock);
 +	list_for_each_entry(zdev, &zcrypt_device_list, list) {
 +		if (!zdev->online ||
 +		    !zdev->ops->rsa_modexpo_crt ||
 +		    zdev->min_mod_size > crt->inputdatalength ||
 +		    zdev->max_mod_size < crt->inputdatalength)
++=======
+ 	rc = get_rsa_crt_fc(crt, &func_code);
+ 	if (rc)
+ 		return rc;
+ 
+ 	pref_zc = NULL;
+ 	pref_zq = NULL;
+ 	spin_lock(&zcrypt_list_lock);
+ 	for_each_zcrypt_card(zc) {
+ 		/* Check for online accelarator and CCA cards */
+ 		if (!zc->online || !(zc->card->functions & 0x18000000))
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
+ 			continue;
+ 		/* Check for size limits */
+ 		if (zc->min_mod_size > crt->inputdatalength ||
+ 		    zc->max_mod_size < crt->inputdatalength)
+ 			continue;
+ 		/* get weight index of the card device	*/
+ 		weight = zc->speed_rating[func_code];
+ 		if (pref_zc && atomic_read(&zc->load) + weight >=
+ 		    atomic_read(&pref_zc->load) + pref_weight)
  			continue;
- 		if (zdev->short_crt && crt->inputdatalength > 240) {
- 			/*
- 			 * Check inputdata for leading zeros for cards
- 			 * that can't handle np_prime, bp_key, or
- 			 * u_mult_inv > 128 bytes.
- 			 */
- 			if (copied == 0) {
- 				unsigned int len;
- 				spin_unlock_bh(&zcrypt_device_lock);
- 				/* len is max 256 / 2 - 120 = 8
- 				 * For bigger device just assume len of leading
- 				 * 0s is 8 as stated in the requirements for
- 				 * ica_rsa_modexpo_crt struct in zcrypt.h.
- 				 */
- 				if (crt->inputdatalength <= 256)
- 					len = crt->inputdatalength / 2 - 120;
- 				else
- 					len = 8;
- 				if (len > sizeof(z1))
- 					return -EFAULT;
- 				z1 = z2 = z3 = 0;
- 				if (copy_from_user(&z1, crt->np_prime, len) ||
- 				    copy_from_user(&z2, crt->bp_key, len) ||
- 				    copy_from_user(&z3, crt->u_mult_inv, len))
- 					return -EFAULT;
- 				z1 = z2 = z3 = 0;
- 				copied = 1;
- 				/*
- 				 * We have to restart device lookup -
- 				 * the device list may have changed by now.
- 				 */
- 				goto restart;
- 			}
- 			if (z1 != 0ULL || z2 != 0ULL || z3 != 0ULL)
- 				/* The device can't handle this request. */
+ 		for_each_zcrypt_queue(zq, zc) {
+ 			/* check if device is online and eligible */
+ 			if (!zq->online)
  				continue;
+ 			if (pref_zq && atomic_read(&zq->load) + weight >=
+ 			    atomic_read(&pref_zq->load) + pref_weight)
+ 				continue;
+ 			pref_zc = zc;
+ 			pref_zq = zq;
+ 			pref_weight = weight;
  		}
++<<<<<<< HEAD
 +		zcrypt_device_get(zdev);
 +		get_device(&zdev->ap_dev->device);
 +		zdev->request_count++;
 +		__zcrypt_decrease_preference(zdev);
 +		if (try_module_get(zdev->ap_dev->drv->driver.owner)) {
 +			spin_unlock_bh(&zcrypt_device_lock);
 +			rc = zdev->ops->rsa_modexpo_crt(zdev, crt);
 +			spin_lock_bh(&zcrypt_device_lock);
 +			module_put(zdev->ap_dev->drv->driver.owner);
 +		}
 +		else
 +			rc = -EAGAIN;
 +		zdev->request_count--;
 +		__zcrypt_increase_preference(zdev);
 +		put_device(&zdev->ap_dev->device);
 +		zcrypt_device_put(zdev);
 +		spin_unlock_bh(&zcrypt_device_lock);
 +		return rc;
 +	}
 +	spin_unlock_bh(&zcrypt_device_lock);
 +	return -ENODEV;
++=======
+ 	}
+ 	pref_zq = zcrypt_pick_queue(pref_zc, pref_zq, weight);
+ 	spin_unlock(&zcrypt_list_lock);
+ 
+ 	if (!pref_zq)
+ 		return -ENODEV;
+ 
+ 	rc = pref_zq->ops->rsa_modexpo_crt(pref_zq, crt);
+ 
+ 	spin_lock(&zcrypt_list_lock);
+ 	zcrypt_drop_queue(pref_zc, pref_zq, weight);
+ 	spin_unlock(&zcrypt_list_lock);
+ 
+ 	return rc;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  }
  
  static long zcrypt_send_cprb(struct ica_xcRB *xcRB)
  {
++<<<<<<< HEAD
 +	struct zcrypt_device *zdev;
 +	int rc;
++=======
+ 	struct zcrypt_card *zc, *pref_zc;
+ 	struct zcrypt_queue *zq, *pref_zq;
+ 	struct ap_message ap_msg;
+ 	unsigned int weight, pref_weight;
+ 	unsigned int func_code;
+ 	unsigned short *domain;
+ 	int rc;
  
- 	spin_lock_bh(&zcrypt_device_lock);
- 	list_for_each_entry(zdev, &zcrypt_device_list, list) {
- 		if (!zdev->online || !zdev->ops->send_cprb ||
- 		   (zdev->ops->variant == MSGTYPE06_VARIANT_EP11) ||
- 		   (xcRB->user_defined != AUTOSELECT &&
- 		    AP_QID_DEVICE(zdev->ap_dev->qid) != xcRB->user_defined))
+ 	rc = get_cprb_fc(xcRB, &ap_msg, &func_code, &domain);
+ 	if (rc)
+ 		return rc;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
+ 
+ 	pref_zc = NULL;
+ 	pref_zq = NULL;
+ 	spin_lock(&zcrypt_list_lock);
+ 	for_each_zcrypt_card(zc) {
+ 		/* Check for online CCA cards */
+ 		if (!zc->online || !(zc->card->functions & 0x10000000))
  			continue;
++<<<<<<< HEAD
 +		zcrypt_device_get(zdev);
 +		get_device(&zdev->ap_dev->device);
 +		zdev->request_count++;
 +		__zcrypt_decrease_preference(zdev);
 +		if (try_module_get(zdev->ap_dev->drv->driver.owner)) {
 +			spin_unlock_bh(&zcrypt_device_lock);
 +			rc = zdev->ops->send_cprb(zdev, xcRB);
 +			spin_lock_bh(&zcrypt_device_lock);
 +			module_put(zdev->ap_dev->drv->driver.owner);
 +		}
 +		else
 +			rc = -EAGAIN;
 +		zdev->request_count--;
 +		__zcrypt_increase_preference(zdev);
 +		put_device(&zdev->ap_dev->device);
 +		zcrypt_device_put(zdev);
 +		spin_unlock_bh(&zcrypt_device_lock);
 +		return rc;
 +	}
 +	spin_unlock_bh(&zcrypt_device_lock);
 +	return -ENODEV;
- }
++=======
+ 		/* Check for user selected CCA card */
+ 		if (xcRB->user_defined != AUTOSELECT &&
+ 		    xcRB->user_defined != zc->card->id)
+ 			continue;
+ 		/* get weight index of the card device	*/
+ 		weight = speed_idx_cca(func_code) * zc->speed_rating[SECKEY];
+ 		if (pref_zc && atomic_read(&zc->load) + weight >=
+ 		    atomic_read(&pref_zc->load) + pref_weight)
+ 			continue;
+ 		for_each_zcrypt_queue(zq, zc) {
+ 			/* check if device is online and eligible */
+ 			if (!zq->online ||
+ 			    ((*domain != (unsigned short) AUTOSELECT) &&
+ 			     (*domain != AP_QID_QUEUE(zq->queue->qid))))
+ 				continue;
+ 			if (pref_zq && atomic_read(&zq->load) + weight >=
+ 			    atomic_read(&pref_zq->load) + pref_weight)
+ 				continue;
+ 			pref_zc = zc;
+ 			pref_zq = zq;
+ 			pref_weight = weight;
+ 		}
+ 	}
+ 	pref_zq = zcrypt_pick_queue(pref_zc, pref_zq, weight);
+ 	spin_unlock(&zcrypt_list_lock);
  
- struct ep11_target_dev_list {
- 	unsigned short		targets_num;
- 	struct ep11_target_dev	*targets;
- };
+ 	if (!pref_zq)
+ 		return -ENODEV;
+ 
+ 	/* in case of auto select, provide the correct domain */
+ 	if (*domain == (unsigned short) AUTOSELECT)
+ 		*domain = AP_QID_QUEUE(pref_zq->queue->qid);
+ 
+ 	rc = pref_zq->ops->send_cprb(pref_zq, xcRB, &ap_msg);
  
- static bool is_desired_ep11dev(unsigned int dev_qid,
- 			       struct ep11_target_dev_list dev_list)
+ 	spin_lock(&zcrypt_list_lock);
+ 	zcrypt_drop_queue(pref_zc, pref_zq, weight);
+ 	spin_unlock(&zcrypt_list_lock);
+ 	return rc;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
+ }
+ 
+ static bool is_desired_ep11_card(unsigned int dev_id,
+ 				 unsigned short target_num,
+ 				 struct ep11_target_dev *targets)
  {
- 	int n;
+ 	while (target_num-- > 0) {
+ 		if (dev_id == targets->ap_id)
+ 			return true;
+ 		targets++;
+ 	}
+ 	return false;
+ }
  
- 	for (n = 0; n < dev_list.targets_num; n++, dev_list.targets++) {
- 		if ((AP_QID_DEVICE(dev_qid) == dev_list.targets->ap_id) &&
- 		    (AP_QID_QUEUE(dev_qid) == dev_list.targets->dom_id)) {
+ static bool is_desired_ep11_queue(unsigned int dev_qid,
+ 				  unsigned short target_num,
+ 				  struct ep11_target_dev *targets)
+ {
+ 	while (target_num-- > 0) {
+ 		if (AP_MKQID(targets->ap_id, targets->dom_id) == dev_qid)
  			return true;
- 		}
+ 		targets++;
  	}
  	return false;
  }
  
  static long zcrypt_send_ep11_cprb(struct ep11_urb *xcrb)
  {
++<<<<<<< HEAD
 +	struct zcrypt_device *zdev;
 +	bool autoselect = false;
++=======
+ 	struct zcrypt_card *zc, *pref_zc;
+ 	struct zcrypt_queue *zq, *pref_zq;
+ 	struct ep11_target_dev *targets;
+ 	unsigned short target_num;
+ 	unsigned int weight, pref_weight;
+ 	unsigned int func_code;
+ 	struct ap_message ap_msg;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	int rc;
- 	struct ep11_target_dev_list ep11_dev_list = {
- 		.targets_num	=  0x00,
- 		.targets	=  NULL,
- 	};
  
- 	ep11_dev_list.targets_num = (unsigned short) xcrb->targets_num;
+ 	target_num = (unsigned short) xcrb->targets_num;
  
  	/* empty list indicates autoselect (all available targets) */
- 	if (ep11_dev_list.targets_num == 0)
- 		autoselect = true;
- 	else {
- 		ep11_dev_list.targets = kcalloc((unsigned short)
- 						xcrb->targets_num,
- 						sizeof(struct ep11_target_dev),
- 						GFP_KERNEL);
- 		if (!ep11_dev_list.targets)
+ 	targets = NULL;
+ 	if (target_num != 0) {
+ 		struct ep11_target_dev __user *uptr;
+ 
+ 		targets = kcalloc(target_num, sizeof(*targets), GFP_KERNEL);
+ 		if (!targets)
  			return -ENOMEM;
  
- 		if (copy_from_user(ep11_dev_list.targets,
- 				   (struct ep11_target_dev __force __user *)
- 				   xcrb->targets, xcrb->targets_num *
- 				   sizeof(struct ep11_target_dev)))
+ 		uptr = (struct ep11_target_dev __force __user *) xcrb->targets;
+ 		if (copy_from_user(targets, uptr,
+ 				   target_num * sizeof(*targets)))
  			return -EFAULT;
  	}
  
++<<<<<<< HEAD
 +	spin_lock_bh(&zcrypt_device_lock);
 +	list_for_each_entry(zdev, &zcrypt_device_list, list) {
 +		/* check if device is eligible */
 +		if (!zdev->online ||
 +		    zdev->ops->variant != MSGTYPE06_VARIANT_EP11)
- 			continue;
++=======
+ 	rc = get_ep11cprb_fc(xcrb, &ap_msg, &func_code);
+ 	if (rc)
+ 		goto out_free;
  
- 		/* check if device is selected as valid target */
- 		if (!is_desired_ep11dev(zdev->ap_dev->qid, ep11_dev_list) &&
- 		    !autoselect)
+ 	pref_zc = NULL;
+ 	pref_zq = NULL;
+ 	spin_lock(&zcrypt_list_lock);
+ 	for_each_zcrypt_card(zc) {
+ 		/* Check for online EP11 cards */
+ 		if (!zc->online || !(zc->card->functions & 0x04000000))
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  			continue;
+ 		/* Check for user selected EP11 card */
+ 		if (targets &&
+ 		    !is_desired_ep11_card(zc->card->id, target_num, targets))
+ 			continue;
++<<<<<<< HEAD
 +
 +		zcrypt_device_get(zdev);
 +		get_device(&zdev->ap_dev->device);
 +		zdev->request_count++;
 +		__zcrypt_decrease_preference(zdev);
 +		if (try_module_get(zdev->ap_dev->drv->driver.owner)) {
 +			spin_unlock_bh(&zcrypt_device_lock);
 +			rc = zdev->ops->send_ep11_cprb(zdev, xcrb);
 +			spin_lock_bh(&zcrypt_device_lock);
 +			module_put(zdev->ap_dev->drv->driver.owner);
 +		} else {
 +			rc = -EAGAIN;
 +		  }
 +		zdev->request_count--;
 +		__zcrypt_increase_preference(zdev);
 +		put_device(&zdev->ap_dev->device);
 +		zcrypt_device_put(zdev);
 +		spin_unlock_bh(&zcrypt_device_lock);
 +		return rc;
 +	}
 +	spin_unlock_bh(&zcrypt_device_lock);
 +	return -ENODEV;
++=======
+ 		/* get weight index of the card device	*/
+ 		weight = speed_idx_ep11(func_code) * zc->speed_rating[SECKEY];
+ 		if (pref_zc && atomic_read(&zc->load) + weight >=
+ 		    atomic_read(&pref_zc->load) + pref_weight)
+ 			continue;
+ 		for_each_zcrypt_queue(zq, zc) {
+ 			/* check if device is online and eligible */
+ 			if (!zq->online ||
+ 			    (targets &&
+ 			     !is_desired_ep11_queue(zq->queue->qid,
+ 						    target_num, targets)))
+ 				continue;
+ 			if (pref_zq && atomic_read(&zq->load) + weight >=
+ 			    atomic_read(&pref_zq->load) + pref_weight)
+ 				continue;
+ 			pref_zc = zc;
+ 			pref_zq = zq;
+ 			pref_weight = weight;
+ 		}
+ 	}
+ 	pref_zq = zcrypt_pick_queue(pref_zc, pref_zq, weight);
+ 	spin_unlock(&zcrypt_list_lock);
+ 
+ 	if (!pref_zq) {
+ 		rc = -ENODEV;
+ 		goto out_free;
+ 	}
+ 
+ 	rc = pref_zq->ops->send_ep11_cprb(pref_zq, xcrb, &ap_msg);
+ 
+ 	spin_lock(&zcrypt_list_lock);
+ 	zcrypt_drop_queue(pref_zc, pref_zq, weight);
+ 	spin_unlock(&zcrypt_list_lock);
+ 
+ out_free:
+ 	kfree(targets);
+ 	return rc;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  }
  
  static long zcrypt_rng(char *buffer)
  {
++<<<<<<< HEAD
 +	struct zcrypt_device *zdev;
 +	int rc;
 +
 +	spin_lock_bh(&zcrypt_device_lock);
 +	list_for_each_entry(zdev, &zcrypt_device_list, list) {
 +		if (!zdev->online || !zdev->ops->rng)
 +			continue;
 +		zcrypt_device_get(zdev);
 +		get_device(&zdev->ap_dev->device);
 +		zdev->request_count++;
 +		__zcrypt_decrease_preference(zdev);
 +		if (try_module_get(zdev->ap_dev->drv->driver.owner)) {
 +			spin_unlock_bh(&zcrypt_device_lock);
 +			rc = zdev->ops->rng(zdev, buffer);
 +			spin_lock_bh(&zcrypt_device_lock);
 +			module_put(zdev->ap_dev->drv->driver.owner);
 +		} else
 +			rc = -EAGAIN;
 +		zdev->request_count--;
 +		__zcrypt_increase_preference(zdev);
 +		put_device(&zdev->ap_dev->device);
 +		zcrypt_device_put(zdev);
 +		spin_unlock_bh(&zcrypt_device_lock);
 +		return rc;
 +	}
 +	spin_unlock_bh(&zcrypt_device_lock);
 +	return -ENODEV;
++=======
+ 	struct zcrypt_card *zc, *pref_zc;
+ 	struct zcrypt_queue *zq, *pref_zq;
+ 	unsigned int weight, pref_weight;
+ 	unsigned int func_code;
+ 	struct ap_message ap_msg;
+ 	unsigned int domain;
+ 	int rc;
+ 
+ 	rc = get_rng_fc(&ap_msg, &func_code, &domain);
+ 	if (rc)
+ 		return rc;
+ 
+ 	pref_zc = NULL;
+ 	pref_zq = NULL;
+ 	spin_lock(&zcrypt_list_lock);
+ 	for_each_zcrypt_card(zc) {
+ 		/* Check for online CCA cards */
+ 		if (!zc->online || !(zc->card->functions & 0x10000000))
+ 			continue;
+ 		/* get weight index of the card device	*/
+ 		weight = zc->speed_rating[func_code];
+ 		if (pref_zc && atomic_read(&zc->load) + weight >=
+ 		    atomic_read(&pref_zc->load) + pref_weight)
+ 			continue;
+ 		for_each_zcrypt_queue(zq, zc) {
+ 			/* check if device is online and eligible */
+ 			if (!zq->online)
+ 				continue;
+ 			if (pref_zq && atomic_read(&zq->load) + weight >=
+ 			    atomic_read(&pref_zq->load) + pref_weight)
+ 				continue;
+ 			pref_zc = zc;
+ 			pref_zq = zq;
+ 			pref_weight = weight;
+ 		}
+ 	}
+ 	pref_zq = zcrypt_pick_queue(pref_zc, pref_zq, weight);
+ 	spin_unlock(&zcrypt_list_lock);
+ 
+ 	if (!pref_zq)
+ 		return -ENODEV;
+ 
+ 	rc = pref_zq->ops->rng(pref_zq, buffer, &ap_msg);
+ 
+ 	spin_lock(&zcrypt_list_lock);
+ 	zcrypt_drop_queue(pref_zc, pref_zq, weight);
+ 	spin_unlock(&zcrypt_list_lock);
+ 	return rc;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  }
  
  static void zcrypt_status_mask(char status[AP_DEVICES])
diff --cc drivers/s390/crypto/zcrypt_api.h
index 01d02342c190,4fb892b99f41..000000000000
--- a/drivers/s390/crypto/zcrypt_api.h
+++ b/drivers/s390/crypto/zcrypt_api.h
@@@ -84,34 -84,67 +84,81 @@@ struct ica_z90_status 
   */
  #define ZCRYPT_RNG_BUFFER_SIZE	4096
  
++<<<<<<< HEAD
 +struct zcrypt_device;
++=======
+ /*
+  * Identifier for Crypto Request Performance Index
+  */
+ enum crypto_ops {
+ 	MEX_1K,
+ 	MEX_2K,
+ 	MEX_4K,
+ 	CRT_1K,
+ 	CRT_2K,
+ 	CRT_4K,
+ 	HWRNG,
+ 	SECKEY,
+ 	NUM_OPS
+ };
+ 
+ struct zcrypt_queue;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  
  struct zcrypt_ops {
- 	long (*rsa_modexpo)(struct zcrypt_device *, struct ica_rsa_modexpo *);
- 	long (*rsa_modexpo_crt)(struct zcrypt_device *,
+ 	long (*rsa_modexpo)(struct zcrypt_queue *, struct ica_rsa_modexpo *);
+ 	long (*rsa_modexpo_crt)(struct zcrypt_queue *,
  				struct ica_rsa_modexpo_crt *);
++<<<<<<< HEAD
 +	long (*send_cprb)(struct zcrypt_device *, struct ica_xcRB *);
 +	long (*send_ep11_cprb)(struct zcrypt_device *, struct ep11_urb *);
 +	long (*rng)(struct zcrypt_device *, char *);
++=======
+ 	long (*send_cprb)(struct zcrypt_queue *, struct ica_xcRB *,
+ 			  struct ap_message *);
+ 	long (*send_ep11_cprb)(struct zcrypt_queue *, struct ep11_urb *,
+ 			       struct ap_message *);
+ 	long (*rng)(struct zcrypt_queue *, char *, struct ap_message *);
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	struct list_head list;		/* zcrypt ops list. */
  	struct module *owner;
  	int variant;
 -	char name[128];
  };
  
- struct zcrypt_device {
+ struct zcrypt_card {
  	struct list_head list;		/* Device list. */
- 	spinlock_t lock;		/* Per device lock. */
+ 	struct list_head zqueues;	/* List of zcrypt queues */
  	struct kref refcount;		/* device refcounting */
- 	struct ap_device *ap_dev;	/* The "real" ap device. */
- 	struct zcrypt_ops *ops;		/* Crypto operations. */
+ 	struct ap_card *card;		/* The "real" ap card device. */
  	int online;			/* User online/offline */
  
  	int user_space_type;		/* User space device id. */
  	char *type_string;		/* User space device name. */
  	int min_mod_size;		/* Min number of bits. */
  	int max_mod_size;		/* Max number of bits. */
++<<<<<<< HEAD
 +	int short_crt;			/* Card has crt length restriction. */
 +	int speed_rating;		/* Speed of the crypto device. */
++=======
+ 	int max_exp_bit_length;
+ 	int speed_rating[NUM_OPS];	/* Speed idx of crypto ops. */
+ 	atomic_t load;			/* Utilization of the crypto device */
+ 
+ 	int request_count;		/* # current requests. */
+ 
+ 	debug_info_t *dbf_area;		/* debugging */
+ };
+ 
+ struct zcrypt_queue {
+ 	struct list_head list;		/* Device list. */
+ 	struct kref refcount;		/* device refcounting */
+ 	struct zcrypt_card *zcard;
+ 	struct zcrypt_ops *ops;		/* Crypto operations. */
+ 	struct ap_queue *queue;		/* The "real" ap queue device. */
+ 	int online;			/* User online/offline */
+ 
+ 	atomic_t load;			/* Utilization of the crypto device */
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  
  	int request_count;		/* # current requests. */
  
@@@ -124,16 -156,46 +170,47 @@@
  /* transport layer rescanning */
  extern atomic_t zcrypt_rescan_req;
  
- struct zcrypt_device *zcrypt_device_alloc(size_t);
- void zcrypt_device_free(struct zcrypt_device *);
- void zcrypt_device_get(struct zcrypt_device *);
- int zcrypt_device_put(struct zcrypt_device *);
- int zcrypt_device_register(struct zcrypt_device *);
- void zcrypt_device_unregister(struct zcrypt_device *);
+ extern spinlock_t zcrypt_list_lock;
+ extern int zcrypt_device_count;
+ extern struct list_head zcrypt_card_list;
+ 
+ extern debug_info_t *zcrypt_dbf_common;
+ extern debug_info_t *zcrypt_dbf_devices;
+ extern debug_info_t *zcrypt_dbf_cards;
+ 
+ #define for_each_zcrypt_card(_zc) \
+ 	list_for_each_entry(_zc, &zcrypt_card_list, list)
+ 
+ #define for_each_zcrypt_queue(_zq, _zc) \
+ 	list_for_each_entry(_zq, &(_zc)->zqueues, list)
+ 
+ struct zcrypt_card *zcrypt_card_alloc(void);
+ void zcrypt_card_free(struct zcrypt_card *);
+ void zcrypt_card_get(struct zcrypt_card *);
+ int zcrypt_card_put(struct zcrypt_card *);
+ int zcrypt_card_register(struct zcrypt_card *);
+ void zcrypt_card_unregister(struct zcrypt_card *);
+ struct zcrypt_card *zcrypt_card_get_best(unsigned int *,
+ 					 unsigned int, unsigned int);
+ void zcrypt_card_put_best(struct zcrypt_card *, unsigned int);
+ 
+ struct zcrypt_queue *zcrypt_queue_alloc(size_t);
+ void zcrypt_queue_free(struct zcrypt_queue *);
+ void zcrypt_queue_get(struct zcrypt_queue *);
+ int zcrypt_queue_put(struct zcrypt_queue *);
+ int zcrypt_queue_register(struct zcrypt_queue *);
+ void zcrypt_queue_unregister(struct zcrypt_queue *);
+ void zcrypt_queue_force_online(struct zcrypt_queue *, int);
+ struct zcrypt_queue *zcrypt_queue_get_best(unsigned int, unsigned int);
+ void  zcrypt_queue_put_best(struct zcrypt_queue *, unsigned int);
+ 
+ int zcrypt_rng_device_add(void);
+ void zcrypt_rng_device_remove(void);
+ 
  void zcrypt_msgtype_register(struct zcrypt_ops *);
  void zcrypt_msgtype_unregister(struct zcrypt_ops *);
 -struct zcrypt_ops *zcrypt_msgtype(unsigned char *, int);
 +struct zcrypt_ops *zcrypt_msgtype_request(unsigned char *, int);
 +void zcrypt_msgtype_release(struct zcrypt_ops *);
  int zcrypt_api_init(void);
  void zcrypt_api_exit(void);
  
diff --cc drivers/s390/crypto/zcrypt_cex2a.c
index 1e849d6e1dfe,c7d48a18199e..000000000000
--- a/drivers/s390/crypto/zcrypt_cex2a.c
+++ b/drivers/s390/crypto/zcrypt_cex2a.c
@@@ -69,90 -60,184 +63,242 @@@ MODULE_DESCRIPTION("CEX2A Cryptographi
  		   "Copyright IBM Corp. 2001, 2012");
  MODULE_LICENSE("GPL");
  
- static int zcrypt_cex2a_probe(struct ap_device *ap_dev);
- static void zcrypt_cex2a_remove(struct ap_device *ap_dev);
+ static struct ap_device_id zcrypt_cex2a_card_ids[] = {
+ 	{ .dev_type = AP_DEVICE_TYPE_CEX2A,
+ 	  .match_flags = AP_DEVICE_ID_MATCH_CARD_TYPE },
+ 	{ .dev_type = AP_DEVICE_TYPE_CEX3A,
+ 	  .match_flags = AP_DEVICE_ID_MATCH_CARD_TYPE },
+ 	{ /* end of list */ },
+ };
+ 
+ MODULE_DEVICE_TABLE(ap, zcrypt_cex2a_card_ids);
  
- static struct ap_driver zcrypt_cex2a_driver = {
- 	.probe = zcrypt_cex2a_probe,
- 	.remove = zcrypt_cex2a_remove,
- 	.ids = zcrypt_cex2a_ids,
- 	.request_timeout = CEX2A_CLEANUP_TIME,
+ static struct ap_device_id zcrypt_cex2a_queue_ids[] = {
+ 	{ .dev_type = AP_DEVICE_TYPE_CEX2A,
+ 	  .match_flags = AP_DEVICE_ID_MATCH_QUEUE_TYPE },
+ 	{ .dev_type = AP_DEVICE_TYPE_CEX3A,
+ 	  .match_flags = AP_DEVICE_ID_MATCH_QUEUE_TYPE },
+ 	{ /* end of list */ },
  };
  
+ MODULE_DEVICE_TABLE(ap, zcrypt_cex2a_queue_ids);
+ 
  /**
-  * Probe function for CEX2A cards. It always accepts the AP device
-  * since the bus_match already checked the hardware type.
+  * Probe function for CEX2A card devices. It always accepts the AP device
+  * since the bus_match already checked the card type.
   * @ap_dev: pointer to the AP device.
   */
- static int zcrypt_cex2a_probe(struct ap_device *ap_dev)
+ static int zcrypt_cex2a_card_probe(struct ap_device *ap_dev)
  {
++<<<<<<< HEAD
 +	struct zcrypt_device *zdev = NULL;
 +	int rc = 0;
 +
 +	switch (ap_dev->device_type) {
 +	case AP_DEVICE_TYPE_CEX2A:
 +		zdev = zcrypt_device_alloc(CEX2A_MAX_RESPONSE_SIZE);
 +		if (!zdev)
 +			return -ENOMEM;
 +		zdev->user_space_type = ZCRYPT_CEX2A;
 +		zdev->type_string = "CEX2A";
 +		zdev->min_mod_size = CEX2A_MIN_MOD_SIZE;
 +		zdev->max_mod_size = CEX2A_MAX_MOD_SIZE;
 +		zdev->short_crt = 1;
 +		zdev->speed_rating = CEX2A_SPEED_RATING;
 +		zdev->max_exp_bit_length = CEX2A_MAX_MOD_SIZE;
 +		break;
 +	case AP_DEVICE_TYPE_CEX3A:
 +		zdev = zcrypt_device_alloc(CEX3A_MAX_RESPONSE_SIZE);
 +		if (!zdev)
 +			return -ENOMEM;
 +		zdev->user_space_type = ZCRYPT_CEX3A;
 +		zdev->type_string = "CEX3A";
 +		zdev->min_mod_size = CEX2A_MIN_MOD_SIZE;
 +		zdev->max_mod_size = CEX2A_MAX_MOD_SIZE;
 +		zdev->max_exp_bit_length = CEX2A_MAX_MOD_SIZE;
 +		if (ap_test_bit(&ap_dev->functions, AP_FUNC_MEX4K) &&
 +		    ap_test_bit(&ap_dev->functions, AP_FUNC_CRT4K)) {
 +			zdev->max_mod_size = CEX3A_MAX_MOD_SIZE;
 +			zdev->max_exp_bit_length = CEX3A_MAX_MOD_SIZE;
 +		}
 +		zdev->short_crt = 1;
 +		zdev->speed_rating = CEX3A_SPEED_RATING;
 +		break;
 +	}
 +	if (!zdev)
 +		return -ENODEV;
 +	zdev->ops = zcrypt_msgtype_request(MSGTYPE50_NAME,
 +					   MSGTYPE50_VARIANT_DEFAULT);
 +	zdev->ap_dev = ap_dev;
 +	zdev->online = 1;
 +	ap_dev->reply = &zdev->reply;
 +	ap_dev->private = zdev;
 +	rc = zcrypt_device_register(zdev);
 +	if (rc) {
 +		ap_dev->private = NULL;
 +		zcrypt_msgtype_release(zdev->ops);
 +		zcrypt_device_free(zdev);
++=======
+ 	/*
+ 	 * Normalized speed ratings per crypto adapter
+ 	 * MEX_1k, MEX_2k, MEX_4k, CRT_1k, CRT_2k, CRT_4k, RNG, SECKEY
+ 	 */
+ 	static const int CEX2A_SPEED_IDX[] = {
+ 		800, 1000, 2000,  900, 1200, 2400, 0, 0};
+ 	static const int CEX3A_SPEED_IDX[] = {
+ 		400,  500, 1000,  450,	550, 1200, 0, 0};
+ 
+ 	struct ap_card *ac = to_ap_card(&ap_dev->device);
+ 	struct zcrypt_card *zc;
+ 	int rc = 0;
+ 
+ 	zc = zcrypt_card_alloc();
+ 	if (!zc)
+ 		return -ENOMEM;
+ 	zc->card = ac;
+ 	ac->private = zc;
+ 
+ 	if (ac->ap_dev.device_type == AP_DEVICE_TYPE_CEX2A) {
+ 		zc->min_mod_size = CEX2A_MIN_MOD_SIZE;
+ 		zc->max_mod_size = CEX2A_MAX_MOD_SIZE;
+ 		memcpy(zc->speed_rating, CEX2A_SPEED_IDX,
+ 		       sizeof(CEX2A_SPEED_IDX));
+ 		zc->max_exp_bit_length = CEX2A_MAX_MOD_SIZE;
+ 		zc->type_string = "CEX2A";
+ 		zc->user_space_type = ZCRYPT_CEX2A;
+ 	} else if (ac->ap_dev.device_type == AP_DEVICE_TYPE_CEX3A) {
+ 		zc->min_mod_size = CEX2A_MIN_MOD_SIZE;
+ 		zc->max_mod_size = CEX2A_MAX_MOD_SIZE;
+ 		zc->max_exp_bit_length = CEX2A_MAX_MOD_SIZE;
+ 		if (ap_test_bit(&ac->functions, AP_FUNC_MEX4K) &&
+ 		    ap_test_bit(&ac->functions, AP_FUNC_CRT4K)) {
+ 			zc->max_mod_size = CEX3A_MAX_MOD_SIZE;
+ 			zc->max_exp_bit_length = CEX3A_MAX_MOD_SIZE;
+ 		}
+ 		memcpy(zc->speed_rating, CEX3A_SPEED_IDX,
+ 		       sizeof(CEX3A_SPEED_IDX));
+ 		zc->type_string = "CEX3A";
+ 		zc->user_space_type = ZCRYPT_CEX3A;
+ 	} else {
+ 		zcrypt_card_free(zc);
+ 		return -ENODEV;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	}
+ 	zc->online = 1;
+ 
+ 	rc = zcrypt_card_register(zc);
+ 	if (rc) {
+ 		ac->private = NULL;
+ 		zcrypt_card_free(zc);
+ 	}
+ 
  	return rc;
  }
  
  /**
-  * This is called to remove the extended CEX2A driver information
-  * if an AP device is removed.
+  * This is called to remove the CEX2A card driver information
+  * if an AP card device is removed.
   */
- static void zcrypt_cex2a_remove(struct ap_device *ap_dev)
+ static void zcrypt_cex2a_card_remove(struct ap_device *ap_dev)
  {
++<<<<<<< HEAD
 +	struct zcrypt_device *zdev = ap_dev->private;
 +	struct zcrypt_ops *zops = zdev->ops;
 +
 +	zcrypt_device_unregister(zdev);
 +	zcrypt_msgtype_release(zops);
++=======
+ 	struct zcrypt_card *zc = to_ap_card(&ap_dev->device)->private;
+ 
+ 	if (zc)
+ 		zcrypt_card_unregister(zc);
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  }
  
+ static struct ap_driver zcrypt_cex2a_card_driver = {
+ 	.probe = zcrypt_cex2a_card_probe,
+ 	.remove = zcrypt_cex2a_card_remove,
+ 	.ids = zcrypt_cex2a_card_ids,
+ };
+ 
+ /**
+  * Probe function for CEX2A queue devices. It always accepts the AP device
+  * since the bus_match already checked the queue type.
+  * @ap_dev: pointer to the AP device.
+  */
+ static int zcrypt_cex2a_queue_probe(struct ap_device *ap_dev)
+ {
+ 	struct ap_queue *aq = to_ap_queue(&ap_dev->device);
+ 	struct zcrypt_queue *zq = NULL;
+ 	int rc;
+ 
+ 	switch (ap_dev->device_type) {
+ 	case AP_DEVICE_TYPE_CEX2A:
+ 		zq = zcrypt_queue_alloc(CEX2A_MAX_RESPONSE_SIZE);
+ 		if (!zq)
+ 			return -ENOMEM;
+ 		break;
+ 	case AP_DEVICE_TYPE_CEX3A:
+ 		zq = zcrypt_queue_alloc(CEX3A_MAX_RESPONSE_SIZE);
+ 		if (!zq)
+ 			return -ENOMEM;
+ 		break;
+ 	}
+ 	if (!zq)
+ 		return -ENODEV;
+ 	zq->ops = zcrypt_msgtype(MSGTYPE50_NAME, MSGTYPE50_VARIANT_DEFAULT);
+ 	zq->queue = aq;
+ 	zq->online = 1;
+ 	atomic_set(&zq->load, 0);
+ 	ap_queue_init_reply(aq, &zq->reply);
+ 	aq->request_timeout = CEX2A_CLEANUP_TIME,
+ 	aq->private = zq;
+ 	rc = zcrypt_queue_register(zq);
+ 	if (rc) {
+ 		aq->private = NULL;
+ 		zcrypt_queue_free(zq);
+ 	}
+ 
+ 	return rc;
+ }
+ 
+ /**
+  * This is called to remove the CEX2A queue driver information
+  * if an AP queue device is removed.
+  */
+ static void zcrypt_cex2a_queue_remove(struct ap_device *ap_dev)
+ {
+ 	struct ap_queue *aq = to_ap_queue(&ap_dev->device);
+ 	struct zcrypt_queue *zq = aq->private;
+ 
+ 	ap_queue_remove(aq);
+ 	if (zq)
+ 		zcrypt_queue_unregister(zq);
+ }
+ 
+ static struct ap_driver zcrypt_cex2a_queue_driver = {
+ 	.probe = zcrypt_cex2a_queue_probe,
+ 	.remove = zcrypt_cex2a_queue_remove,
+ 	.suspend = ap_queue_suspend,
+ 	.resume = ap_queue_resume,
+ 	.ids = zcrypt_cex2a_queue_ids,
+ };
+ 
  int __init zcrypt_cex2a_init(void)
  {
- 	return ap_driver_register(&zcrypt_cex2a_driver, THIS_MODULE, "cex2a");
+ 	int rc;
+ 
+ 	rc = ap_driver_register(&zcrypt_cex2a_card_driver,
+ 				THIS_MODULE, "cex2acard");
+ 	if (rc)
+ 		return rc;
+ 
+ 	rc = ap_driver_register(&zcrypt_cex2a_queue_driver,
+ 				THIS_MODULE, "cex2aqueue");
+ 	if (rc)
+ 		ap_driver_unregister(&zcrypt_cex2a_card_driver);
+ 
+ 	return rc;
  }
  
  void __exit zcrypt_cex2a_exit(void)
diff --cc drivers/s390/crypto/zcrypt_cex4.c
index bb3908818505,4e91163d70a6..000000000000
--- a/drivers/s390/crypto/zcrypt_cex4.c
+++ b/drivers/s390/crypto/zcrypt_cex4.c
@@@ -68,115 -65,210 +72,306 @@@ MODULE_DEVICE_TABLE(ap, zcrypt_cex4_que
   * since the bus_match already checked the hardware type.
   * @ap_dev: pointer to the AP device.
   */
- static int zcrypt_cex4_probe(struct ap_device *ap_dev)
+ static int zcrypt_cex4_card_probe(struct ap_device *ap_dev)
  {
++<<<<<<< HEAD
 +	struct zcrypt_device *zdev = NULL;
 +	int rc = 0;
 +
 +	switch (ap_dev->device_type) {
 +	case AP_DEVICE_TYPE_CEX4:
 +	case AP_DEVICE_TYPE_CEX5:
 +		if (ap_test_bit(&ap_dev->functions, AP_FUNC_ACCEL)) {
 +			zdev = zcrypt_device_alloc(CEX4A_MAX_MESSAGE_SIZE);
 +			if (!zdev)
 +				return -ENOMEM;
 +			if (ap_dev->device_type == AP_DEVICE_TYPE_CEX4) {
 +				zdev->type_string = "CEX4A";
 +				zdev->speed_rating = CEX4A_SPEED_RATING;
 +			} else {
 +				zdev->type_string = "CEX5A";
 +				zdev->speed_rating = CEX5A_SPEED_RATING;
 +			}
 +			zdev->user_space_type = ZCRYPT_CEX3A;
 +			zdev->min_mod_size = CEX4A_MIN_MOD_SIZE;
 +			if (ap_test_bit(&ap_dev->functions, AP_FUNC_MEX4K) &&
 +			    ap_test_bit(&ap_dev->functions, AP_FUNC_CRT4K)) {
 +				zdev->max_mod_size =
 +					CEX4A_MAX_MOD_SIZE_4K;
 +				zdev->max_exp_bit_length =
 +					CEX4A_MAX_MOD_SIZE_4K;
 +			} else {
 +				zdev->max_mod_size =
 +					CEX4A_MAX_MOD_SIZE_2K;
 +				zdev->max_exp_bit_length =
 +					CEX4A_MAX_MOD_SIZE_2K;
 +			}
 +			zdev->short_crt = 1;
 +			zdev->ops = zcrypt_msgtype_request(MSGTYPE50_NAME,
 +							   MSGTYPE50_VARIANT_DEFAULT);
 +		} else if (ap_test_bit(&ap_dev->functions, AP_FUNC_COPRO)) {
 +			zdev = zcrypt_device_alloc(CEX4C_MAX_MESSAGE_SIZE);
 +			if (!zdev)
 +				return -ENOMEM;
 +			if (ap_dev->device_type == AP_DEVICE_TYPE_CEX4) {
 +				zdev->type_string = "CEX4C";
 +				zdev->speed_rating = CEX4C_SPEED_RATING;
 +			} else {
 +				zdev->type_string = "CEX5C";
 +				zdev->speed_rating = CEX5C_SPEED_RATING;
 +			}
 +			zdev->user_space_type = ZCRYPT_CEX3C;
 +			zdev->min_mod_size = CEX4C_MIN_MOD_SIZE;
 +			zdev->max_mod_size = CEX4C_MAX_MOD_SIZE;
 +			zdev->max_exp_bit_length = CEX4C_MAX_MOD_SIZE;
 +			zdev->short_crt = 0;
 +			zdev->ops = zcrypt_msgtype_request(MSGTYPE06_NAME,
 +							   MSGTYPE06_VARIANT_DEFAULT);
 +		} else if (ap_test_bit(&ap_dev->functions, AP_FUNC_EP11)) {
 +			zdev = zcrypt_device_alloc(CEX4C_MAX_MESSAGE_SIZE);
 +			if (!zdev)
 +				return -ENOMEM;
 +			if (ap_dev->device_type == AP_DEVICE_TYPE_CEX4) {
 +				zdev->type_string = "CEX4P";
 +				zdev->speed_rating = CEX4P_SPEED_RATING;
 +			} else {
 +				zdev->type_string = "CEX5P";
 +				zdev->speed_rating = CEX5P_SPEED_RATING;
 +			}
 +			zdev->user_space_type = ZCRYPT_CEX4;
 +			zdev->min_mod_size = CEX4C_MIN_MOD_SIZE;
 +			zdev->max_mod_size = CEX4C_MAX_MOD_SIZE;
 +			zdev->max_exp_bit_length = CEX4C_MAX_MOD_SIZE;
 +			zdev->short_crt = 0;
 +			zdev->ops = zcrypt_msgtype_request(MSGTYPE06_NAME,
 +							MSGTYPE06_VARIANT_EP11);
++=======
+ 	/*
+ 	 * Normalized speed ratings per crypto adapter
+ 	 * MEX_1k, MEX_2k, MEX_4k, CRT_1k, CRT_2k, CRT_4k, RNG, SECKEY
+ 	 */
+ 	static const int CEX4A_SPEED_IDX[] = {
+ 		5,  6,	  59,  20, 115,  581,  0,  0};
+ 	static const int CEX5A_SPEED_IDX[] = {
+ 		3,  3,	   6,	8,  32,  218,  0,  0};
+ 	static const int CEX4C_SPEED_IDX[] = {
+ 		24,  25,   82,	41, 138, 1111, 79,  8};
+ 	static const int CEX5C_SPEED_IDX[] = {
+ 		10,  14,   23,	17,  45,  242, 63,  4};
+ 	static const int CEX4P_SPEED_IDX[] = {
+ 		142, 198, 1852, 203, 331, 1563,  0,  8};
+ 	static const int CEX5P_SPEED_IDX[] = {
+ 		49,  67,  131,	52,  85,  287,	0,  4};
+ 
+ 	struct ap_card *ac = to_ap_card(&ap_dev->device);
+ 	struct zcrypt_card *zc;
+ 	int rc = 0;
+ 
+ 	zc = zcrypt_card_alloc();
+ 	if (!zc)
+ 		return -ENOMEM;
+ 	zc->card = ac;
+ 	ac->private = zc;
+ 	if (ap_test_bit(&ac->functions, AP_FUNC_ACCEL)) {
+ 		if (ac->ap_dev.device_type == AP_DEVICE_TYPE_CEX4) {
+ 			zc->type_string = "CEX4A";
+ 			zc->user_space_type = ZCRYPT_CEX4;
+ 			memcpy(zc->speed_rating, CEX4A_SPEED_IDX,
+ 			       sizeof(CEX4A_SPEED_IDX));
+ 		} else {
+ 			zc->type_string = "CEX5A";
+ 			zc->user_space_type = ZCRYPT_CEX5;
+ 			memcpy(zc->speed_rating, CEX5A_SPEED_IDX,
+ 			       sizeof(CEX5A_SPEED_IDX));
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  		}
- 		break;
- 	}
- 	if (!zdev)
+ 		zc->min_mod_size = CEX4A_MIN_MOD_SIZE;
+ 		if (ap_test_bit(&ac->functions, AP_FUNC_MEX4K) &&
+ 		    ap_test_bit(&ac->functions, AP_FUNC_CRT4K)) {
+ 			zc->max_mod_size = CEX4A_MAX_MOD_SIZE_4K;
+ 			zc->max_exp_bit_length =
+ 				CEX4A_MAX_MOD_SIZE_4K;
+ 		} else {
+ 			zc->max_mod_size = CEX4A_MAX_MOD_SIZE_2K;
+ 			zc->max_exp_bit_length =
+ 				CEX4A_MAX_MOD_SIZE_2K;
+ 		}
+ 	} else if (ap_test_bit(&ac->functions, AP_FUNC_COPRO)) {
+ 		if (ac->ap_dev.device_type == AP_DEVICE_TYPE_CEX4) {
+ 			zc->type_string = "CEX4C";
+ 			/* wrong user space type, must be CEX4
+ 			 * just keep it for cca compatibility
+ 			 */
+ 			zc->user_space_type = ZCRYPT_CEX3C;
+ 			memcpy(zc->speed_rating, CEX4C_SPEED_IDX,
+ 			       sizeof(CEX4C_SPEED_IDX));
+ 		} else {
+ 			zc->type_string = "CEX5C";
+ 			/* wrong user space type, must be CEX5
+ 			 * just keep it for cca compatibility
+ 			 */
+ 			zc->user_space_type = ZCRYPT_CEX3C;
+ 			memcpy(zc->speed_rating, CEX5C_SPEED_IDX,
+ 			       sizeof(CEX5C_SPEED_IDX));
+ 		}
+ 		zc->min_mod_size = CEX4C_MIN_MOD_SIZE;
+ 		zc->max_mod_size = CEX4C_MAX_MOD_SIZE;
+ 		zc->max_exp_bit_length = CEX4C_MAX_MOD_SIZE;
+ 	} else if (ap_test_bit(&ac->functions, AP_FUNC_EP11)) {
+ 		if (ac->ap_dev.device_type == AP_DEVICE_TYPE_CEX4) {
+ 			zc->type_string = "CEX4P";
+ 			zc->user_space_type = ZCRYPT_CEX4;
+ 			memcpy(zc->speed_rating, CEX4P_SPEED_IDX,
+ 			       sizeof(CEX4P_SPEED_IDX));
+ 		} else {
+ 			zc->type_string = "CEX5P";
+ 			zc->user_space_type = ZCRYPT_CEX5;
+ 			memcpy(zc->speed_rating, CEX5P_SPEED_IDX,
+ 			       sizeof(CEX5P_SPEED_IDX));
+ 		}
+ 		zc->min_mod_size = CEX4C_MIN_MOD_SIZE;
+ 		zc->max_mod_size = CEX4C_MAX_MOD_SIZE;
+ 		zc->max_exp_bit_length = CEX4C_MAX_MOD_SIZE;
+ 	} else {
+ 		zcrypt_card_free(zc);
  		return -ENODEV;
++<<<<<<< HEAD
 +	zdev->ap_dev = ap_dev;
 +	zdev->online = 1;
 +	ap_dev->reply = &zdev->reply;
 +	ap_dev->private = zdev;
 +	rc = zcrypt_device_register(zdev);
 +	if (rc) {
 +		zcrypt_msgtype_release(zdev->ops);
 +		ap_dev->private = NULL;
 +		zcrypt_device_free(zdev);
++=======
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
+ 	}
+ 	zc->online = 1;
+ 
+ 	rc = zcrypt_card_register(zc);
+ 	if (rc) {
+ 		ac->private = NULL;
+ 		zcrypt_card_free(zc);
  	}
+ 
  	return rc;
  }
  
  /**
-  * This is called to remove the extended CEX4 driver information
-  * if an AP device is removed.
+  * This is called to remove the CEX4 card driver information
+  * if an AP card device is removed.
   */
- static void zcrypt_cex4_remove(struct ap_device *ap_dev)
+ static void zcrypt_cex4_card_remove(struct ap_device *ap_dev)
  {
++<<<<<<< HEAD
 +	struct zcrypt_device *zdev = ap_dev->private;
 +	struct zcrypt_ops *zops;
 +
 +	if (zdev) {
 +		zops = zdev->ops;
 +		zcrypt_device_unregister(zdev);
 +		zcrypt_msgtype_release(zops);
 +	}
++=======
+ 	struct zcrypt_card *zc = to_ap_card(&ap_dev->device)->private;
+ 
+ 	if (zc)
+ 		zcrypt_card_unregister(zc);
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
+ }
+ 
+ static struct ap_driver zcrypt_cex4_card_driver = {
+ 	.probe = zcrypt_cex4_card_probe,
+ 	.remove = zcrypt_cex4_card_remove,
+ 	.ids = zcrypt_cex4_card_ids,
+ };
+ 
+ /**
+  * Probe function for CEX4 queue device. It always accepts the AP device
+  * since the bus_match already checked the hardware type.
+  * @ap_dev: pointer to the AP device.
+  */
+ static int zcrypt_cex4_queue_probe(struct ap_device *ap_dev)
+ {
+ 	struct ap_queue *aq = to_ap_queue(&ap_dev->device);
+ 	struct zcrypt_queue *zq;
+ 	int rc;
+ 
+ 	if (ap_test_bit(&aq->card->functions, AP_FUNC_ACCEL)) {
+ 		zq = zcrypt_queue_alloc(CEX4A_MAX_MESSAGE_SIZE);
+ 		if (!zq)
+ 			return -ENOMEM;
+ 		zq->ops = zcrypt_msgtype(MSGTYPE50_NAME,
+ 					 MSGTYPE50_VARIANT_DEFAULT);
+ 	} else if (ap_test_bit(&aq->card->functions, AP_FUNC_COPRO)) {
+ 		zq = zcrypt_queue_alloc(CEX4C_MAX_MESSAGE_SIZE);
+ 		if (!zq)
+ 			return -ENOMEM;
+ 		zq->ops = zcrypt_msgtype(MSGTYPE06_NAME,
+ 					 MSGTYPE06_VARIANT_DEFAULT);
+ 	} else if (ap_test_bit(&aq->card->functions, AP_FUNC_EP11)) {
+ 		zq = zcrypt_queue_alloc(CEX4C_MAX_MESSAGE_SIZE);
+ 		if (!zq)
+ 			return -ENOMEM;
+ 		zq->ops = zcrypt_msgtype(MSGTYPE06_NAME,
+ 					 MSGTYPE06_VARIANT_EP11);
+ 	} else {
+ 		return -ENODEV;
+ 	}
+ 	zq->queue = aq;
+ 	zq->online = 1;
+ 	atomic_set(&zq->load, 0);
+ 	ap_queue_init_reply(aq, &zq->reply);
+ 	aq->request_timeout = CEX4_CLEANUP_TIME,
+ 	aq->private = zq;
+ 	rc = zcrypt_queue_register(zq);
+ 	if (rc) {
+ 		aq->private = NULL;
+ 		zcrypt_queue_free(zq);
+ 	}
+ 
+ 	return rc;
  }
  
+ /**
+  * This is called to remove the CEX4 queue driver information
+  * if an AP queue device is removed.
+  */
+ static void zcrypt_cex4_queue_remove(struct ap_device *ap_dev)
+ {
+ 	struct ap_queue *aq = to_ap_queue(&ap_dev->device);
+ 	struct zcrypt_queue *zq = aq->private;
+ 
+ 	ap_queue_remove(aq);
+ 	if (zq)
+ 		zcrypt_queue_unregister(zq);
+ }
+ 
+ static struct ap_driver zcrypt_cex4_queue_driver = {
+ 	.probe = zcrypt_cex4_queue_probe,
+ 	.remove = zcrypt_cex4_queue_remove,
+ 	.suspend = ap_queue_suspend,
+ 	.resume = ap_queue_resume,
+ 	.ids = zcrypt_cex4_queue_ids,
+ };
+ 
  int __init zcrypt_cex4_init(void)
  {
- 	return ap_driver_register(&zcrypt_cex4_driver, THIS_MODULE, "cex4");
+ 	int rc;
+ 
+ 	rc = ap_driver_register(&zcrypt_cex4_card_driver,
+ 				THIS_MODULE, "cex4card");
+ 	if (rc)
+ 		return rc;
+ 
+ 	rc = ap_driver_register(&zcrypt_cex4_queue_driver,
+ 				THIS_MODULE, "cex4queue");
+ 	if (rc)
+ 		ap_driver_unregister(&zcrypt_cex4_card_driver);
+ 
+ 	return rc;
  }
  
  void __exit zcrypt_cex4_exit(void)
diff --cc drivers/s390/crypto/zcrypt_msgtype50.c
index 64cd342bbc8d,a9873b436115..000000000000
--- a/drivers/s390/crypto/zcrypt_msgtype50.c
+++ b/drivers/s390/crypto/zcrypt_msgtype50.c
@@@ -396,13 -430,11 +398,13 @@@ static void zcrypt_cex2a_receive(struc
  	int length;
  
  	/* Copy the reply message to the request message buffer. */
 -	if (!reply)
 -		goto out;	/* ap_msg->rc indicates the error */
 +	if (IS_ERR(reply)) {
 +		memcpy(msg->message, &error_reply, sizeof(error_reply));
 +		goto out;
 +	}
  	t80h = reply->message;
  	if (t80h->type == TYPE80_RSP_CODE) {
- 		if (ap_dev->device_type == AP_DEVICE_TYPE_CEX2A)
+ 		if (aq->ap_dev.device_type == AP_DEVICE_TYPE_CEX2A)
  			length = min_t(int,
  				       CEX2A_MAX_RESPONSE_SIZE, t80h->len);
  		else
@@@ -448,14 -480,16 +450,23 @@@ static long zcrypt_cex2a_modexpo(struc
  	if (rc)
  		goto out_free;
  	init_completion(&work);
- 	ap_queue_message(zdev->ap_dev, &ap_msg);
+ 	ap_queue_message(zq->queue, &ap_msg);
  	rc = wait_for_completion_interruptible(&work);
++<<<<<<< HEAD
 +	if (rc == 0)
 +		rc = convert_response(zdev, &ap_msg, mex->outputdata,
 +				      mex->outputdatalength);
 +	else
++=======
+ 	if (rc == 0) {
+ 		rc = ap_msg.rc;
+ 		if (rc == 0)
+ 			rc = convert_response(zq, &ap_msg, mex->outputdata,
+ 					      mex->outputdatalength);
+ 	} else
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  		/* Signal pending. */
- 		ap_cancel_message(zdev->ap_dev, &ap_msg);
+ 		ap_cancel_message(zq->queue, &ap_msg);
  out_free:
  	kfree(ap_msg.message);
  	return rc;
@@@ -492,14 -526,16 +503,23 @@@ static long zcrypt_cex2a_modexpo_crt(st
  	if (rc)
  		goto out_free;
  	init_completion(&work);
- 	ap_queue_message(zdev->ap_dev, &ap_msg);
+ 	ap_queue_message(zq->queue, &ap_msg);
  	rc = wait_for_completion_interruptible(&work);
++<<<<<<< HEAD
 +	if (rc == 0)
 +		rc = convert_response(zdev, &ap_msg, crt->outputdata,
 +				      crt->outputdatalength);
 +	else
++=======
+ 	if (rc == 0) {
+ 		rc = ap_msg.rc;
+ 		if (rc == 0)
+ 			rc = convert_response(zq, &ap_msg, crt->outputdata,
+ 					      crt->outputdatalength);
+ 	} else
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  		/* Signal pending. */
- 		ap_cancel_message(zdev->ap_dev, &ap_msg);
+ 		ap_cancel_message(zq->queue, &ap_msg);
  out_free:
  	kfree(ap_msg.message);
  	return rc;
diff --cc drivers/s390/crypto/zcrypt_msgtype6.c
index 9adcfa43d01d,c6cfb9acec19..000000000000
--- a/drivers/s390/crypto/zcrypt_msgtype6.c
+++ b/drivers/s390/crypto/zcrypt_msgtype6.c
@@@ -297,9 -388,10 +282,16 @@@ struct type86_fmt2_msg 
  	struct type86_fmt2_ext fmt2;
  } __packed;
  
++<<<<<<< HEAD
 +static int XCRB_msg_to_type6CPRB_msgX(struct zcrypt_device *zdev,
 +				       struct ap_message *ap_msg,
 +				       struct ica_xcRB *xcRB)
++=======
+ static int XCRB_msg_to_type6CPRB_msgX(struct ap_message *ap_msg,
+ 				      struct ica_xcRB *xcRB,
+ 				      unsigned int *fcode,
+ 				      unsigned short **dom)
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  {
  	static struct type6_hdr static_type6_hdrX = {
  		.type		=  0x06,
@@@ -379,6 -471,9 +371,12 @@@
  	memcpy(msg->hdr.function_code, function_code,
  	       sizeof(msg->hdr.function_code));
  
++<<<<<<< HEAD
++=======
+ 	*fcode = (msg->hdr.function_code[0] << 8) | msg->hdr.function_code[1];
+ 	*dom = (unsigned short *)&msg->cprbx.domain;
+ 
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	if (memcmp(function_code, "US", 2) == 0)
  		ap_msg->special = 1;
  	else
@@@ -392,12 -488,11 +391,15 @@@
  	return 0;
  }
  
 -static int xcrb_msg_to_type6_ep11cprb_msgx(struct ap_message *ap_msg,
 -				       struct ep11_urb *xcRB,
 -				       unsigned int *fcode)
 +static int xcrb_msg_to_type6_ep11cprb_msgx(struct zcrypt_device *zdev,
 +				       struct ap_message *ap_msg,
 +				       struct ep11_urb *xcRB)
  {
  	unsigned int lfmt;
++<<<<<<< HEAD
 +
++=======
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	static struct type6_hdr static_type6_ep11_hdr = {
  		.type		=  0x06,
  		.rqid		= {0x00, 0x01},
@@@ -450,36 -545,23 +452,56 @@@
  		return -EFAULT;
  	}
  
++<<<<<<< HEAD
 +	/*
 +	 The target domain field within the cprb body/payload block will be
 +	 replaced by the usage domain for non-management commands only.
 +	 Therefore we check the first bit of the 'flags' parameter for
 +	 management command indication.
 +	   0 - non managment command
 +	   1 - management command
 +	*/
 +	if (!((msg->cprbx.flags & 0x80) == 0x80)) {
 +		msg->cprbx.target_id = (unsigned int)
 +					AP_QID_QUEUE(zdev->ap_dev->qid);
 +
 +		if ((msg->pld_lenfmt & 0x80) == 0x80) { /*ext.len.fmt 2 or 3*/
 +			switch (msg->pld_lenfmt & 0x03) {
 +			case 1:
 +				lfmt = 2;
 +				break;
 +			case 2:
 +				lfmt = 3;
 +				break;
 +			default:
 +				return -EINVAL;
 +			}
 +		} else {
 +			lfmt = 1; /* length format #1 */
 +		  }
 +		payload_hdr = (struct pld_hdr *)((&(msg->pld_lenfmt))+lfmt);
 +		payload_hdr->dom_val = (unsigned int)
 +					AP_QID_QUEUE(zdev->ap_dev->qid);
 +	}
++=======
+ 	if ((msg->pld_lenfmt & 0x80) == 0x80) { /*ext.len.fmt 2 or 3*/
+ 		switch (msg->pld_lenfmt & 0x03) {
+ 		case 1:
+ 			lfmt = 2;
+ 			break;
+ 		case 2:
+ 			lfmt = 3;
+ 			break;
+ 		default:
+ 			return -EINVAL;
+ 		}
+ 	} else {
+ 		lfmt = 1; /* length format #1 */
+ 	}
+ 	payload_hdr = (struct pld_hdr *)((&(msg->pld_lenfmt))+lfmt);
+ 	*fcode = payload_hdr->func_val & 0xFFFF;
+ 
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	return 0;
  }
  
@@@ -933,14 -1027,17 +971,24 @@@ static long zcrypt_msgtype6_modexpo(str
  	if (rc)
  		goto out_free;
  	init_completion(&resp_type.work);
- 	ap_queue_message(zdev->ap_dev, &ap_msg);
+ 	ap_queue_message(zq->queue, &ap_msg);
  	rc = wait_for_completion_interruptible(&resp_type.work);
++<<<<<<< HEAD
 +	if (rc == 0)
 +		rc = convert_response_ica(zdev, &ap_msg, mex->outputdata,
 +					  mex->outputdatalength);
 +	else
++=======
+ 	if (rc == 0) {
+ 		rc = ap_msg.rc;
+ 		if (rc == 0)
+ 			rc = convert_response_ica(zq, &ap_msg,
+ 						  mex->outputdata,
+ 						  mex->outputdatalength);
+ 	} else
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  		/* Signal pending. */
- 		ap_cancel_message(zdev->ap_dev, &ap_msg);
+ 		ap_cancel_message(zq->queue, &ap_msg);
  out_free:
  	free_page((unsigned long) ap_msg.message);
  	return rc;
@@@ -974,19 -1071,53 +1022,63 @@@ static long zcrypt_msgtype6_modexpo_crt
  	if (rc)
  		goto out_free;
  	init_completion(&resp_type.work);
- 	ap_queue_message(zdev->ap_dev, &ap_msg);
+ 	ap_queue_message(zq->queue, &ap_msg);
  	rc = wait_for_completion_interruptible(&resp_type.work);
++<<<<<<< HEAD
 +	if (rc == 0)
 +		rc = convert_response_ica(zdev, &ap_msg, crt->outputdata,
 +					  crt->outputdatalength);
 +	else
++=======
+ 	if (rc == 0) {
+ 		rc = ap_msg.rc;
+ 		if (rc == 0)
+ 			rc = convert_response_ica(zq, &ap_msg,
+ 						  crt->outputdata,
+ 						  crt->outputdatalength);
+ 	} else {
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  		/* Signal pending. */
- 		ap_cancel_message(zdev->ap_dev, &ap_msg);
+ 		ap_cancel_message(zq->queue, &ap_msg);
+ 	}
  out_free:
  	free_page((unsigned long) ap_msg.message);
  	return rc;
  }
  
++<<<<<<< HEAD
++=======
+ unsigned int get_cprb_fc(struct ica_xcRB *xcRB,
+ 				struct ap_message *ap_msg,
+ 				unsigned int *func_code, unsigned short **dom)
+ {
+ 	struct response_type resp_type = {
+ 		.type = PCIXCC_RESPONSE_TYPE_XCRB,
+ 	};
+ 	int rc;
+ 
+ 	ap_init_message(ap_msg);
+ 	ap_msg->message = kmalloc(MSGTYPE06_MAX_MSG_SIZE, GFP_KERNEL);
+ 	if (!ap_msg->message)
+ 		return -ENOMEM;
+ 	ap_msg->receive = zcrypt_msgtype6_receive;
+ 	ap_msg->psmid = (((unsigned long long) current->pid) << 32) +
+ 				atomic_inc_return(&zcrypt_step);
+ 	ap_msg->private = kmalloc(sizeof(resp_type), GFP_KERNEL);
+ 	if (!ap_msg->private) {
+ 		kzfree(ap_msg->message);
+ 		return -ENOMEM;
+ 	}
+ 	memcpy(ap_msg->private, &resp_type, sizeof(resp_type));
+ 	rc = XCRB_msg_to_type6CPRB_msgX(ap_msg, xcRB, func_code, dom);
+ 	if (rc) {
+ 		kzfree(ap_msg->message);
+ 		kzfree(ap_msg->private);
+ 	}
+ 	return rc;
+ }
+ 
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  /**
   * The request distributor calls this function if it picked the PCIXCC/CEX2C
   * device to handle a send_cprb request.
@@@ -994,12 -1125,35 +1086,41 @@@
   *	  PCIXCC/CEX2C device to the request distributor
   * @xcRB: pointer to the send_cprb request buffer
   */
++<<<<<<< HEAD
 +static long zcrypt_msgtype6_send_cprb(struct zcrypt_device *zdev,
 +				    struct ica_xcRB *xcRB)
++=======
+ static long zcrypt_msgtype6_send_cprb(struct zcrypt_queue *zq,
+ 				    struct ica_xcRB *xcRB,
+ 				    struct ap_message *ap_msg)
+ {
+ 	int rc;
+ 	struct response_type *rtype = (struct response_type *)(ap_msg->private);
+ 
+ 	init_completion(&rtype->work);
+ 	ap_queue_message(zq->queue, ap_msg);
+ 	rc = wait_for_completion_interruptible(&rtype->work);
+ 	if (rc == 0) {
+ 		rc = ap_msg->rc;
+ 		if (rc == 0)
+ 			rc = convert_response_xcrb(zq, ap_msg, xcRB);
+ 	} else
+ 		/* Signal pending. */
+ 		ap_cancel_message(zq->queue, ap_msg);
+ 
+ 	kzfree(ap_msg->message);
+ 	kzfree(ap_msg->private);
+ 	return rc;
+ }
+ 
+ unsigned int get_ep11cprb_fc(struct ep11_urb *xcrb,
+ 				    struct ap_message *ap_msg,
+ 				    unsigned int *func_code)
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  {
 +	struct ap_message ap_msg;
  	struct response_type resp_type = {
 -		.type = PCIXCC_RESPONSE_TYPE_EP11,
 +		.type = PCIXCC_RESPONSE_TYPE_XCRB,
  	};
  	int rc;
  
@@@ -1034,37 -1185,101 +1155,119 @@@ out_free
   *	  CEX4P device to the request distributor
   * @xcRB: pointer to the ep11 user request block
   */
++<<<<<<< HEAD
 +static long zcrypt_msgtype6_send_ep11_cprb(struct zcrypt_device *zdev,
 +						struct ep11_urb *xcrb)
++=======
+ static long zcrypt_msgtype6_send_ep11_cprb(struct zcrypt_queue *zq,
+ 					   struct ep11_urb *xcrb,
+ 					   struct ap_message *ap_msg)
+ {
+ 	int rc;
+ 	unsigned int lfmt;
+ 	struct response_type *rtype = (struct response_type *)(ap_msg->private);
+ 	struct {
+ 		struct type6_hdr hdr;
+ 		struct ep11_cprb cprbx;
+ 		unsigned char	pld_tag;	/* fixed value 0x30 */
+ 		unsigned char	pld_lenfmt;	/* payload length format */
+ 	} __packed * msg = ap_msg->message;
+ 	struct pld_hdr {
+ 		unsigned char	func_tag;	/* fixed value 0x4 */
+ 		unsigned char	func_len;	/* fixed value 0x4 */
+ 		unsigned int	func_val;	/* function ID	   */
+ 		unsigned char	dom_tag;	/* fixed value 0x4 */
+ 		unsigned char	dom_len;	/* fixed value 0x4 */
+ 		unsigned int	dom_val;	/* domain id	   */
+ 	} __packed * payload_hdr = NULL;
+ 
+ 
+ 	/**
+ 	 * The target domain field within the cprb body/payload block will be
+ 	 * replaced by the usage domain for non-management commands only.
+ 	 * Therefore we check the first bit of the 'flags' parameter for
+ 	 * management command indication.
+ 	 *   0 - non management command
+ 	 *   1 - management command
+ 	 */
+ 	if (!((msg->cprbx.flags & 0x80) == 0x80)) {
+ 		msg->cprbx.target_id = (unsigned int)
+ 					AP_QID_QUEUE(zq->queue->qid);
+ 
+ 		if ((msg->pld_lenfmt & 0x80) == 0x80) { /*ext.len.fmt 2 or 3*/
+ 			switch (msg->pld_lenfmt & 0x03) {
+ 			case 1:
+ 				lfmt = 2;
+ 				break;
+ 			case 2:
+ 				lfmt = 3;
+ 				break;
+ 			default:
+ 				return -EINVAL;
+ 			}
+ 		} else {
+ 			lfmt = 1; /* length format #1 */
+ 		}
+ 		payload_hdr = (struct pld_hdr *)((&(msg->pld_lenfmt))+lfmt);
+ 		payload_hdr->dom_val = (unsigned int)
+ 					AP_QID_QUEUE(zq->queue->qid);
+ 	}
+ 
+ 	init_completion(&rtype->work);
+ 	ap_queue_message(zq->queue, ap_msg);
+ 	rc = wait_for_completion_interruptible(&rtype->work);
+ 	if (rc == 0) {
+ 		rc = ap_msg->rc;
+ 		if (rc == 0)
+ 			rc = convert_response_ep11_xcrb(zq, ap_msg, xcrb);
+ 	} else
+ 		/* Signal pending. */
+ 		ap_cancel_message(zq->queue, ap_msg);
+ 
+ 	kzfree(ap_msg->message);
+ 	kzfree(ap_msg->private);
+ 	return rc;
+ }
+ 
+ unsigned int get_rng_fc(struct ap_message *ap_msg, int *func_code,
+ 						   unsigned int *domain)
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  {
 +	struct ap_message ap_msg;
  	struct response_type resp_type = {
 -		.type = PCIXCC_RESPONSE_TYPE_XCRB,
 +		.type = PCIXCC_RESPONSE_TYPE_EP11,
  	};
 +	int rc;
  
 -	ap_init_message(ap_msg);
 -	ap_msg->message = kmalloc(MSGTYPE06_MAX_MSG_SIZE, GFP_KERNEL);
 -	if (!ap_msg->message)
 +	ap_init_message(&ap_msg);
 +	ap_msg.message = kmalloc(MSGTYPE06_MAX_MSG_SIZE, GFP_KERNEL);
 +	if (!ap_msg.message)
  		return -ENOMEM;
 -	ap_msg->receive = zcrypt_msgtype6_receive;
 -	ap_msg->psmid = (((unsigned long long) current->pid) << 32) +
 +	ap_msg.receive = zcrypt_msgtype6_receive_ep11;
 +	ap_msg.psmid = (((unsigned long long) current->pid) << 32) +
  				atomic_inc_return(&zcrypt_step);
 -	ap_msg->private = kmalloc(sizeof(resp_type), GFP_KERNEL);
 -	if (!ap_msg->private) {
 -		kzfree(ap_msg->message);
 -		return -ENOMEM;
 -	}
 -	memcpy(ap_msg->private, &resp_type, sizeof(resp_type));
 +	ap_msg.private = &resp_type;
 +	rc = xcrb_msg_to_type6_ep11cprb_msgx(zdev, &ap_msg, xcrb);
 +	if (rc)
 +		goto out_free;
 +	init_completion(&resp_type.work);
 +	ap_queue_message(zdev->ap_dev, &ap_msg);
 +	rc = wait_for_completion_interruptible(&resp_type.work);
 +	if (rc == 0)
 +		rc = convert_response_ep11_xcrb(zdev, &ap_msg, xcrb);
 +	else /* Signal pending. */
 +		ap_cancel_message(zdev->ap_dev, &ap_msg);
  
++<<<<<<< HEAD
 +out_free:
 +	kzfree(ap_msg.message);
 +	return rc;
++=======
+ 	rng_type6CPRB_msgX(ap_msg, ZCRYPT_RNG_BUFFER_SIZE, domain);
+ 
+ 	*func_code = HWRNG;
+ 	return 0;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  }
  
  /**
@@@ -1074,34 -1289,36 +1277,57 @@@
   *	  PCIXCC/CEX2C device to the request distributor
   * @buffer: pointer to a memory page to return random data
   */
++<<<<<<< HEAD
 +
 +static long zcrypt_msgtype6_rng(struct zcrypt_device *zdev,
 +				    char *buffer)
++=======
+ static long zcrypt_msgtype6_rng(struct zcrypt_queue *zq,
+ 				char *buffer, struct ap_message *ap_msg)
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  {
 -	struct {
 -		struct type6_hdr hdr;
 -		struct CPRBX cprbx;
 -		char function_code[2];
 -		short int rule_length;
 -		char rule[8];
 -		short int verb_length;
 -		short int key_length;
 -	} __packed * msg = ap_msg->message;
 -	struct response_type *rtype = (struct response_type *)(ap_msg->private);
 +	struct ap_message ap_msg;
 +	struct response_type resp_type = {
 +		.type = PCIXCC_RESPONSE_TYPE_XCRB,
 +	};
  	int rc;
  
++<<<<<<< HEAD
 +	ap_init_message(&ap_msg);
 +	ap_msg.message = kmalloc(MSGTYPE06_MAX_MSG_SIZE, GFP_KERNEL);
 +	if (!ap_msg.message)
 +		return -ENOMEM;
 +	ap_msg.receive = zcrypt_msgtype6_receive;
 +	ap_msg.psmid = (((unsigned long long) current->pid) << 32) +
 +				atomic_inc_return(&zcrypt_step);
 +	ap_msg.private = &resp_type;
 +	rng_type6CPRB_msgX(zdev->ap_dev, &ap_msg, ZCRYPT_RNG_BUFFER_SIZE);
 +	init_completion(&resp_type.work);
 +	ap_queue_message(zdev->ap_dev, &ap_msg);
 +	rc = wait_for_completion_interruptible(&resp_type.work);
 +	if (rc == 0)
 +		rc = convert_response_rng(zdev, &ap_msg, buffer);
 +	else
 +		/* Signal pending. */
 +		ap_cancel_message(zdev->ap_dev, &ap_msg);
 +	kfree(ap_msg.message);
++=======
+ 	msg->cprbx.domain = AP_QID_QUEUE(zq->queue->qid);
+ 
+ 	init_completion(&rtype->work);
+ 	ap_queue_message(zq->queue, ap_msg);
+ 	rc = wait_for_completion_interruptible(&rtype->work);
+ 	if (rc == 0) {
+ 		rc = ap_msg->rc;
+ 		if (rc == 0)
+ 			rc = convert_response_rng(zq, ap_msg, buffer);
+ 	} else
+ 		/* Signal pending. */
+ 		ap_cancel_message(zq->queue, ap_msg);
+ 
+ 	kzfree(ap_msg->message);
+ 	kzfree(ap_msg->private);
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	return rc;
  }
  
diff --cc drivers/s390/crypto/zcrypt_msgtype6.h
index 207247570623,7a0d5b57821f..000000000000
--- a/drivers/s390/crypto/zcrypt_msgtype6.h
+++ b/drivers/s390/crypto/zcrypt_msgtype6.h
@@@ -116,15 -116,28 +116,37 @@@ struct type86_fmt2_ext 
  	unsigned int	  offset4;	/* 0x00000000			*/
  } __packed;
  
++<<<<<<< HEAD
++=======
+ unsigned int get_cprb_fc(struct ica_xcRB *, struct ap_message *,
+ 			 unsigned int *, unsigned short **);
+ unsigned int get_ep11cprb_fc(struct ep11_urb *, struct ap_message *,
+ 			     unsigned int *);
+ unsigned int get_rng_fc(struct ap_message *, int *, unsigned int *);
+ 
+ #define LOW	10
+ #define MEDIUM	100
+ #define HIGH	500
+ 
+ int speed_idx_cca(int);
+ int speed_idx_ep11(int);
+ 
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  /**
   * Prepare a type6 CPRB message for random number generation
   *
   * @ap_dev: AP device pointer
   * @ap_msg: pointer to AP message
   */
++<<<<<<< HEAD
 +static inline void rng_type6CPRB_msgX(struct ap_device *ap_dev,
 +			       struct ap_message *ap_msg,
 +			       unsigned random_number_length)
++=======
+ static inline void rng_type6CPRB_msgX(struct ap_message *ap_msg,
+ 				      unsigned int random_number_length,
+ 				      unsigned int *domain)
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  {
  	struct {
  		struct type6_hdr hdr;
@@@ -163,9 -175,10 +185,10 @@@
  	msg->verb_length = 0x02;
  	msg->key_length = 0x02;
  	ap_msg->length = sizeof(*msg);
+ 	*domain = (unsigned short)msg->cprbx.domain;
  }
  
 -void zcrypt_msgtype6_init(void);
 +int zcrypt_msgtype6_init(void);
  void zcrypt_msgtype6_exit(void);
  
  #endif /* _ZCRYPT_MSGTYPE6_H_ */
diff --cc drivers/s390/crypto/zcrypt_pcixcc.c
index 899ffa19f5ec,26ceaa696765..000000000000
--- a/drivers/s390/crypto/zcrypt_pcixcc.c
+++ b/drivers/s390/crypto/zcrypt_pcixcc.c
@@@ -80,129 -68,29 +73,59 @@@ MODULE_DESCRIPTION("PCIXCC Cryptographi
  		   "Copyright IBM Corp. 2001, 2012");
  MODULE_LICENSE("GPL");
  
- static int zcrypt_pcixcc_probe(struct ap_device *ap_dev);
- static void zcrypt_pcixcc_remove(struct ap_device *ap_dev);
- 
- static struct ap_driver zcrypt_pcixcc_driver = {
- 	.probe = zcrypt_pcixcc_probe,
- 	.remove = zcrypt_pcixcc_remove,
- 	.ids = zcrypt_pcixcc_ids,
- 	.request_timeout = PCIXCC_CLEANUP_TIME,
+ static struct ap_device_id zcrypt_pcixcc_card_ids[] = {
+ 	{ .dev_type = AP_DEVICE_TYPE_PCIXCC,
+ 	  .match_flags = AP_DEVICE_ID_MATCH_CARD_TYPE },
+ 	{ .dev_type = AP_DEVICE_TYPE_CEX2C,
+ 	  .match_flags = AP_DEVICE_ID_MATCH_CARD_TYPE },
+ 	{ .dev_type = AP_DEVICE_TYPE_CEX3C,
+ 	  .match_flags = AP_DEVICE_ID_MATCH_CARD_TYPE },
+ 	{ /* end of list */ },
  };
  
- /**
-  * Micro-code detection function. Its sends a message to a pcixcc card
-  * to find out the microcode level.
-  * @ap_dev: pointer to the AP device.
-  */
- static int zcrypt_pcixcc_mcl(struct ap_device *ap_dev)
- {
- 	static unsigned char msg[] = {
- 		0x00,0x06,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x58,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x43,0x41,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x50,0x4B,0x00,0x00,
- 		0x00,0x00,0x01,0xC4,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x07,0x24,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0xDC,0x02,0x00,0x00,0x00,0x54,0x32,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0xE8,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x07,0x24,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x04,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x00,0x00,0x00,0x00,
- 		0x00,0x00,0x00,0x00,0x50,0x4B,0x00,0x0A,
- 		0x4D,0x52,0x50,0x20,0x20,0x20,0x20,0x20,
- 		0x00,0x42,0x00,0x01,0x02,0x03,0x04,0x05,
- 		0x06,0x07,0x08,0x09,0x0A,0x0B,0x0C,0x0D,
- 		0x0E,0x0F,0x00,0x11,0x22,0x33,0x44,0x55,
- 		0x66,0x77,0x88,0x99,0xAA,0xBB,0xCC,0xDD,
- 		0xEE,0xFF,0xFF,0xEE,0xDD,0xCC,0xBB,0xAA,
- 		0x99,0x88,0x77,0x66,0x55,0x44,0x33,0x22,
- 		0x11,0x00,0x01,0x23,0x45,0x67,0x89,0xAB,
- 		0xCD,0xEF,0xFE,0xDC,0xBA,0x98,0x76,0x54,
- 		0x32,0x10,0x00,0x9A,0x00,0x98,0x00,0x00,
- 		0x1E,0x00,0x00,0x94,0x00,0x00,0x00,0x00,
- 		0x04,0x00,0x00,0x8C,0x00,0x00,0x00,0x40,
- 		0x02,0x00,0x00,0x40,0xBA,0xE8,0x23,0x3C,
- 		0x75,0xF3,0x91,0x61,0xD6,0x73,0x39,0xCF,
- 		0x7B,0x6D,0x8E,0x61,0x97,0x63,0x9E,0xD9,
- 		0x60,0x55,0xD6,0xC7,0xEF,0xF8,0x1E,0x63,
- 		0x95,0x17,0xCC,0x28,0x45,0x60,0x11,0xC5,
- 		0xC4,0x4E,0x66,0xC6,0xE6,0xC3,0xDE,0x8A,
- 		0x19,0x30,0xCF,0x0E,0xD7,0xAA,0xDB,0x01,
- 		0xD8,0x00,0xBB,0x8F,0x39,0x9F,0x64,0x28,
- 		0xF5,0x7A,0x77,0x49,0xCC,0x6B,0xA3,0x91,
- 		0x97,0x70,0xE7,0x60,0x1E,0x39,0xE1,0xE5,
- 		0x33,0xE1,0x15,0x63,0x69,0x08,0x80,0x4C,
- 		0x67,0xC4,0x41,0x8F,0x48,0xDF,0x26,0x98,
- 		0xF1,0xD5,0x8D,0x88,0xD9,0x6A,0xA4,0x96,
- 		0xC5,0x84,0xD9,0x30,0x49,0x67,0x7D,0x19,
- 		0xB1,0xB3,0x45,0x4D,0xB2,0x53,0x9A,0x47,
- 		0x3C,0x7C,0x55,0xBF,0xCC,0x85,0x00,0x36,
- 		0xF1,0x3D,0x93,0x53
- 	};
- 	unsigned long long psmid;
- 	struct CPRBX *cprbx;
- 	char *reply;
- 	int rc, i;
+ MODULE_DEVICE_TABLE(ap, zcrypt_pcixcc_card_ids);
  
- 	reply = (void *) get_zeroed_page(GFP_KERNEL);
- 	if (!reply)
- 		return -ENOMEM;
+ static struct ap_device_id zcrypt_pcixcc_queue_ids[] = {
+ 	{ .dev_type = AP_DEVICE_TYPE_PCIXCC,
+ 	  .match_flags = AP_DEVICE_ID_MATCH_QUEUE_TYPE },
+ 	{ .dev_type = AP_DEVICE_TYPE_CEX2C,
+ 	  .match_flags = AP_DEVICE_ID_MATCH_QUEUE_TYPE },
+ 	{ .dev_type = AP_DEVICE_TYPE_CEX3C,
+ 	  .match_flags = AP_DEVICE_ID_MATCH_QUEUE_TYPE },
+ 	{ /* end of list */ },
+ };
  
++<<<<<<< HEAD
 +	rc = ap_send(ap_dev->qid, 0x0102030405060708ULL, msg, sizeof(msg));
 +	if (rc)
 +		goto out_free;
 +
 +	/* Wait for the test message to complete. */
 +	for (i = 0; i < 6; i++) {
 +		mdelay(300);
 +		rc = ap_recv(ap_dev->qid, &psmid, reply, 4096);
 +		if (rc == 0 && psmid == 0x0102030405060708ULL)
 +			break;
 +	}
 +
 +	if (i >= 6) {
 +		/* Got no answer. */
 +		rc = -ENODEV;
 +		goto out_free;
 +	}
 +
 +	cprbx = (struct CPRBX *) (reply + 48);
 +	if (cprbx->ccp_rtcode == 8 && cprbx->ccp_rscode == 33)
 +		rc = ZCRYPT_PCIXCC_MCL2;
 +	else
 +		rc = ZCRYPT_PCIXCC_MCL3;
 +out_free:
 +	free_page((unsigned long) reply);
 +	return rc;
 +}
++=======
+ MODULE_DEVICE_TABLE(ap, zcrypt_pcixcc_queue_ids);
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  
  /**
   * Large random number detection function. Its sends a message to a pcixcc
@@@ -227,8 -125,12 +151,17 @@@ static int zcrypt_pcixcc_rng_supported(
  	if (!ap_msg.message)
  		return -ENOMEM;
  
++<<<<<<< HEAD
 +	rng_type6CPRB_msgX(ap_dev, &ap_msg, 4);
 +	rc = ap_send(ap_dev->qid, 0x0102030405060708ULL, ap_msg.message,
++=======
+ 	rng_type6CPRB_msgX(&ap_msg, 4, &domain);
+ 
+ 	msg = ap_msg.message;
+ 	msg->cprbx.domain = AP_QID_QUEUE(aq->qid);
+ 
+ 	rc = ap_send(aq->qid, 0x0102030405060708ULL, ap_msg.message,
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  		     ap_msg.length);
  	if (rc)
  		goto out_free;
@@@ -258,105 -160,162 +191,239 @@@ out_free
  }
  
  /**
-  * Probe function for PCIXCC/CEX2C cards. It always accepts the AP device
-  * since the bus_match already checked the hardware type. The PCIXCC
-  * cards come in two flavours: micro code level 2 and micro code level 3.
-  * This is checked by sending a test message to the device.
-  * @ap_dev: pointer to the AP device.
+  * Probe function for PCIXCC/CEX2C card devices. It always accepts the
+  * AP device since the bus_match already checked the hardware type. The
+  * PCIXCC cards come in two flavours: micro code level 2 and micro code
+  * level 3. This is checked by sending a test message to the device.
+  * @ap_dev: pointer to the AP card device.
   */
- static int zcrypt_pcixcc_probe(struct ap_device *ap_dev)
+ static int zcrypt_pcixcc_card_probe(struct ap_device *ap_dev)
  {
++<<<<<<< HEAD
 +	struct zcrypt_device *zdev;
++=======
+ 	/*
+ 	 * Normalized speed ratings per crypto adapter
+ 	 * MEX_1k, MEX_2k, MEX_4k, CRT_1k, CRT_2k, CRT_4k, RNG, SECKEY
+ 	 */
+ 	static const int CEX2C_SPEED_IDX[] = {
+ 		1000, 1400, 2400, 1100, 1500, 2600, 100, 12};
+ 	static const int CEX3C_SPEED_IDX[] = {
+ 		500,  700, 1400,  550,	800, 1500,  80, 10};
+ 
+ 	struct ap_card *ac = to_ap_card(&ap_dev->device);
+ 	struct zcrypt_card *zc;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	int rc = 0;
  
- 	zdev = zcrypt_device_alloc(PCIXCC_MAX_XCRB_MESSAGE_SIZE);
- 	if (!zdev)
+ 	zc = zcrypt_card_alloc();
+ 	if (!zc)
  		return -ENOMEM;
++<<<<<<< HEAD
 +	zdev->ap_dev = ap_dev;
 +	zdev->online = 1;
 +	switch (ap_dev->device_type) {
 +	case AP_DEVICE_TYPE_PCIXCC:
 +		rc = zcrypt_pcixcc_mcl(ap_dev);
 +		if (rc < 0) {
 +			zcrypt_device_free(zdev);
 +			return rc;
 +		}
 +		zdev->user_space_type = rc;
 +		if (rc == ZCRYPT_PCIXCC_MCL2) {
 +			zdev->type_string = "PCIXCC_MCL2";
 +			zdev->speed_rating = PCIXCC_MCL2_SPEED_RATING;
 +			zdev->min_mod_size = PCIXCC_MIN_MOD_SIZE_OLD;
 +			zdev->max_mod_size = PCIXCC_MAX_MOD_SIZE;
 +			zdev->max_exp_bit_length = PCIXCC_MAX_MOD_SIZE;
 +		} else {
 +			zdev->type_string = "PCIXCC_MCL3";
 +			zdev->speed_rating = PCIXCC_MCL3_SPEED_RATING;
 +			zdev->min_mod_size = PCIXCC_MIN_MOD_SIZE;
 +			zdev->max_mod_size = PCIXCC_MAX_MOD_SIZE;
 +			zdev->max_exp_bit_length = PCIXCC_MAX_MOD_SIZE;
 +		}
 +		break;
 +	case AP_DEVICE_TYPE_CEX2C:
 +		zdev->user_space_type = ZCRYPT_CEX2C;
 +		zdev->type_string = "CEX2C";
 +		zdev->speed_rating = CEX2C_SPEED_RATING;
 +		zdev->min_mod_size = PCIXCC_MIN_MOD_SIZE;
 +		zdev->max_mod_size = PCIXCC_MAX_MOD_SIZE;
 +		zdev->max_exp_bit_length = PCIXCC_MAX_MOD_SIZE;
 +		break;
 +	case AP_DEVICE_TYPE_CEX3C:
 +		zdev->user_space_type = ZCRYPT_CEX3C;
 +		zdev->type_string = "CEX3C";
 +		zdev->speed_rating = CEX3C_SPEED_RATING;
 +		zdev->min_mod_size = CEX3C_MIN_MOD_SIZE;
 +		zdev->max_mod_size = CEX3C_MAX_MOD_SIZE;
 +		zdev->max_exp_bit_length = CEX3C_MAX_MOD_SIZE;
++=======
+ 	zc->card = ac;
+ 	ac->private = zc;
+ 	switch (ac->ap_dev.device_type) {
+ 	case AP_DEVICE_TYPE_CEX2C:
+ 		zc->user_space_type = ZCRYPT_CEX2C;
+ 		zc->type_string = "CEX2C";
+ 		memcpy(zc->speed_rating, CEX2C_SPEED_IDX,
+ 		       sizeof(CEX2C_SPEED_IDX));
+ 		zc->min_mod_size = PCIXCC_MIN_MOD_SIZE;
+ 		zc->max_mod_size = PCIXCC_MAX_MOD_SIZE;
+ 		zc->max_exp_bit_length = PCIXCC_MAX_MOD_SIZE;
+ 		break;
+ 	case AP_DEVICE_TYPE_CEX3C:
+ 		zc->user_space_type = ZCRYPT_CEX3C;
+ 		zc->type_string = "CEX3C";
+ 		memcpy(zc->speed_rating, CEX3C_SPEED_IDX,
+ 		       sizeof(CEX3C_SPEED_IDX));
+ 		zc->min_mod_size = CEX3C_MIN_MOD_SIZE;
+ 		zc->max_mod_size = CEX3C_MAX_MOD_SIZE;
+ 		zc->max_exp_bit_length = CEX3C_MAX_MOD_SIZE;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  		break;
  	default:
- 		goto out_free;
+ 		zcrypt_card_free(zc);
+ 		return -ENODEV;
  	}
- 
- 	rc = zcrypt_pcixcc_rng_supported(ap_dev);
- 	if (rc < 0) {
- 		zcrypt_device_free(zdev);
- 		return rc;
++<<<<<<< HEAD
++=======
+ 	zc->online = 1;
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
+ 
+ 	rc = zcrypt_card_register(zc);
+ 	if (rc) {
+ 		ac->private = NULL;
+ 		zcrypt_card_free(zc);
  	}
++<<<<<<< HEAD
 +	if (rc)
 +		zdev->ops = zcrypt_msgtype_request(MSGTYPE06_NAME,
 +						   MSGTYPE06_VARIANT_DEFAULT);
 +	else
 +		zdev->ops = zcrypt_msgtype_request(MSGTYPE06_NAME,
 +						   MSGTYPE06_VARIANT_NORNG);
 +	ap_dev->reply = &zdev->reply;
 +	ap_dev->private = zdev;
 +	rc = zcrypt_device_register(zdev);
 +	if (rc)
 +		goto out_free;
 +	return 0;
 +
 + out_free:
 +	ap_dev->private = NULL;
 +	zcrypt_msgtype_release(zdev->ops);
 +	zcrypt_device_free(zdev);
++=======
+ 
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  	return rc;
  }
  
  /**
-  * This is called to remove the extended PCIXCC/CEX2C driver information
-  * if an AP device is removed.
+  * This is called to remove the PCIXCC/CEX2C card driver information
+  * if an AP card device is removed.
   */
- static void zcrypt_pcixcc_remove(struct ap_device *ap_dev)
+ static void zcrypt_pcixcc_card_remove(struct ap_device *ap_dev)
  {
++<<<<<<< HEAD
 +	struct zcrypt_device *zdev = ap_dev->private;
 +	struct zcrypt_ops *zops = zdev->ops;
 +
 +	zcrypt_device_unregister(zdev);
 +	zcrypt_msgtype_release(zops);
++=======
+ 	struct zcrypt_card *zc = to_ap_card(&ap_dev->device)->private;
+ 
+ 	if (zc)
+ 		zcrypt_card_unregister(zc);
++>>>>>>> e28d2af43614 (s390/zcrypt: add multi domain support)
  }
  
+ static struct ap_driver zcrypt_pcixcc_card_driver = {
+ 	.probe = zcrypt_pcixcc_card_probe,
+ 	.remove = zcrypt_pcixcc_card_remove,
+ 	.ids = zcrypt_pcixcc_card_ids,
+ };
+ 
+ /**
+  * Probe function for PCIXCC/CEX2C queue devices. It always accepts the
+  * AP device since the bus_match already checked the hardware type. The
+  * PCIXCC cards come in two flavours: micro code level 2 and micro code
+  * level 3. This is checked by sending a test message to the device.
+  * @ap_dev: pointer to the AP card device.
+  */
+ static int zcrypt_pcixcc_queue_probe(struct ap_device *ap_dev)
+ {
+ 	struct ap_queue *aq = to_ap_queue(&ap_dev->device);
+ 	struct zcrypt_queue *zq;
+ 	int rc;
+ 
+ 	zq = zcrypt_queue_alloc(PCIXCC_MAX_XCRB_MESSAGE_SIZE);
+ 	if (!zq)
+ 		return -ENOMEM;
+ 	zq->queue = aq;
+ 	zq->online = 1;
+ 	atomic_set(&zq->load, 0);
+ 	rc = zcrypt_pcixcc_rng_supported(aq);
+ 	if (rc < 0) {
+ 		zcrypt_queue_free(zq);
+ 		return rc;
+ 	}
+ 	if (rc)
+ 		zq->ops = zcrypt_msgtype(MSGTYPE06_NAME,
+ 					 MSGTYPE06_VARIANT_DEFAULT);
+ 	else
+ 		zq->ops = zcrypt_msgtype(MSGTYPE06_NAME,
+ 					 MSGTYPE06_VARIANT_NORNG);
+ 	ap_queue_init_reply(aq, &zq->reply);
+ 	aq->request_timeout = PCIXCC_CLEANUP_TIME,
+ 	aq->private = zq;
+ 	rc = zcrypt_queue_register(zq);
+ 	if (rc) {
+ 		aq->private = NULL;
+ 		zcrypt_queue_free(zq);
+ 	}
+ 	return rc;
+ }
+ 
+ /**
+  * This is called to remove the PCIXCC/CEX2C queue driver information
+  * if an AP queue device is removed.
+  */
+ static void zcrypt_pcixcc_queue_remove(struct ap_device *ap_dev)
+ {
+ 	struct ap_queue *aq = to_ap_queue(&ap_dev->device);
+ 	struct zcrypt_queue *zq = aq->private;
+ 
+ 	ap_queue_remove(aq);
+ 	if (zq)
+ 		zcrypt_queue_unregister(zq);
+ }
+ 
+ static struct ap_driver zcrypt_pcixcc_queue_driver = {
+ 	.probe = zcrypt_pcixcc_queue_probe,
+ 	.remove = zcrypt_pcixcc_queue_remove,
+ 	.suspend = ap_queue_suspend,
+ 	.resume = ap_queue_resume,
+ 	.ids = zcrypt_pcixcc_queue_ids,
+ };
+ 
  int __init zcrypt_pcixcc_init(void)
  {
- 	return ap_driver_register(&zcrypt_pcixcc_driver, THIS_MODULE, "pcixcc");
+ 	int rc;
+ 
+ 	rc = ap_driver_register(&zcrypt_pcixcc_card_driver,
+ 				THIS_MODULE, "pcixcccard");
+ 	if (rc)
+ 		return rc;
+ 
+ 	rc = ap_driver_register(&zcrypt_pcixcc_queue_driver,
+ 				THIS_MODULE, "pcixccqueue");
+ 	if (rc)
+ 		ap_driver_unregister(&zcrypt_pcixcc_card_driver);
+ 
+ 	return rc;
  }
  
  void zcrypt_pcixcc_exit(void)
* Unmerged path drivers/s390/crypto/Makefile
* Unmerged path drivers/s390/crypto/ap_bus.c
* Unmerged path drivers/s390/crypto/ap_bus.h
diff --git a/drivers/s390/crypto/ap_card.c b/drivers/s390/crypto/ap_card.c
new file mode 100644
index 000000000000..731dc0dbfb75
--- /dev/null
+++ b/drivers/s390/crypto/ap_card.c
@@ -0,0 +1,172 @@
+/*
+ * Copyright IBM Corp. 2016
+ * Author(s): Martin Schwidefsky <schwidefsky@de.ibm.com>
+ *
+ * Adjunct processor bus, card related code.
+ */
+
+#define KMSG_COMPONENT "ap"
+#define pr_fmt(fmt) KMSG_COMPONENT ": " fmt
+
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <asm/facility.h>
+
+#include "ap_bus.h"
+#include "ap_asm.h"
+
+/*
+ * AP card related attributes.
+ */
+static ssize_t ap_hwtype_show(struct device *dev,
+			      struct device_attribute *attr, char *buf)
+{
+	struct ap_card *ac = to_ap_card(dev);
+
+	return snprintf(buf, PAGE_SIZE, "%d\n", ac->ap_dev.device_type);
+}
+
+static DEVICE_ATTR(hwtype, 0444, ap_hwtype_show, NULL);
+
+static ssize_t ap_raw_hwtype_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	struct ap_card *ac = to_ap_card(dev);
+
+	return snprintf(buf, PAGE_SIZE, "%d\n", ac->raw_hwtype);
+}
+
+static DEVICE_ATTR(raw_hwtype, 0444, ap_raw_hwtype_show, NULL);
+
+static ssize_t ap_depth_show(struct device *dev, struct device_attribute *attr,
+			     char *buf)
+{
+	struct ap_card *ac = to_ap_card(dev);
+
+	return snprintf(buf, PAGE_SIZE, "%d\n", ac->queue_depth);
+}
+
+static DEVICE_ATTR(depth, 0444, ap_depth_show, NULL);
+
+static ssize_t ap_functions_show(struct device *dev,
+				 struct device_attribute *attr, char *buf)
+{
+	struct ap_card *ac = to_ap_card(dev);
+
+	return snprintf(buf, PAGE_SIZE, "0x%08X\n", ac->functions);
+}
+
+static DEVICE_ATTR(ap_functions, 0444, ap_functions_show, NULL);
+
+static ssize_t ap_request_count_show(struct device *dev,
+				     struct device_attribute *attr,
+				     char *buf)
+{
+	struct ap_card *ac = to_ap_card(dev);
+	struct ap_queue *aq;
+	unsigned int req_cnt;
+
+	req_cnt = 0;
+	spin_lock_bh(&ap_list_lock);
+	for_each_ap_queue(aq, ac)
+		req_cnt += aq->total_request_count;
+	spin_unlock_bh(&ap_list_lock);
+	return snprintf(buf, PAGE_SIZE, "%d\n", req_cnt);
+}
+
+static DEVICE_ATTR(request_count, 0444, ap_request_count_show, NULL);
+
+static ssize_t ap_requestq_count_show(struct device *dev,
+				      struct device_attribute *attr, char *buf)
+{
+	struct ap_card *ac = to_ap_card(dev);
+	struct ap_queue *aq;
+	unsigned int reqq_cnt;
+
+	reqq_cnt = 0;
+	spin_lock_bh(&ap_list_lock);
+	for_each_ap_queue(aq, ac)
+		reqq_cnt += aq->requestq_count;
+	spin_unlock_bh(&ap_list_lock);
+	return snprintf(buf, PAGE_SIZE, "%d\n", reqq_cnt);
+}
+
+static DEVICE_ATTR(requestq_count, 0444, ap_requestq_count_show, NULL);
+
+static ssize_t ap_pendingq_count_show(struct device *dev,
+				      struct device_attribute *attr, char *buf)
+{
+	struct ap_card *ac = to_ap_card(dev);
+	struct ap_queue *aq;
+	unsigned int penq_cnt;
+
+	penq_cnt = 0;
+	spin_lock_bh(&ap_list_lock);
+	for_each_ap_queue(aq, ac)
+		penq_cnt += aq->pendingq_count;
+	spin_unlock_bh(&ap_list_lock);
+	return snprintf(buf, PAGE_SIZE, "%d\n", penq_cnt);
+}
+
+static DEVICE_ATTR(pendingq_count, 0444, ap_pendingq_count_show, NULL);
+
+static ssize_t ap_modalias_show(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	return sprintf(buf, "ap:t%02X\n", to_ap_dev(dev)->device_type);
+}
+
+static DEVICE_ATTR(modalias, 0444, ap_modalias_show, NULL);
+
+static struct attribute *ap_card_dev_attrs[] = {
+	&dev_attr_hwtype.attr,
+	&dev_attr_raw_hwtype.attr,
+	&dev_attr_depth.attr,
+	&dev_attr_ap_functions.attr,
+	&dev_attr_request_count.attr,
+	&dev_attr_requestq_count.attr,
+	&dev_attr_pendingq_count.attr,
+	&dev_attr_modalias.attr,
+	NULL
+};
+
+static struct attribute_group ap_card_dev_attr_group = {
+	.attrs = ap_card_dev_attrs
+};
+
+static const struct attribute_group *ap_card_dev_attr_groups[] = {
+	&ap_card_dev_attr_group,
+	NULL
+};
+
+struct device_type ap_card_type = {
+	.name = "ap_card",
+	.groups = ap_card_dev_attr_groups,
+};
+
+static void ap_card_device_release(struct device *dev)
+{
+	kfree(to_ap_card(dev));
+}
+
+struct ap_card *ap_card_create(int id, int queue_depth, int device_type,
+			       unsigned int functions)
+{
+	struct ap_card *ac;
+
+	ac = kzalloc(sizeof(*ac), GFP_KERNEL);
+	if (!ac)
+		return NULL;
+	INIT_LIST_HEAD(&ac->queues);
+	ac->ap_dev.device.release = ap_card_device_release;
+	ac->ap_dev.device.type = &ap_card_type;
+	ac->ap_dev.device_type = device_type;
+	/* CEX6 toleration: map to CEX5 */
+	if (device_type == AP_DEVICE_TYPE_CEX6)
+		ac->ap_dev.device_type = AP_DEVICE_TYPE_CEX5;
+	ac->raw_hwtype = device_type;
+	ac->queue_depth = queue_depth;
+	ac->functions = functions;
+	ac->id = id;
+	return ac;
+}
diff --git a/drivers/s390/crypto/ap_queue.c b/drivers/s390/crypto/ap_queue.c
new file mode 100644
index 000000000000..8f95a071b670
--- /dev/null
+++ b/drivers/s390/crypto/ap_queue.c
@@ -0,0 +1,700 @@
+/*
+ * Copyright IBM Corp. 2016
+ * Author(s): Martin Schwidefsky <schwidefsky@de.ibm.com>
+ *
+ * Adjunct processor bus, queue related code.
+ */
+
+#define KMSG_COMPONENT "ap"
+#define pr_fmt(fmt) KMSG_COMPONENT ": " fmt
+
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <asm/facility.h>
+
+#include "ap_bus.h"
+#include "ap_asm.h"
+
+/**
+ * ap_queue_enable_interruption(): Enable interruption on an AP queue.
+ * @qid: The AP queue number
+ * @ind: the notification indicator byte
+ *
+ * Enables interruption on AP queue via ap_aqic(). Based on the return
+ * value it waits a while and tests the AP queue if interrupts
+ * have been switched on using ap_test_queue().
+ */
+static int ap_queue_enable_interruption(struct ap_queue *aq, void *ind)
+{
+	struct ap_queue_status status;
+
+	status = ap_aqic(aq->qid, ind);
+	switch (status.response_code) {
+	case AP_RESPONSE_NORMAL:
+	case AP_RESPONSE_OTHERWISE_CHANGED:
+		return 0;
+	case AP_RESPONSE_Q_NOT_AVAIL:
+	case AP_RESPONSE_DECONFIGURED:
+	case AP_RESPONSE_CHECKSTOPPED:
+	case AP_RESPONSE_INVALID_ADDRESS:
+		pr_err("Registering adapter interrupts for AP device %02x.%04x failed\n",
+		       AP_QID_CARD(aq->qid),
+		       AP_QID_QUEUE(aq->qid));
+		return -EOPNOTSUPP;
+	case AP_RESPONSE_RESET_IN_PROGRESS:
+	case AP_RESPONSE_BUSY:
+	default:
+		return -EBUSY;
+	}
+}
+
+/**
+ * __ap_send(): Send message to adjunct processor queue.
+ * @qid: The AP queue number
+ * @psmid: The program supplied message identifier
+ * @msg: The message text
+ * @length: The message length
+ * @special: Special Bit
+ *
+ * Returns AP queue status structure.
+ * Condition code 1 on NQAP can't happen because the L bit is 1.
+ * Condition code 2 on NQAP also means the send is incomplete,
+ * because a segment boundary was reached. The NQAP is repeated.
+ */
+static inline struct ap_queue_status
+__ap_send(ap_qid_t qid, unsigned long long psmid, void *msg, size_t length,
+	  unsigned int special)
+{
+	if (special == 1)
+		qid |= 0x400000UL;
+	return ap_nqap(qid, psmid, msg, length);
+}
+
+int ap_send(ap_qid_t qid, unsigned long long psmid, void *msg, size_t length)
+{
+	struct ap_queue_status status;
+
+	status = __ap_send(qid, psmid, msg, length, 0);
+	switch (status.response_code) {
+	case AP_RESPONSE_NORMAL:
+		return 0;
+	case AP_RESPONSE_Q_FULL:
+	case AP_RESPONSE_RESET_IN_PROGRESS:
+		return -EBUSY;
+	case AP_RESPONSE_REQ_FAC_NOT_INST:
+		return -EINVAL;
+	default:	/* Device is gone. */
+		return -ENODEV;
+	}
+}
+EXPORT_SYMBOL(ap_send);
+
+int ap_recv(ap_qid_t qid, unsigned long long *psmid, void *msg, size_t length)
+{
+	struct ap_queue_status status;
+
+	if (msg == NULL)
+		return -EINVAL;
+	status = ap_dqap(qid, psmid, msg, length);
+	switch (status.response_code) {
+	case AP_RESPONSE_NORMAL:
+		return 0;
+	case AP_RESPONSE_NO_PENDING_REPLY:
+		if (status.queue_empty)
+			return -ENOENT;
+		return -EBUSY;
+	case AP_RESPONSE_RESET_IN_PROGRESS:
+		return -EBUSY;
+	default:
+		return -ENODEV;
+	}
+}
+EXPORT_SYMBOL(ap_recv);
+
+/* State machine definitions and helpers */
+
+static enum ap_wait ap_sm_nop(struct ap_queue *aq)
+{
+	return AP_WAIT_NONE;
+}
+
+/**
+ * ap_sm_recv(): Receive pending reply messages from an AP queue but do
+ *	not change the state of the device.
+ * @aq: pointer to the AP queue
+ *
+ * Returns AP_WAIT_NONE, AP_WAIT_AGAIN, or AP_WAIT_INTERRUPT
+ */
+static struct ap_queue_status ap_sm_recv(struct ap_queue *aq)
+{
+	struct ap_queue_status status;
+	struct ap_message *ap_msg;
+
+	status = ap_dqap(aq->qid, &aq->reply->psmid,
+			 aq->reply->message, aq->reply->length);
+	switch (status.response_code) {
+	case AP_RESPONSE_NORMAL:
+		aq->queue_count--;
+		if (aq->queue_count > 0)
+			mod_timer(&aq->timeout,
+				  jiffies + aq->request_timeout);
+		list_for_each_entry(ap_msg, &aq->pendingq, list) {
+			if (ap_msg->psmid != aq->reply->psmid)
+				continue;
+			list_del_init(&ap_msg->list);
+			aq->pendingq_count--;
+			ap_msg->receive(aq, ap_msg, aq->reply);
+			break;
+		}
+	case AP_RESPONSE_NO_PENDING_REPLY:
+		if (!status.queue_empty || aq->queue_count <= 0)
+			break;
+		/* The card shouldn't forget requests but who knows. */
+		aq->queue_count = 0;
+		list_splice_init(&aq->pendingq, &aq->requestq);
+		aq->requestq_count += aq->pendingq_count;
+		aq->pendingq_count = 0;
+		break;
+	default:
+		break;
+	}
+	return status;
+}
+
+/**
+ * ap_sm_read(): Receive pending reply messages from an AP queue.
+ * @aq: pointer to the AP queue
+ *
+ * Returns AP_WAIT_NONE, AP_WAIT_AGAIN, or AP_WAIT_INTERRUPT
+ */
+static enum ap_wait ap_sm_read(struct ap_queue *aq)
+{
+	struct ap_queue_status status;
+
+	if (!aq->reply)
+		return AP_WAIT_NONE;
+	status = ap_sm_recv(aq);
+	switch (status.response_code) {
+	case AP_RESPONSE_NORMAL:
+		if (aq->queue_count > 0) {
+			aq->state = AP_STATE_WORKING;
+			return AP_WAIT_AGAIN;
+		}
+		aq->state = AP_STATE_IDLE;
+		return AP_WAIT_NONE;
+	case AP_RESPONSE_NO_PENDING_REPLY:
+		if (aq->queue_count > 0)
+			return AP_WAIT_INTERRUPT;
+		aq->state = AP_STATE_IDLE;
+		return AP_WAIT_NONE;
+	default:
+		aq->state = AP_STATE_BORKED;
+		return AP_WAIT_NONE;
+	}
+}
+
+/**
+ * ap_sm_suspend_read(): Receive pending reply messages from an AP queue
+ * without changing the device state in between. In suspend mode we don't
+ * allow sending new requests, therefore just fetch pending replies.
+ * @aq: pointer to the AP queue
+ *
+ * Returns AP_WAIT_NONE or AP_WAIT_AGAIN
+ */
+static enum ap_wait ap_sm_suspend_read(struct ap_queue *aq)
+{
+	struct ap_queue_status status;
+
+	if (!aq->reply)
+		return AP_WAIT_NONE;
+	status = ap_sm_recv(aq);
+	switch (status.response_code) {
+	case AP_RESPONSE_NORMAL:
+		if (aq->queue_count > 0)
+			return AP_WAIT_AGAIN;
+		/* fall through */
+	default:
+		return AP_WAIT_NONE;
+	}
+}
+
+/**
+ * ap_sm_write(): Send messages from the request queue to an AP queue.
+ * @aq: pointer to the AP queue
+ *
+ * Returns AP_WAIT_NONE, AP_WAIT_AGAIN, or AP_WAIT_INTERRUPT
+ */
+static enum ap_wait ap_sm_write(struct ap_queue *aq)
+{
+	struct ap_queue_status status;
+	struct ap_message *ap_msg;
+
+	if (aq->requestq_count <= 0)
+		return AP_WAIT_NONE;
+	/* Start the next request on the queue. */
+	ap_msg = list_entry(aq->requestq.next, struct ap_message, list);
+	status = __ap_send(aq->qid, ap_msg->psmid,
+			   ap_msg->message, ap_msg->length, ap_msg->special);
+	switch (status.response_code) {
+	case AP_RESPONSE_NORMAL:
+		aq->queue_count++;
+		if (aq->queue_count == 1)
+			mod_timer(&aq->timeout, jiffies + aq->request_timeout);
+		list_move_tail(&ap_msg->list, &aq->pendingq);
+		aq->requestq_count--;
+		aq->pendingq_count++;
+		if (aq->queue_count < aq->card->queue_depth) {
+			aq->state = AP_STATE_WORKING;
+			return AP_WAIT_AGAIN;
+		}
+		/* fall through */
+	case AP_RESPONSE_Q_FULL:
+		aq->state = AP_STATE_QUEUE_FULL;
+		return AP_WAIT_INTERRUPT;
+	case AP_RESPONSE_RESET_IN_PROGRESS:
+		aq->state = AP_STATE_RESET_WAIT;
+		return AP_WAIT_TIMEOUT;
+	case AP_RESPONSE_MESSAGE_TOO_BIG:
+	case AP_RESPONSE_REQ_FAC_NOT_INST:
+		list_del_init(&ap_msg->list);
+		aq->requestq_count--;
+		ap_msg->rc = -EINVAL;
+		ap_msg->receive(aq, ap_msg, NULL);
+		return AP_WAIT_AGAIN;
+	default:
+		aq->state = AP_STATE_BORKED;
+		return AP_WAIT_NONE;
+	}
+}
+
+/**
+ * ap_sm_read_write(): Send and receive messages to/from an AP queue.
+ * @aq: pointer to the AP queue
+ *
+ * Returns AP_WAIT_NONE, AP_WAIT_AGAIN, or AP_WAIT_INTERRUPT
+ */
+static enum ap_wait ap_sm_read_write(struct ap_queue *aq)
+{
+	return min(ap_sm_read(aq), ap_sm_write(aq));
+}
+
+/**
+ * ap_sm_reset(): Reset an AP queue.
+ * @qid: The AP queue number
+ *
+ * Submit the Reset command to an AP queue.
+ */
+static enum ap_wait ap_sm_reset(struct ap_queue *aq)
+{
+	struct ap_queue_status status;
+
+	status = ap_rapq(aq->qid);
+	switch (status.response_code) {
+	case AP_RESPONSE_NORMAL:
+	case AP_RESPONSE_RESET_IN_PROGRESS:
+		aq->state = AP_STATE_RESET_WAIT;
+		aq->interrupt = AP_INTR_DISABLED;
+		return AP_WAIT_TIMEOUT;
+	case AP_RESPONSE_BUSY:
+		return AP_WAIT_TIMEOUT;
+	case AP_RESPONSE_Q_NOT_AVAIL:
+	case AP_RESPONSE_DECONFIGURED:
+	case AP_RESPONSE_CHECKSTOPPED:
+	default:
+		aq->state = AP_STATE_BORKED;
+		return AP_WAIT_NONE;
+	}
+}
+
+/**
+ * ap_sm_reset_wait(): Test queue for completion of the reset operation
+ * @aq: pointer to the AP queue
+ *
+ * Returns AP_POLL_IMMEDIATELY, AP_POLL_AFTER_TIMEROUT or 0.
+ */
+static enum ap_wait ap_sm_reset_wait(struct ap_queue *aq)
+{
+	struct ap_queue_status status;
+	void *lsi_ptr;
+
+	if (aq->queue_count > 0 && aq->reply)
+		/* Try to read a completed message and get the status */
+		status = ap_sm_recv(aq);
+	else
+		/* Get the status with TAPQ */
+		status = ap_tapq(aq->qid, NULL);
+
+	switch (status.response_code) {
+	case AP_RESPONSE_NORMAL:
+		lsi_ptr = ap_airq_ptr();
+		if (lsi_ptr && ap_queue_enable_interruption(aq, lsi_ptr) == 0)
+			aq->state = AP_STATE_SETIRQ_WAIT;
+		else
+			aq->state = (aq->queue_count > 0) ?
+				AP_STATE_WORKING : AP_STATE_IDLE;
+		return AP_WAIT_AGAIN;
+	case AP_RESPONSE_BUSY:
+	case AP_RESPONSE_RESET_IN_PROGRESS:
+		return AP_WAIT_TIMEOUT;
+	case AP_RESPONSE_Q_NOT_AVAIL:
+	case AP_RESPONSE_DECONFIGURED:
+	case AP_RESPONSE_CHECKSTOPPED:
+	default:
+		aq->state = AP_STATE_BORKED;
+		return AP_WAIT_NONE;
+	}
+}
+
+/**
+ * ap_sm_setirq_wait(): Test queue for completion of the irq enablement
+ * @aq: pointer to the AP queue
+ *
+ * Returns AP_POLL_IMMEDIATELY, AP_POLL_AFTER_TIMEROUT or 0.
+ */
+static enum ap_wait ap_sm_setirq_wait(struct ap_queue *aq)
+{
+	struct ap_queue_status status;
+
+	if (aq->queue_count > 0 && aq->reply)
+		/* Try to read a completed message and get the status */
+		status = ap_sm_recv(aq);
+	else
+		/* Get the status with TAPQ */
+		status = ap_tapq(aq->qid, NULL);
+
+	if (status.int_enabled == 1) {
+		/* Irqs are now enabled */
+		aq->interrupt = AP_INTR_ENABLED;
+		aq->state = (aq->queue_count > 0) ?
+			AP_STATE_WORKING : AP_STATE_IDLE;
+	}
+
+	switch (status.response_code) {
+	case AP_RESPONSE_NORMAL:
+		if (aq->queue_count > 0)
+			return AP_WAIT_AGAIN;
+		/* fallthrough */
+	case AP_RESPONSE_NO_PENDING_REPLY:
+		return AP_WAIT_TIMEOUT;
+	default:
+		aq->state = AP_STATE_BORKED;
+		return AP_WAIT_NONE;
+	}
+}
+
+/*
+ * AP state machine jump table
+ */
+static ap_func_t *ap_jumptable[NR_AP_STATES][NR_AP_EVENTS] = {
+	[AP_STATE_RESET_START] = {
+		[AP_EVENT_POLL] = ap_sm_reset,
+		[AP_EVENT_TIMEOUT] = ap_sm_nop,
+	},
+	[AP_STATE_RESET_WAIT] = {
+		[AP_EVENT_POLL] = ap_sm_reset_wait,
+		[AP_EVENT_TIMEOUT] = ap_sm_nop,
+	},
+	[AP_STATE_SETIRQ_WAIT] = {
+		[AP_EVENT_POLL] = ap_sm_setirq_wait,
+		[AP_EVENT_TIMEOUT] = ap_sm_nop,
+	},
+	[AP_STATE_IDLE] = {
+		[AP_EVENT_POLL] = ap_sm_write,
+		[AP_EVENT_TIMEOUT] = ap_sm_nop,
+	},
+	[AP_STATE_WORKING] = {
+		[AP_EVENT_POLL] = ap_sm_read_write,
+		[AP_EVENT_TIMEOUT] = ap_sm_reset,
+	},
+	[AP_STATE_QUEUE_FULL] = {
+		[AP_EVENT_POLL] = ap_sm_read,
+		[AP_EVENT_TIMEOUT] = ap_sm_reset,
+	},
+	[AP_STATE_SUSPEND_WAIT] = {
+		[AP_EVENT_POLL] = ap_sm_suspend_read,
+		[AP_EVENT_TIMEOUT] = ap_sm_nop,
+	},
+	[AP_STATE_BORKED] = {
+		[AP_EVENT_POLL] = ap_sm_nop,
+		[AP_EVENT_TIMEOUT] = ap_sm_nop,
+	},
+};
+
+enum ap_wait ap_sm_event(struct ap_queue *aq, enum ap_event event)
+{
+	return ap_jumptable[aq->state][event](aq);
+}
+
+enum ap_wait ap_sm_event_loop(struct ap_queue *aq, enum ap_event event)
+{
+	enum ap_wait wait;
+
+	while ((wait = ap_sm_event(aq, event)) == AP_WAIT_AGAIN)
+		;
+	return wait;
+}
+
+/*
+ * Power management for queue devices
+ */
+void ap_queue_suspend(struct ap_device *ap_dev)
+{
+	struct ap_queue *aq = to_ap_queue(&ap_dev->device);
+
+	/* Poll on the device until all requests are finished. */
+	spin_lock_bh(&aq->lock);
+	aq->state = AP_STATE_SUSPEND_WAIT;
+	while (ap_sm_event(aq, AP_EVENT_POLL) != AP_WAIT_NONE)
+		;
+	aq->state = AP_STATE_BORKED;
+	spin_unlock_bh(&aq->lock);
+}
+EXPORT_SYMBOL(ap_queue_suspend);
+
+void ap_queue_resume(struct ap_device *ap_dev)
+{
+}
+EXPORT_SYMBOL(ap_queue_resume);
+
+/*
+ * AP queue related attributes.
+ */
+static ssize_t ap_request_count_show(struct device *dev,
+				     struct device_attribute *attr,
+				     char *buf)
+{
+	struct ap_queue *aq = to_ap_queue(dev);
+	unsigned int req_cnt;
+
+	spin_lock_bh(&aq->lock);
+	req_cnt = aq->total_request_count;
+	spin_unlock_bh(&aq->lock);
+	return snprintf(buf, PAGE_SIZE, "%d\n", req_cnt);
+}
+
+static DEVICE_ATTR(request_count, 0444, ap_request_count_show, NULL);
+
+static ssize_t ap_requestq_count_show(struct device *dev,
+				      struct device_attribute *attr, char *buf)
+{
+	struct ap_queue *aq = to_ap_queue(dev);
+	unsigned int reqq_cnt = 0;
+
+	spin_lock_bh(&aq->lock);
+	reqq_cnt = aq->requestq_count;
+	spin_unlock_bh(&aq->lock);
+	return snprintf(buf, PAGE_SIZE, "%d\n", reqq_cnt);
+}
+
+static DEVICE_ATTR(requestq_count, 0444, ap_requestq_count_show, NULL);
+
+static ssize_t ap_pendingq_count_show(struct device *dev,
+				      struct device_attribute *attr, char *buf)
+{
+	struct ap_queue *aq = to_ap_queue(dev);
+	unsigned int penq_cnt = 0;
+
+	spin_lock_bh(&aq->lock);
+	penq_cnt = aq->pendingq_count;
+	spin_unlock_bh(&aq->lock);
+	return snprintf(buf, PAGE_SIZE, "%d\n", penq_cnt);
+}
+
+static DEVICE_ATTR(pendingq_count, 0444, ap_pendingq_count_show, NULL);
+
+static ssize_t ap_reset_show(struct device *dev,
+				      struct device_attribute *attr, char *buf)
+{
+	struct ap_queue *aq = to_ap_queue(dev);
+	int rc = 0;
+
+	spin_lock_bh(&aq->lock);
+	switch (aq->state) {
+	case AP_STATE_RESET_START:
+	case AP_STATE_RESET_WAIT:
+		rc = snprintf(buf, PAGE_SIZE, "Reset in progress.\n");
+		break;
+	case AP_STATE_WORKING:
+	case AP_STATE_QUEUE_FULL:
+		rc = snprintf(buf, PAGE_SIZE, "Reset Timer armed.\n");
+		break;
+	default:
+		rc = snprintf(buf, PAGE_SIZE, "No Reset Timer set.\n");
+	}
+	spin_unlock_bh(&aq->lock);
+	return rc;
+}
+
+static DEVICE_ATTR(reset, 0444, ap_reset_show, NULL);
+
+static ssize_t ap_interrupt_show(struct device *dev,
+				 struct device_attribute *attr, char *buf)
+{
+	struct ap_queue *aq = to_ap_queue(dev);
+	int rc = 0;
+
+	spin_lock_bh(&aq->lock);
+	if (aq->state == AP_STATE_SETIRQ_WAIT)
+		rc = snprintf(buf, PAGE_SIZE, "Enable Interrupt pending.\n");
+	else if (aq->interrupt == AP_INTR_ENABLED)
+		rc = snprintf(buf, PAGE_SIZE, "Interrupts enabled.\n");
+	else
+		rc = snprintf(buf, PAGE_SIZE, "Interrupts disabled.\n");
+	spin_unlock_bh(&aq->lock);
+	return rc;
+}
+
+static DEVICE_ATTR(interrupt, 0444, ap_interrupt_show, NULL);
+
+static struct attribute *ap_queue_dev_attrs[] = {
+	&dev_attr_request_count.attr,
+	&dev_attr_requestq_count.attr,
+	&dev_attr_pendingq_count.attr,
+	&dev_attr_reset.attr,
+	&dev_attr_interrupt.attr,
+	NULL
+};
+
+static struct attribute_group ap_queue_dev_attr_group = {
+	.attrs = ap_queue_dev_attrs
+};
+
+static const struct attribute_group *ap_queue_dev_attr_groups[] = {
+	&ap_queue_dev_attr_group,
+	NULL
+};
+
+struct device_type ap_queue_type = {
+	.name = "ap_queue",
+	.groups = ap_queue_dev_attr_groups,
+};
+
+static void ap_queue_device_release(struct device *dev)
+{
+	kfree(to_ap_queue(dev));
+}
+
+struct ap_queue *ap_queue_create(ap_qid_t qid, int device_type)
+{
+	struct ap_queue *aq;
+
+	aq = kzalloc(sizeof(*aq), GFP_KERNEL);
+	if (!aq)
+		return NULL;
+	aq->ap_dev.device.release = ap_queue_device_release;
+	aq->ap_dev.device.type = &ap_queue_type;
+	aq->ap_dev.device_type = device_type;
+	/* CEX6 toleration: map to CEX5 */
+	if (device_type == AP_DEVICE_TYPE_CEX6)
+		aq->ap_dev.device_type = AP_DEVICE_TYPE_CEX5;
+	aq->qid = qid;
+	aq->state = AP_STATE_RESET_START;
+	aq->interrupt = AP_INTR_DISABLED;
+	spin_lock_init(&aq->lock);
+	INIT_LIST_HEAD(&aq->pendingq);
+	INIT_LIST_HEAD(&aq->requestq);
+	setup_timer(&aq->timeout, ap_request_timeout, (unsigned long) aq);
+
+	return aq;
+}
+
+void ap_queue_init_reply(struct ap_queue *aq, struct ap_message *reply)
+{
+	aq->reply = reply;
+
+	spin_lock_bh(&aq->lock);
+	ap_wait(ap_sm_event(aq, AP_EVENT_POLL));
+	spin_unlock_bh(&aq->lock);
+}
+EXPORT_SYMBOL(ap_queue_init_reply);
+
+/**
+ * ap_queue_message(): Queue a request to an AP device.
+ * @aq: The AP device to queue the message to
+ * @ap_msg: The message that is to be added
+ */
+void ap_queue_message(struct ap_queue *aq, struct ap_message *ap_msg)
+{
+	/* For asynchronous message handling a valid receive-callback
+	 * is required.
+	 */
+	BUG_ON(!ap_msg->receive);
+
+	spin_lock_bh(&aq->lock);
+	/* Queue the message. */
+	list_add_tail(&ap_msg->list, &aq->requestq);
+	aq->requestq_count++;
+	aq->total_request_count++;
+	/* Send/receive as many request from the queue as possible. */
+	ap_wait(ap_sm_event_loop(aq, AP_EVENT_POLL));
+	spin_unlock_bh(&aq->lock);
+}
+EXPORT_SYMBOL(ap_queue_message);
+
+/**
+ * ap_cancel_message(): Cancel a crypto request.
+ * @aq: The AP device that has the message queued
+ * @ap_msg: The message that is to be removed
+ *
+ * Cancel a crypto request. This is done by removing the request
+ * from the device pending or request queue. Note that the
+ * request stays on the AP queue. When it finishes the message
+ * reply will be discarded because the psmid can't be found.
+ */
+void ap_cancel_message(struct ap_queue *aq, struct ap_message *ap_msg)
+{
+	struct ap_message *tmp;
+
+	spin_lock_bh(&aq->lock);
+	if (!list_empty(&ap_msg->list)) {
+		list_for_each_entry(tmp, &aq->pendingq, list)
+			if (tmp->psmid == ap_msg->psmid) {
+				aq->pendingq_count--;
+				goto found;
+			}
+		aq->requestq_count--;
+found:
+		list_del_init(&ap_msg->list);
+	}
+	spin_unlock_bh(&aq->lock);
+}
+EXPORT_SYMBOL(ap_cancel_message);
+
+/**
+ * __ap_flush_queue(): Flush requests.
+ * @aq: Pointer to the AP queue
+ *
+ * Flush all requests from the request/pending queue of an AP device.
+ */
+static void __ap_flush_queue(struct ap_queue *aq)
+{
+	struct ap_message *ap_msg, *next;
+
+	list_for_each_entry_safe(ap_msg, next, &aq->pendingq, list) {
+		list_del_init(&ap_msg->list);
+		aq->pendingq_count--;
+		ap_msg->rc = -EAGAIN;
+		ap_msg->receive(aq, ap_msg, NULL);
+	}
+	list_for_each_entry_safe(ap_msg, next, &aq->requestq, list) {
+		list_del_init(&ap_msg->list);
+		aq->requestq_count--;
+		ap_msg->rc = -EAGAIN;
+		ap_msg->receive(aq, ap_msg, NULL);
+	}
+}
+
+void ap_flush_queue(struct ap_queue *aq)
+{
+	spin_lock_bh(&aq->lock);
+	__ap_flush_queue(aq);
+	spin_unlock_bh(&aq->lock);
+}
+EXPORT_SYMBOL(ap_flush_queue);
+
+void ap_queue_remove(struct ap_queue *aq)
+{
+	ap_flush_queue(aq);
+	del_timer_sync(&aq->timeout);
+}
+EXPORT_SYMBOL(ap_queue_remove);
* Unmerged path drivers/s390/crypto/zcrypt_api.c
* Unmerged path drivers/s390/crypto/zcrypt_api.h
diff --git a/drivers/s390/crypto/zcrypt_card.c b/drivers/s390/crypto/zcrypt_card.c
new file mode 100644
index 000000000000..57873d775e95
--- /dev/null
+++ b/drivers/s390/crypto/zcrypt_card.c
@@ -0,0 +1,181 @@
+/*
+ *  zcrypt 2.1.0
+ *
+ *  Copyright IBM Corp. 2001, 2012
+ *  Author(s): Robert Burroughs
+ *	       Eric Rossman (edrossma@us.ibm.com)
+ *	       Cornelia Huck <cornelia.huck@de.ibm.com>
+ *
+ *  Hotplug & misc device support: Jochen Roehrig (roehrig@de.ibm.com)
+ *  Major cleanup & driver split: Martin Schwidefsky <schwidefsky@de.ibm.com>
+ *				  Ralph Wuerthner <rwuerthn@de.ibm.com>
+ *  MSGTYPE restruct:		  Holger Dengler <hd@linux.vnet.ibm.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/miscdevice.h>
+#include <linux/fs.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/compat.h>
+#include <linux/slab.h>
+#include <linux/atomic.h>
+#include <linux/uaccess.h>
+#include <linux/hw_random.h>
+#include <linux/debugfs.h>
+#include <asm/debug.h>
+
+#include "zcrypt_debug.h"
+#include "zcrypt_api.h"
+
+#include "zcrypt_msgtype6.h"
+#include "zcrypt_msgtype50.h"
+
+/*
+ * Device attributes common for all crypto card devices.
+ */
+
+static ssize_t zcrypt_card_type_show(struct device *dev,
+				     struct device_attribute *attr, char *buf)
+{
+	struct zcrypt_card *zc = to_ap_card(dev)->private;
+
+	return snprintf(buf, PAGE_SIZE, "%s\n", zc->type_string);
+}
+
+static DEVICE_ATTR(type, 0444, zcrypt_card_type_show, NULL);
+
+static ssize_t zcrypt_card_online_show(struct device *dev,
+				       struct device_attribute *attr,
+				       char *buf)
+{
+	struct zcrypt_card *zc = to_ap_card(dev)->private;
+
+	return snprintf(buf, PAGE_SIZE, "%d\n", zc->online);
+}
+
+static ssize_t zcrypt_card_online_store(struct device *dev,
+					struct device_attribute *attr,
+					const char *buf, size_t count)
+{
+	struct zcrypt_card *zc = to_ap_card(dev)->private;
+	struct zcrypt_queue *zq;
+	int online, id;
+
+	if (sscanf(buf, "%d\n", &online) != 1 || online < 0 || online > 1)
+		return -EINVAL;
+
+	zc->online = online;
+	id = zc->card->id;
+	ZCRYPT_DBF_DEV(DBF_INFO, zc, "card%02xo%dman", id, online);
+	spin_lock(&zcrypt_list_lock);
+	list_for_each_entry(zq, &zc->zqueues, list)
+		zcrypt_queue_force_online(zq, online);
+	spin_unlock(&zcrypt_list_lock);
+	return count;
+}
+
+static DEVICE_ATTR(online, 0644, zcrypt_card_online_show,
+		   zcrypt_card_online_store);
+
+static struct attribute *zcrypt_card_attrs[] = {
+	&dev_attr_type.attr,
+	&dev_attr_online.attr,
+	NULL,
+};
+
+static struct attribute_group zcrypt_card_attr_group = {
+	.attrs = zcrypt_card_attrs,
+};
+
+struct zcrypt_card *zcrypt_card_alloc(void)
+{
+	struct zcrypt_card *zc;
+
+	zc = kzalloc(sizeof(struct zcrypt_card), GFP_KERNEL);
+	if (!zc)
+		return NULL;
+	INIT_LIST_HEAD(&zc->list);
+	INIT_LIST_HEAD(&zc->zqueues);
+	zc->dbf_area = zcrypt_dbf_cards;
+	kref_init(&zc->refcount);
+	return zc;
+}
+EXPORT_SYMBOL(zcrypt_card_alloc);
+
+void zcrypt_card_free(struct zcrypt_card *zc)
+{
+	kfree(zc);
+}
+EXPORT_SYMBOL(zcrypt_card_free);
+
+static void zcrypt_card_release(struct kref *kref)
+{
+	struct zcrypt_card *zdev =
+		container_of(kref, struct zcrypt_card, refcount);
+	zcrypt_card_free(zdev);
+}
+
+void zcrypt_card_get(struct zcrypt_card *zc)
+{
+	kref_get(&zc->refcount);
+}
+EXPORT_SYMBOL(zcrypt_card_get);
+
+int zcrypt_card_put(struct zcrypt_card *zc)
+{
+	return kref_put(&zc->refcount, zcrypt_card_release);
+}
+EXPORT_SYMBOL(zcrypt_card_put);
+
+/**
+ * zcrypt_card_register() - Register a crypto card device.
+ * @zc: Pointer to a crypto card device
+ *
+ * Register a crypto card device. Returns 0 if successful.
+ */
+int zcrypt_card_register(struct zcrypt_card *zc)
+{
+	int rc;
+
+	rc = sysfs_create_group(&zc->card->ap_dev.device.kobj,
+				&zcrypt_card_attr_group);
+	if (rc)
+		return rc;
+
+	spin_lock(&zcrypt_list_lock);
+	list_add_tail(&zc->list, &zcrypt_card_list);
+	spin_unlock(&zcrypt_list_lock);
+
+	zc->online = 1;
+	return rc;
+}
+EXPORT_SYMBOL(zcrypt_card_register);
+
+/**
+ * zcrypt_card_unregister(): Unregister a crypto card device.
+ * @zc: Pointer to crypto card device
+ *
+ * Unregister a crypto card device.
+ */
+void zcrypt_card_unregister(struct zcrypt_card *zc)
+{
+	spin_lock(&zcrypt_list_lock);
+	list_del_init(&zc->list);
+	spin_unlock(&zcrypt_list_lock);
+	sysfs_remove_group(&zc->card->ap_dev.device.kobj,
+			   &zcrypt_card_attr_group);
+}
+EXPORT_SYMBOL(zcrypt_card_unregister);
* Unmerged path drivers/s390/crypto/zcrypt_cex2a.c
* Unmerged path drivers/s390/crypto/zcrypt_cex4.c
diff --git a/drivers/s390/crypto/zcrypt_error.h b/drivers/s390/crypto/zcrypt_error.h
index a9c4d2d160af..865978879661 100644
--- a/drivers/s390/crypto/zcrypt_error.h
+++ b/drivers/s390/crypto/zcrypt_error.h
@@ -89,7 +89,7 @@ struct error_hdr {
 #define REP88_ERROR_OPERAND		    0x84 /* CEX2A	*/
 #define REP88_ERROR_OPERAND_EVEN_MOD	    0x85 /* CEX2A	*/
 
-static inline int convert_error(struct zcrypt_device *zdev,
+static inline int convert_error(struct zcrypt_queue *zq,
 				struct ap_message *reply)
 {
 	struct error_hdr *ehdr = reply->message;
@@ -114,11 +114,13 @@ static inline int convert_error(struct zcrypt_device *zdev,
 		 * and then repeat the request.
 		 */
 		atomic_set(&zcrypt_rescan_req, 1);
-		zdev->online = 0;
-		pr_err("Cryptographic device %x failed and was set offline\n",
-		       AP_QID_DEVICE(zdev->ap_dev->qid));
-		ZCRYPT_DBF_DEV(DBF_ERR, zdev, "dev%04xo%drc%d",
-			AP_QID_DEVICE(zdev->ap_dev->qid), zdev->online,
+		zq->online = 0;
+		pr_err("Cryptographic device %02x.%04x failed and was set offline\n",
+		       AP_QID_CARD(zq->queue->qid),
+		       AP_QID_QUEUE(zq->queue->qid));
+		ZCRYPT_DBF_DEV(DBF_ERR, zq, "dev%02x%04xo%drc%d",
+			AP_QID_CARD(zq->queue->qid),
+			AP_QID_QUEUE(zq->queue->qid), zq->online,
 			ehdr->reply_code);
 		return -EAGAIN;
 	case REP82_ERROR_TRANSPORT_FAIL:
@@ -126,19 +128,23 @@ static inline int convert_error(struct zcrypt_device *zdev,
 	//   REP88_ERROR_MODULE_FAILURE		// '10' CEX2A
 		/* If a card fails disable it and repeat the request. */
 		atomic_set(&zcrypt_rescan_req, 1);
-		zdev->online = 0;
-		pr_err("Cryptographic device %x failed and was set offline\n",
-		       AP_QID_DEVICE(zdev->ap_dev->qid));
-		ZCRYPT_DBF_DEV(DBF_ERR, zdev, "dev%04xo%drc%d",
-			AP_QID_DEVICE(zdev->ap_dev->qid), zdev->online,
+		zq->online = 0;
+		pr_err("Cryptographic device %02x.%04x failed and was set offline\n",
+		       AP_QID_CARD(zq->queue->qid),
+		       AP_QID_QUEUE(zq->queue->qid));
+		ZCRYPT_DBF_DEV(DBF_ERR, zq, "dev%02x%04xo%drc%d",
+			AP_QID_CARD(zq->queue->qid),
+			AP_QID_QUEUE(zq->queue->qid), zq->online,
 			ehdr->reply_code);
 		return -EAGAIN;
 	default:
-		zdev->online = 0;
-		pr_err("Cryptographic device %x failed and was set offline\n",
-		       AP_QID_DEVICE(zdev->ap_dev->qid));
-		ZCRYPT_DBF_DEV(DBF_ERR, zdev, "dev%04xo%drc%d",
-			AP_QID_DEVICE(zdev->ap_dev->qid), zdev->online,
+		zq->online = 0;
+		pr_err("Cryptographic device %02x.%04x failed and was set offline\n",
+		       AP_QID_CARD(zq->queue->qid),
+		       AP_QID_QUEUE(zq->queue->qid));
+		ZCRYPT_DBF_DEV(DBF_ERR, zq, "dev%02x%04xo%drc%d",
+			AP_QID_CARD(zq->queue->qid),
+			AP_QID_QUEUE(zq->queue->qid), zq->online,
 			ehdr->reply_code);
 		return -EAGAIN;	/* repeat the request on a different device. */
 	}
* Unmerged path drivers/s390/crypto/zcrypt_msgtype50.c
* Unmerged path drivers/s390/crypto/zcrypt_msgtype6.c
* Unmerged path drivers/s390/crypto/zcrypt_msgtype6.h
* Unmerged path drivers/s390/crypto/zcrypt_pcixcc.c
diff --git a/drivers/s390/crypto/zcrypt_queue.c b/drivers/s390/crypto/zcrypt_queue.c
new file mode 100644
index 000000000000..c70b2528d9a3
--- /dev/null
+++ b/drivers/s390/crypto/zcrypt_queue.c
@@ -0,0 +1,221 @@
+/*
+ *  zcrypt 2.1.0
+ *
+ *  Copyright IBM Corp. 2001, 2012
+ *  Author(s): Robert Burroughs
+ *	       Eric Rossman (edrossma@us.ibm.com)
+ *	       Cornelia Huck <cornelia.huck@de.ibm.com>
+ *
+ *  Hotplug & misc device support: Jochen Roehrig (roehrig@de.ibm.com)
+ *  Major cleanup & driver split: Martin Schwidefsky <schwidefsky@de.ibm.com>
+ *				  Ralph Wuerthner <rwuerthn@de.ibm.com>
+ *  MSGTYPE restruct:		  Holger Dengler <hd@linux.vnet.ibm.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/miscdevice.h>
+#include <linux/fs.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/compat.h>
+#include <linux/slab.h>
+#include <linux/atomic.h>
+#include <linux/uaccess.h>
+#include <linux/hw_random.h>
+#include <linux/debugfs.h>
+#include <asm/debug.h>
+
+#include "zcrypt_debug.h"
+#include "zcrypt_api.h"
+
+#include "zcrypt_msgtype6.h"
+#include "zcrypt_msgtype50.h"
+
+/*
+ * Device attributes common for all crypto queue devices.
+ */
+
+static ssize_t zcrypt_queue_online_show(struct device *dev,
+					struct device_attribute *attr,
+					char *buf)
+{
+	struct zcrypt_queue *zq = to_ap_queue(dev)->private;
+
+	return snprintf(buf, PAGE_SIZE, "%d\n", zq->online);
+}
+
+static ssize_t zcrypt_queue_online_store(struct device *dev,
+					 struct device_attribute *attr,
+					 const char *buf, size_t count)
+{
+	struct zcrypt_queue *zq = to_ap_queue(dev)->private;
+	struct zcrypt_card *zc = zq->zcard;
+	int online;
+
+	if (sscanf(buf, "%d\n", &online) != 1 || online < 0 || online > 1)
+		return -EINVAL;
+
+	if (online && !zc->online)
+		return -EINVAL;
+	zq->online = online;
+	ZCRYPT_DBF_DEV(DBF_INFO, zq, "dev%02x%04xo%dman",
+		       AP_QID_CARD(zq->queue->qid),
+		       AP_QID_QUEUE(zq->queue->qid), online);
+	if (!online)
+		ap_flush_queue(zq->queue);
+	return count;
+}
+
+static DEVICE_ATTR(online, 0644, zcrypt_queue_online_show,
+		   zcrypt_queue_online_store);
+
+static struct attribute *zcrypt_queue_attrs[] = {
+	&dev_attr_online.attr,
+	NULL,
+};
+
+static struct attribute_group zcrypt_queue_attr_group = {
+	.attrs = zcrypt_queue_attrs,
+};
+
+void zcrypt_queue_force_online(struct zcrypt_queue *zq, int online)
+{
+	zq->online = online;
+	if (!online)
+		ap_flush_queue(zq->queue);
+}
+
+struct zcrypt_queue *zcrypt_queue_alloc(size_t max_response_size)
+{
+	struct zcrypt_queue *zq;
+
+	zq = kzalloc(sizeof(struct zcrypt_queue), GFP_KERNEL);
+	if (!zq)
+		return NULL;
+	zq->reply.message = kmalloc(max_response_size, GFP_KERNEL);
+	if (!zq->reply.message)
+		goto out_free;
+	zq->reply.length = max_response_size;
+	INIT_LIST_HEAD(&zq->list);
+	zq->dbf_area = zcrypt_dbf_devices;
+	kref_init(&zq->refcount);
+	return zq;
+
+out_free:
+	kfree(zq);
+	return NULL;
+}
+EXPORT_SYMBOL(zcrypt_queue_alloc);
+
+void zcrypt_queue_free(struct zcrypt_queue *zq)
+{
+	kfree(zq->reply.message);
+	kfree(zq);
+}
+EXPORT_SYMBOL(zcrypt_queue_free);
+
+static void zcrypt_queue_release(struct kref *kref)
+{
+	struct zcrypt_queue *zq =
+		container_of(kref, struct zcrypt_queue, refcount);
+	zcrypt_queue_free(zq);
+}
+
+void zcrypt_queue_get(struct zcrypt_queue *zq)
+{
+	kref_get(&zq->refcount);
+}
+EXPORT_SYMBOL(zcrypt_queue_get);
+
+int zcrypt_queue_put(struct zcrypt_queue *zq)
+{
+	return kref_put(&zq->refcount, zcrypt_queue_release);
+}
+EXPORT_SYMBOL(zcrypt_queue_put);
+
+/**
+ * zcrypt_queue_register() - Register a crypto queue device.
+ * @zq: Pointer to a crypto queue device
+ *
+ * Register a crypto queue device. Returns 0 if successful.
+ */
+int zcrypt_queue_register(struct zcrypt_queue *zq)
+{
+	struct zcrypt_card *zc;
+	int rc;
+
+	spin_lock(&zcrypt_list_lock);
+	zc = zq->queue->card->private;
+	zcrypt_card_get(zc);
+	zq->zcard = zc;
+	zq->online = 1;	/* New devices are online by default. */
+	ZCRYPT_DBF_DEV(DBF_INFO, zq, "dev%02x%04xo%dreg",
+		       AP_QID_CARD(zq->queue->qid),
+		       AP_QID_QUEUE(zq->queue->qid),
+		       zq->online);
+	list_add_tail(&zq->list, &zc->zqueues);
+	zcrypt_device_count++;
+	spin_unlock(&zcrypt_list_lock);
+
+	rc = sysfs_create_group(&zq->queue->ap_dev.device.kobj,
+				&zcrypt_queue_attr_group);
+	if (rc)
+		goto out;
+	get_device(&zq->queue->ap_dev.device);
+
+	if (zq->ops->rng) {
+		rc = zcrypt_rng_device_add();
+		if (rc)
+			goto out_unregister;
+	}
+	return 0;
+
+out_unregister:
+	sysfs_remove_group(&zq->queue->ap_dev.device.kobj,
+			   &zcrypt_queue_attr_group);
+	put_device(&zq->queue->ap_dev.device);
+out:
+	spin_lock(&zcrypt_list_lock);
+	list_del_init(&zq->list);
+	spin_unlock(&zcrypt_list_lock);
+	zcrypt_card_put(zc);
+	return rc;
+}
+EXPORT_SYMBOL(zcrypt_queue_register);
+
+/**
+ * zcrypt_queue_unregister(): Unregister a crypto queue device.
+ * @zq: Pointer to crypto queue device
+ *
+ * Unregister a crypto queue device.
+ */
+void zcrypt_queue_unregister(struct zcrypt_queue *zq)
+{
+	struct zcrypt_card *zc;
+
+	zc = zq->zcard;
+	spin_lock(&zcrypt_list_lock);
+	list_del_init(&zq->list);
+	zcrypt_device_count--;
+	spin_unlock(&zcrypt_list_lock);
+	zcrypt_card_put(zc);
+	if (zq->ops->rng)
+		zcrypt_rng_device_remove();
+	sysfs_remove_group(&zq->queue->ap_dev.device.kobj,
+			   &zcrypt_queue_attr_group);
+	put_device(&zq->queue->ap_dev.device);
+	zcrypt_queue_put(zq);
+}
+EXPORT_SYMBOL(zcrypt_queue_unregister);
diff --git a/include/linux/mod_devicetable.h b/include/linux/mod_devicetable.h
index 275369eb9eaf..0206a01a941d 100644
--- a/include/linux/mod_devicetable.h
+++ b/include/linux/mod_devicetable.h
@@ -175,7 +175,8 @@ struct ap_device_id {
 	kernel_ulong_t driver_info;
 };
 
-#define AP_DEVICE_ID_MATCH_DEVICE_TYPE		0x01
+#define AP_DEVICE_ID_MATCH_CARD_TYPE		0x01
+#define AP_DEVICE_ID_MATCH_QUEUE_TYPE		0x02
 
 /* s390 css bus devices (subchannels) */
 struct css_device_id {
