seccomp: allow mode setting across threads

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Kees Cook <keescook@chromium.org>
commit 3ba2530cc06eb4aee4f1f754f43d781e8a12ee09
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/3ba2530c.failed

This changes the mode setting helper to allow threads to change the
seccomp mode from another thread. We must maintain barriers to keep
TIF_SECCOMP synchronized with the rest of the seccomp state.

	Signed-off-by: Kees Cook <keescook@chromium.org>
	Reviewed-by: Oleg Nesterov <oleg@redhat.com>
	Reviewed-by: Andy Lutomirski <luto@amacapital.net>
(cherry picked from commit 3ba2530cc06eb4aee4f1f754f43d781e8a12ee09)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/seccomp.c
diff --cc kernel/seccomp.c
index dab81904040f,9065d2c79c56..000000000000
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@@ -201,19 -173,26 +201,38 @@@ static int seccomp_check_filter(struct 
   */
  static u32 seccomp_run_filters(int syscall)
  {
++<<<<<<< HEAD
 +	struct seccomp_filter *f;
++=======
+ 	struct seccomp_filter *f = ACCESS_ONCE(current->seccomp.filter);
+ 	struct seccomp_data sd;
++>>>>>>> 3ba2530cc06e (seccomp: allow mode setting across threads)
  	u32 ret = SECCOMP_RET_ALLOW;
  
  	/* Ensure unexpected behavior doesn't result in failing open. */
- 	if (WARN_ON(current->seccomp.filter == NULL))
+ 	if (unlikely(WARN_ON(f == NULL)))
  		return SECCOMP_RET_KILL;
  
++<<<<<<< HEAD
++=======
+ 	/* Make sure cross-thread synced filter points somewhere sane. */
+ 	smp_read_barrier_depends();
+ 
+ 	populate_seccomp_data(&sd);
+ 
++>>>>>>> 3ba2530cc06e (seccomp: allow mode setting across threads)
  	/*
  	 * All filters in the list are evaluated and the lowest BPF return
  	 * value always takes priority (ignoring the DATA).
  	 */
++<<<<<<< HEAD
 +	for (f = current->seccomp.filter; f; f = f->prev) {
 +		u32 cur_ret = sk_run_filter(NULL, f->insns);
++=======
+ 	for (; f; f = f->prev) {
+ 		u32 cur_ret = SK_RUN_FILTER(f->prog, (void *)&sd);
+ 
++>>>>>>> 3ba2530cc06e (seccomp: allow mode setting across threads)
  		if ((cur_ret & SECCOMP_RET_ACTION) < (ret & SECCOMP_RET_ACTION))
  			ret = cur_ret;
  	}
@@@ -229,10 -210,18 +248,23 @@@ static inline bool seccomp_may_assign_m
  	return true;
  }
  
- static inline void seccomp_assign_mode(unsigned long seccomp_mode)
+ static inline void seccomp_assign_mode(struct task_struct *task,
+ 				       unsigned long seccomp_mode)
  {
++<<<<<<< HEAD
 +	current->seccomp.mode = seccomp_mode;
 +	set_tsk_thread_flag(current, TIF_SECCOMP);
++=======
+ 	BUG_ON(!spin_is_locked(&task->sighand->siglock));
+ 
+ 	task->seccomp.mode = seccomp_mode;
+ 	/*
+ 	 * Make sure TIF_SECCOMP cannot be set before the mode (and
+ 	 * filter) is set.
+ 	 */
+ 	smp_mb__before_atomic();
+ 	set_tsk_thread_flag(task, TIF_SECCOMP);
++>>>>>>> 3ba2530cc06e (seccomp: allow mode setting across threads)
  }
  
  #ifdef CONFIG_SECCOMP_FILTER
@@@ -529,12 -592,27 +566,12 @@@ static long seccomp_set_mode_filter(cha
  	if (!seccomp_may_assign_mode(seccomp_mode))
  		goto out;
  
 -	ret = seccomp_attach_filter(flags, prepared);
 +	ret = seccomp_attach_user_filter(filter);
  	if (ret)
  		goto out;
 -	/* Do not free the successfully attached filter. */
 -	prepared = NULL;
  
- 	seccomp_assign_mode(seccomp_mode);
+ 	seccomp_assign_mode(current, seccomp_mode);
  out:
 -	spin_unlock_irq(&current->sighand->siglock);
 -	seccomp_filter_free(prepared);
  	return ret;
  }
  #else
* Unmerged path kernel/seccomp.c
