scsi: cxlflash: Combine the send queue locks

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [scsi] cxlflash: Combine the send queue locks (Gustavo Duarte) [1456494]
Rebuild_FUZZ: 92.68%
commit-author Uma Krishnan <ukrishn@linux.vnet.ibm.com>
commit 66ea9bcc392017b6df465b6f5847f6eac966a801
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/66ea9bcc.failed

Currently there are separate spin locks for the two supported I/O queueing
models. This makes it difficult to serialize with paths outside the enqueue
path.

As a design simplification and to support serialization with enqueue
operations, move to only a single lock that is used for enqueueing
regardless of the queueing model.

	Signed-off-by: Uma Krishnan <ukrishn@linux.vnet.ibm.com>
	Acked-by: Matthew R. Ochs <mrochs@linux.vnet.ibm.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit 66ea9bcc392017b6df465b6f5847f6eac966a801)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/cxlflash/common.h
#	drivers/scsi/cxlflash/main.c
diff --cc drivers/scsi/cxlflash/common.h
index 811927d91c5c,6fc32cfc6026..000000000000
--- a/drivers/scsi/cxlflash/common.h
+++ b/drivers/scsi/cxlflash/common.h
@@@ -158,24 -184,47 +158,49 @@@ struct afu 
  	/* Beware of alignment till here. Preferably introduce new
  	 * fields after this point
  	 */
 -	struct afu *afu;
 -	struct cxl_context *ctx;
 +
 +	/* AFU HW */
  	struct cxl_ioctl_start_work work;
 +	struct cxlflash_afu_map __iomem *afu_map;	/* entire MMIO map */
  	struct sisl_host_map __iomem *host_map;		/* MC host map */
  	struct sisl_ctrl_map __iomem *ctrl_map;		/* MC control map */
 -	ctx_hndl_t ctx_hndl;	/* master's context handle */
 -	u32 index;		/* Index of this hwq */
  
++<<<<<<< HEAD
 +	ctx_hndl_t ctx_hndl;	/* master's context handle */
++=======
+ 	atomic_t hsq_credits;
+ 	spinlock_t hsq_slock;	/* Hardware send queue lock */
+ 	struct sisl_ioarcb *hsq_start;
+ 	struct sisl_ioarcb *hsq_end;
+ 	struct sisl_ioarcb *hsq_curr;
+ 	spinlock_t hrrq_slock;
++>>>>>>> 66ea9bcc3920 (scsi: cxlflash: Combine the send queue locks)
  	u64 *hrrq_start;
  	u64 *hrrq_end;
  	u64 *hrrq_curr;
  	bool toggle;
 -
  	s64 room;
++<<<<<<< HEAD
 +	spinlock_t rrin_slock; /* Lock to rrin queuing and cmd_room updates */
++=======
+ 
+ 	struct irq_poll irqpoll;
+ } __aligned(cache_line_size());
+ 
+ struct afu {
+ 	struct hwq hwqs[CXLFLASH_MAX_HWQS];
+ 	int (*send_cmd)(struct afu *, struct afu_cmd *);
+ 	void (*context_reset)(struct afu_cmd *);
+ 
+ 	/* AFU HW */
+ 	struct cxlflash_afu_map __iomem *afu_map;	/* entire MMIO map */
+ 
+ 	atomic_t cmds_active;	/* Number of currently active AFU commands */
++>>>>>>> 66ea9bcc3920 (scsi: cxlflash: Combine the send queue locks)
  	u64 hb;
 +	u32 cmd_couts;		/* Number of command checkouts */
  	u32 internal_lun;	/* User-desired LUN mode for this AFU */
  
 -	u32 num_hwqs;		/* Number of hardware queues */
 -	u32 desired_hwqs;	/* Desired h/w queues, effective on AFU reset */
 -	enum cxlflash_hwq_mode hwq_mode; /* Steering mode for h/w queues */
 -	u32 hwq_rr_count;	/* Count to distribute traffic for roundrobin */
 -
  	char version[16];
  	u64 interface_version;
  
diff --cc drivers/scsi/cxlflash/main.c
index c68badcfa77f,64ea597ca98e..000000000000
--- a/drivers/scsi/cxlflash/main.c
+++ b/drivers/scsi/cxlflash/main.c
@@@ -313,9 -261,9 +313,15 @@@ static int send_cmd(struct afu *afu, st
  	 * To avoid the performance penalty of MMIO, spread the update of
  	 * 'room' over multiple commands.
  	 */
++<<<<<<< HEAD
 +	spin_lock_irqsave(&afu->rrin_slock, lock_flags);
 +	if (--afu->room < 0) {
 +		room = readq_be(&afu->host_map->cmd_room);
++=======
+ 	spin_lock_irqsave(&hwq->hsq_slock, lock_flags);
+ 	if (--hwq->room < 0) {
+ 		room = readq_be(&hwq->host_map->cmd_room);
++>>>>>>> 66ea9bcc3920 (scsi: cxlflash: Combine the send queue locks)
  		if (room <= 0) {
  			dev_dbg_ratelimited(dev, "%s: no cmd_room to send "
  					    "0x%02X, room=0x%016llX\n",
@@@ -324,14 -272,58 +330,64 @@@
  			rc = SCSI_MLQUEUE_HOST_BUSY;
  			goto out;
  		}
 -		hwq->room = room - 1;
 +		afu->room = room - 1;
  	}
  
 -	writeq_be((u64)&cmd->rcb, &hwq->host_map->ioarrin);
 +	writeq_be((u64)&cmd->rcb, &afu->host_map->ioarrin);
  out:
++<<<<<<< HEAD
 +	spin_unlock_irqrestore(&afu->rrin_slock, lock_flags);
 +	pr_devel("%s: cmd=%p len=%d ea=%p rc=%d\n", __func__, cmd,
 +		 cmd->rcb.data_len, (void *)cmd->rcb.data_ea, rc);
++=======
+ 	spin_unlock_irqrestore(&hwq->hsq_slock, lock_flags);
+ 	dev_dbg(dev, "%s: cmd=%p len=%u ea=%016llx rc=%d\n", __func__,
+ 		cmd, cmd->rcb.data_len, cmd->rcb.data_ea, rc);
+ 	return rc;
+ }
+ 
+ /**
+  * send_cmd_sq() - sends an AFU command via SQ ring
+  * @afu:	AFU associated with the host.
+  * @cmd:	AFU command to send.
+  *
+  * Return:
+  *	0 on success, SCSI_MLQUEUE_HOST_BUSY on failure
+  */
+ static int send_cmd_sq(struct afu *afu, struct afu_cmd *cmd)
+ {
+ 	struct cxlflash_cfg *cfg = afu->parent;
+ 	struct device *dev = &cfg->dev->dev;
+ 	struct hwq *hwq = get_hwq(afu, cmd->hwq_index);
+ 	int rc = 0;
+ 	int newval;
+ 	ulong lock_flags;
+ 
+ 	newval = atomic_dec_if_positive(&hwq->hsq_credits);
+ 	if (newval <= 0) {
+ 		rc = SCSI_MLQUEUE_HOST_BUSY;
+ 		goto out;
+ 	}
+ 
+ 	cmd->rcb.ioasa = &cmd->sa;
+ 
+ 	spin_lock_irqsave(&hwq->hsq_slock, lock_flags);
+ 
+ 	*hwq->hsq_curr = cmd->rcb;
+ 	if (hwq->hsq_curr < hwq->hsq_end)
+ 		hwq->hsq_curr++;
+ 	else
+ 		hwq->hsq_curr = hwq->hsq_start;
+ 	writeq_be((u64)hwq->hsq_curr, &hwq->host_map->sq_tail);
+ 
+ 	spin_unlock_irqrestore(&hwq->hsq_slock, lock_flags);
+ out:
+ 	dev_dbg(dev, "%s: cmd=%p len=%u ea=%016llx ioasa=%p rc=%d curr=%p "
+ 	       "head=%016llx tail=%016llx\n", __func__, cmd, cmd->rcb.data_len,
+ 	       cmd->rcb.data_ea, cmd->rcb.ioasa, rc, hwq->hsq_curr,
+ 	       readq_be(&hwq->host_map->sq_head),
+ 	       readq_be(&hwq->host_map->sq_tail));
++>>>>>>> 66ea9bcc3920 (scsi: cxlflash: Combine the send queue locks)
  	return rc;
  }
  
@@@ -1580,14 -1710,39 +1636,46 @@@ static int start_afu(struct cxlflash_cf
  
  	init_pcr(cfg);
  
 -	/* Initialize each HWQ */
 -	for (i = 0; i < afu->num_hwqs; i++) {
 -		hwq = get_hwq(afu, i);
 +	/* After an AFU reset, RRQ entries are stale, clear them */
 +	memset(&afu->rrq_entry, 0, sizeof(afu->rrq_entry));
  
++<<<<<<< HEAD
 +	/* Initialize RRQ pointers */
 +	afu->hrrq_start = &afu->rrq_entry[0];
 +	afu->hrrq_end = &afu->rrq_entry[NUM_RRQ_ENTRY - 1];
 +	afu->hrrq_curr = afu->hrrq_start;
 +	afu->toggle = 1;
++=======
+ 		/* After an AFU reset, RRQ entries are stale, clear them */
+ 		memset(&hwq->rrq_entry, 0, sizeof(hwq->rrq_entry));
+ 
+ 		/* Initialize RRQ pointers */
+ 		hwq->hrrq_start = &hwq->rrq_entry[0];
+ 		hwq->hrrq_end = &hwq->rrq_entry[NUM_RRQ_ENTRY - 1];
+ 		hwq->hrrq_curr = hwq->hrrq_start;
+ 		hwq->toggle = 1;
+ 
+ 		/* Initialize spin locks */
+ 		spin_lock_init(&hwq->hrrq_slock);
+ 		spin_lock_init(&hwq->hsq_slock);
+ 
+ 		/* Initialize SQ */
+ 		if (afu_is_sq_cmd_mode(afu)) {
+ 			memset(&hwq->sq, 0, sizeof(hwq->sq));
+ 			hwq->hsq_start = &hwq->sq[0];
+ 			hwq->hsq_end = &hwq->sq[NUM_SQ_ENTRY - 1];
+ 			hwq->hsq_curr = hwq->hsq_start;
+ 
+ 			atomic_set(&hwq->hsq_credits, NUM_SQ_ENTRY - 1);
+ 		}
+ 
+ 		/* Initialize IRQ poll */
+ 		if (afu_is_irqpoll_enabled(afu))
+ 			irq_poll_init(&hwq->irqpoll, afu->irqpoll_weight,
+ 				      cxlflash_irqpoll);
+ 
+ 	}
++>>>>>>> 66ea9bcc3920 (scsi: cxlflash: Combine the send queue locks)
  
  	rc = init_global(cfg);
  
@@@ -1760,8 -1983,11 +1848,16 @@@ static int init_afu(struct cxlflash_cf
  	}
  
  	afu_err_intr_init(cfg->afu);
++<<<<<<< HEAD
 +	spin_lock_init(&afu->rrin_slock);
 +	afu->room = readq_be(&afu->host_map->cmd_room);
++=======
+ 	for (i = 0; i < afu->num_hwqs; i++) {
+ 		hwq = get_hwq(afu, i);
+ 
+ 		hwq->room = readq_be(&hwq->host_map->cmd_room);
+ 	}
++>>>>>>> 66ea9bcc3920 (scsi: cxlflash: Combine the send queue locks)
  
  	/* Restore the LUN mappings */
  	cxlflash_restore_luntable(cfg);
* Unmerged path drivers/scsi/cxlflash/common.h
* Unmerged path drivers/scsi/cxlflash/main.c
