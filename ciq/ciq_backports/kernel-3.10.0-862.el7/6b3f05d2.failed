fsnotify: Detach mark from object list when last reference is dropped

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Jan Kara <jack@suse.cz>
commit 6b3f05d24d355f50f3d9814304650fcab0efb482
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/6b3f05d2.failed

Instead of removing mark from object list from fsnotify_detach_mark(),
remove the mark when last reference to the mark is dropped. This will
allow fanotify to wait for userspace response to event without having to
hold onto fsnotify_mark_srcu.

To avoid pinning inodes by elevated refcount (and thus e.g. delaying
file deletion) while someone holds mark reference, we detach connector
from the object also from fsnotify_destroy_marks() and not only after
removing last mark from the list as it was now.

	Reviewed-by: Miklos Szeredi <mszeredi@redhat.com>
	Reviewed-by: Amir Goldstein <amir73il@gmail.com>
	Signed-off-by: Jan Kara <jack@suse.cz>
(cherry picked from commit 6b3f05d24d355f50f3d9814304650fcab0efb482)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/notify/mark.c
#	include/linux/fsnotify_backend.h
#	kernel/audit_tree.c
diff --cc fs/notify/mark.c
index c90e4dd6743b,21c7791362c8..000000000000
--- a/fs/notify/mark.c
+++ b/fs/notify/mark.c
@@@ -44,10 -44,18 +44,22 @@@
   * is assigned to as well as the access to a reference of the inode/vfsmount
   * that is being watched by the mark.
   *
 - * mark->connector->lock protects the list of marks anchored inside an
 - * inode / vfsmount and each mark is hooked via the i_list.
 + * inode->i_lock protects the i_fsnotify_marks list anchored inside a
 + * given inode and each mark is hooked via the i_list. (and sorta the
 + * free_i_list)
   *
++<<<<<<< HEAD
++=======
+  * A list of notification marks relating to inode / mnt is contained in
+  * fsnotify_mark_connector. That structure is alive as long as there are any
+  * marks in the list and is also protected by fsnotify_mark_srcu. A mark gets
+  * detached from fsnotify_mark_connector when last reference to the mark is
+  * dropped.  Thus having mark reference is enough to protect mark->connector
+  * pointer and to make sure fsnotify_mark_connector cannot disappear. Also
+  * because we remove mark from g_list before dropping mark reference associated
+  * with that, any mark found through g_list is guaranteed to have
+  * mark->connector set until we drop group->mark_mutex.
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
   *
   * LIFETIME:
   * Inode marks survive between when they are added to an inode and when their
@@@ -95,26 -109,138 +107,160 @@@ void fsnotify_get_mark(struct fsnotify_
  	atomic_inc(&mark->refcnt);
  }
  
++<<<<<<< HEAD
 +void fsnotify_put_mark(struct fsnotify_mark *mark)
 +{
 +	if (atomic_dec_and_test(&mark->refcnt)) {
 +		spin_lock(&destroy_lock);
 +		list_add(&mark->g_list, &destroy_list);
 +		spin_unlock(&destroy_lock);
 +		queue_delayed_work(system_unbound_wq, &reaper_work,
 +				   FSNOTIFY_REAPER_DELAY);
 +	}
 +}
 +
 +/* Calculate mask of events for a list of marks */
 +u32 fsnotify_recalc_mask(struct hlist_head *head)
++=======
+ static void __fsnotify_recalc_mask(struct fsnotify_mark_connector *conn)
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  {
  	u32 new_mask = 0;
  	struct fsnotify_mark *mark;
  
++<<<<<<< HEAD
 +	hlist_for_each_entry(mark, head, obj_list)
 +		new_mask |= mark->mask;
 +	return new_mask;
++=======
+ 	assert_spin_locked(&conn->lock);
+ 	hlist_for_each_entry(mark, &conn->list, obj_list) {
+ 		if (mark->flags & FSNOTIFY_MARK_FLAG_ATTACHED)
+ 			new_mask |= mark->mask;
+ 	}
+ 	if (conn->flags & FSNOTIFY_OBJ_TYPE_INODE)
+ 		conn->inode->i_fsnotify_mask = new_mask;
+ 	else if (conn->flags & FSNOTIFY_OBJ_TYPE_VFSMOUNT)
+ 		real_mount(conn->mnt)->mnt_fsnotify_mask = new_mask;
+ }
+ 
+ /*
+  * Calculate mask of events for a list of marks. The caller must make sure
+  * connector and connector->inode cannot disappear under us.  Callers achieve
+  * this by holding a mark->lock or mark->group->mark_mutex for a mark on this
+  * list.
+  */
+ void fsnotify_recalc_mask(struct fsnotify_mark_connector *conn)
+ {
+ 	if (!conn)
+ 		return;
+ 
+ 	spin_lock(&conn->lock);
+ 	__fsnotify_recalc_mask(conn);
+ 	spin_unlock(&conn->lock);
+ 	if (conn->flags & FSNOTIFY_OBJ_TYPE_INODE)
+ 		__fsnotify_update_child_dentry_flags(conn->inode);
+ }
+ 
+ /* Free all connectors queued for freeing once SRCU period ends */
+ static void fsnotify_connector_destroy_workfn(struct work_struct *work)
+ {
+ 	struct fsnotify_mark_connector *conn, *free;
+ 
+ 	spin_lock(&destroy_lock);
+ 	conn = connector_destroy_list;
+ 	connector_destroy_list = NULL;
+ 	spin_unlock(&destroy_lock);
+ 
+ 	synchronize_srcu(&fsnotify_mark_srcu);
+ 	while (conn) {
+ 		free = conn;
+ 		conn = conn->destroy_next;
+ 		kmem_cache_free(fsnotify_mark_connector_cachep, free);
+ 	}
+ }
+ 
+ static struct inode *fsnotify_detach_connector_from_object(
+ 					struct fsnotify_mark_connector *conn)
+ {
+ 	struct inode *inode = NULL;
+ 
+ 	if (conn->flags & FSNOTIFY_OBJ_TYPE_INODE) {
+ 		inode = conn->inode;
+ 		rcu_assign_pointer(inode->i_fsnotify_marks, NULL);
+ 		inode->i_fsnotify_mask = 0;
+ 		conn->inode = NULL;
+ 		conn->flags &= ~FSNOTIFY_OBJ_TYPE_INODE;
+ 	} else if (conn->flags & FSNOTIFY_OBJ_TYPE_VFSMOUNT) {
+ 		rcu_assign_pointer(real_mount(conn->mnt)->mnt_fsnotify_marks,
+ 				   NULL);
+ 		real_mount(conn->mnt)->mnt_fsnotify_mask = 0;
+ 		conn->mnt = NULL;
+ 		conn->flags &= ~FSNOTIFY_OBJ_TYPE_VFSMOUNT;
+ 	}
+ 
+ 	return inode;
+ }
+ 
+ static void fsnotify_final_mark_destroy(struct fsnotify_mark *mark)
+ {
+ 	if (mark->group)
+ 		fsnotify_put_group(mark->group);
+ 	mark->free_mark(mark);
+ }
+ 
+ void fsnotify_put_mark(struct fsnotify_mark *mark)
+ {
+ 	struct fsnotify_mark_connector *conn;
+ 	struct inode *inode = NULL;
+ 	bool free_conn = false;
+ 
+ 	/* Catch marks that were actually never attached to object */
+ 	if (!mark->connector) {
+ 		if (atomic_dec_and_test(&mark->refcnt))
+ 			fsnotify_final_mark_destroy(mark);
+ 		return;
+ 	}
+ 
+ 	/*
+ 	 * We have to be careful so that traversals of obj_list under lock can
+ 	 * safely grab mark reference.
+ 	 */
+ 	if (!atomic_dec_and_lock(&mark->refcnt, &mark->connector->lock))
+ 		return;
+ 
+ 	conn = mark->connector;
+ 	hlist_del_init_rcu(&mark->obj_list);
+ 	if (hlist_empty(&conn->list)) {
+ 		inode = fsnotify_detach_connector_from_object(conn);
+ 		free_conn = true;
+ 	} else {
+ 		__fsnotify_recalc_mask(conn);
+ 	}
+ 	mark->connector = NULL;
+ 	spin_unlock(&conn->lock);
+ 
+ 	iput(inode);
+ 
+ 	if (free_conn) {
+ 		spin_lock(&destroy_lock);
+ 		conn->destroy_next = connector_destroy_list;
+ 		connector_destroy_list = conn;
+ 		spin_unlock(&destroy_lock);
+ 		queue_work(system_unbound_wq, &connector_reaper_work);
+ 	}
+ 	/*
+ 	 * Note that we didn't update flags telling whether inode cares about
+ 	 * what's happening with children. We update these flags from
+ 	 * __fsnotify_parent() lazily when next event happens on one of our
+ 	 * children.
+ 	 */
+ 	spin_lock(&destroy_lock);
+ 	list_add(&mark->g_list, &destroy_list);
+ 	spin_unlock(&destroy_lock);
+ 	queue_delayed_work(system_unbound_wq, &reaper_work,
+ 			   FSNOTIFY_REAPER_DELAY);
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  }
  
  /*
@@@ -141,30 -268,10 +288,34 @@@ void fsnotify_detach_mark(struct fsnoti
  		spin_unlock(&mark->lock);
  		return;
  	}
- 
  	mark->flags &= ~FSNOTIFY_MARK_FLAG_ATTACHED;
++<<<<<<< HEAD
 +
 +	if (mark->flags & FSNOTIFY_MARK_FLAG_INODE) {
 +		inode = mark->inode;
 +		fsnotify_destroy_inode_mark(mark);
 +	} else if (mark->flags & FSNOTIFY_MARK_FLAG_VFSMOUNT)
 +		fsnotify_destroy_vfsmount_mark(mark);
 +	else
 +		BUG();
 +	/*
 +	 * Note that we didn't update flags telling whether inode cares about
 +	 * what's happening with children. We update these flags from
 +	 * __fsnotify_parent() lazily when next event happens on one of our
 +	 * children.
 +	 */
 +
++=======
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  	list_del_init(&mark->g_list);
- 
  	spin_unlock(&mark->lock);
  
++<<<<<<< HEAD
 +	if (inode && (mark->flags & FSNOTIFY_MARK_FLAG_OBJECT_PINNED))
 +		iput(inode);
 +
++=======
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  	atomic_dec(&group->num_marks);
  
  	/* Drop mark reference acquired in fsnotify_add_mark_locked() */
@@@ -308,11 -468,15 +459,20 @@@ int fsnotify_add_mark_list(struct hlist
  	}
  
  	/* should mark be in the middle of the current list? */
 -	hlist_for_each_entry(lmark, &conn->list, obj_list) {
 +	hlist_for_each_entry(lmark, head, obj_list) {
  		last = lmark;
  
++<<<<<<< HEAD
 +		if ((lmark->group == mark->group) && !allow_dups)
 +			return -EEXIST;
++=======
+ 		if ((lmark->group == mark->group) &&
+ 		    (lmark->flags & FSNOTIFY_MARK_FLAG_ATTACHED) &&
+ 		    !allow_dups) {
+ 			err = -EEXIST;
+ 			goto out_err;
+ 		}
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  
  		cmp = fsnotify_compare_groups(lmark->group, mark->group);
  		if (cmp >= 0) {
@@@ -355,26 -524,15 +515,30 @@@ int fsnotify_add_mark_locked(struct fsn
  	mark->group = group;
  	list_add(&mark->g_list, &group->marks_list);
  	atomic_inc(&group->num_marks);
++<<<<<<< HEAD
 +	fsnotify_get_mark(mark); /* for i_list and g_list */
 +
 +	if (inode) {
 +		ret = fsnotify_add_inode_mark(mark, group, inode, allow_dups);
 +		if (ret)
 +			goto err;
 +	} else if (mnt) {
 +		ret = fsnotify_add_vfsmount_mark(mark, group, mnt, allow_dups);
 +		if (ret)
 +			goto err;
 +	} else {
 +		BUG();
 +	}
 +
 +	/* this will pin the object if appropriate */
 +	fsnotify_set_mark_mask_locked(mark, mark->mask);
++=======
+ 	fsnotify_get_mark(mark); /* for g_list */
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  	spin_unlock(&mark->lock);
  
 -	ret = fsnotify_add_mark_list(mark, inode, mnt, allow_dups);
 -	if (ret)
 -		goto err;
 -
 -	if (mark->mask)
 -		fsnotify_recalc_mask(mark->connector);
 +	if (inode)
 +		__fsnotify_update_child_dentry_flags(inode);
  
  	return ret;
  err:
@@@ -402,14 -560,22 +566,24 @@@ int fsnotify_add_mark(struct fsnotify_m
   * Given a list of marks, find the mark associated with given group. If found
   * take a reference to that mark and return it, else return NULL.
   */
 -struct fsnotify_mark *fsnotify_find_mark(
 -				struct fsnotify_mark_connector __rcu **connp,
 -				struct fsnotify_group *group)
 +struct fsnotify_mark *fsnotify_find_mark(struct hlist_head *head,
 +					 struct fsnotify_group *group)
  {
 -	struct fsnotify_mark_connector *conn;
  	struct fsnotify_mark *mark;
  
++<<<<<<< HEAD
 +	hlist_for_each_entry(mark, head, obj_list) {
 +		if (mark->group == group) {
++=======
+ 	conn = fsnotify_grab_connector(connp);
+ 	if (!conn)
+ 		return NULL;
+ 
+ 	hlist_for_each_entry(mark, &conn->list, obj_list) {
+ 		if (mark->group == group &&
+ 		    (mark->flags & FSNOTIFY_MARK_FLAG_ATTACHED)) {
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  			fsnotify_get_mark(mark);
 -			spin_unlock(&conn->lock);
  			return mark;
  		}
  	}
@@@ -482,6 -649,44 +656,47 @@@ void fsnotify_detach_group_marks(struc
  	}
  }
  
++<<<<<<< HEAD
++=======
+ /* Destroy all marks attached to inode / vfsmount */
+ void fsnotify_destroy_marks(struct fsnotify_mark_connector __rcu **connp)
+ {
+ 	struct fsnotify_mark_connector *conn;
+ 	struct fsnotify_mark *mark, *old_mark = NULL;
+ 	struct inode *inode;
+ 
+ 	conn = fsnotify_grab_connector(connp);
+ 	if (!conn)
+ 		return;
+ 	/*
+ 	 * We have to be careful since we can race with e.g.
+ 	 * fsnotify_clear_marks_by_group() and once we drop the conn->lock, the
+ 	 * list can get modified. However we are holding mark reference and
+ 	 * thus our mark cannot be removed from obj_list so we can continue
+ 	 * iteration after regaining conn->lock.
+ 	 */
+ 	hlist_for_each_entry(mark, &conn->list, obj_list) {
+ 		fsnotify_get_mark(mark);
+ 		spin_unlock(&conn->lock);
+ 		if (old_mark)
+ 			fsnotify_put_mark(old_mark);
+ 		old_mark = mark;
+ 		fsnotify_destroy_mark(mark, mark->group);
+ 		spin_lock(&conn->lock);
+ 	}
+ 	/*
+ 	 * Detach list from object now so that we don't pin inode until all
+ 	 * mark references get dropped. It would lead to strange results such
+ 	 * as delaying inode deletion or blocking unmount.
+ 	 */
+ 	inode = fsnotify_detach_connector_from_object(conn);
+ 	spin_unlock(&conn->lock);
+ 	if (old_mark)
+ 		fsnotify_put_mark(old_mark);
+ 	iput(inode);
+ }
+ 
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  /*
   * Nothing fancy, just initialize lists and locks and counters.
   */
diff --cc include/linux/fsnotify_backend.h
index 0256909191e5,a483614b25d0..000000000000
--- a/include/linux/fsnotify_backend.h
+++ b/include/linux/fsnotify_backend.h
@@@ -223,20 -245,15 +223,27 @@@ struct fsnotify_mark 
  	struct list_head g_list;
  	/* Protects inode / mnt pointers, flags, masks */
  	spinlock_t lock;
++<<<<<<< HEAD
 +	/* List of marks for inode / vfsmount [obj_lock] */
 +	struct hlist_node obj_list;
 +	union {	/* Object pointer [mark->lock, group->mark_mutex] */
 +		struct inode *inode;	/* inode this mark is associated with */
 +		struct vfsmount *mnt;	/* vfsmount this mark is associated with */
 +	};
++=======
+ 	/* List of marks for inode / vfsmount [connector->lock, mark ref] */
+ 	struct hlist_node obj_list;
+ 	/* Head of list of marks for an object [mark ref] */
+ 	struct fsnotify_mark_connector *connector;
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  	/* Events types to ignore [mark->lock, group->mark_mutex] */
  	__u32 ignored_mask;
 -#define FSNOTIFY_MARK_FLAG_IGNORED_SURV_MODIFY	0x01
 -#define FSNOTIFY_MARK_FLAG_ALIVE		0x02
 -#define FSNOTIFY_MARK_FLAG_ATTACHED		0x04
 +#define FSNOTIFY_MARK_FLAG_INODE		0x01
 +#define FSNOTIFY_MARK_FLAG_VFSMOUNT		0x02
 +#define FSNOTIFY_MARK_FLAG_OBJECT_PINNED	0x04
 +#define FSNOTIFY_MARK_FLAG_IGNORED_SURV_MODIFY	0x08
 +#define FSNOTIFY_MARK_FLAG_ALIVE		0x10
 +#define FSNOTIFY_MARK_FLAG_ATTACHED		0x20
  	unsigned int flags;		/* flags [mark->lock] */
  	void (*free_mark)(struct fsnotify_mark *mark); /* called on final put+free */
  };
diff --cc kernel/audit_tree.c
index 4dfdb945bae9,2fa8d61b6fd2..000000000000
--- a/kernel/audit_tree.c
+++ b/kernel/audit_tree.c
@@@ -162,21 -163,42 +162,49 @@@ enum {HASH_SIZE = 128}
  static struct list_head chunk_hash_heads[HASH_SIZE];
  static __cacheline_aligned_in_smp DEFINE_SPINLOCK(hash_lock);
  
 -/* Function to return search key in our hash from inode. */
 -static unsigned long inode_to_key(const struct inode *inode)
 +static inline struct list_head *chunk_hash(const struct inode *inode)
  {
++<<<<<<< HEAD
 +	unsigned long n = (unsigned long)inode / L1_CACHE_BYTES;
++=======
+ 	return (unsigned long)inode;
+ }
+ 
+ /*
+  * Function to return search key in our hash from chunk. Key 0 is special and
+  * should never be present in the hash.
+  */
+ static unsigned long chunk_to_key(struct audit_chunk *chunk)
+ {
+ 	/*
+ 	 * We have a reference to the mark so it should be attached to a
+ 	 * connector.
+ 	 */
+ 	if (WARN_ON_ONCE(!chunk->mark.connector))
+ 		return 0;
+ 	return (unsigned long)chunk->mark.connector->inode;
+ }
+ 
+ static inline struct list_head *chunk_hash(unsigned long key)
+ {
+ 	unsigned long n = key / L1_CACHE_BYTES;
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  	return chunk_hash_heads + n % HASH_SIZE;
  }
  
  /* hash_lock & entry->lock is held by caller */
  static void insert_hash(struct audit_chunk *chunk)
  {
++<<<<<<< HEAD
 +	struct fsnotify_mark *entry = &chunk->mark;
++=======
+ 	unsigned long key = chunk_to_key(chunk);
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  	struct list_head *list;
  
 -	if (!(chunk->mark.flags & FSNOTIFY_MARK_FLAG_ATTACHED))
 +	if (!entry->inode)
  		return;
 -	list = chunk_hash(key);
 +	list = chunk_hash(entry->inode);
  	list_add_rcu(&chunk->hash, list);
  }
  
@@@ -232,7 -254,11 +260,15 @@@ static void untag_chunk(struct node *p
  
  	mutex_lock(&entry->group->mark_mutex);
  	spin_lock(&entry->lock);
++<<<<<<< HEAD
 +	if (chunk->dead || !entry->inode) {
++=======
+ 	/*
+ 	 * mark_mutex protects mark from getting detached and thus also from
+ 	 * mark->connector->inode getting NULL.
+ 	 */
+ 	if (chunk->dead || !(entry->flags & FSNOTIFY_MARK_FLAG_ATTACHED)) {
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  		spin_unlock(&entry->lock);
  		mutex_unlock(&entry->group->mark_mutex);
  		if (new)
@@@ -392,7 -418,11 +428,15 @@@ static int tag_chunk(struct inode *inod
  
  	mutex_lock(&old_entry->group->mark_mutex);
  	spin_lock(&old_entry->lock);
++<<<<<<< HEAD
 +	if (!old_entry->inode) {
++=======
+ 	/*
+ 	 * mark_mutex protects mark from getting detached and thus also from
+ 	 * mark->connector->inode getting NULL.
+ 	 */
+ 	if (!(old_entry->flags & FSNOTIFY_MARK_FLAG_ATTACHED)) {
++>>>>>>> 6b3f05d24d35 (fsnotify: Detach mark from object list when last reference is dropped)
  		/* old_entry is being shot, lets just lie */
  		spin_unlock(&old_entry->lock);
  		mutex_unlock(&old_entry->group->mark_mutex);
* Unmerged path fs/notify/mark.c
* Unmerged path include/linux/fsnotify_backend.h
* Unmerged path kernel/audit_tree.c
