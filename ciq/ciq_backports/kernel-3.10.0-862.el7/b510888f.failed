ibmvnic: Merge the two release_sub_crq_queue routines

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Nathan Fontenot <nfont@linux.vnet.ibm.com>
commit b510888f9639588d30d48eaaa32502cdb1c9e9e0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/b510888f.failed

Keeping two routines for releasing sub crqs, one for when irqs are not
initialized and one for when they are, is a bit of overkill. Merge the
two routines to a common release routine that will check for an irq
and release it if needed.

	Signed-off-by: Nathan Fontenot <nfont@linux.vnet.ibm.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit b510888f9639588d30d48eaaa32502cdb1c9e9e0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/ibm/ibmvnic.c
diff --cc drivers/net/ethernet/ibm/ibmvnic.c
index 6a325c61534d,f2d2f1f1ce1c..000000000000
--- a/drivers/net/ethernet/ibm/ibmvnic.c
+++ b/drivers/net/ethernet/ibm/ibmvnic.c
@@@ -347,25 -302,250 +346,244 @@@ static void replenish_pools(struct ibmv
  	}
  }
  
 -static void release_rx_pools(struct ibmvnic_adapter *adapter)
 +static void free_rx_pool(struct ibmvnic_adapter *adapter,
 +			 struct ibmvnic_rx_pool *pool)
  {
 -	struct ibmvnic_rx_pool *rx_pool;
 -	int rx_scrqs;
 -	int i, j;
 -
 -	if (!adapter->rx_pool)
 -		return;
 -
 -	rx_scrqs = be32_to_cpu(adapter->login_rsp_buf->num_rxadd_subcrqs);
 -	for (i = 0; i < rx_scrqs; i++) {
 -		rx_pool = &adapter->rx_pool[i];
 +	int i;
  
 -		kfree(rx_pool->free_map);
 -		free_long_term_buff(adapter, &rx_pool->long_term_buff);
 +	kfree(pool->free_map);
 +	pool->free_map = NULL;
  
 -		if (!rx_pool->rx_buff)
 -		continue;
 +	if (!pool->rx_buff)
 +		return;
  
 -		for (j = 0; j < rx_pool->size; j++) {
 -			if (rx_pool->rx_buff[j].skb) {
 -				dev_kfree_skb_any(rx_pool->rx_buff[i].skb);
 -				rx_pool->rx_buff[i].skb = NULL;
 -			}
 +	for (i = 0; i < pool->size; i++) {
 +		if (pool->rx_buff[i].skb) {
 +			dev_kfree_skb_any(pool->rx_buff[i].skb);
 +			pool->rx_buff[i].skb = NULL;
  		}
 -
 -		kfree(rx_pool->rx_buff);
  	}
++<<<<<<< HEAD
 +	kfree(pool->rx_buff);
 +	pool->rx_buff = NULL;
++=======
+ 
+ 	kfree(adapter->rx_pool);
+ 	adapter->rx_pool = NULL;
+ }
+ 
+ static int init_rx_pools(struct net_device *netdev)
+ {
+ 	struct ibmvnic_adapter *adapter = netdev_priv(netdev);
+ 	struct device *dev = &adapter->vdev->dev;
+ 	struct ibmvnic_rx_pool *rx_pool;
+ 	int rxadd_subcrqs;
+ 	u64 *size_array;
+ 	int i, j;
+ 
+ 	rxadd_subcrqs =
+ 		be32_to_cpu(adapter->login_rsp_buf->num_rxadd_subcrqs);
+ 	size_array = (u64 *)((u8 *)(adapter->login_rsp_buf) +
+ 		be32_to_cpu(adapter->login_rsp_buf->off_rxadd_buff_size));
+ 
+ 	adapter->rx_pool = kcalloc(rxadd_subcrqs,
+ 				   sizeof(struct ibmvnic_rx_pool),
+ 				   GFP_KERNEL);
+ 	if (!adapter->rx_pool) {
+ 		dev_err(dev, "Failed to allocate rx pools\n");
+ 		return -1;
+ 	}
+ 
+ 	for (i = 0; i < rxadd_subcrqs; i++) {
+ 		rx_pool = &adapter->rx_pool[i];
+ 
+ 		netdev_dbg(adapter->netdev,
+ 			   "Initializing rx_pool %d, %lld buffs, %lld bytes each\n",
+ 			   i, adapter->req_rx_add_entries_per_subcrq,
+ 			   be64_to_cpu(size_array[i]));
+ 
+ 		rx_pool->size = adapter->req_rx_add_entries_per_subcrq;
+ 		rx_pool->index = i;
+ 		rx_pool->buff_size = be64_to_cpu(size_array[i]);
+ 		rx_pool->active = 1;
+ 
+ 		rx_pool->free_map = kcalloc(rx_pool->size, sizeof(int),
+ 					    GFP_KERNEL);
+ 		if (!rx_pool->free_map) {
+ 			release_rx_pools(adapter);
+ 			return -1;
+ 		}
+ 
+ 		rx_pool->rx_buff = kcalloc(rx_pool->size,
+ 					   sizeof(struct ibmvnic_rx_buff),
+ 					   GFP_KERNEL);
+ 		if (!rx_pool->rx_buff) {
+ 			dev_err(dev, "Couldn't alloc rx buffers\n");
+ 			release_rx_pools(adapter);
+ 			return -1;
+ 		}
+ 
+ 		if (alloc_long_term_buff(adapter, &rx_pool->long_term_buff,
+ 					 rx_pool->size * rx_pool->buff_size)) {
+ 			release_rx_pools(adapter);
+ 			return -1;
+ 		}
+ 
+ 		for (j = 0; j < rx_pool->size; ++j)
+ 			rx_pool->free_map[j] = j;
+ 
+ 		atomic_set(&rx_pool->available, 0);
+ 		rx_pool->next_alloc = 0;
+ 		rx_pool->next_free = 0;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void release_tx_pools(struct ibmvnic_adapter *adapter)
+ {
+ 	struct ibmvnic_tx_pool *tx_pool;
+ 	int i, tx_scrqs;
+ 
+ 	if (!adapter->tx_pool)
+ 		return;
+ 
+ 	tx_scrqs = be32_to_cpu(adapter->login_rsp_buf->num_txsubm_subcrqs);
+ 	for (i = 0; i < tx_scrqs; i++) {
+ 		tx_pool = &adapter->tx_pool[i];
+ 		kfree(tx_pool->tx_buff);
+ 		free_long_term_buff(adapter, &tx_pool->long_term_buff);
+ 		kfree(tx_pool->free_map);
+ 	}
+ 
+ 	kfree(adapter->tx_pool);
+ 	adapter->tx_pool = NULL;
+ }
+ 
+ static int init_tx_pools(struct net_device *netdev)
+ {
+ 	struct ibmvnic_adapter *adapter = netdev_priv(netdev);
+ 	struct device *dev = &adapter->vdev->dev;
+ 	struct ibmvnic_tx_pool *tx_pool;
+ 	int tx_subcrqs;
+ 	int i, j;
+ 
+ 	tx_subcrqs = be32_to_cpu(adapter->login_rsp_buf->num_txsubm_subcrqs);
+ 	adapter->tx_pool = kcalloc(tx_subcrqs,
+ 				   sizeof(struct ibmvnic_tx_pool), GFP_KERNEL);
+ 	if (!adapter->tx_pool)
+ 		return -1;
+ 
+ 	for (i = 0; i < tx_subcrqs; i++) {
+ 		tx_pool = &adapter->tx_pool[i];
+ 		tx_pool->tx_buff = kcalloc(adapter->req_tx_entries_per_subcrq,
+ 					   sizeof(struct ibmvnic_tx_buff),
+ 					   GFP_KERNEL);
+ 		if (!tx_pool->tx_buff) {
+ 			dev_err(dev, "tx pool buffer allocation failed\n");
+ 			release_tx_pools(adapter);
+ 			return -1;
+ 		}
+ 
+ 		if (alloc_long_term_buff(adapter, &tx_pool->long_term_buff,
+ 					 adapter->req_tx_entries_per_subcrq *
+ 					 adapter->req_mtu)) {
+ 			release_tx_pools(adapter);
+ 			return -1;
+ 		}
+ 
+ 		tx_pool->free_map = kcalloc(adapter->req_tx_entries_per_subcrq,
+ 					    sizeof(int), GFP_KERNEL);
+ 		if (!tx_pool->free_map) {
+ 			release_tx_pools(adapter);
+ 			return -1;
+ 		}
+ 
+ 		for (j = 0; j < adapter->req_tx_entries_per_subcrq; j++)
+ 			tx_pool->free_map[j] = j;
+ 
+ 		tx_pool->consumer_index = 0;
+ 		tx_pool->producer_index = 0;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void release_bounce_buffer(struct ibmvnic_adapter *adapter)
+ {
+ 	struct device *dev = &adapter->vdev->dev;
+ 
+ 	if (!adapter->bounce_buffer)
+ 		return;
+ 
+ 	if (!dma_mapping_error(dev, adapter->bounce_buffer_dma)) {
+ 		dma_unmap_single(dev, adapter->bounce_buffer_dma,
+ 				 adapter->bounce_buffer_size,
+ 				 DMA_BIDIRECTIONAL);
+ 		adapter->bounce_buffer_dma = DMA_ERROR_CODE;
+ 	}
+ 
+ 	kfree(adapter->bounce_buffer);
+ 	adapter->bounce_buffer = NULL;
+ }
+ 
+ static int init_bounce_buffer(struct net_device *netdev)
+ {
+ 	struct ibmvnic_adapter *adapter = netdev_priv(netdev);
+ 	struct device *dev = &adapter->vdev->dev;
+ 	char *buf;
+ 	int buf_sz;
+ 	dma_addr_t map_addr;
+ 
+ 	buf_sz = (netdev->mtu + ETH_HLEN - 1) / PAGE_SIZE + 1;
+ 	buf = kmalloc(adapter->bounce_buffer_size, GFP_KERNEL);
+ 	if (!buf)
+ 		return -1;
+ 
+ 	map_addr = dma_map_single(dev, buf, buf_sz, DMA_TO_DEVICE);
+ 	if (dma_mapping_error(dev, map_addr)) {
+ 		dev_err(dev, "Couldn't map bounce buffer\n");
+ 		kfree(buf);
+ 		return -1;
+ 	}
+ 
+ 	adapter->bounce_buffer = buf;
+ 	adapter->bounce_buffer_size = buf_sz;
+ 	adapter->bounce_buffer_dma = map_addr;
+ 	return 0;
+ }
+ 
+ static int ibmvnic_login(struct net_device *netdev)
+ {
+ 	struct ibmvnic_adapter *adapter = netdev_priv(netdev);
+ 	unsigned long timeout = msecs_to_jiffies(30000);
+ 	struct device *dev = &adapter->vdev->dev;
+ 
+ 	do {
+ 		if (adapter->renegotiate) {
+ 			adapter->renegotiate = false;
+ 			release_sub_crqs(adapter);
+ 
+ 			reinit_completion(&adapter->init_done);
+ 			send_cap_queries(adapter);
+ 			if (!wait_for_completion_timeout(&adapter->init_done,
+ 							 timeout)) {
+ 				dev_err(dev, "Capabilities query timeout\n");
+ 				return -1;
+ 			}
+ 		}
+ 
+ 		reinit_completion(&adapter->init_done);
+ 		send_login(adapter);
+ 		if (!wait_for_completion_timeout(&adapter->init_done,
+ 						 timeout)) {
+ 			dev_err(dev, "Login timeout\n");
+ 			return -1;
+ 		}
+ 	} while (adapter->renegotiate);
+ 
+ 	return 0;
++>>>>>>> b510888f9639 (ibmvnic: Merge the two release_sub_crq_queue routines)
  }
  
  static int ibmvnic_open(struct net_device *netdev)
* Unmerged path drivers/net/ethernet/ibm/ibmvnic.c
