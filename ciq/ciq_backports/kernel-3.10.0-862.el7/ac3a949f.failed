IB/CM: Set appropriate slid and dlid when handling CM request

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
commit-author Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
commit ac3a949fb2fff36bebdc4fab90567ed349ea7245
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/ac3a949f.failed

If extended LIDs are being used, a connection request contains
OPA GIDs in them. Extract the lids from the OPA gids and populate
slid/dlid fields in the path records that are created when handling
a connection request.

	Signed-off-by: Dasaratharaman Chandramouli <dasaratharaman.chandramouli@intel.com>
	Reviewed-by: Don Hiatt <don.hiatt@intel.com>
	Reviewed-by: Ira Weiny <ira.weiny@intel.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit ac3a949fb2fff36bebdc4fab90567ed349ea7245)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/cm.c
diff --cc drivers/infiniband/core/cm.c
index 70c24aef631d,d5ca101057b7..000000000000
--- a/drivers/infiniband/core/cm.c
+++ b/drivers/infiniband/core/cm.c
@@@ -1400,15 -1428,63 +1400,72 @@@ static inline int cm_is_active_peer(__b
  		 (be32_to_cpu(local_qpn) > be32_to_cpu(remote_qpn))));
  }
  
++<<<<<<< HEAD
++=======
+ static bool cm_req_has_alt_path(struct cm_req_msg *req_msg)
+ {
+ 	return ((req_msg->alt_local_lid) ||
+ 		(ib_is_opa_gid(&req_msg->alt_local_gid)));
+ }
+ 
+ static void cm_path_set_rec_type(struct ib_device *ib_device, u8 port_num,
+ 				 struct sa_path_rec *path, union ib_gid *gid)
+ {
+ 	if (ib_is_opa_gid(gid) && rdma_cap_opa_ah(ib_device, port_num))
+ 		path->rec_type = SA_PATH_REC_TYPE_OPA;
+ 	else
+ 		path->rec_type = SA_PATH_REC_TYPE_IB;
+ }
+ 
+ static void cm_format_path_lid_from_req(struct cm_req_msg *req_msg,
+ 					struct sa_path_rec *primary_path,
+ 					struct sa_path_rec *alt_path)
+ {
+ 	u32 lid;
+ 
+ 	if (primary_path->rec_type != SA_PATH_REC_TYPE_OPA) {
+ 		sa_path_set_dlid(primary_path,
+ 				 htonl(ntohs(req_msg->primary_local_lid)));
+ 		sa_path_set_slid(primary_path,
+ 				 htonl(ntohs(req_msg->primary_remote_lid)));
+ 	} else {
+ 		lid = opa_get_lid_from_gid(&req_msg->primary_local_gid);
+ 		sa_path_set_dlid(primary_path, cpu_to_be32(lid));
+ 
+ 		lid = opa_get_lid_from_gid(&req_msg->primary_remote_gid);
+ 		sa_path_set_slid(primary_path, cpu_to_be32(lid));
+ 	}
+ 
+ 	if (!cm_req_has_alt_path(req_msg))
+ 		return;
+ 
+ 	if (alt_path->rec_type != SA_PATH_REC_TYPE_OPA) {
+ 		sa_path_set_dlid(alt_path,
+ 				 htonl(ntohs(req_msg->alt_local_lid)));
+ 		sa_path_set_slid(alt_path,
+ 				 htonl(ntohs(req_msg->alt_remote_lid)));
+ 	} else {
+ 		lid = opa_get_lid_from_gid(&req_msg->alt_local_gid);
+ 		sa_path_set_dlid(alt_path, cpu_to_be32(lid));
+ 
+ 		lid = opa_get_lid_from_gid(&req_msg->alt_remote_gid);
+ 		sa_path_set_slid(alt_path, cpu_to_be32(lid));
+ 	}
+ }
+ 
++>>>>>>> ac3a949fb2ff (IB/CM: Set appropriate slid and dlid when handling CM request)
  static void cm_format_paths_from_req(struct cm_req_msg *req_msg,
 -				     struct sa_path_rec *primary_path,
 -				     struct sa_path_rec *alt_path)
 +					    struct ib_sa_path_rec *primary_path,
 +					    struct ib_sa_path_rec *alt_path)
  {
 +	memset(primary_path, 0, sizeof(*primary_path));
  	primary_path->dgid = req_msg->primary_local_gid;
  	primary_path->sgid = req_msg->primary_remote_gid;
++<<<<<<< HEAD
 +	primary_path->dlid = req_msg->primary_local_lid;
 +	primary_path->slid = req_msg->primary_remote_lid;
++=======
++>>>>>>> ac3a949fb2ff (IB/CM: Set appropriate slid and dlid when handling CM request)
  	primary_path->flow_label = cm_req_get_primary_flow_label(req_msg);
  	primary_path->hop_limit = req_msg->primary_hop_limit;
  	primary_path->traffic_class = req_msg->primary_traffic_class;
@@@ -1425,12 -1501,9 +1482,18 @@@
  	primary_path->packet_life_time -= (primary_path->packet_life_time > 0);
  	primary_path->service_id = req_msg->service_id;
  
++<<<<<<< HEAD
 +	if (req_msg->alt_local_lid) {
 +		memset(alt_path, 0, sizeof(*alt_path));
 +		alt_path->dgid = req_msg->alt_local_gid;
 +		alt_path->sgid = req_msg->alt_remote_gid;
 +		alt_path->dlid = req_msg->alt_local_lid;
 +		alt_path->slid = req_msg->alt_remote_lid;
++=======
+ 	if (cm_req_has_alt_path(req_msg)) {
+ 		alt_path->dgid = req_msg->alt_local_gid;
+ 		alt_path->sgid = req_msg->alt_remote_gid;
++>>>>>>> ac3a949fb2ff (IB/CM: Set appropriate slid and dlid when handling CM request)
  		alt_path->flow_label = cm_req_get_alt_flow_label(req_msg);
  		alt_path->hop_limit = req_msg->alt_hop_limit;
  		alt_path->traffic_class = req_msg->alt_traffic_class;
@@@ -2894,15 -3008,29 +2958,35 @@@ out:	spin_unlock_irqrestore(&cm_id_priv
  }
  EXPORT_SYMBOL(ib_send_cm_lap);
  
+ static void cm_format_path_lid_from_lap(struct cm_lap_msg *lap_msg,
+ 					struct sa_path_rec *path)
+ {
+ 	u32 lid;
+ 
+ 	if (path->rec_type != SA_PATH_REC_TYPE_OPA) {
+ 		sa_path_set_dlid(path, htonl(ntohs(lap_msg->alt_local_lid)));
+ 		sa_path_set_slid(path, htonl(ntohs(lap_msg->alt_remote_lid)));
+ 	} else {
+ 		lid = opa_get_lid_from_gid(&lap_msg->alt_local_gid);
+ 		sa_path_set_dlid(path, cpu_to_be32(lid));
+ 
+ 		lid = opa_get_lid_from_gid(&lap_msg->alt_remote_gid);
+ 		sa_path_set_slid(path, cpu_to_be32(lid));
+ 	}
+ }
+ 
  static void cm_format_path_from_lap(struct cm_id_private *cm_id_priv,
 -				    struct sa_path_rec *path,
 +				    struct ib_sa_path_rec *path,
  				    struct cm_lap_msg *lap_msg)
  {
 +	memset(path, 0, sizeof *path);
  	path->dgid = lap_msg->alt_local_gid;
  	path->sgid = lap_msg->alt_remote_gid;
++<<<<<<< HEAD
 +	path->dlid = lap_msg->alt_local_lid;
 +	path->slid = lap_msg->alt_remote_lid;
++=======
++>>>>>>> ac3a949fb2ff (IB/CM: Set appropriate slid and dlid when handling CM request)
  	path->flow_label = cm_lap_get_flow_label(lap_msg);
  	path->hop_limit = lap_msg->alt_hop_limit;
  	path->traffic_class = cm_lap_get_traffic_class(lap_msg);
* Unmerged path drivers/infiniband/core/cm.c
