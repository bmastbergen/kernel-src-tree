net/mlx5e: Optimize poll ICOSQ completion queue

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-862.el7
Rebuild_CHGLOG: - [netdrv] mlx5e: Optimize poll ICOSQ completion queue (Don Dutile) [1456694 1499362]
Rebuild_FUZZ: 95.56%
commit-author Tariq Toukan <tariqt@mellanox.com>
commit 1f5b1e47ee08f6c623db599b6c23ce7c20b79458
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-862.el7/1f5b1e47.failed

UMR operations are more frequent and important.
Check them first, and add a compiler branch predictor hint.

According to current design, ICOSQ CQ can contain at most one
pending CQE per napi. Poll function is optimized accordingly.

Performance:
Single-stream packet-rate tested with pktgen.
Packets are dropped in tc level to zoom into driver data-path.
Larger gain is expected for larger packet sizes, as BW is higher
and UMR posts are more frequent.

---------------------------------------------
packet size | before    | after     | gain  |
64B         | 4,092,370 | 4,113,306 |  0.5% |
1024B       | 3,421,435 | 3,633,819 |  6.2% |

	Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
	Cc: kernel-team@fb.com
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 1f5b1e47ee08f6c623db599b6c23ce7c20b79458)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_txrx.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_txrx.c
index 8689b7bebc3c,491e83d09b58..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_txrx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_txrx.c
@@@ -49,10 -49,40 +49,45 @@@ struct mlx5_cqe64 *mlx5e_get_cqe(struc
  	return cqe;
  }
  
+ static inline void mlx5e_poll_ico_single_cqe(struct mlx5e_cq *cq,
+ 					     struct mlx5e_icosq *sq,
+ 					     struct mlx5_cqe64 *cqe,
+ 					     u16 *sqcc)
+ {
+ 	struct mlx5_wq_cyc *wq = &sq->wq;
+ 	u16 ci = be16_to_cpu(cqe->wqe_counter) & wq->sz_m1;
+ 	struct mlx5e_sq_wqe_info *icowi = &sq->db.ico_wqe[ci];
+ 	struct mlx5e_rq *rq = &sq->channel->rq;
+ 
+ 	prefetch(rq);
+ 	mlx5_cqwq_pop(&cq->wq);
+ 	*sqcc += icowi->num_wqebbs;
+ 
+ 	if (unlikely((cqe->op_own >> 4) != MLX5_CQE_REQ)) {
+ 		WARN_ONCE(true, "mlx5e: Bad OP in ICOSQ CQE: 0x%x\n",
+ 			  cqe->op_own);
+ 		return;
+ 	}
+ 
+ 	if (likely(icowi->opcode == MLX5_OPCODE_UMR)) {
+ 		mlx5e_post_rx_mpwqe(rq);
+ 		return;
+ 	}
+ 
+ 	if (unlikely(icowi->opcode != MLX5_OPCODE_NOP))
+ 		WARN_ONCE(true,
+ 			  "mlx5e: Bad OPCODE in ICOSQ WQE info: 0x%x\n",
+ 			  icowi->opcode);
+ }
+ 
  static void mlx5e_poll_ico_cq(struct mlx5e_cq *cq)
  {
++<<<<<<< HEAD
 +	struct mlx5e_sq *sq = container_of(cq, struct mlx5e_sq, cq);
 +	struct mlx5_wq_cyc *wq;
++=======
+ 	struct mlx5e_icosq *sq = container_of(cq, struct mlx5e_icosq, cq);
++>>>>>>> 1f5b1e47ee08 (net/mlx5e: Optimize poll ICOSQ completion queue)
  	struct mlx5_cqe64 *cqe;
  	u16 sqcc;
  
@@@ -70,32 -98,8 +103,37 @@@
  	 */
  	sqcc = sq->cc;
  
++<<<<<<< HEAD
 +	do {
 +		u16 ci = be16_to_cpu(cqe->wqe_counter) & wq->sz_m1;
 +		struct mlx5e_ico_wqe_info *icowi = &sq->db.ico_wqe[ci];
 +
 +		mlx5_cqwq_pop(&cq->wq);
 +		sqcc += icowi->num_wqebbs;
 +
 +		if (unlikely((cqe->op_own >> 4) != MLX5_CQE_REQ)) {
 +			WARN_ONCE(true, "mlx5e: Bad OP in ICOSQ CQE: 0x%x\n",
 +				  cqe->op_own);
 +			break;
 +		}
 +
 +		switch (icowi->opcode) {
 +		case MLX5_OPCODE_NOP:
 +			break;
 +		case MLX5_OPCODE_UMR:
 +			mlx5e_post_rx_mpwqe(&sq->channel->rq);
 +			break;
 +		default:
 +			WARN_ONCE(true,
 +				  "mlx5e: Bad OPCODE in ICOSQ WQE info: 0x%x\n",
 +				  icowi->opcode);
 +		}
 +
 +	} while ((cqe = mlx5e_get_cqe(cq)));
++=======
+ 	/* by design, there's only a single cqe */
+ 	mlx5e_poll_ico_single_cqe(cq, sq, cqe, &sqcc);
++>>>>>>> 1f5b1e47ee08 (net/mlx5e: Optimize poll ICOSQ completion queue)
  
  	mlx5_cqwq_update_db_record(&cq->wq);
  
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_txrx.c
