drm/i915/guc: Update firmware to v62.0.0

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-365.el8
commit-author Michal Wajdeczko <michal.wajdeczko@intel.com>
commit 572f2a5cd9742c52f6d4d659409180168a169a24
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-365.el8/572f2a5c.failed

Most of the changes to the 62.0.0 firmware revolved around CTB
communication channel. Conform to the new (stable) CTB protocol.

v2:
 (Michal)
  Add values back to kernel DOC for actions
 (Docs)
  Add 'CT buffer' back in to fix warning

	Signed-off-by: John Harrison <John.C.Harrison@Intel.com>
	Signed-off-by: Michal Wajdeczko <michal.wajdeczko@intel.com>
	Signed-off-by: Matthew Brost <matthew.brost@intel.com>
	Reviewed-by: Daniele Ceraolo Spurio <daniele.ceraolospurio@intel.com>
[mattrope: Tweaked kerneldoc while pushing as suggested by Daniele/Michal]
	Signed-off-by: Matt Roper <matthew.d.roper@intel.com>
Link: https://patchwork.freedesktop.org/patch/msgid/20210616001302.84233-3-matthew.brost@intel.com
(cherry picked from commit 572f2a5cd9742c52f6d4d659409180168a169a24)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/i915/gt/uc/abi/guc_actions_abi.h
#	drivers/gpu/drm/i915/gt/uc/abi/guc_communication_ctb_abi.h
#	drivers/gpu/drm/i915/gt/uc/abi/guc_communication_mmio_abi.h
#	drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c
#	drivers/gpu/drm/i915/gt/uc/intel_guc_ct.h
#	drivers/gpu/drm/i915/gt/uc/intel_guc_fwif.h
diff --cc drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c
index fa9e048cc65f,43409044528e..000000000000
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c
@@@ -79,41 -112,57 +79,65 @@@ static inline const char *guc_ct_buffer
  	}
  }
  
- static void guc_ct_buffer_desc_init(struct guc_ct_buffer_desc *desc,
- 				    u32 cmds_addr, u32 size)
+ static void guc_ct_buffer_desc_init(struct guc_ct_buffer_desc *desc)
  {
  	memset(desc, 0, sizeof(*desc));
- 	desc->addr = cmds_addr;
- 	desc->size = size;
- 	desc->owner = CTB_OWNER_HOST;
  }
  
++<<<<<<< HEAD
 +static void guc_ct_buffer_desc_reset(struct guc_ct_buffer_desc *desc)
 +{
 +	desc->head = 0;
 +	desc->tail = 0;
 +	desc->is_in_error = 0;
++=======
+ static void guc_ct_buffer_reset(struct intel_guc_ct_buffer *ctb)
+ {
+ 	ctb->broken = false;
+ 	guc_ct_buffer_desc_init(ctb->desc);
+ }
+ 
+ static void guc_ct_buffer_init(struct intel_guc_ct_buffer *ctb,
+ 			       struct guc_ct_buffer_desc *desc,
+ 			       u32 *cmds, u32 size_in_bytes)
+ {
+ 	GEM_BUG_ON(size_in_bytes % 4);
+ 
+ 	ctb->desc = desc;
+ 	ctb->cmds = cmds;
+ 	ctb->size = size_in_bytes / 4;
+ 
+ 	guc_ct_buffer_reset(ctb);
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  }
  
- static int guc_action_register_ct_buffer(struct intel_guc *guc,
- 					 u32 desc_addr,
- 					 u32 type)
+ static int guc_action_register_ct_buffer(struct intel_guc *guc, u32 type,
+ 					 u32 desc_addr, u32 buff_addr, u32 size)
  {
- 	u32 action[] = {
- 		INTEL_GUC_ACTION_REGISTER_COMMAND_TRANSPORT_BUFFER,
- 		desc_addr,
- 		sizeof(struct guc_ct_buffer_desc),
- 		type
+ 	u32 request[HOST2GUC_REGISTER_CTB_REQUEST_MSG_LEN] = {
+ 		FIELD_PREP(GUC_HXG_MSG_0_ORIGIN, GUC_HXG_ORIGIN_HOST) |
+ 		FIELD_PREP(GUC_HXG_MSG_0_TYPE, GUC_HXG_TYPE_REQUEST) |
+ 		FIELD_PREP(GUC_HXG_REQUEST_MSG_0_ACTION, GUC_ACTION_HOST2GUC_REGISTER_CTB),
+ 		FIELD_PREP(HOST2GUC_REGISTER_CTB_REQUEST_MSG_1_SIZE, size / SZ_4K - 1) |
+ 		FIELD_PREP(HOST2GUC_REGISTER_CTB_REQUEST_MSG_1_TYPE, type),
+ 		FIELD_PREP(HOST2GUC_REGISTER_CTB_REQUEST_MSG_2_DESC_ADDR, desc_addr),
+ 		FIELD_PREP(HOST2GUC_REGISTER_CTB_REQUEST_MSG_3_BUFF_ADDR, buff_addr),
  	};
  
- 	/* Can't use generic send(), CT registration must go over MMIO */
- 	return intel_guc_send_mmio(guc, action, ARRAY_SIZE(action), NULL, 0);
+ 	GEM_BUG_ON(type != GUC_CTB_TYPE_HOST2GUC && type != GUC_CTB_TYPE_GUC2HOST);
+ 	GEM_BUG_ON(size % SZ_4K);
+ 
+ 	/* CT registration must go over MMIO */
+ 	return intel_guc_send_mmio(guc, request, ARRAY_SIZE(request), NULL, 0);
  }
  
- static int ct_register_buffer(struct intel_guc_ct *ct, u32 desc_addr, u32 type)
+ static int ct_register_buffer(struct intel_guc_ct *ct, u32 type,
+ 			      u32 desc_addr, u32 buff_addr, u32 size)
  {
- 	int err = guc_action_register_ct_buffer(ct_to_guc(ct), desc_addr, type);
+ 	int err;
  
+ 	err = guc_action_register_ct_buffer(ct_to_guc(ct), type,
+ 					    desc_addr, buff_addr, size);
  	if (unlikely(err))
  		CT_ERROR(ct, "Failed to register %s buffer (err=%d)\n",
  			 guc_ct_buffer_type_to_str(type), err);
@@@ -222,38 -269,42 +249,69 @@@ void intel_guc_ct_fini(struct intel_guc
  int intel_guc_ct_enable(struct intel_guc_ct *ct)
  {
  	struct intel_guc *guc = ct_to_guc(ct);
++<<<<<<< HEAD
 +	u32 base, cmds, size;
++=======
+ 	u32 base, desc, cmds;
+ 	void *blob;
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  	int err;
 +	int i;
  
  	GEM_BUG_ON(ct->enabled);
  
  	/* vma should be already allocated and map'ed */
  	GEM_BUG_ON(!ct->vma);
 -	GEM_BUG_ON(!i915_gem_object_has_pinned_pages(ct->vma->obj));
  	base = intel_guc_ggtt_offset(guc, ct->vma);
  
++<<<<<<< HEAD
 +	/* (re)initialize descriptors
 +	 * cmds buffers are in the second half of the blob page
 +	 */
 +	for (i = 0; i < ARRAY_SIZE(ct->ctbs); i++) {
 +		GEM_BUG_ON((i != CTB_SEND) && (i != CTB_RECV));
 +		cmds = base + PAGE_SIZE / 4 * i + PAGE_SIZE / 2;
 +		size = PAGE_SIZE / 4;
 +		CT_DEBUG(ct, "%d: addr=%#x size=%u\n", i, cmds, size);
 +		guc_ct_buffer_desc_init(ct->ctbs[i].desc, cmds, size);
 +	}
++=======
+ 	/* blob should start with send descriptor */
+ 	blob = __px_vaddr(ct->vma->obj);
+ 	GEM_BUG_ON(blob != ct->ctbs.send.desc);
+ 
+ 	/* (re)initialize descriptors */
+ 	guc_ct_buffer_reset(&ct->ctbs.send);
+ 	guc_ct_buffer_reset(&ct->ctbs.recv);
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  
  	/*
  	 * Register both CT buffers starting with RECV buffer.
  	 * Descriptors are in first half of the blob.
  	 */
++<<<<<<< HEAD
 +	err = ct_register_buffer(ct, base + PAGE_SIZE / 4 * CTB_RECV,
 +				 INTEL_GUC_CT_BUFFER_TYPE_RECV);
 +	if (unlikely(err))
 +		goto err_out;
 +
 +	err = ct_register_buffer(ct, base + PAGE_SIZE / 4 * CTB_SEND,
 +				 INTEL_GUC_CT_BUFFER_TYPE_SEND);
++=======
+ 	desc = base + ptrdiff(ct->ctbs.recv.desc, blob);
+ 	cmds = base + ptrdiff(ct->ctbs.recv.cmds, blob);
+ 	err = ct_register_buffer(ct, GUC_CTB_TYPE_GUC2HOST,
+ 				 desc, cmds, ct->ctbs.recv.size * 4);
+ 
+ 	if (unlikely(err))
+ 		goto err_out;
+ 
+ 	desc = base + ptrdiff(ct->ctbs.send.desc, blob);
+ 	cmds = base + ptrdiff(ct->ctbs.send.cmds, blob);
+ 	err = ct_register_buffer(ct, GUC_CTB_TYPE_HOST2GUC,
+ 				 desc, cmds, ct->ctbs.send.size * 4);
+ 
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  	if (unlikely(err))
  		goto err_deregister;
  
@@@ -262,9 -313,9 +320,9 @@@
  	return 0;
  
  err_deregister:
- 	ct_deregister_buffer(ct, INTEL_GUC_CT_BUFFER_TYPE_RECV);
+ 	ct_deregister_buffer(ct, GUC_CTB_TYPE_GUC2HOST);
  err_out:
 -	CT_PROBE_ERROR(ct, "Failed to enable CTB (%pe)\n", ERR_PTR(err));
 +	CT_ERROR(ct, "Failed to open open CT channel (err=%d)\n", err);
  	return err;
  }
  
@@@ -292,23 -343,27 +350,47 @@@ static u32 ct_get_next_fence(struct int
  	return ++ct->requests.last_fence;
  }
  
++<<<<<<< HEAD
 +/**
 + * DOC: CTB Host to GuC request
 + *
 + * Format of the CTB Host to GuC request message is as follows::
 + *
 + *      +------------+---------+---------+---------+---------+
 + *      |   msg[0]   |   [1]   |   [2]   |   ...   |  [n-1]  |
 + *      +------------+---------+---------+---------+---------+
 + *      |   MESSAGE  |       MESSAGE PAYLOAD                 |
 + *      +   HEADER   +---------+---------+---------+---------+
 + *      |            |    0    |    1    |   ...   |    n    |
 + *      +============+=========+=========+=========+=========+
 + *      |  len >= 1  |  FENCE  |     request specific data   |
 + *      +------+-----+---------+---------+---------+---------+
 + *
 + *                   ^-----------------len-------------------^
 + */
++=======
+ static void write_barrier(struct intel_guc_ct *ct)
+ {
+ 	struct intel_guc *guc = ct_to_guc(ct);
+ 	struct intel_gt *gt = guc_to_gt(guc);
+ 
+ 	if (i915_gem_object_is_lmem(guc->ct.vma->obj)) {
+ 		GEM_BUG_ON(guc->send_regs.fw_domains);
+ 		/*
+ 		 * This register is used by the i915 and GuC for MMIO based
+ 		 * communication. Once we are in this code CTBs are the only
+ 		 * method the i915 uses to communicate with the GuC so it is
+ 		 * safe to write to this register (a value of 0 is NOP for MMIO
+ 		 * communication). If we ever start mixing CTBs and MMIOs a new
+ 		 * register will have to be chosen.
+ 		 */
+ 		intel_uncore_write_fw(gt->uncore, GEN11_SOFT_SCRATCH(0), 0);
+ 	} else {
+ 		/* wmb() sufficient for a barrier if in smem */
+ 		wmb();
+ 	}
+ }
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  
  static int ct_write(struct intel_guc_ct *ct,
  		    const u32 *action,
@@@ -320,23 -374,25 +402,30 @@@
  	struct guc_ct_buffer_desc *desc = ctb->desc;
  	u32 head = desc->head;
  	u32 tail = desc->tail;
 -	u32 size = ctb->size;
 +	u32 size = desc->size;
  	u32 used;
  	u32 header;
+ 	u32 hxg;
  	u32 *cmds = ctb->cmds;
  	unsigned int i;
  
- 	if (unlikely(desc->is_in_error))
+ 	if (unlikely(ctb->broken))
  		return -EPIPE;
  
++<<<<<<< HEAD
 +	if (unlikely(!IS_ALIGNED(head | tail | size, 4) ||
 +		     (tail | head) >= size))
++=======
+ 	if (unlikely(desc->status))
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  		goto corrupted;
  
- 	/* later calculations will be done in dwords */
- 	head /= 4;
- 	tail /= 4;
- 	size /= 4;
+ 	if (unlikely((tail | head) >= size)) {
+ 		CT_ERROR(ct, "Invalid offsets head=%u tail=%u (size=%u)\n",
+ 			 head, tail, size);
+ 		desc->status |= GUC_CTB_STATUS_OVERFLOW;
+ 		goto corrupted;
+ 	}
  
  	/*
  	 * tail == head condition indicates empty. GuC FW does not support
@@@ -352,18 -408,20 +441,27 @@@
  		return -ENOSPC;
  
  	/*
- 	 * Write the message. The format is the following:
- 	 * DW0: header (including action code)
- 	 * DW1: fence
- 	 * DW2+: action data
+ 	 * dw0: CT header (including fence)
+ 	 * dw1: HXG header (including action code)
+ 	 * dw2+: action data
  	 */
++<<<<<<< HEAD
 +	header = (len << GUC_CT_MSG_LEN_SHIFT) |
 +		 (GUC_CT_MSG_WRITE_FENCE_TO_DESC) |
 +		 (want_response ? GUC_CT_MSG_SEND_STATUS : 0) |
 +		 (action[0] << GUC_CT_MSG_ACTION_SHIFT);
++=======
+ 	header = FIELD_PREP(GUC_CTB_MSG_0_FORMAT, GUC_CTB_FORMAT_HXG) |
+ 		 FIELD_PREP(GUC_CTB_MSG_0_NUM_DWORDS, len) |
+ 		 FIELD_PREP(GUC_CTB_MSG_0_FENCE, fence);
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
+ 
+ 	hxg = FIELD_PREP(GUC_HXG_MSG_0_TYPE, GUC_HXG_TYPE_REQUEST) |
+ 	      FIELD_PREP(GUC_HXG_REQUEST_MSG_0_ACTION |
+ 			 GUC_HXG_REQUEST_MSG_0_DATA0, action[0]);
  
- 	CT_DEBUG(ct, "writing %*ph %*ph %*ph\n",
- 		 4, &header, 4, &fence, 4 * (len - 1), &action[1]);
+ 	CT_DEBUG(ct, "writing (tail %u) %*ph %*ph %*ph\n",
+ 		 tail, 4, &header, 4, &hxg, 4 * (len - 1), &action[1]);
  
  	cmds[tail] = header;
  	tail = (tail + 1) % size;
@@@ -377,8 -435,15 +475,20 @@@
  	}
  	GEM_BUG_ON(tail > size);
  
++<<<<<<< HEAD
 +	/* now update desc tail (back in bytes) */
 +	desc->tail = tail * 4;
++=======
+ 	/*
+ 	 * make sure H2G buffer update and LRC tail update (if this triggering a
+ 	 * submission) are visible before updating the descriptor tail
+ 	 */
+ 	write_barrier(ct);
+ 
+ 	/* now update descriptor */
+ 	WRITE_ONCE(desc->tail, tail);
+ 
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  	return 0;
  
  corrupted:
@@@ -571,24 -584,28 +683,28 @@@ int intel_guc_ct_send(struct intel_guc_
  	return ret;
  }
  
 -static struct ct_incoming_msg *ct_alloc_msg(u32 num_dwords)
++<<<<<<< HEAD
 +static inline unsigned int ct_header_get_len(u32 header)
  {
 -	struct ct_incoming_msg *msg;
 +	return (header >> GUC_CT_MSG_LEN_SHIFT) & GUC_CT_MSG_LEN_MASK;
 +}
  
 -	msg = kmalloc(sizeof(*msg) + sizeof(u32) * num_dwords, GFP_ATOMIC);
 -	if (msg)
 -		msg->size = num_dwords;
 -	return msg;
 +static inline unsigned int ct_header_get_action(u32 header)
 +{
 +	return (header >> GUC_CT_MSG_ACTION_SHIFT) & GUC_CT_MSG_ACTION_MASK;
  }
  
 -static void ct_free_msg(struct ct_incoming_msg *msg)
 +static inline bool ct_header_is_response(u32 header)
  {
 -	kfree(msg);
 +	return !!(header & GUC_CT_MSG_IS_RESPONSE);
  }
  
 -/*
 - * Return: number available remaining dwords to read (0 if empty)
 - *         or a negative error code on failure
 - */
 -static int ct_read(struct intel_guc_ct *ct, struct ct_incoming_msg **msg)
 +static int ct_read(struct intel_guc_ct *ct, u32 *data)
++=======
++static struct ct_incoming_msg *ct_alloc_msg(u32 num_dwords)
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  {
 -	struct intel_guc_ct_buffer *ctb = &ct->ctbs.recv;
 +	struct intel_guc_ct_buffer *ctb = &ct->ctbs[CTB_RECV];
  	struct guc_ct_buffer_desc *desc = ctb->desc;
  	u32 head = desc->head;
  	u32 tail = desc->tail;
@@@ -597,18 -614,20 +713,24 @@@
  	s32 available;
  	unsigned int len;
  	unsigned int i;
 -	u32 header;
  
- 	if (unlikely(desc->is_in_error))
+ 	if (unlikely(ctb->broken))
  		return -EPIPE;
  
++<<<<<<< HEAD
 +	if (unlikely(!IS_ALIGNED(head | tail | size, 4) ||
 +		     (tail | head) >= size))
++=======
+ 	if (unlikely(desc->status))
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  		goto corrupted;
  
- 	/* later calculations will be done in dwords */
- 	head /= 4;
- 	tail /= 4;
- 	size /= 4;
+ 	if (unlikely((tail | head) >= size)) {
+ 		CT_ERROR(ct, "Invalid offsets head=%u tail=%u (size=%u)\n",
+ 			 head, tail, size);
+ 		desc->status |= GUC_CTB_STATUS_OVERFLOW;
+ 		goto corrupted;
+ 	}
  
  	/* tail == head condition indicates empty */
  	available = tail - head;
@@@ -625,10 -646,10 +747,14 @@@
  	head = (head + 1) % size;
  
  	/* message len with header */
++<<<<<<< HEAD
 +	len = ct_header_get_len(data[0]) + 1;
++=======
+ 	len = FIELD_GET(GUC_CTB_MSG_0_NUM_DWORDS, header) + GUC_CTB_MSG_MIN_LEN;
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  	if (unlikely(len > (u32)available)) {
  		CT_ERROR(ct, "Incomplete message %*ph %*ph %*ph\n",
 -			 4, &header,
 +			 4, data,
  			 4 * (head + available - 1 > size ?
  			      size - head : available - 1), &cmds[head],
  			 4 * (head + available - 1 > size ?
@@@ -636,73 -658,57 +763,99 @@@
  		goto corrupted;
  	}
  
 -	*msg = ct_alloc_msg(len);
 -	if (!*msg) {
 -		CT_ERROR(ct, "No memory for message %*ph %*ph %*ph\n",
 -			 4, &header,
 -			 4 * (head + available - 1 > size ?
 -			      size - head : available - 1), &cmds[head],
 -			 4 * (head + available - 1 > size ?
 -			      available - 1 - size + head : 0), &cmds[0]);
 -		return available;
 -	}
 -
 -	(*msg)->msg[0] = header;
 -
  	for (i = 1; i < len; i++) {
 -		(*msg)->msg[i] = cmds[head];
 +		data[i] = cmds[head];
  		head = (head + 1) % size;
  	}
 -	CT_DEBUG(ct, "received %*ph\n", 4 * len, (*msg)->msg);
 +	CT_DEBUG(ct, "received %*ph\n", 4 * len, data);
  
++<<<<<<< HEAD
 +	desc->head = head * 4;
 +	return 0;
++=======
+ 	/* now update descriptor */
+ 	WRITE_ONCE(desc->head, head);
+ 
+ 	return available - len;
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  
  corrupted:
- 	CT_ERROR(ct, "Corrupted descriptor addr=%#x head=%u tail=%u size=%u\n",
- 		 desc->addr, desc->head, desc->tail, desc->size);
- 	desc->is_in_error = 1;
+ 	CT_ERROR(ct, "Corrupted descriptor head=%u tail=%u status=%#x\n",
+ 		 desc->head, desc->tail, desc->status);
+ 	ctb->broken = true;
  	return -EPIPE;
  }
  
++<<<<<<< HEAD
 +/**
 + * DOC: CTB GuC to Host response
 + *
 + * Format of the CTB GuC to Host response message is as follows::
 + *
 + *      +------------+---------+---------+---------+---------+---------+
 + *      |   msg[0]   |   [1]   |   [2]   |   [3]   |   ...   |  [n-1]  |
 + *      +------------+---------+---------+---------+---------+---------+
 + *      |   MESSAGE  |       MESSAGE PAYLOAD                           |
 + *      +   HEADER   +---------+---------+---------+---------+---------+
 + *      |            |    0    |    1    |    2    |   ...   |    n    |
 + *      +============+=========+=========+=========+=========+=========+
 + *      |  len >= 2  |  FENCE  |  STATUS |   response specific data    |
 + *      +------+-----+---------+---------+---------+---------+---------+
 + *
 + *                   ^-----------------------len-----------------------^
 + */
 +
 +static int ct_handle_response(struct intel_guc_ct *ct, const u32 *msg)
 +{
 +	u32 header = msg[0];
 +	u32 len = ct_header_get_len(header);
 +	u32 msgsize = (len + 1) * sizeof(u32); /* msg size in bytes w/header */
 +	u32 fence;
 +	u32 status;
 +	u32 datalen;
++=======
+ static int ct_handle_response(struct intel_guc_ct *ct, struct ct_incoming_msg *response)
+ {
+ 	u32 len = FIELD_GET(GUC_CTB_MSG_0_NUM_DWORDS, response->msg[0]);
+ 	u32 fence = FIELD_GET(GUC_CTB_MSG_0_FENCE, response->msg[0]);
+ 	const u32 *hxg = &response->msg[GUC_CTB_MSG_MIN_LEN];
+ 	const u32 *data = &hxg[GUC_HXG_MSG_MIN_LEN];
+ 	u32 datalen = len - GUC_HXG_MSG_MIN_LEN;
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  	struct ct_request *req;
 -	unsigned long flags;
  	bool found = false;
 -	int err = 0;
  
++<<<<<<< HEAD
 +	GEM_BUG_ON(!ct_header_is_response(header));
 +	GEM_BUG_ON(!in_irq());
 +
 +	/* Response payload shall at least include fence and status */
 +	if (unlikely(len < 2)) {
 +		CT_ERROR(ct, "Corrupted response %*ph\n", msgsize, msg);
 +		return -EPROTO;
 +	}
 +
 +	fence = msg[1];
 +	status = msg[2];
 +	datalen = len - 2;
 +
 +	/* Format of the status follows RESPONSE message */
 +	if (unlikely(!INTEL_GUC_MSG_IS_RESPONSE(status))) {
 +		CT_ERROR(ct, "Corrupted response %*ph\n", msgsize, msg);
 +		return -EPROTO;
 +	}
 +
 +	CT_DEBUG(ct, "response fence %u status %#x\n", fence, status);
++=======
+ 	GEM_BUG_ON(len < GUC_HXG_MSG_MIN_LEN);
+ 	GEM_BUG_ON(FIELD_GET(GUC_HXG_MSG_0_ORIGIN, hxg[0]) != GUC_HXG_ORIGIN_GUC);
+ 	GEM_BUG_ON(FIELD_GET(GUC_HXG_MSG_0_TYPE, hxg[0]) != GUC_HXG_TYPE_RESPONSE_SUCCESS &&
+ 		   FIELD_GET(GUC_HXG_MSG_0_TYPE, hxg[0]) != GUC_HXG_TYPE_RESPONSE_FAILURE);
+ 
+ 	CT_DEBUG(ct, "response fence %u status %#x\n", fence, hxg[0]);
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  
 -	spin_lock_irqsave(&ct->requests.lock, flags);
 +	spin_lock(&ct->requests.lock);
  	list_for_each_entry(req, &ct->requests.pending, link) {
  		if (unlikely(fence != req->fence)) {
  			CT_DEBUG(ct, "request %u awaits response\n",
@@@ -710,14 -716,15 +863,18 @@@
  			continue;
  		}
  		if (unlikely(datalen > req->response_len)) {
 -			CT_ERROR(ct, "Response %u too long (datalen %u > %u)\n",
 -				 req->fence, datalen, req->response_len);
 -			datalen = min(datalen, req->response_len);
 -			err = -EMSGSIZE;
 +			CT_ERROR(ct, "Response for %u is too long %*ph\n",
 +				 req->fence, msgsize, msg);
 +			datalen = 0;
  		}
  		if (datalen)
++<<<<<<< HEAD
 +			memcpy(req->response_buf, msg + 3, 4 * datalen);
++=======
+ 			memcpy(req->response_buf, data, 4 * datalen);
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  		req->response_len = datalen;
- 		WRITE_ONCE(req->status, status);
+ 		WRITE_ONCE(req->status, hxg[0]);
  		found = true;
  		break;
  	}
@@@ -728,12 -742,20 +885,26 @@@
  	return 0;
  }
  
 -static int ct_process_request(struct intel_guc_ct *ct, struct ct_incoming_msg *request)
 +static void ct_process_request(struct intel_guc_ct *ct,
 +			       u32 action, u32 len, const u32 *payload)
  {
  	struct intel_guc *guc = ct_to_guc(ct);
++<<<<<<< HEAD
 +	int ret;
 +
++=======
+ 	const u32 *hxg;
+ 	const u32 *payload;
+ 	u32 hxg_len, action, len;
+ 	int ret;
+ 
+ 	hxg = &request->msg[GUC_CTB_MSG_MIN_LEN];
+ 	hxg_len = request->size - GUC_CTB_MSG_MIN_LEN;
+ 	payload = &hxg[GUC_HXG_MSG_MIN_LEN];
+ 	action = FIELD_GET(GUC_HXG_EVENT_MSG_0_ACTION, hxg[0]);
+ 	len = hxg_len - GUC_HXG_MSG_MIN_LEN;
+ 
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  	CT_DEBUG(ct, "request %x %*ph\n", action, 4 * len, payload);
  
  	switch (action) {
@@@ -792,40 -816,12 +963,49 @@@ static void ct_incoming_request_worker_
  		queue_work(system_unbound_wq, &ct->requests.worker);
  }
  
++<<<<<<< HEAD
 +/**
 + * DOC: CTB GuC to Host request
 + *
 + * Format of the CTB GuC to Host request message is as follows::
 + *
 + *      +------------+---------+---------+---------+---------+---------+
 + *      |   msg[0]   |   [1]   |   [2]   |   [3]   |   ...   |  [n-1]  |
 + *      +------------+---------+---------+---------+---------+---------+
 + *      |   MESSAGE  |       MESSAGE PAYLOAD                           |
 + *      +   HEADER   +---------+---------+---------+---------+---------+
 + *      |            |    0    |    1    |    2    |   ...   |    n    |
 + *      +============+=========+=========+=========+=========+=========+
 + *      |     len    |            request specific data                |
 + *      +------+-----+---------+---------+---------+---------+---------+
 + *
 + *                   ^-----------------------len-----------------------^
 + */
 +
 +static int ct_handle_request(struct intel_guc_ct *ct, const u32 *msg)
 +{
 +	u32 header = msg[0];
 +	u32 len = ct_header_get_len(header);
 +	u32 msgsize = (len + 1) * sizeof(u32); /* msg size in bytes w/header */
 +	struct ct_incoming_request *request;
 +	unsigned long flags;
 +
 +	GEM_BUG_ON(ct_header_is_response(header));
 +
 +	request = kmalloc(sizeof(*request) + msgsize, GFP_ATOMIC);
 +	if (unlikely(!request)) {
 +		CT_ERROR(ct, "Dropping request %*ph\n", msgsize, msg);
 +		return 0; /* XXX: -ENOMEM ? */
 +	}
 +	memcpy(request->msg, msg, msgsize);
++=======
+ static int ct_handle_event(struct intel_guc_ct *ct, struct ct_incoming_msg *request)
+ {
+ 	const u32 *hxg = &request->msg[GUC_CTB_MSG_MIN_LEN];
+ 	unsigned long flags;
+ 
+ 	GEM_BUG_ON(FIELD_GET(GUC_HXG_MSG_0_TYPE, hxg[0]) != GUC_HXG_TYPE_EVENT);
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  
  	spin_lock_irqsave(&ct->requests.lock, flags);
  	list_add_tail(&request->link, &ct->requests.incoming);
@@@ -835,6 -831,102 +1015,105 @@@
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static int ct_handle_hxg(struct intel_guc_ct *ct, struct ct_incoming_msg *msg)
+ {
+ 	u32 origin, type;
+ 	u32 *hxg;
+ 	int err;
+ 
+ 	if (unlikely(msg->size < GUC_CTB_HXG_MSG_MIN_LEN))
+ 		return -EBADMSG;
+ 
+ 	hxg = &msg->msg[GUC_CTB_MSG_MIN_LEN];
+ 
+ 	origin = FIELD_GET(GUC_HXG_MSG_0_ORIGIN, hxg[0]);
+ 	if (unlikely(origin != GUC_HXG_ORIGIN_GUC)) {
+ 		err = -EPROTO;
+ 		goto failed;
+ 	}
+ 
+ 	type = FIELD_GET(GUC_HXG_MSG_0_TYPE, hxg[0]);
+ 	switch (type) {
+ 	case GUC_HXG_TYPE_EVENT:
+ 		err = ct_handle_event(ct, msg);
+ 		break;
+ 	case GUC_HXG_TYPE_RESPONSE_SUCCESS:
+ 	case GUC_HXG_TYPE_RESPONSE_FAILURE:
+ 		err = ct_handle_response(ct, msg);
+ 		break;
+ 	default:
+ 		err = -EOPNOTSUPP;
+ 	}
+ 
+ 	if (unlikely(err)) {
+ failed:
+ 		CT_ERROR(ct, "Failed to handle HXG message (%pe) %*ph\n",
+ 			 ERR_PTR(err), 4 * GUC_HXG_MSG_MIN_LEN, hxg);
+ 	}
+ 	return err;
+ }
+ 
+ static void ct_handle_msg(struct intel_guc_ct *ct, struct ct_incoming_msg *msg)
+ {
+ 	u32 format = FIELD_GET(GUC_CTB_MSG_0_FORMAT, msg->msg[0]);
+ 	int err;
+ 
+ 	if (format == GUC_CTB_FORMAT_HXG)
+ 		err = ct_handle_hxg(ct, msg);
+ 	else
+ 		err = -EOPNOTSUPP;
+ 
+ 	if (unlikely(err)) {
+ 		CT_ERROR(ct, "Failed to process CT message (%pe) %*ph\n",
+ 			 ERR_PTR(err), 4 * msg->size, msg->msg);
+ 		ct_free_msg(msg);
+ 	}
+ }
+ 
+ /*
+  * Return: number available remaining dwords to read (0 if empty)
+  *         or a negative error code on failure
+  */
+ static int ct_receive(struct intel_guc_ct *ct)
+ {
+ 	struct ct_incoming_msg *msg = NULL;
+ 	unsigned long flags;
+ 	int ret;
+ 
+ 	spin_lock_irqsave(&ct->ctbs.recv.lock, flags);
+ 	ret = ct_read(ct, &msg);
+ 	spin_unlock_irqrestore(&ct->ctbs.recv.lock, flags);
+ 	if (ret < 0)
+ 		return ret;
+ 
+ 	if (msg)
+ 		ct_handle_msg(ct, msg);
+ 
+ 	return ret;
+ }
+ 
+ static void ct_try_receive_message(struct intel_guc_ct *ct)
+ {
+ 	int ret;
+ 
+ 	if (GEM_WARN_ON(!ct->enabled))
+ 		return;
+ 
+ 	ret = ct_receive(ct);
+ 	if (ret > 0)
+ 		tasklet_hi_schedule(&ct->receive_tasklet);
+ }
+ 
+ static void ct_receive_tasklet_func(struct tasklet_struct *t)
+ {
+ 	struct intel_guc_ct *ct = from_tasklet(ct, t, receive_tasklet);
+ 
+ 	ct_try_receive_message(ct);
+ }
+ 
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  /*
   * When we're communicating with the GuC over CT, GuC uses events
   * to notify us about new messages being posted on the RECV buffer.
diff --cc drivers/gpu/drm/i915/gt/uc/intel_guc_ct.h
index 494a51a5200f,1ae2dde6db93..000000000000
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc_ct.h
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc_ct.h
@@@ -27,12 -28,18 +27,22 @@@ struct intel_guc
   * record (command transport buffer descriptor) and the actual buffer which
   * holds the commands.
   *
 - * @lock: protects access to the commands buffer and buffer descriptor
   * @desc: pointer to the buffer descriptor
   * @cmds: pointer to the commands buffer
++<<<<<<< HEAD
++=======
+  * @size: size of the commands buffer in dwords
+  * @broken: flag to indicate if descriptor data is broken
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
   */
  struct intel_guc_ct_buffer {
 -	spinlock_t lock;
  	struct guc_ct_buffer_desc *desc;
  	u32 *cmds;
++<<<<<<< HEAD
++=======
+ 	u32 size;
+ 	bool broken;
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  };
  
  
@@@ -45,11 -52,16 +55,11 @@@ struct intel_guc_ct 
  	struct i915_vma *vma;
  	bool enabled;
  
 -	/* buffers for sending and receiving commands */
 -	struct {
 -		struct intel_guc_ct_buffer send;
 -		struct intel_guc_ct_buffer recv;
 -	} ctbs;
 -
 -	struct tasklet_struct receive_tasklet;
 +	/* buffers for sending(0) and receiving(1) commands */
 +	struct intel_guc_ct_buffer ctbs[2];
  
  	struct {
- 		u32 last_fence; /* last fence used to send request */
+ 		u16 last_fence; /* last fence used to send request */
  
  		spinlock_t lock; /* protects pending requests list */
  		struct list_head pending; /* requests waiting for response */
diff --cc drivers/gpu/drm/i915/gt/uc/intel_guc_fwif.h
index 79c560d9c0b6,617ec601648d..000000000000
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc_fwif.h
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc_fwif.h
@@@ -480,126 -378,6 +444,129 @@@ struct guc_shared_ctx_data 
  	struct guc_ctx_report preempt_ctx_report[GUC_MAX_ENGINES_NUM];
  } __packed;
  
++<<<<<<< HEAD
 +/**
 + * DOC: MMIO based communication
 + *
 + * The MMIO based communication between Host and GuC uses software scratch
 + * registers, where first register holds data treated as message header,
 + * and other registers are used to hold message payload.
 + *
 + * For Gen9+, GuC uses software scratch registers 0xC180-0xC1B8,
 + * but no H2G command takes more than 8 parameters and the GuC FW
 + * itself uses an 8-element array to store the H2G message.
 + *
 + *      +-----------+---------+---------+---------+
 + *      |  MMIO[0]  | MMIO[1] |   ...   | MMIO[n] |
 + *      +-----------+---------+---------+---------+
 + *      | header    |      optional payload       |
 + *      +======+====+=========+=========+=========+
 + *      | 31:28|type|         |         |         |
 + *      +------+----+         |         |         |
 + *      | 27:16|data|         |         |         |
 + *      +------+----+         |         |         |
 + *      |  15:0|code|         |         |         |
 + *      +------+----+---------+---------+---------+
 + *
 + * The message header consists of:
 + *
 + * - **type**, indicates message type
 + * - **code**, indicates message code, is specific for **type**
 + * - **data**, indicates message data, optional, depends on **code**
 + *
 + * The following message **types** are supported:
 + *
 + * - **REQUEST**, indicates Host-to-GuC request, requested GuC action code
 + *   must be priovided in **code** field. Optional action specific parameters
 + *   can be provided in remaining payload registers or **data** field.
 + *
 + * - **RESPONSE**, indicates GuC-to-Host response from earlier GuC request,
 + *   action response status will be provided in **code** field. Optional
 + *   response data can be returned in remaining payload registers or **data**
 + *   field.
 + */
 +
 +#define GUC_MAX_MMIO_MSG_LEN		8
 +
 +#define INTEL_GUC_MSG_TYPE_SHIFT	28
 +#define INTEL_GUC_MSG_TYPE_MASK		(0xF << INTEL_GUC_MSG_TYPE_SHIFT)
 +#define INTEL_GUC_MSG_DATA_SHIFT	16
 +#define INTEL_GUC_MSG_DATA_MASK		(0xFFF << INTEL_GUC_MSG_DATA_SHIFT)
 +#define INTEL_GUC_MSG_CODE_SHIFT	0
 +#define INTEL_GUC_MSG_CODE_MASK		(0xFFFF << INTEL_GUC_MSG_CODE_SHIFT)
 +
 +#define __INTEL_GUC_MSG_GET(T, m) \
 +	(((m) & INTEL_GUC_MSG_ ## T ## _MASK) >> INTEL_GUC_MSG_ ## T ## _SHIFT)
 +#define INTEL_GUC_MSG_TO_TYPE(m)	__INTEL_GUC_MSG_GET(TYPE, m)
 +#define INTEL_GUC_MSG_TO_DATA(m)	__INTEL_GUC_MSG_GET(DATA, m)
 +#define INTEL_GUC_MSG_TO_CODE(m)	__INTEL_GUC_MSG_GET(CODE, m)
 +
 +enum intel_guc_msg_type {
 +	INTEL_GUC_MSG_TYPE_REQUEST = 0x0,
 +	INTEL_GUC_MSG_TYPE_RESPONSE = 0xF,
 +};
 +
 +#define __INTEL_GUC_MSG_TYPE_IS(T, m) \
 +	(INTEL_GUC_MSG_TO_TYPE(m) == INTEL_GUC_MSG_TYPE_ ## T)
 +#define INTEL_GUC_MSG_IS_REQUEST(m)	__INTEL_GUC_MSG_TYPE_IS(REQUEST, m)
 +#define INTEL_GUC_MSG_IS_RESPONSE(m)	__INTEL_GUC_MSG_TYPE_IS(RESPONSE, m)
 +
 +enum intel_guc_action {
 +	INTEL_GUC_ACTION_DEFAULT = 0x0,
 +	INTEL_GUC_ACTION_REQUEST_PREEMPTION = 0x2,
 +	INTEL_GUC_ACTION_REQUEST_ENGINE_RESET = 0x3,
 +	INTEL_GUC_ACTION_ALLOCATE_DOORBELL = 0x10,
 +	INTEL_GUC_ACTION_DEALLOCATE_DOORBELL = 0x20,
 +	INTEL_GUC_ACTION_LOG_BUFFER_FILE_FLUSH_COMPLETE = 0x30,
 +	INTEL_GUC_ACTION_UK_LOG_ENABLE_LOGGING = 0x40,
 +	INTEL_GUC_ACTION_FORCE_LOG_BUFFER_FLUSH = 0x302,
 +	INTEL_GUC_ACTION_ENTER_S_STATE = 0x501,
 +	INTEL_GUC_ACTION_EXIT_S_STATE = 0x502,
 +	INTEL_GUC_ACTION_SLPC_REQUEST = 0x3003,
 +	INTEL_GUC_ACTION_SAMPLE_FORCEWAKE = 0x3005,
 +	INTEL_GUC_ACTION_AUTHENTICATE_HUC = 0x4000,
 +	INTEL_GUC_ACTION_REGISTER_COMMAND_TRANSPORT_BUFFER = 0x4505,
 +	INTEL_GUC_ACTION_DEREGISTER_COMMAND_TRANSPORT_BUFFER = 0x4506,
 +	INTEL_GUC_ACTION_LIMIT
 +};
 +
 +enum intel_guc_preempt_options {
 +	INTEL_GUC_PREEMPT_OPTION_DROP_WORK_Q = 0x4,
 +	INTEL_GUC_PREEMPT_OPTION_DROP_SUBMIT_Q = 0x8,
 +};
 +
 +enum intel_guc_report_status {
 +	INTEL_GUC_REPORT_STATUS_UNKNOWN = 0x0,
 +	INTEL_GUC_REPORT_STATUS_ACKED = 0x1,
 +	INTEL_GUC_REPORT_STATUS_ERROR = 0x2,
 +	INTEL_GUC_REPORT_STATUS_COMPLETE = 0x4,
 +};
 +
 +enum intel_guc_sleep_state_status {
 +	INTEL_GUC_SLEEP_STATE_SUCCESS = 0x1,
 +	INTEL_GUC_SLEEP_STATE_PREEMPT_TO_IDLE_FAILED = 0x2,
 +	INTEL_GUC_SLEEP_STATE_ENGINE_RESET_FAILED = 0x3
 +#define INTEL_GUC_SLEEP_STATE_INVALID_MASK 0x80000000
 +};
 +
 +#define GUC_LOG_CONTROL_LOGGING_ENABLED	(1 << 0)
 +#define GUC_LOG_CONTROL_VERBOSITY_SHIFT	4
 +#define GUC_LOG_CONTROL_VERBOSITY_MASK	(0xF << GUC_LOG_CONTROL_VERBOSITY_SHIFT)
 +#define GUC_LOG_CONTROL_DEFAULT_LOGGING	(1 << 8)
 +
 +enum intel_guc_response_status {
 +	INTEL_GUC_RESPONSE_STATUS_SUCCESS = 0x0,
 +	INTEL_GUC_RESPONSE_STATUS_GENERIC_FAIL = 0xF000,
 +};
 +
 +#define INTEL_GUC_MSG_IS_RESPONSE_SUCCESS(m) \
 +	 (typecheck(u32, (m)) && \
 +	  ((m) & (INTEL_GUC_MSG_TYPE_MASK | INTEL_GUC_MSG_CODE_MASK)) == \
 +	  ((INTEL_GUC_MSG_TYPE_RESPONSE << INTEL_GUC_MSG_TYPE_SHIFT) | \
 +	   (INTEL_GUC_RESPONSE_STATUS_SUCCESS << INTEL_GUC_MSG_CODE_SHIFT)))
 +
++=======
++>>>>>>> 572f2a5cd974 (drm/i915/guc: Update firmware to v62.0.0)
  /* This action will be programmed in C1BC - SOFT_SCRATCH_15_REG */
  enum intel_guc_recv_message {
  	INTEL_GUC_RECV_MSG_CRASH_DUMP_POSTED = BIT(1),
* Unmerged path drivers/gpu/drm/i915/gt/uc/abi/guc_actions_abi.h
* Unmerged path drivers/gpu/drm/i915/gt/uc/abi/guc_communication_ctb_abi.h
* Unmerged path drivers/gpu/drm/i915/gt/uc/abi/guc_communication_mmio_abi.h
* Unmerged path drivers/gpu/drm/i915/gt/uc/abi/guc_actions_abi.h
* Unmerged path drivers/gpu/drm/i915/gt/uc/abi/guc_communication_ctb_abi.h
* Unmerged path drivers/gpu/drm/i915/gt/uc/abi/guc_communication_mmio_abi.h
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_guc.c b/drivers/gpu/drm/i915/gt/uc/intel_guc.c
index 4545e90e3bf1..9d0c9583454c 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc.c
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc.c
@@ -228,24 +228,19 @@ static u32 guc_ctl_log_params_flags(struct intel_guc *guc)
 
 	BUILD_BUG_ON(!CRASH_BUFFER_SIZE);
 	BUILD_BUG_ON(!IS_ALIGNED(CRASH_BUFFER_SIZE, UNIT));
-	BUILD_BUG_ON(!DPC_BUFFER_SIZE);
-	BUILD_BUG_ON(!IS_ALIGNED(DPC_BUFFER_SIZE, UNIT));
-	BUILD_BUG_ON(!ISR_BUFFER_SIZE);
-	BUILD_BUG_ON(!IS_ALIGNED(ISR_BUFFER_SIZE, UNIT));
+	BUILD_BUG_ON(!DEBUG_BUFFER_SIZE);
+	BUILD_BUG_ON(!IS_ALIGNED(DEBUG_BUFFER_SIZE, UNIT));
 
 	BUILD_BUG_ON((CRASH_BUFFER_SIZE / UNIT - 1) >
 			(GUC_LOG_CRASH_MASK >> GUC_LOG_CRASH_SHIFT));
-	BUILD_BUG_ON((DPC_BUFFER_SIZE / UNIT - 1) >
-			(GUC_LOG_DPC_MASK >> GUC_LOG_DPC_SHIFT));
-	BUILD_BUG_ON((ISR_BUFFER_SIZE / UNIT - 1) >
-			(GUC_LOG_ISR_MASK >> GUC_LOG_ISR_SHIFT));
+	BUILD_BUG_ON((DEBUG_BUFFER_SIZE / UNIT - 1) >
+			(GUC_LOG_DEBUG_MASK >> GUC_LOG_DEBUG_SHIFT));
 
 	flags = GUC_LOG_VALID |
 		GUC_LOG_NOTIFY_ON_HALF_FULL |
 		FLAG |
 		((CRASH_BUFFER_SIZE / UNIT - 1) << GUC_LOG_CRASH_SHIFT) |
-		((DPC_BUFFER_SIZE / UNIT - 1) << GUC_LOG_DPC_SHIFT) |
-		((ISR_BUFFER_SIZE / UNIT - 1) << GUC_LOG_ISR_SHIFT) |
+		((DEBUG_BUFFER_SIZE / UNIT - 1) << GUC_LOG_DEBUG_SHIFT) |
 		(offset << GUC_LOG_BUF_ADDR_SHIFT);
 
 	#undef UNIT
@@ -385,29 +380,27 @@ void intel_guc_fini(struct intel_guc *guc)
 /*
  * This function implements the MMIO based host to GuC interface.
  */
-int intel_guc_send_mmio(struct intel_guc *guc, const u32 *action, u32 len,
+int intel_guc_send_mmio(struct intel_guc *guc, const u32 *request, u32 len,
 			u32 *response_buf, u32 response_buf_size)
 {
+	struct drm_i915_private *i915 = guc_to_gt(guc)->i915;
 	struct intel_uncore *uncore = guc_to_gt(guc)->uncore;
-	u32 status;
+	u32 header;
 	int i;
 	int ret;
 
 	GEM_BUG_ON(!len);
 	GEM_BUG_ON(len > guc->send_regs.count);
 
-	/* We expect only action code */
-	GEM_BUG_ON(*action & ~INTEL_GUC_MSG_CODE_MASK);
-
-	/* If CT is available, we expect to use MMIO only during init/fini */
-	GEM_BUG_ON(*action != INTEL_GUC_ACTION_REGISTER_COMMAND_TRANSPORT_BUFFER &&
-		   *action != INTEL_GUC_ACTION_DEREGISTER_COMMAND_TRANSPORT_BUFFER);
+	GEM_BUG_ON(FIELD_GET(GUC_HXG_MSG_0_ORIGIN, request[0]) != GUC_HXG_ORIGIN_HOST);
+	GEM_BUG_ON(FIELD_GET(GUC_HXG_MSG_0_TYPE, request[0]) != GUC_HXG_TYPE_REQUEST);
 
 	mutex_lock(&guc->send_mutex);
 	intel_uncore_forcewake_get(uncore, guc->send_regs.fw_domains);
 
+retry:
 	for (i = 0; i < len; i++)
-		intel_uncore_write(uncore, guc_send_reg(guc, i), action[i]);
+		intel_uncore_write(uncore, guc_send_reg(guc, i), request[i]);
 
 	intel_uncore_posting_read(uncore, guc_send_reg(guc, i - 1));
 
@@ -419,30 +412,74 @@ int intel_guc_send_mmio(struct intel_guc *guc, const u32 *action, u32 len,
 	 */
 	ret = __intel_wait_for_register_fw(uncore,
 					   guc_send_reg(guc, 0),
-					   INTEL_GUC_MSG_TYPE_MASK,
-					   INTEL_GUC_MSG_TYPE_RESPONSE <<
-					   INTEL_GUC_MSG_TYPE_SHIFT,
-					   10, 10, &status);
-	/* If GuC explicitly returned an error, convert it to -EIO */
-	if (!ret && !INTEL_GUC_MSG_IS_RESPONSE_SUCCESS(status))
-		ret = -EIO;
+					   GUC_HXG_MSG_0_ORIGIN,
+					   FIELD_PREP(GUC_HXG_MSG_0_ORIGIN,
+						      GUC_HXG_ORIGIN_GUC),
+					   10, 10, &header);
+	if (unlikely(ret)) {
+timeout:
+		drm_err(&i915->drm, "mmio request %#x: no reply %x\n",
+			request[0], header);
+		goto out;
+	}
 
-	if (ret) {
-		DRM_ERROR("MMIO: GuC action %#x failed with error %d %#x\n",
-			  action[0], ret, status);
+	if (FIELD_GET(GUC_HXG_MSG_0_TYPE, header) == GUC_HXG_TYPE_NO_RESPONSE_BUSY) {
+#define done ({ header = intel_uncore_read(uncore, guc_send_reg(guc, 0)); \
+		FIELD_GET(GUC_HXG_MSG_0_ORIGIN, header) != GUC_HXG_ORIGIN_GUC || \
+		FIELD_GET(GUC_HXG_MSG_0_TYPE, header) != GUC_HXG_TYPE_NO_RESPONSE_BUSY; })
+
+		ret = wait_for(done, 1000);
+		if (unlikely(ret))
+			goto timeout;
+		if (unlikely(FIELD_GET(GUC_HXG_MSG_0_ORIGIN, header) !=
+				       GUC_HXG_ORIGIN_GUC))
+			goto proto;
+#undef done
+	}
+
+	if (FIELD_GET(GUC_HXG_MSG_0_TYPE, header) == GUC_HXG_TYPE_NO_RESPONSE_RETRY) {
+		u32 reason = FIELD_GET(GUC_HXG_RETRY_MSG_0_REASON, header);
+
+		drm_dbg(&i915->drm, "mmio request %#x: retrying, reason %u\n",
+			request[0], reason);
+		goto retry;
+	}
+
+	if (FIELD_GET(GUC_HXG_MSG_0_TYPE, header) == GUC_HXG_TYPE_RESPONSE_FAILURE) {
+		u32 hint = FIELD_GET(GUC_HXG_FAILURE_MSG_0_HINT, header);
+		u32 error = FIELD_GET(GUC_HXG_FAILURE_MSG_0_ERROR, header);
+
+		drm_err(&i915->drm, "mmio request %#x: failure %x/%u\n",
+			request[0], error, hint);
+		ret = -ENXIO;
+		goto out;
+	}
+
+	if (FIELD_GET(GUC_HXG_MSG_0_TYPE, header) != GUC_HXG_TYPE_RESPONSE_SUCCESS) {
+proto:
+		drm_err(&i915->drm, "mmio request %#x: unexpected reply %#x\n",
+			request[0], header);
+		ret = -EPROTO;
 		goto out;
 	}
 
 	if (response_buf) {
-		int count = min(response_buf_size, guc->send_regs.count - 1);
+		int count = min(response_buf_size, guc->send_regs.count);
 
-		for (i = 0; i < count; i++)
+		GEM_BUG_ON(!count);
+
+		response_buf[0] = header;
+
+		for (i = 1; i < count; i++)
 			response_buf[i] = intel_uncore_read(uncore,
-							    guc_send_reg(guc, i + 1));
-	}
+							    guc_send_reg(guc, i));
 
-	/* Use data from the GuC response as our return value */
-	ret = INTEL_GUC_MSG_TO_DATA(status);
+		/* Use number of copied dwords as our return value */
+		ret = count;
+	} else {
+		/* Use data from the GuC response as our return value */
+		ret = FIELD_GET(GUC_HXG_RESPONSE_MSG_0_DATA0, header);
+	}
 
 out:
 	intel_uncore_forcewake_put(uncore, guc->send_regs.fw_domains);
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_guc_ads.c b/drivers/gpu/drm/i915/gt/uc/intel_guc_ads.c
index 17526717368c..203c0a9ce09b 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc_ads.c
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc_ads.c
@@ -23,10 +23,6 @@
  *      +---------------------------------------+
  *      | guc_gt_system_info                    |
  *      +---------------------------------------+
- *      | guc_clients_info                      |
- *      +---------------------------------------+
- *      | guc_ct_pool_entry[size]               |
- *      +---------------------------------------+
  *      | padding                               |
  *      +---------------------------------------+ <== 4K aligned
  *      | private data                          |
@@ -38,8 +34,6 @@ struct __guc_ads_blob {
 	struct guc_ads ads;
 	struct guc_policies policies;
 	struct guc_gt_system_info system_info;
-	struct guc_clients_info clients_info;
-	struct guc_ct_pool_entry ct_pool[GUC_CT_POOL_SIZE];
 } __packed;
 
 static u32 guc_ads_private_data_size(struct intel_guc *guc)
@@ -58,38 +52,15 @@ static u32 guc_ads_blob_size(struct intel_guc *guc)
 	       guc_ads_private_data_size(guc);
 }
 
-static void guc_policy_init(struct guc_policy *policy)
-{
-	policy->execution_quantum = POLICY_DEFAULT_EXECUTION_QUANTUM_US;
-	policy->preemption_time = POLICY_DEFAULT_PREEMPTION_TIME_US;
-	policy->fault_time = POLICY_DEFAULT_FAULT_TIME_US;
-	policy->policy_flags = 0;
-}
-
 static void guc_policies_init(struct guc_policies *policies)
 {
-	struct guc_policy *policy;
-	u32 p, i;
-
-	policies->dpc_promote_time = POLICY_DEFAULT_DPC_PROMOTE_TIME_US;
-	policies->max_num_work_items = POLICY_MAX_NUM_WI;
-
-	for (p = 0; p < GUC_CLIENT_PRIORITY_NUM; p++) {
-		for (i = 0; i < GUC_MAX_ENGINE_CLASSES; i++) {
-			policy = &policies->policy[p][i];
-
-			guc_policy_init(policy);
-		}
-	}
-
+	policies->dpc_promote_time = GLOBAL_POLICY_DEFAULT_DPC_PROMOTE_TIME_US;
+	policies->max_num_work_items = GLOBAL_POLICY_MAX_NUM_WI;
+	/* Disable automatic resets as not yet supported. */
+	policies->global_flags = GLOBAL_POLICY_DISABLE_ENGINE_RESET;
 	policies->is_valid = 1;
 }
 
-static void guc_ct_pool_entries_init(struct guc_ct_pool_entry *pool, u32 num)
-{
-	memset(pool, 0, num * sizeof(*pool));
-}
-
 static void guc_mapping_table_init(struct intel_gt *gt,
 				   struct guc_gt_system_info *system_info)
 {
@@ -174,17 +145,9 @@ static void __guc_ads_init(struct intel_guc *guc)
 
 	base = intel_guc_ggtt_offset(guc, guc->ads_vma);
 
-	/* Clients info  */
-	guc_ct_pool_entries_init(blob->ct_pool, ARRAY_SIZE(blob->ct_pool));
-
-	blob->clients_info.clients_num = 1;
-	blob->clients_info.ct_pool_addr = base + ptr_offset(blob, ct_pool);
-	blob->clients_info.ct_pool_count = ARRAY_SIZE(blob->ct_pool);
-
 	/* ADS */
 	blob->ads.scheduler_policies = base + ptr_offset(blob, policies);
 	blob->ads.gt_system_info = base + ptr_offset(blob, system_info);
-	blob->ads.clients_info = base + ptr_offset(blob, clients_info);
 
 	/* Private Data */
 	blob->ads.private_data = base + guc_ads_private_data_offset(guc);
* Unmerged path drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c
* Unmerged path drivers/gpu/drm/i915/gt/uc/intel_guc_ct.h
* Unmerged path drivers/gpu/drm/i915/gt/uc/intel_guc_fwif.h
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_guc_log.c b/drivers/gpu/drm/i915/gt/uc/intel_guc_log.c
index c92f2c056db4..6628c7757834 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc_log.c
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc_log.c
@@ -197,10 +197,8 @@ static bool guc_check_log_buf_overflow(struct intel_guc_log *log,
 static unsigned int guc_get_log_buffer_size(enum guc_log_buffer_type type)
 {
 	switch (type) {
-	case GUC_ISR_LOG_BUFFER:
-		return ISR_BUFFER_SIZE;
-	case GUC_DPC_LOG_BUFFER:
-		return DPC_BUFFER_SIZE;
+	case GUC_DEBUG_LOG_BUFFER:
+		return DEBUG_BUFFER_SIZE;
 	case GUC_CRASH_DUMP_LOG_BUFFER:
 		return CRASH_BUFFER_SIZE;
 	default:
@@ -245,7 +243,7 @@ static void guc_read_update_log_buffer(struct intel_guc_log *log)
 	src_data += PAGE_SIZE;
 	dst_data += PAGE_SIZE;
 
-	for (type = GUC_ISR_LOG_BUFFER; type < GUC_MAX_LOG_BUFFER; type++) {
+	for (type = GUC_DEBUG_LOG_BUFFER; type < GUC_MAX_LOG_BUFFER; type++) {
 		/*
 		 * Make a copy of the state structure, inside GuC log buffer
 		 * (which is uncached mapped), on the stack to avoid reading
@@ -463,21 +461,16 @@ int intel_guc_log_create(struct intel_guc_log *log)
 	 *  +===============================+ 00B
 	 *  |    Crash dump state header    |
 	 *  +-------------------------------+ 32B
-	 *  |       DPC state header        |
+	 *  |      Debug state header       |
 	 *  +-------------------------------+ 64B
-	 *  |       ISR state header        |
-	 *  +-------------------------------+ 96B
 	 *  |                               |
 	 *  +===============================+ PAGE_SIZE (4KB)
 	 *  |        Crash Dump logs        |
 	 *  +===============================+ + CRASH_SIZE
-	 *  |           DPC logs            |
-	 *  +===============================+ + DPC_SIZE
-	 *  |           ISR logs            |
-	 *  +===============================+ + ISR_SIZE
+	 *  |          Debug logs           |
+	 *  +===============================+ + DEBUG_SIZE
 	 */
-	guc_log_size = PAGE_SIZE + CRASH_BUFFER_SIZE + DPC_BUFFER_SIZE +
-			ISR_BUFFER_SIZE;
+	guc_log_size = PAGE_SIZE + CRASH_BUFFER_SIZE + DEBUG_BUFFER_SIZE;
 
 	vma = intel_guc_allocate_vma(guc, guc_log_size);
 	if (IS_ERR(vma)) {
@@ -675,10 +668,8 @@ static const char *
 stringify_guc_log_type(enum guc_log_buffer_type type)
 {
 	switch (type) {
-	case GUC_ISR_LOG_BUFFER:
-		return "ISR";
-	case GUC_DPC_LOG_BUFFER:
-		return "DPC";
+	case GUC_DEBUG_LOG_BUFFER:
+		return "DEBUG";
 	case GUC_CRASH_DUMP_LOG_BUFFER:
 		return "CRASH";
 	default:
@@ -708,7 +699,7 @@ void intel_guc_log_info(struct intel_guc_log *log, struct drm_printer *p)
 
 	drm_printf(p, "\tRelay full count: %u\n", log->relay.full_count);
 
-	for (type = GUC_ISR_LOG_BUFFER; type < GUC_MAX_LOG_BUFFER; type++) {
+	for (type = GUC_DEBUG_LOG_BUFFER; type < GUC_MAX_LOG_BUFFER; type++) {
 		drm_printf(p, "\t%s:\tflush count %10u, overflow count %10u\n",
 			   stringify_guc_log_type(type),
 			   log->stats[type].flush,
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_guc_log.h b/drivers/gpu/drm/i915/gt/uc/intel_guc_log.h
index 11fccd0b2294..ac1ee1d5ce10 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_guc_log.h
+++ b/drivers/gpu/drm/i915/gt/uc/intel_guc_log.h
@@ -17,12 +17,10 @@ struct intel_guc;
 
 #ifdef CONFIG_DRM_I915_DEBUG_GUC
 #define CRASH_BUFFER_SIZE	SZ_2M
-#define DPC_BUFFER_SIZE		SZ_8M
-#define ISR_BUFFER_SIZE		SZ_8M
+#define DEBUG_BUFFER_SIZE	SZ_16M
 #else
 #define CRASH_BUFFER_SIZE	SZ_8K
-#define DPC_BUFFER_SIZE		SZ_32K
-#define ISR_BUFFER_SIZE		SZ_32K
+#define DEBUG_BUFFER_SIZE	SZ_64K
 #endif
 
 /*
diff --git a/drivers/gpu/drm/i915/gt/uc/intel_uc_fw.c b/drivers/gpu/drm/i915/gt/uc/intel_uc_fw.c
index 984fa79e0fa7..8d365a359bae 100644
--- a/drivers/gpu/drm/i915/gt/uc/intel_uc_fw.c
+++ b/drivers/gpu/drm/i915/gt/uc/intel_uc_fw.c
@@ -48,19 +48,19 @@ void intel_uc_fw_change_status(struct intel_uc_fw *uc_fw,
  * firmware as TGL.
  */
 #define INTEL_UC_FIRMWARE_DEFS(fw_def, guc_def, huc_def) \
-	fw_def(ALDERLAKE_S, 0, guc_def(tgl, 49, 0, 1), huc_def(tgl,  7, 5, 0)) \
-	fw_def(ROCKETLAKE,  0, guc_def(tgl, 49, 0, 1), huc_def(tgl,  7, 5, 0)) \
-	fw_def(TIGERLAKE,   0, guc_def(tgl, 49, 0, 1), huc_def(tgl,  7, 5, 0)) \
-	fw_def(JASPERLAKE,  0, guc_def(ehl, 49, 0, 1), huc_def(ehl,  9, 0, 0)) \
-	fw_def(ELKHARTLAKE, 0, guc_def(ehl, 49, 0, 1), huc_def(ehl,  9, 0, 0)) \
-	fw_def(ICELAKE,     0, guc_def(icl, 49, 0, 1), huc_def(icl,  9, 0, 0)) \
-	fw_def(COMETLAKE,   5, guc_def(cml, 49, 0, 1), huc_def(cml,  4, 0, 0)) \
-	fw_def(COMETLAKE,   0, guc_def(kbl, 49, 0, 1), huc_def(kbl,  4, 0, 0)) \
-	fw_def(COFFEELAKE,  0, guc_def(kbl, 49, 0, 1), huc_def(kbl,  4, 0, 0)) \
-	fw_def(GEMINILAKE,  0, guc_def(glk, 49, 0, 1), huc_def(glk,  4, 0, 0)) \
-	fw_def(KABYLAKE,    0, guc_def(kbl, 49, 0, 1), huc_def(kbl,  4, 0, 0)) \
-	fw_def(BROXTON,     0, guc_def(bxt, 49, 0, 1), huc_def(bxt,  2, 0, 0)) \
-	fw_def(SKYLAKE,     0, guc_def(skl, 49, 0, 1), huc_def(skl,  2, 0, 0))
+	fw_def(ALDERLAKE_S, 0, guc_def(tgl, 62, 0, 0), huc_def(tgl,  7, 5, 0)) \
+	fw_def(ROCKETLAKE,  0, guc_def(tgl, 62, 0, 0), huc_def(tgl,  7, 5, 0)) \
+	fw_def(TIGERLAKE,   0, guc_def(tgl, 62, 0, 0), huc_def(tgl,  7, 5, 0)) \
+	fw_def(JASPERLAKE,  0, guc_def(ehl, 62, 0, 0), huc_def(ehl,  9, 0, 0)) \
+	fw_def(ELKHARTLAKE, 0, guc_def(ehl, 62, 0, 0), huc_def(ehl,  9, 0, 0)) \
+	fw_def(ICELAKE,     0, guc_def(icl, 62, 0, 0), huc_def(icl,  9, 0, 0)) \
+	fw_def(COMETLAKE,   5, guc_def(cml, 62, 0, 0), huc_def(cml,  4, 0, 0)) \
+	fw_def(COMETLAKE,   0, guc_def(kbl, 62, 0, 0), huc_def(kbl,  4, 0, 0)) \
+	fw_def(COFFEELAKE,  0, guc_def(kbl, 62, 0, 0), huc_def(kbl,  4, 0, 0)) \
+	fw_def(GEMINILAKE,  0, guc_def(glk, 62, 0, 0), huc_def(glk,  4, 0, 0)) \
+	fw_def(KABYLAKE,    0, guc_def(kbl, 62, 0, 0), huc_def(kbl,  4, 0, 0)) \
+	fw_def(BROXTON,     0, guc_def(bxt, 62, 0, 0), huc_def(bxt,  2, 0, 0)) \
+	fw_def(SKYLAKE,     0, guc_def(skl, 62, 0, 0), huc_def(skl,  2, 0, 0))
 
 #define __MAKE_UC_FW_PATH(prefix_, name_, major_, minor_, patch_) \
 	"i915/" \
