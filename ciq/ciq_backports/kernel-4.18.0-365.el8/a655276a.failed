KVM: SEV: Fall back to vmalloc for SEV-ES scratch area if necessary

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-365.el8
commit-author Sean Christopherson <seanjc@google.com>
commit a655276a594978a4887520c1241cf6ac49d6230b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-365.el8/a655276a.failed

Use kvzalloc() to allocate KVM's buffer for SEV-ES's GHCB scratch area so
that KVM falls back to __vmalloc() if physically contiguous memory isn't
available.  The buffer is purely a KVM software construct, i.e. there's
no need for it to be physically contiguous.

	Cc: Tom Lendacky <thomas.lendacky@amd.com>
	Signed-off-by: Sean Christopherson <seanjc@google.com>
Message-Id: <20211109222350.2266045-3-seanjc@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit a655276a594978a4887520c1241cf6ac49d6230b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/svm/sev.c
diff --cc arch/x86/kvm/svm/sev.c
index 2917da934694,94bde57df72e..000000000000
--- a/arch/x86/kvm/svm/sev.c
+++ b/arch/x86/kvm/svm/sev.c
@@@ -2039,11 -2256,11 +2039,16 @@@ void sev_free_vcpu(struct kvm_vcpu *vcp
  	svm = to_svm(vcpu);
  
  	if (vcpu->arch.guest_state_protected)
 -		sev_flush_guest_memory(svm, svm->sev_es.vmsa, PAGE_SIZE);
 -	__free_page(virt_to_page(svm->sev_es.vmsa));
 +		sev_flush_guest_memory(svm, svm->vmsa, PAGE_SIZE);
 +	__free_page(virt_to_page(svm->vmsa));
  
++<<<<<<< HEAD
 +	if (svm->ghcb_sa_free)
 +		kfree(svm->ghcb_sa);
++=======
+ 	if (svm->sev_es.ghcb_sa_free)
+ 		kvfree(svm->sev_es.ghcb_sa);
++>>>>>>> a655276a5949 (KVM: SEV: Fall back to vmalloc for SEV-ES scratch area if necessary)
  }
  
  static void dump_ghcb(struct vcpu_svm *svm)
@@@ -2268,19 -2485,20 +2273,25 @@@ void sev_es_unmap_ghcb(struct vcpu_svm 
  		 * buffer that, depending on the operation performed, may
  		 * need to be synced, then freed.
  		 */
 -		if (svm->sev_es.ghcb_sa_sync) {
 +		if (svm->ghcb_sa_sync) {
  			kvm_write_guest(svm->vcpu.kvm,
 -					ghcb_get_sw_scratch(svm->sev_es.ghcb),
 -					svm->sev_es.ghcb_sa,
 -					svm->sev_es.ghcb_sa_len);
 -			svm->sev_es.ghcb_sa_sync = false;
 +					ghcb_get_sw_scratch(svm->ghcb),
 +					svm->ghcb_sa, svm->ghcb_sa_len);
 +			svm->ghcb_sa_sync = false;
  		}
  
++<<<<<<< HEAD
 +		kfree(svm->ghcb_sa);
 +		svm->ghcb_sa = NULL;
 +		svm->ghcb_sa_free = false;
++=======
+ 		kvfree(svm->sev_es.ghcb_sa);
+ 		svm->sev_es.ghcb_sa = NULL;
+ 		svm->sev_es.ghcb_sa_free = false;
++>>>>>>> a655276a5949 (KVM: SEV: Fall back to vmalloc for SEV-ES scratch area if necessary)
  	}
  
 -	trace_kvm_vmgexit_exit(svm->vcpu.vcpu_id, svm->sev_es.ghcb);
 +	trace_kvm_vmgexit_exit(svm->vcpu.vcpu_id, svm->ghcb);
  
  	sev_es_sync_to_ghcb(svm);
  
* Unmerged path arch/x86/kvm/svm/sev.c
