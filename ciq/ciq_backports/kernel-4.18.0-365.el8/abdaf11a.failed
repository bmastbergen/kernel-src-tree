dma-mapping: add (back) arch_dma_mark_clean for ia64

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-365.el8
commit-author Christoph Hellwig <hch@lst.de>
commit abdaf11ac18925ce8cc229e62e35b342d548ece2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-365.el8/abdaf11a.failed

Add back a hook to optimize dcache flushing after reading executable
code using DMA.  This gets ia64 out of the business of pretending to
be dma incoherent just for this optimization.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
(cherry picked from commit abdaf11ac18925ce8cc229e62e35b342d548ece2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/ia64/Kconfig
#	arch/ia64/kernel/dma-mapping.c
#	arch/ia64/mm/init.c
#	kernel/dma/Kconfig
diff --cc arch/ia64/Kconfig
index d6f777303de9,513ba0c5d336..000000000000
--- a/arch/ia64/Kconfig
+++ b/arch/ia64/Kconfig
@@@ -12,13 -8,19 +12,14 @@@ menu "Processor type and features
  
  config IA64
  	bool
+ 	select ARCH_HAS_DMA_MARK_CLEAN
  	select ARCH_MIGHT_HAVE_PC_PARPORT
  	select ARCH_MIGHT_HAVE_PC_SERIO
 -	select ACPI
 -	select ACPI_NUMA if NUMA
 -	select ARCH_SUPPORTS_ACPI
 +	select PCI if (!IA64_HP_SIM)
 +	select ACPI if (!IA64_HP_SIM)
 +	select ARCH_SUPPORTS_ACPI if (!IA64_HP_SIM)
  	select ACPI_SYSTEM_POWER_STATES_SUPPORT if ACPI
  	select ARCH_MIGHT_HAVE_ACPI_PDC if ACPI
 -	select FORCE_PCI
 -	select PCI_DOMAINS if PCI
 -	select PCI_MSI
 -	select PCI_SYSCALL if PCI
 -	select HAVE_ASM_MODVERSIONS
  	select HAVE_UNSTABLE_SCHED_CLOCK
  	select HAVE_EXIT_THREAD
  	select HAVE_IDE
@@@ -30,12 -32,8 +31,15 @@@
  	select HAVE_FUNCTION_TRACER
  	select TTY
  	select HAVE_ARCH_TRACEHOOK
 +	select HAVE_MEMBLOCK_NODE_MAP
  	select HAVE_VIRT_CPU_ACCOUNTING
++<<<<<<< HEAD
 +	select ARCH_HAS_DMA_MARK_CLEAN
 +	select ARCH_HAS_SG_CHAIN
++=======
++>>>>>>> abdaf11ac189 (dma-mapping: add (back) arch_dma_mark_clean for ia64)
  	select VIRT_TO_BUS
 +	select ARCH_DISCARD_MEMBLOCK
  	select GENERIC_IRQ_PROBE
  	select GENERIC_PENDING_IRQ if SMP
  	select GENERIC_IRQ_SHOW
diff --cc arch/ia64/kernel/dma-mapping.c
index 7a471d8d67d4,f640ed6fe1d5..000000000000
--- a/arch/ia64/kernel/dma-mapping.c
+++ b/arch/ia64/kernel/dma-mapping.c
@@@ -1,6 -1,5 +1,9 @@@
  // SPDX-License-Identifier: GPL-2.0
  #include <linux/dma-mapping.h>
++<<<<<<< HEAD
 +#include <linux/swiotlb.h>
++=======
++>>>>>>> abdaf11ac189 (dma-mapping: add (back) arch_dma_mark_clean for ia64)
  #include <linux/export.h>
  
  /* Set this to 1 if there is a HW IOMMU in the system */
@@@ -8,17 -7,3 +11,20 @@@ int iommu_detected __read_mostly
  
  const struct dma_map_ops *dma_ops;
  EXPORT_SYMBOL(dma_ops);
++<<<<<<< HEAD
 +
 +const struct dma_map_ops *dma_get_ops(struct device *dev)
 +{
 +	return dma_ops;
 +}
 +EXPORT_SYMBOL(dma_get_ops);
 +
 +#ifdef CONFIG_SWIOTLB
 +void __init swiotlb_dma_init(void)
 +{
 +	dma_ops = &swiotlb_dma_ops;
 +	swiotlb_init(1);
 +}
 +#endif
++=======
++>>>>>>> abdaf11ac189 (dma-mapping: add (back) arch_dma_mark_clean for ia64)
diff --cc arch/ia64/mm/init.c
index 5ab64d9d3462,02e5aa08294e..000000000000
--- a/arch/ia64/mm/init.c
+++ b/arch/ia64/mm/init.c
@@@ -71,18 -73,13 +71,22 @@@ __ia64_sync_icache_dcache (pte_t pte
   * DMA can be marked as "clean" so that lazy_mmu_prot_update() doesn't have to
   * flush them when they get mapped into an executable vm-area.
   */
++<<<<<<< HEAD
 +void
 +dma_mark_clean(void *addr, size_t size)
++=======
+ void arch_dma_mark_clean(phys_addr_t paddr, size_t size)
++>>>>>>> abdaf11ac189 (dma-mapping: add (back) arch_dma_mark_clean for ia64)
  {
 -	unsigned long pfn = PHYS_PFN(paddr);
 -
 -	do {
 -		set_bit(PG_arch_1, &pfn_to_page(pfn)->flags);
 -	} while (++pfn <= PHYS_PFN(paddr + size - 1));
 +	unsigned long pg_addr, end;
 +
 +	pg_addr = PAGE_ALIGN((unsigned long) addr);
 +	end = (unsigned long) addr + size;
 +	while (pg_addr + PAGE_SIZE <= end) {
 +		struct page *page = virt_to_page(pg_addr);
 +		set_bit(PG_arch_1, &page->flags);
 +		pg_addr += PAGE_SIZE;
 +	}
  }
  
  inline void
diff --cc kernel/dma/Kconfig
index 35c60ac3ee93,281785feb874..000000000000
--- a/kernel/dma/Kconfig
+++ b/kernel/dma/Kconfig
@@@ -39,7 -44,13 +39,17 @@@ config ARCH_HAS_DMA_SET_MAS
  config ARCH_HAS_DMA_WRITE_COMBINE
  	bool
  
++<<<<<<< HEAD
 +config HAVE_GENERIC_DMA_COHERENT
++=======
+ #
+ # Select if the architectures provides the arch_dma_mark_clean hook
+ #
+ config ARCH_HAS_DMA_MARK_CLEAN
+ 	bool
+ 
+ config DMA_DECLARE_COHERENT
++>>>>>>> abdaf11ac189 (dma-mapping: add (back) arch_dma_mark_clean for ia64)
  	bool
  
  config ARCH_HAS_SETUP_DMA_OPS
* Unmerged path arch/ia64/Kconfig
* Unmerged path arch/ia64/kernel/dma-mapping.c
* Unmerged path arch/ia64/mm/init.c
diff --git a/include/linux/dma-direct.h b/include/linux/dma-direct.h
index 28fdd6ebdd10..571c1320e7c8 100644
--- a/include/linux/dma-direct.h
+++ b/include/linux/dma-direct.h
@@ -148,6 +148,9 @@ static inline void dma_direct_sync_single_for_cpu(struct device *dev,
 
 	if (unlikely(is_swiotlb_buffer(paddr)))
 		swiotlb_tbl_sync_single(dev, paddr, size, dir, SYNC_FOR_CPU);
+
+	if (dir == DMA_FROM_DEVICE)
+		arch_dma_mark_clean(paddr, size);
 }
 
 static inline dma_addr_t dma_direct_map_page(struct device *dev,
diff --git a/include/linux/dma-noncoherent.h b/include/linux/dma-noncoherent.h
index 73252358824d..fe76b1099122 100644
--- a/include/linux/dma-noncoherent.h
+++ b/include/linux/dma-noncoherent.h
@@ -92,6 +92,14 @@ static inline void arch_dma_prep_coherent(struct page *page, size_t size)
 }
 #endif /* CONFIG_ARCH_HAS_DMA_PREP_COHERENT */
 
+#ifdef CONFIG_ARCH_HAS_DMA_MARK_CLEAN
+void arch_dma_mark_clean(phys_addr_t paddr, size_t size);
+#else
+static inline void arch_dma_mark_clean(phys_addr_t paddr, size_t size)
+{
+}
+#endif /* ARCH_HAS_DMA_MARK_CLEAN */
+
 void *arch_dma_set_uncached(void *addr, size_t size);
 void arch_dma_clear_uncached(void *addr, size_t size);
 
* Unmerged path kernel/dma/Kconfig
diff --git a/kernel/dma/direct.c b/kernel/dma/direct.c
index 7d488b64b9de..ade77d5e125d 100644
--- a/kernel/dma/direct.c
+++ b/kernel/dma/direct.c
@@ -367,6 +367,9 @@ void dma_direct_sync_sg_for_cpu(struct device *dev,
 		if (unlikely(is_swiotlb_buffer(paddr)))
 			swiotlb_tbl_sync_single(dev, paddr, sg->length, dir,
 					SYNC_FOR_CPU);
+
+		if (dir == DMA_FROM_DEVICE)
+			arch_dma_mark_clean(paddr, sg->length);
 	}
 
 	if (!dev_is_dma_coherent(dev))
