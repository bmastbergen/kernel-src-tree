arm64: Fix kcore macros after 52-bit virtual addressing fallout

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-365.el8
commit-author Chris von Recklinghausen <crecklin@redhat.com>
commit 86109a691a454e08cbe0356400268cb2a81f1997
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-365.el8/86109a69.failed

We export the entire kernel address space (i.e. the whole of the TTBR1
address range) via /proc/kcore. The kc_vaddr_to_offset() and
kc_offset_to_vaddr() macros are intended to convert between a kernel
virtual address and its offset relative to the start of the TTBR1
address space.

Prior to commit:

  14c127c957c1c607 ("arm64: mm: Flip kernel VA space")

... the offset was calculated relative to VA_START, which at the time
was the start of the TTBR1 address space. At this time, PAGE_OFFSET
pointed to the high half of the TTBR1 address space where arm64's
linear map lived.

That commit swapped the position of VA_START and PAGE_OFFSET, but
failed to update kc_vaddr_to_offset() or kc_offset_to_vaddr(), so
since then the two macros behave incorrectly.

Note that VA_START was subsequently renamed to PAGE_END in commit:

  77ad4ce69321abbe ("arm64: memory: rename VA_START to PAGE_END")

As the generic implementations of the two macros calculate the offset
relative to PAGE_OFFSET (which is now the start of the TTBR1 address
space), we can delete the arm64 implementation and use those.

Fixes: 14c127c957c1c607 ("arm64: mm: Flip kernel VA space")
	Reviewed-by: James Morse <james.morse@arm.com>
	Reviewed-by: Mark Rutland <mark.rutland@arm.com>
	Signed-off-by: Chris von Recklinghausen <crecklin@redhat.com>
	Signed-off-by: Will Deacon <will@kernel.org>
(cherry picked from commit 86109a691a454e08cbe0356400268cb2a81f1997)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/pgtable.h
diff --cc arch/arm64/include/asm/pgtable.h
index d4a2e93735be,8330810f699e..000000000000
--- a/arch/arm64/include/asm/pgtable.h
+++ b/arch/arm64/include/asm/pgtable.h
@@@ -827,9 -876,6 +827,12 @@@ static inline void update_mmu_cache(str
  
  #define update_mmu_cache_pmd(vma, address, pmd) do { } while (0)
  
++<<<<<<< HEAD
 +#define kc_vaddr_to_offset(v)	((v) & ~VA_START)
 +#define kc_offset_to_vaddr(o)	((o) | VA_START)
 +
++=======
++>>>>>>> 86109a691a45 (arm64: Fix kcore macros after 52-bit virtual addressing fallout)
  #ifdef CONFIG_ARM64_PA_BITS_52
  #define phys_to_ttbr(addr)	(((addr) | ((addr) >> 46)) & TTBR_BADDR_MASK_52)
  #else
* Unmerged path arch/arm64/include/asm/pgtable.h
