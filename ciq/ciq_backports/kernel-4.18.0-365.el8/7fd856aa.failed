swiotlb: Update is_swiotlb_buffer to add a struct device argument

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-365.el8
commit-author Claire Chang <tientzu@chromium.org>
commit 7fd856aa7f4261ddac62ea59d8383fef22a0690e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-365.el8/7fd856aa.failed

Update is_swiotlb_buffer to add a struct device argument. This will be
useful later to allow for different pools.

	Signed-off-by: Claire Chang <tientzu@chromium.org>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Tested-by: Stefano Stabellini <sstabellini@kernel.org>
	Tested-by: Will Deacon <will@kernel.org>
	Acked-by: Stefano Stabellini <sstabellini@kernel.org>
	Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
(cherry picked from commit 7fd856aa7f4261ddac62ea59d8383fef22a0690e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/dma-iommu.c
#	include/linux/swiotlb.h
#	kernel/dma/direct.c
#	kernel/dma/direct.h
diff --cc drivers/iommu/dma-iommu.c
index 7a9d033bfda4,4e34e8b26579..000000000000
--- a/drivers/iommu/dma-iommu.c
+++ b/drivers/iommu/dma-iommu.c
@@@ -517,9 -506,8 +517,14 @@@ static void __iommu_dma_unmap_swiotlb(s
  
  	__iommu_dma_unmap(dev, dma_addr, size);
  
++<<<<<<< HEAD
 +	if (unlikely(is_swiotlb_buffer(phys)))
 +		swiotlb_tbl_unmap_single(dev, phys, size,
 +				iova_align(iovad, size), dir, attrs);
++=======
+ 	if (unlikely(is_swiotlb_buffer(dev, phys)))
+ 		swiotlb_tbl_unmap_single(dev, phys, size, dir, attrs);
++>>>>>>> 7fd856aa7f42 (swiotlb: Update is_swiotlb_buffer to add a struct device argument)
  }
  
  static dma_addr_t __iommu_dma_map(struct device *dev, phys_addr_t phys,
@@@ -589,10 -577,8 +594,15 @@@ static dma_addr_t __iommu_dma_map_swiot
  	}
  
  	iova = __iommu_dma_map(dev, phys, aligned_size, prot, dma_mask);
++<<<<<<< HEAD
 +	if ((iova == DMA_MAPPING_ERROR) && is_swiotlb_buffer(phys))
 +		swiotlb_tbl_unmap_single(dev, phys, org_size,
 +				aligned_size, dir, attrs);
 +
++=======
+ 	if (iova == DMA_MAPPING_ERROR && is_swiotlb_buffer(dev, phys))
+ 		swiotlb_tbl_unmap_single(dev, phys, org_size, dir, attrs);
++>>>>>>> 7fd856aa7f42 (swiotlb: Update is_swiotlb_buffer to add a struct device argument)
  	return iova;
  }
  
@@@ -798,8 -783,8 +808,13 @@@ static void iommu_dma_sync_single_for_c
  	if (!dev_is_dma_coherent(dev))
  		arch_sync_dma_for_cpu(phys, size, dir);
  
++<<<<<<< HEAD
 +	if (is_swiotlb_buffer(phys))
 +		swiotlb_tbl_sync_single(dev, phys, size, dir, SYNC_FOR_CPU);
++=======
+ 	if (is_swiotlb_buffer(dev, phys))
+ 		swiotlb_sync_single_for_cpu(dev, phys, size, dir);
++>>>>>>> 7fd856aa7f42 (swiotlb: Update is_swiotlb_buffer to add a struct device argument)
  }
  
  static void iommu_dma_sync_single_for_device(struct device *dev,
@@@ -811,8 -796,8 +826,13 @@@
  		return;
  
  	phys = iommu_iova_to_phys(iommu_get_dma_domain(dev), dma_handle);
++<<<<<<< HEAD
 +	if (is_swiotlb_buffer(phys))
 +		swiotlb_tbl_sync_single(dev, phys, size, dir, SYNC_FOR_DEVICE);
++=======
+ 	if (is_swiotlb_buffer(dev, phys))
+ 		swiotlb_sync_single_for_device(dev, phys, size, dir);
++>>>>>>> 7fd856aa7f42 (swiotlb: Update is_swiotlb_buffer to add a struct device argument)
  
  	if (!dev_is_dma_coherent(dev))
  		arch_sync_dma_for_device(phys, size, dir);
@@@ -832,9 -817,9 +852,15 @@@ static void iommu_dma_sync_sg_for_cpu(s
  		if (!dev_is_dma_coherent(dev))
  			arch_sync_dma_for_cpu(sg_phys(sg), sg->length, dir);
  
++<<<<<<< HEAD
 +		if (is_swiotlb_buffer(sg_phys(sg)))
 +			swiotlb_tbl_sync_single(dev, sg_phys(sg), sg->length,
 +						dir, SYNC_FOR_CPU);
++=======
+ 		if (is_swiotlb_buffer(dev, sg_phys(sg)))
+ 			swiotlb_sync_single_for_cpu(dev, sg_phys(sg),
+ 						    sg->length, dir);
++>>>>>>> 7fd856aa7f42 (swiotlb: Update is_swiotlb_buffer to add a struct device argument)
  	}
  }
  
@@@ -849,9 -834,9 +875,15 @@@ static void iommu_dma_sync_sg_for_devic
  		return;
  
  	for_each_sg(sgl, sg, nelems, i) {
++<<<<<<< HEAD
 +		if (is_swiotlb_buffer(sg_phys(sg)))
 +			swiotlb_tbl_sync_single(dev, sg_phys(sg), sg->length,
 +						dir, SYNC_FOR_DEVICE);
++=======
+ 		if (is_swiotlb_buffer(dev, sg_phys(sg)))
+ 			swiotlb_sync_single_for_device(dev, sg_phys(sg),
+ 						       sg->length, dir);
++>>>>>>> 7fd856aa7f42 (swiotlb: Update is_swiotlb_buffer to add a struct device argument)
  
  		if (!dev_is_dma_coherent(dev))
  			arch_sync_dma_for_device(sg_phys(sg), sg->length, dir);
diff --cc include/linux/swiotlb.h
index 5857a937c637,d1f3d95881cd..000000000000
--- a/include/linux/swiotlb.h
+++ b/include/linux/swiotlb.h
@@@ -71,21 -62,61 +72,27 @@@ dma_addr_t swiotlb_map(struct device *d
  
  #ifdef CONFIG_SWIOTLB
  extern enum swiotlb_force swiotlb_force;
 -
 -/**
 - * struct io_tlb_mem - IO TLB Memory Pool Descriptor
 - *
 - * @start:	The start address of the swiotlb memory pool. Used to do a quick
 - *		range check to see if the memory was in fact allocated by this
 - *		API.
 - * @end:	The end address of the swiotlb memory pool. Used to do a quick
 - *		range check to see if the memory was in fact allocated by this
 - *		API.
 - * @nslabs:	The number of IO TLB blocks (in groups of 64) between @start and
 - *		@end. This is command line adjustable via setup_io_tlb_npages.
 - * @used:	The number of used IO TLB block.
 - * @list:	The free list describing the number of free entries available
 - *		from each index.
 - * @index:	The index to start searching in the next round.
 - * @orig_addr:	The original address corresponding to a mapped entry.
 - * @alloc_size:	Size of the allocated buffer.
 - * @lock:	The lock to protect the above data structures in the map and
 - *		unmap calls.
 - * @debugfs:	The dentry to debugfs.
 - * @late_alloc:	%true if allocated using the page allocator
 - */
 -struct io_tlb_mem {
 -	phys_addr_t start;
 -	phys_addr_t end;
 -	unsigned long nslabs;
 -	unsigned long used;
 -	unsigned int index;
 -	spinlock_t lock;
 -	struct dentry *debugfs;
 -	bool late_alloc;
 -	struct io_tlb_slot {
 -		phys_addr_t orig_addr;
 -		size_t alloc_size;
 -		unsigned int list;
 -	} slots[];
 -};
 -extern struct io_tlb_mem *io_tlb_default_mem;
 +extern phys_addr_t io_tlb_start, io_tlb_end;
  
- static inline bool is_swiotlb_buffer(phys_addr_t paddr)
+ static inline bool is_swiotlb_buffer(struct device *dev, phys_addr_t paddr)
  {
++<<<<<<< HEAD
 +	return paddr >= io_tlb_start && paddr < io_tlb_end;
++=======
+ 	struct io_tlb_mem *mem = dev->dma_io_tlb_mem;
+ 
+ 	return mem && paddr >= mem->start && paddr < mem->end;
++>>>>>>> 7fd856aa7f42 (swiotlb: Update is_swiotlb_buffer to add a struct device argument)
  }
  
  void __init swiotlb_exit(void);
  unsigned int swiotlb_max_segment(void);
  size_t swiotlb_max_mapping_size(struct device *dev);
  bool is_swiotlb_active(void);
 -void __init swiotlb_adjust_size(unsigned long size);
 +void __init swiotlb_adjust_size(unsigned long new_size);
  #else
  #define swiotlb_force SWIOTLB_NO_FORCE
- static inline bool is_swiotlb_buffer(phys_addr_t paddr)
+ static inline bool is_swiotlb_buffer(struct device *dev, phys_addr_t paddr)
  {
  	return false;
  }
diff --cc kernel/dma/direct.c
index 7d488b64b9de,84c9feb5474a..000000000000
--- a/kernel/dma/direct.c
+++ b/kernel/dma/direct.c
@@@ -338,9 -343,9 +338,15 @@@ void dma_direct_sync_sg_for_device(stru
  	for_each_sg(sgl, sg, nents, i) {
  		phys_addr_t paddr = dma_to_phys(dev, sg_dma_address(sg));
  
++<<<<<<< HEAD
 +		if (unlikely(is_swiotlb_buffer(paddr)))
 +			swiotlb_tbl_sync_single(dev, paddr, sg->length,
 +					dir, SYNC_FOR_DEVICE);
++=======
+ 		if (unlikely(is_swiotlb_buffer(dev, paddr)))
+ 			swiotlb_sync_single_for_device(dev, paddr, sg->length,
+ 						       dir);
++>>>>>>> 7fd856aa7f42 (swiotlb: Update is_swiotlb_buffer to add a struct device argument)
  
  		if (!dev_is_dma_coherent(dev))
  			arch_sync_dma_for_device(paddr, sg->length,
@@@ -364,9 -369,12 +370,18 @@@ void dma_direct_sync_sg_for_cpu(struct 
  		if (!dev_is_dma_coherent(dev))
  			arch_sync_dma_for_cpu(paddr, sg->length, dir);
  
++<<<<<<< HEAD
 +		if (unlikely(is_swiotlb_buffer(paddr)))
 +			swiotlb_tbl_sync_single(dev, paddr, sg->length, dir,
 +					SYNC_FOR_CPU);
++=======
+ 		if (unlikely(is_swiotlb_buffer(dev, paddr)))
+ 			swiotlb_sync_single_for_cpu(dev, paddr, sg->length,
+ 						    dir);
+ 
+ 		if (dir == DMA_FROM_DEVICE)
+ 			arch_dma_mark_clean(paddr, sg->length);
++>>>>>>> 7fd856aa7f42 (swiotlb: Update is_swiotlb_buffer to add a struct device argument)
  	}
  
  	if (!dev_is_dma_coherent(dev))
@@@ -496,5 -504,46 +511,5 @@@ size_t dma_direct_max_mapping_size(stru
  bool dma_direct_need_sync(struct device *dev, dma_addr_t dma_addr)
  {
  	return !dev_is_dma_coherent(dev) ||
- 		is_swiotlb_buffer(dma_to_phys(dev, dma_addr));
+ 	       is_swiotlb_buffer(dev, dma_to_phys(dev, dma_addr));
  }
 -
 -/**
 - * dma_direct_set_offset - Assign scalar offset for a single DMA range.
 - * @dev:	device pointer; needed to "own" the alloced memory.
 - * @cpu_start:  beginning of memory region covered by this offset.
 - * @dma_start:  beginning of DMA/PCI region covered by this offset.
 - * @size:	size of the region.
 - *
 - * This is for the simple case of a uniform offset which cannot
 - * be discovered by "dma-ranges".
 - *
 - * It returns -ENOMEM if out of memory, -EINVAL if a map
 - * already exists, 0 otherwise.
 - *
 - * Note: any call to this from a driver is a bug.  The mapping needs
 - * to be described by the device tree or other firmware interfaces.
 - */
 -int dma_direct_set_offset(struct device *dev, phys_addr_t cpu_start,
 -			 dma_addr_t dma_start, u64 size)
 -{
 -	struct bus_dma_region *map;
 -	u64 offset = (u64)cpu_start - (u64)dma_start;
 -
 -	if (dev->dma_range_map) {
 -		dev_err(dev, "attempt to add DMA range to existing map\n");
 -		return -EINVAL;
 -	}
 -
 -	if (!offset)
 -		return 0;
 -
 -	map = kcalloc(2, sizeof(*map), GFP_KERNEL);
 -	if (!map)
 -		return -ENOMEM;
 -	map[0].cpu_start = cpu_start;
 -	map[0].dma_start = dma_start;
 -	map[0].offset = offset;
 -	map[0].size = size;
 -	dev->dma_range_map = map;
 -	return 0;
 -}
* Unmerged path kernel/dma/direct.h
* Unmerged path drivers/iommu/dma-iommu.c
diff --git a/drivers/xen/swiotlb-xen.c b/drivers/xen/swiotlb-xen.c
index 8ccd85660984..33ed3bfc1543 100644
--- a/drivers/xen/swiotlb-xen.c
+++ b/drivers/xen/swiotlb-xen.c
@@ -109,7 +109,7 @@ static int is_xen_swiotlb_buffer(struct device *dev, dma_addr_t dma_addr)
 	 * in our domain. Therefore _only_ check address within our domain.
 	 */
 	if (pfn_valid(PFN_DOWN(paddr)))
-		return is_swiotlb_buffer(paddr);
+		return is_swiotlb_buffer(dev, paddr);
 	return 0;
 }
 
* Unmerged path include/linux/swiotlb.h
* Unmerged path kernel/dma/direct.c
* Unmerged path kernel/dma/direct.h
