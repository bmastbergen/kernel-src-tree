topology: Represent clusters of CPUs within a die

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-365.el8
commit-author Jonathan Cameron <Jonathan.Cameron@huawei.com>
commit c5e22feffdd736cb02b98b0f5b375c8ebc858dd4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-365.el8/c5e22fef.failed

Both ACPI and DT provide the ability to describe additional layers of
topology between that of individual cores and higher level constructs
such as the level at which the last level cache is shared.
In ACPI this can be represented in PPTT as a Processor Hierarchy
Node Structure [1] that is the parent of the CPU cores and in turn
has a parent Processor Hierarchy Nodes Structure representing
a higher level of topology.

For example Kunpeng 920 has 6 or 8 clusters in each NUMA node, and each
cluster has 4 cpus. All clusters share L3 cache data, but each cluster
has local L3 tag. On the other hand, each clusters will share some
internal system bus.

+-----------------------------------+                          +---------+
|  +------+    +------+             +--------------------------+         |
|  | CPU0 |    | cpu1 |             |    +-----------+         |         |
|  +------+    +------+             |    |           |         |         |
|                                   +----+    L3     |         |         |
|  +------+    +------+   cluster   |    |    tag    |         |         |
|  | CPU2 |    | CPU3 |             |    |           |         |         |
|  +------+    +------+             |    +-----------+         |         |
|                                   |                          |         |
+-----------------------------------+                          |         |
+-----------------------------------+                          |         |
|  +------+    +------+             +--------------------------+         |
|  |      |    |      |             |    +-----------+         |         |
|  +------+    +------+             |    |           |         |         |
|                                   |    |    L3     |         |         |
|  +------+    +------+             +----+    tag    |         |         |
|  |      |    |      |             |    |           |         |         |
|  +------+    +------+             |    +-----------+         |         |
|                                   |                          |         |
+-----------------------------------+                          |   L3    |
                                                               |   data  |
+-----------------------------------+                          |         |
|  +------+    +------+             |    +-----------+         |         |
|  |      |    |      |             |    |           |         |         |
|  +------+    +------+             +----+    L3     |         |         |
|                                   |    |    tag    |         |         |
|  +------+    +------+             |    |           |         |         |
|  |      |    |      |             |    +-----------+         |         |
|  +------+    +------+             +--------------------------+         |
+-----------------------------------|                          |         |
+-----------------------------------|                          |         |
|  +------+    +------+             +--------------------------+         |
|  |      |    |      |             |    +-----------+         |         |
|  +------+    +------+             |    |           |         |         |
|                                   +----+    L3     |         |         |
|  +------+    +------+             |    |    tag    |         |         |
|  |      |    |      |             |    |           |         |         |
|  +------+    +------+             |    +-----------+         |         |
|                                   |                          |         |
+-----------------------------------+                          |         |
+-----------------------------------+                          |         |
|  +------+    +------+             +--------------------------+         |
|  |      |    |      |             |   +-----------+          |         |
|  +------+    +------+             |   |           |          |         |
|                                   |   |    L3     |          |         |
|  +------+    +------+             +---+    tag    |          |         |
|  |      |    |      |             |   |           |          |         |
|  +------+    +------+             |   +-----------+          |         |
|                                   |                          |         |
+-----------------------------------+                          |         |
+-----------------------------------+                          |         |
|  +------+    +------+             +--------------------------+         |
|  |      |    |      |             |  +-----------+           |         |
|  +------+    +------+             |  |           |           |         |
|                                   |  |    L3     |           |         |
|  +------+    +------+             +--+    tag    |           |         |
|  |      |    |      |             |  |           |           |         |
|  +------+    +------+             |  +-----------+           |         |
|                                   |                          +---------+
+-----------------------------------+

That means spreading tasks among clusters will bring more bandwidth
while packing tasks within one cluster will lead to smaller cache
synchronization latency. So both kernel and userspace will have
a chance to leverage this topology to deploy tasks accordingly to
achieve either smaller cache latency within one cluster or an even
distribution of load among clusters for higher throughput.

This patch exposes cluster topology to both kernel and userspace.
Libraried like hwloc will know cluster by cluster_cpus and related
sysfs attributes. PoC of HWLOC support at [2].

Note this patch only handle the ACPI case.

Special consideration is needed for SMT processors, where it is
necessary to move 2 levels up the hierarchy from the leaf nodes
(thus skipping the processor core level).

Note that arm64 / ACPI does not provide any means of identifying
a die level in the topology but that may be unrelate to the cluster
level.

[1] ACPI Specification 6.3 - section 5.2.29.1 processor hierarchy node
    structure (Type 0)
[2] https://github.com/hisilicon/hwloc/tree/linux-cluster

	Signed-off-by: Jonathan Cameron <Jonathan.Cameron@huawei.com>
	Signed-off-by: Tian Tao <tiantao6@hisilicon.com>
	Signed-off-by: Barry Song <song.bao.hua@hisilicon.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: https://lore.kernel.org/r/20210924085104.44806-2-21cnbao@gmail.com
(cherry picked from commit c5e22feffdd736cb02b98b0f5b375c8ebc858dd4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/ABI/stable/sysfs-devices-system-cpu
#	drivers/base/arch_topology.c
#	include/linux/arch_topology.h
diff --cc Documentation/ABI/stable/sysfs-devices-system-cpu
index 33c133e2a631,3965ce504484..000000000000
--- a/Documentation/ABI/stable/sysfs-devices-system-cpu
+++ b/Documentation/ABI/stable/sysfs-devices-system-cpu
@@@ -23,3 -23,101 +23,104 @@@ Description:	Default value for the Dat
  		here).
  		If set by a process it will be inherited by child processes.
  Values:		64 bit unsigned integer (bit field)
++<<<<<<< HEAD
++=======
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/physical_package_id
+ Description:    physical package id of cpuX. Typically corresponds to a physical
+                 socket number, but the actual value is architecture and platform
+                 dependent.
+ Values:         integer
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/die_id
+ Description:    the CPU die ID of cpuX. Typically it is the hardware platform's
+                 identifier (rather than the kernel's). The actual value is
+                 architecture and platform dependent.
+ Values:         integer
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/core_id
+ Description:    the CPU core ID of cpuX. Typically it is the hardware platform's
+                 identifier (rather than the kernel's). The actual value is
+                 architecture and platform dependent.
+ Values:         integer
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/cluster_id
+ Description:    the cluster ID of cpuX.  Typically it is the hardware platform's
+                 identifier (rather than the kernel's). The actual value is
+                 architecture and platform dependent.
+ Values:         integer
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/book_id
+ Description:    the book ID of cpuX. Typically it is the hardware platform's
+                 identifier (rather than the kernel's). The actual value is
+                 architecture and platform dependent. it's only used on s390.
+ Values:         integer
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/drawer_id
+ Description:    the drawer ID of cpuX. Typically it is the hardware platform's
+                 identifier (rather than the kernel's). The actual value is
+                 architecture and platform dependent. it's only used on s390.
+ Values:         integer
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/core_cpus
+ Description:    internal kernel map of CPUs within the same core.
+                 (deprecated name: "thread_siblings")
+ Values:         hexadecimal bitmask.
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/core_cpus_list
+ Description:    human-readable list of CPUs within the same core.
+                 The format is like 0-3, 8-11, 14,17.
+                 (deprecated name: "thread_siblings_list").
+ Values:         decimal list.
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/package_cpus
+ Description:    internal kernel map of the CPUs sharing the same physical_package_id.
+                 (deprecated name: "core_siblings").
+ Values:         hexadecimal bitmask.
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/package_cpus_list
+ Description:    human-readable list of CPUs sharing the same physical_package_id.
+                 The format is like 0-3, 8-11, 14,17.
+                 (deprecated name: "core_siblings_list")
+ Values:         decimal list.
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/die_cpus
+ Description:    internal kernel map of CPUs within the same die.
+ Values:         hexadecimal bitmask.
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/die_cpus_list
+ Description:    human-readable list of CPUs within the same die.
+                 The format is like 0-3, 8-11, 14,17.
+ Values:         decimal list.
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/cluster_cpus
+ Description:    internal kernel map of CPUs within the same cluster.
+ Values:         hexadecimal bitmask.
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/cluster_cpus_list
+ Description:    human-readable list of CPUs within the same cluster.
+                 The format is like 0-3, 8-11, 14,17.
+ Values:         decimal list.
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/book_siblings
+ Description:    internal kernel map of cpuX's hardware threads within the same
+                 book_id. it's only used on s390.
+ Values:         hexadecimal bitmask.
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/book_siblings_list
+ Description:    human-readable list of cpuX's hardware threads within the same
+                 book_id.
+                 The format is like 0-3, 8-11, 14,17. it's only used on s390.
+ Values:         decimal list.
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/drawer_siblings
+ Description:    internal kernel map of cpuX's hardware threads within the same
+                 drawer_id. it's only used on s390.
+ Values:         hexadecimal bitmask.
+ 
+ What:           /sys/devices/system/cpu/cpuX/topology/drawer_siblings_list
+ Description:    human-readable list of cpuX's hardware threads within the same
+                 drawer_id.
+                 The format is like 0-3, 8-11, 14,17. it's only used on s390.
+ Values:         decimal list.
++>>>>>>> c5e22feffdd7 (topology: Represent clusters of CPUs within a die)
diff --cc drivers/base/arch_topology.c
index 347cddcd2879,fc0836f460fb..000000000000
--- a/drivers/base/arch_topology.c
+++ b/drivers/base/arch_topology.c
@@@ -244,3 -388,321 +244,324 @@@ static void parsing_done_workfn(struct 
  #else
  core_initcall(free_raw_capacity);
  #endif
++<<<<<<< HEAD
++=======
+ 
+ #if defined(CONFIG_ARM64) || defined(CONFIG_RISCV)
+ /*
+  * This function returns the logic cpu number of the node.
+  * There are basically three kinds of return values:
+  * (1) logic cpu number which is > 0.
+  * (2) -ENODEV when the device tree(DT) node is valid and found in the DT but
+  * there is no possible logical CPU in the kernel to match. This happens
+  * when CONFIG_NR_CPUS is configure to be smaller than the number of
+  * CPU nodes in DT. We need to just ignore this case.
+  * (3) -1 if the node does not exist in the device tree
+  */
+ static int __init get_cpu_for_node(struct device_node *node)
+ {
+ 	struct device_node *cpu_node;
+ 	int cpu;
+ 
+ 	cpu_node = of_parse_phandle(node, "cpu", 0);
+ 	if (!cpu_node)
+ 		return -1;
+ 
+ 	cpu = of_cpu_node_to_id(cpu_node);
+ 	if (cpu >= 0)
+ 		topology_parse_cpu_capacity(cpu_node, cpu);
+ 	else
+ 		pr_info("CPU node for %pOF exist but the possible cpu range is :%*pbl\n",
+ 			cpu_node, cpumask_pr_args(cpu_possible_mask));
+ 
+ 	of_node_put(cpu_node);
+ 	return cpu;
+ }
+ 
+ static int __init parse_core(struct device_node *core, int package_id,
+ 			     int core_id)
+ {
+ 	char name[20];
+ 	bool leaf = true;
+ 	int i = 0;
+ 	int cpu;
+ 	struct device_node *t;
+ 
+ 	do {
+ 		snprintf(name, sizeof(name), "thread%d", i);
+ 		t = of_get_child_by_name(core, name);
+ 		if (t) {
+ 			leaf = false;
+ 			cpu = get_cpu_for_node(t);
+ 			if (cpu >= 0) {
+ 				cpu_topology[cpu].package_id = package_id;
+ 				cpu_topology[cpu].core_id = core_id;
+ 				cpu_topology[cpu].thread_id = i;
+ 			} else if (cpu != -ENODEV) {
+ 				pr_err("%pOF: Can't get CPU for thread\n", t);
+ 				of_node_put(t);
+ 				return -EINVAL;
+ 			}
+ 			of_node_put(t);
+ 		}
+ 		i++;
+ 	} while (t);
+ 
+ 	cpu = get_cpu_for_node(core);
+ 	if (cpu >= 0) {
+ 		if (!leaf) {
+ 			pr_err("%pOF: Core has both threads and CPU\n",
+ 			       core);
+ 			return -EINVAL;
+ 		}
+ 
+ 		cpu_topology[cpu].package_id = package_id;
+ 		cpu_topology[cpu].core_id = core_id;
+ 	} else if (leaf && cpu != -ENODEV) {
+ 		pr_err("%pOF: Can't get CPU for leaf core\n", core);
+ 		return -EINVAL;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int __init parse_cluster(struct device_node *cluster, int depth)
+ {
+ 	char name[20];
+ 	bool leaf = true;
+ 	bool has_cores = false;
+ 	struct device_node *c;
+ 	static int package_id __initdata;
+ 	int core_id = 0;
+ 	int i, ret;
+ 
+ 	/*
+ 	 * First check for child clusters; we currently ignore any
+ 	 * information about the nesting of clusters and present the
+ 	 * scheduler with a flat list of them.
+ 	 */
+ 	i = 0;
+ 	do {
+ 		snprintf(name, sizeof(name), "cluster%d", i);
+ 		c = of_get_child_by_name(cluster, name);
+ 		if (c) {
+ 			leaf = false;
+ 			ret = parse_cluster(c, depth + 1);
+ 			of_node_put(c);
+ 			if (ret != 0)
+ 				return ret;
+ 		}
+ 		i++;
+ 	} while (c);
+ 
+ 	/* Now check for cores */
+ 	i = 0;
+ 	do {
+ 		snprintf(name, sizeof(name), "core%d", i);
+ 		c = of_get_child_by_name(cluster, name);
+ 		if (c) {
+ 			has_cores = true;
+ 
+ 			if (depth == 0) {
+ 				pr_err("%pOF: cpu-map children should be clusters\n",
+ 				       c);
+ 				of_node_put(c);
+ 				return -EINVAL;
+ 			}
+ 
+ 			if (leaf) {
+ 				ret = parse_core(c, package_id, core_id++);
+ 			} else {
+ 				pr_err("%pOF: Non-leaf cluster with core %s\n",
+ 				       cluster, name);
+ 				ret = -EINVAL;
+ 			}
+ 
+ 			of_node_put(c);
+ 			if (ret != 0)
+ 				return ret;
+ 		}
+ 		i++;
+ 	} while (c);
+ 
+ 	if (leaf && !has_cores)
+ 		pr_warn("%pOF: empty cluster\n", cluster);
+ 
+ 	if (leaf)
+ 		package_id++;
+ 
+ 	return 0;
+ }
+ 
+ static int __init parse_dt_topology(void)
+ {
+ 	struct device_node *cn, *map;
+ 	int ret = 0;
+ 	int cpu;
+ 
+ 	cn = of_find_node_by_path("/cpus");
+ 	if (!cn) {
+ 		pr_err("No CPU information found in DT\n");
+ 		return 0;
+ 	}
+ 
+ 	/*
+ 	 * When topology is provided cpu-map is essentially a root
+ 	 * cluster with restricted subnodes.
+ 	 */
+ 	map = of_get_child_by_name(cn, "cpu-map");
+ 	if (!map)
+ 		goto out;
+ 
+ 	ret = parse_cluster(map, 0);
+ 	if (ret != 0)
+ 		goto out_map;
+ 
+ 	topology_normalize_cpu_scale();
+ 
+ 	/*
+ 	 * Check that all cores are in the topology; the SMP code will
+ 	 * only mark cores described in the DT as possible.
+ 	 */
+ 	for_each_possible_cpu(cpu)
+ 		if (cpu_topology[cpu].package_id == -1)
+ 			ret = -EINVAL;
+ 
+ out_map:
+ 	of_node_put(map);
+ out:
+ 	of_node_put(cn);
+ 	return ret;
+ }
+ #endif
+ 
+ /*
+  * cpu topology table
+  */
+ struct cpu_topology cpu_topology[NR_CPUS];
+ EXPORT_SYMBOL_GPL(cpu_topology);
+ 
+ const struct cpumask *cpu_coregroup_mask(int cpu)
+ {
+ 	const cpumask_t *core_mask = cpumask_of_node(cpu_to_node(cpu));
+ 
+ 	/* Find the smaller of NUMA, core or LLC siblings */
+ 	if (cpumask_subset(&cpu_topology[cpu].core_sibling, core_mask)) {
+ 		/* not numa in package, lets use the package siblings */
+ 		core_mask = &cpu_topology[cpu].core_sibling;
+ 	}
+ 	if (cpu_topology[cpu].llc_id != -1) {
+ 		if (cpumask_subset(&cpu_topology[cpu].llc_sibling, core_mask))
+ 			core_mask = &cpu_topology[cpu].llc_sibling;
+ 	}
+ 
+ 	return core_mask;
+ }
+ 
+ const struct cpumask *cpu_clustergroup_mask(int cpu)
+ {
+ 	return &cpu_topology[cpu].cluster_sibling;
+ }
+ 
+ void update_siblings_masks(unsigned int cpuid)
+ {
+ 	struct cpu_topology *cpu_topo, *cpuid_topo = &cpu_topology[cpuid];
+ 	int cpu;
+ 
+ 	/* update core and thread sibling masks */
+ 	for_each_online_cpu(cpu) {
+ 		cpu_topo = &cpu_topology[cpu];
+ 
+ 		if (cpuid_topo->llc_id == cpu_topo->llc_id) {
+ 			cpumask_set_cpu(cpu, &cpuid_topo->llc_sibling);
+ 			cpumask_set_cpu(cpuid, &cpu_topo->llc_sibling);
+ 		}
+ 
+ 		if (cpuid_topo->package_id != cpu_topo->package_id)
+ 			continue;
+ 
+ 		if (cpuid_topo->cluster_id == cpu_topo->cluster_id &&
+ 		    cpuid_topo->cluster_id != -1) {
+ 			cpumask_set_cpu(cpu, &cpuid_topo->cluster_sibling);
+ 			cpumask_set_cpu(cpuid, &cpu_topo->cluster_sibling);
+ 		}
+ 
+ 		cpumask_set_cpu(cpuid, &cpu_topo->core_sibling);
+ 		cpumask_set_cpu(cpu, &cpuid_topo->core_sibling);
+ 
+ 		if (cpuid_topo->core_id != cpu_topo->core_id)
+ 			continue;
+ 
+ 		cpumask_set_cpu(cpuid, &cpu_topo->thread_sibling);
+ 		cpumask_set_cpu(cpu, &cpuid_topo->thread_sibling);
+ 	}
+ }
+ 
+ static void clear_cpu_topology(int cpu)
+ {
+ 	struct cpu_topology *cpu_topo = &cpu_topology[cpu];
+ 
+ 	cpumask_clear(&cpu_topo->llc_sibling);
+ 	cpumask_set_cpu(cpu, &cpu_topo->llc_sibling);
+ 
+ 	cpumask_clear(&cpu_topo->cluster_sibling);
+ 	cpumask_set_cpu(cpu, &cpu_topo->cluster_sibling);
+ 
+ 	cpumask_clear(&cpu_topo->core_sibling);
+ 	cpumask_set_cpu(cpu, &cpu_topo->core_sibling);
+ 	cpumask_clear(&cpu_topo->thread_sibling);
+ 	cpumask_set_cpu(cpu, &cpu_topo->thread_sibling);
+ }
+ 
+ void __init reset_cpu_topology(void)
+ {
+ 	unsigned int cpu;
+ 
+ 	for_each_possible_cpu(cpu) {
+ 		struct cpu_topology *cpu_topo = &cpu_topology[cpu];
+ 
+ 		cpu_topo->thread_id = -1;
+ 		cpu_topo->core_id = -1;
+ 		cpu_topo->cluster_id = -1;
+ 		cpu_topo->package_id = -1;
+ 		cpu_topo->llc_id = -1;
+ 
+ 		clear_cpu_topology(cpu);
+ 	}
+ }
+ 
+ void remove_cpu_topology(unsigned int cpu)
+ {
+ 	int sibling;
+ 
+ 	for_each_cpu(sibling, topology_core_cpumask(cpu))
+ 		cpumask_clear_cpu(cpu, topology_core_cpumask(sibling));
+ 	for_each_cpu(sibling, topology_sibling_cpumask(cpu))
+ 		cpumask_clear_cpu(cpu, topology_sibling_cpumask(sibling));
+ 	for_each_cpu(sibling, topology_llc_cpumask(cpu))
+ 		cpumask_clear_cpu(cpu, topology_llc_cpumask(sibling));
+ 
+ 	clear_cpu_topology(cpu);
+ }
+ 
+ __weak int __init parse_acpi_topology(void)
+ {
+ 	return 0;
+ }
+ 
+ #if defined(CONFIG_ARM64) || defined(CONFIG_RISCV)
+ void __init init_cpu_topology(void)
+ {
+ 	reset_cpu_topology();
+ 
+ 	/*
+ 	 * Discard anything that was parsed if we hit an error so we
+ 	 * don't use partial information.
+ 	 */
+ 	if (parse_acpi_topology())
+ 		reset_cpu_topology();
+ 	else if (of_have_populated_dt() && parse_dt_topology())
+ 		reset_cpu_topology();
+ }
+ #endif
++>>>>>>> c5e22feffdd7 (topology: Represent clusters of CPUs within a die)
diff --cc include/linux/arch_topology.h
index 1cfe05ea1d89,b97cea83b25e..000000000000
--- a/include/linux/arch_topology.h
+++ b/include/linux/arch_topology.h
@@@ -25,12 -23,72 +25,76 @@@ unsigned long topology_get_cpu_scale(in
  
  void topology_set_cpu_scale(unsigned int cpu, unsigned long capacity);
  
 -DECLARE_PER_CPU(unsigned long, arch_freq_scale);
 +DECLARE_PER_CPU(unsigned long, freq_scale);
  
 -static inline unsigned long topology_get_freq_scale(int cpu)
 +static inline
 +unsigned long topology_get_freq_scale(int cpu)
  {
 -	return per_cpu(arch_freq_scale, cpu);
 +	return per_cpu(freq_scale, cpu);
  }
  
++<<<<<<< HEAD
++=======
+ void topology_set_freq_scale(const struct cpumask *cpus, unsigned long cur_freq,
+ 			     unsigned long max_freq);
+ bool topology_scale_freq_invariant(void);
+ 
+ enum scale_freq_source {
+ 	SCALE_FREQ_SOURCE_CPUFREQ = 0,
+ 	SCALE_FREQ_SOURCE_ARCH,
+ 	SCALE_FREQ_SOURCE_CPPC,
+ };
+ 
+ struct scale_freq_data {
+ 	enum scale_freq_source source;
+ 	void (*set_freq_scale)(void);
+ };
+ 
+ void topology_scale_freq_tick(void);
+ void topology_set_scale_freq_source(struct scale_freq_data *data, const struct cpumask *cpus);
+ void topology_clear_scale_freq_source(enum scale_freq_source source, const struct cpumask *cpus);
+ 
+ DECLARE_PER_CPU(unsigned long, thermal_pressure);
+ 
+ static inline unsigned long topology_get_thermal_pressure(int cpu)
+ {
+ 	return per_cpu(thermal_pressure, cpu);
+ }
+ 
+ void topology_set_thermal_pressure(const struct cpumask *cpus,
+ 				   unsigned long th_pressure);
+ 
+ struct cpu_topology {
+ 	int thread_id;
+ 	int core_id;
+ 	int cluster_id;
+ 	int package_id;
+ 	int llc_id;
+ 	cpumask_t thread_sibling;
+ 	cpumask_t core_sibling;
+ 	cpumask_t cluster_sibling;
+ 	cpumask_t llc_sibling;
+ };
+ 
+ #ifdef CONFIG_GENERIC_ARCH_TOPOLOGY
+ extern struct cpu_topology cpu_topology[NR_CPUS];
+ 
+ #define topology_physical_package_id(cpu)	(cpu_topology[cpu].package_id)
+ #define topology_cluster_id(cpu)	(cpu_topology[cpu].cluster_id)
+ #define topology_core_id(cpu)		(cpu_topology[cpu].core_id)
+ #define topology_core_cpumask(cpu)	(&cpu_topology[cpu].core_sibling)
+ #define topology_sibling_cpumask(cpu)	(&cpu_topology[cpu].thread_sibling)
+ #define topology_cluster_cpumask(cpu)	(&cpu_topology[cpu].cluster_sibling)
+ #define topology_llc_cpumask(cpu)	(&cpu_topology[cpu].llc_sibling)
+ void init_cpu_topology(void);
+ void store_cpu_topology(unsigned int cpuid);
+ const struct cpumask *cpu_coregroup_mask(int cpu);
+ const struct cpumask *cpu_clustergroup_mask(int cpu);
+ void update_siblings_masks(unsigned int cpu);
+ void remove_cpu_topology(unsigned int cpuid);
+ void reset_cpu_topology(void);
+ int parse_acpi_topology(void);
+ #endif
+ 
++>>>>>>> c5e22feffdd7 (topology: Represent clusters of CPUs within a die)
  #endif /* _LINUX_ARCH_TOPOLOGY_H_ */
* Unmerged path Documentation/ABI/stable/sysfs-devices-system-cpu
diff --git a/Documentation/cputopology.txt b/Documentation/cputopology.txt
index b90dafcc8237..7b2bf1c99502 100644
--- a/Documentation/cputopology.txt
+++ b/Documentation/cputopology.txt
@@ -96,11 +96,13 @@ these macros in include/asm-XXX/topology.h::
 
 	#define topology_physical_package_id(cpu)
 	#define topology_die_id(cpu)
+	#define topology_cluster_id(cpu)
 	#define topology_core_id(cpu)
 	#define topology_book_id(cpu)
 	#define topology_drawer_id(cpu)
 	#define topology_sibling_cpumask(cpu)
 	#define topology_core_cpumask(cpu)
+	#define topology_cluster_cpumask(cpu)
 	#define topology_die_cpumask(cpu)
 	#define topology_book_cpumask(cpu)
 	#define topology_drawer_cpumask(cpu)
@@ -116,10 +118,12 @@ not defined by include/asm-XXX/topology.h:
 
 1) topology_physical_package_id: -1
 2) topology_die_id: -1
-3) topology_core_id: 0
-4) topology_sibling_cpumask: just the given CPU
-5) topology_core_cpumask: just the given CPU
-6) topology_die_cpumask: just the given CPU
+3) topology_cluster_id: -1
+4) topology_core_id: 0
+5) topology_sibling_cpumask: just the given CPU
+6) topology_core_cpumask: just the given CPU
+7) topology_cluster_cpumask: just the given CPU
+8) topology_die_cpumask: just the given CPU
 
 For architectures that don't support books (CONFIG_SCHED_BOOK) there are no
 default definitions for topology_book_id() and topology_book_cpumask().
diff --git a/arch/arm64/kernel/topology.c b/arch/arm64/kernel/topology.c
index 6106c49f84bc..223f796ad457 100644
--- a/arch/arm64/kernel/topology.c
+++ b/arch/arm64/kernel/topology.c
@@ -377,6 +377,8 @@ static int __init parse_acpi_topology(void)
 			cpu_topology[cpu].thread_id  = -1;
 			cpu_topology[cpu].core_id    = topology_id;
 		}
+		topology_id = find_acpi_cpu_topology_cluster(cpu);
+		cpu_topology[cpu].cluster_id = topology_id;
 		topology_id = find_acpi_cpu_topology_package(cpu);
 		cpu_topology[cpu].package_id = topology_id;
 
diff --git a/drivers/acpi/pptt.c b/drivers/acpi/pptt.c
index fe69dc518f31..701f61c01359 100644
--- a/drivers/acpi/pptt.c
+++ b/drivers/acpi/pptt.c
@@ -746,6 +746,73 @@ int find_acpi_cpu_topology_package(unsigned int cpu)
 					  ACPI_PPTT_PHYSICAL_PACKAGE);
 }
 
+/**
+ * find_acpi_cpu_topology_cluster() - Determine a unique CPU cluster value
+ * @cpu: Kernel logical CPU number
+ *
+ * Determine a topology unique cluster ID for the given CPU/thread.
+ * This ID can then be used to group peers, which will have matching ids.
+ *
+ * The cluster, if present is the level of topology above CPUs. In a
+ * multi-thread CPU, it will be the level above the CPU, not the thread.
+ * It may not exist in single CPU systems. In simple multi-CPU systems,
+ * it may be equal to the package topology level.
+ *
+ * Return: -ENOENT if the PPTT doesn't exist, the CPU cannot be found
+ * or there is no toplogy level above the CPU..
+ * Otherwise returns a value which represents the package for this CPU.
+ */
+
+int find_acpi_cpu_topology_cluster(unsigned int cpu)
+{
+	struct acpi_table_header *table;
+	acpi_status status;
+	struct acpi_pptt_processor *cpu_node, *cluster_node;
+	u32 acpi_cpu_id;
+	int retval;
+	int is_thread;
+
+	status = acpi_get_table(ACPI_SIG_PPTT, 0, &table);
+	if (ACPI_FAILURE(status)) {
+		acpi_pptt_warn_missing();
+		return -ENOENT;
+	}
+
+	acpi_cpu_id = get_acpi_id_for_cpu(cpu);
+	cpu_node = acpi_find_processor_node(table, acpi_cpu_id);
+	if (cpu_node == NULL || !cpu_node->parent) {
+		retval = -ENOENT;
+		goto put_table;
+	}
+
+	is_thread = cpu_node->flags & ACPI_PPTT_ACPI_PROCESSOR_IS_THREAD;
+	cluster_node = fetch_pptt_node(table, cpu_node->parent);
+	if (cluster_node == NULL) {
+		retval = -ENOENT;
+		goto put_table;
+	}
+	if (is_thread) {
+		if (!cluster_node->parent) {
+			retval = -ENOENT;
+			goto put_table;
+		}
+		cluster_node = fetch_pptt_node(table, cluster_node->parent);
+		if (cluster_node == NULL) {
+			retval = -ENOENT;
+			goto put_table;
+		}
+	}
+	if (cluster_node->flags & ACPI_PPTT_ACPI_PROCESSOR_ID_VALID)
+		retval = cluster_node->acpi_processor_id;
+	else
+		retval = ACPI_PTR_DIFF(cluster_node, table);
+
+put_table:
+	acpi_put_table(table);
+
+	return retval;
+}
+
 /**
  * find_acpi_cpu_topology_hetero_id() - Get a core architecture tag
  * @cpu: Kernel logical CPU number
* Unmerged path drivers/base/arch_topology.c
diff --git a/drivers/base/topology.c b/drivers/base/topology.c
index e6d34249d1e3..10680cb3aa51 100644
--- a/drivers/base/topology.c
+++ b/drivers/base/topology.c
@@ -48,6 +48,9 @@ static DEVICE_ATTR_RO(physical_package_id);
 define_id_show_func(die_id);
 static DEVICE_ATTR_RO(die_id);
 
+define_id_show_func(cluster_id);
+static DEVICE_ATTR_RO(cluster_id);
+
 define_id_show_func(core_id);
 static DEVICE_ATTR_RO(core_id);
 
@@ -63,6 +66,10 @@ define_siblings_read_func(core_siblings, core_cpumask);
 static BIN_ATTR_RO(core_siblings, 0);
 static BIN_ATTR_RO(core_siblings_list, 0);
 
+define_siblings_read_func(cluster_cpus, cluster_cpumask);
+static BIN_ATTR_RO(cluster_cpus, 0);
+static BIN_ATTR_RO(cluster_cpus_list, 0);
+
 define_siblings_read_func(die_cpus, die_cpumask);
 static BIN_ATTR_RO(die_cpus, 0);
 static BIN_ATTR_RO(die_cpus_list, 0);
@@ -94,6 +101,8 @@ static struct bin_attribute *bin_attrs[] = {
 	&bin_attr_thread_siblings_list,
 	&bin_attr_core_siblings,
 	&bin_attr_core_siblings_list,
+	&bin_attr_cluster_cpus,
+	&bin_attr_cluster_cpus_list,
 	&bin_attr_die_cpus,
 	&bin_attr_die_cpus_list,
 	&bin_attr_package_cpus,
@@ -112,6 +121,7 @@ static struct bin_attribute *bin_attrs[] = {
 static struct attribute *default_attrs[] = {
 	&dev_attr_physical_package_id.attr,
 	&dev_attr_die_id.attr,
+	&dev_attr_cluster_id.attr,
 	&dev_attr_core_id.attr,
 #ifdef CONFIG_SCHED_BOOK
 	&dev_attr_book_id.attr,
diff --git a/include/linux/acpi.h b/include/linux/acpi.h
index 5d4a9187f573..ad940ac8d7de 100644
--- a/include/linux/acpi.h
+++ b/include/linux/acpi.h
@@ -1337,6 +1337,7 @@ static inline int lpit_read_residency_count_address(u64 *address)
 #ifdef CONFIG_ACPI_PPTT
 int acpi_pptt_cpu_is_thread(unsigned int cpu);
 int find_acpi_cpu_topology(unsigned int cpu, int level);
+int find_acpi_cpu_topology_cluster(unsigned int cpu);
 int find_acpi_cpu_topology_package(unsigned int cpu);
 int find_acpi_cpu_topology_hetero_id(unsigned int cpu);
 int find_acpi_cpu_cache_topology(unsigned int cpu, int level);
@@ -1349,6 +1350,10 @@ static inline int find_acpi_cpu_topology(unsigned int cpu, int level)
 {
 	return -EINVAL;
 }
+static inline int find_acpi_cpu_topology_cluster(unsigned int cpu)
+{
+	return -EINVAL;
+}
 static inline int find_acpi_cpu_topology_package(unsigned int cpu)
 {
 	return -EINVAL;
* Unmerged path include/linux/arch_topology.h
diff --git a/include/linux/topology.h b/include/linux/topology.h
index 31c72c1bcf7d..c667bf741245 100644
--- a/include/linux/topology.h
+++ b/include/linux/topology.h
@@ -201,6 +201,9 @@ static inline int cpu_to_mem(int cpu)
 #ifndef topology_die_id
 #define topology_die_id(cpu)			((void)(cpu), -1)
 #endif
+#ifndef topology_cluster_id
+#define topology_cluster_id(cpu)		((void)(cpu), -1)
+#endif
 #ifndef topology_core_id
 #define topology_core_id(cpu)			((void)(cpu), 0)
 #endif
@@ -210,6 +213,9 @@ static inline int cpu_to_mem(int cpu)
 #ifndef topology_core_cpumask
 #define topology_core_cpumask(cpu)		cpumask_of(cpu)
 #endif
+#ifndef topology_cluster_cpumask
+#define topology_cluster_cpumask(cpu)		cpumask_of(cpu)
+#endif
 #ifndef topology_die_cpumask
 #define topology_die_cpumask(cpu)		cpumask_of(cpu)
 #endif
