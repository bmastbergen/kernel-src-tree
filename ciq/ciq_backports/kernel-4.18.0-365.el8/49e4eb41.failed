x86/fpu/xstate: Use fpstate for copy_uabi_to_xstate()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-365.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 49e4eb4125d506937e52e10c34c8cafd93ab0ed6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-365.el8/49e4eb41.failed

Prepare for dynamically enabled states per task. The function needs to
retrieve the features and sizes which are valid in a fpstate
context. Retrieve them from fpstate.

Move the function declarations to the core header as they are not
required anywhere else.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Signed-off-by: Borislav Petkov <bp@suse.de>
Link: https://lkml.kernel.org/r/20211013145323.233529986@linutronix.de
(cherry picked from commit 49e4eb4125d506937e52e10c34c8cafd93ab0ed6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/fpu/core.c
#	arch/x86/kernel/fpu/regset.c
#	arch/x86/kernel/fpu/signal.c
#	arch/x86/kernel/fpu/xstate.h
diff --cc arch/x86/kernel/fpu/core.c
index 3f16056105e8,b497ecae9270..000000000000
--- a/arch/x86/kernel/fpu/core.c
+++ b/arch/x86/kernel/fpu/core.c
@@@ -209,7 -222,7 +209,11 @@@ int fpu_copy_kvm_uabi_to_fpstate(struc
  	if (ustate->xsave.header.xfeatures & ~xcr0)
  		return -EINVAL;
  
++<<<<<<< HEAD
 +	ret = copy_uabi_from_kernel_to_xstate(&kstate->xsave, ustate);
++=======
+ 	ret = copy_uabi_from_kernel_to_xstate(kstate, ustate);
++>>>>>>> 49e4eb4125d5 (x86/fpu/xstate: Use fpstate for copy_uabi_to_xstate())
  	if (ret)
  		return ret;
  
diff --cc arch/x86/kernel/fpu/regset.c
index 843a02b1037d,f8c485ab73f5..000000000000
--- a/arch/x86/kernel/fpu/regset.c
+++ b/arch/x86/kernel/fpu/regset.c
@@@ -5,13 -5,14 +5,17 @@@
  #include <linux/sched/task_stack.h>
  #include <linux/vmalloc.h>
  
 -#include <asm/fpu/api.h>
 +#include <asm/fpu/internal.h>
  #include <asm/fpu/signal.h>
  #include <asm/fpu/regset.h>
- #include <asm/fpu/xstate.h>
  
  #include "context.h"
  #include "internal.h"
++<<<<<<< HEAD
++=======
+ #include "legacy.h"
+ #include "xstate.h"
++>>>>>>> 49e4eb4125d5 (x86/fpu/xstate: Use fpstate for copy_uabi_to_xstate())
  
  /*
   * The xstateregs_active() routine is the same as the regset_fpregs_active() routine,
diff --cc arch/x86/kernel/fpu/signal.c
index f74c29985497,935818b0406e..000000000000
--- a/arch/x86/kernel/fpu/signal.c
+++ b/arch/x86/kernel/fpu/signal.c
@@@ -372,14 -373,14 +372,19 @@@ static int __fpu_restore_sig(void __use
  	__cpu_invalidate_fpregs_state();
  	fpregs_unlock();
  
 -	fpregs = &fpu->fpstate->regs;
  	if (use_xsave() && !fx_only) {
++<<<<<<< HEAD
 +		ret = copy_sigframe_from_user_to_xstate(&fpu->state.xsave, buf_fx);
 +		if (ret)
 +			return ret;
++=======
+ 		if (copy_sigframe_from_user_to_xstate(fpu->fpstate, buf_fx))
+ 			return false;
++>>>>>>> 49e4eb4125d5 (x86/fpu/xstate: Use fpstate for copy_uabi_to_xstate())
  	} else {
 -		if (__copy_from_user(&fpregs->fxsave, buf_fx,
 -				     sizeof(fpregs->fxsave)))
 -			return false;
 +		if (__copy_from_user(&fpu->state.fxsave, buf_fx,
 +				     sizeof(fpu->state.fxsave)))
 +			return -EFAULT;
  
  		if (IS_ENABLED(CONFIG_X86_64)) {
  			/* Reject invalid MXCSR values. */
diff --cc arch/x86/kernel/fpu/xstate.h
index 0789a04ee705,379dbfa4f526..000000000000
--- a/arch/x86/kernel/fpu/xstate.h
+++ b/arch/x86/kernel/fpu/xstate.h
@@@ -15,4 -15,198 +15,201 @@@ static inline void xstate_init_xcomp_bv
  		xsave->header.xcomp_bv = mask | XCOMP_BV_COMPACTED_FORMAT;
  }
  
++<<<<<<< HEAD
++=======
+ enum xstate_copy_mode {
+ 	XSTATE_COPY_FP,
+ 	XSTATE_COPY_FX,
+ 	XSTATE_COPY_XSAVE,
+ };
+ 
+ struct membuf;
+ extern void __copy_xstate_to_uabi_buf(struct membuf to, struct fpstate *fpstate,
+ 				      u32 pkru_val, enum xstate_copy_mode copy_mode);
+ extern void copy_xstate_to_uabi_buf(struct membuf to, struct task_struct *tsk,
+ 				    enum xstate_copy_mode mode);
+ extern int copy_uabi_from_kernel_to_xstate(struct fpstate *fpstate, const void *kbuf);
+ extern int copy_sigframe_from_user_to_xstate(struct fpstate *fpstate, const void __user *ubuf);
+ 
+ 
+ extern void fpu__init_cpu_xstate(void);
+ extern void fpu__init_system_xstate(void);
+ 
+ extern void *get_xsave_addr(struct xregs_state *xsave, int xfeature_nr);
+ 
+ /* XSAVE/XRSTOR wrapper functions */
+ 
+ #ifdef CONFIG_X86_64
+ #define REX_PREFIX	"0x48, "
+ #else
+ #define REX_PREFIX
+ #endif
+ 
+ /* These macros all use (%edi)/(%rdi) as the single memory argument. */
+ #define XSAVE		".byte " REX_PREFIX "0x0f,0xae,0x27"
+ #define XSAVEOPT	".byte " REX_PREFIX "0x0f,0xae,0x37"
+ #define XSAVES		".byte " REX_PREFIX "0x0f,0xc7,0x2f"
+ #define XRSTOR		".byte " REX_PREFIX "0x0f,0xae,0x2f"
+ #define XRSTORS		".byte " REX_PREFIX "0x0f,0xc7,0x1f"
+ 
+ /*
+  * After this @err contains 0 on success or the trap number when the
+  * operation raises an exception.
+  */
+ #define XSTATE_OP(op, st, lmask, hmask, err)				\
+ 	asm volatile("1:" op "\n\t"					\
+ 		     "xor %[err], %[err]\n"				\
+ 		     "2:\n\t"						\
+ 		     _ASM_EXTABLE_TYPE(1b, 2b, EX_TYPE_FAULT_MCE_SAFE)	\
+ 		     : [err] "=a" (err)					\
+ 		     : "D" (st), "m" (*st), "a" (lmask), "d" (hmask)	\
+ 		     : "memory")
+ 
+ /*
+  * If XSAVES is enabled, it replaces XSAVEOPT because it supports a compact
+  * format and supervisor states in addition to modified optimization in
+  * XSAVEOPT.
+  *
+  * Otherwise, if XSAVEOPT is enabled, XSAVEOPT replaces XSAVE because XSAVEOPT
+  * supports modified optimization which is not supported by XSAVE.
+  *
+  * We use XSAVE as a fallback.
+  *
+  * The 661 label is defined in the ALTERNATIVE* macros as the address of the
+  * original instruction which gets replaced. We need to use it here as the
+  * address of the instruction where we might get an exception at.
+  */
+ #define XSTATE_XSAVE(st, lmask, hmask, err)				\
+ 	asm volatile(ALTERNATIVE_2(XSAVE,				\
+ 				   XSAVEOPT, X86_FEATURE_XSAVEOPT,	\
+ 				   XSAVES,   X86_FEATURE_XSAVES)	\
+ 		     "\n"						\
+ 		     "xor %[err], %[err]\n"				\
+ 		     "3:\n"						\
+ 		     ".pushsection .fixup,\"ax\"\n"			\
+ 		     "4: movl $-2, %[err]\n"				\
+ 		     "jmp 3b\n"						\
+ 		     ".popsection\n"					\
+ 		     _ASM_EXTABLE(661b, 4b)				\
+ 		     : [err] "=r" (err)					\
+ 		     : "D" (st), "m" (*st), "a" (lmask), "d" (hmask)	\
+ 		     : "memory")
+ 
+ /*
+  * Use XRSTORS to restore context if it is enabled. XRSTORS supports compact
+  * XSAVE area format.
+  */
+ #define XSTATE_XRESTORE(st, lmask, hmask)				\
+ 	asm volatile(ALTERNATIVE(XRSTOR,				\
+ 				 XRSTORS, X86_FEATURE_XSAVES)		\
+ 		     "\n"						\
+ 		     "3:\n"						\
+ 		     _ASM_EXTABLE_TYPE(661b, 3b, EX_TYPE_FPU_RESTORE)	\
+ 		     :							\
+ 		     : "D" (st), "m" (*st), "a" (lmask), "d" (hmask)	\
+ 		     : "memory")
+ 
+ /*
+  * Save processor xstate to xsave area.
+  *
+  * Uses either XSAVE or XSAVEOPT or XSAVES depending on the CPU features
+  * and command line options. The choice is permanent until the next reboot.
+  */
+ static inline void os_xsave(struct fpstate *fpstate)
+ {
+ 	u64 mask = fpstate->xfeatures;
+ 	u32 lmask = mask;
+ 	u32 hmask = mask >> 32;
+ 	int err;
+ 
+ 	WARN_ON_FPU(!alternatives_patched);
+ 
+ 	XSTATE_XSAVE(&fpstate->regs.xsave, lmask, hmask, err);
+ 
+ 	/* We should never fault when copying to a kernel buffer: */
+ 	WARN_ON_FPU(err);
+ }
+ 
+ /*
+  * Restore processor xstate from xsave area.
+  *
+  * Uses XRSTORS when XSAVES is used, XRSTOR otherwise.
+  */
+ static inline void os_xrstor(struct xregs_state *xstate, u64 mask)
+ {
+ 	u32 lmask = mask;
+ 	u32 hmask = mask >> 32;
+ 
+ 	XSTATE_XRESTORE(xstate, lmask, hmask);
+ }
+ 
+ /*
+  * Save xstate to user space xsave area.
+  *
+  * We don't use modified optimization because xrstor/xrstors might track
+  * a different application.
+  *
+  * We don't use compacted format xsave area for backward compatibility for
+  * old applications which don't understand the compacted format of the
+  * xsave area.
+  *
+  * The caller has to zero buf::header before calling this because XSAVE*
+  * does not touch the reserved fields in the header.
+  */
+ static inline int xsave_to_user_sigframe(struct xregs_state __user *buf)
+ {
+ 	/*
+ 	 * Include the features which are not xsaved/rstored by the kernel
+ 	 * internally, e.g. PKRU. That's user space ABI and also required
+ 	 * to allow the signal handler to modify PKRU.
+ 	 */
+ 	u64 mask = current->thread.fpu.fpstate->user_xfeatures;
+ 	u32 lmask = mask;
+ 	u32 hmask = mask >> 32;
+ 	int err;
+ 
+ 	stac();
+ 	XSTATE_OP(XSAVE, buf, lmask, hmask, err);
+ 	clac();
+ 
+ 	return err;
+ }
+ 
+ /*
+  * Restore xstate from user space xsave area.
+  */
+ static inline int xrstor_from_user_sigframe(struct xregs_state __user *buf, u64 mask)
+ {
+ 	struct xregs_state *xstate = ((__force struct xregs_state *)buf);
+ 	u32 lmask = mask;
+ 	u32 hmask = mask >> 32;
+ 	int err;
+ 
+ 	stac();
+ 	XSTATE_OP(XRSTOR, xstate, lmask, hmask, err);
+ 	clac();
+ 
+ 	return err;
+ }
+ 
+ /*
+  * Restore xstate from kernel space xsave area, return an error code instead of
+  * an exception.
+  */
+ static inline int os_xrstor_safe(struct xregs_state *xstate, u64 mask)
+ {
+ 	u32 lmask = mask;
+ 	u32 hmask = mask >> 32;
+ 	int err;
+ 
+ 	if (cpu_feature_enabled(X86_FEATURE_XSAVES))
+ 		XSTATE_OP(XRSTORS, xstate, lmask, hmask, err);
+ 	else
+ 		XSTATE_OP(XRSTOR, xstate, lmask, hmask, err);
+ 
+ 	return err;
+ }
+ 
+ 
++>>>>>>> 49e4eb4125d5 (x86/fpu/xstate: Use fpstate for copy_uabi_to_xstate())
  #endif
diff --git a/arch/x86/include/asm/fpu/xstate.h b/arch/x86/include/asm/fpu/xstate.h
index 2df5bd667a43..dfdcb3e79c4f 100644
--- a/arch/x86/include/asm/fpu/xstate.h
+++ b/arch/x86/include/asm/fpu/xstate.h
@@ -137,20 +137,8 @@ extern void __init update_regset_xstate_info(unsigned int size,
 void *get_xsave_addr(struct xregs_state *xsave, int xfeature_nr);
 const void *get_xsave_field_ptr(int xfeature_nr);
 int xfeature_size(int xfeature_nr);
-int copy_uabi_from_kernel_to_xstate(struct xregs_state *xsave, const void *kbuf);
-int copy_sigframe_from_user_to_xstate(struct xregs_state *xsave, const void __user *ubuf);
 
 void xsaves(struct xregs_state *xsave, u64 mask);
 void xrstors(struct xregs_state *xsave, u64 mask);
 
-enum xstate_copy_mode {
-	XSTATE_COPY_FP,
-	XSTATE_COPY_FX,
-	XSTATE_COPY_XSAVE,
-};
-
-struct membuf;
-void copy_xstate_to_uabi_buf(struct membuf to, struct task_struct *tsk,
-			     enum xstate_copy_mode mode);
-
 #endif
* Unmerged path arch/x86/kernel/fpu/core.c
* Unmerged path arch/x86/kernel/fpu/regset.c
* Unmerged path arch/x86/kernel/fpu/signal.c
diff --git a/arch/x86/kernel/fpu/xstate.c b/arch/x86/kernel/fpu/xstate.c
index 8c27dcecbad5..454aaff304bf 100644
--- a/arch/x86/kernel/fpu/xstate.c
+++ b/arch/x86/kernel/fpu/xstate.c
@@ -462,10 +462,11 @@ int xfeature_size(int xfeature_nr)
 }
 
 /* Validate an xstate header supplied by userspace (ptrace or sigreturn) */
-static int validate_user_xstate_header(const struct xstate_header *hdr)
+static int validate_user_xstate_header(const struct xstate_header *hdr,
+				       struct fpstate *fpstate)
 {
 	/* No unknown or supervisor features may be set */
-	if (hdr->xfeatures & ~xfeatures_mask_uabi())
+	if (hdr->xfeatures & ~fpstate->user_xfeatures)
 		return -EINVAL;
 
 	/* Userspace must use the uncompacted format */
@@ -1123,9 +1124,10 @@ static int copy_from_buffer(void *dst, unsigned int offset, unsigned int size,
 }
 
 
-static int copy_uabi_to_xstate(struct xregs_state *xsave, const void *kbuf,
+static int copy_uabi_to_xstate(struct fpstate *fpstate, const void *kbuf,
 			       const void __user *ubuf)
 {
+	struct xregs_state *xsave = &fpstate->regs.xsave;
 	unsigned int offset, size;
 	struct xstate_header hdr;
 	u64 mask;
@@ -1135,7 +1137,7 @@ static int copy_uabi_to_xstate(struct xregs_state *xsave, const void *kbuf,
 	if (copy_from_buffer(&hdr, offset, sizeof(hdr), kbuf, ubuf))
 		return -EFAULT;
 
-	if (validate_user_xstate_header(&hdr))
+	if (validate_user_xstate_header(&hdr, fpstate))
 		return -EINVAL;
 
 	/* Validate MXCSR when any of the related features is in use */
@@ -1190,9 +1192,9 @@ static int copy_uabi_to_xstate(struct xregs_state *xsave, const void *kbuf,
  * Convert from a ptrace standard-format kernel buffer to kernel XSAVE[S]
  * format and copy to the target thread. Used by ptrace and KVM.
  */
-int copy_uabi_from_kernel_to_xstate(struct xregs_state *xsave, const void *kbuf)
+int copy_uabi_from_kernel_to_xstate(struct fpstate *fpstate, const void *kbuf)
 {
-	return copy_uabi_to_xstate(xsave, kbuf, NULL);
+	return copy_uabi_to_xstate(fpstate, kbuf, NULL);
 }
 
 /*
@@ -1200,10 +1202,10 @@ int copy_uabi_from_kernel_to_xstate(struct xregs_state *xsave, const void *kbuf)
  * XSAVE[S] format and copy to the target thread. This is called from the
  * sigreturn() and rt_sigreturn() system calls.
  */
-int copy_sigframe_from_user_to_xstate(struct xregs_state *xsave,
+int copy_sigframe_from_user_to_xstate(struct fpstate *fpstate,
 				      const void __user *ubuf)
 {
-	return copy_uabi_to_xstate(xsave, NULL, ubuf);
+	return copy_uabi_to_xstate(fpstate, NULL, ubuf);
 }
 
 static bool validate_independent_components(u64 mask)
* Unmerged path arch/x86/kernel/fpu/xstate.h
