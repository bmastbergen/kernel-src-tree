ipv6: use prandom_u32() for ID generation

jira LE-1907
cve CVE-2021-45485
Rebuild_History Non-Buildable kernel-4.18.0-365.el8
commit-author Willy Tarreau <w@1wt.eu>
commit 62f20e068ccc50d6ab66fdb72ba90da2b9418c99
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-365.el8/62f20e06.failed

This is a complement to commit aa6dd211e4b1 ("inet: use bigger hash
table for IP ID generation"), but focusing on some specific aspects
of IPv6.

Contary to IPv4, IPv6 only uses packet IDs with fragments, and with a
minimum MTU of 1280, it's much less easy to force a remote peer to
produce many fragments to explore its ID sequence. In addition packet
IDs are 32-bit in IPv6, which further complicates their analysis. On
the other hand, it is often easier to choose among plenty of possible
source addresses and partially work around the bigger hash table the
commit above permits, which leaves IPv6 partially exposed to some
possibilities of remote analysis at the risk of weakening some
protocols like DNS if some IDs can be predicted with a good enough
probability.

Given the wide range of permitted IDs, the risk of collision is extremely
low so there's no need to rely on the positive increment algorithm that
is shared with the IPv4 code via ip_idents_reserve(). We have a fast
PRNG, so let's simply call prandom_u32() and be done with it.

Performance measurements at 10 Gbps couldn't show any difference with
the previous code, even when using a single core, because due to the
large fragments, we're limited to only ~930 kpps at 10 Gbps and the cost
of the random generation is completely offset by other operations and by
the network transfer time. In addition, this change removes the need to
update a shared entry in the idents table so it may even end up being
slightly faster on large scale systems where this matters.

The risk of at least one collision here is about 1/80 million among
10 IDs, 1/850k among 100 IDs, and still only 1/8.5k among 1000 IDs,
which remains very low compared to IPv4 where all IDs are reused
every 4 to 80ms on a 10 Gbps flow depending on packet sizes.

	Reported-by: Amit Klein <aksecurity@gmail.com>
	Signed-off-by: Willy Tarreau <w@1wt.eu>
	Reviewed-by: Eric Dumazet <edumazet@google.com>
Link: https://lore.kernel.org/r/20210529110746.6796-1-w@1wt.eu
	Signed-off-by: Jakub Kicinski <kuba@kernel.org>
(cherry picked from commit 62f20e068ccc50d6ab66fdb72ba90da2b9418c99)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/ipv6/output_core.c
diff --cc net/ipv6/output_core.c
index cb587251ed61,2880dc7d9a49..000000000000
--- a/net/ipv6/output_core.c
+++ b/net/ipv6/output_core.c
@@@ -14,29 -15,11 +14,28 @@@ static u32 __ipv6_select_ident(struct n
  			       const struct in6_addr *dst,
  			       const struct in6_addr *src)
  {
- 	const struct {
- 		struct in6_addr dst;
- 		struct in6_addr src;
- 	} __aligned(SIPHASH_ALIGNMENT) combined = {
- 		.dst = *dst,
- 		.src = *src,
- 	};
- 	u32 hash, id;
+ 	u32 id;
  
++<<<<<<< HEAD
 +	/* Note the following code is not safe, but this is okay. */
 +	if (unlikely(siphash_key_is_zero(&net->ipv4_ip_id_key)))
 +		get_random_bytes(&net->ipv4_ip_id_key,
 +				 sizeof(net->ipv4_ip_id_key));
 +
 +	hash = siphash(&combined, sizeof(combined), &net->ipv4_ip_id_key);
 +
 +	/* Treat id of 0 as unset and if we get 0 back from ip_idents_reserve,
 +	 * set the hight order instead thus minimizing possible future
 +	 * collisions.
 +	 */
 +	id = ip_idents_reserve(hash, 1);
 +	if (unlikely(!id))
 +		id = 1 << 31;
++=======
+ 	do {
+ 		id = prandom_u32();
+ 	} while (!id);
++>>>>>>> 62f20e068ccc (ipv6: use prandom_u32() for ID generation)
  
  	return id;
  }
* Unmerged path net/ipv6/output_core.c
