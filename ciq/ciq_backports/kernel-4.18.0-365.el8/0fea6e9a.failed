kasan, arm64: expand CONFIG_KASAN checks

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-365.el8
commit-author Andrey Konovalov <andreyknvl@google.com>
commit 0fea6e9af889f1a4e072f5de999e07fe6859fc88
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-365.el8/0fea6e9a.failed

Some #ifdef CONFIG_KASAN checks are only relevant for software KASAN modes
(either related to shadow memory or compiler instrumentation).  Expand
those into CONFIG_KASAN_GENERIC || CONFIG_KASAN_SW_TAGS.

Link: https://lkml.kernel.org/r/e6971e432dbd72bb897ff14134ebb7e169bdcf0c.1606161801.git.andreyknvl@google.com
	Signed-off-by: Andrey Konovalov <andreyknvl@google.com>
	Signed-off-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
	Reviewed-by: Catalin Marinas <catalin.marinas@arm.com>
	Reviewed-by: Alexander Potapenko <glider@google.com>
	Tested-by: Vincenzo Frascino <vincenzo.frascino@arm.com>
	Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
	Cc: Branislav Rankov <Branislav.Rankov@arm.com>
	Cc: Dmitry Vyukov <dvyukov@google.com>
	Cc: Evgenii Stepanov <eugenis@google.com>
	Cc: Kevin Brodsky <kevin.brodsky@arm.com>
	Cc: Marco Elver <elver@google.com>
	Cc: Vasily Gorbik <gor@linux.ibm.com>
	Cc: Will Deacon <will.deacon@arm.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 0fea6e9af889f1a4e072f5de999e07fe6859fc88)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/Kconfig
#	arch/arm64/include/asm/memory.h
#	arch/arm64/kernel/module.c
#	arch/arm64/mm/dump.c
#	include/linux/kasan.h
#	mm/ptdump.c
diff --cc arch/arm64/Kconfig
index 35a553b6fc18,9386b108b132..000000000000
--- a/arch/arm64/Kconfig
+++ b/arch/arm64/Kconfig
@@@ -291,9 -329,23 +291,26 @@@ config ARCH_SUPPORTS_UPROBE
  config ARCH_PROC_KCORE_TEXT
  	def_bool y
  
 -config BROKEN_GAS_INST
 -	def_bool !$(as-instr,1:\n.inst 0\n.rept . - 1b\n\nnop\n.endr\n)
 +source "init/Kconfig"
  
++<<<<<<< HEAD
 +source "kernel/Kconfig.freezer"
++=======
+ config KASAN_SHADOW_OFFSET
+ 	hex
+ 	depends on KASAN_GENERIC || KASAN_SW_TAGS
+ 	default 0xdfff800000000000 if (ARM64_VA_BITS_48 || ARM64_VA_BITS_52) && !KASAN_SW_TAGS
+ 	default 0xdfffc00000000000 if ARM64_VA_BITS_47 && !KASAN_SW_TAGS
+ 	default 0xdffffe0000000000 if ARM64_VA_BITS_42 && !KASAN_SW_TAGS
+ 	default 0xdfffffc000000000 if ARM64_VA_BITS_39 && !KASAN_SW_TAGS
+ 	default 0xdffffff800000000 if ARM64_VA_BITS_36 && !KASAN_SW_TAGS
+ 	default 0xefff800000000000 if (ARM64_VA_BITS_48 || ARM64_VA_BITS_52) && KASAN_SW_TAGS
+ 	default 0xefffc00000000000 if ARM64_VA_BITS_47 && KASAN_SW_TAGS
+ 	default 0xeffffe0000000000 if ARM64_VA_BITS_42 && KASAN_SW_TAGS
+ 	default 0xefffffc000000000 if ARM64_VA_BITS_39 && KASAN_SW_TAGS
+ 	default 0xeffffff800000000 if ARM64_VA_BITS_36 && KASAN_SW_TAGS
+ 	default 0xffffffffffffffff
++>>>>>>> 0fea6e9af889 (kasan, arm64: expand CONFIG_KASAN checks)
  
  source "arch/arm64/Kconfig.platforms"
  
diff --cc arch/arm64/include/asm/memory.h
index f6715969d223,cd671fb6707c..000000000000
--- a/arch/arm64/include/asm/memory.h
+++ b/arch/arm64/include/asm/memory.h
@@@ -94,13 -72,16 +94,21 @@@
   * address space for the shadow region respectively. They can bloat the stack
   * significantly, so double the (minimum) stack size when they are in use.
   */
++<<<<<<< HEAD
 +#ifdef CONFIG_KASAN
 +#define KASAN_SHADOW_SIZE	(UL(1) << (VA_BITS - KASAN_SHADOW_SCALE_SHIFT))
++=======
+ #if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)
+ #define KASAN_SHADOW_OFFSET	_AC(CONFIG_KASAN_SHADOW_OFFSET, UL)
+ #define KASAN_SHADOW_END	((UL(1) << (64 - KASAN_SHADOW_SCALE_SHIFT)) \
+ 					+ KASAN_SHADOW_OFFSET)
+ #define PAGE_END		(KASAN_SHADOW_END - (1UL << (vabits_actual - KASAN_SHADOW_SCALE_SHIFT)))
++>>>>>>> 0fea6e9af889 (kasan, arm64: expand CONFIG_KASAN checks)
  #define KASAN_THREAD_SHIFT	1
  #else
 +#define KASAN_SHADOW_SIZE	(0)
  #define KASAN_THREAD_SHIFT	0
 -#define PAGE_END		(_PAGE_END(VA_BITS_MIN))
 -#endif /* CONFIG_KASAN */
 +#endif
  
  #define MIN_THREAD_SHIFT	(14 + KASAN_THREAD_SHIFT)
  
diff --cc arch/arm64/kernel/module.c
index f0f27aeefb73,fe21e0f06492..000000000000
--- a/arch/arm64/kernel/module.c
+++ b/arch/arm64/kernel/module.c
@@@ -39,9 -30,13 +39,17 @@@ void *module_alloc(unsigned long size
  	if (IS_ENABLED(CONFIG_ARM64_MODULE_PLTS))
  		gfp_mask |= __GFP_NOWARN;
  
++<<<<<<< HEAD
++=======
+ 	if (IS_ENABLED(CONFIG_KASAN_GENERIC) ||
+ 	    IS_ENABLED(CONFIG_KASAN_SW_TAGS))
+ 		/* don't exceed the static module region - see below */
+ 		module_alloc_end = MODULES_END;
+ 
++>>>>>>> 0fea6e9af889 (kasan, arm64: expand CONFIG_KASAN checks)
  	p = __vmalloc_node_range(size, MODULE_ALIGN, module_alloc_base,
 -				module_alloc_end, gfp_mask, PAGE_KERNEL, 0,
 +				module_alloc_base + MODULES_VSIZE,
 +				gfp_mask, PAGE_KERNEL_EXEC, 0,
  				NUMA_NO_NODE, __builtin_return_address(0));
  
  	if (!p && IS_ENABLED(CONFIG_ARM64_MODULE_PLTS) &&
diff --cc arch/arm64/mm/dump.c
index e38089453a79,04137a8f3d2d..000000000000
--- a/arch/arm64/mm/dump.c
+++ b/arch/arm64/mm/dump.c
@@@ -33,16 -28,16 +33,26 @@@
  
  enum address_markers_idx {
  	PAGE_OFFSET_NR = 0,
++<<<<<<< HEAD:arch/arm64/mm/dump.c
 +	VA_START_NR,
 +#ifdef CONFIG_KASAN
++=======
+ 	PAGE_END_NR,
+ #if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)
++>>>>>>> 0fea6e9af889 (kasan, arm64: expand CONFIG_KASAN checks):arch/arm64/mm/ptdump.c
  	KASAN_START_NR,
  #endif
  };
  
  static struct addr_marker address_markers[] = {
  	{ PAGE_OFFSET,			"Linear Mapping start" },
++<<<<<<< HEAD:arch/arm64/mm/dump.c
 +	{ 0 /* VA_START */,		"Linear Mapping end" },
 +#ifdef CONFIG_KASAN
++=======
+ 	{ 0 /* PAGE_END */,		"Linear Mapping end" },
+ #if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)
++>>>>>>> 0fea6e9af889 (kasan, arm64: expand CONFIG_KASAN checks):arch/arm64/mm/ptdump.c
  	{ 0 /* KASAN_SHADOW_START */,	"Kasan shadow start" },
  	{ KASAN_SHADOW_END,		"Kasan shadow end" },
  #endif
@@@ -374,8 -382,8 +384,13 @@@ void ptdump_check_wx(void
  
  static int ptdump_init(void)
  {
++<<<<<<< HEAD:arch/arm64/mm/dump.c
 +	address_markers[VA_START_NR].start_address = VA_START;
 +#ifdef CONFIG_KASAN
++=======
+ 	address_markers[PAGE_END_NR].start_address = PAGE_END;
+ #if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)
++>>>>>>> 0fea6e9af889 (kasan, arm64: expand CONFIG_KASAN checks):arch/arm64/mm/ptdump.c
  	address_markers[KASAN_START_NR].start_address = KASAN_SHADOW_START;
  #endif
  	ptdump_initialize();
diff --cc include/linux/kasan.h
index f00d17cf6822,b1381ee6922a..000000000000
--- a/include/linux/kasan.h
+++ b/include/linux/kasan.h
@@@ -226,6 -235,31 +226,35 @@@ static inline void kasan_release_vmallo
  					 unsigned long end,
  					 unsigned long free_region_start,
  					 unsigned long free_region_end) {}
++<<<<<<< HEAD
 +#endif
++=======
+ 
+ #endif /* CONFIG_KASAN_VMALLOC */
+ 
+ #if (defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)) && \
+ 		!defined(CONFIG_KASAN_VMALLOC)
+ 
+ /*
+  * These functions provide a special case to support backing module
+  * allocations with real shadow memory. With KASAN vmalloc, the special
+  * case is unnecessary, as the work is handled in the generic case.
+  */
+ int kasan_module_alloc(void *addr, size_t size);
+ void kasan_free_shadow(const struct vm_struct *vm);
+ 
+ #else /* (CONFIG_KASAN_GENERIC || CONFIG_KASAN_SW_TAGS) && !CONFIG_KASAN_VMALLOC */
+ 
+ static inline int kasan_module_alloc(void *addr, size_t size) { return 0; }
+ static inline void kasan_free_shadow(const struct vm_struct *vm) {}
+ 
+ #endif /* (CONFIG_KASAN_GENERIC || CONFIG_KASAN_SW_TAGS) && !CONFIG_KASAN_VMALLOC */
+ 
+ #ifdef CONFIG_KASAN_INLINE
+ void kasan_non_canonical_hook(unsigned long addr);
+ #else /* CONFIG_KASAN_INLINE */
+ static inline void kasan_non_canonical_hook(unsigned long addr) { }
+ #endif /* CONFIG_KASAN_INLINE */
++>>>>>>> 0fea6e9af889 (kasan, arm64: expand CONFIG_KASAN checks)
  
  #endif /* LINUX_KASAN_H */
* Unmerged path mm/ptdump.c
* Unmerged path arch/arm64/Kconfig
diff --git a/arch/arm64/Makefile b/arch/arm64/Makefile
index 8fb3e953e94c..6a626a50381f 100644
--- a/arch/arm64/Makefile
+++ b/arch/arm64/Makefile
@@ -128,7 +128,7 @@ endif
 
 ifeq ($(CONFIG_KASAN_SW_TAGS), y)
 KASAN_SHADOW_SCALE_SHIFT := 4
-else
+else ifeq ($(CONFIG_KASAN_GENERIC), y)
 KASAN_SHADOW_SCALE_SHIFT := 3
 endif
 
diff --git a/arch/arm64/include/asm/assembler.h b/arch/arm64/include/asm/assembler.h
index 48612de3922e..b32d2c956ac5 100644
--- a/arch/arm64/include/asm/assembler.h
+++ b/arch/arm64/include/asm/assembler.h
@@ -499,7 +499,7 @@ USER(\label, ic	ivau, \tmp2)			// invalidate I line PoU
 #define NOKPROBE(x)
 #endif
 
-#ifdef CONFIG_KASAN
+#if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)
 #define EXPORT_SYMBOL_NOKASAN(name)
 #else
 #define EXPORT_SYMBOL_NOKASAN(name)	EXPORT_SYMBOL(name)
* Unmerged path arch/arm64/include/asm/memory.h
diff --git a/arch/arm64/include/asm/string.h b/arch/arm64/include/asm/string.h
index 03a6c256b7ec..bd7f26db1d63 100644
--- a/arch/arm64/include/asm/string.h
+++ b/arch/arm64/include/asm/string.h
@@ -16,7 +16,7 @@
 #ifndef __ASM_STRING_H
 #define __ASM_STRING_H
 
-#ifndef CONFIG_KASAN
+#if !(defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS))
 #define __HAVE_ARCH_STRRCHR
 extern char *strrchr(const char *, int c);
 
@@ -59,7 +59,8 @@ extern void *__memset(void *, int, __kernel_size_t);
 void memcpy_flushcache(void *dst, const void *src, size_t cnt);
 #endif
 
-#if defined(CONFIG_KASAN) && !defined(__SANITIZE_ADDRESS__)
+#if (defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)) && \
+	!defined(__SANITIZE_ADDRESS__)
 
 /*
  * For files that are not instrumented (e.g. mm/slub.c) we
diff --git a/arch/arm64/kernel/head.S b/arch/arm64/kernel/head.S
index e9dba3e173cf..1c2ff32f1719 100644
--- a/arch/arm64/kernel/head.S
+++ b/arch/arm64/kernel/head.S
@@ -447,7 +447,7 @@ __primary_switched:
 	bl	__pi_memset
 	dsb	ishst				// Make zero page visible to PTW
 
-#ifdef CONFIG_KASAN
+#if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)
 	bl	kasan_early_init
 #endif
 #ifdef CONFIG_RANDOMIZE_BASE
diff --git a/arch/arm64/kernel/image-vars.h b/arch/arm64/kernel/image-vars.h
index 199c94570a6a..d5ec554c52a8 100644
--- a/arch/arm64/kernel/image-vars.h
+++ b/arch/arm64/kernel/image-vars.h
@@ -35,7 +35,7 @@ __efistub_strncmp		= __pi_strncmp;
 __efistub_strrchr		= __pi_strrchr;
 __efistub___flush_dcache_area	= __pi___flush_dcache_area;
 
-#ifdef CONFIG_KASAN
+#if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)
 __efistub___memcpy		= __pi_memcpy;
 __efistub___memmove		= __pi_memmove;
 __efistub___memset		= __pi_memset;
diff --git a/arch/arm64/kernel/kaslr.c b/arch/arm64/kernel/kaslr.c
index ce7c985c3f9f..0ecfaded3d18 100644
--- a/arch/arm64/kernel/kaslr.c
+++ b/arch/arm64/kernel/kaslr.c
@@ -157,7 +157,8 @@ u64 __init kaslr_early_init(u64 dt_phys)
 	/* use the top 16 bits to randomize the linear region */
 	memstart_offset_seed = seed >> 48;
 
-	if (IS_ENABLED(CONFIG_KASAN))
+	if (IS_ENABLED(CONFIG_KASAN_GENERIC) ||
+	    IS_ENABLED(CONFIG_KASAN_SW_TAGS))
 		/*
 		 * KASAN does not expect the module region to intersect the
 		 * vmalloc region, since shadow memory is allocated for each
* Unmerged path arch/arm64/kernel/module.c
* Unmerged path arch/arm64/mm/dump.c
diff --git a/include/linux/kasan-checks.h b/include/linux/kasan-checks.h
index ac6aba632f2d..ca5e89fb10d3 100644
--- a/include/linux/kasan-checks.h
+++ b/include/linux/kasan-checks.h
@@ -9,7 +9,7 @@
  * even in compilation units that selectively disable KASAN, but must use KASAN
  * to validate access to an address.   Never use these in header files!
  */
-#ifdef CONFIG_KASAN
+#if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)
 bool __kasan_check_read(const volatile void *p, unsigned int size);
 bool __kasan_check_write(const volatile void *p, unsigned int size);
 #else
* Unmerged path include/linux/kasan.h
diff --git a/include/linux/moduleloader.h b/include/linux/moduleloader.h
index 86a0ce606f2f..24891508fd1c 100644
--- a/include/linux/moduleloader.h
+++ b/include/linux/moduleloader.h
@@ -86,7 +86,8 @@ void module_arch_cleanup(struct module *mod);
 /* Any cleanup before freeing mod->module_init */
 void module_arch_freeing_init(struct module *mod);
 
-#if defined(CONFIG_KASAN) && !defined(CONFIG_KASAN_VMALLOC)
+#if (defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)) && \
+		!defined(CONFIG_KASAN_VMALLOC)
 #include <linux/kasan.h>
 #define MODULE_ALIGN (PAGE_SIZE << KASAN_SHADOW_SCALE_SHIFT)
 #else
diff --git a/include/linux/string.h b/include/linux/string.h
index 1f903f72d857..b0bfaa82808b 100644
--- a/include/linux/string.h
+++ b/include/linux/string.h
@@ -267,7 +267,7 @@ void __write_overflow(void) __compiletime_error("detected write beyond size of o
 
 #if !defined(__NO_FORTIFY) && defined(__OPTIMIZE__) && defined(CONFIG_FORTIFY_SOURCE)
 
-#ifdef CONFIG_KASAN
+#if defined(CONFIG_KASAN_GENERIC) || defined(CONFIG_KASAN_SW_TAGS)
 extern void *__underlying_memchr(const void *p, int c, __kernel_size_t size) __RENAME(memchr);
 extern int __underlying_memcmp(const void *p, const void *q, __kernel_size_t size) __RENAME(memcmp);
 extern void *__underlying_memcpy(void *p, const void *q, __kernel_size_t size) __RENAME(memcpy);
* Unmerged path mm/ptdump.c
diff --git a/scripts/Makefile.lib b/scripts/Makefile.lib
index e16181669bdb..ec05e9cae8f6 100644
--- a/scripts/Makefile.lib
+++ b/scripts/Makefile.lib
@@ -120,10 +120,12 @@ endif
 # we don't want to check (depends on variables KASAN_SANITIZE_obj.o, KASAN_SANITIZE)
 #
 ifeq ($(CONFIG_KASAN),y)
+ifneq ($(CONFIG_KASAN_HW_TAGS),y)
 _c_flags += $(if $(patsubst n%,, \
 		$(KASAN_SANITIZE_$(basetarget).o)$(KASAN_SANITIZE)y), \
 		$(CFLAGS_KASAN), $(CFLAGS_KASAN_NOSANITIZE))
 endif
+endif
 
 ifeq ($(CONFIG_UBSAN),y)
 _c_flags += $(if $(patsubst n%,, \
