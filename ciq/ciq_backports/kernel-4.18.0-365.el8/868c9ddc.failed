swiotlb: add overflow checks to swiotlb_bounce

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-365.el8
commit-author Dominique Martinet <dominique.martinet@atmark-techno.com>
commit 868c9ddc182bc6728bb380cbfb3170734f72c599
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-365.el8/868c9ddc.failed

This is a follow-up on 5f89468e2f06 ("swiotlb: manipulate orig_addr
when tlb_addr has offset") which fixed unaligned dma mappings,
making sure the following overflows are caught:

- offset of the start of the slot within the device bigger than
requested address' offset, in other words if the base address
given in swiotlb_tbl_map_single to create the mapping (orig_addr)
was after the requested address for the sync (tlb_offset) in the
same block:

 |------------------------------------------| block
              <----------------------------> mapped part of the block
              ^
              orig_addr
       ^
       invalid tlb_addr for sync

- if the resulting offset was bigger than the allocation size
this one could happen if the mapping was not until the end. e.g.

 |------------------------------------------| block
      <---------------------> mapped part of the block
      ^                               ^
      orig_addr                       invalid tlb_addr

Both should never happen so print a warning and bail out without trying
to adjust the sizes/offsets: the first one could try to sync from
orig_addr to whatever is left of the requested size, but the later
really has nothing to sync there...

	Signed-off-by: Dominique Martinet <dominique.martinet@atmark-techno.com>
	Cc: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
	Reviewed-by: Bumyong Lee <bumyong.lee@samsung.com
	Cc: Chanho Park <chanho61.park@samsung.com>
	Cc: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Konrad Rzeszutek Wilk <konrad@kernel.org>
(cherry picked from commit 868c9ddc182bc6728bb380cbfb3170734f72c599)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/dma/swiotlb.c
diff --cc kernel/dma/swiotlb.c
index be0e4e04c6fd,f1a9ae7fad8f..000000000000
--- a/kernel/dma/swiotlb.c
+++ b/kernel/dma/swiotlb.c
@@@ -467,11 -356,46 +467,45 @@@ void __init swiotlb_exit(void
  /*
   * Bounce: copy the swiotlb buffer from or back to the original dma location
   */
 -static void swiotlb_bounce(struct device *dev, phys_addr_t tlb_addr, size_t size,
 -			   enum dma_data_direction dir)
 +static void swiotlb_bounce(phys_addr_t orig_addr, phys_addr_t tlb_addr,
 +			   size_t size, enum dma_data_direction dir)
  {
 -	struct io_tlb_mem *mem = dev->dma_io_tlb_mem;
 -	int index = (tlb_addr - mem->start) >> IO_TLB_SHIFT;
 -	phys_addr_t orig_addr = mem->slots[index].orig_addr;
 -	size_t alloc_size = mem->slots[index].alloc_size;
  	unsigned long pfn = PFN_DOWN(orig_addr);
  	unsigned char *vaddr = phys_to_virt(tlb_addr);
++<<<<<<< HEAD
++=======
+ 	unsigned int tlb_offset, orig_addr_offset;
+ 
+ 	if (orig_addr == INVALID_PHYS_ADDR)
+ 		return;
+ 
+ 	tlb_offset = tlb_addr & (IO_TLB_SIZE - 1);
+ 	orig_addr_offset = swiotlb_align_offset(dev, orig_addr);
+ 	if (tlb_offset < orig_addr_offset) {
+ 		dev_WARN_ONCE(dev, 1,
+ 			"Access before mapping start detected. orig offset %u, requested offset %u.\n",
+ 			orig_addr_offset, tlb_offset);
+ 		return;
+ 	}
+ 
+ 	tlb_offset -= orig_addr_offset;
+ 	if (tlb_offset > alloc_size) {
+ 		dev_WARN_ONCE(dev, 1,
+ 			"Buffer overflow detected. Allocation size: %zu. Mapping size: %zu+%u.\n",
+ 			alloc_size, size, tlb_offset);
+ 		return;
+ 	}
+ 
+ 	orig_addr += tlb_offset;
+ 	alloc_size -= tlb_offset;
+ 
+ 	if (size > alloc_size) {
+ 		dev_WARN_ONCE(dev, 1,
+ 			"Buffer overflow detected. Allocation size: %zu. Mapping size: %zu.\n",
+ 			alloc_size, size);
+ 		size = alloc_size;
+ 	}
++>>>>>>> 868c9ddc182b (swiotlb: add overflow checks to swiotlb_bounce)
  
  	if (PageHighMem(pfn_to_page(pfn))) {
  		/* The buffer does not have a mapping.  Map it in and copy */
* Unmerged path kernel/dma/swiotlb.c
