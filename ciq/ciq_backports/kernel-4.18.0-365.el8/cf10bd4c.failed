kasan: fix per-page tags for non-page_alloc pages

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-365.el8
commit-author Andrey Konovalov <andreyknvl@google.com>
commit cf10bd4c4aff8dd64d1aa7f2a529d0c672bc16af
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-365.el8/cf10bd4c.failed

To allow performing tag checks on page_alloc addresses obtained via
page_address(), tag-based KASAN modes store tags for page_alloc
allocations in page->flags.

Currently, the default tag value stored in page->flags is 0x00.
Therefore, page_address() returns a 0x00ffff...  address for pages that
were not allocated via page_alloc.

This might cause problems.  A particular case we encountered is a
conflict with KFENCE.  If a KFENCE-allocated slab object is being freed
via kfree(page_address(page) + offset), the address passed to kfree()
will get tagged with 0x00 (as slab pages keep the default per-page
tags).  This leads to is_kfence_address() check failing, and a KFENCE
object ending up in normal slab freelist, which causes memory
corruptions.

This patch changes the way KASAN stores tag in page-flags: they are now
stored xor'ed with 0xff.  This way, KASAN doesn't need to initialize
per-page flags for every created page, which might be slow.

With this change, page_address() returns natively-tagged (with 0xff)
pointers for pages that didn't have tags set explicitly.

This patch fixes the encountered conflict with KFENCE and prevents more
similar issues that can occur in the future.

Link: https://lkml.kernel.org/r/1a41abb11c51b264511d9e71c303bb16d5cb367b.1615475452.git.andreyknvl@google.com
Fixes: 2813b9c02962 ("kasan, mm, arm64: tag non slab memory allocated via pagealloc")
	Signed-off-by: Andrey Konovalov <andreyknvl@google.com>
	Reviewed-by: Marco Elver <elver@google.com>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Will Deacon <will.deacon@arm.com>
	Cc: Vincenzo Frascino <vincenzo.frascino@arm.com>
	Cc: Dmitry Vyukov <dvyukov@google.com>
	Cc: Andrey Ryabinin <aryabinin@virtuozzo.com>
	Cc: Alexander Potapenko <glider@google.com>
	Cc: Peter Collingbourne <pcc@google.com>
	Cc: Evgenii Stepanov <eugenis@google.com>
	Cc: Branislav Rankov <Branislav.Rankov@arm.com>
	Cc: Kevin Brodsky <kevin.brodsky@arm.com>
	Cc: <stable@vger.kernel.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit cf10bd4c4aff8dd64d1aa7f2a529d0c672bc16af)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/mm.h
diff --cc include/linux/mm.h
index 3b01604de2d9,8ba434287387..000000000000
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@@ -1375,16 -1459,33 +1375,45 @@@ static inline bool cpupid_match_pid(str
  }
  #endif /* CONFIG_NUMA_BALANCING */
  
++<<<<<<< HEAD
 +#ifdef CONFIG_KASAN_SW_TAGS
 +static inline u8 page_kasan_tag(const struct page *page)
 +{
 +	return (page->flags >> KASAN_TAG_PGSHIFT) & KASAN_TAG_MASK;
++=======
+ #if defined(CONFIG_KASAN_SW_TAGS) || defined(CONFIG_KASAN_HW_TAGS)
+ 
+ /*
+  * KASAN per-page tags are stored xor'ed with 0xff. This allows to avoid
+  * setting tags for all pages to native kernel tag value 0xff, as the default
+  * value 0x00 maps to 0xff.
+  */
+ 
+ static inline u8 page_kasan_tag(const struct page *page)
+ {
+ 	u8 tag = 0xff;
+ 
+ 	if (kasan_enabled()) {
+ 		tag = (page->flags >> KASAN_TAG_PGSHIFT) & KASAN_TAG_MASK;
+ 		tag ^= 0xff;
+ 	}
+ 
+ 	return tag;
++>>>>>>> cf10bd4c4aff (kasan: fix per-page tags for non-page_alloc pages)
  }
  
  static inline void page_kasan_tag_set(struct page *page, u8 tag)
  {
++<<<<<<< HEAD
 +	page->flags &= ~(KASAN_TAG_MASK << KASAN_TAG_PGSHIFT);
 +	page->flags |= (tag & KASAN_TAG_MASK) << KASAN_TAG_PGSHIFT;
++=======
+ 	if (kasan_enabled()) {
+ 		tag ^= 0xff;
+ 		page->flags &= ~(KASAN_TAG_MASK << KASAN_TAG_PGSHIFT);
+ 		page->flags |= (tag & KASAN_TAG_MASK) << KASAN_TAG_PGSHIFT;
+ 	}
++>>>>>>> cf10bd4c4aff (kasan: fix per-page tags for non-page_alloc pages)
  }
  
  static inline void page_kasan_tag_reset(struct page *page)
* Unmerged path include/linux/mm.h
