x86/speculation: Add seccomp Spectre v2 user space protection mode

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-80.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 6b3e64c237c072797a9ec918654a60e3a46488e2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-80.el8/6b3e64c2.failed

If 'prctl' mode of user space protection from spectre v2 is selected
on the kernel command-line, STIBP and IBPB are applied on tasks which
restrict their indirect branch speculation via prctl.

SECCOMP enables the SSBD mitigation for sandboxed tasks already, so it
makes sense to prevent spectre v2 user space to user space attacks as
well.

The Intel mitigation guide documents how STIPB works:
    
   Setting bit 1 (STIBP) of the IA32_SPEC_CTRL MSR on a logical processor
   prevents the predicted targets of indirect branches on any logical
   processor of that core from being controlled by software that executes
   (or executed previously) on another logical processor of the same core.

Ergo setting STIBP protects the task itself from being attacked from a task
running on a different hyper-thread and protects the tasks running on
different hyper-threads from being attacked.

While the document suggests that the branch predictors are shielded between
the logical processors, the observed performance regressions suggest that
STIBP simply disables the branch predictor more or less completely. Of
course the document wording is vague, but the fact that there is also no
requirement for issuing IBPB when STIBP is used points clearly in that
direction. The kernel still issues IBPB even when STIBP is used until Intel
clarifies the whole mechanism.

IBPB is issued when the task switches out, so malicious sandbox code cannot
mistrain the branch predictor for the next user space task on the same
logical processor.

	Signed-off-by: Jiri Kosina <jkosina@suse.cz>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Reviewed-by: Ingo Molnar <mingo@kernel.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Tom Lendacky <thomas.lendacky@amd.com>
	Cc: Josh Poimboeuf <jpoimboe@redhat.com>
	Cc: Andrea Arcangeli <aarcange@redhat.com>
	Cc: David Woodhouse <dwmw@amazon.co.uk>
	Cc: Tim Chen <tim.c.chen@linux.intel.com>
	Cc: Andi Kleen <ak@linux.intel.com>
	Cc: Dave Hansen <dave.hansen@intel.com>
	Cc: Casey Schaufler <casey.schaufler@intel.com>
	Cc: Asit Mallick <asit.k.mallick@intel.com>
	Cc: Arjan van de Ven <arjan@linux.intel.com>
	Cc: Jon Masters <jcm@redhat.com>
	Cc: Waiman Long <longman9394@gmail.com>
	Cc: Greg KH <gregkh@linuxfoundation.org>
	Cc: Dave Stewart <david.c.stewart@intel.com>
	Cc: Kees Cook <keescook@chromium.org>
	Cc: stable@vger.kernel.org
Link: https://lkml.kernel.org/r/20181125185006.051663132@linutronix.de


(cherry picked from commit 6b3e64c237c072797a9ec918654a60e3a46488e2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/admin-guide/kernel-parameters.txt
#	arch/x86/include/asm/nospec-branch.h
#	arch/x86/kernel/cpu/bugs.c
diff --cc Documentation/admin-guide/kernel-parameters.txt
index 8059a56ef18f,f405281bb202..000000000000
--- a/Documentation/admin-guide/kernel-parameters.txt
+++ b/Documentation/admin-guide/kernel-parameters.txt
@@@ -4093,6 -4225,36 +4093,39 @@@
  			Not specifying this option is equivalent to
  			spectre_v2=auto.
  
++<<<<<<< HEAD
++=======
+ 	spectre_v2_user=
+ 			[X86] Control mitigation of Spectre variant 2
+ 		        (indirect branch speculation) vulnerability between
+ 		        user space tasks
+ 
+ 			on	- Unconditionally enable mitigations. Is
+ 				  enforced by spectre_v2=on
+ 
+ 			off     - Unconditionally disable mitigations. Is
+ 				  enforced by spectre_v2=off
+ 
+ 			prctl   - Indirect branch speculation is enabled,
+ 				  but mitigation can be enabled via prctl
+ 				  per thread.  The mitigation control state
+ 				  is inherited on fork.
+ 
+ 			seccomp
+ 				- Same as "prctl" above, but all seccomp
+ 				  threads will enable the mitigation unless
+ 				  they explicitly opt out.
+ 
+ 			auto    - Kernel selects the mitigation depending on
+ 				  the available CPU features and vulnerability.
+ 
+ 			Default mitigation:
+ 			If CONFIG_SECCOMP=y then "seccomp", otherwise "prctl"
+ 
+ 			Not specifying this option is equivalent to
+ 			spectre_v2_user=auto.
+ 
++>>>>>>> 6b3e64c237c0 (x86/speculation: Add seccomp Spectre v2 user space protection mode)
  	spec_store_bypass_disable=
  			[HW] Control Speculative Store Bypass (SSB) Disable mitigation
  			(Speculative Store Bypass vulnerability)
diff --cc arch/x86/include/asm/nospec-branch.h
index c202a64edd95,032b6009baab..000000000000
--- a/arch/x86/include/asm/nospec-branch.h
+++ b/arch/x86/include/asm/nospec-branch.h
@@@ -226,6 -228,14 +226,17 @@@ enum spectre_v2_mitigation 
  	SPECTRE_V2_IBRS_ENHANCED,
  };
  
++<<<<<<< HEAD
++=======
+ /* The indirect branch speculation control variants */
+ enum spectre_v2_user_mitigation {
+ 	SPECTRE_V2_USER_NONE,
+ 	SPECTRE_V2_USER_STRICT,
+ 	SPECTRE_V2_USER_PRCTL,
+ 	SPECTRE_V2_USER_SECCOMP,
+ };
+ 
++>>>>>>> 6b3e64c237c0 (x86/speculation: Add seccomp Spectre v2 user space protection mode)
  /* The Speculative Store Bypass disable variants */
  enum ssb_mitigation {
  	SPEC_STORE_BYPASS_NONE,
diff --cc arch/x86/kernel/cpu/bugs.c
index 990094aa6fc9,c9e304960534..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -255,6 -241,156 +255,159 @@@ static inline bool match_option(const c
  	return len == arglen && !strncmp(arg, opt, len);
  }
  
++<<<<<<< HEAD
++=======
+ /* The kernel command line selection for spectre v2 */
+ enum spectre_v2_mitigation_cmd {
+ 	SPECTRE_V2_CMD_NONE,
+ 	SPECTRE_V2_CMD_AUTO,
+ 	SPECTRE_V2_CMD_FORCE,
+ 	SPECTRE_V2_CMD_RETPOLINE,
+ 	SPECTRE_V2_CMD_RETPOLINE_GENERIC,
+ 	SPECTRE_V2_CMD_RETPOLINE_AMD,
+ };
+ 
+ enum spectre_v2_user_cmd {
+ 	SPECTRE_V2_USER_CMD_NONE,
+ 	SPECTRE_V2_USER_CMD_AUTO,
+ 	SPECTRE_V2_USER_CMD_FORCE,
+ 	SPECTRE_V2_USER_CMD_PRCTL,
+ 	SPECTRE_V2_USER_CMD_SECCOMP,
+ };
+ 
+ static const char * const spectre_v2_user_strings[] = {
+ 	[SPECTRE_V2_USER_NONE]		= "User space: Vulnerable",
+ 	[SPECTRE_V2_USER_STRICT]	= "User space: Mitigation: STIBP protection",
+ 	[SPECTRE_V2_USER_PRCTL]		= "User space: Mitigation: STIBP via prctl",
+ 	[SPECTRE_V2_USER_SECCOMP]	= "User space: Mitigation: STIBP via seccomp and prctl",
+ };
+ 
+ static const struct {
+ 	const char			*option;
+ 	enum spectre_v2_user_cmd	cmd;
+ 	bool				secure;
+ } v2_user_options[] __initdata = {
+ 	{ "auto",	SPECTRE_V2_USER_CMD_AUTO,	false },
+ 	{ "off",	SPECTRE_V2_USER_CMD_NONE,	false },
+ 	{ "on",		SPECTRE_V2_USER_CMD_FORCE,	true  },
+ 	{ "prctl",	SPECTRE_V2_USER_CMD_PRCTL,	false },
+ 	{ "seccomp",	SPECTRE_V2_USER_CMD_SECCOMP,	false },
+ };
+ 
+ static void __init spec_v2_user_print_cond(const char *reason, bool secure)
+ {
+ 	if (boot_cpu_has_bug(X86_BUG_SPECTRE_V2) != secure)
+ 		pr_info("spectre_v2_user=%s forced on command line.\n", reason);
+ }
+ 
+ static enum spectre_v2_user_cmd __init
+ spectre_v2_parse_user_cmdline(enum spectre_v2_mitigation_cmd v2_cmd)
+ {
+ 	char arg[20];
+ 	int ret, i;
+ 
+ 	switch (v2_cmd) {
+ 	case SPECTRE_V2_CMD_NONE:
+ 		return SPECTRE_V2_USER_CMD_NONE;
+ 	case SPECTRE_V2_CMD_FORCE:
+ 		return SPECTRE_V2_USER_CMD_FORCE;
+ 	default:
+ 		break;
+ 	}
+ 
+ 	ret = cmdline_find_option(boot_command_line, "spectre_v2_user",
+ 				  arg, sizeof(arg));
+ 	if (ret < 0)
+ 		return SPECTRE_V2_USER_CMD_AUTO;
+ 
+ 	for (i = 0; i < ARRAY_SIZE(v2_user_options); i++) {
+ 		if (match_option(arg, ret, v2_user_options[i].option)) {
+ 			spec_v2_user_print_cond(v2_user_options[i].option,
+ 						v2_user_options[i].secure);
+ 			return v2_user_options[i].cmd;
+ 		}
+ 	}
+ 
+ 	pr_err("Unknown user space protection option (%s). Switching to AUTO select\n", arg);
+ 	return SPECTRE_V2_USER_CMD_AUTO;
+ }
+ 
+ static void __init
+ spectre_v2_user_select_mitigation(enum spectre_v2_mitigation_cmd v2_cmd)
+ {
+ 	enum spectre_v2_user_mitigation mode = SPECTRE_V2_USER_NONE;
+ 	bool smt_possible = IS_ENABLED(CONFIG_SMP);
+ 
+ 	if (!boot_cpu_has(X86_FEATURE_IBPB) && !boot_cpu_has(X86_FEATURE_STIBP))
+ 		return;
+ 
+ 	if (cpu_smt_control == CPU_SMT_FORCE_DISABLED ||
+ 	    cpu_smt_control == CPU_SMT_NOT_SUPPORTED)
+ 		smt_possible = false;
+ 
+ 	switch (spectre_v2_parse_user_cmdline(v2_cmd)) {
+ 	case SPECTRE_V2_USER_CMD_NONE:
+ 		goto set_mode;
+ 	case SPECTRE_V2_USER_CMD_FORCE:
+ 		mode = SPECTRE_V2_USER_STRICT;
+ 		break;
+ 	case SPECTRE_V2_USER_CMD_PRCTL:
+ 		mode = SPECTRE_V2_USER_PRCTL;
+ 		break;
+ 	case SPECTRE_V2_USER_CMD_AUTO:
+ 	case SPECTRE_V2_USER_CMD_SECCOMP:
+ 		if (IS_ENABLED(CONFIG_SECCOMP))
+ 			mode = SPECTRE_V2_USER_SECCOMP;
+ 		else
+ 			mode = SPECTRE_V2_USER_PRCTL;
+ 		break;
+ 	}
+ 
+ 	/* Initialize Indirect Branch Prediction Barrier */
+ 	if (boot_cpu_has(X86_FEATURE_IBPB)) {
+ 		setup_force_cpu_cap(X86_FEATURE_USE_IBPB);
+ 
+ 		switch (mode) {
+ 		case SPECTRE_V2_USER_STRICT:
+ 			static_branch_enable(&switch_mm_always_ibpb);
+ 			break;
+ 		case SPECTRE_V2_USER_PRCTL:
+ 		case SPECTRE_V2_USER_SECCOMP:
+ 			static_branch_enable(&switch_mm_cond_ibpb);
+ 			break;
+ 		default:
+ 			break;
+ 		}
+ 
+ 		pr_info("mitigation: Enabling %s Indirect Branch Prediction Barrier\n",
+ 			mode == SPECTRE_V2_USER_STRICT ? "always-on" : "conditional");
+ 	}
+ 
+ 	/* If enhanced IBRS is enabled no STIPB required */
+ 	if (spectre_v2_enabled == SPECTRE_V2_IBRS_ENHANCED)
+ 		return;
+ 
+ 	/*
+ 	 * If SMT is not possible or STIBP is not available clear the STIPB
+ 	 * mode.
+ 	 */
+ 	if (!smt_possible || !boot_cpu_has(X86_FEATURE_STIBP))
+ 		mode = SPECTRE_V2_USER_NONE;
+ set_mode:
+ 	spectre_v2_user = mode;
+ 	/* Only print the STIBP mode when SMT possible */
+ 	if (smt_possible)
+ 		pr_info("%s\n", spectre_v2_user_strings[mode]);
+ }
+ 
+ static const char * const spectre_v2_strings[] = {
+ 	[SPECTRE_V2_NONE]			= "Vulnerable",
+ 	[SPECTRE_V2_RETPOLINE_GENERIC]		= "Mitigation: Full generic retpoline",
+ 	[SPECTRE_V2_RETPOLINE_AMD]		= "Mitigation: Full AMD retpoline",
+ 	[SPECTRE_V2_IBRS_ENHANCED]		= "Mitigation: Enhanced IBRS",
+ };
+ 
++>>>>>>> 6b3e64c237c0 (x86/speculation: Add seccomp Spectre v2 user space protection mode)
  static const struct {
  	const char *option;
  	enum spectre_v2_mitigation_cmd cmd;
@@@ -455,6 -555,60 +608,63 @@@ specv2_set_mode
  	arch_smt_update();
  }
  
++<<<<<<< HEAD
++=======
+ static void update_stibp_msr(void * __unused)
+ {
+ 	wrmsrl(MSR_IA32_SPEC_CTRL, x86_spec_ctrl_base);
+ }
+ 
+ /* Update x86_spec_ctrl_base in case SMT state changed. */
+ static void update_stibp_strict(void)
+ {
+ 	u64 mask = x86_spec_ctrl_base & ~SPEC_CTRL_STIBP;
+ 
+ 	if (sched_smt_active())
+ 		mask |= SPEC_CTRL_STIBP;
+ 
+ 	if (mask == x86_spec_ctrl_base)
+ 		return;
+ 
+ 	pr_info("Update user space SMT mitigation: STIBP %s\n",
+ 		mask & SPEC_CTRL_STIBP ? "always-on" : "off");
+ 	x86_spec_ctrl_base = mask;
+ 	on_each_cpu(update_stibp_msr, NULL, 1);
+ }
+ 
+ /* Update the static key controlling the evaluation of TIF_SPEC_IB */
+ static void update_indir_branch_cond(void)
+ {
+ 	if (sched_smt_active())
+ 		static_branch_enable(&switch_to_cond_stibp);
+ 	else
+ 		static_branch_disable(&switch_to_cond_stibp);
+ }
+ 
+ void arch_smt_update(void)
+ {
+ 	/* Enhanced IBRS implies STIBP. No update required. */
+ 	if (spectre_v2_enabled == SPECTRE_V2_IBRS_ENHANCED)
+ 		return;
+ 
+ 	mutex_lock(&spec_ctrl_mutex);
+ 
+ 	switch (spectre_v2_user) {
+ 	case SPECTRE_V2_USER_NONE:
+ 		break;
+ 	case SPECTRE_V2_USER_STRICT:
+ 		update_stibp_strict();
+ 		break;
+ 	case SPECTRE_V2_USER_PRCTL:
+ 	case SPECTRE_V2_USER_SECCOMP:
+ 		update_indir_branch_cond();
+ 		break;
+ 	}
+ 
+ 	mutex_unlock(&spec_ctrl_mutex);
+ }
+ 
++>>>>>>> 6b3e64c237c0 (x86/speculation: Add seccomp Spectre v2 user space protection mode)
  #undef pr_fmt
  #define pr_fmt(fmt)	"Speculative Store Bypass: " fmt
  
@@@ -674,6 -868,28 +886,31 @@@ static int ssb_prctl_get(struct task_st
  	}
  }
  
++<<<<<<< HEAD
++=======
+ static int ib_prctl_get(struct task_struct *task)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V2))
+ 		return PR_SPEC_NOT_AFFECTED;
+ 
+ 	switch (spectre_v2_user) {
+ 	case SPECTRE_V2_USER_NONE:
+ 		return PR_SPEC_ENABLE;
+ 	case SPECTRE_V2_USER_PRCTL:
+ 	case SPECTRE_V2_USER_SECCOMP:
+ 		if (task_spec_ib_force_disable(task))
+ 			return PR_SPEC_PRCTL | PR_SPEC_FORCE_DISABLE;
+ 		if (task_spec_ib_disable(task))
+ 			return PR_SPEC_PRCTL | PR_SPEC_DISABLE;
+ 		return PR_SPEC_PRCTL | PR_SPEC_ENABLE;
+ 	case SPECTRE_V2_USER_STRICT:
+ 		return PR_SPEC_DISABLE;
+ 	default:
+ 		return PR_SPEC_NOT_AFFECTED;
+ 	}
+ }
+ 
++>>>>>>> 6b3e64c237c0 (x86/speculation: Add seccomp Spectre v2 user space protection mode)
  int arch_prctl_spec_ctrl_get(struct task_struct *task, unsigned long which)
  {
  	switch (which) {
@@@ -728,6 -1031,71 +965,74 @@@ static void __init l1tf_select_mitigati
  
  #ifdef CONFIG_SYSFS
  
++<<<<<<< HEAD
++=======
+ #define L1TF_DEFAULT_MSG "Mitigation: PTE Inversion"
+ 
+ #if IS_ENABLED(CONFIG_KVM_INTEL)
+ static const char * const l1tf_vmx_states[] = {
+ 	[VMENTER_L1D_FLUSH_AUTO]		= "auto",
+ 	[VMENTER_L1D_FLUSH_NEVER]		= "vulnerable",
+ 	[VMENTER_L1D_FLUSH_COND]		= "conditional cache flushes",
+ 	[VMENTER_L1D_FLUSH_ALWAYS]		= "cache flushes",
+ 	[VMENTER_L1D_FLUSH_EPT_DISABLED]	= "EPT disabled",
+ 	[VMENTER_L1D_FLUSH_NOT_REQUIRED]	= "flush not necessary"
+ };
+ 
+ static ssize_t l1tf_show_state(char *buf)
+ {
+ 	if (l1tf_vmx_mitigation == VMENTER_L1D_FLUSH_AUTO)
+ 		return sprintf(buf, "%s\n", L1TF_DEFAULT_MSG);
+ 
+ 	if (l1tf_vmx_mitigation == VMENTER_L1D_FLUSH_EPT_DISABLED ||
+ 	    (l1tf_vmx_mitigation == VMENTER_L1D_FLUSH_NEVER &&
+ 	     sched_smt_active())) {
+ 		return sprintf(buf, "%s; VMX: %s\n", L1TF_DEFAULT_MSG,
+ 			       l1tf_vmx_states[l1tf_vmx_mitigation]);
+ 	}
+ 
+ 	return sprintf(buf, "%s; VMX: %s, SMT %s\n", L1TF_DEFAULT_MSG,
+ 		       l1tf_vmx_states[l1tf_vmx_mitigation],
+ 		       sched_smt_active() ? "vulnerable" : "disabled");
+ }
+ #else
+ static ssize_t l1tf_show_state(char *buf)
+ {
+ 	return sprintf(buf, "%s\n", L1TF_DEFAULT_MSG);
+ }
+ #endif
+ 
+ static char *stibp_state(void)
+ {
+ 	if (spectre_v2_enabled == SPECTRE_V2_IBRS_ENHANCED)
+ 		return "";
+ 
+ 	switch (spectre_v2_user) {
+ 	case SPECTRE_V2_USER_NONE:
+ 		return ", STIBP: disabled";
+ 	case SPECTRE_V2_USER_STRICT:
+ 		return ", STIBP: forced";
+ 	case SPECTRE_V2_USER_PRCTL:
+ 	case SPECTRE_V2_USER_SECCOMP:
+ 		if (static_key_enabled(&switch_to_cond_stibp))
+ 			return ", STIBP: conditional";
+ 	}
+ 	return "";
+ }
+ 
+ static char *ibpb_state(void)
+ {
+ 	if (boot_cpu_has(X86_FEATURE_IBPB)) {
+ 		if (static_key_enabled(&switch_mm_always_ibpb))
+ 			return ", IBPB: always-on";
+ 		if (static_key_enabled(&switch_mm_cond_ibpb))
+ 			return ", IBPB: conditional";
+ 		return ", IBPB: disabled";
+ 	}
+ 	return "";
+ }
+ 
++>>>>>>> 6b3e64c237c0 (x86/speculation: Add seccomp Spectre v2 user space protection mode)
  static ssize_t cpu_show_common(struct device *dev, struct device_attribute *attr,
  			       char *buf, unsigned int bug)
  {
* Unmerged path Documentation/admin-guide/kernel-parameters.txt
* Unmerged path arch/x86/include/asm/nospec-branch.h
* Unmerged path arch/x86/kernel/cpu/bugs.c
