dma-mapping: implement dma_map_single_attrs using dma_map_page_attrs

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-80.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 2e05ea5cdc1ac55d9ef678ed5ea6c38acf7fd2a3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-80.el8/2e05ea5c.failed

And also switch the way we implement the unmap side around to stay
consistent.  This ensures dma-debug works again because it records which
function we used for mapping to ensure it is also used for unmapping,
and also reduces further code duplication.  Last but not least this
also officially allows calling dma_sync_single_* for mappings created
using dma_map_page, which is perfectly fine given that the sync calls
only take a dma_addr_t, but not a virtual address or struct page.

Fixes: 7f0fee242e ("dma-mapping: merge dma_unmap_page_attrs and dma_unmap_single_attrs")
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Tested-by: LABBE Corentin <clabbe.montjoie@gmail.com>
(cherry picked from commit 2e05ea5cdc1ac55d9ef678ed5ea6c38acf7fd2a3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/dma-mapping.h
diff --cc include/linux/dma-mapping.h
index c9c61a1eccca,0452a8be2789..000000000000
--- a/include/linux/dma-mapping.h
+++ b/include/linux/dma-mapping.h
@@@ -222,22 -221,83 +222,100 @@@ static inline const struct dma_map_ops 
  }
  #endif
  
++<<<<<<< HEAD
 +static inline dma_addr_t dma_map_single_attrs(struct device *dev, void *ptr,
 +					      size_t size,
 +					      enum dma_data_direction dir,
 +					      unsigned long attrs)
++=======
+ static inline bool dma_is_direct(const struct dma_map_ops *ops)
+ {
+ 	return likely(!ops);
+ }
+ 
+ /*
+  * All the dma_direct_* declarations are here just for the indirect call bypass,
+  * and must not be used directly drivers!
+  */
+ dma_addr_t dma_direct_map_page(struct device *dev, struct page *page,
+ 		unsigned long offset, size_t size, enum dma_data_direction dir,
+ 		unsigned long attrs);
+ int dma_direct_map_sg(struct device *dev, struct scatterlist *sgl, int nents,
+ 		enum dma_data_direction dir, unsigned long attrs);
+ 
+ #if defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_DEVICE) || \
+     defined(CONFIG_SWIOTLB)
+ void dma_direct_sync_single_for_device(struct device *dev,
+ 		dma_addr_t addr, size_t size, enum dma_data_direction dir);
+ void dma_direct_sync_sg_for_device(struct device *dev,
+ 		struct scatterlist *sgl, int nents, enum dma_data_direction dir);
+ #else
+ static inline void dma_direct_sync_single_for_device(struct device *dev,
+ 		dma_addr_t addr, size_t size, enum dma_data_direction dir)
+ {
+ }
+ static inline void dma_direct_sync_sg_for_device(struct device *dev,
+ 		struct scatterlist *sgl, int nents, enum dma_data_direction dir)
+ {
+ }
+ #endif
+ 
+ #if defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU) || \
+     defined(CONFIG_ARCH_HAS_SYNC_DMA_FOR_CPU_ALL) || \
+     defined(CONFIG_SWIOTLB)
+ void dma_direct_unmap_page(struct device *dev, dma_addr_t addr,
+ 		size_t size, enum dma_data_direction dir, unsigned long attrs);
+ void dma_direct_unmap_sg(struct device *dev, struct scatterlist *sgl,
+ 		int nents, enum dma_data_direction dir, unsigned long attrs);
+ void dma_direct_sync_single_for_cpu(struct device *dev,
+ 		dma_addr_t addr, size_t size, enum dma_data_direction dir);
+ void dma_direct_sync_sg_for_cpu(struct device *dev,
+ 		struct scatterlist *sgl, int nents, enum dma_data_direction dir);
+ #else
+ static inline void dma_direct_unmap_page(struct device *dev, dma_addr_t addr,
+ 		size_t size, enum dma_data_direction dir, unsigned long attrs)
+ {
+ }
+ static inline void dma_direct_unmap_sg(struct device *dev,
+ 		struct scatterlist *sgl, int nents, enum dma_data_direction dir,
+ 		unsigned long attrs)
+ {
+ }
+ static inline void dma_direct_sync_single_for_cpu(struct device *dev,
+ 		dma_addr_t addr, size_t size, enum dma_data_direction dir)
+ {
+ }
+ static inline void dma_direct_sync_sg_for_cpu(struct device *dev,
+ 		struct scatterlist *sgl, int nents, enum dma_data_direction dir)
+ {
+ }
+ #endif
+ 
+ static inline dma_addr_t dma_map_page_attrs(struct device *dev,
+ 		struct page *page, size_t offset, size_t size,
+ 		enum dma_data_direction dir, unsigned long attrs)
++>>>>>>> 2e05ea5cdc1a (dma-mapping: implement dma_map_single_attrs using dma_map_page_attrs)
  {
  	const struct dma_map_ops *ops = get_dma_ops(dev);
  	dma_addr_t addr;
  
  	BUG_ON(!valid_dma_direction(dir));
++<<<<<<< HEAD
 +	debug_dma_map_single(dev, ptr, size);
 +	addr = ops->map_page(dev, virt_to_page(ptr),
 +			     offset_in_page(ptr), size,
 +			     dir, attrs);
 +	debug_dma_map_page(dev, virt_to_page(ptr),
 +			   offset_in_page(ptr), size,
 +			   dir, addr, true);
++=======
+ 	if (dma_is_direct(ops))
+ 		addr = dma_direct_map_page(dev, page, offset, size, dir, attrs);
+ 	else
+ 		addr = ops->map_page(dev, page, offset, size, dir, attrs);
+ 	debug_dma_map_page(dev, page, offset, size, dir, addr);
+ 
++>>>>>>> 2e05ea5cdc1a (dma-mapping: implement dma_map_single_attrs using dma_map_page_attrs)
  	return addr;
  }
  
@@@ -249,15 -307,11 +325,9 @@@ static inline void dma_unmap_page_attrs
  	const struct dma_map_ops *ops = get_dma_ops(dev);
  
  	BUG_ON(!valid_dma_direction(dir));
 -	if (dma_is_direct(ops))
 -		dma_direct_unmap_page(dev, addr, size, dir, attrs);
 -	else if (ops->unmap_page)
 +	if (ops->unmap_page)
  		ops->unmap_page(dev, addr, size, dir, attrs);
- 	debug_dma_unmap_page(dev, addr, size, dir, true);
- }
- 
- static inline void dma_unmap_page_attrs(struct device *dev, dma_addr_t addr,
- 		size_t size, enum dma_data_direction dir, unsigned long attrs)
- {
- 	return dma_unmap_single_attrs(dev, addr, size, dir, attrs);
+ 	debug_dma_unmap_page(dev, addr, size, dir);
  }
  
  /*
@@@ -291,22 -350,6 +361,25 @@@ static inline void dma_unmap_sg_attrs(s
  		ops->unmap_sg(dev, sg, nents, dir, attrs);
  }
  
++<<<<<<< HEAD
 +static inline dma_addr_t dma_map_page_attrs(struct device *dev,
 +					    struct page *page,
 +					    size_t offset, size_t size,
 +					    enum dma_data_direction dir,
 +					    unsigned long attrs)
 +{
 +	const struct dma_map_ops *ops = get_dma_ops(dev);
 +	dma_addr_t addr;
 +
 +	BUG_ON(!valid_dma_direction(dir));
 +	addr = ops->map_page(dev, page, offset, size, dir, attrs);
 +	debug_dma_map_page(dev, page, offset, size, dir, addr, false);
 +
 +	return addr;
 +}
 +
++=======
++>>>>>>> 2e05ea5cdc1a (dma-mapping: implement dma_map_single_attrs using dma_map_page_attrs)
  static inline dma_addr_t dma_map_resource(struct device *dev,
  					  phys_addr_t phys_addr,
  					  size_t size,
diff --git a/include/linux/dma-debug.h b/include/linux/dma-debug.h
index c85e097a984c..a34d62fecdc7 100644
--- a/include/linux/dma-debug.h
+++ b/include/linux/dma-debug.h
@@ -37,13 +37,12 @@ extern void debug_dma_map_single(struct device *dev, const void *addr,
 
 extern void debug_dma_map_page(struct device *dev, struct page *page,
 			       size_t offset, size_t size,
-			       int direction, dma_addr_t dma_addr,
-			       bool map_single);
+			       int direction, dma_addr_t dma_addr);
 
 extern void debug_dma_mapping_error(struct device *dev, dma_addr_t dma_addr);
 
 extern void debug_dma_unmap_page(struct device *dev, dma_addr_t addr,
-				 size_t size, int direction, bool map_single);
+				 size_t size, int direction);
 
 extern void debug_dma_map_sg(struct device *dev, struct scatterlist *sg,
 			     int nents, int mapped_ents, int direction);
@@ -102,8 +101,7 @@ static inline void debug_dma_map_single(struct device *dev, const void *addr,
 
 static inline void debug_dma_map_page(struct device *dev, struct page *page,
 				      size_t offset, size_t size,
-				      int direction, dma_addr_t dma_addr,
-				      bool map_single)
+				      int direction, dma_addr_t dma_addr)
 {
 }
 
@@ -113,8 +111,7 @@ static inline void debug_dma_mapping_error(struct device *dev,
 }
 
 static inline void debug_dma_unmap_page(struct device *dev, dma_addr_t addr,
-					size_t size, int direction,
-					bool map_single)
+					size_t size, int direction)
 {
 }
 
* Unmerged path include/linux/dma-mapping.h
diff --git a/kernel/dma/debug.c b/kernel/dma/debug.c
index 3214833b47e2..d2f8bee2eb3a 100644
--- a/kernel/dma/debug.c
+++ b/kernel/dma/debug.c
@@ -48,7 +48,6 @@
 
 enum {
 	dma_debug_single,
-	dma_debug_page,
 	dma_debug_sg,
 	dma_debug_coherent,
 	dma_debug_resource,
@@ -1329,8 +1328,7 @@ void debug_dma_map_single(struct device *dev, const void *addr,
 EXPORT_SYMBOL(debug_dma_map_single);
 
 void debug_dma_map_page(struct device *dev, struct page *page, size_t offset,
-			size_t size, int direction, dma_addr_t dma_addr,
-			bool map_single)
+			size_t size, int direction, dma_addr_t dma_addr)
 {
 	struct dma_debug_entry *entry;
 
@@ -1345,7 +1343,7 @@ void debug_dma_map_page(struct device *dev, struct page *page, size_t offset,
 		return;
 
 	entry->dev       = dev;
-	entry->type      = dma_debug_page;
+	entry->type      = dma_debug_single;
 	entry->pfn	 = page_to_pfn(page);
 	entry->offset	 = offset,
 	entry->dev_addr  = dma_addr;
@@ -1353,9 +1351,6 @@ void debug_dma_map_page(struct device *dev, struct page *page, size_t offset,
 	entry->direction = direction;
 	entry->map_err_type = MAP_ERR_NOT_CHECKED;
 
-	if (map_single)
-		entry->type = dma_debug_single;
-
 	check_for_stack(dev, page, offset);
 
 	if (!PageHighMem(page)) {
@@ -1407,10 +1402,10 @@ void debug_dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
 EXPORT_SYMBOL(debug_dma_mapping_error);
 
 void debug_dma_unmap_page(struct device *dev, dma_addr_t addr,
-			  size_t size, int direction, bool map_single)
+			  size_t size, int direction)
 {
 	struct dma_debug_entry ref = {
-		.type           = dma_debug_page,
+		.type           = dma_debug_single,
 		.dev            = dev,
 		.dev_addr       = addr,
 		.size           = size,
@@ -1419,10 +1414,6 @@ void debug_dma_unmap_page(struct device *dev, dma_addr_t addr,
 
 	if (unlikely(dma_debug_disabled()))
 		return;
-
-	if (map_single)
-		ref.type = dma_debug_single;
-
 	check_unmap(&ref);
 }
 EXPORT_SYMBOL(debug_dma_unmap_page);
