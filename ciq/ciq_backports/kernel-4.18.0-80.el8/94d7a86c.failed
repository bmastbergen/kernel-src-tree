x86/kvm/vmx: Remove duplicate l1d flush definitions

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-80.el8
commit-author Josh Poimboeuf <jpoimboe@redhat.com>
commit 94d7a86c21a3d6046bf4616272313cb7d525075a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-80.el8/94d7a86c.failed

These are already defined higher up in the file.

Fixes: 7db92e165ac8 ("x86/kvm: Move l1tf setup function")
	Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: Paolo Bonzini <pbonzini@redhat.com>
	Cc: stable@vger.kernel.org
Link: https://lkml.kernel.org/r/d7ca03ae210d07173452aeed85ffe344301219a5.1534253536.git.jpoimboe@redhat.com

(cherry picked from commit 94d7a86c21a3d6046bf4616272313cb7d525075a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/vmx.c
diff --cc arch/x86/kvm/vmx.c
index dba5876b675e,4be481c72f60..000000000000
--- a/arch/x86/kvm/vmx.c
+++ b/arch/x86/kvm/vmx.c
@@@ -9964,6 -9716,76 +9964,79 @@@ static int vmx_handle_exit(struct kvm_v
  	}
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * Software based L1D cache flush which is used when microcode providing
+  * the cache control MSR is not loaded.
+  *
+  * The L1D cache is 32 KiB on Nehalem and later microarchitectures, but to
+  * flush it is required to read in 64 KiB because the replacement algorithm
+  * is not exactly LRU. This could be sized at runtime via topology
+  * information but as all relevant affected CPUs have 32KiB L1D cache size
+  * there is no point in doing so.
+  */
+ static void vmx_l1d_flush(struct kvm_vcpu *vcpu)
+ {
+ 	int size = PAGE_SIZE << L1D_CACHE_ORDER;
+ 
+ 	/*
+ 	 * This code is only executed when the the flush mode is 'cond' or
+ 	 * 'always'
+ 	 */
+ 	if (static_branch_likely(&vmx_l1d_flush_cond)) {
+ 		bool flush_l1d;
+ 
+ 		/*
+ 		 * Clear the per-vcpu flush bit, it gets set again
+ 		 * either from vcpu_run() or from one of the unsafe
+ 		 * VMEXIT handlers.
+ 		 */
+ 		flush_l1d = vcpu->arch.l1tf_flush_l1d;
+ 		vcpu->arch.l1tf_flush_l1d = false;
+ 
+ 		/*
+ 		 * Clear the per-cpu flush bit, it gets set again from
+ 		 * the interrupt handlers.
+ 		 */
+ 		flush_l1d |= kvm_get_cpu_l1tf_flush_l1d();
+ 		kvm_clear_cpu_l1tf_flush_l1d();
+ 
+ 		if (!flush_l1d)
+ 			return;
+ 	}
+ 
+ 	vcpu->stat.l1d_flush++;
+ 
+ 	if (static_cpu_has(X86_FEATURE_FLUSH_L1D)) {
+ 		wrmsrl(MSR_IA32_FLUSH_CMD, L1D_FLUSH);
+ 		return;
+ 	}
+ 
+ 	asm volatile(
+ 		/* First ensure the pages are in the TLB */
+ 		"xorl	%%eax, %%eax\n"
+ 		".Lpopulate_tlb:\n\t"
+ 		"movzbl	(%[flush_pages], %%" _ASM_AX "), %%ecx\n\t"
+ 		"addl	$4096, %%eax\n\t"
+ 		"cmpl	%%eax, %[size]\n\t"
+ 		"jne	.Lpopulate_tlb\n\t"
+ 		"xorl	%%eax, %%eax\n\t"
+ 		"cpuid\n\t"
+ 		/* Now fill the cache */
+ 		"xorl	%%eax, %%eax\n"
+ 		".Lfill_cache:\n"
+ 		"movzbl	(%[flush_pages], %%" _ASM_AX "), %%ecx\n\t"
+ 		"addl	$64, %%eax\n\t"
+ 		"cmpl	%%eax, %[size]\n\t"
+ 		"jne	.Lfill_cache\n\t"
+ 		"lfence\n"
+ 		:: [flush_pages] "r" (vmx_l1d_flush_pages),
+ 		    [size] "r" (size)
+ 		: "eax", "ebx", "ecx", "edx");
+ }
+ 
++>>>>>>> 94d7a86c21a3 (x86/kvm/vmx: Remove duplicate l1d flush definitions)
  static void update_cr8_intercept(struct kvm_vcpu *vcpu, int tpr, int irr)
  {
  	struct vmcs12 *vmcs12 = get_vmcs12(vcpu);
* Unmerged path arch/x86/kvm/vmx.c
