act_ife: move tcfa_lock down to where necessary

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-80.el8
commit-author Cong Wang <xiyou.wangcong@gmail.com>
commit 4e407ff5cd67ec76eeeea1deec227b7982dc7f66
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-80.el8/4e407ff5.failed

The only time we need to take tcfa_lock is when adding
a new metainfo to an existing ife->metalist. We don't need
to take tcfa_lock so early and so broadly in tcf_ife_init().

This means we can always take ife_mod_lock first, avoid the
reverse locking ordering warning as reported by Vlad.

	Reported-by: Vlad Buslov <vladbu@mellanox.com>
	Tested-by: Vlad Buslov <vladbu@mellanox.com>
	Cc: Vlad Buslov <vladbu@mellanox.com>
	Cc: Jamal Hadi Salim <jhs@mojatatu.com>
	Signed-off-by: Cong Wang <xiyou.wangcong@gmail.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 4e407ff5cd67ec76eeeea1deec227b7982dc7f66)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sched/act_ife.c
diff --cc net/sched/act_ife.c
index dc8f301f3be3,244a8cf48183..000000000000
--- a/net/sched/act_ife.c
+++ b/net/sched/act_ife.c
@@@ -265,10 -265,8 +265,13 @@@ static const char *ife_meta_id2name(u3
  #endif
  
  /* called when adding new meta information
-  * under ife->tcf_lock for existing action
  */
++<<<<<<< HEAD
 +static int load_metaops_and_vet(struct tcf_ife_info *ife, u32 metaid,
 +				void *val, int len, bool exists)
++=======
+ static int load_metaops_and_vet(u32 metaid, void *val, int len, bool rtnl_held)
++>>>>>>> 4e407ff5cd67 (act_ife: move tcfa_lock down to where necessary)
  {
  	struct tcf_meta_ops *ops = find_ife_oplist(metaid);
  	int ret = 0;
@@@ -276,13 -274,11 +279,21 @@@
  	if (!ops) {
  		ret = -ENOENT;
  #ifdef CONFIG_MODULES
++<<<<<<< HEAD
 +		if (exists)
 +			spin_unlock_bh(&ife->tcf_lock);
 +		rtnl_unlock();
 +		request_module("ife-meta-%s", ife_meta_id2name(metaid));
 +		rtnl_lock();
 +		if (exists)
 +			spin_lock_bh(&ife->tcf_lock);
++=======
+ 		if (rtnl_held)
+ 			rtnl_unlock();
+ 		request_module("ife-meta-%s", ife_meta_id2name(metaid));
+ 		if (rtnl_held)
+ 			rtnl_lock();
++>>>>>>> 4e407ff5cd67 (act_ife: move tcfa_lock down to where necessary)
  		ops = find_ife_oplist(metaid);
  #endif
  	}
@@@ -419,9 -418,8 +433,8 @@@ static void tcf_ife_cleanup(struct tc_a
  		kfree_rcu(p, rcu);
  }
  
- /* under ife->tcf_lock for existing action */
  static int populate_metalist(struct tcf_ife_info *ife, struct nlattr **tb,
 -			     bool exists, bool rtnl_held)
 +			     bool exists)
  {
  	int len = 0;
  	int rc = 0;
@@@ -433,7 -431,7 +446,11 @@@
  			val = nla_data(tb[i]);
  			len = nla_len(tb[i]);
  
++<<<<<<< HEAD
 +			rc = load_metaops_and_vet(ife, i, val, len, exists);
++=======
+ 			rc = load_metaops_and_vet(i, val, len, rtnl_held);
++>>>>>>> 4e407ff5cd67 (act_ife: move tcfa_lock down to where necessary)
  			if (rc != 0)
  				return rc;
  
@@@ -543,8 -543,7 +558,12 @@@ static int tcf_ife_init(struct net *net
  				       NULL, NULL);
  		if (err) {
  metadata_parse_err:
++<<<<<<< HEAD
 +			if (exists)
 +				spin_unlock_bh(&ife->tcf_lock);
++=======
+ 			tcf_idr_release(*a, bind);
++>>>>>>> 4e407ff5cd67 (act_ife: move tcfa_lock down to where necessary)
  			kfree(p);
  			return err;
  		}
@@@ -570,14 -566,16 +586,16 @@@
  		}
  	}
  
+ 	if (exists)
+ 		spin_lock_bh(&ife->tcf_lock);
  	ife->tcf_action = parm->action;
 -	/* protected by tcf_lock when modifying existing action */
 -	rcu_swap_protected(ife->params, p, 1);
 -
  	if (exists)
  		spin_unlock_bh(&ife->tcf_lock);
 -	if (p)
 -		kfree_rcu(p, rcu);
 +
 +	p_old = rtnl_dereference(ife->params);
 +	rcu_assign_pointer(ife->params, p);
 +	if (p_old)
 +		kfree_rcu(p_old, rcu);
  
  	if (ret == ACT_P_CREATED)
  		tcf_idr_insert(tn, *a);
* Unmerged path net/sched/act_ife.c
