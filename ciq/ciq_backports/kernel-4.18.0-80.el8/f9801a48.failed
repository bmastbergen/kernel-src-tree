nvme-rdma: remove I/O polling support

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-80.el8
commit-author Christoph Hellwig <hch@lst.de>
commit f9801a484ad6dcc33b10c61b143efc3352541802
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-80.el8/f9801a48.failed

The code was always a bit of a hack that digs far too much into
RDMA core internals.  Lets kick it out and reimplement proper
dedicated poll queues as needed.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit f9801a484ad6dcc33b10c61b143efc3352541802)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/rdma.c
diff --cc drivers/nvme/host/rdma.c
index 8ecaac370289,75c01d20a133..000000000000
--- a/drivers/nvme/host/rdma.c
+++ b/drivers/nvme/host/rdma.c
@@@ -1696,27 -1738,6 +1696,30 @@@ err
  	return BLK_STS_IOERR;
  }
  
++<<<<<<< HEAD
 +static int nvme_rdma_poll(struct blk_mq_hw_ctx *hctx, unsigned int tag)
 +{
 +	struct nvme_rdma_queue *queue = hctx->driver_data;
 +	struct ib_cq *cq = queue->ib_cq;
 +	struct ib_wc wc;
 +	int found = 0;
 +
 +	while (ib_poll_cq(cq, 1, &wc) > 0) {
 +		struct ib_cqe *cqe = wc.wr_cqe;
 +
 +		if (cqe) {
 +			if (cqe->done == nvme_rdma_recv_done)
 +				found |= __nvme_rdma_recv_done(cq, &wc, tag);
 +			else
 +				cqe->done(cq, &wc);
 +		}
 +	}
 +
 +	return found;
 +}
 +
++=======
++>>>>>>> f9801a484ad6 (nvme-rdma: remove I/O polling support)
  static void nvme_rdma_complete_rq(struct request *rq)
  {
  	struct nvme_rdma_request *req = blk_mq_rq_to_pdu(rq);
* Unmerged path drivers/nvme/host/rdma.c
