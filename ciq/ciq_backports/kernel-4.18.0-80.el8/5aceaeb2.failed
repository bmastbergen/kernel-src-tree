blk-mq: only dispatch to non-defauly queue maps if they have queues

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-80.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 5aceaeb26394538858a9dbae5830d628469a44cf
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-80.el8/5aceaeb2.failed

We should check if a given queue map actually has queues enabled before
dispatching to it.  This allows drivers to not initialize optional but
not used map types, which subsequently will allow fixing problems with
queue map rebuilds for that case.

	Reviewed-by: Ming Lei <ming.lei@redhat.com>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 5aceaeb26394538858a9dbae5830d628469a44cf)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq.h
diff --cc block/blk-mq.h
index 7a8828f8b01e,d1ed096723fb..000000000000
--- a/block/blk-mq.h
+++ b/block/blk-mq.h
@@@ -78,19 -80,43 +78,34 @@@ void blk_mq_try_issue_list_directly(str
   */
  extern int blk_mq_hw_queue_to_node(struct blk_mq_queue_map *qmap, unsigned int);
  
 -/*
 - * blk_mq_map_queue_type() - map (hctx_type,cpu) to hardware queue
 - * @q: request queue
 - * @type: the hctx type index
 - * @cpu: CPU
 - */
 -static inline struct blk_mq_hw_ctx *blk_mq_map_queue_type(struct request_queue *q,
 -							  enum hctx_type type,
 -							  unsigned int cpu)
 -{
 -	return q->queue_hw_ctx[q->tag_set->map[type].mq_map[cpu]];
 -}
 -
 -/*
 - * blk_mq_map_queue() - map (cmd_flags,type) to hardware queue
 - * @q: request queue
 - * @flags: request command flags
 - * @cpu: CPU
 - */
  static inline struct blk_mq_hw_ctx *blk_mq_map_queue(struct request_queue *q,
 -						     unsigned int flags,
  						     unsigned int cpu)
  {
 -	enum hctx_type type = HCTX_TYPE_DEFAULT;
 +	struct blk_mq_tag_set *set = q->tag_set;
  
++<<<<<<< HEAD
 +	return q->queue_hw_ctx[set->map[0].mq_map[cpu]];
 +}
 +
 +static inline struct blk_mq_hw_ctx *blk_mq_map_queue_type(struct request_queue *q,
 +							  unsigned int hctx_type,
 +							  unsigned int cpu)
 +{
 +	return blk_mq_map_queue(q, cpu);
++=======
+ 	if ((flags & REQ_HIPRI) &&
+ 	    q->tag_set->nr_maps > HCTX_TYPE_POLL && 
+ 	    q->tag_set->map[HCTX_TYPE_POLL].nr_queues &&
+ 	    test_bit(QUEUE_FLAG_POLL, &q->queue_flags))
+ 		type = HCTX_TYPE_POLL;
+ 
+ 	else if (((flags & REQ_OP_MASK) == REQ_OP_READ) &&
+ 	         q->tag_set->nr_maps > HCTX_TYPE_READ &&
+ 		 q->tag_set->map[HCTX_TYPE_READ].nr_queues)
+ 		type = HCTX_TYPE_READ;
+ 	
+ 	return blk_mq_map_queue_type(q, type, cpu);
++>>>>>>> 5aceaeb26394 (blk-mq: only dispatch to non-defauly queue maps if they have queues)
  }
  
  /*
* Unmerged path block/blk-mq.h
