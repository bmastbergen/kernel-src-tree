dma-mapping: move dma_get_required_mask to kernel/dma

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-80.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 05887cb610a54bf568de7f0bc07c4a64e45ac6f9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-80.el8/05887cb6.failed

dma_get_required_mask should really be with the rest of the DMA mapping
implementation instead of in drivers/base as a lone outlier.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Acked-by: Jesper Dangaard Brouer <brouer@redhat.com>
	Tested-by: Jesper Dangaard Brouer <brouer@redhat.com>
	Tested-by: Tony Luck <tony.luck@intel.com>
(cherry picked from commit 05887cb610a54bf568de7f0bc07c4a64e45ac6f9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/dma/mapping.c
diff --cc kernel/dma/mapping.c
index e100ec904c99,dfe29d18dba1..000000000000
--- a/kernel/dma/mapping.c
+++ b/kernel/dma/mapping.c
@@@ -5,9 -5,9 +5,9 @@@
   * Copyright (c) 2006  SUSE Linux Products GmbH
   * Copyright (c) 2006  Tejun Heo <teheo@suse.de>
   */
- 
+ #include <linux/memblock.h> /* for max_pfn */
  #include <linux/acpi.h>
 -#include <linux/dma-noncoherent.h>
 +#include <linux/dma-mapping.h>
  #include <linux/export.h>
  #include <linux/gfp.h>
  #include <linux/of_device.h>
@@@ -242,97 -244,53 +242,131 @@@ int dma_common_mmap(struct device *dev
  	if (dma_mmap_from_dev_coherent(dev, vma, cpu_addr, size, &ret))
  		return ret;
  
 -	if (off >= count || user_count > count - off)
 -		return -ENXIO;
 +	if (off < count && user_count <= (count - off))
 +		ret = remap_pfn_range(vma, vma->vm_start,
 +				      page_to_pfn(virt_to_page(cpu_addr)) + off,
 +				      user_count << PAGE_SHIFT,
 +				      vma->vm_page_prot);
 +#endif	/* !CONFIG_ARCH_NO_COHERENT_DMA_MMAP */
  
 -	if (!dev_is_dma_coherent(dev)) {
 -		if (!IS_ENABLED(CONFIG_ARCH_HAS_DMA_COHERENT_TO_PFN))
 -			return -ENXIO;
 -		pfn = arch_dma_coherent_to_pfn(dev, cpu_addr, dma_addr);
 -	} else {
 -		pfn = page_to_pfn(virt_to_page(cpu_addr));
 +	return ret;
 +}
 +EXPORT_SYMBOL(dma_common_mmap);
 +
++<<<<<<< HEAD
 +#ifdef CONFIG_MMU
 +static struct vm_struct *__dma_common_pages_remap(struct page **pages,
 +			size_t size, unsigned long vm_flags, pgprot_t prot,
 +			const void *caller)
 +{
 +	struct vm_struct *area;
 +
 +	area = get_vm_area_caller(size, vm_flags, caller);
 +	if (!area)
 +		return NULL;
 +
 +	if (map_vm_area(area, prot, pages)) {
 +		vunmap(area->addr);
 +		return NULL;
  	}
  
 -	return remap_pfn_range(vma, vma->vm_start, pfn + vma->vm_pgoff,
 -			user_count << PAGE_SHIFT, vma->vm_page_prot);
 -#else
 -	return -ENXIO;
 -#endif /* !CONFIG_ARCH_NO_COHERENT_DMA_MMAP */
 +	return area;
  }
 -EXPORT_SYMBOL(dma_common_mmap);
  
 +/*
 + * remaps an array of PAGE_SIZE pages into another vm_area
 + * Cannot be used in non-sleeping contexts
 + */
 +void *dma_common_pages_remap(struct page **pages, size_t size,
 +			unsigned long vm_flags, pgprot_t prot,
 +			const void *caller)
 +{
 +	struct vm_struct *area;
 +
 +	area = __dma_common_pages_remap(pages, size, vm_flags, prot, caller);
 +	if (!area)
 +		return NULL;
 +
 +	area->pages = pages;
 +
 +	return area->addr;
 +}
 +
 +/*
 + * remaps an allocated contiguous region into another vm_area.
 + * Cannot be used in non-sleeping contexts
 + */
 +
 +void *dma_common_contiguous_remap(struct page *page, size_t size,
 +			unsigned long vm_flags,
 +			pgprot_t prot, const void *caller)
 +{
 +	int i;
 +	struct page **pages;
 +	struct vm_struct *area;
 +
 +	pages = kmalloc(sizeof(struct page *) << get_order(size), GFP_KERNEL);
 +	if (!pages)
 +		return NULL;
 +
 +	for (i = 0; i < (size >> PAGE_SHIFT); i++)
 +		pages[i] = nth_page(page, i);
 +
 +	area = __dma_common_pages_remap(pages, size, vm_flags, prot, caller);
 +
 +	kfree(pages);
 +
 +	if (!area)
 +		return NULL;
 +	return area->addr;
 +}
 +
 +/*
 + * unmaps a range previously mapped by dma_common_*_remap
 + */
 +void dma_common_free_remap(void *cpu_addr, size_t size, unsigned long vm_flags)
 +{
 +	struct vm_struct *area = find_vm_area(cpu_addr);
 +
 +	if (!area || (area->flags & vm_flags) != vm_flags) {
 +		WARN(1, "trying to free invalid coherent area: %p\n", cpu_addr);
 +		return;
 +	}
 +
 +	unmap_kernel_range((unsigned long)cpu_addr, PAGE_ALIGN(size));
 +	vunmap(cpu_addr);
 +}
 +#endif
++=======
+ #ifndef ARCH_HAS_DMA_GET_REQUIRED_MASK
+ static u64 dma_default_get_required_mask(struct device *dev)
+ {
+ 	u32 low_totalram = ((max_pfn - 1) << PAGE_SHIFT);
+ 	u32 high_totalram = ((max_pfn - 1) >> (32 - PAGE_SHIFT));
+ 	u64 mask;
+ 
+ 	if (!high_totalram) {
+ 		/* convert to mask just covering totalram */
+ 		low_totalram = (1 << (fls(low_totalram) - 1));
+ 		low_totalram += low_totalram - 1;
+ 		mask = low_totalram;
+ 	} else {
+ 		high_totalram = (1 << (fls(high_totalram) - 1));
+ 		high_totalram += high_totalram - 1;
+ 		mask = (((u64)high_totalram) << 32) + 0xffffffff;
+ 	}
+ 	return mask;
+ }
+ 
+ u64 dma_get_required_mask(struct device *dev)
+ {
+ 	const struct dma_map_ops *ops = get_dma_ops(dev);
+ 
+ 	if (ops->get_required_mask)
+ 		return ops->get_required_mask(dev);
+ 	return dma_default_get_required_mask(dev);
+ }
+ EXPORT_SYMBOL_GPL(dma_get_required_mask);
+ #endif
+ 
++>>>>>>> 05887cb610a5 (dma-mapping: move dma_get_required_mask to kernel/dma)
diff --git a/drivers/base/platform.c b/drivers/base/platform.c
index 23cf4427f425..2af1f66b1970 100644
--- a/drivers/base/platform.c
+++ b/drivers/base/platform.c
@@ -1179,37 +1179,6 @@ int __init platform_bus_init(void)
 	return error;
 }
 
-#ifndef ARCH_HAS_DMA_GET_REQUIRED_MASK
-static u64 dma_default_get_required_mask(struct device *dev)
-{
-	u32 low_totalram = ((max_pfn - 1) << PAGE_SHIFT);
-	u32 high_totalram = ((max_pfn - 1) >> (32 - PAGE_SHIFT));
-	u64 mask;
-
-	if (!high_totalram) {
-		/* convert to mask just covering totalram */
-		low_totalram = (1 << (fls(low_totalram) - 1));
-		low_totalram += low_totalram - 1;
-		mask = low_totalram;
-	} else {
-		high_totalram = (1 << (fls(high_totalram) - 1));
-		high_totalram += high_totalram - 1;
-		mask = (((u64)high_totalram) << 32) + 0xffffffff;
-	}
-	return mask;
-}
-
-u64 dma_get_required_mask(struct device *dev)
-{
-	const struct dma_map_ops *ops = get_dma_ops(dev);
-
-	if (ops->get_required_mask)
-		return ops->get_required_mask(dev);
-	return dma_default_get_required_mask(dev);
-}
-EXPORT_SYMBOL_GPL(dma_get_required_mask);
-#endif
-
 static __initdata LIST_HEAD(early_platform_driver_list);
 static __initdata LIST_HEAD(early_platform_device_list);
 
* Unmerged path kernel/dma/mapping.c
