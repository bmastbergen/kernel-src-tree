dma-direct: fix return value of dma_direct_supported

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-80.el8
commit-author Alexander Duyck <alexander.h.duyck@linux.intel.com>
commit 1fc8e6423edb4bba365b0780c2fcddfb921b24b2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-80.el8/1fc8e642.failed

It appears that in commit 9d7a224b463e ("dma-direct: always allow dma mask
<= physiscal memory size") the logic of the test was changed from a "<" to
a ">=" however I don't see any reason for that change. I am assuming that
there was some additional change planned, specifically I suspect the logic
was intended to be reversed and possibly used for a return. Since that is
the case I have gone ahead and done that.

This addresses issues I had on my system that prevented me from booting
with the above mentioned commit applied on an x86_64 system w/ Intel IOMMU.

Fixes: 9d7a224b463e ("dma-direct: always allow dma mask <= physiscal memory size")
	Signed-off-by: Alexander Duyck <alexander.h.duyck@linux.intel.com>
	Acked-by: Robin Murphy <robin.murphy@arm.com>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
(cherry picked from commit 1fc8e6423edb4bba365b0780c2fcddfb921b24b2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/dma/direct.c
diff --cc kernel/dma/direct.c
index 2ba3b52698ea,674a8da22844..000000000000
--- a/kernel/dma/direct.c
+++ b/kernel/dma/direct.c
@@@ -163,28 -282,26 +163,41 @@@ int dma_direct_map_sg(struct device *de
  	return nents;
  }
  
 -/*
 - * Because 32-bit DMA masks are so common we expect every architecture to be
 - * able to satisfy them - either by not supporting more physical memory, or by
 - * providing a ZONE_DMA32.  If neither is the case, the architecture needs to
 - * use an IOMMU instead of the direct mapping.
 - */
  int dma_direct_supported(struct device *dev, u64 mask)
  {
++<<<<<<< HEAD
 +#ifdef CONFIG_ZONE_DMA
 +	if (mask < phys_to_dma(dev, DMA_BIT_MASK(ARCH_ZONE_DMA_BITS)))
 +		return 0;
 +#else
 +	/*
 +	 * Because 32-bit DMA masks are so common we expect every architecture
 +	 * to be able to satisfy them - either by not supporting more physical
 +	 * memory, or by providing a ZONE_DMA32.  If neither is the case, the
 +	 * architecture needs to use an IOMMU instead of the direct mapping.
 +	 */
 +	if (mask < phys_to_dma(dev, DMA_BIT_MASK(32)))
 +		return 0;
 +#endif
 +	/*
 +	 * Upstream PCI/PCIe bridges or SoC interconnects may not carry
 +	 * as many DMA address bits as the device itself supports.
 +	 */
 +	if (dev->bus_dma_mask && mask > dev->bus_dma_mask)
 +		return 0;
 +	return 1;
++=======
+ 	u64 min_mask;
+ 
+ 	if (IS_ENABLED(CONFIG_ZONE_DMA))
+ 		min_mask = DMA_BIT_MASK(ARCH_ZONE_DMA_BITS);
+ 	else
+ 		min_mask = DMA_BIT_MASK(32);
+ 
+ 	min_mask = min_t(u64, min_mask, (max_pfn - 1) << PAGE_SHIFT);
+ 
+ 	return mask >= phys_to_dma(dev, min_mask);
++>>>>>>> 1fc8e6423edb (dma-direct: fix return value of dma_direct_supported)
  }
  
  int dma_direct_mapping_error(struct device *dev, dma_addr_t dma_addr)
* Unmerged path kernel/dma/direct.c
