lockdep: Demagic the return value of BFS

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-315.el8
commit-author Boqun Feng <boqun.feng@gmail.com>
commit b11be024de164213f6338973d76ab9ab139120cd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-315.el8/b11be024.failed

__bfs() could return four magic numbers:

	1: search succeeds, but none match.
	0: search succeeds, find one match.
	-1: search fails because of the cq is full.
	-2: search fails because a invalid node is found.

This patch cleans things up by using a enum type for the return value
of __bfs() and its friends, this improves the code readability of the
code, and further, could help if we want to extend the BFS.

	Signed-off-by: Boqun Feng <boqun.feng@gmail.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: https://lkml.kernel.org/r/20200807074238.1632519-4-boqun.feng@gmail.com
(cherry picked from commit b11be024de164213f6338973d76ab9ab139120cd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/locking/lockdep.c
diff --cc kernel/locking/lockdep.c
index 4d916f0bb12e,462c68cfb378..000000000000
--- a/kernel/locking/lockdep.c
+++ b/kernel/locking/lockdep.c
@@@ -1826,8 -1835,8 +1858,13 @@@ static noinline enum bfs_resul
  check_noncircular(struct held_lock *src, struct held_lock *target,
  		  struct lock_trace **const trace)
  {
++<<<<<<< HEAD
 +	int ret;
 +	struct lock_list *uninitialized_var(target_entry);
++=======
+ 	enum bfs_result ret;
+ 	struct lock_list *target_entry;
++>>>>>>> b11be024de16 (lockdep: Demagic the return value of BFS)
  	struct lock_list src_entry = {
  		.class = hlock_class(src),
  		.parent = NULL,
@@@ -1859,13 -1868,14 +1896,19 @@@
   * <target> or not. If it can, <src> -> <target> dependency is already
   * in the graph.
   *
-  * Print an error and return 2 if it does or 1 if it does not.
+  * Return BFS_RMATCH if it does, or BFS_RMATCH if it does not, return BFS_E* if
+  * any error appears in the bfs search.
   */
- static noinline int
+ static noinline enum bfs_result
  check_redundant(struct held_lock *src, struct held_lock *target)
  {
++<<<<<<< HEAD
 +	int ret;
 +	struct lock_list *uninitialized_var(target_entry);
++=======
+ 	enum bfs_result ret;
+ 	struct lock_list *target_entry;
++>>>>>>> b11be024de16 (lockdep: Demagic the return value of BFS)
  	struct lock_list src_entry = {
  		.class = hlock_class(src),
  		.parent = NULL,
@@@ -2267,10 -2265,10 +2298,10 @@@ static int check_irq_usage(struct task_
  {
  	unsigned long usage_mask = 0, forward_mask, backward_mask;
  	enum lock_usage_bit forward_bit = 0, backward_bit = 0;
 -	struct lock_list *target_entry1;
 -	struct lock_list *target_entry;
 +	struct lock_list *uninitialized_var(target_entry1);
 +	struct lock_list *uninitialized_var(target_entry);
  	struct lock_list this, that;
- 	int ret;
+ 	enum bfs_result ret;
  
  	/*
  	 * Step 1: gather all hard/soft IRQs usages backward in an
@@@ -3459,9 -3459,9 +3492,9 @@@ static in
  check_usage_forwards(struct task_struct *curr, struct held_lock *this,
  		     enum lock_usage_bit bit, const char *irqclass)
  {
- 	int ret;
+ 	enum bfs_result ret;
  	struct lock_list root;
 -	struct lock_list *target_entry;
 +	struct lock_list *uninitialized_var(target_entry);
  
  	root.parent = NULL;
  	root.class = hlock_class(this);
@@@ -3486,9 -3486,9 +3519,9 @@@ static in
  check_usage_backwards(struct task_struct *curr, struct held_lock *this,
  		      enum lock_usage_bit bit, const char *irqclass)
  {
- 	int ret;
+ 	enum bfs_result ret;
  	struct lock_list root;
 -	struct lock_list *target_entry;
 +	struct lock_list *uninitialized_var(target_entry);
  
  	root.parent = NULL;
  	root.class = hlock_class(this);
* Unmerged path kernel/locking/lockdep.c
