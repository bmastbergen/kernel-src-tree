bpf: Introducte bpf_this_cpu_ptr()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-315.el8
commit-author Hao Luo <haoluo@google.com>
commit 63d9b80dcf2c67bc5ade61cbbaa09d7af21f43f1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-315.el8/63d9b80d.failed

Add bpf_this_cpu_ptr() to help access percpu var on this cpu. This
helper always returns a valid pointer, therefore no need to check
returned value for NULL. Also note that all programs run with
preemption disabled, which means that the returned pointer is stable
during all the execution of the program.

	Signed-off-by: Hao Luo <haoluo@google.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Andrii Nakryiko <andriin@fb.com>
Link: https://lore.kernel.org/bpf/20200929235049.2533242-6-haoluo@google.com
(cherry picked from commit 63d9b80dcf2c67bc5ade61cbbaa09d7af21f43f1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
#	include/uapi/linux/bpf.h
#	kernel/bpf/helpers.c
#	kernel/bpf/verifier.c
#	kernel/trace/bpf_trace.c
#	tools/include/uapi/linux/bpf.h
diff --cc include/linux/bpf.h
index e36b4db03c9a,dc63eeed4fd9..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -291,6 -308,8 +291,11 @@@ enum bpf_return_type 
  	RET_PTR_TO_SOCK_COMMON_OR_NULL,	/* returns a pointer to a sock_common or NULL */
  	RET_PTR_TO_ALLOC_MEM_OR_NULL,	/* returns a pointer to dynamically allocated memory or NULL */
  	RET_PTR_TO_BTF_ID_OR_NULL,	/* returns a pointer to a btf_id or NULL */
++<<<<<<< HEAD
++=======
+ 	RET_PTR_TO_MEM_OR_BTF_ID_OR_NULL, /* returns a pointer to a valid memory or a btf_id or NULL */
+ 	RET_PTR_TO_MEM_OR_BTF_ID,	/* returns a pointer to a valid memory or a btf_id */
++>>>>>>> 63d9b80dcf2c (bpf: Introducte bpf_this_cpu_ptr())
  };
  
  /* eBPF function prototype used by verifier to allow BPF_CALLs from eBPF programs
@@@ -1814,6 -1830,10 +1819,13 @@@ extern const struct bpf_func_proto bpf_
  extern const struct bpf_func_proto bpf_skc_to_tcp_timewait_sock_proto;
  extern const struct bpf_func_proto bpf_skc_to_tcp_request_sock_proto;
  extern const struct bpf_func_proto bpf_skc_to_udp6_sock_proto;
++<<<<<<< HEAD
++=======
+ extern const struct bpf_func_proto bpf_copy_from_user_proto;
+ extern const struct bpf_func_proto bpf_snprintf_btf_proto;
+ extern const struct bpf_func_proto bpf_per_cpu_ptr_proto;
+ extern const struct bpf_func_proto bpf_this_cpu_ptr_proto;
++>>>>>>> 63d9b80dcf2c (bpf: Introducte bpf_this_cpu_ptr())
  
  const struct bpf_func_proto *bpf_tracing_func_proto(
  	enum bpf_func_id func_id, const struct bpf_prog *prog);
diff --cc include/uapi/linux/bpf.h
index 818231d02d19,c446394135be..000000000000
--- a/include/uapi/linux/bpf.h
+++ b/include/uapi/linux/bpf.h
@@@ -3444,6 -3448,273 +3444,276 @@@ union bpf_attr 
   *		A non-negative value equal to or less than *size* on success,
   *		or a negative error in case of failure.
   *
++<<<<<<< HEAD
++=======
+  * long bpf_load_hdr_opt(struct bpf_sock_ops *skops, void *searchby_res, u32 len, u64 flags)
+  *	Description
+  *		Load header option.  Support reading a particular TCP header
+  *		option for bpf program (**BPF_PROG_TYPE_SOCK_OPS**).
+  *
+  *		If *flags* is 0, it will search the option from the
+  *		*skops*\ **->skb_data**.  The comment in **struct bpf_sock_ops**
+  *		has details on what skb_data contains under different
+  *		*skops*\ **->op**.
+  *
+  *		The first byte of the *searchby_res* specifies the
+  *		kind that it wants to search.
+  *
+  *		If the searching kind is an experimental kind
+  *		(i.e. 253 or 254 according to RFC6994).  It also
+  *		needs to specify the "magic" which is either
+  *		2 bytes or 4 bytes.  It then also needs to
+  *		specify the size of the magic by using
+  *		the 2nd byte which is "kind-length" of a TCP
+  *		header option and the "kind-length" also
+  *		includes the first 2 bytes "kind" and "kind-length"
+  *		itself as a normal TCP header option also does.
+  *
+  *		For example, to search experimental kind 254 with
+  *		2 byte magic 0xeB9F, the searchby_res should be
+  *		[ 254, 4, 0xeB, 0x9F, 0, 0, .... 0 ].
+  *
+  *		To search for the standard window scale option (3),
+  *		the *searchby_res* should be [ 3, 0, 0, .... 0 ].
+  *		Note, kind-length must be 0 for regular option.
+  *
+  *		Searching for No-Op (0) and End-of-Option-List (1) are
+  *		not supported.
+  *
+  *		*len* must be at least 2 bytes which is the minimal size
+  *		of a header option.
+  *
+  *		Supported flags:
+  *
+  *		* **BPF_LOAD_HDR_OPT_TCP_SYN** to search from the
+  *		  saved_syn packet or the just-received syn packet.
+  *
+  *	Return
+  *		> 0 when found, the header option is copied to *searchby_res*.
+  *		The return value is the total length copied. On failure, a
+  *		negative error code is returned:
+  *
+  *		**-EINVAL** if a parameter is invalid.
+  *
+  *		**-ENOMSG** if the option is not found.
+  *
+  *		**-ENOENT** if no syn packet is available when
+  *		**BPF_LOAD_HDR_OPT_TCP_SYN** is used.
+  *
+  *		**-ENOSPC** if there is not enough space.  Only *len* number of
+  *		bytes are copied.
+  *
+  *		**-EFAULT** on failure to parse the header options in the
+  *		packet.
+  *
+  *		**-EPERM** if the helper cannot be used under the current
+  *		*skops*\ **->op**.
+  *
+  * long bpf_store_hdr_opt(struct bpf_sock_ops *skops, const void *from, u32 len, u64 flags)
+  *	Description
+  *		Store header option.  The data will be copied
+  *		from buffer *from* with length *len* to the TCP header.
+  *
+  *		The buffer *from* should have the whole option that
+  *		includes the kind, kind-length, and the actual
+  *		option data.  The *len* must be at least kind-length
+  *		long.  The kind-length does not have to be 4 byte
+  *		aligned.  The kernel will take care of the padding
+  *		and setting the 4 bytes aligned value to th->doff.
+  *
+  *		This helper will check for duplicated option
+  *		by searching the same option in the outgoing skb.
+  *
+  *		This helper can only be called during
+  *		**BPF_SOCK_OPS_WRITE_HDR_OPT_CB**.
+  *
+  *	Return
+  *		0 on success, or negative error in case of failure:
+  *
+  *		**-EINVAL** If param is invalid.
+  *
+  *		**-ENOSPC** if there is not enough space in the header.
+  *		Nothing has been written
+  *
+  *		**-EEXIST** if the option already exists.
+  *
+  *		**-EFAULT** on failrue to parse the existing header options.
+  *
+  *		**-EPERM** if the helper cannot be used under the current
+  *		*skops*\ **->op**.
+  *
+  * long bpf_reserve_hdr_opt(struct bpf_sock_ops *skops, u32 len, u64 flags)
+  *	Description
+  *		Reserve *len* bytes for the bpf header option.  The
+  *		space will be used by **bpf_store_hdr_opt**\ () later in
+  *		**BPF_SOCK_OPS_WRITE_HDR_OPT_CB**.
+  *
+  *		If **bpf_reserve_hdr_opt**\ () is called multiple times,
+  *		the total number of bytes will be reserved.
+  *
+  *		This helper can only be called during
+  *		**BPF_SOCK_OPS_HDR_OPT_LEN_CB**.
+  *
+  *	Return
+  *		0 on success, or negative error in case of failure:
+  *
+  *		**-EINVAL** if a parameter is invalid.
+  *
+  *		**-ENOSPC** if there is not enough space in the header.
+  *
+  *		**-EPERM** if the helper cannot be used under the current
+  *		*skops*\ **->op**.
+  *
+  * void *bpf_inode_storage_get(struct bpf_map *map, void *inode, void *value, u64 flags)
+  *	Description
+  *		Get a bpf_local_storage from an *inode*.
+  *
+  *		Logically, it could be thought of as getting the value from
+  *		a *map* with *inode* as the **key**.  From this
+  *		perspective,  the usage is not much different from
+  *		**bpf_map_lookup_elem**\ (*map*, **&**\ *inode*) except this
+  *		helper enforces the key must be an inode and the map must also
+  *		be a **BPF_MAP_TYPE_INODE_STORAGE**.
+  *
+  *		Underneath, the value is stored locally at *inode* instead of
+  *		the *map*.  The *map* is used as the bpf-local-storage
+  *		"type". The bpf-local-storage "type" (i.e. the *map*) is
+  *		searched against all bpf_local_storage residing at *inode*.
+  *
+  *		An optional *flags* (**BPF_LOCAL_STORAGE_GET_F_CREATE**) can be
+  *		used such that a new bpf_local_storage will be
+  *		created if one does not exist.  *value* can be used
+  *		together with **BPF_LOCAL_STORAGE_GET_F_CREATE** to specify
+  *		the initial value of a bpf_local_storage.  If *value* is
+  *		**NULL**, the new bpf_local_storage will be zero initialized.
+  *	Return
+  *		A bpf_local_storage pointer is returned on success.
+  *
+  *		**NULL** if not found or there was an error in adding
+  *		a new bpf_local_storage.
+  *
+  * int bpf_inode_storage_delete(struct bpf_map *map, void *inode)
+  *	Description
+  *		Delete a bpf_local_storage from an *inode*.
+  *	Return
+  *		0 on success.
+  *
+  *		**-ENOENT** if the bpf_local_storage cannot be found.
+  *
+  * long bpf_d_path(struct path *path, char *buf, u32 sz)
+  *	Description
+  *		Return full path for given **struct path** object, which
+  *		needs to be the kernel BTF *path* object. The path is
+  *		returned in the provided buffer *buf* of size *sz* and
+  *		is zero terminated.
+  *
+  *	Return
+  *		On success, the strictly positive length of the string,
+  *		including the trailing NUL character. On error, a negative
+  *		value.
+  *
+  * long bpf_copy_from_user(void *dst, u32 size, const void *user_ptr)
+  * 	Description
+  * 		Read *size* bytes from user space address *user_ptr* and store
+  * 		the data in *dst*. This is a wrapper of **copy_from_user**\ ().
+  * 	Return
+  * 		0 on success, or a negative error in case of failure.
+  *
+  * long bpf_snprintf_btf(char *str, u32 str_size, struct btf_ptr *ptr, u32 btf_ptr_size, u64 flags)
+  *	Description
+  *		Use BTF to store a string representation of *ptr*->ptr in *str*,
+  *		using *ptr*->type_id.  This value should specify the type
+  *		that *ptr*->ptr points to. LLVM __builtin_btf_type_id(type, 1)
+  *		can be used to look up vmlinux BTF type ids. Traversing the
+  *		data structure using BTF, the type information and values are
+  *		stored in the first *str_size* - 1 bytes of *str*.  Safe copy of
+  *		the pointer data is carried out to avoid kernel crashes during
+  *		operation.  Smaller types can use string space on the stack;
+  *		larger programs can use map data to store the string
+  *		representation.
+  *
+  *		The string can be subsequently shared with userspace via
+  *		bpf_perf_event_output() or ring buffer interfaces.
+  *		bpf_trace_printk() is to be avoided as it places too small
+  *		a limit on string size to be useful.
+  *
+  *		*flags* is a combination of
+  *
+  *		**BTF_F_COMPACT**
+  *			no formatting around type information
+  *		**BTF_F_NONAME**
+  *			no struct/union member names/types
+  *		**BTF_F_PTR_RAW**
+  *			show raw (unobfuscated) pointer values;
+  *			equivalent to printk specifier %px.
+  *		**BTF_F_ZERO**
+  *			show zero-valued struct/union members; they
+  *			are not displayed by default
+  *
+  *	Return
+  *		The number of bytes that were written (or would have been
+  *		written if output had to be truncated due to string size),
+  *		or a negative error in cases of failure.
+  *
+  * long bpf_seq_printf_btf(struct seq_file *m, struct btf_ptr *ptr, u32 ptr_size, u64 flags)
+  *	Description
+  *		Use BTF to write to seq_write a string representation of
+  *		*ptr*->ptr, using *ptr*->type_id as per bpf_snprintf_btf().
+  *		*flags* are identical to those used for bpf_snprintf_btf.
+  *	Return
+  *		0 on success or a negative error in case of failure.
+  *
+  * u64 bpf_skb_cgroup_classid(struct sk_buff *skb)
+  * 	Description
+  * 		See **bpf_get_cgroup_classid**\ () for the main description.
+  * 		This helper differs from **bpf_get_cgroup_classid**\ () in that
+  * 		the cgroup v1 net_cls class is retrieved only from the *skb*'s
+  * 		associated socket instead of the current process.
+  * 	Return
+  * 		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * long bpf_redirect_neigh(u32 ifindex, u64 flags)
+  * 	Description
+  * 		Redirect the packet to another net device of index *ifindex*
+  * 		and fill in L2 addresses from neighboring subsystem. This helper
+  * 		is somewhat similar to **bpf_redirect**\ (), except that it
+  * 		fills in e.g. MAC addresses based on the L3 information from
+  * 		the packet. This helper is supported for IPv4 and IPv6 protocols.
+  * 		The *flags* argument is reserved and must be 0. The helper is
+  * 		currently only supported for tc BPF program types.
+  * 	Return
+  * 		The helper returns **TC_ACT_REDIRECT** on success or
+  * 		**TC_ACT_SHOT** on error.
+  *
+  * void *bpf_per_cpu_ptr(const void *percpu_ptr, u32 cpu)
+  *     Description
+  *             Take a pointer to a percpu ksym, *percpu_ptr*, and return a
+  *             pointer to the percpu kernel variable on *cpu*. A ksym is an
+  *             extern variable decorated with '__ksym'. For ksym, there is a
+  *             global var (either static or global) defined of the same name
+  *             in the kernel. The ksym is percpu if the global var is percpu.
+  *             The returned pointer points to the global percpu var on *cpu*.
+  *
+  *             bpf_per_cpu_ptr() has the same semantic as per_cpu_ptr() in the
+  *             kernel, except that bpf_per_cpu_ptr() may return NULL. This
+  *             happens if *cpu* is larger than nr_cpu_ids. The caller of
+  *             bpf_per_cpu_ptr() must check the returned value.
+  *     Return
+  *             A pointer pointing to the kernel percpu variable on *cpu*, or
+  *             NULL, if *cpu* is invalid.
+  *
+  * void *bpf_this_cpu_ptr(const void *percpu_ptr)
+  *	Description
+  *		Take a pointer to a percpu ksym, *percpu_ptr*, and return a
+  *		pointer to the percpu kernel variable on this cpu. See the
+  *		description of 'ksym' in **bpf_per_cpu_ptr**\ ().
+  *
+  *		bpf_this_cpu_ptr() has the same semantic as this_cpu_ptr() in
+  *		the kernel. Different from **bpf_per_cpu_ptr**\ (), it would
+  *		never return NULL.
+  *	Return
+  *		A pointer pointing to the kernel percpu variable on this cpu.
++>>>>>>> 63d9b80dcf2c (bpf: Introducte bpf_this_cpu_ptr())
   */
  #define __BPF_FUNC_MAPPER(FN)		\
  	FN(unspec),			\
@@@ -3588,6 -3859,19 +3858,22 @@@
  	FN(skc_to_tcp_request_sock),	\
  	FN(skc_to_udp6_sock),		\
  	FN(get_task_stack),		\
++<<<<<<< HEAD
++=======
+ 	FN(load_hdr_opt),		\
+ 	FN(store_hdr_opt),		\
+ 	FN(reserve_hdr_opt),		\
+ 	FN(inode_storage_get),		\
+ 	FN(inode_storage_delete),	\
+ 	FN(d_path),			\
+ 	FN(copy_from_user),		\
+ 	FN(snprintf_btf),		\
+ 	FN(seq_printf_btf),		\
+ 	FN(skb_cgroup_classid),		\
+ 	FN(redirect_neigh),		\
+ 	FN(bpf_per_cpu_ptr),            \
+ 	FN(bpf_this_cpu_ptr),		\
++>>>>>>> 63d9b80dcf2c (bpf: Introducte bpf_this_cpu_ptr())
  	/* */
  
  /* integer value in 'imm' field of BPF_CALL instruction selects which helper
diff --cc kernel/bpf/helpers.c
index 558c98f4de99,25520f5eeaf6..000000000000
--- a/kernel/bpf/helpers.c
+++ b/kernel/bpf/helpers.c
@@@ -609,6 -601,56 +609,59 @@@ const struct bpf_func_proto bpf_event_o
  	.arg5_type      = ARG_CONST_SIZE_OR_ZERO,
  };
  
++<<<<<<< HEAD
++=======
+ BPF_CALL_3(bpf_copy_from_user, void *, dst, u32, size,
+ 	   const void __user *, user_ptr)
+ {
+ 	int ret = copy_from_user(dst, user_ptr, size);
+ 
+ 	if (unlikely(ret)) {
+ 		memset(dst, 0, size);
+ 		ret = -EFAULT;
+ 	}
+ 
+ 	return ret;
+ }
+ 
+ const struct bpf_func_proto bpf_copy_from_user_proto = {
+ 	.func		= bpf_copy_from_user,
+ 	.gpl_only	= false,
+ 	.ret_type	= RET_INTEGER,
+ 	.arg1_type	= ARG_PTR_TO_UNINIT_MEM,
+ 	.arg2_type	= ARG_CONST_SIZE_OR_ZERO,
+ 	.arg3_type	= ARG_ANYTHING,
+ };
+ 
+ BPF_CALL_2(bpf_per_cpu_ptr, const void *, ptr, u32, cpu)
+ {
+ 	if (cpu >= nr_cpu_ids)
+ 		return (unsigned long)NULL;
+ 
+ 	return (unsigned long)per_cpu_ptr((const void __percpu *)ptr, cpu);
+ }
+ 
+ const struct bpf_func_proto bpf_per_cpu_ptr_proto = {
+ 	.func		= bpf_per_cpu_ptr,
+ 	.gpl_only	= false,
+ 	.ret_type	= RET_PTR_TO_MEM_OR_BTF_ID_OR_NULL,
+ 	.arg1_type	= ARG_PTR_TO_PERCPU_BTF_ID,
+ 	.arg2_type	= ARG_ANYTHING,
+ };
+ 
+ BPF_CALL_1(bpf_this_cpu_ptr, const void *, percpu_ptr)
+ {
+ 	return (unsigned long)this_cpu_ptr((const void __percpu *)percpu_ptr);
+ }
+ 
+ const struct bpf_func_proto bpf_this_cpu_ptr_proto = {
+ 	.func		= bpf_this_cpu_ptr,
+ 	.gpl_only	= false,
+ 	.ret_type	= RET_PTR_TO_MEM_OR_BTF_ID,
+ 	.arg1_type	= ARG_PTR_TO_PERCPU_BTF_ID,
+ };
+ 
++>>>>>>> 63d9b80dcf2c (bpf: Introducte bpf_this_cpu_ptr())
  const struct bpf_func_proto bpf_get_current_task_proto __weak;
  const struct bpf_func_proto bpf_probe_read_user_proto __weak;
  const struct bpf_func_proto bpf_probe_read_user_str_proto __weak;
@@@ -669,8 -711,16 +722,15 @@@ bpf_base_func_proto(enum bpf_func_id fu
  		if (!perfmon_capable())
  			return NULL;
  		return bpf_get_trace_printk_proto();
 -	case BPF_FUNC_snprintf_btf:
 -		if (!perfmon_capable())
 -			return NULL;
 -		return &bpf_snprintf_btf_proto;
  	case BPF_FUNC_jiffies64:
  		return &bpf_jiffies64_proto;
++<<<<<<< HEAD
++=======
+ 	case BPF_FUNC_bpf_per_cpu_ptr:
+ 		return &bpf_per_cpu_ptr_proto;
+ 	case BPF_FUNC_bpf_this_cpu_ptr:
+ 		return &bpf_this_cpu_ptr_proto;
++>>>>>>> 63d9b80dcf2c (bpf: Introducte bpf_this_cpu_ptr())
  	default:
  		break;
  	}
diff --cc kernel/bpf/verifier.c
index 3fd224c98ac3,d9dbf271ebab..000000000000
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@@ -5029,7 -5125,38 +5029,39 @@@ static int check_helper_call(struct bpf
  	} else if (fn->ret_type == RET_PTR_TO_ALLOC_MEM_OR_NULL) {
  		mark_reg_known_zero(env, regs, BPF_REG_0);
  		regs[BPF_REG_0].type = PTR_TO_MEM_OR_NULL;
 -		regs[BPF_REG_0].id = ++env->id_gen;
  		regs[BPF_REG_0].mem_size = meta.mem_size;
++<<<<<<< HEAD
++=======
+ 	} else if (fn->ret_type == RET_PTR_TO_MEM_OR_BTF_ID_OR_NULL ||
+ 		   fn->ret_type == RET_PTR_TO_MEM_OR_BTF_ID) {
+ 		const struct btf_type *t;
+ 
+ 		mark_reg_known_zero(env, regs, BPF_REG_0);
+ 		t = btf_type_skip_modifiers(btf_vmlinux, meta.ret_btf_id, NULL);
+ 		if (!btf_type_is_struct(t)) {
+ 			u32 tsize;
+ 			const struct btf_type *ret;
+ 			const char *tname;
+ 
+ 			/* resolve the type size of ksym. */
+ 			ret = btf_resolve_size(btf_vmlinux, t, &tsize);
+ 			if (IS_ERR(ret)) {
+ 				tname = btf_name_by_offset(btf_vmlinux, t->name_off);
+ 				verbose(env, "unable to resolve the size of type '%s': %ld\n",
+ 					tname, PTR_ERR(ret));
+ 				return -EINVAL;
+ 			}
+ 			regs[BPF_REG_0].type =
+ 				fn->ret_type == RET_PTR_TO_MEM_OR_BTF_ID ?
+ 				PTR_TO_MEM : PTR_TO_MEM_OR_NULL;
+ 			regs[BPF_REG_0].mem_size = tsize;
+ 		} else {
+ 			regs[BPF_REG_0].type =
+ 				fn->ret_type == RET_PTR_TO_MEM_OR_BTF_ID ?
+ 				PTR_TO_BTF_ID : PTR_TO_BTF_ID_OR_NULL;
+ 			regs[BPF_REG_0].btf_id = meta.ret_btf_id;
+ 		}
++>>>>>>> 63d9b80dcf2c (bpf: Introducte bpf_this_cpu_ptr())
  	} else if (fn->ret_type == RET_PTR_TO_BTF_ID_OR_NULL) {
  		int ret_btf_id;
  
diff --cc kernel/trace/bpf_trace.c
index fa9081cef38b,a136a6a63a71..000000000000
--- a/kernel/trace/bpf_trace.c
+++ b/kernel/trace/bpf_trace.c
@@@ -1170,6 -1323,14 +1170,17 @@@ bpf_tracing_func_proto(enum bpf_func_i
  		return &bpf_jiffies64_proto;
  	case BPF_FUNC_get_task_stack:
  		return &bpf_get_task_stack_proto;
++<<<<<<< HEAD
++=======
+ 	case BPF_FUNC_copy_from_user:
+ 		return prog->aux->sleepable ? &bpf_copy_from_user_proto : NULL;
+ 	case BPF_FUNC_snprintf_btf:
+ 		return &bpf_snprintf_btf_proto;
+ 	case BPF_FUNC_bpf_per_cpu_ptr:
+ 		return &bpf_per_cpu_ptr_proto;
+ 	case BPF_FUNC_bpf_this_cpu_ptr:
+ 		return &bpf_this_cpu_ptr_proto;
++>>>>>>> 63d9b80dcf2c (bpf: Introducte bpf_this_cpu_ptr())
  	default:
  		return NULL;
  	}
diff --cc tools/include/uapi/linux/bpf.h
index 4c62783528f1,c446394135be..000000000000
--- a/tools/include/uapi/linux/bpf.h
+++ b/tools/include/uapi/linux/bpf.h
@@@ -3424,6 -3448,273 +3424,276 @@@ union bpf_attr 
   *		A non-negative value equal to or less than *size* on success,
   *		or a negative error in case of failure.
   *
++<<<<<<< HEAD
++=======
+  * long bpf_load_hdr_opt(struct bpf_sock_ops *skops, void *searchby_res, u32 len, u64 flags)
+  *	Description
+  *		Load header option.  Support reading a particular TCP header
+  *		option for bpf program (**BPF_PROG_TYPE_SOCK_OPS**).
+  *
+  *		If *flags* is 0, it will search the option from the
+  *		*skops*\ **->skb_data**.  The comment in **struct bpf_sock_ops**
+  *		has details on what skb_data contains under different
+  *		*skops*\ **->op**.
+  *
+  *		The first byte of the *searchby_res* specifies the
+  *		kind that it wants to search.
+  *
+  *		If the searching kind is an experimental kind
+  *		(i.e. 253 or 254 according to RFC6994).  It also
+  *		needs to specify the "magic" which is either
+  *		2 bytes or 4 bytes.  It then also needs to
+  *		specify the size of the magic by using
+  *		the 2nd byte which is "kind-length" of a TCP
+  *		header option and the "kind-length" also
+  *		includes the first 2 bytes "kind" and "kind-length"
+  *		itself as a normal TCP header option also does.
+  *
+  *		For example, to search experimental kind 254 with
+  *		2 byte magic 0xeB9F, the searchby_res should be
+  *		[ 254, 4, 0xeB, 0x9F, 0, 0, .... 0 ].
+  *
+  *		To search for the standard window scale option (3),
+  *		the *searchby_res* should be [ 3, 0, 0, .... 0 ].
+  *		Note, kind-length must be 0 for regular option.
+  *
+  *		Searching for No-Op (0) and End-of-Option-List (1) are
+  *		not supported.
+  *
+  *		*len* must be at least 2 bytes which is the minimal size
+  *		of a header option.
+  *
+  *		Supported flags:
+  *
+  *		* **BPF_LOAD_HDR_OPT_TCP_SYN** to search from the
+  *		  saved_syn packet or the just-received syn packet.
+  *
+  *	Return
+  *		> 0 when found, the header option is copied to *searchby_res*.
+  *		The return value is the total length copied. On failure, a
+  *		negative error code is returned:
+  *
+  *		**-EINVAL** if a parameter is invalid.
+  *
+  *		**-ENOMSG** if the option is not found.
+  *
+  *		**-ENOENT** if no syn packet is available when
+  *		**BPF_LOAD_HDR_OPT_TCP_SYN** is used.
+  *
+  *		**-ENOSPC** if there is not enough space.  Only *len* number of
+  *		bytes are copied.
+  *
+  *		**-EFAULT** on failure to parse the header options in the
+  *		packet.
+  *
+  *		**-EPERM** if the helper cannot be used under the current
+  *		*skops*\ **->op**.
+  *
+  * long bpf_store_hdr_opt(struct bpf_sock_ops *skops, const void *from, u32 len, u64 flags)
+  *	Description
+  *		Store header option.  The data will be copied
+  *		from buffer *from* with length *len* to the TCP header.
+  *
+  *		The buffer *from* should have the whole option that
+  *		includes the kind, kind-length, and the actual
+  *		option data.  The *len* must be at least kind-length
+  *		long.  The kind-length does not have to be 4 byte
+  *		aligned.  The kernel will take care of the padding
+  *		and setting the 4 bytes aligned value to th->doff.
+  *
+  *		This helper will check for duplicated option
+  *		by searching the same option in the outgoing skb.
+  *
+  *		This helper can only be called during
+  *		**BPF_SOCK_OPS_WRITE_HDR_OPT_CB**.
+  *
+  *	Return
+  *		0 on success, or negative error in case of failure:
+  *
+  *		**-EINVAL** If param is invalid.
+  *
+  *		**-ENOSPC** if there is not enough space in the header.
+  *		Nothing has been written
+  *
+  *		**-EEXIST** if the option already exists.
+  *
+  *		**-EFAULT** on failrue to parse the existing header options.
+  *
+  *		**-EPERM** if the helper cannot be used under the current
+  *		*skops*\ **->op**.
+  *
+  * long bpf_reserve_hdr_opt(struct bpf_sock_ops *skops, u32 len, u64 flags)
+  *	Description
+  *		Reserve *len* bytes for the bpf header option.  The
+  *		space will be used by **bpf_store_hdr_opt**\ () later in
+  *		**BPF_SOCK_OPS_WRITE_HDR_OPT_CB**.
+  *
+  *		If **bpf_reserve_hdr_opt**\ () is called multiple times,
+  *		the total number of bytes will be reserved.
+  *
+  *		This helper can only be called during
+  *		**BPF_SOCK_OPS_HDR_OPT_LEN_CB**.
+  *
+  *	Return
+  *		0 on success, or negative error in case of failure:
+  *
+  *		**-EINVAL** if a parameter is invalid.
+  *
+  *		**-ENOSPC** if there is not enough space in the header.
+  *
+  *		**-EPERM** if the helper cannot be used under the current
+  *		*skops*\ **->op**.
+  *
+  * void *bpf_inode_storage_get(struct bpf_map *map, void *inode, void *value, u64 flags)
+  *	Description
+  *		Get a bpf_local_storage from an *inode*.
+  *
+  *		Logically, it could be thought of as getting the value from
+  *		a *map* with *inode* as the **key**.  From this
+  *		perspective,  the usage is not much different from
+  *		**bpf_map_lookup_elem**\ (*map*, **&**\ *inode*) except this
+  *		helper enforces the key must be an inode and the map must also
+  *		be a **BPF_MAP_TYPE_INODE_STORAGE**.
+  *
+  *		Underneath, the value is stored locally at *inode* instead of
+  *		the *map*.  The *map* is used as the bpf-local-storage
+  *		"type". The bpf-local-storage "type" (i.e. the *map*) is
+  *		searched against all bpf_local_storage residing at *inode*.
+  *
+  *		An optional *flags* (**BPF_LOCAL_STORAGE_GET_F_CREATE**) can be
+  *		used such that a new bpf_local_storage will be
+  *		created if one does not exist.  *value* can be used
+  *		together with **BPF_LOCAL_STORAGE_GET_F_CREATE** to specify
+  *		the initial value of a bpf_local_storage.  If *value* is
+  *		**NULL**, the new bpf_local_storage will be zero initialized.
+  *	Return
+  *		A bpf_local_storage pointer is returned on success.
+  *
+  *		**NULL** if not found or there was an error in adding
+  *		a new bpf_local_storage.
+  *
+  * int bpf_inode_storage_delete(struct bpf_map *map, void *inode)
+  *	Description
+  *		Delete a bpf_local_storage from an *inode*.
+  *	Return
+  *		0 on success.
+  *
+  *		**-ENOENT** if the bpf_local_storage cannot be found.
+  *
+  * long bpf_d_path(struct path *path, char *buf, u32 sz)
+  *	Description
+  *		Return full path for given **struct path** object, which
+  *		needs to be the kernel BTF *path* object. The path is
+  *		returned in the provided buffer *buf* of size *sz* and
+  *		is zero terminated.
+  *
+  *	Return
+  *		On success, the strictly positive length of the string,
+  *		including the trailing NUL character. On error, a negative
+  *		value.
+  *
+  * long bpf_copy_from_user(void *dst, u32 size, const void *user_ptr)
+  * 	Description
+  * 		Read *size* bytes from user space address *user_ptr* and store
+  * 		the data in *dst*. This is a wrapper of **copy_from_user**\ ().
+  * 	Return
+  * 		0 on success, or a negative error in case of failure.
+  *
+  * long bpf_snprintf_btf(char *str, u32 str_size, struct btf_ptr *ptr, u32 btf_ptr_size, u64 flags)
+  *	Description
+  *		Use BTF to store a string representation of *ptr*->ptr in *str*,
+  *		using *ptr*->type_id.  This value should specify the type
+  *		that *ptr*->ptr points to. LLVM __builtin_btf_type_id(type, 1)
+  *		can be used to look up vmlinux BTF type ids. Traversing the
+  *		data structure using BTF, the type information and values are
+  *		stored in the first *str_size* - 1 bytes of *str*.  Safe copy of
+  *		the pointer data is carried out to avoid kernel crashes during
+  *		operation.  Smaller types can use string space on the stack;
+  *		larger programs can use map data to store the string
+  *		representation.
+  *
+  *		The string can be subsequently shared with userspace via
+  *		bpf_perf_event_output() or ring buffer interfaces.
+  *		bpf_trace_printk() is to be avoided as it places too small
+  *		a limit on string size to be useful.
+  *
+  *		*flags* is a combination of
+  *
+  *		**BTF_F_COMPACT**
+  *			no formatting around type information
+  *		**BTF_F_NONAME**
+  *			no struct/union member names/types
+  *		**BTF_F_PTR_RAW**
+  *			show raw (unobfuscated) pointer values;
+  *			equivalent to printk specifier %px.
+  *		**BTF_F_ZERO**
+  *			show zero-valued struct/union members; they
+  *			are not displayed by default
+  *
+  *	Return
+  *		The number of bytes that were written (or would have been
+  *		written if output had to be truncated due to string size),
+  *		or a negative error in cases of failure.
+  *
+  * long bpf_seq_printf_btf(struct seq_file *m, struct btf_ptr *ptr, u32 ptr_size, u64 flags)
+  *	Description
+  *		Use BTF to write to seq_write a string representation of
+  *		*ptr*->ptr, using *ptr*->type_id as per bpf_snprintf_btf().
+  *		*flags* are identical to those used for bpf_snprintf_btf.
+  *	Return
+  *		0 on success or a negative error in case of failure.
+  *
+  * u64 bpf_skb_cgroup_classid(struct sk_buff *skb)
+  * 	Description
+  * 		See **bpf_get_cgroup_classid**\ () for the main description.
+  * 		This helper differs from **bpf_get_cgroup_classid**\ () in that
+  * 		the cgroup v1 net_cls class is retrieved only from the *skb*'s
+  * 		associated socket instead of the current process.
+  * 	Return
+  * 		The id is returned or 0 in case the id could not be retrieved.
+  *
+  * long bpf_redirect_neigh(u32 ifindex, u64 flags)
+  * 	Description
+  * 		Redirect the packet to another net device of index *ifindex*
+  * 		and fill in L2 addresses from neighboring subsystem. This helper
+  * 		is somewhat similar to **bpf_redirect**\ (), except that it
+  * 		fills in e.g. MAC addresses based on the L3 information from
+  * 		the packet. This helper is supported for IPv4 and IPv6 protocols.
+  * 		The *flags* argument is reserved and must be 0. The helper is
+  * 		currently only supported for tc BPF program types.
+  * 	Return
+  * 		The helper returns **TC_ACT_REDIRECT** on success or
+  * 		**TC_ACT_SHOT** on error.
+  *
+  * void *bpf_per_cpu_ptr(const void *percpu_ptr, u32 cpu)
+  *     Description
+  *             Take a pointer to a percpu ksym, *percpu_ptr*, and return a
+  *             pointer to the percpu kernel variable on *cpu*. A ksym is an
+  *             extern variable decorated with '__ksym'. For ksym, there is a
+  *             global var (either static or global) defined of the same name
+  *             in the kernel. The ksym is percpu if the global var is percpu.
+  *             The returned pointer points to the global percpu var on *cpu*.
+  *
+  *             bpf_per_cpu_ptr() has the same semantic as per_cpu_ptr() in the
+  *             kernel, except that bpf_per_cpu_ptr() may return NULL. This
+  *             happens if *cpu* is larger than nr_cpu_ids. The caller of
+  *             bpf_per_cpu_ptr() must check the returned value.
+  *     Return
+  *             A pointer pointing to the kernel percpu variable on *cpu*, or
+  *             NULL, if *cpu* is invalid.
+  *
+  * void *bpf_this_cpu_ptr(const void *percpu_ptr)
+  *	Description
+  *		Take a pointer to a percpu ksym, *percpu_ptr*, and return a
+  *		pointer to the percpu kernel variable on this cpu. See the
+  *		description of 'ksym' in **bpf_per_cpu_ptr**\ ().
+  *
+  *		bpf_this_cpu_ptr() has the same semantic as this_cpu_ptr() in
+  *		the kernel. Different from **bpf_per_cpu_ptr**\ (), it would
+  *		never return NULL.
+  *	Return
+  *		A pointer pointing to the kernel percpu variable on this cpu.
++>>>>>>> 63d9b80dcf2c (bpf: Introducte bpf_this_cpu_ptr())
   */
  #define __BPF_FUNC_MAPPER(FN)		\
  	FN(unspec),			\
@@@ -3568,6 -3859,19 +3838,22 @@@
  	FN(skc_to_tcp_request_sock),	\
  	FN(skc_to_udp6_sock),		\
  	FN(get_task_stack),		\
++<<<<<<< HEAD
++=======
+ 	FN(load_hdr_opt),		\
+ 	FN(store_hdr_opt),		\
+ 	FN(reserve_hdr_opt),		\
+ 	FN(inode_storage_get),		\
+ 	FN(inode_storage_delete),	\
+ 	FN(d_path),			\
+ 	FN(copy_from_user),		\
+ 	FN(snprintf_btf),		\
+ 	FN(seq_printf_btf),		\
+ 	FN(skb_cgroup_classid),		\
+ 	FN(redirect_neigh),		\
+ 	FN(bpf_per_cpu_ptr),            \
+ 	FN(bpf_this_cpu_ptr),		\
++>>>>>>> 63d9b80dcf2c (bpf: Introducte bpf_this_cpu_ptr())
  	/* */
  
  /* integer value in 'imm' field of BPF_CALL instruction selects which helper
* Unmerged path include/linux/bpf.h
* Unmerged path include/uapi/linux/bpf.h
* Unmerged path kernel/bpf/helpers.c
* Unmerged path kernel/bpf/verifier.c
* Unmerged path kernel/trace/bpf_trace.c
* Unmerged path tools/include/uapi/linux/bpf.h
