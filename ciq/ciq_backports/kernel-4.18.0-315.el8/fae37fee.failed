locking/rtmutex: Move rt_mutex_debug_task_free() to rtmutex.c

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-315.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit fae37feee096bd3c85f6453713131a471404c6f5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-315.el8/fae37fee.failed

Prepare for removing the header maze.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
	Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: https://lore.kernel.org/r/20210326153943.646359691@linutronix.de
(cherry picked from commit fae37feee096bd3c85f6453713131a471404c6f5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/locking/rtmutex-debug.c
diff --cc kernel/locking/rtmutex-debug.c
index 36222f3f2c33,f1a83ec9c9b0..000000000000
--- a/kernel/locking/rtmutex-debug.c
+++ b/kernel/locking/rtmutex-debug.c
@@@ -32,109 -32,6 +32,112 @@@
  
  #include "rtmutex_common.h"
  
++<<<<<<< HEAD
 +static void printk_task(struct task_struct *p)
 +{
 +	if (p)
 +		printk("%16s:%5d [%p, %3d]", p->comm, task_pid_nr(p), p, p->prio);
 +	else
 +		printk("<none>");
 +}
 +
 +static void printk_lock(struct rt_mutex *lock, int print_owner)
 +{
 +	printk(" [%p] {%s}\n", lock, lock->name);
 +
 +	if (print_owner && rt_mutex_owner(lock)) {
 +		printk(".. ->owner: %p\n", lock->owner);
 +		printk(".. held by:  ");
 +		printk_task(rt_mutex_owner(lock));
 +		printk("\n");
 +	}
 +}
 +
 +void rt_mutex_debug_task_free(struct task_struct *task)
 +{
 +	DEBUG_LOCKS_WARN_ON(!RB_EMPTY_ROOT(&task->pi_waiters.rb_root));
 +	DEBUG_LOCKS_WARN_ON(task->pi_blocked_on);
 +}
 +
 +/*
 + * We fill out the fields in the waiter to store the information about
 + * the deadlock. We print when we return. act_waiter can be NULL in
 + * case of a remove waiter operation.
 + */
 +void debug_rt_mutex_deadlock(enum rtmutex_chainwalk chwalk,
 +			     struct rt_mutex_waiter *act_waiter,
 +			     struct rt_mutex *lock)
 +{
 +	struct task_struct *task;
 +
 +	if (!debug_locks || chwalk == RT_MUTEX_FULL_CHAINWALK || !act_waiter)
 +		return;
 +
 +	task = rt_mutex_owner(act_waiter->lock);
 +	if (task && task != current) {
 +		act_waiter->deadlock_task_pid = get_pid(task_pid(task));
 +		act_waiter->deadlock_lock = lock;
 +	}
 +}
 +
 +void debug_rt_mutex_print_deadlock(struct rt_mutex_waiter *waiter)
 +{
 +	struct task_struct *task;
 +
 +	if (!waiter->deadlock_lock || !debug_locks)
 +		return;
 +
 +	rcu_read_lock();
 +	task = pid_task(waiter->deadlock_task_pid, PIDTYPE_PID);
 +	if (!task) {
 +		rcu_read_unlock();
 +		return;
 +	}
 +
 +	if (!debug_locks_off()) {
 +		rcu_read_unlock();
 +		return;
 +	}
 +
 +	pr_warn("\n");
 +	pr_warn("============================================\n");
 +	pr_warn("WARNING: circular locking deadlock detected!\n");
 +	pr_warn("%s\n", print_tainted());
 +	pr_warn("--------------------------------------------\n");
 +	printk("%s/%d is deadlocking current task %s/%d\n\n",
 +	       task->comm, task_pid_nr(task),
 +	       current->comm, task_pid_nr(current));
 +
 +	printk("\n1) %s/%d is trying to acquire this lock:\n",
 +	       current->comm, task_pid_nr(current));
 +	printk_lock(waiter->lock, 1);
 +
 +	printk("\n2) %s/%d is blocked on this lock:\n",
 +		task->comm, task_pid_nr(task));
 +	printk_lock(waiter->deadlock_lock, 1);
 +
 +	debug_show_held_locks(current);
 +	debug_show_held_locks(task);
 +
 +	printk("\n%s/%d's [blocked] stackdump:\n\n",
 +		task->comm, task_pid_nr(task));
 +	show_stack(task, NULL);
 +	printk("\n%s/%d's [current] stackdump:\n\n",
 +		current->comm, task_pid_nr(current));
 +	dump_stack();
 +	debug_show_all_locks();
 +	rcu_read_unlock();
 +
 +	printk("[ turning off deadlock detection."
 +	       "Please report this trace. ]\n\n");
 +}
 +
 +void debug_rt_mutex_lock(struct rt_mutex *lock)
 +{
 +}
 +
++=======
++>>>>>>> fae37feee096 (locking/rtmutex: Move rt_mutex_debug_task_free() to rtmutex.c)
  void debug_rt_mutex_unlock(struct rt_mutex *lock)
  {
  	DEBUG_LOCKS_WARN_ON(rt_mutex_owner(lock) != current);
* Unmerged path kernel/locking/rtmutex-debug.c
diff --git a/kernel/locking/rtmutex.c b/kernel/locking/rtmutex.c
index 0d1634491095..14615921db39 100644
--- a/kernel/locking/rtmutex.c
+++ b/kernel/locking/rtmutex.c
@@ -1855,3 +1855,11 @@ bool rt_mutex_cleanup_proxy_lock(struct rt_mutex *lock,
 
 	return cleanup;
 }
+
+#ifdef CONFIG_DEBUG_RT_MUTEXES
+void rt_mutex_debug_task_free(struct task_struct *task)
+{
+	DEBUG_LOCKS_WARN_ON(!RB_EMPTY_ROOT(&task->pi_waiters.rb_root));
+	DEBUG_LOCKS_WARN_ON(task->pi_blocked_on);
+}
+#endif
