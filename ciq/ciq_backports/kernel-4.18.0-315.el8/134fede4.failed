bpf: Relax max_entries check for most of the inner map types

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-315.el8
commit-author Martin KaFai Lau <kafai@fb.com>
commit 134fede4eecfcbe7900e789f625fa6f9c3a8cd0e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-315.el8/134fede4.failed

Most of the maps do not use max_entries during verification time.
Thus, those map_meta_equal() do not need to enforce max_entries
when it is inserted as an inner map during runtime.  The max_entries
check is removed from the default implementation bpf_map_meta_equal().

The prog_array_map and xsk_map are exception.  Its map_gen_lookup
uses max_entries to generate inline lookup code.  Thus, they will
implement its own map_meta_equal() to enforce max_entries.
Since there are only two cases now, the max_entries check
is not refactored and stays in its own .c file.

	Signed-off-by: Martin KaFai Lau <kafai@fb.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
Link: https://lore.kernel.org/bpf/20200828011813.1970516-1-kafai@fb.com
(cherry picked from commit 134fede4eecfcbe7900e789f625fa6f9c3a8cd0e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/arraymap.c
#	net/xdp/xskmap.c
diff --cc kernel/bpf/arraymap.c
index e44c2b8877d8,d851ebbcf302..000000000000
--- a/kernel/bpf/arraymap.c
+++ b/kernel/bpf/arraymap.c
@@@ -633,6 -632,7 +640,10 @@@ static const struct bpf_iter_seq_info i
  
  static int array_map_btf_id;
  const struct bpf_map_ops array_map_ops = {
++<<<<<<< HEAD
++=======
+ 	.map_meta_equal = array_map_meta_equal,
++>>>>>>> 134fede4eecf (bpf: Relax max_entries check for most of the inner map types)
  	.map_alloc_check = array_map_alloc_check,
  	.map_alloc = array_map_alloc,
  	.map_free = array_map_free,
diff --cc net/xdp/xskmap.c
index 8367adbbe9df,2a4fd6677155..000000000000
--- a/net/xdp/xskmap.c
+++ b/net/xdp/xskmap.c
@@@ -254,8 -254,16 +254,19 @@@ void xsk_map_try_sock_delete(struct xsk
  	spin_unlock_bh(&map->lock);
  }
  
+ static bool xsk_map_meta_equal(const struct bpf_map *meta0,
+ 			       const struct bpf_map *meta1)
+ {
+ 	return meta0->max_entries == meta1->max_entries &&
+ 		bpf_map_meta_equal(meta0, meta1);
+ }
+ 
  static int xsk_map_btf_id;
  const struct bpf_map_ops xsk_map_ops = {
++<<<<<<< HEAD
++=======
+ 	.map_meta_equal = xsk_map_meta_equal,
++>>>>>>> 134fede4eecf (bpf: Relax max_entries check for most of the inner map types)
  	.map_alloc = xsk_map_alloc,
  	.map_free = xsk_map_free,
  	.map_get_next_key = xsk_map_get_next_key,
* Unmerged path kernel/bpf/arraymap.c
diff --git a/kernel/bpf/map_in_map.c b/kernel/bpf/map_in_map.c
index 759755f96f10..87785df6c725 100644
--- a/kernel/bpf/map_in_map.c
+++ b/kernel/bpf/map_in_map.c
@@ -84,8 +84,7 @@ bool bpf_map_meta_equal(const struct bpf_map *meta0,
 	return meta0->map_type == meta1->map_type &&
 		meta0->key_size == meta1->key_size &&
 		meta0->value_size == meta1->value_size &&
-		meta0->map_flags == meta1->map_flags &&
-		meta0->max_entries == meta1->max_entries;
+		meta0->map_flags == meta1->map_flags;
 }
 
 void *bpf_map_fd_get_ptr(struct bpf_map *map,
* Unmerged path net/xdp/xskmap.c
