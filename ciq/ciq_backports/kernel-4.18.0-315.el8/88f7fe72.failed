libbpf: Support test run of raw tracepoint programs

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-315.el8
commit-author Song Liu <songliubraving@fb.com>
commit 88f7fe7233244101fa5b7786e2e298bf27fe1375
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-315.el8/88f7fe72.failed

Add bpf_prog_test_run_opts() with support of new fields in bpf_attr.test,
namely, flags and cpu. Also extend _opts operations to support outputs via
opts.

	Signed-off-by: Song Liu <songliubraving@fb.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Acked-by: Andrii Nakryiko <andriin@fb.com>
Link: https://lore.kernel.org/bpf/20200925205432.1777-3-songliubraving@fb.com
(cherry picked from commit 88f7fe7233244101fa5b7786e2e298bf27fe1375)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/lib/bpf/bpf.h
#	tools/lib/bpf/libbpf.map
diff --cc tools/lib/bpf/bpf.h
index 8e520707e745,4f3568e55527..000000000000
--- a/tools/lib/bpf/bpf.h
+++ b/tools/lib/bpf/bpf.h
@@@ -246,6 -243,40 +246,43 @@@ LIBBPF_API int bpf_task_fd_query(int pi
  enum bpf_stats_type; /* defined in up-to-date linux/bpf.h */
  LIBBPF_API int bpf_enable_stats(enum bpf_stats_type type);
  
++<<<<<<< HEAD
++=======
+ struct bpf_prog_bind_opts {
+ 	size_t sz; /* size of this struct for forward/backward compatibility */
+ 	__u32 flags;
+ };
+ #define bpf_prog_bind_opts__last_field flags
+ 
+ LIBBPF_API int bpf_prog_bind_map(int prog_fd, int map_fd,
+ 				 const struct bpf_prog_bind_opts *opts);
+ 
+ struct bpf_test_run_opts {
+ 	size_t sz; /* size of this struct for forward/backward compatibility */
+ 	const void *data_in; /* optional */
+ 	void *data_out;      /* optional */
+ 	__u32 data_size_in;
+ 	__u32 data_size_out; /* in: max length of data_out
+ 			      * out: length of data_out
+ 			      */
+ 	const void *ctx_in; /* optional */
+ 	void *ctx_out;      /* optional */
+ 	__u32 ctx_size_in;
+ 	__u32 ctx_size_out; /* in: max length of ctx_out
+ 			     * out: length of cxt_out
+ 			     */
+ 	__u32 retval;        /* out: return code of the BPF program */
+ 	int repeat;
+ 	__u32 duration;      /* out: average per repetition in ns */
+ 	__u32 flags;
+ 	__u32 cpu;
+ };
+ #define bpf_test_run_opts__last_field cpu
+ 
+ LIBBPF_API int bpf_prog_test_run_opts(int prog_fd,
+ 				      struct bpf_test_run_opts *opts);
+ 
++>>>>>>> 88f7fe723324 (libbpf: Support test run of raw tracepoint programs)
  #ifdef __cplusplus
  } /* extern "C" */
  #endif
diff --cc tools/lib/bpf/libbpf.map
index 0db77fbd2de9,0623e7a99b1e..000000000000
--- a/tools/lib/bpf/libbpf.map
+++ b/tools/lib/bpf/libbpf.map
@@@ -334,30 -302,12 +334,41 @@@ LIBBPF_0.1.0 
  
  LIBBPF_0.2.0 {
  	global:
++<<<<<<< HEAD
 +		bpf_program__attach_freplace;
 +		btf__add_array;
 +		btf__add_const;
 +		btf__add_enum;
 +		btf__add_enum_value;
 +		btf__add_datasec;
 +		btf__add_datasec_var_info;
 +		btf__add_field;
 +		btf__add_func;
 +		btf__add_func_param;
 +		btf__add_func_proto;
 +		btf__add_fwd;
 +		btf__add_int;
 +		btf__add_ptr;
 +		btf__add_restrict;
 +		btf__add_str;
 +		btf__add_struct;
 +		btf__add_typedef;
 +		btf__add_union;
 +		btf__add_var;
 +		btf__add_volatile;
 +		btf__endianness;
 +		btf__find_str;
 +		btf__new_empty;
 +		btf__set_endianness;
 +		btf__str_by_offset;
++=======
+ 		bpf_prog_bind_map;
+ 		bpf_prog_test_run_opts;
+ 		bpf_program__section_name;
+ 		perf_buffer__buffer_cnt;
+ 		perf_buffer__buffer_fd;
+ 		perf_buffer__epoll_fd;
+ 		perf_buffer__consume_buffer;
+ 		xsk_socket__create_shared;
++>>>>>>> 88f7fe723324 (libbpf: Support test run of raw tracepoint programs)
  } LIBBPF_0.1.0;
diff --git a/tools/lib/bpf/bpf.c b/tools/lib/bpf/bpf.c
index faa51231d17d..238d16049bd7 100644
--- a/tools/lib/bpf/bpf.c
+++ b/tools/lib/bpf/bpf.c
@@ -724,6 +724,37 @@ int bpf_prog_test_run_xattr(struct bpf_prog_test_run_attr *test_attr)
 	return ret;
 }
 
+int bpf_prog_test_run_opts(int prog_fd, struct bpf_test_run_opts *opts)
+{
+	union bpf_attr attr;
+	int ret;
+
+	if (!OPTS_VALID(opts, bpf_test_run_opts))
+		return -EINVAL;
+
+	memset(&attr, 0, sizeof(attr));
+	attr.test.prog_fd = prog_fd;
+	attr.test.cpu = OPTS_GET(opts, cpu, 0);
+	attr.test.flags = OPTS_GET(opts, flags, 0);
+	attr.test.repeat = OPTS_GET(opts, repeat, 0);
+	attr.test.duration = OPTS_GET(opts, duration, 0);
+	attr.test.ctx_size_in = OPTS_GET(opts, ctx_size_in, 0);
+	attr.test.ctx_size_out = OPTS_GET(opts, ctx_size_out, 0);
+	attr.test.data_size_in = OPTS_GET(opts, data_size_in, 0);
+	attr.test.data_size_out = OPTS_GET(opts, data_size_out, 0);
+	attr.test.ctx_in = ptr_to_u64(OPTS_GET(opts, ctx_in, NULL));
+	attr.test.ctx_out = ptr_to_u64(OPTS_GET(opts, ctx_out, NULL));
+	attr.test.data_in = ptr_to_u64(OPTS_GET(opts, data_in, NULL));
+	attr.test.data_out = ptr_to_u64(OPTS_GET(opts, data_out, NULL));
+
+	ret = sys_bpf(BPF_PROG_TEST_RUN, &attr, sizeof(attr));
+	OPTS_SET(opts, data_size_out, attr.test.data_size_out);
+	OPTS_SET(opts, ctx_size_out, attr.test.ctx_size_out);
+	OPTS_SET(opts, duration, attr.test.duration);
+	OPTS_SET(opts, retval, attr.test.retval);
+	return ret;
+}
+
 static int bpf_obj_get_next_id(__u32 start_id, __u32 *next_id, int cmd)
 {
 	union bpf_attr attr;
* Unmerged path tools/lib/bpf/bpf.h
* Unmerged path tools/lib/bpf/libbpf.map
diff --git a/tools/lib/bpf/libbpf_internal.h b/tools/lib/bpf/libbpf_internal.h
index c035963fa925..03dfecd01e07 100644
--- a/tools/lib/bpf/libbpf_internal.h
+++ b/tools/lib/bpf/libbpf_internal.h
@@ -139,6 +139,11 @@ static inline bool libbpf_validate_opts(const char *opts,
 	((opts) && opts->sz >= offsetofend(typeof(*(opts)), field))
 #define OPTS_GET(opts, field, fallback_value) \
 	(OPTS_HAS(opts, field) ? (opts)->field : fallback_value)
+#define OPTS_SET(opts, field, value)		\
+	do {					\
+		if (OPTS_HAS(opts, field))	\
+			(opts)->field = value;	\
+	} while (0)
 
 int parse_cpu_mask_str(const char *s, bool **mask, int *mask_sz);
 int parse_cpu_mask_file(const char *fcpu, bool **mask, int *mask_sz);
