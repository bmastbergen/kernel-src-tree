mt76: flush tx status queue on DMA reset

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-315.el8
commit-author Felix Fietkau <nbd@nbd.name>
commit 6929d1d747b3934df3b0b2bb8af31b3f1f539ae4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-315.el8/6929d1d7.failed

After DMA reset, tx status information for queued frames will never arrive.
Flush the queue to free skbs immediately instead of waiting for a timeout

	Signed-off-by: Felix Fietkau <nbd@nbd.name>
(cherry picked from commit 6929d1d747b3934df3b0b2bb8af31b3f1f539ae4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/wireless/mediatek/mt76/mt7615/pci_mac.c
#	drivers/net/wireless/mediatek/mt76/mt7921/mac.c
diff --cc drivers/net/wireless/mediatek/mt76/mt7615/pci_mac.c
index 4cf7c5d34325,8cd79e849045..000000000000
--- a/drivers/net/wireless/mediatek/mt76/mt7615/pci_mac.c
+++ b/drivers/net/wireless/mediatek/mt76/mt7615/pci_mac.c
@@@ -181,3 -181,173 +181,176 @@@ int mt7615_tx_prepare_skb(struct mt76_d
  
  	return 0;
  }
++<<<<<<< HEAD
++=======
+ 
+ void mt7615_dma_reset(struct mt7615_dev *dev)
+ {
+ 	int i;
+ 
+ 	mt76_clear(dev, MT_WPDMA_GLO_CFG,
+ 		   MT_WPDMA_GLO_CFG_RX_DMA_EN | MT_WPDMA_GLO_CFG_TX_DMA_EN |
+ 		   MT_WPDMA_GLO_CFG_TX_WRITEBACK_DONE);
+ 
+ 	usleep_range(1000, 2000);
+ 
+ 	for (i = 0; i < __MT_TXQ_MAX; i++)
+ 		mt76_queue_tx_cleanup(dev, dev->mphy.q_tx[i], true);
+ 
+ 	for (i = 0; i < __MT_MCUQ_MAX; i++)
+ 		mt76_queue_tx_cleanup(dev, dev->mt76.q_mcu[i], true);
+ 
+ 	mt76_for_each_q_rx(&dev->mt76, i)
+ 		mt76_queue_rx_reset(dev, i);
+ 
+ 	mt76_tx_status_check(&dev->mt76, NULL, true);
+ 
+ 	mt7615_dma_start(dev);
+ }
+ EXPORT_SYMBOL_GPL(mt7615_dma_reset);
+ 
+ static void
+ mt7615_hif_int_event_trigger(struct mt7615_dev *dev, u8 event)
+ {
+ 	mt76_wr(dev, MT_MCU_INT_EVENT, event);
+ 
+ 	mt7622_trigger_hif_int(dev, true);
+ 	mt7622_trigger_hif_int(dev, false);
+ }
+ 
+ static bool
+ mt7615_wait_reset_state(struct mt7615_dev *dev, u32 state)
+ {
+ 	bool ret;
+ 
+ 	ret = wait_event_timeout(dev->reset_wait,
+ 				 (READ_ONCE(dev->reset_state) & state),
+ 				 MT7615_RESET_TIMEOUT);
+ 	WARN(!ret, "Timeout waiting for MCU reset state %x\n", state);
+ 	return ret;
+ }
+ 
+ static void
+ mt7615_update_vif_beacon(void *priv, u8 *mac, struct ieee80211_vif *vif)
+ {
+ 	struct ieee80211_hw *hw = priv;
+ 	struct mt7615_dev *dev = mt7615_hw_dev(hw);
+ 
+ 	switch (vif->type) {
+ 	case NL80211_IFTYPE_MESH_POINT:
+ 	case NL80211_IFTYPE_ADHOC:
+ 	case NL80211_IFTYPE_AP:
+ 		mt7615_mcu_add_beacon(dev, hw, vif,
+ 				      vif->bss_conf.enable_beacon);
+ 		break;
+ 	default:
+ 		break;
+ 	}
+ }
+ 
+ static void
+ mt7615_update_beacons(struct mt7615_dev *dev)
+ {
+ 	ieee80211_iterate_active_interfaces(dev->mt76.hw,
+ 		IEEE80211_IFACE_ITER_RESUME_ALL,
+ 		mt7615_update_vif_beacon, dev->mt76.hw);
+ 
+ 	if (!dev->mt76.phy2)
+ 		return;
+ 
+ 	ieee80211_iterate_active_interfaces(dev->mt76.phy2->hw,
+ 		IEEE80211_IFACE_ITER_RESUME_ALL,
+ 		mt7615_update_vif_beacon, dev->mt76.phy2->hw);
+ }
+ 
+ void mt7615_mac_reset_work(struct work_struct *work)
+ {
+ 	struct mt7615_phy *phy2;
+ 	struct mt76_phy *ext_phy;
+ 	struct mt7615_dev *dev;
+ 
+ 	dev = container_of(work, struct mt7615_dev, reset_work);
+ 	ext_phy = dev->mt76.phy2;
+ 	phy2 = ext_phy ? ext_phy->priv : NULL;
+ 
+ 	if (!(READ_ONCE(dev->reset_state) & MT_MCU_CMD_STOP_PDMA))
+ 		return;
+ 
+ 	ieee80211_stop_queues(mt76_hw(dev));
+ 	if (ext_phy)
+ 		ieee80211_stop_queues(ext_phy->hw);
+ 
+ 	set_bit(MT76_RESET, &dev->mphy.state);
+ 	set_bit(MT76_MCU_RESET, &dev->mphy.state);
+ 	wake_up(&dev->mt76.mcu.wait);
+ 	cancel_delayed_work_sync(&dev->mphy.mac_work);
+ 	del_timer_sync(&dev->phy.roc_timer);
+ 	cancel_work_sync(&dev->phy.roc_work);
+ 	if (phy2) {
+ 		set_bit(MT76_RESET, &phy2->mt76->state);
+ 		cancel_delayed_work_sync(&phy2->mt76->mac_work);
+ 		del_timer_sync(&phy2->roc_timer);
+ 		cancel_work_sync(&phy2->roc_work);
+ 	}
+ 
+ 	/* lock/unlock all queues to ensure that no tx is pending */
+ 	mt76_txq_schedule_all(&dev->mphy);
+ 	if (ext_phy)
+ 		mt76_txq_schedule_all(ext_phy);
+ 
+ 	mt76_worker_disable(&dev->mt76.tx_worker);
+ 	napi_disable(&dev->mt76.napi[0]);
+ 	napi_disable(&dev->mt76.napi[1]);
+ 	napi_disable(&dev->mt76.tx_napi);
+ 
+ 	mt7615_mutex_acquire(dev);
+ 
+ 	mt7615_hif_int_event_trigger(dev, MT_MCU_INT_EVENT_PDMA_STOPPED);
+ 
+ 	if (mt7615_wait_reset_state(dev, MT_MCU_CMD_RESET_DONE)) {
+ 		mt7615_dma_reset(dev);
+ 
+ 		mt7615_tx_token_put(dev);
+ 		idr_init(&dev->token);
+ 
+ 		mt76_wr(dev, MT_WPDMA_MEM_RNG_ERR, 0);
+ 
+ 		mt7615_hif_int_event_trigger(dev, MT_MCU_INT_EVENT_PDMA_INIT);
+ 		mt7615_wait_reset_state(dev, MT_MCU_CMD_RECOVERY_DONE);
+ 	}
+ 
+ 	clear_bit(MT76_MCU_RESET, &dev->mphy.state);
+ 	clear_bit(MT76_RESET, &dev->mphy.state);
+ 	if (phy2)
+ 		clear_bit(MT76_RESET, &phy2->mt76->state);
+ 
+ 	mt76_worker_enable(&dev->mt76.tx_worker);
+ 	napi_enable(&dev->mt76.tx_napi);
+ 	napi_schedule(&dev->mt76.tx_napi);
+ 
+ 	napi_enable(&dev->mt76.napi[0]);
+ 	napi_schedule(&dev->mt76.napi[0]);
+ 
+ 	napi_enable(&dev->mt76.napi[1]);
+ 	napi_schedule(&dev->mt76.napi[1]);
+ 
+ 	ieee80211_wake_queues(mt76_hw(dev));
+ 	if (ext_phy)
+ 		ieee80211_wake_queues(ext_phy->hw);
+ 
+ 	mt7615_hif_int_event_trigger(dev, MT_MCU_INT_EVENT_RESET_DONE);
+ 	mt7615_wait_reset_state(dev, MT_MCU_CMD_NORMAL_STATE);
+ 
+ 	mt7615_update_beacons(dev);
+ 
+ 	mt7615_mutex_release(dev);
+ 
+ 	ieee80211_queue_delayed_work(mt76_hw(dev), &dev->mphy.mac_work,
+ 				     MT7615_WATCHDOG_TIME);
+ 	if (phy2)
+ 		ieee80211_queue_delayed_work(ext_phy->hw,
+ 					     &phy2->mt76->mac_work,
+ 					     MT7615_WATCHDOG_TIME);
+ 
+ }
++>>>>>>> 6929d1d747b3 (mt76: flush tx status queue on DMA reset)
diff --cc drivers/net/wireless/mediatek/mt76/mt7921/mac.c
index bcbd59a23f9b,572bab82315a..000000000000
--- a/drivers/net/wireless/mediatek/mt76/mt7921/mac.c
+++ b/drivers/net/wireless/mediatek/mt76/mt7921/mac.c
@@@ -1178,29 -1221,67 +1178,38 @@@ mt7921_wait_reset_state(struct mt7921_d
  }
  
  static void
 -mt7921_dma_reset(struct mt7921_dev *dev)
 +mt7921_dma_reset(struct mt7921_phy *phy)
  {
 +	struct mt7921_dev *dev = phy->dev;
  	int i;
  
 -	/* reset */
 -	mt76_clear(dev, MT_WFDMA0_RST,
 -		   MT_WFDMA0_RST_DMASHDL_ALL_RST | MT_WFDMA0_RST_LOGIC_RST);
 -
 -	mt76_set(dev, MT_WFDMA0_RST,
 -		 MT_WFDMA0_RST_DMASHDL_ALL_RST | MT_WFDMA0_RST_LOGIC_RST);
 -
 -	/* disable WFDMA0 */
  	mt76_clear(dev, MT_WFDMA0_GLO_CFG,
 -		   MT_WFDMA0_GLO_CFG_TX_DMA_EN | MT_WFDMA0_GLO_CFG_RX_DMA_EN |
 -		   MT_WFDMA0_GLO_CFG_CSR_DISP_BASE_PTR_CHAIN_EN |
 -		   MT_WFDMA0_GLO_CFG_OMIT_TX_INFO |
 -		   MT_WFDMA0_GLO_CFG_OMIT_RX_INFO |
 -		   MT_WFDMA0_GLO_CFG_OMIT_RX_INFO_PFET2);
 +		   MT_WFDMA0_GLO_CFG_TX_DMA_EN | MT_WFDMA0_GLO_CFG_RX_DMA_EN);
  
 -	mt76_poll(dev, MT_WFDMA0_GLO_CFG,
 -		  MT_WFDMA0_GLO_CFG_TX_DMA_BUSY |
 -		  MT_WFDMA0_GLO_CFG_RX_DMA_BUSY, 0, 1000);
 +	usleep_range(1000, 2000);
  
 -	/* reset hw queues */
 +	mt76_queue_tx_cleanup(dev, dev->mt76.q_mcu[MT_MCUQ_WA], true);
  	for (i = 0; i < __MT_TXQ_MAX; i++)
 -		mt76_queue_reset(dev, dev->mphy.q_tx[i]);
 +		mt76_queue_tx_cleanup(dev, phy->mt76->q_tx[i], true);
  
 -	for (i = 0; i < __MT_MCUQ_MAX; i++)
 -		mt76_queue_reset(dev, dev->mt76.q_mcu[i]);
 +	mt76_for_each_q_rx(&dev->mt76, i) {
 +		mt76_queue_rx_reset(dev, i);
 +	}
  
++<<<<<<< HEAD
 +	/* re-init prefetch settings after reset */
++=======
+ 	mt76_for_each_q_rx(&dev->mt76, i)
+ 		mt76_queue_reset(dev, &dev->mt76.q_rx[i]);
+ 
+ 	mt76_tx_status_check(&dev->mt76, NULL, true);
+ 
+ 	/* configure perfetch settings */
++>>>>>>> 6929d1d747b3 (mt76: flush tx status queue on DMA reset)
  	mt7921_dma_prefetch(dev);
  
 -	/* reset dma idx */
 -	mt76_wr(dev, MT_WFDMA0_RST_DTX_PTR, ~0);
 -
 -	/* configure delay interrupt */
 -	mt76_wr(dev, MT_WFDMA0_PRI_DLY_INT_CFG0, 0);
 -
 -	mt76_set(dev, MT_WFDMA0_GLO_CFG,
 -		 MT_WFDMA0_GLO_CFG_TX_WB_DDONE |
 -		 MT_WFDMA0_GLO_CFG_FIFO_LITTLE_ENDIAN |
 -		 MT_WFDMA0_GLO_CFG_CLK_GAT_DIS |
 -		 MT_WFDMA0_GLO_CFG_OMIT_TX_INFO |
 -		 MT_WFDMA0_GLO_CFG_CSR_DISP_BASE_PTR_CHAIN_EN |
 -		 MT_WFDMA0_GLO_CFG_OMIT_RX_INFO_PFET2);
 -
  	mt76_set(dev, MT_WFDMA0_GLO_CFG,
  		 MT_WFDMA0_GLO_CFG_TX_DMA_EN | MT_WFDMA0_GLO_CFG_RX_DMA_EN);
 -
 -	mt76_set(dev, MT_WFDMA_DUMMY_CR, MT_WFDMA_NEED_REINIT);
 -
 -	/* enable interrupts for TX/RX rings */
 -	mt7921_irq_enable(dev,
 -			  MT_INT_RX_DONE_ALL | MT_INT_TX_DONE_ALL |
 -			  MT_INT_MCU_CMD);
  }
  
  void mt7921_tx_token_put(struct mt7921_dev *dev)
diff --git a/drivers/net/wireless/mediatek/mt76/mt7603/mac.c b/drivers/net/wireless/mediatek/mt76/mt7603/mac.c
index d0066e98a766..6da14b1f8d13 100644
--- a/drivers/net/wireless/mediatek/mt76/mt7603/mac.c
+++ b/drivers/net/wireless/mediatek/mt76/mt7603/mac.c
@@ -1442,6 +1442,8 @@ static void mt7603_mac_watchdog_reset(struct mt7603_dev *dev)
 		mt76_queue_rx_reset(dev, i);
 	}
 
+	mt76_tx_status_check(&dev->mt76, NULL, true);
+
 	mt7603_dma_sched_reset(dev);
 
 	mt7603_mac_dma_start(dev);
* Unmerged path drivers/net/wireless/mediatek/mt76/mt7615/pci_mac.c
diff --git a/drivers/net/wireless/mediatek/mt76/mt76x02_mmio.c b/drivers/net/wireless/mediatek/mt76/mt76x02_mmio.c
index 1caa9f703491..8d1caed626a7 100644
--- a/drivers/net/wireless/mediatek/mt76/mt76x02_mmio.c
+++ b/drivers/net/wireless/mediatek/mt76/mt76x02_mmio.c
@@ -473,6 +473,8 @@ static void mt76x02_watchdog_reset(struct mt76x02_dev *dev)
 		mt76_queue_rx_reset(dev, i);
 	}
 
+	mt76_tx_status_check(&dev->mt76, NULL, true);
+
 	mt76x02_mac_start(dev);
 
 	if (dev->ed_monitor)
diff --git a/drivers/net/wireless/mediatek/mt76/mt7915/mac.c b/drivers/net/wireless/mediatek/mt76/mt7915/mac.c
index 44bdff82d4d2..0810fad434d6 100644
--- a/drivers/net/wireless/mediatek/mt76/mt7915/mac.c
+++ b/drivers/net/wireless/mediatek/mt76/mt7915/mac.c
@@ -1478,6 +1478,8 @@ mt7915_dma_reset(struct mt7915_dev *dev)
 		mt76_queue_rx_reset(dev, i);
 	}
 
+	mt76_tx_status_check(&dev->mt76, NULL, true);
+
 	/* re-init prefetch settings after reset */
 	mt7915_dma_prefetch(dev);
 
* Unmerged path drivers/net/wireless/mediatek/mt76/mt7921/mac.c
