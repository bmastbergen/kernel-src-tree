x86/kvm: Unify kvm_pv_guest_cpu_reboot() with kvm_guest_cpu_offline()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-315.el8
commit-author Vitaly Kuznetsov <vkuznets@redhat.com>
commit 384fc672f528d3b84eacd9a86ecf35df3363b8ba
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-315.el8/384fc672.failed

Simplify the code by making PV features shutdown happen in one place.

	Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
Message-Id: <20210414123544.1060604-6-vkuznets@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 384fc672f528d3b84eacd9a86ecf35df3363b8ba)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/kvm.c
diff --cc arch/x86/kernel/kvm.c
index 1a02ea5c1ffd,a26643dc6bd6..000000000000
--- a/arch/x86/kernel/kvm.c
+++ b/arch/x86/kernel/kvm.c
@@@ -383,31 -376,14 +383,42 @@@ static void kvm_pv_disable_apf(void
  	pr_info("disable async PF for cpu %d\n", smp_processor_id());
  }
  
++<<<<<<< HEAD
 +static void kvm_pv_guest_cpu_reboot(void *unused)
 +{
 +	/*
 +	 * We disable PV EOI before we load a new kernel by kexec,
 +	 * since MSR_KVM_PV_EOI_EN stores a pointer into old kernel's memory.
 +	 * New kernel can re-enable when it boots.
 +	 */
 +	if (kvm_para_has_feature(KVM_FEATURE_PV_EOI))
 +		wrmsrl(MSR_KVM_PV_EOI_EN, 0);
 +	kvm_pv_disable_apf();
 +	kvm_disable_steal_time();
 +}
 +
 +static int kvm_pv_reboot_notify(struct notifier_block *nb,
 +				unsigned long code, void *unused)
 +{
 +	if (code == SYS_RESTART)
 +		on_each_cpu(kvm_pv_guest_cpu_reboot, NULL, 1);
 +	return NOTIFY_DONE;
 +}
 +
 +static struct notifier_block kvm_pv_reboot_nb = {
 +	.notifier_call = kvm_pv_reboot_notify,
 +};
 +
++=======
+ static void kvm_disable_steal_time(void)
+ {
+ 	if (!has_steal_clock)
+ 		return;
+ 
+ 	wrmsr(MSR_KVM_STEAL_TIME, 0, 0);
+ }
+ 
++>>>>>>> 384fc672f528 (x86/kvm: Unify kvm_pv_guest_cpu_reboot() with kvm_guest_cpu_offline())
  static u64 kvm_steal_clock(int cpu)
  {
  	u64 steal;
@@@ -613,41 -643,56 +624,85 @@@ static int kvm_cpu_online(unsigned int 
  	return 0;
  }
  
 +static int kvm_cpu_down_prepare(unsigned int cpu)
 +{
 +	local_irq_disable();
 +	kvm_guest_cpu_offline();
 +	local_irq_enable();
 +	return 0;
 +}
  #endif
  
 -static int kvm_suspend(void)
 +static void kvm_flush_tlb_others(const struct cpumask *cpumask,
 +			const struct flush_tlb_info *info)
  {
 -	kvm_guest_cpu_offline(false);
 +	u8 state;
 +	int cpu;
 +	struct kvm_steal_time *src;
 +	struct cpumask *flushmask = this_cpu_cpumask_var_ptr(__pv_cpu_mask);
  
 -	return 0;
 +	cpumask_copy(flushmask, cpumask);
 +	/*
 +	 * We have to call flush only on online vCPUs. And
 +	 * queue flush_on_enter for pre-empted vCPUs
 +	 */
 +	for_each_cpu(cpu, flushmask) {
 +		src = &per_cpu(steal_time, cpu);
 +		state = READ_ONCE(src->preempted);
 +		if ((state & KVM_VCPU_PREEMPTED)) {
 +			if (try_cmpxchg(&src->preempted, &state,
 +					state | KVM_VCPU_FLUSH_TLB))
 +				__cpumask_clear_cpu(cpu, flushmask);
 +		}
 +	}
 +
 +	native_flush_tlb_others(flushmask, info);
  }
  
++<<<<<<< HEAD
++=======
+ static void kvm_resume(void)
+ {
+ 	kvm_cpu_online(raw_smp_processor_id());
+ }
+ 
+ static struct syscore_ops kvm_syscore_ops = {
+ 	.suspend	= kvm_suspend,
+ 	.resume		= kvm_resume,
+ };
+ 
+ static void kvm_pv_guest_cpu_reboot(void *unused)
+ {
+ 	kvm_guest_cpu_offline(true);
+ }
+ 
+ static int kvm_pv_reboot_notify(struct notifier_block *nb,
+ 				unsigned long code, void *unused)
+ {
+ 	if (code == SYS_RESTART)
+ 		on_each_cpu(kvm_pv_guest_cpu_reboot, NULL, 1);
+ 	return NOTIFY_DONE;
+ }
+ 
+ static struct notifier_block kvm_pv_reboot_nb = {
+ 	.notifier_call = kvm_pv_reboot_notify,
+ };
+ 
+ /*
+  * After a PV feature is registered, the host will keep writing to the
+  * registered memory location. If the guest happens to shutdown, this memory
+  * won't be valid. In cases like kexec, in which you install a new kernel, this
+  * means a random memory location will be kept being written.
+  */
+ #ifdef CONFIG_KEXEC_CORE
+ static void kvm_crash_shutdown(struct pt_regs *regs)
+ {
+ 	kvm_guest_cpu_offline(true);
+ 	native_machine_crash_shutdown(regs);
+ }
+ #endif
+ 
++>>>>>>> 384fc672f528 (x86/kvm: Unify kvm_pv_guest_cpu_reboot() with kvm_guest_cpu_offline())
  static void __init kvm_guest_init(void)
  {
  	int i;
* Unmerged path arch/x86/kernel/kvm.c
