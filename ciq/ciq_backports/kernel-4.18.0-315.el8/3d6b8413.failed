x86/kvm: Disable all PV features on crash

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-315.el8
commit-author Vitaly Kuznetsov <vkuznets@redhat.com>
commit 3d6b84132d2a57b5a74100f6923a8feb679ac2ce
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-315.el8/3d6b8413.failed

Crash shutdown handler only disables kvmclock and steal time, other PV
features remain active so we risk corrupting memory or getting some
side-effects in kdump kernel. Move crash handler to kvm.c and unify
with CPU offline.

	Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
Message-Id: <20210414123544.1060604-5-vkuznets@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 3d6b84132d2a57b5a74100f6923a8feb679ac2ce)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/kvm_para.h
#	arch/x86/kernel/kvm.c
#	arch/x86/kernel/kvmclock.c
diff --cc arch/x86/include/asm/kvm_para.h
index 27ceb6b49287,69299878b200..000000000000
--- a/arch/x86/include/asm/kvm_para.h
+++ b/arch/x86/include/asm/kvm_para.h
@@@ -143,12 -136,7 +142,16 @@@ static inline u32 kvm_read_and_reset_ap
  	return 0;
  }
  
++<<<<<<< HEAD
 +static inline void kvm_disable_steal_time(void)
 +{
 +	return;
 +}
 +
 +static inline bool kvm_handle_async_pf(struct pt_regs *regs, u32 token)
++=======
+ static __always_inline bool kvm_handle_async_pf(struct pt_regs *regs, u32 token)
++>>>>>>> 3d6b84132d2a (x86/kvm: Disable all PV features on crash)
  {
  	return false;
  }
diff --cc arch/x86/kernel/kvm.c
index 1a02ea5c1ffd,8eb91dc0f5a8..000000000000
--- a/arch/x86/kernel/kvm.c
+++ b/arch/x86/kernel/kvm.c
@@@ -460,6 -453,31 +461,34 @@@ static void __init sev_map_percpu_data(
  	}
  }
  
++<<<<<<< HEAD
++=======
+ static void kvm_guest_cpu_offline(bool shutdown)
+ {
+ 	kvm_disable_steal_time();
+ 	if (kvm_para_has_feature(KVM_FEATURE_PV_EOI))
+ 		wrmsrl(MSR_KVM_PV_EOI_EN, 0);
+ 	kvm_pv_disable_apf();
+ 	if (!shutdown)
+ 		apf_task_wake_all();
+ 	kvmclock_disable();
+ }
+ 
+ static int kvm_cpu_online(unsigned int cpu)
+ {
+ 	unsigned long flags;
+ 
+ 	local_irq_save(flags);
+ 	kvm_guest_cpu_init();
+ 	local_irq_restore(flags);
+ 	return 0;
+ }
+ 
+ #ifdef CONFIG_SMP
+ 
+ static DEFINE_PER_CPU(cpumask_var_t, __pv_cpu_mask);
+ 
++>>>>>>> 3d6b84132d2a (x86/kvm: Disable all PV features on crash)
  static bool pv_tlb_flush_supported(void)
  {
  	return (kvm_para_has_feature(KVM_FEATURE_PV_TLB_FLUSH) &&
@@@ -596,58 -658,49 +625,97 @@@ static void __init kvm_smp_prepare_boot
  	kvm_spinlock_init();
  }
  
 +static void kvm_guest_cpu_offline(void)
 +{
 +	kvm_disable_steal_time();
 +	if (kvm_para_has_feature(KVM_FEATURE_PV_EOI))
 +		wrmsrl(MSR_KVM_PV_EOI_EN, 0);
 +	kvm_pv_disable_apf();
 +	apf_task_wake_all();
 +}
 +
 +static int kvm_cpu_online(unsigned int cpu)
 +{
 +	local_irq_disable();
 +	kvm_guest_cpu_init();
 +	local_irq_enable();
 +	return 0;
 +}
 +
  static int kvm_cpu_down_prepare(unsigned int cpu)
  {
++<<<<<<< HEAD
 +	local_irq_disable();
 +	kvm_guest_cpu_offline();
 +	local_irq_enable();
++=======
+ 	unsigned long flags;
+ 
+ 	local_irq_save(flags);
+ 	kvm_guest_cpu_offline(false);
+ 	local_irq_restore(flags);
++>>>>>>> 3d6b84132d2a (x86/kvm: Disable all PV features on crash)
  	return 0;
  }
 -
  #endif
  
 -static int kvm_suspend(void)
 +static void kvm_flush_tlb_others(const struct cpumask *cpumask,
 +			const struct flush_tlb_info *info)
  {
++<<<<<<< HEAD
 +	u8 state;
 +	int cpu;
 +	struct kvm_steal_time *src;
 +	struct cpumask *flushmask = this_cpu_cpumask_var_ptr(__pv_cpu_mask);
++=======
+ 	kvm_guest_cpu_offline(false);
++>>>>>>> 3d6b84132d2a (x86/kvm: Disable all PV features on crash)
  
 -	return 0;
 +	cpumask_copy(flushmask, cpumask);
 +	/*
 +	 * We have to call flush only on online vCPUs. And
 +	 * queue flush_on_enter for pre-empted vCPUs
 +	 */
 +	for_each_cpu(cpu, flushmask) {
 +		src = &per_cpu(steal_time, cpu);
 +		state = READ_ONCE(src->preempted);
 +		if ((state & KVM_VCPU_PREEMPTED)) {
 +			if (try_cmpxchg(&src->preempted, &state,
 +					state | KVM_VCPU_FLUSH_TLB))
 +				__cpumask_clear_cpu(cpu, flushmask);
 +		}
 +	}
 +
 +	native_flush_tlb_others(flushmask, info);
  }
  
++<<<<<<< HEAD
++=======
+ static void kvm_resume(void)
+ {
+ 	kvm_cpu_online(raw_smp_processor_id());
+ }
+ 
+ static struct syscore_ops kvm_syscore_ops = {
+ 	.suspend	= kvm_suspend,
+ 	.resume		= kvm_resume,
+ };
+ 
+ /*
+  * After a PV feature is registered, the host will keep writing to the
+  * registered memory location. If the guest happens to shutdown, this memory
+  * won't be valid. In cases like kexec, in which you install a new kernel, this
+  * means a random memory location will be kept being written.
+  */
+ #ifdef CONFIG_KEXEC_CORE
+ static void kvm_crash_shutdown(struct pt_regs *regs)
+ {
+ 	kvm_guest_cpu_offline(true);
+ 	native_machine_crash_shutdown(regs);
+ }
+ #endif
+ 
++>>>>>>> 3d6b84132d2a (x86/kvm: Disable all PV features on crash)
  static void __init kvm_guest_init(void)
  {
  	int i;
@@@ -690,6 -743,12 +758,15 @@@
  	kvm_guest_cpu_init();
  #endif
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_KEXEC_CORE
+ 	machine_ops.crash_shutdown = kvm_crash_shutdown;
+ #endif
+ 
+ 	register_syscore_ops(&kvm_syscore_ops);
+ 
++>>>>>>> 3d6b84132d2a (x86/kvm: Disable all PV features on crash)
  	/*
  	 * Hard lockup detection is enabled by default. Disable it, as guests
  	 * can get false positives too easily, for example if the host is
diff --cc arch/x86/kernel/kvmclock.c
index 426e1df11b40,ad273e5861c1..000000000000
--- a/arch/x86/kernel/kvmclock.c
+++ b/arch/x86/kernel/kvmclock.c
@@@ -203,28 -202,9 +202,32 @@@ static void kvm_setup_secondary_clock(v
  }
  #endif
  
++<<<<<<< HEAD
 +/*
 + * After the clock is registered, the host will keep writing to the
 + * registered memory location. If the guest happens to shutdown, this memory
 + * won't be valid. In cases like kexec, in which you install a new kernel, this
 + * means a random memory location will be kept being written. So before any
 + * kind of shutdown from our side, we unregister the clock by writing anything
 + * that does not have the 'enable' bit set in the msr
 + */
 +#ifdef CONFIG_KEXEC_CORE
 +static void kvm_crash_shutdown(struct pt_regs *regs)
 +{
 +	native_write_msr(msr_kvm_system_time, 0, 0);
 +	kvm_disable_steal_time();
 +	native_machine_crash_shutdown(regs);
 +}
 +#endif
 +
 +static void kvm_shutdown(void)
++=======
+ void kvmclock_disable(void)
++>>>>>>> 3d6b84132d2a (x86/kvm: Disable all PV features on crash)
  {
  	native_write_msr(msr_kvm_system_time, 0, 0);
 +	kvm_disable_steal_time();
 +	native_machine_shutdown();
  }
  
  static void __init kvmclock_init_mem(void)
@@@ -351,10 -331,6 +354,13 @@@ void __init kvmclock_init(void
  #endif
  	x86_platform.save_sched_clock_state = kvm_save_sched_clock_state;
  	x86_platform.restore_sched_clock_state = kvm_restore_sched_clock_state;
++<<<<<<< HEAD
 +	machine_ops.shutdown  = kvm_shutdown;
 +#ifdef CONFIG_KEXEC_CORE
 +	machine_ops.crash_shutdown  = kvm_crash_shutdown;
 +#endif
++=======
++>>>>>>> 3d6b84132d2a (x86/kvm: Disable all PV features on crash)
  	kvm_get_preset_lpj();
  
  	/*
* Unmerged path arch/x86/include/asm/kvm_para.h
* Unmerged path arch/x86/kernel/kvm.c
* Unmerged path arch/x86/kernel/kvmclock.c
