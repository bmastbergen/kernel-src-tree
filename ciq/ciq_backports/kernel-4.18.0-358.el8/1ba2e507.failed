nvme-tcp: Do not reset transport on data digest errors

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Daniel Wagner <dwagner@suse.de>
commit 1ba2e507f55c5b0cbde8c0fbfe0d9e39612a3e52
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/1ba2e507.failed

The spec says

  7.4.6.1 Digest Error handling

  When a host detects a data digest error in a C2HData PDU, that host
  shall continue processing C2HData PDUs associated with the command and
  when the command processing has completed, if a successful status was
  returned by the controller, the host shall fail the command with a
  non-fatal transport error.

Currently the transport is reseted when a data digest error is
detected. Instead, when a digest error is detected, mark the final
status as NVME_SC_DATA_XFER_ERROR and let the upper layer handle
the error.

In order to keep track of the final result maintain a status field in
nvme_tcp_request object and use it to overwrite the completion queue
status (which might be successful even though a digest error has been
detected) when completing the request.

	Signed-off-by: Daniel Wagner <dwagner@suse.de>
	Reviewed-by: Sagi Grimberg <sagi@grimberg.me>
	Reviewed-by: Hannes Reinecke <hare@suse.de>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
(cherry picked from commit 1ba2e507f55c5b0cbde8c0fbfe0d9e39612a3e52)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/tcp.c
diff --cc drivers/nvme/host/tcp.c
index 7a4d12c0af20,e2ab12f3f51c..000000000000
--- a/drivers/nvme/host/tcp.c
+++ b/drivers/nvme/host/tcp.c
@@@ -477,18 -486,23 +478,27 @@@ static void nvme_tcp_error_recovery(str
  static int nvme_tcp_process_nvme_cqe(struct nvme_tcp_queue *queue,
  		struct nvme_completion *cqe)
  {
+ 	struct nvme_tcp_request *req;
  	struct request *rq;
  
 -	rq = nvme_find_rq(nvme_tcp_tagset(queue), cqe->command_id);
 +	rq = blk_mq_tag_to_rq(nvme_tcp_tagset(queue), cqe->command_id);
  	if (!rq) {
  		dev_err(queue->ctrl->ctrl.device,
 -			"got bad cqe.command_id %#x on queue %d\n",
 -			cqe->command_id, nvme_tcp_queue_id(queue));
 +			"queue %d tag 0x%x not found\n",
 +			nvme_tcp_queue_id(queue), cqe->command_id);
  		nvme_tcp_error_recovery(&queue->ctrl->ctrl);
  		return -EINVAL;
  	}
  
++<<<<<<< HEAD
 +	if (!nvme_end_request(rq, cqe->status, cqe->result))
++=======
+ 	req = blk_mq_rq_to_pdu(rq);
+ 	if (req->status == cpu_to_le16(NVME_SC_SUCCESS))
+ 		req->status = cqe->status;
+ 
+ 	if (!nvme_try_complete_req(rq, req->status, cqe->result))
++>>>>>>> 1ba2e507f55c (nvme-tcp: Do not reset transport on data digest errors)
  		nvme_complete_rq(rq);
  	queue->nr_cqe++;
  
@@@ -787,11 -808,11 +804,16 @@@ static int nvme_tcp_recv_ddgst(struct n
  	}
  
  	if (pdu->hdr.flags & NVME_TCP_F_DATA_SUCCESS) {
++<<<<<<< HEAD
 +		struct request *rq = blk_mq_tag_to_rq(nvme_tcp_tagset(queue),
 +						pdu->command_id);
++=======
+ 		struct request *rq = nvme_cid_to_rq(nvme_tcp_tagset(queue),
+ 					pdu->command_id);
+ 		struct nvme_tcp_request *req = blk_mq_rq_to_pdu(rq);
++>>>>>>> 1ba2e507f55c (nvme-tcp: Do not reset transport on data digest errors)
  
- 		nvme_tcp_end_request(rq, NVME_SC_SUCCESS);
+ 		nvme_tcp_end_request(rq, le16_to_cpu(req->status));
  		queue->nr_cqe++;
  	}
  
* Unmerged path drivers/nvme/host/tcp.c
