locking/rtmutex: Use rt_mutex_wake_q_head

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 7980aa397cc0968ea3ffee7a985c31c92ad84f81
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/7980aa39.failed

Prepare for the required state aware handling of waiter wakeups via wake_q
and switch the rtmutex code over to the rtmutex specific wrapper.

No functional change.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
Link: https://lore.kernel.org/r/20210815211303.197113263@linutronix.de
(cherry picked from commit 7980aa397cc0968ea3ffee7a985c31c92ad84f81)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/locking/rtmutex.c
#	kernel/locking/rtmutex_api.c
#	kernel/locking/rtmutex_common.h
diff --cc kernel/locking/rtmutex.c
index 7ac7ffd805d7,5f0d0725ca32..000000000000
--- a/kernel/locking/rtmutex.c
+++ b/kernel/locking/rtmutex.c
@@@ -1016,8 -1017,8 +1016,13 @@@ static int __sched task_blocks_on_rt_mu
   *
   * Called with lock->wait_lock held and interrupts disabled.
   */
++<<<<<<< HEAD
 +static void __sched mark_wakeup_next_waiter(struct wake_q_head *wake_q,
 +					    struct rt_mutex *lock)
++=======
+ static void __sched mark_wakeup_next_waiter(struct rt_wake_q_head *wqh,
+ 					    struct rt_mutex_base *lock)
++>>>>>>> 7980aa397cc0 (locking/rtmutex: Use rt_mutex_wake_q_head)
  {
  	struct rt_mutex_waiter *waiter;
  
@@@ -1307,9 -1326,9 +1312,9 @@@ static __always_inline int __rt_mutex_t
  /*
   * Slow path to release a rt-mutex.
   */
 -static void __sched rt_mutex_slowunlock(struct rt_mutex_base *lock)
 +static void __sched rt_mutex_slowunlock(struct rt_mutex *lock)
  {
- 	DEFINE_WAKE_Q(wake_q);
+ 	DEFINE_RT_WAKE_Q(wqh);
  	unsigned long flags;
  
  	/* irqsave required to support early boot calls */
@@@ -1362,13 -1381,13 +1367,13 @@@
  	 *
  	 * Queue the next waiter for wakeup once we release the wait_lock.
  	 */
- 	mark_wakeup_next_waiter(&wake_q, lock);
+ 	mark_wakeup_next_waiter(&wqh, lock);
  	raw_spin_unlock_irqrestore(&lock->wait_lock, flags);
  
- 	rt_mutex_postunlock(&wake_q);
+ 	rt_mutex_wake_up_q(&wqh);
  }
  
 -static __always_inline void __rt_mutex_unlock(struct rt_mutex_base *lock)
 +static __always_inline void __rt_mutex_unlock(struct rt_mutex *lock)
  {
  	if (likely(rt_mutex_cmpxchg_release(lock, current, NULL)))
  		return;
diff --cc kernel/locking/rtmutex_api.c
index fc1322f5b219,56403dc5c2fc..000000000000
--- a/kernel/locking/rtmutex_api.c
+++ b/kernel/locking/rtmutex_api.c
@@@ -131,10 -137,10 +131,15 @@@ int __sched __rt_mutex_futex_trylock(st
   * do not use the fast-path, can be simple and will not need to retry.
   *
   * @lock:	The rt_mutex to be unlocked
-  * @wake_q:	The wake queue head from which to get the next lock waiter
+  * @wqh:	The wake queue head from which to get the next lock waiter
   */
++<<<<<<< HEAD
 +bool __sched __rt_mutex_futex_unlock(struct rt_mutex *lock,
 +				     struct wake_q_head *wake_q)
++=======
+ bool __sched __rt_mutex_futex_unlock(struct rt_mutex_base *lock,
+ 				     struct rt_wake_q_head *wqh)
++>>>>>>> 7980aa397cc0 (locking/rtmutex: Use rt_mutex_wake_q_head)
  {
  	lockdep_assert_held(&lock->wait_lock);
  
@@@ -156,9 -162,9 +161,9 @@@
  	return true; /* call postunlock() */
  }
  
 -void __sched rt_mutex_futex_unlock(struct rt_mutex_base *lock)
 +void __sched rt_mutex_futex_unlock(struct rt_mutex *lock)
  {
- 	DEFINE_WAKE_Q(wake_q);
+ 	DEFINE_RT_WAKE_Q(wqh);
  	unsigned long flags;
  	bool postunlock;
  
diff --cc kernel/locking/rtmutex_common.h
index cd3579108fbc,ff36316003d8..000000000000
--- a/kernel/locking/rtmutex_common.h
+++ b/kernel/locking/rtmutex_common.h
@@@ -54,29 -56,29 +54,35 @@@ struct rt_wake_q_head 
  /*
   * PI-futex support (proxy locking functions, etc.):
   */
 -extern void rt_mutex_init_proxy_locked(struct rt_mutex_base *lock,
 +extern void rt_mutex_init_proxy_locked(struct rt_mutex *lock,
  				       struct task_struct *proxy_owner);
 -extern void rt_mutex_proxy_unlock(struct rt_mutex_base *lock);
 -extern int __rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,
 +extern void rt_mutex_proxy_unlock(struct rt_mutex *lock);
 +extern int __rt_mutex_start_proxy_lock(struct rt_mutex *lock,
  				     struct rt_mutex_waiter *waiter,
  				     struct task_struct *task);
 -extern int rt_mutex_start_proxy_lock(struct rt_mutex_base *lock,
 +extern int rt_mutex_start_proxy_lock(struct rt_mutex *lock,
  				     struct rt_mutex_waiter *waiter,
  				     struct task_struct *task);
 -extern int rt_mutex_wait_proxy_lock(struct rt_mutex_base *lock,
 +extern int rt_mutex_wait_proxy_lock(struct rt_mutex *lock,
  			       struct hrtimer_sleeper *to,
  			       struct rt_mutex_waiter *waiter);
 -extern bool rt_mutex_cleanup_proxy_lock(struct rt_mutex_base *lock,
 +extern bool rt_mutex_cleanup_proxy_lock(struct rt_mutex *lock,
  				 struct rt_mutex_waiter *waiter);
  
 -extern int rt_mutex_futex_trylock(struct rt_mutex_base *l);
 -extern int __rt_mutex_futex_trylock(struct rt_mutex_base *l);
 +extern int rt_mutex_futex_trylock(struct rt_mutex *l);
 +extern int __rt_mutex_futex_trylock(struct rt_mutex *l);
  
++<<<<<<< HEAD
 +extern void rt_mutex_futex_unlock(struct rt_mutex *lock);
 +extern bool __rt_mutex_futex_unlock(struct rt_mutex *lock,
 +				struct wake_q_head *wake_q);
++=======
+ extern void rt_mutex_futex_unlock(struct rt_mutex_base *lock);
+ extern bool __rt_mutex_futex_unlock(struct rt_mutex_base *lock,
+ 				struct rt_wake_q_head *wqh);
++>>>>>>> 7980aa397cc0 (locking/rtmutex: Use rt_mutex_wake_q_head)
  
- extern void rt_mutex_postunlock(struct wake_q_head *wake_q);
+ extern void rt_mutex_postunlock(struct rt_wake_q_head *wqh);
  
  /*
   * Must be guarded because this header is included from rcu/tree_plugin.h
diff --git a/kernel/futex.c b/kernel/futex.c
index 87366e24faf0..7a18ded0f022 100644
--- a/kernel/futex.c
+++ b/kernel/futex.c
@@ -1506,11 +1506,11 @@ static void mark_wake_futex(struct wake_q_head *wake_q, struct futex_q *q)
  */
 static int wake_futex_pi(u32 __user *uaddr, u32 uval, struct futex_pi_state *pi_state)
 {
-	u32 curval, newval;
 	struct rt_mutex_waiter *top_waiter;
 	struct task_struct *new_owner;
 	bool postunlock = false;
-	DEFINE_WAKE_Q(wake_q);
+	DEFINE_RT_WAKE_Q(wqh);
+	u32 curval, newval;
 	int ret = 0;
 
 	top_waiter = rt_mutex_top_waiter(&pi_state->pi_mutex);
@@ -1562,14 +1562,14 @@ static int wake_futex_pi(u32 __user *uaddr, u32 uval, struct futex_pi_state *pi_
 		 * not fail.
 		 */
 		pi_state_update_owner(pi_state, new_owner);
-		postunlock = __rt_mutex_futex_unlock(&pi_state->pi_mutex, &wake_q);
+		postunlock = __rt_mutex_futex_unlock(&pi_state->pi_mutex, &wqh);
 	}
 
 out_unlock:
 	raw_spin_unlock_irq(&pi_state->pi_mutex.wait_lock);
 
 	if (postunlock)
-		rt_mutex_postunlock(&wake_q);
+		rt_mutex_postunlock(&wqh);
 
 	return ret;
 }
* Unmerged path kernel/locking/rtmutex.c
* Unmerged path kernel/locking/rtmutex_api.c
* Unmerged path kernel/locking/rtmutex_common.h
