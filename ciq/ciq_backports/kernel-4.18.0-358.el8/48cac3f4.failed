bpf: Implement formatted output helpers with bstr_printf

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Florent Revest <revest@chromium.org>
commit 48cac3f4a96ddf08df8e53809ed066de0dc93915
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/48cac3f4.failed

BPF has three formatted output helpers: bpf_trace_printk, bpf_seq_printf
and bpf_snprintf. Their signatures specify that all arguments are
provided from the BPF world as u64s (in an array or as registers). All
of these helpers are currently implemented by calling functions such as
snprintf() whose signatures take a variable number of arguments, then
placed in a va_list by the compiler to call vsnprintf().

"d9c9e4db bpf: Factorize bpf_trace_printk and bpf_seq_printf" introduced
a bpf_printf_prepare function that fills an array of u64 sanitized
arguments with an array of "modifiers" which indicate what the "real"
size of each argument should be (given by the format specifier). The
BPF_CAST_FMT_ARG macro consumes these arrays and casts each argument to
its real size. However, the C promotion rules implicitely cast them all
back to u64s. Therefore, the arguments given to snprintf are u64s and
the va_list constructed by the compiler will use 64 bits for each
argument. On 64 bit machines, this happens to work well because 32 bit
arguments in va_lists need to occupy 64 bits anyway, but on 32 bit
architectures this breaks the layout of the va_list expected by the
called function and mangles values.

In "88a5c690b6 bpf: fix bpf_trace_printk on 32 bit archs", this problem
had been solved for bpf_trace_printk only with a "horrid workaround"
that emitted multiple calls to trace_printk where each call had
different argument types and generated different va_list layouts. One of
the call would be dynamically chosen at runtime. This was ok with the 3
arguments that bpf_trace_printk takes but bpf_seq_printf and
bpf_snprintf accept up to 12 arguments. Because this approach scales
code exponentially, it is not a viable option anymore.

Because the promotion rules are part of the language and because the
construction of a va_list is an arch-specific ABI, it's best to just
avoid variadic arguments and va_lists altogether. Thankfully the
kernel's snprintf() has an alternative in the form of bstr_printf() that
accepts arguments in a "binary buffer representation". These binary
buffers are currently created by vbin_printf and used in the tracing
subsystem to split the cost of printing into two parts: a fast one that
only dereferences and remembers values, and a slower one, called later,
that does the pretty-printing.

This patch refactors bpf_printf_prepare to construct binary buffers of
arguments consumable by bstr_printf() instead of arrays of arguments and
modifiers. This gets rid of BPF_CAST_FMT_ARG and greatly simplifies the
bpf_printf_prepare usage but there are a few gotchas that change how
bpf_printf_prepare needs to do things.

Currently, bpf_printf_prepare uses a per cpu temporary buffer as a
generic storage for strings and IP addresses. With this refactoring, the
temporary buffers now holds all the arguments in a structured binary
format.

To comply with the format expected by bstr_printf, certain format
specifiers also need to be pre-formatted: %pB and %pi6/%pi4/%pI4/%pI6.
Because vsnprintf subroutines for these specifiers are hard to expose,
we pre-format these arguments with calls to snprintf().

	Reported-by: Rasmus Villemoes <linux@rasmusvillemoes.dk>
	Signed-off-by: Florent Revest <revest@chromium.org>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
Link: https://lore.kernel.org/bpf/20210427174313.860948-3-revest@chromium.org
(cherry picked from commit 48cac3f4a96ddf08df8e53809ed066de0dc93915)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
#	init/Kconfig
#	kernel/bpf/helpers.c
#	kernel/bpf/verifier.c
#	kernel/trace/bpf_trace.c
diff --cc include/linux/bpf.h
index 95b950412549,b33f199c4cc2..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -2070,4 -2081,8 +2070,11 @@@ int bpf_arch_text_poke(void *ip, enum b
  struct btf_id_set;
  bool btf_id_set_contains(const struct btf_id_set *set, u32 id);
  
++<<<<<<< HEAD
++=======
+ int bpf_bprintf_prepare(char *fmt, u32 fmt_size, const u64 *raw_args,
+ 			u32 **bin_buf, u32 num_args);
+ void bpf_bprintf_cleanup(void);
+ 
++>>>>>>> 48cac3f4a96d (bpf: Implement formatted output helpers with bstr_printf)
  #endif /* _LINUX_BPF_H */
diff --cc init/Kconfig
index 7609c6684f41,0d82a1f838cc..000000000000
--- a/init/Kconfig
+++ b/init/Kconfig
@@@ -1510,6 -1708,8 +1510,11 @@@ config BPF_SYSCAL
  	select BPF
  	select IRQ_WORK
  	select TASKS_TRACE_RCU
++<<<<<<< HEAD
++=======
+ 	select BINARY_PRINTF
+ 	select NET_SOCK_MSG if INET
++>>>>>>> 48cac3f4a96d (bpf: Implement formatted output helpers with bstr_printf)
  	default n
  	help
  	  Enable the bpf() system call that allows to manipulate eBPF
diff --cc kernel/bpf/helpers.c
index cc97656102f8,544773970dbc..000000000000
--- a/kernel/bpf/helpers.c
+++ b/kernel/bpf/helpers.c
@@@ -670,6 -669,322 +670,325 @@@ const struct bpf_func_proto bpf_this_cp
  	.arg1_type	= ARG_PTR_TO_PERCPU_BTF_ID,
  };
  
++<<<<<<< HEAD
++=======
+ static int bpf_trace_copy_string(char *buf, void *unsafe_ptr, char fmt_ptype,
+ 		size_t bufsz)
+ {
+ 	void __user *user_ptr = (__force void __user *)unsafe_ptr;
+ 
+ 	buf[0] = 0;
+ 
+ 	switch (fmt_ptype) {
+ 	case 's':
+ #ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE
+ 		if ((unsigned long)unsafe_ptr < TASK_SIZE)
+ 			return strncpy_from_user_nofault(buf, user_ptr, bufsz);
+ 		fallthrough;
+ #endif
+ 	case 'k':
+ 		return strncpy_from_kernel_nofault(buf, unsafe_ptr, bufsz);
+ 	case 'u':
+ 		return strncpy_from_user_nofault(buf, user_ptr, bufsz);
+ 	}
+ 
+ 	return -EINVAL;
+ }
+ 
+ /* Per-cpu temp buffers which can be used by printf-like helpers for %s or %p
+  */
+ #define MAX_PRINTF_BUF_LEN	512
+ 
+ struct bpf_printf_buf {
+ 	char tmp_buf[MAX_PRINTF_BUF_LEN];
+ };
+ static DEFINE_PER_CPU(struct bpf_printf_buf, bpf_printf_buf);
+ static DEFINE_PER_CPU(int, bpf_printf_buf_used);
+ 
+ static int try_get_fmt_tmp_buf(char **tmp_buf)
+ {
+ 	struct bpf_printf_buf *bufs;
+ 	int used;
+ 
+ 	preempt_disable();
+ 	used = this_cpu_inc_return(bpf_printf_buf_used);
+ 	if (WARN_ON_ONCE(used > 1)) {
+ 		this_cpu_dec(bpf_printf_buf_used);
+ 		preempt_enable();
+ 		return -EBUSY;
+ 	}
+ 	bufs = this_cpu_ptr(&bpf_printf_buf);
+ 	*tmp_buf = bufs->tmp_buf;
+ 
+ 	return 0;
+ }
+ 
+ void bpf_bprintf_cleanup(void)
+ {
+ 	if (this_cpu_read(bpf_printf_buf_used)) {
+ 		this_cpu_dec(bpf_printf_buf_used);
+ 		preempt_enable();
+ 	}
+ }
+ 
+ /*
+  * bpf_bprintf_prepare - Generic pass on format strings for bprintf-like helpers
+  *
+  * Returns a negative value if fmt is an invalid format string or 0 otherwise.
+  *
+  * This can be used in two ways:
+  * - Format string verification only: when bin_args is NULL
+  * - Arguments preparation: in addition to the above verification, it writes in
+  *   bin_args a binary representation of arguments usable by bstr_printf where
+  *   pointers from BPF have been sanitized.
+  *
+  * In argument preparation mode, if 0 is returned, safe temporary buffers are
+  * allocated and bpf_bprintf_cleanup should be called to free them after use.
+  */
+ int bpf_bprintf_prepare(char *fmt, u32 fmt_size, const u64 *raw_args,
+ 			u32 **bin_args, u32 num_args)
+ {
+ 	char *unsafe_ptr = NULL, *tmp_buf = NULL, *tmp_buf_end, *fmt_end;
+ 	size_t sizeof_cur_arg, sizeof_cur_ip;
+ 	int err, i, num_spec = 0;
+ 	u64 cur_arg;
+ 	char fmt_ptype, cur_ip[16], ip_spec[] = "%pXX";
+ 
+ 	fmt_end = strnchr(fmt, fmt_size, 0);
+ 	if (!fmt_end)
+ 		return -EINVAL;
+ 	fmt_size = fmt_end - fmt;
+ 
+ 	if (bin_args) {
+ 		if (num_args && try_get_fmt_tmp_buf(&tmp_buf))
+ 			return -EBUSY;
+ 
+ 		tmp_buf_end = tmp_buf + MAX_PRINTF_BUF_LEN;
+ 		*bin_args = (u32 *)tmp_buf;
+ 	}
+ 
+ 	for (i = 0; i < fmt_size; i++) {
+ 		if ((!isprint(fmt[i]) && !isspace(fmt[i])) || !isascii(fmt[i])) {
+ 			err = -EINVAL;
+ 			goto out;
+ 		}
+ 
+ 		if (fmt[i] != '%')
+ 			continue;
+ 
+ 		if (fmt[i + 1] == '%') {
+ 			i++;
+ 			continue;
+ 		}
+ 
+ 		if (num_spec >= num_args) {
+ 			err = -EINVAL;
+ 			goto out;
+ 		}
+ 
+ 		/* The string is zero-terminated so if fmt[i] != 0, we can
+ 		 * always access fmt[i + 1], in the worst case it will be a 0
+ 		 */
+ 		i++;
+ 
+ 		/* skip optional "[0 +-][num]" width formatting field */
+ 		while (fmt[i] == '0' || fmt[i] == '+'  || fmt[i] == '-' ||
+ 		       fmt[i] == ' ')
+ 			i++;
+ 		if (fmt[i] >= '1' && fmt[i] <= '9') {
+ 			i++;
+ 			while (fmt[i] >= '0' && fmt[i] <= '9')
+ 				i++;
+ 		}
+ 
+ 		if (fmt[i] == 'p') {
+ 			sizeof_cur_arg = sizeof(long);
+ 
+ 			if ((fmt[i + 1] == 'k' || fmt[i + 1] == 'u') &&
+ 			    fmt[i + 2] == 's') {
+ 				fmt_ptype = fmt[i + 1];
+ 				i += 2;
+ 				goto fmt_str;
+ 			}
+ 
+ 			if (fmt[i + 1] == 0 || isspace(fmt[i + 1]) ||
+ 			    ispunct(fmt[i + 1]) || fmt[i + 1] == 'K' ||
+ 			    fmt[i + 1] == 'x' || fmt[i + 1] == 's' ||
+ 			    fmt[i + 1] == 'S') {
+ 				/* just kernel pointers */
+ 				if (tmp_buf)
+ 					cur_arg = raw_args[num_spec];
+ 				i++;
+ 				goto nocopy_fmt;
+ 			}
+ 
+ 			if (fmt[i + 1] == 'B') {
+ 				if (tmp_buf)  {
+ 					err = snprintf(tmp_buf,
+ 						       (tmp_buf_end - tmp_buf),
+ 						       "%pB",
+ 						       (void *)(long)raw_args[num_spec]);
+ 					tmp_buf += (err + 1);
+ 				}
+ 
+ 				i++;
+ 				num_spec++;
+ 				continue;
+ 			}
+ 
+ 			/* only support "%pI4", "%pi4", "%pI6" and "%pi6". */
+ 			if ((fmt[i + 1] != 'i' && fmt[i + 1] != 'I') ||
+ 			    (fmt[i + 2] != '4' && fmt[i + 2] != '6')) {
+ 				err = -EINVAL;
+ 				goto out;
+ 			}
+ 
+ 			i += 2;
+ 			if (!tmp_buf)
+ 				goto nocopy_fmt;
+ 
+ 			sizeof_cur_ip = (fmt[i] == '4') ? 4 : 16;
+ 			if (tmp_buf_end - tmp_buf < sizeof_cur_ip) {
+ 				err = -ENOSPC;
+ 				goto out;
+ 			}
+ 
+ 			unsafe_ptr = (char *)(long)raw_args[num_spec];
+ 			err = copy_from_kernel_nofault(cur_ip, unsafe_ptr,
+ 						       sizeof_cur_ip);
+ 			if (err < 0)
+ 				memset(cur_ip, 0, sizeof_cur_ip);
+ 
+ 			/* hack: bstr_printf expects IP addresses to be
+ 			 * pre-formatted as strings, ironically, the easiest way
+ 			 * to do that is to call snprintf.
+ 			 */
+ 			ip_spec[2] = fmt[i - 1];
+ 			ip_spec[3] = fmt[i];
+ 			err = snprintf(tmp_buf, tmp_buf_end - tmp_buf,
+ 				       ip_spec, &cur_ip);
+ 
+ 			tmp_buf += err + 1;
+ 			num_spec++;
+ 
+ 			continue;
+ 		} else if (fmt[i] == 's') {
+ 			fmt_ptype = fmt[i];
+ fmt_str:
+ 			if (fmt[i + 1] != 0 &&
+ 			    !isspace(fmt[i + 1]) &&
+ 			    !ispunct(fmt[i + 1])) {
+ 				err = -EINVAL;
+ 				goto out;
+ 			}
+ 
+ 			if (!tmp_buf)
+ 				goto nocopy_fmt;
+ 
+ 			if (tmp_buf_end == tmp_buf) {
+ 				err = -ENOSPC;
+ 				goto out;
+ 			}
+ 
+ 			unsafe_ptr = (char *)(long)raw_args[num_spec];
+ 			err = bpf_trace_copy_string(tmp_buf, unsafe_ptr,
+ 						    fmt_ptype,
+ 						    tmp_buf_end - tmp_buf);
+ 			if (err < 0) {
+ 				tmp_buf[0] = '\0';
+ 				err = 1;
+ 			}
+ 
+ 			tmp_buf += err;
+ 			num_spec++;
+ 
+ 			continue;
+ 		}
+ 
+ 		sizeof_cur_arg = sizeof(int);
+ 
+ 		if (fmt[i] == 'l') {
+ 			sizeof_cur_arg = sizeof(long);
+ 			i++;
+ 		}
+ 		if (fmt[i] == 'l') {
+ 			sizeof_cur_arg = sizeof(long long);
+ 			i++;
+ 		}
+ 
+ 		if (fmt[i] != 'i' && fmt[i] != 'd' && fmt[i] != 'u' &&
+ 		    fmt[i] != 'x' && fmt[i] != 'X') {
+ 			err = -EINVAL;
+ 			goto out;
+ 		}
+ 
+ 		if (tmp_buf)
+ 			cur_arg = raw_args[num_spec];
+ nocopy_fmt:
+ 		if (tmp_buf) {
+ 			tmp_buf = PTR_ALIGN(tmp_buf, sizeof(u32));
+ 			if (tmp_buf_end - tmp_buf < sizeof_cur_arg) {
+ 				err = -ENOSPC;
+ 				goto out;
+ 			}
+ 
+ 			if (sizeof_cur_arg == 8) {
+ 				*(u32 *)tmp_buf = *(u32 *)&cur_arg;
+ 				*(u32 *)(tmp_buf + 4) = *((u32 *)&cur_arg + 1);
+ 			} else {
+ 				*(u32 *)tmp_buf = (u32)(long)cur_arg;
+ 			}
+ 			tmp_buf += sizeof_cur_arg;
+ 		}
+ 		num_spec++;
+ 	}
+ 
+ 	err = 0;
+ out:
+ 	if (err)
+ 		bpf_bprintf_cleanup();
+ 	return err;
+ }
+ 
+ #define MAX_SNPRINTF_VARARGS		12
+ 
+ BPF_CALL_5(bpf_snprintf, char *, str, u32, str_size, char *, fmt,
+ 	   const void *, data, u32, data_len)
+ {
+ 	int err, num_args;
+ 	u32 *bin_args;
+ 
+ 	if (data_len % 8 || data_len > MAX_SNPRINTF_VARARGS * 8 ||
+ 	    (data_len && !data))
+ 		return -EINVAL;
+ 	num_args = data_len / 8;
+ 
+ 	/* ARG_PTR_TO_CONST_STR guarantees that fmt is zero-terminated so we
+ 	 * can safely give an unbounded size.
+ 	 */
+ 	err = bpf_bprintf_prepare(fmt, UINT_MAX, data, &bin_args, num_args);
+ 	if (err < 0)
+ 		return err;
+ 
+ 	err = bstr_printf(str, str_size, fmt, bin_args);
+ 
+ 	bpf_bprintf_cleanup();
+ 
+ 	return err + 1;
+ }
+ 
+ const struct bpf_func_proto bpf_snprintf_proto = {
+ 	.func		= bpf_snprintf,
+ 	.gpl_only	= true,
+ 	.ret_type	= RET_INTEGER,
+ 	.arg1_type	= ARG_PTR_TO_MEM_OR_NULL,
+ 	.arg2_type	= ARG_CONST_SIZE_OR_ZERO,
+ 	.arg3_type	= ARG_PTR_TO_CONST_STR,
+ 	.arg4_type	= ARG_PTR_TO_MEM_OR_NULL,
+ 	.arg5_type	= ARG_CONST_SIZE_OR_ZERO,
+ };
+ 
++>>>>>>> 48cac3f4a96d (bpf: Implement formatted output helpers with bstr_printf)
  const struct bpf_func_proto bpf_get_current_task_proto __weak;
  const struct bpf_func_proto bpf_probe_read_user_proto __weak;
  const struct bpf_func_proto bpf_probe_read_user_str_proto __weak;
diff --cc kernel/bpf/verifier.c
index 3c2ee850da6c,8fd552c16763..000000000000
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@@ -5563,7 -5916,45 +5563,49 @@@ static int check_reference_leak(struct 
  	return state->acquired_refs ? -EINVAL : 0;
  }
  
++<<<<<<< HEAD
 +static int check_helper_call(struct bpf_verifier_env *env, int func_id, int insn_idx)
++=======
+ static int check_bpf_snprintf_call(struct bpf_verifier_env *env,
+ 				   struct bpf_reg_state *regs)
+ {
+ 	struct bpf_reg_state *fmt_reg = &regs[BPF_REG_3];
+ 	struct bpf_reg_state *data_len_reg = &regs[BPF_REG_5];
+ 	struct bpf_map *fmt_map = fmt_reg->map_ptr;
+ 	int err, fmt_map_off, num_args;
+ 	u64 fmt_addr;
+ 	char *fmt;
+ 
+ 	/* data must be an array of u64 */
+ 	if (data_len_reg->var_off.value % 8)
+ 		return -EINVAL;
+ 	num_args = data_len_reg->var_off.value / 8;
+ 
+ 	/* fmt being ARG_PTR_TO_CONST_STR guarantees that var_off is const
+ 	 * and map_direct_value_addr is set.
+ 	 */
+ 	fmt_map_off = fmt_reg->off + fmt_reg->var_off.value;
+ 	err = fmt_map->ops->map_direct_value_addr(fmt_map, &fmt_addr,
+ 						  fmt_map_off);
+ 	if (err) {
+ 		verbose(env, "verifier bug\n");
+ 		return -EFAULT;
+ 	}
+ 	fmt = (char *)(long)fmt_addr + fmt_map_off;
+ 
+ 	/* We are also guaranteed that fmt+fmt_map_off is NULL terminated, we
+ 	 * can focus on validating the format specifiers.
+ 	 */
+ 	err = bpf_bprintf_prepare(fmt, UINT_MAX, NULL, NULL, num_args);
+ 	if (err < 0)
+ 		verbose(env, "Invalid format string\n");
+ 
+ 	return err;
+ }
+ 
+ static int check_helper_call(struct bpf_verifier_env *env, struct bpf_insn *insn,
+ 			     int *insn_idx_p)
++>>>>>>> 48cac3f4a96d (bpf: Implement formatted output helpers with bstr_printf)
  {
  	const struct bpf_func_proto *fn = NULL;
  	struct bpf_reg_state *regs;
diff --cc kernel/trace/bpf_trace.c
index 235070f4b98b,d2d7cf6cfe83..000000000000
--- a/kernel/trace/bpf_trace.c
+++ b/kernel/trace/bpf_trace.c
@@@ -362,52 -372,33 +362,73 @@@ static const struct bpf_func_proto *bpf
  	return &bpf_probe_write_user_proto;
  }
  
 +static void bpf_trace_copy_string(char *buf, void *unsafe_ptr, char fmt_ptype,
 +		size_t bufsz)
 +{
 +	void __user *user_ptr = (__force void __user *)unsafe_ptr;
 +
 +	buf[0] = 0;
 +
 +	switch (fmt_ptype) {
 +	case 's':
 +#ifdef CONFIG_ARCH_HAS_NON_OVERLAPPING_ADDRESS_SPACE
 +		if ((unsigned long)unsafe_ptr < TASK_SIZE) {
 +			strncpy_from_unsafe_user(buf, user_ptr, bufsz);
 +			break;
 +		}
 +		/* fallthrough */
 +#endif
 +	case 'k':
 +		strncpy_from_unsafe_strict(buf, unsafe_ptr, bufsz);
 +		break;
 +	case 'u':
 +		strncpy_from_unsafe_user(buf, user_ptr, bufsz);
 +		break;
 +	}
 +}
 +
  static DEFINE_RAW_SPINLOCK(trace_printk_lock);
  
 -#define MAX_TRACE_PRINTK_VARARGS	3
 -#define BPF_TRACE_PRINTK_SIZE		1024
 +#define BPF_TRACE_PRINTK_SIZE   1024
  
 -BPF_CALL_5(bpf_trace_printk, char *, fmt, u32, fmt_size, u64, arg1,
 -	   u64, arg2, u64, arg3)
 +static __printf(1, 0) int bpf_do_trace_printk(const char *fmt, ...)
  {
++<<<<<<< HEAD
++=======
+ 	u64 args[MAX_TRACE_PRINTK_VARARGS] = { arg1, arg2, arg3 };
+ 	u32 *bin_args;
++>>>>>>> 48cac3f4a96d (bpf: Implement formatted output helpers with bstr_printf)
  	static char buf[BPF_TRACE_PRINTK_SIZE];
  	unsigned long flags;
 +	va_list ap;
  	int ret;
  
++<<<<<<< HEAD
 +	raw_spin_lock_irqsave(&trace_printk_lock, flags);
 +	va_start(ap, fmt);
 +	ret = vsnprintf(buf, sizeof(buf), fmt, ap);
 +	va_end(ap);
 +	/* vsnprintf() will not append null for zero-length strings */
 +	if (ret == 0)
 +		buf[0] = '\0';
 +	trace_bpf_trace_printk(buf);
 +	raw_spin_unlock_irqrestore(&trace_printk_lock, flags);
 +
++=======
+ 	ret = bpf_bprintf_prepare(fmt, fmt_size, args, &bin_args,
+ 				  MAX_TRACE_PRINTK_VARARGS);
+ 	if (ret < 0)
+ 		return ret;
+ 
+ 	raw_spin_lock_irqsave(&trace_printk_lock, flags);
+ 	ret = bstr_printf(buf, sizeof(buf), fmt, bin_args);
+ 
+ 	trace_bpf_trace_printk(buf);
+ 	raw_spin_unlock_irqrestore(&trace_printk_lock, flags);
+ 
+ 	bpf_bprintf_cleanup();
+ 
++>>>>>>> 48cac3f4a96d (bpf: Implement formatted output helpers with bstr_printf)
  	return ret;
  }
  
@@@ -583,170 -431,23 +604,187 @@@ static DEFINE_PER_CPU(int, bpf_seq_prin
  BPF_CALL_5(bpf_seq_printf, struct seq_file *, m, char *, fmt, u32, fmt_size,
  	   const void *, data, u32, data_len)
  {
++<<<<<<< HEAD
 +	int err = -EINVAL, fmt_cnt = 0, memcpy_cnt = 0;
 +	int i, buf_used, copy_size, num_args;
 +	u64 params[MAX_SEQ_PRINTF_VARARGS];
 +	struct bpf_seq_printf_buf *bufs;
 +	const u64 *args = data;
 +
 +	buf_used = this_cpu_inc_return(bpf_seq_printf_buf_used);
 +	if (WARN_ON_ONCE(buf_used > 1)) {
 +		err = -EBUSY;
 +		goto out;
 +	}
 +
 +	bufs = this_cpu_ptr(&bpf_seq_printf_buf);
 +
 +	/*
 +	 * bpf_check()->check_func_arg()->check_stack_boundary()
 +	 * guarantees that fmt points to bpf program stack,
 +	 * fmt_size bytes of it were initialized and fmt_size > 0
 +	 */
 +	if (fmt[--fmt_size] != 0)
 +		goto out;
 +
 +	if (data_len & 7)
 +		goto out;
 +
 +	for (i = 0; i < fmt_size; i++) {
 +		if (fmt[i] == '%') {
 +			if (fmt[i + 1] == '%')
 +				i++;
 +			else if (!data || !data_len)
 +				goto out;
 +		}
 +	}
++=======
+ 	int err, num_args;
+ 	u32 *bin_args;
++>>>>>>> 48cac3f4a96d (bpf: Implement formatted output helpers with bstr_printf)
  
 -	if (data_len & 7 || data_len > MAX_SEQ_PRINTF_VARARGS * 8 ||
 -	    (data_len && !data))
 -		return -EINVAL;
  	num_args = data_len / 8;
  
++<<<<<<< HEAD
 +	/* check format string for allowed specifiers */
 +	for (i = 0; i < fmt_size; i++) {
 +		/* only printable ascii for now. */
 +		if ((!isprint(fmt[i]) && !isspace(fmt[i])) || !isascii(fmt[i])) {
 +			err = -EINVAL;
 +			goto out;
 +		}
 +
 +		if (fmt[i] != '%')
 +			continue;
 +
 +		if (fmt[i + 1] == '%') {
 +			i++;
 +			continue;
 +		}
 +
 +		if (fmt_cnt >= MAX_SEQ_PRINTF_VARARGS) {
 +			err = -E2BIG;
 +			goto out;
 +		}
 +
 +		if (fmt_cnt >= num_args) {
 +			err = -EINVAL;
 +			goto out;
 +		}
 +
 +		/* fmt[i] != 0 && fmt[last] == 0, so we can access fmt[i + 1] */
 +		i++;
 +
 +		/* skip optional "[0 +-][num]" width formating field */
 +		while (fmt[i] == '0' || fmt[i] == '+'  || fmt[i] == '-' ||
 +		       fmt[i] == ' ')
 +			i++;
 +		if (fmt[i] >= '1' && fmt[i] <= '9') {
 +			i++;
 +			while (fmt[i] >= '0' && fmt[i] <= '9')
 +				i++;
 +		}
 +
 +		if (fmt[i] == 's') {
 +			/* try our best to copy */
 +			if (memcpy_cnt >= MAX_SEQ_PRINTF_MAX_MEMCPY) {
 +				err = -E2BIG;
 +				goto out;
 +			}
 +
 +			err = strncpy_from_unsafe_strict(bufs->buf[memcpy_cnt],
 +							 (void *) (long) args[fmt_cnt],
 +							 MAX_SEQ_PRINTF_STR_LEN);
 +			if (err < 0)
 +				bufs->buf[memcpy_cnt][0] = '\0';
 +			params[fmt_cnt] = (u64)(long)bufs->buf[memcpy_cnt];
 +
 +			fmt_cnt++;
 +			memcpy_cnt++;
 +			continue;
 +		}
 +
 +		if (fmt[i] == 'p') {
 +			if (fmt[i + 1] == 0 ||
 +			    fmt[i + 1] == 'K' ||
 +			    fmt[i + 1] == 'x' ||
 +			    fmt[i + 1] == 'B') {
 +				/* just kernel pointers */
 +				params[fmt_cnt] = args[fmt_cnt];
 +				fmt_cnt++;
 +				continue;
 +			}
 +
 +			/* only support "%pI4", "%pi4", "%pI6" and "%pi6". */
 +			if (fmt[i + 1] != 'i' && fmt[i + 1] != 'I') {
 +				err = -EINVAL;
 +				goto out;
 +			}
 +			if (fmt[i + 2] != '4' && fmt[i + 2] != '6') {
 +				err = -EINVAL;
 +				goto out;
 +			}
 +
 +			if (memcpy_cnt >= MAX_SEQ_PRINTF_MAX_MEMCPY) {
 +				err = -E2BIG;
 +				goto out;
 +			}
 +
 +
 +			copy_size = (fmt[i + 2] == '4') ? 4 : 16;
 +
 +			err = probe_kernel_read(bufs->buf[memcpy_cnt],
 +						(void *) (long) args[fmt_cnt],
 +						copy_size);
 +			if (err < 0)
 +				memset(bufs->buf[memcpy_cnt], 0, copy_size);
 +			params[fmt_cnt] = (u64)(long)bufs->buf[memcpy_cnt];
 +
 +			i += 2;
 +			fmt_cnt++;
 +			memcpy_cnt++;
 +			continue;
 +		}
 +
 +		if (fmt[i] == 'l') {
 +			i++;
 +			if (fmt[i] == 'l')
 +				i++;
 +		}
 +
 +		if (fmt[i] != 'i' && fmt[i] != 'd' &&
 +		    fmt[i] != 'u' && fmt[i] != 'x' &&
 +		    fmt[i] != 'X') {
 +			err = -EINVAL;
 +			goto out;
 +		}
 +
 +		params[fmt_cnt] = args[fmt_cnt];
 +		fmt_cnt++;
 +	}
 +
 +	/* Maximumly we can have MAX_SEQ_PRINTF_VARARGS parameter, just give
 +	 * all of them to seq_printf().
 +	 */
 +	seq_printf(m, fmt, params[0], params[1], params[2], params[3],
 +		   params[4], params[5], params[6], params[7], params[8],
 +		   params[9], params[10], params[11]);
 +
 +	err = seq_has_overflowed(m) ? -EOVERFLOW : 0;
 +out:
 +	this_cpu_dec(bpf_seq_printf_buf_used);
 +	return err;
++=======
+ 	err = bpf_bprintf_prepare(fmt, fmt_size, data, &bin_args, num_args);
+ 	if (err < 0)
+ 		return err;
+ 
+ 	seq_bprintf(m, fmt, bin_args);
+ 
+ 	bpf_bprintf_cleanup();
+ 
+ 	return seq_has_overflowed(m) ? -EOVERFLOW : 0;
++>>>>>>> 48cac3f4a96d (bpf: Implement formatted output helpers with bstr_printf)
  }
  
  BTF_ID_LIST_SINGLE(btf_seq_file_ids, struct, seq_file)
* Unmerged path include/linux/bpf.h
* Unmerged path init/Kconfig
* Unmerged path kernel/bpf/helpers.c
* Unmerged path kernel/bpf/verifier.c
* Unmerged path kernel/trace/bpf_trace.c
