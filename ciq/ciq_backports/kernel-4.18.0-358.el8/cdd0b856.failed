RDMA/rxe: Implement memory access through MWs

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Bob Pearson <rpearsonhpe@gmail.com>
commit cdd0b85675aecc77eba8c38d55070a014a49ab98
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/cdd0b856.failed

Add code to implement memory access through memory windows.

Link: https://lore.kernel.org/r/20210608042552.33275-10-rpearsonhpe@gmail.com
	Signed-off-by: Bob Pearson <rpearsonhpe@gmail.com>
	Signed-off-by: Jason Gunthorpe <jgg@nvidia.com>
(cherry picked from commit cdd0b85675aecc77eba8c38d55070a014a49ab98)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/sw/rxe/rxe_loc.h
#	drivers/infiniband/sw/rxe/rxe_mw.c
#	drivers/infiniband/sw/rxe/rxe_resp.c
diff --cc drivers/infiniband/sw/rxe/rxe_loc.h
index e6f574973298,6e4b5e22541e..000000000000
--- a/drivers/infiniband/sw/rxe/rxe_loc.h
+++ b/drivers/infiniband/sw/rxe/rxe_loc.h
@@@ -111,6 -93,8 +111,11 @@@ int advance_dma_data(struct rxe_dma_inf
  int rxe_alloc_mw(struct ib_mw *ibmw, struct ib_udata *udata);
  int rxe_dealloc_mw(struct ib_mw *ibmw);
  int rxe_bind_mw(struct rxe_qp *qp, struct rxe_send_wqe *wqe);
++<<<<<<< HEAD
++=======
+ int rxe_invalidate_mw(struct rxe_qp *qp, u32 rkey);
+ struct rxe_mw *rxe_lookup_mw(struct rxe_qp *qp, int access, u32 rkey);
++>>>>>>> cdd0b85675ae (RDMA/rxe: Implement memory access through MWs)
  void rxe_mw_cleanup(struct rxe_pool_entry *arg);
  
  /* rxe_net.c */
diff --cc drivers/infiniband/sw/rxe/rxe_mw.c
index 65215dde9974,5ba77df7598e..000000000000
--- a/drivers/infiniband/sw/rxe/rxe_mw.c
+++ b/drivers/infiniband/sw/rxe/rxe_mw.c
@@@ -245,6 -245,96 +245,99 @@@ err
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ static int rxe_check_invalidate_mw(struct rxe_qp *qp, struct rxe_mw *mw)
+ {
+ 	if (unlikely(mw->state == RXE_MW_STATE_INVALID))
+ 		return -EINVAL;
+ 
+ 	/* o10-37.2.26 */
+ 	if (unlikely(mw->ibmw.type == IB_MW_TYPE_1))
+ 		return -EINVAL;
+ 
+ 	return 0;
+ }
+ 
+ static void rxe_do_invalidate_mw(struct rxe_mw *mw)
+ {
+ 	struct rxe_qp *qp;
+ 	struct rxe_mr *mr;
+ 
+ 	/* valid type 2 MW will always have a QP pointer */
+ 	qp = mw->qp;
+ 	mw->qp = NULL;
+ 	rxe_drop_ref(qp);
+ 
+ 	/* valid type 2 MW will always have an MR pointer */
+ 	mr = mw->mr;
+ 	mw->mr = NULL;
+ 	atomic_dec(&mr->num_mw);
+ 	rxe_drop_ref(mr);
+ 
+ 	mw->access = 0;
+ 	mw->addr = 0;
+ 	mw->length = 0;
+ 	mw->state = RXE_MW_STATE_FREE;
+ }
+ 
+ int rxe_invalidate_mw(struct rxe_qp *qp, u32 rkey)
+ {
+ 	struct rxe_dev *rxe = to_rdev(qp->ibqp.device);
+ 	unsigned long flags;
+ 	struct rxe_mw *mw;
+ 	int ret;
+ 
+ 	mw = rxe_pool_get_index(&rxe->mw_pool, rkey >> 8);
+ 	if (!mw) {
+ 		ret = -EINVAL;
+ 		goto err;
+ 	}
+ 
+ 	if (rkey != mw->ibmw.rkey) {
+ 		ret = -EINVAL;
+ 		goto err_drop_ref;
+ 	}
+ 
+ 	spin_lock_irqsave(&mw->lock, flags);
+ 
+ 	ret = rxe_check_invalidate_mw(qp, mw);
+ 	if (ret)
+ 		goto err_unlock;
+ 
+ 	rxe_do_invalidate_mw(mw);
+ err_unlock:
+ 	spin_unlock_irqrestore(&mw->lock, flags);
+ err_drop_ref:
+ 	rxe_drop_ref(mw);
+ err:
+ 	return ret;
+ }
+ 
+ struct rxe_mw *rxe_lookup_mw(struct rxe_qp *qp, int access, u32 rkey)
+ {
+ 	struct rxe_dev *rxe = to_rdev(qp->ibqp.device);
+ 	struct rxe_pd *pd = to_rpd(qp->ibqp.pd);
+ 	struct rxe_mw *mw;
+ 	int index = rkey >> 8;
+ 
+ 	mw = rxe_pool_get_index(&rxe->mw_pool, index);
+ 	if (!mw)
+ 		return NULL;
+ 
+ 	if (unlikely((rxe_mw_rkey(mw) != rkey) || rxe_mw_pd(mw) != pd ||
+ 		     (mw->ibmw.type == IB_MW_TYPE_2 && mw->qp != qp) ||
+ 		     (mw->length == 0) ||
+ 		     (access && !(access & mw->access)) ||
+ 		     mw->state != RXE_MW_STATE_VALID)) {
+ 		rxe_drop_ref(mw);
+ 		return NULL;
+ 	}
+ 
+ 	return mw;
+ }
+ 
++>>>>>>> cdd0b85675ae (RDMA/rxe: Implement memory access through MWs)
  void rxe_mw_cleanup(struct rxe_pool_entry *elem)
  {
  	struct rxe_mw *mw = container_of(elem, typeof(*mw), pelem);
diff --cc drivers/infiniband/sw/rxe/rxe_resp.c
index 9c0ce1a4f2ea,f8a7ccd4d8b7..000000000000
--- a/drivers/infiniband/sw/rxe/rxe_resp.c
+++ b/drivers/infiniband/sw/rxe/rxe_resp.c
@@@ -449,18 -454,36 +452,43 @@@ static enum resp_states check_rkey(stru
  	resid	= qp->resp.resid;
  	pktlen	= payload_size(pkt);
  
++<<<<<<< HEAD
 +	mr = lookup_mr(qp->pd, access, rkey, lookup_remote);
 +	if (!mr) {
 +		state = RESPST_ERR_RKEY_VIOLATION;
 +		goto err;
- 	}
++=======
+ 	if (rkey_is_mw(rkey)) {
+ 		mw = rxe_lookup_mw(qp, access, rkey);
+ 		if (!mw) {
+ 			pr_err("%s: no MW matches rkey %#x\n", __func__, rkey);
+ 			state = RESPST_ERR_RKEY_VIOLATION;
+ 			goto err;
+ 		}
  
- 	if (unlikely(mr->state == RXE_MR_STATE_FREE)) {
- 		state = RESPST_ERR_RKEY_VIOLATION;
- 		goto err;
+ 		mr = mw->mr;
+ 		if (!mr) {
+ 			pr_err("%s: MW doesn't have an MR\n", __func__);
+ 			state = RESPST_ERR_RKEY_VIOLATION;
+ 			goto err;
+ 		}
+ 
+ 		if (mw->access & IB_ZERO_BASED)
+ 			qp->resp.offset = mw->addr;
+ 
+ 		rxe_drop_ref(mw);
+ 		rxe_add_ref(mr);
+ 	} else {
+ 		mr = lookup_mr(qp->pd, access, rkey, RXE_LOOKUP_REMOTE);
+ 		if (!mr) {
+ 			pr_err("%s: no MR matches rkey %#x\n", __func__, rkey);
+ 			state = RESPST_ERR_RKEY_VIOLATION;
+ 			goto err;
+ 		}
++>>>>>>> cdd0b85675ae (RDMA/rxe: Implement memory access through MWs)
  	}
  
- 	if (mr_check_range(mr, va, resid)) {
+ 	if (mr_check_range(mr, va + qp->resp.offset, resid)) {
  		state = RESPST_ERR_RKEY_VIOLATION;
  		goto err;
  	}
@@@ -518,8 -544,8 +549,13 @@@ static enum resp_states write_data_in(s
  	int	err;
  	int data_len = payload_size(pkt);
  
++<<<<<<< HEAD
 +	err = rxe_mr_copy(qp->resp.mr, qp->resp.va, payload_addr(pkt), data_len,
 +			  to_mr_obj, NULL);
++=======
+ 	err = rxe_mr_copy(qp->resp.mr, qp->resp.va + qp->resp.offset,
+ 			  payload_addr(pkt), data_len, RXE_TO_MR_OBJ, NULL);
++>>>>>>> cdd0b85675ae (RDMA/rxe: Implement memory access through MWs)
  	if (err) {
  		rc = RESPST_ERR_RKEY_VIOLATION;
  		goto out;
* Unmerged path drivers/infiniband/sw/rxe/rxe_loc.h
* Unmerged path drivers/infiniband/sw/rxe/rxe_mw.c
* Unmerged path drivers/infiniband/sw/rxe/rxe_resp.c
diff --git a/drivers/infiniband/sw/rxe/rxe_verbs.h b/drivers/infiniband/sw/rxe/rxe_verbs.h
index 3d0ab8b7804f..94a9f861685f 100644
--- a/drivers/infiniband/sw/rxe/rxe_verbs.h
+++ b/drivers/infiniband/sw/rxe/rxe_verbs.h
@@ -186,6 +186,7 @@ struct rxe_resp_info {
 
 	/* RDMA read / atomic only */
 	u64			va;
+	u64			offset;
 	struct rxe_mr		*mr;
 	u32			resid;
 	u32			rkey;
@@ -466,6 +467,16 @@ static inline u32 mr_rkey(struct rxe_mr *mr)
 	return mr->ibmr.rkey;
 }
 
+static inline struct rxe_pd *rxe_mw_pd(struct rxe_mw *mw)
+{
+	return to_rpd(mw->ibmw.pd);
+}
+
+static inline u32 rxe_mw_rkey(struct rxe_mw *mw)
+{
+	return mw->ibmw.rkey;
+}
+
 int rxe_register_device(struct rxe_dev *rxe, const char *ibdev_name);
 
 void rxe_mc_cleanup(struct rxe_pool_entry *arg);
