sched/clock: Move sched clock initialization and merge with generic clock

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Pavel Tatashin <pasha.tatashin@oracle.com>
commit 5d2a4e91a541cb04d20d11602f0f9340291322ac
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/5d2a4e91.failed

sched_clock_postinit() initializes a generic clock on systems where no
other clock is provided. This function may be called only after
timekeeping_init().

Rename sched_clock_postinit to generic_clock_inti() and call it from
sched_clock_init(). Move the call for sched_clock_init() until after
time_init().

	Suggested-by: Peter Zijlstra <peterz@infradead.org>
	Signed-off-by: Pavel Tatashin <pasha.tatashin@oracle.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: steven.sistare@oracle.com
	Cc: daniel.m.jordan@oracle.com
	Cc: linux@armlinux.org.uk
	Cc: schwidefsky@de.ibm.com
	Cc: heiko.carstens@de.ibm.com
	Cc: john.stultz@linaro.org
	Cc: sboyd@codeaurora.org
	Cc: hpa@zytor.com
	Cc: douly.fnst@cn.fujitsu.com
	Cc: prarit@redhat.com
	Cc: feng.tang@intel.com
	Cc: pmladek@suse.com
	Cc: gnomes@lxorguk.ukuu.org.uk
	Cc: linux-s390@vger.kernel.org
	Cc: boris.ostrovsky@oracle.com
	Cc: jgross@suse.com
	Cc: pbonzini@redhat.com
Link: https://lkml.kernel.org/r/20180719205545.16512-23-pasha.tatashin@oracle.com

(cherry picked from commit 5d2a4e91a541cb04d20d11602f0f9340291322ac)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	init/main.c
diff --cc init/main.c
index 4b5df336efd2,162d931c9511..000000000000
--- a/init/main.c
+++ b/init/main.c
@@@ -647,22 -641,9 +647,27 @@@ asmlinkage __visible void __init start_
  	hrtimers_init();
  	softirq_init();
  	timekeeping_init();
 +
 +	/*
 +	 * For best initial stack canary entropy, prepare it after:
 +	 * - setup_arch() for any UEFI RNG entropy and boot cmdline access
 +	 * - timekeeping_init() for ktime entropy used in rand_initialize()
 +	 * - rand_initialize() to get any arch-specific entropy like RDRAND
 +	 * - add_latent_entropy() to get any latent entropy
 +	 * - adding command line entropy
 +	 */
 +	rand_initialize();
 +	add_latent_entropy();
 +	add_device_randomness(command_line, strlen(command_line));
 +	boot_init_stack_canary();
 +
  	time_init();
++<<<<<<< HEAD
 +	sched_clock_postinit();
++=======
+ 	sched_clock_init();
+ 	printk_safe_init();
++>>>>>>> 5d2a4e91a541 (sched/clock: Move sched clock initialization and merge with generic clock)
  	perf_event_init();
  	profile_init();
  	call_function_init();
diff --git a/include/linux/sched_clock.h b/include/linux/sched_clock.h
index 411b52e424e1..abe28d5cb3f4 100644
--- a/include/linux/sched_clock.h
+++ b/include/linux/sched_clock.h
@@ -9,17 +9,16 @@
 #define LINUX_SCHED_CLOCK
 
 #ifdef CONFIG_GENERIC_SCHED_CLOCK
-extern void sched_clock_postinit(void);
+extern void generic_sched_clock_init(void);
 
 extern void sched_clock_register(u64 (*read)(void), int bits,
 				 unsigned long rate);
 #else
-static inline void sched_clock_postinit(void) { }
+static inline void generic_sched_clock_init(void) { }
 
 static inline void sched_clock_register(u64 (*read)(void), int bits,
 					unsigned long rate)
 {
-	;
 }
 #endif
 
* Unmerged path init/main.c
diff --git a/kernel/sched/clock.c b/kernel/sched/clock.c
index 10c83e73837a..0e9dbb2d9aea 100644
--- a/kernel/sched/clock.c
+++ b/kernel/sched/clock.c
@@ -53,6 +53,7 @@
  *
  */
 #include "sched.h"
+#include <linux/sched_clock.h>
 
 /*
  * Scheduler clock - returns current time in nanosec units.
@@ -68,11 +69,6 @@ EXPORT_SYMBOL_GPL(sched_clock);
 
 __read_mostly int sched_clock_running;
 
-void sched_clock_init(void)
-{
-	sched_clock_running = 1;
-}
-
 #ifdef CONFIG_HAVE_UNSTABLE_SCHED_CLOCK
 /*
  * We must start with !__sched_clock_stable because the unstable -> stable
@@ -199,6 +195,15 @@ void clear_sched_clock_stable(void)
 		__clear_sched_clock_stable();
 }
 
+static void __sched_clock_gtod_offset(void)
+{
+	__gtod_offset = (sched_clock() + __sched_clock_offset) - ktime_get_ns();
+}
+
+void __init sched_clock_init(void)
+{
+	sched_clock_running = 1;
+}
 /*
  * We run this as late_initcall() such that it runs after all built-in drivers,
  * notably: acpi_processor and intel_idle, which can mark the TSC as unstable.
@@ -385,8 +390,6 @@ void sched_clock_tick(void)
 
 void sched_clock_tick_stable(void)
 {
-	u64 gtod, clock;
-
 	if (!sched_clock_stable())
 		return;
 
@@ -398,9 +401,7 @@ void sched_clock_tick_stable(void)
 	 * TSC to be unstable, any computation will be computing crap.
 	 */
 	local_irq_disable();
-	gtod = ktime_get_ns();
-	clock = sched_clock();
-	__gtod_offset = (clock + __sched_clock_offset) - gtod;
+	__sched_clock_gtod_offset();
 	local_irq_enable();
 }
 
@@ -434,6 +435,12 @@ EXPORT_SYMBOL_GPL(sched_clock_idle_wakeup_event);
 
 #else /* CONFIG_HAVE_UNSTABLE_SCHED_CLOCK */
 
+void __init sched_clock_init(void)
+{
+	sched_clock_running = 1;
+	generic_sched_clock_init();
+}
+
 u64 sched_clock_cpu(int cpu)
 {
 	if (unlikely(!sched_clock_running))
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 5b7fe01e78ee..8629bc356037 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -6441,7 +6441,6 @@ void __init sched_init(void)
 	unsigned long alloc_size = 0, ptr;
 	int i;
 
-	sched_clock_init();
 	wait_bit_init();
 
 #ifdef CONFIG_FAIR_GROUP_SCHED
diff --git a/kernel/time/sched_clock.c b/kernel/time/sched_clock.c
index 2eafbb8581fa..b0608d8d3891 100644
--- a/kernel/time/sched_clock.c
+++ b/kernel/time/sched_clock.c
@@ -238,7 +238,7 @@ sched_clock_register(u64 (*read)(void), int bits, unsigned long rate)
 	pr_debug("Registered %pF as sched_clock source\n", read);
 }
 
-void __init sched_clock_postinit(void)
+void __init generic_sched_clock_init(void)
 {
 	/*
 	 * If no sched_clock() function has been provided at that point,
