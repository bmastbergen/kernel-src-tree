trace/hwlat: Use trace_min_max_param for width and window params

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Daniel Bristot de Oliveira <bristot@redhat.com>
commit f27a1c9e1ba1e4f18f2c01e7bcbc400651ed821d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/f27a1c9e.failed

Use the trace_min_max_param to reduce code duplication.

No functional change.

Link: https://lkml.kernel.org/r/b91accd5a7c6c14ea02d3379aae974ba22b47dd6.1624372313.git.bristot@redhat.com

	Cc: Phil Auld <pauld@redhat.com>
	Cc: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
	Cc: Kate Carcia <kcarcia@redhat.com>
	Cc: Jonathan Corbet <corbet@lwn.net>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Alexandre Chartre <alexandre.chartre@oracle.com>
	Cc: Clark Willaims <williams@redhat.com>
	Cc: John Kacur <jkacur@redhat.com>
	Cc: Juri Lelli <juri.lelli@redhat.com>
	Cc: Borislav Petkov <bp@alien8.de>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: x86@kernel.org
	Cc: linux-doc@vger.kernel.org
	Cc: linux-kernel@vger.kernel.org
	Signed-off-by: Daniel Bristot de Oliveira <bristot@redhat.com>
	Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
(cherry picked from commit f27a1c9e1ba1e4f18f2c01e7bcbc400651ed821d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/trace/trace_hwlat.c
diff --cc kernel/trace/trace_hwlat.c
index 86a0e47cf098,44f46bc1140f..000000000000
--- a/kernel/trace/trace_hwlat.c
+++ b/kernel/trace/trace_hwlat.c
@@@ -378,141 -440,248 +378,284 @@@ static int start_kthread(struct trace_a
  	return 0;
  }
  
 -/*
 - * stop_cpu_kthread - Stop a hwlat cpu kthread
 +/**
 + * stop_kthread - Inform the hardware latency samping/detector kthread to stop
 + *
 + * This kicks the running hardware latency sampling/detector kernel thread and
 + * tells it to stop sampling now. Use this on unload and at system shutdown.
   */
 -static void stop_cpu_kthread(unsigned int cpu)
 +static void stop_kthread(void)
  {
 -	struct task_struct *kthread;
 -
 -	kthread = per_cpu(hwlat_per_cpu_data, cpu).kthread;
 -	if (kthread)
 -		kthread_stop(kthread);
 +	if (!hwlat_kthread)
 +		return;
 +	kthread_stop(hwlat_kthread);
 +	hwlat_kthread = NULL;
  }
  
++<<<<<<< HEAD
  /*
 - * stop_per_cpu_kthreads - Inform the hardware latency sampling/detector kthread to stop
 + * hwlat_read - Wrapper read function for reading both window and width
 + * @filp: The active open file structure
 + * @ubuf: The userspace provided buffer to read value into
 + * @cnt: The maximum number of bytes to read
 + * @ppos: The current "file" position
   *
 - * This kicks the running hardware latency sampling/detector kernel threads and
 - * tells it to stop sampling now. Use this on unload and at system shutdown.
 + * This function provides a generic read implementation for the global state
 + * "hwlat_data" structure filesystem entries.
   */
 -static void stop_per_cpu_kthreads(void)
 +static ssize_t hwlat_read(struct file *filp, char __user *ubuf,
 +			  size_t cnt, loff_t *ppos)
  {
 -	unsigned int cpu;
 +	char buf[U64STR_SIZE];
 +	u64 *entry = filp->private_data;
 +	u64 val;
 +	int len;
  
 -	get_online_cpus();
 -	for_each_online_cpu(cpu)
 -		stop_cpu_kthread(cpu);
 -	put_online_cpus();
 +	if (!entry)
 +		return -EFAULT;
 +
 +	if (cnt > sizeof(buf))
 +		cnt = sizeof(buf);
 +
 +	val = *entry;
 +
 +	len = snprintf(buf, sizeof(buf), "%llu\n", val);
 +
 +	return simple_read_from_buffer(ubuf, cnt, ppos, buf, len);
  }
  
 -/*
 - * start_cpu_kthread - Start a hwlat cpu kthread
 +/**
 + * hwlat_width_write - Write function for "width" entry
 + * @filp: The active open file structure
 + * @ubuf: The user buffer that contains the value to write
 + * @cnt: The maximum number of bytes to write to "file"
 + * @ppos: The current position in @file
 + *
 + * This function provides a write implementation for the "width" interface
 + * to the hardware latency detector. It can be used to configure
 + * for how many us of the total window us we will actively sample for any
 + * hardware-induced latency periods. Obviously, it is not possible to
 + * sample constantly and have the system respond to a sample reader, or,
 + * worse, without having the system appear to have gone out to lunch. It
 + * is enforced that width is less that the total window size.
   */
 -static int start_cpu_kthread(unsigned int cpu)
 +static ssize_t
 +hwlat_width_write(struct file *filp, const char __user *ubuf,
 +		  size_t cnt, loff_t *ppos)
  {
 -	struct task_struct *kthread;
 -	char comm[24];
 +	u64 val;
 +	int err;
  
 -	snprintf(comm, 24, "hwlatd/%d", cpu);
 +	err = kstrtoull_from_user(ubuf, cnt, 10, &val);
 +	if (err)
 +		return err;
  
 -	kthread = kthread_create_on_cpu(kthread_fn, NULL, cpu, comm);
 -	if (IS_ERR(kthread)) {
 -		pr_err(BANNER "could not start sampling thread\n");
 -		return -ENOMEM;
 -	}
 +	mutex_lock(&hwlat_data.lock);
 +	if (val < hwlat_data.sample_window)
 +		hwlat_data.sample_width = val;
 +	else
 +		err = -EINVAL;
 +	mutex_unlock(&hwlat_data.lock);
  
 -	per_cpu(hwlat_per_cpu_data, cpu).kthread = kthread;
 -	wake_up_process(kthread);
 +	if (err)
 +		return err;
  
 -	return 0;
 +	return cnt;
  }
  
 -/*
 - * start_per_cpu_kthreads - Kick off the hardware latency sampling/detector kthreads
 +/**
 + * hwlat_window_write - Write function for "window" entry
 + * @filp: The active open file structure
 + * @ubuf: The user buffer that contains the value to write
 + * @cnt: The maximum number of bytes to write to "file"
 + * @ppos: The current position in @file
   *
 - * This starts the kernel threads that will sit on potentially all cpus and
 - * sample the CPU timestamp counter (TSC or similar) and look for potential
 - * hardware latencies.
 + * This function provides a write implementation for the "window" interface
 + * to the hardware latency detetector. The window is the total time
 + * in us that will be considered one sample period. Conceptually, windows
 + * occur back-to-back and contain a sample width period during which
 + * actual sampling occurs. Can be used to write a new total window size. It
 + * is enfoced that any value written must be greater than the sample width
 + * size, or an error results.
   */
 -static int start_per_cpu_kthreads(struct trace_array *tr)
 +static ssize_t
 +hwlat_window_write(struct file *filp, const char __user *ubuf,
 +		   size_t cnt, loff_t *ppos)
  {
 -	struct cpumask *current_mask = &save_cpumask;
 -	unsigned int cpu;
 -	int retval;
 -
 -	get_online_cpus();
 -	/*
 -	 * Run only on CPUs in which hwlat is allowed to run.
 -	 */
 -	cpumask_and(current_mask, cpu_online_mask, tr->tracing_cpumask);
 +	u64 val;
 +	int err;
  
 -	for_each_online_cpu(cpu)
 -		per_cpu(hwlat_per_cpu_data, cpu).kthread = NULL;
 +	err = kstrtoull_from_user(ubuf, cnt, 10, &val);
 +	if (err)
 +		return err;
  
 -	for_each_cpu(cpu, current_mask) {
 -		retval = start_cpu_kthread(cpu);
 -		if (retval)
 -			goto out_error;
 -	}
 -	put_online_cpus();
 +	mutex_lock(&hwlat_data.lock);
 +	if (hwlat_data.sample_width < val)
 +		hwlat_data.sample_window = val;
 +	else
 +		err = -EINVAL;
 +	mutex_unlock(&hwlat_data.lock);
  
 -	return 0;
 +	if (err)
 +		return err;
  
 -out_error:
 -	put_online_cpus();
 -	stop_per_cpu_kthreads();
 -	return retval;
 +	return cnt;
  }
  
 +static const struct file_operations width_fops = {
 +	.open		= tracing_open_generic,
 +	.read		= hwlat_read,
 +	.write		= hwlat_width_write,
++=======
+ static void *s_mode_start(struct seq_file *s, loff_t *pos)
+ {
+ 	int mode = *pos;
+ 
+ 	mutex_lock(&hwlat_data.lock);
+ 
+ 	if (mode >= MODE_MAX)
+ 		return NULL;
+ 
+ 	return pos;
+ }
+ 
+ static void *s_mode_next(struct seq_file *s, void *v, loff_t *pos)
+ {
+ 	int mode = ++(*pos);
+ 
+ 	if (mode >= MODE_MAX)
+ 		return NULL;
+ 
+ 	return pos;
+ }
+ 
+ static int s_mode_show(struct seq_file *s, void *v)
+ {
+ 	loff_t *pos = v;
+ 	int mode = *pos;
+ 
+ 	if (mode == hwlat_data.thread_mode)
+ 		seq_printf(s, "[%s]", thread_mode_str[mode]);
+ 	else
+ 		seq_printf(s, "%s", thread_mode_str[mode]);
+ 
+ 	if (mode != MODE_MAX)
+ 		seq_puts(s, " ");
+ 
+ 	return 0;
+ }
+ 
+ static void s_mode_stop(struct seq_file *s, void *v)
+ {
+ 	seq_puts(s, "\n");
+ 	mutex_unlock(&hwlat_data.lock);
+ }
+ 
+ static const struct seq_operations thread_mode_seq_ops = {
+ 	.start		= s_mode_start,
+ 	.next		= s_mode_next,
+ 	.show		= s_mode_show,
+ 	.stop		= s_mode_stop
  };
  
- static const struct file_operations window_fops = {
- 	.open		= tracing_open_generic,
- 	.read		= hwlat_read,
- 	.write		= hwlat_window_write,
+ static int hwlat_mode_open(struct inode *inode, struct file *file)
+ {
+ 	return seq_open(file, &thread_mode_seq_ops);
+ };
+ 
+ static void hwlat_tracer_start(struct trace_array *tr);
+ static void hwlat_tracer_stop(struct trace_array *tr);
+ 
+ /**
+  * hwlat_mode_write - Write function for "mode" entry
+  * @filp: The active open file structure
+  * @ubuf: The user buffer that contains the value to write
+  * @cnt: The maximum number of bytes to write to "file"
+  * @ppos: The current position in @file
+  *
+  * This function provides a write implementation for the "mode" interface
+  * to the hardware latency detector. hwlatd has different operation modes.
+  * The "none" sets the allowed cpumask for a single hwlatd thread at the
+  * startup and lets the scheduler handle the migration. The default mode is
+  * the "round-robin" one, in which a single hwlatd thread runs, migrating
+  * among the allowed CPUs in a round-robin fashion. The "per-cpu" mode
+  * creates one hwlatd thread per allowed CPU.
+  */
+ static ssize_t hwlat_mode_write(struct file *filp, const char __user *ubuf,
+ 				 size_t cnt, loff_t *ppos)
+ {
+ 	struct trace_array *tr = hwlat_trace;
+ 	const char *mode;
+ 	char buf[64];
+ 	int ret, i;
+ 
+ 	if (cnt >= sizeof(buf))
+ 		return -EINVAL;
+ 
+ 	if (copy_from_user(buf, ubuf, cnt))
+ 		return -EFAULT;
+ 
+ 	buf[cnt] = 0;
+ 
+ 	mode = strstrip(buf);
+ 
+ 	ret = -EINVAL;
+ 
+ 	/*
+ 	 * trace_types_lock is taken to avoid concurrency on start/stop
+ 	 * and hwlat_busy.
+ 	 */
+ 	mutex_lock(&trace_types_lock);
+ 	if (hwlat_busy)
+ 		hwlat_tracer_stop(tr);
+ 
+ 	mutex_lock(&hwlat_data.lock);
+ 
+ 	for (i = 0; i < MODE_MAX; i++) {
+ 		if (strcmp(mode, thread_mode_str[i]) == 0) {
+ 			hwlat_data.thread_mode = i;
+ 			ret = cnt;
+ 		}
+ 	}
+ 
+ 	mutex_unlock(&hwlat_data.lock);
+ 
+ 	if (hwlat_busy)
+ 		hwlat_tracer_start(tr);
+ 	mutex_unlock(&trace_types_lock);
+ 
+ 	*ppos += cnt;
+ 
+ 
+ 
+ 	return ret;
+ }
+ 
+ /*
+  * The width parameter is read/write using the generic trace_min_max_param
+  * method. The *val is protected by the hwlat_data lock and is upper
+  * bounded by the window parameter.
+  */
+ static struct trace_min_max_param hwlat_width = {
+ 	.lock		= &hwlat_data.lock,
+ 	.val		= &hwlat_data.sample_width,
+ 	.max		= &hwlat_data.sample_window,
+ 	.min		= NULL,
++>>>>>>> f27a1c9e1ba1 (trace/hwlat: Use trace_min_max_param for width and window params)
+ };
+ 
+ /*
+  * The window parameter is read/write using the generic trace_min_max_param
+  * method. The *val is protected by the hwlat_data lock and is lower
+  * bounded by the width parameter.
+  */
+ static struct trace_min_max_param hwlat_window = {
+ 	.lock		= &hwlat_data.lock,
+ 	.val		= &hwlat_data.sample_window,
+ 	.max		= NULL,
+ 	.min		= &hwlat_data.sample_width,
  };
  
 -static const struct file_operations thread_mode_fops = {
 -	.open		= hwlat_mode_open,
 -	.read		= seq_read,
 -	.llseek		= seq_lseek,
 -	.release	= seq_release,
 -	.write		= hwlat_mode_write
 -};
  /**
   * init_tracefs - A function to initialize the tracefs interface files
   *
* Unmerged path kernel/trace/trace_hwlat.c
