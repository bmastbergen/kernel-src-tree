locking/rtmutex: Prevent lockdep false positive with PI futexes

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 51711e825a6d1b2fe7ca46bb06d08c25d97656ee
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/51711e82.failed

On PREEMPT_RT the futex hashbucket spinlock becomes 'sleeping' and rtmutex
based. That causes a lockdep false positive because some of the futex
functions invoke spin_unlock(&hb->lock) with the wait_lock of the rtmutex
associated to the pi_futex held.  spin_unlock() in turn takes wait_lock of
the rtmutex on which the spinlock is based which makes lockdep notice a
lock recursion.

Give the futex/rtmutex wait_lock a separate key.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
Link: https://lore.kernel.org/r/20210815211305.750701219@linutronix.de
(cherry picked from commit 51711e825a6d1b2fe7ca46bb06d08c25d97656ee)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/locking/rtmutex_api.c
diff --cc kernel/locking/rtmutex_api.c
index 0eaa83e405a1,5c9299aaabae..000000000000
--- a/kernel/locking/rtmutex_api.c
+++ b/kernel/locking/rtmutex_api.c
@@@ -205,10 -211,22 +205,26 @@@ EXPORT_SYMBOL_GPL(__rt_mutex_init)
   * possible at this point because the pi_state which contains the rtmutex
   * is not yet visible to other tasks.
   */
 -void __sched rt_mutex_init_proxy_locked(struct rt_mutex_base *lock,
 +void __sched rt_mutex_init_proxy_locked(struct rt_mutex *lock,
  					struct task_struct *proxy_owner)
  {
++<<<<<<< HEAD
 +	__rt_mutex_basic_init(lock);
++=======
+ 	static struct lock_class_key pi_futex_key;
+ 
+ 	__rt_mutex_base_init(lock);
+ 	/*
+ 	 * On PREEMPT_RT the futex hashbucket spinlock becomes 'sleeping'
+ 	 * and rtmutex based. That causes a lockdep false positive, because
+ 	 * some of the futex functions invoke spin_unlock(&hb->lock) with
+ 	 * the wait_lock of the rtmutex associated to the pi_futex held.
+ 	 * spin_unlock() in turn takes wait_lock of the rtmutex on which
+ 	 * the spinlock is based, which makes lockdep notice a lock
+ 	 * recursion. Give the futex/rtmutex wait_lock a separate key.
+ 	 */
+ 	lockdep_set_class(&lock->wait_lock, &pi_futex_key);
++>>>>>>> 51711e825a6d (locking/rtmutex: Prevent lockdep false positive with PI futexes)
  	rt_mutex_set_owner(lock, proxy_owner);
  }
  
* Unmerged path kernel/locking/rtmutex_api.c
