iommu/vt-d: Refactor prq_event_thread()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Lu Baolu <baolu.lu@linux.intel.com>
commit ae7f09b14b4ff18f65790a906d7c2fe2561568b5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/ae7f09b1.failed

Refactor prq_event_thread() by moving handling single prq event out of
the main loop.

	Signed-off-by: Lu Baolu <baolu.lu@linux.intel.com>
Link: https://lore.kernel.org/r/20210520031531.712333-1-baolu.lu@linux.intel.com
Link: https://lore.kernel.org/r/20210610020115.1637656-10-baolu.lu@linux.intel.com
	Signed-off-by: Joerg Roedel <jroedel@suse.de>
(cherry picked from commit ae7f09b14b4ff18f65790a906d7c2fe2561568b5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/iommu/intel/svm.c
diff --cc drivers/iommu/intel/svm.c
index bdd69ea8edbc,d51ddece4259..000000000000
--- a/drivers/iommu/intel/svm.c
+++ b/drivers/iommu/intel/svm.c
@@@ -956,60 -1033,7 +1042,64 @@@ bad_req
  				goto bad_req;
  		}
  
++<<<<<<< HEAD
 +		/* If the mm is already defunct, don't handle faults. */
 +		if (!mmget_not_zero(svm->mm))
 +			goto bad_req;
 +
 +		mmap_read_lock(svm->mm);
 +		vma = find_extend_vma(svm->mm, address);
 +		if (!vma || address < vma->vm_start)
 +			goto invalid;
 +
 +		if (access_error(vma, req))
 +			goto invalid;
 +
 +		flags = FAULT_FLAG_USER | FAULT_FLAG_REMOTE;
 +		if (req->wr_req)
 +			flags |= FAULT_FLAG_WRITE;
 +
 +		ret = handle_mm_fault(vma, address, flags);
 +		if (ret & VM_FAULT_ERROR)
 +			goto invalid;
 +
 +		result = QI_RESP_SUCCESS;
 +invalid:
 +		mmap_read_unlock(svm->mm);
 +		mmput(svm->mm);
 +bad_req:
 +		/* We get here in the error case where the PASID lookup failed,
 +		   and these can be NULL. Do not use them below this point! */
 +		sdev = NULL;
 +		svm = NULL;
 +no_pasid:
 +		if (req->lpig || req->priv_data_present) {
 +			/*
 +			 * Per VT-d spec. v3.0 ch7.7, system software must
 +			 * respond with page group response if private data
 +			 * is present (PDP) or last page in group (LPIG) bit
 +			 * is set. This is an additional VT-d feature beyond
 +			 * PCI ATS spec.
 +			 */
 +			resp.qw0 = QI_PGRP_PASID(req->pasid) |
 +				QI_PGRP_DID(req->rid) |
 +				QI_PGRP_PASID_P(req->pasid_present) |
 +				QI_PGRP_PDP(req->priv_data_present) |
 +				QI_PGRP_RESP_CODE(result) |
 +				QI_PGRP_RESP_TYPE;
 +			resp.qw1 = QI_PGRP_IDX(req->prg_index) |
 +				QI_PGRP_LPIG(req->lpig);
 +			resp.qw2 = 0;
 +			resp.qw3 = 0;
 +
 +			if (req->priv_data_present)
 +				memcpy(&resp.qw2, req->priv_data,
 +				       sizeof(req->priv_data));
 +			qi_submit_sync(iommu, &resp, 1, 0);
 +		}
++=======
+ 		handle_single_prq_event(iommu, svm->mm, req);
++>>>>>>> ae7f09b14b4f (iommu/vt-d: Refactor prq_event_thread())
  prq_advance:
  		head = (head + sizeof(*req)) & PRQ_RING_MASK;
  	}
* Unmerged path drivers/iommu/intel/svm.c
