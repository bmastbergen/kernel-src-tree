rcu/tree: segcblist: Remove redundant smp_mb()s

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Joel Fernandes (Google) <joel@joelfernandes.org>
commit 68804cf1c905ce227e4e1d0bc252c216811c59fd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/68804cf1.failed

The full memory barriers in rcu_segcblist_enqueue() and in rcu_do_batch()
are not needed because rcu_segcblist_add_len(), and thus also
rcu_segcblist_inc_len(), already includes a memory barrier *before*
and *after* the length of the list is updated.

This commit therefore removes these redundant smp_mb() invocations.

	Reviewed-by: Frederic Weisbecker <frederic@kernel.org>
	Signed-off-by: Joel Fernandes (Google) <joel@joelfernandes.org>
	Signed-off-by: Paul E. McKenney <paulmck@kernel.org>
(cherry picked from commit 68804cf1c905ce227e4e1d0bc252c216811c59fd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/rcu/rcu_segcblist.c
diff --cc kernel/rcu/rcu_segcblist.c
index 66c440083921,1e80a0a9036a..000000000000
--- a/kernel/rcu/rcu_segcblist.c
+++ b/kernel/rcu/rcu_segcblist.c
@@@ -318,7 -327,7 +318,11 @@@ void rcu_segcblist_enqueue(struct rcu_s
  			   struct rcu_head *rhp)
  {
  	rcu_segcblist_inc_len(rsclp);
++<<<<<<< HEAD
 +	smp_mb(); /* Ensure counts are updated before callback is enqueued. */
++=======
+ 	rcu_segcblist_inc_seglen(rsclp, RCU_NEXT_TAIL);
++>>>>>>> 68804cf1c905 (rcu/tree: segcblist: Remove redundant smp_mb()s)
  	rhp->next = NULL;
  	WRITE_ONCE(*rsclp->tails[RCU_NEXT_TAIL], rhp);
  	WRITE_ONCE(rsclp->tails[RCU_NEXT_TAIL], &rhp->next);
* Unmerged path kernel/rcu/rcu_segcblist.c
diff --git a/kernel/rcu/tree.c b/kernel/rcu/tree.c
index a5ba4f758832..39377ba0e060 100644
--- a/kernel/rcu/tree.c
+++ b/kernel/rcu/tree.c
@@ -2470,7 +2470,6 @@ static void rcu_do_batch(struct rcu_data *rdp)
 
 	/* Update counts and requeue any remaining callbacks. */
 	rcu_segcblist_insert_done_cbs(&rdp->cblist, &rcl);
-	smp_mb(); /* List handling before counting for rcu_barrier(). */
 	rcu_segcblist_add_len(&rdp->cblist, -count);
 
 	/* Reinstate batch limit if we have worked down the excess. */
