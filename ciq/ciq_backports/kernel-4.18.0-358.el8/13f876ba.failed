highmem: High implementation details and document API

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 13f876ba77ebd5125799bb042201f22cf73df154
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/13f876ba.failed

Move the gory details of kmap & al into a private header and only document
the interfaces which are usable by drivers.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: Linus Torvalds <torvalds@linuxfoundation.org>
	Cc: Christoph Hellwig <hch@lst.de>
	Cc: Andrew Morton <akpm@linux-foundation.org>
Link: https://lore.kernel.org/r/20201103095858.827582066@linutronix.de

(cherry picked from commit 13f876ba77ebd5125799bb042201f22cf73df154)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/highmem.h
diff --cc include/linux/highmem.h
index b1641d4ce279,7d098bd621f6..000000000000
--- a/include/linux/highmem.h
+++ b/include/linux/highmem.h
@@@ -29,120 -131,6 +131,123 @@@ static inline void invalidate_kernel_vm
  }
  #endif
  
++<<<<<<< HEAD
 +#include <asm/kmap_types.h>
 +
 +#ifdef CONFIG_HIGHMEM
 +#include <asm/highmem.h>
 +
 +/* declarations for linux/mm/highmem.c */
 +unsigned int nr_free_highpages(void);
 +extern atomic_long_t _totalhigh_pages;
 +static inline unsigned long totalhigh_pages(void)
 +{
 +	return (unsigned long)atomic_long_read(&_totalhigh_pages);
 +}
 +
 +static inline void totalhigh_pages_inc(void)
 +{
 +	atomic_long_inc(&_totalhigh_pages);
 +}
 +
 +static inline void totalhigh_pages_add(long count)
 +{
 +	atomic_long_add(count, &_totalhigh_pages);
 +}
 +
 +void kmap_flush_unused(void);
 +
 +struct page *kmap_to_page(void *addr);
 +
 +#else /* CONFIG_HIGHMEM */
 +
 +static inline unsigned int nr_free_highpages(void) { return 0; }
 +
 +static inline struct page *kmap_to_page(void *addr)
 +{
 +	return virt_to_page(addr);
 +}
 +
 +static inline unsigned long totalhigh_pages(void) { return 0UL; }
 +
 +#ifndef ARCH_HAS_KMAP
 +static inline void *kmap(struct page *page)
 +{
 +	might_sleep();
 +	return page_address(page);
 +}
 +
 +static inline void kunmap(struct page *page)
 +{
 +}
 +
 +static inline void *kmap_atomic(struct page *page)
 +{
 +	preempt_disable();
 +	pagefault_disable();
 +	return page_address(page);
 +}
 +#define kmap_atomic_prot(page, prot)	kmap_atomic(page)
 +
 +static inline void __kunmap_atomic(void *addr)
 +{
 +	pagefault_enable();
 +	preempt_enable();
 +}
 +
 +#define kmap_atomic_pfn(pfn)	kmap_atomic(pfn_to_page(pfn))
 +
 +#define kmap_flush_unused()	do {} while(0)
 +#endif
 +
 +#endif /* CONFIG_HIGHMEM */
 +
 +#if defined(CONFIG_HIGHMEM) || defined(CONFIG_X86_32)
 +
 +DECLARE_PER_CPU(int, __kmap_atomic_idx);
 +
 +static inline int kmap_atomic_idx_push(void)
 +{
 +	int idx = __this_cpu_inc_return(__kmap_atomic_idx) - 1;
 +
 +#ifdef CONFIG_DEBUG_HIGHMEM
 +	WARN_ON_ONCE(in_irq() && !irqs_disabled());
 +	BUG_ON(idx >= KM_TYPE_NR);
 +#endif
 +	return idx;
 +}
 +
 +static inline int kmap_atomic_idx(void)
 +{
 +	return __this_cpu_read(__kmap_atomic_idx) - 1;
 +}
 +
 +static inline void kmap_atomic_idx_pop(void)
 +{
 +#ifdef CONFIG_DEBUG_HIGHMEM
 +	int idx = __this_cpu_dec_return(__kmap_atomic_idx);
 +
 +	BUG_ON(idx < 0);
 +#else
 +	__this_cpu_dec(__kmap_atomic_idx);
 +#endif
 +}
 +
 +#endif
 +
 +/*
 + * Prevent people trying to call kunmap_atomic() as if it were kunmap()
 + * kunmap_atomic() should get the return value of kmap_atomic, not the page.
 + */
 +#define kunmap_atomic(addr)                                     \
 +do {                                                            \
 +	BUILD_BUG_ON(__same_type((addr), struct page *));       \
 +	__kunmap_atomic(addr);                                  \
 +} while (0)
 +
 +
++=======
++>>>>>>> 13f876ba77eb (highmem: High implementation details and document API)
  /* when CONFIG_HIGHMEM is not set these will be plain clear/copy_page */
  #ifndef clear_user_highpage
  static inline void clear_user_highpage(struct page *page, unsigned long vaddr)
diff --git a/include/linux/highmem-internal.h b/include/linux/highmem-internal.h
new file mode 100644
index 000000000000..6ceed907b14e
--- /dev/null
+++ b/include/linux/highmem-internal.h
@@ -0,0 +1,174 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef _LINUX_HIGHMEM_INTERNAL_H
+#define _LINUX_HIGHMEM_INTERNAL_H
+
+/*
+ * Outside of CONFIG_HIGHMEM to support X86 32bit iomap_atomic() cruft.
+ */
+#ifdef CONFIG_KMAP_LOCAL
+void *__kmap_local_pfn_prot(unsigned long pfn, pgprot_t prot);
+void *__kmap_local_page_prot(struct page *page, pgprot_t prot);
+void kunmap_local_indexed(void *vaddr);
+#endif
+
+#ifdef CONFIG_HIGHMEM
+#include <asm/highmem.h>
+
+#ifndef ARCH_HAS_KMAP_FLUSH_TLB
+static inline void kmap_flush_tlb(unsigned long addr) { }
+#endif
+
+#ifndef kmap_prot
+#define kmap_prot PAGE_KERNEL
+#endif
+
+void *kmap_high(struct page *page);
+void kunmap_high(struct page *page);
+void __kmap_flush_unused(void);
+struct page *__kmap_to_page(void *addr);
+
+static inline void *kmap(struct page *page)
+{
+	void *addr;
+
+	might_sleep();
+	if (!PageHighMem(page))
+		addr = page_address(page);
+	else
+		addr = kmap_high(page);
+	kmap_flush_tlb((unsigned long)addr);
+	return addr;
+}
+
+static inline void kunmap(struct page *page)
+{
+	might_sleep();
+	if (!PageHighMem(page))
+		return;
+	kunmap_high(page);
+}
+
+static inline struct page *kmap_to_page(void *addr)
+{
+	return __kmap_to_page(addr);
+}
+
+static inline void kmap_flush_unused(void)
+{
+	__kmap_flush_unused();
+}
+
+static inline void *kmap_atomic_prot(struct page *page, pgprot_t prot)
+{
+	preempt_disable();
+	pagefault_disable();
+	return __kmap_local_page_prot(page, prot);
+}
+
+static inline void *kmap_atomic(struct page *page)
+{
+	return kmap_atomic_prot(page, kmap_prot);
+}
+
+static inline void *kmap_atomic_pfn(unsigned long pfn)
+{
+	preempt_disable();
+	pagefault_disable();
+	return __kmap_local_pfn_prot(pfn, kmap_prot);
+}
+
+static inline void __kunmap_atomic(void *addr)
+{
+	kunmap_local_indexed(addr);
+	pagefault_enable();
+	preempt_enable();
+}
+
+unsigned int __nr_free_highpages(void);
+extern atomic_long_t _totalhigh_pages;
+
+static inline unsigned int nr_free_highpages(void)
+{
+	return __nr_free_highpages();
+}
+
+static inline unsigned long totalhigh_pages(void)
+{
+	return (unsigned long)atomic_long_read(&_totalhigh_pages);
+}
+
+static inline void totalhigh_pages_inc(void)
+{
+	atomic_long_inc(&_totalhigh_pages);
+}
+
+static inline void totalhigh_pages_add(long count)
+{
+	atomic_long_add(count, &_totalhigh_pages);
+}
+
+#else /* CONFIG_HIGHMEM */
+
+static inline struct page *kmap_to_page(void *addr)
+{
+	return virt_to_page(addr);
+}
+
+static inline void *kmap(struct page *page)
+{
+	might_sleep();
+	return page_address(page);
+}
+
+static inline void kunmap_high(struct page *page) { }
+static inline void kmap_flush_unused(void) { }
+
+static inline void kunmap(struct page *page)
+{
+#ifdef ARCH_HAS_FLUSH_ON_KUNMAP
+	kunmap_flush_on_unmap(page_address(page));
+#endif
+}
+
+static inline void *kmap_atomic(struct page *page)
+{
+	preempt_disable();
+	pagefault_disable();
+	return page_address(page);
+}
+
+static inline void *kmap_atomic_prot(struct page *page, pgprot_t prot)
+{
+	return kmap_atomic(page);
+}
+
+static inline void *kmap_atomic_pfn(unsigned long pfn)
+{
+	return kmap_atomic(pfn_to_page(pfn));
+}
+
+static inline void __kunmap_atomic(void *addr)
+{
+#ifdef ARCH_HAS_FLUSH_ON_KUNMAP
+	kunmap_flush_on_unmap(addr);
+#endif
+	pagefault_enable();
+	preempt_enable();
+}
+
+static inline unsigned int nr_free_highpages(void) { return 0; }
+static inline unsigned long totalhigh_pages(void) { return 0UL; }
+
+#endif /* CONFIG_HIGHMEM */
+
+/*
+ * Prevent people trying to call kunmap_atomic() as if it were kunmap()
+ * kunmap_atomic() should get the return value of kmap_atomic, not the page.
+ */
+#define kunmap_atomic(__addr)					\
+do {								\
+	BUILD_BUG_ON(__same_type((__addr), struct page *));	\
+	__kunmap_atomic(__addr);				\
+} while (0)
+
+#endif
* Unmerged path include/linux/highmem.h
diff --git a/mm/highmem.c b/mm/highmem.c
index 51171d0f44c2..ece808e11109 100644
--- a/mm/highmem.c
+++ b/mm/highmem.c
@@ -108,7 +108,7 @@ static inline wait_queue_head_t *get_pkmap_wait_queue_head(unsigned int color)
 atomic_long_t _totalhigh_pages __read_mostly;
 EXPORT_SYMBOL(_totalhigh_pages);
 
-unsigned int nr_free_highpages (void)
+unsigned int __nr_free_highpages (void)
 {
 	struct zone *zone;
 	unsigned int pages = 0;
@@ -145,7 +145,7 @@ pte_t * pkmap_page_table;
 		do { spin_unlock(&kmap_lock); (void)(flags); } while (0)
 #endif
 
-struct page *kmap_to_page(void *vaddr)
+struct page *__kmap_to_page(void *vaddr)
 {
 	unsigned long addr = (unsigned long)vaddr;
 
@@ -156,7 +156,7 @@ struct page *kmap_to_page(void *vaddr)
 
 	return virt_to_page(addr);
 }
-EXPORT_SYMBOL(kmap_to_page);
+EXPORT_SYMBOL(__kmap_to_page);
 
 static void flush_all_zero_pkmaps(void)
 {
@@ -198,10 +198,7 @@ static void flush_all_zero_pkmaps(void)
 		flush_tlb_kernel_range(PKMAP_ADDR(0), PKMAP_ADDR(LAST_PKMAP));
 }
 
-/**
- * kmap_flush_unused - flush all unused kmap mappings in order to remove stray mappings
- */
-void kmap_flush_unused(void)
+void __kmap_flush_unused(void)
 {
 	lock_kmap();
 	flush_all_zero_pkmaps();
