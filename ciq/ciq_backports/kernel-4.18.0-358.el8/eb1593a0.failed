net: bridge: multicast: use the port group to port context helper

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Nikolay Aleksandrov <nikolay@nvidia.com>
commit eb1593a0b4c49443acbe2ebaa7a9947fa5471c01
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/eb1593a0.failed

We need to use the new port group to port context helper in places where
we cannot pass down the proper context (i.e. functions that can be
called by timers or outside the packet snooping paths).

	Signed-off-by: Nikolay Aleksandrov <nikolay@nvidia.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit eb1593a0b4c49443acbe2ebaa7a9947fa5471c01)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/bridge/br_multicast.c
diff --cc net/bridge/br_multicast.c
index def6f1840985,e61e23c0ce17..000000000000
--- a/net/bridge/br_multicast.c
+++ b/net/bridge/br_multicast.c
@@@ -147,6 -192,389 +147,392 @@@ struct net_bridge_mdb_entry *br_mdb_get
  	return br_mdb_ip_get_rcu(br, &ip);
  }
  
++<<<<<<< HEAD
++=======
+ /* IMPORTANT: this function must be used only when the contexts cannot be
+  * passed down (e.g. timer) and must be used for read-only purposes because
+  * the vlan snooping option can change, so it can return any context
+  * (non-vlan or vlan). Its initial intended purpose is to read timer values
+  * from the *current* context based on the option. At worst that could lead
+  * to inconsistent timers when the contexts are changed, i.e. src timer
+  * which needs to re-arm with a specific delay taken from the old context
+  */
+ static struct net_bridge_mcast_port *
+ br_multicast_pg_to_port_ctx(const struct net_bridge_port_group *pg)
+ {
+ 	struct net_bridge_mcast_port *pmctx = &pg->key.port->multicast_ctx;
+ 	struct net_bridge_vlan *vlan;
+ 
+ 	lockdep_assert_held_once(&pg->key.port->br->multicast_lock);
+ 
+ 	/* if vlan snooping is disabled use the port's multicast context */
+ 	if (!pg->key.addr.vid ||
+ 	    !br_opt_get(pg->key.port->br, BROPT_MCAST_VLAN_SNOOPING_ENABLED))
+ 		goto out;
+ 
+ 	/* locking is tricky here, due to different rules for multicast and
+ 	 * vlans we need to take rcu to find the vlan and make sure it has
+ 	 * the BR_VLFLAG_MCAST_ENABLED flag set, it can only change under
+ 	 * multicast_lock which must be already held here, so the vlan's pmctx
+ 	 * can safely be used on return
+ 	 */
+ 	rcu_read_lock();
+ 	vlan = br_vlan_find(nbp_vlan_group(pg->key.port), pg->key.addr.vid);
+ 	if (vlan && !br_multicast_port_ctx_vlan_disabled(&vlan->port_mcast_ctx))
+ 		pmctx = &vlan->port_mcast_ctx;
+ 	else
+ 		pmctx = NULL;
+ 	rcu_read_unlock();
+ out:
+ 	return pmctx;
+ }
+ 
+ static bool br_port_group_equal(struct net_bridge_port_group *p,
+ 				struct net_bridge_port *port,
+ 				const unsigned char *src)
+ {
+ 	if (p->key.port != port)
+ 		return false;
+ 
+ 	if (!(port->flags & BR_MULTICAST_TO_UNICAST))
+ 		return true;
+ 
+ 	return ether_addr_equal(src, p->eth_addr);
+ }
+ 
+ static void __fwd_add_star_excl(struct net_bridge_mcast_port *pmctx,
+ 				struct net_bridge_port_group *pg,
+ 				struct br_ip *sg_ip)
+ {
+ 	struct net_bridge_port_group_sg_key sg_key;
+ 	struct net_bridge_port_group *src_pg;
+ 	struct net_bridge_mcast *brmctx;
+ 
+ 	memset(&sg_key, 0, sizeof(sg_key));
+ 	brmctx = br_multicast_port_ctx_get_global(pmctx);
+ 	sg_key.port = pg->key.port;
+ 	sg_key.addr = *sg_ip;
+ 	if (br_sg_port_find(brmctx->br, &sg_key))
+ 		return;
+ 
+ 	src_pg = __br_multicast_add_group(brmctx, pmctx,
+ 					  sg_ip, pg->eth_addr,
+ 					  MCAST_INCLUDE, false, false);
+ 	if (IS_ERR_OR_NULL(src_pg) ||
+ 	    src_pg->rt_protocol != RTPROT_KERNEL)
+ 		return;
+ 
+ 	src_pg->flags |= MDB_PG_FLAGS_STAR_EXCL;
+ }
+ 
+ static void __fwd_del_star_excl(struct net_bridge_port_group *pg,
+ 				struct br_ip *sg_ip)
+ {
+ 	struct net_bridge_port_group_sg_key sg_key;
+ 	struct net_bridge *br = pg->key.port->br;
+ 	struct net_bridge_port_group *src_pg;
+ 
+ 	memset(&sg_key, 0, sizeof(sg_key));
+ 	sg_key.port = pg->key.port;
+ 	sg_key.addr = *sg_ip;
+ 	src_pg = br_sg_port_find(br, &sg_key);
+ 	if (!src_pg || !(src_pg->flags & MDB_PG_FLAGS_STAR_EXCL) ||
+ 	    src_pg->rt_protocol != RTPROT_KERNEL)
+ 		return;
+ 
+ 	br_multicast_find_del_pg(br, src_pg);
+ }
+ 
+ /* When a port group transitions to (or is added as) EXCLUDE we need to add it
+  * to all other ports' S,G entries which are not blocked by the current group
+  * for proper replication, the assumption is that any S,G blocked entries
+  * are already added so the S,G,port lookup should skip them.
+  * When a port group transitions from EXCLUDE -> INCLUDE mode or is being
+  * deleted we need to remove it from all ports' S,G entries where it was
+  * automatically installed before (i.e. where it's MDB_PG_FLAGS_STAR_EXCL).
+  */
+ void br_multicast_star_g_handle_mode(struct net_bridge_port_group *pg,
+ 				     u8 filter_mode)
+ {
+ 	struct net_bridge *br = pg->key.port->br;
+ 	struct net_bridge_port_group *pg_lst;
+ 	struct net_bridge_mcast_port *pmctx;
+ 	struct net_bridge_mdb_entry *mp;
+ 	struct br_ip sg_ip;
+ 
+ 	if (WARN_ON(!br_multicast_is_star_g(&pg->key.addr)))
+ 		return;
+ 
+ 	mp = br_mdb_ip_get(br, &pg->key.addr);
+ 	if (!mp)
+ 		return;
+ 	pmctx = br_multicast_pg_to_port_ctx(pg);
+ 	if (!pmctx)
+ 		return;
+ 
+ 	memset(&sg_ip, 0, sizeof(sg_ip));
+ 	sg_ip = pg->key.addr;
+ 
+ 	for (pg_lst = mlock_dereference(mp->ports, br);
+ 	     pg_lst;
+ 	     pg_lst = mlock_dereference(pg_lst->next, br)) {
+ 		struct net_bridge_group_src *src_ent;
+ 
+ 		if (pg_lst == pg)
+ 			continue;
+ 		hlist_for_each_entry(src_ent, &pg_lst->src_list, node) {
+ 			if (!(src_ent->flags & BR_SGRP_F_INSTALLED))
+ 				continue;
+ 			sg_ip.src = src_ent->addr.src;
+ 			switch (filter_mode) {
+ 			case MCAST_INCLUDE:
+ 				__fwd_del_star_excl(pg, &sg_ip);
+ 				break;
+ 			case MCAST_EXCLUDE:
+ 				__fwd_add_star_excl(pmctx, pg, &sg_ip);
+ 				break;
+ 			}
+ 		}
+ 	}
+ }
+ 
+ /* called when adding a new S,G with host_joined == false by default */
+ static void br_multicast_sg_host_state(struct net_bridge_mdb_entry *star_mp,
+ 				       struct net_bridge_port_group *sg)
+ {
+ 	struct net_bridge_mdb_entry *sg_mp;
+ 
+ 	if (WARN_ON(!br_multicast_is_star_g(&star_mp->addr)))
+ 		return;
+ 	if (!star_mp->host_joined)
+ 		return;
+ 
+ 	sg_mp = br_mdb_ip_get(star_mp->br, &sg->key.addr);
+ 	if (!sg_mp)
+ 		return;
+ 	sg_mp->host_joined = true;
+ }
+ 
+ /* set the host_joined state of all of *,G's S,G entries */
+ static void br_multicast_star_g_host_state(struct net_bridge_mdb_entry *star_mp)
+ {
+ 	struct net_bridge *br = star_mp->br;
+ 	struct net_bridge_mdb_entry *sg_mp;
+ 	struct net_bridge_port_group *pg;
+ 	struct br_ip sg_ip;
+ 
+ 	if (WARN_ON(!br_multicast_is_star_g(&star_mp->addr)))
+ 		return;
+ 
+ 	memset(&sg_ip, 0, sizeof(sg_ip));
+ 	sg_ip = star_mp->addr;
+ 	for (pg = mlock_dereference(star_mp->ports, br);
+ 	     pg;
+ 	     pg = mlock_dereference(pg->next, br)) {
+ 		struct net_bridge_group_src *src_ent;
+ 
+ 		hlist_for_each_entry(src_ent, &pg->src_list, node) {
+ 			if (!(src_ent->flags & BR_SGRP_F_INSTALLED))
+ 				continue;
+ 			sg_ip.src = src_ent->addr.src;
+ 			sg_mp = br_mdb_ip_get(br, &sg_ip);
+ 			if (!sg_mp)
+ 				continue;
+ 			sg_mp->host_joined = star_mp->host_joined;
+ 		}
+ 	}
+ }
+ 
+ static void br_multicast_sg_del_exclude_ports(struct net_bridge_mdb_entry *sgmp)
+ {
+ 	struct net_bridge_port_group __rcu **pp;
+ 	struct net_bridge_port_group *p;
+ 
+ 	/* *,G exclude ports are only added to S,G entries */
+ 	if (WARN_ON(br_multicast_is_star_g(&sgmp->addr)))
+ 		return;
+ 
+ 	/* we need the STAR_EXCLUDE ports if there are non-STAR_EXCLUDE ports
+ 	 * we should ignore perm entries since they're managed by user-space
+ 	 */
+ 	for (pp = &sgmp->ports;
+ 	     (p = mlock_dereference(*pp, sgmp->br)) != NULL;
+ 	     pp = &p->next)
+ 		if (!(p->flags & (MDB_PG_FLAGS_STAR_EXCL |
+ 				  MDB_PG_FLAGS_PERMANENT)))
+ 			return;
+ 
+ 	/* currently the host can only have joined the *,G which means
+ 	 * we treat it as EXCLUDE {}, so for an S,G it's considered a
+ 	 * STAR_EXCLUDE entry and we can safely leave it
+ 	 */
+ 	sgmp->host_joined = false;
+ 
+ 	for (pp = &sgmp->ports;
+ 	     (p = mlock_dereference(*pp, sgmp->br)) != NULL;) {
+ 		if (!(p->flags & MDB_PG_FLAGS_PERMANENT))
+ 			br_multicast_del_pg(sgmp, p, pp);
+ 		else
+ 			pp = &p->next;
+ 	}
+ }
+ 
+ void br_multicast_sg_add_exclude_ports(struct net_bridge_mdb_entry *star_mp,
+ 				       struct net_bridge_port_group *sg)
+ {
+ 	struct net_bridge_port_group_sg_key sg_key;
+ 	struct net_bridge *br = star_mp->br;
+ 	struct net_bridge_mcast_port *pmctx;
+ 	struct net_bridge_port_group *pg;
+ 	struct net_bridge_mcast *brmctx;
+ 
+ 	if (WARN_ON(br_multicast_is_star_g(&sg->key.addr)))
+ 		return;
+ 	if (WARN_ON(!br_multicast_is_star_g(&star_mp->addr)))
+ 		return;
+ 
+ 	br_multicast_sg_host_state(star_mp, sg);
+ 	memset(&sg_key, 0, sizeof(sg_key));
+ 	sg_key.addr = sg->key.addr;
+ 	/* we need to add all exclude ports to the S,G */
+ 	for (pg = mlock_dereference(star_mp->ports, br);
+ 	     pg;
+ 	     pg = mlock_dereference(pg->next, br)) {
+ 		struct net_bridge_port_group *src_pg;
+ 
+ 		if (pg == sg || pg->filter_mode == MCAST_INCLUDE)
+ 			continue;
+ 
+ 		sg_key.port = pg->key.port;
+ 		if (br_sg_port_find(br, &sg_key))
+ 			continue;
+ 
+ 		pmctx = br_multicast_pg_to_port_ctx(pg);
+ 		if (!pmctx)
+ 			continue;
+ 		brmctx = br_multicast_port_ctx_get_global(pmctx);
+ 
+ 		src_pg = __br_multicast_add_group(brmctx, pmctx,
+ 						  &sg->key.addr,
+ 						  sg->eth_addr,
+ 						  MCAST_INCLUDE, false, false);
+ 		if (IS_ERR_OR_NULL(src_pg) ||
+ 		    src_pg->rt_protocol != RTPROT_KERNEL)
+ 			continue;
+ 		src_pg->flags |= MDB_PG_FLAGS_STAR_EXCL;
+ 	}
+ }
+ 
+ static void br_multicast_fwd_src_add(struct net_bridge_group_src *src)
+ {
+ 	struct net_bridge_mdb_entry *star_mp;
+ 	struct net_bridge_mcast_port *pmctx;
+ 	struct net_bridge_port_group *sg;
+ 	struct net_bridge_mcast *brmctx;
+ 	struct br_ip sg_ip;
+ 
+ 	if (src->flags & BR_SGRP_F_INSTALLED)
+ 		return;
+ 
+ 	memset(&sg_ip, 0, sizeof(sg_ip));
+ 	pmctx = br_multicast_pg_to_port_ctx(src->pg);
+ 	if (!pmctx)
+ 		return;
+ 	brmctx = br_multicast_port_ctx_get_global(pmctx);
+ 	sg_ip = src->pg->key.addr;
+ 	sg_ip.src = src->addr.src;
+ 
+ 	sg = __br_multicast_add_group(brmctx, pmctx, &sg_ip,
+ 				      src->pg->eth_addr, MCAST_INCLUDE, false,
+ 				      !timer_pending(&src->timer));
+ 	if (IS_ERR_OR_NULL(sg))
+ 		return;
+ 	src->flags |= BR_SGRP_F_INSTALLED;
+ 	sg->flags &= ~MDB_PG_FLAGS_STAR_EXCL;
+ 
+ 	/* if it was added by user-space as perm we can skip next steps */
+ 	if (sg->rt_protocol != RTPROT_KERNEL &&
+ 	    (sg->flags & MDB_PG_FLAGS_PERMANENT))
+ 		return;
+ 
+ 	/* the kernel is now responsible for removing this S,G */
+ 	del_timer(&sg->timer);
+ 	star_mp = br_mdb_ip_get(src->br, &src->pg->key.addr);
+ 	if (!star_mp)
+ 		return;
+ 
+ 	br_multicast_sg_add_exclude_ports(star_mp, sg);
+ }
+ 
+ static void br_multicast_fwd_src_remove(struct net_bridge_group_src *src,
+ 					bool fastleave)
+ {
+ 	struct net_bridge_port_group *p, *pg = src->pg;
+ 	struct net_bridge_port_group __rcu **pp;
+ 	struct net_bridge_mdb_entry *mp;
+ 	struct br_ip sg_ip;
+ 
+ 	memset(&sg_ip, 0, sizeof(sg_ip));
+ 	sg_ip = pg->key.addr;
+ 	sg_ip.src = src->addr.src;
+ 
+ 	mp = br_mdb_ip_get(src->br, &sg_ip);
+ 	if (!mp)
+ 		return;
+ 
+ 	for (pp = &mp->ports;
+ 	     (p = mlock_dereference(*pp, src->br)) != NULL;
+ 	     pp = &p->next) {
+ 		if (!br_port_group_equal(p, pg->key.port, pg->eth_addr))
+ 			continue;
+ 
+ 		if (p->rt_protocol != RTPROT_KERNEL &&
+ 		    (p->flags & MDB_PG_FLAGS_PERMANENT))
+ 			break;
+ 
+ 		if (fastleave)
+ 			p->flags |= MDB_PG_FLAGS_FAST_LEAVE;
+ 		br_multicast_del_pg(mp, p, pp);
+ 		break;
+ 	}
+ 	src->flags &= ~BR_SGRP_F_INSTALLED;
+ }
+ 
+ /* install S,G and based on src's timer enable or disable forwarding */
+ static void br_multicast_fwd_src_handle(struct net_bridge_group_src *src)
+ {
+ 	struct net_bridge_port_group_sg_key sg_key;
+ 	struct net_bridge_port_group *sg;
+ 	u8 old_flags;
+ 
+ 	br_multicast_fwd_src_add(src);
+ 
+ 	memset(&sg_key, 0, sizeof(sg_key));
+ 	sg_key.addr = src->pg->key.addr;
+ 	sg_key.addr.src = src->addr.src;
+ 	sg_key.port = src->pg->key.port;
+ 
+ 	sg = br_sg_port_find(src->br, &sg_key);
+ 	if (!sg || (sg->flags & MDB_PG_FLAGS_PERMANENT))
+ 		return;
+ 
+ 	old_flags = sg->flags;
+ 	if (timer_pending(&src->timer))
+ 		sg->flags &= ~MDB_PG_FLAGS_BLOCKED;
+ 	else
+ 		sg->flags |= MDB_PG_FLAGS_BLOCKED;
+ 
+ 	if (old_flags != sg->flags) {
+ 		struct net_bridge_mdb_entry *sg_mp;
+ 
+ 		sg_mp = br_mdb_ip_get(src->br, &sg_key.addr);
+ 		if (!sg_mp)
+ 			return;
+ 		br_mdb_notify(src->br->dev, sg_mp, sg, RTM_NEWMDB);
+ 	}
+ }
+ 
++>>>>>>> eb1593a0b4c4 (net: bridge: multicast: use the port group to port context helper)
  static void br_multicast_destroy_mdb_entry(struct net_bridge_mcast_gc *gc)
  {
  	struct net_bridge_mdb_entry *mp;
@@@ -1161,11 -1703,15 +1547,20 @@@ static void br_multicast_port_group_rex
  	    !br_opt_get(br, BROPT_MULTICAST_QUERIER))
  		goto out;
  
++<<<<<<< HEAD
 +	if (pg->addr.proto == htons(ETH_P_IP))
 +		other_query = &br->ip4_other_query;
++=======
+ 	pmctx = br_multicast_pg_to_port_ctx(pg);
+ 	if (!pmctx)
+ 		goto out;
+ 	brmctx = br_multicast_port_ctx_get_global(pmctx);
+ 	if (pg->key.addr.proto == htons(ETH_P_IP))
+ 		other_query = &brmctx->ip4_other_query;
++>>>>>>> eb1593a0b4c4 (net: bridge: multicast: use the port group to port context helper)
  #if IS_ENABLED(CONFIG_IPV6)
  	else
 -		other_query = &brmctx->ip6_other_query;
 +		other_query = &br->ip6_other_query;
  #endif
  
  	if (!other_query || timer_pending(&other_query->timer))
* Unmerged path net/bridge/br_multicast.c
