KVM: debugfs: Reuse binary stats descriptors

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Jing Zhang <jingzhangos@google.com>
commit bc9e9e672df9f16f3825320c53ec01b3d44add28
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/bc9e9e67.failed

To remove code duplication, use the binary stats descriptors in the
implementation of the debugfs interface for statistics. This unifies
the definition of statistics for the binary and debugfs interfaces.

	Signed-off-by: Jing Zhang <jingzhangos@google.com>
Message-Id: <20210618222709.1858088-8-jingzhangos@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit bc9e9e672df9f16f3825320c53ec01b3d44add28)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/kvm/guest.c
#	arch/mips/kvm/mips.c
#	arch/powerpc/kvm/book3s.c
#	arch/powerpc/kvm/booke.c
#	arch/s390/kvm/kvm-s390.c
#	arch/x86/kvm/x86.c
#	include/linux/kvm_host.h
diff --cc arch/arm64/kvm/guest.c
index 55fc8899da78,1512a8007a78..000000000000
--- a/arch/arm64/kvm/guest.c
+++ b/arch/arm64/kvm/guest.c
@@@ -40,20 -28,40 +40,57 @@@
  
  #include "trace.h"
  
++<<<<<<< HEAD
 +struct kvm_stats_debugfs_item debugfs_entries[] = {
 +	VCPU_STAT("halt_successful_poll", halt_successful_poll),
 +	VCPU_STAT("halt_attempted_poll", halt_attempted_poll),
 +	VCPU_STAT("halt_poll_invalid", halt_poll_invalid),
 +	VCPU_STAT("halt_wakeup", halt_wakeup),
 +	VCPU_STAT("hvc_exit_stat", hvc_exit_stat),
 +	VCPU_STAT("wfe_exit_stat", wfe_exit_stat),
 +	VCPU_STAT("wfi_exit_stat", wfi_exit_stat),
 +	VCPU_STAT("mmio_exit_user", mmio_exit_user),
 +	VCPU_STAT("mmio_exit_kernel", mmio_exit_kernel),
 +	VCPU_STAT("exits", exits),
 +	VCPU_STAT("halt_poll_success_ns", halt_poll_success_ns),
 +	VCPU_STAT("halt_poll_fail_ns", halt_poll_fail_ns),
 +	{ NULL }
++=======
+ const struct _kvm_stats_desc kvm_vm_stats_desc[] = {
+ 	KVM_GENERIC_VM_STATS()
+ };
+ static_assert(ARRAY_SIZE(kvm_vm_stats_desc) ==
+ 		sizeof(struct kvm_vm_stat) / sizeof(u64));
+ 
+ const struct kvm_stats_header kvm_vm_stats_header = {
+ 	.name_size = KVM_STATS_NAME_SIZE,
+ 	.num_desc = ARRAY_SIZE(kvm_vm_stats_desc),
+ 	.id_offset =  sizeof(struct kvm_stats_header),
+ 	.desc_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE,
+ 	.data_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE +
+ 		       sizeof(kvm_vm_stats_desc),
+ };
+ 
+ const struct _kvm_stats_desc kvm_vcpu_stats_desc[] = {
+ 	KVM_GENERIC_VCPU_STATS(),
+ 	STATS_DESC_COUNTER(VCPU, hvc_exit_stat),
+ 	STATS_DESC_COUNTER(VCPU, wfe_exit_stat),
+ 	STATS_DESC_COUNTER(VCPU, wfi_exit_stat),
+ 	STATS_DESC_COUNTER(VCPU, mmio_exit_user),
+ 	STATS_DESC_COUNTER(VCPU, mmio_exit_kernel),
+ 	STATS_DESC_COUNTER(VCPU, exits)
+ };
+ static_assert(ARRAY_SIZE(kvm_vcpu_stats_desc) ==
+ 		sizeof(struct kvm_vcpu_stat) / sizeof(u64));
+ 
+ const struct kvm_stats_header kvm_vcpu_stats_header = {
+ 	.name_size = KVM_STATS_NAME_SIZE,
+ 	.num_desc = ARRAY_SIZE(kvm_vcpu_stats_desc),
+ 	.id_offset = sizeof(struct kvm_stats_header),
+ 	.desc_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE,
+ 	.data_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE +
+ 		       sizeof(kvm_vcpu_stats_desc),
++>>>>>>> bc9e9e672df9 (KVM: debugfs: Reuse binary stats descriptors)
  };
  
  static bool core_reg_offset_is_vreg(u64 off)
diff --cc arch/mips/kvm/mips.c
index fb7fb30a3287,af9dd029a4e1..000000000000
--- a/arch/mips/kvm/mips.c
+++ b/arch/mips/kvm/mips.c
@@@ -39,40 -38,63 +39,100 @@@
  #define VECTORSPACING 0x100	/* for EI/VI mode */
  #endif
  
++<<<<<<< HEAD
 +struct kvm_stats_debugfs_item debugfs_entries[] = {
 +	VCPU_STAT("wait", wait_exits),
 +	VCPU_STAT("cache", cache_exits),
 +	VCPU_STAT("signal", signal_exits),
 +	VCPU_STAT("interrupt", int_exits),
 +	VCPU_STAT("cop_unusable", cop_unusable_exits),
 +	VCPU_STAT("tlbmod", tlbmod_exits),
 +	VCPU_STAT("tlbmiss_ld", tlbmiss_ld_exits),
 +	VCPU_STAT("tlbmiss_st", tlbmiss_st_exits),
 +	VCPU_STAT("addrerr_st", addrerr_st_exits),
 +	VCPU_STAT("addrerr_ld", addrerr_ld_exits),
 +	VCPU_STAT("syscall", syscall_exits),
 +	VCPU_STAT("resvd_inst", resvd_inst_exits),
 +	VCPU_STAT("break_inst", break_inst_exits),
 +	VCPU_STAT("trap_inst", trap_inst_exits),
 +	VCPU_STAT("msa_fpe", msa_fpe_exits),
 +	VCPU_STAT("fpe", fpe_exits),
 +	VCPU_STAT("msa_disabled", msa_disabled_exits),
 +	VCPU_STAT("flush_dcache", flush_dcache_exits),
 +#ifdef CONFIG_KVM_MIPS_VZ
 +	VCPU_STAT("vz_gpsi", vz_gpsi_exits),
 +	VCPU_STAT("vz_gsfc", vz_gsfc_exits),
 +	VCPU_STAT("vz_hc", vz_hc_exits),
 +	VCPU_STAT("vz_grr", vz_grr_exits),
 +	VCPU_STAT("vz_gva", vz_gva_exits),
 +	VCPU_STAT("vz_ghfc", vz_ghfc_exits),
 +	VCPU_STAT("vz_gpa", vz_gpa_exits),
 +	VCPU_STAT("vz_resvd", vz_resvd_exits),
 +#endif
 +	VCPU_STAT("halt_successful_poll", halt_successful_poll),
 +	VCPU_STAT("halt_attempted_poll", halt_attempted_poll),
 +	VCPU_STAT("halt_poll_invalid", halt_poll_invalid),
 +	VCPU_STAT("halt_wakeup", halt_wakeup),
 +	{NULL}
++=======
+ const struct _kvm_stats_desc kvm_vm_stats_desc[] = {
+ 	KVM_GENERIC_VM_STATS()
+ };
+ static_assert(ARRAY_SIZE(kvm_vm_stats_desc) ==
+ 		sizeof(struct kvm_vm_stat) / sizeof(u64));
+ 
+ const struct kvm_stats_header kvm_vm_stats_header = {
+ 	.name_size = KVM_STATS_NAME_SIZE,
+ 	.num_desc = ARRAY_SIZE(kvm_vm_stats_desc),
+ 	.id_offset = sizeof(struct kvm_stats_header),
+ 	.desc_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE,
+ 	.data_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE +
+ 		       sizeof(kvm_vm_stats_desc),
+ };
+ 
+ const struct _kvm_stats_desc kvm_vcpu_stats_desc[] = {
+ 	KVM_GENERIC_VCPU_STATS(),
+ 	STATS_DESC_COUNTER(VCPU, wait_exits),
+ 	STATS_DESC_COUNTER(VCPU, cache_exits),
+ 	STATS_DESC_COUNTER(VCPU, signal_exits),
+ 	STATS_DESC_COUNTER(VCPU, int_exits),
+ 	STATS_DESC_COUNTER(VCPU, cop_unusable_exits),
+ 	STATS_DESC_COUNTER(VCPU, tlbmod_exits),
+ 	STATS_DESC_COUNTER(VCPU, tlbmiss_ld_exits),
+ 	STATS_DESC_COUNTER(VCPU, tlbmiss_st_exits),
+ 	STATS_DESC_COUNTER(VCPU, addrerr_st_exits),
+ 	STATS_DESC_COUNTER(VCPU, addrerr_ld_exits),
+ 	STATS_DESC_COUNTER(VCPU, syscall_exits),
+ 	STATS_DESC_COUNTER(VCPU, resvd_inst_exits),
+ 	STATS_DESC_COUNTER(VCPU, break_inst_exits),
+ 	STATS_DESC_COUNTER(VCPU, trap_inst_exits),
+ 	STATS_DESC_COUNTER(VCPU, msa_fpe_exits),
+ 	STATS_DESC_COUNTER(VCPU, fpe_exits),
+ 	STATS_DESC_COUNTER(VCPU, msa_disabled_exits),
+ 	STATS_DESC_COUNTER(VCPU, flush_dcache_exits),
+ 	STATS_DESC_COUNTER(VCPU, vz_gpsi_exits),
+ 	STATS_DESC_COUNTER(VCPU, vz_gsfc_exits),
+ 	STATS_DESC_COUNTER(VCPU, vz_hc_exits),
+ 	STATS_DESC_COUNTER(VCPU, vz_grr_exits),
+ 	STATS_DESC_COUNTER(VCPU, vz_gva_exits),
+ 	STATS_DESC_COUNTER(VCPU, vz_ghfc_exits),
+ 	STATS_DESC_COUNTER(VCPU, vz_gpa_exits),
+ 	STATS_DESC_COUNTER(VCPU, vz_resvd_exits),
+ #ifdef CONFIG_CPU_LOONGSON64
+ 	STATS_DESC_COUNTER(VCPU, vz_cpucfg_exits),
+ #endif
+ };
+ static_assert(ARRAY_SIZE(kvm_vcpu_stats_desc) ==
+ 		sizeof(struct kvm_vcpu_stat) / sizeof(u64));
+ 
+ const struct kvm_stats_header kvm_vcpu_stats_header = {
+ 	.name_size = KVM_STATS_NAME_SIZE,
+ 	.num_desc = ARRAY_SIZE(kvm_vcpu_stats_desc),
+ 	.id_offset = sizeof(struct kvm_stats_header),
+ 	.desc_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE,
+ 	.data_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE +
+ 		       sizeof(kvm_vcpu_stats_desc),
++>>>>>>> bc9e9e672df9 (KVM: debugfs: Reuse binary stats descriptors)
  };
  
  bool kvm_trace_guest_mode_change;
diff --cc arch/powerpc/kvm/book3s.c
index 5063a9817c96,79833f78d1da..000000000000
--- a/arch/powerpc/kvm/book3s.c
+++ b/arch/powerpc/kvm/book3s.c
@@@ -42,37 -38,66 +42,100 @@@
  
  /* #define EXIT_DEBUG */
  
++<<<<<<< HEAD
 +struct kvm_stats_debugfs_item debugfs_entries[] = {
 +	VCPU_STAT("exits", sum_exits),
 +	VCPU_STAT("mmio", mmio_exits),
 +	VCPU_STAT("sig", signal_exits),
 +	VCPU_STAT("sysc", syscall_exits),
 +	VCPU_STAT("inst_emu", emulated_inst_exits),
 +	VCPU_STAT("dec", dec_exits),
 +	VCPU_STAT("ext_intr", ext_intr_exits),
 +	VCPU_STAT("queue_intr", queue_intr),
 +	VCPU_STAT("halt_poll_success_ns", halt_poll_success_ns),
 +	VCPU_STAT("halt_poll_fail_ns", halt_poll_fail_ns),
 +	VCPU_STAT("halt_wait_ns", halt_wait_ns),
 +	VCPU_STAT("halt_successful_poll", halt_successful_poll),
 +	VCPU_STAT("halt_attempted_poll", halt_attempted_poll),
 +	VCPU_STAT("halt_successful_wait", halt_successful_wait),
 +	VCPU_STAT("halt_poll_invalid", halt_poll_invalid),
 +	VCPU_STAT("halt_wakeup", halt_wakeup),
 +	VCPU_STAT("pf_storage", pf_storage),
 +	VCPU_STAT("sp_storage", sp_storage),
 +	VCPU_STAT("pf_instruc", pf_instruc),
 +	VCPU_STAT("sp_instruc", sp_instruc),
 +	VCPU_STAT("ld", ld),
 +	VCPU_STAT("ld_slow", ld_slow),
 +	VCPU_STAT("st", st),
 +	VCPU_STAT("st_slow", st_slow),
 +	VCPU_STAT("pthru_all", pthru_all),
 +	VCPU_STAT("pthru_host", pthru_host),
 +	VCPU_STAT("pthru_bad_aff", pthru_bad_aff),
 +	VM_STAT("largepages_2M", num_2M_pages, .mode = 0444),
 +	VM_STAT("largepages_1G", num_1G_pages, .mode = 0444),
 +	{ NULL }
++=======
+ const struct _kvm_stats_desc kvm_vm_stats_desc[] = {
+ 	KVM_GENERIC_VM_STATS(),
+ 	STATS_DESC_ICOUNTER(VM, num_2M_pages),
+ 	STATS_DESC_ICOUNTER(VM, num_1G_pages)
+ };
+ static_assert(ARRAY_SIZE(kvm_vm_stats_desc) ==
+ 		sizeof(struct kvm_vm_stat) / sizeof(u64));
+ 
+ const struct kvm_stats_header kvm_vm_stats_header = {
+ 	.name_size = KVM_STATS_NAME_SIZE,
+ 	.num_desc = ARRAY_SIZE(kvm_vm_stats_desc),
+ 	.id_offset = sizeof(struct kvm_stats_header),
+ 	.desc_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE,
+ 	.data_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE +
+ 		       sizeof(kvm_vm_stats_desc),
+ };
+ 
+ const struct _kvm_stats_desc kvm_vcpu_stats_desc[] = {
+ 	KVM_GENERIC_VCPU_STATS(),
+ 	STATS_DESC_COUNTER(VCPU, sum_exits),
+ 	STATS_DESC_COUNTER(VCPU, mmio_exits),
+ 	STATS_DESC_COUNTER(VCPU, signal_exits),
+ 	STATS_DESC_COUNTER(VCPU, light_exits),
+ 	STATS_DESC_COUNTER(VCPU, itlb_real_miss_exits),
+ 	STATS_DESC_COUNTER(VCPU, itlb_virt_miss_exits),
+ 	STATS_DESC_COUNTER(VCPU, dtlb_real_miss_exits),
+ 	STATS_DESC_COUNTER(VCPU, dtlb_virt_miss_exits),
+ 	STATS_DESC_COUNTER(VCPU, syscall_exits),
+ 	STATS_DESC_COUNTER(VCPU, isi_exits),
+ 	STATS_DESC_COUNTER(VCPU, dsi_exits),
+ 	STATS_DESC_COUNTER(VCPU, emulated_inst_exits),
+ 	STATS_DESC_COUNTER(VCPU, dec_exits),
+ 	STATS_DESC_COUNTER(VCPU, ext_intr_exits),
+ 	STATS_DESC_TIME_NSEC(VCPU, halt_wait_ns),
+ 	STATS_DESC_COUNTER(VCPU, halt_successful_wait),
+ 	STATS_DESC_COUNTER(VCPU, dbell_exits),
+ 	STATS_DESC_COUNTER(VCPU, gdbell_exits),
+ 	STATS_DESC_COUNTER(VCPU, ld),
+ 	STATS_DESC_COUNTER(VCPU, st),
+ 	STATS_DESC_COUNTER(VCPU, pf_storage),
+ 	STATS_DESC_COUNTER(VCPU, pf_instruc),
+ 	STATS_DESC_COUNTER(VCPU, sp_storage),
+ 	STATS_DESC_COUNTER(VCPU, sp_instruc),
+ 	STATS_DESC_COUNTER(VCPU, queue_intr),
+ 	STATS_DESC_COUNTER(VCPU, ld_slow),
+ 	STATS_DESC_COUNTER(VCPU, st_slow),
+ 	STATS_DESC_COUNTER(VCPU, pthru_all),
+ 	STATS_DESC_COUNTER(VCPU, pthru_host),
+ 	STATS_DESC_COUNTER(VCPU, pthru_bad_aff)
+ };
+ static_assert(ARRAY_SIZE(kvm_vcpu_stats_desc) ==
+ 		sizeof(struct kvm_vcpu_stat) / sizeof(u64));
+ 
+ const struct kvm_stats_header kvm_vcpu_stats_header = {
+ 	.name_size = KVM_STATS_NAME_SIZE,
+ 	.num_desc = ARRAY_SIZE(kvm_vcpu_stats_desc),
+ 	.id_offset = sizeof(struct kvm_stats_header),
+ 	.desc_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE,
+ 	.data_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE +
+ 		       sizeof(kvm_vcpu_stats_desc),
++>>>>>>> bc9e9e672df9 (KVM: debugfs: Reuse binary stats descriptors)
  };
  
  static inline void kvmppc_update_int_pending(struct kvm_vcpu *vcpu,
diff --cc arch/powerpc/kvm/booke.c
index f7ec42fd14d5,551b30d84aee..000000000000
--- a/arch/powerpc/kvm/booke.c
+++ b/arch/powerpc/kvm/booke.c
@@@ -46,29 -36,59 +46,85 @@@
  
  unsigned long kvmppc_booke_handlers;
  
++<<<<<<< HEAD
 +struct kvm_stats_debugfs_item debugfs_entries[] = {
 +	VCPU_STAT("mmio", mmio_exits),
 +	VCPU_STAT("sig", signal_exits),
 +	VCPU_STAT("itlb_r", itlb_real_miss_exits),
 +	VCPU_STAT("itlb_v", itlb_virt_miss_exits),
 +	VCPU_STAT("dtlb_r", dtlb_real_miss_exits),
 +	VCPU_STAT("dtlb_v", dtlb_virt_miss_exits),
 +	VCPU_STAT("sysc", syscall_exits),
 +	VCPU_STAT("isi", isi_exits),
 +	VCPU_STAT("dsi", dsi_exits),
 +	VCPU_STAT("inst_emu", emulated_inst_exits),
 +	VCPU_STAT("dec", dec_exits),
 +	VCPU_STAT("ext_intr", ext_intr_exits),
 +	VCPU_STAT("halt_successful_poll", halt_successful_poll),
 +	VCPU_STAT("halt_attempted_poll", halt_attempted_poll),
 +	VCPU_STAT("halt_poll_invalid", halt_poll_invalid),
 +	VCPU_STAT("halt_wakeup", halt_wakeup),
 +	VCPU_STAT("doorbell", dbell_exits),
 +	VCPU_STAT("guest doorbell", gdbell_exits),
 +	VCPU_STAT("halt_poll_success_ns", halt_poll_success_ns),
 +	VCPU_STAT("halt_poll_fail_ns", halt_poll_fail_ns),
 +	VM_STAT("remote_tlb_flush", remote_tlb_flush),
 +	{ NULL }
++=======
+ const struct _kvm_stats_desc kvm_vm_stats_desc[] = {
+ 	KVM_GENERIC_VM_STATS(),
+ 	STATS_DESC_ICOUNTER(VM, num_2M_pages),
+ 	STATS_DESC_ICOUNTER(VM, num_1G_pages)
+ };
+ static_assert(ARRAY_SIZE(kvm_vm_stats_desc) ==
+ 		sizeof(struct kvm_vm_stat) / sizeof(u64));
+ 
+ const struct kvm_stats_header kvm_vm_stats_header = {
+ 	.name_size = KVM_STATS_NAME_SIZE,
+ 	.num_desc = ARRAY_SIZE(kvm_vm_stats_desc),
+ 	.id_offset = sizeof(struct kvm_stats_header),
+ 	.desc_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE,
+ 	.data_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE +
+ 		       sizeof(kvm_vm_stats_desc),
+ };
+ 
+ const struct _kvm_stats_desc kvm_vcpu_stats_desc[] = {
+ 	KVM_GENERIC_VCPU_STATS(),
+ 	STATS_DESC_COUNTER(VCPU, sum_exits),
+ 	STATS_DESC_COUNTER(VCPU, mmio_exits),
+ 	STATS_DESC_COUNTER(VCPU, signal_exits),
+ 	STATS_DESC_COUNTER(VCPU, light_exits),
+ 	STATS_DESC_COUNTER(VCPU, itlb_real_miss_exits),
+ 	STATS_DESC_COUNTER(VCPU, itlb_virt_miss_exits),
+ 	STATS_DESC_COUNTER(VCPU, dtlb_real_miss_exits),
+ 	STATS_DESC_COUNTER(VCPU, dtlb_virt_miss_exits),
+ 	STATS_DESC_COUNTER(VCPU, syscall_exits),
+ 	STATS_DESC_COUNTER(VCPU, isi_exits),
+ 	STATS_DESC_COUNTER(VCPU, dsi_exits),
+ 	STATS_DESC_COUNTER(VCPU, emulated_inst_exits),
+ 	STATS_DESC_COUNTER(VCPU, dec_exits),
+ 	STATS_DESC_COUNTER(VCPU, ext_intr_exits),
+ 	STATS_DESC_TIME_NSEC(VCPU, halt_wait_ns),
+ 	STATS_DESC_COUNTER(VCPU, halt_successful_wait),
+ 	STATS_DESC_COUNTER(VCPU, dbell_exits),
+ 	STATS_DESC_COUNTER(VCPU, gdbell_exits),
+ 	STATS_DESC_COUNTER(VCPU, ld),
+ 	STATS_DESC_COUNTER(VCPU, st),
+ 	STATS_DESC_COUNTER(VCPU, pthru_all),
+ 	STATS_DESC_COUNTER(VCPU, pthru_host),
+ 	STATS_DESC_COUNTER(VCPU, pthru_bad_aff)
+ };
+ static_assert(ARRAY_SIZE(kvm_vcpu_stats_desc) ==
+ 		sizeof(struct kvm_vcpu_stat) / sizeof(u64));
+ 
+ const struct kvm_stats_header kvm_vcpu_stats_header = {
+ 	.name_size = KVM_STATS_NAME_SIZE,
+ 	.num_desc = ARRAY_SIZE(kvm_vcpu_stats_desc),
+ 	.id_offset = sizeof(struct kvm_stats_header),
+ 	.desc_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE,
+ 	.data_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE +
+ 		       sizeof(kvm_vcpu_stats_desc),
++>>>>>>> bc9e9e672df9 (KVM: debugfs: Reuse binary stats descriptors)
  };
  
  /* TODO: use vcpu_printf() */
diff --cc arch/s390/kvm/kvm-s390.c
index 77ac3932fe76,1695f0ced5ba..000000000000
--- a/arch/s390/kvm/kvm-s390.c
+++ b/arch/s390/kvm/kvm-s390.c
@@@ -57,119 -58,133 +57,249 @@@
  #define VCPU_IRQS_MAX_BUF (sizeof(struct kvm_s390_irq) * \
  			   (KVM_MAX_VCPUS + LOCAL_IRQS))
  
++<<<<<<< HEAD
 +struct kvm_stats_debugfs_item debugfs_entries[] = {
 +	VCPU_STAT("userspace_handled", exit_userspace),
 +	VCPU_STAT("exit_null", exit_null),
 +	VCPU_STAT("pfault_sync", pfault_sync),
 +	VCPU_STAT("exit_validity", exit_validity),
 +	VCPU_STAT("exit_stop_request", exit_stop_request),
 +	VCPU_STAT("exit_external_request", exit_external_request),
 +	VCPU_STAT("exit_io_request", exit_io_request),
 +	VCPU_STAT("exit_external_interrupt", exit_external_interrupt),
 +	VCPU_STAT("exit_instruction", exit_instruction),
 +	VCPU_STAT("exit_pei", exit_pei),
 +	VCPU_STAT("exit_program_interruption", exit_program_interruption),
 +	VCPU_STAT("exit_instr_and_program_int", exit_instr_and_program),
 +	VCPU_STAT("exit_operation_exception", exit_operation_exception),
 +	VCPU_STAT("halt_successful_poll", halt_successful_poll),
 +	VCPU_STAT("halt_attempted_poll", halt_attempted_poll),
 +	VCPU_STAT("halt_poll_invalid", halt_poll_invalid),
 +	VCPU_STAT("halt_no_poll_steal", halt_no_poll_steal),
 +	VCPU_STAT("halt_wakeup", halt_wakeup),
 +	VCPU_STAT("halt_poll_success_ns", halt_poll_success_ns),
 +	VCPU_STAT("halt_poll_fail_ns", halt_poll_fail_ns),
 +	VCPU_STAT("instruction_lctlg", instruction_lctlg),
 +	VCPU_STAT("instruction_lctl", instruction_lctl),
 +	VCPU_STAT("instruction_stctl", instruction_stctl),
 +	VCPU_STAT("instruction_stctg", instruction_stctg),
 +	VCPU_STAT("deliver_ckc", deliver_ckc),
 +	VCPU_STAT("deliver_cputm", deliver_cputm),
 +	VCPU_STAT("deliver_emergency_signal", deliver_emergency_signal),
 +	VCPU_STAT("deliver_external_call", deliver_external_call),
 +	VCPU_STAT("deliver_service_signal", deliver_service_signal),
 +	VCPU_STAT("deliver_virtio", deliver_virtio),
 +	VCPU_STAT("deliver_stop_signal", deliver_stop_signal),
 +	VCPU_STAT("deliver_prefix_signal", deliver_prefix_signal),
 +	VCPU_STAT("deliver_restart_signal", deliver_restart_signal),
 +	VCPU_STAT("deliver_program", deliver_program),
 +	VCPU_STAT("deliver_io", deliver_io),
 +	VCPU_STAT("deliver_machine_check", deliver_machine_check),
 +	VCPU_STAT("exit_wait_state", exit_wait_state),
 +	VCPU_STAT("inject_ckc", inject_ckc),
 +	VCPU_STAT("inject_cputm", inject_cputm),
 +	VCPU_STAT("inject_external_call", inject_external_call),
 +	VM_STAT("inject_float_mchk", inject_float_mchk),
 +	VCPU_STAT("inject_emergency_signal", inject_emergency_signal),
 +	VM_STAT("inject_io", inject_io),
 +	VCPU_STAT("inject_mchk", inject_mchk),
 +	VM_STAT("inject_pfault_done", inject_pfault_done),
 +	VCPU_STAT("inject_program", inject_program),
 +	VCPU_STAT("inject_restart", inject_restart),
 +	VM_STAT("inject_service_signal", inject_service_signal),
 +	VCPU_STAT("inject_set_prefix", inject_set_prefix),
 +	VCPU_STAT("inject_stop_signal", inject_stop_signal),
 +	VCPU_STAT("inject_pfault_init", inject_pfault_init),
 +	VM_STAT("inject_virtio", inject_virtio),
 +	VCPU_STAT("instruction_epsw", instruction_epsw),
 +	VCPU_STAT("instruction_gs", instruction_gs),
 +	VCPU_STAT("instruction_io_other", instruction_io_other),
 +	VCPU_STAT("instruction_lpsw", instruction_lpsw),
 +	VCPU_STAT("instruction_lpswe", instruction_lpswe),
 +	VCPU_STAT("instruction_pfmf", instruction_pfmf),
 +	VCPU_STAT("instruction_ptff", instruction_ptff),
 +	VCPU_STAT("instruction_stidp", instruction_stidp),
 +	VCPU_STAT("instruction_sck", instruction_sck),
 +	VCPU_STAT("instruction_sckpf", instruction_sckpf),
 +	VCPU_STAT("instruction_spx", instruction_spx),
 +	VCPU_STAT("instruction_stpx", instruction_stpx),
 +	VCPU_STAT("instruction_stap", instruction_stap),
 +	VCPU_STAT("instruction_iske", instruction_iske),
 +	VCPU_STAT("instruction_ri", instruction_ri),
 +	VCPU_STAT("instruction_rrbe", instruction_rrbe),
 +	VCPU_STAT("instruction_sske", instruction_sske),
 +	VCPU_STAT("instruction_ipte_interlock", instruction_ipte_interlock),
 +	VCPU_STAT("instruction_essa", instruction_essa),
 +	VCPU_STAT("instruction_stsi", instruction_stsi),
 +	VCPU_STAT("instruction_stfl", instruction_stfl),
 +	VCPU_STAT("instruction_tb", instruction_tb),
 +	VCPU_STAT("instruction_tpi", instruction_tpi),
 +	VCPU_STAT("instruction_tprot", instruction_tprot),
 +	VCPU_STAT("instruction_tsch", instruction_tsch),
 +	VCPU_STAT("instruction_sthyi", instruction_sthyi),
 +	VCPU_STAT("instruction_sie", instruction_sie),
 +	VCPU_STAT("instruction_sigp_sense", instruction_sigp_sense),
 +	VCPU_STAT("instruction_sigp_sense_running", instruction_sigp_sense_running),
 +	VCPU_STAT("instruction_sigp_external_call", instruction_sigp_external_call),
 +	VCPU_STAT("instruction_sigp_emergency", instruction_sigp_emergency),
 +	VCPU_STAT("instruction_sigp_cond_emergency", instruction_sigp_cond_emergency),
 +	VCPU_STAT("instruction_sigp_start", instruction_sigp_start),
 +	VCPU_STAT("instruction_sigp_stop", instruction_sigp_stop),
 +	VCPU_STAT("instruction_sigp_stop_store_status", instruction_sigp_stop_store_status),
 +	VCPU_STAT("instruction_sigp_store_status", instruction_sigp_store_status),
 +	VCPU_STAT("instruction_sigp_store_adtl_status", instruction_sigp_store_adtl_status),
 +	VCPU_STAT("instruction_sigp_set_arch", instruction_sigp_arch),
 +	VCPU_STAT("instruction_sigp_set_prefix", instruction_sigp_prefix),
 +	VCPU_STAT("instruction_sigp_restart", instruction_sigp_restart),
 +	VCPU_STAT("instruction_sigp_cpu_reset", instruction_sigp_cpu_reset),
 +	VCPU_STAT("instruction_sigp_init_cpu_reset", instruction_sigp_init_cpu_reset),
 +	VCPU_STAT("instruction_sigp_unknown", instruction_sigp_unknown),
 +	VCPU_STAT("instruction_diag_10", diagnose_10),
 +	VCPU_STAT("instruction_diag_44", diagnose_44),
 +	VCPU_STAT("instruction_diag_9c", diagnose_9c),
 +	VCPU_STAT("diag_9c_ignored", diagnose_9c_ignored),
 +	VCPU_STAT("diag_9c_forward", diagnose_9c_forward),
 +	VCPU_STAT("instruction_diag_258", diagnose_258),
 +	VCPU_STAT("instruction_diag_308", diagnose_308),
 +	VCPU_STAT("instruction_diag_500", diagnose_500),
 +	VCPU_STAT("instruction_diag_other", diagnose_other),
 +	{ NULL }
 +};
 +
 +struct kvm_s390_tod_clock_ext {
 +	__u8 epoch_idx;
 +	__u64 tod;
 +	__u8 reserved[7];
 +} __packed;
++=======
+ const struct _kvm_stats_desc kvm_vm_stats_desc[] = {
+ 	KVM_GENERIC_VM_STATS(),
+ 	STATS_DESC_COUNTER(VM, inject_io),
+ 	STATS_DESC_COUNTER(VM, inject_float_mchk),
+ 	STATS_DESC_COUNTER(VM, inject_pfault_done),
+ 	STATS_DESC_COUNTER(VM, inject_service_signal),
+ 	STATS_DESC_COUNTER(VM, inject_virtio)
+ };
+ static_assert(ARRAY_SIZE(kvm_vm_stats_desc) ==
+ 		sizeof(struct kvm_vm_stat) / sizeof(u64));
+ 
+ const struct kvm_stats_header kvm_vm_stats_header = {
+ 	.name_size = KVM_STATS_NAME_SIZE,
+ 	.num_desc = ARRAY_SIZE(kvm_vm_stats_desc),
+ 	.id_offset = sizeof(struct kvm_stats_header),
+ 	.desc_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE,
+ 	.data_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE +
+ 		       sizeof(kvm_vm_stats_desc),
+ };
+ 
+ const struct _kvm_stats_desc kvm_vcpu_stats_desc[] = {
+ 	KVM_GENERIC_VCPU_STATS(),
+ 	STATS_DESC_COUNTER(VCPU, exit_userspace),
+ 	STATS_DESC_COUNTER(VCPU, exit_null),
+ 	STATS_DESC_COUNTER(VCPU, exit_external_request),
+ 	STATS_DESC_COUNTER(VCPU, exit_io_request),
+ 	STATS_DESC_COUNTER(VCPU, exit_external_interrupt),
+ 	STATS_DESC_COUNTER(VCPU, exit_stop_request),
+ 	STATS_DESC_COUNTER(VCPU, exit_validity),
+ 	STATS_DESC_COUNTER(VCPU, exit_instruction),
+ 	STATS_DESC_COUNTER(VCPU, exit_pei),
+ 	STATS_DESC_COUNTER(VCPU, halt_no_poll_steal),
+ 	STATS_DESC_COUNTER(VCPU, instruction_lctl),
+ 	STATS_DESC_COUNTER(VCPU, instruction_lctlg),
+ 	STATS_DESC_COUNTER(VCPU, instruction_stctl),
+ 	STATS_DESC_COUNTER(VCPU, instruction_stctg),
+ 	STATS_DESC_COUNTER(VCPU, exit_program_interruption),
+ 	STATS_DESC_COUNTER(VCPU, exit_instr_and_program),
+ 	STATS_DESC_COUNTER(VCPU, exit_operation_exception),
+ 	STATS_DESC_COUNTER(VCPU, deliver_ckc),
+ 	STATS_DESC_COUNTER(VCPU, deliver_cputm),
+ 	STATS_DESC_COUNTER(VCPU, deliver_external_call),
+ 	STATS_DESC_COUNTER(VCPU, deliver_emergency_signal),
+ 	STATS_DESC_COUNTER(VCPU, deliver_service_signal),
+ 	STATS_DESC_COUNTER(VCPU, deliver_virtio),
+ 	STATS_DESC_COUNTER(VCPU, deliver_stop_signal),
+ 	STATS_DESC_COUNTER(VCPU, deliver_prefix_signal),
+ 	STATS_DESC_COUNTER(VCPU, deliver_restart_signal),
+ 	STATS_DESC_COUNTER(VCPU, deliver_program),
+ 	STATS_DESC_COUNTER(VCPU, deliver_io),
+ 	STATS_DESC_COUNTER(VCPU, deliver_machine_check),
+ 	STATS_DESC_COUNTER(VCPU, exit_wait_state),
+ 	STATS_DESC_COUNTER(VCPU, inject_ckc),
+ 	STATS_DESC_COUNTER(VCPU, inject_cputm),
+ 	STATS_DESC_COUNTER(VCPU, inject_external_call),
+ 	STATS_DESC_COUNTER(VCPU, inject_emergency_signal),
+ 	STATS_DESC_COUNTER(VCPU, inject_mchk),
+ 	STATS_DESC_COUNTER(VCPU, inject_pfault_init),
+ 	STATS_DESC_COUNTER(VCPU, inject_program),
+ 	STATS_DESC_COUNTER(VCPU, inject_restart),
+ 	STATS_DESC_COUNTER(VCPU, inject_set_prefix),
+ 	STATS_DESC_COUNTER(VCPU, inject_stop_signal),
+ 	STATS_DESC_COUNTER(VCPU, instruction_epsw),
+ 	STATS_DESC_COUNTER(VCPU, instruction_gs),
+ 	STATS_DESC_COUNTER(VCPU, instruction_io_other),
+ 	STATS_DESC_COUNTER(VCPU, instruction_lpsw),
+ 	STATS_DESC_COUNTER(VCPU, instruction_lpswe),
+ 	STATS_DESC_COUNTER(VCPU, instruction_pfmf),
+ 	STATS_DESC_COUNTER(VCPU, instruction_ptff),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sck),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sckpf),
+ 	STATS_DESC_COUNTER(VCPU, instruction_stidp),
+ 	STATS_DESC_COUNTER(VCPU, instruction_spx),
+ 	STATS_DESC_COUNTER(VCPU, instruction_stpx),
+ 	STATS_DESC_COUNTER(VCPU, instruction_stap),
+ 	STATS_DESC_COUNTER(VCPU, instruction_iske),
+ 	STATS_DESC_COUNTER(VCPU, instruction_ri),
+ 	STATS_DESC_COUNTER(VCPU, instruction_rrbe),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sske),
+ 	STATS_DESC_COUNTER(VCPU, instruction_ipte_interlock),
+ 	STATS_DESC_COUNTER(VCPU, instruction_stsi),
+ 	STATS_DESC_COUNTER(VCPU, instruction_stfl),
+ 	STATS_DESC_COUNTER(VCPU, instruction_tb),
+ 	STATS_DESC_COUNTER(VCPU, instruction_tpi),
+ 	STATS_DESC_COUNTER(VCPU, instruction_tprot),
+ 	STATS_DESC_COUNTER(VCPU, instruction_tsch),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sie),
+ 	STATS_DESC_COUNTER(VCPU, instruction_essa),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sthyi),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_sense),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_sense_running),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_external_call),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_emergency),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_cond_emergency),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_start),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_stop),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_stop_store_status),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_store_status),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_store_adtl_status),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_arch),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_prefix),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_restart),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_init_cpu_reset),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_cpu_reset),
+ 	STATS_DESC_COUNTER(VCPU, instruction_sigp_unknown),
+ 	STATS_DESC_COUNTER(VCPU, diagnose_10),
+ 	STATS_DESC_COUNTER(VCPU, diagnose_44),
+ 	STATS_DESC_COUNTER(VCPU, diagnose_9c),
+ 	STATS_DESC_COUNTER(VCPU, diagnose_9c_ignored),
+ 	STATS_DESC_COUNTER(VCPU, diagnose_9c_forward),
+ 	STATS_DESC_COUNTER(VCPU, diagnose_258),
+ 	STATS_DESC_COUNTER(VCPU, diagnose_308),
+ 	STATS_DESC_COUNTER(VCPU, diagnose_500),
+ 	STATS_DESC_COUNTER(VCPU, diagnose_other),
+ 	STATS_DESC_COUNTER(VCPU, pfault_sync)
+ };
+ static_assert(ARRAY_SIZE(kvm_vcpu_stats_desc) ==
+ 		sizeof(struct kvm_vcpu_stat) / sizeof(u64));
+ 
+ const struct kvm_stats_header kvm_vcpu_stats_header = {
+ 	.name_size = KVM_STATS_NAME_SIZE,
+ 	.num_desc = ARRAY_SIZE(kvm_vcpu_stats_desc),
+ 	.id_offset = sizeof(struct kvm_stats_header),
+ 	.desc_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE,
+ 	.data_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE +
+ 		       sizeof(kvm_vcpu_stats_desc),
+ };
++>>>>>>> bc9e9e672df9 (KVM: debugfs: Reuse binary stats descriptors)
  
  /* allow nested virtualization in KVM (if enabled by user space) */
  static int nested;
diff --cc arch/x86/kvm/x86.c
index 89e29588b837,5833b8780808..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -214,51 -223,70 +214,118 @@@ EXPORT_SYMBOL_GPL(host_xss)
  u64 __read_mostly supported_xss;
  EXPORT_SYMBOL_GPL(supported_xss);
  
++<<<<<<< HEAD
 +struct kvm_stats_debugfs_item debugfs_entries[] = {
 +	VCPU_STAT("pf_fixed", pf_fixed),
 +	VCPU_STAT("pf_guest", pf_guest),
 +	VCPU_STAT("tlb_flush", tlb_flush),
 +	VCPU_STAT("invlpg", invlpg),
 +	VCPU_STAT("exits", exits),
 +	VCPU_STAT("io_exits", io_exits),
 +	VCPU_STAT("mmio_exits", mmio_exits),
 +	VCPU_STAT("signal_exits", signal_exits),
 +	VCPU_STAT("irq_window", irq_window_exits),
 +	VCPU_STAT("nmi_window", nmi_window_exits),
 +	VCPU_STAT("halt_exits", halt_exits),
 +	VCPU_STAT("halt_successful_poll", halt_successful_poll),
 +	VCPU_STAT("halt_attempted_poll", halt_attempted_poll),
 +	VCPU_STAT("halt_poll_invalid", halt_poll_invalid),
 +	VCPU_STAT("halt_wakeup", halt_wakeup),
 +	VCPU_STAT("hypercalls", hypercalls),
 +	VCPU_STAT("request_irq", request_irq_exits),
 +	VCPU_STAT("irq_exits", irq_exits),
 +	VCPU_STAT("host_state_reload", host_state_reload),
 +	VCPU_STAT("fpu_reload", fpu_reload),
 +	VCPU_STAT("insn_emulation", insn_emulation),
 +	VCPU_STAT("insn_emulation_fail", insn_emulation_fail),
 +	VCPU_STAT("irq_injections", irq_injections),
 +	VCPU_STAT("nmi_injections", nmi_injections),
 +	VCPU_STAT("req_event", req_event),
 +	VCPU_STAT("l1d_flush", l1d_flush),
 +	VCPU_STAT("halt_poll_success_ns", halt_poll_success_ns),
 +	VCPU_STAT("halt_poll_fail_ns", halt_poll_fail_ns),
 +	VCPU_STAT("nested_run", nested_run),
 +	VCPU_STAT("directed_yield_attempted", directed_yield_attempted),
 +	VCPU_STAT("directed_yield_successful", directed_yield_successful),
 +	VCPU_STAT("guest_mode", guest_mode),
 +	VM_STAT("mmu_shadow_zapped", mmu_shadow_zapped),
 +	VM_STAT("mmu_pte_write", mmu_pte_write),
 +	VM_STAT("mmu_pde_zapped", mmu_pde_zapped),
 +	VM_STAT("mmu_flooded", mmu_flooded),
 +	VM_STAT("mmu_recycled", mmu_recycled),
 +	VM_STAT("mmu_cache_miss", mmu_cache_miss),
 +	VM_STAT("mmu_unsync", mmu_unsync),
 +	VM_STAT("remote_tlb_flush", remote_tlb_flush),
 +	VM_STAT("largepages", lpages, .mode = 0444),
 +	VM_STAT("nx_largepages_splitted", nx_lpage_splits, .mode = 0444),
 +	VM_STAT("max_mmu_page_hash_collisions", max_mmu_page_hash_collisions),
 +	{ NULL }
++=======
+ const struct _kvm_stats_desc kvm_vm_stats_desc[] = {
+ 	KVM_GENERIC_VM_STATS(),
+ 	STATS_DESC_COUNTER(VM, mmu_shadow_zapped),
+ 	STATS_DESC_COUNTER(VM, mmu_pte_write),
+ 	STATS_DESC_COUNTER(VM, mmu_pde_zapped),
+ 	STATS_DESC_COUNTER(VM, mmu_flooded),
+ 	STATS_DESC_COUNTER(VM, mmu_recycled),
+ 	STATS_DESC_COUNTER(VM, mmu_cache_miss),
+ 	STATS_DESC_ICOUNTER(VM, mmu_unsync),
+ 	STATS_DESC_ICOUNTER(VM, lpages),
+ 	STATS_DESC_ICOUNTER(VM, nx_lpage_splits),
+ 	STATS_DESC_PCOUNTER(VM, max_mmu_page_hash_collisions)
+ };
+ static_assert(ARRAY_SIZE(kvm_vm_stats_desc) ==
+ 		sizeof(struct kvm_vm_stat) / sizeof(u64));
+ 
+ const struct kvm_stats_header kvm_vm_stats_header = {
+ 	.name_size = KVM_STATS_NAME_SIZE,
+ 	.num_desc = ARRAY_SIZE(kvm_vm_stats_desc),
+ 	.id_offset = sizeof(struct kvm_stats_header),
+ 	.desc_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE,
+ 	.data_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE +
+ 		       sizeof(kvm_vm_stats_desc),
+ };
+ 
+ const struct _kvm_stats_desc kvm_vcpu_stats_desc[] = {
+ 	KVM_GENERIC_VCPU_STATS(),
+ 	STATS_DESC_COUNTER(VCPU, pf_fixed),
+ 	STATS_DESC_COUNTER(VCPU, pf_guest),
+ 	STATS_DESC_COUNTER(VCPU, tlb_flush),
+ 	STATS_DESC_COUNTER(VCPU, invlpg),
+ 	STATS_DESC_COUNTER(VCPU, exits),
+ 	STATS_DESC_COUNTER(VCPU, io_exits),
+ 	STATS_DESC_COUNTER(VCPU, mmio_exits),
+ 	STATS_DESC_COUNTER(VCPU, signal_exits),
+ 	STATS_DESC_COUNTER(VCPU, irq_window_exits),
+ 	STATS_DESC_COUNTER(VCPU, nmi_window_exits),
+ 	STATS_DESC_COUNTER(VCPU, l1d_flush),
+ 	STATS_DESC_COUNTER(VCPU, halt_exits),
+ 	STATS_DESC_COUNTER(VCPU, request_irq_exits),
+ 	STATS_DESC_COUNTER(VCPU, irq_exits),
+ 	STATS_DESC_COUNTER(VCPU, host_state_reload),
+ 	STATS_DESC_COUNTER(VCPU, fpu_reload),
+ 	STATS_DESC_COUNTER(VCPU, insn_emulation),
+ 	STATS_DESC_COUNTER(VCPU, insn_emulation_fail),
+ 	STATS_DESC_COUNTER(VCPU, hypercalls),
+ 	STATS_DESC_COUNTER(VCPU, irq_injections),
+ 	STATS_DESC_COUNTER(VCPU, nmi_injections),
+ 	STATS_DESC_COUNTER(VCPU, req_event),
+ 	STATS_DESC_COUNTER(VCPU, nested_run),
+ 	STATS_DESC_COUNTER(VCPU, directed_yield_attempted),
+ 	STATS_DESC_COUNTER(VCPU, directed_yield_successful),
+ 	STATS_DESC_ICOUNTER(VCPU, guest_mode)
+ };
+ static_assert(ARRAY_SIZE(kvm_vcpu_stats_desc) ==
+ 		sizeof(struct kvm_vcpu_stat) / sizeof(u64));
+ 
+ const struct kvm_stats_header kvm_vcpu_stats_header = {
+ 	.name_size = KVM_STATS_NAME_SIZE,
+ 	.num_desc = ARRAY_SIZE(kvm_vcpu_stats_desc),
+ 	.id_offset = sizeof(struct kvm_stats_header),
+ 	.desc_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE,
+ 	.data_offset = sizeof(struct kvm_stats_header) + KVM_STATS_NAME_SIZE +
+ 		       sizeof(kvm_vcpu_stats_desc),
++>>>>>>> bc9e9e672df9 (KVM: debugfs: Reuse binary stats descriptors)
  };
  
  u64 __read_mostly host_xcr0;
diff --cc include/linux/kvm_host.h
index 5dcd8faa29b8,ae7735b490b4..000000000000
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@@ -1205,26 -1264,104 +1205,108 @@@ enum kvm_stat_kind 
  
  struct kvm_stat_data {
  	struct kvm *kvm;
- 	struct kvm_stats_debugfs_item *dbgfs_item;
- };
- 
- struct kvm_stats_debugfs_item {
- 	const char *name;
- 	int offset;
+ 	const struct _kvm_stats_desc *desc;
  	enum kvm_stat_kind kind;
- 	int mode;
  };
  
++<<<<<<< HEAD
 +#define KVM_DBGFS_GET_MODE(dbgfs_item)                                         \
 +	((dbgfs_item)->mode ? (dbgfs_item)->mode : 0644)
 +
 +#define VM_STAT(n, x, ...) 							\
 +	{ n, offsetof(struct kvm, stat.x), KVM_STAT_VM, ## __VA_ARGS__ }
 +#define VCPU_STAT(n, x, ...)							\
 +	{ n, offsetof(struct kvm_vcpu, stat.x), KVM_STAT_VCPU, ## __VA_ARGS__ }
 +
 +extern struct kvm_stats_debugfs_item debugfs_entries[];
++=======
+ struct _kvm_stats_desc {
+ 	struct kvm_stats_desc desc;
+ 	char name[KVM_STATS_NAME_SIZE];
+ };
+ 
+ #define STATS_DESC_COMMON(type, unit, base, exp)			       \
+ 	.flags = type | unit | base |					       \
+ 		 BUILD_BUG_ON_ZERO(type & ~KVM_STATS_TYPE_MASK) |	       \
+ 		 BUILD_BUG_ON_ZERO(unit & ~KVM_STATS_UNIT_MASK) |	       \
+ 		 BUILD_BUG_ON_ZERO(base & ~KVM_STATS_BASE_MASK),	       \
+ 	.exponent = exp,						       \
+ 	.size = 1
+ 
+ #define VM_GENERIC_STATS_DESC(stat, type, unit, base, exp)		       \
+ 	{								       \
+ 		{							       \
+ 			STATS_DESC_COMMON(type, unit, base, exp),	       \
+ 			.offset = offsetof(struct kvm_vm_stat, generic.stat)   \
+ 		},							       \
+ 		.name = #stat,						       \
+ 	}
+ #define VCPU_GENERIC_STATS_DESC(stat, type, unit, base, exp)		       \
+ 	{								       \
+ 		{							       \
+ 			STATS_DESC_COMMON(type, unit, base, exp),	       \
+ 			.offset = offsetof(struct kvm_vcpu_stat, generic.stat) \
+ 		},							       \
+ 		.name = #stat,						       \
+ 	}
+ #define VM_STATS_DESC(stat, type, unit, base, exp)			       \
+ 	{								       \
+ 		{							       \
+ 			STATS_DESC_COMMON(type, unit, base, exp),	       \
+ 			.offset = offsetof(struct kvm_vm_stat, stat)	       \
+ 		},							       \
+ 		.name = #stat,						       \
+ 	}
+ #define VCPU_STATS_DESC(stat, type, unit, base, exp)			       \
+ 	{								       \
+ 		{							       \
+ 			STATS_DESC_COMMON(type, unit, base, exp),	       \
+ 			.offset = offsetof(struct kvm_vcpu_stat, stat)	       \
+ 		},							       \
+ 		.name = #stat,						       \
+ 	}
+ /* SCOPE: VM, VM_GENERIC, VCPU, VCPU_GENERIC */
+ #define STATS_DESC(SCOPE, stat, type, unit, base, exp)			       \
+ 	SCOPE##_STATS_DESC(stat, type, unit, base, exp)
+ 
+ #define STATS_DESC_CUMULATIVE(SCOPE, name, unit, base, exponent)	       \
+ 	STATS_DESC(SCOPE, name, KVM_STATS_TYPE_CUMULATIVE, unit, base, exponent)
+ #define STATS_DESC_INSTANT(SCOPE, name, unit, base, exponent)		       \
+ 	STATS_DESC(SCOPE, name, KVM_STATS_TYPE_INSTANT, unit, base, exponent)
+ #define STATS_DESC_PEAK(SCOPE, name, unit, base, exponent)		       \
+ 	STATS_DESC(SCOPE, name, KVM_STATS_TYPE_PEAK, unit, base, exponent)
+ 
+ /* Cumulative counter, read/write */
+ #define STATS_DESC_COUNTER(SCOPE, name)					       \
+ 	STATS_DESC_CUMULATIVE(SCOPE, name, KVM_STATS_UNIT_NONE,		       \
+ 		KVM_STATS_BASE_POW10, 0)
+ /* Instantaneous counter, read only */
+ #define STATS_DESC_ICOUNTER(SCOPE, name)				       \
+ 	STATS_DESC_INSTANT(SCOPE, name, KVM_STATS_UNIT_NONE,		       \
+ 		KVM_STATS_BASE_POW10, 0)
+ /* Peak counter, read/write */
+ #define STATS_DESC_PCOUNTER(SCOPE, name)				       \
+ 	STATS_DESC_PEAK(SCOPE, name, KVM_STATS_UNIT_NONE,		       \
+ 		KVM_STATS_BASE_POW10, 0)
+ 
+ /* Cumulative time in nanosecond */
+ #define STATS_DESC_TIME_NSEC(SCOPE, name)				       \
+ 	STATS_DESC_CUMULATIVE(SCOPE, name, KVM_STATS_UNIT_SECONDS,	       \
+ 		KVM_STATS_BASE_POW10, -9)
+ 
+ #define KVM_GENERIC_VM_STATS()						       \
+ 	STATS_DESC_COUNTER(VM_GENERIC, remote_tlb_flush)
+ 
+ #define KVM_GENERIC_VCPU_STATS()					       \
+ 	STATS_DESC_COUNTER(VCPU_GENERIC, halt_successful_poll),		       \
+ 	STATS_DESC_COUNTER(VCPU_GENERIC, halt_attempted_poll),		       \
+ 	STATS_DESC_COUNTER(VCPU_GENERIC, halt_poll_invalid),		       \
+ 	STATS_DESC_COUNTER(VCPU_GENERIC, halt_wakeup),			       \
+ 	STATS_DESC_TIME_NSEC(VCPU_GENERIC, halt_poll_success_ns),	       \
+ 	STATS_DESC_TIME_NSEC(VCPU_GENERIC, halt_poll_fail_ns)
+ 
++>>>>>>> bc9e9e672df9 (KVM: debugfs: Reuse binary stats descriptors)
  extern struct dentry *kvm_debugfs_dir;
 -ssize_t kvm_stats_read(char *id, const struct kvm_stats_header *header,
 -		       const struct _kvm_stats_desc *desc,
 -		       void *stats, size_t size_stats,
 -		       char __user *user_buffer, size_t size, loff_t *offset);
 -extern const struct kvm_stats_header kvm_vm_stats_header;
 -extern const struct _kvm_stats_desc kvm_vm_stats_desc[];
 -extern const struct kvm_stats_header kvm_vcpu_stats_header;
 -extern const struct _kvm_stats_desc kvm_vcpu_stats_desc[];
  
  #if defined(CONFIG_MMU_NOTIFIER) && defined(KVM_ARCH_WANT_MMU_NOTIFIER)
  static inline int mmu_notifier_retry(struct kvm *kvm, unsigned long mmu_seq)
* Unmerged path arch/arm64/kvm/guest.c
* Unmerged path arch/mips/kvm/mips.c
* Unmerged path arch/powerpc/kvm/book3s.c
* Unmerged path arch/powerpc/kvm/booke.c
* Unmerged path arch/s390/kvm/kvm-s390.c
* Unmerged path arch/x86/kvm/x86.c
* Unmerged path include/linux/kvm_host.h
diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index 9d090cc95b7f..c73b0314feaa 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -118,7 +118,6 @@ static DEFINE_PER_CPU(struct kvm_vcpu *, kvm_running_vcpu);
 struct dentry *kvm_debugfs_dir;
 EXPORT_SYMBOL_GPL(kvm_debugfs_dir);
 
-static int kvm_debugfs_num_entries;
 static const struct file_operations stat_fops_per_vm;
 
 static long kvm_vcpu_ioctl(struct file *file, unsigned int ioctl,
@@ -698,9 +697,24 @@ static void kvm_free_memslots(struct kvm *kvm, struct kvm_memslots *slots)
 	kvfree(slots);
 }
 
+static umode_t kvm_stats_debugfs_mode(const struct _kvm_stats_desc *pdesc)
+{
+	switch (pdesc->desc.flags & KVM_STATS_TYPE_MASK) {
+	case KVM_STATS_TYPE_INSTANT:
+		return 0444;
+	case KVM_STATS_TYPE_CUMULATIVE:
+	case KVM_STATS_TYPE_PEAK:
+	default:
+		return 0644;
+	}
+}
+
+
 static void kvm_destroy_vm_debugfs(struct kvm *kvm)
 {
 	int i;
+	int kvm_debugfs_num_entries = kvm_vm_stats_header.num_desc +
+				      kvm_vcpu_stats_header.num_desc;
 
 	if (!kvm->debugfs_dentry)
 		return;
@@ -718,7 +732,10 @@ static int kvm_create_vm_debugfs(struct kvm *kvm, int fd)
 {
 	char dir_name[ITOA_MAX_LEN * 2];
 	struct kvm_stat_data *stat_data;
-	struct kvm_stats_debugfs_item *p;
+	const struct _kvm_stats_desc *pdesc;
+	int i;
+	int kvm_debugfs_num_entries = kvm_vm_stats_header.num_desc +
+				      kvm_vcpu_stats_header.num_desc;
 
 	if (!debugfs_initialized())
 		return 0;
@@ -732,15 +749,32 @@ static int kvm_create_vm_debugfs(struct kvm *kvm, int fd)
 	if (!kvm->debugfs_stat_data)
 		return -ENOMEM;
 
-	for (p = debugfs_entries; p->name; p++) {
+	for (i = 0; i < kvm_vm_stats_header.num_desc; ++i) {
+		pdesc = &kvm_vm_stats_desc[i];
 		stat_data = kzalloc(sizeof(*stat_data), GFP_KERNEL_ACCOUNT);
 		if (!stat_data)
 			return -ENOMEM;
 
 		stat_data->kvm = kvm;
-		stat_data->dbgfs_item = p;
-		kvm->debugfs_stat_data[p - debugfs_entries] = stat_data;
-		debugfs_create_file(p->name, KVM_DBGFS_GET_MODE(p),
+		stat_data->desc = pdesc;
+		stat_data->kind = KVM_STAT_VM;
+		kvm->debugfs_stat_data[i] = stat_data;
+		debugfs_create_file(pdesc->name, kvm_stats_debugfs_mode(pdesc),
+				    kvm->debugfs_dentry, stat_data,
+				    &stat_fops_per_vm);
+	}
+
+	for (i = 0; i < kvm_vcpu_stats_header.num_desc; ++i) {
+		pdesc = &kvm_vcpu_stats_desc[i];
+		stat_data = kzalloc(sizeof(*stat_data), GFP_KERNEL_ACCOUNT);
+		if (!stat_data)
+			return -ENOMEM;
+
+		stat_data->kvm = kvm;
+		stat_data->desc = pdesc;
+		stat_data->kind = KVM_STAT_VCPU;
+		kvm->debugfs_stat_data[i] = stat_data;
+		debugfs_create_file(pdesc->name, kvm_stats_debugfs_mode(pdesc),
 				    kvm->debugfs_dentry, stat_data,
 				    &stat_fops_per_vm);
 	}
@@ -4663,7 +4697,7 @@ static int kvm_debugfs_open(struct inode *inode, struct file *file,
 		return -ENOENT;
 
 	if (simple_attr_open(inode, file, get,
-		    KVM_DBGFS_GET_MODE(stat_data->dbgfs_item) & 0222
+		    kvm_stats_debugfs_mode(stat_data->desc) & 0222
 		    ? set : NULL,
 		    fmt)) {
 		kvm_put_kvm(stat_data->kvm);
@@ -4686,14 +4720,14 @@ static int kvm_debugfs_release(struct inode *inode, struct file *file)
 
 static int kvm_get_stat_per_vm(struct kvm *kvm, size_t offset, u64 *val)
 {
-	*val = *(u64 *)((void *)kvm + offset);
+	*val = *(u64 *)((void *)(&kvm->stat) + offset);
 
 	return 0;
 }
 
 static int kvm_clear_stat_per_vm(struct kvm *kvm, size_t offset)
 {
-	*(u64 *)((void *)kvm + offset) = 0;
+	*(u64 *)((void *)(&kvm->stat) + offset) = 0;
 
 	return 0;
 }
@@ -4706,7 +4740,7 @@ static int kvm_get_stat_per_vcpu(struct kvm *kvm, size_t offset, u64 *val)
 	*val = 0;
 
 	kvm_for_each_vcpu(i, vcpu, kvm)
-		*val += *(u64 *)((void *)vcpu + offset);
+		*val += *(u64 *)((void *)(&vcpu->stat) + offset);
 
 	return 0;
 }
@@ -4717,7 +4751,7 @@ static int kvm_clear_stat_per_vcpu(struct kvm *kvm, size_t offset)
 	struct kvm_vcpu *vcpu;
 
 	kvm_for_each_vcpu(i, vcpu, kvm)
-		*(u64 *)((void *)vcpu + offset) = 0;
+		*(u64 *)((void *)(&vcpu->stat) + offset) = 0;
 
 	return 0;
 }
@@ -4727,14 +4761,14 @@ static int kvm_stat_data_get(void *data, u64 *val)
 	int r = -EFAULT;
 	struct kvm_stat_data *stat_data = (struct kvm_stat_data *)data;
 
-	switch (stat_data->dbgfs_item->kind) {
+	switch (stat_data->kind) {
 	case KVM_STAT_VM:
 		r = kvm_get_stat_per_vm(stat_data->kvm,
-					stat_data->dbgfs_item->offset, val);
+					stat_data->desc->desc.offset, val);
 		break;
 	case KVM_STAT_VCPU:
 		r = kvm_get_stat_per_vcpu(stat_data->kvm,
-					  stat_data->dbgfs_item->offset, val);
+					  stat_data->desc->desc.offset, val);
 		break;
 	}
 
@@ -4749,14 +4783,14 @@ static int kvm_stat_data_clear(void *data, u64 val)
 	if (val)
 		return -EINVAL;
 
-	switch (stat_data->dbgfs_item->kind) {
+	switch (stat_data->kind) {
 	case KVM_STAT_VM:
 		r = kvm_clear_stat_per_vm(stat_data->kvm,
-					  stat_data->dbgfs_item->offset);
+					  stat_data->desc->desc.offset);
 		break;
 	case KVM_STAT_VCPU:
 		r = kvm_clear_stat_per_vcpu(stat_data->kvm,
-					    stat_data->dbgfs_item->offset);
+					    stat_data->desc->desc.offset);
 		break;
 	}
 
@@ -4813,6 +4847,7 @@ static int vm_stat_clear(void *_offset, u64 val)
 }
 
 DEFINE_SIMPLE_ATTRIBUTE(vm_stat_fops, vm_stat_get, vm_stat_clear, "%llu\n");
+DEFINE_SIMPLE_ATTRIBUTE(vm_stat_readonly_fops, vm_stat_get, NULL, "%llu\n");
 
 static int vcpu_stat_get(void *_offset, u64 *val)
 {
@@ -4849,11 +4884,7 @@ static int vcpu_stat_clear(void *_offset, u64 val)
 
 DEFINE_SIMPLE_ATTRIBUTE(vcpu_stat_fops, vcpu_stat_get, vcpu_stat_clear,
 			"%llu\n");
-
-static const struct file_operations *stat_fops[] = {
-	[KVM_STAT_VCPU] = &vcpu_stat_fops,
-	[KVM_STAT_VM]   = &vm_stat_fops,
-};
+DEFINE_SIMPLE_ATTRIBUTE(vcpu_stat_readonly_fops, vcpu_stat_get, NULL, "%llu\n");
 
 static void kvm_uevent_notify_change(unsigned int type, struct kvm *kvm)
 {
@@ -4907,15 +4938,32 @@ static void kvm_uevent_notify_change(unsigned int type, struct kvm *kvm)
 
 static void kvm_init_debug(void)
 {
-	struct kvm_stats_debugfs_item *p;
+	const struct file_operations *fops;
+	const struct _kvm_stats_desc *pdesc;
+	int i;
 
 	kvm_debugfs_dir = debugfs_create_dir("kvm", NULL);
 
-	kvm_debugfs_num_entries = 0;
-	for (p = debugfs_entries; p->name; ++p, kvm_debugfs_num_entries++) {
-		debugfs_create_file(p->name, KVM_DBGFS_GET_MODE(p),
-				    kvm_debugfs_dir, (void *)(long)p->offset,
-				    stat_fops[p->kind]);
+	for (i = 0; i < kvm_vm_stats_header.num_desc; ++i) {
+		pdesc = &kvm_vm_stats_desc[i];
+		if (kvm_stats_debugfs_mode(pdesc) & 0222)
+			fops = &vm_stat_fops;
+		else
+			fops = &vm_stat_readonly_fops;
+		debugfs_create_file(pdesc->name, kvm_stats_debugfs_mode(pdesc),
+				kvm_debugfs_dir,
+				(void *)(long)pdesc->desc.offset, fops);
+	}
+
+	for (i = 0; i < kvm_vcpu_stats_header.num_desc; ++i) {
+		pdesc = &kvm_vcpu_stats_desc[i];
+		if (kvm_stats_debugfs_mode(pdesc) & 0222)
+			fops = &vcpu_stat_fops;
+		else
+			fops = &vcpu_stat_readonly_fops;
+		debugfs_create_file(pdesc->name, kvm_stats_debugfs_mode(pdesc),
+				kvm_debugfs_dir,
+				(void *)(long)pdesc->desc.offset, fops);
 	}
 }
 
