exec: Transform exec_update_mutex into a rw_semaphore

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Eric W. Biederman <ebiederm@xmission.com>
commit f7cfd871ae0c5008d94b6f66834e7845caa93c15
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/f7cfd871.failed

Recently syzbot reported[0] that there is a deadlock amongst the users
of exec_update_mutex.  The problematic lock ordering found by lockdep
was:

   perf_event_open  (exec_update_mutex -> ovl_i_mutex)
   chown            (ovl_i_mutex       -> sb_writes)
   sendfile         (sb_writes         -> p->lock)
     by reading from a proc file and writing to overlayfs
   proc_pid_syscall (p->lock           -> exec_update_mutex)

While looking at possible solutions it occured to me that all of the
users and possible users involved only wanted to state of the given
process to remain the same.  They are all readers.  The only writer is
exec.

There is no reason for readers to block on each other.  So fix
this deadlock by transforming exec_update_mutex into a rw_semaphore
named exec_update_lock that only exec takes for writing.

	Cc: Jann Horn <jannh@google.com>
	Cc: Vasiliy Kulikov <segoon@openwall.com>
	Cc: Al Viro <viro@zeniv.linux.org.uk>
	Cc: Bernd Edlinger <bernd.edlinger@hotmail.de>
	Cc: Oleg Nesterov <oleg@redhat.com>
	Cc: Christopher Yeoh <cyeoh@au1.ibm.com>
	Cc: Cyrill Gorcunov <gorcunov@gmail.com>
	Cc: Sargun Dhillon <sargun@sargun.me>
	Cc: Christian Brauner <christian.brauner@ubuntu.com>
	Cc: Arnd Bergmann <arnd@arndb.de>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Fixes: eea9673250db ("exec: Add exec_update_mutex to replace cred_guard_mutex")
[0] https://lkml.kernel.org/r/00000000000063640c05ade8e3de@google.com
	Reported-by: syzbot+db9cdf3dd1f64252c6ef@syzkaller.appspotmail.com
Link: https://lkml.kernel.org/r/87ft4mbqen.fsf@x220.int.ebiederm.org
	Signed-off-by: Eric W. Biederman <ebiederm@xmission.com>
(cherry picked from commit f7cfd871ae0c5008d94b6f66834e7845caa93c15)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/exec.c
#	include/linux/sched/signal.h
#	init/init_task.c
#	kernel/events/core.c
#	kernel/fork.c
diff --cc fs/exec.c
index 267f61b63004,ca89e0e3ef10..000000000000
--- a/fs/exec.c
+++ b/fs/exec.c
@@@ -1002,7 -961,13 +1002,15 @@@ ssize_t read_code(struct file *file, un
  	return res;
  }
  EXPORT_SYMBOL(read_code);
 -#endif
  
++<<<<<<< HEAD
++=======
+ /*
+  * Maps the mm_struct mm into the current task struct.
+  * On success, this function returns with exec_update_lock
+  * held for writing.
+  */
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
  static int exec_mmap(struct mm_struct *mm)
  {
  	struct task_struct *tsk;
@@@ -1012,9 -978,14 +1020,18 @@@
  	tsk = current;
  	old_mm = current->mm;
  	exec_mm_release(tsk, old_mm);
++<<<<<<< HEAD
++=======
+ 	if (old_mm)
+ 		sync_mm_rss(old_mm);
+ 
+ 	ret = down_write_killable(&tsk->signal->exec_update_lock);
+ 	if (ret)
+ 		return ret;
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
  
  	if (old_mm) {
 +		sync_mm_rss(old_mm);
  		/*
  		 * Make sure that if there is a core dump in progress
  		 * for the old mm, we get out and die instead of going
@@@ -1024,6 -995,7 +1041,10 @@@
  		mmap_read_lock(old_mm);
  		if (unlikely(old_mm->core_state)) {
  			mmap_read_unlock(old_mm);
++<<<<<<< HEAD
++=======
+ 			up_write(&tsk->signal->exec_update_lock);
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
  			return -EINTR;
  		}
  	}
@@@ -1327,42 -1309,6 +1348,47 @@@ int flush_old_exec(struct linux_binprm 
  	 * undergoing exec(2).
  	 */
  	do_close_on_exec(me->files);
 +	return 0;
 +
++<<<<<<< HEAD
++=======
++out_unlock:
++	up_write(&me->signal->exec_update_lock);
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
 +out:
 +	return retval;
 +}
 +EXPORT_SYMBOL(flush_old_exec);
 +
 +void would_dump(struct linux_binprm *bprm, struct file *file)
 +{
 +	struct inode *inode = file_inode(file);
 +	if (inode_permission(inode, MAY_READ) < 0) {
 +		struct user_namespace *old, *user_ns;
 +		bprm->interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP;
 +
 +		/* Ensure mm->user_ns contains the executable */
 +		user_ns = old = bprm->mm->user_ns;
 +		while ((user_ns != &init_user_ns) &&
 +		       !privileged_wrt_inode_uidgid(user_ns, inode))
 +			user_ns = user_ns->parent;
 +
 +		if (old != user_ns) {
 +			bprm->mm->user_ns = get_user_ns(user_ns);
 +			put_user_ns(old);
 +		}
 +	}
 +}
 +EXPORT_SYMBOL(would_dump);
 +
 +void setup_new_exec(struct linux_binprm * bprm)
 +{
 +	/*
 +	 * Once here, prepare_binrpm() will not be called any more, so
 +	 * the final state of setuid/setgid/fscaps can be merged into the
 +	 * secureexec flag.
 +	 */
 +	bprm->secureexec |= bprm->cap_elevated;
  
  	if (bprm->secureexec) {
  		/* Make sure parent cannot signal privileged process. */
@@@ -1395,26 -1339,97 +1421,32 @@@
  	else
  		set_dumpable(current->mm, SUID_DUMP_USER);
  
 +	arch_setup_new_exec();
  	perf_event_exec();
 -	__set_task_comm(me, kbasename(bprm->filename), true);
 -
 -	/* An exec changes our domain. We are no longer part of the thread
 -	   group */
 -	WRITE_ONCE(me->self_exec_id, me->self_exec_id + 1);
 -	flush_signal_handlers(me, 0);
 +	__set_task_comm(current, kbasename(bprm->filename), true);
  
 -	/*
 -	 * install the new credentials for this executable
 -	 */
 -	security_bprm_committing_creds(bprm);
 -
 -	commit_creds(bprm->cred);
 -	bprm->cred = NULL;
 -
 -	/*
 -	 * Disable monitoring for regular users
 -	 * when executing setuid binaries. Must
 -	 * wait until new credentials are committed
 -	 * by commit_creds() above
 -	 */
 -	if (get_dumpable(me->mm) != SUID_DUMP_USER)
 -		perf_event_exit_task(me);
 -	/*
 -	 * cred_guard_mutex must be held at least to this point to prevent
 -	 * ptrace_attach() from altering our determination of the task's
 -	 * credentials; any time after this it may be unlocked.
 +	/* Set the new mm task size. We have to do that late because it may
 +	 * depend on TIF_32BIT which is only updated in flush_thread() on
 +	 * some architectures like powerpc
  	 */
 -	security_bprm_committed_creds(bprm);
 -
 -	/* Pass the opened binary to the interpreter. */
 -	if (bprm->have_execfd) {
 -		retval = get_unused_fd_flags(0);
 -		if (retval < 0)
 -			goto out_unlock;
 -		fd_install(retval, bprm->executable);
 -		bprm->executable = NULL;
 -		bprm->execfd = retval;
 -	}
 -	return 0;
++<<<<<<< HEAD
 +	current->mm->task_size = TASK_SIZE;
  
 -out_unlock:
 +	/* An exec changes our domain. We are no longer part of the thread
 +	   group */
 +	WRITE_ONCE(current->task_struct_rh->self_exec_id,
 +		current->task_struct_rh->self_exec_id + 1);
 +	flush_signal_handlers(current, 0);
++=======
++	me->mm->task_size = TASK_SIZE;
+ 	up_write(&me->signal->exec_update_lock);
 -out:
 -	return retval;
++	mutex_unlock(&me->signal->cred_guard_mutex);
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
  }
 -EXPORT_SYMBOL(begin_new_exec);
 +EXPORT_SYMBOL(setup_new_exec);
  
 -void would_dump(struct linux_binprm *bprm, struct file *file)
 -{
 -	struct inode *inode = file_inode(file);
 -	if (inode_permission(inode, MAY_READ) < 0) {
 -		struct user_namespace *old, *user_ns;
 -		bprm->interp_flags |= BINPRM_FLAGS_ENFORCE_NONDUMP;
 -
 -		/* Ensure mm->user_ns contains the executable */
 -		user_ns = old = bprm->mm->user_ns;
 -		while ((user_ns != &init_user_ns) &&
 -		       !privileged_wrt_inode_uidgid(user_ns, inode))
 -			user_ns = user_ns->parent;
 -
 -		if (old != user_ns) {
 -			bprm->mm->user_ns = get_user_ns(user_ns);
 -			put_user_ns(old);
 -		}
 -	}
 -}
 -EXPORT_SYMBOL(would_dump);
 -
 -void setup_new_exec(struct linux_binprm * bprm)
 -{
 -	/* Setup things that can depend upon the personality */
 -	struct task_struct *me = current;
 -
 -	arch_pick_mmap_layout(me->mm, &bprm->rlim_stack);
 -
 -	arch_setup_new_exec();
 -
 -	/* Set the new mm task size. We have to do that late because it may
 -	 * depend on TIF_32BIT which is only updated in flush_thread() on
 -	 * some architectures like powerpc
 -	 */
 -	me->mm->task_size = TASK_SIZE;
 -	up_write(&me->signal->exec_update_lock);
 -	mutex_unlock(&me->signal->cred_guard_mutex);
 -}
 -EXPORT_SYMBOL(setup_new_exec);
 -
 -/* Runs immediately before start_thread() takes over. */
 -void finalize_exec(struct linux_binprm *bprm)
 +/* Runs immediately before start_thread() takes over. */
 +void finalize_exec(struct linux_binprm *bprm)
  {
  	/* Store any stack rlimit changes before starting thread. */
  	task_lock(current->group_leader);
diff --cc include/linux/sched/signal.h
index b260e8feef0c,4b6a8234d7fc..000000000000
--- a/include/linux/sched/signal.h
+++ b/include/linux/sched/signal.h
@@@ -228,23 -226,15 +228,35 @@@ struct signal_struct 
  
  	struct mutex cred_guard_mutex;	/* guard against foreign influences on
  					 * credential calculations
++<<<<<<< HEAD
 +					 * (notably. ptrace) */
 +
 +	/*
 +	 * RHEL8: signal_struct is always dynamically allocated at process
 +	 * creation time and not embedded directly into other structure.
 +	 * So it is safe to extend the size of the structure.
 +	 */
 +	/* PID/PID hash table linkage. */
 +	RH_KABI_EXTEND(struct pid *pids[PIDTYPE_MAX])
 +
 +	/* For collecting multiprocess signals during fork */
 +	RH_KABI_USE(1, struct hlist_head multiprocess)
 +
 +	RH_KABI_RESERVE(2)
 +	RH_KABI_RESERVE(3)
 +	RH_KABI_RESERVE(4)
 +	RH_KABI_EXTEND(struct posix_cputimers posix_cputimers)
++=======
+ 					 * (notably. ptrace)
+ 					 * Deprecated do not use in new code.
+ 					 * Use exec_update_lock instead.
+ 					 */
+ 	struct rw_semaphore exec_update_lock;	/* Held while task_struct is
+ 						 * being updated during exec,
+ 						 * and may have inconsistent
+ 						 * permissions.
+ 						 */
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
  } __randomize_layout;
  
  /*
diff --cc init/init_task.c
index a267e8049159,15f6eb93a04f..000000000000
--- a/init/init_task.c
+++ b/init/init_task.c
@@@ -27,6 -26,7 +27,10 @@@ static struct signal_struct init_signal
  	.multiprocess	= HLIST_HEAD_INIT,
  	.rlim		= INIT_RLIMITS,
  	.cred_guard_mutex = __MUTEX_INITIALIZER(init_signals.cred_guard_mutex),
++<<<<<<< HEAD
++=======
+ 	.exec_update_lock = __RWSEM_INITIALIZER(init_signals.exec_update_lock),
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
  #ifdef CONFIG_POSIX_TIMERS
  	.posix_timers = LIST_HEAD_INIT(init_signals.posix_timers),
  	.cputimer	= {
diff --cc kernel/events/core.c
index 9ae222f3c9bc,55b2330b556c..000000000000
--- a/kernel/events/core.c
+++ b/kernel/events/core.c
@@@ -1332,7 -1325,7 +1332,11 @@@ static void put_ctx(struct perf_event_c
   * function.
   *
   * Lock order:
++<<<<<<< HEAD
 + *    cred_guard_mutex
++=======
+  *    exec_update_lock
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
   *	task_struct::perf_event_mutex
   *	  perf_event_context::mutex
   *	    perf_event::child_mutex;
@@@ -11917,6 -11720,24 +11921,27 @@@ SYSCALL_DEFINE5(perf_event_open
  		goto err_task;
  	}
  
++<<<<<<< HEAD
++=======
+ 	if (task) {
+ 		err = down_read_interruptible(&task->signal->exec_update_lock);
+ 		if (err)
+ 			goto err_task;
+ 
+ 		/*
+ 		 * Preserve ptrace permission check for backwards compatibility.
+ 		 *
+ 		 * We must hold exec_update_lock across this and any potential
+ 		 * perf_install_in_context() call for this new event to
+ 		 * serialize against exec() altering our credentials (and the
+ 		 * perf_event_exit_task() that could imply).
+ 		 */
+ 		err = -EACCES;
+ 		if (!perfmon_capable() && !ptrace_may_access(task, PTRACE_MODE_READ_REALCREDS))
+ 			goto err_cred;
+ 	}
+ 
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
  	if (flags & PERF_FLAG_PID_CGROUP)
  		cgroup_fd = pid;
  
@@@ -12214,7 -12017,7 +12239,11 @@@
  	mutex_unlock(&ctx->mutex);
  
  	if (task) {
++<<<<<<< HEAD
 +		mutex_unlock(&task->signal->cred_guard_mutex);
++=======
+ 		up_read(&task->signal->exec_update_lock);
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
  		put_task_struct(task);
  	}
  
@@@ -12251,6 -12051,9 +12280,12 @@@ err_alloc
  	 */
  	if (!event_file)
  		free_event(event);
++<<<<<<< HEAD
++=======
+ err_cred:
+ 	if (task)
+ 		up_read(&task->signal->exec_update_lock);
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
  err_task:
  	if (task)
  		put_task_struct(task);
@@@ -12555,8 -12358,8 +12590,13 @@@ static void perf_event_exit_task_contex
  /*
   * When a child task exits, feed back event values to parent events.
   *
++<<<<<<< HEAD
 + * Can be called with cred_guard_mutex held when called from
 + * install_exec_creds().
++=======
+  * Can be called with exec_update_lock held when called from
+  * setup_new_exec().
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
   */
  void perf_event_exit_task(struct task_struct *child)
  {
diff --cc kernel/fork.c
index 20adca7ab057,e8cb80b266d2..000000000000
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@@ -1590,6 -1591,7 +1590,10 @@@ static int copy_signal(unsigned long cl
  	sig->oom_score_adj_min = current->signal->oom_score_adj_min;
  
  	mutex_init(&sig->cred_guard_mutex);
++<<<<<<< HEAD
++=======
+ 	init_rwsem(&sig->exec_update_lock);
++>>>>>>> f7cfd871ae0c (exec: Transform exec_update_mutex into a rw_semaphore)
  
  	return 0;
  }
* Unmerged path fs/exec.c
diff --git a/fs/proc/base.c b/fs/proc/base.c
index a1601d41d21d..52fd3d37499c 100644
--- a/fs/proc/base.c
+++ b/fs/proc/base.c
@@ -387,11 +387,11 @@ static int proc_pid_wchan(struct seq_file *m, struct pid_namespace *ns,
 
 static int lock_trace(struct task_struct *task)
 {
-	int err = mutex_lock_killable(&task->signal->exec_update_mutex);
+	int err = down_read_killable(&task->signal->exec_update_lock);
 	if (err)
 		return err;
 	if (!ptrace_may_access(task, PTRACE_MODE_ATTACH_FSCREDS)) {
-		mutex_unlock(&task->signal->exec_update_mutex);
+		up_read(&task->signal->exec_update_lock);
 		return -EPERM;
 	}
 	return 0;
@@ -399,7 +399,7 @@ static int lock_trace(struct task_struct *task)
 
 static void unlock_trace(struct task_struct *task)
 {
-	mutex_unlock(&task->signal->exec_update_mutex);
+	up_read(&task->signal->exec_update_lock);
 }
 
 #ifdef CONFIG_STACKTRACE
@@ -2857,7 +2857,7 @@ static int do_io_accounting(struct task_struct *task, struct seq_file *m, int wh
 	unsigned long flags;
 	int result;
 
-	result = mutex_lock_killable(&task->signal->exec_update_mutex);
+	result = down_read_killable(&task->signal->exec_update_lock);
 	if (result)
 		return result;
 
@@ -2893,7 +2893,7 @@ static int do_io_accounting(struct task_struct *task, struct seq_file *m, int wh
 	result = 0;
 
 out_unlock:
-	mutex_unlock(&task->signal->exec_update_mutex);
+	up_read(&task->signal->exec_update_lock);
 	return result;
 }
 
* Unmerged path include/linux/sched/signal.h
* Unmerged path init/init_task.c
* Unmerged path kernel/events/core.c
* Unmerged path kernel/fork.c
diff --git a/kernel/kcmp.c b/kernel/kcmp.c
index b3ff9288c6cc..c0d2ad9b4705 100644
--- a/kernel/kcmp.c
+++ b/kernel/kcmp.c
@@ -75,25 +75,25 @@ get_file_raw_ptr(struct task_struct *task, unsigned int idx)
 	return file;
 }
 
-static void kcmp_unlock(struct mutex *m1, struct mutex *m2)
+static void kcmp_unlock(struct rw_semaphore *l1, struct rw_semaphore *l2)
 {
-	if (likely(m2 != m1))
-		mutex_unlock(m2);
-	mutex_unlock(m1);
+	if (likely(l2 != l1))
+		up_read(l2);
+	up_read(l1);
 }
 
-static int kcmp_lock(struct mutex *m1, struct mutex *m2)
+static int kcmp_lock(struct rw_semaphore *l1, struct rw_semaphore *l2)
 {
 	int err;
 
-	if (m2 > m1)
-		swap(m1, m2);
+	if (l2 > l1)
+		swap(l1, l2);
 
-	err = mutex_lock_killable(m1);
-	if (!err && likely(m1 != m2)) {
-		err = mutex_lock_killable_nested(m2, SINGLE_DEPTH_NESTING);
+	err = down_read_killable(l1);
+	if (!err && likely(l1 != l2)) {
+		err = down_read_killable_nested(l2, SINGLE_DEPTH_NESTING);
 		if (err)
-			mutex_unlock(m1);
+			up_read(l1);
 	}
 
 	return err;
@@ -173,8 +173,8 @@ SYSCALL_DEFINE5(kcmp, pid_t, pid1, pid_t, pid2, int, type,
 	/*
 	 * One should have enough rights to inspect task details.
 	 */
-	ret = kcmp_lock(&task1->signal->exec_update_mutex,
-			&task2->signal->exec_update_mutex);
+	ret = kcmp_lock(&task1->signal->exec_update_lock,
+			&task2->signal->exec_update_lock);
 	if (ret)
 		goto err;
 	if (!ptrace_may_access(task1, PTRACE_MODE_READ_REALCREDS) ||
@@ -229,8 +229,8 @@ SYSCALL_DEFINE5(kcmp, pid_t, pid1, pid_t, pid2, int, type,
 	}
 
 err_unlock:
-	kcmp_unlock(&task1->signal->exec_update_mutex,
-		    &task2->signal->exec_update_mutex);
+	kcmp_unlock(&task1->signal->exec_update_lock,
+		    &task2->signal->exec_update_lock);
 err:
 	put_task_struct(task1);
 	put_task_struct(task2);
diff --git a/kernel/pid.c b/kernel/pid.c
index 88bfb334a3f8..1df5a8c494fc 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -480,7 +480,7 @@ static struct file *__pidfd_fget(struct task_struct *task, int fd)
 	struct file *file;
 	int ret;
 
-	ret = mutex_lock_killable(&task->signal->exec_update_mutex);
+	ret = down_read_killable(&task->signal->exec_update_lock);
 	if (ret)
 		return ERR_PTR(ret);
 
@@ -489,7 +489,7 @@ static struct file *__pidfd_fget(struct task_struct *task, int fd)
 	else
 		file = ERR_PTR(-EPERM);
 
-	mutex_unlock(&task->signal->exec_update_mutex);
+	up_read(&task->signal->exec_update_lock);
 
 	return file ?: ERR_PTR(-EBADF);
 }
