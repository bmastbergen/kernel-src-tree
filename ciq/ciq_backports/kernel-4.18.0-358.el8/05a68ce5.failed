bpf: Don't do bpf_cgroup_storage_set() for kuprobe/tp programs

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Yonghong Song <yhs@fb.com>
commit 05a68ce5fa51a83c360381630f823545c5757aa2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/05a68ce5.failed

For kuprobe and tracepoint bpf programs, kernel calls
trace_call_bpf() which calls BPF_PROG_RUN_ARRAY_CHECK()
to run the program array. Currently, BPF_PROG_RUN_ARRAY_CHECK()
also calls bpf_cgroup_storage_set() to set percpu
cgroup local storage with NULL value. This is
due to Commit 394e40a29788 ("bpf: extend bpf_prog_array to store
pointers to the cgroup storage") which modified
__BPF_PROG_RUN_ARRAY() to call bpf_cgroup_storage_set()
and this macro is also used by BPF_PROG_RUN_ARRAY_CHECK().

kuprobe and tracepoint programs are not allowed to call
bpf_get_local_storage() helper hence does not
access percpu cgroup local storage. Let us
change BPF_PROG_RUN_ARRAY_CHECK() not to
modify percpu cgroup local storage.

The issue is observed when I tried to debug [1] where
percpu data is overwritten due to
  preempt_disable -> migration_disable
change. This patch does not completely fix the above issue,
which will be addressed separately, e.g., multiple cgroup
prog runs may preempt each other. But it does fix
any potential issue caused by tracing program
overwriting percpu cgroup storage:
 - in a busy system, a tracing program is to run between
   bpf_cgroup_storage_set() and the cgroup prog run.
 - a kprobe program is triggered by a helper in cgroup prog
   before bpf_get_local_storage() is called.

 [1] https://lore.kernel.org/bpf/CAKH8qBuXCfUz=w8L+Fj74OaUpbosO29niYwTki7e3Ag044_aww@mail.gmail.com/T

Fixes: 394e40a29788 ("bpf: extend bpf_prog_array to store pointers to the cgroup storage")
	Signed-off-by: Yonghong Song <yhs@fb.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Roman Gushchin <guro@fb.com>
Link: https://lore.kernel.org/bpf/20210309185028.3763817-1-yhs@fb.com
(cherry picked from commit 05a68ce5fa51a83c360381630f823545c5757aa2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
diff --cc include/linux/bpf.h
index 0224d4d0ec67,d7e0f479a5b0..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -1113,7 -1065,35 +1113,39 @@@ int bpf_prog_array_copy(struct bpf_prog
  			struct bpf_prog *include_prog,
  			struct bpf_prog_array **new_array);
  
++<<<<<<< HEAD
 +#define __BPF_PROG_RUN_ARRAY(array, ctx, func, check_non_null)	\
++=======
+ /* BPF program asks to bypass CAP_NET_BIND_SERVICE in bind. */
+ #define BPF_RET_BIND_NO_CAP_NET_BIND_SERVICE			(1 << 0)
+ /* BPF program asks to set CN on the packet. */
+ #define BPF_RET_SET_CN						(1 << 0)
+ 
+ #define BPF_PROG_RUN_ARRAY_FLAGS(array, ctx, func, ret_flags)		\
+ 	({								\
+ 		struct bpf_prog_array_item *_item;			\
+ 		struct bpf_prog *_prog;					\
+ 		struct bpf_prog_array *_array;				\
+ 		u32 _ret = 1;						\
+ 		u32 func_ret;						\
+ 		migrate_disable();					\
+ 		rcu_read_lock();					\
+ 		_array = rcu_dereference(array);			\
+ 		_item = &_array->items[0];				\
+ 		while ((_prog = READ_ONCE(_item->prog))) {		\
+ 			bpf_cgroup_storage_set(_item->cgroup_storage);	\
+ 			func_ret = func(_prog, ctx);			\
+ 			_ret &= (func_ret & 1);				\
+ 			*(ret_flags) |= (func_ret >> 1);			\
+ 			_item++;					\
+ 		}							\
+ 		rcu_read_unlock();					\
+ 		migrate_enable();					\
+ 		_ret;							\
+ 	 })
+ 
+ #define __BPF_PROG_RUN_ARRAY(array, ctx, func, check_non_null, set_cg_storage)	\
++>>>>>>> 05a68ce5fa51 (bpf: Don't do bpf_cgroup_storage_set() for kuprobe/tp programs)
  	({						\
  		struct bpf_prog_array_item *_item;	\
  		struct bpf_prog *_prog;			\
* Unmerged path include/linux/bpf.h
