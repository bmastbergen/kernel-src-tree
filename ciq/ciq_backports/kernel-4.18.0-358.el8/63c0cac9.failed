KVM: x86/mmu: Refactor is_tdp_mmu_root into is_tdp_mmu

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author David Matlack <dmatlack@google.com>
commit 63c0cac938edfa5d72bfbe8f1eeb9d47b397829c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/63c0cac9.failed

This change simplifies the call sites slightly and also abstracts away
the implementation detail of looking at root_hpa as the mechanism for
determining if the mmu is the TDP MMU.

	Suggested-by: Sean Christopherson <seanjc@google.com>
	Signed-off-by: David Matlack <dmatlack@google.com>
Message-Id: <20210617231948.2591431-4-dmatlack@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 63c0cac938edfa5d72bfbe8f1eeb9d47b397829c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu/tdp_mmu.h
diff --cc arch/x86/kvm/mmu/tdp_mmu.h
index f74813ea3313,b981a044ab55..000000000000
--- a/arch/x86/kvm/mmu/tdp_mmu.h
+++ b/arch/x86/kvm/mmu/tdp_mmu.h
@@@ -79,16 -85,11 +79,17 @@@ void kvm_mmu_init_tdp_mmu(struct kvm *k
  void kvm_mmu_uninit_tdp_mmu(struct kvm *kvm);
  static inline bool is_tdp_mmu_enabled(struct kvm *kvm) { return kvm->arch.tdp_mmu_enabled; }
  static inline bool is_tdp_mmu_page(struct kvm_mmu_page *sp) { return sp->tdp_mmu_page; }
 +#else
 +static inline void kvm_mmu_init_tdp_mmu(struct kvm *kvm) {}
 +static inline void kvm_mmu_uninit_tdp_mmu(struct kvm *kvm) {}
 +static inline bool is_tdp_mmu_enabled(struct kvm *kvm) { return false; }
 +static inline bool is_tdp_mmu_page(struct kvm_mmu_page *sp) { return false; }
 +#endif
  
- static inline bool is_tdp_mmu_root(hpa_t hpa)
+ static inline bool is_tdp_mmu(struct kvm_mmu *mmu)
  {
  	struct kvm_mmu_page *sp;
+ 	hpa_t hpa = mmu->root_hpa;
  
  	if (WARN_ON(!VALID_PAGE(hpa)))
  		return false;
@@@ -99,5 -100,12 +100,15 @@@
  
  	return is_tdp_mmu_page(sp) && sp->root_count;
  }
++<<<<<<< HEAD
++=======
+ #else
+ static inline bool kvm_mmu_init_tdp_mmu(struct kvm *kvm) { return false; }
+ static inline void kvm_mmu_uninit_tdp_mmu(struct kvm *kvm) {}
+ static inline bool is_tdp_mmu_enabled(struct kvm *kvm) { return false; }
+ static inline bool is_tdp_mmu_page(struct kvm_mmu_page *sp) { return false; }
+ static inline bool is_tdp_mmu(struct kvm_mmu *mmu) { return false; }
+ #endif
++>>>>>>> 63c0cac938ed (KVM: x86/mmu: Refactor is_tdp_mmu_root into is_tdp_mmu)
  
  #endif /* __KVM_X86_MMU_TDP_MMU_H */
diff --git a/arch/x86/kvm/mmu/mmu.c b/arch/x86/kvm/mmu/mmu.c
index 3ea1a3f588dc..2eacb3c23410 100644
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@ -3625,7 +3625,7 @@ static bool get_mmio_spte(struct kvm_vcpu *vcpu, u64 addr, u64 *sptep)
 		return reserved;
 	}
 
-	if (is_tdp_mmu_root(vcpu->arch.mmu->root_hpa))
+	if (is_tdp_mmu(vcpu->arch.mmu))
 		leaf = kvm_tdp_mmu_get_walk(vcpu, addr, sptes, &root);
 	else
 		leaf = get_walk(vcpu, addr, sptes, &root);
@@ -3797,7 +3797,7 @@ static bool try_async_pf(struct kvm_vcpu *vcpu, bool prefault, gfn_t gfn,
 static int direct_page_fault(struct kvm_vcpu *vcpu, gpa_t gpa, u32 error_code,
 			     bool prefault, int max_level, bool is_tdp)
 {
-	bool is_tdp_mmu_fault = is_tdp_mmu_root(vcpu->arch.mmu->root_hpa);
+	bool is_tdp_mmu_fault = is_tdp_mmu(vcpu->arch.mmu);
 	bool write = error_code & PFERR_WRITE_MASK;
 	bool map_writable;
 
* Unmerged path arch/x86/kvm/mmu/tdp_mmu.h
