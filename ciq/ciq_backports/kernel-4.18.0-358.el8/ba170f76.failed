mm, notifier: Catch sleeping/blocking for !blockable

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Daniel Vetter <daniel.vetter@ffwll.ch>
commit ba170f76b69d1d45a60eaa9ec920c8fddd4c16f3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/ba170f76.failed

We need to make sure implementations don't cheat and don't have a possible
schedule/blocking point deeply burried where review can't catch it.

I'm not sure whether this is the best way to make sure all the
might_sleep() callsites trigger, and it's a bit ugly in the code flow.
But it gets the job done.

Inspired by an i915 patch series which did exactly that, because the rules
haven't been entirely clear to us.

Link: https://lore.kernel.org/r/20190826201425.17547-5-daniel.vetter@ffwll.ch
	Reviewed-by: Christian König <christian.koenig@amd.com> (v1)
	Reviewed-by: Jérôme Glisse <jglisse@redhat.com> (v4)
	Signed-off-by: Daniel Vetter <daniel.vetter@intel.com>
	Reviewed-by: Jason Gunthorpe <jgg@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit ba170f76b69d1d45a60eaa9ec920c8fddd4c16f3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/mmu_notifier.c
diff --cc mm/mmu_notifier.c
index 4361d699fa34,7fde88695f35..000000000000
--- a/mm/mmu_notifier.c
+++ b/mm/mmu_notifier.c
@@@ -452,9 -165,24 +452,27 @@@ static void mn_hlist_invalidate_range_s
  	int id;
  
  	id = srcu_read_lock(&srcu);
 -	hlist_for_each_entry_rcu(mn, &range->mm->mmu_notifier_mm->list, hlist) {
 +	hlist_for_each_entry_rcu(mn, &mmn_mm->list, hlist) {
  		if (mn->ops->invalidate_range_start) {
++<<<<<<< HEAD
 +			mn->ops->invalidate_range_start(mn, range->mm, range->start, range->end);
++=======
+ 			int _ret;
+ 
+ 			if (!mmu_notifier_range_blockable(range))
+ 				non_block_start();
+ 			_ret = mn->ops->invalidate_range_start(mn, range);
+ 			if (!mmu_notifier_range_blockable(range))
+ 				non_block_end();
+ 			if (_ret) {
+ 				pr_info("%pS callback failed with %d in %sblockable context.\n",
+ 					mn->ops->invalidate_range_start, _ret,
+ 					!mmu_notifier_range_blockable(range) ? "non-" : "");
+ 				WARN_ON(mmu_notifier_range_blockable(range) ||
+ 					ret != -EAGAIN);
+ 				ret = _ret;
+ 			}
++>>>>>>> ba170f76b69d (mm, notifier: Catch sleeping/blocking for !blockable)
  		}
  	}
  	srcu_read_unlock(&srcu, id);
@@@ -498,7 -217,11 +516,15 @@@ static void mn_hlist_invalidate_end(str
  						  range->start,
  						  range->end);
  		if (mn->ops->invalidate_range_end) {
++<<<<<<< HEAD
 +			mn->ops->invalidate_range_end(mn, range->mm, range->start, range->end);
++=======
+ 			if (!mmu_notifier_range_blockable(range))
+ 				non_block_start();
+ 			mn->ops->invalidate_range_end(mn, range);
+ 			if (!mmu_notifier_range_blockable(range))
+ 				non_block_end();
++>>>>>>> ba170f76b69d (mm, notifier: Catch sleeping/blocking for !blockable)
  		}
  	}
  	srcu_read_unlock(&srcu, id);
* Unmerged path mm/mmu_notifier.c
