mptcp: faster active backup recovery

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Paolo Abeni <pabeni@redhat.com>
commit ff5a0b421cb23bf6b2898939ffef5b683045d9d3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/ff5a0b42.failed

The msk can use backup subflows to transmit in-sequence data
only if there are no other active subflow. On active backup
scenario, the MPTCP connection can do forward progress only
due to MPTCP retransmissions - rtx can pick backup subflows.

This patch introduces a new flag flow MPTCP subflows: if the
underlying TCP connection made no progresses for long time,
and there are other less problematic subflows available, the
given subflow become stale.

Stale subflows are not considered active: if all non backup
subflows become stale, the MPTCP scheduler can pick backup
subflows for plain transmissions.

Stale subflows can return in active state, as soon as any reply
from the peer is observed.

Active backup scenarios can now leverage the available b/w
with no restrinction.

Closes: https://github.com/multipath-tcp/mptcp_net-next/issues/207
	Signed-off-by: Paolo Abeni <pabeni@redhat.com>
	Signed-off-by: Mat Martineau <mathew.j.martineau@linux.intel.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit ff5a0b421cb23bf6b2898939ffef5b683045d9d3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/networking/mptcp-sysctl.rst
#	net/mptcp/ctrl.c
#	net/mptcp/protocol.h
diff --cc Documentation/networking/mptcp-sysctl.rst
index 3b352e5f6300,b0d4da71e68e..000000000000
--- a/Documentation/networking/mptcp-sysctl.rst
+++ b/Documentation/networking/mptcp-sysctl.rst
@@@ -24,3 -24,36 +24,39 @@@ add_addr_timeout - INTEGER (seconds
  	sysctl.
  
  	Default: 120
++<<<<<<< HEAD
++=======
+ 
+ checksum_enabled - BOOLEAN
+ 	Control whether DSS checksum can be enabled.
+ 
+ 	DSS checksum can be enabled if the value is nonzero. This is a
+ 	per-namespace sysctl.
+ 
+ 	Default: 0
+ 
+ allow_join_initial_addr_port - BOOLEAN
+ 	Allow peers to send join requests to the IP address and port number used
+ 	by the initial subflow if the value is 1. This controls a flag that is
+ 	sent to the peer at connection time, and whether such join requests are
+ 	accepted or denied.
+ 
+ 	Joins to addresses advertised with ADD_ADDR are not affected by this
+ 	value.
+ 
+ 	This is a per-namespace sysctl.
+ 
+ 	Default: 1
+ 
+ stale_loss_cnt - INTEGER
+ 	The number of MPTCP-level retransmission intervals with no traffic and
+ 	pending outstanding data on a given subflow required to declare it stale.
+ 	The packet scheduler ignores stale subflows.
+ 	A low stale_loss_cnt  value allows for fast active-backup switch-over,
+ 	an high value maximize links utilization on edge scenarios e.g. lossy
+ 	link with high BER or peer pausing the data processing.
+ 
+ 	This is a per-namespace sysctl.
+ 
+ 	Default: 4
++>>>>>>> ff5a0b421cb2 (mptcp: faster active backup recovery)
diff --cc net/mptcp/ctrl.c
index 7ce1fb8404d7,8b235468c88f..000000000000
--- a/net/mptcp/ctrl.c
+++ b/net/mptcp/ctrl.c
@@@ -21,11 -21,14 +21,18 @@@ struct mptcp_pernet 
  	struct ctl_table_header *ctl_table_hdr;
  #endif
  
 +	int mptcp_enabled;
  	unsigned int add_addr_timeout;
++<<<<<<< HEAD
++=======
+ 	unsigned int stale_loss_cnt;
+ 	u8 mptcp_enabled;
+ 	u8 checksum_enabled;
+ 	u8 allow_join_initial_addr_port;
++>>>>>>> ff5a0b421cb2 (mptcp: faster active backup recovery)
  };
  
 -static struct mptcp_pernet *mptcp_get_pernet(const struct net *net)
 +static struct mptcp_pernet *mptcp_get_pernet(struct net *net)
  {
  	return net_generic(net, mptcp_pernet_id);
  }
@@@ -40,10 -43,28 +47,34 @@@ unsigned int mptcp_get_add_addr_timeout
  	return mptcp_get_pernet(net)->add_addr_timeout;
  }
  
++<<<<<<< HEAD
++=======
+ int mptcp_is_checksum_enabled(const struct net *net)
+ {
+ 	return mptcp_get_pernet(net)->checksum_enabled;
+ }
+ 
+ int mptcp_allow_join_id0(const struct net *net)
+ {
+ 	return mptcp_get_pernet(net)->allow_join_initial_addr_port;
+ }
+ 
+ unsigned int mptcp_stale_loss_cnt(const struct net *net)
+ {
+ 	return mptcp_get_pernet(net)->stale_loss_cnt;
+ }
+ 
++>>>>>>> ff5a0b421cb2 (mptcp: faster active backup recovery)
  static void mptcp_pernet_set_defaults(struct mptcp_pernet *pernet)
  {
 -	pernet->mptcp_enabled = 1;
 +	pernet->mptcp_enabled = 0;
  	pernet->add_addr_timeout = TCP_RTO_MAX;
++<<<<<<< HEAD
++=======
+ 	pernet->checksum_enabled = 0;
+ 	pernet->allow_join_initial_addr_port = 1;
+ 	pernet->stale_loss_cnt = 4;
++>>>>>>> ff5a0b421cb2 (mptcp: faster active backup recovery)
  }
  
  #ifdef CONFIG_SYSCTL
@@@ -65,6 -86,28 +96,31 @@@ static struct ctl_table mptcp_sysctl_ta
  		.mode = 0644,
  		.proc_handler = proc_dointvec_jiffies,
  	},
++<<<<<<< HEAD
++=======
+ 	{
+ 		.procname = "checksum_enabled",
+ 		.maxlen = sizeof(u8),
+ 		.mode = 0644,
+ 		.proc_handler = proc_dou8vec_minmax,
+ 		.extra1       = SYSCTL_ZERO,
+ 		.extra2       = SYSCTL_ONE
+ 	},
+ 	{
+ 		.procname = "allow_join_initial_addr_port",
+ 		.maxlen = sizeof(u8),
+ 		.mode = 0644,
+ 		.proc_handler = proc_dou8vec_minmax,
+ 		.extra1       = SYSCTL_ZERO,
+ 		.extra2       = SYSCTL_ONE
+ 	},
+ 	{
+ 		.procname = "stale_loss_cnt",
+ 		.maxlen = sizeof(unsigned int),
+ 		.mode = 0644,
+ 		.proc_handler = proc_douintvec_minmax,
+ 	},
++>>>>>>> ff5a0b421cb2 (mptcp: faster active backup recovery)
  	{}
  };
  
@@@ -82,6 -125,9 +138,12 @@@ static int mptcp_pernet_new_table(struc
  
  	table[0].data = &pernet->mptcp_enabled;
  	table[1].data = &pernet->add_addr_timeout;
++<<<<<<< HEAD
++=======
+ 	table[2].data = &pernet->checksum_enabled;
+ 	table[3].data = &pernet->allow_join_initial_addr_port;
+ 	table[4].data = &pernet->stale_loss_cnt;
++>>>>>>> ff5a0b421cb2 (mptcp: faster active backup recovery)
  
  	hdr = register_net_sysctl(net, MPTCP_SYSCTL_PATH, table);
  	if (!hdr)
diff --cc net/mptcp/protocol.h
index 5c8dbbab0f7e,8bdd038def38..000000000000
--- a/net/mptcp/protocol.h
+++ b/net/mptcp/protocol.h
@@@ -530,10 -557,15 +531,22 @@@ static inline void mptcp_subflow_delega
  	clear_bit(MPTCP_DELEGATE_SEND, &subflow->delegated_status);
  }
  
++<<<<<<< HEAD
 +int mptcp_is_enabled(struct net *net);
 +unsigned int mptcp_get_add_addr_timeout(struct net *net);
 +void mptcp_subflow_fully_established(struct mptcp_subflow_context *subflow,
 +				     struct mptcp_options_received *mp_opt);
++=======
+ int mptcp_is_enabled(const struct net *net);
+ unsigned int mptcp_get_add_addr_timeout(const struct net *net);
+ int mptcp_is_checksum_enabled(const struct net *net);
+ int mptcp_allow_join_id0(const struct net *net);
+ unsigned int mptcp_stale_loss_cnt(const struct net *net);
+ void mptcp_subflow_fully_established(struct mptcp_subflow_context *subflow,
+ 				     struct mptcp_options_received *mp_opt);
+ bool __mptcp_retransmit_pending_data(struct sock *sk);
+ void __mptcp_push_pending(struct sock *sk, unsigned int flags);
++>>>>>>> ff5a0b421cb2 (mptcp: faster active backup recovery)
  bool mptcp_subflow_data_available(struct sock *sk);
  void __init mptcp_subflow_init(void);
  void mptcp_subflow_shutdown(struct sock *sk, struct sock *ssk, int how);
* Unmerged path Documentation/networking/mptcp-sysctl.rst
* Unmerged path net/mptcp/ctrl.c
diff --git a/net/mptcp/pm.c b/net/mptcp/pm.c
index f42945077607..734d5e5e362e 100644
--- a/net/mptcp/pm.c
+++ b/net/mptcp/pm.c
@@ -320,8 +320,10 @@ void mptcp_pm_subflow_chk_stale(const struct mptcp_sock *msk, struct sock *ssk)
 	} else if (subflow->stale_rcv_tstamp == rcv_tstamp) {
 		if (subflow->stale_count < U8_MAX)
 			subflow->stale_count++;
+		mptcp_pm_nl_subflow_chk_stale(msk, ssk);
 	} else {
 		subflow->stale_count = 0;
+		mptcp_subflow_set_active(subflow);
 	}
 }
 
diff --git a/net/mptcp/pm_netlink.c b/net/mptcp/pm_netlink.c
index 41d1ed7a0e8c..aab0cea4de91 100644
--- a/net/mptcp/pm_netlink.c
+++ b/net/mptcp/pm_netlink.c
@@ -47,6 +47,7 @@ struct pm_nl_pernet {
 	spinlock_t		lock;
 	struct list_head	local_addr_list;
 	unsigned int		addrs;
+	unsigned int		stale_loss_cnt;
 	unsigned int		add_addr_signal_max;
 	unsigned int		add_addr_accept_max;
 	unsigned int		local_addr_max;
@@ -891,6 +892,42 @@ static const struct nla_policy mptcp_pm_policy[MPTCP_PM_ATTR_MAX + 1] = {
 	[MPTCP_PM_ATTR_SUBFLOWS]	= { .type	= NLA_U32,	},
 };
 
+void mptcp_pm_nl_subflow_chk_stale(const struct mptcp_sock *msk, struct sock *ssk)
+{
+	struct mptcp_subflow_context *iter, *subflow = mptcp_subflow_ctx(ssk);
+	struct sock *sk = (struct sock *)msk;
+	unsigned int active_max_loss_cnt;
+	struct net *net = sock_net(sk);
+	unsigned int stale_loss_cnt;
+	bool slow;
+
+	stale_loss_cnt = mptcp_stale_loss_cnt(net);
+	if (subflow->stale || !stale_loss_cnt || subflow->stale_count <= stale_loss_cnt)
+		return;
+
+	/* look for another available subflow not in loss state */
+	active_max_loss_cnt = max_t(int, stale_loss_cnt - 1, 1);
+	mptcp_for_each_subflow(msk, iter) {
+		if (iter != subflow && mptcp_subflow_active(iter) &&
+		    iter->stale_count < active_max_loss_cnt) {
+			/* we have some alternatives, try to mark this subflow as idle ...*/
+			slow = lock_sock_fast(ssk);
+			if (!tcp_rtx_and_write_queues_empty(ssk)) {
+				subflow->stale = 1;
+				__mptcp_retransmit_pending_data(sk);
+			}
+			unlock_sock_fast(ssk, slow);
+
+			/* always try to push the pending data regarless of re-injections:
+			 * we can possibly use backup subflows now, and subflow selection
+			 * is cheap under the msk socket lock
+			 */
+			__mptcp_push_pending(sk, 0);
+			return;
+		}
+	}
+}
+
 static int mptcp_pm_family_to_addr(int family)
 {
 #if IS_ENABLED(CONFIG_MPTCP_IPV6)
@@ -1891,6 +1928,7 @@ static int __net_init pm_nl_init_net(struct net *net)
 
 	INIT_LIST_HEAD_RCU(&pernet->local_addr_list);
 	pernet->next_id = 1;
+	pernet->stale_loss_cnt = 4;
 	spin_lock_init(&pernet->lock);
 
 	/* No need to initialize other pernet fields, the struct is zeroed at
diff --git a/net/mptcp/protocol.c b/net/mptcp/protocol.c
index 11b37cc5a34e..74c5bd63d3e9 100644
--- a/net/mptcp/protocol.c
+++ b/net/mptcp/protocol.c
@@ -1374,6 +1374,27 @@ struct subflow_send_info {
 	u64 ratio;
 };
 
+void mptcp_subflow_set_active(struct mptcp_subflow_context *subflow)
+{
+	if (!subflow->stale)
+		return;
+
+	subflow->stale = 0;
+}
+
+bool mptcp_subflow_active(struct mptcp_subflow_context *subflow)
+{
+	if (unlikely(subflow->stale)) {
+		u32 rcv_tstamp = READ_ONCE(tcp_sk(mptcp_subflow_tcp_sock(subflow))->rcv_tstamp);
+
+		if (subflow->stale_rcv_tstamp == rcv_tstamp)
+			return false;
+
+		mptcp_subflow_set_active(subflow);
+	}
+	return __mptcp_subflow_active(subflow);
+}
+
 /* implement the mptcp packet scheduler;
  * returns the subflow that will transmit the next DSS
  * additionally updates the rtx timeout
@@ -1455,7 +1476,7 @@ static void mptcp_push_release(struct sock *sk, struct sock *ssk,
 	release_sock(ssk);
 }
 
-static void __mptcp_push_pending(struct sock *sk, unsigned int flags)
+void __mptcp_push_pending(struct sock *sk, unsigned int flags)
 {
 	struct sock *prev_ssk = NULL, *ssk = NULL;
 	struct mptcp_sock *msk = mptcp_sk(sk);
@@ -2057,7 +2078,7 @@ static void mptcp_timeout_timer(struct timer_list *t)
  *
  * A backup subflow is returned only if that is the only kind available.
  */
-static struct sock *mptcp_subflow_get_retrans(const struct mptcp_sock *msk)
+static struct sock *mptcp_subflow_get_retrans(struct mptcp_sock *msk)
 {
 	struct sock *backup = NULL, *pick = NULL;
 	struct mptcp_subflow_context *subflow;
@@ -2071,7 +2092,7 @@ static struct sock *mptcp_subflow_get_retrans(const struct mptcp_sock *msk)
 	mptcp_for_each_subflow(msk, subflow) {
 		struct sock *ssk = mptcp_subflow_tcp_sock(subflow);
 
-		if (!mptcp_subflow_active(subflow))
+		if (!__mptcp_subflow_active(subflow))
 			continue;
 
 		/* still data outstanding at TCP level? skip this */
* Unmerged path net/mptcp/protocol.h
