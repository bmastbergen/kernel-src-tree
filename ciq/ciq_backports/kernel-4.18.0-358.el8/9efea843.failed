scsi: qla2xxx: edif: Add detection of secure device

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Quinn Tran <qutran@marvell.com>
commit 9efea843a906c6674ac6728f3f5db2cbfa3e1830
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/9efea843.failed

Some FC adapters from Marvell offer the ability to encrypt data in flight
(EDIF). This feature requires an application to act as an authenticator.

There is no FC switch scan service that can indicate whether a device is
secure or non-secure.

In order to detect whether the remote port supports encrypted operation,
driver must first do a PLOGI with the remote device. On completion of the
PLOGI, driver will query firmware to see if the device supports secure
login. To do that, driver + firmware must advertise the security bit via
PLOGI's service parameter. The remote device shall respond using the same
service parameter whether it supports it or not.

Link: https://lore.kernel.org/r/20210624052606.21613-8-njavali@marvell.com
	Reviewed-by: Hannes Reinecke <hare@suse.de>
	Reviewed-by: Himanshu Madhani <himanshu.madhani@oracle.com>
Co-developed-by: Larry Wisneski <Larry.Wisneski@marvell.com>
	Signed-off-by: Larry Wisneski <Larry.Wisneski@marvell.com>
Co-developed-by: Duane Grigsby <duane.grigsby@marvell.com>
	Signed-off-by: Duane Grigsby <duane.grigsby@marvell.com>
Co-developed-by: Rick Hicksted Jr <rhicksted@marvell.com>
	Signed-off-by: Rick Hicksted Jr <rhicksted@marvell.com>
	Signed-off-by: Quinn Tran <qutran@marvell.com>
	Signed-off-by: Nilesh Javali <njavali@marvell.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit 9efea843a906c6674ac6728f3f5db2cbfa3e1830)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/qla2xxx/qla_edif.c
#	drivers/scsi/qla2xxx/qla_gbl.h
diff --cc drivers/scsi/qla2xxx/qla_edif.c
index 8c567362bb60,51f96f5882af..000000000000
--- a/drivers/scsi/qla2xxx/qla_edif.c
+++ b/drivers/scsi/qla2xxx/qla_edif.c
@@@ -743,3 -1788,1037 +743,1040 @@@ qla_edb_stop(scsi_qla_host_t *vha
  		return;
  	}
  }
++<<<<<<< HEAD
++=======
+ 
+ static void qla_noop_sp_done(srb_t *sp, int res)
+ {
+ 	sp->free(sp);
+ }
+ 
+ /*
+  * Called from work queue
+  * build and send the sa_update iocb to delete an rx sa_index
+  */
+ int
+ qla24xx_issue_sa_replace_iocb(scsi_qla_host_t *vha, struct qla_work_evt *e)
+ {
+ 	srb_t *sp;
+ 	fc_port_t	*fcport = NULL;
+ 	struct srb_iocb *iocb_cmd = NULL;
+ 	int rval = QLA_SUCCESS;
+ 	struct	edif_sa_ctl *sa_ctl = e->u.sa_update.sa_ctl;
+ 	uint16_t nport_handle = e->u.sa_update.nport_handle;
+ 
+ 	ql_dbg(ql_dbg_edif, vha, 0x70e6,
+ 	    "%s: starting,  sa_ctl: %p\n", __func__, sa_ctl);
+ 
+ 	if (!sa_ctl) {
+ 		ql_dbg(ql_dbg_edif, vha, 0x70e6,
+ 		    "sa_ctl allocation failed\n");
+ 		return -ENOMEM;
+ 	}
+ 
+ 	fcport = sa_ctl->fcport;
+ 
+ 	/* Alloc SRB structure */
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp) {
+ 		ql_dbg(ql_dbg_edif, vha, 0x70e6,
+ 		 "SRB allocation failed\n");
+ 		return -ENOMEM;
+ 	}
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	iocb_cmd = &sp->u.iocb_cmd;
+ 	iocb_cmd->u.sa_update.sa_ctl = sa_ctl;
+ 
+ 	ql_dbg(ql_dbg_edif, vha, 0x3073,
+ 	    "Enter: SA REPL portid=%06x, sa_ctl %p, index %x, nport_handle: 0x%x\n",
+ 	    fcport->d_id.b24, sa_ctl, sa_ctl->index, nport_handle);
+ 	/*
+ 	 * if this is a sadb cleanup delete, mark it so the isr can
+ 	 * take the correct action
+ 	 */
+ 	if (sa_ctl->flags & EDIF_SA_CTL_FLG_CLEANUP_DEL) {
+ 		/* mark this srb as a cleanup delete */
+ 		sp->flags |= SRB_EDIF_CLEANUP_DELETE;
+ 		ql_dbg(ql_dbg_edif, vha, 0x70e6,
+ 		    "%s: sp 0x%p flagged as cleanup delete\n", __func__, sp);
+ 	}
+ 
+ 	sp->type = SRB_SA_REPLACE;
+ 	sp->name = "SA_REPLACE";
+ 	sp->fcport = fcport;
+ 	sp->free = qla2x00_rel_sp;
+ 	sp->done = qla_noop_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 
+ 	if (rval != QLA_SUCCESS)
+ 		rval = QLA_FUNCTION_FAILED;
+ 
+ 	return rval;
+ }
+ 
+ void qla24xx_sa_update_iocb(srb_t *sp, struct sa_update_28xx *sa_update_iocb)
+ {
+ 	int	itr = 0;
+ 	struct	scsi_qla_host		*vha = sp->vha;
+ 	struct	qla_sa_update_frame	*sa_frame =
+ 		&sp->u.iocb_cmd.u.sa_update.sa_frame;
+ 	u8 flags = 0;
+ 
+ 	switch (sa_frame->flags & (SAU_FLG_INV | SAU_FLG_TX)) {
+ 	case 0:
+ 		ql_dbg(ql_dbg_edif, vha, 0x911d,
+ 		    "%s: EDIF SA UPDATE RX IOCB  vha: 0x%p  index: %d\n",
+ 		    __func__, vha, sa_frame->fast_sa_index);
+ 		break;
+ 	case 1:
+ 		ql_dbg(ql_dbg_edif, vha, 0x911d,
+ 		    "%s: EDIF SA DELETE RX IOCB  vha: 0x%p  index: %d\n",
+ 		    __func__, vha, sa_frame->fast_sa_index);
+ 		flags |= SA_FLAG_INVALIDATE;
+ 		break;
+ 	case 2:
+ 		ql_dbg(ql_dbg_edif, vha, 0x911d,
+ 		    "%s: EDIF SA UPDATE TX IOCB  vha: 0x%p  index: %d\n",
+ 		    __func__, vha, sa_frame->fast_sa_index);
+ 		flags |= SA_FLAG_TX;
+ 		break;
+ 	case 3:
+ 		ql_dbg(ql_dbg_edif, vha, 0x911d,
+ 		    "%s: EDIF SA DELETE TX IOCB  vha: 0x%p  index: %d\n",
+ 		    __func__, vha, sa_frame->fast_sa_index);
+ 		flags |= SA_FLAG_TX | SA_FLAG_INVALIDATE;
+ 		break;
+ 	}
+ 
+ 	sa_update_iocb->entry_type = SA_UPDATE_IOCB_TYPE;
+ 	sa_update_iocb->entry_count = 1;
+ 	sa_update_iocb->sys_define = 0;
+ 	sa_update_iocb->entry_status = 0;
+ 	sa_update_iocb->handle = sp->handle;
+ 	sa_update_iocb->u.nport_handle = cpu_to_le16(sp->fcport->loop_id);
+ 	sa_update_iocb->vp_index = sp->fcport->vha->vp_idx;
+ 	sa_update_iocb->port_id[0] = sp->fcport->d_id.b.al_pa;
+ 	sa_update_iocb->port_id[1] = sp->fcport->d_id.b.area;
+ 	sa_update_iocb->port_id[2] = sp->fcport->d_id.b.domain;
+ 
+ 	sa_update_iocb->flags = flags;
+ 	sa_update_iocb->salt = cpu_to_le32(sa_frame->salt);
+ 	sa_update_iocb->spi = cpu_to_le32(sa_frame->spi);
+ 	sa_update_iocb->sa_index = cpu_to_le16(sa_frame->fast_sa_index);
+ 
+ 	sa_update_iocb->sa_control |= SA_CNTL_ENC_FCSP;
+ 	if (sp->fcport->edif.aes_gmac)
+ 		sa_update_iocb->sa_control |= SA_CNTL_AES_GMAC;
+ 
+ 	if (sa_frame->flags & SAU_FLG_KEY256) {
+ 		sa_update_iocb->sa_control |= SA_CNTL_KEY256;
+ 		for (itr = 0; itr < 32; itr++)
+ 			sa_update_iocb->sa_key[itr] = sa_frame->sa_key[itr];
+ 
+ 		ql_dbg(ql_dbg_edif + ql_dbg_verbose, vha, 0x921f, "%s 256 sa key=%32phN\n",
+ 		    __func__, sa_update_iocb->sa_key);
+ 	} else {
+ 		sa_update_iocb->sa_control |= SA_CNTL_KEY128;
+ 		for (itr = 0; itr < 16; itr++)
+ 			sa_update_iocb->sa_key[itr] = sa_frame->sa_key[itr];
+ 
+ 		ql_dbg(ql_dbg_edif +  ql_dbg_verbose, vha, 0x921f, "%s 128 sa key=%16phN\n",
+ 		    __func__, sa_update_iocb->sa_key);
+ 	}
+ 
+ 	ql_dbg(ql_dbg_edif, vha, 0x921d,
+ 	    "%s SAU Port ID = %02x%02x%02x, flags=%xh, index=%u, ctl=%xh, SPI 0x%x flags 0x%x hdl=%x gmac %d\n",
+ 	    __func__, sa_update_iocb->port_id[2], sa_update_iocb->port_id[1],
+ 	    sa_update_iocb->port_id[0], sa_update_iocb->flags, sa_update_iocb->sa_index,
+ 	    sa_update_iocb->sa_control, sa_update_iocb->spi, sa_frame->flags, sp->handle,
+ 	    sp->fcport->edif.aes_gmac);
+ 
+ 	if (sa_frame->flags & SAU_FLG_TX)
+ 		sp->fcport->edif.tx_sa_pending = 1;
+ 	else
+ 		sp->fcport->edif.rx_sa_pending = 1;
+ 
+ 	sp->fcport->vha->qla_stats.control_requests++;
+ }
+ 
+ void
+ qla24xx_sa_replace_iocb(srb_t *sp, struct sa_update_28xx *sa_update_iocb)
+ {
+ 	struct	scsi_qla_host		*vha = sp->vha;
+ 	struct srb_iocb *srb_iocb = &sp->u.iocb_cmd;
+ 	struct	edif_sa_ctl		*sa_ctl = srb_iocb->u.sa_update.sa_ctl;
+ 	uint16_t nport_handle = sp->fcport->loop_id;
+ 
+ 	sa_update_iocb->entry_type = SA_UPDATE_IOCB_TYPE;
+ 	sa_update_iocb->entry_count = 1;
+ 	sa_update_iocb->sys_define = 0;
+ 	sa_update_iocb->entry_status = 0;
+ 	sa_update_iocb->handle = sp->handle;
+ 
+ 	sa_update_iocb->u.nport_handle = cpu_to_le16(nport_handle);
+ 
+ 	sa_update_iocb->vp_index = sp->fcport->vha->vp_idx;
+ 	sa_update_iocb->port_id[0] = sp->fcport->d_id.b.al_pa;
+ 	sa_update_iocb->port_id[1] = sp->fcport->d_id.b.area;
+ 	sa_update_iocb->port_id[2] = sp->fcport->d_id.b.domain;
+ 
+ 	/* Invalidate the index. salt, spi, control & key are ignore */
+ 	sa_update_iocb->flags = SA_FLAG_INVALIDATE;
+ 	sa_update_iocb->salt = 0;
+ 	sa_update_iocb->spi = 0;
+ 	sa_update_iocb->sa_index = cpu_to_le16(sa_ctl->index);
+ 	sa_update_iocb->sa_control = 0;
+ 
+ 	ql_dbg(ql_dbg_edif, vha, 0x921d,
+ 	    "%s SAU DELETE RX Port ID = %02x:%02x:%02x, lid %d flags=%xh, index=%u, hdl=%x\n",
+ 	    __func__, sa_update_iocb->port_id[2], sa_update_iocb->port_id[1],
+ 	    sa_update_iocb->port_id[0], nport_handle, sa_update_iocb->flags,
+ 	    sa_update_iocb->sa_index, sp->handle);
+ 
+ 	sp->fcport->vha->qla_stats.control_requests++;
+ }
+ 
+ void qla24xx_auth_els(scsi_qla_host_t *vha, void **pkt, struct rsp_que **rsp)
+ {
+ 	struct purex_entry_24xx *p = *pkt;
+ 	struct enode		*ptr;
+ 	int		sid;
+ 	u16 totlen;
+ 	struct purexevent	*purex;
+ 	struct scsi_qla_host *host = NULL;
+ 	int rc;
+ 	struct fc_port *fcport;
+ 	struct qla_els_pt_arg a;
+ 	be_id_t beid;
+ 
+ 	memset(&a, 0, sizeof(a));
+ 
+ 	a.els_opcode = ELS_AUTH_ELS;
+ 	a.nport_handle = p->nport_handle;
+ 	a.rx_xchg_address = p->rx_xchg_addr;
+ 	a.did.b.domain = p->s_id[2];
+ 	a.did.b.area   = p->s_id[1];
+ 	a.did.b.al_pa  = p->s_id[0];
+ 	a.tx_byte_count = a.tx_len = sizeof(struct fc_els_ls_rjt);
+ 	a.tx_addr = vha->hw->elsrej.cdma;
+ 	a.vp_idx = vha->vp_idx;
+ 	a.control_flags = EPD_ELS_RJT;
+ 
+ 	sid = p->s_id[0] | (p->s_id[1] << 8) | (p->s_id[2] << 16);
+ 
+ 	totlen = (le16_to_cpu(p->frame_size) & 0x0fff) - PURX_ELS_HEADER_SIZE;
+ 	if (le16_to_cpu(p->status_flags) & 0x8000) {
+ 		totlen = le16_to_cpu(p->trunc_frame_size);
+ 		qla_els_reject_iocb(vha, (*rsp)->qpair, &a);
+ 		__qla_consume_iocb(vha, pkt, rsp);
+ 		return;
+ 	}
+ 
+ 	if (totlen > MAX_PAYLOAD) {
+ 		ql_dbg(ql_dbg_edif, vha, 0x0910d,
+ 		    "%s WARNING: verbose ELS frame received (totlen=%x)\n",
+ 		    __func__, totlen);
+ 		qla_els_reject_iocb(vha, (*rsp)->qpair, &a);
+ 		__qla_consume_iocb(vha, pkt, rsp);
+ 		return;
+ 	}
+ 
+ 	if (!vha->hw->flags.edif_enabled) {
+ 		/* edif support not enabled */
+ 		ql_dbg(ql_dbg_edif, vha, 0x910e, "%s edif not enabled\n",
+ 		    __func__);
+ 		qla_els_reject_iocb(vha, (*rsp)->qpair, &a);
+ 		__qla_consume_iocb(vha, pkt, rsp);
+ 		return;
+ 	}
+ 
+ 	ptr = qla_enode_alloc(vha, N_PUREX);
+ 	if (!ptr) {
+ 		ql_dbg(ql_dbg_edif, vha, 0x09109,
+ 		    "WARNING: enode allloc failed for sid=%x\n",
+ 		    sid);
+ 		qla_els_reject_iocb(vha, (*rsp)->qpair, &a);
+ 		__qla_consume_iocb(vha, pkt, rsp);
+ 		return;
+ 	}
+ 
+ 	purex = &ptr->u.purexinfo;
+ 	purex->pur_info.pur_sid = a.did;
+ 	purex->pur_info.pur_pend = 0;
+ 	purex->pur_info.pur_bytes_rcvd = totlen;
+ 	purex->pur_info.pur_rx_xchg_address = le32_to_cpu(p->rx_xchg_addr);
+ 	purex->pur_info.pur_nphdl = le16_to_cpu(p->nport_handle);
+ 	purex->pur_info.pur_did.b.domain =  p->d_id[2];
+ 	purex->pur_info.pur_did.b.area =  p->d_id[1];
+ 	purex->pur_info.pur_did.b.al_pa =  p->d_id[0];
+ 	purex->pur_info.vp_idx = p->vp_idx;
+ 
+ 	rc = __qla_copy_purex_to_buffer(vha, pkt, rsp, purex->msgp,
+ 		purex->msgp_len);
+ 	if (rc) {
+ 		qla_els_reject_iocb(vha, (*rsp)->qpair, &a);
+ 		qla_enode_free(vha, ptr);
+ 		return;
+ 	}
+ 	beid.al_pa = purex->pur_info.pur_did.b.al_pa;
+ 	beid.area   = purex->pur_info.pur_did.b.area;
+ 	beid.domain = purex->pur_info.pur_did.b.domain;
+ 	host = qla_find_host_by_d_id(vha, beid);
+ 	if (!host) {
+ 		ql_log(ql_log_fatal, vha, 0x508b,
+ 		    "%s Drop ELS due to unable to find host %06x\n",
+ 		    __func__, purex->pur_info.pur_did.b24);
+ 
+ 		qla_els_reject_iocb(vha, (*rsp)->qpair, &a);
+ 		qla_enode_free(vha, ptr);
+ 		return;
+ 	}
+ 
+ 	fcport = qla2x00_find_fcport_by_pid(host, &purex->pur_info.pur_sid);
+ 
+ 	if (host->e_dbell.db_flags != EDB_ACTIVE ||
+ 	    (fcport && fcport->loop_id == FC_NO_LOOP_ID)) {
+ 		ql_dbg(ql_dbg_edif, host, 0x0910c, "%s e_dbell.db_flags =%x %06x\n",
+ 		    __func__, host->e_dbell.db_flags,
+ 		    fcport ? fcport->d_id.b24 : 0);
+ 
+ 		qla_els_reject_iocb(host, (*rsp)->qpair, &a);
+ 		qla_enode_free(host, ptr);
+ 		return;
+ 	}
+ 
+ 	/* add the local enode to the list */
+ 	qla_enode_add(host, ptr);
+ 
+ 	ql_dbg(ql_dbg_edif, host, 0x0910c,
+ 	    "%s COMPLETE purex->pur_info.pur_bytes_rcvd =%xh s:%06x -> d:%06x xchg=%xh\n",
+ 	    __func__, purex->pur_info.pur_bytes_rcvd, purex->pur_info.pur_sid.b24,
+ 	    purex->pur_info.pur_did.b24, p->rx_xchg_addr);
+ }
+ 
+ static uint16_t  qla_edif_get_sa_index_from_freepool(fc_port_t *fcport, int dir)
+ {
+ 	struct scsi_qla_host *vha = fcport->vha;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	void *sa_id_map;
+ 	unsigned long flags = 0;
+ 	u16 sa_index;
+ 
+ 	ql_dbg(ql_dbg_edif + ql_dbg_verbose, vha, 0x3063,
+ 	    "%s: entry\n", __func__);
+ 
+ 	if (dir)
+ 		sa_id_map = ha->edif_tx_sa_id_map;
+ 	else
+ 		sa_id_map = ha->edif_rx_sa_id_map;
+ 
+ 	spin_lock_irqsave(&ha->sadb_fp_lock, flags);
+ 	sa_index = find_first_zero_bit(sa_id_map, EDIF_NUM_SA_INDEX);
+ 	if (sa_index >=  EDIF_NUM_SA_INDEX) {
+ 		spin_unlock_irqrestore(&ha->sadb_fp_lock, flags);
+ 		return INVALID_EDIF_SA_INDEX;
+ 	}
+ 	set_bit(sa_index, sa_id_map);
+ 	spin_unlock_irqrestore(&ha->sadb_fp_lock, flags);
+ 
+ 	if (dir)
+ 		sa_index += EDIF_TX_SA_INDEX_BASE;
+ 
+ 	ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 	    "%s: index retrieved from free pool %d\n", __func__, sa_index);
+ 
+ 	return sa_index;
+ }
+ 
+ /* find an sadb entry for an nport_handle */
+ static struct edif_sa_index_entry *
+ qla_edif_sadb_find_sa_index_entry(uint16_t nport_handle,
+ 		struct list_head *sa_list)
+ {
+ 	struct edif_sa_index_entry *entry;
+ 	struct edif_sa_index_entry *tentry;
+ 	struct list_head *indx_list = sa_list;
+ 
+ 	list_for_each_entry_safe(entry, tentry, indx_list, next) {
+ 		if (entry->handle == nport_handle)
+ 			return entry;
+ 	}
+ 	return NULL;
+ }
+ 
+ /* remove an sa_index from the nport_handle and return it to the free pool */
+ static int qla_edif_sadb_delete_sa_index(fc_port_t *fcport, uint16_t nport_handle,
+ 		uint16_t sa_index)
+ {
+ 	struct edif_sa_index_entry *entry;
+ 	struct list_head *sa_list;
+ 	int dir = (sa_index < EDIF_TX_SA_INDEX_BASE) ? 0 : 1;
+ 	int slot = 0;
+ 	int free_slot_count = 0;
+ 	scsi_qla_host_t *vha = fcport->vha;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	unsigned long flags = 0;
+ 
+ 	ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 	    "%s: entry\n", __func__);
+ 
+ 	if (dir)
+ 		sa_list = &ha->sadb_tx_index_list;
+ 	else
+ 		sa_list = &ha->sadb_rx_index_list;
+ 
+ 	entry = qla_edif_sadb_find_sa_index_entry(nport_handle, sa_list);
+ 	if (!entry) {
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: no entry found for nport_handle 0x%x\n",
+ 		    __func__, nport_handle);
+ 		return -1;
+ 	}
+ 
+ 	spin_lock_irqsave(&ha->sadb_lock, flags);
+ 	/*
+ 	 * each tx/rx direction has up to 2 sa indexes/slots. 1 slot for in flight traffic
+ 	 * the other is use at re-key time.
+ 	 */
+ 	for (slot = 0; slot < 2; slot++) {
+ 		if (entry->sa_pair[slot].sa_index == sa_index) {
+ 			entry->sa_pair[slot].sa_index = INVALID_EDIF_SA_INDEX;
+ 			entry->sa_pair[slot].spi = 0;
+ 			free_slot_count++;
+ 			qla_edif_add_sa_index_to_freepool(fcport, dir, sa_index);
+ 		} else if (entry->sa_pair[slot].sa_index == INVALID_EDIF_SA_INDEX) {
+ 			free_slot_count++;
+ 		}
+ 	}
+ 
+ 	if (free_slot_count == 2) {
+ 		list_del(&entry->next);
+ 		kfree(entry);
+ 	}
+ 	spin_unlock_irqrestore(&ha->sadb_lock, flags);
+ 
+ 	ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 	    "%s: sa_index %d removed, free_slot_count: %d\n",
+ 	    __func__, sa_index, free_slot_count);
+ 
+ 	return 0;
+ }
+ 
+ void
+ qla28xx_sa_update_iocb_entry(scsi_qla_host_t *v, struct req_que *req,
+ 	struct sa_update_28xx *pkt)
+ {
+ 	const char *func = "SA_UPDATE_RESPONSE_IOCB";
+ 	srb_t *sp;
+ 	struct edif_sa_ctl *sa_ctl;
+ 	int old_sa_deleted = 1;
+ 	uint16_t nport_handle;
+ 	struct scsi_qla_host *vha;
+ 
+ 	sp = qla2x00_get_sp_from_handle(v, func, req, pkt);
+ 
+ 	if (!sp) {
+ 		ql_dbg(ql_dbg_edif, v, 0x3063,
+ 			"%s: no sp found for pkt\n", __func__);
+ 		return;
+ 	}
+ 	/* use sp->vha due to npiv */
+ 	vha = sp->vha;
+ 
+ 	switch (pkt->flags & (SA_FLAG_INVALIDATE | SA_FLAG_TX)) {
+ 	case 0:
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: EDIF SA UPDATE RX IOCB  vha: 0x%p  index: %d\n",
+ 		    __func__, vha, pkt->sa_index);
+ 		break;
+ 	case 1:
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: EDIF SA DELETE RX IOCB  vha: 0x%p  index: %d\n",
+ 		    __func__, vha, pkt->sa_index);
+ 		break;
+ 	case 2:
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: EDIF SA UPDATE TX IOCB  vha: 0x%p  index: %d\n",
+ 		    __func__, vha, pkt->sa_index);
+ 		break;
+ 	case 3:
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: EDIF SA DELETE TX IOCB  vha: 0x%p  index: %d\n",
+ 		    __func__, vha, pkt->sa_index);
+ 		break;
+ 	}
+ 
+ 	/*
+ 	 * dig the nport handle out of the iocb, fcport->loop_id can not be trusted
+ 	 * to be correct during cleanup sa_update iocbs.
+ 	 */
+ 	nport_handle = sp->fcport->loop_id;
+ 
+ 	ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 	    "%s: %8phN comp status=%x old_sa_info=%x new_sa_info=%x lid %d, index=0x%x pkt_flags %xh hdl=%x\n",
+ 	    __func__, sp->fcport->port_name, pkt->u.comp_sts, pkt->old_sa_info, pkt->new_sa_info,
+ 	    nport_handle, pkt->sa_index, pkt->flags, sp->handle);
+ 
+ 	/* if rx delete, remove the timer */
+ 	if ((pkt->flags & (SA_FLAG_INVALIDATE | SA_FLAG_TX)) ==  SA_FLAG_INVALIDATE) {
+ 		struct edif_list_entry *edif_entry;
+ 
+ 		sp->fcport->flags &= ~(FCF_ASYNC_SENT | FCF_ASYNC_ACTIVE);
+ 
+ 		edif_entry = qla_edif_list_find_sa_index(sp->fcport, nport_handle);
+ 		if (edif_entry) {
+ 			ql_dbg(ql_dbg_edif, vha, 0x5033,
+ 			    "%s: removing edif_entry %p, new sa_index: 0x%x\n",
+ 			    __func__, edif_entry, pkt->sa_index);
+ 			qla_edif_list_delete_sa_index(sp->fcport, edif_entry);
+ 			del_timer(&edif_entry->timer);
+ 
+ 			ql_dbg(ql_dbg_edif, vha, 0x5033,
+ 			    "%s: releasing edif_entry %p, new sa_index: 0x%x\n",
+ 			    __func__, edif_entry, pkt->sa_index);
+ 
+ 			kfree(edif_entry);
+ 		}
+ 	}
+ 
+ 	/*
+ 	 * if this is a delete for either tx or rx, make sure it succeeded.
+ 	 * The new_sa_info field should be 0xffff on success
+ 	 */
+ 	if (pkt->flags & SA_FLAG_INVALIDATE)
+ 		old_sa_deleted = (le16_to_cpu(pkt->new_sa_info) == 0xffff) ? 1 : 0;
+ 
+ 	/* Process update and delete the same way */
+ 
+ 	/* If this is an sadb cleanup delete, bypass sending events to IPSEC */
+ 	if (sp->flags & SRB_EDIF_CLEANUP_DELETE) {
+ 		sp->fcport->flags &= ~(FCF_ASYNC_SENT | FCF_ASYNC_ACTIVE);
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: nph 0x%x, sa_index %d removed from fw\n",
+ 		    __func__, sp->fcport->loop_id, pkt->sa_index);
+ 
+ 	} else if ((pkt->entry_status == 0) && (pkt->u.comp_sts == 0) &&
+ 	    old_sa_deleted) {
+ 		/*
+ 		 * Note: Wa are only keeping track of latest SA,
+ 		 * so we know when we can start enableing encryption per I/O.
+ 		 * If all SA's get deleted, let FW reject the IOCB.
+ 
+ 		 * TODO: edif: don't set enabled here I think
+ 		 * TODO: edif: prli complete is where it should be set
+ 		 */
+ 		ql_dbg(ql_dbg_edif + ql_dbg_verbose, vha, 0x3063,
+ 			"SA(%x)updated for s_id %02x%02x%02x\n",
+ 			pkt->new_sa_info,
+ 			pkt->port_id[2], pkt->port_id[1], pkt->port_id[0]);
+ 		sp->fcport->edif.enable = 1;
+ 		if (pkt->flags & SA_FLAG_TX) {
+ 			sp->fcport->edif.tx_sa_set = 1;
+ 			sp->fcport->edif.tx_sa_pending = 0;
+ 		} else {
+ 			sp->fcport->edif.rx_sa_set = 1;
+ 			sp->fcport->edif.rx_sa_pending = 0;
+ 		}
+ 	} else {
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: %8phN SA update FAILED: sa_index: %d, new_sa_info %d, %02x%02x%02x\n",
+ 		    __func__, sp->fcport->port_name, pkt->sa_index, pkt->new_sa_info,
+ 		    pkt->port_id[2], pkt->port_id[1], pkt->port_id[0]);
+ 	}
+ 
+ 	/* for delete, release sa_ctl, sa_index */
+ 	if (pkt->flags & SA_FLAG_INVALIDATE) {
+ 		/* release the sa_ctl */
+ 		sa_ctl = qla_edif_find_sa_ctl_by_index(sp->fcport,
+ 		    le16_to_cpu(pkt->sa_index), (pkt->flags & SA_FLAG_TX));
+ 		if (sa_ctl &&
+ 		    qla_edif_find_sa_ctl_by_index(sp->fcport, sa_ctl->index,
+ 			(pkt->flags & SA_FLAG_TX)) != NULL) {
+ 			ql_dbg(ql_dbg_edif + ql_dbg_verbose, vha, 0x3063,
+ 			    "%s: freeing sa_ctl for index %d\n",
+ 			    __func__, sa_ctl->index);
+ 			qla_edif_free_sa_ctl(sp->fcport, sa_ctl, sa_ctl->index);
+ 		} else {
+ 			ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 			    "%s: sa_ctl NOT freed, sa_ctl: %p\n",
+ 			    __func__, sa_ctl);
+ 		}
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: freeing sa_index %d, nph: 0x%x\n",
+ 		    __func__, le16_to_cpu(pkt->sa_index), nport_handle);
+ 		qla_edif_sadb_delete_sa_index(sp->fcport, nport_handle,
+ 		    le16_to_cpu(pkt->sa_index));
+ 	/*
+ 	 * check for a failed sa_update and remove
+ 	 * the sadb entry.
+ 	 */
+ 	} else if (pkt->u.comp_sts) {
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: freeing sa_index %d, nph: 0x%x\n",
+ 		    __func__, pkt->sa_index, nport_handle);
+ 		qla_edif_sadb_delete_sa_index(sp->fcport, nport_handle,
+ 		    le16_to_cpu(pkt->sa_index));
+ 	}
+ 
+ 	sp->done(sp, 0);
+ }
+ 
+ /**********************************************
+  * edif update/delete sa_index list functions *
+  **********************************************/
+ 
+ /* clear the edif_indx_list for this port */
+ void qla_edif_list_del(fc_port_t *fcport)
+ {
+ 	struct edif_list_entry *indx_lst;
+ 	struct edif_list_entry *tindx_lst;
+ 	struct list_head *indx_list = &fcport->edif.edif_indx_list;
+ 	unsigned long flags = 0;
+ 
+ 	spin_lock_irqsave(&fcport->edif.indx_list_lock, flags);
+ 	list_for_each_entry_safe(indx_lst, tindx_lst, indx_list, next) {
+ 		list_del(&indx_lst->next);
+ 		kfree(indx_lst);
+ 	}
+ 	spin_unlock_irqrestore(&fcport->edif.indx_list_lock, flags);
+ }
+ 
+ /******************
+  * SADB functions *
+  ******************/
+ 
+ /* allocate/retrieve an sa_index for a given spi */
+ static uint16_t qla_edif_sadb_get_sa_index(fc_port_t *fcport,
+ 		struct qla_sa_update_frame *sa_frame)
+ {
+ 	struct edif_sa_index_entry *entry;
+ 	struct list_head *sa_list;
+ 	uint16_t sa_index;
+ 	int dir = sa_frame->flags & SAU_FLG_TX;
+ 	int slot = 0;
+ 	int free_slot = -1;
+ 	scsi_qla_host_t *vha = fcport->vha;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	unsigned long flags = 0;
+ 	uint16_t nport_handle = fcport->loop_id;
+ 
+ 	ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 	    "%s: entry  fc_port: %p, nport_handle: 0x%x\n",
+ 	    __func__, fcport, nport_handle);
+ 
+ 	if (dir)
+ 		sa_list = &ha->sadb_tx_index_list;
+ 	else
+ 		sa_list = &ha->sadb_rx_index_list;
+ 
+ 	entry = qla_edif_sadb_find_sa_index_entry(nport_handle, sa_list);
+ 	if (!entry) {
+ 		if ((sa_frame->flags & (SAU_FLG_TX | SAU_FLG_INV)) == SAU_FLG_INV) {
+ 			ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 			    "%s: rx delete request with no entry\n", __func__);
+ 			return RX_DELETE_NO_EDIF_SA_INDEX;
+ 		}
+ 
+ 		/* if there is no entry for this nport, add one */
+ 		entry = kzalloc((sizeof(struct edif_sa_index_entry)), GFP_ATOMIC);
+ 		if (!entry)
+ 			return INVALID_EDIF_SA_INDEX;
+ 
+ 		sa_index = qla_edif_get_sa_index_from_freepool(fcport, dir);
+ 		if (sa_index == INVALID_EDIF_SA_INDEX) {
+ 			kfree(entry);
+ 			return INVALID_EDIF_SA_INDEX;
+ 		}
+ 
+ 		INIT_LIST_HEAD(&entry->next);
+ 		entry->handle = nport_handle;
+ 		entry->fcport = fcport;
+ 		entry->sa_pair[0].spi = sa_frame->spi;
+ 		entry->sa_pair[0].sa_index = sa_index;
+ 		entry->sa_pair[1].spi = 0;
+ 		entry->sa_pair[1].sa_index = INVALID_EDIF_SA_INDEX;
+ 		spin_lock_irqsave(&ha->sadb_lock, flags);
+ 		list_add_tail(&entry->next, sa_list);
+ 		spin_unlock_irqrestore(&ha->sadb_lock, flags);
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: Created new sadb entry for nport_handle 0x%x, spi 0x%x, returning sa_index %d\n",
+ 		    __func__, nport_handle, sa_frame->spi, sa_index);
+ 
+ 		return sa_index;
+ 	}
+ 
+ 	spin_lock_irqsave(&ha->sadb_lock, flags);
+ 
+ 	/* see if we already have an entry for this spi */
+ 	for (slot = 0; slot < 2; slot++) {
+ 		if (entry->sa_pair[slot].sa_index == INVALID_EDIF_SA_INDEX) {
+ 			free_slot = slot;
+ 		} else {
+ 			if (entry->sa_pair[slot].spi == sa_frame->spi) {
+ 				spin_unlock_irqrestore(&ha->sadb_lock, flags);
+ 				ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 				    "%s: sadb slot %d entry for lid 0x%x, spi 0x%x found, sa_index %d\n",
+ 				    __func__, slot, entry->handle, sa_frame->spi,
+ 				    entry->sa_pair[slot].sa_index);
+ 				return entry->sa_pair[slot].sa_index;
+ 			}
+ 		}
+ 	}
+ 	spin_unlock_irqrestore(&ha->sadb_lock, flags);
+ 
+ 	/* both slots are used */
+ 	if (free_slot == -1) {
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: WARNING: No free slots in sadb for nport_handle 0x%x, spi: 0x%x\n",
+ 		    __func__, entry->handle, sa_frame->spi);
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: Slot 0  spi: 0x%x  sa_index: %d,  Slot 1  spi: 0x%x  sa_index: %d\n",
+ 		    __func__, entry->sa_pair[0].spi, entry->sa_pair[0].sa_index,
+ 		    entry->sa_pair[1].spi, entry->sa_pair[1].sa_index);
+ 
+ 		return INVALID_EDIF_SA_INDEX;
+ 	}
+ 
+ 	/* there is at least one free slot, use it */
+ 	sa_index = qla_edif_get_sa_index_from_freepool(fcport, dir);
+ 	if (sa_index == INVALID_EDIF_SA_INDEX) {
+ 		ql_dbg(ql_dbg_edif, fcport->vha, 0x3063,
+ 		    "%s: empty freepool!!\n", __func__);
+ 		return INVALID_EDIF_SA_INDEX;
+ 	}
+ 
+ 	spin_lock_irqsave(&ha->sadb_lock, flags);
+ 	entry->sa_pair[free_slot].spi = sa_frame->spi;
+ 	entry->sa_pair[free_slot].sa_index = sa_index;
+ 	spin_unlock_irqrestore(&ha->sadb_lock, flags);
+ 	ql_dbg(ql_dbg_edif, fcport->vha, 0x3063,
+ 	    "%s: sadb slot %d entry for nport_handle 0x%x, spi 0x%x added, returning sa_index %d\n",
+ 	    __func__, free_slot, entry->handle, sa_frame->spi, sa_index);
+ 
+ 	return sa_index;
+ }
+ 
+ /* release any sadb entries -- only done at teardown */
+ void qla_edif_sadb_release(struct qla_hw_data *ha)
+ {
+ 	struct list_head *pos;
+ 	struct list_head *tmp;
+ 	struct edif_sa_index_entry *entry;
+ 
+ 	list_for_each_safe(pos, tmp, &ha->sadb_rx_index_list) {
+ 		entry = list_entry(pos, struct edif_sa_index_entry, next);
+ 		list_del(&entry->next);
+ 		kfree(entry);
+ 	}
+ 
+ 	list_for_each_safe(pos, tmp, &ha->sadb_tx_index_list) {
+ 		entry = list_entry(pos, struct edif_sa_index_entry, next);
+ 		list_del(&entry->next);
+ 		kfree(entry);
+ 	}
+ }
+ 
+ /**************************
+  * sadb freepool functions
+  **************************/
+ 
+ /* build the rx and tx sa_index free pools -- only done at fcport init */
+ int qla_edif_sadb_build_free_pool(struct qla_hw_data *ha)
+ {
+ 	ha->edif_tx_sa_id_map =
+ 	    kcalloc(BITS_TO_LONGS(EDIF_NUM_SA_INDEX), sizeof(long), GFP_KERNEL);
+ 
+ 	if (!ha->edif_tx_sa_id_map) {
+ 		ql_log_pci(ql_log_fatal, ha->pdev, 0x0009,
+ 		    "Unable to allocate memory for sadb tx.\n");
+ 		return -ENOMEM;
+ 	}
+ 
+ 	ha->edif_rx_sa_id_map =
+ 	    kcalloc(BITS_TO_LONGS(EDIF_NUM_SA_INDEX), sizeof(long), GFP_KERNEL);
+ 	if (!ha->edif_rx_sa_id_map) {
+ 		kfree(ha->edif_tx_sa_id_map);
+ 		ha->edif_tx_sa_id_map = NULL;
+ 		ql_log_pci(ql_log_fatal, ha->pdev, 0x0009,
+ 		    "Unable to allocate memory for sadb rx.\n");
+ 		return -ENOMEM;
+ 	}
+ 	return 0;
+ }
+ 
+ /* release the free pool - only done during fcport teardown */
+ void qla_edif_sadb_release_free_pool(struct qla_hw_data *ha)
+ {
+ 	kfree(ha->edif_tx_sa_id_map);
+ 	ha->edif_tx_sa_id_map = NULL;
+ 	kfree(ha->edif_rx_sa_id_map);
+ 	ha->edif_rx_sa_id_map = NULL;
+ }
+ 
+ static void __chk_edif_rx_sa_delete_pending(scsi_qla_host_t *vha,
+ 		fc_port_t *fcport, uint32_t handle, uint16_t sa_index)
+ {
+ 	struct edif_list_entry *edif_entry;
+ 	struct edif_sa_ctl *sa_ctl;
+ 	uint16_t delete_sa_index = INVALID_EDIF_SA_INDEX;
+ 	unsigned long flags = 0;
+ 	uint16_t nport_handle = fcport->loop_id;
+ 	uint16_t cached_nport_handle;
+ 
+ 	spin_lock_irqsave(&fcport->edif.indx_list_lock, flags);
+ 	edif_entry = qla_edif_list_find_sa_index(fcport, nport_handle);
+ 	if (!edif_entry) {
+ 		spin_unlock_irqrestore(&fcport->edif.indx_list_lock, flags);
+ 		return;		/* no pending delete for this handle */
+ 	}
+ 
+ 	/*
+ 	 * check for no pending delete for this index or iocb does not
+ 	 * match rx sa_index
+ 	 */
+ 	if (edif_entry->delete_sa_index == INVALID_EDIF_SA_INDEX ||
+ 	    edif_entry->update_sa_index != sa_index) {
+ 		spin_unlock_irqrestore(&fcport->edif.indx_list_lock, flags);
+ 		return;
+ 	}
+ 
+ 	/*
+ 	 * wait until we have seen at least EDIF_DELAY_COUNT transfers before
+ 	 * queueing RX delete
+ 	 */
+ 	if (edif_entry->count++ < EDIF_RX_DELETE_FILTER_COUNT) {
+ 		spin_unlock_irqrestore(&fcport->edif.indx_list_lock, flags);
+ 		return;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_edif, vha, 0x5033,
+ 	    "%s: invalidating delete_sa_index,  update_sa_index: 0x%x sa_index: 0x%x, delete_sa_index: 0x%x\n",
+ 	    __func__, edif_entry->update_sa_index, sa_index, edif_entry->delete_sa_index);
+ 
+ 	delete_sa_index = edif_entry->delete_sa_index;
+ 	edif_entry->delete_sa_index = INVALID_EDIF_SA_INDEX;
+ 	cached_nport_handle = edif_entry->handle;
+ 	spin_unlock_irqrestore(&fcport->edif.indx_list_lock, flags);
+ 
+ 	/* sanity check on the nport handle */
+ 	if (nport_handle != cached_nport_handle) {
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: POST SA DELETE nport_handle mismatch: lid: 0x%x, edif_entry nph: 0x%x\n",
+ 		    __func__, nport_handle, cached_nport_handle);
+ 	}
+ 
+ 	/* find the sa_ctl for the delete and schedule the delete */
+ 	sa_ctl = qla_edif_find_sa_ctl_by_index(fcport, delete_sa_index, 0);
+ 	if (sa_ctl) {
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: POST SA DELETE sa_ctl: %p, index recvd %d\n",
+ 		    __func__, sa_ctl, sa_index);
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "delete index %d, update index: %d, nport handle: 0x%x, handle: 0x%x\n",
+ 		    delete_sa_index,
+ 		    edif_entry->update_sa_index, nport_handle, handle);
+ 
+ 		sa_ctl->flags = EDIF_SA_CTL_FLG_DEL;
+ 		set_bit(EDIF_SA_CTL_REPL, &sa_ctl->state);
+ 		qla_post_sa_replace_work(fcport->vha, fcport,
+ 		    nport_handle, sa_ctl);
+ 	} else {
+ 		ql_dbg(ql_dbg_edif, vha, 0x3063,
+ 		    "%s: POST SA DELETE sa_ctl not found for delete_sa_index: %d\n",
+ 		    __func__, delete_sa_index);
+ 	}
+ }
+ 
+ void qla_chk_edif_rx_sa_delete_pending(scsi_qla_host_t *vha,
+ 		srb_t *sp, struct sts_entry_24xx *sts24)
+ {
+ 	fc_port_t *fcport = sp->fcport;
+ 	/* sa_index used by this iocb */
+ 	struct scsi_cmnd *cmd = GET_CMD_SP(sp);
+ 	uint32_t handle;
+ 
+ 	handle = (uint32_t)LSW(sts24->handle);
+ 
+ 	/* find out if this status iosb is for a scsi read */
+ 	if (cmd->sc_data_direction != DMA_FROM_DEVICE)
+ 		return;
+ 
+ 	return __chk_edif_rx_sa_delete_pending(vha, fcport, handle,
+ 	   le16_to_cpu(sts24->edif_sa_index));
+ }
+ 
+ void qlt_chk_edif_rx_sa_delete_pending(scsi_qla_host_t *vha, fc_port_t *fcport,
+ 		struct ctio7_from_24xx *pkt)
+ {
+ 	__chk_edif_rx_sa_delete_pending(vha, fcport,
+ 	    pkt->handle, le16_to_cpu(pkt->edif_sa_index));
+ }
+ 
+ static void qla_parse_auth_els_ctl(struct srb *sp)
+ {
+ 	struct qla_els_pt_arg *a = &sp->u.bsg_cmd.u.els_arg;
+ 	struct bsg_job *bsg_job = sp->u.bsg_cmd.bsg_job;
+ 	struct fc_bsg_request *request = bsg_job->request;
+ 	struct qla_bsg_auth_els_request *p =
+ 	    (struct qla_bsg_auth_els_request *)bsg_job->request;
+ 
+ 	a->tx_len = a->tx_byte_count = sp->remap.req.len;
+ 	a->tx_addr = sp->remap.req.dma;
+ 	a->rx_len = a->rx_byte_count = sp->remap.rsp.len;
+ 	a->rx_addr = sp->remap.rsp.dma;
+ 
+ 	if (p->e.sub_cmd == SEND_ELS_REPLY) {
+ 		a->control_flags = p->e.extra_control_flags << 13;
+ 		a->rx_xchg_address = cpu_to_le32(p->e.extra_rx_xchg_address);
+ 		if (p->e.extra_control_flags == BSG_CTL_FLAG_LS_ACC)
+ 			a->els_opcode = ELS_LS_ACC;
+ 		else if (p->e.extra_control_flags == BSG_CTL_FLAG_LS_RJT)
+ 			a->els_opcode = ELS_LS_RJT;
+ 	}
+ 	a->did = sp->fcport->d_id;
+ 	a->els_opcode =  request->rqst_data.h_els.command_code;
+ 	a->nport_handle = cpu_to_le16(sp->fcport->loop_id);
+ 	a->vp_idx = sp->vha->vp_idx;
+ }
+ 
+ int qla_edif_process_els(scsi_qla_host_t *vha, struct bsg_job *bsg_job)
+ {
+ 	struct fc_bsg_request *bsg_request = bsg_job->request;
+ 	struct fc_bsg_reply *bsg_reply = bsg_job->reply;
+ 	fc_port_t *fcport = NULL;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	srb_t *sp;
+ 	int rval =  (DID_ERROR << 16);
+ 	port_id_t d_id;
+ 	struct qla_bsg_auth_els_request *p =
+ 	    (struct qla_bsg_auth_els_request *)bsg_job->request;
+ 
+ 	d_id.b.al_pa = bsg_request->rqst_data.h_els.port_id[2];
+ 	d_id.b.area = bsg_request->rqst_data.h_els.port_id[1];
+ 	d_id.b.domain = bsg_request->rqst_data.h_els.port_id[0];
+ 
+ 	/* find matching d_id in fcport list */
+ 	fcport = qla2x00_find_fcport_by_pid(vha, &d_id);
+ 	if (!fcport) {
+ 		ql_dbg(ql_dbg_edif, vha, 0x911a,
+ 		    "%s fcport not find online portid=%06x.\n",
+ 		    __func__, d_id.b24);
+ 		SET_DID_STATUS(bsg_reply->result, DID_ERROR);
+ 		return -EIO;
+ 	}
+ 
+ 	if (qla_bsg_check(vha, bsg_job, fcport))
+ 		return 0;
+ 
+ 	if (fcport->loop_id == FC_NO_LOOP_ID) {
+ 		ql_dbg(ql_dbg_edif, vha, 0x910d,
+ 		    "%s ELS code %x, no loop id.\n", __func__,
+ 		    bsg_request->rqst_data.r_els.els_code);
+ 		SET_DID_STATUS(bsg_reply->result, DID_BAD_TARGET);
+ 		return -ENXIO;
+ 	}
+ 
+ 	if (!vha->flags.online) {
+ 		ql_log(ql_log_warn, vha, 0x7005, "Host not online.\n");
+ 		SET_DID_STATUS(bsg_reply->result, DID_BAD_TARGET);
+ 		rval = -EIO;
+ 		goto done;
+ 	}
+ 
+ 	/* pass through is supported only for ISP 4Gb or higher */
+ 	if (!IS_FWI2_CAPABLE(ha)) {
+ 		ql_dbg(ql_dbg_user, vha, 0x7001,
+ 		    "ELS passthru not supported for ISP23xx based adapters.\n");
+ 		SET_DID_STATUS(bsg_reply->result, DID_BAD_TARGET);
+ 		rval = -EPERM;
+ 		goto done;
+ 	}
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp) {
+ 		ql_dbg(ql_dbg_user, vha, 0x7004,
+ 		    "Failed get sp pid=%06x\n", fcport->d_id.b24);
+ 		rval = -ENOMEM;
+ 		SET_DID_STATUS(bsg_reply->result, DID_IMM_RETRY);
+ 		goto done;
+ 	}
+ 
+ 	sp->remap.req.len = bsg_job->request_payload.payload_len;
+ 	sp->remap.req.buf = dma_pool_alloc(ha->purex_dma_pool,
+ 	    GFP_KERNEL, &sp->remap.req.dma);
+ 	if (!sp->remap.req.buf) {
+ 		ql_dbg(ql_dbg_user, vha, 0x7005,
+ 		    "Failed allocate request dma len=%x\n",
+ 		    bsg_job->request_payload.payload_len);
+ 		rval = -ENOMEM;
+ 		SET_DID_STATUS(bsg_reply->result, DID_IMM_RETRY);
+ 		goto done_free_sp;
+ 	}
+ 
+ 	sp->remap.rsp.len = bsg_job->reply_payload.payload_len;
+ 	sp->remap.rsp.buf = dma_pool_alloc(ha->purex_dma_pool,
+ 	    GFP_KERNEL, &sp->remap.rsp.dma);
+ 	if (!sp->remap.rsp.buf) {
+ 		ql_dbg(ql_dbg_user, vha, 0x7006,
+ 		    "Failed allocate response dma len=%x\n",
+ 		    bsg_job->reply_payload.payload_len);
+ 		rval = -ENOMEM;
+ 		SET_DID_STATUS(bsg_reply->result, DID_IMM_RETRY);
+ 		goto done_free_remap_req;
+ 	}
+ 	sg_copy_to_buffer(bsg_job->request_payload.sg_list,
+ 	    bsg_job->request_payload.sg_cnt, sp->remap.req.buf,
+ 	    sp->remap.req.len);
+ 	sp->remap.remapped = true;
+ 
+ 	sp->type = SRB_ELS_CMD_HST_NOLOGIN;
+ 	sp->name = "SPCN_BSG_HST_NOLOGIN";
+ 	sp->u.bsg_cmd.bsg_job = bsg_job;
+ 	qla_parse_auth_els_ctl(sp);
+ 
+ 	sp->free = qla2x00_bsg_sp_free;
+ 	sp->done = qla2x00_bsg_job_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 
+ 	ql_dbg(ql_dbg_edif, vha, 0x700a,
+ 	    "%s %s %8phN xchg %x ctlflag %x hdl %x reqlen %xh bsg ptr %p\n",
+ 	    __func__, sc_to_str(p->e.sub_cmd), fcport->port_name,
+ 	    p->e.extra_rx_xchg_address, p->e.extra_control_flags,
+ 	    sp->handle, sp->remap.req.len, bsg_job);
+ 
+ 	if (rval != QLA_SUCCESS) {
+ 		ql_log(ql_log_warn, vha, 0x700e,
+ 		    "qla2x00_start_sp failed = %d\n", rval);
+ 		SET_DID_STATUS(bsg_reply->result, DID_IMM_RETRY);
+ 		rval = -EIO;
+ 		goto done_free_remap_rsp;
+ 	}
+ 	return rval;
+ 
+ done_free_remap_rsp:
+ 	dma_pool_free(ha->purex_dma_pool, sp->remap.rsp.buf,
+ 	    sp->remap.rsp.dma);
+ done_free_remap_req:
+ 	dma_pool_free(ha->purex_dma_pool, sp->remap.req.buf,
+ 	    sp->remap.req.dma);
+ done_free_sp:
+ 	qla2x00_rel_sp(sp);
+ 
+ done:
+ 	return rval;
+ }
+ 
+ void qla_edif_sess_down(struct scsi_qla_host *vha, struct fc_port *sess)
+ {
+ 	if (sess->edif.app_sess_online && vha->e_dbell.db_flags & EDB_ACTIVE) {
+ 		ql_dbg(ql_dbg_disc, vha, 0xf09c,
+ 			"%s: sess %8phN send port_offline event\n",
+ 			__func__, sess->port_name);
+ 		sess->edif.app_sess_online = 0;
+ 		qla2x00_post_aen_work(vha, FCH_EVT_PORT_OFFLINE, sess->d_id.b24);
+ 	}
+ }
++>>>>>>> 9efea843a906 (scsi: qla2xxx: edif: Add detection of secure device)
diff --cc drivers/scsi/qla2xxx/qla_gbl.h
index 50ae84979282,61b0164ac283..000000000000
--- a/drivers/scsi/qla2xxx/qla_gbl.h
+++ b/drivers/scsi/qla2xxx/qla_gbl.h
@@@ -132,6 -131,18 +132,21 @@@ void qla24xx_free_purex_item(struct pur
  extern bool qla24xx_risc_firmware_invalid(uint32_t *);
  void qla_init_iocb_limit(scsi_qla_host_t *);
  
++<<<<<<< HEAD
++=======
+ void qla_edif_list_del(fc_port_t *fcport);
+ void qla_edif_sadb_release(struct qla_hw_data *ha);
+ int qla_edif_sadb_build_free_pool(struct qla_hw_data *ha);
+ void qla_edif_sadb_release_free_pool(struct qla_hw_data *ha);
+ void qla_chk_edif_rx_sa_delete_pending(scsi_qla_host_t *vha,
+ 		srb_t *sp, struct sts_entry_24xx *sts24);
+ void qlt_chk_edif_rx_sa_delete_pending(scsi_qla_host_t *vha, fc_port_t *fcport,
+ 		struct ctio7_from_24xx *ctio);
+ void qla2x00_release_all_sadb(struct scsi_qla_host *vha, struct fc_port *fcport);
+ int qla_edif_process_els(scsi_qla_host_t *vha, struct bsg_job *bsgjob);
+ void qla_edif_sess_down(struct scsi_qla_host *vha, struct fc_port *sess);
+ const char *sc_to_str(uint16_t cmd);
++>>>>>>> 9efea843a906 (scsi: qla2xxx: edif: Add detection of secure device)
  
  /*
   * Global Data in qla_os.c source file.
diff --git a/drivers/scsi/qla2xxx/qla_def.h b/drivers/scsi/qla2xxx/qla_def.h
index 3f8adf82ab1b..e73c9c09ee8e 100644
--- a/drivers/scsi/qla2xxx/qla_def.h
+++ b/drivers/scsi/qla2xxx/qla_def.h
@@ -485,6 +485,7 @@ struct srb_iocb {
 #define SRB_LOGIN_SKIP_PRLI	BIT_2
 #define SRB_LOGIN_NVME_PRLI	BIT_3
 #define SRB_LOGIN_PRLI_ONLY	BIT_4
+#define SRB_LOGIN_FCSP		BIT_5
 			uint16_t data[2];
 			u32 iop[2];
 		} logio;
@@ -2295,6 +2296,7 @@ struct imm_ntfy_from_isp {
 			__le16	nport_handle;
 			uint16_t reserved_2;
 			__le16	flags;
+#define NOTIFY24XX_FLAGS_FCSP		BIT_5
 #define NOTIFY24XX_FLAGS_GLOBAL_TPRLO   BIT_1
 #define NOTIFY24XX_FLAGS_PUREX_IOCB     BIT_0
 			__le16	srr_rx_id;
@@ -2623,7 +2625,8 @@ static const char * const port_dstate_str[] = {
 	"UPD_FCPORT",
 	"LOGIN_COMPLETE",
 	"ADISC",
-	"DELETE_PEND"
+	"DELETE_PEND",
+	"LOGIN_AUTH_PEND",
 };
 
 /*
* Unmerged path drivers/scsi/qla2xxx/qla_edif.c
diff --git a/drivers/scsi/qla2xxx/qla_fw.h b/drivers/scsi/qla2xxx/qla_fw.h
index 44db5e1fc35e..6cb30105ed17 100644
--- a/drivers/scsi/qla2xxx/qla_fw.h
+++ b/drivers/scsi/qla2xxx/qla_fw.h
@@ -83,10 +83,11 @@ struct port_database_24xx {
 	uint8_t port_name[WWN_SIZE];
 	uint8_t node_name[WWN_SIZE];
 
-	uint8_t reserved_3[4];
+	uint8_t reserved_3[2];
+	uint16_t nvme_first_burst_size;
 	uint16_t prli_nvme_svc_param_word_0;	/* Bits 15-0 of word 0 */
 	uint16_t prli_nvme_svc_param_word_3;	/* Bits 15-0 of word 3 */
-	uint16_t nvme_first_burst_size;
+	uint8_t secure_login;
 	uint8_t reserved_4[14];
 };
 
@@ -897,6 +898,7 @@ struct logio_entry_24xx {
 #define LCF_FCP2_OVERRIDE	BIT_9	/* Set/Reset word 3 of PRLI. */
 #define LCF_CLASS_2		BIT_8	/* Enable class 2 during PLOGI. */
 #define LCF_FREE_NPORT		BIT_7	/* Release NPORT handle after LOGO. */
+#define LCF_COMMON_FEAT		BIT_7	/* PLOGI - Set Common Features Field */
 #define LCF_EXPL_LOGO		BIT_6	/* Perform an explicit LOGO. */
 #define LCF_NVME_PRLI		BIT_6   /* Perform NVME FC4 PRLI */
 #define LCF_SKIP_PRLI		BIT_5	/* Skip PRLI after PLOGI. */
@@ -921,6 +923,8 @@ struct logio_entry_24xx {
 	uint8_t rsp_size;		/* Response size in 32bit words. */
 
 	__le32	io_parameter[11];	/* General I/O parameters. */
+#define LIO_COMM_FEAT_FCSP	BIT_21
+#define LIO_COMM_FEAT_CIO	BIT_31
 #define LSC_SCODE_NOLINK	0x01
 #define LSC_SCODE_NOIOCB	0x02
 #define LSC_SCODE_NOXCB		0x03
* Unmerged path drivers/scsi/qla2xxx/qla_gbl.h
diff --git a/drivers/scsi/qla2xxx/qla_gs.c b/drivers/scsi/qla2xxx/qla_gs.c
index 35ef268ad9b4..50494958e62c 100644
--- a/drivers/scsi/qla2xxx/qla_gs.c
+++ b/drivers/scsi/qla2xxx/qla_gs.c
@@ -2820,6 +2820,10 @@ void qla24xx_handle_gpsc_event(scsi_qla_host_t *vha, struct event_arg *ea)
 	if (fcport->disc_state == DSC_DELETE_PEND)
 		return;
 
+	/* We will figure-out what happen after AUTH completes */
+	if (fcport->disc_state == DSC_LOGIN_AUTH_PEND)
+		return;
+
 	if (ea->sp->gen2 != fcport->login_gen) {
 		/* target side must have changed it. */
 		ql_dbg(ql_dbg_disc, vha, 0x20d3,
diff --git a/drivers/scsi/qla2xxx/qla_init.c b/drivers/scsi/qla2xxx/qla_init.c
index 2a2edf816619..f85ddb496f00 100644
--- a/drivers/scsi/qla2xxx/qla_init.c
+++ b/drivers/scsi/qla2xxx/qla_init.c
@@ -343,10 +343,22 @@ qla2x00_async_login(struct scsi_qla_host *vha, fc_port_t *fcport,
 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
 
 	sp->done = qla2x00_async_login_sp_done;
-	if (N2N_TOPO(fcport->vha->hw) && fcport_is_bigger(fcport))
+	if (N2N_TOPO(fcport->vha->hw) && fcport_is_bigger(fcport)) {
 		lio->u.logio.flags |= SRB_LOGIN_PRLI_ONLY;
-	else
-		lio->u.logio.flags |= SRB_LOGIN_COND_PLOGI;
+	} else {
+		if (vha->hw->flags.edif_enabled) {
+			if (fcport->edif.non_secured_login == 0) {
+				lio->u.logio.flags |=
+					(SRB_LOGIN_FCSP | SRB_LOGIN_SKIP_PRLI);
+				ql_dbg(ql_dbg_disc, vha, 0x2072,
+				    "Async-login: w/ FCSP %8phC hdl=%x, loopid=%x portid=%06x\n",
+				    fcport->port_name, sp->handle, fcport->loop_id,
+				    fcport->d_id.b24);
+			}
+		} else {
+			lio->u.logio.flags |= SRB_LOGIN_COND_PLOGI;
+		}
+	}
 
 	if (NVME_TARGET(vha->hw, fcport))
 		lio->u.logio.flags |= SRB_LOGIN_SKIP_PRLI;
@@ -378,7 +390,7 @@ static void qla2x00_async_logout_sp_done(srb_t *sp, int res)
 {
 	sp->fcport->flags &= ~(FCF_ASYNC_SENT | FCF_ASYNC_ACTIVE);
 	sp->fcport->login_gen++;
-	qlt_logo_completion_handler(sp->fcport, res);
+	qlt_logo_completion_handler(sp->fcport, sp->u.iocb_cmd.u.logio.data[0]);
 	sp->free(sp);
 }
 
@@ -404,10 +416,10 @@ qla2x00_async_logout(struct scsi_qla_host *vha, fc_port_t *fcport)
 	sp->done = qla2x00_async_logout_sp_done;
 
 	ql_dbg(ql_dbg_disc, vha, 0x2070,
-	    "Async-logout - hdl=%x loop-id=%x portid=%02x%02x%02x %8phC.\n",
+	    "Async-logout - hdl=%x loop-id=%x portid=%02x%02x%02x %8phC explicit %d.\n",
 	    sp->handle, fcport->loop_id, fcport->d_id.b.domain,
 		fcport->d_id.b.area, fcport->d_id.b.al_pa,
-		fcport->port_name);
+		fcport->port_name, fcport->explicit_logout);
 
 	rval = qla2x00_start_sp(sp);
 	if (rval != QLA_SUCCESS)
@@ -692,11 +704,11 @@ static void qla24xx_handle_gnl_done_event(scsi_qla_host_t *vha,
 
 	fcport = ea->fcport;
 	ql_dbg(ql_dbg_disc, vha, 0xffff,
-	    "%s %8phC DS %d LS rc %d %d login %d|%d rscn %d|%d lid %d\n",
+	    "%s %8phC DS %d LS rc %d %d login %d|%d rscn %d|%d lid %d edif %d\n",
 	    __func__, fcport->port_name, fcport->disc_state,
 	    fcport->fw_login_state, ea->rc,
 	    fcport->login_gen, fcport->last_login_gen,
-	    fcport->rscn_gen, fcport->last_rscn_gen, vha->loop_id);
+	    fcport->rscn_gen, fcport->last_rscn_gen, vha->loop_id, fcport->edif.enable);
 
 	if (fcport->disc_state == DSC_DELETE_PEND)
 		return;
@@ -822,6 +834,13 @@ static void qla24xx_handle_gnl_done_event(scsi_qla_host_t *vha,
 				qla2x00_post_async_adisc_work(vha, fcport,
 				    data);
 				break;
+			case DSC_LS_PLOGI_COMP:
+				if (vha->hw->flags.edif_enabled) {
+					/* check to see if App support Secure */
+					qla24xx_post_gpdb_work(vha, fcport, 0);
+					break;
+				}
+				fallthrough;
 			case DSC_LS_PORT_UNAVAIL:
 			default:
 				if (fcport->loop_id == FC_NO_LOOP_ID) {
@@ -1418,6 +1437,57 @@ void __qla24xx_handle_gpdb_event(scsi_qla_host_t *vha, struct event_arg *ea)
 	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
 }
 
+static int	qla_chk_secure_login(scsi_qla_host_t	*vha, fc_port_t *fcport,
+	struct port_database_24xx *pd)
+{
+	int rc = 0;
+
+	if (pd->secure_login) {
+		ql_dbg(ql_dbg_disc, vha, 0x104d,
+		    "Secure Login established on %8phC\n",
+		    fcport->port_name);
+		fcport->edif.secured_login = 1;
+		fcport->edif.non_secured_login = 0;
+		fcport->flags |= FCF_FCSP_DEVICE;
+	} else {
+		ql_dbg(ql_dbg_disc, vha, 0x104d,
+		    "non-Secure Login %8phC",
+		    fcport->port_name);
+		fcport->edif.secured_login = 0;
+		fcport->edif.non_secured_login = 1;
+	}
+	if (vha->hw->flags.edif_enabled) {
+		if (fcport->flags & FCF_FCSP_DEVICE) {
+			qla2x00_set_fcport_disc_state(fcport, DSC_LOGIN_AUTH_PEND);
+			/* Start edif prli timer & ring doorbell for app */
+			fcport->edif.rx_sa_set = 0;
+			fcport->edif.tx_sa_set = 0;
+			fcport->edif.rx_sa_pending = 0;
+			fcport->edif.tx_sa_pending = 0;
+
+			qla2x00_post_aen_work(vha, FCH_EVT_PORT_ONLINE,
+			    fcport->d_id.b24);
+
+			if (vha->e_dbell.db_flags ==  EDB_ACTIVE) {
+				ql_dbg(ql_dbg_disc, vha, 0x20ef,
+				    "%s %d %8phC EDIF: post DB_AUTH: AUTH needed\n",
+				    __func__, __LINE__, fcport->port_name);
+				fcport->edif.app_started = 1;
+				fcport->edif.app_sess_online = 1;
+			}
+
+			rc = 1;
+		} else {
+			ql_dbg(ql_dbg_disc, vha, 0x2117,
+			    "%s %d %8phC post prli\n",
+			    __func__, __LINE__, fcport->port_name);
+			qla24xx_post_prli_work(vha, fcport);
+			rc = 1;
+		}
+	}
+	return rc;
+}
+
 static
 void qla24xx_handle_gpdb_event(scsi_qla_host_t *vha, struct event_arg *ea)
 {
@@ -1460,8 +1530,11 @@ void qla24xx_handle_gpdb_event(scsi_qla_host_t *vha, struct event_arg *ea)
 	case PDS_PRLI_COMPLETE:
 		__qla24xx_parse_gpdb(vha, fcport, pd);
 		break;
-	case PDS_PLOGI_PENDING:
 	case PDS_PLOGI_COMPLETE:
+		if (qla_chk_secure_login(vha, fcport, pd))
+			return;
+		fallthrough;
+	case PDS_PLOGI_PENDING:
 	case PDS_PRLI_PENDING:
 	case PDS_PRLI2_PENDING:
 		/* Set discovery state back to GNL to Relogin attempt */
@@ -2053,26 +2126,38 @@ qla24xx_handle_plogi_done_event(struct scsi_qla_host *vha, struct event_arg *ea)
 		 * force a relogin attempt via implicit LOGO, PLOGI, and PRLI
 		 * requests.
 		 */
-		if (NVME_TARGET(vha->hw, ea->fcport)) {
-			ql_dbg(ql_dbg_disc, vha, 0x2117,
-				"%s %d %8phC post prli\n",
-				__func__, __LINE__, ea->fcport->port_name);
-			qla24xx_post_prli_work(vha, ea->fcport);
-		} else {
-			ql_dbg(ql_dbg_disc, vha, 0x20ea,
-			    "%s %d %8phC LoopID 0x%x in use with %06x. post gpdb\n",
-			    __func__, __LINE__, ea->fcport->port_name,
-			    ea->fcport->loop_id, ea->fcport->d_id.b24);
-
+		if (vha->hw->flags.edif_enabled) {
 			set_bit(ea->fcport->loop_id, vha->hw->loop_id_map);
 			spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
 			ea->fcport->chip_reset = vha->hw->base_qpair->chip_reset;
 			ea->fcport->logout_on_delete = 1;
 			ea->fcport->send_els_logo = 0;
-			ea->fcport->fw_login_state = DSC_LS_PRLI_COMP;
+			ea->fcport->fw_login_state = DSC_LS_PLOGI_COMP;
 			spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
 
 			qla24xx_post_gpdb_work(vha, ea->fcport, 0);
+		} else {
+			if (NVME_TARGET(vha->hw, fcport)) {
+				ql_dbg(ql_dbg_disc, vha, 0x2117,
+				    "%s %d %8phC post prli\n",
+				    __func__, __LINE__, fcport->port_name);
+				qla24xx_post_prli_work(vha, fcport);
+			} else {
+				ql_dbg(ql_dbg_disc, vha, 0x20ea,
+				    "%s %d %8phC LoopID 0x%x in use with %06x. post gpdb\n",
+				    __func__, __LINE__, fcport->port_name,
+				    fcport->loop_id, fcport->d_id.b24);
+
+				set_bit(fcport->loop_id, vha->hw->loop_id_map);
+				spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+				fcport->chip_reset = vha->hw->base_qpair->chip_reset;
+				fcport->logout_on_delete = 1;
+				fcport->send_els_logo = 0;
+				fcport->fw_login_state = DSC_LS_PRLI_COMP;
+				spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+
+				qla24xx_post_gpdb_work(vha, fcport, 0);
+			}
 		}
 		break;
 	case MBS_COMMAND_ERROR:
@@ -5098,8 +5183,13 @@ qla2x00_free_fcport(fc_port_t *fcport)
 
 		fcport->ct_desc.ct_sns = NULL;
 	}
+
+	qla_edif_flush_sa_ctl_lists(fcport);
 	list_del(&fcport->list);
 	qla2x00_clear_loop_id(fcport);
+
+	qla_edif_list_del(fcport);
+
 	kfree(fcport);
 }
 
@@ -5218,6 +5308,12 @@ qla2x00_configure_loop(scsi_qla_host_t *vha)
 			    "LOOP READY.\n");
 			ha->flags.fw_init_done = 1;
 
+			if (vha->hw->flags.edif_enabled &&
+			    vha->e_dbell.db_flags != EDB_ACTIVE) {
+				/* wake up authentication app to get ready */
+				qla2x00_post_aen_work(vha, FCH_EVT_PORT_ONLINE, 0);
+			}
+
 			/*
 			 * Process any ATIO queue entries that came in
 			 * while we weren't online.
@@ -5237,7 +5333,8 @@ qla2x00_configure_loop(scsi_qla_host_t *vha)
 		    "%s *** FAILED ***.\n", __func__);
 	} else {
 		ql_dbg(ql_dbg_disc, vha, 0x206b,
-		    "%s: exiting normally.\n", __func__);
+		    "%s: exiting normally. local port wwpn %8phN id %06x)\n",
+		    __func__, vha->port_name, vha->d_id.b24);
 	}
 
 	/* Restore state if a resync event occurred during processing */
diff --git a/drivers/scsi/qla2xxx/qla_iocb.c b/drivers/scsi/qla2xxx/qla_iocb.c
index 7c55022f5a26..ffae5e428654 100644
--- a/drivers/scsi/qla2xxx/qla_iocb.c
+++ b/drivers/scsi/qla2xxx/qla_iocb.c
@@ -2463,6 +2463,12 @@ qla24xx_login_iocb(srb_t *sp, struct logio_entry_24xx *logio)
 			logio->control_flags |= cpu_to_le16(LCF_COND_PLOGI);
 		if (lio->u.logio.flags & SRB_LOGIN_SKIP_PRLI)
 			logio->control_flags |= cpu_to_le16(LCF_SKIP_PRLI);
+		if (lio->u.logio.flags & SRB_LOGIN_FCSP) {
+			logio->control_flags |=
+			    cpu_to_le16(LCF_COMMON_FEAT | LCF_SKIP_PRLI);
+			logio->io_parameter[0] =
+			    cpu_to_le32(LIO_COMM_FEAT_FCSP | LIO_COMM_FEAT_CIO);
+		}
 	}
 	logio->nport_handle = cpu_to_le16(sp->fcport->loop_id);
 	logio->port_id[0] = sp->fcport->d_id.b.al_pa;
@@ -2803,7 +2809,6 @@ qla24xx_els_logo_iocb(srb_t *sp, struct els_entry_24xx *els_iocb)
 		    (uint8_t *)els_iocb,
 		    sizeof(*els_iocb));
 	} else {
-		els_iocb->control_flags = cpu_to_le16(1 << 13);
 		els_iocb->tx_byte_count =
 			cpu_to_le32(sizeof(struct els_logo_payload));
 		put_unaligned_le64(elsio->u.els_logo.els_logo_pyld_dma,
@@ -3697,6 +3702,16 @@ static void qla2x00_send_notify_ack_iocb(srb_t *sp,
 	nack->u.isp24.srr_reject_code = 0;
 	nack->u.isp24.srr_reject_code_expl = 0;
 	nack->u.isp24.vp_index = ntfy->u.isp24.vp_index;
+
+	if (ntfy->u.isp24.status_subcode == ELS_PLOGI &&
+	    (le16_to_cpu(ntfy->u.isp24.flags) & NOTIFY24XX_FLAGS_FCSP) &&
+	    sp->vha->hw->flags.edif_enabled) {
+		ql_dbg(ql_dbg_disc, sp->vha, 0x3074,
+		    "%s PLOGI NACK sent with FC SECURITY bit, hdl=%x, loopid=%x, to pid %06x\n",
+		    sp->name, sp->handle, sp->fcport->loop_id,
+		    sp->fcport->d_id.b24);
+		nack->u.isp24.flags |= cpu_to_le16(NOTIFY_ACK_FLAGS_FCSP);
+	}
 }
 
 /*
diff --git a/drivers/scsi/qla2xxx/qla_isr.c b/drivers/scsi/qla2xxx/qla_isr.c
index 6e542510f034..d775dbdcfc13 100644
--- a/drivers/scsi/qla2xxx/qla_isr.c
+++ b/drivers/scsi/qla2xxx/qla_isr.c
@@ -2154,6 +2154,10 @@ qla24xx_logio_entry(scsi_qla_host_t *vha, struct req_que *req,
 		if (sp->type != SRB_LOGIN_CMD)
 			goto logio_done;
 
+		lio->u.logio.iop[1] = le32_to_cpu(logio->io_parameter[5]);
+		if (le32_to_cpu(logio->io_parameter[5]) & LIO_COMM_FEAT_FCSP)
+			fcport->flags |= FCF_FCSP_DEVICE;
+
 		iop[0] = le32_to_cpu(logio->io_parameter[0]);
 		if (iop[0] & BIT_4) {
 			fcport->port_type = FCT_TARGET;
diff --git a/drivers/scsi/qla2xxx/qla_mbx.c b/drivers/scsi/qla2xxx/qla_mbx.c
index 611f9530ce87..23de7dd96827 100644
--- a/drivers/scsi/qla2xxx/qla_mbx.c
+++ b/drivers/scsi/qla2xxx/qla_mbx.c
@@ -6589,6 +6589,12 @@ int __qla24xx_parse_gpdb(struct scsi_qla_host *vha, fc_port_t *fcport,
 	fcport->d_id.b.al_pa = pd->port_id[2];
 	fcport->d_id.b.rsvd_1 = 0;
 
+	ql_dbg(ql_dbg_disc, vha, 0x2062,
+	     "%8phC SVC Param w3 %02x%02x",
+	     fcport->port_name,
+	     pd->prli_svc_param_word_3[1],
+	     pd->prli_svc_param_word_3[0]);
+
 	if (NVME_TARGET(vha->hw, fcport)) {
 		fcport->port_type = FCT_NVME;
 		if ((pd->prli_svc_param_word_3[0] & BIT_5) == 0)
diff --git a/drivers/scsi/qla2xxx/qla_mid.c b/drivers/scsi/qla2xxx/qla_mid.c
index 08cfe043ac66..d58efa927f36 100644
--- a/drivers/scsi/qla2xxx/qla_mid.c
+++ b/drivers/scsi/qla2xxx/qla_mid.c
@@ -159,6 +159,10 @@ qla24xx_disable_vp(scsi_qla_host_t *vha)
 	int ret = QLA_SUCCESS;
 	fc_port_t *fcport;
 
+	if (vha->hw->flags.edif_enabled)
+		/* delete sessions and flush sa_indexes */
+		qla2x00_wait_for_sess_deletion(vha);
+
 	if (vha->hw->flags.fw_started)
 		ret = qla24xx_control_vp(vha, VCE_COMMAND_DISABLE_VPS_LOGO_ALL);
 
@@ -167,7 +171,8 @@ qla24xx_disable_vp(scsi_qla_host_t *vha)
 	list_for_each_entry(fcport, &vha->vp_fcports, list)
 		fcport->logout_on_delete = 0;
 
-	qla2x00_mark_all_devices_lost(vha);
+	if (!vha->hw->flags.edif_enabled)
+		qla2x00_wait_for_sess_deletion(vha);
 
 	/* Remove port id from vp target map */
 	spin_lock_irqsave(&vha->hw->hardware_lock, flags);
diff --git a/drivers/scsi/qla2xxx/qla_os.c b/drivers/scsi/qla2xxx/qla_os.c
index fbb549c49362..edebd1afefc3 100644
--- a/drivers/scsi/qla2xxx/qla_os.c
+++ b/drivers/scsi/qla2xxx/qla_os.c
@@ -1120,12 +1120,28 @@ static inline int test_fcport_count(scsi_qla_host_t *vha)
 	struct qla_hw_data *ha = vha->hw;
 	unsigned long flags;
 	int res;
+	/* Return 0 = sleep, x=wake */
 
 	spin_lock_irqsave(&ha->tgt.sess_lock, flags);
 	ql_dbg(ql_dbg_init, vha, 0x00ec,
 	    "tgt %p, fcport_count=%d\n",
 	    vha, vha->fcport_count);
 	res = (vha->fcport_count == 0);
+	if  (res) {
+		struct fc_port *fcport;
+
+		list_for_each_entry(fcport, &vha->vp_fcports, list) {
+			if (fcport->deleted != QLA_SESS_DELETED) {
+				/* session(s) may not be fully logged in
+				 * (ie fcport_count=0), but session
+				 * deletion thread(s) may be inflight.
+				 */
+
+				res = 0;
+				break;
+			}
+		}
+	}
 	spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
 
 	return res;
@@ -3813,6 +3829,8 @@ void qla2x00_mark_device_lost(scsi_qla_host_t *vha, fc_port_t *fcport,
 		qla2x00_set_fcport_state(fcport, FCS_DEVICE_LOST);
 		qla2x00_schedule_rport_del(vha, fcport);
 	}
+
+	qla_edif_sess_down(vha, fcport);
 	/*
 	 * We may need to retry the login, so don't change the state of the
 	 * port but do the retries.
@@ -5270,6 +5288,7 @@ void qla2x00_relogin(struct scsi_qla_host *vha)
 		if (atomic_read(&fcport->state) != FCS_ONLINE &&
 		    fcport->login_retry) {
 			if (fcport->scan_state != QLA_FCPORT_FOUND ||
+			    fcport->disc_state == DSC_LOGIN_AUTH_PEND ||
 			    fcport->disc_state == DSC_LOGIN_COMPLETE)
 				continue;
 
diff --git a/drivers/scsi/qla2xxx/qla_target.c b/drivers/scsi/qla2xxx/qla_target.c
index cc3934c87715..2ca2f156ad39 100644
--- a/drivers/scsi/qla2xxx/qla_target.c
+++ b/drivers/scsi/qla2xxx/qla_target.c
@@ -588,6 +588,16 @@ static void qla2x00_async_nack_sp_done(srb_t *sp, int res)
 		sp->fcport->logout_on_delete = 1;
 		sp->fcport->plogi_nack_done_deadline = jiffies + HZ;
 		sp->fcport->send_els_logo = 0;
+
+		if (sp->fcport->flags & FCF_FCSP_DEVICE) {
+			ql_dbg(ql_dbg_edif, vha, 0x20ef,
+			    "%s %8phC edif: PLOGI- AUTH WAIT\n", __func__,
+			    sp->fcport->port_name);
+			qla2x00_set_fcport_disc_state(sp->fcport,
+			    DSC_LOGIN_AUTH_PEND);
+			qla2x00_post_aen_work(vha, FCH_EVT_PORT_ONLINE,
+			    sp->fcport->d_id.b24);
+		}
 		break;
 
 	case SRB_NACK_PRLI:
@@ -635,6 +645,10 @@ int qla24xx_async_notify_ack(scsi_qla_host_t *vha, fc_port_t *fcport,
 	case SRB_NACK_PLOGI:
 		fcport->fw_login_state = DSC_LS_PLOGI_PEND;
 		c = "PLOGI";
+		if (vha->hw->flags.edif_enabled &&
+		    (le16_to_cpu(ntfy->u.isp24.flags) & NOTIFY24XX_FLAGS_FCSP)) {
+			fcport->flags |= FCF_FCSP_DEVICE;
+		}
 		break;
 	case SRB_NACK_PRLI:
 		fcport->fw_login_state = DSC_LS_PRLI_PEND;
@@ -704,7 +718,12 @@ void qla24xx_do_nack_work(struct scsi_qla_host *vha, struct qla_work_evt *e)
 void qla24xx_delete_sess_fn(struct work_struct *work)
 {
 	fc_port_t *fcport = container_of(work, struct fc_port, del_work);
-	struct qla_hw_data *ha = fcport->vha->hw;
+	struct qla_hw_data *ha = NULL;
+
+	if (!fcport || !fcport->vha || !fcport->vha->hw)
+		return;
+
+	ha = fcport->vha->hw;
 
 	if (fcport->se_sess) {
 		ha->tgt.tgt_ops->shutdown_sess(fcport);
@@ -976,6 +995,19 @@ void qlt_free_session_done(struct work_struct *work)
 		sess->send_els_logo);
 
 	if (!IS_SW_RESV_ADDR(sess->d_id)) {
+		if (ha->flags.edif_enabled &&
+		    (!own || own->iocb.u.isp24.status_subcode == ELS_PLOGI)) {
+			if (!ha->flags.host_shutting_down) {
+				ql_dbg(ql_dbg_edif, vha, 0x911e,
+					"%s wwpn %8phC calling qla2x00_release_all_sadb\n",
+					__func__, sess->port_name);
+				qla2x00_release_all_sadb(vha, sess);
+			} else {
+				ql_dbg(ql_dbg_edif, vha, 0x911e,
+					"%s bypassing release_all_sadb\n",
+					__func__);
+			}
+		}
 		qla2x00_mark_device_lost(vha, sess, 0);
 
 		if (sess->send_els_logo) {
@@ -983,6 +1015,7 @@ void qlt_free_session_done(struct work_struct *work)
 
 			logo.id = sess->d_id;
 			logo.cmd_count = 0;
+			INIT_LIST_HEAD(&logo.list);
 			if (!own)
 				qlt_send_first_logo(vha, &logo);
 			sess->send_els_logo = 0;
@@ -993,6 +1026,7 @@ void qlt_free_session_done(struct work_struct *work)
 
 			if (!own ||
 			     (own->iocb.u.isp24.status_subcode == ELS_PLOGI)) {
+				sess->logout_completed = 0;
 				rc = qla2x00_post_async_logout_work(vha, sess,
 				    NULL);
 				if (rc != QLA_SUCCESS)
@@ -1731,6 +1765,12 @@ static void qlt_send_notify_ack(struct qla_qpair *qpair,
 	nack->u.isp24.srr_reject_code_expl = srr_explan;
 	nack->u.isp24.vp_index = ntfy->u.isp24.vp_index;
 
+	/* TODO qualify this with EDIF enable */
+	if (ntfy->u.isp24.status_subcode == ELS_PLOGI &&
+	    (le16_to_cpu(ntfy->u.isp24.flags) & NOTIFY24XX_FLAGS_FCSP)) {
+		nack->u.isp24.flags |= cpu_to_le16(NOTIFY_ACK_FLAGS_FCSP);
+	}
+
 	ql_dbg(ql_dbg_tgt, vha, 0xe005,
 	    "qla_target(%d): Sending 24xx Notify Ack %d\n",
 	    vha->vp_idx, nack->u.isp24.status);
@@ -4744,6 +4784,15 @@ static int qlt_handle_login(struct scsi_qla_host *vha,
 		goto out;
 	}
 
+	if (vha->hw->flags.edif_enabled &&
+	    vha->e_dbell.db_flags != EDB_ACTIVE) {
+		ql_dbg(ql_dbg_disc, vha, 0xffff,
+			"%s %d Term INOT due to app not available lid=%d, NportID %06X ",
+			__func__, __LINE__, loop_id, port_id.b24);
+		qlt_send_term_imm_notif(vha, iocb, 1);
+		goto out;
+	}
+
 	pla = qlt_plogi_ack_find_add(vha, &port_id, iocb);
 	if (!pla) {
 		ql_dbg(ql_dbg_disc + ql_dbg_verbose, vha, 0xffff,
@@ -4809,6 +4858,16 @@ static int qlt_handle_login(struct scsi_qla_host *vha,
 	qlt_plogi_ack_link(vha, pla, sess, QLT_PLOGI_LINK_SAME_WWN);
 	sess->d_id = port_id;
 	sess->login_gen++;
+	sess->loop_id = loop_id;
+
+	if (iocb->u.isp24.status_subcode == ELS_PLOGI) {
+		ql_dbg(ql_dbg_disc, vha, 0xffff,
+		    "%s %8phC - send port online\n",
+		    __func__, sess->port_name);
+
+		qla2x00_post_aen_work(vha, FCH_EVT_PORT_ONLINE,
+		    sess->d_id.b24);
+	}
 
 	if (iocb->u.isp24.status_subcode == ELS_PRLI) {
 		sess->fw_login_state = DSC_LS_PRLI_PEND;
diff --git a/drivers/scsi/qla2xxx/qla_target.h b/drivers/scsi/qla2xxx/qla_target.h
index 6b5ee6c3a43f..32858b412f4d 100644
--- a/drivers/scsi/qla2xxx/qla_target.h
+++ b/drivers/scsi/qla2xxx/qla_target.h
@@ -185,6 +185,7 @@ struct nack_to_isp {
 	uint8_t  reserved[2];
 	__le16	ox_id;
 } __packed;
+#define NOTIFY_ACK_FLAGS_FCSP		BIT_5
 #define NOTIFY_ACK_FLAGS_TERMINATE	BIT_3
 #define NOTIFY_ACK_SRR_FLAGS_ACCEPT	0
 #define NOTIFY_ACK_SRR_FLAGS_REJECT	1
