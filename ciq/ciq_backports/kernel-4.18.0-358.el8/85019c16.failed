sched/wakeup: Reorganize the current::__state helpers

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 85019c1674890fa0408e324589e20803b3241755
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/85019c16.failed

In order to avoid more duplicate implementations for the debug and
non-debug variants of the state change macros, split the debug portion out
and make that conditional on CONFIG_DEBUG_ATOMIC_SLEEP=y.

	Suggested-by: Waiman Long <longman@redhat.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
Link: https://lore.kernel.org/r/20210815211302.200898048@linutronix.de
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 85019c1674890fa0408e324589e20803b3241755)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/sched.h
diff --cc include/linux/sched.h
index a7fd30871ea0,4c72cf6aaabf..000000000000
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@@ -113,14 -115,14 +113,12 @@@ struct task_group
  					 __TASK_TRACED | EXIT_DEAD | EXIT_ZOMBIE | \
  					 TASK_PARKED)
  
 -#define task_is_running(task)		(READ_ONCE((task)->__state) == TASK_RUNNING)
 +#define task_is_traced(task)		((task->state & __TASK_TRACED) != 0)
  
 -#define task_is_traced(task)		((READ_ONCE(task->__state) & __TASK_TRACED) != 0)
 +#define task_is_stopped(task)		((task->state & __TASK_STOPPED) != 0)
  
 -#define task_is_stopped(task)		((READ_ONCE(task->__state) & __TASK_STOPPED) != 0)
 -
 -#define task_is_stopped_or_traced(task)	((READ_ONCE(task->__state) & (__TASK_STOPPED | __TASK_TRACED)) != 0)
 +#define task_is_stopped_or_traced(task)	((task->state & (__TASK_STOPPED | __TASK_TRACED)) != 0)
  
- #ifdef CONFIG_DEBUG_ATOMIC_SLEEP
- 
  /*
   * Special states are those that do not use the normal wait-loop pattern. See
   * the comment with set_special_state().
@@@ -128,30 -130,24 +126,47 @@@
  #define is_special_task_state(state)				\
  	((state) & (__TASK_STOPPED | __TASK_TRACED | TASK_PARKED | TASK_DEAD))
  
++<<<<<<< HEAD
 +#define __set_current_state(state_value)			\
 +	do {							\
 +		WARN_ON_ONCE(is_special_task_state(state_value));\
 +		current->task_state_change = _THIS_IP_;		\
 +		current->state = (state_value);			\
 +	} while (0)
 +
 +#define set_current_state(state_value)				\
 +	do {							\
 +		WARN_ON_ONCE(is_special_task_state(state_value));\
 +		current->task_state_change = _THIS_IP_;		\
 +		smp_store_mb(current->state, (state_value));	\
 +	} while (0)
 +
 +#define set_special_state(state_value)					\
++=======
+ #ifdef CONFIG_DEBUG_ATOMIC_SLEEP
+ # define debug_normal_state_change(state_value)				\
++>>>>>>> 85019c167489 (sched/wakeup: Reorganize the current::__state helpers)
  	do {								\
- 		unsigned long flags; /* may shadow */			\
- 		WARN_ON_ONCE(!is_special_task_state(state_value));	\
- 		raw_spin_lock_irqsave(&current->pi_lock, flags);	\
+ 		WARN_ON_ONCE(is_special_task_state(state_value));	\
  		current->task_state_change = _THIS_IP_;			\
++<<<<<<< HEAD
 +		current->state = (state_value);				\
 +		raw_spin_unlock_irqrestore(&current->pi_lock, flags);	\
++=======
++>>>>>>> 85019c167489 (sched/wakeup: Reorganize the current::__state helpers)
  	} while (0)
+ 
+ # define debug_special_state_change(state_value)			\
+ 	do {								\
+ 		WARN_ON_ONCE(!is_special_task_state(state_value));	\
+ 		current->task_state_change = _THIS_IP_;			\
+ 	} while (0)
+ 
  #else
+ # define debug_normal_state_change(cond)	do { } while (0)
+ # define debug_special_state_change(cond)	do { } while (0)
+ #endif
+ 
  /*
   * set_current_state() includes a barrier so that the write of current->state
   * is correctly serialised wrt the caller's subsequent test of whether to
@@@ -190,10 -186,16 +205,23 @@@
   * Also see the comments of try_to_wake_up().
   */
  #define __set_current_state(state_value)				\
++<<<<<<< HEAD
 +	current->state = (state_value)
 +
 +#define set_current_state(state_value)					\
 +	smp_store_mb(current->state, (state_value))
++=======
+ 	do {								\
+ 		debug_normal_state_change((state_value));		\
+ 		WRITE_ONCE(current->__state, (state_value));		\
+ 	} while (0)
+ 
+ #define set_current_state(state_value)					\
+ 	do {								\
+ 		debug_normal_state_change((state_value));		\
+ 		smp_store_mb(current->__state, (state_value));		\
+ 	} while (0)
++>>>>>>> 85019c167489 (sched/wakeup: Reorganize the current::__state helpers)
  
  /*
   * set_special_state() should be used for those states when the blocking task
@@@ -204,14 -206,14 +232,24 @@@
  #define set_special_state(state_value)					\
  	do {								\
  		unsigned long flags; /* may shadow */			\
+ 									\
  		raw_spin_lock_irqsave(&current->pi_lock, flags);	\
++<<<<<<< HEAD
 +		current->state = (state_value);				\
 +		raw_spin_unlock_irqrestore(&current->pi_lock, flags);	\
 +	} while (0)
 +
 +#endif
 +
 +#define get_current_state()	READ_ONCE(current->state)
++=======
+ 		debug_special_state_change((state_value));		\
+ 		WRITE_ONCE(current->__state, (state_value));		\
+ 		raw_spin_unlock_irqrestore(&current->pi_lock, flags);	\
+ 	} while (0)
+ 
+ #define get_current_state()	READ_ONCE(current->__state)
++>>>>>>> 85019c167489 (sched/wakeup: Reorganize the current::__state helpers)
  
  /* Task command name length: */
  #define TASK_COMM_LEN			16
* Unmerged path include/linux/sched.h
