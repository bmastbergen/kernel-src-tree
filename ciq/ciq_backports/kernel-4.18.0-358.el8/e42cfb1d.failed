block: Remove unnecessary elevator operation checks

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Damien Le Moal <damien.lemoal@wdc.com>
commit e42cfb1da0bf33c313318da201730324c423351d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/e42cfb1d.failed

The insert_requests and dispatch_request elevator operations are
mandatory for the correct execution of an elevator, and all implemented
elevators (bfq, kyber and mq-deadline) implement them. As a result,
there is no need to check for these operations before calling them when
a queue has an elevator set. This simplifies the code in
__blk_mq_sched_dispatch_requests() and blk_mq_sched_insert_request().

To avoid out-of-tree elevators to crash the kernel in case of bad
implementation, add a check in elv_register() to verify that these
operations are implemented.

A small, probably not significant, IOPS improvement of 0.1% is observed
with this patch applied (4.117 MIOPS to 4.123 MIOPS, average of 20 fio
runs doing 4K random direct reads with psync and 32 jobs).

	Signed-off-by: Damien Le Moal <damien.lemoal@wdc.com>
	Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
Link: https://lore.kernel.org/r/20210618015922.713999-1-damien.lemoal@wdc.com
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit e42cfb1da0bf33c313318da201730324c423351d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/elevator.c
diff --cc block/elevator.c
index aa39bbc8f7ec,85d0d4adbb64..000000000000
--- a/block/elevator.c
+++ b/block/elevator.c
@@@ -539,7 -522,9 +539,13 @@@ void elv_unregister_queue(struct reques
  
  int elv_register(struct elevator_type *e)
  {
++<<<<<<< HEAD
 +	char *def = "";
++=======
+ 	/* insert_requests and dispatch_request are mandatory */
+ 	if (WARN_ON_ONCE(!e->ops.insert_requests || !e->ops.dispatch_request))
+ 		return -EINVAL;
++>>>>>>> e42cfb1da0bf (block: Remove unnecessary elevator operation checks)
  
  	/* create icq_cache if requested */
  	if (e->icq_size) {
diff --git a/block/blk-mq-sched.c b/block/blk-mq-sched.c
index 938b66f0ed60..c4cb5932a0fe 100644
--- a/block/blk-mq-sched.c
+++ b/block/blk-mq-sched.c
@@ -294,8 +294,7 @@ static int blk_mq_do_dispatch_ctx(struct blk_mq_hw_ctx *hctx)
 static int __blk_mq_sched_dispatch_requests(struct blk_mq_hw_ctx *hctx)
 {
 	struct request_queue *q = hctx->queue;
-	struct elevator_queue *e = q->elevator;
-	const bool has_sched_dispatch = e && e->type->ops.dispatch_request;
+	const bool has_sched = q->elevator;
 	int ret = 0;
 	LIST_HEAD(rq_list);
 
@@ -326,12 +325,12 @@ static int __blk_mq_sched_dispatch_requests(struct blk_mq_hw_ctx *hctx)
 	if (!list_empty(&rq_list)) {
 		blk_mq_sched_mark_restart_hctx(hctx);
 		if (blk_mq_dispatch_rq_list(hctx, &rq_list, 0)) {
-			if (has_sched_dispatch)
+			if (has_sched)
 				ret = blk_mq_do_dispatch_sched(hctx);
 			else
 				ret = blk_mq_do_dispatch_ctx(hctx);
 		}
-	} else if (has_sched_dispatch) {
+	} else if (has_sched) {
 		ret = blk_mq_do_dispatch_sched(hctx);
 	} else if (hctx->dispatch_busy) {
 		/* dequeue request one by one from sw queue if queue is busy */
@@ -509,7 +508,7 @@ void blk_mq_sched_insert_request(struct request *rq, bool at_head,
 		goto run;
 	}
 
-	if (e && e->type->ops.insert_requests) {
+	if (e) {
 		LIST_HEAD(list);
 
 		list_add(&rq->queuelist, &list);
@@ -540,9 +539,9 @@ void blk_mq_sched_insert_requests(struct blk_mq_hw_ctx *hctx,
 	percpu_ref_get(&q->q_usage_counter);
 
 	e = hctx->queue->elevator;
-	if (e && e->type->ops.insert_requests)
+	if (e) {
 		e->type->ops.insert_requests(hctx, list, false);
-	else {
+	} else {
 		/*
 		 * try to issue requests directly if the hw queue isn't
 		 * busy in case of 'none' scheduler, and this way may save
* Unmerged path block/elevator.c
