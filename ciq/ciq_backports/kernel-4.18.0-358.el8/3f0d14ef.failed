net: bridge: mcast: use the correct vlan group helper

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Nikolay Aleksandrov <nikolay@nvidia.com>
commit 3f0d14efe2fa8656a1c46f1d13d42bb5bd88f32f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/3f0d14ef.failed

When dereferencing the port vlan group we should use the rcu helper
instead of the one relying on rtnl. In br_multicast_pg_to_port_ctx the
entry cannot disappear as we hold the multicast lock and rcu as explained
in the comment above it.
For the same reason we're ok in br_multicast_start_querier.

 =============================
 WARNING: suspicious RCU usage
 5.14.0-rc5+ #429 Tainted: G        W
 -----------------------------
 net/bridge/br_private.h:1478 suspicious rcu_dereference_protected() usage!

 other info that might help us debug this:

 rcu_scheduler_active = 2, debug_locks = 1
 3 locks held by swapper/2/0:
  #0: ffff88822be85eb0 ((&p->timer)){+.-.}-{0:0}, at: call_timer_fn+0x5/0x2da
  #1: ffff88810b32f260 (&br->multicast_lock){+.-.}-{3:3}, at: br_multicast_port_group_expired+0x28/0x13d [bridge]
  #2: ffffffff824f6c80 (rcu_read_lock){....}-{1:3}, at: rcu_lock_acquire.constprop.0+0x0/0x22 [bridge]

 stack backtrace:
 CPU: 2 PID: 0 Comm: swapper/2 Kdump: loaded Tainted: G        W         5.14.0-rc5+ #429
 Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.14.0-4.fc34 04/01/2014
 Call Trace:
  <IRQ>
  dump_stack_lvl+0x45/0x59
  nbp_vlan_group+0x3e/0x44 [bridge]
  br_multicast_pg_to_port_ctx+0xd6/0x10d [bridge]
  br_multicast_star_g_handle_mode+0xa1/0x2ce [bridge]
  ? netlink_broadcast+0xf/0x11
  ? nlmsg_notify+0x56/0x99
  ? br_mdb_notify+0x224/0x2e9 [bridge]
  ? br_multicast_del_pg+0x1dc/0x26d [bridge]
  br_multicast_del_pg+0x1dc/0x26d [bridge]
  br_multicast_port_group_expired+0xaa/0x13d [bridge]
  ? __grp_src_delete_marked.isra.0+0x35/0x35 [bridge]
  ? __grp_src_delete_marked.isra.0+0x35/0x35 [bridge]
  call_timer_fn+0x134/0x2da
  __run_timers+0x169/0x193
  run_timer_softirq+0x19/0x2d
  __do_softirq+0x1bc/0x42a
  __irq_exit_rcu+0x5c/0xb3
  irq_exit_rcu+0xa/0x12
  sysvec_apic_timer_interrupt+0x5e/0x75
  </IRQ>
  asm_sysvec_apic_timer_interrupt+0x12/0x20
 RIP: 0010:default_idle+0xc/0xd
 Code: e8 14 40 71 ff e8 10 b3 ff ff 4c 89 e2 48 89 ef 31 f6 5d 41 5c e9 a9 e8 c2 ff cc cc cc cc 0f 1f 44 00 00 e8 7f 55 65 ff fb f4 <c3> 0f 1f 44 00 00 55 65 48 8b 2c 25 40 6f 01 00 53 f0 80 4d 02 20
 RSP: 0018:ffff88810033bf00 EFLAGS: 00000206
 RAX: ffffffff819cf828 RBX: ffff888100328000 RCX: 0000000000000001
 RDX: 0000000000000000 RSI: 0000000000000000 RDI: ffffffff819cfa2d
 RBP: 0000000000000000 R08: 0000000000000000 R09: 0000000000000001
 R10: ffff8881008302c0 R11: 00000000000006db R12: 0000000000000000
 R13: 0000000000000002 R14: 0000000000000000 R15: 0000000000000000
  ? __sched_text_end+0x4/0x4
  ? default_idle_call+0x15/0x7b
  default_idle_call+0x4d/0x7b
  do_idle+0x124/0x2a2
  cpu_startup_entry+0x1d/0x1f
  secondary_startup_64_no_verify+0xb0/0xbb

Fixes: 74edfd483de8 ("net: bridge: multicast: add helper to get port mcast context from port group")
	Signed-off-by: Nikolay Aleksandrov <nikolay@nvidia.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 3f0d14efe2fa8656a1c46f1d13d42bb5bd88f32f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/bridge/br_multicast.c
diff --cc net/bridge/br_multicast.c
index def6f1840985,c9f7f56eaf9b..000000000000
--- a/net/bridge/br_multicast.c
+++ b/net/bridge/br_multicast.c
@@@ -147,6 -193,407 +147,410 @@@ struct net_bridge_mdb_entry *br_mdb_get
  	return br_mdb_ip_get_rcu(br, &ip);
  }
  
++<<<<<<< HEAD
++=======
+ /* IMPORTANT: this function must be used only when the contexts cannot be
+  * passed down (e.g. timer) and must be used for read-only purposes because
+  * the vlan snooping option can change, so it can return any context
+  * (non-vlan or vlan). Its initial intended purpose is to read timer values
+  * from the *current* context based on the option. At worst that could lead
+  * to inconsistent timers when the contexts are changed, i.e. src timer
+  * which needs to re-arm with a specific delay taken from the old context
+  */
+ static struct net_bridge_mcast_port *
+ br_multicast_pg_to_port_ctx(const struct net_bridge_port_group *pg)
+ {
+ 	struct net_bridge_mcast_port *pmctx = &pg->key.port->multicast_ctx;
+ 	struct net_bridge_vlan *vlan;
+ 
+ 	lockdep_assert_held_once(&pg->key.port->br->multicast_lock);
+ 
+ 	/* if vlan snooping is disabled use the port's multicast context */
+ 	if (!pg->key.addr.vid ||
+ 	    !br_opt_get(pg->key.port->br, BROPT_MCAST_VLAN_SNOOPING_ENABLED))
+ 		goto out;
+ 
+ 	/* locking is tricky here, due to different rules for multicast and
+ 	 * vlans we need to take rcu to find the vlan and make sure it has
+ 	 * the BR_VLFLAG_MCAST_ENABLED flag set, it can only change under
+ 	 * multicast_lock which must be already held here, so the vlan's pmctx
+ 	 * can safely be used on return
+ 	 */
+ 	rcu_read_lock();
+ 	vlan = br_vlan_find(nbp_vlan_group_rcu(pg->key.port), pg->key.addr.vid);
+ 	if (vlan && !br_multicast_port_ctx_vlan_disabled(&vlan->port_mcast_ctx))
+ 		pmctx = &vlan->port_mcast_ctx;
+ 	else
+ 		pmctx = NULL;
+ 	rcu_read_unlock();
+ out:
+ 	return pmctx;
+ }
+ 
+ /* when snooping we need to check if the contexts should be used
+  * in the following order:
+  * - if pmctx is non-NULL (port), check if it should be used
+  * - if pmctx is NULL (bridge), check if brmctx should be used
+  */
+ static bool
+ br_multicast_ctx_should_use(const struct net_bridge_mcast *brmctx,
+ 			    const struct net_bridge_mcast_port *pmctx)
+ {
+ 	if (!netif_running(brmctx->br->dev))
+ 		return false;
+ 
+ 	if (pmctx)
+ 		return !br_multicast_port_ctx_state_disabled(pmctx);
+ 	else
+ 		return !br_multicast_ctx_vlan_disabled(brmctx);
+ }
+ 
+ static bool br_port_group_equal(struct net_bridge_port_group *p,
+ 				struct net_bridge_port *port,
+ 				const unsigned char *src)
+ {
+ 	if (p->key.port != port)
+ 		return false;
+ 
+ 	if (!(port->flags & BR_MULTICAST_TO_UNICAST))
+ 		return true;
+ 
+ 	return ether_addr_equal(src, p->eth_addr);
+ }
+ 
+ static void __fwd_add_star_excl(struct net_bridge_mcast_port *pmctx,
+ 				struct net_bridge_port_group *pg,
+ 				struct br_ip *sg_ip)
+ {
+ 	struct net_bridge_port_group_sg_key sg_key;
+ 	struct net_bridge_port_group *src_pg;
+ 	struct net_bridge_mcast *brmctx;
+ 
+ 	memset(&sg_key, 0, sizeof(sg_key));
+ 	brmctx = br_multicast_port_ctx_get_global(pmctx);
+ 	sg_key.port = pg->key.port;
+ 	sg_key.addr = *sg_ip;
+ 	if (br_sg_port_find(brmctx->br, &sg_key))
+ 		return;
+ 
+ 	src_pg = __br_multicast_add_group(brmctx, pmctx,
+ 					  sg_ip, pg->eth_addr,
+ 					  MCAST_INCLUDE, false, false);
+ 	if (IS_ERR_OR_NULL(src_pg) ||
+ 	    src_pg->rt_protocol != RTPROT_KERNEL)
+ 		return;
+ 
+ 	src_pg->flags |= MDB_PG_FLAGS_STAR_EXCL;
+ }
+ 
+ static void __fwd_del_star_excl(struct net_bridge_port_group *pg,
+ 				struct br_ip *sg_ip)
+ {
+ 	struct net_bridge_port_group_sg_key sg_key;
+ 	struct net_bridge *br = pg->key.port->br;
+ 	struct net_bridge_port_group *src_pg;
+ 
+ 	memset(&sg_key, 0, sizeof(sg_key));
+ 	sg_key.port = pg->key.port;
+ 	sg_key.addr = *sg_ip;
+ 	src_pg = br_sg_port_find(br, &sg_key);
+ 	if (!src_pg || !(src_pg->flags & MDB_PG_FLAGS_STAR_EXCL) ||
+ 	    src_pg->rt_protocol != RTPROT_KERNEL)
+ 		return;
+ 
+ 	br_multicast_find_del_pg(br, src_pg);
+ }
+ 
+ /* When a port group transitions to (or is added as) EXCLUDE we need to add it
+  * to all other ports' S,G entries which are not blocked by the current group
+  * for proper replication, the assumption is that any S,G blocked entries
+  * are already added so the S,G,port lookup should skip them.
+  * When a port group transitions from EXCLUDE -> INCLUDE mode or is being
+  * deleted we need to remove it from all ports' S,G entries where it was
+  * automatically installed before (i.e. where it's MDB_PG_FLAGS_STAR_EXCL).
+  */
+ void br_multicast_star_g_handle_mode(struct net_bridge_port_group *pg,
+ 				     u8 filter_mode)
+ {
+ 	struct net_bridge *br = pg->key.port->br;
+ 	struct net_bridge_port_group *pg_lst;
+ 	struct net_bridge_mcast_port *pmctx;
+ 	struct net_bridge_mdb_entry *mp;
+ 	struct br_ip sg_ip;
+ 
+ 	if (WARN_ON(!br_multicast_is_star_g(&pg->key.addr)))
+ 		return;
+ 
+ 	mp = br_mdb_ip_get(br, &pg->key.addr);
+ 	if (!mp)
+ 		return;
+ 	pmctx = br_multicast_pg_to_port_ctx(pg);
+ 	if (!pmctx)
+ 		return;
+ 
+ 	memset(&sg_ip, 0, sizeof(sg_ip));
+ 	sg_ip = pg->key.addr;
+ 
+ 	for (pg_lst = mlock_dereference(mp->ports, br);
+ 	     pg_lst;
+ 	     pg_lst = mlock_dereference(pg_lst->next, br)) {
+ 		struct net_bridge_group_src *src_ent;
+ 
+ 		if (pg_lst == pg)
+ 			continue;
+ 		hlist_for_each_entry(src_ent, &pg_lst->src_list, node) {
+ 			if (!(src_ent->flags & BR_SGRP_F_INSTALLED))
+ 				continue;
+ 			sg_ip.src = src_ent->addr.src;
+ 			switch (filter_mode) {
+ 			case MCAST_INCLUDE:
+ 				__fwd_del_star_excl(pg, &sg_ip);
+ 				break;
+ 			case MCAST_EXCLUDE:
+ 				__fwd_add_star_excl(pmctx, pg, &sg_ip);
+ 				break;
+ 			}
+ 		}
+ 	}
+ }
+ 
+ /* called when adding a new S,G with host_joined == false by default */
+ static void br_multicast_sg_host_state(struct net_bridge_mdb_entry *star_mp,
+ 				       struct net_bridge_port_group *sg)
+ {
+ 	struct net_bridge_mdb_entry *sg_mp;
+ 
+ 	if (WARN_ON(!br_multicast_is_star_g(&star_mp->addr)))
+ 		return;
+ 	if (!star_mp->host_joined)
+ 		return;
+ 
+ 	sg_mp = br_mdb_ip_get(star_mp->br, &sg->key.addr);
+ 	if (!sg_mp)
+ 		return;
+ 	sg_mp->host_joined = true;
+ }
+ 
+ /* set the host_joined state of all of *,G's S,G entries */
+ static void br_multicast_star_g_host_state(struct net_bridge_mdb_entry *star_mp)
+ {
+ 	struct net_bridge *br = star_mp->br;
+ 	struct net_bridge_mdb_entry *sg_mp;
+ 	struct net_bridge_port_group *pg;
+ 	struct br_ip sg_ip;
+ 
+ 	if (WARN_ON(!br_multicast_is_star_g(&star_mp->addr)))
+ 		return;
+ 
+ 	memset(&sg_ip, 0, sizeof(sg_ip));
+ 	sg_ip = star_mp->addr;
+ 	for (pg = mlock_dereference(star_mp->ports, br);
+ 	     pg;
+ 	     pg = mlock_dereference(pg->next, br)) {
+ 		struct net_bridge_group_src *src_ent;
+ 
+ 		hlist_for_each_entry(src_ent, &pg->src_list, node) {
+ 			if (!(src_ent->flags & BR_SGRP_F_INSTALLED))
+ 				continue;
+ 			sg_ip.src = src_ent->addr.src;
+ 			sg_mp = br_mdb_ip_get(br, &sg_ip);
+ 			if (!sg_mp)
+ 				continue;
+ 			sg_mp->host_joined = star_mp->host_joined;
+ 		}
+ 	}
+ }
+ 
+ static void br_multicast_sg_del_exclude_ports(struct net_bridge_mdb_entry *sgmp)
+ {
+ 	struct net_bridge_port_group __rcu **pp;
+ 	struct net_bridge_port_group *p;
+ 
+ 	/* *,G exclude ports are only added to S,G entries */
+ 	if (WARN_ON(br_multicast_is_star_g(&sgmp->addr)))
+ 		return;
+ 
+ 	/* we need the STAR_EXCLUDE ports if there are non-STAR_EXCLUDE ports
+ 	 * we should ignore perm entries since they're managed by user-space
+ 	 */
+ 	for (pp = &sgmp->ports;
+ 	     (p = mlock_dereference(*pp, sgmp->br)) != NULL;
+ 	     pp = &p->next)
+ 		if (!(p->flags & (MDB_PG_FLAGS_STAR_EXCL |
+ 				  MDB_PG_FLAGS_PERMANENT)))
+ 			return;
+ 
+ 	/* currently the host can only have joined the *,G which means
+ 	 * we treat it as EXCLUDE {}, so for an S,G it's considered a
+ 	 * STAR_EXCLUDE entry and we can safely leave it
+ 	 */
+ 	sgmp->host_joined = false;
+ 
+ 	for (pp = &sgmp->ports;
+ 	     (p = mlock_dereference(*pp, sgmp->br)) != NULL;) {
+ 		if (!(p->flags & MDB_PG_FLAGS_PERMANENT))
+ 			br_multicast_del_pg(sgmp, p, pp);
+ 		else
+ 			pp = &p->next;
+ 	}
+ }
+ 
+ void br_multicast_sg_add_exclude_ports(struct net_bridge_mdb_entry *star_mp,
+ 				       struct net_bridge_port_group *sg)
+ {
+ 	struct net_bridge_port_group_sg_key sg_key;
+ 	struct net_bridge *br = star_mp->br;
+ 	struct net_bridge_mcast_port *pmctx;
+ 	struct net_bridge_port_group *pg;
+ 	struct net_bridge_mcast *brmctx;
+ 
+ 	if (WARN_ON(br_multicast_is_star_g(&sg->key.addr)))
+ 		return;
+ 	if (WARN_ON(!br_multicast_is_star_g(&star_mp->addr)))
+ 		return;
+ 
+ 	br_multicast_sg_host_state(star_mp, sg);
+ 	memset(&sg_key, 0, sizeof(sg_key));
+ 	sg_key.addr = sg->key.addr;
+ 	/* we need to add all exclude ports to the S,G */
+ 	for (pg = mlock_dereference(star_mp->ports, br);
+ 	     pg;
+ 	     pg = mlock_dereference(pg->next, br)) {
+ 		struct net_bridge_port_group *src_pg;
+ 
+ 		if (pg == sg || pg->filter_mode == MCAST_INCLUDE)
+ 			continue;
+ 
+ 		sg_key.port = pg->key.port;
+ 		if (br_sg_port_find(br, &sg_key))
+ 			continue;
+ 
+ 		pmctx = br_multicast_pg_to_port_ctx(pg);
+ 		if (!pmctx)
+ 			continue;
+ 		brmctx = br_multicast_port_ctx_get_global(pmctx);
+ 
+ 		src_pg = __br_multicast_add_group(brmctx, pmctx,
+ 						  &sg->key.addr,
+ 						  sg->eth_addr,
+ 						  MCAST_INCLUDE, false, false);
+ 		if (IS_ERR_OR_NULL(src_pg) ||
+ 		    src_pg->rt_protocol != RTPROT_KERNEL)
+ 			continue;
+ 		src_pg->flags |= MDB_PG_FLAGS_STAR_EXCL;
+ 	}
+ }
+ 
+ static void br_multicast_fwd_src_add(struct net_bridge_group_src *src)
+ {
+ 	struct net_bridge_mdb_entry *star_mp;
+ 	struct net_bridge_mcast_port *pmctx;
+ 	struct net_bridge_port_group *sg;
+ 	struct net_bridge_mcast *brmctx;
+ 	struct br_ip sg_ip;
+ 
+ 	if (src->flags & BR_SGRP_F_INSTALLED)
+ 		return;
+ 
+ 	memset(&sg_ip, 0, sizeof(sg_ip));
+ 	pmctx = br_multicast_pg_to_port_ctx(src->pg);
+ 	if (!pmctx)
+ 		return;
+ 	brmctx = br_multicast_port_ctx_get_global(pmctx);
+ 	sg_ip = src->pg->key.addr;
+ 	sg_ip.src = src->addr.src;
+ 
+ 	sg = __br_multicast_add_group(brmctx, pmctx, &sg_ip,
+ 				      src->pg->eth_addr, MCAST_INCLUDE, false,
+ 				      !timer_pending(&src->timer));
+ 	if (IS_ERR_OR_NULL(sg))
+ 		return;
+ 	src->flags |= BR_SGRP_F_INSTALLED;
+ 	sg->flags &= ~MDB_PG_FLAGS_STAR_EXCL;
+ 
+ 	/* if it was added by user-space as perm we can skip next steps */
+ 	if (sg->rt_protocol != RTPROT_KERNEL &&
+ 	    (sg->flags & MDB_PG_FLAGS_PERMANENT))
+ 		return;
+ 
+ 	/* the kernel is now responsible for removing this S,G */
+ 	del_timer(&sg->timer);
+ 	star_mp = br_mdb_ip_get(src->br, &src->pg->key.addr);
+ 	if (!star_mp)
+ 		return;
+ 
+ 	br_multicast_sg_add_exclude_ports(star_mp, sg);
+ }
+ 
+ static void br_multicast_fwd_src_remove(struct net_bridge_group_src *src,
+ 					bool fastleave)
+ {
+ 	struct net_bridge_port_group *p, *pg = src->pg;
+ 	struct net_bridge_port_group __rcu **pp;
+ 	struct net_bridge_mdb_entry *mp;
+ 	struct br_ip sg_ip;
+ 
+ 	memset(&sg_ip, 0, sizeof(sg_ip));
+ 	sg_ip = pg->key.addr;
+ 	sg_ip.src = src->addr.src;
+ 
+ 	mp = br_mdb_ip_get(src->br, &sg_ip);
+ 	if (!mp)
+ 		return;
+ 
+ 	for (pp = &mp->ports;
+ 	     (p = mlock_dereference(*pp, src->br)) != NULL;
+ 	     pp = &p->next) {
+ 		if (!br_port_group_equal(p, pg->key.port, pg->eth_addr))
+ 			continue;
+ 
+ 		if (p->rt_protocol != RTPROT_KERNEL &&
+ 		    (p->flags & MDB_PG_FLAGS_PERMANENT))
+ 			break;
+ 
+ 		if (fastleave)
+ 			p->flags |= MDB_PG_FLAGS_FAST_LEAVE;
+ 		br_multicast_del_pg(mp, p, pp);
+ 		break;
+ 	}
+ 	src->flags &= ~BR_SGRP_F_INSTALLED;
+ }
+ 
+ /* install S,G and based on src's timer enable or disable forwarding */
+ static void br_multicast_fwd_src_handle(struct net_bridge_group_src *src)
+ {
+ 	struct net_bridge_port_group_sg_key sg_key;
+ 	struct net_bridge_port_group *sg;
+ 	u8 old_flags;
+ 
+ 	br_multicast_fwd_src_add(src);
+ 
+ 	memset(&sg_key, 0, sizeof(sg_key));
+ 	sg_key.addr = src->pg->key.addr;
+ 	sg_key.addr.src = src->addr.src;
+ 	sg_key.port = src->pg->key.port;
+ 
+ 	sg = br_sg_port_find(src->br, &sg_key);
+ 	if (!sg || (sg->flags & MDB_PG_FLAGS_PERMANENT))
+ 		return;
+ 
+ 	old_flags = sg->flags;
+ 	if (timer_pending(&src->timer))
+ 		sg->flags &= ~MDB_PG_FLAGS_BLOCKED;
+ 	else
+ 		sg->flags |= MDB_PG_FLAGS_BLOCKED;
+ 
+ 	if (old_flags != sg->flags) {
+ 		struct net_bridge_mdb_entry *sg_mp;
+ 
+ 		sg_mp = br_mdb_ip_get(src->br, &sg_key.addr);
+ 		if (!sg_mp)
+ 			return;
+ 		br_mdb_notify(src->br->dev, sg_mp, sg, RTM_NEWMDB);
+ 	}
+ }
+ 
++>>>>>>> 3f0d14efe2fa (net: bridge: mcast: use the correct vlan group helper)
  static void br_multicast_destroy_mdb_entry(struct net_bridge_mcast_gc *gc)
  {
  	struct net_bridge_mdb_entry *mp;
@@@ -3037,19 -4311,46 +3441,44 @@@ static void br_multicast_start_querier(
  {
  	struct net_bridge_port *port;
  
 -	if (!br_multicast_ctx_matches_vlan_snooping(brmctx))
 -		return;
 -
 -	__br_multicast_open_query(brmctx->br, query);
 +	__br_multicast_open(br, query);
  
  	rcu_read_lock();
 -	list_for_each_entry_rcu(port, &brmctx->br->port_list, list) {
 -		struct bridge_mcast_own_query *ip4_own_query;
 -#if IS_ENABLED(CONFIG_IPV6)
 -		struct bridge_mcast_own_query *ip6_own_query;
 -#endif
 -
 -		if (br_multicast_port_ctx_state_stopped(&port->multicast_ctx))
 +	list_for_each_entry_rcu(port, &br->port_list, list) {
 +		if (port->state == BR_STATE_DISABLED ||
 +		    port->state == BR_STATE_BLOCKING)
  			continue;
  
++<<<<<<< HEAD
 +		if (query == &br->ip4_own_query)
 +			br_multicast_enable(&port->ip4_own_query);
++=======
+ 		if (br_multicast_ctx_is_vlan(brmctx)) {
+ 			struct net_bridge_vlan *vlan;
+ 
+ 			vlan = br_vlan_find(nbp_vlan_group_rcu(port),
+ 					    brmctx->vlan->vid);
+ 			if (!vlan ||
+ 			    br_multicast_port_ctx_state_stopped(&vlan->port_mcast_ctx))
+ 				continue;
+ 
+ 			ip4_own_query = &vlan->port_mcast_ctx.ip4_own_query;
+ #if IS_ENABLED(CONFIG_IPV6)
+ 			ip6_own_query = &vlan->port_mcast_ctx.ip6_own_query;
+ #endif
+ 		} else {
+ 			ip4_own_query = &port->multicast_ctx.ip4_own_query;
+ #if IS_ENABLED(CONFIG_IPV6)
+ 			ip6_own_query = &port->multicast_ctx.ip6_own_query;
+ #endif
+ 		}
+ 
+ 		if (query == &brmctx->ip4_own_query)
+ 			br_multicast_enable(ip4_own_query);
++>>>>>>> 3f0d14efe2fa (net: bridge: mcast: use the correct vlan group helper)
  #if IS_ENABLED(CONFIG_IPV6)
  		else
 -			br_multicast_enable(ip6_own_query);
 +			br_multicast_enable(&port->ip6_own_query);
  #endif
  	}
  	rcu_read_unlock();
* Unmerged path net/bridge/br_multicast.c
