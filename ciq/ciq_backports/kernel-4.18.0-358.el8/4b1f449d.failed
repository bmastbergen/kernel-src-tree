mm, slub: stop disabling irqs around get_partial()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Vlastimil Babka <vbabka@suse.cz>
commit 4b1f449dedd2ff1eede4ced08a503e13c8d668ce
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/4b1f449d.failed

The function get_partial() does not need to have irqs disabled as a whole. It's
sufficient to convert spin_lock operations to their irq saving/restoring
versions.

As a result, it's now possible to reach the page allocator from the slab
allocator without disabling and re-enabling interrupts on the way.

	Signed-off-by: Vlastimil Babka <vbabka@suse.cz>
(cherry picked from commit 4b1f449dedd2ff1eede4ced08a503e13c8d668ce)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/slub.c
diff --cc mm/slub.c
index 18ea2f53cb90,8433e50d2c8e..000000000000
--- a/mm/slub.c
+++ b/mm/slub.c
@@@ -2684,19 -2765,42 +2685,42 @@@ load_freelist
  new_slab:
  
  	if (slub_percpu_partial(c)) {
++<<<<<<< HEAD
++=======
+ 		local_irq_save(flags);
+ 		if (unlikely(c->page)) {
+ 			local_irq_restore(flags);
+ 			goto reread_page;
+ 		}
+ 		if (unlikely(!slub_percpu_partial(c))) {
+ 			local_irq_restore(flags);
+ 			goto new_objects; /* stolen by an IRQ handler */
+ 		}
+ 
++>>>>>>> 4b1f449dedd2 (mm, slub: stop disabling irqs around get_partial())
  		page = c->page = slub_percpu_partial(c);
  		slub_set_percpu_partial(c, page);
 -		local_irq_restore(flags);
  		stat(s, CPU_PARTIAL_ALLOC);
  		goto redo;
  	}
  
++<<<<<<< HEAD
 +	freelist = get_partial(s, gfpflags, node, &page);
 +	if (freelist) {
 +		c->page = page;
 +		goto check_new_page;
 +	}
 +
++=======
+ new_objects:
+ 
+ 	freelist = get_partial(s, gfpflags, node, &page);
+ 	if (freelist)
+ 		goto check_new_page;
+ 
+ 	put_cpu_ptr(s->cpu_slab);
++>>>>>>> 4b1f449dedd2 (mm, slub: stop disabling irqs around get_partial())
  	page = new_slab(s, gfpflags, node);
 -	c = get_cpu_ptr(s->cpu_slab);
  
  	if (unlikely(!page)) {
  		slab_out_of_memory(s, gfpflags, node);
* Unmerged path mm/slub.c
