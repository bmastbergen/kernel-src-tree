KVM: x86/mmu: Remove redundant spte present check in mmu_set_spte

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Mingwei Zhang <mizhang@google.com>
commit 4293ddb788c1a98bdfa6479bcfd63ad5ce0a5ce6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/4293ddb7.failed

Drop an unnecessary is_shadow_present_pte() check when updating the rmaps
after installing a non-MMIO SPTE.  set_spte() is used only to create
shadow-present SPTEs, e.g. MMIO SPTEs are handled early on, mmu_set_spte()
runs with mmu_lock held for write, i.e. the SPTE can't be zapped between
writing the SPTE and updating the rmaps.

Opportunistically combine the "new SPTE" logic for large pages and rmaps.

No functional change intended.

	Suggested-by: Ben Gardon <bgardon@google.com>

	Reviewed-by: David Matlack <dmatlack@google.com>
	Reviewed-by: Ben Gardon <bgardon@google.com>
	Reviewed-by: Sean Christopherson <seanjc@google.com>
	Signed-off-by: Mingwei Zhang <mizhang@google.com>
Message-Id: <20210803044607.599629-2-mizhang@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 4293ddb788c1a98bdfa6479bcfd63ad5ce0a5ce6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu/mmu.c
diff --cc arch/x86/kvm/mmu/mmu.c
index f7b714eeccbb,2f6458bca65d..000000000000
--- a/arch/x86/kvm/mmu/mmu.c
+++ b/arch/x86/kvm/mmu/mmu.c
@@@ -2742,15 -2776,13 +2742,22 @@@ static int mmu_set_spte(struct kvm_vcp
  
  	pgprintk("%s: setting spte %llx\n", __func__, *sptep);
  	trace_kvm_mmu_set_spte(level, gfn, sptep);
- 	if (!was_rmapped && is_large_pte(*sptep))
- 		++vcpu->kvm->stat.lpages;
  
++<<<<<<< HEAD
 +	if (is_shadow_present_pte(*sptep)) {
 +		if (!was_rmapped) {
 +			rmap_count = rmap_add(vcpu, sptep, gfn);
 +			if (rmap_count > RMAP_RECYCLE_THRESHOLD)
 +				rmap_recycle(vcpu, sptep, gfn);
 +		}
++=======
+ 	if (!was_rmapped) {
+ 		if (is_large_pte(*sptep))
+ 			++vcpu->kvm->stat.lpages;
+ 		rmap_count = rmap_add(vcpu, sptep, gfn);
+ 		if (rmap_count > RMAP_RECYCLE_THRESHOLD)
+ 			rmap_recycle(vcpu, sptep, gfn);
++>>>>>>> 4293ddb788c1 (KVM: x86/mmu: Remove redundant spte present check in mmu_set_spte)
  	}
  
  	return ret;
* Unmerged path arch/x86/kvm/mmu/mmu.c
