RDMA/core: Fix incorrect print format specifier

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-358.el8
commit-author Wenpeng Liang <liangwenpeng@huawei.com>
commit 3cea7b4a7d9b3cb8036ca799fe4254a710cd7e40
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-358.el8/3cea7b4a.failed

There are some '%u' for 'int' and '%d' for 'unsigend int', they should be
fixed.

Link: https://lore.kernel.org/r/1623325232-30900-1-git-send-email-liweihang@huawei.com
	Signed-off-by: Wenpeng Liang <liangwenpeng@huawei.com>
	Signed-off-by: Weihang Li <liweihang@huawei.com>
	Signed-off-by: Jason Gunthorpe <jgg@nvidia.com>
(cherry picked from commit 3cea7b4a7d9b3cb8036ca799fe4254a710cd7e40)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/cache.c
#	drivers/infiniband/core/sysfs.c
#	drivers/infiniband/core/umem_odp.c
diff --cc drivers/infiniband/core/cache.c
index a27a159ec5fa,f44a0d4a86e9..000000000000
--- a/drivers/infiniband/core/cache.c
+++ b/drivers/infiniband/core/cache.c
@@@ -237,10 -237,10 +237,14 @@@ static void put_gid_ndev(struct rcu_hea
  static void free_gid_entry_locked(struct ib_gid_table_entry *entry)
  {
  	struct ib_device *device = entry->attr.device;
 -	u32 port_num = entry->attr.port_num;
 +	u8 port_num = entry->attr.port_num;
  	struct ib_gid_table *table = rdma_gid_table(device, port_num);
  
++<<<<<<< HEAD
 +	dev_dbg(&device->dev, "%s port=%d index=%d gid %pI6\n", __func__,
++=======
+ 	dev_dbg(&device->dev, "%s port=%u index=%u gid %pI6\n", __func__,
++>>>>>>> 3cea7b4a7d9b (RDMA/core: Fix incorrect print format specifier)
  		port_num, entry->attr.index, entry->attr.gid.raw);
  
  	write_lock_irq(&table->rwlock);
diff --cc drivers/infiniband/core/sysfs.c
index 1ae9eecb09be,6146c3c1cbe5..000000000000
--- a/drivers/infiniband/core/sysfs.c
+++ b/drivers/infiniband/core/sysfs.c
@@@ -194,11 -259,11 +194,15 @@@ static ssize_t lid_mask_count_show(stru
  	if (ret)
  		return ret;
  
++<<<<<<< HEAD
 +	return sprintf(buf, "%d\n", attr.lmc);
++=======
+ 	return sysfs_emit(buf, "%u\n", attr.lmc);
++>>>>>>> 3cea7b4a7d9b (RDMA/core: Fix incorrect print format specifier)
  }
  
 -static ssize_t sm_lid_show(struct ib_device *ibdev, u32 port_num,
 -			   struct ib_port_attribute *unused, char *buf)
 +static ssize_t sm_lid_show(struct ib_port *p, struct port_attribute *unused,
 +			   char *buf)
  {
  	struct ib_port_attr attr;
  	ssize_t ret;
@@@ -220,11 -285,11 +224,15 @@@ static ssize_t sm_sl_show(struct ib_por
  	if (ret)
  		return ret;
  
++<<<<<<< HEAD
 +	return sprintf(buf, "%d\n", attr.sm_sl);
++=======
+ 	return sysfs_emit(buf, "%u\n", attr.sm_sl);
++>>>>>>> 3cea7b4a7d9b (RDMA/core: Fix incorrect print format specifier)
  }
  
 -static ssize_t cap_mask_show(struct ib_device *ibdev, u32 port_num,
 -			     struct ib_port_attribute *unused, char *buf)
 +static ssize_t cap_mask_show(struct ib_port *p, struct port_attribute *unused,
 +			     char *buf)
  {
  	struct ib_port_attr attr;
  	ssize_t ret;
@@@ -322,43 -387,50 +330,48 @@@ static ssize_t phys_state_show(struct i
  	if (ret)
  		return ret;
  
++<<<<<<< HEAD
 +	return sprintf(buf, "%d: %s\n", attr.phys_state,
 +		       phys_state_to_str(attr.phys_state));
++=======
+ 	return sysfs_emit(buf, "%u: %s\n", attr.phys_state,
+ 			  phys_state_to_str(attr.phys_state));
++>>>>>>> 3cea7b4a7d9b (RDMA/core: Fix incorrect print format specifier)
  }
  
 -static ssize_t link_layer_show(struct ib_device *ibdev, u32 port_num,
 -			       struct ib_port_attribute *unused, char *buf)
 +static ssize_t link_layer_show(struct ib_port *p, struct port_attribute *unused,
 +			       char *buf)
  {
 -	const char *output;
 -
 -	switch (rdma_port_get_link_layer(ibdev, port_num)) {
 +	switch (rdma_port_get_link_layer(p->ibdev, p->port_num)) {
  	case IB_LINK_LAYER_INFINIBAND:
 -		output = "InfiniBand";
 -		break;
 +		return sprintf(buf, "%s\n", "InfiniBand");
  	case IB_LINK_LAYER_ETHERNET:
 -		output = "Ethernet";
 -		break;
 +		return sprintf(buf, "%s\n", "Ethernet");
  	default:
 -		output = "Unknown";
 -		break;
 +		return sprintf(buf, "%s\n", "Unknown");
  	}
 -
 -	return sysfs_emit(buf, "%s\n", output);
  }
  
 -static IB_PORT_ATTR_RO(state);
 -static IB_PORT_ATTR_RO(lid);
 -static IB_PORT_ATTR_RO(lid_mask_count);
 -static IB_PORT_ATTR_RO(sm_lid);
 -static IB_PORT_ATTR_RO(sm_sl);
 -static IB_PORT_ATTR_RO(cap_mask);
 -static IB_PORT_ATTR_RO(rate);
 -static IB_PORT_ATTR_RO(phys_state);
 -static IB_PORT_ATTR_RO(link_layer);
 +static PORT_ATTR_RO(state);
 +static PORT_ATTR_RO(lid);
 +static PORT_ATTR_RO(lid_mask_count);
 +static PORT_ATTR_RO(sm_lid);
 +static PORT_ATTR_RO(sm_sl);
 +static PORT_ATTR_RO(cap_mask);
 +static PORT_ATTR_RO(rate);
 +static PORT_ATTR_RO(phys_state);
 +static PORT_ATTR_RO(link_layer);
  
  static struct attribute *port_default_attrs[] = {
 -	&ib_port_attr_state.attr,
 -	&ib_port_attr_lid.attr,
 -	&ib_port_attr_lid_mask_count.attr,
 -	&ib_port_attr_sm_lid.attr,
 -	&ib_port_attr_sm_sl.attr,
 -	&ib_port_attr_cap_mask.attr,
 -	&ib_port_attr_rate.attr,
 -	&ib_port_attr_phys_state.attr,
 -	&ib_port_attr_link_layer.attr,
 +	&port_attr_state.attr,
 +	&port_attr_lid.attr,
 +	&port_attr_lid_mask_count.attr,
 +	&port_attr_sm_lid.attr,
 +	&port_attr_sm_sl.attr,
 +	&port_attr_cap_mask.attr,
 +	&port_attr_rate.attr,
 +	&port_attr_phys_state.attr,
 +	&port_attr_link_layer.attr,
  	NULL
  };
  
@@@ -535,30 -612,27 +548,35 @@@ static ssize_t show_pma_counter(struct 
  
  	switch (width) {
  	case 4:
++<<<<<<< HEAD
 +		ret = sprintf(buf, "%u\n", (*data >>
 +					    (4 - (offset % 8))) & 0xf);
++=======
+ 		len = sysfs_emit(buf, "%d\n",
+ 				 (*data >> (4 - (offset % 8))) & 0xf);
++>>>>>>> 3cea7b4a7d9b (RDMA/core: Fix incorrect print format specifier)
  		break;
  	case 8:
 -		len = sysfs_emit(buf, "%u\n", *data);
 +		ret = sprintf(buf, "%u\n", *data);
  		break;
  	case 16:
 -		len = sysfs_emit(buf, "%u\n", be16_to_cpup((__be16 *)data));
 +		ret = sprintf(buf, "%u\n",
 +			      be16_to_cpup((__be16 *)data));
  		break;
  	case 32:
 -		len = sysfs_emit(buf, "%u\n", be32_to_cpup((__be32 *)data));
 +		ret = sprintf(buf, "%u\n",
 +			      be32_to_cpup((__be32 *)data));
  		break;
  	case 64:
 -		len = sysfs_emit(buf, "%llu\n", be64_to_cpup((__be64 *)data));
 +		ret = sprintf(buf, "%llu\n",
 +				be64_to_cpup((__be64 *)data));
  		break;
 +
  	default:
 -		len = 0;
 -		break;
 +		ret = 0;
  	}
  
 -	return len;
 +	return ret;
  }
  
  static PORT_PMA_ATTR(symbol_error		    ,  0, 16,  32);
@@@ -1238,16 -1298,8 +1256,21 @@@ static ssize_t node_type_show(struct de
  {
  	struct ib_device *dev = rdma_device_to_ibdev(device);
  
++<<<<<<< HEAD
 +	switch (dev->node_type) {
 +	case RDMA_NODE_IB_CA:	  return sprintf(buf, "%d: CA\n", dev->node_type);
 +	case RDMA_NODE_RNIC:	  return sprintf(buf, "%d: RNIC\n", dev->node_type);
 +	case RDMA_NODE_USNIC:	  return sprintf(buf, "%d: usNIC\n", dev->node_type);
 +	case RDMA_NODE_USNIC_UDP: return sprintf(buf, "%d: usNIC UDP\n", dev->node_type);
 +	case RDMA_NODE_UNSPECIFIED: return sprintf(buf, "%d: unspecified\n", dev->node_type);
 +	case RDMA_NODE_IB_SWITCH: return sprintf(buf, "%d: switch\n", dev->node_type);
 +	case RDMA_NODE_IB_ROUTER: return sprintf(buf, "%d: router\n", dev->node_type);
 +	default:		  return sprintf(buf, "%d: <unknown>\n", dev->node_type);
 +	}
++=======
+ 	return sysfs_emit(buf, "%u: %s\n", dev->node_type,
+ 			  node_type_string(dev->node_type));
++>>>>>>> 3cea7b4a7d9b (RDMA/core: Fix incorrect print format specifier)
  }
  static DEVICE_ATTR_RO(node_type);
  
diff --cc drivers/infiniband/core/umem_odp.c
index 8a77fe583fed,9462dbe66014..000000000000
--- a/drivers/infiniband/core/umem_odp.c
+++ b/drivers/infiniband/core/umem_odp.c
@@@ -672,76 -381,81 +672,90 @@@ int ib_umem_odp_map_dma_pages(struct ib
  		goto out_put_task;
  	}
  
 -	range.notifier = &umem_odp->notifier;
 -	range.start = ALIGN_DOWN(user_virt, 1UL << page_shift);
 -	range.end = ALIGN(user_virt + bcnt, 1UL << page_shift);
 -	pfn_start_idx = (range.start - ib_umem_start(umem_odp)) >> PAGE_SHIFT;
 -	num_pfns = (range.end - range.start) >> PAGE_SHIFT;
 -	if (fault) {
 -		range.default_flags = HMM_PFN_REQ_FAULT;
 -
 -		if (access_mask & ODP_WRITE_ALLOWED_BIT)
 -			range.default_flags |= HMM_PFN_REQ_WRITE;
 -	}
 -
 -	range.hmm_pfns = &(umem_odp->pfn_list[pfn_start_idx]);
 -	timeout = jiffies + msecs_to_jiffies(HMM_RANGE_DEFAULT_TIMEOUT);
 +	if (access_mask & ODP_WRITE_ALLOWED_BIT)
 +		flags |= FOLL_WRITE;
  
 -retry:
 -	current_seq = range.notifier_seq =
 -		mmu_interval_read_begin(&umem_odp->notifier);
 +	start_idx = (user_virt - ib_umem_start(umem_odp)) >> page_shift;
 +	k = start_idx;
  
 -	mmap_read_lock(owning_mm);
 -	ret = hmm_range_fault(&range);
 -	mmap_read_unlock(owning_mm);
 -	if (unlikely(ret)) {
 -		if (ret == -EBUSY && !time_after(jiffies, timeout))
 -			goto retry;
 -		goto out_put_mm;
 -	}
 +	while (bcnt > 0) {
 +		const size_t gup_num_pages = min_t(size_t,
 +				ALIGN(bcnt, PAGE_SIZE) / PAGE_SIZE,
 +				PAGE_SIZE / sizeof(struct page *));
  
 -	start_idx = (range.start - ib_umem_start(umem_odp)) >> page_shift;
 -	dma_index = start_idx;
 -
 -	mutex_lock(&umem_odp->umem_mutex);
 -	if (mmu_interval_read_retry(&umem_odp->notifier, current_seq)) {
 -		mutex_unlock(&umem_odp->umem_mutex);
 -		goto retry;
 -	}
 -
 -	for (pfn_index = 0; pfn_index < num_pfns;
 -		pfn_index += 1 << (page_shift - PAGE_SHIFT), dma_index++) {
 +		mmap_read_lock(owning_mm);
 +		/*
 +		 * Note: this might result in redundent page getting. We can
 +		 * avoid this by checking dma_list to be 0 before calling
 +		 * get_user_pages. However, this make the code much more
 +		 * complex (and doesn't gain us much performance in most use
 +		 * cases).
 +		 */
 +		npages = get_user_pages_remote(owning_process, owning_mm,
 +				user_virt, gup_num_pages,
 +				flags, local_page_list, NULL, NULL);
 +		mmap_read_unlock(owning_mm);
 +
 +		if (npages < 0) {
 +			if (npages != -EAGAIN)
 +				pr_warn("fail to get %zu user pages with error %d\n", gup_num_pages, npages);
 +			else
 +				pr_debug("fail to get %zu user pages with error %d\n", gup_num_pages, npages);
 +			break;
 +		}
  
 -		if (fault) {
 -			/*
 -			 * Since we asked for hmm_range_fault() to populate
 -			 * pages it shouldn't return an error entry on success.
 -			 */
 -			WARN_ON(range.hmm_pfns[pfn_index] & HMM_PFN_ERROR);
 -			WARN_ON(!(range.hmm_pfns[pfn_index] & HMM_PFN_VALID));
 -		} else {
 -			if (!(range.hmm_pfns[pfn_index] & HMM_PFN_VALID)) {
 -				WARN_ON(umem_odp->dma_list[dma_index]);
 +		bcnt -= min_t(size_t, npages << PAGE_SHIFT, bcnt);
 +		mutex_lock(&umem_odp->umem_mutex);
 +		for (j = 0; j < npages; j++, user_virt += PAGE_SIZE) {
 +			if (user_virt & ~page_mask) {
 +				p += PAGE_SIZE;
 +				if (page_to_phys(local_page_list[j]) != p) {
 +					ret = -EFAULT;
 +					break;
 +				}
 +				put_page(local_page_list[j]);
  				continue;
  			}
 -			access_mask = ODP_READ_ALLOWED_BIT;
 -			if (range.hmm_pfns[pfn_index] & HMM_PFN_WRITE)
 -				access_mask |= ODP_WRITE_ALLOWED_BIT;
 -		}
  
++<<<<<<< HEAD
 +			ret = ib_umem_odp_map_dma_single_page(
 +					umem_odp, k, local_page_list[j],
 +					access_mask, current_seq);
 +			if (ret < 0) {
 +				if (ret != -EAGAIN)
 +					pr_warn("ib_umem_odp_map_dma_single_page failed with error %d\n", ret);
 +				else
 +					pr_debug("ib_umem_odp_map_dma_single_page failed with error %d\n", ret);
 +				break;
 +			}
 +
 +			p = page_to_phys(local_page_list[j]);
 +			k++;
 +		}
 +		mutex_unlock(&umem_odp->umem_mutex);
++=======
+ 		hmm_order = hmm_pfn_to_map_order(range.hmm_pfns[pfn_index]);
+ 		/* If a hugepage was detected and ODP wasn't set for, the umem
+ 		 * page_shift will be used, the opposite case is an error.
+ 		 */
+ 		if (hmm_order + PAGE_SHIFT < page_shift) {
+ 			ret = -EINVAL;
+ 			ibdev_dbg(umem_odp->umem.ibdev,
+ 				  "%s: un-expected hmm_order %u, page_shift %u\n",
+ 				  __func__, hmm_order, page_shift);
+ 			break;
+ 		}
++>>>>>>> 3cea7b4a7d9b (RDMA/core: Fix incorrect print format specifier)
  
 -		ret = ib_umem_odp_map_dma_single_page(
 -				umem_odp, dma_index, hmm_pfn_to_page(range.hmm_pfns[pfn_index]),
 -				access_mask);
  		if (ret < 0) {
 -			ibdev_dbg(umem_odp->umem.ibdev,
 -				  "ib_umem_odp_map_dma_single_page failed with error %d\n", ret);
 +			/*
 +			 * Release pages, remembering that the first page
 +			 * to hit an error was already released by
 +			 * ib_umem_odp_map_dma_single_page().
 +			 */
 +			if (npages - (j + 1) > 0)
 +				release_pages(&local_page_list[j+1],
 +					      npages - (j + 1));
  			break;
  		}
  	}
* Unmerged path drivers/infiniband/core/cache.c
diff --git a/drivers/infiniband/core/cm.c b/drivers/infiniband/core/cm.c
index 98486d3832e9..0a20a870273b 100644
--- a/drivers/infiniband/core/cm.c
+++ b/drivers/infiniband/core/cm.c
@@ -1794,7 +1794,7 @@ static u16 cm_get_bth_pkey(struct cm_work *work)
 
 	ret = ib_get_cached_pkey(ib_dev, port_num, pkey_index, &pkey);
 	if (ret) {
-		dev_warn_ratelimited(&ib_dev->dev, "ib_cm: Couldn't retrieve pkey for incoming request (port %d, pkey index %d). %d\n",
+		dev_warn_ratelimited(&ib_dev->dev, "ib_cm: Couldn't retrieve pkey for incoming request (port %u, pkey index %u). %d\n",
 				     port_num, pkey_index, ret);
 		return 0;
 	}
diff --git a/drivers/infiniband/core/iwpm_msg.c b/drivers/infiniband/core/iwpm_msg.c
index 932b26f50d03..12a9816fc0e2 100644
--- a/drivers/infiniband/core/iwpm_msg.c
+++ b/drivers/infiniband/core/iwpm_msg.c
@@ -123,7 +123,7 @@ int iwpm_register_pid(struct iwpm_dev_data *pm_msg, u8 nl_client)
 	ret = iwpm_wait_complete_req(nlmsg_request);
 	return ret;
 pid_query_error:
-	pr_info("%s: %s (client = %d)\n", __func__, err_str, nl_client);
+	pr_info("%s: %s (client = %u)\n", __func__, err_str, nl_client);
 	dev_kfree_skb(skb);
 	if (nlmsg_request)
 		iwpm_free_nlmsg_request(&nlmsg_request->kref);
@@ -211,7 +211,7 @@ int iwpm_add_mapping(struct iwpm_sa_data *pm_msg, u8 nl_client)
 	ret = iwpm_wait_complete_req(nlmsg_request);
 	return ret;
 add_mapping_error:
-	pr_info("%s: %s (client = %d)\n", __func__, err_str, nl_client);
+	pr_info("%s: %s (client = %u)\n", __func__, err_str, nl_client);
 add_mapping_error_nowarn:
 	dev_kfree_skb(skb);
 	if (nlmsg_request)
@@ -304,7 +304,7 @@ int iwpm_add_and_query_mapping(struct iwpm_sa_data *pm_msg, u8 nl_client)
 	ret = iwpm_wait_complete_req(nlmsg_request);
 	return ret;
 query_mapping_error:
-	pr_info("%s: %s (client = %d)\n", __func__, err_str, nl_client);
+	pr_info("%s: %s (client = %u)\n", __func__, err_str, nl_client);
 query_mapping_error_nowarn:
 	dev_kfree_skb(skb);
 	if (nlmsg_request)
@@ -372,7 +372,7 @@ int iwpm_remove_mapping(struct sockaddr_storage *local_addr, u8 nl_client)
 			"remove_mapping: Local sockaddr:");
 	return 0;
 remove_mapping_error:
-	pr_info("%s: %s (client = %d)\n", __func__, err_str, nl_client);
+	pr_info("%s: %s (client = %u)\n", __func__, err_str, nl_client);
 	if (skb)
 		dev_kfree_skb_any(skb);
 	return ret;
@@ -431,7 +431,7 @@ int iwpm_register_pid_cb(struct sk_buff *skb, struct netlink_callback *cb)
 			strcmp(iwpm_ulib_name, iwpm_name) ||
 			iwpm_version < IWPM_UABI_VERSION_MIN) {
 
-		pr_info("%s: Incorrect info (dev = %s name = %s version = %d)\n",
+		pr_info("%s: Incorrect info (dev = %s name = %s version = %u)\n",
 				__func__, dev_name, iwpm_name, iwpm_version);
 		nlmsg_request->err_code = IWPM_USER_LIB_INFO_ERR;
 		goto register_pid_response_exit;
@@ -439,7 +439,7 @@ int iwpm_register_pid_cb(struct sk_buff *skb, struct netlink_callback *cb)
 	iwpm_user_pid = cb->nlh->nlmsg_pid;
 	iwpm_ulib_version = iwpm_version;
 	if (iwpm_ulib_version < IWPM_UABI_VERSION)
-		pr_warn_once("%s: Down level iwpmd/pid %u.  Continuing...",
+		pr_warn_once("%s: Down level iwpmd/pid %d.  Continuing...",
 			__func__, iwpm_user_pid);
 	atomic_set(&echo_nlmsg_seq, cb->nlh->nlmsg_seq);
 	pr_debug("%s: iWarp Port Mapper (pid = %d) is available!\n",
@@ -650,7 +650,7 @@ int iwpm_remote_info_cb(struct sk_buff *skb, struct netlink_callback *cb)
 
 	nl_client = RDMA_NL_GET_CLIENT(cb->nlh->nlmsg_type);
 	if (!iwpm_valid_client(nl_client)) {
-		pr_info("%s: Invalid port mapper client = %d\n",
+		pr_info("%s: Invalid port mapper client = %u\n",
 				__func__, nl_client);
 		return ret;
 	}
@@ -731,13 +731,13 @@ int iwpm_mapping_info_cb(struct sk_buff *skb, struct netlink_callback *cb)
 	iwpm_version = nla_get_u16(nltb[IWPM_NLA_MAPINFO_ULIB_VER]);
 	if (strcmp(iwpm_ulib_name, iwpm_name) ||
 			iwpm_version < IWPM_UABI_VERSION_MIN) {
-		pr_info("%s: Invalid port mapper name = %s version = %d\n",
+		pr_info("%s: Invalid port mapper name = %s version = %u\n",
 				__func__, iwpm_name, iwpm_version);
 		return ret;
 	}
 	nl_client = RDMA_NL_GET_CLIENT(cb->nlh->nlmsg_type);
 	if (!iwpm_valid_client(nl_client)) {
-		pr_info("%s: Invalid port mapper client = %d\n",
+		pr_info("%s: Invalid port mapper client = %u\n",
 				__func__, nl_client);
 		return ret;
 	}
@@ -746,7 +746,7 @@ int iwpm_mapping_info_cb(struct sk_buff *skb, struct netlink_callback *cb)
 	iwpm_user_pid = cb->nlh->nlmsg_pid;
 
 	if (iwpm_ulib_version < IWPM_UABI_VERSION)
-		pr_warn_once("%s: Down level iwpmd/pid %u.  Continuing...",
+		pr_warn_once("%s: Down level iwpmd/pid %d.  Continuing...",
 			__func__, iwpm_user_pid);
 
 	if (!iwpm_mapinfo_available())
@@ -864,7 +864,7 @@ int iwpm_hello_cb(struct sk_buff *skb, struct netlink_callback *cb)
 	abi_version = nla_get_u16(nltb[IWPM_NLA_HELLO_ABI_VERSION]);
 	nl_client = RDMA_NL_GET_CLIENT(cb->nlh->nlmsg_type);
 	if (!iwpm_valid_client(nl_client)) {
-		pr_info("%s: Invalid port mapper client = %d\n",
+		pr_info("%s: Invalid port mapper client = %u\n",
 				__func__, nl_client);
 		return ret;
 	}
diff --git a/drivers/infiniband/core/iwpm_util.c b/drivers/infiniband/core/iwpm_util.c
index b8f40e698ba1..3f8c019c7260 100644
--- a/drivers/infiniband/core/iwpm_util.c
+++ b/drivers/infiniband/core/iwpm_util.c
@@ -307,7 +307,7 @@ int iwpm_get_remote_info(struct sockaddr_storage *mapped_loc_addr,
 	int ret = -EINVAL;
 
 	if (!iwpm_valid_client(nl_client)) {
-		pr_info("%s: Invalid client = %d\n", __func__, nl_client);
+		pr_info("%s: Invalid client = %u\n", __func__, nl_client);
 		return ret;
 	}
 	spin_lock_irqsave(&iwpm_reminfo_lock, flags);
@@ -655,7 +655,7 @@ static int send_mapinfo_num(u32 mapping_num, u8 nl_client, int iwpm_pid)
 		err_str = "Unable to send a nlmsg";
 		goto mapinfo_num_error;
 	}
-	pr_debug("%s: Sent mapping number = %d\n", __func__, mapping_num);
+	pr_debug("%s: Sent mapping number = %u\n", __func__, mapping_num);
 	return 0;
 mapinfo_num_error:
 	pr_info("%s: %s\n", __func__, err_str);
diff --git a/drivers/infiniband/core/mad.c b/drivers/infiniband/core/mad.c
index 5fd4e0688d83..9310ba3679b3 100644
--- a/drivers/infiniband/core/mad.c
+++ b/drivers/infiniband/core/mad.c
@@ -351,7 +351,7 @@ struct ib_mad_agent *ib_register_mad_agent(struct ib_device *device,
 	/* Validate device and port */
 	port_priv = ib_get_mad_port(device, port_num);
 	if (!port_priv) {
-		dev_dbg_ratelimited(&device->dev, "%s: Invalid port %d\n",
+		dev_dbg_ratelimited(&device->dev, "%s: Invalid port %u\n",
 				    __func__, port_num);
 		ret = ERR_PTR(-ENODEV);
 		goto error1;
@@ -1626,7 +1626,7 @@ static int validate_mad(const struct ib_mad_hdr *mad_hdr,
 	/* Make sure MAD base version is understood */
 	if (mad_hdr->base_version != IB_MGMT_BASE_VERSION &&
 	    (!opa || mad_hdr->base_version != OPA_MGMT_BASE_VERSION)) {
-		pr_err("MAD received with unsupported base version %d %s\n",
+		pr_err("MAD received with unsupported base version %u %s\n",
 		       mad_hdr->base_version, opa ? "(opa)" : "");
 		goto out;
 	}
@@ -2867,7 +2867,7 @@ static void qp_event_handler(struct ib_event *event, void *qp_context)
 
 	/* It's worse than that! He's dead, Jim! */
 	dev_err(&qp_info->port_priv->device->dev,
-		"Fatal error (%d) on MAD QP (%d)\n",
+		"Fatal error (%d) on MAD QP (%u)\n",
 		event->event, qp_info->qp->qp_num);
 }
 
@@ -3125,9 +3125,9 @@ static void ib_mad_remove_device(struct ib_device *device, void *client_data)
 
 		if (ib_agent_port_close(device, i))
 			dev_err(&device->dev,
-				"Couldn't close port %d for agents\n", i);
+				"Couldn't close port %u for agents\n", i);
 		if (ib_mad_port_close(device, i))
-			dev_err(&device->dev, "Couldn't close port %d\n", i);
+			dev_err(&device->dev, "Couldn't close port %u\n", i);
 	}
 }
 
diff --git a/drivers/infiniband/core/netlink.c b/drivers/infiniband/core/netlink.c
index 8cd31ef25eff..1b2cc9e45ade 100644
--- a/drivers/infiniband/core/netlink.c
+++ b/drivers/infiniband/core/netlink.c
@@ -98,7 +98,7 @@ get_cb_table(const struct sk_buff *skb, unsigned int type, unsigned int op)
 		 */
 		up_read(&rdma_nl_types[type].sem);
 
-		request_module("rdma-netlink-subsys-%d", type);
+		request_module("rdma-netlink-subsys-%u", type);
 
 		down_read(&rdma_nl_types[type].sem);
 		cb_table = READ_ONCE(rdma_nl_types[type].cb_table);
diff --git a/drivers/infiniband/core/rw.c b/drivers/infiniband/core/rw.c
index 31156e22d3e7..2521a465bb95 100644
--- a/drivers/infiniband/core/rw.c
+++ b/drivers/infiniband/core/rw.c
@@ -389,7 +389,7 @@ int rdma_rw_ctx_signature_init(struct rdma_rw_ctx *ctx, struct ib_qp *qp,
 	int count = 0, ret;
 
 	if (sg_cnt > pages_per_mr || prot_sg_cnt > pages_per_mr) {
-		pr_err("SG count too large: sg_cnt=%d, prot_sg_cnt=%d, pages_per_mr=%d\n",
+		pr_err("SG count too large: sg_cnt=%u, prot_sg_cnt=%u, pages_per_mr=%u\n",
 		       sg_cnt, prot_sg_cnt, pages_per_mr);
 		return -EINVAL;
 	}
@@ -429,7 +429,7 @@ int rdma_rw_ctx_signature_init(struct rdma_rw_ctx *ctx, struct ib_qp *qp,
 	ret = ib_map_mr_sg_pi(ctx->reg->mr, sg, sg_cnt, NULL, prot_sg,
 			      prot_sg_cnt, NULL, SZ_4K);
 	if (unlikely(ret)) {
-		pr_err("failed to map PI sg (%d)\n", sg_cnt + prot_sg_cnt);
+		pr_err("failed to map PI sg (%u)\n", sg_cnt + prot_sg_cnt);
 		goto out_destroy_sig_mr;
 	}
 
@@ -713,7 +713,7 @@ int rdma_rw_init_mrs(struct ib_qp *qp, struct ib_qp_init_attr *attr)
 				IB_MR_TYPE_MEM_REG,
 				max_num_sg, 0);
 		if (ret) {
-			pr_err("%s: failed to allocated %d MRs\n",
+			pr_err("%s: failed to allocated %u MRs\n",
 				__func__, nr_mrs);
 			return ret;
 		}
@@ -723,7 +723,7 @@ int rdma_rw_init_mrs(struct ib_qp *qp, struct ib_qp_init_attr *attr)
 		ret = ib_mr_pool_init(qp, &qp->sig_mrs, nr_sig_mrs,
 				IB_MR_TYPE_INTEGRITY, max_num_sg, max_num_sg);
 		if (ret) {
-			pr_err("%s: failed to allocated %d SIG MRs\n",
+			pr_err("%s: failed to allocated %u SIG MRs\n",
 				__func__, nr_sig_mrs);
 			goto out_free_rdma_mrs;
 		}
diff --git a/drivers/infiniband/core/security.c b/drivers/infiniband/core/security.c
index 75e7ec017836..9f9512b782d3 100644
--- a/drivers/infiniband/core/security.c
+++ b/drivers/infiniband/core/security.c
@@ -586,7 +586,7 @@ int ib_security_modify_qp(struct ib_qp *qp,
 	WARN_ONCE((qp_attr_mask & IB_QP_PORT &&
 		   rdma_protocol_ib(real_qp->device, qp_attr->port_num) &&
 		   !real_qp->qp_sec),
-		   "%s: QP security is not initialized for IB QP: %d\n",
+		   "%s: QP security is not initialized for IB QP: %u\n",
 		   __func__, real_qp->qp_num);
 
 	/* The port/pkey settings are maintained only for the real QP. Open
* Unmerged path drivers/infiniband/core/sysfs.c
diff --git a/drivers/infiniband/core/ud_header.c b/drivers/infiniband/core/ud_header.c
index d65d541b9a25..64d9c492de64 100644
--- a/drivers/infiniband/core/ud_header.c
+++ b/drivers/infiniband/core/ud_header.c
@@ -479,7 +479,7 @@ int ib_ud_header_unpack(void                *buf,
 	buf += IB_LRH_BYTES;
 
 	if (header->lrh.link_version != 0) {
-		pr_warn("Invalid LRH.link_version %d\n",
+		pr_warn("Invalid LRH.link_version %u\n",
 			header->lrh.link_version);
 		return -EINVAL;
 	}
@@ -496,7 +496,7 @@ int ib_ud_header_unpack(void                *buf,
 		buf += IB_GRH_BYTES;
 
 		if (header->grh.ip_version != 6) {
-			pr_warn("Invalid GRH.ip_version %d\n",
+			pr_warn("Invalid GRH.ip_version %u\n",
 				header->grh.ip_version);
 			return -EINVAL;
 		}
@@ -508,7 +508,7 @@ int ib_ud_header_unpack(void                *buf,
 		break;
 
 	default:
-		pr_warn("Invalid LRH.link_next_header %d\n",
+		pr_warn("Invalid LRH.link_next_header %u\n",
 			header->lrh.link_next_header);
 		return -EINVAL;
 	}
@@ -530,7 +530,7 @@ int ib_ud_header_unpack(void                *buf,
 	}
 
 	if (header->bth.transport_header_version != 0) {
-		pr_warn("Invalid BTH.transport_header_version %d\n",
+		pr_warn("Invalid BTH.transport_header_version %u\n",
 			header->bth.transport_header_version);
 		return -EINVAL;
 	}
* Unmerged path drivers/infiniband/core/umem_odp.c
diff --git a/drivers/infiniband/core/user_mad.c b/drivers/infiniband/core/user_mad.c
index 5945abcaf0a1..40f9848b3d21 100644
--- a/drivers/infiniband/core/user_mad.c
+++ b/drivers/infiniband/core/user_mad.c
@@ -700,7 +700,7 @@ static int ib_umad_reg_agent(struct ib_umad_file *file, void __user *arg,
 
 	if (ureq.qpn != 0 && ureq.qpn != 1) {
 		dev_notice(&file->port->dev,
-			   "%s: invalid QPN %d specified\n", __func__,
+			   "%s: invalid QPN %u specified\n", __func__,
 			   ureq.qpn);
 		ret = -EINVAL;
 		goto out;
@@ -800,7 +800,7 @@ static int ib_umad_reg_agent2(struct ib_umad_file *file, void __user *arg)
 	}
 
 	if (ureq.qpn != 0 && ureq.qpn != 1) {
-		dev_notice(&file->port->dev, "%s: invalid QPN %d specified\n",
+		dev_notice(&file->port->dev, "%s: invalid QPN %u specified\n",
 			   __func__, ureq.qpn);
 		ret = -EINVAL;
 		goto out;
diff --git a/drivers/infiniband/core/uverbs_cmd.c b/drivers/infiniband/core/uverbs_cmd.c
index 2aa1ed15d68e..c45e5aa67532 100644
--- a/drivers/infiniband/core/uverbs_cmd.c
+++ b/drivers/infiniband/core/uverbs_cmd.c
@@ -3321,7 +3321,7 @@ static int ib_uverbs_ex_create_flow(struct uverbs_attr_bundle *attrs)
 		ib_spec += ((union ib_flow_spec *) ib_spec)->size;
 	}
 	if (cmd.flow_attr.size || (i != flow_attr->num_of_specs)) {
-		pr_warn("create flow failed, flow %d: %d bytes left from uverb cmd\n",
+		pr_warn("create flow failed, flow %d: %u bytes left from uverb cmd\n",
 			i, cmd.flow_attr.size);
 		err = -EINVAL;
 		goto err_free;
diff --git a/drivers/infiniband/core/uverbs_uapi.c b/drivers/infiniband/core/uverbs_uapi.c
index 62f5bcb712cf..2f2c7646fce1 100644
--- a/drivers/infiniband/core/uverbs_uapi.c
+++ b/drivers/infiniband/core/uverbs_uapi.c
@@ -517,7 +517,7 @@ static void uapi_key_okay(u32 key)
 		count++;
 	if (uapi_key_is_attr(key))
 		count++;
-	WARN(count != 1, "Bad count %d key=%x", count, key);
+	WARN(count != 1, "Bad count %u key=%x", count, key);
 }
 
 static void uapi_finalize_disable(struct uverbs_api *uapi)
diff --git a/drivers/infiniband/core/verbs.c b/drivers/infiniband/core/verbs.c
index 518e734308ff..e63e98ae4e49 100644
--- a/drivers/infiniband/core/verbs.c
+++ b/drivers/infiniband/core/verbs.c
@@ -1833,7 +1833,7 @@ int ib_get_eth_speed(struct ib_device *dev, u8 port_num, u16 *speed, u8 *width)
 		netdev_speed = lksettings.base.speed;
 	} else {
 		netdev_speed = SPEED_1000;
-		pr_warn("%s speed is unknown, defaulting to %d\n", netdev->name,
+		pr_warn("%s speed is unknown, defaulting to %u\n", netdev->name,
 			netdev_speed);
 	}
 
