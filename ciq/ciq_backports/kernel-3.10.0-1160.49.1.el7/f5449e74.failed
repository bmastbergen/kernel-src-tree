RDMA/ucma: Rework ucma_migrate_id() to avoid races with destroy

jira LE-1907
cve CVE-2020-36385
Rebuild_History Non-Buildable kernel-3.10.0-1160.49.1.el7
commit-author Jason Gunthorpe <jgg@nvidia.com>
commit f5449e74802c1112dea984aec8af7a33c4516af1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.49.1.el7/f5449e74.failed

ucma_destroy_id() assumes that all things accessing the ctx will do so via
the xarray. This assumption violated only in the case the FD is being
closed, then the ctx is reached via the ctx_list. Normally this is OK
since ucma_destroy_id() cannot run concurrenty with release(), however
with ucma_migrate_id() is involved this can violated as the close of the
2nd FD can run concurrently with destroy on the first:

                CPU0                      CPU1
        ucma_destroy_id(fda)
                                  ucma_migrate_id(fda -> fdb)
                                       ucma_get_ctx()
        xa_lock()
         _ucma_find_context()
         xa_erase()
        xa_unlock()
                                       xa_lock()
                                        ctx->file = new_file
                                        list_move()
                                       xa_unlock()
                                      ucma_put_ctx()

                                   ucma_close(fdb)
                                      _destroy_id()
                                      kfree(ctx)

        _destroy_id()
          wait_for_completion()
          // boom, ctx was freed

The ctx->file must be modified under the handler and xa_lock, and prior to
modification the ID must be rechecked that it is still reachable from
cur_file, ie there is no parallel destroy or migrate.

To make this work remove the double locking and streamline the control
flow. The double locking was obsoleted by the handler lock now directly
preventing new uevents from being created, and the ctx_list cannot be read
while holding fgets on both files. Removing the double locking also
removes the need to check for the same file.

Fixes: 88314e4dda1e ("RDMA/cma: add support for rdma_migrate_id()")
Link: https://lore.kernel.org/r/0-v1-05c5a4090305+3a872-ucma_syz_migrate_jgg@nvidia.com
Reported-and-tested-by: syzbot+cc6fc752b3819e082d0c@syzkaller.appspotmail.com
	Signed-off-by: Jason Gunthorpe <jgg@nvidia.com>
(cherry picked from commit f5449e74802c1112dea984aec8af7a33c4516af1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/ucma.c
diff --cc drivers/infiniband/core/ucma.c
index 0a074233033d,b3a7dbb12f25..000000000000
--- a/drivers/infiniband/core/ucma.c
+++ b/drivers/infiniband/core/ucma.c
@@@ -1644,34 -1620,44 +1615,71 @@@ static ssize_t ucma_migrate_id(struct u
  		goto file_put;
  	}
  
++<<<<<<< HEAD
 +	cur_file = ctx->file;
 +	if (cur_file == new_file) {
 +		mutex_lock(&cur_file->mut);
 +		resp.events_reported = ctx->events_reported;
 +		mutex_unlock(&cur_file->mut);
 +		goto response;
 +	}
 +
++=======
+ 	rdma_lock_handler(ctx->cm_id);
++>>>>>>> f5449e74802c (RDMA/ucma: Rework ucma_migrate_id() to avoid races with destroy)
  	/*
- 	 * Migrate events between fd's, maintaining order, and avoiding new
- 	 * events being added before existing events.
+ 	 * ctx->file can only be changed under the handler & xa_lock. xa_load()
+ 	 * must be checked again to ensure the ctx hasn't begun destruction
+ 	 * since the ucma_get_ctx().
  	 */
++<<<<<<< HEAD
 +	ucma_lock_files(cur_file, new_file);
 +	mutex_lock(&mut);
 +
 +	list_move_tail(&ctx->list, &new_file->ctx_list);
 +	ucma_move_events(ctx, new_file);
 +	ctx->file = new_file;
 +	resp.events_reported = ctx->events_reported;
 +
 +	mutex_unlock(&mut);
 +	ucma_unlock_files(cur_file, new_file);
++=======
+ 	xa_lock(&ctx_table);
+ 	if (_ucma_find_context(cmd.id, cur_file) != ctx) {
+ 		xa_unlock(&ctx_table);
+ 		ret = -ENOENT;
+ 		goto err_unlock;
+ 	}
+ 	ctx->file = new_file;
+ 	xa_unlock(&ctx_table);
++>>>>>>> f5449e74802c (RDMA/ucma: Rework ucma_migrate_id() to avoid races with destroy)
+ 
+ 	mutex_lock(&cur_file->mut);
+ 	list_del(&ctx->list);
+ 	/*
+ 	 * At this point lock_handler() prevents addition of new uevents for
+ 	 * this ctx.
+ 	 */
+ 	list_for_each_entry_safe(uevent, tmp, &cur_file->event_list, list)
+ 		if (uevent->ctx == ctx)
+ 			list_move_tail(&uevent->list, &event_list);
+ 	resp.events_reported = ctx->events_reported;
+ 	mutex_unlock(&cur_file->mut);
+ 
+ 	mutex_lock(&new_file->mut);
+ 	list_add_tail(&ctx->list, &new_file->ctx_list);
+ 	list_splice_tail(&event_list, &new_file->event_list);
+ 	mutex_unlock(&new_file->mut);
  
- response:
  	if (copy_to_user(u64_to_user_ptr(cmd.response),
  			 &resp, sizeof(resp)))
  		ret = -EFAULT;
  
++<<<<<<< HEAD
++=======
+ err_unlock:
+ 	rdma_unlock_handler(ctx->cm_id);
++>>>>>>> f5449e74802c (RDMA/ucma: Rework ucma_migrate_id() to avoid races with destroy)
  	ucma_put_ctx(ctx);
  file_put:
  	fdput(f);
* Unmerged path drivers/infiniband/core/ucma.c
