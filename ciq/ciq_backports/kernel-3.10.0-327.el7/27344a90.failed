percpu_ref: add PCPU_REF_DEAD

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [lib] percpu-refcount: add PCPU_REF_DEAD (Jeff Moyer) [1209624]
Rebuild_FUZZ: 88.89%
commit-author Tejun Heo <tj@kernel.org>
commit 27344a9017cdaff82a167827da3001a0918afdc3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/27344a90.failed

percpu_ref will be restructured so that percpu/atomic mode switching
and reference killing are dedoupled.  In preparation, add
PCPU_REF_DEAD and PCPU_REF_ATOMIC_DEAD which is OR of ATOMIC and DEAD.
For now, ATOMIC and DEAD are changed together and all PCPU_REF_ATOMIC
uses are converted to PCPU_REF_ATOMIC_DEAD without causing any
behavior changes.

percpu_ref_init() now specifies an explicit alignment when allocating
the percpu counters so that the pointer has enough unused low bits to
accomodate the flags.  Note that one flag was fine as min alignment
for percpu memory is 2 bytes but two flags are already too many for
the natural alignment of unsigned longs on archs like cris and m68k.

v2: The original patch had BUILD_BUG_ON() which triggers if unsigned
    long's alignment isn't enough to accomodate the flags, which
    triggered on cris and m64k.  percpu_ref_init() updated to specify
    the required alignment explicitly.  Reported by Fengguang.

	Signed-off-by: Tejun Heo <tj@kernel.org>
	Reviewed-by: Kent Overstreet <kmo@daterainc.com>
	Cc: kbuild test robot <fengguang.wu@intel.com>
(cherry picked from commit 27344a9017cdaff82a167827da3001a0918afdc3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/percpu-refcount.h
#	lib/percpu-refcount.c
* Unmerged path include/linux/percpu-refcount.h
* Unmerged path lib/percpu-refcount.c
* Unmerged path include/linux/percpu-refcount.h
* Unmerged path lib/percpu-refcount.c
