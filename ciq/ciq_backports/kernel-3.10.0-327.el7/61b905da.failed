net: Rename skb->rxhash to skb->hash

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [net] Rename skb->rxhash to skb->hash (Ivan Vecera) [1215920]
Rebuild_FUZZ: 92.54%
commit-author Tom Herbert <therbert@google.com>
commit 61b905da33ae25edb6b9d2a5de21e34c3a77efe3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/61b905da.failed

The packet hash can be considered a property of the packet, not just
on RX path.

This patch changes name of rxhash and l4_rxhash skbuff fields to be
hash and l4_hash respectively. This includes changing uses of the
field in the code which don't call the access functions.

	Signed-off-by: Tom Herbert <therbert@google.com>
	Signed-off-by: Eric Dumazet <edumazet@google.com>
	Cc: Mahesh Bandewar <maheshb@google.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 61b905da33ae25edb6b9d2a5de21e34c3a77efe3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/trace/events/net.h
diff --cc include/trace/events/net.h
index f99645d05a8f,1de256b35807..000000000000
--- a/include/trace/events/net.h
+++ b/include/trace/events/net.h
@@@ -78,6 -136,106 +78,109 @@@ DEFINE_EVENT(net_dev_template, netif_rx
  
  	TP_ARGS(skb)
  );
++<<<<<<< HEAD
++=======
+ 
+ DECLARE_EVENT_CLASS(net_dev_rx_verbose_template,
+ 
+ 	TP_PROTO(const struct sk_buff *skb),
+ 
+ 	TP_ARGS(skb),
+ 
+ 	TP_STRUCT__entry(
+ 		__string(	name,			skb->dev->name	)
+ 		__field(	unsigned int,		napi_id		)
+ 		__field(	u16,			queue_mapping	)
+ 		__field(	const void *,		skbaddr		)
+ 		__field(	bool,			vlan_tagged	)
+ 		__field(	u16,			vlan_proto	)
+ 		__field(	u16,			vlan_tci	)
+ 		__field(	u16,			protocol	)
+ 		__field(	u8,			ip_summed	)
+ 		__field(	u32,			hash		)
+ 		__field(	bool,			l4_hash		)
+ 		__field(	unsigned int,		len		)
+ 		__field(	unsigned int,		data_len	)
+ 		__field(	unsigned int,		truesize	)
+ 		__field(	bool,			mac_header_valid)
+ 		__field(	int,			mac_header	)
+ 		__field(	unsigned char,		nr_frags	)
+ 		__field(	u16,			gso_size	)
+ 		__field(	u16,			gso_type	)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__assign_str(name, skb->dev->name);
+ #ifdef CONFIG_NET_RX_BUSY_POLL
+ 		__entry->napi_id = skb->napi_id;
+ #else
+ 		__entry->napi_id = 0;
+ #endif
+ 		__entry->queue_mapping = skb->queue_mapping;
+ 		__entry->skbaddr = skb;
+ 		__entry->vlan_tagged = vlan_tx_tag_present(skb);
+ 		__entry->vlan_proto = ntohs(skb->vlan_proto);
+ 		__entry->vlan_tci = vlan_tx_tag_get(skb);
+ 		__entry->protocol = ntohs(skb->protocol);
+ 		__entry->ip_summed = skb->ip_summed;
+ 		__entry->hash = skb->hash;
+ 		__entry->l4_hash = skb->l4_hash;
+ 		__entry->len = skb->len;
+ 		__entry->data_len = skb->data_len;
+ 		__entry->truesize = skb->truesize;
+ 		__entry->mac_header_valid = skb_mac_header_was_set(skb);
+ 		__entry->mac_header = skb_mac_header(skb) - skb->data;
+ 		__entry->nr_frags = skb_shinfo(skb)->nr_frags;
+ 		__entry->gso_size = skb_shinfo(skb)->gso_size;
+ 		__entry->gso_type = skb_shinfo(skb)->gso_type;
+ 	),
+ 
+ 	TP_printk("dev=%s napi_id=%#x queue_mapping=%u skbaddr=%p vlan_tagged=%d vlan_proto=0x%04x vlan_tci=0x%04x protocol=0x%04x ip_summed=%d hash=0x%08x l4_hash=%d len=%u data_len=%u truesize=%u mac_header_valid=%d mac_header=%d nr_frags=%d gso_size=%d gso_type=%#x",
+ 		  __get_str(name), __entry->napi_id, __entry->queue_mapping,
+ 		  __entry->skbaddr, __entry->vlan_tagged, __entry->vlan_proto,
+ 		  __entry->vlan_tci, __entry->protocol, __entry->ip_summed,
+ 		  __entry->hash, __entry->l4_hash, __entry->len,
+ 		  __entry->data_len, __entry->truesize,
+ 		  __entry->mac_header_valid, __entry->mac_header,
+ 		  __entry->nr_frags, __entry->gso_size, __entry->gso_type)
+ );
+ 
+ DEFINE_EVENT(net_dev_rx_verbose_template, napi_gro_frags_entry,
+ 
+ 	TP_PROTO(const struct sk_buff *skb),
+ 
+ 	TP_ARGS(skb)
+ );
+ 
+ DEFINE_EVENT(net_dev_rx_verbose_template, napi_gro_receive_entry,
+ 
+ 	TP_PROTO(const struct sk_buff *skb),
+ 
+ 	TP_ARGS(skb)
+ );
+ 
+ DEFINE_EVENT(net_dev_rx_verbose_template, netif_receive_skb_entry,
+ 
+ 	TP_PROTO(const struct sk_buff *skb),
+ 
+ 	TP_ARGS(skb)
+ );
+ 
+ DEFINE_EVENT(net_dev_rx_verbose_template, netif_rx_entry,
+ 
+ 	TP_PROTO(const struct sk_buff *skb),
+ 
+ 	TP_ARGS(skb)
+ );
+ 
+ DEFINE_EVENT(net_dev_rx_verbose_template, netif_rx_ni_entry,
+ 
+ 	TP_PROTO(const struct sk_buff *skb),
+ 
+ 	TP_ARGS(skb)
+ );
+ 
++>>>>>>> 61b905da33ae (net: Rename skb->rxhash to skb->hash)
  #endif /* _TRACE_NET_H */
  
  /* This part must be outside protection */
diff --git a/arch/arm/net/bpf_jit_32.c b/arch/arm/net/bpf_jit_32.c
index 6de423dbd385..09420d09618b 100644
--- a/arch/arm/net/bpf_jit_32.c
+++ b/arch/arm/net/bpf_jit_32.c
@@ -821,8 +821,8 @@ b_epilogue:
 			break;
 		case BPF_S_ANC_RXHASH:
 			ctx->seen |= SEEN_SKB;
-			BUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, rxhash) != 4);
-			off = offsetof(struct sk_buff, rxhash);
+			BUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, hash) != 4);
+			off = offsetof(struct sk_buff, hash);
 			emit(ARM_LDR_I(r_A, r_skb, off), ctx);
 			break;
 		case BPF_S_ANC_VLAN_TAG:
diff --git a/arch/powerpc/net/bpf_jit_comp.c b/arch/powerpc/net/bpf_jit_comp.c
index f60d644ef7da..3c4d59c26d16 100644
--- a/arch/powerpc/net/bpf_jit_comp.c
+++ b/arch/powerpc/net/bpf_jit_comp.c
@@ -390,9 +390,9 @@ static int bpf_jit_build_body(struct sk_filter *fp, u32 *image,
 							  mark));
 			break;
 		case BPF_S_ANC_RXHASH:
-			BUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, rxhash) != 4);
+			BUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, hash) != 4);
 			PPC_LWZ_OFFS(r_A, r_skb, offsetof(struct sk_buff,
-							  rxhash));
+							  hash));
 			break;
 		case BPF_S_ANC_VLAN_TAG:
 		case BPF_S_ANC_VLAN_TAG_PRESENT:
diff --git a/arch/s390/net/bpf_jit_comp.c b/arch/s390/net/bpf_jit_comp.c
index e65f32d1edb8..17e6cd61ad0f 100644
--- a/arch/s390/net/bpf_jit_comp.c
+++ b/arch/s390/net/bpf_jit_comp.c
@@ -700,10 +700,10 @@ call_fn:	/* lg %r1,<d(function)>(%r13) */
 		/* icm	%r5,3,<d(type)>(%r1) */
 		EMIT4_DISP(0xbf531000, offsetof(struct net_device, type));
 		break;
-	case BPF_S_ANC_RXHASH: /* A = skb->rxhash */
-		BUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, rxhash) != 4);
-		/* l %r5,<d(rxhash)>(%r2) */
-		EMIT4_DISP(0x58502000, offsetof(struct sk_buff, rxhash));
+	case BPF_S_ANC_RXHASH: /* A = skb->hash */
+		BUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, hash) != 4);
+		/* l %r5,<d(hash)>(%r2) */
+		EMIT4_DISP(0x58502000, offsetof(struct sk_buff, hash));
 		break;
 	case BPF_S_ANC_VLAN_TAG:
 	case BPF_S_ANC_VLAN_TAG_PRESENT:
diff --git a/arch/sparc/net/bpf_jit_comp.c b/arch/sparc/net/bpf_jit_comp.c
index fd95862c65aa..d32340c1e7af 100644
--- a/arch/sparc/net/bpf_jit_comp.c
+++ b/arch/sparc/net/bpf_jit_comp.c
@@ -618,7 +618,7 @@ void bpf_jit_compile(struct sk_filter *fp)
 				emit_load16(r_A, struct net_device, type, r_A);
 				break;
 			case BPF_S_ANC_RXHASH:
-				emit_skb_load32(rxhash, r_A);
+				emit_skb_load32(hash, r_A);
 				break;
 			case BPF_S_ANC_VLAN_TAG:
 			case BPF_S_ANC_VLAN_TAG_PRESENT:
diff --git a/arch/x86/net/bpf_jit_comp.c b/arch/x86/net/bpf_jit_comp.c
index 0c966fecfb8c..9b3ddd33a5a8 100644
--- a/arch/x86/net/bpf_jit_comp.c
+++ b/arch/x86/net/bpf_jit_comp.c
@@ -518,13 +518,13 @@ void bpf_jit_compile(struct sk_filter *fp)
 				}
 				break;
 			case BPF_S_ANC_RXHASH:
-				BUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, rxhash) != 4);
-				if (is_imm8(offsetof(struct sk_buff, rxhash))) {
+				BUILD_BUG_ON(FIELD_SIZEOF(struct sk_buff, hash) != 4);
+				if (is_imm8(offsetof(struct sk_buff, hash))) {
 					/* mov off8(%rdi),%eax */
-					EMIT3(0x8b, 0x47, offsetof(struct sk_buff, rxhash));
+					EMIT3(0x8b, 0x47, offsetof(struct sk_buff, hash));
 				} else {
 					EMIT2(0x8b, 0x87);
-					EMIT(offsetof(struct sk_buff, rxhash), 4);
+					EMIT(offsetof(struct sk_buff, hash), 4);
 				}
 				break;
 			case BPF_S_ANC_QUEUE:
diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index 7d61df58cfdc..4d5d4bb0a49f 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -479,11 +479,11 @@ static inline u32 skb_mstamp_us_delta(const struct skb_mstamp *t1,
  *	@skb_iif: ifindex of device we arrived on
  *	@tc_index: Traffic control index
  *	@tc_verd: traffic control verdict
- *	@rxhash: the packet hash computed on receive
+ *	@hash: the packet hash
  *	@queue_mapping: Queue mapping for multiqueue devices
  *	@ndisc_nodetype: router type (from link layer)
  *	@ooo_okay: allow the mapping of a socket to a queue to be changed
- *	@l4_rxhash: indicate rxhash is a canonical 4-tuple hash over transport
+ *	@l4_hash: indicate hash is a canonical 4-tuple hash over transport
  *		ports.
  *	@wifi_acked_valid: wifi_acked was set
  *	@wifi_acked: whether frame was acked on wifi or not
@@ -570,7 +570,7 @@ struct sk_buff {
 
 	int			skb_iif;
 
-	__u32			rxhash;
+	__u32			hash;
 
 	__be16			vlan_proto;
 	__u16			vlan_tci;
@@ -589,7 +589,7 @@ struct sk_buff {
 #endif
 	__u8			pfmemalloc:1;
 	__u8			ooo_okay:1;
-	__u8			l4_rxhash:1;
+	__u8			l4_hash:1;
 	__u8			wifi_acked_valid:1;
 	__u8			wifi_acked:1;
 	__u8			no_fcs:1;
@@ -877,40 +877,40 @@ enum pkt_hash_types {
 static inline void
 skb_set_hash(struct sk_buff *skb, __u32 hash, enum pkt_hash_types type)
 {
-	skb->l4_rxhash = (type == PKT_HASH_TYPE_L4);
-	skb->rxhash = hash;
+	skb->l4_hash = (type == PKT_HASH_TYPE_L4);
+	skb->hash = hash;
 }
 
 void __skb_get_hash(struct sk_buff *skb);
 static inline __u32 skb_get_hash(struct sk_buff *skb)
 {
-	if (!skb->l4_rxhash)
+	if (!skb->l4_hash)
 		__skb_get_hash(skb);
 
-	return skb->rxhash;
+	return skb->hash;
 }
 
 static inline __u32 skb_get_hash_raw(const struct sk_buff *skb)
 {
-	return skb->rxhash;
+	return skb->hash;
 }
 
 static inline void skb_clear_hash(struct sk_buff *skb)
 {
-	skb->rxhash = 0;
-	skb->l4_rxhash = 0;
+	skb->hash = 0;
+	skb->l4_hash = 0;
 }
 
 static inline void skb_clear_hash_if_not_l4(struct sk_buff *skb)
 {
-	if (!skb->l4_rxhash)
+	if (!skb->l4_hash)
 		skb_clear_hash(skb);
 }
 
 static inline void skb_copy_hash(struct sk_buff *to, const struct sk_buff *from)
 {
-	to->rxhash = from->rxhash;
-	to->l4_rxhash = from->l4_rxhash;
+	to->hash = from->hash;
+	to->l4_hash = from->l4_hash;
 };
 
 #ifdef NET_SKBUFF_DATA_USES_OFFSET
diff --git a/include/net/sock.h b/include/net/sock.h
index a7480947869a..651f5545c008 100644
--- a/include/net/sock.h
+++ b/include/net/sock.h
@@ -874,9 +874,9 @@ static inline void sock_rps_save_rxhash(struct sock *sk,
 					const struct sk_buff *skb)
 {
 #ifdef CONFIG_RPS
-	if (unlikely(sk->sk_rxhash != skb->rxhash)) {
+	if (unlikely(sk->sk_rxhash != skb->hash)) {
 		sock_rps_reset_flow(sk);
-		sk->sk_rxhash = skb->rxhash;
+		sk->sk_rxhash = skb->hash;
 	}
 #endif
 }
* Unmerged path include/trace/events/net.h
diff --git a/net/core/dev.c b/net/core/dev.c
index 883bfd5aec6c..d1fdda6db6c0 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -2910,7 +2910,7 @@ set_rps_cpu(struct net_device *dev, struct sk_buff *skb,
 		flow_table = rcu_dereference(rxqueue->rps_flow_table);
 		if (!flow_table)
 			goto out;
-		flow_id = skb->rxhash & flow_table->mask;
+		flow_id = skb_get_hash(skb) & flow_table->mask;
 		rc = dev->netdev_ops->ndo_rx_flow_steer(dev, skb,
 							rxq_index, flow_id);
 		if (rc < 0)
@@ -2944,6 +2944,7 @@ static int get_rps_cpu(struct net_device *dev, struct sk_buff *skb,
 	struct rps_sock_flow_table *sock_flow_table;
 	int cpu = -1;
 	u16 tcpu;
+	u32 hash;
 
 	if (skb_rx_queue_recorded(skb)) {
 		u16 index = skb_get_rx_queue(skb);
@@ -2972,7 +2973,8 @@ static int get_rps_cpu(struct net_device *dev, struct sk_buff *skb,
 	}
 
 	skb_reset_network_header(skb);
-	if (!skb_get_hash(skb))
+	hash = skb_get_hash(skb);
+	if (!hash)
 		goto done;
 
 	flow_table = rcu_dereference(rxqueue->rps_flow_table);
@@ -2981,11 +2983,10 @@ static int get_rps_cpu(struct net_device *dev, struct sk_buff *skb,
 		u16 next_cpu;
 		struct rps_dev_flow *rflow;
 
-		rflow = &flow_table->flows[skb->rxhash & flow_table->mask];
+		rflow = &flow_table->flows[hash & flow_table->mask];
 		tcpu = rflow->cpu;
 
-		next_cpu = sock_flow_table->ents[skb->rxhash &
-		    sock_flow_table->mask];
+		next_cpu = sock_flow_table->ents[hash & sock_flow_table->mask];
 
 		/*
 		 * If the desired CPU (where last recvmsg was done) is
@@ -3014,7 +3015,7 @@ static int get_rps_cpu(struct net_device *dev, struct sk_buff *skb,
 	}
 
 	if (map) {
-		tcpu = map->cpus[((u64) skb->rxhash * map->len) >> 32];
+		tcpu = map->cpus[((u64) hash * map->len) >> 32];
 
 		if (cpu_online(tcpu)) {
 			cpu = tcpu;
diff --git a/net/core/filter.c b/net/core/filter.c
index 01bd4de9aefe..88c71ce99748 100644
--- a/net/core/filter.c
+++ b/net/core/filter.c
@@ -336,7 +336,7 @@ load_b:
 			A = skb->dev->type;
 			continue;
 		case BPF_S_ANC_RXHASH:
-			A = skb->rxhash;
+			A = skb->hash;
 			continue;
 		case BPF_S_ANC_CPU:
 			A = raw_smp_processor_id();
diff --git a/net/core/flow_dissector.c b/net/core/flow_dissector.c
index a82ac44a3fe2..60b125d78fe4 100644
--- a/net/core/flow_dissector.c
+++ b/net/core/flow_dissector.c
@@ -182,8 +182,8 @@ static __always_inline u32 __flow_hash_1word(u32 a)
 
 /*
  * __skb_get_hash: calculate a flow hash based on src/dst addresses
- * and src/dst port numbers.  Sets rxhash in skb to non-zero hash value
- * on success, zero indicates no valid hash.  Also, sets l4_rxhash in skb
+ * and src/dst port numbers.  Sets hash in skb to non-zero hash value
+ * on success, zero indicates no valid hash.  Also, sets l4_hash in skb
  * if hash is a canonical 4-tuple hash over transport ports.
  */
 void __skb_get_hash(struct sk_buff *skb)
@@ -195,7 +195,7 @@ void __skb_get_hash(struct sk_buff *skb)
 		return;
 
 	if (keys.ports)
-		skb->l4_rxhash = 1;
+		skb->l4_hash = 1;
 
 	/* get a consistent hash (same value on both flow directions) */
 	if (((__force u32)keys.dst < (__force u32)keys.src) ||
@@ -211,7 +211,7 @@ void __skb_get_hash(struct sk_buff *skb)
 	if (!hash)
 		hash = 1;
 
-	skb->rxhash = hash;
+	skb->hash = hash;
 }
 EXPORT_SYMBOL(__skb_get_hash);
 
@@ -334,7 +334,7 @@ static inline int get_xps_queue(struct net_device *dev, struct sk_buff *skb)
 					hash = skb->sk->sk_hash;
 				else
 					hash = (__force u16) skb->protocol ^
-					    skb->rxhash;
+					    skb->hash;
 				hash = __flow_hash_1word(hash);
 				queue_index = map->queues[
 				    ((u64)hash * map->len) >> 32];
diff --git a/net/packet/af_packet.c b/net/packet/af_packet.c
index 674dd1d4ef8f..8904d552d47c 100644
--- a/net/packet/af_packet.c
+++ b/net/packet/af_packet.c
@@ -1205,7 +1205,7 @@ static unsigned int fanout_demux_hash(struct packet_fanout *f,
 				      struct sk_buff *skb,
 				      unsigned int num)
 {
-	return reciprocal_scale(skb->rxhash, num);
+	return reciprocal_scale(skb_get_hash(skb), num);
 }
 
 static unsigned int fanout_demux_lb(struct packet_fanout *f,
@@ -1283,7 +1283,6 @@ static int packet_rcv_fanout(struct sk_buff *skb, struct net_device *dev,
 			if (!skb)
 				return 0;
 		}
-		skb_get_hash(skb);
 		idx = fanout_demux_hash(f, skb, num);
 		break;
 	case PACKET_FANOUT_LB:
