IB/iser: Centralize iser completion contexts

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [infiniband] iser: Centralize iser completion contexts (Amir Vadai) [1164539]
Rebuild_FUZZ: 96.47%
commit-author Sagi Grimberg <sagig@mellanox.com>
commit bf17554035ab2aaf770321208ce48e69aab71cc8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/bf175540.failed

Introduce iser_comp which centralizes all iser completion related
items and is referenced by iser_device and each ib_conn.

	Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
	Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
	Signed-off-by: Roland Dreier <roland@purestorage.com>
(cherry picked from commit bf17554035ab2aaf770321208ce48e69aab71cc8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/ulp/iser/iscsi_iser.h
#	drivers/infiniband/ulp/iser/iser_verbs.c
diff --cc drivers/infiniband/ulp/iser/iscsi_iser.h
index 9f0e0e34d6ca,2bc34aa50705..000000000000
--- a/drivers/infiniband/ulp/iser/iscsi_iser.h
+++ b/drivers/infiniband/ulp/iser/iscsi_iser.h
@@@ -265,8 -264,27 +264,26 @@@ struct iser_rx_desc 
  #define ISER_MAX_CQ 4
  
  struct iser_conn;
 -struct ib_conn;
  struct iscsi_iser_task;
  
+ /**
+  * struct iser_comp - iSER completion context
+  *
+  * @device:     pointer to device handle
+  * @rx_cq:      RX completion queue
+  * @tx_cq:      TX completion queue
+  * @tasklet:    Tasklet handle
+  * @active_qps: Number of active QPs attached
+  *              to completion context
+  */
+ struct iser_comp {
+ 	struct iser_device      *device;
+ 	struct ib_cq		*rx_cq;
+ 	struct ib_cq		*tx_cq;
+ 	struct tasklet_struct	 tasklet;
+ 	int                      active_qps;
+ };
+ 
  struct iser_device {
  	struct ib_device             *ib_device;
  	struct ib_pd	             *pd;
@@@ -277,13 -293,11 +292,18 @@@
  	struct ib_event_handler      event_handler;
  	struct list_head             ig_list; /* entry in ig devices list */
  	int                          refcount;
++<<<<<<< HEAD
 +	int                          cq_active_qps[ISER_MAX_CQ];
 +	int			     cqs_used;
 +	struct iser_cq_desc	     *cq_desc;
 +	int                          (*iser_alloc_rdma_reg_res)(struct iser_conn *ib_conn,
++=======
+ 	int			     comps_used;
+ 	struct iser_comp	     comps[ISER_MAX_CQ];
+ 	int                          (*iser_alloc_rdma_reg_res)(struct ib_conn *ib_conn,
++>>>>>>> bf17554035ab (IB/iser: Centralize iser completion contexts)
  								unsigned cmds_max);
 -	void                         (*iser_free_rdma_reg_res)(struct ib_conn *ib_conn);
 +	void                         (*iser_free_rdma_reg_res)(struct iser_conn *ib_conn);
  	int                          (*iser_reg_rdma_mem)(struct iscsi_iser_task *iser_task,
  							  enum iser_data_dir cmd_dir);
  	void                         (*iser_unreg_rdma_mem)(struct iscsi_iser_task *iser_task,
@@@ -317,15 -331,54 +337,61 @@@ struct fast_reg_descriptor 
  	u8				  reg_indicators;
  };
  
++<<<<<<< HEAD
++=======
+ /**
+  * struct ib_conn - Infiniband related objects
+  *
+  * @cma_id:              rdma_cm connection maneger handle
+  * @qp:                  Connection Queue-pair
+  * @post_recv_buf_count: post receive counter
+  * @post_send_buf_count: post send counter
+  * @rx_wr:               receive work request for batch posts
+  * @device:              reference to iser device
+  * @comp:                iser completion context
+  * @pi_support:          Indicate device T10-PI support
+  * @lock:                protects fmr/fastreg pool
+  * @union.fmr:
+  *     @pool:            FMR pool for fast registrations
+  *     @page_vec:        page vector to hold mapped commands pages
+  *                       used for registration
+  * @union.fastreg:
+  *     @pool:            Fast registration descriptors pool for fast
+  *                       registrations
+  *     @pool_size:       Size of pool
+  */
+ struct ib_conn {
+ 	struct rdma_cm_id           *cma_id;
+ 	struct ib_qp	            *qp;
+ 	int                          post_recv_buf_count;
+ 	atomic_t                     post_send_buf_count;
+ 	struct ib_recv_wr	     rx_wr[ISER_MIN_POSTED_RX];
+ 	struct iser_device          *device;
+ 	struct iser_comp	    *comp;
+ 	bool			     pi_support;
+ 	spinlock_t		     lock;
+ 	union {
+ 		struct {
+ 			struct ib_fmr_pool      *pool;
+ 			struct iser_page_vec	*page_vec;
+ 		} fmr;
+ 		struct {
+ 			struct list_head	 pool;
+ 			int			 pool_size;
+ 		} fastreg;
+ 	};
+ };
+ 
++>>>>>>> bf17554035ab (IB/iser: Centralize iser completion contexts)
  struct iser_conn {
 -	struct ib_conn		     ib_conn;
  	struct iscsi_conn	     *iscsi_conn;
  	struct iscsi_endpoint	     *ep;
 -	enum iser_conn_state	     state;	    /* rdma connection state   */
 +	enum iser_ib_conn_state	     state;	    /* rdma connection state   */
 +	atomic_t		     refcount;
 +	spinlock_t		     lock;	    /* used for state changes  */
 +	struct iser_device           *device;       /* device context          */
 +	struct rdma_cm_id            *cma_id;       /* CMA ID		       */
 +	struct ib_qp	             *qp;           /* QP 		       */
  	unsigned		     qp_max_recv_dtos; /* num of rx buffers */
  	unsigned		     qp_max_recv_dtos_mask; /* above minus 1 */
  	unsigned		     min_posted_rx; /* qp_max_recv_dtos >> 2 */
diff --cc drivers/infiniband/ulp/iser/iser_verbs.c
index fbf2a1e0f2e2,94d1b46b467a..000000000000
--- a/drivers/infiniband/ulp/iser/iser_verbs.c
+++ b/drivers/infiniband/ulp/iser/iser_verbs.c
@@@ -44,6 -44,7 +44,10 @@@
  
  static void iser_cq_tasklet_fn(unsigned long data);
  static void iser_cq_callback(struct ib_cq *cq, void *cq_context);
++<<<<<<< HEAD
++=======
+ static int iser_drain_tx_cq(struct iser_comp *comp);
++>>>>>>> bf17554035ab (IB/iser: Centralize iser completion contexts)
  
  static void iser_cq_event_callback(struct ib_event *cause, void *context)
  {
@@@ -71,9 -72,8 +75,8 @@@ static void iser_event_handler(struct i
   */
  static int iser_create_device_ib_res(struct iser_device *device)
  {
- 	struct iser_cq_desc *cq_desc;
  	struct ib_device_attr *dev_attr = &device->dev_attr;
 -	int ret, i;
 +	int ret, i, max_cqe;
  
  	ret = ib_query_device(device->ib_device, dev_attr);
  	if (ret) {
@@@ -116,29 -111,26 +114,48 @@@
  	if (IS_ERR(device->pd))
  		goto pd_err;
  
- 	for (i = 0; i < device->cqs_used; i++) {
- 		cq_desc[i].device   = device;
- 		cq_desc[i].cq_index = i;
+ 	for (i = 0; i < device->comps_used; i++) {
+ 		struct iser_comp *comp = &device->comps[i];
  
++<<<<<<< HEAD
 +		max_cqe = min(ISER_MAX_RX_CQ_LEN, dev_attr->max_cqe);
 +		device->rx_cq[i] = ib_create_cq(device->ib_device,
 +					  iser_cq_callback,
 +					  iser_cq_event_callback,
 +					  (void *)&cq_desc[i],
 +					  max_cqe, i);
 +		if (IS_ERR(device->rx_cq[i])) {
 +			device->rx_cq[i] = NULL;
 +			goto cq_err;
 +		}
 +
 +		max_cqe = min(ISER_MAX_TX_CQ_LEN, dev_attr->max_cqe);
 +		device->tx_cq[i] = ib_create_cq(device->ib_device,
 +					  NULL, iser_cq_event_callback,
 +					  (void *)&cq_desc[i],
 +					  max_cqe, i);
 +
 +		if (IS_ERR(device->tx_cq[i])) {
 +			device->tx_cq[i] = NULL;
++=======
+ 		comp->device = device;
+ 		comp->rx_cq = ib_create_cq(device->ib_device,
+ 					   iser_cq_callback,
+ 					   iser_cq_event_callback,
+ 					   (void *)comp,
+ 					   ISER_MAX_RX_CQ_LEN, i);
+ 		if (IS_ERR(comp->rx_cq)) {
+ 			comp->rx_cq = NULL;
+ 			goto cq_err;
+ 		}
+ 
+ 		comp->tx_cq = ib_create_cq(device->ib_device, NULL,
+ 					   iser_cq_event_callback,
+ 					   (void *)comp,
+ 					   ISER_MAX_TX_CQ_LEN, i);
+ 		if (IS_ERR(comp->tx_cq)) {
+ 			comp->tx_cq = NULL;
++>>>>>>> bf17554035ab (IB/iser: Centralize iser completion contexts)
  			goto cq_err;
  		}
  
@@@ -459,11 -448,13 +475,17 @@@ static int iser_create_ib_conn_res(stru
  
  	mutex_lock(&ig.connlist_mutex);
  	/* select the CQ with the minimal number of usages */
- 	for (index = 0; index < device->cqs_used; index++)
- 		if (device->cq_active_qps[index] <
- 		    device->cq_active_qps[min_index])
+ 	for (index = 0; index < device->comps_used; index++) {
+ 		if (device->comps[index].active_qps <
+ 		    device->comps[min_index].active_qps)
  			min_index = index;
++<<<<<<< HEAD
 +	device->cq_active_qps[min_index]++;
++=======
+ 	}
+ 	ib_conn->comp = &device->comps[min_index];
+ 	ib_conn->comp->active_qps++;
++>>>>>>> bf17554035ab (IB/iser: Centralize iser completion contexts)
  	mutex_unlock(&ig.connlist_mutex);
  	iser_info("cq index %d used for ib_conn %p\n", min_index, ib_conn);
  
@@@ -591,26 -558,54 +613,44 @@@ static int iser_conn_state_comp_exch(st
  
  void iser_release_work(struct work_struct *work)
  {
 -	struct iser_conn *iser_conn;
 +	struct iser_conn *ib_conn;
 +	int rc;
  
 -	iser_conn = container_of(work, struct iser_conn, release_work);
 +	ib_conn = container_of(work, struct iser_conn, release_work);
  
 -	/* Wait for conn_stop to complete */
 -	wait_for_completion(&iser_conn->stop_completion);
 -	/* Wait for IB resouces cleanup to complete */
 -	wait_for_completion(&iser_conn->ib_completion);
 +	/* wait for .conn_stop callback */
 +	rc = wait_for_completion_timeout(&ib_conn->stop_completion, 30 * HZ);
 +	WARN_ON(rc == 0);
  
 -	mutex_lock(&iser_conn->state_mutex);
 -	iser_conn->state = ISER_CONN_DOWN;
 -	mutex_unlock(&iser_conn->state_mutex);
 +	/* wait for the qp`s post send and post receive buffers to empty */
 +	rc = wait_for_completion_timeout(&ib_conn->flush_completion, 30 * HZ);
 +	WARN_ON(rc == 0);
  
 -	iser_conn_release(iser_conn);
 -}
 +	ib_conn->state = ISER_CONN_DOWN;
  
 -/**
 - * iser_free_ib_conn_res - release IB related resources
 - * @iser_conn: iser connection struct
 - * @destroy_device: indicator if we need to try to release
 - *     the iser device (only iscsi shutdown and DEVICE_REMOVAL
 - *     will use this.
 - *
 - * This routine is called with the iser state mutex held
 - * so the cm_id removal is out of here. It is Safe to
 - * be invoked multiple times.
 - */
 -static void iser_free_ib_conn_res(struct iser_conn *iser_conn,
 -				  bool destroy_device)
 -{
 -	struct ib_conn *ib_conn = &iser_conn->ib_conn;
 -	struct iser_device *device = ib_conn->device;
 +	mutex_lock(&ib_conn->state_mutex);
 +	ib_conn->state = ISER_CONN_DOWN;
 +	mutex_unlock(&ib_conn->state_mutex);
  
++<<<<<<< HEAD
 +	iser_conn_release(ib_conn);
++=======
+ 	iser_info("freeing conn %p cma_id %p qp %p\n",
+ 		  iser_conn, ib_conn->cma_id, ib_conn->qp);
+ 
+ 	iser_free_rx_descriptors(iser_conn);
+ 
+ 	if (ib_conn->qp != NULL) {
+ 		ib_conn->comp->active_qps--;
+ 		rdma_destroy_qp(ib_conn->cma_id);
+ 		ib_conn->qp = NULL;
+ 	}
+ 
+ 	if (destroy_device && device != NULL) {
+ 		iser_device_try_release(device);
+ 		ib_conn->device = NULL;
+ 	}
++>>>>>>> bf17554035ab (IB/iser: Centralize iser completion contexts)
  }
  
  /**
@@@ -640,7 -634,35 +680,39 @@@ void iser_conn_release(struct iser_con
  		rdma_destroy_id(ib_conn->cma_id);
  		ib_conn->cma_id = NULL;
  	}
++<<<<<<< HEAD
 +	kfree(ib_conn);
++=======
+ 
+ 	kfree(iser_conn);
+ }
+ 
+ /**
+  * iser_poll_for_flush_errors - Don't settle for less than all.
+  * @struct ib_conn: IB context of the connection
+  *
+  * This routine is called when the QP is in error state
+  * It polls the send CQ until all flush errors are consumed and
+  * returns when all flush errors were processed.
+  */
+ static void iser_poll_for_flush_errors(struct ib_conn *ib_conn)
+ {
+ 	int count = 0;
+ 
+ 	while (ib_conn->post_recv_buf_count > 0 ||
+ 	       atomic_read(&ib_conn->post_send_buf_count) > 0) {
+ 		msleep(100);
+ 		if (atomic_read(&ib_conn->post_send_buf_count) > 0)
+ 			iser_drain_tx_cq(ib_conn->comp);
+ 
+ 		count++;
+ 		/* Don't flood with prints */
+ 		if (count % 30 == 0)
+ 			iser_dbg("post_recv %d post_send %d",
+ 				 ib_conn->post_recv_buf_count,
+ 				 atomic_read(&ib_conn->post_send_buf_count));
+ 	}
++>>>>>>> bf17554035ab (IB/iser: Centralize iser completion contexts)
  }
  
  /**
@@@ -1090,36 -1153,40 +1162,36 @@@ int iser_post_send(struct iser_conn *ib
  	return ib_ret;
  }
  
 -/**
 - * iser_handle_comp_error() - Handle error completion
 - * @desc:      iser TX descriptor
 - * @ib_conn:   connection RDMA resources
 - * @wc:        work completion
 - *
 - * Notes: We may handle a FLUSH error completion and in this case
 - *        we only cleanup in case TX type was DATAOUT. For non-FLUSH
 - *        error completion we should also notify iscsi layer that
 - *        connection is failed (in case we passed bind stage).
 - */
 -static void
 -iser_handle_comp_error(struct iser_tx_desc *desc,
 -		       struct ib_conn *ib_conn,
 -		       struct ib_wc *wc)
 +static void iser_handle_comp_error(struct iser_tx_desc *desc,
 +				struct iser_conn *ib_conn)
  {
 -	struct iser_conn *iser_conn = container_of(ib_conn, struct iser_conn,
 -						   ib_conn);
 +	if (desc && desc->type == ISCSI_TX_DATAOUT)
 +		kmem_cache_free(ig.desc_cache, desc);
  
 -	if (wc->status != IB_WC_WR_FLUSH_ERR)
 -		if (iser_conn->iscsi_conn)
 -			iscsi_conn_failure(iser_conn->iscsi_conn,
 +	if (ib_conn->post_recv_buf_count == 0 &&
 +	    atomic_read(&ib_conn->post_send_buf_count) == 0) {
 +		/**
 +		 * getting here when the state is UP means that the conn is
 +		 * being terminated asynchronously from the iSCSI layer's
 +		 * perspective. It is safe to peek at the connection state
 +		 * since iscsi_conn_failure is allowed to be called twice.
 +		 **/
 +		if (ib_conn->state == ISER_CONN_UP)
 +			iscsi_conn_failure(ib_conn->iscsi_conn,
  					   ISCSI_ERR_CONN_FAILED);
  
 -	if (desc && desc->type == ISCSI_TX_DATAOUT)
 -		kmem_cache_free(ig.desc_cache, desc);
 +		/* no more non completed posts to the QP, complete the
 +		 * termination process w.o worrying on disconnect event */
 +		complete(&ib_conn->flush_completion);
 +	}
  }
  
- static int iser_drain_tx_cq(struct iser_device  *device, int cq_index)
+ static int iser_drain_tx_cq(struct iser_comp *comp)
  {
- 	struct ib_cq  *cq = device->tx_cq[cq_index];
+ 	struct ib_cq *cq = comp->tx_cq;
  	struct ib_wc  wc;
  	struct iser_tx_desc *tx_desc;
 -	struct ib_conn *ib_conn;
 +	struct iser_conn *ib_conn;
  	int completed_tx = 0;
  
  	while (ib_poll_cq(cq, 1, &wc) == 1) {
@@@ -1147,14 -1214,12 +1219,23 @@@
  
  static void iser_cq_tasklet_fn(unsigned long data)
  {
++<<<<<<< HEAD
 +	struct iser_cq_desc *cq_desc = (struct iser_cq_desc *)data;
 +	struct iser_device  *device = cq_desc->device;
 +	int cq_index = cq_desc->cq_index;
 +	struct ib_cq	     *cq = device->rx_cq[cq_index];
 +	 struct ib_wc	     wc;
 +	 struct iser_rx_desc *desc;
 +	 unsigned long	     xfer_len;
 +	struct iser_conn *ib_conn;
++=======
+ 	struct iser_comp *comp = (struct iser_comp *)data;
+ 	struct ib_cq *cq = comp->rx_cq;
+ 	struct ib_wc wc;
+ 	struct iser_rx_desc *desc;
+ 	unsigned long xfer_len;
+ 	struct ib_conn *ib_conn;
++>>>>>>> bf17554035ab (IB/iser: Centralize iser completion contexts)
  	int completed_tx, completed_rx = 0;
  
  	/* First do tx drain, so in a case where we have rx flushes and a successful
* Unmerged path drivers/infiniband/ulp/iser/iscsi_iser.h
* Unmerged path drivers/infiniband/ulp/iser/iser_verbs.c
