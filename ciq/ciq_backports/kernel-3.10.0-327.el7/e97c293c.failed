block: introduce 'blk_mq_ctx' parameter to blk_get_flush_queue

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [block] introduce 'blk_mq_ctx' parameter to blk_get_flush_queue (Jeff Moyer) [1209624]
Rebuild_FUZZ: 94.02%
commit-author Ming Lei <ming.lei@canonical.com>
commit e97c293cdf77263abdc021de280516e0017afc84
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/e97c293c.failed

This patch adds 'blk_mq_ctx' parameter to blk_get_flush_queue(),
so that this function can find the corresponding blk_flush_queue
bound with current mq context since the flush queue will become
per hw-queue.

For legacy queue, the parameter can be simply 'NULL'.

For multiqueue case, the parameter should be set as the context
from which the related request is originated. With this context
info, the hw queue and related flush queue can be found easily.

	Signed-off-by: Ming Lei <ming.lei@canonical.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit e97c293cdf77263abdc021de280516e0017afc84)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-core.c
#	block/blk-flush.c
#	block/blk-mq.c
#	block/blk.h
diff --cc block/blk-core.c
index 6c8ecd3370db,b1dd4e086740..000000000000
--- a/block/blk-core.c
+++ b/block/blk-core.c
@@@ -390,6 -390,7 +390,10 @@@ static void __blk_drain_queue(struct re
  		 * be drained.  Check all the queues and counters.
  		 */
  		if (drain_all) {
++<<<<<<< HEAD
++=======
+ 			struct blk_flush_queue *fq = blk_get_flush_queue(q, NULL);
++>>>>>>> e97c293cdf77 (block: introduce 'blk_mq_ctx' parameter to blk_get_flush_queue)
  			drain |= !list_empty(&q->queue_head);
  			for (i = 0; i < 2; i++) {
  				drain |= q->nr_rqs[i];
diff --cc block/blk-flush.c
index 4ba98aaf2ce6,004d95e4098e..000000000000
--- a/block/blk-flush.c
+++ b/block/blk-flush.c
@@@ -220,9 -223,10 +220,13 @@@ static void flush_end_io(struct reques
  	bool queued = false;
  	struct request *rq, *n;
  	unsigned long flags = 0;
++<<<<<<< HEAD
++=======
+ 	struct blk_flush_queue *fq = blk_get_flush_queue(q, flush_rq->mq_ctx);
++>>>>>>> e97c293cdf77 (block: introduce 'blk_mq_ctx' parameter to blk_get_flush_queue)
  
  	if (q->mq_ops) {
 -		spin_lock_irqsave(&fq->mq_flush_lock, flags);
 +		spin_lock_irqsave(&q->mq_flush_lock, flags);
  		flush_rq->tag = -1;
  	}
  
@@@ -314,6 -319,7 +318,10 @@@ static bool blk_kick_flush(struct reque
  static void flush_data_end_io(struct request *rq, int error)
  {
  	struct request_queue *q = rq->q;
++<<<<<<< HEAD
++=======
+ 	struct blk_flush_queue *fq = blk_get_flush_queue(q, NULL);
++>>>>>>> e97c293cdf77 (block: introduce 'blk_mq_ctx' parameter to blk_get_flush_queue)
  
  	/*
  	 * After populating an empty queue, kick it to avoid stall.  Read
@@@ -327,10 -333,10 +335,13 @@@ static void mq_flush_data_end_io(struc
  {
  	struct request_queue *q = rq->q;
  	struct blk_mq_hw_ctx *hctx;
- 	struct blk_mq_ctx *ctx;
+ 	struct blk_mq_ctx *ctx = rq->mq_ctx;
  	unsigned long flags;
++<<<<<<< HEAD
++=======
+ 	struct blk_flush_queue *fq = blk_get_flush_queue(q, ctx);
++>>>>>>> e97c293cdf77 (block: introduce 'blk_mq_ctx' parameter to blk_get_flush_queue)
  
- 	ctx = rq->mq_ctx;
  	hctx = q->mq_ops->map_queue(q, ctx->cpu);
  
  	/*
@@@ -360,6 -366,7 +371,10 @@@ void blk_insert_flush(struct request *r
  	struct request_queue *q = rq->q;
  	unsigned int fflags = q->flush_flags;	/* may change, cache */
  	unsigned int policy = blk_flush_policy(fflags, rq);
++<<<<<<< HEAD
++=======
+ 	struct blk_flush_queue *fq = blk_get_flush_queue(q, rq->mq_ctx);
++>>>>>>> e97c293cdf77 (block: introduce 'blk_mq_ctx' parameter to blk_get_flush_queue)
  
  	/*
  	 * @policy now records what operations need to be done.  Adjust
diff --cc block/blk-mq.c
index 77afc91943c8,53b6def12fc4..000000000000
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@@ -521,11 -518,13 +521,16 @@@ static inline bool is_flush_request(str
  struct request *blk_mq_tag_to_rq(struct blk_mq_tags *tags, unsigned int tag)
  {
  	struct request *rq = tags->rqs[tag];
++<<<<<<< HEAD
++=======
+ 	/* mq_ctx of flush rq is always cloned from the corresponding req */
+ 	struct blk_flush_queue *fq = blk_get_flush_queue(rq->q, rq->mq_ctx);
++>>>>>>> e97c293cdf77 (block: introduce 'blk_mq_ctx' parameter to blk_get_flush_queue)
  
 -	if (!is_flush_request(rq, fq, tag))
 +	if (!is_flush_request(rq, tag))
  		return rq;
  
 -	return fq->flush_rq;
 +	return rq->q->flush_rq;
  }
  EXPORT_SYMBOL(blk_mq_tag_to_rq);
  
diff --cc block/blk.h
index e515a285d4c9,7ecdd8517e69..000000000000
--- a/block/blk.h
+++ b/block/blk.h
@@@ -17,6 -28,12 +17,15 @@@ extern struct kmem_cache *request_cache
  extern struct kobj_type blk_queue_ktype;
  extern struct ida blk_queue_ida;
  
++<<<<<<< HEAD
++=======
+ static inline struct blk_flush_queue *blk_get_flush_queue(
+ 		struct request_queue *q, struct blk_mq_ctx *ctx)
+ {
+ 	return q->fq;
+ }
+ 
++>>>>>>> e97c293cdf77 (block: introduce 'blk_mq_ctx' parameter to blk_get_flush_queue)
  static inline void __blk_get_queue(struct request_queue *q)
  {
  	kobject_get(&q->kobj);
@@@ -86,6 -106,7 +95,10 @@@ void blk_insert_flush(struct request *r
  static inline struct request *__elv_next_request(struct request_queue *q)
  {
  	struct request *rq;
++<<<<<<< HEAD
++=======
+ 	struct blk_flush_queue *fq = blk_get_flush_queue(q, NULL);
++>>>>>>> e97c293cdf77 (block: introduce 'blk_mq_ctx' parameter to blk_get_flush_queue)
  
  	while (1) {
  		if (!list_empty(&q->queue_head)) {
* Unmerged path block/blk-core.c
* Unmerged path block/blk-flush.c
* Unmerged path block/blk-mq.c
* Unmerged path block/blk.h
