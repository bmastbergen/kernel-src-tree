tcp: Remove unnecessary arg from tcp_enter_cwr and tcp_init_cwnd_reduction

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Christoph Paasch <christoph.paasch@uclouvain.be>
commit 5ee2c941b5969eb1b5592f9731b3ee76a784641f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/5ee2c941.failed

Since Yuchung's 9b44190dc11 (tcp: refactor F-RTO), tcp_enter_cwr is always
called with set_ssthresh = 1. Thus, we can remove this argument from
tcp_enter_cwr. Further, as we remove this one, tcp_init_cwnd_reduction
is then always called with set_ssthresh = true, and so we can get rid of
this argument as well.

	Cc: Yuchung Cheng <ycheng@google.com>
	Signed-off-by: Christoph Paasch <christoph.paasch@uclouvain.be>
	Acked-by: Yuchung Cheng <ycheng@google.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 5ee2c941b5969eb1b5592f9731b3ee76a784641f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/tcp.h
diff --cc include/net/tcp.h
index b0e667090696,0aeb2eb749dc..000000000000
--- a/include/net/tcp.h
+++ b/include/net/tcp.h
@@@ -951,8 -928,8 +951,13 @@@ static inline __u32 tcp_current_ssthres
  /* Use define here intentionally to get WARN_ON location shown at the caller */
  #define tcp_verify_left_out(tp)	WARN_ON(tcp_left_out(tp) > tp->packets_out)
  
++<<<<<<< HEAD
 +extern void tcp_enter_cwr(struct sock *sk, const int set_ssthresh);
 +extern __u32 tcp_init_cwnd(const struct tcp_sock *tp, const struct dst_entry *dst);
++=======
+ void tcp_enter_cwr(struct sock *sk);
+ __u32 tcp_init_cwnd(const struct tcp_sock *tp, const struct dst_entry *dst);
++>>>>>>> 5ee2c941b596 (tcp: Remove unnecessary arg from tcp_enter_cwr and tcp_init_cwnd_reduction)
  
  /* The maximum number of MSS of available cwnd for which TSO defers
   * sending if not using sysctl_tcp_tso_win_divisor.
* Unmerged path include/net/tcp.h
diff --git a/net/ipv4/tcp_input.c b/net/ipv4/tcp_input.c
index 7bcc2fdfb73f..b15db7021c6a 100644
--- a/net/ipv4/tcp_input.c
+++ b/net/ipv4/tcp_input.c
@@ -2496,7 +2496,7 @@ static bool tcp_try_undo_loss(struct sock *sk, bool frto_undo)
  *	losses and/or application stalls), do not perform any further cwnd
  *	reductions, but instead slow start up to ssthresh.
  */
-static void tcp_init_cwnd_reduction(struct sock *sk, const bool set_ssthresh)
+static void tcp_init_cwnd_reduction(struct sock *sk)
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 
@@ -2506,8 +2506,7 @@ static void tcp_init_cwnd_reduction(struct sock *sk, const bool set_ssthresh)
 	tp->prior_cwnd = tp->snd_cwnd;
 	tp->prr_delivered = 0;
 	tp->prr_out = 0;
-	if (set_ssthresh)
-		tp->snd_ssthresh = inet_csk(sk)->icsk_ca_ops->ssthresh(sk);
+	tp->snd_ssthresh = inet_csk(sk)->icsk_ca_ops->ssthresh(sk);
 	TCP_ECN_queue_cwr(tp);
 }
 
@@ -2549,14 +2548,14 @@ static inline void tcp_end_cwnd_reduction(struct sock *sk)
 }
 
 /* Enter CWR state. Disable cwnd undo since congestion is proven with ECN */
-void tcp_enter_cwr(struct sock *sk, const int set_ssthresh)
+void tcp_enter_cwr(struct sock *sk)
 {
 	struct tcp_sock *tp = tcp_sk(sk);
 
 	tp->prior_ssthresh = 0;
 	if (inet_csk(sk)->icsk_ca_state < TCP_CA_CWR) {
 		tp->undo_marker = 0;
-		tcp_init_cwnd_reduction(sk, set_ssthresh);
+		tcp_init_cwnd_reduction(sk);
 		tcp_set_ca_state(sk, TCP_CA_CWR);
 	}
 }
@@ -2585,7 +2584,7 @@ static void tcp_try_to_open(struct sock *sk, int flag, const int prior_unsacked)
 		tp->retrans_stamp = 0;
 
 	if (flag & FLAG_ECE)
-		tcp_enter_cwr(sk, 1);
+		tcp_enter_cwr(sk);
 
 	if (inet_csk(sk)->icsk_ca_state != TCP_CA_CWR) {
 		tcp_try_keep_open(sk);
@@ -2691,7 +2690,7 @@ static void tcp_enter_recovery(struct sock *sk, bool ece_ack)
 	if (inet_csk(sk)->icsk_ca_state < TCP_CA_CWR) {
 		if (!ece_ack)
 			tp->prior_ssthresh = tcp_current_ssthresh(sk);
-		tcp_init_cwnd_reduction(sk, true);
+		tcp_init_cwnd_reduction(sk);
 	}
 	tcp_set_ca_state(sk, TCP_CA_Recovery);
 }
@@ -3330,7 +3329,7 @@ static void tcp_process_tlp_ack(struct sock *sk, u32 ack, int flag)
 		tp->tlp_high_seq = 0;
 		/* Don't reduce cwnd if DSACK arrives for TLP retrans. */
 		if (!(flag & FLAG_DSACKING_ACK)) {
-			tcp_init_cwnd_reduction(sk, true);
+			tcp_init_cwnd_reduction(sk);
 			tcp_set_ca_state(sk, TCP_CA_CWR);
 			tcp_end_cwnd_reduction(sk);
 			tcp_try_keep_open(sk);
diff --git a/net/ipv4/tcp_output.c b/net/ipv4/tcp_output.c
index c2d7ad7cb668..0c6aa7421b2d 100644
--- a/net/ipv4/tcp_output.c
+++ b/net/ipv4/tcp_output.c
@@ -986,7 +986,7 @@ static int tcp_transmit_skb(struct sock *sk, struct sk_buff *skb, int clone_it,
 	if (likely(err <= 0))
 		return err;
 
-	tcp_enter_cwr(sk, 1);
+	tcp_enter_cwr(sk);
 
 	return net_xmit_eval(err);
 }
