powernv/cpuidle: Redesign idle states management

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [powerpc] powernv: Redesign idle states management (Gustavo Duarte) [1123121]
Rebuild_FUZZ: 90.91%
commit-author Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
commit 7cba160ad789a3ad7e68b92bf20eaad6ed171f80
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/7cba160a.failed

Deep idle states like sleep and winkle are per core idle states. A core
enters these states only when all the threads enter either the
particular idle state or a deeper one. There are tasks like fastsleep
hardware bug workaround and hypervisor core state save which have to be
done only by the last thread of the core entering deep idle state and
similarly tasks like timebase resync, hypervisor core register restore
that have to be done only by the first thread waking up from these
state.

The current idle state management does not have a way to distinguish the
first/last thread of the core waking/entering idle states. Tasks like
timebase resync are done for all the threads. This is not only is
suboptimal, but can cause functionality issues when subcores and kvm is
involved.

This patch adds the necessary infrastructure to track idle states of
threads in a per-core structure. It uses this info to perform tasks like
fastsleep workaround and timebase resync only once per core.

	Signed-off-by: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
Originally-by: Preeti U. Murthy <preeti@linux.vnet.ibm.com>
	Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
	Cc: Paul Mackerras <paulus@samba.org>
	Cc: Michael Ellerman <mpe@ellerman.id.au>
	Cc: Rafael J. Wysocki <rjw@rjwysocki.net>
	Cc: linux-pm@vger.kernel.org
	Cc: linuxppc-dev@lists.ozlabs.org
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
(cherry picked from commit 7cba160ad789a3ad7e68b92bf20eaad6ed171f80)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/include/asm/opal.h
#	arch/powerpc/include/asm/paca.h
#	arch/powerpc/kernel/asm-offsets.c
#	arch/powerpc/kernel/idle_power7.S
#	arch/powerpc/platforms/powernv/opal-wrappers.S
#	arch/powerpc/platforms/powernv/setup.c
#	arch/powerpc/platforms/powernv/smp.c
#	drivers/cpuidle/cpuidle-powernv.c
diff --cc arch/powerpc/include/asm/opal.h
index e795ae10954f,3dea31c1080c..000000000000
--- a/arch/powerpc/include/asm/opal.h
+++ b/arch/powerpc/include/asm/opal.h
@@@ -146,9 -155,28 +146,32 @@@ struct opal_sg_list 
  #define OPAL_GET_PARAM				89
  #define OPAL_SET_PARAM				90
  #define OPAL_DUMP_RESEND			91
 -#define OPAL_PCI_SET_PHB_CXL_MODE		93
  #define OPAL_DUMP_INFO2				94
++<<<<<<< HEAD
 +#define OPAL_REGISTER_DUMP_REGION		101
 +#define OPAL_UNREGISTER_DUMP_REGION		102
++=======
+ #define OPAL_PCI_ERR_INJECT			96
+ #define OPAL_PCI_EEH_FREEZE_SET			97
+ #define OPAL_HANDLE_HMI				98
+ #define OPAL_CONFIG_CPU_IDLE_STATE		99
+ #define OPAL_REGISTER_DUMP_REGION		101
+ #define OPAL_UNREGISTER_DUMP_REGION		102
+ #define OPAL_WRITE_TPO				103
+ #define OPAL_READ_TPO				104
+ #define OPAL_IPMI_SEND				107
+ #define OPAL_IPMI_RECV				108
+ #define OPAL_I2C_REQUEST			109
+ 
+ /* Device tree flags */
+ 
+ /* Flags set in power-mgmt nodes in device tree if
+  * respective idle states are supported in the platform.
+  */
+ #define OPAL_PM_NAP_ENABLED	0x00010000
+ #define OPAL_PM_SLEEP_ENABLED	0x00020000
+ #define OPAL_PM_SLEEP_ENABLED_ER1	0x00080000
++>>>>>>> 7cba160ad789 (powernv/cpuidle: Redesign idle states management)
  
  #ifndef __ASSEMBLY__
  
diff --cc arch/powerpc/include/asm/paca.h
index 82270c09d005,a0a16847bd40..000000000000
--- a/arch/powerpc/include/asm/paca.h
+++ b/arch/powerpc/include/asm/paca.h
@@@ -149,11 -153,13 +149,21 @@@ struct paca_struct 
  #endif
  
  #ifdef CONFIG_PPC_POWERNV
++<<<<<<< HEAD
 +	/* Pointer to OPAL machine check event structure set by the
 +	 * early exception handler for use by high level C handler
 +	 */
 +	struct opal_machine_check_event *opal_mc_evt;
 +#endif
++=======
+ 	/* Per-core mask tracking idle threads and a lock bit-[L][TTTTTTTT] */
+ 	u32 *core_idle_state_ptr;
+ 	u8 thread_idle_state;		/* PNV_THREAD_RUNNING/NAP/SLEEP	*/
+ 	/* Mask to indicate thread id in core */
+ 	u8 thread_mask;
+ #endif
+ 
++>>>>>>> 7cba160ad789 (powernv/cpuidle: Redesign idle states management)
  #ifdef CONFIG_PPC_BOOK3S_64
  	/* Exclusive emergency stack pointer for machine check exception. */
  	void *mc_emergency_sp;
diff --cc arch/powerpc/kernel/asm-offsets.c
index 3b59d088fb8a,bbd27fe0c039..000000000000
--- a/arch/powerpc/kernel/asm-offsets.c
+++ b/arch/powerpc/kernel/asm-offsets.c
@@@ -719,10 -727,12 +719,19 @@@ int main(void
  #endif
  
  #ifdef CONFIG_PPC_POWERNV
++<<<<<<< HEAD
 +	DEFINE(OPAL_MC_GPR3, offsetof(struct opal_machine_check_event, gpr3));
 +	DEFINE(OPAL_MC_SRR0, offsetof(struct opal_machine_check_event, srr0));
 +	DEFINE(OPAL_MC_SRR1, offsetof(struct opal_machine_check_event, srr1));
 +	DEFINE(PACA_OPAL_MC_EVT, offsetof(struct paca_struct, opal_mc_evt));
++=======
+ 	DEFINE(PACA_CORE_IDLE_STATE_PTR,
+ 			offsetof(struct paca_struct, core_idle_state_ptr));
+ 	DEFINE(PACA_THREAD_IDLE_STATE,
+ 			offsetof(struct paca_struct, thread_idle_state));
+ 	DEFINE(PACA_THREAD_MASK,
+ 			offsetof(struct paca_struct, thread_mask));
++>>>>>>> 7cba160ad789 (powernv/cpuidle: Redesign idle states management)
  #endif
  
  	return 0;
diff --cc arch/powerpc/kernel/idle_power7.S
index 60fb4853cd9a,0f2c113c8ca5..000000000000
--- a/arch/powerpc/kernel/idle_power7.S
+++ b/arch/powerpc/kernel/idle_power7.S
@@@ -151,20 -197,127 +197,140 @@@ _GLOBAL(power7_sleep
  	b	power7_powersave_common
  	/* No return */
  
++<<<<<<< HEAD
++=======
+ #define CHECK_HMI_INTERRUPT						\
+ 	mfspr	r0,SPRN_SRR1;						\
+ BEGIN_FTR_SECTION_NESTED(66);						\
+ 	rlwinm	r0,r0,45-31,0xf;  /* extract wake reason field (P8) */	\
+ FTR_SECTION_ELSE_NESTED(66);						\
+ 	rlwinm	r0,r0,45-31,0xe;  /* P7 wake reason field is 3 bits */	\
+ ALT_FTR_SECTION_END_NESTED_IFSET(CPU_FTR_ARCH_207S, 66);		\
+ 	cmpwi	r0,0xa;			/* Hypervisor maintenance ? */	\
+ 	bne	20f;							\
+ 	/* Invoke opal call to handle hmi */				\
+ 	ld	r2,PACATOC(r13);					\
+ 	ld	r1,PACAR1(r13);						\
+ 	std	r3,ORIG_GPR3(r1);	/* Save original r3 */		\
+ 	li	r0,OPAL_HANDLE_HMI;	/* Pass opal token argument*/	\
+ 	bl	opal_call_realmode;					\
+ 	ld	r3,ORIG_GPR3(r1);	/* Restore original r3 */	\
+ 20:	nop;
+ 
+ 
++>>>>>>> 7cba160ad789 (powernv/cpuidle: Redesign idle states management)
  _GLOBAL(power7_wakeup_tb_loss)
  	ld	r2,PACATOC(r13);
  	ld	r1,PACAR1(r13)
+ 	/*
+ 	 * Before entering any idle state, the NVGPRs are saved in the stack
+ 	 * and they are restored before switching to the process context. Hence
+ 	 * until they are restored, they are free to be used.
+ 	 *
+ 	 * Save SRR1 in a NVGPR as it might be clobbered in opal_call_realmode
+ 	 * (called in CHECK_HMI_INTERRUPT). SRR1 is required to determine the
+ 	 * wakeup reason if we branch to kvm_start_guest.
+ 	 */
  
++<<<<<<< HEAD
 +	/* Time base re-sync */
 +	li	r0,OPAL_RESYNC_TIMEBASE
 +	LOAD_REG_ADDR(r11,opal);
 +	ld	r12,8(r11);
 +	ld	r2,0(r11);
 +	mtctr	r12
 +	bctrl
++=======
+ 	mfspr	r16,SPRN_SRR1
+ BEGIN_FTR_SECTION
+ 	CHECK_HMI_INTERRUPT
+ END_FTR_SECTION_IFSET(CPU_FTR_HVMODE)
++>>>>>>> 7cba160ad789 (powernv/cpuidle: Redesign idle states management)
  
+ 	lbz	r7,PACA_THREAD_MASK(r13)
+ 	ld	r14,PACA_CORE_IDLE_STATE_PTR(r13)
+ lwarx_loop2:
+ 	lwarx	r15,0,r14
+ 	andi.	r9,r15,PNV_CORE_IDLE_LOCK_BIT
+ 	/*
+ 	 * Lock bit is set in one of the 2 cases-
+ 	 * a. In the sleep/winkle enter path, the last thread is executing
+ 	 * fastsleep workaround code.
+ 	 * b. In the wake up path, another thread is executing fastsleep
+ 	 * workaround undo code or resyncing timebase or restoring context
+ 	 * In either case loop until the lock bit is cleared.
+ 	 */
+ 	bne	core_idle_lock_held
+ 
+ 	cmpwi	cr2,r15,0
+ 	or	r15,r15,r7		/* Set thread bit */
+ 
+ 	beq	cr2,first_thread
+ 
+ 	/* Not first thread in core to wake up */
+ 	stwcx.	r15,0,r14
+ 	bne-	lwarx_loop2
+ 	isync
+ 	b	common_exit
+ 
+ core_idle_lock_held:
+ 	HMT_LOW
+ core_idle_lock_loop:
+ 	lwz	r15,0(14)
+ 	andi.   r9,r15,PNV_CORE_IDLE_LOCK_BIT
+ 	bne	core_idle_lock_loop
+ 	HMT_MEDIUM
+ 	b	lwarx_loop2
+ 
+ first_thread:
+ 	/* First thread in core to wakeup */
+ 	ori	r15,r15,PNV_CORE_IDLE_LOCK_BIT
+ 	stwcx.	r15,0,r14
+ 	bne-	lwarx_loop2
+ 	isync
+ 
+ 	/*
+ 	 * First thread in the core waking up from fastsleep. It needs to
+ 	 * call the fastsleep workaround code if the platform requires it.
+ 	 * Call it unconditionally here. The below branch instruction will
+ 	 * be patched out when the idle states are discovered if platform
+ 	 * does not require workaround.
+ 	 */
+ .global pnv_fastsleep_workaround_at_exit
+ pnv_fastsleep_workaround_at_exit:
+ 	b	fastsleep_workaround_at_exit
+ 
+ timebase_resync:
+ 	/* Do timebase resync if we are waking up from sleep. Use cr3 value
+ 	 * set in exceptions-64s.S */
+ 	ble	cr3,clear_lock
+ 	/* Time base re-sync */
+ 	li	r0,OPAL_RESYNC_TIMEBASE
+ 	bl	opal_call_realmode;
  	/* TODO: Check r3 for failure */
  
+ clear_lock:
+ 	andi.	r15,r15,PNV_CORE_IDLE_THREAD_BITS
+ 	lwsync
+ 	stw	r15,0(r14)
+ 
+ common_exit:
+ 	li	r5,PNV_THREAD_RUNNING
+ 	stb     r5,PACA_THREAD_IDLE_STATE(r13)
+ 
+ 	mtspr	SPRN_SRR1,r16
+ #ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE
+ 	li      r0,KVM_HWTHREAD_IN_KERNEL
+ 	stb     r0,HSTATE_HWTHREAD_STATE(r13)
+ 	/* Order setting hwthread_state vs. testing hwthread_req */
+ 	sync
+ 	lbz     r0,HSTATE_HWTHREAD_REQ(r13)
+ 	cmpwi   r0,0
+ 	beq     6f
+ 	b       kvm_start_guest
+ 6:
+ #endif
+ 
  	REST_NVGPRS(r1)
  	REST_GPR(2, r1)
  	ld	r3,_CCR(r1)
diff --cc arch/powerpc/platforms/powernv/opal-wrappers.S
index 0f016cb7a5f5,78289ed7058c..000000000000
--- a/arch/powerpc/platforms/powernv/opal-wrappers.S
+++ b/arch/powerpc/platforms/powernv/opal-wrappers.S
@@@ -61,6 -100,101 +61,104 @@@ opal_return
  	mtcr	r4;
  	rfid
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_TRACEPOINTS
+ opal_tracepoint_entry:
+ 	stdu	r1,-STACKFRAMESIZE(r1)
+ 	std	r0,STK_REG(R23)(r1)
+ 	std	r3,STK_REG(R24)(r1)
+ 	std	r4,STK_REG(R25)(r1)
+ 	std	r5,STK_REG(R26)(r1)
+ 	std	r6,STK_REG(R27)(r1)
+ 	std	r7,STK_REG(R28)(r1)
+ 	std	r8,STK_REG(R29)(r1)
+ 	std	r9,STK_REG(R30)(r1)
+ 	std	r10,STK_REG(R31)(r1)
+ 	mr	r3,r0
+ 	addi	r4,r1,STK_REG(R24)
+ 	bl	__trace_opal_entry
+ 	ld	r0,STK_REG(R23)(r1)
+ 	ld	r3,STK_REG(R24)(r1)
+ 	ld	r4,STK_REG(R25)(r1)
+ 	ld	r5,STK_REG(R26)(r1)
+ 	ld	r6,STK_REG(R27)(r1)
+ 	ld	r7,STK_REG(R28)(r1)
+ 	ld	r8,STK_REG(R29)(r1)
+ 	ld	r9,STK_REG(R30)(r1)
+ 	ld	r10,STK_REG(R31)(r1)
+ 	LOAD_REG_ADDR(r11,opal_tracepoint_return)
+ 	mfcr	r12
+ 	std	r11,16(r1)
+ 	stw	r12,8(r1)
+ 	std	r1,PACAR1(r13)
+ 	li	r11,0
+ 	mfmsr	r12
+ 	ori	r11,r11,MSR_EE
+ 	std	r12,PACASAVEDMSR(r13)
+ 	andc	r12,r12,r11
+ 	mtmsrd	r12,1
+ 	LOAD_REG_ADDR(r11,opal_return)
+ 	mtlr	r11
+ 	li	r11,MSR_DR|MSR_IR|MSR_LE
+ 	andc	r12,r12,r11
+ 	mtspr	SPRN_HSRR1,r12
+ 	LOAD_REG_ADDR(r11,opal)
+ 	ld	r12,8(r11)
+ 	ld	r2,0(r11)
+ 	mtspr	SPRN_HSRR0,r12
+ 	hrfid
+ 
+ opal_tracepoint_return:
+ 	std	r3,STK_REG(R31)(r1)
+ 	mr	r4,r3
+ 	ld	r0,STK_REG(R23)(r1)
+ 	bl	__trace_opal_exit
+ 	ld	r3,STK_REG(R31)(r1)
+ 	addi	r1,r1,STACKFRAMESIZE
+ 	ld	r0,16(r1)
+ 	mtlr	r0
+ 	blr
+ #endif
+ 
+ /*
+  * Make opal call in realmode. This is a generic function to be called
+  * from realmode. It handles endianness.
+  *
+  * r13 - paca pointer
+  * r1  - stack pointer
+  * r0  - opal token
+  */
+ _GLOBAL(opal_call_realmode)
+ 	mflr	r12
+ 	std	r12,PPC_LR_STKOFF(r1)
+ 	ld	r2,PACATOC(r13)
+ 	/* Set opal return address */
+ 	LOAD_REG_ADDR(r12,return_from_opal_call)
+ 	mtlr	r12
+ 
+ 	mfmsr	r12
+ #ifdef __LITTLE_ENDIAN__
+ 	/* Handle endian-ness */
+ 	li	r11,MSR_LE
+ 	andc	r12,r12,r11
+ #endif
+ 	mtspr	SPRN_HSRR1,r12
+ 	LOAD_REG_ADDR(r11,opal)
+ 	ld	r12,8(r11)
+ 	ld	r2,0(r11)
+ 	mtspr	SPRN_HSRR0,r12
+ 	hrfid
+ 
+ return_from_opal_call:
+ #ifdef __LITTLE_ENDIAN__
+ 	FIXUP_ENDIAN
+ #endif
+ 	ld	r12,PPC_LR_STKOFF(r1)
+ 	mtlr	r12
+ 	blr
+ 
++>>>>>>> 7cba160ad789 (powernv/cpuidle: Redesign idle states management)
  OPAL_CALL(opal_invalid_call,			OPAL_INVALID_CALL);
  OPAL_CALL(opal_console_write,			OPAL_CONSOLE_WRITE);
  OPAL_CALL(opal_console_read,			OPAL_CONSOLE_READ);
diff --cc arch/powerpc/platforms/powernv/setup.c
index d9b88fa7c5a3,2e9b53bb73e2..000000000000
--- a/arch/powerpc/platforms/powernv/setup.c
+++ b/arch/powerpc/platforms/powernv/setup.c
@@@ -280,6 -291,97 +283,100 @@@ static void __init pnv_setup_machdep_rt
  }
  #endif /* CONFIG_PPC_POWERNV_RTAS */
  
++<<<<<<< HEAD
++=======
+ static u32 supported_cpuidle_states;
+ 
+ static void pnv_alloc_idle_core_states(void)
+ {
+ 	int i, j;
+ 	int nr_cores = cpu_nr_cores();
+ 	u32 *core_idle_state;
+ 
+ 	/*
+ 	 * core_idle_state - First 8 bits track the idle state of each thread
+ 	 * of the core. The 8th bit is the lock bit. Initially all thread bits
+ 	 * are set. They are cleared when the thread enters deep idle state
+ 	 * like sleep and winkle. Initially the lock bit is cleared.
+ 	 * The lock bit has 2 purposes
+ 	 * a. While the first thread is restoring core state, it prevents
+ 	 * other threads in the core from switching to process context.
+ 	 * b. While the last thread in the core is saving the core state, it
+ 	 * prevents a different thread from waking up.
+ 	 */
+ 	for (i = 0; i < nr_cores; i++) {
+ 		int first_cpu = i * threads_per_core;
+ 		int node = cpu_to_node(first_cpu);
+ 
+ 		core_idle_state = kmalloc_node(sizeof(u32), GFP_KERNEL, node);
+ 		*core_idle_state = PNV_CORE_IDLE_THREAD_BITS;
+ 
+ 		for (j = 0; j < threads_per_core; j++) {
+ 			int cpu = first_cpu + j;
+ 
+ 			paca[cpu].core_idle_state_ptr = core_idle_state;
+ 			paca[cpu].thread_idle_state = PNV_THREAD_RUNNING;
+ 			paca[cpu].thread_mask = 1 << j;
+ 		}
+ 	}
+ }
+ 
+ u32 pnv_get_supported_cpuidle_states(void)
+ {
+ 	return supported_cpuidle_states;
+ }
+ EXPORT_SYMBOL_GPL(pnv_get_supported_cpuidle_states);
+ 
+ static int __init pnv_init_idle_states(void)
+ {
+ 	struct device_node *power_mgt;
+ 	int dt_idle_states;
+ 	const __be32 *idle_state_flags;
+ 	u32 len_flags, flags;
+ 	int i;
+ 
+ 	supported_cpuidle_states = 0;
+ 
+ 	if (cpuidle_disable != IDLE_NO_OVERRIDE)
+ 		return 0;
+ 
+ 	if (!firmware_has_feature(FW_FEATURE_OPALv3))
+ 		return 0;
+ 
+ 	power_mgt = of_find_node_by_path("/ibm,opal/power-mgt");
+ 	if (!power_mgt) {
+ 		pr_warn("opal: PowerMgmt Node not found\n");
+ 		return 0;
+ 	}
+ 
+ 	idle_state_flags = of_get_property(power_mgt,
+ 			"ibm,cpu-idle-state-flags", &len_flags);
+ 	if (!idle_state_flags) {
+ 		pr_warn("DT-PowerMgmt: missing ibm,cpu-idle-state-flags\n");
+ 		return 0;
+ 	}
+ 
+ 	dt_idle_states = len_flags / sizeof(u32);
+ 
+ 	for (i = 0; i < dt_idle_states; i++) {
+ 		flags = be32_to_cpu(idle_state_flags[i]);
+ 		supported_cpuidle_states |= flags;
+ 	}
+ 	if (!(supported_cpuidle_states & OPAL_PM_SLEEP_ENABLED_ER1)) {
+ 		patch_instruction(
+ 			(unsigned int *)pnv_fastsleep_workaround_at_entry,
+ 			PPC_INST_NOP);
+ 		patch_instruction(
+ 			(unsigned int *)pnv_fastsleep_workaround_at_exit,
+ 			PPC_INST_NOP);
+ 	}
+ 	pnv_alloc_idle_core_states();
+ 	return 0;
+ }
+ 
+ subsys_initcall(pnv_init_idle_states);
+ 
++>>>>>>> 7cba160ad789 (powernv/cpuidle: Redesign idle states management)
  static int __init pnv_probe(void)
  {
  	unsigned long root = of_get_flat_dt_root();
diff --cc arch/powerpc/platforms/powernv/smp.c
index 1c14ba216c76,c0691d0fb385..000000000000
--- a/arch/powerpc/platforms/powernv/smp.c
+++ b/arch/powerpc/platforms/powernv/smp.c
@@@ -166,7 -168,11 +166,15 @@@ static void pnv_smp_cpu_kill_self(void
  	mtspr(SPRN_LPCR, mfspr(SPRN_LPCR) & ~(u64)LPCR_PECE1);
  	while (!generic_check_cpu_restart(cpu)) {
  		ppc64_runlatch_off();
++<<<<<<< HEAD
 +		srr1 = power7_nap(1);
++=======
+ 		if ((idle_states & OPAL_PM_SLEEP_ENABLED) ||
+ 				(idle_states & OPAL_PM_SLEEP_ENABLED_ER1))
+ 			srr1 = power7_sleep();
+ 		else
+ 			srr1 = power7_nap(1);
++>>>>>>> 7cba160ad789 (powernv/cpuidle: Redesign idle states management)
  		ppc64_runlatch_on();
  
  		/*
diff --cc drivers/cpuidle/cpuidle-powernv.c
index a64be578dab2,a489b56e92df..000000000000
--- a/drivers/cpuidle/cpuidle-powernv.c
+++ b/drivers/cpuidle/cpuidle-powernv.c
@@@ -196,7 -208,8 +196,12 @@@ static int powernv_add_idle_states(void
  			nr_idle_states++;
  		}
  
++<<<<<<< HEAD
 +		if (flags & IDLE_USE_INST_SLEEP) {
++=======
+ 		if (flags & OPAL_PM_SLEEP_ENABLED ||
+ 			flags & OPAL_PM_SLEEP_ENABLED_ER1) {
++>>>>>>> 7cba160ad789 (powernv/cpuidle: Redesign idle states management)
  			/* Add FASTSLEEP state */
  			strcpy(powernv_states[nr_idle_states].name, "FastSleep");
  			strcpy(powernv_states[nr_idle_states].desc, "FastSleep");
diff --git a/arch/powerpc/include/asm/cpuidle.h b/arch/powerpc/include/asm/cpuidle.h
new file mode 100644
index 000000000000..d2f99ca1e3a6
--- /dev/null
+++ b/arch/powerpc/include/asm/cpuidle.h
@@ -0,0 +1,20 @@
+#ifndef _ASM_POWERPC_CPUIDLE_H
+#define _ASM_POWERPC_CPUIDLE_H
+
+#ifdef CONFIG_PPC_POWERNV
+/* Used in powernv idle state management */
+#define PNV_THREAD_RUNNING              0
+#define PNV_THREAD_NAP                  1
+#define PNV_THREAD_SLEEP                2
+#define PNV_THREAD_WINKLE               3
+#define PNV_CORE_IDLE_LOCK_BIT          0x100
+#define PNV_CORE_IDLE_THREAD_BITS       0x0FF
+
+#ifndef __ASSEMBLY__
+extern u32 pnv_fastsleep_workaround_at_entry[];
+extern u32 pnv_fastsleep_workaround_at_exit[];
+#endif
+
+#endif
+
+#endif
* Unmerged path arch/powerpc/include/asm/opal.h
* Unmerged path arch/powerpc/include/asm/paca.h
diff --git a/arch/powerpc/include/asm/processor.h b/arch/powerpc/include/asm/processor.h
index 208b4e9bf7ec..2cb4ddea578b 100644
--- a/arch/powerpc/include/asm/processor.h
+++ b/arch/powerpc/include/asm/processor.h
@@ -497,7 +497,7 @@ enum idle_boot_override {IDLE_NO_OVERRIDE = 0, IDLE_POWERSAVE_OFF};
 
 extern int powersave_nap;	/* set if nap mode can be used in idle loop */
 extern unsigned long power7_nap(int check_irq);
-extern void power7_sleep(void);
+extern unsigned long power7_sleep(void);
 extern void flush_instruction_cache(void);
 extern void hard_reset_now(void);
 extern void poweroff_now(void);
* Unmerged path arch/powerpc/kernel/asm-offsets.c
diff --git a/arch/powerpc/kernel/exceptions-64s.S b/arch/powerpc/kernel/exceptions-64s.S
index 82b10f56e2a0..d7271cc9f945 100644
--- a/arch/powerpc/kernel/exceptions-64s.S
+++ b/arch/powerpc/kernel/exceptions-64s.S
@@ -15,6 +15,7 @@
 #include <asm/hw_irq.h>
 #include <asm/exception-64s.h>
 #include <asm/ptrace.h>
+#include <asm/cpuidle.h>
 
 /*
  * We layout physical memory as follows:
@@ -109,15 +110,19 @@ BEGIN_FTR_SECTION
 	rlwinm.	r13,r13,47-31,30,31
 	beq	9f
 
-	/* waking up from powersave (nap) state */
-	cmpwi	cr1,r13,2
-	/* Total loss of HV state is fatal, we could try to use the
-	 * PIR to locate a PACA, then use an emergency stack etc...
-	 * OPAL v3 based powernv platforms have new idle states
-	 * which fall in this catagory.
-	 */
-	bgt	cr1,8f
+	cmpwi	cr3,r13,2
+
 	GET_PACA(r13)
+	lbz	r0,PACA_THREAD_IDLE_STATE(r13)
+	cmpwi   cr2,r0,PNV_THREAD_NAP
+	bgt     cr2,8f				/* Either sleep or Winkle */
+
+	/* Waking up from nap should not cause hypervisor state loss */
+	bgt	cr3,.
+
+	/* Waking up from nap */
+	li	r0,PNV_THREAD_RUNNING
+	stb	r0,PACA_THREAD_IDLE_STATE(r13)	/* Clear thread state */
 
 #ifdef CONFIG_KVM_BOOK3S_HV_POSSIBLE
 	li	r0,KVM_HWTHREAD_IN_KERNEL
@@ -133,7 +138,7 @@ BEGIN_FTR_SECTION
 
 	/* Return SRR1 from power7_nap() */
 	mfspr	r3,SPRN_SRR1
-	beq	cr1,2f
+	beq	cr3,2f
 	b	power7_wakeup_noloss
 2:	b	power7_wakeup_loss
 
@@ -1431,6 +1436,7 @@ machine_check_handle_early:
 	MACHINE_CHECK_HANDLER_WINDUP
 	GET_PACA(r13)
 	ld	r1,PACAR1(r13)
+	li	r3,PNV_THREAD_NAP
 	b	power7_enter_nap_mode
 4:
 #endif
* Unmerged path arch/powerpc/kernel/idle_power7.S
* Unmerged path arch/powerpc/platforms/powernv/opal-wrappers.S
* Unmerged path arch/powerpc/platforms/powernv/setup.c
* Unmerged path arch/powerpc/platforms/powernv/smp.c
* Unmerged path drivers/cpuidle/cpuidle-powernv.c
