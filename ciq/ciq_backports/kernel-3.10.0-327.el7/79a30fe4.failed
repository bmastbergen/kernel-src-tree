perf tools: Make perf_session__deliver_event global

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [tools] perf: Make perf_session__deliver_event global (Jiri Olsa) [1169436]
Rebuild_FUZZ: 93.75%
commit-author Jiri Olsa <jolsa@kernel.org>
commit 79a30fe4f3758c98e1b7a474952b9701d513e580
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/79a30fe4.failed

Making perf_session__deliver_event global function, as it will be called
from another object in following patch.

	Signed-off-by: Jiri Olsa <jolsa@kernel.org>
	Acked-by: David Ahern <dsahern@gmail.com>
	Cc: Corey Ashford <cjashfor@linux.vnet.ibm.com>
	Cc: David Ahern <dsahern@gmail.com>
	Cc: Frederic Weisbecker <fweisbec@gmail.com>
	Cc: Ingo Molnar <mingo@kernel.org>
	Cc: Jean Pihet <jean.pihet@linaro.org>
	Cc: Namhyung Kim <namhyung@kernel.org>
	Cc: Paul Mackerras <paulus@samba.org>
	Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
Link: http://lkml.kernel.org/n/tip-rz7s2b8uwv567bigckh75gvk@git.kernel.org
[ Fixup naming to match class__method schema, as now is more widely exposed ]
	Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
(cherry picked from commit 79a30fe4f3758c98e1b7a474952b9701d513e580)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/perf/util/session.c
diff --cc tools/perf/util/session.c
index 8f2eedc2c5c3,ed6b7f14631f..000000000000
--- a/tools/perf/util/session.c
+++ b/tools/perf/util/session.c
@@@ -469,11 -473,103 +469,111 @@@ static void perf_session_free_sample_bu
  	}
  }
  
++<<<<<<< HEAD
 +static int perf_session_deliver_event(struct perf_session *session,
 +				      union perf_event *event,
 +				      struct perf_sample *sample,
 +				      struct perf_tool *tool,
 +				      u64 file_offset);
++=======
+ /* The queue is ordered by time */
+ static void queue_event(struct ordered_events *oe, struct ordered_event *new)
+ {
+ 	struct ordered_event *last = oe->last;
+ 	u64 timestamp = new->timestamp;
+ 	struct list_head *p;
+ 
+ 	++oe->nr_events;
+ 	oe->last = new;
+ 
+ 	if (!last) {
+ 		list_add(&new->list, &oe->events);
+ 		oe->max_timestamp = timestamp;
+ 		return;
+ 	}
+ 
+ 	/*
+ 	 * last event might point to some random place in the list as it's
+ 	 * the last queued event. We expect that the new event is close to
+ 	 * this.
+ 	 */
+ 	if (last->timestamp <= timestamp) {
+ 		while (last->timestamp <= timestamp) {
+ 			p = last->list.next;
+ 			if (p == &oe->events) {
+ 				list_add_tail(&new->list, &oe->events);
+ 				oe->max_timestamp = timestamp;
+ 				return;
+ 			}
+ 			last = list_entry(p, struct ordered_event, list);
+ 		}
+ 		list_add_tail(&new->list, &last->list);
+ 	} else {
+ 		while (last->timestamp > timestamp) {
+ 			p = last->list.prev;
+ 			if (p == &oe->events) {
+ 				list_add(&new->list, &oe->events);
+ 				return;
+ 			}
+ 			last = list_entry(p, struct ordered_event, list);
+ 		}
+ 		list_add(&new->list, &last->list);
+ 	}
+ }
+ 
+ #define MAX_SAMPLE_BUFFER	(64 * 1024 / sizeof(struct ordered_event))
+ static struct ordered_event *alloc_event(struct ordered_events *oe)
+ {
+ 	struct list_head *cache = &oe->cache;
+ 	struct ordered_event *new = NULL;
+ 
+ 	if (!list_empty(cache)) {
+ 		new = list_entry(cache->next, struct ordered_event, list);
+ 		list_del(&new->list);
+ 	} else if (oe->buffer) {
+ 		new = oe->buffer + oe->buffer_idx;
+ 		if (++oe->buffer_idx == MAX_SAMPLE_BUFFER)
+ 			oe->buffer = NULL;
+ 	} else if (oe->cur_alloc_size < oe->max_alloc_size) {
+ 		size_t size = MAX_SAMPLE_BUFFER * sizeof(*new);
+ 
+ 		oe->buffer = malloc(size);
+ 		if (!oe->buffer)
+ 			return NULL;
+ 
+ 		oe->cur_alloc_size += size;
+ 		list_add(&oe->buffer->list, &oe->to_free);
+ 
+ 		/* First entry is abused to maintain the to_free list. */
+ 		oe->buffer_idx = 2;
+ 		new = oe->buffer + 1;
+ 	}
+ 
+ 	return new;
+ }
+ 
+ static struct ordered_event *
+ ordered_events__new(struct ordered_events *oe, u64 timestamp)
+ {
+ 	struct ordered_event *new;
+ 
+ 	new = alloc_event(oe);
+ 	if (new) {
+ 		new->timestamp = timestamp;
+ 		queue_event(oe, new);
+ 	}
+ 
+ 	return new;
+ }
+ 
+ static void
+ ordered_events__delete(struct ordered_events *oe, struct ordered_event *event)
+ {
+ 	list_del(&event->list);
+ 	list_add(&event->list, &oe->cache);
+ 	oe->nr_events--;
+ }
++>>>>>>> 79a30fe4f375 (perf tools: Make perf_session__deliver_event global)
  
  static int __ordered_events__flush(struct perf_session *s,
  				   struct perf_tool *tool)
* Unmerged path tools/perf/util/session.c
diff --git a/tools/perf/util/session.h b/tools/perf/util/session.h
index 419eb50e1cd3..fcc7930809eb 100644
--- a/tools/perf/util/session.h
+++ b/tools/perf/util/session.h
@@ -69,6 +69,11 @@ int perf_session_queue_event(struct perf_session *s, union perf_event *event,
 
 void perf_tool__fill_defaults(struct perf_tool *tool);
 
+int perf_session__deliver_event(struct perf_session *session,
+				union perf_event *event,
+				struct perf_sample *sample,
+				struct perf_tool *tool, u64 file_offset);
+
 int perf_session__resolve_callchain(struct perf_session *session,
 				    struct perf_evsel *evsel,
 				    struct thread *thread,
