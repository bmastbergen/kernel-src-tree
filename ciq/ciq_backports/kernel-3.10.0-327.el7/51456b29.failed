ipv4: coding style: comparison for equality with NULL

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [net] geneve: coding style: comparison for equality with NULL (Jiri Benc) [1156461 1211348]
Rebuild_FUZZ: 92.59%
commit-author Ian Morris <ipm@chirality.org.uk>
commit 51456b2914a34d16b1255b7c55d5cbf6a681d306
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/51456b29.failed

The ipv4 code uses a mixture of coding styles. In some instances check
for NULL pointer is done as x == NULL and sometimes as !x. !x is
preferred according to checkpatch and this patch makes the code
consistent by adopting the latter form.

No changes detected by objdiff.

	Signed-off-by: Ian Morris <ipm@chirality.org.uk>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 51456b2914a34d16b1255b7c55d5cbf6a681d306)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/ipv4/arp.c
#	net/ipv4/fib_frontend.c
#	net/ipv4/fib_trie.c
#	net/ipv4/icmp.c
#	net/ipv4/inet_fragment.c
#	net/ipv4/ip_sockglue.c
#	net/ipv4/ipmr.c
#	net/ipv4/ping.c
#	net/ipv4/tcp_fastopen.c
#	net/ipv4/tcp_input.c
#	net/ipv4/tcp_output.c
diff --cc net/ipv4/arp.c
index d2b96c3354dc,ffe84226a2c8..000000000000
--- a/net/ipv4/arp.c
+++ b/net/ipv4/arp.c
@@@ -896,10 -805,12 +896,19 @@@ static int arp_process(struct sk_buff *
  		   It is possible, that this option should be enabled for some
  		   devices (strip is candidate)
  		 */
++<<<<<<< HEAD
 +		if (n == NULL &&
 +		    (arp->ar_op == htons(ARPOP_REPLY) ||
 +		     (arp->ar_op == htons(ARPOP_REQUEST) && tip == sip)) &&
 +		    inet_addr_type(net, sip) == RTN_UNICAST)
++=======
+ 		is_garp = arp->ar_op == htons(ARPOP_REQUEST) && tip == sip &&
+ 			  inet_addr_type(net, sip) == RTN_UNICAST;
+ 
+ 		if (!n &&
+ 		    ((arp->ar_op == htons(ARPOP_REPLY)  &&
+ 		      inet_addr_type(net, sip) == RTN_UNICAST) || is_garp))
++>>>>>>> 51456b2914a3 (ipv4: coding style: comparison for equality with NULL)
  			n = __neigh_lookup(&arp_tbl, &sip, dev, 1);
  	}
  
diff --cc net/ipv4/fib_frontend.c
index 23a5b44b74a0,2166d2bf1562..000000000000
--- a/net/ipv4/fib_frontend.c
+++ b/net/ipv4/fib_frontend.c
@@@ -52,12 -52,12 +52,21 @@@ static int __net_init fib4_rules_init(s
  {
  	struct fib_table *local_table, *main_table;
  
++<<<<<<< HEAD
 +	local_table = fib_trie_table(RT_TABLE_LOCAL);
 +	if (local_table == NULL)
 +		return -ENOMEM;
 +
 +	main_table  = fib_trie_table(RT_TABLE_MAIN);
 +	if (main_table == NULL)
++=======
+ 	main_table  = fib_trie_table(RT_TABLE_MAIN, NULL);
+ 	if (!main_table)
+ 		return -ENOMEM;
+ 
+ 	local_table = fib_trie_table(RT_TABLE_LOCAL, main_table);
+ 	if (!local_table)
++>>>>>>> 51456b2914a3 (ipv4: coding style: comparison for equality with NULL)
  		goto fail;
  
  	hlist_add_head_rcu(&local_table->tb_hlist,
diff --cc net/ipv4/fib_trie.c
index 8be89b1a8b93,9e4a3e3423b4..000000000000
--- a/net/ipv4/fib_trie.c
+++ b/net/ipv4/fib_trie.c
@@@ -381,17 -382,18 +381,17 @@@ static inline int tnode_full(const stru
  /* Add a child at position i overwriting the old value.
   * Update the value of full_children and empty_children.
   */
 -static void put_child(struct key_vector *tn, unsigned long i,
 -		      struct key_vector *n)
 +static void put_child(struct tnode *tn, unsigned long i, struct tnode *n)
  {
 -	struct key_vector *chi = get_child(tn, i);
 +	struct tnode *chi = tnode_get_child(tn, i);
  	int isfull, wasfull;
  
 -	BUG_ON(i >= child_length(tn));
 +	BUG_ON(i >= tnode_child_length(tn));
  
  	/* update emptyChildren, overflow into fullChildren */
- 	if (n == NULL && chi != NULL)
+ 	if (!n && chi != NULL)
  		empty_child_inc(tn);
- 	if (n != NULL && chi == NULL)
+ 	if (n != NULL && !chi)
  		empty_child_dec(tn);
  
  	/* update fullChildren */
@@@ -1840,10 -1969,13 +1840,18 @@@ struct fib_table *fib_trie_table(u32 id
  {
  	struct fib_table *tb;
  	struct trie *t;
 -	size_t sz = sizeof(*tb);
  
++<<<<<<< HEAD
 +	tb = kmalloc(sizeof(struct fib_table) + sizeof(struct trie),
 +		     GFP_KERNEL);
 +	if (tb == NULL)
++=======
+ 	if (!alias)
+ 		sz += sizeof(struct trie);
+ 
+ 	tb = kzalloc(sz, GFP_KERNEL);
+ 	if (!tb)
++>>>>>>> 51456b2914a3 (ipv4: coding style: comparison for equality with NULL)
  		return NULL;
  
  	tb->tb_id = id;
diff --cc net/ipv4/icmp.c
index f4c71714a70c,f5203fba6236..000000000000
--- a/net/ipv4/icmp.c
+++ b/net/ipv4/icmp.c
@@@ -561,9 -622,13 +561,14 @@@ void icmp_send(struct sk_buff *skb_in, 
  		}
  	}
  
 -	icmp_param = kmalloc(sizeof(*icmp_param), GFP_ATOMIC);
 -	if (!icmp_param)
 -		return;
 -
  	sk = icmp_xmit_lock(net);
++<<<<<<< HEAD
 +	if (sk == NULL)
 +		return;
++=======
+ 	if (!sk)
+ 		goto out_free;
++>>>>>>> 51456b2914a3 (ipv4: coding style: comparison for equality with NULL)
  
  	/*
  	 *	Construct source address and options.
diff --cc net/ipv4/inet_fragment.c
index af02a39175e3,5e346a082e5f..000000000000
--- a/net/ipv4/inet_fragment.c
+++ b/net/ipv4/inet_fragment.c
@@@ -295,8 -379,13 +295,18 @@@ static struct inet_frag_queue *inet_fra
  {
  	struct inet_frag_queue *q;
  
++<<<<<<< HEAD
 +	q = kzalloc(f->qsize, GFP_ATOMIC);
 +	if (q == NULL)
++=======
+ 	if (frag_mem_limit(nf) > nf->high_thresh) {
+ 		inet_frag_schedule_worker(f);
+ 		return NULL;
+ 	}
+ 
+ 	q = kmem_cache_zalloc(f->frags_cachep, GFP_ATOMIC);
+ 	if (!q)
++>>>>>>> 51456b2914a3 (ipv4: coding style: comparison for equality with NULL)
  		return NULL;
  
  	q->net = nf;
diff --cc net/ipv4/ip_sockglue.c
index ed7a5765c117,f64b1b24c64f..000000000000
--- a/net/ipv4/ip_sockglue.c
+++ b/net/ipv4/ip_sockglue.c
@@@ -398,9 -478,11 +398,14 @@@ int ip_recv_error(struct sock *sk, stru
  	int err;
  	int copied;
  
 -	WARN_ON_ONCE(sk->sk_family == AF_INET6);
 -
  	err = -EAGAIN;
++<<<<<<< HEAD
 +	skb = skb_dequeue(&sk->sk_error_queue);
 +	if (skb == NULL)
++=======
+ 	skb = sock_dequeue_err_skb(sk);
+ 	if (!skb)
++>>>>>>> 51456b2914a3 (ipv4: coding style: comparison for equality with NULL)
  		goto out;
  
  	copied = skb->len;
diff --cc net/ipv4/ipmr.c
index ca997b6766ed,a170e4bc9006..000000000000
--- a/net/ipv4/ipmr.c
+++ b/net/ipv4/ipmr.c
@@@ -503,9 -504,9 +503,9 @@@ static struct net_device *ipmr_reg_vif(
  	else
  		sprintf(name, "pimreg%u", mrt->id);
  
 -	dev = alloc_netdev(0, name, NET_NAME_UNKNOWN, reg_vif_setup);
 +	dev = alloc_netdev(0, name, reg_vif_setup);
  
- 	if (dev == NULL)
+ 	if (!dev)
  		return NULL;
  
  	dev_net_set(dev, net);
@@@ -2265,8 -2266,8 +2265,13 @@@ static int ipmr_fill_mroute(struct mr_t
  	struct rtmsg *rtm;
  	int err;
  
++<<<<<<< HEAD
 +	nlh = nlmsg_put(skb, portid, seq, cmd, sizeof(*rtm), NLM_F_MULTI);
 +	if (nlh == NULL)
++=======
+ 	nlh = nlmsg_put(skb, portid, seq, cmd, sizeof(*rtm), flags);
+ 	if (!nlh)
++>>>>>>> 51456b2914a3 (ipv4: coding style: comparison for equality with NULL)
  		return -EMSGSIZE;
  
  	rtm = nlmsg_data(nlh);
@@@ -2330,10 -2332,10 +2335,10 @@@ static void mroute_netlink_event(struc
  
  	skb = nlmsg_new(mroute_msgsize(mfc->mfc_parent >= MAXVIFS, mrt->maxvif),
  			GFP_ATOMIC);
- 	if (skb == NULL)
+ 	if (!skb)
  		goto errout;
  
 -	err = ipmr_fill_mroute(mrt, skb, 0, 0, mfc, cmd, 0);
 +	err = ipmr_fill_mroute(mrt, skb, 0, 0, mfc, cmd);
  	if (err < 0)
  		goto errout;
  
diff --cc net/ipv4/ping.c
index f0a2419ebdac,2dcd2e60df64..000000000000
--- a/net/ipv4/ping.c
+++ b/net/ipv4/ping.c
@@@ -337,17 -492,31 +337,22 @@@ void ping_err(struct sk_buff *skb, u32 
  	int harderr;
  	int err;
  
 -	if (skb->protocol == htons(ETH_P_IP)) {
 -		family = AF_INET;
 -		type = icmp_hdr(skb)->type;
 -		code = icmp_hdr(skb)->code;
 -		icmph = (struct icmphdr *)(skb->data + offset);
 -	} else if (skb->protocol == htons(ETH_P_IPV6)) {
 -		family = AF_INET6;
 -		type = icmp6_hdr(skb)->icmp6_type;
 -		code = icmp6_hdr(skb)->icmp6_code;
 -		icmph = (struct icmphdr *) (skb->data + offset);
 -	} else {
 -		BUG();
 -	}
 -
  	/* We assume the packet has already been checked by icmp_unreach */
  
 -	if (!ping_supported(family, icmph->type, icmph->code))
 +	if (!ping_supported(icmph->type, icmph->code))
  		return;
  
 -	pr_debug("ping_err(proto=0x%x,type=%d,code=%d,id=%04x,seq=%04x)\n",
 -		 skb->protocol, type, code, ntohs(icmph->un.echo.id),
 -		 ntohs(icmph->un.echo.sequence));
 +	pr_debug("ping_err(type=%04x,code=%04x,id=%04x,seq=%04x)\n", type,
 +		 code, ntohs(icmph->un.echo.id), ntohs(icmph->un.echo.sequence));
  
++<<<<<<< HEAD
 +	sk = ping_v4_lookup(net, iph->daddr, iph->saddr,
 +			    ntohs(icmph->un.echo.id), skb->dev->ifindex);
 +	if (sk == NULL) {
++=======
+ 	sk = ping_lookup(net, skb, ntohs(icmph->un.echo.id));
+ 	if (!sk) {
++>>>>>>> 51456b2914a3 (ipv4: coding style: comparison for equality with NULL)
  		pr_debug("no socket, dropping\n");
  		return;	/* No socket for error */
  	}
diff --cc net/ipv4/tcp_fastopen.c
index ab7bd35bb312,5da55e2b5cd2..000000000000
--- a/net/ipv4/tcp_fastopen.c
+++ b/net/ipv4/tcp_fastopen.c
@@@ -73,19 -83,227 +73,203 @@@ void tcp_fastopen_cookie_gen(__be32 src
  	rcu_read_lock();
  	ctx = rcu_dereference(tcp_fastopen_ctx);
  	if (ctx) {
 -		crypto_cipher_encrypt_one(ctx->tfm, foc->val, path);
 +		crypto_cipher_encrypt_one(ctx->tfm, foc->val, (__u8 *)path);
  		foc->len = TCP_FASTOPEN_COOKIE_SIZE;
 -		ok = true;
  	}
  	rcu_read_unlock();
 -	return ok;
  }
  
 -/* Generate the fastopen cookie by doing aes128 encryption on both
 - * the source and destination addresses. Pad 0s for IPv4 or IPv4-mapped-IPv6
 - * addresses. For the longer IPv6 addresses use CBC-MAC.
 - *
 - * XXX (TFO) - refactor when TCP_FASTOPEN_COOKIE_SIZE != AES_BLOCK_SIZE.
 - */
 -static bool tcp_fastopen_cookie_gen(struct request_sock *req,
 -				    struct sk_buff *syn,
 -				    struct tcp_fastopen_cookie *foc)
 +static int __init tcp_fastopen_init(void)
  {
 -	if (req->rsk_ops->family == AF_INET) {
 -		const struct iphdr *iph = ip_hdr(syn);
 -
 -		__be32 path[4] = { iph->saddr, iph->daddr, 0, 0 };
 -		return __tcp_fastopen_cookie_gen(path, foc);
 -	}
 -
 -#if IS_ENABLED(CONFIG_IPV6)
 -	if (req->rsk_ops->family == AF_INET6) {
 -		const struct ipv6hdr *ip6h = ipv6_hdr(syn);
 -		struct tcp_fastopen_cookie tmp;
 +	__u8 key[TCP_FASTOPEN_KEY_LENGTH];
  
 -		if (__tcp_fastopen_cookie_gen(&ip6h->saddr, &tmp)) {
 -			struct in6_addr *buf = (struct in6_addr *) tmp.val;
 -			int i;
 -
 -			for (i = 0; i < 4; i++)
 -				buf->s6_addr32[i] ^= ip6h->daddr.s6_addr32[i];
 -			return __tcp_fastopen_cookie_gen(buf, foc);
 -		}
 -	}
 -#endif
 -	return false;
 +	get_random_bytes(key, sizeof(key));
 +	tcp_fastopen_reset_cipher(key, sizeof(key));
 +	return 0;
  }
  
++<<<<<<< HEAD
 +late_initcall(tcp_fastopen_init);
++=======
+ static bool tcp_fastopen_create_child(struct sock *sk,
+ 				      struct sk_buff *skb,
+ 				      struct dst_entry *dst,
+ 				      struct request_sock *req)
+ {
+ 	struct tcp_sock *tp;
+ 	struct request_sock_queue *queue = &inet_csk(sk)->icsk_accept_queue;
+ 	struct sock *child;
+ 	u32 end_seq;
+ 
+ 	req->num_retrans = 0;
+ 	req->num_timeout = 0;
+ 	req->sk = NULL;
+ 
+ 	child = inet_csk(sk)->icsk_af_ops->syn_recv_sock(sk, skb, req, NULL);
+ 	if (!child)
+ 		return false;
+ 
+ 	spin_lock(&queue->fastopenq->lock);
+ 	queue->fastopenq->qlen++;
+ 	spin_unlock(&queue->fastopenq->lock);
+ 
+ 	/* Initialize the child socket. Have to fix some values to take
+ 	 * into account the child is a Fast Open socket and is created
+ 	 * only out of the bits carried in the SYN packet.
+ 	 */
+ 	tp = tcp_sk(child);
+ 
+ 	tp->fastopen_rsk = req;
+ 	tcp_rsk(req)->tfo_listener = true;
+ 
+ 	/* RFC1323: The window in SYN & SYN/ACK segments is never
+ 	 * scaled. So correct it appropriately.
+ 	 */
+ 	tp->snd_wnd = ntohs(tcp_hdr(skb)->window);
+ 
+ 	/* Activate the retrans timer so that SYNACK can be retransmitted.
+ 	 * The request socket is not added to the SYN table of the parent
+ 	 * because it's been added to the accept queue directly.
+ 	 */
+ 	inet_csk_reset_xmit_timer(child, ICSK_TIME_RETRANS,
+ 				  TCP_TIMEOUT_INIT, TCP_RTO_MAX);
+ 
+ 	atomic_set(&req->rsk_refcnt, 1);
+ 	/* Add the child socket directly into the accept queue */
+ 	inet_csk_reqsk_queue_add(sk, req, child);
+ 
+ 	/* Now finish processing the fastopen child socket. */
+ 	inet_csk(child)->icsk_af_ops->rebuild_header(child);
+ 	tcp_init_congestion_control(child);
+ 	tcp_mtup_init(child);
+ 	tcp_init_metrics(child);
+ 	tcp_init_buffer_space(child);
+ 
+ 	/* Queue the data carried in the SYN packet. We need to first
+ 	 * bump skb's refcnt because the caller will attempt to free it.
+ 	 * Note that IPv6 might also have used skb_get() trick
+ 	 * in tcp_v6_conn_request() to keep this SYN around (treq->pktopts)
+ 	 * So we need to eventually get a clone of the packet,
+ 	 * before inserting it in sk_receive_queue.
+ 	 *
+ 	 * XXX (TFO) - we honor a zero-payload TFO request for now,
+ 	 * (any reason not to?) but no need to queue the skb since
+ 	 * there is no data. How about SYN+FIN?
+ 	 */
+ 	end_seq = TCP_SKB_CB(skb)->end_seq;
+ 	if (end_seq != TCP_SKB_CB(skb)->seq + 1) {
+ 		struct sk_buff *skb2;
+ 
+ 		if (unlikely(skb_shared(skb)))
+ 			skb2 = skb_clone(skb, GFP_ATOMIC);
+ 		else
+ 			skb2 = skb_get(skb);
+ 
+ 		if (likely(skb2)) {
+ 			skb_dst_drop(skb2);
+ 			__skb_pull(skb2, tcp_hdrlen(skb));
+ 			skb_set_owner_r(skb2, child);
+ 			__skb_queue_tail(&child->sk_receive_queue, skb2);
+ 			tp->syn_data_acked = 1;
+ 		} else {
+ 			end_seq = TCP_SKB_CB(skb)->seq + 1;
+ 		}
+ 	}
+ 	tcp_rsk(req)->rcv_nxt = tp->rcv_nxt = end_seq;
+ 	sk->sk_data_ready(sk);
+ 	bh_unlock_sock(child);
+ 	sock_put(child);
+ 	WARN_ON(!req->sk);
+ 	return true;
+ }
+ 
+ static bool tcp_fastopen_queue_check(struct sock *sk)
+ {
+ 	struct fastopen_queue *fastopenq;
+ 
+ 	/* Make sure the listener has enabled fastopen, and we don't
+ 	 * exceed the max # of pending TFO requests allowed before trying
+ 	 * to validating the cookie in order to avoid burning CPU cycles
+ 	 * unnecessarily.
+ 	 *
+ 	 * XXX (TFO) - The implication of checking the max_qlen before
+ 	 * processing a cookie request is that clients can't differentiate
+ 	 * between qlen overflow causing Fast Open to be disabled
+ 	 * temporarily vs a server not supporting Fast Open at all.
+ 	 */
+ 	fastopenq = inet_csk(sk)->icsk_accept_queue.fastopenq;
+ 	if (!fastopenq || fastopenq->max_qlen == 0)
+ 		return false;
+ 
+ 	if (fastopenq->qlen >= fastopenq->max_qlen) {
+ 		struct request_sock *req1;
+ 		spin_lock(&fastopenq->lock);
+ 		req1 = fastopenq->rskq_rst_head;
+ 		if (!req1 || time_after(req1->rsk_timer.expires, jiffies)) {
+ 			spin_unlock(&fastopenq->lock);
+ 			NET_INC_STATS_BH(sock_net(sk),
+ 					 LINUX_MIB_TCPFASTOPENLISTENOVERFLOW);
+ 			return false;
+ 		}
+ 		fastopenq->rskq_rst_head = req1->dl_next;
+ 		fastopenq->qlen--;
+ 		spin_unlock(&fastopenq->lock);
+ 		reqsk_put(req1);
+ 	}
+ 	return true;
+ }
+ 
+ /* Returns true if we should perform Fast Open on the SYN. The cookie (foc)
+  * may be updated and return the client in the SYN-ACK later. E.g., Fast Open
+  * cookie request (foc->len == 0).
+  */
+ bool tcp_try_fastopen(struct sock *sk, struct sk_buff *skb,
+ 		      struct request_sock *req,
+ 		      struct tcp_fastopen_cookie *foc,
+ 		      struct dst_entry *dst)
+ {
+ 	struct tcp_fastopen_cookie valid_foc = { .len = -1 };
+ 	bool syn_data = TCP_SKB_CB(skb)->end_seq != TCP_SKB_CB(skb)->seq + 1;
+ 
+ 	if (foc->len == 0) /* Client requests a cookie */
+ 		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPFASTOPENCOOKIEREQD);
+ 
+ 	if (!((sysctl_tcp_fastopen & TFO_SERVER_ENABLE) &&
+ 	      (syn_data || foc->len >= 0) &&
+ 	      tcp_fastopen_queue_check(sk))) {
+ 		foc->len = -1;
+ 		return false;
+ 	}
+ 
+ 	if (syn_data && (sysctl_tcp_fastopen & TFO_SERVER_COOKIE_NOT_REQD))
+ 		goto fastopen;
+ 
+ 	if (foc->len >= 0 &&  /* Client presents or requests a cookie */
+ 	    tcp_fastopen_cookie_gen(req, skb, &valid_foc) &&
+ 	    foc->len == TCP_FASTOPEN_COOKIE_SIZE &&
+ 	    foc->len == valid_foc.len &&
+ 	    !memcmp(foc->val, valid_foc.val, foc->len)) {
+ 		/* Cookie is valid. Create a (full) child socket to accept
+ 		 * the data in SYN before returning a SYN-ACK to ack the
+ 		 * data. If we fail to create the socket, fall back and
+ 		 * ack the ISN only but includes the same cookie.
+ 		 *
+ 		 * Note: Data-less SYN with valid cookie is allowed to send
+ 		 * data in SYN_RECV state.
+ 		 */
+ fastopen:
+ 		if (tcp_fastopen_create_child(sk, skb, dst, req)) {
+ 			foc->len = -1;
+ 			NET_INC_STATS_BH(sock_net(sk),
+ 					 LINUX_MIB_TCPFASTOPENPASSIVE);
+ 			return true;
+ 		}
+ 		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPFASTOPENPASSIVEFAIL);
+ 	} else if (foc->len > 0) /* Client presents an invalid cookie */
+ 		NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPFASTOPENPASSIVEFAIL);
+ 
+ 	*foc = valid_foc;
+ 	return false;
+ }
+ EXPORT_SYMBOL(tcp_try_fastopen);
++>>>>>>> 51456b2914a3 (ipv4: coding style: comparison for equality with NULL)
diff --cc net/ipv4/tcp_input.c
index ef845c96b4d4,1fd283684303..000000000000
--- a/net/ipv4/tcp_input.c
+++ b/net/ipv4/tcp_input.c
@@@ -5632,7 -5694,7 +5632,11 @@@ int tcp_rcv_state_process(struct sock *
  		WARN_ON_ONCE(sk->sk_state != TCP_SYN_RECV &&
  		    sk->sk_state != TCP_FIN_WAIT1);
  
++<<<<<<< HEAD
 +		if (tcp_check_req(sk, skb, req, NULL, true) == NULL)
++=======
+ 		if (!tcp_check_req(sk, skb, req, true))
++>>>>>>> 51456b2914a3 (ipv4: coding style: comparison for equality with NULL)
  			goto discard;
  	}
  
diff --cc net/ipv4/tcp_output.c
index 074c9a68acbd,bdc80734cd2c..000000000000
--- a/net/ipv4/tcp_output.c
+++ b/net/ipv4/tcp_output.c
@@@ -545,9 -565,9 +545,9 @@@ static unsigned int tcp_syn_options(str
  	opts->mss = tcp_advertise_mss(sk);
  	remaining -= TCPOLEN_MSS_ALIGNED;
  
- 	if (likely(sysctl_tcp_timestamps && *md5 == NULL)) {
+ 	if (likely(sysctl_tcp_timestamps && !*md5)) {
  		opts->options |= OPTION_TS;
 -		opts->tsval = tcp_skb_timestamp(skb) + tp->tsoffset;
 +		opts->tsval = TCP_SKB_CB(skb)->when + tp->tsoffset;
  		opts->tsecr = tp->rx_opt.ts_recent;
  		remaining -= TCPOLEN_TSTAMP_ALIGNED;
  	}
@@@ -1102,8 -1147,8 +1102,13 @@@ int tcp_fragment(struct sock *sk, struc
  		return -ENOMEM;
  
  	/* Get a new skb... force flag on. */
++<<<<<<< HEAD
 +	buff = sk_stream_alloc_skb(sk, nsize, GFP_ATOMIC);
 +	if (buff == NULL)
++=======
+ 	buff = sk_stream_alloc_skb(sk, nsize, gfp);
+ 	if (!buff)
++>>>>>>> 51456b2914a3 (ipv4: coding style: comparison for equality with NULL)
  		return -ENOMEM; /* We'll just try again later. */
  
  	sk->sk_wmem_queued += buff->truesize;
@@@ -1603,10 -1704,10 +1608,10 @@@ static int tso_fragment(struct sock *sk
  
  	/* All of a TSO frame must be composed of paged data.  */
  	if (skb->len != skb->data_len)
 -		return tcp_fragment(sk, skb, len, mss_now, gfp);
 +		return tcp_fragment(sk, skb, len, mss_now);
  
  	buff = sk_stream_alloc_skb(sk, 0, gfp);
- 	if (unlikely(buff == NULL))
+ 	if (unlikely(!buff))
  		return -ENOMEM;
  
  	sk->sk_wmem_queued += buff->truesize;
diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7da79adb81ec..f6192c09b796 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -217,7 +217,7 @@ int inet_listen(struct socket *sock, int backlog)
 		 * shutdown() (rather than close()).
 		 */
 		if ((sysctl_tcp_fastopen & TFO_SERVER_ENABLE) != 0 &&
-		    inet_csk(sk)->icsk_accept_queue.fastopenq == NULL) {
+		    !inet_csk(sk)->icsk_accept_queue.fastopenq) {
 			if ((sysctl_tcp_fastopen & TFO_SERVER_WO_SOCKOPT1) != 0)
 				err = fastopen_init_queue(sk, backlog);
 			else if ((sysctl_tcp_fastopen &
@@ -341,11 +341,11 @@ lookup_protocol:
 	answer_flags = answer->flags;
 	rcu_read_unlock();
 
-	WARN_ON(answer_prot->slab == NULL);
+	WARN_ON(!answer_prot->slab);
 
 	err = -ENOBUFS;
 	sk = sk_alloc(net, PF_INET, GFP_KERNEL, answer_prot);
-	if (sk == NULL)
+	if (!sk)
 		goto out;
 
 	err = 0;
* Unmerged path net/ipv4/arp.c
diff --git a/net/ipv4/cipso_ipv4.c b/net/ipv4/cipso_ipv4.c
index 1c46d73c8f2c..fc966430acdd 100644
--- a/net/ipv4/cipso_ipv4.c
+++ b/net/ipv4/cipso_ipv4.c
@@ -254,7 +254,7 @@ static int cipso_v4_cache_init(void)
 	cipso_v4_cache = kcalloc(CIPSO_V4_CACHE_BUCKETS,
 				 sizeof(struct cipso_v4_map_cache_bkt),
 				 GFP_KERNEL);
-	if (cipso_v4_cache == NULL)
+	if (!cipso_v4_cache)
 		return -ENOMEM;
 
 	for (iter = 0; iter < CIPSO_V4_CACHE_BUCKETS; iter++) {
@@ -338,7 +338,7 @@ static int cipso_v4_cache_check(const unsigned char *key,
 			secattr->cache = entry->lsm_data;
 			secattr->flags |= NETLBL_SECATTR_CACHE;
 			secattr->type = NETLBL_NLTYPE_CIPSOV4;
-			if (prev_entry == NULL) {
+			if (!prev_entry) {
 				spin_unlock_bh(&cipso_v4_cache[bkt].lock);
 				return 0;
 			}
@@ -394,10 +394,10 @@ int cipso_v4_cache_add(const struct sk_buff *skb,
 	cipso_ptr_len = cipso_ptr[1];
 
 	entry = kzalloc(sizeof(*entry), GFP_ATOMIC);
-	if (entry == NULL)
+	if (!entry)
 		return -ENOMEM;
 	entry->key = kmemdup(cipso_ptr, cipso_ptr_len, GFP_ATOMIC);
-	if (entry->key == NULL) {
+	if (!entry->key) {
 		ret_val = -ENOMEM;
 		goto cache_add_failure;
 	}
@@ -548,7 +548,7 @@ doi_add_return:
  */
 void cipso_v4_doi_free(struct cipso_v4_doi *doi_def)
 {
-	if (doi_def == NULL)
+	if (!doi_def)
 		return;
 
 	switch (doi_def->type) {
@@ -599,7 +599,7 @@ int cipso_v4_doi_remove(u32 doi, struct netlbl_audit *audit_info)
 
 	spin_lock(&cipso_v4_doi_list_lock);
 	doi_def = cipso_v4_doi_search(doi);
-	if (doi_def == NULL) {
+	if (!doi_def) {
 		spin_unlock(&cipso_v4_doi_list_lock);
 		ret_val = -ENOENT;
 		goto doi_remove_return;
@@ -645,7 +645,7 @@ struct cipso_v4_doi *cipso_v4_doi_getdef(u32 doi)
 
 	rcu_read_lock();
 	doi_def = cipso_v4_doi_search(doi);
-	if (doi_def == NULL)
+	if (!doi_def)
 		goto doi_getdef_return;
 	if (!atomic_inc_not_zero(&doi_def->refcount))
 		doi_def = NULL;
@@ -665,7 +665,7 @@ doi_getdef_return:
  */
 void cipso_v4_doi_putdef(struct cipso_v4_doi *doi_def)
 {
-	if (doi_def == NULL)
+	if (!doi_def)
 		return;
 
 	if (!atomic_dec_and_test(&doi_def->refcount))
@@ -1616,7 +1616,7 @@ int cipso_v4_validate(const struct sk_buff *skb, unsigned char **option)
 
 	rcu_read_lock();
 	doi_def = cipso_v4_doi_search(get_unaligned_be32(&opt[2]));
-	if (doi_def == NULL) {
+	if (!doi_def) {
 		err_offset = 2;
 		goto validate_return_locked;
 	}
@@ -1710,7 +1710,7 @@ int cipso_v4_validate(const struct sk_buff *skb, unsigned char **option)
 			 * not the loopback device drop the packet. Further,
 			 * there is no legitimate reason for setting this from
 			 * userspace so reject it if skb is NULL. */
-			if (skb == NULL || !(skb->dev->flags & IFF_LOOPBACK)) {
+			if (!skb || !(skb->dev->flags & IFF_LOOPBACK)) {
 				err_offset = opt_iter;
 				goto validate_return_locked;
 			}
@@ -1871,7 +1871,7 @@ int cipso_v4_sock_setattr(struct sock *sk,
 	 * defined yet but it is not a problem as the only users of these
 	 * "lite" PF_INET sockets are functions which do an accept() call
 	 * afterwards so we will label the socket as part of the accept(). */
-	if (sk == NULL)
+	if (!sk)
 		return 0;
 
 	/* We allocate the maximum CIPSO option size here so we are probably
@@ -1879,7 +1879,7 @@ int cipso_v4_sock_setattr(struct sock *sk,
 	 * on and after all we are only talking about 40 bytes. */
 	buf_len = CIPSO_V4_OPT_LEN_MAX;
 	buf = kmalloc(buf_len, GFP_ATOMIC);
-	if (buf == NULL) {
+	if (!buf) {
 		ret_val = -ENOMEM;
 		goto socket_setattr_failure;
 	}
@@ -1895,7 +1895,7 @@ int cipso_v4_sock_setattr(struct sock *sk,
 	 * set the IPOPT_CIPSO option. */
 	opt_len = (buf_len + 3) & ~3;
 	opt = kzalloc(sizeof(*opt) + opt_len, GFP_ATOMIC);
-	if (opt == NULL) {
+	if (!opt) {
 		ret_val = -ENOMEM;
 		goto socket_setattr_failure;
 	}
@@ -1955,7 +1955,7 @@ int cipso_v4_req_setattr(struct request_sock *req,
 	 * on and after all we are only talking about 40 bytes. */
 	buf_len = CIPSO_V4_OPT_LEN_MAX;
 	buf = kmalloc(buf_len, GFP_ATOMIC);
-	if (buf == NULL) {
+	if (!buf) {
 		ret_val = -ENOMEM;
 		goto req_setattr_failure;
 	}
@@ -1971,7 +1971,7 @@ int cipso_v4_req_setattr(struct request_sock *req,
 	 * set the IPOPT_CIPSO option. */
 	opt_len = (buf_len + 3) & ~3;
 	opt = kzalloc(sizeof(*opt) + opt_len, GFP_ATOMIC);
-	if (opt == NULL) {
+	if (!opt) {
 		ret_val = -ENOMEM;
 		goto req_setattr_failure;
 	}
@@ -2076,7 +2076,7 @@ void cipso_v4_sock_delattr(struct sock *sk)
 
 	sk_inet = inet_sk(sk);
 	opt = rcu_dereference_protected(sk_inet->inet_opt, 1);
-	if (opt == NULL || opt->opt.cipso == 0)
+	if (!opt || opt->opt.cipso == 0)
 		return;
 
 	hdr_delta = cipso_v4_delopt(&sk_inet->inet_opt);
@@ -2102,7 +2102,7 @@ void cipso_v4_req_delattr(struct request_sock *req)
 
 	req_inet = inet_rsk(req);
 	opt = req_inet->opt;
-	if (opt == NULL || opt->opt.cipso == 0)
+	if (!opt || opt->opt.cipso == 0)
 		return;
 
 	cipso_v4_delopt(&req_inet->opt);
@@ -2131,7 +2131,7 @@ static int cipso_v4_getattr(const unsigned char *cipso,
 	doi = get_unaligned_be32(&cipso[2]);
 	rcu_read_lock();
 	doi_def = cipso_v4_doi_search(doi);
-	if (doi_def == NULL)
+	if (!doi_def)
 		goto getattr_return;
 	/* XXX - This code assumes only one tag per CIPSO option which isn't
 	 * really a good assumption to make but since we only support the MAC
diff --git a/net/ipv4/devinet.c b/net/ipv4/devinet.c
index 0da4dc8f4743..36445d331416 100644
--- a/net/ipv4/devinet.c
+++ b/net/ipv4/devinet.c
@@ -555,7 +555,7 @@ static int inet_rtm_deladdr(struct sk_buff *skb, struct nlmsghdr *nlh)
 
 	ifm = nlmsg_data(nlh);
 	in_dev = inetdev_by_index(net, ifm->ifa_index);
-	if (in_dev == NULL) {
+	if (!in_dev) {
 		err = -ENODEV;
 		goto errout;
 	}
@@ -722,21 +722,21 @@ static struct in_ifaddr *rtm_to_ifaddr(struct net *net, struct nlmsghdr *nlh,
 
 	ifm = nlmsg_data(nlh);
 	err = -EINVAL;
-	if (ifm->ifa_prefixlen > 32 || tb[IFA_LOCAL] == NULL)
+	if (ifm->ifa_prefixlen > 32 || !tb[IFA_LOCAL])
 		goto errout;
 
 	dev = __dev_get_by_index(net, ifm->ifa_index);
 	err = -ENODEV;
-	if (dev == NULL)
+	if (!dev)
 		goto errout;
 
 	in_dev = __in_dev_get_rtnl(dev);
 	err = -ENOBUFS;
-	if (in_dev == NULL)
+	if (!in_dev)
 		goto errout;
 
 	ifa = inet_alloc_ifa();
-	if (ifa == NULL)
+	if (!ifa)
 		/*
 		 * A potential indev allocation can be left alive, it stays
 		 * assigned to its device and is destroy with it.
@@ -747,7 +747,7 @@ static struct in_ifaddr *rtm_to_ifaddr(struct net *net, struct nlmsghdr *nlh,
 	neigh_parms_data_state_setall(in_dev->arp_parms);
 	in_dev_hold(in_dev);
 
-	if (tb[IFA_ADDRESS] == NULL)
+	if (!tb[IFA_ADDRESS])
 		tb[IFA_ADDRESS] = tb[IFA_LOCAL];
 
 	INIT_HLIST_NODE(&ifa->hash);
@@ -1301,7 +1301,7 @@ static void inetdev_changename(struct net_device *dev, struct in_device *in_dev)
 		if (named++ == 0)
 			goto skip;
 		dot = strchr(old, ':');
-		if (dot == NULL) {
+		if (!dot) {
 			sprintf(old, ":%d", named);
 			dot = old;
 		}
@@ -1469,7 +1469,7 @@ static int inet_fill_ifaddr(struct sk_buff *skb, struct in_ifaddr *ifa,
 	u32 preferred, valid;
 
 	nlh = nlmsg_put(skb, portid, seq, event, sizeof(*ifm), flags);
-	if (nlh == NULL)
+	if (!nlh)
 		return -EMSGSIZE;
 
 	ifm = nlmsg_data(nlh);
@@ -1587,7 +1587,7 @@ static void rtmsg_ifa(int event, struct in_ifaddr *ifa, struct nlmsghdr *nlh,
 
 	net = dev_net(ifa->ifa_dev->dev);
 	skb = nlmsg_new(inet_nlmsg_size(), GFP_KERNEL);
-	if (skb == NULL)
+	if (!skb)
 		goto errout;
 
 	err = inet_fill_ifaddr(skb, ifa, portid, seq, event, 0);
@@ -1624,7 +1624,7 @@ static int inet_fill_link_af(struct sk_buff *skb, const struct net_device *dev)
 		return -ENODATA;
 
 	nla = nla_reserve(skb, IFLA_INET_CONF, IPV4_DEVCONF_MAX * 4);
-	if (nla == NULL)
+	if (!nla)
 		return -EMSGSIZE;
 
 	for (i = 0; i < IPV4_DEVCONF_MAX; i++)
@@ -1711,7 +1711,7 @@ static int inet_netconf_fill_devconf(struct sk_buff *skb, int ifindex,
 
 	nlh = nlmsg_put(skb, portid, seq, event, sizeof(struct netconfmsg),
 			flags);
-	if (nlh == NULL)
+	if (!nlh)
 		return -EMSGSIZE;
 
 	ncm = nlmsg_data(nlh);
@@ -1748,7 +1748,7 @@ void inet_netconf_notify_devconf(struct net *net, int type, int ifindex,
 	int err = -ENOBUFS;
 
 	skb = nlmsg_new(inet_netconf_msgsize_devconf(type), GFP_ATOMIC);
-	if (skb == NULL)
+	if (!skb)
 		goto errout;
 
 	err = inet_netconf_fill_devconf(skb, ifindex, devconf, 0, 0,
@@ -1804,10 +1804,10 @@ static int inet_netconf_get_devconf(struct sk_buff *in_skb,
 		break;
 	default:
 		dev = __dev_get_by_index(net, ifindex);
-		if (dev == NULL)
+		if (!dev)
 			goto errout;
 		in_dev = __in_dev_get_rtnl(dev);
-		if (in_dev == NULL)
+		if (!in_dev)
 			goto errout;
 		devconf = &in_dev->cnf;
 		break;
@@ -1815,7 +1815,7 @@ static int inet_netconf_get_devconf(struct sk_buff *in_skb,
 
 	err = -ENOBUFS;
 	skb = nlmsg_new(inet_netconf_msgsize_devconf(-1), GFP_ATOMIC);
-	if (skb == NULL)
+	if (!skb)
 		goto errout;
 
 	err = inet_netconf_fill_devconf(skb, ifindex, devconf,
@@ -2152,7 +2152,7 @@ static void __devinet_sysctl_unregister(struct ipv4_devconf *cnf)
 {
 	struct devinet_sysctl_table *t = cnf->sysctl;
 
-	if (t == NULL)
+	if (!t)
 		return;
 
 	cnf->sysctl = NULL;
@@ -2203,16 +2203,16 @@ static __net_init int devinet_init_net(struct net *net)
 
 	if (!net_eq(net, &init_net)) {
 		all = kmemdup(all, sizeof(ipv4_devconf), GFP_KERNEL);
-		if (all == NULL)
+		if (!all)
 			goto err_alloc_all;
 
 		dflt = kmemdup(dflt, sizeof(ipv4_devconf_dflt), GFP_KERNEL);
-		if (dflt == NULL)
+		if (!dflt)
 			goto err_alloc_dflt;
 
 #ifdef CONFIG_SYSCTL
 		tbl = kmemdup(tbl, sizeof(ctl_forward_entry), GFP_KERNEL);
-		if (tbl == NULL)
+		if (!tbl)
 			goto err_alloc_ctl;
 
 		tbl[0].data = &all->data[IPV4_DEVCONF_FORWARDING - 1];
@@ -2232,7 +2232,7 @@ static __net_init int devinet_init_net(struct net *net)
 
 	err = -ENOMEM;
 	forw_hdr = register_net_sysctl(net, "net/ipv4", tbl);
-	if (forw_hdr == NULL)
+	if (!forw_hdr)
 		goto err_reg_ctl;
 	net->ipv4.forw_hdr = forw_hdr;
 #endif
diff --git a/net/ipv4/esp4.c b/net/ipv4/esp4.c
index bc94fc8e488f..cc585b48cde9 100644
--- a/net/ipv4/esp4.c
+++ b/net/ipv4/esp4.c
@@ -561,7 +561,7 @@ static int esp_init_authenc(struct xfrm_state *x)
 	int err;
 
 	err = -EINVAL;
-	if (x->ealg == NULL)
+	if (!x->ealg)
 		goto error;
 
 	err = -ENAMETOOLONG;
* Unmerged path net/ipv4/fib_frontend.c
diff --git a/net/ipv4/fib_rules.c b/net/ipv4/fib_rules.c
index 9f46a79bb895..13653d76dad0 100644
--- a/net/ipv4/fib_rules.c
+++ b/net/ipv4/fib_rules.c
@@ -126,7 +126,7 @@ static struct fib_table *fib_empty_table(struct net *net)
 	u32 id;
 
 	for (id = 1; id <= RT_TABLE_MAX; id++)
-		if (fib_get_table(net, id) == NULL)
+		if (!fib_get_table(net, id))
 			return fib_new_table(net, id);
 	return NULL;
 }
@@ -152,7 +152,7 @@ static int fib4_rule_configure(struct fib_rule *rule, struct sk_buff *skb,
 			struct fib_table *table;
 
 			table = fib_empty_table(net);
-			if (table == NULL) {
+			if (!table) {
 				err = -ENOBUFS;
 				goto errout;
 			}
diff --git a/net/ipv4/fib_semantics.c b/net/ipv4/fib_semantics.c
index 33ffde3d859d..a795bc478f00 100644
--- a/net/ipv4/fib_semantics.c
+++ b/net/ipv4/fib_semantics.c
@@ -389,7 +389,7 @@ void rtmsg_fib(int event, __be32 key, struct fib_alias *fa,
 	int err = -ENOBUFS;
 
 	skb = nlmsg_new(fib_nlmsg_size(fa->fa_info), GFP_KERNEL);
-	if (skb == NULL)
+	if (!skb)
 		goto errout;
 
 	err = fib_dump_info(skb, info->portid, seq, event, tb_id,
@@ -519,7 +519,7 @@ int fib_nh_match(struct fib_config *cfg, struct fib_info *fi)
 	}
 
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
-	if (cfg->fc_mp == NULL)
+	if (!cfg->fc_mp)
 		return 0;
 
 	rtnh = cfg->fc_mp;
@@ -661,7 +661,7 @@ static int fib_check_nh(struct fib_config *cfg, struct fib_info *fi,
 		rcu_read_lock();
 		err = -ENODEV;
 		in_dev = inetdev_by_index(net, nh->nh_oif);
-		if (in_dev == NULL)
+		if (!in_dev)
 			goto out;
 		err = -ENETDOWN;
 		if (!(in_dev->dev->flags & IFF_UP))
@@ -818,7 +818,7 @@ struct fib_info *fib_create_info(struct fib_config *cfg)
 	}
 
 	fi = kzalloc(sizeof(*fi)+nhs*sizeof(struct fib_nh), GFP_KERNEL);
-	if (fi == NULL)
+	if (!fi)
 		goto failure;
 	if (cfg->fc_mx) {
 		fi->fib_metrics = kzalloc(sizeof(u32) * RTAX_MAX, GFP_KERNEL);
@@ -927,7 +927,7 @@ struct fib_info *fib_create_info(struct fib_config *cfg)
 		nh->nh_scope = RT_SCOPE_NOWHERE;
 		nh->nh_dev = dev_get_by_index(net, fi->fib_nh->nh_oif);
 		err = -ENODEV;
-		if (nh->nh_dev == NULL)
+		if (!nh->nh_dev)
 			goto failure;
 	} else {
 		change_nexthops(fi) {
@@ -1001,7 +1001,7 @@ int fib_dump_info(struct sk_buff *skb, u32 portid, u32 seq, int event,
 	struct rtmsg *rtm;
 
 	nlh = nlmsg_put(skb, portid, seq, event, sizeof(*rtm), flags);
-	if (nlh == NULL)
+	if (!nlh)
 		return -EMSGSIZE;
 
 	rtm = nlmsg_data(nlh);
@@ -1051,12 +1051,12 @@ int fib_dump_info(struct sk_buff *skb, u32 portid, u32 seq, int event,
 		struct nlattr *mp;
 
 		mp = nla_nest_start(skb, RTA_MULTIPATH);
-		if (mp == NULL)
+		if (!mp)
 			goto nla_put_failure;
 
 		for_nexthops(fi) {
 			rtnh = nla_reserve_nohdr(skb, sizeof(*rtnh));
-			if (rtnh == NULL)
+			if (!rtnh)
 				goto nla_put_failure;
 
 			rtnh->rtnh_flags = nh->nh_flags & 0xFF;
@@ -1098,7 +1098,7 @@ int fib_sync_down_addr(struct net *net, __be32 local)
 	struct hlist_head *head = &fib_info_laddrhash[hash];
 	struct fib_info *fi;
 
-	if (fib_info_laddrhash == NULL || local == 0)
+	if (!fib_info_laddrhash || local == 0)
 		return 0;
 
 	hlist_for_each_entry(fi, head, fib_lhash) {
@@ -1187,7 +1187,7 @@ void fib_select_default(struct fib_result *res)
 
 		fib_alias_accessed(fa);
 
-		if (fi == NULL) {
+		if (!fi) {
 			if (next_fi != res->fi)
 				break;
 		} else if (!fib_detect_death(fi, order, &last_resort,
@@ -1200,7 +1200,7 @@ void fib_select_default(struct fib_result *res)
 		order++;
 	}
 
-	if (order <= 0 || fi == NULL) {
+	if (order <= 0 || !fi) {
 		tb->tb_default = -1;
 		goto out;
 	}
@@ -1256,7 +1256,7 @@ int fib_sync_up(struct net_device *dev)
 				alive++;
 				continue;
 			}
-			if (nexthop_nh->nh_dev == NULL ||
+			if (!nexthop_nh->nh_dev ||
 			    !(nexthop_nh->nh_dev->flags & IFF_UP))
 				continue;
 			if (nexthop_nh->nh_dev != dev ||
* Unmerged path net/ipv4/fib_trie.c
diff --git a/net/ipv4/geneve.c b/net/ipv4/geneve.c
index 6c1d8cbeb11d..16e09d8156b9 100644
--- a/net/ipv4/geneve.c
+++ b/net/ipv4/geneve.c
@@ -197,7 +197,7 @@ static struct sk_buff **geneve_gro_receive(struct sk_buff **head,
 
 	rcu_read_lock();
 	ptype = gro_find_receive_by_type(type);
-	if (ptype == NULL) {
+	if (!ptype) {
 		flush = 1;
 		goto out_unlock;
 	}
diff --git a/net/ipv4/gre_offload.c b/net/ipv4/gre_offload.c
index 5771ffc8da3d..c968fb9bb445 100644
--- a/net/ipv4/gre_offload.c
+++ b/net/ipv4/gre_offload.c
@@ -153,7 +153,7 @@ static struct sk_buff **gre_gro_receive(struct sk_buff **head,
 
 	rcu_read_lock();
 	ptype = gro_find_receive_by_type(type);
-	if (ptype == NULL)
+	if (!ptype)
 		goto out_unlock;
 
 	grehlen = GRE_HEADER_SECTION;
* Unmerged path net/ipv4/icmp.c
diff --git a/net/ipv4/igmp.c b/net/ipv4/igmp.c
index b15ffcfd3055..cf18d3c4d144 100644
--- a/net/ipv4/igmp.c
+++ b/net/ipv4/igmp.c
@@ -667,7 +667,7 @@ static int igmp_send_report(struct in_device *in_dev, struct ip_mc_list *pmc,
 	hlen = LL_RESERVED_SPACE(dev);
 	tlen = dev->needed_tailroom;
 	skb = alloc_skb(IGMP_SIZE + hlen + tlen, GFP_ATOMIC);
-	if (skb == NULL) {
+	if (!skb) {
 		ip_rt_put(rt);
 		return -1;
 	}
@@ -955,7 +955,7 @@ int igmp_rcv(struct sk_buff *skb)
 	int len = skb->len;
 	bool dropped = true;
 
-	if (in_dev == NULL)
+	if (!in_dev)
 		goto drop;
 
 	if (!pskb_may_pull(skb, sizeof(struct igmphdr)))
@@ -1809,7 +1809,7 @@ int __ip_mc_join_group(struct sock *sk, struct ip_mreqn *imr)
 	if (count >= sysctl_igmp_max_memberships)
 		goto done;
 	iml = sock_kmalloc(sk, sizeof(*iml), GFP_KERNEL);
-	if (iml == NULL)
+	if (!iml)
 		goto done;
 
 	memcpy(&iml->multi, imr, sizeof(*imr));
@@ -1844,7 +1844,7 @@ static int ip_mc_leave_src(struct sock *sk, struct ip_mc_socklist *iml,
 	struct ip_sf_socklist *psf = rtnl_dereference(iml->sflist);
 	int err;
 
-	if (psf == NULL) {
+	if (!psf) {
 		/* any-source empty exclude case */
 		return ip_mc_del_src(in_dev, &iml->multi.imr_multiaddr.s_addr,
 			iml->sfmode, 0, NULL, 0);
@@ -2309,7 +2309,7 @@ void ip_mc_drop_socket(struct sock *sk)
 	struct ip_mc_socklist *iml;
 	struct net *net = sock_net(sk);
 
-	if (inet->mc_list == NULL)
+	if (!inet->mc_list)
 		return;
 
 	rtnl_lock();
@@ -2523,7 +2523,7 @@ static inline struct ip_sf_list *igmp_mcf_get_first(struct seq_file *seq)
 	for_each_netdev_rcu(net, state->dev) {
 		struct in_device *idev;
 		idev = __in_dev_get_rcu(state->dev);
-		if (unlikely(idev == NULL))
+		if (unlikely(!idev))
 			continue;
 		im = rcu_dereference(idev->mc_list);
 		if (likely(im != NULL)) {
* Unmerged path net/ipv4/inet_fragment.c
diff --git a/net/ipv4/ip_fragment.c b/net/ipv4/ip_fragment.c
index 049a0fac430a..3a5900a2afa5 100644
--- a/net/ipv4/ip_fragment.c
+++ b/net/ipv4/ip_fragment.c
@@ -386,7 +386,7 @@ static int ip_frag_queue(struct ipq *qp, struct sk_buff *skb)
 		goto err;
 
 	err = -ENOMEM;
-	if (pskb_pull(skb, ihl) == NULL)
+	if (!pskb_pull(skb, ihl))
 		goto err;
 
 	err = pskb_trim_rcsum(skb, end - offset);
@@ -552,7 +552,7 @@ static int ip_frag_reasm(struct ipq *qp, struct sk_buff *prev,
 		qp->q.fragments = head;
 	}
 
-	WARN_ON(head == NULL);
+	WARN_ON(!head);
 	WARN_ON(FRAG_CB(head)->offset != 0);
 
 	/* Allocate a new buffer for the datagram. */
@@ -574,7 +574,8 @@ static int ip_frag_reasm(struct ipq *qp, struct sk_buff *prev,
 		struct sk_buff *clone;
 		int i, plen = 0;
 
-		if ((clone = alloc_skb(0, GFP_ATOMIC)) == NULL)
+		clone = alloc_skb(0, GFP_ATOMIC);
+		if (!clone)
 			goto out_nomem;
 		clone->next = head->next;
 		head->next = clone;
@@ -765,7 +766,7 @@ static int __net_init ip4_frags_ns_ctl_register(struct net *net)
 	table = ip4_frags_ns_ctl_table;
 	if (!net_eq(net, &init_net)) {
 		table = kmemdup(table, sizeof(ip4_frags_ns_ctl_table), GFP_KERNEL);
-		if (table == NULL)
+		if (!table)
 			goto err_alloc;
 
 		table[0].data = &net->ipv4.frags.high_thresh;
@@ -778,7 +779,7 @@ static int __net_init ip4_frags_ns_ctl_register(struct net *net)
 	}
 
 	hdr = register_net_sysctl(net, "net/ipv4", table);
-	if (hdr == NULL)
+	if (!hdr)
 		goto err_reg;
 
 	net->ipv4.frags_hdr = hdr;
diff --git a/net/ipv4/ip_gre.c b/net/ipv4/ip_gre.c
index 32050064effe..fed1e1e2d5ac 100644
--- a/net/ipv4/ip_gre.c
+++ b/net/ipv4/ip_gre.c
@@ -182,7 +182,7 @@ static int ipgre_err(struct sk_buff *skb, u32 info,
 	t = ip_tunnel_lookup(itn, skb->dev->ifindex, tpi->flags,
 			     iph->daddr, iph->saddr, tpi->key);
 
-	if (t == NULL)
+	if (!t)
 		return PACKET_REJECT;
 
 	if (t->parms.iph.daddr == 0 ||
@@ -422,7 +422,7 @@ static int ipgre_open(struct net_device *dev)
 			return -EADDRNOTAVAIL;
 		dev = rt->dst.dev;
 		ip_rt_put(rt);
-		if (__in_dev_get_rtnl(dev) == NULL)
+		if (!__in_dev_get_rtnl(dev))
 			return -EADDRNOTAVAIL;
 		t->mlink = dev->ifindex;
 		ip_mc_inc_group(__in_dev_get_rtnl(dev), t->parms.iph.daddr);
diff --git a/net/ipv4/ip_input.c b/net/ipv4/ip_input.c
index 3d4da2c16b6a..00bed6fe3b66 100644
--- a/net/ipv4/ip_input.c
+++ b/net/ipv4/ip_input.c
@@ -314,7 +314,7 @@ static int ip_rcv_finish(struct sk_buff *skb)
 	const struct iphdr *iph = ip_hdr(skb);
 	struct rtable *rt;
 
-	if (sysctl_ip_early_demux && !skb_dst(skb) && skb->sk == NULL) {
+	if (sysctl_ip_early_demux && !skb_dst(skb) && !skb->sk) {
 		const struct net_protocol *ipprot;
 		int protocol = iph->protocol;
 
@@ -387,7 +387,8 @@ int ip_rcv(struct sk_buff *skb, struct net_device *dev, struct packet_type *pt,
 
 	IP_UPD_PO_STATS_BH(dev_net(dev), IPSTATS_MIB_IN, skb->len);
 
-	if ((skb = skb_share_check(skb, GFP_ATOMIC)) == NULL) {
+	skb = skb_share_check(skb, GFP_ATOMIC);
+	if (!skb) {
 		IP_INC_STATS_BH(dev_net(dev), IPSTATS_MIB_INDISCARDS);
 		goto out;
 	}
diff --git a/net/ipv4/ip_output.c b/net/ipv4/ip_output.c
index 8c66d61254bb..f76f3c158ae7 100644
--- a/net/ipv4/ip_output.c
+++ b/net/ipv4/ip_output.c
@@ -182,7 +182,7 @@ static inline int ip_finish_output2(struct sk_buff *skb)
 		struct sk_buff *skb2;
 
 		skb2 = skb_realloc_headroom(skb, LL_RESERVED_SPACE(dev));
-		if (skb2 == NULL) {
+		if (!skb2) {
 			kfree_skb(skb);
 			return -ENOMEM;
 		}
@@ -379,7 +379,7 @@ int ip_queue_xmit(struct sk_buff *skb, struct flowi *fl)
 
 	/* Make sure we can route this packet. */
 	rt = (struct rtable *)__sk_dst_check(sk, 0);
-	if (rt == NULL) {
+	if (!rt) {
 		__be32 daddr;
 
 		/* Use correct destination address if we have options. */
@@ -795,12 +795,13 @@ static inline int ip_ufo_append_data(struct sock *sk,
 	 * device, so create one single skb packet containing complete
 	 * udp datagram
 	 */
-	if ((skb = skb_peek_tail(queue)) == NULL) {
+	skb = skb_peek_tail(queue);
+	if (!skb) {
 		skb = sock_alloc_send_skb(sk,
 			hh_len + fragheaderlen + transhdrlen + 20,
 			(flags & MSG_DONTWAIT), &err);
 
-		if (skb == NULL)
+		if (!skb)
 			return err;
 
 		/* reserve space for Hardware header */
@@ -961,14 +962,14 @@ alloc_new_skb:
 					skb = sock_wmalloc(sk,
 							   alloclen + hh_len + 15, 1,
 							   sk->sk_allocation);
-				if (unlikely(skb == NULL))
+				if (unlikely(!skb))
 					err = -ENOBUFS;
 				else
 					/* only the initial fragment is
 					   time stamped */
 					cork->tx_flags = 0;
 			}
-			if (skb == NULL)
+			if (!skb)
 				goto error;
 
 			/*
@@ -1087,10 +1088,10 @@ static int ip_setup_cork(struct sock *sk, struct inet_cork *cork,
 	 */
 	opt = ipc->opt;
 	if (opt) {
-		if (cork->opt == NULL) {
+		if (!cork->opt) {
 			cork->opt = kmalloc(sizeof(struct ip_options) + 40,
 					    sk->sk_allocation);
-			if (unlikely(cork->opt == NULL))
+			if (unlikely(!cork->opt))
 				return -ENOBUFS;
 		}
 		memcpy(cork->opt, &opt->opt, sizeof(struct ip_options) + opt->opt.optlen);
@@ -1196,7 +1197,8 @@ ssize_t	ip_append_page(struct sock *sk, struct flowi4 *fl4, struct page *page,
 		return -EMSGSIZE;
 	}
 
-	if ((skb = skb_peek_tail(&sk->sk_write_queue)) == NULL)
+	skb = skb_peek_tail(&sk->sk_write_queue);
+	if (!skb)
 		return -EINVAL;
 
 	cork->length += size;
@@ -1320,7 +1322,8 @@ struct sk_buff *__ip_make_skb(struct sock *sk,
 	__be16 df = 0;
 	__u8 ttl;
 
-	if ((skb = __skb_dequeue(queue)) == NULL)
+	skb = __skb_dequeue(queue);
+	if (!skb)
 		goto out;
 	tail_skb = &(skb_shinfo(skb)->frag_list);
 
* Unmerged path net/ipv4/ip_sockglue.c
diff --git a/net/ipv4/ip_tunnel.c b/net/ipv4/ip_tunnel.c
index 1129aec53c2c..bc3c1676c7fe 100644
--- a/net/ipv4/ip_tunnel.c
+++ b/net/ipv4/ip_tunnel.c
@@ -546,7 +546,7 @@ void ip_tunnel_xmit(struct sk_buff *skb, struct net_device *dev,
 	if (dst == 0) {
 		/* NBMA tunnel */
 
-		if (skb_dst(skb) == NULL) {
+		if (!skb_dst(skb)) {
 			dev->stats.tx_fifo_errors++;
 			goto tx_error;
 		}
@@ -564,7 +564,7 @@ void ip_tunnel_xmit(struct sk_buff *skb, struct net_device *dev,
 
 			neigh = dst_neigh_lookup(skb_dst(skb),
 						 &ipv6_hdr(skb)->daddr);
-			if (neigh == NULL)
+			if (!neigh)
 				goto tx_error;
 
 			addr6 = (const struct in6_addr *)&neigh->primary_key;
@@ -722,7 +722,7 @@ int ip_tunnel_ioctl(struct net_device *dev, struct ip_tunnel_parm *p, int cmd)
 	case SIOCGETTUNNEL:
 		if (dev == itn->fb_tunnel_dev) {
 			t = ip_tunnel_find(itn, p, itn->fb_tunnel_dev->type);
-			if (t == NULL)
+			if (!t)
 				t = netdev_priv(dev);
 		}
 		memcpy(p, &t->parms, sizeof(*p));
@@ -793,7 +793,7 @@ int ip_tunnel_ioctl(struct net_device *dev, struct ip_tunnel_parm *p, int cmd)
 		if (dev == itn->fb_tunnel_dev) {
 			err = -ENOENT;
 			t = ip_tunnel_find(itn, p, itn->fb_tunnel_dev->type);
-			if (t == NULL)
+			if (!t)
 				goto done;
 			err = -EPERM;
 			if (t == netdev_priv(itn->fb_tunnel_dev))
diff --git a/net/ipv4/ipcomp.c b/net/ipv4/ipcomp.c
index c0855d50a3fa..d97f4f2787f5 100644
--- a/net/ipv4/ipcomp.c
+++ b/net/ipv4/ipcomp.c
@@ -63,7 +63,7 @@ static struct xfrm_state *ipcomp_tunnel_create(struct xfrm_state *x)
 	struct xfrm_state *t;
 
 	t = xfrm_state_alloc(net);
-	if (t == NULL)
+	if (!t)
 		goto out;
 
 	t->id.proto = IPPROTO_IPIP;
diff --git a/net/ipv4/ipconfig.c b/net/ipv4/ipconfig.c
index efa1138fa523..fc884e897a61 100644
--- a/net/ipv4/ipconfig.c
+++ b/net/ipv4/ipconfig.c
@@ -505,7 +505,8 @@ ic_rarp_recv(struct sk_buff *skb, struct net_device *dev, struct packet_type *pt
 	if (!net_eq(dev_net(dev), &init_net))
 		goto drop;
 
-	if ((skb = skb_share_check(skb, GFP_ATOMIC)) == NULL)
+	skb = skb_share_check(skb, GFP_ATOMIC);
+	if (!skb)
 		return NET_RX_DROP;
 
 	if (!pskb_may_pull(skb, sizeof(struct arphdr)))
@@ -959,7 +960,8 @@ static int __init ic_bootp_recv(struct sk_buff *skb, struct net_device *dev, str
 	if (skb->pkt_type == PACKET_OTHERHOST)
 		goto drop;
 
-	if ((skb = skb_share_check(skb, GFP_ATOMIC)) == NULL)
+	skb = skb_share_check(skb, GFP_ATOMIC);
+	if (!skb)
 		return NET_RX_DROP;
 
 	if (!pskb_may_pull(skb,
diff --git a/net/ipv4/ipip.c b/net/ipv4/ipip.c
index 9c98996b11f7..b0244934dbcc 100644
--- a/net/ipv4/ipip.c
+++ b/net/ipv4/ipip.c
@@ -144,7 +144,7 @@ static int ipip_err(struct sk_buff *skb, u32 info)
 	err = -ENOENT;
 	t = ip_tunnel_lookup(itn, skb->dev->ifindex, TUNNEL_NO_KEY,
 			     iph->daddr, iph->saddr, 0);
-	if (t == NULL)
+	if (!t)
 		goto out;
 
 	if (type == ICMP_DEST_UNREACH && code == ICMP_FRAG_NEEDED) {
* Unmerged path net/ipv4/ipmr.c
* Unmerged path net/ipv4/ping.c
diff --git a/net/ipv4/raw.c b/net/ipv4/raw.c
index aa890cf77afa..c7410a366b24 100644
--- a/net/ipv4/raw.c
+++ b/net/ipv4/raw.c
@@ -348,7 +348,7 @@ static int raw_send_hdrinc(struct sock *sk, struct flowi4 *fl4,
 	skb = sock_alloc_send_skb(sk,
 				  length + hlen + tlen + 15,
 				  flags & MSG_DONTWAIT, &err);
-	if (skb == NULL)
+	if (!skb)
 		goto error;
 	skb_reserve(skb, hlen);
 
diff --git a/net/ipv4/route.c b/net/ipv4/route.c
index e5dadb183261..e9e2f7dcc068 100644
--- a/net/ipv4/route.c
+++ b/net/ipv4/route.c
@@ -1024,7 +1024,7 @@ void ipv4_sk_update_pmtu(struct sk_buff *skb, struct sock *sk, u32 mtu)
 	__build_flow_key(&fl4, sk, iph, 0, 0, 0, 0, 0);
 
 	rt = (struct rtable *)odst;
-	if (odst->obsolete && odst->ops->check(odst, 0) == NULL) {
+	if (odst->obsolete && !odst->ops->check(odst, 0)) {
 		rt = ip_route_output_flow(sock_net(sk), &fl4, sk);
 		if (IS_ERR(rt))
 			goto out;
@@ -1397,7 +1397,7 @@ static int ip_route_input_mc(struct sk_buff *skb, __be32 daddr, __be32 saddr,
 
 	/* Primary sanity checks. */
 
-	if (in_dev == NULL)
+	if (!in_dev)
 		return -EINVAL;
 
 	if (ipv4_is_multicast(saddr) || ipv4_is_lbcast(saddr) ||
@@ -1499,7 +1499,7 @@ static int __mkroute_input(struct sk_buff *skb,
 
 	/* get a working reference to the output device */
 	out_dev = __in_dev_get_rcu(FIB_RES_DEV(*res));
-	if (out_dev == NULL) {
+	if (!out_dev) {
 		net_crit_ratelimited("Bug in ip_route_input_slow(). Please report.\n");
 		return -EINVAL;
 	}
@@ -1992,7 +1992,7 @@ struct rtable *__ip_route_output_key(struct net *net, struct flowi4 *fl4)
 		     ipv4_is_lbcast(fl4->daddr))) {
 			/* It is equivalent to inet_addr_type(saddr) == RTN_LOCAL */
 			dev_out = __ip_dev_find(net, fl4->saddr, false);
-			if (dev_out == NULL)
+			if (!dev_out)
 				goto out;
 
 			/* Special hack: user can direct multicasts
@@ -2025,7 +2025,7 @@ struct rtable *__ip_route_output_key(struct net *net, struct flowi4 *fl4)
 	if (fl4->flowi4_oif) {
 		dev_out = dev_get_by_index_rcu(net, fl4->flowi4_oif);
 		rth = ERR_PTR(-ENODEV);
-		if (dev_out == NULL)
+		if (!dev_out)
 			goto out;
 
 		/* RACE: Check return value of inet_select_addr instead. */
@@ -2238,7 +2238,7 @@ static int rt_fill_info(struct net *net,  __be32 dst, __be32 src,
 	u32 metrics[RTAX_MAX];
 
 	nlh = nlmsg_put(skb, portid, seq, event, sizeof(*r), flags);
-	if (nlh == NULL)
+	if (!nlh)
 		return -EMSGSIZE;
 
 	r = nlmsg_data(nlh);
@@ -2359,7 +2359,7 @@ static int inet_rtm_getroute(struct sk_buff *in_skb, struct nlmsghdr *nlh)
 	rtm = nlmsg_data(nlh);
 
 	skb = alloc_skb(NLMSG_GOODSIZE, GFP_KERNEL);
-	if (skb == NULL) {
+	if (!skb) {
 		err = -ENOBUFS;
 		goto errout;
 	}
@@ -2390,7 +2390,7 @@ static int inet_rtm_getroute(struct sk_buff *in_skb, struct nlmsghdr *nlh)
 		struct net_device *dev;
 
 		dev = __dev_get_by_index(net, iif);
-		if (dev == NULL) {
+		if (!dev) {
 			err = -ENODEV;
 			goto errout_free;
 		}
@@ -2594,7 +2594,7 @@ static __net_init int sysctl_route_net_init(struct net *net)
 	tbl = ipv4_route_flush_table;
 	if (!net_eq(net, &init_net)) {
 		tbl = kmemdup(tbl, sizeof(ipv4_route_flush_table), GFP_KERNEL);
-		if (tbl == NULL)
+		if (!tbl)
 			goto err_dup;
 
 		/* Don't export sysctls to unprivileged users */
@@ -2604,7 +2604,7 @@ static __net_init int sysctl_route_net_init(struct net *net)
 	tbl[0].extra1 = net;
 
 	net->ipv4.route_hdr = register_net_sysctl(net, "net/ipv4/route", tbl);
-	if (net->ipv4.route_hdr == NULL)
+	if (!net->ipv4.route_hdr)
 		goto err_reg;
 	return 0;
 
diff --git a/net/ipv4/sysctl_net_ipv4.c b/net/ipv4/sysctl_net_ipv4.c
index 86ec716ad775..cf1a3d68400a 100644
--- a/net/ipv4/sysctl_net_ipv4.c
+++ b/net/ipv4/sysctl_net_ipv4.c
@@ -879,7 +879,7 @@ static __net_init int ipv4_sysctl_init_net(struct net *net)
 	table = ipv4_net_table;
 	if (!net_eq(net, &init_net)) {
 		table = kmemdup(table, sizeof(ipv4_net_table), GFP_KERNEL);
-		if (table == NULL)
+		if (!table)
 			goto err_alloc;
 
 		table[0].data =
@@ -914,7 +914,7 @@ static __net_init int ipv4_sysctl_init_net(struct net *net)
 	tcp_init_mem(net);
 
 	net->ipv4.ipv4_hdr = register_net_sysctl(net, "net/ipv4", table);
-	if (net->ipv4.ipv4_hdr == NULL)
+	if (!net->ipv4.ipv4_hdr)
 		goto err_reg;
 
 	return 0;
@@ -955,7 +955,7 @@ static __init int sysctl_ipv4_init(void)
 		return -EINVAL;
 
 	hdr = register_net_sysctl(&init_net, "net/ipv4", ipv4_table);
-	if (hdr == NULL)
+	if (!hdr)
 		return -ENOMEM;
 
 	if (register_pernet_subsys(&ipv4_sysctl_ops)) {
diff --git a/net/ipv4/tcp.c b/net/ipv4/tcp.c
index 82001502275d..4a7fdae7ac01 100644
--- a/net/ipv4/tcp.c
+++ b/net/ipv4/tcp.c
@@ -1054,7 +1054,7 @@ static int tcp_sendmsg_fastopen(struct sock *sk, struct msghdr *msg,
 
 	tp->fastopen_req = kzalloc(sizeof(struct tcp_fastopen_request),
 				   sk->sk_allocation);
-	if (unlikely(tp->fastopen_req == NULL))
+	if (unlikely(!tp->fastopen_req))
 		return -ENOBUFS;
 	tp->fastopen_req->data = msg;
 	tp->fastopen_req->size = size;
* Unmerged path net/ipv4/tcp_fastopen.c
* Unmerged path net/ipv4/tcp_input.c
diff --git a/net/ipv4/tcp_ipv4.c b/net/ipv4/tcp_ipv4.c
index cf2a920676db..1fdf97aa790f 100644
--- a/net/ipv4/tcp_ipv4.c
+++ b/net/ipv4/tcp_ipv4.c
@@ -123,7 +123,7 @@ int tcp_twsk_unique(struct sock *sk, struct sock *sktw, void *twp)
 	   and use initial timestamp retrieved from peer table.
 	 */
 	if (tcptw->tw_ts_recent_stamp &&
-	    (twp == NULL || (sysctl_tcp_tw_reuse &&
+	    (!twp || (sysctl_tcp_tw_reuse &&
 			     get_seconds() - tcptw->tw_ts_recent_stamp > 1))) {
 		tp->write_seq = tcptw->tw_snd_nxt + 65535 + 2;
 		if (tp->write_seq == 0)
@@ -497,7 +497,7 @@ void tcp_v4_err(struct sk_buff *icmp_skb, u32 info)
 		/* Only in fast or simultaneous open. If a fast open socket is
 		 * is already accepted it is treated as a connected one below.
 		 */
-		if (fastopen && fastopen->sk == NULL)
+		if (fastopen && !fastopen->sk)
 			break;
 
 		if (!sock_owned_by_user(sk)) {
@@ -1769,7 +1769,7 @@ int tcp_v4_do_rcv(struct sock *sk, struct sk_buff *skb)
 		sock_rps_save_rxhash(sk, skb);
 		if (dst) {
 			if (inet_sk(sk)->rx_dst_ifindex != skb->skb_iif ||
-			    dst->ops->check(dst, 0) == NULL) {
+			    !dst->ops->check(dst, 0)) {
 				dst_release(dst);
 				sk->sk_rx_dst = NULL;
 			}
diff --git a/net/ipv4/tcp_metrics.c b/net/ipv4/tcp_metrics.c
index a6d841c9a986..5d8cbffa9436 100644
--- a/net/ipv4/tcp_metrics.c
+++ b/net/ipv4/tcp_metrics.c
@@ -475,7 +475,7 @@ void tcp_init_metrics(struct sock *sk)
 	struct tcp_metrics_block *tm;
 	u32 val, crtt = 0; /* cached RTT scaled by 8 */
 
-	if (dst == NULL)
+	if (!dst)
 		goto reset;
 
 	dst_confirm(dst);
diff --git a/net/ipv4/tcp_minisocks.c b/net/ipv4/tcp_minisocks.c
index 6c69a4574ad0..9e6651e29a9e 100644
--- a/net/ipv4/tcp_minisocks.c
+++ b/net/ipv4/tcp_minisocks.c
@@ -711,7 +711,7 @@ struct sock *tcp_check_req(struct sock *sk, struct sk_buff *skb,
 	 * socket is created, wait for troubles.
 	 */
 	child = inet_csk(sk)->icsk_af_ops->syn_recv_sock(sk, skb, req, NULL);
-	if (child == NULL)
+	if (!child)
 		goto listen_overflow;
 
 	inet_csk_reqsk_queue_unlink(sk, req, prev);
* Unmerged path net/ipv4/tcp_output.c
diff --git a/net/ipv4/udp.c b/net/ipv4/udp.c
index 8d174c3136c6..b7925578ea46 100644
--- a/net/ipv4/udp.c
+++ b/net/ipv4/udp.c
@@ -621,7 +621,7 @@ void __udp4_lib_err(struct sk_buff *skb, u32 info, struct udp_table *udptable)
 
 	sk = __udp4_lib_lookup(net, iph->daddr, uh->dest,
 			iph->saddr, uh->source, skb->dev->ifindex, udptable);
-	if (sk == NULL) {
+	if (!sk) {
 		ICMP_INC_STATS_BH(net, ICMP_MIB_INERRORS);
 		return;	/* No socket for error */
 	}
@@ -997,7 +997,7 @@ int udp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg,
 	if (connected)
 		rt = (struct rtable *)sk_dst_check(sk, 0);
 
-	if (rt == NULL) {
+	if (!rt) {
 		struct net *net = sock_net(sk);
 
 		fl4 = &fl4_stack;
@@ -1602,7 +1602,7 @@ static void flush_stack(struct sock **stack, unsigned int count,
 
 	for (i = 0; i < count; i++) {
 		sk = stack[i];
-		if (likely(skb1 == NULL))
+		if (likely(!skb1))
 			skb1 = (i == final) ? skb : skb_clone(skb, GFP_ATOMIC);
 
 		if (!skb1) {
diff --git a/net/ipv4/udp_diag.c b/net/ipv4/udp_diag.c
index 4a000f1dd757..eb0de3b9bdb4 100644
--- a/net/ipv4/udp_diag.c
+++ b/net/ipv4/udp_diag.c
@@ -56,7 +56,7 @@ static int udp_dump_one(struct udp_table *tbl, struct sk_buff *in_skb,
 		goto out_nosk;
 
 	err = -ENOENT;
-	if (sk == NULL)
+	if (!sk)
 		goto out_nosk;
 
 	err = sock_diag_check_cookie(sk, req->id.idiag_cookie);
diff --git a/net/ipv4/xfrm4_input.c b/net/ipv4/xfrm4_input.c
index aac6197b7a71..cac7468db0a1 100644
--- a/net/ipv4/xfrm4_input.c
+++ b/net/ipv4/xfrm4_input.c
@@ -24,7 +24,7 @@ int xfrm4_extract_input(struct xfrm_state *x, struct sk_buff *skb)
 
 static inline int xfrm4_rcv_encap_finish(struct sk_buff *skb)
 {
-	if (skb_dst(skb) == NULL) {
+	if (!skb_dst(skb)) {
 		const struct iphdr *iph = ip_hdr(skb);
 
 		if (ip_route_input_noref(skb, iph->daddr, iph->saddr,
diff --git a/net/ipv4/xfrm4_policy.c b/net/ipv4/xfrm4_policy.c
index 9a459be24af7..e91fdc66b5be 100644
--- a/net/ipv4/xfrm4_policy.c
+++ b/net/ipv4/xfrm4_policy.c
@@ -294,7 +294,7 @@ static void __net_exit xfrm4_net_exit(struct net *net)
 {
 	struct ctl_table *table;
 
-	if (net->ipv4.xfrm4_hdr == NULL)
+	if (!net->ipv4.xfrm4_hdr)
 		return;
 
 	table = net->ipv4.xfrm4_hdr->ctl_table_arg;
