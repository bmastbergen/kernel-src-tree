xfs: refactor recovery transaction start handling

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Dave Chinner <dchinner@redhat.com>
commit b818cca1976d1a01754033ac08724e05d07cce8f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/b818cca1.failed

Rework the transaction lookup and allocation code in
xlog_recovery_process_ophdr() to fold two related call-once
helper functions into a single helper. Then fold in all the
XLOG_START_TRANS logic to that helper to clean up the remaining
logic in xlog_recovery_process_ophdr().

	Signed-off-by: Dave Chinner <dchinner@redhat.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Dave Chinner <david@fromorbit.com>
(cherry picked from commit b818cca1976d1a01754033ac08724e05d07cce8f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/xfs_log_recover.c
diff --cc fs/xfs/xfs_log_recover.c
index da155de2b4de,5019f52e4cc2..000000000000
--- a/fs/xfs/xfs_log_recover.c
+++ b/fs/xfs/xfs_log_recover.c
@@@ -3533,16 -3353,305 +3533,287 @@@ out
  	return error ? error : error2;
  }
  
++<<<<<<< HEAD
++=======
+ STATIC void
+ xlog_recover_add_item(
+ 	struct list_head	*head)
+ {
+ 	xlog_recover_item_t	*item;
+ 
+ 	item = kmem_zalloc(sizeof(xlog_recover_item_t), KM_SLEEP);
+ 	INIT_LIST_HEAD(&item->ri_list);
+ 	list_add_tail(&item->ri_list, head);
+ }
+ 
++>>>>>>> b818cca1976d (xfs: refactor recovery transaction start handling)
  STATIC int
 -xlog_recover_add_to_cont_trans(
 -	struct xlog		*log,
 -	struct xlog_recover	*trans,
 -	xfs_caddr_t		dp,
 -	int			len)
 +xlog_recover_unmount_trans(
 +	struct xlog		*log)
  {
 -	xlog_recover_item_t	*item;
 -	xfs_caddr_t		ptr, old_ptr;
 -	int			old_len;
 -
 -	if (list_empty(&trans->r_itemq)) {
 -		/* finish copying rest of trans header */
 -		xlog_recover_add_item(&trans->r_itemq);
 -		ptr = (xfs_caddr_t) &trans->r_theader +
 -				sizeof(xfs_trans_header_t) - len;
 -		memcpy(ptr, dp, len);
 -		return 0;
 -	}
 -	/* take the tail entry */
 -	item = list_entry(trans->r_itemq.prev, xlog_recover_item_t, ri_list);
 -
 -	old_ptr = item->ri_buf[item->ri_cnt-1].i_addr;
 -	old_len = item->ri_buf[item->ri_cnt-1].i_len;
 -
 -	ptr = kmem_realloc(old_ptr, len+old_len, old_len, KM_SLEEP);
 -	memcpy(&ptr[old_len], dp, len);
 -	item->ri_buf[item->ri_cnt-1].i_len += len;
 -	item->ri_buf[item->ri_cnt-1].i_addr = ptr;
 -	trace_xfs_log_recover_item_add_cont(log, trans, item, 0);
 +	/* Do nothing now */
 +	xfs_warn(log->l_mp, "%s: Unmount LR", __func__);
  	return 0;
  }
  
  /*
++<<<<<<< HEAD
++=======
+  * The next region to add is the start of a new region.  It could be
+  * a whole region or it could be the first part of a new region.  Because
+  * of this, the assumption here is that the type and size fields of all
+  * format structures fit into the first 32 bits of the structure.
+  *
+  * This works because all regions must be 32 bit aligned.  Therefore, we
+  * either have both fields or we have neither field.  In the case we have
+  * neither field, the data part of the region is zero length.  We only have
+  * a log_op_header and can throw away the header since a new one will appear
+  * later.  If we have at least 4 bytes, then we can determine how many regions
+  * will appear in the current log item.
+  */
+ STATIC int
+ xlog_recover_add_to_trans(
+ 	struct xlog		*log,
+ 	struct xlog_recover	*trans,
+ 	xfs_caddr_t		dp,
+ 	int			len)
+ {
+ 	xfs_inode_log_format_t	*in_f;			/* any will do */
+ 	xlog_recover_item_t	*item;
+ 	xfs_caddr_t		ptr;
+ 
+ 	if (!len)
+ 		return 0;
+ 	if (list_empty(&trans->r_itemq)) {
+ 		/* we need to catch log corruptions here */
+ 		if (*(uint *)dp != XFS_TRANS_HEADER_MAGIC) {
+ 			xfs_warn(log->l_mp, "%s: bad header magic number",
+ 				__func__);
+ 			ASSERT(0);
+ 			return -EIO;
+ 		}
+ 		if (len == sizeof(xfs_trans_header_t))
+ 			xlog_recover_add_item(&trans->r_itemq);
+ 		memcpy(&trans->r_theader, dp, len);
+ 		return 0;
+ 	}
+ 
+ 	ptr = kmem_alloc(len, KM_SLEEP);
+ 	memcpy(ptr, dp, len);
+ 	in_f = (xfs_inode_log_format_t *)ptr;
+ 
+ 	/* take the tail entry */
+ 	item = list_entry(trans->r_itemq.prev, xlog_recover_item_t, ri_list);
+ 	if (item->ri_total != 0 &&
+ 	     item->ri_total == item->ri_cnt) {
+ 		/* tail item is in use, get a new one */
+ 		xlog_recover_add_item(&trans->r_itemq);
+ 		item = list_entry(trans->r_itemq.prev,
+ 					xlog_recover_item_t, ri_list);
+ 	}
+ 
+ 	if (item->ri_total == 0) {		/* first region to be added */
+ 		if (in_f->ilf_size == 0 ||
+ 		    in_f->ilf_size > XLOG_MAX_REGIONS_IN_ITEM) {
+ 			xfs_warn(log->l_mp,
+ 		"bad number of regions (%d) in inode log format",
+ 				  in_f->ilf_size);
+ 			ASSERT(0);
+ 			kmem_free(ptr);
+ 			return -EIO;
+ 		}
+ 
+ 		item->ri_total = in_f->ilf_size;
+ 		item->ri_buf =
+ 			kmem_zalloc(item->ri_total * sizeof(xfs_log_iovec_t),
+ 				    KM_SLEEP);
+ 	}
+ 	ASSERT(item->ri_total > item->ri_cnt);
+ 	/* Description region is ri_buf[0] */
+ 	item->ri_buf[item->ri_cnt].i_addr = ptr;
+ 	item->ri_buf[item->ri_cnt].i_len  = len;
+ 	item->ri_cnt++;
+ 	trace_xfs_log_recover_item_add(log, trans, item, 0);
+ 	return 0;
+ }
+ 
+ /*
+  * Free up any resources allocated by the transaction
+  *
+  * Remember that EFIs, EFDs, and IUNLINKs are handled later.
+  */
+ STATIC void
+ xlog_recover_free_trans(
+ 	struct xlog_recover	*trans)
+ {
+ 	xlog_recover_item_t	*item, *n;
+ 	int			i;
+ 
+ 	list_for_each_entry_safe(item, n, &trans->r_itemq, ri_list) {
+ 		/* Free the regions in the item. */
+ 		list_del(&item->ri_list);
+ 		for (i = 0; i < item->ri_cnt; i++)
+ 			kmem_free(item->ri_buf[i].i_addr);
+ 		/* Free the item itself */
+ 		kmem_free(item->ri_buf);
+ 		kmem_free(item);
+ 	}
+ 	/* Free the transaction recover structure */
+ 	kmem_free(trans);
+ }
+ 
+ /*
+  * On error or completion, trans is freed.
+  */
+ STATIC int
+ xlog_recovery_process_trans(
+ 	struct xlog		*log,
+ 	struct xlog_recover	*trans,
+ 	xfs_caddr_t		dp,
+ 	unsigned int		len,
+ 	unsigned int		flags,
+ 	int			pass)
+ {
+ 	int			error = 0;
+ 	bool			freeit = false;
+ 
+ 	/* mask off ophdr transaction container flags */
+ 	flags &= ~XLOG_END_TRANS;
+ 	if (flags & XLOG_WAS_CONT_TRANS)
+ 		flags &= ~XLOG_CONTINUE_TRANS;
+ 
+ 	/*
+ 	 * Callees must not free the trans structure. We'll decide if we need to
+ 	 * free it or not based on the operation being done and it's result.
+ 	 */
+ 	switch (flags) {
+ 	/* expected flag values */
+ 	case 0:
+ 	case XLOG_CONTINUE_TRANS:
+ 		error = xlog_recover_add_to_trans(log, trans, dp, len);
+ 		break;
+ 	case XLOG_WAS_CONT_TRANS:
+ 		error = xlog_recover_add_to_cont_trans(log, trans, dp, len);
+ 		break;
+ 	case XLOG_COMMIT_TRANS:
+ 		error = xlog_recover_commit_trans(log, trans, pass);
+ 		/* success or fail, we are now done with this transaction. */
+ 		freeit = true;
+ 		break;
+ 
+ 	/* unexpected flag values */
+ 	case XLOG_UNMOUNT_TRANS:
+ 		/* just skip trans */
+ 		xfs_warn(log->l_mp, "%s: Unmount LR", __func__);
+ 		freeit = true;
+ 		break;
+ 	case XLOG_START_TRANS:
+ 	default:
+ 		xfs_warn(log->l_mp, "%s: bad flag 0x%x", __func__, flags);
+ 		ASSERT(0);
+ 		error = -EIO;
+ 		break;
+ 	}
+ 	if (error || freeit)
+ 		xlog_recover_free_trans(trans);
+ 	return error;
+ }
+ 
+ /*
+  * Lookup the transaction recovery structure associated with the ID in the
+  * current ophdr. If the transaction doesn't exist and the start flag is set in
+  * the ophdr, then allocate a new transaction for future ID matches to find.
+  * Either way, return what we found during the lookup - an existing transaction
+  * or nothing.
+  */
+ STATIC struct xlog_recover *
+ xlog_recover_ophdr_to_trans(
+ 	struct hlist_head	rhash[],
+ 	struct xlog_rec_header	*rhead,
+ 	struct xlog_op_header	*ohead)
+ {
+ 	struct xlog_recover	*trans;
+ 	xlog_tid_t		tid;
+ 	struct hlist_head	*rhp;
+ 
+ 	tid = be32_to_cpu(ohead->oh_tid);
+ 	rhp = &rhash[XLOG_RHASH(tid)];
+ 	hlist_for_each_entry(trans, rhp, r_list) {
+ 		if (trans->r_log_tid == tid)
+ 			return trans;
+ 	}
+ 
+ 	/*
+ 	 * skip over non-start transaction headers - we could be
+ 	 * processing slack space before the next transaction starts
+ 	 */
+ 	if (!(ohead->oh_flags & XLOG_START_TRANS))
+ 		return NULL;
+ 
+ 	ASSERT(be32_to_cpu(ohead->oh_len) == 0);
+ 
+ 	/*
+ 	 * This is a new transaction so allocate a new recovery container to
+ 	 * hold the recovery ops that will follow.
+ 	 */
+ 	trans = kmem_zalloc(sizeof(struct xlog_recover), KM_SLEEP);
+ 	trans->r_log_tid = tid;
+ 	trans->r_lsn = be64_to_cpu(rhead->h_lsn);
+ 	INIT_LIST_HEAD(&trans->r_itemq);
+ 	INIT_HLIST_NODE(&trans->r_list);
+ 	hlist_add_head(&trans->r_list, rhp);
+ 
+ 	/*
+ 	 * Nothing more to do for this ophdr. Items to be added to this new
+ 	 * transaction will be in subsequent ophdr containers.
+ 	 */
+ 	return NULL;
+ }
+ 
+ STATIC int
+ xlog_recover_process_ophdr(
+ 	struct xlog		*log,
+ 	struct hlist_head	rhash[],
+ 	struct xlog_rec_header	*rhead,
+ 	struct xlog_op_header	*ohead,
+ 	xfs_caddr_t		dp,
+ 	xfs_caddr_t		end,
+ 	int			pass)
+ {
+ 	struct xlog_recover	*trans;
+ 	unsigned int		len;
+ 
+ 	/* Do we understand who wrote this op? */
+ 	if (ohead->oh_clientid != XFS_TRANSACTION &&
+ 	    ohead->oh_clientid != XFS_LOG) {
+ 		xfs_warn(log->l_mp, "%s: bad clientid 0x%x",
+ 			__func__, ohead->oh_clientid);
+ 		ASSERT(0);
+ 		return -EIO;
+ 	}
+ 
+ 	/*
+ 	 * Check the ophdr contains all the data it is supposed to contain.
+ 	 */
+ 	len = be32_to_cpu(ohead->oh_len);
+ 	if (dp + len > end) {
+ 		xfs_warn(log->l_mp, "%s: bad length 0x%x", __func__, len);
+ 		WARN_ON(1);
+ 		return -EIO;
+ 	}
+ 
+ 	trans = xlog_recover_ophdr_to_trans(rhash, rhead, ohead);
+ 	if (!trans) {
+ 		/* nothing to do, so skip over this ophdr */
+ 		return 0;
+ 	}
+ 
+ 	return xlog_recovery_process_trans(log, trans, dp, len,
+ 					   ohead->oh_flags, pass);
+ }
+ 
+ /*
++>>>>>>> b818cca1976d (xfs: refactor recovery transaction start handling)
   * There are two valid states of the r_state field.  0 indicates that the
   * transaction structure is in a normal state.  We have either seen the
   * start of the transaction or the last operation we added was not a partial
* Unmerged path fs/xfs/xfs_log_recover.c
