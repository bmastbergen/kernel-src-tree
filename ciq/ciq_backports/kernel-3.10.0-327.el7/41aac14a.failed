KVM: x86/vPMU: introduce kvm_pmu_msr_idx_to_pmc

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [x86] kvm: vpmu: introduce kvm_pmu_msr_idx_to_pmc (Wei Huang) [1076010]
Rebuild_FUZZ: 95.56%
commit-author Wei Huang <wehuang@redhat.com>
commit 41aac14a8dee66a720894e5979c2372c0d5afd34
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/41aac14a.failed

This function will be part of the kvm_pmu_ops interface.  Introduce
it already.

	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 41aac14a8dee66a720894e5979c2372c0d5afd34)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/pmu.c
diff --cc arch/x86/kvm/pmu.c
index ed5c6727d1e3,bd5dbd9ce0e3..000000000000
--- a/arch/x86/kvm/pmu.c
+++ b/arch/x86/kvm/pmu.c
@@@ -315,10 -315,81 +315,85 @@@ static void global_ctrl_changed(struct 
  	pmu->global_ctrl = data;
  
  	for_each_set_bit(bit, (unsigned long *)&diff, X86_PMC_IDX_MAX)
 -		reprogram_counter(pmu, bit);
 +		reprogram_idx(pmu, bit);
  }
  
++<<<<<<< HEAD
 +bool kvm_pmu_msr(struct kvm_vcpu *vcpu, u32 msr)
++=======
+ void kvm_pmu_handle_event(struct kvm_vcpu *vcpu)
+ {
+ 	struct kvm_pmu *pmu = vcpu_to_pmu(vcpu);
+ 	u64 bitmask;
+ 	int bit;
+ 
+ 	bitmask = pmu->reprogram_pmi;
+ 
+ 	for_each_set_bit(bit, (unsigned long *)&bitmask, X86_PMC_IDX_MAX) {
+ 		struct kvm_pmc *pmc = global_idx_to_pmc(pmu, bit);
+ 
+ 		if (unlikely(!pmc || !pmc->perf_event)) {
+ 			clear_bit(bit, (unsigned long *)&pmu->reprogram_pmi);
+ 			continue;
+ 		}
+ 
+ 		reprogram_counter(pmu, bit);
+ 	}
+ }
+ 
+ /* check if idx is a valid index to access PMU */
+ int kvm_pmu_is_valid_msr_idx(struct kvm_vcpu *vcpu, unsigned idx)
+ {
+ 	struct kvm_pmu *pmu = vcpu_to_pmu(vcpu);
+ 	bool fixed = idx & (1u << 30);
+ 	idx &= ~(3u << 30);
+ 	return (!fixed && idx >= pmu->nr_arch_gp_counters) ||
+ 		(fixed && idx >= pmu->nr_arch_fixed_counters);
+ }
+ 
+ static struct kvm_pmc *kvm_pmu_msr_idx_to_pmc(struct kvm_vcpu *vcpu,
+                                             unsigned idx)
+ {
+ 	struct kvm_pmu *pmu = vcpu_to_pmu(vcpu);
+ 	bool fixed = idx & (1u << 30);
+ 	struct kvm_pmc *counters;
+ 
+ 	idx &= ~(3u << 30);
+ 	if (!fixed && idx >= pmu->nr_arch_gp_counters)
+ 		return NULL;
+ 	if (fixed && idx >= pmu->nr_arch_fixed_counters)
+ 		return NULL;
+ 	counters = fixed ? pmu->fixed_counters : pmu->gp_counters;
+ 
+ 	return &counters[idx];
+ }
+ 
+ int kvm_pmu_rdpmc(struct kvm_vcpu *vcpu, unsigned idx, u64 *data)
+ {
+ 	bool fast_mode = idx & (1u << 31);
+ 	struct kvm_pmc *pmc;
+ 	u64 ctr_val;
+ 
+ 	pmc = kvm_pmu_msr_idx_to_pmc(vcpu, idx);
+ 	if (!pmc)
+ 		return 1;
+ 
+ 	ctr_val = pmc_read_counter(pmc);
+ 	if (fast_mode)
+ 		ctr_val = (u32)ctr_val;
+ 
+ 	*data = ctr_val;
+ 	return 0;
+ }
+ 
+ void kvm_pmu_deliver_pmi(struct kvm_vcpu *vcpu)
+ {
+ 	if (vcpu->arch.apic)
+ 		kvm_apic_local_deliver(vcpu->arch.apic, APIC_LVTPC);
+ }
+ 
+ bool kvm_pmu_is_valid_msr(struct kvm_vcpu *vcpu, u32 msr)
++>>>>>>> 41aac14a8dee (KVM: x86/vPMU: introduce kvm_pmu_msr_idx_to_pmc)
  {
  	struct kvm_pmu *pmu = vcpu_to_pmu(vcpu);
  	int ret;
* Unmerged path arch/x86/kvm/pmu.c
