perf/x86/intel: Add new cache events table for Haswell

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [x86] perf: Add new cache events table for Haswell (Jiri Olsa) [1086843]
Rebuild_FUZZ: 89.80%
commit-author Andi Kleen <ak@linux.intel.com>
commit 0f1b5ca240c65ed9533f193720f337bf24fb2f2f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/0f1b5ca2.failed

Haswell offcore events are quite different from Sandy Bridge.
Add a new table to handle Haswell properly.

Note that the offcore bits listed in the SDM are not quite correct
(this is currently being fixed). An uptodate list of bits is
in the patch.

The basic setup is similar to Sandy Bridge. The prefetch columns
have been removed, as prefetch counting is not very reliable
on Haswell. One L1 event that is not in the event list anymore
has been also removed.

- data reads do not include code reads (comparable to earlier Sandy Bridge tables)
- data counts include speculative execution (except L1 write, dtlb, bpu)
- remote node access includes both remote memory, remote cache, remote mmio.
- prefetches are not included in the counts for consistency
  (different from Sandy Bridge, which includes prefetches in the remote node)

	Signed-off-by: Andi Kleen <ak@linux.intel.com>
[ Removed the HSM30 comments; we don't have them for SNB/IVB either. ]
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: http://lkml.kernel.org/r/1424225886-18652-1-git-send-email-andi@firstfloor.org
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 0f1b5ca240c65ed9533f193720f337bf24fb2f2f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/perf_event_intel.c
diff --cc arch/x86/kernel/cpu/perf_event_intel.c
index b3b49b7a9d14,5ef64bf88ecd..000000000000
--- a/arch/x86/kernel/cpu/perf_event_intel.c
+++ b/arch/x86/kernel/cpu/perf_event_intel.c
@@@ -424,6 -415,44 +424,47 @@@ static __initconst const u64 snb_hw_cac
  
  };
  
++<<<<<<< HEAD
++=======
+ /*
+  * Notes on the events:
+  * - data reads do not include code reads (comparable to earlier tables)
+  * - data counts include speculative execution (except L1 write, dtlb, bpu)
+  * - remote node access includes remote memory, remote cache, remote mmio.
+  * - prefetches are not included in the counts because they are not
+  *   reliably counted.
+  */
+ 
+ #define HSW_DEMAND_DATA_RD		BIT_ULL(0)
+ #define HSW_DEMAND_RFO			BIT_ULL(1)
+ #define HSW_ANY_RESPONSE		BIT_ULL(16)
+ #define HSW_SUPPLIER_NONE		BIT_ULL(17)
+ #define HSW_L3_MISS_LOCAL_DRAM		BIT_ULL(22)
+ #define HSW_L3_MISS_REMOTE_HOP0		BIT_ULL(27)
+ #define HSW_L3_MISS_REMOTE_HOP1		BIT_ULL(28)
+ #define HSW_L3_MISS_REMOTE_HOP2P	BIT_ULL(29)
+ #define HSW_L3_MISS			(HSW_L3_MISS_LOCAL_DRAM| \
+ 					 HSW_L3_MISS_REMOTE_HOP0|HSW_L3_MISS_REMOTE_HOP1| \
+ 					 HSW_L3_MISS_REMOTE_HOP2P)
+ #define HSW_SNOOP_NONE			BIT_ULL(31)
+ #define HSW_SNOOP_NOT_NEEDED		BIT_ULL(32)
+ #define HSW_SNOOP_MISS			BIT_ULL(33)
+ #define HSW_SNOOP_HIT_NO_FWD		BIT_ULL(34)
+ #define HSW_SNOOP_HIT_WITH_FWD		BIT_ULL(35)
+ #define HSW_SNOOP_HITM			BIT_ULL(36)
+ #define HSW_SNOOP_NON_DRAM		BIT_ULL(37)
+ #define HSW_ANY_SNOOP			(HSW_SNOOP_NONE| \
+ 					 HSW_SNOOP_NOT_NEEDED|HSW_SNOOP_MISS| \
+ 					 HSW_SNOOP_HIT_NO_FWD|HSW_SNOOP_HIT_WITH_FWD| \
+ 					 HSW_SNOOP_HITM|HSW_SNOOP_NON_DRAM)
+ #define HSW_SNOOP_DRAM			(HSW_ANY_SNOOP & ~HSW_SNOOP_NON_DRAM)
+ #define HSW_DEMAND_READ			HSW_DEMAND_DATA_RD
+ #define HSW_DEMAND_WRITE		HSW_DEMAND_RFO
+ #define HSW_L3_MISS_REMOTE		(HSW_L3_MISS_REMOTE_HOP0|\
+ 					 HSW_L3_MISS_REMOTE_HOP1|HSW_L3_MISS_REMOTE_HOP2P)
+ #define HSW_LLC_ACCESS			HSW_ANY_RESPONSE
+ 
++>>>>>>> 0f1b5ca240c6 (perf/x86/intel: Add new cache events table for Haswell)
  static __initconst const u64 hsw_hw_cache_event_ids
  				[PERF_COUNT_HW_CACHE_MAX]
  				[PERF_COUNT_HW_CACHE_OP_MAX]
@@@ -431,11 -460,11 +472,19 @@@
  {
   [ C(L1D ) ] = {
  	[ C(OP_READ) ] = {
++<<<<<<< HEAD
 +		[ C(RESULT_ACCESS) ] = 0x81d0, 	/* MEM_UOPS_RETIRED.ALL_LOADS */
 +		[ C(RESULT_MISS)   ] = 0x151, 	/* L1D.REPLACEMENT */
 +	},
 +	[ C(OP_WRITE) ] = {
 +		[ C(RESULT_ACCESS) ] = 0x82d0, 	/* MEM_UOPS_RETIRED.ALL_STORES */
++=======
+ 		[ C(RESULT_ACCESS) ] = 0x81d0,	/* MEM_UOPS_RETIRED.ALL_LOADS */
+ 		[ C(RESULT_MISS)   ] = 0x151,	/* L1D.REPLACEMENT */
+ 	},
+ 	[ C(OP_WRITE) ] = {
+ 		[ C(RESULT_ACCESS) ] = 0x82d0,	/* MEM_UOPS_RETIRED.ALL_STORES */
++>>>>>>> 0f1b5ca240c6 (perf/x86/intel: Add new cache events table for Haswell)
  		[ C(RESULT_MISS)   ] = 0x0,
  	},
  	[ C(OP_PREFETCH) ] = {
@@@ -446,7 -475,7 +495,11 @@@
   [ C(L1I ) ] = {
  	[ C(OP_READ) ] = {
  		[ C(RESULT_ACCESS) ] = 0x0,
++<<<<<<< HEAD
 +		[ C(RESULT_MISS)   ] = 0x280, 	/* ICACHE.MISSES */
++=======
+ 		[ C(RESULT_MISS)   ] = 0x280,	/* ICACHE.MISSES */
++>>>>>>> 0f1b5ca240c6 (perf/x86/intel: Add new cache events table for Haswell)
  	},
  	[ C(OP_WRITE) ] = {
  		[ C(RESULT_ACCESS) ] = -1,
@@@ -459,16 -488,12 +512,25 @@@
   },
   [ C(LL  ) ] = {
  	[ C(OP_READ) ] = {
++<<<<<<< HEAD
 +		/* OFFCORE_RESPONSE:ALL_DATA_RD|ALL_CODE_RD */
 +		[ C(RESULT_ACCESS) ] = 0x1b7,
 +		/* OFFCORE_RESPONSE:ALL_DATA_RD|ALL_CODE_RD|SUPPLIER_NONE|
 +                   L3_MISS|ANY_SNOOP */
 +		[ C(RESULT_MISS)   ] = 0x1b7,
 +	},
 +	[ C(OP_WRITE) ] = {
 +		[ C(RESULT_ACCESS) ] = 0x1b7, 	/* OFFCORE_RESPONSE:ALL_RFO */
 +		/* OFFCORE_RESPONSE:ALL_RFO|SUPPLIER_NONE|L3_MISS|ANY_SNOOP */
 +		[ C(RESULT_MISS)   ] = 0x1b7,
++=======
+ 		[ C(RESULT_ACCESS) ] = 0x1b7,	/* OFFCORE_RESPONSE */
+ 		[ C(RESULT_MISS)   ] = 0x1b7,	/* OFFCORE_RESPONSE */
+ 	},
+ 	[ C(OP_WRITE) ] = {
+ 		[ C(RESULT_ACCESS) ] = 0x1b7,	/* OFFCORE_RESPONSE */
+ 		[ C(RESULT_MISS)   ] = 0x1b7,	/* OFFCORE_RESPONSE */
++>>>>>>> 0f1b5ca240c6 (perf/x86/intel: Add new cache events table for Haswell)
  	},
  	[ C(OP_PREFETCH) ] = {
  		[ C(RESULT_ACCESS) ] = 0x0,
@@@ -477,12 -502,12 +539,21 @@@
   },
   [ C(DTLB) ] = {
  	[ C(OP_READ) ] = {
++<<<<<<< HEAD
 +		[ C(RESULT_ACCESS) ] = 0x81d0, 	/* MEM_UOPS_RETIRED.ALL_LOADS */
 +		[ C(RESULT_MISS)   ] = 0x108, 	/* DTLB_LOAD_MISSES.MISS_CAUSES_A_WALK */
 +	},
 +	[ C(OP_WRITE) ] = {
 +		[ C(RESULT_ACCESS) ] = 0x82d0, 	/* MEM_UOPS_RETIRED.ALL_STORES */
 +		[ C(RESULT_MISS)   ] = 0x149, 	/* DTLB_STORE_MISSES.MISS_CAUSES_A_WALK */
++=======
+ 		[ C(RESULT_ACCESS) ] = 0x81d0,	/* MEM_UOPS_RETIRED.ALL_LOADS */
+ 		[ C(RESULT_MISS)   ] = 0x108,	/* DTLB_LOAD_MISSES.MISS_CAUSES_A_WALK */
+ 	},
+ 	[ C(OP_WRITE) ] = {
+ 		[ C(RESULT_ACCESS) ] = 0x82d0,	/* MEM_UOPS_RETIRED.ALL_STORES */
+ 		[ C(RESULT_MISS)   ] = 0x149,	/* DTLB_STORE_MISSES.MISS_CAUSES_A_WALK */
++>>>>>>> 0f1b5ca240c6 (perf/x86/intel: Add new cache events table for Haswell)
  	},
  	[ C(OP_PREFETCH) ] = {
  		[ C(RESULT_ACCESS) ] = 0x0,
@@@ -491,8 -516,8 +562,13 @@@
   },
   [ C(ITLB) ] = {
  	[ C(OP_READ) ] = {
++<<<<<<< HEAD
 +		[ C(RESULT_ACCESS) ] = 0x6085, 	/* ITLB_MISSES.STLB_HIT */
 +		[ C(RESULT_MISS)   ] = 0x185, 	/* ITLB_MISSES.MISS_CAUSES_A_WALK */
++=======
+ 		[ C(RESULT_ACCESS) ] = 0x6085,	/* ITLB_MISSES.STLB_HIT */
+ 		[ C(RESULT_MISS)   ] = 0x185,	/* ITLB_MISSES.MISS_CAUSES_A_WALK */
++>>>>>>> 0f1b5ca240c6 (perf/x86/intel: Add new cache events table for Haswell)
  	},
  	[ C(OP_WRITE) ] = {
  		[ C(RESULT_ACCESS) ] = -1,
@@@ -505,8 -530,8 +581,13 @@@
   },
   [ C(BPU ) ] = {
  	[ C(OP_READ) ] = {
++<<<<<<< HEAD
 +		[ C(RESULT_ACCESS) ] = 0xc4, 	/* BR_INST_RETIRED.ALL_BRANCHES */
 +		[ C(RESULT_MISS)   ] = 0xc5, 	/* BR_MISP_RETIRED.ALL_BRANCHES */
++=======
+ 		[ C(RESULT_ACCESS) ] = 0xc4,	/* BR_INST_RETIRED.ALL_BRANCHES */
+ 		[ C(RESULT_MISS)   ] = 0xc5,	/* BR_MISP_RETIRED.ALL_BRANCHES */
++>>>>>>> 0f1b5ca240c6 (perf/x86/intel: Add new cache events table for Haswell)
  	},
  	[ C(OP_WRITE) ] = {
  		[ C(RESULT_ACCESS) ] = -1,
@@@ -517,6 -542,20 +598,23 @@@
  		[ C(RESULT_MISS)   ] = -1,
  	},
   },
++<<<<<<< HEAD
++=======
+  [ C(NODE) ] = {
+ 	[ C(OP_READ) ] = {
+ 		[ C(RESULT_ACCESS) ] = 0x1b7,	/* OFFCORE_RESPONSE */
+ 		[ C(RESULT_MISS)   ] = 0x1b7,	/* OFFCORE_RESPONSE */
+ 	},
+ 	[ C(OP_WRITE) ] = {
+ 		[ C(RESULT_ACCESS) ] = 0x1b7,	/* OFFCORE_RESPONSE */
+ 		[ C(RESULT_MISS)   ] = 0x1b7,	/* OFFCORE_RESPONSE */
+ 	},
+ 	[ C(OP_PREFETCH) ] = {
+ 		[ C(RESULT_ACCESS) ] = 0x0,
+ 		[ C(RESULT_MISS)   ] = 0x0,
+ 	},
+  },
++>>>>>>> 0f1b5ca240c6 (perf/x86/intel: Add new cache events table for Haswell)
  };
  
  static __initconst const u64 hsw_hw_cache_extra_regs
@@@ -526,16 -565,38 +624,51 @@@
  {
   [ C(LL  ) ] = {
  	[ C(OP_READ) ] = {
++<<<<<<< HEAD
 +		/* OFFCORE_RESPONSE:ALL_DATA_RD|ALL_CODE_RD */
 +		[ C(RESULT_ACCESS) ] = 0x2d5,
 +		/* OFFCORE_RESPONSE:ALL_DATA_RD|ALL_CODE_RD|SUPPLIER_NONE|
 +                   L3_MISS|ANY_SNOOP */
 +		[ C(RESULT_MISS)   ] = 0x3fbc0202d5ull,
 +	},
 +	[ C(OP_WRITE) ] = {
 +		[ C(RESULT_ACCESS) ] = 0x122, 	/* OFFCORE_RESPONSE:ALL_RFO */
 +		/* OFFCORE_RESPONSE:ALL_RFO|SUPPLIER_NONE|L3_MISS|ANY_SNOOP */
 +		[ C(RESULT_MISS)   ] = 0x3fbc020122ull,
++=======
+ 		[ C(RESULT_ACCESS) ] = HSW_DEMAND_READ|
+ 				       HSW_LLC_ACCESS,
+ 		[ C(RESULT_MISS)   ] = HSW_DEMAND_READ|
+ 				       HSW_L3_MISS|HSW_ANY_SNOOP,
+ 	},
+ 	[ C(OP_WRITE) ] = {
+ 		[ C(RESULT_ACCESS) ] = HSW_DEMAND_WRITE|
+ 				       HSW_LLC_ACCESS,
+ 		[ C(RESULT_MISS)   ] = HSW_DEMAND_WRITE|
+ 				       HSW_L3_MISS|HSW_ANY_SNOOP,
+ 	},
+ 	[ C(OP_PREFETCH) ] = {
+ 		[ C(RESULT_ACCESS) ] = 0x0,
+ 		[ C(RESULT_MISS)   ] = 0x0,
+ 	},
+  },
+  [ C(NODE) ] = {
+ 	[ C(OP_READ) ] = {
+ 		[ C(RESULT_ACCESS) ] = HSW_DEMAND_READ|
+ 				       HSW_L3_MISS_LOCAL_DRAM|
+ 				       HSW_SNOOP_DRAM,
+ 		[ C(RESULT_MISS)   ] = HSW_DEMAND_READ|
+ 				       HSW_L3_MISS_REMOTE|
+ 				       HSW_SNOOP_DRAM,
+ 	},
+ 	[ C(OP_WRITE) ] = {
+ 		[ C(RESULT_ACCESS) ] = HSW_DEMAND_WRITE|
+ 				       HSW_L3_MISS_LOCAL_DRAM|
+ 				       HSW_SNOOP_DRAM,
+ 		[ C(RESULT_MISS)   ] = HSW_DEMAND_WRITE|
+ 				       HSW_L3_MISS_REMOTE|
+ 				       HSW_SNOOP_DRAM,
++>>>>>>> 0f1b5ca240c6 (perf/x86/intel: Add new cache events table for Haswell)
  	},
  	[ C(OP_PREFETCH) ] = {
  		[ C(RESULT_ACCESS) ] = 0x0,
* Unmerged path arch/x86/kernel/cpu/perf_event_intel.c
