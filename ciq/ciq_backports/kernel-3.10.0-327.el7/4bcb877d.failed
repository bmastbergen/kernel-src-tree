udp: Offload outer UDP tunnel csum if available

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Tom Herbert <therbert@google.com>
commit 4bcb877d257c87298aedead1ffeaba0d5df1991d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/4bcb877d.failed

In __skb_udp_tunnel_segment if outer UDP checksums are enabled and
ip_summed is not already CHECKSUM_PARTIAL, set up checksum offload
if device features allow it.

	Signed-off-by: Tom Herbert <therbert@google.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 4bcb877d257c87298aedead1ffeaba0d5df1991d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/ipv4/udp_offload.c
diff --cc net/ipv4/udp_offload.c
index 7729d35bcf82,a774711a88b9..000000000000
--- a/net/ipv4/udp_offload.c
+++ b/net/ipv4/udp_offload.c
@@@ -25,9 -25,141 +25,147 @@@ struct udp_offload_priv 
  	struct udp_offload_priv __rcu *next;
  };
  
++<<<<<<< HEAD
 +static int udp4_ufo_send_check(struct sk_buff *skb)
 +{
 +	return 0;
++=======
+ static struct sk_buff *__skb_udp_tunnel_segment(struct sk_buff *skb,
+ 	netdev_features_t features,
+ 	struct sk_buff *(*gso_inner_segment)(struct sk_buff *skb,
+ 					     netdev_features_t features),
+ 	__be16 new_protocol, bool is_ipv6)
+ {
+ 	struct sk_buff *segs = ERR_PTR(-EINVAL);
+ 	u16 mac_offset = skb->mac_header;
+ 	int mac_len = skb->mac_len;
+ 	int tnl_hlen = skb_inner_mac_header(skb) - skb_transport_header(skb);
+ 	__be16 protocol = skb->protocol;
+ 	netdev_features_t enc_features;
+ 	int udp_offset, outer_hlen;
+ 	unsigned int oldlen;
+ 	bool need_csum = !!(skb_shinfo(skb)->gso_type &
+ 			    SKB_GSO_UDP_TUNNEL_CSUM);
+ 	bool offload_csum = false, dont_encap = need_csum;
+ 
+ 	oldlen = (u16)~skb->len;
+ 
+ 	if (unlikely(!pskb_may_pull(skb, tnl_hlen)))
+ 		goto out;
+ 
+ 	skb->encapsulation = 0;
+ 	__skb_pull(skb, tnl_hlen);
+ 	skb_reset_mac_header(skb);
+ 	skb_set_network_header(skb, skb_inner_network_offset(skb));
+ 	skb->mac_len = skb_inner_network_offset(skb);
+ 	skb->protocol = new_protocol;
+ 	skb->encap_hdr_csum = need_csum;
+ 
+ 	/* Try to offload checksum if possible */
+ 	offload_csum = !!(need_csum &&
+ 			  (skb->dev->features &
+ 			   (is_ipv6 ? NETIF_F_V6_CSUM : NETIF_F_V4_CSUM)));
+ 
+ 	/* segment inner packet. */
+ 	enc_features = skb->dev->hw_enc_features & features;
+ 	segs = gso_inner_segment(skb, enc_features);
+ 	if (IS_ERR_OR_NULL(segs)) {
+ 		skb_gso_error_unwind(skb, protocol, tnl_hlen, mac_offset,
+ 				     mac_len);
+ 		goto out;
+ 	}
+ 
+ 	outer_hlen = skb_tnl_header_len(skb);
+ 	udp_offset = outer_hlen - tnl_hlen;
+ 	skb = segs;
+ 	do {
+ 		struct udphdr *uh;
+ 		int len;
+ 		__be32 delta;
+ 
+ 		if (dont_encap) {
+ 			skb->encapsulation = 0;
+ 			skb->ip_summed = CHECKSUM_NONE;
+ 		} else {
+ 			/* Only set up inner headers if we might be offloading
+ 			 * inner checksum.
+ 			 */
+ 			skb_reset_inner_headers(skb);
+ 			skb->encapsulation = 1;
+ 		}
+ 
+ 		skb->mac_len = mac_len;
+ 		skb->protocol = protocol;
+ 
+ 		skb_push(skb, outer_hlen);
+ 		skb_reset_mac_header(skb);
+ 		skb_set_network_header(skb, mac_len);
+ 		skb_set_transport_header(skb, udp_offset);
+ 		len = skb->len - udp_offset;
+ 		uh = udp_hdr(skb);
+ 		uh->len = htons(len);
+ 
+ 		if (!need_csum)
+ 			continue;
+ 
+ 		delta = htonl(oldlen + len);
+ 
+ 		uh->check = ~csum_fold((__force __wsum)
+ 				       ((__force u32)uh->check +
+ 					(__force u32)delta));
+ 
+ 		if (offload_csum) {
+ 			skb->ip_summed = CHECKSUM_PARTIAL;
+ 			skb->csum_start = skb_transport_header(skb) - skb->head;
+ 			skb->csum_offset = offsetof(struct udphdr, check);
+ 		} else {
+ 			uh->check = gso_make_checksum(skb, ~uh->check);
+ 
+ 			if (uh->check == 0)
+ 				uh->check = CSUM_MANGLED_0;
+ 		}
+ 	} while ((skb = skb->next));
+ out:
+ 	return segs;
+ }
+ 
+ struct sk_buff *skb_udp_tunnel_segment(struct sk_buff *skb,
+ 				       netdev_features_t features,
+ 				       bool is_ipv6)
+ {
+ 	__be16 protocol = skb->protocol;
+ 	const struct net_offload **offloads;
+ 	const struct net_offload *ops;
+ 	struct sk_buff *segs = ERR_PTR(-EINVAL);
+ 	struct sk_buff *(*gso_inner_segment)(struct sk_buff *skb,
+ 					     netdev_features_t features);
+ 
+ 	rcu_read_lock();
+ 
+ 	switch (skb->inner_protocol_type) {
+ 	case ENCAP_TYPE_ETHER:
+ 		protocol = skb->inner_protocol;
+ 		gso_inner_segment = skb_mac_gso_segment;
+ 		break;
+ 	case ENCAP_TYPE_IPPROTO:
+ 		offloads = is_ipv6 ? inet6_offloads : inet_offloads;
+ 		ops = rcu_dereference(offloads[skb->inner_ipproto]);
+ 		if (!ops || !ops->callbacks.gso_segment)
+ 			goto out_unlock;
+ 		gso_inner_segment = ops->callbacks.gso_segment;
+ 		break;
+ 	default:
+ 		goto out_unlock;
+ 	}
+ 
+ 	segs = __skb_udp_tunnel_segment(skb, features, gso_inner_segment,
+ 					protocol, is_ipv6);
+ 
+ out_unlock:
+ 	rcu_read_unlock();
+ 
+ 	return segs;
++>>>>>>> 4bcb877d257c (udp: Offload outer UDP tunnel csum if available)
  }
  
  static struct sk_buff *udp4_ufo_fragment(struct sk_buff *skb,
* Unmerged path net/ipv4/udp_offload.c
