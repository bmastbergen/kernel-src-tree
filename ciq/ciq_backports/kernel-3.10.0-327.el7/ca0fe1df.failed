pnfs/blocklayout: refactor extent processing

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Christoph Hellwig <hch@lst.de>
commit ca0fe1dfa5acac6ec4ef5820d2eb5460b02648d5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/ca0fe1df.failed

Factor out a helper for all per-extent work, and merge the now trivial
functions for lseg allocation and parsing.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Trond Myklebust <trond.myklebust@primarydata.com>
(cherry picked from commit ca0fe1dfa5acac6ec4ef5820d2eb5460b02648d5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/nfs/blocklayout/blocklayout.c
diff --cc fs/nfs/blocklayout/blocklayout.c
index 5b7b41d3b0f9,76ec017a6f0a..000000000000
--- a/fs/nfs/blocklayout/blocklayout.c
+++ b/fs/nfs/blocklayout/blocklayout.c
@@@ -994,25 -446,214 +994,232 @@@ static void bl_free_lseg(struct pnfs_la
  	kfree(lseg);
  }
  
++<<<<<<< HEAD
 +/* We pretty much ignore lseg, and store all data layout wide, so we
 + * can correctly merge.
 + */
 +static struct pnfs_layout_segment *bl_alloc_lseg(struct pnfs_layout_hdr *lo,
 +						 struct nfs4_layoutget_res *lgr,
 +						 gfp_t gfp_flags)
 +{
 +	struct pnfs_layout_segment *lseg;
 +	int status;
 +
 +	dprintk("%s enter\n", __func__);
 +	lseg = kzalloc(sizeof(*lseg), gfp_flags);
 +	if (!lseg)
 +		return ERR_PTR(-ENOMEM);
 +	status = nfs4_blk_process_layoutget(lo, lgr, gfp_flags);
- 	if (status) {
- 		/* We don't want to call the full-blown bl_free_lseg,
- 		 * since on error extents were not touched.
++=======
+ /* Tracks info needed to ensure extents in layout obey constraints of spec */
+ struct layout_verification {
+ 	u32 mode;	/* R or RW */
+ 	u64 start;	/* Expected start of next non-COW extent */
+ 	u64 inval;	/* Start of INVAL coverage */
+ 	u64 cowread;	/* End of COW read coverage */
+ };
+ 
+ /* Verify the extent meets the layout requirements of the pnfs-block draft,
+  * section 2.3.1.
+  */
+ static int verify_extent(struct pnfs_block_extent *be,
+ 			 struct layout_verification *lv)
+ {
+ 	if (lv->mode == IOMODE_READ) {
+ 		if (be->be_state == PNFS_BLOCK_READWRITE_DATA ||
+ 		    be->be_state == PNFS_BLOCK_INVALID_DATA)
+ 			return -EIO;
+ 		if (be->be_f_offset != lv->start)
+ 			return -EIO;
+ 		lv->start += be->be_length;
+ 		return 0;
+ 	}
+ 	/* lv->mode == IOMODE_RW */
+ 	if (be->be_state == PNFS_BLOCK_READWRITE_DATA) {
+ 		if (be->be_f_offset != lv->start)
+ 			return -EIO;
+ 		if (lv->cowread > lv->start)
+ 			return -EIO;
+ 		lv->start += be->be_length;
+ 		lv->inval = lv->start;
+ 		return 0;
+ 	} else if (be->be_state == PNFS_BLOCK_INVALID_DATA) {
+ 		if (be->be_f_offset != lv->start)
+ 			return -EIO;
+ 		lv->start += be->be_length;
+ 		return 0;
+ 	} else if (be->be_state == PNFS_BLOCK_READ_DATA) {
+ 		if (be->be_f_offset > lv->start)
+ 			return -EIO;
+ 		if (be->be_f_offset < lv->inval)
+ 			return -EIO;
+ 		if (be->be_f_offset < lv->cowread)
+ 			return -EIO;
+ 		/* It looks like you might want to min this with lv->start,
+ 		 * but you really don't.
  		 */
+ 		lv->inval = lv->inval + be->be_length;
+ 		lv->cowread = be->be_f_offset + be->be_length;
+ 		return 0;
+ 	} else
+ 		return -EIO;
+ }
+ 
+ static int decode_sector_number(__be32 **rp, sector_t *sp)
+ {
+ 	uint64_t s;
+ 
+ 	*rp = xdr_decode_hyper(*rp, &s);
+ 	if (s & 0x1ff) {
+ 		printk(KERN_WARNING "NFS: %s: sector not aligned\n", __func__);
+ 		return -1;
+ 	}
+ 	*sp = s >> SECTOR_SHIFT;
+ 	return 0;
+ }
+ 
+ static int
+ bl_alloc_extent(struct xdr_stream *xdr, struct pnfs_layout_hdr *lo,
+ 		struct layout_verification *lv, struct list_head *extents,
+ 		gfp_t gfp_mask)
+ {
+ 	struct pnfs_block_extent *be;
+ 	struct nfs4_deviceid id;
+ 	int error;
+ 	__be32 *p;
+ 
+ 	p = xdr_inline_decode(xdr, 28 + NFS4_DEVICEID4_SIZE);
+ 	if (!p)
+ 		return -EIO;
+ 
+ 	be = kzalloc(sizeof(*be), GFP_NOFS);
+ 	if (!be)
+ 		return -ENOMEM;
+ 
+ 	memcpy(&id, p, NFS4_DEVICEID4_SIZE);
+ 	p += XDR_QUADLEN(NFS4_DEVICEID4_SIZE);
+ 
+ 	error = -EIO;
+ 	be->be_device = nfs4_find_get_deviceid(NFS_SERVER(lo->plh_inode), &id,
+ 						lo->plh_lc_cred, gfp_mask);
+ 	if (!be->be_device)
+ 		goto out_free_be;
+ 
+ 	/*
+ 	 * The next three values are read in as bytes, but stored in the
+ 	 * extent structure in 512-byte granularity.
+ 	 */
+ 	if (decode_sector_number(&p, &be->be_f_offset) < 0)
+ 		goto out_put_deviceid;
+ 	if (decode_sector_number(&p, &be->be_length) < 0)
+ 		goto out_put_deviceid;
+ 	if (decode_sector_number(&p, &be->be_v_offset) < 0)
+ 		goto out_put_deviceid;
+ 	be->be_state = be32_to_cpup(p++);
+ 
+ 	error = verify_extent(be, lv);
+ 	if (error) {
+ 		dprintk("%s: extent verification failed\n", __func__);
+ 		goto out_put_deviceid;
+ 	}
+ 
+ 	list_add_tail(&be->be_list, extents);
+ 	return 0;
+ 
+ out_put_deviceid:
+ 	nfs4_put_deviceid_node(be->be_device);
+ out_free_be:
+ 	kfree(be);
+ 	return error;
+ }
+ 
+ static struct pnfs_layout_segment *
+ bl_alloc_lseg(struct pnfs_layout_hdr *lo, struct nfs4_layoutget_res *lgr,
+ 		gfp_t gfp_mask)
+ {
+ 	struct layout_verification lv = {
+ 		.mode = lgr->range.iomode,
+ 		.start = lgr->range.offset >> SECTOR_SHIFT,
+ 		.inval = lgr->range.offset >> SECTOR_SHIFT,
+ 		.cowread = lgr->range.offset >> SECTOR_SHIFT,
+ 	};
+ 	struct pnfs_block_layout *bl = BLK_LO2EXT(lo);
+ 	struct pnfs_layout_segment *lseg;
+ 	struct xdr_buf buf;
+ 	struct xdr_stream xdr;
+ 	struct page *scratch;
+ 	int status, i;
+ 	uint32_t count;
+ 	__be32 *p;
+ 	LIST_HEAD(extents);
+ 
+ 	dprintk("---> %s\n", __func__);
+ 
+ 	lseg = kzalloc(sizeof(*lseg), gfp_mask);
+ 	if (!lseg)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	status = -ENOMEM;
+ 	scratch = alloc_page(gfp_mask);
+ 	if (!scratch)
+ 		goto out;
+ 
+ 	xdr_init_decode_pages(&xdr, &buf,
+ 			lgr->layoutp->pages, lgr->layoutp->len);
+ 	xdr_set_scratch_buffer(&xdr, page_address(scratch), PAGE_SIZE);
+ 
+ 	status = -EIO;
+ 	p = xdr_inline_decode(&xdr, 4);
+ 	if (unlikely(!p))
+ 		goto out_free_scratch;
+ 
+ 	count = be32_to_cpup(p++);
+ 	dprintk("%s: number of extents %d\n", __func__, count);
+ 
+ 	/*
+ 	 * Decode individual extents, putting them in temporary staging area
+ 	 * until whole layout is decoded to make error recovery easier.
+ 	 */
+ 	for (i = 0; i < count; i++) {
+ 		status = bl_alloc_extent(&xdr, lo, &lv, &extents, gfp_mask);
+ 		if (status)
+ 			goto process_extents;
+ 	}
+ 
+ 	if (lgr->range.offset + lgr->range.length !=
+ 			lv.start << SECTOR_SHIFT) {
+ 		dprintk("%s Final length mismatch\n", __func__);
+ 		status = -EIO;
+ 		goto process_extents;
+ 	}
+ 
+ 	if (lv.start < lv.cowread) {
+ 		dprintk("%s Final uncovered COW extent\n", __func__);
+ 		status = -EIO;
+ 	}
+ 
+ process_extents:
+ 	while (!list_empty(&extents)) {
+ 		struct pnfs_block_extent *be =
+ 			list_first_entry(&extents, struct pnfs_block_extent,
+ 					 be_list);
+ 		list_del(&be->be_list);
+ 
+ 		if (!status)
+ 			status = ext_tree_insert(bl, be);
+ 
+ 		if (status) {
+ 			nfs4_put_deviceid_node(be->be_device);
+ 			kfree(be);
+ 		}
+ 	}
+ 
+ out_free_scratch:
+ 	__free_page(scratch);
+ out:
+ 	dprintk("%s returns %d\n", __func__, status);
++>>>>>>> ca0fe1dfa5ac (pnfs/blocklayout: refactor extent processing)
+ 	if (status) {
  		kfree(lseg);
  		return ERR_PTR(status);
  	}
* Unmerged path fs/nfs/blocklayout/blocklayout.c
