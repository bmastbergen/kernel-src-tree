IB/iser: Re-adjust CQ and QP send ring sizes to HW limits

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [infiniband] iser: Re-adjust CQ and QP send ring sizes to HW limits (Amir Vadai) [1164539]
Rebuild_FUZZ: 97.30%
commit-author Minh Tran <minhduc.tran@emulex.com>
commit f4641ef701d41929e0674f114e47a6824761e5b1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/f4641ef7.failed

Re-adjust max CQEs per CQ and max send_wr per QP according
to the resource limits supported by underlying hardware.

	Signed-off-by: Minh Tran <minhduc.tran@emulex.com>
	Signed-off-by: Jayamohan Kallickal <jayamohan.kallickal@emulex.com>
	Acked-by: Sagi Grimberg <sagig@mellanox.com>
	Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
	Signed-off-by: Roland Dreier <roland@purestorage.com>
(cherry picked from commit f4641ef701d41929e0674f114e47a6824761e5b1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/ulp/iser/iscsi_iser.c
#	drivers/infiniband/ulp/iser/iscsi_iser.h
#	drivers/infiniband/ulp/iser/iser_verbs.c
diff --cc drivers/infiniband/ulp/iser/iscsi_iser.c
index 9e53334ea7c7,46028151a904..000000000000
--- a/drivers/infiniband/ulp/iser/iscsi_iser.c
+++ b/drivers/infiniband/ulp/iser/iscsi_iser.c
@@@ -554,7 -567,9 +554,13 @@@ iscsi_iser_session_create(struct iscsi_
  	struct iscsi_cls_session *cls_session;
  	struct iscsi_session *session;
  	struct Scsi_Host *shost;
++<<<<<<< HEAD
 +	struct iser_conn *ib_conn = NULL;
++=======
+ 	struct iser_conn *iser_conn = NULL;
+ 	struct ib_conn *ib_conn;
+ 	u16 max_cmds;
++>>>>>>> f4641ef701d4 (IB/iser: Re-adjust CQ and QP send ring sizes to HW limits)
  
  	shost = iscsi_host_alloc(&iscsi_iser_sht, 0, 0);
  	if (!shost)
@@@ -571,7 -586,9 +577,13 @@@
  	 * the leading conn's ep so this will be NULL;
  	 */
  	if (ep) {
++<<<<<<< HEAD
 +		ib_conn = ep->dd_data;
++=======
+ 		iser_conn = ep->dd_data;
+ 		max_cmds = iser_conn->max_cmds;
+ 		ib_conn = &iser_conn->ib_conn;
++>>>>>>> f4641ef701d4 (IB/iser: Re-adjust CQ and QP send ring sizes to HW limits)
  		if (ib_conn->pi_support) {
  			u32 sig_caps = ib_conn->device->dev_attr.sig_prot_cap;
  
@@@ -581,16 -598,18 +593,18 @@@
  			else
  				scsi_host_set_guard(shost, SHOST_DIX_GUARD_CRC);
  		}
+ 	} else {
+ 		max_cmds = ISER_DEF_XMIT_CMDS_MAX;
  	}
  
 -	if (iscsi_host_add(shost, ep ?
 -			   ib_conn->device->ib_device->dma_device : NULL))
 +	if (iscsi_host_add(shost,
 +			   ep ? ib_conn->device->ib_device->dma_device : NULL))
  		goto free_host;
  
- 	if (cmds_max > ISER_DEF_XMIT_CMDS_MAX) {
+ 	if (cmds_max > max_cmds) {
  		iser_info("cmds_max changed from %u to %u\n",
- 			  cmds_max, ISER_DEF_XMIT_CMDS_MAX);
- 		cmds_max = ISER_DEF_XMIT_CMDS_MAX;
+ 			  cmds_max, max_cmds);
+ 		cmds_max = max_cmds;
  	}
  
  	cls_session = iscsi_session_setup(&iscsi_iser_transport, shost,
diff --cc drivers/infiniband/ulp/iser/iscsi_iser.h
index 50ec84465483,44d64b74c365..000000000000
--- a/drivers/infiniband/ulp/iser/iscsi_iser.h
+++ b/drivers/infiniband/ulp/iser/iscsi_iser.h
@@@ -145,6 -144,14 +145,17 @@@
  					ISER_MAX_TX_MISC_PDUS         + \
  					ISER_MAX_RX_MISC_PDUS)
  
++<<<<<<< HEAD
++=======
+ #define ISER_GET_MAX_XMIT_CMDS(send_wr) ((send_wr			\
+ 					 - ISER_MAX_TX_MISC_PDUS	\
+ 					 - ISER_MAX_RX_MISC_PDUS) /	\
+ 					 (1 + ISER_INFLIGHT_DATAOUTS))
+ 
+ #define ISER_WC_BATCH_COUNT   16
+ #define ISER_SIGNAL_CMD_COUNT 32
+ 
++>>>>>>> f4641ef701d4 (IB/iser: Re-adjust CQ and QP send ring sizes to HW limits)
  #define ISER_VER			0x10
  #define ISER_WSV			0x08
  #define ISER_RSV			0x04
@@@ -317,27 -431,96 +328,112 @@@ struct fast_reg_descriptor 
  	u8				  reg_indicators;
  };
  
++<<<<<<< HEAD
++=======
+ /**
+  * struct ib_conn - Infiniband related objects
+  *
+  * @cma_id:              rdma_cm connection maneger handle
+  * @qp:                  Connection Queue-pair
+  * @post_recv_buf_count: post receive counter
+  * @rx_wr:               receive work request for batch posts
+  * @device:              reference to iser device
+  * @comp:                iser completion context
+  * @pi_support:          Indicate device T10-PI support
+  * @beacon:              beacon send wr to signal all flush errors were drained
+  * @flush_comp:          completes when all connection completions consumed
+  * @lock:                protects fmr/fastreg pool
+  * @union.fmr:
+  *     @pool:            FMR pool for fast registrations
+  *     @page_vec:        page vector to hold mapped commands pages
+  *                       used for registration
+  * @union.fastreg:
+  *     @pool:            Fast registration descriptors pool for fast
+  *                       registrations
+  *     @pool_size:       Size of pool
+  */
+ struct ib_conn {
+ 	struct rdma_cm_id           *cma_id;
+ 	struct ib_qp	            *qp;
+ 	int                          post_recv_buf_count;
+ 	struct ib_recv_wr	     rx_wr[ISER_MIN_POSTED_RX];
+ 	struct iser_device          *device;
+ 	struct iser_comp	    *comp;
+ 	bool			     pi_support;
+ 	struct ib_send_wr	     beacon;
+ 	struct completion	     flush_comp;
+ 	spinlock_t		     lock;
+ 	union {
+ 		struct {
+ 			struct ib_fmr_pool      *pool;
+ 			struct iser_page_vec	*page_vec;
+ 		} fmr;
+ 		struct {
+ 			struct list_head	 pool;
+ 			int			 pool_size;
+ 		} fastreg;
+ 	};
+ };
+ 
+ /**
+  * struct iser_conn - iSER connection context
+  *
+  * @ib_conn:          connection RDMA resources
+  * @iscsi_conn:       link to matching iscsi connection
+  * @ep:               transport handle
+  * @state:            connection logical state
+  * @qp_max_recv_dtos: maximum number of data outs, corresponds
+  *                    to max number of post recvs
+  * @qp_max_recv_dtos_mask: (qp_max_recv_dtos - 1)
+  * @min_posted_rx:    (qp_max_recv_dtos >> 2)
+  * @max_cmds:         maximum cmds allowed for this connection
+  * @name:             connection peer portal
+  * @release_work:     deffered work for release job
+  * @state_mutex:      protects iser onnection state
+  * @stop_completion:  conn_stop completion
+  * @ib_completion:    RDMA cleanup completion
+  * @up_completion:    connection establishment completed
+  *                    (state is ISER_CONN_UP)
+  * @conn_list:        entry in ig conn list
+  * @login_buf:        login data buffer (stores login parameters)
+  * @login_req_buf:    login request buffer
+  * @login_req_dma:    login request buffer dma address
+  * @login_resp_buf:   login response buffer
+  * @login_resp_dma:   login response buffer dma address
+  * @rx_desc_head:     head of rx_descs cyclic buffer
+  * @rx_descs:         rx buffers array (cyclic buffer)
+  * @num_rx_descs:     number of rx descriptors
+  */
++>>>>>>> f4641ef701d4 (IB/iser: Re-adjust CQ and QP send ring sizes to HW limits)
  struct iser_conn {
 -	struct ib_conn		     ib_conn;
  	struct iscsi_conn	     *iscsi_conn;
  	struct iscsi_endpoint	     *ep;
++<<<<<<< HEAD
 +	enum iser_ib_conn_state	     state;	    /* rdma connection state   */
 +	atomic_t		     refcount;
 +	spinlock_t		     lock;	    /* used for state changes  */
 +	struct iser_device           *device;       /* device context          */
 +	struct rdma_cm_id            *cma_id;       /* CMA ID		       */
 +	struct ib_qp	             *qp;           /* QP 		       */
 +	unsigned		     qp_max_recv_dtos; /* num of rx buffers */
 +	unsigned		     qp_max_recv_dtos_mask; /* above minus 1 */
 +	unsigned		     min_posted_rx; /* qp_max_recv_dtos >> 2 */
 +	int                          post_recv_buf_count; /* posted rx count  */
 +	atomic_t                     post_send_buf_count; /* posted tx count   */
++=======
+ 	enum iser_conn_state	     state;
+ 	unsigned		     qp_max_recv_dtos;
+ 	unsigned		     qp_max_recv_dtos_mask;
+ 	unsigned		     min_posted_rx;
+ 	u16                          max_cmds;
++>>>>>>> f4641ef701d4 (IB/iser: Re-adjust CQ and QP send ring sizes to HW limits)
  	char 			     name[ISER_OBJECT_NAME_SIZE];
  	struct work_struct	     release_work;
 -	struct mutex		     state_mutex;
  	struct completion	     stop_completion;
 -	struct completion	     ib_completion;
 +	struct mutex		     state_mutex;
 +	struct completion	     flush_completion;
  	struct completion	     up_completion;
 -	struct list_head	     conn_list;
 +	struct list_head	     conn_list;       /* entry in ig conn list */
  
  	char  			     *login_buf;
  	char			     *login_req_buf, *login_resp_buf;
diff --cc drivers/infiniband/ulp/iser/iser_verbs.c
index fbf2a1e0f2e2,08e51e79a054..000000000000
--- a/drivers/infiniband/ulp/iser/iser_verbs.c
+++ b/drivers/infiniband/ulp/iser/iser_verbs.c
@@@ -101,44 -104,30 +101,66 @@@ static int iser_create_device_ib_res(st
  		return -1;
  	}
  
++<<<<<<< HEAD
 +	device->cqs_used = min(ISER_MAX_CQ, device->ib_device->num_comp_vectors);
 +	iser_info("using %d CQs, device %s supports %d vectors\n",
 +		  device->cqs_used, device->ib_device->name,
 +		  device->ib_device->num_comp_vectors);
++=======
+ 	device->comps_used = min(ISER_MAX_CQ,
+ 				 device->ib_device->num_comp_vectors);
+ 
+ 	max_cqe = min(ISER_MAX_CQ_LEN, dev_attr->max_cqe);
+ 
+ 	iser_info("using %d CQs, device %s supports %d vectors max_cqe %d\n",
+ 		  device->comps_used, device->ib_device->name,
+ 		  device->ib_device->num_comp_vectors, max_cqe);
++>>>>>>> f4641ef701d4 (IB/iser: Re-adjust CQ and QP send ring sizes to HW limits)
 +
 +	device->cq_desc = kmalloc(sizeof(struct iser_cq_desc) * device->cqs_used,
 +				  GFP_KERNEL);
 +	if (device->cq_desc == NULL)
 +		goto cq_desc_err;
 +	cq_desc = device->cq_desc;
  
  	device->pd = ib_alloc_pd(device->ib_device);
  	if (IS_ERR(device->pd))
  		goto pd_err;
  
 -	for (i = 0; i < device->comps_used; i++) {
 -		struct iser_comp *comp = &device->comps[i];
 -
 +	for (i = 0; i < device->cqs_used; i++) {
 +		cq_desc[i].device   = device;
 +		cq_desc[i].cq_index = i;
 +
++<<<<<<< HEAD
 +		max_cqe = min(ISER_MAX_RX_CQ_LEN, dev_attr->max_cqe);
 +		device->rx_cq[i] = ib_create_cq(device->ib_device,
 +					  iser_cq_callback,
 +					  iser_cq_event_callback,
 +					  (void *)&cq_desc[i],
 +					  max_cqe, i);
 +		if (IS_ERR(device->rx_cq[i])) {
 +			device->rx_cq[i] = NULL;
++=======
+ 		comp->device = device;
+ 		comp->cq = ib_create_cq(device->ib_device,
+ 					iser_cq_callback,
+ 					iser_cq_event_callback,
+ 					(void *)comp,
+ 					max_cqe, i);
+ 		if (IS_ERR(comp->cq)) {
+ 			comp->cq = NULL;
++>>>>>>> f4641ef701d4 (IB/iser: Re-adjust CQ and QP send ring sizes to HW limits)
 +			goto cq_err;
 +		}
 +
 +		max_cqe = min(ISER_MAX_TX_CQ_LEN, dev_attr->max_cqe);
 +		device->tx_cq[i] = ib_create_cq(device->ib_device,
 +					  NULL, iser_cq_event_callback,
 +					  (void *)&cq_desc[i],
 +					  max_cqe, i);
 +
 +		if (IS_ERR(device->tx_cq[i])) {
 +			device->tx_cq[i] = NULL;
  			goto cq_err;
  		}
  
@@@ -442,10 -426,12 +464,16 @@@ void iser_free_fastreg_pool(struct iser
   *
   * returns 0 on success, -1 on failure
   */
 -static int iser_create_ib_conn_res(struct ib_conn *ib_conn)
 +static int iser_create_ib_conn_res(struct iser_conn *ib_conn)
  {
+ 	struct iser_conn *iser_conn = container_of(ib_conn, struct iser_conn,
+ 						   ib_conn);
  	struct iser_device	*device;
++<<<<<<< HEAD
 +	struct ib_device_attr	*dev_attr;
++=======
+ 	struct ib_device_attr *dev_attr;
++>>>>>>> f4641ef701d4 (IB/iser: Re-adjust CQ and QP send ring sizes to HW limits)
  	struct ib_qp_init_attr	init_attr;
  	int			ret = -ENOMEM;
  	int index, min_index = 0;
@@@ -477,12 -465,22 +505,28 @@@
  	init_attr.sq_sig_type	= IB_SIGNAL_REQ_WR;
  	init_attr.qp_type	= IB_QPT_RC;
  	if (ib_conn->pi_support) {
 -		init_attr.cap.max_send_wr = ISER_QP_SIG_MAX_REQ_DTOS + 1;
 +		init_attr.cap.max_send_wr = min(ISER_QP_SIG_MAX_REQ_DTOS,
 +							dev_attr->max_qp_wr);
  		init_attr.create_flags |= IB_QP_CREATE_SIGNATURE_EN;
+ 		iser_conn->max_cmds =
+ 			ISER_GET_MAX_XMIT_CMDS(ISER_QP_SIG_MAX_REQ_DTOS);
  	} else {
++<<<<<<< HEAD
 +		init_attr.cap.max_send_wr  = min(ISER_QP_MAX_REQ_DTOS,
 +							dev_attr->max_qp_wr);
++=======
+ 		if (dev_attr->max_qp_wr > ISER_QP_MAX_REQ_DTOS) {
+ 			init_attr.cap.max_send_wr  = ISER_QP_MAX_REQ_DTOS + 1;
+ 			iser_conn->max_cmds =
+ 				ISER_GET_MAX_XMIT_CMDS(ISER_QP_MAX_REQ_DTOS);
+ 		} else {
+ 			init_attr.cap.max_send_wr = dev_attr->max_qp_wr;
+ 			iser_conn->max_cmds =
+ 				ISER_GET_MAX_XMIT_CMDS(dev_attr->max_qp_wr);
+ 			iser_dbg("device %s supports max_send_wr %d\n",
+ 				 device->ib_device->name, dev_attr->max_qp_wr);
+ 		}
++>>>>>>> f4641ef701d4 (IB/iser: Re-adjust CQ and QP send ring sizes to HW limits)
  	}
  
  	ret = rdma_create_qp(ib_conn->cma_id, device->pd, &init_attr);
* Unmerged path drivers/infiniband/ulp/iser/iscsi_iser.c
* Unmerged path drivers/infiniband/ulp/iser/iscsi_iser.h
* Unmerged path drivers/infiniband/ulp/iser/iser_verbs.c
