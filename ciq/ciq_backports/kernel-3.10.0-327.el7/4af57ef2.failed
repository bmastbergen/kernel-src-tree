perf: Add pmu specific data for perf task context

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [perf] Add pmu specific data for perf task context (Jiri Olsa) [1222189]
Rebuild_FUZZ: 93.48%
commit-author Yan, Zheng <zheng.z.yan@intel.com>
commit 4af57ef28c2c1047fda9e1a5be02aa7a6a69cf9e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/4af57ef2.failed

Introduce a new flag PERF_ATTACH_TASK_DATA for perf event's attach
stata. The flag is set by PMU's event_init() callback, it indicates
that perf event needs PMU specific data.

The PMU specific data are initialized to zeros. Later patches will
use PMU specific data to save LBR stack.

	Signed-off-by: Yan, Zheng <zheng.z.yan@intel.com>
	Signed-off-by: Kan Liang <kan.liang@intel.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Paul Mackerras <paulus@samba.org>
	Cc: eranian@google.com
	Cc: jolsa@redhat.com
Link: http://lkml.kernel.org/r/1415156173-10035-6-git-send-email-kan.liang@intel.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 4af57ef28c2c1047fda9e1a5be02aa7a6a69cf9e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/perf_event.h
diff --cc include/linux/perf_event.h
index 4d40d5541619,270cd0173e61..000000000000
--- a/include/linux/perf_event.h
+++ b/include/linux/perf_event.h
@@@ -284,12 -266,16 +284,24 @@@ struct pmu 
  	 */
  	void (*flush_branch_stack)	(void);
  
++<<<<<<< HEAD
 +	RH_KABI_EXTEND(struct module *module)
++=======
+ 	/*
+ 	 * context-switches callback
+ 	 */
+ 	void (*sched_task)		(struct perf_event_context *ctx,
+ 					bool sched_in);
+ 	/*
+ 	 * PMU specific data size
+ 	 */
+ 	size_t				task_ctx_size;
++>>>>>>> 4af57ef28c2c (perf: Add pmu specific data for perf task context)
  
 +	/*
 +	 * various common per-pmu feature flags
 +	 */
 +	RH_KABI_EXTEND(int	capabilities)
  };
  
  /**
@@@ -523,7 -516,7 +536,11 @@@ struct perf_event_context 
  	u64				generation;
  	int				pin_count;
  	int				nr_cgroups;	 /* cgroup evts */
++<<<<<<< HEAD
 +	int				nr_branch_stack; /* branch_stack evt */
++=======
+ 	void				*task_ctx_data; /* pmu specific data */
++>>>>>>> 4af57ef28c2c (perf: Add pmu specific data for perf task context)
  	struct rcu_head			rcu_head;
  
  	struct delayed_work		orphans_remove;
* Unmerged path include/linux/perf_event.h
diff --git a/kernel/events/core.c b/kernel/events/core.c
index ec07afe9af6e..ead0673a6a58 100644
--- a/kernel/events/core.c
+++ b/kernel/events/core.c
@@ -911,6 +911,15 @@ static void get_ctx(struct perf_event_context *ctx)
 	WARN_ON(!atomic_inc_not_zero(&ctx->refcount));
 }
 
+static void free_ctx(struct rcu_head *head)
+{
+	struct perf_event_context *ctx;
+
+	ctx = container_of(head, struct perf_event_context, rcu_head);
+	kfree(ctx->task_ctx_data);
+	kfree(ctx);
+}
+
 static void put_ctx(struct perf_event_context *ctx)
 {
 	if (atomic_dec_and_test(&ctx->refcount)) {
@@ -918,7 +927,7 @@ static void put_ctx(struct perf_event_context *ctx)
 			put_ctx(ctx->parent_ctx);
 		if (ctx->task)
 			put_task_struct(ctx->task);
-		kfree_rcu(ctx, rcu_head);
+		call_rcu(&ctx->rcu_head, free_ctx);
 	}
 }
 
@@ -3348,12 +3357,15 @@ errout:
  * Returns a matching context with refcount and pincount.
  */
 static struct perf_event_context *
-find_get_context(struct pmu *pmu, struct task_struct *task, int cpu)
+find_get_context(struct pmu *pmu, struct task_struct *task,
+		struct perf_event *event)
 {
 	struct perf_event_context *ctx, *clone_ctx = NULL;
 	struct perf_cpu_context *cpuctx;
+	void *task_ctx_data = NULL;
 	unsigned long flags;
 	int ctxn, err;
+	int cpu = event->cpu;
 
 	if (!task) {
 		/* Must be root to operate on a CPU event: */
@@ -3381,11 +3393,24 @@ find_get_context(struct pmu *pmu, struct task_struct *task, int cpu)
 	if (ctxn < 0)
 		goto errout;
 
+	if (event->attach_state & PERF_ATTACH_TASK_DATA) {
+		task_ctx_data = kzalloc(pmu->task_ctx_size, GFP_KERNEL);
+		if (!task_ctx_data) {
+			err = -ENOMEM;
+			goto errout;
+		}
+	}
+
 retry:
 	ctx = perf_lock_task_context(task, ctxn, &flags);
 	if (ctx) {
 		clone_ctx = unclone_ctx(ctx);
 		++ctx->pin_count;
+
+		if (task_ctx_data && !ctx->task_ctx_data) {
+			ctx->task_ctx_data = task_ctx_data;
+			task_ctx_data = NULL;
+		}
 		raw_spin_unlock_irqrestore(&ctx->lock, flags);
 
 		if (clone_ctx)
@@ -3396,6 +3421,11 @@ retry:
 		if (!ctx)
 			goto errout;
 
+		if (task_ctx_data) {
+			ctx->task_ctx_data = task_ctx_data;
+			task_ctx_data = NULL;
+		}
+
 		err = 0;
 		mutex_lock(&task->perf_event_mutex);
 		/*
@@ -3422,9 +3452,11 @@ retry:
 		}
 	}
 
+	kfree(task_ctx_data);
 	return ctx;
 
 errout:
+	kfree(task_ctx_data);
 	return ERR_PTR(err);
 }
 
@@ -7613,7 +7645,7 @@ SYSCALL_DEFINE5(perf_event_open,
 	/*
 	 * Get the target context (task or percpu):
 	 */
-	ctx = find_get_context(pmu, task, event->cpu);
+	ctx = find_get_context(pmu, task, event);
 	if (IS_ERR(ctx)) {
 		err = PTR_ERR(ctx);
 		goto err_alloc;
@@ -7819,7 +7851,7 @@ perf_event_create_kernel_counter(struct perf_event_attr *attr, int cpu,
 
 	account_event(event);
 
-	ctx = find_get_context(event->pmu, task, cpu);
+	ctx = find_get_context(event->pmu, task, event);
 	if (IS_ERR(ctx)) {
 		err = PTR_ERR(ctx);
 		goto err_free;
