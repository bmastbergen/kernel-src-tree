xfs: validate transaction header length on log recovery

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Brian Foster <bfoster@redhat.com>
commit 89cebc8477290b152618ffa110bbeae340d50900
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/89cebc84.failed

When log recovery hits a new transaction, it copies the transaction
header from the expected location in the log to the in-core structure
using the length from the op record header. This length is validated to
ensure it doesn't exceed the length of the record, but not against the
expected size of a transaction header (and thus the size of the in-core
structure). If the on-disk length is corrupted, the associated memcpy()
can overflow, write to unrelated memory and lead to crashes. This has
been reproduced via filesystem fuzzing.

The code currently handles the possibility that the transaction header
is split across two op records. Neither instance accounts for corruption
where the op record length might be larger than the in-core transaction
header. Update both sites to detect such corruption, warn and return an
error from log recovery. Also add some comments and assert that if the
record is split, the copy of the second portion is less than a full
header. Otherwise, this suggests the copy of the second portion could
have overwritten bits from the first and thus that something could be
wrong.

	Signed-off-by: Brian Foster <bfoster@redhat.com>
	Reviewed-by: Dave Chinner <dchinner@redhat.com>
	Signed-off-by: Dave Chinner <david@fromorbit.com>


(cherry picked from commit 89cebc8477290b152618ffa110bbeae340d50900)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/xfs_log_recover.c
diff --cc fs/xfs/xfs_log_recover.c
index 7b97b53b2b95,493a8ef146fc..000000000000
--- a/fs/xfs/xfs_log_recover.c
+++ b/fs/xfs/xfs_log_recover.c
@@@ -3534,16 -3358,327 +3534,321 @@@ out
  	return error ? error : error2;
  }
  
 -STATIC void
 -xlog_recover_add_item(
 -	struct list_head	*head)
 -{
 -	xlog_recover_item_t	*item;
 -
 -	item = kmem_zalloc(sizeof(xlog_recover_item_t), KM_SLEEP);
 -	INIT_LIST_HEAD(&item->ri_list);
 -	list_add_tail(&item->ri_list, head);
 -}
 -
  STATIC int
 -xlog_recover_add_to_cont_trans(
 -	struct xlog		*log,
 -	struct xlog_recover	*trans,
 -	char			*dp,
 -	int			len)
 +xlog_recover_unmount_trans(
 +	struct xlog		*log)
  {
++<<<<<<< HEAD
 +	/* Do nothing now */
 +	xfs_warn(log->l_mp, "%s: Unmount LR", __func__);
++=======
+ 	xlog_recover_item_t	*item;
+ 	char			*ptr, *old_ptr;
+ 	int			old_len;
+ 
+ 	/*
+ 	 * If the transaction is empty, the header was split across this and the
+ 	 * previous record. Copy the rest of the header.
+ 	 */
+ 	if (list_empty(&trans->r_itemq)) {
+ 		ASSERT(len < sizeof(struct xfs_trans_header));
+ 		if (len > sizeof(struct xfs_trans_header)) {
+ 			xfs_warn(log->l_mp, "%s: bad header length", __func__);
+ 			return -EIO;
+ 		}
+ 
+ 		xlog_recover_add_item(&trans->r_itemq);
+ 		ptr = (char *)&trans->r_theader +
+ 				sizeof(struct xfs_trans_header) - len;
+ 		memcpy(ptr, dp, len);
+ 		return 0;
+ 	}
+ 
+ 	/* take the tail entry */
+ 	item = list_entry(trans->r_itemq.prev, xlog_recover_item_t, ri_list);
+ 
+ 	old_ptr = item->ri_buf[item->ri_cnt-1].i_addr;
+ 	old_len = item->ri_buf[item->ri_cnt-1].i_len;
+ 
+ 	ptr = kmem_realloc(old_ptr, len+old_len, old_len, KM_SLEEP);
+ 	memcpy(&ptr[old_len], dp, len);
+ 	item->ri_buf[item->ri_cnt-1].i_len += len;
+ 	item->ri_buf[item->ri_cnt-1].i_addr = ptr;
+ 	trace_xfs_log_recover_item_add_cont(log, trans, item, 0);
++>>>>>>> 89cebc847729 (xfs: validate transaction header length on log recovery)
+ 	return 0;
+ }
+ 
+ /*
++<<<<<<< HEAD
++=======
+  * The next region to add is the start of a new region.  It could be
+  * a whole region or it could be the first part of a new region.  Because
+  * of this, the assumption here is that the type and size fields of all
+  * format structures fit into the first 32 bits of the structure.
+  *
+  * This works because all regions must be 32 bit aligned.  Therefore, we
+  * either have both fields or we have neither field.  In the case we have
+  * neither field, the data part of the region is zero length.  We only have
+  * a log_op_header and can throw away the header since a new one will appear
+  * later.  If we have at least 4 bytes, then we can determine how many regions
+  * will appear in the current log item.
+  */
+ STATIC int
+ xlog_recover_add_to_trans(
+ 	struct xlog		*log,
+ 	struct xlog_recover	*trans,
+ 	char			*dp,
+ 	int			len)
+ {
+ 	xfs_inode_log_format_t	*in_f;			/* any will do */
+ 	xlog_recover_item_t	*item;
+ 	char			*ptr;
+ 
+ 	if (!len)
+ 		return 0;
+ 	if (list_empty(&trans->r_itemq)) {
+ 		/* we need to catch log corruptions here */
+ 		if (*(uint *)dp != XFS_TRANS_HEADER_MAGIC) {
+ 			xfs_warn(log->l_mp, "%s: bad header magic number",
+ 				__func__);
+ 			ASSERT(0);
+ 			return -EIO;
+ 		}
+ 
+ 		if (len > sizeof(struct xfs_trans_header)) {
+ 			xfs_warn(log->l_mp, "%s: bad header length", __func__);
+ 			ASSERT(0);
+ 			return -EIO;
+ 		}
+ 
+ 		/*
+ 		 * The transaction header can be arbitrarily split across op
+ 		 * records. If we don't have the whole thing here, copy what we
+ 		 * do have and handle the rest in the next record.
+ 		 */
+ 		if (len == sizeof(struct xfs_trans_header))
+ 			xlog_recover_add_item(&trans->r_itemq);
+ 		memcpy(&trans->r_theader, dp, len);
+ 		return 0;
+ 	}
+ 
+ 	ptr = kmem_alloc(len, KM_SLEEP);
+ 	memcpy(ptr, dp, len);
+ 	in_f = (xfs_inode_log_format_t *)ptr;
+ 
+ 	/* take the tail entry */
+ 	item = list_entry(trans->r_itemq.prev, xlog_recover_item_t, ri_list);
+ 	if (item->ri_total != 0 &&
+ 	     item->ri_total == item->ri_cnt) {
+ 		/* tail item is in use, get a new one */
+ 		xlog_recover_add_item(&trans->r_itemq);
+ 		item = list_entry(trans->r_itemq.prev,
+ 					xlog_recover_item_t, ri_list);
+ 	}
+ 
+ 	if (item->ri_total == 0) {		/* first region to be added */
+ 		if (in_f->ilf_size == 0 ||
+ 		    in_f->ilf_size > XLOG_MAX_REGIONS_IN_ITEM) {
+ 			xfs_warn(log->l_mp,
+ 		"bad number of regions (%d) in inode log format",
+ 				  in_f->ilf_size);
+ 			ASSERT(0);
+ 			kmem_free(ptr);
+ 			return -EIO;
+ 		}
+ 
+ 		item->ri_total = in_f->ilf_size;
+ 		item->ri_buf =
+ 			kmem_zalloc(item->ri_total * sizeof(xfs_log_iovec_t),
+ 				    KM_SLEEP);
+ 	}
+ 	ASSERT(item->ri_total > item->ri_cnt);
+ 	/* Description region is ri_buf[0] */
+ 	item->ri_buf[item->ri_cnt].i_addr = ptr;
+ 	item->ri_buf[item->ri_cnt].i_len  = len;
+ 	item->ri_cnt++;
+ 	trace_xfs_log_recover_item_add(log, trans, item, 0);
  	return 0;
  }
  
  /*
+  * Free up any resources allocated by the transaction
+  *
+  * Remember that EFIs, EFDs, and IUNLINKs are handled later.
+  */
+ STATIC void
+ xlog_recover_free_trans(
+ 	struct xlog_recover	*trans)
+ {
+ 	xlog_recover_item_t	*item, *n;
+ 	int			i;
+ 
+ 	list_for_each_entry_safe(item, n, &trans->r_itemq, ri_list) {
+ 		/* Free the regions in the item. */
+ 		list_del(&item->ri_list);
+ 		for (i = 0; i < item->ri_cnt; i++)
+ 			kmem_free(item->ri_buf[i].i_addr);
+ 		/* Free the item itself */
+ 		kmem_free(item->ri_buf);
+ 		kmem_free(item);
+ 	}
+ 	/* Free the transaction recover structure */
+ 	kmem_free(trans);
+ }
+ 
+ /*
+  * On error or completion, trans is freed.
+  */
+ STATIC int
+ xlog_recovery_process_trans(
+ 	struct xlog		*log,
+ 	struct xlog_recover	*trans,
+ 	char			*dp,
+ 	unsigned int		len,
+ 	unsigned int		flags,
+ 	int			pass)
+ {
+ 	int			error = 0;
+ 	bool			freeit = false;
+ 
+ 	/* mask off ophdr transaction container flags */
+ 	flags &= ~XLOG_END_TRANS;
+ 	if (flags & XLOG_WAS_CONT_TRANS)
+ 		flags &= ~XLOG_CONTINUE_TRANS;
+ 
+ 	/*
+ 	 * Callees must not free the trans structure. We'll decide if we need to
+ 	 * free it or not based on the operation being done and it's result.
+ 	 */
+ 	switch (flags) {
+ 	/* expected flag values */
+ 	case 0:
+ 	case XLOG_CONTINUE_TRANS:
+ 		error = xlog_recover_add_to_trans(log, trans, dp, len);
+ 		break;
+ 	case XLOG_WAS_CONT_TRANS:
+ 		error = xlog_recover_add_to_cont_trans(log, trans, dp, len);
+ 		break;
+ 	case XLOG_COMMIT_TRANS:
+ 		error = xlog_recover_commit_trans(log, trans, pass);
+ 		/* success or fail, we are now done with this transaction. */
+ 		freeit = true;
+ 		break;
+ 
+ 	/* unexpected flag values */
+ 	case XLOG_UNMOUNT_TRANS:
+ 		/* just skip trans */
+ 		xfs_warn(log->l_mp, "%s: Unmount LR", __func__);
+ 		freeit = true;
+ 		break;
+ 	case XLOG_START_TRANS:
+ 	default:
+ 		xfs_warn(log->l_mp, "%s: bad flag 0x%x", __func__, flags);
+ 		ASSERT(0);
+ 		error = -EIO;
+ 		break;
+ 	}
+ 	if (error || freeit)
+ 		xlog_recover_free_trans(trans);
+ 	return error;
+ }
+ 
+ /*
+  * Lookup the transaction recovery structure associated with the ID in the
+  * current ophdr. If the transaction doesn't exist and the start flag is set in
+  * the ophdr, then allocate a new transaction for future ID matches to find.
+  * Either way, return what we found during the lookup - an existing transaction
+  * or nothing.
+  */
+ STATIC struct xlog_recover *
+ xlog_recover_ophdr_to_trans(
+ 	struct hlist_head	rhash[],
+ 	struct xlog_rec_header	*rhead,
+ 	struct xlog_op_header	*ohead)
+ {
+ 	struct xlog_recover	*trans;
+ 	xlog_tid_t		tid;
+ 	struct hlist_head	*rhp;
+ 
+ 	tid = be32_to_cpu(ohead->oh_tid);
+ 	rhp = &rhash[XLOG_RHASH(tid)];
+ 	hlist_for_each_entry(trans, rhp, r_list) {
+ 		if (trans->r_log_tid == tid)
+ 			return trans;
+ 	}
+ 
+ 	/*
+ 	 * skip over non-start transaction headers - we could be
+ 	 * processing slack space before the next transaction starts
+ 	 */
+ 	if (!(ohead->oh_flags & XLOG_START_TRANS))
+ 		return NULL;
+ 
+ 	ASSERT(be32_to_cpu(ohead->oh_len) == 0);
+ 
+ 	/*
+ 	 * This is a new transaction so allocate a new recovery container to
+ 	 * hold the recovery ops that will follow.
+ 	 */
+ 	trans = kmem_zalloc(sizeof(struct xlog_recover), KM_SLEEP);
+ 	trans->r_log_tid = tid;
+ 	trans->r_lsn = be64_to_cpu(rhead->h_lsn);
+ 	INIT_LIST_HEAD(&trans->r_itemq);
+ 	INIT_HLIST_NODE(&trans->r_list);
+ 	hlist_add_head(&trans->r_list, rhp);
+ 
+ 	/*
+ 	 * Nothing more to do for this ophdr. Items to be added to this new
+ 	 * transaction will be in subsequent ophdr containers.
+ 	 */
+ 	return NULL;
+ }
+ 
+ STATIC int
+ xlog_recover_process_ophdr(
+ 	struct xlog		*log,
+ 	struct hlist_head	rhash[],
+ 	struct xlog_rec_header	*rhead,
+ 	struct xlog_op_header	*ohead,
+ 	char			*dp,
+ 	char			*end,
+ 	int			pass)
+ {
+ 	struct xlog_recover	*trans;
+ 	unsigned int		len;
+ 
+ 	/* Do we understand who wrote this op? */
+ 	if (ohead->oh_clientid != XFS_TRANSACTION &&
+ 	    ohead->oh_clientid != XFS_LOG) {
+ 		xfs_warn(log->l_mp, "%s: bad clientid 0x%x",
+ 			__func__, ohead->oh_clientid);
+ 		ASSERT(0);
+ 		return -EIO;
+ 	}
+ 
+ 	/*
+ 	 * Check the ophdr contains all the data it is supposed to contain.
+ 	 */
+ 	len = be32_to_cpu(ohead->oh_len);
+ 	if (dp + len > end) {
+ 		xfs_warn(log->l_mp, "%s: bad length 0x%x", __func__, len);
+ 		WARN_ON(1);
+ 		return -EIO;
+ 	}
+ 
+ 	trans = xlog_recover_ophdr_to_trans(rhash, rhead, ohead);
+ 	if (!trans) {
+ 		/* nothing to do, so skip over this ophdr */
+ 		return 0;
+ 	}
+ 
+ 	return xlog_recovery_process_trans(log, trans, dp, len,
+ 					   ohead->oh_flags, pass);
+ }
+ 
+ /*
++>>>>>>> 89cebc847729 (xfs: validate transaction header length on log recovery)
   * There are two valid states of the r_state field.  0 indicates that the
   * transaction structure is in a normal state.  We have either seen the
   * start of the transaction or the last operation we added was not a partial
* Unmerged path fs/xfs/xfs_log_recover.c
