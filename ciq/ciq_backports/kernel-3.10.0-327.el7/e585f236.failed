udp: Changes to udp_offload to support remote checksum offload

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Tom Herbert <therbert@google.com>
commit e585f23636370320bc2071ca5ba2744ae37c3e51
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/e585f236.failed

Add a new GSO type, SKB_GSO_TUNNEL_REMCSUM, which indicates remote
checksum offload being done (in this case inner checksum must not
be offloaded to the NIC).

Added logic in __skb_udp_tunnel_segment to handle remote checksum
offload case.

	Signed-off-by: Tom Herbert <therbert@google.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit e585f23636370320bc2071ca5ba2744ae37c3e51)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/skbuff.h
#	net/ipv4/udp_offload.c
diff --cc include/linux/skbuff.h
index 9599a478ca15,74ed34413969..000000000000
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@@ -360,24 -361,21 +360,28 @@@ enum 
  
  	SKB_GSO_GRE = 1 << 6,
  
 -	SKB_GSO_GRE_CSUM = 1 << 7,
 -
 -	SKB_GSO_IPIP = 1 << 8,
 +	SKB_GSO_IPIP = 1 << 7,
  
 -	SKB_GSO_SIT = 1 << 9,
 +	SKB_GSO_SIT = 1 << 8,
  
 -	SKB_GSO_UDP_TUNNEL = 1 << 10,
 +	SKB_GSO_UDP_TUNNEL = 1 << 9,
  
 -	SKB_GSO_UDP_TUNNEL_CSUM = 1 << 11,
 +	SKB_GSO_MPLS = 1 << 10,
  
 -	SKB_GSO_MPLS = 1 << 12,
 +	/* GSO_MASK2, see netdev_features.h */
 +	SKB_GSO_GRE_CSUM = 1 << 11,
  
++<<<<<<< HEAD
 +	SKB_GSO_UDP_TUNNEL_CSUM = 1 << 12,
++=======
+ 	SKB_GSO_TUNNEL_REMCSUM = 1 << 13,
++>>>>>>> e585f2363637 (udp: Changes to udp_offload to support remote checksum offload)
  };
  
 +/* NETIF_F_GSO flags are no longer part of a single range */
 +#define SKB_GSO1_MASK (SKB_GSO_GRE_CSUM - 1)
 +#define SKB_GSO2_MASK (SKB_GSO_GRE_CSUM|SKB_GSO_UDP_TUNNEL_CSUM)
 +
  #if BITS_PER_LONG > 32
  #define NET_SKBUFF_DATA_USES_OFFSET 1
  #endif
@@@ -534,6 -546,74 +538,77 @@@ struct sk_buff 
  				data_len;
  	__u16			mac_len,
  				hdr_len;
++<<<<<<< HEAD
++=======
+ 
+ 	/* Following fields are _not_ copied in __copy_skb_header()
+ 	 * Note that queue_mapping is here mostly to fill a hole.
+ 	 */
+ 	kmemcheck_bitfield_begin(flags1);
+ 	__u16			queue_mapping;
+ 	__u8			cloned:1,
+ 				nohdr:1,
+ 				fclone:2,
+ 				peeked:1,
+ 				head_frag:1,
+ 				xmit_more:1;
+ 	/* one bit hole */
+ 	kmemcheck_bitfield_end(flags1);
+ 
+ 	/* fields enclosed in headers_start/headers_end are copied
+ 	 * using a single memcpy() in __copy_skb_header()
+ 	 */
+ 	/* private: */
+ 	__u32			headers_start[0];
+ 	/* public: */
+ 
+ /* if you move pkt_type around you also must adapt those constants */
+ #ifdef __BIG_ENDIAN_BITFIELD
+ #define PKT_TYPE_MAX	(7 << 5)
+ #else
+ #define PKT_TYPE_MAX	7
+ #endif
+ #define PKT_TYPE_OFFSET()	offsetof(struct sk_buff, __pkt_type_offset)
+ 
+ 	__u8			__pkt_type_offset[0];
+ 	__u8			pkt_type:3;
+ 	__u8			pfmemalloc:1;
+ 	__u8			ignore_df:1;
+ 	__u8			nfctinfo:3;
+ 
+ 	__u8			nf_trace:1;
+ 	__u8			ip_summed:2;
+ 	__u8			ooo_okay:1;
+ 	__u8			l4_hash:1;
+ 	__u8			sw_hash:1;
+ 	__u8			wifi_acked_valid:1;
+ 	__u8			wifi_acked:1;
+ 
+ 	__u8			no_fcs:1;
+ 	/* Indicates the inner headers are valid in the skbuff. */
+ 	__u8			encapsulation:1;
+ 	__u8			encap_hdr_csum:1;
+ 	__u8			csum_valid:1;
+ 	__u8			csum_complete_sw:1;
+ 	__u8			csum_level:2;
+ 	__u8			csum_bad:1;
+ 
+ #ifdef CONFIG_IPV6_NDISC_NODETYPE
+ 	__u8			ndisc_nodetype:2;
+ #endif
+ 	__u8			ipvs_property:1;
+ 	__u8			inner_protocol_type:1;
+ 	__u8			remcsum_offload:1;
+ 	/* 3 or 5 bit hole */
+ 
+ #ifdef CONFIG_NET_SCHED
+ 	__u16			tc_index;	/* traffic control index */
+ #ifdef CONFIG_NET_CLS_ACT
+ 	__u16			tc_verd;	/* traffic control verdict */
+ #endif
+ #endif
+ 
++>>>>>>> e585f2363637 (udp: Changes to udp_offload to support remote checksum offload)
  	union {
  		__wsum		csum;
  		struct {
diff --cc net/ipv4/udp_offload.c
index 7729d35bcf82,0a5a70d0e84c..000000000000
--- a/net/ipv4/udp_offload.c
+++ b/net/ipv4/udp_offload.c
@@@ -25,9 -25,154 +25,154 @@@ struct udp_offload_priv 
  	struct udp_offload_priv __rcu *next;
  };
  
 -static struct sk_buff *__skb_udp_tunnel_segment(struct sk_buff *skb,
 -	netdev_features_t features,
 -	struct sk_buff *(*gso_inner_segment)(struct sk_buff *skb,
 -					     netdev_features_t features),
 -	__be16 new_protocol, bool is_ipv6)
 +static int udp4_ufo_send_check(struct sk_buff *skb)
  {
++<<<<<<< HEAD
 +	return 0;
++=======
+ 	struct sk_buff *segs = ERR_PTR(-EINVAL);
+ 	u16 mac_offset = skb->mac_header;
+ 	int mac_len = skb->mac_len;
+ 	int tnl_hlen = skb_inner_mac_header(skb) - skb_transport_header(skb);
+ 	__be16 protocol = skb->protocol;
+ 	netdev_features_t enc_features;
+ 	int udp_offset, outer_hlen;
+ 	unsigned int oldlen;
+ 	bool need_csum = !!(skb_shinfo(skb)->gso_type &
+ 			    SKB_GSO_UDP_TUNNEL_CSUM);
+ 	bool remcsum = !!(skb_shinfo(skb)->gso_type & SKB_GSO_TUNNEL_REMCSUM);
+ 	bool offload_csum = false, dont_encap = (need_csum || remcsum);
+ 
+ 	oldlen = (u16)~skb->len;
+ 
+ 	if (unlikely(!pskb_may_pull(skb, tnl_hlen)))
+ 		goto out;
+ 
+ 	skb->encapsulation = 0;
+ 	__skb_pull(skb, tnl_hlen);
+ 	skb_reset_mac_header(skb);
+ 	skb_set_network_header(skb, skb_inner_network_offset(skb));
+ 	skb->mac_len = skb_inner_network_offset(skb);
+ 	skb->protocol = new_protocol;
+ 	skb->encap_hdr_csum = need_csum;
+ 	skb->remcsum_offload = remcsum;
+ 
+ 	/* Try to offload checksum if possible */
+ 	offload_csum = !!(need_csum &&
+ 			  (skb->dev->features &
+ 			   (is_ipv6 ? NETIF_F_V6_CSUM : NETIF_F_V4_CSUM)));
+ 
+ 	/* segment inner packet. */
+ 	enc_features = skb->dev->hw_enc_features & features;
+ 	segs = gso_inner_segment(skb, enc_features);
+ 	if (IS_ERR_OR_NULL(segs)) {
+ 		skb_gso_error_unwind(skb, protocol, tnl_hlen, mac_offset,
+ 				     mac_len);
+ 		goto out;
+ 	}
+ 
+ 	outer_hlen = skb_tnl_header_len(skb);
+ 	udp_offset = outer_hlen - tnl_hlen;
+ 	skb = segs;
+ 	do {
+ 		struct udphdr *uh;
+ 		int len;
+ 		__be32 delta;
+ 
+ 		if (dont_encap) {
+ 			skb->encapsulation = 0;
+ 			skb->ip_summed = CHECKSUM_NONE;
+ 		} else {
+ 			/* Only set up inner headers if we might be offloading
+ 			 * inner checksum.
+ 			 */
+ 			skb_reset_inner_headers(skb);
+ 			skb->encapsulation = 1;
+ 		}
+ 
+ 		skb->mac_len = mac_len;
+ 		skb->protocol = protocol;
+ 
+ 		skb_push(skb, outer_hlen);
+ 		skb_reset_mac_header(skb);
+ 		skb_set_network_header(skb, mac_len);
+ 		skb_set_transport_header(skb, udp_offset);
+ 		len = skb->len - udp_offset;
+ 		uh = udp_hdr(skb);
+ 		uh->len = htons(len);
+ 
+ 		if (!need_csum)
+ 			continue;
+ 
+ 		delta = htonl(oldlen + len);
+ 
+ 		uh->check = ~csum_fold((__force __wsum)
+ 				       ((__force u32)uh->check +
+ 					(__force u32)delta));
+ 		if (offload_csum) {
+ 			skb->ip_summed = CHECKSUM_PARTIAL;
+ 			skb->csum_start = skb_transport_header(skb) - skb->head;
+ 			skb->csum_offset = offsetof(struct udphdr, check);
+ 		} else if (remcsum) {
+ 			/* Need to calculate checksum from scratch,
+ 			 * inner checksums are never when doing
+ 			 * remote_checksum_offload.
+ 			 */
+ 
+ 			skb->csum = skb_checksum(skb, udp_offset,
+ 						 skb->len - udp_offset,
+ 						 0);
+ 			uh->check = csum_fold(skb->csum);
+ 			if (uh->check == 0)
+ 				uh->check = CSUM_MANGLED_0;
+ 		} else {
+ 			uh->check = gso_make_checksum(skb, ~uh->check);
+ 
+ 			if (uh->check == 0)
+ 				uh->check = CSUM_MANGLED_0;
+ 		}
+ 	} while ((skb = skb->next));
+ out:
+ 	return segs;
+ }
+ 
+ struct sk_buff *skb_udp_tunnel_segment(struct sk_buff *skb,
+ 				       netdev_features_t features,
+ 				       bool is_ipv6)
+ {
+ 	__be16 protocol = skb->protocol;
+ 	const struct net_offload **offloads;
+ 	const struct net_offload *ops;
+ 	struct sk_buff *segs = ERR_PTR(-EINVAL);
+ 	struct sk_buff *(*gso_inner_segment)(struct sk_buff *skb,
+ 					     netdev_features_t features);
+ 
+ 	rcu_read_lock();
+ 
+ 	switch (skb->inner_protocol_type) {
+ 	case ENCAP_TYPE_ETHER:
+ 		protocol = skb->inner_protocol;
+ 		gso_inner_segment = skb_mac_gso_segment;
+ 		break;
+ 	case ENCAP_TYPE_IPPROTO:
+ 		offloads = is_ipv6 ? inet6_offloads : inet_offloads;
+ 		ops = rcu_dereference(offloads[skb->inner_ipproto]);
+ 		if (!ops || !ops->callbacks.gso_segment)
+ 			goto out_unlock;
+ 		gso_inner_segment = ops->callbacks.gso_segment;
+ 		break;
+ 	default:
+ 		goto out_unlock;
+ 	}
+ 
+ 	segs = __skb_udp_tunnel_segment(skb, features, gso_inner_segment,
+ 					protocol, is_ipv6);
+ 
+ out_unlock:
+ 	rcu_read_unlock();
+ 
+ 	return segs;
++>>>>>>> e585f2363637 (udp: Changes to udp_offload to support remote checksum offload)
  }
  
  static struct sk_buff *udp4_ufo_fragment(struct sk_buff *skb,
diff --git a/include/linux/netdev_features.h b/include/linux/netdev_features.h
index 799c6053a1fd..c745e8455315 100644
--- a/include/linux/netdev_features.h
+++ b/include/linux/netdev_features.h
@@ -46,8 +46,9 @@ enum {
 	NETIF_F_GSO_SIT_BIT,		/* ... SIT tunnel with TSO */
 	NETIF_F_GSO_UDP_TUNNEL_BIT,	/* ... UDP TUNNEL with TSO */
 	NETIF_F_GSO_MPLS_BIT,		/* ... MPLS segmentation */
+	NETIF_F_GSO_TUNNEL_REMCSUM_BIT, /* ... TUNNEL with TSO & REMCSUM */
 	/**/NETIF_F_GSO_LAST =		/* last bit, see GSO_MASK */
-		NETIF_F_GSO_MPLS_BIT,
+		NETIF_F_GSO_TUNNEL_REMCSUM_BIT,
 
 	NETIF_F_FCOE_CRC_BIT,		/* FCoE CRC32 */
 	NETIF_F_SCTP_CSUM_BIT,		/* SCTP checksum offload */
@@ -118,6 +119,7 @@ enum {
 #define NETIF_F_GSO_UDP_TUNNEL	__NETIF_F(GSO_UDP_TUNNEL)
 #define NETIF_F_GSO_UDP_TUNNEL_CSUM __NETIF_F(GSO_UDP_TUNNEL_CSUM)
 #define NETIF_F_GSO_MPLS	__NETIF_F(GSO_MPLS)
+#define NETIF_F_GSO_TUNNEL_REMCSUM __NETIF_F(GSO_TUNNEL_REMCSUM)
 #define NETIF_F_HW_VLAN_STAG_FILTER __NETIF_F(HW_VLAN_STAG_FILTER)
 #define NETIF_F_HW_VLAN_STAG_RX	__NETIF_F(HW_VLAN_STAG_RX)
 #define NETIF_F_HW_VLAN_STAG_TX	__NETIF_F(HW_VLAN_STAG_TX)
diff --git a/include/linux/netdevice.h b/include/linux/netdevice.h
index 93c2d6dc113c..47554901b189 100644
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@ -3043,6 +3043,7 @@ static inline bool net_gso_ok(netdev_features_t features, int gso_type)
 	BUILD_BUG_ON(SKB_GSO_SIT     != (NETIF_F_GSO_SIT >> NETIF_F_GSO_SHIFT));
 	BUILD_BUG_ON(SKB_GSO_UDP_TUNNEL != (NETIF_F_GSO_UDP_TUNNEL >> NETIF_F_GSO_SHIFT));
 	BUILD_BUG_ON(SKB_GSO_MPLS    != (NETIF_F_GSO_MPLS >> NETIF_F_GSO_SHIFT));
+	BUILD_BUG_ON(SKB_GSO_TUNNEL_REMCSUM != (NETIF_F_GSO_TUNNEL_REMCSUM >> NETIF_F_GSO_SHIFT));
 
 	/* GSO2 flags, see netdev_features.h */
 	BUILD_BUG_ON(SKB_GSO_GRE_CSUM != (NETIF_F_GSO_GRE_CSUM >> NETIF_F_GSO2_SHIFT));
* Unmerged path include/linux/skbuff.h
diff --git a/net/core/skbuff.c b/net/core/skbuff.c
index af49e6e94c48..e86d62b49271 100644
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -2973,7 +2973,7 @@ struct sk_buff *skb_segment(struct sk_buff *head_skb,
 		if (nskb->len == len + doffset)
 			goto perform_csum_check;
 
-		if (!sg) {
+		if (!sg && !nskb->remcsum_offload) {
 			nskb->ip_summed = CHECKSUM_NONE;
 			nskb->csum = skb_copy_and_csum_bits(head_skb, offset,
 							    skb_put(nskb, len),
@@ -3045,7 +3045,7 @@ skip_fraglist:
 		nskb->truesize += nskb->data_len;
 
 perform_csum_check:
-		if (!csum) {
+		if (!csum && !nskb->remcsum_offload) {
 			nskb->csum = skb_checksum(nskb, doffset,
 						  nskb->len - doffset, 0);
 			nskb->ip_summed = CHECKSUM_NONE;
diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 7da79adb81ec..ecd4bc84e631 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1287,6 +1287,7 @@ static struct sk_buff *inet_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_TCPV6 |
 		       SKB_GSO_UDP_TUNNEL |
 		       SKB_GSO_UDP_TUNNEL_CSUM |
+		       SKB_GSO_TUNNEL_REMCSUM |
 		       SKB_GSO_MPLS |
 		       0)))
 		goto out;
diff --git a/net/ipv4/tcp_offload.c b/net/ipv4/tcp_offload.c
index 7cdeac54cee6..a9d66f80cd97 100644
--- a/net/ipv4/tcp_offload.c
+++ b/net/ipv4/tcp_offload.c
@@ -63,6 +63,7 @@ struct sk_buff *tcp_gso_segment(struct sk_buff *skb,
 			       SKB_GSO_MPLS |
 			       SKB_GSO_UDP_TUNNEL |
 			       SKB_GSO_UDP_TUNNEL_CSUM |
+			       SKB_GSO_TUNNEL_REMCSUM |
 			       0) ||
 			     !(type & (SKB_GSO_TCPV4 | SKB_GSO_TCPV6))))
 			goto out;
* Unmerged path net/ipv4/udp_offload.c
diff --git a/net/ipv6/ip6_offload.c b/net/ipv6/ip6_offload.c
index 8f4bf8d4e2f6..88e65a4439e3 100644
--- a/net/ipv6/ip6_offload.c
+++ b/net/ipv6/ip6_offload.c
@@ -103,6 +103,7 @@ static struct sk_buff *ipv6_gso_segment(struct sk_buff *skb,
 		       SKB_GSO_SIT |
 		       SKB_GSO_UDP_TUNNEL |
 		       SKB_GSO_UDP_TUNNEL_CSUM |
+		       SKB_GSO_TUNNEL_REMCSUM |
 		       SKB_GSO_MPLS |
 		       SKB_GSO_TCPV6 |
 		       0)))
diff --git a/net/ipv6/udp_offload.c b/net/ipv6/udp_offload.c
index 71bc2d6c3277..cffba4d8d081 100644
--- a/net/ipv6/udp_offload.c
+++ b/net/ipv6/udp_offload.c
@@ -47,6 +47,7 @@ static struct sk_buff *udp6_ufo_fragment(struct sk_buff *skb,
 				      SKB_GSO_DODGY |
 				      SKB_GSO_UDP_TUNNEL |
 				      SKB_GSO_UDP_TUNNEL_CSUM |
+				      SKB_GSO_TUNNEL_REMCSUM |
 				      SKB_GSO_GRE |
 				      SKB_GSO_GRE_CSUM |
 				      SKB_GSO_IPIP |
