block: flush: avoid to figure out flush queue unnecessarily

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [block] flush: avoid to figure out flush queue unnecessarily (Jeff Moyer) [1209624]
Rebuild_FUZZ: 93.69%
commit-author Ming Lei <ming.lei@canonical.com>
commit 0bae352da54a95435f721705d3670a6eaefdcf87
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/0bae352d.failed

Just figuring out flush queue at the entry of kicking off flush
machinery and request's completion handler, then pass it through.

	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Ming Lei <ming.lei@canonical.com>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 0bae352da54a95435f721705d3670a6eaefdcf87)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-flush.c
diff --cc block/blk-flush.c
index 4ba98aaf2ce6,9bc5b4f35c23..000000000000
--- a/block/blk-flush.c
+++ b/block/blk-flush.c
@@@ -160,11 -162,12 +162,16 @@@ static bool blk_flush_queue_rq(struct r
   * RETURNS:
   * %true if requests were added to the dispatch queue, %false otherwise.
   */
- static bool blk_flush_complete_seq(struct request *rq, unsigned int seq,
- 				   int error)
+ static bool blk_flush_complete_seq(struct request *rq,
+ 				   struct blk_flush_queue *fq,
+ 				   unsigned int seq, int error)
  {
  	struct request_queue *q = rq->q;
++<<<<<<< HEAD
 +	struct list_head *pending = &q->flush_queue[q->flush_pending_idx];
++=======
+ 	struct list_head *pending = &fq->flush_queue[fq->flush_pending_idx];
++>>>>>>> 0bae352da54a (block: flush: avoid to figure out flush queue unnecessarily)
  	bool queued = false, kicked;
  
  	BUG_ON(rq->flush.seq & seq);
@@@ -276,15 -281,15 +284,19 @@@ static void flush_end_io(struct reques
   * RETURNS:
   * %true if flush was issued, %false otherwise.
   */
- static bool blk_kick_flush(struct request_queue *q)
+ static bool blk_kick_flush(struct request_queue *q, struct blk_flush_queue *fq)
  {
++<<<<<<< HEAD
 +	struct list_head *pending = &q->flush_queue[q->flush_pending_idx];
++=======
+ 	struct list_head *pending = &fq->flush_queue[fq->flush_pending_idx];
++>>>>>>> 0bae352da54a (block: flush: avoid to figure out flush queue unnecessarily)
  	struct request *first_rq =
  		list_first_entry(pending, struct request, flush.list);
 -	struct request *flush_rq = fq->flush_rq;
 +	struct request *flush_rq = q->flush_rq;
  
  	/* C1 described at the top of this file */
 -	if (fq->flush_pending_idx != fq->flush_running_idx || list_empty(pending))
 +	if (q->flush_pending_idx != q->flush_running_idx || list_empty(pending))
  		return false;
  
  	/* C2 and C3 */
@@@ -337,10 -344,10 +350,15 @@@ static void mq_flush_data_end_io(struc
  	 * After populating an empty queue, kick it to avoid stall.  Read
  	 * the comment in flush_end_io().
  	 */
++<<<<<<< HEAD
 +	spin_lock_irqsave(&q->mq_flush_lock, flags);
 +	if (blk_flush_complete_seq(rq, REQ_FSEQ_DATA, error))
++=======
+ 	spin_lock_irqsave(&fq->mq_flush_lock, flags);
+ 	if (blk_flush_complete_seq(rq, fq, REQ_FSEQ_DATA, error))
++>>>>>>> 0bae352da54a (block: flush: avoid to figure out flush queue unnecessarily)
  		blk_mq_run_hw_queue(hctx, true);
 -	spin_unlock_irqrestore(&fq->mq_flush_lock, flags);
 +	spin_unlock_irqrestore(&q->mq_flush_lock, flags);
  }
  
  /**
@@@ -410,25 -418,16 +429,31 @@@ void blk_insert_flush(struct request *r
  	if (q->mq_ops) {
  		rq->end_io = mq_flush_data_end_io;
  
++<<<<<<< HEAD
 +		spin_lock_irq(&q->mq_flush_lock);
 +		blk_flush_complete_seq(rq, REQ_FSEQ_ACTIONS & ~policy, 0);
 +		spin_unlock_irq(&q->mq_flush_lock);
++=======
+ 		spin_lock_irq(&fq->mq_flush_lock);
+ 		blk_flush_complete_seq(rq, fq, REQ_FSEQ_ACTIONS & ~policy, 0);
+ 		spin_unlock_irq(&fq->mq_flush_lock);
++>>>>>>> 0bae352da54a (block: flush: avoid to figure out flush queue unnecessarily)
  		return;
  	}
  	rq->end_io = flush_data_end_io;
  
- 	blk_flush_complete_seq(rq, REQ_FSEQ_ACTIONS & ~policy, 0);
+ 	blk_flush_complete_seq(rq, fq, REQ_FSEQ_ACTIONS & ~policy, 0);
  }
  
 +static void bio_end_flush(struct bio *bio, int err)
 +{
 +	if (err)
 +		clear_bit(BIO_UPTODATE, &bio->bi_flags);
 +	if (bio->bi_private)
 +		complete(bio->bi_private);
 +	bio_put(bio);
 +}
 +
  /**
   * blkdev_issue_flush - queue a flush
   * @bdev:	blockdev to issue flush for
* Unmerged path block/blk-flush.c
