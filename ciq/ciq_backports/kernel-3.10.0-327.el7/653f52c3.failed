kvm,x86: load guest FPU context more eagerly

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [kvm] x86: load guest FPU context more eagerly (Paolo Bonzini) [1202825]
Rebuild_FUZZ: 95.24%
commit-author Rik van Riel <riel@redhat.com>
commit 653f52c316a49c5ee2701bc13b15879f20790662
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/653f52c3.failed

Currently KVM will clear the FPU bits in CR0.TS in the VMCS, and trap to
re-load them every time the guest accesses the FPU after a switch back into
the guest from the host.

This patch copies the x86 task switch semantics for FPU loading, with the
FPU loaded eagerly after first use if the system uses eager fpu mode,
or if the guest uses the FPU frequently.

In the latter case, after loading the FPU for 255 times, the fpu_counter
will roll over, and we will revert to loading the FPU on demand, until
it has been established that the guest is still actively using the FPU.

This mirrors the x86 task switch policy, which seems to work.

	Signed-off-by: Rik van Riel <riel@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 653f52c316a49c5ee2701bc13b15879f20790662)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/x86.c
diff --cc arch/x86/kvm/x86.c
index c09978a6a4ee,c42134e98e31..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -6926,9 -7095,16 +6928,22 @@@ void kvm_put_guest_fpu(struct kvm_vcpu 
  	fpu_save_init(&vcpu->arch.guest_fpu);
  	__kernel_fpu_end();
  	++vcpu->stat.fpu_reload;
++<<<<<<< HEAD
 +	if (!vcpu->arch.eager_fpu)
 +		kvm_make_request(KVM_REQ_DEACTIVATE_FPU, vcpu);
 +
++=======
+ 	/*
+ 	 * If using eager FPU mode, or if the guest is a frequent user
+ 	 * of the FPU, just leave the FPU active for next time.
+ 	 * Every 255 times fpu_counter rolls over to 0; a guest that uses
+ 	 * the FPU in bursts will revert to loading it on demand.
+ 	 */
+ 	if (!use_eager_fpu()) {
+ 		if (++vcpu->fpu_counter < 5)
+ 			kvm_make_request(KVM_REQ_DEACTIVATE_FPU, vcpu);
+ 	}
++>>>>>>> 653f52c316a4 (kvm,x86: load guest FPU context more eagerly)
  	trace_kvm_fpu(0);
  }
  
* Unmerged path arch/x86/kvm/x86.c
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index e9f180bc34be..6ac4c8a6a6e1 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -234,6 +234,7 @@ struct kvm_vcpu {
 
 	int fpu_active;
 	int guest_fpu_loaded, guest_xcr0_loaded;
+	unsigned char fpu_counter;
 	wait_queue_head_t wq;
 	struct pid *pid;
 	int sigset_active;
