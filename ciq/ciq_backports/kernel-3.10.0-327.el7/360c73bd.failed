hpsa: factor out hpsa_init_cmd function

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Stephen Cameron <stephenmcameron@gmail.com>
commit 360c73bdde4537397f70b17cadd8139ff1f75ab9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/360c73bd.failed

Factor out hpsa_cmd_init from cmd_alloc().  We also need
this for resubmitting commands down the default RAID path
when they have returned from the ioaccel paths with errors.

In particular, reinitialize the cmd_type and busaddr fields as these
will not be correct for submitting down the RAID stack path
after ioaccel command completion.

This saves time when submitting commands.

	Reviewed-by: Scott Teel <scott.teel@pmcs.com>
	Reviewed-by: Kevin Barnett <kevin.barnett@pmcs.com>
	Reviewed-by: Tomas Henzl <thenzl@redhat.com>
	Reviewed-by: Hannes Reinecke <hare@Suse.de>
	Signed-off-by: Don Brace <don.brace@pmcs.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: James Bottomley <JBottomley@Odin.com>
(cherry picked from commit 360c73bdde4537397f70b17cadd8139ff1f75ab9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/hpsa.c
#	drivers/scsi/hpsa_cmd.h
diff --cc drivers/scsi/hpsa.c
index c02c149a91c8,6bb8a3683b1e..000000000000
--- a/drivers/scsi/hpsa.c
+++ b/drivers/scsi/hpsa.c
@@@ -3965,7 -4334,148 +3964,152 @@@ static int hpsa_scsi_queue_command(stru
  	return 0;
  }
  
++<<<<<<< HEAD
 +static int do_not_scan_if_controller_locked_up(struct ctlr_info *h)
++=======
+ static void hpsa_cmd_init(struct ctlr_info *h, int index,
+ 				struct CommandList *c)
+ {
+ 	dma_addr_t cmd_dma_handle, err_dma_handle;
+ 
+ 	/* Zero out all of commandlist except the last field, refcount */
+ 	memset(c, 0, offsetof(struct CommandList, refcount));
+ 	c->Header.tag = cpu_to_le64((u64) (index << DIRECT_LOOKUP_SHIFT));
+ 	cmd_dma_handle = h->cmd_pool_dhandle + index * sizeof(*c);
+ 	c->err_info = h->errinfo_pool + index;
+ 	memset(c->err_info, 0, sizeof(*c->err_info));
+ 	err_dma_handle = h->errinfo_pool_dhandle
+ 	    + index * sizeof(*c->err_info);
+ 	c->cmdindex = index;
+ 	c->busaddr = (u32) cmd_dma_handle;
+ 	c->ErrDesc.Addr = cpu_to_le64((u64) err_dma_handle);
+ 	c->ErrDesc.Len = cpu_to_le32((u32) sizeof(*c->err_info));
+ 	c->h = h;
+ }
+ 
+ static void hpsa_preinitialize_commands(struct ctlr_info *h)
+ {
+ 	int i;
+ 
+ 	for (i = 0; i < h->nr_cmds; i++) {
+ 		struct CommandList *c = h->cmd_pool + i;
+ 
+ 		hpsa_cmd_init(h, i, c);
+ 		atomic_set(&c->refcount, 0);
+ 	}
+ }
+ 
+ static inline void hpsa_cmd_partial_init(struct ctlr_info *h, int index,
+ 				struct CommandList *c)
+ {
+ 	dma_addr_t cmd_dma_handle = h->cmd_pool_dhandle + index * sizeof(*c);
+ 
+ 	memset(c->Request.CDB, 0, sizeof(c->Request.CDB));
+ 	memset(c->err_info, 0, sizeof(*c->err_info));
+ 	c->busaddr = (u32) cmd_dma_handle;
+ }
+ 
+ static void hpsa_command_resubmit_worker(struct work_struct *work)
+ {
+ 	struct scsi_cmnd *cmd;
+ 	struct hpsa_scsi_dev_t *dev;
+ 	struct CommandList *c =
+ 			container_of(work, struct CommandList, work);
+ 
+ 	cmd = c->scsi_cmd;
+ 	dev = cmd->device->hostdata;
+ 	if (!dev) {
+ 		cmd->result = DID_NO_CONNECT << 16;
+ 		cmd->scsi_done(cmd);
+ 		return;
+ 	}
+ 	hpsa_cmd_partial_init(c->h, c->cmdindex, c);
+ 	if (hpsa_ciss_submit(c->h, c, cmd, dev->scsi3addr)) {
+ 		/*
+ 		 * If we get here, it means dma mapping failed. Try
+ 		 * again via scsi mid layer, which will then get
+ 		 * SCSI_MLQUEUE_HOST_BUSY.
+ 		 */
+ 		cmd->result = DID_IMM_RETRY << 16;
+ 		cmd->scsi_done(cmd);
+ 	}
+ }
+ 
+ /* Running in struct Scsi_Host->host_lock less mode */
+ static int hpsa_scsi_queue_command(struct Scsi_Host *sh, struct scsi_cmnd *cmd)
+ {
+ 	struct ctlr_info *h;
+ 	struct hpsa_scsi_dev_t *dev;
+ 	unsigned char scsi3addr[8];
+ 	struct CommandList *c;
+ 	int rc = 0;
+ 
+ 	/* Get the ptr to our adapter structure out of cmd->host. */
+ 	h = sdev_to_hba(cmd->device);
+ 	dev = cmd->device->hostdata;
+ 	if (!dev) {
+ 		cmd->result = DID_NO_CONNECT << 16;
+ 		cmd->scsi_done(cmd);
+ 		return 0;
+ 	}
+ 	memcpy(scsi3addr, dev->scsi3addr, sizeof(scsi3addr));
+ 
+ 	if (unlikely(lockup_detected(h))) {
+ 		cmd->result = DID_NO_CONNECT << 16;
+ 		cmd->scsi_done(cmd);
+ 		return 0;
+ 	}
+ 	c = cmd_alloc(h);
+ 	if (c == NULL) {			/* trouble... */
+ 		dev_err(&h->pdev->dev, "cmd_alloc returned NULL!\n");
+ 		return SCSI_MLQUEUE_HOST_BUSY;
+ 	}
+ 	if (unlikely(lockup_detected(h))) {
+ 		cmd->result = DID_NO_CONNECT << 16;
+ 		cmd_free(h, c);
+ 		cmd->scsi_done(cmd);
+ 		return 0;
+ 	}
+ 
+ 	/*
+ 	 * Call alternate submit routine for I/O accelerated commands.
+ 	 * Retries always go down the normal I/O path.
+ 	 */
+ 	if (likely(cmd->retries == 0 &&
+ 		cmd->request->cmd_type == REQ_TYPE_FS &&
+ 		h->acciopath_status)) {
+ 
+ 		cmd->host_scribble = (unsigned char *) c;
+ 
+ 		if (dev->offload_enabled) {
+ 			hpsa_cmd_init(h, c->cmdindex, c);
+ 			c->cmd_type = CMD_SCSI;
+ 			c->scsi_cmd = cmd;
+ 			rc = hpsa_scsi_ioaccel_raid_map(h, c);
+ 			if (rc == 0)
+ 				return 0; /* Sent on ioaccel path */
+ 			if (rc < 0) {   /* scsi_dma_map failed. */
+ 				cmd_free(h, c);
+ 				return SCSI_MLQUEUE_HOST_BUSY;
+ 			}
+ 		} else if (dev->ioaccel_handle) {
+ 			hpsa_cmd_init(h, c->cmdindex, c);
+ 			c->cmd_type = CMD_SCSI;
+ 			c->scsi_cmd = cmd;
+ 			rc = hpsa_scsi_ioaccel_direct_map(h, c);
+ 			if (rc == 0)
+ 				return 0; /* Sent on direct map path */
+ 			if (rc < 0) {   /* scsi_dma_map failed. */
+ 				cmd_free(h, c);
+ 				return SCSI_MLQUEUE_HOST_BUSY;
+ 			}
+ 		}
+ 	}
+ 	return hpsa_ciss_submit(h, c, cmd, scsi3addr);
+ }
+ 
+ static void hpsa_scan_complete(struct ctlr_info *h)
++>>>>>>> 360c73bdde45 (hpsa: factor out hpsa_init_cmd function)
  {
  	unsigned long flags;
  
@@@ -4483,12 -5058,12 +4627,17 @@@ static int hpsa_eh_abort_handler(struc
  static struct CommandList *cmd_alloc(struct ctlr_info *h)
  {
  	struct CommandList *c;
++<<<<<<< HEAD
 +	int i;
 +	union u64bit temp64;
 +	dma_addr_t cmd_dma_handle, err_dma_handle;
 +	int loopcount;
++=======
+ 	int refcount, i;
+ 	unsigned long offset;
++>>>>>>> 360c73bdde45 (hpsa: factor out hpsa_init_cmd function)
  
 -	/*
 -	 * There is some *extremely* small but non-zero chance that that
 +	/* There is some *extremely* small but non-zero chance that that
  	 * multiple threads could get in here, and one thread could
  	 * be scanning through the list of bits looking for a free
  	 * one, but the free ones are always behind him, and other
@@@ -4499,73 -5074,26 +4648,96 @@@
  	 * infrequently as to be indistinguishable from never.
  	 */
  
++<<<<<<< HEAD
 +	loopcount = 0;
 +	do {
 +		i = find_first_zero_bit(h->cmd_pool_bits, h->nr_cmds);
 +		if (i == h->nr_cmds)
 +			i = 0;
 +		loopcount++;
 +	} while (test_and_set_bit(i & (BITS_PER_LONG - 1),
 +		  h->cmd_pool_bits + (i / BITS_PER_LONG)) != 0 &&
 +		loopcount < 10);
 +
 +	/* Thread got starved?  We do not expect this to ever happen. */
 +	if (loopcount >= 10)
 +		return NULL;
 +
 +	c = h->cmd_pool + i;
 +	memset(c, 0, sizeof(*c));
 +	c->Header.tag = cpu_to_le64((u64) i << DIRECT_LOOKUP_SHIFT);
 +	cmd_dma_handle = h->cmd_pool_dhandle + i * sizeof(*c);
 +	c->err_info = h->errinfo_pool + i;
 +	memset(c->err_info, 0, sizeof(*c->err_info));
 +	err_dma_handle = h->errinfo_pool_dhandle
 +	    + i * sizeof(*c->err_info);
 +
 +	c->cmdindex = i;
 +
 +	c->busaddr = (u32) cmd_dma_handle;
 +	temp64.val = (u64) err_dma_handle;
 +	c->ErrDesc.Addr = cpu_to_le64(err_dma_handle);
 +	c->ErrDesc.Len = cpu_to_le32(sizeof(*c->err_info));
 +
 +	c->h = h;
 +	return c;
 +}
 +
 +/* For operations that can wait for kmalloc to possibly sleep,
 + * this routine can be called. Lock need not be held to call
 + * cmd_special_alloc. cmd_special_free() is the complement.
 + */
 +static struct CommandList *cmd_special_alloc(struct ctlr_info *h)
 +{
 +	struct CommandList *c;
 +	dma_addr_t cmd_dma_handle, err_dma_handle;
 +
 +	c = pci_alloc_consistent(h->pdev, sizeof(*c), &cmd_dma_handle);
 +	if (c == NULL)
 +		return NULL;
 +	memset(c, 0, sizeof(*c));
 +
 +	c->cmd_type = CMD_SCSI;
 +	c->cmdindex = -1;
 +
 +	c->err_info = pci_alloc_consistent(h->pdev, sizeof(*c->err_info),
 +		    &err_dma_handle);
 +
 +	if (c->err_info == NULL) {
 +		pci_free_consistent(h->pdev,
 +			sizeof(*c), c, cmd_dma_handle);
 +		return NULL;
 +	}
 +	memset(c->err_info, 0, sizeof(*c->err_info));
 +
 +	INIT_LIST_HEAD(&c->list);
 +	c->busaddr = (u32) cmd_dma_handle;
 +	c->ErrDesc.Addr = cpu_to_le64(err_dma_handle);
 +	c->ErrDesc.Len = cpu_to_le32(sizeof(*c->err_info));
 +
 +	c->h = h;
++=======
+ 	offset = h->last_allocation; /* benignly racy */
+ 	for (;;) {
+ 		i = find_next_zero_bit(h->cmd_pool_bits, h->nr_cmds, offset);
+ 		if (unlikely(i == h->nr_cmds)) {
+ 			offset = 0;
+ 			continue;
+ 		}
+ 		c = h->cmd_pool + i;
+ 		refcount = atomic_inc_return(&c->refcount);
+ 		if (unlikely(refcount > 1)) {
+ 			cmd_free(h, c); /* already in use */
+ 			offset = (i + 1) % h->nr_cmds;
+ 			continue;
+ 		}
+ 		set_bit(i & (BITS_PER_LONG - 1),
+ 			h->cmd_pool_bits + (i / BITS_PER_LONG));
+ 		break; /* it's ours now. */
+ 	}
+ 	h->last_allocation = i; /* benignly racy */
+ 	hpsa_cmd_partial_init(h, i, c);
++>>>>>>> 360c73bdde45 (hpsa: factor out hpsa_init_cmd function)
  	return c;
  }
  
diff --cc drivers/scsi/hpsa_cmd.h
index d78e66629650,0efb6f2b4297..000000000000
--- a/drivers/scsi/hpsa_cmd.h
+++ b/drivers/scsi/hpsa_cmd.h
@@@ -403,7 -425,20 +403,24 @@@ struct CommandList 
  	int			   cmd_type;
  	long			   cmdindex;
  	struct completion *waiting;
++<<<<<<< HEAD
 +	void   *scsi_cmd;
++=======
+ 	struct scsi_cmnd *scsi_cmd;
+ 	struct work_struct work;
+ 
+ 	/*
+ 	 * For commands using either of the two "ioaccel" paths to
+ 	 * bypass the RAID stack and go directly to the physical disk
+ 	 * phys_disk is a pointer to the hpsa_scsi_dev_t to which the
+ 	 * i/o is destined.  We need to store that here because the command
+ 	 * may potentially encounter TASK SET FULL and need to be resubmitted
+ 	 * For "normal" i/o's not using the "ioaccel" paths, phys_disk is
+ 	 * not used.
+ 	 */
+ 	struct hpsa_scsi_dev_t *phys_disk;
+ 	atomic_t refcount; /* Must be last to avoid memset in hpsa_cmd_init() */
++>>>>>>> 360c73bdde45 (hpsa: factor out hpsa_init_cmd function)
  } __aligned(COMMANDLIST_ALIGNMENT);
  
  /* Max S/G elements in I/O accelerator command */
* Unmerged path drivers/scsi/hpsa.c
* Unmerged path drivers/scsi/hpsa_cmd.h
