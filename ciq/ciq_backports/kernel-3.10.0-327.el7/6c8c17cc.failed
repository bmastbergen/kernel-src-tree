crypto: x86/sha1 - fix stack alignment of AVX2 variant

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [crypto] x86: sha1 - fix stack alignment of AVX2 variant (Herbert Xu) [1177968]
Rebuild_FUZZ: 89.11%
commit-author Mathias Krause <minipli@googlemail.com>
commit 6c8c17cc7a8806dde074d7c0bf4d519dd4d028c5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/6c8c17cc.failed

The AVX2 implementation might waste up to a page of stack memory because
of a wrong alignment calculation. This will, in the worst case, increase
the stack usage of sha1_transform_avx2() alone to 5.4 kB -- way to big
for a kernel function. Even worse, it might also allocate *less* bytes
than needed if the stack pointer is already aligned bacause in that case
the 'sub %rbx, %rsp' is effectively moving the stack pointer upwards,
not downwards.

Fix those issues by changing and simplifying the alignment calculation
to use a 32 byte alignment, the alignment really needed.

	Cc: Chandramouli Narayanan <mouli@linux.intel.com>
	Signed-off-by: Mathias Krause <minipli@googlemail.com>
	Reviewed-by: H. Peter Anvin <hpa@linux.intel.com>
	Reviewed-by: Marek Vasut <marex@denx.de>
	Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
(cherry picked from commit 6c8c17cc7a8806dde074d7c0bf4d519dd4d028c5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/crypto/sha1_avx2_x86_64_asm.S
* Unmerged path arch/x86/crypto/sha1_avx2_x86_64_asm.S
* Unmerged path arch/x86/crypto/sha1_avx2_x86_64_asm.S
