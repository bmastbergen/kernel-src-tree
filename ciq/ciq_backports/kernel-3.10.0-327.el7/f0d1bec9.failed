new helper: copy_page_from_iter()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Al Viro <viro@zeniv.linux.org.uk>
commit f0d1bec9d58d4c038d0ac958c9af82be6eb18045
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/f0d1bec9.failed

parallel to copy_page_to_iter().  pipe_write() switched to it (and became
->write_iter()).

	Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
(cherry picked from commit f0d1bec9d58d4c038d0ac958c9af82be6eb18045)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/pipe.c
#	include/linux/uio.h
#	mm/iov_iter.c
diff --cc fs/pipe.c
index 78fd0d0788db,21981e58e2a6..000000000000
--- a/fs/pipe.c
+++ b/fs/pipe.c
@@@ -116,99 -116,6 +116,102 @@@ void pipe_wait(struct pipe_inode_info *
  	pipe_lock(pipe);
  }
  
++<<<<<<< HEAD
 +static int
 +pipe_iov_copy_from_user(void *to, struct iovec *iov, unsigned long len,
 +			int atomic)
 +{
 +	unsigned long copy;
 +
 +	while (len > 0) {
 +		while (!iov->iov_len)
 +			iov++;
 +		copy = min_t(unsigned long, len, iov->iov_len);
 +
 +		if (atomic) {
 +			if (__copy_from_user_inatomic(to, iov->iov_base, copy))
 +				return -EFAULT;
 +		} else {
 +			if (copy_from_user(to, iov->iov_base, copy))
 +				return -EFAULT;
 +		}
 +		to += copy;
 +		len -= copy;
 +		iov->iov_base += copy;
 +		iov->iov_len -= copy;
 +	}
 +	return 0;
 +}
 +
 +static int
 +pipe_iov_copy_to_user(struct iovec *iov, const void *from, unsigned long len,
 +		      int atomic)
 +{
 +	unsigned long copy;
 +
 +	while (len > 0) {
 +		while (!iov->iov_len)
 +			iov++;
 +		copy = min_t(unsigned long, len, iov->iov_len);
 +
 +		if (atomic) {
 +			if (__copy_to_user_inatomic(iov->iov_base, from, copy))
 +				return -EFAULT;
 +		} else {
 +			if (copy_to_user(iov->iov_base, from, copy))
 +				return -EFAULT;
 +		}
 +		from += copy;
 +		len -= copy;
 +		iov->iov_base += copy;
 +		iov->iov_len -= copy;
 +	}
 +	return 0;
 +}
 +
 +/*
 + * Attempt to pre-fault in the user memory, so we can use atomic copies.
 + * Returns the number of bytes not faulted in.
 + */
 +static int iov_fault_in_pages_write(struct iovec *iov, unsigned long len)
 +{
 +	while (!iov->iov_len)
 +		iov++;
 +
 +	while (len > 0) {
 +		unsigned long this_len;
 +
 +		this_len = min_t(unsigned long, len, iov->iov_len);
 +		if (fault_in_pages_writeable(iov->iov_base, this_len))
 +			break;
 +
 +		len -= this_len;
 +		iov++;
 +	}
 +
 +	return len;
 +}
 +
 +/*
 + * Pre-fault in the user memory, so we can use atomic copies.
 + */
 +static void iov_fault_in_pages_read(struct iovec *iov, unsigned long len)
 +{
 +	while (!iov->iov_len)
 +		iov++;
 +
 +	while (len > 0) {
 +		unsigned long this_len;
 +
 +		this_len = min_t(unsigned long, len, iov->iov_len);
 +		fault_in_pages_readable(iov->iov_base, this_len);
 +		len -= this_len;
 +		iov++;
 +	}
 +}
 +
++=======
++>>>>>>> f0d1bec9d58d (new helper: copy_page_from_iter())
  static void anon_pipe_buf_release(struct pipe_inode_info *pipe,
  				  struct pipe_buffer *buf)
  {
@@@ -536,25 -371,15 +531,31 @@@ pipe_write(struct kiocb *iocb, struct i
  			if (error)
  				goto out;
  
++<<<<<<< HEAD
 +			iov_fault_in_pages_read(iov, chars);
 +redo1:
 +			addr = ops->map(pipe, buf, atomic);
 +			error = pipe_iov_copy_from_user(offset + addr, iov,
 +							chars, atomic);
 +			ops->unmap(pipe, buf, addr);
 +			ret = error;
 +			do_wakeup = 1;
 +			if (error) {
 +				if (atomic) {
 +					atomic = 0;
 +					goto redo1;
 +				}
++=======
+ 			ret = copy_page_from_iter(buf->page, offset, chars, from);
+ 			if (unlikely(ret < chars)) {
+ 				error = -EFAULT;
++>>>>>>> f0d1bec9d58d (new helper: copy_page_from_iter())
  				goto out;
  			}
+ 			do_wakeup = 1;
  			buf->len += chars;
- 			total_len -= chars;
  			ret = chars;
- 			if (!total_len)
+ 			if (!iov_iter_count(from))
  				goto out;
  		}
  	}
@@@ -1145,10 -947,10 +1123,17 @@@ err
  const struct file_operations pipefifo_fops = {
  	.open		= fifo_open,
  	.llseek		= no_llseek,
++<<<<<<< HEAD
 +	.read		= do_sync_read,
 +	.aio_read	= pipe_read,
 +	.write		= do_sync_write,
 +	.aio_write	= pipe_write,
++=======
+ 	.read		= new_sync_read,
+ 	.read_iter	= pipe_read,
+ 	.write		= new_sync_write,
+ 	.write_iter	= pipe_write,
++>>>>>>> f0d1bec9d58d (new helper: copy_page_from_iter())
  	.poll		= pipe_poll,
  	.unlocked_ioctl	= pipe_ioctl,
  	.release	= pipe_release,
diff --cc include/linux/uio.h
index c55ce243cc09,66012352d333..000000000000
--- a/include/linux/uio.h
+++ b/include/linux/uio.h
@@@ -34,8 -44,54 +34,40 @@@ static inline size_t iov_length(const s
  	return ret;
  }
  
 -static inline struct iovec iov_iter_iovec(const struct iov_iter *iter)
 -{
 -	return (struct iovec) {
 -		.iov_base = iter->iov->iov_base + iter->iov_offset,
 -		.iov_len = min(iter->count,
 -			       iter->iov->iov_len - iter->iov_offset),
 -	};
 -}
 -
 -#define iov_for_each(iov, iter, start)				\
 -	for (iter = (start);					\
 -	     (iter).count &&					\
 -	     ((iov = iov_iter_iovec(&(iter))), 1);		\
 -	     iov_iter_advance(&(iter), (iov).iov_len))
 -
  unsigned long iov_shorten(struct iovec *iov, unsigned long nr_segs, size_t to);
  
++<<<<<<< HEAD
++=======
+ size_t iov_iter_copy_from_user_atomic(struct page *page,
+ 		struct iov_iter *i, unsigned long offset, size_t bytes);
+ void iov_iter_advance(struct iov_iter *i, size_t bytes);
+ int iov_iter_fault_in_readable(struct iov_iter *i, size_t bytes);
+ size_t iov_iter_single_seg_count(const struct iov_iter *i);
+ size_t copy_page_to_iter(struct page *page, size_t offset, size_t bytes,
+ 			 struct iov_iter *i);
+ size_t copy_page_from_iter(struct page *page, size_t offset, size_t bytes,
+ 			 struct iov_iter *i);
+ unsigned long iov_iter_alignment(const struct iov_iter *i);
+ void iov_iter_init(struct iov_iter *i, int direction, const struct iovec *iov,
+ 			unsigned long nr_segs, size_t count);
+ ssize_t iov_iter_get_pages(struct iov_iter *i, struct page **pages,
+ 			size_t maxsize, size_t *start);
+ ssize_t iov_iter_get_pages_alloc(struct iov_iter *i, struct page ***pages,
+ 			size_t maxsize, size_t *start);
+ int iov_iter_npages(const struct iov_iter *i, int maxpages);
+ 
+ static inline size_t iov_iter_count(struct iov_iter *i)
+ {
+ 	return i->count;
+ }
+ 
+ static inline void iov_iter_truncate(struct iov_iter *i, size_t count)
+ {
+ 	if (i->count > count)
+ 		i->count = count;
+ }
+ 
++>>>>>>> f0d1bec9d58d (new helper: copy_page_from_iter())
  int memcpy_fromiovec(unsigned char *kdata, struct iovec *iov, int len);
  int memcpy_toiovec(struct iovec *iov, unsigned char *kdata, int len);
 -
 -
  #endif
* Unmerged path mm/iov_iter.c
* Unmerged path fs/pipe.c
* Unmerged path include/linux/uio.h
* Unmerged path mm/iov_iter.c
