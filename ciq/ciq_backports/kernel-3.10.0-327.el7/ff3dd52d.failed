IB/iser: Use beacon to indicate all completions were consumed

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [infiniband] iser: Use beacon to indicate all completions were consumed (Amir Vadai) [1164539]
Rebuild_FUZZ: 97.48%
commit-author Sagi Grimberg <sagig@mellanox.com>
commit ff3dd52d267165347d6f92a90016e692d074a00c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/ff3dd52d.failed

Avoid post_send counting (atomic) in the IO path just to keep track of
how many completions we need to consume.  Use a beacon post to indicate
that all prior posts completed.

	Signed-off-by: Sagi Grimberg <sagig@mellanox.com>
	Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
	Signed-off-by: Roland Dreier <roland@purestorage.com>
(cherry picked from commit ff3dd52d267165347d6f92a90016e692d074a00c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/ulp/iser/iscsi_iser.h
#	drivers/infiniband/ulp/iser/iser_verbs.c
diff --cc drivers/infiniband/ulp/iser/iscsi_iser.h
index 9f0e0e34d6ca,4fcb25604d80..000000000000
--- a/drivers/infiniband/ulp/iser/iscsi_iser.h
+++ b/drivers/infiniband/ulp/iser/iscsi_iser.h
@@@ -317,15 -330,56 +318,63 @@@ struct fast_reg_descriptor 
  	u8				  reg_indicators;
  };
  
++<<<<<<< HEAD
++=======
+ /**
+  * struct ib_conn - Infiniband related objects
+  *
+  * @cma_id:              rdma_cm connection maneger handle
+  * @qp:                  Connection Queue-pair
+  * @post_recv_buf_count: post receive counter
+  * @rx_wr:               receive work request for batch posts
+  * @device:              reference to iser device
+  * @comp:                iser completion context
+  * @pi_support:          Indicate device T10-PI support
+  * @beacon:              beacon send wr to signal all flush errors were drained
+  * @flush_comp:          completes when all connection completions consumed
+  * @lock:                protects fmr/fastreg pool
+  * @union.fmr:
+  *     @pool:            FMR pool for fast registrations
+  *     @page_vec:        page vector to hold mapped commands pages
+  *                       used for registration
+  * @union.fastreg:
+  *     @pool:            Fast registration descriptors pool for fast
+  *                       registrations
+  *     @pool_size:       Size of pool
+  */
+ struct ib_conn {
+ 	struct rdma_cm_id           *cma_id;
+ 	struct ib_qp	            *qp;
+ 	int                          post_recv_buf_count;
+ 	struct ib_recv_wr	     rx_wr[ISER_MIN_POSTED_RX];
+ 	struct iser_device          *device;
+ 	struct iser_comp	    *comp;
+ 	bool			     pi_support;
+ 	struct ib_send_wr	     beacon;
+ 	struct completion	     flush_comp;
+ 	spinlock_t		     lock;
+ 	union {
+ 		struct {
+ 			struct ib_fmr_pool      *pool;
+ 			struct iser_page_vec	*page_vec;
+ 		} fmr;
+ 		struct {
+ 			struct list_head	 pool;
+ 			int			 pool_size;
+ 		} fastreg;
+ 	};
+ };
+ 
++>>>>>>> ff3dd52d2671 (IB/iser: Use beacon to indicate all completions were consumed)
  struct iser_conn {
 -	struct ib_conn		     ib_conn;
  	struct iscsi_conn	     *iscsi_conn;
  	struct iscsi_endpoint	     *ep;
 -	enum iser_conn_state	     state;	    /* rdma connection state   */
 +	enum iser_ib_conn_state	     state;	    /* rdma connection state   */
 +	atomic_t		     refcount;
 +	spinlock_t		     lock;	    /* used for state changes  */
 +	struct iser_device           *device;       /* device context          */
 +	struct rdma_cm_id            *cma_id;       /* CMA ID		       */
 +	struct ib_qp	             *qp;           /* QP 		       */
  	unsigned		     qp_max_recv_dtos; /* num of rx buffers */
  	unsigned		     qp_max_recv_dtos_mask; /* above minus 1 */
  	unsigned		     min_posted_rx; /* qp_max_recv_dtos >> 2 */
diff --cc drivers/infiniband/ulp/iser/iser_verbs.c
index fbf2a1e0f2e2,805a9bdc9520..000000000000
--- a/drivers/infiniband/ulp/iser/iser_verbs.c
+++ b/drivers/infiniband/ulp/iser/iser_verbs.c
@@@ -39,8 -39,12 +39,17 @@@
  #include "iscsi_iser.h"
  
  #define ISCSI_ISER_MAX_CONN	8
++<<<<<<< HEAD
 +#define ISER_MAX_RX_CQ_LEN	(ISER_QP_MAX_RECV_DTOS * ISCSI_ISER_MAX_CONN)
 +#define ISER_MAX_TX_CQ_LEN	(ISER_QP_MAX_REQ_DTOS  * ISCSI_ISER_MAX_CONN)
++=======
+ #define ISER_MAX_RX_LEN		(ISER_QP_MAX_RECV_DTOS * ISCSI_ISER_MAX_CONN)
+ #define ISER_MAX_TX_LEN		(ISER_QP_MAX_REQ_DTOS  * ISCSI_ISER_MAX_CONN)
+ #define ISER_MAX_CQ_LEN		(ISER_MAX_RX_LEN + ISER_MAX_TX_LEN + \
+ 				 ISCSI_ISER_MAX_CONN)
+ 
+ static int iser_cq_poll_limit = 512;
++>>>>>>> ff3dd52d2671 (IB/iser: Use beacon to indicate all completions were consumed)
  
  static void iser_cq_tasklet_fn(unsigned long data);
  static void iser_cq_callback(struct ib_cq *cq, void *cq_context);
@@@ -477,12 -458,10 +486,19 @@@ static int iser_create_ib_conn_res(stru
  	init_attr.sq_sig_type	= IB_SIGNAL_REQ_WR;
  	init_attr.qp_type	= IB_QPT_RC;
  	if (ib_conn->pi_support) {
++<<<<<<< HEAD
 +		init_attr.cap.max_send_wr = min(ISER_QP_SIG_MAX_REQ_DTOS,
 +							dev_attr->max_qp_wr);
 +		init_attr.create_flags |= IB_QP_CREATE_SIGNATURE_EN;
 +	} else {
 +		init_attr.cap.max_send_wr  = min(ISER_QP_MAX_REQ_DTOS,
 +							dev_attr->max_qp_wr);
++=======
+ 		init_attr.cap.max_send_wr = ISER_QP_SIG_MAX_REQ_DTOS + 1;
+ 		init_attr.create_flags |= IB_QP_CREATE_SIGNATURE_EN;
+ 	} else {
+ 		init_attr.cap.max_send_wr  = ISER_QP_MAX_REQ_DTOS + 1;
++>>>>>>> ff3dd52d2671 (IB/iser: Use beacon to indicate all completions were consumed)
  	}
  
  	ret = rdma_create_qp(ib_conn->cma_id, device->pd, &init_attr);
@@@ -645,21 -630,45 +661,38 @@@ void iser_conn_release(struct iser_con
  
  /**
   * triggers start of the disconnect procedures and wait for them to be done
 - * Called with state mutex held
   */
 -int iser_conn_terminate(struct iser_conn *iser_conn)
 +void iser_conn_terminate(struct iser_conn *ib_conn)
  {
++<<<<<<< HEAD
++=======
+ 	struct ib_conn *ib_conn = &iser_conn->ib_conn;
+ 	struct ib_send_wr *bad_wr;
++>>>>>>> ff3dd52d2671 (IB/iser: Use beacon to indicate all completions were consumed)
  	int err = 0;
  
 -	/* terminate the iser conn only if the conn state is UP */
 -	if (!iser_conn_state_comp_exch(iser_conn, ISER_CONN_UP,
 -				       ISER_CONN_TERMINATING))
 -		return 0;
 -
 -	iser_info("iser_conn %p state %d\n", iser_conn, iser_conn->state);
 -
 -	/* suspend queuing of new iscsi commands */
 -	if (iser_conn->iscsi_conn)
 -		iscsi_suspend_queue(iser_conn->iscsi_conn);
 -
 -	/*
 -	 * In case we didn't already clean up the cma_id (peer initiated
 -	 * a disconnection), we need to Cause the CMA to change the QP
 -	 * state to ERROR.
 +	/* change the ib conn state only if the conn is UP, however always call
 +	 * rdma_disconnect since this is the only way to cause the CMA to change
 +	 * the QP state to ERROR
  	 */
 -	if (ib_conn->cma_id) {
 -		err = rdma_disconnect(ib_conn->cma_id);
 -		if (err)
 -			iser_err("Failed to disconnect, conn: 0x%p err %d\n",
 -				 iser_conn, err);
  
++<<<<<<< HEAD
 +	iser_conn_state_comp_exch(ib_conn, ISER_CONN_UP, ISER_CONN_TERMINATING);
 +	err = rdma_disconnect(ib_conn->cma_id);
 +	if (err)
 +		iser_err("Failed to disconnect, conn: 0x%p err %d\n",
 +			 ib_conn,err);
++=======
+ 		/* post an indication that all flush errors were consumed */
+ 		err = ib_post_send(ib_conn->qp, &ib_conn->beacon, &bad_wr);
+ 		if (err)
+ 			iser_err("conn %p failed to post beacon", ib_conn);
+ 
+ 		wait_for_completion(&ib_conn->flush_comp);
+ 	}
+ 
+ 	return 1;
++>>>>>>> ff3dd52d2671 (IB/iser: Use beacon to indicate all completions were consumed)
  }
  
  /**
@@@ -839,21 -865,22 +872,33 @@@ static int iser_cma_handler(struct rdma
  		iser_err("Unexpected RDMA CM event (%d)\n", event->event);
  		break;
  	}
 -	mutex_unlock(&iser_conn->state_mutex);
 -
 -	return ret;
 +	mutex_unlock(&ib_conn->state_mutex);
 +	return 0;
  }
  
 -void iser_conn_init(struct iser_conn *iser_conn)
 +void iser_conn_init(struct iser_conn *ib_conn)
  {
++<<<<<<< HEAD
 +	ib_conn->state = ISER_CONN_INIT;
 +	ib_conn->post_recv_buf_count = 0;
 +	atomic_set(&ib_conn->post_send_buf_count, 0);
 +	init_completion(&ib_conn->stop_completion);
 +	init_completion(&ib_conn->flush_completion);
 +	init_completion(&ib_conn->up_completion);
 +	INIT_LIST_HEAD(&ib_conn->conn_list);
 +	spin_lock_init(&ib_conn->lock);
 +	mutex_init(&ib_conn->state_mutex);
++=======
+ 	iser_conn->state = ISER_CONN_INIT;
+ 	iser_conn->ib_conn.post_recv_buf_count = 0;
+ 	init_completion(&iser_conn->ib_conn.flush_comp);
+ 	init_completion(&iser_conn->stop_completion);
+ 	init_completion(&iser_conn->ib_completion);
+ 	init_completion(&iser_conn->up_completion);
+ 	INIT_LIST_HEAD(&iser_conn->conn_list);
+ 	spin_lock_init(&iser_conn->ib_conn.lock);
+ 	mutex_init(&iser_conn->state_mutex);
++>>>>>>> ff3dd52d2671 (IB/iser: Use beacon to indicate all completions were consumed)
  }
  
   /**
@@@ -876,11 -904,14 +921,14 @@@ int iser_connect(struct iser_conn   *ib
  	/* the device is known only --after-- address resolution */
  	ib_conn->device = NULL;
  
 -	iser_conn->state = ISER_CONN_PENDING;
 +	ib_conn->state = ISER_CONN_PENDING;
  
+ 	ib_conn->beacon.wr_id = ISER_BEACON_WRID;
+ 	ib_conn->beacon.opcode = IB_WR_SEND;
+ 
  	ib_conn->cma_id = rdma_create_id(iser_cma_handler,
 -					 (void *)iser_conn,
 -					 RDMA_PS_TCP, IB_QPT_RC);
 +					     (void *)ib_conn,
 +					     RDMA_PS_TCP, IB_QPT_RC);
  	if (IS_ERR(ib_conn->cma_id)) {
  		err = PTR_ERR(ib_conn->cma_id);
  		iser_err("rdma_create_id failed: %d\n", err);
@@@ -1090,105 -1122,133 +1135,163 @@@ int iser_post_send(struct iser_conn *ib
  	return ib_ret;
  }
  
 -/**
 - * is_iser_tx_desc - Indicate if the completion wr_id
 - *     is a TX descriptor or not.
 - * @iser_conn: iser connection
 - * @wr_id: completion WR identifier
 - *
 - * Since we cannot rely on wc opcode in FLUSH errors
 - * we must work around it by checking if the wr_id address
 - * falls in the iser connection rx_descs buffer. If so
 - * it is an RX descriptor, otherwize it is a TX.
 - */
 -static inline bool
 -is_iser_tx_desc(struct iser_conn *iser_conn, void *wr_id)
 -{
 -	void *start = iser_conn->rx_descs;
 -	int len = iser_conn->num_rx_descs * sizeof(*iser_conn->rx_descs);
 -
 -	if (wr_id >= start && wr_id < start + len)
 -		return false;
 -
 -	return true;
 -}
 -
 -/**
 - * iser_handle_comp_error() - Handle error completion
 - * @ib_conn:   connection RDMA resources
 - * @wc:        work completion
 - *
 - * Notes: We may handle a FLUSH error completion and in this case
 - *        we only cleanup in case TX type was DATAOUT. For non-FLUSH
 - *        error completion we should also notify iscsi layer that
 - *        connection is failed (in case we passed bind stage).
 - */
 -static void
 -iser_handle_comp_error(struct ib_conn *ib_conn,
 -		       struct ib_wc *wc)
 +static void iser_handle_comp_error(struct iser_tx_desc *desc,
 +				struct iser_conn *ib_conn)
  {
 -	struct iser_conn *iser_conn = container_of(ib_conn, struct iser_conn,
 -						   ib_conn);
 -
 -	if (wc->status != IB_WC_WR_FLUSH_ERR)
 -		if (iser_conn->iscsi_conn)
 -			iscsi_conn_failure(iser_conn->iscsi_conn,
 +	if (desc && desc->type == ISCSI_TX_DATAOUT)
 +		kmem_cache_free(ig.desc_cache, desc);
 +
 +	if (ib_conn->post_recv_buf_count == 0 &&
 +	    atomic_read(&ib_conn->post_send_buf_count) == 0) {
 +		/**
 +		 * getting here when the state is UP means that the conn is
 +		 * being terminated asynchronously from the iSCSI layer's
 +		 * perspective. It is safe to peek at the connection state
 +		 * since iscsi_conn_failure is allowed to be called twice.
 +		 **/
 +		if (ib_conn->state == ISER_CONN_UP)
 +			iscsi_conn_failure(ib_conn->iscsi_conn,
  					   ISCSI_ERR_CONN_FAILED);
  
++<<<<<<< HEAD
 +		/* no more non completed posts to the QP, complete the
 +		 * termination process w.o worrying on disconnect event */
 +		complete(&ib_conn->flush_completion);
++=======
+ 	if (is_iser_tx_desc(iser_conn, (void *)wc->wr_id)) {
+ 		struct iser_tx_desc *desc = (struct iser_tx_desc *)wc->wr_id;
+ 
+ 		if (desc->type == ISCSI_TX_DATAOUT)
+ 			kmem_cache_free(ig.desc_cache, desc);
+ 	} else {
+ 		ib_conn->post_recv_buf_count--;
++>>>>>>> ff3dd52d2671 (IB/iser: Use beacon to indicate all completions were consumed)
  	}
  }
  
 -/**
 - * iser_handle_wc - handle a single work completion
 - * @wc: work completion
 - *
 - * Soft-IRQ context, work completion can be either
 - * SEND or RECV, and can turn out successful or
 - * with error (or flush error).
 - */
 -static void iser_handle_wc(struct ib_wc *wc)
 +static int iser_drain_tx_cq(struct iser_device  *device, int cq_index)
  {
 -	struct ib_conn *ib_conn;
 +	struct ib_cq  *cq = device->tx_cq[cq_index];
 +	struct ib_wc  wc;
  	struct iser_tx_desc *tx_desc;
++<<<<<<< HEAD
 +	struct iser_conn *ib_conn;
 +	int completed_tx = 0;
++=======
+ 	struct iser_rx_desc *rx_desc;
+ 
+ 	ib_conn = wc->qp->qp_context;
+ 	if (wc->status == IB_WC_SUCCESS) {
+ 		if (wc->opcode == IB_WC_RECV) {
+ 			rx_desc = (struct iser_rx_desc *)wc->wr_id;
+ 			iser_rcv_completion(rx_desc, wc->byte_len,
+ 					    ib_conn);
+ 		} else
+ 		if (wc->opcode == IB_WC_SEND) {
+ 			tx_desc = (struct iser_tx_desc *)wc->wr_id;
+ 			iser_snd_completion(tx_desc, ib_conn);
+ 		} else {
+ 			iser_err("Unknown wc opcode %d\n", wc->opcode);
+ 		}
+ 	} else {
+ 		if (wc->status != IB_WC_WR_FLUSH_ERR)
+ 			iser_err("wr id %llx status %d vend_err %x\n",
+ 				 wc->wr_id, wc->status, wc->vendor_err);
+ 		else
+ 			iser_dbg("flush error: wr id %llx\n", wc->wr_id);
+ 
+ 		if (wc->wr_id != ISER_FASTREG_LI_WRID &&
+ 		    wc->wr_id != ISER_BEACON_WRID)
+ 			iser_handle_comp_error(ib_conn, wc);
+ 
+ 		/* complete in case all flush errors were consumed */
+ 		if (wc->wr_id == ISER_BEACON_WRID)
+ 			complete(&ib_conn->flush_comp);
+ 	}
+ }
+ 
+ /**
+  * iser_cq_tasklet_fn - iSER completion polling loop
+  * @data: iSER completion context
+  *
+  * Soft-IRQ context, polling connection CQ until
+  * either CQ was empty or we exausted polling budget
+  */
+ static void iser_cq_tasklet_fn(unsigned long data)
+ {
+ 	struct iser_comp *comp = (struct iser_comp *)data;
+ 	struct ib_cq *cq = comp->cq;
+ 	struct ib_wc wc;
+ 	int completed = 0;
++>>>>>>> ff3dd52d2671 (IB/iser: Use beacon to indicate all completions were consumed)
  
  	while (ib_poll_cq(cq, 1, &wc) == 1) {
 -		iser_handle_wc(&wc);
 -
 -		if (++completed >= iser_cq_poll_limit)
 -			break;
 +		tx_desc	= (struct iser_tx_desc *) (unsigned long) wc.wr_id;
 +		ib_conn = wc.qp->qp_context;
 +		if (wc.status == IB_WC_SUCCESS) {
 +			if (wc.opcode == IB_WC_SEND)
 +				iser_snd_completion(tx_desc, ib_conn);
 +			else
 +				iser_err("expected opcode %d got %d\n",
 +					IB_WC_SEND, wc.opcode);
 +		} else {
 +			iser_err("tx id %llx status %d vend_err %x\n",
 +				 wc.wr_id, wc.status, wc.vendor_err);
 +			if (wc.wr_id != ISER_FASTREG_LI_WRID) {
 +				atomic_dec(&ib_conn->post_send_buf_count);
 +				iser_handle_comp_error(tx_desc, ib_conn);
 +			}
 +		}
 +		completed_tx++;
  	}
 +	return completed_tx;
 +}
 +
  
 -	/*
 -	 * It is assumed here that arming CQ only once its empty
 -	 * would not cause interrupts to be missed.
 +static void iser_cq_tasklet_fn(unsigned long data)
 +{
 +	struct iser_cq_desc *cq_desc = (struct iser_cq_desc *)data;
 +	struct iser_device  *device = cq_desc->device;
 +	int cq_index = cq_desc->cq_index;
 +	struct ib_cq	     *cq = device->rx_cq[cq_index];
 +	 struct ib_wc	     wc;
 +	 struct iser_rx_desc *desc;
 +	 unsigned long	     xfer_len;
 +	struct iser_conn *ib_conn;
 +	int completed_tx, completed_rx = 0;
 +
 +	/* First do tx drain, so in a case where we have rx flushes and a successful
 +	 * tx completion we will still go through completion error handling.
  	 */
 +	completed_tx = iser_drain_tx_cq(device, cq_index);
 +
 +	while (ib_poll_cq(cq, 1, &wc) == 1) {
 +		desc	 = (struct iser_rx_desc *) (unsigned long) wc.wr_id;
 +		BUG_ON(desc == NULL);
 +		ib_conn = wc.qp->qp_context;
 +		if (wc.status == IB_WC_SUCCESS) {
 +			if (wc.opcode == IB_WC_RECV) {
 +				xfer_len = (unsigned long)wc.byte_len;
 +				iser_rcv_completion(desc, xfer_len, ib_conn);
 +			} else
 +				iser_err("expected opcode %d got %d\n",
 +					IB_WC_RECV, wc.opcode);
 +		} else {
 +			if (wc.status != IB_WC_WR_FLUSH_ERR)
 +				iser_err("rx id %llx status %d vend_err %x\n",
 +					wc.wr_id, wc.status, wc.vendor_err);
 +			ib_conn->post_recv_buf_count--;
 +			iser_handle_comp_error(NULL, ib_conn);
 +		}
 +		completed_rx++;
 +		if (!(completed_rx & 63))
 +			completed_tx += iser_drain_tx_cq(device, cq_index);
 +	}
 +	/* #warning "it is assumed here that arming CQ only once its empty" *
 +	 * " would not cause interrupts to be missed"                       */
  	ib_req_notify_cq(cq, IB_CQ_NEXT_COMP);
  
 -	iser_dbg("got %d completions\n", completed);
 +	iser_dbg("got %d rx %d tx completions\n", completed_rx, completed_tx);
  }
  
  static void iser_cq_callback(struct ib_cq *cq, void *cq_context)
* Unmerged path drivers/infiniband/ulp/iser/iscsi_iser.h
diff --git a/drivers/infiniband/ulp/iser/iser_initiator.c b/drivers/infiniband/ulp/iser/iser_initiator.c
index 8d44a4060634..3d6bac624c13 100644
--- a/drivers/infiniband/ulp/iser/iser_initiator.c
+++ b/drivers/infiniband/ulp/iser/iser_initiator.c
@@ -343,12 +343,10 @@ static int iser_post_rx_bufs(struct iscsi_conn *conn, struct iscsi_hdr *req)
 		return 0;
 
 	/*
-	 * Check that there is one posted recv buffer (for the last login
-	 * response) and no posted send buffers left - they must have been
-	 * consumed during previous login phases.
+	 * Check that there is one posted recv buffer
+	 * (for the last login response).
 	 */
 	WARN_ON(ib_conn->post_recv_buf_count != 1);
-	WARN_ON(atomic_read(&ib_conn->post_send_buf_count) != 0);
 
 	if (session->discovery_sess) {
 		iser_info("Discovery session, re-using login RX buffer\n");
@@ -625,8 +623,6 @@ void iser_snd_completion(struct iser_tx_desc *tx_desc,
 		tx_desc = NULL;
 	}
 
-	atomic_dec(&ib_conn->post_send_buf_count);
-
 	if (tx_desc && tx_desc->type == ISCSI_TX_CONTROL) {
 		/* this arithmetic is legal by libiscsi dd_data allocation */
 		task = (void *) ((long)(void *)tx_desc -
* Unmerged path drivers/infiniband/ulp/iser/iser_verbs.c
