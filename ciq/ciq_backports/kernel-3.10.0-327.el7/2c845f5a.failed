xfs: track collapse via file offset rather than extent index

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Brian Foster <bfoster@redhat.com>
commit 2c845f5a5f238f42376b6551a7f7716952c8f509
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/2c845f5a.failed

The collapse range implementation uses a transaction per extent shift.
The progress of the overall operation is tracked via the current extent
index of the in-core extent list. This is racy because the ilock must be
dropped and reacquired for each transaction according to locking and log
reservation rules. Therefore, writeback to prior regions of the file is
possible and can change the extent count. This changes the extent to
which the current index refers and causes the collapse to fail mid
operation. To avoid this problem, the entire file is currently written
back before the collapse operation starts.

To eliminate the need to flush the entire file, use the file offset
(fsb) to track the progress of the overall extent shift operation rather
than the extent index. Modify xfs_bmap_shift_extents() to
unconditionally convert the start_fsb parameter to an extent index and
return the file offset of the extent where the shift left off, if
further extents exist. The bulk of ths function can remain based on
extent index as ilock is held by the caller. xfs_collapse_file_space()
now uses the fsb output as the starting point for the subsequent shift.

	Signed-off-by: Brian Foster <bfoster@redhat.com>
	Reviewed-by: Dave Chinner <dchinner@redhat.com>
	Signed-off-by: Dave Chinner <david@fromorbit.com>

(cherry picked from commit 2c845f5a5f238f42376b6551a7f7716952c8f509)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/libxfs/xfs_bmap.c
#	fs/xfs/libxfs/xfs_bmap.h
#	fs/xfs/xfs_bmap_util.c
diff --cc fs/xfs/libxfs/xfs_bmap.c
index b6f15ccf3239,4b3f1b92cddd..000000000000
--- a/fs/xfs/libxfs/xfs_bmap.c
+++ b/fs/xfs/libxfs/xfs_bmap.c
@@@ -5402,3 -5402,206 +5402,209 @@@ error0
  	}
  	return error;
  }
++<<<<<<< HEAD
++=======
+ 
+ /*
+  * Shift extent records to the left to cover a hole.
+  *
+  * The maximum number of extents to be shifted in a single operation is
+  * @num_exts. @start_fsb specifies the file offset to start the shift and the
+  * file offset where we've left off is returned in @next_fsb. @offset_shift_fsb
+  * is the length by which each extent is shifted. If there is no hole to shift
+  * the extents into, this will be considered invalid operation and we abort
+  * immediately.
+  */
+ int
+ xfs_bmap_shift_extents(
+ 	struct xfs_trans	*tp,
+ 	struct xfs_inode	*ip,
+ 	xfs_fileoff_t		start_fsb,
+ 	xfs_fileoff_t		offset_shift_fsb,
+ 	int			*done,
+ 	xfs_fileoff_t		*next_fsb,
+ 	xfs_fsblock_t		*firstblock,
+ 	struct xfs_bmap_free	*flist,
+ 	int			num_exts)
+ {
+ 	struct xfs_btree_cur		*cur = NULL;
+ 	struct xfs_bmbt_rec_host	*gotp;
+ 	struct xfs_bmbt_irec            got;
+ 	struct xfs_bmbt_irec		left;
+ 	struct xfs_mount		*mp = ip->i_mount;
+ 	struct xfs_ifork		*ifp;
+ 	xfs_extnum_t			nexts = 0;
+ 	xfs_extnum_t			current_ext;
+ 	xfs_fileoff_t			startoff;
+ 	int				error = 0;
+ 	int				i;
+ 	int				whichfork = XFS_DATA_FORK;
+ 	int				logflags = 0;
+ 	xfs_filblks_t			blockcount = 0;
+ 	int				total_extents;
+ 
+ 	if (unlikely(XFS_TEST_ERROR(
+ 	    (XFS_IFORK_FORMAT(ip, whichfork) != XFS_DINODE_FMT_EXTENTS &&
+ 	     XFS_IFORK_FORMAT(ip, whichfork) != XFS_DINODE_FMT_BTREE),
+ 	     mp, XFS_ERRTAG_BMAPIFORMAT, XFS_RANDOM_BMAPIFORMAT))) {
+ 		XFS_ERROR_REPORT("xfs_bmap_shift_extents",
+ 				 XFS_ERRLEVEL_LOW, mp);
+ 		return -EFSCORRUPTED;
+ 	}
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		return -EIO;
+ 
+ 	ASSERT(xfs_isilocked(ip, XFS_IOLOCK_EXCL));
+ 	ASSERT(xfs_isilocked(ip, XFS_ILOCK_EXCL));
+ 
+ 	ifp = XFS_IFORK_PTR(ip, whichfork);
+ 	if (!(ifp->if_flags & XFS_IFEXTENTS)) {
+ 		/* Read in all the extents */
+ 		error = xfs_iread_extents(tp, ip, whichfork);
+ 		if (error)
+ 			return error;
+ 	}
+ 
+ 	/*
+ 	 * Look up the extent index for the fsb where we start shifting. We can
+ 	 * henceforth iterate with current_ext as extent list changes are locked
+ 	 * out via ilock.
+ 	 *
+ 	 * gotp can be null in 2 cases: 1) if there are no extents or 2)
+ 	 * start_fsb lies in a hole beyond which there are no extents. Either
+ 	 * way, we are done.
+ 	 */
+ 	gotp = xfs_iext_bno_to_ext(ifp, start_fsb, &current_ext);
+ 	if (!gotp) {
+ 		*done = 1;
+ 		return 0;
+ 	}
+ 
+ 	if (ifp->if_flags & XFS_IFBROOT) {
+ 		cur = xfs_bmbt_init_cursor(mp, tp, ip, whichfork);
+ 		cur->bc_private.b.firstblock = *firstblock;
+ 		cur->bc_private.b.flist = flist;
+ 		cur->bc_private.b.flags = 0;
+ 	}
+ 
+ 	/*
+ 	 * There may be delalloc extents in the data fork before the range we
+ 	 * are collapsing out, so we cannot use the count of real extents here.
+ 	 * Instead we have to calculate it from the incore fork.
+ 	 */
+ 	total_extents = ifp->if_bytes / sizeof(xfs_bmbt_rec_t);
+ 	while (nexts++ < num_exts && current_ext < total_extents) {
+ 
+ 		gotp = xfs_iext_get_ext(ifp, current_ext);
+ 		xfs_bmbt_get_all(gotp, &got);
+ 		startoff = got.br_startoff - offset_shift_fsb;
+ 
+ 		/*
+ 		 * Before shifting extent into hole, make sure that the hole is
+ 		 * large enough to accommodate the shift.
+ 		 */
+ 		if (current_ext > 0) {
+ 			xfs_bmbt_get_all(xfs_iext_get_ext(ifp, current_ext - 1),
+ 					 &left);
+ 			if (startoff < left.br_startoff + left.br_blockcount)
+ 				error = -EINVAL;
+ 		} else if (offset_shift_fsb > got.br_startoff) {
+ 			/*
+ 			 * When first extent is shifted, offset_shift_fsb should
+ 			 * be less than the stating offset of the first extent.
+ 			 */
+ 			error = -EINVAL;
+ 		}
+ 		if (error)
+ 			goto del_cursor;
+ 
+ 		if (cur) {
+ 			error = xfs_bmbt_lookup_eq(cur, got.br_startoff,
+ 						   got.br_startblock,
+ 						   got.br_blockcount,
+ 						   &i);
+ 			if (error)
+ 				goto del_cursor;
+ 			XFS_WANT_CORRUPTED_GOTO(i == 1, del_cursor);
+ 		}
+ 
+ 		/* Check if we can merge 2 adjacent extents */
+ 		if (current_ext &&
+ 		    left.br_startoff + left.br_blockcount == startoff &&
+ 		    left.br_startblock + left.br_blockcount ==
+ 				got.br_startblock &&
+ 		    left.br_state == got.br_state &&
+ 		    left.br_blockcount + got.br_blockcount <= MAXEXTLEN) {
+ 			blockcount = left.br_blockcount +
+ 				got.br_blockcount;
+ 			xfs_iext_remove(ip, current_ext, 1, 0);
+ 			logflags |= XFS_ILOG_CORE;
+ 			if (cur) {
+ 				error = xfs_btree_delete(cur, &i);
+ 				if (error)
+ 					goto del_cursor;
+ 				XFS_WANT_CORRUPTED_GOTO(i == 1, del_cursor);
+ 			} else {
+ 				logflags |= XFS_ILOG_DEXT;
+ 			}
+ 			XFS_IFORK_NEXT_SET(ip, whichfork,
+ 				XFS_IFORK_NEXTENTS(ip, whichfork) - 1);
+ 			gotp = xfs_iext_get_ext(ifp, --current_ext);
+ 			xfs_bmbt_get_all(gotp, &got);
+ 
+ 			/* Make cursor point to the extent we will update */
+ 			if (cur) {
+ 				error = xfs_bmbt_lookup_eq(cur, got.br_startoff,
+ 							   got.br_startblock,
+ 							   got.br_blockcount,
+ 							   &i);
+ 				if (error)
+ 					goto del_cursor;
+ 				XFS_WANT_CORRUPTED_GOTO(i == 1, del_cursor);
+ 			}
+ 
+ 			xfs_bmbt_set_blockcount(gotp, blockcount);
+ 			got.br_blockcount = blockcount;
+ 		} else {
+ 			/* We have to update the startoff */
+ 			xfs_bmbt_set_startoff(gotp, startoff);
+ 			got.br_startoff = startoff;
+ 		}
+ 
+ 		logflags |= XFS_ILOG_CORE;
+ 		if (cur) {
+ 			error = xfs_bmbt_update(cur, got.br_startoff,
+ 						got.br_startblock,
+ 						got.br_blockcount,
+ 						got.br_state);
+ 			if (error)
+ 				goto del_cursor;
+ 		} else {
+ 			logflags |= XFS_ILOG_DEXT;
+ 		}
+ 
+ 		current_ext++;
+ 		total_extents = ifp->if_bytes / sizeof(xfs_bmbt_rec_t);
+ 	}
+ 
+ 	/* Check if we are done */
+ 	if (current_ext == total_extents)
+ 		*done = 1;
+ 	else if (next_fsb) {
+ 		gotp = xfs_iext_get_ext(ifp, current_ext);
+ 		xfs_bmbt_get_all(gotp, &got);
+ 		*next_fsb = got.br_startoff;
+ 	}
+ 
+ del_cursor:
+ 	if (cur)
+ 		xfs_btree_del_cursor(cur,
+ 			error ? XFS_BTREE_ERROR : XFS_BTREE_NOERROR);
+ 
+ 	if (logflags)
+ 		xfs_trans_log_inode(tp, ip, logflags);
+ 
+ 	return error;
+ }
++>>>>>>> 2c845f5a5f23 (xfs: track collapse via file offset rather than extent index)
diff --cc fs/xfs/libxfs/xfs_bmap.h
index 476c061aff59,44db6db86402..000000000000
--- a/fs/xfs/libxfs/xfs_bmap.h
+++ b/fs/xfs/libxfs/xfs_bmap.h
@@@ -167,5 -177,9 +167,12 @@@ int	xfs_bunmapi(struct xfs_trans *tp, s
  int	xfs_check_nostate_extents(struct xfs_ifork *ifp, xfs_extnum_t idx,
  		xfs_extnum_t num);
  uint	xfs_default_attroffset(struct xfs_inode *ip);
++<<<<<<< HEAD
++=======
+ int	xfs_bmap_shift_extents(struct xfs_trans *tp, struct xfs_inode *ip,
+ 		xfs_fileoff_t start_fsb, xfs_fileoff_t offset_shift_fsb,
+ 		int *done, xfs_fileoff_t *next_fsb, xfs_fsblock_t *firstblock,
+ 		struct xfs_bmap_free *flist, int num_exts);
++>>>>>>> 2c845f5a5f23 (xfs: track collapse via file offset rather than extent index)
  
  #endif	/* __XFS_BMAP_H__ */
diff --cc fs/xfs/xfs_bmap_util.c
index e2ea28ff57bf,1e96d778bb9e..000000000000
--- a/fs/xfs/xfs_bmap_util.c
+++ b/fs/xfs/xfs_bmap_util.c
@@@ -1436,6 -1435,120 +1436,123 @@@ out
  }
  
  /*
++<<<<<<< HEAD
++=======
+  * xfs_collapse_file_space()
+  *	This routine frees disk space and shift extent for the given file.
+  *	The first thing we do is to free data blocks in the specified range
+  *	by calling xfs_free_file_space(). It would also sync dirty data
+  *	and invalidate page cache over the region on which collapse range
+  *	is working. And Shift extent records to the left to cover a hole.
+  * RETURNS:
+  *	0 on success
+  *	errno on error
+  *
+  */
+ int
+ xfs_collapse_file_space(
+ 	struct xfs_inode	*ip,
+ 	xfs_off_t		offset,
+ 	xfs_off_t		len)
+ {
+ 	int			done = 0;
+ 	struct xfs_mount	*mp = ip->i_mount;
+ 	struct xfs_trans	*tp;
+ 	int			error;
+ 	struct xfs_bmap_free	free_list;
+ 	xfs_fsblock_t		first_block;
+ 	int			committed;
+ 	xfs_fileoff_t		start_fsb;
+ 	xfs_fileoff_t		next_fsb;
+ 	xfs_fileoff_t		shift_fsb;
+ 
+ 	ASSERT(xfs_isilocked(ip, XFS_IOLOCK_EXCL));
+ 
+ 	trace_xfs_collapse_file_space(ip);
+ 
+ 	next_fsb = XFS_B_TO_FSB(mp, offset + len);
+ 	shift_fsb = XFS_B_TO_FSB(mp, len);
+ 
+ 	/*
+ 	 * Writeback the entire file and force remove any post-eof blocks. The
+ 	 * writeback prevents changes to the extent list via concurrent
+ 	 * writeback and the eofblocks trim prevents the extent shift algorithm
+ 	 * from running into a post-eof delalloc extent.
+ 	 *
+ 	 * XXX: This is a temporary fix until the extent shift loop below is
+ 	 * converted to use offsets and lookups within the ILOCK rather than
+ 	 * carrying around the index into the extent list for the next
+ 	 * iteration.
+ 	 */
+ 	error = filemap_write_and_wait(VFS_I(ip)->i_mapping);
+ 	if (error)
+ 		return error;
+ 	if (xfs_can_free_eofblocks(ip, true)) {
+ 		error = xfs_free_eofblocks(mp, ip, false);
+ 		if (error)
+ 			return error;
+ 	}
+ 
+ 	error = xfs_free_file_space(ip, offset, len);
+ 	if (error)
+ 		return error;
+ 
+ 	while (!error && !done) {
+ 		tp = xfs_trans_alloc(mp, XFS_TRANS_DIOSTRAT);
+ 		/*
+ 		 * We would need to reserve permanent block for transaction.
+ 		 * This will come into picture when after shifting extent into
+ 		 * hole we found that adjacent extents can be merged which
+ 		 * may lead to freeing of a block during record update.
+ 		 */
+ 		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_write,
+ 				XFS_DIOSTRAT_SPACE_RES(mp, 0), 0);
+ 		if (error) {
+ 			xfs_trans_cancel(tp, 0);
+ 			break;
+ 		}
+ 
+ 		xfs_ilock(ip, XFS_ILOCK_EXCL);
+ 		error = xfs_trans_reserve_quota(tp, mp, ip->i_udquot,
+ 				ip->i_gdquot, ip->i_pdquot,
+ 				XFS_DIOSTRAT_SPACE_RES(mp, 0), 0,
+ 				XFS_QMOPT_RES_REGBLKS);
+ 		if (error)
+ 			goto out;
+ 
+ 		xfs_trans_ijoin(tp, ip, 0);
+ 
+ 		xfs_bmap_init(&free_list, &first_block);
+ 
+ 		/*
+ 		 * We are using the write transaction in which max 2 bmbt
+ 		 * updates are allowed
+ 		 */
+ 		start_fsb = next_fsb;
+ 		error = xfs_bmap_shift_extents(tp, ip, start_fsb, shift_fsb,
+ 				&done, &next_fsb, &first_block, &free_list,
+ 				XFS_BMAP_MAX_SHIFT_EXTENTS);
+ 		if (error)
+ 			goto out;
+ 
+ 		error = xfs_bmap_finish(&tp, &free_list, &committed);
+ 		if (error)
+ 			goto out;
+ 
+ 		error = xfs_trans_commit(tp, XFS_TRANS_RELEASE_LOG_RES);
+ 		xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 	}
+ 
+ 	return error;
+ 
+ out:
+ 	xfs_trans_cancel(tp, XFS_TRANS_RELEASE_LOG_RES | XFS_TRANS_ABORT);
+ 	xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 	return error;
+ }
+ 
+ /*
++>>>>>>> 2c845f5a5f23 (xfs: track collapse via file offset rather than extent index)
   * We need to check that the format of the data fork in the temporary inode is
   * valid for the target inode before doing the swap. This is not a problem with
   * attr1 because of the fixed fork offset, but attr2 has a dynamically sized
* Unmerged path fs/xfs/libxfs/xfs_bmap.c
* Unmerged path fs/xfs/libxfs/xfs_bmap.h
* Unmerged path fs/xfs/xfs_bmap_util.c
