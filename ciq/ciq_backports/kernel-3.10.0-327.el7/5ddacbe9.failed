mm: free compound page with correct order

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [mm] free compound page with correct order (Andrea Arcangeli) [1274867]
Rebuild_FUZZ: 94.87%
commit-author Yu Zhao <yuzhao@google.com>
commit 5ddacbe92b806cd5b4f8f154e8e46ac267fff55c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/5ddacbe9.failed

Compound page should be freed by put_page() or free_pages() with correct
order.  Not doing so will cause tail pages leaked.

The compound order can be obtained by compound_order() or use
HPAGE_PMD_ORDER in our case.  Some people would argue the latter is
faster but I prefer the former which is more general.

This bug was observed not just on our servers (the worst case we saw is
11G leaked on a 48G machine) but also on our workstations running Ubuntu
based distro.

  $ cat /proc/vmstat  | grep thp_zero_page_alloc
  thp_zero_page_alloc 55
  thp_zero_page_alloc_failed 0

This means there is (thp_zero_page_alloc - 1) * (2M - 4K) memory leaked.

Fixes: 97ae17497e99 ("thp: implement refcounting for huge zero page")
	Signed-off-by: Yu Zhao <yuzhao@google.com>
	Acked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
	Cc: Andrea Arcangeli <aarcange@redhat.com>
	Cc: Mel Gorman <mel@csn.ul.ie>
	Cc: David Rientjes <rientjes@google.com>
	Cc: Bob Liu <lliubbo@gmail.com>
	Cc: <stable@vger.kernel.org>	[3.8+]
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 5ddacbe92b806cd5b4f8f154e8e46ac267fff55c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/huge_memory.c
diff --cc mm/huge_memory.c
index c8c32264deab,780d12c000e9..000000000000
--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@@ -221,7 -229,11 +221,12 @@@ static int shrink_huge_zero_page(struc
  	if (atomic_cmpxchg(&huge_zero_refcount, 1, 0) == 1) {
  		struct page *zero_page = xchg(&huge_zero_page, NULL);
  		BUG_ON(zero_page == NULL);
++<<<<<<< HEAD
 +		__free_page(zero_page);
++=======
+ 		__free_pages(zero_page, compound_order(zero_page));
+ 		return HPAGE_PMD_NR;
++>>>>>>> 5ddacbe92b80 (mm: free compound page with correct order)
  	}
  
  	return 0;
* Unmerged path mm/huge_memory.c
