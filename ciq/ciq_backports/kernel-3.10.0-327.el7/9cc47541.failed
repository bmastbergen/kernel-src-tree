pnfs/blocklayout: move extent processing to blocklayout.c

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Christoph Hellwig <hch@lst.de>
commit 9cc475411779d635619c2d414da0769e3cbf796b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/9cc47541.failed

This isn't device(id) related, so move it into the main file.  Simple move
for now, the next commit will clean it up a bit.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Trond Myklebust <trond.myklebust@primarydata.com>
(cherry picked from commit 9cc475411779d635619c2d414da0769e3cbf796b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/nfs/blocklayout/blocklayout.h
#	fs/nfs/blocklayout/blocklayoutdev.c
diff --cc fs/nfs/blocklayout/blocklayout.h
index 9838fb020473,00c11eb9d765..000000000000
--- a/fs/nfs/blocklayout/blocklayout.h
+++ b/fs/nfs/blocklayout/blocklayout.h
@@@ -174,38 -113,24 +174,41 @@@ struct bl_msg_hdr 
  /* blocklayoutdev.c */
  ssize_t bl_pipe_downcall(struct file *, const char __user *, size_t);
  void bl_pipe_destroy_msg(struct rpc_pipe_msg *);
 -
 -struct nfs4_deviceid_node *bl_alloc_deviceid_node(struct nfs_server *server,
 -		struct pnfs_device *pdev, gfp_t gfp_mask);
 -void bl_free_deviceid_node(struct nfs4_deviceid_node *d);
++<<<<<<< HEAD
 +void nfs4_blkdev_put(struct block_device *bdev);
 +struct pnfs_block_dev *nfs4_blk_decode_device(struct nfs_server *server,
 +						struct pnfs_device *dev);
 +int nfs4_blk_process_layoutget(struct pnfs_layout_hdr *lo,
 +				struct nfs4_layoutget_res *lgr, gfp_t gfp_flags);
++=======
++>>>>>>> 9cc475411779 (pnfs/blocklayout: move extent processing to blocklayout.c)
  
  /* blocklayoutdm.c */
 -void bl_dm_remove(struct net *net, dev_t dev);
 -
 -/* extent_tree.c */
 -int ext_tree_insert(struct pnfs_block_layout *bl,
 -		struct pnfs_block_extent *new);
 -int ext_tree_remove(struct pnfs_block_layout *bl, bool rw, sector_t start,
 -		sector_t end);
 -int ext_tree_mark_written(struct pnfs_block_layout *bl, sector_t start,
 -		sector_t len);
 -bool ext_tree_lookup(struct pnfs_block_layout *bl, sector_t isect,
 -		struct pnfs_block_extent *ret, bool rw);
 -int ext_tree_prepare_commit(struct nfs4_layoutcommit_args *arg);
 -void ext_tree_mark_committed(struct nfs4_layoutcommit_args *arg, int status);
 +void bl_free_block_dev(struct pnfs_block_dev *bdev);
 +
 +/* extents.c */
 +struct pnfs_block_extent *
 +bl_find_get_extent(struct pnfs_block_layout *bl, sector_t isect,
 +		struct pnfs_block_extent **cow_read);
 +int bl_mark_sectors_init(struct pnfs_inval_markings *marks,
 +			     sector_t offset, sector_t length);
 +void bl_put_extent(struct pnfs_block_extent *be);
 +struct pnfs_block_extent *bl_alloc_extent(void);
 +int bl_is_sector_init(struct pnfs_inval_markings *marks, sector_t isect);
 +int encode_pnfs_block_layoutupdate(struct pnfs_block_layout *bl,
 +				   struct xdr_stream *xdr,
 +				   const struct nfs4_layoutcommit_args *arg);
 +void clean_pnfs_block_layoutupdate(struct pnfs_block_layout *bl,
 +				   const struct nfs4_layoutcommit_args *arg,
 +				   int status);
 +int bl_add_merge_extent(struct pnfs_block_layout *bl,
 +			 struct pnfs_block_extent *new);
 +int bl_mark_for_commit(struct pnfs_block_extent *be,
 +			sector_t offset, sector_t length,
 +			struct pnfs_block_short_extent *new);
 +int bl_push_one_short_extent(struct pnfs_inval_markings *marks);
 +struct pnfs_block_short_extent *
 +bl_pop_one_short_extent(struct pnfs_inval_markings *marks);
 +void bl_free_short_extents(struct pnfs_inval_markings *marks, int num_to_free);
  
  #endif /* FS_NFS_NFS4BLOCKLAYOUT_H */
diff --cc fs/nfs/blocklayout/blocklayoutdev.c
index 63f77925aa87,2b54e2940288..000000000000
--- a/fs/nfs/blocklayout/blocklayoutdev.c
+++ b/fs/nfs/blocklayout/blocklayoutdev.c
@@@ -40,29 -40,6 +40,32 @@@
  
  #define NFSDBG_FACILITY         NFSDBG_PNFS_LD
  
++<<<<<<< HEAD
 +static int decode_sector_number(__be32 **rp, sector_t *sp)
 +{
 +	uint64_t s;
 +
 +	*rp = xdr_decode_hyper(*rp, &s);
 +	if (s & 0x1ff) {
 +		printk(KERN_WARNING "NFS: %s: sector not aligned\n", __func__);
 +		return -1;
 +	}
 +	*sp = s >> SECTOR_SHIFT;
 +	return 0;
 +}
 +
 +/*
 + * Release the block device
 + */
 +void nfs4_blkdev_put(struct block_device *bdev)
 +{
 +	dprintk("%s for device %d:%d\n", __func__, MAJOR(bdev->bd_dev),
 +			MINOR(bdev->bd_dev));
 +	blkdev_put(bdev, FMODE_READ);
 +}
 +
++=======
++>>>>>>> 9cc475411779 (pnfs/blocklayout: move extent processing to blocklayout.c)
  ssize_t bl_pipe_downcall(struct file *filp, const char __user *src,
  			 size_t mlen)
  {
@@@ -180,206 -150,23 +183,209 @@@ nfs4_blk_decode_device(struct nfs_serve
  		bd->bd_disk->disk_name,
  		bd->bd_block_size);
  
 -	kfree(msg->data);
 -	return &rv->d_node;
 -
  out:
  	kfree(msg->data);
 -	return NULL;
 +	return rv;
  }
  
 -void
 -bl_free_deviceid_node(struct nfs4_deviceid_node *d)
 +/* Map deviceid returned by the server to constructed block_device */
 +static struct block_device *translate_devid(struct pnfs_layout_hdr *lo,
 +					    struct nfs4_deviceid *id)
  {
 -	struct pnfs_block_dev *dev =
 -		container_of(d, struct pnfs_block_dev, d_node);
 -	struct net *net = d->nfs_client->cl_net;
 +	struct block_device *rv = NULL;
 +	struct block_mount_id *mid;
 +	struct pnfs_block_dev *dev;
  
 -	blkdev_put(dev->d_bdev, FMODE_READ);
 -	bl_dm_remove(net, dev->d_bdev->bd_dev);
 +	dprintk("%s enter, lo=%p, id=%p\n", __func__, lo, id);
 +	mid = BLK_ID(lo);
 +	spin_lock(&mid->bm_lock);
 +	list_for_each_entry(dev, &mid->bm_devlist, bm_node) {
 +		if (memcmp(id->data, dev->bm_mdevid.data,
 +			   NFS4_DEVICEID4_SIZE) == 0) {
 +			rv = dev->bm_mdev;
 +			goto out;
 +		}
 +	}
 + out:
 +	spin_unlock(&mid->bm_lock);
 +	dprintk("%s returning %p\n", __func__, rv);
 +	return rv;
 +}
++<<<<<<< HEAD
 +
 +/* Tracks info needed to ensure extents in layout obey constraints of spec */
 +struct layout_verification {
 +	u32 mode;	/* R or RW */
 +	u64 start;	/* Expected start of next non-COW extent */
 +	u64 inval;	/* Start of INVAL coverage */
 +	u64 cowread;	/* End of COW read coverage */
 +};
  
 -	kfree(dev);
 +/* Verify the extent meets the layout requirements of the pnfs-block draft,
 + * section 2.3.1.
 + */
 +static int verify_extent(struct pnfs_block_extent *be,
 +			 struct layout_verification *lv)
 +{
 +	if (lv->mode == IOMODE_READ) {
 +		if (be->be_state == PNFS_BLOCK_READWRITE_DATA ||
 +		    be->be_state == PNFS_BLOCK_INVALID_DATA)
 +			return -EIO;
 +		if (be->be_f_offset != lv->start)
 +			return -EIO;
 +		lv->start += be->be_length;
 +		return 0;
 +	}
 +	/* lv->mode == IOMODE_RW */
 +	if (be->be_state == PNFS_BLOCK_READWRITE_DATA) {
 +		if (be->be_f_offset != lv->start)
 +			return -EIO;
 +		if (lv->cowread > lv->start)
 +			return -EIO;
 +		lv->start += be->be_length;
 +		lv->inval = lv->start;
 +		return 0;
 +	} else if (be->be_state == PNFS_BLOCK_INVALID_DATA) {
 +		if (be->be_f_offset != lv->start)
 +			return -EIO;
 +		lv->start += be->be_length;
 +		return 0;
 +	} else if (be->be_state == PNFS_BLOCK_READ_DATA) {
 +		if (be->be_f_offset > lv->start)
 +			return -EIO;
 +		if (be->be_f_offset < lv->inval)
 +			return -EIO;
 +		if (be->be_f_offset < lv->cowread)
 +			return -EIO;
 +		/* It looks like you might want to min this with lv->start,
 +		 * but you really don't.
 +		 */
 +		lv->inval = lv->inval + be->be_length;
 +		lv->cowread = be->be_f_offset + be->be_length;
 +		return 0;
 +	} else
 +		return -EIO;
 +}
 +
 +/* XDR decode pnfs_block_layout4 structure */
 +int
 +nfs4_blk_process_layoutget(struct pnfs_layout_hdr *lo,
 +			   struct nfs4_layoutget_res *lgr, gfp_t gfp_flags)
 +{
 +	struct pnfs_block_layout *bl = BLK_LO2EXT(lo);
 +	int i, status = -EIO;
 +	uint32_t count;
 +	struct pnfs_block_extent *be = NULL, *save;
 +	struct xdr_stream stream;
 +	struct xdr_buf buf;
 +	struct page *scratch;
 +	__be32 *p;
 +	struct layout_verification lv = {
 +		.mode = lgr->range.iomode,
 +		.start = lgr->range.offset >> SECTOR_SHIFT,
 +		.inval = lgr->range.offset >> SECTOR_SHIFT,
 +		.cowread = lgr->range.offset >> SECTOR_SHIFT,
 +	};
 +	LIST_HEAD(extents);
 +
 +	dprintk("---> %s\n", __func__);
 +
 +	scratch = alloc_page(gfp_flags);
 +	if (!scratch)
 +		return -ENOMEM;
 +
 +	xdr_init_decode_pages(&stream, &buf, lgr->layoutp->pages, lgr->layoutp->len);
 +	xdr_set_scratch_buffer(&stream, page_address(scratch), PAGE_SIZE);
 +
 +	p = xdr_inline_decode(&stream, 4);
 +	if (unlikely(!p))
 +		goto out_err;
 +
 +	count = be32_to_cpup(p++);
 +
 +	dprintk("%s enter, number of extents %i\n", __func__, count);
 +	p = xdr_inline_decode(&stream, (28 + NFS4_DEVICEID4_SIZE) * count);
 +	if (unlikely(!p))
 +		goto out_err;
 +
 +	/* Decode individual extents, putting them in temporary
 +	 * staging area until whole layout is decoded to make error
 +	 * recovery easier.
 +	 */
 +	for (i = 0; i < count; i++) {
 +		be = bl_alloc_extent();
 +		if (!be) {
 +			status = -ENOMEM;
 +			goto out_err;
 +		}
 +		memcpy(&be->be_devid, p, NFS4_DEVICEID4_SIZE);
 +		p += XDR_QUADLEN(NFS4_DEVICEID4_SIZE);
 +		be->be_mdev = translate_devid(lo, &be->be_devid);
 +		if (!be->be_mdev)
 +			goto out_err;
 +
 +		/* The next three values are read in as bytes,
 +		 * but stored as 512-byte sector lengths
 +		 */
 +		if (decode_sector_number(&p, &be->be_f_offset) < 0)
 +			goto out_err;
 +		if (decode_sector_number(&p, &be->be_length) < 0)
 +			goto out_err;
 +		if (decode_sector_number(&p, &be->be_v_offset) < 0)
 +			goto out_err;
 +		be->be_state = be32_to_cpup(p++);
 +		if (be->be_state == PNFS_BLOCK_INVALID_DATA)
 +			be->be_inval = &bl->bl_inval;
 +		if (verify_extent(be, &lv)) {
 +			dprintk("%s verify failed\n", __func__);
 +			goto out_err;
 +		}
 +		list_add_tail(&be->be_node, &extents);
 +	}
 +	if (lgr->range.offset + lgr->range.length !=
 +			lv.start << SECTOR_SHIFT) {
 +		dprintk("%s Final length mismatch\n", __func__);
 +		be = NULL;
 +		goto out_err;
 +	}
 +	if (lv.start < lv.cowread) {
 +		dprintk("%s Final uncovered COW extent\n", __func__);
 +		be = NULL;
 +		goto out_err;
 +	}
 +	/* Extents decoded properly, now try to merge them in to
 +	 * existing layout extents.
 +	 */
 +	spin_lock(&bl->bl_ext_lock);
 +	list_for_each_entry_safe(be, save, &extents, be_node) {
 +		list_del(&be->be_node);
 +		status = bl_add_merge_extent(bl, be);
 +		if (status) {
 +			spin_unlock(&bl->bl_ext_lock);
 +			/* This is a fairly catastrophic error, as the
 +			 * entire layout extent lists are now corrupted.
 +			 * We should have some way to distinguish this.
 +			 */
 +			be = NULL;
 +			goto out_err;
 +		}
 +	}
 +	spin_unlock(&bl->bl_ext_lock);
 +	status = 0;
 + out:
 +	__free_page(scratch);
 +	dprintk("%s returns %i\n", __func__, status);
 +	return status;
 +
 + out_err:
 +	bl_put_extent(be);
 +	while (!list_empty(&extents)) {
 +		be = list_first_entry(&extents, struct pnfs_block_extent,
 +				      be_node);
 +		list_del(&be->be_node);
 +		bl_put_extent(be);
 +	}
 +	goto out;
  }
++=======
++>>>>>>> 9cc475411779 (pnfs/blocklayout: move extent processing to blocklayout.c)
diff --git a/fs/nfs/blocklayout/blocklayout.c b/fs/nfs/blocklayout/blocklayout.c
index 5b7b41d3b0f9..92417d807cd5 100644
--- a/fs/nfs/blocklayout/blocklayout.c
+++ b/fs/nfs/blocklayout/blocklayout.c
@@ -994,6 +994,192 @@ static void bl_free_lseg(struct pnfs_layout_segment *lseg)
 	kfree(lseg);
 }
 
+/* Tracks info needed to ensure extents in layout obey constraints of spec */
+struct layout_verification {
+	u32 mode;	/* R or RW */
+	u64 start;	/* Expected start of next non-COW extent */
+	u64 inval;	/* Start of INVAL coverage */
+	u64 cowread;	/* End of COW read coverage */
+};
+
+/* Verify the extent meets the layout requirements of the pnfs-block draft,
+ * section 2.3.1.
+ */
+static int verify_extent(struct pnfs_block_extent *be,
+			 struct layout_verification *lv)
+{
+	if (lv->mode == IOMODE_READ) {
+		if (be->be_state == PNFS_BLOCK_READWRITE_DATA ||
+		    be->be_state == PNFS_BLOCK_INVALID_DATA)
+			return -EIO;
+		if (be->be_f_offset != lv->start)
+			return -EIO;
+		lv->start += be->be_length;
+		return 0;
+	}
+	/* lv->mode == IOMODE_RW */
+	if (be->be_state == PNFS_BLOCK_READWRITE_DATA) {
+		if (be->be_f_offset != lv->start)
+			return -EIO;
+		if (lv->cowread > lv->start)
+			return -EIO;
+		lv->start += be->be_length;
+		lv->inval = lv->start;
+		return 0;
+	} else if (be->be_state == PNFS_BLOCK_INVALID_DATA) {
+		if (be->be_f_offset != lv->start)
+			return -EIO;
+		lv->start += be->be_length;
+		return 0;
+	} else if (be->be_state == PNFS_BLOCK_READ_DATA) {
+		if (be->be_f_offset > lv->start)
+			return -EIO;
+		if (be->be_f_offset < lv->inval)
+			return -EIO;
+		if (be->be_f_offset < lv->cowread)
+			return -EIO;
+		/* It looks like you might want to min this with lv->start,
+		 * but you really don't.
+		 */
+		lv->inval = lv->inval + be->be_length;
+		lv->cowread = be->be_f_offset + be->be_length;
+		return 0;
+	} else
+		return -EIO;
+}
+
+static int decode_sector_number(__be32 **rp, sector_t *sp)
+{
+	uint64_t s;
+
+	*rp = xdr_decode_hyper(*rp, &s);
+	if (s & 0x1ff) {
+		printk(KERN_WARNING "NFS: %s: sector not aligned\n", __func__);
+		return -1;
+	}
+	*sp = s >> SECTOR_SHIFT;
+	return 0;
+}
+
+/* XDR decode pnfs_block_layout4 structure */
+static int
+nfs4_blk_process_layoutget(struct pnfs_layout_hdr *lo,
+			   struct nfs4_layoutget_res *lgr, gfp_t gfp_flags)
+{
+	struct pnfs_block_layout *bl = BLK_LO2EXT(lo);
+	int i, status = -EIO;
+	uint32_t count;
+	struct pnfs_block_extent *be = NULL, *save;
+	struct xdr_stream stream;
+	struct xdr_buf buf;
+	struct page *scratch;
+	__be32 *p;
+	struct layout_verification lv = {
+		.mode = lgr->range.iomode,
+		.start = lgr->range.offset >> SECTOR_SHIFT,
+		.inval = lgr->range.offset >> SECTOR_SHIFT,
+		.cowread = lgr->range.offset >> SECTOR_SHIFT,
+	};
+	LIST_HEAD(extents);
+
+	dprintk("---> %s\n", __func__);
+
+	scratch = alloc_page(gfp_flags);
+	if (!scratch)
+		return -ENOMEM;
+
+	xdr_init_decode_pages(&stream, &buf, lgr->layoutp->pages, lgr->layoutp->len);
+	xdr_set_scratch_buffer(&stream, page_address(scratch), PAGE_SIZE);
+
+	p = xdr_inline_decode(&stream, 4);
+	if (unlikely(!p))
+		goto out_err;
+
+	count = be32_to_cpup(p++);
+
+	dprintk("%s enter, number of extents %i\n", __func__, count);
+	p = xdr_inline_decode(&stream, (28 + NFS4_DEVICEID4_SIZE) * count);
+	if (unlikely(!p))
+		goto out_err;
+
+	/* Decode individual extents, putting them in temporary
+	 * staging area until whole layout is decoded to make error
+	 * recovery easier.
+	 */
+	for (i = 0; i < count; i++) {
+		struct nfs4_deviceid id;
+
+		be = kzalloc(sizeof(struct pnfs_block_extent), GFP_NOFS);
+		if (!be) {
+			status = -ENOMEM;
+			goto out_err;
+		}
+		memcpy(&id, p, NFS4_DEVICEID4_SIZE);
+		p += XDR_QUADLEN(NFS4_DEVICEID4_SIZE);
+
+		be->be_device =
+			nfs4_find_get_deviceid(NFS_SERVER(lo->plh_inode), &id,
+						lo->plh_lc_cred, gfp_flags);
+		if (!be->be_device)
+			goto out_err;
+
+		/* The next three values are read in as bytes,
+		 * but stored as 512-byte sector lengths
+		 */
+		if (decode_sector_number(&p, &be->be_f_offset) < 0)
+			goto out_err;
+		if (decode_sector_number(&p, &be->be_length) < 0)
+			goto out_err;
+		if (decode_sector_number(&p, &be->be_v_offset) < 0)
+			goto out_err;
+		be->be_state = be32_to_cpup(p++);
+		if (verify_extent(be, &lv)) {
+			dprintk("%s verify failed\n", __func__);
+			goto out_err;
+		}
+		list_add_tail(&be->be_list, &extents);
+	}
+	if (lgr->range.offset + lgr->range.length !=
+			lv.start << SECTOR_SHIFT) {
+		dprintk("%s Final length mismatch\n", __func__);
+		be = NULL;
+		goto out_err;
+	}
+	if (lv.start < lv.cowread) {
+		dprintk("%s Final uncovered COW extent\n", __func__);
+		be = NULL;
+		goto out_err;
+	}
+	/* Extents decoded properly, now try to merge them in to
+	 * existing layout extents.
+	 */
+	list_for_each_entry_safe(be, save, &extents, be_list) {
+		list_del(&be->be_list);
+
+		status = ext_tree_insert(bl, be);
+		if (status)
+			goto out_free_list;
+	}
+	status = 0;
+ out:
+	__free_page(scratch);
+	dprintk("%s returns %i\n", __func__, status);
+	return status;
+
+ out_err:
+	nfs4_put_deviceid_node(be->be_device);
+	kfree(be);
+ out_free_list:
+	while (!list_empty(&extents)) {
+		be = list_first_entry(&extents, struct pnfs_block_extent,
+				      be_list);
+		list_del(&be->be_list);
+		nfs4_put_deviceid_node(be->be_device);
+		kfree(be);
+	}
+	goto out;
+}
+
 /* We pretty much ignore lseg, and store all data layout wide, so we
  * can correctly merge.
  */
* Unmerged path fs/nfs/blocklayout/blocklayout.h
* Unmerged path fs/nfs/blocklayout/blocklayoutdev.c
