powerpc: Add a proper syscall for switching endianness

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [powerpc] Add a proper syscall for switching endianness (Gustavo Duarte) [1221073]
Rebuild_FUZZ: 90.91%
commit-author Michael Ellerman <mpe@ellerman.id.au>
commit 529d235a0e190ded1d21ccc80a73e625ebcad09b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/529d235a.failed

We currently have a "special" syscall for switching endianness. This is
syscall number 0x1ebe, which is handled explicitly in the 64-bit syscall
exception entry.

That has a few problems, firstly the syscall number is outside of the
usual range, which confuses various tools. For example strace doesn't
recognise the syscall at all.

Secondly it's handled explicitly as a special case in the syscall
exception entry, which is complicated enough without it.

As a first step toward removing the special syscall, we need to add a
regular syscall that implements the same functionality.

The logic is simple, it simply toggles the MSR_LE bit in the userspace
MSR. This is the same as the special syscall, with the caveat that the
special syscall clobbers fewer registers.

This version clobbers r9-r12, XER, CTR, and CR0-1,5-7.

	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
(cherry picked from commit 529d235a0e190ded1d21ccc80a73e625ebcad09b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/include/asm/systbl.h
#	arch/powerpc/include/asm/unistd.h
#	arch/powerpc/include/uapi/asm/unistd.h
diff --cc arch/powerpc/include/asm/systbl.h
index acbe99d714f5,f1863a138b4a..000000000000
--- a/arch/powerpc/include/asm/systbl.h
+++ b/arch/powerpc/include/asm/systbl.h
@@@ -359,3 -359,12 +359,15 @@@ COMPAT_SYS(process_vm_readv
  COMPAT_SYS(process_vm_writev)
  SYSCALL(finit_module)
  SYSCALL(ni_syscall) /* sys_kcmp */
++<<<<<<< HEAD
++=======
+ SYSCALL_SPU(sched_setattr)
+ SYSCALL_SPU(sched_getattr)
+ SYSCALL_SPU(renameat2)
+ SYSCALL_SPU(seccomp)
+ SYSCALL_SPU(getrandom)
+ SYSCALL_SPU(memfd_create)
+ SYSCALL_SPU(bpf)
+ COMPAT_SYS(execveat)
+ PPC64ONLY(switch_endian)
++>>>>>>> 529d235a0e19 (powerpc: Add a proper syscall for switching endianness)
diff --cc arch/powerpc/include/asm/unistd.h
index 3ca819f541bf,f4f8b667d75b..000000000000
--- a/arch/powerpc/include/asm/unistd.h
+++ b/arch/powerpc/include/asm/unistd.h
@@@ -12,7 -12,7 +12,11 @@@
  #include <uapi/asm/unistd.h>
  
  
++<<<<<<< HEAD
 +#define __NR_syscalls		355
++=======
+ #define __NR_syscalls		364
++>>>>>>> 529d235a0e19 (powerpc: Add a proper syscall for switching endianness)
  
  #define __NR__exit __NR_exit
  #define NR_syscalls	__NR_syscalls
diff --cc arch/powerpc/include/uapi/asm/unistd.h
index 74cb4d72d673,e4aa173dae62..000000000000
--- a/arch/powerpc/include/uapi/asm/unistd.h
+++ b/arch/powerpc/include/uapi/asm/unistd.h
@@@ -377,6 -377,14 +377,18 @@@
  #define __NR_process_vm_writev	352
  #define __NR_finit_module	353
  #define __NR_kcmp		354
++<<<<<<< HEAD
 +
++=======
+ #define __NR_sched_setattr	355
+ #define __NR_sched_getattr	356
+ #define __NR_renameat2		357
+ #define __NR_seccomp		358
+ #define __NR_getrandom		359
+ #define __NR_memfd_create	360
+ #define __NR_bpf		361
+ #define __NR_execveat		362
+ #define __NR_switch_endian	363
++>>>>>>> 529d235a0e19 (powerpc: Add a proper syscall for switching endianness)
  
  #endif /* _UAPI_ASM_POWERPC_UNISTD_H_ */
* Unmerged path arch/powerpc/include/asm/systbl.h
* Unmerged path arch/powerpc/include/asm/unistd.h
* Unmerged path arch/powerpc/include/uapi/asm/unistd.h
diff --git a/arch/powerpc/kernel/entry_64.S b/arch/powerpc/kernel/entry_64.S
index 5ed698a00d56..076d37fdeb76 100644
--- a/arch/powerpc/kernel/entry_64.S
+++ b/arch/powerpc/kernel/entry_64.S
@@ -356,6 +356,11 @@ _GLOBAL(ppc64_swapcontext)
 	bl	sys_swapcontext
 	b	.Lsyscall_exit
 
+_GLOBAL(ppc_switch_endian)
+	bl	save_nvgprs
+	bl	sys_switch_endian
+	b	.Lsyscall_exit
+
 _GLOBAL(ret_from_fork)
 	bl	schedule_tail
 	REST_NVGPRS(r1)
diff --git a/arch/powerpc/kernel/syscalls.c b/arch/powerpc/kernel/syscalls.c
index b2702e87db0d..5fa92706444b 100644
--- a/arch/powerpc/kernel/syscalls.c
+++ b/arch/powerpc/kernel/syscalls.c
@@ -121,3 +121,20 @@ long ppc_fadvise64_64(int fd, int advice, u32 offset_high, u32 offset_low,
 	return sys_fadvise64(fd, (u64)offset_high << 32 | offset_low,
 			     (u64)len_high << 32 | len_low, advice);
 }
+
+long sys_switch_endian(void)
+{
+	struct thread_info *ti;
+
+	current->thread.regs->msr ^= MSR_LE;
+
+	/*
+	 * Set TIF_RESTOREALL so that r3 isn't clobbered on return to
+	 * userspace. That also has the effect of restoring the non-volatile
+	 * GPRs, so we saved them on the way in here.
+	 */
+	ti = current_thread_info();
+	ti->flags |= _TIF_RESTOREALL;
+
+	return 0;
+}
diff --git a/arch/powerpc/kernel/systbl.S b/arch/powerpc/kernel/systbl.S
index 895c50ca943c..7500486b0d22 100644
--- a/arch/powerpc/kernel/systbl.S
+++ b/arch/powerpc/kernel/systbl.S
@@ -22,6 +22,7 @@
 #define PPC_SYS(func)		.llong	DOTSYM(ppc_##func),DOTSYM(ppc_##func)
 #define OLDSYS(func)		.llong	DOTSYM(sys_ni_syscall),DOTSYM(sys_ni_syscall)
 #define SYS32ONLY(func)		.llong	DOTSYM(sys_ni_syscall),DOTSYM(compat_sys_##func)
+#define PPC64ONLY(func)		.llong	DOTSYM(ppc_##func),DOTSYM(sys_ni_syscall)
 #define SYSX(f, f3264, f32)	.llong	DOTSYM(f),DOTSYM(f3264)
 #else
 #define SYSCALL(func)		.long	sys_##func
@@ -29,6 +30,7 @@
 #define PPC_SYS(func)		.long	ppc_##func
 #define OLDSYS(func)		.long	sys_##func
 #define SYS32ONLY(func)		.long	sys_##func
+#define PPC64ONLY(func)		.long	sys_ni_syscall
 #define SYSX(f, f3264, f32)	.long	f32
 #endif
 #define SYSCALL_SPU(func)	SYSCALL(func)
diff --git a/arch/powerpc/kernel/systbl_chk.c b/arch/powerpc/kernel/systbl_chk.c
index 238aa63ced8f..2384129f5893 100644
--- a/arch/powerpc/kernel/systbl_chk.c
+++ b/arch/powerpc/kernel/systbl_chk.c
@@ -21,9 +21,11 @@
 #ifdef CONFIG_PPC64
 #define OLDSYS(func)		-1
 #define SYS32ONLY(func)		-1
+#define PPC64ONLY(func)		__NR_##func
 #else
 #define OLDSYS(func)		__NR_old##func
 #define SYS32ONLY(func)		__NR_##func
+#define PPC64ONLY(func)		-1
 #endif
 #define SYSX(f, f3264, f32)	-1
 
diff --git a/arch/powerpc/platforms/cell/spu_callbacks.c b/arch/powerpc/platforms/cell/spu_callbacks.c
index b0ec78e8ad68..a494028b2cdf 100644
--- a/arch/powerpc/platforms/cell/spu_callbacks.c
+++ b/arch/powerpc/platforms/cell/spu_callbacks.c
@@ -39,6 +39,7 @@ static void *spu_syscall_table[] = {
 #define PPC_SYS(func)		sys_ni_syscall,
 #define OLDSYS(func)		sys_ni_syscall,
 #define SYS32ONLY(func)		sys_ni_syscall,
+#define PPC64ONLY(func)		sys_ni_syscall,
 #define SYSX(f, f3264, f32)	sys_ni_syscall,
 
 #define SYSCALL_SPU(func)	sys_##func,
