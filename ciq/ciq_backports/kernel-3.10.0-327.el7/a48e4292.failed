net: introduce new macro net_get_random_once

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [net] introduce new macro net_get_random_once (Ivan Vecera) [1200759]
Rebuild_FUZZ: 93.98%
commit-author Hannes Frederic Sowa <hannes@stressinduktion.org>
commit a48e42920ff38bc90bbf75143fff4555723d4540
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/a48e4292.failed

net_get_random_once is a new macro which handles the initialization
of secret keys. It is possible to call it in the fast path. Only the
initialization depends on the spinlock and is rather slow. Otherwise
it should get used just before the key is used to delay the entropy
extration as late as possible to get better randomness. It returns true
if the key got initialized.

The usage of static_keys for net_get_random_once is a bit uncommon so
it needs some further explanation why this actually works:

=== In the simple non-HAVE_JUMP_LABEL case we actually have ===
no constrains to use static_key_(true|false) on keys initialized with
STATIC_KEY_INIT_(FALSE|TRUE). So this path just expands in favor of
the likely case that the initialization is already done. The key is
initialized like this:

___done_key = { .enabled = ATOMIC_INIT(0) }

The check

                if (!static_key_true(&___done_key))                     \

expands into (pseudo code)

                if (!likely(___done_key > 0))

, so we take the fast path as soon as ___done_key is increased from the
helper function.

=== If HAVE_JUMP_LABELs are available this depends ===
on patching of jumps into the prepared NOPs, which is done in
jump_label_init at boot-up time (from start_kernel). It is forbidden
and dangerous to use net_get_random_once in functions which are called
before that!

At compilation time NOPs are generated at the call sites of
net_get_random_once. E.g. net/ipv6/inet6_hashtable.c:inet6_ehashfn (we
need to call net_get_random_once two times in inet6_ehashfn, so two NOPs):

      71:       0f 1f 44 00 00          nopl   0x0(%rax,%rax,1)
      76:       0f 1f 44 00 00          nopl   0x0(%rax,%rax,1)

Both will be patched to the actual jumps to the end of the function to
call __net_get_random_once at boot time as explained above.

arch_static_branch is optimized and inlined for false as return value and
actually also returns false in case the NOP is placed in the instruction
stream. So in the fast case we get a "return false". But because we
initialize ___done_key with (enabled != (entries & 1)) this call-site
will get patched up at boot thus returning true. The final check looks
like this:

                if (!static_key_true(&___done_key))                     \
                        ___ret = __net_get_random_once(buf,             \

expands to

                if (!!static_key_false(&___done_key))                     \
                        ___ret = __net_get_random_once(buf,             \

So we get true at boot time and as soon as static_key_slow_inc is called
on the key it will invert the logic and return false for the fast path.
static_key_slow_inc will change the branch because it got initialized
with .enabled == 0. After static_key_slow_inc is called on the key the
branch is replaced with a nop again.

=== Misc: ===
The helper defers the increment into a workqueue so we don't
have problems calling this code from atomic sections. A seperate boolean
(___done) guards the case where we enter net_get_random_once again before
the increment happend.

	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: Steven Rostedt <rostedt@goodmis.org>
	Cc: Jason Baron <jbaron@redhat.com>
	Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
	Cc: Eric Dumazet <edumazet@google.com>
	Cc: "David S. Miller" <davem@davemloft.net>
	Signed-off-by: Hannes Frederic Sowa <hannes@stressinduktion.org>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit a48e42920ff38bc90bbf75143fff4555723d4540)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/net.h
#	net/core/utils.c
diff --cc include/linux/net.h
index d3d63a49a105,a489705f6fa3..000000000000
--- a/include/linux/net.h
+++ b/include/linux/net.h
@@@ -254,32 -239,53 +254,64 @@@ do {								
  #define net_random()		prandom_u32()
  #define net_srandom(seed)	prandom_seed((__force u32)(seed))
  
++<<<<<<< HEAD
 +extern int   	     kernel_sendmsg(struct socket *sock, struct msghdr *msg,
 +				    struct kvec *vec, size_t num, size_t len);
 +extern int   	     kernel_recvmsg(struct socket *sock, struct msghdr *msg,
 +				    struct kvec *vec, size_t num,
 +				    size_t len, int flags);
++=======
+ bool __net_get_random_once(void *buf, int nbytes, bool *done,
+ 			   struct static_key *done_key);
+ 
+ #ifdef HAVE_JUMP_LABEL
+ #define ___NET_RANDOM_STATIC_KEY_INIT ((struct static_key) \
+ 		{ .enabled = ATOMIC_INIT(0), .entries = (void *)1 })
+ #else /* !HAVE_JUMP_LABEL */
+ #define ___NET_RANDOM_STATIC_KEY_INIT STATIC_KEY_INIT_FALSE
+ #endif /* HAVE_JUMP_LABEL */
+ 
+ /* BE CAREFUL: this function is not interrupt safe */
+ #define net_get_random_once(buf, nbytes)				\
+ 	({								\
+ 		bool ___ret = false;					\
+ 		static bool ___done = false;				\
+ 		static struct static_key ___done_key =			\
+ 			___NET_RANDOM_STATIC_KEY_INIT;			\
+ 		if (!static_key_true(&___done_key))			\
+ 			___ret = __net_get_random_once(buf,		\
+ 						       nbytes,		\
+ 						       &___done,	\
+ 						       &___done_key);	\
+ 		___ret;							\
+ 	})
+ 
+ int kernel_sendmsg(struct socket *sock, struct msghdr *msg, struct kvec *vec,
+ 		   size_t num, size_t len);
+ int kernel_recvmsg(struct socket *sock, struct msghdr *msg, struct kvec *vec,
+ 		   size_t num, size_t len, int flags);
 -
 -int kernel_bind(struct socket *sock, struct sockaddr *addr, int addrlen);
 -int kernel_listen(struct socket *sock, int backlog);
 -int kernel_accept(struct socket *sock, struct socket **newsock, int flags);
 -int kernel_connect(struct socket *sock, struct sockaddr *addr, int addrlen,
 -		   int flags);
 -int kernel_getsockname(struct socket *sock, struct sockaddr *addr,
 -		       int *addrlen);
 -int kernel_getpeername(struct socket *sock, struct sockaddr *addr,
 -		       int *addrlen);
 -int kernel_getsockopt(struct socket *sock, int level, int optname, char *optval,
 -		      int *optlen);
 -int kernel_setsockopt(struct socket *sock, int level, int optname, char *optval,
 -		      unsigned int optlen);
 -int kernel_sendpage(struct socket *sock, struct page *page, int offset,
 -		    size_t size, int flags);
 -int kernel_sock_ioctl(struct socket *sock, int cmd, unsigned long arg);
 -int kernel_sock_shutdown(struct socket *sock, enum sock_shutdown_cmd how);
++>>>>>>> a48e42920ff3 (net: introduce new macro net_get_random_once)
 +
 +extern int kernel_bind(struct socket *sock, struct sockaddr *addr,
 +		       int addrlen);
 +extern int kernel_listen(struct socket *sock, int backlog);
 +extern int kernel_accept(struct socket *sock, struct socket **newsock,
 +			 int flags);
 +extern int kernel_connect(struct socket *sock, struct sockaddr *addr,
 +			  int addrlen, int flags);
 +extern int kernel_getsockname(struct socket *sock, struct sockaddr *addr,
 +			      int *addrlen);
 +extern int kernel_getpeername(struct socket *sock, struct sockaddr *addr,
 +			      int *addrlen);
 +extern int kernel_getsockopt(struct socket *sock, int level, int optname,
 +			     char *optval, int *optlen);
 +extern int kernel_setsockopt(struct socket *sock, int level, int optname,
 +			     char *optval, unsigned int optlen);
 +extern int kernel_sendpage(struct socket *sock, struct page *page, int offset,
 +			   size_t size, int flags);
 +extern int kernel_sock_ioctl(struct socket *sock, int cmd, unsigned long arg);
 +extern int kernel_sock_shutdown(struct socket *sock,
 +				enum sock_shutdown_cmd how);
  
  #define MODULE_ALIAS_NETPROTO(proto) \
  	MODULE_ALIAS("net-pf-" __stringify(proto))
diff --cc net/core/utils.c
index 3c7f5b51b979,bf09371e19b1..000000000000
--- a/net/core/utils.c
+++ b/net/core/utils.c
@@@ -339,24 -339,50 +339,74 @@@ void inet_proto_csum_replace16(__sum16 
  }
  EXPORT_SYMBOL(inet_proto_csum_replace16);
  
++<<<<<<< HEAD
 +int mac_pton(const char *s, u8 *mac)
 +{
 +	int i;
 +
 +	/* XX:XX:XX:XX:XX:XX */
 +	if (strlen(s) < 3 * ETH_ALEN - 1)
 +		return 0;
 +
 +	/* Don't dirty result unless string is valid MAC. */
 +	for (i = 0; i < ETH_ALEN; i++) {
 +		if (!isxdigit(s[i * 3]) || !isxdigit(s[i * 3 + 1]))
 +			return 0;
 +		if (i != ETH_ALEN - 1 && s[i * 3 + 2] != ':')
 +			return 0;
 +	}
 +	for (i = 0; i < ETH_ALEN; i++) {
 +		mac[i] = (hex_to_bin(s[i * 3]) << 4) | hex_to_bin(s[i * 3 + 1]);
 +	}
 +	return 1;
 +}
 +EXPORT_SYMBOL(mac_pton);
++=======
+ struct __net_random_once_work {
+ 	struct work_struct work;
+ 	struct static_key *key;
+ };
+ 
+ static void __net_random_once_deferred(struct work_struct *w)
+ {
+ 	struct __net_random_once_work *work =
+ 		container_of(w, struct __net_random_once_work, work);
+ 	if (!static_key_enabled(work->key))
+ 		static_key_slow_inc(work->key);
+ 	kfree(work);
+ }
+ 
+ static void __net_random_once_disable_jump(struct static_key *key)
+ {
+ 	struct __net_random_once_work *w;
+ 
+ 	w = kmalloc(sizeof(*w), GFP_ATOMIC);
+ 	if (!w)
+ 		return;
+ 
+ 	INIT_WORK(&w->work, __net_random_once_deferred);
+ 	w->key = key;
+ 	schedule_work(&w->work);
+ }
+ 
+ bool __net_get_random_once(void *buf, int nbytes, bool *done,
+ 			   struct static_key *done_key)
+ {
+ 	static DEFINE_SPINLOCK(lock);
+ 
+ 	spin_lock_bh(&lock);
+ 	if (*done) {
+ 		spin_unlock_bh(&lock);
+ 		return false;
+ 	}
+ 
+ 	get_random_bytes(buf, nbytes);
+ 	*done = true;
+ 	spin_unlock_bh(&lock);
+ 
+ 	__net_random_once_disable_jump(done_key);
+ 
+ 	return true;
+ }
+ EXPORT_SYMBOL(__net_get_random_once);
++>>>>>>> a48e42920ff3 (net: introduce new macro net_get_random_once)
* Unmerged path include/linux/net.h
* Unmerged path net/core/utils.c
