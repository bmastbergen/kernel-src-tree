udp: Generalize skb_udp_segment

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Tom Herbert <therbert@google.com>
commit 8bce6d7d0d1ede22af334ee241841e9278365278
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/8bce6d7d.failed

skb_udp_segment is the function called from udp4_ufo_fragment to
segment a UDP tunnel packet. This function currently assumes
segmentation is transparent Ethernet bridging (i.e. VXLAN
encapsulation). This patch generalizes the function to
operate on either Ethertype or IP protocol.

The inner_protocol field must be set to the protocol of the inner
header. This can now be either an Ethertype or an IP protocol
(in a union). A new flag in the skbuff indicates which type is
effective. skb_set_inner_protocol and skb_set_inner_ipproto
helper functions were added to set the inner_protocol. These
functions are called from the point where the tunnel encapsulation
is occuring.

When skb_udp_tunnel_segment is called, the function to segment the
inner packet is selected based on the inner IP or Ethertype. In the
case of an IP protocol encapsulation, the function is derived from
inet[6]_offloads. In the case of Ethertype, skb->protocol is
set to the inner_protocol and skb_mac_gso_segment is called. (GRE
currently does this, but it might be possible to lookup the protocol
in offload_base and call the appropriate segmenation function
directly).

	Signed-off-by: Tom Herbert <therbert@google.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 8bce6d7d0d1ede22af334ee241841e9278365278)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/skbuff.h
#	include/net/udp.h
#	net/ipv4/udp_offload.c
diff --cc include/linux/skbuff.h
index 9599a478ca15,7c5036d11feb..000000000000
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@@ -534,6 -541,71 +534,74 @@@ struct sk_buff 
  				data_len;
  	__u16			mac_len,
  				hdr_len;
++<<<<<<< HEAD
++=======
+ 
+ 	/* Following fields are _not_ copied in __copy_skb_header()
+ 	 * Note that queue_mapping is here mostly to fill a hole.
+ 	 */
+ 	kmemcheck_bitfield_begin(flags1);
+ 	__u16			queue_mapping;
+ 	__u8			cloned:1,
+ 				nohdr:1,
+ 				fclone:2,
+ 				peeked:1,
+ 				head_frag:1,
+ 				xmit_more:1;
+ 	/* one bit hole */
+ 	kmemcheck_bitfield_end(flags1);
+ 
+ 	/* fields enclosed in headers_start/headers_end are copied
+ 	 * using a single memcpy() in __copy_skb_header()
+ 	 */
+ 	__u32			headers_start[0];
+ 
+ /* if you move pkt_type around you also must adapt those constants */
+ #ifdef __BIG_ENDIAN_BITFIELD
+ #define PKT_TYPE_MAX	(7 << 5)
+ #else
+ #define PKT_TYPE_MAX	7
+ #endif
+ #define PKT_TYPE_OFFSET()	offsetof(struct sk_buff, __pkt_type_offset)
+ 
+ 	__u8			__pkt_type_offset[0];
+ 	__u8			pkt_type:3;
+ 	__u8			pfmemalloc:1;
+ 	__u8			ignore_df:1;
+ 	__u8			nfctinfo:3;
+ 
+ 	__u8			nf_trace:1;
+ 	__u8			ip_summed:2;
+ 	__u8			ooo_okay:1;
+ 	__u8			l4_hash:1;
+ 	__u8			sw_hash:1;
+ 	__u8			wifi_acked_valid:1;
+ 	__u8			wifi_acked:1;
+ 
+ 	__u8			no_fcs:1;
+ 	/* Indicates the inner headers are valid in the skbuff. */
+ 	__u8			encapsulation:1;
+ 	__u8			encap_hdr_csum:1;
+ 	__u8			csum_valid:1;
+ 	__u8			csum_complete_sw:1;
+ 	__u8			csum_level:2;
+ 	__u8			csum_bad:1;
+ 
+ #ifdef CONFIG_IPV6_NDISC_NODETYPE
+ 	__u8			ndisc_nodetype:2;
+ #endif
+ 	__u8			ipvs_property:1;
+ 	__u8			inner_protocol_type:1;
+ 	/* 4 or 6 bit hole */
+ 
+ #ifdef CONFIG_NET_SCHED
+ 	__u16			tc_index;	/* traffic control index */
+ #ifdef CONFIG_NET_CLS_ACT
+ 	__u16			tc_verd;	/* traffic control verdict */
+ #endif
+ #endif
+ 
++>>>>>>> 8bce6d7d0d1e (udp: Generalize skb_udp_segment)
  	union {
  		__wsum		csum;
  		struct {
diff --cc include/net/udp.h
index bba909b90a94,07f9b70962f6..000000000000
--- a/include/net/udp.h
+++ b/include/net/udp.h
@@@ -224,38 -224,41 +224,76 @@@ static inline __be16 udp_flow_src_port(
  }
  
  /* net/ipv4/udp.c */
++<<<<<<< HEAD
 +extern int udp_get_port(struct sock *sk, unsigned short snum,
 +			int (*saddr_cmp)(const struct sock *,
 +					 const struct sock *));
 +extern void udp_err(struct sk_buff *, u32);
 +extern int udp_sendmsg(struct kiocb *iocb, struct sock *sk,
 +			    struct msghdr *msg, size_t len);
 +extern int udp_push_pending_frames(struct sock *sk);
 +extern void udp_flush_pending_frames(struct sock *sk);
 +extern int udp_rcv(struct sk_buff *skb);
 +extern int udp_ioctl(struct sock *sk, int cmd, unsigned long arg);
 +extern int udp_disconnect(struct sock *sk, int flags);
 +extern unsigned int udp_poll(struct file *file, struct socket *sock,
 +			     poll_table *wait);
 +extern struct sk_buff *skb_udp_tunnel_segment(struct sk_buff *skb,
 +					      netdev_features_t features);
 +extern int udp_lib_getsockopt(struct sock *sk, int level, int optname,
 +			      char __user *optval, int __user *optlen);
 +extern int udp_lib_setsockopt(struct sock *sk, int level, int optname,
 +			      char __user *optval, unsigned int optlen,
 +			      int (*push_pending_frames)(struct sock *));
 +extern struct sock *udp4_lib_lookup(struct net *net, __be32 saddr, __be16 sport,
 +				    __be32 daddr, __be16 dport,
 +				    int dif);
 +extern struct sock *__udp4_lib_lookup(struct net *net, __be32 saddr, __be16 sport,
 +				    __be32 daddr, __be16 dport,
 +				    int dif, struct udp_table *tbl);
 +extern struct sock *udp6_lib_lookup(struct net *net, const struct in6_addr *saddr, __be16 sport,
 +				    const struct in6_addr *daddr, __be16 dport,
 +				    int dif);
 +extern struct sock *__udp6_lib_lookup(struct net *net, const struct in6_addr *saddr, __be16 sport,
 +				    const struct in6_addr *daddr, __be16 dport,
 +				    int dif, struct udp_table *tbl);
++=======
+ void udp_v4_early_demux(struct sk_buff *skb);
+ int udp_get_port(struct sock *sk, unsigned short snum,
+ 		 int (*saddr_cmp)(const struct sock *,
+ 				  const struct sock *));
+ void udp_err(struct sk_buff *, u32);
+ int udp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg,
+ 		size_t len);
+ int udp_push_pending_frames(struct sock *sk);
+ void udp_flush_pending_frames(struct sock *sk);
+ void udp4_hwcsum(struct sk_buff *skb, __be32 src, __be32 dst);
+ int udp_rcv(struct sk_buff *skb);
+ int udp_ioctl(struct sock *sk, int cmd, unsigned long arg);
+ int udp_disconnect(struct sock *sk, int flags);
+ unsigned int udp_poll(struct file *file, struct socket *sock, poll_table *wait);
+ struct sk_buff *skb_udp_tunnel_segment(struct sk_buff *skb,
+ 				       netdev_features_t features,
+ 				       bool is_ipv6);
+ int udp_lib_getsockopt(struct sock *sk, int level, int optname,
+ 		       char __user *optval, int __user *optlen);
+ int udp_lib_setsockopt(struct sock *sk, int level, int optname,
+ 		       char __user *optval, unsigned int optlen,
+ 		       int (*push_pending_frames)(struct sock *));
+ struct sock *udp4_lib_lookup(struct net *net, __be32 saddr, __be16 sport,
+ 			     __be32 daddr, __be16 dport, int dif);
+ struct sock *__udp4_lib_lookup(struct net *net, __be32 saddr, __be16 sport,
+ 			       __be32 daddr, __be16 dport, int dif,
+ 			       struct udp_table *tbl);
+ struct sock *udp6_lib_lookup(struct net *net,
+ 			     const struct in6_addr *saddr, __be16 sport,
+ 			     const struct in6_addr *daddr, __be16 dport,
+ 			     int dif);
+ struct sock *__udp6_lib_lookup(struct net *net,
+ 			       const struct in6_addr *saddr, __be16 sport,
+ 			       const struct in6_addr *daddr, __be16 dport,
+ 			       int dif, struct udp_table *tbl);
++>>>>>>> 8bce6d7d0d1e (udp: Generalize skb_udp_segment)
  
  /*
   * 	SNMP statistics for UDP and UDP-Lite
diff --cc net/ipv4/udp_offload.c
index cc9bad87f4e1,8c35f2c939ee..000000000000
--- a/net/ipv4/udp_offload.c
+++ b/net/ipv4/udp_offload.c
@@@ -25,9 -25,121 +25,127 @@@ struct udp_offload_priv 
  	struct udp_offload_priv __rcu *next;
  };
  
++<<<<<<< HEAD
 +static int udp4_ufo_send_check(struct sk_buff *skb)
 +{
 +	return 0;
++=======
+ static struct sk_buff *__skb_udp_tunnel_segment(struct sk_buff *skb,
+ 	netdev_features_t features,
+ 	struct sk_buff *(*gso_inner_segment)(struct sk_buff *skb,
+ 					     netdev_features_t features),
+ 	__be16 new_protocol)
+ {
+ 	struct sk_buff *segs = ERR_PTR(-EINVAL);
+ 	u16 mac_offset = skb->mac_header;
+ 	int mac_len = skb->mac_len;
+ 	int tnl_hlen = skb_inner_mac_header(skb) - skb_transport_header(skb);
+ 	__be16 protocol = skb->protocol;
+ 	netdev_features_t enc_features;
+ 	int udp_offset, outer_hlen;
+ 	unsigned int oldlen;
+ 	bool need_csum;
+ 
+ 	oldlen = (u16)~skb->len;
+ 
+ 	if (unlikely(!pskb_may_pull(skb, tnl_hlen)))
+ 		goto out;
+ 
+ 	skb->encapsulation = 0;
+ 	__skb_pull(skb, tnl_hlen);
+ 	skb_reset_mac_header(skb);
+ 	skb_set_network_header(skb, skb_inner_network_offset(skb));
+ 	skb->mac_len = skb_inner_network_offset(skb);
+ 	skb->protocol = new_protocol;
+ 
+ 	need_csum = !!(skb_shinfo(skb)->gso_type & SKB_GSO_UDP_TUNNEL_CSUM);
+ 	if (need_csum)
+ 		skb->encap_hdr_csum = 1;
+ 
+ 	/* segment inner packet. */
+ 	enc_features = skb->dev->hw_enc_features & netif_skb_features(skb);
+ 	segs = gso_inner_segment(skb, enc_features);
+ 	if (IS_ERR_OR_NULL(segs)) {
+ 		skb_gso_error_unwind(skb, protocol, tnl_hlen, mac_offset,
+ 				     mac_len);
+ 		goto out;
+ 	}
+ 
+ 	outer_hlen = skb_tnl_header_len(skb);
+ 	udp_offset = outer_hlen - tnl_hlen;
+ 	skb = segs;
+ 	do {
+ 		struct udphdr *uh;
+ 		int len;
+ 
+ 		skb_reset_inner_headers(skb);
+ 		skb->encapsulation = 1;
+ 
+ 		skb->mac_len = mac_len;
+ 
+ 		skb_push(skb, outer_hlen);
+ 		skb_reset_mac_header(skb);
+ 		skb_set_network_header(skb, mac_len);
+ 		skb_set_transport_header(skb, udp_offset);
+ 		len = skb->len - udp_offset;
+ 		uh = udp_hdr(skb);
+ 		uh->len = htons(len);
+ 
+ 		if (need_csum) {
+ 			__be32 delta = htonl(oldlen + len);
+ 
+ 			uh->check = ~csum_fold((__force __wsum)
+ 					       ((__force u32)uh->check +
+ 						(__force u32)delta));
+ 			uh->check = gso_make_checksum(skb, ~uh->check);
+ 
+ 			if (uh->check == 0)
+ 				uh->check = CSUM_MANGLED_0;
+ 		}
+ 
+ 		skb->protocol = protocol;
+ 	} while ((skb = skb->next));
+ out:
+ 	return segs;
++>>>>>>> 8bce6d7d0d1e (udp: Generalize skb_udp_segment)
+ }
+ 
+ struct sk_buff *skb_udp_tunnel_segment(struct sk_buff *skb,
+ 				       netdev_features_t features,
+ 				       bool is_ipv6)
+ {
+ 	__be16 protocol = skb->protocol;
+ 	const struct net_offload **offloads;
+ 	const struct net_offload *ops;
+ 	struct sk_buff *segs = ERR_PTR(-EINVAL);
+ 	struct sk_buff *(*gso_inner_segment)(struct sk_buff *skb,
+ 					     netdev_features_t features);
+ 
+ 	rcu_read_lock();
+ 
+ 	switch (skb->inner_protocol_type) {
+ 	case ENCAP_TYPE_ETHER:
+ 		protocol = skb->inner_protocol;
+ 		gso_inner_segment = skb_mac_gso_segment;
+ 		break;
+ 	case ENCAP_TYPE_IPPROTO:
+ 		offloads = is_ipv6 ? inet6_offloads : inet_offloads;
+ 		ops = rcu_dereference(offloads[skb->inner_ipproto]);
+ 		if (!ops || !ops->callbacks.gso_segment)
+ 			goto out_unlock;
+ 		gso_inner_segment = ops->callbacks.gso_segment;
+ 		break;
+ 	default:
+ 		goto out_unlock;
+ 	}
+ 
+ 	segs = __skb_udp_tunnel_segment(skb, features, gso_inner_segment,
+ 					protocol);
+ 
+ out_unlock:
+ 	rcu_read_unlock();
+ 
+ 	return segs;
  }
  
  static struct sk_buff *udp4_ufo_fragment(struct sk_buff *skb,
* Unmerged path include/linux/skbuff.h
* Unmerged path include/net/udp.h
* Unmerged path net/ipv4/udp_offload.c
diff --git a/net/ipv6/udp_offload.c b/net/ipv6/udp_offload.c
index 5df577b7a269..6a76a8e52aa0 100644
--- a/net/ipv6/udp_offload.c
+++ b/net/ipv6/udp_offload.c
@@ -63,7 +63,7 @@ static struct sk_buff *udp6_ufo_fragment(struct sk_buff *skb,
 
 	if (skb->encapsulation && skb_shinfo(skb)->gso_type &
 	    (SKB_GSO_UDP_TUNNEL|SKB_GSO_UDP_TUNNEL_CSUM))
-		segs = skb_udp_tunnel_segment(skb, features);
+		segs = skb_udp_tunnel_segment(skb, features, true);
 	else {
 		const struct ipv6hdr *ipv6h;
 		struct udphdr *uh;
