cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Hariprasad Shenai <hariprasad@chelsio.com>
commit 1ecc7b7a5998eb8fc4e9f79979638e77436b0b0b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/1ecc7b7a.failed

Cleanup few MACROS left out in t4_hw.h to be consistent with the
existing ones. Also replace few hardcoded values with MACROS. Also
update comments for some code

	Signed-off-by: Hariprasad Shenai <hariprasad@chelsio.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 1ecc7b7a5998eb8fc4e9f79979638e77436b0b0b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/chelsio/cxgb4/cxgb4_ethtool.c
#	drivers/net/ethernet/chelsio/cxgb4/sge.c
#	drivers/net/ethernet/chelsio/cxgb4/t4_values.h
#	drivers/net/ethernet/chelsio/cxgb4/t4fw_api.h
#	drivers/net/ethernet/chelsio/cxgb4vf/sge.c
diff --cc drivers/net/ethernet/chelsio/cxgb4/sge.c
index 9797215ec30f,dd18fcb644f9..000000000000
--- a/drivers/net/ethernet/chelsio/cxgb4/sge.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/sge.c
@@@ -527,20 -524,28 +527,33 @@@ static inline void ring_fl_db(struct ad
  {
  	u32 val;
  	if (q->pend_cred >= 8) {
++<<<<<<< HEAD
 +		val = PIDX(q->pend_cred / 8);
 +		if (!is_t4(adap->params.chip))
 +			val |= DBTYPE(1);
 +		val |= DBPRIO(1);
++=======
+ 		if (is_t4(adap->params.chip))
+ 			val = PIDX_V(q->pend_cred / 8);
+ 		else
+ 			val = PIDX_T5_V(q->pend_cred / 8) |
+ 				DBTYPE_F;
+ 		val |= DBPRIO_F;
+ 
+ 		/* Make sure all memory writes to the Free List queue are
+ 		 * committed before we tell the hardware about them.
+ 		 */
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  		wmb();
  
 -		/* If we don't have access to the new User Doorbell (T5+), use
 -		 * the old doorbell mechanism; otherwise use the new BAR2
 -		 * mechanism.
 +		/* If we're on T4, use the old doorbell mechanism; otherwise
 +		 * use the new BAR2 mechanism.
  		 */
 -		if (unlikely(q->bar2_addr == NULL)) {
 -			t4_write_reg(adap, MYPF_REG(SGE_PF_KDOORBELL_A),
 -				     val | QID_V(q->cntxt_id));
 +		if (is_t4(adap->params.chip)) {
 +			t4_write_reg(adap, MYPF_REG(SGE_PF_KDOORBELL),
 +				     val | QID(q->cntxt_id));
  		} else {
 -			writel(val | QID_V(q->bar2_qid),
 -			       q->bar2_addr + SGE_UDB_KDOORBELL);
 +			writel(val,  adap->bar2 + q->udb + SGE_UDB_KDOORBELL);
  
  			/* This Write memory Barrier will force the write to
  			 * the User Doorbell area to be flushed.
@@@ -916,10 -924,16 +929,13 @@@ static void cxgb_pio_copy(u64 __iomem *
   */
  static inline void ring_tx_db(struct adapter *adap, struct sge_txq *q, int n)
  {
- 	wmb();            /* write descriptors before telling HW */
+ 	/* Make sure that all writes to the TX Descriptors are committed
+ 	 * before we tell the hardware about them.
+ 	 */
+ 	wmb();
  
 -	/* If we don't have access to the new User Doorbell (T5+), use the old
 -	 * doorbell mechanism; otherwise use the new BAR2 mechanism.
 -	 */
 -	if (unlikely(q->bar2_addr == NULL)) {
 -		u32 val = PIDX_V(n);
 +	if (is_t4(adap->params.chip)) {
 +		u32 val = PIDX(n);
  		unsigned long flags;
  
  		/* For T4 we need to participate in the Doorbell Recovery
@@@ -1074,6 -1087,38 +1091,41 @@@ static inline void txq_advance(struct s
  		q->pidx -= q->size;
  }
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_CHELSIO_T4_FCOE
+ static inline int
+ cxgb_fcoe_offload(struct sk_buff *skb, struct adapter *adap,
+ 		  const struct port_info *pi, u64 *cntrl)
+ {
+ 	const struct cxgb_fcoe *fcoe = &pi->fcoe;
+ 
+ 	if (!(fcoe->flags & CXGB_FCOE_ENABLED))
+ 		return 0;
+ 
+ 	if (skb->protocol != htons(ETH_P_FCOE))
+ 		return 0;
+ 
+ 	skb_reset_mac_header(skb);
+ 	skb->mac_len = sizeof(struct ethhdr);
+ 
+ 	skb_set_network_header(skb, skb->mac_len);
+ 	skb_set_transport_header(skb, skb->mac_len + sizeof(struct fcoe_hdr));
+ 
+ 	if (!cxgb_fcoe_sof_eof_supported(adap, skb))
+ 		return -ENOTSUPP;
+ 
+ 	/* FC CRC offload */
+ 	*cntrl = TXPKT_CSUM_TYPE_V(TX_CSUM_FCOE) |
+ 		     TXPKT_L4CSUM_DIS_F | TXPKT_IPCSUM_DIS_F |
+ 		     TXPKT_CSUM_START_V(CXGB_FCOE_TXPKT_CSUM_START) |
+ 		     TXPKT_CSUM_END_V(CXGB_FCOE_TXPKT_CSUM_END) |
+ 		     TXPKT_CSUM_LOC_V(CXGB_FCOE_TXPKT_CSUM_END);
+ 	return 0;
+ }
+ #endif /* CONFIG_CHELSIO_T4_FCOE */
+ 
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  /**
   *	t4_eth_xmit - add a packet to an Ethernet Tx queue
   *	@skb: the packet
@@@ -1112,6 -1167,13 +1164,16 @@@ out_free:	dev_kfree_skb_any(skb)
  	q = &adap->sge.ethtxq[qidx + pi->first_qset];
  
  	reclaim_completed_tx(adap, &q->q, true);
++<<<<<<< HEAD
++=======
+ 	cntrl = TXPKT_L4CSUM_DIS_F | TXPKT_IPCSUM_DIS_F;
+ 
+ #ifdef CONFIG_CHELSIO_T4_FCOE
+ 	err = cxgb_fcoe_offload(skb, adap, pi, &cntrl);
+ 	if (unlikely(err == -ENOTSUPP))
+ 		goto out_free;
+ #endif /* CONFIG_CHELSIO_T4_FCOE */
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  
  	flits = calc_tx_flits(skb);
  	ndesc = flits_to_desc(flits);
@@@ -1154,14 -1216,14 +1216,25 @@@
  		int eth_xtra_len = skb_network_offset(skb) - ETH_HLEN;
  
  		len += sizeof(*lso);
++<<<<<<< HEAD
 +		wr->op_immdlen = htonl(FW_WR_OP(FW_ETH_TX_PKT_WR) |
 +				       FW_WR_IMMDLEN(len));
 +		lso->c.lso_ctrl = htonl(LSO_OPCODE(CPL_TX_PKT_LSO) |
 +					LSO_FIRST_SLICE | LSO_LAST_SLICE |
 +					LSO_IPV6(v6) |
 +					LSO_ETHHDR_LEN(eth_xtra_len / 4) |
 +					LSO_IPHDR_LEN(l3hdr_len / 4) |
 +					LSO_TCPHDR_LEN(tcp_hdr(skb)->doff));
++=======
+ 		wr->op_immdlen = htonl(FW_WR_OP_V(FW_ETH_TX_PKT_WR) |
+ 				       FW_WR_IMMDLEN_V(len));
+ 		lso->c.lso_ctrl = htonl(LSO_OPCODE_V(CPL_TX_PKT_LSO) |
+ 					LSO_FIRST_SLICE_F | LSO_LAST_SLICE_F |
+ 					LSO_IPV6_V(v6) |
+ 					LSO_ETHHDR_LEN_V(eth_xtra_len / 4) |
+ 					LSO_IPHDR_LEN_V(l3hdr_len / 4) |
+ 					LSO_TCPHDR_LEN_V(tcp_hdr(skb)->doff));
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  		lso->c.ipid_ofst = htons(0);
  		lso->c.mss = htons(ssi->gso_size);
  		lso->c.seqno_offset = htonl(0);
@@@ -1177,23 -1239,28 +1250,33 @@@
  		q->tx_cso += ssi->gso_segs;
  	} else {
  		len += sizeof(*cpl);
 -		wr->op_immdlen = htonl(FW_WR_OP_V(FW_ETH_TX_PKT_WR) |
 -				       FW_WR_IMMDLEN_V(len));
 +		wr->op_immdlen = htonl(FW_WR_OP(FW_ETH_TX_PKT_WR) |
 +				       FW_WR_IMMDLEN(len));
  		cpl = (void *)(wr + 1);
  		if (skb->ip_summed == CHECKSUM_PARTIAL) {
- 			cntrl = hwcsum(skb) | TXPKT_IPCSUM_DIS;
+ 			cntrl = hwcsum(skb) | TXPKT_IPCSUM_DIS_F;
  			q->tx_cso++;
 -		}
 +		} else
 +			cntrl = TXPKT_L4CSUM_DIS | TXPKT_IPCSUM_DIS;
  	}
  
 -	if (skb_vlan_tag_present(skb)) {
 +	if (vlan_tx_tag_present(skb)) {
  		q->vlan_ins++;
++<<<<<<< HEAD
 +		cntrl |= TXPKT_VLAN_VLD | TXPKT_VLAN(vlan_tx_tag_get(skb));
- 	}
- 
- 	cpl->ctrl0 = htonl(TXPKT_OPCODE(CPL_TX_PKT_XT) |
- 			   TXPKT_INTF(pi->tx_chan) | TXPKT_PF(adap->fn));
++=======
+ 		cntrl |= TXPKT_VLAN_VLD_F | TXPKT_VLAN_V(skb_vlan_tag_get(skb));
+ #ifdef CONFIG_CHELSIO_T4_FCOE
+ 		if (skb->protocol == htons(ETH_P_FCOE))
+ 			cntrl |= TXPKT_VLAN_V(
+ 				 ((skb->priority & 0x7) << VLAN_PRIO_SHIFT));
+ #endif /* CONFIG_CHELSIO_T4_FCOE */
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
+ 	}
+ 
+ 	cpl->ctrl0 = htonl(TXPKT_OPCODE_V(CPL_TX_PKT_XT) |
+ 			   TXPKT_INTF_V(pi->tx_chan) |
+ 			   TXPKT_PF_V(adap->fn));
  	cpl->pack = htons(0);
  	cpl->len = htons(skb->len);
  	cpl->ctrl1 = cpu_to_be64(cntrl);
@@@ -1994,6 -2085,38 +2077,41 @@@ static int process_responses(struct sge
  	return budget - budget_left;
  }
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_NET_RX_BUSY_POLL
+ int cxgb_busy_poll(struct napi_struct *napi)
+ {
+ 	struct sge_rspq *q = container_of(napi, struct sge_rspq, napi);
+ 	unsigned int params, work_done;
+ 	u32 val;
+ 
+ 	if (!cxgb_poll_lock_poll(q))
+ 		return LL_FLUSH_BUSY;
+ 
+ 	work_done = process_responses(q, 4);
+ 	params = QINTR_TIMER_IDX_V(TIMERREG_COUNTER0_X) | QINTR_CNT_EN_V(1);
+ 	q->next_intr_params = params;
+ 	val = CIDXINC_V(work_done) | SEINTARM_V(params);
+ 
+ 	/* If we don't have access to the new User GTS (T5+), use the old
+ 	 * doorbell mechanism; otherwise use the new BAR2 mechanism.
+ 	 */
+ 	if (unlikely(!q->bar2_addr))
+ 		t4_write_reg(q->adap, MYPF_REG(SGE_PF_GTS_A),
+ 			     val | INGRESSQID_V((u32)q->cntxt_id));
+ 	else {
+ 		writel(val | INGRESSQID_V(q->bar2_qid),
+ 		       q->bar2_addr + SGE_UDB_GTS);
+ 		wmb();
+ 	}
+ 
+ 	cxgb_poll_unlock_poll(q);
+ 	return work_done;
+ }
+ #endif /* CONFIG_NET_RX_BUSY_POLL */
+ 
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  /**
   *	napi_rx_handler - the NAPI handler for Rx processing
   *	@napi: the napi instance
@@@ -2034,16 -2162,22 +2153,16 @@@ static int napi_rx_handler(struct napi_
  			q->next_intr_params = q->intr_params;
  		}
  	} else
- 		params = QINTR_TIMER_IDX(7);
+ 		params = QINTR_TIMER_IDX_V(7);
  
 -	val = CIDXINC_V(work_done) | SEINTARM_V(params);
 -
 -	/* If we don't have access to the new User GTS (T5+), use the old
 -	 * doorbell mechanism; otherwise use the new BAR2 mechanism.
 -	 */
 -	if (unlikely(q->bar2_addr == NULL)) {
 -		t4_write_reg(q->adap, MYPF_REG(SGE_PF_GTS_A),
 -			     val | INGRESSQID_V((u32)q->cntxt_id));
 +	val = CIDXINC(work_done) | SEINTARM(params);
 +	if (is_t4(q->adap->params.chip)) {
 +		t4_write_reg(q->adap, MYPF_REG(SGE_PF_GTS),
 +			     val | INGRESSQID((u32)q->cntxt_id));
  	} else {
 -		writel(val | INGRESSQID_V(q->bar2_qid),
 -		       q->bar2_addr + SGE_UDB_GTS);
 +		writel(val, q->adap->bar2 + q->udb + SGE_UDB_GTS);
  		wmb();
  	}
 -	cxgb_poll_unlock_napi(q);
  	return work_done;
  }
  
@@@ -2337,22 -2414,25 +2456,30 @@@ int t4_sge_alloc_rxq(struct adapter *ad
  		return -ENOMEM;
  
  	memset(&c, 0, sizeof(c));
 -	c.op_to_vfn = htonl(FW_CMD_OP_V(FW_IQ_CMD) | FW_CMD_REQUEST_F |
 -			    FW_CMD_WRITE_F | FW_CMD_EXEC_F |
 -			    FW_IQ_CMD_PFN_V(adap->fn) | FW_IQ_CMD_VFN_V(0));
 -	c.alloc_to_len16 = htonl(FW_IQ_CMD_ALLOC_F | FW_IQ_CMD_IQSTART_F |
 +	c.op_to_vfn = htonl(FW_CMD_OP(FW_IQ_CMD) | FW_CMD_REQUEST |
 +			    FW_CMD_WRITE | FW_CMD_EXEC |
 +			    FW_IQ_CMD_PFN(adap->fn) | FW_IQ_CMD_VFN(0));
 +	c.alloc_to_len16 = htonl(FW_IQ_CMD_ALLOC | FW_IQ_CMD_IQSTART(1) |
  				 FW_LEN16(c));
++<<<<<<< HEAD
 +	c.type_to_iqandstindex = htonl(FW_IQ_CMD_TYPE(FW_IQ_TYPE_FL_INT_CAP) |
 +		FW_IQ_CMD_IQASYNCH(fwevtq) | FW_IQ_CMD_VIID(pi->viid) |
 +		FW_IQ_CMD_IQANDST(intr_idx < 0) | FW_IQ_CMD_IQANUD(1) |
 +		FW_IQ_CMD_IQANDSTINDEX(intr_idx >= 0 ? intr_idx :
++=======
+ 	c.type_to_iqandstindex = htonl(FW_IQ_CMD_TYPE_V(FW_IQ_TYPE_FL_INT_CAP) |
+ 		FW_IQ_CMD_IQASYNCH_V(fwevtq) | FW_IQ_CMD_VIID_V(pi->viid) |
+ 		FW_IQ_CMD_IQANDST_V(intr_idx < 0) |
+ 		FW_IQ_CMD_IQANUD_V(UPDATEDELIVERY_INTERRUPT_X) |
+ 		FW_IQ_CMD_IQANDSTINDEX_V(intr_idx >= 0 ? intr_idx :
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  							-intr_idx - 1));
 -	c.iqdroprss_to_iqesize = htons(FW_IQ_CMD_IQPCIECH_V(pi->tx_chan) |
 -		FW_IQ_CMD_IQGTSMODE_F |
 -		FW_IQ_CMD_IQINTCNTTHRESH_V(iq->pktcnt_idx) |
 -		FW_IQ_CMD_IQESIZE_V(ilog2(iq->iqe_len) - 4));
 +	c.iqdroprss_to_iqesize = htons(FW_IQ_CMD_IQPCIECH(pi->tx_chan) |
 +		FW_IQ_CMD_IQGTSMODE |
 +		FW_IQ_CMD_IQINTCNTTHRESH(iq->pktcnt_idx) |
 +		FW_IQ_CMD_IQESIZE(ilog2(iq->iqe_len) - 4));
  	c.iqsize = htons(iq->size);
  	c.iqaddr = cpu_to_be64(iq->phys_addr);
 -	if (cong >= 0)
 -		c.iqns_to_fl0congen = htonl(FW_IQ_CMD_IQFLINTCONGEN_F);
  
  	if (fl) {
  		/* Allocate the ring for the hardware free list (with space
@@@ -2372,12 -2452,18 +2499,27 @@@
  			goto fl_nomem;
  
  		flsz = fl->size / 8 + s->stat_len / sizeof(struct tx_desc);
++<<<<<<< HEAD
 +		c.iqns_to_fl0congen = htonl(FW_IQ_CMD_FL0PACKEN(1) |
 +					    FW_IQ_CMD_FL0FETCHRO(1) |
 +					    FW_IQ_CMD_FL0DATARO(1) |
 +					    FW_IQ_CMD_FL0PADEN(1));
 +		c.fl0dcaen_to_fl0cidxfthresh = htons(FW_IQ_CMD_FL0FBMIN(2) |
 +				FW_IQ_CMD_FL0FBMAX(3));
++=======
+ 		c.iqns_to_fl0congen |= htonl(FW_IQ_CMD_FL0PACKEN_F |
+ 					     FW_IQ_CMD_FL0FETCHRO_F |
+ 					     FW_IQ_CMD_FL0DATARO_F |
+ 					     FW_IQ_CMD_FL0PADEN_F);
+ 		if (cong >= 0)
+ 			c.iqns_to_fl0congen |=
+ 				htonl(FW_IQ_CMD_FL0CNGCHMAP_V(cong) |
+ 				      FW_IQ_CMD_FL0CONGCIF_F |
+ 				      FW_IQ_CMD_FL0CONGEN_F);
+ 		c.fl0dcaen_to_fl0cidxfthresh =
+ 			htons(FW_IQ_CMD_FL0FBMIN_V(FETCHBURSTMIN_64B_X) |
+ 			      FW_IQ_CMD_FL0FBMAX_V(FETCHBURSTMAX_512B_X));
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  		c.fl0size = htons(flsz);
  		c.fl0addr = cpu_to_be64(fl->addr);
  	}
@@@ -2472,21 -2599,23 +2614,41 @@@ int t4_sge_alloc_eth_txq(struct adapte
  		return -ENOMEM;
  
  	memset(&c, 0, sizeof(c));
++<<<<<<< HEAD
 +	c.op_to_vfn = htonl(FW_CMD_OP(FW_EQ_ETH_CMD) | FW_CMD_REQUEST |
 +			    FW_CMD_WRITE | FW_CMD_EXEC |
 +			    FW_EQ_ETH_CMD_PFN(adap->fn) | FW_EQ_ETH_CMD_VFN(0));
 +	c.alloc_to_len16 = htonl(FW_EQ_ETH_CMD_ALLOC |
 +				 FW_EQ_ETH_CMD_EQSTART | FW_LEN16(c));
 +	c.viid_pkd = htonl(FW_EQ_ETH_CMD_AUTOEQUEQE |
 +			   FW_EQ_ETH_CMD_VIID(pi->viid));
 +	c.fetchszm_to_iqid = htonl(FW_EQ_ETH_CMD_HOSTFCMODE(2) |
 +				   FW_EQ_ETH_CMD_PCIECHN(pi->tx_chan) |
 +				   FW_EQ_ETH_CMD_FETCHRO(1) |
 +				   FW_EQ_ETH_CMD_IQID(iqid));
 +	c.dcaen_to_eqsize = htonl(FW_EQ_ETH_CMD_FBMIN(2) |
 +				  FW_EQ_ETH_CMD_FBMAX(3) |
 +				  FW_EQ_ETH_CMD_CIDXFTHRESH(5) |
 +				  FW_EQ_ETH_CMD_EQSIZE(nentries));
++=======
+ 	c.op_to_vfn = htonl(FW_CMD_OP_V(FW_EQ_ETH_CMD) | FW_CMD_REQUEST_F |
+ 			    FW_CMD_WRITE_F | FW_CMD_EXEC_F |
+ 			    FW_EQ_ETH_CMD_PFN_V(adap->fn) |
+ 			    FW_EQ_ETH_CMD_VFN_V(0));
+ 	c.alloc_to_len16 = htonl(FW_EQ_ETH_CMD_ALLOC_F |
+ 				 FW_EQ_ETH_CMD_EQSTART_F | FW_LEN16(c));
+ 	c.viid_pkd = htonl(FW_EQ_ETH_CMD_AUTOEQUEQE_F |
+ 			   FW_EQ_ETH_CMD_VIID_V(pi->viid));
+ 	c.fetchszm_to_iqid =
+ 		htonl(FW_EQ_ETH_CMD_HOSTFCMODE_V(HOSTFCMODE_STATUS_PAGE_X) |
+ 		      FW_EQ_ETH_CMD_PCIECHN_V(pi->tx_chan) |
+ 		      FW_EQ_ETH_CMD_FETCHRO_F | FW_EQ_ETH_CMD_IQID_V(iqid));
+ 	c.dcaen_to_eqsize =
+ 		htonl(FW_EQ_ETH_CMD_FBMIN_V(FETCHBURSTMIN_64B_X) |
+ 		      FW_EQ_ETH_CMD_FBMAX_V(FETCHBURSTMAX_512B_X) |
+ 		      FW_EQ_ETH_CMD_CIDXFTHRESH_V(CIDXFLUSHTHRESH_32_X) |
+ 		      FW_EQ_ETH_CMD_EQSIZE_V(nentries));
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  	c.eqaddr = cpu_to_be64(txq->q.phys_addr);
  
  	ret = t4_wr_mbox(adap, adap->fn, &c, sizeof(c), &c);
@@@ -2525,22 -2654,23 +2687,34 @@@ int t4_sge_alloc_ctrl_txq(struct adapte
  	if (!txq->q.desc)
  		return -ENOMEM;
  
 -	c.op_to_vfn = htonl(FW_CMD_OP_V(FW_EQ_CTRL_CMD) | FW_CMD_REQUEST_F |
 -			    FW_CMD_WRITE_F | FW_CMD_EXEC_F |
 -			    FW_EQ_CTRL_CMD_PFN_V(adap->fn) |
 -			    FW_EQ_CTRL_CMD_VFN_V(0));
 -	c.alloc_to_len16 = htonl(FW_EQ_CTRL_CMD_ALLOC_F |
 -				 FW_EQ_CTRL_CMD_EQSTART_F | FW_LEN16(c));
 -	c.cmpliqid_eqid = htonl(FW_EQ_CTRL_CMD_CMPLIQID_V(cmplqid));
 +	c.op_to_vfn = htonl(FW_CMD_OP(FW_EQ_CTRL_CMD) | FW_CMD_REQUEST |
 +			    FW_CMD_WRITE | FW_CMD_EXEC |
 +			    FW_EQ_CTRL_CMD_PFN(adap->fn) |
 +			    FW_EQ_CTRL_CMD_VFN(0));
 +	c.alloc_to_len16 = htonl(FW_EQ_CTRL_CMD_ALLOC |
 +				 FW_EQ_CTRL_CMD_EQSTART | FW_LEN16(c));
 +	c.cmpliqid_eqid = htonl(FW_EQ_CTRL_CMD_CMPLIQID(cmplqid));
  	c.physeqid_pkd = htonl(0);
++<<<<<<< HEAD
 +	c.fetchszm_to_iqid = htonl(FW_EQ_CTRL_CMD_HOSTFCMODE(2) |
 +				   FW_EQ_CTRL_CMD_PCIECHN(pi->tx_chan) |
 +				   FW_EQ_CTRL_CMD_FETCHRO |
 +				   FW_EQ_CTRL_CMD_IQID(iqid));
 +	c.dcaen_to_eqsize = htonl(FW_EQ_CTRL_CMD_FBMIN(2) |
 +				  FW_EQ_CTRL_CMD_FBMAX(3) |
 +				  FW_EQ_CTRL_CMD_CIDXFTHRESH(5) |
 +				  FW_EQ_CTRL_CMD_EQSIZE(nentries));
++=======
+ 	c.fetchszm_to_iqid =
+ 		htonl(FW_EQ_CTRL_CMD_HOSTFCMODE_V(HOSTFCMODE_STATUS_PAGE_X) |
+ 		      FW_EQ_CTRL_CMD_PCIECHN_V(pi->tx_chan) |
+ 		      FW_EQ_CTRL_CMD_FETCHRO_F | FW_EQ_CTRL_CMD_IQID_V(iqid));
+ 	c.dcaen_to_eqsize =
+ 		htonl(FW_EQ_CTRL_CMD_FBMIN_V(FETCHBURSTMIN_64B_X) |
+ 		      FW_EQ_CTRL_CMD_FBMAX_V(FETCHBURSTMAX_512B_X) |
+ 		      FW_EQ_CTRL_CMD_CIDXFTHRESH_V(CIDXFLUSHTHRESH_32_X) |
+ 		      FW_EQ_CTRL_CMD_EQSIZE_V(nentries));
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  	c.eqaddr = cpu_to_be64(txq->q.phys_addr);
  
  	ret = t4_wr_mbox(adap, adap->fn, &c, sizeof(c), &c);
@@@ -2579,20 -2709,21 +2753,38 @@@ int t4_sge_alloc_ofld_txq(struct adapte
  		return -ENOMEM;
  
  	memset(&c, 0, sizeof(c));
++<<<<<<< HEAD
 +	c.op_to_vfn = htonl(FW_CMD_OP(FW_EQ_OFLD_CMD) | FW_CMD_REQUEST |
 +			    FW_CMD_WRITE | FW_CMD_EXEC |
 +			    FW_EQ_OFLD_CMD_PFN(adap->fn) |
 +			    FW_EQ_OFLD_CMD_VFN(0));
 +	c.alloc_to_len16 = htonl(FW_EQ_OFLD_CMD_ALLOC |
 +				 FW_EQ_OFLD_CMD_EQSTART | FW_LEN16(c));
 +	c.fetchszm_to_iqid = htonl(FW_EQ_OFLD_CMD_HOSTFCMODE(2) |
 +				   FW_EQ_OFLD_CMD_PCIECHN(pi->tx_chan) |
 +				   FW_EQ_OFLD_CMD_FETCHRO(1) |
 +				   FW_EQ_OFLD_CMD_IQID(iqid));
 +	c.dcaen_to_eqsize = htonl(FW_EQ_OFLD_CMD_FBMIN(2) |
 +				  FW_EQ_OFLD_CMD_FBMAX(3) |
 +				  FW_EQ_OFLD_CMD_CIDXFTHRESH(5) |
 +				  FW_EQ_OFLD_CMD_EQSIZE(nentries));
++=======
+ 	c.op_to_vfn = htonl(FW_CMD_OP_V(FW_EQ_OFLD_CMD) | FW_CMD_REQUEST_F |
+ 			    FW_CMD_WRITE_F | FW_CMD_EXEC_F |
+ 			    FW_EQ_OFLD_CMD_PFN_V(adap->fn) |
+ 			    FW_EQ_OFLD_CMD_VFN_V(0));
+ 	c.alloc_to_len16 = htonl(FW_EQ_OFLD_CMD_ALLOC_F |
+ 				 FW_EQ_OFLD_CMD_EQSTART_F | FW_LEN16(c));
+ 	c.fetchszm_to_iqid =
+ 		htonl(FW_EQ_OFLD_CMD_HOSTFCMODE_V(HOSTFCMODE_STATUS_PAGE_X) |
+ 		      FW_EQ_OFLD_CMD_PCIECHN_V(pi->tx_chan) |
+ 		      FW_EQ_OFLD_CMD_FETCHRO_F | FW_EQ_OFLD_CMD_IQID_V(iqid));
+ 	c.dcaen_to_eqsize =
+ 		htonl(FW_EQ_OFLD_CMD_FBMIN_V(FETCHBURSTMIN_64B_X) |
+ 		      FW_EQ_OFLD_CMD_FBMAX_V(FETCHBURSTMAX_512B_X) |
+ 		      FW_EQ_OFLD_CMD_CIDXFTHRESH_V(CIDXFLUSHTHRESH_32_X) |
+ 		      FW_EQ_OFLD_CMD_EQSIZE_V(nentries));
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  	c.eqaddr = cpu_to_be64(txq->q.phys_addr);
  
  	ret = t4_wr_mbox(adap, adap->fn, &c, sizeof(c), &c);
@@@ -2979,10 -3038,14 +3171,14 @@@ int t4_sge_init(struct adapter *adap
  	 * Packing Boundary.  T5 introduced the ability to specify these
  	 * separately.  The actual Ingress Packet Data alignment boundary
  	 * within Packed Buffer Mode is the maximum of these two
- 	 * specifications.
+ 	 * specifications.  (Note that it makes no real practical sense to
+ 	 * have the Pading Boudary be larger than the Packing Boundary but you
+ 	 * could set the chip up that way and, in fact, legacy T4 code would
+ 	 * end doing this because it would initialize the Padding Boundary and
+ 	 * leave the Packing Boundary initialized to 0 (16 bytes).)
  	 */
 -	ingpadboundary = 1 << (INGPADBOUNDARY_G(sge_control) +
 -			       INGPADBOUNDARY_SHIFT_X);
 +	ingpadboundary = 1 << (INGPADBOUNDARY_GET(sge_control) +
 +			       X_INGPADBOUNDARY_SHIFT);
  	if (is_t4(adap->params.chip)) {
  		s->fl_align = ingpadboundary;
  	} else {
@@@ -3019,18 -3079,21 +3215,26 @@@
  	 * buffers and a new field which only applies to Packed Mode Free List
  	 * buffers.
  	 */
 -	sge_conm_ctrl = t4_read_reg(adap, SGE_CONM_CTRL_A);
 +	sge_conm_ctrl = t4_read_reg(adap, SGE_CONM_CTRL);
  	if (is_t4(adap->params.chip))
 -		egress_threshold = EGRTHRESHOLD_G(sge_conm_ctrl);
 +		egress_threshold = EGRTHRESHOLD_GET(sge_conm_ctrl);
  	else
 -		egress_threshold = EGRTHRESHOLDPACKING_G(sge_conm_ctrl);
 +		egress_threshold = EGRTHRESHOLDPACKING_GET(sge_conm_ctrl);
  	s->fl_starve_thres = 2*egress_threshold + 1;
  
++<<<<<<< HEAD
++=======
+ 	t4_idma_monitor_init(adap, &s->idma_monitor);
+ 
+ 	/* Set up timers used for recuring callbacks to process RX and TX
+ 	 * administrative tasks.
+ 	 */
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  	setup_timer(&s->rx_timer, sge_rx_timer_cb, (unsigned long)adap);
  	setup_timer(&s->tx_timer, sge_tx_timer_cb, (unsigned long)adap);
 -
 +	s->idma_1s_thresh = core_ticks_per_usec(adap) * 1000000;  /* 1 s */
 +	s->idma_stalled[0] = 0;
 +	s->idma_stalled[1] = 0;
  	spin_lock_init(&s->intrq_lock);
  
  	return 0;
diff --cc drivers/net/ethernet/chelsio/cxgb4/t4fw_api.h
index 6e8a06e7cea8,16c6d67370ee..000000000000
--- a/drivers/net/ethernet/chelsio/cxgb4/t4fw_api.h
+++ b/drivers/net/ethernet/chelsio/cxgb4/t4fw_api.h
@@@ -1196,40 -1539,103 +1196,126 @@@ struct fw_eq_eth_cmd 
  	__be64 r9;
  };
  
 -#define FW_EQ_ETH_CMD_PFN_S	8
 -#define FW_EQ_ETH_CMD_PFN_V(x)	((x) << FW_EQ_ETH_CMD_PFN_S)
 -
 -#define FW_EQ_ETH_CMD_VFN_S	0
 -#define FW_EQ_ETH_CMD_VFN_V(x)	((x) << FW_EQ_ETH_CMD_VFN_S)
 -
 -#define FW_EQ_ETH_CMD_ALLOC_S		31
 -#define FW_EQ_ETH_CMD_ALLOC_V(x)	((x) << FW_EQ_ETH_CMD_ALLOC_S)
 -#define FW_EQ_ETH_CMD_ALLOC_F	FW_EQ_ETH_CMD_ALLOC_V(1U)
 -
 -#define FW_EQ_ETH_CMD_FREE_S	30
 -#define FW_EQ_ETH_CMD_FREE_V(x)	((x) << FW_EQ_ETH_CMD_FREE_S)
 -#define FW_EQ_ETH_CMD_FREE_F	FW_EQ_ETH_CMD_FREE_V(1U)
 -
 +#define FW_EQ_ETH_CMD_PFN(x) ((x) << 8)
 +#define FW_EQ_ETH_CMD_VFN(x) ((x) << 0)
 +#define FW_EQ_ETH_CMD_ALLOC (1U << 31)
 +#define FW_EQ_ETH_CMD_FREE (1U << 30)
 +#define FW_EQ_ETH_CMD_MODIFY (1U << 29)
 +#define FW_EQ_ETH_CMD_EQSTART (1U << 28)
 +#define FW_EQ_ETH_CMD_EQSTOP (1U << 27)
 +
 +#define FW_EQ_ETH_CMD_EQID(x) ((x) << 0)
 +#define FW_EQ_ETH_CMD_EQID_GET(x) (((x) >> 0) & 0xfffff)
 +#define FW_EQ_ETH_CMD_PHYSEQID(x) ((x) << 0)
 +#define FW_EQ_ETH_CMD_PHYSEQID_GET(x) (((x) >> 0) & 0xfffff)
 +
 +#define FW_EQ_ETH_CMD_FETCHSZM(x) ((x) << 26)
 +#define FW_EQ_ETH_CMD_STATUSPGNS(x) ((x) << 25)
 +#define FW_EQ_ETH_CMD_STATUSPGRO(x) ((x) << 24)
 +#define FW_EQ_ETH_CMD_FETCHNS(x) ((x) << 23)
 +#define FW_EQ_ETH_CMD_FETCHRO(x) ((x) << 22)
 +#define FW_EQ_ETH_CMD_HOSTFCMODE(x) ((x) << 20)
 +#define FW_EQ_ETH_CMD_CPRIO(x) ((x) << 19)
 +#define FW_EQ_ETH_CMD_ONCHIP(x) ((x) << 18)
 +#define FW_EQ_ETH_CMD_PCIECHN(x) ((x) << 16)
 +#define FW_EQ_ETH_CMD_IQID(x) ((x) << 0)
 +
 +#define FW_EQ_ETH_CMD_DCAEN(x) ((x) << 31)
 +#define FW_EQ_ETH_CMD_DCACPU(x) ((x) << 26)
 +#define FW_EQ_ETH_CMD_FBMIN(x) ((x) << 23)
 +#define FW_EQ_ETH_CMD_FBMAX(x) ((x) << 20)
 +#define FW_EQ_ETH_CMD_CIDXFTHRESHO(x) ((x) << 19)
 +#define FW_EQ_ETH_CMD_CIDXFTHRESH(x) ((x) << 16)
 +#define FW_EQ_ETH_CMD_EQSIZE(x) ((x) << 0)
 +
++<<<<<<< HEAD
 +#define FW_EQ_ETH_CMD_AUTOEQUEQE (1U << 30)
 +#define FW_EQ_ETH_CMD_VIID(x) ((x) << 16)
++=======
+ #define FW_EQ_ETH_CMD_MODIFY_S		29
+ #define FW_EQ_ETH_CMD_MODIFY_V(x)	((x) << FW_EQ_ETH_CMD_MODIFY_S)
+ #define FW_EQ_ETH_CMD_MODIFY_F	FW_EQ_ETH_CMD_MODIFY_V(1U)
+ 
+ #define FW_EQ_ETH_CMD_EQSTART_S		28
+ #define FW_EQ_ETH_CMD_EQSTART_V(x)	((x) << FW_EQ_ETH_CMD_EQSTART_S)
+ #define FW_EQ_ETH_CMD_EQSTART_F	FW_EQ_ETH_CMD_EQSTART_V(1U)
+ 
+ #define FW_EQ_ETH_CMD_EQSTOP_S		27
+ #define FW_EQ_ETH_CMD_EQSTOP_V(x)	((x) << FW_EQ_ETH_CMD_EQSTOP_S)
+ #define FW_EQ_ETH_CMD_EQSTOP_F	FW_EQ_ETH_CMD_EQSTOP_V(1U)
+ 
+ #define FW_EQ_ETH_CMD_EQID_S	0
+ #define FW_EQ_ETH_CMD_EQID_M	0xfffff
+ #define FW_EQ_ETH_CMD_EQID_V(x)	((x) << FW_EQ_ETH_CMD_EQID_S)
+ #define FW_EQ_ETH_CMD_EQID_G(x)	\
+ 	(((x) >> FW_EQ_ETH_CMD_EQID_S) & FW_EQ_ETH_CMD_EQID_M)
+ 
+ #define FW_EQ_ETH_CMD_PHYSEQID_S	0
+ #define FW_EQ_ETH_CMD_PHYSEQID_M	0xfffff
+ #define FW_EQ_ETH_CMD_PHYSEQID_V(x)	((x) << FW_EQ_ETH_CMD_PHYSEQID_S)
+ #define FW_EQ_ETH_CMD_PHYSEQID_G(x)	\
+ 	(((x) >> FW_EQ_ETH_CMD_PHYSEQID_S) & FW_EQ_ETH_CMD_PHYSEQID_M)
+ 
+ #define FW_EQ_ETH_CMD_FETCHSZM_S	26
+ #define FW_EQ_ETH_CMD_FETCHSZM_V(x)	((x) << FW_EQ_ETH_CMD_FETCHSZM_S)
+ #define FW_EQ_ETH_CMD_FETCHSZM_F	FW_EQ_ETH_CMD_FETCHSZM_V(1U)
+ 
+ #define FW_EQ_ETH_CMD_STATUSPGNS_S	25
+ #define FW_EQ_ETH_CMD_STATUSPGNS_V(x)	((x) << FW_EQ_ETH_CMD_STATUSPGNS_S)
+ 
+ #define FW_EQ_ETH_CMD_STATUSPGRO_S	24
+ #define FW_EQ_ETH_CMD_STATUSPGRO_V(x)	((x) << FW_EQ_ETH_CMD_STATUSPGRO_S)
+ 
+ #define FW_EQ_ETH_CMD_FETCHNS_S		23
+ #define FW_EQ_ETH_CMD_FETCHNS_V(x)	((x) << FW_EQ_ETH_CMD_FETCHNS_S)
+ 
+ #define FW_EQ_ETH_CMD_FETCHRO_S		22
+ #define FW_EQ_ETH_CMD_FETCHRO_V(x)	((x) << FW_EQ_ETH_CMD_FETCHRO_S)
+ #define FW_EQ_ETH_CMD_FETCHRO_F		FW_EQ_ETH_CMD_FETCHRO_V(1U)
+ 
+ #define FW_EQ_ETH_CMD_HOSTFCMODE_S	20
+ #define FW_EQ_ETH_CMD_HOSTFCMODE_V(x)	((x) << FW_EQ_ETH_CMD_HOSTFCMODE_S)
+ 
+ #define FW_EQ_ETH_CMD_CPRIO_S		19
+ #define FW_EQ_ETH_CMD_CPRIO_V(x)	((x) << FW_EQ_ETH_CMD_CPRIO_S)
+ 
+ #define FW_EQ_ETH_CMD_ONCHIP_S		18
+ #define FW_EQ_ETH_CMD_ONCHIP_V(x)	((x) << FW_EQ_ETH_CMD_ONCHIP_S)
+ 
+ #define FW_EQ_ETH_CMD_PCIECHN_S		16
+ #define FW_EQ_ETH_CMD_PCIECHN_V(x)	((x) << FW_EQ_ETH_CMD_PCIECHN_S)
+ 
+ #define FW_EQ_ETH_CMD_IQID_S	0
+ #define FW_EQ_ETH_CMD_IQID_V(x)	((x) << FW_EQ_ETH_CMD_IQID_S)
+ 
+ #define FW_EQ_ETH_CMD_DCAEN_S		31
+ #define FW_EQ_ETH_CMD_DCAEN_V(x)	((x) << FW_EQ_ETH_CMD_DCAEN_S)
+ 
+ #define FW_EQ_ETH_CMD_DCACPU_S		26
+ #define FW_EQ_ETH_CMD_DCACPU_V(x)	((x) << FW_EQ_ETH_CMD_DCACPU_S)
+ 
+ #define FW_EQ_ETH_CMD_FBMIN_S		23
+ #define FW_EQ_ETH_CMD_FBMIN_V(x)	((x) << FW_EQ_ETH_CMD_FBMIN_S)
+ 
+ #define FW_EQ_ETH_CMD_FBMAX_S		20
+ #define FW_EQ_ETH_CMD_FBMAX_V(x)	((x) << FW_EQ_ETH_CMD_FBMAX_S)
+ 
+ #define FW_EQ_ETH_CMD_CIDXFTHRESHO_S	19
+ #define FW_EQ_ETH_CMD_CIDXFTHRESHO_V(x)	((x) << FW_EQ_ETH_CMD_CIDXFTHRESHO_S)
+ 
+ #define FW_EQ_ETH_CMD_CIDXFTHRESH_S	16
+ #define FW_EQ_ETH_CMD_CIDXFTHRESH_V(x)	((x) << FW_EQ_ETH_CMD_CIDXFTHRESH_S)
+ 
+ #define FW_EQ_ETH_CMD_EQSIZE_S		0
+ #define FW_EQ_ETH_CMD_EQSIZE_V(x)	((x) << FW_EQ_ETH_CMD_EQSIZE_S)
+ 
+ #define FW_EQ_ETH_CMD_AUTOEQUEQE_S	30
+ #define FW_EQ_ETH_CMD_AUTOEQUEQE_V(x)	((x) << FW_EQ_ETH_CMD_AUTOEQUEQE_S)
+ #define FW_EQ_ETH_CMD_AUTOEQUEQE_F	FW_EQ_ETH_CMD_AUTOEQUEQE_V(1U)
+ 
+ #define FW_EQ_ETH_CMD_VIID_S	16
+ #define FW_EQ_ETH_CMD_VIID_V(x)	((x) << FW_EQ_ETH_CMD_VIID_S)
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  
  struct fw_eq_ctrl_cmd {
  	__be32 op_to_vfn;
diff --cc drivers/net/ethernet/chelsio/cxgb4vf/sge.c
index 8c552f8bc3c3,2e41d1541d73..000000000000
--- a/drivers/net/ethernet/chelsio/cxgb4vf/sge.c
+++ b/drivers/net/ethernet/chelsio/cxgb4vf/sge.c
@@@ -1243,9 -1338,9 +1244,13 @@@ int t4vf_eth_xmit(struct sk_buff *skb, 
  	 * If there's a VLAN tag present, add that to the list of things to
  	 * do in this Work Request.
  	 */
 -	if (skb_vlan_tag_present(skb)) {
 +	if (vlan_tx_tag_present(skb)) {
  		txq->vlan_ins++;
++<<<<<<< HEAD
 +		cntrl |= TXPKT_VLAN_VLD | TXPKT_VLAN(vlan_tx_tag_get(skb));
++=======
+ 		cntrl |= TXPKT_VLAN_VLD_F | TXPKT_VLAN_V(skb_vlan_tag_get(skb));
++>>>>>>> 1ecc7b7a5998 (cxgb4/cxgb4vf: Cleanup macros, add comments and add new MACROS)
  	}
  
  	/*
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/cxgb4_ethtool.c
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/t4_values.h
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/cxgb4_ethtool.c
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
index 2a3e5627b439..15fce3039b78 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
@@ -2598,7 +2598,7 @@ static int set_rspq_intr_params(struct sge_rspq *q,
 	}
 
 	us = us == 0 ? 6 : closest_timer(&adap->sge, us);
-	q->intr_params = QINTR_TIMER_IDX(us) | (cnt > 0 ? QINTR_CNT_EN : 0);
+	q->intr_params = QINTR_TIMER_IDX_V(us) | QINTR_CNT_EN_V(cnt > 0);
 	return 0;
 }
 
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/sge.c
diff --git a/drivers/net/ethernet/chelsio/cxgb4/t4_hw.h b/drivers/net/ethernet/chelsio/cxgb4/t4_hw.h
index c19a90e7f7d1..cf534eeb3275 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/t4_hw.h
+++ b/drivers/net/ethernet/chelsio/cxgb4/t4_hw.h
@@ -128,17 +128,33 @@ struct rsp_ctrl {
 	};
 };
 
-#define RSPD_NEWBUF 0x80000000U
-#define RSPD_LEN(x) (((x) >> 0) & 0x7fffffffU)
-#define RSPD_QID(x) RSPD_LEN(x)
+#define RSPD_NEWBUF_S    31
+#define RSPD_NEWBUF_V(x) ((x) << RSPD_NEWBUF_S)
+#define RSPD_NEWBUF_F    RSPD_NEWBUF_V(1U)
 
-#define RSPD_GEN(x)  ((x) >> 7)
-#define RSPD_TYPE(x) (((x) >> 4) & 3)
+#define RSPD_LEN_S    0
+#define RSPD_LEN_M    0x7fffffff
+#define RSPD_LEN_G(x) (((x) >> RSPD_LEN_S) & RSPD_LEN_M)
 
-#define V_QINTR_CNT_EN	   0x0
-#define QINTR_CNT_EN       0x1
-#define QINTR_TIMER_IDX(x) ((x) << 1)
-#define QINTR_TIMER_IDX_GET(x) (((x) >> 1) & 0x7)
+#define RSPD_QID_S    RSPD_LEN_S
+#define RSPD_QID_M    RSPD_LEN_M
+#define RSPD_QID_G(x) RSPD_LEN_G(x)
+
+#define RSPD_GEN_S    7
+
+#define RSPD_TYPE_S    4
+#define RSPD_TYPE_M    0x3
+#define RSPD_TYPE_G(x) (((x) >> RSPD_TYPE_S) & RSPD_TYPE_M)
+
+/* Rx queue interrupt deferral fields: counter enable and timer index */
+#define QINTR_CNT_EN_S    0
+#define QINTR_CNT_EN_V(x) ((x) << QINTR_CNT_EN_S)
+#define QINTR_CNT_EN_F    QINTR_CNT_EN_V(1U)
+
+#define QINTR_TIMER_IDX_S    1
+#define QINTR_TIMER_IDX_M    0x7
+#define QINTR_TIMER_IDX_V(x) ((x) << QINTR_TIMER_IDX_S)
+#define QINTR_TIMER_IDX_G(x) (((x) >> QINTR_TIMER_IDX_S) & QINTR_TIMER_IDX_M)
 
 /*
  * Flash layout.
diff --git a/drivers/net/ethernet/chelsio/cxgb4/t4_msg.h b/drivers/net/ethernet/chelsio/cxgb4/t4_msg.h
index 5f4db2398c71..d25a806c360b 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/t4_msg.h
+++ b/drivers/net/ethernet/chelsio/cxgb4/t4_msg.h
@@ -489,26 +489,9 @@ struct cpl_tid_release {
 
 struct cpl_tx_pkt_core {
 	__be32 ctrl0;
-#define TXPKT_VF(x)        ((x) << 0)
-#define TXPKT_PF(x)        ((x) << 8)
-#define TXPKT_VF_VLD       (1 << 11)
-#define TXPKT_OVLAN_IDX(x) ((x) << 12)
-#define TXPKT_INTF(x)      ((x) << 16)
-#define TXPKT_INS_OVLAN    (1 << 21)
-#define TXPKT_OPCODE(x)    ((x) << 24)
 	__be16 pack;
 	__be16 len;
 	__be64 ctrl1;
-#define TXPKT_CSUM_END(x)   ((x) << 12)
-#define TXPKT_CSUM_START(x) ((x) << 20)
-#define TXPKT_IPHDR_LEN(x)  ((u64)(x) << 20)
-#define TXPKT_CSUM_LOC(x)   ((u64)(x) << 30)
-#define TXPKT_ETHHDR_LEN(x) ((u64)(x) << 34)
-#define TXPKT_CSUM_TYPE(x)  ((u64)(x) << 40)
-#define TXPKT_VLAN(x)       ((u64)(x) << 44)
-#define TXPKT_VLAN_VLD      (1ULL << 60)
-#define TXPKT_IPCSUM_DIS    (1ULL << 62)
-#define TXPKT_L4CSUM_DIS    (1ULL << 63)
 };
 
 struct cpl_tx_pkt {
@@ -518,16 +501,66 @@ struct cpl_tx_pkt {
 
 #define cpl_tx_pkt_xt cpl_tx_pkt
 
+/* cpl_tx_pkt_core.ctrl0 fields */
+#define TXPKT_VF_S    0
+#define TXPKT_VF_V(x) ((x) << TXPKT_VF_S)
+
+#define TXPKT_PF_S    8
+#define TXPKT_PF_V(x) ((x) << TXPKT_PF_S)
+
+#define TXPKT_VF_VLD_S    11
+#define TXPKT_VF_VLD_V(x) ((x) << TXPKT_VF_VLD_S)
+#define TXPKT_VF_VLD_F    TXPKT_VF_VLD_V(1U)
+
+#define TXPKT_OVLAN_IDX_S    12
+#define TXPKT_OVLAN_IDX_V(x) ((x) << TXPKT_OVLAN_IDX_S)
+
+#define TXPKT_INTF_S    16
+#define TXPKT_INTF_V(x) ((x) << TXPKT_INTF_S)
+
+#define TXPKT_INS_OVLAN_S    21
+#define TXPKT_INS_OVLAN_V(x) ((x) << TXPKT_INS_OVLAN_S)
+#define TXPKT_INS_OVLAN_F    TXPKT_INS_OVLAN_V(1U)
+
+#define TXPKT_OPCODE_S    24
+#define TXPKT_OPCODE_V(x) ((x) << TXPKT_OPCODE_S)
+
+/* cpl_tx_pkt_core.ctrl1 fields */
+#define TXPKT_CSUM_END_S    12
+#define TXPKT_CSUM_END_V(x) ((x) << TXPKT_CSUM_END_S)
+
+#define TXPKT_CSUM_START_S    20
+#define TXPKT_CSUM_START_V(x) ((x) << TXPKT_CSUM_START_S)
+
+#define TXPKT_IPHDR_LEN_S    20
+#define TXPKT_IPHDR_LEN_V(x) ((__u64)(x) << TXPKT_IPHDR_LEN_S)
+
+#define TXPKT_CSUM_LOC_S    30
+#define TXPKT_CSUM_LOC_V(x) ((__u64)(x) << TXPKT_CSUM_LOC_S)
+
+#define TXPKT_ETHHDR_LEN_S    34
+#define TXPKT_ETHHDR_LEN_V(x) ((__u64)(x) << TXPKT_ETHHDR_LEN_S)
+
+#define TXPKT_CSUM_TYPE_S    40
+#define TXPKT_CSUM_TYPE_V(x) ((__u64)(x) << TXPKT_CSUM_TYPE_S)
+
+#define TXPKT_VLAN_S    44
+#define TXPKT_VLAN_V(x) ((__u64)(x) << TXPKT_VLAN_S)
+
+#define TXPKT_VLAN_VLD_S    60
+#define TXPKT_VLAN_VLD_V(x) ((__u64)(x) << TXPKT_VLAN_VLD_S)
+#define TXPKT_VLAN_VLD_F    TXPKT_VLAN_VLD_V(1ULL)
+
+#define TXPKT_IPCSUM_DIS_S    62
+#define TXPKT_IPCSUM_DIS_V(x) ((__u64)(x) << TXPKT_IPCSUM_DIS_S)
+#define TXPKT_IPCSUM_DIS_F    TXPKT_IPCSUM_DIS_V(1ULL)
+
+#define TXPKT_L4CSUM_DIS_S    63
+#define TXPKT_L4CSUM_DIS_V(x) ((__u64)(x) << TXPKT_L4CSUM_DIS_S)
+#define TXPKT_L4CSUM_DIS_F    TXPKT_L4CSUM_DIS_V(1ULL)
+
 struct cpl_tx_pkt_lso_core {
 	__be32 lso_ctrl;
-#define LSO_TCPHDR_LEN(x) ((x) << 0)
-#define LSO_IPHDR_LEN(x)  ((x) << 4)
-#define LSO_ETHHDR_LEN(x) ((x) << 16)
-#define LSO_IPV6(x)       ((x) << 20)
-#define LSO_LAST_SLICE    (1 << 22)
-#define LSO_FIRST_SLICE   (1 << 23)
-#define LSO_OPCODE(x)     ((x) << 24)
-#define LSO_T5_XFER_SIZE(x) ((x) << 0)
 	__be16 ipid_ofst;
 	__be16 mss;
 	__be32 seqno_offset;
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/t4_values.h
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/t4fw_api.h
diff --git a/drivers/net/ethernet/chelsio/cxgb4vf/cxgb4vf_main.c b/drivers/net/ethernet/chelsio/cxgb4vf/cxgb4vf_main.c
index 0b0c9434b272..a910f0f1f491 100644
--- a/drivers/net/ethernet/chelsio/cxgb4vf/cxgb4vf_main.c
+++ b/drivers/net/ethernet/chelsio/cxgb4vf/cxgb4vf_main.c
@@ -988,7 +988,7 @@ static int closest_thres(const struct sge *s, int thres)
 static unsigned int qtimer_val(const struct adapter *adapter,
 			       const struct sge_rspq *rspq)
 {
-	unsigned int timer_idx = QINTR_TIMER_IDX_GET(rspq->intr_params);
+	unsigned int timer_idx = QINTR_TIMER_IDX_G(rspq->intr_params);
 
 	return timer_idx < SGE_NTIMERS
 		? adapter->sge.timer_val[timer_idx]
@@ -1053,8 +1053,8 @@ static int set_rxq_intr_params(struct adapter *adapter, struct sge_rspq *rspq,
 	 * Update the response queue's interrupt coalescing parameters and
 	 * return success.
 	 */
-	rspq->intr_params = (QINTR_TIMER_IDX(timer_idx) |
-			     (cnt > 0 ? QINTR_CNT_EN : 0));
+	rspq->intr_params = (QINTR_TIMER_IDX_V(timer_idx) |
+			     QINTR_CNT_EN_V(cnt > 0));
 	return 0;
 }
 
@@ -1327,7 +1327,7 @@ static int cxgb4vf_get_coalesce(struct net_device *dev,
 
 	coalesce->rx_coalesce_usecs = qtimer_val(adapter, rspq);
 	coalesce->rx_max_coalesced_frames =
-		((rspq->intr_params & QINTR_CNT_EN)
+		((rspq->intr_params & QINTR_CNT_EN_F)
 		 ? adapter->sge.counter_val[rspq->pktcnt_idx]
 		 : 0);
 	return 0;
@@ -2297,8 +2297,9 @@ static inline void init_rspq(struct sge_rspq *rspq, u8 timer_idx,
 			     u8 pkt_cnt_idx, unsigned int size,
 			     unsigned int iqe_size)
 {
-	rspq->intr_params = (QINTR_TIMER_IDX(timer_idx) |
-			     (pkt_cnt_idx < SGE_NCOUNTERS ? QINTR_CNT_EN : 0));
+	rspq->intr_params = (QINTR_TIMER_IDX_V(timer_idx) |
+			     (pkt_cnt_idx < SGE_NCOUNTERS ?
+			      QINTR_CNT_EN_F : 0));
 	rspq->pktcnt_idx = (pkt_cnt_idx < SGE_NCOUNTERS
 			    ? pkt_cnt_idx
 			    : 0);
* Unmerged path drivers/net/ethernet/chelsio/cxgb4vf/sge.c
