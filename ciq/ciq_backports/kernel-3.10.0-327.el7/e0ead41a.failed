KVM: async_pf: Provide additional direct page notification

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [kvm] async_pf: Provide additional direct page notification (Paolo Bonzini) [1202825]
Rebuild_FUZZ: 95.50%
commit-author Dominik Dingel <dingel@linux.vnet.ibm.com>
commit e0ead41a6dac09f86675ce07a66e4b253a9b7bd5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/e0ead41a.failed

By setting a Kconfig option, the architecture can control when
guest notifications will be presented by the apf backend.
There is the default batch mechanism, working as before, where the vcpu
thread should pull in this information.
Opposite to this, there is now the direct mechanism, that will push the
information to the guest.
This way s390 can use an already existing architecture interface.

Still the vcpu thread should call check_completion to cleanup leftovers.

	Signed-off-by: Dominik Dingel <dingel@linux.vnet.ibm.com>
	Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
(cherry picked from commit e0ead41a6dac09f86675ce07a66e4b253a9b7bd5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	virt/kvm/async_pf.c
diff --cc virt/kvm/async_pf.c
index a53dfa3b8628,00980ab02c45..000000000000
--- a/virt/kvm/async_pf.c
+++ b/virt/kvm/async_pf.c
@@@ -65,9 -80,12 +80,14 @@@ static void async_pf_execute(struct wor
  
  	might_sleep();
  
 -	use_mm(mm);
  	down_read(&mm->mmap_sem);
 -	get_user_pages(current, mm, addr, 1, 1, 0, NULL, NULL);
 +	get_user_pages(NULL, mm, addr, 1, 1, 0, NULL, NULL);
  	up_read(&mm->mmap_sem);
++<<<<<<< HEAD
++=======
+ 	kvm_async_page_present_sync(vcpu, apf);
+ 	unuse_mm(mm);
++>>>>>>> e0ead41a6dac (KVM: async_pf: Provide additional direct page notification)
  
  	spin_lock(&vcpu->async_pf.lock);
  	list_add_tail(&apf->link, &vcpu->async_pf.done);
@@@ -157,10 -175,10 +177,10 @@@ int kvm_setup_async_pf(struct kvm_vcpu 
  	work->wakeup_all = false;
  	work->vcpu = vcpu;
  	work->gva = gva;
- 	work->addr = gfn_to_hva(vcpu->kvm, gfn);
+ 	work->addr = hva;
  	work->arch = *arch;
  	work->mm = current->mm;
 -	atomic_inc(&work->mm->mm_count);
 +	atomic_inc(&work->mm->mm_users);
  	kvm_get_kvm(work->vcpu->kvm);
  
  	/* this can't really happen otherwise gfn_to_pfn_async
diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c
index 486947d144c0..7fc70f08b30a 100644
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@ -3351,7 +3351,7 @@ static int kvm_arch_setup_async_pf(struct kvm_vcpu *vcpu, gva_t gva, gfn_t gfn)
 	arch.direct_map = vcpu->arch.mmu.direct_map;
 	arch.cr3 = vcpu->arch.mmu.get_cr3(vcpu);
 
-	return kvm_setup_async_pf(vcpu, gva, gfn, &arch);
+	return kvm_setup_async_pf(vcpu, gva, gfn_to_hva(vcpu->kvm, gfn), &arch);
 }
 
 static bool can_do_async_pf(struct kvm_vcpu *vcpu)
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index e9f180bc34be..d6497b6f973b 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -195,7 +195,7 @@ struct kvm_async_pf {
 
 void kvm_clear_async_pf_completion_queue(struct kvm_vcpu *vcpu);
 void kvm_check_async_pf_completion(struct kvm_vcpu *vcpu);
-int kvm_setup_async_pf(struct kvm_vcpu *vcpu, gva_t gva, gfn_t gfn,
+int kvm_setup_async_pf(struct kvm_vcpu *vcpu, gva_t gva, unsigned long hva,
 		       struct kvm_arch_async_pf *arch);
 int kvm_async_pf_wakeup_all(struct kvm_vcpu *vcpu);
 #endif
diff --git a/virt/kvm/Kconfig b/virt/kvm/Kconfig
index 7a0584b686bd..50d110654b42 100644
--- a/virt/kvm/Kconfig
+++ b/virt/kvm/Kconfig
@@ -25,6 +25,10 @@ config KVM_MMIO
 config KVM_ASYNC_PF
        bool
 
+# Toggle to switch between direct notification and batch job
+config KVM_ASYNC_PF_SYNC
+       bool
+
 config HAVE_KVM_MSI
        bool
 
* Unmerged path virt/kvm/async_pf.c
