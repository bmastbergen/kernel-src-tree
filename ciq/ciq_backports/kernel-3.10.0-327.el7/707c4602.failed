net/mlx5_core: Add new query HCA vport commands

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [netdrv] mlx5_core: Add new query HCA vport commands (Amir Vadai) [1164527 1164530 1164531 1164536 1164537]
Rebuild_FUZZ: 95.56%
commit-author Majd Dibbiny <majd@mellanox.com>
commit 707c4602cda6624940761b66a4119f1909492385
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/707c4602.failed

Added the implementation for the following commands:

1. QUERY_HCA_VPORT_GID
2. QUERY_HCA_VPORT_PKEY
3. QUERY_HCA_VPORT_CONTEXT

They will be needed when we move to work with ISSI > 0 in the IB driver too.

	Signed-off-by: Majd Dibbiny <majd@mellanox.com>
	Signed-off-by: Or Gerlitz <ogerlitz@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 707c4602cda6624940761b66a4119f1909492385)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/Makefile
#	drivers/net/ethernet/mellanox/mlx5/core/main.c
#	drivers/net/ethernet/mellanox/mlx5/core/vport.c
#	drivers/net/ethernet/mellanox/mlx5/core/vport.h
#	include/linux/mlx5/device.h
diff --cc drivers/net/ethernet/mellanox/mlx5/core/Makefile
index 105780bb980b,26a68b8af2c5..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/Makefile
+++ b/drivers/net/ethernet/mellanox/mlx5/core/Makefile
@@@ -2,4 -2,7 +2,11 @@@ obj-$(CONFIG_MLX5_CORE)		+= mlx5_core.
  
  mlx5_core-y :=	main.o cmd.o debugfs.o fw.o eq.o uar.o pagealloc.o \
  		health.o mcg.o cq.o srq.o alloc.o qp.o port.o mr.o pd.o   \
++<<<<<<< HEAD
 +		mad.o
++=======
+ 		mad.o transobj.o vport.o
+ mlx5_core-$(CONFIG_MLX5_CORE_EN) += wq.o flow_table.o \
+ 		en_main.o en_flow_table.o en_ethtool.o en_tx.o en_rx.o \
+ 		en_txrx.o
++>>>>>>> 707c4602cda6 (net/mlx5_core: Add new query HCA vport commands)
diff --cc drivers/net/ethernet/mellanox/mlx5/core/main.c
index a652cb93ceaa,58354122dfe4..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/main.c
@@@ -287,87 -284,8 +287,92 @@@ static u16 to_fw_pkey_sz(u32 size
  	}
  }
  
++<<<<<<< HEAD
 +/* selectively copy writable fields clearing any reserved area
 + */
 +static void copy_rw_fields(void *to, struct mlx5_caps *from)
 +{
 +	__be64 *flags_off = (__be64 *)MLX5_ADDR_OF(cmd_hca_cap, to, reserved_22);
 +	u64 v64;
 +
 +	MLX5_SET(cmd_hca_cap, to, log_max_qp, from->gen.log_max_qp);
 +	MLX5_SET(cmd_hca_cap, to, log_max_ra_req_qp, from->gen.log_max_ra_req_qp);
 +	MLX5_SET(cmd_hca_cap, to, log_max_ra_res_qp, from->gen.log_max_ra_res_qp);
 +	MLX5_SET(cmd_hca_cap, to, pkey_table_size, from->gen.pkey_table_size);
 +	MLX5_SET(cmd_hca_cap, to, pkey_table_size, to_fw_pkey_sz(from->gen.pkey_table_size));
 +	MLX5_SET(cmd_hca_cap, to, log_uar_page_sz, PAGE_SHIFT - 12);
 +	v64 = from->gen.flags & MLX5_CAP_BITS_RW_MASK;
 +	*flags_off = cpu_to_be64(v64);
 +}
 +
 +static u16 get_pkey_table_size(int pkey)
 +{
 +	if (pkey > MLX5_MAX_LOG_PKEY_TABLE)
 +		return 0;
 +
 +	return MLX5_MIN_PKEY_TABLE_SIZE << pkey;
 +}
 +
 +static void fw2drv_caps(struct mlx5_caps *caps, void *out)
 +{
 +	struct mlx5_general_caps *gen = &caps->gen;
 +
 +	gen->max_srq_wqes = 1 << MLX5_GET_PR(cmd_hca_cap, out, log_max_srq_sz);
 +	gen->max_wqes = 1 << MLX5_GET_PR(cmd_hca_cap, out, log_max_qp_sz);
 +	gen->log_max_qp = MLX5_GET_PR(cmd_hca_cap, out, log_max_qp);
 +	gen->log_max_srq = MLX5_GET_PR(cmd_hca_cap, out, log_max_srq);
 +	gen->max_cqes = 1 << MLX5_GET_PR(cmd_hca_cap, out, log_max_cq_sz);
 +	gen->log_max_cq = MLX5_GET_PR(cmd_hca_cap, out, log_max_cq);
 +	gen->max_eqes = 1 << MLX5_GET_PR(cmd_hca_cap, out, log_max_eq_sz);
 +	gen->log_max_mkey = MLX5_GET_PR(cmd_hca_cap, out, log_max_mkey);
 +	gen->log_max_eq = MLX5_GET_PR(cmd_hca_cap, out, log_max_eq);
 +	gen->max_indirection = MLX5_GET_PR(cmd_hca_cap, out, max_indirection);
 +	gen->log_max_mrw_sz = MLX5_GET_PR(cmd_hca_cap, out, log_max_mrw_sz);
 +	gen->log_max_bsf_list_size = MLX5_GET_PR(cmd_hca_cap, out, log_max_bsf_list_size);
 +	gen->log_max_klm_list_size = MLX5_GET_PR(cmd_hca_cap, out, log_max_klm_list_size);
 +	gen->log_max_ra_req_dc = MLX5_GET_PR(cmd_hca_cap, out, log_max_ra_req_dc);
 +	gen->log_max_ra_res_dc = MLX5_GET_PR(cmd_hca_cap, out, log_max_ra_res_dc);
 +	gen->log_max_ra_req_qp = MLX5_GET_PR(cmd_hca_cap, out, log_max_ra_req_qp);
 +	gen->log_max_ra_res_qp = MLX5_GET_PR(cmd_hca_cap, out, log_max_ra_res_qp);
 +	gen->max_qp_counters = MLX5_GET_PR(cmd_hca_cap, out, max_qp_cnt);
 +	gen->pkey_table_size = get_pkey_table_size(MLX5_GET_PR(cmd_hca_cap, out, pkey_table_size));
 +	gen->local_ca_ack_delay = MLX5_GET_PR(cmd_hca_cap, out, local_ca_ack_delay);
 +	gen->num_ports = MLX5_GET_PR(cmd_hca_cap, out, num_ports);
 +	gen->log_max_msg = MLX5_GET_PR(cmd_hca_cap, out, log_max_msg);
 +	gen->stat_rate_support = MLX5_GET_PR(cmd_hca_cap, out, stat_rate_support);
 +	gen->flags = be64_to_cpu(*(__be64 *)MLX5_ADDR_OF(cmd_hca_cap, out, reserved_22));
 +	pr_debug("flags = 0x%llx\n", gen->flags);
 +	gen->uar_sz = MLX5_GET_PR(cmd_hca_cap, out, uar_sz);
 +	gen->min_log_pg_sz = MLX5_GET_PR(cmd_hca_cap, out, log_pg_sz);
 +	gen->bf_reg_size = MLX5_GET_PR(cmd_hca_cap, out, bf);
 +	gen->bf_reg_size = 1 << MLX5_GET_PR(cmd_hca_cap, out, log_bf_reg_size);
 +	gen->max_sq_desc_sz = MLX5_GET_PR(cmd_hca_cap, out, max_wqe_sz_sq);
 +	gen->max_rq_desc_sz = MLX5_GET_PR(cmd_hca_cap, out, max_wqe_sz_rq);
 +	gen->max_dc_sq_desc_sz = MLX5_GET_PR(cmd_hca_cap, out, max_wqe_sz_sq_dc);
 +	gen->max_qp_mcg = MLX5_GET_PR(cmd_hca_cap, out, max_qp_mcg);
 +	gen->log_max_pd = MLX5_GET_PR(cmd_hca_cap, out, log_max_pd);
 +	gen->log_max_xrcd = MLX5_GET_PR(cmd_hca_cap, out, log_max_xrcd);
 +	gen->log_uar_page_sz = MLX5_GET_PR(cmd_hca_cap, out, log_uar_page_sz);
 +}
 +
 +static const char *caps_opmod_str(u16 opmod)
 +{
 +	switch (opmod) {
 +	case HCA_CAP_OPMOD_GET_MAX:
 +		return "GET_MAX";
 +	case HCA_CAP_OPMOD_GET_CUR:
 +		return "GET_CUR";
 +	default:
 +		return "Invalid";
 +	}
 +}
 +
 +int mlx5_core_get_caps(struct mlx5_core_dev *dev, struct mlx5_caps *caps,
 +		       u16 opmod)
++=======
+ int mlx5_core_get_caps(struct mlx5_core_dev *dev, enum mlx5_cap_type cap_type,
+ 		       enum mlx5_cap_mode cap_mode)
++>>>>>>> 707c4602cda6 (net/mlx5_core: Add new query HCA vport commands)
  {
  	u8 in[MLX5_ST_SZ_BYTES(query_hca_cap_in)];
  	int out_sz = MLX5_ST_SZ_BYTES(query_hca_cap_out);
@@@ -443,17 -372,25 +448,28 @@@ static int handle_hca_cap(struct mlx5_c
  	if (err)
  		goto query_ex;
  
++<<<<<<< HEAD
++=======
+ 	set_hca_cap = MLX5_ADDR_OF(set_hca_cap_in, set_ctx,
+ 				   capability);
+ 	memcpy(set_hca_cap, dev->hca_caps_cur[MLX5_CAP_GENERAL],
+ 	       MLX5_ST_SZ_BYTES(cmd_hca_cap));
+ 
+ 	mlx5_core_dbg(dev, "Current Pkey table size %d Setting new size %d\n",
+ 		      mlx5_to_sw_pkey_sz(MLX5_CAP_GEN(dev, pkey_table_size)),
+ 		      128);
++>>>>>>> 707c4602cda6 (net/mlx5_core: Add new query HCA vport commands)
  	/* we limit the size of the pkey table to 128 entries for now */
 -	MLX5_SET(cmd_hca_cap, set_hca_cap, pkey_table_size,
 -		 to_fw_pkey_sz(128));
 +	cur_caps->gen.pkey_table_size = 128;
  
  	if (prof->mask & MLX5_PROF_MASK_QP_SIZE)
 -		MLX5_SET(cmd_hca_cap, set_hca_cap, log_max_qp,
 -			 prof->log_max_qp);
 +		cur_caps->gen.log_max_qp = prof->log_max_qp;
  
 -	/* disable cmdif checksum */
 -	MLX5_SET(cmd_hca_cap, set_hca_cap, cmdif_checksum, 0);
 +	/* disable checksum */
 +	cur_caps->gen.flags &= ~MLX5_DEV_CAP_FLAG_CMDIF_CSUM;
  
 +	copy_rw_fields(MLX5_ADDR_OF(set_hca_cap_in, set_ctx, capability),
 +		       cur_caps);
  	err = set_caps(dev, set_ctx, set_sz);
  
  query_ex:
diff --cc drivers/net/ethernet/mellanox/mlx5/core/vport.c
index ba374b9a6c87,20150ffa8b16..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/vport.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/vport.c
@@@ -82,3 -83,263 +82,266 @@@ void mlx5_query_vport_mac_address(struc
  
  	kvfree(out);
  }
++<<<<<<< HEAD
++=======
+ EXPORT_SYMBOL(mlx5_query_nic_vport_mac_address);
+ 
+ int mlx5_query_hca_vport_gid(struct mlx5_core_dev *dev, u8 other_vport,
+ 			     u8 port_num, u16  vf_num, u16 gid_index,
+ 			     union ib_gid *gid)
+ {
+ 	int in_sz = MLX5_ST_SZ_BYTES(query_hca_vport_gid_in);
+ 	int out_sz = MLX5_ST_SZ_BYTES(query_hca_vport_gid_out);
+ 	int is_group_manager;
+ 	void *out = NULL;
+ 	void *in = NULL;
+ 	union ib_gid *tmp;
+ 	int tbsz;
+ 	int nout;
+ 	int err;
+ 
+ 	is_group_manager = MLX5_CAP_GEN(dev, vport_group_manager);
+ 	tbsz = mlx5_get_gid_table_len(MLX5_CAP_GEN(dev, gid_table_size));
+ 	mlx5_core_dbg(dev, "vf_num %d, index %d, gid_table_size %d\n",
+ 		      vf_num, gid_index, tbsz);
+ 
+ 	if (gid_index > tbsz && gid_index != 0xffff)
+ 		return -EINVAL;
+ 
+ 	if (gid_index == 0xffff)
+ 		nout = tbsz;
+ 	else
+ 		nout = 1;
+ 
+ 	out_sz += nout * sizeof(*gid);
+ 
+ 	in = kzalloc(in_sz, GFP_KERNEL);
+ 	out = kzalloc(out_sz, GFP_KERNEL);
+ 	if (!in || !out) {
+ 		err = -ENOMEM;
+ 		goto out;
+ 	}
+ 
+ 	MLX5_SET(query_hca_vport_gid_in, in, opcode, MLX5_CMD_OP_QUERY_HCA_VPORT_GID);
+ 	if (other_vport) {
+ 		if (is_group_manager) {
+ 			MLX5_SET(query_hca_vport_gid_in, in, vport_number, vf_num);
+ 			MLX5_SET(query_hca_vport_gid_in, in, other_vport, 1);
+ 		} else {
+ 			err = -EPERM;
+ 			goto out;
+ 		}
+ 	}
+ 	MLX5_SET(query_hca_vport_gid_in, in, gid_index, gid_index);
+ 
+ 	if (MLX5_CAP_GEN(dev, num_ports) == 2)
+ 		MLX5_SET(query_hca_vport_gid_in, in, port_num, port_num);
+ 
+ 	err = mlx5_cmd_exec(dev, in, in_sz, out, out_sz);
+ 	if (err)
+ 		goto out;
+ 
+ 	err = mlx5_cmd_status_to_err_v2(out);
+ 	if (err)
+ 		goto out;
+ 
+ 	tmp = out + MLX5_ST_SZ_BYTES(query_hca_vport_gid_out);
+ 	gid->global.subnet_prefix = tmp->global.subnet_prefix;
+ 	gid->global.interface_id = tmp->global.interface_id;
+ 
+ out:
+ 	kfree(in);
+ 	kfree(out);
+ 	return err;
+ }
+ EXPORT_SYMBOL_GPL(mlx5_query_hca_vport_gid);
+ 
+ int mlx5_query_hca_vport_pkey(struct mlx5_core_dev *dev, u8 other_vport,
+ 			      u8 port_num, u16 vf_num, u16 pkey_index,
+ 			      u16 *pkey)
+ {
+ 	int in_sz = MLX5_ST_SZ_BYTES(query_hca_vport_pkey_in);
+ 	int out_sz = MLX5_ST_SZ_BYTES(query_hca_vport_pkey_out);
+ 	int is_group_manager;
+ 	void *out = NULL;
+ 	void *in = NULL;
+ 	void *pkarr;
+ 	int nout;
+ 	int tbsz;
+ 	int err;
+ 	int i;
+ 
+ 	is_group_manager = MLX5_CAP_GEN(dev, vport_group_manager);
+ 
+ 	tbsz = mlx5_to_sw_pkey_sz(MLX5_CAP_GEN(dev, pkey_table_size));
+ 	if (pkey_index > tbsz && pkey_index != 0xffff)
+ 		return -EINVAL;
+ 
+ 	if (pkey_index == 0xffff)
+ 		nout = tbsz;
+ 	else
+ 		nout = 1;
+ 
+ 	out_sz += nout * MLX5_ST_SZ_BYTES(pkey);
+ 
+ 	in = kzalloc(in_sz, GFP_KERNEL);
+ 	out = kzalloc(out_sz, GFP_KERNEL);
+ 	if (!in || !out) {
+ 		err = -ENOMEM;
+ 		goto out;
+ 	}
+ 
+ 	MLX5_SET(query_hca_vport_pkey_in, in, opcode, MLX5_CMD_OP_QUERY_HCA_VPORT_PKEY);
+ 	if (other_vport) {
+ 		if (is_group_manager) {
+ 			MLX5_SET(query_hca_vport_pkey_in, in, vport_number, vf_num);
+ 			MLX5_SET(query_hca_vport_pkey_in, in, other_vport, 1);
+ 		} else {
+ 			err = -EPERM;
+ 			goto out;
+ 		}
+ 	}
+ 	MLX5_SET(query_hca_vport_pkey_in, in, pkey_index, pkey_index);
+ 
+ 	if (MLX5_CAP_GEN(dev, num_ports) == 2)
+ 		MLX5_SET(query_hca_vport_pkey_in, in, port_num, port_num);
+ 
+ 	err = mlx5_cmd_exec(dev, in, in_sz, out, out_sz);
+ 	if (err)
+ 		goto out;
+ 
+ 	err = mlx5_cmd_status_to_err_v2(out);
+ 	if (err)
+ 		goto out;
+ 
+ 	pkarr = MLX5_ADDR_OF(query_hca_vport_pkey_out, out, pkey);
+ 	for (i = 0; i < nout; i++, pkey++, pkarr += MLX5_ST_SZ_BYTES(pkey))
+ 		*pkey = MLX5_GET_PR(pkey, pkarr, pkey);
+ 
+ out:
+ 	kfree(in);
+ 	kfree(out);
+ 	return err;
+ }
+ EXPORT_SYMBOL_GPL(mlx5_query_hca_vport_pkey);
+ 
+ int mlx5_query_hca_vport_context(struct mlx5_core_dev *dev,
+ 				 u8 other_vport, u8 port_num,
+ 				 u16 vf_num,
+ 				 struct mlx5_hca_vport_context *rep)
+ {
+ 	int out_sz = MLX5_ST_SZ_BYTES(query_hca_vport_context_out);
+ 	int in[MLX5_ST_SZ_DW(query_hca_vport_context_in)];
+ 	int is_group_manager;
+ 	void *out;
+ 	void *ctx;
+ 	int err;
+ 
+ 	is_group_manager = MLX5_CAP_GEN(dev, vport_group_manager);
+ 
+ 	memset(in, 0, sizeof(in));
+ 	out = kzalloc(out_sz, GFP_KERNEL);
+ 	if (!out)
+ 		return -ENOMEM;
+ 
+ 	MLX5_SET(query_hca_vport_context_in, in, opcode, MLX5_CMD_OP_QUERY_HCA_VPORT_CONTEXT);
+ 
+ 	if (other_vport) {
+ 		if (is_group_manager) {
+ 			MLX5_SET(query_hca_vport_context_in, in, other_vport, 1);
+ 			MLX5_SET(query_hca_vport_context_in, in, vport_number, vf_num);
+ 		} else {
+ 			err = -EPERM;
+ 			goto ex;
+ 		}
+ 	}
+ 
+ 	if (MLX5_CAP_GEN(dev, num_ports) == 2)
+ 		MLX5_SET(query_hca_vport_context_in, in, port_num, port_num);
+ 
+ 	err = mlx5_cmd_exec(dev, in, sizeof(in), out,  out_sz);
+ 	if (err)
+ 		goto ex;
+ 	err = mlx5_cmd_status_to_err_v2(out);
+ 	if (err)
+ 		goto ex;
+ 
+ 	ctx = MLX5_ADDR_OF(query_hca_vport_context_out, out, hca_vport_context);
+ 	rep->field_select = MLX5_GET_PR(hca_vport_context, ctx, field_select);
+ 	rep->sm_virt_aware = MLX5_GET_PR(hca_vport_context, ctx, sm_virt_aware);
+ 	rep->has_smi = MLX5_GET_PR(hca_vport_context, ctx, has_smi);
+ 	rep->has_raw = MLX5_GET_PR(hca_vport_context, ctx, has_raw);
+ 	rep->policy = MLX5_GET_PR(hca_vport_context, ctx, vport_state_policy);
+ 	rep->phys_state = MLX5_GET_PR(hca_vport_context, ctx,
+ 				      port_physical_state);
+ 	rep->vport_state = MLX5_GET_PR(hca_vport_context, ctx, vport_state);
+ 	rep->port_physical_state = MLX5_GET_PR(hca_vport_context, ctx,
+ 					       port_physical_state);
+ 	rep->port_guid = MLX5_GET64_PR(hca_vport_context, ctx, port_guid);
+ 	rep->node_guid = MLX5_GET64_PR(hca_vport_context, ctx, node_guid);
+ 	rep->cap_mask1 = MLX5_GET_PR(hca_vport_context, ctx, cap_mask1);
+ 	rep->cap_mask1_perm = MLX5_GET_PR(hca_vport_context, ctx,
+ 					  cap_mask1_field_select);
+ 	rep->cap_mask2 = MLX5_GET_PR(hca_vport_context, ctx, cap_mask2);
+ 	rep->cap_mask2_perm = MLX5_GET_PR(hca_vport_context, ctx,
+ 					  cap_mask2_field_select);
+ 	rep->lid = MLX5_GET_PR(hca_vport_context, ctx, lid);
+ 	rep->init_type_reply = MLX5_GET_PR(hca_vport_context, ctx,
+ 					   init_type_reply);
+ 	rep->lmc = MLX5_GET_PR(hca_vport_context, ctx, lmc);
+ 	rep->subnet_timeout = MLX5_GET_PR(hca_vport_context, ctx,
+ 					  subnet_timeout);
+ 	rep->sm_lid = MLX5_GET_PR(hca_vport_context, ctx, sm_lid);
+ 	rep->sm_sl = MLX5_GET_PR(hca_vport_context, ctx, sm_sl);
+ 	rep->qkey_violation_counter = MLX5_GET_PR(hca_vport_context, ctx,
+ 						  qkey_violation_counter);
+ 	rep->pkey_violation_counter = MLX5_GET_PR(hca_vport_context, ctx,
+ 						  pkey_violation_counter);
+ 	rep->grh_required = MLX5_GET_PR(hca_vport_context, ctx, grh_required);
+ 	rep->sys_image_guid = MLX5_GET64_PR(hca_vport_context, ctx,
+ 					    system_image_guid);
+ 
+ ex:
+ 	kfree(out);
+ 	return err;
+ }
+ EXPORT_SYMBOL_GPL(mlx5_query_hca_vport_context);
+ 
+ int mlx5_query_hca_vport_system_image_guid(struct mlx5_core_dev *dev,
+ 					   __be64 *sys_image_guid)
+ {
+ 	struct mlx5_hca_vport_context *rep;
+ 	int err;
+ 
+ 	rep = kzalloc(sizeof(*rep), GFP_KERNEL);
+ 	if (!rep)
+ 		return -ENOMEM;
+ 
+ 	err = mlx5_query_hca_vport_context(dev, 0, 1, 0, rep);
+ 	if (!err)
+ 		*sys_image_guid = rep->sys_image_guid;
+ 
+ 	kfree(rep);
+ 	return err;
+ }
+ EXPORT_SYMBOL_GPL(mlx5_query_hca_vport_system_image_guid);
+ 
+ int mlx5_query_hca_vport_node_guid(struct mlx5_core_dev *dev,
+ 				   u64 *node_guid)
+ {
+ 	struct mlx5_hca_vport_context *rep;
+ 	int err;
+ 
+ 	rep = kzalloc(sizeof(*rep), GFP_KERNEL);
+ 	if (!rep)
+ 		return -ENOMEM;
+ 
+ 	err = mlx5_query_hca_vport_context(dev, 0, 1, 0, rep);
+ 	if (!err)
+ 		*node_guid = rep->node_guid;
+ 
+ 	kfree(rep);
+ 	return err;
+ }
+ EXPORT_SYMBOL_GPL(mlx5_query_hca_vport_node_guid);
++>>>>>>> 707c4602cda6 (net/mlx5_core: Add new query HCA vport commands)
diff --cc drivers/net/ethernet/mellanox/mlx5/core/vport.h
index c05ca2c3419d,67882a834efb..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/vport.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/vport.h
@@@ -36,6 -36,20 +36,24 @@@
  #include <linux/mlx5/driver.h>
  
  u8 mlx5_query_vport_state(struct mlx5_core_dev *mdev, u8 opmod);
++<<<<<<< HEAD:drivers/net/ethernet/mellanox/mlx5/core/vport.h
 +void mlx5_query_vport_mac_address(struct mlx5_core_dev *mdev, u8 *addr);
++=======
+ void mlx5_query_nic_vport_mac_address(struct mlx5_core_dev *mdev, u8 *addr);
+ int mlx5_query_hca_vport_gid(struct mlx5_core_dev *dev, u8 other_vport,
+ 			     u8 port_num, u16  vf_num, u16 gid_index,
+ 			     union ib_gid *gid);
+ int mlx5_query_hca_vport_pkey(struct mlx5_core_dev *dev, u8 other_vport,
+ 			      u8 port_num, u16 vf_num, u16 pkey_index,
+ 			      u16 *pkey);
+ int mlx5_query_hca_vport_context(struct mlx5_core_dev *dev,
+ 				 u8 other_vport, u8 port_num,
+ 				 u16 vf_num,
+ 				 struct mlx5_hca_vport_context *rep);
+ int mlx5_query_hca_vport_system_image_guid(struct mlx5_core_dev *dev,
+ 					   __be64 *sys_image_guid);
+ int mlx5_query_hca_vport_node_guid(struct mlx5_core_dev *dev,
+ 				   u64 *node_guid);
++>>>>>>> 707c4602cda6 (net/mlx5_core: Add new query HCA vport commands):include/linux/mlx5/vport.h
  
  #endif /* __MLX5_VPORT_H__ */
diff --cc include/linux/mlx5/device.h
index 00cdcf199c10,b2c43508a737..000000000000
--- a/include/linux/mlx5/device.h
+++ b/include/linux/mlx5/device.h
@@@ -1108,4 -1102,87 +1114,90 @@@ enum 
  	MLX5_RQC_RQ_TYPE_MEMORY_RQ_RPM    = 0x1,
  };
  
++<<<<<<< HEAD
++=======
+ /* MLX5 DEV CAPs */
+ 
+ /* TODO: EAT.ME */
+ enum mlx5_cap_mode {
+ 	HCA_CAP_OPMOD_GET_MAX	= 0,
+ 	HCA_CAP_OPMOD_GET_CUR	= 1,
+ };
+ 
+ enum mlx5_cap_type {
+ 	MLX5_CAP_GENERAL = 0,
+ 	MLX5_CAP_ETHERNET_OFFLOADS,
+ 	MLX5_CAP_ODP,
+ 	MLX5_CAP_ATOMIC,
+ 	MLX5_CAP_ROCE,
+ 	MLX5_CAP_IPOIB_OFFLOADS,
+ 	MLX5_CAP_EOIB_OFFLOADS,
+ 	MLX5_CAP_FLOW_TABLE,
+ 	/* NUM OF CAP Types */
+ 	MLX5_CAP_NUM
+ };
+ 
+ /* GET Dev Caps macros */
+ #define MLX5_CAP_GEN(mdev, cap) \
+ 	MLX5_GET(cmd_hca_cap, mdev->hca_caps_cur[MLX5_CAP_GENERAL], cap)
+ 
+ #define MLX5_CAP_GEN_MAX(mdev, cap) \
+ 	MLX5_GET(cmd_hca_cap, mdev->hca_caps_max[MLX5_CAP_GENERAL], cap)
+ 
+ #define MLX5_CAP_ETH(mdev, cap) \
+ 	MLX5_GET(per_protocol_networking_offload_caps,\
+ 		 mdev->hca_caps_cur[MLX5_CAP_ETHERNET_OFFLOADS], cap)
+ 
+ #define MLX5_CAP_ETH_MAX(mdev, cap) \
+ 	MLX5_GET(per_protocol_networking_offload_caps,\
+ 		 mdev->hca_caps_max[MLX5_CAP_ETHERNET_OFFLOADS], cap)
+ 
+ #define MLX5_CAP_ROCE(mdev, cap) \
+ 	MLX5_GET(roce_cap, mdev->hca_caps_cur[MLX5_CAP_ROCE], cap)
+ 
+ #define MLX5_CAP_ROCE_MAX(mdev, cap) \
+ 	MLX5_GET(roce_cap, mdev->hca_caps_max[MLX5_CAP_ROCE], cap)
+ 
+ #define MLX5_CAP_ATOMIC(mdev, cap) \
+ 	MLX5_GET(atomic_caps, mdev->hca_caps_cur[MLX5_CAP_ATOMIC], cap)
+ 
+ #define MLX5_CAP_ATOMIC_MAX(mdev, cap) \
+ 	MLX5_GET(atomic_caps, mdev->hca_caps_max[MLX5_CAP_ATOMIC], cap)
+ 
+ #define MLX5_CAP_FLOWTABLE(mdev, cap) \
+ 	MLX5_GET(flow_table_nic_cap, mdev->hca_caps_cur[MLX5_CAP_FLOW_TABLE], cap)
+ 
+ #define MLX5_CAP_FLOWTABLE_MAX(mdev, cap) \
+ 	MLX5_GET(flow_table_nic_cap, mdev->hca_caps_max[MLX5_CAP_FLOW_TABLE], cap)
+ 
+ #define MLX5_CAP_ODP(mdev, cap)\
+ 	MLX5_GET(odp_cap, mdev->hca_caps_cur[MLX5_CAP_ODP], cap)
+ 
+ enum {
+ 	MLX5_CMD_STAT_OK			= 0x0,
+ 	MLX5_CMD_STAT_INT_ERR			= 0x1,
+ 	MLX5_CMD_STAT_BAD_OP_ERR		= 0x2,
+ 	MLX5_CMD_STAT_BAD_PARAM_ERR		= 0x3,
+ 	MLX5_CMD_STAT_BAD_SYS_STATE_ERR		= 0x4,
+ 	MLX5_CMD_STAT_BAD_RES_ERR		= 0x5,
+ 	MLX5_CMD_STAT_RES_BUSY			= 0x6,
+ 	MLX5_CMD_STAT_LIM_ERR			= 0x8,
+ 	MLX5_CMD_STAT_BAD_RES_STATE_ERR		= 0x9,
+ 	MLX5_CMD_STAT_IX_ERR			= 0xa,
+ 	MLX5_CMD_STAT_NO_RES_ERR		= 0xf,
+ 	MLX5_CMD_STAT_BAD_INP_LEN_ERR		= 0x50,
+ 	MLX5_CMD_STAT_BAD_OUTP_LEN_ERR		= 0x51,
+ 	MLX5_CMD_STAT_BAD_QP_STATE_ERR		= 0x10,
+ 	MLX5_CMD_STAT_BAD_PKT_ERR		= 0x30,
+ 	MLX5_CMD_STAT_BAD_SIZE_OUTS_CQES_ERR	= 0x40,
+ };
+ 
+ static inline u16 mlx5_to_sw_pkey_sz(int pkey_sz)
+ {
+ 	if (pkey_sz > MLX5_MAX_LOG_PKEY_TABLE)
+ 		return 0;
+ 	return MLX5_MIN_PKEY_TABLE_SIZE << pkey_sz;
+ }
+ 
++>>>>>>> 707c4602cda6 (net/mlx5_core: Add new query HCA vport commands)
  #endif /* MLX5_DEVICE_H */
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/Makefile
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/vport.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/vport.h
* Unmerged path include/linux/mlx5/device.h
diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index ee45556daa8c..1019fefe7a9a 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -595,6 +595,41 @@ struct mlx5_pas {
 	u8	log_sz;
 };
 
+enum port_state_policy {
+	MLX5_AAA_000
+};
+
+enum phy_port_state {
+	MLX5_AAA_111
+};
+
+struct mlx5_hca_vport_context {
+	u32			field_select;
+	bool			sm_virt_aware;
+	bool			has_smi;
+	bool			has_raw;
+	enum port_state_policy	policy;
+	enum phy_port_state	phys_state;
+	enum ib_port_state	vport_state;
+	u8			port_physical_state;
+	u64			sys_image_guid;
+	u64			port_guid;
+	u64			node_guid;
+	u32			cap_mask1;
+	u32			cap_mask1_perm;
+	u32			cap_mask2;
+	u32			cap_mask2_perm;
+	u16			lid;
+	u8			init_type_reply; /* bitmask: see ib spec 14.2.5.6 InitTypeReply */
+	u8			lmc;
+	u8			subnet_timeout;
+	u16			sm_lid;
+	u8			sm_sl;
+	u16			qkey_violation_counter;
+	u16			pkey_violation_counter;
+	bool			grh_required;
+};
+
 static inline void *mlx5_buf_offset(struct mlx5_buf *buf, int offset)
 {
 		return buf->direct.buf + offset;
@@ -833,4 +868,14 @@ struct mlx5_profile {
 	} mr_cache[MAX_MR_CACHE_ENTRIES];
 };
 
+static inline int mlx5_get_gid_table_len(u16 param)
+{
+	if (param > 4) {
+		pr_warn("gid table length is zero\n");
+		return 0;
+	}
+
+	return 8 * (1 << param);
+}
+
 #endif /* MLX5_DRIVER_H */
diff --git a/include/linux/mlx5/mlx5_ifc.h b/include/linux/mlx5/mlx5_ifc.h
index b27e9f6e090a..16b9857dc280 100644
--- a/include/linux/mlx5/mlx5_ifc.h
+++ b/include/linux/mlx5/mlx5_ifc.h
@@ -2224,12 +2224,15 @@ struct mlx5_ifc_hca_vport_context_bits {
 	u8         has_smi[0x1];
 	u8         has_raw[0x1];
 	u8         grh_required[0x1];
-	u8         reserved_1[0x10];
-	u8         port_state_policy[0x4];
-	u8         phy_port_state[0x4];
+	u8         reserved_1[0xc];
+	u8         port_physical_state[0x4];
+	u8         vport_state_policy[0x4];
+	u8         port_state[0x4];
 	u8         vport_state[0x4];
 
-	u8         reserved_2[0x60];
+	u8         reserved_2[0x20];
+
+	u8         system_image_guid[0x40];
 
 	u8         port_guid[0x40];
 
@@ -3493,7 +3496,8 @@ struct mlx5_ifc_query_hca_vport_pkey_in_bits {
 	u8         op_mod[0x10];
 
 	u8         other_vport[0x1];
-	u8         reserved_2[0xf];
+	u8         reserved_2[0xb];
+	u8         port_num[0x4];
 	u8         vport_number[0x10];
 
 	u8         reserved_3[0x10];
@@ -3522,7 +3526,8 @@ struct mlx5_ifc_query_hca_vport_gid_in_bits {
 	u8         op_mod[0x10];
 
 	u8         other_vport[0x1];
-	u8         reserved_2[0xf];
+	u8         reserved_2[0xb];
+	u8         port_num[0x4];
 	u8         vport_number[0x10];
 
 	u8         reserved_3[0x10];
@@ -3548,7 +3553,8 @@ struct mlx5_ifc_query_hca_vport_context_in_bits {
 	u8         op_mod[0x10];
 
 	u8         other_vport[0x1];
-	u8         reserved_2[0xf];
+	u8         reserved_2[0xb];
+	u8         port_num[0x4];
 	u8         vport_number[0x10];
 
 	u8         reserved_3[0x20];
@@ -4239,7 +4245,8 @@ struct mlx5_ifc_modify_hca_vport_context_in_bits {
 	u8         op_mod[0x10];
 
 	u8         other_vport[0x1];
-	u8         reserved_2[0xf];
+	u8         reserved_2[0xb];
+	u8         port_num[0x4];
 	u8         vport_number[0x10];
 
 	u8         reserved_3[0x20];
