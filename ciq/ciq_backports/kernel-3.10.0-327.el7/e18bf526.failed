perf/x86/intel: Allocate space for storing LBR stack

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [perf] x86/intel: Allocate space for storing LBR stack (Jiri Olsa) [1222189]
Rebuild_FUZZ: 94.95%
commit-author Yan, Zheng <zheng.z.yan@intel.com>
commit e18bf526422769611e7248135e36a4cea0e4e38d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/e18bf526.failed

When the LBR call stack is enabled, it is necessary to save/restore
the LBR stack on context switch. We can use pmu specific data to
store LBR stack when task is scheduled out. This patch adds code
that allocates the pmu specific data.

	Signed-off-by: Yan, Zheng <zheng.z.yan@intel.com>
	Signed-off-by: Kan Liang <kan.liang@intel.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Reviewed-by: Stephane Eranian <eranian@google.com>
	Cc: Andy Lutomirski <luto@amacapital.net>
	Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Paul Mackerras <paulus@samba.org>
	Cc: Vince Weaver <vincent.weaver@maine.edu>
	Cc: jolsa@redhat.com
Link: http://lkml.kernel.org/r/1415156173-10035-8-git-send-email-kan.liang@intel.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit e18bf526422769611e7248135e36a4cea0e4e38d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/perf_event.c
diff --cc arch/x86/kernel/cpu/perf_event.c
index bcdabcaa6d7a,8ffd71ec2173..000000000000
--- a/arch/x86/kernel/cpu/perf_event.c
+++ b/arch/x86/kernel/cpu/perf_event.c
@@@ -1919,14 -1952,19 +1922,19 @@@ static struct pmu pmu = 
  	.commit_txn		= x86_pmu_commit_txn,
  
  	.event_idx		= x86_pmu_event_idx,
++<<<<<<< HEAD
 +	.flush_branch_stack	= x86_pmu_flush_branch_stack,
++=======
+ 	.sched_task		= x86_pmu_sched_task,
+ 	.task_ctx_size          = sizeof(struct x86_perf_task_context),
++>>>>>>> e18bf5264227 (perf/x86/intel: Allocate space for storing LBR stack)
  };
  
 -void arch_perf_update_userpage(struct perf_event *event,
 -			       struct perf_event_mmap_page *userpg, u64 now)
 +void arch_perf_update_userpage(struct perf_event_mmap_page *userpg, u64 now)
  {
 -	struct cyc2ns_data *data;
 -
  	userpg->cap_user_time = 0;
  	userpg->cap_user_time_zero = 0;
 -	userpg->cap_user_rdpmc =
 -		!!(event->hw.flags & PERF_X86_EVENT_RDPMC_ALLOWED);
 +	userpg->cap_user_rdpmc = x86_pmu.attr_rdpmc;
  	userpg->pmc_width = x86_pmu.cntval_bits;
  
  	if (!sched_clock_stable())
* Unmerged path arch/x86/kernel/cpu/perf_event.c
diff --git a/arch/x86/kernel/cpu/perf_event.h b/arch/x86/kernel/cpu/perf_event.h
index 9c09927edc5c..179e34bc08d0 100644
--- a/arch/x86/kernel/cpu/perf_event.h
+++ b/arch/x86/kernel/cpu/perf_event.h
@@ -514,6 +514,13 @@ struct x86_pmu {
 	struct perf_guest_switch_msr *(*guest_get_msrs)(int *nr);
 };
 
+struct x86_perf_task_context {
+	u64 lbr_from[MAX_LBR_ENTRIES];
+	u64 lbr_to[MAX_LBR_ENTRIES];
+	int lbr_callstack_users;
+	int lbr_stack_state;
+};
+
 enum {
 	PERF_SAMPLE_BRANCH_CALL_STACK_SHIFT = PERF_SAMPLE_BRANCH_MAX_SHIFT,
 	PERF_SAMPLE_BRANCH_SELECT_MAP_SIZE,
