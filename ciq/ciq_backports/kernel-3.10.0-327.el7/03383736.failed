hpsa: honor queue depth of physical devices

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Don Brace <don.brace@pmcs.com>
commit 03383736348bb73a45f8460afca3c5f5bd1be172
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/03383736.failed

When using the ioaccel submission methods, requests destined for RAID volumes
are sometimes diverted to physical devices.  The OS has no or limited
knowledge of these physical devices, so it is up to the driver to avoid
pushing the device too hard.  It is better to honor the physical device queue
limit rather than making the device spew zillions of TASK SET FULL responses.

This is so that hpsa based devices support /sys/block/sdNN/device/queue_type
of simple, which lets the SCSI midlayer automatically adjust the queue_depth
based on TASK SET FULL and GOOD status.

Adjust the queue depth for a new device after it is created based on the
maximum queue depths of the physical devices that constitute the
device. This drops the maximum queue depth from .can_queue of 1024 to
something like 174 for single-drive RAID-0, 348 for two-drive RAID-1, etc.
It also adjusts for the ratio of data to parity drives.

	Reviewed-by: Scott Teel <scott.teel@pmcs.com>
	Signed-off-by: Webb Scales <webbnh@hp.com>
	Signed-off-by: Don Brace <don.brace@pmcs.com>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
(cherry picked from commit 03383736348bb73a45f8460afca3c5f5bd1be172)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/hpsa.c
#	drivers/scsi/hpsa_cmd.h
diff --cc drivers/scsi/hpsa.c
index 3e784c38914c,60f57347d53b..000000000000
--- a/drivers/scsi/hpsa.c
+++ b/drivers/scsi/hpsa.c
@@@ -256,7 -247,8 +256,12 @@@ static void hpsa_drain_accel_commands(s
  static void hpsa_flush_cache(struct ctlr_info *h);
  static int hpsa_scsi_ioaccel_queue_command(struct ctlr_info *h,
  	struct CommandList *c, u32 ioaccel_handle, u8 *cdb, int cdb_len,
++<<<<<<< HEAD
 +	u8 *scsi3addr);
++=======
+ 	u8 *scsi3addr, struct hpsa_scsi_dev_t *phys_disk);
+ static void hpsa_command_resubmit_worker(struct work_struct *work);
++>>>>>>> 03383736348b (hpsa: honor queue depth of physical devices)
  
  static inline struct ctlr_info *sdev_to_hba(struct scsi_device *sdev)
  {
@@@ -3814,71 -3974,18 +3991,72 @@@ static int hpsa_scsi_ioaccel_raid_map(s
  		cdb_len = 10;
  	}
  	return hpsa_scsi_ioaccel_queue_command(h, c, disk_handle, cdb, cdb_len,
- 						dev->scsi3addr);
+ 						dev->scsi3addr,
+ 						dev->phys_disk[map_index]);
  }
  
 -/* Submit commands down the "normal" RAID stack path */
 -static int hpsa_ciss_submit(struct ctlr_info *h,
 -	struct CommandList *c, struct scsi_cmnd *cmd,
 -	unsigned char scsi3addr[])
 +/* Running in struct Scsi_Host->host_lock less mode */
 +static int hpsa_scsi_queue_command(struct Scsi_Host *sh, struct scsi_cmnd *cmd)
  {
 +	struct ctlr_info *h;
 +	struct hpsa_scsi_dev_t *dev;
 +	unsigned char scsi3addr[8];
 +	struct CommandList *c;
 +	int rc = 0;
 +
 +	/* Get the ptr to our adapter structure out of cmd->host. */
 +	h = sdev_to_hba(cmd->device);
 +	dev = cmd->device->hostdata;
 +	if (!dev) {
 +		cmd->result = DID_NO_CONNECT << 16;
 +		cmd->scsi_done(cmd);
 +		return 0;
 +	}
 +	memcpy(scsi3addr, dev->scsi3addr, sizeof(scsi3addr));
 +
 +	if (unlikely(lockup_detected(h))) {
 +		cmd->result = DID_ERROR << 16;
 +		cmd->scsi_done(cmd);
 +		return 0;
 +	}
 +	c = cmd_alloc(h);
 +	if (c == NULL) {			/* trouble... */
 +		dev_err(&h->pdev->dev, "cmd_alloc returned NULL!\n");
 +		return SCSI_MLQUEUE_HOST_BUSY;
 +	}
 +
 +	/* Fill in the command list header */
 +	/* save c in case we have to abort it  */
  	cmd->host_scribble = (unsigned char *) c;
 +
  	c->cmd_type = CMD_SCSI;
  	c->scsi_cmd = cmd;
 +
 +	/* Call alternate submit routine for I/O accelerated commands.
 +	 * Retries always go down the normal I/O path.
 +	 */
 +	if (likely(cmd->retries == 0 &&
 +		cmd->request->cmd_type == REQ_TYPE_FS &&
 +		h->acciopath_status)) {
 +		if (dev->offload_enabled) {
 +			rc = hpsa_scsi_ioaccel_raid_map(h, c);
 +			if (rc == 0)
 +				return 0; /* Sent on ioaccel path */
 +			if (rc < 0) {   /* scsi_dma_map failed. */
 +				cmd_free(h, c);
 +				return SCSI_MLQUEUE_HOST_BUSY;
 +			}
 +		} else if (dev->ioaccel_handle) {
 +			rc = hpsa_scsi_ioaccel_direct_map(h, c);
 +			if (rc == 0)
 +				return 0; /* Sent on direct map path */
 +			if (rc < 0) {   /* scsi_dma_map failed. */
 +				cmd_free(h, c);
 +				return SCSI_MLQUEUE_HOST_BUSY;
 +			}
 +		}
 +	}
 +
  	c->Header.ReplyQueue = 0;  /* unused in simple mode */
  	memcpy(&c->Header.LUN.LunAddrBytes[0], &scsi3addr[0], 8);
  	c->Header.tag = cpu_to_le64((c->cmdindex << DIRECT_LOOKUP_SHIFT));
@@@ -3993,6 -4187,21 +4171,24 @@@ static void hpsa_scan_start(struct Scsi
  	spin_unlock_irqrestore(&h->scan_lock, flags);
  }
  
++<<<<<<< HEAD
++=======
+ static int hpsa_change_queue_depth(struct scsi_device *sdev, int qdepth)
+ {
+ 	struct hpsa_scsi_dev_t *logical_drive = sdev->hostdata;
+ 
+ 	if (!logical_drive)
+ 		return -ENODEV;
+ 
+ 	if (qdepth < 1)
+ 		qdepth = 1;
+ 	else if (qdepth > logical_drive->queue_depth)
+ 		qdepth = logical_drive->queue_depth;
+ 
+ 	return scsi_change_queue_depth(sdev, qdepth);
+ }
+ 
++>>>>>>> 03383736348b (hpsa: honor queue depth of physical devices)
  static int hpsa_scan_finished(struct Scsi_Host *sh,
  	unsigned long elapsed_time)
  {
diff --cc drivers/scsi/hpsa_cmd.h
index d78e66629650,4726dbb67fa3..000000000000
--- a/drivers/scsi/hpsa_cmd.h
+++ b/drivers/scsi/hpsa_cmd.h
@@@ -404,6 -409,18 +409,21 @@@ struct CommandList 
  	long			   cmdindex;
  	struct completion *waiting;
  	void   *scsi_cmd;
++<<<<<<< HEAD
++=======
+ 	struct work_struct work;
+ 
+ 	/*
+ 	 * For commands using either of the two "ioaccel" paths to
+ 	 * bypass the RAID stack and go directly to the physical disk
+ 	 * phys_disk is a pointer to the hpsa_scsi_dev_t to which the
+ 	 * i/o is destined.  We need to store that here because the command
+ 	 * may potentially encounter TASK SET FULL and need to be resubmitted
+ 	 * For "normal" i/o's not using the "ioaccel" paths, phys_disk is
+ 	 * not used.
+ 	 */
+ 	struct hpsa_scsi_dev_t *phys_disk;
++>>>>>>> 03383736348b (hpsa: honor queue depth of physical devices)
  } __aligned(COMMANDLIST_ALIGNMENT);
  
  /* Max S/G elements in I/O accelerator command */
* Unmerged path drivers/scsi/hpsa.c
diff --git a/drivers/scsi/hpsa.h b/drivers/scsi/hpsa.h
index b105d9492e11..1d530236f26a 100644
--- a/drivers/scsi/hpsa.h
+++ b/drivers/scsi/hpsa.h
@@ -46,6 +46,11 @@ struct hpsa_scsi_dev_t {
 	unsigned char model[16];        /* bytes 16-31 of inquiry data */
 	unsigned char raid_level;	/* from inquiry page 0xC1 */
 	unsigned char volume_offline;	/* discovered via TUR or VPD */
+	u16 queue_depth;		/* max queue_depth for this device */
+	atomic_t ioaccel_cmds_out;	/* Only used for physical devices
+					 * counts commands sent to physical
+					 * device via "ioaccel" path.
+					 */
 	u32 ioaccel_handle;
 	int offload_config;		/* I/O accel RAID offload configured */
 	int offload_enabled;		/* I/O accel RAID offload enabled */
@@ -54,6 +59,15 @@ struct hpsa_scsi_dev_t {
 					 */
 	struct raid_map_data raid_map;	/* I/O accelerator RAID map */
 
+	/*
+	 * Pointers from logical drive map indices to the phys drives that
+	 * make those logical drives.  Note, multiple logical drives may
+	 * share physical drives.  You can have for instance 5 physical
+	 * drives with 3 logical drives each using those same 5 physical
+	 * disks. We need these pointers for counting i/o's out to physical
+	 * devices in order to honor physical device queue depth limits.
+	 */
+	struct hpsa_scsi_dev_t *phys_disk[RAID_MAP_MAX_ENTRIES];
 };
 
 struct reply_queue_buffer {
* Unmerged path drivers/scsi/hpsa_cmd.h
