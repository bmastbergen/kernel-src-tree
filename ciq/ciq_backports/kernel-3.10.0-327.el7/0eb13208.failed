powerpc/powernv: Restore LPCR with LPCR_PECE1 cleared

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [powerpc] powernv: Restore LPCR with LPCR_PECE1 cleared (Gustavo Duarte) [1193516]
Rebuild_FUZZ: 91.84%
commit-author Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
commit 0eb13208aa16ca5517835ea8f3feef091a13b984
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/0eb13208.failed

LPCR_PECE1 bit controls whether decrementer interrupts are allowed to
cause exit from power-saving mode. While waking up from winkle, restoring
LPCR with LPCR_PECE1 set (i.e Decrementer interrupts allowed) can cause
issue in the following scenario:

- All the threads in a core are offlined. The core enters deep winkle.
- Spurious interrupt wakes up a thread in the core. Here LPCR is restored
  with LPCR_PECE1 bit set.
- Since it was a spurious interrupt on a offline thread, the thread clears
  the interrupt and goes back to winkle.
- Here before the thread executes winkle and puts the core into deep winkle,
  if a decrementer interrupt occurs on any of the sibling threads in the core
  that thread wakes up.
- Since in offline loop we are flushing interrupt only in case of external
  interrupt, the decrementer interrupt does not get flushed. So at this stage
  the thread is stuck in this is loop of waking up at 0x100 due to decrementer
  interrupt, not flushing the interrupt as only external interrupts get flushed,
  entering winkle, waking up at 0x100 again.

Fix this by programming PORE to restore LPCR with LPCR_PECE1 bit
cleared when waking up from winkle.

	Signed-off-by: Shreyas B. Prabhu <shreyas@linux.vnet.ibm.com>
	Cc: Paul Mackerras <paulus@samba.org>
	Cc: Benjamin Herrenschmidt <benh@kernel.crashing.org>
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
(cherry picked from commit 0eb13208aa16ca5517835ea8f3feef091a13b984)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/platforms/powernv/setup.c
diff --cc arch/powerpc/platforms/powernv/setup.c
index d9b88fa7c5a3,d2de7d5d7574..000000000000
--- a/arch/powerpc/platforms/powernv/setup.c
+++ b/arch/powerpc/platforms/powernv/setup.c
@@@ -280,6 -292,168 +280,171 @@@ static void __init pnv_setup_machdep_rt
  }
  #endif /* CONFIG_PPC_POWERNV_RTAS */
  
++<<<<<<< HEAD
++=======
+ static u32 supported_cpuidle_states;
+ 
+ int pnv_save_sprs_for_winkle(void)
+ {
+ 	int cpu;
+ 	int rc;
+ 
+ 	/*
+ 	 * hid0, hid1, hid4, hid5, hmeer and lpcr values are symmetric accross
+ 	 * all cpus at boot. Get these reg values of current cpu and use the
+ 	 * same accross all cpus.
+ 	 */
+ 	uint64_t lpcr_val = mfspr(SPRN_LPCR) & ~(u64)LPCR_PECE1;
+ 	uint64_t hid0_val = mfspr(SPRN_HID0);
+ 	uint64_t hid1_val = mfspr(SPRN_HID1);
+ 	uint64_t hid4_val = mfspr(SPRN_HID4);
+ 	uint64_t hid5_val = mfspr(SPRN_HID5);
+ 	uint64_t hmeer_val = mfspr(SPRN_HMEER);
+ 
+ 	for_each_possible_cpu(cpu) {
+ 		uint64_t pir = get_hard_smp_processor_id(cpu);
+ 		uint64_t hsprg0_val = (uint64_t)&paca[cpu];
+ 
+ 		/*
+ 		 * HSPRG0 is used to store the cpu's pointer to paca. Hence last
+ 		 * 3 bits are guaranteed to be 0. Program slw to restore HSPRG0
+ 		 * with 63rd bit set, so that when a thread wakes up at 0x100 we
+ 		 * can use this bit to distinguish between fastsleep and
+ 		 * deep winkle.
+ 		 */
+ 		hsprg0_val |= 1;
+ 
+ 		rc = opal_slw_set_reg(pir, SPRN_HSPRG0, hsprg0_val);
+ 		if (rc != 0)
+ 			return rc;
+ 
+ 		rc = opal_slw_set_reg(pir, SPRN_LPCR, lpcr_val);
+ 		if (rc != 0)
+ 			return rc;
+ 
+ 		/* HIDs are per core registers */
+ 		if (cpu_thread_in_core(cpu) == 0) {
+ 
+ 			rc = opal_slw_set_reg(pir, SPRN_HMEER, hmeer_val);
+ 			if (rc != 0)
+ 				return rc;
+ 
+ 			rc = opal_slw_set_reg(pir, SPRN_HID0, hid0_val);
+ 			if (rc != 0)
+ 				return rc;
+ 
+ 			rc = opal_slw_set_reg(pir, SPRN_HID1, hid1_val);
+ 			if (rc != 0)
+ 				return rc;
+ 
+ 			rc = opal_slw_set_reg(pir, SPRN_HID4, hid4_val);
+ 			if (rc != 0)
+ 				return rc;
+ 
+ 			rc = opal_slw_set_reg(pir, SPRN_HID5, hid5_val);
+ 			if (rc != 0)
+ 				return rc;
+ 		}
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void pnv_alloc_idle_core_states(void)
+ {
+ 	int i, j;
+ 	int nr_cores = cpu_nr_cores();
+ 	u32 *core_idle_state;
+ 
+ 	/*
+ 	 * core_idle_state - First 8 bits track the idle state of each thread
+ 	 * of the core. The 8th bit is the lock bit. Initially all thread bits
+ 	 * are set. They are cleared when the thread enters deep idle state
+ 	 * like sleep and winkle. Initially the lock bit is cleared.
+ 	 * The lock bit has 2 purposes
+ 	 * a. While the first thread is restoring core state, it prevents
+ 	 * other threads in the core from switching to process context.
+ 	 * b. While the last thread in the core is saving the core state, it
+ 	 * prevents a different thread from waking up.
+ 	 */
+ 	for (i = 0; i < nr_cores; i++) {
+ 		int first_cpu = i * threads_per_core;
+ 		int node = cpu_to_node(first_cpu);
+ 
+ 		core_idle_state = kmalloc_node(sizeof(u32), GFP_KERNEL, node);
+ 		*core_idle_state = PNV_CORE_IDLE_THREAD_BITS;
+ 
+ 		for (j = 0; j < threads_per_core; j++) {
+ 			int cpu = first_cpu + j;
+ 
+ 			paca[cpu].core_idle_state_ptr = core_idle_state;
+ 			paca[cpu].thread_idle_state = PNV_THREAD_RUNNING;
+ 			paca[cpu].thread_mask = 1 << j;
+ 		}
+ 	}
+ 
+ 	update_subcore_sibling_mask();
+ 
+ 	if (supported_cpuidle_states & OPAL_PM_WINKLE_ENABLED)
+ 		pnv_save_sprs_for_winkle();
+ }
+ 
+ u32 pnv_get_supported_cpuidle_states(void)
+ {
+ 	return supported_cpuidle_states;
+ }
+ EXPORT_SYMBOL_GPL(pnv_get_supported_cpuidle_states);
+ 
+ static int __init pnv_init_idle_states(void)
+ {
+ 	struct device_node *power_mgt;
+ 	int dt_idle_states;
+ 	const __be32 *idle_state_flags;
+ 	u32 len_flags, flags;
+ 	int i;
+ 
+ 	supported_cpuidle_states = 0;
+ 
+ 	if (cpuidle_disable != IDLE_NO_OVERRIDE)
+ 		return 0;
+ 
+ 	if (!firmware_has_feature(FW_FEATURE_OPALv3))
+ 		return 0;
+ 
+ 	power_mgt = of_find_node_by_path("/ibm,opal/power-mgt");
+ 	if (!power_mgt) {
+ 		pr_warn("opal: PowerMgmt Node not found\n");
+ 		return 0;
+ 	}
+ 
+ 	idle_state_flags = of_get_property(power_mgt,
+ 			"ibm,cpu-idle-state-flags", &len_flags);
+ 	if (!idle_state_flags) {
+ 		pr_warn("DT-PowerMgmt: missing ibm,cpu-idle-state-flags\n");
+ 		return 0;
+ 	}
+ 
+ 	dt_idle_states = len_flags / sizeof(u32);
+ 
+ 	for (i = 0; i < dt_idle_states; i++) {
+ 		flags = be32_to_cpu(idle_state_flags[i]);
+ 		supported_cpuidle_states |= flags;
+ 	}
+ 	if (!(supported_cpuidle_states & OPAL_PM_SLEEP_ENABLED_ER1)) {
+ 		patch_instruction(
+ 			(unsigned int *)pnv_fastsleep_workaround_at_entry,
+ 			PPC_INST_NOP);
+ 		patch_instruction(
+ 			(unsigned int *)pnv_fastsleep_workaround_at_exit,
+ 			PPC_INST_NOP);
+ 	}
+ 	pnv_alloc_idle_core_states();
+ 	return 0;
+ }
+ 
+ subsys_initcall(pnv_init_idle_states);
+ 
++>>>>>>> 0eb13208aa16 (powerpc/powernv: Restore LPCR with LPCR_PECE1 cleared)
  static int __init pnv_probe(void)
  {
  	unsigned long root = of_get_flat_dt_root();
* Unmerged path arch/powerpc/platforms/powernv/setup.c
