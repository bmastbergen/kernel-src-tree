xfs: xfs_file_collapse_range is delalloc challenged

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Dave Chinner <dchinner@redhat.com>
commit 1669a8ca2105968f660cf7d84ba38fd18075cd99
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/1669a8ca.failed

If we have delalloc extents on a file before we run a collapse range
opertaion, we sync the range that we are going to collapse to
convert delalloc extents in that region to real extents to simplify
the shift operation.

However, the shift operation then assumes that the extent list is
not going to change as it iterates over the extent list moving
things about. Unfortunately, this isn't true because we can't hold
the ILOCK over all the operations. We can prevent new IO from
modifying the extent list by holding the IOLOCK, but that doesn't
prevent writeback from running....

And when writeback runs, it can convert delalloc extents is the
range of the file prior to the region being collapsed, and this
changes the indexes of all the extents in the file. That causes the
collapse range operation to Go Bad.

The right fix is to rewrite the extent shift operation not to be
dependent on the extent list not changing across the entire
operation, but this is a fairly significant piece of work to do.
Hence, as a short-term workaround for the problem, sync the entire
file before starting a collapse operation to remove all delalloc
ranges from the file and so avoid the problem of concurrent
writeback changing the extent list.

Diagnosed-and-Reported-by: Brian Foster <bfoster@redhat.com>
	Signed-off-by: Dave Chinner <dchinner@redhat.com>
	Reviewed-by: Brian Foster <bfoster@redhat.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Dave Chinner <david@fromorbit.com>



(cherry picked from commit 1669a8ca2105968f660cf7d84ba38fd18075cd99)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/xfs_bmap_util.c
diff --cc fs/xfs/xfs_bmap_util.c
index e2ea28ff57bf,76b6a2910e40..000000000000
--- a/fs/xfs/xfs_bmap_util.c
+++ b/fs/xfs/xfs_bmap_util.c
@@@ -1436,6 -1435,113 +1436,116 @@@ out
  }
  
  /*
++<<<<<<< HEAD
++=======
+  * xfs_collapse_file_space()
+  *	This routine frees disk space and shift extent for the given file.
+  *	The first thing we do is to free data blocks in the specified range
+  *	by calling xfs_free_file_space(). It would also sync dirty data
+  *	and invalidate page cache over the region on which collapse range
+  *	is working. And Shift extent records to the left to cover a hole.
+  * RETURNS:
+  *	0 on success
+  *	errno on error
+  *
+  */
+ int
+ xfs_collapse_file_space(
+ 	struct xfs_inode	*ip,
+ 	xfs_off_t		offset,
+ 	xfs_off_t		len)
+ {
+ 	int			done = 0;
+ 	struct xfs_mount	*mp = ip->i_mount;
+ 	struct xfs_trans	*tp;
+ 	int			error;
+ 	xfs_extnum_t		current_ext = 0;
+ 	struct xfs_bmap_free	free_list;
+ 	xfs_fsblock_t		first_block;
+ 	int			committed;
+ 	xfs_fileoff_t		start_fsb;
+ 	xfs_fileoff_t		shift_fsb;
+ 
+ 	ASSERT(xfs_isilocked(ip, XFS_IOLOCK_EXCL));
+ 
+ 	trace_xfs_collapse_file_space(ip);
+ 
+ 	start_fsb = XFS_B_TO_FSB(mp, offset + len);
+ 	shift_fsb = XFS_B_TO_FSB(mp, len);
+ 
+ 	/*
+ 	 * writeback the entire file to prevent concurrent writeback of ranges
+ 	 * outside the collapsing region from changing the extent list.
+ 	 *
+ 	 * XXX: This is a temporary fix until the extent shift loop below is
+ 	 * converted to use offsets and lookups within the ILOCK rather than
+ 	 * carrying around the index into the extent list for the next
+ 	 * iteration.
+ 	 */
+ 	error = filemap_write_and_wait(VFS_I(ip)->i_mapping);
+ 	if (error)
+ 		return error;
+ 
+ 	error = xfs_free_file_space(ip, offset, len);
+ 	if (error)
+ 		return error;
+ 
+ 	while (!error && !done) {
+ 		tp = xfs_trans_alloc(mp, XFS_TRANS_DIOSTRAT);
+ 		/*
+ 		 * We would need to reserve permanent block for transaction.
+ 		 * This will come into picture when after shifting extent into
+ 		 * hole we found that adjacent extents can be merged which
+ 		 * may lead to freeing of a block during record update.
+ 		 */
+ 		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_write,
+ 				XFS_DIOSTRAT_SPACE_RES(mp, 0), 0);
+ 		if (error) {
+ 			xfs_trans_cancel(tp, 0);
+ 			break;
+ 		}
+ 
+ 		xfs_ilock(ip, XFS_ILOCK_EXCL);
+ 		error = xfs_trans_reserve_quota(tp, mp, ip->i_udquot,
+ 				ip->i_gdquot, ip->i_pdquot,
+ 				XFS_DIOSTRAT_SPACE_RES(mp, 0), 0,
+ 				XFS_QMOPT_RES_REGBLKS);
+ 		if (error)
+ 			goto out;
+ 
+ 		xfs_trans_ijoin(tp, ip, 0);
+ 
+ 		xfs_bmap_init(&free_list, &first_block);
+ 
+ 		/*
+ 		 * We are using the write transaction in which max 2 bmbt
+ 		 * updates are allowed
+ 		 */
+ 		error = xfs_bmap_shift_extents(tp, ip, &done, start_fsb,
+ 					       shift_fsb, &current_ext,
+ 					       &first_block, &free_list,
+ 					       XFS_BMAP_MAX_SHIFT_EXTENTS);
+ 		if (error)
+ 			goto out;
+ 
+ 		error = xfs_bmap_finish(&tp, &free_list, &committed);
+ 		if (error)
+ 			goto out;
+ 
+ 		error = xfs_trans_commit(tp, XFS_TRANS_RELEASE_LOG_RES);
+ 		xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 	}
+ 
+ 	return error;
+ 
+ out:
+ 	xfs_trans_cancel(tp, XFS_TRANS_RELEASE_LOG_RES | XFS_TRANS_ABORT);
+ 	xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 	return error;
+ }
+ 
+ /*
++>>>>>>> 1669a8ca2105 (xfs: xfs_file_collapse_range is delalloc challenged)
   * We need to check that the format of the data fork in the temporary inode is
   * valid for the target inode before doing the swap. This is not a problem with
   * attr1 because of the fixed fork offset, but attr2 has a dynamically sized
* Unmerged path fs/xfs/xfs_bmap_util.c
