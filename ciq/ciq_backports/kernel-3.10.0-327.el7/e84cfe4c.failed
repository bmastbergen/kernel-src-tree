KVM: x86/vPMU: whitespace and stylistic adjustments in PMU code

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [x86] kvm: vpmu: whitespace and stylistic adjustments in PMU code (Wei Huang) [1076010]
Rebuild_FUZZ: 96.72%
commit-author Wei Huang <wehuang@redhat.com>
commit e84cfe4ce0113a6c5e3bdf70e20a21552ad3a28d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/e84cfe4c.failed

	Signed-off-by: Wei Huang <wei@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit e84cfe4ce0113a6c5e3bdf70e20a21552ad3a28d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/pmu.c
diff --cc arch/x86/kvm/pmu.c
index ed5c6727d1e3,24d213bd42d4..000000000000
--- a/arch/x86/kvm/pmu.c
+++ b/arch/x86/kvm/pmu.c
@@@ -160,9 -162,10 +166,16 @@@ static void stop_counter(struct kvm_pm
  	}
  }
  
++<<<<<<< HEAD
 +static void reprogram_counter(struct kvm_pmc *pmc, u32 type,
 +		unsigned config, bool exclude_user, bool exclude_kernel,
 +		bool intr, bool in_tx, bool in_tx_cp)
++=======
+ static void pmc_reprogram_counter(struct kvm_pmc *pmc, u32 type,
+ 				  unsigned config, bool exclude_user,
+ 				  bool exclude_kernel, bool intr,
+ 				  bool in_tx, bool in_tx_cp)
++>>>>>>> e84cfe4ce011 (KVM: x86/vPMU: whitespace and stylistic adjustments in PMU code)
  {
  	struct perf_event *event;
  	struct perf_event_attr attr = {
@@@ -244,32 -248,32 +258,52 @@@ static void reprogram_gp_counter(struc
  	if (type == PERF_TYPE_RAW)
  		config = eventsel & X86_RAW_EVENT_MASK;
  
++<<<<<<< HEAD
 +	reprogram_counter(pmc, type, config,
 +			!(eventsel & ARCH_PERFMON_EVENTSEL_USR),
 +			!(eventsel & ARCH_PERFMON_EVENTSEL_OS),
 +			eventsel & ARCH_PERFMON_EVENTSEL_INT,
 +			(eventsel & HSW_IN_TX),
 +			(eventsel & HSW_IN_TX_CHECKPOINTED));
++=======
+ 	pmc_reprogram_counter(pmc, type, config,
+ 			      !(eventsel & ARCH_PERFMON_EVENTSEL_USR),
+ 			      !(eventsel & ARCH_PERFMON_EVENTSEL_OS),
+ 			      eventsel & ARCH_PERFMON_EVENTSEL_INT,
+ 			      (eventsel & HSW_IN_TX),
+ 			      (eventsel & HSW_IN_TX_CHECKPOINTED));
++>>>>>>> e84cfe4ce011 (KVM: x86/vPMU: whitespace and stylistic adjustments in PMU code)
  }
  
- static void reprogram_fixed_counter(struct kvm_pmc *pmc, u8 en_pmi, int idx)
+ static void reprogram_fixed_counter(struct kvm_pmc *pmc, u8 ctrl, int idx)
  {
- 	unsigned en = en_pmi & 0x3;
- 	bool pmi = en_pmi & 0x8;
+ 	unsigned en_field = ctrl & 0x3;
+ 	bool pmi = ctrl & 0x8;
  
 -	pmc_stop_counter(pmc);
 +	stop_counter(pmc);
  
++<<<<<<< HEAD
 +	if (!en || !pmc_enabled(pmc))
 +		return;
 +
 +	reprogram_counter(pmc, PERF_TYPE_HARDWARE,
 +			arch_events[fixed_pmc_events[idx]].event_type,
 +			!(en & 0x2), /* exclude user */
 +			!(en & 0x1), /* exclude kernel */
 +			pmi, false, false);
++=======
+ 	if (!en_field || !pmc_is_enabled(pmc))
+ 		return;
+ 
+ 	pmc_reprogram_counter(pmc, PERF_TYPE_HARDWARE,
+ 			      arch_events[fixed_pmc_events[idx]].event_type,
+ 			      !(en_field & 0x2), /* exclude user */
+ 			      !(en_field & 0x1), /* exclude kernel */
+ 			      pmi, false, false);
++>>>>>>> e84cfe4ce011 (KVM: x86/vPMU: whitespace and stylistic adjustments in PMU code)
  }
  
 -static inline u8 fixed_ctrl_field(u64 ctrl, int idx)
 +static inline u8 fixed_en_pmi(u64 ctrl, int idx)
  {
  	return (ctrl >> (idx * 4)) & 0xf;
  }
@@@ -279,21 -283,22 +313,33 @@@ static void reprogram_fixed_counters(st
  	int i;
  
  	for (i = 0; i < pmu->nr_arch_fixed_counters; i++) {
++<<<<<<< HEAD
 +		u8 en_pmi = fixed_en_pmi(data, i);
 +		struct kvm_pmc *pmc = get_fixed_pmc_idx(pmu, i);
 +
 +		if (fixed_en_pmi(pmu->fixed_ctr_ctrl, i) == en_pmi)
++=======
+ 		u8 old_ctrl = fixed_ctrl_field(pmu->fixed_ctr_ctrl, i);
+ 		u8 new_ctrl = fixed_ctrl_field(data, i);
+ 		struct kvm_pmc *pmc = get_fixed_pmc_idx(pmu, i);
+ 
+ 		if (old_ctrl == new_ctrl)
++>>>>>>> e84cfe4ce011 (KVM: x86/vPMU: whitespace and stylistic adjustments in PMU code)
  			continue;
  
- 		reprogram_fixed_counter(pmc, en_pmi, i);
+ 		reprogram_fixed_counter(pmc, new_ctrl, i);
  	}
  
  	pmu->fixed_ctr_ctrl = data;
  }
  
++<<<<<<< HEAD
 +static void reprogram_idx(struct kvm_pmu *pmu, int idx)
++=======
+ static void reprogram_counter(struct kvm_pmu *pmu, int pmc_idx)
++>>>>>>> e84cfe4ce011 (KVM: x86/vPMU: whitespace and stylistic adjustments in PMU code)
  {
- 	struct kvm_pmc *pmc = global_idx_to_pmc(pmu, idx);
+ 	struct kvm_pmc *pmc = global_idx_to_pmc(pmu, pmc_idx);
  
  	if (!pmc)
  		return;
@@@ -301,9 -306,10 +347,16 @@@
  	if (pmc_is_gp(pmc))
  		reprogram_gp_counter(pmc, pmc->eventsel);
  	else {
++<<<<<<< HEAD
 +		int fidx = idx - INTEL_PMC_IDX_FIXED;
 +		reprogram_fixed_counter(pmc,
 +				fixed_en_pmi(pmu->fixed_ctr_ctrl, fidx), fidx);
++=======
+ 		int idx = pmc_idx - INTEL_PMC_IDX_FIXED;
+ 		u8 ctrl = fixed_ctrl_field(pmu->fixed_ctr_ctrl, idx);
+ 
+ 		reprogram_fixed_counter(pmc, ctrl, idx);
++>>>>>>> e84cfe4ce011 (KVM: x86/vPMU: whitespace and stylistic adjustments in PMU code)
  	}
  }
  
@@@ -427,38 -433,44 +480,63 @@@ int kvm_pmu_set_msr(struct kvm_vcpu *vc
  	return 1;
  }
  
++<<<<<<< HEAD
 +int kvm_pmu_check_pmc(struct kvm_vcpu *vcpu, unsigned pmc)
++=======
+ /* check if idx is a valid index to access PMU */
+ int kvm_pmu_is_valid_msr_idx(struct kvm_vcpu *vcpu, unsigned idx)
++>>>>>>> e84cfe4ce011 (KVM: x86/vPMU: whitespace and stylistic adjustments in PMU code)
  {
  	struct kvm_pmu *pmu = vcpu_to_pmu(vcpu);
- 	bool fixed = pmc & (1u << 30);
- 	pmc &= ~(3u << 30);
- 	return (!fixed && pmc >= pmu->nr_arch_gp_counters) ||
- 		(fixed && pmc >= pmu->nr_arch_fixed_counters);
+ 	bool fixed = idx & (1u << 30);
+ 	idx &= ~(3u << 30);
+ 	return (!fixed && idx >= pmu->nr_arch_gp_counters) ||
+ 		(fixed && idx >= pmu->nr_arch_fixed_counters);
  }
  
++<<<<<<< HEAD
 +int kvm_pmu_read_pmc(struct kvm_vcpu *vcpu, unsigned pmc, u64 *data)
++=======
+ int kvm_pmu_rdpmc(struct kvm_vcpu *vcpu, unsigned idx, u64 *data)
++>>>>>>> e84cfe4ce011 (KVM: x86/vPMU: whitespace and stylistic adjustments in PMU code)
  {
  	struct kvm_pmu *pmu = vcpu_to_pmu(vcpu);
- 	bool fast_mode = pmc & (1u << 31);
- 	bool fixed = pmc & (1u << 30);
+ 	bool fast_mode = idx & (1u << 31);
+ 	bool fixed = idx & (1u << 30);
  	struct kvm_pmc *counters;
- 	u64 ctr;
+ 	u64 ctr_val;
  
- 	pmc &= ~(3u << 30);
- 	if (!fixed && pmc >= pmu->nr_arch_gp_counters)
+ 	idx &= ~(3u << 30);
+ 	if (!fixed && idx >= pmu->nr_arch_gp_counters)
  		return 1;
- 	if (fixed && pmc >= pmu->nr_arch_fixed_counters)
+ 	if (fixed && idx >= pmu->nr_arch_fixed_counters)
  		return 1;
  	counters = fixed ? pmu->fixed_counters : pmu->gp_counters;
++<<<<<<< HEAD
 +	ctr = read_pmc(&counters[pmc]);
 +	if (fast_mode)
 +		ctr = (u32)ctr;
 +	*data = ctr;
++=======
++>>>>>>> e84cfe4ce011 (KVM: x86/vPMU: whitespace and stylistic adjustments in PMU code)
  
+ 	ctr_val = pmc_read_counter(&counters[idx]);
+ 	if (fast_mode)
+ 		ctr_val = (u32)ctr_val;
+ 
+ 	*data = ctr_val;
  	return 0;
  }
  
++<<<<<<< HEAD
 +void kvm_pmu_cpuid_update(struct kvm_vcpu *vcpu)
++=======
+ /* refresh PMU settings. This function generally is called when underlying
+  * settings are changed (such as changes of PMU CPUID by guest VMs), which
+  * should rarely happen.
+  */
+ void kvm_pmu_refresh(struct kvm_vcpu *vcpu)
++>>>>>>> e84cfe4ce011 (KVM: x86/vPMU: whitespace and stylistic adjustments in PMU code)
  {
  	struct kvm_pmu *pmu = vcpu_to_pmu(vcpu);
  	struct kvm_cpuid_entry2 *entry;
* Unmerged path arch/x86/kvm/pmu.c
