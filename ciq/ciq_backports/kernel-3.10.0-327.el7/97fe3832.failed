NVMe: fix error return checking from blk_mq_alloc_request()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Jens Axboe <axboe@fb.com>
commit 97fe383222cb8a01fb67a8823498ad2edcc20b35
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/97fe3832.failed

We return an error pointer or the request, not NULL. Half
the call paths got it right, the others didn't. Fix those up.

	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit 97fe383222cb8a01fb67a8823498ad2edcc20b35)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/block/nvme-core.c
diff --cc drivers/block/nvme-core.c
index 48e1152870d9,2cc2cee7a367..000000000000
--- a/drivers/block/nvme-core.c
+++ b/drivers/block/nvme-core.c
@@@ -1068,24 -868,39 +1068,51 @@@ int nvme_submit_async_cmd(struct nvme_q
  	return nvme_submit_cmd(nvmeq, cmd);
  }
  
++<<<<<<< HEAD
++=======
+ static int __nvme_submit_admin_cmd(struct nvme_dev *dev, struct nvme_command *cmd,
+ 						u32 *result, unsigned timeout)
+ {
+ 	int res;
+ 	struct request *req;
+ 
+ 	req = blk_mq_alloc_request(dev->admin_q, WRITE, GFP_KERNEL, false);
+ 	if (IS_ERR(req))
+ 		return PTR_ERR(req);
+ 	res = nvme_submit_sync_cmd(req, cmd, result, timeout);
+ 	blk_mq_free_request(req);
+ 	return res;
+ }
+ 
++>>>>>>> 97fe383222cb (NVMe: fix error return checking from blk_mq_alloc_request())
  int nvme_submit_admin_cmd(struct nvme_dev *dev, struct nvme_command *cmd,
  								u32 *result)
  {
 -	return __nvme_submit_admin_cmd(dev, cmd, result, ADMIN_TIMEOUT);
 +	return nvme_submit_sync_cmd(dev, 0, cmd, result, ADMIN_TIMEOUT);
  }
  
 -int nvme_submit_io_cmd(struct nvme_dev *dev, struct nvme_ns *ns,
 -					struct nvme_command *cmd, u32 *result)
 +int nvme_submit_io_cmd(struct nvme_dev *dev, struct nvme_command *cmd,
 +								u32 *result)
  {
 -	int res;
 -	struct request *req;
 +	return nvme_submit_sync_cmd(dev, this_cpu_read(*dev->io_queue), cmd,
 +						result,	NVME_IO_TIMEOUT);
 +}
  
++<<<<<<< HEAD
 +int nvme_submit_admin_cmd_async(struct nvme_dev *dev, struct nvme_command *cmd,
 +						struct async_cmd_info *cmdinfo)
 +{
 +	return nvme_submit_async_cmd(raw_nvmeq(dev, 0), cmd, cmdinfo,
 +								ADMIN_TIMEOUT);
++=======
+ 	req = blk_mq_alloc_request(ns->queue, WRITE, (GFP_KERNEL|__GFP_WAIT),
+ 									false);
+ 	if (IS_ERR(req))
+ 		return PTR_ERR(req);
+ 	res = nvme_submit_sync_cmd(req, cmd, result, NVME_IO_TIMEOUT);
+ 	blk_mq_free_request(req);
+ 	return res;
++>>>>>>> 97fe383222cb (NVMe: fix error return checking from blk_mq_alloc_request())
  }
  
  static int adapter_delete_queue(struct nvme_dev *dev, u8 opcode, u16 id)
@@@ -1830,13 -1683,23 +1857,30 @@@ static int nvme_user_cmd(struct nvme_de
  
  	timeout = cmd.timeout_ms ? msecs_to_jiffies(cmd.timeout_ms) :
  								ADMIN_TIMEOUT;
 -
  	if (length != cmd.data_len)
  		status = -ENOMEM;
++<<<<<<< HEAD
 +	else if (ioq)
 +		status = nvme_submit_sync_cmd(dev, this_cpu_read(*dev->io_queue), &c,
 +							&cmd.result, timeout);
 +	else
 +		status = nvme_submit_sync_cmd(dev, 0, &c, &cmd.result, timeout);
++=======
+ 	else if (ns) {
+ 		struct request *req;
+ 
+ 		req = blk_mq_alloc_request(ns->queue, WRITE,
+ 						(GFP_KERNEL|__GFP_WAIT), false);
+ 		if (IS_ERR(req))
+ 			status = PTR_ERR(req);
+ 		else {
+ 			status = nvme_submit_sync_cmd(req, &c, &cmd.result,
+ 								timeout);
+ 			blk_mq_free_request(req);
+ 		}
+ 	} else
+ 		status = __nvme_submit_admin_cmd(dev, &c, &cmd.result, timeout);
++>>>>>>> 97fe383222cb (NVMe: fix error return checking from blk_mq_alloc_request())
  
  	if (cmd.data_len) {
  		nvme_unmap_user_pages(dev, cmd.opcode & 1, iod);
* Unmerged path drivers/block/nvme-core.c
