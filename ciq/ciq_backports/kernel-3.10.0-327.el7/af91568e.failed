perf/x86/intel/uncore: Make sure only uncore events are collected

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [x86] perf_event_intel_uncore: Make sure only uncore events are collected (Jiri Olsa) [1066402]
Rebuild_FUZZ: 89.39%
commit-author Jiri Olsa <jolsa@kernel.org>
commit af91568e762d04931dcbdd6bef4655433d8b9418
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/af91568e.failed

The uncore_collect_events functions assumes that event group
might contain only uncore events which is wrong, because it
might contain any type of events.

This bug leads to uncore framework touching 'not' uncore events,
which could end up all sorts of bugs.

One was triggered by Vince's perf fuzzer, when the uncore code
touched breakpoint event private event space as if it was uncore
event and caused BUG:

   BUG: unable to handle kernel paging request at ffffffff82822068
   IP: [<ffffffff81020338>] uncore_assign_events+0x188/0x250
   ...

The code in uncore_assign_events() function was looking for
event->hw.idx data while the event was initialized as a
breakpoint with different members in event->hw union.

This patch forces uncore_collect_events() to collect only uncore
events.

	Reported-by: Vince Weaver <vince@deater.net>
	Signed-off-by: Jiri Olsa <jolsa@redhat.com>
	Cc: Arnaldo Carvalho de Melo <acme@redhat.com>
	Cc: Frederic Weisbecker <fweisbec@gmail.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Stephane Eranian <eranian@google.com>
	Cc: Yan, Zheng <zheng.z.yan@intel.com>
	Cc: <stable@vger.kernel.org>
Link: http://lkml.kernel.org/r/1418243031-20367-2-git-send-email-jolsa@kernel.org
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit af91568e762d04931dcbdd6bef4655433d8b9418)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/perf_event_intel_uncore.c
diff --cc arch/x86/kernel/cpu/perf_event_intel_uncore.c
index ff5f2b552830,e98f68cfea02..000000000000
--- a/arch/x86/kernel/cpu/perf_event_intel_uncore.c
+++ b/arch/x86/kernel/cpu/perf_event_intel_uncore.c
@@@ -2623,43 -268,23 +2623,55 @@@ struct intel_uncore_box *uncore_alloc_b
  	box->cpu = -1;
  	box->phys_id = -1;
  
 -	/* set default hrtimer timeout */
 -	box->hrtimer_duration = UNCORE_PMU_HRTIMER_INTERVAL;
 +	return box;
 +}
 +
++<<<<<<< HEAD
 +static struct intel_uncore_box *
 +uncore_pmu_to_box(struct intel_uncore_pmu *pmu, int cpu)
 +{
 +	struct intel_uncore_box *box;
  
 -	INIT_LIST_HEAD(&box->active_list);
 +	box = *per_cpu_ptr(pmu->box, cpu);
 +	if (box)
 +		return box;
  
 -	return box;
 +	raw_spin_lock(&uncore_box_lock);
 +	list_for_each_entry(box, &pmu->box_list, list) {
 +		if (box->phys_id == topology_physical_package_id(cpu)) {
 +			atomic_inc(&box->refcnt);
 +			*per_cpu_ptr(pmu->box, cpu) = box;
 +			break;
 +		}
 +	}
 +	raw_spin_unlock(&uncore_box_lock);
 +
 +	return *per_cpu_ptr(pmu->box, cpu);
 +}
 +
 +static struct intel_uncore_pmu *uncore_event_to_pmu(struct perf_event *event)
 +{
 +	return container_of(event->pmu, struct intel_uncore_pmu, pmu);
  }
  
 +static struct intel_uncore_box *uncore_event_to_box(struct perf_event *event)
 +{
 +	/*
 +	 * perf core schedules event on the basis of cpu, uncore events are
 +	 * collected by one of the cpus inside a physical package.
 +	 */
 +	return uncore_pmu_to_box(uncore_event_to_pmu(event), smp_processor_id());
++=======
+ /*
+  * Using uncore_pmu_event_init pmu event_init callback
+  * as a detection point for uncore events.
+  */
+ static int uncore_pmu_event_init(struct perf_event *event);
+ 
+ static bool is_uncore_event(struct perf_event *event)
+ {
+ 	return event->pmu->event_init == uncore_pmu_event_init;
++>>>>>>> af91568e762d (perf/x86/intel/uncore: Make sure only uncore events are collected)
  }
  
  static int
* Unmerged path arch/x86/kernel/cpu/perf_event_intel_uncore.c
