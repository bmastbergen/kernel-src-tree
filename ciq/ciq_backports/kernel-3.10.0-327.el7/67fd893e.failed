ethernet/intel: Use napi_alloc_skb

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Alexander Duyck <alexander.h.duyck@redhat.com>
commit 67fd893ee07db94bcef6c7537f8569b49ff124d4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/67fd893e.failed

This change replaces calls to netdev_alloc_skb_ip_align with
napi_alloc_skb.  The advantage of napi_alloc_skb is currently the fact that
the page allocation doesn't make use of any irq disable calls.

There are few spots where I couldn't replace the calls as the buffer
allocation routine is called as a part of init which is outside of the
softirq context.

	Cc: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
	Signed-off-by: Alexander Duyck <alexander.h.duyck@redhat.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 67fd893ee07db94bcef6c7537f8569b49ff124d4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/e1000/e1000_main.c
#	drivers/net/ethernet/intel/fm10k/fm10k_main.c
diff --cc drivers/net/ethernet/intel/e1000/e1000_main.c
index 60bb25c97093,83140cbb5f01..000000000000
--- a/drivers/net/ethernet/intel/e1000/e1000_main.c
+++ b/drivers/net/ethernet/intel/e1000/e1000_main.c
@@@ -3993,6 -4001,113 +3993,116 @@@ static void e1000_receive_skb(struct e1
  }
  
  /**
++<<<<<<< HEAD
++=======
+  * e1000_tbi_adjust_stats
+  * @hw: Struct containing variables accessed by shared code
+  * @frame_len: The length of the frame in question
+  * @mac_addr: The Ethernet destination address of the frame in question
+  *
+  * Adjusts the statistic counters when a frame is accepted by TBI_ACCEPT
+  */
+ static void e1000_tbi_adjust_stats(struct e1000_hw *hw,
+ 				   struct e1000_hw_stats *stats,
+ 				   u32 frame_len, const u8 *mac_addr)
+ {
+ 	u64 carry_bit;
+ 
+ 	/* First adjust the frame length. */
+ 	frame_len--;
+ 	/* We need to adjust the statistics counters, since the hardware
+ 	 * counters overcount this packet as a CRC error and undercount
+ 	 * the packet as a good packet
+ 	 */
+ 	/* This packet should not be counted as a CRC error. */
+ 	stats->crcerrs--;
+ 	/* This packet does count as a Good Packet Received. */
+ 	stats->gprc++;
+ 
+ 	/* Adjust the Good Octets received counters */
+ 	carry_bit = 0x80000000 & stats->gorcl;
+ 	stats->gorcl += frame_len;
+ 	/* If the high bit of Gorcl (the low 32 bits of the Good Octets
+ 	 * Received Count) was one before the addition,
+ 	 * AND it is zero after, then we lost the carry out,
+ 	 * need to add one to Gorch (Good Octets Received Count High).
+ 	 * This could be simplified if all environments supported
+ 	 * 64-bit integers.
+ 	 */
+ 	if (carry_bit && ((stats->gorcl & 0x80000000) == 0))
+ 		stats->gorch++;
+ 	/* Is this a broadcast or multicast?  Check broadcast first,
+ 	 * since the test for a multicast frame will test positive on
+ 	 * a broadcast frame.
+ 	 */
+ 	if (is_broadcast_ether_addr(mac_addr))
+ 		stats->bprc++;
+ 	else if (is_multicast_ether_addr(mac_addr))
+ 		stats->mprc++;
+ 
+ 	if (frame_len == hw->max_frame_size) {
+ 		/* In this case, the hardware has overcounted the number of
+ 		 * oversize frames.
+ 		 */
+ 		if (stats->roc > 0)
+ 			stats->roc--;
+ 	}
+ 
+ 	/* Adjust the bin counters when the extra byte put the frame in the
+ 	 * wrong bin. Remember that the frame_len was adjusted above.
+ 	 */
+ 	if (frame_len == 64) {
+ 		stats->prc64++;
+ 		stats->prc127--;
+ 	} else if (frame_len == 127) {
+ 		stats->prc127++;
+ 		stats->prc255--;
+ 	} else if (frame_len == 255) {
+ 		stats->prc255++;
+ 		stats->prc511--;
+ 	} else if (frame_len == 511) {
+ 		stats->prc511++;
+ 		stats->prc1023--;
+ 	} else if (frame_len == 1023) {
+ 		stats->prc1023++;
+ 		stats->prc1522--;
+ 	} else if (frame_len == 1522) {
+ 		stats->prc1522++;
+ 	}
+ }
+ 
+ static bool e1000_tbi_should_accept(struct e1000_adapter *adapter,
+ 				    u8 status, u8 errors,
+ 				    u32 length, const u8 *data)
+ {
+ 	struct e1000_hw *hw = &adapter->hw;
+ 	u8 last_byte = *(data + length - 1);
+ 
+ 	if (TBI_ACCEPT(hw, status, errors, length, last_byte)) {
+ 		unsigned long irq_flags;
+ 
+ 		spin_lock_irqsave(&adapter->stats_lock, irq_flags);
+ 		e1000_tbi_adjust_stats(hw, &adapter->stats, length, data);
+ 		spin_unlock_irqrestore(&adapter->stats_lock, irq_flags);
+ 
+ 		return true;
+ 	}
+ 
+ 	return false;
+ }
+ 
+ static struct sk_buff *e1000_alloc_rx_skb(struct e1000_adapter *adapter,
+ 					  unsigned int bufsz)
+ {
+ 	struct sk_buff *skb = napi_alloc_skb(&adapter->napi, bufsz);
+ 
+ 	if (unlikely(!skb))
+ 		adapter->alloc_rx_buff_failed++;
+ 	return skb;
+ }
+ 
+ /**
++>>>>>>> 67fd893ee07d (ethernet/intel: Use napi_alloc_skb)
   * e1000_clean_jumbo_rx_irq - Send received data up the network stack; legacy
   * @adapter: board private structure
   * @rx_ring: ring to clean
* Unmerged path drivers/net/ethernet/intel/fm10k/fm10k_main.c
* Unmerged path drivers/net/ethernet/intel/e1000/e1000_main.c
diff --git a/drivers/net/ethernet/intel/e1000e/netdev.c b/drivers/net/ethernet/intel/e1000e/netdev.c
index d2b29b6b6641..bcbf5513c67a 100644
--- a/drivers/net/ethernet/intel/e1000e/netdev.c
+++ b/drivers/net/ethernet/intel/e1000e/netdev.c
@@ -1014,7 +1014,7 @@ static bool e1000_clean_rx_irq(struct e1000_ring *rx_ring, int *work_done,
 		 */
 		if (length < copybreak) {
 			struct sk_buff *new_skb =
-			    netdev_alloc_skb_ip_align(netdev, length);
+				napi_alloc_skb(&adapter->napi, length);
 			if (new_skb) {
 				skb_copy_to_linear_data_offset(new_skb,
 							       -NET_IP_ALIGN,
* Unmerged path drivers/net/ethernet/intel/fm10k/fm10k_main.c
diff --git a/drivers/net/ethernet/intel/igb/igb_main.c b/drivers/net/ethernet/intel/igb/igb_main.c
index 15a626c9978a..70b202eb7d8f 100644
--- a/drivers/net/ethernet/intel/igb/igb_main.c
+++ b/drivers/net/ethernet/intel/igb/igb_main.c
@@ -6645,8 +6645,7 @@ static struct sk_buff *igb_fetch_rx_buffer(struct igb_ring *rx_ring,
 #endif
 
 		/* allocate a skb to store the frags */
-		skb = netdev_alloc_skb_ip_align(rx_ring->netdev,
-						IGB_RX_HDR_LEN);
+		skb = napi_alloc_skb(&rx_ring->q_vector->napi, IGB_RX_HDR_LEN);
 		if (unlikely(!skb)) {
 			rx_ring->rx_stats.alloc_failed++;
 			return NULL;
diff --git a/drivers/net/ethernet/intel/ixgb/ixgb_main.c b/drivers/net/ethernet/intel/ixgb/ixgb_main.c
index fce3e92f9d11..0543324e4c5a 100644
--- a/drivers/net/ethernet/intel/ixgb/ixgb_main.c
+++ b/drivers/net/ethernet/intel/ixgb/ixgb_main.c
@@ -1971,7 +1971,7 @@ ixgb_rx_checksum(struct ixgb_adapter *adapter,
  * this should improve performance for small packets with large amounts
  * of reassembly being done in the stack
  */
-static void ixgb_check_copybreak(struct net_device *netdev,
+static void ixgb_check_copybreak(struct napi_struct *napi,
 				 struct ixgb_buffer *buffer_info,
 				 u32 length, struct sk_buff **skb)
 {
@@ -1980,7 +1980,7 @@ static void ixgb_check_copybreak(struct net_device *netdev,
 	if (length > copybreak)
 		return;
 
-	new_skb = netdev_alloc_skb_ip_align(netdev, length);
+	new_skb = napi_alloc_skb(napi, length);
 	if (!new_skb)
 		return;
 
@@ -2072,7 +2072,7 @@ ixgb_clean_rx_irq(struct ixgb_adapter *adapter, int *work_done, int work_to_do)
 			goto rxdesc_done;
 		}
 
-		ixgb_check_copybreak(netdev, buffer_info, length, &skb);
+		ixgb_check_copybreak(&adapter->napi, buffer_info, length, &skb);
 
 		/* Good Receive */
 		skb_put(skb, length);
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
index b0a004972e7a..9ce201f57542 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
@@ -2006,8 +2006,8 @@ static struct sk_buff *ixgbe_fetch_rx_buffer(struct ixgbe_ring *rx_ring,
 #endif
 
 		/* allocate a skb to store the frags */
-		skb = netdev_alloc_skb_ip_align(rx_ring->netdev,
-						IXGBE_RX_HDR_SIZE);
+		skb = napi_alloc_skb(&rx_ring->q_vector->napi,
+				     IXGBE_RX_HDR_SIZE);
 		if (unlikely(!skb)) {
 			rx_ring->rx_stats.alloc_rx_buff_failed++;
 			return NULL;
