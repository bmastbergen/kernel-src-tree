dm crypt: avoid deadlock in mempools

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [md] dm-crypt: avoid deadlock in mempools (Mike Snitzer) [1205955 752438]
Rebuild_FUZZ: 97.22%
commit-author Mikulas Patocka <mpatocka@redhat.com>
commit 7145c241a1bf2841952c3e297c4080b357b3e52d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/7145c241.failed

Fix a theoretical deadlock introduced in the previous commit ("dm crypt:
don't allocate pages for a partial request").

The function crypt_alloc_buffer may be called concurrently.  If we allocate
from the mempool concurrently, there is a possibility of deadlock.  For
example, if we have mempool of 256 pages, two processes, each wanting
256, pages allocate from the mempool concurrently, it may deadlock in a
situation where both processes have allocated 128 pages and the mempool
is exhausted.

To avoid such a scenario we allocate the pages under a mutex.  In order
to not degrade performance with excessive locking, we try non-blocking
allocations without a mutex first and if that fails, we fallback to a
blocking allocations with a mutex.

	Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
	Signed-off-by: Mike Snitzer <snitzer@redhat.com>
(cherry picked from commit 7145c241a1bf2841952c3e297c4080b357b3e52d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/dm-crypt.c
diff --cc drivers/md/dm-crypt.c
index e3eca8135e5f,fa1dba1d06f7..000000000000
--- a/drivers/md/dm-crypt.c
+++ b/drivers/md/dm-crypt.c
@@@ -967,54 -948,67 +968,89 @@@ static int crypt_convert(struct crypt_c
  /*
   * Generate a new unfragmented bio with the given size
   * This should never violate the device limitations
++<<<<<<< HEAD
 + * May return a smaller bio when running out of pages, indicated by
 + * *out_of_pages set to 1.
++=======
+  *
+  * This function may be called concurrently. If we allocate from the mempool
+  * concurrently, there is a possibility of deadlock. For example, if we have
+  * mempool of 256 pages, two processes, each wanting 256, pages allocate from
+  * the mempool concurrently, it may deadlock in a situation where both processes
+  * have allocated 128 pages and the mempool is exhausted.
+  *
+  * In order to avoid this scenario we allocate the pages under a mutex.
+  *
+  * In order to not degrade performance with excessive locking, we try
+  * non-blocking allocations without a mutex first but on failure we fallback
+  * to blocking allocations with a mutex.
++>>>>>>> 7145c241a1bf (dm crypt: avoid deadlock in mempools)
   */
 -static struct bio *crypt_alloc_buffer(struct dm_crypt_io *io, unsigned size)
 +static struct bio *crypt_alloc_buffer(struct dm_crypt_io *io, unsigned size,
 +				      unsigned *out_of_pages)
  {
  	struct crypt_config *cc = io->cc;
  	struct bio *clone;
  	unsigned int nr_iovecs = (size + PAGE_SIZE - 1) >> PAGE_SHIFT;
- 	gfp_t gfp_mask = GFP_NOIO | __GFP_HIGHMEM;
- 	unsigned i, len;
+ 	gfp_t gfp_mask = GFP_NOWAIT | __GFP_HIGHMEM;
+ 	unsigned i, len, remaining_size;
  	struct page *page;
 -	struct bio_vec *bvec;
  
+ retry:
+ 	if (unlikely(gfp_mask & __GFP_WAIT))
+ 		mutex_lock(&cc->bio_alloc_lock);
+ 
  	clone = bio_alloc_bioset(GFP_NOIO, nr_iovecs, cc->bs);
  	if (!clone)
- 		return NULL;
+ 		goto return_clone;
  
  	clone_init(io, clone);
 +	*out_of_pages = 0;
  
+ 	remaining_size = size;
+ 
  	for (i = 0; i < nr_iovecs; i++) {
  		page = mempool_alloc(cc->page_pool, gfp_mask);
  		if (!page) {
++<<<<<<< HEAD
 +			*out_of_pages = 1;
 +			break;
 +		}
 +
 +		/*
 +		 * If additional pages cannot be allocated without waiting,
 +		 * return a partially-allocated bio.  The caller will then try
 +		 * to allocate more bios while submitting this partial bio.
 +		 */
 +		gfp_mask = (gfp_mask | __GFP_NOWARN) & ~__GFP_WAIT;
++=======
+ 			crypt_free_buffer_pages(cc, clone);
+ 			bio_put(clone);
+ 			gfp_mask |= __GFP_WAIT;
+ 			goto retry;
+ 		}
++>>>>>>> 7145c241a1bf (dm crypt: avoid deadlock in mempools)
  
- 		len = (size > PAGE_SIZE) ? PAGE_SIZE : size;
+ 		len = (remaining_size > PAGE_SIZE) ? PAGE_SIZE : remaining_size;
  
 -		bvec = &clone->bi_io_vec[clone->bi_vcnt++];
 -		bvec->bv_page = page;
 -		bvec->bv_len = len;
 -		bvec->bv_offset = 0;
 -
 -		clone->bi_iter.bi_size += len;
 +		if (!bio_add_page(clone, page, len, 0)) {
 +			mempool_free(page, cc->page_pool);
 +			break;
 +		}
  
- 		size -= len;
+ 		remaining_size -= len;
  	}
  
++<<<<<<< HEAD
 +	if (!clone->bi_size) {
 +		bio_put(clone);
 +		return NULL;
 +	}
++=======
+ return_clone:
+ 	if (unlikely(gfp_mask & __GFP_WAIT))
+ 		mutex_unlock(&cc->bio_alloc_lock);
++>>>>>>> 7145c241a1bf (dm crypt: avoid deadlock in mempools)
  
  	return clone;
  }
* Unmerged path drivers/md/dm-crypt.c
