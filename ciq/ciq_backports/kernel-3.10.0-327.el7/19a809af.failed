userfaultfd: teach vma_merge to merge across vma->vm_userfaultfd_ctx

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Andrea Arcangeli <aarcange@redhat.com>
commit 19a809afe2fe089317226bbe5c5a1ce7f53dcdca
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/19a809af.failed

vma->vm_userfaultfd_ctx is yet another vma parameter that vma_merge
must be aware about so that we can merge vmas back like they were
originally before arming the userfaultfd on some memory range.

	Signed-off-by: Andrea Arcangeli <aarcange@redhat.com>
	Acked-by: Pavel Emelyanov <xemul@parallels.com>
	Cc: Sanidhya Kashyap <sanidhya.gatech@gmail.com>
	Cc: zhang.zhanghailiang@huawei.com
	Cc: "Kirill A. Shutemov" <kirill@shutemov.name>
	Cc: Andres Lagar-Cavilla <andreslc@google.com>
	Cc: Dave Hansen <dave.hansen@intel.com>
	Cc: Paolo Bonzini <pbonzini@redhat.com>
	Cc: Rik van Riel <riel@redhat.com>
	Cc: Mel Gorman <mgorman@suse.de>
	Cc: Andy Lutomirski <luto@amacapital.net>
	Cc: Hugh Dickins <hughd@google.com>
	Cc: Peter Feiner <pfeiner@google.com>
	Cc: "Dr. David Alan Gilbert" <dgilbert@redhat.com>
	Cc: Johannes Weiner <hannes@cmpxchg.org>
	Cc: "Huangpeng (Peter)" <peter.huangpeng@huawei.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 19a809afe2fe089317226bbe5c5a1ce7f53dcdca)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/mmap.c
diff --cc mm/mmap.c
index 0e22a92fd84b,82db4fc0a9d3..000000000000
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@@ -36,6 -40,8 +36,11 @@@
  #include <linux/sched/sysctl.h>
  #include <linux/notifier.h>
  #include <linux/memory.h>
++<<<<<<< HEAD
++=======
+ #include <linux/printk.h>
+ #include <linux/userfaultfd_k.h>
++>>>>>>> 19a809afe2fe (userfaultfd: teach vma_merge to merge across vma->vm_userfaultfd_ctx)
  
  #include <asm/uaccess.h>
  #include <asm/cacheflush.h>
@@@ -892,9 -920,18 +897,10 @@@ again:			remove_next = 1 + (end > next-
   * per-vma resources, so we don't attempt to merge those.
   */
  static inline int is_mergeable_vma(struct vm_area_struct *vma,
- 			struct file *file, unsigned long vm_flags)
+ 				struct file *file, unsigned long vm_flags,
+ 				struct vm_userfaultfd_ctx vm_userfaultfd_ctx)
  {
 -	/*
 -	 * VM_SOFTDIRTY should not prevent from VMA merging, if we
 -	 * match the flags but dirty bit -- the caller should mark
 -	 * merged VMA as dirty. If dirty bit won't be excluded from
 -	 * comparison, we increase pressue on the memory system forcing
 -	 * the kernel to generate new VMAs when old one could be
 -	 * extended instead.
 -	 */
 -	if ((vma->vm_flags ^ vm_flags) & ~VM_SOFTDIRTY)
 +	if (vma->vm_flags ^ vm_flags)
  		return 0;
  	if (vma->vm_file != file)
  		return 0;
@@@ -949,12 -990,14 +959,14 @@@ can_vma_merge_before(struct vm_area_str
   */
  static int
  can_vma_merge_after(struct vm_area_struct *vma, unsigned long vm_flags,
- 	struct anon_vma *anon_vma, struct file *file, pgoff_t vm_pgoff)
+ 		    struct anon_vma *anon_vma, struct file *file,
+ 		    pgoff_t vm_pgoff,
+ 		    struct vm_userfaultfd_ctx vm_userfaultfd_ctx)
  {
- 	if (is_mergeable_vma(vma, file, vm_flags) &&
+ 	if (is_mergeable_vma(vma, file, vm_flags, vm_userfaultfd_ctx) &&
  	    is_mergeable_anon_vma(anon_vma, vma->anon_vma, vma)) {
  		pgoff_t vm_pglen;
 -		vm_pglen = vma_pages(vma);
 +		vm_pglen = (vma->vm_end - vma->vm_start) >> PAGE_SHIFT;
  		if (vma->vm_pgoff + vm_pglen == vm_pgoff)
  			return 1;
  	}
@@@ -993,8 -1036,9 +1005,14 @@@
  struct vm_area_struct *vma_merge(struct mm_struct *mm,
  			struct vm_area_struct *prev, unsigned long addr,
  			unsigned long end, unsigned long vm_flags,
++<<<<<<< HEAD
 +		     	struct anon_vma *anon_vma, struct file *file,
 +			pgoff_t pgoff, struct mempolicy *policy)
++=======
+ 			struct anon_vma *anon_vma, struct file *file,
+ 			pgoff_t pgoff, struct mempolicy *policy,
+ 			struct vm_userfaultfd_ctx vm_userfaultfd_ctx)
++>>>>>>> 19a809afe2fe (userfaultfd: teach vma_merge to merge across vma->vm_userfaultfd_ctx)
  {
  	pgoff_t pglen = (end - addr) >> PAGE_SHIFT;
  	struct vm_area_struct *area, *next;
@@@ -1019,9 -1063,10 +1037,10 @@@
  	 * Can it merge with the predecessor?
  	 */
  	if (prev && prev->vm_end == addr &&
 -			mpol_equal(vma_policy(prev), policy) &&
 +  			mpol_equal(vma_policy(prev), policy) &&
  			can_vma_merge_after(prev, vm_flags,
- 						anon_vma, file, pgoff)) {
+ 					    anon_vma, file, pgoff,
+ 					    vm_userfaultfd_ctx)) {
  		/*
  		 * OK, it can.  Can we now merge in the successor as well?
  		 */
@@@ -1047,9 -1094,10 +1068,10 @@@
  	 * Can this new request be merged in front of next?
  	 */
  	if (next && end == next->vm_start &&
 -			mpol_equal(policy, vma_policy(next)) &&
 + 			mpol_equal(policy, vma_policy(next)) &&
  			can_vma_merge_before(next, vm_flags,
- 					anon_vma, file, pgoff+pglen)) {
+ 					     anon_vma, file, pgoff+pglen,
+ 					     vm_userfaultfd_ctx)) {
  		if (prev && addr < prev->vm_end)	/* case 4 */
  			err = vma_adjust(prev, prev->vm_start,
  				addr, prev->vm_pgoff, NULL);
@@@ -1518,7 -1583,8 +1540,12 @@@ munmap_back
  	/*
  	 * Can we just expand an old mapping?
  	 */
++<<<<<<< HEAD
 +	vma = vma_merge(mm, prev, addr, addr + len, vm_flags, NULL, file, pgoff, NULL);
++=======
+ 	vma = vma_merge(mm, prev, addr, addr + len, vm_flags,
+ 			NULL, file, pgoff, NULL, NULL_VM_UFFD_CTX);
++>>>>>>> 19a809afe2fe (userfaultfd: teach vma_merge to merge across vma->vm_userfaultfd_ctx)
  	if (vma)
  		goto out;
  
diff --git a/include/linux/mm.h b/include/linux/mm.h
index c63a534bdbff..0373da241d6b 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -1728,7 +1728,7 @@ extern int vma_adjust(struct vm_area_struct *vma, unsigned long start,
 extern struct vm_area_struct *vma_merge(struct mm_struct *,
 	struct vm_area_struct *prev, unsigned long addr, unsigned long end,
 	unsigned long vm_flags, struct anon_vma *, struct file *, pgoff_t,
-	struct mempolicy *);
+	struct mempolicy *, struct vm_userfaultfd_ctx);
 extern struct anon_vma *find_mergeable_anon_vma(struct vm_area_struct *);
 extern int split_vma(struct mm_struct *,
 	struct vm_area_struct *, unsigned long addr, int new_below);
diff --git a/mm/madvise.c b/mm/madvise.c
index 7055883e6e25..794c9b482d2c 100644
--- a/mm/madvise.c
+++ b/mm/madvise.c
@@ -102,7 +102,8 @@ static long madvise_behavior(struct vm_area_struct * vma,
 
 	pgoff = vma->vm_pgoff + ((start - vma->vm_start) >> PAGE_SHIFT);
 	*prev = vma_merge(mm, *prev, start, end, new_flags, vma->anon_vma,
-				vma->vm_file, pgoff, vma_policy(vma));
+			  vma->vm_file, pgoff, vma_policy(vma),
+			  vma->vm_userfaultfd_ctx);
 	if (*prev) {
 		vma = *prev;
 		goto success;
diff --git a/mm/mempolicy.c b/mm/mempolicy.c
index 4af9dc35103a..bd372cebafca 100644
--- a/mm/mempolicy.c
+++ b/mm/mempolicy.c
@@ -726,8 +726,8 @@ static int mbind_range(struct mm_struct *mm, unsigned long start,
 		pgoff = vma->vm_pgoff +
 			((vmstart - vma->vm_start) >> PAGE_SHIFT);
 		prev = vma_merge(mm, prev, vmstart, vmend, vma->vm_flags,
-				  vma->anon_vma, vma->vm_file, pgoff,
-				  new_pol);
+				 vma->anon_vma, vma->vm_file, pgoff,
+				 new_pol, vma->vm_userfaultfd_ctx);
 		if (prev) {
 			vma = prev;
 			next = vma->vm_next;
diff --git a/mm/mlock.c b/mm/mlock.c
index 713e462c0776..cd6ffab75dd7 100644
--- a/mm/mlock.c
+++ b/mm/mlock.c
@@ -289,7 +289,8 @@ static int mlock_fixup(struct vm_area_struct *vma, struct vm_area_struct **prev,
 
 	pgoff = vma->vm_pgoff + ((start - vma->vm_start) >> PAGE_SHIFT);
 	*prev = vma_merge(mm, *prev, start, end, newflags, vma->anon_vma,
-			  vma->vm_file, pgoff, vma_policy(vma));
+			  vma->vm_file, pgoff, vma_policy(vma),
+			  vma->vm_userfaultfd_ctx);
 	if (*prev) {
 		vma = *prev;
 		goto success;
* Unmerged path mm/mmap.c
diff --git a/mm/mprotect.c b/mm/mprotect.c
index a182e560297e..468917529124 100644
--- a/mm/mprotect.c
+++ b/mm/mprotect.c
@@ -294,7 +294,8 @@ mprotect_fixup(struct vm_area_struct *vma, struct vm_area_struct **pprev,
 	 */
 	pgoff = vma->vm_pgoff + ((start - vma->vm_start) >> PAGE_SHIFT);
 	*pprev = vma_merge(mm, *pprev, start, end, newflags,
-			vma->anon_vma, vma->vm_file, pgoff, vma_policy(vma));
+			   vma->anon_vma, vma->vm_file, pgoff, vma_policy(vma),
+			   vma->vm_userfaultfd_ctx);
 	if (*pprev) {
 		vma = *pprev;
 		goto success;
