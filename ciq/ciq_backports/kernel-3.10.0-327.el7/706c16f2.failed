perpcu: fold pcpu_split_block() into the only caller

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [mm] percpu: fold pcpu_split_block() into the only caller (Jeff Moyer) [1209624]
Rebuild_FUZZ: 98.08%
commit-author Al Viro <viro@zeniv.linux.org.uk>
commit 706c16f2372316a0a8af3be6e2bd6e391c073ca0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/706c16f2.failed

... and simplify the results a bit.  Makes the next step easier
to deal with - we will be changing the data representation for
chunk->map[] and it's easier to do if the code in question is
not split between pcpu_alloc_area() and pcpu_split_block().

	Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
	Signed-off-by: Tejun Heo <tj@kernel.org>
(cherry picked from commit 706c16f2372316a0a8af3be6e2bd6e391c073ca0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/percpu.c
diff --cc mm/percpu.c
index 89e586173340,592f289819b7..000000000000
--- a/mm/percpu.c
+++ b/mm/percpu.c
@@@ -419,47 -418,6 +419,50 @@@ out_unlock
  }
  
  /**
++<<<<<<< HEAD
 + * pcpu_split_block - split a map block
 + * @chunk: chunk of interest
 + * @i: index of map block to split
 + * @head: head size in bytes (can be 0)
 + * @tail: tail size in bytes (can be 0)
 + *
 + * Split the @i'th map block into two or three blocks.  If @head is
 + * non-zero, @head bytes block is inserted before block @i moving it
 + * to @i+1 and reducing its size by @head bytes.
 + *
 + * If @tail is non-zero, the target block, which can be @i or @i+1
 + * depending on @head, is reduced by @tail bytes and @tail byte block
 + * is inserted after the target block.
 + *
 + * @chunk->map must have enough free slots to accommodate the split.
 + *
 + * CONTEXT:
 + * pcpu_lock.
 + */
 +static void pcpu_split_block(struct pcpu_chunk *chunk, int i,
 +			     int head, int size, int tail)
 +{
 +	int nr_extra = !!head + !!tail;
 +	int off;
 +
 +	BUG_ON(chunk->map_alloc <= chunk->map_used + nr_extra);
 +
 +	/* insert new subblocks */
 +	memmove(&chunk->map[i + nr_extra] + 1, &chunk->map[i] + 1,
 +		sizeof(chunk->map[0]) * (chunk->map_used - i));
 +	chunk->map_used += nr_extra;
 +
 +	off = chunk->map[i];
 +
 +	if (head)
 +		chunk->map[++i] = off += head;
 +	if (tail)
 +		chunk->map[++i] = off += size;
 +}
 +
 +/**
++=======
++>>>>>>> 706c16f23723 (perpcu: fold pcpu_split_block() into the only caller)
   * pcpu_alloc_area - allocate area from a pcpu_chunk
   * @chunk: chunk of interest
   * @size: wanted size in bytes
@@@ -530,23 -482,27 +533,45 @@@ static int pcpu_alloc_area(struct pcpu_
  
  		/* split if warranted */
  		if (head || tail) {
++<<<<<<< HEAD
 +			pcpu_split_block(chunk, i, head, size, tail);
 +			if (head) {
 +				if (!seen_free) {
 +					chunk->first_free = i;
 +					seen_free = true;
 +				}
 +				i++;
 +				off += head;
 +				max_contig = max(head, max_contig);
 +			}
 +			if (tail)
 +				max_contig = max(tail, max_contig);
++=======
+ 			int nr_extra = !!head + !!tail;
+ 
+ 			/* insert new subblocks */
+ 			memmove(&chunk->map[i + nr_extra], &chunk->map[i],
+ 				sizeof(chunk->map[0]) * (chunk->map_used - i));
+ 			chunk->map_used += nr_extra;
+ 
+ 			if (head) {
+ 				chunk->map[i + 1] = chunk->map[i] - head;
+ 				chunk->map[i] = head;
+ 				off += head;
+ 				i++;
+ 				max_contig = max(head, max_contig);
+ 			}
+ 			if (tail) {
+ 				chunk->map[i] -= tail;
+ 				chunk->map[i + 1] = tail;
+ 				max_contig = max(tail, max_contig);
+ 			}
++>>>>>>> 706c16f23723 (perpcu: fold pcpu_split_block() into the only caller)
  		}
  
 +		if (!seen_free)
 +			chunk->first_free = i + 1;
 +
  		/* update hint and mark allocated */
  		if (is_last)
  			chunk->contig_hint = max_contig; /* fully scanned */
* Unmerged path mm/percpu.c
