blk-mq: Fix use after of free q->mq_map

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
commit-author Akinobu Mita <akinobu.mita@gmail.com>
commit a723bab3d7529133f71fc8a5e96f86e3639a0d13
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/a723bab3.failed

CPU hotplug handling for blk-mq (blk_mq_queue_reinit) updates
q->mq_map by blk_mq_update_queue_map() for all request queues in
all_q_list.  On the other hand, q->mq_map is released before deleting
the queue from all_q_list.

So if CPU hotplug event occurs in the window, invalid memory access
can happen.  Fix it by releasing q->mq_map in blk_mq_release() to make
it happen latter than removal from all_q_list.

	Signed-off-by: Akinobu Mita <akinobu.mita@gmail.com>
	Suggested-by: Ming Lei <tom.leiming@gmail.com>
	Reviewed-by: Ming Lei <tom.leiming@gmail.com>
	Cc: Ming Lei <tom.leiming@gmail.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@fb.com>
(cherry picked from commit a723bab3d7529133f71fc8a5e96f86e3639a0d13)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq.c
diff --cc block/blk-mq.c
index c84efe52e26a,92648d8d6a4a..000000000000
--- a/block/blk-mq.c
+++ b/block/blk-mq.c
@@@ -1810,7 -1906,52 +1810,38 @@@ static void blk_mq_add_queue_tag_set(st
  	mutex_unlock(&set->tag_list_lock);
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * It is the actual release handler for mq, but we do it from
+  * request queue's release handler for avoiding use-after-free
+  * and headache because q->mq_kobj shouldn't have been introduced,
+  * but we can't group ctx/kctx kobj without it.
+  */
+ void blk_mq_release(struct request_queue *q)
+ {
+ 	struct blk_mq_hw_ctx *hctx;
+ 	unsigned int i;
+ 
+ 	/* hctx kobj stays in hctx */
+ 	queue_for_each_hw_ctx(q, hctx, i) {
+ 		if (!hctx)
+ 			continue;
+ 		kfree(hctx->ctxs);
+ 		kfree(hctx);
+ 	}
+ 
+ 	kfree(q->mq_map);
+ 	q->mq_map = NULL;
+ 
+ 	kfree(q->queue_hw_ctx);
+ 
+ 	/* ctx kobj stays in queue_ctx */
+ 	free_percpu(q->queue_ctx);
+ }
+ 
++>>>>>>> a723bab3d752 (blk-mq: Fix use after of free q->mq_map)
  struct request_queue *blk_mq_init_queue(struct blk_mq_tag_set *set)
 -{
 -	struct request_queue *uninit_q, *q;
 -
 -	uninit_q = blk_alloc_queue_node(GFP_KERNEL, set->numa_node);
 -	if (!uninit_q)
 -		return ERR_PTR(-ENOMEM);
 -
 -	q = blk_mq_init_allocated_queue(set, uninit_q);
 -	if (IS_ERR(q))
 -		blk_cleanup_queue(uninit_q);
 -
 -	return q;
 -}
 -EXPORT_SYMBOL(blk_mq_init_queue);
 -
 -struct request_queue *blk_mq_init_allocated_queue(struct blk_mq_tag_set *set,
 -						  struct request_queue *q)
  {
  	struct blk_mq_hw_ctx **hctxs;
  	struct blk_mq_ctx __percpu *ctx;
@@@ -1939,15 -2073,6 +1970,18 @@@ void blk_mq_free_queue(struct request_q
  	blk_mq_free_hw_queues(q, set);
  
  	percpu_ref_exit(&q->mq_usage_counter);
++<<<<<<< HEAD
 +
 +	free_percpu(q->queue_ctx);
 +	kfree(q->queue_hw_ctx);
 +	kfree(q->mq_map);
 +
 +	q->queue_ctx = NULL;
 +	q->queue_hw_ctx = NULL;
 +	q->mq_map = NULL;
 +
++=======
++>>>>>>> a723bab3d752 (blk-mq: Fix use after of free q->mq_map)
  	mutex_lock(&all_q_mutex);
  	list_del_init(&q->all_q_node);
  	mutex_unlock(&all_q_mutex);
* Unmerged path block/blk-mq.c
