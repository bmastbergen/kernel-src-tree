KVM: PPC: Book3S HV: Use msgsnd for signalling threads on POWER8

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-327.el7
Rebuild_CHGLOG: - [kvm] ppc: book3s-hv: Use msgsnd for signalling threads on POWER8 (Laurent Vivier) [1213669]
Rebuild_FUZZ: 94.31%
commit-author Paul Mackerras <paulus@samba.org>
commit 66feed61cdf6ee65fd551d3460b1efba6bee55b8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-327.el7/66feed61.failed

This uses msgsnd where possible for signalling other threads within
the same core on POWER8 systems, rather than IPIs through the XICS
interrupt controller.  This includes waking secondary threads to run
the guest, the interrupts generated by the virtual XICS, and the
interrupts to bring the other threads out of the guest when exiting.

Aggregated statistics from debugfs across vcpus for a guest with 32
vcpus, 8 threads/vcore, running on a POWER8, show this before the
change:

 rm_entry:     3387.6ns (228 - 86600, 1008969 samples)
  rm_exit:     4561.5ns (12 - 3477452, 1009402 samples)
  rm_intr:     1660.0ns (12 - 553050, 3600051 samples)

and this after the change:

 rm_entry:     3060.1ns (212 - 65138, 953873 samples)
  rm_exit:     4244.1ns (12 - 9693408, 954331 samples)
  rm_intr:     1342.3ns (12 - 1104718, 3405326 samples)

for a test of booting Fedora 20 big-endian to the login prompt.

The time taken for a H_PROD hcall (which is handled in the host
kernel) went down from about 35 microseconds to about 16 microseconds
with this change.

The noinline added to kvmppc_run_core turned out to be necessary for
good performance, at least with gcc 4.9.2 as packaged with Fedora 21
and a little-endian POWER8 host.

	Signed-off-by: Paul Mackerras <paulus@samba.org>
	Signed-off-by: Alexander Graf <agraf@suse.de>
(cherry picked from commit 66feed61cdf6ee65fd551d3460b1efba6bee55b8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/kvm/book3s_hv_builtin.c
#	arch/powerpc/kvm/book3s_hv_rmhandlers.S
diff --cc arch/powerpc/kvm/book3s_hv_builtin.c
index f719a1437a31,ed2589d4593f..000000000000
--- a/arch/powerpc/kvm/book3s_hv_builtin.c
+++ b/arch/powerpc/kvm/book3s_hv_builtin.c
@@@ -20,8 -21,13 +20,17 @@@
  #include <asm/cputable.h>
  #include <asm/kvm_ppc.h>
  #include <asm/kvm_book3s.h>
++<<<<<<< HEAD
++=======
+ #include <asm/archrandom.h>
+ #include <asm/xics.h>
+ #include <asm/dbell.h>
+ #include <asm/cputhreads.h>
+ 
+ #define KVM_CMA_CHUNK_ORDER	18
++>>>>>>> 66feed61cdf6 (KVM: PPC: Book3S HV: Use msgsnd for signalling threads on POWER8)
  
 +#include "book3s_hv_cma.h"
  /*
   * Hash page table alignment on newer cpus(CPU_FTR_ARCH_206)
   * should be power of 2.
@@@ -231,3 -173,89 +240,92 @@@ int kvmppc_hcall_impl_hv_realmode(unsig
  	return 0;
  }
  EXPORT_SYMBOL_GPL(kvmppc_hcall_impl_hv_realmode);
++<<<<<<< HEAD
++=======
+ 
+ int kvmppc_hwrng_present(void)
+ {
+ 	return powernv_hwrng_present();
+ }
+ EXPORT_SYMBOL_GPL(kvmppc_hwrng_present);
+ 
+ long kvmppc_h_random(struct kvm_vcpu *vcpu)
+ {
+ 	if (powernv_get_random_real_mode(&vcpu->arch.gpr[4]))
+ 		return H_SUCCESS;
+ 
+ 	return H_HARDWARE;
+ }
+ 
+ static inline void rm_writeb(unsigned long paddr, u8 val)
+ {
+ 	__asm__ __volatile__("stbcix %0,0,%1"
+ 		: : "r" (val), "r" (paddr) : "memory");
+ }
+ 
+ /*
+  * Send an interrupt or message to another CPU.
+  * This can only be called in real mode.
+  * The caller needs to include any barrier needed to order writes
+  * to memory vs. the IPI/message.
+  */
+ void kvmhv_rm_send_ipi(int cpu)
+ {
+ 	unsigned long xics_phys;
+ 
+ 	/* On POWER8 for IPIs to threads in the same core, use msgsnd */
+ 	if (cpu_has_feature(CPU_FTR_ARCH_207S) &&
+ 	    cpu_first_thread_sibling(cpu) ==
+ 	    cpu_first_thread_sibling(raw_smp_processor_id())) {
+ 		unsigned long msg = PPC_DBELL_TYPE(PPC_DBELL_SERVER);
+ 		msg |= cpu_thread_in_core(cpu);
+ 		__asm__ __volatile__ (PPC_MSGSND(%0) : : "r" (msg));
+ 		return;
+ 	}
+ 
+ 	/* Else poke the target with an IPI */
+ 	xics_phys = paca[cpu].kvm_hstate.xics_phys;
+ 	rm_writeb(xics_phys + XICS_MFRR, IPI_PRIORITY);
+ }
+ 
+ /*
+  * The following functions are called from the assembly code
+  * in book3s_hv_rmhandlers.S.
+  */
+ static void kvmhv_interrupt_vcore(struct kvmppc_vcore *vc, int active)
+ {
+ 	int cpu = vc->pcpu;
+ 
+ 	/* Order setting of exit map vs. msgsnd/IPI */
+ 	smp_mb();
+ 	for (; active; active >>= 1, ++cpu)
+ 		if (active & 1)
+ 			kvmhv_rm_send_ipi(cpu);
+ }
+ 
+ void kvmhv_commence_exit(int trap)
+ {
+ 	struct kvmppc_vcore *vc = local_paca->kvm_hstate.kvm_vcore;
+ 	int ptid = local_paca->kvm_hstate.ptid;
+ 	int me, ee;
+ 
+ 	/* Set our bit in the threads-exiting-guest map in the 0xff00
+ 	   bits of vcore->entry_exit_map */
+ 	me = 0x100 << ptid;
+ 	do {
+ 		ee = vc->entry_exit_map;
+ 	} while (cmpxchg(&vc->entry_exit_map, ee, ee | me) != ee);
+ 
+ 	/* Are we the first here? */
+ 	if ((ee >> 8) != 0)
+ 		return;
+ 
+ 	/*
+ 	 * Trigger the other threads in this vcore to exit the guest.
+ 	 * If this is a hypervisor decrementer interrupt then they
+ 	 * will be already on their way out of the guest.
+ 	 */
+ 	if (trap != BOOK3S_INTERRUPT_HV_DECREMENTER)
+ 		kvmhv_interrupt_vcore(vc, ee & ~(1 << ptid));
+ }
++>>>>>>> 66feed61cdf6 (KVM: PPC: Book3S HV: Use msgsnd for signalling threads on POWER8)
diff --cc arch/powerpc/kvm/book3s_hv_rmhandlers.S
index 499fdba9ddf8,4d70df26c402..000000000000
--- a/arch/powerpc/kvm/book3s_hv_rmhandlers.S
+++ b/arch/powerpc/kvm/book3s_hv_rmhandlers.S
@@@ -1149,33 -1123,30 +1149,43 @@@ END_FTR_SECTION_IFSET(CPU_FTR_ARCH_206
  	cmpwi	r12,BOOK3S_INTERRUPT_SYSCALL
  	beq	hcall_try_real_mode
  
++<<<<<<< HEAD
 +	/* Only handle external interrupts here on arch 206 and later */
 +BEGIN_FTR_SECTION
 +	b	ext_interrupt_to_host
 +END_FTR_SECTION_IFCLR(CPU_FTR_ARCH_206)
 +
++=======
+ 	/* Hypervisor doorbell - exit only if host IPI flag set */
+ 	cmpwi	r12, BOOK3S_INTERRUPT_H_DOORBELL
+ 	bne	3f
+ 	lbz	r0, HSTATE_HOST_IPI(r13)
+ 	beq	4f
+ 	b	guest_exit_cont
+ 3:
++>>>>>>> 66feed61cdf6 (KVM: PPC: Book3S HV: Use msgsnd for signalling threads on POWER8)
  	/* External interrupt ? */
  	cmpwi	r12, BOOK3S_INTERRUPT_EXTERNAL
 -	bne+	guest_exit_cont
 +	bne+	ext_interrupt_to_host
  
  	/* External interrupt, first check for host_ipi. If this is
  	 * set, we know the host wants us out so let's do it now
  	 */
  	bl	kvmppc_read_intr
  	cmpdi	r3, 0
 -	bgt	guest_exit_cont
 +	bgt	ext_interrupt_to_host
  
  	/* Check if any CPU is heading out to the host, if so head out too */
- 	ld	r5, HSTATE_KVM_VCORE(r13)
+ 4:	ld	r5, HSTATE_KVM_VCORE(r13)
  	lwz	r0, VCORE_ENTRY_EXIT(r5)
  	cmpwi	r0, 0x100
 +	bge	ext_interrupt_to_host
 +
 +	/* Return to guest after delivering any pending interrupt */
  	mr	r4, r9
 -	blt	deliver_guest_interrupt
 +	b	deliver_guest_interrupt
 +
 +ext_interrupt_to_host:
  
  guest_exit_cont:		/* r9 = vcpu, r12 = trap, r13 = paca */
  	/* Save more register state  */
@@@ -2176,22 -2123,53 +2186,33 @@@ END_FTR_SECTION_IFCLR(CPU_FTR_ARCH_206
  	/* save FP state */
  	bl	kvmppc_save_fp
  
 -	/*
 -	 * Set DEC to the smaller of DEC and HDEC, so that we wake
 -	 * no later than the end of our timeslice (HDEC interrupts
 -	 * don't wake us from nap).
 -	 */
 -	mfspr	r3, SPRN_DEC
 -	mfspr	r4, SPRN_HDEC
 -	mftb	r5
 -	cmpw	r3, r4
 -	ble	67f
 -	mtspr	SPRN_DEC, r4
 -67:
 -	/* save expiry time of guest decrementer */
 -	extsw	r3, r3
 -	add	r3, r3, r5
 -	ld	r4, HSTATE_KVM_VCPU(r13)
 -	ld	r5, HSTATE_KVM_VCORE(r13)
 -	ld	r6, VCORE_TB_OFFSET(r5)
 -	subf	r3, r6, r3	/* convert to host TB value */
 -	std	r3, VCPU_DEC_EXPIRES(r4)
 -
 -#ifdef CONFIG_KVM_BOOK3S_HV_EXIT_TIMING
 -	ld	r4, HSTATE_KVM_VCPU(r13)
 -	addi	r3, r4, VCPU_TB_CEDE
 -	bl	kvmhv_accumulate_time
 -#endif
 -
 -	lis	r3, LPCR_PECEDP@h	/* Do wake on privileged doorbell */
 -
  	/*
  	 * Take a nap until a decrementer or external or doobell interrupt
++<<<<<<< HEAD
 +	 * occurs, with PECE1, PECE0 and PECEDP set in LPCR. Also clear the
 +	 * runlatch bit before napping.
++=======
+ 	 * occurs, with PECE1 and PECE0 set in LPCR.
+ 	 * On POWER8, set PECEDH, and if we are ceding, also set PECEDP.
+ 	 * Also clear the runlatch bit before napping.
++>>>>>>> 66feed61cdf6 (KVM: PPC: Book3S HV: Use msgsnd for signalling threads on POWER8)
  	 */
  kvm_do_nap:
 -	mfspr	r0, SPRN_CTRLF
 -	clrrdi	r0, r0, 1
 -	mtspr	SPRN_CTRLT, r0
 +	mfspr	r2, SPRN_CTRLF
 +	clrrdi	r2, r2, 1
 +	mtspr	SPRN_CTRLT, r2
  
  	li	r0,1
  	stb	r0,HSTATE_HWTHREAD_REQ(r13)
  	mfspr	r5,SPRN_LPCR
  	ori	r5,r5,LPCR_PECE0 | LPCR_PECE1
  BEGIN_FTR_SECTION
++<<<<<<< HEAD
 +	oris	r5,r5,LPCR_PECEDP@h
++=======
+ 	ori	r5, r5, LPCR_PECEDH
+ 	rlwimi	r5, r3, 0, LPCR_PECEDP
++>>>>>>> 66feed61cdf6 (KVM: PPC: Book3S HV: Use msgsnd for signalling threads on POWER8)
  END_FTR_SECTION_IFSET(CPU_FTR_ARCH_207S)
  	mtspr	SPRN_LPCR,r5
  	isync
@@@ -2311,10 -2304,10 +2332,10 @@@ machine_check_realmode
  
  /*
   * Check the reason we woke from nap, and take appropriate action.
 - * Returns (in r3):
 + * Returns:
   *	0 if nothing needs to be done
   *	1 if something happened that needs to be handled by the host
-  *	-1 if there was a guest wakeup (IPI)
+  *	-1 if there was a guest wakeup (IPI or msgsnd)
   *
   * Also sets r12 to the interrupt vector for any interrupt that needs
   * to be handled now by the host (0x500 for external interrupt), or zero.
diff --git a/arch/powerpc/kernel/asm-offsets.c b/arch/powerpc/kernel/asm-offsets.c
index b98af275a63f..2d8734bf98e5 100644
--- a/arch/powerpc/kernel/asm-offsets.c
+++ b/arch/powerpc/kernel/asm-offsets.c
@@ -37,6 +37,7 @@
 #include <asm/thread_info.h>
 #include <asm/rtas.h>
 #include <asm/vdso_datapage.h>
+#include <asm/dbell.h>
 #ifdef CONFIG_PPC64
 #include <asm/paca.h>
 #include <asm/lppaca.h>
@@ -724,5 +725,7 @@ int main(void)
 	DEFINE(PACA_OPAL_MC_EVT, offsetof(struct paca_struct, opal_mc_evt));
 #endif
 
+	DEFINE(PPC_DBELL_SERVER, PPC_DBELL_SERVER);
+
 	return 0;
 }
diff --git a/arch/powerpc/kvm/book3s_hv.c b/arch/powerpc/kvm/book3s_hv.c
index 077343fa2903..5a2b2fbbfc63 100644
--- a/arch/powerpc/kvm/book3s_hv.c
+++ b/arch/powerpc/kvm/book3s_hv.c
@@ -50,6 +50,7 @@
 #include <asm/hvcall.h>
 #include <asm/switch_to.h>
 #include <asm/smp.h>
+#include <asm/dbell.h>
 #include <linux/gfp.h>
 #include <linux/vmalloc.h>
 #include <linux/highmem.h>
@@ -80,9 +81,35 @@ static DECLARE_BITMAP(default_enabled_hcalls, MAX_HCALL_OPCODE/4 + 1);
 static void kvmppc_end_cede(struct kvm_vcpu *vcpu);
 static int kvmppc_hv_setup_htab_rma(struct kvm_vcpu *vcpu);
 
+static bool kvmppc_ipi_thread(int cpu)
+{
+	/* On POWER8 for IPIs to threads in the same core, use msgsnd */
+	if (cpu_has_feature(CPU_FTR_ARCH_207S)) {
+		preempt_disable();
+		if (cpu_first_thread_sibling(cpu) ==
+		    cpu_first_thread_sibling(smp_processor_id())) {
+			unsigned long msg = PPC_DBELL_TYPE(PPC_DBELL_SERVER);
+			msg |= cpu_thread_in_core(cpu);
+			smp_mb();
+			__asm__ __volatile__ (PPC_MSGSND(%0) : : "r" (msg));
+			preempt_enable();
+			return true;
+		}
+		preempt_enable();
+	}
+
+#if defined(CONFIG_PPC_ICP_NATIVE) && defined(CONFIG_SMP)
+	if (cpu >= 0 && cpu < nr_cpu_ids && paca[cpu].kvm_hstate.xics_phys) {
+		xics_wake_cpu(cpu);
+		return true;
+	}
+#endif
+
+	return false;
+}
+
 static void kvmppc_fast_vcpu_kick_hv(struct kvm_vcpu *vcpu)
 {
-	int me;
 	int cpu = vcpu->cpu;
 	wait_queue_head_t *wqp;
 
@@ -92,20 +119,12 @@ static void kvmppc_fast_vcpu_kick_hv(struct kvm_vcpu *vcpu)
 		++vcpu->stat.halt_wakeup;
 	}
 
-	me = get_cpu();
+	if (kvmppc_ipi_thread(cpu + vcpu->arch.ptid))
+		return;
 
 	/* CPU points to the first thread of the core */
-	if (cpu != me && cpu >= 0 && cpu < nr_cpu_ids) {
-#ifdef CONFIG_PPC_ICP_NATIVE
-		int real_cpu = cpu + vcpu->arch.ptid;
-		if (paca[real_cpu].kvm_hstate.xics_phys)
-			xics_wake_cpu(real_cpu);
-		else
-#endif
-		if (cpu_online(cpu))
-			smp_send_reschedule(cpu);
-	}
-	put_cpu();
+	if (cpu >= 0 && cpu < nr_cpu_ids && cpu_online(cpu))
+		smp_send_reschedule(cpu);
 }
 
 /*
@@ -1584,10 +1603,8 @@ static void kvmppc_start_thread(struct kvm_vcpu *vcpu)
 	/* Order stores to hstate.kvm_vcore etc. before store to kvm_vcpu */
 	smp_wmb();
 	tpaca->kvm_hstate.kvm_vcpu = vcpu;
-#if defined(CONFIG_PPC_ICP_NATIVE) && defined(CONFIG_SMP)
 	if (cpu != smp_processor_id())
-		xics_wake_cpu(cpu);
-#endif
+		kvmppc_ipi_thread(cpu);
 }
 
 static void kvmppc_wait_for_nap(void)
@@ -1699,7 +1716,7 @@ static void prepare_threads(struct kvmppc_vcore *vc)
  * Run a set of guest threads on a physical core.
  * Called with vc->lock held.
  */
-static void kvmppc_run_core(struct kvmppc_vcore *vc)
+static noinline void kvmppc_run_core(struct kvmppc_vcore *vc)
 {
 	struct kvm_vcpu *vcpu, *vnext;
 	long ret;
* Unmerged path arch/powerpc/kvm/book3s_hv_builtin.c
* Unmerged path arch/powerpc/kvm/book3s_hv_rmhandlers.S
