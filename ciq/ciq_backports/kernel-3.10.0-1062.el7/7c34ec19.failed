net/mlx5: Make RoCE and SR-IOV LAG modes explicit

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
Rebuild_CHGLOG: - [netdrv] mlx5: Make RoCE and SR-IOV LAG modes explicit (Alaa Hleihel) [1642355 1642498]
Rebuild_FUZZ: 95.74%
commit-author Aviv Heller <avivh@mellanox.com>
commit 7c34ec19e10c0d13ca2f3435fb85d2dddccad917
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/7c34ec19.failed

With the introduction of SR-IOV LAG, checking whether LAG is active
is no longer good enough, since RoCE and SR-IOV LAG each entails
different behavior by both the core and infiniband drivers.

This patch introduces facilities to discern LAG type, in addition to
mlx5_lag_is_active(). These are implemented in such a way as to allow
more complex mode combinations in the future.

	Signed-off-by: Aviv Heller <avivh@mellanox.com>
	Reviewed-by: Roi Dayan <roid@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 7c34ec19e10c0d13ca2f3435fb85d2dddccad917)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/main.c
#	drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
#	drivers/net/ethernet/mellanox/mlx5/core/lag.c
diff --cc drivers/infiniband/hw/mlx5/main.c
index 8f90751c4e18,e85974ab06c0..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -1824,10 -1848,21 +1824,21 @@@ static struct ib_ucontext *mlx5_ib_allo
  	context->lib_caps = req.lib_caps;
  	print_lib_caps(dev, context->lib_caps);
  
++<<<<<<< HEAD
++=======
+ 	if (dev->lag_active) {
+ 		u8 port = mlx5_core_native_port_num(dev->mdev);
+ 
+ 		atomic_set(&context->tx_port_affinity,
+ 			   atomic_add_return(
+ 				   1, &dev->roce[port].tx_port_affinity));
+ 	}
+ 
++>>>>>>> 7c34ec19e10c (net/mlx5: Make RoCE and SR-IOV LAG modes explicit)
  	return &context->ibucontext;
  
 -out_mdev:
 -	mlx5_ib_dealloc_transport_domain(dev, context->tdn, context->devx_uid);
 -out_devx:
 -	if (req.flags & MLX5_IB_ALLOC_UCTX_DEVX)
 -		mlx5_ib_devx_destroy(dev, context->devx_uid);
 +out_td:
 +	mlx5_ib_dealloc_transport_domain(dev, context->tdn);
  
  out_uars:
  	deallocate_uars(dev, context);
@@@ -4105,7 -4854,8 +4116,12 @@@ static int mlx5_eth_lag_init(struct mlx
  		goto err_destroy_vport_lag;
  	}
  
++<<<<<<< HEAD
 +	dev->flow_db.lag_demux_ft = ft;
++=======
+ 	dev->flow_db->lag_demux_ft = ft;
+ 	dev->lag_active = true;
++>>>>>>> 7c34ec19e10c (net/mlx5: Make RoCE and SR-IOV LAG modes explicit)
  	return 0;
  
  err_destroy_vport_lag:
@@@ -4117,9 -4867,11 +4133,17 @@@ static void mlx5_eth_lag_cleanup(struc
  {
  	struct mlx5_core_dev *mdev = dev->mdev;
  
++<<<<<<< HEAD
 +	if (dev->flow_db.lag_demux_ft) {
 +		mlx5_destroy_flow_table(dev->flow_db.lag_demux_ft);
 +		dev->flow_db.lag_demux_ft = NULL;
++=======
+ 	if (dev->lag_active) {
+ 		dev->lag_active = false;
+ 
+ 		mlx5_destroy_flow_table(dev->flow_db->lag_demux_ft);
+ 		dev->flow_db->lag_demux_ft = NULL;
++>>>>>>> 7c34ec19e10c (net/mlx5: Make RoCE and SR-IOV LAG modes explicit)
  
  		mlx5_cmd_destroy_vport_lag(mdev);
  	}
@@@ -5216,12 -6166,24 +5240,28 @@@ static void mlx5_ib_stage_bfrag_cleanup
  	mlx5_free_bfreg(dev->mdev, &dev->bfreg);
  }
  
 -static int mlx5_ib_stage_populate_specs(struct mlx5_ib_dev *dev)
 +static int mlx5_ib_stage_ib_reg_init(struct mlx5_ib_dev *dev)
  {
 -	return populate_specs_root(dev);
 +	return ib_register_device(&dev->ib_dev, NULL);
  }
  
++<<<<<<< HEAD
 +static void mlx5_ib_stage_pre_ib_reg_umr_cleanup(struct mlx5_ib_dev *dev)
++=======
+ int mlx5_ib_stage_ib_reg_init(struct mlx5_ib_dev *dev)
+ {
+ 	const char *name;
+ 
+ 	rdma_set_device_sysfs_group(&dev->ib_dev, &mlx5_attr_group);
+ 	if (!mlx5_lag_is_roce(dev->mdev))
+ 		name = "mlx5_%d";
+ 	else
+ 		name = "mlx5_bond_%d";
+ 	return ib_register_device(&dev->ib_dev, name, NULL);
+ }
+ 
+ void mlx5_ib_stage_pre_ib_reg_umr_cleanup(struct mlx5_ib_dev *dev)
++>>>>>>> 7c34ec19e10c (net/mlx5: Make RoCE and SR-IOV LAG modes explicit)
  {
  	destroy_umrc_res(dev);
  }
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
index 1af2953c38f5,e4a34c9ef700..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
@@@ -218,7 -308,20 +218,18 @@@ int mlx5e_attr_get(struct net_device *d
  	switch (attr->id) {
  	case SWITCHDEV_ATTR_ID_PORT_PARENT_ID:
  		attr->u.ppid.id_len = ETH_ALEN;
++<<<<<<< HEAD
 +		ether_addr_copy(attr->u.ppid.id, rep->hw_id);
++=======
+ 		if (uplink_upper && mlx5_lag_is_sriov(uplink_priv->mdev)) {
+ 			ether_addr_copy(attr->u.ppid.id, uplink_upper->dev_addr);
+ 		} else {
+ 			struct mlx5e_rep_priv *rpriv = priv->ppriv;
+ 			struct mlx5_eswitch_rep *rep = rpriv->rep;
+ 
+ 			ether_addr_copy(attr->u.ppid.id, rep->hw_id);
+ 		}
++>>>>>>> 7c34ec19e10c (net/mlx5: Make RoCE and SR-IOV LAG modes explicit)
  		break;
  	default:
  		return -EOPNOTSUPP;
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index fbb4f1b36627,53ebb5a48018..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -2727,31 -2708,29 +2727,53 @@@ static struct rhashtable *get_tc_ht(str
  		return &priv->fs.tc.ht;
  }
  
++<<<<<<< HEAD
 +int mlx5e_configure_flower(struct mlx5e_priv *priv,
 +			   struct tc_cls_flower_offload *f, int flags)
++=======
+ static bool is_peer_flow_needed(struct mlx5e_tc_flow *flow)
+ {
+ 	struct mlx5_esw_flow_attr *attr = flow->esw_attr;
+ 	bool is_rep_ingress = attr->in_rep->vport != FDB_UPLINK_VPORT &&
+ 			      flow->flags & MLX5E_TC_FLOW_INGRESS;
+ 	bool act_is_encap = !!(attr->action &
+ 			       MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT);
+ 	bool esw_paired = mlx5_devcom_is_paired(attr->in_mdev->priv.devcom,
+ 						MLX5_DEVCOM_ESW_OFFLOADS);
+ 
+ 	return esw_paired && mlx5_lag_is_sriov(attr->in_mdev) &&
+ 	       (is_rep_ingress || act_is_encap);
+ }
+ 
+ static int
+ mlx5e_alloc_flow(struct mlx5e_priv *priv, int attr_size,
+ 		 struct tc_cls_flower_offload *f, u16 flow_flags,
+ 		 struct mlx5e_tc_flow_parse_attr **__parse_attr,
+ 		 struct mlx5e_tc_flow **__flow)
++>>>>>>> 7c34ec19e10c (net/mlx5: Make RoCE and SR-IOV LAG modes explicit)
  {
 +	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
  	struct mlx5e_tc_flow_parse_attr *parse_attr;
 +	struct rhashtable *tc_ht = get_tc_ht(priv);
  	struct mlx5e_tc_flow *flow;
 -	int err;
 +	int attr_size, err = 0;
 +	u8 flow_flags = 0;
 +
 +	get_flags(flags, &flow_flags);
 +
 +	flow = rhashtable_lookup_fast(tc_ht, &f->cookie, tc_ht_params);
 +	if (flow) {
 +		netdev_warn_once(priv->netdev, "flow cookie %lx already exists, ignoring\n", f->cookie);
 +		return 0;
 +	}
 +
 +	if (esw && esw->mode == SRIOV_OFFLOADS) {
 +		flow_flags |= MLX5E_TC_FLOW_ESWITCH;
 +		attr_size  = sizeof(struct mlx5_esw_flow_attr);
 +	} else {
 +		flow_flags |= MLX5E_TC_FLOW_NIC;
 +		attr_size  = sizeof(struct mlx5_nic_flow_attr);
 +	}
  
  	flow = kzalloc(sizeof(*flow) + attr_size, GFP_KERNEL);
  	parse_attr = kvzalloc(sizeof(*parse_attr), GFP_KERNEL);
diff --cc drivers/net/ethernet/mellanox/mlx5/core/lag.c
index 10a4532b7144,feb8230d3f86..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/lag.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/lag.c
@@@ -271,10 -288,13 +283,13 @@@ static void mlx5_do_bond(struct mlx5_la
  	tracker = ldev->tracker;
  	mutex_unlock(&lag_mutex);
  
 -	do_bond = tracker.is_bonded && mlx5_lag_check_prereq(ldev);
 +	do_bond = tracker.is_bonded && ldev->allowed;
  
  	if (do_bond && !__mlx5_lag_is_active(ldev)) {
- 		if (!sriov_enabled)
+ 		roce_lag = !mlx5_sriov_is_enabled(dev0) &&
+ 			   !mlx5_sriov_is_enabled(dev1);
+ 
+ 		if (roce_lag)
  			for (i = 0; i < MLX5_MAX_PORTS; i++)
  				mlx5_remove_dev_by_protocol(ldev->pf[i].dev,
  							    MLX5_INTERFACE_PROTOCOL_IB);
@@@ -593,42 -619,33 +626,60 @@@ bool mlx5_lag_is_active(struct mlx5_cor
  }
  EXPORT_SYMBOL(mlx5_lag_is_active);
  
++<<<<<<< HEAD
 +static int mlx5_lag_set_state(struct mlx5_core_dev *dev, bool allow)
++=======
+ bool mlx5_lag_is_sriov(struct mlx5_core_dev *dev)
+ {
+ 	struct mlx5_lag *ldev;
+ 	bool res;
+ 
+ 	mutex_lock(&lag_mutex);
+ 	ldev = mlx5_lag_dev_get(dev);
+ 	res  = ldev && __mlx5_lag_is_sriov(ldev);
+ 	mutex_unlock(&lag_mutex);
+ 
+ 	return res;
+ }
+ EXPORT_SYMBOL(mlx5_lag_is_sriov);
+ 
+ void mlx5_lag_update(struct mlx5_core_dev *dev)
++>>>>>>> 7c34ec19e10c (net/mlx5: Make RoCE and SR-IOV LAG modes explicit)
  {
  	struct mlx5_lag *ldev;
 +	int ret = 0;
 +	bool lag_active;
  
  	mlx5_dev_list_lock();
 +
  	ldev = mlx5_lag_dev_get(dev);
 -	if (!ldev)
 +	if (!ldev) {
 +		ret = -ENODEV;
  		goto unlock;
 -
 -	mlx5_do_bond(ldev);
 -
 +	}
 +	lag_active = mlx5_lag_is_bonded(ldev);
 +	if (!mlx5_lag_check_prereq(ldev) && allow) {
 +		ret = -EINVAL;
 +		goto unlock;
 +	}
 +	if (ldev->allowed == allow)
 +		goto unlock;
 +	ldev->allowed = allow;
 +	if ((lag_active && !allow) || allow)
 +		mlx5_do_bond(ldev);
  unlock:
  	mlx5_dev_list_unlock();
 +	return ret;
 +}
 +
 +int mlx5_lag_forbid(struct mlx5_core_dev *dev)
 +{
 +	return mlx5_lag_set_state(dev, false);
 +}
 +
 +int mlx5_lag_allow(struct mlx5_core_dev *dev)
 +{
 +	return mlx5_lag_set_state(dev, true);
  }
  
  struct net_device *mlx5_lag_get_roce_netdev(struct mlx5_core_dev *dev)
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.c
* Unmerged path drivers/infiniband/hw/mlx5/main.c
diff --git a/drivers/infiniband/hw/mlx5/mlx5_ib.h b/drivers/infiniband/hw/mlx5/mlx5_ib.h
index 3c57e5c58ad3..6f43b4787e41 100644
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -805,6 +805,7 @@ struct mlx5_ib_dev {
 	struct mlx5_ib_delay_drop	delay_drop;
 	const struct mlx5_ib_profile	*profile;
 	struct mlx5_eswitch_rep		*rep;
+	int				lag_active;
 
 	/* protect the user_td */
 	struct mutex		lb_mutex;
diff --git a/drivers/infiniband/hw/mlx5/qp.c b/drivers/infiniband/hw/mlx5/qp.c
index 0e92d3e28641..acafec48887e 100644
--- a/drivers/infiniband/hw/mlx5/qp.c
+++ b/drivers/infiniband/hw/mlx5/qp.c
@@ -3191,7 +3191,7 @@ static int __mlx5_ib_modify_qp(struct ib_qp *ibqp,
 		    (ibqp->qp_type == IB_QPT_RAW_PACKET) ||
 		    (ibqp->qp_type == IB_QPT_XRC_INI) ||
 		    (ibqp->qp_type == IB_QPT_XRC_TGT)) {
-			if (mlx5_lag_is_active(dev->mdev)) {
+			if (dev->lag_active) {
 				u8 p = mlx5_core_native_port_num(dev->mdev);
 				tx_affinity = (unsigned int)atomic_add_return(1,
 						&dev->roce[p].next_port) %
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/lag.c
diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index af4fa7465c37..72aca934647f 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1177,6 +1177,8 @@ int mlx5_core_query_vendor_id(struct mlx5_core_dev *mdev, u32 *vendor_id);
 
 int mlx5_cmd_create_vport_lag(struct mlx5_core_dev *dev);
 int mlx5_cmd_destroy_vport_lag(struct mlx5_core_dev *dev);
+bool mlx5_lag_is_roce(struct mlx5_core_dev *dev);
+bool mlx5_lag_is_sriov(struct mlx5_core_dev *dev);
 bool mlx5_lag_is_active(struct mlx5_core_dev *dev);
 struct net_device *mlx5_lag_get_roce_netdev(struct mlx5_core_dev *dev);
 int mlx5_lag_query_cong_counters(struct mlx5_core_dev *dev,
