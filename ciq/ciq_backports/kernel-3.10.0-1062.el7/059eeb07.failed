qede: Support XDP adjustment of headers

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Mintz, Yuval <Yuval.Mintz@cavium.com>
commit 059eeb07e175086db1f84c1d8d29bb9aa8057797
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/059eeb07.failed

In case an XDP program is attached, reserve XDP_PACKET_HEADROOM
bytes at the beginning of the packet for the program to play
with.

Modify the XDP logic in the driver to fill-in the missing bits
and re-calculate offsets and length after the program has finished
running to properly reflect the current status of the packet.

We can then go and remove the limitation of not supporting XDP programs
where xdp_adjust_head is set.

	Signed-off-by: Yuval Mintz <Yuval.Mintz@cavium.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 059eeb07e175086db1f84c1d8d29bb9aa8057797)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/qlogic/qede/qede_filter.c
#	drivers/net/ethernet/qlogic/qede/qede_fp.c
diff --cc drivers/net/ethernet/qlogic/qede/qede_filter.c
index 057c39b50ff1,b00a4fce44b7..000000000000
--- a/drivers/net/ethernet/qlogic/qede/qede_filter.c
+++ b/drivers/net/ethernet/qlogic/qede/qede_filter.c
@@@ -1067,6 -502,50 +1067,53 @@@ void qede_udp_tunnel_del(struct net_dev
  	default:
  		return;
  	}
++<<<<<<< HEAD
++=======
+ 
+ 	schedule_delayed_work(&edev->sp_task, 0);
+ }
+ 
+ static void qede_xdp_reload_func(struct qede_dev *edev,
+ 				 struct qede_reload_args *args)
+ {
+ 	struct bpf_prog *old;
+ 
+ 	old = xchg(&edev->xdp_prog, args->u.new_prog);
+ 	if (old)
+ 		bpf_prog_put(old);
+ }
+ 
+ static int qede_xdp_set(struct qede_dev *edev, struct bpf_prog *prog)
+ {
+ 	struct qede_reload_args args;
+ 
+ 	/* If we're called, there was already a bpf reference increment */
+ 	args.func = &qede_xdp_reload_func;
+ 	args.u.new_prog = prog;
+ 	qede_reload(edev, &args, false);
+ 
+ 	return 0;
+ }
+ 
+ int qede_xdp(struct net_device *dev, struct netdev_xdp *xdp)
+ {
+ 	struct qede_dev *edev = netdev_priv(dev);
+ 
+ 	if (IS_VF(edev)) {
+ 		DP_NOTICE(edev, "VFs don't support XDP\n");
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	switch (xdp->command) {
+ 	case XDP_SETUP_PROG:
+ 		return qede_xdp_set(edev, xdp->prog);
+ 	case XDP_QUERY_PROG:
+ 		xdp->prog_attached = !!edev->xdp_prog;
+ 		return 0;
+ 	default:
+ 		return -EINVAL;
+ 	}
++>>>>>>> 059eeb07e175 (qede: Support XDP adjustment of headers)
  }
  
  static int qede_set_mcast_rx_mac(struct qede_dev *edev,
diff --cc drivers/net/ethernet/qlogic/qede/qede_fp.c
index 6001b8e5a281,961b1d36b9eb..000000000000
--- a/drivers/net/ethernet/qlogic/qede/qede_fp.c
+++ b/drivers/net/ethernet/qlogic/qede/qede_fp.c
@@@ -921,6 -987,74 +921,77 @@@ static bool qede_pkt_is_ip_fragmented(s
  	return false;
  }
  
++<<<<<<< HEAD
++=======
+ /* Return true iff packet is to be passed to stack */
+ static bool qede_rx_xdp(struct qede_dev *edev,
+ 			struct qede_fastpath *fp,
+ 			struct qede_rx_queue *rxq,
+ 			struct bpf_prog *prog,
+ 			struct sw_rx_data *bd,
+ 			struct eth_fast_path_rx_reg_cqe *cqe,
+ 			u16 *data_offset, u16 *len)
+ {
+ 	struct xdp_buff xdp;
+ 	enum xdp_action act;
+ 
+ 	xdp.data_hard_start = page_address(bd->data);
+ 	xdp.data = xdp.data_hard_start + *data_offset;
+ 	xdp.data_end = xdp.data + *len;
+ 
+ 	/* Queues always have a full reset currently, so for the time
+ 	 * being until there's atomic program replace just mark read
+ 	 * side for map helpers.
+ 	 */
+ 	rcu_read_lock();
+ 	act = bpf_prog_run_xdp(prog, &xdp);
+ 	rcu_read_unlock();
+ 
+ 	/* Recalculate, as XDP might have changed the headers */
+ 	*data_offset = xdp.data - xdp.data_hard_start;
+ 	*len = xdp.data_end - xdp.data;
+ 
+ 	if (act == XDP_PASS)
+ 		return true;
+ 
+ 	/* Count number of packets not to be passed to stack */
+ 	rxq->xdp_no_pass++;
+ 
+ 	switch (act) {
+ 	case XDP_TX:
+ 		/* We need the replacement buffer before transmit. */
+ 		if (qede_alloc_rx_buffer(rxq, true)) {
+ 			qede_recycle_rx_bd_ring(rxq, 1);
+ 			trace_xdp_exception(edev->ndev, prog, act);
+ 			return false;
+ 		}
+ 
+ 		/* Now if there's a transmission problem, we'd still have to
+ 		 * throw current buffer, as replacement was already allocated.
+ 		 */
+ 		if (qede_xdp_xmit(edev, fp, bd, *data_offset, *len)) {
+ 			dma_unmap_page(rxq->dev, bd->mapping,
+ 				       PAGE_SIZE, DMA_BIDIRECTIONAL);
+ 			__free_page(bd->data);
+ 			trace_xdp_exception(edev->ndev, prog, act);
+ 		}
+ 
+ 		/* Regardless, we've consumed an Rx BD */
+ 		qede_rx_bd_ring_consume(rxq);
+ 		return false;
+ 
+ 	default:
+ 		bpf_warn_invalid_xdp_action(act);
+ 	case XDP_ABORTED:
+ 		trace_xdp_exception(edev->ndev, prog, act);
+ 	case XDP_DROP:
+ 		qede_recycle_rx_bd_ring(rxq, cqe->bd_num);
+ 	}
+ 
+ 	return false;
+ }
+ 
++>>>>>>> 059eeb07e175 (qede: Support XDP adjustment of headers)
  static struct sk_buff *qede_rx_allocate_skb(struct qede_dev *edev,
  					    struct qede_rx_queue *rxq,
  					    struct sw_rx_data *bd, u16 len,
@@@ -1098,6 -1233,11 +1169,14 @@@ static int qede_rx_process_cqe(struct q
  	len = le16_to_cpu(fp_cqe->len_on_first_bd);
  	pad = fp_cqe->placement_offset + rxq->rx_headroom;
  
++<<<<<<< HEAD
++=======
+ 	/* Run eBPF program if one is attached */
+ 	if (xdp_prog)
+ 		if (!qede_rx_xdp(edev, fp, rxq, xdp_prog, bd, fp_cqe,
+ 				 &pad, &len))
+ 			return 0;
++>>>>>>> 059eeb07e175 (qede: Support XDP adjustment of headers)
  
  	/* If this is an error packet then drop it */
  	flags = cqe->fast_path_regular.pars_flags.flags;
* Unmerged path drivers/net/ethernet/qlogic/qede/qede_filter.c
* Unmerged path drivers/net/ethernet/qlogic/qede/qede_fp.c
diff --git a/drivers/net/ethernet/qlogic/qede/qede_main.c b/drivers/net/ethernet/qlogic/qede/qede_main.c
index 121608beefab..e7b07be2f252 100644
--- a/drivers/net/ethernet/qlogic/qede/qede_main.c
+++ b/drivers/net/ethernet/qlogic/qede/qede_main.c
@@ -1302,6 +1302,7 @@ static int qede_alloc_mem_rxq(struct qede_dev *edev, struct qede_rx_queue *rxq)
 	rxq->num_rx_buffers = edev->q_num_rx_buffers;
 
 	rxq->rx_buf_size = NET_IP_ALIGN + ETH_OVERHEAD + edev->ndev->mtu;
+	rxq->rx_headroom = edev->xdp_prog ? XDP_PACKET_HEADROOM : 0;
 
 	/* Make sure that the headroom and  payload fit in a single page */
 	if (rxq->rx_buf_size + rxq->rx_headroom > PAGE_SIZE)
