RDMA/nldev: Don't expose unsafe global rkey to regular user

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Leon Romanovsky <leonro@mellanox.com>
commit a9666c1cae8dbcd1a9aacd08a778bf2a28eea300
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/a9666c1c.failed

Unsafe global rkey is considered dangerous because it exposes memory
registered for all memory in the system. Only users with a QP on the same
PD can use the rkey, and generally those QPs will already know the
value. However, out of caution, do not expose the value to unprivleged
users on the local system. Require CAP_NET_ADMIN instead.

	Cc: <stable@vger.kernel.org> # 4.16
Fixes: 29cf1351d450 ("RDMA/nldev: provide detailed PD information")
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit a9666c1cae8dbcd1a9aacd08a778bf2a28eea300)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/nldev.c
diff --cc drivers/infiniband/core/nldev.c
index 8da01040baaf,3c97a8b6bf1e..000000000000
--- a/drivers/infiniband/core/nldev.c
+++ b/drivers/infiniband/core/nldev.c
@@@ -284,7 -487,121 +284,125 @@@ out
  	return -EMSGSIZE;
  }
  
++<<<<<<< HEAD
 +static int nldev_get_doit(struct sk_buff *skb, struct nlmsghdr *nlh)
++=======
+ static int fill_res_cq_entry(struct sk_buff *msg, struct netlink_callback *cb,
+ 			     struct rdma_restrack_entry *res, uint32_t port)
+ {
+ 	struct ib_cq *cq = container_of(res, struct ib_cq, res);
+ 	struct rdma_restrack_root *resroot = &cq->device->res;
+ 	struct nlattr *entry_attr;
+ 
+ 	entry_attr = nla_nest_start(msg, RDMA_NLDEV_ATTR_RES_CQ_ENTRY);
+ 	if (!entry_attr)
+ 		goto out;
+ 
+ 	if (nla_put_u32(msg, RDMA_NLDEV_ATTR_RES_CQE, cq->cqe))
+ 		goto err;
+ 	if (nla_put_u64_64bit(msg, RDMA_NLDEV_ATTR_RES_USECNT,
+ 			      atomic_read(&cq->usecnt), RDMA_NLDEV_ATTR_PAD))
+ 		goto err;
+ 
+ 	/* Poll context is only valid for kernel CQs */
+ 	if (rdma_is_kernel_res(res) &&
+ 	    nla_put_u8(msg, RDMA_NLDEV_ATTR_RES_POLL_CTX, cq->poll_ctx))
+ 		goto err;
+ 
+ 	if (fill_res_name_pid(msg, res))
+ 		goto err;
+ 
+ 	if (resroot->fill_res_entry(msg, res))
+ 		goto err;
+ 
+ 	nla_nest_end(msg, entry_attr);
+ 	return 0;
+ 
+ err:
+ 	nla_nest_cancel(msg, entry_attr);
+ out:
+ 	return -EMSGSIZE;
+ }
+ 
+ static int fill_res_mr_entry(struct sk_buff *msg, struct netlink_callback *cb,
+ 			     struct rdma_restrack_entry *res, uint32_t port)
+ {
+ 	struct ib_mr *mr = container_of(res, struct ib_mr, res);
+ 	struct rdma_restrack_root *resroot = &mr->pd->device->res;
+ 	struct nlattr *entry_attr;
+ 
+ 	entry_attr = nla_nest_start(msg, RDMA_NLDEV_ATTR_RES_MR_ENTRY);
+ 	if (!entry_attr)
+ 		goto out;
+ 
+ 	if (netlink_capable(cb->skb, CAP_NET_ADMIN)) {
+ 		if (nla_put_u32(msg, RDMA_NLDEV_ATTR_RES_RKEY, mr->rkey))
+ 			goto err;
+ 		if (nla_put_u32(msg, RDMA_NLDEV_ATTR_RES_LKEY, mr->lkey))
+ 			goto err;
+ 	}
+ 
+ 	if (nla_put_u64_64bit(msg, RDMA_NLDEV_ATTR_RES_MRLEN, mr->length,
+ 			      RDMA_NLDEV_ATTR_PAD))
+ 		goto err;
+ 
+ 	if (fill_res_name_pid(msg, res))
+ 		goto err;
+ 
+ 	if (resroot->fill_res_entry(msg, res))
+ 		goto err;
+ 
+ 	nla_nest_end(msg, entry_attr);
+ 	return 0;
+ 
+ err:
+ 	nla_nest_cancel(msg, entry_attr);
+ out:
+ 	return -EMSGSIZE;
+ }
+ 
+ static int fill_res_pd_entry(struct sk_buff *msg, struct netlink_callback *cb,
+ 			     struct rdma_restrack_entry *res, uint32_t port)
+ {
+ 	struct ib_pd *pd = container_of(res, struct ib_pd, res);
+ 	struct rdma_restrack_root *resroot = &pd->device->res;
+ 	struct nlattr *entry_attr;
+ 
+ 	entry_attr = nla_nest_start(msg, RDMA_NLDEV_ATTR_RES_PD_ENTRY);
+ 	if (!entry_attr)
+ 		goto out;
+ 
+ 	if (netlink_capable(cb->skb, CAP_NET_ADMIN)) {
+ 		if (nla_put_u32(msg, RDMA_NLDEV_ATTR_RES_LOCAL_DMA_LKEY,
+ 				pd->local_dma_lkey))
+ 			goto err;
+ 		if ((pd->flags & IB_PD_UNSAFE_GLOBAL_RKEY) &&
+ 		    nla_put_u32(msg, RDMA_NLDEV_ATTR_RES_UNSAFE_GLOBAL_RKEY,
+ 				pd->unsafe_global_rkey))
+ 			goto err;
+ 	}
+ 	if (nla_put_u64_64bit(msg, RDMA_NLDEV_ATTR_RES_USECNT,
+ 			      atomic_read(&pd->usecnt), RDMA_NLDEV_ATTR_PAD))
+ 		goto err;
+ 
+ 	if (fill_res_name_pid(msg, res))
+ 		goto err;
+ 
+ 	if (resroot->fill_res_entry(msg, res))
+ 		goto err;
+ 
+ 	nla_nest_end(msg, entry_attr);
+ 	return 0;
+ 
+ err:
+ 	nla_nest_cancel(msg, entry_attr);
+ out:
+ 	return -EMSGSIZE;
+ }
+ 
+ static int nldev_get_doit(struct sk_buff *skb, struct nlmsghdr *nlh,
+ 			  struct netlink_ext_ack *extack)
++>>>>>>> a9666c1cae8d (RDMA/nldev: Don't expose unsafe global rkey to regular user)
  {
  	struct nlattr *tb[RDMA_NLDEV_ATTR_MAX];
  	struct ib_device *device;
* Unmerged path drivers/infiniband/core/nldev.c
