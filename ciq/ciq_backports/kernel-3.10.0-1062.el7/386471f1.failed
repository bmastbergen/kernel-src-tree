net/mlx5e: RX, Dedicate a function for copying SKB header

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
Rebuild_CHGLOG: - [netdrv] mlx5e: RX, Dedicate a function for copying SKB header (Alaa Hleihel) [1642498]
Rebuild_FUZZ: 96.36%
commit-author Tariq Toukan <tariqt@mellanox.com>
commit 386471f16b73ddc52d1f711d63c7dba5559c31f6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/386471f1.failed

Get the logic of copying the packet header into the SKB linear part
into a generic function. Function does copy length alignment
and dma buffer sync.

It is currently called only within the MPWQE flow.
In a downstream patch, it will be called within the legacy RQ flow
as well.

	Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 386471f16b73ddc52d1f711d63c7dba5559c31f6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
index 29331bf7aa1d,634540afdcfc..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
@@@ -304,44 -311,42 +304,57 @@@ void mlx5e_dealloc_rx_wqe(struct mlx5e_
  		mlx5e_free_rx_wqe(rq, wi);
  }
  
 -static inline void
 -mlx5e_add_skb_frag(struct mlx5e_rq *rq, struct sk_buff *skb,
 -		   struct mlx5e_dma_info *di, u32 frag_offset, u32 len,
 -		   unsigned int truesize)
 +static inline int mlx5e_mpwqe_strides_per_page(struct mlx5e_rq *rq)
 +{
 +	return rq->mpwqe.num_strides >> MLX5_MPWRQ_WQE_PAGE_ORDER;
 +}
 +
 +static inline void mlx5e_add_skb_frag_mpwqe(struct mlx5e_rq *rq,
 +					    struct sk_buff *skb,
 +					    struct mlx5e_mpw_info *wi,
 +					    u32 page_idx, u32 frag_offset,
 +					    u32 len)
  {
 +	unsigned int truesize = ALIGN(len, BIT(rq->mpwqe.log_stride_sz));
 +
  	dma_sync_single_for_cpu(rq->pdev,
 -				di->addr + frag_offset,
 +				wi->umr.dma_info[page_idx].addr + frag_offset,
  				len, DMA_FROM_DEVICE);
 -	page_ref_inc(di->page);
 +	wi->skbs_frags[page_idx]++;
  	skb_add_rx_frag(skb, skb_shinfo(skb)->nr_frags,
 -			di->page, frag_offset, len, truesize);
 +			wi->umr.dma_info[page_idx].page, frag_offset,
 +			len, truesize);
  }
  
+ static inline void
+ mlx5e_copy_skb_header(struct device *pdev, struct sk_buff *skb,
+ 		      struct mlx5e_dma_info *dma_info,
+ 		      int offset_from, int offset_to, u32 headlen)
+ {
+ 	const void *from = page_address(dma_info->page) + offset_from;
+ 	/* Aligning len to sizeof(long) optimizes memcpy performance */
+ 	unsigned int len = ALIGN(headlen, sizeof(long));
+ 
+ 	dma_sync_single_for_cpu(pdev, dma_info->addr + offset_from, len,
+ 				DMA_FROM_DEVICE);
+ 	skb_copy_to_linear_data_offset(skb, offset_to, from, len);
+ }
+ 
  static inline void
  mlx5e_copy_skb_header_mpwqe(struct device *pdev,
  			    struct sk_buff *skb,
 -			    struct mlx5e_dma_info *dma_info,
 -			    u32 offset, u32 headlen)
 +			    struct mlx5e_mpw_info *wi,
 +			    u32 page_idx, u32 offset,
 +			    u32 headlen)
  {
  	u16 headlen_pg = min_t(u32, headlen, PAGE_SIZE - offset);
++<<<<<<< HEAD
 +	struct mlx5e_dma_info *dma_info = &wi->umr.dma_info[page_idx];
 +	unsigned int len;
++=======
++>>>>>>> 386471f16b73 (net/mlx5e: RX, Dedicate a function for copying SKB header)
  
- 	 /* Aligning len to sizeof(long) optimizes memcpy performance */
- 	len = ALIGN(headlen_pg, sizeof(long));
- 	dma_sync_single_for_cpu(pdev, dma_info->addr + offset, len,
- 				DMA_FROM_DEVICE);
- 	skb_copy_to_linear_data(skb, page_address(dma_info->page) + offset, len);
+ 	mlx5e_copy_skb_header(pdev, skb, dma_info, offset, 0, headlen_pg);
  
  	if (unlikely(offset + headlen > PAGE_SIZE)) {
  		dma_info++;
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
