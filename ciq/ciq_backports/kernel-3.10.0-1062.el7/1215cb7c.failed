RDMA/umem: Refactor exit paths in ib_umem_get

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Leon Romanovsky <leonro@mellanox.com>
commit 1215cb7c88ec888d599a249142a74dd93b8985ad
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/1215cb7c.failed

Simplify exit paths in ib_umem_get to use the standard goto unwind
pattern.

	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Reviewed-by: Michael J. Ruhl <michael.j.ruhl@intel.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 1215cb7c88ec888d599a249142a74dd93b8985ad)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/umem.c
diff --cc drivers/infiniband/core/umem.c
index 92842b803b18,a41792dbae1f..000000000000
--- a/drivers/infiniband/core/umem.c
+++ b/drivers/infiniband/core/umem.c
@@@ -90,12 -89,12 +90,16 @@@ struct ib_umem *ib_umem_get(struct ib_u
  	unsigned long npages;
  	int ret;
  	int i;
 -	unsigned long dma_attrs = 0;
 +	DEFINE_DMA_ATTRS(attrs);
  	struct scatterlist *sg, *sg_list_start;
++<<<<<<< HEAD
 +	int need_release = 0;
++=======
+ 	unsigned int gup_flags = FOLL_WRITE;
++>>>>>>> 1215cb7c88ec (RDMA/umem: Refactor exit paths in ib_umem_get)
  
  	if (dmasync)
 -		dma_attrs |= DMA_ATTR_WRITE_BARRIER;
 +		dma_set_attr(DMA_ATTR_WRITE_BARRIER, &attrs);
  
  	/*
  	 * If the combination of the addr and size requested for this memory
@@@ -148,15 -145,16 +150,15 @@@
  
  	npages = ib_umem_num_pages(umem);
  
 +	down_write(&current->mm->mmap_sem);
 +
 +	locked     = npages + current->mm->pinned_vm;
  	lock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;
  
 -	down_write(&current->mm->mmap_sem);
 -	current->mm->pinned_vm += npages;
 -	if ((current->mm->pinned_vm > lock_limit) && !capable(CAP_IPC_LOCK)) {
 -		up_write(&current->mm->mmap_sem);
 +	if ((locked > lock_limit) && !capable(CAP_IPC_LOCK)) {
  		ret = -ENOMEM;
- 		goto out;
+ 		goto vma;
  	}
 -	up_write(&current->mm->mmap_sem);
  
  	cur_base = addr & PAGE_MASK;
  
@@@ -167,19 -165,23 +169,35 @@@
  
  	ret = sg_alloc_table(&umem->sg_head, npages, GFP_KERNEL);
  	if (ret)
- 		goto out;
+ 		goto vma;
  
++<<<<<<< HEAD
 +	need_release = 1;
++=======
+ 	if (!umem->writable)
+ 		gup_flags |= FOLL_FORCE;
+ 
++>>>>>>> 1215cb7c88ec (RDMA/umem: Refactor exit paths in ib_umem_get)
  	sg_list_start = umem->sg_head.sgl;
  
 -	down_read(&current->mm->mmap_sem);
  	while (npages) {
  		ret = get_user_pages_longterm(cur_base,
++<<<<<<< HEAD
 +				min_t(unsigned long, npages,
 +				      PAGE_SIZE / sizeof (struct page *)),
 +				1, !umem->writable, page_list, vma_list);
 +
 +		if (ret < 0)
 +			goto out;
++=======
+ 				     min_t(unsigned long, npages,
+ 					   PAGE_SIZE / sizeof (struct page *)),
+ 				     gup_flags, page_list, vma_list);
+ 		if (ret < 0) {
+ 			up_read(&current->mm->mmap_sem);
+ 			goto umem_release;
+ 		}
++>>>>>>> 1215cb7c88ec (RDMA/umem: Refactor exit paths in ib_umem_get)
  
  		umem->npages += ret;
  		cur_base += ret * PAGE_SIZE;
@@@ -208,16 -211,15 +226,26 @@@
  	}
  
  	ret = 0;
+ 	goto out;
  
+ umem_release:
+ 	__ib_umem_release(context->device, umem, 0);
+ vma:
+ 	down_write(&current->mm->mmap_sem);
+ 	current->mm->pinned_vm -= ib_umem_num_pages(umem);
+ 	up_write(&current->mm->mmap_sem);
  out:
++<<<<<<< HEAD
 +	if (ret < 0) {
 +		if (need_release)
 +			__ib_umem_release(context->device, umem, 0);
 +		kfree(umem);
 +	} else
 +		current->mm->pinned_vm = locked;
 +
 +	up_write(&current->mm->mmap_sem);
++=======
++>>>>>>> 1215cb7c88ec (RDMA/umem: Refactor exit paths in ib_umem_get)
  	if (vma_list)
  		free_page((unsigned long) vma_list);
  	free_page((unsigned long) page_list);
* Unmerged path drivers/infiniband/core/umem.c
