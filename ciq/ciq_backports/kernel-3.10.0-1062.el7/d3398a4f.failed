net/mlx5e: RX, Prefetch the xdp_frame data area

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
Rebuild_CHGLOG: - [netdrv] mlx5e: RX, Prefetch the xdp_frame data area (Alaa Hleihel) [1642498]
Rebuild_FUZZ: 95.56%
commit-author Tariq Toukan <tariqt@mellanox.com>
commit d3398a4f1887eee46c22b37f6245faa6c51b130b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/d3398a4f.failed

A loaded XDP program might write to the xdp_frame data area,
prefetchw() it to avoid a potential cache miss.

Performance tests:
ConnectX-5, XDP_TX packet rate, single ring.
CPU: Intel(R) Xeon(R) CPU E5-2680 v3 @ 2.50GHz

Before: 13,172,976 pps
After:  13,456,248 pps
2% gain.

Fixes: 22f453988194 ("net/mlx5e: Support XDP over Striding RQ")
	Signed-off-by: Tariq Toukan <tariqt@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit d3398a4f1887eee46c22b37f6245faa6c51b130b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
index 3631c4f3022b,15d8ae28c040..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
@@@ -1043,6 -1077,48 +1043,51 @@@ static inline void mlx5e_mpwqe_fill_rx_
  	/* skb linear part was allocated with headlen and aligned to long */
  	skb->tail += headlen;
  	skb->len  += headlen;
++<<<<<<< HEAD
++=======
+ 
+ 	return skb;
+ }
+ 
+ struct sk_buff *
+ mlx5e_skb_from_cqe_mpwrq_linear(struct mlx5e_rq *rq, struct mlx5e_mpw_info *wi,
+ 				u16 cqe_bcnt, u32 head_offset, u32 page_idx)
+ {
+ 	struct mlx5e_dma_info *di = &wi->umr.dma_info[page_idx];
+ 	u16 rx_headroom = rq->buff.headroom;
+ 	u32 cqe_bcnt32 = cqe_bcnt;
+ 	struct sk_buff *skb;
+ 	void *va, *data;
+ 	u32 frag_size;
+ 	bool consumed;
+ 
+ 	va             = page_address(di->page) + head_offset;
+ 	data           = va + rx_headroom;
+ 	frag_size      = MLX5_SKB_FRAG_SZ(rx_headroom + cqe_bcnt32);
+ 
+ 	dma_sync_single_range_for_cpu(rq->pdev, di->addr, head_offset,
+ 				      frag_size, DMA_FROM_DEVICE);
+ 	prefetchw(va); /* xdp_frame data area */
+ 	prefetch(data);
+ 
+ 	rcu_read_lock();
+ 	consumed = mlx5e_xdp_handle(rq, di, va, &rx_headroom, &cqe_bcnt32);
+ 	rcu_read_unlock();
+ 	if (consumed) {
+ 		if (__test_and_clear_bit(MLX5E_RQ_FLAG_XDP_XMIT, rq->flags))
+ 			__set_bit(page_idx, wi->xdp_xmit_bitmap); /* non-atomic */
+ 		return NULL; /* page/packet was consumed by XDP */
+ 	}
+ 
+ 	skb = mlx5e_build_linear_skb(rq, va, frag_size, rx_headroom, cqe_bcnt32);
+ 	if (unlikely(!skb))
+ 		return NULL;
+ 
+ 	/* queue up for recycling/reuse */
+ 	page_ref_inc(di->page);
+ 
+ 	return skb;
++>>>>>>> d3398a4f1887 (net/mlx5e: RX, Prefetch the xdp_frame data area)
  }
  
  void mlx5e_handle_rx_cqe_mpwrq(struct mlx5e_rq *rq, struct mlx5_cqe64 *cqe)
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rx.c
