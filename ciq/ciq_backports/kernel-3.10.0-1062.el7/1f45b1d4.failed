perf bpf: Attach eBPF filter to perf event

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Wang Nan <wangnan0@huawei.com>
commit 1f45b1d49073541947193bd7dac9e904142576aa
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/1f45b1d4.failed

This is the final patch which makes basic BPF filter work. After
applying this patch, users are allowed to use BPF filter like:

 # perf record --event ./hello_world.o ls

A bpf_fd field is appended to 'struct evsel', and setup during the
callback function add_bpf_event() for each 'probe_trace_event'.

PERF_EVENT_IOC_SET_BPF ioctl is used to attach eBPF program to a newly
created perf event. The file descriptor of the eBPF program is passed to
perf record using previous patches, and stored into evsel->bpf_fd.

It is possible that different perf event are created for one kprobe
events for different CPUs. In this case, when trying to call the ioctl,
EEXIST will be return. This patch doesn't treat it as an error.

Committer note:

The bpf proggie used so far:

  __attribute__((section("fork=_do_fork"), used))
  int fork(void *ctx)
  {
	  return 0;
  }

  char _license[] __attribute__((section("license"), used)) = "GPL";
  int _version __attribute__((section("version"), used)) = 0x40300;

failed to produce any samples, even with forks happening and it being
running in system wide mode.

That is because now the filter is being associated, and the code above
always returns zero, meaning that all forks will be probed but filtered
away ;-/

Change it to 'return 1;' instead and after that:

  # trace --no-syscalls --event /tmp/foo.o
     0.000 perf_bpf_probe:fork:(ffffffff8109be30))
     2.333 perf_bpf_probe:fork:(ffffffff8109be30))
     3.725 perf_bpf_probe:fork:(ffffffff8109be30))
     4.550 perf_bpf_probe:fork:(ffffffff8109be30))
  ^C#

And it works with all tools, including 'perf trace'.

	Signed-off-by: Wang Nan <wangnan0@huawei.com>
	Tested-by: Arnaldo Carvalho de Melo <acme@redhat.com>
	Cc: Alexei Starovoitov <ast@plumgrid.com>
	Cc: Brendan Gregg <brendan.d.gregg@gmail.com>
	Cc: Daniel Borkmann <daniel@iogearbox.net>
	Cc: David Ahern <dsahern@gmail.com>
	Cc: He Kuang <hekuang@huawei.com>
	Cc: Jiri Olsa <jolsa@kernel.org>
	Cc: Kaixu Xia <xiakaixu@huawei.com>
	Cc: Masami Hiramatsu <masami.hiramatsu.pt@hitachi.com>
	Cc: Namhyung Kim <namhyung@kernel.org>
	Cc: Peter Zijlstra <a.p.zijlstra@chello.nl>
	Cc: Zefan Li <lizefan@huawei.com>
	Cc: pi3orama@163.com
Link: http://lkml.kernel.org/r/1444826502-49291-8-git-send-email-wangnan0@huawei.com
	Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
(cherry picked from commit 1f45b1d49073541947193bd7dac9e904142576aa)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/perf/util/evsel.c
#	tools/perf/util/evsel.h
#	tools/perf/util/parse-events.c
diff --cc tools/perf/util/evsel.c
index 72b728d1c057,397fb4ed3c97..000000000000
--- a/tools/perf/util/evsel.c
+++ b/tools/perf/util/evsel.c
@@@ -1712,7 -1358,20 +1713,24 @@@ retry_open
  				goto try_fallback;
  			}
  
++<<<<<<< HEAD
 +			pr_debug2(" = %d\n", fd);
++=======
+ 			if (evsel->bpf_fd >= 0) {
+ 				int evt_fd = FD(evsel, cpu, thread);
+ 				int bpf_fd = evsel->bpf_fd;
+ 
+ 				err = ioctl(evt_fd,
+ 					    PERF_EVENT_IOC_SET_BPF,
+ 					    bpf_fd);
+ 				if (err && errno != EEXIST) {
+ 					pr_err("failed to attach bpf fd %d: %s\n",
+ 					       bpf_fd, strerror(errno));
+ 					err = -EINVAL;
+ 					goto out_close;
+ 				}
+ 			}
++>>>>>>> 1f45b1d49073 (perf bpf: Attach eBPF filter to perf event)
  
  			set_rlimit = NO_CHANGE;
  
diff --cc tools/perf/util/evsel.h
index 2f73d542a1a1,0e49bd742c63..000000000000
--- a/tools/perf/util/evsel.h
+++ b/tools/perf/util/evsel.h
@@@ -132,13 -123,7 +132,17 @@@ struct perf_evsel 
  	char			*group_name;
  	bool			cmdline_group_boundary;
  	struct list_head	config_terms;
++<<<<<<< HEAD
 +	bool			auto_merge_stats;
 +	bool			merged_stat;
 +	const char *		metric_expr;
 +	const char *		metric_name;
 +	struct perf_evsel	**metric_events;
 +	bool			collect_stat;
 +	bool			weak_group;
++=======
+ 	int			bpf_fd;
++>>>>>>> 1f45b1d49073 (perf bpf: Attach eBPF filter to perf event)
  };
  
  union u64_swap {
diff --cc tools/perf/util/parse-events.c
index 3a234b74d6ff,cee8c619ec7e..000000000000
--- a/tools/perf/util/parse-events.c
+++ b/tools/perf/util/parse-events.c
@@@ -590,6 -530,129 +590,132 @@@ static int add_tracepoint_multi_sys(str
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ struct __add_bpf_event_param {
+ 	struct parse_events_evlist *data;
+ 	struct list_head *list;
+ };
+ 
+ static int add_bpf_event(struct probe_trace_event *tev, int fd,
+ 			 void *_param)
+ {
+ 	LIST_HEAD(new_evsels);
+ 	struct __add_bpf_event_param *param = _param;
+ 	struct parse_events_evlist *evlist = param->data;
+ 	struct list_head *list = param->list;
+ 	struct perf_evsel *pos;
+ 	int err;
+ 
+ 	pr_debug("add bpf event %s:%s and attach bpf program %d\n",
+ 		 tev->group, tev->event, fd);
+ 
+ 	err = parse_events_add_tracepoint(&new_evsels, &evlist->idx, tev->group,
+ 					  tev->event, evlist->error, NULL);
+ 	if (err) {
+ 		struct perf_evsel *evsel, *tmp;
+ 
+ 		pr_debug("Failed to add BPF event %s:%s\n",
+ 			 tev->group, tev->event);
+ 		list_for_each_entry_safe(evsel, tmp, &new_evsels, node) {
+ 			list_del(&evsel->node);
+ 			perf_evsel__delete(evsel);
+ 		}
+ 		return err;
+ 	}
+ 	pr_debug("adding %s:%s\n", tev->group, tev->event);
+ 
+ 	list_for_each_entry(pos, &new_evsels, node) {
+ 		pr_debug("adding %s:%s to %p\n",
+ 			 tev->group, tev->event, pos);
+ 		pos->bpf_fd = fd;
+ 	}
+ 	list_splice(&new_evsels, list);
+ 	return 0;
+ }
+ 
+ int parse_events_load_bpf_obj(struct parse_events_evlist *data,
+ 			      struct list_head *list,
+ 			      struct bpf_object *obj)
+ {
+ 	int err;
+ 	char errbuf[BUFSIZ];
+ 	struct __add_bpf_event_param param = {data, list};
+ 	static bool registered_unprobe_atexit = false;
+ 
+ 	if (IS_ERR(obj) || !obj) {
+ 		snprintf(errbuf, sizeof(errbuf),
+ 			 "Internal error: load bpf obj with NULL");
+ 		err = -EINVAL;
+ 		goto errout;
+ 	}
+ 
+ 	/*
+ 	 * Register atexit handler before calling bpf__probe() so
+ 	 * bpf__probe() don't need to unprobe probe points its already
+ 	 * created when failure.
+ 	 */
+ 	if (!registered_unprobe_atexit) {
+ 		atexit(bpf__clear);
+ 		registered_unprobe_atexit = true;
+ 	}
+ 
+ 	err = bpf__probe(obj);
+ 	if (err) {
+ 		bpf__strerror_probe(obj, err, errbuf, sizeof(errbuf));
+ 		goto errout;
+ 	}
+ 
+ 	err = bpf__load(obj);
+ 	if (err) {
+ 		bpf__strerror_load(obj, err, errbuf, sizeof(errbuf));
+ 		goto errout;
+ 	}
+ 
+ 	err = bpf__foreach_tev(obj, add_bpf_event, &param);
+ 	if (err) {
+ 		snprintf(errbuf, sizeof(errbuf),
+ 			 "Attach events in BPF object failed");
+ 		goto errout;
+ 	}
+ 
+ 	return 0;
+ errout:
+ 	data->error->help = strdup("(add -v to see detail)");
+ 	data->error->str = strdup(errbuf);
+ 	return err;
+ }
+ 
+ int parse_events_load_bpf(struct parse_events_evlist *data,
+ 			  struct list_head *list,
+ 			  char *bpf_file_name)
+ {
+ 	struct bpf_object *obj;
+ 
+ 	obj = bpf__prepare_load(bpf_file_name);
+ 	if (IS_ERR(obj) || !obj) {
+ 		char errbuf[BUFSIZ];
+ 		int err;
+ 
+ 		err = obj ? PTR_ERR(obj) : -EINVAL;
+ 
+ 		if (err == -ENOTSUP)
+ 			snprintf(errbuf, sizeof(errbuf),
+ 				 "BPF support is not compiled");
+ 		else
+ 			snprintf(errbuf, sizeof(errbuf),
+ 				 "BPF object file '%s' is invalid",
+ 				 bpf_file_name);
+ 
+ 		data->error->help = strdup("(add -v to see detail)");
+ 		data->error->str = strdup(errbuf);
+ 		return err;
+ 	}
+ 
+ 	return parse_events_load_bpf_obj(data, list, obj);
+ }
+ 
++>>>>>>> 1f45b1d49073 (perf bpf: Attach eBPF filter to perf event)
  static int
  parse_breakpoint_type(const char *type, struct perf_event_attr *attr)
  {
* Unmerged path tools/perf/util/evsel.c
* Unmerged path tools/perf/util/evsel.h
* Unmerged path tools/perf/util/parse-events.c
