rcu: Move lockless_dereference() out of rcupdate.h

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Peter Zijlstra <peterz@infradead.org>
commit 0a04b0166929405cd833c1cc40f99e862b965ddc
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/0a04b016.failed

I want to use lockless_dereference() from seqlock.h, which would mean
including rcupdate.h from it, however rcupdate.h already includes
seqlock.h.

Avoid this by moving lockless_dereference() into compiler.h. This is
somewhat tricky since it uses smp_read_barrier_depends() which isn't
available there, but its a CPP macro so we can get away with it.

The alternative would be moving it into asm/barrier.h, but that would
be updating each arch (I can do if people feel that is more
appropriate).

	Cc: Paul McKenney <paulmck@linux.vnet.ibm.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Signed-off-by: Rusty Russell <rusty@rustcorp.com.au>
(cherry picked from commit 0a04b0166929405cd833c1cc40f99e862b965ddc)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/rcupdate.h
diff --cc include/linux/rcupdate.h
index 68df10240cb4,0356ad954ea5..000000000000
--- a/include/linux/rcupdate.h
+++ b/include/linux/rcupdate.h
@@@ -536,63 -608,79 +536,97 @@@ static inline void rcu_preempt_sleep_ch
  #endif /* #else #ifdef __CHECKER__ */
  
  #define __rcu_access_pointer(p, space) \
 -({ \
 -	typeof(*p) *_________p1 = (typeof(*p) *__force)ACCESS_ONCE(p); \
 -	rcu_dereference_sparse(p, space); \
 -	((typeof(*p) __force __kernel *)(_________p1)); \
 -})
 +	({ \
 +		typeof(*p) *_________p1 = (typeof(*p)*__force )ACCESS_ONCE(p); \
 +		rcu_dereference_sparse(p, space); \
 +		((typeof(*p) __force __kernel *)(_________p1)); \
 +	})
  #define __rcu_dereference_check(p, c, space) \
 -({ \
 -	/* Dependency order vs. p above. */ \
 -	typeof(*p) *________p1 = (typeof(*p) *__force)lockless_dereference(p); \
 -	rcu_lockdep_assert(c, "suspicious rcu_dereference_check() usage"); \
 -	rcu_dereference_sparse(p, space); \
 -	((typeof(*p) __force __kernel *)(________p1)); \
 -})
 +	({ \
 +		typeof(*p) *_________p1 = (typeof(*p)*__force )ACCESS_ONCE(p); \
 +		rcu_lockdep_assert(c, "suspicious rcu_dereference_check()" \
 +				      " usage"); \
 +		rcu_dereference_sparse(p, space); \
 +		smp_read_barrier_depends(); \
 +		((typeof(*p) __force __kernel *)(_________p1)); \
 +	})
  #define __rcu_dereference_protected(p, c, space) \
 -({ \
 -	rcu_lockdep_assert(c, "suspicious rcu_dereference_protected() usage"); \
 -	rcu_dereference_sparse(p, space); \
 -	((typeof(*p) __force __kernel *)(p)); \
 -})
 +	({ \
 +		rcu_lockdep_assert(c, "suspicious rcu_dereference_protected()" \
 +				      " usage"); \
 +		rcu_dereference_sparse(p, space); \
 +		((typeof(*p) __force __kernel *)(p)); \
 +	})
  
  #define __rcu_access_index(p, space) \
 -({ \
 -	typeof(p) _________p1 = ACCESS_ONCE(p); \
 -	rcu_dereference_sparse(p, space); \
 -	(_________p1); \
 -})
 +	({ \
 +		typeof(p) _________p1 = ACCESS_ONCE(p); \
 +		rcu_dereference_sparse(p, space); \
 +		(_________p1); \
 +	})
  #define __rcu_dereference_index_check(p, c) \
 -({ \
 -	/* Dependency order vs. p above. */ \
 -	typeof(p) _________p1 = lockless_dereference(p); \
 -	rcu_lockdep_assert(c, \
 -			   "suspicious rcu_dereference_index_check() usage"); \
 -	(_________p1); \
 -})
 +	({ \
 +		typeof(p) _________p1 = ACCESS_ONCE(p); \
 +		rcu_lockdep_assert(c, \
 +				   "suspicious rcu_dereference_index_check()" \
 +				   " usage"); \
 +		smp_read_barrier_depends(); \
 +		(_________p1); \
 +	})
 +#define __rcu_assign_pointer(p, v, space) \
 +	do { \
 +		smp_wmb(); \
 +		(p) = (typeof(*v) __force space *)(v); \
 +	} while (0)
  
  /**
 - * RCU_INITIALIZER() - statically initialize an RCU-protected global variable
 - * @v: The value to statically initialize with.
++<<<<<<< HEAD
 + * lockless_dereference() - safely load a pointer for later dereference
 + * @p: The pointer to load
 + *
 + * Similar to rcu_dereference(), but for situations where the pointed-to
 + * object's lifetime is managed by something other than RCU.  That
 + * "something other" might be reference counting or simple immortality.
   */
 -#define RCU_INITIALIZER(v) (typeof(*(v)) __force __rcu *)(v)
 -
 -/**
 +#define lockless_dereference(p) \
 +({ \
 +	typeof(p) _________p1 = ACCESS_ONCE(p); \
 +	smp_read_barrier_depends(); /* Dependency order vs. p above. */ \
 +	(_________p1); \
 +})
++=======
+  * rcu_assign_pointer() - assign to RCU-protected pointer
+  * @p: pointer to assign to
+  * @v: value to assign (publish)
+  *
+  * Assigns the specified value to the specified RCU-protected
+  * pointer, ensuring that any concurrent RCU readers will see
+  * any prior initialization.
+  *
+  * Inserts memory barriers on architectures that require them
+  * (which is most of them), and also prevents the compiler from
+  * reordering the code that initializes the structure after the pointer
+  * assignment.  More importantly, this call documents which pointers
+  * will be dereferenced by RCU read-side code.
+  *
+  * In some special cases, you may use RCU_INIT_POINTER() instead
+  * of rcu_assign_pointer().  RCU_INIT_POINTER() is a bit faster due
+  * to the fact that it does not constrain either the CPU or the compiler.
+  * That said, using RCU_INIT_POINTER() when you should have used
+  * rcu_assign_pointer() is a very bad thing that results in
+  * impossible-to-diagnose memory corruption.  So please be careful.
+  * See the RCU_INIT_POINTER() comment header for details.
+  *
+  * Note that rcu_assign_pointer() evaluates each of its arguments only
+  * once, appearances notwithstanding.  One of the "extra" evaluations
+  * is in typeof() and the other visible only to sparse (__CHECKER__),
+  * neither of which actually execute the argument.  As with most cpp
+  * macros, this execute-arguments-only-once property is important, so
+  * please be careful when making changes to rcu_assign_pointer() and the
+  * other macros that it invokes.
+  */
+ #define rcu_assign_pointer(p, v) smp_store_release(&p, RCU_INITIALIZER(v))
++>>>>>>> 0a04b0166929 (rcu: Move lockless_dereference() out of rcupdate.h)
  
  /**
   * rcu_access_pointer() - fetch RCU pointer with no dereferencing
diff --git a/include/linux/compiler.h b/include/linux/compiler.h
index b3ab2d59538a..4671173fe14f 100644
--- a/include/linux/compiler.h
+++ b/include/linux/compiler.h
@@ -471,6 +471,21 @@ static __always_inline void __write_once_size(volatile void *p, void *res, int s
  */
 #define ACCESS_ONCE(x) (*(volatile typeof(x) *)&(x))
 
+/**
+ * lockless_dereference() - safely load a pointer for later dereference
+ * @p: The pointer to load
+ *
+ * Similar to rcu_dereference(), but for situations where the pointed-to
+ * object's lifetime is managed by something other than RCU.  That
+ * "something other" might be reference counting or simple immortality.
+ */
+#define lockless_dereference(p) \
+({ \
+	typeof(p) _________p1 = ACCESS_ONCE(p); \
+	smp_read_barrier_depends(); /* Dependency order vs. p above. */ \
+	(_________p1); \
+})
+
 /* Ignore/forbid kprobes attach on very low level functions marked by this attribute: */
 #ifdef CONFIG_KPROBES
 # define __kprobes	__attribute__((__section__(".kprobes.text")))
* Unmerged path include/linux/rcupdate.h
