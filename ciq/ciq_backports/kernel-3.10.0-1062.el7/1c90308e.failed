pagemap: hide physical addresses from non-privileged users

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
commit 1c90308e7a77af6742a97d1021cca923b23b7f0d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/1c90308e.failed

This patch makes pagemap readable for normal users and hides physical
addresses from them.  For some use-cases PFN isn't required at all.

See http://lkml.kernel.org/r/1425935472-17949-1-git-send-email-kirill@shutemov.name

Fixes: ab676b7d6fbf ("pagemap: do not leak physical addresses to non-privileged userspace")
	Signed-off-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>
	Cc: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
	Reviewed-by: Mark Williamson <mwilliamson@undo-software.com>
	Tested-by:  Mark Williamson <mwilliamson@undo-software.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 1c90308e7a77af6742a97d1021cca923b23b7f0d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/proc/task_mmu.c
diff --cc fs/proc/task_mmu.c
index bf81d9f4a02e,bc651644b1b2..000000000000
--- a/fs/proc/task_mmu.c
+++ b/fs/proc/task_mmu.c
@@@ -999,7 -939,7 +999,11 @@@ typedef struct 
  struct pagemapread {
  	int pos, len;		/* units: PM_ENTRY_BYTES, not bytes */
  	pagemap_entry_t *buffer;
++<<<<<<< HEAD
 +	bool v2;
++=======
+ 	bool show_pfn;
++>>>>>>> 1c90308e7a77 (pagemap: hide physical addresses from non-privileged users)
  };
  
  #define PAGEMAP_WALK_SIZE	(PMD_SIZE)
@@@ -1080,19 -1009,19 +1084,25 @@@ out
  	return err;
  }
  
 -static pagemap_entry_t pte_to_pagemap_entry(struct pagemapread *pm,
 +static void pte_to_pagemap_entry(pagemap_entry_t *pme, struct pagemapread *pm,
  		struct vm_area_struct *vma, unsigned long addr, pte_t pte)
  {
 -	u64 frame = 0, flags = 0;
 +	u64 frame, flags;
  	struct page *page = NULL;
 +	int flags2 = 0;
  
  	if (pte_present(pte)) {
++<<<<<<< HEAD
 +		frame = pte_pfn(pte);
 +		flags = PM_PRESENT;
++=======
+ 		if (pm->show_pfn)
+ 			frame = pte_pfn(pte);
+ 		flags |= PM_PRESENT;
++>>>>>>> 1c90308e7a77 (pagemap: hide physical addresses from non-privileged users)
  		page = vm_normal_page(vma, addr, pte);
  		if (pte_soft_dirty(pte))
 -			flags |= PM_SOFT_DIRTY;
 +			flags2 |= __PM_SOFT_DIRTY;
  	} else if (is_swap_pte(pte)) {
  		swp_entry_t entry;
  		if (pte_swp_soft_dirty(pte))
@@@ -1114,63 -1036,50 +1124,86 @@@
  
  	if (page && !PageAnon(page))
  		flags |= PM_FILE;
 -	if (vma->vm_flags & VM_SOFTDIRTY)
 -		flags |= PM_SOFT_DIRTY;
 +	if ((vma->vm_flags & VM_SOFTDIRTY))
 +		flags2 |= __PM_SOFT_DIRTY;
  
 -	return make_pme(frame, flags);
 +	*pme = make_pme(PM_PFRAME(frame) | PM_STATUS2(pm->v2, flags2) | flags);
  }
  
 -static int pagemap_pmd_range(pmd_t *pmdp, unsigned long addr, unsigned long end,
 +#ifdef CONFIG_TRANSPARENT_HUGEPAGE
 +static void thp_pmd_to_pagemap_entry(pagemap_entry_t *pme, struct pagemapread *pm,
 +		pmd_t pmd, int offset, int pmd_flags2)
 +{
 +	/*
 +	 * Currently pmd for thp is always present because thp can not be
 +	 * swapped-out, migrated, or HWPOISONed (split in such cases instead.)
 +	 * This if-check is just to prepare for future implementation.
 +	 */
 +	if (pmd_present(pmd))
 +		*pme = make_pme(PM_PFRAME(pmd_pfn(pmd) + offset)
 +				| PM_STATUS2(pm->v2, pmd_flags2) | PM_PRESENT);
 +	else
 +		*pme = make_pme(PM_NOT_PRESENT(pm->v2) | PM_STATUS2(pm->v2, pmd_flags2));
 +}
 +#else
 +static inline void thp_pmd_to_pagemap_entry(pagemap_entry_t *pme, struct pagemapread *pm,
 +		pmd_t pmd, int offset, int pmd_flags2)
 +{
 +}
 +#endif
 +
 +static int pagemap_pte_range(pmd_t *pmd, unsigned long addr, unsigned long end,
  			     struct mm_walk *walk)
  {
 -	struct vm_area_struct *vma = walk->vma;
 +	struct vm_area_struct *vma;
  	struct pagemapread *pm = walk->private;
  	spinlock_t *ptl;
 -	pte_t *pte, *orig_pte;
 +	pte_t *pte;
  	int err = 0;
  
 -#ifdef CONFIG_TRANSPARENT_HUGEPAGE
 -	if (pmd_trans_huge_lock(pmdp, vma, &ptl) == 1) {
 -		u64 flags = 0, frame = 0;
 -		pmd_t pmd = *pmdp;
 +	/* find the first VMA at or above 'addr' */
 +	vma = find_vma(walk->mm, addr);
 +	if (vma && pmd_trans_huge_lock(pmd, vma, &ptl) == 1) {
 +		int pmd_flags2;
  
++<<<<<<< HEAD
 +		if ((vma->vm_flags & VM_SOFTDIRTY) || pmd_soft_dirty(*pmd))
 +			pmd_flags2 = __PM_SOFT_DIRTY;
 +		else
 +			pmd_flags2 = 0;
++=======
+ 		if ((vma->vm_flags & VM_SOFTDIRTY) || pmd_soft_dirty(pmd))
+ 			flags |= PM_SOFT_DIRTY;
+ 
+ 		/*
+ 		 * Currently pmd for thp is always present because thp
+ 		 * can not be swapped-out, migrated, or HWPOISONed
+ 		 * (split in such cases instead.)
+ 		 * This if-check is just to prepare for future implementation.
+ 		 */
+ 		if (pmd_present(pmd)) {
+ 			flags |= PM_PRESENT;
+ 			if (pm->show_pfn)
+ 				frame = pmd_pfn(pmd) +
+ 					((addr & ~PMD_MASK) >> PAGE_SHIFT);
+ 		}
++>>>>>>> 1c90308e7a77 (pagemap: hide physical addresses from non-privileged users)
  
  		for (; addr != end; addr += PAGE_SIZE) {
 -			pagemap_entry_t pme = make_pme(frame, flags);
 +			unsigned long offset;
 +			pagemap_entry_t pme;
  
 +			offset = (addr & ~PAGEMAP_WALK_MASK) >>
 +					PAGE_SHIFT;
 +			thp_pmd_to_pagemap_entry(&pme, pm, *pmd, offset, pmd_flags2);
  			err = add_to_pagemap(addr, &pme, pm);
  			if (err)
  				break;
++<<<<<<< HEAD
++=======
+ 			if (pm->show_pfn && (flags & PM_PRESENT))
+ 				frame++;
++>>>>>>> 1c90308e7a77 (pagemap: hide physical addresses from non-privileged users)
  		}
  		spin_unlock(ptl);
  		return err;
@@@ -1249,25 -1116,35 +1282,45 @@@ static int pagemap_hugetlb_range(pte_t 
  				 struct mm_walk *walk)
  {
  	struct pagemapread *pm = walk->private;
 -	struct vm_area_struct *vma = walk->vma;
 -	u64 flags = 0, frame = 0;
 +	struct vm_area_struct *vma;
  	int err = 0;
 -	pte_t pte;
 -
 -	if (vma->vm_flags & VM_SOFTDIRTY)
 -		flags |= PM_SOFT_DIRTY;
 -
 +	int flags2;
 +	pagemap_entry_t pme;
 +
 +	vma = find_vma(walk->mm, addr);
 +	WARN_ON_ONCE(!vma);
 +
++<<<<<<< HEAD
 +	if (vma && (vma->vm_flags & VM_SOFTDIRTY))
 +		flags2 = __PM_SOFT_DIRTY;
 +	else
 +		flags2 = 0;
++=======
+ 	pte = huge_ptep_get(ptep);
+ 	if (pte_present(pte)) {
+ 		struct page *page = pte_page(pte);
+ 
+ 		if (!PageAnon(page))
+ 			flags |= PM_FILE;
+ 
+ 		flags |= PM_PRESENT;
+ 		if (pm->show_pfn)
+ 			frame = pte_pfn(pte) +
+ 				((addr & ~hmask) >> PAGE_SHIFT);
+ 	}
++>>>>>>> 1c90308e7a77 (pagemap: hide physical addresses from non-privileged users)
  
  	for (; addr != end; addr += PAGE_SIZE) {
 -		pagemap_entry_t pme = make_pme(frame, flags);
 -
 +		int offset = (addr & ~hmask) >> PAGE_SHIFT;
 +		huge_pte_to_pagemap_entry(&pme, pm, *pte, offset, flags2);
  		err = add_to_pagemap(addr, &pme, pm);
  		if (err)
  			return err;
++<<<<<<< HEAD
++=======
+ 		if (pm->show_pfn && (flags & PM_PRESENT))
+ 			frame++;
++>>>>>>> 1c90308e7a77 (pagemap: hide physical addresses from non-privileged users)
  	}
  
  	cond_resched();
@@@ -1324,7 -1202,9 +1377,13 @@@ static ssize_t pagemap_read(struct fil
  	if (!count)
  		goto out_mm;
  
++<<<<<<< HEAD
 +	pm.v2 = soft_dirty_cleared;
++=======
+ 	/* do not disclose physical addresses: attack vector */
+ 	pm.show_pfn = file_ns_capable(file, &init_user_ns, CAP_SYS_ADMIN);
+ 
++>>>>>>> 1c90308e7a77 (pagemap: hide physical addresses from non-privileged users)
  	pm.len = (PAGEMAP_WALK_SIZE >> PAGE_SHIFT);
  	pm.buffer = kmalloc(pm.len * PM_ENTRY_BYTES, GFP_TEMPORARY);
  	ret = -ENOMEM;
@@@ -1394,13 -1274,6 +1453,16 @@@ static int pagemap_open(struct inode *i
  {
  	struct mm_struct *mm;
  
++<<<<<<< HEAD
 +	/* do not disclose physical addresses: attack vector */
 +	if (!capable(CAP_SYS_ADMIN))
 +		return -EPERM;
 +	pr_warn_once("Bits 55-60 of /proc/PID/pagemap entries are about "
 +			"to stop being page-shift some time soon. See the "
 +			"linux/Documentation/vm/pagemap.txt for details.\n");
 +
++=======
++>>>>>>> 1c90308e7a77 (pagemap: hide physical addresses from non-privileged users)
  	mm = proc_mem_open(inode, PTRACE_MODE_READ);
  	if (IS_ERR(mm))
  		return PTR_ERR(mm);
* Unmerged path fs/proc/task_mmu.c
