kvm: x86: Introduce KVM_REQ_LOAD_CR3

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Junaid Shahid <junaids@google.com>
commit 6e42782f516f05c8030f63308f2457681b1c9919
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/6e42782f.failed

The KVM_REQ_LOAD_CR3 request loads the hardware CR3 using the
current root_hpa.

	Signed-off-by: Junaid Shahid <junaids@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 6e42782f516f05c8030f63308f2457681b1c9919)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/kvm_host.h
diff --cc arch/x86/include/asm/kvm_host.h
index 86bec63d5f8a,c2b4df8a03cd..000000000000
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@@ -50,6 -48,36 +50,39 @@@
  
  #define KVM_IRQCHIP_NUM_PINS  KVM_IOAPIC_NUM_PINS
  
++<<<<<<< HEAD
++=======
+ /* x86-specific vcpu->requests bit members */
+ #define KVM_REQ_MIGRATE_TIMER		KVM_ARCH_REQ(0)
+ #define KVM_REQ_REPORT_TPR_ACCESS	KVM_ARCH_REQ(1)
+ #define KVM_REQ_TRIPLE_FAULT		KVM_ARCH_REQ(2)
+ #define KVM_REQ_MMU_SYNC		KVM_ARCH_REQ(3)
+ #define KVM_REQ_CLOCK_UPDATE		KVM_ARCH_REQ(4)
+ #define KVM_REQ_LOAD_CR3		KVM_ARCH_REQ(5)
+ #define KVM_REQ_EVENT			KVM_ARCH_REQ(6)
+ #define KVM_REQ_APF_HALT		KVM_ARCH_REQ(7)
+ #define KVM_REQ_STEAL_UPDATE		KVM_ARCH_REQ(8)
+ #define KVM_REQ_NMI			KVM_ARCH_REQ(9)
+ #define KVM_REQ_PMU			KVM_ARCH_REQ(10)
+ #define KVM_REQ_PMI			KVM_ARCH_REQ(11)
+ #define KVM_REQ_SMI			KVM_ARCH_REQ(12)
+ #define KVM_REQ_MASTERCLOCK_UPDATE	KVM_ARCH_REQ(13)
+ #define KVM_REQ_MCLOCK_INPROGRESS \
+ 	KVM_ARCH_REQ_FLAGS(14, KVM_REQUEST_WAIT | KVM_REQUEST_NO_WAKEUP)
+ #define KVM_REQ_SCAN_IOAPIC \
+ 	KVM_ARCH_REQ_FLAGS(15, KVM_REQUEST_WAIT | KVM_REQUEST_NO_WAKEUP)
+ #define KVM_REQ_GLOBAL_CLOCK_UPDATE	KVM_ARCH_REQ(16)
+ #define KVM_REQ_APIC_PAGE_RELOAD \
+ 	KVM_ARCH_REQ_FLAGS(17, KVM_REQUEST_WAIT | KVM_REQUEST_NO_WAKEUP)
+ #define KVM_REQ_HV_CRASH		KVM_ARCH_REQ(18)
+ #define KVM_REQ_IOAPIC_EOI_EXIT		KVM_ARCH_REQ(19)
+ #define KVM_REQ_HV_RESET		KVM_ARCH_REQ(20)
+ #define KVM_REQ_HV_EXIT			KVM_ARCH_REQ(21)
+ #define KVM_REQ_HV_STIMER		KVM_ARCH_REQ(22)
+ #define KVM_REQ_LOAD_EOI_EXITMAP	KVM_ARCH_REQ(23)
+ #define KVM_REQ_GET_VMCS12_PAGES	KVM_ARCH_REQ(24)
+ 
++>>>>>>> 6e42782f516f (kvm: x86: Introduce KVM_REQ_LOAD_CR3)
  #define CR0_RESERVED_BITS                                               \
  	(~(unsigned long)(X86_CR0_PE | X86_CR0_MP | X86_CR0_EM | X86_CR0_TS \
  			  | X86_CR0_ET | X86_CR0_NE | X86_CR0_WP | X86_CR0_AM \
* Unmerged path arch/x86/include/asm/kvm_host.h
diff --git a/arch/x86/kvm/mmu.c b/arch/x86/kvm/mmu.c
index db86a346eaea..78e192d5077b 100644
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@ -4605,8 +4605,7 @@ int kvm_mmu_load(struct kvm_vcpu *vcpu)
 	kvm_mmu_sync_roots(vcpu);
 	if (r)
 		goto out;
-	/* set_cr3() should ensure TLB has been flushed */
-	vcpu->arch.mmu.set_cr3(vcpu, vcpu->arch.mmu.root_hpa);
+	kvm_mmu_load_cr3(vcpu);
 out:
 	return r;
 }
diff --git a/arch/x86/kvm/mmu.h b/arch/x86/kvm/mmu.h
index 3d1af6f75377..a3abd41ee960 100644
--- a/arch/x86/kvm/mmu.h
+++ b/arch/x86/kvm/mmu.h
@@ -78,6 +78,13 @@ static inline int kvm_mmu_reload(struct kvm_vcpu *vcpu)
 	return kvm_mmu_load(vcpu);
 }
 
+static inline void kvm_mmu_load_cr3(struct kvm_vcpu *vcpu)
+{
+	/* set_cr3() should ensure TLB has been flushed */
+	if (VALID_PAGE(vcpu->arch.mmu.root_hpa))
+		vcpu->arch.mmu.set_cr3(vcpu, vcpu->arch.mmu.root_hpa);
+}
+
 /*
  * Currently, we have two sorts of write-protection, a) the first one
  * write-protects guest page to sync the guest modification, b) another one is
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index bc19a3517278..1a745880463a 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -6580,6 +6580,8 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 		}
 		if (kvm_check_request(KVM_REQ_MMU_SYNC, vcpu))
 			kvm_mmu_sync_roots(vcpu);
+		if (kvm_check_request(KVM_REQ_LOAD_CR3, vcpu))
+			kvm_mmu_load_cr3(vcpu);
 		if (kvm_check_request(KVM_REQ_TLB_FLUSH, vcpu))
 			kvm_vcpu_flush_tlb(vcpu);
 		if (kvm_check_request(KVM_REQ_REPORT_TPR_ACCESS, vcpu)) {
