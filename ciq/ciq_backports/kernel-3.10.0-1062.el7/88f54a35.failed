powerpc/iommu: Pass mm_struct to init/cleanup helpers

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
Rebuild_CHGLOG: - [powerpc] iommu: Pass mm_struct to init/cleanup helpers (David Gibson) [1612677]
Rebuild_FUZZ: 91.84%
commit-author Alexey Kardashevskiy <aik@ozlabs.ru>
commit 88f54a3581eb9deaa3bd1aade40aef266d782385
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/88f54a35.failed

We are going to get rid of @current references in mmu_context_boos3s64.c
and cache mm_struct in the VFIO container. Since mm_context_t does not
have reference counting, we will be using mm_struct which does have
the reference counter.

This changes mm_iommu_init/mm_iommu_cleanup to receive mm_struct rather
than mm_context_t (which is embedded into mm).

This should not cause any behavioral change.

	Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
	Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
(cherry picked from commit 88f54a3581eb9deaa3bd1aade40aef266d782385)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/kernel/setup-common.c
#	arch/powerpc/mm/mmu_context_iommu.c
diff --cc arch/powerpc/kernel/setup-common.c
index a82612b417fc,f516ac508ae3..000000000000
--- a/arch/powerpc/kernel/setup-common.c
+++ b/arch/powerpc/kernel/setup-common.c
@@@ -775,3 -775,169 +775,172 @@@ void arch_setup_pdev_archdata(struct pl
  	pdev->dev.dma_mask = &pdev->archdata.dma_mask;
   	set_dma_ops(&pdev->dev, &dma_direct_ops);
  }
++<<<<<<< HEAD
++=======
+ 
+ static __init void print_system_info(void)
+ {
+ 	pr_info("-----------------------------------------------------\n");
+ #ifdef CONFIG_PPC_STD_MMU_64
+ 	pr_info("ppc64_pft_size    = 0x%llx\n", ppc64_pft_size);
+ #endif
+ #ifdef CONFIG_PPC_STD_MMU_32
+ 	pr_info("Hash_size         = 0x%lx\n", Hash_size);
+ #endif
+ 	pr_info("phys_mem_size     = 0x%llx\n",
+ 		(unsigned long long)memblock_phys_mem_size());
+ 
+ 	pr_info("dcache_bsize      = 0x%x\n", dcache_bsize);
+ 	pr_info("icache_bsize      = 0x%x\n", icache_bsize);
+ 	if (ucache_bsize != 0)
+ 		pr_info("ucache_bsize      = 0x%x\n", ucache_bsize);
+ 
+ 	pr_info("cpu_features      = 0x%016lx\n", cur_cpu_spec->cpu_features);
+ 	pr_info("  possible        = 0x%016lx\n",
+ 		(unsigned long)CPU_FTRS_POSSIBLE);
+ 	pr_info("  always          = 0x%016lx\n",
+ 		(unsigned long)CPU_FTRS_ALWAYS);
+ 	pr_info("cpu_user_features = 0x%08x 0x%08x\n",
+ 		cur_cpu_spec->cpu_user_features,
+ 		cur_cpu_spec->cpu_user_features2);
+ 	pr_info("mmu_features      = 0x%08x\n", cur_cpu_spec->mmu_features);
+ #ifdef CONFIG_PPC64
+ 	pr_info("firmware_features = 0x%016lx\n", powerpc_firmware_features);
+ #endif
+ 
+ #ifdef CONFIG_PPC_STD_MMU_64
+ 	if (htab_address)
+ 		pr_info("htab_address      = 0x%p\n", htab_address);
+ 	if (htab_hash_mask)
+ 		pr_info("htab_hash_mask    = 0x%lx\n", htab_hash_mask);
+ #endif
+ #ifdef CONFIG_PPC_STD_MMU_32
+ 	if (Hash)
+ 		pr_info("Hash              = 0x%p\n", Hash);
+ 	if (Hash_mask)
+ 		pr_info("Hash_mask         = 0x%lx\n", Hash_mask);
+ #endif
+ 
+ 	if (PHYSICAL_START > 0)
+ 		pr_info("physical_start    = 0x%llx\n",
+ 		       (unsigned long long)PHYSICAL_START);
+ 	pr_info("-----------------------------------------------------\n");
+ }
+ 
+ /*
+  * Called into from start_kernel this initializes memblock, which is used
+  * to manage page allocation until mem_init is called.
+  */
+ void __init setup_arch(char **cmdline_p)
+ {
+ 	*cmdline_p = boot_command_line;
+ 
+ 	/* Set a half-reasonable default so udelay does something sensible */
+ 	loops_per_jiffy = 500000000 / HZ;
+ 
+ 	/* Unflatten the device-tree passed by prom_init or kexec */
+ 	unflatten_device_tree();
+ 
+ 	/*
+ 	 * Initialize cache line/block info from device-tree (on ppc64) or
+ 	 * just cputable (on ppc32).
+ 	 */
+ 	initialize_cache_info();
+ 
+ 	/* Initialize RTAS if available. */
+ 	rtas_initialize();
+ 
+ 	/* Check if we have an initrd provided via the device-tree. */
+ 	check_for_initrd();
+ 
+ 	/* Probe the machine type, establish ppc_md. */
+ 	probe_machine();
+ 
+ 	/* Setup panic notifier if requested by the platform. */
+ 	setup_panic();
+ 
+ 	/*
+ 	 * Configure ppc_md.power_save (ppc32 only, 64-bit machines do
+ 	 * it from their respective probe() function.
+ 	 */
+ 	setup_power_save();
+ 
+ 	/* Discover standard serial ports. */
+ 	find_legacy_serial_ports();
+ 
+ 	/* Register early console with the printk subsystem. */
+ 	register_early_udbg_console();
+ 
+ 	/* Setup the various CPU maps based on the device-tree. */
+ 	smp_setup_cpu_maps();
+ 
+ 	/* Initialize xmon. */
+ 	xmon_setup();
+ 
+ 	/* Check the SMT related command line arguments (ppc64). */
+ 	check_smt_enabled();
+ 
+ 	/* On BookE, setup per-core TLB data structures. */
+ 	setup_tlb_core_data();
+ 
+ 	/*
+ 	 * Release secondary cpus out of their spinloops at 0x60 now that
+ 	 * we can map physical -> logical CPU ids.
+ 	 *
+ 	 * Freescale Book3e parts spin in a loop provided by firmware,
+ 	 * so smp_release_cpus() does nothing for them.
+ 	 */
+ #ifdef CONFIG_SMP
+ 	smp_release_cpus();
+ #endif
+ 
+ 	/* Print various info about the machine that has been gathered so far. */
+ 	print_system_info();
+ 
+ 	/* Reserve large chunks of memory for use by CMA for KVM. */
+ 	kvm_cma_reserve();
+ 
+ 	/*
+ 	 * Reserve any gigantic pages requested on the command line.
+ 	 * memblock needs to have been initialized by the time this is
+ 	 * called since this will reserve memory.
+ 	 */
+ 	reserve_hugetlb_gpages();
+ 
+ 	klp_init_thread_info(&init_thread_info);
+ 
+ 	init_mm.start_code = (unsigned long)_stext;
+ 	init_mm.end_code = (unsigned long) _etext;
+ 	init_mm.end_data = (unsigned long) _edata;
+ 	init_mm.brk = klimit;
+ #ifdef CONFIG_PPC_64K_PAGES
+ 	init_mm.context.pte_frag = NULL;
+ #endif
+ #ifdef CONFIG_SPAPR_TCE_IOMMU
+ 	mm_iommu_init(&init_mm);
+ #endif
+ 	irqstack_early_init();
+ 	exc_lvl_early_init();
+ 	emergency_stack_init();
+ 
+ 	initmem_init();
+ 
+ #ifdef CONFIG_DUMMY_CONSOLE
+ 	conswitchp = &dummy_con;
+ #endif
+ 	if (ppc_md.setup_arch)
+ 		ppc_md.setup_arch();
+ 
+ 	paging_init();
+ 
+ 	/* Initialize the MMU context management stuff. */
+ 	mmu_context_init();
+ 
+ #ifdef CONFIG_PPC64
+ 	/* Interrupt code needs to be 64K-aligned. */
+ 	if ((unsigned long)_stext & 0xffff)
+ 		panic("Kernelbase not 64K-aligned (0x%lx)!\n",
+ 		      (unsigned long)_stext);
+ #endif
+ }
++>>>>>>> 88f54a3581eb (powerpc/iommu: Pass mm_struct to init/cleanup helpers)
diff --cc arch/powerpc/mm/mmu_context_iommu.c
index f68c12901fa8,ad2e575fd418..000000000000
--- a/arch/powerpc/mm/mmu_context_iommu.c
+++ b/arch/powerpc/mm/mmu_context_iommu.c
@@@ -373,18 -373,17 +373,27 @@@ void mm_iommu_mapped_dec(struct mm_iomm
  }
  EXPORT_SYMBOL_GPL(mm_iommu_mapped_dec);
  
- void mm_iommu_init(mm_context_t *ctx)
+ void mm_iommu_init(struct mm_struct *mm)
  {
++<<<<<<< HEAD
 +	struct mm_struct *mm = container_of(ctx, struct mm_struct, context);
 +	INIT_LIST_HEAD_RCU(&mm->iommu_group_mem_list);
++=======
+ 	INIT_LIST_HEAD_RCU(&mm->context.iommu_group_mem_list);
++>>>>>>> 88f54a3581eb (powerpc/iommu: Pass mm_struct to init/cleanup helpers)
  }
  
- void mm_iommu_cleanup(mm_context_t *ctx)
+ void mm_iommu_cleanup(struct mm_struct *mm)
  {
 +	struct mm_struct *mm = container_of(ctx, struct mm_struct, context);
  	struct mm_iommu_table_group_mem_t *mem, *tmp;
  
++<<<<<<< HEAD
 +	list_for_each_entry_safe(mem, tmp, &mm->iommu_group_mem_list, next) {
++=======
+ 	list_for_each_entry_safe(mem, tmp, &mm->context.iommu_group_mem_list,
+ 			next) {
++>>>>>>> 88f54a3581eb (powerpc/iommu: Pass mm_struct to init/cleanup helpers)
  		list_del_rcu(&mem->next);
  		mm_iommu_do_free(mem);
  	}
diff --git a/arch/powerpc/include/asm/mmu_context.h b/arch/powerpc/include/asm/mmu_context.h
index 884fe3a8d621..584071766311 100644
--- a/arch/powerpc/include/asm/mmu_context.h
+++ b/arch/powerpc/include/asm/mmu_context.h
@@ -23,8 +23,8 @@ extern bool mm_iommu_preregistered(void);
 extern long mm_iommu_get(unsigned long ua, unsigned long entries,
 		struct mm_iommu_table_group_mem_t **pmem);
 extern long mm_iommu_put(struct mm_iommu_table_group_mem_t *mem);
-extern void mm_iommu_init(mm_context_t *ctx);
-extern void mm_iommu_cleanup(mm_context_t *ctx);
+extern void mm_iommu_init(struct mm_struct *mm);
+extern void mm_iommu_cleanup(struct mm_struct *mm);
 extern struct mm_iommu_table_group_mem_t *mm_iommu_lookup(unsigned long ua,
 		unsigned long size);
 extern struct mm_iommu_table_group_mem_t *mm_iommu_find(unsigned long ua,
* Unmerged path arch/powerpc/kernel/setup-common.c
diff --git a/arch/powerpc/mm/mmu_context_hash64.c b/arch/powerpc/mm/mmu_context_hash64.c
index 9ca6fe16cb29..cf075c6d836d 100644
--- a/arch/powerpc/mm/mmu_context_hash64.c
+++ b/arch/powerpc/mm/mmu_context_hash64.c
@@ -90,7 +90,7 @@ int init_new_context(struct task_struct *tsk, struct mm_struct *mm)
 	mm->context.pte_frag = NULL;
 #endif
 #ifdef CONFIG_SPAPR_TCE_IOMMU
-	mm_iommu_init(&mm->context);
+	mm_iommu_init(mm);
 #endif
 	return 0;
 }
@@ -135,7 +135,7 @@ static inline void destroy_pagetable_page(struct mm_struct *mm)
 void destroy_context(struct mm_struct *mm)
 {
 #ifdef CONFIG_SPAPR_TCE_IOMMU
-	mm_iommu_cleanup(&mm->context);
+	mm_iommu_cleanup(mm);
 #endif
 
 #ifdef CONFIG_PPC_ICSWX
* Unmerged path arch/powerpc/mm/mmu_context_iommu.c
