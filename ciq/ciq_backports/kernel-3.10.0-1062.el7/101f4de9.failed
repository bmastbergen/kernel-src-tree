net/mlx5e: Move TC tunnel offloading code to separate source file

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
Rebuild_CHGLOG: - [netdrv] mlx5e: Move TC tunnel offloading code to separate source file (Alaa Hleihel) [1642362 1642498]
Rebuild_FUZZ: 96.83%
commit-author Oz Shlomo <ozsh@mellanox.com>
commit 101f4de9dd521c6d06dfdacaa35e506a8db8494b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/101f4de9.failed

Move tunnel offloading related code to a separate source file for better
code maintainability.

Code refactoring with no functional change.

	Signed-off-by: Oz Shlomo <ozsh@mellanox.com>
	Reviewed-by: Eli Britstein <elibr@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 101f4de9dd521c6d06dfdacaa35e506a8db8494b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/Makefile
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/Makefile
index 7500fab9286b,40764d87413a..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/Makefile
+++ b/drivers/net/ethernet/mellanox/mlx5/core/Makefile
@@@ -1,12 -1,53 +1,46 @@@
 -# SPDX-License-Identifier: GPL-2.0
 -#
 -# Makefile for Mellanox 5th generation network adapters
 -# (ConnectX series) core & netdev driver
 -#
 -
 +obj-$(CONFIG_MLX5_CORE)		+= mlx5_core.o
  subdir-ccflags-y += -I$(src)
  
 -obj-$(CONFIG_MLX5_CORE) += mlx5_core.o
 -
 -#
 -# mlx5 core basic
 -#
  mlx5_core-y :=	main.o cmd.o debugfs.o fw.o eq.o uar.o pagealloc.o \
 -		health.o mcg.o cq.o alloc.o qp.o port.o mr.o pd.o \
 +		health.o mcg.o cq.o srq.o alloc.o qp.o port.o mr.o pd.o \
  		mad.o transobj.o vport.o sriov.o fs_cmd.o fs_core.o \
 -		fs_counters.o rl.o lag.o dev.o events.o wq.o lib/gid.o \
 +		fs_counters.o rl.o lag.o dev.o wq.o lib/gid.o lib/clock.o \
  		diag/fs_tracepoint.o diag/fw_tracer.o
  
++<<<<<<< HEAD
++=======
+ #
+ # Netdev basic
+ #
+ mlx5_core-$(CONFIG_MLX5_CORE_EN) += en_main.o en_common.o en_fs.o en_ethtool.o \
+ 		en_tx.o en_rx.o en_dim.o en_txrx.o en/xdp.o en_stats.o \
+ 		en_selftest.o en/port.o
+ 
+ #
+ # Netdev extra
+ #
+ mlx5_core-$(CONFIG_MLX5_EN_ARFS)     += en_arfs.o
+ mlx5_core-$(CONFIG_MLX5_EN_RXNFC)    += en_fs_ethtool.o
+ mlx5_core-$(CONFIG_MLX5_CORE_EN_DCB) += en_dcbnl.o en/port_buffer.o
+ mlx5_core-$(CONFIG_MLX5_ESWITCH)     += en_rep.o en_tc.o en/tc_tun.o
+ 
+ #
+ # Core extra
+ #
+ mlx5_core-$(CONFIG_MLX5_ESWITCH)   += eswitch.o eswitch_offloads.o
+ mlx5_core-$(CONFIG_MLX5_MPFS)      += lib/mpfs.o
+ mlx5_core-$(CONFIG_VXLAN)          += lib/vxlan.o
+ mlx5_core-$(CONFIG_PTP_1588_CLOCK) += lib/clock.o
+ 
+ #
+ # Ipoib netdev
+ #
+ mlx5_core-$(CONFIG_MLX5_CORE_IPOIB) += ipoib/ipoib.o ipoib/ethtool.o ipoib/ipoib_vlan.o
+ 
+ #
+ # Accelerations & FPGA
+ #
++>>>>>>> 101f4de9dd52 (net/mlx5e: Move TC tunnel offloading code to separate source file)
  mlx5_core-$(CONFIG_MLX5_ACCEL) += accel/ipsec.o accel/tls.o
  
  mlx5_core-$(CONFIG_MLX5_FPGA) += fpga/cmd.o fpga/core.o fpga/conn.o fpga/sdk.o \
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index fbb4f1b36627,abc200947e84..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -50,8 -49,9 +49,14 @@@
  #include "en_rep.h"
  #include "en_tc.h"
  #include "eswitch.h"
++<<<<<<< HEAD
 +#include "vxlan.h"
 +#include "fs_core.h"
++=======
+ #include "fs_core.h"
+ #include "en/port.h"
+ #include "en/tc_tun.h"
++>>>>>>> 101f4de9dd52 (net/mlx5e: Move TC tunnel offloading code to separate source file)
  
  struct mlx5_nic_flow_attr {
  	u32 action;
@@@ -72,8 -73,11 +77,13 @@@ enum 
  	MLX5E_TC_FLOW_OFFLOADED	= BIT(MLX5E_TC_FLOW_BASE + 2),
  	MLX5E_TC_FLOW_HAIRPIN	= BIT(MLX5E_TC_FLOW_BASE + 3),
  	MLX5E_TC_FLOW_HAIRPIN_RSS = BIT(MLX5E_TC_FLOW_BASE + 4),
 -	MLX5E_TC_FLOW_SLOW	  = BIT(MLX5E_TC_FLOW_BASE + 5),
  };
  
++<<<<<<< HEAD
++=======
+ #define MLX5E_TC_MAX_SPLITS 1
+ 
++>>>>>>> 101f4de9dd52 (net/mlx5e: Move TC tunnel offloading code to separate source file)
  struct mlx5e_tc_flow {
  	struct rhash_head	node;
  	struct mlx5e_priv	*priv;
@@@ -666,10 -676,11 +676,14 @@@ static void mlx5e_hairpin_flow_del(stru
  	}
  }
  
++<<<<<<< HEAD
 +static struct mlx5_flow_handle *
++=======
+ static int
++>>>>>>> 101f4de9dd52 (net/mlx5e: Move TC tunnel offloading code to separate source file)
  mlx5e_tc_add_nic_flow(struct mlx5e_priv *priv,
  		      struct mlx5e_tc_flow_parse_attr *parse_attr,
 -		      struct mlx5e_tc_flow *flow,
 -		      struct netlink_ext_ack *extack)
 +		      struct mlx5e_tc_flow *flow)
  {
  	struct mlx5_nic_flow_attr *attr = flow->nic_attr;
  	struct mlx5_core_dev *dev = priv->mdev;
@@@ -1035,36 -1193,6 +1049,39 @@@ static void mlx5e_tc_del_flow(struct ml
  		mlx5e_tc_del_nic_flow(priv, flow);
  }
  
++<<<<<<< HEAD
 +static void parse_vxlan_attr(struct mlx5_flow_spec *spec,
 +			     struct tc_cls_flower_offload *f)
 +{
 +	void *headers_c = MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 +				       outer_headers);
 +	void *headers_v = MLX5_ADDR_OF(fte_match_param, spec->match_value,
 +				       outer_headers);
 +	void *misc_c = MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 +				    misc_parameters);
 +	void *misc_v = MLX5_ADDR_OF(fte_match_param, spec->match_value,
 +				    misc_parameters);
 +
 +	MLX5_SET_TO_ONES(fte_match_set_lyr_2_4, headers_c, ip_protocol);
 +	MLX5_SET(fte_match_set_lyr_2_4, headers_v, ip_protocol, IPPROTO_UDP);
 +
 +	if (dissector_uses_key(f->dissector, FLOW_DISSECTOR_KEY_ENC_KEYID)) {
 +		struct flow_dissector_key_keyid *key =
 +			skb_flow_dissector_target(f->dissector,
 +						  FLOW_DISSECTOR_KEY_ENC_KEYID,
 +						  f->key);
 +		struct flow_dissector_key_keyid *mask =
 +			skb_flow_dissector_target(f->dissector,
 +						  FLOW_DISSECTOR_KEY_ENC_KEYID,
 +						  f->mask);
 +		MLX5_SET(fte_match_set_misc, misc_c, vxlan_vni,
 +			 be32_to_cpu(mask->keyid));
 +		MLX5_SET(fte_match_set_misc, misc_v, vxlan_vni,
 +			 be32_to_cpu(key->keyid));
 +	}
 +}
++=======
++>>>>>>> 101f4de9dd52 (net/mlx5e: Move TC tunnel offloading code to separate source file)
  
  static int parse_tunnel_attr(struct mlx5e_priv *priv,
  			     struct mlx5_flow_spec *spec,
@@@ -1079,48 -1209,14 +1096,59 @@@
  		skb_flow_dissector_target(f->dissector,
  					  FLOW_DISSECTOR_KEY_ENC_CONTROL,
  					  f->key);
++<<<<<<< HEAD
 +
 +	if (dissector_uses_key(f->dissector, FLOW_DISSECTOR_KEY_ENC_PORTS)) {
 +		struct flow_dissector_key_ports *key =
 +			skb_flow_dissector_target(f->dissector,
 +						  FLOW_DISSECTOR_KEY_ENC_PORTS,
 +						  f->key);
 +		struct flow_dissector_key_ports *mask =
 +			skb_flow_dissector_target(f->dissector,
 +						  FLOW_DISSECTOR_KEY_ENC_PORTS,
 +						  f->mask);
 +		struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 +		struct mlx5e_rep_priv *uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
 +		struct net_device *up_dev = uplink_rpriv->netdev;
 +		struct mlx5e_priv *up_priv = netdev_priv(up_dev);
 +
 +		/* Full udp dst port must be given */
 +		if (memchr_inv(&mask->dst, 0xff, sizeof(mask->dst)))
 +			goto vxlan_match_offload_err;
 +
 +		if (mlx5e_vxlan_lookup_port(up_priv, be16_to_cpu(key->dst)) &&
 +		    MLX5_CAP_ESW(priv->mdev, vxlan_encap_decap))
 +			parse_vxlan_attr(spec, f);
 +		else {
 +			netdev_warn(priv->netdev,
 +				    "%d isn't an offloaded vxlan udp dport\n", be16_to_cpu(key->dst));
 +			return -EOPNOTSUPP;
 +		}
 +
 +		MLX5_SET(fte_match_set_lyr_2_4, headers_c,
 +			 udp_dport, ntohs(mask->dst));
 +		MLX5_SET(fte_match_set_lyr_2_4, headers_v,
 +			 udp_dport, ntohs(key->dst));
 +
 +		MLX5_SET(fte_match_set_lyr_2_4, headers_c,
 +			 udp_sport, ntohs(mask->src));
 +		MLX5_SET(fte_match_set_lyr_2_4, headers_v,
 +			 udp_sport, ntohs(key->src));
 +	} else { /* udp dst port must be given */
 +vxlan_match_offload_err:
 +		netdev_warn(priv->netdev,
 +			    "IP tunnel decap offload supported only for vxlan, must set UDP dport\n");
 +		return -EOPNOTSUPP;
++=======
+ 	int err = 0;
+ 
+ 	err = mlx5e_tc_tun_parse(filter_dev, priv, spec, f,
+ 				 headers_c, headers_v);
+ 	if (err) {
+ 		NL_SET_ERR_MSG_MOD(extack,
+ 				   "failed to parse tunnel attributes");
+ 		return err;
++>>>>>>> 101f4de9dd52 (net/mlx5e: Move TC tunnel offloading code to separate source file)
  	}
  
  	if (enc_control->addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS) {
@@@ -2112,383 -2259,22 +2140,402 @@@ static inline int hash_encap_info(struc
  	return jhash(key, sizeof(*key), 0);
  }
  
++<<<<<<< HEAD
 +static int mlx5e_route_lookup_ipv4(struct mlx5e_priv *priv,
 +				   struct net_device *mirred_dev,
 +				   struct net_device **out_dev,
 +				   struct flowi4 *fl4,
 +				   struct neighbour **out_n,
 +				   u8 *out_ttl)
 +{
 +	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 +	struct mlx5e_rep_priv *uplink_rpriv;
 +	struct rtable *rt;
 +	struct neighbour *n = NULL;
 +
 +#if IS_ENABLED(CONFIG_INET)
 +	int ret;
 +
 +	rt = ip_route_output_key(dev_net(mirred_dev), fl4);
 +	ret = PTR_ERR_OR_ZERO(rt);
 +	if (ret)
 +		return ret;
 +#else
 +	return -EOPNOTSUPP;
 +#endif
 +	uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
 +	/* if the egress device isn't on the same HW e-switch, we use the uplink */
 +	if (!switchdev_port_same_parent_id(priv->netdev, rt->dst.dev))
 +		*out_dev = uplink_rpriv->netdev;
 +	else
 +		*out_dev = rt->dst.dev;
 +
 +	if (!(*out_ttl))
 +		*out_ttl = ip4_dst_hoplimit(&rt->dst);
 +	n = dst_neigh_lookup(&rt->dst, &fl4->daddr);
 +	ip_rt_put(rt);
 +	if (!n)
 +		return -ENOMEM;
 +
 +	*out_n = n;
 +
 +	return 0;
 +}
 +
 +static int mlx5e_route_lookup_ipv6(struct mlx5e_priv *priv,
 +				   struct net_device *mirred_dev,
 +				   struct net_device **out_dev,
 +				   struct flowi6 *fl6,
 +				   struct neighbour **out_n,
 +				   u8 *out_ttl)
 +{
 +	struct neighbour *n = NULL;
 +	struct dst_entry *dst;
 +
 +#if IS_ENABLED(CONFIG_INET) && IS_ENABLED(CONFIG_IPV6)
 +	struct mlx5e_rep_priv *uplink_rpriv;
 +	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 +	int ret;
 +
 +	ret = ipv6_stub->ipv6_dst_lookup(dev_net(mirred_dev), NULL, &dst,
 +					 fl6);
 +	if (ret < 0)
 +		return ret;
 +
 +	if (!(*out_ttl))
 +		*out_ttl = ip6_dst_hoplimit(dst);
 +
 +	uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
 +	/* if the egress device isn't on the same HW e-switch, we use the uplink */
 +	if (!switchdev_port_same_parent_id(priv->netdev, dst->dev))
 +		*out_dev = uplink_rpriv->netdev;
 +	else
 +		*out_dev = dst->dev;
 +#else
 +	return -EOPNOTSUPP;
 +#endif
 +
 +	n = dst_neigh_lookup(dst, &fl6->daddr);
 +	dst_release(dst);
 +	if (!n)
 +		return -ENOMEM;
 +
 +	*out_n = n;
 +	return 0;
 +}
 +
 +static void gen_vxlan_header_ipv4(struct net_device *out_dev,
 +				  char buf[], int encap_size,
 +				  unsigned char h_dest[ETH_ALEN],
 +				  u8 tos, u8 ttl,
 +				  __be32 daddr,
 +				  __be32 saddr,
 +				  __be16 udp_dst_port,
 +				  __be32 vx_vni)
 +{
 +	struct ethhdr *eth = (struct ethhdr *)buf;
 +	struct iphdr  *ip = (struct iphdr *)((char *)eth + sizeof(struct ethhdr));
 +	struct udphdr *udp = (struct udphdr *)((char *)ip + sizeof(struct iphdr));
 +	struct vxlanhdr *vxh = (struct vxlanhdr *)((char *)udp + sizeof(struct udphdr));
 +
 +	memset(buf, 0, encap_size);
 +
 +	ether_addr_copy(eth->h_dest, h_dest);
 +	ether_addr_copy(eth->h_source, out_dev->dev_addr);
 +	eth->h_proto = htons(ETH_P_IP);
 +
 +	ip->daddr = daddr;
 +	ip->saddr = saddr;
 +
 +	ip->tos = tos;
 +	ip->ttl = ttl;
 +	ip->protocol = IPPROTO_UDP;
 +	ip->version = 0x4;
 +	ip->ihl = 0x5;
 +
 +	udp->dest = udp_dst_port;
 +	vxh->vx_flags = VXLAN_HF_VNI;
 +	vxh->vx_vni = vxlan_vni_field(vx_vni);
 +}
 +
 +static void gen_vxlan_header_ipv6(struct net_device *out_dev,
 +				  char buf[], int encap_size,
 +				  unsigned char h_dest[ETH_ALEN],
 +				  u8 tos, u8 ttl,
 +				  struct in6_addr *daddr,
 +				  struct in6_addr *saddr,
 +				  __be16 udp_dst_port,
 +				  __be32 vx_vni)
 +{
 +	struct ethhdr *eth = (struct ethhdr *)buf;
 +	struct ipv6hdr *ip6h = (struct ipv6hdr *)((char *)eth + sizeof(struct ethhdr));
 +	struct udphdr *udp = (struct udphdr *)((char *)ip6h + sizeof(struct ipv6hdr));
 +	struct vxlanhdr *vxh = (struct vxlanhdr *)((char *)udp + sizeof(struct udphdr));
 +
 +	memset(buf, 0, encap_size);
 +
 +	ether_addr_copy(eth->h_dest, h_dest);
 +	ether_addr_copy(eth->h_source, out_dev->dev_addr);
 +	eth->h_proto = htons(ETH_P_IPV6);
 +
 +	ip6_flow_hdr(ip6h, tos, 0);
 +	/* the HW fills up ipv6 payload len */
 +	ip6h->nexthdr     = IPPROTO_UDP;
 +	ip6h->hop_limit   = ttl;
 +	ip6h->daddr	  = *daddr;
 +	ip6h->saddr	  = *saddr;
 +
 +	udp->dest = udp_dst_port;
 +	vxh->vx_flags = VXLAN_HF_VNI;
 +	vxh->vx_vni = vxlan_vni_field(vx_vni);
 +}
 +
 +static int mlx5e_create_encap_header_ipv4(struct mlx5e_priv *priv,
 +					  struct net_device *mirred_dev,
 +					  struct mlx5e_encap_entry *e)
 +{
 +	int max_encap_size = MLX5_CAP_ESW(priv->mdev, max_encap_header_size);
 +	int ipv4_encap_size = ETH_HLEN + sizeof(struct iphdr) + VXLAN_HLEN;
 +	struct ip_tunnel_key *tun_key = &e->tun_info.key;
 +	struct net_device *out_dev;
 +	struct neighbour *n = NULL;
 +	struct flowi4 fl4 = {};
 +	u8 nud_state, tos, ttl;
 +	char *encap_header;
 +	int err;
 +
 +	if (max_encap_size < ipv4_encap_size) {
 +		mlx5_core_warn(priv->mdev, "encap size %d too big, max supported is %d\n",
 +			       ipv4_encap_size, max_encap_size);
 +		return -EOPNOTSUPP;
 +	}
 +
 +	encap_header = kzalloc(ipv4_encap_size, GFP_KERNEL);
 +	if (!encap_header)
 +		return -ENOMEM;
 +
 +	switch (e->tunnel_type) {
 +	case MLX5_HEADER_TYPE_VXLAN:
 +		fl4.flowi4_proto = IPPROTO_UDP;
 +		fl4.fl4_dport = tun_key->tp_dst;
 +		break;
 +	default:
 +		err = -EOPNOTSUPP;
 +		goto free_encap;
 +	}
 +
 +	tos = tun_key->tos;
 +	ttl = tun_key->ttl;
 +
 +	fl4.flowi4_tos = tun_key->tos;
 +	fl4.daddr = tun_key->u.ipv4.dst;
 +	fl4.saddr = tun_key->u.ipv4.src;
 +
 +	err = mlx5e_route_lookup_ipv4(priv, mirred_dev, &out_dev,
 +				      &fl4, &n, &ttl);
 +	if (err)
 +		goto free_encap;
 +
 +	/* used by mlx5e_detach_encap to lookup a neigh hash table
 +	 * entry in the neigh hash table when a user deletes a rule
 +	 */
 +	e->m_neigh.dev = n->dev;
 +	e->m_neigh.family = n->ops->family;
 +	memcpy(&e->m_neigh.dst_ip, n->primary_key, n->tbl->key_len);
 +	e->out_dev = out_dev;
 +
 +	/* It's importent to add the neigh to the hash table before checking
 +	 * the neigh validity state. So if we'll get a notification, in case the
 +	 * neigh changes it's validity state, we would find the relevant neigh
 +	 * in the hash.
 +	 */
 +	err = mlx5e_rep_encap_entry_attach(netdev_priv(out_dev), e);
 +	if (err)
 +		goto free_encap;
 +
 +	read_lock_bh(&n->lock);
 +	nud_state = n->nud_state;
 +	ether_addr_copy(e->h_dest, n->ha);
 +	read_unlock_bh(&n->lock);
 +
 +	switch (e->tunnel_type) {
 +	case MLX5_HEADER_TYPE_VXLAN:
 +		gen_vxlan_header_ipv4(out_dev, encap_header,
 +				      ipv4_encap_size, e->h_dest, tos, ttl,
 +				      fl4.daddr,
 +				      fl4.saddr, tun_key->tp_dst,
 +				      tunnel_id_to_key32(tun_key->tun_id));
 +		break;
 +	default:
 +		err = -EOPNOTSUPP;
 +		goto destroy_neigh_entry;
 +	}
 +	e->encap_size = ipv4_encap_size;
 +	e->encap_header = encap_header;
 +
 +	if (!(nud_state & NUD_VALID)) {
 +		neigh_event_send(n, NULL);
 +		err = -EAGAIN;
 +		goto out;
 +	}
 +
 +	err = mlx5_encap_alloc(priv->mdev, e->tunnel_type,
 +			       ipv4_encap_size, encap_header, &e->encap_id);
 +	if (err)
 +		goto destroy_neigh_entry;
 +
 +	e->flags |= MLX5_ENCAP_ENTRY_VALID;
 +	mlx5e_rep_queue_neigh_stats_work(netdev_priv(out_dev));
 +	neigh_release(n);
 +	return err;
 +
 +destroy_neigh_entry:
 +	mlx5e_rep_encap_entry_detach(netdev_priv(e->out_dev), e);
 +free_encap:
 +	kfree(encap_header);
 +out:
 +	if (n)
 +		neigh_release(n);
 +	return err;
 +}
 +
 +static int mlx5e_create_encap_header_ipv6(struct mlx5e_priv *priv,
 +					  struct net_device *mirred_dev,
 +					  struct mlx5e_encap_entry *e)
 +{
 +	int max_encap_size = MLX5_CAP_ESW(priv->mdev, max_encap_header_size);
 +	int ipv6_encap_size = ETH_HLEN + sizeof(struct ipv6hdr) + VXLAN_HLEN;
 +	struct ip_tunnel_key *tun_key = &e->tun_info.key;
 +	struct net_device *out_dev;
 +	struct neighbour *n = NULL;
 +	struct flowi6 fl6 = {};
 +	u8 nud_state, tos, ttl;
 +	char *encap_header;
 +	int err;
 +
 +	if (max_encap_size < ipv6_encap_size) {
 +		mlx5_core_warn(priv->mdev, "encap size %d too big, max supported is %d\n",
 +			       ipv6_encap_size, max_encap_size);
 +		return -EOPNOTSUPP;
 +	}
 +
 +	encap_header = kzalloc(ipv6_encap_size, GFP_KERNEL);
 +	if (!encap_header)
 +		return -ENOMEM;
 +
 +	switch (e->tunnel_type) {
 +	case MLX5_HEADER_TYPE_VXLAN:
 +		fl6.flowi6_proto = IPPROTO_UDP;
 +		fl6.fl6_dport = tun_key->tp_dst;
 +		break;
 +	default:
 +		err = -EOPNOTSUPP;
 +		goto free_encap;
 +	}
 +
 +	tos = tun_key->tos;
 +	ttl = tun_key->ttl;
 +
 +	fl6.flowlabel = ip6_make_flowinfo(RT_TOS(tun_key->tos), tun_key->label);
 +	fl6.daddr = tun_key->u.ipv6.dst;
 +	fl6.saddr = tun_key->u.ipv6.src;
 +
 +	err = mlx5e_route_lookup_ipv6(priv, mirred_dev, &out_dev,
 +				      &fl6, &n, &ttl);
 +	if (err)
 +		goto free_encap;
 +
 +	/* used by mlx5e_detach_encap to lookup a neigh hash table
 +	 * entry in the neigh hash table when a user deletes a rule
 +	 */
 +	e->m_neigh.dev = n->dev;
 +	e->m_neigh.family = n->ops->family;
 +	memcpy(&e->m_neigh.dst_ip, n->primary_key, n->tbl->key_len);
 +	e->out_dev = out_dev;
 +
 +	/* It's importent to add the neigh to the hash table before checking
 +	 * the neigh validity state. So if we'll get a notification, in case the
 +	 * neigh changes it's validity state, we would find the relevant neigh
 +	 * in the hash.
 +	 */
 +	err = mlx5e_rep_encap_entry_attach(netdev_priv(out_dev), e);
 +	if (err)
 +		goto free_encap;
 +
 +	read_lock_bh(&n->lock);
 +	nud_state = n->nud_state;
 +	ether_addr_copy(e->h_dest, n->ha);
 +	read_unlock_bh(&n->lock);
 +
 +	switch (e->tunnel_type) {
 +	case MLX5_HEADER_TYPE_VXLAN:
 +		gen_vxlan_header_ipv6(out_dev, encap_header,
 +				      ipv6_encap_size, e->h_dest, tos, ttl,
 +				      &fl6.daddr,
 +				      &fl6.saddr, tun_key->tp_dst,
 +				      tunnel_id_to_key32(tun_key->tun_id));
 +		break;
 +	default:
 +		err = -EOPNOTSUPP;
 +		goto destroy_neigh_entry;
 +	}
 +
 +	e->encap_size = ipv6_encap_size;
 +	e->encap_header = encap_header;
 +
 +	if (!(nud_state & NUD_VALID)) {
 +		neigh_event_send(n, NULL);
 +		err = -EAGAIN;
 +		goto out;
 +	}
 +
 +	err = mlx5_encap_alloc(priv->mdev, e->tunnel_type,
 +			       ipv6_encap_size, encap_header, &e->encap_id);
 +	if (err)
 +		goto destroy_neigh_entry;
 +
 +	e->flags |= MLX5_ENCAP_ENTRY_VALID;
 +	mlx5e_rep_queue_neigh_stats_work(netdev_priv(out_dev));
 +	neigh_release(n);
 +	return err;
 +
 +destroy_neigh_entry:
 +	mlx5e_rep_encap_entry_detach(netdev_priv(e->out_dev), e);
 +free_encap:
 +	kfree(encap_header);
 +out:
 +	if (n)
 +		neigh_release(n);
 +	return err;
 +}
 +
 +bool mlx5e_tc_tun_device_to_offload(struct mlx5e_priv *priv,
 +				    struct net_device *netdev)
 +{
 +	if (netif_is_vxlan(netdev) &&
 +	    MLX5_CAP_ESW(priv->mdev, vxlan_encap_decap))
 +		return true;
 +
 +	return false;
 +}
++=======
+ 
+ static bool is_merged_eswitch_dev(struct mlx5e_priv *priv,
+ 				  struct net_device *peer_netdev)
+ {
+ 	struct mlx5e_priv *peer_priv;
+ 
+ 	peer_priv = netdev_priv(peer_netdev);
+ 
+ 	return (MLX5_CAP_ESW(priv->mdev, merged_eswitch) &&
+ 		(priv->netdev->netdev_ops == peer_netdev->netdev_ops) &&
+ 		same_hw_devs(priv, peer_priv) &&
+ 		MLX5_VPORT_MANAGER(peer_priv->mdev) &&
+ 		(peer_priv->mdev->priv.eswitch->mode == SRIOV_OFFLOADS));
+ }
+ 
+ 
++>>>>>>> 101f4de9dd52 (net/mlx5e: Move TC tunnel offloading code to separate source file)
  
  static int mlx5e_attach_encap(struct mlx5e_priv *priv,
  			      struct ip_tunnel_info *tun_info,
@@@ -2549,7 -2311,10 +2596,14 @@@ vxlan_encap_offload_err
  		return -ENOMEM;
  
  	e->tun_info = *tun_info;
++<<<<<<< HEAD
 +	e->tunnel_type = tunnel_type;
++=======
+ 	err = mlx5e_tc_tun_init_encap_attr(mirred_dev, priv, e, extack);
+ 	if (err)
+ 		goto out_err;
+ 
++>>>>>>> 101f4de9dd52 (net/mlx5e: Move TC tunnel offloading code to separate source file)
  	INIT_LIST_HEAD(&e->flows);
  
  	if (family == AF_INET)
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/Makefile
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.c b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.c
new file mode 100644
index 000000000000..eaa43477e0ea
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.c
@@ -0,0 +1,496 @@
+/* SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB */
+/* Copyright (c) 2018 Mellanox Technologies. */
+
+#include <net/vxlan.h>
+#include "lib/vxlan.h"
+#include "en/tc_tun.h"
+
+static int mlx5e_route_lookup_ipv4(struct mlx5e_priv *priv,
+				   struct net_device *mirred_dev,
+				   struct net_device **out_dev,
+				   struct flowi4 *fl4,
+				   struct neighbour **out_n,
+				   u8 *out_ttl)
+{
+	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+	struct mlx5e_rep_priv *uplink_rpriv;
+	struct rtable *rt;
+	struct neighbour *n = NULL;
+
+#if IS_ENABLED(CONFIG_INET)
+	int ret;
+
+	rt = ip_route_output_key(dev_net(mirred_dev), fl4);
+	ret = PTR_ERR_OR_ZERO(rt);
+	if (ret)
+		return ret;
+#else
+	return -EOPNOTSUPP;
+#endif
+	uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
+	/* if the egress device isn't on the same HW e-switch, we use the uplink */
+	if (!switchdev_port_same_parent_id(priv->netdev, rt->dst.dev))
+		*out_dev = uplink_rpriv->netdev;
+	else
+		*out_dev = rt->dst.dev;
+
+	if (!(*out_ttl))
+		*out_ttl = ip4_dst_hoplimit(&rt->dst);
+	n = dst_neigh_lookup(&rt->dst, &fl4->daddr);
+	ip_rt_put(rt);
+	if (!n)
+		return -ENOMEM;
+
+	*out_n = n;
+	return 0;
+}
+
+static const char *mlx5e_netdev_kind(struct net_device *dev)
+{
+	if (dev->rtnl_link_ops)
+		return dev->rtnl_link_ops->kind;
+	else
+		return "";
+}
+
+static int mlx5e_route_lookup_ipv6(struct mlx5e_priv *priv,
+				   struct net_device *mirred_dev,
+				   struct net_device **out_dev,
+				   struct flowi6 *fl6,
+				   struct neighbour **out_n,
+				   u8 *out_ttl)
+{
+	struct neighbour *n = NULL;
+	struct dst_entry *dst;
+
+#if IS_ENABLED(CONFIG_INET) && IS_ENABLED(CONFIG_IPV6)
+	struct mlx5e_rep_priv *uplink_rpriv;
+	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+	int ret;
+
+	ret = ipv6_stub->ipv6_dst_lookup(dev_net(mirred_dev), NULL, &dst,
+					 fl6);
+	if (ret < 0)
+		return ret;
+
+	if (!(*out_ttl))
+		*out_ttl = ip6_dst_hoplimit(dst);
+
+	uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
+	/* if the egress device isn't on the same HW e-switch, we use the uplink */
+	if (!switchdev_port_same_parent_id(priv->netdev, dst->dev))
+		*out_dev = uplink_rpriv->netdev;
+	else
+		*out_dev = dst->dev;
+#else
+	return -EOPNOTSUPP;
+#endif
+
+	n = dst_neigh_lookup(dst, &fl6->daddr);
+	dst_release(dst);
+	if (!n)
+		return -ENOMEM;
+
+	*out_n = n;
+	return 0;
+}
+
+static int mlx5e_gen_vxlan_header(char buf[], struct ip_tunnel_key *tun_key)
+{
+	__be32 tun_id = tunnel_id_to_key32(tun_key->tun_id);
+	struct udphdr *udp = (struct udphdr *)(buf);
+	struct vxlanhdr *vxh = (struct vxlanhdr *)
+			       ((char *)udp + sizeof(struct udphdr));
+
+	udp->dest = tun_key->tp_dst;
+	vxh->vx_flags = VXLAN_HF_VNI;
+	vxh->vx_vni = vxlan_vni_field(tun_id);
+
+	return 0;
+}
+
+static int mlx5e_gen_ip_tunnel_header(char buf[], __u8 *ip_proto,
+				      struct mlx5e_encap_entry *e)
+{
+	int err = 0;
+	struct ip_tunnel_key *key = &e->tun_info.key;
+
+	if (e->tunnel_type == MLX5E_TC_TUNNEL_TYPE_VXLAN) {
+		*ip_proto = IPPROTO_UDP;
+		err = mlx5e_gen_vxlan_header(buf, key);
+	} else {
+		pr_warn("mlx5: Cannot generate tunnel header for tunnel type (%d)\n"
+			, e->tunnel_type);
+		err = -EOPNOTSUPP;
+	}
+
+	return err;
+}
+
+int mlx5e_tc_tun_create_header_ipv4(struct mlx5e_priv *priv,
+				    struct net_device *mirred_dev,
+				    struct mlx5e_encap_entry *e)
+{
+	int max_encap_size = MLX5_CAP_ESW(priv->mdev, max_encap_header_size);
+	int ipv4_encap_size = ETH_HLEN +
+			      sizeof(struct iphdr) +
+			      e->tunnel_hlen;
+	struct ip_tunnel_key *tun_key = &e->tun_info.key;
+	struct net_device *out_dev;
+	struct neighbour *n = NULL;
+	struct flowi4 fl4 = {};
+	char *encap_header;
+	struct ethhdr *eth;
+	u8 nud_state, ttl;
+	struct iphdr *ip;
+	int err;
+
+	if (max_encap_size < ipv4_encap_size) {
+		mlx5_core_warn(priv->mdev, "encap size %d too big, max supported is %d\n",
+			       ipv4_encap_size, max_encap_size);
+		return -EOPNOTSUPP;
+	}
+
+	encap_header = kzalloc(ipv4_encap_size, GFP_KERNEL);
+	if (!encap_header)
+		return -ENOMEM;
+
+	/* add the IP fields */
+	fl4.flowi4_tos = tun_key->tos;
+	fl4.daddr = tun_key->u.ipv4.dst;
+	fl4.saddr = tun_key->u.ipv4.src;
+	ttl = tun_key->ttl;
+
+	err = mlx5e_route_lookup_ipv4(priv, mirred_dev, &out_dev,
+				      &fl4, &n, &ttl);
+	if (err)
+		goto free_encap;
+
+	/* used by mlx5e_detach_encap to lookup a neigh hash table
+	 * entry in the neigh hash table when a user deletes a rule
+	 */
+	e->m_neigh.dev = n->dev;
+	e->m_neigh.family = n->ops->family;
+	memcpy(&e->m_neigh.dst_ip, n->primary_key, n->tbl->key_len);
+	e->out_dev = out_dev;
+
+	/* It's important to add the neigh to the hash table before checking
+	 * the neigh validity state. So if we'll get a notification, in case the
+	 * neigh changes it's validity state, we would find the relevant neigh
+	 * in the hash.
+	 */
+	err = mlx5e_rep_encap_entry_attach(netdev_priv(out_dev), e);
+	if (err)
+		goto free_encap;
+
+	read_lock_bh(&n->lock);
+	nud_state = n->nud_state;
+	ether_addr_copy(e->h_dest, n->ha);
+	read_unlock_bh(&n->lock);
+
+	/* add ethernet header */
+	eth = (struct ethhdr *)encap_header;
+	ether_addr_copy(eth->h_dest, e->h_dest);
+	ether_addr_copy(eth->h_source, out_dev->dev_addr);
+	eth->h_proto = htons(ETH_P_IP);
+
+	/* add ip header */
+	ip = (struct iphdr *)((char *)eth + sizeof(struct ethhdr));
+	ip->tos = tun_key->tos;
+	ip->version = 0x4;
+	ip->ihl = 0x5;
+	ip->ttl = ttl;
+	ip->daddr = fl4.daddr;
+	ip->saddr = fl4.saddr;
+
+	/* add tunneling protocol header */
+	err = mlx5e_gen_ip_tunnel_header((char *)ip + sizeof(struct iphdr),
+					 &ip->protocol, e);
+	if (err)
+		goto destroy_neigh_entry;
+
+	e->encap_size = ipv4_encap_size;
+	e->encap_header = encap_header;
+
+	if (!(nud_state & NUD_VALID)) {
+		neigh_event_send(n, NULL);
+		err = -EAGAIN;
+		goto out;
+	}
+
+	err = mlx5_packet_reformat_alloc(priv->mdev,
+					 e->reformat_type,
+					 ipv4_encap_size, encap_header,
+					 MLX5_FLOW_NAMESPACE_FDB,
+					 &e->encap_id);
+	if (err)
+		goto destroy_neigh_entry;
+
+	e->flags |= MLX5_ENCAP_ENTRY_VALID;
+	mlx5e_rep_queue_neigh_stats_work(netdev_priv(out_dev));
+	neigh_release(n);
+	return err;
+
+destroy_neigh_entry:
+	mlx5e_rep_encap_entry_detach(netdev_priv(e->out_dev), e);
+free_encap:
+	kfree(encap_header);
+out:
+	if (n)
+		neigh_release(n);
+	return err;
+}
+
+int mlx5e_tc_tun_create_header_ipv6(struct mlx5e_priv *priv,
+				    struct net_device *mirred_dev,
+				    struct mlx5e_encap_entry *e)
+{
+	int max_encap_size = MLX5_CAP_ESW(priv->mdev, max_encap_header_size);
+	int ipv6_encap_size = ETH_HLEN +
+			      sizeof(struct ipv6hdr) +
+			      e->tunnel_hlen;
+	struct ip_tunnel_key *tun_key = &e->tun_info.key;
+	struct net_device *out_dev;
+	struct neighbour *n = NULL;
+	struct flowi6 fl6 = {};
+	struct ipv6hdr *ip6h;
+	char *encap_header;
+	struct ethhdr *eth;
+	u8 nud_state, ttl;
+	int err;
+
+	if (max_encap_size < ipv6_encap_size) {
+		mlx5_core_warn(priv->mdev, "encap size %d too big, max supported is %d\n",
+			       ipv6_encap_size, max_encap_size);
+		return -EOPNOTSUPP;
+	}
+
+	encap_header = kzalloc(ipv6_encap_size, GFP_KERNEL);
+	if (!encap_header)
+		return -ENOMEM;
+
+	ttl = tun_key->ttl;
+
+	fl6.flowlabel = ip6_make_flowinfo(RT_TOS(tun_key->tos), tun_key->label);
+	fl6.daddr = tun_key->u.ipv6.dst;
+	fl6.saddr = tun_key->u.ipv6.src;
+
+	err = mlx5e_route_lookup_ipv6(priv, mirred_dev, &out_dev,
+				      &fl6, &n, &ttl);
+	if (err)
+		goto free_encap;
+
+	/* used by mlx5e_detach_encap to lookup a neigh hash table
+	 * entry in the neigh hash table when a user deletes a rule
+	 */
+	e->m_neigh.dev = n->dev;
+	e->m_neigh.family = n->ops->family;
+	memcpy(&e->m_neigh.dst_ip, n->primary_key, n->tbl->key_len);
+	e->out_dev = out_dev;
+
+	/* It's importent to add the neigh to the hash table before checking
+	 * the neigh validity state. So if we'll get a notification, in case the
+	 * neigh changes it's validity state, we would find the relevant neigh
+	 * in the hash.
+	 */
+	err = mlx5e_rep_encap_entry_attach(netdev_priv(out_dev), e);
+	if (err)
+		goto free_encap;
+
+	read_lock_bh(&n->lock);
+	nud_state = n->nud_state;
+	ether_addr_copy(e->h_dest, n->ha);
+	read_unlock_bh(&n->lock);
+
+	/* add ethernet header */
+	eth = (struct ethhdr *)encap_header;
+	ether_addr_copy(eth->h_dest, e->h_dest);
+	ether_addr_copy(eth->h_source, out_dev->dev_addr);
+	eth->h_proto = htons(ETH_P_IPV6);
+
+	/* add ip header */
+	ip6h = (struct ipv6hdr *)((char *)eth + sizeof(struct ethhdr));
+	ip6_flow_hdr(ip6h, tun_key->tos, 0);
+	/* the HW fills up ipv6 payload len */
+	ip6h->hop_limit   = ttl;
+	ip6h->daddr	  = fl6.daddr;
+	ip6h->saddr	  = fl6.saddr;
+
+	/* add tunneling protocol header */
+	err = mlx5e_gen_ip_tunnel_header((char *)ip6h + sizeof(struct ipv6hdr),
+					 &ip6h->nexthdr, e);
+	if (err)
+		goto destroy_neigh_entry;
+
+	e->encap_size = ipv6_encap_size;
+	e->encap_header = encap_header;
+
+	if (!(nud_state & NUD_VALID)) {
+		neigh_event_send(n, NULL);
+		err = -EAGAIN;
+		goto out;
+	}
+
+	err = mlx5_packet_reformat_alloc(priv->mdev,
+					 e->reformat_type,
+					 ipv6_encap_size, encap_header,
+					 MLX5_FLOW_NAMESPACE_FDB,
+					 &e->encap_id);
+	if (err)
+		goto destroy_neigh_entry;
+
+	e->flags |= MLX5_ENCAP_ENTRY_VALID;
+	mlx5e_rep_queue_neigh_stats_work(netdev_priv(out_dev));
+	neigh_release(n);
+	return err;
+
+destroy_neigh_entry:
+	mlx5e_rep_encap_entry_detach(netdev_priv(e->out_dev), e);
+free_encap:
+	kfree(encap_header);
+out:
+	if (n)
+		neigh_release(n);
+	return err;
+}
+
+int mlx5e_tc_tun_get_type(struct net_device *tunnel_dev)
+{
+	if (netif_is_vxlan(tunnel_dev))
+		return MLX5E_TC_TUNNEL_TYPE_VXLAN;
+	else
+		return MLX5E_TC_TUNNEL_TYPE_UNKNOWN;
+}
+
+bool mlx5e_tc_tun_device_to_offload(struct mlx5e_priv *priv,
+				    struct net_device *netdev)
+{
+	int tunnel_type = mlx5e_tc_tun_get_type(netdev);
+
+	if (tunnel_type == MLX5E_TC_TUNNEL_TYPE_VXLAN &&
+	    MLX5_CAP_ESW(priv->mdev, vxlan_encap_decap))
+		return true;
+	else
+		return false;
+}
+
+int mlx5e_tc_tun_init_encap_attr(struct net_device *tunnel_dev,
+				 struct mlx5e_priv *priv,
+				 struct mlx5e_encap_entry *e,
+				 struct netlink_ext_ack *extack)
+{
+	e->tunnel_type = mlx5e_tc_tun_get_type(tunnel_dev);
+
+	if (e->tunnel_type == MLX5E_TC_TUNNEL_TYPE_VXLAN) {
+		int dst_port =  be16_to_cpu(e->tun_info.key.tp_dst);
+
+		if (!mlx5_vxlan_lookup_port(priv->mdev->vxlan, dst_port)) {
+			NL_SET_ERR_MSG_MOD(extack,
+					   "vxlan udp dport was not registered with the HW");
+			netdev_warn(priv->netdev,
+				    "%d isn't an offloaded vxlan udp dport\n",
+				    dst_port);
+			return -EOPNOTSUPP;
+		}
+		e->reformat_type = MLX5_REFORMAT_TYPE_L2_TO_VXLAN;
+		e->tunnel_hlen = VXLAN_HLEN;
+	} else {
+		e->reformat_type = -1;
+		e->tunnel_hlen = -1;
+		return -EOPNOTSUPP;
+	}
+	return 0;
+}
+
+static int mlx5e_tc_tun_parse_vxlan(struct mlx5e_priv *priv,
+				    struct mlx5_flow_spec *spec,
+				    struct tc_cls_flower_offload *f,
+				    void *headers_c,
+				    void *headers_v)
+{
+	struct netlink_ext_ack *extack = f->common.extack;
+	struct flow_dissector_key_ports *key =
+		skb_flow_dissector_target(f->dissector,
+					  FLOW_DISSECTOR_KEY_ENC_PORTS,
+					  f->key);
+	struct flow_dissector_key_ports *mask =
+		skb_flow_dissector_target(f->dissector,
+					  FLOW_DISSECTOR_KEY_ENC_PORTS,
+					  f->mask);
+	void *misc_c = MLX5_ADDR_OF(fte_match_param,
+				    spec->match_criteria,
+				    misc_parameters);
+	void *misc_v = MLX5_ADDR_OF(fte_match_param,
+				    spec->match_value,
+				    misc_parameters);
+
+	/* Full udp dst port must be given */
+	if (!dissector_uses_key(f->dissector, FLOW_DISSECTOR_KEY_ENC_PORTS) ||
+	    memchr_inv(&mask->dst, 0xff, sizeof(mask->dst))) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "VXLAN decap filter must include enc_dst_port condition");
+		netdev_warn(priv->netdev,
+			    "VXLAN decap filter must include enc_dst_port condition\n");
+		return -EOPNOTSUPP;
+	}
+
+	/* udp dst port must be knonwn as a VXLAN port */
+	if (!mlx5_vxlan_lookup_port(priv->mdev->vxlan, be16_to_cpu(key->dst))) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "Matched UDP port is not registered as a VXLAN port");
+		netdev_warn(priv->netdev,
+			    "UDP port %d is not registered as a VXLAN port\n",
+			    be16_to_cpu(key->dst));
+		return -EOPNOTSUPP;
+	}
+
+	/* dst UDP port is valid here */
+	MLX5_SET_TO_ONES(fte_match_set_lyr_2_4, headers_c, ip_protocol);
+	MLX5_SET(fte_match_set_lyr_2_4, headers_v, ip_protocol, IPPROTO_UDP);
+
+	MLX5_SET(fte_match_set_lyr_2_4, headers_c, udp_dport, ntohs(mask->dst));
+	MLX5_SET(fte_match_set_lyr_2_4, headers_v, udp_dport, ntohs(key->dst));
+
+	MLX5_SET(fte_match_set_lyr_2_4, headers_c, udp_sport, ntohs(mask->src));
+	MLX5_SET(fte_match_set_lyr_2_4, headers_v, udp_sport, ntohs(key->src));
+
+	/* match on VNI */
+	if (dissector_uses_key(f->dissector, FLOW_DISSECTOR_KEY_ENC_KEYID)) {
+		struct flow_dissector_key_keyid *key =
+			skb_flow_dissector_target(f->dissector,
+						  FLOW_DISSECTOR_KEY_ENC_KEYID,
+						  f->key);
+		struct flow_dissector_key_keyid *mask =
+			skb_flow_dissector_target(f->dissector,
+						  FLOW_DISSECTOR_KEY_ENC_KEYID,
+						  f->mask);
+		MLX5_SET(fte_match_set_misc, misc_c, vxlan_vni,
+			 be32_to_cpu(mask->keyid));
+		MLX5_SET(fte_match_set_misc, misc_v, vxlan_vni,
+			 be32_to_cpu(key->keyid));
+	}
+	return 0;
+}
+
+int mlx5e_tc_tun_parse(struct net_device *filter_dev,
+		       struct mlx5e_priv *priv,
+		       struct mlx5_flow_spec *spec,
+		       struct tc_cls_flower_offload *f,
+		       void *headers_c,
+		       void *headers_v)
+{
+	int tunnel_type;
+	int err = 0;
+
+	tunnel_type = mlx5e_tc_tun_get_type(filter_dev);
+	if (tunnel_type == MLX5E_TC_TUNNEL_TYPE_VXLAN) {
+		err = mlx5e_tc_tun_parse_vxlan(priv, spec, f,
+					       headers_c, headers_v);
+	} else {
+		netdev_warn(priv->netdev,
+			    "decapsulation offload is not supported for %s net device (%d)\n",
+			    mlx5e_netdev_kind(filter_dev), tunnel_type);
+		return -EOPNOTSUPP;
+	}
+	return err;
+}
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.h b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.h
new file mode 100644
index 000000000000..ad4fc93b17a1
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_tun.h
@@ -0,0 +1,43 @@
+/* SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB */
+/* Copyright (c) 2018 Mellanox Technologies. */
+
+#ifndef __MLX5_EN_TC_TUNNEL_H__
+#define __MLX5_EN_TC_TUNNEL_H__
+
+#include <linux/netdevice.h>
+#include <linux/mlx5/fs.h>
+#include <net/pkt_cls.h>
+#include <linux/netlink.h>
+#include "en.h"
+#include "en_rep.h"
+
+enum {
+	MLX5E_TC_TUNNEL_TYPE_UNKNOWN,
+	MLX5E_TC_TUNNEL_TYPE_VXLAN
+};
+
+int mlx5e_tc_tun_init_encap_attr(struct net_device *tunnel_dev,
+				 struct mlx5e_priv *priv,
+				 struct mlx5e_encap_entry *e,
+				 struct netlink_ext_ack *extack);
+
+int mlx5e_tc_tun_create_header_ipv4(struct mlx5e_priv *priv,
+				    struct net_device *mirred_dev,
+				    struct mlx5e_encap_entry *e);
+
+int mlx5e_tc_tun_create_header_ipv6(struct mlx5e_priv *priv,
+				    struct net_device *mirred_dev,
+				    struct mlx5e_encap_entry *e);
+
+int mlx5e_tc_tun_get_type(struct net_device *tunnel_dev);
+bool mlx5e_tc_tun_device_to_offload(struct mlx5e_priv *priv,
+				    struct net_device *netdev);
+
+int mlx5e_tc_tun_parse(struct net_device *filter_dev,
+		       struct mlx5e_priv *priv,
+		       struct mlx5_flow_spec *spec,
+		       struct tc_cls_flower_offload *f,
+		       void *headers_c,
+		       void *headers_v);
+
+#endif //__MLX5_EN_TC_TUNNEL_H__
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
index 1af2953c38f5..4f6880605690 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
@@ -42,6 +42,7 @@
 #include "en.h"
 #include "en_rep.h"
 #include "en_tc.h"
+#include "en/tc_tun.h"
 #include "fs_core.h"
 
 #define MLX5E_REP_PARAMS_LOG_SQ_SIZE \
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
index 378507988a32..3ca07d3995ac 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
@@ -70,8 +70,6 @@ void mlx5e_tc_update_neigh_used_value(struct mlx5e_neigh_hash_entry *nhe);
 
 int mlx5e_tc_num_filters(struct mlx5e_priv *priv);
 
-bool mlx5e_tc_tun_device_to_offload(struct mlx5e_priv *priv,
-				    struct net_device *netdev);
 
 #else /* CONFIG_MLX5_ESWITCH */
 static inline int  mlx5e_tc_nic_init(struct mlx5e_priv *priv) { return 0; }
