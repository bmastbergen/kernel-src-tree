net/mlx5: E-Switch, Add chains and priorities

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
Rebuild_CHGLOG: - [netdrv] mlx5: E-Switch, Add chains and priorities (Alaa Hleihel) [1642498]
Rebuild_FUZZ: 95.35%
commit-author Paul Blakey <paulb@mellanox.com>
commit e52c2802400831389c773bc5bb119ab4b96fde3b
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/e52c2802.failed

A chain is a group of priorities, so use the fdb parallel
sub namespaces to implement chains, and a flow table for each
priority in them.

Because these namespaces are parallel and in series to the slow path
fdb, the chains aren't connected to one another (but to the slow path),
and one must use a explicit goto action to reach a different chain.

Flow tables for the priorities will be created on demand and destroyed
once not used.

The Firmware has four pools of tables for sizes S/XS/M/L (4k, 64k, 1m, 4m).
We maintain ghost copies of the pools occupancy.

When a new table is to be created, we scan the pools from large to small
and find the 1st table size which can be now created. When a table is
destroyed, we update the relevant pool.

Multi chain/prio isn't enabled yet by this patch, for now all flows
will use the default chain 0, and prio 1.

	Signed-off-by: Paul Blakey <paulb@mellanox.com>
	Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit e52c2802400831389c773bc5bb119ab4b96fde3b)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index 3a01f0d3c372,6c04e11f9a05..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -821,20 -832,23 +821,27 @@@ mlx5e_tc_add_fdb_flow(struct mlx5e_pri
  	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
  	struct mlx5_esw_flow_attr *attr = flow->esw_attr;
  	struct net_device *out_dev, *encap_dev = NULL;
 -	struct mlx5_fc *counter = NULL;
 +	struct mlx5_flow_handle *rule = NULL;
  	struct mlx5e_rep_priv *rpriv;
  	struct mlx5e_priv *out_priv;
 -	int err = 0, encap_err = 0;
 +	int err;
  
++<<<<<<< HEAD
 +	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_ENCAP) {
++=======
+ 	/* keep the old behaviour, use same prio for all offloaded rules */
+ 	attr->prio = 1;
+ 
+ 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT) {
++>>>>>>> e52c28024008 (net/mlx5: E-Switch, Add chains and priorities)
  		out_dev = __dev_get_by_index(dev_net(priv->netdev),
  					     attr->parse_attr->mirred_ifindex);
 -		encap_err = mlx5e_attach_encap(priv, &parse_attr->tun_info,
 -					       out_dev, &encap_dev, flow,
 -					       extack);
 -		if (encap_err && encap_err != -EAGAIN) {
 -			err = encap_err;
 -			goto err_attach_encap;
 +		err = mlx5e_attach_encap(priv, &parse_attr->tun_info,
 +					 out_dev, &encap_dev, flow);
 +		if (err) {
 +			rule = ERR_PTR(err);
 +			if (err != -EAGAIN)
 +				goto err_attach_encap;
  		}
  		out_priv = netdev_priv(encap_dev);
  		rpriv = out_priv->ppriv;
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index 21bc97b70ed9,54215f4312fa..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@@ -224,7 -247,20 +240,16 @@@ voi
  mlx5_eswitch_del_offloaded_rule(struct mlx5_eswitch *esw,
  				struct mlx5_flow_handle *rule,
  				struct mlx5_esw_flow_attr *attr);
 -void
 -mlx5_eswitch_del_fwd_rule(struct mlx5_eswitch *esw,
 -			  struct mlx5_flow_handle *rule,
 -			  struct mlx5_esw_flow_attr *attr);
  
+ bool
+ mlx5_eswitch_prios_supported(struct mlx5_eswitch *esw);
+ 
+ u16
+ mlx5_eswitch_get_prio_range(struct mlx5_eswitch *esw);
+ 
+ u32
+ mlx5_eswitch_get_chain_range(struct mlx5_eswitch *esw);
+ 
  struct mlx5_flow_handle *
  mlx5_eswitch_create_vport_rx_rule(struct mlx5_eswitch *esw, int vport,
  				  struct mlx5_flow_destination *dest);
@@@ -255,6 -298,10 +280,13 @@@ struct mlx5_esw_flow_attr 
  	u32	encap_id;
  	u32	mod_hdr_id;
  	u8	match_level;
++<<<<<<< HEAD
++=======
+ 	struct mlx5_fc *counter;
+ 	u32	chain;
+ 	u16	prio;
+ 	u32	dest_chain;
++>>>>>>> e52c28024008 (net/mlx5: E-Switch, Add chains and priorities)
  	struct mlx5e_tc_flow_parse_attr *parse_attr;
  };
  
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
index 84864631953e,8501b6c31c02..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@@ -48,12 -79,13 +79,21 @@@ mlx5_eswitch_add_offloaded_rule(struct 
  				struct mlx5_flow_spec *spec,
  				struct mlx5_esw_flow_attr *attr)
  {
++<<<<<<< HEAD
 +	struct mlx5_flow_destination dest[2] = {};
 +	struct mlx5_flow_act flow_act = {0};
 +	struct mlx5_fc *counter = NULL;
 +	struct mlx5_flow_handle *rule;
++=======
+ 	struct mlx5_flow_destination dest[MLX5_MAX_FLOW_FWD_VPORTS + 1] = {};
+ 	bool mirror = !!(attr->mirror_count);
+ 	struct mlx5_flow_act flow_act = {0};
+ 	struct mlx5_flow_handle *rule;
+ 	struct mlx5_flow_table *fdb;
+ 	int j, i = 0;
++>>>>>>> e52c28024008 (net/mlx5: E-Switch, Add chains and priorities)
  	void *misc;
 +	int i = 0;
  
  	if (esw->mode != SRIOV_OFFLOADS)
  		return ERR_PTR(-EOPNOTSUPP);
@@@ -70,23 -107,33 +110,48 @@@
  	}
  
  	if (flow_act.action & MLX5_FLOW_CONTEXT_ACTION_FWD_DEST) {
++<<<<<<< HEAD
 +		dest[i].type = MLX5_FLOW_DESTINATION_TYPE_VPORT;
 +		dest[i].vport.num = attr->out_rep->vport;
 +		if (MLX5_CAP_ESW(esw->dev, merged_eswitch)) {
 +			dest[i].vport.vhca_id =
 +				MLX5_CAP_GEN(attr->out_mdev, vhca_id);
 +			dest[i].vport.vhca_id_valid = 1;
++=======
+ 		if (attr->dest_chain) {
+ 			struct mlx5_flow_table *ft;
+ 
+ 			ft = esw_get_prio_table(esw, attr->dest_chain, 1, 0);
+ 			if (IS_ERR(ft)) {
+ 				rule = ERR_CAST(ft);
+ 				goto err_create_goto_table;
+ 			}
+ 
+ 			dest[i].type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
+ 			dest[i].ft = ft;
+ 			i++;
+ 		} else {
+ 			for (j = attr->mirror_count; j < attr->out_count; j++) {
+ 				dest[i].type = MLX5_FLOW_DESTINATION_TYPE_VPORT;
+ 				dest[i].vport.num = attr->out_rep[j]->vport;
+ 				dest[i].vport.vhca_id =
+ 					MLX5_CAP_GEN(attr->out_mdev[j], vhca_id);
+ 				dest[i].vport.vhca_id_valid =
+ 					!!MLX5_CAP_ESW(esw->dev, merged_eswitch);
+ 				i++;
+ 			}
++>>>>>>> e52c28024008 (net/mlx5: E-Switch, Add chains and priorities)
  		}
 +		i++;
  	}
  	if (flow_act.action & MLX5_FLOW_CONTEXT_ACTION_COUNT) {
 +		counter = mlx5_fc_create(esw->dev, true);
 +		if (IS_ERR(counter)) {
 +			rule = ERR_CAST(counter);
 +			goto err_counter_alloc;
 +		}
  		dest[i].type = MLX5_FLOW_DESTINATION_TYPE_COUNTER;
 -		dest[i].counter_id = mlx5_fc_id(attr->counter);
 +		dest[i].counter = counter;
  		i++;
  	}
  
@@@ -116,22 -163,124 +181,136 @@@
  	if (flow_act.action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR)
  		flow_act.modify_id = attr->mod_hdr_id;
  
 -	if (flow_act.action & MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT)
 -		flow_act.reformat_id = attr->encap_id;
 +	if (flow_act.action & MLX5_FLOW_CONTEXT_ACTION_ENCAP)
 +		flow_act.encap_id = attr->encap_id;
  
++<<<<<<< HEAD
 +	rule = mlx5_add_flow_rules((struct mlx5_flow_table *)esw->fdb_table.offloads.fast_fdb,
 +				   spec, &flow_act, dest, i);
++=======
+ 	fdb = esw_get_prio_table(esw, attr->chain, attr->prio, !!mirror);
+ 	if (IS_ERR(fdb)) {
+ 		rule = ERR_CAST(fdb);
+ 		goto err_esw_get;
+ 	}
+ 
+ 	rule = mlx5_add_flow_rules(fdb, spec, &flow_act, dest, i);
++>>>>>>> e52c28024008 (net/mlx5: E-Switch, Add chains and priorities)
  	if (IS_ERR(rule))
  		goto err_add_rule;
  	else
  		esw->offloads.num_flows++;
  
++<<<<<<< HEAD
 +	return rule;
++=======
+ 	return rule;
+ 
+ err_add_rule:
+ 	esw_put_prio_table(esw, attr->chain, attr->prio, !!mirror);
+ err_esw_get:
+ 	if (attr->dest_chain)
+ 		esw_put_prio_table(esw, attr->dest_chain, 1, 0);
+ err_create_goto_table:
+ 	return rule;
+ }
+ 
+ struct mlx5_flow_handle *
+ mlx5_eswitch_add_fwd_rule(struct mlx5_eswitch *esw,
+ 			  struct mlx5_flow_spec *spec,
+ 			  struct mlx5_esw_flow_attr *attr)
+ {
+ 	struct mlx5_flow_destination dest[MLX5_MAX_FLOW_FWD_VPORTS + 1] = {};
+ 	struct mlx5_flow_act flow_act = {0};
+ 	struct mlx5_flow_table *fast_fdb;
+ 	struct mlx5_flow_table *fwd_fdb;
+ 	struct mlx5_flow_handle *rule;
+ 	void *misc;
+ 	int i;
+ 
+ 	fast_fdb = esw_get_prio_table(esw, attr->chain, attr->prio, 0);
+ 	if (IS_ERR(fast_fdb)) {
+ 		rule = ERR_CAST(fast_fdb);
+ 		goto err_get_fast;
+ 	}
+ 
+ 	fwd_fdb = esw_get_prio_table(esw, attr->chain, attr->prio, 1);
+ 	if (IS_ERR(fwd_fdb)) {
+ 		rule = ERR_CAST(fwd_fdb);
+ 		goto err_get_fwd;
+ 	}
+ 
+ 	flow_act.action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST;
+ 	for (i = 0; i < attr->mirror_count; i++) {
+ 		dest[i].type = MLX5_FLOW_DESTINATION_TYPE_VPORT;
+ 		dest[i].vport.num = attr->out_rep[i]->vport;
+ 		dest[i].vport.vhca_id =
+ 			MLX5_CAP_GEN(attr->out_mdev[i], vhca_id);
+ 		dest[i].vport.vhca_id_valid = !!MLX5_CAP_ESW(esw->dev, merged_eswitch);
+ 	}
+ 	dest[i].type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
+ 	dest[i].ft = fwd_fdb,
+ 	i++;
+ 
+ 	misc = MLX5_ADDR_OF(fte_match_param, spec->match_value, misc_parameters);
+ 	MLX5_SET(fte_match_set_misc, misc, source_port, attr->in_rep->vport);
+ 
+ 	if (MLX5_CAP_ESW(esw->dev, merged_eswitch))
+ 		MLX5_SET(fte_match_set_misc, misc,
+ 			 source_eswitch_owner_vhca_id,
+ 			 MLX5_CAP_GEN(attr->in_mdev, vhca_id));
+ 
+ 	misc = MLX5_ADDR_OF(fte_match_param, spec->match_criteria, misc_parameters);
+ 	MLX5_SET_TO_ONES(fte_match_set_misc, misc, source_port);
+ 	if (MLX5_CAP_ESW(esw->dev, merged_eswitch))
+ 		MLX5_SET_TO_ONES(fte_match_set_misc, misc,
+ 				 source_eswitch_owner_vhca_id);
+ 
+ 	if (attr->match_level == MLX5_MATCH_NONE)
+ 		spec->match_criteria_enable = MLX5_MATCH_MISC_PARAMETERS;
+ 	else
+ 		spec->match_criteria_enable = MLX5_MATCH_OUTER_HEADERS |
+ 					      MLX5_MATCH_MISC_PARAMETERS;
+ 
+ 	rule = mlx5_add_flow_rules(fast_fdb, spec, &flow_act, dest, i);
+ 
+ 	if (IS_ERR(rule))
+ 		goto add_err;
+ 
+ 	esw->offloads.num_flows++;
++>>>>>>> e52c28024008 (net/mlx5: E-Switch, Add chains and priorities)
  
 +err_add_rule:
 +	mlx5_fc_destroy(esw->dev, counter);
 +err_counter_alloc:
  	return rule;
+ add_err:
+ 	esw_put_prio_table(esw, attr->chain, attr->prio, 1);
+ err_get_fwd:
+ 	esw_put_prio_table(esw, attr->chain, attr->prio, 0);
+ err_get_fast:
+ 	return rule;
+ }
+ 
+ static void
+ __mlx5_eswitch_del_rule(struct mlx5_eswitch *esw,
+ 			struct mlx5_flow_handle *rule,
+ 			struct mlx5_esw_flow_attr *attr,
+ 			bool fwd_rule)
+ {
+ 	bool mirror = (attr->mirror_count > 0);
+ 
+ 	mlx5_del_flow_rules(rule);
+ 	esw->offloads.num_flows--;
+ 
+ 	if (fwd_rule)  {
+ 		esw_put_prio_table(esw, attr->chain, attr->prio, 1);
+ 		esw_put_prio_table(esw, attr->chain, attr->prio, 0);
+ 	} else {
+ 		esw_put_prio_table(esw, attr->chain, attr->prio, !!mirror);
+ 		if (attr->dest_chain)
+ 			esw_put_prio_table(esw, attr->dest_chain, 1, 0);
+ 	}
  }
  
  void
@@@ -139,12 -288,15 +318,24 @@@ mlx5_eswitch_del_offloaded_rule(struct 
  				struct mlx5_flow_handle *rule,
  				struct mlx5_esw_flow_attr *attr)
  {
++<<<<<<< HEAD
 +	struct mlx5_fc *counter = NULL;
 +
 +	counter = mlx5_flow_rule_counter(rule);
 +	mlx5_del_flow_rules(rule);
 +	mlx5_fc_destroy(esw->dev, counter);
 +	esw->offloads.num_flows--;
++=======
+ 	__mlx5_eswitch_del_rule(esw, rule, attr, false);
+ }
+ 
+ void
+ mlx5_eswitch_del_fwd_rule(struct mlx5_eswitch *esw,
+ 			  struct mlx5_flow_handle *rule,
+ 			  struct mlx5_esw_flow_attr *attr)
+ {
+ 	__mlx5_eswitch_del_rule(esw, rule, attr, true);
++>>>>>>> e52c28024008 (net/mlx5: E-Switch, Add chains and priorities)
  }
  
  static int esw_set_global_vlan_pop(struct mlx5_eswitch *esw, u8 val)
@@@ -440,75 -593,164 +632,164 @@@ out
  
  #define ESW_OFFLOADS_NUM_GROUPS  4
  
- static int esw_create_offloads_fast_fdb_table(struct mlx5_eswitch *esw)
+ /* Firmware currently has 4 pool of 4 sizes that it supports (ESW_POOLS),
+  * and a virtual memory region of 16M (ESW_SIZE), this region is duplicated
+  * for each flow table pool. We can allocate up to 16M of each pool,
+  * and we keep track of how much we used via put/get_sz_to_pool.
+  * Firmware doesn't report any of this for now.
+  * ESW_POOL is expected to be sorted from large to small
+  */
+ #define ESW_SIZE (16 * 1024 * 1024)
+ const unsigned int ESW_POOLS[4] = { 4 * 1024 * 1024, 1 * 1024 * 1024,
+ 				    64 * 1024, 4 * 1024 };
+ 
+ static int
+ get_sz_from_pool(struct mlx5_eswitch *esw)
+ {
+ 	int sz = 0, i;
+ 
+ 	for (i = 0; i < ARRAY_SIZE(ESW_POOLS); i++) {
+ 		if (esw->fdb_table.offloads.fdb_left[i]) {
+ 			--esw->fdb_table.offloads.fdb_left[i];
+ 			sz = ESW_POOLS[i];
+ 			break;
+ 		}
+ 	}
+ 
+ 	return sz;
+ }
+ 
+ static void
+ put_sz_to_pool(struct mlx5_eswitch *esw, int sz)
+ {
+ 	int i;
+ 
+ 	for (i = 0; i < ARRAY_SIZE(ESW_POOLS); i++) {
+ 		if (sz >= ESW_POOLS[i]) {
+ 			++esw->fdb_table.offloads.fdb_left[i];
+ 			break;
+ 		}
+ 	}
+ }
+ 
+ static struct mlx5_flow_table *
+ create_next_size_table(struct mlx5_eswitch *esw,
+ 		       struct mlx5_flow_namespace *ns,
+ 		       u16 table_prio,
+ 		       int level,
+ 		       u32 flags)
+ {
+ 	struct mlx5_flow_table *fdb;
+ 	int sz;
+ 
+ 	sz = get_sz_from_pool(esw);
+ 	if (!sz)
+ 		return ERR_PTR(-ENOSPC);
+ 
+ 	fdb = mlx5_create_auto_grouped_flow_table(ns,
+ 						  table_prio,
+ 						  sz,
+ 						  ESW_OFFLOADS_NUM_GROUPS,
+ 						  level,
+ 						  flags);
+ 	if (IS_ERR(fdb)) {
+ 		esw_warn(esw->dev, "Failed to create FDB Table err %d (table prio: %d, level: %d, size: %d)\n",
+ 			 (int)PTR_ERR(fdb), table_prio, level, sz);
+ 		put_sz_to_pool(esw, sz);
+ 	}
+ 
+ 	return fdb;
+ }
+ 
+ static struct mlx5_flow_table *
+ esw_get_prio_table(struct mlx5_eswitch *esw, u32 chain, u16 prio, int level)
  {
  	struct mlx5_core_dev *dev = esw->dev;
- 	struct mlx5_flow_namespace *root_ns;
  	struct mlx5_flow_table *fdb = NULL;
- 	int esw_size, err = 0;
+ 	struct mlx5_flow_namespace *ns;
+ 	int table_prio, l = 0;
  	u32 flags = 0;
- 	u32 max_flow_counter = (MLX5_CAP_GEN(dev, max_flow_counter_31_16) << 16) |
- 				MLX5_CAP_GEN(dev, max_flow_counter_15_0);
  
- 	root_ns = mlx5_get_flow_namespace(dev, MLX5_FLOW_NAMESPACE_FDB);
- 	if (!root_ns) {
- 		esw_warn(dev, "Failed to get FDB flow namespace\n");
- 		err = -EOPNOTSUPP;
- 		goto out_namespace;
- 	}
+ 	mutex_lock(&esw->fdb_table.offloads.fdb_prio_lock);
  
- 	esw_debug(dev, "Create offloads FDB table, min (max esw size(2^%d), max counters(%d)*groups(%d))\n",
- 		  MLX5_CAP_ESW_FLOWTABLE_FDB(dev, log_max_ft_size),
- 		  max_flow_counter, ESW_OFFLOADS_NUM_GROUPS);
- 
- 	esw_size = min_t(int, max_flow_counter * ESW_OFFLOADS_NUM_GROUPS,
- 			 1 << MLX5_CAP_ESW_FLOWTABLE_FDB(dev, log_max_ft_size));
+ 	fdb = fdb_prio_table(esw, chain, prio, level).fdb;
+ 	if (fdb) {
+ 		/* take ref on earlier levels as well */
+ 		while (level >= 0)
+ 			fdb_prio_table(esw, chain, prio, level--).num_rules++;
+ 		mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
+ 		return fdb;
+ 	}
  
- 	if (mlx5_esw_has_fwd_fdb(dev))
- 		esw_size >>= 1;
+ 	ns = mlx5_get_fdb_sub_ns(dev, chain);
+ 	if (!ns) {
+ 		esw_warn(dev, "Failed to get FDB sub namespace\n");
+ 		mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
+ 		return ERR_PTR(-EOPNOTSUPP);
+ 	}
  
  	if (esw->offloads.encap != DEVLINK_ESWITCH_ENCAP_MODE_NONE)
 -		flags |= (MLX5_FLOW_TABLE_TUNNEL_EN_REFORMAT |
 +		flags |= (MLX5_FLOW_TABLE_TUNNEL_EN_ENCAP |
  			  MLX5_FLOW_TABLE_TUNNEL_EN_DECAP);
  
- 	fdb = mlx5_create_auto_grouped_flow_table(root_ns, FDB_FAST_PATH,
- 						  esw_size,
- 						  ESW_OFFLOADS_NUM_GROUPS, 0,
- 						  flags);
- 	if (IS_ERR(fdb)) {
- 		err = PTR_ERR(fdb);
- 		esw_warn(dev, "Failed to create Fast path FDB Table err %d\n", err);
- 		goto out_namespace;
- 	}
- 	esw->fdb_table.offloads.fast_fdb = fdb;
+ 	table_prio = (chain * FDB_MAX_PRIO) + prio - 1;
  
- 	if (!mlx5_esw_has_fwd_fdb(dev))
- 		goto out_namespace;
+ 	/* create earlier levels for correct fs_core lookup when
+ 	 * connecting tables
+ 	 */
+ 	for (l = 0; l <= level; l++) {
+ 		if (fdb_prio_table(esw, chain, prio, l).fdb) {
+ 			fdb_prio_table(esw, chain, prio, l).num_rules++;
+ 			continue;
+ 		}
  
- 	fdb = mlx5_create_auto_grouped_flow_table(root_ns, FDB_FAST_PATH,
- 						  esw_size,
- 						  ESW_OFFLOADS_NUM_GROUPS, 1,
- 						  flags);
- 	if (IS_ERR(fdb)) {
- 		err = PTR_ERR(fdb);
- 		esw_warn(dev, "Failed to create fwd table err %d\n", err);
- 		goto out_ft;
+ 		fdb = create_next_size_table(esw, ns, table_prio, l, flags);
+ 		if (IS_ERR(fdb)) {
+ 			l--;
+ 			goto err_create_fdb;
+ 		}
+ 
+ 		fdb_prio_table(esw, chain, prio, l).fdb = fdb;
+ 		fdb_prio_table(esw, chain, prio, l).num_rules = 1;
  	}
- 	esw->fdb_table.offloads.fwd_fdb = fdb;
  
- 	return err;
+ 	mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
+ 	return fdb;
  
- out_ft:
- 	mlx5_destroy_flow_table(esw->fdb_table.offloads.fast_fdb);
- out_namespace:
- 	return err;
+ err_create_fdb:
+ 	mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
+ 	if (l >= 0)
+ 		esw_put_prio_table(esw, chain, prio, l);
+ 
+ 	return fdb;
+ }
+ 
+ static void
+ esw_put_prio_table(struct mlx5_eswitch *esw, u32 chain, u16 prio, int level)
+ {
+ 	int l;
+ 
+ 	mutex_lock(&esw->fdb_table.offloads.fdb_prio_lock);
+ 
+ 	for (l = level; l >= 0; l--) {
+ 		if (--(fdb_prio_table(esw, chain, prio, l).num_rules) > 0)
+ 			continue;
+ 
+ 		put_sz_to_pool(esw, fdb_prio_table(esw, chain, prio, l).fdb->max_fte);
+ 		mlx5_destroy_flow_table(fdb_prio_table(esw, chain, prio, l).fdb);
+ 		fdb_prio_table(esw, chain, prio, l).fdb = NULL;
+ 	}
+ 
+ 	mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
  }
  
- static void esw_destroy_offloads_fast_fdb_table(struct mlx5_eswitch *esw)
+ static void esw_destroy_offloads_fast_fdb_tables(struct mlx5_eswitch *esw)
  {
- 	if (mlx5_esw_has_fwd_fdb(esw->dev))
- 		mlx5_destroy_flow_table(esw->fdb_table.offloads.fwd_fdb);
- 	mlx5_destroy_flow_table(esw->fdb_table.offloads.fast_fdb);
+ 	/* If lazy creation isn't supported, deref the fast path tables */
+ 	if (!(esw->fdb_table.flags & ESW_FDB_CHAINS_AND_PRIOS_SUPPORTED)) {
+ 		esw_put_prio_table(esw, 0, 1, 1);
+ 		esw_put_prio_table(esw, 0, 1, 0);
+ 	}
  }
  
  #define MAX_PF_SQ 256
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
