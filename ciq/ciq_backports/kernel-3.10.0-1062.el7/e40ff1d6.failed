KVM: nVMX: Do not load EOI-exitmap while running L2

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Liran Alon <liran.alon@oracle.com>
commit e40ff1d6608dd9a5e07d7bc3079c64d9d676fe15
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/e40ff1d6.failed

When L1 IOAPIC redirection-table is written, a request of
KVM_REQ_SCAN_IOAPIC is set on all vCPUs. This is done such that
all vCPUs will now recalc their IOAPIC handled vectors and load
it to their EOI-exitmap.

However, it could be that one of the vCPUs is currently running
L2. In this case, load_eoi_exitmap() will be called which would
write to vmcs02->eoi_exit_bitmap, which is wrong because
vmcs02->eoi_exit_bitmap should always be equal to
vmcs12->eoi_exit_bitmap. Furthermore, at this point
KVM_REQ_SCAN_IOAPIC was already consumed and therefore we will
never update vmcs01->eoi_exit_bitmap. This could lead to remote_irr
of some IOAPIC level-triggered entry to remain set forever.

Fix this issue by delaying the load of EOI-exitmap to when vCPU
is running L1.

One may wonder why not just delay entire KVM_REQ_SCAN_IOAPIC
processing to when vCPU is running L1. This is done in order to handle
correctly the case where LAPIC & IO-APIC of L1 is pass-throughed into
L2. In this case, vmcs12->virtual_interrupt_delivery should be 0. In
current nVMX implementation, that results in
vmcs02->virtual_interrupt_delivery to also be 0. Thus,
vmcs02->eoi_exit_bitmap is not used. Therefore, every L2 EOI cause
a #VMExit into L0 (either on MSR_WRITE to x2APIC MSR or
APIC_ACCESS/APIC_WRITE/EPT_MISCONFIG to APIC MMIO page).
In order for such L2 EOI to be broadcasted, if needed, from LAPIC
to IO-APIC, vcpu->arch.ioapic_handled_vectors must be updated
while L2 is running. Therefore, patch makes sure to delay only the
loading of EOI-exitmap but not the update of
vcpu->arch.ioapic_handled_vectors.

	Reviewed-by: Arbel Moshe <arbel.moshe@oracle.com>
	Reviewed-by: Krish Sadhukhan <krish.sadhukhan@oracle.com>
	Signed-off-by: Liran Alon <liran.alon@oracle.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit e40ff1d6608dd9a5e07d7bc3079c64d9d676fe15)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/kvm_host.h
#	arch/x86/kvm/x86.c
diff --cc arch/x86/include/asm/kvm_host.h
index 4091026435c1,c72891dd7d78..000000000000
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@@ -50,6 -47,34 +50,37 @@@
  
  #define KVM_IRQCHIP_NUM_PINS  KVM_IOAPIC_NUM_PINS
  
++<<<<<<< HEAD
++=======
+ /* x86-specific vcpu->requests bit members */
+ #define KVM_REQ_MIGRATE_TIMER		KVM_ARCH_REQ(0)
+ #define KVM_REQ_REPORT_TPR_ACCESS	KVM_ARCH_REQ(1)
+ #define KVM_REQ_TRIPLE_FAULT		KVM_ARCH_REQ(2)
+ #define KVM_REQ_MMU_SYNC		KVM_ARCH_REQ(3)
+ #define KVM_REQ_CLOCK_UPDATE		KVM_ARCH_REQ(4)
+ #define KVM_REQ_EVENT			KVM_ARCH_REQ(6)
+ #define KVM_REQ_APF_HALT		KVM_ARCH_REQ(7)
+ #define KVM_REQ_STEAL_UPDATE		KVM_ARCH_REQ(8)
+ #define KVM_REQ_NMI			KVM_ARCH_REQ(9)
+ #define KVM_REQ_PMU			KVM_ARCH_REQ(10)
+ #define KVM_REQ_PMI			KVM_ARCH_REQ(11)
+ #define KVM_REQ_SMI			KVM_ARCH_REQ(12)
+ #define KVM_REQ_MASTERCLOCK_UPDATE	KVM_ARCH_REQ(13)
+ #define KVM_REQ_MCLOCK_INPROGRESS \
+ 	KVM_ARCH_REQ_FLAGS(14, KVM_REQUEST_WAIT | KVM_REQUEST_NO_WAKEUP)
+ #define KVM_REQ_SCAN_IOAPIC \
+ 	KVM_ARCH_REQ_FLAGS(15, KVM_REQUEST_WAIT | KVM_REQUEST_NO_WAKEUP)
+ #define KVM_REQ_GLOBAL_CLOCK_UPDATE	KVM_ARCH_REQ(16)
+ #define KVM_REQ_APIC_PAGE_RELOAD \
+ 	KVM_ARCH_REQ_FLAGS(17, KVM_REQUEST_WAIT | KVM_REQUEST_NO_WAKEUP)
+ #define KVM_REQ_HV_CRASH		KVM_ARCH_REQ(18)
+ #define KVM_REQ_IOAPIC_EOI_EXIT		KVM_ARCH_REQ(19)
+ #define KVM_REQ_HV_RESET		KVM_ARCH_REQ(20)
+ #define KVM_REQ_HV_EXIT			KVM_ARCH_REQ(21)
+ #define KVM_REQ_HV_STIMER		KVM_ARCH_REQ(22)
+ #define KVM_REQ_LOAD_EOI_EXITMAP	KVM_ARCH_REQ(23)
+ 
++>>>>>>> e40ff1d6608d (KVM: nVMX: Do not load EOI-exitmap while running L2)
  #define CR0_RESERVED_BITS                                               \
  	(~(unsigned long)(X86_CR0_PE | X86_CR0_MP | X86_CR0_EM | X86_CR0_TS \
  			  | X86_CR0_ET | X86_CR0_NE | X86_CR0_WP | X86_CR0_AM \
@@@ -443,7 -499,8 +474,12 @@@ struct kvm_vcpu_arch 
  	u64 apic_base;
  	struct kvm_lapic *apic;    /* kernel irqchip context */
  	bool apicv_active;
++<<<<<<< HEAD
 +	u64 eoi_exit_bitmap[4];
++=======
+ 	bool load_eoi_exitmap_pending;
+ 	DECLARE_BITMAP(ioapic_handled_vectors, 256);
++>>>>>>> e40ff1d6608d (KVM: nVMX: Do not load EOI-exitmap while running L2)
  	unsigned long apic_attention;
  	int32_t apic_arb_prio;
  	int mp_state;
diff --cc arch/x86/kvm/x86.c
index f751a44d4548,9d19e6a31ed4..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -6489,21 -7103,56 +6489,59 @@@ static void process_smi(struct kvm_vcp
  	kvm_make_request(KVM_REQ_EVENT, vcpu);
  }
  
 -void kvm_make_scan_ioapic_request(struct kvm *kvm)
 -{
 -	kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
 -}
 -
  static void vcpu_scan_ioapic(struct kvm_vcpu *vcpu)
  {
++<<<<<<< HEAD
 +	if (!kvm_apic_present(vcpu))
++=======
+ 	if (!kvm_apic_hw_enabled(vcpu->arch.apic))
++>>>>>>> e40ff1d6608d (KVM: nVMX: Do not load EOI-exitmap while running L2)
  		return;
  
 -	bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
 +	memset(vcpu->arch.eoi_exit_bitmap, 0, 256 / 8);
  
  	if (irqchip_split(vcpu->kvm))
 -		kvm_scan_ioapic_routes(vcpu, vcpu->arch.ioapic_handled_vectors);
 +		kvm_scan_ioapic_routes(vcpu, vcpu->arch.eoi_exit_bitmap);
  	else {
 -		if (vcpu->arch.apicv_active)
 +		if (kvm_x86_ops->sync_pir_to_irr && vcpu->arch.apicv_active)
  			kvm_x86_ops->sync_pir_to_irr(vcpu);
 -		kvm_ioapic_scan_entry(vcpu, vcpu->arch.ioapic_handled_vectors);
 +		kvm_ioapic_scan_entry(vcpu, vcpu->arch.eoi_exit_bitmap);
  	}
++<<<<<<< HEAD
 +	kvm_x86_ops->load_eoi_exitmap(vcpu);
++=======
+ 
+ 	if (is_guest_mode(vcpu))
+ 		vcpu->arch.load_eoi_exitmap_pending = true;
+ 	else
+ 		kvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);
+ }
+ 
+ static void vcpu_load_eoi_exitmap(struct kvm_vcpu *vcpu)
+ {
+ 	u64 eoi_exit_bitmap[4];
+ 
+ 	if (!kvm_apic_hw_enabled(vcpu->arch.apic))
+ 		return;
+ 
+ 	bitmap_or((ulong *)eoi_exit_bitmap, vcpu->arch.ioapic_handled_vectors,
+ 		  vcpu_to_synic(vcpu)->vec_bitmap, 256);
+ 	kvm_x86_ops->load_eoi_exitmap(vcpu, eoi_exit_bitmap);
+ }
+ 
+ void kvm_arch_mmu_notifier_invalidate_range(struct kvm *kvm,
+ 		unsigned long start, unsigned long end)
+ {
+ 	unsigned long apic_address;
+ 
+ 	/*
+ 	 * The physical address of apic access page is stored in the VMCS.
+ 	 * Update it when it becomes invalid.
+ 	 */
+ 	apic_address = gfn_to_hva(kvm, APIC_DEFAULT_PHYS_BASE >> PAGE_SHIFT);
+ 	if (start <= apic_address && apic_address < end)
+ 		kvm_make_all_cpus_request(kvm, KVM_REQ_APIC_PAGE_RELOAD);
++>>>>>>> e40ff1d6608d (KVM: nVMX: Do not load EOI-exitmap while running L2)
  }
  
  void kvm_vcpu_reload_apic_access_page(struct kvm_vcpu *vcpu)
* Unmerged path arch/x86/include/asm/kvm_host.h
diff --git a/arch/x86/kvm/kvm_cache_regs.h b/arch/x86/kvm/kvm_cache_regs.h
index e1e89ee4af75..ac7bb1429491 100644
--- a/arch/x86/kvm/kvm_cache_regs.h
+++ b/arch/x86/kvm/kvm_cache_regs.h
@@ -92,6 +92,11 @@ static inline void enter_guest_mode(struct kvm_vcpu *vcpu)
 static inline void leave_guest_mode(struct kvm_vcpu *vcpu)
 {
 	vcpu->arch.hflags &= ~HF_GUEST_MASK;
+
+	if (vcpu->arch.load_eoi_exitmap_pending) {
+		vcpu->arch.load_eoi_exitmap_pending = false;
+		kvm_make_request(KVM_REQ_LOAD_EOI_EXITMAP, vcpu);
+	}
 }
 
 static inline bool is_guest_mode(struct kvm_vcpu *vcpu)
* Unmerged path arch/x86/kvm/x86.c
