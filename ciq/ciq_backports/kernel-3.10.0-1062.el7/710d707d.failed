xfs: always rejoin held resources during defer roll

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Darrick J. Wong <darrick.wong@oracle.com>
commit 710d707d2fa9cf4c2aa9def129e71e99513466ea
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/710d707d.failed

During testing of xfs/141 on a V4 filesystem, I observed some
inconsistent behavior with regards to resources that are held (i.e.
remain locked) across a defer roll.  The transaction roll always gives
the defer roll function a new transaction, even if committing the old
transaction fails.  However, the defer roll function only rejoins the
held resources if the transaction commit succeedied.  This means that
callers of defer roll have to figure out whether the held resources are
attached to the transaction being passed back.

Worse yet, if the defer roll was part of a defer finish call, we have a
third possibility: the defer finish could pass back a dirty transaction
with dirty held resources and an error code.

The only sane way to handle all of these scenarios is to require that
the code that held the resource either cancel the transaction before
unlocking and releasing the resources, or use functions that detach
resources from a transaction properly (e.g.  xfs_trans_brelse) if they
need to drop the reference before committing or cancelling the
transaction.

In order to make this so, change the defer roll code to join held
resources to the new transaction unconditionally and fix all the bhold
callers to release the held buffers correctly.

	Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
	Reviewed-by: Brian Foster <bfoster@redhat.com>
(cherry picked from commit 710d707d2fa9cf4c2aa9def129e71e99513466ea)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/libxfs/xfs_attr.c
#	fs/xfs/libxfs/xfs_defer.c
#	fs/xfs/xfs_attr.h
#	fs/xfs/xfs_dquot.c
diff --cc fs/xfs/libxfs/xfs_attr.c
index 3e8597157ebe,c441f41f14e8..000000000000
--- a/fs/xfs/libxfs/xfs_attr.c
+++ b/fs/xfs/libxfs/xfs_attr.c
@@@ -203,6 -191,121 +203,124 @@@ xfs_attr_calc_size
  	return nblks;
  }
  
++<<<<<<< HEAD
++=======
+ STATIC int
+ xfs_attr_try_sf_addname(
+ 	struct xfs_inode	*dp,
+ 	struct xfs_da_args	*args)
+ {
+ 
+ 	struct xfs_mount	*mp = dp->i_mount;
+ 	int			error, error2;
+ 
+ 	error = xfs_attr_shortform_addname(args);
+ 	if (error == -ENOSPC)
+ 		return error;
+ 
+ 	/*
+ 	 * Commit the shortform mods, and we're done.
+ 	 * NOTE: this is also the error path (EEXIST, etc).
+ 	 */
+ 	if (!error && (args->flags & ATTR_KERNOTIME) == 0)
+ 		xfs_trans_ichgtime(args->trans, dp, XFS_ICHGTIME_CHG);
+ 
+ 	if (mp->m_flags & XFS_MOUNT_WSYNC)
+ 		xfs_trans_set_sync(args->trans);
+ 
+ 	error2 = xfs_trans_commit(args->trans);
+ 	args->trans = NULL;
+ 	return error ? error : error2;
+ }
+ 
+ /*
+  * Set the attribute specified in @args.
+  */
+ int
+ xfs_attr_set_args(
+ 	struct xfs_da_args	*args)
+ {
+ 	struct xfs_inode	*dp = args->dp;
+ 	struct xfs_buf          *leaf_bp = NULL;
+ 	int			error;
+ 
+ 	/*
+ 	 * If the attribute list is non-existent or a shortform list,
+ 	 * upgrade it to a single-leaf-block attribute list.
+ 	 */
+ 	if (dp->i_d.di_aformat == XFS_DINODE_FMT_LOCAL ||
+ 	    (dp->i_d.di_aformat == XFS_DINODE_FMT_EXTENTS &&
+ 	     dp->i_d.di_anextents == 0)) {
+ 
+ 		/*
+ 		 * Build initial attribute list (if required).
+ 		 */
+ 		if (dp->i_d.di_aformat == XFS_DINODE_FMT_EXTENTS)
+ 			xfs_attr_shortform_create(args);
+ 
+ 		/*
+ 		 * Try to add the attr to the attribute list in the inode.
+ 		 */
+ 		error = xfs_attr_try_sf_addname(dp, args);
+ 		if (error != -ENOSPC)
+ 			return error;
+ 
+ 		/*
+ 		 * It won't fit in the shortform, transform to a leaf block.
+ 		 * GROT: another possible req'mt for a double-split btree op.
+ 		 */
+ 		error = xfs_attr_shortform_to_leaf(args, &leaf_bp);
+ 		if (error)
+ 			return error;
+ 
+ 		/*
+ 		 * Prevent the leaf buffer from being unlocked so that a
+ 		 * concurrent AIL push cannot grab the half-baked leaf
+ 		 * buffer and run into problems with the write verifier.
+ 		 * Once we're done rolling the transaction we can release
+ 		 * the hold and add the attr to the leaf.
+ 		 */
+ 		xfs_trans_bhold(args->trans, leaf_bp);
+ 		error = xfs_defer_finish(&args->trans);
+ 		xfs_trans_bhold_release(args->trans, leaf_bp);
+ 		if (error) {
+ 			xfs_trans_brelse(args->trans, leaf_bp);
+ 			return error;
+ 		}
+ 	}
+ 
+ 	if (xfs_bmap_one_block(dp, XFS_ATTR_FORK))
+ 		error = xfs_attr_leaf_addname(args);
+ 	else
+ 		error = xfs_attr_node_addname(args);
+ 	return error;
+ }
+ 
+ /*
+  * Remove the attribute specified in @args.
+  */
+ int
+ xfs_attr_remove_args(
+ 	struct xfs_da_args      *args)
+ {
+ 	struct xfs_inode	*dp = args->dp;
+ 	int			error;
+ 
+ 	if (!xfs_inode_hasattr(dp)) {
+ 		error = -ENOATTR;
+ 	} else if (dp->i_d.di_aformat == XFS_DINODE_FMT_LOCAL) {
+ 		ASSERT(dp->i_afp->if_flags & XFS_IFINLINE);
+ 		error = xfs_attr_shortform_remove(args);
+ 	} else if (xfs_bmap_one_block(dp, XFS_ATTR_FORK)) {
+ 		error = xfs_attr_leaf_removename(args);
+ 	} else {
+ 		error = xfs_attr_node_removename(args);
+ 	}
+ 
+ 	return error;
+ }
+ 
++>>>>>>> 710d707d2fa9 (xfs: always rejoin held resources during defer roll)
  int
  xfs_attr_set(
  	struct xfs_inode	*dp,
@@@ -270,90 -369,18 +388,99 @@@
  	error = xfs_trans_reserve_quota_nblks(args.trans, dp, args.total, 0,
  				rsvd ? XFS_QMOPT_RES_REGBLKS | XFS_QMOPT_FORCE_RES :
  				       XFS_QMOPT_RES_REGBLKS);
 -	if (error)
 -		goto out_trans_cancel;
 +	if (error) {
 +		xfs_iunlock(dp, XFS_ILOCK_EXCL);
 +		xfs_trans_cancel(args.trans);
 +		return error;
 +	}
  
  	xfs_trans_ijoin(args.trans, dp, 0);
++<<<<<<< HEAD
 +
 +	/*
 +	 * If the attribute list is non-existent or a shortform list,
 +	 * upgrade it to a single-leaf-block attribute list.
 +	 */
 +	if (dp->i_d.di_aformat == XFS_DINODE_FMT_LOCAL ||
 +	    (dp->i_d.di_aformat == XFS_DINODE_FMT_EXTENTS &&
 +	     dp->i_d.di_anextents == 0)) {
 +
 +		/*
 +		 * Build initial attribute list (if required).
 +		 */
 +		if (dp->i_d.di_aformat == XFS_DINODE_FMT_EXTENTS)
 +			xfs_attr_shortform_create(&args);
 +
 +		/*
 +		 * Try to add the attr to the attribute list in
 +		 * the inode.
 +		 */
 +		error = xfs_attr_shortform_addname(&args);
 +		if (error != -ENOSPC) {
 +			/*
 +			 * Commit the shortform mods, and we're done.
 +			 * NOTE: this is also the error path (EEXIST, etc).
 +			 */
 +			ASSERT(args.trans != NULL);
 +
 +			/*
 +			 * If this is a synchronous mount, make sure that
 +			 * the transaction goes to disk before returning
 +			 * to the user.
 +			 */
 +			if (mp->m_flags & XFS_MOUNT_WSYNC)
 +				xfs_trans_set_sync(args.trans);
 +
 +			if (!error && (flags & ATTR_KERNOTIME) == 0) {
 +				xfs_trans_ichgtime(args.trans, dp,
 +							XFS_ICHGTIME_CHG);
 +			}
 +			err2 = xfs_trans_commit(args.trans);
 +			xfs_iunlock(dp, XFS_ILOCK_EXCL);
 +
 +			return error ? error : err2;
 +		}
 +
 +		/*
 +		 * It won't fit in the shortform, transform to a leaf block.
 +		 * GROT: another possible req'mt for a double-split btree op.
 +		 */
 +		xfs_defer_init(args.dfops, args.firstblock);
 +		error = xfs_attr_shortform_to_leaf(&args);
 +		if (!error)
 +			error = xfs_defer_finish(&args.trans, args.dfops, dp);
 +		if (error) {
 +			args.trans = NULL;
 +			xfs_defer_cancel(&dfops);
 +			goto out;
 +		}
 +
 +		/*
 +		 * Commit the leaf transformation.  We'll need another (linked)
 +		 * transaction to add the new attribute to the leaf.
 +		 */
 +
 +		error = xfs_trans_roll_inode(&args.trans, dp);
 +		if (error)
 +			goto out;
 +
++=======
+ 	error = xfs_attr_set_args(&args);
+ 	if (error)
+ 		goto out_trans_cancel;
+ 	if (!args.trans) {
+ 		/* shortform attribute has already been committed */
+ 		goto out_unlock;
++>>>>>>> 710d707d2fa9 (xfs: always rejoin held resources during defer roll)
  	}
  
 +	if (xfs_bmap_one_block(dp, XFS_ATTR_FORK))
 +		error = xfs_attr_leaf_addname(&args);
 +	else
 +		error = xfs_attr_node_addname(&args);
 +	if (error)
 +		goto out;
 +
  	/*
  	 * If this is a synchronous mount, make sure that the
  	 * transaction goes to disk before returning to the user.
@@@ -369,15 -396,14 +496,19 @@@
  	 */
  	xfs_trans_log_inode(args.trans, dp, XFS_ILOG_CORE);
  	error = xfs_trans_commit(args.trans);
 -out_unlock:
  	xfs_iunlock(dp, XFS_ILOCK_EXCL);
 +
  	return error;
  
++<<<<<<< HEAD
 +out:
++=======
+ out_trans_cancel:
++>>>>>>> 710d707d2fa9 (xfs: always rejoin held resources during defer roll)
  	if (args.trans)
  		xfs_trans_cancel(args.trans);
 -	goto out_unlock;
 +	xfs_iunlock(dp, XFS_ILOCK_EXCL);
 +	return error;
  }
  
  /*
diff --cc fs/xfs/libxfs/xfs_defer.c
index 606e68286320,1c6bf2105939..000000000000
--- a/fs/xfs/libxfs/xfs_defer.c
+++ b/fs/xfs/libxfs/xfs_defer.c
@@@ -245,25 -233,69 +245,39 @@@ xfs_defer_trans_roll
  	int				i;
  	int				error;
  
 -	list_for_each_entry(lip, &tp->t_items, li_trans) {
 -		switch (lip->li_type) {
 -		case XFS_LI_BUF:
 -			bli = container_of(lip, struct xfs_buf_log_item,
 -					   bli_item);
 -			if (bli->bli_flags & XFS_BLI_HOLD) {
 -				if (bpcount >= XFS_DEFER_OPS_NR_BUFS) {
 -					ASSERT(0);
 -					return -EFSCORRUPTED;
 -				}
 -				xfs_trans_dirty_buf(tp, bli->bli_buf);
 -				bplist[bpcount++] = bli->bli_buf;
 -			}
 -			break;
 -		case XFS_LI_INODE:
 -			ili = container_of(lip, struct xfs_inode_log_item,
 -					   ili_item);
 -			if (ili->ili_lock_flags == 0) {
 -				if (ipcount >= XFS_DEFER_OPS_NR_INODES) {
 -					ASSERT(0);
 -					return -EFSCORRUPTED;
 -				}
 -				xfs_trans_log_inode(tp, ili->ili_inode,
 -						    XFS_ILOG_CORE);
 -				iplist[ipcount++] = ili->ili_inode;
 -			}
 -			break;
 -		default:
 -			break;
 -		}
 -	}
 +	/* Log all the joined inodes. */
 +	for (i = 0; i < XFS_DEFER_OPS_NR_INODES && dop->dop_inodes[i]; i++)
 +		xfs_trans_log_inode(*tp, dop->dop_inodes[i], XFS_ILOG_CORE);
  
 -	trace_xfs_defer_trans_roll(tp, _RET_IP_);
 +	trace_xfs_defer_trans_roll((*tp)->t_mountp, dop);
  
++<<<<<<< HEAD
 +	/* Roll the transaction. */
 +	error = xfs_trans_roll(tp);
 +	if (error) {
 +		trace_xfs_defer_trans_roll_error((*tp)->t_mountp, dop, error);
 +		xfs_defer_trans_abort(*tp, dop, error);
 +		return error;
 +	}
 +	dop->dop_committed = true;
++=======
+ 	/*
+ 	 * Roll the transaction.  Rolling always given a new transaction (even
+ 	 * if committing the old one fails!) to hand back to the caller, so we
+ 	 * join the held resources to the new transaction so that we always
+ 	 * return with the held resources joined to @tpp, no matter what
+ 	 * happened.
+ 	 */
+ 	error = xfs_trans_roll(tpp);
+ 	tp = *tpp;
++>>>>>>> 710d707d2fa9 (xfs: always rejoin held resources during defer roll)
  
  	/* Rejoin the joined inodes. */
 -	for (i = 0; i < ipcount; i++)
 -		xfs_trans_ijoin(tp, iplist[i], 0);
 -
 -	/* Rejoin the buffers and dirty them so the log moves forward. */
 -	for (i = 0; i < bpcount; i++) {
 -		xfs_trans_bjoin(tp, bplist[i]);
 -		xfs_trans_bhold(tp, bplist[i]);
 -	}
 +	for (i = 0; i < XFS_DEFER_OPS_NR_INODES && dop->dop_inodes[i]; i++)
 +		xfs_trans_ijoin(*tp, dop->dop_inodes[i], 0);
  
+ 	if (error)
+ 		trace_xfs_defer_trans_roll_error(tp, error);
  	return error;
  }
  
diff --cc fs/xfs/xfs_attr.h
index 5d5a5e277f35,3b0dce06e454..000000000000
--- a/fs/xfs/xfs_attr.h
+++ b/fs/xfs/xfs_attr.h
@@@ -149,9 -140,11 +149,13 @@@ int xfs_attr_get(struct xfs_inode *ip, 
  		 unsigned char *value, int *valuelenp, int flags);
  int xfs_attr_set(struct xfs_inode *dp, const unsigned char *name,
  		 unsigned char *value, int valuelen, int flags);
++<<<<<<< HEAD:fs/xfs/xfs_attr.h
++=======
+ int xfs_attr_set_args(struct xfs_da_args *args);
++>>>>>>> 710d707d2fa9 (xfs: always rejoin held resources during defer roll):fs/xfs/libxfs/xfs_attr.h
  int xfs_attr_remove(struct xfs_inode *dp, const unsigned char *name, int flags);
 -int xfs_attr_remove_args(struct xfs_da_args *args);
  int xfs_attr_list(struct xfs_inode *dp, char *buffer, int bufsize,
  		  int flags, struct attrlist_cursor_kern *cursor);
 -bool xfs_attr_namecheck(const void *name, size_t length);
 +
  
  #endif	/* __XFS_ATTR_H__ */
diff --cc fs/xfs/xfs_dquot.c
index 191ab4fa4c54,a1af984e4913..000000000000
--- a/fs/xfs/xfs_dquot.c
+++ b/fs/xfs/xfs_dquot.c
@@@ -288,26 -276,23 +288,32 @@@ xfs_dquot_set_prealloc_limits(struct xf
  }
  
  /*
++<<<<<<< HEAD
 + * Allocate a block and fill it with dquots.
 + * This is called when the bmapi finds a hole.
++=======
+  * Ensure that the given in-core dquot has a buffer on disk backing it, and
+  * return the buffer locked and held. This is called when the bmapi finds a
+  * hole.
++>>>>>>> 710d707d2fa9 (xfs: always rejoin held resources during defer roll)
   */
  STATIC int
 -xfs_dquot_disk_alloc(
 -	struct xfs_trans	**tpp,
 -	struct xfs_dquot	*dqp,
 -	struct xfs_buf		**bpp)
 +xfs_qm_dqalloc(
 +	xfs_trans_t	**tpp,
 +	xfs_mount_t	*mp,
 +	xfs_dquot_t	*dqp,
 +	xfs_inode_t	*quotip,
 +	xfs_fileoff_t	offset_fsb,
 +	xfs_buf_t	**O_bpp)
  {
 -	struct xfs_bmbt_irec	map;
 -	struct xfs_trans	*tp = *tpp;
 -	struct xfs_mount	*mp = tp->t_mountp;
 -	struct xfs_buf		*bp;
 -	struct xfs_inode	*quotip = xfs_quota_inode(mp, dqp->dq_flags);
 -	int			nmaps = 1;
 -	int			error;
 +	xfs_fsblock_t	firstblock;
 +	struct xfs_defer_ops dfops;
 +	xfs_bmbt_irec_t map;
 +	int		nmaps, error;
 +	xfs_buf_t	*bp;
 +	xfs_trans_t	*tp = *tpp;
 +
 +	ASSERT(tp != NULL);
  
  	trace_xfs_dqalloc(dqp);
  
@@@ -360,88 -336,37 +366,103 @@@
  	 */
  	xfs_qm_init_dquot_blk(tp, mp, be32_to_cpu(dqp->q_core.d_id),
  			      dqp->dq_flags & XFS_DQ_ALLTYPES, bp);
 -	xfs_buf_set_ref(bp, XFS_DQUOT_REF);
  
  	/*
 -	 * Hold the buffer and join it to the dfops so that we'll still own
 -	 * the buffer when we return to the caller.  The buffer disposal on
 -	 * error must be paid attention to very carefully, as it has been
 -	 * broken since commit efa092f3d4c6 "[XFS] Fixes a bug in the quota
 -	 * code when allocating a new dquot record" in 2005, and the later
 -	 * conversion to xfs_defer_ops in commit 310a75a3c6c747 failed to keep
 -	 * the buffer locked across the _defer_finish call.  We can now do
 -	 * this correctly with xfs_defer_bjoin.
 +	 * xfs_defer_finish() may commit the current transaction and
 +	 * start a second transaction if the freelist is not empty.
  	 *
 -	 * Above, we allocated a disk block for the dquot information and used
 -	 * get_buf to initialize the dquot. If the _defer_finish fails, the old
 -	 * transaction is gone but the new buffer is not joined or held to any
 -	 * transaction, so we must _buf_relse it.
 +	 * Since we still want to modify this buffer, we need to
 +	 * ensure that the buffer is not released on commit of
 +	 * the first transaction and ensure the buffer is added to the
 +	 * second transaction.
  	 *
++<<<<<<< HEAD
 +	 * If there is only one transaction then don't stop the buffer
 +	 * from being released when it commits later on.
++=======
+ 	 * If everything succeeds, the caller of this function is returned a
+ 	 * buffer that is locked and held to the transaction.  The caller
+ 	 * is responsible for unlocking any buffer passed back, either
+ 	 * manually or by committing the transaction.  On error, the buffer is
+ 	 * released and not passed back.
++>>>>>>> 710d707d2fa9 (xfs: always rejoin held resources during defer roll)
  	 */
 +
  	xfs_trans_bhold(tp, bp);
++<<<<<<< HEAD
 +
 +	error = xfs_defer_finish(tpp, &dfops, NULL);
 +	if (error)
 +		goto error1;
 +
 +	/* Transaction was committed? */
 +	if (*tpp != tp) {
 +		tp = *tpp;
 +		xfs_trans_bjoin(tp, bp);
 +	} else {
 +		xfs_trans_bhold_release(tp, bp);
 +	}
 +
 +	*O_bpp = bp;
 +	return 0;
 +
 +error1:
 +	xfs_defer_cancel(&dfops);
 +error0:
 +	xfs_iunlock(quotip, XFS_ILOCK_EXCL);
 +
 +	return error;
 +}
 +
 +STATIC int
 +xfs_qm_dqrepair(
 +	struct xfs_mount	*mp,
 +	struct xfs_trans	*tp,
 +	struct xfs_dquot	*dqp,
 +	xfs_dqid_t		firstid,
 +	struct xfs_buf		**bpp)
 +{
 +	int			error;
 +	struct xfs_disk_dquot	*ddq;
 +	struct xfs_dqblk	*d;
 +	int			i;
 +
 +	/*
 +	 * Read the buffer without verification so we get the corrupted
 +	 * buffer returned to us. make sure we verify it on write, though.
 +	 */
 +	error = xfs_trans_read_buf(mp, tp, mp->m_ddev_targp, dqp->q_blkno,
 +				   mp->m_quotainfo->qi_dqchunklen,
 +				   0, bpp, NULL);
 +
 +	if (error) {
 +		ASSERT(*bpp == NULL);
++=======
+ 	error = xfs_defer_finish(tpp);
+ 	if (error) {
+ 		xfs_trans_bhold_release(*tpp, bp);
+ 		xfs_trans_brelse(*tpp, bp);
++>>>>>>> 710d707d2fa9 (xfs: always rejoin held resources during defer roll)
  		return error;
  	}
 -	*bpp = bp;
 +	(*bpp)->b_ops = &xfs_dquot_buf_ops;
 +
 +	ASSERT(xfs_buf_islocked(*bpp));
 +	d = (struct xfs_dqblk *)(*bpp)->b_addr;
 +
 +	/* Do the actual repair of dquots in this buffer */
 +	for (i = 0; i < mp->m_quotainfo->qi_dqperchunk; i++) {
 +		ddq = &d[i].dd_diskdq;
 +		error = xfs_dqcheck(mp, ddq, firstid + i,
 +				       dqp->dq_flags & XFS_DQ_ALLTYPES,
 +				       XFS_QMOPT_DQREPAIR, "xfs_qm_dqrepair");
 +		if (error) {
 +			/* repair failed, we're screwed */
 +			xfs_trans_brelse(tp, *bpp);
 +			return -EIO;
 +		}
 +	}
 +
  	return 0;
  }
  
@@@ -644,40 -513,89 +665,106 @@@ xfs_qm_dqread
  
  	/* initialize the dquot speculative prealloc thresholds */
  	xfs_dquot_set_prealloc_limits(dqp);
 -}
  
++<<<<<<< HEAD
 +	/* Mark the buf so that this will stay incore a little longer */
 +	xfs_buf_set_ref(bp, XFS_DQUOT_REF);
++=======
+ /* Allocate and initialize the dquot buffer for this in-core dquot. */
+ static int
+ xfs_qm_dqread_alloc(
+ 	struct xfs_mount	*mp,
+ 	struct xfs_dquot	*dqp,
+ 	struct xfs_buf		**bpp)
+ {
+ 	struct xfs_trans	*tp;
+ 	int			error;
+ 
+ 	error = xfs_trans_alloc(mp, &M_RES(mp)->tr_qm_dqalloc,
+ 			XFS_QM_DQALLOC_SPACE_RES(mp), 0, 0, &tp);
+ 	if (error)
+ 		goto err;
+ 
+ 	error = xfs_dquot_disk_alloc(&tp, dqp, bpp);
+ 	if (error)
+ 		goto err_cancel;
+ 
+ 	error = xfs_trans_commit(tp);
+ 	if (error) {
+ 		/*
+ 		 * Buffer was held to the transaction, so we have to unlock it
+ 		 * manually here because we're not passing it back.
+ 		 */
+ 		xfs_buf_relse(*bpp);
+ 		*bpp = NULL;
+ 		goto err;
+ 	}
+ 	return 0;
+ 
+ err_cancel:
+ 	xfs_trans_cancel(tp);
+ err:
+ 	return error;
+ }
+ 
+ /*
+  * Read in the ondisk dquot using dqtobp() then copy it to an incore version,
+  * and release the buffer immediately.  If @can_alloc is true, fill any
+  * holes in the on-disk metadata.
+  */
+ static int
+ xfs_qm_dqread(
+ 	struct xfs_mount	*mp,
+ 	xfs_dqid_t		id,
+ 	uint			type,
+ 	bool			can_alloc,
+ 	struct xfs_dquot	**dqpp)
+ {
+ 	struct xfs_dquot	*dqp;
+ 	struct xfs_buf		*bp;
+ 	int			error;
+ 
+ 	dqp = xfs_dquot_alloc(mp, id, type);
+ 	trace_xfs_dqread(dqp);
+ 
+ 	/* Try to read the buffer, allocating if necessary. */
+ 	error = xfs_dquot_disk_read(mp, dqp, &bp);
+ 	if (error == -ENOENT && can_alloc)
+ 		error = xfs_qm_dqread_alloc(mp, dqp, &bp);
+ 	if (error)
+ 		goto err;
++>>>>>>> 710d707d2fa9 (xfs: always rejoin held resources during defer roll)
  
  	/*
 -	 * At this point we should have a clean locked buffer.  Copy the data
 -	 * to the incore dquot and release the buffer since the incore dquot
 -	 * has its own locking protocol so we needn't tie up the buffer any
 -	 * further.
 +	 * We got the buffer with a xfs_trans_read_buf() (in dqtobp())
 +	 * So we need to release with xfs_trans_brelse().
 +	 * The strategy here is identical to that of inodes; we lock
 +	 * the dquot in xfs_qm_dqget() before making it accessible to
 +	 * others. This is because dquots, like inodes, need a good level of
 +	 * concurrency, and we don't want to take locks on the entire buffers
 +	 * for dquot accesses.
 +	 * Note also that the dquot buffer may even be dirty at this point, if
 +	 * this particular dquot was repaired. We still aren't afraid to
 +	 * brelse it because we have the changes incore.
  	 */
  	ASSERT(xfs_buf_islocked(bp));
 -	xfs_dquot_from_disk(dqp, bp);
 +	xfs_trans_brelse(tp, bp);
 +
 +	if (tp) {
 +		error = xfs_trans_commit(tp);
 +		if (error)
 +			goto error0;
 +	}
  
 -	xfs_buf_relse(bp);
 -	*dqpp = dqp;
 +	*O_dqpp = dqp;
  	return error;
  
 -err:
 -	trace_xfs_dqread_fail(dqp);
 +error1:
 +	if (tp)
 +		xfs_trans_cancel(tp);
 +error0:
  	xfs_qm_dqdestroy(dqp);
 -	*dqpp = NULL;
 +	*O_dqpp = NULL;
  	return error;
  }
  
* Unmerged path fs/xfs/libxfs/xfs_attr.c
* Unmerged path fs/xfs/libxfs/xfs_defer.c
* Unmerged path fs/xfs/xfs_attr.h
* Unmerged path fs/xfs/xfs_dquot.c
