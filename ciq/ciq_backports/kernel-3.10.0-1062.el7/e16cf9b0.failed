xfs: pass a struct xfs_bmbt_irec to xfs_bmbt_lookup_eq

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Christoph Hellwig <hch@lst.de>
commit e16cf9b03cee4d2797695d4ca691e854c7a24864
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/e16cf9b0.failed

Now that we've massaged the callers into the right form we can always
pass the actual extent record instead of the individual fields.

As an additional benefit the btree cursor will now be prepoulated with
the correct extent state instead of having to fix it up later.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Brian Foster <bfoster@redhat.com>
	Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
	Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
(cherry picked from commit e16cf9b03cee4d2797695d4ca691e854c7a24864)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/libxfs/xfs_bmap.c
diff --cc fs/xfs/libxfs/xfs_bmap.c
index 667acf472273,0033471a5e3a..000000000000
--- a/fs/xfs/libxfs/xfs_bmap.c
+++ b/fs/xfs/libxfs/xfs_bmap.c
@@@ -1715,9 -1729,7 +1709,13 @@@ xfs_bmap_add_extent_delay_real
  			rval = XFS_ILOG_DEXT;
  		else {
  			rval = 0;
++<<<<<<< HEAD
 +			error = xfs_bmbt_lookup_eq(bma->cur, LEFT.br_startoff,
 +					LEFT.br_startblock, LEFT.br_blockcount,
 +					&i);
++=======
+ 			error = xfs_bmbt_lookup_eq(bma->cur, &old, &i);
++>>>>>>> e16cf9b03cee (xfs: pass a struct xfs_bmbt_irec to xfs_bmbt_lookup_eq)
  			if (error)
  				goto done;
  			XFS_WANT_CORRUPTED_GOTO(mp, i == 1, done);
@@@ -1810,9 -1819,7 +1803,13 @@@
  			rval = XFS_ILOG_DEXT;
  		else {
  			rval = 0;
++<<<<<<< HEAD
 +			error = xfs_bmbt_lookup_eq(bma->cur, LEFT.br_startoff,
 +					LEFT.br_startblock, LEFT.br_blockcount,
 +					&i);
++=======
+ 			error = xfs_bmbt_lookup_eq(bma->cur, &old, &i);
++>>>>>>> e16cf9b03cee (xfs: pass a struct xfs_bmbt_irec to xfs_bmbt_lookup_eq)
  			if (error)
  				goto done;
  			XFS_WANT_CORRUPTED_GOTO(mp, i == 1, done);
@@@ -1893,9 -1892,7 +1887,13 @@@
  			rval = XFS_ILOG_DEXT;
  		else {
  			rval = 0;
++<<<<<<< HEAD
 +			error = xfs_bmbt_lookup_eq(bma->cur, RIGHT.br_startoff,
 +					RIGHT.br_startblock,
 +					RIGHT.br_blockcount, &i);
++=======
+ 			error = xfs_bmbt_lookup_eq(bma->cur, &old, &i);
++>>>>>>> e16cf9b03cee (xfs: pass a struct xfs_bmbt_irec to xfs_bmbt_lookup_eq)
  			if (error)
  				goto done;
  			XFS_WANT_CORRUPTED_GOTO(mp, i == 1, done);
@@@ -2341,14 -2325,11 +2330,13 @@@ xfs_bmap_add_extent_unwritten_real
  			rval = XFS_ILOG_DEXT;
  		else {
  			rval = 0;
- 			if ((error = xfs_bmbt_lookup_eq(cur, new->br_startoff,
- 					new->br_startblock, new->br_blockcount,
- 					&i)))
+ 			error = xfs_bmbt_lookup_eq(cur, new, &i);
+ 			if (error)
  				goto done;
  			XFS_WANT_CORRUPTED_GOTO(mp, i == 1, done);
 -			error = xfs_bmbt_update(cur, &PREV);
 +			error = xfs_bmbt_update(cur, PREV.br_startoff,
 +					PREV.br_startblock, PREV.br_blockcount,
 +					PREV.br_state);
  			if (error)
  				goto done;
  		}
@@@ -2510,17 -2473,13 +2490,15 @@@
  			if (error)
  				goto done;
  			XFS_WANT_CORRUPTED_GOTO(mp, i == 1, done);
 -			error = xfs_bmbt_update(cur, &PREV);
 +			error = xfs_bmbt_update(cur, PREV.br_startoff,
 +					PREV.br_startblock, PREV.br_blockcount,
 +					PREV.br_state);
  			if (error)
  				goto done;
- 			if ((error = xfs_bmbt_lookup_eq(cur, new->br_startoff,
- 					new->br_startblock, new->br_blockcount,
- 					&i)))
+ 			error = xfs_bmbt_lookup_eq(cur, new, &i);
+ 			if (error)
  				goto done;
  			XFS_WANT_CORRUPTED_GOTO(mp, i == 0, done);
- 			cur->bc_rec.b.br_state = new->br_state;
  			if ((error = xfs_btree_insert(cur, &i)))
  				goto done;
  			XFS_WANT_CORRUPTED_GOTO(mp, i == 1, done);
@@@ -4707,71 -5001,63 +4671,90 @@@ xfs_bmap_del_extent
  	del_endoff = del->br_startoff + del->br_blockcount;
  	got_endoff = got.br_startoff + got.br_blockcount;
  	ASSERT(got_endoff >= del_endoff);
 -	ASSERT(!isnullstartblock(got.br_startblock));
 +	delay = isnullstartblock(got.br_startblock);
 +	ASSERT(isnullstartblock(del->br_startblock) == delay);
 +	flags = 0;
  	qfield = 0;
  	error = 0;
 -
  	/*
 -	 * If it's the case where the directory code is running with no block
 -	 * reservation, and the deleted block is in the middle of its extent,
 -	 * and the resulting insert of an extent would cause transformation to
 -	 * btree format, then reject it.  The calling code will then swap blocks
 -	 * around instead.  We have to do this now, rather than waiting for the
 -	 * conversion to btree format, since the transaction will be dirty then.
 +	 * If deleting a real allocation, must free up the disk space.
  	 */
 -	if (tp->t_blk_res == 0 &&
 -	    XFS_IFORK_FORMAT(ip, whichfork) == XFS_DINODE_FMT_EXTENTS &&
 -	    XFS_IFORK_NEXTENTS(ip, whichfork) >=
 -			XFS_IFORK_MAXEXT(ip, whichfork) &&
 -	    del->br_startoff > got.br_startoff && del_endoff < got_endoff)
 -		return -ENOSPC;
 -
 -	flags = XFS_ILOG_CORE;
 -	if (whichfork == XFS_DATA_FORK && XFS_IS_REALTIME_INODE(ip)) {
 -		xfs_fsblock_t	bno;
 -		xfs_filblks_t	len;
 -
 -		ASSERT(do_mod(del->br_blockcount, mp->m_sb.sb_rextsize) == 0);
 -		ASSERT(do_mod(del->br_startblock, mp->m_sb.sb_rextsize) == 0);
 -		bno = del->br_startblock;
 -		len = del->br_blockcount;
 -		do_div(bno, mp->m_sb.sb_rextsize);
 -		do_div(len, mp->m_sb.sb_rextsize);
 -		error = xfs_rtfree_extent(tp, bno, (xfs_extlen_t)len);
 -		if (error)
 -			goto done;
 -		do_fx = 0;
 -		nblks = len * mp->m_sb.sb_rextsize;
 -		qfield = XFS_TRANS_DQ_RTBCOUNT;
 +	if (!delay) {
 +		flags = XFS_ILOG_CORE;
 +		/*
 +		 * Realtime allocation.  Free it and record di_nblocks update.
 +		 */
 +		if (whichfork == XFS_DATA_FORK && XFS_IS_REALTIME_INODE(ip)) {
 +			xfs_fsblock_t	bno;
 +			xfs_filblks_t	len;
 +
 +			ASSERT(do_mod(del->br_blockcount,
 +				      mp->m_sb.sb_rextsize) == 0);
 +			ASSERT(do_mod(del->br_startblock,
 +				      mp->m_sb.sb_rextsize) == 0);
 +			bno = del->br_startblock;
 +			len = del->br_blockcount;
 +			do_div(bno, mp->m_sb.sb_rextsize);
 +			do_div(len, mp->m_sb.sb_rextsize);
 +			error = xfs_rtfree_extent(tp, bno, (xfs_extlen_t)len);
 +			if (error)
 +				goto done;
 +			do_fx = 0;
 +			nblks = len * mp->m_sb.sb_rextsize;
 +			qfield = XFS_TRANS_DQ_RTBCOUNT;
 +		}
 +		/*
 +		 * Ordinary allocation.
 +		 */
 +		else {
 +			do_fx = 1;
 +			nblks = del->br_blockcount;
 +			qfield = XFS_TRANS_DQ_BCOUNT;
 +		}
 +		/*
 +		 * Set up del_endblock and cur for later.
 +		 */
 +		del_endblock = del->br_startblock + del->br_blockcount;
 +		if (cur) {
 +			if ((error = xfs_bmbt_lookup_eq(cur, got.br_startoff,
 +					got.br_startblock, got.br_blockcount,
 +					&i)))
 +				goto done;
 +			XFS_WANT_CORRUPTED_GOTO(mp, i == 1, done);
 +		}
 +		da_old = da_new = 0;
  	} else {
 -		do_fx = 1;
 -		nblks = del->br_blockcount;
 -		qfield = XFS_TRANS_DQ_BCOUNT;
 +		da_old = startblockval(got.br_startblock);
 +		da_new = 0;
 +		nblks = 0;
 +		do_fx = 0;
  	}
++<<<<<<< HEAD
 +	/*
 +	 * Set flag value to use in switch statement.
 +	 * Left-contig is 2, right-contig is 1.
 +	 */
 +	switch (((got.br_startoff == del->br_startoff) << 1) |
 +		(got_endoff == del_endoff)) {
 +	case 3:
++=======
+ 
+ 	del_endblock = del->br_startblock + del->br_blockcount;
+ 	if (cur) {
+ 		error = xfs_bmbt_lookup_eq(cur, &got, &i);
+ 		if (error)
+ 			goto done;
+ 		XFS_WANT_CORRUPTED_GOTO(mp, i == 1, done);
+ 	}
+ 
+ 	if (got.br_startoff == del->br_startoff)
+ 		state |= BMAP_LEFT_FILLING;
+ 	if (got_endoff == del_endoff)
+ 		state |= BMAP_RIGHT_FILLING;
+ 
+ 	switch (state & (BMAP_LEFT_FILLING | BMAP_RIGHT_FILLING)) {
+ 	case BMAP_LEFT_FILLING | BMAP_RIGHT_FILLING:
++>>>>>>> e16cf9b03cee (xfs: pass a struct xfs_bmbt_irec to xfs_bmbt_lookup_eq)
  		/*
  		 * Matches the whole extent.  Delete the entry.
  		 */
@@@ -4852,96 -5115,64 +4835,125 @@@
  		/*
  		 * Deleting the middle of the extent.
  		 */
 +		temp = del->br_startoff - got.br_startoff;
  		trace_xfs_bmap_pre_update(ip, *idx, state, _THIS_IP_);
 -
 -		old = got;
 -		got.br_blockcount = del->br_startoff - got.br_startoff;
 -		xfs_iext_update_extent(ifp, *idx, &got);
 -
 +		xfs_bmbt_set_blockcount(ep, temp);
  		new.br_startoff = del_endoff;
 -		new.br_blockcount = got_endoff - del_endoff;
 +		temp2 = got_endoff - del_endoff;
 +		new.br_blockcount = temp2;
  		new.br_state = got.br_state;
++<<<<<<< HEAD
 +		if (!delay) {
 +			new.br_startblock = del_endblock;
 +			flags |= XFS_ILOG_CORE;
 +			if (cur) {
 +				if ((error = xfs_bmbt_update(cur,
 +						got.br_startoff,
 +						got.br_startblock, temp,
 +						got.br_state)))
++=======
+ 		new.br_startblock = del_endblock;
+ 
+ 		flags |= XFS_ILOG_CORE;
+ 		if (cur) {
+ 			error = xfs_bmbt_update(cur, &got);
+ 			if (error)
+ 				goto done;
+ 			error = xfs_btree_increment(cur, 0, &i);
+ 			if (error)
+ 				goto done;
+ 			cur->bc_rec.b = new;
+ 			error = xfs_btree_insert(cur, &i);
+ 			if (error && error != -ENOSPC)
+ 				goto done;
+ 			/*
+ 			 * If get no-space back from btree insert, it tried a
+ 			 * split, and we have a zero block reservation.  Fix up
+ 			 * our state and return the error.
+ 			 */
+ 			if (error == -ENOSPC) {
+ 				/*
+ 				 * Reset the cursor, don't trust it after any
+ 				 * insert operation.
+ 				 */
+ 				error = xfs_bmbt_lookup_eq(cur, &got, &i);
+ 				if (error)
++>>>>>>> e16cf9b03cee (xfs: pass a struct xfs_bmbt_irec to xfs_bmbt_lookup_eq)
  					goto done;
 -				XFS_WANT_CORRUPTED_GOTO(mp, i == 1, done);
 -				/*
 -				 * Update the btree record back
 -				 * to the original value.
 -				 */
 -				error = xfs_bmbt_update(cur, &old);
 -				if (error)
 +				if ((error = xfs_btree_increment(cur, 0, &i)))
 +					goto done;
 +				cur->bc_rec.b = new;
 +				error = xfs_btree_insert(cur, &i);
 +				if (error && error != -ENOSPC)
  					goto done;
  				/*
 -				 * Reset the extent record back
 -				 * to the original value.
 +				 * If get no-space back from btree insert,
 +				 * it tried a split, and we have a zero
 +				 * block reservation.
 +				 * Fix up our state and return the error.
  				 */
 -				xfs_iext_update_extent(ifp, *idx, &old);
 -				flags = 0;
 -				error = -ENOSPC;
 -				goto done;
 -			}
 -			XFS_WANT_CORRUPTED_GOTO(mp, i == 1, done);
 -		} else
 -			flags |= xfs_ilog_fext(whichfork);
 -		XFS_IFORK_NEXT_SET(ip, whichfork,
 -			XFS_IFORK_NEXTENTS(ip, whichfork) + 1);
 +				if (error == -ENOSPC) {
 +					/*
 +					 * Reset the cursor, don't trust
 +					 * it after any insert operation.
 +					 */
 +					if ((error = xfs_bmbt_lookup_eq(cur,
 +							got.br_startoff,
 +							got.br_startblock,
 +							temp, &i)))
 +						goto done;
 +					XFS_WANT_CORRUPTED_GOTO(mp,
 +								i == 1, done);
 +					/*
 +					 * Update the btree record back
 +					 * to the original value.
 +					 */
 +					if ((error = xfs_bmbt_update(cur,
 +							got.br_startoff,
 +							got.br_startblock,
 +							got.br_blockcount,
 +							got.br_state)))
 +						goto done;
 +					/*
 +					 * Reset the extent record back
 +					 * to the original value.
 +					 */
 +					xfs_bmbt_set_blockcount(ep,
 +						got.br_blockcount);
 +					flags = 0;
 +					error = -ENOSPC;
 +					goto done;
 +				}
 +				XFS_WANT_CORRUPTED_GOTO(mp, i == 1, done);
 +			} else
 +				flags |= xfs_ilog_fext(whichfork);
 +			XFS_IFORK_NEXT_SET(ip, whichfork,
 +				XFS_IFORK_NEXTENTS(ip, whichfork) + 1);
 +		} else {
 +			xfs_filblks_t	stolen;
 +			ASSERT(whichfork == XFS_DATA_FORK);
 +
 +			/*
 +			 * Distribute the original indlen reservation across the
 +			 * two new extents. Steal blocks from the deleted extent
 +			 * if necessary. Stealing blocks simply fudges the
 +			 * fdblocks accounting in xfs_bunmapi().
 +			 */
 +			temp = xfs_bmap_worst_indlen(ip, got.br_blockcount);
 +			temp2 = xfs_bmap_worst_indlen(ip, new.br_blockcount);
 +			stolen = xfs_bmap_split_indlen(da_old, &temp, &temp2,
 +						       del->br_blockcount);
 +			da_new = temp + temp2 - stolen;
 +			del->br_blockcount -= stolen;
 +
 +			/*
 +			 * Set the reservation for each extent. Warn if either
 +			 * is zero as this can lead to delalloc problems.
 +			 */
 +			WARN_ON_ONCE(!temp || !temp2);
 +			xfs_bmbt_set_startblock(ep, nullstartblock((int)temp));
 +			new.br_startblock = nullstartblock((int)temp2);
 +		}
  		trace_xfs_bmap_post_update(ip, *idx, state, _THIS_IP_);
  		xfs_iext_insert(ip, *idx + 1, 1, &new, state);
  		++*idx;
@@@ -5469,8 -5676,7 +5481,12 @@@ xfs_bmse_merge
  	}
  
  	/* lookup and remove the extent to merge */
++<<<<<<< HEAD
 +	error = xfs_bmbt_lookup_eq(cur, got.br_startoff, got.br_startblock,
 +				   got.br_blockcount, &i);
++=======
+ 	error = xfs_bmbt_lookup_eq(cur, got, &i);
++>>>>>>> e16cf9b03cee (xfs: pass a struct xfs_bmbt_irec to xfs_bmbt_lookup_eq)
  	if (error)
  		return error;
  	XFS_WANT_CORRUPTED_RETURN(mp, i == 1);
@@@ -5481,8 -5687,7 +5497,12 @@@
  	XFS_WANT_CORRUPTED_RETURN(mp, i == 1);
  
  	/* lookup and update size of the previous extent */
++<<<<<<< HEAD
 +	error = xfs_bmbt_lookup_eq(cur, left.br_startoff, left.br_startblock,
 +				   left.br_blockcount, &i);
++=======
+ 	error = xfs_bmbt_lookup_eq(cur, left, &i);
++>>>>>>> e16cf9b03cee (xfs: pass a struct xfs_bmbt_irec to xfs_bmbt_lookup_eq)
  	if (error)
  		return error;
  	XFS_WANT_CORRUPTED_RETURN(mp, i == 1);
@@@ -5549,23 -5796,37 +5569,40 @@@ xfs_bmse_shift_one
  	 * Increment the extent index for the next iteration, update the start
  	 * offset of the in-core extent and update the btree if applicable.
  	 */
 -update_current_ext:
 +	(*current_ext)++;
 +	xfs_bmbt_set_startoff(gotp, startoff);
  	*logflags |= XFS_ILOG_CORE;
++<<<<<<< HEAD
 +	if (!cur) {
++=======
+ 
+ 	new = *got;
+ 	new.br_startoff = startoff;
+ 
+ 	if (cur) {
+ 		error = xfs_bmbt_lookup_eq(cur, got, &i);
+ 		if (error)
+ 			return error;
+ 		XFS_WANT_CORRUPTED_RETURN(mp, i == 1);
+ 
+ 		error = xfs_bmbt_update(cur, &new);
+ 		if (error)
+ 			return error;
+ 	} else {
++>>>>>>> e16cf9b03cee (xfs: pass a struct xfs_bmbt_irec to xfs_bmbt_lookup_eq)
  		*logflags |= XFS_ILOG_DEXT;
 +		return 0;
  	}
  
 -	xfs_iext_update_extent(ifp, *current_ext, &new);
 -
 -	if (direction == SHIFT_LEFT)
 -		(*current_ext)++;
 -	else
 -		(*current_ext)--;
 -
 -	/* update reverse mapping */
 -	error = xfs_rmap_unmap_extent(mp, dfops, ip, whichfork, got);
 +	error = xfs_bmbt_lookup_eq(cur, got.br_startoff, got.br_startblock,
 +				   got.br_blockcount, &i);
  	if (error)
  		return error;
 -	return xfs_rmap_map_extent(mp, dfops, ip, whichfork, &new);
 +	XFS_WANT_CORRUPTED_RETURN(mp, i == 1);
 +
 +	got.br_startoff = startoff;
 +	return xfs_bmbt_update(cur, got.br_startoff, got.br_startblock,
 +				got.br_blockcount, got.br_state);
  }
  
  /*
@@@ -5684,3 -5990,299 +5721,302 @@@ del_cursor
  
  	return error;
  }
++<<<<<<< HEAD
++=======
+ 
+ /*
+  * Splits an extent into two extents at split_fsb block such that it is
+  * the first block of the current_ext. @current_ext is a target extent
+  * to be split. @split_fsb is a block where the extents is split.
+  * If split_fsb lies in a hole or the first block of extents, just return 0.
+  */
+ STATIC int
+ xfs_bmap_split_extent_at(
+ 	struct xfs_trans	*tp,
+ 	struct xfs_inode	*ip,
+ 	xfs_fileoff_t		split_fsb,
+ 	xfs_fsblock_t		*firstfsb,
+ 	struct xfs_defer_ops	*dfops)
+ {
+ 	int				whichfork = XFS_DATA_FORK;
+ 	struct xfs_btree_cur		*cur = NULL;
+ 	struct xfs_bmbt_irec		got;
+ 	struct xfs_bmbt_irec		new; /* split extent */
+ 	struct xfs_mount		*mp = ip->i_mount;
+ 	struct xfs_ifork		*ifp;
+ 	xfs_fsblock_t			gotblkcnt; /* new block count for got */
+ 	xfs_extnum_t			current_ext;
+ 	int				error = 0;
+ 	int				logflags = 0;
+ 	int				i = 0;
+ 
+ 	if (unlikely(XFS_TEST_ERROR(
+ 	    (XFS_IFORK_FORMAT(ip, whichfork) != XFS_DINODE_FMT_EXTENTS &&
+ 	     XFS_IFORK_FORMAT(ip, whichfork) != XFS_DINODE_FMT_BTREE),
+ 	     mp, XFS_ERRTAG_BMAPIFORMAT))) {
+ 		XFS_ERROR_REPORT("xfs_bmap_split_extent_at",
+ 				 XFS_ERRLEVEL_LOW, mp);
+ 		return -EFSCORRUPTED;
+ 	}
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		return -EIO;
+ 
+ 	ifp = XFS_IFORK_PTR(ip, whichfork);
+ 	if (!(ifp->if_flags & XFS_IFEXTENTS)) {
+ 		/* Read in all the extents */
+ 		error = xfs_iread_extents(tp, ip, whichfork);
+ 		if (error)
+ 			return error;
+ 	}
+ 
+ 	/*
+ 	 * If there are not extents, or split_fsb lies in a hole we are done.
+ 	 */
+ 	if (!xfs_iext_lookup_extent(ip, ifp, split_fsb, &current_ext, &got) ||
+ 	    got.br_startoff >= split_fsb)
+ 		return 0;
+ 
+ 	gotblkcnt = split_fsb - got.br_startoff;
+ 	new.br_startoff = split_fsb;
+ 	new.br_startblock = got.br_startblock + gotblkcnt;
+ 	new.br_blockcount = got.br_blockcount - gotblkcnt;
+ 	new.br_state = got.br_state;
+ 
+ 	if (ifp->if_flags & XFS_IFBROOT) {
+ 		cur = xfs_bmbt_init_cursor(mp, tp, ip, whichfork);
+ 		cur->bc_private.b.firstblock = *firstfsb;
+ 		cur->bc_private.b.dfops = dfops;
+ 		cur->bc_private.b.flags = 0;
+ 		error = xfs_bmbt_lookup_eq(cur, &got, &i);
+ 		if (error)
+ 			goto del_cursor;
+ 		XFS_WANT_CORRUPTED_GOTO(mp, i == 1, del_cursor);
+ 	}
+ 
+ 	got.br_blockcount = gotblkcnt;
+ 	xfs_iext_update_extent(ifp, current_ext, &got);
+ 
+ 	logflags = XFS_ILOG_CORE;
+ 	if (cur) {
+ 		error = xfs_bmbt_update(cur, &got);
+ 		if (error)
+ 			goto del_cursor;
+ 	} else
+ 		logflags |= XFS_ILOG_DEXT;
+ 
+ 	/* Add new extent */
+ 	current_ext++;
+ 	xfs_iext_insert(ip, current_ext, 1, &new, 0);
+ 	XFS_IFORK_NEXT_SET(ip, whichfork,
+ 			   XFS_IFORK_NEXTENTS(ip, whichfork) + 1);
+ 
+ 	if (cur) {
+ 		error = xfs_bmbt_lookup_eq(cur, &new, &i);
+ 		if (error)
+ 			goto del_cursor;
+ 		XFS_WANT_CORRUPTED_GOTO(mp, i == 0, del_cursor);
+ 		error = xfs_btree_insert(cur, &i);
+ 		if (error)
+ 			goto del_cursor;
+ 		XFS_WANT_CORRUPTED_GOTO(mp, i == 1, del_cursor);
+ 	}
+ 
+ 	/*
+ 	 * Convert to a btree if necessary.
+ 	 */
+ 	if (xfs_bmap_needs_btree(ip, whichfork)) {
+ 		int tmp_logflags; /* partial log flag return val */
+ 
+ 		ASSERT(cur == NULL);
+ 		error = xfs_bmap_extents_to_btree(tp, ip, firstfsb, dfops,
+ 				&cur, 0, &tmp_logflags, whichfork);
+ 		logflags |= tmp_logflags;
+ 	}
+ 
+ del_cursor:
+ 	if (cur) {
+ 		cur->bc_private.b.allocated = 0;
+ 		xfs_btree_del_cursor(cur,
+ 				error ? XFS_BTREE_ERROR : XFS_BTREE_NOERROR);
+ 	}
+ 
+ 	if (logflags)
+ 		xfs_trans_log_inode(tp, ip, logflags);
+ 	return error;
+ }
+ 
+ int
+ xfs_bmap_split_extent(
+ 	struct xfs_inode        *ip,
+ 	xfs_fileoff_t           split_fsb)
+ {
+ 	struct xfs_mount        *mp = ip->i_mount;
+ 	struct xfs_trans        *tp;
+ 	struct xfs_defer_ops    dfops;
+ 	xfs_fsblock_t           firstfsb;
+ 	int                     error;
+ 
+ 	error = xfs_trans_alloc(mp, &M_RES(mp)->tr_write,
+ 			XFS_DIOSTRAT_SPACE_RES(mp, 0), 0, 0, &tp);
+ 	if (error)
+ 		return error;
+ 
+ 	xfs_ilock(ip, XFS_ILOCK_EXCL);
+ 	xfs_trans_ijoin(tp, ip, XFS_ILOCK_EXCL);
+ 
+ 	xfs_defer_init(&dfops, &firstfsb);
+ 
+ 	error = xfs_bmap_split_extent_at(tp, ip, split_fsb,
+ 			&firstfsb, &dfops);
+ 	if (error)
+ 		goto out;
+ 
+ 	error = xfs_defer_finish(&tp, &dfops);
+ 	if (error)
+ 		goto out;
+ 
+ 	return xfs_trans_commit(tp);
+ 
+ out:
+ 	xfs_defer_cancel(&dfops);
+ 	xfs_trans_cancel(tp);
+ 	return error;
+ }
+ 
+ /* Deferred mapping is only for real extents in the data fork. */
+ static bool
+ xfs_bmap_is_update_needed(
+ 	struct xfs_bmbt_irec	*bmap)
+ {
+ 	return  bmap->br_startblock != HOLESTARTBLOCK &&
+ 		bmap->br_startblock != DELAYSTARTBLOCK;
+ }
+ 
+ /* Record a bmap intent. */
+ static int
+ __xfs_bmap_add(
+ 	struct xfs_mount		*mp,
+ 	struct xfs_defer_ops		*dfops,
+ 	enum xfs_bmap_intent_type	type,
+ 	struct xfs_inode		*ip,
+ 	int				whichfork,
+ 	struct xfs_bmbt_irec		*bmap)
+ {
+ 	int				error;
+ 	struct xfs_bmap_intent		*bi;
+ 
+ 	trace_xfs_bmap_defer(mp,
+ 			XFS_FSB_TO_AGNO(mp, bmap->br_startblock),
+ 			type,
+ 			XFS_FSB_TO_AGBNO(mp, bmap->br_startblock),
+ 			ip->i_ino, whichfork,
+ 			bmap->br_startoff,
+ 			bmap->br_blockcount,
+ 			bmap->br_state);
+ 
+ 	bi = kmem_alloc(sizeof(struct xfs_bmap_intent), KM_SLEEP | KM_NOFS);
+ 	INIT_LIST_HEAD(&bi->bi_list);
+ 	bi->bi_type = type;
+ 	bi->bi_owner = ip;
+ 	bi->bi_whichfork = whichfork;
+ 	bi->bi_bmap = *bmap;
+ 
+ 	error = xfs_defer_ijoin(dfops, bi->bi_owner);
+ 	if (error) {
+ 		kmem_free(bi);
+ 		return error;
+ 	}
+ 
+ 	xfs_defer_add(dfops, XFS_DEFER_OPS_TYPE_BMAP, &bi->bi_list);
+ 	return 0;
+ }
+ 
+ /* Map an extent into a file. */
+ int
+ xfs_bmap_map_extent(
+ 	struct xfs_mount	*mp,
+ 	struct xfs_defer_ops	*dfops,
+ 	struct xfs_inode	*ip,
+ 	struct xfs_bmbt_irec	*PREV)
+ {
+ 	if (!xfs_bmap_is_update_needed(PREV))
+ 		return 0;
+ 
+ 	return __xfs_bmap_add(mp, dfops, XFS_BMAP_MAP, ip,
+ 			XFS_DATA_FORK, PREV);
+ }
+ 
+ /* Unmap an extent out of a file. */
+ int
+ xfs_bmap_unmap_extent(
+ 	struct xfs_mount	*mp,
+ 	struct xfs_defer_ops	*dfops,
+ 	struct xfs_inode	*ip,
+ 	struct xfs_bmbt_irec	*PREV)
+ {
+ 	if (!xfs_bmap_is_update_needed(PREV))
+ 		return 0;
+ 
+ 	return __xfs_bmap_add(mp, dfops, XFS_BMAP_UNMAP, ip,
+ 			XFS_DATA_FORK, PREV);
+ }
+ 
+ /*
+  * Process one of the deferred bmap operations.  We pass back the
+  * btree cursor to maintain our lock on the bmapbt between calls.
+  */
+ int
+ xfs_bmap_finish_one(
+ 	struct xfs_trans		*tp,
+ 	struct xfs_defer_ops		*dfops,
+ 	struct xfs_inode		*ip,
+ 	enum xfs_bmap_intent_type	type,
+ 	int				whichfork,
+ 	xfs_fileoff_t			startoff,
+ 	xfs_fsblock_t			startblock,
+ 	xfs_filblks_t			*blockcount,
+ 	xfs_exntst_t			state)
+ {
+ 	xfs_fsblock_t			firstfsb;
+ 	int				error = 0;
+ 
+ 	/*
+ 	 * firstfsb is tied to the transaction lifetime and is used to
+ 	 * ensure correct AG locking order and schedule work item
+ 	 * continuations.  XFS_BUI_MAX_FAST_EXTENTS (== 1) restricts us
+ 	 * to only making one bmap call per transaction, so it should
+ 	 * be safe to have it as a local variable here.
+ 	 */
+ 	firstfsb = NULLFSBLOCK;
+ 
+ 	trace_xfs_bmap_deferred(tp->t_mountp,
+ 			XFS_FSB_TO_AGNO(tp->t_mountp, startblock), type,
+ 			XFS_FSB_TO_AGBNO(tp->t_mountp, startblock),
+ 			ip->i_ino, whichfork, startoff, *blockcount, state);
+ 
+ 	if (WARN_ON_ONCE(whichfork != XFS_DATA_FORK))
+ 		return -EFSCORRUPTED;
+ 
+ 	if (XFS_TEST_ERROR(false, tp->t_mountp,
+ 			XFS_ERRTAG_BMAP_FINISH_ONE))
+ 		return -EIO;
+ 
+ 	switch (type) {
+ 	case XFS_BMAP_MAP:
+ 		error = xfs_bmapi_remap(tp, ip, startoff, *blockcount,
+ 				startblock, dfops);
+ 		*blockcount = 0;
+ 		break;
+ 	case XFS_BMAP_UNMAP:
+ 		error = __xfs_bunmapi(tp, ip, startoff, blockcount,
+ 				XFS_BMAPI_REMAP, 1, &firstfsb, dfops);
+ 		break;
+ 	default:
+ 		ASSERT(0);
+ 		error = -EFSCORRUPTED;
+ 	}
+ 
+ 	return error;
+ }
++>>>>>>> e16cf9b03cee (xfs: pass a struct xfs_bmbt_irec to xfs_bmbt_lookup_eq)
* Unmerged path fs/xfs/libxfs/xfs_bmap.c
