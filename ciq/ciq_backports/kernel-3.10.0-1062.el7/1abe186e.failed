IB/mlx5: Reset access mask when looping inside page fault handler

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Moni Shoua <monis@mellanox.com>
commit 1abe186ed8a6593069bc122da55fc684383fdc1c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/1abe186e.failed

If page-fault handler spans multiple MRs then the access mask needs to
be reset before each MR handling or otherwise write access will be
granted to mapped pages instead of read-only.

	Cc: <stable@vger.kernel.org> # 3.19
Fixes: 7bdf65d411c1 ("IB/mlx5: Handle page faults")
	Reported-by: Jerome Glisse <jglisse@redhat.com>
	Signed-off-by: Moni Shoua <monis@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 1abe186ed8a6593069bc122da55fc684383fdc1c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/odp.c
diff --cc drivers/infiniband/hw/mlx5/odp.c
index 10808ac0001c,0aa10ebda5d9..000000000000
--- a/drivers/infiniband/hw/mlx5/odp.c
+++ b/drivers/infiniband/hw/mlx5/odp.c
@@@ -495,18 -574,23 +495,27 @@@ void mlx5_ib_free_implicit_mr(struct ml
  	wait_event(imr->q_leaf_free, !atomic_read(&imr->num_leaf_free));
  }
  
 -#define MLX5_PF_FLAGS_PREFETCH  BIT(0)
 -#define MLX5_PF_FLAGS_DOWNGRADE BIT(1)
  static int pagefault_mr(struct mlx5_ib_dev *dev, struct mlx5_ib_mr *mr,
 -			u64 io_virt, size_t bcnt, u32 *bytes_mapped,
 -			u32 flags)
 +			u64 io_virt, size_t bcnt, u32 *bytes_mapped)
  {
++<<<<<<< HEAD
 +	u64 access_mask = ODP_READ_ALLOWED_BIT;
 +	int npages = 0, page_shift, np;
++=======
+ 	int npages = 0, current_seq, page_shift, ret, np;
+ 	bool implicit = false;
+ 	struct ib_umem_odp *odp_mr = to_ib_umem_odp(mr->umem);
+ 	bool downgrade = flags & MLX5_PF_FLAGS_DOWNGRADE;
+ 	bool prefetch = flags & MLX5_PF_FLAGS_PREFETCH;
+ 	u64 access_mask;
++>>>>>>> 1abe186ed8a6 (IB/mlx5: Reset access mask when looping inside page fault handler)
  	u64 start_idx, page_mask;
  	struct ib_umem_odp *odp;
 +	int current_seq;
  	size_t size;
 +	int ret;
  
 -	if (!odp_mr->page_list) {
 +	if (!mr->umem->odp_data->page_list) {
  		odp = implicit_mr_get_data(mr, io_virt, bcnt);
  
  		if (IS_ERR(odp))
@@@ -523,8 -607,17 +532,9 @@@ next_mr
  	page_shift = mr->umem->page_shift;
  	page_mask = ~(BIT(page_shift) - 1);
  	start_idx = (io_virt - (mr->mmkey.iova & page_mask)) >> page_shift;
+ 	access_mask = ODP_READ_ALLOWED_BIT;
  
 -	if (prefetch && !downgrade && !mr->umem->writable) {
 -		/* prefetch with write-access must
 -		 * be supported by the MR
 -		 */
 -		ret = -EINVAL;
 -		goto out;
 -	}
 -
 -	if (mr->umem->writable && !downgrade)
 +	if (mr->umem->writable)
  		access_mask |= ODP_WRITE_ALLOWED_BIT;
  
  	current_seq = READ_ONCE(odp->notifiers_seq);
* Unmerged path drivers/infiniband/hw/mlx5/odp.c
