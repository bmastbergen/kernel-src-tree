mm/mincore.c: make mincore() more conservative

jira LE-1907
cve CVE-2019-5489
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
Rebuild_CHGLOG: - [mm] mincore.c: make mincore() more conservative (Rafael Aquini) [1664199] {CVE-2019-5489}
Rebuild_FUZZ: 96.63%
commit-author Jiri Kosina <jkosina@suse.cz>
commit 134fca9063ad4851de767d1768180e5dede9a881
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/134fca90.failed

The semantics of what mincore() considers to be resident is not
completely clear, but Linux has always (since 2.3.52, which is when
mincore() was initially done) treated it as "page is available in page
cache".

That's potentially a problem, as that [in]directly exposes
meta-information about pagecache / memory mapping state even about
memory not strictly belonging to the process executing the syscall,
opening possibilities for sidechannel attacks.

Change the semantics of mincore() so that it only reveals pagecache
information for non-anonymous mappings that belog to files that the
calling process could (if it tried to) successfully open for writing;
otherwise we'd be including shared non-exclusive mappings, which

 - is the sidechannel

 - is not the usecase for mincore(), as that's primarily used for data,
   not (shared) text

[jkosina@suse.cz: v2]
  Link: http://lkml.kernel.org/r/20190312141708.6652-2-vbabka@suse.cz
[mhocko@suse.com: restructure can_do_mincore() conditions]
Link: http://lkml.kernel.org/r/nycvar.YFH.7.76.1903062342020.19912@cbobk.fhfr.pm
	Signed-off-by: Jiri Kosina <jkosina@suse.cz>
	Signed-off-by: Vlastimil Babka <vbabka@suse.cz>
	Acked-by: Josh Snyder <joshs@netflix.com>
	Acked-by: Michal Hocko <mhocko@suse.com>
Originally-by: Linus Torvalds <torvalds@linux-foundation.org>
Originally-by: Dominique Martinet <asmadeus@codewreck.org>
	Cc: Andy Lutomirski <luto@amacapital.net>
	Cc: Dave Chinner <david@fromorbit.com>
	Cc: Kevin Easton <kevin@guarana.org>
	Cc: Matthew Wilcox <willy@infradead.org>
	Cc: Cyril Hrubis <chrubis@suse.cz>
	Cc: Tejun Heo <tj@kernel.org>
	Cc: Kirill A. Shutemov <kirill@shutemov.name>
	Cc: Daniel Gruss <daniel@gruss.cc>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 134fca9063ad4851de767d1768180e5dede9a881)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/mincore.c
diff --cc mm/mincore.c
index f0d1f8ea77da,c3f058bd0faf..000000000000
--- a/mm/mincore.c
+++ b/mm/mincore.c
@@@ -155,72 -161,30 +155,88 @@@ static void mincore_pte_range(struct vm
  			}
  		}
  		vec++;
 -	}
 +	} while (ptep++, addr = next, addr != end);
  	pte_unmap_unlock(ptep - 1, ptl);
 -out:
 -	walk->private += nr;
 -	cond_resched();
 -	return 0;
 +}
 +
 +static void mincore_pmd_range(struct vm_area_struct *vma, pud_t *pud,
 +			unsigned long addr, unsigned long end,
 +			unsigned char *vec)
 +{
 +	unsigned long next;
 +	pmd_t *pmd;
 +
 +	pmd = pmd_offset(pud, addr);
 +	do {
 +		next = pmd_addr_end(addr, end);
 +		if (pmd_trans_huge(*pmd) || pmd_devmap(*pmd)) {
 +			if (mincore_huge_pmd(vma, pmd, addr, next, vec)) {
 +				vec += (next - addr) >> PAGE_SHIFT;
 +				continue;
 +			}
 +			/* fall through */
 +		}
 +		if (pmd_devmap(*pmd) ||
 +				pmd_none_or_trans_huge_or_clear_bad(pmd))
 +			mincore_unmapped_range(vma, addr, next, vec);
 +		else
 +			mincore_pte_range(vma, pmd, addr, next, vec);
 +		vec += (next - addr) >> PAGE_SHIFT;
 +	} while (pmd++, addr = next, addr != end);
 +}
 +
 +static void mincore_pud_range(struct vm_area_struct *vma, pgd_t *pgd,
 +			unsigned long addr, unsigned long end,
 +			unsigned char *vec)
 +{
 +	unsigned long next;
 +	pud_t *pud;
 +
 +	pud = pud_offset(pgd, addr);
 +	do {
 +		next = pud_addr_end(addr, end);
 +		if (pud_none_or_clear_bad(pud))
 +			mincore_unmapped_range(vma, addr, next, vec);
 +		else
 +			mincore_pmd_range(vma, pud, addr, next, vec);
 +		vec += (next - addr) >> PAGE_SHIFT;
 +	} while (pud++, addr = next, addr != end);
 +}
 +
 +static void mincore_page_range(struct vm_area_struct *vma,
 +			unsigned long addr, unsigned long end,
 +			unsigned char *vec)
 +{
 +	unsigned long next;
 +	pgd_t *pgd;
 +
 +	pgd = pgd_offset(vma->vm_mm, addr);
 +	do {
 +		next = pgd_addr_end(addr, end);
 +		if (pgd_none_or_clear_bad(pgd))
 +			mincore_unmapped_range(vma, addr, next, vec);
 +		else
 +			mincore_pud_range(vma, pgd, addr, next, vec);
 +		vec += (next - addr) >> PAGE_SHIFT;
 +	} while (pgd++, addr = next, addr != end);
  }
  
+ static inline bool can_do_mincore(struct vm_area_struct *vma)
+ {
+ 	if (vma_is_anonymous(vma))
+ 		return true;
+ 	if (!vma->vm_file)
+ 		return false;
+ 	/*
+ 	 * Reveal pagecache information only for non-anonymous mappings that
+ 	 * correspond to the files the calling process could (if tried) open
+ 	 * for writing; otherwise we'd be including shared non-exclusive
+ 	 * mappings, which opens a side channel.
+ 	 */
+ 	return inode_owner_or_capable(file_inode(vma->vm_file)) ||
+ 		inode_permission(file_inode(vma->vm_file), MAY_WRITE) == 0;
+ }
+ 
  /*
   * Do a chunk of "sys_mincore()". We've already checked
   * all the arguments, we hold the mmap semaphore: we should
@@@ -234,21 -205,16 +250,34 @@@ static long do_mincore(unsigned long ad
  	vma = find_vma(current->mm, addr);
  	if (!vma || addr < vma->vm_start)
  		return -ENOMEM;
++<<<<<<< HEAD
 +
 +	end = min(vma->vm_end, addr + (pages << PAGE_SHIFT));
 +
 +	if (is_vm_hugetlb_page(vma)) {
 +		mincore_hugetlb_page_range(vma, addr, end, vec);
 +		return (end - addr) >> PAGE_SHIFT;
 +	}
 +
 +	end = pmd_addr_end(addr, end);
 +
 +	if (is_vm_hugetlb_page(vma))
 +		mincore_hugetlb_page_range(vma, addr, end, vec);
 +	else
 +		mincore_page_range(vma, addr, end, vec);
 +
++=======
+ 	end = min(vma->vm_end, addr + (pages << PAGE_SHIFT));
+ 	if (!can_do_mincore(vma)) {
+ 		unsigned long pages = DIV_ROUND_UP(end - addr, PAGE_SIZE);
+ 		memset(vec, 1, pages);
+ 		return pages;
+ 	}
+ 	mincore_walk.mm = vma->vm_mm;
+ 	err = walk_page_range(addr, end, &mincore_walk);
+ 	if (err < 0)
+ 		return err;
++>>>>>>> 134fca9063ad (mm/mincore.c: make mincore() more conservative)
  	return (end - addr) >> PAGE_SHIFT;
  }
  
* Unmerged path mm/mincore.c
