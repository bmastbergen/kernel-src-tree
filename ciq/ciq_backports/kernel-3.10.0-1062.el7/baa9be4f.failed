sched/fair: Fix throttle_list starvation with low CFS quota

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Phil Auld <pauld@redhat.com>
commit baa9be4ffb55876923dc9716abc0a448e510ba30
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/baa9be4f.failed

With a very low cpu.cfs_quota_us setting, such as the minimum of 1000,
distribute_cfs_runtime may not empty the throttled_list before it runs
out of runtime to distribute. In that case, due to the change from
c06f04c7048 to put throttled entries at the head of the list, later entries
on the list will starve.  Essentially, the same X processes will get pulled
off the list, given CPU time and then, when expired, get put back on the
head of the list where distribute_cfs_runtime will give runtime to the same
set of processes leaving the rest.

Fix the issue by setting a bit in struct cfs_bandwidth when
distribute_cfs_runtime is running, so that the code in throttle_cfs_rq can
decide to put the throttled entry on the tail or the head of the list.  The
bit is set/cleared by the callers of distribute_cfs_runtime while they hold
cfs_bandwidth->lock.

This is easy to reproduce with a handful of CPU consumers. I use 'crash' on
the live system. In some cases you can simply look at the throttled list and
see the later entries are not changing:

  crash> list cfs_rq.throttled_list -H 0xffff90b54f6ade40 -s cfs_rq.runtime_remaining | paste - - | awk '{print $1"  "$4}' | pr -t -n3
    1     ffff90b56cb2d200  -976050
    2     ffff90b56cb2cc00  -484925
    3     ffff90b56cb2bc00  -658814
    4     ffff90b56cb2ba00  -275365
    5     ffff90b166a45600  -135138
    6     ffff90b56cb2da00  -282505
    7     ffff90b56cb2e000  -148065
    8     ffff90b56cb2fa00  -872591
    9     ffff90b56cb2c000  -84687
   10     ffff90b56cb2f000  -87237
   11     ffff90b166a40a00  -164582

  crash> list cfs_rq.throttled_list -H 0xffff90b54f6ade40 -s cfs_rq.runtime_remaining | paste - - | awk '{print $1"  "$4}' | pr -t -n3
    1     ffff90b56cb2d200  -994147
    2     ffff90b56cb2cc00  -306051
    3     ffff90b56cb2bc00  -961321
    4     ffff90b56cb2ba00  -24490
    5     ffff90b166a45600  -135138
    6     ffff90b56cb2da00  -282505
    7     ffff90b56cb2e000  -148065
    8     ffff90b56cb2fa00  -872591
    9     ffff90b56cb2c000  -84687
   10     ffff90b56cb2f000  -87237
   11     ffff90b166a40a00  -164582

Sometimes it is easier to see by finding a process getting starved and looking
at the sched_info:

  crash> task ffff8eb765994500 sched_info
  PID: 7800   TASK: ffff8eb765994500  CPU: 16  COMMAND: "cputest"
    sched_info = {
      pcount = 8,
      run_delay = 697094208,
      last_arrival = 240260125039,
      last_queued = 240260327513
    },
  crash> task ffff8eb765994500 sched_info
  PID: 7800   TASK: ffff8eb765994500  CPU: 16  COMMAND: "cputest"
    sched_info = {
      pcount = 8,
      run_delay = 697094208,
      last_arrival = 240260125039,
      last_queued = 240260327513
    },

	Signed-off-by: Phil Auld <pauld@redhat.com>
	Reviewed-by: Ben Segall <bsegall@google.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: stable@vger.kernel.org
Fixes: c06f04c70489 ("sched: Fix potential near-infinite distribute_cfs_runtime() loop")
Link: http://lkml.kernel.org/r/20181008143639.GA4019@pauld.bos.csb
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit baa9be4ffb55876923dc9716abc0a448e510ba30)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/fair.c
#	kernel/sched/sched.h
diff --cc kernel/sched/fair.c
index c019c17cc2ca,f88e00705b55..000000000000
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@@ -3423,13 -4472,25 +3423,29 @@@ static void throttle_cfs_rq(struct cfs_
  	cfs_rq->throttled = 1;
  	cfs_rq->throttled_clock = rq_clock(rq);
  	raw_spin_lock(&cfs_b->lock);
 -	empty = list_empty(&cfs_b->throttled_cfs_rq);
 -
  	/*
  	 * Add to the _head_ of the list, so that an already-started
- 	 * distribute_cfs_runtime will not see us
+ 	 * distribute_cfs_runtime will not see us. If disribute_cfs_runtime is
+ 	 * not running add to the tail so that later runqueues don't get starved.
  	 */
++<<<<<<< HEAD
 +	list_add_rcu(&cfs_rq->throttled_list, &cfs_b->throttled_cfs_rq);
 +	if (!cfs_b->timer_active)
 +		__start_cfs_bandwidth(cfs_b, false);
++=======
+ 	if (cfs_b->distribute_running)
+ 		list_add_rcu(&cfs_rq->throttled_list, &cfs_b->throttled_cfs_rq);
+ 	else
+ 		list_add_tail_rcu(&cfs_rq->throttled_list, &cfs_b->throttled_cfs_rq);
+ 
+ 	/*
+ 	 * If we're the first throttled task, make sure the bandwidth
+ 	 * timer is running.
+ 	 */
+ 	if (empty)
+ 		start_cfs_bandwidth(cfs_b);
+ 
++>>>>>>> baa9be4ffb55 (sched/fair: Fix throttle_list starvation with low CFS quota)
  	raw_spin_unlock(&cfs_b->lock);
  }
  
diff --cc kernel/sched/sched.h
index 7969a5cf1ec6,9683f458aec7..000000000000
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@@ -227,19 -328,26 +227,28 @@@ extern struct list_head task_groups
  
  struct cfs_bandwidth {
  #ifdef CONFIG_CFS_BANDWIDTH
 -	raw_spinlock_t		lock;
 -	ktime_t			period;
 -	u64			quota;
 -	u64			runtime;
 -	s64			hierarchical_quota;
 -	u64			runtime_expires;
 -	int			expires_seq;
 -
 -	short			idle;
 -	short			period_active;
 -	struct hrtimer		period_timer;
 -	struct hrtimer		slack_timer;
 -	struct list_head	throttled_cfs_rq;
 -
 +	raw_spinlock_t lock;
 +	ktime_t period;
 +	u64 quota, runtime;
 +	s64 hierarchal_quota;
 +	u64 runtime_expires;
 +
 +	int idle, timer_active;
 +	struct hrtimer period_timer, slack_timer;
 +	struct list_head throttled_cfs_rq;
 +
++<<<<<<< HEAD
 +	/* statistics */
 +	int nr_periods, nr_throttled;
 +	u64 throttled_time;
++=======
+ 	/* Statistics: */
+ 	int			nr_periods;
+ 	int			nr_throttled;
+ 	u64			throttled_time;
+ 
+ 	bool                    distribute_running;
++>>>>>>> baa9be4ffb55 (sched/fair: Fix throttle_list starvation with low CFS quota)
  #endif
  };
  
* Unmerged path kernel/sched/fair.c
* Unmerged path kernel/sched/sched.h
