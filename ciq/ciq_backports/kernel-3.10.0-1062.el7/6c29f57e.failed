IB/mlx5: Device memory mr registration support

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Ariel Levkovich <lariel@mellanox.com>
commit 6c29f57ea4751c4887627521027cd72aba831a97
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/6c29f57e.failed

Adding mlx5_ib driver implementation for reg_dm_mr callback
which allows registering device memory (DM) as an MR for
local and remote access.

	Signed-off-by: Ariel Levkovich <lariel@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 6c29f57ea4751c4887627521027cd72aba831a97)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/main.c
#	drivers/infiniband/hw/mlx5/mlx5_ib.h
diff --cc drivers/infiniband/hw/mlx5/main.c
index 4f262a79ae0d,4ead79513e3a..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -4840,6 -5223,12 +4840,15 @@@ static int mlx5_ib_stage_caps_init(stru
  			(1ull << IB_USER_VERBS_CMD_CLOSE_XRCD);
  	}
  
++<<<<<<< HEAD
++=======
+ 	if (MLX5_CAP_DEV_MEM(mdev, memic)) {
+ 		dev->ib_dev.alloc_dm = mlx5_ib_alloc_dm;
+ 		dev->ib_dev.dealloc_dm = mlx5_ib_dealloc_dm;
+ 		dev->ib_dev.reg_dm_mr = mlx5_ib_reg_dm_mr;
+ 	}
+ 
++>>>>>>> 6c29f57ea475 (IB/mlx5: Device memory mr registration support)
  	dev->ib_dev.create_flow	= mlx5_ib_create_flow;
  	dev->ib_dev.destroy_flow = mlx5_ib_destroy_flow;
  	dev->ib_dev.uverbs_ex_cmd_mask |=
diff --cc drivers/infiniband/hw/mlx5/mlx5_ib.h
index 7653bfad9f25,49a1aa0ff429..000000000000
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@@ -521,8 -533,19 +521,14 @@@ enum mlx5_ib_mtt_access_flags 
  	MLX5_IB_MTT_WRITE = (1 << 1),
  };
  
 -struct mlx5_ib_dm {
 -	struct ib_dm		ibdm;
 -	phys_addr_t		dev_addr;
 -};
 -
  #define MLX5_IB_MTT_PRESENT (MLX5_IB_MTT_READ | MLX5_IB_MTT_WRITE)
  
+ #define MLX5_IB_DM_ALLOWED_ACCESS (IB_ACCESS_LOCAL_WRITE   |\
+ 				   IB_ACCESS_REMOTE_WRITE  |\
+ 				   IB_ACCESS_REMOTE_READ   |\
+ 				   IB_ACCESS_REMOTE_ATOMIC |\
+ 				   IB_ZERO_BASED)
+ 
  struct mlx5_ib_mr {
  	struct ib_mr		ibmr;
  	void			*descs;
@@@ -1025,7 -1076,14 +1031,18 @@@ struct ib_rwq_ind_table *mlx5_ib_create
  						      struct ib_udata *udata);
  int mlx5_ib_destroy_rwq_ind_table(struct ib_rwq_ind_table *wq_ind_table);
  bool mlx5_ib_dc_atomic_is_supported(struct mlx5_ib_dev *dev);
- 
++<<<<<<< HEAD
++
++=======
+ struct ib_dm *mlx5_ib_alloc_dm(struct ib_device *ibdev,
+ 			       struct ib_ucontext *context,
+ 			       struct ib_dm_alloc_attr *attr,
+ 			       struct uverbs_attr_bundle *attrs);
+ int mlx5_ib_dealloc_dm(struct ib_dm *ibdm);
+ struct ib_mr *mlx5_ib_reg_dm_mr(struct ib_pd *pd, struct ib_dm *dm,
+ 				struct ib_dm_mr_attr *attr,
+ 				struct uverbs_attr_bundle *attrs);
++>>>>>>> 6c29f57ea475 (IB/mlx5: Device memory mr registration support)
  
  #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
  void mlx5_ib_internal_fill_odp_caps(struct mlx5_ib_dev *dev);
* Unmerged path drivers/infiniband/hw/mlx5/main.c
* Unmerged path drivers/infiniband/hw/mlx5/mlx5_ib.h
diff --git a/drivers/infiniband/hw/mlx5/mr.c b/drivers/infiniband/hw/mlx5/mr.c
index e6f0b2f89fc3..e9cfc454b24f 100644
--- a/drivers/infiniband/hw/mlx5/mr.c
+++ b/drivers/infiniband/hw/mlx5/mr.c
@@ -1230,6 +1230,80 @@ static void set_mr_fileds(struct mlx5_ib_dev *dev, struct mlx5_ib_mr *mr,
 	mr->access_flags = access_flags;
 }
 
+static struct ib_mr *mlx5_ib_get_memic_mr(struct ib_pd *pd, u64 memic_addr,
+					  u64 length, int acc)
+{
+	struct mlx5_ib_dev *dev = to_mdev(pd->device);
+	int inlen = MLX5_ST_SZ_BYTES(create_mkey_in);
+	struct mlx5_core_dev *mdev = dev->mdev;
+	struct mlx5_ib_mr *mr;
+	void *mkc;
+	u32 *in;
+	int err;
+
+	mr = kzalloc(sizeof(*mr), GFP_KERNEL);
+	if (!mr)
+		return ERR_PTR(-ENOMEM);
+
+	in = kzalloc(inlen, GFP_KERNEL);
+	if (!in) {
+		err = -ENOMEM;
+		goto err_free;
+	}
+
+	mkc = MLX5_ADDR_OF(create_mkey_in, in, memory_key_mkey_entry);
+
+	MLX5_SET(mkc, mkc, access_mode_1_0, MLX5_MKC_ACCESS_MODE_MEMIC & 0x3);
+	MLX5_SET(mkc, mkc, access_mode_4_2,
+		 (MLX5_MKC_ACCESS_MODE_MEMIC >> 2) & 0x7);
+	MLX5_SET(mkc, mkc, a, !!(acc & IB_ACCESS_REMOTE_ATOMIC));
+	MLX5_SET(mkc, mkc, rw, !!(acc & IB_ACCESS_REMOTE_WRITE));
+	MLX5_SET(mkc, mkc, rr, !!(acc & IB_ACCESS_REMOTE_READ));
+	MLX5_SET(mkc, mkc, lw, !!(acc & IB_ACCESS_LOCAL_WRITE));
+	MLX5_SET(mkc, mkc, lr, 1);
+
+	MLX5_SET64(mkc, mkc, len, length);
+	MLX5_SET(mkc, mkc, pd, to_mpd(pd)->pdn);
+	MLX5_SET(mkc, mkc, qpn, 0xffffff);
+	MLX5_SET64(mkc, mkc, start_addr,
+		   memic_addr - pci_resource_start(dev->mdev->pdev, 0));
+
+	err = mlx5_core_create_mkey(mdev, &mr->mmkey, in, inlen);
+	if (err)
+		goto err_in;
+
+	kfree(in);
+
+	mr->umem = NULL;
+	set_mr_fileds(dev, mr, 0, length, acc);
+
+	return &mr->ibmr;
+
+err_in:
+	kfree(in);
+
+err_free:
+	kfree(mr);
+
+	return ERR_PTR(err);
+}
+
+struct ib_mr *mlx5_ib_reg_dm_mr(struct ib_pd *pd, struct ib_dm *dm,
+				struct ib_dm_mr_attr *attr,
+				struct uverbs_attr_bundle *attrs)
+{
+	struct mlx5_ib_dm *mdm = to_mdm(dm);
+	u64 memic_addr;
+
+	if (attr->access_flags & ~MLX5_IB_DM_ALLOWED_ACCESS)
+		return ERR_PTR(-EINVAL);
+
+	memic_addr = mdm->dev_addr + attr->offset;
+
+	return mlx5_ib_get_memic_mr(pd, memic_addr, attr->length,
+				    attr->access_flags);
+}
+
 struct ib_mr *mlx5_ib_reg_user_mr(struct ib_pd *pd, u64 start, u64 length,
 				  u64 virt_addr, int access_flags,
 				  struct ib_udata *udata)
