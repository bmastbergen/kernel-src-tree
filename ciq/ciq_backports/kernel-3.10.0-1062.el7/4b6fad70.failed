powerpc/mm/iommu, vfio/spapr: Put pages on VFIO container shutdown

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Alexey Kardashevskiy <aik@ozlabs.ru>
commit 4b6fad7097f883335b6d9627c883cb7f276d94c9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/4b6fad70.failed

At the moment the userspace tool is expected to request pinning of
the entire guest RAM when VFIO IOMMU SPAPR v2 driver is present.
When the userspace process finishes, all the pinned pages need to
be put; this is done as a part of the userspace memory context (MM)
destruction which happens on the very last mmdrop().

This approach has a problem that a MM of the userspace process
may live longer than the userspace process itself as kernel threads
use userspace process MMs which was runnning on a CPU where
the kernel thread was scheduled to. If this happened, the MM remains
referenced until this exact kernel thread wakes up again
and releases the very last reference to the MM, on an idle system this
can take even hours.

This moves preregistered regions tracking from MM to VFIO; insteads of
using mm_iommu_table_group_mem_t::used, tce_container::prereg_list is
added so each container releases regions which it has pre-registered.

This changes the userspace interface to return EBUSY if a memory
region is already registered in a container. However it should not
have any practical effect as the only userspace tool available now
does register memory region once per container anyway.

As tce_iommu_register_pages/tce_iommu_unregister_pages are called
under container->lock, this does not need additional locking.

	Signed-off-by: Alexey Kardashevskiy <aik@ozlabs.ru>
	Reviewed-by: Nicholas Piggin <npiggin@gmail.com>
	Acked-by: Alex Williamson <alex.williamson@redhat.com>
	Reviewed-by: David Gibson <david@gibson.dropbear.id.au>
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
(cherry picked from commit 4b6fad7097f883335b6d9627c883cb7f276d94c9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/mm/mmu_context_hash64.c
#	arch/powerpc/mm/mmu_context_iommu.c
#	drivers/vfio/vfio_iommu_spapr_tce.c
diff --cc arch/powerpc/mm/mmu_context_hash64.c
index 9ca6fe16cb29,73bf6e14c3aa..000000000000
--- a/arch/powerpc/mm/mmu_context_hash64.c
+++ b/arch/powerpc/mm/mmu_context_hash64.c
@@@ -134,10 -159,8 +134,12 @@@ static inline void destroy_pagetable_pa
  void destroy_context(struct mm_struct *mm)
  {
  #ifdef CONFIG_SPAPR_TCE_IOMMU
++<<<<<<< HEAD:arch/powerpc/mm/mmu_context_hash64.c
 +	mm_iommu_cleanup(&mm->context);
++=======
+ 	WARN_ON_ONCE(!list_empty(&mm->context.iommu_group_mem_list));
++>>>>>>> 4b6fad7097f8 (powerpc/mm/iommu, vfio/spapr: Put pages on VFIO container shutdown):arch/powerpc/mm/mmu_context_book3s64.c
  #endif
- 
  #ifdef CONFIG_PPC_ICSWX
  	drop_cop(mm->context.acop, mm);
  	kfree(mm->context.cop_lockp);
diff --cc arch/powerpc/mm/mmu_context_iommu.c
index f68c12901fa8,104bad029ce9..000000000000
--- a/arch/powerpc/mm/mmu_context_iommu.c
+++ b/arch/powerpc/mm/mmu_context_iommu.c
@@@ -373,19 -361,7 +373,22 @@@ void mm_iommu_mapped_dec(struct mm_iomm
  }
  EXPORT_SYMBOL_GPL(mm_iommu_mapped_dec);
  
 -void mm_iommu_init(struct mm_struct *mm)
 +void mm_iommu_init(mm_context_t *ctx)
  {
 -	INIT_LIST_HEAD_RCU(&mm->context.iommu_group_mem_list);
 +	struct mm_struct *mm = container_of(ctx, struct mm_struct, context);
 +	INIT_LIST_HEAD_RCU(&mm->iommu_group_mem_list);
 +}
++<<<<<<< HEAD
 +
 +void mm_iommu_cleanup(mm_context_t *ctx)
 +{
 +	struct mm_struct *mm = container_of(ctx, struct mm_struct, context);
 +	struct mm_iommu_table_group_mem_t *mem, *tmp;
 +
 +	list_for_each_entry_safe(mem, tmp, &mm->iommu_group_mem_list, next) {
 +		list_del_rcu(&mem->next);
 +		mm_iommu_do_free(mem);
 +	}
  }
++=======
++>>>>>>> 4b6fad7097f8 (powerpc/mm/iommu, vfio/spapr: Put pages on VFIO container shutdown)
diff --cc drivers/vfio/vfio_iommu_spapr_tce.c
index ea54ab856f66,c8823578a1b2..000000000000
--- a/drivers/vfio/vfio_iommu_spapr_tce.c
+++ b/drivers/vfio/vfio_iommu_spapr_tce.c
@@@ -99,10 -108,41 +108,43 @@@ struct tce_container 
  	bool v2;
  	bool def_window_pending;
  	unsigned long locked_pages;
 -	struct mm_struct *mm;
  	struct iommu_table *tables[IOMMU_TABLE_GROUP_MAX_TABLES];
  	struct list_head group_list;
+ 	struct list_head prereg_list;
  };
  
++<<<<<<< HEAD
++=======
+ static long tce_iommu_mm_set(struct tce_container *container)
+ {
+ 	if (container->mm) {
+ 		if (container->mm == current->mm)
+ 			return 0;
+ 		return -EPERM;
+ 	}
+ 	BUG_ON(!current->mm);
+ 	container->mm = current->mm;
+ 	atomic_inc(&container->mm->mm_count);
+ 
+ 	return 0;
+ }
+ 
+ static long tce_iommu_prereg_free(struct tce_container *container,
+ 		struct tce_iommu_prereg *tcemem)
+ {
+ 	long ret;
+ 
+ 	ret = mm_iommu_put(container->mm, tcemem->mem);
+ 	if (ret)
+ 		return ret;
+ 
+ 	list_del(&tcemem->next);
+ 	kfree(tcemem);
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 4b6fad7097f8 (powerpc/mm/iommu, vfio/spapr: Put pages on VFIO container shutdown)
  static long tce_iommu_unregister_pages(struct tce_container *container,
  		__u64 vaddr, __u64 size)
  {
@@@ -115,7 -157,17 +159,21 @@@
  	if (!mem)
  		return -ENOENT;
  
++<<<<<<< HEAD
 +	return mm_iommu_put(mem);
++=======
+ 	list_for_each_entry(tcemem, &container->prereg_list, next) {
+ 		if (tcemem->mem == mem) {
+ 			found = true;
+ 			break;
+ 		}
+ 	}
+ 
+ 	if (!found)
+ 		return -ENOENT;
+ 
+ 	return tce_iommu_prereg_free(container, tcemem);
++>>>>>>> 4b6fad7097f8 (powerpc/mm/iommu, vfio/spapr: Put pages on VFIO container shutdown)
  }
  
  static long tce_iommu_register_pages(struct tce_container *container,
@@@ -129,7 -182,15 +188,19 @@@
  			((vaddr + size) < vaddr))
  		return -EINVAL;
  
++<<<<<<< HEAD
 +	ret = mm_iommu_get(vaddr, entries, &mem);
++=======
+ 	mem = mm_iommu_find(container->mm, vaddr, entries);
+ 	if (mem) {
+ 		list_for_each_entry(tcemem, &container->prereg_list, next) {
+ 			if (tcemem->mem == mem)
+ 				return -EBUSY;
+ 		}
+ 	}
+ 
+ 	ret = mm_iommu_get(container->mm, vaddr, entries, &mem);
++>>>>>>> 4b6fad7097f8 (powerpc/mm/iommu, vfio/spapr: Put pages on VFIO container shutdown)
  	if (ret)
  		return ret;
  
@@@ -352,10 -420,20 +428,18 @@@ static void tce_iommu_release(void *iom
  			continue;
  
  		tce_iommu_clear(container, tbl, tbl->it_offset, tbl->it_size);
 -		tce_iommu_free_table(container, tbl);
 +		tce_iommu_free_table(tbl);
  	}
  
+ 	while (!list_empty(&container->prereg_list)) {
+ 		struct tce_iommu_prereg *tcemem;
+ 
+ 		tcemem = list_first_entry(&container->prereg_list,
+ 				struct tce_iommu_prereg, next);
+ 		WARN_ON_ONCE(tce_iommu_prereg_free(container, tcemem));
+ 	}
+ 
  	tce_iommu_disable(container);
 -	if (container->mm)
 -		mmdrop(container->mm);
  	mutex_destroy(&container->lock);
  
  	kfree(container);
* Unmerged path arch/powerpc/mm/mmu_context_hash64.c
* Unmerged path arch/powerpc/mm/mmu_context_iommu.c
* Unmerged path drivers/vfio/vfio_iommu_spapr_tce.c
