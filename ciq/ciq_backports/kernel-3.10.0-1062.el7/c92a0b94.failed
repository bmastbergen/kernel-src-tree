net/mlx5: E-Switch, Enable setting goto slow path chain action

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
Rebuild_CHGLOG: - [netdrv] mlx5: E-Switch, Enable setting goto slow path chain action (Alaa Hleihel) [1642498]
Rebuild_FUZZ: 96.67%
commit-author Paul Blakey <paulb@mellanox.com>
commit c92a0b9457a4e44e1e7f53785490a5482eedfe2d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/c92a0b94.failed

A pre-step for the tc offloads code to use this when a neigh is
not available for encap rules.

	Signed-off-by: Paul Blakey <paulb@mellanox.com>
	Reviewed-by: Or Gerlitz <ogerlitz@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit c92a0b9457a4e44e1e7f53785490a5482eedfe2d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index 21bc97b70ed9,aaafc9f17115..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@@ -59,6 -59,10 +59,13 @@@
  #define mlx5_esw_has_fwd_fdb(dev) \
  	MLX5_CAP_ESW_FLOWTABLE(dev, fdb_multi_path_to_table)
  
++<<<<<<< HEAD
++=======
+ #define FDB_MAX_CHAIN 3
+ #define FDB_SLOW_PATH_CHAIN (FDB_MAX_CHAIN + 1)
+ #define FDB_MAX_PRIO 16
+ 
++>>>>>>> c92a0b9457a4 (net/mlx5: E-Switch, Enable setting goto slow path chain action)
  struct vport_ingress {
  	struct mlx5_flow_table *acl;
  	struct mlx5_flow_group *allow_untagged_spoofchk_grp;
@@@ -297,6 -355,11 +304,14 @@@ static inline void mlx5_eswitch_cleanup
  static inline void mlx5_eswitch_vport_event(struct mlx5_eswitch *esw, struct mlx5_eqe *eqe) {}
  static inline int  mlx5_eswitch_enable_sriov(struct mlx5_eswitch *esw, int nvfs, int mode) { return 0; }
  static inline void mlx5_eswitch_disable_sriov(struct mlx5_eswitch *esw) {}
++<<<<<<< HEAD
++=======
+ 
+ #define FDB_MAX_CHAIN 1
+ #define FDB_SLOW_PATH_CHAIN (FDB_MAX_CHAIN + 1)
+ #define FDB_MAX_PRIO 1
+ 
++>>>>>>> c92a0b9457a4 (net/mlx5: E-Switch, Enable setting goto slow path chain action)
  #endif /* CONFIG_MLX5_ESWITCH */
  
  #endif /* __MLX5_ESWITCH_H__ */
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
index 84864631953e,42a130455ef8..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@@ -440,75 -593,170 +440,119 @@@ out
  
  #define ESW_OFFLOADS_NUM_GROUPS  4
  
 -/* Firmware currently has 4 pool of 4 sizes that it supports (ESW_POOLS),
 - * and a virtual memory region of 16M (ESW_SIZE), this region is duplicated
 - * for each flow table pool. We can allocate up to 16M of each pool,
 - * and we keep track of how much we used via put/get_sz_to_pool.
 - * Firmware doesn't report any of this for now.
 - * ESW_POOL is expected to be sorted from large to small
 - */
 -#define ESW_SIZE (16 * 1024 * 1024)
 -const unsigned int ESW_POOLS[4] = { 4 * 1024 * 1024, 1 * 1024 * 1024,
 -				    64 * 1024, 4 * 1024 };
 -
 -static int
 -get_sz_from_pool(struct mlx5_eswitch *esw)
 -{
 -	int sz = 0, i;
 -
 -	for (i = 0; i < ARRAY_SIZE(ESW_POOLS); i++) {
 -		if (esw->fdb_table.offloads.fdb_left[i]) {
 -			--esw->fdb_table.offloads.fdb_left[i];
 -			sz = ESW_POOLS[i];
 -			break;
 -		}
 -	}
 -
 -	return sz;
 -}
 -
 -static void
 -put_sz_to_pool(struct mlx5_eswitch *esw, int sz)
 -{
 -	int i;
 -
 -	for (i = 0; i < ARRAY_SIZE(ESW_POOLS); i++) {
 -		if (sz >= ESW_POOLS[i]) {
 -			++esw->fdb_table.offloads.fdb_left[i];
 -			break;
 -		}
 -	}
 -}
 -
 -static struct mlx5_flow_table *
 -create_next_size_table(struct mlx5_eswitch *esw,
 -		       struct mlx5_flow_namespace *ns,
 -		       u16 table_prio,
 -		       int level,
 -		       u32 flags)
 -{
 -	struct mlx5_flow_table *fdb;
 -	int sz;
 -
 -	sz = get_sz_from_pool(esw);
 -	if (!sz)
 -		return ERR_PTR(-ENOSPC);
 -
 -	fdb = mlx5_create_auto_grouped_flow_table(ns,
 -						  table_prio,
 -						  sz,
 -						  ESW_OFFLOADS_NUM_GROUPS,
 -						  level,
 -						  flags);
 -	if (IS_ERR(fdb)) {
 -		esw_warn(esw->dev, "Failed to create FDB Table err %d (table prio: %d, level: %d, size: %d)\n",
 -			 (int)PTR_ERR(fdb), table_prio, level, sz);
 -		put_sz_to_pool(esw, sz);
 -	}
 -
 -	return fdb;
 -}
 -
 -static struct mlx5_flow_table *
 -esw_get_prio_table(struct mlx5_eswitch *esw, u32 chain, u16 prio, int level)
 +static int esw_create_offloads_fast_fdb_table(struct mlx5_eswitch *esw)
  {
  	struct mlx5_core_dev *dev = esw->dev;
 +	struct mlx5_flow_namespace *root_ns;
  	struct mlx5_flow_table *fdb = NULL;
 -	struct mlx5_flow_namespace *ns;
 -	int table_prio, l = 0;
 +	int esw_size, err = 0;
  	u32 flags = 0;
 +	u32 max_flow_counter = (MLX5_CAP_GEN(dev, max_flow_counter_31_16) << 16) |
 +				MLX5_CAP_GEN(dev, max_flow_counter_15_0);
  
++<<<<<<< HEAD
 +	root_ns = mlx5_get_flow_namespace(dev, MLX5_FLOW_NAMESPACE_FDB);
 +	if (!root_ns) {
 +		esw_warn(dev, "Failed to get FDB flow namespace\n");
 +		err = -EOPNOTSUPP;
 +		goto out_namespace;
++=======
+ 	if (chain == FDB_SLOW_PATH_CHAIN)
+ 		return esw->fdb_table.offloads.slow_fdb;
+ 
+ 	mutex_lock(&esw->fdb_table.offloads.fdb_prio_lock);
+ 
+ 	fdb = fdb_prio_table(esw, chain, prio, level).fdb;
+ 	if (fdb) {
+ 		/* take ref on earlier levels as well */
+ 		while (level >= 0)
+ 			fdb_prio_table(esw, chain, prio, level--).num_rules++;
+ 		mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
+ 		return fdb;
++>>>>>>> c92a0b9457a4 (net/mlx5: E-Switch, Enable setting goto slow path chain action)
  	}
  
 -	ns = mlx5_get_fdb_sub_ns(dev, chain);
 -	if (!ns) {
 -		esw_warn(dev, "Failed to get FDB sub namespace\n");
 -		mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
 -		return ERR_PTR(-EOPNOTSUPP);
 -	}
 +	esw_debug(dev, "Create offloads FDB table, min (max esw size(2^%d), max counters(%d)*groups(%d))\n",
 +		  MLX5_CAP_ESW_FLOWTABLE_FDB(dev, log_max_ft_size),
 +		  max_flow_counter, ESW_OFFLOADS_NUM_GROUPS);
 +
 +	esw_size = min_t(int, max_flow_counter * ESW_OFFLOADS_NUM_GROUPS,
 +			 1 << MLX5_CAP_ESW_FLOWTABLE_FDB(dev, log_max_ft_size));
 +
 +	if (mlx5_esw_has_fwd_fdb(dev))
 +		esw_size >>= 1;
  
  	if (esw->offloads.encap != DEVLINK_ESWITCH_ENCAP_MODE_NONE)
 -		flags |= (MLX5_FLOW_TABLE_TUNNEL_EN_REFORMAT |
 +		flags |= (MLX5_FLOW_TABLE_TUNNEL_EN_ENCAP |
  			  MLX5_FLOW_TABLE_TUNNEL_EN_DECAP);
  
 -	table_prio = (chain * FDB_MAX_PRIO) + prio - 1;
 -
 -	/* create earlier levels for correct fs_core lookup when
 -	 * connecting tables
 -	 */
 -	for (l = 0; l <= level; l++) {
 -		if (fdb_prio_table(esw, chain, prio, l).fdb) {
 -			fdb_prio_table(esw, chain, prio, l).num_rules++;
 -			continue;
 -		}
 +	fdb = mlx5_create_auto_grouped_flow_table(root_ns, FDB_FAST_PATH,
 +						  esw_size,
 +						  ESW_OFFLOADS_NUM_GROUPS, 0,
 +						  flags);
 +	if (IS_ERR(fdb)) {
 +		err = PTR_ERR(fdb);
 +		esw_warn(dev, "Failed to create Fast path FDB Table err %d\n", err);
 +		goto out_namespace;
 +	}
 +	esw->fdb_table.offloads.fast_fdb = fdb;
  
 -		fdb = create_next_size_table(esw, ns, table_prio, l, flags);
 -		if (IS_ERR(fdb)) {
 -			l--;
 -			goto err_create_fdb;
 -		}
 +	if (!mlx5_esw_has_fwd_fdb(dev))
 +		goto out_namespace;
  
 -		fdb_prio_table(esw, chain, prio, l).fdb = fdb;
 -		fdb_prio_table(esw, chain, prio, l).num_rules = 1;
 +	fdb = mlx5_create_auto_grouped_flow_table(root_ns, FDB_FAST_PATH,
 +						  esw_size,
 +						  ESW_OFFLOADS_NUM_GROUPS, 1,
 +						  flags);
 +	if (IS_ERR(fdb)) {
 +		err = PTR_ERR(fdb);
 +		esw_warn(dev, "Failed to create fwd table err %d\n", err);
 +		goto out_ft;
  	}
 +	esw->fdb_table.offloads.fwd_fdb = fdb;
  
 -	mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
 -	return fdb;
 -
 -err_create_fdb:
 -	mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
 -	if (l >= 0)
 -		esw_put_prio_table(esw, chain, prio, l);
 +	return err;
  
 -	return fdb;
 +out_ft:
 +	mlx5_destroy_flow_table(esw->fdb_table.offloads.fast_fdb);
 +out_namespace:
 +	return err;
  }
  
 -static void
 -esw_put_prio_table(struct mlx5_eswitch *esw, u32 chain, u16 prio, int level)
 +static void esw_destroy_offloads_fast_fdb_table(struct mlx5_eswitch *esw)
  {
++<<<<<<< HEAD
 +	if (mlx5_esw_has_fwd_fdb(esw->dev))
 +		mlx5_destroy_flow_table(esw->fdb_table.offloads.fwd_fdb);
 +	mlx5_destroy_flow_table(esw->fdb_table.offloads.fast_fdb);
++=======
+ 	int l;
+ 
+ 	if (chain == FDB_SLOW_PATH_CHAIN)
+ 		return;
+ 
+ 	mutex_lock(&esw->fdb_table.offloads.fdb_prio_lock);
+ 
+ 	for (l = level; l >= 0; l--) {
+ 		if (--(fdb_prio_table(esw, chain, prio, l).num_rules) > 0)
+ 			continue;
+ 
+ 		put_sz_to_pool(esw, fdb_prio_table(esw, chain, prio, l).fdb->max_fte);
+ 		mlx5_destroy_flow_table(fdb_prio_table(esw, chain, prio, l).fdb);
+ 		fdb_prio_table(esw, chain, prio, l).fdb = NULL;
+ 	}
+ 
+ 	mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
+ }
+ 
+ static void esw_destroy_offloads_fast_fdb_tables(struct mlx5_eswitch *esw)
+ {
+ 	/* If lazy creation isn't supported, deref the fast path tables */
+ 	if (!(esw->fdb_table.flags & ESW_FDB_CHAINS_AND_PRIOS_SUPPORTED)) {
+ 		esw_put_prio_table(esw, 0, 1, 1);
+ 		esw_put_prio_table(esw, 0, 1, 0);
+ 	}
++>>>>>>> c92a0b9457a4 (net/mlx5: E-Switch, Enable setting goto slow path chain action)
  }
  
  #define MAX_PF_SQ 256
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
