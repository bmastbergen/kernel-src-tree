IB/core: Introduce GID entry reference counts

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Parav Pandit <parav@mellanox.com>
commit b150c3862d21a4a9ce0f26d8067b9dcd41e2050c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/b150c386.failed

In order to be able to expose pointers to the ib_gid_attrs in the GID
table we need to make it so the value of the pointer cannot be
changed. Thus each GID table entry gets a unique piece of kref'd memory
that is written only during initialization and remains constant for its
lifetime.

This eventually will allow the struct ib_gid_attrs to be returned without
copy from many of query the APIs, but it also provides a way to track when
all users of a HW table index go away.

For roce we no longer allow an in-use HW table index to be re-used for a
new an different entry. When a GID table entry needs to be removed it is
hidden from the find API, but remains as a valid HW index and all
ib_gid_attr points remain valid. The HW index is not relased until all
users put the kref.

Later patches will broadly replace the use of the sgid_index integer with
the kref'd structure.

Ultimately this will prevent security problems where the OS changes the
properties of a HW GID table entry while an active user object is still
using the entry.

	Signed-off-by: Parav Pandit <parav@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit b150c3862d21a4a9ce0f26d8067b9dcd41e2050c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/cache.c
#	include/rdma/ib_verbs.h
diff --cc drivers/infiniband/core/cache.c
index 235416ffd0cc,09d83c69ec65..000000000000
--- a/drivers/infiniband/core/cache.c
+++ b/drivers/infiniband/core/cache.c
@@@ -68,18 -66,16 +68,31 @@@ enum gid_attr_find_mask 
  	GID_ATTR_FIND_MASK_GID_TYPE	= 1UL << 3,
  };
  
++<<<<<<< HEAD
 +enum gid_table_entry_props {
 +	GID_TABLE_ENTRY_INVALID		= 1UL << 0,
 +	GID_TABLE_ENTRY_DEFAULT		= 1UL << 1,
 +};
 +
 +enum gid_table_write_action {
 +	GID_TABLE_WRITE_ACTION_ADD,
 +	GID_TABLE_WRITE_ACTION_DEL,
 +	/* MODIFY only updates the GID table. Currently only used by
 +	 * ib_cache_update.
 +	 */
 +	GID_TABLE_WRITE_ACTION_MODIFY
++=======
+ enum gid_table_entry_state {
+ 	GID_TABLE_ENTRY_INVALID		= 1,
+ 	GID_TABLE_ENTRY_VALID		= 2,
+ 	/*
+ 	 * Indicates that entry is pending to be removed, there may
+ 	 * be active users of this GID entry.
+ 	 * When last user of the GID entry releases reference to it,
+ 	 * GID entry is detached from the table.
+ 	 */
+ 	GID_TABLE_ENTRY_PENDING_DEL	= 3,
++>>>>>>> b150c3862d21 (IB/core: Introduce GID entry reference counts)
  };
  
  struct ib_gid_table_entry {
@@@ -100,18 -97,18 +114,32 @@@ struct ib_gid_table 
  	 * (a) Find the GID
  	 * (b) Delete it.
  	 *
 +	 * Add/delete should be carried out atomically.
 +	 * This is done by locking this mutex from multiple
 +	 * writers. We don't need this lock for IB, as the MAD
 +	 * layer replaces all entries. All data_vec entries
 +	 * are locked by this lock.
  	 **/
++<<<<<<< HEAD
 +	struct mutex         lock;
 +	/* This lock protects the table entries from being
 +	 * read and written simultaneously.
 +	 */
 +	rwlock_t	     rwlock;
 +	struct ib_gid_table_entry *data_vec;
++=======
+ 	/* Any writer to data_vec must hold this lock and the write side of
+ 	 * rwlock. Readers must hold only rwlock. All writers must be in a
+ 	 * sleepable context.
+ 	 */
+ 	struct mutex			lock;
+ 	/* rwlock protects data_vec[ix]->state and entry pointer.
+ 	 */
+ 	rwlock_t			rwlock;
+ 	struct ib_gid_table_entry	**data_vec;
+ 	/* bit field, each bit indicates the index of default GID */
+ 	u32				default_gid_indices;
++>>>>>>> b150c3862d21 (IB/core: Introduce GID entry reference counts)
  };
  
  static void dispatch_gid_change_event(struct ib_device *ib_dev, u8 port)
@@@ -163,94 -183,220 +191,302 @@@ int ib_cache_gid_parse_type_str(const c
  }
  EXPORT_SYMBOL(ib_cache_gid_parse_type_str);
  
 -static struct ib_gid_table *rdma_gid_table(struct ib_device *device, u8 port)
 +/* This function expects that rwlock will be write locked in all
 + * scenarios and that lock will be locked in sleep-able (RoCE)
 + * scenarios.
 + */
 +static int write_gid(struct ib_device *ib_dev, u8 port,
 +		     struct ib_gid_table *table, int ix,
 +		     const union ib_gid *gid,
 +		     const struct ib_gid_attr *attr,
 +		     enum gid_table_write_action action,
 +		     bool  default_gid)
 +	__releases(&table->rwlock) __acquires(&table->rwlock)
  {
++<<<<<<< HEAD
 +	int ret = 0;
 +	struct net_device *old_net_dev;
 +	enum ib_gid_type old_gid_type;
++=======
+ 	return device->cache.ports[port - rdma_start_port(device)].gid;
+ }
+ 
+ static bool is_gid_entry_free(const struct ib_gid_table_entry *entry)
+ {
+ 	return !entry;
+ }
+ 
+ static bool is_gid_entry_valid(const struct ib_gid_table_entry *entry)
+ {
+ 	return entry && entry->state == GID_TABLE_ENTRY_VALID;
+ }
+ 
+ static void schedule_free_gid(struct kref *kref)
+ {
+ 	struct ib_gid_table_entry *entry =
+ 			container_of(kref, struct ib_gid_table_entry, kref);
+ 
+ 	queue_work(ib_wq, &entry->del_work);
+ }
+ 
+ static void free_gid_entry(struct ib_gid_table_entry *entry)
+ {
+ 	struct ib_device *device = entry->attr.device;
+ 	u8 port_num = entry->attr.port_num;
+ 	struct ib_gid_table *table = rdma_gid_table(device, port_num);
+ 
+ 	pr_debug("%s device=%s port=%d index=%d gid %pI6\n", __func__,
+ 		 device->name, port_num, entry->attr.index,
+ 		 entry->attr.gid.raw);
+ 
+ 	mutex_lock(&table->lock);
+ 	if (rdma_cap_roce_gid_table(device, port_num) &&
+ 	    entry->state != GID_TABLE_ENTRY_INVALID)
+ 		device->del_gid(&entry->attr, &entry->context);
+ 	write_lock_irq(&table->rwlock);
+ 
+ 	/*
+ 	 * The only way to avoid overwriting NULL in table is
+ 	 * by comparing if it is same entry in table or not!
+ 	 * If new entry in table is added by the time we free here,
+ 	 * don't overwrite the table entry.
+ 	 */
+ 	if (entry == table->data_vec[entry->attr.index])
+ 		table->data_vec[entry->attr.index] = NULL;
+ 	/* Now this index is ready to be allocated */
+ 	write_unlock_irq(&table->rwlock);
+ 	mutex_unlock(&table->lock);
+ 
+ 	if (entry->attr.ndev)
+ 		dev_put(entry->attr.ndev);
+ 	kfree(entry);
+ }
+ 
+ /**
+  * free_gid_work - Release reference to the GID entry
+  * @work: Work structure to refer to GID entry which needs to be
+  * deleted.
+  *
+  * free_gid_work() frees the entry from the HCA's hardware table
+  * if provider supports it. It releases reference to netdevice.
+  */
+ static void free_gid_work(struct work_struct *work)
+ {
+ 	struct ib_gid_table_entry *entry =
+ 		container_of(work, struct ib_gid_table_entry, del_work);
+ 	free_gid_entry(entry);
+ }
+ 
+ static struct ib_gid_table_entry *
+ alloc_gid_entry(const struct ib_gid_attr *attr)
+ {
+ 	struct ib_gid_table_entry *entry;
+ 
+ 	entry = kzalloc(sizeof(*entry), GFP_KERNEL);
+ 	if (!entry)
+ 		return NULL;
+ 	kref_init(&entry->kref);
+ 	memcpy(&entry->attr, attr, sizeof(*attr));
+ 	if (entry->attr.ndev)
+ 		dev_hold(entry->attr.ndev);
+ 	INIT_WORK(&entry->del_work, free_gid_work);
+ 	entry->state = GID_TABLE_ENTRY_INVALID;
+ 	return entry;
+ }
+ 
+ static void store_gid_entry(struct ib_gid_table *table,
+ 			    struct ib_gid_table_entry *entry)
+ {
+ 	entry->state = GID_TABLE_ENTRY_VALID;
+ 
+ 	pr_debug("%s device=%s port=%d index=%d gid %pI6\n", __func__,
+ 		 entry->attr.device->name, entry->attr.port_num,
+ 		 entry->attr.index, entry->attr.gid.raw);
+ 
+ 	lockdep_assert_held(&table->lock);
+ 	write_lock_irq(&table->rwlock);
+ 	table->data_vec[entry->attr.index] = entry;
+ 	write_unlock_irq(&table->rwlock);
+ }
+ 
+ static void put_gid_entry(struct ib_gid_table_entry *entry)
+ {
+ 	kref_put(&entry->kref, schedule_free_gid);
+ }
+ 
+ static int add_roce_gid(struct ib_gid_table_entry *entry)
+ {
+ 	const struct ib_gid_attr *attr = &entry->attr;
+ 	int ret;
++>>>>>>> b150c3862d21 (IB/core: Introduce GID entry reference counts)
  
 -	if (!attr->ndev) {
 -		pr_err("%s NULL netdev device=%s port=%d index=%d\n",
 -		       __func__, attr->device->name, attr->port_num,
 -		       attr->index);
 -		return -EINVAL;
 +	/* in rdma_cap_roce_gid_table, this funciton should be protected by a
 +	 * sleep-able lock.
 +	 */
 +
 +	if (rdma_cap_roce_gid_table(ib_dev, port)) {
 +		table->data_vec[ix].props |= GID_TABLE_ENTRY_INVALID;
 +		write_unlock_irq(&table->rwlock);
 +		/* GID_TABLE_WRITE_ACTION_MODIFY currently isn't supported by
 +		 * RoCE providers and thus only updates the cache.
 +		 */
 +		if (action == GID_TABLE_WRITE_ACTION_ADD)
 +			ret = ib_dev->add_gid(ib_dev, port, ix, gid, attr,
 +					      &table->data_vec[ix].context);
 +		else if (action == GID_TABLE_WRITE_ACTION_DEL)
 +			ret = ib_dev->del_gid(ib_dev, port, ix,
 +					      &table->data_vec[ix].context);
 +		write_lock_irq(&table->rwlock);
 +	}
++<<<<<<< HEAD
 +
 +	old_net_dev = table->data_vec[ix].attr.ndev;
 +	old_gid_type = table->data_vec[ix].attr.gid_type;
 +	if (old_net_dev && old_net_dev != attr->ndev)
 +		dev_put(old_net_dev);
 +	/* if modify_gid failed, just delete the old gid */
 +	if (ret || action == GID_TABLE_WRITE_ACTION_DEL) {
 +		gid = &zgid;
 +		attr = &zattr;
 +		table->data_vec[ix].context = NULL;
 +	}
 +
 +	memcpy(&table->data_vec[ix].gid, gid, sizeof(*gid));
 +	memcpy(&table->data_vec[ix].attr, attr, sizeof(*attr));
 +	if (default_gid) {
 +		table->data_vec[ix].props |= GID_TABLE_ENTRY_DEFAULT;
 +		if (action == GID_TABLE_WRITE_ACTION_DEL)
 +			table->data_vec[ix].attr.gid_type = old_gid_type;
  	}
 +	if (table->data_vec[ix].attr.ndev &&
 +	    table->data_vec[ix].attr.ndev != old_net_dev)
 +		dev_hold(table->data_vec[ix].attr.ndev);
 +
 +	table->data_vec[ix].props &= ~GID_TABLE_ENTRY_INVALID;
 +
 +	return ret;
 +}
 +
 +static int add_gid(struct ib_device *ib_dev, u8 port,
 +		   struct ib_gid_table *table, int ix,
 +		   const union ib_gid *gid,
 +		   const struct ib_gid_attr *attr,
 +		   bool  default_gid) {
 +	return write_gid(ib_dev, port, table, ix, gid, attr,
 +			 GID_TABLE_WRITE_ACTION_ADD, default_gid);
 +}
 +
 +static int modify_gid(struct ib_device *ib_dev, u8 port,
 +		      struct ib_gid_table *table, int ix,
 +		      const union ib_gid *gid,
 +		      const struct ib_gid_attr *attr,
 +		      bool  default_gid) {
 +	return write_gid(ib_dev, port, table, ix, gid, attr,
 +			 GID_TABLE_WRITE_ACTION_MODIFY, default_gid);
++=======
+ 	if (rdma_cap_roce_gid_table(attr->device, attr->port_num)) {
+ 		ret = attr->device->add_gid(&attr->gid, attr, &entry->context);
+ 		if (ret) {
+ 			pr_err("%s GID add failed device=%s port=%d index=%d\n",
+ 			       __func__, attr->device->name, attr->port_num,
+ 			       attr->index);
+ 			return ret;
+ 		}
+ 	}
+ 	return 0;
+ }
+ 
+ /**
+  * add_modify_gid - Add or modify GID table entry
+  *
+  * @table:	GID table in which GID to be added or modified
+  * @attr:	Attributes of the GID
+  *
+  * Returns 0 on success or appropriate error code. It accepts zero
+  * GID addition for non RoCE ports for HCA's who report them as valid
+  * GID. However such zero GIDs are not added to the cache.
+  */
+ static int add_modify_gid(struct ib_gid_table *table,
+ 			  const struct ib_gid_attr *attr)
+ {
+ 	struct ib_gid_table_entry *entry;
+ 	int ret = 0;
+ 
+ 	/*
+ 	 * Invalidate any old entry in the table to make it safe to write to
+ 	 * this index.
+ 	 */
+ 	if (is_gid_entry_valid(table->data_vec[attr->index]))
+ 		put_gid_entry(table->data_vec[attr->index]);
+ 
+ 	/*
+ 	 * Some HCA's report multiple GID entries with only one valid GID, and
+ 	 * leave other unused entries as the zero GID. Convert zero GIDs to
+ 	 * empty table entries instead of storing them.
+ 	 */
+ 	if (rdma_is_zero_gid(&attr->gid))
+ 		return 0;
+ 
+ 	entry = alloc_gid_entry(attr);
+ 	if (!entry)
+ 		return -ENOMEM;
+ 
+ 	if (rdma_protocol_roce(attr->device, attr->port_num)) {
+ 		ret = add_roce_gid(entry);
+ 		if (ret)
+ 			goto done;
+ 	}
+ 
+ 	store_gid_entry(table, entry);
+ 	return 0;
+ 
+ done:
+ 	put_gid_entry(entry);
+ 	return ret;
+ }
+ 
+ /**
+  * del_gid - Delete GID table entry
+  *
+  * @ib_dev:	IB device whose GID entry to be deleted
+  * @port:	Port number of the IB device
+  * @table:	GID table of the IB device for a port
+  * @ix:		GID entry index to delete
+  *
+  */
+ static void del_gid(struct ib_device *ib_dev, u8 port,
+ 		    struct ib_gid_table *table, int ix)
+ {
+ 	struct ib_gid_table_entry *entry;
+ 
+ 	lockdep_assert_held(&table->lock);
+ 
+ 	pr_debug("%s device=%s port=%d index=%d gid %pI6\n", __func__,
+ 		 ib_dev->name, port, ix,
+ 		 table->data_vec[ix]->attr.gid.raw);
+ 
+ 	write_lock_irq(&table->rwlock);
+ 	entry = table->data_vec[ix];
+ 	entry->state = GID_TABLE_ENTRY_PENDING_DEL;
+ 	/*
+ 	 * For non RoCE protocol, GID entry slot is ready to use.
+ 	 */
+ 	if (!rdma_protocol_roce(ib_dev, port))
+ 		table->data_vec[ix] = NULL;
+ 	write_unlock_irq(&table->rwlock);
+ 
+ 	put_gid_entry(entry);
++>>>>>>> b150c3862d21 (IB/core: Introduce GID entry reference counts)
  }
  
 -/* rwlock should be read locked, or lock should be held */
 +static int del_gid(struct ib_device *ib_dev, u8 port,
 +		   struct ib_gid_table *table, int ix,
 +		   bool  default_gid) {
 +	return write_gid(ib_dev, port, table, ix, &zgid, &zattr,
 +			 GID_TABLE_WRITE_ACTION_DEL, default_gid);
 +}
 +
 +/* rwlock should be read locked */
  static int find_gid(struct ib_gid_table *table, const union ib_gid *gid,
  		    const struct ib_gid_attr *val, bool default_gid,
  		    unsigned long mask, int *pempty)
@@@ -266,15 -412,36 +502,46 @@@
  
  		i++;
  
++<<<<<<< HEAD
 +		if (data->props & GID_TABLE_ENTRY_INVALID)
++=======
+ 		/* find_gid() is used during GID addition where it is expected
+ 		 * to return a free entry slot which is not duplicate.
+ 		 * Free entry slot is requested and returned if pempty is set,
+ 		 * so lookup free slot only if requested.
+ 		 */
+ 		if (pempty && empty < 0) {
+ 			if (is_gid_entry_free(data) &&
+ 			    default_gid ==
+ 				is_gid_index_default(table, curr_index)) {
+ 				/*
+ 				 * Found an invalid (free) entry; allocate it.
+ 				 * If default GID is requested, then our
+ 				 * found slot must be one of the DEFAULT
+ 				 * reserved slots or we fail.
+ 				 * This ensures that only DEFAULT reserved
+ 				 * slots are used for default property GIDs.
+ 				 */
+ 				empty = curr_index;
+ 			}
+ 		}
+ 
+ 		/*
+ 		 * Additionally find_gid() is used to find valid entry during
+ 		 * lookup operation; so ignore the entries which are marked as
+ 		 * pending for removal and the entries which are marked as
+ 		 * invalid.
+ 		 */
+ 		if (!is_gid_entry_valid(data))
++>>>>>>> b150c3862d21 (IB/core: Introduce GID entry reference counts)
  			continue;
  
 +		if (empty < 0)
 +			if (!memcmp(&data->gid, &zgid, sizeof(*gid)) &&
 +			    !memcmp(attr, &zattr, sizeof(*attr)) &&
 +			    !data->props)
 +				empty = curr_index;
 +
  		if (found >= 0)
  			continue;
  
@@@ -310,6 -477,50 +578,53 @@@ static void make_default_gid(struct  ne
  	addrconf_ifid_eui48(&gid->raw[8], dev);
  }
  
++<<<<<<< HEAD
++=======
+ static int __ib_cache_gid_add(struct ib_device *ib_dev, u8 port,
+ 			      union ib_gid *gid, struct ib_gid_attr *attr,
+ 			      unsigned long mask, bool default_gid)
+ {
+ 	struct ib_gid_table *table;
+ 	int ret = 0;
+ 	int empty;
+ 	int ix;
+ 
+ 	/* Do not allow adding zero GID in support of
+ 	 * IB spec version 1.3 section 4.1.1 point (6) and
+ 	 * section 12.7.10 and section 12.7.20
+ 	 */
+ 	if (rdma_is_zero_gid(gid))
+ 		return -EINVAL;
+ 
+ 	table = rdma_gid_table(ib_dev, port);
+ 
+ 	mutex_lock(&table->lock);
+ 
+ 	ix = find_gid(table, gid, attr, default_gid, mask, &empty);
+ 	if (ix >= 0)
+ 		goto out_unlock;
+ 
+ 	if (empty < 0) {
+ 		ret = -ENOSPC;
+ 		goto out_unlock;
+ 	}
+ 	attr->device = ib_dev;
+ 	attr->index = empty;
+ 	attr->port_num = port;
+ 	attr->gid = *gid;
+ 	ret = add_modify_gid(table, attr);
+ 	if (!ret)
+ 		dispatch_gid_change_event(ib_dev, port);
+ 
+ out_unlock:
+ 	mutex_unlock(&table->lock);
+ 	if (ret)
+ 		pr_warn("%s: unable to add gid %pI6 error=%d\n",
+ 			__func__, gid->raw, ret);
+ 	return ret;
+ }
+ 
++>>>>>>> b150c3862d21 (IB/core: Introduce GID entry reference counts)
  int ib_cache_gid_add(struct ib_device *ib_dev, u8 port,
  		     union ib_gid *gid, struct ib_gid_attr *attr)
  {
@@@ -400,19 -600,18 +715,29 @@@ int ib_cache_gid_del_all_netdev_gids(st
  	int ix;
  	bool deleted = false;
  
 -	table = rdma_gid_table(ib_dev, port);
 +	table = ib_dev->cache.ports[port - rdma_start_port(ib_dev)].gid;
  
  	mutex_lock(&table->lock);
 +	write_lock_irq(&table->rwlock);
  
++<<<<<<< HEAD
 +	for (ix = 0; ix < table->sz; ix++)
 +		if (table->data_vec[ix].attr.ndev == ndev)
 +			if (!del_gid(ib_dev, port, table, ix,
 +				     !!(table->data_vec[ix].props &
 +					GID_TABLE_ENTRY_DEFAULT)))
 +				deleted = true;
++=======
+ 	for (ix = 0; ix < table->sz; ix++) {
+ 		if (is_gid_entry_valid(table->data_vec[ix]) &&
+ 		    table->data_vec[ix]->attr.ndev == ndev) {
+ 			del_gid(ib_dev, port, table, ix);
+ 			deleted = true;
+ 		}
+ 	}
++>>>>>>> b150c3862d21 (IB/core: Introduce GID entry reference counts)
  
 +	write_unlock_irq(&table->rwlock);
  	mutex_unlock(&table->lock);
  
  	if (deleted)
@@@ -607,8 -808,7 +934,12 @@@ static int ib_cache_gid_find_by_filter(
  
  static struct ib_gid_table *alloc_gid_table(int sz)
  {
++<<<<<<< HEAD
 +	struct ib_gid_table *table =
 +		kzalloc(sizeof(struct ib_gid_table), GFP_KERNEL);
++=======
+ 	struct ib_gid_table *table = kzalloc(sizeof(*table), GFP_KERNEL);
++>>>>>>> b150c3862d21 (IB/core: Introduce GID entry reference counts)
  
  	if (!table)
  		return NULL;
@@@ -621,7 -821,6 +952,10 @@@
  
  	table->sz = sz;
  	rwlock_init(&table->rwlock);
++<<<<<<< HEAD
 +
++=======
++>>>>>>> b150c3862d21 (IB/core: Introduce GID entry reference counts)
  	return table;
  
  err_free_table:
@@@ -646,16 -863,14 +998,23 @@@ static void cleanup_gid_table_port(stru
  	if (!table)
  		return;
  
 -	mutex_lock(&table->lock);
 +	write_lock_irq(&table->rwlock);
  	for (i = 0; i < table->sz; ++i) {
++<<<<<<< HEAD
 +		if (memcmp(&table->data_vec[i].gid, &zgid,
 +			   sizeof(table->data_vec[i].gid)))
 +			if (!del_gid(ib_dev, port, table, i,
 +				     table->data_vec[i].props &
 +				     GID_ATTR_FIND_MASK_DEFAULT))
 +				deleted = true;
++=======
+ 		if (is_gid_entry_valid(table->data_vec[i])) {
+ 			del_gid(ib_dev, port, table, i);
+ 			deleted = true;
+ 		}
++>>>>>>> b150c3862d21 (IB/core: Introduce GID entry reference counts)
  	}
 -	mutex_unlock(&table->lock);
 +	write_unlock_irq(&table->rwlock);
  
  	if (deleted)
  		dispatch_gid_change_event(ib_dev, port);
@@@ -1034,6 -1208,36 +1393,39 @@@ int ib_get_cached_port_state(struct ib_
  }
  EXPORT_SYMBOL(ib_get_cached_port_state);
  
++<<<<<<< HEAD
++=======
+ static int config_non_roce_gid_cache(struct ib_device *device,
+ 				     u8 port, int gid_tbl_len)
+ {
+ 	struct ib_gid_attr gid_attr = {};
+ 	struct ib_gid_table *table;
+ 	int ret = 0;
+ 	int i;
+ 
+ 	gid_attr.device = device;
+ 	gid_attr.port_num = port;
+ 	table = rdma_gid_table(device, port);
+ 
+ 	mutex_lock(&table->lock);
+ 	for (i = 0; i < gid_tbl_len; ++i) {
+ 		if (!device->query_gid)
+ 			continue;
+ 		ret = device->query_gid(device, port, i, &gid_attr.gid);
+ 		if (ret) {
+ 			pr_warn("query_gid failed (%d) for %s (index %d)\n",
+ 				ret, device->name, i);
+ 			goto err;
+ 		}
+ 		gid_attr.index = i;
+ 		add_modify_gid(table, &gid_attr);
+ 	}
+ err:
+ 	mutex_unlock(&table->lock);
+ 	return ret;
+ }
+ 
++>>>>>>> b150c3862d21 (IB/core: Introduce GID entry reference counts)
  static void ib_cache_update(struct ib_device *device,
  			    u8                port,
  			    bool	      enforce_security)
diff --cc include/rdma/ib_verbs.h
index 696c31d40d6e,0a77afedabd0..000000000000
--- a/include/rdma/ib_verbs.h
+++ b/include/rdma/ib_verbs.h
@@@ -89,8 -92,12 +89,14 @@@ enum ib_gid_type 
  
  #define ROCE_V2_UDP_DPORT      4791
  struct ib_gid_attr {
++<<<<<<< HEAD
++=======
+ 	struct net_device	*ndev;
+ 	struct ib_device	*device;
+ 	union ib_gid		gid;
++>>>>>>> b150c3862d21 (IB/core: Introduce GID entry reference counts)
  	enum ib_gid_type	gid_type;
 -	u16			index;
 -	u8			port_num;
 +	struct net_device	*ndev;
  };
  
  enum rdma_node_type {
* Unmerged path drivers/infiniband/core/cache.c
* Unmerged path include/rdma/ib_verbs.h
