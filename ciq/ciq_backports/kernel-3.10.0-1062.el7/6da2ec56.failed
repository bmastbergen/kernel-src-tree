treewide: kmalloc() -> kmalloc_array()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Kees Cook <keescook@chromium.org>
commit 6da2ec56059c3c7a7e5f729e6349e74ace1e5c57
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/6da2ec56.failed

The kmalloc() function has a 2-factor argument form, kmalloc_array(). This
patch replaces cases of:

        kmalloc(a * b, gfp)

with:
        kmalloc_array(a * b, gfp)

as well as handling cases of:

        kmalloc(a * b * c, gfp)

with:

        kmalloc(array3_size(a, b, c), gfp)

as it's slightly less ugly than:

        kmalloc_array(array_size(a, b), c, gfp)

This does, however, attempt to ignore constant size factors like:

        kmalloc(4 * 1024, gfp)

though any constants defined via macros get caught up in the conversion.

Any factors with a sizeof() of "unsigned char", "char", and "u8" were
dropped, since they're redundant.

The tools/ directory was manually excluded, since it has its own
implementation of kmalloc().

The Coccinelle script used for this was:

// Fix redundant parens around sizeof().
@@
type TYPE;
expression THING, E;
@@

(
  kmalloc(
-	(sizeof(TYPE)) * E
+	sizeof(TYPE) * E
  , ...)
|
  kmalloc(
-	(sizeof(THING)) * E
+	sizeof(THING) * E
  , ...)
)

// Drop single-byte sizes and redundant parens.
@@
expression COUNT;
typedef u8;
typedef __u8;
@@

(
  kmalloc(
-	sizeof(u8) * (COUNT)
+	COUNT
  , ...)
|
  kmalloc(
-	sizeof(__u8) * (COUNT)
+	COUNT
  , ...)
|
  kmalloc(
-	sizeof(char) * (COUNT)
+	COUNT
  , ...)
|
  kmalloc(
-	sizeof(unsigned char) * (COUNT)
+	COUNT
  , ...)
|
  kmalloc(
-	sizeof(u8) * COUNT
+	COUNT
  , ...)
|
  kmalloc(
-	sizeof(__u8) * COUNT
+	COUNT
  , ...)
|
  kmalloc(
-	sizeof(char) * COUNT
+	COUNT
  , ...)
|
  kmalloc(
-	sizeof(unsigned char) * COUNT
+	COUNT
  , ...)
)

// 2-factor product with sizeof(type/expression) and identifier or constant.
@@
type TYPE;
expression THING;
identifier COUNT_ID;
constant COUNT_CONST;
@@

(
- kmalloc
+ kmalloc_array
  (
-	sizeof(TYPE) * (COUNT_ID)
+	COUNT_ID, sizeof(TYPE)
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	sizeof(TYPE) * COUNT_ID
+	COUNT_ID, sizeof(TYPE)
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	sizeof(TYPE) * (COUNT_CONST)
+	COUNT_CONST, sizeof(TYPE)
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	sizeof(TYPE) * COUNT_CONST
+	COUNT_CONST, sizeof(TYPE)
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	sizeof(THING) * (COUNT_ID)
+	COUNT_ID, sizeof(THING)
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	sizeof(THING) * COUNT_ID
+	COUNT_ID, sizeof(THING)
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	sizeof(THING) * (COUNT_CONST)
+	COUNT_CONST, sizeof(THING)
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	sizeof(THING) * COUNT_CONST
+	COUNT_CONST, sizeof(THING)
  , ...)
)

// 2-factor product, only identifiers.
@@
identifier SIZE, COUNT;
@@

- kmalloc
+ kmalloc_array
  (
-	SIZE * COUNT
+	COUNT, SIZE
  , ...)

// 3-factor product with 1 sizeof(type) or sizeof(expression), with
// redundant parens removed.
@@
expression THING;
identifier STRIDE, COUNT;
type TYPE;
@@

(
  kmalloc(
-	sizeof(TYPE) * (COUNT) * (STRIDE)
+	array3_size(COUNT, STRIDE, sizeof(TYPE))
  , ...)
|
  kmalloc(
-	sizeof(TYPE) * (COUNT) * STRIDE
+	array3_size(COUNT, STRIDE, sizeof(TYPE))
  , ...)
|
  kmalloc(
-	sizeof(TYPE) * COUNT * (STRIDE)
+	array3_size(COUNT, STRIDE, sizeof(TYPE))
  , ...)
|
  kmalloc(
-	sizeof(TYPE) * COUNT * STRIDE
+	array3_size(COUNT, STRIDE, sizeof(TYPE))
  , ...)
|
  kmalloc(
-	sizeof(THING) * (COUNT) * (STRIDE)
+	array3_size(COUNT, STRIDE, sizeof(THING))
  , ...)
|
  kmalloc(
-	sizeof(THING) * (COUNT) * STRIDE
+	array3_size(COUNT, STRIDE, sizeof(THING))
  , ...)
|
  kmalloc(
-	sizeof(THING) * COUNT * (STRIDE)
+	array3_size(COUNT, STRIDE, sizeof(THING))
  , ...)
|
  kmalloc(
-	sizeof(THING) * COUNT * STRIDE
+	array3_size(COUNT, STRIDE, sizeof(THING))
  , ...)
)

// 3-factor product with 2 sizeof(variable), with redundant parens removed.
@@
expression THING1, THING2;
identifier COUNT;
type TYPE1, TYPE2;
@@

(
  kmalloc(
-	sizeof(TYPE1) * sizeof(TYPE2) * COUNT
+	array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
  , ...)
|
  kmalloc(
-	sizeof(TYPE1) * sizeof(THING2) * (COUNT)
+	array3_size(COUNT, sizeof(TYPE1), sizeof(TYPE2))
  , ...)
|
  kmalloc(
-	sizeof(THING1) * sizeof(THING2) * COUNT
+	array3_size(COUNT, sizeof(THING1), sizeof(THING2))
  , ...)
|
  kmalloc(
-	sizeof(THING1) * sizeof(THING2) * (COUNT)
+	array3_size(COUNT, sizeof(THING1), sizeof(THING2))
  , ...)
|
  kmalloc(
-	sizeof(TYPE1) * sizeof(THING2) * COUNT
+	array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
  , ...)
|
  kmalloc(
-	sizeof(TYPE1) * sizeof(THING2) * (COUNT)
+	array3_size(COUNT, sizeof(TYPE1), sizeof(THING2))
  , ...)
)

// 3-factor product, only identifiers, with redundant parens removed.
@@
identifier STRIDE, SIZE, COUNT;
@@

(
  kmalloc(
-	(COUNT) * STRIDE * SIZE
+	array3_size(COUNT, STRIDE, SIZE)
  , ...)
|
  kmalloc(
-	COUNT * (STRIDE) * SIZE
+	array3_size(COUNT, STRIDE, SIZE)
  , ...)
|
  kmalloc(
-	COUNT * STRIDE * (SIZE)
+	array3_size(COUNT, STRIDE, SIZE)
  , ...)
|
  kmalloc(
-	(COUNT) * (STRIDE) * SIZE
+	array3_size(COUNT, STRIDE, SIZE)
  , ...)
|
  kmalloc(
-	COUNT * (STRIDE) * (SIZE)
+	array3_size(COUNT, STRIDE, SIZE)
  , ...)
|
  kmalloc(
-	(COUNT) * STRIDE * (SIZE)
+	array3_size(COUNT, STRIDE, SIZE)
  , ...)
|
  kmalloc(
-	(COUNT) * (STRIDE) * (SIZE)
+	array3_size(COUNT, STRIDE, SIZE)
  , ...)
|
  kmalloc(
-	COUNT * STRIDE * SIZE
+	array3_size(COUNT, STRIDE, SIZE)
  , ...)
)

// Any remaining multi-factor products, first at least 3-factor products,
// when they're not all constants...
@@
expression E1, E2, E3;
constant C1, C2, C3;
@@

(
  kmalloc(C1 * C2 * C3, ...)
|
  kmalloc(
-	(E1) * E2 * E3
+	array3_size(E1, E2, E3)
  , ...)
|
  kmalloc(
-	(E1) * (E2) * E3
+	array3_size(E1, E2, E3)
  , ...)
|
  kmalloc(
-	(E1) * (E2) * (E3)
+	array3_size(E1, E2, E3)
  , ...)
|
  kmalloc(
-	E1 * E2 * E3
+	array3_size(E1, E2, E3)
  , ...)
)

// And then all remaining 2 factors products when they're not all constants,
// keeping sizeof() as the second factor argument.
@@
expression THING, E1, E2;
type TYPE;
constant C1, C2, C3;
@@

(
  kmalloc(sizeof(THING) * C2, ...)
|
  kmalloc(sizeof(TYPE) * C2, ...)
|
  kmalloc(C1 * C2 * C3, ...)
|
  kmalloc(C1 * C2, ...)
|
- kmalloc
+ kmalloc_array
  (
-	sizeof(TYPE) * (E2)
+	E2, sizeof(TYPE)
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	sizeof(TYPE) * E2
+	E2, sizeof(TYPE)
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	sizeof(THING) * (E2)
+	E2, sizeof(THING)
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	sizeof(THING) * E2
+	E2, sizeof(THING)
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	(E1) * E2
+	E1, E2
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	(E1) * (E2)
+	E1, E2
  , ...)
|
- kmalloc
+ kmalloc_array
  (
-	E1 * E2
+	E1, E2
  , ...)
)

	Signed-off-by: Kees Cook <keescook@chromium.org>
(cherry picked from commit 6da2ec56059c3c7a7e5f729e6349e74ace1e5c57)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm/kernel/sys_oabi-compat.c
#	arch/powerpc/platforms/4xx/hsta_msi.c
#	arch/s390/kernel/debug.c
#	arch/s390/mm/extmem.c
#	arch/um/drivers/ubd_kern.c
#	arch/um/drivers/vector_kern.c
#	arch/x86/kvm/svm.c
#	arch/x86/net/bpf_jit_comp.c
#	arch/x86/net/bpf_jit_comp32.c
#	crypto/testmgr.c
#	drivers/acpi/video.c
#	drivers/block/loop.c
#	drivers/cpufreq/bmips-cpufreq.c
#	drivers/crypto/chelsio/chtls/chtls_io.c
#	drivers/crypto/stm32/stm32-hash.c
#	drivers/dma/mv_xor.c
#	drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v9.c
#	drivers/gpu/drm/tinydrm/repaper.c
#	drivers/gpu/drm/vc4/vc4_plane.c
#	drivers/i2c/i2c-dev.c
#	drivers/irqchip/irq-gic-v3-its.c
#	drivers/isdn/gigaset/capi.c
#	drivers/lightnvm/pblk-init.c
#	drivers/md/dm-integrity.c
#	drivers/media/platform/vivid/vivid-core.c
#	drivers/media/usb/cx231xx/cx231xx-audio.c
#	drivers/media/usb/tm6000/tm6000-video.c
#	drivers/media/usb/usbvision/usbvision-video.c
#	drivers/memstick/core/ms_block.c
#	drivers/misc/eeprom/idt_89hpesx.c
#	drivers/mtd/chips/cfi_cmdset_0002.c
#	drivers/mtd/mtdswap.c
#	drivers/mtd/tests/mtd_stresstest.c
#	drivers/net/ethernet/broadcom/bnx2.c
#	drivers/net/ethernet/moxa/moxart_ether.c
#	drivers/net/ethernet/qlogic/qed/qed_mcp.c
#	drivers/net/gtp.c
#	drivers/pinctrl/freescale/pinctrl-imx.c
#	drivers/pinctrl/freescale/pinctrl-imx1-core.c
#	drivers/pinctrl/sunxi/pinctrl-sunxi.c
#	drivers/scsi/aha1542.c
#	drivers/scsi/megaraid/megaraid_mm.c
#	drivers/soc/fsl/qbman/qman.c
#	drivers/staging/rtl8192u/ieee80211/ieee80211_rx.c
#	drivers/staging/rtl8192u/r8192U_core.c
#	drivers/tty/vt/consolemap.c
#	drivers/tty/vt/keyboard.c
#	drivers/vhost/scsi.c
#	drivers/vhost/test.c
#	drivers/vhost/vhost.c
#	drivers/virt/vboxguest/vboxguest_core.c
#	drivers/virtio/virtio_pci_common.c
#	drivers/xen/xen-pciback/pciback_ops.c
#	fs/afs/cmservice.c
#	fs/block_dev.c
#	fs/cifs/transport.c
#	fs/hpfs/dnode.c
#	fs/hpfs/map.c
#	fs/mbcache.c
#	fs/namei.c
#	fs/proc/task_mmu.c
#	fs/read_write.c
#	fs/reiserfs/journal.c
#	fs/select.c
#	fs/splice.c
#	kernel/cgroup/cgroup-v1.c
#	kernel/cpuset.c
#	kernel/fail_function.c
#	kernel/locking/locktorture.c
#	kernel/sched/topology.c
#	kernel/trace/trace.c
#	kernel/trace/trace_events_filter.c
#	kernel/user_namespace.c
#	lib/interval_tree_test.c
#	lib/rbtree_test.c
#	lib/reed_solomon/reed_solomon.c
#	mm/slub.c
#	net/9p/trans_virtio.c
#	net/can/bcm.c
#	net/netfilter/nf_tables_api.c
#	net/tipc/netlink_compat.c
#	sound/core/pcm_native.c
#	sound/pci/cs46xx/cs46xx_lib.c
#	sound/soc/codecs/wm8904.c
#	sound/soc/codecs/wm8958-dsp2.c
diff --cc arch/arm/kernel/sys_oabi-compat.c
index eb821e7b80f9,1df21a61e379..000000000000
--- a/arch/arm/kernel/sys_oabi-compat.c
+++ b/arch/arm/kernel/sys_oabi-compat.c
@@@ -279,9 -280,13 +279,15 @@@ asmlinkage long sys_oabi_epoll_wait(in
  	mm_segment_t fs;
  	long ret, err, i;
  
 -	if (maxevents <= 0 ||
 -			maxevents > (INT_MAX/sizeof(*kbuf)) ||
 -			maxevents > (INT_MAX/sizeof(*events)))
 +	if (maxevents <= 0 || maxevents > (INT_MAX/sizeof(struct epoll_event)))
  		return -EINVAL;
++<<<<<<< HEAD
 +	kbuf = kmalloc(sizeof(*kbuf) * maxevents, GFP_KERNEL);
++=======
+ 	if (!access_ok(VERIFY_WRITE, events, sizeof(*events) * maxevents))
+ 		return -EFAULT;
+ 	kbuf = kmalloc_array(maxevents, sizeof(*kbuf), GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (!kbuf)
  		return -ENOMEM;
  	fs = get_fs();
@@@ -317,7 -322,9 +323,13 @@@ asmlinkage long sys_oabi_semtimedop(in
  
  	if (nsops < 1 || nsops > SEMOPM)
  		return -EINVAL;
++<<<<<<< HEAD
 +	sops = kmalloc(sizeof(*sops) * nsops, GFP_KERNEL);
++=======
+ 	if (!access_ok(VERIFY_READ, tsops, sizeof(*tsops) * nsops))
+ 		return -EFAULT;
+ 	sops = kmalloc_array(nsops, sizeof(*sops), GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (!sops)
  		return -ENOMEM;
  	err = 0;
diff --cc arch/s390/kernel/debug.c
index 17d62fe5d7b7,d374f9b218b4..000000000000
--- a/arch/s390/kernel/debug.c
+++ b/arch/s390/kernel/debug.c
@@@ -190,29 -189,25 +190,40 @@@ static struct dentry *debug_debugfs_roo
   *   areas[areanumber][pagenumber][pageoffset]
   */
  
 -static debug_entry_t ***debug_areas_alloc(int pages_per_area, int nr_areas)
 +static debug_entry_t***
 +debug_areas_alloc(int pages_per_area, int nr_areas)
  {
 -	debug_entry_t ***areas;
 -	int i, j;
 +	debug_entry_t*** areas;
 +	int i,j;
  
++<<<<<<< HEAD
 +	areas = kmalloc(nr_areas *
 +					sizeof(debug_entry_t**),
 +					GFP_KERNEL);
 +	if (!areas)
 +		goto fail_malloc_areas;
 +	for (i = 0; i < nr_areas; i++) {
 +		areas[i] = kmalloc(pages_per_area *
 +				sizeof(debug_entry_t*),GFP_KERNEL);
 +		if (!areas[i]) {
++=======
+ 	areas = kmalloc_array(nr_areas, sizeof(debug_entry_t **), GFP_KERNEL);
+ 	if (!areas)
+ 		goto fail_malloc_areas;
+ 	for (i = 0; i < nr_areas; i++) {
+ 		areas[i] = kmalloc_array(pages_per_area,
+ 					 sizeof(debug_entry_t *),
+ 					 GFP_KERNEL);
+ 		if (!areas[i])
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  			goto fail_malloc_areas2;
 -		for (j = 0; j < pages_per_area; j++) {
 +		}
 +		for(j = 0; j < pages_per_area; j++) {
  			areas[i][j] = kzalloc(PAGE_SIZE, GFP_KERNEL);
 -			if (!areas[i][j]) {
 -				for (j--; j >= 0 ; j--)
 +			if(!areas[i][j]) {
 +				for(j--; j >=0 ; j--) {
  					kfree(areas[i][j]);
 +				}
  				kfree(areas[i]);
  				goto fail_malloc_areas2;
  			}
diff --cc arch/s390/mm/extmem.c
index 519bba716cc3,6ad15d3fab81..000000000000
--- a/arch/s390/mm/extmem.c
+++ b/arch/s390/mm/extmem.c
@@@ -103,8 -103,7 +103,12 @@@ static int scode_set
  static int
  dcss_set_subcodes(void)
  {
++<<<<<<< HEAD
 +#ifdef CONFIG_64BIT
 +	char *name = kmalloc(8 * sizeof(char), GFP_KERNEL | GFP_DMA);
++=======
+ 	char *name = kmalloc(8, GFP_KERNEL | GFP_DMA);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	unsigned long rx, ry;
  	int rc;
  
diff --cc arch/um/drivers/ubd_kern.c
index 879990cb66c6,83c470364dfb..000000000000
--- a/arch/um/drivers/ubd_kern.c
+++ b/arch/um/drivers/ubd_kern.c
@@@ -1066,6 -1126,28 +1066,31 @@@ static int __init ubd_init(void
  		if (register_blkdev(fake_major, "ubd"))
  			return -1;
  	}
++<<<<<<< HEAD
++=======
+ 
+ 	irq_req_buffer = kmalloc_array(UBD_REQ_BUFFER_SIZE,
+ 				       sizeof(struct io_thread_req *),
+ 				       GFP_KERNEL
+ 		);
+ 	irq_remainder = 0;
+ 
+ 	if (irq_req_buffer == NULL) {
+ 		printk(KERN_ERR "Failed to initialize ubd buffering\n");
+ 		return -1;
+ 	}
+ 	io_req_buffer = kmalloc_array(UBD_REQ_BUFFER_SIZE,
+ 				      sizeof(struct io_thread_req *),
+ 				      GFP_KERNEL
+ 		);
+ 
+ 	io_remainder = 0;
+ 
+ 	if (io_req_buffer == NULL) {
+ 		printk(KERN_ERR "Failed to initialize ubd buffering\n");
+ 		return -1;
+ 	}
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	platform_driver_register(&ubd_driver);
  	mutex_lock(&ubd_lock);
  	for (i = 0; i < MAX_DEV; i++){
diff --cc arch/x86/kvm/svm.c
index f67dc0d0660d,e831e6d3b70e..000000000000
--- a/arch/x86/kvm/svm.c
+++ b/arch/x86/kvm/svm.c
@@@ -922,6 -999,15 +922,18 @@@ static int svm_cpu_init(int cpu
  	if (!sd->save_area)
  		goto err_1;
  
++<<<<<<< HEAD
++=======
+ 	if (svm_sev_enabled()) {
+ 		r = -ENOMEM;
+ 		sd->sev_vmcbs = kmalloc_array(max_sev_asid + 1,
+ 					      sizeof(void *),
+ 					      GFP_KERNEL);
+ 		if (!sd->sev_vmcbs)
+ 			goto err_1;
+ 	}
+ 
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	per_cpu(svm_data, cpu) = sd;
  
  	return 0;
diff --cc arch/x86/net/bpf_jit_comp.c
index 9f43ac6fc966,2580cd2e98b1..000000000000
--- a/arch/x86/net/bpf_jit_comp.c
+++ b/arch/x86/net/bpf_jit_comp.c
@@@ -88,88 -93,1031 +88,127 @@@ do {									
  #define X86_JNE 0x75
  #define X86_JBE 0x76
  #define X86_JA  0x77
 -#define X86_JL  0x7C
 -#define X86_JGE 0x7D
 -#define X86_JLE 0x7E
 -#define X86_JG  0x7F
  
 -/* Pick a register outside of BPF range for JIT internal work */
 -#define AUX_REG (MAX_BPF_JIT_REG + 1)
 +#define EMIT_COND_JMP(op, offset)				\
 +do {								\
 +	if (is_near(offset))					\
 +		EMIT2(op, offset); /* jxx .+off8 */		\
 +	else {							\
 +		EMIT2(0x0f, op + 0x10);				\
 +		EMIT(offset, 4); /* jxx .+off32 */		\
 +	}							\
 +} while (0)
  
 -/*
 - * The following table maps BPF registers to x86-64 registers.
 - *
 - * x86-64 register R12 is unused, since if used as base address
 - * register in load/store instructions, it always needs an
 - * extra byte of encoding and is callee saved.
 - *
 - * Also x86-64 register R9 is unused. x86-64 register R10 is
 - * used for blinding (if enabled).
 - */
 -static const int reg2hex[] = {
 -	[BPF_REG_0] = 0,  /* RAX */
 -	[BPF_REG_1] = 7,  /* RDI */
 -	[BPF_REG_2] = 6,  /* RSI */
 -	[BPF_REG_3] = 2,  /* RDX */
 -	[BPF_REG_4] = 1,  /* RCX */
 -	[BPF_REG_5] = 0,  /* R8  */
 -	[BPF_REG_6] = 3,  /* RBX callee saved */
 -	[BPF_REG_7] = 5,  /* R13 callee saved */
 -	[BPF_REG_8] = 6,  /* R14 callee saved */
 -	[BPF_REG_9] = 7,  /* R15 callee saved */
 -	[BPF_REG_FP] = 5, /* RBP readonly */
 -	[BPF_REG_AX] = 2, /* R10 temp register */
 -	[AUX_REG] = 3,    /* R11 temp register */
 -};
 +#define COND_SEL(CODE, TOP, FOP)	\
 +	case CODE:			\
 +		t_op = TOP;		\
 +		f_op = FOP;		\
 +		goto cond_branch
  
 -/*
 - * is_ereg() == true if BPF register 'reg' maps to x86-64 r8..r15
 - * which need extra byte of encoding.
 - * rax,rcx,...,rbp have simpler encoding
 - */
 -static bool is_ereg(u32 reg)
 -{
 -	return (1 << reg) & (BIT(BPF_REG_5) |
 -			     BIT(AUX_REG) |
 -			     BIT(BPF_REG_7) |
 -			     BIT(BPF_REG_8) |
 -			     BIT(BPF_REG_9) |
 -			     BIT(BPF_REG_AX));
 -}
 -
 -static bool is_axreg(u32 reg)
 -{
 -	return reg == BPF_REG_0;
 -}
 -
 -/* Add modifiers if 'reg' maps to x86-64 registers R8..R15 */
 -static u8 add_1mod(u8 byte, u32 reg)
 -{
 -	if (is_ereg(reg))
 -		byte |= 1;
 -	return byte;
 -}
 -
 -static u8 add_2mod(u8 byte, u32 r1, u32 r2)
 -{
 -	if (is_ereg(r1))
 -		byte |= 1;
 -	if (is_ereg(r2))
 -		byte |= 4;
 -	return byte;
 -}
  
 -/* Encode 'dst_reg' register into x86-64 opcode 'byte' */
 -static u8 add_1reg(u8 byte, u32 dst_reg)
 -{
 -	return byte + reg2hex[dst_reg];
 -}
 +#define SEEN_DATAREF 1 /* might call external helpers */
 +#define SEEN_XREG    2 /* ebx is used */
 +#define SEEN_MEM     4 /* use mem[] for temporary storage */
  
 -/* Encode 'dst_reg' and 'src_reg' registers into x86-64 opcode 'byte' */
 -static u8 add_2reg(u8 byte, u32 dst_reg, u32 src_reg)
 +static inline void bpf_flush_icache(void *start, void *end)
  {
 -	return byte + reg2hex[dst_reg] + (reg2hex[src_reg] << 3);
 -}
 +	mm_segment_t old_fs = get_fs();
  
 -static void jit_fill_hole(void *area, unsigned int size)
 -{
 -	/* Fill whole space with INT3 instructions */
 -	memset(area, 0xcc, size);
 +	set_fs(KERNEL_DS);
 +	smp_wmb();
 +	flush_icache_range((unsigned long)start, (unsigned long)end);
 +	set_fs(old_fs);
  }
  
 -struct jit_context {
 -	int cleanup_addr; /* Epilogue code offset */
 -};
 -
 -/* Maximum number of bytes emitted while JITing one eBPF insn */
 -#define BPF_MAX_INSN_SIZE	128
 -#define BPF_INSN_SAFETY		64
 -
 -#define AUX_STACK_SPACE		40 /* Space for RBX, R13, R14, R15, tailcnt */
 -
 -#define PROLOGUE_SIZE		37
 -
 -/*
 - * Emit x86-64 prologue code for BPF program and check its size.
 - * bpf_tail_call helper will skip it while jumping into another program
 - */
 -static void emit_prologue(u8 **pprog, u32 stack_depth, bool ebpf_from_cbpf)
 -{
 -	u8 *prog = *pprog;
 -	int cnt = 0;
 -
 -	/* push rbp */
 -	EMIT1(0x55);
 -
 -	/* mov rbp,rsp */
 -	EMIT3(0x48, 0x89, 0xE5);
 -
 -	/* sub rsp, rounded_stack_depth + AUX_STACK_SPACE */
 -	EMIT3_off32(0x48, 0x81, 0xEC,
 -		    round_up(stack_depth, 8) + AUX_STACK_SPACE);
 -
 -	/* sub rbp, AUX_STACK_SPACE */
 -	EMIT4(0x48, 0x83, 0xED, AUX_STACK_SPACE);
 -
 -	/* mov qword ptr [rbp+0],rbx */
 -	EMIT4(0x48, 0x89, 0x5D, 0);
 -	/* mov qword ptr [rbp+8],r13 */
 -	EMIT4(0x4C, 0x89, 0x6D, 8);
 -	/* mov qword ptr [rbp+16],r14 */
 -	EMIT4(0x4C, 0x89, 0x75, 16);
 -	/* mov qword ptr [rbp+24],r15 */
 -	EMIT4(0x4C, 0x89, 0x7D, 24);
 -
 -	if (!ebpf_from_cbpf) {
 -		/*
 -		 * Clear the tail call counter (tail_call_cnt): for eBPF tail
 -		 * calls we need to reset the counter to 0. It's done in two
 -		 * instructions, resetting RAX register to 0, and moving it
 -		 * to the counter location.
 -		 */
 -
 -		/* xor eax, eax */
 -		EMIT2(0x31, 0xc0);
 -		/* mov qword ptr [rbp+32], rax */
 -		EMIT4(0x48, 0x89, 0x45, 32);
 -
 -		BUILD_BUG_ON(cnt != PROLOGUE_SIZE);
 -	}
 +#define CHOOSE_LOAD_FUNC(K, func) \
 +	((int)K < 0 ? ((int)K >= SKF_LL_OFF ? func##_negative_offset : func) : func##_positive_offset)
  
 -	*pprog = prog;
 -}
 -
 -/*
 - * Generate the following code:
 - *
 - * ... bpf_tail_call(void *ctx, struct bpf_array *array, u64 index) ...
 - *   if (index >= array->map.max_entries)
 - *     goto out;
 - *   if (++tail_call_cnt > MAX_TAIL_CALL_CNT)
 - *     goto out;
 - *   prog = array->ptrs[index];
 - *   if (prog == NULL)
 - *     goto out;
 - *   goto *(prog->bpf_func + prologue_size);
 - * out:
 +/* Helper to find the offset of pkt_type in sk_buff
 + * We want to make sure its still a 3bit field starting at a byte boundary.
   */
 -static void emit_bpf_tail_call(u8 **pprog)
 -{
 -	u8 *prog = *pprog;
 -	int label1, label2, label3;
 -	int cnt = 0;
 -
 -	/*
 -	 * rdi - pointer to ctx
 -	 * rsi - pointer to bpf_array
 -	 * rdx - index in bpf_array
 -	 */
 -
 -	/*
 -	 * if (index >= array->map.max_entries)
 -	 *	goto out;
 -	 */
 -	EMIT2(0x89, 0xD2);                        /* mov edx, edx */
 -	EMIT3(0x39, 0x56,                         /* cmp dword ptr [rsi + 16], edx */
 -	      offsetof(struct bpf_array, map.max_entries));
 -#define OFFSET1 (41 + RETPOLINE_RAX_BPF_JIT_SIZE) /* Number of bytes to jump */
 -	EMIT2(X86_JBE, OFFSET1);                  /* jbe out */
 -	label1 = cnt;
 -
 -	/*
 -	 * if (tail_call_cnt > MAX_TAIL_CALL_CNT)
 -	 *	goto out;
 -	 */
 -	EMIT2_off32(0x8B, 0x85, 36);              /* mov eax, dword ptr [rbp + 36] */
 -	EMIT3(0x83, 0xF8, MAX_TAIL_CALL_CNT);     /* cmp eax, MAX_TAIL_CALL_CNT */
 -#define OFFSET2 (30 + RETPOLINE_RAX_BPF_JIT_SIZE)
 -	EMIT2(X86_JA, OFFSET2);                   /* ja out */
 -	label2 = cnt;
 -	EMIT3(0x83, 0xC0, 0x01);                  /* add eax, 1 */
 -	EMIT2_off32(0x89, 0x85, 36);              /* mov dword ptr [rbp + 36], eax */
 -
 -	/* prog = array->ptrs[index]; */
 -	EMIT4_off32(0x48, 0x8B, 0x84, 0xD6,       /* mov rax, [rsi + rdx * 8 + offsetof(...)] */
 -		    offsetof(struct bpf_array, ptrs));
 -
 -	/*
 -	 * if (prog == NULL)
 -	 *	goto out;
 -	 */
 -	EMIT3(0x48, 0x85, 0xC0);		  /* test rax,rax */
 -#define OFFSET3 (8 + RETPOLINE_RAX_BPF_JIT_SIZE)
 -	EMIT2(X86_JE, OFFSET3);                   /* je out */
 -	label3 = cnt;
 -
 -	/* goto *(prog->bpf_func + prologue_size); */
 -	EMIT4(0x48, 0x8B, 0x40,                   /* mov rax, qword ptr [rax + 32] */
 -	      offsetof(struct bpf_prog, bpf_func));
 -	EMIT4(0x48, 0x83, 0xC0, PROLOGUE_SIZE);   /* add rax, prologue_size */
 -
 -	/*
 -	 * Wow we're ready to jump into next BPF program
 -	 * rdi == ctx (1st arg)
 -	 * rax == prog->bpf_func + prologue_size
 -	 */
 -	RETPOLINE_RAX_BPF_JIT();
 -
 -	/* out: */
 -	BUILD_BUG_ON(cnt - label1 != OFFSET1);
 -	BUILD_BUG_ON(cnt - label2 != OFFSET2);
 -	BUILD_BUG_ON(cnt - label3 != OFFSET3);
 -	*pprog = prog;
 -}
 -
 -static void emit_mov_imm32(u8 **pprog, bool sign_propagate,
 -			   u32 dst_reg, const u32 imm32)
 -{
 -	u8 *prog = *pprog;
 -	u8 b1, b2, b3;
 -	int cnt = 0;
 -
 -	/*
 -	 * Optimization: if imm32 is positive, use 'mov %eax, imm32'
 -	 * (which zero-extends imm32) to save 2 bytes.
 -	 */
 -	if (sign_propagate && (s32)imm32 < 0) {
 -		/* 'mov %rax, imm32' sign extends imm32 */
 -		b1 = add_1mod(0x48, dst_reg);
 -		b2 = 0xC7;
 -		b3 = 0xC0;
 -		EMIT3_off32(b1, b2, add_1reg(b3, dst_reg), imm32);
 -		goto done;
 -	}
 -
 -	/*
 -	 * Optimization: if imm32 is zero, use 'xor %eax, %eax'
 -	 * to save 3 bytes.
 -	 */
 -	if (imm32 == 0) {
 -		if (is_ereg(dst_reg))
 -			EMIT1(add_2mod(0x40, dst_reg, dst_reg));
 -		b2 = 0x31; /* xor */
 -		b3 = 0xC0;
 -		EMIT2(b2, add_2reg(b3, dst_reg, dst_reg));
 -		goto done;
 -	}
 -
 -	/* mov %eax, imm32 */
 -	if (is_ereg(dst_reg))
 -		EMIT1(add_1mod(0x40, dst_reg));
 -	EMIT1_off32(add_1reg(0xB8, dst_reg), imm32);
 -done:
 -	*pprog = prog;
 -}
 -
 -static void emit_mov_imm64(u8 **pprog, u32 dst_reg,
 -			   const u32 imm32_hi, const u32 imm32_lo)
 +#define PKT_TYPE_MAX 7
 +static int pkt_type_offset(void)
  {
 -	u8 *prog = *pprog;
 -	int cnt = 0;
 -
 -	if (is_uimm32(((u64)imm32_hi << 32) | (u32)imm32_lo)) {
 -		/*
 -		 * For emitting plain u32, where sign bit must not be
 -		 * propagated LLVM tends to load imm64 over mov32
 -		 * directly, so save couple of bytes by just doing
 -		 * 'mov %eax, imm32' instead.
 -		 */
 -		emit_mov_imm32(&prog, false, dst_reg, imm32_lo);
 -	} else {
 -		/* movabsq %rax, imm64 */
 -		EMIT2(add_1mod(0x48, dst_reg), add_1reg(0xB8, dst_reg));
 -		EMIT(imm32_lo, 4);
 -		EMIT(imm32_hi, 4);
 -	}
 -
 -	*pprog = prog;
 -}
 -
 -static void emit_mov_reg(u8 **pprog, bool is64, u32 dst_reg, u32 src_reg)
 -{
 -	u8 *prog = *pprog;
 -	int cnt = 0;
 -
 -	if (is64) {
 -		/* mov dst, src */
 -		EMIT_mov(dst_reg, src_reg);
 -	} else {
 -		/* mov32 dst, src */
 -		if (is_ereg(dst_reg) || is_ereg(src_reg))
 -			EMIT1(add_2mod(0x40, dst_reg, src_reg));
 -		EMIT2(0x89, add_2reg(0xC0, dst_reg, src_reg));
 -	}
 -
 -	*pprog = prog;
 -}
 -
 -static int do_jit(struct bpf_prog *bpf_prog, int *addrs, u8 *image,
 -		  int oldproglen, struct jit_context *ctx)
 -{
 -	struct bpf_insn *insn = bpf_prog->insnsi;
 -	int insn_cnt = bpf_prog->len;
 -	bool seen_exit = false;
 -	u8 temp[BPF_MAX_INSN_SIZE + BPF_INSN_SAFETY];
 -	int i, cnt = 0;
 -	int proglen = 0;
 -	u8 *prog = temp;
 -
 -	emit_prologue(&prog, bpf_prog->aux->stack_depth,
 -		      bpf_prog_was_classic(bpf_prog));
 -
 -	for (i = 0; i < insn_cnt; i++, insn++) {
 -		const s32 imm32 = insn->imm;
 -		u32 dst_reg = insn->dst_reg;
 -		u32 src_reg = insn->src_reg;
 -		u8 b2 = 0, b3 = 0;
 -		s64 jmp_offset;
 -		u8 jmp_cond;
 -		int ilen;
 -		u8 *func;
 -
 -		switch (insn->code) {
 -			/* ALU */
 -		case BPF_ALU | BPF_ADD | BPF_X:
 -		case BPF_ALU | BPF_SUB | BPF_X:
 -		case BPF_ALU | BPF_AND | BPF_X:
 -		case BPF_ALU | BPF_OR | BPF_X:
 -		case BPF_ALU | BPF_XOR | BPF_X:
 -		case BPF_ALU64 | BPF_ADD | BPF_X:
 -		case BPF_ALU64 | BPF_SUB | BPF_X:
 -		case BPF_ALU64 | BPF_AND | BPF_X:
 -		case BPF_ALU64 | BPF_OR | BPF_X:
 -		case BPF_ALU64 | BPF_XOR | BPF_X:
 -			switch (BPF_OP(insn->code)) {
 -			case BPF_ADD: b2 = 0x01; break;
 -			case BPF_SUB: b2 = 0x29; break;
 -			case BPF_AND: b2 = 0x21; break;
 -			case BPF_OR: b2 = 0x09; break;
 -			case BPF_XOR: b2 = 0x31; break;
 -			}
 -			if (BPF_CLASS(insn->code) == BPF_ALU64)
 -				EMIT1(add_2mod(0x48, dst_reg, src_reg));
 -			else if (is_ereg(dst_reg) || is_ereg(src_reg))
 -				EMIT1(add_2mod(0x40, dst_reg, src_reg));
 -			EMIT2(b2, add_2reg(0xC0, dst_reg, src_reg));
 -			break;
 -
 -		case BPF_ALU64 | BPF_MOV | BPF_X:
 -		case BPF_ALU | BPF_MOV | BPF_X:
 -			emit_mov_reg(&prog,
 -				     BPF_CLASS(insn->code) == BPF_ALU64,
 -				     dst_reg, src_reg);
 -			break;
 -
 -			/* neg dst */
 -		case BPF_ALU | BPF_NEG:
 -		case BPF_ALU64 | BPF_NEG:
 -			if (BPF_CLASS(insn->code) == BPF_ALU64)
 -				EMIT1(add_1mod(0x48, dst_reg));
 -			else if (is_ereg(dst_reg))
 -				EMIT1(add_1mod(0x40, dst_reg));
 -			EMIT2(0xF7, add_1reg(0xD8, dst_reg));
 -			break;
 -
 -		case BPF_ALU | BPF_ADD | BPF_K:
 -		case BPF_ALU | BPF_SUB | BPF_K:
 -		case BPF_ALU | BPF_AND | BPF_K:
 -		case BPF_ALU | BPF_OR | BPF_K:
 -		case BPF_ALU | BPF_XOR | BPF_K:
 -		case BPF_ALU64 | BPF_ADD | BPF_K:
 -		case BPF_ALU64 | BPF_SUB | BPF_K:
 -		case BPF_ALU64 | BPF_AND | BPF_K:
 -		case BPF_ALU64 | BPF_OR | BPF_K:
 -		case BPF_ALU64 | BPF_XOR | BPF_K:
 -			if (BPF_CLASS(insn->code) == BPF_ALU64)
 -				EMIT1(add_1mod(0x48, dst_reg));
 -			else if (is_ereg(dst_reg))
 -				EMIT1(add_1mod(0x40, dst_reg));
 -
 -			/*
 -			 * b3 holds 'normal' opcode, b2 short form only valid
 -			 * in case dst is eax/rax.
 -			 */
 -			switch (BPF_OP(insn->code)) {
 -			case BPF_ADD:
 -				b3 = 0xC0;
 -				b2 = 0x05;
 -				break;
 -			case BPF_SUB:
 -				b3 = 0xE8;
 -				b2 = 0x2D;
 -				break;
 -			case BPF_AND:
 -				b3 = 0xE0;
 -				b2 = 0x25;
 -				break;
 -			case BPF_OR:
 -				b3 = 0xC8;
 -				b2 = 0x0D;
 -				break;
 -			case BPF_XOR:
 -				b3 = 0xF0;
 -				b2 = 0x35;
 -				break;
 -			}
 -
 -			if (is_imm8(imm32))
 -				EMIT3(0x83, add_1reg(b3, dst_reg), imm32);
 -			else if (is_axreg(dst_reg))
 -				EMIT1_off32(b2, imm32);
 -			else
 -				EMIT2_off32(0x81, add_1reg(b3, dst_reg), imm32);
 -			break;
 -
 -		case BPF_ALU64 | BPF_MOV | BPF_K:
 -		case BPF_ALU | BPF_MOV | BPF_K:
 -			emit_mov_imm32(&prog, BPF_CLASS(insn->code) == BPF_ALU64,
 -				       dst_reg, imm32);
 -			break;
 -
 -		case BPF_LD | BPF_IMM | BPF_DW:
 -			emit_mov_imm64(&prog, dst_reg, insn[1].imm, insn[0].imm);
 -			insn++;
 -			i++;
 -			break;
 -
 -			/* dst %= src, dst /= src, dst %= imm32, dst /= imm32 */
 -		case BPF_ALU | BPF_MOD | BPF_X:
 -		case BPF_ALU | BPF_DIV | BPF_X:
 -		case BPF_ALU | BPF_MOD | BPF_K:
 -		case BPF_ALU | BPF_DIV | BPF_K:
 -		case BPF_ALU64 | BPF_MOD | BPF_X:
 -		case BPF_ALU64 | BPF_DIV | BPF_X:
 -		case BPF_ALU64 | BPF_MOD | BPF_K:
 -		case BPF_ALU64 | BPF_DIV | BPF_K:
 -			EMIT1(0x50); /* push rax */
 -			EMIT1(0x52); /* push rdx */
 -
 -			if (BPF_SRC(insn->code) == BPF_X)
 -				/* mov r11, src_reg */
 -				EMIT_mov(AUX_REG, src_reg);
 -			else
 -				/* mov r11, imm32 */
 -				EMIT3_off32(0x49, 0xC7, 0xC3, imm32);
 -
 -			/* mov rax, dst_reg */
 -			EMIT_mov(BPF_REG_0, dst_reg);
 -
 -			/*
 -			 * xor edx, edx
 -			 * equivalent to 'xor rdx, rdx', but one byte less
 -			 */
 -			EMIT2(0x31, 0xd2);
 -
 -			if (BPF_CLASS(insn->code) == BPF_ALU64)
 -				/* div r11 */
 -				EMIT3(0x49, 0xF7, 0xF3);
 -			else
 -				/* div r11d */
 -				EMIT3(0x41, 0xF7, 0xF3);
 -
 -			if (BPF_OP(insn->code) == BPF_MOD)
 -				/* mov r11, rdx */
 -				EMIT3(0x49, 0x89, 0xD3);
 -			else
 -				/* mov r11, rax */
 -				EMIT3(0x49, 0x89, 0xC3);
 -
 -			EMIT1(0x5A); /* pop rdx */
 -			EMIT1(0x58); /* pop rax */
 -
 -			/* mov dst_reg, r11 */
 -			EMIT_mov(dst_reg, AUX_REG);
 -			break;
 -
 -		case BPF_ALU | BPF_MUL | BPF_K:
 -		case BPF_ALU | BPF_MUL | BPF_X:
 -		case BPF_ALU64 | BPF_MUL | BPF_K:
 -		case BPF_ALU64 | BPF_MUL | BPF_X:
 -		{
 -			bool is64 = BPF_CLASS(insn->code) == BPF_ALU64;
 -
 -			if (dst_reg != BPF_REG_0)
 -				EMIT1(0x50); /* push rax */
 -			if (dst_reg != BPF_REG_3)
 -				EMIT1(0x52); /* push rdx */
 -
 -			/* mov r11, dst_reg */
 -			EMIT_mov(AUX_REG, dst_reg);
 -
 -			if (BPF_SRC(insn->code) == BPF_X)
 -				emit_mov_reg(&prog, is64, BPF_REG_0, src_reg);
 -			else
 -				emit_mov_imm32(&prog, is64, BPF_REG_0, imm32);
 -
 -			if (is64)
 -				EMIT1(add_1mod(0x48, AUX_REG));
 -			else if (is_ereg(AUX_REG))
 -				EMIT1(add_1mod(0x40, AUX_REG));
 -			/* mul(q) r11 */
 -			EMIT2(0xF7, add_1reg(0xE0, AUX_REG));
 -
 -			if (dst_reg != BPF_REG_3)
 -				EMIT1(0x5A); /* pop rdx */
 -			if (dst_reg != BPF_REG_0) {
 -				/* mov dst_reg, rax */
 -				EMIT_mov(dst_reg, BPF_REG_0);
 -				EMIT1(0x58); /* pop rax */
 -			}
 -			break;
 -		}
 -			/* Shifts */
 -		case BPF_ALU | BPF_LSH | BPF_K:
 -		case BPF_ALU | BPF_RSH | BPF_K:
 -		case BPF_ALU | BPF_ARSH | BPF_K:
 -		case BPF_ALU64 | BPF_LSH | BPF_K:
 -		case BPF_ALU64 | BPF_RSH | BPF_K:
 -		case BPF_ALU64 | BPF_ARSH | BPF_K:
 -			if (BPF_CLASS(insn->code) == BPF_ALU64)
 -				EMIT1(add_1mod(0x48, dst_reg));
 -			else if (is_ereg(dst_reg))
 -				EMIT1(add_1mod(0x40, dst_reg));
 -
 -			switch (BPF_OP(insn->code)) {
 -			case BPF_LSH: b3 = 0xE0; break;
 -			case BPF_RSH: b3 = 0xE8; break;
 -			case BPF_ARSH: b3 = 0xF8; break;
 -			}
 -
 -			if (imm32 == 1)
 -				EMIT2(0xD1, add_1reg(b3, dst_reg));
 -			else
 -				EMIT3(0xC1, add_1reg(b3, dst_reg), imm32);
 -			break;
 -
 -		case BPF_ALU | BPF_LSH | BPF_X:
 -		case BPF_ALU | BPF_RSH | BPF_X:
 -		case BPF_ALU | BPF_ARSH | BPF_X:
 -		case BPF_ALU64 | BPF_LSH | BPF_X:
 -		case BPF_ALU64 | BPF_RSH | BPF_X:
 -		case BPF_ALU64 | BPF_ARSH | BPF_X:
 -
 -			/* Check for bad case when dst_reg == rcx */
 -			if (dst_reg == BPF_REG_4) {
 -				/* mov r11, dst_reg */
 -				EMIT_mov(AUX_REG, dst_reg);
 -				dst_reg = AUX_REG;
 -			}
 -
 -			if (src_reg != BPF_REG_4) { /* common case */
 -				EMIT1(0x51); /* push rcx */
 -
 -				/* mov rcx, src_reg */
 -				EMIT_mov(BPF_REG_4, src_reg);
 -			}
 -
 -			/* shl %rax, %cl | shr %rax, %cl | sar %rax, %cl */
 -			if (BPF_CLASS(insn->code) == BPF_ALU64)
 -				EMIT1(add_1mod(0x48, dst_reg));
 -			else if (is_ereg(dst_reg))
 -				EMIT1(add_1mod(0x40, dst_reg));
 -
 -			switch (BPF_OP(insn->code)) {
 -			case BPF_LSH: b3 = 0xE0; break;
 -			case BPF_RSH: b3 = 0xE8; break;
 -			case BPF_ARSH: b3 = 0xF8; break;
 -			}
 -			EMIT2(0xD3, add_1reg(b3, dst_reg));
 -
 -			if (src_reg != BPF_REG_4)
 -				EMIT1(0x59); /* pop rcx */
 -
 -			if (insn->dst_reg == BPF_REG_4)
 -				/* mov dst_reg, r11 */
 -				EMIT_mov(insn->dst_reg, AUX_REG);
 -			break;
 -
 -		case BPF_ALU | BPF_END | BPF_FROM_BE:
 -			switch (imm32) {
 -			case 16:
 -				/* Emit 'ror %ax, 8' to swap lower 2 bytes */
 -				EMIT1(0x66);
 -				if (is_ereg(dst_reg))
 -					EMIT1(0x41);
 -				EMIT3(0xC1, add_1reg(0xC8, dst_reg), 8);
 -
 -				/* Emit 'movzwl eax, ax' */
 -				if (is_ereg(dst_reg))
 -					EMIT3(0x45, 0x0F, 0xB7);
 -				else
 -					EMIT2(0x0F, 0xB7);
 -				EMIT1(add_2reg(0xC0, dst_reg, dst_reg));
 -				break;
 -			case 32:
 -				/* Emit 'bswap eax' to swap lower 4 bytes */
 -				if (is_ereg(dst_reg))
 -					EMIT2(0x41, 0x0F);
 -				else
 -					EMIT1(0x0F);
 -				EMIT1(add_1reg(0xC8, dst_reg));
 -				break;
 -			case 64:
 -				/* Emit 'bswap rax' to swap 8 bytes */
 -				EMIT3(add_1mod(0x48, dst_reg), 0x0F,
 -				      add_1reg(0xC8, dst_reg));
 -				break;
 -			}
 -			break;
 -
 -		case BPF_ALU | BPF_END | BPF_FROM_LE:
 -			switch (imm32) {
 -			case 16:
 -				/*
 -				 * Emit 'movzwl eax, ax' to zero extend 16-bit
 -				 * into 64 bit
 -				 */
 -				if (is_ereg(dst_reg))
 -					EMIT3(0x45, 0x0F, 0xB7);
 -				else
 -					EMIT2(0x0F, 0xB7);
 -				EMIT1(add_2reg(0xC0, dst_reg, dst_reg));
 -				break;
 -			case 32:
 -				/* Emit 'mov eax, eax' to clear upper 32-bits */
 -				if (is_ereg(dst_reg))
 -					EMIT1(0x45);
 -				EMIT2(0x89, add_2reg(0xC0, dst_reg, dst_reg));
 -				break;
 -			case 64:
 -				/* nop */
 -				break;
 -			}
 -			break;
 -
 -			/* ST: *(u8*)(dst_reg + off) = imm */
 -		case BPF_ST | BPF_MEM | BPF_B:
 -			if (is_ereg(dst_reg))
 -				EMIT2(0x41, 0xC6);
 -			else
 -				EMIT1(0xC6);
 -			goto st;
 -		case BPF_ST | BPF_MEM | BPF_H:
 -			if (is_ereg(dst_reg))
 -				EMIT3(0x66, 0x41, 0xC7);
 -			else
 -				EMIT2(0x66, 0xC7);
 -			goto st;
 -		case BPF_ST | BPF_MEM | BPF_W:
 -			if (is_ereg(dst_reg))
 -				EMIT2(0x41, 0xC7);
 -			else
 -				EMIT1(0xC7);
 -			goto st;
 -		case BPF_ST | BPF_MEM | BPF_DW:
 -			EMIT2(add_1mod(0x48, dst_reg), 0xC7);
 -
 -st:			if (is_imm8(insn->off))
 -				EMIT2(add_1reg(0x40, dst_reg), insn->off);
 -			else
 -				EMIT1_off32(add_1reg(0x80, dst_reg), insn->off);
 -
 -			EMIT(imm32, bpf_size_to_x86_bytes(BPF_SIZE(insn->code)));
 -			break;
 -
 -			/* STX: *(u8*)(dst_reg + off) = src_reg */
 -		case BPF_STX | BPF_MEM | BPF_B:
 -			/* Emit 'mov byte ptr [rax + off], al' */
 -			if (is_ereg(dst_reg) || is_ereg(src_reg) ||
 -			    /* We have to add extra byte for x86 SIL, DIL regs */
 -			    src_reg == BPF_REG_1 || src_reg == BPF_REG_2)
 -				EMIT2(add_2mod(0x40, dst_reg, src_reg), 0x88);
 -			else
 -				EMIT1(0x88);
 -			goto stx;
 -		case BPF_STX | BPF_MEM | BPF_H:
 -			if (is_ereg(dst_reg) || is_ereg(src_reg))
 -				EMIT3(0x66, add_2mod(0x40, dst_reg, src_reg), 0x89);
 -			else
 -				EMIT2(0x66, 0x89);
 -			goto stx;
 -		case BPF_STX | BPF_MEM | BPF_W:
 -			if (is_ereg(dst_reg) || is_ereg(src_reg))
 -				EMIT2(add_2mod(0x40, dst_reg, src_reg), 0x89);
 -			else
 -				EMIT1(0x89);
 -			goto stx;
 -		case BPF_STX | BPF_MEM | BPF_DW:
 -			EMIT2(add_2mod(0x48, dst_reg, src_reg), 0x89);
 -stx:			if (is_imm8(insn->off))
 -				EMIT2(add_2reg(0x40, dst_reg, src_reg), insn->off);
 -			else
 -				EMIT1_off32(add_2reg(0x80, dst_reg, src_reg),
 -					    insn->off);
 -			break;
 -
 -			/* LDX: dst_reg = *(u8*)(src_reg + off) */
 -		case BPF_LDX | BPF_MEM | BPF_B:
 -			/* Emit 'movzx rax, byte ptr [rax + off]' */
 -			EMIT3(add_2mod(0x48, src_reg, dst_reg), 0x0F, 0xB6);
 -			goto ldx;
 -		case BPF_LDX | BPF_MEM | BPF_H:
 -			/* Emit 'movzx rax, word ptr [rax + off]' */
 -			EMIT3(add_2mod(0x48, src_reg, dst_reg), 0x0F, 0xB7);
 -			goto ldx;
 -		case BPF_LDX | BPF_MEM | BPF_W:
 -			/* Emit 'mov eax, dword ptr [rax+0x14]' */
 -			if (is_ereg(dst_reg) || is_ereg(src_reg))
 -				EMIT2(add_2mod(0x40, src_reg, dst_reg), 0x8B);
 -			else
 -				EMIT1(0x8B);
 -			goto ldx;
 -		case BPF_LDX | BPF_MEM | BPF_DW:
 -			/* Emit 'mov rax, qword ptr [rax+0x14]' */
 -			EMIT2(add_2mod(0x48, src_reg, dst_reg), 0x8B);
 -ldx:			/*
 -			 * If insn->off == 0 we can save one extra byte, but
 -			 * special case of x86 R13 which always needs an offset
 -			 * is not worth the hassle
 -			 */
 -			if (is_imm8(insn->off))
 -				EMIT2(add_2reg(0x40, src_reg, dst_reg), insn->off);
 -			else
 -				EMIT1_off32(add_2reg(0x80, src_reg, dst_reg),
 -					    insn->off);
 -			break;
 -
 -			/* STX XADD: lock *(u32*)(dst_reg + off) += src_reg */
 -		case BPF_STX | BPF_XADD | BPF_W:
 -			/* Emit 'lock add dword ptr [rax + off], eax' */
 -			if (is_ereg(dst_reg) || is_ereg(src_reg))
 -				EMIT3(0xF0, add_2mod(0x40, dst_reg, src_reg), 0x01);
 -			else
 -				EMIT2(0xF0, 0x01);
 -			goto xadd;
 -		case BPF_STX | BPF_XADD | BPF_DW:
 -			EMIT3(0xF0, add_2mod(0x48, dst_reg, src_reg), 0x01);
 -xadd:			if (is_imm8(insn->off))
 -				EMIT2(add_2reg(0x40, dst_reg, src_reg), insn->off);
 -			else
 -				EMIT1_off32(add_2reg(0x80, dst_reg, src_reg),
 -					    insn->off);
 -			break;
 -
 -			/* call */
 -		case BPF_JMP | BPF_CALL:
 -			func = (u8 *) __bpf_call_base + imm32;
 -			jmp_offset = func - (image + addrs[i]);
 -			if (!imm32 || !is_simm32(jmp_offset)) {
 -				pr_err("unsupported BPF func %d addr %p image %p\n",
 -				       imm32, func, image);
 -				return -EINVAL;
 -			}
 -			EMIT1_off32(0xE8, jmp_offset);
 -			break;
 -
 -		case BPF_JMP | BPF_TAIL_CALL:
 -			emit_bpf_tail_call(&prog);
 -			break;
 -
 -			/* cond jump */
 -		case BPF_JMP | BPF_JEQ | BPF_X:
 -		case BPF_JMP | BPF_JNE | BPF_X:
 -		case BPF_JMP | BPF_JGT | BPF_X:
 -		case BPF_JMP | BPF_JLT | BPF_X:
 -		case BPF_JMP | BPF_JGE | BPF_X:
 -		case BPF_JMP | BPF_JLE | BPF_X:
 -		case BPF_JMP | BPF_JSGT | BPF_X:
 -		case BPF_JMP | BPF_JSLT | BPF_X:
 -		case BPF_JMP | BPF_JSGE | BPF_X:
 -		case BPF_JMP | BPF_JSLE | BPF_X:
 -			/* cmp dst_reg, src_reg */
 -			EMIT3(add_2mod(0x48, dst_reg, src_reg), 0x39,
 -			      add_2reg(0xC0, dst_reg, src_reg));
 -			goto emit_cond_jmp;
 -
 -		case BPF_JMP | BPF_JSET | BPF_X:
 -			/* test dst_reg, src_reg */
 -			EMIT3(add_2mod(0x48, dst_reg, src_reg), 0x85,
 -			      add_2reg(0xC0, dst_reg, src_reg));
 -			goto emit_cond_jmp;
 -
 -		case BPF_JMP | BPF_JSET | BPF_K:
 -			/* test dst_reg, imm32 */
 -			EMIT1(add_1mod(0x48, dst_reg));
 -			EMIT2_off32(0xF7, add_1reg(0xC0, dst_reg), imm32);
 -			goto emit_cond_jmp;
 -
 -		case BPF_JMP | BPF_JEQ | BPF_K:
 -		case BPF_JMP | BPF_JNE | BPF_K:
 -		case BPF_JMP | BPF_JGT | BPF_K:
 -		case BPF_JMP | BPF_JLT | BPF_K:
 -		case BPF_JMP | BPF_JGE | BPF_K:
 -		case BPF_JMP | BPF_JLE | BPF_K:
 -		case BPF_JMP | BPF_JSGT | BPF_K:
 -		case BPF_JMP | BPF_JSLT | BPF_K:
 -		case BPF_JMP | BPF_JSGE | BPF_K:
 -		case BPF_JMP | BPF_JSLE | BPF_K:
 -			/* cmp dst_reg, imm8/32 */
 -			EMIT1(add_1mod(0x48, dst_reg));
 -
 -			if (is_imm8(imm32))
 -				EMIT3(0x83, add_1reg(0xF8, dst_reg), imm32);
 -			else
 -				EMIT2_off32(0x81, add_1reg(0xF8, dst_reg), imm32);
 -
 -emit_cond_jmp:		/* Convert BPF opcode to x86 */
 -			switch (BPF_OP(insn->code)) {
 -			case BPF_JEQ:
 -				jmp_cond = X86_JE;
 -				break;
 -			case BPF_JSET:
 -			case BPF_JNE:
 -				jmp_cond = X86_JNE;
 -				break;
 -			case BPF_JGT:
 -				/* GT is unsigned '>', JA in x86 */
 -				jmp_cond = X86_JA;
 -				break;
 -			case BPF_JLT:
 -				/* LT is unsigned '<', JB in x86 */
 -				jmp_cond = X86_JB;
 -				break;
 -			case BPF_JGE:
 -				/* GE is unsigned '>=', JAE in x86 */
 -				jmp_cond = X86_JAE;
 -				break;
 -			case BPF_JLE:
 -				/* LE is unsigned '<=', JBE in x86 */
 -				jmp_cond = X86_JBE;
 -				break;
 -			case BPF_JSGT:
 -				/* Signed '>', GT in x86 */
 -				jmp_cond = X86_JG;
 -				break;
 -			case BPF_JSLT:
 -				/* Signed '<', LT in x86 */
 -				jmp_cond = X86_JL;
 -				break;
 -			case BPF_JSGE:
 -				/* Signed '>=', GE in x86 */
 -				jmp_cond = X86_JGE;
 -				break;
 -			case BPF_JSLE:
 -				/* Signed '<=', LE in x86 */
 -				jmp_cond = X86_JLE;
 -				break;
 -			default: /* to silence GCC warning */
 -				return -EFAULT;
 -			}
 -			jmp_offset = addrs[i + insn->off] - addrs[i];
 -			if (is_imm8(jmp_offset)) {
 -				EMIT2(jmp_cond, jmp_offset);
 -			} else if (is_simm32(jmp_offset)) {
 -				EMIT2_off32(0x0F, jmp_cond + 0x10, jmp_offset);
 -			} else {
 -				pr_err("cond_jmp gen bug %llx\n", jmp_offset);
 -				return -EFAULT;
 -			}
 -
 -			break;
 -
 -		case BPF_JMP | BPF_JA:
 -			if (insn->off == -1)
 -				/* -1 jmp instructions will always jump
 -				 * backwards two bytes. Explicitly handling
 -				 * this case avoids wasting too many passes
 -				 * when there are long sequences of replaced
 -				 * dead code.
 -				 */
 -				jmp_offset = -2;
 -			else
 -				jmp_offset = addrs[i + insn->off] - addrs[i];
 -
 -			if (!jmp_offset)
 -				/* Optimize out nop jumps */
 -				break;
 -emit_jmp:
 -			if (is_imm8(jmp_offset)) {
 -				EMIT2(0xEB, jmp_offset);
 -			} else if (is_simm32(jmp_offset)) {
 -				EMIT1_off32(0xE9, jmp_offset);
 -			} else {
 -				pr_err("jmp gen bug %llx\n", jmp_offset);
 -				return -EFAULT;
 -			}
 -			break;
 -
 -		case BPF_JMP | BPF_EXIT:
 -			if (seen_exit) {
 -				jmp_offset = ctx->cleanup_addr - addrs[i];
 -				goto emit_jmp;
 -			}
 -			seen_exit = true;
 -			/* Update cleanup_addr */
 -			ctx->cleanup_addr = proglen;
 -			/* mov rbx, qword ptr [rbp+0] */
 -			EMIT4(0x48, 0x8B, 0x5D, 0);
 -			/* mov r13, qword ptr [rbp+8] */
 -			EMIT4(0x4C, 0x8B, 0x6D, 8);
 -			/* mov r14, qword ptr [rbp+16] */
 -			EMIT4(0x4C, 0x8B, 0x75, 16);
 -			/* mov r15, qword ptr [rbp+24] */
 -			EMIT4(0x4C, 0x8B, 0x7D, 24);
 -
 -			/* add rbp, AUX_STACK_SPACE */
 -			EMIT4(0x48, 0x83, 0xC5, AUX_STACK_SPACE);
 -			EMIT1(0xC9); /* leave */
 -			EMIT1(0xC3); /* ret */
 -			break;
 -
 -		default:
 -			/*
 -			 * By design x86-64 JIT should support all BPF instructions.
 -			 * This error will be seen if new instruction was added
 -			 * to the interpreter, but not to the JIT, or if there is
 -			 * junk in bpf_prog.
 -			 */
 -			pr_err("bpf_jit: unknown opcode %02x\n", insn->code);
 -			return -EINVAL;
 -		}
 -
 -		ilen = prog - temp;
 -		if (ilen > BPF_MAX_INSN_SIZE) {
 -			pr_err("bpf_jit: fatal insn size error\n");
 -			return -EFAULT;
 -		}
 -
 -		if (image) {
 -			if (unlikely(proglen + ilen > oldproglen)) {
 -				pr_err("bpf_jit: fatal error\n");
 -				return -EFAULT;
 -			}
 -			memcpy(image + proglen, temp, ilen);
 -		}
 -		proglen += ilen;
 -		addrs[i] = proglen;
 -		prog = temp;
 +	struct sk_buff skb_probe = {
 +		.pkt_type = ~0,
 +	};
 +	char *ct = (char *)&skb_probe;
 +	unsigned int off;
 +
 +	for (off = 0; off < sizeof(struct sk_buff); off++) {
 +		if (ct[off] == PKT_TYPE_MAX)
 +			return off;
  	}
 -	return proglen;
 +	pr_err_once("Please fix pkt_type_offset(), as pkt_type couldn't be found\n");
 +	return -1;
  }
  
 -struct x64_jit_data {
 -	struct bpf_binary_header *header;
 -	int *addrs;
 -	u8 *image;
 -	int proglen;
 -	struct jit_context ctx;
 -};
 -
 -struct bpf_prog *bpf_int_jit_compile(struct bpf_prog *prog)
 +void bpf_jit_compile(struct sk_filter *fp)
  {
 -	struct bpf_binary_header *header = NULL;
 -	struct bpf_prog *tmp, *orig_prog = prog;
 -	struct x64_jit_data *jit_data;
 -	int proglen, oldproglen = 0;
 -	struct jit_context ctx = {};
 -	bool tmp_blinded = false;
 -	bool extra_pass = false;
 +	u8 temp[64];
 +	u8 *prog;
 +	unsigned int proglen, oldproglen = 0;
 +	int ilen, i;
 +	int t_offset, f_offset;
 +	u8 t_op, f_op, seen = 0, pass;
  	u8 *image = NULL;
 -	int *addrs;
 -	int pass;
 -	int i;
 -
 -	if (!prog->jit_requested)
 -		return orig_prog;
 -
 -	tmp = bpf_jit_blind_constants(prog);
 -	/*
 -	 * If blinding was requested and we failed during blinding,
 -	 * we must fall back to the interpreter.
 +	u8 *func;
 +	int pc_ret0 = -1; /* bpf index of first RET #0 instruction (if any) */
 +	unsigned int cleanup_addr; /* epilogue code offset */
 +	unsigned int *addrs;
 +	const struct sock_filter *filter = fp->insns;
 +	int flen = fp->len;
 +
 +	if (!bpf_jit_enable)
 +		return;
 +
 +	addrs = kmalloc(flen * sizeof(*addrs), GFP_KERNEL);
 +	if (addrs == NULL)
 +		return;
 +
 +	/* Before first pass, make a rough estimation of addrs[]
 +	 * each bpf instruction is translated to less than 64 bytes
  	 */
++<<<<<<< HEAD
 +	for (proglen = 0, i = 0; i < flen; i++) {
++=======
+ 	if (IS_ERR(tmp))
+ 		return orig_prog;
+ 	if (tmp != prog) {
+ 		tmp_blinded = true;
+ 		prog = tmp;
+ 	}
+ 
+ 	jit_data = prog->aux->jit_data;
+ 	if (!jit_data) {
+ 		jit_data = kzalloc(sizeof(*jit_data), GFP_KERNEL);
+ 		if (!jit_data) {
+ 			prog = orig_prog;
+ 			goto out;
+ 		}
+ 		prog->aux->jit_data = jit_data;
+ 	}
+ 	addrs = jit_data->addrs;
+ 	if (addrs) {
+ 		ctx = jit_data->ctx;
+ 		oldproglen = jit_data->proglen;
+ 		image = jit_data->image;
+ 		header = jit_data->header;
+ 		extra_pass = true;
+ 		goto skip_init_addrs;
+ 	}
+ 	addrs = kmalloc_array(prog->len, sizeof(*addrs), GFP_KERNEL);
+ 	if (!addrs) {
+ 		prog = orig_prog;
+ 		goto out_addrs;
+ 	}
+ 
+ 	/*
+ 	 * Before first pass, make a rough estimation of addrs[]
+ 	 * each BPF instruction is translated to less than 64 bytes
+ 	 */
+ 	for (proglen = 0, i = 0; i < prog->len; i++) {
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  		proglen += 64;
  		addrs[i] = proglen;
  	}
diff --cc crypto/testmgr.c
index 673c85b2c7d0,11e45352fd0b..000000000000
--- a/crypto/testmgr.c
+++ b/crypto/testmgr.c
@@@ -405,11 -603,11 +405,16 @@@ static int __test_aead(struct crypto_ae
  		goto out_nooutbuf;
  
  	/* avoid "the frame size is larger than 1024 bytes" compiler warning */
++<<<<<<< HEAD
 +	sg = kmalloc(sizeof(*sg) * 8 * (diff_dst ? 3 : 2), GFP_KERNEL);
++=======
+ 	sg = kmalloc(array3_size(sizeof(*sg), 8, (diff_dst ? 4 : 2)),
+ 		     GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (!sg)
  		goto out_nosg;
 -	sgout = &sg[16];
 +	asg = &sg[8];
 +	sgout = &asg[8];
  
  	if (diff_dst)
  		d = "-ddst";
diff --cc drivers/acpi/video.c
index c7d2c80b513e,f0b52266b3ac..000000000000
--- a/drivers/acpi/video.c
+++ b/drivers/acpi/video.c
@@@ -831,8 -827,14 +831,19 @@@ acpi_video_init_brightness(struct acpi_
  		goto out;
  	}
  
++<<<<<<< HEAD:drivers/acpi/video.c
 +	br->levels = kmalloc((obj->package.count + 2) * sizeof *(br->levels),
 +				GFP_KERNEL);
++=======
+ 	/*
+ 	 * Note that we have to reserve 2 extra items (ACPI_VIDEO_FIRST_LEVEL),
+ 	 * in order to account for buggy BIOS which don't export the first two
+ 	 * special levels (see below)
+ 	 */
+ 	br->levels = kmalloc_array(obj->package.count + ACPI_VIDEO_FIRST_LEVEL,
+ 				   sizeof(*br->levels),
+ 				   GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array()):drivers/acpi/acpi_video.c
  	if (!br->levels) {
  		result = -ENOMEM;
  		goto out_free;
diff --cc drivers/block/loop.c
index 0d3f632c73f2,d6b6f434fd4b..000000000000
--- a/drivers/block/loop.c
+++ b/drivers/block/loop.c
@@@ -268,210 -307,323 +268,263 @@@ static int do_lo_send_direct_write(stru
   * data as it cannot do the transformations in place without having direct
   * access to the destination pages of the backing file.
   */
 -static int lo_write_transfer(struct loop_device *lo, struct request *rq,
 -		loff_t pos)
 +static int do_lo_send_write(struct loop_device *lo, struct bio_vec *bvec,
 +		loff_t pos, struct page *page)
  {
 -	struct bio_vec bvec, b;
 -	struct req_iterator iter;
 -	struct page *page;
 -	int ret = 0;
 -
 -	page = alloc_page(GFP_NOIO);
 -	if (unlikely(!page))
 -		return -ENOMEM;
 +	int ret = lo_do_transfer(lo, WRITE, page, 0, bvec->bv_page,
 +			bvec->bv_offset, bvec->bv_len, pos >> 9);
 +	if (likely(!ret))
 +		return __do_lo_send_write(lo->lo_backing_file,
 +				page_address(page), bvec->bv_len,
 +				pos);
 +	printk(KERN_ERR "loop: Transfer error at byte offset %llu, "
 +			"length %i.\n", (unsigned long long)pos, bvec->bv_len);
 +	if (ret > 0)
 +		ret = -EIO;
 +	return ret;
 +}
  
 -	rq_for_each_segment(bvec, rq, iter) {
 -		ret = lo_do_transfer(lo, WRITE, page, 0, bvec.bv_page,
 -			bvec.bv_offset, bvec.bv_len, pos >> 9);
 -		if (unlikely(ret))
 -			break;
 +static int lo_send(struct loop_device *lo, struct bio *bio, loff_t pos)
 +{
 +	int (*do_lo_send)(struct loop_device *, struct bio_vec *, loff_t,
 +			struct page *page);
 +	struct bio_vec *bvec;
 +	struct page *page = NULL;
 +	int i, ret = 0;
 +
 +	if (lo->transfer != transfer_none) {
 +		page = alloc_page(GFP_NOIO | __GFP_HIGHMEM);
 +		if (unlikely(!page))
 +			goto fail;
 +		kmap(page);
 +		do_lo_send = do_lo_send_write;
 +	} else {
 +		do_lo_send = do_lo_send_direct_write;
 +	}
  
 -		b.bv_page = page;
 -		b.bv_offset = 0;
 -		b.bv_len = bvec.bv_len;
 -		ret = lo_write_bvec(lo->lo_backing_file, &b, &pos);
 +	bio_for_each_segment(bvec, bio, i) {
 +		ret = do_lo_send(lo, bvec, pos, page);
  		if (ret < 0)
  			break;
 +		pos += bvec->bv_len;
  	}
 -
 -	__free_page(page);
 +	if (page) {
 +		kunmap(page);
 +		__free_page(page);
 +	}
 +out:
  	return ret;
 +fail:
 +	printk(KERN_ERR "loop: Failed to allocate temporary page for write.\n");
 +	ret = -ENOMEM;
 +	goto out;
  }
  
 -static int lo_read_simple(struct loop_device *lo, struct request *rq,
 -		loff_t pos)
 -{
 -	struct bio_vec bvec;
 -	struct req_iterator iter;
 -	struct iov_iter i;
 -	ssize_t len;
 -
 -	rq_for_each_segment(bvec, rq, iter) {
 -		iov_iter_bvec(&i, ITER_BVEC, &bvec, 1, bvec.bv_len);
 -		len = vfs_iter_read(lo->lo_backing_file, &i, &pos, 0);
 -		if (len < 0)
 -			return len;
 +struct lo_read_data {
 +	struct loop_device *lo;
 +	struct page *page;
 +	unsigned offset;
 +	int bsize;
 +};
  
 -		flush_dcache_page(bvec.bv_page);
 +static int
 +lo_splice_actor(struct pipe_inode_info *pipe, struct pipe_buffer *buf,
 +		struct splice_desc *sd)
 +{
 +	struct lo_read_data *p = sd->u.data;
 +	struct loop_device *lo = p->lo;
 +	struct page *page = buf->page;
 +	sector_t IV;
 +	int size;
 +
 +	IV = ((sector_t) page->index << (PAGE_CACHE_SHIFT - 9)) +
 +							(buf->offset >> 9);
 +	size = sd->len;
 +	if (size > p->bsize)
 +		size = p->bsize;
 +
 +	if (lo_do_transfer(lo, READ, page, buf->offset, p->page, p->offset, size, IV)) {
 +		printk(KERN_ERR "loop: transfer error block %ld\n",
 +		       page->index);
 +		size = -EINVAL;
 +	}
  
 -		if (len != bvec.bv_len) {
 -			struct bio *bio;
 +	flush_dcache_page(p->page);
  
 -			__rq_for_each_bio(bio, rq)
 -				zero_fill_bio(bio);
 -			break;
 -		}
 -		cond_resched();
 -	}
 +	if (size > 0)
 +		p->offset += size;
  
 -	return 0;
 +	return size;
  }
  
 -static int lo_read_transfer(struct loop_device *lo, struct request *rq,
 -		loff_t pos)
 +static int
 +lo_direct_splice_actor(struct pipe_inode_info *pipe, struct splice_desc *sd)
  {
 -	struct bio_vec bvec, b;
 -	struct req_iterator iter;
 -	struct iov_iter i;
 -	struct page *page;
 -	ssize_t len;
 -	int ret = 0;
 +	return __splice_from_pipe(pipe, sd, lo_splice_actor);
 +}
  
 -	page = alloc_page(GFP_NOIO);
 -	if (unlikely(!page))
 -		return -ENOMEM;
 +static ssize_t
 +do_lo_receive(struct loop_device *lo,
 +	      struct bio_vec *bvec, int bsize, loff_t pos)
 +{
 +	struct lo_read_data cookie;
 +	struct splice_desc sd;
 +	struct file *file;
 +	ssize_t retval;
  
 -	rq_for_each_segment(bvec, rq, iter) {
 -		loff_t offset = pos;
 +	cookie.lo = lo;
 +	cookie.page = bvec->bv_page;
 +	cookie.offset = bvec->bv_offset;
 +	cookie.bsize = bsize;
  
 -		b.bv_page = page;
 -		b.bv_offset = 0;
 -		b.bv_len = bvec.bv_len;
 +	sd.len = 0;
 +	sd.total_len = bvec->bv_len;
 +	sd.flags = 0;
 +	sd.pos = pos;
 +	sd.u.data = &cookie;
  
 -		iov_iter_bvec(&i, ITER_BVEC, &b, 1, b.bv_len);
 -		len = vfs_iter_read(lo->lo_backing_file, &i, &pos, 0);
 -		if (len < 0) {
 -			ret = len;
 -			goto out_free_page;
 -		}
 +	file = lo->lo_backing_file;
 +	retval = splice_direct_to_actor(file, &sd, lo_direct_splice_actor);
  
 -		ret = lo_do_transfer(lo, READ, page, 0, bvec.bv_page,
 -			bvec.bv_offset, len, offset >> 9);
 -		if (ret)
 -			goto out_free_page;
 +	return retval;
 +}
  
 -		flush_dcache_page(bvec.bv_page);
 +static int
 +lo_receive(struct loop_device *lo, struct bio *bio, int bsize, loff_t pos)
 +{
 +	struct bio_vec *bvec;
 +	ssize_t s;
 +	int i;
  
 -		if (len != bvec.bv_len) {
 -			struct bio *bio;
 +	bio_for_each_segment(bvec, bio, i) {
 +		s = do_lo_receive(lo, bvec, bsize, pos);
 +		if (s < 0)
 +			return s;
  
 -			__rq_for_each_bio(bio, rq)
 -				zero_fill_bio(bio);
 +		if (s != bvec->bv_len) {
 +			zero_fill_bio(bio);
  			break;
  		}
 +		pos += bvec->bv_len;
  	}
 -
 -	ret = 0;
 -out_free_page:
 -	__free_page(page);
 -	return ret;
 +	return 0;
  }
  
 -static int lo_discard(struct loop_device *lo, struct request *rq, loff_t pos)
 +static int do_bio_filebacked(struct loop_device *lo, struct bio *bio)
  {
 -	/*
 -	 * We use punch hole to reclaim the free space used by the
 -	 * image a.k.a. discard. However we do not support discard if
 -	 * encryption is enabled, because it may give an attacker
 -	 * useful information.
 -	 */
 -	struct file *file = lo->lo_backing_file;
 -	int mode = FALLOC_FL_PUNCH_HOLE | FALLOC_FL_KEEP_SIZE;
 +	loff_t pos;
  	int ret;
  
 -	if ((!file->f_op->fallocate) || lo->lo_encrypt_key_size) {
 -		ret = -EOPNOTSUPP;
 -		goto out;
 -	}
 -
 -	ret = file->f_op->fallocate(file, mode, pos, blk_rq_bytes(rq));
 -	if (unlikely(ret && ret != -EINVAL && ret != -EOPNOTSUPP))
 -		ret = -EIO;
 - out:
 -	return ret;
 -}
 +	pos = ((loff_t) bio->bi_sector << 9) + lo->lo_offset;
  
 -static int lo_req_flush(struct loop_device *lo, struct request *rq)
 -{
 -	struct file *file = lo->lo_backing_file;
 -	int ret = vfs_fsync(file, 0);
 -	if (unlikely(ret && ret != -EINVAL))
 -		ret = -EIO;
 +	if (bio_rw(bio) == WRITE) {
 +		struct file *file = lo->lo_backing_file;
  
 -	return ret;
 -}
 -
 -static void lo_complete_rq(struct request *rq)
 -{
 -	struct loop_cmd *cmd = blk_mq_rq_to_pdu(rq);
 -	blk_status_t ret = BLK_STS_OK;
 -
 -	if (!cmd->use_aio || cmd->ret < 0 || cmd->ret == blk_rq_bytes(rq) ||
 -	    req_op(rq) != REQ_OP_READ) {
 -		if (cmd->ret < 0)
 -			ret = BLK_STS_IOERR;
 -		goto end_io;
 -	}
 -
 -	/*
 -	 * Short READ - if we got some data, advance our request and
 -	 * retry it. If we got no data, end the rest with EIO.
 -	 */
 -	if (cmd->ret) {
 -		blk_update_request(rq, BLK_STS_OK, cmd->ret);
 -		cmd->ret = 0;
 -		blk_mq_requeue_request(rq, true);
 -	} else {
 -		if (cmd->use_aio) {
 -			struct bio *bio = rq->bio;
 -
 -			while (bio) {
 -				zero_fill_bio(bio);
 -				bio = bio->bi_next;
 +		if (bio->bi_rw & REQ_FLUSH) {
 +			ret = vfs_fsync(file, 0);
 +			if (unlikely(ret && ret != -EINVAL)) {
 +				ret = -EIO;
 +				goto out;
  			}
  		}
++<<<<<<< HEAD
++=======
+ 		ret = BLK_STS_IOERR;
+ end_io:
+ 		blk_mq_end_request(rq, ret);
+ 	}
+ }
+ 
+ static void lo_rw_aio_do_completion(struct loop_cmd *cmd)
+ {
+ 	struct request *rq = blk_mq_rq_from_pdu(cmd);
+ 
+ 	if (!atomic_dec_and_test(&cmd->ref))
+ 		return;
+ 	kfree(cmd->bvec);
+ 	cmd->bvec = NULL;
+ 	blk_mq_complete_request(rq);
+ }
+ 
+ static void lo_rw_aio_complete(struct kiocb *iocb, long ret, long ret2)
+ {
+ 	struct loop_cmd *cmd = container_of(iocb, struct loop_cmd, iocb);
+ 
+ 	if (cmd->css)
+ 		css_put(cmd->css);
+ 	cmd->ret = ret;
+ 	lo_rw_aio_do_completion(cmd);
+ }
+ 
+ static int lo_rw_aio(struct loop_device *lo, struct loop_cmd *cmd,
+ 		     loff_t pos, bool rw)
+ {
+ 	struct iov_iter iter;
+ 	struct bio_vec *bvec;
+ 	struct request *rq = blk_mq_rq_from_pdu(cmd);
+ 	struct bio *bio = rq->bio;
+ 	struct file *file = lo->lo_backing_file;
+ 	unsigned int offset;
+ 	int segments = 0;
+ 	int ret;
+ 
+ 	if (rq->bio != rq->biotail) {
+ 		struct req_iterator iter;
+ 		struct bio_vec tmp;
+ 
+ 		__rq_for_each_bio(bio, rq)
+ 			segments += bio_segments(bio);
+ 		bvec = kmalloc_array(segments, sizeof(struct bio_vec),
+ 				     GFP_NOIO);
+ 		if (!bvec)
+ 			return -EIO;
+ 		cmd->bvec = bvec;
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  
  		/*
 -		 * The bios of the request may be started from the middle of
 -		 * the 'bvec' because of bio splitting, so we can't directly
 -		 * copy bio->bi_iov_vec to new bvec. The rq_for_each_segment
 -		 * API will take care of all details for us.
 +		 * We use punch hole to reclaim the free space used by the
 +		 * image a.k.a. discard. However we do not support discard if
 +		 * encryption is enabled, because it may give an attacker
 +		 * useful information.
  		 */
 -		rq_for_each_segment(tmp, rq, iter) {
 -			*bvec = tmp;
 -			bvec++;
 +		if (bio->bi_rw & REQ_DISCARD) {
 +			struct file *file = lo->lo_backing_file;
 +			int mode = FALLOC_FL_PUNCH_HOLE | FALLOC_FL_KEEP_SIZE;
 +
 +			if ((!file->f_op->fallocate) ||
 +			    lo->lo_encrypt_key_size) {
 +				ret = -EOPNOTSUPP;
 +				goto out;
 +			}
 +			ret = file->f_op->fallocate(file, mode, pos,
 +						    bio->bi_size);
 +			if (unlikely(ret && ret != -EINVAL &&
 +				     ret != -EOPNOTSUPP))
 +				ret = -EIO;
 +			goto out;
  		}
 -		bvec = cmd->bvec;
 -		offset = 0;
 -	} else {
 -		/*
 -		 * Same here, this bio may be started from the middle of the
 -		 * 'bvec' because of bio splitting, so offset from the bvec
 -		 * must be passed to iov iterator
 -		 */
 -		offset = bio->bi_iter.bi_bvec_done;
 -		bvec = __bvec_iter_bvec(bio->bi_io_vec, bio->bi_iter);
 -		segments = bio_segments(bio);
 -	}
 -	atomic_set(&cmd->ref, 2);
 -
 -	iov_iter_bvec(&iter, ITER_BVEC | rw, bvec,
 -		      segments, blk_rq_bytes(rq));
 -	iter.iov_offset = offset;
 -
 -	cmd->iocb.ki_pos = pos;
 -	cmd->iocb.ki_filp = file;
 -	cmd->iocb.ki_complete = lo_rw_aio_complete;
 -	cmd->iocb.ki_flags = IOCB_DIRECT;
 -	cmd->iocb.ki_ioprio = IOPRIO_PRIO_VALUE(IOPRIO_CLASS_NONE, 0);
 -	if (cmd->css)
 -		kthread_associate_blkcg(cmd->css);
 -
 -	if (rw == WRITE)
 -		ret = call_write_iter(file, &cmd->iocb, &iter);
 -	else
 -		ret = call_read_iter(file, &cmd->iocb, &iter);
  
 -	lo_rw_aio_do_completion(cmd);
 -	kthread_associate_blkcg(NULL);
 -
 -	if (ret != -EIOCBQUEUED)
 -		cmd->iocb.ki_complete(&cmd->iocb, ret, 0);
 -	return 0;
 -}
 +		ret = lo_send(lo, bio, pos);
  
 -static int do_req_filebacked(struct loop_device *lo, struct request *rq)
 -{
 -	struct loop_cmd *cmd = blk_mq_rq_to_pdu(rq);
 -	loff_t pos = ((loff_t) blk_rq_pos(rq) << 9) + lo->lo_offset;
 +		if ((bio->bi_rw & REQ_FUA) && !ret) {
 +			ret = vfs_fsync(file, 0);
 +			if (unlikely(ret && ret != -EINVAL))
 +				ret = -EIO;
 +		}
 +	} else
 +		ret = lo_receive(lo, bio, lo->lo_blocksize, pos);
  
 -	/*
 -	 * lo_write_simple and lo_read_simple should have been covered
 -	 * by io submit style function like lo_rw_aio(), one blocker
 -	 * is that lo_read_simple() need to call flush_dcache_page after
 -	 * the page is written from kernel, and it isn't easy to handle
 -	 * this in io submit style function which submits all segments
 -	 * of the req at one time. And direct read IO doesn't need to
 -	 * run flush_dcache_page().
 -	 */
 -	switch (req_op(rq)) {
 -	case REQ_OP_FLUSH:
 -		return lo_req_flush(lo, rq);
 -	case REQ_OP_DISCARD:
 -	case REQ_OP_WRITE_ZEROES:
 -		return lo_discard(lo, rq, pos);
 -	case REQ_OP_WRITE:
 -		if (lo->transfer)
 -			return lo_write_transfer(lo, rq, pos);
 -		else if (cmd->use_aio)
 -			return lo_rw_aio(lo, cmd, pos, WRITE);
 -		else
 -			return lo_write_simple(lo, rq, pos);
 -	case REQ_OP_READ:
 -		if (lo->transfer)
 -			return lo_read_transfer(lo, rq, pos);
 -		else if (cmd->use_aio)
 -			return lo_rw_aio(lo, cmd, pos, READ);
 -		else
 -			return lo_read_simple(lo, rq, pos);
 -	default:
 -		WARN_ON_ONCE(1);
 -		return -EIO;
 -		break;
 -	}
 +out:
 +	return ret;
  }
  
 -static inline void loop_update_dio(struct loop_device *lo)
 +/*
 + * Add bio to back of pending list
 + */
 +static void loop_add_bio(struct loop_device *lo, struct bio *bio)
  {
 -	__loop_update_dio(lo, io_is_direct(lo->lo_backing_file) |
 -			lo->use_dio);
 +	lo->lo_bio_count++;
 +	bio_list_add(&lo->lo_bio_list, bio);
  }
  
  static void loop_reread_partitions(struct loop_device *lo,
diff --cc drivers/dma/mv_xor.c
index 7c522ab6433a,4528b560dc4c..000000000000
--- a/drivers/dma/mv_xor.c
+++ b/drivers/dma/mv_xor.c
@@@ -904,9 -774,10 +904,13 @@@ static int mv_xor_memcpy_self_test(stru
  	struct dma_chan *dma_chan;
  	dma_cookie_t cookie;
  	struct dma_async_tx_descriptor *tx;
 -	struct dmaengine_unmap_data *unmap;
  	int err = 0;
  
++<<<<<<< HEAD
 +	src = kmalloc(sizeof(u8) * MV_XOR_TEST_SIZE, GFP_KERNEL);
++=======
+ 	src = kmalloc(PAGE_SIZE, GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (!src)
  		return -ENOMEM;
  
diff --cc drivers/i2c/i2c-dev.c
index 02ead38ed769,1aca742fde4a..000000000000
--- a/drivers/i2c/i2c-dev.c
+++ b/drivers/i2c/i2c-dev.c
@@@ -237,24 -244,9 +237,28 @@@ static noinline int i2cdev_ioctl_rdrw(s
  	u8 __user **data_ptrs;
  	int i, res;
  
++<<<<<<< HEAD
 +	if (copy_from_user(&rdwr_arg,
 +			   (struct i2c_rdwr_ioctl_data __user *)arg,
 +			   sizeof(rdwr_arg)))
 +		return -EFAULT;
 +
 +	/* Put an arbitrary limit on the number of messages that can
 +	 * be sent at once */
 +	if (rdwr_arg.nmsgs > I2C_RDRW_IOCTL_MAX_MSGS)
 +		return -EINVAL;
 +
 +	rdwr_pa = memdup_user(rdwr_arg.msgs,
 +			      rdwr_arg.nmsgs * sizeof(struct i2c_msg));
 +	if (IS_ERR(rdwr_pa))
 +		return PTR_ERR(rdwr_pa);
 +
 +	data_ptrs = kmalloc(rdwr_arg.nmsgs * sizeof(u8 __user *), GFP_KERNEL);
++=======
+ 	data_ptrs = kmalloc_array(nmsgs, sizeof(u8 __user *), GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (data_ptrs == NULL) {
 -		kfree(msgs);
 +		kfree(rdwr_pa);
  		return -ENOMEM;
  	}
  
diff --cc drivers/isdn/gigaset/capi.c
index 3286903a95d2,fd13ed44a54e..000000000000
--- a/drivers/isdn/gigaset/capi.c
+++ b/drivers/isdn/gigaset/capi.c
@@@ -250,7 -250,9 +250,13 @@@ static inline void dump_rawmsg(enum deb
  	l -= 12;
  	if (l <= 0)
  		return;
++<<<<<<< HEAD
 +	dbgline = kmalloc(3 * l, GFP_ATOMIC);
++=======
+ 	if (l > 64)
+ 		l = 64; /* arbitrary limit */
+ 	dbgline = kmalloc_array(3, l, GFP_ATOMIC);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (!dbgline)
  		return;
  	for (i = 0; i < l; i++) {
diff --cc drivers/media/usb/cx231xx/cx231xx-audio.c
index 9b925874d392,c4a84fb930b6..000000000000
--- a/drivers/media/usb/cx231xx/cx231xx-audio.c
+++ b/drivers/media/usb/cx231xx/cx231xx-audio.c
@@@ -707,13 -707,13 +707,23 @@@ static int cx231xx_audio_init(struct cx
  			bEndpointAddress;
  
  	adev->num_alt = uif->num_altsetting;
++<<<<<<< HEAD
 +	cx231xx_info("EndPoint Addr 0x%x, Alternate settings: %i\n",
 +		     adev->end_point_addr, adev->num_alt);
 +	adev->alt_max_pkt_size = kmalloc(32 * adev->num_alt, GFP_KERNEL);
 +
 +	if (adev->alt_max_pkt_size == NULL) {
 +		cx231xx_errdev("out of memory!\n");
 +		return -ENOMEM;
++=======
+ 	dev_info(dev->dev,
+ 		"audio EndPoint Addr 0x%x, Alternate settings: %i\n",
+ 		adev->end_point_addr, adev->num_alt);
+ 	adev->alt_max_pkt_size = kmalloc_array(32, adev->num_alt, GFP_KERNEL);
+ 	if (!adev->alt_max_pkt_size) {
+ 		err = -ENOMEM;
+ 		goto err_free_card;
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	}
  
  	for (i = 0; i < adev->num_alt; i++) {
diff --cc drivers/media/usb/tm6000/tm6000-video.c
index a78de1d1bc9e,96055de6e8ce..000000000000
--- a/drivers/media/usb/tm6000/tm6000-video.c
+++ b/drivers/media/usb/tm6000/tm6000-video.c
@@@ -474,20 -460,17 +474,31 @@@ static int tm6000_alloc_urb_buffers(str
  	int num_bufs = TM6000_NUM_URB_BUF;
  	int i;
  
 -	if (dev->urb_buffer)
 +	if (dev->urb_buffer != NULL)
  		return 0;
  
++<<<<<<< HEAD
 +	dev->urb_buffer = kmalloc(sizeof(void *)*num_bufs, GFP_KERNEL);
 +	if (!dev->urb_buffer) {
 +		tm6000_err("cannot allocate memory for urb buffers\n");
++=======
+ 	dev->urb_buffer = kmalloc_array(num_bufs, sizeof(void *), GFP_KERNEL);
+ 	if (!dev->urb_buffer)
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  		return -ENOMEM;
 +	}
  
++<<<<<<< HEAD
 +	dev->urb_dma = kmalloc(sizeof(dma_addr_t *)*num_bufs, GFP_KERNEL);
 +	if (!dev->urb_dma) {
 +		tm6000_err("cannot allocate memory for urb dma pointers\n");
++=======
+ 	dev->urb_dma = kmalloc_array(num_bufs, sizeof(dma_addr_t *),
+ 				     GFP_KERNEL);
+ 	if (!dev->urb_dma)
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  		return -ENOMEM;
 +	}
  
  	for (i = 0; i < num_bufs; i++) {
  		dev->urb_buffer[i] = usb_alloc_coherent(
@@@ -601,16 -584,15 +612,23 @@@ static int tm6000_prepare_isoc(struct t
  
  	dev->isoc_ctl.num_bufs = num_bufs;
  
++<<<<<<< HEAD
 +	dev->isoc_ctl.urb = kmalloc(sizeof(void *)*num_bufs, GFP_KERNEL);
 +	if (!dev->isoc_ctl.urb) {
 +		tm6000_err("cannot alloc memory for usb buffers\n");
++=======
+ 	dev->isoc_ctl.urb = kmalloc_array(num_bufs, sizeof(void *),
+ 					  GFP_KERNEL);
+ 	if (!dev->isoc_ctl.urb)
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  		return -ENOMEM;
 +	}
  
- 	dev->isoc_ctl.transfer_buffer = kmalloc(sizeof(void *)*num_bufs,
- 				   GFP_KERNEL);
+ 	dev->isoc_ctl.transfer_buffer = kmalloc_array(num_bufs,
+ 						      sizeof(void *),
+ 						      GFP_KERNEL);
  	if (!dev->isoc_ctl.transfer_buffer) {
 +		tm6000_err("cannot allocate memory for usbtransfer\n");
  		kfree(dev->isoc_ctl.urb);
  		return -ENOMEM;
  	}
diff --cc drivers/media/usb/usbvision/usbvision-video.c
index d34c2afe2c24,f29d1bef0293..000000000000
--- a/drivers/media/usb/usbvision/usbvision-video.c
+++ b/drivers/media/usb/usbvision/usbvision-video.c
@@@ -1571,10 -1492,11 +1571,18 @@@ static int usbvision_probe(struct usb_i
  
  	usbvision->num_alt = uif->num_altsetting;
  	PDEBUG(DBG_PROBE, "Alternate settings: %i", usbvision->num_alt);
++<<<<<<< HEAD
 +	usbvision->alt_max_pkt_size = kmalloc(32 * usbvision->num_alt, GFP_KERNEL);
 +	if (usbvision->alt_max_pkt_size == NULL) {
 +		dev_err(&intf->dev, "usbvision: out of memory!\n");
 +		return -ENOMEM;
++=======
+ 	usbvision->alt_max_pkt_size = kmalloc_array(32, usbvision->num_alt,
+ 						    GFP_KERNEL);
+ 	if (!usbvision->alt_max_pkt_size) {
+ 		ret = -ENOMEM;
+ 		goto err_pkt;
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	}
  
  	for (i = 0; i < usbvision->num_alt; i++) {
diff --cc drivers/mtd/chips/cfi_cmdset_0002.c
index fff665d59a0d,22506d22194e..000000000000
--- a/drivers/mtd/chips/cfi_cmdset_0002.c
+++ b/drivers/mtd/chips/cfi_cmdset_0002.c
@@@ -659,12 -692,11 +659,19 @@@ static struct mtd_info *cfi_amdstd_setu
  	mtd->size = devsize * cfi->numchips;
  
  	mtd->numeraseregions = cfi->cfiq->NumEraseRegions * cfi->numchips;
++<<<<<<< HEAD
 +	mtd->eraseregions = kmalloc(sizeof(struct mtd_erase_region_info)
 +				    * mtd->numeraseregions, GFP_KERNEL);
 +	if (!mtd->eraseregions) {
 +		printk(KERN_WARNING "Failed to allocate memory for MTD erase region info\n");
++=======
+ 	mtd->eraseregions = kmalloc_array(mtd->numeraseregions,
+ 					  sizeof(struct mtd_erase_region_info),
+ 					  GFP_KERNEL);
+ 	if (!mtd->eraseregions)
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  		goto setup_err;
 +	}
  
  	for (i=0; i<cfi->cfiq->NumEraseRegions; i++) {
  		unsigned long ernum, ersize;
diff --cc drivers/mtd/mtdswap.c
index c92f0f6bc130,6593879595e3..000000000000
--- a/drivers/mtd/mtdswap.c
+++ b/drivers/mtd/mtdswap.c
@@@ -1387,7 -1340,7 +1387,11 @@@ static int mtdswap_init(struct mtdswap_
  	if (!d->page_buf)
  		goto page_buf_fail;
  
++<<<<<<< HEAD
 +	d->oob_buf = kmalloc(2 * mtd->ecclayout->oobavail, GFP_KERNEL);
++=======
+ 	d->oob_buf = kmalloc_array(2, mtd->oobavail, GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (!d->oob_buf)
  		goto oob_buf_fail;
  
diff --cc drivers/mtd/tests/mtd_stresstest.c
index 787f539d16ca,0fe1217f94b9..000000000000
--- a/drivers/mtd/tests/mtd_stresstest.c
+++ b/drivers/mtd/tests/mtd_stresstest.c
@@@ -275,11 -199,9 +275,16 @@@ static int __init mtd_stresstest_init(v
  	err = -ENOMEM;
  	readbuf = vmalloc(bufsize);
  	writebuf = vmalloc(bufsize);
++<<<<<<< HEAD:drivers/mtd/tests/mtd_stresstest.c
 +	offsets = kmalloc(ebcnt * sizeof(int), GFP_KERNEL);
 +	if (!readbuf || !writebuf || !offsets) {
 +		pr_err("error: cannot allocate memory\n");
++=======
+ 	offsets = kmalloc_array(ebcnt, sizeof(int), GFP_KERNEL);
+ 	if (!readbuf || !writebuf || !offsets)
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array()):drivers/mtd/tests/stresstest.c
  		goto out;
 +	}
  	for (i = 0; i < ebcnt; i++)
  		offsets[i] = mtd->erasesize;
  	prandom_bytes(writebuf, bufsize);
diff --cc drivers/net/ethernet/broadcom/bnx2.c
index 6b838496bd1a,e13bf3b4636d..000000000000
--- a/drivers/net/ethernet/broadcom/bnx2.c
+++ b/drivers/net/ethernet/broadcom/bnx2.c
@@@ -2666,8 -2666,8 +2666,13 @@@ bnx2_alloc_bad_rbuf(struct bnx2 *bp
  	u32 good_mbuf_cnt;
  	u32 val;
  
++<<<<<<< HEAD
 +	good_mbuf = kmalloc(512 * sizeof(u16), GFP_KERNEL);
 +	if (good_mbuf == NULL)
++=======
+ 	good_mbuf = kmalloc_array(512, sizeof(u16), GFP_KERNEL);
+ 	if (!good_mbuf)
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  		return -ENOMEM;
  
  	BNX2_WR(bp, BNX2_MISC_ENABLE_SET_BITS,
diff --cc drivers/net/ethernet/qlogic/qed/qed_mcp.c
index 1691b42a30d5,4e0b443c9519..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_mcp.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_mcp.c
@@@ -3066,10 -2578,10 +3066,17 @@@ int qed_mcp_nvm_info_populate(struct qe
  		goto err0;
  	}
  
++<<<<<<< HEAD
 +	nvm_info.image_att = kmalloc_array(nvm_info.num_images,
 +					   sizeof(struct bist_nvm_image_att),
 +					   GFP_KERNEL);
 +	if (!nvm_info.image_att) {
++=======
+ 	nvm_info->image_att = kmalloc_array(nvm_info->num_images,
+ 					    sizeof(struct bist_nvm_image_att),
+ 					    GFP_KERNEL);
+ 	if (!nvm_info->image_att) {
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  		rc = -ENOMEM;
  		goto err0;
  	}
diff --cc drivers/scsi/aha1542.c
index 770c48ddbe5e,41add33e3f1f..000000000000
--- a/drivers/scsi/aha1542.c
+++ b/drivers/scsi/aha1542.c
@@@ -593,24 -387,28 +593,38 @@@ static int aha1542_queuecommand_lck(Scs
  		return 0;
  	}
  #ifdef DEBUG
 -	{
 -		int i = -1;
 -		if (*cmd->cmnd == READ_10 || *cmd->cmnd == WRITE_10)
 -			i = xscsi2int(cmd->cmnd + 2);
 -		else if (*cmd->cmnd == READ_6 || *cmd->cmnd == WRITE_6)
 -			i = scsi2int(cmd->cmnd + 2);
 -		shost_printk(KERN_DEBUG, sh, "aha1542_queuecommand: dev %d cmd %02x pos %d len %d",
 -						target, *cmd->cmnd, i, bufflen);
 -		print_hex_dump_bytes("command: ", DUMP_PREFIX_NONE, cmd->cmnd, cmd->cmd_len);
 -	}
 +	if (*cmd == READ_10 || *cmd == WRITE_10)
 +		i = xscsi2int(cmd + 2);
 +	else if (*cmd == READ_6 || *cmd == WRITE_6)
 +		i = scsi2int(cmd + 2);
 +	else
 +		i = -1;
 +	if (done)
 +		printk(KERN_DEBUG "aha1542_queuecommand: dev %d cmd %02x pos %d len %d ", target, *cmd, i, bufflen);
 +	else
 +		printk(KERN_DEBUG "aha1542_command: dev %d cmd %02x pos %d len %d ", target, *cmd, i, bufflen);
 +	aha1542_stat();
 +	printk(KERN_DEBUG "aha1542_queuecommand: dumping scsi cmd:");
 +	for (i = 0; i < SCpnt->cmd_len; i++)
 +		printk("%02x ", cmd[i]);
 +	printk("\n");
 +	if (*cmd == WRITE_10 || *cmd == WRITE_6)
 +		return 0;	/* we are still testing, so *don't* write */
  #endif
++<<<<<<< HEAD
++=======
+ 	if (bufflen) {	/* allocate memory before taking host_lock */
+ 		sg_count = scsi_sg_count(cmd);
+ 		cptr = kmalloc_array(sg_count, sizeof(*cptr),
+ 				     GFP_KERNEL | GFP_DMA);
+ 		if (!cptr)
+ 			return SCSI_MLQUEUE_HOST_BUSY;
+ 	} else {
+ 		sg_count = 0;
+ 		cptr = NULL;
+ 	}
+ 
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	/* Use the outgoing mailboxes in a round-robin fashion, because this
  	   is how the host adapter will scan for them */
  
diff --cc drivers/scsi/megaraid/megaraid_mm.c
index 25506c777381,8428247015db..000000000000
--- a/drivers/scsi/megaraid/megaraid_mm.c
+++ b/drivers/scsi/megaraid/megaraid_mm.c
@@@ -930,12 -935,14 +930,23 @@@ mraid_mm_register_adp(mraid_mmadp_t *ll
  	 * Allocate single blocks of memory for all required kiocs,
  	 * mailboxes and passthru structures.
  	 */
++<<<<<<< HEAD
 +	adapter->kioc_list	= kmalloc(sizeof(uioc_t) * lld_adp->max_kioc,
 +						GFP_KERNEL);
 +	adapter->mbox_list	= kmalloc(sizeof(mbox64_t) * lld_adp->max_kioc,
 +						GFP_KERNEL);
 +	adapter->pthru_dma_pool = pci_pool_create("megaraid mm pthru pool",
 +						adapter->pdev,
++=======
+ 	adapter->kioc_list	= kmalloc_array(lld_adp->max_kioc,
+ 						  sizeof(uioc_t),
+ 						  GFP_KERNEL);
+ 	adapter->mbox_list	= kmalloc_array(lld_adp->max_kioc,
+ 						  sizeof(mbox64_t),
+ 						  GFP_KERNEL);
+ 	adapter->pthru_dma_pool = dma_pool_create("megaraid mm pthru pool",
+ 						&adapter->pdev->dev,
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  						sizeof(mraid_passthru_t),
  						16, 0);
  
diff --cc drivers/staging/rtl8192u/ieee80211/ieee80211_rx.c
index efcaf2007a93,f2cdcc2bcab4..000000000000
--- a/drivers/staging/rtl8192u/ieee80211/ieee80211_rx.c
+++ b/drivers/staging/rtl8192u/ieee80211/ieee80211_rx.c
@@@ -614,9 -595,16 +614,20 @@@ void RxReorderIndicatePacket( struct ie
  	u16			WinEnd = (pTS->RxIndicateSeq + WinSize -1)%4096;
  	u8			index = 0;
  	bool			bMatchWinStart = false, bPktInBuf = false;
++<<<<<<< HEAD
 +	IEEE80211_DEBUG(IEEE80211_DL_REORDER,"%s(): Seq is %d,pTS->RxIndicateSeq is %d, WinSize is %d\n",__FUNCTION__,SeqNum,pTS->RxIndicateSeq,WinSize);
++=======
+ 	IEEE80211_DEBUG(IEEE80211_DL_REORDER,"%s(): Seq is %d,pTS->RxIndicateSeq is %d, WinSize is %d\n",__func__,SeqNum,pTS->RxIndicateSeq,WinSize);
+ 
+ 	prxbIndicateArray = kmalloc_array(REORDER_WIN_SIZE,
+ 					  sizeof(struct ieee80211_rxb *),
+ 					  GFP_KERNEL);
+ 	if (!prxbIndicateArray)
+ 		return;
+ 
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	/* Rx Reorder initialize condition.*/
 -	if (pTS->RxIndicateSeq == 0xffff) {
 +	if(pTS->RxIndicateSeq == 0xffff) {
  		pTS->RxIndicateSeq = SeqNum;
  	}
  
diff --cc drivers/staging/rtl8192u/r8192U_core.c
index 71f5cde9ed1c,8b17400f6c13..000000000000
--- a/drivers/staging/rtl8192u/r8192U_core.c
+++ b/drivers/staging/rtl8192u/r8192U_core.c
@@@ -2142,9 -1640,9 +2142,15 @@@ short rtl8192_usb_initendpoints(struct 
  {
  	struct r8192_priv *priv = ieee80211_priv(dev);
  
++<<<<<<< HEAD
 +	priv->rx_urb = kmalloc(sizeof(struct urb *) * (MAX_RX_URB+1),
 +				GFP_KERNEL);
 +	if (priv->rx_urb == NULL)
++=======
+ 	priv->rx_urb = kmalloc_array(MAX_RX_URB + 1, sizeof(struct urb *),
+ 				     GFP_KERNEL);
+ 	if (!priv->rx_urb)
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  		return -ENOMEM;
  
  #ifndef JACKSON_NEW_RX
diff --cc drivers/tty/vt/consolemap.c
index 58d5f08e6d7f,7c7ada0b3ea0..000000000000
--- a/drivers/tty/vt/consolemap.c
+++ b/drivers/tty/vt/consolemap.c
@@@ -490,15 -477,18 +490,28 @@@ con_insert_unipair(struct uni_pagedir *
  	int i, n;
  	u16 **p1, *p2;
  
++<<<<<<< HEAD
 +	if (!(p1 = p->uni_pgdir[n = unicode >> 11])) {
 +		p1 = p->uni_pgdir[n] = kmalloc(32*sizeof(u16 *), GFP_KERNEL);
++=======
+ 	p1 = p->uni_pgdir[n = unicode >> 11];
+ 	if (!p1) {
+ 		p1 = p->uni_pgdir[n] = kmalloc_array(32, sizeof(u16 *),
+ 						     GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  		if (!p1) return -ENOMEM;
  		for (i = 0; i < 32; i++)
  			p1[i] = NULL;
  	}
  
++<<<<<<< HEAD
 +	if (!(p2 = p1[n = (unicode >> 6) & 0x1f])) {
 +		p2 = p1[n] = kmalloc(64*sizeof(u16), GFP_KERNEL);
++=======
+ 	p2 = p1[n = (unicode >> 6) & 0x1f];
+ 	if (!p2) {
+ 		p2 = p1[n] = kmalloc_array(64, sizeof(u16), GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  		if (!p2) return -ENOMEM;
  		memset(p2, 0xff, 64*sizeof(u16)); /* No glyphs for the characters (yet) */
  	}
diff --cc drivers/tty/vt/keyboard.c
index 573dbc1d93b7,d5b4a2b44ab8..000000000000
--- a/drivers/tty/vt/keyboard.c
+++ b/drivers/tty/vt/keyboard.c
@@@ -1651,12 -1620,13 +1651,16 @@@ int vt_do_diacrit(unsigned int cmd, voi
  	switch (cmd) {
  	case KDGKBDIACR:
  	{
 -		struct kbdiacrs __user *a = udp;
 -		struct kbdiacr *dia;
 +		struct kbdiacr *diacr;
  		int i;
  
++<<<<<<< HEAD
 +		diacr = kmalloc(MAX_DIACR * sizeof(struct kbdiacr),
++=======
+ 		dia = kmalloc_array(MAX_DIACR, sizeof(struct kbdiacr),
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  								GFP_KERNEL);
 -		if (!dia)
 +		if (diacr == NULL)
  			return -ENOMEM;
  
  		/* Lock the diacriticals table, make a copy and then
@@@ -1684,10 -1654,10 +1688,10 @@@
  	}
  	case KDGKBDIACRUC:
  	{
 -		struct kbdiacrsuc __user *a = udp;
 +		struct kbdiacrsuc __user *a = up;
  		void *buf;
  
- 		buf = kmalloc(MAX_DIACR * sizeof(struct kbdiacruc),
+ 		buf = kmalloc_array(MAX_DIACR, sizeof(struct kbdiacruc),
  								GFP_KERNEL);
  		if (buf == NULL)
  			return -ENOMEM;
diff --cc drivers/vhost/scsi.c
index 2b14ae4c9782,ce10eb75b042..000000000000
--- a/drivers/vhost/scsi.c
+++ b/drivers/vhost/scsi.c
@@@ -1212,46 -1367,46 +1212,66 @@@ static int vhost_scsi_set_features(stru
  
  static int vhost_scsi_open(struct inode *inode, struct file *f)
  {
 -	struct vhost_scsi *vs;
 +	struct vhost_scsi *s;
  	struct vhost_virtqueue **vqs;
 -	int r = -ENOMEM, i;
 +	int r, i;
  
 -	vs = kzalloc(sizeof(*vs), GFP_KERNEL | __GFP_NOWARN | __GFP_RETRY_MAYFAIL);
 -	if (!vs) {
 -		vs = vzalloc(sizeof(*vs));
 -		if (!vs)
 -			goto err_vs;
 -	}
 +	s = kzalloc(sizeof(*s), GFP_KERNEL);
 +	if (!s)
 +		return -ENOMEM;
  
++<<<<<<< HEAD
 +	vqs = kmalloc(VHOST_SCSI_MAX_VQ * sizeof(*vqs), GFP_KERNEL);
 +	if (!vqs) {
 +		kfree(s);
 +		return -ENOMEM;
++=======
+ 	vqs = kmalloc_array(VHOST_SCSI_MAX_VQ, sizeof(*vqs), GFP_KERNEL);
+ 	if (!vqs)
+ 		goto err_vqs;
+ 
+ 	vhost_work_init(&vs->vs_completion_work, vhost_scsi_complete_cmd_work);
+ 	vhost_work_init(&vs->vs_event_work, vhost_scsi_evt_work);
+ 
+ 	vs->vs_events_nr = 0;
+ 	vs->vs_events_missed = false;
+ 
+ 	vqs[VHOST_SCSI_VQ_CTL] = &vs->vqs[VHOST_SCSI_VQ_CTL].vq;
+ 	vqs[VHOST_SCSI_VQ_EVT] = &vs->vqs[VHOST_SCSI_VQ_EVT].vq;
+ 	vs->vqs[VHOST_SCSI_VQ_CTL].vq.handle_kick = vhost_scsi_ctl_handle_kick;
+ 	vs->vqs[VHOST_SCSI_VQ_EVT].vq.handle_kick = vhost_scsi_evt_handle_kick;
+ 	for (i = VHOST_SCSI_VQ_IO; i < VHOST_SCSI_MAX_VQ; i++) {
+ 		vqs[i] = &vs->vqs[i].vq;
+ 		vs->vqs[i].vq.handle_kick = vhost_scsi_handle_kick;
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	}
 -	vhost_dev_init(&vs->dev, vqs, VHOST_SCSI_MAX_VQ);
  
 -	vhost_scsi_init_inflight(vs, NULL);
 +	vhost_work_init(&s->vs_completion_work, vhost_scsi_complete_cmd_work);
 +	vhost_work_init(&s->vs_event_work, tcm_vhost_evt_work);
  
 -	f->private_data = vs;
 -	return 0;
 +	s->vs_events_nr = 0;
 +	s->vs_events_missed = false;
 +
 +	vqs[VHOST_SCSI_VQ_CTL] = &s->vqs[VHOST_SCSI_VQ_CTL].vq;
 +	vqs[VHOST_SCSI_VQ_EVT] = &s->vqs[VHOST_SCSI_VQ_EVT].vq;
 +	s->vqs[VHOST_SCSI_VQ_CTL].vq.handle_kick = vhost_scsi_ctl_handle_kick;
 +	s->vqs[VHOST_SCSI_VQ_EVT].vq.handle_kick = vhost_scsi_evt_handle_kick;
 +	for (i = VHOST_SCSI_VQ_IO; i < VHOST_SCSI_MAX_VQ; i++) {
 +		vqs[i] = &s->vqs[i].vq;
 +		s->vqs[i].vq.handle_kick = vhost_scsi_handle_kick;
 +	}
 +	r = vhost_dev_init(&s->dev, vqs, VHOST_SCSI_MAX_VQ);
  
 -err_vqs:
 -	kvfree(vs);
 -err_vs:
 -	return r;
 +	tcm_vhost_init_inflight(s, NULL);
 +
 +	if (r < 0) {
 +		kfree(vqs);
 +		kfree(s);
 +		return r;
 +	}
 +
 +	f->private_data = s;
 +	return 0;
  }
  
  static int vhost_scsi_release(struct inode *inode, struct file *f)
diff --cc drivers/vhost/test.c
index 1d0e2f7d00b4,40589850eb33..000000000000
--- a/drivers/vhost/test.c
+++ b/drivers/vhost/test.c
@@@ -105,14 -107,16 +105,22 @@@ static int vhost_test_open(struct inod
  
  	if (!n)
  		return -ENOMEM;
++<<<<<<< HEAD
++=======
+ 	vqs = kmalloc_array(VHOST_TEST_VQ_MAX, sizeof(*vqs), GFP_KERNEL);
+ 	if (!vqs) {
+ 		kfree(n);
+ 		return -ENOMEM;
+ 	}
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  
  	dev = &n->dev;
 -	vqs[VHOST_TEST_VQ] = &n->vqs[VHOST_TEST_VQ];
  	n->vqs[VHOST_TEST_VQ].handle_kick = handle_vq_kick;
 -	vhost_dev_init(dev, vqs, VHOST_TEST_VQ_MAX);
 +	r = vhost_dev_init(dev, n->vqs, VHOST_TEST_VQ_MAX);
 +	if (r < 0) {
 +		kfree(n);
 +		return r;
 +	}
  
  	f->private_data = n;
  
diff --cc drivers/vhost/vhost.c
index b7f40ae98fa5,ce8c95b6365b..000000000000
--- a/drivers/vhost/vhost.c
+++ b/drivers/vhost/vhost.c
@@@ -367,14 -383,16 +367,26 @@@ static long vhost_dev_alloc_iovecs(stru
  	int i;
  
  	for (i = 0; i < dev->nvqs; ++i) {
++<<<<<<< HEAD
 +		dev->vqs[i]->indirect = kmalloc(sizeof *dev->vqs[i]->indirect *
 +					       UIO_MAXIOV, GFP_KERNEL);
 +		dev->vqs[i]->log = kmalloc(sizeof *dev->vqs[i]->log * UIO_MAXIOV,
 +					  GFP_KERNEL);
 +		dev->vqs[i]->heads = kmalloc(sizeof *dev->vqs[i]->heads *
 +					    UIO_MAXIOV, GFP_KERNEL);
 +		if (!dev->vqs[i]->indirect || !dev->vqs[i]->log ||
 +			!dev->vqs[i]->heads)
++=======
+ 		vq = dev->vqs[i];
+ 		vq->indirect = kmalloc_array(UIO_MAXIOV,
+ 					     sizeof(*vq->indirect),
+ 					     GFP_KERNEL);
+ 		vq->log = kmalloc_array(UIO_MAXIOV, sizeof(*vq->log),
+ 					GFP_KERNEL);
+ 		vq->heads = kmalloc_array(UIO_MAXIOV, sizeof(*vq->heads),
+ 					  GFP_KERNEL);
+ 		if (!vq->indirect || !vq->log || !vq->heads)
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  			goto err_nomem;
  	}
  	return 0;
diff --cc drivers/virtio/virtio_pci_common.c
index ee13eb83bfb1,a491d0ed3f16..000000000000
--- a/drivers/virtio/virtio_pci_common.c
+++ b/drivers/virtio/virtio_pci_common.c
@@@ -147,12 -113,9 +147,18 @@@ static int vp_request_msix_vectors(stru
  
  	vp_dev->msix_vectors = nvectors;
  
++<<<<<<< HEAD
 +	vp_dev->msix_entries = kmalloc(nvectors * sizeof *vp_dev->msix_entries,
 +				       GFP_KERNEL);
 +	if (!vp_dev->msix_entries)
 +		goto error;
 +	vp_dev->msix_names = kmalloc(nvectors * sizeof *vp_dev->msix_names,
 +				     GFP_KERNEL);
++=======
+ 	vp_dev->msix_names = kmalloc_array(nvectors,
+ 					   sizeof(*vp_dev->msix_names),
+ 					   GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (!vp_dev->msix_names)
  		goto error;
  	vp_dev->msix_affinity_masks
diff --cc drivers/xen/xen-pciback/pciback_ops.c
index 64eb0cd8b8af,ea4a08b83fa0..000000000000
--- a/drivers/xen/xen-pciback/pciback_ops.c
+++ b/drivers/xen/xen-pciback/pciback_ops.c
@@@ -204,7 -221,20 +204,23 @@@ int xen_pcibk_enable_msix(struct xen_pc
  	if (op->value > SH_INFO_MAX_VEC)
  		return -EINVAL;
  
++<<<<<<< HEAD
 +	entries = kmalloc(op->value * sizeof(*entries), GFP_KERNEL);
++=======
+ 	if (dev->msix_enabled)
+ 		return -EALREADY;
+ 
+ 	/*
+ 	 * PCI_COMMAND_MEMORY must be enabled, otherwise we may not be able
+ 	 * to access the BARs where the MSI-X entries reside.
+ 	 * But VF devices are unique in which the PF needs to be checked.
+ 	 */
+ 	pci_read_config_word(pci_physfn(dev), PCI_COMMAND, &cmd);
+ 	if (dev->msi_enabled || !(cmd & PCI_COMMAND_MEMORY))
+ 		return -ENXIO;
+ 
+ 	entries = kmalloc_array(op->value, sizeof(*entries), GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (entries == NULL)
  		return -ENOMEM;
  
diff --cc fs/afs/cmservice.c
index 1c8c6cc6de30,238fd28cfdd2..000000000000
--- a/fs/afs/cmservice.c
+++ b/fs/afs/cmservice.c
@@@ -189,9 -189,10 +189,10 @@@ static int afs_deliver_cb_callback(stru
  		call->count = ntohl(call->tmp);
  		_debug("FID count: %u", call->count);
  		if (call->count > AFSCBMAX)
 -			return afs_protocol_error(call, -EBADMSG);
 +			return -EBADMSG;
  
- 		call->buffer = kmalloc(call->count * 3 * 4, GFP_KERNEL);
+ 		call->buffer = kmalloc(array3_size(call->count, 3, 4),
+ 				       GFP_KERNEL);
  		if (!call->buffer)
  			return -ENOMEM;
  		call->offset = 0;
@@@ -343,20 -317,60 +344,66 @@@ static int afs_deliver_cb_init_call_bac
  /*
   * deliver request data to a CB.InitCallBackState3 call
   */
 -static int afs_deliver_cb_init_call_back_state3(struct afs_call *call)
 +static int afs_deliver_cb_init_call_back_state3(struct afs_call *call,
 +						struct sk_buff *skb,
 +						bool last)
  {
 -	struct afs_uuid *r;
 -	unsigned loop;
 -	__be32 *b;
 -	int ret;
 +	struct afs_server *server;
 +	struct in_addr addr;
  
 -	_enter("");
 +	_enter(",{%u},%d", skb->len, last);
  
 -	_enter("{%u}", call->unmarshall);
 +	if (!last)
 +		return 0;
  
++<<<<<<< HEAD
 +	/* no unmarshalling required */
 +	call->state = AFS_CALL_REPLYING;
++=======
+ 	switch (call->unmarshall) {
+ 	case 0:
+ 		call->offset = 0;
+ 		call->buffer = kmalloc_array(11, sizeof(__be32), GFP_KERNEL);
+ 		if (!call->buffer)
+ 			return -ENOMEM;
+ 		call->unmarshall++;
+ 
+ 	case 1:
+ 		_debug("extract UUID");
+ 		ret = afs_extract_data(call, call->buffer,
+ 				       11 * sizeof(__be32), false);
+ 		switch (ret) {
+ 		case 0:		break;
+ 		case -EAGAIN:	return 0;
+ 		default:	return ret;
+ 		}
+ 
+ 		_debug("unmarshall UUID");
+ 		call->request = kmalloc(sizeof(struct afs_uuid), GFP_KERNEL);
+ 		if (!call->request)
+ 			return -ENOMEM;
+ 
+ 		b = call->buffer;
+ 		r = call->request;
+ 		r->time_low			= b[0];
+ 		r->time_mid			= htons(ntohl(b[1]));
+ 		r->time_hi_and_version		= htons(ntohl(b[2]));
+ 		r->clock_seq_hi_and_reserved 	= ntohl(b[3]);
+ 		r->clock_seq_low		= ntohl(b[4]);
+ 
+ 		for (loop = 0; loop < 6; loop++)
+ 			r->node[loop] = ntohl(b[loop + 5]);
+ 
+ 		call->offset = 0;
+ 		call->unmarshall++;
+ 
+ 	case 2:
+ 		break;
+ 	}
+ 
+ 	if (!afs_check_call_state(call, AFS_CALL_SV_REPLYING))
+ 		return -EIO;
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  
  	/* we'll need the file server record as that tells us which set of
  	 * vnodes to operate upon */
diff --cc fs/block_dev.c
index c688c32c3aca,0dd87aaeb39a..000000000000
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@@ -181,9 -164,162 +181,147 @@@ static struct inode *bdev_file_inode(st
  	return file->f_mapping->host;
  }
  
 -static unsigned int dio_bio_write_op(struct kiocb *iocb)
 -{
 -	unsigned int op = REQ_OP_WRITE | REQ_SYNC | REQ_IDLE;
 -
 -	/* avoid the need for a I/O completion work item */
 -	if (iocb->ki_flags & IOCB_DSYNC)
 -		op |= REQ_FUA;
 -	return op;
 -}
 -
 -#define DIO_INLINE_BIO_VECS 4
 -
 -static void blkdev_bio_end_io_simple(struct bio *bio)
 -{
 -	struct task_struct *waiter = bio->bi_private;
 -
 -	WRITE_ONCE(bio->bi_private, NULL);
 -	wake_up_process(waiter);
 -}
 -
  static ssize_t
++<<<<<<< HEAD
 +blkdev_direct_IO(int rw, struct kiocb *iocb, const struct iovec *iov,
 +			loff_t offset, unsigned long nr_segs)
++=======
+ __blkdev_direct_IO_simple(struct kiocb *iocb, struct iov_iter *iter,
+ 		int nr_pages)
+ {
+ 	struct file *file = iocb->ki_filp;
+ 	struct block_device *bdev = I_BDEV(bdev_file_inode(file));
+ 	struct bio_vec inline_vecs[DIO_INLINE_BIO_VECS], *vecs, *bvec;
+ 	loff_t pos = iocb->ki_pos;
+ 	bool should_dirty = false;
+ 	struct bio bio;
+ 	ssize_t ret;
+ 	blk_qc_t qc;
+ 	int i;
+ 
+ 	if ((pos | iov_iter_alignment(iter)) &
+ 	    (bdev_logical_block_size(bdev) - 1))
+ 		return -EINVAL;
+ 
+ 	if (nr_pages <= DIO_INLINE_BIO_VECS)
+ 		vecs = inline_vecs;
+ 	else {
+ 		vecs = kmalloc_array(nr_pages, sizeof(struct bio_vec),
+ 				     GFP_KERNEL);
+ 		if (!vecs)
+ 			return -ENOMEM;
+ 	}
+ 
+ 	bio_init(&bio, vecs, nr_pages);
+ 	bio_set_dev(&bio, bdev);
+ 	bio.bi_iter.bi_sector = pos >> 9;
+ 	bio.bi_write_hint = iocb->ki_hint;
+ 	bio.bi_private = current;
+ 	bio.bi_end_io = blkdev_bio_end_io_simple;
+ 	bio.bi_ioprio = iocb->ki_ioprio;
+ 
+ 	ret = bio_iov_iter_get_pages(&bio, iter);
+ 	if (unlikely(ret))
+ 		return ret;
+ 	ret = bio.bi_iter.bi_size;
+ 
+ 	if (iov_iter_rw(iter) == READ) {
+ 		bio.bi_opf = REQ_OP_READ;
+ 		if (iter_is_iovec(iter))
+ 			should_dirty = true;
+ 	} else {
+ 		bio.bi_opf = dio_bio_write_op(iocb);
+ 		task_io_account_write(ret);
+ 	}
+ 
+ 	qc = submit_bio(&bio);
+ 	for (;;) {
+ 		set_current_state(TASK_UNINTERRUPTIBLE);
+ 		if (!READ_ONCE(bio.bi_private))
+ 			break;
+ 		if (!(iocb->ki_flags & IOCB_HIPRI) ||
+ 		    !blk_poll(bdev_get_queue(bdev), qc))
+ 			io_schedule();
+ 	}
+ 	__set_current_state(TASK_RUNNING);
+ 
+ 	bio_for_each_segment_all(bvec, &bio, i) {
+ 		if (should_dirty && !PageCompound(bvec->bv_page))
+ 			set_page_dirty_lock(bvec->bv_page);
+ 		put_page(bvec->bv_page);
+ 	}
+ 
+ 	if (vecs != inline_vecs)
+ 		kfree(vecs);
+ 
+ 	if (unlikely(bio.bi_status))
+ 		ret = blk_status_to_errno(bio.bi_status);
+ 
+ 	bio_uninit(&bio);
+ 
+ 	return ret;
+ }
+ 
+ struct blkdev_dio {
+ 	union {
+ 		struct kiocb		*iocb;
+ 		struct task_struct	*waiter;
+ 	};
+ 	size_t			size;
+ 	atomic_t		ref;
+ 	bool			multi_bio : 1;
+ 	bool			should_dirty : 1;
+ 	bool			is_sync : 1;
+ 	struct bio		bio;
+ };
+ 
+ static struct bio_set blkdev_dio_pool;
+ 
+ static void blkdev_bio_end_io(struct bio *bio)
+ {
+ 	struct blkdev_dio *dio = bio->bi_private;
+ 	bool should_dirty = dio->should_dirty;
+ 
+ 	if (dio->multi_bio && !atomic_dec_and_test(&dio->ref)) {
+ 		if (bio->bi_status && !dio->bio.bi_status)
+ 			dio->bio.bi_status = bio->bi_status;
+ 	} else {
+ 		if (!dio->is_sync) {
+ 			struct kiocb *iocb = dio->iocb;
+ 			ssize_t ret;
+ 
+ 			if (likely(!dio->bio.bi_status)) {
+ 				ret = dio->size;
+ 				iocb->ki_pos += ret;
+ 			} else {
+ 				ret = blk_status_to_errno(dio->bio.bi_status);
+ 			}
+ 
+ 			dio->iocb->ki_complete(iocb, ret, 0);
+ 			bio_put(&dio->bio);
+ 		} else {
+ 			struct task_struct *waiter = dio->waiter;
+ 
+ 			WRITE_ONCE(dio->waiter, NULL);
+ 			wake_up_process(waiter);
+ 		}
+ 	}
+ 
+ 	if (should_dirty) {
+ 		bio_check_pages_dirty(bio);
+ 	} else {
+ 		struct bio_vec *bvec;
+ 		int i;
+ 
+ 		bio_for_each_segment_all(bvec, bio, i)
+ 			put_page(bvec->bv_page);
+ 		bio_put(bio);
+ 	}
+ }
+ 
+ static ssize_t
+ __blkdev_direct_IO(struct kiocb *iocb, struct iov_iter *iter, int nr_pages)
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  {
  	struct file *file = iocb->ki_filp;
  	struct inode *inode = bdev_file_inode(file);
diff --cc fs/cifs/transport.c
index 080bbbf4dce2,1f1a68f89110..000000000000
--- a/fs/cifs/transport.c
+++ b/fs/cifs/transport.c
@@@ -868,10 -844,13 +868,18 @@@ SendReceive2(const unsigned int xid, st
  	int rc;
  
  	if (n_vec + 1 > CIFS_MAX_IOV_SIZE) {
++<<<<<<< HEAD
 +		new_iov = kmalloc(sizeof(struct kvec) * (n_vec + 1),
 +				  GFP_KERNEL);
 +		if (!new_iov)
++=======
+ 		new_iov = kmalloc_array(n_vec + 1, sizeof(struct kvec),
+ 					GFP_KERNEL);
+ 		if (!new_iov) {
+ 			/* otherwise cifs_send_recv below sets resp_buf_type */
+ 			*resp_buf_type = CIFS_NO_BUFFER;
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  			return -ENOMEM;
 -		}
  	} else
  		new_iov = s_iov;
  
diff --cc fs/hpfs/dnode.c
index 4364b2a02c5d,4ada525c5c43..000000000000
--- a/fs/hpfs/dnode.c
+++ b/fs/hpfs/dnode.c
@@@ -29,11 -30,13 +29,18 @@@ void hpfs_add_pos(struct inode *inode, 
  
  	if (hpfs_inode->i_rddir_off)
  		for (; hpfs_inode->i_rddir_off[i]; i++)
 -			if (hpfs_inode->i_rddir_off[i] == pos)
 -				return 0;
 +			if (hpfs_inode->i_rddir_off[i] == pos) return;
  	if (!(i&0x0f)) {
++<<<<<<< HEAD
 +		if (!(ppos = kmalloc((i+0x11) * sizeof(loff_t*), GFP_NOFS))) {
 +			printk("HPFS: out of memory for position list\n");
 +			return;
++=======
+ 		ppos = kmalloc_array(i + 0x11, sizeof(loff_t *), GFP_NOFS);
+ 		if (!ppos) {
+ 			pr_err("out of memory for position list\n");
+ 			return -ENOMEM;
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  		}
  		if (hpfs_inode->i_rddir_off) {
  			memcpy(ppos, hpfs_inode->i_rddir_off, i * sizeof(loff_t));
diff --cc fs/hpfs/map.c
index 803d3da3a0fe,ecd9fccd1663..000000000000
--- a/fs/hpfs/map.c
+++ b/fs/hpfs/map.c
@@@ -96,8 -115,8 +96,13 @@@ __le32 *hpfs_load_bitmap_directory(stru
  	int n = (hpfs_sb(s)->sb_fs_size + 0x200000 - 1) >> 21;
  	int i;
  	__le32 *b;
++<<<<<<< HEAD
 +	if (!(b = kmalloc(n * 512, GFP_KERNEL))) {
 +		printk("HPFS: can't allocate memory for bitmap directory\n");
++=======
+ 	if (!(b = kmalloc_array(n, 512, GFP_KERNEL))) {
+ 		pr_err("can't allocate memory for bitmap directory\n");
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  		return NULL;
  	}	
  	for (i=0;i<n;i++) {
diff --cc fs/mbcache.c
index 8c32ef3ba88e,081ccf0caee3..000000000000
--- a/fs/mbcache.c
+++ b/fs/mbcache.c
@@@ -1,620 -1,436 +1,1012 @@@
 -#include <linux/spinlock.h>
 -#include <linux/slab.h>
 -#include <linux/list.h>
 -#include <linux/list_bl.h>
 -#include <linux/module.h>
 -#include <linux/sched.h>
 -#include <linux/workqueue.h>
 -#include <linux/mbcache.h>
 +/*
 + * linux/fs/mbcache.c
 + * (C) 2001-2002 Andreas Gruenbacher, <a.gruenbacher@computer.org>
 + */
  
  /*
 - * Mbcache is a simple key-value store. Keys need not be unique, however
 - * key-value pairs are expected to be unique (we use this fact in
 - * mb_cache_entry_delete()).
 + * Filesystem Meta Information Block Cache (mbcache)
 + *
 + * The mbcache caches blocks of block devices that need to be located
 + * by their device/block number, as well as by other criteria (such
 + * as the block's contents).
   *
 - * Ext2 and ext4 use this cache for deduplication of extended attribute blocks.
 - * Ext4 also uses it for deduplication of xattr values stored in inodes.
 - * They use hash of data as a key and provide a value that may represent a
 - * block or inode number. That's why keys need not be unique (hash of different
 - * data may be the same). However user provided value always uniquely
 - * identifies a cache entry.
 + * There can only be one cache entry in a cache per device and block number.
 + * Additional indexes need not be unique in this sense. The number of
 + * additional indexes (=other criteria) can be hardwired at compile time
 + * or specified at cache create time.
   *
 - * We provide functions for creation and removal of entries, search by key,
 - * and a special "delete entry with given key-value pair" operation. Fixed
 - * size hash table is used for fast key lookups.
 + * Each cache entry is of fixed size. An entry may be `valid' or `invalid'
 + * in the cache. A valid entry is in the main hash tables of the cache,
 + * and may also be in the lru list. An invalid entry is not in any hashes
 + * or lists.
 + *
 + * A valid cache entry is only in the lru list if no handles refer to it.
 + * Invalid cache entries will be freed when the last handle to the cache
 + * entry is released. Entries that cannot be freed immediately are put
 + * back on the lru list.
   */
  
 -struct mb_cache {
 -	/* Hash table of entries */
 -	struct hlist_bl_head	*c_hash;
 -	/* log2 of hash table size */
 -	int			c_bucket_bits;
 -	/* Maximum entries in cache to avoid degrading hash too much */
 -	unsigned long		c_max_entries;
 -	/* Protects c_list, c_entry_count */
 -	spinlock_t		c_list_lock;
 -	struct list_head	c_list;
 -	/* Number of entries in cache */
 -	unsigned long		c_entry_count;
 -	struct shrinker		c_shrink;
 -	/* Work for shrinking when the cache has too many entries */
 -	struct work_struct	c_shrink_work;
 -};
 +#include <linux/kernel.h>
 +#include <linux/module.h>
  
 -static struct kmem_cache *mb_entry_cache;
 +#include <linux/hash.h>
 +#include <linux/fs.h>
 +#include <linux/mm.h>
 +#include <linux/slab.h>
 +#include <linux/sched.h>
 +#include <linux/init.h>
 +#include <linux/mbcache.h>
  
 +
 +#ifdef MB_CACHE_DEBUG
 +# define mb_debug(f...) do { \
 +		printk(KERN_DEBUG f); \
 +		printk("\n"); \
 +	} while (0)
 +#define mb_assert(c) do { if (!(c)) \
 +		printk(KERN_ERR "assertion " #c " failed\n"); \
 +	} while(0)
 +#else
 +# define mb_debug(f...) do { } while(0)
 +# define mb_assert(c) do { } while(0)
 +#endif
 +#define mb_error(f...) do { \
 +		printk(KERN_ERR f); \
 +		printk("\n"); \
 +	} while(0)
 +
 +#define MB_CACHE_WRITER ((unsigned short)~0U >> 1)
 +
++<<<<<<< HEAD
 +static DECLARE_WAIT_QUEUE_HEAD(mb_cache_queue);
 +		
 +MODULE_AUTHOR("Andreas Gruenbacher <a.gruenbacher@computer.org>");
++=======
+ static unsigned long mb_cache_shrink(struct mb_cache *cache,
+ 				     unsigned long nr_to_scan);
+ 
+ static inline struct hlist_bl_head *mb_cache_entry_head(struct mb_cache *cache,
+ 							u32 key)
+ {
+ 	return &cache->c_hash[hash_32(key, cache->c_bucket_bits)];
+ }
+ 
+ /*
+  * Number of entries to reclaim synchronously when there are too many entries
+  * in cache
+  */
+ #define SYNC_SHRINK_BATCH 64
+ 
+ /*
+  * mb_cache_entry_create - create entry in cache
+  * @cache - cache where the entry should be created
+  * @mask - gfp mask with which the entry should be allocated
+  * @key - key of the entry
+  * @value - value of the entry
+  * @reusable - is the entry reusable by others?
+  *
+  * Creates entry in @cache with key @key and value @value. The function returns
+  * -EBUSY if entry with the same key and value already exists in cache.
+  * Otherwise 0 is returned.
+  */
+ int mb_cache_entry_create(struct mb_cache *cache, gfp_t mask, u32 key,
+ 			  u64 value, bool reusable)
+ {
+ 	struct mb_cache_entry *entry, *dup;
+ 	struct hlist_bl_node *dup_node;
+ 	struct hlist_bl_head *head;
+ 
+ 	/* Schedule background reclaim if there are too many entries */
+ 	if (cache->c_entry_count >= cache->c_max_entries)
+ 		schedule_work(&cache->c_shrink_work);
+ 	/* Do some sync reclaim if background reclaim cannot keep up */
+ 	if (cache->c_entry_count >= 2*cache->c_max_entries)
+ 		mb_cache_shrink(cache, SYNC_SHRINK_BATCH);
+ 
+ 	entry = kmem_cache_alloc(mb_entry_cache, mask);
+ 	if (!entry)
+ 		return -ENOMEM;
+ 
+ 	INIT_LIST_HEAD(&entry->e_list);
+ 	/* One ref for hash, one ref returned */
+ 	atomic_set(&entry->e_refcnt, 1);
+ 	entry->e_key = key;
+ 	entry->e_value = value;
+ 	entry->e_reusable = reusable;
+ 	entry->e_referenced = 0;
+ 	head = mb_cache_entry_head(cache, key);
+ 	hlist_bl_lock(head);
+ 	hlist_bl_for_each_entry(dup, dup_node, head, e_hash_list) {
+ 		if (dup->e_key == key && dup->e_value == value) {
+ 			hlist_bl_unlock(head);
+ 			kmem_cache_free(mb_entry_cache, entry);
+ 			return -EBUSY;
+ 		}
+ 	}
+ 	hlist_bl_add_head(&entry->e_hash_list, head);
+ 	hlist_bl_unlock(head);
+ 
+ 	spin_lock(&cache->c_list_lock);
+ 	list_add_tail(&entry->e_list, &cache->c_list);
+ 	/* Grab ref for LRU list */
+ 	atomic_inc(&entry->e_refcnt);
+ 	cache->c_entry_count++;
+ 	spin_unlock(&cache->c_list_lock);
+ 
+ 	return 0;
+ }
+ EXPORT_SYMBOL(mb_cache_entry_create);
+ 
+ void __mb_cache_entry_free(struct mb_cache_entry *entry)
+ {
+ 	kmem_cache_free(mb_entry_cache, entry);
+ }
+ EXPORT_SYMBOL(__mb_cache_entry_free);
+ 
+ static struct mb_cache_entry *__entry_find(struct mb_cache *cache,
+ 					   struct mb_cache_entry *entry,
+ 					   u32 key)
+ {
+ 	struct mb_cache_entry *old_entry = entry;
+ 	struct hlist_bl_node *node;
+ 	struct hlist_bl_head *head;
+ 
+ 	head = mb_cache_entry_head(cache, key);
+ 	hlist_bl_lock(head);
+ 	if (entry && !hlist_bl_unhashed(&entry->e_hash_list))
+ 		node = entry->e_hash_list.next;
+ 	else
+ 		node = hlist_bl_first(head);
+ 	while (node) {
+ 		entry = hlist_bl_entry(node, struct mb_cache_entry,
+ 				       e_hash_list);
+ 		if (entry->e_key == key && entry->e_reusable) {
+ 			atomic_inc(&entry->e_refcnt);
+ 			goto out;
+ 		}
+ 		node = node->next;
+ 	}
+ 	entry = NULL;
+ out:
+ 	hlist_bl_unlock(head);
+ 	if (old_entry)
+ 		mb_cache_entry_put(cache, old_entry);
+ 
+ 	return entry;
+ }
+ 
+ /*
+  * mb_cache_entry_find_first - find the first reusable entry with the given key
+  * @cache: cache where we should search
+  * @key: key to look for
+  *
+  * Search in @cache for a reusable entry with key @key. Grabs reference to the
+  * first reusable entry found and returns the entry.
+  */
+ struct mb_cache_entry *mb_cache_entry_find_first(struct mb_cache *cache,
+ 						 u32 key)
+ {
+ 	return __entry_find(cache, NULL, key);
+ }
+ EXPORT_SYMBOL(mb_cache_entry_find_first);
+ 
+ /*
+  * mb_cache_entry_find_next - find next reusable entry with the same key
+  * @cache: cache where we should search
+  * @entry: entry to start search from
+  *
+  * Finds next reusable entry in the hash chain which has the same key as @entry.
+  * If @entry is unhashed (which can happen when deletion of entry races with the
+  * search), finds the first reusable entry in the hash chain. The function drops
+  * reference to @entry and returns with a reference to the found entry.
+  */
+ struct mb_cache_entry *mb_cache_entry_find_next(struct mb_cache *cache,
+ 						struct mb_cache_entry *entry)
+ {
+ 	return __entry_find(cache, entry, entry->e_key);
+ }
+ EXPORT_SYMBOL(mb_cache_entry_find_next);
+ 
+ /*
+  * mb_cache_entry_get - get a cache entry by value (and key)
+  * @cache - cache we work with
+  * @key - key
+  * @value - value
+  */
+ struct mb_cache_entry *mb_cache_entry_get(struct mb_cache *cache, u32 key,
+ 					  u64 value)
+ {
+ 	struct hlist_bl_node *node;
+ 	struct hlist_bl_head *head;
+ 	struct mb_cache_entry *entry;
+ 
+ 	head = mb_cache_entry_head(cache, key);
+ 	hlist_bl_lock(head);
+ 	hlist_bl_for_each_entry(entry, node, head, e_hash_list) {
+ 		if (entry->e_key == key && entry->e_value == value) {
+ 			atomic_inc(&entry->e_refcnt);
+ 			goto out;
+ 		}
+ 	}
+ 	entry = NULL;
+ out:
+ 	hlist_bl_unlock(head);
+ 	return entry;
+ }
+ EXPORT_SYMBOL(mb_cache_entry_get);
+ 
+ /* mb_cache_entry_delete - remove a cache entry
+  * @cache - cache we work with
+  * @key - key
+  * @value - value
+  *
+  * Remove entry from cache @cache with key @key and value @value.
+  */
+ void mb_cache_entry_delete(struct mb_cache *cache, u32 key, u64 value)
+ {
+ 	struct hlist_bl_node *node;
+ 	struct hlist_bl_head *head;
+ 	struct mb_cache_entry *entry;
+ 
+ 	head = mb_cache_entry_head(cache, key);
+ 	hlist_bl_lock(head);
+ 	hlist_bl_for_each_entry(entry, node, head, e_hash_list) {
+ 		if (entry->e_key == key && entry->e_value == value) {
+ 			/* We keep hash list reference to keep entry alive */
+ 			hlist_bl_del_init(&entry->e_hash_list);
+ 			hlist_bl_unlock(head);
+ 			spin_lock(&cache->c_list_lock);
+ 			if (!list_empty(&entry->e_list)) {
+ 				list_del_init(&entry->e_list);
+ 				if (!WARN_ONCE(cache->c_entry_count == 0,
+ 		"mbcache: attempt to decrement c_entry_count past zero"))
+ 					cache->c_entry_count--;
+ 				atomic_dec(&entry->e_refcnt);
+ 			}
+ 			spin_unlock(&cache->c_list_lock);
+ 			mb_cache_entry_put(cache, entry);
+ 			return;
+ 		}
+ 	}
+ 	hlist_bl_unlock(head);
+ }
+ EXPORT_SYMBOL(mb_cache_entry_delete);
+ 
+ /* mb_cache_entry_touch - cache entry got used
+  * @cache - cache the entry belongs to
+  * @entry - entry that got used
+  *
+  * Marks entry as used to give hit higher chances of surviving in cache.
+  */
+ void mb_cache_entry_touch(struct mb_cache *cache,
+ 			  struct mb_cache_entry *entry)
+ {
+ 	entry->e_referenced = 1;
+ }
+ EXPORT_SYMBOL(mb_cache_entry_touch);
+ 
+ static unsigned long mb_cache_count(struct shrinker *shrink,
+ 				    struct shrink_control *sc)
+ {
+ 	struct mb_cache *cache = container_of(shrink, struct mb_cache,
+ 					      c_shrink);
+ 
+ 	return cache->c_entry_count;
+ }
+ 
+ /* Shrink number of entries in cache */
+ static unsigned long mb_cache_shrink(struct mb_cache *cache,
+ 				     unsigned long nr_to_scan)
+ {
+ 	struct mb_cache_entry *entry;
+ 	struct hlist_bl_head *head;
+ 	unsigned long shrunk = 0;
+ 
+ 	spin_lock(&cache->c_list_lock);
+ 	while (nr_to_scan-- && !list_empty(&cache->c_list)) {
+ 		entry = list_first_entry(&cache->c_list,
+ 					 struct mb_cache_entry, e_list);
+ 		if (entry->e_referenced) {
+ 			entry->e_referenced = 0;
+ 			list_move_tail(&entry->e_list, &cache->c_list);
+ 			continue;
+ 		}
+ 		list_del_init(&entry->e_list);
+ 		cache->c_entry_count--;
+ 		/*
+ 		 * We keep LRU list reference so that entry doesn't go away
+ 		 * from under us.
+ 		 */
+ 		spin_unlock(&cache->c_list_lock);
+ 		head = mb_cache_entry_head(cache, entry->e_key);
+ 		hlist_bl_lock(head);
+ 		if (!hlist_bl_unhashed(&entry->e_hash_list)) {
+ 			hlist_bl_del_init(&entry->e_hash_list);
+ 			atomic_dec(&entry->e_refcnt);
+ 		}
+ 		hlist_bl_unlock(head);
+ 		if (mb_cache_entry_put(cache, entry))
+ 			shrunk++;
+ 		cond_resched();
+ 		spin_lock(&cache->c_list_lock);
+ 	}
+ 	spin_unlock(&cache->c_list_lock);
+ 
+ 	return shrunk;
+ }
+ 
+ static unsigned long mb_cache_scan(struct shrinker *shrink,
+ 				   struct shrink_control *sc)
+ {
+ 	struct mb_cache *cache = container_of(shrink, struct mb_cache,
+ 					      c_shrink);
+ 	return mb_cache_shrink(cache, sc->nr_to_scan);
+ }
+ 
+ /* We shrink 1/X of the cache when we have too many entries in it */
+ #define SHRINK_DIVISOR 16
+ 
+ static void mb_cache_shrink_worker(struct work_struct *work)
+ {
+ 	struct mb_cache *cache = container_of(work, struct mb_cache,
+ 					      c_shrink_work);
+ 	mb_cache_shrink(cache, cache->c_max_entries / SHRINK_DIVISOR);
+ }
+ 
+ /*
+  * mb_cache_create - create cache
+  * @bucket_bits: log2 of the hash table size
+  *
+  * Create cache for keys with 2^bucket_bits hash entries.
+  */
+ struct mb_cache *mb_cache_create(int bucket_bits)
+ {
+ 	struct mb_cache *cache;
+ 	unsigned long bucket_count = 1UL << bucket_bits;
+ 	unsigned long i;
+ 
+ 	cache = kzalloc(sizeof(struct mb_cache), GFP_KERNEL);
+ 	if (!cache)
+ 		goto err_out;
+ 	cache->c_bucket_bits = bucket_bits;
+ 	cache->c_max_entries = bucket_count << 4;
+ 	INIT_LIST_HEAD(&cache->c_list);
+ 	spin_lock_init(&cache->c_list_lock);
+ 	cache->c_hash = kmalloc_array(bucket_count,
+ 				      sizeof(struct hlist_bl_head),
+ 				      GFP_KERNEL);
+ 	if (!cache->c_hash) {
+ 		kfree(cache);
+ 		goto err_out;
+ 	}
+ 	for (i = 0; i < bucket_count; i++)
+ 		INIT_HLIST_BL_HEAD(&cache->c_hash[i]);
+ 
+ 	cache->c_shrink.count_objects = mb_cache_count;
+ 	cache->c_shrink.scan_objects = mb_cache_scan;
+ 	cache->c_shrink.seeks = DEFAULT_SEEKS;
+ 	if (register_shrinker(&cache->c_shrink)) {
+ 		kfree(cache->c_hash);
+ 		kfree(cache);
+ 		goto err_out;
+ 	}
+ 
+ 	INIT_WORK(&cache->c_shrink_work, mb_cache_shrink_worker);
+ 
+ 	return cache;
+ 
+ err_out:
+ 	return NULL;
+ }
+ EXPORT_SYMBOL(mb_cache_create);
+ 
+ /*
+  * mb_cache_destroy - destroy cache
+  * @cache: the cache to destroy
+  *
+  * Free all entries in cache and cache itself. Caller must make sure nobody
+  * (except shrinker) can reach @cache when calling this.
+  */
+ void mb_cache_destroy(struct mb_cache *cache)
+ {
+ 	struct mb_cache_entry *entry, *next;
+ 
+ 	unregister_shrinker(&cache->c_shrink);
+ 
+ 	/*
+ 	 * We don't bother with any locking. Cache must not be used at this
+ 	 * point.
+ 	 */
+ 	list_for_each_entry_safe(entry, next, &cache->c_list, e_list) {
+ 		if (!hlist_bl_unhashed(&entry->e_hash_list)) {
+ 			hlist_bl_del_init(&entry->e_hash_list);
+ 			atomic_dec(&entry->e_refcnt);
+ 		} else
+ 			WARN_ON(1);
+ 		list_del(&entry->e_list);
+ 		WARN_ON(atomic_read(&entry->e_refcnt) != 1);
+ 		mb_cache_entry_put(cache, entry);
+ 	}
+ 	kfree(cache->c_hash);
+ 	kfree(cache);
+ }
+ EXPORT_SYMBOL(mb_cache_destroy);
+ 
+ static int __init mbcache_init(void)
+ {
+ 	mb_entry_cache = kmem_cache_create("mbcache",
+ 				sizeof(struct mb_cache_entry), 0,
+ 				SLAB_RECLAIM_ACCOUNT|SLAB_MEM_SPREAD, NULL);
+ 	if (!mb_entry_cache)
+ 		return -ENOMEM;
+ 	return 0;
+ }
+ 
+ static void __exit mbcache_exit(void)
+ {
+ 	kmem_cache_destroy(mb_entry_cache);
+ }
+ 
+ module_init(mbcache_init)
+ module_exit(mbcache_exit)
+ 
+ MODULE_AUTHOR("Jan Kara <jack@suse.cz>");
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  MODULE_DESCRIPTION("Meta block cache (for extended attributes)");
  MODULE_LICENSE("GPL");
 +
 +EXPORT_SYMBOL(mb_cache_create);
 +EXPORT_SYMBOL(mb_cache_shrink);
 +EXPORT_SYMBOL(mb_cache_destroy);
 +EXPORT_SYMBOL(mb_cache_entry_alloc);
 +EXPORT_SYMBOL(mb_cache_entry_insert);
 +EXPORT_SYMBOL(mb_cache_entry_release);
 +EXPORT_SYMBOL(mb_cache_entry_free);
 +EXPORT_SYMBOL(mb_cache_entry_get);
 +#if !defined(MB_CACHE_INDEXES_COUNT) || (MB_CACHE_INDEXES_COUNT > 0)
 +EXPORT_SYMBOL(mb_cache_entry_find_first);
 +EXPORT_SYMBOL(mb_cache_entry_find_next);
 +#endif
 +
 +/*
 + * Global data: list of all mbcache's, lru list, and a spinlock for
 + * accessing cache data structures on SMP machines. The lru list is
 + * global across all mbcaches.
 + */
 +
 +static LIST_HEAD(mb_cache_list);
 +static LIST_HEAD(mb_cache_lru_list);
 +static DEFINE_SPINLOCK(mb_cache_spinlock);
 +
 +/*
 + * What the mbcache registers as to get shrunk dynamically.
 + */
 +
 +static int mb_cache_shrink_fn(struct shrinker *shrink,
 +			      struct shrink_control *sc);
 +
 +static struct shrinker mb_cache_shrinker = {
 +	.shrink = mb_cache_shrink_fn,
 +	.seeks = DEFAULT_SEEKS,
 +};
 +
 +static inline int
 +__mb_cache_entry_is_hashed(struct mb_cache_entry *ce)
 +{
 +	return !list_empty(&ce->e_block_list);
 +}
 +
 +
 +static void
 +__mb_cache_entry_unhash(struct mb_cache_entry *ce)
 +{
 +	if (__mb_cache_entry_is_hashed(ce)) {
 +		list_del_init(&ce->e_block_list);
 +		list_del(&ce->e_index.o_list);
 +	}
 +}
 +
 +
 +static void
 +__mb_cache_entry_forget(struct mb_cache_entry *ce, gfp_t gfp_mask)
 +{
 +	struct mb_cache *cache = ce->e_cache;
 +
 +	mb_assert(!(ce->e_used || ce->e_queued));
 +	kmem_cache_free(cache->c_entry_cache, ce);
 +	atomic_dec(&cache->c_entry_count);
 +}
 +
 +
 +static void
 +__mb_cache_entry_release_unlock(struct mb_cache_entry *ce)
 +	__releases(mb_cache_spinlock)
 +{
 +	/* Wake up all processes queuing for this cache entry. */
 +	if (ce->e_queued)
 +		wake_up_all(&mb_cache_queue);
 +	if (ce->e_used >= MB_CACHE_WRITER)
 +		ce->e_used -= MB_CACHE_WRITER;
 +	ce->e_used--;
 +	if (!(ce->e_used || ce->e_queued)) {
 +		if (!__mb_cache_entry_is_hashed(ce))
 +			goto forget;
 +		mb_assert(list_empty(&ce->e_lru_list));
 +		list_add_tail(&ce->e_lru_list, &mb_cache_lru_list);
 +	}
 +	spin_unlock(&mb_cache_spinlock);
 +	return;
 +forget:
 +	spin_unlock(&mb_cache_spinlock);
 +	__mb_cache_entry_forget(ce, GFP_KERNEL);
 +}
 +
 +
 +/*
 + * mb_cache_shrink_fn()  memory pressure callback
 + *
 + * This function is called by the kernel memory management when memory
 + * gets low.
 + *
 + * @shrink: (ignored)
 + * @sc: shrink_control passed from reclaim
 + *
 + * Returns the number of objects which are present in the cache.
 + */
 +static int
 +mb_cache_shrink_fn(struct shrinker *shrink, struct shrink_control *sc)
 +{
 +	LIST_HEAD(free_list);
 +	struct mb_cache *cache;
 +	struct mb_cache_entry *entry, *tmp;
 +	int count = 0;
 +	int nr_to_scan = sc->nr_to_scan;
 +	gfp_t gfp_mask = sc->gfp_mask;
 +
 +	mb_debug("trying to free %d entries", nr_to_scan);
 +	spin_lock(&mb_cache_spinlock);
 +	while (nr_to_scan-- && !list_empty(&mb_cache_lru_list)) {
 +		struct mb_cache_entry *ce =
 +			list_entry(mb_cache_lru_list.next,
 +				   struct mb_cache_entry, e_lru_list);
 +		list_move_tail(&ce->e_lru_list, &free_list);
 +		__mb_cache_entry_unhash(ce);
 +	}
 +	list_for_each_entry(cache, &mb_cache_list, c_cache_list) {
 +		mb_debug("cache %s (%d)", cache->c_name,
 +			  atomic_read(&cache->c_entry_count));
 +		count += atomic_read(&cache->c_entry_count);
 +	}
 +	spin_unlock(&mb_cache_spinlock);
 +	list_for_each_entry_safe(entry, tmp, &free_list, e_lru_list) {
 +		__mb_cache_entry_forget(entry, gfp_mask);
 +	}
 +	return (count / 100) * sysctl_vfs_cache_pressure;
 +}
 +
 +
 +/*
 + * mb_cache_create()  create a new cache
 + *
 + * All entries in one cache are equal size. Cache entries may be from
 + * multiple devices. If this is the first mbcache created, registers
 + * the cache with kernel memory management. Returns NULL if no more
 + * memory was available.
 + *
 + * @name: name of the cache (informal)
 + * @bucket_bits: log2(number of hash buckets)
 + */
 +struct mb_cache *
 +mb_cache_create(const char *name, int bucket_bits)
 +{
 +	int n, bucket_count = 1 << bucket_bits;
 +	struct mb_cache *cache = NULL;
 +
 +	cache = kmalloc(sizeof(struct mb_cache), GFP_KERNEL);
 +	if (!cache)
 +		return NULL;
 +	cache->c_name = name;
 +	atomic_set(&cache->c_entry_count, 0);
 +	cache->c_bucket_bits = bucket_bits;
 +	cache->c_block_hash = kmalloc(bucket_count * sizeof(struct list_head),
 +	                              GFP_KERNEL);
 +	if (!cache->c_block_hash)
 +		goto fail;
 +	for (n=0; n<bucket_count; n++)
 +		INIT_LIST_HEAD(&cache->c_block_hash[n]);
 +	cache->c_index_hash = kmalloc(bucket_count * sizeof(struct list_head),
 +				      GFP_KERNEL);
 +	if (!cache->c_index_hash)
 +		goto fail;
 +	for (n=0; n<bucket_count; n++)
 +		INIT_LIST_HEAD(&cache->c_index_hash[n]);
 +	cache->c_entry_cache = kmem_cache_create(name,
 +		sizeof(struct mb_cache_entry), 0,
 +		SLAB_RECLAIM_ACCOUNT|SLAB_MEM_SPREAD, NULL);
 +	if (!cache->c_entry_cache)
 +		goto fail2;
 +
 +	/*
 +	 * Set an upper limit on the number of cache entries so that the hash
 +	 * chains won't grow too long.
 +	 */
 +	cache->c_max_entries = bucket_count << 4;
 +
 +	spin_lock(&mb_cache_spinlock);
 +	list_add(&cache->c_cache_list, &mb_cache_list);
 +	spin_unlock(&mb_cache_spinlock);
 +	return cache;
 +
 +fail2:
 +	kfree(cache->c_index_hash);
 +
 +fail:
 +	kfree(cache->c_block_hash);
 +	kfree(cache);
 +	return NULL;
 +}
 +
 +
 +/*
 + * mb_cache_shrink()
 + *
 + * Removes all cache entries of a device from the cache. All cache entries
 + * currently in use cannot be freed, and thus remain in the cache. All others
 + * are freed.
 + *
 + * @bdev: which device's cache entries to shrink
 + */
 +void
 +mb_cache_shrink(struct block_device *bdev)
 +{
 +	LIST_HEAD(free_list);
 +	struct list_head *l, *ltmp;
 +
 +	spin_lock(&mb_cache_spinlock);
 +	list_for_each_safe(l, ltmp, &mb_cache_lru_list) {
 +		struct mb_cache_entry *ce =
 +			list_entry(l, struct mb_cache_entry, e_lru_list);
 +		if (ce->e_bdev == bdev) {
 +			list_move_tail(&ce->e_lru_list, &free_list);
 +			__mb_cache_entry_unhash(ce);
 +		}
 +	}
 +	spin_unlock(&mb_cache_spinlock);
 +	list_for_each_safe(l, ltmp, &free_list) {
 +		__mb_cache_entry_forget(list_entry(l, struct mb_cache_entry,
 +						   e_lru_list), GFP_KERNEL);
 +	}
 +}
 +
 +
 +/*
 + * mb_cache_destroy()
 + *
 + * Shrinks the cache to its minimum possible size (hopefully 0 entries),
 + * and then destroys it. If this was the last mbcache, un-registers the
 + * mbcache from kernel memory management.
 + */
 +void
 +mb_cache_destroy(struct mb_cache *cache)
 +{
 +	LIST_HEAD(free_list);
 +	struct list_head *l, *ltmp;
 +
 +	spin_lock(&mb_cache_spinlock);
 +	list_for_each_safe(l, ltmp, &mb_cache_lru_list) {
 +		struct mb_cache_entry *ce =
 +			list_entry(l, struct mb_cache_entry, e_lru_list);
 +		if (ce->e_cache == cache) {
 +			list_move_tail(&ce->e_lru_list, &free_list);
 +			__mb_cache_entry_unhash(ce);
 +		}
 +	}
 +	list_del(&cache->c_cache_list);
 +	spin_unlock(&mb_cache_spinlock);
 +
 +	list_for_each_safe(l, ltmp, &free_list) {
 +		__mb_cache_entry_forget(list_entry(l, struct mb_cache_entry,
 +						   e_lru_list), GFP_KERNEL);
 +	}
 +
 +	if (atomic_read(&cache->c_entry_count) > 0) {
 +		mb_error("cache %s: %d orphaned entries",
 +			  cache->c_name,
 +			  atomic_read(&cache->c_entry_count));
 +	}
 +
 +	kmem_cache_destroy(cache->c_entry_cache);
 +
 +	kfree(cache->c_index_hash);
 +	kfree(cache->c_block_hash);
 +	kfree(cache);
 +}
 +
 +/*
 + * mb_cache_entry_alloc()
 + *
 + * Allocates a new cache entry. The new entry will not be valid initially,
 + * and thus cannot be looked up yet. It should be filled with data, and
 + * then inserted into the cache using mb_cache_entry_insert(). Returns NULL
 + * if no more memory was available.
 + */
 +struct mb_cache_entry *
 +mb_cache_entry_alloc(struct mb_cache *cache, gfp_t gfp_flags)
 +{
 +	struct mb_cache_entry *ce = NULL;
 +
 +	if (atomic_read(&cache->c_entry_count) >= cache->c_max_entries) {
 +		spin_lock(&mb_cache_spinlock);
 +		if (!list_empty(&mb_cache_lru_list)) {
 +			ce = list_entry(mb_cache_lru_list.next,
 +					struct mb_cache_entry, e_lru_list);
 +			list_del_init(&ce->e_lru_list);
 +			__mb_cache_entry_unhash(ce);
 +		}
 +		spin_unlock(&mb_cache_spinlock);
 +	}
 +	if (!ce) {
 +		ce = kmem_cache_alloc(cache->c_entry_cache, gfp_flags);
 +		if (!ce)
 +			return NULL;
 +		atomic_inc(&cache->c_entry_count);
 +		INIT_LIST_HEAD(&ce->e_lru_list);
 +		INIT_LIST_HEAD(&ce->e_block_list);
 +		ce->e_cache = cache;
 +		ce->e_queued = 0;
 +	}
 +	ce->e_used = 1 + MB_CACHE_WRITER;
 +	return ce;
 +}
 +
 +
 +/*
 + * mb_cache_entry_insert()
 + *
 + * Inserts an entry that was allocated using mb_cache_entry_alloc() into
 + * the cache. After this, the cache entry can be looked up, but is not yet
 + * in the lru list as the caller still holds a handle to it. Returns 0 on
 + * success, or -EBUSY if a cache entry for that device + inode exists
 + * already (this may happen after a failed lookup, but when another process
 + * has inserted the same cache entry in the meantime).
 + *
 + * @bdev: device the cache entry belongs to
 + * @block: block number
 + * @key: lookup key
 + */
 +int
 +mb_cache_entry_insert(struct mb_cache_entry *ce, struct block_device *bdev,
 +		      sector_t block, unsigned int key)
 +{
 +	struct mb_cache *cache = ce->e_cache;
 +	unsigned int bucket;
 +	struct list_head *l;
 +	int error = -EBUSY;
 +
 +	bucket = hash_long((unsigned long)bdev + (block & 0xffffffff), 
 +			   cache->c_bucket_bits);
 +	spin_lock(&mb_cache_spinlock);
 +	list_for_each_prev(l, &cache->c_block_hash[bucket]) {
 +		struct mb_cache_entry *ce =
 +			list_entry(l, struct mb_cache_entry, e_block_list);
 +		if (ce->e_bdev == bdev && ce->e_block == block)
 +			goto out;
 +	}
 +	__mb_cache_entry_unhash(ce);
 +	ce->e_bdev = bdev;
 +	ce->e_block = block;
 +	list_add(&ce->e_block_list, &cache->c_block_hash[bucket]);
 +	ce->e_index.o_key = key;
 +	bucket = hash_long(key, cache->c_bucket_bits);
 +	list_add(&ce->e_index.o_list, &cache->c_index_hash[bucket]);
 +	error = 0;
 +out:
 +	spin_unlock(&mb_cache_spinlock);
 +	return error;
 +}
 +
 +
 +/*
 + * mb_cache_entry_release()
 + *
 + * Release a handle to a cache entry. When the last handle to a cache entry
 + * is released it is either freed (if it is invalid) or otherwise inserted
 + * in to the lru list.
 + */
 +void
 +mb_cache_entry_release(struct mb_cache_entry *ce)
 +{
 +	spin_lock(&mb_cache_spinlock);
 +	__mb_cache_entry_release_unlock(ce);
 +}
 +
 +
 +/*
 + * mb_cache_entry_free()
 + *
 + * This is equivalent to the sequence mb_cache_entry_takeout() --
 + * mb_cache_entry_release().
 + */
 +void
 +mb_cache_entry_free(struct mb_cache_entry *ce)
 +{
 +	spin_lock(&mb_cache_spinlock);
 +	mb_assert(list_empty(&ce->e_lru_list));
 +	__mb_cache_entry_unhash(ce);
 +	__mb_cache_entry_release_unlock(ce);
 +}
 +
 +
 +/*
 + * mb_cache_entry_get()
 + *
 + * Get a cache entry  by device / block number. (There can only be one entry
 + * in the cache per device and block.) Returns NULL if no such cache entry
 + * exists. The returned cache entry is locked for exclusive access ("single
 + * writer").
 + */
 +struct mb_cache_entry *
 +mb_cache_entry_get(struct mb_cache *cache, struct block_device *bdev,
 +		   sector_t block)
 +{
 +	unsigned int bucket;
 +	struct list_head *l;
 +	struct mb_cache_entry *ce;
 +
 +	bucket = hash_long((unsigned long)bdev + (block & 0xffffffff),
 +			   cache->c_bucket_bits);
 +	spin_lock(&mb_cache_spinlock);
 +	list_for_each(l, &cache->c_block_hash[bucket]) {
 +		ce = list_entry(l, struct mb_cache_entry, e_block_list);
 +		if (ce->e_bdev == bdev && ce->e_block == block) {
 +			DEFINE_WAIT(wait);
 +
 +			if (!list_empty(&ce->e_lru_list))
 +				list_del_init(&ce->e_lru_list);
 +
 +			while (ce->e_used > 0) {
 +				ce->e_queued++;
 +				prepare_to_wait(&mb_cache_queue, &wait,
 +						TASK_UNINTERRUPTIBLE);
 +				spin_unlock(&mb_cache_spinlock);
 +				schedule();
 +				spin_lock(&mb_cache_spinlock);
 +				ce->e_queued--;
 +			}
 +			finish_wait(&mb_cache_queue, &wait);
 +			ce->e_used += 1 + MB_CACHE_WRITER;
 +
 +			if (!__mb_cache_entry_is_hashed(ce)) {
 +				__mb_cache_entry_release_unlock(ce);
 +				return NULL;
 +			}
 +			goto cleanup;
 +		}
 +	}
 +	ce = NULL;
 +
 +cleanup:
 +	spin_unlock(&mb_cache_spinlock);
 +	return ce;
 +}
 +
 +#if !defined(MB_CACHE_INDEXES_COUNT) || (MB_CACHE_INDEXES_COUNT > 0)
 +
 +static struct mb_cache_entry *
 +__mb_cache_entry_find(struct list_head *l, struct list_head *head,
 +		      struct block_device *bdev, unsigned int key)
 +{
 +	while (l != head) {
 +		struct mb_cache_entry *ce =
 +			list_entry(l, struct mb_cache_entry, e_index.o_list);
 +		if (ce->e_bdev == bdev && ce->e_index.o_key == key) {
 +			DEFINE_WAIT(wait);
 +
 +			if (!list_empty(&ce->e_lru_list))
 +				list_del_init(&ce->e_lru_list);
 +
 +			/* Incrementing before holding the lock gives readers
 +			   priority over writers. */
 +			ce->e_used++;
 +			while (ce->e_used >= MB_CACHE_WRITER) {
 +				ce->e_queued++;
 +				prepare_to_wait(&mb_cache_queue, &wait,
 +						TASK_UNINTERRUPTIBLE);
 +				spin_unlock(&mb_cache_spinlock);
 +				schedule();
 +				spin_lock(&mb_cache_spinlock);
 +				ce->e_queued--;
 +			}
 +			finish_wait(&mb_cache_queue, &wait);
 +
 +			if (!__mb_cache_entry_is_hashed(ce)) {
 +				__mb_cache_entry_release_unlock(ce);
 +				spin_lock(&mb_cache_spinlock);
 +				return ERR_PTR(-EAGAIN);
 +			}
 +			return ce;
 +		}
 +		l = l->next;
 +	}
 +	return NULL;
 +}
 +
 +
 +/*
 + * mb_cache_entry_find_first()
 + *
 + * Find the first cache entry on a given device with a certain key in
 + * an additional index. Additional matches can be found with
 + * mb_cache_entry_find_next(). Returns NULL if no match was found. The
 + * returned cache entry is locked for shared access ("multiple readers").
 + *
 + * @cache: the cache to search
 + * @bdev: the device the cache entry should belong to
 + * @key: the key in the index
 + */
 +struct mb_cache_entry *
 +mb_cache_entry_find_first(struct mb_cache *cache, struct block_device *bdev,
 +			  unsigned int key)
 +{
 +	unsigned int bucket = hash_long(key, cache->c_bucket_bits);
 +	struct list_head *l;
 +	struct mb_cache_entry *ce;
 +
 +	spin_lock(&mb_cache_spinlock);
 +	l = cache->c_index_hash[bucket].next;
 +	ce = __mb_cache_entry_find(l, &cache->c_index_hash[bucket], bdev, key);
 +	spin_unlock(&mb_cache_spinlock);
 +	return ce;
 +}
 +
 +
 +/*
 + * mb_cache_entry_find_next()
 + *
 + * Find the next cache entry on a given device with a certain key in an
 + * additional index. Returns NULL if no match could be found. The previous
 + * entry is atomatically released, so that mb_cache_entry_find_next() can
 + * be called like this:
 + *
 + * entry = mb_cache_entry_find_first();
 + * while (entry) {
 + * 	...
 + *	entry = mb_cache_entry_find_next(entry, ...);
 + * }
 + *
 + * @prev: The previous match
 + * @bdev: the device the cache entry should belong to
 + * @key: the key in the index
 + */
 +struct mb_cache_entry *
 +mb_cache_entry_find_next(struct mb_cache_entry *prev,
 +			 struct block_device *bdev, unsigned int key)
 +{
 +	struct mb_cache *cache = prev->e_cache;
 +	unsigned int bucket = hash_long(key, cache->c_bucket_bits);
 +	struct list_head *l;
 +	struct mb_cache_entry *ce;
 +
 +	spin_lock(&mb_cache_spinlock);
 +	l = prev->e_index.o_list.next;
 +	ce = __mb_cache_entry_find(l, &cache->c_index_hash[bucket], bdev, key);
 +	__mb_cache_entry_release_unlock(prev);
 +	return ce;
 +}
 +
 +#endif  /* !defined(MB_CACHE_INDEXES_COUNT) || (MB_CACHE_INDEXES_COUNT > 0) */
 +
 +static int __init init_mbcache(void)
 +{
 +	register_shrinker(&mb_cache_shrinker);
 +	return 0;
 +}
 +
 +static void __exit exit_mbcache(void)
 +{
 +	unregister_shrinker(&mb_cache_shrinker);
 +}
 +
 +module_init(init_mbcache)
 +module_exit(exit_mbcache)
 +
diff --cc fs/namei.c
index 081045d3a2f2,2490ddb8bc90..000000000000
--- a/fs/namei.c
+++ b/fs/namei.c
@@@ -490,6 -486,72 +490,75 @@@ void path_put(const struct path *path
  }
  EXPORT_SYMBOL(path_put);
  
++<<<<<<< HEAD
++=======
+ #define EMBEDDED_LEVELS 2
+ struct nameidata {
+ 	struct path	path;
+ 	struct qstr	last;
+ 	struct path	root;
+ 	struct inode	*inode; /* path.dentry.d_inode */
+ 	unsigned int	flags;
+ 	unsigned	seq, m_seq;
+ 	int		last_type;
+ 	unsigned	depth;
+ 	int		total_link_count;
+ 	struct saved {
+ 		struct path link;
+ 		struct delayed_call done;
+ 		const char *name;
+ 		unsigned seq;
+ 	} *stack, internal[EMBEDDED_LEVELS];
+ 	struct filename	*name;
+ 	struct nameidata *saved;
+ 	struct inode	*link_inode;
+ 	unsigned	root_seq;
+ 	int		dfd;
+ } __randomize_layout;
+ 
+ static void set_nameidata(struct nameidata *p, int dfd, struct filename *name)
+ {
+ 	struct nameidata *old = current->nameidata;
+ 	p->stack = p->internal;
+ 	p->dfd = dfd;
+ 	p->name = name;
+ 	p->total_link_count = old ? old->total_link_count : 0;
+ 	p->saved = old;
+ 	current->nameidata = p;
+ }
+ 
+ static void restore_nameidata(void)
+ {
+ 	struct nameidata *now = current->nameidata, *old = now->saved;
+ 
+ 	current->nameidata = old;
+ 	if (old)
+ 		old->total_link_count = now->total_link_count;
+ 	if (now->stack != now->internal)
+ 		kfree(now->stack);
+ }
+ 
+ static int __nd_alloc_stack(struct nameidata *nd)
+ {
+ 	struct saved *p;
+ 
+ 	if (nd->flags & LOOKUP_RCU) {
+ 		p= kmalloc_array(MAXSYMLINKS, sizeof(struct saved),
+ 				  GFP_ATOMIC);
+ 		if (unlikely(!p))
+ 			return -ECHILD;
+ 	} else {
+ 		p= kmalloc_array(MAXSYMLINKS, sizeof(struct saved),
+ 				  GFP_KERNEL);
+ 		if (unlikely(!p))
+ 			return -ENOMEM;
+ 	}
+ 	memcpy(p, nd->internal, sizeof(nd->internal));
+ 	nd->stack = p;
+ 	return 0;
+ }
+ 
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  /**
   * path_connected - Verify that a path->dentry is below path->mnt.mnt_root
   * @path: nameidate to verify
diff --cc fs/proc/task_mmu.c
index bf81d9f4a02e,e9679016271f..000000000000
--- a/fs/proc/task_mmu.c
+++ b/fs/proc/task_mmu.c
@@@ -1324,9 -1469,11 +1324,13 @@@ static ssize_t pagemap_read(struct fil
  	if (!count)
  		goto out_mm;
  
 -	/* do not disclose physical addresses: attack vector */
 -	pm.show_pfn = file_ns_capable(file, &init_user_ns, CAP_SYS_ADMIN);
 -
 +	pm.v2 = soft_dirty_cleared;
  	pm.len = (PAGEMAP_WALK_SIZE >> PAGE_SHIFT);
++<<<<<<< HEAD
 +	pm.buffer = kmalloc(pm.len * PM_ENTRY_BYTES, GFP_TEMPORARY);
++=======
+ 	pm.buffer = kmalloc_array(pm.len, PM_ENTRY_BYTES, GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	ret = -ENOMEM;
  	if (!pm.buffer)
  		goto out_mm;
diff --cc fs/read_write.c
index 75b109f135ee,153f8f690490..000000000000
--- a/fs/read_write.c
+++ b/fs/read_write.c
@@@ -787,60 -825,106 +787,140 @@@ out
  	return ret;
  }
  
++<<<<<<< HEAD
 +static ssize_t do_readv_writev(int type, struct file *file,
 +			       const struct iovec __user * uvector,
 +			       unsigned long nr_segs, loff_t *pos)
++=======
+ #ifdef CONFIG_COMPAT
+ ssize_t compat_rw_copy_check_uvector(int type,
+ 		const struct compat_iovec __user *uvector, unsigned long nr_segs,
+ 		unsigned long fast_segs, struct iovec *fast_pointer,
+ 		struct iovec **ret_pointer)
+ {
+ 	compat_ssize_t tot_len;
+ 	struct iovec *iov = *ret_pointer = fast_pointer;
+ 	ssize_t ret = 0;
+ 	int seg;
+ 
+ 	/*
+ 	 * SuS says "The readv() function *may* fail if the iovcnt argument
+ 	 * was less than or equal to 0, or greater than {IOV_MAX}.  Linux has
+ 	 * traditionally returned zero for zero segments, so...
+ 	 */
+ 	if (nr_segs == 0)
+ 		goto out;
+ 
+ 	ret = -EINVAL;
+ 	if (nr_segs > UIO_MAXIOV)
+ 		goto out;
+ 	if (nr_segs > fast_segs) {
+ 		ret = -ENOMEM;
+ 		iov = kmalloc_array(nr_segs, sizeof(struct iovec), GFP_KERNEL);
+ 		if (iov == NULL)
+ 			goto out;
+ 	}
+ 	*ret_pointer = iov;
+ 
+ 	ret = -EFAULT;
+ 	if (!access_ok(VERIFY_READ, uvector, nr_segs*sizeof(*uvector)))
+ 		goto out;
+ 
+ 	/*
+ 	 * Single unix specification:
+ 	 * We should -EINVAL if an element length is not >= 0 and fitting an
+ 	 * ssize_t.
+ 	 *
+ 	 * In Linux, the total length is limited to MAX_RW_COUNT, there is
+ 	 * no overflow possibility.
+ 	 */
+ 	tot_len = 0;
+ 	ret = -EINVAL;
+ 	for (seg = 0; seg < nr_segs; seg++) {
+ 		compat_uptr_t buf;
+ 		compat_ssize_t len;
+ 
+ 		if (__get_user(len, &uvector->iov_len) ||
+ 		   __get_user(buf, &uvector->iov_base)) {
+ 			ret = -EFAULT;
+ 			goto out;
+ 		}
+ 		if (len < 0)	/* size_t not fitting in compat_ssize_t .. */
+ 			goto out;
+ 		if (type >= 0 &&
+ 		    !access_ok(vrfy_dir(type), compat_ptr(buf), len)) {
+ 			ret = -EFAULT;
+ 			goto out;
+ 		}
+ 		if (len > MAX_RW_COUNT - tot_len)
+ 			len = MAX_RW_COUNT - tot_len;
+ 		tot_len += len;
+ 		iov->iov_base = compat_ptr(buf);
+ 		iov->iov_len = (compat_size_t) len;
+ 		uvector++;
+ 		iov++;
+ 	}
+ 	ret = tot_len;
+ 
+ out:
+ 	return ret;
+ }
+ #endif
+ 
+ static ssize_t do_iter_read(struct file *file, struct iov_iter *iter,
+ 		loff_t *pos, rwf_t flags)
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  {
  	size_t tot_len;
 -	ssize_t ret = 0;
 +	struct iovec iovstack[UIO_FASTIOV];
 +	struct iovec *iov = iovstack;
 +	ssize_t ret;
 +	io_fn_t fn;
 +	iov_fn_t fnv;
  
 -	if (!(file->f_mode & FMODE_READ))
 -		return -EBADF;
 -	if (!(file->f_mode & FMODE_CAN_READ))
 -		return -EINVAL;
 +	if (!file->f_op) {
 +		ret = -EINVAL;
 +		goto out;
 +	}
  
 -	tot_len = iov_iter_count(iter);
 -	if (!tot_len)
 +	ret = rw_copy_check_uvector(type, uvector, nr_segs,
 +				    ARRAY_SIZE(iovstack), iovstack, &iov);
 +	if (ret <= 0)
  		goto out;
 -	ret = rw_verify_area(READ, file, pos, tot_len);
 +
 +	tot_len = ret;
 +	ret = rw_verify_area(type, file, pos, tot_len);
  	if (ret < 0)
 -		return ret;
 +		goto out;
 +
 +	fnv = NULL;
 +	if (type == READ) {
 +		fn = file->f_op->read;
 +		fnv = file->f_op->aio_read;
 +	} else {
 +		fn = (io_fn_t)file->f_op->write;
 +		fnv = file->f_op->aio_write;
 +		file_start_write(file);
 +	}
  
 -	if (file->f_op->read_iter)
 -		ret = do_iter_readv_writev(file, iter, pos, READ, flags);
 +	if (fnv)
 +		ret = do_sync_readv_writev(file, iov, nr_segs, tot_len,
 +						pos, fnv);
  	else
 -		ret = do_loop_readv_writev(file, iter, pos, READ, flags);
 +		ret = do_loop_readv_writev(file, iov, nr_segs, pos, fn);
 +
 +	if (type != READ)
 +		file_end_write(file);
 +
  out:
 -	if (ret >= 0)
 -		fsnotify_access(file);
 +	if (iov != iovstack)
 +		kfree(iov);
 +	if ((ret + (type == READ)) > 0) {
 +		if (type == READ)
 +			fsnotify_access(file);
 +		else
 +			fsnotify_modify(file);
 +	}
  	return ret;
  }
  
diff --cc fs/reiserfs/journal.c
index 742fdd4c209a,358ee2a1ce1a..000000000000
--- a/fs/reiserfs/journal.c
+++ b/fs/reiserfs/journal.c
@@@ -2149,11 -2188,16 +2149,24 @@@ static int journal_read_transaction(str
  	}
  
  	trans_id = get_desc_trans_id(desc);
++<<<<<<< HEAD
 +	/* now we know we've got a good transaction, and it was inside the valid time ranges */
 +	log_blocks = kmalloc(get_desc_trans_len(desc) *
 +			     sizeof(struct buffer_head *), GFP_NOFS);
 +	real_blocks = kmalloc(get_desc_trans_len(desc) *
 +			      sizeof(struct buffer_head *), GFP_NOFS);
++=======
+ 	/*
+ 	 * now we know we've got a good transaction, and it was
+ 	 * inside the valid time ranges
+ 	 */
+ 	log_blocks = kmalloc_array(get_desc_trans_len(desc),
+ 				   sizeof(struct buffer_head *),
+ 				   GFP_NOFS);
+ 	real_blocks = kmalloc_array(get_desc_trans_len(desc),
+ 				    sizeof(struct buffer_head *),
+ 				    GFP_NOFS);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (!log_blocks || !real_blocks) {
  		brelse(c_bh);
  		brelse(d_bh);
diff --cc fs/select.c
index 0d775cffd01a,317891ff8165..000000000000
--- a/fs/select.c
+++ b/fs/select.c
@@@ -1044,3 -1117,331 +1044,334 @@@ SYSCALL_DEFINE5(ppoll, struct pollfd __
  
  	return ret;
  }
++<<<<<<< HEAD
++=======
+ 
+ #ifdef CONFIG_COMPAT
+ #define __COMPAT_NFDBITS       (8 * sizeof(compat_ulong_t))
+ 
+ static
+ int compat_poll_select_copy_remaining(struct timespec64 *end_time, void __user *p,
+ 				      int timeval, int ret)
+ {
+ 	struct timespec64 ts;
+ 
+ 	if (!p)
+ 		return ret;
+ 
+ 	if (current->personality & STICKY_TIMEOUTS)
+ 		goto sticky;
+ 
+ 	/* No update for zero timeout */
+ 	if (!end_time->tv_sec && !end_time->tv_nsec)
+ 		return ret;
+ 
+ 	ktime_get_ts64(&ts);
+ 	ts = timespec64_sub(*end_time, ts);
+ 	if (ts.tv_sec < 0)
+ 		ts.tv_sec = ts.tv_nsec = 0;
+ 
+ 	if (timeval) {
+ 		struct compat_timeval rtv;
+ 
+ 		rtv.tv_sec = ts.tv_sec;
+ 		rtv.tv_usec = ts.tv_nsec / NSEC_PER_USEC;
+ 
+ 		if (!copy_to_user(p, &rtv, sizeof(rtv)))
+ 			return ret;
+ 	} else {
+ 		if (!compat_put_timespec64(&ts, p))
+ 			return ret;
+ 	}
+ 	/*
+ 	 * If an application puts its timeval in read-only memory, we
+ 	 * don't want the Linux-specific update to the timeval to
+ 	 * cause a fault after the select has completed
+ 	 * successfully. However, because we're not updating the
+ 	 * timeval, we can't restart the system call.
+ 	 */
+ 
+ sticky:
+ 	if (ret == -ERESTARTNOHAND)
+ 		ret = -EINTR;
+ 	return ret;
+ }
+ 
+ /*
+  * Ooo, nasty.  We need here to frob 32-bit unsigned longs to
+  * 64-bit unsigned longs.
+  */
+ static
+ int compat_get_fd_set(unsigned long nr, compat_ulong_t __user *ufdset,
+ 			unsigned long *fdset)
+ {
+ 	if (ufdset) {
+ 		return compat_get_bitmap(fdset, ufdset, nr);
+ 	} else {
+ 		zero_fd_set(nr, fdset);
+ 		return 0;
+ 	}
+ }
+ 
+ static
+ int compat_set_fd_set(unsigned long nr, compat_ulong_t __user *ufdset,
+ 		      unsigned long *fdset)
+ {
+ 	if (!ufdset)
+ 		return 0;
+ 	return compat_put_bitmap(ufdset, fdset, nr);
+ }
+ 
+ 
+ /*
+  * This is a virtual copy of sys_select from fs/select.c and probably
+  * should be compared to it from time to time
+  */
+ 
+ /*
+  * We can actually return ERESTARTSYS instead of EINTR, but I'd
+  * like to be certain this leads to no problems. So I return
+  * EINTR just for safety.
+  *
+  * Update: ERESTARTSYS breaks at least the xview clock binary, so
+  * I'm trying ERESTARTNOHAND which restart only when you want to.
+  */
+ static int compat_core_sys_select(int n, compat_ulong_t __user *inp,
+ 	compat_ulong_t __user *outp, compat_ulong_t __user *exp,
+ 	struct timespec64 *end_time)
+ {
+ 	fd_set_bits fds;
+ 	void *bits;
+ 	int size, max_fds, ret = -EINVAL;
+ 	struct fdtable *fdt;
+ 	long stack_fds[SELECT_STACK_ALLOC/sizeof(long)];
+ 
+ 	if (n < 0)
+ 		goto out_nofds;
+ 
+ 	/* max_fds can increase, so grab it once to avoid race */
+ 	rcu_read_lock();
+ 	fdt = files_fdtable(current->files);
+ 	max_fds = fdt->max_fds;
+ 	rcu_read_unlock();
+ 	if (n > max_fds)
+ 		n = max_fds;
+ 
+ 	/*
+ 	 * We need 6 bitmaps (in/out/ex for both incoming and outgoing),
+ 	 * since we used fdset we need to allocate memory in units of
+ 	 * long-words.
+ 	 */
+ 	size = FDS_BYTES(n);
+ 	bits = stack_fds;
+ 	if (size > sizeof(stack_fds) / 6) {
+ 		bits = kmalloc_array(6, size, GFP_KERNEL);
+ 		ret = -ENOMEM;
+ 		if (!bits)
+ 			goto out_nofds;
+ 	}
+ 	fds.in      = (unsigned long *)  bits;
+ 	fds.out     = (unsigned long *) (bits +   size);
+ 	fds.ex      = (unsigned long *) (bits + 2*size);
+ 	fds.res_in  = (unsigned long *) (bits + 3*size);
+ 	fds.res_out = (unsigned long *) (bits + 4*size);
+ 	fds.res_ex  = (unsigned long *) (bits + 5*size);
+ 
+ 	if ((ret = compat_get_fd_set(n, inp, fds.in)) ||
+ 	    (ret = compat_get_fd_set(n, outp, fds.out)) ||
+ 	    (ret = compat_get_fd_set(n, exp, fds.ex)))
+ 		goto out;
+ 	zero_fd_set(n, fds.res_in);
+ 	zero_fd_set(n, fds.res_out);
+ 	zero_fd_set(n, fds.res_ex);
+ 
+ 	ret = do_select(n, &fds, end_time);
+ 
+ 	if (ret < 0)
+ 		goto out;
+ 	if (!ret) {
+ 		ret = -ERESTARTNOHAND;
+ 		if (signal_pending(current))
+ 			goto out;
+ 		ret = 0;
+ 	}
+ 
+ 	if (compat_set_fd_set(n, inp, fds.res_in) ||
+ 	    compat_set_fd_set(n, outp, fds.res_out) ||
+ 	    compat_set_fd_set(n, exp, fds.res_ex))
+ 		ret = -EFAULT;
+ out:
+ 	if (bits != stack_fds)
+ 		kfree(bits);
+ out_nofds:
+ 	return ret;
+ }
+ 
+ static int do_compat_select(int n, compat_ulong_t __user *inp,
+ 	compat_ulong_t __user *outp, compat_ulong_t __user *exp,
+ 	struct compat_timeval __user *tvp)
+ {
+ 	struct timespec64 end_time, *to = NULL;
+ 	struct compat_timeval tv;
+ 	int ret;
+ 
+ 	if (tvp) {
+ 		if (copy_from_user(&tv, tvp, sizeof(tv)))
+ 			return -EFAULT;
+ 
+ 		to = &end_time;
+ 		if (poll_select_set_timeout(to,
+ 				tv.tv_sec + (tv.tv_usec / USEC_PER_SEC),
+ 				(tv.tv_usec % USEC_PER_SEC) * NSEC_PER_USEC))
+ 			return -EINVAL;
+ 	}
+ 
+ 	ret = compat_core_sys_select(n, inp, outp, exp, to);
+ 	ret = compat_poll_select_copy_remaining(&end_time, tvp, 1, ret);
+ 
+ 	return ret;
+ }
+ 
+ COMPAT_SYSCALL_DEFINE5(select, int, n, compat_ulong_t __user *, inp,
+ 	compat_ulong_t __user *, outp, compat_ulong_t __user *, exp,
+ 	struct compat_timeval __user *, tvp)
+ {
+ 	return do_compat_select(n, inp, outp, exp, tvp);
+ }
+ 
+ struct compat_sel_arg_struct {
+ 	compat_ulong_t n;
+ 	compat_uptr_t inp;
+ 	compat_uptr_t outp;
+ 	compat_uptr_t exp;
+ 	compat_uptr_t tvp;
+ };
+ 
+ COMPAT_SYSCALL_DEFINE1(old_select, struct compat_sel_arg_struct __user *, arg)
+ {
+ 	struct compat_sel_arg_struct a;
+ 
+ 	if (copy_from_user(&a, arg, sizeof(a)))
+ 		return -EFAULT;
+ 	return do_compat_select(a.n, compat_ptr(a.inp), compat_ptr(a.outp),
+ 				compat_ptr(a.exp), compat_ptr(a.tvp));
+ }
+ 
+ static long do_compat_pselect(int n, compat_ulong_t __user *inp,
+ 	compat_ulong_t __user *outp, compat_ulong_t __user *exp,
+ 	struct compat_timespec __user *tsp, compat_sigset_t __user *sigmask,
+ 	compat_size_t sigsetsize)
+ {
+ 	sigset_t ksigmask, sigsaved;
+ 	struct timespec64 ts, end_time, *to = NULL;
+ 	int ret;
+ 
+ 	if (tsp) {
+ 		if (compat_get_timespec64(&ts, tsp))
+ 			return -EFAULT;
+ 
+ 		to = &end_time;
+ 		if (poll_select_set_timeout(to, ts.tv_sec, ts.tv_nsec))
+ 			return -EINVAL;
+ 	}
+ 
+ 	if (sigmask) {
+ 		if (sigsetsize != sizeof(compat_sigset_t))
+ 			return -EINVAL;
+ 		if (get_compat_sigset(&ksigmask, sigmask))
+ 			return -EFAULT;
+ 
+ 		sigdelsetmask(&ksigmask, sigmask(SIGKILL)|sigmask(SIGSTOP));
+ 		sigprocmask(SIG_SETMASK, &ksigmask, &sigsaved);
+ 	}
+ 
+ 	ret = compat_core_sys_select(n, inp, outp, exp, to);
+ 	ret = compat_poll_select_copy_remaining(&end_time, tsp, 0, ret);
+ 
+ 	if (ret == -ERESTARTNOHAND) {
+ 		/*
+ 		 * Don't restore the signal mask yet. Let do_signal() deliver
+ 		 * the signal on the way back to userspace, before the signal
+ 		 * mask is restored.
+ 		 */
+ 		if (sigmask) {
+ 			memcpy(&current->saved_sigmask, &sigsaved,
+ 					sizeof(sigsaved));
+ 			set_restore_sigmask();
+ 		}
+ 	} else if (sigmask)
+ 		sigprocmask(SIG_SETMASK, &sigsaved, NULL);
+ 
+ 	return ret;
+ }
+ 
+ COMPAT_SYSCALL_DEFINE6(pselect6, int, n, compat_ulong_t __user *, inp,
+ 	compat_ulong_t __user *, outp, compat_ulong_t __user *, exp,
+ 	struct compat_timespec __user *, tsp, void __user *, sig)
+ {
+ 	compat_size_t sigsetsize = 0;
+ 	compat_uptr_t up = 0;
+ 
+ 	if (sig) {
+ 		if (!access_ok(VERIFY_READ, sig,
+ 				sizeof(compat_uptr_t)+sizeof(compat_size_t)) ||
+ 		    	__get_user(up, (compat_uptr_t __user *)sig) ||
+ 		    	__get_user(sigsetsize,
+ 				(compat_size_t __user *)(sig+sizeof(up))))
+ 			return -EFAULT;
+ 	}
+ 	return do_compat_pselect(n, inp, outp, exp, tsp, compat_ptr(up),
+ 				 sigsetsize);
+ }
+ 
+ COMPAT_SYSCALL_DEFINE5(ppoll, struct pollfd __user *, ufds,
+ 	unsigned int,  nfds, struct compat_timespec __user *, tsp,
+ 	const compat_sigset_t __user *, sigmask, compat_size_t, sigsetsize)
+ {
+ 	sigset_t ksigmask, sigsaved;
+ 	struct timespec64 ts, end_time, *to = NULL;
+ 	int ret;
+ 
+ 	if (tsp) {
+ 		if (compat_get_timespec64(&ts, tsp))
+ 			return -EFAULT;
+ 
+ 		to = &end_time;
+ 		if (poll_select_set_timeout(to, ts.tv_sec, ts.tv_nsec))
+ 			return -EINVAL;
+ 	}
+ 
+ 	if (sigmask) {
+ 		if (sigsetsize != sizeof(compat_sigset_t))
+ 			return -EINVAL;
+ 		if (get_compat_sigset(&ksigmask, sigmask))
+ 			return -EFAULT;
+ 
+ 		sigdelsetmask(&ksigmask, sigmask(SIGKILL)|sigmask(SIGSTOP));
+ 		sigprocmask(SIG_SETMASK, &ksigmask, &sigsaved);
+ 	}
+ 
+ 	ret = do_sys_poll(ufds, nfds, to);
+ 
+ 	/* We can restart this syscall, usually */
+ 	if (ret == -EINTR) {
+ 		/*
+ 		 * Don't restore the signal mask yet. Let do_signal() deliver
+ 		 * the signal on the way back to userspace, before the signal
+ 		 * mask is restored.
+ 		 */
+ 		if (sigmask) {
+ 			memcpy(&current->saved_sigmask, &sigsaved,
+ 				sizeof(sigsaved));
+ 			set_restore_sigmask();
+ 		}
+ 		ret = -ERESTARTNOHAND;
+ 	} else if (sigmask)
+ 		sigprocmask(SIG_SETMASK, &sigsaved, NULL);
+ 
+ 	ret = compat_poll_select_copy_remaining(&end_time, tsp, 0, ret);
+ 
+ 	return ret;
+ }
+ #endif
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
diff --cc fs/splice.c
index c14c6237c3bc,2365ab073a27..000000000000
--- a/fs/splice.c
+++ b/fs/splice.c
@@@ -593,52 -369,47 +594,61 @@@ ssize_t default_file_splice_read(struc
  				 struct pipe_inode_info *pipe, size_t len,
  				 unsigned int flags)
  {
 -	struct kvec *vec, __vec[PIPE_DEF_BUFFERS];
 -	struct iov_iter to;
 -	struct page **pages;
  	unsigned int nr_pages;
 -	size_t offset, base, copied = 0;
 +	unsigned int nr_freed;
 +	size_t offset;
 +	struct page *pages[PIPE_DEF_BUFFERS];
 +	struct partial_page partial[PIPE_DEF_BUFFERS];
 +	struct iovec *vec, __vec[PIPE_DEF_BUFFERS];
  	ssize_t res;
 +	size_t this_len;
 +	int error;
  	int i;
 +	struct splice_pipe_desc spd = {
 +		.pages = pages,
 +		.partial = partial,
 +		.nr_pages_max = PIPE_DEF_BUFFERS,
 +		.flags = flags,
 +		.ops = &default_pipe_buf_ops,
 +		.spd_release = spd_release_page,
 +	};
  
 -	if (pipe->nrbufs == pipe->buffers)
 -		return -EAGAIN;
 -
 -	/*
 -	 * Try to keep page boundaries matching to source pagecache ones -
 -	 * it probably won't be much help, but...
 -	 */
 -	offset = *ppos & ~PAGE_MASK;
 -
 -	iov_iter_pipe(&to, ITER_PIPE | READ, pipe, len + offset);
 -
 -	res = iov_iter_get_pages_alloc(&to, &pages, len + offset, &base);
 -	if (res <= 0)
 +	if (splice_grow_spd(pipe, &spd))
  		return -ENOMEM;
  
 -	nr_pages = DIV_ROUND_UP(res + base, PAGE_SIZE);
 -
 +	res = -ENOMEM;
  	vec = __vec;
++<<<<<<< HEAD
 +	if (spd.nr_pages_max > PIPE_DEF_BUFFERS) {
 +		vec = kmalloc(spd.nr_pages_max * sizeof(struct iovec), GFP_KERNEL);
 +		if (!vec)
 +			goto shrink_ret;
++=======
+ 	if (nr_pages > PIPE_DEF_BUFFERS) {
+ 		vec = kmalloc_array(nr_pages, sizeof(struct kvec), GFP_KERNEL);
+ 		if (unlikely(!vec)) {
+ 			res = -ENOMEM;
+ 			goto out;
+ 		}
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	}
  
 -	pipe->bufs[to.idx].offset = offset;
 -	pipe->bufs[to.idx].len -= offset;
 +	offset = *ppos & ~PAGE_CACHE_MASK;
 +	nr_pages = (len + offset + PAGE_CACHE_SIZE - 1) >> PAGE_CACHE_SHIFT;
  
 -	for (i = 0; i < nr_pages; i++) {
 -		size_t this_len = min_t(size_t, len, PAGE_SIZE - offset);
 -		vec[i].iov_base = page_address(pages[i]) + offset;
 +	for (i = 0; i < nr_pages && i < spd.nr_pages_max && len; i++) {
 +		struct page *page;
 +
 +		page = alloc_page(GFP_USER);
 +		error = -ENOMEM;
 +		if (!page)
 +			goto err;
 +
 +		this_len = min_t(size_t, len, PAGE_CACHE_SIZE - offset);
 +		vec[i].iov_base = (void __user *) page_address(page);
  		vec[i].iov_len = this_len;
 +		spd.pages[i] = page;
 +		spd.nr_pages++;
  		len -= this_len;
  		offset = 0;
  	}
diff --cc kernel/cpuset.c
index 13ab000c5f37,d8b12e0d39cd..000000000000
--- a/kernel/cpuset.c
+++ b/kernel/cpuset.c
@@@ -690,7 -683,7 +690,11 @@@ static int generate_sched_domains(cpuma
  		goto done;
  	}
  
++<<<<<<< HEAD:kernel/cpuset.c
 +	csa = kmalloc(number_of_cpusets * sizeof(cp), GFP_KERNEL);
++=======
+ 	csa = kmalloc_array(nr_cpusets(), sizeof(cp), GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array()):kernel/cgroup/cpuset.c
  	if (!csa)
  		goto done;
  	csn = 0;
diff --cc kernel/trace/trace.c
index 7b0fc13198d8,8ea855015613..000000000000
--- a/kernel/trace/trace.c
+++ b/kernel/trace/trace.c
@@@ -3789,11 -4949,171 +3790,76 @@@ static const struct file_operations tra
  	.write		= tracing_saved_cmdlines_size_write,
  };
  
 -#ifdef CONFIG_TRACE_EVAL_MAP_FILE
 -static union trace_eval_map_item *
 -update_eval_map(union trace_eval_map_item *ptr)
 +static void
 +trace_insert_enum_map(struct trace_enum_map **start, struct trace_enum_map **stop)
  {
 -	if (!ptr->map.eval_string) {
 -		if (ptr->tail.next) {
 -			ptr = ptr->tail.next;
 -			/* Set ptr to the next real item (skip head) */
 -			ptr++;
 -		} else
 -			return NULL;
 -	}
 -	return ptr;
 -}
++<<<<<<< HEAD
 +	struct trace_enum_map **map;
 +	int len = stop - start;
++=======
++	struct trace_eval_map **stop;
++	struct trace_eval_map **map;
++	union trace_eval_map_item *map_array;
++	union trace_eval_map_item *ptr;
+ 
 -static void *eval_map_next(struct seq_file *m, void *v, loff_t *pos)
 -{
 -	union trace_eval_map_item *ptr = v;
 -
 -	/*
 -	 * Paranoid! If ptr points to end, we don't want to increment past it.
 -	 * This really should never happen.
 -	 */
 -	ptr = update_eval_map(ptr);
 -	if (WARN_ON_ONCE(!ptr))
 -		return NULL;
 -
 -	ptr++;
 -
 -	(*pos)++;
 -
 -	ptr = update_eval_map(ptr);
 -
 -	return ptr;
 -}
 -
 -static void *eval_map_start(struct seq_file *m, loff_t *pos)
 -{
 -	union trace_eval_map_item *v;
 -	loff_t l = 0;
 -
 -	mutex_lock(&trace_eval_mutex);
 -
 -	v = trace_eval_maps;
 -	if (v)
 -		v++;
 -
 -	while (v && l < *pos) {
 -		v = eval_map_next(m, v, &l);
 -	}
 -
 -	return v;
 -}
 -
 -static void eval_map_stop(struct seq_file *m, void *v)
 -{
 -	mutex_unlock(&trace_eval_mutex);
 -}
 -
 -static int eval_map_show(struct seq_file *m, void *v)
 -{
 -	union trace_eval_map_item *ptr = v;
 -
 -	seq_printf(m, "%s %ld (%s)\n",
 -		   ptr->map.eval_string, ptr->map.eval_value,
 -		   ptr->map.system);
 -
 -	return 0;
 -}
 -
 -static const struct seq_operations tracing_eval_map_seq_ops = {
 -	.start		= eval_map_start,
 -	.next		= eval_map_next,
 -	.stop		= eval_map_stop,
 -	.show		= eval_map_show,
 -};
 -
 -static int tracing_eval_map_open(struct inode *inode, struct file *filp)
 -{
 -	if (tracing_disabled)
 -		return -ENODEV;
 -
 -	return seq_open(filp, &tracing_eval_map_seq_ops);
 -}
 -
 -static const struct file_operations tracing_eval_map_fops = {
 -	.open		= tracing_eval_map_open,
 -	.read		= seq_read,
 -	.llseek		= seq_lseek,
 -	.release	= seq_release,
 -};
 -
 -static inline union trace_eval_map_item *
 -trace_eval_jmp_to_tail(union trace_eval_map_item *ptr)
 -{
 -	/* Return tail of array given the head */
 -	return ptr + ptr->head.length + 1;
 -}
 -
 -static void
 -trace_insert_eval_map_file(struct module *mod, struct trace_eval_map **start,
 -			   int len)
 -{
 -	struct trace_eval_map **stop;
 -	struct trace_eval_map **map;
 -	union trace_eval_map_item *map_array;
 -	union trace_eval_map_item *ptr;
 -
 -	stop = start + len;
++	stop = start + len;
+ 
+ 	/*
+ 	 * The trace_eval_maps contains the map plus a head and tail item,
+ 	 * where the head holds the module and length of array, and the
+ 	 * tail holds a pointer to the next list.
+ 	 */
+ 	map_array = kmalloc_array(len + 2, sizeof(*map_array), GFP_KERNEL);
+ 	if (!map_array) {
+ 		pr_warn("Unable to allocate trace eval mapping\n");
+ 		return;
+ 	}
+ 
+ 	mutex_lock(&trace_eval_mutex);
+ 
+ 	if (!trace_eval_maps)
+ 		trace_eval_maps = map_array;
+ 	else {
+ 		ptr = trace_eval_maps;
+ 		for (;;) {
+ 			ptr = trace_eval_jmp_to_tail(ptr);
+ 			if (!ptr->tail.next)
+ 				break;
+ 			ptr = ptr->tail.next;
+ 
+ 		}
+ 		ptr->tail.next = map_array;
+ 	}
+ 	map_array->head.mod = mod;
+ 	map_array->head.length = len;
+ 	map_array++;
+ 
+ 	for (map = start; (unsigned long)map < (unsigned long)stop; map++) {
+ 		map_array->map = **map;
+ 		map_array++;
+ 	}
+ 	memset(map_array, 0, sizeof(*map_array));
+ 
+ 	mutex_unlock(&trace_eval_mutex);
+ }
+ 
+ static void trace_create_eval_file(struct dentry *d_tracer)
+ {
+ 	trace_create_file("eval_map", 0444, d_tracer,
+ 			  NULL, &tracing_eval_map_fops);
+ }
+ 
+ #else /* CONFIG_TRACE_EVAL_MAP_FILE */
+ static inline void trace_create_eval_file(struct dentry *d_tracer) { }
+ static inline void trace_insert_eval_map_file(struct module *mod,
+ 			      struct trace_eval_map **start, int len) { }
+ #endif /* !CONFIG_TRACE_EVAL_MAP_FILE */
+ 
+ static void trace_insert_eval_map(struct module *mod,
+ 				  struct trace_eval_map **start, int len)
+ {
+ 	struct trace_eval_map **map;
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  
  	if (len <= 0)
  		return;
diff --cc kernel/trace/trace_events_filter.c
index b01769bfd0f8,e1c818dbc0d7..000000000000
--- a/kernel/trace/trace_events_filter.c
+++ b/kernel/trace/trace_events_filter.c
@@@ -33,111 -33,582 +33,127 @@@
  	"# Only events with the given fields will be affected.\n"	\
  	"# If no events are modified, an error message will be displayed here"
  
 -/* Due to token parsing '<=' must be before '<' and '>=' must be before '>' */
 -#define OPS					\
 -	C( OP_GLOB,	"~"  ),			\
 -	C( OP_NE,	"!=" ),			\
 -	C( OP_EQ,	"==" ),			\
 -	C( OP_LE,	"<=" ),			\
 -	C( OP_LT,	"<"  ),			\
 -	C( OP_GE,	">=" ),			\
 -	C( OP_GT,	">"  ),			\
 -	C( OP_BAND,	"&"  ),			\
 -	C( OP_MAX,	NULL )
 -
 -#undef C
 -#define C(a, b)	a
 -
 -enum filter_op_ids { OPS };
 -
 -#undef C
 -#define C(a, b)	b
 -
 -static const char * ops[] = { OPS };
 -
 -/*
 - * pred functions are OP_LE, OP_LT, OP_GE, OP_GT, and OP_BAND
 - * pred_funcs_##type below must match the order of them above.
 - */
 -#define PRED_FUNC_START			OP_LE
 -#define PRED_FUNC_MAX			(OP_BAND - PRED_FUNC_START)
 -
 -#define ERRORS								\
 -	C(NONE,			"No error"),				\
 -	C(INVALID_OP,		"Invalid operator"),			\
 -	C(TOO_MANY_OPEN,	"Too many '('"),			\
 -	C(TOO_MANY_CLOSE,	"Too few '('"),				\
 -	C(MISSING_QUOTE,	"Missing matching quote"),		\
 -	C(OPERAND_TOO_LONG,	"Operand too long"),			\
 -	C(EXPECT_STRING,	"Expecting string field"),		\
 -	C(EXPECT_DIGIT,		"Expecting numeric field"),		\
 -	C(ILLEGAL_FIELD_OP,	"Illegal operation for field type"),	\
 -	C(FIELD_NOT_FOUND,	"Field not found"),			\
 -	C(ILLEGAL_INTVAL,	"Illegal integer value"),		\
 -	C(BAD_SUBSYS_FILTER,	"Couldn't find or set field in one of a subsystem's events"), \
 -	C(TOO_MANY_PREDS,	"Too many terms in predicate expression"), \
 -	C(INVALID_FILTER,	"Meaningless filter expression"),	\
 -	C(IP_FIELD_ONLY,	"Only 'ip' field is supported for function trace"), \
 -	C(INVALID_VALUE,	"Invalid value (did you forget quotes)?"),
 -
 -#undef C
 -#define C(a, b)		FILT_ERR_##a
 -
 -enum { ERRORS };
 -
 -#undef C
 -#define C(a, b)		b
 -
 -static char *err_text[] = { ERRORS };
 -
 -/* Called after a '!' character but "!=" and "!~" are not "not"s */
 -static bool is_not(const char *str)
 -{
 -	switch (str[1]) {
 -	case '=':
 -	case '~':
 -		return false;
 -	}
 -	return true;
 -}
 -
 -/**
 - * prog_entry - a singe entry in the filter program
 - * @target:	     Index to jump to on a branch (actually one minus the index)
 - * @when_to_branch:  The value of the result of the predicate to do a branch
 - * @pred:	     The predicate to execute.
 - */
 -struct prog_entry {
 -	int			target;
 -	int			when_to_branch;
 -	struct filter_pred	*pred;
 -};
 -
 -/**
 - * update_preds- assign a program entry a label target
 - * @prog: The program array
 - * @N: The index of the current entry in @prog
 - * @when_to_branch: What to assign a program entry for its branch condition
 - *
 - * The program entry at @N has a target that points to the index of a program
 - * entry that can have its target and when_to_branch fields updated.
 - * Update the current program entry denoted by index @N target field to be
 - * that of the updated entry. This will denote the entry to update if
 - * we are processing an "||" after an "&&"
 - */
 -static void update_preds(struct prog_entry *prog, int N, int invert)
 +enum filter_op_ids
  {
 -	int t, s;
 -
 -	t = prog[N].target;
 -	s = prog[t].target;
 -	prog[t].when_to_branch = invert;
 -	prog[t].target = N;
 -	prog[N].target = s;
 -}
 -
 -struct filter_parse_error {
 -	int lasterr;
 -	int lasterr_pos;
 +	OP_OR,
 +	OP_AND,
 +	OP_GLOB,
 +	OP_NE,
 +	OP_EQ,
 +	OP_LT,
 +	OP_LE,
 +	OP_GT,
 +	OP_GE,
 +	OP_NONE,
 +	OP_OPEN_PAREN,
  };
  
 -static void parse_error(struct filter_parse_error *pe, int err, int pos)
 -{
 -	pe->lasterr = err;
 -	pe->lasterr_pos = pos;
 -}
 +struct filter_op {
 +	int id;
 +	char *string;
 +	int precedence;
 +};
  
 -typedef int (*parse_pred_fn)(const char *str, void *data, int pos,
 -			     struct filter_parse_error *pe,
 -			     struct filter_pred **pred);
 +static struct filter_op filter_ops[] = {
 +	{ OP_OR,	"||",		1 },
 +	{ OP_AND,	"&&",		2 },
 +	{ OP_GLOB,	"~",		4 },
 +	{ OP_NE,	"!=",		4 },
 +	{ OP_EQ,	"==",		4 },
 +	{ OP_LT,	"<",		5 },
 +	{ OP_LE,	"<=",		5 },
 +	{ OP_GT,	">",		5 },
 +	{ OP_GE,	">=",		5 },
 +	{ OP_NONE,	"OP_NONE",	0 },
 +	{ OP_OPEN_PAREN, "(",		0 },
 +};
  
  enum {
 -	INVERT		= 1,
 -	PROCESS_AND	= 2,
 -	PROCESS_OR	= 4,
 +	FILT_ERR_NONE,
 +	FILT_ERR_INVALID_OP,
 +	FILT_ERR_UNBALANCED_PAREN,
 +	FILT_ERR_TOO_MANY_OPERANDS,
 +	FILT_ERR_OPERAND_TOO_LONG,
 +	FILT_ERR_FIELD_NOT_FOUND,
 +	FILT_ERR_ILLEGAL_FIELD_OP,
 +	FILT_ERR_ILLEGAL_INTVAL,
 +	FILT_ERR_BAD_SUBSYS_FILTER,
 +	FILT_ERR_TOO_MANY_PREDS,
 +	FILT_ERR_MISSING_FIELD,
 +	FILT_ERR_INVALID_FILTER,
 +	FILT_ERR_IP_FIELD_ONLY,
  };
  
 -/*
 - * Without going into a formal proof, this explains the method that is used in
 - * parsing the logical expressions.
 - *
 - * For example, if we have: "a && !(!b || (c && g)) || d || e && !f"
 - * The first pass will convert it into the following program:
 - *
 - * n1: r=a;       l1: if (!r) goto l4;
 - * n2: r=b;       l2: if (!r) goto l4;
 - * n3: r=c; r=!r; l3: if (r) goto l4;
 - * n4: r=g; r=!r; l4: if (r) goto l5;
 - * n5: r=d;       l5: if (r) goto T
 - * n6: r=e;       l6: if (!r) goto l7;
 - * n7: r=f; r=!r; l7: if (!r) goto F
 - * T: return TRUE
 - * F: return FALSE
 - *
 - * To do this, we use a data structure to represent each of the above
 - * predicate and conditions that has:
 - *
 - *  predicate, when_to_branch, invert, target
 - *
 - * The "predicate" will hold the function to determine the result "r".
 - * The "when_to_branch" denotes what "r" should be if a branch is to be taken
 - * "&&" would contain "!r" or (0) and "||" would contain "r" or (1).
 - * The "invert" holds whether the value should be reversed before testing.
 - * The "target" contains the label "l#" to jump to.
 - *
 - * A stack is created to hold values when parentheses are used.
 - *
 - * To simplify the logic, the labels will start at 0 and not 1.
 - *
 - * The possible invert values are 1 and 0. The number of "!"s that are in scope
 - * before the predicate determines the invert value, if the number is odd then
 - * the invert value is 1 and 0 otherwise. This means the invert value only
 - * needs to be toggled when a new "!" is introduced compared to what is stored
 - * on the stack, where parentheses were used.
 - *
 - * The top of the stack and "invert" are initialized to zero.
 - *
 - * ** FIRST PASS **
 - *
 - * #1 A loop through all the tokens is done:
 - *
 - * #2 If the token is an "(", the stack is push, and the current stack value
 - *    gets the current invert value, and the loop continues to the next token.
 - *    The top of the stack saves the "invert" value to keep track of what
 - *    the current inversion is. As "!(a && !b || c)" would require all
 - *    predicates being affected separately by the "!" before the parentheses.
 - *    And that would end up being equivalent to "(!a || b) && !c"
 - *
 - * #3 If the token is an "!", the current "invert" value gets inverted, and
 - *    the loop continues. Note, if the next token is a predicate, then
 - *    this "invert" value is only valid for the current program entry,
 - *    and does not affect other predicates later on.
 - *
 - * The only other acceptable token is the predicate string.
 - *
 - * #4 A new entry into the program is added saving: the predicate and the
 - *    current value of "invert". The target is currently assigned to the
 - *    previous program index (this will not be its final value).
 - *
 - * #5 We now enter another loop and look at the next token. The only valid
 - *    tokens are ")", "&&", "||" or end of the input string "\0".
 - *
 - * #6 The invert variable is reset to the current value saved on the top of
 - *    the stack.
 - *
 - * #7 The top of the stack holds not only the current invert value, but also
 - *    if a "&&" or "||" needs to be processed. Note, the "&&" takes higher
 - *    precedence than "||". That is "a && b || c && d" is equivalent to
 - *    "(a && b) || (c && d)". Thus the first thing to do is to see if "&&" needs
 - *    to be processed. This is the case if an "&&" was the last token. If it was
 - *    then we call update_preds(). This takes the program, the current index in
 - *    the program, and the current value of "invert".  More will be described
 - *    below about this function.
 - *
 - * #8 If the next token is "&&" then we set a flag in the top of the stack
 - *    that denotes that "&&" needs to be processed, break out of this loop
 - *    and continue with the outer loop.
 - *
 - * #9 Otherwise, if a "||" needs to be processed then update_preds() is called.
 - *    This is called with the program, the current index in the program, but
 - *    this time with an inverted value of "invert" (that is !invert). This is
 - *    because the value taken will become the "when_to_branch" value of the
 - *    program.
 - *    Note, this is called when the next token is not an "&&". As stated before,
 - *    "&&" takes higher precedence, and "||" should not be processed yet if the
 - *    next logical operation is "&&".
 - *
 - * #10 If the next token is "||" then we set a flag in the top of the stack
 - *     that denotes that "||" needs to be processed, break out of this loop
 - *     and continue with the outer loop.
 - *
 - * #11 If this is the end of the input string "\0" then we break out of both
 - *     loops.
 - *
 - * #12 Otherwise, the next token is ")", where we pop the stack and continue
 - *     this inner loop.
 - *
 - * Now to discuss the update_pred() function, as that is key to the setting up
 - * of the program. Remember the "target" of the program is initialized to the
 - * previous index and not the "l" label. The target holds the index into the
 - * program that gets affected by the operand. Thus if we have something like
 - *  "a || b && c", when we process "a" the target will be "-1" (undefined).
 - * When we process "b", its target is "0", which is the index of "a", as that's
 - * the predicate that is affected by "||". But because the next token after "b"
 - * is "&&" we don't call update_preds(). Instead continue to "c". As the
 - * next token after "c" is not "&&" but the end of input, we first process the
 - * "&&" by calling update_preds() for the "&&" then we process the "||" by
 - * callin updates_preds() with the values for processing "||".
 - *
 - * What does that mean? What update_preds() does is to first save the "target"
 - * of the program entry indexed by the current program entry's "target"
 - * (remember the "target" is initialized to previous program entry), and then
 - * sets that "target" to the current index which represents the label "l#".
 - * That entry's "when_to_branch" is set to the value passed in (the "invert"
 - * or "!invert"). Then it sets the current program entry's target to the saved
 - * "target" value (the old value of the program that had its "target" updated
 - * to the label).
 - *
 - * Looking back at "a || b && c", we have the following steps:
 - *  "a"  - prog[0] = { "a", X, -1 } // pred, when_to_branch, target
 - *  "||" - flag that we need to process "||"; continue outer loop
 - *  "b"  - prog[1] = { "b", X, 0 }
 - *  "&&" - flag that we need to process "&&"; continue outer loop
 - * (Notice we did not process "||")
 - *  "c"  - prog[2] = { "c", X, 1 }
 - *  update_preds(prog, 2, 0); // invert = 0 as we are processing "&&"
 - *    t = prog[2].target; // t = 1
 - *    s = prog[t].target; // s = 0
 - *    prog[t].target = 2; // Set target to "l2"
 - *    prog[t].when_to_branch = 0;
 - *    prog[2].target = s;
 - * update_preds(prog, 2, 1); // invert = 1 as we are now processing "||"
 - *    t = prog[2].target; // t = 0
 - *    s = prog[t].target; // s = -1
 - *    prog[t].target = 2; // Set target to "l2"
 - *    prog[t].when_to_branch = 1;
 - *    prog[2].target = s;
 - *
 - * #13 Which brings us to the final step of the first pass, which is to set
 - *     the last program entry's when_to_branch and target, which will be
 - *     when_to_branch = 0; target = N; ( the label after the program entry after
 - *     the last program entry processed above).
 - *
 - * If we denote "TRUE" to be the entry after the last program entry processed,
 - * and "FALSE" the program entry after that, we are now done with the first
 - * pass.
 - *
 - * Making the above "a || b && c" have a progam of:
 - *  prog[0] = { "a", 1, 2 }
 - *  prog[1] = { "b", 0, 2 }
 - *  prog[2] = { "c", 0, 3 }
 - *
 - * Which translates into:
 - * n0: r = a; l0: if (r) goto l2;
 - * n1: r = b; l1: if (!r) goto l2;
 - * n2: r = c; l2: if (!r) goto l3;  // Which is the same as "goto F;"
 - * T: return TRUE; l3:
 - * F: return FALSE
 - *
 - * Although, after the first pass, the program is correct, it is
 - * inefficient. The simple sample of "a || b && c" could be easily been
 - * converted into:
 - * n0: r = a; if (r) goto T
 - * n1: r = b; if (!r) goto F
 - * n2: r = c; if (!r) goto F
 - * T: return TRUE;
 - * F: return FALSE;
 - *
 - * The First Pass is over the input string. The next too passes are over
 - * the program itself.
 - *
 - * ** SECOND PASS **
 - *
 - * Which brings us to the second pass. If a jump to a label has the
 - * same condition as that label, it can instead jump to its target.
 - * The original example of "a && !(!b || (c && g)) || d || e && !f"
 - * where the first pass gives us:
 - *
 - * n1: r=a;       l1: if (!r) goto l4;
 - * n2: r=b;       l2: if (!r) goto l4;
 - * n3: r=c; r=!r; l3: if (r) goto l4;
 - * n4: r=g; r=!r; l4: if (r) goto l5;
 - * n5: r=d;       l5: if (r) goto T
 - * n6: r=e;       l6: if (!r) goto l7;
 - * n7: r=f; r=!r; l7: if (!r) goto F:
 - * T: return TRUE;
 - * F: return FALSE
 - *
 - * We can see that "l3: if (r) goto l4;" and at l4, we have "if (r) goto l5;".
 - * And "l5: if (r) goto T", we could optimize this by converting l3 and l4
 - * to go directly to T. To accomplish this, we start from the last
 - * entry in the program and work our way back. If the target of the entry
 - * has the same "when_to_branch" then we could use that entry's target.
 - * Doing this, the above would end up as:
 - *
 - * n1: r=a;       l1: if (!r) goto l4;
 - * n2: r=b;       l2: if (!r) goto l4;
 - * n3: r=c; r=!r; l3: if (r) goto T;
 - * n4: r=g; r=!r; l4: if (r) goto T;
 - * n5: r=d;       l5: if (r) goto T;
 - * n6: r=e;       l6: if (!r) goto F;
 - * n7: r=f; r=!r; l7: if (!r) goto F;
 - * T: return TRUE
 - * F: return FALSE
 - *
 - * In that same pass, if the "when_to_branch" doesn't match, we can simply
 - * go to the program entry after the label. That is, "l2: if (!r) goto l4;"
 - * where "l4: if (r) goto T;", then we can convert l2 to be:
 - * "l2: if (!r) goto n5;".
 - *
 - * This will have the second pass give us:
 - * n1: r=a;       l1: if (!r) goto n5;
 - * n2: r=b;       l2: if (!r) goto n5;
 - * n3: r=c; r=!r; l3: if (r) goto T;
 - * n4: r=g; r=!r; l4: if (r) goto T;
 - * n5: r=d;       l5: if (r) goto T
 - * n6: r=e;       l6: if (!r) goto F;
 - * n7: r=f; r=!r; l7: if (!r) goto F
 - * T: return TRUE
 - * F: return FALSE
 - *
 - * Notice, all the "l#" labels are no longer used, and they can now
 - * be discarded.
 - *
 - * ** THIRD PASS **
 - *
 - * For the third pass we deal with the inverts. As they simply just
 - * make the "when_to_branch" get inverted, a simple loop over the
 - * program to that does: "when_to_branch ^= invert;" will do the
 - * job, leaving us with:
 - * n1: r=a; if (!r) goto n5;
 - * n2: r=b; if (!r) goto n5;
 - * n3: r=c: if (!r) goto T;
 - * n4: r=g; if (!r) goto T;
 - * n5: r=d; if (r) goto T
 - * n6: r=e; if (!r) goto F;
 - * n7: r=f; if (r) goto F
 - * T: return TRUE
 - * F: return FALSE
 - *
 - * As "r = a; if (!r) goto n5;" is obviously the same as
 - * "if (!a) goto n5;" without doing anything we can interperate the
 - * program as:
 - * n1: if (!a) goto n5;
 - * n2: if (!b) goto n5;
 - * n3: if (!c) goto T;
 - * n4: if (!g) goto T;
 - * n5: if (d) goto T
 - * n6: if (!e) goto F;
 - * n7: if (f) goto F
 - * T: return TRUE
 - * F: return FALSE
 - *
 - * Since the inverts are discarded at the end, there's no reason to store
 - * them in the program array (and waste memory). A separate array to hold
 - * the inverts is used and freed at the end.
 - */
 -static struct prog_entry *
 -predicate_parse(const char *str, int nr_parens, int nr_preds,
 -		parse_pred_fn parse_pred, void *data,
 -		struct filter_parse_error *pe)
 -{
 -	struct prog_entry *prog_stack;
 -	struct prog_entry *prog;
 -	const char *ptr = str;
 -	char *inverts = NULL;
 -	int *op_stack;
 -	int *top;
 -	int invert = 0;
 -	int ret = -ENOMEM;
 -	int len;
 -	int N = 0;
 -	int i;
 +static char *err_text[] = {
 +	"No error",
 +	"Invalid operator",
 +	"Unbalanced parens",
 +	"Too many operands",
 +	"Operand too long",
 +	"Field not found",
 +	"Illegal operation for field type",
 +	"Illegal integer value",
 +	"Couldn't find or set field in one of a subsystem's events",
 +	"Too many terms in predicate expression",
 +	"Missing field name and/or value",
 +	"Meaningless filter expression",
 +	"Only 'ip' field is supported for function trace",
 +};
  
 -	nr_preds += 2; /* For TRUE and FALSE */
 +struct opstack_op {
 +	int op;
 +	struct list_head list;
 +};
  
++<<<<<<< HEAD
 +struct postfix_elt {
 +	int op;
 +	char *operand;
 +	struct list_head list;
 +};
++=======
+ 	op_stack = kmalloc_array(nr_parens, sizeof(*op_stack), GFP_KERNEL);
+ 	if (!op_stack)
+ 		return ERR_PTR(-ENOMEM);
+ 	prog_stack = kmalloc_array(nr_preds, sizeof(*prog_stack), GFP_KERNEL);
+ 	if (!prog_stack) {
+ 		parse_error(pe, -ENOMEM, 0);
+ 		goto out_free;
+ 	}
+ 	inverts = kmalloc_array(nr_preds, sizeof(*inverts), GFP_KERNEL);
+ 	if (!inverts) {
+ 		parse_error(pe, -ENOMEM, 0);
+ 		goto out_free;
+ 	}
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  
 -	top = op_stack;
 -	prog = prog_stack;
 -	*top = 0;
 -
 -	/* First pass */
 -	while (*ptr) {						/* #1 */
 -		const char *next = ptr++;
 -
 -		if (isspace(*next))
 -			continue;
 -
 -		switch (*next) {
 -		case '(':					/* #2 */
 -			if (top - op_stack > nr_parens)
 -				return ERR_PTR(-EINVAL);
 -			*(++top) = invert;
 -			continue;
 -		case '!':					/* #3 */
 -			if (!is_not(next))
 -				break;
 -			invert = !invert;
 -			continue;
 -		}
 -
 -		if (N >= nr_preds) {
 -			parse_error(pe, FILT_ERR_TOO_MANY_PREDS, next - str);
 -			goto out_free;
 -		}
 -
 -		inverts[N] = invert;				/* #4 */
 -		prog[N].target = N-1;
 -
 -		len = parse_pred(next, data, ptr - str, pe, &prog[N].pred);
 -		if (len < 0) {
 -			ret = len;
 -			goto out_free;
 -		}
 -		ptr = next + len;
 -
 -		N++;
 -
 -		ret = -1;
 -		while (1) {					/* #5 */
 -			next = ptr++;
 -			if (isspace(*next))
 -				continue;
 -
 -			switch (*next) {
 -			case ')':
 -			case '\0':
 -				break;
 -			case '&':
 -			case '|':
 -				if (next[1] == next[0]) {
 -					ptr++;
 -					break;
 -				}
 -			default:
 -				parse_error(pe, FILT_ERR_TOO_MANY_PREDS,
 -					    next - str);
 -				goto out_free;
 -			}
 -
 -			invert = *top & INVERT;
 -
 -			if (*top & PROCESS_AND) {		/* #7 */
 -				update_preds(prog, N - 1, invert);
 -				*top &= ~PROCESS_AND;
 -			}
 -			if (*next == '&') {			/* #8 */
 -				*top |= PROCESS_AND;
 -				break;
 -			}
 -			if (*top & PROCESS_OR) {		/* #9 */
 -				update_preds(prog, N - 1, !invert);
 -				*top &= ~PROCESS_OR;
 -			}
 -			if (*next == '|') {			/* #10 */
 -				*top |= PROCESS_OR;
 -				break;
 -			}
 -			if (!*next)				/* #11 */
 -				goto out;
 -
 -			if (top == op_stack) {
 -				ret = -1;
 -				/* Too few '(' */
 -				parse_error(pe, FILT_ERR_TOO_MANY_CLOSE, ptr - str);
 -				goto out_free;
 -			}
 -			top--;					/* #12 */
 -		}
 -	}
 - out:
 -	if (top != op_stack) {
 -		/* Too many '(' */
 -		parse_error(pe, FILT_ERR_TOO_MANY_OPEN, ptr - str);
 -		goto out_free;
 -	}
 -
 -	prog[N].pred = NULL;					/* #13 */
 -	prog[N].target = 1;		/* TRUE */
 -	prog[N+1].pred = NULL;
 -	prog[N+1].target = 0;		/* FALSE */
 -	prog[N-1].target = N;
 -	prog[N-1].when_to_branch = false;
 -
 -	/* Second Pass */
 -	for (i = N-1 ; i--; ) {
 -		int target = prog[i].target;
 -		if (prog[i].when_to_branch == prog[target].when_to_branch)
 -			prog[i].target = prog[target].target;
 -	}
 +struct filter_parse_state {
 +	struct filter_op *ops;
 +	struct list_head opstack;
 +	struct list_head postfix;
 +	int lasterr;
 +	int lasterr_pos;
  
 -	/* Third Pass */
 -	for (i = 0; i < N; i++) {
 -		invert = inverts[i] ^ prog[i].when_to_branch;
 -		prog[i].when_to_branch = invert;
 -		/* Make sure the program always moves forward */
 -		if (WARN_ON(prog[i].target <= i)) {
 -			ret = -EINVAL;
 -			goto out_free;
 -		}
 -	}
 +	struct {
 +		char *string;
 +		unsigned int cnt;
 +		unsigned int tail;
 +	} infix;
 +
 +	struct {
 +		char string[MAX_FILTER_STR_VAL];
 +		int pos;
 +		unsigned int tail;
 +	} operand;
 +};
  
 -	return prog;
 -out_free:
 -	kfree(op_stack);
 -	kfree(prog_stack);
 -	kfree(inverts);
 -	return ERR_PTR(ret);
 -}
 +struct pred_stack {
 +	struct filter_pred	**preds;
 +	int			index;
 +};
  
  #define DEFINE_COMPARISON_PRED(type)					\
 -static int filter_pred_LT_##type(struct filter_pred *pred, void *event)	\
 -{									\
 -	type *addr = (type *)(event + pred->offset);			\
 -	type val = (type)pred->val;					\
 -	return *addr < val;						\
 -}									\
 -static int filter_pred_LE_##type(struct filter_pred *pred, void *event)	\
 -{									\
 -	type *addr = (type *)(event + pred->offset);			\
 -	type val = (type)pred->val;					\
 -	return *addr <= val;						\
 -}									\
 -static int filter_pred_GT_##type(struct filter_pred *pred, void *event)	\
 -{									\
 -	type *addr = (type *)(event + pred->offset);			\
 -	type val = (type)pred->val;					\
 -	return *addr > val;					\
 -}									\
 -static int filter_pred_GE_##type(struct filter_pred *pred, void *event)	\
 -{									\
 -	type *addr = (type *)(event + pred->offset);			\
 -	type val = (type)pred->val;					\
 -	return *addr >= val;						\
 -}									\
 -static int filter_pred_BAND_##type(struct filter_pred *pred, void *event) \
 +static int filter_pred_##type(struct filter_pred *pred, void *event)	\
  {									\
  	type *addr = (type *)(event + pred->offset);			\
  	type val = (type)pred->val;					\
diff --cc kernel/user_namespace.c
index 94c9b00b2cae,c3d7583fcd21..000000000000
--- a/kernel/user_namespace.c
+++ b/kernel/user_namespace.c
@@@ -649,6 -751,102 +649,105 @@@ static bool mappings_overlap(struct uid
  	return false;
  }
  
++<<<<<<< HEAD
++=======
+ /**
+  * insert_extent - Safely insert a new idmap extent into struct uid_gid_map.
+  * Takes care to allocate a 4K block of memory if the number of mappings exceeds
+  * UID_GID_MAP_MAX_BASE_EXTENTS.
+  */
+ static int insert_extent(struct uid_gid_map *map, struct uid_gid_extent *extent)
+ {
+ 	struct uid_gid_extent *dest;
+ 
+ 	if (map->nr_extents == UID_GID_MAP_MAX_BASE_EXTENTS) {
+ 		struct uid_gid_extent *forward;
+ 
+ 		/* Allocate memory for 340 mappings. */
+ 		forward = kmalloc_array(UID_GID_MAP_MAX_EXTENTS,
+ 					sizeof(struct uid_gid_extent),
+ 					GFP_KERNEL);
+ 		if (!forward)
+ 			return -ENOMEM;
+ 
+ 		/* Copy over memory. Only set up memory for the forward pointer.
+ 		 * Defer the memory setup for the reverse pointer.
+ 		 */
+ 		memcpy(forward, map->extent,
+ 		       map->nr_extents * sizeof(map->extent[0]));
+ 
+ 		map->forward = forward;
+ 		map->reverse = NULL;
+ 	}
+ 
+ 	if (map->nr_extents < UID_GID_MAP_MAX_BASE_EXTENTS)
+ 		dest = &map->extent[map->nr_extents];
+ 	else
+ 		dest = &map->forward[map->nr_extents];
+ 
+ 	*dest = *extent;
+ 	map->nr_extents++;
+ 	return 0;
+ }
+ 
+ /* cmp function to sort() forward mappings */
+ static int cmp_extents_forward(const void *a, const void *b)
+ {
+ 	const struct uid_gid_extent *e1 = a;
+ 	const struct uid_gid_extent *e2 = b;
+ 
+ 	if (e1->first < e2->first)
+ 		return -1;
+ 
+ 	if (e1->first > e2->first)
+ 		return 1;
+ 
+ 	return 0;
+ }
+ 
+ /* cmp function to sort() reverse mappings */
+ static int cmp_extents_reverse(const void *a, const void *b)
+ {
+ 	const struct uid_gid_extent *e1 = a;
+ 	const struct uid_gid_extent *e2 = b;
+ 
+ 	if (e1->lower_first < e2->lower_first)
+ 		return -1;
+ 
+ 	if (e1->lower_first > e2->lower_first)
+ 		return 1;
+ 
+ 	return 0;
+ }
+ 
+ /**
+  * sort_idmaps - Sorts an array of idmap entries.
+  * Can only be called if number of mappings exceeds UID_GID_MAP_MAX_BASE_EXTENTS.
+  */
+ static int sort_idmaps(struct uid_gid_map *map)
+ {
+ 	if (map->nr_extents <= UID_GID_MAP_MAX_BASE_EXTENTS)
+ 		return 0;
+ 
+ 	/* Sort forward array. */
+ 	sort(map->forward, map->nr_extents, sizeof(struct uid_gid_extent),
+ 	     cmp_extents_forward, NULL);
+ 
+ 	/* Only copy the memory from forward we actually need. */
+ 	map->reverse = kmemdup(map->forward,
+ 			       map->nr_extents * sizeof(struct uid_gid_extent),
+ 			       GFP_KERNEL);
+ 	if (!map->reverse)
+ 		return -ENOMEM;
+ 
+ 	/* Sort reverse array. */
+ 	sort(map->reverse, map->nr_extents, sizeof(struct uid_gid_extent),
+ 	     cmp_extents_reverse, NULL);
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  static ssize_t map_write(struct file *file, const char __user *buf,
  			 size_t count, loff_t *ppos,
  			 int cap_setid,
diff --cc lib/interval_tree_test.c
index 245900b98c8e,75509a1511a3..000000000000
--- a/lib/interval_tree_test.c
+++ b/lib/interval_tree_test.c
@@@ -50,6 -64,17 +50,20 @@@ static int interval_tree_test_init(void
  	unsigned long results;
  	cycles_t time1, time2, time;
  
++<<<<<<< HEAD
++=======
+ 	nodes = kmalloc_array(nnodes, sizeof(struct interval_tree_node),
+ 			      GFP_KERNEL);
+ 	if (!nodes)
+ 		return -ENOMEM;
+ 
+ 	queries = kmalloc_array(nsearches, sizeof(int), GFP_KERNEL);
+ 	if (!queries) {
+ 		kfree(nodes);
+ 		return -ENOMEM;
+ 	}
+ 
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	printk(KERN_ALERT "interval tree insert/remove");
  
  	prandom_seed_state(&rnd, 3141592653589793238ULL);
diff --cc lib/rbtree_test.c
index 122f02f9941b,b7055b2a07d3..000000000000
--- a/lib/rbtree_test.c
+++ b/lib/rbtree_test.c
@@@ -153,6 -245,11 +153,14 @@@ static int __init rbtree_test_init(void
  {
  	int i, j;
  	cycles_t time1, time2, time;
++<<<<<<< HEAD
++=======
+ 	struct rb_node *node;
+ 
+ 	nodes = kmalloc_array(nnodes, sizeof(*nodes), GFP_KERNEL);
+ 	if (!nodes)
+ 		return -ENOMEM;
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  
  	printk(KERN_ALERT "rbtree testing");
  
diff --cc lib/reed_solomon/reed_solomon.c
index 06d04cfa9339,d8bb1a1eba72..000000000000
--- a/lib/reed_solomon/reed_solomon.c
+++ b/lib/reed_solomon/reed_solomon.c
@@@ -85,17 -88,17 +85,29 @@@ static struct rs_control *rs_init(int s
  	rs->gffunc = gffunc;
  
  	/* Allocate the arrays */
++<<<<<<< HEAD
 +	rs->alpha_to = kmalloc(sizeof(uint16_t) * (rs->nn + 1), GFP_KERNEL);
++=======
+ 	rs->alpha_to = kmalloc_array(rs->nn + 1, sizeof(uint16_t), gfp);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (rs->alpha_to == NULL)
 -		goto err;
 +		goto errrs;
  
++<<<<<<< HEAD
 +	rs->index_of = kmalloc(sizeof(uint16_t) * (rs->nn + 1), GFP_KERNEL);
++=======
+ 	rs->index_of = kmalloc_array(rs->nn + 1, sizeof(uint16_t), gfp);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (rs->index_of == NULL)
 -		goto err;
 +		goto erralp;
  
++<<<<<<< HEAD
 +	rs->genpoly = kmalloc(sizeof(uint16_t) * (rs->nroots + 1), GFP_KERNEL);
++=======
+ 	rs->genpoly = kmalloc_array(rs->nroots + 1, sizeof(uint16_t), gfp);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if(rs->genpoly == NULL)
 -		goto err;
 +		goto erridx;
  
  	/* Generate Galois field lookup tables */
  	rs->index_of[0] = rs->nn;	/* log(zero) = -inf */
diff --cc mm/slub.c
index f19ffe7aff38,faf5dcb7b44f..000000000000
--- a/mm/slub.c
+++ b/mm/slub.c
@@@ -4259,8 -4412,10 +4259,15 @@@ static long validate_slab_cache(struct 
  {
  	int node;
  	unsigned long count = 0;
++<<<<<<< HEAD
 +	unsigned long *map = kmalloc(BITS_TO_LONGS(oo_objects(s->max)) *
 +				sizeof(unsigned long), GFP_KERNEL);
++=======
+ 	unsigned long *map = kmalloc_array(BITS_TO_LONGS(oo_objects(s->max)),
+ 					   sizeof(unsigned long),
+ 					   GFP_KERNEL);
+ 	struct kmem_cache_node *n;
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  
  	if (!map)
  		return -ENOMEM;
@@@ -4422,11 -4574,13 +4429,18 @@@ static int list_locations(struct kmem_c
  	unsigned long i;
  	struct loc_track t = { 0, 0, NULL };
  	int node;
++<<<<<<< HEAD
 +	unsigned long *map = kmalloc(BITS_TO_LONGS(oo_objects(s->max)) *
 +				     sizeof(unsigned long), GFP_KERNEL);
++=======
+ 	unsigned long *map = kmalloc_array(BITS_TO_LONGS(oo_objects(s->max)),
+ 					   sizeof(unsigned long),
+ 					   GFP_KERNEL);
+ 	struct kmem_cache_node *n;
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  
  	if (!map || !alloc_loc_track(&t, PAGE_SIZE / sizeof(struct location),
 -				     GFP_KERNEL)) {
 +				     GFP_TEMPORARY)) {
  		kfree(map);
  		return sprintf(buf, "Out of memory\n");
  	}
diff --cc net/9p/trans_virtio.c
index 5d13d8c27e0e,05006cbb3361..000000000000
--- a/net/9p/trans_virtio.c
+++ b/net/9p/trans_virtio.c
@@@ -330,23 -332,50 +330,47 @@@ static int p9_get_mapped_pages(struct v
  			if (err == -ERESTARTSYS)
  				return err;
  		}
 -		n = iov_iter_get_pages_alloc(data, pages, count, offs);
 -		if (n < 0)
 -			return n;
 -		*need_drop = 1;
 -		nr_pages = DIV_ROUND_UP(n + *offs, PAGE_SIZE);
 +		err = p9_payload_gup(data, &nr_pages, pages, write);
 +		if (err < 0)
 +			return err;
  		atomic_add(nr_pages, &vp_pinned);
 -		return n;
  	} else {
  		/* kernel buffer, no need to pin pages */
 -		int index;
 -		size_t len;
 -		void *p;
 -
 -		/* we'd already checked that it's non-empty */
 -		while (1) {
 -			len = iov_iter_single_seg_count(data);
 -			if (likely(len)) {
 -				p = data->kvec->iov_base + data->iov_offset;
 -				break;
 -			}
 -			iov_iter_advance(data, 0);
 +		int s, index = 0;
 +		int count = nr_pages;
 +		while (nr_pages) {
 +			s = rest_of_page(data);
 +			pages[index++] = kmap_to_page(data);
 +			data += s;
 +			nr_pages--;
  		}
++<<<<<<< HEAD
 +		nr_pages = count;
++=======
+ 		if (len > count)
+ 			len = count;
+ 
+ 		nr_pages = DIV_ROUND_UP((unsigned long)p + len, PAGE_SIZE) -
+ 			   (unsigned long)p / PAGE_SIZE;
+ 
+ 		*pages = kmalloc_array(nr_pages, sizeof(struct page *),
+ 				       GFP_NOFS);
+ 		if (!*pages)
+ 			return -ENOMEM;
+ 
+ 		*need_drop = 0;
+ 		p -= (*offs = offset_in_page(p));
+ 		for (index = 0; index < nr_pages; index++) {
+ 			if (is_vmalloc_addr(p))
+ 				(*pages)[index] = vmalloc_to_page(p);
+ 			else
+ 				(*pages)[index] = kmap_to_page(p);
+ 			p += PAGE_SIZE;
+ 		}
+ 		return len;
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	}
 +	return nr_pages;
  }
  
  /**
diff --cc net/can/bcm.c
index a192e8509d71,394ff1d2791f..000000000000
--- a/net/can/bcm.c
+++ b/net/can/bcm.c
@@@ -880,12 -917,15 +880,18 @@@ static int bcm_tx_setup(struct bcm_msg_
  		if (!op)
  			return -ENOMEM;
  
 -		op->can_id = msg_head->can_id;
 -		op->cfsiz = CFSIZ(msg_head->flags);
 -		op->flags = msg_head->flags;
 +		op->can_id    = msg_head->can_id;
  
 -		/* create array for CAN frames and copy the data */
 +		/* create array for can_frames and copy the data */
  		if (msg_head->nframes > 1) {
++<<<<<<< HEAD
 +			op->frames = kmalloc(msg_head->nframes * CFSIZ,
 +					     GFP_KERNEL);
++=======
+ 			op->frames = kmalloc_array(msg_head->nframes,
+ 						   op->cfsiz,
+ 						   GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  			if (!op->frames) {
  				kfree(op);
  				return -ENOMEM;
@@@ -1043,13 -1089,16 +1049,20 @@@ static int bcm_rx_setup(struct bcm_msg_
  		if (!op)
  			return -ENOMEM;
  
 -		op->can_id = msg_head->can_id;
 -		op->nframes = msg_head->nframes;
 -		op->cfsiz = CFSIZ(msg_head->flags);
 -		op->flags = msg_head->flags;
 +		op->can_id    = msg_head->can_id;
 +		op->nframes   = msg_head->nframes;
  
  		if (msg_head->nframes > 1) {
++<<<<<<< HEAD
 +			/* create array for can_frames and copy the data */
 +			op->frames = kmalloc(msg_head->nframes * CFSIZ,
 +					     GFP_KERNEL);
++=======
+ 			/* create array for CAN frames and copy the data */
+ 			op->frames = kmalloc_array(msg_head->nframes,
+ 						   op->cfsiz,
+ 						   GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  			if (!op->frames) {
  				kfree(op);
  				return -ENOMEM;
diff --cc net/netfilter/nf_tables_api.c
index e2ddb2bff2ce,cae4a026859d..000000000000
--- a/net/netfilter/nf_tables_api.c
+++ b/net/netfilter/nf_tables_api.c
@@@ -4692,8 -7162,10 +4692,15 @@@ static int __init nf_tables_module_init
  {
  	int err;
  
++<<<<<<< HEAD
 +	info = kmalloc(sizeof(struct nft_expr_info) * NFT_RULE_MAXEXPRS,
 +		       GFP_KERNEL);
++=======
+ 	nft_chain_filter_init();
+ 
+ 	info = kmalloc_array(NFT_RULE_MAXEXPRS, sizeof(struct nft_expr_info),
+ 			     GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (info == NULL) {
  		err = -ENOMEM;
  		goto err1;
diff --cc sound/core/pcm_native.c
index fc56b217d868,cecc79772c94..000000000000
--- a/sound/core/pcm_native.c
+++ b/sound/core/pcm_native.c
@@@ -3066,16 -3065,18 +3066,23 @@@ static ssize_t snd_pcm_aio_read(struct 
  	runtime = substream->runtime;
  	if (runtime->status->state == SNDRV_PCM_STATE_OPEN)
  		return -EBADFD;
 -	if (!iter_is_iovec(to))
 +	if (nr_segs > 1024 || nr_segs != runtime->channels)
  		return -EINVAL;
 -	if (to->nr_segs > 1024 || to->nr_segs != runtime->channels)
 +	if (!frame_aligned(runtime, iov->iov_len))
  		return -EINVAL;
++<<<<<<< HEAD
 +	frames = bytes_to_samples(runtime, iov->iov_len);
 +	bufs = kmalloc(sizeof(void *) * nr_segs, GFP_KERNEL);
++=======
+ 	if (!frame_aligned(runtime, to->iov->iov_len))
+ 		return -EINVAL;
+ 	frames = bytes_to_samples(runtime, to->iov->iov_len);
+ 	bufs = kmalloc_array(to->nr_segs, sizeof(void *), GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (bufs == NULL)
  		return -ENOMEM;
 -	for (i = 0; i < to->nr_segs; ++i)
 -		bufs[i] = to->iov[i].iov_base;
 +	for (i = 0; i < nr_segs; ++i)
 +		bufs[i] = iov[i].iov_base;
  	result = snd_pcm_lib_readv(substream, bufs, frames);
  	if (result > 0)
  		result = frames_to_bytes(runtime, result);
@@@ -3101,15 -3101,17 +3108,23 @@@ static ssize_t snd_pcm_aio_write(struc
  	runtime = substream->runtime;
  	if (runtime->status->state == SNDRV_PCM_STATE_OPEN)
  		return -EBADFD;
 -	if (!iter_is_iovec(from))
 +	if (nr_segs > 128 || nr_segs != runtime->channels ||
 +	    !frame_aligned(runtime, iov->iov_len))
  		return -EINVAL;
++<<<<<<< HEAD
 +	frames = bytes_to_samples(runtime, iov->iov_len);
 +	bufs = kmalloc(sizeof(void *) * nr_segs, GFP_KERNEL);
++=======
+ 	if (from->nr_segs > 128 || from->nr_segs != runtime->channels ||
+ 	    !frame_aligned(runtime, from->iov->iov_len))
+ 		return -EINVAL;
+ 	frames = bytes_to_samples(runtime, from->iov->iov_len);
+ 	bufs = kmalloc_array(from->nr_segs, sizeof(void *), GFP_KERNEL);
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  	if (bufs == NULL)
  		return -ENOMEM;
 -	for (i = 0; i < from->nr_segs; ++i)
 -		bufs[i] = from->iov[i].iov_base;
 +	for (i = 0; i < nr_segs; ++i)
 +		bufs[i] = iov[i].iov_base;
  	result = snd_pcm_lib_writev(substream, bufs, frames);
  	if (result > 0)
  		result = frames_to_bytes(runtime, result);
diff --cc sound/pci/cs46xx/cs46xx_lib.c
index c5e9255d6aea,146e1a3498c7..000000000000
--- a/sound/pci/cs46xx/cs46xx_lib.c
+++ b/sound/pci/cs46xx/cs46xx_lib.c
@@@ -334,13 -337,147 +334,142 @@@ int snd_cs46xx_download(struct snd_cs46
  	return 0;
  }
  
 -static inline void memcpy_le32(void *dst, const void *src, unsigned int len)
 -{
 -#ifdef __LITTLE_ENDIAN
 -	memcpy(dst, src, len);
 -#else
 -	u32 *_dst = dst;
 -	const __le32 *_src = src;
 -	len /= 4;
 -	while (len-- > 0)
 -		*_dst++ = le32_to_cpu(*_src++);
 -#endif
 -}
 -
  #ifdef CONFIG_SND_CS46XX_NEW_DSP
  
++<<<<<<< HEAD
 +#include "imgs/cwc4630.h"
 +#include "imgs/cwcasync.h"
 +#include "imgs/cwcsnoop.h"
 +#include "imgs/cwcbinhack.h"
 +#include "imgs/cwcdma.h"
++=======
+ static const char *module_names[CS46XX_DSP_MODULES] = {
+ 	"cwc4630", "cwcasync", "cwcsnoop", "cwcbinhack", "cwcdma"
+ };
+ 
+ MODULE_FIRMWARE("cs46xx/cwc4630");
+ MODULE_FIRMWARE("cs46xx/cwcasync");
+ MODULE_FIRMWARE("cs46xx/cwcsnoop");
+ MODULE_FIRMWARE("cs46xx/cwcbinhack");
+ MODULE_FIRMWARE("cs46xx/cwcdma");
+ 
+ static void free_module_desc(struct dsp_module_desc *module)
+ {
+ 	if (!module)
+ 		return;
+ 	kfree(module->module_name);
+ 	kfree(module->symbol_table.symbols);
+ 	if (module->segments) {
+ 		int i;
+ 		for (i = 0; i < module->nsegments; i++)
+ 			kfree(module->segments[i].data);
+ 		kfree(module->segments);
+ 	}
+ 	kfree(module);
+ }
+ 
+ /* firmware binary format:
+  * le32 nsymbols;
+  * struct {
+  *	le32 address;
+  *	char symbol_name[DSP_MAX_SYMBOL_NAME];
+  *	le32 symbol_type;
+  * } symbols[nsymbols];
+  * le32 nsegments;
+  * struct {
+  *	le32 segment_type;
+  *	le32 offset;
+  *	le32 size;
+  *	le32 data[size];
+  * } segments[nsegments];
+  */
+ 
+ static int load_firmware(struct snd_cs46xx *chip,
+ 			 struct dsp_module_desc **module_ret,
+ 			 const char *fw_name)
+ {
+ 	int i, err;
+ 	unsigned int nums, fwlen, fwsize;
+ 	const __le32 *fwdat;
+ 	struct dsp_module_desc *module = NULL;
+ 	const struct firmware *fw;
+ 	char fw_path[32];
+ 
+ 	sprintf(fw_path, "cs46xx/%s", fw_name);
+ 	err = request_firmware(&fw, fw_path, &chip->pci->dev);
+ 	if (err < 0)
+ 		return err;
+ 	fwsize = fw->size / 4;
+ 	if (fwsize < 2) {
+ 		err = -EINVAL;
+ 		goto error;
+ 	}
+ 
+ 	err = -ENOMEM;
+ 	module = kzalloc(sizeof(*module), GFP_KERNEL);
+ 	if (!module)
+ 		goto error;
+ 	module->module_name = kstrdup(fw_name, GFP_KERNEL);
+ 	if (!module->module_name)
+ 		goto error;
+ 
+ 	fwlen = 0;
+ 	fwdat = (const __le32 *)fw->data;
+ 	nums = module->symbol_table.nsymbols = le32_to_cpu(fwdat[fwlen++]);
+ 	if (nums >= 40)
+ 		goto error_inval;
+ 	module->symbol_table.symbols =
+ 		kcalloc(nums, sizeof(struct dsp_symbol_entry), GFP_KERNEL);
+ 	if (!module->symbol_table.symbols)
+ 		goto error;
+ 	for (i = 0; i < nums; i++) {
+ 		struct dsp_symbol_entry *entry =
+ 			&module->symbol_table.symbols[i];
+ 		if (fwlen + 2 + DSP_MAX_SYMBOL_NAME / 4 > fwsize)
+ 			goto error_inval;
+ 		entry->address = le32_to_cpu(fwdat[fwlen++]);
+ 		memcpy(entry->symbol_name, &fwdat[fwlen], DSP_MAX_SYMBOL_NAME - 1);
+ 		fwlen += DSP_MAX_SYMBOL_NAME / 4;
+ 		entry->symbol_type = le32_to_cpu(fwdat[fwlen++]);
+ 	}
+ 
+ 	if (fwlen >= fwsize)
+ 		goto error_inval;
+ 	nums = module->nsegments = le32_to_cpu(fwdat[fwlen++]);
+ 	if (nums > 10)
+ 		goto error_inval;
+ 	module->segments =
+ 		kcalloc(nums, sizeof(struct dsp_segment_desc), GFP_KERNEL);
+ 	if (!module->segments)
+ 		goto error;
+ 	for (i = 0; i < nums; i++) {
+ 		struct dsp_segment_desc *entry = &module->segments[i];
+ 		if (fwlen + 3 > fwsize)
+ 			goto error_inval;
+ 		entry->segment_type = le32_to_cpu(fwdat[fwlen++]);
+ 		entry->offset = le32_to_cpu(fwdat[fwlen++]);
+ 		entry->size = le32_to_cpu(fwdat[fwlen++]);
+ 		if (fwlen + entry->size > fwsize)
+ 			goto error_inval;
+ 		entry->data = kmalloc_array(entry->size, 4, GFP_KERNEL);
+ 		if (!entry->data)
+ 			goto error;
+ 		memcpy_le32(entry->data, &fwdat[fwlen], entry->size * 4);
+ 		fwlen += entry->size;
+ 	}
+ 
+ 	*module_ret = module;
+ 	release_firmware(fw);
+ 	return 0;
+ 
+  error_inval:
+ 	err = -EINVAL;
+  error:
+ 	free_module_desc(module);
+ 	release_firmware(fw);
+ 	return err;
+ }
++>>>>>>> 6da2ec56059c (treewide: kmalloc() -> kmalloc_array())
  
  int snd_cs46xx_clear_BA1(struct snd_cs46xx *chip,
                           unsigned long offset,
* Unmerged path arch/powerpc/platforms/4xx/hsta_msi.c
* Unmerged path arch/um/drivers/vector_kern.c
* Unmerged path arch/x86/net/bpf_jit_comp32.c
* Unmerged path drivers/cpufreq/bmips-cpufreq.c
* Unmerged path drivers/crypto/chelsio/chtls/chtls_io.c
* Unmerged path drivers/crypto/stm32/stm32-hash.c
* Unmerged path drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v9.c
* Unmerged path drivers/gpu/drm/tinydrm/repaper.c
* Unmerged path drivers/gpu/drm/vc4/vc4_plane.c
* Unmerged path drivers/irqchip/irq-gic-v3-its.c
* Unmerged path drivers/lightnvm/pblk-init.c
* Unmerged path drivers/md/dm-integrity.c
* Unmerged path drivers/media/platform/vivid/vivid-core.c
* Unmerged path drivers/memstick/core/ms_block.c
* Unmerged path drivers/misc/eeprom/idt_89hpesx.c
* Unmerged path drivers/net/ethernet/moxa/moxart_ether.c
* Unmerged path drivers/net/gtp.c
* Unmerged path drivers/pinctrl/freescale/pinctrl-imx.c
* Unmerged path drivers/pinctrl/freescale/pinctrl-imx1-core.c
* Unmerged path drivers/pinctrl/sunxi/pinctrl-sunxi.c
* Unmerged path drivers/soc/fsl/qbman/qman.c
* Unmerged path drivers/virt/vboxguest/vboxguest_core.c
* Unmerged path kernel/cgroup/cgroup-v1.c
* Unmerged path kernel/fail_function.c
* Unmerged path kernel/locking/locktorture.c
* Unmerged path kernel/sched/topology.c
* Unmerged path net/tipc/netlink_compat.c
* Unmerged path sound/soc/codecs/wm8904.c
* Unmerged path sound/soc/codecs/wm8958-dsp2.c
diff --git a/arch/arm/kernel/kprobes-test.c b/arch/arm/kernel/kprobes-test.c
index 0cd63d080c7b..c5ed08c3b358 100644
--- a/arch/arm/kernel/kprobes-test.c
+++ b/arch/arm/kernel/kprobes-test.c
@@ -803,8 +803,9 @@ static int coverage_start_fn(const struct decode_header *h, void *args)
 
 static int coverage_start(const union decode_item *table)
 {
-	coverage.base = kmalloc(MAX_COVERAGE_ENTRIES *
-				sizeof(struct coverage_entry), GFP_KERNEL);
+	coverage.base = kmalloc_array(MAX_COVERAGE_ENTRIES,
+				      sizeof(struct coverage_entry),
+				      GFP_KERNEL);
 	coverage.num_entries = 0;
 	coverage.nesting = 0;
 	return table_iter(table, coverage_start_fn, &coverage);
* Unmerged path arch/arm/kernel/sys_oabi-compat.c
diff --git a/arch/arm/mm/pgd.c b/arch/arm/mm/pgd.c
index 1046b373d1ae..473d50cac217 100644
--- a/arch/arm/mm/pgd.c
+++ b/arch/arm/mm/pgd.c
@@ -20,7 +20,7 @@
 #include "mm.h"
 
 #ifdef CONFIG_ARM_LPAE
-#define __pgd_alloc()	kmalloc(PTRS_PER_PGD * sizeof(pgd_t), GFP_KERNEL)
+#define __pgd_alloc()	kmalloc_array(PTRS_PER_PGD, sizeof(pgd_t), GFP_KERNEL)
 #define __pgd_free(pgd)	kfree(pgd)
 #else
 #define __pgd_alloc()	(pgd_t *)__get_free_pages(GFP_KERNEL, 2)
diff --git a/arch/ia64/kernel/mca_drv.c b/arch/ia64/kernel/mca_drv.c
index 94f8bf777afa..dfe40cbdf3b3 100644
--- a/arch/ia64/kernel/mca_drv.c
+++ b/arch/ia64/kernel/mca_drv.c
@@ -350,7 +350,8 @@ init_record_index_pools(void)
 	/* - 3 - */
 	slidx_pool.max_idx = (rec_max_size/sect_min_size) * 2 + 1;
 	slidx_pool.buffer =
-		kmalloc(slidx_pool.max_idx * sizeof(slidx_list_t), GFP_KERNEL);
+		kmalloc_array(slidx_pool.max_idx, sizeof(slidx_list_t),
+			      GFP_KERNEL);
 
 	return slidx_pool.buffer ? 0 : -ENOMEM;
 }
diff --git a/arch/ia64/mm/tlb.c b/arch/ia64/mm/tlb.c
index ed6129768681..c08d042d1639 100644
--- a/arch/ia64/mm/tlb.c
+++ b/arch/ia64/mm/tlb.c
@@ -430,8 +430,9 @@ int ia64_itr_entry(u64 target_mask, u64 va, u64 pte, u64 log_size)
 	int cpu = smp_processor_id();
 
 	if (!ia64_idtrs[cpu]) {
-		ia64_idtrs[cpu] = kmalloc(2 * IA64_TR_ALLOC_MAX *
-				sizeof (struct ia64_tr_entry), GFP_KERNEL);
+		ia64_idtrs[cpu] = kmalloc_array(2 * IA64_TR_ALLOC_MAX,
+						sizeof(struct ia64_tr_entry),
+						GFP_KERNEL);
 		if (!ia64_idtrs[cpu])
 			return -ENOMEM;
 	}
diff --git a/arch/ia64/sn/kernel/irq.c b/arch/ia64/sn/kernel/irq.c
index 62cf4dde6a04..49e100192dd1 100644
--- a/arch/ia64/sn/kernel/irq.c
+++ b/arch/ia64/sn/kernel/irq.c
@@ -474,7 +474,8 @@ void __init sn_irq_lh_init(void)
 {
 	int i;
 
-	sn_irq_lh = kmalloc(sizeof(struct list_head *) * NR_IRQS, GFP_KERNEL);
+	sn_irq_lh = kmalloc_array(NR_IRQS, sizeof(struct list_head *),
+				  GFP_KERNEL);
 	if (!sn_irq_lh)
 		panic("SN PCI INIT: Failed to allocate memory for PCI init\n");
 
diff --git a/arch/mips/alchemy/common/dbdma.c b/arch/mips/alchemy/common/dbdma.c
index 19d5642c16d9..e54be178f848 100644
--- a/arch/mips/alchemy/common/dbdma.c
+++ b/arch/mips/alchemy/common/dbdma.c
@@ -411,8 +411,8 @@ u32 au1xxx_dbdma_ring_alloc(u32 chanid, int entries)
 	 * and if we try that first we are likely to not waste larger
 	 * slabs of memory.
 	 */
-	desc_base = (u32)kmalloc(entries * sizeof(au1x_ddma_desc_t),
-				 GFP_KERNEL|GFP_DMA);
+	desc_base = (u32)kmalloc_array(entries, sizeof(au1x_ddma_desc_t),
+				       GFP_KERNEL|GFP_DMA);
 	if (desc_base == 0)
 		return 0;
 
diff --git a/arch/powerpc/lib/rheap.c b/arch/powerpc/lib/rheap.c
index a1060a868e69..d6094c5924a8 100644
--- a/arch/powerpc/lib/rheap.c
+++ b/arch/powerpc/lib/rheap.c
@@ -54,7 +54,7 @@ static int grow(rh_info_t * info, int max_blocks)
 
 	new_blocks = max_blocks - info->max_blocks;
 
-	block = kmalloc(sizeof(rh_block_t) * max_blocks, GFP_ATOMIC);
+	block = kmalloc_array(max_blocks, sizeof(rh_block_t), GFP_ATOMIC);
 	if (block == NULL)
 		return -ENOMEM;
 
* Unmerged path arch/powerpc/platforms/4xx/hsta_msi.c
diff --git a/arch/powerpc/sysdev/mpic.c b/arch/powerpc/sysdev/mpic.c
index fe4da84e54ae..89a9efa990c8 100644
--- a/arch/powerpc/sysdev/mpic.c
+++ b/arch/powerpc/sysdev/mpic.c
@@ -1612,8 +1612,9 @@ void __init mpic_init(struct mpic *mpic)
 
 #ifdef CONFIG_PM
 	/* allocate memory to save mpic state */
-	mpic->save_data = kmalloc(mpic->num_sources * sizeof(*mpic->save_data),
-				  GFP_KERNEL);
+	mpic->save_data = kmalloc_array(mpic->num_sources,
+				        sizeof(*mpic->save_data),
+				        GFP_KERNEL);
 	BUG_ON(mpic->save_data == NULL);
 #endif
 
diff --git a/arch/powerpc/sysdev/ppc4xx_msi.c b/arch/powerpc/sysdev/ppc4xx_msi.c
index 372d38d9c6c5..3f8d2c82a73b 100644
--- a/arch/powerpc/sysdev/ppc4xx_msi.c
+++ b/arch/powerpc/sysdev/ppc4xx_msi.c
@@ -90,7 +90,7 @@ static int ppc4xx_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 	if (type == PCI_CAP_ID_MSIX)
 		pr_debug("ppc4xx msi: MSI-X untested, trying anyway.\n");
 
-	msi_data->msi_virqs = kmalloc((msi_irqs) * sizeof(int), GFP_KERNEL);
+	msi_data->msi_virqs = kmalloc_array(msi_irqs, sizeof(int), GFP_KERNEL);
 	if (!msi_data->msi_virqs)
 		return -ENOMEM;
 
diff --git a/arch/s390/hypfs/hypfs_diag0c.c b/arch/s390/hypfs/hypfs_diag0c.c
index d4c0d3717543..189fe0373974 100644
--- a/arch/s390/hypfs/hypfs_diag0c.c
+++ b/arch/s390/hypfs/hypfs_diag0c.c
@@ -50,7 +50,8 @@ static void *diag0c_store(unsigned int *count)
 
 	get_online_cpus();
 	cpu_count = num_online_cpus();
-	cpu_vec = kmalloc(sizeof(*cpu_vec) * num_possible_cpus(), GFP_KERNEL);
+	cpu_vec = kmalloc_array(num_possible_cpus(), sizeof(*cpu_vec),
+				GFP_KERNEL);
 	if (!cpu_vec)
 		goto fail_put_online_cpus;
 	/* Note: Diag 0c needs 8 byte alignment and real storage */
* Unmerged path arch/s390/kernel/debug.c
diff --git a/arch/s390/kernel/perf_cpum_cf_events.c b/arch/s390/kernel/perf_cpum_cf_events.c
index d9dc59cfb2f7..8f49d96eae76 100644
--- a/arch/s390/kernel/perf_cpum_cf_events.c
+++ b/arch/s390/kernel/perf_cpum_cf_events.c
@@ -526,7 +526,7 @@ static __init struct attribute **merge_attr(struct attribute **a,
 		j++;
 	j++;
 
-	new = kmalloc(sizeof(struct attribute *) * j, GFP_KERNEL);
+	new = kmalloc_array(j, sizeof(struct attribute *), GFP_KERNEL);
 	if (!new)
 		return NULL;
 	j = 0;
* Unmerged path arch/s390/mm/extmem.c
diff --git a/arch/sparc/kernel/nmi.c b/arch/sparc/kernel/nmi.c
index 6479256fd5a4..8063cdb1b5f2 100644
--- a/arch/sparc/kernel/nmi.c
+++ b/arch/sparc/kernel/nmi.c
@@ -178,7 +178,8 @@ static int __init check_nmi_watchdog(void)
 	if (!atomic_read(&nmi_active))
 		return 0;
 
-	prev_nmi_count = kmalloc(nr_cpu_ids * sizeof(unsigned int), GFP_KERNEL);
+	prev_nmi_count = kmalloc_array(nr_cpu_ids, sizeof(unsigned int),
+				       GFP_KERNEL);
 	if (!prev_nmi_count) {
 		err = -ENOMEM;
 		goto error;
diff --git a/arch/sparc/kernel/sys_sparc_64.c b/arch/sparc/kernel/sys_sparc_64.c
index 1e9e320583c7..e742abd5d61f 100644
--- a/arch/sparc/kernel/sys_sparc_64.c
+++ b/arch/sparc/kernel/sys_sparc_64.c
@@ -581,8 +581,9 @@ SYSCALL_DEFINE5(utrap_install, utrap_entry_t, type,
 			unsigned long *p = current_thread_info()->utraps;
 
 			current_thread_info()->utraps =
-				kmalloc((UT_TRAP_INSTRUCTION_31+1)*sizeof(long),
-					GFP_KERNEL);
+				kmalloc_array(UT_TRAP_INSTRUCTION_31 + 1,
+					      sizeof(long),
+					      GFP_KERNEL);
 			if (!current_thread_info()->utraps) {
 				current_thread_info()->utraps = p;
 				return -ENOMEM;
diff --git a/arch/sparc/net/bpf_jit_comp.c b/arch/sparc/net/bpf_jit_comp.c
index d32340c1e7af..215127869fbd 100644
--- a/arch/sparc/net/bpf_jit_comp.c
+++ b/arch/sparc/net/bpf_jit_comp.c
@@ -366,7 +366,7 @@ void bpf_jit_compile(struct sk_filter *fp)
 	if (!bpf_jit_enable)
 		return;
 
-	addrs = kmalloc(flen * sizeof(*addrs), GFP_KERNEL);
+	addrs = kmalloc_array(flen, sizeof(*addrs), GFP_KERNEL);
 	if (addrs == NULL)
 		return;
 
* Unmerged path arch/um/drivers/ubd_kern.c
* Unmerged path arch/um/drivers/vector_kern.c
diff --git a/arch/unicore32/kernel/pm.c b/arch/unicore32/kernel/pm.c
index 784bc2db3b28..6f8164d91dc2 100644
--- a/arch/unicore32/kernel/pm.c
+++ b/arch/unicore32/kernel/pm.c
@@ -109,8 +109,9 @@ static int __init puv3_pm_init(void)
 		return -EINVAL;
 	}
 
-	sleep_save = kmalloc(puv3_cpu_pm_fns->save_count
-				* sizeof(unsigned long), GFP_KERNEL);
+	sleep_save = kmalloc_array(puv3_cpu_pm_fns->save_count,
+				   sizeof(unsigned long),
+				   GFP_KERNEL);
 	if (!sleep_save) {
 		printk(KERN_ERR "failed to alloc memory for pm save\n");
 		return -ENOMEM;
diff --git a/arch/x86/events/core.c b/arch/x86/events/core.c
index 063beaee49b9..6447e1f67d26 100644
--- a/arch/x86/events/core.c
+++ b/arch/x86/events/core.c
@@ -1623,7 +1623,7 @@ __init struct attribute **merge_attr(struct attribute **a, struct attribute **b)
 		j++;
 	j++;
 
-	new = kmalloc(sizeof(struct attribute *) * j, GFP_KERNEL);
+	new = kmalloc_array(j, sizeof(struct attribute *), GFP_KERNEL);
 	if (!new)
 		return NULL;
 
diff --git a/arch/x86/kernel/hpet.c b/arch/x86/kernel/hpet.c
index e2332b3fcf98..b881c6372a82 100644
--- a/arch/x86/kernel/hpet.c
+++ b/arch/x86/kernel/hpet.c
@@ -960,8 +960,8 @@ int __init hpet_enable(void)
 #endif
 
 	cfg = hpet_readl(HPET_CFG);
-	hpet_boot_cfg = kmalloc((last + 2) * sizeof(*hpet_boot_cfg),
-				GFP_KERNEL);
+	hpet_boot_cfg = kmalloc_array(last + 2, sizeof(*hpet_boot_cfg),
+				      GFP_KERNEL);
 	if (hpet_boot_cfg)
 		*hpet_boot_cfg = cfg;
 	else
diff --git a/arch/x86/kernel/ksysfs.c b/arch/x86/kernel/ksysfs.c
index 55d81aaf5713..a6383270800c 100644
--- a/arch/x86/kernel/ksysfs.c
+++ b/arch/x86/kernel/ksysfs.c
@@ -283,7 +283,7 @@ static int __init create_setup_data_nodes(struct kobject *parent)
 	if (ret)
 		goto out_setup_data_kobj;
 
-	kobjp = kmalloc(sizeof(*kobjp) * nr, GFP_KERNEL);
+	kobjp = kmalloc_array(nr, sizeof(*kobjp), GFP_KERNEL);
 	if (!kobjp) {
 		ret = -ENOMEM;
 		goto out_setup_data_kobj;
* Unmerged path arch/x86/kvm/svm.c
* Unmerged path arch/x86/net/bpf_jit_comp.c
* Unmerged path arch/x86/net/bpf_jit_comp32.c
diff --git a/arch/x86/platform/uv/tlb_uv.c b/arch/x86/platform/uv/tlb_uv.c
index ddb304c9aa75..cea73cef9dcd 100644
--- a/arch/x86/platform/uv/tlb_uv.c
+++ b/arch/x86/platform/uv/tlb_uv.c
@@ -2168,7 +2168,7 @@ static int __init init_per_cpu(int nuvhubs, int base_part_pnode)
 	if (is_uv3_hub() || is_uv2_hub() || is_uv1_hub())
 		timeout_us = calculate_destination_timeout();
 
-	vp = kmalloc(nuvhubs * sizeof(struct uvhub_desc), GFP_KERNEL);
+	vp = kmalloc_array(nuvhubs, sizeof(struct uvhub_desc), GFP_KERNEL);
 	uvhub_descs = (struct uvhub_desc *)vp;
 	memset(uvhub_descs, 0, nuvhubs * sizeof(struct uvhub_desc));
 	uvhub_mask = kzalloc((nuvhubs+7)/8, GFP_KERNEL);
diff --git a/block/partitions/ldm.c b/block/partitions/ldm.c
index e507cfbd044e..e40c3c43575a 100644
--- a/block/partitions/ldm.c
+++ b/block/partitions/ldm.c
@@ -430,7 +430,7 @@ static bool ldm_validate_tocblocks(struct parsed_partitions *state,
 	BUG_ON(!state || !ldb);
 	ph = &ldb->ph;
 	tb[0] = &ldb->toc;
-	tb[1] = kmalloc(sizeof(*tb[1]) * 3, GFP_KERNEL);
+	tb[1] = kmalloc_array(3, sizeof(*tb[1]), GFP_KERNEL);
 	if (!tb[1]) {
 		ldm_crit("Out of memory.");
 		goto err;
* Unmerged path crypto/testmgr.c
diff --git a/drivers/acpi/apei/hest.c b/drivers/acpi/apei/hest.c
index 502024502b13..d2bb81e631c6 100644
--- a/drivers/acpi/apei/hest.c
+++ b/drivers/acpi/apei/hest.c
@@ -216,7 +216,8 @@ static int __init hest_ghes_dev_register(unsigned int ghes_count)
 	struct ghes_arr ghes_arr;
 
 	ghes_arr.count = 0;
-	ghes_arr.ghes_devs = kmalloc(sizeof(void *) * ghes_count, GFP_KERNEL);
+	ghes_arr.ghes_devs = kmalloc_array(ghes_count, sizeof(void *),
+					   GFP_KERNEL);
 	if (!ghes_arr.ghes_devs)
 		return -ENOMEM;
 
diff --git a/drivers/acpi/processor_perflib.c b/drivers/acpi/processor_perflib.c
index ae7e587ed04a..73f89d36d884 100644
--- a/drivers/acpi/processor_perflib.c
+++ b/drivers/acpi/processor_perflib.c
@@ -376,8 +376,9 @@ static int acpi_processor_get_performance_states(struct acpi_processor *pr)
 
 	pr->performance->state_count = pss->package.count;
 	pr->performance->states =
-	    kmalloc(sizeof(struct acpi_processor_px) * pss->package.count,
-		    GFP_KERNEL);
+	    kmalloc_array(pss->package.count,
+			  sizeof(struct acpi_processor_px),
+			  GFP_KERNEL);
 	if (!pr->performance->states) {
 		result = -ENOMEM;
 		goto end;
diff --git a/drivers/acpi/processor_throttling.c b/drivers/acpi/processor_throttling.c
index e7dd2c1fee79..048a0c42a241 100644
--- a/drivers/acpi/processor_throttling.c
+++ b/drivers/acpi/processor_throttling.c
@@ -535,8 +535,9 @@ static int acpi_processor_get_throttling_states(struct acpi_processor *pr)
 
 	pr->throttling.state_count = tss->package.count;
 	pr->throttling.states_tss =
-	    kmalloc(sizeof(struct acpi_processor_tx_tss) * tss->package.count,
-		    GFP_KERNEL);
+	    kmalloc_array(tss->package.count,
+			  sizeof(struct acpi_processor_tx_tss),
+			  GFP_KERNEL);
 	if (!pr->throttling.states_tss) {
 		result = -ENOMEM;
 		goto end;
* Unmerged path drivers/acpi/video.c
diff --git a/drivers/atm/solos-pci.c b/drivers/atm/solos-pci.c
index 32784d18d1f7..b5ddc1f333ef 100644
--- a/drivers/atm/solos-pci.c
+++ b/drivers/atm/solos-pci.c
@@ -1275,7 +1275,8 @@ static int fpga_probe(struct pci_dev *dev, const struct pci_device_id *id)
 		card->using_dma = 1;
 		if (1) { /* All known FPGA versions so far */
 			card->dma_alignment = 3;
-			card->dma_bounce = kmalloc(card->nr_ports * BUF_SIZE, GFP_KERNEL);
+			card->dma_bounce = kmalloc_array(card->nr_ports,
+							 BUF_SIZE, GFP_KERNEL);
 			if (!card->dma_bounce) {
 				dev_warn(&card->dev->dev, "Failed to allocate DMA bounce buffers\n");
 				/* Fallback to MMIO doesn't work */
diff --git a/drivers/auxdisplay/cfag12864b.c b/drivers/auxdisplay/cfag12864b.c
index 41ce4bd96813..d688e94635bb 100644
--- a/drivers/auxdisplay/cfag12864b.c
+++ b/drivers/auxdisplay/cfag12864b.c
@@ -347,8 +347,8 @@ static int __init cfag12864b_init(void)
 		goto none;
 	}
 
-	cfag12864b_cache = kmalloc(sizeof(unsigned char) *
-		CFAG12864B_SIZE, GFP_KERNEL);
+	cfag12864b_cache = kmalloc(CFAG12864B_SIZE,
+				   GFP_KERNEL);
 	if (cfag12864b_cache == NULL) {
 		printk(KERN_ERR CFAG12864B_NAME ": ERROR: "
 			"can't alloc cache buffer (%i bytes)\n",
diff --git a/drivers/block/DAC960.c b/drivers/block/DAC960.c
index eb3950113e42..b97deb9dc5cb 100644
--- a/drivers/block/DAC960.c
+++ b/drivers/block/DAC960.c
@@ -5724,8 +5724,8 @@ static bool DAC960_CheckStatusBuffer(DAC960_Controller_T *Controller,
       Controller->CombinedStatusBufferLength = NewStatusBufferLength;
       return true;
     }
-  NewStatusBuffer = kmalloc(2 * Controller->CombinedStatusBufferLength,
-			     GFP_ATOMIC);
+  NewStatusBuffer = kmalloc_array(2, Controller->CombinedStatusBufferLength,
+                                  GFP_ATOMIC);
   if (NewStatusBuffer == NULL)
     {
       DAC960_Warning("Unable to expand Combined Status Buffer - Truncating\n",
* Unmerged path drivers/block/loop.c
diff --git a/drivers/block/z2ram.c b/drivers/block/z2ram.c
index 5a95baf4b104..3389433ba0e3 100644
--- a/drivers/block/z2ram.c
+++ b/drivers/block/z2ram.c
@@ -198,8 +198,9 @@ static int z2_open(struct block_device *bdev, fmode_t mode)
 		vaddr = (unsigned long)z_remap_nocache_nonser(paddr, size);
 #endif
 		z2ram_map = 
-			kmalloc((size/Z2RAM_CHUNKSIZE)*sizeof(z2ram_map[0]),
-				GFP_KERNEL);
+			kmalloc_array(size / Z2RAM_CHUNKSIZE,
+                                      sizeof(z2ram_map[0]),
+                                      GFP_KERNEL);
 		if ( z2ram_map == NULL )
 		{
 		    printk( KERN_ERR DEVICE_NAME
diff --git a/drivers/cdrom/cdrom.c b/drivers/cdrom/cdrom.c
index 672ad4e30deb..0238e39e4e2e 100644
--- a/drivers/cdrom/cdrom.c
+++ b/drivers/cdrom/cdrom.c
@@ -2104,7 +2104,7 @@ static int cdrom_read_cdda_old(struct cdrom_device_info *cdi, __u8 __user *ubuf,
 	 */
 	nr = nframes;
 	do {
-		cgc.buffer = kmalloc(CD_FRAMESIZE_RAW * nr, GFP_KERNEL);
+		cgc.buffer = kmalloc_array(nr, CD_FRAMESIZE_RAW, GFP_KERNEL);
 		if (cgc.buffer)
 			break;
 
diff --git a/drivers/char/agp/compat_ioctl.c b/drivers/char/agp/compat_ioctl.c
index 2053f70ef66b..52ffe1706ce0 100644
--- a/drivers/char/agp/compat_ioctl.c
+++ b/drivers/char/agp/compat_ioctl.c
@@ -98,11 +98,15 @@ static int compat_agpioc_reserve_wrap(struct agp_file_private *priv, void __user
 		if (ureserve.seg_count >= 16384)
 			return -EINVAL;
 
-		usegment = kmalloc(sizeof(*usegment) * ureserve.seg_count, GFP_KERNEL);
+		usegment = kmalloc_array(ureserve.seg_count,
+					 sizeof(*usegment),
+					 GFP_KERNEL);
 		if (!usegment)
 			return -ENOMEM;
 
-		ksegment = kmalloc(sizeof(*ksegment) * kreserve.seg_count, GFP_KERNEL);
+		ksegment = kmalloc_array(kreserve.seg_count,
+					 sizeof(*ksegment),
+					 GFP_KERNEL);
 		if (!ksegment) {
 			kfree(usegment);
 			return -ENOMEM;
diff --git a/drivers/char/agp/isoch.c b/drivers/char/agp/isoch.c
index c73385cc4b8a..9ff6dee30cfb 100644
--- a/drivers/char/agp/isoch.c
+++ b/drivers/char/agp/isoch.c
@@ -92,7 +92,8 @@ static int agp_3_5_isochronous_node_enable(struct agp_bridge_data *bridge,
 	 * We'll work with an array of isoch_data's (one for each
 	 * device in dev_list) throughout this function.
 	 */
-	if ((master = kmalloc(ndevs * sizeof(*master), GFP_KERNEL)) == NULL) {
+	master = kmalloc_array(ndevs, sizeof(*master), GFP_KERNEL);
+	if (master == NULL) {
 		ret = -ENOMEM;
 		goto get_out;
 	}
diff --git a/drivers/char/agp/sgi-agp.c b/drivers/char/agp/sgi-agp.c
index 3051c73bc383..e7d5bdc02d93 100644
--- a/drivers/char/agp/sgi-agp.c
+++ b/drivers/char/agp/sgi-agp.c
@@ -280,9 +280,9 @@ static int agp_sgi_init(void)
 	else
 		return 0;
 
-	sgi_tioca_agp_bridges = kmalloc(tioca_gart_found *
-					sizeof(struct agp_bridge_data *),
-					GFP_KERNEL);
+	sgi_tioca_agp_bridges = kmalloc_array(tioca_gart_found,
+					      sizeof(struct agp_bridge_data *),
+					      GFP_KERNEL);
 	if (!sgi_tioca_agp_bridges)
 		return -ENOMEM;
 
diff --git a/drivers/char/agp/uninorth-agp.c b/drivers/char/agp/uninorth-agp.c
index fdced547ad59..1f4a117aba6f 100644
--- a/drivers/char/agp/uninorth-agp.c
+++ b/drivers/char/agp/uninorth-agp.c
@@ -402,7 +402,9 @@ static int uninorth_create_gatt_table(struct agp_bridge_data *bridge)
 	if (table == NULL)
 		return -ENOMEM;
 
-	uninorth_priv.pages_arr = kmalloc((1 << page_order) * sizeof(struct page*), GFP_KERNEL);
+	uninorth_priv.pages_arr = kmalloc_array(1 << page_order,
+						sizeof(struct page *),
+						GFP_KERNEL);
 	if (uninorth_priv.pages_arr == NULL)
 		goto enomem;
 
diff --git a/drivers/char/virtio_console.c b/drivers/char/virtio_console.c
index abaf4f6cc551..7f27bfbb491e 100644
--- a/drivers/char/virtio_console.c
+++ b/drivers/char/virtio_console.c
@@ -1870,13 +1870,14 @@ static int init_vqs(struct ports_device *portdev)
 	nr_ports = portdev->config.max_nr_ports;
 	nr_queues = use_multiport(portdev) ? (nr_ports + 1) * 2 : 2;
 
-	vqs = kmalloc(nr_queues * sizeof(struct virtqueue *), GFP_KERNEL);
-	io_callbacks = kmalloc(nr_queues * sizeof(vq_callback_t *), GFP_KERNEL);
-	io_names = kmalloc(nr_queues * sizeof(char *), GFP_KERNEL);
-	portdev->in_vqs = kmalloc(nr_ports * sizeof(struct virtqueue *),
-				  GFP_KERNEL);
-	portdev->out_vqs = kmalloc(nr_ports * sizeof(struct virtqueue *),
-				   GFP_KERNEL);
+	vqs = kmalloc_array(nr_queues, sizeof(struct virtqueue *), GFP_KERNEL);
+	io_callbacks = kmalloc_array(nr_queues, sizeof(vq_callback_t *),
+				     GFP_KERNEL);
+	io_names = kmalloc_array(nr_queues, sizeof(char *), GFP_KERNEL);
+	portdev->in_vqs = kmalloc_array(nr_ports, sizeof(struct virtqueue *),
+					GFP_KERNEL);
+	portdev->out_vqs = kmalloc_array(nr_ports, sizeof(struct virtqueue *),
+					 GFP_KERNEL);
 	if (!vqs || !io_callbacks || !io_names || !portdev->in_vqs ||
 	    !portdev->out_vqs) {
 		err = -ENOMEM;
* Unmerged path drivers/cpufreq/bmips-cpufreq.c
* Unmerged path drivers/crypto/chelsio/chtls/chtls_io.c
* Unmerged path drivers/crypto/stm32/stm32-hash.c
diff --git a/drivers/dma/bestcomm/bestcomm.c b/drivers/dma/bestcomm/bestcomm.c
index a8c2e2994d2e..9493169e1574 100644
--- a/drivers/dma/bestcomm/bestcomm.c
+++ b/drivers/dma/bestcomm/bestcomm.c
@@ -87,7 +87,8 @@ bcom_task_alloc(int bd_count, int bd_size, int priv_size)
 
 	/* Init the BDs, if needed */
 	if (bd_count) {
-		tsk->cookie = kmalloc(sizeof(void*) * bd_count, GFP_KERNEL);
+		tsk->cookie = kmalloc_array(bd_count, sizeof(void *),
+					    GFP_KERNEL);
 		if (!tsk->cookie)
 			goto error;
 
* Unmerged path drivers/dma/mv_xor.c
diff --git a/drivers/firewire/core-iso.c b/drivers/firewire/core-iso.c
index 38c0aa60b2cb..051327a951b1 100644
--- a/drivers/firewire/core-iso.c
+++ b/drivers/firewire/core-iso.c
@@ -45,8 +45,8 @@ int fw_iso_buffer_alloc(struct fw_iso_buffer *buffer, int page_count)
 
 	buffer->page_count = 0;
 	buffer->page_count_mapped = 0;
-	buffer->pages = kmalloc(page_count * sizeof(buffer->pages[0]),
-				GFP_KERNEL);
+	buffer->pages = kmalloc_array(page_count, sizeof(buffer->pages[0]),
+				      GFP_KERNEL);
 	if (buffer->pages == NULL)
 		return -ENOMEM;
 
diff --git a/drivers/firewire/net.c b/drivers/firewire/net.c
index 9dd4573c4f95..fb41c7688b08 100644
--- a/drivers/firewire/net.c
+++ b/drivers/firewire/net.c
@@ -1136,7 +1136,7 @@ static int fwnet_broadcast_start(struct fwnet_device *dev)
 	max_receive = 1U << (dev->card->max_receive + 1);
 	num_packets = (FWNET_ISO_PAGE_COUNT * PAGE_SIZE) / max_receive;
 
-	ptrptr = kmalloc(sizeof(void *) * num_packets, GFP_KERNEL);
+	ptrptr = kmalloc_array(num_packets, sizeof(void *), GFP_KERNEL);
 	if (!ptrptr) {
 		retval = -ENOMEM;
 		goto failed;
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v7.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v7.c
index ea54e53172b9..acbaf6d90db6 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v7.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v7.c
@@ -417,7 +417,7 @@ static int kgd_hqd_dump(struct kgd_dev *kgd,
 		(*dump)[i++][1] = RREG32(addr);		\
 	} while (0)
 
-	*dump = kmalloc(HQD_N_REGS*2*sizeof(uint32_t), GFP_KERNEL);
+	*dump = kmalloc_array(HQD_N_REGS * 2, sizeof(uint32_t), GFP_KERNEL);
 	if (*dump == NULL)
 		return -ENOMEM;
 
@@ -514,7 +514,7 @@ static int kgd_hqd_sdma_dump(struct kgd_dev *kgd,
 #undef HQD_N_REGS
 #define HQD_N_REGS (19+4)
 
-	*dump = kmalloc(HQD_N_REGS*2*sizeof(uint32_t), GFP_KERNEL);
+	*dump = kmalloc_array(HQD_N_REGS * 2, sizeof(uint32_t), GFP_KERNEL);
 	if (*dump == NULL)
 		return -ENOMEM;
 
diff --git a/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v8.c b/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v8.c
index 89264c9a5e9f..133f3ad44904 100644
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v8.c
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v8.c
@@ -405,7 +405,7 @@ static int kgd_hqd_dump(struct kgd_dev *kgd,
 		(*dump)[i++][1] = RREG32(addr);		\
 	} while (0)
 
-	*dump = kmalloc(HQD_N_REGS*2*sizeof(uint32_t), GFP_KERNEL);
+	*dump = kmalloc_array(HQD_N_REGS * 2, sizeof(uint32_t), GFP_KERNEL);
 	if (*dump == NULL)
 		return -ENOMEM;
 
@@ -501,7 +501,7 @@ static int kgd_hqd_sdma_dump(struct kgd_dev *kgd,
 #undef HQD_N_REGS
 #define HQD_N_REGS (19+4+2+3+7)
 
-	*dump = kmalloc(HQD_N_REGS*2*sizeof(uint32_t), GFP_KERNEL);
+	*dump = kmalloc_array(HQD_N_REGS * 2, sizeof(uint32_t), GFP_KERNEL);
 	if (*dump == NULL)
 		return -ENOMEM;
 
* Unmerged path drivers/gpu/drm/amd/amdgpu/amdgpu_amdkfd_gfx_v9.c
diff --git a/drivers/gpu/drm/drm_edid.c b/drivers/gpu/drm/drm_edid.c
index 39f1db4acda4..f45f83bc9996 100644
--- a/drivers/gpu/drm/drm_edid.c
+++ b/drivers/gpu/drm/drm_edid.c
@@ -1633,7 +1633,8 @@ struct edid *drm_do_get_edid(struct drm_connector *connector,
 		edid[EDID_LENGTH-1] += edid[0x7e] - valid_extensions;
 		edid[0x7e] = valid_extensions;
 
-		new = kmalloc((valid_extensions + 1) * EDID_LENGTH, GFP_KERNEL);
+		new = kmalloc_array(valid_extensions + 1, EDID_LENGTH,
+				    GFP_KERNEL);
 		if (!new)
 			goto out;
 
diff --git a/drivers/gpu/drm/gma500/mid_bios.c b/drivers/gpu/drm/gma500/mid_bios.c
index 7171b7475f58..237041a37532 100644
--- a/drivers/gpu/drm/gma500/mid_bios.c
+++ b/drivers/gpu/drm/gma500/mid_bios.c
@@ -239,7 +239,7 @@ static int mid_get_vbt_data_r10(struct drm_psb_private *dev_priv, u32 addr)
 	if (read_vbt_r10(addr, &vbt))
 		return -1;
 
-	gct = kmalloc(sizeof(*gct) * vbt.panel_count, GFP_KERNEL);
+	gct = kmalloc_array(vbt.panel_count, sizeof(*gct), GFP_KERNEL);
 	if (!gct)
 		return -ENOMEM;
 
diff --git a/drivers/gpu/drm/nouveau/nvif/mmu.c b/drivers/gpu/drm/nouveau/nvif/mmu.c
index 358ac4f3cf91..ae08a1ca8044 100644
--- a/drivers/gpu/drm/nouveau/nvif/mmu.c
+++ b/drivers/gpu/drm/nouveau/nvif/mmu.c
@@ -65,12 +65,15 @@ nvif_mmu_init(struct nvif_object *parent, s32 oclass, struct nvif_mmu *mmu)
 		goto done;
 	mmu->mem = mems[ret].oclass;
 
-	mmu->heap = kmalloc(sizeof(*mmu->heap) * mmu->heap_nr, GFP_KERNEL);
-	mmu->type = kmalloc(sizeof(*mmu->type) * mmu->type_nr, GFP_KERNEL);
+	mmu->heap = kmalloc_array(mmu->heap_nr, sizeof(*mmu->heap),
+				  GFP_KERNEL);
+	mmu->type = kmalloc_array(mmu->type_nr, sizeof(*mmu->type),
+				  GFP_KERNEL);
 	if (ret = -ENOMEM, !mmu->heap || !mmu->type)
 		goto done;
 
-	mmu->kind = kmalloc(sizeof(*mmu->kind) * mmu->kind_nr, GFP_KERNEL);
+	mmu->kind = kmalloc_array(mmu->kind_nr, sizeof(*mmu->kind),
+				  GFP_KERNEL);
 	if (!mmu->kind && mmu->kind_nr)
 		goto done;
 
diff --git a/drivers/gpu/drm/nouveau/nvif/vmm.c b/drivers/gpu/drm/nouveau/nvif/vmm.c
index 191832be6c65..6b9c5776547f 100644
--- a/drivers/gpu/drm/nouveau/nvif/vmm.c
+++ b/drivers/gpu/drm/nouveau/nvif/vmm.c
@@ -138,7 +138,8 @@ nvif_vmm_init(struct nvif_mmu *mmu, s32 oclass, u64 addr, u64 size,
 	vmm->limit = args->size;
 
 	vmm->page_nr = args->page_nr;
-	vmm->page = kmalloc(sizeof(*vmm->page) * vmm->page_nr, GFP_KERNEL);
+	vmm->page = kmalloc_array(vmm->page_nr, sizeof(*vmm->page),
+				  GFP_KERNEL);
 	if (!vmm->page) {
 		ret = -ENOMEM;
 		goto done;
diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/bios/iccsense.c b/drivers/gpu/drm/nouveau/nvkm/subdev/bios/iccsense.c
index 73e463ed55c3..dea444d48f94 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/bios/iccsense.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/bios/iccsense.c
@@ -73,7 +73,8 @@ nvbios_iccsense_parse(struct nvkm_bios *bios, struct nvbios_iccsense *iccsense)
 	}
 
 	iccsense->nr_entry = cnt;
-	iccsense->rail = kmalloc(sizeof(struct pwr_rail_t) * cnt, GFP_KERNEL);
+	iccsense->rail = kmalloc_array(cnt, sizeof(struct pwr_rail_t),
+				       GFP_KERNEL);
 	if (!iccsense->rail)
 		return -ENOMEM;
 
diff --git a/drivers/gpu/drm/nouveau/nvkm/subdev/fb/ramgt215.c b/drivers/gpu/drm/nouveau/nvkm/subdev/fb/ramgt215.c
index 920b3d347803..bbfde1cb3a17 100644
--- a/drivers/gpu/drm/nouveau/nvkm/subdev/fb/ramgt215.c
+++ b/drivers/gpu/drm/nouveau/nvkm/subdev/fb/ramgt215.c
@@ -171,7 +171,7 @@ gt215_link_train(struct gt215_ram *ram)
 		return -ENOSYS;
 
 	/* XXX: Multiple partitions? */
-	result = kmalloc(64 * sizeof(u32), GFP_KERNEL);
+	result = kmalloc_array(64, sizeof(u32), GFP_KERNEL);
 	if (!result)
 		return -ENOMEM;
 
diff --git a/drivers/gpu/drm/omapdrm/omap_dmm_tiler.c b/drivers/gpu/drm/omapdrm/omap_dmm_tiler.c
index 9b794c933c81..360d7cde48f9 100644
--- a/drivers/gpu/drm/omapdrm/omap_dmm_tiler.c
+++ b/drivers/gpu/drm/omapdrm/omap_dmm_tiler.c
@@ -864,8 +864,8 @@ int tiler_map_show(struct seq_file *s, void *arg)
 	h_adj = omap_dmm->container_height / ydiv;
 	w_adj = omap_dmm->container_width / xdiv;
 
-	map = kmalloc(h_adj * sizeof(*map), GFP_KERNEL);
-	global_map = kmalloc((w_adj + 1) * h_adj, GFP_KERNEL);
+	map = kmalloc_array(h_adj, sizeof(*map), GFP_KERNEL);
+	global_map = kmalloc_array(w_adj + 1, h_adj, GFP_KERNEL);
 
 	if (!map || !global_map)
 		goto error;
diff --git a/drivers/gpu/drm/omapdrm/omap_gem.c b/drivers/gpu/drm/omapdrm/omap_gem.c
index 8e9fe9e2bbc1..40979c85c497 100644
--- a/drivers/gpu/drm/omapdrm/omap_gem.c
+++ b/drivers/gpu/drm/omapdrm/omap_gem.c
@@ -247,7 +247,7 @@ static int omap_gem_attach_pages(struct drm_gem_object *obj)
 	 * DSS, GPU, etc. are not cache coherent:
 	 */
 	if (omap_obj->flags & (OMAP_BO_WC|OMAP_BO_UNCACHED)) {
-		addrs = kmalloc(npages * sizeof(*addrs), GFP_KERNEL);
+		addrs = kmalloc_array(npages, sizeof(*addrs), GFP_KERNEL);
 		if (!addrs) {
 			ret = -ENOMEM;
 			goto free_pages;
diff --git a/drivers/gpu/drm/qxl/qxl_kms.c b/drivers/gpu/drm/qxl/qxl_kms.c
index e2fb554b14da..01d514e24e05 100644
--- a/drivers/gpu/drm/qxl/qxl_kms.c
+++ b/drivers/gpu/drm/qxl/qxl_kms.c
@@ -200,8 +200,8 @@ int qxl_device_init(struct qxl_device *qdev,
 		(~(uint64_t)0) >> (qdev->slot_id_bits + qdev->slot_gen_bits);
 
 	qdev->mem_slots =
-		kmalloc(qdev->n_mem_slots * sizeof(struct qxl_memslot),
-			GFP_KERNEL);
+		kmalloc_array(qdev->n_mem_slots, sizeof(struct qxl_memslot),
+			      GFP_KERNEL);
 
 	idr_init(&qdev->release_idr);
 	spin_lock_init(&qdev->release_idr_lock);
diff --git a/drivers/gpu/drm/savage/savage_bci.c b/drivers/gpu/drm/savage/savage_bci.c
index 2a5b8466d806..35dc74883f83 100644
--- a/drivers/gpu/drm/savage/savage_bci.c
+++ b/drivers/gpu/drm/savage/savage_bci.c
@@ -298,8 +298,9 @@ static int savage_dma_init(drm_savage_private_t * dev_priv)
 
 	dev_priv->nr_dma_pages = dev_priv->cmd_dma->size /
 	    (SAVAGE_DMA_PAGE_SIZE * 4);
-	dev_priv->dma_pages = kmalloc(sizeof(drm_savage_dma_page_t) *
-				      dev_priv->nr_dma_pages, GFP_KERNEL);
+	dev_priv->dma_pages = kmalloc_array(dev_priv->nr_dma_pages,
+					    sizeof(drm_savage_dma_page_t),
+					    GFP_KERNEL);
 	if (dev_priv->dma_pages == NULL)
 		return -ENOMEM;
 
* Unmerged path drivers/gpu/drm/tinydrm/repaper.c
diff --git a/drivers/gpu/drm/ttm/ttm_page_alloc.c b/drivers/gpu/drm/ttm/ttm_page_alloc.c
index 3295faf11f4c..7d6ef6478048 100644
--- a/drivers/gpu/drm/ttm/ttm_page_alloc.c
+++ b/drivers/gpu/drm/ttm/ttm_page_alloc.c
@@ -345,8 +345,9 @@ static int ttm_page_pool_free(struct ttm_page_pool *pool, unsigned nr_free,
 	if (use_static)
 		pages_to_free = static_buf;
 	else
-		pages_to_free = kmalloc(npages_to_free * sizeof(struct page *),
-					GFP_KERNEL);
+		pages_to_free = kmalloc_array(npages_to_free,
+					      sizeof(struct page *),
+					      GFP_KERNEL);
 	if (!pages_to_free) {
 		pr_debug("Failed to allocate memory for pool free operation\n");
 		return 0;
@@ -544,7 +545,8 @@ static int ttm_alloc_new_pages(struct list_head *pages, gfp_t gfp_flags,
 	unsigned max_cpages = min(count << order, (unsigned)NUM_PAGES_TO_ALLOC);
 
 	/* allocate array for page caching change */
-	caching_array = kmalloc(max_cpages*sizeof(struct page *), GFP_KERNEL);
+	caching_array = kmalloc_array(max_cpages, sizeof(struct page *),
+				      GFP_KERNEL);
 
 	if (!caching_array) {
 		pr_debug("Unable to allocate table for new pages\n");
diff --git a/drivers/gpu/drm/ttm/ttm_page_alloc_dma.c b/drivers/gpu/drm/ttm/ttm_page_alloc_dma.c
index ba22a27e85bc..6a5695981b3e 100644
--- a/drivers/gpu/drm/ttm/ttm_page_alloc_dma.c
+++ b/drivers/gpu/drm/ttm/ttm_page_alloc_dma.c
@@ -459,8 +459,9 @@ static unsigned ttm_dma_page_pool_free(struct dma_pool *pool, unsigned nr_free,
 	if (use_static)
 		pages_to_free = static_buf;
 	else
-		pages_to_free = kmalloc(npages_to_free * sizeof(struct page *),
-					GFP_KERNEL);
+		pages_to_free = kmalloc_array(npages_to_free,
+					      sizeof(struct page *),
+					      GFP_KERNEL);
 
 	if (!pages_to_free) {
 		pr_debug("%s: Failed to allocate memory for pool free operation\n",
@@ -749,7 +750,8 @@ static int ttm_dma_pool_alloc_new_pages(struct dma_pool *pool,
 			(unsigned)(PAGE_SIZE/sizeof(struct page *)));
 
 	/* allocate array for page caching change */
-	caching_array = kmalloc(max_cpages*sizeof(struct page *), GFP_KERNEL);
+	caching_array = kmalloc_array(max_cpages, sizeof(struct page *),
+				      GFP_KERNEL);
 
 	if (!caching_array) {
 		pr_debug("%s: Unable to allocate table for new pages\n",
* Unmerged path drivers/gpu/drm/vc4/vc4_plane.c
diff --git a/drivers/hid/hid-core.c b/drivers/hid/hid-core.c
index 19fda492ad45..1f54c88d6d0a 100644
--- a/drivers/hid/hid-core.c
+++ b/drivers/hid/hid-core.c
@@ -131,8 +131,11 @@ static int open_collection(struct hid_parser *parser, unsigned type)
 	}
 
 	if (parser->device->maxcollection == parser->device->collection_size) {
-		collection = kmalloc(sizeof(struct hid_collection) *
-				parser->device->collection_size * 2, GFP_KERNEL);
+		collection = kmalloc(
+				array3_size(sizeof(struct hid_collection),
+					    parser->device->collection_size,
+					    2),
+				GFP_KERNEL);
 		if (collection == NULL) {
 			hid_err(parser->device, "failed to reallocate collection array\n");
 			return -ENOMEM;
@@ -1257,7 +1260,7 @@ static void hid_input_field(struct hid_device *hid, struct hid_field *field,
 	__s32 max = field->logical_maximum;
 	__s32 *value;
 
-	value = kmalloc(sizeof(__s32) * count, GFP_ATOMIC);
+	value = kmalloc_array(count, sizeof(__s32), GFP_ATOMIC);
 	if (!value)
 		return;
 
diff --git a/drivers/hid/hid-debug.c b/drivers/hid/hid-debug.c
index bf0370e1129d..c0a308d403b7 100644
--- a/drivers/hid/hid-debug.c
+++ b/drivers/hid/hid-debug.c
@@ -604,7 +604,7 @@ void hid_dump_report(struct hid_device *hid, int type, u8 *data,
 	char *buf;
 	unsigned int i;
 
-	buf = kmalloc(sizeof(char) * HID_DEBUG_BUFSIZE, GFP_ATOMIC);
+	buf = kmalloc(HID_DEBUG_BUFSIZE, GFP_ATOMIC);
 
 	if (!buf)
 		return;
diff --git a/drivers/hid/hid-picolcd_fb.c b/drivers/hid/hid-picolcd_fb.c
index c930ab8554ea..cb73e93b5d8e 100644
--- a/drivers/hid/hid-picolcd_fb.c
+++ b/drivers/hid/hid-picolcd_fb.c
@@ -394,7 +394,8 @@ static int picolcd_set_par(struct fb_info *info)
 		return -EINVAL;
 
 	o_fb   = fbdata->bitmap;
-	tmp_fb = kmalloc(PICOLCDFB_SIZE*info->var.bits_per_pixel, GFP_KERNEL);
+	tmp_fb = kmalloc_array(PICOLCDFB_SIZE, info->var.bits_per_pixel,
+			       GFP_KERNEL);
 	if (!tmp_fb)
 		return -ENOMEM;
 
diff --git a/drivers/hid/hidraw.c b/drivers/hid/hidraw.c
index ac13b216d379..7a38c1e67113 100644
--- a/drivers/hid/hidraw.c
+++ b/drivers/hid/hidraw.c
@@ -218,7 +218,7 @@ static ssize_t hidraw_get_report(struct file *file, char __user *buffer, size_t
 		goto out;
 	}
 
-	buf = kmalloc(count * sizeof(__u8), GFP_KERNEL);
+	buf = kmalloc(count, GFP_KERNEL);
 	if (!buf) {
 		ret = -ENOMEM;
 		goto out;
* Unmerged path drivers/i2c/i2c-dev.c
diff --git a/drivers/ide/ide-probe.c b/drivers/ide/ide-probe.c
index 1235eadbe439..dc9adada8f94 100644
--- a/drivers/ide/ide-probe.c
+++ b/drivers/ide/ide-probe.c
@@ -973,8 +973,9 @@ static int hwif_init(ide_hwif_t *hwif)
 	if (!hwif->sg_max_nents)
 		hwif->sg_max_nents = PRD_ENTRIES;
 
-	hwif->sg_table = kmalloc(sizeof(struct scatterlist)*hwif->sg_max_nents,
-				 GFP_KERNEL);
+	hwif->sg_table = kmalloc_array(hwif->sg_max_nents,
+				       sizeof(struct scatterlist),
+				       GFP_KERNEL);
 	if (!hwif->sg_table) {
 		printk(KERN_ERR "%s: unable to allocate SG table.\n", hwif->name);
 		goto out;
diff --git a/drivers/infiniband/core/cma.c b/drivers/infiniband/core/cma.c
index ba6ba35990d5..b4d0b53b8f9d 100644
--- a/drivers/infiniband/core/cma.c
+++ b/drivers/infiniband/core/cma.c
@@ -1944,8 +1944,8 @@ static struct rdma_id_private *cma_new_conn_id(struct rdma_cm_id *listen_id,
 
 	rt = &id->route;
 	rt->num_paths = ib_event->param.req_rcvd.alternate_path ? 2 : 1;
-	rt->path_rec = kmalloc(sizeof *rt->path_rec * rt->num_paths,
-			       GFP_KERNEL);
+	rt->path_rec = kmalloc_array(rt->num_paths, sizeof(*rt->path_rec),
+				     GFP_KERNEL);
 	if (!rt->path_rec)
 		goto err;
 
diff --git a/drivers/infiniband/core/fmr_pool.c b/drivers/infiniband/core/fmr_pool.c
index 593fc31a7a26..eaf80447b4f7 100644
--- a/drivers/infiniband/core/fmr_pool.c
+++ b/drivers/infiniband/core/fmr_pool.c
@@ -244,8 +244,9 @@ struct ib_fmr_pool *ib_create_fmr_pool(struct ib_pd             *pd,
 
 	if (params->cache) {
 		pool->cache_bucket =
-			kmalloc(IB_FMR_HASH_SIZE * sizeof *pool->cache_bucket,
-				GFP_KERNEL);
+			kmalloc_array(IB_FMR_HASH_SIZE,
+				      sizeof(*pool->cache_bucket),
+				      GFP_KERNEL);
 		if (!pool->cache_bucket) {
 			ret = -ENOMEM;
 			goto out_free_pool;
diff --git a/drivers/infiniband/hw/cxgb4/id_table.c b/drivers/infiniband/hw/cxgb4/id_table.c
index 5c2cfdea06ad..724d23297b35 100644
--- a/drivers/infiniband/hw/cxgb4/id_table.c
+++ b/drivers/infiniband/hw/cxgb4/id_table.c
@@ -92,8 +92,8 @@ int c4iw_id_table_alloc(struct c4iw_id_table *alloc, u32 start, u32 num,
 		alloc->last = 0;
 	alloc->max  = num;
 	spin_lock_init(&alloc->lock);
-	alloc->table = kmalloc(BITS_TO_LONGS(num) * sizeof(long),
-				GFP_KERNEL);
+	alloc->table = kmalloc_array(BITS_TO_LONGS(num), sizeof(long),
+				     GFP_KERNEL);
 	if (!alloc->table)
 		return -ENOMEM;
 
diff --git a/drivers/infiniband/hw/mlx4/main.c b/drivers/infiniband/hw/mlx4/main.c
index 9df056678ceb..35bfa7165e12 100644
--- a/drivers/infiniband/hw/mlx4/main.c
+++ b/drivers/infiniband/hw/mlx4/main.c
@@ -302,7 +302,8 @@ static int mlx4_ib_add_gid(struct ib_device *device,
 		ctx->refcount++;
 	}
 	if (!ret && hw_update) {
-		gids = kmalloc(sizeof(*gids) * MLX4_MAX_PORT_GIDS, GFP_ATOMIC);
+		gids = kmalloc_array(MLX4_MAX_PORT_GIDS, sizeof(*gids),
+				     GFP_ATOMIC);
 		if (!gids) {
 			ret = -ENOMEM;
 		} else {
@@ -357,7 +358,8 @@ static int mlx4_ib_del_gid(struct ib_device *device,
 	if (!ret && hw_update) {
 		int i;
 
-		gids = kmalloc(sizeof(*gids) * MLX4_MAX_PORT_GIDS, GFP_ATOMIC);
+		gids = kmalloc_array(MLX4_MAX_PORT_GIDS, sizeof(*gids),
+				     GFP_ATOMIC);
 		if (!gids) {
 			ret = -ENOMEM;
 		} else {
@@ -2790,9 +2792,9 @@ static void *mlx4_ib_add(struct mlx4_dev *dev)
 			goto err_counter;
 
 		ibdev->ib_uc_qpns_bitmap =
-			kmalloc(BITS_TO_LONGS(ibdev->steer_qpn_count) *
-				sizeof(long),
-				GFP_KERNEL);
+			kmalloc_array(BITS_TO_LONGS(ibdev->steer_qpn_count),
+				      sizeof(long),
+				      GFP_KERNEL);
 		if (!ibdev->ib_uc_qpns_bitmap)
 			goto err_steer_qp_release;
 
diff --git a/drivers/infiniband/hw/mlx4/qp.c b/drivers/infiniband/hw/mlx4/qp.c
index f72593e889b4..2b1cbba2418e 100644
--- a/drivers/infiniband/hw/mlx4/qp.c
+++ b/drivers/infiniband/hw/mlx4/qp.c
@@ -457,8 +457,8 @@ static int alloc_proxy_bufs(struct ib_device *dev, struct mlx4_ib_qp *qp)
 	int i;
 
 	qp->sqp_proxy_rcv =
-		kmalloc(sizeof (struct mlx4_ib_buf) * qp->rq.wqe_cnt,
-			GFP_KERNEL);
+		kmalloc_array(qp->rq.wqe_cnt, sizeof(struct mlx4_ib_buf),
+			      GFP_KERNEL);
 	if (!qp->sqp_proxy_rcv)
 		return -ENOMEM;
 	for (i = 0; i < qp->rq.wqe_cnt; i++) {
diff --git a/drivers/infiniband/hw/mthca/mthca_allocator.c b/drivers/infiniband/hw/mthca/mthca_allocator.c
index b4e0cf4e95cd..aaf10dd5364d 100644
--- a/drivers/infiniband/hw/mthca/mthca_allocator.c
+++ b/drivers/infiniband/hw/mthca/mthca_allocator.c
@@ -90,8 +90,8 @@ int mthca_alloc_init(struct mthca_alloc *alloc, u32 num, u32 mask,
 	alloc->max  = num;
 	alloc->mask = mask;
 	spin_lock_init(&alloc->lock);
-	alloc->table = kmalloc(BITS_TO_LONGS(num) * sizeof (long),
-			       GFP_KERNEL);
+	alloc->table = kmalloc_array(BITS_TO_LONGS(num), sizeof(long),
+				     GFP_KERNEL);
 	if (!alloc->table)
 		return -ENOMEM;
 
@@ -162,7 +162,8 @@ int mthca_array_init(struct mthca_array *array, int nent)
 	int npage = (nent * sizeof (void *) + PAGE_SIZE - 1) / PAGE_SIZE;
 	int i;
 
-	array->page_list = kmalloc(npage * sizeof *array->page_list, GFP_KERNEL);
+	array->page_list = kmalloc_array(npage, sizeof(*array->page_list),
+					 GFP_KERNEL);
 	if (!array->page_list)
 		return -ENOMEM;
 
@@ -220,7 +221,8 @@ int mthca_buf_alloc(struct mthca_dev *dev, int size, int max_direct,
 			npages *= 2;
 		}
 
-		dma_list = kmalloc(npages * sizeof *dma_list, GFP_KERNEL);
+		dma_list = kmalloc_array(npages, sizeof(*dma_list),
+					 GFP_KERNEL);
 		if (!dma_list)
 			goto err_free;
 
@@ -231,12 +233,14 @@ int mthca_buf_alloc(struct mthca_dev *dev, int size, int max_direct,
 		npages     = (size + PAGE_SIZE - 1) / PAGE_SIZE;
 		shift      = PAGE_SHIFT;
 
-		dma_list = kmalloc(npages * sizeof *dma_list, GFP_KERNEL);
+		dma_list = kmalloc_array(npages, sizeof(*dma_list),
+					 GFP_KERNEL);
 		if (!dma_list)
 			return -ENOMEM;
 
-		buf->page_list = kmalloc(npages * sizeof *buf->page_list,
-					 GFP_KERNEL);
+		buf->page_list = kmalloc_array(npages,
+					       sizeof(*buf->page_list),
+					       GFP_KERNEL);
 		if (!buf->page_list)
 			goto err_out;
 
diff --git a/drivers/infiniband/hw/mthca/mthca_cmd.c b/drivers/infiniband/hw/mthca/mthca_cmd.c
index 419a2a20c047..83aa47eb81a9 100644
--- a/drivers/infiniband/hw/mthca/mthca_cmd.c
+++ b/drivers/infiniband/hw/mthca/mthca_cmd.c
@@ -565,9 +565,9 @@ int mthca_cmd_use_events(struct mthca_dev *dev)
 {
 	int i;
 
-	dev->cmd.context = kmalloc(dev->cmd.max_cmds *
-				   sizeof (struct mthca_cmd_context),
-				   GFP_KERNEL);
+	dev->cmd.context = kmalloc_array(dev->cmd.max_cmds,
+					 sizeof(struct mthca_cmd_context),
+					 GFP_KERNEL);
 	if (!dev->cmd.context)
 		return -ENOMEM;
 
diff --git a/drivers/infiniband/hw/mthca/mthca_eq.c b/drivers/infiniband/hw/mthca/mthca_eq.c
index 690201738993..30400ea4808b 100644
--- a/drivers/infiniband/hw/mthca/mthca_eq.c
+++ b/drivers/infiniband/hw/mthca/mthca_eq.c
@@ -479,15 +479,15 @@ static int mthca_create_eq(struct mthca_dev *dev,
 	eq->nent = roundup_pow_of_two(max(nent, 2));
 	npages = ALIGN(eq->nent * MTHCA_EQ_ENTRY_SIZE, PAGE_SIZE) / PAGE_SIZE;
 
-	eq->page_list = kmalloc(npages * sizeof *eq->page_list,
-				GFP_KERNEL);
+	eq->page_list = kmalloc_array(npages, sizeof(*eq->page_list),
+				      GFP_KERNEL);
 	if (!eq->page_list)
 		goto err_out;
 
 	for (i = 0; i < npages; ++i)
 		eq->page_list[i].buf = NULL;
 
-	dma_list = kmalloc(npages * sizeof *dma_list, GFP_KERNEL);
+	dma_list = kmalloc_array(npages, sizeof(*dma_list), GFP_KERNEL);
 	if (!dma_list)
 		goto err_out_free;
 
diff --git a/drivers/infiniband/hw/mthca/mthca_memfree.c b/drivers/infiniband/hw/mthca/mthca_memfree.c
index 2fe503e86c1d..9de4b97b9390 100644
--- a/drivers/infiniband/hw/mthca/mthca_memfree.c
+++ b/drivers/infiniband/hw/mthca/mthca_memfree.c
@@ -712,9 +712,9 @@ int mthca_init_db_tab(struct mthca_dev *dev)
 	dev->db_tab->max_group1 = 0;
 	dev->db_tab->min_group2 = dev->db_tab->npages - 1;
 
-	dev->db_tab->page = kmalloc(dev->db_tab->npages *
-				    sizeof *dev->db_tab->page,
-				    GFP_KERNEL);
+	dev->db_tab->page = kmalloc_array(dev->db_tab->npages,
+					  sizeof(*dev->db_tab->page),
+					  GFP_KERNEL);
 	if (!dev->db_tab->page) {
 		kfree(dev->db_tab);
 		return -ENOMEM;
diff --git a/drivers/infiniband/hw/mthca/mthca_mr.c b/drivers/infiniband/hw/mthca/mthca_mr.c
index ed9a989e501b..dc3c2346045c 100644
--- a/drivers/infiniband/hw/mthca/mthca_mr.c
+++ b/drivers/infiniband/hw/mthca/mthca_mr.c
@@ -153,7 +153,7 @@ static int mthca_buddy_init(struct mthca_buddy *buddy, int max_order)
 
 	for (i = 0; i <= buddy->max_order; ++i) {
 		s = BITS_TO_LONGS(1 << (buddy->max_order - i));
-		buddy->bits[i] = kmalloc(s * sizeof (long), GFP_KERNEL);
+		buddy->bits[i] = kmalloc_array(s, sizeof(long), GFP_KERNEL);
 		if (!buddy->bits[i])
 			goto err_out_free;
 		bitmap_zero(buddy->bits[i],
diff --git a/drivers/infiniband/hw/mthca/mthca_qp.c b/drivers/infiniband/hw/mthca/mthca_qp.c
index d21960cd9a49..af1c49d70b89 100644
--- a/drivers/infiniband/hw/mthca/mthca_qp.c
+++ b/drivers/infiniband/hw/mthca/mthca_qp.c
@@ -1054,8 +1054,8 @@ static int mthca_alloc_wqe_buf(struct mthca_dev *dev,
 	size = PAGE_ALIGN(qp->send_wqe_offset +
 			  (qp->sq.max << qp->sq.wqe_shift));
 
-	qp->wrid = kmalloc((qp->rq.max + qp->sq.max) * sizeof (u64),
-			   GFP_KERNEL);
+	qp->wrid = kmalloc_array(qp->rq.max + qp->sq.max, sizeof(u64),
+				 GFP_KERNEL);
 	if (!qp->wrid)
 		goto err_out;
 
diff --git a/drivers/infiniband/hw/mthca/mthca_srq.c b/drivers/infiniband/hw/mthca/mthca_srq.c
index d22f970480c0..f79732bc73b4 100644
--- a/drivers/infiniband/hw/mthca/mthca_srq.c
+++ b/drivers/infiniband/hw/mthca/mthca_srq.c
@@ -155,7 +155,7 @@ static int mthca_alloc_srq_buf(struct mthca_dev *dev, struct mthca_pd *pd,
 	if (pd->ibpd.uobject)
 		return 0;
 
-	srq->wrid = kmalloc(srq->max * sizeof (u64), GFP_KERNEL);
+	srq->wrid = kmalloc_array(srq->max, sizeof(u64), GFP_KERNEL);
 	if (!srq->wrid)
 		return -ENOMEM;
 
diff --git a/drivers/infiniband/hw/nes/nes_nic.c b/drivers/infiniband/hw/nes/nes_nic.c
index 4bc41e436acd..e038ff7c060a 100644
--- a/drivers/infiniband/hw/nes/nes_nic.c
+++ b/drivers/infiniband/hw/nes/nes_nic.c
@@ -901,7 +901,7 @@ static void nes_netdev_set_multicast_list(struct net_device *netdev)
 		int i;
 		struct netdev_hw_addr *ha;
 
-		addrs = kmalloc(ETH_ALEN * mc_count, GFP_ATOMIC);
+		addrs = kmalloc_array(mc_count, ETH_ALEN, GFP_ATOMIC);
 		if (!addrs) {
 			set_allmulti(nesdev, nic_active_bit);
 			goto unlock;
diff --git a/drivers/infiniband/hw/ocrdma/ocrdma_verbs.c b/drivers/infiniband/hw/ocrdma/ocrdma_verbs.c
index ae3e9b166250..7f19c93daeaf 100644
--- a/drivers/infiniband/hw/ocrdma/ocrdma_verbs.c
+++ b/drivers/infiniband/hw/ocrdma/ocrdma_verbs.c
@@ -1879,7 +1879,8 @@ struct ib_srq *ocrdma_create_srq(struct ib_pd *ibpd,
 		srq->bit_fields_len = (srq->rq.max_cnt / 32) +
 		    (srq->rq.max_cnt % 32 ? 1 : 0);
 		srq->idx_bit_fields =
-		    kmalloc(srq->bit_fields_len * sizeof(u32), GFP_KERNEL);
+		    kmalloc_array(srq->bit_fields_len, sizeof(u32),
+				  GFP_KERNEL);
 		if (srq->idx_bit_fields == NULL)
 			goto arm_err;
 		memset(srq->idx_bit_fields, 0xff,
diff --git a/drivers/infiniband/hw/qib/qib_iba6120.c b/drivers/infiniband/hw/qib/qib_iba6120.c
index 87f85c4c1595..1fea88e36c20 100644
--- a/drivers/infiniband/hw/qib/qib_iba6120.c
+++ b/drivers/infiniband/hw/qib/qib_iba6120.c
@@ -2513,15 +2513,16 @@ static void init_6120_cntrnames(struct qib_devdata *dd)
 		dd->cspec->cntrnamelen = sizeof(cntr6120names) - 1;
 	else
 		dd->cspec->cntrnamelen = 1 + s - cntr6120names;
-	dd->cspec->cntrs = kmalloc(dd->cspec->ncntrs
-		* sizeof(u64), GFP_KERNEL);
+	dd->cspec->cntrs = kmalloc_array(dd->cspec->ncntrs, sizeof(u64),
+					 GFP_KERNEL);
 
 	for (i = 0, s = (char *)portcntr6120names; s; i++)
 		s = strchr(s + 1, '\n');
 	dd->cspec->nportcntrs = i - 1;
 	dd->cspec->portcntrnamelen = sizeof(portcntr6120names) - 1;
-	dd->cspec->portcntrs = kmalloc(dd->cspec->nportcntrs
-		* sizeof(u64), GFP_KERNEL);
+	dd->cspec->portcntrs = kmalloc_array(dd->cspec->nportcntrs,
+					     sizeof(u64),
+					     GFP_KERNEL);
 }
 
 static u32 qib_read_6120cntrs(struct qib_devdata *dd, loff_t pos, char **namep,
diff --git a/drivers/infiniband/hw/qib/qib_iba7220.c b/drivers/infiniband/hw/qib/qib_iba7220.c
index 015350d85804..f57def3d9c14 100644
--- a/drivers/infiniband/hw/qib/qib_iba7220.c
+++ b/drivers/infiniband/hw/qib/qib_iba7220.c
@@ -3162,15 +3162,16 @@ static void init_7220_cntrnames(struct qib_devdata *dd)
 		dd->cspec->cntrnamelen = sizeof(cntr7220names) - 1;
 	else
 		dd->cspec->cntrnamelen = 1 + s - cntr7220names;
-	dd->cspec->cntrs = kmalloc(dd->cspec->ncntrs
-		* sizeof(u64), GFP_KERNEL);
+	dd->cspec->cntrs = kmalloc_array(dd->cspec->ncntrs, sizeof(u64),
+					 GFP_KERNEL);
 
 	for (i = 0, s = (char *)portcntr7220names; s; i++)
 		s = strchr(s + 1, '\n');
 	dd->cspec->nportcntrs = i - 1;
 	dd->cspec->portcntrnamelen = sizeof(portcntr7220names) - 1;
-	dd->cspec->portcntrs = kmalloc(dd->cspec->nportcntrs
-		* sizeof(u64), GFP_KERNEL);
+	dd->cspec->portcntrs = kmalloc_array(dd->cspec->nportcntrs,
+					     sizeof(u64),
+					     GFP_KERNEL);
 }
 
 static u32 qib_read_7220cntrs(struct qib_devdata *dd, loff_t pos, char **namep,
diff --git a/drivers/infiniband/hw/qib/qib_iba7322.c b/drivers/infiniband/hw/qib/qib_iba7322.c
index c2f15de34292..0e92eee7eb90 100644
--- a/drivers/infiniband/hw/qib/qib_iba7322.c
+++ b/drivers/infiniband/hw/qib/qib_iba7322.c
@@ -3674,8 +3674,9 @@ static int qib_do_7322_reset(struct qib_devdata *dd)
 	if (msix_entries) {
 		qib_7322_nomsix(dd);
 		/* can be up to 512 bytes, too big for stack */
-		msix_vecsave = kmalloc(2 * dd->cspec->num_msix_entries *
-			sizeof(u64), GFP_KERNEL);
+		msix_vecsave = kmalloc_array(2 * dd->cspec->num_msix_entries,
+					     sizeof(u64),
+					     GFP_KERNEL);
 	}
 
 	/*
@@ -5035,16 +5036,17 @@ static void init_7322_cntrnames(struct qib_devdata *dd)
 		dd->cspec->cntrnamelen = sizeof(cntr7322names) - 1;
 	else
 		dd->cspec->cntrnamelen = 1 + s - cntr7322names;
-	dd->cspec->cntrs = kmalloc(dd->cspec->ncntrs
-		* sizeof(u64), GFP_KERNEL);
+	dd->cspec->cntrs = kmalloc_array(dd->cspec->ncntrs, sizeof(u64),
+					 GFP_KERNEL);
 
 	for (i = 0, s = (char *)portcntr7322names; s; i++)
 		s = strchr(s + 1, '\n');
 	dd->cspec->nportcntrs = i - 1;
 	dd->cspec->portcntrnamelen = sizeof(portcntr7322names) - 1;
 	for (i = 0; i < dd->num_pports; ++i) {
-		dd->pport[i].cpspec->portcntrs = kmalloc(dd->cspec->nportcntrs
-			* sizeof(u64), GFP_KERNEL);
+		dd->pport[i].cpspec->portcntrs =
+			kmalloc_array(dd->cspec->nportcntrs, sizeof(u64),
+				      GFP_KERNEL);
 	}
 }
 
@@ -6441,12 +6443,15 @@ static int qib_init_7322_variables(struct qib_devdata *dd)
 	sbufcnt = dd->piobcnt2k + dd->piobcnt4k +
 		NUM_VL15_BUFS + BITS_PER_LONG - 1;
 	sbufcnt /= BITS_PER_LONG;
-	dd->cspec->sendchkenable = kmalloc(sbufcnt *
-		sizeof(*dd->cspec->sendchkenable), GFP_KERNEL);
-	dd->cspec->sendgrhchk = kmalloc(sbufcnt *
-		sizeof(*dd->cspec->sendgrhchk), GFP_KERNEL);
-	dd->cspec->sendibchk = kmalloc(sbufcnt *
-		sizeof(*dd->cspec->sendibchk), GFP_KERNEL);
+	dd->cspec->sendchkenable =
+		kmalloc_array(sbufcnt, sizeof(*dd->cspec->sendchkenable),
+			      GFP_KERNEL);
+	dd->cspec->sendgrhchk =
+		kmalloc_array(sbufcnt, sizeof(*dd->cspec->sendgrhchk),
+			      GFP_KERNEL);
+	dd->cspec->sendibchk =
+		kmalloc_array(sbufcnt, sizeof(*dd->cspec->sendibchk),
+			      GFP_KERNEL);
 	if (!dd->cspec->sendchkenable || !dd->cspec->sendgrhchk ||
 		!dd->cspec->sendibchk) {
 		ret = -ENOMEM;
diff --git a/drivers/infiniband/ulp/iser/iser_initiator.c b/drivers/infiniband/ulp/iser/iser_initiator.c
index f79195a88cce..96af06cfe0af 100644
--- a/drivers/infiniband/ulp/iser/iser_initiator.c
+++ b/drivers/infiniband/ulp/iser/iser_initiator.c
@@ -258,8 +258,9 @@ int iser_alloc_rx_descriptors(struct iser_conn *iser_conn,
 		goto alloc_login_buf_fail;
 
 	iser_conn->num_rx_descs = session->cmds_max;
-	iser_conn->rx_descs = kmalloc(iser_conn->num_rx_descs *
-				sizeof(struct iser_rx_desc), GFP_KERNEL);
+	iser_conn->rx_descs = kmalloc_array(iser_conn->num_rx_descs,
+					    sizeof(struct iser_rx_desc),
+					    GFP_KERNEL);
 	if (!iser_conn->rx_descs)
 		goto rx_desc_alloc_fail;
 
diff --git a/drivers/infiniband/ulp/srp/ib_srp.c b/drivers/infiniband/ulp/srp/ib_srp.c
index d15fd3cdddfd..278571d854e2 100644
--- a/drivers/infiniband/ulp/srp/ib_srp.c
+++ b/drivers/infiniband/ulp/srp/ib_srp.c
@@ -1031,16 +1031,17 @@ static int srp_alloc_req_data(struct srp_rdma_ch *ch)
 
 	for (i = 0; i < target->req_ring_size; ++i) {
 		req = &ch->req_ring[i];
-		mr_list = kmalloc(target->mr_per_cmd * sizeof(void *),
-				  GFP_KERNEL);
+		mr_list = kmalloc_array(target->mr_per_cmd, sizeof(void *),
+					GFP_KERNEL);
 		if (!mr_list)
 			goto out;
 		if (srp_dev->use_fast_reg) {
 			req->fr_list = mr_list;
 		} else {
 			req->fmr_list = mr_list;
-			req->map_page = kmalloc(srp_dev->max_pages_per_mr *
-						sizeof(void *), GFP_KERNEL);
+			req->map_page = kmalloc_array(srp_dev->max_pages_per_mr,
+						      sizeof(void *),
+						      GFP_KERNEL);
 			if (!req->map_page)
 				goto out;
 		}
diff --git a/drivers/infiniband/ulp/srpt/ib_srpt.c b/drivers/infiniband/ulp/srpt/ib_srpt.c
index 4b79fbb1ec2b..bb10c5019d2b 100644
--- a/drivers/infiniband/ulp/srpt/ib_srpt.c
+++ b/drivers/infiniband/ulp/srpt/ib_srpt.c
@@ -720,7 +720,7 @@ static struct srpt_ioctx **srpt_alloc_ioctx_ring(struct srpt_device *sdev,
 	WARN_ON(ioctx_size != sizeof(struct srpt_recv_ioctx)
 		&& ioctx_size != sizeof(struct srpt_send_ioctx));
 
-	ring = kmalloc(ring_size * sizeof(ring[0]), GFP_KERNEL);
+	ring = kmalloc_array(ring_size, sizeof(ring[0]), GFP_KERNEL);
 	if (!ring)
 		goto out;
 	for (i = 0; i < ring_size; ++i) {
diff --git a/drivers/input/joystick/joydump.c b/drivers/input/joystick/joydump.c
index 7eb878bab968..3a0949b49d74 100644
--- a/drivers/input/joystick/joydump.c
+++ b/drivers/input/joystick/joydump.c
@@ -81,7 +81,7 @@ static int joydump_connect(struct gameport *gameport, struct gameport_driver *dr
 
 	timeout = gameport_time(gameport, 10000); /* 10 ms */
 
-	buf = kmalloc(BUF_SIZE * sizeof(struct joydump), GFP_KERNEL);
+	buf = kmalloc_array(BUF_SIZE, sizeof(struct joydump), GFP_KERNEL);
 	if (!buf) {
 		printk(KERN_INFO "joydump: no memory for testing\n");
 		goto jd_end;
* Unmerged path drivers/irqchip/irq-gic-v3-its.c
diff --git a/drivers/isdn/capi/capidrv.c b/drivers/isdn/capi/capidrv.c
index cc9f1927a322..ebdef5d7d346 100644
--- a/drivers/isdn/capi/capidrv.c
+++ b/drivers/isdn/capi/capidrv.c
@@ -2057,7 +2057,8 @@ static int capidrv_addcontr(u16 contr, struct capi_profile *profp)
 	strcpy(card->name, id);
 	card->contrnr = contr;
 	card->nbchan = profp->nbchannel;
-	card->bchans = kmalloc(sizeof(capidrv_bchan) * card->nbchan, GFP_ATOMIC);
+	card->bchans = kmalloc_array(card->nbchan, sizeof(capidrv_bchan),
+				     GFP_ATOMIC);
 	if (!card->bchans) {
 		printk(KERN_WARNING
 		       "capidrv: (%s) Could not allocate bchan-structs.\n", id);
* Unmerged path drivers/isdn/gigaset/capi.c
diff --git a/drivers/isdn/gigaset/common.c b/drivers/isdn/gigaset/common.c
index 7c7814497e3e..47894afb563e 100644
--- a/drivers/isdn/gigaset/common.c
+++ b/drivers/isdn/gigaset/common.c
@@ -710,7 +710,7 @@ struct cardstate *gigaset_initcs(struct gigaset_driver *drv, int channels,
 	cs->mode = M_UNKNOWN;
 	cs->mstate = MS_UNINITIALIZED;
 
-	cs->bcs = kmalloc(channels * sizeof(struct bc_state), GFP_KERNEL);
+	cs->bcs = kmalloc_array(channels, sizeof(struct bc_state), GFP_KERNEL);
 	cs->inbuf = kmalloc(sizeof(struct inbuf_t), GFP_KERNEL);
 	if (!cs->bcs || !cs->inbuf) {
 		pr_err("out of memory\n");
@@ -1090,7 +1090,7 @@ struct gigaset_driver *gigaset_initdriver(unsigned minor, unsigned minors,
 	drv->owner = owner;
 	INIT_LIST_HEAD(&drv->list);
 
-	drv->cs = kmalloc(minors * sizeof *drv->cs, GFP_KERNEL);
+	drv->cs = kmalloc_array(minors, sizeof(*drv->cs), GFP_KERNEL);
 	if (!drv->cs)
 		goto error;
 
diff --git a/drivers/isdn/hisax/hfc_2bds0.c b/drivers/isdn/hisax/hfc_2bds0.c
index a756e5cb6871..b645b10f6ef2 100644
--- a/drivers/isdn/hisax/hfc_2bds0.c
+++ b/drivers/isdn/hisax/hfc_2bds0.c
@@ -1024,7 +1024,7 @@ static unsigned int
 	int i;
 	unsigned *send;
 
-	if (!(send = kmalloc(cnt * sizeof(unsigned int), GFP_ATOMIC))) {
+	if (!(send = kmalloc_array(cnt, sizeof(unsigned int), GFP_ATOMIC))) {
 		printk(KERN_WARNING
 		       "HiSax: No memory for hfcd.send\n");
 		return (NULL);
diff --git a/drivers/isdn/hisax/hfc_2bs0.c b/drivers/isdn/hisax/hfc_2bs0.c
index 838531b6a60e..e832e59f3251 100644
--- a/drivers/isdn/hisax/hfc_2bs0.c
+++ b/drivers/isdn/hisax/hfc_2bs0.c
@@ -557,7 +557,8 @@ init_send(struct BCState *bcs)
 {
 	int i;
 
-	if (!(bcs->hw.hfc.send = kmalloc(32 * sizeof(unsigned int), GFP_ATOMIC))) {
+	bcs->hw.hfc.send = kmalloc_array(32, sizeof(unsigned int), GFP_ATOMIC);
+	if (!bcs->hw.hfc.send) {
 		printk(KERN_WARNING
 		       "HiSax: No memory for hfc.send\n");
 		return;
diff --git a/drivers/isdn/hisax/netjet.c b/drivers/isdn/hisax/netjet.c
index b646eed379df..da2e70f6ba4a 100644
--- a/drivers/isdn/hisax/netjet.c
+++ b/drivers/isdn/hisax/netjet.c
@@ -912,8 +912,10 @@ setstack_tiger(struct PStack *st, struct BCState *bcs)
 void
 inittiger(struct IsdnCardState *cs)
 {
-	if (!(cs->bcs[0].hw.tiger.send = kmalloc(NETJET_DMA_TXSIZE * sizeof(unsigned int),
-						 GFP_KERNEL | GFP_DMA))) {
+	cs->bcs[0].hw.tiger.send = kmalloc_array(NETJET_DMA_TXSIZE,
+						 sizeof(unsigned int),
+						 GFP_KERNEL | GFP_DMA);
+	if (!cs->bcs[0].hw.tiger.send) {
 		printk(KERN_WARNING
 		       "HiSax: No memory for tiger.send\n");
 		return;
@@ -933,8 +935,10 @@ inittiger(struct IsdnCardState *cs)
 	     cs->hw.njet.base + NETJET_DMA_READ_IRQ);
 	outl(virt_to_bus(cs->bcs[0].hw.tiger.s_end),
 	     cs->hw.njet.base + NETJET_DMA_READ_END);
-	if (!(cs->bcs[0].hw.tiger.rec = kmalloc(NETJET_DMA_RXSIZE * sizeof(unsigned int),
-						GFP_KERNEL | GFP_DMA))) {
+	cs->bcs[0].hw.tiger.rec = kmalloc_array(NETJET_DMA_RXSIZE,
+						sizeof(unsigned int),
+						GFP_KERNEL | GFP_DMA);
+	if (!cs->bcs[0].hw.tiger.rec) {
 		printk(KERN_WARNING
 		       "HiSax: No memory for tiger.rec\n");
 		return;
diff --git a/drivers/isdn/i4l/isdn_common.c b/drivers/isdn/i4l/isdn_common.c
index 9bb12ba3191f..6d349b85dc44 100644
--- a/drivers/isdn/i4l/isdn_common.c
+++ b/drivers/isdn/i4l/isdn_common.c
@@ -2103,7 +2103,8 @@ isdn_add_channels(isdn_driver_t *d, int drvidx, int n, int adding)
 			skb_queue_purge(&d->rpqueue[j]);
 		kfree(d->rpqueue);
 	}
-	if (!(d->rpqueue = kmalloc(sizeof(struct sk_buff_head) * m, GFP_ATOMIC))) {
+	d->rpqueue = kmalloc_array(m, sizeof(struct sk_buff_head), GFP_ATOMIC);
+	if (!d->rpqueue) {
 		printk(KERN_WARNING "register_isdn: Could not alloc rpqueue\n");
 		if (!adding) {
 			kfree(d->rcvcount);
@@ -2117,7 +2118,8 @@ isdn_add_channels(isdn_driver_t *d, int drvidx, int n, int adding)
 
 	if ((adding) && (d->rcv_waitq))
 		kfree(d->rcv_waitq);
-	d->rcv_waitq = kmalloc(sizeof(wait_queue_head_t) * 2 * m, GFP_ATOMIC);
+	d->rcv_waitq = kmalloc(array3_size(sizeof(wait_queue_head_t), 2, m),
+			       GFP_ATOMIC);
 	if (!d->rcv_waitq) {
 		printk(KERN_WARNING "register_isdn: Could not alloc rcv_waitq\n");
 		if (!adding) {
* Unmerged path drivers/lightnvm/pblk-init.c
* Unmerged path drivers/md/dm-integrity.c
diff --git a/drivers/md/dm-snap.c b/drivers/md/dm-snap.c
index 8d813bf90b47..f6c39eb68831 100644
--- a/drivers/md/dm-snap.c
+++ b/drivers/md/dm-snap.c
@@ -325,8 +325,8 @@ static int init_origin_hash(void)
 {
 	int i;
 
-	_origins = kmalloc(ORIGIN_HASH_SIZE * sizeof(struct list_head),
-			   GFP_KERNEL);
+	_origins = kmalloc_array(ORIGIN_HASH_SIZE, sizeof(struct list_head),
+				 GFP_KERNEL);
 	if (!_origins) {
 		DMERR("unable to allocate memory for _origins");
 		return -ENOMEM;
@@ -334,8 +334,9 @@ static int init_origin_hash(void)
 	for (i = 0; i < ORIGIN_HASH_SIZE; i++)
 		INIT_LIST_HEAD(_origins + i);
 
-	_dm_origins = kmalloc(ORIGIN_HASH_SIZE * sizeof(struct list_head),
-			      GFP_KERNEL);
+	_dm_origins = kmalloc_array(ORIGIN_HASH_SIZE,
+				    sizeof(struct list_head),
+				    GFP_KERNEL);
 	if (!_dm_origins) {
 		DMERR("unable to allocate memory for _dm_origins");
 		kfree(_origins);
diff --git a/drivers/md/dm-stats.c b/drivers/md/dm-stats.c
index 8e767cc587b9..33144fa59c5b 100644
--- a/drivers/md/dm-stats.c
+++ b/drivers/md/dm-stats.c
@@ -914,7 +914,9 @@ static int parse_histogram(const char *h, unsigned *n_histogram_entries,
 		if (*q == ',')
 			(*n_histogram_entries)++;
 
-	*histogram_boundaries = kmalloc(*n_histogram_entries * sizeof(unsigned long long), GFP_KERNEL);
+	*histogram_boundaries = kmalloc_array(*n_histogram_entries,
+					      sizeof(unsigned long long),
+					      GFP_KERNEL);
 	if (!*histogram_boundaries)
 		return -ENOMEM;
 
diff --git a/drivers/md/dm-table.c b/drivers/md/dm-table.c
index f557e445aa5d..aee8fc7b3191 100644
--- a/drivers/md/dm-table.c
+++ b/drivers/md/dm-table.c
@@ -533,7 +533,7 @@ static char **realloc_argv(unsigned *size, char **old_argv)
 		new_size = 8;
 		gfp = GFP_NOIO;
 	}
-	argv = kmalloc(new_size * sizeof(*argv), gfp);
+	argv = kmalloc_array(new_size, sizeof(*argv), gfp);
 	if (argv) {
 		memcpy(argv, old_argv, *size * sizeof(*argv));
 		*size = new_size;
diff --git a/drivers/md/md-bitmap.c b/drivers/md/md-bitmap.c
index f0b5deb43b45..ade37b367032 100644
--- a/drivers/md/md-bitmap.c
+++ b/drivers/md/md-bitmap.c
@@ -721,8 +721,8 @@ static int bitmap_storage_alloc(struct bitmap_storage *store,
 
 	num_pages = DIV_ROUND_UP(bytes, PAGE_SIZE);
 
-	store->filemap = kmalloc(sizeof(struct page *)
-				 * num_pages, GFP_KERNEL);
+	store->filemap = kmalloc_array(num_pages, sizeof(struct page *),
+				       GFP_KERNEL);
 	if (!store->filemap)
 		return -ENOMEM;
 
diff --git a/drivers/md/raid1.c b/drivers/md/raid1.c
index 9643c43d8d42..97da959021b6 100644
--- a/drivers/md/raid1.c
+++ b/drivers/md/raid1.c
@@ -125,8 +125,8 @@ static void * r1buf_pool_alloc(gfp_t gfp_flags, void *data)
 	if (!r1_bio)
 		return NULL;
 
-	rps = kmalloc(sizeof(struct resync_pages) * pi->raid_disks,
-		      gfp_flags);
+	rps = kmalloc_array(pi->raid_disks, sizeof(struct resync_pages),
+			    gfp_flags);
 	if (!rps)
 		goto out_free_r1bio;
 
diff --git a/drivers/md/raid10.c b/drivers/md/raid10.c
index 4fd433755960..ecc9d1cdd94e 100644
--- a/drivers/md/raid10.c
+++ b/drivers/md/raid10.c
@@ -175,7 +175,7 @@ static void * r10buf_pool_alloc(gfp_t gfp_flags, void *data)
 		nalloc_rp = nalloc;
 	else
 		nalloc_rp = nalloc * 2;
-	rps = kmalloc(sizeof(struct resync_pages) * nalloc_rp, gfp_flags);
+	rps = kmalloc_array(nalloc_rp, sizeof(struct resync_pages), gfp_flags);
 	if (!rps)
 		goto out_free_r10bio;
 
diff --git a/drivers/media/pci/bt8xx/bttv-risc.c b/drivers/media/pci/bt8xx/bttv-risc.c
index 82cc47d2e3fa..dbde3fae9292 100644
--- a/drivers/media/pci/bt8xx/bttv-risc.c
+++ b/drivers/media/pci/bt8xx/bttv-risc.c
@@ -255,7 +255,8 @@ bttv_risc_overlay(struct bttv *btv, struct btcx_riscmem *risc,
 	u32 addr;
 
 	/* skip list for window clipping */
-	if (NULL == (skips = kmalloc(sizeof(*skips) * ov->nclips,GFP_KERNEL)))
+	skips = kmalloc_array(ov->nclips, sizeof(*skips),GFP_KERNEL);
+	if (NULL == skips)
 		return -ENOMEM;
 
 	/* estimate risc mem: worst case is (1.5*clip+1) * lines instructions
diff --git a/drivers/media/pci/ivtv/ivtvfb.c b/drivers/media/pci/ivtv/ivtvfb.c
index 9ff1230192e8..6186b691446c 100644
--- a/drivers/media/pci/ivtv/ivtvfb.c
+++ b/drivers/media/pci/ivtv/ivtvfb.c
@@ -1084,7 +1084,7 @@ static int ivtvfb_init_vidmode(struct ivtv *itv)
 
 	/* Allocate the pseudo palette */
 	oi->ivtvfb_info.pseudo_palette =
-		kmalloc(sizeof(u32) * 16, GFP_KERNEL|__GFP_NOWARN);
+		kmalloc_array(16, sizeof(u32), GFP_KERNEL|__GFP_NOWARN);
 
 	if (!oi->ivtvfb_info.pseudo_palette) {
 		IVTVFB_ERR("abort, unable to alloc pseudo palette\n");
diff --git a/drivers/media/pci/zoran/zoran_driver.c b/drivers/media/pci/zoran/zoran_driver.c
index d133c30c3fdc..4a0020b265a5 100644
--- a/drivers/media/pci/zoran/zoran_driver.c
+++ b/drivers/media/pci/zoran/zoran_driver.c
@@ -933,7 +933,7 @@ static int zoran_open(struct file *file)
 	/* used to be BUZ_MAX_WIDTH/HEIGHT, but that gives overflows
 	 * on norm-change! */
 	fh->overlay_mask =
-	    kmalloc(((768 + 31) / 32) * 576 * 4, GFP_KERNEL);
+	    kmalloc(array3_size((768 + 31) / 32, 576, 4), GFP_KERNEL);
 	if (!fh->overlay_mask) {
 		dprintk(1,
 			KERN_ERR
* Unmerged path drivers/media/platform/vivid/vivid-core.c
diff --git a/drivers/media/usb/cpia2/cpia2_usb.c b/drivers/media/usb/cpia2/cpia2_usb.c
index be1719283609..6970e53529fa 100644
--- a/drivers/media/usb/cpia2/cpia2_usb.c
+++ b/drivers/media/usb/cpia2/cpia2_usb.c
@@ -643,7 +643,8 @@ static int submit_urbs(struct camera_data *cam)
 		if (cam->sbuf[i].data)
 			continue;
 		cam->sbuf[i].data =
-		    kmalloc(FRAMES_PER_DESC * FRAME_SIZE_PER_DESC, GFP_KERNEL);
+		    kmalloc_array(FRAME_SIZE_PER_DESC, FRAMES_PER_DESC,
+				  GFP_KERNEL);
 		if (!cam->sbuf[i].data) {
 			while (--i >= 0) {
 				kfree(cam->sbuf[i].data);
* Unmerged path drivers/media/usb/cx231xx/cx231xx-audio.c
diff --git a/drivers/media/usb/gspca/t613.c b/drivers/media/usb/gspca/t613.c
index e2cc4e5a0ccb..9823590587cc 100644
--- a/drivers/media/usb/gspca/t613.c
+++ b/drivers/media/usb/gspca/t613.c
@@ -367,7 +367,7 @@ static void reg_w_ixbuf(struct gspca_dev *gspca_dev,
 	if (len * 2 <= USB_BUF_SZ) {
 		p = tmpbuf = gspca_dev->usb_buf;
 	} else {
-		p = tmpbuf = kmalloc(len * 2, GFP_KERNEL);
+		p = tmpbuf = kmalloc_array(len, 2, GFP_KERNEL);
 		if (!tmpbuf) {
 			pr_err("Out of memory\n");
 			return;
diff --git a/drivers/media/usb/stk1160/stk1160-core.c b/drivers/media/usb/stk1160/stk1160-core.c
index 34a26e0cfe77..c81e1bf1e617 100644
--- a/drivers/media/usb/stk1160/stk1160-core.c
+++ b/drivers/media/usb/stk1160/stk1160-core.c
@@ -281,8 +281,9 @@ static int stk1160_probe(struct usb_interface *interface,
 		return -ENODEV;
 
 	/* Alloc an array for all possible max_pkt_size */
-	alt_max_pkt_size = kmalloc(sizeof(alt_max_pkt_size[0]) *
-			interface->num_altsetting, GFP_KERNEL);
+	alt_max_pkt_size = kmalloc_array(interface->num_altsetting,
+					 sizeof(alt_max_pkt_size[0]),
+					 GFP_KERNEL);
 	if (alt_max_pkt_size == NULL)
 		return -ENOMEM;
 
* Unmerged path drivers/media/usb/tm6000/tm6000-video.c
* Unmerged path drivers/media/usb/usbvision/usbvision-video.c
diff --git a/drivers/media/usb/uvc/uvc_video.c b/drivers/media/usb/uvc/uvc_video.c
index ea917fd6d84e..7d8618f43ec8 100644
--- a/drivers/media/usb/uvc/uvc_video.c
+++ b/drivers/media/usb/uvc/uvc_video.c
@@ -513,8 +513,8 @@ static int uvc_video_clock_init(struct uvc_streaming *stream)
 	spin_lock_init(&clock->lock);
 	clock->size = 32;
 
-	clock->samples = kmalloc(clock->size * sizeof(*clock->samples),
-				 GFP_KERNEL);
+	clock->samples = kmalloc_array(clock->size, sizeof(*clock->samples),
+				       GFP_KERNEL);
 	if (clock->samples == NULL)
 		return -ENOMEM;
 
diff --git a/drivers/media/v4l2-core/videobuf-dma-sg.c b/drivers/media/v4l2-core/videobuf-dma-sg.c
index f18f766aeb59..00a61a8f51a9 100644
--- a/drivers/media/v4l2-core/videobuf-dma-sg.c
+++ b/drivers/media/v4l2-core/videobuf-dma-sg.c
@@ -175,7 +175,8 @@ static int videobuf_dma_init_user_locked(struct videobuf_dmabuf *dma,
 	dma->offset = data & ~PAGE_MASK;
 	dma->size = size;
 	dma->nr_pages = last-first+1;
-	dma->pages = kmalloc(dma->nr_pages * sizeof(struct page *), GFP_KERNEL);
+	dma->pages = kmalloc_array(dma->nr_pages, sizeof(struct page *),
+				   GFP_KERNEL);
 	if (NULL == dma->pages)
 		return -ENOMEM;
 
* Unmerged path drivers/memstick/core/ms_block.c
diff --git a/drivers/message/fusion/mptlan.c b/drivers/message/fusion/mptlan.c
index 6955c9e22d57..0d483e81972a 100644
--- a/drivers/message/fusion/mptlan.c
+++ b/drivers/message/fusion/mptlan.c
@@ -394,7 +394,8 @@ mpt_lan_open(struct net_device *dev)
 				"a moment.\n");
 	}
 
-	priv->mpt_txfidx = kmalloc(priv->tx_max_out * sizeof(int), GFP_KERNEL);
+	priv->mpt_txfidx = kmalloc_array(priv->tx_max_out, sizeof(int),
+					 GFP_KERNEL);
 	if (priv->mpt_txfidx == NULL)
 		goto out;
 	priv->mpt_txfidx_tail = -1;
@@ -408,8 +409,8 @@ mpt_lan_open(struct net_device *dev)
 
 	dlprintk((KERN_INFO MYNAM "@lo: Finished initializing SendCtl\n"));
 
-	priv->mpt_rxfidx = kmalloc(priv->max_buckets_out * sizeof(int),
-				   GFP_KERNEL);
+	priv->mpt_rxfidx = kmalloc_array(priv->max_buckets_out, sizeof(int),
+					 GFP_KERNEL);
 	if (priv->mpt_rxfidx == NULL)
 		goto out_SendCtl;
 	priv->mpt_rxfidx_tail = -1;
* Unmerged path drivers/misc/eeprom/idt_89hpesx.c
diff --git a/drivers/misc/vmw_vmci/vmci_queue_pair.c b/drivers/misc/vmw_vmci/vmci_queue_pair.c
index 907b9e9002bc..3a10ab549e0b 100644
--- a/drivers/misc/vmw_vmci/vmci_queue_pair.c
+++ b/drivers/misc/vmw_vmci/vmci_queue_pair.c
@@ -486,12 +486,14 @@ static int qp_alloc_ppn_set(void *prod_q,
 		return VMCI_ERROR_ALREADY_EXISTS;
 
 	produce_ppns =
-	    kmalloc(num_produce_pages * sizeof(*produce_ppns), GFP_KERNEL);
+	    kmalloc_array(num_produce_pages, sizeof(*produce_ppns),
+			  GFP_KERNEL);
 	if (!produce_ppns)
 		return VMCI_ERROR_NO_MEM;
 
 	consume_ppns =
-	    kmalloc(num_consume_pages * sizeof(*consume_ppns), GFP_KERNEL);
+	    kmalloc_array(num_consume_pages, sizeof(*consume_ppns),
+			  GFP_KERNEL);
 	if (!consume_ppns) {
 		kfree(produce_ppns);
 		return VMCI_ERROR_NO_MEM;
diff --git a/drivers/mtd/chips/cfi_cmdset_0001.c b/drivers/mtd/chips/cfi_cmdset_0001.c
index 77514430f1fe..95a657df97d7 100644
--- a/drivers/mtd/chips/cfi_cmdset_0001.c
+++ b/drivers/mtd/chips/cfi_cmdset_0001.c
@@ -708,7 +708,9 @@ static int cfi_intelext_partition_fixup(struct mtd_info *mtd,
 		newcfi = kmalloc(sizeof(struct cfi_private) + numvirtchips * sizeof(struct flchip), GFP_KERNEL);
 		if (!newcfi)
 			return -ENOMEM;
-		shared = kmalloc(sizeof(struct flchip_shared) * cfi->numchips, GFP_KERNEL);
+		shared = kmalloc_array(cfi->numchips,
+				       sizeof(struct flchip_shared),
+				       GFP_KERNEL);
 		if (!shared) {
 			kfree(newcfi);
 			return -ENOMEM;
* Unmerged path drivers/mtd/chips/cfi_cmdset_0002.c
diff --git a/drivers/mtd/chips/cfi_cmdset_0020.c b/drivers/mtd/chips/cfi_cmdset_0020.c
index 096993f9711e..4f11904c1113 100644
--- a/drivers/mtd/chips/cfi_cmdset_0020.c
+++ b/drivers/mtd/chips/cfi_cmdset_0020.c
@@ -186,8 +186,9 @@ static struct mtd_info *cfi_staa_setup(struct map_info *map)
 	mtd->size = devsize * cfi->numchips;
 
 	mtd->numeraseregions = cfi->cfiq->NumEraseRegions * cfi->numchips;
-	mtd->eraseregions = kmalloc(sizeof(struct mtd_erase_region_info)
-			* mtd->numeraseregions, GFP_KERNEL);
+	mtd->eraseregions = kmalloc_array(mtd->numeraseregions,
+					  sizeof(struct mtd_erase_region_info),
+					  GFP_KERNEL);
 	if (!mtd->eraseregions) {
 		printk(KERN_ERR "Failed to allocate memory for MTD erase region info\n");
 		kfree(cfi->cmdset_priv);
diff --git a/drivers/mtd/ftl.c b/drivers/mtd/ftl.c
index 19d637266fcd..db86655b64d6 100644
--- a/drivers/mtd/ftl.c
+++ b/drivers/mtd/ftl.c
@@ -208,15 +208,16 @@ static int build_maps(partition_t *part)
     /* Set up erase unit maps */
     part->DataUnits = le16_to_cpu(part->header.NumEraseUnits) -
 	part->header.NumTransferUnits;
-    part->EUNInfo = kmalloc(part->DataUnits * sizeof(struct eun_info_t),
-			    GFP_KERNEL);
+    part->EUNInfo = kmalloc_array(part->DataUnits, sizeof(struct eun_info_t),
+                                  GFP_KERNEL);
     if (!part->EUNInfo)
 	    goto out;
     for (i = 0; i < part->DataUnits; i++)
 	part->EUNInfo[i].Offset = 0xffffffff;
     part->XferInfo =
-	kmalloc(part->header.NumTransferUnits * sizeof(struct xfer_info_t),
-		GFP_KERNEL);
+	kmalloc_array(part->header.NumTransferUnits,
+                      sizeof(struct xfer_info_t),
+                      GFP_KERNEL);
     if (!part->XferInfo)
 	    goto out_EUNInfo;
 
@@ -276,8 +277,8 @@ static int build_maps(partition_t *part)
     memset(part->VirtualBlockMap, 0xff, blocks * sizeof(uint32_t));
     part->BlocksPerUnit = (1 << header.EraseUnitSize) >> header.BlockSize;
 
-    part->bam_cache = kmalloc(part->BlocksPerUnit * sizeof(uint32_t),
-			      GFP_KERNEL);
+    part->bam_cache = kmalloc_array(part->BlocksPerUnit, sizeof(uint32_t),
+                                    GFP_KERNEL);
     if (!part->bam_cache)
 	    goto out_VirtualBlockMap;
 
diff --git a/drivers/mtd/inftlmount.c b/drivers/mtd/inftlmount.c
index 4adc0374fb6b..8816c237b352 100644
--- a/drivers/mtd/inftlmount.c
+++ b/drivers/mtd/inftlmount.c
@@ -273,7 +273,8 @@ static int find_boot_record(struct INFTLrecord *inftl)
 		inftl->nb_blocks = ip->lastUnit + 1;
 
 		/* Memory alloc */
-		inftl->PUtable = kmalloc(inftl->nb_blocks * sizeof(u16), GFP_KERNEL);
+		inftl->PUtable = kmalloc_array(inftl->nb_blocks, sizeof(u16),
+					       GFP_KERNEL);
 		if (!inftl->PUtable) {
 			printk(KERN_WARNING "INFTL: allocation of PUtable "
 				"failed (%zd bytes)\n",
@@ -281,7 +282,8 @@ static int find_boot_record(struct INFTLrecord *inftl)
 			return -ENOMEM;
 		}
 
-		inftl->VUtable = kmalloc(inftl->nb_blocks * sizeof(u16), GFP_KERNEL);
+		inftl->VUtable = kmalloc_array(inftl->nb_blocks, sizeof(u16),
+					       GFP_KERNEL);
 		if (!inftl->VUtable) {
 			kfree(inftl->PUtable);
 			printk(KERN_WARNING "INFTL: allocation of VUtable "
diff --git a/drivers/mtd/lpddr/lpddr_cmds.c b/drivers/mtd/lpddr/lpddr_cmds.c
index d3cfe26beeaa..e4f990371324 100644
--- a/drivers/mtd/lpddr/lpddr_cmds.c
+++ b/drivers/mtd/lpddr/lpddr_cmds.c
@@ -80,7 +80,7 @@ struct mtd_info *lpddr_cmdset(struct map_info *map)
 	mtd->erasesize = 1 << lpddr->qinfo->UniformBlockSizeShift;
 	mtd->writesize = 1 << lpddr->qinfo->BufSizeShift;
 
-	shared = kmalloc(sizeof(struct flchip_shared) * lpddr->numchips,
+	shared = kmalloc_array(lpddr->numchips, sizeof(struct flchip_shared),
 						GFP_KERNEL);
 	if (!shared) {
 		kfree(lpddr);
diff --git a/drivers/mtd/maps/vmu-flash.c b/drivers/mtd/maps/vmu-flash.c
index 6b223cfe92b7..c5d4b6589488 100644
--- a/drivers/mtd/maps/vmu-flash.c
+++ b/drivers/mtd/maps/vmu-flash.c
@@ -629,15 +629,15 @@ static int vmu_connect(struct maple_device *mdev)
 	* Not sure there are actually any multi-partition devices in the
 	* real world, but the hardware supports them, so, so will we
 	*/
-	card->parts = kmalloc(sizeof(struct vmupart) * card->partitions,
-		GFP_KERNEL);
+	card->parts = kmalloc_array(card->partitions, sizeof(struct vmupart),
+				    GFP_KERNEL);
 	if (!card->parts) {
 		error = -ENOMEM;
 		goto fail_partitions;
 	}
 
-	card->mtd = kmalloc(sizeof(struct mtd_info) * card->partitions,
-		GFP_KERNEL);
+	card->mtd = kmalloc_array(card->partitions, sizeof(struct mtd_info),
+				  GFP_KERNEL);
 	if (!card->mtd) {
 		error = -ENOMEM;
 		goto fail_mtd_info;
diff --git a/drivers/mtd/mtdconcat.c b/drivers/mtd/mtdconcat.c
index b9000563b9f4..665d89536ff8 100644
--- a/drivers/mtd/mtdconcat.c
+++ b/drivers/mtd/mtdconcat.c
@@ -858,8 +858,9 @@ struct mtd_info *mtd_concat_create(struct mtd_info *subdev[],	/* subdevices to c
 		concat->mtd.erasesize = max_erasesize;
 		concat->mtd.numeraseregions = num_erase_region;
 		concat->mtd.eraseregions = erase_region_p =
-		    kmalloc(num_erase_region *
-			    sizeof (struct mtd_erase_region_info), GFP_KERNEL);
+		    kmalloc_array(num_erase_region,
+				  sizeof(struct mtd_erase_region_info),
+				  GFP_KERNEL);
 		if (!erase_region_p) {
 			kfree(concat);
 			printk
* Unmerged path drivers/mtd/mtdswap.c
diff --git a/drivers/mtd/nand/nand_bch.c b/drivers/mtd/nand/nand_bch.c
index 3803e0bba23b..ab76181dc0ce 100644
--- a/drivers/mtd/nand/nand_bch.c
+++ b/drivers/mtd/nand/nand_bch.c
@@ -198,7 +198,7 @@ nand_bch_init(struct mtd_info *mtd, unsigned int eccsize, unsigned int eccbytes,
 	}
 
 	nbc->eccmask = kmalloc(eccbytes, GFP_KERNEL);
-	nbc->errloc = kmalloc(t*sizeof(*nbc->errloc), GFP_KERNEL);
+	nbc->errloc = kmalloc_array(t, sizeof(*nbc->errloc), GFP_KERNEL);
 	if (!nbc->eccmask || !nbc->errloc)
 		goto fail;
 	/*
diff --git a/drivers/mtd/nftlmount.c b/drivers/mtd/nftlmount.c
index 51b9d6af307f..0544e1d52246 100644
--- a/drivers/mtd/nftlmount.c
+++ b/drivers/mtd/nftlmount.c
@@ -198,13 +198,16 @@ device is already correct.
 		nftl->lastEUN = nftl->nb_blocks - 1;
 
 		/* memory alloc */
-		nftl->EUNtable = kmalloc(nftl->nb_blocks * sizeof(u16), GFP_KERNEL);
+		nftl->EUNtable = kmalloc_array(nftl->nb_blocks, sizeof(u16),
+					       GFP_KERNEL);
 		if (!nftl->EUNtable) {
 			printk(KERN_NOTICE "NFTL: allocation of EUNtable failed\n");
 			return -ENOMEM;
 		}
 
-		nftl->ReplUnitTable = kmalloc(nftl->nb_blocks * sizeof(u16), GFP_KERNEL);
+		nftl->ReplUnitTable = kmalloc_array(nftl->nb_blocks,
+						    sizeof(u16),
+						    GFP_KERNEL);
 		if (!nftl->ReplUnitTable) {
 			kfree(nftl->EUNtable);
 			printk(KERN_NOTICE "NFTL: allocation of ReplUnitTable failed\n");
diff --git a/drivers/mtd/sm_ftl.c b/drivers/mtd/sm_ftl.c
index f9d5615c5727..b87142865683 100644
--- a/drivers/mtd/sm_ftl.c
+++ b/drivers/mtd/sm_ftl.c
@@ -770,7 +770,7 @@ static int sm_init_zone(struct sm_ftl *ftl, int zone_num)
 	dbg("initializing zone %d", zone_num);
 
 	/* Allocate memory for FTL table */
-	zone->lba_to_phys_table = kmalloc(ftl->max_lba * 2, GFP_KERNEL);
+	zone->lba_to_phys_table = kmalloc_array(ftl->max_lba, 2, GFP_KERNEL);
 
 	if (!zone->lba_to_phys_table)
 		return -ENOMEM;
diff --git a/drivers/mtd/ssfdc.c b/drivers/mtd/ssfdc.c
index ab2a52a039c3..0080e59e2b0d 100644
--- a/drivers/mtd/ssfdc.c
+++ b/drivers/mtd/ssfdc.c
@@ -332,8 +332,9 @@ static void ssfdcr_add_mtd(struct mtd_blktrans_ops *tr, struct mtd_info *mtd)
 				(long)ssfdc->sectors;
 
 	/* Allocate logical block map */
-	ssfdc->logic_block_map = kmalloc(sizeof(ssfdc->logic_block_map[0]) *
-					 ssfdc->map_len, GFP_KERNEL);
+	ssfdc->logic_block_map =
+		kmalloc_array(ssfdc->map_len,
+			      sizeof(ssfdc->logic_block_map[0]), GFP_KERNEL);
 	if (!ssfdc->logic_block_map)
 		goto out_err;
 	memset(ssfdc->logic_block_map, 0xff, sizeof(ssfdc->logic_block_map[0]) *
* Unmerged path drivers/mtd/tests/mtd_stresstest.c
diff --git a/drivers/mtd/ubi/eba.c b/drivers/mtd/ubi/eba.c
index 0e11671dadc4..24bba380d059 100644
--- a/drivers/mtd/ubi/eba.c
+++ b/drivers/mtd/ubi/eba.c
@@ -1235,11 +1235,11 @@ int self_check_eba(struct ubi_device *ubi, struct ubi_attach_info *ai_fastmap,
 
 	num_volumes = ubi->vtbl_slots + UBI_INT_VOL_COUNT;
 
-	scan_eba = kmalloc(sizeof(*scan_eba) * num_volumes, GFP_KERNEL);
+	scan_eba = kmalloc_array(num_volumes, sizeof(*scan_eba), GFP_KERNEL);
 	if (!scan_eba)
 		return -ENOMEM;
 
-	fm_eba = kmalloc(sizeof(*fm_eba) * num_volumes, GFP_KERNEL);
+	fm_eba = kmalloc_array(num_volumes, sizeof(*fm_eba), GFP_KERNEL);
 	if (!fm_eba) {
 		kfree(scan_eba);
 		return -ENOMEM;
@@ -1250,15 +1250,17 @@ int self_check_eba(struct ubi_device *ubi, struct ubi_attach_info *ai_fastmap,
 		if (!vol)
 			continue;
 
-		scan_eba[i] = kmalloc(vol->reserved_pebs * sizeof(**scan_eba),
-				      GFP_KERNEL);
+		scan_eba[i] = kmalloc_array(vol->reserved_pebs,
+					    sizeof(**scan_eba),
+					    GFP_KERNEL);
 		if (!scan_eba[i]) {
 			ret = -ENOMEM;
 			goto out_free;
 		}
 
-		fm_eba[i] = kmalloc(vol->reserved_pebs * sizeof(**fm_eba),
-				    GFP_KERNEL);
+		fm_eba[i] = kmalloc_array(vol->reserved_pebs,
+					  sizeof(**fm_eba),
+					  GFP_KERNEL);
 		if (!fm_eba[i]) {
 			ret = -ENOMEM;
 			goto out_free;
diff --git a/drivers/net/ethernet/amd/lance.c b/drivers/net/ethernet/amd/lance.c
index fff89b3cad19..a0f27866d3a3 100644
--- a/drivers/net/ethernet/amd/lance.c
+++ b/drivers/net/ethernet/amd/lance.c
@@ -552,13 +552,13 @@ static int __init lance_probe1(struct net_device *dev, int ioaddr, int irq, int
 	if (lance_debug > 6) printk(" (#0x%05lx)", (unsigned long)lp);
 	dev->ml_priv = lp;
 	lp->name = chipname;
-	lp->rx_buffs = (unsigned long)kmalloc(PKT_BUF_SZ*RX_RING_SIZE,
-						  GFP_DMA | GFP_KERNEL);
+	lp->rx_buffs = (unsigned long)kmalloc_array(RX_RING_SIZE, PKT_BUF_SZ,
+						    GFP_DMA | GFP_KERNEL);
 	if (!lp->rx_buffs)
 		goto out_lp;
 	if (lance_need_isa_bounce_buffers) {
-		lp->tx_bounce_buffs = kmalloc(PKT_BUF_SZ*TX_RING_SIZE,
-						  GFP_DMA | GFP_KERNEL);
+		lp->tx_bounce_buffs = kmalloc_array(TX_RING_SIZE, PKT_BUF_SZ,
+						    GFP_DMA | GFP_KERNEL);
 		if (!lp->tx_bounce_buffs)
 			goto out_rx;
 	} else
diff --git a/drivers/net/ethernet/atheros/atl1c/atl1c_ethtool.c b/drivers/net/ethernet/atheros/atl1c/atl1c_ethtool.c
index 05b280331868..9f6f982f6a16 100644
--- a/drivers/net/ethernet/atheros/atl1c/atl1c_ethtool.c
+++ b/drivers/net/ethernet/atheros/atl1c/atl1c_ethtool.c
@@ -203,8 +203,8 @@ static int atl1c_get_eeprom(struct net_device *netdev,
 	first_dword = eeprom->offset >> 2;
 	last_dword = (eeprom->offset + eeprom->len - 1) >> 2;
 
-	eeprom_buff = kmalloc(sizeof(u32) *
-			(last_dword - first_dword + 1), GFP_KERNEL);
+	eeprom_buff = kmalloc_array(last_dword - first_dword + 1, sizeof(u32),
+				    GFP_KERNEL);
 	if (eeprom_buff == NULL)
 		return -ENOMEM;
 
diff --git a/drivers/net/ethernet/atheros/atl1e/atl1e_ethtool.c b/drivers/net/ethernet/atheros/atl1e/atl1e_ethtool.c
index 473c790d421a..e19188ae5fc2 100644
--- a/drivers/net/ethernet/atheros/atl1e/atl1e_ethtool.c
+++ b/drivers/net/ethernet/atheros/atl1e/atl1e_ethtool.c
@@ -226,8 +226,8 @@ static int atl1e_get_eeprom(struct net_device *netdev,
 	first_dword = eeprom->offset >> 2;
 	last_dword = (eeprom->offset + eeprom->len - 1) >> 2;
 
-	eeprom_buff = kmalloc(sizeof(u32) *
-			(last_dword - first_dword + 1), GFP_KERNEL);
+	eeprom_buff = kmalloc_array(last_dword - first_dword + 1, sizeof(u32),
+				    GFP_KERNEL);
 	if (eeprom_buff == NULL)
 		return -ENOMEM;
 
diff --git a/drivers/net/ethernet/atheros/atlx/atl2.c b/drivers/net/ethernet/atheros/atlx/atl2.c
index 3a17664d4d4e..475813d5385e 100644
--- a/drivers/net/ethernet/atheros/atlx/atl2.c
+++ b/drivers/net/ethernet/atheros/atlx/atl2.c
@@ -1941,8 +1941,8 @@ static int atl2_get_eeprom(struct net_device *netdev,
 	first_dword = eeprom->offset >> 2;
 	last_dword = (eeprom->offset + eeprom->len - 1) >> 2;
 
-	eeprom_buff = kmalloc(sizeof(u32) * (last_dword - first_dword + 1),
-		GFP_KERNEL);
+	eeprom_buff = kmalloc_array(last_dword - first_dword + 1, sizeof(u32),
+				    GFP_KERNEL);
 	if (!eeprom_buff)
 		return -ENOMEM;
 
* Unmerged path drivers/net/ethernet/broadcom/bnx2.c
diff --git a/drivers/net/ethernet/broadcom/bnxt/bnxt_vfr.c b/drivers/net/ethernet/broadcom/bnxt/bnxt_vfr.c
index fcb1cf5f1029..395ae4baef7a 100644
--- a/drivers/net/ethernet/broadcom/bnxt/bnxt_vfr.c
+++ b/drivers/net/ethernet/broadcom/bnxt/bnxt_vfr.c
@@ -443,8 +443,8 @@ static int bnxt_vf_reps_create(struct bnxt *bp)
 		return -ENOMEM;
 
 	/* storage for cfa_code to vf-idx mapping */
-	cfa_code_map = kmalloc(sizeof(*bp->cfa_code_map) * MAX_CFA_CODE,
-			       GFP_KERNEL);
+	cfa_code_map = kmalloc_array(MAX_CFA_CODE, sizeof(*bp->cfa_code_map),
+				     GFP_KERNEL);
 	if (!cfa_code_map) {
 		rc = -ENOMEM;
 		goto err;
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_debugfs.c b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_debugfs.c
index 40d23d65ec14..d391b43bc289 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_debugfs.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_debugfs.c
@@ -873,7 +873,7 @@ static int cctrl_tbl_show(struct seq_file *seq, void *v)
 	u16 (*incr)[NCCTRL_WIN];
 	struct adapter *adap = seq->private;
 
-	incr = kmalloc(sizeof(*incr) * NMTUS, GFP_KERNEL);
+	incr = kmalloc_array(NMTUS, sizeof(*incr), GFP_KERNEL);
 	if (!incr)
 		return -ENOMEM;
 
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
index c1c4e9550a7f..2d67861a7551 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
@@ -713,7 +713,7 @@ int cxgb4_write_rss(const struct port_info *pi, const u16 *queues)
 	const struct sge_eth_rxq *rxq;
 
 	rxq = &adapter->sge.ethrxq[pi->first_qset];
-	rss = kmalloc(pi->rss_size * sizeof(u16), GFP_KERNEL);
+	rss = kmalloc_array(pi->rss_size, sizeof(u16), GFP_KERNEL);
 	if (!rss)
 		return -ENOMEM;
 
@@ -4990,8 +4990,8 @@ static int enable_msix(struct adapter *adap)
 		max_ingq += (MAX_OFLD_QSETS * adap->num_uld);
 	if (is_offload(adap))
 		max_ingq += (MAX_OFLD_QSETS * adap->num_ofld_uld);
-	entries = kmalloc(sizeof(*entries) * (max_ingq + 1),
-			  GFP_KERNEL);
+	entries = kmalloc_array(max_ingq + 1, sizeof(*entries),
+				GFP_KERNEL);
 	if (!entries)
 		return -ENOMEM;
 
diff --git a/drivers/net/ethernet/freescale/ucc_geth.c b/drivers/net/ethernet/freescale/ucc_geth.c
index 388f2e5b6b27..3563a2c97a7f 100644
--- a/drivers/net/ethernet/freescale/ucc_geth.c
+++ b/drivers/net/ethernet/freescale/ucc_geth.c
@@ -2253,9 +2253,9 @@ static int ucc_geth_alloc_tx(struct ucc_geth_private *ugeth)
 	/* Init Tx bds */
 	for (j = 0; j < ug_info->numQueuesTx; j++) {
 		/* Setup the skbuff rings */
-		ugeth->tx_skbuff[j] = kmalloc(sizeof(struct sk_buff *) *
-					      ugeth->ug_info->bdRingLenTx[j],
-					      GFP_KERNEL);
+		ugeth->tx_skbuff[j] =
+			kmalloc_array(ugeth->ug_info->bdRingLenTx[j],
+				      sizeof(struct sk_buff *), GFP_KERNEL);
 
 		if (ugeth->tx_skbuff[j] == NULL) {
 			if (netif_msg_ifup(ugeth))
@@ -2326,9 +2326,9 @@ static int ucc_geth_alloc_rx(struct ucc_geth_private *ugeth)
 	/* Init Rx bds */
 	for (j = 0; j < ug_info->numQueuesRx; j++) {
 		/* Setup the skbuff rings */
-		ugeth->rx_skbuff[j] = kmalloc(sizeof(struct sk_buff *) *
-					      ugeth->ug_info->bdRingLenRx[j],
-					      GFP_KERNEL);
+		ugeth->rx_skbuff[j] =
+			kmalloc_array(ugeth->ug_info->bdRingLenRx[j],
+				      sizeof(struct sk_buff *), GFP_KERNEL);
 
 		if (ugeth->rx_skbuff[j] == NULL) {
 			if (netif_msg_ifup(ugeth))
diff --git a/drivers/net/ethernet/ibm/ibmveth.c b/drivers/net/ethernet/ibm/ibmveth.c
index ed9d000178fe..3f3f36a1448a 100644
--- a/drivers/net/ethernet/ibm/ibmveth.c
+++ b/drivers/net/ethernet/ibm/ibmveth.c
@@ -170,7 +170,7 @@ static int ibmveth_alloc_buffer_pool(struct ibmveth_buff_pool *pool)
 {
 	int i;
 
-	pool->free_map = kmalloc(sizeof(u16) * pool->size, GFP_KERNEL);
+	pool->free_map = kmalloc_array(pool->size, sizeof(u16), GFP_KERNEL);
 
 	if (!pool->free_map)
 		return -1;
diff --git a/drivers/net/ethernet/intel/e1000/e1000_ethtool.c b/drivers/net/ethernet/intel/e1000/e1000_ethtool.c
index cd4d72eaf8a7..442ab8c51d85 100644
--- a/drivers/net/ethernet/intel/e1000/e1000_ethtool.c
+++ b/drivers/net/ethernet/intel/e1000/e1000_ethtool.c
@@ -455,8 +455,8 @@ static int e1000_get_eeprom(struct net_device *netdev,
 	first_word = eeprom->offset >> 1;
 	last_word = (eeprom->offset + eeprom->len - 1) >> 1;
 
-	eeprom_buff = kmalloc(sizeof(u16) *
-			(last_word - first_word + 1), GFP_KERNEL);
+	eeprom_buff = kmalloc_array(last_word - first_word + 1, sizeof(u16),
+				    GFP_KERNEL);
 	if (!eeprom_buff)
 		return -ENOMEM;
 
diff --git a/drivers/net/ethernet/intel/e1000e/ethtool.c b/drivers/net/ethernet/intel/e1000e/ethtool.c
index 064cff70f12a..dba7448fe11a 100644
--- a/drivers/net/ethernet/intel/e1000e/ethtool.c
+++ b/drivers/net/ethernet/intel/e1000e/ethtool.c
@@ -520,8 +520,8 @@ static int e1000_get_eeprom(struct net_device *netdev,
 	first_word = eeprom->offset >> 1;
 	last_word = (eeprom->offset + eeprom->len - 1) >> 1;
 
-	eeprom_buff = kmalloc(sizeof(u16) * (last_word - first_word + 1),
-			      GFP_KERNEL);
+	eeprom_buff = kmalloc_array(last_word - first_word + 1, sizeof(u16),
+				    GFP_KERNEL);
 	if (!eeprom_buff)
 		return -ENOMEM;
 
diff --git a/drivers/net/ethernet/intel/igb/igb_ethtool.c b/drivers/net/ethernet/intel/igb/igb_ethtool.c
index 37583fd057f6..d516ed6f274e 100644
--- a/drivers/net/ethernet/intel/igb/igb_ethtool.c
+++ b/drivers/net/ethernet/intel/igb/igb_ethtool.c
@@ -736,8 +736,8 @@ static int igb_get_eeprom(struct net_device *netdev,
 	first_word = eeprom->offset >> 1;
 	last_word = (eeprom->offset + eeprom->len - 1) >> 1;
 
-	eeprom_buff = kmalloc(sizeof(u16) *
-			(last_word - first_word + 1), GFP_KERNEL);
+	eeprom_buff = kmalloc_array(last_word - first_word + 1, sizeof(u16),
+				    GFP_KERNEL);
 	if (!eeprom_buff)
 		return -ENOMEM;
 
@@ -3245,8 +3245,8 @@ static int igb_get_module_eeprom(struct net_device *netdev,
 	first_word = ee->offset >> 1;
 	last_word = (ee->offset + ee->len - 1) >> 1;
 
-	dataword = kmalloc(sizeof(u16) * (last_word - first_word + 1),
-			   GFP_KERNEL);
+	dataword = kmalloc_array(last_word - first_word + 1, sizeof(u16),
+				 GFP_KERNEL);
 	if (!dataword)
 		return -ENOMEM;
 
diff --git a/drivers/net/ethernet/intel/ixgb/ixgb_ethtool.c b/drivers/net/ethernet/intel/ixgb/ixgb_ethtool.c
index a154ca962e3a..e5ddfb9cbbea 100644
--- a/drivers/net/ethernet/intel/ixgb/ixgb_ethtool.c
+++ b/drivers/net/ethernet/intel/ixgb/ixgb_ethtool.c
@@ -393,8 +393,9 @@ ixgb_get_eeprom(struct net_device *netdev,
 	first_word = eeprom->offset >> 1;
 	last_word = (eeprom->offset + eeprom->len - 1) >> 1;
 
-	eeprom_buff = kmalloc(sizeof(__le16) *
-			(last_word - first_word + 1), GFP_KERNEL);
+	eeprom_buff = kmalloc_array(last_word - first_word + 1,
+				    sizeof(__le16),
+				    GFP_KERNEL);
 	if (!eeprom_buff)
 		return -ENOMEM;
 
diff --git a/drivers/net/ethernet/intel/ixgb/ixgb_main.c b/drivers/net/ethernet/intel/ixgb/ixgb_main.c
index dd42930f2b56..b1b33a5240cc 100644
--- a/drivers/net/ethernet/intel/ixgb/ixgb_main.c
+++ b/drivers/net/ethernet/intel/ixgb/ixgb_main.c
@@ -1123,8 +1123,9 @@ ixgb_set_multi(struct net_device *netdev)
 		rctl |= IXGB_RCTL_MPE;
 		IXGB_WRITE_REG(hw, RCTL, rctl);
 	} else {
-		u8 *mta = kmalloc(IXGB_MAX_NUM_MULTICAST_ADDRESSES *
-			      ETH_ALEN, GFP_ATOMIC);
+		u8 *mta = kmalloc_array(ETH_ALEN,
+				        IXGB_MAX_NUM_MULTICAST_ADDRESSES,
+				        GFP_ATOMIC);
 		u8 *addr;
 		if (!mta)
 			goto alloc_failed;
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_ethtool.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_ethtool.c
index 188dde2ea18f..5d5e7136365d 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_ethtool.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_ethtool.c
@@ -911,7 +911,7 @@ static int ixgbe_get_eeprom(struct net_device *netdev,
 	last_word = (eeprom->offset + eeprom->len - 1) >> 1;
 	eeprom_len = last_word - first_word + 1;
 
-	eeprom_buff = kmalloc(sizeof(u16) * eeprom_len, GFP_KERNEL);
+	eeprom_buff = kmalloc_array(eeprom_len, sizeof(u16), GFP_KERNEL);
 	if (!eeprom_buff)
 		return -ENOMEM;
 
diff --git a/drivers/net/ethernet/mellanox/mlx4/cmd.c b/drivers/net/ethernet/mellanox/mlx4/cmd.c
index 6a9086dc1e92..03375c705df7 100644
--- a/drivers/net/ethernet/mellanox/mlx4/cmd.c
+++ b/drivers/net/ethernet/mellanox/mlx4/cmd.c
@@ -2636,9 +2636,9 @@ int mlx4_cmd_use_events(struct mlx4_dev *dev)
 	int i;
 	int err = 0;
 
-	priv->cmd.context = kmalloc(priv->cmd.max_cmds *
-				   sizeof(struct mlx4_cmd_context),
-				   GFP_KERNEL);
+	priv->cmd.context = kmalloc_array(priv->cmd.max_cmds,
+					  sizeof(struct mlx4_cmd_context),
+					  GFP_KERNEL);
 	if (!priv->cmd.context)
 		return -ENOMEM;
 
diff --git a/drivers/net/ethernet/mellanox/mlx4/eq.c b/drivers/net/ethernet/mellanox/mlx4/eq.c
index 6eb7a9deb09b..08a1fbb3f765 100644
--- a/drivers/net/ethernet/mellanox/mlx4/eq.c
+++ b/drivers/net/ethernet/mellanox/mlx4/eq.c
@@ -1213,8 +1213,9 @@ int mlx4_init_eq_table(struct mlx4_dev *dev)
 	}
 
 	priv->eq_table.irq_names =
-		kmalloc(MLX4_IRQNAME_SIZE * (dev->caps.num_comp_vectors + 1),
-			GFP_KERNEL);
+		kmalloc_array(MLX4_IRQNAME_SIZE,
+			      (dev->caps.num_comp_vectors + 1),
+			      GFP_KERNEL);
 	if (!priv->eq_table.irq_names) {
 		err = -ENOMEM;
 		goto err_out_clr_int;
diff --git a/drivers/net/ethernet/mellanox/mlx4/resource_tracker.c b/drivers/net/ethernet/mellanox/mlx4/resource_tracker.c
index f03745a96d40..6c9f31f2d851 100644
--- a/drivers/net/ethernet/mellanox/mlx4/resource_tracker.c
+++ b/drivers/net/ethernet/mellanox/mlx4/resource_tracker.c
@@ -507,10 +507,12 @@ int mlx4_init_resource_tracker(struct mlx4_dev *dev)
 	for (i = 0; i < MLX4_NUM_OF_RESOURCE_TYPE; i++) {
 		struct resource_allocator *res_alloc =
 			&priv->mfunc.master.res_tracker.res_alloc[i];
-		res_alloc->quota = kmalloc((dev->persist->num_vfs + 1) *
-					   sizeof(int), GFP_KERNEL);
-		res_alloc->guaranteed = kmalloc((dev->persist->num_vfs + 1) *
-						sizeof(int), GFP_KERNEL);
+		res_alloc->quota = kmalloc_array(dev->persist->num_vfs + 1,
+						 sizeof(int),
+						 GFP_KERNEL);
+		res_alloc->guaranteed = kmalloc_array(dev->persist->num_vfs + 1,
+						      sizeof(int),
+						      GFP_KERNEL);
 		if (i == RES_MAC || i == RES_VLAN)
 			res_alloc->allocated = kzalloc(MLX4_MAX_PORTS *
 						       (dev->persist->num_vfs
* Unmerged path drivers/net/ethernet/moxa/moxart_ether.c
diff --git a/drivers/net/ethernet/nvidia/forcedeth.c b/drivers/net/ethernet/nvidia/forcedeth.c
index 587f31dba134..6b052d94a50b 100644
--- a/drivers/net/ethernet/nvidia/forcedeth.c
+++ b/drivers/net/ethernet/nvidia/forcedeth.c
@@ -4596,8 +4596,10 @@ static int nv_set_ringparam(struct net_device *dev, struct ethtool_ringparam* ri
 					    sizeof(struct ring_desc_ex) * (ring->rx_pending + ring->tx_pending),
 					    &ring_addr);
 	}
-	rx_skbuff = kmalloc(sizeof(struct nv_skb_map) * ring->rx_pending, GFP_KERNEL);
-	tx_skbuff = kmalloc(sizeof(struct nv_skb_map) * ring->tx_pending, GFP_KERNEL);
+	rx_skbuff = kmalloc_array(ring->rx_pending, sizeof(struct nv_skb_map),
+				  GFP_KERNEL);
+	tx_skbuff = kmalloc_array(ring->tx_pending, sizeof(struct nv_skb_map),
+				  GFP_KERNEL);
 	if (!rxtx_ring || !rx_skbuff || !tx_skbuff) {
 		/* fall back to old rings */
 		if (!nv_optimized(np)) {
diff --git a/drivers/net/ethernet/oki-semi/pch_gbe/pch_gbe_main.c b/drivers/net/ethernet/oki-semi/pch_gbe/pch_gbe_main.c
index 5a5293af83d7..fa552ee02a99 100644
--- a/drivers/net/ethernet/oki-semi/pch_gbe/pch_gbe_main.c
+++ b/drivers/net/ethernet/oki-semi/pch_gbe/pch_gbe_main.c
@@ -2177,7 +2177,7 @@ static void pch_gbe_set_multi(struct net_device *netdev)
 
 	if (mc_count >= PCH_GBE_MAR_ENTRIES)
 		return;
-	mta_list = kmalloc(mc_count * ETH_ALEN, GFP_ATOMIC);
+	mta_list = kmalloc_array(ETH_ALEN, mc_count, GFP_ATOMIC);
 	if (!mta_list)
 		return;
 
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_mcp.c
diff --git a/drivers/net/ethernet/qlogic/qlge/qlge_main.c b/drivers/net/ethernet/qlogic/qlge/qlge_main.c
index 55efbcdfa7f9..deb891d85cd5 100644
--- a/drivers/net/ethernet/qlogic/qlge/qlge_main.c
+++ b/drivers/net/ethernet/qlogic/qlge/qlge_main.c
@@ -2811,7 +2811,8 @@ static int ql_alloc_tx_resources(struct ql_adapter *qdev,
 		goto pci_alloc_err;
 
 	tx_ring->q =
-	    kmalloc(tx_ring->wq_len * sizeof(struct tx_ring_desc), GFP_KERNEL);
+	    kmalloc_array(tx_ring->wq_len, sizeof(struct tx_ring_desc),
+			  GFP_KERNEL);
 	if (tx_ring->q == NULL)
 		goto err;
 
* Unmerged path drivers/net/gtp.c
diff --git a/drivers/net/hippi/rrunner.c b/drivers/net/hippi/rrunner.c
index 91d46c3c11b0..443325b7c6c6 100644
--- a/drivers/net/hippi/rrunner.c
+++ b/drivers/net/hippi/rrunner.c
@@ -1589,7 +1589,7 @@ static int rr_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
 			return -EPERM;
 		}
 
-		image = kmalloc(EEPROM_WORDS * sizeof(u32), GFP_KERNEL);
+		image = kmalloc_array(EEPROM_WORDS, sizeof(u32), GFP_KERNEL);
 		if (!image)
 			return -ENOMEM;
 
diff --git a/drivers/net/team/team.c b/drivers/net/team/team.c
index 43766247fcd0..8a0e7e63db55 100644
--- a/drivers/net/team/team.c
+++ b/drivers/net/team/team.c
@@ -780,7 +780,8 @@ static int team_queue_override_init(struct team *team)
 
 	if (!queue_cnt)
 		return 0;
-	listarr = kmalloc(sizeof(struct list_head) * queue_cnt, GFP_KERNEL);
+	listarr = kmalloc_array(queue_cnt, sizeof(struct list_head),
+				GFP_KERNEL);
 	if (!listarr)
 		return -ENOMEM;
 	team->qom_lists = listarr;
diff --git a/drivers/net/usb/asix_common.c b/drivers/net/usb/asix_common.c
index ba697b0234da..c1dabcdadbbf 100644
--- a/drivers/net/usb/asix_common.c
+++ b/drivers/net/usb/asix_common.c
@@ -638,8 +638,8 @@ int asix_get_eeprom(struct net_device *net, struct ethtool_eeprom *eeprom,
 	first_word = eeprom->offset >> 1;
 	last_word = (eeprom->offset + eeprom->len - 1) >> 1;
 
-	eeprom_buff = kmalloc(sizeof(u16) * (last_word - first_word + 1),
-			      GFP_KERNEL);
+	eeprom_buff = kmalloc_array(last_word - first_word + 1, sizeof(u16),
+				    GFP_KERNEL);
 	if (!eeprom_buff)
 		return -ENOMEM;
 
@@ -678,8 +678,8 @@ int asix_set_eeprom(struct net_device *net, struct ethtool_eeprom *eeprom,
 	first_word = eeprom->offset >> 1;
 	last_word = (eeprom->offset + eeprom->len - 1) >> 1;
 
-	eeprom_buff = kmalloc(sizeof(u16) * (last_word - first_word + 1),
-			      GFP_KERNEL);
+	eeprom_buff = kmalloc_array(last_word - first_word + 1, sizeof(u16),
+				    GFP_KERNEL);
 	if (!eeprom_buff)
 		return -ENOMEM;
 
diff --git a/drivers/net/usb/ax88179_178a.c b/drivers/net/usb/ax88179_178a.c
index 3239cfa8457b..1b03917558a0 100644
--- a/drivers/net/usb/ax88179_178a.c
+++ b/drivers/net/usb/ax88179_178a.c
@@ -599,8 +599,8 @@ ax88179_get_eeprom(struct net_device *net, struct ethtool_eeprom *eeprom,
 
 	first_word = eeprom->offset >> 1;
 	last_word = (eeprom->offset + eeprom->len - 1) >> 1;
-	eeprom_buff = kmalloc(sizeof(u16) * (last_word - first_word + 1),
-			      GFP_KERNEL);
+	eeprom_buff = kmalloc_array(last_word - first_word + 1, sizeof(u16),
+				    GFP_KERNEL);
 	if (!eeprom_buff)
 		return -ENOMEM;
 
diff --git a/drivers/net/usb/usbnet.c b/drivers/net/usb/usbnet.c
index 764e56e7bfaf..998be0bf4d63 100644
--- a/drivers/net/usb/usbnet.c
+++ b/drivers/net/usb/usbnet.c
@@ -1323,8 +1323,8 @@ static int build_dma_sg(const struct sk_buff *skb, struct urb *urb)
 		return 0;
 
 	/* reserve one for zero packet */
-	urb->sg = kmalloc((num_sgs + 1) * sizeof(struct scatterlist),
-			  GFP_ATOMIC);
+	urb->sg = kmalloc_array(num_sgs + 1, sizeof(struct scatterlist),
+				GFP_ATOMIC);
 	if (!urb->sg)
 		return -ENOMEM;
 
diff --git a/drivers/net/virtio_net.c b/drivers/net/virtio_net.c
index da63bcba4f5b..fd5f40b59535 100644
--- a/drivers/net/virtio_net.c
+++ b/drivers/net/virtio_net.c
@@ -1416,10 +1416,10 @@ static int virtnet_find_vqs(struct virtnet_info *vi)
 	vqs = kzalloc(total_vqs * sizeof(*vqs), GFP_KERNEL);
 	if (!vqs)
 		goto err_vq;
-	callbacks = kmalloc(total_vqs * sizeof(*callbacks), GFP_KERNEL);
+	callbacks = kmalloc_array(total_vqs, sizeof(*callbacks), GFP_KERNEL);
 	if (!callbacks)
 		goto err_callback;
-	names = kmalloc(total_vqs * sizeof(*names), GFP_KERNEL);
+	names = kmalloc_array(total_vqs, sizeof(*names), GFP_KERNEL);
 	if (!names)
 		goto err_names;
 
diff --git a/drivers/net/wireless/airo.c b/drivers/net/wireless/airo.c
index 6d5d976d0f6b..d432dfcfd1c9 100644
--- a/drivers/net/wireless/airo.c
+++ b/drivers/net/wireless/airo.c
@@ -7139,7 +7139,7 @@ static int airo_get_aplist(struct net_device *dev,
 	int i;
 	int loseSync = capable(CAP_NET_ADMIN) ? 1: -1;
 
-	qual = kmalloc(IW_MAX_AP * sizeof(*qual), GFP_KERNEL);
+	qual = kmalloc_array(IW_MAX_AP, sizeof(*qual), GFP_KERNEL);
 	if (!qual)
 		return -ENOMEM;
 
diff --git a/drivers/net/wireless/ath/ath5k/phy.c b/drivers/net/wireless/ath/ath5k/phy.c
index 0fce1c76638e..89fdd74dd302 100644
--- a/drivers/net/wireless/ath/ath5k/phy.c
+++ b/drivers/net/wireless/ath/ath5k/phy.c
@@ -890,7 +890,8 @@ ath5k_hw_rfregs_init(struct ath5k_hw *ah,
 	 * ah->ah_rf_banks based on ah->ah_rf_banks_size
 	 * we set above */
 	if (ah->ah_rf_banks == NULL) {
-		ah->ah_rf_banks = kmalloc(sizeof(u32) * ah->ah_rf_banks_size,
+		ah->ah_rf_banks = kmalloc_array(ah->ah_rf_banks_size,
+								sizeof(u32),
 								GFP_KERNEL);
 		if (ah->ah_rf_banks == NULL) {
 			ATH5K_ERR(ah, "out of memory\n");
diff --git a/drivers/net/wireless/ath/ath9k/ar9003_paprd.c b/drivers/net/wireless/ath/ath9k/ar9003_paprd.c
index 6343cc91953e..34e100940284 100644
--- a/drivers/net/wireless/ath/ath9k/ar9003_paprd.c
+++ b/drivers/net/wireless/ath/ath9k/ar9003_paprd.c
@@ -925,7 +925,7 @@ int ar9003_paprd_create_curve(struct ath_hw *ah,
 
 	memset(caldata->pa_table[chain], 0, sizeof(caldata->pa_table[chain]));
 
-	buf = kmalloc(2 * 48 * sizeof(u32), GFP_KERNEL);
+	buf = kmalloc_array(2 * 48, sizeof(u32), GFP_KERNEL);
 	if (!buf)
 		return -ENOMEM;
 
diff --git a/drivers/net/wireless/ath/ath9k/hw.c b/drivers/net/wireless/ath/ath9k/hw.c
index 8c5c2dd8fa7f..61b0e1091865 100644
--- a/drivers/net/wireless/ath/ath9k/hw.c
+++ b/drivers/net/wireless/ath/ath9k/hw.c
@@ -127,13 +127,13 @@ void ath9k_hw_read_array(struct ath_hw *ah, u32 array[][2], int size)
 	u32 *tmp_reg_list, *tmp_data;
 	int i;
 
-	tmp_reg_list = kmalloc(size * sizeof(u32), GFP_KERNEL);
+	tmp_reg_list = kmalloc_array(size, sizeof(u32), GFP_KERNEL);
 	if (!tmp_reg_list) {
 		dev_err(ah->dev, "%s: tmp_reg_list: alloc filed\n", __func__);
 		return;
 	}
 
-	tmp_data = kmalloc(size * sizeof(u32), GFP_KERNEL);
+	tmp_data = kmalloc_array(size, sizeof(u32), GFP_KERNEL);
 	if (!tmp_data) {
 		dev_err(ah->dev, "%s tmp_data: alloc filed\n", __func__);
 		goto error_tmp_data;
diff --git a/drivers/net/wireless/broadcom/brcm80211/brcmsmac/phy/phy_lcn.c b/drivers/net/wireless/broadcom/brcm80211/brcmsmac/phy/phy_lcn.c
index 93d4cde0eb31..a09f96b43a6b 100644
--- a/drivers/net/wireless/broadcom/brcm80211/brcmsmac/phy/phy_lcn.c
+++ b/drivers/net/wireless/broadcom/brcm80211/brcmsmac/phy/phy_lcn.c
@@ -1387,7 +1387,7 @@ wlc_lcnphy_rx_iq_cal(struct brcms_phy *pi,
 	s16 *ptr;
 	struct brcms_phy_lcnphy *pi_lcn = pi->u.pi_lcnphy;
 
-	ptr = kmalloc(sizeof(s16) * 131, GFP_ATOMIC);
+	ptr = kmalloc_array(131, sizeof(s16), GFP_ATOMIC);
 	if (NULL == ptr)
 		return false;
 	if (module == 2) {
@@ -2670,7 +2670,7 @@ wlc_lcnphy_tx_iqlo_cal(struct brcms_phy *pi,
 	u16 *values_to_save;
 	struct brcms_phy_lcnphy *pi_lcn = pi->u.pi_lcnphy;
 
-	values_to_save = kmalloc(sizeof(u16) * 20, GFP_ATOMIC);
+	values_to_save = kmalloc_array(20, sizeof(u16), GFP_ATOMIC);
 	if (NULL == values_to_save)
 		return;
 
@@ -3683,11 +3683,11 @@ wlc_lcnphy_a1(struct brcms_phy *pi, int cal_type, int num_levels,
 	u16 *phy_c32;
 	phy_c21 = 0;
 	phy_c10 = phy_c13 = phy_c14 = phy_c8 = 0;
-	ptr = kmalloc(sizeof(s16) * 131, GFP_ATOMIC);
+	ptr = kmalloc_array(131, sizeof(s16), GFP_ATOMIC);
 	if (NULL == ptr)
 		return;
 
-	phy_c32 = kmalloc(sizeof(u16) * 20, GFP_ATOMIC);
+	phy_c32 = kmalloc_array(20, sizeof(u16), GFP_ATOMIC);
 	if (NULL == phy_c32) {
 		kfree(ptr);
 		return;
diff --git a/drivers/net/wireless/broadcom/brcm80211/brcmsmac/phy/phy_n.c b/drivers/net/wireless/broadcom/brcm80211/brcmsmac/phy/phy_n.c
index ef685465f80a..1e67875cd07f 100644
--- a/drivers/net/wireless/broadcom/brcm80211/brcmsmac/phy/phy_n.c
+++ b/drivers/net/wireless/broadcom/brcm80211/brcmsmac/phy/phy_n.c
@@ -23116,7 +23116,7 @@ wlc_phy_loadsampletable_nphy(struct brcms_phy *pi, struct cordic_iq *tone_buf,
 	u16 t;
 	u32 *data_buf = NULL;
 
-	data_buf = kmalloc(sizeof(u32) * num_samps, GFP_ATOMIC);
+	data_buf = kmalloc_array(num_samps, sizeof(u32), GFP_ATOMIC);
 	if (data_buf == NULL)
 		return;
 
@@ -23158,7 +23158,8 @@ wlc_phy_gen_load_samples_nphy(struct brcms_phy *pi, u32 f_kHz, u16 max_val,
 		tbl_len = (phy_bw << 1);
 	}
 
-	tone_buf = kmalloc(sizeof(struct cordic_iq) * tbl_len, GFP_ATOMIC);
+	tone_buf = kmalloc_array(tbl_len, sizeof(struct cordic_iq),
+				 GFP_ATOMIC);
 	if (tone_buf == NULL)
 		return 0;
 
diff --git a/drivers/net/wireless/hostap/hostap_info.c b/drivers/net/wireless/hostap/hostap_info.c
index de7c4ffec309..4c5e778444d7 100644
--- a/drivers/net/wireless/hostap/hostap_info.c
+++ b/drivers/net/wireless/hostap/hostap_info.c
@@ -270,8 +270,9 @@ static void prism2_info_scanresults(local_info_t *local, unsigned char *buf,
 	left -= 4;
 
 	new_count = left / sizeof(struct hfa384x_scan_result);
-	results = kmalloc(new_count * sizeof(struct hfa384x_hostscan_result),
-			  GFP_ATOMIC);
+	results = kmalloc_array(new_count,
+				sizeof(struct hfa384x_hostscan_result),
+				GFP_ATOMIC);
 	if (results == NULL)
 		return;
 
diff --git a/drivers/net/wireless/hostap/hostap_ioctl.c b/drivers/net/wireless/hostap/hostap_ioctl.c
index e5090309824e..854e0aa0892e 100644
--- a/drivers/net/wireless/hostap/hostap_ioctl.c
+++ b/drivers/net/wireless/hostap/hostap_ioctl.c
@@ -512,8 +512,8 @@ static int prism2_ioctl_giwaplist(struct net_device *dev,
 		return -EOPNOTSUPP;
 	}
 
-	addr = kmalloc(sizeof(struct sockaddr) * IW_MAX_AP, GFP_KERNEL);
-	qual = kmalloc(sizeof(struct iw_quality) * IW_MAX_AP, GFP_KERNEL);
+	addr = kmalloc_array(IW_MAX_AP, sizeof(struct sockaddr), GFP_KERNEL);
+	qual = kmalloc_array(IW_MAX_AP, sizeof(struct iw_quality), GFP_KERNEL);
 	if (addr == NULL || qual == NULL) {
 		kfree(addr);
 		kfree(qual);
diff --git a/drivers/net/wireless/ipw2x00/ipw2100.c b/drivers/net/wireless/ipw2x00/ipw2100.c
index 13c43abab946..f69426cb48f4 100644
--- a/drivers/net/wireless/ipw2x00/ipw2100.c
+++ b/drivers/net/wireless/ipw2x00/ipw2100.c
@@ -3443,8 +3443,9 @@ static int ipw2100_msg_allocate(struct ipw2100_priv *priv)
 	dma_addr_t p;
 
 	priv->msg_buffers =
-	    kmalloc(IPW_COMMAND_POOL_SIZE * sizeof(struct ipw2100_tx_packet),
-		    GFP_KERNEL);
+	    kmalloc_array(IPW_COMMAND_POOL_SIZE,
+			  sizeof(struct ipw2100_tx_packet),
+			  GFP_KERNEL);
 	if (!priv->msg_buffers)
 		return -ENOMEM;
 
@@ -4594,9 +4595,9 @@ static int ipw2100_rx_allocate(struct ipw2100_priv *priv)
 	/*
 	 * allocate packets
 	 */
-	priv->rx_buffers = kmalloc(RX_QUEUE_LENGTH *
-				   sizeof(struct ipw2100_rx_packet),
-				   GFP_KERNEL);
+	priv->rx_buffers = kmalloc_array(RX_QUEUE_LENGTH,
+					 sizeof(struct ipw2100_rx_packet),
+					 GFP_KERNEL);
 	if (!priv->rx_buffers) {
 		IPW_DEBUG_INFO("can't allocate rx packet buffer table\n");
 
diff --git a/drivers/net/wireless/ipw2x00/ipw2200.c b/drivers/net/wireless/ipw2x00/ipw2200.c
index e0f00c7afc46..f07f8ba6a64a 100644
--- a/drivers/net/wireless/ipw2x00/ipw2200.c
+++ b/drivers/net/wireless/ipw2x00/ipw2200.c
@@ -3217,13 +3217,13 @@ static int ipw_load_firmware(struct ipw_priv *priv, u8 * data, size_t len)
 
 	IPW_DEBUG_TRACE("<< :\n");
 
-	virts = kmalloc(sizeof(void *) * CB_NUMBER_OF_ELEMENTS_SMALL,
-			GFP_KERNEL);
+	virts = kmalloc_array(CB_NUMBER_OF_ELEMENTS_SMALL, sizeof(void *),
+			      GFP_KERNEL);
 	if (!virts)
 		return -ENOMEM;
 
-	phys = kmalloc(sizeof(dma_addr_t) * CB_NUMBER_OF_ELEMENTS_SMALL,
-			GFP_KERNEL);
+	phys = kmalloc_array(CB_NUMBER_OF_ELEMENTS_SMALL, sizeof(dma_addr_t),
+			     GFP_KERNEL);
 	if (!phys) {
 		kfree(virts);
 		return -ENOMEM;
@@ -3792,7 +3792,7 @@ static int ipw_queue_tx_init(struct ipw_priv *priv,
 {
 	struct pci_dev *dev = priv->pci_dev;
 
-	q->txb = kmalloc(sizeof(q->txb[0]) * count, GFP_KERNEL);
+	q->txb = kmalloc_array(count, sizeof(q->txb[0]), GFP_KERNEL);
 	if (!q->txb) {
 		IPW_ERROR("vmalloc for auxiliary BD structures failed\n");
 		return -ENOMEM;
diff --git a/drivers/net/wireless/zd1211rw/zd_mac.c b/drivers/net/wireless/zd1211rw/zd_mac.c
index c6208a7988e4..2f3d5d6c4394 100644
--- a/drivers/net/wireless/zd1211rw/zd_mac.c
+++ b/drivers/net/wireless/zd1211rw/zd_mac.c
@@ -735,7 +735,8 @@ static int zd_mac_config_beacon(struct ieee80211_hw *hw, struct sk_buff *beacon,
 
 	/* Alloc memory for full beacon write at once. */
 	num_cmds = 1 + zd_chip_is_zd1211b(&mac->chip) + full_len;
-	ioreqs = kmalloc(num_cmds * sizeof(struct zd_ioreq32), GFP_KERNEL);
+	ioreqs = kmalloc_array(num_cmds, sizeof(struct zd_ioreq32),
+			       GFP_KERNEL);
 	if (!ioreqs) {
 		r = -ENOMEM;
 		goto out_nofree;
diff --git a/drivers/pcmcia/cistpl.c b/drivers/pcmcia/cistpl.c
index 884a984216fe..3e9294965c61 100644
--- a/drivers/pcmcia/cistpl.c
+++ b/drivers/pcmcia/cistpl.c
@@ -1474,11 +1474,11 @@ static ssize_t pccard_extract_cis(struct pcmcia_socket *s, char *buf,
 	u_char *tuplebuffer;
 	u_char *tempbuffer;
 
-	tuplebuffer = kmalloc(sizeof(u_char) * 256, GFP_KERNEL);
+	tuplebuffer = kmalloc_array(256, sizeof(u_char), GFP_KERNEL);
 	if (!tuplebuffer)
 		return -ENOMEM;
 
-	tempbuffer = kmalloc(sizeof(u_char) * 258, GFP_KERNEL);
+	tempbuffer = kmalloc_array(258, sizeof(u_char), GFP_KERNEL);
 	if (!tempbuffer) {
 		ret = -ENOMEM;
 		goto free_tuple;
* Unmerged path drivers/pinctrl/freescale/pinctrl-imx.c
* Unmerged path drivers/pinctrl/freescale/pinctrl-imx1-core.c
* Unmerged path drivers/pinctrl/sunxi/pinctrl-sunxi.c
diff --git a/drivers/s390/block/dasd_eer.c b/drivers/s390/block/dasd_eer.c
index 21ef63cf0960..0c9dd19940f6 100644
--- a/drivers/s390/block/dasd_eer.c
+++ b/drivers/s390/block/dasd_eer.c
@@ -547,8 +547,8 @@ static int dasd_eer_open(struct inode *inp, struct file *filp)
 		return -EINVAL;
 	}
 	eerb->buffersize = eerb->buffer_page_count * PAGE_SIZE;
-	eerb->buffer = kmalloc(eerb->buffer_page_count * sizeof(char *),
-			       GFP_KERNEL);
+	eerb->buffer = kmalloc_array(eerb->buffer_page_count, sizeof(char *),
+				     GFP_KERNEL);
         if (!eerb->buffer) {
 		kfree(eerb);
                 return -ENOMEM;
diff --git a/drivers/s390/char/tty3270.c b/drivers/s390/char/tty3270.c
index 82344290ced5..44735bce9b35 100644
--- a/drivers/s390/char/tty3270.c
+++ b/drivers/s390/char/tty3270.c
@@ -680,7 +680,8 @@ tty3270_alloc_view(void)
 	if (!tp)
 		goto out_err;
 	tp->freemem_pages =
-		kmalloc(sizeof(void *) * TTY3270_STRING_PAGES, GFP_KERNEL);
+		kmalloc_array(TTY3270_STRING_PAGES, sizeof(void *),
+			      GFP_KERNEL);
 	if (!tp->freemem_pages)
 		goto out_tp;
 	INIT_LIST_HEAD(&tp->freemem);
diff --git a/drivers/s390/crypto/pkey_api.c b/drivers/s390/crypto/pkey_api.c
index dae0c82dffdd..231fab13475b 100644
--- a/drivers/s390/crypto/pkey_api.c
+++ b/drivers/s390/crypto/pkey_api.c
@@ -906,9 +906,9 @@ int pkey_findcard(const struct pkey_seckey *seckey,
 		return -EINVAL;
 
 	/* fetch status of all crypto cards */
-	device_status = kmalloc(MAX_ZDEV_ENTRIES_EXT
-				* sizeof(struct zcrypt_device_status_ext),
-				GFP_KERNEL);
+	device_status = kmalloc_array(MAX_ZDEV_ENTRIES_EXT,
+				      sizeof(struct zcrypt_device_status_ext),
+				      GFP_KERNEL);
 	if (!device_status)
 		return -ENOMEM;
 	zcrypt_device_status_mask_ext(device_status);
diff --git a/drivers/scsi/aacraid/aachba.c b/drivers/scsi/aacraid/aachba.c
index 1d20aad3aa92..a57f3a7d4748 100644
--- a/drivers/scsi/aacraid/aachba.c
+++ b/drivers/scsi/aacraid/aachba.c
@@ -4131,7 +4131,7 @@ static int aac_convert_sgraw2(struct aac_raw_io2 *rio2, int pages, int nseg, int
 	if (aac_convert_sgl == 0)
 		return 0;
 
-	sge = kmalloc(nseg_new * sizeof(struct sge_ieee1212), GFP_ATOMIC);
+	sge = kmalloc_array(nseg_new, sizeof(struct sge_ieee1212), GFP_ATOMIC);
 	if (sge == NULL)
 		return -ENOMEM;
 
* Unmerged path drivers/scsi/aha1542.c
diff --git a/drivers/scsi/aic7xxx/aic79xx_core.c b/drivers/scsi/aic7xxx/aic79xx_core.c
index 0bcacf71aef8..cb430e4114a7 100644
--- a/drivers/scsi/aic7xxx/aic79xx_core.c
+++ b/drivers/scsi/aic7xxx/aic79xx_core.c
@@ -7074,7 +7074,8 @@ ahd_init(struct ahd_softc *ahd)
 	AHD_ASSERT_MODES(ahd, AHD_MODE_SCSI_MSK, AHD_MODE_SCSI_MSK);
 
 	ahd->stack_size = ahd_probe_stack_size(ahd);
-	ahd->saved_stack = kmalloc(ahd->stack_size * sizeof(uint16_t), GFP_ATOMIC);
+	ahd->saved_stack = kmalloc_array(ahd->stack_size, sizeof(uint16_t),
+					 GFP_ATOMIC);
 	if (ahd->saved_stack == NULL)
 		return (ENOMEM);
 
diff --git a/drivers/scsi/aic94xx/aic94xx_hwi.c b/drivers/scsi/aic94xx/aic94xx_hwi.c
index 9f636a34d595..0493cc15028f 100644
--- a/drivers/scsi/aic94xx/aic94xx_hwi.c
+++ b/drivers/scsi/aic94xx/aic94xx_hwi.c
@@ -288,7 +288,8 @@ static int asd_alloc_edbs(struct asd_ha_struct *asd_ha, gfp_t gfp_flags)
 	struct asd_seq_data *seq = &asd_ha->seq;
 	int i;
 
-	seq->edb_arr = kmalloc(seq->num_edbs*sizeof(*seq->edb_arr), gfp_flags);
+	seq->edb_arr = kmalloc_array(seq->num_edbs, sizeof(*seq->edb_arr),
+				     gfp_flags);
 	if (!seq->edb_arr)
 		return -ENOMEM;
 
@@ -320,8 +321,8 @@ static int asd_alloc_escbs(struct asd_ha_struct *asd_ha,
 	struct asd_ascb *escb;
 	int i, escbs;
 
-	seq->escb_arr = kmalloc(seq->num_escbs*sizeof(*seq->escb_arr),
-				gfp_flags);
+	seq->escb_arr = kmalloc_array(seq->num_escbs, sizeof(*seq->escb_arr),
+				      gfp_flags);
 	if (!seq->escb_arr)
 		return -ENOMEM;
 
diff --git a/drivers/scsi/arm/queue.c b/drivers/scsi/arm/queue.c
index cb11ccef54e5..9dfc0228cc5f 100644
--- a/drivers/scsi/arm/queue.c
+++ b/drivers/scsi/arm/queue.c
@@ -70,7 +70,7 @@ int queue_initialise (Queue_t *queue)
 	 * need to keep free lists or allocate this
 	 * memory.
 	 */
-	queue->alloc = q = kmalloc(sizeof(QE_t) * nqueues, GFP_KERNEL);
+	queue->alloc = q = kmalloc_array(nqueues, sizeof(QE_t), GFP_KERNEL);
 	if (q) {
 		for (; nqueues; q++, nqueues--) {
 			SET_MAGIC(q, QUEUE_MAGIC_FREE);
diff --git a/drivers/scsi/be2iscsi/be_main.c b/drivers/scsi/be2iscsi/be_main.c
index 8451c95ff857..c75319c9705a 100644
--- a/drivers/scsi/be2iscsi/be_main.c
+++ b/drivers/scsi/be2iscsi/be_main.c
@@ -2484,8 +2484,9 @@ static int beiscsi_alloc_mem(struct beiscsi_hba *phba)
 		return -ENOMEM;
 	}
 
-	mem_arr_orig = kmalloc(sizeof(*mem_arr_orig) * BEISCSI_MAX_FRAGS_INIT,
-			       GFP_KERNEL);
+	mem_arr_orig = kmalloc_array(BEISCSI_MAX_FRAGS_INIT,
+				     sizeof(*mem_arr_orig),
+				     GFP_KERNEL);
 	if (!mem_arr_orig) {
 		kfree(phba->init_mem);
 		kfree(phwi_ctrlr->wrb_context);
@@ -2534,8 +2535,8 @@ static int beiscsi_alloc_mem(struct beiscsi_hba *phba)
 		} while (alloc_size);
 		mem_descr->num_elements = j;
 		mem_descr->size_in_bytes = phba->mem_req[i];
-		mem_descr->mem_array = kmalloc(sizeof(*mem_arr) * j,
-					       GFP_KERNEL);
+		mem_descr->mem_array = kmalloc_array(j, sizeof(*mem_arr),
+						     GFP_KERNEL);
 		if (!mem_descr->mem_array)
 			goto free_mem;
 
@@ -3355,8 +3356,9 @@ beiscsi_create_wrb_rings(struct beiscsi_hba *phba,
 	idx = 0;
 	mem_descr = phba->init_mem;
 	mem_descr += HWI_MEM_WRB;
-	pwrb_arr = kmalloc(sizeof(*pwrb_arr) * phba->params.cxns_per_ctrl,
-			   GFP_KERNEL);
+	pwrb_arr = kmalloc_array(phba->params.cxns_per_ctrl,
+				 sizeof(*pwrb_arr),
+				 GFP_KERNEL);
 	if (!pwrb_arr) {
 		beiscsi_log(phba, KERN_ERR, BEISCSI_LOG_INIT,
 			    "BM_%d : Memory alloc failed in create wrb ring.\n");
diff --git a/drivers/scsi/fcoe/fcoe_ctlr.c b/drivers/scsi/fcoe/fcoe_ctlr.c
index 4979cc1b0585..465663489f4b 100644
--- a/drivers/scsi/fcoe/fcoe_ctlr.c
+++ b/drivers/scsi/fcoe/fcoe_ctlr.c
@@ -1357,8 +1357,8 @@ static void fcoe_ctlr_recv_clr_vlink(struct fcoe_ctlr *fip,
 	 */
 	num_vlink_desc = rlen / sizeof(*vp);
 	if (num_vlink_desc)
-		vlink_desc_arr = kmalloc(sizeof(vp) * num_vlink_desc,
-					 GFP_ATOMIC);
+		vlink_desc_arr = kmalloc_array(num_vlink_desc, sizeof(vp),
+					       GFP_ATOMIC);
 	if (!vlink_desc_arr)
 		return;
 	num_vlink_desc = 0;
diff --git a/drivers/scsi/hpsa.c b/drivers/scsi/hpsa.c
index 76507e2c820f..a93a300fe2af 100644
--- a/drivers/scsi/hpsa.c
+++ b/drivers/scsi/hpsa.c
@@ -2146,8 +2146,9 @@ static int hpsa_allocate_ioaccel2_sg_chain_blocks(struct ctlr_info *h)
 		return -ENOMEM;
 	for (i = 0; i < h->nr_cmds; i++) {
 		h->ioaccel2_cmd_sg_list[i] =
-			kmalloc(sizeof(*h->ioaccel2_cmd_sg_list[i]) *
-					h->maxsgentries, GFP_KERNEL);
+			kmalloc_array(h->maxsgentries,
+				      sizeof(*h->ioaccel2_cmd_sg_list[i]),
+				      GFP_KERNEL);
 		if (!h->ioaccel2_cmd_sg_list[i])
 			goto clean;
 	}
@@ -2185,8 +2186,9 @@ static int hpsa_alloc_sg_chain_blocks(struct ctlr_info *h)
 		return -ENOMEM;
 
 	for (i = 0; i < h->nr_cmds; i++) {
-		h->cmd_sg_list[i] = kmalloc(sizeof(*h->cmd_sg_list[i]) *
-						h->chainsize, GFP_KERNEL);
+		h->cmd_sg_list[i] = kmalloc_array(h->chainsize,
+						  sizeof(*h->cmd_sg_list[i]),
+						  GFP_KERNEL);
 		if (!h->cmd_sg_list[i])
 			goto clean;
 
@@ -6385,7 +6387,7 @@ static int hpsa_big_passthru_ioctl(struct ctlr_info *h, void __user *argp)
 		status = -ENOMEM;
 		goto cleanup1;
 	}
-	buff_size = kmalloc(SG_ENTRIES_IN_CMD * sizeof(int), GFP_KERNEL);
+	buff_size = kmalloc_array(SG_ENTRIES_IN_CMD, sizeof(int), GFP_KERNEL);
 	if (!buff_size) {
 		status = -ENOMEM;
 		goto cleanup1;
@@ -7130,7 +7132,7 @@ static int controller_reset_failed(struct CfgTable __iomem *cfgtable)
 	char *driver_ver, *old_driver_ver;
 	int rc, size = sizeof(cfgtable->driver_version);
 
-	old_driver_ver = kmalloc(2 * size, GFP_KERNEL);
+	old_driver_ver = kmalloc_array(2, size, GFP_KERNEL);
 	if (!old_driver_ver)
 		return -ENOMEM;
 	driver_ver = old_driver_ver + size;
diff --git a/drivers/scsi/lpfc/lpfc_mem.c b/drivers/scsi/lpfc/lpfc_mem.c
index a4ec40659340..66191fa35f63 100644
--- a/drivers/scsi/lpfc/lpfc_mem.c
+++ b/drivers/scsi/lpfc/lpfc_mem.c
@@ -120,8 +120,9 @@ lpfc_mem_alloc(struct lpfc_hba *phba, int align)
 	if (!phba->lpfc_mbuf_pool)
 		goto fail_free_dma_buf_pool;
 
-	pool->elements = kmalloc(sizeof(struct lpfc_dmabuf) *
-					 LPFC_MBUF_POOL_SIZE, GFP_KERNEL);
+	pool->elements = kmalloc_array(LPFC_MBUF_POOL_SIZE,
+				       sizeof(struct lpfc_dmabuf),
+				       GFP_KERNEL);
 	if (!pool->elements)
 		goto fail_free_lpfc_mbuf_pool;
 
diff --git a/drivers/scsi/mac53c94.c b/drivers/scsi/mac53c94.c
index a4056252ede9..1476a4a61c0c 100644
--- a/drivers/scsi/mac53c94.c
+++ b/drivers/scsi/mac53c94.c
@@ -466,8 +466,9 @@ static int mac53c94_probe(struct macio_dev *mdev, const struct of_device_id *mat
        	 * +1 to allow for aligning.
 	 * XXX FIXME: Use DMA consistent routines
 	 */
-       	dma_cmd_space = kmalloc((host->sg_tablesize + 2) *
-       				sizeof(struct dbdma_cmd), GFP_KERNEL);
+       	dma_cmd_space = kmalloc_array(host->sg_tablesize + 2,
+					     sizeof(struct dbdma_cmd),
+					     GFP_KERNEL);
        	if (dma_cmd_space == 0) {
        		printk(KERN_ERR "mac53c94: couldn't allocate dma "
        		       "command space for %s\n", node->full_name);
diff --git a/drivers/scsi/megaraid.c b/drivers/scsi/megaraid.c
index 30d474cfbc55..faacbde10e03 100644
--- a/drivers/scsi/megaraid.c
+++ b/drivers/scsi/megaraid.c
@@ -4329,7 +4329,8 @@ megaraid_probe_one(struct pci_dev *pdev, const struct pci_device_id *id)
 		goto out_host_put;
 	}
 
-	adapter->scb_list = kmalloc(sizeof(scb_t) * MAX_COMMANDS, GFP_KERNEL);
+	adapter->scb_list = kmalloc_array(MAX_COMMANDS, sizeof(scb_t),
+					  GFP_KERNEL);
 	if (!adapter->scb_list) {
 		printk(KERN_WARNING "megaraid: out of RAM.\n");
 		goto out_free_cmd_buffer;
* Unmerged path drivers/scsi/megaraid/megaraid_mm.c
diff --git a/drivers/scsi/osst.c b/drivers/scsi/osst.c
index 5da60596e5e0..2953e267c927 100644
--- a/drivers/scsi/osst.c
+++ b/drivers/scsi/osst.c
@@ -5855,7 +5855,9 @@ static int osst_probe(struct device *dev)
 	/* if this is the first attach, build the infrastructure */
 	write_lock(&os_scsi_tapes_lock);
 	if (os_scsi_tapes == NULL) {
-		os_scsi_tapes = kmalloc(osst_max_dev * sizeof(struct osst_tape *), GFP_ATOMIC);
+		os_scsi_tapes = kmalloc_array(osst_max_dev,
+                                              sizeof(struct osst_tape *),
+                                              GFP_ATOMIC);
 		if (os_scsi_tapes == NULL) {
 			write_unlock(&os_scsi_tapes_lock);
 			printk(KERN_ERR "osst :E: Unable to allocate array for OnStream SCSI tapes.\n");
diff --git a/drivers/scsi/qla2xxx/qla_nx.c b/drivers/scsi/qla2xxx/qla_nx.c
index 868bfb56d972..be192a8009ee 100644
--- a/drivers/scsi/qla2xxx/qla_nx.c
+++ b/drivers/scsi/qla2xxx/qla_nx.c
@@ -1225,7 +1225,7 @@ qla82xx_pinit_from_rom(scsi_qla_host_t *vha)
 	ql_log(ql_log_info, vha, 0x0072,
 	    "%d CRB init values found in ROM.\n", n);
 
-	buf = kmalloc(n * sizeof(struct crb_addr_pair), GFP_KERNEL);
+	buf = kmalloc_array(n, sizeof(struct crb_addr_pair), GFP_KERNEL);
 	if (buf == NULL) {
 		ql_log(ql_log_fatal, vha, 0x010c,
 		    "Unable to allocate memory.\n");
diff --git a/drivers/scsi/qla4xxx/ql4_nx.c b/drivers/scsi/qla4xxx/ql4_nx.c
index 9dbdb4be2d8f..f887b08e4adb 100644
--- a/drivers/scsi/qla4xxx/ql4_nx.c
+++ b/drivers/scsi/qla4xxx/ql4_nx.c
@@ -1075,7 +1075,7 @@ qla4_82xx_pinit_from_rom(struct scsi_qla_host *ha, int verbose)
 	ql4_printk(KERN_INFO, ha,
 		"%s: %d CRB init values found in ROM.\n", DRIVER_NAME, n);
 
-	buf = kmalloc(n * sizeof(struct crb_addr_pair), GFP_KERNEL);
+	buf = kmalloc_array(n, sizeof(struct crb_addr_pair), GFP_KERNEL);
 	if (buf == NULL) {
 		ql4_printk(KERN_WARNING, ha,
 		    "%s: [ERROR] Unable to malloc memory.\n", DRIVER_NAME);
diff --git a/drivers/scsi/smartpqi/smartpqi_init.c b/drivers/scsi/smartpqi/smartpqi_init.c
index f7fe8546866d..fe27d2b6d375 100644
--- a/drivers/scsi/smartpqi/smartpqi_init.c
+++ b/drivers/scsi/smartpqi/smartpqi_init.c
@@ -2037,8 +2037,9 @@ static int pqi_update_scsi_devices(struct pqi_ctrl_info *ctrl_info)
 
 	num_new_devices = num_physicals + num_logicals;
 
-	new_device_list = kmalloc(sizeof(*new_device_list) *
-		num_new_devices, GFP_KERNEL);
+	new_device_list = kmalloc_array(num_new_devices,
+					sizeof(*new_device_list),
+					GFP_KERNEL);
 	if (!new_device_list) {
 		dev_warn(&ctrl_info->pci_dev->dev, "%s\n", out_of_memory_msg);
 		rc = -ENOMEM;
diff --git a/drivers/scsi/st.c b/drivers/scsi/st.c
index 93b0cd27c3c8..7ca88e791f4b 100644
--- a/drivers/scsi/st.c
+++ b/drivers/scsi/st.c
@@ -4882,7 +4882,8 @@ static int sgl_map_user_pages(struct st_buffer *STbp,
 	if (count == 0)
 		return 0;
 
-	if ((pages = kmalloc(max_pages * sizeof(*pages), GFP_KERNEL)) == NULL)
+	pages = kmalloc_array(max_pages, sizeof(*pages), GFP_KERNEL);
+	if (pages == NULL)
 		return -ENOMEM;
 
         /* Try to fault in all of the necessary pages */
diff --git a/drivers/scsi/virtio_scsi.c b/drivers/scsi/virtio_scsi.c
index 3143e3e78035..24a0013c9aaf 100644
--- a/drivers/scsi/virtio_scsi.c
+++ b/drivers/scsi/virtio_scsi.c
@@ -890,9 +890,10 @@ static int virtscsi_init(struct virtio_device *vdev,
 	struct virtqueue **vqs;
 
 	num_vqs = vscsi->num_queues + VIRTIO_SCSI_VQ_BASE;
-	vqs = kmalloc(num_vqs * sizeof(struct virtqueue *), GFP_KERNEL);
-	callbacks = kmalloc(num_vqs * sizeof(vq_callback_t *), GFP_KERNEL);
-	names = kmalloc(num_vqs * sizeof(char *), GFP_KERNEL);
+	vqs = kmalloc_array(num_vqs, sizeof(struct virtqueue *), GFP_KERNEL);
+	callbacks = kmalloc_array(num_vqs, sizeof(vq_callback_t *),
+				  GFP_KERNEL);
+	names = kmalloc_array(num_vqs, sizeof(char *), GFP_KERNEL);
 
 	if (!callbacks || !vqs || !names) {
 		err = -ENOMEM;
* Unmerged path drivers/soc/fsl/qbman/qman.c
diff --git a/drivers/staging/media/go7007/go7007-usb.c b/drivers/staging/media/go7007/go7007-usb.c
index 50066e01a6ed..74e8fce363bf 100644
--- a/drivers/staging/media/go7007/go7007-usb.c
+++ b/drivers/staging/media/go7007/go7007-usb.c
@@ -1168,7 +1168,8 @@ static int go7007_usb_probe(struct usb_interface *intf,
 	usb->intr_urb = usb_alloc_urb(0, GFP_KERNEL);
 	if (usb->intr_urb == NULL)
 		goto allocfail;
-	usb->intr_urb->transfer_buffer = kmalloc(2*sizeof(u16), GFP_KERNEL);
+	usb->intr_urb->transfer_buffer = kmalloc_array(2, sizeof(u16),
+						       GFP_KERNEL);
 	if (usb->intr_urb->transfer_buffer == NULL)
 		goto allocfail;
 
* Unmerged path drivers/staging/rtl8192u/ieee80211/ieee80211_rx.c
* Unmerged path drivers/staging/rtl8192u/r8192U_core.c
diff --git a/drivers/tty/hvc/hvcs.c b/drivers/tty/hvc/hvcs.c
index 950f5744cf2d..0aec28cba3b3 100644
--- a/drivers/tty/hvc/hvcs.c
+++ b/drivers/tty/hvc/hvcs.c
@@ -1456,7 +1456,8 @@ static int hvcs_alloc_index_list(int n)
 {
 	int i;
 
-	hvcs_index_list = kmalloc(n * sizeof(hvcs_index_count),GFP_KERNEL);
+	hvcs_index_list = kmalloc_array(n, sizeof(hvcs_index_count),
+					GFP_KERNEL);
 	if (!hvcs_index_list)
 		return -ENOMEM;
 	hvcs_index_count = n;
diff --git a/drivers/tty/isicom.c b/drivers/tty/isicom.c
index 858291ca889c..7194c19e457e 100644
--- a/drivers/tty/isicom.c
+++ b/drivers/tty/isicom.c
@@ -1491,7 +1491,7 @@ static int load_firmware(struct pci_dev *pdev,
 			goto errrelfw;
 		}
 
-		data = kmalloc(word_count * 2, GFP_KERNEL);
+		data = kmalloc_array(word_count, 2, GFP_KERNEL);
 		if (data == NULL) {
 			dev_err(&pdev->dev, "Card%d, firmware upload "
 				"failed, not enough memory\n", index + 1);
diff --git a/drivers/tty/serial/atmel_serial.c b/drivers/tty/serial/atmel_serial.c
index 3467462869ce..401a62bc1e77 100644
--- a/drivers/tty/serial/atmel_serial.c
+++ b/drivers/tty/serial/atmel_serial.c
@@ -1796,8 +1796,9 @@ static int atmel_serial_probe(struct platform_device *pdev)
 
 	if (!atmel_use_dma_rx(&port->uart)) {
 		ret = -ENOMEM;
-		data = kmalloc(sizeof(struct atmel_uart_char)
-				* ATMEL_SERIAL_RINGSIZE, GFP_KERNEL);
+		data = kmalloc_array(ATMEL_SERIAL_RINGSIZE,
+				     sizeof(struct atmel_uart_char),
+				     GFP_KERNEL);
 		if (!data)
 			goto err_alloc_ring;
 		port->rx_ring.buf = data;
* Unmerged path drivers/tty/vt/consolemap.c
* Unmerged path drivers/tty/vt/keyboard.c
diff --git a/drivers/tty/vt/selection.c b/drivers/tty/vt/selection.c
index d158346bb561..8ad2aa87a53b 100644
--- a/drivers/tty/vt/selection.c
+++ b/drivers/tty/vt/selection.c
@@ -294,7 +294,8 @@ int set_selection(const struct tiocl_selection __user *sel, struct tty_struct *t
 
 	/* Allocate a new buffer before freeing the old one ... */
 	multiplier = use_unicode ? 3 : 1;  /* chars can take up to 3 bytes */
-	bp = kmalloc(((sel_end-sel_start)/2+1)*multiplier, GFP_KERNEL);
+	bp = kmalloc_array((sel_end - sel_start) / 2 + 1, multiplier,
+			   GFP_KERNEL);
 	if (!bp) {
 		printk(KERN_WARNING "selection: kmalloc() failed\n");
 		clear_selection();
diff --git a/drivers/usb/core/devio.c b/drivers/usb/core/devio.c
index 88229ff0e2b4..23a01a882eef 100644
--- a/drivers/usb/core/devio.c
+++ b/drivers/usb/core/devio.c
@@ -900,7 +900,7 @@ static int parse_usbdevfs_streams(struct usb_dev_state *ps,
 	if (num_streams_ret && (num_streams < 2 || num_streams > 65536))
 		return -EINVAL;
 
-	eps = kmalloc(num_eps * sizeof(*eps), GFP_KERNEL);
+	eps = kmalloc_array(num_eps, sizeof(*eps), GFP_KERNEL);
 	if (!eps)
 		return -ENOMEM;
 
@@ -1606,8 +1606,9 @@ static int proc_do_submiturb(struct usb_dev_state *ps, struct usbdevfs_urb *uurb
 	as->mem_usage = u;
 
 	if (num_sgs) {
-		as->urb->sg = kmalloc(num_sgs * sizeof(struct scatterlist),
-				      GFP_KERNEL);
+		as->urb->sg = kmalloc_array(num_sgs,
+					    sizeof(struct scatterlist),
+					    GFP_KERNEL);
 		if (!as->urb->sg) {
 			ret = -ENOMEM;
 			goto error;
diff --git a/drivers/usb/core/message.c b/drivers/usb/core/message.c
index 8120b519e246..c39e612b9601 100644
--- a/drivers/usb/core/message.c
+++ b/drivers/usb/core/message.c
@@ -386,7 +386,7 @@ int usb_sg_init(struct usb_sg_request *io, struct usb_device *dev,
 	}
 
 	/* initialize all the urbs we'll use */
-	io->urbs = kmalloc(io->entries * sizeof(*io->urbs), mem_flags);
+	io->urbs = kmalloc_array(io->entries, sizeof(*io->urbs), mem_flags);
 	if (!io->urbs)
 		goto nomem;
 
@@ -1820,8 +1820,8 @@ int usb_set_configuration(struct usb_device *dev, int configuration)
 	n = nintf = 0;
 	if (cp) {
 		nintf = cp->desc.bNumInterfaces;
-		new_interfaces = kmalloc(nintf * sizeof(*new_interfaces),
-				GFP_NOIO);
+		new_interfaces = kmalloc_array(nintf, sizeof(*new_interfaces),
+					       GFP_NOIO);
 		if (!new_interfaces)
 			return -ENOMEM;
 
diff --git a/drivers/usb/host/fhci-tds.c b/drivers/usb/host/fhci-tds.c
index 1498061f0aea..23f3c54f0d98 100644
--- a/drivers/usb/host/fhci-tds.c
+++ b/drivers/usb/host/fhci-tds.c
@@ -193,7 +193,7 @@ u32 fhci_create_ep(struct fhci_usb *usb, enum fhci_mem_alloc data_mem,
 			goto err;
 		}
 
-		buff = kmalloc(1028 * sizeof(*buff), GFP_KERNEL);
+		buff = kmalloc_array(1028, sizeof(*buff), GFP_KERNEL);
 		if (!buff) {
 			kfree(pkt);
 			err_for = "buffer";
diff --git a/drivers/usb/host/ohci-dbg.c b/drivers/usb/host/ohci-dbg.c
index ac7d4ac34b02..414486c748a9 100644
--- a/drivers/usb/host/ohci-dbg.c
+++ b/drivers/usb/host/ohci-dbg.c
@@ -492,7 +492,7 @@ static ssize_t fill_periodic_buffer(struct debug_buffer *buf)
 	char			*next;
 	unsigned		i;
 
-	seen = kmalloc(DBG_SCHED_LIMIT * sizeof *seen, GFP_ATOMIC);
+	seen = kmalloc_array(DBG_SCHED_LIMIT, sizeof(*seen), GFP_ATOMIC);
 	if (!seen)
 		return 0;
 	seen_count = 0;
diff --git a/drivers/usb/misc/ldusb.c b/drivers/usb/misc/ldusb.c
index 5c1a3b852453..4800a73a5f61 100644
--- a/drivers/usb/misc/ldusb.c
+++ b/drivers/usb/misc/ldusb.c
@@ -689,7 +689,10 @@ static int ld_usb_probe(struct usb_interface *intf, const struct usb_device_id *
 		dev_warn(&intf->dev, "Interrupt out endpoint not found (using control endpoint instead)\n");
 
 	dev->interrupt_in_endpoint_size = usb_endpoint_maxp(dev->interrupt_in_endpoint);
-	dev->ring_buffer = kmalloc(ring_buffer_size*(sizeof(size_t)+dev->interrupt_in_endpoint_size), GFP_KERNEL);
+	dev->ring_buffer =
+		kmalloc_array(ring_buffer_size,
+			      sizeof(size_t) + dev->interrupt_in_endpoint_size,
+			      GFP_KERNEL);
 	if (!dev->ring_buffer)
 		goto error;
 	dev->interrupt_in_buffer = kmalloc(dev->interrupt_in_endpoint_size, GFP_KERNEL);
@@ -700,7 +703,9 @@ static int ld_usb_probe(struct usb_interface *intf, const struct usb_device_id *
 		goto error;
 	dev->interrupt_out_endpoint_size = dev->interrupt_out_endpoint ? usb_endpoint_maxp(dev->interrupt_out_endpoint) :
 									 udev->descriptor.bMaxPacketSize0;
-	dev->interrupt_out_buffer = kmalloc(write_buffer_size*dev->interrupt_out_endpoint_size, GFP_KERNEL);
+	dev->interrupt_out_buffer =
+		kmalloc_array(write_buffer_size,
+			      dev->interrupt_out_endpoint_size, GFP_KERNEL);
 	if (!dev->interrupt_out_buffer)
 		goto error;
 	dev->interrupt_out_urb = usb_alloc_urb(0, GFP_KERNEL);
diff --git a/drivers/usb/serial/iuu_phoenix.c b/drivers/usb/serial/iuu_phoenix.c
index 62c91e360baf..2fb71303ec3a 100644
--- a/drivers/usb/serial/iuu_phoenix.c
+++ b/drivers/usb/serial/iuu_phoenix.c
@@ -736,7 +736,7 @@ static int iuu_uart_on(struct usb_serial_port *port)
 	int status;
 	u8 *buf;
 
-	buf = kmalloc(sizeof(u8) * 4, GFP_KERNEL);
+	buf = kmalloc(4, GFP_KERNEL);
 
 	if (!buf)
 		return -ENOMEM;
@@ -790,7 +790,7 @@ static int iuu_uart_baud(struct usb_serial_port *port, u32 baud_base,
 	unsigned int T1FrekvensHZ = 0;
 
 	dev_dbg(&port->dev, "%s - enter baud_base=%d\n", __func__, baud_base);
-	dataout = kmalloc(sizeof(u8) * 5, GFP_KERNEL);
+	dataout = kmalloc(5, GFP_KERNEL);
 
 	if (!dataout)
 		return -ENOMEM;
diff --git a/drivers/usb/storage/alauda.c b/drivers/usb/storage/alauda.c
index 900591df8bb2..6b8edf6178df 100644
--- a/drivers/usb/storage/alauda.c
+++ b/drivers/usb/storage/alauda.c
@@ -1025,7 +1025,7 @@ static int alauda_write_data(struct us_data *us, unsigned long address,
 	 * We also need a temporary block buffer, where we read in the old data,
 	 * overwrite parts with the new data, and manipulate the redundancy data
 	 */
-	blockbuffer = kmalloc((pagesize + 64) * blocksize, GFP_NOIO);
+	blockbuffer = kmalloc_array(pagesize + 64, blocksize, GFP_NOIO);
 	if (!blockbuffer) {
 		kfree(buffer);
 		return USB_STOR_TRANSPORT_ERROR;
diff --git a/drivers/usb/storage/ene_ub6250.c b/drivers/usb/storage/ene_ub6250.c
index 93cf57ac47d6..4d261e4de9ad 100644
--- a/drivers/usb/storage/ene_ub6250.c
+++ b/drivers/usb/storage/ene_ub6250.c
@@ -807,8 +807,12 @@ static int ms_lib_alloc_logicalmap(struct us_data *us)
 	u32  i;
 	struct ene_ub6250_info *info = (struct ene_ub6250_info *) us->extra;
 
-	info->MS_Lib.Phy2LogMap = kmalloc(info->MS_Lib.NumberOfPhyBlock * sizeof(u16), GFP_KERNEL);
-	info->MS_Lib.Log2PhyMap = kmalloc(info->MS_Lib.NumberOfLogBlock * sizeof(u16), GFP_KERNEL);
+	info->MS_Lib.Phy2LogMap = kmalloc_array(info->MS_Lib.NumberOfPhyBlock,
+						sizeof(u16),
+						GFP_KERNEL);
+	info->MS_Lib.Log2PhyMap = kmalloc_array(info->MS_Lib.NumberOfLogBlock,
+						sizeof(u16),
+						GFP_KERNEL);
 
 	if ((info->MS_Lib.Phy2LogMap == NULL) || (info->MS_Lib.Log2PhyMap == NULL)) {
 		ms_lib_free_logicalmap(us);
@@ -1113,8 +1117,12 @@ static int ms_lib_alloc_writebuf(struct us_data *us)
 
 	info->MS_Lib.wrtblk = (u16)-1;
 
-	info->MS_Lib.blkpag = kmalloc(info->MS_Lib.PagesPerBlock * info->MS_Lib.BytesPerSector, GFP_KERNEL);
-	info->MS_Lib.blkext = kmalloc(info->MS_Lib.PagesPerBlock * sizeof(struct ms_lib_type_extdat), GFP_KERNEL);
+	info->MS_Lib.blkpag = kmalloc_array(info->MS_Lib.PagesPerBlock,
+					    info->MS_Lib.BytesPerSector,
+					    GFP_KERNEL);
+	info->MS_Lib.blkext = kmalloc_array(info->MS_Lib.PagesPerBlock,
+					    sizeof(struct ms_lib_type_extdat),
+					    GFP_KERNEL);
 
 	if ((info->MS_Lib.blkpag == NULL) || (info->MS_Lib.blkext == NULL)) {
 		ms_lib_free_writebuf(us);
diff --git a/drivers/usb/storage/sddr09.c b/drivers/usb/storage/sddr09.c
index 30764ca292ac..20f4219f96a7 100644
--- a/drivers/usb/storage/sddr09.c
+++ b/drivers/usb/storage/sddr09.c
@@ -1231,8 +1231,8 @@ sddr09_read_map(struct us_data *us) {
 
 	kfree(info->lba_to_pba);
 	kfree(info->pba_to_lba);
-	info->lba_to_pba = kmalloc(numblocks*sizeof(int), GFP_NOIO);
-	info->pba_to_lba = kmalloc(numblocks*sizeof(int), GFP_NOIO);
+	info->lba_to_pba = kmalloc_array(numblocks, sizeof(int), GFP_NOIO);
+	info->pba_to_lba = kmalloc_array(numblocks, sizeof(int), GFP_NOIO);
 
 	if (info->lba_to_pba == NULL || info->pba_to_lba == NULL) {
 		printk(KERN_WARNING "sddr09_read_map: out of memory\n");
diff --git a/drivers/usb/storage/sddr55.c b/drivers/usb/storage/sddr55.c
index 8c814b2ec9b2..b8527c55335b 100644
--- a/drivers/usb/storage/sddr55.c
+++ b/drivers/usb/storage/sddr55.c
@@ -651,7 +651,7 @@ static int sddr55_read_map(struct us_data *us) {
 
 	numblocks = info->capacity >> (info->blockshift + info->pageshift);
 	
-	buffer = kmalloc( numblocks * 2, GFP_NOIO );
+	buffer = kmalloc_array(numblocks, 2, GFP_NOIO );
 	
 	if (!buffer)
 		return -1;
@@ -684,8 +684,8 @@ static int sddr55_read_map(struct us_data *us) {
 
 	kfree(info->lba_to_pba);
 	kfree(info->pba_to_lba);
-	info->lba_to_pba = kmalloc(numblocks*sizeof(int), GFP_NOIO);
-	info->pba_to_lba = kmalloc(numblocks*sizeof(int), GFP_NOIO);
+	info->lba_to_pba = kmalloc_array(numblocks, sizeof(int), GFP_NOIO);
+	info->pba_to_lba = kmalloc_array(numblocks, sizeof(int), GFP_NOIO);
 
 	if (info->lba_to_pba == NULL || info->pba_to_lba == NULL) {
 		kfree(info->lba_to_pba);
diff --git a/drivers/uwb/est.c b/drivers/uwb/est.c
index 86ed7e61e597..31a391c3ba96 100644
--- a/drivers/uwb/est.c
+++ b/drivers/uwb/est.c
@@ -217,7 +217,7 @@ static
 int uwb_est_grow(void)
 {
 	size_t actual_size = uwb_est_size * sizeof(uwb_est[0]);
-	void *new = kmalloc(2 * actual_size, GFP_ATOMIC);
+	void *new = kmalloc_array(2, actual_size, GFP_ATOMIC);
 	if (new == NULL)
 		return -ENOMEM;
 	memcpy(new, uwb_est, actual_size);
diff --git a/drivers/uwb/i1480/dfu/usb.c b/drivers/uwb/i1480/dfu/usb.c
index 2bfc846ac071..cf37729d7be8 100644
--- a/drivers/uwb/i1480/dfu/usb.c
+++ b/drivers/uwb/i1480/dfu/usb.c
@@ -372,7 +372,7 @@ int i1480_usb_probe(struct usb_interface *iface, const struct usb_device_id *id)
 
 	i1480 = &i1480_usb->i1480;
 	i1480->buf_size = 512;
-	i1480->cmd_buf = kmalloc(2 * i1480->buf_size, GFP_KERNEL);
+	i1480->cmd_buf = kmalloc_array(2, i1480->buf_size, GFP_KERNEL);
 	if (i1480->cmd_buf == NULL) {
 		dev_err(dev, "Cannot allocate transfer buffers\n");
 		result = -ENOMEM;
diff --git a/drivers/vhost/net.c b/drivers/vhost/net.c
index baf5b225a11a..a91695bad7a5 100644
--- a/drivers/vhost/net.c
+++ b/drivers/vhost/net.c
@@ -179,8 +179,10 @@ int vhost_net_set_ubuf_info(struct vhost_net *n)
 		zcopy = vhost_net_zcopy_mask & (0x1 << i);
 		if (!zcopy)
 			continue;
-		n->vqs[i].ubuf_info = kmalloc(sizeof(*n->vqs[i].ubuf_info) *
-					      UIO_MAXIOV, GFP_KERNEL);
+		n->vqs[i].ubuf_info =
+			kmalloc_array(UIO_MAXIOV,
+				      sizeof(*n->vqs[i].ubuf_info),
+				      GFP_KERNEL);
 		if  (!n->vqs[i].ubuf_info)
 			goto err;
 	}
@@ -843,7 +845,7 @@ static int vhost_net_open(struct inode *inode, struct file *f)
 	n = kvmalloc(sizeof *n, GFP_KERNEL | __GFP_REPEAT);
 	if (!n)
 		return -ENOMEM;
-	vqs = kmalloc(VHOST_NET_VQ_MAX * sizeof(*vqs), GFP_KERNEL);
+	vqs = kmalloc_array(VHOST_NET_VQ_MAX, sizeof(*vqs), GFP_KERNEL);
 	if (!vqs) {
 		vhost_net_free(n);
 		return -ENOMEM;
* Unmerged path drivers/vhost/scsi.c
* Unmerged path drivers/vhost/test.c
* Unmerged path drivers/vhost/vhost.c
diff --git a/drivers/vhost/vringh.c b/drivers/vhost/vringh.c
index 3bb02c60a2f5..0bc3b03c7d4a 100644
--- a/drivers/vhost/vringh.c
+++ b/drivers/vhost/vringh.c
@@ -190,7 +190,7 @@ static int resize_iovec(struct vringh_kiov *iov, gfp_t gfp)
 	if (flag)
 		new = krealloc(iov->iov, new_num * sizeof(struct iovec), gfp);
 	else {
-		new = kmalloc(new_num * sizeof(struct iovec), gfp);
+		new = kmalloc_array(new_num, sizeof(struct iovec), gfp);
 		if (new) {
 			memcpy(new, iov->iov,
 			       iov->max_num * sizeof(struct iovec));
diff --git a/drivers/video/console/bitblit.c b/drivers/video/console/bitblit.c
index 61b182bf32a2..0231c30dbeb2 100644
--- a/drivers/video/console/bitblit.c
+++ b/drivers/video/console/bitblit.c
@@ -270,7 +270,7 @@ static void bit_cursor(struct vc_data *vc, struct fb_info *info, int mode,
 	if (attribute) {
 		u8 *dst;
 
-		dst = kmalloc(w * vc->vc_font.height, GFP_ATOMIC);
+		dst = kmalloc_array(w, vc->vc_font.height, GFP_ATOMIC);
 		if (!dst)
 			return;
 		kfree(ops->cursor_data);
@@ -313,7 +313,7 @@ static void bit_cursor(struct vc_data *vc, struct fb_info *info, int mode,
 	    vc->vc_cursor_type != ops->p->cursor_shape ||
 	    ops->cursor_state.mask == NULL ||
 	    ops->cursor_reset) {
-		char *mask = kmalloc(w*vc->vc_font.height, GFP_ATOMIC);
+		char *mask = kmalloc_array(w, vc->vc_font.height, GFP_ATOMIC);
 		int cur_height, size, i = 0;
 		u8 msk = 0xff;
 
diff --git a/drivers/video/console/fbcon.c b/drivers/video/console/fbcon.c
index ac9e8e1a9d72..7039133ee62e 100644
--- a/drivers/video/console/fbcon.c
+++ b/drivers/video/console/fbcon.c
@@ -617,7 +617,8 @@ static void fbcon_prepare_logo(struct vc_data *vc, struct fb_info *info,
 		if (scr_readw(r) != vc->vc_video_erase_char)
 			break;
 	if (r != q && new_rows >= rows + logo_lines) {
-		save = kmalloc(logo_lines * new_cols * 2, GFP_KERNEL);
+		save = kmalloc(array3_size(logo_lines, new_cols, 2),
+			       GFP_KERNEL);
 		if (save) {
 			int i = cols < new_cols ? cols : new_cols;
 			scr_memsetw(save, erase, logo_lines * new_cols * 2);
diff --git a/drivers/video/console/fbcon_ccw.c b/drivers/video/console/fbcon_ccw.c
index 41b32ae23dac..e52e5d6ddd55 100644
--- a/drivers/video/console/fbcon_ccw.c
+++ b/drivers/video/console/fbcon_ccw.c
@@ -259,7 +259,7 @@ static void ccw_cursor(struct vc_data *vc, struct fb_info *info, int mode,
 	if (attribute) {
 		u8 *dst;
 
-		dst = kmalloc(w * vc->vc_font.width, GFP_ATOMIC);
+		dst = kmalloc_array(w, vc->vc_font.width, GFP_ATOMIC);
 		if (!dst)
 			return;
 		kfree(ops->cursor_data);
@@ -305,14 +305,15 @@ static void ccw_cursor(struct vc_data *vc, struct fb_info *info, int mode,
 	    vc->vc_cursor_type != ops->p->cursor_shape ||
 	    ops->cursor_state.mask == NULL ||
 	    ops->cursor_reset) {
-		char *tmp, *mask = kmalloc(w*vc->vc_font.width, GFP_ATOMIC);
+		char *tmp, *mask = kmalloc_array(w, vc->vc_font.width,
+						 GFP_ATOMIC);
 		int cur_height, size, i = 0;
 		int width = (vc->vc_font.width + 7)/8;
 
 		if (!mask)
 			return;
 
-		tmp = kmalloc(width * vc->vc_font.height, GFP_ATOMIC);
+		tmp = kmalloc_array(width, vc->vc_font.height, GFP_ATOMIC);
 
 		if (!tmp) {
 			kfree(mask);
diff --git a/drivers/video/console/fbcon_cw.c b/drivers/video/console/fbcon_cw.c
index a93670ef7f89..141a064fcd03 100644
--- a/drivers/video/console/fbcon_cw.c
+++ b/drivers/video/console/fbcon_cw.c
@@ -242,7 +242,7 @@ static void cw_cursor(struct vc_data *vc, struct fb_info *info, int mode,
 	if (attribute) {
 		u8 *dst;
 
-		dst = kmalloc(w * vc->vc_font.width, GFP_ATOMIC);
+		dst = kmalloc_array(w, vc->vc_font.width, GFP_ATOMIC);
 		if (!dst)
 			return;
 		kfree(ops->cursor_data);
@@ -288,14 +288,15 @@ static void cw_cursor(struct vc_data *vc, struct fb_info *info, int mode,
 	    vc->vc_cursor_type != ops->p->cursor_shape ||
 	    ops->cursor_state.mask == NULL ||
 	    ops->cursor_reset) {
-		char *tmp, *mask = kmalloc(w*vc->vc_font.width, GFP_ATOMIC);
+		char *tmp, *mask = kmalloc_array(w, vc->vc_font.width,
+						 GFP_ATOMIC);
 		int cur_height, size, i = 0;
 		int width = (vc->vc_font.width + 7)/8;
 
 		if (!mask)
 			return;
 
-		tmp = kmalloc(width * vc->vc_font.height, GFP_ATOMIC);
+		tmp = kmalloc_array(width, vc->vc_font.height, GFP_ATOMIC);
 
 		if (!tmp) {
 			kfree(mask);
diff --git a/drivers/video/console/fbcon_rotate.c b/drivers/video/console/fbcon_rotate.c
index db6528f2d3f2..417e80c84cb3 100644
--- a/drivers/video/console/fbcon_rotate.c
+++ b/drivers/video/console/fbcon_rotate.c
@@ -46,7 +46,7 @@ static int fbcon_rotate_font(struct fb_info *info, struct vc_data *vc)
 		info->fbops->fb_sync(info);
 
 	if (ops->fd_size < d_cellsize * len) {
-		dst = kmalloc(d_cellsize * len, GFP_KERNEL);
+		dst = kmalloc_array(len, d_cellsize, GFP_KERNEL);
 
 		if (dst == NULL) {
 			err = -ENOMEM;
diff --git a/drivers/video/console/fbcon_ud.c b/drivers/video/console/fbcon_ud.c
index ff0872c0498b..cadbe9453b1c 100644
--- a/drivers/video/console/fbcon_ud.c
+++ b/drivers/video/console/fbcon_ud.c
@@ -290,7 +290,7 @@ static void ud_cursor(struct vc_data *vc, struct fb_info *info, int mode,
 	if (attribute) {
 		u8 *dst;
 
-		dst = kmalloc(w * vc->vc_font.height, GFP_ATOMIC);
+		dst = kmalloc_array(w, vc->vc_font.height, GFP_ATOMIC);
 		if (!dst)
 			return;
 		kfree(ops->cursor_data);
@@ -336,7 +336,7 @@ static void ud_cursor(struct vc_data *vc, struct fb_info *info, int mode,
 	    vc->vc_cursor_type != ops->p->cursor_shape ||
 	    ops->cursor_state.mask == NULL ||
 	    ops->cursor_reset) {
-		char *mask = kmalloc(w*vc->vc_font.height, GFP_ATOMIC);
+		char *mask = kmalloc_array(w, vc->vc_font.height, GFP_ATOMIC);
 		int cur_height, size, i = 0;
 		u8 msk = 0xff;
 
diff --git a/drivers/video/fbmem.c b/drivers/video/fbmem.c
index ea8257aab07c..66deada7df95 100644
--- a/drivers/video/fbmem.c
+++ b/drivers/video/fbmem.c
@@ -482,7 +482,8 @@ static int fb_show_logo_line(struct fb_info *info, int rotate,
 	}
 
 	if (fb_logo.depth <= 4) {
-		logo_new = kmalloc(logo->width * logo->height, GFP_KERNEL);
+		logo_new = kmalloc_array(logo->width, logo->height,
+					 GFP_KERNEL);
 		if (logo_new == NULL) {
 			kfree(palette);
 			if (saved_pseudo_palette)
@@ -499,8 +500,8 @@ static int fb_show_logo_line(struct fb_info *info, int rotate,
 	image.height = logo->height;
 
 	if (rotate) {
-		logo_rotate = kmalloc(logo->width *
-				      logo->height, GFP_KERNEL);
+		logo_rotate = kmalloc_array(logo->width, logo->height,
+					    GFP_KERNEL);
 		if (logo_rotate)
 			fb_rotate_logo(info, logo_rotate, &image, rotate);
 	}
diff --git a/drivers/video/fbmon.c b/drivers/video/fbmon.c
index 6103fa6fb54f..068eac2137cb 100644
--- a/drivers/video/fbmon.c
+++ b/drivers/video/fbmon.c
@@ -658,7 +658,7 @@ static struct fb_videomode *fb_create_modedb(unsigned char *edid, int *dbsize)
 	}
 
 	*dbsize = num;
-	m = kmalloc(num * sizeof(struct fb_videomode), GFP_KERNEL);
+	m = kmalloc_array(num, sizeof(struct fb_videomode), GFP_KERNEL);
 	if (!m)
 		return mode;
 	memmove(m, mode, num * sizeof(struct fb_videomode));
diff --git a/drivers/video/imxfb.c b/drivers/video/imxfb.c
index 0abf2bf20836..0d26f13bd9b0 100644
--- a/drivers/video/imxfb.c
+++ b/drivers/video/imxfb.c
@@ -733,7 +733,7 @@ static int __init imxfb_init_fbinfo(struct platform_device *pdev)
 
 	pr_debug("%s\n",__func__);
 
-	info->pseudo_palette = kmalloc(sizeof(u32) * 16, GFP_KERNEL);
+	info->pseudo_palette = kmalloc_array(16, sizeof(u32), GFP_KERNEL);
 	if (!info->pseudo_palette)
 		return -ENOMEM;
 
diff --git a/drivers/video/mb862xx/mb862xxfb_accel.c b/drivers/video/mb862xx/mb862xxfb_accel.c
index fe92eed6da70..8dd296d257dd 100644
--- a/drivers/video/mb862xx/mb862xxfb_accel.c
+++ b/drivers/video/mb862xx/mb862xxfb_accel.c
@@ -245,7 +245,7 @@ static void mb86290fb_imageblit(struct fb_info *info,
 		return;
 	}
 
-	cmd = kmalloc(cmdlen * 4, GFP_DMA);
+	cmd = kmalloc_array(cmdlen, 4, GFP_DMA);
 	if (!cmd)
 		return cfb_imageblit(info, image);
 	cmdfn(cmd, step, dx, dy, width, height, fgcolor, bgcolor, image, info);
diff --git a/drivers/video/nvidia/nvidia.c b/drivers/video/nvidia/nvidia.c
index ff228713425e..0bdd08f116cf 100644
--- a/drivers/video/nvidia/nvidia.c
+++ b/drivers/video/nvidia/nvidia.c
@@ -575,7 +575,7 @@ static int nvidiafb_cursor(struct fb_info *info, struct fb_cursor *cursor)
 		u8 *msk = (u8 *) cursor->mask;
 		u8 *src;
 
-		src = kmalloc(s_pitch * cursor->image.height, GFP_ATOMIC);
+		src = kmalloc_array(s_pitch, cursor->image.height, GFP_ATOMIC);
 
 		if (src) {
 			switch (cursor->rop) {
diff --git a/drivers/video/pvr2fb.c b/drivers/video/pvr2fb.c
index 7bdf509fbc4e..0c5233afcbd7 100644
--- a/drivers/video/pvr2fb.c
+++ b/drivers/video/pvr2fb.c
@@ -682,7 +682,7 @@ static ssize_t pvr2fb_write(struct fb_info *info, const char *buf,
 
 	nr_pages = (count + PAGE_SIZE - 1) >> PAGE_SHIFT;
 
-	pages = kmalloc(nr_pages * sizeof(struct page *), GFP_KERNEL);
+	pages = kmalloc_array(nr_pages, sizeof(struct page *), GFP_KERNEL);
 	if (!pages)
 		return -ENOMEM;
 
diff --git a/drivers/video/riva/fbdev.c b/drivers/video/riva/fbdev.c
index 9536715b5a1b..7fb6da465e68 100644
--- a/drivers/video/riva/fbdev.c
+++ b/drivers/video/riva/fbdev.c
@@ -1635,7 +1635,7 @@ static int rivafb_cursor(struct fb_info *info, struct fb_cursor *cursor)
 		u8 *msk = (u8 *) cursor->mask;
 		u8 *src;
 		
-		src = kmalloc(s_pitch * cursor->image.height, GFP_ATOMIC);
+		src = kmalloc_array(s_pitch, cursor->image.height, GFP_ATOMIC);
 
 		if (src) {
 			switch (cursor->rop) {
diff --git a/drivers/video/via/viafbdev.c b/drivers/video/via/viafbdev.c
index 325c43c6ff97..0c66d6649cf3 100644
--- a/drivers/video/via/viafbdev.c
+++ b/drivers/video/via/viafbdev.c
@@ -596,7 +596,8 @@ static int viafb_ioctl(struct fb_info *info, u_int cmd, u_long arg)
 		break;
 
 	case VIAFB_GET_GAMMA_LUT:
-		viafb_gamma_table = kmalloc(256 * sizeof(u32), GFP_KERNEL);
+		viafb_gamma_table = kmalloc_array(256, sizeof(u32),
+						  GFP_KERNEL);
 		if (!viafb_gamma_table)
 			return -ENOMEM;
 		viafb_get_gamma_table(viafb_gamma_table);
diff --git a/drivers/video/w100fb.c b/drivers/video/w100fb.c
index 7a299e951f75..e9c534a0e92c 100644
--- a/drivers/video/w100fb.c
+++ b/drivers/video/w100fb.c
@@ -693,7 +693,8 @@ int w100fb_probe(struct platform_device *pdev)
 		goto out;
 	}
 
-	info->pseudo_palette = kmalloc(sizeof (u32) * MAX_PALETTES, GFP_KERNEL);
+	info->pseudo_palette = kmalloc_array(MAX_PALETTES, sizeof(u32),
+					     GFP_KERNEL);
 	if (!info->pseudo_palette) {
 		err = -ENOMEM;
 		goto out;
* Unmerged path drivers/virt/vboxguest/vboxguest_core.c
* Unmerged path drivers/virtio/virtio_pci_common.c
diff --git a/drivers/virtio/virtio_ring.c b/drivers/virtio/virtio_ring.c
index d77a91f39d55..e9e8e7b83738 100644
--- a/drivers/virtio/virtio_ring.c
+++ b/drivers/virtio/virtio_ring.c
@@ -229,7 +229,7 @@ static struct vring_desc *alloc_indirect(struct virtqueue *_vq,
 	 */
 	gfp &= ~(__GFP_HIGHMEM | __GFP_HIGH);
 
-	desc = kmalloc(total_sg * sizeof(struct vring_desc), gfp);
+	desc = kmalloc_array(total_sg, sizeof(struct vring_desc), gfp);
 	if (!desc)
 		return NULL;
 
diff --git a/drivers/xen/grant-table.c b/drivers/xen/grant-table.c
index 2aeaa9e7268b..330f1b0549fb 100644
--- a/drivers/xen/grant-table.c
+++ b/drivers/xen/grant-table.c
@@ -1121,7 +1121,7 @@ static int gnttab_map(unsigned int start_idx, unsigned int end_idx)
 	/* No need for kzalloc as it is initialized in following hypercall
 	 * GNTTABOP_setup_table.
 	 */
-	frames = kmalloc(nr_gframes * sizeof(unsigned long), GFP_ATOMIC);
+	frames = kmalloc_array(nr_gframes, sizeof(unsigned long), GFP_ATOMIC);
 	if (!frames)
 		return -ENOMEM;
 
@@ -1262,8 +1262,9 @@ int gnttab_init(void)
 	max_nr_glist_frames = (gnttab_max_grant_frames() *
 			       grefs_per_grant_frame / RPP);
 
-	gnttab_list = kmalloc(max_nr_glist_frames * sizeof(grant_ref_t *),
-			      GFP_KERNEL);
+	gnttab_list = kmalloc_array(max_nr_glist_frames,
+				    sizeof(grant_ref_t *),
+				    GFP_KERNEL);
 	if (gnttab_list == NULL)
 		return -ENOMEM;
 
* Unmerged path drivers/xen/xen-pciback/pciback_ops.c
diff --git a/fs/9p/fid.c b/fs/9p/fid.c
index d51ec9fafcc8..3c1a39c18347 100644
--- a/fs/9p/fid.c
+++ b/fs/9p/fid.c
@@ -100,7 +100,7 @@ static int build_path_from_dentry(struct v9fs_session_info *v9ses,
 	for (ds = dentry; !IS_ROOT(ds); ds = ds->d_parent)
 		n++;
 
-	wnames = kmalloc(sizeof(char *) * n, GFP_KERNEL);
+	wnames = kmalloc_array(n, sizeof(char *), GFP_KERNEL);
 	if (!wnames)
 		goto err_out;
 
diff --git a/fs/adfs/super.c b/fs/adfs/super.c
index 7b3003cb6f1b..7d59d0f61882 100644
--- a/fs/adfs/super.c
+++ b/fs/adfs/super.c
@@ -312,7 +312,7 @@ static struct adfs_discmap *adfs_read_map(struct super_block *sb, struct adfs_di
 
 	asb->s_ids_per_zone = zone_size / (asb->s_idlen + 1);
 
-	dm = kmalloc(nzones * sizeof(*dm), GFP_KERNEL);
+	dm = kmalloc_array(nzones, sizeof(*dm), GFP_KERNEL);
 	if (dm == NULL) {
 		adfs_error(sb, "not enough memory");
 		return NULL;
* Unmerged path fs/afs/cmservice.c
diff --git a/fs/binfmt_elf.c b/fs/binfmt_elf.c
index 97d77c0438c2..41a7ad1044d5 100644
--- a/fs/binfmt_elf.c
+++ b/fs/binfmt_elf.c
@@ -1870,7 +1870,7 @@ static int elf_note_info_init(struct elf_note_info *info)
 	INIT_LIST_HEAD(&info->thread_list);
 
 	/* Allocate space for ELF notes */
-	info->notes = kmalloc(8 * sizeof(struct memelfnote), GFP_KERNEL);
+	info->notes = kmalloc_array(8, sizeof(struct memelfnote), GFP_KERNEL);
 	if (!info->notes)
 		return 0;
 	info->psinfo = kmalloc(sizeof(*info->psinfo), GFP_KERNEL);
diff --git a/fs/binfmt_elf_fdpic.c b/fs/binfmt_elf_fdpic.c
index 4ab2ad56aa0f..6d9956f8338c 100644
--- a/fs/binfmt_elf_fdpic.c
+++ b/fs/binfmt_elf_fdpic.c
@@ -1636,7 +1636,8 @@ static int elf_fdpic_core_dump(struct coredump_params *cprm)
 	psinfo = kmalloc(sizeof(*psinfo), GFP_KERNEL);
 	if (!psinfo)
 		goto cleanup;
-	notes = kmalloc(NUM_NOTES * sizeof(struct memelfnote), GFP_KERNEL);
+	notes = kmalloc_array(NUM_NOTES, sizeof(struct memelfnote),
+			      GFP_KERNEL);
 	if (!notes)
 		goto cleanup;
 	fpu = kmalloc(sizeof(*fpu), GFP_KERNEL);
* Unmerged path fs/block_dev.c
diff --git a/fs/ceph/addr.c b/fs/ceph/addr.c
index 59bfdf1d95f0..0630f93b741f 100644
--- a/fs/ceph/addr.c
+++ b/fs/ceph/addr.c
@@ -348,7 +348,7 @@ static int start_read(struct inode *inode, struct ceph_rw_context *rw_ctx,
 
 	/* build page vector */
 	nr_pages = calc_pages_for(0, len);
-	pages = kmalloc(sizeof(*pages) * nr_pages, GFP_KERNEL);
+	pages = kmalloc_array(nr_pages, sizeof(*pages), GFP_KERNEL);
 	if (!pages) {
 		ret = -ENOMEM;
 		goto out_put;
@@ -939,8 +939,9 @@ get_more_pages:
 
 				BUG_ON(pages);
 				max_pages = calc_pages_for(0, (u64)len);
-				pages = kmalloc(max_pages * sizeof (*pages),
-						GFP_NOFS);
+				pages = kmalloc_array(max_pages,
+						      sizeof(*pages),
+						      GFP_NOFS);
 				if (!pages) {
 					pool = fsc->wb_pagevec_pool;
 					pages = mempool_alloc(pool, GFP_NOFS);
@@ -1086,8 +1087,8 @@ new_request:
 
 			/* allocate new pages array for next request */
 			data_pages = pages;
-			pages = kmalloc(locked_pages * sizeof (*pages),
-					GFP_NOFS);
+			pages = kmalloc_array(locked_pages, sizeof(*pages),
+					      GFP_NOFS);
 			if (!pages) {
 				pool = fsc->wb_pagevec_pool;
 				pages = mempool_alloc(pool, GFP_NOFS);
diff --git a/fs/ceph/mds_client.c b/fs/ceph/mds_client.c
index 0c84b74ee34d..47581daf9295 100644
--- a/fs/ceph/mds_client.c
+++ b/fs/ceph/mds_client.c
@@ -2991,8 +2991,9 @@ encode_again:
 			num_flock_locks = 0;
 		}
 		if (num_fcntl_locks + num_flock_locks > 0) {
-			flocks = kmalloc((num_fcntl_locks + num_flock_locks) *
-					 sizeof(struct ceph_filelock), GFP_NOFS);
+			flocks = kmalloc_array(num_fcntl_locks + num_flock_locks,
+					       sizeof(struct ceph_filelock),
+					       GFP_NOFS);
 			if (!flocks) {
 				err = -ENOMEM;
 				goto out_free;
diff --git a/fs/cifs/asn1.c b/fs/cifs/asn1.c
index a3b56544c21b..3d19595eb352 100644
--- a/fs/cifs/asn1.c
+++ b/fs/cifs/asn1.c
@@ -428,7 +428,7 @@ asn1_oid_decode(struct asn1_ctx *ctx,
 	if (size < 2 || size > UINT_MAX/sizeof(unsigned long))
 		return 0;
 
-	*oid = kmalloc(size * sizeof(unsigned long), GFP_ATOMIC);
+	*oid = kmalloc_array(size, sizeof(unsigned long), GFP_ATOMIC);
 	if (*oid == NULL)
 		return 0;
 
diff --git a/fs/cifs/cifsacl.c b/fs/cifs/cifsacl.c
index 2c57e74b19d3..8bebaf06170f 100644
--- a/fs/cifs/cifsacl.c
+++ b/fs/cifs/cifsacl.c
@@ -749,8 +749,8 @@ static void parse_dacl(struct cifs_acl *pdacl, char *end_of_acl,
 
 		if (num_aces > ULONG_MAX / sizeof(struct cifs_ace *))
 			return;
-		ppace = kmalloc(num_aces * sizeof(struct cifs_ace *),
-				GFP_KERNEL);
+		ppace = kmalloc_array(num_aces, sizeof(struct cifs_ace *),
+				      GFP_KERNEL);
 		if (!ppace)
 			return;
 
diff --git a/fs/cifs/inode.c b/fs/cifs/inode.c
index 169ea2f3c7f6..3f04cf9cec17 100644
--- a/fs/cifs/inode.c
+++ b/fs/cifs/inode.c
@@ -1757,7 +1757,7 @@ cifs_rename2(struct inode *source_dir, struct dentry *source_dentry,
 		 * with unix extensions enabled.
 		 */
 		info_buf_source =
-			kmalloc(2 * sizeof(FILE_UNIX_BASIC_INFO),
+			kmalloc_array(2, sizeof(FILE_UNIX_BASIC_INFO),
 					GFP_KERNEL);
 		if (info_buf_source == NULL) {
 			rc = -ENOMEM;
diff --git a/fs/cifs/smb2pdu.c b/fs/cifs/smb2pdu.c
index 651e69704e4b..30f4e7c6ff78 100644
--- a/fs/cifs/smb2pdu.c
+++ b/fs/cifs/smb2pdu.c
@@ -3067,7 +3067,7 @@ send_set_info(const unsigned int xid, struct cifs_tcon *tcon,
 	if (!num)
 		return -EINVAL;
 
-	iov = kmalloc(sizeof(struct kvec) * num, GFP_KERNEL);
+	iov = kmalloc_array(num, sizeof(struct kvec), GFP_KERNEL);
 	if (!iov)
 		return -ENOMEM;
 
@@ -3128,7 +3128,7 @@ SMB2_rename(const unsigned int xid, struct cifs_tcon *tcon,
 	int rc;
 	int len = (2 * UniStrnlen((wchar_t *)target_file, PATH_MAX));
 
-	data = kmalloc(sizeof(void *) * 2, GFP_KERNEL);
+	data = kmalloc_array(2, sizeof(void *), GFP_KERNEL);
 	if (!data)
 		return -ENOMEM;
 
@@ -3176,7 +3176,7 @@ SMB2_set_hardlink(const unsigned int xid, struct cifs_tcon *tcon,
 	int rc;
 	int len = (2 * UniStrnlen((wchar_t *)target_file, PATH_MAX));
 
-	data = kmalloc(sizeof(void *) * 2, GFP_KERNEL);
+	data = kmalloc_array(2, sizeof(void *), GFP_KERNEL);
 	if (!data)
 		return -ENOMEM;
 
* Unmerged path fs/cifs/transport.c
diff --git a/fs/exofs/inode.c b/fs/exofs/inode.c
index 134de36697d1..132b8481113a 100644
--- a/fs/exofs/inode.c
+++ b/fs/exofs/inode.c
@@ -110,8 +110,8 @@ static int pcol_try_alloc(struct page_collect *pcol)
 	pages =  exofs_max_io_pages(&pcol->sbi->layout, pcol->expected_pages);
 
 	for (; pages; pages >>= 1) {
-		pcol->pages = kmalloc(pages * sizeof(struct page *),
-				      GFP_KERNEL);
+		pcol->pages = kmalloc_array(pages, sizeof(struct page *),
+					    GFP_KERNEL);
 		if (likely(pcol->pages)) {
 			pcol->alloc_pages = pages;
 			return 0;
diff --git a/fs/ext2/super.c b/fs/ext2/super.c
index 241c03defc77..a11813c3da25 100644
--- a/fs/ext2/super.c
+++ b/fs/ext2/super.c
@@ -1035,7 +1035,9 @@ static int ext2_fill_super(struct super_block *sb, void *data, int silent)
  					/ EXT2_BLOCKS_PER_GROUP(sb)) + 1;
 	db_count = (sbi->s_groups_count + EXT2_DESC_PER_BLOCK(sb) - 1) /
 		   EXT2_DESC_PER_BLOCK(sb);
-	sbi->s_group_desc = kmalloc (db_count * sizeof (struct buffer_head *), GFP_KERNEL);
+	sbi->s_group_desc = kmalloc_array (db_count,
+					   sizeof(struct buffer_head *),
+					   GFP_KERNEL);
 	if (sbi->s_group_desc == NULL) {
 		ext2_msg(sb, KERN_ERR, "error: not enough memory");
 		goto failed_mount;
diff --git a/fs/ext4/resize.c b/fs/ext4/resize.c
index ea1b5d944a65..b5f1732aae8c 100644
--- a/fs/ext4/resize.c
+++ b/fs/ext4/resize.c
@@ -202,12 +202,14 @@ static struct ext4_new_flex_group_data *alloc_flex_gd(unsigned long flexbg_size)
 		goto out2;
 	flex_gd->count = flexbg_size;
 
-	flex_gd->groups = kmalloc(sizeof(struct ext4_new_group_data) *
-				  flexbg_size, GFP_NOFS);
+	flex_gd->groups = kmalloc_array(flexbg_size,
+					sizeof(struct ext4_new_group_data),
+					GFP_NOFS);
 	if (flex_gd->groups == NULL)
 		goto out2;
 
-	flex_gd->bg_flags = kmalloc(flexbg_size * sizeof(__u16), GFP_NOFS);
+	flex_gd->bg_flags = kmalloc_array(flexbg_size, sizeof(__u16),
+					  GFP_NOFS);
 	if (flex_gd->bg_flags == NULL)
 		goto out1;
 
@@ -944,7 +946,7 @@ static int reserve_backup_gdb(handle_t *handle, struct inode *inode,
 	int res, i;
 	int err;
 
-	primary = kmalloc(reserved_gdb * sizeof(*primary), GFP_NOFS);
+	primary = kmalloc_array(reserved_gdb, sizeof(*primary), GFP_NOFS);
 	if (!primary)
 		return -ENOMEM;
 
diff --git a/fs/fat/namei_vfat.c b/fs/fat/namei_vfat.c
index 6df8d3d885e5..6125e652d276 100644
--- a/fs/fat/namei_vfat.c
+++ b/fs/fat/namei_vfat.c
@@ -666,7 +666,7 @@ static int vfat_add_entry(struct inode *dir, struct qstr *qname, int is_dir,
 	if (len == 0)
 		return -ENOENT;
 
-	slots = kmalloc(sizeof(*slots) * MSDOS_SLOTS, GFP_NOFS);
+	slots = kmalloc_array(MSDOS_SLOTS, sizeof(*slots), GFP_NOFS);
 	if (slots == NULL)
 		return -ENOMEM;
 
diff --git a/fs/fuse/dev.c b/fs/fuse/dev.c
index ad00311500d7..8919360a4566 100644
--- a/fs/fuse/dev.c
+++ b/fs/fuse/dev.c
@@ -63,9 +63,12 @@ static struct fuse_req *__fuse_request_alloc(unsigned npages, gfp_t flags)
 			pages = req->inline_pages;
 			page_descs = req->inline_page_descs;
 		} else {
-			pages = kmalloc(sizeof(struct page *) * npages, flags);
-			page_descs = kmalloc(sizeof(struct fuse_page_desc) *
-					     npages, flags);
+			pages = kmalloc_array(npages, sizeof(struct page *),
+					      flags);
+			page_descs =
+				kmalloc_array(npages,
+					      sizeof(struct fuse_page_desc),
+					      flags);
 		}
 
 		if (!pages || !page_descs) {
@@ -1333,7 +1336,8 @@ static ssize_t fuse_dev_splice_read(struct file *in, loff_t *ppos,
 	if (!fc)
 		return -EPERM;
 
-	bufs = kmalloc(pipe->buffers * sizeof(struct pipe_buffer), GFP_KERNEL);
+	bufs = kmalloc_array(pipe->buffers, sizeof(struct pipe_buffer),
+			     GFP_KERNEL);
 	if (!bufs)
 		return -ENOMEM;
 
@@ -1936,7 +1940,8 @@ static ssize_t fuse_dev_splice_write(struct pipe_inode_info *pipe,
 	if (!fc)
 		return -EPERM;
 
-	bufs = kmalloc(pipe->buffers * sizeof(struct pipe_buffer), GFP_KERNEL);
+	bufs = kmalloc_array(pipe->buffers, sizeof(struct pipe_buffer),
+			     GFP_KERNEL);
 	if (!bufs)
 		return -ENOMEM;
 
diff --git a/fs/gfs2/dir.c b/fs/gfs2/dir.c
index 25056e88a1cc..7a5f2f1d69d8 100644
--- a/fs/gfs2/dir.c
+++ b/fs/gfs2/dir.c
@@ -1061,7 +1061,7 @@ static int dir_split_leaf(struct inode *inode, const struct qstr *name)
 	/* Change the pointers.
 	   Don't bother distinguishing stuffed from non-stuffed.
 	   This code is complicated enough already. */
-	lp = kmalloc(half_len * sizeof(__be64), GFP_NOFS);
+	lp = kmalloc_array(half_len, sizeof(__be64), GFP_NOFS);
 	if (!lp) {
 		error = -ENOMEM;
 		goto fail_brelse;
@@ -1175,7 +1175,7 @@ static int dir_double_exhash(struct gfs2_inode *dip)
 	if (IS_ERR(hc))
 		return PTR_ERR(hc);
 
-	hc2 = kmalloc(hsize_bytes * 2, GFP_NOFS | __GFP_NOWARN);
+	hc2 = kmalloc_array(hsize_bytes, 2, GFP_NOFS | __GFP_NOWARN);
 	if (hc2 == NULL)
 		hc2 = __vmalloc(hsize_bytes * 2, GFP_NOFS, PAGE_KERNEL);
 
@@ -1617,7 +1617,7 @@ int gfs2_dir_read(struct inode *inode, u64 *offset, void *opaque,
 
 	error = -ENOMEM;
 	/* 96 is max number of dirents which can be stuffed into an inode */
-	darr = kmalloc(96 * sizeof(struct gfs2_dirent *), GFP_NOFS);
+	darr = kmalloc_array(96, sizeof(struct gfs2_dirent *), GFP_NOFS);
 	if (darr) {
 		g.pdent = (const struct gfs2_dirent **)darr;
 		g.offset = 0;
diff --git a/fs/gfs2/glock.c b/fs/gfs2/glock.c
index badf0b709da0..7f00cb887fee 100644
--- a/fs/gfs2/glock.c
+++ b/fs/gfs2/glock.c
@@ -1319,7 +1319,8 @@ int gfs2_glock_nq_m(unsigned int num_gh, struct gfs2_holder *ghs)
 	default:
 		if (num_gh <= 4)
 			break;
-		pph = kmalloc(num_gh * sizeof(struct gfs2_holder *), GFP_NOFS);
+		pph = kmalloc_array(num_gh, sizeof(struct gfs2_holder *),
+				    GFP_NOFS);
 		if (!pph)
 			return -ENOMEM;
 	}
diff --git a/fs/gfs2/quota.c b/fs/gfs2/quota.c
index 3d5f86897bc8..c9dcedf6629d 100644
--- a/fs/gfs2/quota.c
+++ b/fs/gfs2/quota.c
@@ -874,7 +874,7 @@ static int do_sync(unsigned int num_qd, struct gfs2_quota_data **qda)
 	gfs2_write_calc_reserv(ip, sizeof(struct gfs2_quota),
 			      &data_blocks, &ind_blocks);
 
-	ghs = kmalloc(num_qd * sizeof(struct gfs2_holder), GFP_NOFS);
+	ghs = kmalloc_array(num_qd, sizeof(struct gfs2_holder), GFP_NOFS);
 	if (!ghs)
 		return -ENOMEM;
 
diff --git a/fs/gfs2/rgrp.c b/fs/gfs2/rgrp.c
index 84f7836f6073..7ee7c939aeb4 100644
--- a/fs/gfs2/rgrp.c
+++ b/fs/gfs2/rgrp.c
@@ -2567,8 +2567,9 @@ void gfs2_rlist_alloc(struct gfs2_rgrp_list *rlist, unsigned int state)
 {
 	unsigned int x;
 
-	rlist->rl_ghs = kmalloc(rlist->rl_rgrps * sizeof(struct gfs2_holder),
-				GFP_NOFS | __GFP_NOFAIL);
+	rlist->rl_ghs = kmalloc_array(rlist->rl_rgrps,
+				      sizeof(struct gfs2_holder),
+				      GFP_NOFS | __GFP_NOFAIL);
 	for (x = 0; x < rlist->rl_rgrps; x++)
 		gfs2_holder_init(rlist->rl_rgd[x]->rd_gl,
 				state, 0,
diff --git a/fs/gfs2/super.c b/fs/gfs2/super.c
index 03cebdef00bd..4aad7ddbeff6 100644
--- a/fs/gfs2/super.c
+++ b/fs/gfs2/super.c
@@ -1058,7 +1058,7 @@ static int gfs2_statfs_slow(struct gfs2_sbd *sdp, struct gfs2_statfs_change_host
 	int error = 0, err;
 
 	memset(sc, 0, sizeof(struct gfs2_statfs_change_host));
-	gha = kmalloc(slots * sizeof(struct gfs2_holder), GFP_KERNEL);
+	gha = kmalloc_array(slots, sizeof(struct gfs2_holder), GFP_KERNEL);
 	if (!gha)
 		return -ENOMEM;
 	for (x = 0; x < slots; x++)
* Unmerged path fs/hpfs/dnode.c
* Unmerged path fs/hpfs/map.c
diff --git a/fs/jbd2/revoke.c b/fs/jbd2/revoke.c
index 14214da80eb8..1e7ba616d6f1 100644
--- a/fs/jbd2/revoke.c
+++ b/fs/jbd2/revoke.c
@@ -235,7 +235,7 @@ static struct jbd2_revoke_table_s *jbd2_journal_init_revoke_table(int hash_size)
 	table->hash_size = hash_size;
 	table->hash_shift = shift;
 	table->hash_table =
-		kmalloc(hash_size * sizeof(struct list_head), GFP_KERNEL);
+		kmalloc_array(hash_size, sizeof(struct list_head), GFP_KERNEL);
 	if (!table->hash_table) {
 		kmem_cache_free(jbd2_revoke_table_cache, table);
 		table = NULL;
diff --git a/fs/jffs2/wbuf.c b/fs/jffs2/wbuf.c
index a6597d60d76d..316e29118cd4 100644
--- a/fs/jffs2/wbuf.c
+++ b/fs/jffs2/wbuf.c
@@ -1220,7 +1220,7 @@ int jffs2_nand_flash_setup(struct jffs2_sb_info *c)
 	if (!c->wbuf)
 		return -ENOMEM;
 
-	c->oobbuf = kmalloc(NR_OOB_SCAN_PAGES * c->oobavail, GFP_KERNEL);
+	c->oobbuf = kmalloc_array(NR_OOB_SCAN_PAGES, c->oobavail, GFP_KERNEL);
 	if (!c->oobbuf) {
 		kfree(c->wbuf);
 		return -ENOMEM;
diff --git a/fs/jfs/jfs_dmap.c b/fs/jfs/jfs_dmap.c
index 9a55f53be5ff..0cbe0be85435 100644
--- a/fs/jfs/jfs_dmap.c
+++ b/fs/jfs/jfs_dmap.c
@@ -1650,7 +1650,7 @@ s64 dbDiscardAG(struct inode *ip, int agno, s64 minlen)
 	max_ranges = nblocks;
 	do_div(max_ranges, minlen);
 	range_cnt = min_t(u64, max_ranges + 1, 32 * 1024);
-	totrim = kmalloc(sizeof(struct range2trim) * range_cnt, GFP_NOFS);
+	totrim = kmalloc_array(range_cnt, sizeof(struct range2trim), GFP_NOFS);
 	if (totrim == NULL) {
 		jfs_error(bmp->db_ipbmap->i_sb,
 			  "dbDiscardAG: no memory for trim array");
diff --git a/fs/jfs/jfs_dtree.c b/fs/jfs/jfs_dtree.c
index c450fdb3d78d..8f1ba33e9261 100644
--- a/fs/jfs/jfs_dtree.c
+++ b/fs/jfs/jfs_dtree.c
@@ -594,7 +594,8 @@ int dtSearch(struct inode *ip, struct component_name * key, ino_t * data,
 	struct component_name ciKey;
 	struct super_block *sb = ip->i_sb;
 
-	ciKey.name = kmalloc((JFS_NAME_MAX + 1) * sizeof(wchar_t), GFP_NOFS);
+	ciKey.name = kmalloc_array(JFS_NAME_MAX + 1, sizeof(wchar_t),
+				   GFP_NOFS);
 	if (!ciKey.name) {
 		rc = -ENOMEM;
 		goto dtSearch_Exit2;
@@ -957,7 +958,7 @@ static int dtSplitUp(tid_t tid,
 	smp = split->mp;
 	sp = DT_PAGE(ip, smp);
 
-	key.name = kmalloc((JFS_NAME_MAX + 2) * sizeof(wchar_t), GFP_NOFS);
+	key.name = kmalloc_array(JFS_NAME_MAX + 2, sizeof(wchar_t), GFP_NOFS);
 	if (!key.name) {
 		DT_PUTPAGE(smp);
 		rc = -ENOMEM;
@@ -3787,12 +3788,12 @@ static int ciGetLeafPrefixKey(dtpage_t * lp, int li, dtpage_t * rp,
 	struct component_name lkey;
 	struct component_name rkey;
 
-	lkey.name = kmalloc((JFS_NAME_MAX + 1) * sizeof(wchar_t),
+	lkey.name = kmalloc_array(JFS_NAME_MAX + 1, sizeof(wchar_t),
 					GFP_KERNEL);
 	if (lkey.name == NULL)
 		return -ENOMEM;
 
-	rkey.name = kmalloc((JFS_NAME_MAX + 1) * sizeof(wchar_t),
+	rkey.name = kmalloc_array(JFS_NAME_MAX + 1, sizeof(wchar_t),
 					GFP_KERNEL);
 	if (rkey.name == NULL) {
 		kfree(lkey.name);
diff --git a/fs/jfs/jfs_unicode.c b/fs/jfs/jfs_unicode.c
index c7de6f5bbefc..0148e2e4d97a 100644
--- a/fs/jfs/jfs_unicode.c
+++ b/fs/jfs/jfs_unicode.c
@@ -121,7 +121,7 @@ int get_UCSname(struct component_name * uniName, struct dentry *dentry)
 		return -ENAMETOOLONG;
 
 	uniName->name =
-	    kmalloc((length + 1) * sizeof(wchar_t), GFP_NOFS);
+	    kmalloc_array(length + 1, sizeof(wchar_t), GFP_NOFS);
 
 	if (uniName->name == NULL)
 		return -ENOMEM;
* Unmerged path fs/mbcache.c
* Unmerged path fs/namei.c
diff --git a/fs/nfsd/nfs4recover.c b/fs/nfsd/nfs4recover.c
index 958c0e234dad..b492cdbee452 100644
--- a/fs/nfsd/nfs4recover.c
+++ b/fs/nfsd/nfs4recover.c
@@ -501,8 +501,9 @@ nfs4_legacy_state_init(struct net *net)
 	struct nfsd_net *nn = net_generic(net, nfsd_net_id);
 	int i;
 
-	nn->reclaim_str_hashtbl = kmalloc(sizeof(struct list_head) *
-					  CLIENT_HASH_SIZE, GFP_KERNEL);
+	nn->reclaim_str_hashtbl = kmalloc_array(CLIENT_HASH_SIZE,
+						sizeof(struct list_head),
+						GFP_KERNEL);
 	if (!nn->reclaim_str_hashtbl)
 		return -ENOMEM;
 
diff --git a/fs/nfsd/nfs4state.c b/fs/nfsd/nfs4state.c
index ffa2a133d58d..d59ba1e5b855 100644
--- a/fs/nfsd/nfs4state.c
+++ b/fs/nfsd/nfs4state.c
@@ -1791,8 +1791,9 @@ static struct nfs4_client *alloc_client(struct xdr_netobj name)
 	clp->cl_name.data = kmemdup(name.data, name.len, GFP_KERNEL);
 	if (clp->cl_name.data == NULL)
 		goto err_no_name;
-	clp->cl_ownerstr_hashtbl = kmalloc(sizeof(struct list_head) *
-			OWNER_HASH_SIZE, GFP_KERNEL);
+	clp->cl_ownerstr_hashtbl = kmalloc_array(OWNER_HASH_SIZE,
+						 sizeof(struct list_head),
+						 GFP_KERNEL);
 	if (!clp->cl_ownerstr_hashtbl)
 		goto err_no_hashtbl;
 	for (i = 0; i < OWNER_HASH_SIZE; i++)
@@ -6947,16 +6948,19 @@ static int nfs4_state_create_net(struct net *net)
 	struct nfsd_net *nn = net_generic(net, nfsd_net_id);
 	int i;
 
-	nn->conf_id_hashtbl = kmalloc(sizeof(struct list_head) *
-			CLIENT_HASH_SIZE, GFP_KERNEL);
+	nn->conf_id_hashtbl = kmalloc_array(CLIENT_HASH_SIZE,
+					    sizeof(struct list_head),
+					    GFP_KERNEL);
 	if (!nn->conf_id_hashtbl)
 		goto err;
-	nn->unconf_id_hashtbl = kmalloc(sizeof(struct list_head) *
-			CLIENT_HASH_SIZE, GFP_KERNEL);
+	nn->unconf_id_hashtbl = kmalloc_array(CLIENT_HASH_SIZE,
+					      sizeof(struct list_head),
+					      GFP_KERNEL);
 	if (!nn->unconf_id_hashtbl)
 		goto err_unconf_id;
-	nn->sessionid_hashtbl = kmalloc(sizeof(struct list_head) *
-			SESSION_HASH_SIZE, GFP_KERNEL);
+	nn->sessionid_hashtbl = kmalloc_array(SESSION_HASH_SIZE,
+					      sizeof(struct list_head),
+					      GFP_KERNEL);
 	if (!nn->sessionid_hashtbl)
 		goto err_sessionid;
 
diff --git a/fs/ntfs/compress.c b/fs/ntfs/compress.c
index ee4144ce5d7c..72275c747766 100644
--- a/fs/ntfs/compress.c
+++ b/fs/ntfs/compress.c
@@ -531,7 +531,7 @@ int ntfs_read_compressed_block(struct page *page)
 	BUG_ON(ni->type != AT_DATA);
 	BUG_ON(ni->name_len);
 
-	pages = kmalloc(nr_pages * sizeof(struct page *), GFP_NOFS);
+	pages = kmalloc_array(nr_pages, sizeof(struct page *), GFP_NOFS);
 
 	/* Allocate memory to store the buffer heads we need. */
 	bhs_size = cb_size / block_size * sizeof(struct buffer_head *);
diff --git a/fs/ocfs2/cluster/tcp.c b/fs/ocfs2/cluster/tcp.c
index 976ea9ad380a..996b1530ead1 100644
--- a/fs/ocfs2/cluster/tcp.c
+++ b/fs/ocfs2/cluster/tcp.c
@@ -1099,7 +1099,7 @@ int o2net_send_message_vec(u32 msg_type, u32 key, struct kvec *caller_vec,
 	o2net_set_nst_sock_container(&nst, sc);
 
 	veclen = caller_veclen + 1;
-	vec = kmalloc(sizeof(struct kvec) * veclen, GFP_ATOMIC);
+	vec = kmalloc_array(veclen, sizeof(struct kvec), GFP_ATOMIC);
 	if (vec == NULL) {
 		mlog(0, "failed to %zu element kvec!\n", veclen);
 		ret = -ENOMEM;
diff --git a/fs/ocfs2/dlm/dlmdomain.c b/fs/ocfs2/dlm/dlmdomain.c
index 8320a3bedb00..32cdf37654ef 100644
--- a/fs/ocfs2/dlm/dlmdomain.c
+++ b/fs/ocfs2/dlm/dlmdomain.c
@@ -87,7 +87,7 @@ static void dlm_free_pagevec(void **vec, int pages)
 
 static void **dlm_alloc_pagevec(int pages)
 {
-	void **vec = kmalloc(pages * sizeof(void *), GFP_KERNEL);
+	void **vec = kmalloc_array(pages, sizeof(void *), GFP_KERNEL);
 	int i;
 
 	if (!vec)
diff --git a/fs/proc/base.c b/fs/proc/base.c
index 3f20e2834b87..d75d873319a5 100644
--- a/fs/proc/base.c
+++ b/fs/proc/base.c
@@ -468,7 +468,8 @@ static int proc_pid_stack(struct seq_file *m, struct pid_namespace *ns,
 	unsigned long *entries;
 	int err;
 
-	entries = kmalloc(MAX_STACK_TRACE_DEPTH * sizeof(*entries), GFP_KERNEL);
+	entries = kmalloc_array(MAX_STACK_TRACE_DEPTH, sizeof(*entries),
+				GFP_KERNEL);
 	if (!entries)
 		return -ENOMEM;
 
* Unmerged path fs/proc/task_mmu.c
* Unmerged path fs/read_write.c
* Unmerged path fs/reiserfs/journal.c
* Unmerged path fs/select.c
* Unmerged path fs/splice.c
diff --git a/fs/ubifs/lpt.c b/fs/ubifs/lpt.c
index d46b19ec1815..96f042536599 100644
--- a/fs/ubifs/lpt.c
+++ b/fs/ubifs/lpt.c
@@ -628,7 +628,7 @@ int ubifs_create_dflt_lpt(struct ubifs_info *c, int *main_lebs, int lpt_first,
 	/* Needed by 'ubifs_pack_lsave()' */
 	c->main_first = c->leb_cnt - *main_lebs;
 
-	lsave = kmalloc(sizeof(int) * c->lsave_cnt, GFP_KERNEL);
+	lsave = kmalloc_array(c->lsave_cnt, sizeof(int), GFP_KERNEL);
 	pnode = kzalloc(sizeof(struct ubifs_pnode), GFP_KERNEL);
 	nnode = kzalloc(sizeof(struct ubifs_nnode), GFP_KERNEL);
 	buf = vmalloc(c->leb_size);
@@ -1639,15 +1639,17 @@ static int lpt_init_rd(struct ubifs_info *c)
 		return -ENOMEM;
 
 	for (i = 0; i < LPROPS_HEAP_CNT; i++) {
-		c->lpt_heap[i].arr = kmalloc(sizeof(void *) * LPT_HEAP_SZ,
-					     GFP_KERNEL);
+		c->lpt_heap[i].arr = kmalloc_array(LPT_HEAP_SZ,
+						   sizeof(void *),
+						   GFP_KERNEL);
 		if (!c->lpt_heap[i].arr)
 			return -ENOMEM;
 		c->lpt_heap[i].cnt = 0;
 		c->lpt_heap[i].max_cnt = LPT_HEAP_SZ;
 	}
 
-	c->dirty_idx.arr = kmalloc(sizeof(void *) * LPT_HEAP_SZ, GFP_KERNEL);
+	c->dirty_idx.arr = kmalloc_array(LPT_HEAP_SZ, sizeof(void *),
+					 GFP_KERNEL);
 	if (!c->dirty_idx.arr)
 		return -ENOMEM;
 	c->dirty_idx.cnt = 0;
@@ -1700,7 +1702,7 @@ static int lpt_init_wr(struct ubifs_info *c)
 		return -ENOMEM;
 
 	if (c->big_lpt) {
-		c->lsave = kmalloc(sizeof(int) * c->lsave_cnt, GFP_NOFS);
+		c->lsave = kmalloc_array(c->lsave_cnt, sizeof(int), GFP_NOFS);
 		if (!c->lsave)
 			return -ENOMEM;
 		err = read_lsave(c);
@@ -1942,8 +1944,8 @@ int ubifs_lpt_scan_nolock(struct ubifs_info *c, int start_lnum, int end_lnum,
 			return err;
 	}
 
-	path = kmalloc(sizeof(struct lpt_scan_node) * (c->lpt_hght + 1),
-		       GFP_NOFS);
+	path = kmalloc_array(c->lpt_hght + 1, sizeof(struct lpt_scan_node),
+			     GFP_NOFS);
 	if (!path)
 		return -ENOMEM;
 
diff --git a/fs/ubifs/super.c b/fs/ubifs/super.c
index 59ff78d90694..5295ff2688f8 100644
--- a/fs/ubifs/super.c
+++ b/fs/ubifs/super.c
@@ -1199,7 +1199,8 @@ static int mount_ubifs(struct ubifs_info *c)
 	 * never exceed 64.
 	 */
 	err = -ENOMEM;
-	c->bottom_up_buf = kmalloc(BOTTOM_UP_HEIGHT * sizeof(int), GFP_KERNEL);
+	c->bottom_up_buf = kmalloc_array(BOTTOM_UP_HEIGHT, sizeof(int),
+					 GFP_KERNEL);
 	if (!c->bottom_up_buf)
 		goto out_free;
 
diff --git a/fs/ubifs/tnc.c b/fs/ubifs/tnc.c
index 349f31a30f40..9f1037878377 100644
--- a/fs/ubifs/tnc.c
+++ b/fs/ubifs/tnc.c
@@ -1103,8 +1103,9 @@ static struct ubifs_znode *dirty_cow_bottom_up(struct ubifs_info *c,
 	ubifs_assert(znode);
 	if (c->zroot.znode->level > BOTTOM_UP_HEIGHT) {
 		kfree(c->bottom_up_buf);
-		c->bottom_up_buf = kmalloc(c->zroot.znode->level * sizeof(int),
-					   GFP_NOFS);
+		c->bottom_up_buf = kmalloc_array(c->zroot.znode->level,
+						 sizeof(int),
+						 GFP_NOFS);
 		if (!c->bottom_up_buf)
 			return ERR_PTR(-ENOMEM);
 		path = c->bottom_up_buf;
diff --git a/fs/ubifs/tnc_commit.c b/fs/ubifs/tnc_commit.c
index 52a6559275c4..11483f81e5e1 100644
--- a/fs/ubifs/tnc_commit.c
+++ b/fs/ubifs/tnc_commit.c
@@ -364,7 +364,8 @@ static int layout_in_gaps(struct ubifs_info *c, int cnt)
 
 	dbg_gc("%d znodes to write", cnt);
 
-	c->gap_lebs = kmalloc(sizeof(int) * (c->lst.idx_lebs + 1), GFP_NOFS);
+	c->gap_lebs = kmalloc_array(c->lst.idx_lebs + 1, sizeof(int),
+				    GFP_NOFS);
 	if (!c->gap_lebs)
 		return -ENOMEM;
 
@@ -673,7 +674,7 @@ static int alloc_idx_lebs(struct ubifs_info *c, int cnt)
 	dbg_cmt("need about %d empty LEBS for TNC commit", leb_cnt);
 	if (!leb_cnt)
 		return 0;
-	c->ilebs = kmalloc(leb_cnt * sizeof(int), GFP_NOFS);
+	c->ilebs = kmalloc_array(leb_cnt, sizeof(int), GFP_NOFS);
 	if (!c->ilebs)
 		return -ENOMEM;
 	for (i = 0; i < leb_cnt; i++) {
diff --git a/fs/ufs/super.c b/fs/ufs/super.c
index 329f2f53b7ed..4f4b927fcf07 100644
--- a/fs/ufs/super.c
+++ b/fs/ufs/super.c
@@ -560,7 +560,9 @@ static int ufs_read_cylinder_structures(struct super_block *sb)
 	 * Read cylinder group (we read only first fragment from block
 	 * at this time) and prepare internal data structures for cg caching.
 	 */
-	if (!(sbi->s_ucg = kmalloc (sizeof(struct buffer_head *) * uspi->s_ncg, GFP_NOFS)))
+	sbi->s_ucg = kmalloc_array(uspi->s_ncg, sizeof(struct buffer_head *),
+				   GFP_NOFS);
+	if (!sbi->s_ucg)
 		goto failed;
 	for (i = 0; i < uspi->s_ncg; i++) 
 		sbi->s_ucg[i] = NULL;
diff --git a/kernel/bpf/lpm_trie.c b/kernel/bpf/lpm_trie.c
index b4b5b81e7251..1603492c9cc7 100644
--- a/kernel/bpf/lpm_trie.c
+++ b/kernel/bpf/lpm_trie.c
@@ -623,8 +623,9 @@ static int trie_get_next_key(struct bpf_map *map, void *_key, void *_next_key)
 	if (!key || key->prefixlen > trie->max_prefixlen)
 		goto find_leftmost;
 
-	node_stack = kmalloc(trie->max_prefixlen * sizeof(struct lpm_trie_node *),
-			     GFP_ATOMIC | __GFP_NOWARN);
+	node_stack = kmalloc_array(trie->max_prefixlen,
+				   sizeof(struct lpm_trie_node *),
+				   GFP_ATOMIC | __GFP_NOWARN);
 	if (!node_stack)
 		return -ENOMEM;
 
* Unmerged path kernel/cgroup/cgroup-v1.c
* Unmerged path kernel/cpuset.c
diff --git a/kernel/debug/kdb/kdb_main.c b/kernel/debug/kdb/kdb_main.c
index 0b097c8a1e50..ef327d258405 100644
--- a/kernel/debug/kdb/kdb_main.c
+++ b/kernel/debug/kdb/kdb_main.c
@@ -685,8 +685,8 @@ static int kdb_defcmd(int argc, const char **argv)
 		kdb_printf("Command only available during kdb_init()\n");
 		return KDB_NOTIMP;
 	}
-	defcmd_set = kmalloc((defcmd_set_count + 1) * sizeof(*defcmd_set),
-			     GFP_KDB);
+	defcmd_set = kmalloc_array(defcmd_set_count + 1, sizeof(*defcmd_set),
+				   GFP_KDB);
 	if (!defcmd_set)
 		goto fail_defcmd;
 	memcpy(defcmd_set, save_defcmd_set,
@@ -2671,8 +2671,11 @@ int kdb_register_repeat(char *cmd,
 	}
 
 	if (i >= kdb_max_commands) {
-		kdbtab_t *new = kmalloc((kdb_max_commands - KDB_BASE_CMD_MAX +
-			 kdb_command_extend) * sizeof(*new), GFP_KDB);
+		kdbtab_t *new = kmalloc_array(kdb_max_commands -
+						KDB_BASE_CMD_MAX +
+						kdb_command_extend,
+					      sizeof(*new),
+					      GFP_KDB);
 		if (!new) {
 			kdb_printf("Could not allocate new kdb_command "
 				   "table\n");
* Unmerged path kernel/fail_function.c
* Unmerged path kernel/locking/locktorture.c
diff --git a/kernel/relay.c b/kernel/relay.c
index 1b2a7dc44fd9..bf24ccb3fb07 100644
--- a/kernel/relay.c
+++ b/kernel/relay.c
@@ -172,7 +172,8 @@ static struct rchan_buf *relay_create_buf(struct rchan *chan)
 	buf = kzalloc(sizeof(struct rchan_buf), GFP_KERNEL);
 	if (!buf)
 		return NULL;
-	buf->padding = kmalloc(chan->n_subbufs * sizeof(size_t *), GFP_KERNEL);
+	buf->padding = kmalloc_array(chan->n_subbufs, sizeof(size_t *),
+				     GFP_KERNEL);
 	if (!buf->padding)
 		goto free_buf;
 
* Unmerged path kernel/sched/topology.c
diff --git a/kernel/trace/ftrace.c b/kernel/trace/ftrace.c
index 6a691495c059..8c4dda1dd051 100644
--- a/kernel/trace/ftrace.c
+++ b/kernel/trace/ftrace.c
@@ -5035,9 +5035,10 @@ static int alloc_retstack_tasklist(struct ftrace_ret_stack **ret_stack_list)
 	struct task_struct *g, *t;
 
 	for (i = 0; i < FTRACE_RETSTACK_ALLOC_SIZE; i++) {
-		ret_stack_list[i] = kmalloc(FTRACE_RETFUNC_DEPTH
-					* sizeof(struct ftrace_ret_stack),
-					GFP_KERNEL);
+		ret_stack_list[i] =
+			kmalloc_array(FTRACE_RETFUNC_DEPTH,
+				      sizeof(struct ftrace_ret_stack),
+				      GFP_KERNEL);
 		if (!ret_stack_list[i]) {
 			start = 0;
 			end = i;
@@ -5109,9 +5110,9 @@ static int start_graph_tracing(void)
 	struct ftrace_ret_stack **ret_stack_list;
 	int ret, cpu;
 
-	ret_stack_list = kmalloc(FTRACE_RETSTACK_ALLOC_SIZE *
-				sizeof(struct ftrace_ret_stack *),
-				GFP_KERNEL);
+	ret_stack_list = kmalloc_array(FTRACE_RETSTACK_ALLOC_SIZE,
+				       sizeof(struct ftrace_ret_stack *),
+				       GFP_KERNEL);
 
 	if (!ret_stack_list)
 		return -ENOMEM;
@@ -5282,9 +5283,10 @@ void ftrace_graph_init_idle_task(struct task_struct *t, int cpu)
 
 		ret_stack = per_cpu(idle_ret_stack, cpu);
 		if (!ret_stack) {
-			ret_stack = kmalloc(FTRACE_RETFUNC_DEPTH
-					    * sizeof(struct ftrace_ret_stack),
-					    GFP_KERNEL);
+			ret_stack =
+				kmalloc_array(FTRACE_RETFUNC_DEPTH,
+					      sizeof(struct ftrace_ret_stack),
+					      GFP_KERNEL);
 			if (!ret_stack)
 				return;
 			per_cpu(idle_ret_stack, cpu) = ret_stack;
@@ -5303,9 +5305,9 @@ void ftrace_graph_init_task(struct task_struct *t)
 	if (ftrace_graph_active) {
 		struct ftrace_ret_stack *ret_stack;
 
-		ret_stack = kmalloc(FTRACE_RETFUNC_DEPTH
-				* sizeof(struct ftrace_ret_stack),
-				GFP_KERNEL);
+		ret_stack = kmalloc_array(FTRACE_RETFUNC_DEPTH,
+					  sizeof(struct ftrace_ret_stack),
+					  GFP_KERNEL);
 		if (!ret_stack)
 			return;
 		graph_init_task(t, ret_stack);
* Unmerged path kernel/trace/trace.c
* Unmerged path kernel/trace/trace_events_filter.c
* Unmerged path kernel/user_namespace.c
diff --git a/lib/argv_split.c b/lib/argv_split.c
index e927ed0e18a8..90c2f7148998 100644
--- a/lib/argv_split.c
+++ b/lib/argv_split.c
@@ -68,7 +68,7 @@ char **argv_split(gfp_t gfp, const char *str, int *argcp)
 		return NULL;
 
 	argc = count_argc(argv_str);
-	argv = kmalloc(sizeof(*argv) * (argc + 2), gfp);
+	argv = kmalloc_array(argc + 2, sizeof(*argv), gfp);
 	if (!argv) {
 		kfree(argv_str);
 		return NULL;
* Unmerged path lib/interval_tree_test.c
diff --git a/lib/kfifo.c b/lib/kfifo.c
index 7b7f83027b7b..d1027089f121 100644
--- a/lib/kfifo.c
+++ b/lib/kfifo.c
@@ -54,7 +54,7 @@ int __kfifo_alloc(struct __kfifo *fifo, unsigned int size,
 		return -EINVAL;
 	}
 
-	fifo->data = kmalloc(size * esize, gfp_mask);
+	fifo->data = kmalloc_array(esize, size, gfp_mask);
 
 	if (!fifo->data) {
 		fifo->mask = 0;
diff --git a/lib/mpi/mpiutil.c b/lib/mpi/mpiutil.c
index 314f4dfa603e..2dbfc4c8a237 100644
--- a/lib/mpi/mpiutil.c
+++ b/lib/mpi/mpiutil.c
@@ -91,7 +91,7 @@ int mpi_resize(MPI a, unsigned nlimbs)
 		return 0;	/* no need to do it */
 
 	if (a->d) {
-		p = kmalloc(nlimbs * sizeof(mpi_limb_t), GFP_KERNEL);
+		p = kmalloc_array(nlimbs, sizeof(mpi_limb_t), GFP_KERNEL);
 		if (!p)
 			return -ENOMEM;
 		memcpy(p, a->d, a->alloced * sizeof(mpi_limb_t));
* Unmerged path lib/rbtree_test.c
* Unmerged path lib/reed_solomon/reed_solomon.c
diff --git a/lib/scatterlist.c b/lib/scatterlist.c
index 5204227d3a51..c38266421a27 100644
--- a/lib/scatterlist.c
+++ b/lib/scatterlist.c
@@ -181,7 +181,8 @@ static struct scatterlist *sg_kmalloc(unsigned int nents, gfp_t gfp_mask)
 		kmemleak_alloc(ptr, PAGE_SIZE, 1, gfp_mask);
 		return ptr;
 	} else
-		return kmalloc(nents * sizeof(struct scatterlist), gfp_mask);
+		return kmalloc_array(nents, sizeof(struct scatterlist),
+				     gfp_mask);
 }
 
 static void sg_kfree(struct scatterlist *sg, unsigned int nents)
diff --git a/mm/huge_memory.c b/mm/huge_memory.c
index 5f95a9b1998d..e24592f75c82 100644
--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@ -1376,8 +1376,8 @@ static int do_huge_pmd_wp_page_fallback(struct vm_fault *vmf,
 	unsigned long mmun_start;	/* For mmu_notifiers */
 	unsigned long mmun_end;		/* For mmu_notifiers */
 
-	pages = kmalloc(sizeof(struct page *) * HPAGE_PMD_NR,
-			GFP_KERNEL);
+	pages = kmalloc_array(HPAGE_PMD_NR, sizeof(struct page *),
+			      GFP_KERNEL);
 	if (unlikely(!pages)) {
 		ret |= VM_FAULT_OOM;
 		goto out;
diff --git a/mm/hugetlb.c b/mm/hugetlb.c
index 0f91e2c9c2c6..5f270837f1a3 100644
--- a/mm/hugetlb.c
+++ b/mm/hugetlb.c
@@ -2865,7 +2865,8 @@ static int __init hugetlb_init(void)
 	num_fault_mutexes = 1;
 #endif
 	hugetlb_fault_mutex_table =
-		kmalloc(sizeof(struct mutex) * num_fault_mutexes, GFP_KERNEL);
+		kmalloc_array(num_fault_mutexes, sizeof(struct mutex),
+			      GFP_KERNEL);
 	BUG_ON(!hugetlb_fault_mutex_table);
 
 	for (i = 0; i < num_fault_mutexes; i++)
* Unmerged path mm/slub.c
diff --git a/net/9p/protocol.c b/net/9p/protocol.c
index ab9127ec5b7a..3ccec9f47805 100644
--- a/net/9p/protocol.c
+++ b/net/9p/protocol.c
@@ -240,8 +240,9 @@ p9pdu_vreadf(struct p9_fcall *pdu, int proto_version, const char *fmt,
 								"w", nwname);
 				if (!errcode) {
 					*wnames =
-					    kmalloc(sizeof(char *) * *nwname,
-						    GFP_NOFS);
+					    kmalloc_array(*nwname,
+							  sizeof(char *),
+							  GFP_NOFS);
 					if (!*wnames)
 						errcode = -ENOMEM;
 				}
@@ -283,9 +284,9 @@ p9pdu_vreadf(struct p9_fcall *pdu, int proto_version, const char *fmt,
 				    p9pdu_readf(pdu, proto_version, "w", nwqid);
 				if (!errcode) {
 					*wqids =
-					    kmalloc(*nwqid *
-						    sizeof(struct p9_qid),
-						    GFP_NOFS);
+					    kmalloc_array(*nwqid,
+							  sizeof(struct p9_qid),
+							  GFP_NOFS);
 					if (*wqids == NULL)
 						errcode = -ENOMEM;
 				}
* Unmerged path net/9p/trans_virtio.c
diff --git a/net/atm/mpc.c b/net/atm/mpc.c
index 43b7e36ad280..8c366a5c762e 100644
--- a/net/atm/mpc.c
+++ b/net/atm/mpc.c
@@ -472,7 +472,7 @@ static const uint8_t *copy_macs(struct mpoa_client *mpc,
 		if (mpc->number_of_mps_macs != 0)
 			kfree(mpc->mps_macs);
 		mpc->number_of_mps_macs = 0;
-		mpc->mps_macs = kmalloc(num_macs * ETH_ALEN, GFP_KERNEL);
+		mpc->mps_macs = kmalloc_array(ETH_ALEN, num_macs, GFP_KERNEL);
 		if (mpc->mps_macs == NULL) {
 			pr_info("(%s) out of mem\n", mpc->dev->name);
 			return NULL;
diff --git a/net/bluetooth/hci_core.c b/net/bluetooth/hci_core.c
index 31a5b9ba6407..fa8c278c57a6 100644
--- a/net/bluetooth/hci_core.c
+++ b/net/bluetooth/hci_core.c
@@ -1242,7 +1242,7 @@ int hci_inquiry(void __user *arg)
 	/* cache_dump can't sleep. Therefore we allocate temp buffer and then
 	 * copy it to the user space.
 	 */
-	buf = kmalloc(sizeof(struct inquiry_info) * max_rsp, GFP_KERNEL);
+	buf = kmalloc_array(max_rsp, sizeof(struct inquiry_info), GFP_KERNEL);
 	if (!buf) {
 		err = -ENOMEM;
 		goto done;
diff --git a/net/bluetooth/l2cap_core.c b/net/bluetooth/l2cap_core.c
index 3657fcda68d1..36a96fd25b4e 100644
--- a/net/bluetooth/l2cap_core.c
+++ b/net/bluetooth/l2cap_core.c
@@ -332,7 +332,7 @@ static int l2cap_seq_list_init(struct l2cap_seq_list *seq_list, u16 size)
 	 */
 	alloc_size = roundup_pow_of_two(size);
 
-	seq_list->list = kmalloc(sizeof(u16) * alloc_size, GFP_KERNEL);
+	seq_list->list = kmalloc_array(alloc_size, sizeof(u16), GFP_KERNEL);
 	if (!seq_list->list)
 		return -ENOMEM;
 
* Unmerged path net/can/bcm.c
diff --git a/net/ceph/osdmap.c b/net/ceph/osdmap.c
index 46b431f7b776..5d54b92d0c47 100644
--- a/net/ceph/osdmap.c
+++ b/net/ceph/osdmap.c
@@ -1299,8 +1299,9 @@ static int set_primary_affinity(struct ceph_osdmap *map, int osd, u32 aff)
 	if (!map->osd_primary_affinity) {
 		int i;
 
-		map->osd_primary_affinity = kmalloc(map->max_osd*sizeof(u32),
-						    GFP_NOFS);
+		map->osd_primary_affinity = kmalloc_array(map->max_osd,
+							  sizeof(u32),
+							  GFP_NOFS);
 		if (!map->osd_primary_affinity)
 			return -ENOMEM;
 
diff --git a/net/ceph/pagevec.c b/net/ceph/pagevec.c
index 1b1ac7887767..1a74b54e7360 100644
--- a/net/ceph/pagevec.c
+++ b/net/ceph/pagevec.c
@@ -19,7 +19,7 @@ struct page **ceph_get_direct_page_vector(const void __user *data,
 	int got = 0;
 	int rc = 0;
 
-	pages = kmalloc(sizeof(*pages) * num_pages, GFP_NOFS);
+	pages = kmalloc_array(num_pages, sizeof(*pages), GFP_NOFS);
 	if (!pages)
 		return ERR_PTR(-ENOMEM);
 
@@ -73,7 +73,7 @@ struct page **ceph_alloc_page_vector(int num_pages, gfp_t flags)
 	struct page **pages;
 	int i;
 
-	pages = kmalloc(sizeof(*pages) * num_pages, flags);
+	pages = kmalloc_array(num_pages, sizeof(*pages), flags);
 	if (!pages)
 		return ERR_PTR(-ENOMEM);
 	for (i = 0; i < num_pages; i++) {
diff --git a/net/core/dev.c b/net/core/dev.c
index 98359d9d215d..af6634d0d538 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -8529,7 +8529,7 @@ static struct hlist_head *netdev_create_hash(void)
 	int i;
 	struct hlist_head *hash;
 
-	hash = kmalloc(sizeof(*hash) * NETDEV_HASHENTRIES, GFP_KERNEL);
+	hash = kmalloc_array(NETDEV_HASHENTRIES, sizeof(*hash), GFP_KERNEL);
 	if (hash != NULL)
 		for (i = 0; i < NETDEV_HASHENTRIES; i++)
 			INIT_HLIST_HEAD(&hash[i]);
diff --git a/net/core/ethtool.c b/net/core/ethtool.c
index 396a7c77a080..fc6154e531b3 100644
--- a/net/core/ethtool.c
+++ b/net/core/ethtool.c
@@ -1844,7 +1844,7 @@ static int ethtool_self_test(struct net_device *dev, char __user *useraddr)
 		return -EFAULT;
 
 	test.len = test_len;
-	data = kmalloc(test_len * sizeof(u64), GFP_USER);
+	data = kmalloc_array(test_len, sizeof(u64), GFP_USER);
 	if (!data)
 		return -ENOMEM;
 
diff --git a/net/dcb/dcbnl.c b/net/dcb/dcbnl.c
index e502dcb1dc28..60d0edc8eafb 100644
--- a/net/dcb/dcbnl.c
+++ b/net/dcb/dcbnl.c
@@ -988,7 +988,8 @@ static int dcbnl_build_peer_app(struct net_device *netdev, struct sk_buff* skb,
 	 */
 	err = ops->peer_getappinfo(netdev, &info, &app_count);
 	if (!err && app_count) {
-		table = kmalloc(sizeof(struct dcb_app) * app_count, GFP_KERNEL);
+		table = kmalloc_array(app_count, sizeof(struct dcb_app),
+				      GFP_KERNEL);
 		if (!table)
 			return -ENOMEM;
 
diff --git a/net/dccp/ccids/ccid2.c b/net/dccp/ccids/ccid2.c
index e1407bb19002..e661b41f737b 100644
--- a/net/dccp/ccids/ccid2.c
+++ b/net/dccp/ccids/ccid2.c
@@ -46,7 +46,8 @@ static int ccid2_hc_tx_alloc_seq(struct ccid2_hc_tx_sock *hc)
 		return -ENOMEM;
 
 	/* allocate buffer and initialize linked list */
-	seqp = kmalloc(CCID2_SEQBUF_LEN * sizeof(struct ccid2_seq), gfp_any());
+	seqp = kmalloc_array(CCID2_SEQBUF_LEN, sizeof(struct ccid2_seq),
+			     gfp_any());
 	if (seqp == NULL)
 		return -ENOMEM;
 
diff --git a/net/ipv4/route.c b/net/ipv4/route.c
index 1ca3ee23b3a6..81af139c5d7f 100644
--- a/net/ipv4/route.c
+++ b/net/ipv4/route.c
@@ -2926,7 +2926,8 @@ int __init ip_rt_init(void)
 {
 	int rc = 0;
 
-	ip_idents = kmalloc(IP_IDENTS_SZ * sizeof(*ip_idents), GFP_KERNEL);
+	ip_idents = kmalloc_array(IP_IDENTS_SZ, sizeof(*ip_idents),
+				  GFP_KERNEL);
 	if (!ip_idents)
 		panic("IP: failed to allocate ip_idents\n");
 
diff --git a/net/mac80211/main.c b/net/mac80211/main.c
index 3752519e2e15..1e280d903b44 100644
--- a/net/mac80211/main.c
+++ b/net/mac80211/main.c
@@ -765,7 +765,7 @@ static int ieee80211_init_cipher_suites(struct ieee80211_local *local)
 		if (have_mfp)
 			n_suites += 4;
 
-		suites = kmalloc(sizeof(u32) * n_suites, GFP_KERNEL);
+		suites = kmalloc_array(n_suites, sizeof(u32), GFP_KERNEL);
 		if (!suites)
 			return -ENOMEM;
 
diff --git a/net/mac80211/rc80211_minstrel.c b/net/mac80211/rc80211_minstrel.c
index 9766c1cc4b0a..7c9d817e2b04 100644
--- a/net/mac80211/rc80211_minstrel.c
+++ b/net/mac80211/rc80211_minstrel.c
@@ -596,7 +596,7 @@ minstrel_alloc_sta(void *priv, struct ieee80211_sta *sta, gfp_t gfp)
 	if (!mi->r)
 		goto error;
 
-	mi->sample_table = kmalloc(SAMPLE_COLUMNS * max_rates, gfp);
+	mi->sample_table = kmalloc_array(max_rates, SAMPLE_COLUMNS, gfp);
 	if (!mi->sample_table)
 		goto error1;
 
diff --git a/net/mac80211/rc80211_minstrel_ht.c b/net/mac80211/rc80211_minstrel_ht.c
index 4a5bdad9f303..5542d7eeabca 100644
--- a/net/mac80211/rc80211_minstrel_ht.c
+++ b/net/mac80211/rc80211_minstrel_ht.c
@@ -1317,7 +1317,7 @@ minstrel_ht_alloc_sta(void *priv, struct ieee80211_sta *sta, gfp_t gfp)
 	if (!msp->ratelist)
 		goto error;
 
-	msp->sample_table = kmalloc(SAMPLE_COLUMNS * max_rates, gfp);
+	msp->sample_table = kmalloc_array(max_rates, SAMPLE_COLUMNS, gfp);
 	if (!msp->sample_table)
 		goto error1;
 
diff --git a/net/netfilter/nf_conntrack_proto.c b/net/netfilter/nf_conntrack_proto.c
index d69e2d12b0c3..95f0826abaa2 100644
--- a/net/netfilter/nf_conntrack_proto.c
+++ b/net/netfilter/nf_conntrack_proto.c
@@ -381,7 +381,8 @@ int nf_ct_l4proto_register_one(struct nf_conntrack_l4proto *l4proto)
 		struct nf_conntrack_l4proto __rcu **proto_array;
 		int i;
 
-		proto_array = kmalloc(MAX_NF_CT_PROTO *
+		proto_array =
+			kmalloc_array(MAX_NF_CT_PROTO,
 				      sizeof(struct nf_conntrack_l4proto *),
 				      GFP_KERNEL);
 		if (proto_array == NULL) {
diff --git a/net/netfilter/nf_nat_core.c b/net/netfilter/nf_nat_core.c
index e27cb2a1f56a..aef26a03abd5 100644
--- a/net/netfilter/nf_nat_core.c
+++ b/net/netfilter/nf_nat_core.c
@@ -600,8 +600,9 @@ int nf_nat_l4proto_register(u8 l3proto, const struct nf_nat_l4proto *l4proto)
 
 	mutex_lock(&nf_nat_proto_mutex);
 	if (nf_nat_l4protos[l3proto] == NULL) {
-		l4protos = kmalloc(IPPROTO_MAX * sizeof(struct nf_nat_l4proto *),
-				   GFP_KERNEL);
+		l4protos = kmalloc_array(IPPROTO_MAX,
+					 sizeof(struct nf_nat_l4proto *),
+					 GFP_KERNEL);
 		if (l4protos == NULL) {
 			ret = -ENOMEM;
 			goto out;
* Unmerged path net/netfilter/nf_tables_api.c
diff --git a/net/netfilter/x_tables.c b/net/netfilter/x_tables.c
index aba72ac7a97f..1f9a2926c268 100644
--- a/net/netfilter/x_tables.c
+++ b/net/netfilter/x_tables.c
@@ -1703,7 +1703,7 @@ static int __init xt_init(void)
 		seqcount_init(&per_cpu(xt_recseq, i));
 	}
 
-	xt = kmalloc(sizeof(struct xt_af) * NFPROTO_NUMPROTO, GFP_KERNEL);
+	xt = kmalloc_array(NFPROTO_NUMPROTO, sizeof(struct xt_af), GFP_KERNEL);
 	if (!xt)
 		return -ENOMEM;
 
diff --git a/net/netlink/genetlink.c b/net/netlink/genetlink.c
index 5b8aee764473..6ed027146c36 100644
--- a/net/netlink/genetlink.c
+++ b/net/netlink/genetlink.c
@@ -363,8 +363,9 @@ int genl_register_family(struct genl_family *family)
 	}
 
 	if (family->maxattr && !family->parallel_ops) {
-		family->attrbuf = kmalloc((family->maxattr+1) *
-					sizeof(struct nlattr *), GFP_KERNEL);
+		family->attrbuf = kmalloc_array(family->maxattr + 1,
+						sizeof(struct nlattr *),
+						GFP_KERNEL);
 		if (family->attrbuf == NULL) {
 			err = -ENOMEM;
 			goto errout_locked;
@@ -565,8 +566,9 @@ static int genl_family_rcv_msg(const struct genl_family *family,
 		return -EOPNOTSUPP;
 
 	if (family->maxattr && family->parallel_ops) {
-		attrbuf = kmalloc((family->maxattr+1) *
-					sizeof(struct nlattr *), GFP_KERNEL);
+		attrbuf = kmalloc_array(family->maxattr + 1,
+					sizeof(struct nlattr *),
+					GFP_KERNEL);
 		if (attrbuf == NULL)
 			return -ENOMEM;
 	} else
diff --git a/net/openvswitch/datapath.c b/net/openvswitch/datapath.c
index 252adfb6fc0b..d54d9e473e46 100644
--- a/net/openvswitch/datapath.c
+++ b/net/openvswitch/datapath.c
@@ -1605,8 +1605,9 @@ static int ovs_dp_cmd_new(struct sk_buff *skb, struct genl_info *info)
 		goto err_destroy_table;
 	}
 
-	dp->ports = kmalloc(DP_VPORT_HASH_BUCKETS * sizeof(struct hlist_head),
-			    GFP_KERNEL);
+	dp->ports = kmalloc_array(DP_VPORT_HASH_BUCKETS,
+				  sizeof(struct hlist_head),
+				  GFP_KERNEL);
 	if (!dp->ports) {
 		err = -ENOMEM;
 		goto err_destroy_percpu;
diff --git a/net/rds/info.c b/net/rds/info.c
index 140a44a5f7b7..e367a97a18c8 100644
--- a/net/rds/info.c
+++ b/net/rds/info.c
@@ -188,7 +188,7 @@ int rds_info_getsockopt(struct socket *sock, int optname, char __user *optval,
 	nr_pages = (PAGE_ALIGN(start + len) - (start & PAGE_MASK))
 			>> PAGE_SHIFT;
 
-	pages = kmalloc(nr_pages * sizeof(struct page *), GFP_KERNEL);
+	pages = kmalloc_array(nr_pages, sizeof(struct page *), GFP_KERNEL);
 	if (!pages) {
 		ret = -ENOMEM;
 		goto out;
diff --git a/net/rxrpc/rxkad.c b/net/rxrpc/rxkad.c
index f226709ebd8f..2f0c85b489d1 100644
--- a/net/rxrpc/rxkad.c
+++ b/net/rxrpc/rxkad.c
@@ -424,7 +424,7 @@ static int rxkad_verify_packet_encrypt(const struct rxrpc_call *call,
 
 	sg = _sg;
 	if (unlikely(nsg > 4)) {
-		sg = kmalloc(sizeof(*sg) * nsg, GFP_NOIO);
+		sg = kmalloc_array(nsg, sizeof(*sg), GFP_NOIO);
 		if (!sg)
 			goto nomem;
 	}
diff --git a/net/sctp/protocol.c b/net/sctp/protocol.c
index c64d8635d1b6..1ebbb20df43a 100644
--- a/net/sctp/protocol.c
+++ b/net/sctp/protocol.c
@@ -1447,7 +1447,7 @@ static __init int sctp_init(void)
 	/* Allocate and initialize the endpoint hash table.  */
 	sctp_ep_hashsize = 64;
 	sctp_ep_hashtable =
-		kmalloc(64 * sizeof(struct sctp_hashbucket), GFP_KERNEL);
+		kmalloc_array(64, sizeof(struct sctp_hashbucket), GFP_KERNEL);
 	if (!sctp_ep_hashtable) {
 		pr_err("Failed endpoint_hash alloc\n");
 		status = -ENOMEM;
diff --git a/net/sunrpc/auth_gss/auth_gss.c b/net/sunrpc/auth_gss/auth_gss.c
index dedff7eb7d09..bd712d33e476 100644
--- a/net/sunrpc/auth_gss/auth_gss.c
+++ b/net/sunrpc/auth_gss/auth_gss.c
@@ -1753,7 +1753,8 @@ alloc_enc_pages(struct rpc_rqst *rqstp)
 	last = (snd_buf->page_base + snd_buf->page_len - 1) >> PAGE_CACHE_SHIFT;
 	rqstp->rq_enc_pages_num = last - first + 1 + 1;
 	rqstp->rq_enc_pages
-		= kmalloc(rqstp->rq_enc_pages_num * sizeof(struct page *),
+		= kmalloc_array(rqstp->rq_enc_pages_num,
+				sizeof(struct page *),
 				GFP_NOFS);
 	if (!rqstp->rq_enc_pages)
 		goto out;
* Unmerged path net/tipc/netlink_compat.c
diff --git a/security/keys/trusted.c b/security/keys/trusted.c
index d54e6c0fb9db..833936520e0c 100644
--- a/security/keys/trusted.c
+++ b/security/keys/trusted.c
@@ -1148,7 +1148,7 @@ static long trusted_read(const struct key *key, char __user *buffer,
 		return -EINVAL;
 
 	if (buffer && buflen >= 2 * p->blob_len) {
-		ascii_buf = kmalloc(2 * p->blob_len, GFP_KERNEL);
+		ascii_buf = kmalloc_array(2, p->blob_len, GFP_KERNEL);
 		if (!ascii_buf)
 			return -ENOMEM;
 
diff --git a/sound/core/pcm_compat.c b/sound/core/pcm_compat.c
index 39d853bfa5ac..946ab080ac00 100644
--- a/sound/core/pcm_compat.c
+++ b/sound/core/pcm_compat.c
@@ -426,7 +426,7 @@ static int snd_pcm_ioctl_xfern_compat(struct snd_pcm_substream *substream,
 	    get_user(frames, &data32->frames))
 		return -EFAULT;
 	bufptr = compat_ptr(buf);
-	bufs = kmalloc(sizeof(void __user *) * ch, GFP_KERNEL);
+	bufs = kmalloc_array(ch, sizeof(void __user *), GFP_KERNEL);
 	if (bufs == NULL)
 		return -ENOMEM;
 	for (i = 0; i < ch; i++) {
* Unmerged path sound/core/pcm_native.c
diff --git a/sound/core/seq/seq_midi_emul.c b/sound/core/seq/seq_midi_emul.c
index ce780658bbcc..c1975dd31871 100644
--- a/sound/core/seq/seq_midi_emul.c
+++ b/sound/core/seq/seq_midi_emul.c
@@ -657,7 +657,7 @@ static struct snd_midi_channel *snd_midi_channel_init_set(int n)
 	struct snd_midi_channel *chan;
 	int  i;
 
-	chan = kmalloc(n * sizeof(struct snd_midi_channel), GFP_KERNEL);
+	chan = kmalloc_array(n, sizeof(struct snd_midi_channel), GFP_KERNEL);
 	if (chan) {
 		for (i = 0; i < n; i++)
 			snd_midi_channel_init(chan+i, i);
diff --git a/sound/firewire/packets-buffer.c b/sound/firewire/packets-buffer.c
index ea1506679c66..1ebf00c83409 100644
--- a/sound/firewire/packets-buffer.c
+++ b/sound/firewire/packets-buffer.c
@@ -27,7 +27,7 @@ int iso_packets_buffer_init(struct iso_packets_buffer *b, struct fw_unit *unit,
 	void *p;
 	int err;
 
-	b->packets = kmalloc(count * sizeof(*b->packets), GFP_KERNEL);
+	b->packets = kmalloc_array(count, sizeof(*b->packets), GFP_KERNEL);
 	if (!b->packets) {
 		err = -ENOMEM;
 		goto error;
diff --git a/sound/oss/dmasound/dmasound_core.c b/sound/oss/dmasound/dmasound_core.c
index bac43b5b6e95..840755ccd4bf 100644
--- a/sound/oss/dmasound/dmasound_core.c
+++ b/sound/oss/dmasound/dmasound_core.c
@@ -419,7 +419,7 @@ static int sq_allocate_buffers(struct sound_queue *sq, int num, int size)
 		return 0;
 	sq->numBufs = num;
 	sq->bufSize = size;
-	sq->buffers = kmalloc (num * sizeof(char *), GFP_KERNEL);
+	sq->buffers = kmalloc_array (num, sizeof(char *), GFP_KERNEL);
 	if (!sq->buffers)
 		return -ENOMEM;
 	for (i = 0; i < num; i++) {
* Unmerged path sound/pci/cs46xx/cs46xx_lib.c
diff --git a/sound/pci/cs46xx/dsp_spos.c b/sound/pci/cs46xx/dsp_spos.c
index aa61615288ff..a784b5287bac 100644
--- a/sound/pci/cs46xx/dsp_spos.c
+++ b/sound/pci/cs46xx/dsp_spos.c
@@ -243,7 +243,9 @@ struct dsp_spos_instance *cs46xx_dsp_spos_create (struct snd_cs46xx * chip)
 	ins->symbol_table.symbols = vmalloc(sizeof(struct dsp_symbol_entry) *
 					    DSP_MAX_SYMBOLS);
 	ins->code.data = kmalloc(DSP_CODE_BYTE_SIZE, GFP_KERNEL);
-	ins->modules = kmalloc(sizeof(struct dsp_module_desc) * DSP_MAX_MODULES, GFP_KERNEL);
+	ins->modules = kmalloc_array(DSP_MAX_MODULES,
+				     sizeof(struct dsp_module_desc),
+				     GFP_KERNEL);
 	if (!ins->symbol_table.symbols || !ins->code.data || !ins->modules) {
 		cs46xx_dsp_spos_destroy(chip);
 		goto error;
diff --git a/sound/pci/emu10k1/emufx.c b/sound/pci/emu10k1/emufx.c
index 736c30435953..41321aabbc98 100644
--- a/sound/pci/emu10k1/emufx.c
+++ b/sound/pci/emu10k1/emufx.c
@@ -2684,12 +2684,12 @@ int snd_emu10k1_efx_alloc_pm_buffer(struct snd_emu10k1 *emu)
 	int len;
 
 	len = emu->audigy ? 0x200 : 0x100;
-	emu->saved_gpr = kmalloc(len * 4, GFP_KERNEL);
+	emu->saved_gpr = kmalloc_array(len, 4, GFP_KERNEL);
 	if (! emu->saved_gpr)
 		return -ENOMEM;
 	len = emu->audigy ? 0x100 : 0xa0;
-	emu->tram_val_saved = kmalloc(len * 4, GFP_KERNEL);
-	emu->tram_addr_saved = kmalloc(len * 4, GFP_KERNEL);
+	emu->tram_val_saved = kmalloc_array(len, 4, GFP_KERNEL);
+	emu->tram_addr_saved = kmalloc_array(len, 4, GFP_KERNEL);
 	if (! emu->tram_val_saved || ! emu->tram_addr_saved)
 		return -ENOMEM;
 	len = emu->audigy ? 2 * 1024 : 2 * 512;
diff --git a/sound/pci/hda/hda_codec.c b/sound/pci/hda/hda_codec.c
index 63f177d975fd..7265ed842671 100644
--- a/sound/pci/hda/hda_codec.c
+++ b/sound/pci/hda/hda_codec.c
@@ -158,7 +158,7 @@ static int read_and_add_raw_conns(struct hda_codec *codec, hda_nid_t nid)
 	len = snd_hda_get_raw_connections(codec, nid, list, ARRAY_SIZE(list));
 	if (len == -ENOSPC) {
 		len = snd_hda_get_num_raw_conns(codec, nid);
-		result = kmalloc(sizeof(hda_nid_t) * len, GFP_KERNEL);
+		result = kmalloc_array(len, sizeof(hda_nid_t), GFP_KERNEL);
 		if (!result)
 			return -ENOMEM;
 		len = snd_hda_get_raw_connections(codec, nid, result, len);
@@ -438,7 +438,7 @@ static int read_widget_caps(struct hda_codec *codec, hda_nid_t fg_node)
 	int i;
 	hda_nid_t nid;
 
-	codec->wcaps = kmalloc(codec->core.num_nodes * 4, GFP_KERNEL);
+	codec->wcaps = kmalloc_array(codec->core.num_nodes, 4, GFP_KERNEL);
 	if (!codec->wcaps)
 		return -ENOMEM;
 	nid = codec->core.start_nid;
diff --git a/sound/pci/hda/hda_proc.c b/sound/pci/hda/hda_proc.c
index 033aa84365b9..c6b778b2580c 100644
--- a/sound/pci/hda/hda_proc.c
+++ b/sound/pci/hda/hda_proc.c
@@ -825,8 +825,9 @@ static void print_codec_info(struct snd_info_entry *entry,
 		if (wid_caps & AC_WCAP_CONN_LIST) {
 			conn_len = snd_hda_get_num_raw_conns(codec, nid);
 			if (conn_len > 0) {
-				conn = kmalloc(sizeof(hda_nid_t) * conn_len,
-					       GFP_KERNEL);
+				conn = kmalloc_array(conn_len,
+						     sizeof(hda_nid_t),
+						     GFP_KERNEL);
 				if (!conn)
 					return;
 				if (snd_hda_get_raw_connections(codec, nid, conn,
diff --git a/sound/pci/via82xx.c b/sound/pci/via82xx.c
index 0007f6aa8369..26643a125e7b 100644
--- a/sound/pci/via82xx.c
+++ b/sound/pci/via82xx.c
@@ -439,7 +439,9 @@ static int build_via_table(struct viadev *dev, struct snd_pcm_substream *substre
 			return -ENOMEM;
 	}
 	if (! dev->idx_table) {
-		dev->idx_table = kmalloc(sizeof(*dev->idx_table) * VIA_TABLE_SIZE, GFP_KERNEL);
+		dev->idx_table = kmalloc_array(VIA_TABLE_SIZE,
+					       sizeof(*dev->idx_table),
+					       GFP_KERNEL);
 		if (! dev->idx_table)
 			return -ENOMEM;
 	}
diff --git a/sound/pci/via82xx_modem.c b/sound/pci/via82xx_modem.c
index 8a69221c1b86..b13c8688cc8d 100644
--- a/sound/pci/via82xx_modem.c
+++ b/sound/pci/via82xx_modem.c
@@ -292,7 +292,9 @@ static int build_via_table(struct viadev *dev, struct snd_pcm_substream *substre
 			return -ENOMEM;
 	}
 	if (! dev->idx_table) {
-		dev->idx_table = kmalloc(sizeof(*dev->idx_table) * VIA_TABLE_SIZE, GFP_KERNEL);
+		dev->idx_table = kmalloc_array(VIA_TABLE_SIZE,
+					       sizeof(*dev->idx_table),
+					       GFP_KERNEL);
 		if (! dev->idx_table)
 			return -ENOMEM;
 	}
diff --git a/sound/pci/ymfpci/ymfpci_main.c b/sound/pci/ymfpci/ymfpci_main.c
index db8965bb4f4d..34a0a7cd0ed0 100644
--- a/sound/pci/ymfpci/ymfpci_main.c
+++ b/sound/pci/ymfpci/ymfpci_main.c
@@ -2435,8 +2435,8 @@ int snd_ymfpci_create(struct snd_card *card,
 		goto free_chip;
 
 #ifdef CONFIG_PM_SLEEP
-	chip->saved_regs = kmalloc(YDSXGR_NUM_SAVED_REGS * sizeof(u32),
-				   GFP_KERNEL);
+	chip->saved_regs = kmalloc_array(YDSXGR_NUM_SAVED_REGS, sizeof(u32),
+					 GFP_KERNEL);
 	if (chip->saved_regs == NULL) {
 		err = -ENOMEM;
 		goto free_chip;
* Unmerged path sound/soc/codecs/wm8904.c
* Unmerged path sound/soc/codecs/wm8958-dsp2.c
diff --git a/sound/usb/caiaq/audio.c b/sound/usb/caiaq/audio.c
index fb1c1eac0b5e..f35d29f49ffe 100644
--- a/sound/usb/caiaq/audio.c
+++ b/sound/usb/caiaq/audio.c
@@ -728,7 +728,7 @@ static struct urb **alloc_urbs(struct snd_usb_caiaqdev *cdev, int dir, int *ret)
 		usb_sndisocpipe(usb_dev, ENDPOINT_PLAYBACK) :
 		usb_rcvisocpipe(usb_dev, ENDPOINT_CAPTURE);
 
-	urbs = kmalloc(N_URBS * sizeof(*urbs), GFP_KERNEL);
+	urbs = kmalloc_array(N_URBS, sizeof(*urbs), GFP_KERNEL);
 	if (!urbs) {
 		*ret = -ENOMEM;
 		return NULL;
@@ -742,7 +742,8 @@ static struct urb **alloc_urbs(struct snd_usb_caiaqdev *cdev, int dir, int *ret)
 		}
 
 		urbs[i]->transfer_buffer =
-			kmalloc(FRAMES_PER_URB * BYTES_PER_FRAME, GFP_KERNEL);
+			kmalloc_array(BYTES_PER_FRAME, FRAMES_PER_URB,
+				      GFP_KERNEL);
 		if (!urbs[i]->transfer_buffer) {
 			*ret = -ENOMEM;
 			return urbs;
@@ -857,7 +858,7 @@ int snd_usb_caiaq_audio_init(struct snd_usb_caiaqdev *cdev)
 				&snd_usb_caiaq_ops);
 
 	cdev->data_cb_info =
-		kmalloc(sizeof(struct snd_usb_caiaq_cb_info) * N_URBS,
+		kmalloc_array(N_URBS, sizeof(struct snd_usb_caiaq_cb_info),
 					GFP_KERNEL);
 
 	if (!cdev->data_cb_info)
diff --git a/sound/usb/format.c b/sound/usb/format.c
index 49e7ec6d2399..1f7a74a77ea3 100644
--- a/sound/usb/format.c
+++ b/sound/usb/format.c
@@ -188,7 +188,8 @@ static int parse_audio_format_rates_v1(struct snd_usb_audio *chip, struct audiof
 		 */
 		int r, idx;
 
-		fp->rate_table = kmalloc(sizeof(int) * nr_rates, GFP_KERNEL);
+		fp->rate_table = kmalloc_array(nr_rates, sizeof(int),
+					       GFP_KERNEL);
 		if (fp->rate_table == NULL)
 			return -ENOMEM;
 
@@ -362,7 +363,7 @@ static int parse_audio_format_rates_v2v3(struct snd_usb_audio *chip,
 		goto err_free;
 	}
 
-	fp->rate_table = kmalloc(sizeof(int) * fp->nr_rates, GFP_KERNEL);
+	fp->rate_table = kmalloc_array(fp->nr_rates, sizeof(int), GFP_KERNEL);
 	if (!fp->rate_table) {
 		ret = -ENOMEM;
 		goto err_free;
diff --git a/sound/usb/line6/pcm.c b/sound/usb/line6/pcm.c
index b3854f8c0c67..72c6f8e82a7e 100644
--- a/sound/usb/line6/pcm.c
+++ b/sound/usb/line6/pcm.c
@@ -158,8 +158,10 @@ static int line6_buffer_acquire(struct snd_line6_pcm *line6pcm,
 
 	/* Invoked multiple times in a row so allocate once only */
 	if (!test_and_set_bit(type, &pstr->opened) && !pstr->buffer) {
-		pstr->buffer = kmalloc(line6pcm->line6->iso_buffers *
-				       LINE6_ISO_PACKETS * pkt_size, GFP_KERNEL);
+		pstr->buffer =
+			kmalloc(array3_size(line6pcm->line6->iso_buffers,
+					    LINE6_ISO_PACKETS, pkt_size),
+				GFP_KERNEL);
 		if (!pstr->buffer)
 			return -ENOMEM;
 	}
diff --git a/sound/usb/mixer.c b/sound/usb/mixer.c
index 76417943ff85..d2c92c1f88c0 100644
--- a/sound/usb/mixer.c
+++ b/sound/usb/mixer.c
@@ -2331,7 +2331,7 @@ static int parse_audio_selector_unit(struct mixer_build *state, int unitid,
 		cval->control = (desc->bDescriptorSubtype == UAC2_CLOCK_SELECTOR) ?
 			UAC2_CX_CLOCK_SELECTOR : UAC2_SU_SELECTOR;
 
-	namelist = kmalloc(sizeof(char *) * desc->bNrInPins, GFP_KERNEL);
+	namelist = kmalloc_array(desc->bNrInPins, sizeof(char *), GFP_KERNEL);
 	if (!namelist) {
 		kfree(cval);
 		return -ENOMEM;
diff --git a/sound/usb/pcm.c b/sound/usb/pcm.c
index dc2dfec9effd..9accf02b56bb 100644
--- a/sound/usb/pcm.c
+++ b/sound/usb/pcm.c
@@ -1114,7 +1114,7 @@ static int snd_usb_pcm_check_knot(struct snd_pcm_runtime *runtime,
 		return 0;
 
 	subs->rate_list.list = rate_list =
-		kmalloc(sizeof(int) * count, GFP_KERNEL);
+		kmalloc_array(count, sizeof(int), GFP_KERNEL);
 	if (!subs->rate_list.list)
 		return -ENOMEM;
 	subs->rate_list.count = count;
diff --git a/sound/usb/usx2y/usbusx2y.c b/sound/usb/usx2y/usbusx2y.c
index 4569c0efac0a..0ade18f56b4e 100644
--- a/sound/usb/usx2y/usbusx2y.c
+++ b/sound/usb/usx2y/usbusx2y.c
@@ -266,7 +266,9 @@ int usX2Y_AsyncSeq04_init(struct usX2Ydev *usX2Y)
 	int	err = 0,
 		i;
 
-	if (NULL == (usX2Y->AS04.buffer = kmalloc(URB_DataLen_AsyncSeq*URBS_AsyncSeq, GFP_KERNEL))) {
+	usX2Y->AS04.buffer = kmalloc_array(URBS_AsyncSeq,
+					   URB_DataLen_AsyncSeq, GFP_KERNEL);
+	if (NULL == usX2Y->AS04.buffer) {
 		err = -ENOMEM;
 	} else
 		for (i = 0; i < URBS_AsyncSeq; ++i) {
diff --git a/sound/usb/usx2y/usbusx2yaudio.c b/sound/usb/usx2y/usbusx2yaudio.c
index f93b355756e6..5a8e4294758c 100644
--- a/sound/usb/usx2y/usbusx2yaudio.c
+++ b/sound/usb/usx2y/usbusx2yaudio.c
@@ -436,7 +436,9 @@ static int usX2Y_urbs_allocate(struct snd_usX2Y_substream *subs)
 		}
 		if (!is_playback && !(*purb)->transfer_buffer) {
 			/* allocate a capture buffer per urb */
-			(*purb)->transfer_buffer = kmalloc(subs->maxpacksize * nr_of_packs(), GFP_KERNEL);
+			(*purb)->transfer_buffer =
+				kmalloc_array(subs->maxpacksize,
+					      nr_of_packs(), GFP_KERNEL);
 			if (NULL == (*purb)->transfer_buffer) {
 				usX2Y_urbs_release(subs);
 				return -ENOMEM;
@@ -662,7 +664,8 @@ static int usX2Y_rate_set(struct usX2Ydev *usX2Y, int rate)
 			err = -ENOMEM;
 			goto cleanup;
 		}
-		usbdata = kmalloc(sizeof(int) * NOOF_SETRATE_URBS, GFP_KERNEL);
+		usbdata = kmalloc_array(NOOF_SETRATE_URBS, sizeof(int),
+					GFP_KERNEL);
 		if (NULL == usbdata) {
 			err = -ENOMEM;
 			goto cleanup;
