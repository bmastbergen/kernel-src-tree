proc/stat: Make the interrupt statistics more efficient

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Thomas Gleixner <tglx@linutronix.de>
commit c2da3f1b711173b72378258496b49f74db7479de
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/c2da3f1b.failed

Waiman reported that on large systems with a large amount of interrupts the
readout of /proc/stat takes a long time to sum up the interrupt
statistics. In principle this is not a problem. but for unknown reasons
some enterprise quality software reads /proc/stat with a high frequency.

The reason for this is that interrupt statistics are accounted per cpu. So
the /proc/stat logic has to sum up the interrupt stats for each interrupt.

The interrupt core provides now a per interrupt summary counter which can
be used to avoid the summation loops completely except for interrupts
marked PER_CPU which are only a small fraction of the interrupt space if at
all.

Another simplification is to iterate only over the active interrupts and
skip the potentially large gaps in the interrupt number space and just
print zeros for the gaps without going into the interrupt core in the first
place.

Waiman provided test results from a 4-socket IvyBridge-EX system (60-core
120-thread, 3016 irqs) excuting a test program which reads /proc/stat
50,000 times:

   Before: 18.436s (sys 18.380s)
   After:   3.769s (sys  3.742s)

	Reported-by: Waiman Long <longman@redhat.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Reviewed-by: Alexey Dobriyan <adobriyan@gmail.com>
	Reviewed-by: Waiman Long <longman@redhat.com>
	Reviewed-by: Marc Zyngier <marc.zyngier@arm.com>
	Reviewed-by: Davidlohr Bueso <dbueso@suse.de>
	Cc: Matthew Wilcox <willy@infradead.org>
	Cc: Andrew Morton <akpm@linux-foundation.org>
	Cc: Kees Cook <keescook@chromium.org>
	Cc: linux-fsdevel@vger.kernel.org
	Cc: Davidlohr Bueso <dave@stgolabs.net>
	Cc: Miklos Szeredi <miklos@szeredi.hu>
	Cc: Daniel Colascione <dancol@google.com>
	Cc: Dave Chinner <david@fromorbit.com>
	Cc: Randy Dunlap <rdunlap@infradead.org>
Link: https://lkml.kernel.org/r/20190208135021.013828701@linutronix.de

(cherry picked from commit c2da3f1b711173b72378258496b49f74db7479de)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/proc/stat.c
diff --cc fs/proc/stat.c
index 89e115d84eeb,76175211b304..000000000000
--- a/fs/proc/stat.c
+++ b/fs/proc/stat.c
@@@ -143,23 -167,21 +168,27 @@@ static int show_stat(struct seq_file *p
  		guest = kcpustat_cpu(i).cpustat[CPUTIME_GUEST];
  		guest_nice = kcpustat_cpu(i).cpustat[CPUTIME_GUEST_NICE];
  		seq_printf(p, "cpu%d", i);
 -		seq_put_decimal_ull(p, " ", nsec_to_clock_t(user));
 -		seq_put_decimal_ull(p, " ", nsec_to_clock_t(nice));
 -		seq_put_decimal_ull(p, " ", nsec_to_clock_t(system));
 -		seq_put_decimal_ull(p, " ", nsec_to_clock_t(idle));
 -		seq_put_decimal_ull(p, " ", nsec_to_clock_t(iowait));
 -		seq_put_decimal_ull(p, " ", nsec_to_clock_t(irq));
 -		seq_put_decimal_ull(p, " ", nsec_to_clock_t(softirq));
 -		seq_put_decimal_ull(p, " ", nsec_to_clock_t(steal));
 -		seq_put_decimal_ull(p, " ", nsec_to_clock_t(guest));
 -		seq_put_decimal_ull(p, " ", nsec_to_clock_t(guest_nice));
 +		seq_put_decimal_ull(p, ' ', cputime64_to_clock_t(user));
 +		seq_put_decimal_ull(p, ' ', cputime64_to_clock_t(nice));
 +		seq_put_decimal_ull(p, ' ', cputime64_to_clock_t(system));
 +		seq_put_decimal_ull(p, ' ', cputime64_to_clock_t(idle));
 +		seq_put_decimal_ull(p, ' ', cputime64_to_clock_t(iowait));
 +		seq_put_decimal_ull(p, ' ', cputime64_to_clock_t(irq));
 +		seq_put_decimal_ull(p, ' ', cputime64_to_clock_t(softirq));
 +		seq_put_decimal_ull(p, ' ', cputime64_to_clock_t(steal));
 +		seq_put_decimal_ull(p, ' ', cputime64_to_clock_t(guest));
 +		seq_put_decimal_ull(p, ' ', cputime64_to_clock_t(guest_nice));
  		seq_putc(p, '\n');
  	}
 -	seq_put_decimal_ull(p, "intr ", (unsigned long long)sum);
 +	seq_printf(p, "intr %llu", (unsigned long long)sum);
  
++<<<<<<< HEAD
 +	/* sum again ? it could be updated? */
 +	for_each_irq_nr(j)
 +		seq_put_decimal_ull(p, ' ', kstat_irqs(j));
++=======
+ 	show_all_irqs(p);
++>>>>>>> c2da3f1b7111 (proc/stat: Make the interrupt statistics more efficient)
  
  	seq_printf(p,
  		"\nctxt %llu\n"
* Unmerged path fs/proc/stat.c
