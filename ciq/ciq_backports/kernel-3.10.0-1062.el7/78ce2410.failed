x86/MCE/AMD: Cache SMCA MISC block addresses

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
Rebuild_CHGLOG: - [x86] mce/amd: Cache SMCA MISC block addresses (Gary Hook) [1685269]
Rebuild_FUZZ: 95.24%
commit-author Borislav Petkov <bp@suse.de>
commit 78ce241099bb363b19dbd0245442e66c8de8f567
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/78ce2410.failed

... into a global, two-dimensional array and service subsequent reads from
that cache to avoid rdmsr_on_cpu() calls during CPU hotplug (IPIs with IRQs
disabled).

In addition, this fixes a KASAN slab-out-of-bounds read due to wrong usage
of the bank->blocks pointer.

Fixes: 27bd59502702 ("x86/mce/AMD: Get address from already initialized block")
	Reported-by: Johannes Hirte <johannes.hirte@datenkhaos.de>
	Tested-by: Johannes Hirte <johannes.hirte@datenkhaos.de>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: Yazen Ghannam <yazen.ghannam@amd.com>
Link: http://lkml.kernel.org/r/20180414004230.GA2033@probook
(cherry picked from commit 78ce241099bb363b19dbd0245442e66c8de8f567)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/mcheck/mce_amd.c
diff --cc arch/x86/kernel/cpu/mcheck/mce_amd.c
index 6cf441f79966,c8e038800591..000000000000
--- a/arch/x86/kernel/cpu/mcheck/mce_amd.c
+++ b/arch/x86/kernel/cpu/mcheck/mce_amd.c
@@@ -84,9 -93,30 +84,35 @@@ struct smca_bank_name smca_names[] = 
  	[SMCA_PSP]	= { "psp",		"Platform Security Processor" },
  	[SMCA_SMU]	= { "smu",		"System Management Unit" },
  };
 +EXPORT_SYMBOL_GPL(smca_names);
  
++<<<<<<< HEAD
 +static enum smca_bank_types smca_get_bank_type(struct mce *m)
++=======
+ static u32 smca_bank_addrs[MAX_NR_BANKS][NR_BLOCKS] __ro_after_init =
+ {
+ 	[0 ... MAX_NR_BANKS - 1] = { [0 ... NR_BLOCKS - 1] = -1 }
+ };
+ 
+ const char *smca_get_name(enum smca_bank_types t)
+ {
+ 	if (t >= N_SMCA_BANK_TYPES)
+ 		return NULL;
+ 
+ 	return smca_names[t].name;
+ }
+ 
+ const char *smca_get_long_name(enum smca_bank_types t)
+ {
+ 	if (t >= N_SMCA_BANK_TYPES)
+ 		return NULL;
+ 
+ 	return smca_names[t].long_name;
+ }
+ EXPORT_SYMBOL_GPL(smca_get_long_name);
+ 
+ static enum smca_bank_types smca_get_bank_type(unsigned int bank)
++>>>>>>> 78ce241099bb (x86/MCE/AMD: Cache SMCA MISC block addresses)
  {
  	struct smca_bank *b;
  
@@@ -369,6 -436,41 +395,44 @@@ static void deferred_error_interrupt_en
  	wrmsr(MSR_CU_DEF_ERR, low, high);
  }
  
++<<<<<<< HEAD
++=======
+ static u32 smca_get_block_address(unsigned int cpu, unsigned int bank,
+ 				  unsigned int block)
+ {
+ 	u32 low, high;
+ 	u32 addr = 0;
+ 
+ 	if (smca_get_bank_type(bank) == SMCA_RESERVED)
+ 		return addr;
+ 
+ 	if (!block)
+ 		return MSR_AMD64_SMCA_MCx_MISC(bank);
+ 
+ 	/* Check our cache first: */
+ 	if (smca_bank_addrs[bank][block] != -1)
+ 		return smca_bank_addrs[bank][block];
+ 
+ 	/*
+ 	 * For SMCA enabled processors, BLKPTR field of the first MISC register
+ 	 * (MCx_MISC0) indicates presence of additional MISC regs set (MISC1-4).
+ 	 */
+ 	if (rdmsr_safe_on_cpu(cpu, MSR_AMD64_SMCA_MCx_CONFIG(bank), &low, &high))
+ 		goto out;
+ 
+ 	if (!(low & MCI_CONFIG_MCAX))
+ 		goto out;
+ 
+ 	if (!rdmsr_safe_on_cpu(cpu, MSR_AMD64_SMCA_MCx_MISC(bank), &low, &high) &&
+ 	    (low & MASK_BLKPTR_LO))
+ 		addr = MSR_AMD64_SMCA_MCx_MISCy(bank, block - 1);
+ 
+ out:
+ 	smca_bank_addrs[bank][block] = addr;
+ 	return addr;
+ }
+ 
++>>>>>>> 78ce241099bb (x86/MCE/AMD: Cache SMCA MISC block addresses)
  static u32 get_block_address(unsigned int cpu, u32 current_addr, u32 low, u32 high,
  			     unsigned int bank, unsigned int block)
  {
@@@ -377,41 -479,8 +441,46 @@@
  	if ((bank >= mca_cfg.banks) || (block >= NR_BLOCKS))
  		return addr;
  
++<<<<<<< HEAD
 +	/* Get address from already initialized block. */
 +	if (per_cpu(threshold_banks, cpu)) {
 +		struct threshold_bank *bankp = per_cpu(threshold_banks, cpu)[bank];
 +
 +		if (bankp && bankp->blocks) {
 +			struct threshold_block *blockp = &bankp->blocks[block];
 +
 +			if (blockp)
 +				return blockp->address;
 +		}
 +	}
 +
 +	if (mce_flags.smca) {
 +		if (!block) {
 +			addr = MSR_AMD64_SMCA_MCx_MISC(bank);
 +		} else {
 +			/*
 +			 * For SMCA enabled processors, BLKPTR field of the
 +			 * first MISC register (MCx_MISC0) indicates presence of
 +			 * additional MISC register set (MISC1-4).
 +			 */
 +			u32 low, high;
 +
 +			if (rdmsr_safe_on_cpu(cpu, MSR_AMD64_SMCA_MCx_CONFIG(bank), &low, &high))
 +				return addr;
 +
 +			if (!(low & MCI_CONFIG_MCAX))
 +				return addr;
 +
 +			if (!rdmsr_safe_on_cpu(cpu, MSR_AMD64_SMCA_MCx_MISC(bank), &low, &high) &&
 +			    (low & MASK_BLKPTR_LO))
 +				addr = MSR_AMD64_SMCA_MCx_MISCy(bank, block - 1);
 +		}
 +		return addr;
 +	}
++=======
+ 	if (mce_flags.smca)
+ 		return smca_get_block_address(cpu, bank, block);
++>>>>>>> 78ce241099bb (x86/MCE/AMD: Cache SMCA MISC block addresses)
  
  	/* Fall back to method we used for older processors: */
  	switch (block) {
* Unmerged path arch/x86/kernel/cpu/mcheck/mce_amd.c
