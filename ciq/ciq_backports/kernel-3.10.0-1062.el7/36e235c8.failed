RDMA/mlx5: Use the uapi disablement APIs instead of code

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Jason Gunthorpe <jgg@mellanox.com>
commit 36e235c8829935a59d4652c878cffb08229205c2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/36e235c8.failed

Rely on UAPI_DEF_IS_OBJ_SUPPORTED instead of manipulating the contents of
the driver's definition list.

	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
(cherry picked from commit 36e235c8829935a59d4652c878cffb08229205c2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/devx.c
#	drivers/infiniband/hw/mlx5/main.c
diff --cc drivers/infiniband/hw/mlx5/main.c
index e944c3c2b419,0707ede7dcdd..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -4821,7 -5532,107 +4821,111 @@@ static void mlx5_ib_cleanup_multiport_m
  	mlx5_nic_vport_disable_roce(dev->mdev);
  }
  
++<<<<<<< HEAD
 +static void mlx5_ib_stage_init_cleanup(struct mlx5_ib_dev *dev)
++=======
+ ADD_UVERBS_ATTRIBUTES_SIMPLE(
+ 	mlx5_ib_dm,
+ 	UVERBS_OBJECT_DM,
+ 	UVERBS_METHOD_DM_ALLOC,
+ 	UVERBS_ATTR_PTR_OUT(MLX5_IB_ATTR_ALLOC_DM_RESP_START_OFFSET,
+ 			    UVERBS_ATTR_TYPE(u64),
+ 			    UA_MANDATORY),
+ 	UVERBS_ATTR_PTR_OUT(MLX5_IB_ATTR_ALLOC_DM_RESP_PAGE_INDEX,
+ 			    UVERBS_ATTR_TYPE(u16),
+ 			    UA_MANDATORY));
+ 
+ ADD_UVERBS_ATTRIBUTES_SIMPLE(
+ 	mlx5_ib_flow_action,
+ 	UVERBS_OBJECT_FLOW_ACTION,
+ 	UVERBS_METHOD_FLOW_ACTION_ESP_CREATE,
+ 	UVERBS_ATTR_FLAGS_IN(MLX5_IB_ATTR_CREATE_FLOW_ACTION_FLAGS,
+ 			     enum mlx5_ib_uapi_flow_action_flags));
+ 
+ static const struct uapi_definition mlx5_ib_defs[] = {
+ #if IS_ENABLED(CONFIG_INFINIBAND_USER_ACCESS)
+ 	UAPI_DEF_CHAIN(mlx5_ib_devx_defs),
+ 	UAPI_DEF_CHAIN(mlx5_ib_flow_defs),
+ #endif
+ 
+ 	UAPI_DEF_CHAIN_OBJ_TREE(UVERBS_OBJECT_FLOW_ACTION,
+ 				&mlx5_ib_flow_action),
+ 	UAPI_DEF_CHAIN_OBJ_TREE(UVERBS_OBJECT_DM, &mlx5_ib_dm),
+ 	{}
+ };
+ 
+ static int mlx5_ib_read_counters(struct ib_counters *counters,
+ 				 struct ib_counters_read_attr *read_attr,
+ 				 struct uverbs_attr_bundle *attrs)
+ {
+ 	struct mlx5_ib_mcounters *mcounters = to_mcounters(counters);
+ 	struct mlx5_read_counters_attr mread_attr = {};
+ 	struct mlx5_ib_flow_counters_desc *desc;
+ 	int ret, i;
+ 
+ 	mutex_lock(&mcounters->mcntrs_mutex);
+ 	if (mcounters->cntrs_max_index > read_attr->ncounters) {
+ 		ret = -EINVAL;
+ 		goto err_bound;
+ 	}
+ 
+ 	mread_attr.out = kcalloc(mcounters->counters_num, sizeof(u64),
+ 				 GFP_KERNEL);
+ 	if (!mread_attr.out) {
+ 		ret = -ENOMEM;
+ 		goto err_bound;
+ 	}
+ 
+ 	mread_attr.hw_cntrs_hndl = mcounters->hw_cntrs_hndl;
+ 	mread_attr.flags = read_attr->flags;
+ 	ret = mcounters->read_counters(counters->device, &mread_attr);
+ 	if (ret)
+ 		goto err_read;
+ 
+ 	/* do the pass over the counters data array to assign according to the
+ 	 * descriptions and indexing pairs
+ 	 */
+ 	desc = mcounters->counters_data;
+ 	for (i = 0; i < mcounters->ncounters; i++)
+ 		read_attr->counters_buff[desc[i].index] += mread_attr.out[desc[i].description];
+ 
+ err_read:
+ 	kfree(mread_attr.out);
+ err_bound:
+ 	mutex_unlock(&mcounters->mcntrs_mutex);
+ 	return ret;
+ }
+ 
+ static int mlx5_ib_destroy_counters(struct ib_counters *counters)
+ {
+ 	struct mlx5_ib_mcounters *mcounters = to_mcounters(counters);
+ 
+ 	counters_clear_description(counters);
+ 	if (mcounters->hw_cntrs_hndl)
+ 		mlx5_fc_destroy(to_mdev(counters->device)->mdev,
+ 				mcounters->hw_cntrs_hndl);
+ 
+ 	kfree(mcounters);
+ 
+ 	return 0;
+ }
+ 
+ static struct ib_counters *mlx5_ib_create_counters(struct ib_device *device,
+ 						   struct uverbs_attr_bundle *attrs)
+ {
+ 	struct mlx5_ib_mcounters *mcounters;
+ 
+ 	mcounters = kzalloc(sizeof(*mcounters), GFP_KERNEL);
+ 	if (!mcounters)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	mutex_init(&mcounters->mcntrs_mutex);
+ 
+ 	return &mcounters->ibcntrs;
+ }
+ 
+ void mlx5_ib_stage_init_cleanup(struct mlx5_ib_dev *dev)
++>>>>>>> 36e235c88299 (RDMA/mlx5: Use the uapi disablement APIs instead of code)
  {
  	mlx5_ib_cleanup_multiport_master(dev);
  #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
@@@ -5023,7 -5865,22 +5127,10 @@@ static int mlx5_ib_stage_caps_init(stru
  	dev->ib_dev.uverbs_ex_cmd_mask |=
  			(1ull << IB_USER_VERBS_EX_CMD_CREATE_FLOW) |
  			(1ull << IB_USER_VERBS_EX_CMD_DESTROY_FLOW);
 -	if (mlx5_accel_ipsec_device_caps(dev->mdev) &
 -	    MLX5_ACCEL_IPSEC_CAP_DEVICE) {
 -		dev->ib_dev.create_flow_action_esp =
 -			mlx5_ib_create_flow_action_esp;
 -		dev->ib_dev.modify_flow_action_esp =
 -			mlx5_ib_modify_flow_action_esp;
 -	}
 -	dev->ib_dev.destroy_flow_action = mlx5_ib_destroy_flow_action;
 -	dev->ib_dev.driver_id = RDMA_DRIVER_MLX5;
 -	dev->ib_dev.create_counters = mlx5_ib_create_counters;
 -	dev->ib_dev.destroy_counters = mlx5_ib_destroy_counters;
 -	dev->ib_dev.read_counters = mlx5_ib_read_counters;
  
+ 	if (IS_ENABLED(CONFIG_INFINIBAND_USER_ACCESS))
+ 		dev->ib_dev.driver_def = mlx5_ib_defs;
+ 
  	err = init_node_data(dev);
  	if (err)
  		return err;
@@@ -5237,12 -6093,19 +5344,28 @@@ static void mlx5_ib_stage_bfrag_cleanup
  	mlx5_free_bfreg(dev->mdev, &dev->bfreg);
  }
  
++<<<<<<< HEAD
 +static int mlx5_ib_stage_ib_reg_init(struct mlx5_ib_dev *dev)
 +{
 +	return ib_register_device(&dev->ib_dev, NULL);
 +}
 +
 +static void mlx5_ib_stage_pre_ib_reg_umr_cleanup(struct mlx5_ib_dev *dev)
++=======
+ int mlx5_ib_stage_ib_reg_init(struct mlx5_ib_dev *dev)
+ {
+ 	const char *name;
+ 
+ 	rdma_set_device_sysfs_group(&dev->ib_dev, &mlx5_attr_group);
+ 	if (!mlx5_lag_is_active(dev->mdev))
+ 		name = "mlx5_%d";
+ 	else
+ 		name = "mlx5_bond_%d";
+ 	return ib_register_device(&dev->ib_dev, name, NULL);
+ }
+ 
+ void mlx5_ib_stage_pre_ib_reg_umr_cleanup(struct mlx5_ib_dev *dev)
++>>>>>>> 36e235c88299 (RDMA/mlx5: Use the uapi disablement APIs instead of code)
  {
  	destroy_umrc_res(dev);
  }
@@@ -5391,12 -6236,51 +5514,58 @@@ static const struct mlx5_ib_profile pf_
  	STAGE_CREATE(MLX5_IB_STAGE_DELAY_DROP,
  		     mlx5_ib_stage_delay_drop_init,
  		     mlx5_ib_stage_delay_drop_cleanup),
 +	STAGE_CREATE(MLX5_IB_STAGE_CLASS_ATTR,
 +		     mlx5_ib_stage_class_attr_init,
 +		     NULL),
  };
  
++<<<<<<< HEAD
 +static void *mlx5_ib_add_slave_port(struct mlx5_core_dev *mdev, u8 port_num)
++=======
+ static const struct mlx5_ib_profile nic_rep_profile = {
+ 	STAGE_CREATE(MLX5_IB_STAGE_INIT,
+ 		     mlx5_ib_stage_init_init,
+ 		     mlx5_ib_stage_init_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_FLOW_DB,
+ 		     mlx5_ib_stage_flow_db_init,
+ 		     mlx5_ib_stage_flow_db_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_CAPS,
+ 		     mlx5_ib_stage_caps_init,
+ 		     NULL),
+ 	STAGE_CREATE(MLX5_IB_STAGE_NON_DEFAULT_CB,
+ 		     mlx5_ib_stage_rep_non_default_cb,
+ 		     NULL),
+ 	STAGE_CREATE(MLX5_IB_STAGE_ROCE,
+ 		     mlx5_ib_stage_rep_roce_init,
+ 		     mlx5_ib_stage_rep_roce_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_DEVICE_RESOURCES,
+ 		     mlx5_ib_stage_dev_res_init,
+ 		     mlx5_ib_stage_dev_res_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_COUNTERS,
+ 		     mlx5_ib_stage_counters_init,
+ 		     mlx5_ib_stage_counters_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_UAR,
+ 		     mlx5_ib_stage_uar_init,
+ 		     mlx5_ib_stage_uar_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_BFREG,
+ 		     mlx5_ib_stage_bfrag_init,
+ 		     mlx5_ib_stage_bfrag_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_PRE_IB_REG_UMR,
+ 		     NULL,
+ 		     mlx5_ib_stage_pre_ib_reg_umr_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_IB_REG,
+ 		     mlx5_ib_stage_ib_reg_init,
+ 		     mlx5_ib_stage_ib_reg_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_POST_IB_REG_UMR,
+ 		     mlx5_ib_stage_post_ib_reg_umr_init,
+ 		     NULL),
+ 	STAGE_CREATE(MLX5_IB_STAGE_REP_REG,
+ 		     mlx5_ib_stage_rep_reg_init,
+ 		     mlx5_ib_stage_rep_reg_cleanup),
+ };
+ 
+ static void *mlx5_ib_add_slave_port(struct mlx5_core_dev *mdev)
++>>>>>>> 36e235c88299 (RDMA/mlx5: Use the uapi disablement APIs instead of code)
  {
  	struct mlx5_ib_multiport_info *mpi;
  	struct mlx5_ib_dev *dev;
* Unmerged path drivers/infiniband/hw/mlx5/devx.c
* Unmerged path drivers/infiniband/hw/mlx5/devx.c
* Unmerged path drivers/infiniband/hw/mlx5/main.c
