kvm/x86: Hyper-V kvm exit

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Andrey Smetanin <asmetanin@virtuozzo.com>
commit db3975717ac5e2c2761bae7b90c4f2e0abb5ef22
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/db397571.failed

A new vcpu exit is introduced to notify the userspace of the
changes in Hyper-V SynIC configuration triggered by guest writing to the
corresponding MSRs.

Changes v4:
* exit into userspace only if guest writes into SynIC MSR's

Changes v3:
* added KVM_EXIT_HYPERV types and structs notes into docs

	Signed-off-by: Andrey Smetanin <asmetanin@virtuozzo.com>
	Reviewed-by: Roman Kagan <rkagan@virtuozzo.com>
	Signed-off-by: Denis V. Lunev <den@openvz.org>
CC: Gleb Natapov <gleb@kernel.org>
CC: Paolo Bonzini <pbonzini@redhat.com>
CC: Roman Kagan <rkagan@virtuozzo.com>
CC: Denis V. Lunev <den@openvz.org>
CC: qemu-devel@nongnu.org
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit db3975717ac5e2c2761bae7b90c4f2e0abb5ef22)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/virtual/kvm/api.txt
#	arch/x86/include/asm/kvm_host.h
#	arch/x86/kvm/hyperv.c
#	include/uapi/linux/kvm.h
diff --cc Documentation/virtual/kvm/api.txt
index 9488596d832f,053f613fc9a9..000000000000
--- a/Documentation/virtual/kvm/api.txt
+++ b/Documentation/virtual/kvm/api.txt
@@@ -3098,21 -3337,27 +3098,45 @@@ the userspace IOAPIC should process th
  it is still asserted.  Vector is the LAPIC interrupt vector for which the
  EOI was received.
  
++<<<<<<< HEAD
 +               /* KVM_EXIT_SYSTEM_EVENT */
 +               struct {
 +#define KVM_SYSTEM_EVENT_SHUTDOWN       1
 +#define KVM_SYSTEM_EVENT_RESET          2
 +#define KVM_SYSTEM_EVENT_CRASH          3
 +                       __u32 type;
 +                       __u64 flags;
 +               } system_event;
 +
 +If exit_reason is KVM_EXIT_SYSTEM_EVENT then the vcpu has triggered
 +a system-level event using some architecture specific mechanism (hypercall
 +or some special instruction). In case of ARM/ARM64, this is triggered using
 +HVC instruction based PSCI call from the vcpu. The 'type' field describes
 +the system-level event type. The 'flags' field describes architecture
 +specific flags for the system-level event.
++=======
+ 		struct kvm_hyperv_exit {
+ #define KVM_EXIT_HYPERV_SYNIC          1
+ 			__u32 type;
+ 			union {
+ 				struct {
+ 					__u32 msr;
+ 					__u64 control;
+ 					__u64 evt_page;
+ 					__u64 msg_page;
+ 				} synic;
+ 			} u;
+ 		};
+ 		/* KVM_EXIT_HYPERV */
+                 struct kvm_hyperv_exit hyperv;
+ Indicates that the VCPU exits into userspace to process some tasks
+ related to Hyper-V emulation.
+ Valid values for 'type' are:
+ 	KVM_EXIT_HYPERV_SYNIC -- synchronously notify user-space about
+ Hyper-V SynIC state change. Notification is used to remap SynIC
+ event/message pages and to enable/disable SynIC messages/events processing
+ in userspace.
++>>>>>>> db3975717ac5 (kvm/x86: Hyper-V kvm exit)
  
  		/* Fix the size of the union. */
  		char padding[256];
diff --cc arch/x86/include/asm/kvm_host.h
index d78aa4d6276c,f608e170ba3d..000000000000
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@@ -411,6 -392,8 +411,11 @@@ struct kvm_mtrr 
  struct kvm_vcpu_hv {
  	u64 hv_vapic;
  	s64 runtime_offset;
++<<<<<<< HEAD
++=======
+ 	struct kvm_vcpu_hv_synic synic;
+ 	struct kvm_hyperv_exit exit;
++>>>>>>> db3975717ac5 (kvm/x86: Hyper-V kvm exit)
  };
  
  struct kvm_vcpu_arch {
diff --cc arch/x86/kvm/hyperv.c
index 457dbf00fcf1,41869a9d43f8..000000000000
--- a/arch/x86/kvm/hyperv.c
+++ b/arch/x86/kvm/hyperv.c
@@@ -30,23 -32,323 +30,261 @@@
  
  #include "trace.h"
  
 -static inline u64 synic_read_sint(struct kvm_vcpu_hv_synic *synic, int sint)
 -{
 -	return atomic64_read(&synic->sint[sint]);
 -}
 -
 -static inline int synic_get_sint_vector(u64 sint_value)
 -{
 -	if (sint_value & HV_SYNIC_SINT_MASKED)
 -		return -1;
 -	return sint_value & HV_SYNIC_SINT_VECTOR_MASK;
 -}
 -
 -static bool synic_has_vector_connected(struct kvm_vcpu_hv_synic *synic,
 -				      int vector)
 -{
 -	int i;
 -
 -	for (i = 0; i < ARRAY_SIZE(synic->sint); i++) {
 -		if (synic_get_sint_vector(synic_read_sint(synic, i)) == vector)
 -			return true;
 -	}
 -	return false;
 -}
 -
 -static bool synic_has_vector_auto_eoi(struct kvm_vcpu_hv_synic *synic,
 -				     int vector)
 -{
 -	int i;
 -	u64 sint_value;
 -
 -	for (i = 0; i < ARRAY_SIZE(synic->sint); i++) {
 -		sint_value = synic_read_sint(synic, i);
 -		if (synic_get_sint_vector(sint_value) == vector &&
 -		    sint_value & HV_SYNIC_SINT_AUTO_EOI)
 -			return true;
 -	}
 -	return false;
 -}
 -
 -static int synic_set_sint(struct kvm_vcpu_hv_synic *synic, int sint, u64 data)
 -{
 -	int vector;
 -
 -	vector = data & HV_SYNIC_SINT_VECTOR_MASK;
 -	if (vector < 16)
 -		return 1;
 -	/*
 -	 * Guest may configure multiple SINTs to use the same vector, so
 -	 * we maintain a bitmap of vectors handled by synic, and a
 -	 * bitmap of vectors with auto-eoi behavior.  The bitmaps are
 -	 * updated here, and atomically queried on fast paths.
 -	 */
 -
 -	atomic64_set(&synic->sint[sint], data);
 -
 -	if (synic_has_vector_connected(synic, vector))
 -		__set_bit(vector, synic->vec_bitmap);
 -	else
 -		__clear_bit(vector, synic->vec_bitmap);
 -
 -	if (synic_has_vector_auto_eoi(synic, vector))
 -		__set_bit(vector, synic->auto_eoi_bitmap);
 -	else
 -		__clear_bit(vector, synic->auto_eoi_bitmap);
 -
 -	/* Load SynIC vectors into EOI exit bitmap */
 -	kvm_make_request(KVM_REQ_SCAN_IOAPIC, synic_to_vcpu(synic));
 -	return 0;
 -}
 -
 -static struct kvm_vcpu_hv_synic *synic_get(struct kvm *kvm, u32 vcpu_id)
 +static u64 get_time_ref_counter(struct kvm *kvm)
  {
 +	struct kvm_hv *hv = &kvm->arch.hyperv;
  	struct kvm_vcpu *vcpu;
 -	struct kvm_vcpu_hv_synic *synic;
 +	u64 tsc;
  
++<<<<<<< HEAD
++=======
+ 	if (vcpu_id >= atomic_read(&kvm->online_vcpus))
+ 		return NULL;
+ 	vcpu = kvm_get_vcpu(kvm, vcpu_id);
+ 	if (!vcpu)
+ 		return NULL;
+ 	synic = vcpu_to_synic(vcpu);
+ 	return (synic->active) ? synic : NULL;
+ }
+ 
+ static void kvm_hv_notify_acked_sint(struct kvm_vcpu *vcpu, u32 sint)
+ {
+ 	struct kvm *kvm = vcpu->kvm;
+ 	int gsi, idx;
+ 
+ 	vcpu_debug(vcpu, "Hyper-V SynIC acked sint %d\n", sint);
+ 
+ 	idx = srcu_read_lock(&kvm->irq_srcu);
+ 	gsi = atomic_read(&vcpu_to_synic(vcpu)->sint_to_gsi[sint]);
+ 	if (gsi != -1)
+ 		kvm_notify_acked_gsi(kvm, gsi);
+ 	srcu_read_unlock(&kvm->irq_srcu, idx);
+ }
+ 
+ static void synic_exit(struct kvm_vcpu_hv_synic *synic, u32 msr)
+ {
+ 	struct kvm_vcpu *vcpu = synic_to_vcpu(synic);
+ 	struct kvm_vcpu_hv *hv_vcpu = &vcpu->arch.hyperv;
+ 
+ 	hv_vcpu->exit.type = KVM_EXIT_HYPERV_SYNIC;
+ 	hv_vcpu->exit.u.synic.msr = msr;
+ 	hv_vcpu->exit.u.synic.control = synic->control;
+ 	hv_vcpu->exit.u.synic.evt_page = synic->evt_page;
+ 	hv_vcpu->exit.u.synic.msg_page = synic->msg_page;
+ 
+ 	kvm_make_request(KVM_REQ_HV_EXIT, vcpu);
+ }
+ 
+ static int synic_set_msr(struct kvm_vcpu_hv_synic *synic,
+ 			 u32 msr, u64 data, bool host)
+ {
+ 	struct kvm_vcpu *vcpu = synic_to_vcpu(synic);
+ 	int ret;
+ 
+ 	if (!synic->active)
+ 		return 1;
+ 
+ 	vcpu_debug(vcpu, "Hyper-V SynIC set msr 0x%x 0x%llx host %d\n",
+ 		   msr, data, host);
+ 	ret = 0;
+ 	switch (msr) {
+ 	case HV_X64_MSR_SCONTROL:
+ 		synic->control = data;
+ 		if (!host)
+ 			synic_exit(synic, msr);
+ 		break;
+ 	case HV_X64_MSR_SVERSION:
+ 		if (!host) {
+ 			ret = 1;
+ 			break;
+ 		}
+ 		synic->version = data;
+ 		break;
+ 	case HV_X64_MSR_SIEFP:
+ 		if (data & HV_SYNIC_SIEFP_ENABLE)
+ 			if (kvm_clear_guest(vcpu->kvm,
+ 					    data & PAGE_MASK, PAGE_SIZE)) {
+ 				ret = 1;
+ 				break;
+ 			}
+ 		synic->evt_page = data;
+ 		if (!host)
+ 			synic_exit(synic, msr);
+ 		break;
+ 	case HV_X64_MSR_SIMP:
+ 		if (data & HV_SYNIC_SIMP_ENABLE)
+ 			if (kvm_clear_guest(vcpu->kvm,
+ 					    data & PAGE_MASK, PAGE_SIZE)) {
+ 				ret = 1;
+ 				break;
+ 			}
+ 		synic->msg_page = data;
+ 		if (!host)
+ 			synic_exit(synic, msr);
+ 		break;
+ 	case HV_X64_MSR_EOM: {
+ 		int i;
+ 
+ 		for (i = 0; i < ARRAY_SIZE(synic->sint); i++)
+ 			kvm_hv_notify_acked_sint(vcpu, i);
+ 		break;
+ 	}
+ 	case HV_X64_MSR_SINT0 ... HV_X64_MSR_SINT15:
+ 		ret = synic_set_sint(synic, msr - HV_X64_MSR_SINT0, data);
+ 		break;
+ 	default:
+ 		ret = 1;
+ 		break;
+ 	}
+ 	return ret;
+ }
+ 
+ static int synic_get_msr(struct kvm_vcpu_hv_synic *synic, u32 msr, u64 *pdata)
+ {
+ 	int ret;
+ 
+ 	if (!synic->active)
+ 		return 1;
+ 
+ 	ret = 0;
+ 	switch (msr) {
+ 	case HV_X64_MSR_SCONTROL:
+ 		*pdata = synic->control;
+ 		break;
+ 	case HV_X64_MSR_SVERSION:
+ 		*pdata = synic->version;
+ 		break;
+ 	case HV_X64_MSR_SIEFP:
+ 		*pdata = synic->evt_page;
+ 		break;
+ 	case HV_X64_MSR_SIMP:
+ 		*pdata = synic->msg_page;
+ 		break;
+ 	case HV_X64_MSR_EOM:
+ 		*pdata = 0;
+ 		break;
+ 	case HV_X64_MSR_SINT0 ... HV_X64_MSR_SINT15:
+ 		*pdata = atomic64_read(&synic->sint[msr - HV_X64_MSR_SINT0]);
+ 		break;
+ 	default:
+ 		ret = 1;
+ 		break;
+ 	}
+ 	return ret;
+ }
+ 
+ int synic_set_irq(struct kvm_vcpu_hv_synic *synic, u32 sint)
+ {
+ 	struct kvm_vcpu *vcpu = synic_to_vcpu(synic);
+ 	struct kvm_lapic_irq irq;
+ 	int ret, vector;
+ 
+ 	if (sint >= ARRAY_SIZE(synic->sint))
+ 		return -EINVAL;
+ 
+ 	vector = synic_get_sint_vector(synic_read_sint(synic, sint));
+ 	if (vector < 0)
+ 		return -ENOENT;
+ 
+ 	memset(&irq, 0, sizeof(irq));
+ 	irq.dest_id = kvm_apic_id(vcpu->arch.apic);
+ 	irq.dest_mode = APIC_DEST_PHYSICAL;
+ 	irq.delivery_mode = APIC_DM_FIXED;
+ 	irq.vector = vector;
+ 	irq.level = 1;
+ 
+ 	ret = kvm_irq_delivery_to_apic(vcpu->kvm, NULL, &irq, NULL);
+ 	vcpu_debug(vcpu, "Hyper-V SynIC set irq ret %d\n", ret);
+ 	return ret;
+ }
+ 
+ int kvm_hv_synic_set_irq(struct kvm *kvm, u32 vcpu_id, u32 sint)
+ {
+ 	struct kvm_vcpu_hv_synic *synic;
+ 
+ 	synic = synic_get(kvm, vcpu_id);
+ 	if (!synic)
+ 		return -EINVAL;
+ 
+ 	return synic_set_irq(synic, sint);
+ }
+ 
+ void kvm_hv_synic_send_eoi(struct kvm_vcpu *vcpu, int vector)
+ {
+ 	struct kvm_vcpu_hv_synic *synic = vcpu_to_synic(vcpu);
+ 	int i;
+ 
+ 	vcpu_debug(vcpu, "Hyper-V SynIC send eoi vec %d\n", vector);
+ 
+ 	for (i = 0; i < ARRAY_SIZE(synic->sint); i++)
+ 		if (synic_get_sint_vector(synic_read_sint(synic, i)) == vector)
+ 			kvm_hv_notify_acked_sint(vcpu, i);
+ }
+ 
+ static int kvm_hv_set_sint_gsi(struct kvm *kvm, u32 vcpu_id, u32 sint, int gsi)
+ {
+ 	struct kvm_vcpu_hv_synic *synic;
+ 
+ 	synic = synic_get(kvm, vcpu_id);
+ 	if (!synic)
+ 		return -EINVAL;
+ 
+ 	if (sint >= ARRAY_SIZE(synic->sint_to_gsi))
+ 		return -EINVAL;
+ 
+ 	atomic_set(&synic->sint_to_gsi[sint], gsi);
+ 	return 0;
+ }
+ 
+ void kvm_hv_irq_routing_update(struct kvm *kvm)
+ {
+ 	struct kvm_irq_routing_table *irq_rt;
+ 	struct kvm_kernel_irq_routing_entry *e;
+ 	u32 gsi;
+ 
+ 	irq_rt = srcu_dereference_check(kvm->irq_routing, &kvm->irq_srcu,
+ 					lockdep_is_held(&kvm->irq_lock));
+ 
+ 	for (gsi = 0; gsi < irq_rt->nr_rt_entries; gsi++) {
+ 		hlist_for_each_entry(e, &irq_rt->map[gsi], link) {
+ 			if (e->type == KVM_IRQ_ROUTING_HV_SINT)
+ 				kvm_hv_set_sint_gsi(kvm, e->hv_sint.vcpu,
+ 						    e->hv_sint.sint, gsi);
+ 		}
+ 	}
+ }
+ 
+ static void synic_init(struct kvm_vcpu_hv_synic *synic)
+ {
+ 	int i;
+ 
+ 	memset(synic, 0, sizeof(*synic));
+ 	synic->version = HV_SYNIC_VERSION_1;
+ 	for (i = 0; i < ARRAY_SIZE(synic->sint); i++) {
+ 		atomic64_set(&synic->sint[i], HV_SYNIC_SINT_MASKED);
+ 		atomic_set(&synic->sint_to_gsi[i], -1);
+ 	}
+ }
+ 
+ void kvm_hv_vcpu_init(struct kvm_vcpu *vcpu)
+ {
+ 	synic_init(vcpu_to_synic(vcpu));
+ }
+ 
+ int kvm_hv_activate_synic(struct kvm_vcpu *vcpu)
+ {
++>>>>>>> db3975717ac5 (kvm/x86: Hyper-V kvm exit)
  	/*
 -	 * Hyper-V SynIC auto EOI SINT's are
 -	 * not compatible with APICV, so deactivate APICV
 +	 * The guest has not set up the TSC page or the clock isn't
 +	 * stable, fall back to get_kvmclock_ns.
  	 */
 -	kvm_vcpu_deactivate_apicv(vcpu);
 -	vcpu_to_synic(vcpu)->active = true;
 -	return 0;
 +	if (!hv->tsc_ref.tsc_sequence)
 +		return div_u64(get_kvmclock_ns(kvm), 100);
 +
 +	vcpu = kvm_get_vcpu(kvm, 0);
 +	tsc = kvm_read_l1_tsc(vcpu, rdtsc());
 +	return mul_u64_u64_shr(tsc, hv->tsc_ref.tsc_scale, 64)
 +		+ hv->tsc_ref.tsc_offset;
  }
  
  static bool kvm_hv_msr_partition_wide(u32 msr)
diff --cc include/uapi/linux/kvm.h
index 6b525ccf5361,6e32f7599081..000000000000
--- a/include/uapi/linux/kvm.h
+++ b/include/uapi/linux/kvm.h
@@@ -147,6 -147,30 +147,33 @@@ struct kvm_pit_config 
  
  #define KVM_PIT_SPEAKER_DUMMY     1
  
++<<<<<<< HEAD
++=======
+ struct kvm_s390_skeys {
+ 	__u64 start_gfn;
+ 	__u64 count;
+ 	__u64 skeydata_addr;
+ 	__u32 flags;
+ 	__u32 reserved[9];
+ };
+ 
+ struct kvm_hyperv_exit {
+ #define KVM_EXIT_HYPERV_SYNIC          1
+ 	__u32 type;
+ 	union {
+ 		struct {
+ 			__u32 msr;
+ 			__u64 control;
+ 			__u64 evt_page;
+ 			__u64 msg_page;
+ 		} synic;
+ 	} u;
+ };
+ 
+ #define KVM_S390_GET_SKEYS_NONE   1
+ #define KVM_S390_SKEYS_MAX        1048576
+ 
++>>>>>>> db3975717ac5 (kvm/x86: Hyper-V kvm exit)
  #define KVM_EXIT_UNKNOWN          0
  #define KVM_EXIT_EXCEPTION        1
  #define KVM_EXIT_IO               2
@@@ -172,7 -196,9 +199,8 @@@
  #define KVM_EXIT_S390_TSCH        22
  #define KVM_EXIT_EPR              23
  #define KVM_EXIT_SYSTEM_EVENT     24
 -#define KVM_EXIT_S390_STSI        25
  #define KVM_EXIT_IOAPIC_EOI       26
+ #define KVM_EXIT_HYPERV           27
  
  /* For KVM_EXIT_INTERNAL_ERROR */
  /* Emulate instruction failed. */
@@@ -316,7 -340,21 +344,25 @@@ struct kvm_run 
  			__u32 type;
  			__u64 flags;
  		} system_event;
++<<<<<<< HEAD
 +
++=======
+ 		/* KVM_EXIT_S390_STSI */
+ 		struct {
+ 			__u64 addr;
+ 			__u8 ar;
+ 			__u8 reserved;
+ 			__u8 fc;
+ 			__u8 sel1;
+ 			__u16 sel2;
+ 		} s390_stsi;
+ 		/* KVM_EXIT_IOAPIC_EOI */
+ 		struct {
+ 			__u8 vector;
+ 		} eoi;
+ 		/* KVM_EXIT_HYPERV */
+ 		struct kvm_hyperv_exit hyperv;
++>>>>>>> db3975717ac5 (kvm/x86: Hyper-V kvm exit)
  		/* Fix the size of the union. */
  		char padding[256];
  	};
* Unmerged path Documentation/virtual/kvm/api.txt
* Unmerged path arch/x86/include/asm/kvm_host.h
* Unmerged path arch/x86/kvm/hyperv.c
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index 8d92b5d9de18..9391f9be6261 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -6634,6 +6634,12 @@ static int vcpu_enter_guest(struct kvm_vcpu *vcpu)
 			r = 0;
 			goto out;
 		}
+		if (kvm_check_request(KVM_REQ_HV_EXIT, vcpu)) {
+			vcpu->run->exit_reason = KVM_EXIT_HYPERV;
+			vcpu->run->hyperv = vcpu->arch.hyperv.exit;
+			r = 0;
+			goto out;
+		}
 	}
 
 	if (kvm_check_request(KVM_REQ_EVENT, vcpu) || req_int_win) {
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index 2e1b15f53afa..02bab20239a9 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -150,6 +150,7 @@ static inline bool is_error_page(struct page *page)
 #define KVM_REQ_HV_CRASH          27
 #define KVM_REQ_IOAPIC_EOI_EXIT   28
 #define KVM_REQ_HV_RESET          29
+#define KVM_REQ_HV_EXIT           30
 
 #define KVM_USERSPACE_IRQ_SOURCE_ID		0
 #define KVM_IRQFD_RESAMPLE_IRQ_SOURCE_ID	1
* Unmerged path include/uapi/linux/kvm.h
