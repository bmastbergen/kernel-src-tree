nfp: flower: support multiple memory units for filter offloads

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Pieter Jansen van Vuuren <pieter.jansenvanvuuren@netronome.com>
commit 467322e2627f863c8b48b0229674d9a22027e559
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/467322e2.failed

Adds support for multiple memory units which are used for filter
offloads. Each filter is assigned a stats id, the MSBs of the id are
used to determine which memory unit the filter should be offloaded
to. The number of available memory units that could be used for filter
offload is obtained from HW. A simple round robin technique is used to
allocate and distribute the ids across memory units.

	Signed-off-by: Pieter Jansen van Vuuren <pieter.jansenvanvuuren@netronome.com>
	Reviewed-by: Jakub Kicinski <jakub.kicinski@netronome.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 467322e2627f863c8b48b0229674d9a22027e559)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/netronome/nfp/flower/main.c
#	drivers/net/ethernet/netronome/nfp/flower/main.h
#	drivers/net/ethernet/netronome/nfp/flower/metadata.c
diff --cc drivers/net/ethernet/netronome/nfp/flower/main.c
index 171014032993,c370fbcbcc38..000000000000
--- a/drivers/net/ethernet/netronome/nfp/flower/main.c
+++ b/drivers/net/ethernet/netronome/nfp/flower/main.c
@@@ -516,9 -474,9 +516,10 @@@ err_clear_nn
  
  static int nfp_flower_init(struct nfp_app *app)
  {
+ 	u64 version, features, ctx_count, num_mems;
  	const struct nfp_pf *pf = app->pf;
  	struct nfp_flower_priv *app_priv;
 +	u64 version, features;
  	int err;
  
  	if (!pf->eth_tbl) {
@@@ -542,6 -500,33 +543,36 @@@
  		return err;
  	}
  
++<<<<<<< HEAD
++=======
+ 	num_mems = nfp_rtsym_read_le(app->pf->rtbl, "CONFIG_FC_HOST_CTX_SPLIT",
+ 				     &err);
+ 	if (err) {
+ 		nfp_warn(app->cpp,
+ 			 "FlowerNIC: unsupported host context memory: %d\n",
+ 			 err);
+ 		err = 0;
+ 		num_mems = 1;
+ 	}
+ 
+ 	if (!FIELD_FIT(NFP_FL_STAT_ID_MU_NUM, num_mems) || !num_mems) {
+ 		nfp_warn(app->cpp,
+ 			 "FlowerNIC: invalid host context memory: %llu\n",
+ 			 num_mems);
+ 		return -EINVAL;
+ 	}
+ 
+ 	ctx_count = nfp_rtsym_read_le(app->pf->rtbl, "CONFIG_FC_HOST_CTX_COUNT",
+ 				      &err);
+ 	if (err) {
+ 		nfp_warn(app->cpp,
+ 			 "FlowerNIC: unsupported host context count: %d\n",
+ 			 err);
+ 		err = 0;
+ 		ctx_count = BIT(17);
+ 	}
+ 
++>>>>>>> 467322e2627f (nfp: flower: support multiple memory units for filter offloads)
  	/* We need to ensure hardware has enough flower capabilities. */
  	if (version != NFP_FLOWER_ALLOWED_VER) {
  		nfp_warn(app->cpp, "FlowerNIC: unsupported firmware version\n");
@@@ -552,6 -537,9 +583,12 @@@
  	if (!app_priv)
  		return -ENOMEM;
  
++<<<<<<< HEAD
++=======
+ 	app_priv->total_mem_units = num_mems;
+ 	app_priv->active_mem_unit = 0;
+ 	app_priv->stats_ring_size = roundup_pow_of_two(ctx_count);
++>>>>>>> 467322e2627f (nfp: flower: support multiple memory units for filter offloads)
  	app->priv = app_priv;
  	app_priv->app = app;
  	skb_queue_head_init(&app_priv->cmsg_skbs_high);
@@@ -562,7 -550,7 +599,11 @@@
  	init_waitqueue_head(&app_priv->mtu_conf.wait_q);
  	spin_lock_init(&app_priv->mtu_conf.lock);
  
++<<<<<<< HEAD
 +	err = nfp_flower_metadata_init(app);
++=======
+ 	err = nfp_flower_metadata_init(app, ctx_count, num_mems);
++>>>>>>> 467322e2627f (nfp: flower: support multiple memory units for filter offloads)
  	if (err)
  		goto err_free_app_priv;
  
diff --cc drivers/net/ethernet/netronome/nfp/flower/main.h
index 90cc96d4eae4,324b7fe3192f..000000000000
--- a/drivers/net/ethernet/netronome/nfp/flower/main.h
+++ b/drivers/net/ethernet/netronome/nfp/flower/main.h
@@@ -49,10 -20,11 +49,18 @@@ struct tc_to_netdev
  struct net_device;
  struct nfp_app;
  
++<<<<<<< HEAD
 +#define NFP_FL_STATS_ENTRY_RS		BIT(20)
 +#define NFP_FL_STATS_ELEM_RS		4
 +#define NFP_FL_REPEATED_HASH_MAX	BIT(17)
 +#define NFP_FLOWER_HASH_BITS		19
++=======
+ #define NFP_FL_STAT_ID_MU_NUM		GENMASK(31, 22)
+ #define NFP_FL_STAT_ID_STAT		GENMASK(21, 0)
+ 
+ #define NFP_FL_STATS_ELEM_RS		FIELD_SIZEOF(struct nfp_fl_stats_id, \
+ 						     init_unalloc)
++>>>>>>> 467322e2627f (nfp: flower: support multiple memory units for filter offloads)
  #define NFP_FLOWER_MASK_ENTRY_RS	256
  #define NFP_FLOWER_MASK_ELEMENT_RS	1
  #define NFP_FLOWER_MASK_HASH_BITS	10
@@@ -163,6 -132,9 +171,12 @@@ struct nfp_fl_lag 
   * @reify_wait_queue:	wait queue for repr reify response counting
   * @mtu_conf:		Configuration of repr MTU value
   * @nfp_lag:		Link aggregation data block
++<<<<<<< HEAD
++=======
+  * @indr_block_cb_priv:	List of priv data passed to indirect block cbs
+  * @active_mem_unit:	Current active memory unit for flower rules
+  * @total_mem_units:	Total number of available memory units for flower rules
++>>>>>>> 467322e2627f (nfp: flower: support multiple memory units for filter offloads)
   */
  struct nfp_flower_priv {
  	struct nfp_app *app;
@@@ -193,6 -167,9 +207,12 @@@
  	wait_queue_head_t reify_wait_queue;
  	struct nfp_mtu_conf mtu_conf;
  	struct nfp_fl_lag nfp_lag;
++<<<<<<< HEAD
++=======
+ 	struct list_head indr_block_cb_priv;
+ 	unsigned int active_mem_unit;
+ 	unsigned int total_mem_units;
++>>>>>>> 467322e2627f (nfp: flower: support multiple memory units for filter offloads)
  };
  
  /**
@@@ -246,16 -224,8 +266,21 @@@ struct nfp_fl_stats_frame 
  	__be64 stats_cookie;
  };
  
++<<<<<<< HEAD
 +static inline unsigned long nfp_flower_fl_key(unsigned long tc_flower_cookie)
 +{
 +#if BITS_PER_LONG == 64
 +	return tc_flower_cookie * NFP_FLOWER_GOLDEN_RATIO_64;
 +#else
 +	return tc_flower_cookie * NFP_FLOWER_GOLDEN_RATIO_32;
 +#endif
 +}
 +
 +int nfp_flower_metadata_init(struct nfp_app *app);
++=======
+ int nfp_flower_metadata_init(struct nfp_app *app, u64 host_ctx_count,
+ 			     unsigned int host_ctx_split);
++>>>>>>> 467322e2627f (nfp: flower: support multiple memory units for filter offloads)
  void nfp_flower_metadata_cleanup(struct nfp_app *app);
  
  int nfp_flower_setup_tc(struct nfp_app *app, struct net_device *netdev,
diff --cc drivers/net/ethernet/netronome/nfp/flower/metadata.c
index c748aceb17bb,492837b852b6..000000000000
--- a/drivers/net/ethernet/netronome/nfp/flower/metadata.c
+++ b/drivers/net/ethernet/netronome/nfp/flower/metadata.c
@@@ -74,11 -50,20 +75,20 @@@ static int nfp_get_stats_entry(struct n
  	struct circ_buf *ring;
  
  	ring = &priv->stats_ids.free_list;
 -	freed_stats_id = priv->stats_ring_size;
 +	freed_stats_id = NFP_FL_STATS_ENTRY_RS;
  	/* Check for unallocated entries first. */
  	if (priv->stats_ids.init_unalloc > 0) {
- 		*stats_context_id = priv->stats_ids.init_unalloc - 1;
- 		priv->stats_ids.init_unalloc--;
+ 		if (priv->active_mem_unit == priv->total_mem_units) {
+ 			priv->stats_ids.init_unalloc--;
+ 			priv->active_mem_unit = 0;
+ 		}
+ 
+ 		*stats_context_id =
+ 			FIELD_PREP(NFP_FL_STAT_ID_STAT,
+ 				   priv->stats_ids.init_unalloc - 1) |
+ 			FIELD_PREP(NFP_FL_STAT_ID_MU_NUM,
+ 				   priv->active_mem_unit);
+ 		priv->active_mem_unit++;
  		return 0;
  	}
  
@@@ -386,12 -354,55 +396,57 @@@ int nfp_modify_flow_metadata(struct nfp
  	return nfp_release_stats_entry(app, temp_ctx_id);
  }
  
++<<<<<<< HEAD
 +int nfp_flower_metadata_init(struct nfp_app *app)
 +{
 +	struct nfp_flower_priv *priv = app->priv;
++=======
+ static int nfp_fl_obj_cmpfn(struct rhashtable_compare_arg *arg,
+ 			    const void *obj)
+ {
+ 	const struct nfp_fl_flow_table_cmp_arg *cmp_arg = arg->key;
+ 	const struct nfp_fl_payload *flow_entry = obj;
+ 
+ 	if (flow_entry->ingress_dev == cmp_arg->netdev)
+ 		return flow_entry->tc_flower_cookie != cmp_arg->cookie;
+ 
+ 	return 1;
+ }
+ 
+ static u32 nfp_fl_obj_hashfn(const void *data, u32 len, u32 seed)
+ {
+ 	const struct nfp_fl_payload *flower_entry = data;
+ 
+ 	return jhash2((u32 *)&flower_entry->tc_flower_cookie,
+ 		      sizeof(flower_entry->tc_flower_cookie) / sizeof(u32),
+ 		      seed);
+ }
+ 
+ static u32 nfp_fl_key_hashfn(const void *data, u32 len, u32 seed)
+ {
+ 	const struct nfp_fl_flow_table_cmp_arg *cmp_arg = data;
+ 
+ 	return jhash2((u32 *)&cmp_arg->cookie,
+ 		      sizeof(cmp_arg->cookie) / sizeof(u32), seed);
+ }
+ 
+ const struct rhashtable_params nfp_flower_table_params = {
+ 	.head_offset		= offsetof(struct nfp_fl_payload, fl_node),
+ 	.hashfn			= nfp_fl_key_hashfn,
+ 	.obj_cmpfn		= nfp_fl_obj_cmpfn,
+ 	.obj_hashfn		= nfp_fl_obj_hashfn,
+ 	.automatic_shrinking	= true,
+ };
+ 
+ int nfp_flower_metadata_init(struct nfp_app *app, u64 host_ctx_count,
+ 			     unsigned int host_num_mems)
+ {
+ 	struct nfp_flower_priv *priv = app->priv;
+ 	int err, stats_size;
++>>>>>>> 467322e2627f (nfp: flower: support multiple memory units for filter offloads)
  
  	hash_init(priv->mask_table);
 -
 -	err = rhashtable_init(&priv->flow_table, &nfp_flower_table_params);
 -	if (err)
 -		return err;
 -
 +	hash_init(priv->flow_table);
  	get_random_bytes(&priv->mask_id_seed, sizeof(priv->mask_id_seed));
  
  	/* Init ring buffer and unallocated mask_ids. */
@@@ -416,7 -428,16 +471,20 @@@
  	if (!priv->stats_ids.free_list.buf)
  		goto err_free_last_used;
  
++<<<<<<< HEAD
 +	priv->stats_ids.init_unalloc = NFP_FL_REPEATED_HASH_MAX;
++=======
+ 	priv->stats_ids.init_unalloc = div_u64(host_ctx_count, host_num_mems);
+ 
+ 	stats_size = FIELD_PREP(NFP_FL_STAT_ID_STAT, host_ctx_count) |
+ 		     FIELD_PREP(NFP_FL_STAT_ID_MU_NUM, host_num_mems - 1);
+ 	priv->stats = kvmalloc_array(stats_size, sizeof(struct nfp_fl_stats),
+ 				     GFP_KERNEL);
+ 	if (!priv->stats)
+ 		goto err_free_ring_buf;
+ 
+ 	spin_lock_init(&priv->stats_lock);
++>>>>>>> 467322e2627f (nfp: flower: support multiple memory units for filter offloads)
  
  	return 0;
  
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/main.c
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/main.h
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/metadata.c
