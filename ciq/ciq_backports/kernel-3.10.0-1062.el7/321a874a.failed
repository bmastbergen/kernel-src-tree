sched/smt: Expose sched_smt_present static key

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 321a874a7ef85655e93b3206d0f36b4a6097f948
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/321a874a.failed

Make the scheduler's 'sched_smt_present' static key globaly available, so
it can be used in the x86 speculation control code.

Provide a query function and a stub for the CONFIG_SMP=n case.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Reviewed-by: Ingo Molnar <mingo@kernel.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Andy Lutomirski <luto@kernel.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Jiri Kosina <jkosina@suse.cz>
	Cc: Tom Lendacky <thomas.lendacky@amd.com>
	Cc: Josh Poimboeuf <jpoimboe@redhat.com>
	Cc: Andrea Arcangeli <aarcange@redhat.com>
	Cc: David Woodhouse <dwmw@amazon.co.uk>
	Cc: Tim Chen <tim.c.chen@linux.intel.com>
	Cc: Andi Kleen <ak@linux.intel.com>
	Cc: Dave Hansen <dave.hansen@intel.com>
	Cc: Casey Schaufler <casey.schaufler@intel.com>
	Cc: Asit Mallick <asit.k.mallick@intel.com>
	Cc: Arjan van de Ven <arjan@linux.intel.com>
	Cc: Jon Masters <jcm@redhat.com>
	Cc: Waiman Long <longman9394@gmail.com>
	Cc: Greg KH <gregkh@linuxfoundation.org>
	Cc: Dave Stewart <david.c.stewart@intel.com>
	Cc: Kees Cook <keescook@chromium.org>
	Cc: stable@vger.kernel.org
Link: https://lkml.kernel.org/r/20181125185004.430168326@linutronix.de

(cherry picked from commit 321a874a7ef85655e93b3206d0f36b4a6097f948)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/sched/sched.h
diff --cc kernel/sched/sched.h
index 64fc595fae84,4e524ab589c9..000000000000
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@@ -1,16 -1,75 +1,41 @@@
 -/* SPDX-License-Identifier: GPL-2.0 */
 -/*
 - * Scheduler internal types and methods:
 - */
 +
  #include <linux/sched.h>
++<<<<<<< HEAD
++=======
+ 
+ #include <linux/sched/autogroup.h>
+ #include <linux/sched/clock.h>
+ #include <linux/sched/coredump.h>
+ #include <linux/sched/cpufreq.h>
+ #include <linux/sched/cputime.h>
+ #include <linux/sched/deadline.h>
+ #include <linux/sched/debug.h>
+ #include <linux/sched/hotplug.h>
+ #include <linux/sched/idle.h>
+ #include <linux/sched/init.h>
+ #include <linux/sched/isolation.h>
+ #include <linux/sched/jobctl.h>
+ #include <linux/sched/loadavg.h>
+ #include <linux/sched/mm.h>
+ #include <linux/sched/nohz.h>
+ #include <linux/sched/numa_balancing.h>
+ #include <linux/sched/prio.h>
+ #include <linux/sched/rt.h>
+ #include <linux/sched/signal.h>
+ #include <linux/sched/smt.h>
+ #include <linux/sched/stat.h>
++>>>>>>> 321a874a7ef8 (sched/smt: Expose sched_smt_present static key)
  #include <linux/sched/sysctl.h>
 -#include <linux/sched/task.h>
 -#include <linux/sched/task_stack.h>
 -#include <linux/sched/topology.h>
 -#include <linux/sched/user.h>
 -#include <linux/sched/wake_q.h>
 -#include <linux/sched/xacct.h>
 -
 -#include <uapi/linux/sched/types.h>
 -
 -#include <linux/binfmts.h>
 -#include <linux/blkdev.h>
 -#include <linux/compat.h>
 -#include <linux/context_tracking.h>
 -#include <linux/cpufreq.h>
 -#include <linux/cpuidle.h>
 -#include <linux/cpuset.h>
 -#include <linux/ctype.h>
 -#include <linux/debugfs.h>
 -#include <linux/delayacct.h>
 -#include <linux/init_task.h>
 -#include <linux/kprobes.h>
 -#include <linux/kthread.h>
 -#include <linux/membarrier.h>
 -#include <linux/migrate.h>
 -#include <linux/mmu_context.h>
 -#include <linux/nmi.h>
 -#include <linux/proc_fs.h>
 -#include <linux/prefetch.h>
 -#include <linux/profile.h>
 -#include <linux/psi.h>
 -#include <linux/rcupdate_wait.h>
 -#include <linux/security.h>
 +#include <linux/sched/rt.h>
 +#include <linux/sched/deadline.h>
 +#include <linux/sched/cpufreq.h>
 +#include <linux/mutex.h>
 +#include <linux/spinlock.h>
  #include <linux/stop_machine.h>
 -#include <linux/suspend.h>
 -#include <linux/swait.h>
 -#include <linux/syscalls.h>
 -#include <linux/task_work.h>
 -#include <linux/tsacct_kern.h>
 +#include <linux/tick.h>
 +#include <linux/slab.h>
  
 -#include <asm/tlb.h>
 -
 -#ifdef CONFIG_PARAVIRT
 -# include <asm/paravirt.h>
 -#endif
 +#include <linux/rh_kabi.h>
  
  #include "cpupri.h"
  #include "cpudeadline.h"
@@@ -747,13 -935,70 +772,31 @@@ static inline int cpu_of(struct rq *rq
  #endif
  }
  
++<<<<<<< HEAD
 +DECLARE_PER_CPU(struct rq, runqueues);
++=======
+ 
+ #ifdef CONFIG_SCHED_SMT
+ extern void __update_idle_core(struct rq *rq);
+ 
+ static inline void update_idle_core(struct rq *rq)
+ {
+ 	if (static_branch_unlikely(&sched_smt_present))
+ 		__update_idle_core(rq);
+ }
+ 
+ #else
+ static inline void update_idle_core(struct rq *rq) { }
+ #endif
+ 
+ DECLARE_PER_CPU_SHARED_ALIGNED(struct rq, runqueues);
++>>>>>>> 321a874a7ef8 (sched/smt: Expose sched_smt_present static key)
  
  #define cpu_rq(cpu)		(&per_cpu(runqueues, (cpu)))
 -#define this_rq()		this_cpu_ptr(&runqueues)
 +#define this_rq()		(&__get_cpu_var(runqueues))
  #define task_rq(p)		cpu_rq(task_cpu(p))
  #define cpu_curr(cpu)		(cpu_rq(cpu)->curr)
 -#define raw_rq()		raw_cpu_ptr(&runqueues)
 -
 -extern void update_rq_clock(struct rq *rq);
 -
 -static inline u64 __rq_clock_broken(struct rq *rq)
 -{
 -	return READ_ONCE(rq->clock);
 -}
 -
 -/*
 - * rq::clock_update_flags bits
 - *
 - * %RQCF_REQ_SKIP - will request skipping of clock update on the next
 - *  call to __schedule(). This is an optimisation to avoid
 - *  neighbouring rq clock updates.
 - *
 - * %RQCF_ACT_SKIP - is set from inside of __schedule() when skipping is
 - *  in effect and calls to update_rq_clock() are being ignored.
 - *
 - * %RQCF_UPDATED - is a debug flag that indicates whether a call has been
 - *  made to update_rq_clock() since the last time rq::lock was pinned.
 - *
 - * If inside of __schedule(), clock_update_flags will have been
 - * shifted left (a left shift is a cheap operation for the fast path
 - * to promote %RQCF_REQ_SKIP to %RQCF_ACT_SKIP), so you must use,
 - *
 - *	if (rq-clock_update_flags >= RQCF_UPDATED)
 - *
 - * to check if %RQCF_UPADTED is set. It'll never be shifted more than
 - * one position though, because the next rq_unpin_lock() will shift it
 - * back.
 - */
 -#define RQCF_REQ_SKIP		0x01
 -#define RQCF_ACT_SKIP		0x02
 -#define RQCF_UPDATED		0x04
 -
 -static inline void assert_clock_updated(struct rq *rq)
 -{
 -	/*
 -	 * The only reason for not seeing a clock update since the
 -	 * last rq_pin_lock() is if we're currently skipping updates.
 -	 */
 -	SCHED_WARN_ON(rq->clock_update_flags < RQCF_ACT_SKIP);
 -}
 +#define raw_rq()		(&__raw_get_cpu_var(runqueues))
  
  static inline u64 rq_clock(struct rq *rq)
  {
diff --git a/include/linux/sched/smt.h b/include/linux/sched/smt.h
new file mode 100644
index 000000000000..c9e0be514110
--- /dev/null
+++ b/include/linux/sched/smt.h
@@ -0,0 +1,18 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#ifndef _LINUX_SCHED_SMT_H
+#define _LINUX_SCHED_SMT_H
+
+#include <linux/static_key.h>
+
+#ifdef CONFIG_SCHED_SMT
+extern struct static_key_false sched_smt_present;
+
+static __always_inline bool sched_smt_active(void)
+{
+	return static_branch_likely(&sched_smt_present);
+}
+#else
+static inline bool sched_smt_active(void) { return false; }
+#endif
+
+#endif
* Unmerged path kernel/sched/sched.h
