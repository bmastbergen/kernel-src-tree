dm table: propagate BDI_CAP_STABLE_WRITES to fix sporadic checksum errors

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Ilya Dryomov <idryomov@gmail.com>
commit eb40c0acdc342b815d4d03ae6abb09e80c0f2988
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/eb40c0ac.failed

Some devices don't use blk_integrity but still want stable pages
because they do their own checksumming.  Examples include rbd and iSCSI
when data digests are negotiated.  Stacking DM (and thus LVM) on top of
these devices results in sporadic checksum errors.

Set BDI_CAP_STABLE_WRITES if any underlying device has it set.

	Cc: stable@vger.kernel.org
	Signed-off-by: Ilya Dryomov <idryomov@gmail.com>
	Signed-off-by: Mike Snitzer <snitzer@redhat.com>
(cherry picked from commit eb40c0acdc342b815d4d03ae6abb09e80c0f2988)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/dm-table.c
diff --cc drivers/md/dm-table.c
index f557e445aa5d,cde3b49b2a91..000000000000
--- a/drivers/md/dm-table.c
+++ b/drivers/md/dm-table.c
@@@ -1615,6 -1816,64 +1615,67 @@@ static bool dm_table_supports_discards(
  	return true;
  }
  
++<<<<<<< HEAD
++=======
+ static int device_not_secure_erase_capable(struct dm_target *ti,
+ 					   struct dm_dev *dev, sector_t start,
+ 					   sector_t len, void *data)
+ {
+ 	struct request_queue *q = bdev_get_queue(dev->bdev);
+ 
+ 	return q && !blk_queue_secure_erase(q);
+ }
+ 
+ static bool dm_table_supports_secure_erase(struct dm_table *t)
+ {
+ 	struct dm_target *ti;
+ 	unsigned int i;
+ 
+ 	for (i = 0; i < dm_table_get_num_targets(t); i++) {
+ 		ti = dm_table_get_target(t, i);
+ 
+ 		if (!ti->num_secure_erase_bios)
+ 			return false;
+ 
+ 		if (!ti->type->iterate_devices ||
+ 		    ti->type->iterate_devices(ti, device_not_secure_erase_capable, NULL))
+ 			return false;
+ 	}
+ 
+ 	return true;
+ }
+ 
+ static int device_requires_stable_pages(struct dm_target *ti,
+ 					struct dm_dev *dev, sector_t start,
+ 					sector_t len, void *data)
+ {
+ 	struct request_queue *q = bdev_get_queue(dev->bdev);
+ 
+ 	return q && bdi_cap_stable_pages_required(q->backing_dev_info);
+ }
+ 
+ /*
+  * If any underlying device requires stable pages, a table must require
+  * them as well.  Only targets that support iterate_devices are considered:
+  * don't want error, zero, etc to require stable pages.
+  */
+ static bool dm_table_requires_stable_pages(struct dm_table *t)
+ {
+ 	struct dm_target *ti;
+ 	unsigned i;
+ 
+ 	for (i = 0; i < dm_table_get_num_targets(t); i++) {
+ 		ti = dm_table_get_target(t, i);
+ 
+ 		if (ti->type->iterate_devices &&
+ 		    ti->type->iterate_devices(ti, device_requires_stable_pages, NULL))
+ 			return true;
+ 	}
+ 
+ 	return false;
+ }
+ 
++>>>>>>> eb40c0acdc34 (dm table: propagate BDI_CAP_STABLE_WRITES to fix sporadic checksum errors)
  void dm_table_set_restrictions(struct dm_table *t, struct request_queue *q,
  			       struct queue_limits *limits)
  {
@@@ -1664,14 -1921,20 +1725,23 @@@
  
  	if (!dm_table_supports_write_same(t))
  		q->limits.max_write_same_sectors = 0;
 -	if (!dm_table_supports_write_zeroes(t))
 -		q->limits.max_write_zeroes_sectors = 0;
  
 -	dm_table_verify_integrity(t);
 +	if (dm_table_all_devices_attribute(t, queue_supports_sg_merge))
 +		queue_flag_clear_unlocked(QUEUE_FLAG_NO_SG_MERGE, q);
 +	else
 +		queue_flag_set_unlocked(QUEUE_FLAG_NO_SG_MERGE, q);
 +
 +	dm_table_set_integrity(t);
  
+ 	/*
+ 	 * Some devices don't use blk_integrity but still want stable pages
+ 	 * because they do their own checksumming.
+ 	 */
+ 	if (dm_table_requires_stable_pages(t))
+ 		q->backing_dev_info->capabilities |= BDI_CAP_STABLE_WRITES;
+ 	else
+ 		q->backing_dev_info->capabilities &= ~BDI_CAP_STABLE_WRITES;
+ 
  	/*
  	 * Determine whether or not this queue's I/O timings contribute
  	 * to the entropy pool, Only request-based targets use this.
* Unmerged path drivers/md/dm-table.c
