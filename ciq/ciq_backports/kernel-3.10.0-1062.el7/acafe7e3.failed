treewide: Use struct_size() for kmalloc()-family

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Kees Cook <keescook@chromium.org>
commit acafe7e30216166a17e6e226aadc3ecb63993242
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/acafe7e3.failed

One of the more common cases of allocation size calculations is finding
the size of a structure that has a zero-sized array at the end, along
with memory for some number of elements for that array. For example:

struct foo {
    int stuff;
    void *entry[];
};

instance = kmalloc(sizeof(struct foo) + sizeof(void *) * count, GFP_KERNEL);

Instead of leaving these open-coded and prone to type mistakes, we can
now use the new struct_size() helper:

instance = kmalloc(struct_size(instance, entry, count), GFP_KERNEL);

This patch makes the changes for kmalloc()-family (and kvmalloc()-family)
uses. It was done via automatic conversion with manual review for the
"CHECKME" non-standard cases noted below, using the following Coccinelle
script:

// pkey_cache = kmalloc(sizeof *pkey_cache + tprops->pkey_tbl_len *
//                      sizeof *pkey_cache->table, GFP_KERNEL);
@@
identifier alloc =~ "kmalloc|kzalloc|kvmalloc|kvzalloc";
expression GFP;
identifier VAR, ELEMENT;
expression COUNT;
@@

- alloc(sizeof(*VAR) + COUNT * sizeof(*VAR->ELEMENT), GFP)
+ alloc(struct_size(VAR, ELEMENT, COUNT), GFP)

// mr = kzalloc(sizeof(*mr) + m * sizeof(mr->map[0]), GFP_KERNEL);
@@
identifier alloc =~ "kmalloc|kzalloc|kvmalloc|kvzalloc";
expression GFP;
identifier VAR, ELEMENT;
expression COUNT;
@@

- alloc(sizeof(*VAR) + COUNT * sizeof(VAR->ELEMENT[0]), GFP)
+ alloc(struct_size(VAR, ELEMENT, COUNT), GFP)

// Same pattern, but can't trivially locate the trailing element name,
// or variable name.
@@
identifier alloc =~ "kmalloc|kzalloc|kvmalloc|kvzalloc";
expression GFP;
expression SOMETHING, COUNT, ELEMENT;
@@

- alloc(sizeof(SOMETHING) + COUNT * sizeof(ELEMENT), GFP)
+ alloc(CHECKME_struct_size(&SOMETHING, ELEMENT, COUNT), GFP)

	Signed-off-by: Kees Cook <keescook@chromium.org>
(cherry picked from commit acafe7e30216166a17e6e226aadc3ecb63993242)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/clk/bcm/clk-iproc-asiu.c
#	drivers/clk/bcm/clk-iproc-pll.c
#	drivers/clk/berlin/bg2.c
#	drivers/clk/berlin/bg2q.c
#	drivers/clk/clk-asm9260.c
#	drivers/clk/clk-aspeed.c
#	drivers/clk/clk-clps711x.c
#	drivers/clk/clk-efm32gg.c
#	drivers/clk/clk-gemini.c
#	drivers/clk/clk-stm32h7.c
#	drivers/clk/clk-stm32mp1.c
#	drivers/clk/samsung/clk-exynos-clkout.c
#	drivers/dma/edma.c
#	drivers/dma/moxart-dma.c
#	drivers/dma/sh/usb-dmac.c
#	drivers/gpio/gpiolib.c
#	drivers/infiniband/core/cache.c
#	drivers/infiniband/core/uverbs_cmd.c
#	drivers/misc/vexpress-syscfg.c
#	drivers/net/wireless/mediatek/mt76/agg-rx.c
#	drivers/reset/core.c
#	drivers/s390/cio/ccwgroup.c
#	drivers/staging/greybus/module.c
#	drivers/usb/gadget/f_midi.c
#	drivers/zorro/zorro.c
#	fs/afs/addr_list.c
#	kernel/cgroup/cgroup.c
#	net/netfilter/xt_recent.c
#	net/sctp/endpointola.c
diff --cc drivers/dma/edma.c
index cd7e3280fadd,9bc722ca8329..000000000000
--- a/drivers/dma/edma.c
+++ b/drivers/dma/edma.c
@@@ -104,23 -751,615 +104,612 @@@ static void edma_desc_free(struct virt_
  /* Dispatch a queued descriptor to the controller (caller holds lock) */
  static void edma_execute(struct edma_chan *echan)
  {
 -	struct edma_cc *ecc = echan->ecc;
 -	struct virt_dma_desc *vdesc;
 +	struct virt_dma_desc *vdesc = vchan_next_desc(&echan->vchan);
  	struct edma_desc *edesc;
 -	struct device *dev = echan->vchan.chan.device->dev;
 -	int i, j, left, nslots;
 -
 -	if (!echan->edesc) {
 -		/* Setup is needed for the first transfer */
 -		vdesc = vchan_next_desc(&echan->vchan);
 -		if (!vdesc)
 -			return;
 -		list_del(&vdesc->node);
 -		echan->edesc = to_edma_desc(&vdesc->tx);
 +	int i;
 +
 +	if (!vdesc) {
 +		echan->edesc = NULL;
 +		return;
  	}
  
 -	edesc = echan->edesc;
 +	list_del(&vdesc->node);
  
 -	/* Find out how many left */
 -	left = edesc->pset_nr - edesc->processed;
 -	nslots = min(MAX_NR_SG, left);
 -	edesc->sg_len = 0;
 +	echan->edesc = edesc = to_edma_desc(&vdesc->tx);
  
  	/* Write descriptor PaRAM set(s) */
++<<<<<<< HEAD
 +	for (i = 0; i < edesc->pset_nr; i++) {
 +		edma_write_slot(echan->slot[i], &edesc->pset[i]);
 +		dev_dbg(echan->vchan.chan.device->dev,
++=======
+ 	for (i = 0; i < nslots; i++) {
+ 		j = i + edesc->processed;
+ 		edma_write_slot(ecc, echan->slot[i], &edesc->pset[j].param);
+ 		edesc->sg_len += edesc->pset[j].len;
+ 		dev_vdbg(dev,
+ 			 "\n pset[%d]:\n"
+ 			 "  chnum\t%d\n"
+ 			 "  slot\t%d\n"
+ 			 "  opt\t%08x\n"
+ 			 "  src\t%08x\n"
+ 			 "  dst\t%08x\n"
+ 			 "  abcnt\t%08x\n"
+ 			 "  ccnt\t%08x\n"
+ 			 "  bidx\t%08x\n"
+ 			 "  cidx\t%08x\n"
+ 			 "  lkrld\t%08x\n",
+ 			 j, echan->ch_num, echan->slot[i],
+ 			 edesc->pset[j].param.opt,
+ 			 edesc->pset[j].param.src,
+ 			 edesc->pset[j].param.dst,
+ 			 edesc->pset[j].param.a_b_cnt,
+ 			 edesc->pset[j].param.ccnt,
+ 			 edesc->pset[j].param.src_dst_bidx,
+ 			 edesc->pset[j].param.src_dst_cidx,
+ 			 edesc->pset[j].param.link_bcntrld);
+ 		/* Link to the previous slot if not the last set */
+ 		if (i != (nslots - 1))
+ 			edma_link(ecc, echan->slot[i], echan->slot[i + 1]);
+ 	}
+ 
+ 	edesc->processed += nslots;
+ 
+ 	/*
+ 	 * If this is either the last set in a set of SG-list transactions
+ 	 * then setup a link to the dummy slot, this results in all future
+ 	 * events being absorbed and that's OK because we're done
+ 	 */
+ 	if (edesc->processed == edesc->pset_nr) {
+ 		if (edesc->cyclic)
+ 			edma_link(ecc, echan->slot[nslots - 1], echan->slot[1]);
+ 		else
+ 			edma_link(ecc, echan->slot[nslots - 1],
+ 				  echan->ecc->dummy_slot);
+ 	}
+ 
+ 	if (echan->missed) {
+ 		/*
+ 		 * This happens due to setup times between intermediate
+ 		 * transfers in long SG lists which have to be broken up into
+ 		 * transfers of MAX_NR_SG
+ 		 */
+ 		dev_dbg(dev, "missed event on channel %d\n", echan->ch_num);
+ 		edma_clean_channel(echan);
+ 		edma_stop(echan);
+ 		edma_start(echan);
+ 		edma_trigger_channel(echan);
+ 		echan->missed = 0;
+ 	} else if (edesc->processed <= MAX_NR_SG) {
+ 		dev_dbg(dev, "first transfer starting on channel %d\n",
+ 			echan->ch_num);
+ 		edma_start(echan);
+ 	} else {
+ 		dev_dbg(dev, "chan: %d: completed %d elements, resuming\n",
+ 			echan->ch_num, edesc->processed);
+ 		edma_resume(echan);
+ 	}
+ }
+ 
+ static int edma_terminate_all(struct dma_chan *chan)
+ {
+ 	struct edma_chan *echan = to_edma_chan(chan);
+ 	unsigned long flags;
+ 	LIST_HEAD(head);
+ 
+ 	spin_lock_irqsave(&echan->vchan.lock, flags);
+ 
+ 	/*
+ 	 * Stop DMA activity: we assume the callback will not be called
+ 	 * after edma_dma() returns (even if it does, it will see
+ 	 * echan->edesc is NULL and exit.)
+ 	 */
+ 	if (echan->edesc) {
+ 		edma_stop(echan);
+ 		/* Move the cyclic channel back to default queue */
+ 		if (!echan->tc && echan->edesc->cyclic)
+ 			edma_assign_channel_eventq(echan, EVENTQ_DEFAULT);
+ 
+ 		vchan_terminate_vdesc(&echan->edesc->vdesc);
+ 		echan->edesc = NULL;
+ 	}
+ 
+ 	vchan_get_all_descriptors(&echan->vchan, &head);
+ 	spin_unlock_irqrestore(&echan->vchan.lock, flags);
+ 	vchan_dma_desc_free_list(&echan->vchan, &head);
+ 
+ 	return 0;
+ }
+ 
+ static void edma_synchronize(struct dma_chan *chan)
+ {
+ 	struct edma_chan *echan = to_edma_chan(chan);
+ 
+ 	vchan_synchronize(&echan->vchan);
+ }
+ 
+ static int edma_slave_config(struct dma_chan *chan,
+ 	struct dma_slave_config *cfg)
+ {
+ 	struct edma_chan *echan = to_edma_chan(chan);
+ 
+ 	if (cfg->src_addr_width == DMA_SLAVE_BUSWIDTH_8_BYTES ||
+ 	    cfg->dst_addr_width == DMA_SLAVE_BUSWIDTH_8_BYTES)
+ 		return -EINVAL;
+ 
+ 	if (cfg->src_maxburst > chan->device->max_burst ||
+ 	    cfg->dst_maxburst > chan->device->max_burst)
+ 		return -EINVAL;
+ 
+ 	memcpy(&echan->cfg, cfg, sizeof(echan->cfg));
+ 
+ 	return 0;
+ }
+ 
+ static int edma_dma_pause(struct dma_chan *chan)
+ {
+ 	struct edma_chan *echan = to_edma_chan(chan);
+ 
+ 	if (!echan->edesc)
+ 		return -EINVAL;
+ 
+ 	edma_pause(echan);
+ 	return 0;
+ }
+ 
+ static int edma_dma_resume(struct dma_chan *chan)
+ {
+ 	struct edma_chan *echan = to_edma_chan(chan);
+ 
+ 	edma_resume(echan);
+ 	return 0;
+ }
+ 
+ /*
+  * A PaRAM set configuration abstraction used by other modes
+  * @chan: Channel who's PaRAM set we're configuring
+  * @pset: PaRAM set to initialize and setup.
+  * @src_addr: Source address of the DMA
+  * @dst_addr: Destination address of the DMA
+  * @burst: In units of dev_width, how much to send
+  * @dev_width: How much is the dev_width
+  * @dma_length: Total length of the DMA transfer
+  * @direction: Direction of the transfer
+  */
+ static int edma_config_pset(struct dma_chan *chan, struct edma_pset *epset,
+ 			    dma_addr_t src_addr, dma_addr_t dst_addr, u32 burst,
+ 			    unsigned int acnt, unsigned int dma_length,
+ 			    enum dma_transfer_direction direction)
+ {
+ 	struct edma_chan *echan = to_edma_chan(chan);
+ 	struct device *dev = chan->device->dev;
+ 	struct edmacc_param *param = &epset->param;
+ 	int bcnt, ccnt, cidx;
+ 	int src_bidx, dst_bidx, src_cidx, dst_cidx;
+ 	int absync;
+ 
+ 	/* src/dst_maxburst == 0 is the same case as src/dst_maxburst == 1 */
+ 	if (!burst)
+ 		burst = 1;
+ 	/*
+ 	 * If the maxburst is equal to the fifo width, use
+ 	 * A-synced transfers. This allows for large contiguous
+ 	 * buffer transfers using only one PaRAM set.
+ 	 */
+ 	if (burst == 1) {
+ 		/*
+ 		 * For the A-sync case, bcnt and ccnt are the remainder
+ 		 * and quotient respectively of the division of:
+ 		 * (dma_length / acnt) by (SZ_64K -1). This is so
+ 		 * that in case bcnt over flows, we have ccnt to use.
+ 		 * Note: In A-sync tranfer only, bcntrld is used, but it
+ 		 * only applies for sg_dma_len(sg) >= SZ_64K.
+ 		 * In this case, the best way adopted is- bccnt for the
+ 		 * first frame will be the remainder below. Then for
+ 		 * every successive frame, bcnt will be SZ_64K-1. This
+ 		 * is assured as bcntrld = 0xffff in end of function.
+ 		 */
+ 		absync = false;
+ 		ccnt = dma_length / acnt / (SZ_64K - 1);
+ 		bcnt = dma_length / acnt - ccnt * (SZ_64K - 1);
+ 		/*
+ 		 * If bcnt is non-zero, we have a remainder and hence an
+ 		 * extra frame to transfer, so increment ccnt.
+ 		 */
+ 		if (bcnt)
+ 			ccnt++;
+ 		else
+ 			bcnt = SZ_64K - 1;
+ 		cidx = acnt;
+ 	} else {
+ 		/*
+ 		 * If maxburst is greater than the fifo address_width,
+ 		 * use AB-synced transfers where A count is the fifo
+ 		 * address_width and B count is the maxburst. In this
+ 		 * case, we are limited to transfers of C count frames
+ 		 * of (address_width * maxburst) where C count is limited
+ 		 * to SZ_64K-1. This places an upper bound on the length
+ 		 * of an SG segment that can be handled.
+ 		 */
+ 		absync = true;
+ 		bcnt = burst;
+ 		ccnt = dma_length / (acnt * bcnt);
+ 		if (ccnt > (SZ_64K - 1)) {
+ 			dev_err(dev, "Exceeded max SG segment size\n");
+ 			return -EINVAL;
+ 		}
+ 		cidx = acnt * bcnt;
+ 	}
+ 
+ 	epset->len = dma_length;
+ 
+ 	if (direction == DMA_MEM_TO_DEV) {
+ 		src_bidx = acnt;
+ 		src_cidx = cidx;
+ 		dst_bidx = 0;
+ 		dst_cidx = 0;
+ 		epset->addr = src_addr;
+ 	} else if (direction == DMA_DEV_TO_MEM)  {
+ 		src_bidx = 0;
+ 		src_cidx = 0;
+ 		dst_bidx = acnt;
+ 		dst_cidx = cidx;
+ 		epset->addr = dst_addr;
+ 	} else if (direction == DMA_MEM_TO_MEM)  {
+ 		src_bidx = acnt;
+ 		src_cidx = cidx;
+ 		dst_bidx = acnt;
+ 		dst_cidx = cidx;
+ 	} else {
+ 		dev_err(dev, "%s: direction not implemented yet\n", __func__);
+ 		return -EINVAL;
+ 	}
+ 
+ 	param->opt = EDMA_TCC(EDMA_CHAN_SLOT(echan->ch_num));
+ 	/* Configure A or AB synchronized transfers */
+ 	if (absync)
+ 		param->opt |= SYNCDIM;
+ 
+ 	param->src = src_addr;
+ 	param->dst = dst_addr;
+ 
+ 	param->src_dst_bidx = (dst_bidx << 16) | src_bidx;
+ 	param->src_dst_cidx = (dst_cidx << 16) | src_cidx;
+ 
+ 	param->a_b_cnt = bcnt << 16 | acnt;
+ 	param->ccnt = ccnt;
+ 	/*
+ 	 * Only time when (bcntrld) auto reload is required is for
+ 	 * A-sync case, and in this case, a requirement of reload value
+ 	 * of SZ_64K-1 only is assured. 'link' is initially set to NULL
+ 	 * and then later will be populated by edma_execute.
+ 	 */
+ 	param->link_bcntrld = 0xffffffff;
+ 	return absync;
+ }
+ 
+ static struct dma_async_tx_descriptor *edma_prep_slave_sg(
+ 	struct dma_chan *chan, struct scatterlist *sgl,
+ 	unsigned int sg_len, enum dma_transfer_direction direction,
+ 	unsigned long tx_flags, void *context)
+ {
+ 	struct edma_chan *echan = to_edma_chan(chan);
+ 	struct device *dev = chan->device->dev;
+ 	struct edma_desc *edesc;
+ 	dma_addr_t src_addr = 0, dst_addr = 0;
+ 	enum dma_slave_buswidth dev_width;
+ 	u32 burst;
+ 	struct scatterlist *sg;
+ 	int i, nslots, ret;
+ 
+ 	if (unlikely(!echan || !sgl || !sg_len))
+ 		return NULL;
+ 
+ 	if (direction == DMA_DEV_TO_MEM) {
+ 		src_addr = echan->cfg.src_addr;
+ 		dev_width = echan->cfg.src_addr_width;
+ 		burst = echan->cfg.src_maxburst;
+ 	} else if (direction == DMA_MEM_TO_DEV) {
+ 		dst_addr = echan->cfg.dst_addr;
+ 		dev_width = echan->cfg.dst_addr_width;
+ 		burst = echan->cfg.dst_maxburst;
+ 	} else {
+ 		dev_err(dev, "%s: bad direction: %d\n", __func__, direction);
+ 		return NULL;
+ 	}
+ 
+ 	if (dev_width == DMA_SLAVE_BUSWIDTH_UNDEFINED) {
+ 		dev_err(dev, "%s: Undefined slave buswidth\n", __func__);
+ 		return NULL;
+ 	}
+ 
+ 	edesc = kzalloc(struct_size(edesc, pset, sg_len), GFP_ATOMIC);
+ 	if (!edesc)
+ 		return NULL;
+ 
+ 	edesc->pset_nr = sg_len;
+ 	edesc->residue = 0;
+ 	edesc->direction = direction;
+ 	edesc->echan = echan;
+ 
+ 	/* Allocate a PaRAM slot, if needed */
+ 	nslots = min_t(unsigned, MAX_NR_SG, sg_len);
+ 
+ 	for (i = 0; i < nslots; i++) {
+ 		if (echan->slot[i] < 0) {
+ 			echan->slot[i] =
+ 				edma_alloc_slot(echan->ecc, EDMA_SLOT_ANY);
+ 			if (echan->slot[i] < 0) {
+ 				kfree(edesc);
+ 				dev_err(dev, "%s: Failed to allocate slot\n",
+ 					__func__);
+ 				return NULL;
+ 			}
+ 		}
+ 	}
+ 
+ 	/* Configure PaRAM sets for each SG */
+ 	for_each_sg(sgl, sg, sg_len, i) {
+ 		/* Get address for each SG */
+ 		if (direction == DMA_DEV_TO_MEM)
+ 			dst_addr = sg_dma_address(sg);
+ 		else
+ 			src_addr = sg_dma_address(sg);
+ 
+ 		ret = edma_config_pset(chan, &edesc->pset[i], src_addr,
+ 				       dst_addr, burst, dev_width,
+ 				       sg_dma_len(sg), direction);
+ 		if (ret < 0) {
+ 			kfree(edesc);
+ 			return NULL;
+ 		}
+ 
+ 		edesc->absync = ret;
+ 		edesc->residue += sg_dma_len(sg);
+ 
+ 		if (i == sg_len - 1)
+ 			/* Enable completion interrupt */
+ 			edesc->pset[i].param.opt |= TCINTEN;
+ 		else if (!((i+1) % MAX_NR_SG))
+ 			/*
+ 			 * Enable early completion interrupt for the
+ 			 * intermediateset. In this case the driver will be
+ 			 * notified when the paRAM set is submitted to TC. This
+ 			 * will allow more time to set up the next set of slots.
+ 			 */
+ 			edesc->pset[i].param.opt |= (TCINTEN | TCCMODE);
+ 	}
+ 	edesc->residue_stat = edesc->residue;
+ 
+ 	return vchan_tx_prep(&echan->vchan, &edesc->vdesc, tx_flags);
+ }
+ 
+ static struct dma_async_tx_descriptor *edma_prep_dma_memcpy(
+ 	struct dma_chan *chan, dma_addr_t dest, dma_addr_t src,
+ 	size_t len, unsigned long tx_flags)
+ {
+ 	int ret, nslots;
+ 	struct edma_desc *edesc;
+ 	struct device *dev = chan->device->dev;
+ 	struct edma_chan *echan = to_edma_chan(chan);
+ 	unsigned int width, pset_len, array_size;
+ 
+ 	if (unlikely(!echan || !len))
+ 		return NULL;
+ 
+ 	/* Align the array size (acnt block) with the transfer properties */
+ 	switch (__ffs((src | dest | len))) {
+ 	case 0:
+ 		array_size = SZ_32K - 1;
+ 		break;
+ 	case 1:
+ 		array_size = SZ_32K - 2;
+ 		break;
+ 	default:
+ 		array_size = SZ_32K - 4;
+ 		break;
+ 	}
+ 
+ 	if (len < SZ_64K) {
+ 		/*
+ 		 * Transfer size less than 64K can be handled with one paRAM
+ 		 * slot and with one burst.
+ 		 * ACNT = length
+ 		 */
+ 		width = len;
+ 		pset_len = len;
+ 		nslots = 1;
+ 	} else {
+ 		/*
+ 		 * Transfer size bigger than 64K will be handled with maximum of
+ 		 * two paRAM slots.
+ 		 * slot1: (full_length / 32767) times 32767 bytes bursts.
+ 		 *	  ACNT = 32767, length1: (full_length / 32767) * 32767
+ 		 * slot2: the remaining amount of data after slot1.
+ 		 *	  ACNT = full_length - length1, length2 = ACNT
+ 		 *
+ 		 * When the full_length is multibple of 32767 one slot can be
+ 		 * used to complete the transfer.
+ 		 */
+ 		width = array_size;
+ 		pset_len = rounddown(len, width);
+ 		/* One slot is enough for lengths multiple of (SZ_32K -1) */
+ 		if (unlikely(pset_len == len))
+ 			nslots = 1;
+ 		else
+ 			nslots = 2;
+ 	}
+ 
+ 	edesc = kzalloc(struct_size(edesc, pset, nslots), GFP_ATOMIC);
+ 	if (!edesc)
+ 		return NULL;
+ 
+ 	edesc->pset_nr = nslots;
+ 	edesc->residue = edesc->residue_stat = len;
+ 	edesc->direction = DMA_MEM_TO_MEM;
+ 	edesc->echan = echan;
+ 
+ 	ret = edma_config_pset(chan, &edesc->pset[0], src, dest, 1,
+ 			       width, pset_len, DMA_MEM_TO_MEM);
+ 	if (ret < 0) {
+ 		kfree(edesc);
+ 		return NULL;
+ 	}
+ 
+ 	edesc->absync = ret;
+ 
+ 	edesc->pset[0].param.opt |= ITCCHEN;
+ 	if (nslots == 1) {
+ 		/* Enable transfer complete interrupt */
+ 		edesc->pset[0].param.opt |= TCINTEN;
+ 	} else {
+ 		/* Enable transfer complete chaining for the first slot */
+ 		edesc->pset[0].param.opt |= TCCHEN;
+ 
+ 		if (echan->slot[1] < 0) {
+ 			echan->slot[1] = edma_alloc_slot(echan->ecc,
+ 							 EDMA_SLOT_ANY);
+ 			if (echan->slot[1] < 0) {
+ 				kfree(edesc);
+ 				dev_err(dev, "%s: Failed to allocate slot\n",
+ 					__func__);
+ 				return NULL;
+ 			}
+ 		}
+ 		dest += pset_len;
+ 		src += pset_len;
+ 		pset_len = width = len % array_size;
+ 
+ 		ret = edma_config_pset(chan, &edesc->pset[1], src, dest, 1,
+ 				       width, pset_len, DMA_MEM_TO_MEM);
+ 		if (ret < 0) {
+ 			kfree(edesc);
+ 			return NULL;
+ 		}
+ 
+ 		edesc->pset[1].param.opt |= ITCCHEN;
+ 		edesc->pset[1].param.opt |= TCINTEN;
+ 	}
+ 
+ 	return vchan_tx_prep(&echan->vchan, &edesc->vdesc, tx_flags);
+ }
+ 
+ static struct dma_async_tx_descriptor *edma_prep_dma_cyclic(
+ 	struct dma_chan *chan, dma_addr_t buf_addr, size_t buf_len,
+ 	size_t period_len, enum dma_transfer_direction direction,
+ 	unsigned long tx_flags)
+ {
+ 	struct edma_chan *echan = to_edma_chan(chan);
+ 	struct device *dev = chan->device->dev;
+ 	struct edma_desc *edesc;
+ 	dma_addr_t src_addr, dst_addr;
+ 	enum dma_slave_buswidth dev_width;
+ 	bool use_intermediate = false;
+ 	u32 burst;
+ 	int i, ret, nslots;
+ 
+ 	if (unlikely(!echan || !buf_len || !period_len))
+ 		return NULL;
+ 
+ 	if (direction == DMA_DEV_TO_MEM) {
+ 		src_addr = echan->cfg.src_addr;
+ 		dst_addr = buf_addr;
+ 		dev_width = echan->cfg.src_addr_width;
+ 		burst = echan->cfg.src_maxburst;
+ 	} else if (direction == DMA_MEM_TO_DEV) {
+ 		src_addr = buf_addr;
+ 		dst_addr = echan->cfg.dst_addr;
+ 		dev_width = echan->cfg.dst_addr_width;
+ 		burst = echan->cfg.dst_maxburst;
+ 	} else {
+ 		dev_err(dev, "%s: bad direction: %d\n", __func__, direction);
+ 		return NULL;
+ 	}
+ 
+ 	if (dev_width == DMA_SLAVE_BUSWIDTH_UNDEFINED) {
+ 		dev_err(dev, "%s: Undefined slave buswidth\n", __func__);
+ 		return NULL;
+ 	}
+ 
+ 	if (unlikely(buf_len % period_len)) {
+ 		dev_err(dev, "Period should be multiple of Buffer length\n");
+ 		return NULL;
+ 	}
+ 
+ 	nslots = (buf_len / period_len) + 1;
+ 
+ 	/*
+ 	 * Cyclic DMA users such as audio cannot tolerate delays introduced
+ 	 * by cases where the number of periods is more than the maximum
+ 	 * number of SGs the EDMA driver can handle at a time. For DMA types
+ 	 * such as Slave SGs, such delays are tolerable and synchronized,
+ 	 * but the synchronization is difficult to achieve with Cyclic and
+ 	 * cannot be guaranteed, so we error out early.
+ 	 */
+ 	if (nslots > MAX_NR_SG) {
+ 		/*
+ 		 * If the burst and period sizes are the same, we can put
+ 		 * the full buffer into a single period and activate
+ 		 * intermediate interrupts. This will produce interrupts
+ 		 * after each burst, which is also after each desired period.
+ 		 */
+ 		if (burst == period_len) {
+ 			period_len = buf_len;
+ 			nslots = 2;
+ 			use_intermediate = true;
+ 		} else {
+ 			return NULL;
+ 		}
+ 	}
+ 
+ 	edesc = kzalloc(struct_size(edesc, pset, nslots), GFP_ATOMIC);
+ 	if (!edesc)
+ 		return NULL;
+ 
+ 	edesc->cyclic = 1;
+ 	edesc->pset_nr = nslots;
+ 	edesc->residue = edesc->residue_stat = buf_len;
+ 	edesc->direction = direction;
+ 	edesc->echan = echan;
+ 
+ 	dev_dbg(dev, "%s: channel=%d nslots=%d period_len=%zu buf_len=%zu\n",
+ 		__func__, echan->ch_num, nslots, period_len, buf_len);
+ 
+ 	for (i = 0; i < nslots; i++) {
+ 		/* Allocate a PaRAM slot, if needed */
+ 		if (echan->slot[i] < 0) {
+ 			echan->slot[i] =
+ 				edma_alloc_slot(echan->ecc, EDMA_SLOT_ANY);
+ 			if (echan->slot[i] < 0) {
+ 				kfree(edesc);
+ 				dev_err(dev, "%s: Failed to allocate slot\n",
+ 					__func__);
+ 				return NULL;
+ 			}
+ 		}
+ 
+ 		if (i == nslots - 1) {
+ 			memcpy(&edesc->pset[i], &edesc->pset[0],
+ 			       sizeof(edesc->pset[0]));
+ 			break;
+ 		}
+ 
+ 		ret = edma_config_pset(chan, &edesc->pset[i], src_addr,
+ 				       dst_addr, burst, dev_width, period_len,
+ 				       direction);
+ 		if (ret < 0) {
+ 			kfree(edesc);
+ 			return NULL;
+ 		}
+ 
+ 		if (direction == DMA_DEV_TO_MEM)
+ 			dst_addr += period_len;
+ 		else
+ 			src_addr += period_len;
+ 
+ 		dev_vdbg(dev, "%s: Configure period %d of buf:\n", __func__, i);
+ 		dev_vdbg(dev,
++>>>>>>> acafe7e30216 (treewide: Use struct_size() for kmalloc()-family)
  			"\n pset[%d]:\n"
  			"  chnum\t%d\n"
  			"  slot\t%d\n"
diff --cc drivers/gpio/gpiolib.c
index 001ee0831fc2,c4518fa9070f..000000000000
--- a/drivers/gpio/gpiolib.c
+++ b/drivers/gpio/gpiolib.c
@@@ -2982,7 -3933,135 +2982,139 @@@ struct gpio_desc *__must_check __gpiod_
  
  	return desc;
  }
++<<<<<<< HEAD
 +EXPORT_SYMBOL_GPL(__gpiod_get_index_optional);
++=======
+ EXPORT_SYMBOL_GPL(gpiod_get_index_optional);
+ 
+ /**
+  * gpiod_hog - Hog the specified GPIO desc given the provided flags
+  * @desc:	gpio whose value will be assigned
+  * @name:	gpio line name
+  * @lflags:	gpio_lookup_flags - returned from of_find_gpio() or
+  *		of_get_gpio_hog()
+  * @dflags:	gpiod_flags - optional GPIO initialization flags
+  */
+ int gpiod_hog(struct gpio_desc *desc, const char *name,
+ 	      unsigned long lflags, enum gpiod_flags dflags)
+ {
+ 	struct gpio_chip *chip;
+ 	struct gpio_desc *local_desc;
+ 	int hwnum;
+ 	int status;
+ 
+ 	chip = gpiod_to_chip(desc);
+ 	hwnum = gpio_chip_hwgpio(desc);
+ 
+ 	local_desc = gpiochip_request_own_desc(chip, hwnum, name);
+ 	if (IS_ERR(local_desc)) {
+ 		status = PTR_ERR(local_desc);
+ 		pr_err("requesting hog GPIO %s (chip %s, offset %d) failed, %d\n",
+ 		       name, chip->label, hwnum, status);
+ 		return status;
+ 	}
+ 
+ 	status = gpiod_configure_flags(desc, name, lflags, dflags);
+ 	if (status < 0) {
+ 		pr_err("setup of hog GPIO %s (chip %s, offset %d) failed, %d\n",
+ 		       name, chip->label, hwnum, status);
+ 		gpiochip_free_own_desc(desc);
+ 		return status;
+ 	}
+ 
+ 	/* Mark GPIO as hogged so it can be identified and removed later */
+ 	set_bit(FLAG_IS_HOGGED, &desc->flags);
+ 
+ 	pr_info("GPIO line %d (%s) hogged as %s%s\n",
+ 		desc_to_gpio(desc), name,
+ 		(dflags&GPIOD_FLAGS_BIT_DIR_OUT) ? "output" : "input",
+ 		(dflags&GPIOD_FLAGS_BIT_DIR_OUT) ?
+ 		  (dflags&GPIOD_FLAGS_BIT_DIR_VAL) ? "/high" : "/low":"");
+ 
+ 	return 0;
+ }
+ 
+ /**
+  * gpiochip_free_hogs - Scan gpio-controller chip and release GPIO hog
+  * @chip:	gpio chip to act on
+  *
+  * This is only used by of_gpiochip_remove to free hogged gpios
+  */
+ static void gpiochip_free_hogs(struct gpio_chip *chip)
+ {
+ 	int id;
+ 
+ 	for (id = 0; id < chip->ngpio; id++) {
+ 		if (test_bit(FLAG_IS_HOGGED, &chip->gpiodev->descs[id].flags))
+ 			gpiochip_free_own_desc(&chip->gpiodev->descs[id]);
+ 	}
+ }
+ 
+ /**
+  * gpiod_get_array - obtain multiple GPIOs from a multi-index GPIO function
+  * @dev:	GPIO consumer, can be NULL for system-global GPIOs
+  * @con_id:	function within the GPIO consumer
+  * @flags:	optional GPIO initialization flags
+  *
+  * This function acquires all the GPIOs defined under a given function.
+  *
+  * Return a struct gpio_descs containing an array of descriptors, -ENOENT if
+  * no GPIO has been assigned to the requested function, or another IS_ERR()
+  * code if an error occurred while trying to acquire the GPIOs.
+  */
+ struct gpio_descs *__must_check gpiod_get_array(struct device *dev,
+ 						const char *con_id,
+ 						enum gpiod_flags flags)
+ {
+ 	struct gpio_desc *desc;
+ 	struct gpio_descs *descs;
+ 	int count;
+ 
+ 	count = gpiod_count(dev, con_id);
+ 	if (count < 0)
+ 		return ERR_PTR(count);
+ 
+ 	descs = kzalloc(struct_size(descs, desc, count), GFP_KERNEL);
+ 	if (!descs)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	for (descs->ndescs = 0; descs->ndescs < count; ) {
+ 		desc = gpiod_get_index(dev, con_id, descs->ndescs, flags);
+ 		if (IS_ERR(desc)) {
+ 			gpiod_put_array(descs);
+ 			return ERR_CAST(desc);
+ 		}
+ 		descs->desc[descs->ndescs] = desc;
+ 		descs->ndescs++;
+ 	}
+ 	return descs;
+ }
+ EXPORT_SYMBOL_GPL(gpiod_get_array);
+ 
+ /**
+  * gpiod_get_array_optional - obtain multiple GPIOs from a multi-index GPIO
+  *                            function
+  * @dev:	GPIO consumer, can be NULL for system-global GPIOs
+  * @con_id:	function within the GPIO consumer
+  * @flags:	optional GPIO initialization flags
+  *
+  * This is equivalent to gpiod_get_array(), except that when no GPIO was
+  * assigned to the requested function it will return NULL.
+  */
+ struct gpio_descs *__must_check gpiod_get_array_optional(struct device *dev,
+ 							const char *con_id,
+ 							enum gpiod_flags flags)
+ {
+ 	struct gpio_descs *descs;
+ 
+ 	descs = gpiod_get_array(dev, con_id, flags);
+ 	if (IS_ERR(descs) && (PTR_ERR(descs) == -ENOENT))
+ 		return NULL;
+ 
+ 	return descs;
+ }
+ EXPORT_SYMBOL_GPL(gpiod_get_array_optional);
++>>>>>>> acafe7e30216 (treewide: Use struct_size() for kmalloc()-family)
  
  /**
   * gpiod_put - dispose of a GPIO descriptor
diff --cc drivers/infiniband/core/cache.c
index 36d3478f5cc1,cad8f1d7954b..000000000000
--- a/drivers/infiniband/core/cache.c
+++ b/drivers/infiniband/core/cache.c
@@@ -1124,8 -1150,16 +1124,21 @@@ static void ib_cache_update(struct ib_d
  		goto err;
  	}
  
++<<<<<<< HEAD
 +	pkey_cache = kmalloc(sizeof *pkey_cache + tprops->pkey_tbl_len *
 +			     sizeof *pkey_cache->table, GFP_KERNEL);
++=======
+ 	if (!rdma_protocol_roce(device, port)) {
+ 		ret = config_non_roce_gid_cache(device, port,
+ 						tprops->gid_tbl_len);
+ 		if (ret)
+ 			goto err;
+ 	}
+ 
+ 	pkey_cache = kmalloc(struct_size(pkey_cache, table,
+ 					 tprops->pkey_tbl_len),
+ 			     GFP_KERNEL);
++>>>>>>> acafe7e30216 (treewide: Use struct_size() for kmalloc()-family)
  	if (!pkey_cache)
  		goto err;
  
diff --cc drivers/infiniband/core/uverbs_cmd.c
index 507521d53e3f,e3662a8ee465..000000000000
--- a/drivers/infiniband/core/uverbs_cmd.c
+++ b/drivers/infiniband/core/uverbs_cmd.c
@@@ -2782,7 -2755,9 +2782,13 @@@ static struct ib_uflow_resources *flow_
  {
  	struct ib_uflow_resources *resources;
  
++<<<<<<< HEAD
 +	resources = kzalloc(sizeof(*resources), GFP_KERNEL);
++=======
+ 	resources =
+ 		kmalloc(struct_size(resources, collection, num_specs),
+ 			GFP_KERNEL);
++>>>>>>> acafe7e30216 (treewide: Use struct_size() for kmalloc()-family)
  
  	if (!resources)
  		return NULL;
diff --cc drivers/reset/core.c
index d1b6089a0ef8,225e34c56b94..000000000000
--- a/drivers/reset/core.c
+++ b/drivers/reset/core.c
@@@ -294,4 -681,116 +294,120 @@@ int device_reset(struct device *dev
  
  	return ret;
  }
++<<<<<<< HEAD
 +EXPORT_SYMBOL_GPL(device_reset);
++=======
+ EXPORT_SYMBOL_GPL(__device_reset);
+ 
+ /**
+  * APIs to manage an array of reset controls.
+  */
+ /**
+  * of_reset_control_get_count - Count number of resets available with a device
+  *
+  * @node: device node that contains 'resets'.
+  *
+  * Returns positive reset count on success, or error number on failure and
+  * on count being zero.
+  */
+ static int of_reset_control_get_count(struct device_node *node)
+ {
+ 	int count;
+ 
+ 	if (!node)
+ 		return -EINVAL;
+ 
+ 	count = of_count_phandle_with_args(node, "resets", "#reset-cells");
+ 	if (count == 0)
+ 		count = -ENOENT;
+ 
+ 	return count;
+ }
+ 
+ /**
+  * of_reset_control_array_get - Get a list of reset controls using
+  *				device node.
+  *
+  * @np: device node for the device that requests the reset controls array
+  * @shared: whether reset controls are shared or not
+  * @optional: whether it is optional to get the reset controls
+  *
+  * Returns pointer to allocated reset_control_array on success or
+  * error on failure
+  */
+ struct reset_control *
+ of_reset_control_array_get(struct device_node *np, bool shared, bool optional)
+ {
+ 	struct reset_control_array *resets;
+ 	struct reset_control *rstc;
+ 	int num, i;
+ 
+ 	num = of_reset_control_get_count(np);
+ 	if (num < 0)
+ 		return optional ? NULL : ERR_PTR(num);
+ 
+ 	resets = kzalloc(struct_size(resets, rstc, num), GFP_KERNEL);
+ 	if (!resets)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	for (i = 0; i < num; i++) {
+ 		rstc = __of_reset_control_get(np, NULL, i, shared, optional);
+ 		if (IS_ERR(rstc))
+ 			goto err_rst;
+ 		resets->rstc[i] = rstc;
+ 	}
+ 	resets->num_rstcs = num;
+ 	resets->base.array = true;
+ 
+ 	return &resets->base;
+ 
+ err_rst:
+ 	mutex_lock(&reset_list_mutex);
+ 	while (--i >= 0)
+ 		__reset_control_put_internal(resets->rstc[i]);
+ 	mutex_unlock(&reset_list_mutex);
+ 
+ 	kfree(resets);
+ 
+ 	return rstc;
+ }
+ EXPORT_SYMBOL_GPL(of_reset_control_array_get);
+ 
+ /**
+  * devm_reset_control_array_get - Resource managed reset control array get
+  *
+  * @dev: device that requests the list of reset controls
+  * @shared: whether reset controls are shared or not
+  * @optional: whether it is optional to get the reset controls
+  *
+  * The reset control array APIs are intended for a list of resets
+  * that just have to be asserted or deasserted, without any
+  * requirements on the order.
+  *
+  * Returns pointer to allocated reset_control_array on success or
+  * error on failure
+  */
+ struct reset_control *
+ devm_reset_control_array_get(struct device *dev, bool shared, bool optional)
+ {
+ 	struct reset_control **devres;
+ 	struct reset_control *rstc;
+ 
+ 	devres = devres_alloc(devm_reset_control_release, sizeof(*devres),
+ 			      GFP_KERNEL);
+ 	if (!devres)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	rstc = of_reset_control_array_get(dev->of_node, shared, optional);
+ 	if (IS_ERR(rstc)) {
+ 		devres_free(devres);
+ 		return rstc;
+ 	}
+ 
+ 	*devres = rstc;
+ 	devres_add(dev, devres);
+ 
+ 	return rstc;
+ }
+ EXPORT_SYMBOL_GPL(devm_reset_control_array_get);
++>>>>>>> acafe7e30216 (treewide: Use struct_size() for kmalloc()-family)
diff --cc drivers/s390/cio/ccwgroup.c
index 84846c2b96d3,838752efc1c0..000000000000
--- a/drivers/s390/cio/ccwgroup.c
+++ b/drivers/s390/cio/ccwgroup.c
@@@ -315,8 -323,10 +315,15 @@@ int ccwgroup_create_dev(struct device *
  	struct ccw_dev_id dev_id;
  	int rc, i;
  
++<<<<<<< HEAD
 +	gdev = kzalloc(sizeof(*gdev) + num_devices * sizeof(gdev->cdev[0]),
 +		       GFP_KERNEL);
++=======
+ 	if (num_devices < 1)
+ 		return -EINVAL;
+ 
+ 	gdev = kzalloc(struct_size(gdev, cdev, num_devices), GFP_KERNEL);
++>>>>>>> acafe7e30216 (treewide: Use struct_size() for kmalloc()-family)
  	if (!gdev)
  		return -ENOMEM;
  
diff --cc drivers/usb/gadget/f_midi.c
index 94942a25707f,3fcc8aaaa446..000000000000
--- a/drivers/usb/gadget/f_midi.c
+++ b/drivers/usb/gadget/f_midi.c
@@@ -911,84 -1064,275 +911,89 @@@ fail
  	return status;
  }
  
 -static inline struct f_midi_opts *to_f_midi_opts(struct config_item *item)
 -{
 -	return container_of(to_config_group(item), struct f_midi_opts,
 -			    func_inst.group);
 -}
 -
 -static void midi_attr_release(struct config_item *item)
 -{
 -	struct f_midi_opts *opts = to_f_midi_opts(item);
 -
 -	usb_put_function_instance(&opts->func_inst);
 -}
 -
 -static struct configfs_item_operations midi_item_ops = {
 -	.release	= midi_attr_release,
 -};
 -
 -#define F_MIDI_OPT(name, test_limit, limit)				\
 -static ssize_t f_midi_opts_##name##_show(struct config_item *item, char *page) \
 -{									\
 -	struct f_midi_opts *opts = to_f_midi_opts(item);		\
 -	int result;							\
 -									\
 -	mutex_lock(&opts->lock);					\
 -	result = sprintf(page, "%d\n", opts->name);			\
 -	mutex_unlock(&opts->lock);					\
 -									\
 -	return result;							\
 -}									\
 -									\
 -static ssize_t f_midi_opts_##name##_store(struct config_item *item,	\
 -					 const char *page, size_t len)	\
 -{									\
 -	struct f_midi_opts *opts = to_f_midi_opts(item);		\
 -	int ret;							\
 -	u32 num;							\
 -									\
 -	mutex_lock(&opts->lock);					\
 -	if (opts->refcnt) {						\
 -		ret = -EBUSY;						\
 -		goto end;						\
 -	}								\
 -									\
 -	ret = kstrtou32(page, 0, &num);					\
 -	if (ret)							\
 -		goto end;						\
 -									\
 -	if (test_limit && num > limit) {				\
 -		ret = -EINVAL;						\
 -		goto end;						\
 -	}								\
 -	opts->name = num;						\
 -	ret = len;							\
 -									\
 -end:									\
 -	mutex_unlock(&opts->lock);					\
 -	return ret;							\
 -}									\
 -									\
 -CONFIGFS_ATTR(f_midi_opts_, name);
 -
 -F_MIDI_OPT(index, true, SNDRV_CARDS);
 -F_MIDI_OPT(buflen, false, 0);
 -F_MIDI_OPT(qlen, false, 0);
 -F_MIDI_OPT(in_ports, true, MAX_PORTS);
 -F_MIDI_OPT(out_ports, true, MAX_PORTS);
 -
 -static ssize_t f_midi_opts_id_show(struct config_item *item, char *page)
 -{
 -	struct f_midi_opts *opts = to_f_midi_opts(item);
 -	int result;
 -
 -	mutex_lock(&opts->lock);
 -	if (opts->id) {
 -		result = strlcpy(page, opts->id, PAGE_SIZE);
 -	} else {
 -		page[0] = 0;
 -		result = 0;
 -	}
 -
 -	mutex_unlock(&opts->lock);
 -
 -	return result;
 -}
 -
 -static ssize_t f_midi_opts_id_store(struct config_item *item,
 -				    const char *page, size_t len)
 -{
 -	struct f_midi_opts *opts = to_f_midi_opts(item);
 -	int ret;
 -	char *c;
 -
 -	mutex_lock(&opts->lock);
 -	if (opts->refcnt) {
 -		ret = -EBUSY;
 -		goto end;
 -	}
 -
 -	c = kstrndup(page, len, GFP_KERNEL);
 -	if (!c) {
 -		ret = -ENOMEM;
 -		goto end;
 -	}
 -	if (opts->id_allocated)
 -		kfree(opts->id);
 -	opts->id = c;
 -	opts->id_allocated = true;
 -	ret = len;
 -end:
 -	mutex_unlock(&opts->lock);
 -	return ret;
 -}
 -
 -CONFIGFS_ATTR(f_midi_opts_, id);
 -
 -static struct configfs_attribute *midi_attrs[] = {
 -	&f_midi_opts_attr_index,
 -	&f_midi_opts_attr_buflen,
 -	&f_midi_opts_attr_qlen,
 -	&f_midi_opts_attr_in_ports,
 -	&f_midi_opts_attr_out_ports,
 -	&f_midi_opts_attr_id,
 -	NULL,
 -};
 -
 -static const struct config_item_type midi_func_type = {
 -	.ct_item_ops	= &midi_item_ops,
 -	.ct_attrs	= midi_attrs,
 -	.ct_owner	= THIS_MODULE,
 -};
 -
 -static void f_midi_free_inst(struct usb_function_instance *f)
 -{
 -	struct f_midi_opts *opts;
 -
 -	opts = container_of(f, struct f_midi_opts, func_inst);
 -
 -	if (opts->id_allocated)
 -		kfree(opts->id);
 -
 -	kfree(opts);
 -}
 -
 -static struct usb_function_instance *f_midi_alloc_inst(void)
 -{
 -	struct f_midi_opts *opts;
 -
 -	opts = kzalloc(sizeof(*opts), GFP_KERNEL);
 -	if (!opts)
 -		return ERR_PTR(-ENOMEM);
 -
 -	mutex_init(&opts->lock);
 -	opts->func_inst.free_func_inst = f_midi_free_inst;
 -	opts->index = SNDRV_DEFAULT_IDX1;
 -	opts->id = SNDRV_DEFAULT_STR1;
 -	opts->buflen = 512;
 -	opts->qlen = 32;
 -	opts->in_ports = 1;
 -	opts->out_ports = 1;
 -
 -	config_group_init_type_name(&opts->func_inst.group, "",
 -				    &midi_func_type);
 -
 -	return &opts->func_inst;
 -}
 -
 -static void f_midi_free(struct usb_function *f)
 +/**
 + * f_midi_bind_config - add USB MIDI function to a configuration
 + * @c: the configuration to supcard the USB audio function
 + * @index: the soundcard index to use for the ALSA device creation
 + * @id: the soundcard id to use for the ALSA device creation
 + * @buflen: the buffer length to use
 + * @qlen the number of read requests to pre-allocate
 + * Context: single threaded during gadget setup
 + *
 + * Returns zero on success, else negative errno.
 + */
 +int __init f_midi_bind_config(struct usb_configuration *c,
 +			      int index, char *id,
 +			      unsigned int in_ports,
 +			      unsigned int out_ports,
 +			      unsigned int buflen,
 +			      unsigned int qlen)
  {
  	struct f_midi *midi;
 -	struct f_midi_opts *opts;
 -
 -	midi = func_to_midi(f);
 -	opts = container_of(f->fi, struct f_midi_opts, func_inst);
 -	mutex_lock(&opts->lock);
 -	if (!--midi->free_ref) {
 -		kfree(midi->id);
 -		kfifo_free(&midi->in_req_fifo);
 -		kfree(midi);
 -		--opts->refcnt;
 -	}
 -	mutex_unlock(&opts->lock);
 -}
 -
 -static void f_midi_rmidi_free(struct snd_rawmidi *rmidi)
 -{
 -	f_midi_free(rmidi->private_data);
 -}
 -
 -static void f_midi_unbind(struct usb_configuration *c, struct usb_function *f)
 -{
 -	struct usb_composite_dev *cdev = f->config->cdev;
 -	struct f_midi *midi = func_to_midi(f);
 -	struct snd_card *card;
 -
 -	DBG(cdev, "unbind\n");
 -
 -	/* just to be sure */
 -	f_midi_disable(f);
 -
 -	card = midi->card;
 -	midi->card = NULL;
 -	if (card)
 -		snd_card_free_when_closed(card);
 -
 -	usb_free_all_descriptors(f);
 -}
 -
 -static struct usb_function *f_midi_alloc(struct usb_function_instance *fi)
 -{
 -	struct f_midi *midi = NULL;
 -	struct f_midi_opts *opts;
  	int status, i;
  
 -	opts = container_of(fi, struct f_midi_opts, func_inst);
 -
 -	mutex_lock(&opts->lock);
  	/* sanity check */
 -	if (opts->in_ports > MAX_PORTS || opts->out_ports > MAX_PORTS) {
 -		status = -EINVAL;
 -		goto setup_fail;
 -	}
 +	if (in_ports > MAX_PORTS || out_ports > MAX_PORTS)
 +		return -EINVAL;
  
  	/* allocate and initialize one new instance */
++<<<<<<< HEAD:drivers/usb/gadget/f_midi.c
 +	midi = kzalloc(sizeof *midi, GFP_KERNEL);
++=======
+ 	midi = kzalloc(struct_size(midi, in_ports_array, opts->in_ports),
+ 		       GFP_KERNEL);
++>>>>>>> acafe7e30216 (treewide: Use struct_size() for kmalloc()-family):drivers/usb/gadget/function/f_midi.c
  	if (!midi) {
  		status = -ENOMEM;
 -		goto setup_fail;
 +		goto fail;
  	}
  
 -	for (i = 0; i < opts->in_ports; i++)
 -		midi->in_ports_array[i].cable = i;
 +	for (i = 0; i < in_ports; i++) {
 +		struct gmidi_in_port *port = kzalloc(sizeof(*port), GFP_KERNEL);
 +		if (!port) {
 +			status = -ENOMEM;
 +			goto setup_fail;
 +		}
  
 -	/* set up ALSA midi devices */
 -	midi->id = kstrdup(opts->id, GFP_KERNEL);
 -	if (opts->id && !midi->id) {
 -		status = -ENOMEM;
 -		goto setup_fail;
 +		port->midi = midi;
 +		port->active = 0;
 +		port->cable = i;
 +		midi->in_port[i] = port;
  	}
 -	midi->in_ports = opts->in_ports;
 -	midi->out_ports = opts->out_ports;
 -	midi->index = opts->index;
 -	midi->buflen = opts->buflen;
 -	midi->qlen = opts->qlen;
 -	midi->in_last_port = 0;
 -	midi->free_ref = 1;
 -
 -	status = kfifo_alloc(&midi->in_req_fifo, midi->qlen, GFP_KERNEL);
 -	if (status)
 +
 +	midi->gadget = c->cdev->gadget;
 +	tasklet_init(&midi->tasklet, f_midi_in_tasklet, (unsigned long) midi);
 +
 +	/* set up ALSA midi devices */
 +	midi->in_ports = in_ports;
 +	midi->out_ports = out_ports;
 +	status = f_midi_register_card(midi);
 +	if (status < 0)
  		goto setup_fail;
  
 -	spin_lock_init(&midi->transmit_lock);
 +	midi->func.name        = "gmidi function";
 +	midi->func.strings     = midi_strings;
 +	midi->func.bind        = f_midi_bind;
 +	midi->func.unbind      = f_midi_unbind;
 +	midi->func.set_alt     = f_midi_set_alt;
 +	midi->func.disable     = f_midi_disable;
  
 -	++opts->refcnt;
 -	mutex_unlock(&opts->lock);
 +	midi->id = kstrdup(id, GFP_KERNEL);
 +	midi->index = index;
 +	midi->buflen = buflen;
 +	midi->qlen = qlen;
  
 -	midi->func.name		= "gmidi function";
 -	midi->func.bind		= f_midi_bind;
 -	midi->func.unbind	= f_midi_unbind;
 -	midi->func.set_alt	= f_midi_set_alt;
 -	midi->func.disable	= f_midi_disable;
 -	midi->func.free_func	= f_midi_free;
 +	status = usb_add_function(c, &midi->func);
 +	if (status)
 +		goto setup_fail;
  
 -	return &midi->func;
 +	return 0;
  
  setup_fail:
 -	mutex_unlock(&opts->lock);
 +	for (--i; i >= 0; i--)
 +		kfree(midi->in_port[i]);
  	kfree(midi);
 -	return ERR_PTR(status);
 +fail:
 +	return status;
  }
  
 -DECLARE_USB_FUNCTION_INIT(midi, f_midi_alloc_inst, f_midi_alloc);
diff --cc drivers/zorro/zorro.c
index 858c9714b2f3,875e569bf123..000000000000
--- a/drivers/zorro/zorro.c
+++ b/drivers/zorro/zorro.c
@@@ -131,7 -136,8 +131,12 @@@ static int __init amiga_zorro_probe(str
  	int error;
  
  	/* Initialize the Zorro bus */
++<<<<<<< HEAD
 +	bus = kzalloc(sizeof(*bus), GFP_KERNEL);
++=======
+ 	bus = kzalloc(struct_size(bus, devices, zorro_num_autocon),
+ 		      GFP_KERNEL);
++>>>>>>> acafe7e30216 (treewide: Use struct_size() for kmalloc()-family)
  	if (!bus)
  		return -ENOMEM;
  
diff --cc net/netfilter/xt_recent.c
index 31c5e0046dd0,07085c22b19c..000000000000
--- a/net/netfilter/xt_recent.c
+++ b/net/netfilter/xt_recent.c
@@@ -176,8 -182,9 +176,14 @@@ recent_entry_init(struct recent_table *
  		e = list_entry(t->lru_list.next, struct recent_entry, lru_list);
  		recent_entry_remove(t, e);
  	}
++<<<<<<< HEAD
 +	e = kmalloc(sizeof(*e) + sizeof(e->stamps[0]) * ip_pkt_list_tot,
 +		    GFP_ATOMIC);
++=======
+ 
+ 	nstamps_max += 1;
+ 	e = kmalloc(struct_size(e, stamps, nstamps_max), GFP_ATOMIC);
++>>>>>>> acafe7e30216 (treewide: Use struct_size() for kmalloc()-family)
  	if (e == NULL)
  		return NULL;
  	memcpy(&e->addr, addr, sizeof(e->addr));
diff --cc net/sctp/endpointola.c
index 5f91e7953566,40c7eb941bc9..000000000000
--- a/net/sctp/endpointola.c
+++ b/net/sctp/endpointola.c
@@@ -81,8 -73,8 +81,13 @@@ static struct sctp_endpoint *sctp_endpo
  		 * variables.  There are arrays that we encode directly
  		 * into parameters to make the rest of the operations easier.
  		 */
++<<<<<<< HEAD
 +		auth_hmacs = kzalloc(sizeof(sctp_hmac_algo_param_t) +
 +				sizeof(__u16) * SCTP_AUTH_NUM_HMACS, gfp);
++=======
+ 		auth_hmacs = kzalloc(struct_size(auth_hmacs, hmac_ids,
+ 						 SCTP_AUTH_NUM_HMACS), gfp);
++>>>>>>> acafe7e30216 (treewide: Use struct_size() for kmalloc()-family)
  		if (!auth_hmacs)
  			goto nomem;
  
* Unmerged path drivers/clk/bcm/clk-iproc-asiu.c
* Unmerged path drivers/clk/bcm/clk-iproc-pll.c
* Unmerged path drivers/clk/berlin/bg2.c
* Unmerged path drivers/clk/berlin/bg2q.c
* Unmerged path drivers/clk/clk-asm9260.c
* Unmerged path drivers/clk/clk-aspeed.c
* Unmerged path drivers/clk/clk-clps711x.c
* Unmerged path drivers/clk/clk-efm32gg.c
* Unmerged path drivers/clk/clk-gemini.c
* Unmerged path drivers/clk/clk-stm32h7.c
* Unmerged path drivers/clk/clk-stm32mp1.c
* Unmerged path drivers/clk/samsung/clk-exynos-clkout.c
* Unmerged path drivers/dma/moxart-dma.c
* Unmerged path drivers/dma/sh/usb-dmac.c
* Unmerged path drivers/misc/vexpress-syscfg.c
* Unmerged path drivers/net/wireless/mediatek/mt76/agg-rx.c
* Unmerged path drivers/staging/greybus/module.c
* Unmerged path fs/afs/addr_list.c
* Unmerged path kernel/cgroup/cgroup.c
* Unmerged path drivers/clk/bcm/clk-iproc-asiu.c
* Unmerged path drivers/clk/bcm/clk-iproc-pll.c
* Unmerged path drivers/clk/berlin/bg2.c
* Unmerged path drivers/clk/berlin/bg2q.c
* Unmerged path drivers/clk/clk-asm9260.c
* Unmerged path drivers/clk/clk-aspeed.c
* Unmerged path drivers/clk/clk-clps711x.c
* Unmerged path drivers/clk/clk-efm32gg.c
* Unmerged path drivers/clk/clk-gemini.c
* Unmerged path drivers/clk/clk-stm32h7.c
* Unmerged path drivers/clk/clk-stm32mp1.c
* Unmerged path drivers/clk/samsung/clk-exynos-clkout.c
diff --git a/drivers/dax/device.c b/drivers/dax/device.c
index ff8a72922dfb..5499b8eb697f 100644
--- a/drivers/dax/device.c
+++ b/drivers/dax/device.c
@@ -613,7 +613,7 @@ struct dev_dax *devm_create_dev_dax(struct dax_region *dax_region,
 	if (!count)
 		return ERR_PTR(-EINVAL);
 
-	dev_dax = kzalloc(sizeof(*dev_dax) + sizeof(*res) * count, GFP_KERNEL);
+	dev_dax = kzalloc(struct_size(dev_dax, res, count), GFP_KERNEL);
 	if (!dev_dax)
 		return ERR_PTR(-ENOMEM);
 
* Unmerged path drivers/dma/edma.c
* Unmerged path drivers/dma/moxart-dma.c
diff --git a/drivers/dma/omap-dma.c b/drivers/dma/omap-dma.c
index ec3fc4fd9160..cafd65d47970 100644
--- a/drivers/dma/omap-dma.c
+++ b/drivers/dma/omap-dma.c
@@ -343,7 +343,7 @@ static struct dma_async_tx_descriptor *omap_dma_prep_slave_sg(
 	}
 
 	/* Now allocate and setup the descriptor. */
-	d = kzalloc(sizeof(*d) + sglen * sizeof(d->sg[0]), GFP_ATOMIC);
+	d = kzalloc(struct_size(d, sg, sglen), GFP_ATOMIC);
 	if (!d)
 		return NULL;
 
diff --git a/drivers/dma/sa11x0-dma.c b/drivers/dma/sa11x0-dma.c
index 461a91ab70bb..df7f8a951cc7 100644
--- a/drivers/dma/sa11x0-dma.c
+++ b/drivers/dma/sa11x0-dma.c
@@ -564,7 +564,7 @@ static struct dma_async_tx_descriptor *sa11x0_dma_prep_slave_sg(
 		}
 	}
 
-	txd = kzalloc(sizeof(*txd) + j * sizeof(txd->sg[0]), GFP_ATOMIC);
+	txd = kzalloc(struct_size(txd, sg, j), GFP_ATOMIC);
 	if (!txd) {
 		dev_dbg(chan->device->dev, "vchan %p: kzalloc failed\n", &c->vc);
 		return NULL;
@@ -634,7 +634,7 @@ static struct dma_async_tx_descriptor *sa11x0_dma_prep_dma_cyclic(
 	if (sglen == 0)
 		return NULL;
 
-	txd = kzalloc(sizeof(*txd) + sglen * sizeof(txd->sg[0]), GFP_ATOMIC);
+	txd = kzalloc(struct_size(txd, sg, sglen), GFP_ATOMIC);
 	if (!txd) {
 		dev_dbg(chan->device->dev, "vchan %p: kzalloc failed\n", &c->vc);
 		return NULL;
* Unmerged path drivers/dma/sh/usb-dmac.c
diff --git a/drivers/firewire/core-topology.c b/drivers/firewire/core-topology.c
index 0de83508f321..0c60d3886309 100644
--- a/drivers/firewire/core-topology.c
+++ b/drivers/firewire/core-topology.c
@@ -112,8 +112,7 @@ static struct fw_node *fw_node_create(u32 sid, int port_count, int color)
 {
 	struct fw_node *node;
 
-	node = kzalloc(sizeof(*node) + port_count * sizeof(node->ports[0]),
-		       GFP_ATOMIC);
+	node = kzalloc(struct_size(node, ports, port_count), GFP_ATOMIC);
 	if (node == NULL)
 		return NULL;
 
* Unmerged path drivers/gpio/gpiolib.c
diff --git a/drivers/gpu/drm/nouveau/nvkm/engine/pm/base.c b/drivers/gpu/drm/nouveau/nvkm/engine/pm/base.c
index 53859b6254d6..b2785bee418e 100644
--- a/drivers/gpu/drm/nouveau/nvkm/engine/pm/base.c
+++ b/drivers/gpu/drm/nouveau/nvkm/engine/pm/base.c
@@ -779,8 +779,8 @@ nvkm_perfdom_new(struct nvkm_pm *pm, const char *name, u32 mask,
 
 		sdom = spec;
 		while (sdom->signal_nr) {
-			dom = kzalloc(sizeof(*dom) + sdom->signal_nr *
-				      sizeof(*dom->signal), GFP_KERNEL);
+			dom = kzalloc(struct_size(dom, signal, sdom->signal_nr),
+				      GFP_KERNEL);
 			if (!dom)
 				return -ENOMEM;
 
diff --git a/drivers/hwspinlock/omap_hwspinlock.c b/drivers/hwspinlock/omap_hwspinlock.c
index 292869cc9034..00eb5ab57de4 100644
--- a/drivers/hwspinlock/omap_hwspinlock.c
+++ b/drivers/hwspinlock/omap_hwspinlock.c
@@ -110,7 +110,7 @@ static int omap_hwspinlock_probe(struct platform_device *pdev)
 
 	num_locks = i * 32; /* actual number of locks in this device */
 
-	bank = kzalloc(sizeof(*bank) + num_locks * sizeof(*hwlock), GFP_KERNEL);
+	bank = kzalloc(struct_size(bank, lock, num_locks), GFP_KERNEL);
 	if (!bank) {
 		ret = -ENOMEM;
 		goto iounmap_base;
diff --git a/drivers/hwspinlock/u8500_hsem.c b/drivers/hwspinlock/u8500_hsem.c
index 401c33bcdb45..444bfc235b9b 100644
--- a/drivers/hwspinlock/u8500_hsem.c
+++ b/drivers/hwspinlock/u8500_hsem.c
@@ -119,7 +119,7 @@ static int u8500_hsem_probe(struct platform_device *pdev)
 	/* clear all interrupts */
 	writel(0xFFFF, io_base + HSEM_ICRALL);
 
-	bank = kzalloc(sizeof(*bank) + num_locks * sizeof(*hwlock), GFP_KERNEL);
+	bank = kzalloc(struct_size(bank, lock, num_locks), GFP_KERNEL);
 	if (!bank) {
 		ret = -ENOMEM;
 		goto iounmap_base;
* Unmerged path drivers/infiniband/core/cache.c
diff --git a/drivers/infiniband/core/cm.c b/drivers/infiniband/core/cm.c
index e2b10b1f78bd..b5903b7da263 100644
--- a/drivers/infiniband/core/cm.c
+++ b/drivers/infiniband/core/cm.c
@@ -4358,8 +4358,8 @@ static void cm_add_one(struct ib_device *ib_device)
 	int count = 0;
 	u8 i;
 
-	cm_dev = kzalloc(sizeof(*cm_dev) + sizeof(*port) *
-			 ib_device->phys_port_cnt, GFP_KERNEL);
+	cm_dev = kzalloc(struct_size(cm_dev, port, ib_device->phys_port_cnt),
+			 GFP_KERNEL);
 	if (!cm_dev)
 		return;
 
diff --git a/drivers/infiniband/core/multicast.c b/drivers/infiniband/core/multicast.c
index d71c63107151..d50ff70bb24b 100644
--- a/drivers/infiniband/core/multicast.c
+++ b/drivers/infiniband/core/multicast.c
@@ -823,7 +823,7 @@ static void mcast_add_one(struct ib_device *device)
 	int i;
 	int count = 0;
 
-	dev = kmalloc(sizeof *dev + device->phys_port_cnt * sizeof *port,
+	dev = kmalloc(struct_size(dev, port, device->phys_port_cnt),
 		      GFP_KERNEL);
 	if (!dev)
 		return;
* Unmerged path drivers/infiniband/core/uverbs_cmd.c
diff --git a/drivers/infiniband/core/uverbs_ioctl_merge.c b/drivers/infiniband/core/uverbs_ioctl_merge.c
index 0f88a1919d51..6ceb672c4d46 100644
--- a/drivers/infiniband/core/uverbs_ioctl_merge.c
+++ b/drivers/infiniband/core/uverbs_ioctl_merge.c
@@ -297,8 +297,7 @@ static struct uverbs_method_spec *build_method_with_attrs(const struct uverbs_me
 	if (max_attr_buckets >= 0)
 		num_attr_buckets = max_attr_buckets + 1;
 
-	method = kzalloc(sizeof(*method) +
-			 num_attr_buckets * sizeof(*method->attr_buckets),
+	method = kzalloc(struct_size(method, attr_buckets, num_attr_buckets),
 			 GFP_KERNEL);
 	if (!method)
 		return ERR_PTR(-ENOMEM);
@@ -446,9 +445,9 @@ static struct uverbs_object_spec *build_object_with_methods(const struct uverbs_
 	if (max_method_buckets >= 0)
 		num_method_buckets = max_method_buckets + 1;
 
-	object = kzalloc(sizeof(*object) +
-			 num_method_buckets *
-			 sizeof(*object->method_buckets), GFP_KERNEL);
+	object = kzalloc(struct_size(object, method_buckets,
+				     num_method_buckets),
+			 GFP_KERNEL);
 	if (!object)
 		return ERR_PTR(-ENOMEM);
 
@@ -469,8 +468,8 @@ static struct uverbs_object_spec *build_object_with_methods(const struct uverbs_
 		if (methods_max_bucket < 0)
 			continue;
 
-		hash = kzalloc(sizeof(*hash) +
-			       sizeof(*hash->methods) * (methods_max_bucket + 1),
+		hash = kzalloc(struct_size(hash, methods,
+					   methods_max_bucket + 1),
 			       GFP_KERNEL);
 		if (!hash) {
 			res = -ENOMEM;
@@ -579,8 +578,8 @@ struct uverbs_root_spec *uverbs_alloc_spec_tree(unsigned int num_trees,
 	if (max_object_buckets >= 0)
 		num_objects_buckets = max_object_buckets + 1;
 
-	root_spec = kzalloc(sizeof(*root_spec) +
-			    num_objects_buckets * sizeof(*root_spec->object_buckets),
+	root_spec = kzalloc(struct_size(root_spec, object_buckets,
+					num_objects_buckets),
 			    GFP_KERNEL);
 	if (!root_spec)
 		return ERR_PTR(-ENOMEM);
@@ -603,8 +602,8 @@ struct uverbs_root_spec *uverbs_alloc_spec_tree(unsigned int num_trees,
 		if (objects_max_bucket < 0)
 			continue;
 
-		hash = kzalloc(sizeof(*hash) +
-			       sizeof(*hash->objects) * (objects_max_bucket + 1),
+		hash = kzalloc(struct_size(hash, objects,
+					   objects_max_bucket + 1),
 			       GFP_KERNEL);
 		if (!hash) {
 			res = -ENOMEM;
diff --git a/drivers/infiniband/hw/mthca/mthca_memfree.c b/drivers/infiniband/hw/mthca/mthca_memfree.c
index 2fe503e86c1d..7a31be3c3e73 100644
--- a/drivers/infiniband/hw/mthca/mthca_memfree.c
+++ b/drivers/infiniband/hw/mthca/mthca_memfree.c
@@ -367,7 +367,7 @@ struct mthca_icm_table *mthca_alloc_icm_table(struct mthca_dev *dev,
 	obj_per_chunk = MTHCA_TABLE_CHUNK_SIZE / obj_size;
 	num_icm = DIV_ROUND_UP(nobj, obj_per_chunk);
 
-	table = kmalloc(sizeof *table + num_icm * sizeof *table->icm, GFP_KERNEL);
+	table = kmalloc(struct_size(table, icm, num_icm), GFP_KERNEL);
 	if (!table)
 		return NULL;
 
@@ -529,7 +529,7 @@ struct mthca_user_db_table *mthca_init_user_db_tab(struct mthca_dev *dev)
 		return NULL;
 
 	npages = dev->uar_table.uarc_size / MTHCA_ICM_PAGE_SIZE;
-	db_tab = kmalloc(sizeof *db_tab + npages * sizeof *db_tab->page, GFP_KERNEL);
+	db_tab = kmalloc(struct_size(db_tab, page, npages), GFP_KERNEL);
 	if (!db_tab)
 		return ERR_PTR(-ENOMEM);
 
diff --git a/drivers/infiniband/sw/rdmavt/mr.c b/drivers/infiniband/sw/rdmavt/mr.c
index cc429b567d0a..49c9541050d4 100644
--- a/drivers/infiniband/sw/rdmavt/mr.c
+++ b/drivers/infiniband/sw/rdmavt/mr.c
@@ -283,7 +283,7 @@ static struct rvt_mr *__rvt_alloc_mr(int count, struct ib_pd *pd)
 
 	/* Allocate struct plus pointers to first level page tables. */
 	m = (count + RVT_SEGSZ - 1) / RVT_SEGSZ;
-	mr = kzalloc(sizeof(*mr) + m * sizeof(mr->mr.map[0]), GFP_KERNEL);
+	mr = kzalloc(struct_size(mr, mr.map, m), GFP_KERNEL);
 	if (!mr)
 		goto bail;
 
@@ -730,7 +730,7 @@ struct ib_fmr *rvt_alloc_fmr(struct ib_pd *pd, int mr_access_flags,
 
 	/* Allocate struct plus pointers to first level page tables. */
 	m = (fmr_attr->max_pages + RVT_SEGSZ - 1) / RVT_SEGSZ;
-	fmr = kzalloc(sizeof(*fmr) + m * sizeof(fmr->mr.map[0]), GFP_KERNEL);
+	fmr = kzalloc(struct_size(fmr, mr.map, m), GFP_KERNEL);
 	if (!fmr)
 		goto bail;
 
diff --git a/drivers/input/input-leds.c b/drivers/input/input-leds.c
index 5f04b2d94635..99cc784e1264 100644
--- a/drivers/input/input-leds.c
+++ b/drivers/input/input-leds.c
@@ -98,8 +98,7 @@ static int input_leds_connect(struct input_handler *handler,
 	if (!num_leds)
 		return -ENXIO;
 
-	leds = kzalloc(sizeof(*leds) + num_leds * sizeof(*leds->leds),
-		       GFP_KERNEL);
+	leds = kzalloc(struct_size(leds, leds, num_leds), GFP_KERNEL);
 	if (!leds)
 		return -ENOMEM;
 
diff --git a/drivers/input/input-mt.c b/drivers/input/input-mt.c
index 72e807e2f18e..aa9fcdb24526 100644
--- a/drivers/input/input-mt.c
+++ b/drivers/input/input-mt.c
@@ -49,7 +49,7 @@ int input_mt_init_slots(struct input_dev *dev, unsigned int num_slots,
 	if (mt)
 		return mt->num_slots != num_slots ? -EINVAL : 0;
 
-	mt = kzalloc(sizeof(*mt) + num_slots * sizeof(*mt->slots), GFP_KERNEL);
+	mt = kzalloc(struct_size(mt, slots, num_slots), GFP_KERNEL);
 	if (!mt)
 		goto err_mem;
 
diff --git a/drivers/md/dm-raid.c b/drivers/md/dm-raid.c
index 731aa5b78b5a..09458790db7d 100644
--- a/drivers/md/dm-raid.c
+++ b/drivers/md/dm-raid.c
@@ -739,7 +739,7 @@ static struct raid_set *raid_set_alloc(struct dm_target *ti, struct raid_type *r
 		return ERR_PTR(-EINVAL);
 	}
 
-	rs = kzalloc(sizeof(*rs) + raid_devs * sizeof(rs->dev[0]), GFP_KERNEL);
+	rs = kzalloc(struct_size(rs, dev, raid_devs), GFP_KERNEL);
 	if (!rs) {
 		ti->error = "Cannot allocate raid context";
 		return ERR_PTR(-ENOMEM);
* Unmerged path drivers/misc/vexpress-syscfg.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/debugfs.c b/drivers/net/ethernet/mellanox/mlx5/core/debugfs.c
index 7ecadb501743..413080a312a7 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/debugfs.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/debugfs.c
@@ -494,7 +494,7 @@ static int add_res_tree(struct mlx5_core_dev *dev, enum dbg_rsc_type type,
 	int err;
 	int i;
 
-	d = kzalloc(sizeof(*d) + nfile * sizeof(d->fields[0]), GFP_KERNEL);
+	d = kzalloc(struct_size(d, fields, nfile), GFP_KERNEL);
 	if (!d)
 		return -ENOMEM;
 
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
index 6fe2d966a371..6d972d8b7130 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
@@ -1128,8 +1128,7 @@ static struct mlx5_flow_handle *alloc_handle(int num_rules)
 {
 	struct mlx5_flow_handle *handle;
 
-	handle = kzalloc(sizeof(*handle) + sizeof(handle->rule[0]) *
-			  num_rules, GFP_KERNEL);
+	handle = kzalloc(struct_size(handle, rule, num_rules), GFP_KERNEL);
 	if (!handle)
 		return NULL;
 
diff --git a/drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c b/drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c
index 15405f675b5c..791fec5b40d0 100644
--- a/drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c
+++ b/drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c
@@ -2970,9 +2970,8 @@ static int iwl_mvm_mac_set_key(struct ieee80211_hw *hw,
 
 			mvmsta = iwl_mvm_sta_from_mac80211(sta);
 			WARN_ON(rcu_access_pointer(mvmsta->ptk_pn[keyidx]));
-			ptk_pn = kzalloc(sizeof(*ptk_pn) +
-					 mvm->trans->num_rx_queues *
-						sizeof(ptk_pn->q[0]),
+			ptk_pn = kzalloc(struct_size(ptk_pn, q,
+						     mvm->trans->num_rx_queues),
 					 GFP_KERNEL);
 			if (!ptk_pn) {
 				ret = -ENOMEM;
* Unmerged path drivers/net/wireless/mediatek/mt76/agg-rx.c
* Unmerged path drivers/reset/core.c
* Unmerged path drivers/s390/cio/ccwgroup.c
* Unmerged path drivers/staging/greybus/module.c
* Unmerged path drivers/usb/gadget/f_midi.c
* Unmerged path drivers/zorro/zorro.c
* Unmerged path fs/afs/addr_list.c
* Unmerged path kernel/cgroup/cgroup.c
diff --git a/kernel/module.c b/kernel/module.c
index 0d9ef67fd99a..6900dd64e3c3 100644
--- a/kernel/module.c
+++ b/kernel/module.c
@@ -1553,8 +1553,7 @@ static void add_notes_attrs(struct module *mod, const struct load_info *info)
 	if (notes == 0)
 		return;
 
-	notes_attrs = kzalloc(sizeof(*notes_attrs)
-			      + notes * sizeof(notes_attrs->attrs[0]),
+	notes_attrs = kzalloc(struct_size(notes_attrs, attrs, notes),
 			      GFP_KERNEL);
 	if (notes_attrs == NULL)
 		return;
diff --git a/kernel/workqueue.c b/kernel/workqueue.c
index ddaafa97bdb8..900a14eb9714 100644
--- a/kernel/workqueue.c
+++ b/kernel/workqueue.c
@@ -4104,8 +4104,7 @@ apply_wqattrs_prepare(struct workqueue_struct *wq,
 
 	lockdep_assert_held(&wq_pool_mutex);
 
-	ctx = kzalloc(sizeof(*ctx) + nr_node_ids * sizeof(ctx->pwq_tbl[0]),
-		      GFP_KERNEL);
+	ctx = kzalloc(struct_size(ctx, pwq_tbl, nr_node_ids), GFP_KERNEL);
 
 	new_attrs = alloc_workqueue_attrs(GFP_KERNEL);
 	tmp_attrs = alloc_workqueue_attrs(GFP_KERNEL);
diff --git a/net/ceph/mon_client.c b/net/ceph/mon_client.c
index 6c09879b59a3..81a27a8e670f 100644
--- a/net/ceph/mon_client.c
+++ b/net/ceph/mon_client.c
@@ -61,7 +61,7 @@ struct ceph_monmap *ceph_monmap_decode(void *p, void *end)
 
 	if (num_mon > CEPH_MAX_MON)
 		goto bad;
-	m = kmalloc(sizeof(*m) + sizeof(m->mon_inst[0])*num_mon, GFP_NOFS);
+	m = kmalloc(struct_size(m, mon_inst, num_mon), GFP_NOFS);
 	if (m == NULL)
 		return ERR_PTR(-ENOMEM);
 	m->fsid = fsid;
@@ -999,8 +999,7 @@ static int build_initial_monmap(struct ceph_mon_client *monc)
 	int i;
 
 	/* build initial monmap */
-	monc->monmap = kzalloc(sizeof(*monc->monmap) +
-			       num_mon*sizeof(monc->monmap->mon_inst[0]),
+	monc->monmap = kzalloc(struct_size(monc->monmap, mon_inst, num_mon),
 			       GFP_KERNEL);
 	if (!monc->monmap)
 		return -ENOMEM;
diff --git a/net/ceph/osd_client.c b/net/ceph/osd_client.c
index 8606c0afbcc0..95b1a884009a 100644
--- a/net/ceph/osd_client.c
+++ b/net/ceph/osd_client.c
@@ -523,8 +523,7 @@ struct ceph_osd_request *ceph_osdc_alloc_request(struct ceph_osd_client *osdc,
 		req = kmem_cache_alloc(ceph_osd_request_cache, gfp_flags);
 	} else {
 		BUG_ON(num_ops > CEPH_OSD_MAX_OPS);
-		req = kmalloc(sizeof(*req) + num_ops * sizeof(req->r_ops[0]),
-			      gfp_flags);
+		req = kmalloc(struct_size(req, r_ops, num_ops), gfp_flags);
 	}
 	if (unlikely(!req))
 		return NULL;
* Unmerged path net/netfilter/xt_recent.c
* Unmerged path net/sctp/endpointola.c
diff --git a/sound/core/vmaster.c b/sound/core/vmaster.c
index 58fa3f94722a..fd99d8abe2af 100644
--- a/sound/core/vmaster.c
+++ b/sound/core/vmaster.c
@@ -259,8 +259,8 @@ int _snd_ctl_add_slave(struct snd_kcontrol *master, struct snd_kcontrol *slave,
 	struct link_master *master_link = snd_kcontrol_chip(master);
 	struct link_slave *srec;
 
-	srec = kzalloc(sizeof(*srec) +
-		       slave->count * sizeof(*slave->vd), GFP_KERNEL);
+	srec = kzalloc(struct_size(srec, slave.vd, slave->count),
+		       GFP_KERNEL);
 	if (!srec)
 		return -ENOMEM;
 	srec->kctl = slave;
diff --git a/sound/soc/soc-dapm.c b/sound/soc/soc-dapm.c
index 84ab79ffba0b..13b3eaa0bd71 100644
--- a/sound/soc/soc-dapm.c
+++ b/sound/soc/soc-dapm.c
@@ -1088,7 +1088,7 @@ static int dapm_widget_list_create(struct snd_soc_dapm_widget_list **list,
 	list_for_each(it, widgets)
 		size++;
 
-	*list = kzalloc(sizeof(**list) + size * sizeof(*w), GFP_KERNEL);
+	*list = kzalloc(struct_size(*list, widgets, size), GFP_KERNEL);
 	if (*list == NULL)
 		return -ENOMEM;
 
