dm: disable DISCARD if the underlying storage no longer supports it

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Mike Snitzer <snitzer@redhat.com>
commit bcb44433bba5eaff293888ef22ffa07f1f0347d6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/bcb44433.failed

Storage devices which report supporting discard commands like
WRITE_SAME_16 with unmap, but reject discard commands sent to the
storage device.  This is a clear storage firmware bug but it doesn't
change the fact that should a program cause discards to be sent to a
multipath device layered on this buggy storage, all paths can end up
failed at the same time from the discards, causing possible I/O loss.

The first discard to a path will fail with Illegal Request, Invalid
field in cdb, e.g.:
 kernel: sd 8:0:8:19: [sdfn] tag#0 FAILED Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE
 kernel: sd 8:0:8:19: [sdfn] tag#0 Sense Key : Illegal Request [current]
 kernel: sd 8:0:8:19: [sdfn] tag#0 Add. Sense: Invalid field in cdb
 kernel: sd 8:0:8:19: [sdfn] tag#0 CDB: Write same(16) 93 08 00 00 00 00 00 a0 08 00 00 00 80 00 00 00
 kernel: blk_update_request: critical target error, dev sdfn, sector 10487808

The SCSI layer converts this to the BLK_STS_TARGET error number, the sd
device disables its support for discard on this path, and because of the
BLK_STS_TARGET error multipath fails the discard without failing any
path or retrying down a different path.  But subsequent discards can
cause path failures.  Any discards sent to the path which already failed
a discard ends up failing with EIO from blk_cloned_rq_check_limits with
an "over max size limit" error since the discard limit was set to 0 by
the sd driver for the path.  As the error is EIO, this now fails the
path and multipath tries to send the discard down the next path.  This
cycle continues as discards are sent until all paths fail.

Fix this by training DM core to disable DISCARD if the underlying
storage already did so.

Also, fix branching in dm_done() and clone_endio() to reflect the
mutually exclussive nature of the IO operations in question.

	Cc: stable@vger.kernel.org
	Reported-by: David Jeffery <djeffery@redhat.com>
	Signed-off-by: Mike Snitzer <snitzer@redhat.com>
(cherry picked from commit bcb44433bba5eaff293888ef22ffa07f1f0347d6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/dm-core.h
#	drivers/md/dm-rq.c
#	drivers/md/dm.c
diff --cc drivers/md/dm-core.h
index d719498daa82,c4ef1fceead6..000000000000
--- a/drivers/md/dm-core.h
+++ b/drivers/md/dm-core.h
@@@ -131,10 -115,9 +131,14 @@@ struct mapped_device 
  	struct srcu_struct io_barrier;
  };
  
++<<<<<<< HEAD
 +void dm_init_md_queue(struct mapped_device *md);
 +void dm_init_normal_md_queue(struct mapped_device *md);
 +int md_in_flight(struct mapped_device *md);
++=======
+ void disable_discard(struct mapped_device *md);
++>>>>>>> bcb44433bba5 (dm: disable DISCARD if the underlying storage no longer supports it)
  void disable_write_same(struct mapped_device *md);
 -void disable_write_zeroes(struct mapped_device *md);
  
  static inline struct completion *dm_get_completion_from_kobject(struct kobject *kobj)
  {
diff --cc drivers/md/dm-rq.c
index 02da1e65782f,b66745bd08bb..000000000000
--- a/drivers/md/dm-rq.c
+++ b/drivers/md/dm-rq.c
@@@ -364,20 -221,35 +364,34 @@@ static void dm_done(struct request *clo
  			r = rq_end_io(tio->ti, clone, error, &tio->info);
  	}
  
++<<<<<<< HEAD
 +	if (unlikely(r == -EREMOTEIO && (clone->cmd_flags & REQ_WRITE_SAME) &&
 +		     !clone->q->limits.max_write_same_sectors))
 +		disable_write_same(tio->md);
++=======
+ 	if (unlikely(error == BLK_STS_TARGET)) {
+ 		if (req_op(clone) == REQ_OP_DISCARD &&
+ 		    !clone->q->limits.max_discard_sectors)
+ 			disable_discard(tio->md);
+ 		else if (req_op(clone) == REQ_OP_WRITE_SAME &&
+ 			 !clone->q->limits.max_write_same_sectors)
+ 			disable_write_same(tio->md);
+ 		else if (req_op(clone) == REQ_OP_WRITE_ZEROES &&
+ 			 !clone->q->limits.max_write_zeroes_sectors)
+ 			disable_write_zeroes(tio->md);
+ 	}
++>>>>>>> bcb44433bba5 (dm: disable DISCARD if the underlying storage no longer supports it)
  
 -	switch (r) {
 -	case DM_ENDIO_DONE:
 +	if (r <= 0)
  		/* The target wants to complete the I/O */
 -		dm_end_request(clone, error);
 -		break;
 -	case DM_ENDIO_INCOMPLETE:
 +		dm_end_request(clone, r);
 +	else if (r == DM_ENDIO_INCOMPLETE)
  		/* The target will handle the I/O */
  		return;
 -	case DM_ENDIO_REQUEUE:
 +	else if (r == DM_ENDIO_REQUEUE)
  		/* The target wants to requeue the I/O */
  		dm_requeue_original_request(tio, false);
 -		break;
 -	case DM_ENDIO_DELAY_REQUEUE:
 -		/* The target wants to requeue the I/O after a delay */
 -		dm_requeue_original_request(tio, true);
 -		break;
 -	default:
 +	else {
  		DMWARN("unimplemented target endio return value: %d", r);
  		BUG();
  	}
diff --cc drivers/md/dm.c
index 7dba2e7128fb,043f0761e4a0..000000000000
--- a/drivers/md/dm.c
+++ b/drivers/md/dm.c
@@@ -833,21 -978,30 +842,35 @@@ static void clone_endio(struct bio *bio
  	struct mapped_device *md = tio->io->md;
  	dm_endio_fn endio = tio->ti->type->end_io;
  
++<<<<<<< HEAD
 +	if (!bio_flagged(bio, BIO_UPTODATE) && !error)
 +		error = -EIO;
++=======
+ 	if (unlikely(error == BLK_STS_TARGET) && md->type != DM_TYPE_NVME_BIO_BASED) {
+ 		if (bio_op(bio) == REQ_OP_DISCARD &&
+ 		    !bio->bi_disk->queue->limits.max_discard_sectors)
+ 			disable_discard(md);
+ 		else if (bio_op(bio) == REQ_OP_WRITE_SAME &&
+ 			 !bio->bi_disk->queue->limits.max_write_same_sectors)
+ 			disable_write_same(md);
+ 		else if (bio_op(bio) == REQ_OP_WRITE_ZEROES &&
+ 			 !bio->bi_disk->queue->limits.max_write_zeroes_sectors)
+ 			disable_write_zeroes(md);
+ 	}
++>>>>>>> bcb44433bba5 (dm: disable DISCARD if the underlying storage no longer supports it)
  
  	if (endio) {
 -		int r = endio(tio->ti, bio, &error);
 -		switch (r) {
 -		case DM_ENDIO_REQUEUE:
 -			error = BLK_STS_DM_REQUEUE;
 -			/*FALLTHRU*/
 -		case DM_ENDIO_DONE:
 -			break;
 -		case DM_ENDIO_INCOMPLETE:
 +		r = endio(tio->ti, bio, error);
 +		if (r < 0 || r == DM_ENDIO_REQUEUE)
 +			/*
 +			 * error and requeue request are handled
 +			 * in dec_pending().
 +			 */
 +			error = r;
 +		else if (r == DM_ENDIO_INCOMPLETE)
  			/* The target will handle the io */
  			return;
 -		default:
 +		else if (r) {
  			DMWARN("unimplemented target endio return value: %d", r);
  			BUG();
  		}
* Unmerged path drivers/md/dm-core.h
* Unmerged path drivers/md/dm-rq.c
* Unmerged path drivers/md/dm.c
