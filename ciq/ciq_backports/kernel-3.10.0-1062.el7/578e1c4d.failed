kvm: x86: Avoid taking MMU lock in kvm_mmu_sync_roots if no sync is needed

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Junaid Shahid <junaids@google.com>
commit 578e1c4db22135d91bad6c79585c4d19252b8d81
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/578e1c4d.failed

kvm_mmu_sync_roots() can locklessly check whether a sync is needed and just
bail out if it isn't.

	Signed-off-by: Junaid Shahid <junaids@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 578e1c4db22135d91bad6c79585c4d19252b8d81)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu.c
diff --cc arch/x86/kvm/mmu.c
index db86a346eaea,4b4452d0022e..000000000000
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@@ -3540,14 -3605,39 +3579,44 @@@ void kvm_mmu_sync_roots(struct kvm_vcp
  		return;
  
  	vcpu_clear_mmio_info(vcpu, MMIO_GVA_ANY);
++<<<<<<< HEAD
 +	kvm_mmu_audit(vcpu, AUDIT_PRE_SYNC);
 +	if (vcpu->arch.mmu.root_level == PT64_ROOT_LEVEL) {
++=======
+ 
+ 	if (vcpu->arch.mmu.root_level >= PT64_ROOT_4LEVEL) {
++>>>>>>> 578e1c4db221 (kvm: x86: Avoid taking MMU lock in kvm_mmu_sync_roots if no sync is needed)
  		hpa_t root = vcpu->arch.mmu.root_hpa;
+ 
  		sp = page_header(root);
+ 
+ 		/*
+ 		 * Even if another CPU was marking the SP as unsync-ed
+ 		 * simultaneously, any guest page table changes are not
+ 		 * guaranteed to be visible anyway until this VCPU issues a TLB
+ 		 * flush strictly after those changes are made. We only need to
+ 		 * ensure that the other CPU sets these flags before any actual
+ 		 * changes to the page tables are made. The comments in
+ 		 * mmu_need_write_protect() describe what could go wrong if this
+ 		 * requirement isn't satisfied.
+ 		 */
+ 		if (!smp_load_acquire(&sp->unsync) &&
+ 		    !smp_load_acquire(&sp->unsync_children))
+ 			return;
+ 
+ 		spin_lock(&vcpu->kvm->mmu_lock);
+ 		kvm_mmu_audit(vcpu, AUDIT_PRE_SYNC);
+ 
  		mmu_sync_children(vcpu, sp);
+ 
  		kvm_mmu_audit(vcpu, AUDIT_POST_SYNC);
+ 		spin_unlock(&vcpu->kvm->mmu_lock);
  		return;
  	}
+ 
+ 	spin_lock(&vcpu->kvm->mmu_lock);
+ 	kvm_mmu_audit(vcpu, AUDIT_PRE_SYNC);
+ 
  	for (i = 0; i < 4; ++i) {
  		hpa_t root = vcpu->arch.mmu.pae_root[i];
  
* Unmerged path arch/x86/kvm/mmu.c
