vhost_net: introduce vhost_exceeds_weight()

jira LE-1907
cve CVE-2019-3900
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Jason Wang <jasowang@redhat.com>
commit 272f35cba53d088085e5952fd81d7a133ab90789
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/272f35cb.failed

	Signed-off-by: Jason Wang <jasowang@redhat.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 272f35cba53d088085e5952fd81d7a133ab90789)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/vhost/net.c
diff --cc drivers/vhost/net.c
index 90b124ca16a4,b9e1674ca9e1..000000000000
--- a/drivers/vhost/net.c
+++ b/drivers/vhost/net.c
@@@ -377,10 -462,28 +377,16 @@@ static bool vhost_exceeds_maxpend(struc
  	struct vhost_net_virtqueue *nvq = &net->vqs[VHOST_NET_VQ_TX];
  	struct vhost_virtqueue *vq = &nvq->vq;
  
 -	return (nvq->upend_idx + UIO_MAXIOV - nvq->done_idx) % UIO_MAXIOV >
 -	       min_t(unsigned int, VHOST_MAX_PEND, vq->num >> 2);
 -}
 -
 -static size_t init_iov_iter(struct vhost_virtqueue *vq, struct iov_iter *iter,
 -			    size_t hdr_size, int out)
 -{
 -	/* Skip header. TODO: support TSO. */
 -	size_t len = iov_length(vq->iov, out);
 -
 -	iov_iter_init(iter, WRITE, vq->iov, out, len);
 -	iov_iter_advance(iter, hdr_size);
 -
 -	return iov_iter_count(iter);
 +	return (nvq->upend_idx + vq->num - VHOST_MAX_PEND) % UIO_MAXIOV
 +		== nvq->done_idx;
  }
  
+ static bool vhost_exceeds_weight(int pkts, int total_len)
+ {
+ 	return total_len >= VHOST_NET_WEIGHT ||
+ 	       pkts >= VHOST_NET_PKT_WEIGHT;
+ }
+ 
  /* Expects to be always run from workqueue - which acts as
   * read-size critical section for our kind of RCU. */
  static void handle_tx(struct vhost_net *net)
@@@ -464,33 -564,24 +470,38 @@@
  
  		/* use msg_control to pass vhost zerocopy ubuf info to skb */
  		if (zcopy_used) {
 -			struct ubuf_info *ubuf;
 -			ubuf = nvq->ubuf_info + nvq->upend_idx;
 -
  			vq->heads[nvq->upend_idx].id = cpu_to_vhost32(vq, head);
 -			vq->heads[nvq->upend_idx].len = VHOST_DMA_IN_PROGRESS;
 -			ubuf->callback = vhost_zerocopy_callback;
 -			ubuf->ctx = nvq->ubufs;
 -			ubuf->desc = nvq->upend_idx;
 -			refcount_set(&ubuf->refcnt, 1);
 -			msg.msg_control = ubuf;
 -			msg.msg_controllen = sizeof(ubuf);
 -			ubufs = nvq->ubufs;
 -			atomic_inc(&ubufs->refcount);
 +			if (!vhost_net_tx_select_zcopy(net) ||
 +			    len < VHOST_GOODCOPY_LEN) {
 +				/* copy don't need to wait for DMA done */
 +				vq->heads[nvq->upend_idx].len =
 +							VHOST_DMA_DONE_LEN;
 +				msg.msg_control = NULL;
 +				msg.msg_controllen = 0;
 +				ubufs = NULL;
 +			} else {
 +				struct ubuf_info *ubuf;
 +				ubuf = nvq->ubuf_info + nvq->upend_idx;
 +
 +				vq->heads[nvq->upend_idx].len =
 +					VHOST_DMA_IN_PROGRESS;
 +				ubuf->callback = vhost_zerocopy_callback;
 +				ubuf->ctx = nvq->ubufs;
 +				ubuf->desc = nvq->upend_idx;
 +				msg.msg_control = ubuf;
 +				msg.msg_controllen = sizeof(ubuf);
 +				ubufs = nvq->ubufs;
 +				atomic_inc(&ubufs->refcount);
 +			}
  			nvq->upend_idx = (nvq->upend_idx + 1) % UIO_MAXIOV;
 -		} else {
 +		} else
  			msg.msg_control = NULL;
++<<<<<<< HEAD
 +
++=======
+ 			ubufs = NULL;
+ 		}
++>>>>>>> 272f35cba53d (vhost_net: introduce vhost_exceeds_weight())
  		total_len += len;
  		if (total_len < VHOST_NET_WEIGHT &&
  		    !vhost_vq_avail_empty(&net->dev, vq) &&
@@@ -520,8 -611,7 +531,12 @@@
  		else
  			vhost_zerocopy_signal_used(net, vq);
  		vhost_net_tx_packet(net);
++<<<<<<< HEAD
 +		if (unlikely(total_len >= VHOST_NET_WEIGHT) ||
 +		    unlikely(++sent_pkts >= VHOST_NET_PKT_WEIGHT(vq))) {
++=======
+ 		if (unlikely(vhost_exceeds_weight(++sent_pkts, total_len))) {
++>>>>>>> 272f35cba53d (vhost_net: introduce vhost_exceeds_weight())
  			vhost_poll_queue(&vq->poll);
  			break;
  		}
@@@ -807,11 -922,15 +822,15 @@@ static void handle_rx(struct vhost_net 
  		if (unlikely(vq_log))
  			vhost_log_write(vq, vq_log, log, vhost_len);
  		total_len += vhost_len;
++<<<<<<< HEAD
 +		if (unlikely(total_len >= VHOST_NET_WEIGHT)) {
++=======
+ 		if (unlikely(vhost_exceeds_weight(++recv_pkts, total_len))) {
++>>>>>>> 272f35cba53d (vhost_net: introduce vhost_exceeds_weight())
  			vhost_poll_queue(&vq->poll);
 -			goto out;
 +			break;
  		}
  	}
 -	if (unlikely(busyloop_intr))
 -		vhost_poll_queue(&vq->poll);
 -	else
 -		vhost_net_enable_vq(net, vq);
  out:
  	vhost_rx_signal_used(nvq);
  	mutex_unlock(&vq->mutex);
* Unmerged path drivers/vhost/net.c
