qed: Revise load sequence to avoid PCI errors

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Tomer Tayar <tomer.tayar@cavium.com>
commit cfdb1b63eefe918e5c8419c9a88188fef1b9cc5e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/cfdb1b63.failed

Initiating final cleanup after an ungraceful driver unload can lead to bad
PCI accesses towards the host.
This patch revises the load sequence so final cleanup is sent while the
internal master enable is cleared, to prevent the host accesses, and clears
the internal error indications just before enabling the internal master
enable.

	Signed-off-by: Tomer Tayar <tomer.tayar@cavium.com>
	Signed-off-by: Ariel Elior <ariel.elior@cavium.com>
	Signed-off-by: Michal Kalderon <michal.kalderon@cavium.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit cfdb1b63eefe918e5c8419c9a88188fef1b9cc5e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/qlogic/qed/qed_int.c
diff --cc drivers/net/ethernet/qlogic/qed/qed_int.c
index 7e27b333bb7b,e23980e301b6..000000000000
--- a/drivers/net/ethernet/qlogic/qed/qed_int.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_int.c
@@@ -294,37 -294,36 +294,40 @@@ int qed_pglueb_rbc_attn_handler(struct 
  	if (tmp & PGLUE_ATTENTION_RD_VALID) {
  		u32 addr_lo, addr_hi, details;
  
- 		addr_lo = qed_rd(p_hwfn, p_hwfn->p_dpc_ptt,
+ 		addr_lo = qed_rd(p_hwfn, p_ptt,
  				 PGLUE_B_REG_TX_ERR_RD_ADD_31_0);
- 		addr_hi = qed_rd(p_hwfn, p_hwfn->p_dpc_ptt,
+ 		addr_hi = qed_rd(p_hwfn, p_ptt,
  				 PGLUE_B_REG_TX_ERR_RD_ADD_63_32);
- 		details = qed_rd(p_hwfn, p_hwfn->p_dpc_ptt,
+ 		details = qed_rd(p_hwfn, p_ptt,
  				 PGLUE_B_REG_TX_ERR_RD_DETAILS);
  
- 		DP_INFO(p_hwfn,
- 			"Illegal read by chip from [%08x:%08x] blocked.\n"
- 			" Details: %08x [PFID %02x, VFID %02x, VF_VALID %02x]\n"
- 			" Details2 %08x [Was_error %02x BME deassert %02x FID_enable deassert %02x]\n",
- 			addr_hi, addr_lo, details,
- 			(u8)GET_FIELD(details, PGLUE_ATTENTION_DETAILS_PFID),
- 			(u8)GET_FIELD(details, PGLUE_ATTENTION_DETAILS_VFID),
- 			GET_FIELD(details,
- 				  PGLUE_ATTENTION_DETAILS_VF_VALID) ? 1 : 0,
- 			tmp,
- 			GET_FIELD(tmp, PGLUE_ATTENTION_DETAILS2_WAS_ERR) ? 1
- 									 : 0,
- 			GET_FIELD(tmp, PGLUE_ATTENTION_DETAILS2_BME) ? 1 : 0,
- 			GET_FIELD(tmp, PGLUE_ATTENTION_DETAILS2_FID_EN) ? 1
- 									: 0);
+ 		DP_NOTICE(p_hwfn,
+ 			  "Illegal read by chip from [%08x:%08x] blocked.\n"
+ 			  "Details: %08x [PFID %02x, VFID %02x, VF_VALID %02x]\n"
+ 			  "Details2 %08x [Was_error %02x BME deassert %02x FID_enable deassert %02x]\n",
+ 			  addr_hi, addr_lo, details,
+ 			  (u8)GET_FIELD(details, PGLUE_ATTENTION_DETAILS_PFID),
+ 			  (u8)GET_FIELD(details, PGLUE_ATTENTION_DETAILS_VFID),
+ 			  GET_FIELD(details,
+ 				    PGLUE_ATTENTION_DETAILS_VF_VALID) ? 1 : 0,
+ 			  tmp,
+ 			  GET_FIELD(tmp,
+ 				    PGLUE_ATTENTION_DETAILS2_WAS_ERR) ? 1 : 0,
+ 			  GET_FIELD(tmp,
+ 				    PGLUE_ATTENTION_DETAILS2_BME) ? 1 : 0,
+ 			  GET_FIELD(tmp,
+ 				    PGLUE_ATTENTION_DETAILS2_FID_EN) ? 1 : 0);
  	}
  
- 	tmp = qed_rd(p_hwfn, p_hwfn->p_dpc_ptt,
- 		     PGLUE_B_REG_TX_ERR_WR_DETAILS_ICPL);
+ 	tmp = qed_rd(p_hwfn, p_ptt, PGLUE_B_REG_TX_ERR_WR_DETAILS_ICPL);
  	if (tmp & PGLUE_ATTENTION_ICPL_VALID)
++<<<<<<< HEAD
 +		DP_INFO(p_hwfn, "ICPL eror - %08x\n", tmp);
++=======
+ 		DP_NOTICE(p_hwfn, "ICPL error - %08x\n", tmp);
++>>>>>>> cfdb1b63eefe (qed: Revise load sequence to avoid PCI errors)
  
- 	tmp = qed_rd(p_hwfn, p_hwfn->p_dpc_ptt,
- 		     PGLUE_B_REG_MASTER_ZLR_ERR_DETAILS);
+ 	tmp = qed_rd(p_hwfn, p_ptt, PGLUE_B_REG_MASTER_ZLR_ERR_DETAILS);
  	if (tmp & PGLUE_ATTENTION_ZLR_VALID) {
  		u32 addr_hi, addr_lo;
  
@@@ -361,29 -358,152 +362,108 @@@
  	return 0;
  }
  
++<<<<<<< HEAD
 +#define QED_DORQ_ATTENTION_REASON_MASK	(0xfffff)
 +#define QED_DORQ_ATTENTION_OPAQUE_MASK (0xffff)
 +#define QED_DORQ_ATTENTION_SIZE_MASK	(0x7f)
 +#define QED_DORQ_ATTENTION_SIZE_SHIFT	(16)
++=======
+ static int qed_pglueb_rbc_attn_cb(struct qed_hwfn *p_hwfn)
+ {
+ 	return qed_pglueb_rbc_attn_handler(p_hwfn, p_hwfn->p_dpc_ptt);
+ }
+ 
+ #define QED_DORQ_ATTENTION_REASON_MASK  (0xfffff)
+ #define QED_DORQ_ATTENTION_OPAQUE_MASK  (0xffff)
+ #define QED_DORQ_ATTENTION_OPAQUE_SHIFT (0x0)
+ #define QED_DORQ_ATTENTION_SIZE_MASK            (0x7f)
+ #define QED_DORQ_ATTENTION_SIZE_SHIFT           (16)
+ 
+ #define QED_DB_REC_COUNT                        1000
+ #define QED_DB_REC_INTERVAL                     100
+ 
+ static int qed_db_rec_flush_queue(struct qed_hwfn *p_hwfn,
+ 				  struct qed_ptt *p_ptt)
+ {
+ 	u32 count = QED_DB_REC_COUNT;
+ 	u32 usage = 1;
+ 
+ 	/* wait for usage to zero or count to run out. This is necessary since
+ 	 * EDPM doorbell transactions can take multiple 64b cycles, and as such
+ 	 * can "split" over the pci. Possibly, the doorbell drop can happen with
+ 	 * half an EDPM in the queue and other half dropped. Another EDPM
+ 	 * doorbell to the same address (from doorbell recovery mechanism or
+ 	 * from the doorbelling entity) could have first half dropped and second
+ 	 * half interpreted as continuation of the first. To prevent such
+ 	 * malformed doorbells from reaching the device, flush the queue before
+ 	 * releasing the overflow sticky indication.
+ 	 */
+ 	while (count-- && usage) {
+ 		usage = qed_rd(p_hwfn, p_ptt, DORQ_REG_PF_USAGE_CNT);
+ 		udelay(QED_DB_REC_INTERVAL);
+ 	}
+ 
+ 	/* should have been depleted by now */
+ 	if (usage) {
+ 		DP_NOTICE(p_hwfn->cdev,
+ 			  "DB recovery: doorbell usage failed to zero after %d usec. usage was %x\n",
+ 			  QED_DB_REC_INTERVAL * QED_DB_REC_COUNT, usage);
+ 		return -EBUSY;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ int qed_db_rec_handler(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)
+ {
+ 	u32 overflow;
+ 	int rc;
+ 
+ 	overflow = qed_rd(p_hwfn, p_ptt, DORQ_REG_PF_OVFL_STICKY);
+ 	DP_NOTICE(p_hwfn, "PF Overflow sticky 0x%x\n", overflow);
+ 	if (!overflow) {
+ 		qed_db_recovery_execute(p_hwfn, DB_REC_ONCE);
+ 		return 0;
+ 	}
+ 
+ 	if (qed_edpm_enabled(p_hwfn)) {
+ 		rc = qed_db_rec_flush_queue(p_hwfn, p_ptt);
+ 		if (rc)
+ 			return rc;
+ 	}
+ 
+ 	/* Flush any pending (e)dpm as they may never arrive */
+ 	qed_wr(p_hwfn, p_ptt, DORQ_REG_DPM_FORCE_ABORT, 0x1);
+ 
+ 	/* Release overflow sticky indication (stop silently dropping everything) */
+ 	qed_wr(p_hwfn, p_ptt, DORQ_REG_PF_OVFL_STICKY, 0x0);
+ 
+ 	/* Repeat all last doorbells (doorbell drop recovery) */
+ 	qed_db_recovery_execute(p_hwfn, DB_REC_REAL_DEAL);
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> cfdb1b63eefe (qed: Revise load sequence to avoid PCI errors)
  static int qed_dorq_attn_cb(struct qed_hwfn *p_hwfn)
  {
 -	u32 int_sts, first_drop_reason, details, address, all_drops_reason;
 -	struct qed_ptt *p_ptt = p_hwfn->p_dpc_ptt;
 -	int rc;
 -
 -	int_sts = qed_rd(p_hwfn, p_ptt, DORQ_REG_INT_STS);
 -	DP_NOTICE(p_hwfn->cdev, "DORQ attention. int_sts was %x\n", int_sts);
 -
 -	/* int_sts may be zero since all PFs were interrupted for doorbell
 -	 * overflow but another one already handled it. Can abort here. If
 -	 * This PF also requires overflow recovery we will be interrupted again.
 -	 * The masked almost full indication may also be set. Ignoring.
 -	 */
 -	if (!(int_sts & ~DORQ_REG_INT_STS_DORQ_FIFO_AFULL))
 -		return 0;
 +	u32 reason;
  
 -	/* check if db_drop or overflow happened */
 -	if (int_sts & (DORQ_REG_INT_STS_DB_DROP |
 -		       DORQ_REG_INT_STS_DORQ_FIFO_OVFL_ERR)) {
 -		/* Obtain data about db drop/overflow */
 -		first_drop_reason = qed_rd(p_hwfn, p_ptt,
 -					   DORQ_REG_DB_DROP_REASON) &
 -		    QED_DORQ_ATTENTION_REASON_MASK;
 -		details = qed_rd(p_hwfn, p_ptt, DORQ_REG_DB_DROP_DETAILS);
 -		address = qed_rd(p_hwfn, p_ptt,
 -				 DORQ_REG_DB_DROP_DETAILS_ADDRESS);
 -		all_drops_reason = qed_rd(p_hwfn, p_ptt,
 -					  DORQ_REG_DB_DROP_DETAILS_REASON);
 -
 -		/* Log info */
 -		DP_NOTICE(p_hwfn->cdev,
 -			  "Doorbell drop occurred\n"
 -			  "Address\t\t0x%08x\t(second BAR address)\n"
 -			  "FID\t\t0x%04x\t\t(Opaque FID)\n"
 -			  "Size\t\t0x%04x\t\t(in bytes)\n"
 -			  "1st drop reason\t0x%08x\t(details on first drop since last handling)\n"
 -			  "Sticky reasons\t0x%08x\t(all drop reasons since last handling)\n",
 -			  address,
 -			  GET_FIELD(details, QED_DORQ_ATTENTION_OPAQUE),
 -			  GET_FIELD(details, QED_DORQ_ATTENTION_SIZE) * 4,
 -			  first_drop_reason, all_drops_reason);
 -
 -		rc = qed_db_rec_handler(p_hwfn, p_ptt);
 -		qed_periodic_db_rec_start(p_hwfn);
 -		if (rc)
 -			return rc;
 +	reason = qed_rd(p_hwfn, p_hwfn->p_dpc_ptt, DORQ_REG_DB_DROP_REASON) &
 +			QED_DORQ_ATTENTION_REASON_MASK;
 +	if (reason) {
 +		u32 details = qed_rd(p_hwfn, p_hwfn->p_dpc_ptt,
 +				     DORQ_REG_DB_DROP_DETAILS);
  
 -		/* Clear the doorbell drop details and prepare for next drop */
 -		qed_wr(p_hwfn, p_ptt, DORQ_REG_DB_DROP_DETAILS_REL, 0);
 -
 -		/* Mark interrupt as handled (note: even if drop was due to a different
 -		 * reason than overflow we mark as handled)
 -		 */
 -		qed_wr(p_hwfn,
 -		       p_ptt,
 -		       DORQ_REG_INT_STS_WR,
 -		       DORQ_REG_INT_STS_DB_DROP |
 -		       DORQ_REG_INT_STS_DORQ_FIFO_OVFL_ERR);
 -
 -		/* If there are no indications other than drop indications, success */
 -		if ((int_sts & ~(DORQ_REG_INT_STS_DB_DROP |
 -				 DORQ_REG_INT_STS_DORQ_FIFO_OVFL_ERR |
 -				 DORQ_REG_INT_STS_DORQ_FIFO_AFULL)) == 0)
 -			return 0;
 +		DP_INFO(p_hwfn->cdev,
 +			"DORQ db_drop: adress 0x%08x Opaque FID 0x%04x Size [bytes] 0x%08x Reason: 0x%08x\n",
 +			qed_rd(p_hwfn, p_hwfn->p_dpc_ptt,
 +			       DORQ_REG_DB_DROP_DETAILS_ADDRESS),
 +			(u16)(details & QED_DORQ_ATTENTION_OPAQUE_MASK),
 +			GET_FIELD(details, QED_DORQ_ATTENTION_SIZE) * 4,
 +			reason);
  	}
  
 -	/* Some other indication was present - non recoverable */
 -	DP_INFO(p_hwfn, "DORQ fatal attention\n");
 -
  	return -EINVAL;
  }
  
diff --git a/drivers/net/ethernet/qlogic/qed/qed.h b/drivers/net/ethernet/qlogic/qed/qed.h
index fb399ee681d3..cddcd6145085 100644
--- a/drivers/net/ethernet/qlogic/qed/qed.h
+++ b/drivers/net/ethernet/qlogic/qed/qed.h
@@ -553,7 +553,6 @@ struct qed_hwfn {
 	u8				dp_level;
 	char				name[NAME_SIZE];
 
-	bool				first_on_engine;
 	bool				hw_init_done;
 
 	u8				num_funcs_on_engine;
diff --git a/drivers/net/ethernet/qlogic/qed/qed_dev.c b/drivers/net/ethernet/qlogic/qed/qed_dev.c
index 7cecdc02ae8f..d1525e9bd1ba 100644
--- a/drivers/net/ethernet/qlogic/qed/qed_dev.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_dev.c
@@ -1951,11 +1951,6 @@ static int qed_hw_init_pf(struct qed_hwfn *p_hwfn,
 		     (p_hwfn->hw_info.personality == QED_PCI_FCOE) ? 1 : 0);
 	STORE_RT_REG(p_hwfn, PRS_REG_SEARCH_ROCE_RT_OFFSET, 0);
 
-	/* Cleanup chip from previous driver if such remains exist */
-	rc = qed_final_cleanup(p_hwfn, p_ptt, rel_pf_id, false);
-	if (rc)
-		return rc;
-
 	/* Sanity check before the PF init sequence that uses DMAE */
 	rc = qed_dmae_sanity(p_hwfn, p_ptt, "pf_phase");
 	if (rc)
@@ -1999,17 +1994,15 @@ static int qed_hw_init_pf(struct qed_hwfn *p_hwfn,
 	return rc;
 }
 
-static int qed_change_pci_hwfn(struct qed_hwfn *p_hwfn,
-			       struct qed_ptt *p_ptt,
-			       u8 enable)
+int qed_pglueb_set_pfid_enable(struct qed_hwfn *p_hwfn,
+			       struct qed_ptt *p_ptt, bool b_enable)
 {
-	u32 delay_idx = 0, val, set_val = enable ? 1 : 0;
+	u32 delay_idx = 0, val, set_val = b_enable ? 1 : 0;
 
-	/* Change PF in PXP */
-	qed_wr(p_hwfn, p_ptt,
-	       PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER, set_val);
+	/* Configure the PF's internal FID_enable for master transactions */
+	qed_wr(p_hwfn, p_ptt, PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER, set_val);
 
-	/* wait until value is set - try for 1 second every 50us */
+	/* Wait until value is set - try for 1 second every 50us */
 	for (delay_idx = 0; delay_idx < 20000; delay_idx++) {
 		val = qed_rd(p_hwfn, p_ptt,
 			     PGLUE_B_REG_INTERNAL_PFID_ENABLE_MASTER);
@@ -2063,13 +2056,19 @@ static int qed_vf_start(struct qed_hwfn *p_hwfn,
 	return 0;
 }
 
+static void qed_pglueb_clear_err(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)
+{
+	qed_wr(p_hwfn, p_ptt, PGLUE_B_REG_WAS_ERROR_PF_31_0_CLR,
+	       BIT(p_hwfn->abs_pf_id));
+}
+
 int qed_hw_init(struct qed_dev *cdev, struct qed_hw_init_params *p_params)
 {
 	struct qed_load_req_params load_req_params;
 	u32 load_code, resp, param, drv_mb_param;
 	bool b_default_mtu = true;
 	struct qed_hwfn *p_hwfn;
-	int rc = 0, mfw_rc, i;
+	int rc = 0, i;
 	u16 ether_type;
 
 	if ((p_params->int_mode == QED_INT_MODE_MSI) && (cdev->num_hwfns > 1)) {
@@ -2084,7 +2083,7 @@ int qed_hw_init(struct qed_dev *cdev, struct qed_hw_init_params *p_params)
 	}
 
 	for_each_hwfn(cdev, i) {
-		struct qed_hwfn *p_hwfn = &cdev->hwfns[i];
+		p_hwfn = &cdev->hwfns[i];
 
 		/* If management didn't provide a default, set one of our own */
 		if (!p_hwfn->hw_info.mtu) {
@@ -2097,9 +2096,6 @@ int qed_hw_init(struct qed_dev *cdev, struct qed_hw_init_params *p_params)
 			continue;
 		}
 
-		/* Enable DMAE in PXP */
-		rc = qed_change_pci_hwfn(p_hwfn, p_hwfn->p_main_ptt, true);
-
 		rc = qed_calc_hw_mode(p_hwfn);
 		if (rc)
 			return rc;
@@ -2140,8 +2136,34 @@ int qed_hw_init(struct qed_dev *cdev, struct qed_hw_init_params *p_params)
 
 		qed_reset_mb_shadow(p_hwfn, p_hwfn->p_main_ptt);
 
-		p_hwfn->first_on_engine = (load_code ==
-					   FW_MSG_CODE_DRV_LOAD_ENGINE);
+		/* Clean up chip from previous driver if such remains exist.
+		 * This is not needed when the PF is the first one on the
+		 * engine, since afterwards we are going to init the FW.
+		 */
+		if (load_code != FW_MSG_CODE_DRV_LOAD_ENGINE) {
+			rc = qed_final_cleanup(p_hwfn, p_hwfn->p_main_ptt,
+					       p_hwfn->rel_pf_id, false);
+			if (rc) {
+				DP_NOTICE(p_hwfn, "Final cleanup failed\n");
+				goto load_err;
+			}
+		}
+
+		/* Log and clear previous pglue_b errors if such exist */
+		qed_pglueb_rbc_attn_handler(p_hwfn, p_hwfn->p_main_ptt);
+
+		/* Enable the PF's internal FID_enable in the PXP */
+		rc = qed_pglueb_set_pfid_enable(p_hwfn, p_hwfn->p_main_ptt,
+						true);
+		if (rc)
+			goto load_err;
+
+		/* Clear the pglue_b was_error indication.
+		 * In E4 it must be done after the BME and the internal
+		 * FID_enable for the PF are set, since VDMs may cause the
+		 * indication to be set again.
+		 */
+		qed_pglueb_clear_err(p_hwfn, p_hwfn->p_main_ptt);
 
 		switch (load_code) {
 		case FW_MSG_CODE_DRV_LOAD_ENGINE:
@@ -2172,39 +2194,29 @@ int qed_hw_init(struct qed_dev *cdev, struct qed_hw_init_params *p_params)
 			break;
 		}
 
-		if (rc)
+		if (rc) {
 			DP_NOTICE(p_hwfn,
 				  "init phase failed for loadcode 0x%x (rc %d)\n",
-				   load_code, rc);
+				  load_code, rc);
+			goto load_err;
+		}
 
-		/* ACK mfw regardless of success or failure of initialization */
-		mfw_rc = qed_mcp_cmd(p_hwfn, p_hwfn->p_main_ptt,
-				     DRV_MSG_CODE_LOAD_DONE,
-				     0, &load_code, &param);
+		rc = qed_mcp_load_done(p_hwfn, p_hwfn->p_main_ptt);
 		if (rc)
 			return rc;
-		if (mfw_rc) {
-			DP_NOTICE(p_hwfn, "Failed sending LOAD_DONE command\n");
-			return mfw_rc;
-		}
-
-		/* Check if there is a DID mismatch between nvm-cfg/efuse */
-		if (param & FW_MB_PARAM_LOAD_DONE_DID_EFUSE_ERROR)
-			DP_NOTICE(p_hwfn,
-				  "warning: device configuration is not supported on this board type. The device may not function as expected.\n");
 
 		/* send DCBX attention request command */
 		DP_VERBOSE(p_hwfn,
 			   QED_MSG_DCB,
 			   "sending phony dcbx set command to trigger DCBx attention handling\n");
-		mfw_rc = qed_mcp_cmd(p_hwfn, p_hwfn->p_main_ptt,
-				     DRV_MSG_CODE_SET_DCBX,
-				     1 << DRV_MB_PARAM_DCBX_NOTIFY_SHIFT,
-				     &load_code, &param);
-		if (mfw_rc) {
+		rc = qed_mcp_cmd(p_hwfn, p_hwfn->p_main_ptt,
+				 DRV_MSG_CODE_SET_DCBX,
+				 1 << DRV_MB_PARAM_DCBX_NOTIFY_SHIFT,
+				 &resp, &param);
+		if (rc) {
 			DP_NOTICE(p_hwfn,
 				  "Failed to send DCBX attention request\n");
-			return mfw_rc;
+			return rc;
 		}
 
 		p_hwfn->hw_init_done = true;
@@ -2253,6 +2265,12 @@ int qed_hw_init(struct qed_dev *cdev, struct qed_hw_init_params *p_params)
 	}
 
 	return 0;
+
+load_err:
+	/* The MFW load lock should be released also when initialization fails.
+	 */
+	qed_mcp_load_done(p_hwfn, p_hwfn->p_main_ptt);
+	return rc;
 }
 
 #define QED_HW_STOP_RETRY_LIMIT (10)
@@ -2387,14 +2405,16 @@ int qed_hw_stop(struct qed_dev *cdev)
 		p_hwfn = QED_LEADING_HWFN(cdev);
 		p_ptt = QED_LEADING_HWFN(cdev)->p_main_ptt;
 
-		/* Disable DMAE in PXP - in CMT, this should only be done for
-		 * first hw-function, and only after all transactions have
-		 * stopped for all active hw-functions.
+		/* Clear the PF's internal FID_enable in the PXP.
+		 * In CMT this should only be done for first hw-function, and
+		 * only after all transactions have stopped for all active
+		 * hw-functions.
 		 */
-		rc = qed_change_pci_hwfn(p_hwfn, p_ptt, false);
+		rc = qed_pglueb_set_pfid_enable(p_hwfn, p_ptt, false);
 		if (rc) {
 			DP_NOTICE(p_hwfn,
-				  "qed_change_pci_hwfn failed. rc = %d.\n", rc);
+				  "qed_pglueb_set_pfid_enable() failed. rc = %d.\n",
+				  rc);
 			rc2 = -EINVAL;
 		}
 	}
@@ -2494,9 +2514,8 @@ static void qed_hw_hwfn_prepare(struct qed_hwfn *p_hwfn)
 		       PGLUE_B_REG_PGL_ADDR_94_F0_BB, 0);
 	}
 
-	/* Clean Previous errors if such exist */
-	qed_wr(p_hwfn, p_hwfn->p_main_ptt,
-	       PGLUE_B_REG_WAS_ERROR_PF_31_0_CLR, 1 << p_hwfn->abs_pf_id);
+	/* Clean previous pglue_b errors if such exist */
+	qed_pglueb_clear_err(p_hwfn, p_hwfn->p_main_ptt);
 
 	/* enable internal target-read */
 	qed_wr(p_hwfn, p_hwfn->p_main_ptt,
diff --git a/drivers/net/ethernet/qlogic/qed/qed_dev_api.h b/drivers/net/ethernet/qlogic/qed/qed_dev_api.h
index acccd85170aa..e4b4e3b78e8a 100644
--- a/drivers/net/ethernet/qlogic/qed/qed_dev_api.h
+++ b/drivers/net/ethernet/qlogic/qed/qed_dev_api.h
@@ -472,6 +472,18 @@ int qed_get_queue_coalesce(struct qed_hwfn *p_hwfn, u16 *coal, void *handle);
 int
 qed_set_queue_coalesce(u16 rx_coal, u16 tx_coal, void *p_handle);
 
+/**
+ * @brief qed_pglueb_set_pfid_enable - Enable or disable PCI BUS MASTER
+ *
+ * @param p_hwfn
+ * @param p_ptt
+ * @param b_enable - true/false
+ *
+ * @return int
+ */
+int qed_pglueb_set_pfid_enable(struct qed_hwfn *p_hwfn,
+			       struct qed_ptt *p_ptt, bool b_enable);
+
 /**
  * @brief db_recovery_add - add doorbell information to the doorbell
  * recovery mechanism.
* Unmerged path drivers/net/ethernet/qlogic/qed/qed_int.c
diff --git a/drivers/net/ethernet/qlogic/qed/qed_int.h b/drivers/net/ethernet/qlogic/qed/qed_int.h
index 54b4ee0acfd7..6789a39f8d7c 100644
--- a/drivers/net/ethernet/qlogic/qed/qed_int.h
+++ b/drivers/net/ethernet/qlogic/qed/qed_int.h
@@ -421,4 +421,7 @@ int qed_int_set_timer_res(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt,
 
 #define QED_MAPPING_MEMORY_SIZE(dev)	(NUM_OF_SBS(dev))
 
+int qed_pglueb_rbc_attn_handler(struct qed_hwfn *p_hwfn,
+				struct qed_ptt *p_ptt);
+
 #endif
diff --git a/drivers/net/ethernet/qlogic/qed/qed_mcp.c b/drivers/net/ethernet/qlogic/qed/qed_mcp.c
index e57de0e64b8a..c1d5d6235bb2 100644
--- a/drivers/net/ethernet/qlogic/qed/qed_mcp.c
+++ b/drivers/net/ethernet/qlogic/qed/qed_mcp.c
@@ -1070,6 +1070,27 @@ int qed_mcp_load_req(struct qed_hwfn *p_hwfn,
 	return 0;
 }
 
+int qed_mcp_load_done(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)
+{
+	u32 resp = 0, param = 0;
+	int rc;
+
+	rc = qed_mcp_cmd(p_hwfn, p_ptt, DRV_MSG_CODE_LOAD_DONE, 0, &resp,
+			 &param);
+	if (rc) {
+		DP_NOTICE(p_hwfn,
+			  "Failed to send a LOAD_DONE command, rc = %d\n", rc);
+		return rc;
+	}
+
+	/* Check if there is a DID mismatch between nvm-cfg/efuse */
+	if (param & FW_MB_PARAM_LOAD_DONE_DID_EFUSE_ERROR)
+		DP_NOTICE(p_hwfn,
+			  "warning: device configuration is not supported on this board type. The device may not function as expected.\n");
+
+	return 0;
+}
+
 int qed_mcp_unload_req(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt)
 {
 	struct qed_mcp_mb_params mb_params;
diff --git a/drivers/net/ethernet/qlogic/qed/qed_mcp.h b/drivers/net/ethernet/qlogic/qed/qed_mcp.h
index eddf67798d6f..387c5e649136 100644
--- a/drivers/net/ethernet/qlogic/qed/qed_mcp.h
+++ b/drivers/net/ethernet/qlogic/qed/qed_mcp.h
@@ -800,6 +800,16 @@ int qed_mcp_load_req(struct qed_hwfn *p_hwfn,
 		     struct qed_ptt *p_ptt,
 		     struct qed_load_req_params *p_params);
 
+/**
+ * @brief Sends a LOAD_DONE message to the MFW
+ *
+ * @param p_hwfn
+ * @param p_ptt
+ *
+ * @return int - 0 - Operation was successful.
+ */
+int qed_mcp_load_done(struct qed_hwfn *p_hwfn, struct qed_ptt *p_ptt);
+
 /**
  * @brief Sends a UNLOAD_REQ message to the MFW
  *
