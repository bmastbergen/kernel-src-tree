net/mlx5e: Move flow attr reformat action bit to per dest flags

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
Rebuild_CHGLOG: - [netdrv] mlx5e: Move flow attr reformat action bit to per dest flags (Alaa Hleihel) [1642383 1642498]
Rebuild_FUZZ: 96.72%
commit-author Eli Britstein <elibr@mellanox.com>
commit f493f15534ecb5c2c295ba49a2add5822d05ae19
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/f493f155.failed

Flow attr reformat action bit is moved from the global action bits to a
per destination flags field, as a pre-step for adding additional flags
to support encapsulation properties per destination, with no
functionality change.

	Signed-off-by: Eli Britstein <elibr@mellanox.com>
	Reviewed-by: Oz Shlomo <ozsh@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit f493f15534ecb5c2c295ba49a2add5822d05ae19)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index fbb4f1b36627,e48fbb7d9735..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -811,30 -823,123 +811,58 @@@ static int mlx5e_attach_encap(struct ml
  			      struct ip_tunnel_info *tun_info,
  			      struct net_device *mirred_dev,
  			      struct net_device **encap_dev,
 -			      struct mlx5e_tc_flow *flow,
 -			      struct netlink_ext_ack *extack);
 +			      struct mlx5e_tc_flow *flow);
  
  static struct mlx5_flow_handle *
 -mlx5e_tc_offload_fdb_rules(struct mlx5_eswitch *esw,
 -			   struct mlx5e_tc_flow *flow,
 -			   struct mlx5_flow_spec *spec,
 -			   struct mlx5_esw_flow_attr *attr)
 -{
 -	struct mlx5_flow_handle *rule;
 -
 -	rule = mlx5_eswitch_add_offloaded_rule(esw, spec, attr);
 -	if (IS_ERR(rule))
 -		return rule;
 -
 -	if (attr->split_count) {
 -		flow->rule[1] = mlx5_eswitch_add_fwd_rule(esw, spec, attr);
 -		if (IS_ERR(flow->rule[1])) {
 -			mlx5_eswitch_del_offloaded_rule(esw, rule, attr);
 -			return flow->rule[1];
 -		}
 -	}
 -
 -	flow->flags |= MLX5E_TC_FLOW_OFFLOADED;
 -	return rule;
 -}
 -
 -static void
 -mlx5e_tc_unoffload_fdb_rules(struct mlx5_eswitch *esw,
 -			     struct mlx5e_tc_flow *flow,
 -			   struct mlx5_esw_flow_attr *attr)
 -{
 -	flow->flags &= ~MLX5E_TC_FLOW_OFFLOADED;
 -
 -	if (attr->split_count)
 -		mlx5_eswitch_del_fwd_rule(esw, flow->rule[1], attr);
 -
 -	mlx5_eswitch_del_offloaded_rule(esw, flow->rule[0], attr);
 -}
 -
 -static struct mlx5_flow_handle *
 -mlx5e_tc_offload_to_slow_path(struct mlx5_eswitch *esw,
 -			      struct mlx5e_tc_flow *flow,
 -			      struct mlx5_flow_spec *spec,
 -			      struct mlx5_esw_flow_attr *slow_attr)
 -{
 -	struct mlx5_flow_handle *rule;
 -
 -	memcpy(slow_attr, flow->esw_attr, sizeof(*slow_attr));
 -	slow_attr->action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST,
 -	slow_attr->split_count = 0,
 -	slow_attr->dest_chain = FDB_SLOW_PATH_CHAIN,
 -
 -	rule = mlx5e_tc_offload_fdb_rules(esw, flow, spec, slow_attr);
 -	if (!IS_ERR(rule))
 -		flow->flags |= MLX5E_TC_FLOW_SLOW;
 -
 -	return rule;
 -}
 -
 -static void
 -mlx5e_tc_unoffload_from_slow_path(struct mlx5_eswitch *esw,
 -				  struct mlx5e_tc_flow *flow,
 -				  struct mlx5_esw_flow_attr *slow_attr)
 -{
 -	memcpy(slow_attr, flow->esw_attr, sizeof(*slow_attr));
 -	mlx5e_tc_unoffload_fdb_rules(esw, flow, slow_attr);
 -	flow->flags &= ~MLX5E_TC_FLOW_SLOW;
 -}
 -
 -static int
  mlx5e_tc_add_fdb_flow(struct mlx5e_priv *priv,
  		      struct mlx5e_tc_flow_parse_attr *parse_attr,
 -		      struct mlx5e_tc_flow *flow,
 -		      struct netlink_ext_ack *extack)
 +		      struct mlx5e_tc_flow *flow)
  {
  	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 -	u32 max_chain = mlx5_eswitch_get_chain_range(esw);
  	struct mlx5_esw_flow_attr *attr = flow->esw_attr;
 -	u16 max_prio = mlx5_eswitch_get_prio_range(esw);
  	struct net_device *out_dev, *encap_dev = NULL;
 -	struct mlx5_fc *counter = NULL;
 +	struct mlx5_flow_handle *rule = NULL;
  	struct mlx5e_rep_priv *rpriv;
  	struct mlx5e_priv *out_priv;
++<<<<<<< HEAD
 +	int err;
 +
 +	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_ENCAP) {
++=======
+ 	int err = 0, encap_err = 0;
+ 	int out_index;
+ 
+ 	/* if prios are not supported, keep the old behaviour of using same prio
+ 	 * for all offloaded rules.
+ 	 */
+ 	if (!mlx5_eswitch_prios_supported(esw))
+ 		attr->prio = 1;
+ 
+ 	if (attr->chain > max_chain) {
+ 		NL_SET_ERR_MSG(extack, "Requested chain is out of supported range");
+ 		err = -EOPNOTSUPP;
+ 		goto err_max_prio_chain;
+ 	}
+ 
+ 	if (attr->prio > max_prio) {
+ 		NL_SET_ERR_MSG(extack, "Requested priority is out of supported range");
+ 		err = -EOPNOTSUPP;
+ 		goto err_max_prio_chain;
+ 	}
+ 
+ 	for (out_index = 0; out_index < MLX5_MAX_FLOW_FWD_VPORTS; out_index++) {
+ 		if (!(attr->dests[out_index].flags & MLX5_ESW_DEST_ENCAP))
+ 			continue;
+ 
++>>>>>>> f493f15534ec (net/mlx5e: Move flow attr reformat action bit to per dest flags)
  		out_dev = __dev_get_by_index(dev_net(priv->netdev),
  					     attr->parse_attr->mirred_ifindex);
 -		encap_err = mlx5e_attach_encap(priv, &parse_attr->tun_info,
 -					       out_dev, &encap_dev, flow,
 -					       extack);
 -		if (encap_err && encap_err != -EAGAIN) {
 -			err = encap_err;
 -			goto err_attach_encap;
 +		err = mlx5e_attach_encap(priv, &parse_attr->tun_info,
 +					 out_dev, &encap_dev, flow);
 +		if (err) {
 +			rule = ERR_PTR(err);
 +			if (err != -EAGAIN)
 +				goto err_attach_encap;
  		}
  		out_priv = netdev_priv(encap_dev);
  		rpriv = out_priv->ppriv;
@@@ -873,10 -995,14 +901,18 @@@ err_add_rule
  err_mod_hdr:
  	mlx5_eswitch_del_vlan_action(esw, attr);
  err_add_vlan:
++<<<<<<< HEAD
 +	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_ENCAP)
 +		mlx5e_detach_encap(priv, flow);
++=======
+ 	for (out_index = 0; out_index < MLX5_MAX_FLOW_FWD_VPORTS; out_index++)
+ 		if (attr->dests[out_index].flags & MLX5_ESW_DEST_ENCAP) {
+ 			mlx5e_detach_encap(priv, flow);
+ 			break;
+ 		}
++>>>>>>> f493f15534ec (net/mlx5e: Move flow attr reformat action bit to per dest flags)
  err_attach_encap:
 -err_max_prio_chain:
 -	return err;
 +	return rule;
  }
  
  static void mlx5e_tc_del_fdb_flow(struct mlx5e_priv *priv,
@@@ -884,18 -1010,24 +920,32 @@@
  {
  	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
  	struct mlx5_esw_flow_attr *attr = flow->esw_attr;
++<<<<<<< HEAD
++=======
+ 	struct mlx5_esw_flow_attr slow_attr;
+ 	int out_index;
++>>>>>>> f493f15534ec (net/mlx5e: Move flow attr reformat action bit to per dest flags)
  
  	if (flow->flags & MLX5E_TC_FLOW_OFFLOADED) {
 -		if (flow->flags & MLX5E_TC_FLOW_SLOW)
 -			mlx5e_tc_unoffload_from_slow_path(esw, flow, &slow_attr);
 -		else
 -			mlx5e_tc_unoffload_fdb_rules(esw, flow, attr);
 +		flow->flags &= ~MLX5E_TC_FLOW_OFFLOADED;
 +		mlx5_eswitch_del_offloaded_rule(esw, flow->rule, attr);
  	}
  
  	mlx5_eswitch_del_vlan_action(esw, attr);
  
++<<<<<<< HEAD
 +	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_ENCAP) {
 +		mlx5e_detach_encap(priv, flow);
 +		kvfree(attr->parse_attr);
 +	}
++=======
+ 	for (out_index = 0; out_index < MLX5_MAX_FLOW_FWD_VPORTS; out_index++)
+ 		if (attr->dests[out_index].flags & MLX5_ESW_DEST_ENCAP) {
+ 			mlx5e_detach_encap(priv, flow);
+ 			break;
+ 		}
+ 	kvfree(attr->parse_attr);
++>>>>>>> f493f15534ec (net/mlx5e: Move flow attr reformat action bit to per dest flags)
  
  	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR)
  		mlx5e_detach_mod_hdr(priv, flow);
@@@ -2622,29 -2441,65 +2672,51 @@@ static int parse_tc_fdb_actions(struct 
  			continue;
  		}
  
 -		if (is_tcf_csum(a)) {
 -			if (csum_offload_supported(priv, action,
 -						   tcf_csum_update_flags(a),
 -						   extack))
 -				continue;
 -
 -			return -EOPNOTSUPP;
 -		}
 -
 -		if (is_tcf_mirred_egress_redirect(a) || is_tcf_mirred_egress_mirror(a)) {
 -			struct mlx5e_priv *out_priv;
 +		if (is_tcf_mirred_egress_redirect(a)) {
  			struct net_device *out_dev;
 +			struct mlx5e_priv *out_priv;
  
  			out_dev = tcf_mirred_dev(a);
 -			if (!out_dev) {
 -				/* out_dev is NULL when filters with
 -				 * non-existing mirred device are replayed to
 -				 * the driver.
 -				 */
 -				return -EINVAL;
 -			}
 -
 -			if (attr->out_count >= MLX5_MAX_FLOW_FWD_VPORTS) {
 -				NL_SET_ERR_MSG_MOD(extack,
 -						   "can't support more output ports, can't offload forwarding");
 -				pr_err("can't support more than %d output ports, can't offload forwarding\n",
 -				       attr->out_count);
 -				return -EOPNOTSUPP;
 -			}
  
+ 			action |= MLX5_FLOW_CONTEXT_ACTION_FWD_DEST |
+ 				  MLX5_FLOW_CONTEXT_ACTION_COUNT;
  			if (switchdev_port_same_parent_id(priv->netdev,
++<<<<<<< HEAD
 +							  out_dev)) {
 +				attr->action |= MLX5_FLOW_CONTEXT_ACTION_FWD_DEST |
 +					MLX5_FLOW_CONTEXT_ACTION_COUNT;
++=======
+ 							  out_dev) ||
+ 			    is_merged_eswitch_dev(priv, out_dev)) {
++>>>>>>> f493f15534ec (net/mlx5e: Move flow attr reformat action bit to per dest flags)
  				out_priv = netdev_priv(out_dev);
  				rpriv = out_priv->ppriv;
 -				attr->dests[attr->out_count].rep = rpriv->rep;
 -				attr->dests[attr->out_count].mdev = out_priv->mdev;
 -				attr->out_count++;
 +				attr->out_rep = rpriv->rep;
 +				attr->out_mdev = out_priv->mdev;
  			} else if (encap) {
  				parse_attr->mirred_ifindex = out_dev->ifindex;
  				parse_attr->tun_info = *info;
  				attr->parse_attr = parse_attr;
++<<<<<<< HEAD
 +				attr->action |= MLX5_FLOW_CONTEXT_ACTION_ENCAP |
 +					MLX5_FLOW_CONTEXT_ACTION_FWD_DEST |
 +					MLX5_FLOW_CONTEXT_ACTION_COUNT;
 +				/* attr->out_rep is resolved when we handle encap */
++=======
+ 				attr->dests[attr->out_count].flags |=
+ 					MLX5_ESW_DEST_ENCAP;
+ 				/* attr->dests[].rep is resolved when we
+ 				 * handle encap
+ 				 */
+ 			} else if (parse_attr->filter_dev != priv->netdev) {
+ 				/* All mlx5 devices are called to configure
+ 				 * high level device filters. Therefore, the
+ 				 * *attempt* to  install a filter on invalid
+ 				 * eswitch should not trigger an explicit error
+ 				 */
+ 				return -EINVAL;
++>>>>>>> f493f15534ec (net/mlx5e: Move flow attr reformat action bit to per dest flags)
  			} else {
 -				NL_SET_ERR_MSG_MOD(extack,
 -						   "devices are not on same switch HW, can't offload forwarding");
  				pr_err("devices %s %s not on same switch HW, can't offload forwarding\n",
  				       priv->netdev->name, out_dev->name);
  				return -EINVAL;
@@@ -2764,46 -2620,171 +2836,162 @@@ int mlx5e_configure_flower(struct mlx5e
  	flow->flags = flow_flags;
  	flow->priv = priv;
  
 -	*__flow = flow;
 -	*__parse_attr = parse_attr;
 -
 -	return 0;
 -
 -err_free:
 -	kfree(flow);
 -	kvfree(parse_attr);
 -	return err;
 -}
 -
 -static int
 -mlx5e_add_fdb_flow(struct mlx5e_priv *priv,
 -		   struct tc_cls_flower_offload *f,
 -		   u16 flow_flags,
 -		   struct net_device *filter_dev,
 -		   struct mlx5e_tc_flow **__flow)
 -{
 -	struct netlink_ext_ack *extack = f->common.extack;
 -	struct mlx5e_tc_flow_parse_attr *parse_attr;
 -	struct mlx5e_tc_flow *flow;
 -	int attr_size, err;
 -
 -	flow_flags |= MLX5E_TC_FLOW_ESWITCH;
 -	attr_size  = sizeof(struct mlx5_esw_flow_attr);
 -	err = mlx5e_alloc_flow(priv, attr_size, f, flow_flags,
 -			       &parse_attr, &flow);
 -	if (err)
 -		goto out;
 -	parse_attr->filter_dev = filter_dev;
 -	flow->esw_attr->parse_attr = parse_attr;
 -	err = parse_cls_flower(flow->priv, flow, &parse_attr->spec,
 -			       f, filter_dev);
 -	if (err)
 +	err = parse_cls_flower(priv, flow, &parse_attr->spec, f);
 +	if (err < 0)
  		goto err_free;
  
++<<<<<<< HEAD
 +	if (flow->flags & MLX5E_TC_FLOW_ESWITCH) {
 +		err = parse_tc_fdb_actions(priv, f->exts, parse_attr, flow);
 +		if (err < 0)
 +			goto err_free;
 +		flow->rule = mlx5e_tc_add_fdb_flow(priv, parse_attr, flow);
 +	} else {
 +		err = parse_tc_nic_actions(priv, f->exts, parse_attr, flow);
 +		if (err < 0)
 +			goto err_free;
 +		flow->rule = mlx5e_tc_add_nic_flow(priv, parse_attr, flow);
++=======
+ 	flow->esw_attr->chain = f->common.chain_index;
+ 	flow->esw_attr->prio = TC_H_MAJ(f->common.prio) >> 16;
+ 	err = parse_tc_fdb_actions(priv, f->exts, parse_attr, flow, extack);
+ 	if (err)
+ 		goto err_free;
+ 
+ 	err = mlx5e_tc_add_fdb_flow(priv, parse_attr, flow, extack);
+ 	if (err)
+ 		goto err_free;
+ 
+ 	*__flow = flow;
+ 
+ 	return 0;
+ 
+ err_free:
+ 	kfree(flow);
+ 	kvfree(parse_attr);
+ out:
+ 	return err;
+ }
+ 
+ static int
+ mlx5e_add_nic_flow(struct mlx5e_priv *priv,
+ 		   struct tc_cls_flower_offload *f,
+ 		   u16 flow_flags,
+ 		   struct net_device *filter_dev,
+ 		   struct mlx5e_tc_flow **__flow)
+ {
+ 	struct netlink_ext_ack *extack = f->common.extack;
+ 	struct mlx5e_tc_flow_parse_attr *parse_attr;
+ 	struct mlx5e_tc_flow *flow;
+ 	int attr_size, err;
+ 
+ 	/* multi-chain not supported for NIC rules */
+ 	if (!tc_cls_can_offload_and_chain0(priv->netdev, &f->common))
+ 		return -EOPNOTSUPP;
+ 
+ 	flow_flags |= MLX5E_TC_FLOW_NIC;
+ 	attr_size  = sizeof(struct mlx5_nic_flow_attr);
+ 	err = mlx5e_alloc_flow(priv, attr_size, f, flow_flags,
+ 			       &parse_attr, &flow);
+ 	if (err)
+ 		goto out;
+ 
+ 	parse_attr->filter_dev = filter_dev;
+ 	err = parse_cls_flower(flow->priv, flow, &parse_attr->spec,
+ 			       f, filter_dev);
+ 	if (err)
+ 		goto err_free;
+ 
+ 	err = parse_tc_nic_actions(priv, f->exts, parse_attr, flow, extack);
+ 	if (err)
+ 		goto err_free;
+ 
+ 	err = mlx5e_tc_add_nic_flow(priv, parse_attr, flow, extack);
+ 	if (err)
+ 		goto err_free;
+ 
+ 	flow->flags |= MLX5E_TC_FLOW_OFFLOADED;
+ 	kvfree(parse_attr);
+ 	*__flow = flow;
+ 
+ 	return 0;
+ 
+ err_free:
+ 	kfree(flow);
+ 	kvfree(parse_attr);
+ out:
+ 	return err;
+ }
+ 
+ static int
+ mlx5e_tc_add_flow(struct mlx5e_priv *priv,
+ 		  struct tc_cls_flower_offload *f,
+ 		  int flags,
+ 		  struct net_device *filter_dev,
+ 		  struct mlx5e_tc_flow **flow)
+ {
+ 	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+ 	u16 flow_flags;
+ 	int err;
+ 
+ 	get_flags(flags, &flow_flags);
+ 
+ 	if (!tc_can_offload_extack(priv->netdev, f->common.extack))
+ 		return -EOPNOTSUPP;
+ 
+ 	if (esw && esw->mode == SRIOV_OFFLOADS)
+ 		err = mlx5e_add_fdb_flow(priv, f, flow_flags,
+ 					 filter_dev, flow);
+ 	else
+ 		err = mlx5e_add_nic_flow(priv, f, flow_flags,
+ 					 filter_dev, flow);
+ 
+ 	return err;
+ }
+ 
+ int mlx5e_configure_flower(struct net_device *dev, struct mlx5e_priv *priv,
+ 			   struct tc_cls_flower_offload *f, int flags)
+ {
+ 	struct netlink_ext_ack *extack = f->common.extack;
+ 	struct rhashtable *tc_ht = get_tc_ht(priv);
+ 	struct mlx5e_tc_flow *flow;
+ 	int err = 0;
+ 
+ 	flow = rhashtable_lookup_fast(tc_ht, &f->cookie, tc_ht_params);
+ 	if (flow) {
+ 		NL_SET_ERR_MSG_MOD(extack,
+ 				   "flow cookie already exists, ignoring");
+ 		netdev_warn_once(priv->netdev,
+ 				 "flow cookie %lx already exists, ignoring\n",
+ 				 f->cookie);
+ 		goto out;
++>>>>>>> f493f15534ec (net/mlx5e: Move flow attr reformat action bit to per dest flags)
  	}
  
 -	err = mlx5e_tc_add_flow(priv, f, flags, dev, &flow);
 -	if (err)
 -		goto out;
 +	if (IS_ERR(flow->rule)) {
 +		err = PTR_ERR(flow->rule);
 +		if (err != -EAGAIN)
 +			goto err_free;
 +	}
 +
 +	if (err != -EAGAIN)
 +		flow->flags |= MLX5E_TC_FLOW_OFFLOADED;
 +
 +	if (!(flow->flags & MLX5E_TC_FLOW_ESWITCH) ||
 +	    !(flow->esw_attr->action & MLX5_FLOW_CONTEXT_ACTION_ENCAP))
 +		kvfree(parse_attr);
  
  	err = rhashtable_insert_fast(tc_ht, &flow->node, tc_ht_params);
 -	if (err)
 -		goto err_free;
 +	if (err) {
 +		mlx5e_tc_del_flow(priv, flow);
 +		kfree(flow);
 +	}
  
 -	return 0;
 +	return err;
  
  err_free:
 -	mlx5e_tc_del_flow(priv, flow);
 +	kvfree(parse_attr);
  	kfree(flow);
 -out:
  	return err;
  }
  
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index 21bc97b70ed9,39363d4662b3..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@@ -241,20 -278,38 +241,38 @@@ enum mlx5_flow_match_level 
  	MLX5_MATCH_L4	= MLX5_INLINE_MODE_TCP_UDP,
  };
  
++<<<<<<< HEAD
++=======
+ /* current maximum for flow based vport multicasting */
+ #define MLX5_MAX_FLOW_FWD_VPORTS 2
+ 
+ enum {
+ 	MLX5_ESW_DEST_ENCAP         = BIT(0),
+ };
+ 
++>>>>>>> f493f15534ec (net/mlx5e: Move flow attr reformat action bit to per dest flags)
  struct mlx5_esw_flow_attr {
  	struct mlx5_eswitch_rep *in_rep;
 +	struct mlx5_eswitch_rep *out_rep;
 +	struct mlx5_core_dev	*out_mdev;
  	struct mlx5_core_dev	*in_mdev;
  
 -	int split_count;
 -	int out_count;
 -
  	int	action;
 -	__be16	vlan_proto[MLX5_FS_VLAN_DEPTH];
 -	u16	vlan_vid[MLX5_FS_VLAN_DEPTH];
 -	u8	vlan_prio[MLX5_FS_VLAN_DEPTH];
 -	u8	total_vlan;
 +	__be16	vlan_proto;
 +	u16	vlan_vid;
 +	u8	vlan_prio;
  	bool	vlan_handled;
  	u32	encap_id;
++<<<<<<< HEAD
++=======
+ 	struct {
+ 		u32 flags;
+ 		struct mlx5_eswitch_rep *rep;
+ 		struct mlx5_core_dev *mdev;
+ 	} dests[MLX5_MAX_FLOW_FWD_VPORTS];
++>>>>>>> f493f15534ec (net/mlx5e: Move flow attr reformat action bit to per dest flags)
  	u32	mod_hdr_id;
  	u8	match_level;
 -	struct mlx5_fc *counter;
 -	u32	chain;
 -	u16	prio;
 -	u32	dest_chain;
  	struct mlx5e_tc_flow_parse_attr *parse_attr;
  };
  
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
index 84864631953e,0387b5068be6..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@@ -70,23 -107,38 +70,53 @@@ mlx5_eswitch_add_offloaded_rule(struct 
  	}
  
  	if (flow_act.action & MLX5_FLOW_CONTEXT_ACTION_FWD_DEST) {
++<<<<<<< HEAD
 +		dest[i].type = MLX5_FLOW_DESTINATION_TYPE_VPORT;
 +		dest[i].vport.num = attr->out_rep->vport;
 +		if (MLX5_CAP_ESW(esw->dev, merged_eswitch)) {
 +			dest[i].vport.vhca_id =
 +				MLX5_CAP_GEN(attr->out_mdev, vhca_id);
 +			dest[i].vport.vhca_id_valid = 1;
++=======
+ 		if (attr->dest_chain) {
+ 			struct mlx5_flow_table *ft;
+ 
+ 			ft = esw_get_prio_table(esw, attr->dest_chain, 1, 0);
+ 			if (IS_ERR(ft)) {
+ 				rule = ERR_CAST(ft);
+ 				goto err_create_goto_table;
+ 			}
+ 
+ 			dest[i].type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
+ 			dest[i].ft = ft;
+ 			i++;
+ 		} else {
+ 			for (j = attr->split_count; j < attr->out_count; j++) {
+ 				dest[i].type = MLX5_FLOW_DESTINATION_TYPE_VPORT;
+ 				dest[i].vport.num = attr->dests[j].rep->vport;
+ 				dest[i].vport.vhca_id =
+ 					MLX5_CAP_GEN(attr->dests[j].mdev, vhca_id);
+ 				if (MLX5_CAP_ESW(esw->dev, merged_eswitch))
+ 					dest[i].vport.flags |=
+ 						MLX5_FLOW_DEST_VPORT_VHCA_ID;
+ 				if (attr->dests[j].flags & MLX5_ESW_DEST_ENCAP) {
+ 					flow_act.action |= MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT;
+ 					flow_act.reformat_id = attr->encap_id;
+ 				}
+ 				i++;
+ 			}
++>>>>>>> f493f15534ec (net/mlx5e: Move flow attr reformat action bit to per dest flags)
  		}
 +		i++;
  	}
  	if (flow_act.action & MLX5_FLOW_CONTEXT_ACTION_COUNT) {
 +		counter = mlx5_fc_create(esw->dev, true);
 +		if (IS_ERR(counter)) {
 +			rule = ERR_CAST(counter);
 +			goto err_counter_alloc;
 +		}
  		dest[i].type = MLX5_FLOW_DESTINATION_TYPE_COUNTER;
 -		dest[i].counter_id = mlx5_fc_id(attr->counter);
 +		dest[i].counter = counter;
  		i++;
  	}
  
@@@ -116,11 -168,13 +146,21 @@@
  	if (flow_act.action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR)
  		flow_act.modify_id = attr->mod_hdr_id;
  
++<<<<<<< HEAD
 +	if (flow_act.action & MLX5_FLOW_CONTEXT_ACTION_ENCAP)
 +		flow_act.encap_id = attr->encap_id;
 +
 +	rule = mlx5_add_flow_rules((struct mlx5_flow_table *)esw->fdb_table.offloads.fast_fdb,
 +				   spec, &flow_act, dest, i);
++=======
+ 	fdb = esw_get_prio_table(esw, attr->chain, attr->prio, !!split);
+ 	if (IS_ERR(fdb)) {
+ 		rule = ERR_CAST(fdb);
+ 		goto err_esw_get;
+ 	}
+ 
+ 	rule = mlx5_add_flow_rules(fdb, spec, &flow_act, dest, i);
++>>>>>>> f493f15534ec (net/mlx5e: Move flow attr reformat action bit to per dest flags)
  	if (IS_ERR(rule))
  		goto err_add_rule;
  	else
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
