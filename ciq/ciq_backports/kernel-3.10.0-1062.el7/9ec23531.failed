sched/preempt, mm/fault: Trigger might_sleep() in might_fault() with disabled pagefaults

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author David Hildenbrand <dahi@linux.vnet.ibm.com>
commit 9ec23531fd48031d1b6ca5366f5f967d17a8bc28
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/9ec23531.failed

Commit 662bbcb2747c ("mm, sched: Allow uaccess in atomic with
pagefault_disable()") removed might_sleep() checks for all user access
code (that uses might_fault()).

The reason was to disable wrong "sleep in atomic" warnings in the
following scenario:

    pagefault_disable()
    rc = copy_to_user(...)
    pagefault_enable()

Which is valid, as pagefault_disable() increments the preempt counter
and therefore disables the pagefault handler. copy_to_user() will not
sleep and return an error code if a page is not available.

However, as all might_sleep() checks are removed,
CONFIG_DEBUG_ATOMIC_SLEEP would no longer detect the following scenario:

    spin_lock(&lock);
    rc = copy_to_user(...)
    spin_unlock(&lock)

If the kernel is compiled with preemption turned on, preempt_disable()
will make in_atomic() detect disabled preemption. The fault handler would
correctly never sleep on user access.
However, with preemption turned off, preempt_disable() is usually a NOP
(with !CONFIG_PREEMPT_COUNT), therefore in_atomic() will not be able to
detect disabled preemption nor disabled pagefaults. The fault handler
could sleep.
We really want to enable CONFIG_DEBUG_ATOMIC_SLEEP checks for user access
functions again, otherwise we can end up with horrible deadlocks.

Root of all evil is that pagefault_disable() acts almost as
preempt_disable(), depending on preemption being turned on/off.

As we now have pagefault_disabled(), we can use it to distinguish
whether user acces functions might sleep.

Convert might_fault() into a makro that calls __might_fault(), to
allow proper file + line messages in case of a might_sleep() warning.

Reviewed-and-tested-by: Thomas Gleixner <tglx@linutronix.de>
	Signed-off-by: David Hildenbrand <dahi@linux.vnet.ibm.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: David.Laight@ACULAB.COM
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: airlied@linux.ie
	Cc: akpm@linux-foundation.org
	Cc: benh@kernel.crashing.org
	Cc: bigeasy@linutronix.de
	Cc: borntraeger@de.ibm.com
	Cc: daniel.vetter@intel.com
	Cc: heiko.carstens@de.ibm.com
	Cc: herbert@gondor.apana.org.au
	Cc: hocko@suse.cz
	Cc: hughd@google.com
	Cc: mst@redhat.com
	Cc: paulus@samba.org
	Cc: ralf@linux-mips.org
	Cc: schwidefsky@de.ibm.com
	Cc: yang.shi@windriver.com
Link: http://lkml.kernel.org/r/1431359540-32227-3-git-send-email-dahi@linux.vnet.ibm.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 9ec23531fd48031d1b6ca5366f5f967d17a8bc28)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/kernel.h
diff --cc include/linux/kernel.h
index c9308a0d7467,060dd7b61c6d..000000000000
--- a/include/linux/kernel.h
+++ b/include/linux/kernel.h
@@@ -248,8 -242,10 +248,15 @@@ static inline u32 reciprocal_scale(u32 
  	return (u32)(((u64) val * ep_ro) >> 32);
  }
  
++<<<<<<< HEAD
 +#if defined(CONFIG_PROVE_LOCKING) || defined(CONFIG_DEBUG_ATOMIC_SLEEP)
 +void might_fault(void);
++=======
+ #if defined(CONFIG_MMU) && \
+ 	(defined(CONFIG_PROVE_LOCKING) || defined(CONFIG_DEBUG_ATOMIC_SLEEP))
+ #define might_fault() __might_fault(__FILE__, __LINE__)
+ void __might_fault(const char *file, int line);
++>>>>>>> 9ec23531fd48 (sched/preempt, mm/fault: Trigger might_sleep() in might_fault() with disabled pagefaults)
  #else
  static inline void might_fault(void) { }
  #endif
* Unmerged path include/linux/kernel.h
diff --git a/mm/memory.c b/mm/memory.c
index 992044080678..1d41f1088eb7 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -4035,7 +4035,7 @@ void print_vma_addr(char *prefix, unsigned long ip)
 }
 
 #if defined(CONFIG_PROVE_LOCKING) || defined(CONFIG_DEBUG_ATOMIC_SLEEP)
-void might_fault(void)
+void __might_fault(const char *file, int line)
 {
 	/*
 	 * Some code (nfs/sunrpc) uses socket ops on kernel memory while
@@ -4045,21 +4045,15 @@ void might_fault(void)
 	 */
 	if (segment_eq(get_fs(), KERNEL_DS))
 		return;
-
-	/*
-	 * it would be nicer only to annotate paths which are not under
-	 * pagefault_disable, however that requires a larger audit and
-	 * providing helpers like get_user_atomic.
-	 */
-	if (in_atomic())
+	if (pagefault_disabled())
 		return;
-
-	__might_sleep(__FILE__, __LINE__, 0);
-
+	__might_sleep(file, line, 0);
+#if defined(CONFIG_DEBUG_ATOMIC_SLEEP)
 	if (current->mm)
 		might_lock_read(&current->mm->mmap_sem);
+#endif
 }
-EXPORT_SYMBOL(might_fault);
+EXPORT_SYMBOL(__might_fault);
 #endif
 
 #if defined(CONFIG_TRANSPARENT_HUGEPAGE) || defined(CONFIG_HUGETLBFS)
