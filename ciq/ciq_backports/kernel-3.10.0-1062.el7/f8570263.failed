memcg, slab: RCU protect memcg_params for root caches

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Vladimir Davydov <vdavydov@parallels.com>
commit f8570263ee16eb1d5038b8e20d7db3a68bbb2b49
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/f8570263.failed

We relocate root cache's memcg_params whenever we need to grow the
memcg_caches array to accommodate all kmem-active memory cgroups.
Currently on relocation we free the old version immediately, which can
lead to use-after-free, because the memcg_caches array is accessed
lock-free (see cache_from_memcg_idx()).  This patch fixes this by making
memcg_params RCU-protected for root caches.

	Signed-off-by: Vladimir Davydov <vdavydov@parallels.com>
	Cc: Michal Hocko <mhocko@suse.cz>
	Cc: Glauber Costa <glommer@gmail.com>
	Cc: Johannes Weiner <hannes@cmpxchg.org>
	Cc: Balbir Singh <bsingharora@gmail.com>
	Cc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>
	Cc: Pekka Enberg <penberg@kernel.org>
	Cc: Christoph Lameter <cl@linux.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit f8570263ee16eb1d5038b8e20d7db3a68bbb2b49)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/slab.h
diff --cc mm/slab.h
index 6a02fdac0ff7,8184a7cde272..000000000000
--- a/mm/slab.h
+++ b/mm/slab.h
@@@ -165,9 -172,24 +174,30 @@@ static inline const char *cache_name(st
  static inline struct kmem_cache *
  cache_from_memcg_idx(struct kmem_cache *s, int idx)
  {
++<<<<<<< HEAD
 +	if (!s->memcg_params)
 +		return NULL;
 +	return s->memcg_params->memcg_caches[idx];
++=======
+ 	struct kmem_cache *cachep;
+ 	struct memcg_cache_params *params;
+ 
+ 	if (!s->memcg_params)
+ 		return NULL;
+ 
+ 	rcu_read_lock();
+ 	params = rcu_dereference(s->memcg_params);
+ 	cachep = params->memcg_caches[idx];
+ 	rcu_read_unlock();
+ 
+ 	/*
+ 	 * Make sure we will access the up-to-date value. The code updating
+ 	 * memcg_caches issues a write barrier to match this (see
+ 	 * memcg_register_cache()).
+ 	 */
+ 	smp_read_barrier_depends();
+ 	return cachep;
++>>>>>>> f8570263ee16 (memcg, slab: RCU protect memcg_params for root caches)
  }
  
  static inline struct kmem_cache *memcg_root_cache(struct kmem_cache *s)
diff --git a/include/linux/slab.h b/include/linux/slab.h
index eab8fa5b7846..55b40c9feaa9 100644
--- a/include/linux/slab.h
+++ b/include/linux/slab.h
@@ -335,7 +335,9 @@ static __always_inline int kmalloc_size(int n)
  *
  * Both the root cache and the child caches will have it. For the root cache,
  * this will hold a dynamically allocated array large enough to hold
- * information about the currently limited memcgs in the system.
+ * information about the currently limited memcgs in the system. To allow the
+ * array to be accessed without taking any locks, on relocation we free the old
+ * version only after a grace period.
  *
  * Child caches will hold extra metadata needed for its operation. Fields are:
  *
@@ -350,7 +352,10 @@ static __always_inline int kmalloc_size(int n)
 struct memcg_cache_params {
 	bool is_root_cache;
 	union {
-		struct kmem_cache *memcg_caches[0];
+		struct {
+			struct rcu_head rcu_head;
+			struct kmem_cache *memcg_caches[0];
+		};
 		struct {
 			struct mem_cgroup *memcg;
 			struct list_head list;
diff --git a/mm/memcontrol.c b/mm/memcontrol.c
index 5a271ae6c0ad..abfbfa19ef9f 100644
--- a/mm/memcontrol.c
+++ b/mm/memcontrol.c
@@ -3158,18 +3158,17 @@ int memcg_update_cache_size(struct kmem_cache *s, int num_groups)
 	 */
 	if (num_groups > memcg_limited_groups_array_size || !cur_params) {
 		int i;
+		struct memcg_cache_params *new_params;
 		ssize_t size = memcg_caches_array_size(num_groups);
 
 		size *= sizeof(void *);
 		size += sizeof(struct memcg_cache_params);
 
-		s->memcg_params = kzalloc(size, GFP_KERNEL);
-		if (!s->memcg_params) {
-			s->memcg_params = cur_params;
+		new_params = kzalloc(size, GFP_KERNEL);
+		if (!new_params)
 			return -ENOMEM;
-		}
 
-		s->memcg_params->is_root_cache = true;
+		new_params->is_root_cache = true;
 
 		/* if there was no kmem_cache->memcg_params, first time so we are done */
 		if (!cur_params)
@@ -3187,7 +3186,7 @@ int memcg_update_cache_size(struct kmem_cache *s, int num_groups)
 		for (i = 0; i < memcg_limited_groups_array_size; i++) {
 			if (!cur_params->memcg_caches[i])
 				continue;
-			s->memcg_params->memcg_caches[i] =
+			new_params->memcg_caches[i] =
 						cur_params->memcg_caches[i];
 		}
 
@@ -3200,7 +3199,9 @@ int memcg_update_cache_size(struct kmem_cache *s, int num_groups)
 		 * bigger than the others. And all updates will reset this
 		 * anyway.
 		 */
-		kfree(cur_params);
+		rcu_assign_pointer(s->memcg_params, new_params);
+		if (cur_params)
+			kfree_rcu(cur_params, rcu_head);
 	}
 	return 0;
 }
* Unmerged path mm/slab.h
