xdp: generic XDP handling of xdp_rxq_info

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Jesper Dangaard Brouer <brouer@redhat.com>
commit e817f85652c14d78f170b18797e4c477c78949e0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/e817f856.failed

Hook points for xdp_rxq_info:
 * reg  : netif_alloc_rx_queues
 * unreg: netif_free_rx_queues

The net_device have some members (num_rx_queues + real_num_rx_queues)
and data-area (dev->_rx with struct netdev_rx_queue's) that were
primarily used for exporting information about RPS (CONFIG_RPS) queues
to sysfs (CONFIG_SYSFS).

For generic XDP extend struct netdev_rx_queue with the xdp_rxq_info,
and remove some of the CONFIG_SYSFS ifdefs.

	Signed-off-by: Jesper Dangaard Brouer <brouer@redhat.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
(cherry picked from commit e817f85652c14d78f170b18797e4c477c78949e0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/core/dev.c
diff --cc net/core/dev.c
index 8e4fb78a977c,d7925ef8743d..000000000000
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@@ -3833,6 -3906,169 +3833,172 @@@ drop
  	return NET_RX_DROP;
  }
  
++<<<<<<< HEAD
++=======
+ static struct netdev_rx_queue *netif_get_rxqueue(struct sk_buff *skb)
+ {
+ 	struct net_device *dev = skb->dev;
+ 	struct netdev_rx_queue *rxqueue;
+ 
+ 	rxqueue = dev->_rx;
+ 
+ 	if (skb_rx_queue_recorded(skb)) {
+ 		u16 index = skb_get_rx_queue(skb);
+ 
+ 		if (unlikely(index >= dev->real_num_rx_queues)) {
+ 			WARN_ONCE(dev->real_num_rx_queues > 1,
+ 				  "%s received packet on queue %u, but number "
+ 				  "of RX queues is %u\n",
+ 				  dev->name, index, dev->real_num_rx_queues);
+ 
+ 			return rxqueue; /* Return first rxqueue */
+ 		}
+ 		rxqueue += index;
+ 	}
+ 	return rxqueue;
+ }
+ 
+ static u32 netif_receive_generic_xdp(struct sk_buff *skb,
+ 				     struct bpf_prog *xdp_prog)
+ {
+ 	struct netdev_rx_queue *rxqueue;
+ 	u32 metalen, act = XDP_DROP;
+ 	struct xdp_buff xdp;
+ 	void *orig_data;
+ 	int hlen, off;
+ 	u32 mac_len;
+ 
+ 	/* Reinjected packets coming from act_mirred or similar should
+ 	 * not get XDP generic processing.
+ 	 */
+ 	if (skb_cloned(skb))
+ 		return XDP_PASS;
+ 
+ 	/* XDP packets must be linear and must have sufficient headroom
+ 	 * of XDP_PACKET_HEADROOM bytes. This is the guarantee that also
+ 	 * native XDP provides, thus we need to do it here as well.
+ 	 */
+ 	if (skb_is_nonlinear(skb) ||
+ 	    skb_headroom(skb) < XDP_PACKET_HEADROOM) {
+ 		int hroom = XDP_PACKET_HEADROOM - skb_headroom(skb);
+ 		int troom = skb->tail + skb->data_len - skb->end;
+ 
+ 		/* In case we have to go down the path and also linearize,
+ 		 * then lets do the pskb_expand_head() work just once here.
+ 		 */
+ 		if (pskb_expand_head(skb,
+ 				     hroom > 0 ? ALIGN(hroom, NET_SKB_PAD) : 0,
+ 				     troom > 0 ? troom + 128 : 0, GFP_ATOMIC))
+ 			goto do_drop;
+ 		if (skb_linearize(skb))
+ 			goto do_drop;
+ 	}
+ 
+ 	/* The XDP program wants to see the packet starting at the MAC
+ 	 * header.
+ 	 */
+ 	mac_len = skb->data - skb_mac_header(skb);
+ 	hlen = skb_headlen(skb) + mac_len;
+ 	xdp.data = skb->data - mac_len;
+ 	xdp.data_meta = xdp.data;
+ 	xdp.data_end = xdp.data + hlen;
+ 	xdp.data_hard_start = skb->data - skb_headroom(skb);
+ 	orig_data = xdp.data;
+ 
+ 	rxqueue = netif_get_rxqueue(skb);
+ 	xdp.rxq = &rxqueue->xdp_rxq;
+ 
+ 	act = bpf_prog_run_xdp(xdp_prog, &xdp);
+ 
+ 	off = xdp.data - orig_data;
+ 	if (off > 0)
+ 		__skb_pull(skb, off);
+ 	else if (off < 0)
+ 		__skb_push(skb, -off);
+ 	skb->mac_header += off;
+ 
+ 	switch (act) {
+ 	case XDP_REDIRECT:
+ 	case XDP_TX:
+ 		__skb_push(skb, mac_len);
+ 		break;
+ 	case XDP_PASS:
+ 		metalen = xdp.data - xdp.data_meta;
+ 		if (metalen)
+ 			skb_metadata_set(skb, metalen);
+ 		break;
+ 	default:
+ 		bpf_warn_invalid_xdp_action(act);
+ 		/* fall through */
+ 	case XDP_ABORTED:
+ 		trace_xdp_exception(skb->dev, xdp_prog, act);
+ 		/* fall through */
+ 	case XDP_DROP:
+ 	do_drop:
+ 		kfree_skb(skb);
+ 		break;
+ 	}
+ 
+ 	return act;
+ }
+ 
+ /* When doing generic XDP we have to bypass the qdisc layer and the
+  * network taps in order to match in-driver-XDP behavior.
+  */
+ void generic_xdp_tx(struct sk_buff *skb, struct bpf_prog *xdp_prog)
+ {
+ 	struct net_device *dev = skb->dev;
+ 	struct netdev_queue *txq;
+ 	bool free_skb = true;
+ 	int cpu, rc;
+ 
+ 	txq = netdev_pick_tx(dev, skb, NULL);
+ 	cpu = smp_processor_id();
+ 	HARD_TX_LOCK(dev, txq, cpu);
+ 	if (!netif_xmit_stopped(txq)) {
+ 		rc = netdev_start_xmit(skb, dev, txq, 0);
+ 		if (dev_xmit_complete(rc))
+ 			free_skb = false;
+ 	}
+ 	HARD_TX_UNLOCK(dev, txq);
+ 	if (free_skb) {
+ 		trace_xdp_exception(dev, xdp_prog, XDP_TX);
+ 		kfree_skb(skb);
+ 	}
+ }
+ EXPORT_SYMBOL_GPL(generic_xdp_tx);
+ 
+ static struct static_key generic_xdp_needed __read_mostly;
+ 
+ int do_xdp_generic(struct bpf_prog *xdp_prog, struct sk_buff *skb)
+ {
+ 	if (xdp_prog) {
+ 		u32 act = netif_receive_generic_xdp(skb, xdp_prog);
+ 		int err;
+ 
+ 		if (act != XDP_PASS) {
+ 			switch (act) {
+ 			case XDP_REDIRECT:
+ 				err = xdp_do_generic_redirect(skb->dev, skb,
+ 							      xdp_prog);
+ 				if (err)
+ 					goto out_redir;
+ 			/* fallthru to submit skb */
+ 			case XDP_TX:
+ 				generic_xdp_tx(skb, xdp_prog);
+ 				break;
+ 			}
+ 			return XDP_DROP;
+ 		}
+ 	}
+ 	return XDP_PASS;
+ out_redir:
+ 	kfree_skb(skb);
+ 	return XDP_DROP;
+ }
+ EXPORT_SYMBOL_GPL(do_xdp_generic);
+ 
++>>>>>>> e817f85652c1 (xdp: generic XDP handling of xdp_rxq_info)
  static int netif_rx_internal(struct sk_buff *skb)
  {
  	int ret;
@@@ -7472,7 -7616,6 +7638,10 @@@ void netif_stacked_transfer_operstate(c
  }
  EXPORT_SYMBOL(netif_stacked_transfer_operstate);
  
++<<<<<<< HEAD
 +#ifdef CONFIG_RPS
++=======
++>>>>>>> e817f85652c1 (xdp: generic XDP handling of xdp_rxq_info)
  static int netif_alloc_rx_queues(struct net_device *dev)
  {
  	unsigned int i, count = dev->num_rx_queues;
@@@ -8068,7 -8224,6 +8266,10 @@@ struct net_device *alloc_netdev_mqs(in
  		return NULL;
  	}
  
++<<<<<<< HEAD
 +#ifdef CONFIG_RPS
++=======
++>>>>>>> e817f85652c1 (xdp: generic XDP handling of xdp_rxq_info)
  	if (rxqs < 1) {
  		pr_err("alloc_netdev: Unable to allocate device with zero RX queues\n");
  		return NULL;
@@@ -8138,14 -8284,13 +8338,16 @@@
  	if (netif_alloc_netdev_queues(dev))
  		goto free_all;
  
++<<<<<<< HEAD
 +#ifdef CONFIG_RPS
++=======
++>>>>>>> e817f85652c1 (xdp: generic XDP handling of xdp_rxq_info)
  	dev->num_rx_queues = rxqs;
  	dev->real_num_rx_queues = rxqs;
  	if (netif_alloc_rx_queues(dev))
  		goto free_all;
- #endif
  
  	strcpy(dev->name, name);
 -	dev->name_assign_type = name_assign_type;
  	dev->group = INIT_NETDEV_GROUP;
  	if (!dev->ethtool_ops)
  		dev->ethtool_ops = &default_ethtool_ops;
@@@ -8179,9 -8326,7 +8381,13 @@@ void free_netdev(struct net_device *dev
  
  	might_sleep();
  	netif_free_tx_queues(dev);
++<<<<<<< HEAD
 +#ifdef CONFIG_RPS
 +	kvfree(dev->_rx);
 +#endif
++=======
+ 	netif_free_rx_queues(dev);
++>>>>>>> e817f85652c1 (xdp: generic XDP handling of xdp_rxq_info)
  
  	kfree(rcu_dereference_protected(dev->ingress_queue, 1));
  
diff --git a/include/linux/netdevice.h b/include/linux/netdevice.h
index 63a3866ea81e..f1c05eb869bf 100644
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@ -47,6 +47,7 @@
 #include <net/dcbnl.h>
 #endif
 #include <net/netprio_cgroup.h>
+#include <net/xdp.h>
 
 #include <linux/netdev_features.h>
 #include <linux/neighbour.h>
@@ -734,6 +735,7 @@ struct netdev_rx_queue {
 	struct rps_dev_flow_table __rcu	*rps_flow_table;
 	struct kobject			kobj;
 	struct net_device		*dev;
+	struct xdp_rxq_info		xdp_rxq;
 } ____cacheline_aligned_in_smp;
 #endif /* CONFIG_RPS */
 
* Unmerged path net/core/dev.c
