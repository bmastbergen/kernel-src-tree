IB/mlx5: Use uid as part of PD commands

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
commit-author Yishai Hadas <yishaih@mellanox.com>
commit a1069c1c75d5be4d7fed354a33e5590de27ae0f3
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/a1069c1c.failed

Use uid as part of PD commands so that the firmware can manage the
PD object in a secured way.

For example when a QP is created its uid must match the CQ uid which it
uses.

Next patches in this series will use the uid from the PD, then will come
a patch to set the uid on the PD so that all objects will be properly
work in one change.

	Signed-off-by: Yishai Hadas <yishaih@mellanox.com>
	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit a1069c1c75d5be4d7fed354a33e5590de27ae0f3)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/cmd.c
#	drivers/infiniband/hw/mlx5/cmd.h
diff --cc drivers/infiniband/hw/mlx5/cmd.c
index 20fa395e65e0,67f16e900445..000000000000
--- a/drivers/infiniband/hw/mlx5/cmd.c
+++ b/drivers/infiniband/hw/mlx5/cmd.c
@@@ -81,3 -81,130 +81,133 @@@ int mlx5_cmd_modify_cong_params(struct 
  
  	return mlx5_cmd_exec(dev, in, in_size, out, sizeof(out));
  }
++<<<<<<< HEAD
++=======
+ 
+ int mlx5_cmd_alloc_memic(struct mlx5_memic *memic, phys_addr_t *addr,
+ 			  u64 length, u32 alignment)
+ {
+ 	struct mlx5_core_dev *dev = memic->dev;
+ 	u64 num_memic_hw_pages = MLX5_CAP_DEV_MEM(dev, memic_bar_size)
+ 					>> PAGE_SHIFT;
+ 	u64 hw_start_addr = MLX5_CAP64_DEV_MEM(dev, memic_bar_start_addr);
+ 	u32 max_alignment = MLX5_CAP_DEV_MEM(dev, log_max_memic_addr_alignment);
+ 	u32 num_pages = DIV_ROUND_UP(length, PAGE_SIZE);
+ 	u32 out[MLX5_ST_SZ_DW(alloc_memic_out)] = {};
+ 	u32 in[MLX5_ST_SZ_DW(alloc_memic_in)] = {};
+ 	u32 mlx5_alignment;
+ 	u64 page_idx = 0;
+ 	int ret = 0;
+ 
+ 	if (!length || (length & MLX5_MEMIC_ALLOC_SIZE_MASK))
+ 		return -EINVAL;
+ 
+ 	/* mlx5 device sets alignment as 64*2^driver_value
+ 	 * so normalizing is needed.
+ 	 */
+ 	mlx5_alignment = (alignment < MLX5_MEMIC_BASE_ALIGN) ? 0 :
+ 			 alignment - MLX5_MEMIC_BASE_ALIGN;
+ 	if (mlx5_alignment > max_alignment)
+ 		return -EINVAL;
+ 
+ 	MLX5_SET(alloc_memic_in, in, opcode, MLX5_CMD_OP_ALLOC_MEMIC);
+ 	MLX5_SET(alloc_memic_in, in, range_size, num_pages * PAGE_SIZE);
+ 	MLX5_SET(alloc_memic_in, in, memic_size, length);
+ 	MLX5_SET(alloc_memic_in, in, log_memic_addr_alignment,
+ 		 mlx5_alignment);
+ 
+ 	while (page_idx < num_memic_hw_pages) {
+ 		spin_lock(&memic->memic_lock);
+ 		page_idx = bitmap_find_next_zero_area(memic->memic_alloc_pages,
+ 						      num_memic_hw_pages,
+ 						      page_idx,
+ 						      num_pages, 0);
+ 
+ 		if (page_idx < num_memic_hw_pages)
+ 			bitmap_set(memic->memic_alloc_pages,
+ 				   page_idx, num_pages);
+ 
+ 		spin_unlock(&memic->memic_lock);
+ 
+ 		if (page_idx >= num_memic_hw_pages)
+ 			break;
+ 
+ 		MLX5_SET64(alloc_memic_in, in, range_start_addr,
+ 			   hw_start_addr + (page_idx * PAGE_SIZE));
+ 
+ 		ret = mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));
+ 		if (ret) {
+ 			spin_lock(&memic->memic_lock);
+ 			bitmap_clear(memic->memic_alloc_pages,
+ 				     page_idx, num_pages);
+ 			spin_unlock(&memic->memic_lock);
+ 
+ 			if (ret == -EAGAIN) {
+ 				page_idx++;
+ 				continue;
+ 			}
+ 
+ 			return ret;
+ 		}
+ 
+ 		*addr = pci_resource_start(dev->pdev, 0) +
+ 			MLX5_GET64(alloc_memic_out, out, memic_start_addr);
+ 
+ 		return 0;
+ 	}
+ 
+ 	return -ENOMEM;
+ }
+ 
+ int mlx5_cmd_dealloc_memic(struct mlx5_memic *memic, u64 addr, u64 length)
+ {
+ 	struct mlx5_core_dev *dev = memic->dev;
+ 	u64 hw_start_addr = MLX5_CAP64_DEV_MEM(dev, memic_bar_start_addr);
+ 	u32 num_pages = DIV_ROUND_UP(length, PAGE_SIZE);
+ 	u32 out[MLX5_ST_SZ_DW(dealloc_memic_out)] = {0};
+ 	u32 in[MLX5_ST_SZ_DW(dealloc_memic_in)] = {0};
+ 	u64 start_page_idx;
+ 	int err;
+ 
+ 	addr -= pci_resource_start(dev->pdev, 0);
+ 	start_page_idx = (addr - hw_start_addr) >> PAGE_SHIFT;
+ 
+ 	MLX5_SET(dealloc_memic_in, in, opcode, MLX5_CMD_OP_DEALLOC_MEMIC);
+ 	MLX5_SET64(dealloc_memic_in, in, memic_start_addr, addr);
+ 	MLX5_SET(dealloc_memic_in, in, memic_size, length);
+ 
+ 	err =  mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));
+ 
+ 	if (!err) {
+ 		spin_lock(&memic->memic_lock);
+ 		bitmap_clear(memic->memic_alloc_pages,
+ 			     start_page_idx, num_pages);
+ 		spin_unlock(&memic->memic_lock);
+ 	}
+ 
+ 	return err;
+ }
+ 
+ int mlx5_cmd_query_ext_ppcnt_counters(struct mlx5_core_dev *dev, void *out)
+ {
+ 	u32 in[MLX5_ST_SZ_DW(ppcnt_reg)] = {};
+ 	int sz = MLX5_ST_SZ_BYTES(ppcnt_reg);
+ 
+ 	MLX5_SET(ppcnt_reg, in, local_port, 1);
+ 
+ 	MLX5_SET(ppcnt_reg, in, grp, MLX5_ETHERNET_EXTENDED_COUNTERS_GROUP);
+ 	return  mlx5_core_access_reg(dev, in, sz, out, sz, MLX5_REG_PPCNT,
+ 				     0, 0);
+ }
+ 
+ void mlx5_cmd_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn, u16 uid)
+ {
+ 	u32 out[MLX5_ST_SZ_DW(dealloc_pd_out)] = {};
+ 	u32 in[MLX5_ST_SZ_DW(dealloc_pd_in)]   = {};
+ 
+ 	MLX5_SET(dealloc_pd_in, in, opcode, MLX5_CMD_OP_DEALLOC_PD);
+ 	MLX5_SET(dealloc_pd_in, in, pd, pdn);
+ 	MLX5_SET(dealloc_pd_in, in, uid, uid);
+ 	mlx5_cmd_exec(dev, in, sizeof(in), out, sizeof(out));
+ }
++>>>>>>> a1069c1c75d5 (IB/mlx5: Use uid as part of PD commands)
diff --cc drivers/infiniband/hw/mlx5/cmd.h
index 802f939e52b9,6df031d41a8f..000000000000
--- a/drivers/infiniband/hw/mlx5/cmd.h
+++ b/drivers/infiniband/hw/mlx5/cmd.h
@@@ -40,6 -41,11 +40,13 @@@ int mlx5_cmd_dump_fill_mkey(struct mlx5
  int mlx5_cmd_null_mkey(struct mlx5_core_dev *dev, u32 *null_mkey);
  int mlx5_cmd_query_cong_params(struct mlx5_core_dev *dev, int cong_point,
  			       void *out, int out_size);
 -int mlx5_cmd_query_ext_ppcnt_counters(struct mlx5_core_dev *dev, void *out);
  int mlx5_cmd_modify_cong_params(struct mlx5_core_dev *mdev,
  				void *in, int in_size);
++<<<<<<< HEAD
++=======
+ int mlx5_cmd_alloc_memic(struct mlx5_memic *memic, phys_addr_t *addr,
+ 			 u64 length, u32 alignment);
+ int mlx5_cmd_dealloc_memic(struct mlx5_memic *memic, u64 addr, u64 length);
+ void mlx5_cmd_dealloc_pd(struct mlx5_core_dev *dev, u32 pdn, u16 uid);
++>>>>>>> a1069c1c75d5 (IB/mlx5: Use uid as part of PD commands)
  #endif /* MLX5_IB_CMD_H */
* Unmerged path drivers/infiniband/hw/mlx5/cmd.c
* Unmerged path drivers/infiniband/hw/mlx5/cmd.h
diff --git a/drivers/infiniband/hw/mlx5/main.c b/drivers/infiniband/hw/mlx5/main.c
index b529cb4f76e1..5016f9c6fe84 100644
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@ -2205,21 +2205,29 @@ static struct ib_pd *mlx5_ib_alloc_pd(struct ib_device *ibdev,
 	struct mlx5_ib_alloc_pd_resp resp;
 	struct mlx5_ib_pd *pd;
 	int err;
+	u32 out[MLX5_ST_SZ_DW(alloc_pd_out)] = {};
+	u32 in[MLX5_ST_SZ_DW(alloc_pd_in)]   = {};
+	u16 uid = 0;
 
 	pd = kmalloc(sizeof(*pd), GFP_KERNEL);
 	if (!pd)
 		return ERR_PTR(-ENOMEM);
 
-	err = mlx5_core_alloc_pd(to_mdev(ibdev)->mdev, &pd->pdn);
+	MLX5_SET(alloc_pd_in, in, opcode, MLX5_CMD_OP_ALLOC_PD);
+	MLX5_SET(alloc_pd_in, in, uid, uid);
+	err = mlx5_cmd_exec(to_mdev(ibdev)->mdev, in, sizeof(in),
+			    out, sizeof(out));
 	if (err) {
 		kfree(pd);
 		return ERR_PTR(err);
 	}
 
+	pd->pdn = MLX5_GET(alloc_pd_out, out, pd);
+	pd->uid = uid;
 	if (context) {
 		resp.pdn = pd->pdn;
 		if (ib_copy_to_udata(udata, &resp, sizeof(resp))) {
-			mlx5_core_dealloc_pd(to_mdev(ibdev)->mdev, pd->pdn);
+			mlx5_cmd_dealloc_pd(to_mdev(ibdev)->mdev, pd->pdn, uid);
 			kfree(pd);
 			return ERR_PTR(-EFAULT);
 		}
@@ -2233,7 +2241,7 @@ static int mlx5_ib_dealloc_pd(struct ib_pd *pd)
 	struct mlx5_ib_dev *mdev = to_mdev(pd->device);
 	struct mlx5_ib_pd *mpd = to_mpd(pd);
 
-	mlx5_core_dealloc_pd(mdev->mdev, mpd->pdn);
+	mlx5_cmd_dealloc_pd(mdev->mdev, mpd->pdn, mpd->uid);
 	kfree(mpd);
 
 	return 0;
diff --git a/drivers/infiniband/hw/mlx5/mlx5_ib.h b/drivers/infiniband/hw/mlx5/mlx5_ib.h
index 4d12ef8ba98b..a283298d8649 100644
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -135,6 +135,7 @@ static inline struct mlx5_ib_ucontext *to_mucontext(struct ib_ucontext *ibuconte
 struct mlx5_ib_pd {
 	struct ib_pd		ibpd;
 	u32			pdn;
+	u16			uid;
 };
 
 #define MLX5_IB_FLOW_MCAST_PRIO		(MLX5_BY_PASS_NUM_PRIOS - 1)
