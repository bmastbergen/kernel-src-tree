vfio/type1: Limit DMA mappings per container

jira LE-1907
cve CVE-2019-3882
Rebuild_History Non-Buildable kernel-3.10.0-1062.el7
Rebuild_CHGLOG: - [vfio] type1: Limit DMA mappings per container (Alex Williamson) [1695589] {CVE-2019-3882}
Rebuild_FUZZ: 93.98%
commit-author Alex Williamson <alex.williamson@redhat.com>
commit 492855939bdb59c6f947b0b5b44af9ad82b7e38c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1062.el7/49285593.failed

Memory backed DMA mappings are accounted against a user's locked
memory limit, including multiple mappings of the same memory.  This
accounting bounds the number of such mappings that a user can create.
However, DMA mappings that are not backed by memory, such as DMA
mappings of device MMIO via mmaps, do not make use of page pinning
and therefore do not count against the user's locked memory limit.
These mappings still consume memory, but the memory is not well
associated to the process for the purpose of oom killing a task.

To add bounding on this use case, we introduce a limit to the total
number of concurrent DMA mappings that a user is allowed to create.
This limit is exposed as a tunable module option where the default
value of 64K is expected to be well in excess of any reasonable use
case (a large virtual machine configuration would typically only make
use of tens of concurrent mappings).

This fixes CVE-2019-3882.

	Reviewed-by: Eric Auger <eric.auger@redhat.com>
	Tested-by: Eric Auger <eric.auger@redhat.com>
	Reviewed-by: Peter Xu <peterx@redhat.com>
	Reviewed-by: Cornelia Huck <cohuck@redhat.com>
	Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
(cherry picked from commit 492855939bdb59c6f947b0b5b44af9ad82b7e38c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/vfio/vfio_iommu_type1.c
diff --cc drivers/vfio/vfio_iommu_type1.c
index 27ec46bc22aa,d0f731c9920a..000000000000
--- a/drivers/vfio/vfio_iommu_type1.c
+++ b/drivers/vfio/vfio_iommu_type1.c
@@@ -61,7 -69,9 +66,13 @@@ struct vfio_iommu 
  	struct mutex		lock;
  	struct rb_root		dma_list;
  	struct blocking_notifier_head notifier;
++<<<<<<< HEAD
 +	bool v2;
++=======
+ 	unsigned int		dma_avail;
+ 	bool			v2;
+ 	bool			nesting;
++>>>>>>> 492855939bdb (vfio/type1: Limit DMA mappings per container)
  };
  
  struct vfio_domain {
@@@ -1398,10 -1580,24 +1416,11 @@@ static void *vfio_iommu_type1_open(unsi
  	if (!iommu)
  		return ERR_PTR(-ENOMEM);
  
 -	switch (arg) {
 -	case VFIO_TYPE1_IOMMU:
 -		break;
 -	case VFIO_TYPE1_NESTING_IOMMU:
 -		iommu->nesting = true;
 -		/* fall through */
 -	case VFIO_TYPE1v2_IOMMU:
 -		iommu->v2 = true;
 -		break;
 -	default:
 -		kfree(iommu);
 -		return ERR_PTR(-EINVAL);
 -	}
 -
  	INIT_LIST_HEAD(&iommu->domain_list);
  	iommu->dma_list = RB_ROOT;
+ 	iommu->dma_avail = dma_entry_limit;
  	mutex_init(&iommu->lock);
 +	iommu->v2 = (arg == VFIO_TYPE1v2_IOMMU);
  	BLOCKING_INIT_NOTIFIER_HEAD(&iommu->notifier);
  
  	return iommu;
* Unmerged path drivers/vfio/vfio_iommu_type1.c
