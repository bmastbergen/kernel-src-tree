net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [net] sched: avoid ndo_setup_tc calls for TC_SETUP_CLS* (Ivan Vecera) [1572720]
Rebuild_FUZZ: 95.15%
commit-author Jiri Pirko <jiri@mellanox.com>
commit 8d26d5636dff9fca30816579910aaa9a55b4d96d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/8d26d563.failed

All drivers are converted to use block callbacks for TC_SETUP_CLS*.
So it is now safe to remove the calls to ndo_setup_tc from cls_*

	Signed-off-by: Jiri Pirko <jiri@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 8d26d5636dff9fca30816579910aaa9a55b4d96d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_main.c
#	drivers/net/ethernet/netronome/nfp/bpf/main.c
#	drivers/net/ethernet/netronome/nfp/flower/offload.c
#	net/dsa/slave.c
#	net/sched/cls_bpf.c
#	net/sched/cls_flower.c
#	net/sched/cls_matchall.c
#	net/sched/cls_u32.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index f9f9996c2b9e,560b208c0483..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@@ -2940,8 -3141,8 +2940,13 @@@ static int mlx5e_setup_tc(struct net_de
  {
  	switch (type) {
  #ifdef CONFIG_MLX5_ESWITCH
++<<<<<<< HEAD
 +	case TC_SETUP_CLSFLOWER:
 +		return mlx5e_setup_tc_cls_flower(dev, type_data);
++=======
+ 	case TC_SETUP_BLOCK:
+ 		return mlx5e_setup_tc_block(dev, type_data);
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  #endif
  	case TC_SETUP_MQPRIO:
  		return mlx5e_setup_tc_mqprio(dev, type_data);
diff --cc drivers/net/ethernet/netronome/nfp/bpf/main.c
index 4ca14182b178,fa0ac90ed956..000000000000
--- a/drivers/net/ethernet/netronome/nfp/bpf/main.c
+++ b/drivers/net/ethernet/netronome/nfp/bpf/main.c
@@@ -117,23 -117,53 +117,30 @@@ static void nfp_bpf_vnic_free(struct nf
  static int nfp_bpf_setup_tc(struct nfp_app *app, struct net_device *netdev,
  			    enum tc_setup_type type, void *type_data)
  {
++<<<<<<< HEAD
 +#if 0 /* Not in RHEL7 */
 +	struct nfp_net *nn = netdev_priv(netdev);
 +
 +	if (TC_H_MAJ(handle) != TC_H_MAJ(TC_H_INGRESS))
++=======
+ 	switch (type) {
+ 	case TC_SETUP_BLOCK:
+ 		return nfp_bpf_setup_tc_block(netdev, type_data);
+ 	default:
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
 +		return -EOPNOTSUPP;
 +	if (proto != htons(ETH_P_ALL))
  		return -EOPNOTSUPP;
 +
 +	if (tc->type == TC_SETUP_CLSBPF && nfp_net_ebpf_capable(nn)) {
 +		if (!nn->dp.bpf_offload_xdp)
 +			return nfp_net_bpf_offload(nn, tc->cls_bpf);
 +		else
 +			return -EBUSY;
  	}
 +#endif
 +
 +	return -EINVAL;
  }
  
  static bool nfp_bpf_tc_busy(struct nfp_app *app, struct nfp_net *nn)
diff --cc drivers/net/ethernet/netronome/nfp/flower/offload.c
index 0e039508dc42,c47753fdb55b..000000000000
--- a/drivers/net/ethernet/netronome/nfp/flower/offload.c
+++ b/drivers/net/ethernet/netronome/nfp/flower/offload.c
@@@ -463,19 -465,50 +463,26 @@@ nfp_flower_repr_offload(struct nfp_app 
  	return -EOPNOTSUPP;
  }
  
 -static int nfp_flower_setup_tc_block_cb(enum tc_setup_type type,
 -					void *type_data, void *cb_priv)
 +int nfp_flower_setup_tc(struct nfp_app *app, struct net_device *netdev,
 +			enum tc_setup_type type, void *type_data)
  {
 -	struct nfp_net *nn = cb_priv;
++<<<<<<< HEAD
 +	struct tc_cls_flower_offload *cls_flower = type_data;
  
 +	if (TC_H_MAJ(cls_flower->common.handle) != TC_H_MAJ(TC_H_INGRESS))
++=======
+ 	switch (type) {
 -	case TC_SETUP_CLSFLOWER:
 -		return nfp_flower_repr_offload(nn->app, nn->port->netdev,
 -					       type_data);
++	case TC_SETUP_BLOCK:
++		return nfp_flower_setup_tc_block(netdev, type_data);
+ 	default:
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  		return -EOPNOTSUPP;
 -	}
 -}
 -
 -static int nfp_flower_setup_tc_block(struct net_device *netdev,
 -				     struct tc_block_offload *f)
 -{
 -	struct nfp_net *nn = netdev_priv(netdev);
  
 -	if (f->binder_type != TCF_BLOCK_BINDER_TYPE_CLSACT_INGRESS)
 +	if (!eth_proto_is_802_3(cls_flower->common.protocol))
  		return -EOPNOTSUPP;
  
 -	switch (f->command) {
 -	case TC_BLOCK_BIND:
 -		return tcf_block_cb_register(f->block,
 -					     nfp_flower_setup_tc_block_cb,
 -					     nn, nn);
 -	case TC_BLOCK_UNBIND:
 -		tcf_block_cb_unregister(f->block,
 -					nfp_flower_setup_tc_block_cb,
 -					nn);
 -		return 0;
 -	default:
 -		return -EOPNOTSUPP;
 -	}
 -}
 +	if (type != TC_SETUP_CLSFLOWER)
 +		return -EINVAL;
  
 -int nfp_flower_setup_tc(struct nfp_app *app, struct net_device *netdev,
 -			enum tc_setup_type type, void *type_data)
 -{
 -	switch (type) {
 -	case TC_SETUP_BLOCK:
 -		return nfp_flower_setup_tc_block(netdev, type_data);
 -	default:
 -		return -EOPNOTSUPP;
 -	}
 +	return nfp_flower_repr_offload(app, netdev, cls_flower);
  }
diff --cc net/dsa/slave.c
index f3efc3546e20,d0ae7010ea45..000000000000
--- a/net/dsa/slave.c
+++ b/net/dsa/slave.c
@@@ -290,12 -554,366 +290,366 @@@ static int dsa_slave_get_sset_count(str
  	return -EOPNOTSUPP;
  }
  
++<<<<<<< HEAD
++=======
+ static void dsa_slave_get_wol(struct net_device *dev, struct ethtool_wolinfo *w)
+ {
+ 	struct dsa_port *dp = dsa_slave_to_port(dev);
+ 	struct dsa_switch *ds = dp->ds;
+ 
+ 	if (ds->ops->get_wol)
+ 		ds->ops->get_wol(ds, dp->index, w);
+ }
+ 
+ static int dsa_slave_set_wol(struct net_device *dev, struct ethtool_wolinfo *w)
+ {
+ 	struct dsa_port *dp = dsa_slave_to_port(dev);
+ 	struct dsa_switch *ds = dp->ds;
+ 	int ret = -EOPNOTSUPP;
+ 
+ 	if (ds->ops->set_wol)
+ 		ret = ds->ops->set_wol(ds, dp->index, w);
+ 
+ 	return ret;
+ }
+ 
+ static int dsa_slave_set_eee(struct net_device *dev, struct ethtool_eee *e)
+ {
+ 	struct dsa_port *dp = dsa_slave_to_port(dev);
+ 	struct dsa_switch *ds = dp->ds;
+ 	int ret;
+ 
+ 	/* Port's PHY and MAC both need to be EEE capable */
+ 	if (!dev->phydev)
+ 		return -ENODEV;
+ 
+ 	if (!ds->ops->set_mac_eee)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = ds->ops->set_mac_eee(ds, dp->index, e);
+ 	if (ret)
+ 		return ret;
+ 
+ 	if (e->eee_enabled) {
+ 		ret = phy_init_eee(dev->phydev, 0);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	return phy_ethtool_set_eee(dev->phydev, e);
+ }
+ 
+ static int dsa_slave_get_eee(struct net_device *dev, struct ethtool_eee *e)
+ {
+ 	struct dsa_port *dp = dsa_slave_to_port(dev);
+ 	struct dsa_switch *ds = dp->ds;
+ 	int ret;
+ 
+ 	/* Port's PHY and MAC both need to be EEE capable */
+ 	if (!dev->phydev)
+ 		return -ENODEV;
+ 
+ 	if (!ds->ops->get_mac_eee)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = ds->ops->get_mac_eee(ds, dp->index, e);
+ 	if (ret)
+ 		return ret;
+ 
+ 	return phy_ethtool_get_eee(dev->phydev, e);
+ }
+ 
+ #ifdef CONFIG_NET_POLL_CONTROLLER
+ static int dsa_slave_netpoll_setup(struct net_device *dev,
+ 				   struct netpoll_info *ni)
+ {
+ 	struct net_device *master = dsa_slave_to_master(dev);
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct netpoll *netpoll;
+ 	int err = 0;
+ 
+ 	netpoll = kzalloc(sizeof(*netpoll), GFP_KERNEL);
+ 	if (!netpoll)
+ 		return -ENOMEM;
+ 
+ 	err = __netpoll_setup(netpoll, master);
+ 	if (err) {
+ 		kfree(netpoll);
+ 		goto out;
+ 	}
+ 
+ 	p->netpoll = netpoll;
+ out:
+ 	return err;
+ }
+ 
+ static void dsa_slave_netpoll_cleanup(struct net_device *dev)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct netpoll *netpoll = p->netpoll;
+ 
+ 	if (!netpoll)
+ 		return;
+ 
+ 	p->netpoll = NULL;
+ 
+ 	__netpoll_free_async(netpoll);
+ }
+ 
+ static void dsa_slave_poll_controller(struct net_device *dev)
+ {
+ }
+ #endif
+ 
+ static int dsa_slave_get_phys_port_name(struct net_device *dev,
+ 					char *name, size_t len)
+ {
+ 	struct dsa_port *dp = dsa_slave_to_port(dev);
+ 
+ 	if (snprintf(name, len, "p%d", dp->index) >= len)
+ 		return -EINVAL;
+ 
+ 	return 0;
+ }
+ 
+ static struct dsa_mall_tc_entry *
+ dsa_slave_mall_tc_entry_find(struct net_device *dev, unsigned long cookie)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 
+ 	list_for_each_entry(mall_tc_entry, &p->mall_tc_list, list)
+ 		if (mall_tc_entry->cookie == cookie)
+ 			return mall_tc_entry;
+ 
+ 	return NULL;
+ }
+ 
+ static int dsa_slave_add_cls_matchall(struct net_device *dev,
+ 				      struct tc_cls_matchall_offload *cls,
+ 				      bool ingress)
+ {
+ 	struct dsa_port *dp = dsa_slave_to_port(dev);
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 	__be16 protocol = cls->common.protocol;
+ 	struct net *net = dev_net(dev);
+ 	struct dsa_switch *ds = dp->ds;
+ 	struct net_device *to_dev;
+ 	const struct tc_action *a;
+ 	struct dsa_port *to_dp;
+ 	int err = -EOPNOTSUPP;
+ 	LIST_HEAD(actions);
+ 	int ifindex;
+ 
+ 	if (!ds->ops->port_mirror_add)
+ 		return err;
+ 
+ 	if (!tcf_exts_has_one_action(cls->exts))
+ 		return err;
+ 
+ 	tcf_exts_to_list(cls->exts, &actions);
+ 	a = list_first_entry(&actions, struct tc_action, list);
+ 
+ 	if (is_tcf_mirred_egress_mirror(a) && protocol == htons(ETH_P_ALL)) {
+ 		struct dsa_mall_mirror_tc_entry *mirror;
+ 
+ 		ifindex = tcf_mirred_ifindex(a);
+ 		to_dev = __dev_get_by_index(net, ifindex);
+ 		if (!to_dev)
+ 			return -EINVAL;
+ 
+ 		if (!dsa_slave_dev_check(to_dev))
+ 			return -EOPNOTSUPP;
+ 
+ 		mall_tc_entry = kzalloc(sizeof(*mall_tc_entry), GFP_KERNEL);
+ 		if (!mall_tc_entry)
+ 			return -ENOMEM;
+ 
+ 		mall_tc_entry->cookie = cls->cookie;
+ 		mall_tc_entry->type = DSA_PORT_MALL_MIRROR;
+ 		mirror = &mall_tc_entry->mirror;
+ 
+ 		to_dp = dsa_slave_to_port(to_dev);
+ 
+ 		mirror->to_local_port = to_dp->index;
+ 		mirror->ingress = ingress;
+ 
+ 		err = ds->ops->port_mirror_add(ds, dp->index, mirror, ingress);
+ 		if (err) {
+ 			kfree(mall_tc_entry);
+ 			return err;
+ 		}
+ 
+ 		list_add_tail(&mall_tc_entry->list, &p->mall_tc_list);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static void dsa_slave_del_cls_matchall(struct net_device *dev,
+ 				       struct tc_cls_matchall_offload *cls)
+ {
+ 	struct dsa_port *dp = dsa_slave_to_port(dev);
+ 	struct dsa_mall_tc_entry *mall_tc_entry;
+ 	struct dsa_switch *ds = dp->ds;
+ 
+ 	if (!ds->ops->port_mirror_del)
+ 		return;
+ 
+ 	mall_tc_entry = dsa_slave_mall_tc_entry_find(dev, cls->cookie);
+ 	if (!mall_tc_entry)
+ 		return;
+ 
+ 	list_del(&mall_tc_entry->list);
+ 
+ 	switch (mall_tc_entry->type) {
+ 	case DSA_PORT_MALL_MIRROR:
+ 		ds->ops->port_mirror_del(ds, dp->index, &mall_tc_entry->mirror);
+ 		break;
+ 	default:
+ 		WARN_ON(1);
+ 	}
+ 
+ 	kfree(mall_tc_entry);
+ }
+ 
+ static int dsa_slave_setup_tc_cls_matchall(struct net_device *dev,
+ 					   struct tc_cls_matchall_offload *cls,
+ 					   bool ingress)
+ {
+ 	if (cls->common.chain_index)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (cls->command) {
+ 	case TC_CLSMATCHALL_REPLACE:
+ 		return dsa_slave_add_cls_matchall(dev, cls, ingress);
+ 	case TC_CLSMATCHALL_DESTROY:
+ 		dsa_slave_del_cls_matchall(dev, cls);
+ 		return 0;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int dsa_slave_setup_tc_block_cb(enum tc_setup_type type, void *type_data,
+ 				       void *cb_priv, bool ingress)
+ {
+ 	struct net_device *dev = cb_priv;
+ 
+ 	switch (type) {
+ 	case TC_SETUP_CLSMATCHALL:
+ 		return dsa_slave_setup_tc_cls_matchall(dev, type_data, ingress);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int dsa_slave_setup_tc_block_cb_ig(enum tc_setup_type type,
+ 					  void *type_data, void *cb_priv)
+ {
+ 	return dsa_slave_setup_tc_block_cb(type, type_data, cb_priv, true);
+ }
+ 
+ static int dsa_slave_setup_tc_block_cb_eg(enum tc_setup_type type,
+ 					  void *type_data, void *cb_priv)
+ {
+ 	return dsa_slave_setup_tc_block_cb(type, type_data, cb_priv, false);
+ }
+ 
+ static int dsa_slave_setup_tc_block(struct net_device *dev,
+ 				    struct tc_block_offload *f)
+ {
+ 	tc_setup_cb_t *cb;
+ 
+ 	if (f->binder_type == TCF_BLOCK_BINDER_TYPE_CLSACT_INGRESS)
+ 		cb = dsa_slave_setup_tc_block_cb_ig;
+ 	else if (f->binder_type == TCF_BLOCK_BINDER_TYPE_CLSACT_EGRESS)
+ 		cb = dsa_slave_setup_tc_block_cb_eg;
+ 	else
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (f->command) {
+ 	case TC_BLOCK_BIND:
+ 		return tcf_block_cb_register(f->block, cb, dev, dev);
+ 	case TC_BLOCK_UNBIND:
+ 		tcf_block_cb_unregister(f->block, cb, dev);
+ 		return 0;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static int dsa_slave_setup_tc(struct net_device *dev, enum tc_setup_type type,
+ 			      void *type_data)
+ {
+ 	switch (type) {
+ 	case TC_SETUP_BLOCK:
+ 		return dsa_slave_setup_tc_block(dev, type_data);
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ }
+ 
+ static void dsa_slave_get_stats64(struct net_device *dev,
+ 				  struct rtnl_link_stats64 *stats)
+ {
+ 	struct dsa_slave_priv *p = netdev_priv(dev);
+ 	struct pcpu_sw_netstats *s;
+ 	unsigned int start;
+ 	int i;
+ 
+ 	netdev_stats_to_stats64(stats, &dev->stats);
+ 	for_each_possible_cpu(i) {
+ 		u64 tx_packets, tx_bytes, rx_packets, rx_bytes;
+ 
+ 		s = per_cpu_ptr(p->stats64, i);
+ 		do {
+ 			start = u64_stats_fetch_begin_irq(&s->syncp);
+ 			tx_packets = s->tx_packets;
+ 			tx_bytes = s->tx_bytes;
+ 			rx_packets = s->rx_packets;
+ 			rx_bytes = s->rx_bytes;
+ 		} while (u64_stats_fetch_retry_irq(&s->syncp, start));
+ 
+ 		stats->tx_packets += tx_packets;
+ 		stats->tx_bytes += tx_bytes;
+ 		stats->rx_packets += rx_packets;
+ 		stats->rx_bytes += rx_bytes;
+ 	}
+ }
+ 
+ static int dsa_slave_get_rxnfc(struct net_device *dev,
+ 			       struct ethtool_rxnfc *nfc, u32 *rule_locs)
+ {
+ 	struct dsa_port *dp = dsa_slave_to_port(dev);
+ 	struct dsa_switch *ds = dp->ds;
+ 
+ 	if (!ds->ops->get_rxnfc)
+ 		return -EOPNOTSUPP;
+ 
+ 	return ds->ops->get_rxnfc(ds, dp->index, nfc, rule_locs);
+ }
+ 
+ static int dsa_slave_set_rxnfc(struct net_device *dev,
+ 			       struct ethtool_rxnfc *nfc)
+ {
+ 	struct dsa_port *dp = dsa_slave_to_port(dev);
+ 	struct dsa_switch *ds = dp->ds;
+ 
+ 	if (!ds->ops->set_rxnfc)
+ 		return -EOPNOTSUPP;
+ 
+ 	return ds->ops->set_rxnfc(ds, dp->index, nfc);
+ }
+ 
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  static const struct ethtool_ops dsa_slave_ethtool_ops = {
 +	.get_settings		= dsa_slave_get_settings,
 +	.set_settings		= dsa_slave_set_settings,
  	.get_drvinfo		= dsa_slave_get_drvinfo,
 -	.get_regs_len		= dsa_slave_get_regs_len,
 -	.get_regs		= dsa_slave_get_regs,
 -	.nway_reset		= phy_ethtool_nway_reset,
 +	.nway_reset		= dsa_slave_nway_reset,
  	.get_link		= dsa_slave_get_link,
 -	.get_eeprom_len		= dsa_slave_get_eeprom_len,
 -	.get_eeprom		= dsa_slave_get_eeprom,
 -	.set_eeprom		= dsa_slave_set_eeprom,
  	.get_strings		= dsa_slave_get_strings,
  	.get_ethtool_stats	= dsa_slave_get_ethtool_stats,
  	.get_sset_count		= dsa_slave_get_sset_count,
diff --cc net/sched/cls_bpf.c
index c7a7c00a2b7c,0f8b51061c39..000000000000
--- a/net/sched/cls_bpf.c
+++ b/net/sched/cls_bpf.c
@@@ -73,23 -132,112 +73,99 @@@ static int cls_bpf_classify(struct sk_b
  		if (ret < 0)
  			continue;
  
++<<<<<<< HEAD
++=======
+ 		break;
+ 	}
+ 	rcu_read_unlock();
+ 
+ 	return ret;
+ }
+ 
+ static bool cls_bpf_is_ebpf(const struct cls_bpf_prog *prog)
+ {
+ 	return !prog->bpf_ops;
+ }
+ 
+ static int cls_bpf_offload_cmd(struct tcf_proto *tp, struct cls_bpf_prog *prog,
+ 			       enum tc_clsbpf_command cmd)
+ {
+ 	bool addorrep = cmd == TC_CLSBPF_ADD || cmd == TC_CLSBPF_REPLACE;
+ 	struct tcf_block *block = tp->chain->block;
+ 	bool skip_sw = tc_skip_sw(prog->gen_flags);
+ 	struct tc_cls_bpf_offload cls_bpf = {};
+ 	int err;
+ 
+ 	tc_cls_common_offload_init(&cls_bpf.common, tp);
+ 	cls_bpf.command = cmd;
+ 	cls_bpf.exts = &prog->exts;
+ 	cls_bpf.prog = prog->filter;
+ 	cls_bpf.name = prog->bpf_name;
+ 	cls_bpf.exts_integrated = prog->exts_integrated;
+ 	cls_bpf.gen_flags = prog->gen_flags;
+ 
+ 	err = tc_setup_cb_call(block, NULL, TC_SETUP_CLSBPF, &cls_bpf, skip_sw);
+ 	if (addorrep) {
+ 		if (err < 0) {
+ 			cls_bpf_offload_cmd(tp, prog, TC_CLSBPF_DESTROY);
+ 			return err;
+ 		} else if (err > 0) {
+ 			prog->gen_flags |= TCA_CLS_FLAGS_IN_HW;
+ 		}
+ 	}
+ 
+ 	if (addorrep && skip_sw && !(prog->gen_flags && TCA_CLS_FLAGS_IN_HW))
+ 		return -EINVAL;
+ 
+ 	return 0;
+ }
+ 
+ static int cls_bpf_offload(struct tcf_proto *tp, struct cls_bpf_prog *prog,
+ 			   struct cls_bpf_prog *oldprog)
+ {
+ 	struct cls_bpf_prog *obj = prog;
+ 	enum tc_clsbpf_command cmd;
+ 	bool skip_sw;
+ 	int ret;
+ 
+ 	skip_sw = tc_skip_sw(prog->gen_flags) ||
+ 		(oldprog && tc_skip_sw(oldprog->gen_flags));
+ 
+ 	if (oldprog && oldprog->offloaded) {
+ 		if (!tc_skip_hw(prog->gen_flags)) {
+ 			cmd = TC_CLSBPF_REPLACE;
+ 		} else if (!tc_skip_sw(prog->gen_flags)) {
+ 			obj = oldprog;
+ 			cmd = TC_CLSBPF_DESTROY;
+ 		} else {
+ 			return -EINVAL;
+ 		}
+ 	} else {
+ 		if (tc_skip_hw(prog->gen_flags))
+ 			return skip_sw ? -EINVAL : 0;
+ 		cmd = TC_CLSBPF_ADD;
+ 	}
+ 
+ 	ret = cls_bpf_offload_cmd(tp, obj, cmd);
+ 	if (ret)
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  		return ret;
 +	}
  
 -	obj->offloaded = true;
 -	if (oldprog)
 -		oldprog->offloaded = false;
 -
 -	return 0;
 +	return -1;
  }
  
 -static void cls_bpf_stop_offload(struct tcf_proto *tp,
 -				 struct cls_bpf_prog *prog)
 -{
 -	int err;
 -
 -	if (!prog->offloaded)
 -		return;
  
 -	err = cls_bpf_offload_cmd(tp, prog, TC_CLSBPF_DESTROY);
 -	if (err) {
 -		pr_err("Stopping hardware offload failed: %d\n", err);
 -		return;
 -	}
 -
 -	prog->offloaded = false;
 +static void cls_bpf_offload(struct tcf_proto *tp, struct cls_bpf_prog *prog,
 +			    struct cls_bpf_prog *oldprog)
 +{
 +	return;
  }
  
 -static void cls_bpf_offload_update_stats(struct tcf_proto *tp,
 -					 struct cls_bpf_prog *prog)
 +static void cls_bpf_stop_offload(struct tcf_proto *tp,
 +				 struct cls_bpf_prog *prog)
  {
 -	if (!prog->offloaded)
 -		return;
 -
 -	cls_bpf_offload_cmd(tp, prog, TC_CLSBPF_STATS);
 +	return;
  }
  
  static int cls_bpf_init(struct tcf_proto *tp)
diff --cc net/sched/cls_flower.c
index 0f196b560aec,16f58abaa697..000000000000
--- a/net/sched/cls_flower.c
+++ b/net/sched/cls_flower.c
@@@ -245,17 -200,14 +245,26 @@@ static void fl_destroy_filter(struct rc
  static void fl_hw_destroy_filter(struct tcf_proto *tp, struct cls_fl_filter *f)
  {
  	struct tc_cls_flower_offload cls_flower = {};
++<<<<<<< HEAD
 +	struct net_device *dev = f->hw_dev;
 +
 +	if (!tc_can_offload(dev))
 +		return;
++=======
+ 	struct tcf_block *block = tp->chain->block;
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  
  	tc_cls_common_offload_init(&cls_flower.common, tp);
  	cls_flower.command = TC_CLSFLOWER_DESTROY;
  	cls_flower.cookie = (unsigned long) f;
 +	cls_flower.egress_dev = f->hw_dev != tp->q->dev_queue->dev;
  
++<<<<<<< HEAD
 +	__rh_call_ndo_setup_tc(dev, TC_SETUP_CLSFLOWER, &cls_flower);
++=======
+ 	tc_setup_cb_call(block, &f->exts, TC_SETUP_CLSFLOWER,
+ 			 &cls_flower, false);
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  }
  
  static int fl_hw_replace_filter(struct tcf_proto *tp,
@@@ -263,22 -215,11 +272,21 @@@
  				struct fl_flow_key *mask,
  				struct cls_fl_filter *f)
  {
- 	struct net_device *dev = tp->q->dev_queue->dev;
  	struct tc_cls_flower_offload cls_flower = {};
 -	struct tcf_block *block = tp->chain->block;
 -	bool skip_sw = tc_skip_sw(f->flags);
  	int err;
  
 +	if (!tc_can_offload(dev)) {
 +		if (tcf_exts_get_dev(dev, &f->exts, &f->hw_dev) ||
 +		    (f->hw_dev && !tc_can_offload(f->hw_dev))) {
 +			f->hw_dev = dev;
 +			return tc_skip_sw(f->flags) ? -EINVAL : 0;
 +		}
 +		dev = f->hw_dev;
 +		cls_flower.egress_dev = true;
 +	} else {
 +		f->hw_dev = dev;
 +	}
 +
  	tc_cls_common_offload_init(&cls_flower.common, tp);
  	cls_flower.command = TC_CLSFLOWER_REPLACE;
  	cls_flower.cookie = (unsigned long) f;
@@@ -287,30 -228,33 +295,48 @@@
  	cls_flower.key = &f->mkey;
  	cls_flower.exts = &f->exts;
  
++<<<<<<< HEAD
 +	err = __rh_call_ndo_setup_tc(dev, TC_SETUP_CLSFLOWER, &cls_flower);
 +	if (!err)
++=======
+ 	err = tc_setup_cb_call(block, &f->exts, TC_SETUP_CLSFLOWER,
+ 			       &cls_flower, skip_sw);
+ 	if (err < 0) {
+ 		fl_hw_destroy_filter(tp, f);
+ 		return err;
+ 	} else if (err > 0) {
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  		f->flags |= TCA_CLS_FLAGS_IN_HW;
 -	}
 -
 -	if (skip_sw && !(f->flags & TCA_CLS_FLAGS_IN_HW))
 -		return -EINVAL;
  
 +	if (tc_skip_sw(f->flags))
 +		return err;
  	return 0;
  }
  
  static void fl_hw_update_stats(struct tcf_proto *tp, struct cls_fl_filter *f)
  {
  	struct tc_cls_flower_offload cls_flower = {};
++<<<<<<< HEAD
 +	struct net_device *dev = f->hw_dev;
 +
 +	if (!tc_can_offload(dev))
 +		return;
++=======
+ 	struct tcf_block *block = tp->chain->block;
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  
  	tc_cls_common_offload_init(&cls_flower.common, tp);
  	cls_flower.command = TC_CLSFLOWER_STATS;
  	cls_flower.cookie = (unsigned long) f;
  	cls_flower.exts = &f->exts;
 +	cls_flower.egress_dev = f->hw_dev != tp->q->dev_queue->dev;
  
++<<<<<<< HEAD
 +	__rh_call_ndo_setup_tc(dev, TC_SETUP_CLSFLOWER, &cls_flower);
++=======
+ 	tc_setup_cb_call(block, &f->exts, TC_SETUP_CLSFLOWER,
+ 			 &cls_flower, false);
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  }
  
  static void __fl_delete(struct tcf_proto *tp, struct cls_fl_filter *f)
diff --cc net/sched/cls_matchall.c
index f0adbab7f7c3,70e78d74f6d3..000000000000
--- a/net/sched/cls_matchall.c
+++ b/net/sched/cls_matchall.c
@@@ -65,16 -46,31 +65,34 @@@ static void mall_destroy_rcu(struct rcu
  	struct cls_mall_head *head = container_of(rcu, struct cls_mall_head,
  						  rcu);
  
++<<<<<<< HEAD
 +	INIT_WORK(&head->work, mall_destroy_work);
 +	tcf_queue_work(&head->work);
++=======
+ 	tcf_exts_destroy(&head->exts);
+ 	kfree(head);
+ }
+ 
+ static void mall_destroy_hw_filter(struct tcf_proto *tp,
+ 				   struct cls_mall_head *head,
+ 				   unsigned long cookie)
+ {
+ 	struct tc_cls_matchall_offload cls_mall = {};
+ 	struct tcf_block *block = tp->chain->block;
+ 
+ 	tc_cls_common_offload_init(&cls_mall.common, tp);
+ 	cls_mall.command = TC_CLSMATCHALL_DESTROY;
+ 	cls_mall.cookie = cookie;
+ 
+ 	tc_setup_cb_call(block, NULL, TC_SETUP_CLSMATCHALL, &cls_mall, false);
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  }
  
  static int mall_replace_hw_filter(struct tcf_proto *tp,
  				  struct cls_mall_head *head,
  				  unsigned long cookie)
  {
- 	struct net_device *dev = tp->q->dev_queue->dev;
  	struct tc_cls_matchall_offload cls_mall = {};
 -	struct tcf_block *block = tp->chain->block;
 -	bool skip_sw = tc_skip_sw(head->flags);
  	int err;
  
  	tc_cls_common_offload_init(&cls_mall.common, tp);
@@@ -82,25 -78,19 +100,34 @@@
  	cls_mall.exts = &head->exts;
  	cls_mall.cookie = cookie;
  
++<<<<<<< HEAD
 +	err = __rh_call_ndo_setup_tc(dev, TC_SETUP_CLSMATCHALL, &cls_mall);
 +	if (!err)
++=======
+ 	err = tc_setup_cb_call(block, NULL, TC_SETUP_CLSMATCHALL,
+ 			       &cls_mall, skip_sw);
+ 	if (err < 0) {
+ 		mall_destroy_hw_filter(tp, head, cookie);
+ 		return err;
+ 	} else if (err > 0) {
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  		head->flags |= TCA_CLS_FLAGS_IN_HW;
 -	}
  
 -	if (skip_sw && !(head->flags & TCA_CLS_FLAGS_IN_HW))
 -		return -EINVAL;
 +	return err;
 +}
  
 -	return 0;
 +static void mall_destroy_hw_filter(struct tcf_proto *tp,
 +				   struct cls_mall_head *head,
 +				   unsigned long cookie)
 +{
 +	struct net_device *dev = tp->q->dev_queue->dev;
 +	struct tc_cls_matchall_offload cls_mall = {};
 +
 +	tc_cls_common_offload_init(&cls_mall.common, tp);
 +	cls_mall.command = TC_CLSMATCHALL_DESTROY;
 +	cls_mall.cookie = cookie;
 +
 +	__rh_call_ndo_setup_tc(dev, TC_SETUP_CLSMATCHALL, &cls_mall);
  }
  
  static void mall_destroy(struct tcf_proto *tp)
diff --cc net/sched/cls_u32.c
index 42766c25ee6a,9ff17159fb61..000000000000
--- a/net/sched/cls_u32.c
+++ b/net/sched/cls_u32.c
@@@ -488,69 -464,67 +488,99 @@@ static int u32_delete_key(struct tcf_pr
  
  static void u32_clear_hw_hnode(struct tcf_proto *tp, struct tc_u_hnode *h)
  {
++<<<<<<< HEAD
 +	struct net_device *dev = tp->q->dev_queue->dev;
++=======
+ 	struct tcf_block *block = tp->chain->block;
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  	struct tc_cls_u32_offload cls_u32 = {};
  
 +	if (!tc_should_offload(dev, 0))
 +		return;
 +
  	tc_cls_common_offload_init(&cls_u32.common, tp);
  	cls_u32.command = TC_CLSU32_DELETE_HNODE;
  	cls_u32.hnode.divisor = h->divisor;
  	cls_u32.hnode.handle = h->handle;
  	cls_u32.hnode.prio = h->prio;
  
++<<<<<<< HEAD
 +	__rh_call_ndo_setup_tc(dev, TC_SETUP_CLSU32, &cls_u32);
++=======
+ 	tc_setup_cb_call(block, NULL, TC_SETUP_CLSU32, &cls_u32, false);
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  }
  
  static int u32_replace_hw_hnode(struct tcf_proto *tp, struct tc_u_hnode *h,
  				u32 flags)
  {
++<<<<<<< HEAD
 +	struct net_device *dev = tp->q->dev_queue->dev;
++=======
+ 	struct tcf_block *block = tp->chain->block;
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  	struct tc_cls_u32_offload cls_u32 = {};
 -	bool skip_sw = tc_skip_sw(flags);
 -	bool offloaded = false;
  	int err;
  
 +	if (!tc_should_offload(dev, flags))
 +		return tc_skip_sw(flags) ? -EINVAL : 0;
 +
  	tc_cls_common_offload_init(&cls_u32.common, tp);
  	cls_u32.command = TC_CLSU32_NEW_HNODE;
  	cls_u32.hnode.divisor = h->divisor;
  	cls_u32.hnode.handle = h->handle;
  	cls_u32.hnode.prio = h->prio;
  
++<<<<<<< HEAD
 +	err = __rh_call_ndo_setup_tc(dev, TC_SETUP_CLSU32, &cls_u32);
 +	if (tc_skip_sw(flags))
++=======
+ 	err = tc_setup_cb_call(block, NULL, TC_SETUP_CLSU32, &cls_u32, skip_sw);
+ 	if (err < 0) {
+ 		u32_clear_hw_hnode(tp, h);
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  		return err;
 -	} else if (err > 0) {
 -		offloaded = true;
 -	}
 -
 -	if (skip_sw && !offloaded)
 -		return -EINVAL;
  
  	return 0;
  }
  
  static void u32_remove_hw_knode(struct tcf_proto *tp, u32 handle)
  {
++<<<<<<< HEAD
 +	struct net_device *dev = tp->q->dev_queue->dev;
++=======
+ 	struct tcf_block *block = tp->chain->block;
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  	struct tc_cls_u32_offload cls_u32 = {};
  
 +	if (!tc_should_offload(dev, 0))
 +		return;
 +
  	tc_cls_common_offload_init(&cls_u32.common, tp);
  	cls_u32.command = TC_CLSU32_DELETE_KNODE;
  	cls_u32.knode.handle = handle;
  
++<<<<<<< HEAD
 +	__rh_call_ndo_setup_tc(dev, TC_SETUP_CLSU32, &cls_u32);
++=======
+ 	tc_setup_cb_call(block, NULL, TC_SETUP_CLSU32, &cls_u32, false);
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  }
  
  static int u32_replace_hw_knode(struct tcf_proto *tp, struct tc_u_knode *n,
  				u32 flags)
  {
++<<<<<<< HEAD
 +	struct net_device *dev = tp->q->dev_queue->dev;
++=======
+ 	struct tcf_block *block = tp->chain->block;
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  	struct tc_cls_u32_offload cls_u32 = {};
 -	bool skip_sw = tc_skip_sw(flags);
  	int err;
  
 +	if (!tc_should_offload(dev, flags))
 +		return tc_skip_sw(flags) ? -EINVAL : 0;
 +
  	tc_cls_common_offload_init(&cls_u32.common, tp);
  	cls_u32.command = TC_CLSU32_REPLACE_KNODE;
  	cls_u32.knode.handle = n->handle;
@@@ -567,13 -541,16 +597,21 @@@
  	if (n->ht_down)
  		cls_u32.knode.link_handle = n->ht_down->handle;
  
++<<<<<<< HEAD
 +	err = __rh_call_ndo_setup_tc(dev, TC_SETUP_CLSU32, &cls_u32);
 +
 +	if (!err)
++=======
+ 	err = tc_setup_cb_call(block, NULL, TC_SETUP_CLSU32, &cls_u32, skip_sw);
+ 	if (err < 0) {
+ 		u32_remove_hw_knode(tp, n->handle);
+ 		return err;
+ 	} else if (err > 0) {
++>>>>>>> 8d26d5636dff (net: sched: avoid ndo_setup_tc calls for TC_SETUP_CLS*)
  		n->flags |= TCA_CLS_FLAGS_IN_HW;
 -	}
  
 -	if (skip_sw && !(n->flags && TCA_CLS_FLAGS_IN_HW))
 -		return -EINVAL;
 +	if (tc_skip_sw(flags))
 +		return err;
  
  	return 0;
  }
diff --git a/drivers/net/ethernet/broadcom/bnxt/bnxt.c b/drivers/net/ethernet/broadcom/bnxt/bnxt.c
index d1e80d4c22df..c80dc942ecab 100644
--- a/drivers/net/ethernet/broadcom/bnxt/bnxt.c
+++ b/drivers/net/ethernet/broadcom/bnxt/bnxt.c
@@ -7365,8 +7365,6 @@ static int bnxt_setup_tc(struct net_device *dev, enum tc_setup_type type,
 			 void *type_data)
 {
 	switch (type) {
-	case TC_SETUP_CLSFLOWER:
-		return 0; /* will be removed after conversion from ndo */
 	case TC_SETUP_BLOCK:
 		return bnxt_setup_tc_block(dev, type_data);
 	case TC_SETUP_MQPRIO: {
diff --git a/drivers/net/ethernet/broadcom/bnxt/bnxt_vfr.c b/drivers/net/ethernet/broadcom/bnxt/bnxt_vfr.c
index be4d8b510abb..1c0ed781af7f 100644
--- a/drivers/net/ethernet/broadcom/bnxt/bnxt_vfr.c
+++ b/drivers/net/ethernet/broadcom/bnxt/bnxt_vfr.c
@@ -162,8 +162,6 @@ static int bnxt_vf_rep_setup_tc(struct net_device *dev, enum tc_setup_type type,
 				void *type_data)
 {
 	switch (type) {
-	case TC_SETUP_CLSFLOWER:
-		return 0; /* will be removed after conversion from ndo */
 	case TC_SETUP_BLOCK:
 		return bnxt_vf_rep_setup_tc_block(dev, type_data);
 	default:
diff --git a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
index df3df86da091..bb4be1315cd2 100644
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c
@@ -2975,9 +2975,6 @@ static int cxgb_setup_tc(struct net_device *dev, enum tc_setup_type type,
 			 void *type_data)
 {
 	switch (type) {
-	case TC_SETUP_CLSU32:
-	case TC_SETUP_CLSFLOWER:
-		return 0; /* will be removed after conversion from ndo */
 	case TC_SETUP_BLOCK:
 		return cxgb_setup_tc_block(dev, type_data);
 	default:
diff --git a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
index 90f60ed0b65b..ff111f2ca75d 100644
--- a/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
+++ b/drivers/net/ethernet/intel/ixgbe/ixgbe_main.c
@@ -9065,8 +9065,6 @@ static int __ixgbe_setup_tc(struct net_device *dev, enum tc_setup_type type,
 			    void *type_data)
 {
 	switch (type) {
-	case TC_SETUP_CLSU32:
-		return 0; /* will be removed after conversion from ndo */
 	case TC_SETUP_BLOCK:
 		return ixgbe_setup_tc_block(dev, type_data);
 	case TC_SETUP_MQPRIO:
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_main.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
index 1f6b50ed685e..6f4e45b326d9 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.c
@@ -780,8 +780,6 @@ static int mlx5e_rep_setup_tc(struct net_device *dev, enum tc_setup_type type,
 			      void *type_data)
 {
 	switch (type) {
-	case TC_SETUP_CLSFLOWER:
-		return 0; /* will be removed after conversion from ndo */
 	case TC_SETUP_BLOCK:
 		return mlx5e_rep_setup_tc_block(dev, type_data);
 	default:
diff --git a/drivers/net/ethernet/mellanox/mlxsw/spectrum.c b/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
index 6957213219f7..3024ee0693d6 100644
--- a/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
+++ b/drivers/net/ethernet/mellanox/mlxsw/spectrum.c
@@ -1791,9 +1791,6 @@ static int mlxsw_sp_setup_tc(struct net_device *dev, enum tc_setup_type type,
 	struct mlxsw_sp_port *mlxsw_sp_port = netdev_priv(dev);
 
 	switch (type) {
-	case TC_SETUP_CLSMATCHALL:
-	case TC_SETUP_CLSFLOWER:
-		return 0; /* will be removed after conversion from ndo */
 	case TC_SETUP_BLOCK:
 		return mlxsw_sp_setup_tc_block(mlxsw_sp_port, type_data);
 	default:
* Unmerged path drivers/net/ethernet/netronome/nfp/bpf/main.c
* Unmerged path drivers/net/ethernet/netronome/nfp/flower/offload.c
* Unmerged path net/dsa/slave.c
* Unmerged path net/sched/cls_bpf.c
* Unmerged path net/sched/cls_flower.c
* Unmerged path net/sched/cls_matchall.c
* Unmerged path net/sched/cls_u32.c
