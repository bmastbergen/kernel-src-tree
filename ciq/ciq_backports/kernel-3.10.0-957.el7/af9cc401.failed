ceph: invalidate pages that beyond EOF in ceph_writepages_start()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Yan, Zheng <zyan@redhat.com>
commit af9cc401ce7452f9d965ba4553d8ffe7f0ed42ee
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/af9cc401.failed

Dirty pages can be associated with different capsnap. Different capsnap
may have different EOF value. So invalidating dirty pages according to
the largest EOF value is wrong. Dirty pages beyond EOF, but associated
with other capsnap, do not get invalidated.

	Signed-off-by: "Yan, Zheng" <zyan@redhat.com>
	Signed-off-by: Ilya Dryomov <idryomov@gmail.com>
(cherry picked from commit af9cc401ce7452f9d965ba4553d8ffe7f0ed42ee)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/ceph/addr.c
diff --cc fs/ceph/addr.c
index adf7d1009bc0,3376822a624e..000000000000
--- a/fs/ceph/addr.c
+++ b/fs/ceph/addr.c
@@@ -710,19 -793,15 +710,25 @@@ static int ceph_writepages_start(struc
  	struct ceph_inode_info *ci = ceph_inode(inode);
  	struct ceph_fs_client *fsc = ceph_inode_to_client(inode);
  	struct ceph_vino vino = ceph_vino(inode);
 -	pgoff_t index, start_index, end = -1;
 +	pgoff_t index, start, end;
 +	int range_whole = 0;
 +	int should_loop = 1;
 +	pgoff_t max_pages = 0, max_pages_ever = 0;
  	struct ceph_snap_context *snapc = NULL, *last_snapc = NULL, *pgsnapc;
  	struct pagevec pvec;
 +	int done = 0;
  	int rc = 0;
 -	unsigned int wsize = i_blocksize(inode);
 +	unsigned wsize = 1 << inode->i_blkbits;
  	struct ceph_osd_request *req = NULL;
++<<<<<<< HEAD
 +	loff_t snap_size, i_size;
 +	u64 truncate_size;
 +	u32 truncate_seq;
++=======
+ 	struct ceph_writeback_ctl ceph_wbc;
+ 	bool should_loop, range_whole = false;
+ 	bool done = false;
++>>>>>>> af9cc401ce74 (ceph: invalidate pages that beyond EOF in ceph_writepages_start())
  
  	dout("writepages_start %p (mode=%s)\n", inode,
  	     wbc->sync_mode == WB_SYNC_NONE ? "NONE" :
@@@ -785,11 -866,8 +791,14 @@@ retry
  	last_snapc = snapc;
  
  	while (!done && index <= end) {
++<<<<<<< HEAD
 +		unsigned i;
 +		int first;
 +		pgoff_t strip_unit_end = 0;
++=======
++>>>>>>> af9cc401ce74 (ceph: invalidate pages that beyond EOF in ceph_writepages_start())
  		int num_ops = 0, op_idx;
 -		unsigned i, pvec_pages, max_pages, locked_pages = 0;
 +		int pvec_pages, locked_pages = 0;
  		struct page **pages = NULL, **data_pages;
  		mempool_t *pool = NULL;	/* Becomes non-null if mempool used */
  		struct page *page;
@@@ -823,48 -896,41 +832,69 @@@ get_more_pages
  			    unlikely(page->mapping != mapping)) {
  				dout("!dirty or !mapping %p\n", page);
  				unlock_page(page);
 -				continue;
 +				break;
 +			}
 +			if (!wbc->range_cyclic && page->index > end) {
 +				dout("end of range %p\n", page);
 +				done = 1;
 +				unlock_page(page);
 +				break;
  			}
- 			if (strip_unit_end && (page->index > strip_unit_end)) {
- 				dout("end of strip unit %p\n", page);
+ 			/* only if matching snap context */
+ 			pgsnapc = page_snap_context(page);
+ 			if (pgsnapc != snapc) {
+ 				dout("page snapc %p %lld != oldest %p %lld\n",
+ 				     pgsnapc, pgsnapc->seq, snapc, snapc->seq);
  				unlock_page(page);
- 				break;
+ 				continue;
  			}
++<<<<<<< HEAD
 +			if (wbc->sync_mode != WB_SYNC_NONE) {
 +				dout("waiting on writeback %p\n", page);
 +				wait_on_page_writeback(page);
 +			}
 +			if (page_offset(page) >=
 +			    (snap_size == -1 ? i_size : snap_size)) {
 +				dout("%p page eof %llu\n", page,
 +				     (snap_size == -1 ? i_size : snap_size));
 +				done = 1;
++=======
+ 			if (page_offset(page) >= ceph_wbc.i_size) {
+ 				dout("%p page eof %llu\n",
+ 				     page, ceph_wbc.i_size);
+ 				if (ceph_wbc.size_stable ||
+ 				    page_offset(page) >= i_size_read(inode))
+ 					mapping->a_ops->invalidatepage(page,
+ 								0, PAGE_SIZE);
+ 				unlock_page(page);
+ 				continue;
+ 			}
+ 			if (strip_unit_end && (page->index > strip_unit_end)) {
+ 				dout("end of strip unit %p\n", page);
++>>>>>>> af9cc401ce74 (ceph: invalidate pages that beyond EOF in ceph_writepages_start())
  				unlock_page(page);
  				break;
  			}
  			if (PageWriteback(page)) {
 -				if (wbc->sync_mode == WB_SYNC_NONE) {
 -					dout("%p under writeback\n", page);
 -					unlock_page(page);
 -					continue;
 -				}
 -				dout("waiting on writeback %p\n", page);
 -				wait_on_page_writeback(page);
 +				dout("%p under writeback\n", page);
 +				unlock_page(page);
 +				break;
 +			}
 +
++<<<<<<< HEAD
 +			/* only if matching snap context */
 +			pgsnapc = page_snap_context(page);
 +			if (pgsnapc != snapc) {
 +				dout("page snapc %p %lld != oldest %p %lld\n",
 +				     pgsnapc, pgsnapc->seq, snapc, snapc->seq);
 +				unlock_page(page);
 +				if (!locked_pages)
 +					continue; /* keep looking for snap */
 +				break;
  			}
  
++=======
++>>>>>>> af9cc401ce74 (ceph: invalidate pages that beyond EOF in ceph_writepages_start())
  			if (!clear_page_dirty_for_io(page)) {
  				dout("%p !clear_page_dirty_for_io\n", page);
  				unlock_page(page);
@@@ -1074,8 -1136,14 +1104,19 @@@ new_request
  		if (pages)
  			goto new_request;
  
++<<<<<<< HEAD
 +		if (wbc->nr_to_write <= 0)
 +			done = 1;
++=======
+ 		/*
+ 		 * We stop writing back only if we are not doing
+ 		 * integrity sync. In case of integrity sync we have to
+ 		 * keep going until we have written all the pages
+ 		 * we tagged for writeback prior to entering this loop.
+ 		 */
+ 		if (wbc->nr_to_write <= 0 && wbc->sync_mode == WB_SYNC_NONE)
+ 			done = true;
++>>>>>>> af9cc401ce74 (ceph: invalidate pages that beyond EOF in ceph_writepages_start())
  
  release_pvec_pages:
  		dout("pagevec_release on %d pages (%p)\n", (int)pvec.nr,
* Unmerged path fs/ceph/addr.c
diff --git a/fs/ceph/inode.c b/fs/ceph/inode.c
index 89fde4d86e99..351e58953dcf 100644
--- a/fs/ceph/inode.c
+++ b/fs/ceph/inode.c
@@ -1826,20 +1826,9 @@ retry:
 	 * possibly truncate them.. so write AND block!
 	 */
 	if (ci->i_wrbuffer_ref_head < ci->i_wrbuffer_ref) {
-		struct ceph_cap_snap *capsnap;
-		to = ci->i_truncate_size;
-		list_for_each_entry(capsnap, &ci->i_cap_snaps, ci_item) {
-			// MDS should have revoked Frw caps
-			WARN_ON_ONCE(capsnap->writing);
-			if (capsnap->dirty_pages && capsnap->size > to)
-				to = capsnap->size;
-		}
 		spin_unlock(&ci->i_ceph_lock);
 		dout("__do_pending_vmtruncate %p flushing snaps first\n",
 		     inode);
-
-		truncate_pagecache(inode, to);
-
 		filemap_write_and_wait_range(&inode->i_data, 0,
 					     inode->i_sb->s_maxbytes);
 		goto retry;
