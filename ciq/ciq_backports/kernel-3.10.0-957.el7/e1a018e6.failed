crypto: chelsio - Remove dst sg size zero check

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [crypto] chelsio - Remove dst sg size zero check (Arjun Vynipadath) [1523191]
Rebuild_FUZZ: 90.70%
commit-author Harsh Jain <harsh@chelsio.com>
commit e1a018e607a33dc9f987c761daf1792082fb9ca7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/e1a018e6.failed

sg_nents_xlen will take care of zero length sg list.
Remove Destination sg list size zero check.

	Signed-off-by: Harsh Jain <harsh@chelsio.com>
	Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
(cherry picked from commit e1a018e607a33dc9f987c761daf1792082fb9ca7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/crypto/chelsio/chcr_algo.c
diff --cc drivers/crypto/chelsio/chcr_algo.c
index 3d0dcd08d9d8,a9c894bf9c01..000000000000
mode 100755,100644..100755
--- a/drivers/crypto/chelsio/chcr_algo.c
+++ b/drivers/crypto/chelsio/chcr_algo.c
@@@ -1971,14 -2109,16 +1971,27 @@@ static struct sk_buff *create_authenc_w
  		null = 1;
  		assoclen = 0;
  	}
++<<<<<<< HEAD
 +	reqctx->dst_nents = sg_nents_for_len(reqctx->dst, req->cryptlen +
 +					     (op_type ? -authsize : authsize));
 +	if (reqctx->dst_nents < 0) {
 +		pr_err("AUTHENC:Invalid Destination sg entries\n");
 +		error = -EINVAL;
 +		goto err;
 +	}
 +	dst_size = get_space_for_phys_dsgl(reqctx->dst_nents);
++=======
+ 	error = chcr_aead_common_init(req, op_type);
+ 	if (error)
+ 		return ERR_PTR(error);
+ 		dnents = sg_nents_xlen(req->dst, assoclen, CHCR_DST_SG_SIZE, 0);
+ 		dnents += sg_nents_xlen(req->dst, req->cryptlen +
+ 			(op_type ? -authsize : authsize), CHCR_DST_SG_SIZE,
+ 			req->assoclen);
+ 		dnents += MIN_AUTH_SG; // For IV
+ 
+ 	dst_size = get_space_for_phys_dsgl(dnents);
++>>>>>>> e1a018e607a3 (crypto: chelsio - Remove dst sg size zero check)
  	kctx_len = (ntohl(KEY_CONTEXT_CTX_LEN_V(aeadctx->key_ctx_hdr)) << 4)
  		- sizeof(chcr_req->key_ctx);
  	transhdr_len = CIPHER_TRANSHDR_SIZE(kctx_len, dst_size);
@@@ -2261,59 -2667,54 +2274,79 @@@ static struct sk_buff *create_aead_ccm_
  	struct sk_buff *skb = NULL;
  	struct chcr_wr *chcr_req;
  	struct cpl_rx_phys_dsgl *phys_cpl;
 -	struct ulptx_sgl *ulptx;
 -	unsigned int transhdr_len;
 -	unsigned int dst_size = 0, kctx_len, dnents, temp;
 -	unsigned int sub_type, assoclen = req->assoclen;
 +	struct phys_sge_parm sg_param;
 +	unsigned int frags = 0, transhdr_len, ivsize = AES_BLOCK_SIZE;
 +	unsigned int dst_size = 0, kctx_len, nents;
 +	unsigned int sub_type;
  	unsigned int authsize = crypto_aead_authsize(tfm);
 -	int error = -EINVAL;
 +	int error = -EINVAL, src_nent;
  	gfp_t flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ? GFP_KERNEL :
  		GFP_ATOMIC;
 -	struct adapter *adap = padap(a_ctx(tfm)->dev);
 +	struct adapter *adap = padap(ctx->dev);
 +
 +	dst_size = req->cryptlen + (op_type ? -authsize :
 +					      authsize);
 +	reqctx->newdstsg = NULL;
 +	if (op_type && req->cryptlen < crypto_aead_authsize(tfm))
 +		goto err;
 +	src_nent = sg_nents_for_len(req->src, req->cryptlen);
 +	if (src_nent < 0)
 +		goto err;
  
 -	reqctx->b0_dma = 0;
  	sub_type = get_aead_subtype(tfm);
++<<<<<<< HEAD
 +	if (dst_size && is_newsg(req->dst, &nents)) {
 +		reqctx->newdstsg = alloc_new_sg(req->dst, nents);
 +		if (IS_ERR(reqctx->newdstsg))
 +			return ERR_CAST(reqctx->newdstsg);
 +		reqctx->dst = reqctx->newdstsg;
 +	} else {
 +		reqctx->dst = req->dst;
 +	}
 +	reqctx->dst_nents = sg_nents_for_len(reqctx->dst, req->cryptlen +
 +					     (op_type ? -authsize : authsize));
 +	if (reqctx->dst_nents < 0) {
 +		pr_err("CCM:Invalid Destination sg entries\n");
 +		error = -EINVAL;
 +		goto err;
 +	}
 +	error = aead_ccm_validate_input(op_type, req, aeadctx, sub_type);
 +	if (error)
 +		goto err;
 +
 +	dst_size = get_space_for_phys_dsgl(reqctx->dst_nents);
++=======
+ 	if (sub_type == CRYPTO_ALG_SUB_TYPE_AEAD_RFC4309)
+ 		assoclen -= 8;
+ 	error = chcr_aead_common_init(req, op_type);
+ 	if (error)
+ 		return ERR_PTR(error);
+ 
+ 
+ 	reqctx->b0_len = CCM_B0_SIZE + (assoclen ? CCM_AAD_FIELD_SIZE : 0);
+ 	error = aead_ccm_validate_input(op_type, req, aeadctx, sub_type);
+ 	if (error)
+ 		goto err;
+ 	dnents = sg_nents_xlen(req->dst, assoclen, CHCR_DST_SG_SIZE, 0);
+ 	dnents += sg_nents_xlen(req->dst, req->cryptlen
+ 			+ (op_type ? -authsize : authsize),
+ 			CHCR_DST_SG_SIZE, req->assoclen);
+ 	dnents += MIN_CCM_SG; // For IV and B0
+ 	dst_size = get_space_for_phys_dsgl(dnents);
++>>>>>>> e1a018e607a3 (crypto: chelsio - Remove dst sg size zero check)
  	kctx_len = ((DIV_ROUND_UP(aeadctx->enckey_len, 16)) << 4) * 2;
  	transhdr_len = CIPHER_TRANSHDR_SIZE(kctx_len, dst_size);
 -	reqctx->imm = (transhdr_len + assoclen + IV + req->cryptlen +
 -		       reqctx->b0_len) <= SGE_MAX_WR_LEN;
 -	temp = reqctx->imm ? (DIV_ROUND_UP((assoclen + IV + req->cryptlen +
 -				reqctx->b0_len), 16) * 16) :
 -		(sgl_len(reqctx->src_nents + reqctx->aad_nents +
 -				    MIN_CCM_SG) *  8);
 -	transhdr_len += temp;
 -	transhdr_len = DIV_ROUND_UP(transhdr_len, 16) * 16;
 -
 -	if (chcr_aead_need_fallback(req, dnents, T6_MAX_AAD_SIZE -
 -				    reqctx->b0_len, transhdr_len, op_type)) {
 +	if (chcr_aead_need_fallback(req, src_nent + MIN_CCM_SG,
 +			    T6_MAX_AAD_SIZE - 18,
 +			    transhdr_len + (sgl_len(src_nent + MIN_CCM_SG) * 8),
 +			    op_type)) {
  		atomic_inc(&adap->chcr_stats.fallback);
 -		chcr_aead_dma_unmap(&ULD_CTX(a_ctx(tfm))->lldi.pdev->dev, req,
 -				    op_type);
 +		free_new_sg(reqctx->newdstsg);
 +		reqctx->newdstsg = NULL;
  		return ERR_PTR(chcr_aead_fallback(req, op_type));
  	}
 -	skb = alloc_skb(SGE_MAX_WR_LEN,  flags);
 +
 +	skb = alloc_skb((transhdr_len + sizeof(struct sge_opaque_hdr)),  flags);
  
  	if (!skb) {
  		error = -ENOMEM;
@@@ -2374,49 -2776,28 +2407,62 @@@ static struct sk_buff *create_gcm_wr(st
  	struct sk_buff *skb = NULL;
  	struct chcr_wr *chcr_req;
  	struct cpl_rx_phys_dsgl *phys_cpl;
 -	struct ulptx_sgl *ulptx;
 -	unsigned int transhdr_len, dnents = 0;
 -	unsigned int dst_size = 0, temp = 0, kctx_len, assoclen = req->assoclen;
 +	struct phys_sge_parm sg_param;
 +	unsigned int frags = 0, transhdr_len;
 +	unsigned int ivsize = AES_BLOCK_SIZE;
 +	unsigned int dst_size = 0, kctx_len, nents, assoclen = req->assoclen;
 +	unsigned char tag_offset = 0;
  	unsigned int authsize = crypto_aead_authsize(tfm);
 -	int error = -EINVAL;
 +	int error = -EINVAL, src_nent;
  	gfp_t flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ? GFP_KERNEL :
  		GFP_ATOMIC;
 -	struct adapter *adap = padap(a_ctx(tfm)->dev);
 +	struct adapter *adap = padap(ctx->dev);
  
 -	if (get_aead_subtype(tfm) == CRYPTO_ALG_SUB_TYPE_AEAD_RFC4106)
 -		assoclen = req->assoclen - 8;
 +	reqctx->newdstsg = NULL;
 +	dst_size = req->cryptlen + (op_type ? -authsize :
 +					      authsize);
 +	/* validate key size */
 +	if (aeadctx->enckey_len == 0)
 +		goto err;
  
++<<<<<<< HEAD
 +	if (op_type && req->cryptlen < crypto_aead_authsize(tfm))
 +		goto err;
 +	src_nent = sg_nents_for_len(req->src, req->cryptlen);
 +	if (src_nent < 0)
 +		goto err;
 +
 +	if (dst_size && is_newsg(req->dst, &nents)) {
 +		reqctx->newdstsg = alloc_new_sg(req->dst, nents);
 +		if (IS_ERR(reqctx->newdstsg))
 +			return ERR_CAST(reqctx->newdstsg);
 +		reqctx->dst = reqctx->newdstsg;
 +	} else {
 +		reqctx->dst = req->dst;
 +	}
 +
 +	reqctx->dst_nents = sg_nents_for_len(reqctx->dst, req->cryptlen +
 +					     (op_type ? -authsize : authsize));
 +	if (reqctx->dst_nents < 0) {
 +		pr_err("GCM:Invalid Destination sg entries\n");
 +		error = -EINVAL;
 +		goto err;
 +	}
 +
 +
 +	dst_size = get_space_for_phys_dsgl(reqctx->dst_nents);
++=======
+ 	reqctx->b0_dma = 0;
+ 	error = chcr_aead_common_init(req, op_type);
+ 	if (error)
+ 		return ERR_PTR(error);
+ 	dnents = sg_nents_xlen(req->dst, assoclen, CHCR_DST_SG_SIZE, 0);
+ 	dnents += sg_nents_xlen(req->dst, req->cryptlen +
+ 				(op_type ? -authsize : authsize),
+ 				CHCR_DST_SG_SIZE, req->assoclen);
+ 	dnents += MIN_GCM_SG; // For IV
+ 	dst_size = get_space_for_phys_dsgl(dnents);
++>>>>>>> e1a018e607a3 (crypto: chelsio - Remove dst sg size zero check)
  	kctx_len = ((DIV_ROUND_UP(aeadctx->enckey_len, 16)) << 4) +
  		AEAD_H_SIZE;
  	transhdr_len = CIPHER_TRANSHDR_SIZE(kctx_len, dst_size);
@@@ -2435,25 -2821,22 +2481,33 @@@
  		goto err;
  	}
  
 -	chcr_req = __skb_put_zero(skb, transhdr_len);
 +	/* NIC driver is going to write the sge hdr. */
 +	skb_reserve(skb, sizeof(struct sge_opaque_hdr));
 +
 +	chcr_req = (struct chcr_wr *)__skb_put(skb, transhdr_len);
 +	memset(chcr_req, 0, transhdr_len);
  
 -	//Offset of tag from end
 -	temp = (op_type == CHCR_ENCRYPT_OP) ? 0 : authsize;
 +	tag_offset = (op_type == CHCR_ENCRYPT_OP) ? 0 : authsize;
  	chcr_req->sec_cpl.op_ivinsrtofst = FILL_SEC_CPL_OP_IVINSR(
 -					a_ctx(tfm)->dev->rx_channel_id, 2,
 -					(assoclen + 1));
 +					ctx->dev->rx_channel_id, 2, (ivsize ?
 +					(assoclen + 1) : 0));
  	chcr_req->sec_cpl.pldlen =
 -		htonl(assoclen + IV + req->cryptlen);
 +		htonl(assoclen + ivsize + req->cryptlen);
  	chcr_req->sec_cpl.aadstart_cipherstop_hi = FILL_SEC_CPL_CIPHERSTOP_HI(
  					assoclen ? 1 : 0, assoclen,
++<<<<<<< HEAD
 +					assoclen + ivsize + 1, 0);
 +		chcr_req->sec_cpl.cipherstop_lo_authinsert =
 +			FILL_SEC_CPL_AUTHINSERT(0, assoclen + ivsize + 1,
 +						tag_offset, tag_offset);
 +		chcr_req->sec_cpl.seqno_numivs =
++=======
+ 					assoclen + IV + 1, 0);
+ 	chcr_req->sec_cpl.cipherstop_lo_authinsert =
+ 			FILL_SEC_CPL_AUTHINSERT(0, assoclen + IV + 1,
+ 						temp, temp);
+ 	chcr_req->sec_cpl.seqno_numivs =
++>>>>>>> e1a018e607a3 (crypto: chelsio - Remove dst sg size zero check)
  			FILL_SEC_CPL_SCMD0_SEQNO(op_type, (op_type ==
  					CHCR_ENCRYPT_OP) ? 1 : 0,
  					CHCR_SCMD_CIPHER_MODE_AES_GCM,
* Unmerged path drivers/crypto/chelsio/chcr_algo.c
