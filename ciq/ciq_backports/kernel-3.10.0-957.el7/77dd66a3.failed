mm: Fix devm_memremap_pages() collision handling

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Jan H. Schönherr <jschoenh@amazon.de>
commit 77dd66a3c67c93ab401ccc15efff25578be281fd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/77dd66a3.failed

If devm_memremap_pages() detects a collision while adding entries
to the radix-tree, we call pgmap_radix_release(). Unfortunately,
the function removes *all* entries for the range -- including the
entries that caused the collision in the first place.

Modify pgmap_radix_release() to take an additional argument to
indicate where to stop, so that only newly added entries are removed
from the tree.

	Cc: <stable@vger.kernel.org>
Fixes: 9476df7d80df ("mm: introduce find_dev_pagemap()")
	Signed-off-by: Jan H. Schönherr <jschoenh@amazon.de>
	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
(cherry picked from commit 77dd66a3c67c93ab401ccc15efff25578be281fd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/memremap.c
diff --cc kernel/memremap.c
index eca98ec515d8,4849be5f9b3c..000000000000
--- a/kernel/memremap.c
+++ b/kernel/memremap.c
@@@ -273,7 -213,35 +273,39 @@@ static unsigned long order_at(struct re
  	for (pgoff = 0, order = order_at((res), pgoff); order < ULONG_MAX; \
  			pgoff += 1UL << order, order = order_at((res), pgoff))
  
++<<<<<<< HEAD
 +static void pgmap_radix_release(struct resource *res)
++=======
+ #if IS_ENABLED(CONFIG_DEVICE_PRIVATE)
+ int device_private_entry_fault(struct vm_area_struct *vma,
+ 		       unsigned long addr,
+ 		       swp_entry_t entry,
+ 		       unsigned int flags,
+ 		       pmd_t *pmdp)
+ {
+ 	struct page *page = device_private_entry_to_page(entry);
+ 
+ 	/*
+ 	 * The page_fault() callback must migrate page back to system memory
+ 	 * so that CPU can access it. This might fail for various reasons
+ 	 * (device issue, device was unsafely unplugged, ...). When such
+ 	 * error conditions happen, the callback must return VM_FAULT_SIGBUS.
+ 	 *
+ 	 * Note that because memory cgroup charges are accounted to the device
+ 	 * memory, this should never fail because of memory restrictions (but
+ 	 * allocation of regular system page might still fail because we are
+ 	 * out of memory).
+ 	 *
+ 	 * There is a more in-depth description of what that callback can and
+ 	 * cannot do, in include/linux/memremap.h
+ 	 */
+ 	return page->pgmap->page_fault(vma, addr, page, flags, pmdp);
+ }
+ EXPORT_SYMBOL(device_private_entry_fault);
+ #endif /* CONFIG_DEVICE_PRIVATE */
+ 
+ static void pgmap_radix_release(struct resource *res, unsigned long end_pgoff)
++>>>>>>> 77dd66a3c67c (mm: Fix devm_memremap_pages() collision handling)
  {
  	unsigned long pgoff, order;
  
@@@ -322,26 -296,18 +357,32 @@@ static void devm_memremap_pages_release
  
  	/* pages are dead and unused, undo the arch mapping */
  	align_start = res->start & ~(SECTION_SIZE - 1);
 -	align_size = ALIGN(res->start + resource_size(res), SECTION_SIZE)
 -		- align_start;
 +	align_size = ALIGN(resource_size(res), SECTION_SIZE);
  
  	mem_hotplug_begin();
 -	arch_remove_memory(align_start, align_size, pgmap->altmap_valid ?
 -			&pgmap->altmap : NULL);
 +	arch_remove_memory(align_start, align_size);
 +	untrack_pfn(NULL, PHYS_PFN(align_start), align_size);
++<<<<<<< HEAD
  	mem_hotplug_done();
 +	pgmap_radix_release(res);
 +	dev_WARN_ONCE(dev, pgmap->altmap && pgmap->altmap->alloc,
 +			"%s: failed to free all reserved pages\n", __func__);
 +}
  
 -	untrack_pfn(NULL, PHYS_PFN(align_start), align_size);
 +/* assumes rcu_read_lock() held at entry */
 +struct dev_pagemap *find_dev_pagemap(resource_size_t phys)
 +{
 +	struct page_map *page_map;
 +
 +	WARN_ON_ONCE(!rcu_read_lock_held());
 +
 +	page_map = radix_tree_lookup(&pgmap_radix, PHYS_PFN(phys));
 +	return page_map ? &page_map->pgmap : NULL;
++=======
+ 	pgmap_radix_release(res, -1);
+ 	dev_WARN_ONCE(dev, pgmap->altmap.alloc,
+ 		      "%s: failed to free all reserved pages\n", __func__);
++>>>>>>> 77dd66a3c67c (mm: Fix devm_memremap_pages() collision handling)
  }
  
  /**
@@@ -462,8 -421,8 +503,13 @@@ void *devm_memremap_pages(struct devic
  	untrack_pfn(NULL, PHYS_PFN(align_start), align_size);
   err_pfn_remap:
   err_radix:
++<<<<<<< HEAD
 +	pgmap_radix_release(res);
 +	devres_free(page_map);
++=======
+ 	pgmap_radix_release(res, pgoff);
+ 	devres_free(pgmap);
++>>>>>>> 77dd66a3c67c (mm: Fix devm_memremap_pages() collision handling)
  	return ERR_PTR(error);
  }
  EXPORT_SYMBOL(devm_memremap_pages);
* Unmerged path kernel/memremap.c
