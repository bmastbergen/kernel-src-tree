lockdep: Introduce lock_acquire_exclusive()/shared() helper macros

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Michel Lespinasse <walken@google.com>
commit a51805efae5dda0da66f79268ffcf0715f9dbea4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/a51805ef.failed

In lockdep.h, the spinlock/mutex/rwsem/rwlock/lock_map acquire macros have
different definitions based on the value of CONFIG_PROVE_LOCKING.  We have
separate ifdefs for each of these definitions, which seems redundant.

Introduce lock_acquire_{exclusive,shared,shared_recursive} helpers which
will have different definitions based on CONFIG_PROVE_LOCKING.  Then all
other helper macros can be defined based on the above ones, which reduces
the amount of ifdefined code.

	Signed-off-by: Michel Lespinasse <walken@google.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Peter Zijlstra <peterz@infradead.org>
	Cc: Oleg Nesterov <oleg@redhat.com>
	Cc: Lai Jiangshan <laijs@cn.fujitsu.com>
	Cc: "Srivatsa S. Bhat" <srivatsa.bhat@linux.vnet.ibm.com>
	Cc: Rusty Russell <rusty@rustcorp.com.au>
	Cc: Andi Kleen <ak@linux.intel.com>
	Cc: "Paul E. McKenney" <paulmck@us.ibm.com>
	Cc: Steven Rostedt <rostedt@goodmis.org>
Link: http://lkml.kernel.org/r/20130708212350.6DD1931C15E@corp2gmr1-1.hot.corp.google.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit a51805efae5dda0da66f79268ffcf0715f9dbea4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/lockdep.h
diff --cc include/linux/lockdep.h
index 338d5ef062c6,cfc2f119779a..000000000000
--- a/include/linux/lockdep.h
+++ b/include/linux/lockdep.h
@@@ -363,13 -363,9 +363,13 @@@ extern void lockdep_trace_alloc(gfp_t m
  		WARN_ON(debug_locks && !lockdep_is_held(l));	\
  	} while (0)
  
 +#define lockdep_assert_held_once(l)	do {				\
 +		WARN_ON_ONCE(debug_locks && !lockdep_is_held(l));	\
 +	} while (0)
 +
  #define lockdep_recursing(tsk)	((tsk)->lockdep_recursion)
  
- #else /* !LOCKDEP */
+ #else /* !CONFIG_LOCKDEP */
  
  static inline void lockdep_off(void)
  {
@@@ -484,85 -479,36 +484,56 @@@ static inline void print_irqtrace_event
   * on the per lock-class debug mode:
   */
  
- #ifdef CONFIG_DEBUG_LOCK_ALLOC
- # ifdef CONFIG_PROVE_LOCKING
- #  define spin_acquire(l, s, t, i)		lock_acquire(l, s, t, 0, 2, NULL, i)
- #  define spin_acquire_nest(l, s, t, n, i)	lock_acquire(l, s, t, 0, 2, n, i)
- # else
- #  define spin_acquire(l, s, t, i)		lock_acquire(l, s, t, 0, 1, NULL, i)
- #  define spin_acquire_nest(l, s, t, n, i)	lock_acquire(l, s, t, 0, 1, NULL, i)
- # endif
- # define spin_release(l, n, i)			lock_release(l, n, i)
+ #ifdef CONFIG_PROVE_LOCKING
+  #define lock_acquire_exclusive(l, s, t, n, i)		lock_acquire(l, s, t, 0, 2, n, i)
+  #define lock_acquire_shared(l, s, t, n, i)		lock_acquire(l, s, t, 1, 2, n, i)
+  #define lock_acquire_shared_recursive(l, s, t, n, i)	lock_acquire(l, s, t, 2, 2, n, i)
  #else
- # define spin_acquire(l, s, t, i)		do { } while (0)
- # define spin_release(l, n, i)			do { } while (0)
+  #define lock_acquire_exclusive(l, s, t, n, i)		lock_acquire(l, s, t, 0, 1, n, i)
+  #define lock_acquire_shared(l, s, t, n, i)		lock_acquire(l, s, t, 1, 1, n, i)
+  #define lock_acquire_shared_recursive(l, s, t, n, i)	lock_acquire(l, s, t, 2, 1, n, i)
  #endif
  
- #ifdef CONFIG_DEBUG_LOCK_ALLOC
- # ifdef CONFIG_PROVE_LOCKING
- #  define rwlock_acquire(l, s, t, i)		lock_acquire(l, s, t, 0, 2, NULL, i)
- #  define rwlock_acquire_read(l, s, t, i)	lock_acquire(l, s, t, 2, 2, NULL, i)
- # else
- #  define rwlock_acquire(l, s, t, i)		lock_acquire(l, s, t, 0, 1, NULL, i)
- #  define rwlock_acquire_read(l, s, t, i)	lock_acquire(l, s, t, 2, 1, NULL, i)
- # endif
- # define rwlock_release(l, n, i)		lock_release(l, n, i)
- #else
- # define rwlock_acquire(l, s, t, i)		do { } while (0)
- # define rwlock_acquire_read(l, s, t, i)	do { } while (0)
- # define rwlock_release(l, n, i)		do { } while (0)
- #endif
+ #define spin_acquire(l, s, t, i)		lock_acquire_exclusive(l, s, t, NULL, i)
+ #define spin_acquire_nest(l, s, t, n, i)	lock_acquire_exclusive(l, s, t, n, i)
+ #define spin_release(l, n, i)			lock_release(l, n, i)
  
- #ifdef CONFIG_DEBUG_LOCK_ALLOC
- # ifdef CONFIG_PROVE_LOCKING
- #  define mutex_acquire(l, s, t, i)		lock_acquire(l, s, t, 0, 2, NULL, i)
- #  define mutex_acquire_nest(l, s, t, n, i)	lock_acquire(l, s, t, 0, 2, n, i)
- # else
- #  define mutex_acquire(l, s, t, i)		lock_acquire(l, s, t, 0, 1, NULL, i)
- #  define mutex_acquire_nest(l, s, t, n, i)	lock_acquire(l, s, t, 0, 1, n, i)
- # endif
- # define mutex_release(l, n, i)			lock_release(l, n, i)
- #else
- # define mutex_acquire(l, s, t, i)		do { } while (0)
- # define mutex_acquire_nest(l, s, t, n, i)	do { } while (0)
- # define mutex_release(l, n, i)			do { } while (0)
- #endif
+ #define rwlock_acquire(l, s, t, i)		lock_acquire_exclusive(l, s, t, NULL, i)
+ #define rwlock_acquire_read(l, s, t, i)		lock_acquire_shared_recursive(l, s, t, NULL, i)
+ #define rwlock_release(l, n, i)			lock_release(l, n, i)
  
- #ifdef CONFIG_DEBUG_LOCK_ALLOC
- # ifdef CONFIG_PROVE_LOCKING
- #  define rwsem_acquire(l, s, t, i)		lock_acquire(l, s, t, 0, 2, NULL, i)
- #  define rwsem_acquire_nest(l, s, t, n, i)	lock_acquire(l, s, t, 0, 2, n, i)
- #  define rwsem_acquire_read(l, s, t, i)	lock_acquire(l, s, t, 1, 2, NULL, i)
- # else
- #  define rwsem_acquire(l, s, t, i)		lock_acquire(l, s, t, 0, 1, NULL, i)
- #  define rwsem_acquire_nest(l, s, t, n, i)	lock_acquire(l, s, t, 0, 1, n, i)
- #  define rwsem_acquire_read(l, s, t, i)	lock_acquire(l, s, t, 1, 1, NULL, i)
- # endif
+ #define mutex_acquire(l, s, t, i)		lock_acquire_exclusive(l, s, t, NULL, i)
+ #define mutex_acquire_nest(l, s, t, n, i)	lock_acquire_exclusive(l, s, t, n, i)
+ #define mutex_release(l, n, i)			lock_release(l, n, i)
+ 
+ #define rwsem_acquire(l, s, t, i)		lock_acquire_exclusive(l, s, t, NULL, i)
+ #define rwsem_acquire_nest(l, s, t, n, i)	lock_acquire_exclusive(l, s, t, n, i)
+ #define rwsem_acquire_read(l, s, t, i)		lock_acquire_shared(l, s, t, NULL, i)
  # define rwsem_release(l, n, i)			lock_release(l, n, i)
- #else
- # define rwsem_acquire(l, s, t, i)		do { } while (0)
- # define rwsem_acquire_nest(l, s, t, n, i)	do { } while (0)
- # define rwsem_acquire_read(l, s, t, i)		do { } while (0)
- # define rwsem_release(l, n, i)			do { } while (0)
- #endif
  
++<<<<<<< HEAD
 +#ifdef CONFIG_DEBUG_LOCK_ALLOC
 +# ifdef CONFIG_PROVE_LOCKING
 +#  define lock_map_acquire(l)		lock_acquire(l, 0, 0, 0, 2, NULL, _THIS_IP_)
 +#  define lock_map_acquire_read(l)	lock_acquire(l, 0, 0, 2, 2, NULL, _THIS_IP_)
 +#  define lock_map_acquire_tryread(l)	lock_acquire(l, 0, 1, 2, 2, NULL, _THIS_IP_)
 +# else
 +#  define lock_map_acquire(l)		lock_acquire(l, 0, 0, 0, 1, NULL, _THIS_IP_)
 +#  define lock_map_acquire_read(l)	lock_acquire(l, 0, 0, 2, 1, NULL, _THIS_IP_)
 +#  define lock_map_acquire_tryread(l)	lock_acquire(l, 0, 1, 2, 1, NULL, _THIS_IP_)
 +# endif
 +# define lock_map_release(l)			lock_release(l, 1, _THIS_IP_)
 +#else
 +# define lock_map_acquire(l)			do { } while (0)
 +# define lock_map_acquire_read(l)		do { } while (0)
 +# define lock_map_acquire_tryread(l)		do { } while (0)
 +# define lock_map_release(l)			do { } while (0)
 +#endif
++=======
+ #define lock_map_acquire(l)			lock_acquire_exclusive(l, 0, 0, NULL, _THIS_IP_)
+ #define lock_map_acquire_read(l)		lock_acquire_shared_recursive(l, 0, 0, NULL, _THIS_IP_)
+ # define lock_map_release(l)			lock_release(l, 1, _THIS_IP_)
++>>>>>>> a51805efae5d (lockdep: Introduce lock_acquire_exclusive()/shared() helper macros)
  
  #ifdef CONFIG_PROVE_LOCKING
  # define might_lock(lock) 						\
* Unmerged path include/linux/lockdep.h
