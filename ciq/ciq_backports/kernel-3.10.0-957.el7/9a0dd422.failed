dax: Allow dax_iomap_fault() to return pfn

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Jan Kara <jack@suse.cz>
commit 9a0dd42251439de635088b97533109a935864a84
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/9a0dd422.failed

For synchronous page fault dax_iomap_fault() will need to return PFN
which will then need to be inserted into page tables after fsync()
completes. Add necessary parameter to dax_iomap_fault().

	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Ross Zwisler <ross.zwisler@linux.intel.com>
	Signed-off-by: Jan Kara <jack@suse.cz>
	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
(cherry picked from commit 9a0dd42251439de635088b97533109a935864a84)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/dax.c
#	fs/ext2/file.c
#	fs/xfs/xfs_file.c
#	include/linux/dax.h
diff --cc fs/dax.c
index 1e9b52eccd08,5ddf15161390..000000000000
--- a/fs/dax.c
+++ b/fs/dax.c
@@@ -1178,14 -1079,14 +1178,19 @@@ static int dax_fault_return(int error
  	return VM_FAULT_SIGBUS;
  }
  
++<<<<<<< HEAD
 +static int dax_iomap_pte_fault(struct vm_fault *vmf,
 +			const struct iomap_ops *ops)
++=======
+ static int dax_iomap_pte_fault(struct vm_fault *vmf, pfn_t *pfnp,
+ 			       const struct iomap_ops *ops)
++>>>>>>> 9a0dd4225143 (dax: Allow dax_iomap_fault() to return pfn)
  {
 -	struct vm_area_struct *vma = vmf->vma;
 -	struct address_space *mapping = vma->vm_file->f_mapping;
 +	struct address_space *mapping = vmf->vma->vm_file->f_mapping;
  	struct inode *inode = mapping->host;
 -	unsigned long vaddr = vmf->address;
 +	unsigned long vaddr = (unsigned long)vmf->virtual_address;
  	loff_t pos = (loff_t)vmf->pgoff << PAGE_SHIFT;
 +	sector_t sector;
  	struct iomap iomap = { 0 };
  	unsigned flags = IOMAP_FAULT;
  	int error, major = 0;
@@@ -1414,8 -1280,8 +1419,13 @@@ fallback
  	return VM_FAULT_FALLBACK;
  }
  
++<<<<<<< HEAD
 +static int dax_iomap_pmd_fault(struct vm_fault *vmf,
 +		const struct iomap_ops *ops)
++=======
+ static int dax_iomap_pmd_fault(struct vm_fault *vmf, pfn_t *pfnp,
+ 			       const struct iomap_ops *ops)
++>>>>>>> 9a0dd4225143 (dax: Allow dax_iomap_fault() to return pfn)
  {
  	struct vm_area_struct *vma = vmf->vma;
  	struct address_space *mapping = vma->vm_file->f_mapping;
@@@ -1547,8 -1425,8 +1557,13 @@@ out
  	return result;
  }
  #else
++<<<<<<< HEAD
 +static int dax_iomap_pmd_fault(struct vm_fault *vmf,
 +		const struct iomap_ops *ops)
++=======
+ static int dax_iomap_pmd_fault(struct vm_fault *vmf, pfn_t *pfnp,
+ 			       const struct iomap_ops *ops)
++>>>>>>> 9a0dd4225143 (dax: Allow dax_iomap_fault() to return pfn)
  {
  	return VM_FAULT_FALLBACK;
  }
@@@ -1566,7 -1445,7 +1582,11 @@@
   * successfully.
   */
  int dax_iomap_fault(struct vm_fault *vmf, enum page_entry_size pe_size,
++<<<<<<< HEAD
 +		const struct iomap_ops *ops)
++=======
+ 		    pfn_t *pfnp, const struct iomap_ops *ops)
++>>>>>>> 9a0dd4225143 (dax: Allow dax_iomap_fault() to return pfn)
  {
  	switch (pe_size) {
  	case PE_SIZE_PTE:
diff --cc fs/ext2/file.c
index 4d0447eb265d,d2bb7c96307d..000000000000
--- a/fs/ext2/file.c
+++ b/fs/ext2/file.c
@@@ -51,7 -99,7 +51,11 @@@ static int ext2_dax_fault(struct vm_are
  	}
  	down_read(&ei->dax_sem);
  
++<<<<<<< HEAD
 +	ret = dax_fault(vma, vmf, ext2_get_block);
++=======
+ 	ret = dax_iomap_fault(vmf, PE_SIZE_PTE, NULL, &ext2_iomap_ops);
++>>>>>>> 9a0dd4225143 (dax: Allow dax_iomap_fault() to return pfn)
  
  	up_read(&ei->dax_sem);
  	if (vmf->flags & FAULT_FLAG_WRITE)
diff --cc fs/xfs/xfs_file.c
index cea567087acc,7c6b8def6eed..000000000000
--- a/fs/xfs/xfs_file.c
+++ b/fs/xfs/xfs_file.c
@@@ -1183,28 -1069,19 +1183,39 @@@ xfs_filemap_huge_fault
  	struct vm_fault		*vmf,
  	enum page_entry_size	pe_size)
  {
 -	if (!IS_DAX(file_inode(vmf->vma->vm_file)))
 +	struct inode		*inode = file_inode(vmf->vma->vm_file);
 +	struct xfs_inode	*ip = XFS_I(inode);
 +	int			ret;
 +
 +	if (!IS_DAX(inode))
  		return VM_FAULT_FALLBACK;
  
 -	/* DAX can shortcut the normal fault path on write faults! */
 -	return __xfs_filemap_fault(vmf, pe_size,
 -			(vmf->flags & FAULT_FLAG_WRITE));
 -}
 +	trace_xfs_filemap_huge_fault(ip);
  
 -static int
 -xfs_filemap_page_mkwrite(
 -	struct vm_fault		*vmf)
 -{
 -	return __xfs_filemap_fault(vmf, PE_SIZE_PTE, true);
 +	if (vmf->flags & FAULT_FLAG_WRITE) {
 +		sb_start_pagefault(inode->i_sb);
 +		file_update_time(vmf->vma->vm_file);
 +	}
 +
 +	xfs_ilock(XFS_I(inode), XFS_MMAPLOCK_SHARED);
++<<<<<<< HEAD
 +	ret = dax_iomap_fault(vmf, pe_size, &xfs_iomap_ops);
++=======
++	if (IS_DAX(inode)) {
++		ret = dax_iomap_fault(vmf, pe_size, NULL, &xfs_iomap_ops);
++	} else {
++		if (write_fault)
++			ret = iomap_page_mkwrite(vmf, &xfs_iomap_ops);
++		else
++			ret = filemap_fault(vmf);
++	}
++>>>>>>> 9a0dd4225143 (dax: Allow dax_iomap_fault() to return pfn)
 +	xfs_iunlock(XFS_I(inode), XFS_MMAPLOCK_SHARED);
 +
 +	if (vmf->flags & FAULT_FLAG_WRITE)
 +		sb_end_pagefault(inode->i_sb);
 +
 +	return ret;
  }
  
  /*
@@@ -1235,7 -1111,7 +1246,11 @@@ xfs_filemap_pfn_mkwrite
  	if (vmf->pgoff >= size)
  		ret = VM_FAULT_SIGBUS;
  	else if (IS_DAX(inode))
++<<<<<<< HEAD
 +		ret = dax_pfn_mkwrite(vma, vmf);
++=======
+ 		ret = dax_iomap_fault(vmf, PE_SIZE_PTE, NULL, &xfs_iomap_ops);
++>>>>>>> 9a0dd4225143 (dax: Allow dax_iomap_fault() to return pfn)
  	xfs_iunlock(ip, XFS_MMAPLOCK_SHARED);
  	sb_end_pagefault(inode->i_sb);
  	return ret;
diff --cc include/linux/dax.h
index b7b81d6cc271,e7fa4b8f45bc..000000000000
--- a/include/linux/dax.h
+++ b/include/linux/dax.h
@@@ -85,13 -86,16 +85,17 @@@ void kill_dax(struct dax_device *dax_de
  void *dax_get_private(struct dax_device *dax_dev);
  long dax_direct_access(struct dax_device *dax_dev, pgoff_t pgoff, long nr_pages,
  		void **kaddr, pfn_t *pfn);
 -size_t dax_copy_from_iter(struct dax_device *dax_dev, pgoff_t pgoff, void *addr,
 -		size_t bytes, struct iov_iter *i);
 -void dax_flush(struct dax_device *dax_dev, void *addr, size_t size);
 -void dax_write_cache(struct dax_device *dax_dev, bool wc);
 -bool dax_write_cache_enabled(struct dax_device *dax_dev);
  
 -ssize_t dax_iomap_rw(struct kiocb *iocb, struct iov_iter *iter,
 -		const struct iomap_ops *ops);
 +ssize_t dax_iomap_rw(int rw, struct kiocb *iocb, const struct iovec *iov,
 +		unsigned long nr_segs, loff_t pos,
 +		size_t count, const struct iomap_ops *ops);
  int dax_iomap_fault(struct vm_fault *vmf, enum page_entry_size pe_size,
++<<<<<<< HEAD
 +		const struct iomap_ops *ops);
 +int dax_fault(struct vm_area_struct *, struct vm_fault *, get_block_t);
++=======
+ 		    pfn_t *pfnp, const struct iomap_ops *ops);
++>>>>>>> 9a0dd4225143 (dax: Allow dax_iomap_fault() to return pfn)
  int dax_delete_mapping_entry(struct address_space *mapping, pgoff_t index);
  int dax_invalidate_mapping_entry_sync(struct address_space *mapping,
  				      pgoff_t index);
* Unmerged path fs/dax.c
* Unmerged path fs/ext2/file.c
diff --git a/fs/ext4/file.c b/fs/ext4/file.c
index feb7f54458b2..895421ee3b8a 100644
--- a/fs/ext4/file.c
+++ b/fs/ext4/file.c
@@ -301,7 +301,7 @@ static int ext4_dax_huge_fault(struct vm_fault *vmf,
 		down_read(&EXT4_I(inode)->i_mmap_sem);
 	}
 	if (!IS_ERR(handle))
-		result = dax_iomap_fault(vmf, pe_size, &ext4_iomap_ops);
+		result = dax_iomap_fault(vmf, pe_size, NULL, &ext4_iomap_ops);
 	else
 		result = VM_FAULT_SIGBUS;
 	if (write) {
* Unmerged path fs/xfs/xfs_file.c
* Unmerged path include/linux/dax.h
