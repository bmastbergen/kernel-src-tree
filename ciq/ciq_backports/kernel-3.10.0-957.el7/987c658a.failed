sfc: fix ARFS expiry check on EF10

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Edward Cree <ecree@solarflare.com>
commit 987c658a61f432804c4662b736dbd5fc5939af1f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/987c658a.failed

Owing to a missing conditional, the result of rps_may_expire_flow() was
 being ignored and filters were being removed even if we'd decided not to
 expire them.

Fixes: f8d6203780b7 ("sfc: ARFS filter IDs")
	Signed-off-by: Edward Cree <ecree@solarflare.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 987c658a61f432804c4662b736dbd5fc5939af1f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/sfc/ef10.c
diff --cc drivers/net/ethernet/sfc/ef10.c
index 4fcde9306ea4,d90a7b1f4088..000000000000
--- a/drivers/net/ethernet/sfc/ef10.c
+++ b/drivers/net/ethernet/sfc/ef10.c
@@@ -4690,196 -4736,70 +4690,228 @@@ static s32 efx_ef10_filter_get_rx_ids(s
  
  #ifdef CONFIG_RFS_ACCEL
  
 -static bool efx_ef10_filter_rfs_expire_one(struct efx_nic *efx, u32 flow_id,
 -					   unsigned int filter_idx)
 +static efx_mcdi_async_completer efx_ef10_filter_rfs_insert_complete;
 +
 +static s32 efx_ef10_filter_rfs_insert(struct efx_nic *efx,
 +				      struct efx_filter_spec *spec)
  {
 -	struct efx_filter_spec *spec, saved_spec;
 -	struct efx_ef10_filter_table *table;
 -	struct efx_arfs_rule *rule = NULL;
 -	bool ret = true, force = false;
 -	u16 arfs_id;
 +	struct efx_ef10_filter_table *table = efx->filter_state;
 +	MCDI_DECLARE_BUF(inbuf, MC_CMD_FILTER_OP_EXT_IN_LEN);
 +	struct efx_filter_spec *saved_spec;
 +	unsigned int hash, i, depth = 1;
 +	bool replacing = false;
 +	int ins_index = -1;
 +	u64 cookie;
 +	s32 rc;
  
 -	down_read(&efx->filter_sem);
 -	table = efx->filter_state;
 -	down_write(&table->lock);
 -	spec = efx_ef10_filter_entry_spec(table, filter_idx);
 +	/* Must be an RX filter without RSS and not for a multicast
 +	 * destination address (RFS only works for connected sockets).
 +	 * These restrictions allow us to pass only a tiny amount of
 +	 * data through to the completion function.
 +	 */
 +	EFX_WARN_ON_PARANOID(spec->flags !=
 +			     (EFX_FILTER_FLAG_RX | EFX_FILTER_FLAG_RX_SCATTER));
 +	EFX_WARN_ON_PARANOID(spec->priority != EFX_FILTER_PRI_HINT);
 +	EFX_WARN_ON_PARANOID(efx_filter_is_mc_recipient(spec));
  
 -	if (!spec || spec->priority != EFX_FILTER_PRI_HINT)
 -		goto out_unlock;
 +	hash = efx_ef10_filter_hash(spec);
 +
 +	spin_lock_bh(&efx->filter_lock);
 +
 +	/* Find any existing filter with the same match tuple or else
 +	 * a free slot to insert at.  If an existing filter is busy,
 +	 * we have to give up.
 +	 */
 +	for (;;) {
 +		i = (hash + depth) & (HUNT_FILTER_TBL_ROWS - 1);
 +		saved_spec = efx_ef10_filter_entry_spec(table, i);
 +
 +		if (!saved_spec) {
 +			if (ins_index < 0)
 +				ins_index = i;
 +		} else if (efx_ef10_filter_equal(spec, saved_spec)) {
 +			if (table->entry[i].spec & EFX_EF10_FILTER_FLAG_BUSY) {
 +				rc = -EBUSY;
 +				goto fail_unlock;
 +			}
 +			if (spec->priority < saved_spec->priority) {
 +				rc = -EPERM;
 +				goto fail_unlock;
 +			}
 +			ins_index = i;
 +			break;
 +		}
 +
 +		/* Once we reach the maximum search depth, use the
 +		 * first suitable slot or return -EBUSY if there was
 +		 * none
 +		 */
 +		if (depth == EFX_EF10_FILTER_SEARCH_LIMIT) {
 +			if (ins_index < 0) {
 +				rc = -EBUSY;
 +				goto fail_unlock;
 +			}
 +			break;
 +		}
  
 -	spin_lock_bh(&efx->rps_hash_lock);
 -	if (!efx->rps_hash_table) {
 -		/* In the absence of the table, we always return 0 to ARFS. */
 -		arfs_id = 0;
 +		++depth;
 +	}
 +
 +	/* Create a software table entry if necessary, and mark it
 +	 * busy.  We might yet fail to insert, but any attempt to
 +	 * insert a conflicting filter while we're waiting for the
 +	 * firmware must find the busy entry.
 +	 */
 +	saved_spec = efx_ef10_filter_entry_spec(table, ins_index);
 +	if (saved_spec) {
 +		replacing = true;
  	} else {
 -		rule = efx_rps_hash_find(efx, spec);
 -		if (!rule)
 -			/* ARFS table doesn't know of this filter, so remove it */
 -			goto expire;
 -		arfs_id = rule->arfs_id;
 -		ret = efx_rps_check_rule(rule, filter_idx, &force);
 -		if (force)
 -			goto expire;
 -		if (!ret) {
 -			spin_unlock_bh(&efx->rps_hash_lock);
 -			goto out_unlock;
 +		saved_spec = kmalloc(sizeof(*spec), GFP_ATOMIC);
 +		if (!saved_spec) {
 +			rc = -ENOMEM;
 +			goto fail_unlock;
  		}
 +		*saved_spec = *spec;
  	}
 +	efx_ef10_filter_set_entry(table, ins_index, saved_spec,
 +				  EFX_EF10_FILTER_FLAG_BUSY);
 +
 +	spin_unlock_bh(&efx->filter_lock);
 +
 +	/* Pack up the variables needed on completion */
 +	cookie = replacing << 31 | ins_index << 16 | spec->dmaq_id;
 +
 +	efx_ef10_filter_push_prep(efx, spec, inbuf,
 +				  table->entry[ins_index].handle, NULL,
 +				  replacing);
 +	efx_mcdi_rpc_async(efx, MC_CMD_FILTER_OP, inbuf, sizeof(inbuf),
 +			   MC_CMD_FILTER_OP_OUT_LEN,
 +			   efx_ef10_filter_rfs_insert_complete, cookie);
 +
 +	return ins_index;
 +
 +fail_unlock:
 +	spin_unlock_bh(&efx->filter_lock);
 +	return rc;
 +}
 +
 +static void
 +efx_ef10_filter_rfs_insert_complete(struct efx_nic *efx, unsigned long cookie,
 +				    int rc, efx_dword_t *outbuf,
 +				    size_t outlen_actual)
 +{
 +	struct efx_ef10_filter_table *table = efx->filter_state;
 +	unsigned int ins_index, dmaq_id;
 +	struct efx_filter_spec *spec;
 +	bool replacing;
 +
 +	/* Unpack the cookie */
 +	replacing = cookie >> 31;
 +	ins_index = (cookie >> 16) & (HUNT_FILTER_TBL_ROWS - 1);
 +	dmaq_id = cookie & 0xffff;
 +
 +	spin_lock_bh(&efx->filter_lock);
 +	spec = efx_ef10_filter_entry_spec(table, ins_index);
 +	if (rc == 0) {
 +		table->entry[ins_index].handle =
 +			MCDI_QWORD(outbuf, FILTER_OP_OUT_HANDLE);
 +		if (replacing)
 +			spec->dmaq_id = dmaq_id;
 +	} else if (!replacing) {
 +		kfree(spec);
 +		spec = NULL;
 +	}
 +	efx_ef10_filter_set_entry(table, ins_index, spec, 0);
 +	spin_unlock_bh(&efx->filter_lock);
 +
 +	wake_up_all(&table->waitq);
 +}
 +
 +static void
 +efx_ef10_filter_rfs_expire_complete(struct efx_nic *efx,
 +				    unsigned long filter_idx,
 +				    int rc, efx_dword_t *outbuf,
 +				    size_t outlen_actual);
 +
 +static bool efx_ef10_filter_rfs_expire_one(struct efx_nic *efx, u32 flow_id,
 +					   unsigned int filter_idx)
 +{
 +	struct efx_ef10_filter_table *table = efx->filter_state;
 +	struct efx_filter_spec *spec =
 +		efx_ef10_filter_entry_spec(table, filter_idx);
 +	MCDI_DECLARE_BUF(inbuf,
 +			 MC_CMD_FILTER_OP_IN_HANDLE_OFST +
 +			 MC_CMD_FILTER_OP_IN_HANDLE_LEN);
 +
 +	if (!spec ||
 +	    (table->entry[filter_idx].spec & EFX_EF10_FILTER_FLAG_BUSY) ||
 +	    spec->priority != EFX_FILTER_PRI_HINT ||
 +	    !rps_may_expire_flow(efx->net_dev, spec->dmaq_id,
 +				 flow_id, filter_idx))
 +		return false;
 +
 +	MCDI_SET_DWORD(inbuf, FILTER_OP_IN_OP,
 +		       MC_CMD_FILTER_OP_IN_OP_REMOVE);
 +	MCDI_SET_QWORD(inbuf, FILTER_OP_IN_HANDLE,
 +		       table->entry[filter_idx].handle);
 +	if (efx_mcdi_rpc_async(efx, MC_CMD_FILTER_OP, inbuf, sizeof(inbuf), 0,
 +			       efx_ef10_filter_rfs_expire_complete, filter_idx))
 +		return false;
 +
 +	table->entry[filter_idx].spec |= EFX_EF10_FILTER_FLAG_BUSY;
 +	return true;
 +}
 +
 +static void
 +efx_ef10_filter_rfs_expire_complete(struct efx_nic *efx,
 +				    unsigned long filter_idx,
 +				    int rc, efx_dword_t *outbuf,
 +				    size_t outlen_actual)
 +{
 +	struct efx_ef10_filter_table *table = efx->filter_state;
 +	struct efx_filter_spec *spec =
 +		efx_ef10_filter_entry_spec(table, filter_idx);
 +
 +	spin_lock_bh(&efx->filter_lock);
 +	if (rc == 0) {
 +		kfree(spec);
 +		efx_ef10_filter_set_entry(table, filter_idx, NULL, 0);
 +	}
++<<<<<<< HEAD
 +	table->entry[filter_idx].spec &= ~EFX_EF10_FILTER_FLAG_BUSY;
 +	wake_up_all(&table->waitq);
 +	spin_unlock_bh(&efx->filter_lock);
++=======
+ 	if (!rps_may_expire_flow(efx->net_dev, spec->dmaq_id, flow_id, arfs_id))
+ 		ret = false;
+ 	else if (rule)
+ 		rule->filter_id = EFX_ARFS_FILTER_ID_REMOVING;
+ expire:
+ 	saved_spec = *spec; /* remove operation will kfree spec */
+ 	spin_unlock_bh(&efx->rps_hash_lock);
+ 	/* At this point (since we dropped the lock), another thread might queue
+ 	 * up a fresh insertion request (but the actual insertion will be held
+ 	 * up by our possession of the filter table lock).  In that case, it
+ 	 * will set rule->filter_id to EFX_ARFS_FILTER_ID_PENDING, meaning that
+ 	 * the rule is not removed by efx_rps_hash_del() below.
+ 	 */
+ 	if (ret)
+ 		ret = efx_ef10_filter_remove_internal(efx, 1U << spec->priority,
+ 						      filter_idx, true) == 0;
+ 	/* While we can't safely dereference rule (we dropped the lock), we can
+ 	 * still test it for NULL.
+ 	 */
+ 	if (ret && rule) {
+ 		/* Expiring, so remove entry from ARFS table */
+ 		spin_lock_bh(&efx->rps_hash_lock);
+ 		efx_rps_hash_del(efx, &saved_spec);
+ 		spin_unlock_bh(&efx->rps_hash_lock);
+ 	}
+ out_unlock:
+ 	up_write(&table->lock);
+ 	up_read(&efx->filter_sem);
+ 	return ret;
++>>>>>>> 987c658a61f4 (sfc: fix ARFS expiry check on EF10)
  }
  
  #endif /* CONFIG_RFS_ACCEL */
* Unmerged path drivers/net/ethernet/sfc/ef10.c
