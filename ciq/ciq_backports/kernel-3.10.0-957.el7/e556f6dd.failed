net/mlx5e: Keep updating ethtool statistics when the interface is down

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [netdrv] mlx5e: Keep updating ethtool statistics when the interface is down (Alaa Hleihel) [1520297]
Rebuild_FUZZ: 97.06%
commit-author Gal Pressman <galp@mellanox.com>
commit e556f6dd47eda62cbb046fa92e03265245a1537f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/e556f6dd.failed

ethtool statistics should be updated even when the interface is down
since it shows more than just netdev counters, which might change while
the logical link is down.
One useful use case, for example, is when running RoCE traffic over the
interface (while the logical link is down, but physical link is up) and
examining rx_prioX_bytes.

Fixes: f62b8bb8f2d3 ("net/mlx5: Extend mlx5_core to support ConnectX-4 Ethernet functionality")
	Signed-off-by: Gal Pressman <galp@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit e556f6dd47eda62cbb046fa92e03265245a1537f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
index 4b10afbe7ede,ea5fff2c3143..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
@@@ -349,104 -207,11 +349,108 @@@ void mlx5e_ethtool_get_ethtool_stats(st
  		return;
  
  	mutex_lock(&priv->state_lock);
++<<<<<<< HEAD
 +	if (test_bit(MLX5E_STATE_OPENED, &priv->state))
 +		mlx5e_update_stats(priv, true);
 +	channels = &priv->channels;
++=======
+ 	mlx5e_update_stats(priv, true);
++>>>>>>> e556f6dd47ed (net/mlx5e: Keep updating ethtool statistics when the interface is down)
  	mutex_unlock(&priv->state_lock);
  
 -	for (i = 0; i < mlx5e_num_stats_grps; i++)
 -		idx = mlx5e_stats_grps[i].fill_stats(priv, data, idx);
 +	for (i = 0; i < NUM_SW_COUNTERS; i++)
 +		data[idx++] = MLX5E_READ_CTR64_CPU(&priv->stats.sw,
 +						   sw_stats_desc, i);
 +
 +	for (i = 0; i < MLX5E_NUM_Q_CNTRS(priv); i++)
 +		data[idx++] = MLX5E_READ_CTR32_CPU(&priv->stats.qcnt,
 +						   q_stats_desc, i);
 +
 +	for (i = 0; i < NUM_VPORT_COUNTERS; i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(priv->stats.vport.query_vport_out,
 +						  vport_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PPORT_802_3_COUNTERS; i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.IEEE_802_3_counters,
 +						  pport_802_3_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PPORT_2863_COUNTERS; i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.RFC_2863_counters,
 +						  pport_2863_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PPORT_2819_COUNTERS; i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.RFC_2819_counters,
 +						  pport_2819_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PPORT_PHY_STATISTICAL_COUNTERS(priv); i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.phy_statistical_counters,
 +						  pport_phy_statistical_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PPORT_ETH_EXT_COUNTERS(priv); i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.eth_ext_counters,
 +						  pport_eth_ext_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PCIE_PERF_COUNTERS(priv); i++)
 +		data[idx++] = MLX5E_READ_CTR32_BE(&priv->stats.pcie.pcie_perf_counters,
 +						  pcie_perf_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PCIE_PERF_COUNTERS64(priv); i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pcie.pcie_perf_counters,
 +						  pcie_perf_stats_desc64, i);
 +
 +	for (i = 0; i < NUM_PCIE_PERF_STALL_COUNTERS(priv); i++)
 +		data[idx++] = MLX5E_READ_CTR32_BE(&priv->stats.pcie.pcie_perf_counters,
 +						  pcie_perf_stall_stats_desc, i);
 +
 +	for (prio = 0; prio < NUM_PPORT_PRIO; prio++) {
 +		for (i = 0; i < NUM_PPORT_PER_PRIO_TRAFFIC_COUNTERS; i++)
 +			data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.per_prio_counters[prio],
 +						 pport_per_prio_traffic_stats_desc, i);
 +	}
 +
 +	pfc_combined = mlx5e_query_pfc_combined(priv);
 +	for_each_set_bit(prio, &pfc_combined, NUM_PPORT_PRIO) {
 +		for (i = 0; i < NUM_PPORT_PER_PRIO_PFC_COUNTERS; i++) {
 +			data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.per_prio_counters[prio],
 +							  pport_per_prio_pfc_stats_desc, i);
 +		}
 +	}
 +
 +	if (mlx5e_query_global_pause_combined(priv)) {
 +		for (i = 0; i < NUM_PPORT_PER_PRIO_PFC_COUNTERS; i++) {
 +			data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.per_prio_counters[0],
 +							  pport_per_prio_pfc_stats_desc, i);
 +		}
 +	}
 +
 +	/* port module event counters */
 +	mlx5_priv =  &priv->mdev->priv;
 +	for (i = 0; i < ARRAY_SIZE(mlx5e_pme_status_desc); i++)
 +		data[idx++] = MLX5E_READ_CTR64_CPU(mlx5_priv->pme_stats.status_counters,
 +						   mlx5e_pme_status_desc, i);
 +
 +	for (i = 0; i < ARRAY_SIZE(mlx5e_pme_error_desc); i++)
 +		data[idx++] = MLX5E_READ_CTR64_CPU(mlx5_priv->pme_stats.error_counters,
 +						   mlx5e_pme_error_desc, i);
 +
 +	/* IPSec counters */
 +	idx += mlx5e_ipsec_get_stats(priv, data + idx);
 +
 +	if (!test_bit(MLX5E_STATE_OPENED, &priv->state))
 +		return;
 +
 +	/* per channel counters */
 +	for (i = 0; i < channels->num; i++)
 +		for (j = 0; j < NUM_RQ_STATS; j++)
 +			data[idx++] =
 +			       MLX5E_READ_CTR64_CPU(&channels->c[i]->rq.stats,
 +						    rq_stats_desc, j);
 +
 +	for (tc = 0; tc < priv->channels.params.num_tc; tc++)
 +		for (i = 0; i < channels->num; i++)
 +			for (j = 0; j < NUM_SQ_STATS; j++)
 +				data[idx++] = MLX5E_READ_CTR64_CPU(&channels->c[i]->sq[tc].stats,
 +								   sq_stats_desc, j);
  }
  
  static void mlx5e_get_ethtool_stats(struct net_device *dev,
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
