x86/KVM/VMX: Add find_msr() helper function

jira LE-1907
cve CVE-2018-3620
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [x86] kvm/vmx: add find_msr() helper function (Christoph von Recklinghausen) [1593384] {CVE-2018-3620}
Rebuild_FUZZ: 95.12%
commit-author Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
commit ca83b4a7f2d068da79a029d323024aa45decb250
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/ca83b4a7.failed

.. to help find the MSR on either the guest or host MSR list.

	Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

(cherry picked from commit ca83b4a7f2d068da79a029d323024aa45decb250)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/vmx.c
diff --cc arch/x86/kvm/vmx.c
index e2f48f8aba96,e18805f8ed31..000000000000
--- a/arch/x86/kvm/vmx.c
+++ b/arch/x86/kvm/vmx.c
@@@ -1876,18 -2455,15 +1887,23 @@@ static void clear_atomic_switch_msr(str
  		}
  		break;
  	}
++<<<<<<< HEAD
 +
 +	for (i = 0; i < m->nr; ++i)
 +		if (m->guest[i].index == msr)
 +			break;
 +
 +	if (i == m->nr)
++=======
+ 	i = find_msr(&m->guest, msr);
+ 	if (i < 0)
++>>>>>>> ca83b4a7f2d0 (x86/KVM/VMX: Add find_msr() helper function)
  		return;
 -	--m->guest.nr;
 -	--m->host.nr;
 -	m->guest.val[i] = m->guest.val[m->guest.nr];
 -	m->host.val[i] = m->host.val[m->host.nr];
 -	vmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, m->guest.nr);
 -	vmcs_write32(VM_EXIT_MSR_LOAD_COUNT, m->host.nr);
 +	--m->nr;
 +	m->guest[i] = m->guest[m->nr];
 +	m->host[i] = m->host[m->nr];
 +	vmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, m->nr);
 +	vmcs_write32(VM_EXIT_MSR_LOAD_COUNT, m->nr);
  }
  
  static void add_atomic_switch_msr_special(struct vcpu_vmx *vmx,
@@@ -1939,37 -2515,22 +1955,49 @@@ static void add_atomic_switch_msr(struc
  		wrmsrl(MSR_IA32_PEBS_ENABLE, 0);
  	}
  
++<<<<<<< HEAD
 +	for (i = 0; i < m->nr; ++i)
 +		if (m->guest[i].index == msr)
 +			break;
 +
++=======
+ 	i = find_msr(&m->guest, msr);
++>>>>>>> ca83b4a7f2d0 (x86/KVM/VMX: Add find_msr() helper function)
  	if (i == NR_AUTOLOAD_MSRS) {
  		printk_once(KERN_WARNING "Not enough msr switch entries. "
  				"Can't add msr %x\n", msr);
  		return;
++<<<<<<< HEAD
 +	} else if (i == m->nr) {
 +		++m->nr;
 +		vmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, m->nr);
 +		vmcs_write32(VM_EXIT_MSR_LOAD_COUNT, m->nr);
++=======
+ 	} else if (i < 0) {
+ 		i = m->guest.nr++;
+ 		++m->host.nr;
+ 		vmcs_write32(VM_ENTRY_MSR_LOAD_COUNT, m->guest.nr);
+ 		vmcs_write32(VM_EXIT_MSR_LOAD_COUNT, m->host.nr);
++>>>>>>> ca83b4a7f2d0 (x86/KVM/VMX: Add find_msr() helper function)
  	}
  
 -	m->guest.val[i].index = msr;
 -	m->guest.val[i].value = guest_val;
 -	m->host.val[i].index = msr;
 -	m->host.val[i].value = host_val;
 +	m->guest[i].index = msr;
 +	m->guest[i].value = guest_val;
 +	m->host[i].index = msr;
 +	m->host[i].value = host_val;
 +}
 +
 +static void reload_tss(void)
 +{
 +	/*
 +	 * VT restores TR but not its size.  Useless.
 +	 */
 +	struct desc_ptr *gdt = this_cpu_ptr(&host_gdt);
 +	struct desc_struct *descs;
 +
 +	descs = (void *)gdt->address;
 +	descs[GDT_ENTRY_TSS].type = 9; /* available TSS */
 +	load_TR_desc();
  }
  
  static bool update_transition_efer(struct vcpu_vmx *vmx, int efer_offset)
* Unmerged path arch/x86/kvm/vmx.c
