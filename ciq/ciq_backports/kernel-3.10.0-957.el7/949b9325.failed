memremap: fix softlockup reports at teardown

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Dan Williams <dan.j.williams@intel.com>
commit 949b93250a566cc7a578b4f829cf76b70d19a62c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/949b9325.failed

The cond_resched() currently in the setup path needs to be duplicated in
the teardown path. Rather than require each instance of
for_each_device_pfn() to open code the same sequence, embed it in the
helper.

Link: https://github.com/intel/ixpdimm_sw/issues/11
	Cc: "Jérôme Glisse" <jglisse@redhat.com>
	Cc: Michal Hocko <mhocko@suse.com>
	Cc: Christoph Hellwig <hch@lst.de>
	Cc: <stable@vger.kernel.org>
Fixes: 71389703839e ("mm, zone_device: Replace {get, put}_zone_device_page()...")
	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
(cherry picked from commit 949b93250a566cc7a578b4f829cf76b70d19a62c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/memremap.c
diff --cc kernel/memremap.c
index eca98ec515d8,4dd4274cabe2..000000000000
--- a/kernel/memremap.c
+++ b/kernel/memremap.c
@@@ -305,15 -275,26 +305,22 @@@ static unsigned long pfn_end(struct pag
  	return (res->start + resource_size(res)) >> PAGE_SHIFT;
  }
  
+ static unsigned long pfn_next(unsigned long pfn)
+ {
+ 	if (pfn % 1024 == 0)
+ 		cond_resched();
+ 	return pfn + 1;
+ }
+ 
  #define for_each_device_pfn(pfn, map) \
- 	for (pfn = pfn_first(map); pfn < pfn_end(map); pfn++)
+ 	for (pfn = pfn_first(map); pfn < pfn_end(map); pfn = pfn_next(pfn))
  
 -static void devm_memremap_pages_release(void *data)
 +static void devm_memremap_pages_release(struct device *dev, void *data)
  {
 -	struct dev_pagemap *pgmap = data;
 -	struct device *dev = pgmap->dev;
 -	struct resource *res = &pgmap->res;
 +	struct page_map *page_map = data;
 +	struct resource *res = &page_map->res;
  	resource_size_t align_start, align_size;
 -	unsigned long pfn;
 -
 -	for_each_device_pfn(pfn, pgmap)
 -		put_page(pfn_to_page(pfn));
 +	struct dev_pagemap *pgmap = &page_map->pgmap;
  
  	if (percpu_ref_tryget_live(pgmap->ref)) {
  		dev_WARN(dev, "%s: page mapping is still live!\n", __func__);
@@@ -359,14 -339,14 +366,22 @@@ struct dev_pagemap *find_dev_pagemap(re
   *    treated as a "System RAM" range, i.e. not a device mmio range, but
   *    this is not enforced.
   */
 -void *devm_memremap_pages(struct device *dev, struct dev_pagemap *pgmap)
 +void *devm_memremap_pages(struct device *dev, struct resource *res,
 +		struct percpu_ref *ref, struct vmem_altmap *altmap)
  {
  	resource_size_t align_start, align_size, align_end;
++<<<<<<< HEAD
 +	unsigned long pfn, pgoff, order;
 +	pgprot_t pgprot = PAGE_KERNEL;
 +	struct dev_pagemap *pgmap;
 +	struct page_map *page_map;
++=======
+ 	struct vmem_altmap *altmap = pgmap->altmap_valid ?
+ 			&pgmap->altmap : NULL;
+ 	struct resource *res = &pgmap->res;
+ 	unsigned long pfn, pgoff, order;
+ 	pgprot_t pgprot = PAGE_KERNEL;
++>>>>>>> 949b93250a56 (memremap: fix softlockup reports at teardown)
  	int error, nid, is_ram;
  
  	align_start = res->start & ~(SECTION_SIZE - 1);
@@@ -454,8 -415,11 +469,12 @@@
  		 */
  		list_del(&page->lru);
  		page->pgmap = pgmap;
++<<<<<<< HEAD
++=======
+ 		percpu_ref_get(pgmap->ref);
++>>>>>>> 949b93250a56 (memremap: fix softlockup reports at teardown)
  	}
 -
 -	devm_add_action(dev, devm_memremap_pages_release, pgmap);
 -
 +	devres_add(dev, page_map);
  	return __va(res->start);
  
   err_add_memory:
* Unmerged path kernel/memremap.c
