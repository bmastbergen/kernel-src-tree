x86/CPU/AMD: Move TOPOEXT reenablement before reading smp_num_siblings

jira LE-1907
cve CVE-2018-3620
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [x86] cpu/amd: move topoext reenablement before reading smp_num_siblings (Christoph von Recklinghausen) [1593384] {CVE-2018-3620}
Rebuild_FUZZ: 97.06%
commit-author Borislav Petkov <bp@suse.de>
commit 7ce2f0393ea2396142b7faf6ee9b1f3676d08a5f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/7ce2f039.failed

The TOPOEXT reenablement is a workaround for broken BIOSen which didn't
enable the CPUID bit. amd_get_topology_early(), however, relies on
that bit being set so that it can read out the CPUID leaf and set
smp_num_siblings properly.

Move the reenablement up to early_init_amd(). While at it, simplify
amd_get_topology_early().

	Signed-off-by: Borislav Petkov <bp@suse.de>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
(cherry picked from commit 7ce2f0393ea2396142b7faf6ee9b1f3676d08a5f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/amd.c
diff --cc arch/x86/kernel/cpu/amd.c
index ec77a1caf239,74061e421e62..000000000000
--- a/arch/x86/kernel/cpu/amd.c
+++ b/arch/x86/kernel/cpu/amd.c
@@@ -309,6 -315,13 +309,16 @@@ static void legacy_fixup_core_id(struc
  	c->cpu_core_id %= cus_per_node;
  }
  
++<<<<<<< HEAD
++=======
+ 
+ static void amd_get_topology_early(struct cpuinfo_x86 *c)
+ {
+ 	if (cpu_has(c, X86_FEATURE_TOPOEXT))
+ 		smp_num_siblings = ((cpuid_ebx(0x8000001e) >> 8) & 0xff) + 1;
+ }
+ 
++>>>>>>> 7ce2f0393ea2 (x86/CPU/AMD: Move TOPOEXT reenablement before reading smp_num_siblings)
  /*
   * Fixup core topology information for
   * (1) AMD multi-node processors
@@@ -326,10 -339,8 +336,9 @@@ static void amd_get_topology(struct cpu
  		u32 eax, ebx, ecx, edx;
  
  		cpuid(0x8000001e, &eax, &ebx, &ecx, &edx);
 +		nodes_per_socket = ((ecx >> 8) & 7) + 1;
  
  		node_id  = ecx & 0xff;
- 		smp_num_siblings = ((ebx >> 8) & 0xff) + 1;
  
  		if (c->x86 == 0x15)
  			c->cu_id = ebx & 0xff;
@@@ -553,35 -674,63 +563,77 @@@ static void early_init_amd(struct cpuin
  	 */
  	set_cpu_cap(c, X86_FEATURE_VMMCALL);
  
 -	/* F16h erratum 793, CVE-2013-6885 */
 -	if (c->x86 == 0x16 && c->x86_model <= 0xf)
 -		msr_set_bit(MSR_AMD64_LS_CFG, 15);
 -
  	/*
 -	 * Check whether the machine is affected by erratum 400. This is
 -	 * used to select the proper idle routine and to enable the check
 -	 * whether the machine is affected in arch_post_acpi_init(), which
 -	 * sets the X86_BUG_AMD_APIC_C1E bug depending on the MSR check.
 +	 * BIOS support is required for SME. If BIOS has enabled SME then
 +	 * adjust x86_phys_bits by the SME physical address space reduction
 +	 * value. If BIOS has not enabled SME then don't advertise the
 +	 * feature (set in scattered.c). Also, since the SME support requires
 +	 * long mode, don't advertise the feature under CONFIG_X86_32.
  	 */
 -	if (cpu_has_amd_erratum(c, amd_erratum_400))
 -		set_cpu_bug(c, X86_BUG_AMD_E400);
 +	if (cpu_has(c, X86_FEATURE_SME)) {
 +		u64 msr;
  
++<<<<<<< HEAD
 +		/* Check if SME is enabled */
 +		rdmsrl(MSR_K8_SYSCFG, msr);
 +		if (msr & MSR_K8_SYSCFG_MEM_ENCRYPT) {
 +			c->x86_phys_bits -= (cpuid_ebx(0x8000001f) >> 6) & 0x3f;
 +			if (IS_ENABLED(CONFIG_X86_32))
 +				clear_cpu_cap(c, X86_FEATURE_SME);
 +		} else {
 +			clear_cpu_cap(c, X86_FEATURE_SME);
++=======
+ 	early_detect_mem_encrypt(c);
+ 
+ 	/* Re-enable TopologyExtensions if switched off by BIOS */
+ 	if (c->x86 == 0x15 &&
+ 	    (c->x86_model >= 0x10 && c->x86_model <= 0x6f) &&
+ 	    !cpu_has(c, X86_FEATURE_TOPOEXT)) {
+ 
+ 		if (msr_set_bit(0xc0011005, 54) > 0) {
+ 			rdmsrl(0xc0011005, value);
+ 			if (value & BIT_64(54)) {
+ 				set_cpu_cap(c, X86_FEATURE_TOPOEXT);
+ 				pr_info_once(FW_INFO "CPU: Re-enabling disabled Topology Extensions Support.\n");
+ 			}
+ 		}
+ 	}
+ 
+ 	amd_get_topology_early(c);
+ }
+ 
+ static void init_amd_k8(struct cpuinfo_x86 *c)
+ {
+ 	u32 level;
+ 	u64 value;
+ 
+ 	/* On C+ stepping K8 rep microcode works well for copy/memset */
+ 	level = cpuid_eax(1);
+ 	if ((level >= 0x0f48 && level < 0x0f50) || level >= 0x0f58)
+ 		set_cpu_cap(c, X86_FEATURE_REP_GOOD);
+ 
+ 	/*
+ 	 * Some BIOSes incorrectly force this feature, but only K8 revision D
+ 	 * (model = 0x14) and later actually support it.
+ 	 * (AMD Erratum #110, docId: 25759).
+ 	 */
+ 	if (c->x86_model < 0x14 && cpu_has(c, X86_FEATURE_LAHF_LM)) {
+ 		clear_cpu_cap(c, X86_FEATURE_LAHF_LM);
+ 		if (!rdmsrl_amd_safe(0xc001100d, &value)) {
+ 			value &= ~BIT_64(32);
+ 			wrmsrl_amd_safe(0xc001100d, value);
++>>>>>>> 7ce2f0393ea2 (x86/CPU/AMD: Move TOPOEXT reenablement before reading smp_num_siblings)
  		}
  	}
 +}
 +
 +static const int amd_erratum_383[];
 +static const int amd_erratum_400[];
 +static bool cpu_has_amd_erratum(struct cpuinfo_x86 *cpu, const int *erratum);
  
 -	if (!c->x86_model_id[0])
 -		strcpy(c->x86_model_id, "Hammer");
 +static void init_amd(struct cpuinfo_x86 *c)
 +{
 +	unsigned long long value;
  
  #ifdef CONFIG_SMP
  	/*
@@@ -591,12 -740,86 +643,95 @@@
  	 * Errata 63 for SH-B3 steppings
  	 * Errata 122 for all steppings (F+ have it disabled by default)
  	 */
++<<<<<<< HEAD
 +	if (c->x86 == 0xf) {
 +		rdmsrl(MSR_K7_HWCR, value);
 +		value |= 1 << 6;
 +		wrmsrl(MSR_K7_HWCR, value);
 +	}
 +#endif
++=======
+ 	msr_set_bit(MSR_K7_HWCR, 6);
+ #endif
+ 	set_cpu_bug(c, X86_BUG_SWAPGS_FENCE);
+ }
+ 
+ static void init_amd_gh(struct cpuinfo_x86 *c)
+ {
+ #ifdef CONFIG_MMCONF_FAM10H
+ 	/* do this for boot cpu */
+ 	if (c == &boot_cpu_data)
+ 		check_enable_amd_mmconf_dmi();
+ 
+ 	fam10h_check_enable_mmcfg();
+ #endif
+ 
+ 	/*
+ 	 * Disable GART TLB Walk Errors on Fam10h. We do this here because this
+ 	 * is always needed when GART is enabled, even in a kernel which has no
+ 	 * MCE support built in. BIOS should disable GartTlbWlk Errors already.
+ 	 * If it doesn't, we do it here as suggested by the BKDG.
+ 	 *
+ 	 * Fixes: https://bugzilla.kernel.org/show_bug.cgi?id=33012
+ 	 */
+ 	msr_set_bit(MSR_AMD64_MCx_MASK(4), 10);
+ 
+ 	/*
+ 	 * On family 10h BIOS may not have properly enabled WC+ support, causing
+ 	 * it to be converted to CD memtype. This may result in performance
+ 	 * degradation for certain nested-paging guests. Prevent this conversion
+ 	 * by clearing bit 24 in MSR_AMD64_BU_CFG2.
+ 	 *
+ 	 * NOTE: we want to use the _safe accessors so as not to #GP kvm
+ 	 * guests on older kvm hosts.
+ 	 */
+ 	msr_clear_bit(MSR_AMD64_BU_CFG2, 24);
+ 
+ 	if (cpu_has_amd_erratum(c, amd_erratum_383))
+ 		set_cpu_bug(c, X86_BUG_AMD_TLB_MMATCH);
+ }
+ 
+ #define MSR_AMD64_DE_CFG	0xC0011029
+ 
+ static void init_amd_ln(struct cpuinfo_x86 *c)
+ {
+ 	/*
+ 	 * Apply erratum 665 fix unconditionally so machines without a BIOS
+ 	 * fix work.
+ 	 */
+ 	msr_set_bit(MSR_AMD64_DE_CFG, 31);
+ }
+ 
+ static void init_amd_bd(struct cpuinfo_x86 *c)
+ {
+ 	u64 value;
+ 
+ 	/*
+ 	 * The way access filter has a performance penalty on some workloads.
+ 	 * Disable it on the affected CPUs.
+ 	 */
+ 	if ((c->x86_model >= 0x02) && (c->x86_model < 0x20)) {
+ 		if (!rdmsrl_safe(MSR_F15H_IC_CFG, &value) && !(value & 0x1E)) {
+ 			value |= 0x1E;
+ 			wrmsrl_safe(MSR_F15H_IC_CFG, value);
+ 		}
+ 	}
+ }
+ 
+ static void init_amd_zn(struct cpuinfo_x86 *c)
+ {
+ 	set_cpu_cap(c, X86_FEATURE_ZEN);
+ 	/*
+ 	 * Fix erratum 1076: CPB feature bit not being set in CPUID. It affects
+ 	 * all up to and including B1.
+ 	 */
+ 	if (c->x86_model <= 1 && c->x86_stepping <= 1)
+ 		set_cpu_cap(c, X86_FEATURE_CPB);
+ }
+ 
+ static void init_amd(struct cpuinfo_x86 *c)
+ {
++>>>>>>> 7ce2f0393ea2 (x86/CPU/AMD: Move TOPOEXT reenablement before reading smp_num_siblings)
  	early_init_amd(c);
  
  	/*
* Unmerged path arch/x86/kernel/cpu/amd.c
