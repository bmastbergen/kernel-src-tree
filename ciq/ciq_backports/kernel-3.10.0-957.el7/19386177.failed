net/mlx5e: Extend the stats group API to have update_stats()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [netdrv] mlx5e: Extend the stats group API to have update_stats() (Alaa Hleihel) [1520297]
Rebuild_FUZZ: 96.55%
commit-author Kamal Heib <kamalh@mellanox.com>
commit 193861773534a5711aa439d97eba3515310bb586
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/19386177.failed

Extend the stats group API to have an update_stats() callback which
will be used to fetch the hardware or software counters data.

	Signed-off-by: Kamal Heib <kamalh@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 193861773534a5711aa439d97eba3515310bb586)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_main.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_stats.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_stats.h
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
index 70bcc77ec46b,cc8048f68f11..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
@@@ -349,104 -207,11 +349,108 @@@ void mlx5e_ethtool_get_ethtool_stats(st
  		return;
  
  	mutex_lock(&priv->state_lock);
++<<<<<<< HEAD
 +	if (test_bit(MLX5E_STATE_OPENED, &priv->state))
 +		mlx5e_update_stats(priv, true);
 +	channels = &priv->channels;
++=======
+ 	mlx5e_update_stats(priv);
++>>>>>>> 193861773534 (net/mlx5e: Extend the stats group API to have update_stats())
  	mutex_unlock(&priv->state_lock);
  
 -	for (i = 0; i < mlx5e_num_stats_grps; i++)
 -		idx = mlx5e_stats_grps[i].fill_stats(priv, data, idx);
 +	for (i = 0; i < NUM_SW_COUNTERS; i++)
 +		data[idx++] = MLX5E_READ_CTR64_CPU(&priv->stats.sw,
 +						   sw_stats_desc, i);
 +
 +	for (i = 0; i < MLX5E_NUM_Q_CNTRS(priv); i++)
 +		data[idx++] = MLX5E_READ_CTR32_CPU(&priv->stats.qcnt,
 +						   q_stats_desc, i);
 +
 +	for (i = 0; i < NUM_VPORT_COUNTERS; i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(priv->stats.vport.query_vport_out,
 +						  vport_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PPORT_802_3_COUNTERS; i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.IEEE_802_3_counters,
 +						  pport_802_3_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PPORT_2863_COUNTERS; i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.RFC_2863_counters,
 +						  pport_2863_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PPORT_2819_COUNTERS; i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.RFC_2819_counters,
 +						  pport_2819_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PPORT_PHY_STATISTICAL_COUNTERS(priv); i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.phy_statistical_counters,
 +						  pport_phy_statistical_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PPORT_ETH_EXT_COUNTERS(priv); i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.eth_ext_counters,
 +						  pport_eth_ext_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PCIE_PERF_COUNTERS(priv); i++)
 +		data[idx++] = MLX5E_READ_CTR32_BE(&priv->stats.pcie.pcie_perf_counters,
 +						  pcie_perf_stats_desc, i);
 +
 +	for (i = 0; i < NUM_PCIE_PERF_COUNTERS64(priv); i++)
 +		data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pcie.pcie_perf_counters,
 +						  pcie_perf_stats_desc64, i);
 +
 +	for (i = 0; i < NUM_PCIE_PERF_STALL_COUNTERS(priv); i++)
 +		data[idx++] = MLX5E_READ_CTR32_BE(&priv->stats.pcie.pcie_perf_counters,
 +						  pcie_perf_stall_stats_desc, i);
 +
 +	for (prio = 0; prio < NUM_PPORT_PRIO; prio++) {
 +		for (i = 0; i < NUM_PPORT_PER_PRIO_TRAFFIC_COUNTERS; i++)
 +			data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.per_prio_counters[prio],
 +						 pport_per_prio_traffic_stats_desc, i);
 +	}
 +
 +	pfc_combined = mlx5e_query_pfc_combined(priv);
 +	for_each_set_bit(prio, &pfc_combined, NUM_PPORT_PRIO) {
 +		for (i = 0; i < NUM_PPORT_PER_PRIO_PFC_COUNTERS; i++) {
 +			data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.per_prio_counters[prio],
 +							  pport_per_prio_pfc_stats_desc, i);
 +		}
 +	}
 +
 +	if (mlx5e_query_global_pause_combined(priv)) {
 +		for (i = 0; i < NUM_PPORT_PER_PRIO_PFC_COUNTERS; i++) {
 +			data[idx++] = MLX5E_READ_CTR64_BE(&priv->stats.pport.per_prio_counters[0],
 +							  pport_per_prio_pfc_stats_desc, i);
 +		}
 +	}
 +
 +	/* port module event counters */
 +	mlx5_priv =  &priv->mdev->priv;
 +	for (i = 0; i < ARRAY_SIZE(mlx5e_pme_status_desc); i++)
 +		data[idx++] = MLX5E_READ_CTR64_CPU(mlx5_priv->pme_stats.status_counters,
 +						   mlx5e_pme_status_desc, i);
 +
 +	for (i = 0; i < ARRAY_SIZE(mlx5e_pme_error_desc); i++)
 +		data[idx++] = MLX5E_READ_CTR64_CPU(mlx5_priv->pme_stats.error_counters,
 +						   mlx5e_pme_error_desc, i);
 +
 +	/* IPSec counters */
 +	idx += mlx5e_ipsec_get_stats(priv, data + idx);
 +
 +	if (!test_bit(MLX5E_STATE_OPENED, &priv->state))
 +		return;
 +
 +	/* per channel counters */
 +	for (i = 0; i < channels->num; i++)
 +		for (j = 0; j < NUM_RQ_STATS; j++)
 +			data[idx++] =
 +			       MLX5E_READ_CTR64_CPU(&channels->c[i]->rq.stats,
 +						    rq_stats_desc, j);
 +
 +	for (tc = 0; tc < priv->channels.params.num_tc; tc++)
 +		for (i = 0; i < channels->num; i++)
 +			for (j = 0; j < NUM_SQ_STATS; j++)
 +				data[idx++] = MLX5E_READ_CTR64_CPU(&channels->c[i]->sq[tc].stats,
 +								   sq_stats_desc, j);
  }
  
  static void mlx5e_get_ethtool_stats(struct net_device *dev,
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_main.c
index 22c2b5464142,8530c770c873..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_main.c
@@@ -170,172 -173,13 +170,180 @@@ unlock
  	rtnl_unlock();
  }
  
- static void mlx5e_update_sw_counters(struct mlx5e_priv *priv)
+ void mlx5e_update_stats(struct mlx5e_priv *priv)
  {
++<<<<<<< HEAD
 +	struct mlx5e_sw_stats temp, *s = &temp;
 +	struct mlx5e_rq_stats *rq_stats;
 +	struct mlx5e_sq_stats *sq_stats;
 +	int i, j;
 +
 +	memset(s, 0, sizeof(*s));
 +	for (i = 0; i < priv->channels.num; i++) {
 +		struct mlx5e_channel *c = priv->channels.c[i];
 +
 +		rq_stats = &c->rq.stats;
 +
 +		s->rx_packets	+= rq_stats->packets;
 +		s->rx_bytes	+= rq_stats->bytes;
 +		s->rx_lro_packets += rq_stats->lro_packets;
 +		s->rx_lro_bytes	+= rq_stats->lro_bytes;
 +		s->rx_csum_none	+= rq_stats->csum_none;
 +		s->rx_csum_complete += rq_stats->csum_complete;
 +		s->rx_csum_unnecessary += rq_stats->csum_unnecessary;
 +		s->rx_csum_unnecessary_inner += rq_stats->csum_unnecessary_inner;
 +		s->rx_wqe_err   += rq_stats->wqe_err;
 +		s->rx_mpwqe_filler += rq_stats->mpwqe_filler;
 +		s->rx_buff_alloc_err += rq_stats->buff_alloc_err;
 +		s->rx_cqe_compress_blks += rq_stats->cqe_compress_blks;
 +		s->rx_cqe_compress_pkts += rq_stats->cqe_compress_pkts;
 +		s->rx_page_reuse  += rq_stats->page_reuse;
 +		s->rx_cache_reuse += rq_stats->cache_reuse;
 +		s->rx_cache_full  += rq_stats->cache_full;
 +		s->rx_cache_empty += rq_stats->cache_empty;
 +		s->rx_cache_busy  += rq_stats->cache_busy;
 +		s->rx_cache_waive += rq_stats->cache_waive;
 +
 +		for (j = 0; j < priv->channels.params.num_tc; j++) {
 +			sq_stats = &c->sq[j].stats;
 +
 +			s->tx_packets		+= sq_stats->packets;
 +			s->tx_bytes		+= sq_stats->bytes;
 +			s->tx_tso_packets	+= sq_stats->tso_packets;
 +			s->tx_tso_bytes		+= sq_stats->tso_bytes;
 +			s->tx_tso_inner_packets	+= sq_stats->tso_inner_packets;
 +			s->tx_tso_inner_bytes	+= sq_stats->tso_inner_bytes;
 +			s->tx_queue_stopped	+= sq_stats->stopped;
 +			s->tx_queue_wake	+= sq_stats->wake;
 +			s->tx_queue_dropped	+= sq_stats->dropped;
 +			s->tx_xmit_more		+= sq_stats->xmit_more;
 +			s->tx_csum_partial_inner += sq_stats->csum_partial_inner;
 +			s->tx_csum_none		+= sq_stats->csum_none;
 +			s->tx_csum_partial	+= sq_stats->csum_partial;
 +		}
 +	}
 +
 +	s->link_down_events_phy = MLX5_GET(ppcnt_reg,
 +				priv->stats.pport.phy_counters,
 +				counter_set.phys_layer_cntrs.link_down_events);
 +	memcpy(&priv->stats.sw, s, sizeof(*s));
 +}
 +
 +static void mlx5e_update_vport_counters(struct mlx5e_priv *priv)
 +{
 +	int outlen = MLX5_ST_SZ_BYTES(query_vport_counter_out);
 +	u32 *out = (u32 *)priv->stats.vport.query_vport_out;
 +	u32 in[MLX5_ST_SZ_DW(query_vport_counter_in)] = {0};
 +	struct mlx5_core_dev *mdev = priv->mdev;
 +
 +	MLX5_SET(query_vport_counter_in, in, opcode,
 +		 MLX5_CMD_OP_QUERY_VPORT_COUNTER);
 +	MLX5_SET(query_vport_counter_in, in, op_mod, 0);
 +	MLX5_SET(query_vport_counter_in, in, other_vport, 0);
 +
 +	mlx5_cmd_exec(mdev, in, sizeof(in), out, outlen);
 +}
 +
 +static void mlx5e_update_pport_counters(struct mlx5e_priv *priv, bool full)
 +{
 +	struct mlx5e_pport_stats *pstats = &priv->stats.pport;
 +	struct mlx5_core_dev *mdev = priv->mdev;
 +	u32 in[MLX5_ST_SZ_DW(ppcnt_reg)] = {0};
 +	int sz = MLX5_ST_SZ_BYTES(ppcnt_reg);
 +	int prio;
 +	void *out;
 +
 +	MLX5_SET(ppcnt_reg, in, local_port, 1);
 +
 +	out = pstats->IEEE_802_3_counters;
 +	MLX5_SET(ppcnt_reg, in, grp, MLX5_IEEE_802_3_COUNTERS_GROUP);
 +	mlx5_core_access_reg(mdev, in, sz, out, sz, MLX5_REG_PPCNT, 0, 0);
 +
 +	if (!full)
 +		return;
 +
 +	out = pstats->RFC_2863_counters;
 +	MLX5_SET(ppcnt_reg, in, grp, MLX5_RFC_2863_COUNTERS_GROUP);
 +	mlx5_core_access_reg(mdev, in, sz, out, sz, MLX5_REG_PPCNT, 0, 0);
 +
 +	out = pstats->RFC_2819_counters;
 +	MLX5_SET(ppcnt_reg, in, grp, MLX5_RFC_2819_COUNTERS_GROUP);
 +	mlx5_core_access_reg(mdev, in, sz, out, sz, MLX5_REG_PPCNT, 0, 0);
 +
 +	out = pstats->phy_counters;
 +	MLX5_SET(ppcnt_reg, in, grp, MLX5_PHYSICAL_LAYER_COUNTERS_GROUP);
 +	mlx5_core_access_reg(mdev, in, sz, out, sz, MLX5_REG_PPCNT, 0, 0);
 +
 +	if (MLX5_CAP_PCAM_FEATURE(mdev, ppcnt_statistical_group)) {
 +		out = pstats->phy_statistical_counters;
 +		MLX5_SET(ppcnt_reg, in, grp, MLX5_PHYSICAL_LAYER_STATISTICAL_GROUP);
 +		mlx5_core_access_reg(mdev, in, sz, out, sz, MLX5_REG_PPCNT, 0, 0);
 +	}
 +
 +	if (MLX5_CAP_PCAM_FEATURE(mdev, rx_buffer_fullness_counters)) {
 +		out = pstats->eth_ext_counters;
 +		MLX5_SET(ppcnt_reg, in, grp, MLX5_ETHERNET_EXTENDED_COUNTERS_GROUP);
 +		mlx5_core_access_reg(mdev, in, sz, out, sz, MLX5_REG_PPCNT, 0, 0);
 +	}
 +
 +	MLX5_SET(ppcnt_reg, in, grp, MLX5_PER_PRIORITY_COUNTERS_GROUP);
 +	for (prio = 0; prio < NUM_PPORT_PRIO; prio++) {
 +		out = pstats->per_prio_counters[prio];
 +		MLX5_SET(ppcnt_reg, in, prio_tc, prio);
 +		mlx5_core_access_reg(mdev, in, sz, out, sz,
 +				     MLX5_REG_PPCNT, 0, 0);
 +	}
 +}
 +
 +static void mlx5e_update_q_counter(struct mlx5e_priv *priv)
 +{
 +	struct mlx5e_qcounter_stats *qcnt = &priv->stats.qcnt;
 +	u32 out[MLX5_ST_SZ_DW(query_q_counter_out)];
 +	int err;
 +
 +	if (!priv->q_counter)
 +		return;
 +
 +	err = mlx5_core_query_q_counter(priv->mdev, priv->q_counter, 0, out, sizeof(out));
 +	if (err)
 +		return;
 +
 +	qcnt->rx_out_of_buffer = MLX5_GET(query_q_counter_out, out, out_of_buffer);
 +}
 +
 +static void mlx5e_update_pcie_counters(struct mlx5e_priv *priv)
 +{
 +	struct mlx5e_pcie_stats *pcie_stats = &priv->stats.pcie;
 +	struct mlx5_core_dev *mdev = priv->mdev;
 +	u32 in[MLX5_ST_SZ_DW(mpcnt_reg)] = {0};
 +	int sz = MLX5_ST_SZ_BYTES(mpcnt_reg);
 +	void *out;
 +
 +	if (!MLX5_CAP_MCAM_FEATURE(mdev, pcie_performance_group))
 +		return;
 +
 +	out = pcie_stats->pcie_perf_counters;
 +	MLX5_SET(mpcnt_reg, in, grp, MLX5_PCIE_PERFORMANCE_COUNTERS_GROUP);
 +	mlx5_core_access_reg(mdev, in, sz, out, sz, MLX5_REG_MPCNT, 0, 0);
 +}
 +
 +void mlx5e_update_stats(struct mlx5e_priv *priv, bool full)
 +{
 +	if (full) {
 +		mlx5e_update_pcie_counters(priv);
 +		mlx5e_ipsec_update_stats(priv);
 +	}
 +	mlx5e_update_pport_counters(priv, full);
 +	mlx5e_update_vport_counters(priv);
 +	mlx5e_update_q_counter(priv);
 +	mlx5e_update_sw_counters(priv);
++=======
+ 	int i;
+ 
+ 	for (i = mlx5e_num_stats_grps - 1; i >= 0; i--)
+ 		if (mlx5e_stats_grps[i].update_stats)
+ 			mlx5e_stats_grps[i].update_stats(priv);
++>>>>>>> 193861773534 (net/mlx5e: Extend the stats group API to have update_stats())
  }
  
  static void mlx5e_update_ndo_stats(struct mlx5e_priv *priv)
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_stats.h
index 6008820e81eb,0b3320a2b072..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_stats.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_stats.h
@@@ -454,18 -203,24 +454,32 @@@ struct mlx5e_stats 
  	struct mlx5e_qcounter_stats qcnt;
  	struct mlx5e_vport_stats vport;
  	struct mlx5e_pport_stats pport;
 -	struct rtnl_link_stats64 vf_vport;
  	struct mlx5e_pcie_stats pcie;
 +	struct rtnl_link_stats64 vf_vport;
  };
  
++<<<<<<< HEAD
 +static const struct counter_desc mlx5e_pme_status_desc[] = {
 +	{ "module_unplug", 8 },
++=======
+ enum {
+ 	MLX5E_NDO_UPDATE_STATS = BIT(0x1),
+ };
+ 
+ struct mlx5e_priv;
+ struct mlx5e_stats_grp {
+ 	u16 update_stats_mask;
+ 	int (*get_num_stats)(struct mlx5e_priv *priv);
+ 	int (*fill_strings)(struct mlx5e_priv *priv, u8 *data, int idx);
+ 	int (*fill_stats)(struct mlx5e_priv *priv, u64 *data, int idx);
+ 	void (*update_stats)(struct mlx5e_priv *priv);
++>>>>>>> 193861773534 (net/mlx5e: Extend the stats group API to have update_stats())
  };
  
 -extern const struct mlx5e_stats_grp mlx5e_stats_grps[];
 -extern const int mlx5e_num_stats_grps;
 +static const struct counter_desc mlx5e_pme_error_desc[] = {
 +	{ "module_bus_stuck", 16 },       /* bus stuck (I2C or data shorted) */
 +	{ "module_high_temp", 48 },       /* high temperature */
 +	{ "module_bad_shorted", 56 },    /* bad or shorted cable/module */
 +};
  
  #endif /* __MLX5_EN_STATS_H__ */
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_stats.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en.h b/drivers/net/ethernet/mellanox/mlx5/core/en.h
index 3bc28bc1fd68..494faa72f232 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en.h
@@ -783,7 +783,7 @@ void mlx5e_dealloc_rx_wqe(struct mlx5e_rq *rq, u16 ix);
 void mlx5e_dealloc_rx_mpwqe(struct mlx5e_rq *rq, u16 ix);
 void mlx5e_free_rx_mpwqe(struct mlx5e_rq *rq, struct mlx5e_mpw_info *wi);
 
-void mlx5e_update_stats(struct mlx5e_priv *priv, bool full);
+void mlx5e_update_stats(struct mlx5e_priv *priv);
 
 int mlx5e_create_flow_steering(struct mlx5e_priv *priv);
 void mlx5e_destroy_flow_steering(struct mlx5e_priv *priv);
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_ethtool.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_main.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_stats.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_stats.h
