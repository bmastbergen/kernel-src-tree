x86/cpufeatures: Disentangle SSBD enumeration

jira LE-1907
cve CVE-2018-3639
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [x86] cpufeatures: Disentangle SSBD enumeration (Waiman Long) [1584569] {CVE-2018-3639}
Rebuild_FUZZ: 95.35%
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 52817587e706686fcdb27f14c1b000c92f266c96
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/52817587.failed

The SSBD enumeration is similarly to the other bits magically shared
between Intel and AMD though the mechanisms are different.

Make X86_FEATURE_SSBD synthetic and set it depending on the vendor specific
features or family dependent setup.

Change the Intel bit to X86_FEATURE_SPEC_CTRL_SSBD to denote that SSBD is
controlled via MSR_SPEC_CTRL and fix up the usage sites.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Reviewed-by: Borislav Petkov <bp@suse.de>
	Reviewed-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
(cherry picked from commit 52817587e706686fcdb27f14c1b000c92f266c96)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/cpufeatures.h
#	arch/x86/kernel/cpu/amd.c
#	arch/x86/kernel/cpu/bugs.c
#	arch/x86/kernel/cpu/common.c
#	arch/x86/kernel/cpu/intel.c
#	arch/x86/kernel/process.c
diff --cc arch/x86/include/asm/cpufeatures.h
index 7a3e9c71ed7d,61c34c1a525c..000000000000
--- a/arch/x86/include/asm/cpufeatures.h
+++ b/arch/x86/include/asm/cpufeatures.h
@@@ -190,133 -190,155 +190,168 @@@
   *
   * Reuse free bits when adding new feature flags!
   */
++<<<<<<< HEAD
 +
 +#define X86_FEATURE_RING3MWAIT	(7*32+ 0) /* Ring 3 MONITOR/MWAIT */
 +#define X86_FEATURE_CPB		(7*32+ 2) /* AMD Core Performance Boost */
 +#define X86_FEATURE_EPB		(7*32+ 3) /* IA32_ENERGY_PERF_BIAS support */
 +#define X86_FEATURE_CAT_L3	(7*32+ 4) /* Cache Allocation Technology L3 */
 +#define X86_FEATURE_CAT_L2	(7*32+ 5) /* Cache Allocation Technology L2 */
 +#define X86_FEATURE_CDP_L3	(7*32+ 6) /* Code and Data Prioritization L3 */
 +
 +#define X86_FEATURE_HW_PSTATE	(7*32+ 8) /* AMD HW-PState */
 +#define X86_FEATURE_PROC_FEEDBACK (7*32+ 9) /* AMD ProcFeedbackInterface */
 +#define X86_FEATURE_SME		( 7*32+10) /* AMD Secure Memory Encryption */
 +#define X86_FEATURE_RETPOLINE_AMD (7*32+13) /* AMD Retpoline mitigation for Spectre variant 2 */
 +#define X86_FEATURE_INTEL_PPIN	( 7*32+14) /* Intel Processor Inventory Number */
 +#define X86_FEATURE_INTEL_PT	( 7*32+15) /* Intel Processor Trace */
 +
 +#define X86_FEATURE_MBA		( 7*32+18) /* Memory Bandwidth Allocation */
 +#define X86_FEATURE_IBP_DISABLE ( 7*32+21) /* Old AMD Indirect Branch Predictor Disable */
++=======
+ #define X86_FEATURE_RING3MWAIT		( 7*32+ 0) /* Ring 3 MONITOR/MWAIT instructions */
+ #define X86_FEATURE_CPUID_FAULT		( 7*32+ 1) /* Intel CPUID faulting */
+ #define X86_FEATURE_CPB			( 7*32+ 2) /* AMD Core Performance Boost */
+ #define X86_FEATURE_EPB			( 7*32+ 3) /* IA32_ENERGY_PERF_BIAS support */
+ #define X86_FEATURE_CAT_L3		( 7*32+ 4) /* Cache Allocation Technology L3 */
+ #define X86_FEATURE_CAT_L2		( 7*32+ 5) /* Cache Allocation Technology L2 */
+ #define X86_FEATURE_CDP_L3		( 7*32+ 6) /* Code and Data Prioritization L3 */
+ #define X86_FEATURE_INVPCID_SINGLE	( 7*32+ 7) /* Effectively INVPCID && CR4.PCIDE=1 */
+ #define X86_FEATURE_HW_PSTATE		( 7*32+ 8) /* AMD HW-PState */
+ #define X86_FEATURE_PROC_FEEDBACK	( 7*32+ 9) /* AMD ProcFeedbackInterface */
+ #define X86_FEATURE_SME			( 7*32+10) /* AMD Secure Memory Encryption */
+ #define X86_FEATURE_PTI			( 7*32+11) /* Kernel Page Table Isolation enabled */
+ #define X86_FEATURE_RETPOLINE		( 7*32+12) /* "" Generic Retpoline mitigation for Spectre variant 2 */
+ #define X86_FEATURE_RETPOLINE_AMD	( 7*32+13) /* "" AMD Retpoline mitigation for Spectre variant 2 */
+ #define X86_FEATURE_INTEL_PPIN		( 7*32+14) /* Intel Processor Inventory Number */
+ #define X86_FEATURE_CDP_L2		( 7*32+15) /* Code and Data Prioritization L2 */
+ #define X86_FEATURE_MSR_SPEC_CTRL	( 7*32+16) /* "" MSR SPEC_CTRL is implemented */
+ #define X86_FEATURE_SSBD		( 7*32+17) /* Speculative Store Bypass Disable */
+ #define X86_FEATURE_MBA			( 7*32+18) /* Memory Bandwidth Allocation */
+ #define X86_FEATURE_RSB_CTXSW		( 7*32+19) /* "" Fill RSB on context switches */
+ #define X86_FEATURE_SEV			( 7*32+20) /* AMD Secure Encrypted Virtualization */
+ #define X86_FEATURE_USE_IBPB		( 7*32+21) /* "" Indirect Branch Prediction Barrier enabled */
+ #define X86_FEATURE_USE_IBRS_FW		( 7*32+22) /* "" Use IBRS during runtime firmware calls */
+ #define X86_FEATURE_SPEC_STORE_BYPASS_DISABLE	( 7*32+23) /* "" Disable Speculative Store Bypass. */
+ #define X86_FEATURE_LS_CFG_SSBD		( 7*32+24)  /* "" AMD SSBD implementation via LS_CFG MSR */
+ #define X86_FEATURE_IBRS		( 7*32+25) /* Indirect Branch Restricted Speculation */
+ #define X86_FEATURE_IBPB		( 7*32+26) /* Indirect Branch Prediction Barrier */
+ #define X86_FEATURE_STIBP		( 7*32+27) /* Single Thread Indirect Branch Predictors */
++>>>>>>> 52817587e706 (x86/cpufeatures: Disentangle SSBD enumeration)
  
  /* Virtualization flags: Linux defined, word 8 */
 -#define X86_FEATURE_TPR_SHADOW		( 8*32+ 0) /* Intel TPR Shadow */
 -#define X86_FEATURE_VNMI		( 8*32+ 1) /* Intel Virtual NMI */
 -#define X86_FEATURE_FLEXPRIORITY	( 8*32+ 2) /* Intel FlexPriority */
 -#define X86_FEATURE_EPT			( 8*32+ 3) /* Intel Extended Page Table */
 -#define X86_FEATURE_VPID		( 8*32+ 4) /* Intel Virtual Processor ID */
 -
 -#define X86_FEATURE_VMMCALL		( 8*32+15) /* Prefer VMMCALL to VMCALL */
 -#define X86_FEATURE_XENPV		( 8*32+16) /* "" Xen paravirtual guest */
 -
 +#define X86_FEATURE_TPR_SHADOW  (8*32+ 0) /* Intel TPR Shadow */
 +#define X86_FEATURE_VNMI        (8*32+ 1) /* Intel Virtual NMI */
 +#define X86_FEATURE_FLEXPRIORITY (8*32+ 2) /* Intel FlexPriority */
 +#define X86_FEATURE_EPT         (8*32+ 3) /* Intel Extended Page Table */
 +#define X86_FEATURE_VPID        (8*32+ 4) /* Intel Virtual Processor ID */
 +#define X86_FEATURE_VMMCALL     (8*32+15) /* Prefer vmmcall to vmcall */
  
 -/* Intel-defined CPU features, CPUID level 0x00000007:0 (EBX), word 9 */
 -#define X86_FEATURE_FSGSBASE		( 9*32+ 0) /* RDFSBASE, WRFSBASE, RDGSBASE, WRGSBASE instructions*/
 -#define X86_FEATURE_TSC_ADJUST		( 9*32+ 1) /* TSC adjustment MSR 0x3B */
 -#define X86_FEATURE_BMI1		( 9*32+ 3) /* 1st group bit manipulation extensions */
 -#define X86_FEATURE_HLE			( 9*32+ 4) /* Hardware Lock Elision */
 -#define X86_FEATURE_AVX2		( 9*32+ 5) /* AVX2 instructions */
 -#define X86_FEATURE_SMEP		( 9*32+ 7) /* Supervisor Mode Execution Protection */
 -#define X86_FEATURE_BMI2		( 9*32+ 8) /* 2nd group bit manipulation extensions */
 -#define X86_FEATURE_ERMS		( 9*32+ 9) /* Enhanced REP MOVSB/STOSB instructions */
 -#define X86_FEATURE_INVPCID		( 9*32+10) /* Invalidate Processor Context ID */
 -#define X86_FEATURE_RTM			( 9*32+11) /* Restricted Transactional Memory */
 -#define X86_FEATURE_CQM			( 9*32+12) /* Cache QoS Monitoring */
 -#define X86_FEATURE_MPX			( 9*32+14) /* Memory Protection Extension */
 -#define X86_FEATURE_RDT_A		( 9*32+15) /* Resource Director Technology Allocation */
 -#define X86_FEATURE_AVX512F		( 9*32+16) /* AVX-512 Foundation */
 -#define X86_FEATURE_AVX512DQ		( 9*32+17) /* AVX-512 DQ (Double/Quad granular) Instructions */
 -#define X86_FEATURE_RDSEED		( 9*32+18) /* RDSEED instruction */
 -#define X86_FEATURE_ADX			( 9*32+19) /* ADCX and ADOX instructions */
 -#define X86_FEATURE_SMAP		( 9*32+20) /* Supervisor Mode Access Prevention */
 -#define X86_FEATURE_AVX512IFMA		( 9*32+21) /* AVX-512 Integer Fused Multiply-Add instructions */
 -#define X86_FEATURE_CLFLUSHOPT		( 9*32+23) /* CLFLUSHOPT instruction */
 -#define X86_FEATURE_CLWB		( 9*32+24) /* CLWB instruction */
 -#define X86_FEATURE_INTEL_PT		( 9*32+25) /* Intel Processor Trace */
 -#define X86_FEATURE_AVX512PF		( 9*32+26) /* AVX-512 Prefetch */
 -#define X86_FEATURE_AVX512ER		( 9*32+27) /* AVX-512 Exponential and Reciprocal */
 -#define X86_FEATURE_AVX512CD		( 9*32+28) /* AVX-512 Conflict Detection */
 -#define X86_FEATURE_SHA_NI		( 9*32+29) /* SHA1/SHA256 Instruction Extensions */
 -#define X86_FEATURE_AVX512BW		( 9*32+30) /* AVX-512 BW (Byte/Word granular) Instructions */
 -#define X86_FEATURE_AVX512VL		( 9*32+31) /* AVX-512 VL (128/256 Vector Length) Extensions */
 +/* Intel-defined CPU features, CPUID level 0x00000007:0 (ebx), word 9 */
 +#define X86_FEATURE_FSGSBASE	(9*32+ 0) /* {RD/WR}{FS/GS}BASE instructions*/
 +#define X86_FEATURE_TSC_ADJUST	(9*32+ 1) /* TSC adjustment MSR 0x3b */
 +#define X86_FEATURE_BMI1	(9*32+ 3) /* 1st group bit manipulation extensions */
 +#define X86_FEATURE_HLE		(9*32+ 4) /* Hardware Lock Elision */
 +#define X86_FEATURE_AVX2	(9*32+ 5) /* AVX2 instructions */
 +#define X86_FEATURE_SMEP	(9*32+ 7) /* Supervisor Mode Execution Protection */
 +#define X86_FEATURE_BMI2	(9*32+ 8) /* 2nd group bit manipulation extensions */
 +#define X86_FEATURE_ERMS	(9*32+ 9) /* Enhanced REP MOVSB/STOSB */
 +#define X86_FEATURE_INVPCID	(9*32+10) /* Invalidate Processor Context ID */
 +#define X86_FEATURE_RTM		(9*32+11) /* Restricted Transactional Memory */
 +#define X86_FEATURE_CQM		(9*32+12) /* Cache QoS Monitoring */
 +#define X86_FEATURE_MPX		(9*32+14) /* Memory Protection Extension */
 +#define X86_FEATURE_RDT_A	(9*32+15) /* Resource Director Technology Allocation */
 +#define X86_FEATURE_AVX512F	(9*32+16) /* AVX-512 Foundation */
 +#define X86_FEATURE_AVX512DQ	( 9*32+17) /* AVX-512 DQ (Double/Quad granular) Instructions */
 +#define X86_FEATURE_RDSEED	(9*32+18) /* The RDSEED instruction */
 +#define X86_FEATURE_ADX		(9*32+19) /* The ADCX and ADOX instructions */
 +#define X86_FEATURE_SMAP	(9*32+20) /* Supervisor Mode Access Prevention */
 +#define X86_FEATURE_AVX512IFMA	( 9*32+21) /* AVX-512 Integer Fused Multiply-Add instructions */
 +#define X86_FEATURE_CLFLUSHOPT	(9*32+23) /* CLFLUSHOPT instruction */
 +#define X86_FEATURE_CLWB	( 9*32+24) /* CLWB instruction */
 +#define X86_FEATURE_AVX512PF	(9*32+26) /* AVX-512 Prefetch */
 +#define X86_FEATURE_AVX512ER	(9*32+27) /* AVX-512 Exponential and Reciprocal */
 +#define X86_FEATURE_AVX512CD	(9*32+28) /* AVX-512 Conflict Detection */
 +#define X86_FEATURE_SHA_NI	( 9*32+29) /* SHA1/SHA256 Instruction Extensions */
 +#define X86_FEATURE_AVX512BW	( 9*32+30) /* AVX-512 BW (Byte/Word granular) Instructions */
 +#define X86_FEATURE_AVX512VL	( 9*32+31) /* AVX-512 VL (128/256 Vector Length) Extensions */
  
 -/* Extended state features, CPUID level 0x0000000d:1 (EAX), word 10 */
 -#define X86_FEATURE_XSAVEOPT		(10*32+ 0) /* XSAVEOPT instruction */
 -#define X86_FEATURE_XSAVEC		(10*32+ 1) /* XSAVEC instruction */
 -#define X86_FEATURE_XGETBV1		(10*32+ 2) /* XGETBV with ECX = 1 instruction */
 -#define X86_FEATURE_XSAVES		(10*32+ 3) /* XSAVES/XRSTORS instructions */
 +/* Extended state features, CPUID level 0x0000000d:1 (eax), word 10 */
 +#define X86_FEATURE_XSAVEOPT   (10*32+ 0) /* XSAVEOPT */
 +#define X86_FEATURE_XSAVEC     (10*32+ 1) /* XSAVEC */
 +#define X86_FEATURE_XGETBV1    (10*32+ 2) /* XGETBV with ECX = 1 */
 +#define X86_FEATURE_XSAVES     (10*32+ 3) /* XSAVES/XRSTORS */
  
 -/* Intel-defined CPU QoS Sub-leaf, CPUID level 0x0000000F:0 (EDX), word 11 */
 -#define X86_FEATURE_CQM_LLC		(11*32+ 1) /* LLC QoS if 1 */
 +/* Intel-defined CPU QoS Sub-leaf, CPUID level 0x0000000F:0 (edx), word 11 */
 +#define X86_FEATURE_CQM_LLC	(11*32+ 1) /* LLC QoS if 1 */
  
 -/* Intel-defined CPU QoS Sub-leaf, CPUID level 0x0000000F:1 (EDX), word 12 */
 -#define X86_FEATURE_CQM_OCCUP_LLC	(12*32+ 0) /* LLC occupancy monitoring */
 -#define X86_FEATURE_CQM_MBM_TOTAL	(12*32+ 1) /* LLC Total MBM monitoring */
 -#define X86_FEATURE_CQM_MBM_LOCAL	(12*32+ 2) /* LLC Local MBM monitoring */
 +/* Intel-defined CPU QoS Sub-leaf, CPUID level 0x0000000F:1 (edx), word 12 */
 +#define X86_FEATURE_CQM_OCCUP_LLC (12*32+ 0) /* LLC occupancy monitoring if 1 */
 +#define X86_FEATURE_CQM_MBM_TOTAL (12*32+ 1) /* LLC Total MBM monitoring */
 +#define X86_FEATURE_CQM_MBM_LOCAL (12*32+ 2) /* LLC Local MBM monitoring */
  
  /* AMD-defined CPU features, CPUID level 0x80000008 (EBX), word 13 */
 -#define X86_FEATURE_CLZERO		(13*32+ 0) /* CLZERO instruction */
 -#define X86_FEATURE_IRPERF		(13*32+ 1) /* Instructions Retired Count */
 -#define X86_FEATURE_XSAVEERPTR		(13*32+ 2) /* Always save/restore FP error pointers */
 -#define X86_FEATURE_AMD_IBPB		(13*32+12) /* "" Indirect Branch Prediction Barrier */
 -#define X86_FEATURE_AMD_IBRS		(13*32+14) /* "" Indirect Branch Restricted Speculation */
 -#define X86_FEATURE_AMD_STIBP		(13*32+15) /* "" Single Thread Indirect Branch Predictors */
 +#define X86_FEATURE_CLZERO              (13*32+ 0) /* CLZERO instruction */
 +#define X86_FEATURE_IRPERF              (13*32+ 1) /* Instructions Retired Count */
 +#define X86_FEATURE_XSAVEERPTR          (13*32+ 2) /* Always save/restore FP error pointers */
 +#define X86_FEATURE_IBPB		(13*32+12) /* Indirect Branch Prediction Barrier */
 +#define X86_FEATURE_IBRS		(13*32+14) /* Indirect Branch Restricted Speculation */
 +#define X86_FEATURE_STIBP		(13*32+15) /* Single Thread Indirect Branch Predictors */
  
 -/* Thermal and Power Management Leaf, CPUID level 0x00000006 (EAX), word 14 */
 -#define X86_FEATURE_DTHERM		(14*32+ 0) /* Digital Thermal Sensor */
 -#define X86_FEATURE_IDA			(14*32+ 1) /* Intel Dynamic Acceleration */
 -#define X86_FEATURE_ARAT		(14*32+ 2) /* Always Running APIC Timer */
 -#define X86_FEATURE_PLN			(14*32+ 4) /* Intel Power Limit Notification */
 -#define X86_FEATURE_PTS			(14*32+ 6) /* Intel Package Thermal Status */
 -#define X86_FEATURE_HWP			(14*32+ 7) /* Intel Hardware P-states */
 -#define X86_FEATURE_HWP_NOTIFY		(14*32+ 8) /* HWP Notification */
 -#define X86_FEATURE_HWP_ACT_WINDOW	(14*32+ 9) /* HWP Activity Window */
 -#define X86_FEATURE_HWP_EPP		(14*32+10) /* HWP Energy Perf. Preference */
 -#define X86_FEATURE_HWP_PKG_REQ		(14*32+11) /* HWP Package Level Request */
 +/* AMD-defined CPU features, CPUID level 0x80000007 (ebx), word 17 */
 +#define X86_FEATURE_OVERFLOW_RECOV (17*32+0) /* MCA overflow recovery support */
 +#define X86_FEATURE_SUCCOR	(17*32+1) /* Uncorrectable error containment and recovery */
 +#define X86_FEATURE_SMCA	(17*32+3) /* Scalable MCA */
  
 -/* AMD SVM Feature Identification, CPUID level 0x8000000a (EDX), word 15 */
 -#define X86_FEATURE_NPT			(15*32+ 0) /* Nested Page Table support */
 -#define X86_FEATURE_LBRV		(15*32+ 1) /* LBR Virtualization support */
 -#define X86_FEATURE_SVML		(15*32+ 2) /* "svm_lock" SVM locking MSR */
 -#define X86_FEATURE_NRIPS		(15*32+ 3) /* "nrip_save" SVM next_rip save */
 -#define X86_FEATURE_TSCRATEMSR		(15*32+ 4) /* "tsc_scale" TSC scaling support */
 -#define X86_FEATURE_VMCBCLEAN		(15*32+ 5) /* "vmcb_clean" VMCB clean bits support */
 -#define X86_FEATURE_FLUSHBYASID		(15*32+ 6) /* flush-by-ASID support */
 -#define X86_FEATURE_DECODEASSISTS	(15*32+ 7) /* Decode Assists support */
 -#define X86_FEATURE_PAUSEFILTER		(15*32+10) /* filtered pause intercept */
 -#define X86_FEATURE_PFTHRESHOLD		(15*32+12) /* pause filter threshold */
 -#define X86_FEATURE_AVIC		(15*32+13) /* Virtual Interrupt Controller */
 -#define X86_FEATURE_V_VMSAVE_VMLOAD	(15*32+15) /* Virtual VMSAVE VMLOAD */
 -#define X86_FEATURE_VGIF		(15*32+16) /* Virtual GIF */
 +/* Thermal and Power Management Leaf, CPUID level 0x00000006 (eax), word 14 */
 +#define X86_FEATURE_DTHERM	(14*32+ 0) /* Digital Thermal Sensor */
 +#define X86_FEATURE_IDA		(14*32+ 1) /* Intel Dynamic Acceleration */
 +#define X86_FEATURE_ARAT	(14*32+ 2) /* Always Running APIC Timer */
 +#define X86_FEATURE_PLN		(14*32+ 4) /* Intel Power Limit Notification */
 +#define X86_FEATURE_PTS		(14*32+ 6) /* Intel Package Thermal Status */
 +#define X86_FEATURE_HWP		(14*32+ 7) /* Intel Hardware P-states */
 +#define X86_FEATURE_HWP_NOTIFY	(14*32+ 8) /* HWP Notification */
 +#define X86_FEATURE_HWP_ACT_WINDOW (14*32+ 9) /* HWP Activity Window */
 +#define X86_FEATURE_HWP_EPP	(14*32+10) /* HWP Energy Perf. Preference */
 +#define X86_FEATURE_HWP_PKG_REQ (14*32+11) /* HWP Package Level Request */
  
 -/* Intel-defined CPU features, CPUID level 0x00000007:0 (ECX), word 16 */
 -#define X86_FEATURE_AVX512VBMI		(16*32+ 1) /* AVX512 Vector Bit Manipulation instructions*/
 -#define X86_FEATURE_UMIP		(16*32+ 2) /* User Mode Instruction Protection */
 -#define X86_FEATURE_PKU			(16*32+ 3) /* Protection Keys for Userspace */
 -#define X86_FEATURE_OSPKE		(16*32+ 4) /* OS Protection Keys Enable */
 -#define X86_FEATURE_AVX512_VBMI2	(16*32+ 6) /* Additional AVX512 Vector Bit Manipulation Instructions */
 -#define X86_FEATURE_GFNI		(16*32+ 8) /* Galois Field New Instructions */
 -#define X86_FEATURE_VAES		(16*32+ 9) /* Vector AES */
 -#define X86_FEATURE_VPCLMULQDQ		(16*32+10) /* Carry-Less Multiplication Double Quadword */
 -#define X86_FEATURE_AVX512_VNNI		(16*32+11) /* Vector Neural Network Instructions */
 -#define X86_FEATURE_AVX512_BITALG	(16*32+12) /* Support for VPOPCNT[B,W] and VPSHUF-BITQMB instructions */
 -#define X86_FEATURE_TME			(16*32+13) /* Intel Total Memory Encryption */
 -#define X86_FEATURE_AVX512_VPOPCNTDQ	(16*32+14) /* POPCNT for vectors of DW/QW */
 -#define X86_FEATURE_LA57		(16*32+16) /* 5-level page tables */
 -#define X86_FEATURE_RDPID		(16*32+22) /* RDPID instruction */
 -#define X86_FEATURE_CLDEMOTE		(16*32+25) /* CLDEMOTE instruction */
 +/* AMD SVM Feature Identification, CPUID level 0x8000000a (edx), word 15 */
 +#define X86_FEATURE_NPT		(15*32+ 0) /* Nested Page Table support */
 +#define X86_FEATURE_LBRV	(15*32+ 1) /* LBR Virtualization support */
 +#define X86_FEATURE_SVML	(15*32+ 2) /* "svm_lock" SVM locking MSR */
 +#define X86_FEATURE_NRIPS	(15*32+ 3) /* "nrip_save" SVM next_rip save */
 +#define X86_FEATURE_TSCRATEMSR  (15*32+ 4) /* "tsc_scale" TSC scaling support */
 +#define X86_FEATURE_VMCBCLEAN   (15*32+ 5) /* "vmcb_clean" VMCB clean bits support */
 +#define X86_FEATURE_FLUSHBYASID (15*32+ 6) /* flush-by-ASID support */
 +#define X86_FEATURE_DECODEASSISTS (15*32+ 7) /* Decode Assists support */
 +#define X86_FEATURE_PAUSEFILTER (15*32+10) /* filtered pause intercept */
 +#define X86_FEATURE_PFTHRESHOLD (15*32+12) /* pause filter threshold */
 +#define X86_FEATURE_AVIC	(15*32+13) /* Virtual Interrupt Controller */
 +#define X86_FEATURE_V_VMSAVE_VMLOAD (15*32+15) /* Virtual VMSAVE VMLOAD */
 +#define X86_FEATURE_VGIF	(15*32+16) /* Virtual GIF */
  
 -/* AMD-defined CPU features, CPUID level 0x80000007 (EBX), word 17 */
 -#define X86_FEATURE_OVERFLOW_RECOV	(17*32+ 0) /* MCA overflow recovery support */
 -#define X86_FEATURE_SUCCOR		(17*32+ 1) /* Uncorrectable error containment and recovery */
 -#define X86_FEATURE_SMCA		(17*32+ 3) /* Scalable MCA */
 +/* Intel-defined CPU features, CPUID level 0x00000007:0 (ecx), word 16 */
 +#define X86_FEATURE_AVX512VBMI	(16*32+ 1) /* AVX512 Vector Bit Manipulation instructions*/
 +#define X86_FEATURE_PKU		(16*32+ 3) /* Protection Keys for Userspace */
 +#define X86_FEATURE_OSPKE	(16*32+ 4) /* OS Protection Keys Enable */
 +#define X86_FEATURE_AVX512_VBMI2 (16*32+ 6) /* Additional AVX512 Vector Bit Manipulation Instructions */
 +#define X86_FEATURE_GFNI	(16*32+ 8) /* Galois Field New Instructions */
 +#define X86_FEATURE_VAES	(16*32+ 9) /* Vector AES */
 +#define X86_FEATURE_VPCLMULQDQ	(16*32+ 10) /* Carry-Less Multiplication Double Quadword */
 +#define X86_FEATURE_AVX512_VNNI (16*32+ 11) /* Vector Neural Network Instructions */
 +#define X86_FEATURE_AVX512_BITALG (16*32+12) /* Support for VPOPCNT[B,W] and VPSHUF-BITQMB */
 +#define X86_FEATURE_AVX512_VPOPCNTDQ (16*32+14) /* POPCNT for vectors of DW/QW */
  
  /* Intel-defined CPU features, CPUID level 0x00000007:0 (EDX), word 18 */
  #define X86_FEATURE_AVX512_4VNNIW	(18*32+ 2) /* AVX-512 Neural Network Instructions */
  #define X86_FEATURE_AVX512_4FMAPS	(18*32+ 3) /* AVX-512 Multiply Accumulation Single precision */
 -#define X86_FEATURE_PCONFIG		(18*32+18) /* Intel PCONFIG */
 -#define X86_FEATURE_SPEC_CTRL		(18*32+26) /* "" Speculation Control (IBRS + IBPB) */
 -#define X86_FEATURE_INTEL_STIBP		(18*32+27) /* "" Single Thread Indirect Branch Predictors */
 +#define X86_FEATURE_SPEC_CTRL		(18*32+26) /* Speculation Control (IBRS + IBPB) */
 +#define X86_FEATURE_INTEL_STIBP		(18*32+27) /* Single Thread Indirect Branch Predictors */
  #define X86_FEATURE_ARCH_CAPABILITIES	(18*32+29) /* IA32_ARCH_CAPABILITIES MSR (Intel) */
++<<<<<<< HEAD
++=======
+ #define X86_FEATURE_SPEC_CTRL_SSBD	(18*32+31) /* "" Speculative Store Bypass Disable */
++>>>>>>> 52817587e706 (x86/cpufeatures: Disentangle SSBD enumeration)
  
  /*
   * BUG word(s)
diff --cc arch/x86/kernel/cpu/amd.c
index 8e108518b7dc,2d2d8985654b..000000000000
--- a/arch/x86/kernel/cpu/amd.c
+++ b/arch/x86/kernel/cpu/amd.c
@@@ -512,6 -540,86 +512,89 @@@ static void bsp_init_amd(struct cpuinfo
  		/* A random value per boot for bit slice [12:upper_bit) */
  		va_align.bits = get_random_int() & va_align.mask;
  	}
++<<<<<<< HEAD
++=======
+ 
+ 	if (cpu_has(c, X86_FEATURE_MWAITX))
+ 		use_mwaitx_delay();
+ 
+ 	if (boot_cpu_has(X86_FEATURE_TOPOEXT)) {
+ 		u32 ecx;
+ 
+ 		ecx = cpuid_ecx(0x8000001e);
+ 		nodes_per_socket = ((ecx >> 8) & 7) + 1;
+ 	} else if (boot_cpu_has(X86_FEATURE_NODEID_MSR)) {
+ 		u64 value;
+ 
+ 		rdmsrl(MSR_FAM10H_NODE_ID, value);
+ 		nodes_per_socket = ((value >> 3) & 7) + 1;
+ 	}
+ 
+ 	if (c->x86 >= 0x15 && c->x86 <= 0x17) {
+ 		unsigned int bit;
+ 
+ 		switch (c->x86) {
+ 		case 0x15: bit = 54; break;
+ 		case 0x16: bit = 33; break;
+ 		case 0x17: bit = 10; break;
+ 		default: return;
+ 		}
+ 		/*
+ 		 * Try to cache the base value so further operations can
+ 		 * avoid RMW. If that faults, do not enable SSBD.
+ 		 */
+ 		if (!rdmsrl_safe(MSR_AMD64_LS_CFG, &x86_amd_ls_cfg_base)) {
+ 			setup_force_cpu_cap(X86_FEATURE_LS_CFG_SSBD);
+ 			setup_force_cpu_cap(X86_FEATURE_SSBD);
+ 			x86_amd_ls_cfg_ssbd_mask = 1ULL << bit;
+ 		}
+ 	}
+ }
+ 
+ static void early_detect_mem_encrypt(struct cpuinfo_x86 *c)
+ {
+ 	u64 msr;
+ 
+ 	/*
+ 	 * BIOS support is required for SME and SEV.
+ 	 *   For SME: If BIOS has enabled SME then adjust x86_phys_bits by
+ 	 *	      the SME physical address space reduction value.
+ 	 *	      If BIOS has not enabled SME then don't advertise the
+ 	 *	      SME feature (set in scattered.c).
+ 	 *   For SEV: If BIOS has not enabled SEV then don't advertise the
+ 	 *            SEV feature (set in scattered.c).
+ 	 *
+ 	 *   In all cases, since support for SME and SEV requires long mode,
+ 	 *   don't advertise the feature under CONFIG_X86_32.
+ 	 */
+ 	if (cpu_has(c, X86_FEATURE_SME) || cpu_has(c, X86_FEATURE_SEV)) {
+ 		/* Check if memory encryption is enabled */
+ 		rdmsrl(MSR_K8_SYSCFG, msr);
+ 		if (!(msr & MSR_K8_SYSCFG_MEM_ENCRYPT))
+ 			goto clear_all;
+ 
+ 		/*
+ 		 * Always adjust physical address bits. Even though this
+ 		 * will be a value above 32-bits this is still done for
+ 		 * CONFIG_X86_32 so that accurate values are reported.
+ 		 */
+ 		c->x86_phys_bits -= (cpuid_ebx(0x8000001f) >> 6) & 0x3f;
+ 
+ 		if (IS_ENABLED(CONFIG_X86_32))
+ 			goto clear_all;
+ 
+ 		rdmsrl(MSR_K7_HWCR, msr);
+ 		if (!(msr & MSR_K7_HWCR_SMMLOCK))
+ 			goto clear_sev;
+ 
+ 		return;
+ 
+ clear_all:
+ 		clear_cpu_cap(c, X86_FEATURE_SME);
+ clear_sev:
+ 		clear_cpu_cap(c, X86_FEATURE_SEV);
+ 	}
++>>>>>>> 52817587e706 (x86/cpufeatures: Disentangle SSBD enumeration)
  }
  
  static void early_init_amd(struct cpuinfo_x86 *c)
@@@ -780,51 -911,14 +863,57 @@@ static void init_amd(struct cpuinfo_x8
  	if (c->x86 > 0x11)
  		set_cpu_cap(c, X86_FEATURE_ARAT);
  
 -	/* 3DNow or LM implies PREFETCHW */
 -	if (!cpu_has(c, X86_FEATURE_3DNOWPREFETCH))
 -		if (cpu_has(c, X86_FEATURE_3DNOW) || cpu_has(c, X86_FEATURE_LM))
 -			set_cpu_cap(c, X86_FEATURE_3DNOWPREFETCH);
 +	if (c->x86 == 0x10) {
 +		/*
 +		 * Disable GART TLB Walk Errors on Fam10h. We do this here
 +		 * because this is always needed when GART is enabled, even in a
 +		 * kernel which has no MCE support built in.
 +		 * BIOS should disable GartTlbWlk Errors themself. If
 +		 * it doesn't do it here as suggested by the BKDG.
 +		 *
 +		 * Fixes: https://bugzilla.kernel.org/show_bug.cgi?id=33012
 +		 */
 +		u64 mask;
 +		int err;
 +
++<<<<<<< HEAD
 +		err = rdmsrl_safe(MSR_AMD64_MCx_MASK(4), &mask);
 +		if (err == 0) {
 +			mask |= (1 << 10);
 +			wrmsrl_safe(MSR_AMD64_MCx_MASK(4), mask);
 +		}
 +
 +		/*
 +		 * On family 10h BIOS may not have properly enabled WC+ support,
 +		 * causing it to be converted to CD memtype. This may result in
 +		 * performance degradation for certain nested-paging guests.
 +		 * Prevent this conversion by clearing bit 24 in
 +		 * MSR_AMD64_BU_CFG2.
 +		 *
 +		 * NOTE: we want to use the _safe accessors so as not to #GP kvm
 +		 * guests on older kvm hosts.
 +		 */
 +
 +		rdmsrl_safe(MSR_AMD64_BU_CFG2, &value);
 +		value &= ~(1ULL << 24);
 +		wrmsrl_safe(MSR_AMD64_BU_CFG2, value);
 +
 +		if (cpu_has_amd_erratum(c, amd_erratum_383))
 +			set_cpu_bug(c, X86_BUG_AMD_TLB_MMATCH);
 +	}
 +
 +	if (cpu_has_amd_erratum(c, amd_erratum_400))
 +		set_cpu_bug(c, X86_BUG_AMD_APIC_C1E);
  
 +	if (c->x86 == 0x10 || c->x86 == 0x12)
 +		set_cpu_cap(c, X86_FEATURE_IBP_DISABLE);
 +
 +	set_cpu_cap(c, X86_FEATURE_RETPOLINE_AMD);
++=======
+ 	/* AMD CPUs don't reset SS attributes on SYSRET, Xen does. */
+ 	if (!cpu_has(c, X86_FEATURE_XENPV))
+ 		set_cpu_bug(c, X86_BUG_SYSRET_SS_ATTRS);
++>>>>>>> 52817587e706 (x86/cpufeatures: Disentangle SSBD enumeration)
  }
  
  #ifdef CONFIG_X86_32
diff --cc arch/x86/kernel/cpu/bugs.c
index 29b8876b1f95,7ebd6373fc31..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -104,6 -129,108 +104,111 @@@ enum spectre_v2_mitigation_cmd spectre_
  #undef pr_fmt
  #define pr_fmt(fmt)     "Spectre V2 : " fmt
  
++<<<<<<< HEAD
++=======
+ static enum spectre_v2_mitigation spectre_v2_enabled __ro_after_init =
+ 	SPECTRE_V2_NONE;
+ 
+ void x86_spec_ctrl_set(u64 val)
+ {
+ 	if (val & x86_spec_ctrl_mask)
+ 		WARN_ONCE(1, "SPEC_CTRL MSR value 0x%16llx is unknown.\n", val);
+ 	else
+ 		wrmsrl(MSR_IA32_SPEC_CTRL, x86_spec_ctrl_base | val);
+ }
+ EXPORT_SYMBOL_GPL(x86_spec_ctrl_set);
+ 
+ u64 x86_spec_ctrl_get_default(void)
+ {
+ 	u64 msrval = x86_spec_ctrl_base;
+ 
+ 	if (static_cpu_has(X86_FEATURE_SPEC_CTRL))
+ 		msrval |= ssbd_tif_to_spec_ctrl(current_thread_info()->flags);
+ 	return msrval;
+ }
+ EXPORT_SYMBOL_GPL(x86_spec_ctrl_get_default);
+ 
+ void x86_spec_ctrl_set_guest(u64 guest_spec_ctrl)
+ {
+ 	u64 host = x86_spec_ctrl_base;
+ 
+ 	/* Is MSR_SPEC_CTRL implemented ? */
+ 	if (!static_cpu_has(X86_FEATURE_MSR_SPEC_CTRL))
+ 		return;
+ 
+ 	/* SSBD controlled in MSR_SPEC_CTRL */
+ 	if (static_cpu_has(X86_FEATURE_SPEC_CTRL_SSBD))
+ 		host |= ssbd_tif_to_spec_ctrl(current_thread_info()->flags);
+ 
+ 	if (host != guest_spec_ctrl)
+ 		wrmsrl(MSR_IA32_SPEC_CTRL, guest_spec_ctrl);
+ }
+ EXPORT_SYMBOL_GPL(x86_spec_ctrl_set_guest);
+ 
+ void x86_spec_ctrl_restore_host(u64 guest_spec_ctrl)
+ {
+ 	u64 host = x86_spec_ctrl_base;
+ 
+ 	/* Is MSR_SPEC_CTRL implemented ? */
+ 	if (!static_cpu_has(X86_FEATURE_MSR_SPEC_CTRL))
+ 		return;
+ 
+ 	/* SSBD controlled in MSR_SPEC_CTRL */
+ 	if (static_cpu_has(X86_FEATURE_SPEC_CTRL_SSBD))
+ 		host |= ssbd_tif_to_spec_ctrl(current_thread_info()->flags);
+ 
+ 	if (host != guest_spec_ctrl)
+ 		wrmsrl(MSR_IA32_SPEC_CTRL, host);
+ }
+ EXPORT_SYMBOL_GPL(x86_spec_ctrl_restore_host);
+ 
+ static void x86_amd_ssb_disable(void)
+ {
+ 	u64 msrval = x86_amd_ls_cfg_base | x86_amd_ls_cfg_ssbd_mask;
+ 
+ 	if (boot_cpu_has(X86_FEATURE_LS_CFG_SSBD))
+ 		wrmsrl(MSR_AMD64_LS_CFG, msrval);
+ }
+ 
+ #ifdef RETPOLINE
+ static bool spectre_v2_bad_module;
+ 
+ bool retpoline_module_ok(bool has_retpoline)
+ {
+ 	if (spectre_v2_enabled == SPECTRE_V2_NONE || has_retpoline)
+ 		return true;
+ 
+ 	pr_err("System may be vulnerable to spectre v2\n");
+ 	spectre_v2_bad_module = true;
+ 	return false;
+ }
+ 
+ static inline const char *spectre_v2_module_string(void)
+ {
+ 	return spectre_v2_bad_module ? " - vulnerable module loaded" : "";
+ }
+ #else
+ static inline const char *spectre_v2_module_string(void) { return ""; }
+ #endif
+ 
+ static void __init spec2_print_if_insecure(const char *reason)
+ {
+ 	if (boot_cpu_has_bug(X86_BUG_SPECTRE_V2))
+ 		pr_info("%s selected on command line.\n", reason);
+ }
+ 
+ static void __init spec2_print_if_secure(const char *reason)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_SPECTRE_V2))
+ 		pr_info("%s selected on command line.\n", reason);
+ }
+ 
+ static inline bool retp_compiler(void)
+ {
+ 	return __is_defined(RETPOLINE);
+ }
+ 
++>>>>>>> 52817587e706 (x86/cpufeatures: Disentangle SSBD enumeration)
  static inline bool match_option(const char *arg, int arglen, const char *opt)
  {
  	int len = strlen(opt);
diff --cc arch/x86/kernel/cpu/common.c
index 49cb90f121df,68282514c025..000000000000
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@@ -723,9 -761,27 +723,28 @@@ static void init_speculation_control(st
  	if (cpu_has(c, X86_FEATURE_SPEC_CTRL)) {
  		set_cpu_cap(c, X86_FEATURE_IBRS);
  		set_cpu_cap(c, X86_FEATURE_IBPB);
 -		set_cpu_cap(c, X86_FEATURE_MSR_SPEC_CTRL);
  	}
 -
  	if (cpu_has(c, X86_FEATURE_INTEL_STIBP))
  		set_cpu_cap(c, X86_FEATURE_STIBP);
++<<<<<<< HEAD
++=======
+ 
+ 	if (cpu_has(c, X86_FEATURE_SPEC_CTRL_SSBD))
+ 		set_cpu_cap(c, X86_FEATURE_SSBD);
+ 
+ 	if (cpu_has(c, X86_FEATURE_AMD_IBRS)) {
+ 		set_cpu_cap(c, X86_FEATURE_IBRS);
+ 		set_cpu_cap(c, X86_FEATURE_MSR_SPEC_CTRL);
+ 	}
+ 
+ 	if (cpu_has(c, X86_FEATURE_AMD_IBPB))
+ 		set_cpu_cap(c, X86_FEATURE_IBPB);
+ 
+ 	if (cpu_has(c, X86_FEATURE_AMD_STIBP)) {
+ 		set_cpu_cap(c, X86_FEATURE_STIBP);
+ 		set_cpu_cap(c, X86_FEATURE_MSR_SPEC_CTRL);
+ 	}
++>>>>>>> 52817587e706 (x86/cpufeatures: Disentangle SSBD enumeration)
  }
  
  void get_cpu_cap(struct cpuinfo_x86 *c)
diff --cc arch/x86/kernel/cpu/intel.c
index 9ac0d10cb29f,577e7f7ae273..000000000000
--- a/arch/x86/kernel/cpu/intel.c
+++ b/arch/x86/kernel/cpu/intel.c
@@@ -123,13 -175,23 +123,30 @@@ static void early_init_intel(struct cpu
  		(c->x86 == 0x6 && c->x86_model >= 0x0e))
  		set_cpu_cap(c, X86_FEATURE_CONSTANT_TSC);
  
 -	if (c->x86 >= 6 && !cpu_has(c, X86_FEATURE_IA64))
 -		c->microcode = intel_get_microcode_revision();
 +	if (c->x86 >= 6 && !cpu_has(c, X86_FEATURE_IA64)) {
 +		unsigned lower_word;
  
++<<<<<<< HEAD
 +		wrmsr(MSR_IA32_UCODE_REV, 0, 0);
 +		/* Required by the SDM */
 +		sync_core();
 +		rdmsr(MSR_IA32_UCODE_REV, lower_word, c->microcode);
++=======
+ 	/* Now if any of them are set, check the blacklist and clear the lot */
+ 	if ((cpu_has(c, X86_FEATURE_SPEC_CTRL) ||
+ 	     cpu_has(c, X86_FEATURE_INTEL_STIBP) ||
+ 	     cpu_has(c, X86_FEATURE_IBRS) || cpu_has(c, X86_FEATURE_IBPB) ||
+ 	     cpu_has(c, X86_FEATURE_STIBP)) && bad_spectre_microcode(c)) {
+ 		pr_warn("Intel Spectre v2 broken microcode detected; disabling Speculation Control\n");
+ 		setup_clear_cpu_cap(X86_FEATURE_IBRS);
+ 		setup_clear_cpu_cap(X86_FEATURE_IBPB);
+ 		setup_clear_cpu_cap(X86_FEATURE_STIBP);
+ 		setup_clear_cpu_cap(X86_FEATURE_SPEC_CTRL);
+ 		setup_clear_cpu_cap(X86_FEATURE_MSR_SPEC_CTRL);
+ 		setup_clear_cpu_cap(X86_FEATURE_INTEL_STIBP);
+ 		setup_clear_cpu_cap(X86_FEATURE_SSBD);
+ 		setup_clear_cpu_cap(X86_FEATURE_SPEC_CTRL_SSBD);
++>>>>>>> 52817587e706 (x86/cpufeatures: Disentangle SSBD enumeration)
  	}
  
  	/*
diff --cc arch/x86/kernel/process.c
index f741d66041de,d71ef7eaa7ef..000000000000
--- a/arch/x86/kernel/process.c
+++ b/arch/x86/kernel/process.c
@@@ -237,7 -277,60 +237,43 @@@ void __switch_to_xtra(struct task_struc
  		 */
  		memset(tss->io_bitmap, 0xff, prev->io_bitmap_max);
  	}
++<<<<<<< HEAD
++=======
+ }
+ 
+ static __always_inline void __speculative_store_bypass_update(unsigned long tifn)
+ {
+ 	u64 msr;
+ 
+ 	if (static_cpu_has(X86_FEATURE_LS_CFG_SSBD)) {
+ 		msr = x86_amd_ls_cfg_base | ssbd_tif_to_amd_ls_cfg(tifn);
+ 		wrmsrl(MSR_AMD64_LS_CFG, msr);
+ 	} else {
+ 		msr = x86_spec_ctrl_base | ssbd_tif_to_spec_ctrl(tifn);
+ 		wrmsrl(MSR_IA32_SPEC_CTRL, msr);
+ 	}
+ }
+ 
+ void speculative_store_bypass_update(void)
+ {
+ 	__speculative_store_bypass_update(current_thread_info()->flags);
+ }
+ 
+ void __switch_to_xtra(struct task_struct *prev_p, struct task_struct *next_p,
+ 		      struct tss_struct *tss)
+ {
+ 	struct thread_struct *prev, *next;
+ 	unsigned long tifp, tifn;
+ 
+ 	prev = &prev_p->thread;
+ 	next = &next_p->thread;
+ 
+ 	tifn = READ_ONCE(task_thread_info(next_p)->flags);
+ 	tifp = READ_ONCE(task_thread_info(prev_p)->flags);
+ 	switch_to_bitmap(tss, prev, next, tifp, tifn);
+ 
++>>>>>>> 52817587e706 (x86/cpufeatures: Disentangle SSBD enumeration)
  	propagate_user_return_notify(prev_p, next_p);
 -
 -	if ((tifp & _TIF_BLOCKSTEP || tifn & _TIF_BLOCKSTEP) &&
 -	    arch_has_block_step()) {
 -		unsigned long debugctl, msk;
 -
 -		rdmsrl(MSR_IA32_DEBUGCTLMSR, debugctl);
 -		debugctl &= ~DEBUGCTLMSR_BTF;
 -		msk = tifn & _TIF_BLOCKSTEP;
 -		debugctl |= (msk >> TIF_BLOCKSTEP) << DEBUGCTLMSR_BTF_SHIFT;
 -		wrmsrl(MSR_IA32_DEBUGCTLMSR, debugctl);
 -	}
 -
 -	if ((tifp ^ tifn) & _TIF_NOTSC)
 -		cr4_toggle_bits_irqsoff(X86_CR4_TSD);
 -
 -	if ((tifp ^ tifn) & _TIF_NOCPUID)
 -		set_cpuid_faulting(!!(tifn & _TIF_NOCPUID));
 -
 -	if ((tifp ^ tifn) & _TIF_SSBD)
 -		__speculative_store_bypass_update(tifn);
  }
  
  /*
* Unmerged path arch/x86/include/asm/cpufeatures.h
* Unmerged path arch/x86/kernel/cpu/amd.c
* Unmerged path arch/x86/kernel/cpu/bugs.c
* Unmerged path arch/x86/kernel/cpu/common.c
* Unmerged path arch/x86/kernel/cpu/intel.c
* Unmerged path arch/x86/kernel/process.c
