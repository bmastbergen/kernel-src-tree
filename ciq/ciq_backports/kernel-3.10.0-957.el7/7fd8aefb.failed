IB/mlx5: Make netdev notifications multiport capable

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Daniel Jurgens <danielj@mellanox.com>
commit 7fd8aefb7ce202dd9d97f752bf249be6215f1004
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/7fd8aefb.failed

When multiple RoCE ports are supported registration for events on
multiple netdevs is required. Refactor the event registration and
handling to support multiple ports.

	Signed-off-by: Daniel Jurgens <danielj@mellanox.com>
	Reviewed-by: Parav Pandit <parav@mellanox.com>
	Signed-off-by: Leon Romanovsky <leon@kernel.org>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 7fd8aefb7ce202dd9d97f752bf249be6215f1004)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/main.c
diff --cc drivers/infiniband/hw/mlx5/main.c
index 0f4f1df8ee11,5fcb2ed94c11..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -3588,21 -3590,21 +3595,32 @@@ static int mlx5_add_netdev_notifier(str
  {
  	int err;
  
++<<<<<<< HEAD
 +	dev->roce.nb.notifier_call = mlx5_netdev_event;
 +	err = register_netdevice_notifier_rh(&dev->roce.nb);
++=======
+ 	dev->roce[port_num].nb.notifier_call = mlx5_netdev_event;
+ 	err = register_netdevice_notifier(&dev->roce[port_num].nb);
++>>>>>>> 7fd8aefb7ce2 (IB/mlx5: Make netdev notifications multiport capable)
  	if (err) {
- 		dev->roce.nb.notifier_call = NULL;
+ 		dev->roce[port_num].nb.notifier_call = NULL;
  		return err;
  	}
  
  	return 0;
  }
  
- static void mlx5_remove_netdev_notifier(struct mlx5_ib_dev *dev)
+ static void mlx5_remove_netdev_notifier(struct mlx5_ib_dev *dev, u8 port_num)
  {
++<<<<<<< HEAD
 +	if (dev->roce.nb.notifier_call) {
 +		unregister_netdevice_notifier_rh(&dev->roce.nb);
 +		dev->roce.nb.notifier_call = NULL;
++=======
+ 	if (dev->roce[port_num].nb.notifier_call) {
+ 		unregister_netdevice_notifier(&dev->roce[port_num].nb);
+ 		dev->roce[port_num].nb.notifier_call = NULL;
++>>>>>>> 7fd8aefb7ce2 (IB/mlx5: Make netdev notifications multiport capable)
  	}
  }
  
@@@ -4052,32 -4054,25 +4070,31 @@@ mlx5_ib_get_vector_affinity(struct ib_d
  	return mlx5_get_vector_affinity(dev->mdev, comp_vector);
  }
  
 -static void mlx5_ib_stage_init_cleanup(struct mlx5_ib_dev *dev)
 -{
 -#ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
 -	cleanup_srcu_struct(&dev->mr_srcu);
 -#endif
 -	kfree(dev->port);
 -}
 -
 -static int mlx5_ib_stage_init_init(struct mlx5_ib_dev *dev)
 +static void *mlx5_ib_add(struct mlx5_core_dev *mdev)
  {
 -	struct mlx5_core_dev *mdev = dev->mdev;
 +	struct mlx5_ib_dev *dev;
 +	enum rdma_link_layer ll;
 +	int port_type_cap;
  	const char *name;
  	int err;
 +	int i;
 +
 +	port_type_cap = MLX5_CAP_GEN(mdev, port_type);
 +	ll = mlx5_port_type_cap_to_rdma_ll(port_type_cap);
 +
 +	printk_once(KERN_INFO "%s", mlx5_version);
 +
 +	dev = (struct mlx5_ib_dev *)ib_alloc_device(sizeof(*dev));
 +	if (!dev)
 +		return NULL;
 +
 +	dev->mdev = mdev;
  
 -	dev->port = kcalloc(dev->num_ports, sizeof(*dev->port),
 +	dev->port = kcalloc(MLX5_CAP_GEN(mdev, num_ports), sizeof(*dev->port),
  			    GFP_KERNEL);
  	if (!dev->port)
 -		return -ENOMEM;
 +		goto err_dealloc;
  
- 	rwlock_init(&dev->roce.netdev_lock);
  	err = get_port_caps(dev);
  	if (err)
  		goto err_free_port;
@@@ -4227,8 -4236,38 +4244,43 @@@
  			(1ull << IB_USER_VERBS_EX_CMD_CREATE_FLOW) |
  			(1ull << IB_USER_VERBS_EX_CMD_DESTROY_FLOW);
  
++<<<<<<< HEAD
 +	if (mlx5_ib_port_link_layer(&dev->ib_dev, 1) ==
 +	    IB_LINK_LAYER_ETHERNET) {
++=======
+ 	err = init_node_data(dev);
+ 	if (err)
+ 		return err;
+ 
+ 	if ((MLX5_CAP_GEN(dev->mdev, port_type) == MLX5_CAP_PORT_TYPE_ETH) &&
+ 	    MLX5_CAP_GEN(dev->mdev, disable_local_lb))
+ 		mutex_init(&dev->lb_mutex);
+ 
+ 	return 0;
+ }
+ 
+ static int mlx5_ib_stage_roce_init(struct mlx5_ib_dev *dev)
+ {
+ 	struct mlx5_core_dev *mdev = dev->mdev;
+ 	enum rdma_link_layer ll;
+ 	int port_type_cap;
+ 	u8 port_num = 0;
+ 	int err;
+ 	int i;
+ 
+ 	port_type_cap = MLX5_CAP_GEN(mdev, port_type);
+ 	ll = mlx5_port_type_cap_to_rdma_ll(port_type_cap);
+ 
+ 	if (ll == IB_LINK_LAYER_ETHERNET) {
+ 		for (i = 0; i < dev->num_ports; i++) {
+ 			rwlock_init(&dev->roce[i].netdev_lock);
+ 			dev->roce[i].dev = dev;
+ 			dev->roce[i].native_port_num = i + 1;
+ 			dev->roce[i].last_port_state = IB_PORT_DOWN;
+ 		}
+ 
+ 		dev->ib_dev.get_netdev	= mlx5_ib_get_netdev;
++>>>>>>> 7fd8aefb7ce2 (IB/mlx5: Make netdev notifications multiport capable)
  		dev->ib_dev.create_wq	 = mlx5_ib_create_wq;
  		dev->ib_dev.modify_wq	 = mlx5_ib_modify_wq;
  		dev->ib_dev.destroy_wq	 = mlx5_ib_destroy_wq;
@@@ -4240,44 -4279,91 +4292,88 @@@
  			(1ull << IB_USER_VERBS_EX_CMD_DESTROY_WQ) |
  			(1ull << IB_USER_VERBS_EX_CMD_CREATE_RWQ_IND_TBL) |
  			(1ull << IB_USER_VERBS_EX_CMD_DESTROY_RWQ_IND_TBL);
++<<<<<<< HEAD
 +	}
 +	err = init_node_data(dev);
 +	if (err)
 +		goto err_free_port;
 +
 +	mutex_init(&dev->flow_db.lock);
 +	mutex_init(&dev->cap_mask_mutex);
 +	INIT_LIST_HEAD(&dev->qp_list);
 +	spin_lock_init(&dev->reset_flow_resource_lock);
 +
 +	if (ll == IB_LINK_LAYER_ETHERNET) {
 +		err = mlx5_enable_eth(dev);
 +		if (err)
 +			goto err_free_port;
 +		dev->roce.last_port_state = IB_PORT_DOWN;
++=======
+ 		err = mlx5_enable_eth(dev, port_num);
+ 		if (err)
+ 			return err;
++>>>>>>> 7fd8aefb7ce2 (IB/mlx5: Make netdev notifications multiport capable)
  	}
  
 -	return 0;
 -}
 +	err = create_dev_resources(&dev->devr);
 +	if (err)
 +		goto err_disable_eth;
  
++<<<<<<< HEAD
 +	err = mlx5_ib_odp_init_one(dev);
 +	if (err)
 +		goto err_rsrc;
 +
++=======
+ static void mlx5_ib_stage_roce_cleanup(struct mlx5_ib_dev *dev)
+ {
+ 	struct mlx5_core_dev *mdev = dev->mdev;
+ 	enum rdma_link_layer ll;
+ 	int port_type_cap;
+ 	u8 port_num = 0;
+ 
+ 	port_type_cap = MLX5_CAP_GEN(mdev, port_type);
+ 	ll = mlx5_port_type_cap_to_rdma_ll(port_type_cap);
+ 
+ 	if (ll == IB_LINK_LAYER_ETHERNET) {
+ 		mlx5_disable_eth(dev);
+ 		mlx5_remove_netdev_notifier(dev, port_num);
+ 	}
+ }
+ 
+ static int mlx5_ib_stage_dev_res_init(struct mlx5_ib_dev *dev)
+ {
+ 	return create_dev_resources(&dev->devr);
+ }
+ 
+ static void mlx5_ib_stage_dev_res_cleanup(struct mlx5_ib_dev *dev)
+ {
+ 	destroy_dev_resources(&dev->devr);
+ }
+ 
+ static int mlx5_ib_stage_odp_init(struct mlx5_ib_dev *dev)
+ {
+ 	mlx5_ib_internal_fill_odp_caps(dev);
+ 
+ 	return mlx5_ib_odp_init_one(dev);
+ }
+ 
+ static int mlx5_ib_stage_counters_init(struct mlx5_ib_dev *dev)
+ {
++>>>>>>> 7fd8aefb7ce2 (IB/mlx5: Make netdev notifications multiport capable)
  	if (MLX5_CAP_GEN(dev->mdev, max_qp_cnt)) {
 -		dev->ib_dev.get_hw_stats	= mlx5_ib_get_hw_stats;
 -		dev->ib_dev.alloc_hw_stats	= mlx5_ib_alloc_hw_stats;
 -
 -		return mlx5_ib_alloc_counters(dev);
 +		err = mlx5_ib_alloc_counters(dev);
 +		if (err)
 +			goto err_odp;
  	}
  
 -	return 0;
 -}
 -
 -static void mlx5_ib_stage_counters_cleanup(struct mlx5_ib_dev *dev)
 -{
 -	if (MLX5_CAP_GEN(dev->mdev, max_qp_cnt))
 -		mlx5_ib_dealloc_counters(dev);
 -}
 -
 -static int mlx5_ib_stage_cong_debugfs_init(struct mlx5_ib_dev *dev)
 -{
 -	return mlx5_ib_init_cong_debugfs(dev);
 -}
 -
 -static void mlx5_ib_stage_cong_debugfs_cleanup(struct mlx5_ib_dev *dev)
 -{
 -	mlx5_ib_cleanup_cong_debugfs(dev);
 -}
 +	err = mlx5_ib_init_cong_debugfs(dev);
 +	if (err)
 +		goto err_cnt;
  
 -static int mlx5_ib_stage_uar_init(struct mlx5_ib_dev *dev)
 -{
  	dev->mdev->priv.uar = mlx5_get_uars_page(dev->mdev);
 -	if (!dev->mdev->priv.uar)
 -		return -ENOMEM;
 -	return 0;
 -}
 -
 -static void mlx5_ib_stage_uar_cleanup(struct mlx5_ib_dev *dev)
 -{
 -	mlx5_put_uars_page(dev->mdev, dev->mdev->priv.uar);
 -}
 -
 -static int mlx5_ib_stage_bfrag_init(struct mlx5_ib_dev *dev)
 -{
 -	int err;
 +	if (IS_ERR(dev->mdev->priv.uar))
 +		goto err_cong;
  
  	err = mlx5_alloc_bfreg(dev->mdev, &dev->bfreg, false, false);
  	if (err)
* Unmerged path drivers/infiniband/hw/mlx5/main.c
diff --git a/drivers/infiniband/hw/mlx5/mlx5_ib.h b/drivers/infiniband/hw/mlx5/mlx5_ib.h
index 11ef2d2f4974..6b7d54ddd478 100644
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -667,6 +667,8 @@ struct mlx5_roce {
 	struct notifier_block	nb;
 	atomic_t		next_port;
 	enum ib_port_state last_port_state;
+	struct mlx5_ib_dev	*dev;
+	u8			native_port_num;
 };
 
 struct mlx5_ib_dbg_param {
@@ -728,7 +730,7 @@ struct mlx5_ib_delay_drop {
 struct mlx5_ib_dev {
 	struct ib_device		ib_dev;
 	struct mlx5_core_dev		*mdev;
-	struct mlx5_roce		roce;
+	struct mlx5_roce		roce[MLX5_MAX_PORTS];
 	int				num_ports;
 	/* serialize update of capability mask
 	 */
diff --git a/drivers/infiniband/hw/mlx5/qp.c b/drivers/infiniband/hw/mlx5/qp.c
index 8dd30da62791..8b2d9f6ee5b6 100644
--- a/drivers/infiniband/hw/mlx5/qp.c
+++ b/drivers/infiniband/hw/mlx5/qp.c
@@ -2962,8 +2962,9 @@ static int __mlx5_ib_modify_qp(struct ib_qp *ibqp,
 		    (ibqp->qp_type == IB_QPT_XRC_INI) ||
 		    (ibqp->qp_type == IB_QPT_XRC_TGT)) {
 			if (mlx5_lag_is_active(dev->mdev)) {
+				u8 p = mlx5_core_native_port_num(dev->mdev);
 				tx_affinity = (unsigned int)atomic_add_return(1,
-						&dev->roce.next_port) %
+						&dev->roce[p].next_port) %
 						MLX5_MAX_PORTS + 1;
 				context->flags |= cpu_to_be32(tx_affinity << 24);
 			}
diff --git a/include/linux/mlx5/driver.h b/include/linux/mlx5/driver.h
index eb5400f89ba1..37acaf18d98c 100644
--- a/include/linux/mlx5/driver.h
+++ b/include/linux/mlx5/driver.h
@@ -1233,6 +1233,11 @@ static inline bool mlx5_rl_is_supported(struct mlx5_core_dev *dev)
 	return !!(dev->priv.rl_table.max_size);
 }
 
+static inline int mlx5_core_native_port_num(struct mlx5_core_dev *dev)
+{
+	return 1;
+}
+
 enum {
 	MLX5_TRIGGERED_CMD_COMP = (u64)1 << 32,
 };
