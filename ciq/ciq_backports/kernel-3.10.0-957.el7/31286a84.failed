mm: hwpoison: disable memory error handling on 1GB hugepage

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [mm] hwpoison: disable memory error handling on 1GB hugepage (Aristeu Rozanski) [1525701]
Rebuild_FUZZ: 96.49%
commit-author Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
commit 31286a8484a85e8b4e91ddb0f5415aee8a416827
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/31286a84.failed

Recently the following BUG was reported:

    Injecting memory failure for pfn 0x3c0000 at process virtual address 0x7fe300000000
    Memory failure: 0x3c0000: recovery action for huge page: Recovered
    BUG: unable to handle kernel paging request at ffff8dfcc0003000
    IP: gup_pgd_range+0x1f0/0xc20
    PGD 17ae72067 P4D 17ae72067 PUD 0
    Oops: 0000 [#1] SMP PTI
    ...
    CPU: 3 PID: 5467 Comm: hugetlb_1gb Not tainted 4.15.0-rc8-mm1-abc+ #3
    Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.9.3-1.fc25 04/01/2014

You can easily reproduce this by calling madvise(MADV_HWPOISON) twice on
a 1GB hugepage.  This happens because get_user_pages_fast() is not aware
of a migration entry on pud that was created in the 1st madvise() event.

I think that conversion to pud-aligned migration entry is working, but
other MM code walking over page table isn't prepared for it.  We need
some time and effort to make all this work properly, so this patch
avoids the reported bug by just disabling error handling for 1GB
hugepage.

[n-horiguchi@ah.jp.nec.com: v2]
  Link: http://lkml.kernel.org/r/1517284444-18149-1-git-send-email-n-horiguchi@ah.jp.nec.com
Link: http://lkml.kernel.org/r/1517207283-15769-1-git-send-email-n-horiguchi@ah.jp.nec.com
	Signed-off-by: Naoya Horiguchi <n-horiguchi@ah.jp.nec.com>
	Acked-by: Michal Hocko <mhocko@suse.com>
	Reviewed-by: Andrew Morton <akpm@linux-foundation.org>
	Reviewed-by: Mike Kravetz <mike.kravetz@oracle.com>
	Acked-by: Punit Agrawal <punit.agrawal@arm.com>
	Tested-by: Michael Ellerman <mpe@ellerman.id.au>
	Cc: Anshuman Khandual <khandual@linux.vnet.ibm.com>
	Cc: "Aneesh Kumar K.V" <aneesh.kumar@linux.vnet.ibm.com>
	Cc: <stable@vger.kernel.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 31286a8484a85e8b4e91ddb0f5415aee8a416827)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/mm.h
#	mm/memory-failure.c
diff --cc include/linux/mm.h
index 329d8a2b3e80,2e2be527642a..000000000000
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@@ -2401,9 -2594,44 +2401,47 @@@ extern void shake_page(struct page *p, 
  extern atomic_long_t num_poisoned_pages;
  extern int soft_offline_page(struct page *page, int flags);
  
++<<<<<<< HEAD
++=======
+ 
+ /*
+  * Error handlers for various types of pages.
+  */
+ enum mf_result {
+ 	MF_IGNORED,	/* Error: cannot be handled */
+ 	MF_FAILED,	/* Error: handling failed */
+ 	MF_DELAYED,	/* Will be handled later */
+ 	MF_RECOVERED,	/* Successfully recovered */
+ };
+ 
+ enum mf_action_page_type {
+ 	MF_MSG_KERNEL,
+ 	MF_MSG_KERNEL_HIGH_ORDER,
+ 	MF_MSG_SLAB,
+ 	MF_MSG_DIFFERENT_COMPOUND,
+ 	MF_MSG_POISONED_HUGE,
+ 	MF_MSG_HUGE,
+ 	MF_MSG_FREE_HUGE,
+ 	MF_MSG_NON_PMD_HUGE,
+ 	MF_MSG_UNMAP_FAILED,
+ 	MF_MSG_DIRTY_SWAPCACHE,
+ 	MF_MSG_CLEAN_SWAPCACHE,
+ 	MF_MSG_DIRTY_MLOCKED_LRU,
+ 	MF_MSG_CLEAN_MLOCKED_LRU,
+ 	MF_MSG_DIRTY_UNEVICTABLE_LRU,
+ 	MF_MSG_CLEAN_UNEVICTABLE_LRU,
+ 	MF_MSG_DIRTY_LRU,
+ 	MF_MSG_CLEAN_LRU,
+ 	MF_MSG_TRUNCATED_LRU,
+ 	MF_MSG_BUDDY,
+ 	MF_MSG_BUDDY_2ND,
+ 	MF_MSG_UNKNOWN,
+ };
+ 
++>>>>>>> 31286a8484a8 (mm: hwpoison: disable memory error handling on 1GB hugepage)
  #if defined(CONFIG_TRANSPARENT_HUGEPAGE) || defined(CONFIG_HUGETLBFS)
  extern void clear_huge_page(struct page *page,
 -			    unsigned long addr_hint,
 +			    unsigned long addr,
  			    unsigned int pages_per_huge_page);
  extern void copy_user_huge_page(struct page *dst, struct page *src,
  				unsigned long addr, struct vm_area_struct *vma,
diff --cc mm/memory-failure.c
index e377f767503f,2d4bf647cf01..000000000000
--- a/mm/memory-failure.c
+++ b/mm/memory-failure.c
@@@ -517,22 -487,35 +517,47 @@@ static void collect_procs(struct page *
  	kfree(tk);
  }
  
 -static const char *action_name[] = {
 -	[MF_IGNORED] = "Ignored",
 -	[MF_FAILED] = "Failed",
 -	[MF_DELAYED] = "Delayed",
 -	[MF_RECOVERED] = "Recovered",
 +/*
 + * Error handlers for various types of pages.
 + */
 +
 +enum outcome {
 +	IGNORED,	/* Error: cannot be handled */
 +	FAILED,		/* Error: handling failed */
 +	DELAYED,	/* Will be handled later */
 +	RECOVERED,	/* Successfully recovered */
  };
  
++<<<<<<< HEAD
 +static const char *action_name[] = {
 +	[IGNORED] = "Ignored",
 +	[FAILED] = "Failed",
 +	[DELAYED] = "Delayed",
 +	[RECOVERED] = "Recovered",
++=======
+ static const char * const action_page_types[] = {
+ 	[MF_MSG_KERNEL]			= "reserved kernel page",
+ 	[MF_MSG_KERNEL_HIGH_ORDER]	= "high-order kernel page",
+ 	[MF_MSG_SLAB]			= "kernel slab page",
+ 	[MF_MSG_DIFFERENT_COMPOUND]	= "different compound page after locking",
+ 	[MF_MSG_POISONED_HUGE]		= "huge page already hardware poisoned",
+ 	[MF_MSG_HUGE]			= "huge page",
+ 	[MF_MSG_FREE_HUGE]		= "free huge page",
+ 	[MF_MSG_NON_PMD_HUGE]		= "non-pmd-sized huge page",
+ 	[MF_MSG_UNMAP_FAILED]		= "unmapping failed page",
+ 	[MF_MSG_DIRTY_SWAPCACHE]	= "dirty swapcache page",
+ 	[MF_MSG_CLEAN_SWAPCACHE]	= "clean swapcache page",
+ 	[MF_MSG_DIRTY_MLOCKED_LRU]	= "dirty mlocked LRU page",
+ 	[MF_MSG_CLEAN_MLOCKED_LRU]	= "clean mlocked LRU page",
+ 	[MF_MSG_DIRTY_UNEVICTABLE_LRU]	= "dirty unevictable LRU page",
+ 	[MF_MSG_CLEAN_UNEVICTABLE_LRU]	= "clean unevictable LRU page",
+ 	[MF_MSG_DIRTY_LRU]		= "dirty LRU page",
+ 	[MF_MSG_CLEAN_LRU]		= "clean LRU page",
+ 	[MF_MSG_TRUNCATED_LRU]		= "already truncated LRU page",
+ 	[MF_MSG_BUDDY]			= "free buddy page",
+ 	[MF_MSG_BUDDY_2ND]		= "free buddy page (2nd try)",
+ 	[MF_MSG_UNKNOWN]		= "unknown page",
++>>>>>>> 31286a8484a8 (mm: hwpoison: disable memory error handling on 1GB hugepage)
  };
  
  /*
@@@ -1013,26 -1012,104 +1038,97 @@@ static int hwpoison_user_mappings(struc
  	 * any accesses to the poisoned memory.
  	 */
  	forcekill = PageDirty(hpage) || (flags & MF_MUST_KILL);
 -	kill_procs(&tokill, forcekill, !unmap_success, p, pfn, flags);
 +	kill_procs(&tokill, forcekill, trapno,
 +		      ret != SWAP_SUCCESS, p, pfn, flags);
  
 -	return unmap_success;
 +	return ret;
  }
  
 -static int identify_page_state(unsigned long pfn, struct page *p,
 -				unsigned long page_flags)
 +static void set_page_hwpoison_huge_page(struct page *hpage)
  {
 -	struct page_state *ps;
 -
 -	/*
 -	 * The first check uses the current page flags which may not have any
 -	 * relevant information. The second check with the saved page flags is
 -	 * carried out only if the first check can't determine the page status.
 -	 */
 -	for (ps = error_states;; ps++)
 -		if ((p->flags & ps->mask) == ps->res)
 -			break;
 -
 -	page_flags |= (p->flags & (1UL << PG_dirty));
 -
 -	if (!ps->mask)
 -		for (ps = error_states;; ps++)
 -			if ((page_flags & ps->mask) == ps->res)
 -				break;
 -	return page_action(ps, p, pfn);
 +	int i;
 +	int nr_pages = 1 << compound_order(hpage);
 +	for (i = 0; i < nr_pages; i++)
 +		SetPageHWPoison(hpage + i);
  }
  
 -static int memory_failure_hugetlb(unsigned long pfn, int flags)
 +static void clear_page_hwpoison_huge_page(struct page *hpage)
  {
++<<<<<<< HEAD
 +	int i;
 +	int nr_pages = 1 << compound_order(hpage);
 +	for (i = 0; i < nr_pages; i++)
 +		ClearPageHWPoison(hpage + i);
++=======
+ 	struct page *p = pfn_to_page(pfn);
+ 	struct page *head = compound_head(p);
+ 	int res;
+ 	unsigned long page_flags;
+ 
+ 	if (TestSetPageHWPoison(head)) {
+ 		pr_err("Memory failure: %#lx: already hardware poisoned\n",
+ 		       pfn);
+ 		return 0;
+ 	}
+ 
+ 	num_poisoned_pages_inc();
+ 
+ 	if (!(flags & MF_COUNT_INCREASED) && !get_hwpoison_page(p)) {
+ 		/*
+ 		 * Check "filter hit" and "race with other subpage."
+ 		 */
+ 		lock_page(head);
+ 		if (PageHWPoison(head)) {
+ 			if ((hwpoison_filter(p) && TestClearPageHWPoison(p))
+ 			    || (p != head && TestSetPageHWPoison(head))) {
+ 				num_poisoned_pages_dec();
+ 				unlock_page(head);
+ 				return 0;
+ 			}
+ 		}
+ 		unlock_page(head);
+ 		dissolve_free_huge_page(p);
+ 		action_result(pfn, MF_MSG_FREE_HUGE, MF_DELAYED);
+ 		return 0;
+ 	}
+ 
+ 	lock_page(head);
+ 	page_flags = head->flags;
+ 
+ 	if (!PageHWPoison(head)) {
+ 		pr_err("Memory failure: %#lx: just unpoisoned\n", pfn);
+ 		num_poisoned_pages_dec();
+ 		unlock_page(head);
+ 		put_hwpoison_page(head);
+ 		return 0;
+ 	}
+ 
+ 	/*
+ 	 * TODO: hwpoison for pud-sized hugetlb doesn't work right now, so
+ 	 * simply disable it. In order to make it work properly, we need
+ 	 * make sure that:
+ 	 *  - conversion of a pud that maps an error hugetlb into hwpoison
+ 	 *    entry properly works, and
+ 	 *  - other mm code walking over page table is aware of pud-aligned
+ 	 *    hwpoison entries.
+ 	 */
+ 	if (huge_page_size(page_hstate(head)) > PMD_SIZE) {
+ 		action_result(pfn, MF_MSG_NON_PMD_HUGE, MF_IGNORED);
+ 		res = -EBUSY;
+ 		goto out;
+ 	}
+ 
+ 	if (!hwpoison_user_mappings(p, pfn, flags, &head)) {
+ 		action_result(pfn, MF_MSG_UNMAP_FAILED, MF_IGNORED);
+ 		res = -EBUSY;
+ 		goto out;
+ 	}
+ 
+ 	res = identify_page_state(pfn, p, page_flags);
+ out:
+ 	unlock_page(head);
+ 	return res;
++>>>>>>> 31286a8484a8 (mm: hwpoison: disable memory error handling on 1GB hugepage)
  }
  
  /**
* Unmerged path include/linux/mm.h
* Unmerged path mm/memory-failure.c
