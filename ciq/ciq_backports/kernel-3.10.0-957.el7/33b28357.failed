scsi: qla2xxx: Fix Async GPN_FT for FCP and FC-NVMe scan

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [scsi] qla2xxx: Fix Async GPN_FT for FCP and FC-NVMe scan (Himanshu Madhani) [1547714]
Rebuild_FUZZ: 94.34%
commit-author Quinn Tran <quinn.tran@cavium.com>
commit 33b28357dd0033ef0e146861cd575a9c5ed2fb5e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/33b28357.failed

This patch combines FCP and FC-NVMe scan into single scan when
driver detects FC-NVMe capability on same port.

	Signed-off-by: Quinn Tran <quinn.tran@cavium.com>
	Signed-off-by: Himanshu Madhani <himanshu.madhani@cavium.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit 33b28357dd0033ef0e146861cd575a9c5ed2fb5e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/qla2xxx/qla_def.h
#	drivers/scsi/qla2xxx/qla_gbl.h
#	drivers/scsi/qla2xxx/qla_gs.c
#	drivers/scsi/qla2xxx/qla_init.c
#	drivers/scsi/qla2xxx/qla_os.c
diff --cc drivers/scsi/qla2xxx/qla_def.h
index d0397ca42fad,54625eb2904f..000000000000
--- a/drivers/scsi/qla2xxx/qla_def.h
+++ b/drivers/scsi/qla2xxx/qla_def.h
@@@ -2856,6 -2971,39 +2857,42 @@@ struct ct_sns_pkt 
  	} p;
  };
  
++<<<<<<< HEAD
++=======
+ struct ct_sns_gpnft_pkt {
+ 	union {
+ 		struct ct_sns_req req;
+ 		struct ct_sns_gpnft_rsp rsp;
+ 	} p;
+ };
+ 
+ enum scan_flags_t {
+ 	SF_SCANNING = BIT_0,
+ 	SF_QUEUED = BIT_1,
+ };
+ 
+ enum fc4type_t {
+ 	FS_FC4TYPE_FCP	= BIT_0,
+ 	FS_FC4TYPE_NVME	= BIT_1,
+ };
+ 
+ struct fab_scan_rp {
+ 	port_id_t id;
+ 	enum fc4type_t fc4type;
+ 	u8 port_name[8];
+ 	u8 node_name[8];
+ };
+ 
+ struct fab_scan {
+ 	struct fab_scan_rp *l;
+ 	u32 size;
+ 	u16 scan_retry;
+ #define MAX_SCAN_RETRIES 5
+ 	enum scan_flags_t scan_flags;
+ 	struct delayed_work scan_work;
+ };
+ 
++>>>>>>> 33b28357dd00 (scsi: qla2xxx: Fix Async GPN_FT for FCP and FC-NVMe scan)
  /*
   * SNS command structures -- for 2200 compatibility.
   */
@@@ -3120,6 -3280,10 +3157,13 @@@ struct qla_work_evt 
  			u8 iocb[IOCB_SIZE];
  			int type;
  		} nack;
++<<<<<<< HEAD
++=======
+ 		struct {
+ 			u8 fc4_type;
+ 			srb_t *sp;
+ 		} gpnft;
++>>>>>>> 33b28357dd00 (scsi: qla2xxx: Fix Async GPN_FT for FCP and FC-NVMe scan)
  	 } u;
  };
  
diff --cc drivers/scsi/qla2xxx/qla_gbl.h
index b82df4e47b9c,3c4c84ed0f0f..000000000000
--- a/drivers/scsi/qla2xxx/qla_gbl.h
+++ b/drivers/scsi/qla2xxx/qla_gbl.h
@@@ -635,7 -654,21 +635,23 @@@ void qla24xx_handle_gpnid_event(scsi_ql
  
  int qla24xx_post_gpsc_work(struct scsi_qla_host *, fc_port_t *);
  int qla24xx_async_gpsc(scsi_qla_host_t *, fc_port_t *);
 -void qla24xx_handle_gpsc_event(scsi_qla_host_t *, struct event_arg *);
  int qla2x00_mgmt_svr_login(scsi_qla_host_t *);
++<<<<<<< HEAD
++=======
+ void qla24xx_handle_gffid_event(scsi_qla_host_t *vha, struct event_arg *ea);
+ int qla24xx_async_gffid(scsi_qla_host_t *vha, fc_port_t *fcport);
+ int qla24xx_async_gpnft(scsi_qla_host_t *, u8, srb_t *);
+ void qla24xx_async_gpnft_done(scsi_qla_host_t *, srb_t *);
+ void qla24xx_async_gnnft_done(scsi_qla_host_t *, srb_t *);
+ int qla24xx_async_gnnid(scsi_qla_host_t *, fc_port_t *);
+ void qla24xx_handle_gnnid_event(scsi_qla_host_t *, struct event_arg *);
+ int qla24xx_post_gnnid_work(struct scsi_qla_host *, fc_port_t *);
+ int qla24xx_post_gfpnid_work(struct scsi_qla_host *, fc_port_t *);
+ int qla24xx_async_gfpnid(scsi_qla_host_t *, fc_port_t *);
+ void qla24xx_handle_gfpnid_event(scsi_qla_host_t *, struct event_arg *);
+ void qla24xx_sp_unmap(scsi_qla_host_t *, srb_t *);
+ void qla_scan_work_fn(struct work_struct *);
++>>>>>>> 33b28357dd00 (scsi: qla2xxx: Fix Async GPN_FT for FCP and FC-NVMe scan)
  
  /*
   * Global Function Prototypes in qla_attr.c source file.
diff --cc drivers/scsi/qla2xxx/qla_gs.c
index 985af1dbf875,39dd62b8c649..000000000000
--- a/drivers/scsi/qla2xxx/qla_gs.c
+++ b/drivers/scsi/qla2xxx/qla_gs.c
@@@ -3326,3 -3719,972 +3326,975 @@@ done_free_sp
  done:
  	return rval;
  }
++<<<<<<< HEAD
++=======
+ 
+ void qla24xx_handle_gffid_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+        fc_port_t *fcport = ea->fcport;
+ 
+        qla24xx_post_gnl_work(vha, fcport);
+ }
+ 
+ void qla24xx_async_gffid_sp_done(void *s, int res)
+ {
+        struct srb *sp = s;
+        struct scsi_qla_host *vha = sp->vha;
+        fc_port_t *fcport = sp->fcport;
+        struct ct_sns_rsp *ct_rsp;
+        struct event_arg ea;
+ 
+        ql_dbg(ql_dbg_disc, vha, 0x2133,
+ 	   "Async done-%s res %x ID %x. %8phC\n",
+ 	   sp->name, res, fcport->d_id.b24, fcport->port_name);
+ 
+        fcport->flags &= ~FCF_ASYNC_SENT;
+        ct_rsp = &fcport->ct_desc.ct_sns->p.rsp;
+        /*
+ 	* FC-GS-7, 5.2.3.12 FC-4 Features - format
+ 	* The format of the FC-4 Features object, as defined by the FC-4,
+ 	* Shall be an array of 4-bit values, one for each type code value
+ 	*/
+        if (!res) {
+ 	       if (ct_rsp->rsp.gff_id.fc4_features[GFF_FCP_SCSI_OFFSET] & 0xf) {
+ 		       /* w1 b00:03 */
+ 		       fcport->fc4_type =
+ 			   ct_rsp->rsp.gff_id.fc4_features[GFF_FCP_SCSI_OFFSET];
+ 		       fcport->fc4_type &= 0xf;
+ 	       }
+ 
+ 	       if (ct_rsp->rsp.gff_id.fc4_features[GFF_NVME_OFFSET] & 0xf) {
+ 		       /* w5 [00:03]/28h */
+ 		       fcport->fc4f_nvme =
+ 			   ct_rsp->rsp.gff_id.fc4_features[GFF_NVME_OFFSET];
+ 		       fcport->fc4f_nvme &= 0xf;
+ 	       }
+        }
+ 
+        memset(&ea, 0, sizeof(ea));
+        ea.sp = sp;
+        ea.fcport = sp->fcport;
+        ea.rc = res;
+        ea.event = FCME_GFFID_DONE;
+ 
+        qla2x00_fcport_event_handler(vha, &ea);
+        sp->free(sp);
+ }
+ 
+ /* Get FC4 Feature with Nport ID. */
+ int qla24xx_async_gffid(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online || (fcport->flags & FCF_ASYNC_SENT))
+ 		return rval;
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		return rval;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gffid";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(fcport->ct_desc.ct_sns, GFF_ID_CMD,
+ 	    GFF_ID_RSP_SIZE);
+ 
+ 	ct_req->req.gff_id.port_id[0] = fcport->d_id.b.domain;
+ 	ct_req->req.gff_id.port_id[1] = fcport->d_id.b.area;
+ 	ct_req->req.gff_id.port_id[2] = fcport->d_id.b.al_pa;
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GFF_ID_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GFF_ID_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla24xx_async_gffid_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2132,
+ 	    "Async-%s hdl=%x  %8phC.\n", sp->name,
+ 	    sp->handle, fcport->port_name);
+ 
+ 	return rval;
+ done_free_sp:
+ 	sp->free(sp);
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ /* GPN_FT + GNN_FT*/
+ static int qla2x00_is_a_vp(scsi_qla_host_t *vha, u64 wwn)
+ {
+ 	struct qla_hw_data *ha = vha->hw;
+ 	scsi_qla_host_t *vp;
+ 	unsigned long flags;
+ 	u64 twwn;
+ 	int rc = 0;
+ 
+ 	if (!ha->num_vhosts)
+ 		return 0;
+ 
+ 	spin_lock_irqsave(&ha->vport_slock, flags);
+ 	list_for_each_entry(vp, &ha->vp_list, list) {
+ 		twwn = wwn_to_u64(vp->port_name);
+ 		if (wwn == twwn) {
+ 			rc = 1;
+ 			break;
+ 		}
+ 	}
+ 	spin_unlock_irqrestore(&ha->vport_slock, flags);
+ 
+ 	return rc;
+ }
+ 
+ void qla24xx_async_gnnft_done(scsi_qla_host_t *vha, srb_t *sp)
+ {
+ 	fc_port_t *fcport;
+ 	u32 i, rc;
+ 	bool found;
+ 	struct fab_scan_rp *rp;
+ 	unsigned long flags;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s enter\n", __func__);
+ 
+ 	if (sp->gen1 != vha->hw->base_qpair->chip_reset) {
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "%s scan stop due to chip reset %x/%x\n",
+ 		    sp->name, sp->gen1, vha->hw->base_qpair->chip_reset);
+ 		goto out;
+ 	}
+ 
+ 	rc = sp->rc;
+ 	if (rc) {
+ 		vha->scan.scan_retry++;
+ 		if (vha->scan.scan_retry < MAX_SCAN_RETRIES) {
+ 			set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 			set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 			    "Fabric scan failed on all retries.\n");
+ 		}
+ 		goto out;
+ 	}
+ 	vha->scan.scan_retry = 0;
+ 
+ 	list_for_each_entry(fcport, &vha->vp_fcports, list)
+ 		fcport->scan_state = QLA_FCPORT_SCAN;
+ 
+ 	for (i = 0; i < vha->hw->max_fibre_devices; i++) {
+ 		u64 wwn;
+ 
+ 		rp = &vha->scan.l[i];
+ 		found = false;
+ 
+ 		wwn = wwn_to_u64(rp->port_name);
+ 		if (wwn == 0)
+ 			continue;
+ 
+ 		if (!memcmp(rp->port_name, vha->port_name, WWN_SIZE))
+ 			continue;
+ 
+ 		/* Bypass reserved domain fields. */
+ 		if ((rp->id.b.domain & 0xf0) == 0xf0)
+ 			continue;
+ 
+ 		/* Bypass virtual ports of the same host. */
+ 		if (qla2x00_is_a_vp(vha, wwn))
+ 			continue;
+ 
+ 		list_for_each_entry(fcport, &vha->vp_fcports, list) {
+ 			if (memcmp(rp->port_name, fcport->port_name, WWN_SIZE))
+ 				continue;
+ 			fcport->scan_state = QLA_FCPORT_FOUND;
+ 			fcport->d_id.b24 = rp->id.b24;
+ 			found = true;
+ 			/*
+ 			 * If device was not a fabric device before.
+ 			 */
+ 			if ((fcport->flags & FCF_FABRIC_DEVICE) == 0) {
+ 				qla2x00_clear_loop_id(fcport);
+ 				fcport->flags |= FCF_FABRIC_DEVICE;
+ 			}
+ 			break;
+ 		}
+ 
+ 		if (!found) {
+ 			ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 			    "%s %d %8phC post new sess\n",
+ 			    __func__, __LINE__, rp->port_name);
+ 			qla24xx_post_newsess_work(vha, &rp->id, rp->port_name,
+ 			    rp->node_name, NULL, rp->fc4type);
+ 		}
+ 	}
+ 
+ 	/*
+ 	 * Logout all previous fabric dev marked lost, except FCP2 devices.
+ 	 */
+ 	list_for_each_entry(fcport, &vha->vp_fcports, list) {
+ 		if ((fcport->flags & FCF_FABRIC_DEVICE) == 0)
+ 			continue;
+ 
+ 		if (fcport->scan_state != QLA_FCPORT_FOUND) {
+ 			if ((qla_dual_mode_enabled(vha) ||
+ 				qla_ini_mode_enabled(vha)) &&
+ 			    atomic_read(&fcport->state) == FCS_ONLINE) {
+ 				qla2x00_mark_device_lost(vha, fcport,
+ 				    ql2xplogiabsentdevice, 0);
+ 
+ 				if (fcport->loop_id != FC_NO_LOOP_ID &&
+ 				    (fcport->flags & FCF_FCP2_DEVICE) == 0) {
+ 					ql_dbg(ql_dbg_disc, vha, 0x20f0,
+ 					    "%s %d %8phC post del sess\n",
+ 					    __func__, __LINE__,
+ 					    fcport->port_name);
+ 
+ 					qlt_schedule_sess_for_deletion(fcport);
+ 					continue;
+ 				}
+ 			}
+ 		} else
+ 			qla24xx_fcport_handle_login(vha, fcport);
+ 	}
+ 
+ out:
+ 	qla24xx_sp_unmap(vha, sp);
+ 	spin_lock_irqsave(&vha->work_lock, flags);
+ 	vha->scan.scan_flags &= ~SF_SCANNING;
+ 	spin_unlock_irqrestore(&vha->work_lock, flags);
+ }
+ 
+ static void qla2x00_find_free_fcp_nvme_slot(struct scsi_qla_host *vha,
+ 	struct srb *sp)
+ {
+ 	struct qla_hw_data *ha = vha->hw;
+ 	int num_fibre_dev = ha->max_fibre_devices;
+ 	struct ct_sns_req *ct_req =
+ 		(struct ct_sns_req *)sp->u.iocb_cmd.u.ctarg.req;
+ 	struct ct_sns_gpnft_rsp *ct_rsp =
+ 		(struct ct_sns_gpnft_rsp *)sp->u.iocb_cmd.u.ctarg.rsp;
+ 	struct ct_sns_gpn_ft_data *d;
+ 	struct fab_scan_rp *rp;
+ 	u16 cmd = be16_to_cpu(ct_req->command);
+ 	u8 fc4_type = sp->gen2;
+ 	int i, j, k;
+ 	port_id_t id;
+ 	u8 found;
+ 	u64 wwn;
+ 
+ 	j = 0;
+ 	for (i = 0; i < num_fibre_dev; i++) {
+ 		d  = &ct_rsp->entries[i];
+ 
+ 		id.b.rsvd_1 = 0;
+ 		id.b.domain = d->port_id[0];
+ 		id.b.area   = d->port_id[1];
+ 		id.b.al_pa  = d->port_id[2];
+ 		wwn = wwn_to_u64(d->port_name);
+ 
+ 		if (id.b24 == 0 || wwn == 0)
+ 			continue;
+ 
+ 		if (fc4_type == FC4_TYPE_FCP_SCSI) {
+ 			if (cmd == GPN_FT_CMD) {
+ 				rp = &vha->scan.l[j];
+ 				rp->id = id;
+ 				memcpy(rp->port_name, d->port_name, 8);
+ 				j++;
+ 				rp->fc4type = FS_FC4TYPE_FCP;
+ 			} else {
+ 				for (k = 0; k < num_fibre_dev; k++) {
+ 					rp = &vha->scan.l[k];
+ 					if (id.b24 == rp->id.b24) {
+ 						memcpy(rp->node_name,
+ 						    d->port_name, 8);
+ 						break;
+ 					}
+ 				}
+ 			}
+ 		} else {
+ 			/* Search if the fibre device supports FC4_TYPE_NVME */
+ 			if (cmd == GPN_FT_CMD) {
+ 				found = 0;
+ 
+ 				for (k = 0; k < num_fibre_dev; k++) {
+ 					rp = &vha->scan.l[k];
+ 					if (!memcmp(rp->port_name,
+ 					    d->port_name, 8)) {
+ 						/*
+ 						 * Supports FC-NVMe & FCP
+ 						 */
+ 						rp->fc4type |= FS_FC4TYPE_NVME;
+ 						found = 1;
+ 						break;
+ 					}
+ 				}
+ 
+ 				/* We found new FC-NVMe only port */
+ 				if (!found) {
+ 					for (k = 0; k < num_fibre_dev; k++) {
+ 						rp = &vha->scan.l[k];
+ 						if (wwn_to_u64(rp->port_name)) {
+ 							continue;
+ 						} else {
+ 							rp->id = id;
+ 							memcpy(rp->port_name,
+ 							    d->port_name, 8);
+ 							rp->fc4type =
+ 							    FS_FC4TYPE_NVME;
+ 							break;
+ 						}
+ 					}
+ 				}
+ 			} else {
+ 				for (k = 0; k < num_fibre_dev; k++) {
+ 					rp = &vha->scan.l[k];
+ 					if (id.b24 == rp->id.b24) {
+ 						memcpy(rp->node_name,
+ 						    d->port_name, 8);
+ 						break;
+ 					}
+ 				}
+ 			}
+ 		}
+ 	}
+ }
+ 
+ static void qla2x00_async_gpnft_gnnft_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	struct qla_work_evt *e;
+ 	struct ct_sns_req *ct_req =
+ 		(struct ct_sns_req *)sp->u.iocb_cmd.u.ctarg.req;
+ 	u16 cmd = be16_to_cpu(ct_req->command);
+ 	u8 fc4_type = sp->gen2;
+ 	unsigned long flags;
+ 
+ 	/* gen2 field is holding the fc4type */
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async done-%s res %x FC4Type %x\n",
+ 	    sp->name, res, sp->gen2);
+ 
+ 	if (res) {
+ 		unsigned long flags;
+ 
+ 		sp->free(sp);
+ 		spin_lock_irqsave(&vha->work_lock, flags);
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		vha->scan.scan_retry++;
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 
+ 		if (vha->scan.scan_retry < MAX_SCAN_RETRIES) {
+ 			set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 			set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 			qla2xxx_wake_dpc(vha);
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, sp->vha, 0xffff,
+ 			    "Async done-%s rescan failed on all retries\n",
+ 			    sp->name);
+ 		}
+ 		return;
+ 	}
+ 
+ 	if (!res)
+ 		qla2x00_find_free_fcp_nvme_slot(vha, sp);
+ 
+ 	if ((fc4_type == FC4_TYPE_FCP_SCSI) && vha->flags.nvme_enabled &&
+ 	    cmd == GNN_FT_CMD) {
+ 		del_timer(&sp->u.iocb_cmd.timer);
+ 		spin_lock_irqsave(&vha->work_lock, flags);
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 
+ 		e = qla2x00_alloc_work(vha, QLA_EVT_GPNFT);
+ 		if (!e) {
+ 			/*
+ 			 * please ignore kernel warning. Otherwise,
+ 			 * we have mem leak.
+ 			 */
+ 			if (sp->u.iocb_cmd.u.ctarg.req) {
+ 				dma_free_coherent(&vha->hw->pdev->dev,
+ 				    sizeof(struct ct_sns_pkt),
+ 				    sp->u.iocb_cmd.u.ctarg.req,
+ 				    sp->u.iocb_cmd.u.ctarg.req_dma);
+ 				sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 			}
+ 			if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 				dma_free_coherent(&vha->hw->pdev->dev,
+ 				    sizeof(struct ct_sns_pkt),
+ 				    sp->u.iocb_cmd.u.ctarg.rsp,
+ 				    sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 				sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 			}
+ 
+ 			ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 			    "Async done-%s unable to alloc work element\n",
+ 			    sp->name);
+ 			sp->free(sp);
+ 			set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 			set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 			return;
+ 		}
+ 		e->u.gpnft.fc4_type = FC4_TYPE_NVME;
+ 		sp->rc = res;
+ 		e->u.gpnft.sp = sp;
+ 
+ 		qla2x00_post_work(vha, e);
+ 		return;
+ 	}
+ 
+ 	if (cmd == GPN_FT_CMD)
+ 		e = qla2x00_alloc_work(vha, QLA_EVT_GPNFT_DONE);
+ 	else
+ 		e = qla2x00_alloc_work(vha, QLA_EVT_GNNFT_DONE);
+ 	if (!e) {
+ 		/* please ignore kernel warning. Otherwise, we have mem leak. */
+ 		if (sp->u.iocb_cmd.u.ctarg.req) {
+ 			dma_free_coherent(&vha->hw->pdev->dev,
+ 			    sizeof(struct ct_sns_pkt),
+ 			    sp->u.iocb_cmd.u.ctarg.req,
+ 			    sp->u.iocb_cmd.u.ctarg.req_dma);
+ 			sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 		}
+ 		if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 			dma_free_coherent(&vha->hw->pdev->dev,
+ 			    sizeof(struct ct_sns_pkt),
+ 			    sp->u.iocb_cmd.u.ctarg.rsp,
+ 			    sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 			sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 		}
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "Async done-%s unable to alloc work element\n",
+ 		    sp->name);
+ 		sp->free(sp);
+ 		set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 		set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 		return;
+ 	}
+ 
+ 	sp->rc = res;
+ 	e->u.iosb.sp = sp;
+ 
+ 	qla2x00_post_work(vha, e);
+ }
+ 
+ /*
+  * Get WWNN list for fc4_type
+  *
+  * It is assumed the same SRB is re-used from GPNFT to avoid
+  * mem free & re-alloc
+  */
+ static int qla24xx_async_gnnft(scsi_qla_host_t *vha, struct srb *sp,
+     u8 fc4_type)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req *ct_req;
+ 	struct ct_sns_pkt *ct_sns;
+ 	unsigned long flags;
+ 
+ 	if (!vha->flags.online) {
+ 		spin_lock_irqsave(&vha->work_lock, flags);
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 		goto done_free_sp;
+ 	}
+ 
+ 	if (!sp->u.iocb_cmd.u.ctarg.req || !sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		ql_log(ql_log_warn, vha, 0xffff,
+ 		    "%s: req %p rsp %p are not setup\n",
+ 		    __func__, sp->u.iocb_cmd.u.ctarg.req,
+ 		    sp->u.iocb_cmd.u.ctarg.rsp);
+ 		spin_lock_irqsave(&vha->work_lock, flags);
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 		WARN_ON(1);
+ 		goto done_free_sp;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xfffff,
+ 	    "%s: FC4Type %x, CT-PASSTRHU %s command ctarg rsp size %d, ctarg req size %d\n",
+ 	    __func__, fc4_type, sp->name, sp->u.iocb_cmd.u.ctarg.rsp_size,
+ 	     sp->u.iocb_cmd.u.ctarg.req_size);
+ 
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gnnft";
+ 	sp->gen1 = vha->hw->base_qpair->chip_reset;
+ 	sp->gen2 = fc4_type;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	memset(sp->u.iocb_cmd.u.ctarg.rsp, 0, sp->u.iocb_cmd.u.ctarg.rsp_size);
+ 	memset(sp->u.iocb_cmd.u.ctarg.req, 0, sp->u.iocb_cmd.u.ctarg.req_size);
+ 
+ 	ct_sns = (struct ct_sns_pkt *)sp->u.iocb_cmd.u.ctarg.req;
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(ct_sns, GNN_FT_CMD,
+ 	    sp->u.iocb_cmd.u.ctarg.rsp_size);
+ 
+ 	/* GPN_FT req */
+ 	ct_req->req.gpn_ft.port_type = fc4_type;
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GNN_FT_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_gpnft_gnnft_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async-%s hdl=%x FC4Type %x.\n", sp->name,
+ 	    sp->handle, ct_req->req.gpn_ft.port_type);
+ 	return rval;
+ 
+ done_free_sp:
+ 	if (sp->u.iocb_cmd.u.ctarg.req) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 		    sizeof(struct ct_sns_pkt),
+ 		    sp->u.iocb_cmd.u.ctarg.req,
+ 		    sp->u.iocb_cmd.u.ctarg.req_dma);
+ 		sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 	}
+ 	if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 		    sizeof(struct ct_sns_pkt),
+ 		    sp->u.iocb_cmd.u.ctarg.rsp,
+ 		    sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 		sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 	}
+ 
+ 	sp->free(sp);
+ 
+ 	return rval;
+ } /* GNNFT */
+ 
+ void qla24xx_async_gpnft_done(scsi_qla_host_t *vha, srb_t *sp)
+ {
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s enter\n", __func__);
+ 	del_timer(&sp->u.iocb_cmd.timer);
+ 	qla24xx_async_gnnft(vha, sp, sp->gen2);
+ }
+ 
+ /* Get WWPN list for certain fc4_type */
+ int qla24xx_async_gpnft(scsi_qla_host_t *vha, u8 fc4_type, srb_t *sp)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	struct ct_sns_pkt *ct_sns;
+ 	u32 rspsz;
+ 	unsigned long flags;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s enter\n", __func__);
+ 
+ 	if (!vha->flags.online)
+ 		return rval;
+ 
+ 	spin_lock_irqsave(&vha->work_lock, flags);
+ 	if (vha->scan.scan_flags & SF_SCANNING) {
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff, "scan active\n");
+ 		return rval;
+ 	}
+ 	vha->scan.scan_flags |= SF_SCANNING;
+ 	spin_unlock_irqrestore(&vha->work_lock, flags);
+ 
+ 	if (fc4_type == FC4_TYPE_FCP_SCSI) {
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "%s: Performing FCP Scan\n", __func__);
+ 
+ 		if (sp)
+ 			sp->free(sp); /* should not happen */
+ 
+ 		sp = qla2x00_get_sp(vha, NULL, GFP_KERNEL);
+ 		if (!sp) {
+ 			spin_lock_irqsave(&vha->work_lock, flags);
+ 			vha->scan.scan_flags &= ~SF_SCANNING;
+ 			spin_unlock_irqrestore(&vha->work_lock, flags);
+ 			return rval;
+ 		}
+ 
+ 		sp->u.iocb_cmd.u.ctarg.req = dma_zalloc_coherent(
+ 			&vha->hw->pdev->dev, sizeof(struct ct_sns_pkt),
+ 			&sp->u.iocb_cmd.u.ctarg.req_dma, GFP_KERNEL);
+ 		if (!sp->u.iocb_cmd.u.ctarg.req) {
+ 			ql_log(ql_log_warn, vha, 0xffff,
+ 			    "Failed to allocate ct_sns request.\n");
+ 			spin_lock_irqsave(&vha->work_lock, flags);
+ 			vha->scan.scan_flags &= ~SF_SCANNING;
+ 			spin_unlock_irqrestore(&vha->work_lock, flags);
+ 			goto done_free_sp;
+ 		}
+ 		sp->u.iocb_cmd.u.ctarg.req_size = GPN_FT_REQ_SIZE;
+ 
+ 		rspsz = sizeof(struct ct_sns_gpnft_rsp) +
+ 			((vha->hw->max_fibre_devices - 1) *
+ 			    sizeof(struct ct_sns_gpn_ft_data));
+ 
+ 		sp->u.iocb_cmd.u.ctarg.rsp = dma_zalloc_coherent(
+ 			&vha->hw->pdev->dev, rspsz,
+ 			&sp->u.iocb_cmd.u.ctarg.rsp_dma, GFP_KERNEL);
+ 		if (!sp->u.iocb_cmd.u.ctarg.rsp) {
+ 			ql_log(ql_log_warn, vha, 0xffff,
+ 			    "Failed to allocate ct_sns request.\n");
+ 			spin_lock_irqsave(&vha->work_lock, flags);
+ 			vha->scan.scan_flags &= ~SF_SCANNING;
+ 			spin_unlock_irqrestore(&vha->work_lock, flags);
+ 			goto done_free_sp;
+ 		}
+ 		sp->u.iocb_cmd.u.ctarg.rsp_size = rspsz;
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "%s scan list size %d\n", __func__, vha->scan.size);
+ 
+ 		memset(vha->scan.l, 0, vha->scan.size);
+ 	} else if (!sp) {
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "NVME scan did not provide SP\n");
+ 		return rval;
+ 	}
+ 
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gpnft";
+ 	sp->gen1 = vha->hw->base_qpair->chip_reset;
+ 	sp->gen2 = fc4_type;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	rspsz = sizeof(struct ct_sns_gpnft_rsp) +
+ 		((vha->hw->max_fibre_devices - 1) *
+ 		    sizeof(struct ct_sns_gpn_ft_data));
+ 
+ 	ct_sns = (struct ct_sns_pkt *)sp->u.iocb_cmd.u.ctarg.req;
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(ct_sns, GPN_FT_CMD, rspsz);
+ 
+ 	/* GPN_FT req */
+ 	ct_req->req.gpn_ft.port_type = fc4_type;
+ 
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_gpnft_gnnft_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS) {
+ 		spin_lock_irqsave(&vha->work_lock, flags);
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 		goto done_free_sp;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async-%s hdl=%x FC4Type %x.\n", sp->name,
+ 	    sp->handle, ct_req->req.gpn_ft.port_type);
+ 	return rval;
+ 
+ done_free_sp:
+ 	if (sp->u.iocb_cmd.u.ctarg.req) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 		    sizeof(struct ct_sns_pkt),
+ 		    sp->u.iocb_cmd.u.ctarg.req,
+ 		    sp->u.iocb_cmd.u.ctarg.req_dma);
+ 		sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 	}
+ 	if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 		    sizeof(struct ct_sns_pkt),
+ 		    sp->u.iocb_cmd.u.ctarg.rsp,
+ 		    sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 		sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 	}
+ 
+ 	sp->free(sp);
+ 
+ 	return rval;
+ }
+ 
+ void qla_scan_work_fn(struct work_struct *work)
+ {
+ 	struct fab_scan *s = container_of(to_delayed_work(work),
+ 	    struct fab_scan, scan_work);
+ 	struct scsi_qla_host *vha = container_of(s, struct scsi_qla_host,
+ 	    scan);
+ 	unsigned long flags;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s: schedule loop resync\n", __func__);
+ 	set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 	set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 	qla2xxx_wake_dpc(vha);
+ 	spin_lock_irqsave(&vha->work_lock, flags);
+ 	vha->scan.scan_flags &= ~SF_QUEUED;
+ 	spin_unlock_irqrestore(&vha->work_lock, flags);
+ }
+ 
+ /* GNN_ID */
+ void qla24xx_handle_gnnid_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	qla24xx_post_gnl_work(vha, ea->fcport);
+ }
+ 
+ static void qla2x00_async_gnnid_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	fc_port_t *fcport = sp->fcport;
+ 	u8 *node_name = fcport->ct_desc.ct_sns->p.rsp.rsp.gnn_id.node_name;
+ 	struct event_arg ea;
+ 	u64 wwnn;
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	wwnn = wwn_to_u64(node_name);
+ 	if (wwnn)
+ 		memcpy(fcport->node_name, node_name, WWN_SIZE);
+ 
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.fcport = fcport;
+ 	ea.sp = sp;
+ 	ea.rc = res;
+ 	ea.event = FCME_GNNID_DONE;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x204f,
+ 	    "Async done-%s res %x, WWPN %8phC %8phC\n",
+ 	    sp->name, res, fcport->port_name, fcport->node_name);
+ 
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_gnnid(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online || (fcport->flags & FCF_ASYNC_SENT))
+ 		return rval;
+ 
+ 	fcport->disc_state = DSC_GNN_ID;
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_ATOMIC);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gnnid";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(fcport->ct_desc.ct_sns, GNN_ID_CMD,
+ 	    GNN_ID_RSP_SIZE);
+ 
+ 	/* GNN_ID req */
+ 	ct_req->req.port_id.port_id[0] = fcport->d_id.b.domain;
+ 	ct_req->req.port_id.port_id[1] = fcport->d_id.b.area;
+ 	ct_req->req.port_id.port_id[2] = fcport->d_id.b.al_pa;
+ 
+ 
+ 	/* req & rsp use the same buffer */
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GNN_ID_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GNN_ID_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_gnnid_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async-%s - %8phC hdl=%x loopid=%x portid %06x.\n",
+ 	    sp->name, fcport->port_name,
+ 	    sp->handle, fcport->loop_id, fcport->d_id.b24);
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ done:
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gnnid_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 	int ls;
+ 
+ 	ls = atomic_read(&vha->loop_state);
+ 	if (((ls != LOOP_READY) && (ls != LOOP_UP)) ||
+ 		test_bit(UNLOADING, &vha->dpc_flags))
+ 		return 0;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GNNID);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ /* GPFN_ID */
+ void qla24xx_handle_gfpnid_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	fc_port_t *fcport = ea->fcport;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s %8phC DS %d LS %d rc %d login %d|%d rscn %d|%d fcpcnt %d\n",
+ 	    __func__, fcport->port_name, fcport->disc_state,
+ 	    fcport->fw_login_state, ea->rc, fcport->login_gen, ea->sp->gen2,
+ 	    fcport->rscn_gen, ea->sp->gen1, vha->fcport_count);
+ 
+ 	if (fcport->disc_state == DSC_DELETE_PEND)
+ 		return;
+ 
+ 	if (ea->sp->gen2 != fcport->login_gen) {
+ 		/* target side must have changed it. */
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d3,
+ 		    "%s %8phC generation changed\n",
+ 		    __func__, fcport->port_name);
+ 		return;
+ 	} else if (ea->sp->gen1 != fcport->rscn_gen) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d4, "%s %d %8phC post gidpn\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 		qla24xx_post_gidpn_work(vha, fcport);
+ 		return;
+ 	}
+ 
+ 	qla24xx_post_gpsc_work(vha, fcport);
+ }
+ 
+ static void qla2x00_async_gfpnid_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	fc_port_t *fcport = sp->fcport;
+ 	u8 *fpn = fcport->ct_desc.ct_sns->p.rsp.rsp.gfpn_id.port_name;
+ 	struct event_arg ea;
+ 	u64 wwn;
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	wwn = wwn_to_u64(fpn);
+ 	if (wwn)
+ 		memcpy(fcport->fabric_port_name, fpn, WWN_SIZE);
+ 
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.fcport = fcport;
+ 	ea.sp = sp;
+ 	ea.rc = res;
+ 	ea.event = FCME_GFPNID_DONE;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x204f,
+ 	    "Async done-%s res %x, WWPN %8phC %8phC\n",
+ 	    sp->name, res, fcport->port_name, fcport->fabric_port_name);
+ 
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_gfpnid(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online || (fcport->flags & FCF_ASYNC_SENT))
+ 		return rval;
+ 
+ 	fcport->disc_state = DSC_GFPN_ID;
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_ATOMIC);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gfpnid";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(fcport->ct_desc.ct_sns, GFPN_ID_CMD,
+ 	    GFPN_ID_RSP_SIZE);
+ 
+ 	/* GFPN_ID req */
+ 	ct_req->req.port_id.port_id[0] = fcport->d_id.b.domain;
+ 	ct_req->req.port_id.port_id[1] = fcport->d_id.b.area;
+ 	ct_req->req.port_id.port_id[2] = fcport->d_id.b.al_pa;
+ 
+ 
+ 	/* req & rsp use the same buffer */
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GFPN_ID_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GFPN_ID_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_gfpnid_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async-%s - %8phC hdl=%x loopid=%x portid %06x.\n",
+ 	    sp->name, fcport->port_name,
+ 	    sp->handle, fcport->loop_id, fcport->d_id.b24);
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ done:
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gfpnid_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 	int ls;
+ 
+ 	ls = atomic_read(&vha->loop_state);
+ 	if (((ls != LOOP_READY) && (ls != LOOP_UP)) ||
+ 		test_bit(UNLOADING, &vha->dpc_flags))
+ 		return 0;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GFPNID);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	return qla2x00_post_work(vha, e);
+ }
++>>>>>>> 33b28357dd00 (scsi: qla2xxx: Fix Async GPN_FT for FCP and FC-NVMe scan)
diff --cc drivers/scsi/qla2xxx/qla_init.c
index f74932ce86ba,77c9177d0c25..000000000000
--- a/drivers/scsi/qla2xxx/qla_init.c
+++ b/drivers/scsi/qla2xxx/qla_init.c
@@@ -4709,7 -5263,17 +4709,21 @@@ qla2x00_configure_fabric(scsi_qla_host_
  		 * will be newer than discovery_gen. */
  		qlt_do_generation_tick(vha, &discovery_gen);
  
++<<<<<<< HEAD
 +		rval = qla2x00_find_all_fabric_devs(vha);
++=======
+ 		if (USE_ASYNC_SCAN(ha)) {
+ 			rval = qla24xx_async_gpnft(vha, FC4_TYPE_FCP_SCSI,
+ 			    NULL);
+ 			if (rval)
+ 				set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 		} else  {
+ 			list_for_each_entry(fcport, &vha->vp_fcports, list)
+ 				fcport->scan_state = QLA_FCPORT_SCAN;
+ 
+ 			rval = qla2x00_find_all_fabric_devs(vha);
+ 		}
++>>>>>>> 33b28357dd00 (scsi: qla2xxx: Fix Async GPN_FT for FCP and FC-NVMe scan)
  		if (rval != QLA_SUCCESS)
  			break;
  	} while (0);
diff --cc drivers/scsi/qla2xxx/qla_os.c
index 20a870bdd02c,6fa2467e2a16..000000000000
--- a/drivers/scsi/qla2xxx/qla_os.c
+++ b/drivers/scsi/qla2xxx/qla_os.c
@@@ -4765,9 -4801,15 +4765,19 @@@ void qla24xx_create_new_sess(struct scs
  		fcport = qla2x00_alloc_fcport(vha, GFP_KERNEL);
  		if (fcport) {
  			fcport->d_id = e->u.new_sess.id;
 +			fcport->scan_state = QLA_FCPORT_FOUND;
  			fcport->flags |= FCF_FABRIC_DEVICE;
  			fcport->fw_login_state = DSC_LS_PLOGI_PEND;
++<<<<<<< HEAD
++=======
+ 			if (e->u.new_sess.fc4_type & FS_FC4TYPE_FCP)
+ 				fcport->fc4_type = FC4_TYPE_FCP_SCSI;
++>>>>>>> 33b28357dd00 (scsi: qla2xxx: Fix Async GPN_FT for FCP and FC-NVMe scan)
+ 
+ 			if (e->u.new_sess.fc4_type & FS_FC4TYPE_NVME) {
+ 				fcport->fc4_type = FC4_TYPE_OTHER;
+ 				fcport->fc4f_nvme = FC4_TYPE_NVME;
+ 			}
  
  			memcpy(fcport->port_name, e->u.new_sess.port_name,
  			    WWN_SIZE);
@@@ -4894,6 -5018,31 +4904,34 @@@ qla2x00_do_work(struct scsi_qla_host *v
  		case QLA_EVT_NACK:
  			qla24xx_do_nack_work(vha, e);
  			break;
++<<<<<<< HEAD
++=======
+ 		case QLA_EVT_ASYNC_PRLO:
+ 			qla2x00_async_prlo(vha, e->u.logio.fcport);
+ 			break;
+ 		case QLA_EVT_ASYNC_PRLO_DONE:
+ 			qla2x00_async_prlo_done(vha, e->u.logio.fcport,
+ 			    e->u.logio.data);
+ 			break;
+ 		case QLA_EVT_GPNFT:
+ 			qla24xx_async_gpnft(vha, e->u.gpnft.fc4_type,
+ 			    e->u.gpnft.sp);
+ 			break;
+ 		case QLA_EVT_GPNFT_DONE:
+ 			qla24xx_async_gpnft_done(vha, e->u.iosb.sp);
+ 			break;
+ 		case QLA_EVT_GNNFT_DONE:
+ 			qla24xx_async_gnnft_done(vha, e->u.iosb.sp);
+ 			break;
+ 		case QLA_EVT_GNNID:
+ 			qla24xx_async_gnnid(vha, e->u.fcport.fcport);
+ 			break;
+ 		case QLA_EVT_GFPNID:
+ 			qla24xx_async_gfpnid(vha, e->u.fcport.fcport);
+ 			break;
+ 		case QLA_EVT_SP_RETRY:
+ 			qla_sp_retry(vha, e);
++>>>>>>> 33b28357dd00 (scsi: qla2xxx: Fix Async GPN_FT for FCP and FC-NVMe scan)
  		}
  		if (e->flags & QLA_EVT_FLAG_FREE)
  			kfree(e);
* Unmerged path drivers/scsi/qla2xxx/qla_def.h
* Unmerged path drivers/scsi/qla2xxx/qla_gbl.h
* Unmerged path drivers/scsi/qla2xxx/qla_gs.c
* Unmerged path drivers/scsi/qla2xxx/qla_init.c
* Unmerged path drivers/scsi/qla2xxx/qla_os.c
