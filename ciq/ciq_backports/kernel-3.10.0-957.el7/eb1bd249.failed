nvme-rdma: fix memory leak during queue allocation

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Max Gurtovoy <maxg@mellanox.com>
commit eb1bd249ba016284ed762d87c1989dd822500773
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/eb1bd249.failed

In case nvme_rdma_wait_for_cm timeout expires before we get
an established or rejected event (rdma_connect succeeded) from
rdma_cm, we end up with leaking the ib transport resources for
dedicated queue. This scenario can easily reproduced using traffic
test during port toggling.
Also, in order to protect from parallel ib queue destruction, that
may be invoked from different context's, introduce new flag that
stands for transport readiness. While we're here, protect also against
a situation that we can receive rdma_cm events during ib queue destruction.

	Signed-off-by: Max Gurtovoy <maxg@mellanox.com>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
(cherry picked from commit eb1bd249ba016284ed762d87c1989dd822500773)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/rdma.c
diff --cc drivers/nvme/host/rdma.c
index 2e9ce2cbb1eb,37af56596be6..000000000000
--- a/drivers/nvme/host/rdma.c
+++ b/drivers/nvme/host/rdma.c
@@@ -84,8 -75,9 +84,14 @@@ struct nvme_rdma_request 
  };
  
  enum nvme_rdma_queue_flags {
++<<<<<<< HEAD
 +	NVME_RDMA_Q_LIVE		= 0,
 +	NVME_RDMA_Q_DELETING		= 1,
++=======
+ 	NVME_RDMA_Q_ALLOCATED		= 0,
+ 	NVME_RDMA_Q_LIVE		= 1,
+ 	NVME_RDMA_Q_TR_READY		= 2,
++>>>>>>> eb1bd249ba01 (nvme-rdma: fix memory leak during queue allocation)
  };
  
  struct nvme_rdma_queue {
@@@ -463,10 -391,23 +469,27 @@@ out_err
  
  static void nvme_rdma_destroy_queue_ib(struct nvme_rdma_queue *queue)
  {
- 	struct nvme_rdma_device *dev = queue->device;
- 	struct ib_device *ibdev = dev->dev;
+ 	struct nvme_rdma_device *dev;
+ 	struct ib_device *ibdev;
  
+ 	if (!test_and_clear_bit(NVME_RDMA_Q_TR_READY, &queue->flags))
+ 		return;
+ 
+ 	dev = queue->device;
+ 	ibdev = dev->dev;
+ 
++<<<<<<< HEAD
 +	rdma_destroy_qp(queue->cm_id);
++=======
+ 	ib_mr_pool_destroy(queue->qp, &queue->qp->rdma_mrs);
+ 
+ 	/*
+ 	 * The cm_id object might have been destroyed during RDMA connection
+ 	 * establishment error flow to avoid getting other cma events, thus
+ 	 * the destruction of the QP shouldn't use rdma_cm API.
+ 	 */
+ 	ib_destroy_qp(queue->qp);
++>>>>>>> eb1bd249ba01 (nvme-rdma: fix memory leak during queue allocation)
  	ib_free_cq(queue->ib_cq);
  
  	nvme_rdma_free_ring(ibdev, queue->rsp_ring, queue->queue_size,
@@@ -521,8 -464,24 +544,24 @@@ static int nvme_rdma_create_queue_ib(st
  		goto out_destroy_qp;
  	}
  
++<<<<<<< HEAD
++=======
+ 	ret = ib_mr_pool_init(queue->qp, &queue->qp->rdma_mrs,
+ 			      queue->queue_size,
+ 			      IB_MR_TYPE_MEM_REG,
+ 			      nvme_rdma_get_max_fr_pages(ibdev));
+ 	if (ret) {
+ 		dev_err(queue->ctrl->ctrl.device,
+ 			"failed to initialize MR pool sized %d for QID %d\n",
+ 			queue->queue_size, idx);
+ 		goto out_destroy_ring;
+ 	}
+ 
+ 	set_bit(NVME_RDMA_Q_TR_READY, &queue->flags);
+ 
++>>>>>>> eb1bd249ba01 (nvme-rdma: fix memory leak during queue allocation)
  	return 0;
  
 -out_destroy_ring:
 -	nvme_rdma_free_ring(ibdev, queue->rsp_ring, queue->queue_size,
 -			    sizeof(struct nvme_completion), DMA_FROM_DEVICE);
  out_destroy_qp:
  	rdma_destroy_qp(queue->cm_id);
  out_destroy_ib_cq:
* Unmerged path drivers/nvme/host/rdma.c
