nfp: hand over to BPF offload app at coarser granularity

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Jakub Kicinski <jakub.kicinski@netronome.com>
commit af93d15ac6c40d097b08c18a65a0414f94110401
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/af93d15a.failed

Instead of having an app callback per message type hand off
all offload-related handling to apps with one "rest of ndo_bpf"
callback.

	Signed-off-by: Jakub Kicinski <jakub.kicinski@netronome.com>
	Reviewed-by: Quentin Monnet <quentin.monnet@netronome.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
(cherry picked from commit af93d15ac6c40d097b08c18a65a0414f94110401)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/netronome/nfp/bpf/main.h
#	drivers/net/ethernet/netronome/nfp/bpf/offload.c
diff --cc drivers/net/ethernet/netronome/nfp/bpf/main.h
index 5212b54abaf7,66381afee2a9..000000000000
--- a/drivers/net/ethernet/netronome/nfp/bpf/main.h
+++ b/drivers/net/ethernet/netronome/nfp/bpf/main.h
@@@ -183,37 -235,35 +183,48 @@@ struct nfp_prog 
  	struct list_head insns;
  };
  
 -/**
 - * struct nfp_bpf_vnic - per-vNIC BPF priv structure
 - * @tc_prog:	currently loaded cls_bpf program
 - * @start_off:	address of the first instruction in the memory
 - * @tgt_done:	jump target to get the next packet
 - */
 -struct nfp_bpf_vnic {
 -	struct bpf_prog *tc_prog;
 -	unsigned int start_off;
 -	unsigned int tgt_done;
 +struct nfp_bpf_result {
 +	unsigned int n_instr;
 +	bool dense_mode;
  };
  
 -void nfp_bpf_jit_prepare(struct nfp_prog *nfp_prog, unsigned int cnt);
 -int nfp_bpf_jit(struct nfp_prog *prog);
 +int
 +nfp_bpf_jit(struct bpf_prog *filter, void *prog, enum nfp_bpf_action_type act,
 +	    unsigned int prog_start, unsigned int prog_done,
 +	    unsigned int prog_sz, struct nfp_bpf_result *res);
  
 -extern const struct bpf_prog_offload_ops nfp_bpf_analyzer_ops;
 +int nfp_prog_verify(struct nfp_prog *nfp_prog, struct bpf_prog *prog);
  
 -struct netdev_bpf;
 -struct nfp_app;
  struct nfp_net;
 +struct tc_cls_bpf_offload;
 +
++<<<<<<< HEAD
 +/**
 + * struct nfp_net_bpf_priv - per-vNIC BPF private data
 + * @rx_filter:		Filter offload statistics - dropped packets/bytes
 + * @rx_filter_prev:	Filter offload statistics - values from previous update
 + * @rx_filter_change:	Jiffies when statistics last changed
 + * @rx_filter_stats_timer:  Timer for polling filter offload statistics
 + * @rx_filter_lock:	Lock protecting timer state changes (teardown)
 + */
 +struct nfp_net_bpf_priv {
 +	struct nfp_stat_pair rx_filter, rx_filter_prev;
 +	unsigned long rx_filter_change;
 +	struct timer_list rx_filter_stats_timer;
 +	spinlock_t rx_filter_lock;
 +};
  
 +int nfp_net_bpf_offload(struct nfp_net *nn, struct tc_cls_bpf_offload *cls_bpf);
 +void nfp_net_filter_stats_timer(unsigned long data);
++=======
+ int nfp_ndo_bpf(struct nfp_app *app, struct nfp_net *nn,
+ 		struct netdev_bpf *bpf);
+ int nfp_net_bpf_offload(struct nfp_net *nn, struct bpf_prog *prog,
+ 			bool old_prog);
+ 
+ struct nfp_insn_meta *
+ nfp_bpf_goto_meta(struct nfp_prog *nfp_prog, struct nfp_insn_meta *meta,
+ 		  unsigned int insn_idx, unsigned int n_insns);
++>>>>>>> af93d15ac6c4 (nfp: hand over to BPF offload app at coarser granularity)
  
 -void *nfp_bpf_relo_for_vnic(struct nfp_prog *nfp_prog, struct nfp_bpf_vnic *bv);
  #endif
diff --cc drivers/net/ethernet/netronome/nfp/bpf/offload.c
index de79faf0874b,320b2250d29a..000000000000
--- a/drivers/net/ethernet/netronome/nfp/bpf/offload.c
+++ b/drivers/net/ethernet/netronome/nfp/bpf/offload.c
@@@ -112,57 -76,104 +112,132 @@@ nfp_net_bpf_stats_update(struct nfp_ne
  	return 0;
  }
  
 -static void nfp_prog_free(struct nfp_prog *nfp_prog)
 +static int
 +nfp_net_bpf_get_act(struct nfp_net *nn, struct tc_cls_bpf_offload *cls_bpf)
  {
 -	struct nfp_insn_meta *meta, *tmp;
 +	const struct tc_action *a;
 +	LIST_HEAD(actions);
  
 -	list_for_each_entry_safe(meta, tmp, &nfp_prog->insns, l) {
 -		list_del(&meta->l);
 -		kfree(meta);
 -	}
 -	kfree(nfp_prog);
 -}
 +	if (!cls_bpf->exts)
 +		return NN_ACT_XDP;
  
++<<<<<<< HEAD
 +	/* TC direct action */
 +	if (cls_bpf->exts_integrated) {
 +		if (tc_no_actions(cls_bpf->exts))
 +			return NN_ACT_DIRECT;
 +
++=======
+ static int
+ nfp_bpf_verifier_prep(struct nfp_app *app, struct nfp_net *nn,
+ 		      struct netdev_bpf *bpf)
+ {
+ 	struct bpf_prog *prog = bpf->verifier.prog;
+ 	struct nfp_prog *nfp_prog;
+ 	int ret;
+ 
+ 	nfp_prog = kzalloc(sizeof(*nfp_prog), GFP_KERNEL);
+ 	if (!nfp_prog)
+ 		return -ENOMEM;
+ 	prog->aux->offload->dev_priv = nfp_prog;
+ 
+ 	INIT_LIST_HEAD(&nfp_prog->insns);
+ 	nfp_prog->type = prog->type;
+ 	nfp_prog->bpf = app->priv;
+ 
+ 	ret = nfp_prog_prepare(nfp_prog, prog->insnsi, prog->len);
+ 	if (ret)
+ 		goto err_free;
+ 
+ 	nfp_prog->verifier_meta = nfp_prog_first_meta(nfp_prog);
+ 	bpf->verifier.ops = &nfp_bpf_analyzer_ops;
+ 
+ 	return 0;
+ 
+ err_free:
+ 	nfp_prog_free(nfp_prog);
+ 
+ 	return ret;
+ }
+ 
+ static int nfp_bpf_translate(struct nfp_net *nn, struct bpf_prog *prog)
+ {
+ 	struct nfp_prog *nfp_prog = prog->aux->offload->dev_priv;
+ 	unsigned int stack_size;
+ 	unsigned int max_instr;
+ 
+ 	stack_size = nn_readb(nn, NFP_NET_CFG_BPF_STACK_SZ) * 64;
+ 	if (prog->aux->stack_depth > stack_size) {
+ 		nn_info(nn, "stack too large: program %dB > FW stack %dB\n",
+ 			prog->aux->stack_depth, stack_size);
++>>>>>>> af93d15ac6c4 (nfp: hand over to BPF offload app at coarser granularity)
  		return -EOPNOTSUPP;
  	}
 -	nfp_prog->stack_depth = round_up(prog->aux->stack_depth, 4);
  
 -	max_instr = nn_readw(nn, NFP_NET_CFG_BPF_MAX_LEN);
 -	nfp_prog->__prog_alloc_len = max_instr * sizeof(u64);
 +	/* TC legacy mode */
 +	if (!tc_single_action(cls_bpf->exts))
 +		return -EOPNOTSUPP;
  
 -	nfp_prog->prog = kvmalloc(nfp_prog->__prog_alloc_len, GFP_KERNEL);
 -	if (!nfp_prog->prog)
 -		return -ENOMEM;
 +	tcf_exts_to_list(cls_bpf->exts, &actions);
 +	list_for_each_entry(a, &actions, list) {
 +		if (is_tcf_gact_shot(a))
 +			return NN_ACT_TC_DROP;
  
 -	return nfp_bpf_jit(nfp_prog);
 +		if (is_tcf_mirred_egress_redirect(a) &&
 +		    tcf_mirred_ifindex(a) == nn->dp.netdev->ifindex)
 +			return NN_ACT_TC_REDIR;
 +	}
 +
 +	return -EOPNOTSUPP;
  }
  
++<<<<<<< HEAD
 +static int
 +nfp_net_bpf_offload_prepare(struct nfp_net *nn,
 +			    struct tc_cls_bpf_offload *cls_bpf,
 +			    struct nfp_bpf_result *res,
 +			    void **code, dma_addr_t *dma_addr, u16 max_instr)
 +{
 +	unsigned int code_sz = max_instr * sizeof(u64);
 +	enum nfp_bpf_action_type act;
 +	unsigned int stack_size;
 +	u16 start_off, done_off;
++=======
+ static int nfp_bpf_destroy(struct nfp_net *nn, struct bpf_prog *prog)
+ {
+ 	struct nfp_prog *nfp_prog = prog->aux->offload->dev_priv;
+ 
+ 	kvfree(nfp_prog->prog);
+ 	nfp_prog_free(nfp_prog);
+ 
+ 	return 0;
+ }
+ 
+ int nfp_ndo_bpf(struct nfp_app *app, struct nfp_net *nn, struct netdev_bpf *bpf)
+ {
+ 	switch (bpf->command) {
+ 	case BPF_OFFLOAD_VERIFIER_PREP:
+ 		return nfp_bpf_verifier_prep(app, nn, bpf);
+ 	case BPF_OFFLOAD_TRANSLATE:
+ 		return nfp_bpf_translate(nn, bpf->offload.prog);
+ 	case BPF_OFFLOAD_DESTROY:
+ 		return nfp_bpf_destroy(nn, bpf->offload.prog);
+ 	default:
+ 		return -EINVAL;
+ 	}
+ }
+ 
+ static int nfp_net_bpf_load(struct nfp_net *nn, struct bpf_prog *prog)
+ {
+ 	struct nfp_prog *nfp_prog = prog->aux->offload->dev_priv;
++>>>>>>> af93d15ac6c4 (nfp: hand over to BPF offload app at coarser granularity)
  	unsigned int max_mtu;
 -	dma_addr_t dma_addr;
 -	void *img;
 -	int err;
 +	int ret;
 +
 +	ret = nfp_net_bpf_get_act(nn, cls_bpf);
 +	if (ret < 0)
 +		return ret;
 +	act = ret;
  
  	max_mtu = nn_readb(nn, NFP_NET_CFG_BPF_INL_MTU) * 64 - 32;
  	if (max_mtu < nn->dp.netdev->mtu) {
diff --git a/drivers/net/ethernet/netronome/nfp/bpf/main.c b/drivers/net/ethernet/netronome/nfp/bpf/main.c
index 60a7af297852..d633759217ee 100644
--- a/drivers/net/ethernet/netronome/nfp/bpf/main.c
+++ b/drivers/net/ethernet/netronome/nfp/bpf/main.c
@@ -154,5 +154,6 @@ const struct nfp_app_type app_bpf = {
 
 	.setup_tc	= nfp_bpf_setup_tc,
 	.tc_busy	= nfp_bpf_tc_busy,
+	.bpf		= nfp_ndo_bpf,
 	.xdp_offload	= nfp_bpf_xdp_offload,
 };
* Unmerged path drivers/net/ethernet/netronome/nfp/bpf/main.h
* Unmerged path drivers/net/ethernet/netronome/nfp/bpf/offload.c
diff --git a/drivers/net/ethernet/netronome/nfp/nfp_app.h b/drivers/net/ethernet/netronome/nfp/nfp_app.h
index b6035aad75b0..5938ca5589f7 100644
--- a/drivers/net/ethernet/netronome/nfp/nfp_app.h
+++ b/drivers/net/ethernet/netronome/nfp/nfp_app.h
@@ -83,6 +83,7 @@ extern const struct nfp_app_type app_flower;
  * @ctrl_msg_rx:    control message handler
  * @setup_tc:	setup TC ndo
  * @tc_busy:	TC HW offload busy (rules loaded)
+ * @bpf:	BPF ndo offload-related calls
  * @xdp_offload:    offload an XDP program
  * @eswitch_mode_get:    get SR-IOV eswitch mode
  * @sriov_enable: app-specific sriov initialisation
@@ -117,6 +118,8 @@ struct nfp_app_type {
 	int (*setup_tc)(struct nfp_app *app, struct net_device *netdev,
 			enum tc_setup_type type, void *type_data);
 	bool (*tc_busy)(struct nfp_app *app, struct nfp_net *nn);
+	int (*bpf)(struct nfp_app *app, struct nfp_net *nn,
+		   struct netdev_bpf *xdp);
 	int (*xdp_offload)(struct nfp_app *app, struct nfp_net *nn,
 			   struct bpf_prog *prog);
 
@@ -265,6 +268,14 @@ static inline int nfp_app_setup_tc(struct nfp_app *app,
 	return app->type->setup_tc(app, netdev, type, type_data);
 }
 
+static inline int nfp_app_bpf(struct nfp_app *app, struct nfp_net *nn,
+			      struct netdev_bpf *bpf)
+{
+	if (!app || !app->type->bpf)
+		return -EINVAL;
+	return app->type->bpf(app, nn, bpf);
+}
+
 static inline int nfp_app_xdp_offload(struct nfp_app *app, struct nfp_net *nn,
 				      struct bpf_prog *prog)
 {
diff --git a/drivers/net/ethernet/netronome/nfp/nfp_net_common.c b/drivers/net/ethernet/netronome/nfp/nfp_net_common.c
index 51e5c398d8b2..9ef1486515ce 100644
--- a/drivers/net/ethernet/netronome/nfp/nfp_net_common.c
+++ b/drivers/net/ethernet/netronome/nfp/nfp_net_common.c
@@ -3424,7 +3424,7 @@ static int nfp_net_xdp(struct net_device *netdev, struct netdev_xdp *xdp)
 		xdp->prog_flags = nn->xdp_prog ? nn->xdp_flags : 0;
 		return 0;
 	default:
-		return -EINVAL;
+		return nfp_app_bpf(nn->app, nn, xdp);
 	}
 #else
 	return -EINVAL;
