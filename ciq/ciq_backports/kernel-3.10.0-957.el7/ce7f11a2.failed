libnvdimm, pmem: Unconditionally deep flush on *sync

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Ross Zwisler <ross.zwisler@linux.intel.com>
commit ce7f11a230d5b7165480b96c0cc7a90358b5b5e2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/ce7f11a2.failed

Prior to this commit we would only do a "deep flush" (have nvdimm_flush()
write to each of the flush hints for a region) in response to an
msync/fsync/sync call if the nvdimm_has_cache() returned true at the time
we were setting up the request queue.  This happens due to the write cache
value passed in to blk_queue_write_cache(), which then causes the block
layer to send down BIOs with REQ_FUA and REQ_PREFLUSH set.  We do have a
"write_cache" sysfs entry for namespaces, i.e.:

  /sys/bus/nd/devices/pfn0.1/block/pmem0/dax/write_cache

which can be used to control whether or not the kernel thinks a given
namespace has a write cache, but this didn't modify the deep flush behavior
that we set up when the driver was initialized.  Instead, it only modified
whether or not DAX would flush CPU caches via dax_flush() in response to
*sync calls.

Simplify this by making the *sync deep flush always happen, regardless of
the write cache setting of a namespace.  The DAX CPU cache flushing will
still be controlled the write_cache setting of the namespace.

	Cc: <stable@vger.kernel.org>
Fixes: 5fdf8e5ba566 ("libnvdimm: re-enable deep flush for pmem devices via fsync()")
	Signed-off-by: Ross Zwisler <ross.zwisler@linux.intel.com>
	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
(cherry picked from commit ce7f11a230d5b7165480b96c0cc7a90358b5b5e2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvdimm/pmem.c
diff --cc drivers/nvdimm/pmem.c
index 3cb343008661,97b4c39a9267..000000000000
--- a/drivers/nvdimm/pmem.c
+++ b/drivers/nvdimm/pmem.c
@@@ -261,17 -294,22 +261,21 @@@ static int pmem_attach_disk(struct devi
  {
  	struct nd_namespace_io *nsio = to_nd_namespace_io(&ndns->dev);
  	struct nd_region *nd_region = to_nd_region(dev->parent);
++<<<<<<< HEAD
 +	struct vmem_altmap __altmap, *altmap = NULL;
++=======
+ 	int nid = dev_to_node(dev), fua;
++>>>>>>> ce7f11a230d5 (libnvdimm, pmem: Unconditionally deep flush on *sync)
  	struct resource *res = &nsio->res;
 -	struct resource bb_res;
  	struct nd_pfn *nd_pfn = NULL;
  	struct dax_device *dax_dev;
 +	int nid = dev_to_node(dev);
  	struct nd_pfn_sb *pfn_sb;
  	struct pmem_device *pmem;
 +	struct resource pfn_res;
  	struct request_queue *q;
 -	struct device *gendev;
  	struct gendisk *disk;
  	void *addr;
 -	int rc;
 -
 -	pmem = devm_kzalloc(dev, sizeof(*pmem), GFP_KERNEL);
 -	if (!pmem)
 -		return -ENOMEM;
  
  	/* while nsio_rw_bytes is active, parse a pfn info block if present */
  	if (is_nd_pfn(dev)) {
@@@ -291,9 -325,11 +295,14 @@@
  	dev_set_drvdata(dev, pmem);
  	pmem->phys_addr = res->start;
  	pmem->size = resource_size(res);
 -	fua = nvdimm_has_flush(nd_region);
 -	if (!IS_ENABLED(CONFIG_ARCH_HAS_UACCESS_FLUSHCACHE) || fua < 0) {
 +	if (!IS_ENABLED(CONFIG_ARCH_HAS_UACCESS_FLUSHCACHE)
 +			|| nvdimm_has_flush(nd_region) < 0)
  		dev_warn(dev, "unable to guarantee persistence of writes\n");
++<<<<<<< HEAD
++=======
+ 		fua = 0;
+ 	}
++>>>>>>> ce7f11a230d5 (libnvdimm, pmem: Unconditionally deep flush on *sync)
  
  	if (!devm_request_mem_region(dev, res->start, resource_size(res),
  				dev_name(&ndns->dev))) {
@@@ -334,7 -376,7 +343,11 @@@
  		return PTR_ERR(addr);
  	pmem->virt_addr = addr;
  
++<<<<<<< HEAD
 +	blk_queue_flush(q, REQ_FLUSH|REQ_FUA);
++=======
+ 	blk_queue_write_cache(q, true, fua);
++>>>>>>> ce7f11a230d5 (libnvdimm, pmem: Unconditionally deep flush on *sync)
  	blk_queue_make_request(q, pmem_make_request);
  	blk_queue_physical_block_size(q, PAGE_SIZE);
  	blk_queue_logical_block_size(q, pmem_sector_size(ndns));
@@@ -366,9 -407,13 +379,13 @@@
  		put_disk(disk);
  		return -ENOMEM;
  	}
++<<<<<<< HEAD
++=======
+ 	dax_write_cache(dax_dev, nvdimm_has_cache(nd_region));
++>>>>>>> ce7f11a230d5 (libnvdimm, pmem: Unconditionally deep flush on *sync)
  	pmem->dax_dev = dax_dev;
  
 -	gendev = disk_to_dev(disk);
 -	gendev->groups = pmem_attribute_groups;
 -
 -	device_add_disk(dev, disk);
 +	add_disk(disk);
  	if (devm_add_action_or_reset(dev, pmem_release_disk, pmem))
  		return -ENOMEM;
  
* Unmerged path drivers/nvdimm/pmem.c
