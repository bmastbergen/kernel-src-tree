ipv4: lock mtu in fnhe when received PMTU < net.ipv4.route.min_pmtu

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Sabrina Dubroca <sd@queasysnail.net>
commit d52e5a7e7ca49457dd31fc8b42fb7c0d58a31221
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/d52e5a7e.failed

Prior to the rework of PMTU information storage in commit
2c8cec5c10bc ("ipv4: Cache learned PMTU information in inetpeer."),
when a PMTU event advertising a PMTU smaller than
net.ipv4.route.min_pmtu was received, we would disable setting the DF
flag on packets by locking the MTU metric, and set the PMTU to
net.ipv4.route.min_pmtu.

Since then, we don't disable DF, and set PMTU to
net.ipv4.route.min_pmtu, so the intermediate router that has this link
with a small MTU will have to drop the packets.

This patch reestablishes pre-2.6.39 behavior by splitting
rtable->rt_pmtu into a bitfield with rt_mtu_locked and rt_pmtu.
rt_mtu_locked indicates that we shouldn't set the DF bit on that path,
and is checked in ip_dont_fragment().

One possible workaround is to set net.ipv4.route.min_pmtu to a value low
enough to accommodate the lowest MTU encountered.

Fixes: 2c8cec5c10bc ("ipv4: Cache learned PMTU information in inetpeer.")
	Signed-off-by: Sabrina Dubroca <sd@queasysnail.net>
	Reviewed-by: Stefano Brivio <sbrivio@redhat.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit d52e5a7e7ca49457dd31fc8b42fb7c0d58a31221)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/ip.h
#	net/ipv4/route.c
#	net/ipv4/xfrm4_policy.c
diff --cc include/net/ip.h
index 511918beec0b,f49b3a576bec..000000000000
--- a/include/net/ip.h
+++ b/include/net/ip.h
@@@ -275,12 -328,21 +275,27 @@@ int ip_decrease_ttl(struct iphdr *iph
  	return --iph->ttl;
  }
  
+ static inline int ip_mtu_locked(const struct dst_entry *dst)
+ {
+ 	const struct rtable *rt = (const struct rtable *)dst;
+ 
+ 	return rt->rt_mtu_locked || dst_metric_locked(dst, RTAX_MTU);
+ }
+ 
  static inline
 -int ip_dont_fragment(const struct sock *sk, const struct dst_entry *dst)
 +int ip_dont_fragment(struct sock *sk, struct dst_entry *dst)
  {
++<<<<<<< HEAD
 +	return  inet_sk(sk)->pmtudisc == IP_PMTUDISC_DO ||
 +		(inet_sk(sk)->pmtudisc == IP_PMTUDISC_WANT &&
 +		 !(dst_metric_locked(dst, RTAX_MTU)));
++=======
+ 	u8 pmtudisc = READ_ONCE(inet_sk(sk)->pmtudisc);
+ 
+ 	return  pmtudisc == IP_PMTUDISC_DO ||
+ 		(pmtudisc == IP_PMTUDISC_WANT &&
+ 		 !ip_mtu_locked(dst));
++>>>>>>> d52e5a7e7ca4 (ipv4: lock mtu in fnhe when received PMTU < net.ipv4.route.min_pmtu)
  }
  
  static inline bool ip_sk_accept_pmtu(const struct sock *sk)
@@@ -305,8 -367,8 +320,13 @@@ static inline unsigned int ip_dst_mtu_m
  {
  	struct net *net = dev_net(dst->dev);
  
++<<<<<<< HEAD
 +	if (net->sysctl_ip_fwd_use_pmtu ||
 +	    dst_metric_locked(dst, RTAX_MTU) ||
++=======
+ 	if (net->ipv4.sysctl_ip_fwd_use_pmtu ||
+ 	    ip_mtu_locked(dst) ||
++>>>>>>> d52e5a7e7ca4 (ipv4: lock mtu in fnhe when received PMTU < net.ipv4.route.min_pmtu)
  	    !forwarding)
  		return dst_mtu(dst);
  
diff --cc net/ipv4/route.c
index c617c77403d2,299e247b2032..000000000000
--- a/net/ipv4/route.c
+++ b/net/ipv4/route.c
@@@ -1005,14 -1022,20 +1011,16 @@@ static void __ip_rt_update_pmtu(struct 
  	if (ipv4_mtu(dst) < mtu)
  		return;
  
- 	if (mtu < ip_rt_min_pmtu)
+ 	if (mtu < ip_rt_min_pmtu) {
+ 		lock = true;
  		mtu = ip_rt_min_pmtu;
+ 	}
  
 -	if (rt->rt_pmtu == mtu &&
 -	    time_before(jiffies, dst->expires - ip_rt_mtu_expires / 2))
 -		return;
 -
  	rcu_read_lock();
 -	if (fib_lookup(dev_net(dst->dev), fl4, &res, 0) == 0) {
 +	if (fib_lookup(dev_net(dst->dev), fl4, &res) == 0) {
  		struct fib_nh *nh = &FIB_RES_NH(res);
  
- 		update_or_create_fnhe(nh, fl4->daddr, 0, mtu,
+ 		update_or_create_fnhe(nh, fl4->daddr, 0, mtu, lock,
  				      jiffies + ip_rt_mtu_expires);
  	}
  	rcu_read_unlock();
@@@ -1264,9 -1286,9 +1272,9 @@@ static unsigned int ipv4_mtu(const stru
  	if (mtu)
  		return mtu;
  
 -	mtu = READ_ONCE(dst->dev->mtu);
 +	mtu = dst->dev->mtu;
  
- 	if (unlikely(dst_metric_locked(dst, RTAX_MTU))) {
+ 	if (unlikely(ip_mtu_locked(dst))) {
  		if (rt->rt_uses_gateway && mtu > 576)
  			mtu = 576;
  	}
@@@ -1453,14 -1511,38 +1461,43 @@@ static void rt_set_nexthop(struct rtabl
  #endif
  }
  
 -struct rtable *rt_dst_alloc(struct net_device *dev,
 -			    unsigned int flags, u16 type,
 -			    bool nopolicy, bool noxfrm, bool will_cache)
 +static struct rtable *rt_dst_alloc(struct net_device *dev,
 +				   bool nopolicy, bool noxfrm, bool will_cache)
  {
++<<<<<<< HEAD
 +	return dst_alloc(&ipv4_dst_ops, dev, 1, DST_OBSOLETE_FORCE_CHK,
 +			 (will_cache ? 0 : (DST_HOST | DST_NOCACHE)) |
 +			 (nopolicy ? DST_NOPOLICY : 0) |
 +			 (noxfrm ? DST_NOXFRM : 0));
++=======
+ 	struct rtable *rt;
+ 
+ 	rt = dst_alloc(&ipv4_dst_ops, dev, 1, DST_OBSOLETE_FORCE_CHK,
+ 		       (will_cache ? 0 : DST_HOST) |
+ 		       (nopolicy ? DST_NOPOLICY : 0) |
+ 		       (noxfrm ? DST_NOXFRM : 0));
+ 
+ 	if (rt) {
+ 		rt->rt_genid = rt_genid_ipv4(dev_net(dev));
+ 		rt->rt_flags = flags;
+ 		rt->rt_type = type;
+ 		rt->rt_is_input = 0;
+ 		rt->rt_iif = 0;
+ 		rt->rt_pmtu = 0;
+ 		rt->rt_mtu_locked = 0;
+ 		rt->rt_gateway = 0;
+ 		rt->rt_uses_gateway = 0;
+ 		rt->rt_table_id = 0;
+ 		INIT_LIST_HEAD(&rt->rt_uncached);
+ 
+ 		rt->dst.output = ip_output;
+ 		if (flags & RTCF_LOCAL)
+ 			rt->dst.input = ip_local_deliver;
+ 	}
+ 
+ 	return rt;
++>>>>>>> d52e5a7e7ca4 (ipv4: lock mtu in fnhe when received PMTU < net.ipv4.route.min_pmtu)
  }
 -EXPORT_SYMBOL(rt_dst_alloc);
  
  /* called in rcu_read_lock() section */
  int ip_mc_validate_source(struct sk_buff *skb, __be32 daddr, __be32 saddr,
diff --cc net/ipv4/xfrm4_policy.c
index d956ecd2cff1,fbebda67ac1b..000000000000
--- a/net/ipv4/xfrm4_policy.c
+++ b/net/ipv4/xfrm4_policy.c
@@@ -93,7 -100,10 +93,12 @@@ static int xfrm4_fill_dst(struct xfrm_d
  	xdst->u.rt.rt_gateway = rt->rt_gateway;
  	xdst->u.rt.rt_uses_gateway = rt->rt_uses_gateway;
  	xdst->u.rt.rt_pmtu = rt->rt_pmtu;
++<<<<<<< HEAD
++=======
+ 	xdst->u.rt.rt_mtu_locked = rt->rt_mtu_locked;
+ 	xdst->u.rt.rt_table_id = rt->rt_table_id;
++>>>>>>> d52e5a7e7ca4 (ipv4: lock mtu in fnhe when received PMTU < net.ipv4.route.min_pmtu)
  	INIT_LIST_HEAD(&xdst->u.rt.rt_uncached);
 -	rt_add_uncached_list(&xdst->u.rt);
  
  	return 0;
  }
* Unmerged path include/net/ip.h
diff --git a/include/net/ip_fib.h b/include/net/ip_fib.h
index 81968d1d3054..20926b93f2d2 100644
--- a/include/net/ip_fib.h
+++ b/include/net/ip_fib.h
@@ -58,6 +58,7 @@ struct fib_nh_exception {
 	int				fnhe_genid;
 	__be32				fnhe_daddr;
 	u32				fnhe_pmtu;
+	bool				fnhe_mtu_locked;
 	__be32				fnhe_gw;
 	unsigned long			fnhe_expires;
 	struct rtable __rcu		*fnhe_rth_input;
diff --git a/include/net/route.h b/include/net/route.h
index 79ebe28e40b2..40c472a9099b 100644
--- a/include/net/route.h
+++ b/include/net/route.h
@@ -61,7 +61,8 @@ struct rtable {
 	__be32			rt_gateway;
 
 	/* Miscellaneous cached information */
-	u32			rt_pmtu;
+	u32			rt_mtu_locked:1,
+				rt_pmtu:31;
 
 	struct list_head	rt_uncached;
 };
* Unmerged path net/ipv4/route.c
* Unmerged path net/ipv4/xfrm4_policy.c
