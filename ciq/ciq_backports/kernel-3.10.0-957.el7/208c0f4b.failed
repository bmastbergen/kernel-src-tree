net: sched: use tc_setup_cb_call to call per-block callbacks

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [net] sched: use tc_setup_cb_call to call per-block callbacks (Ivan Vecera) [1572720]
Rebuild_FUZZ: 95.65%
commit-author Jiri Pirko <jiri@mellanox.com>
commit 208c0f4b5237f1d6611b2c679a8022d6901577d6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/208c0f4b.failed

Extend the tc_setup_cb_call entrypoint function originally used only for
action egress devices callbacks to call per-block callbacks as well.

	Signed-off-by: Jiri Pirko <jiri@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 208c0f4b5237f1d6611b2c679a8022d6901577d6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/net/pkt_cls.h
#	net/sched/cls_api.c
#	net/sched/cls_flower.c
diff --cc include/net/pkt_cls.h
index 43b9922037a8,fcca5a9d9880..000000000000
--- a/include/net/pkt_cls.h
+++ b/include/net/pkt_cls.h
@@@ -460,8 -543,21 +460,25 @@@ tcf_match_indev(struct sk_buff *skb, in
  }
  #endif /* CONFIG_NET_CLS_IND */
  
++<<<<<<< HEAD
++=======
+ int tc_setup_cb_call(struct tcf_block *block, struct tcf_exts *exts,
+ 		     enum tc_setup_type type, void *type_data, bool err_stop);
+ 
+ enum tc_block_command {
+ 	TC_BLOCK_BIND,
+ 	TC_BLOCK_UNBIND,
+ };
+ 
+ struct tc_block_offload {
+ 	enum tc_block_command command;
+ 	enum tcf_block_binder_type binder_type;
+ 	struct tcf_block *block;
+ };
+ 
++>>>>>>> 208c0f4b5237 (net: sched: use tc_setup_cb_call to call per-block callbacks)
  struct tc_cls_common_offload {
 +	u32 handle;
  	u32 chain_index;
  	__be16 protocol;
  	u32 prio;
diff --cc net/sched/cls_api.c
index 0e9c21220742,cdfdc24b89cf..000000000000
--- a/net/sched/cls_api.c
+++ b/net/sched/cls_api.c
@@@ -1039,15 -1192,41 +1039,40 @@@ int tcf_exts_get_dev(struct net_device 
  
  	tcf_exts_to_list(exts, &actions);
  	list_for_each_entry(a, &actions, list) {
 -		if (!a->ops->get_dev)
 -			continue;
 -		dev = a->ops->get_dev(a);
 -		if (!dev || !tc_can_offload(dev))
 -			continue;
 -		ret = tc_setup_cb_egdev_call(dev, type, type_data, err_stop);
 -		if (ret < 0)
 -			return ret;
 -		ok_count += ret;
 +		if (a->ops->get_dev)
 +			*hw_dev = a->ops->get_dev(a);
  	}
 +	if (*hw_dev)
 +		return 0;
  #endif
 -	return ok_count;
 +	return -EOPNOTSUPP;
  }
++<<<<<<< HEAD
 +EXPORT_SYMBOL(tcf_exts_get_dev);
++=======
+ 
+ int tc_setup_cb_call(struct tcf_block *block, struct tcf_exts *exts,
+ 		     enum tc_setup_type type, void *type_data, bool err_stop)
+ {
+ 	int ok_count;
+ 	int ret;
+ 
+ 	ret = tcf_block_cb_call(block, type, type_data, err_stop);
+ 	if (ret < 0)
+ 		return ret;
+ 	ok_count = ret;
+ 
+ 	if (!exts)
+ 		return ok_count;
+ 	ret = tc_exts_setup_cb_egdev_call(exts, type, type_data, err_stop);
+ 	if (ret < 0)
+ 		return ret;
+ 	ok_count += ret;
+ 
+ 	return ok_count;
+ }
+ EXPORT_SYMBOL(tc_setup_cb_call);
++>>>>>>> 208c0f4b5237 (net: sched: use tc_setup_cb_call to call per-block callbacks)
  
  static int __init tc_filter_init(void)
  {
diff --cc net/sched/cls_flower.c
index 0f196b560aec,76b4e0a1c92f..000000000000
--- a/net/sched/cls_flower.c
+++ b/net/sched/cls_flower.c
@@@ -245,17 -200,18 +245,30 @@@ static void fl_destroy_filter(struct rc
  static void fl_hw_destroy_filter(struct tcf_proto *tp, struct cls_fl_filter *f)
  {
  	struct tc_cls_flower_offload cls_flower = {};
++<<<<<<< HEAD
 +	struct net_device *dev = f->hw_dev;
 +
 +	if (!tc_can_offload(dev))
 +		return;
++=======
+ 	struct net_device *dev = tp->q->dev_queue->dev;
+ 	struct tcf_block *block = tp->chain->block;
++>>>>>>> 208c0f4b5237 (net: sched: use tc_setup_cb_call to call per-block callbacks)
  
  	tc_cls_common_offload_init(&cls_flower.common, tp);
  	cls_flower.command = TC_CLSFLOWER_DESTROY;
  	cls_flower.cookie = (unsigned long) f;
 +	cls_flower.egress_dev = f->hw_dev != tp->q->dev_queue->dev;
  
++<<<<<<< HEAD
 +	__rh_call_ndo_setup_tc(dev, TC_SETUP_CLSFLOWER, &cls_flower);
++=======
+ 	if (tc_can_offload(dev))
+ 		dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSFLOWER,
+ 					      &cls_flower);
+ 	tc_setup_cb_call(block, &f->exts, TC_SETUP_CLSFLOWER,
+ 			 &cls_flower, false);
++>>>>>>> 208c0f4b5237 (net: sched: use tc_setup_cb_call to call per-block callbacks)
  }
  
  static int fl_hw_replace_filter(struct tcf_proto *tp,
@@@ -265,20 -221,10 +278,25 @@@
  {
  	struct net_device *dev = tp->q->dev_queue->dev;
  	struct tc_cls_flower_offload cls_flower = {};
++<<<<<<< HEAD
++=======
+ 	struct tcf_block *block = tp->chain->block;
+ 	bool skip_sw = tc_skip_sw(f->flags);
++>>>>>>> 208c0f4b5237 (net: sched: use tc_setup_cb_call to call per-block callbacks)
  	int err;
  
 +	if (!tc_can_offload(dev)) {
 +		if (tcf_exts_get_dev(dev, &f->exts, &f->hw_dev) ||
 +		    (f->hw_dev && !tc_can_offload(f->hw_dev))) {
 +			f->hw_dev = dev;
 +			return tc_skip_sw(f->flags) ? -EINVAL : 0;
 +		}
 +		dev = f->hw_dev;
 +		cls_flower.egress_dev = true;
 +	} else {
 +		f->hw_dev = dev;
 +	}
 +
  	tc_cls_common_offload_init(&cls_flower.common, tp);
  	cls_flower.command = TC_CLSFLOWER_REPLACE;
  	cls_flower.cookie = (unsigned long) f;
@@@ -287,30 -233,48 +305,63 @@@
  	cls_flower.key = &f->mkey;
  	cls_flower.exts = &f->exts;
  
++<<<<<<< HEAD
 +	err = __rh_call_ndo_setup_tc(dev, TC_SETUP_CLSFLOWER, &cls_flower);
 +	if (!err)
++=======
+ 	if (tc_can_offload(dev)) {
+ 		err = dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSFLOWER,
+ 						    &cls_flower);
+ 		if (err) {
+ 			if (skip_sw)
+ 				return err;
+ 		} else {
+ 			f->flags |= TCA_CLS_FLAGS_IN_HW;
+ 		}
+ 	}
+ 
+ 	err = tc_setup_cb_call(block, &f->exts, TC_SETUP_CLSFLOWER,
+ 			       &cls_flower, skip_sw);
+ 	if (err < 0) {
+ 		fl_hw_destroy_filter(tp, f);
+ 		return err;
+ 	} else if (err > 0) {
++>>>>>>> 208c0f4b5237 (net: sched: use tc_setup_cb_call to call per-block callbacks)
  		f->flags |= TCA_CLS_FLAGS_IN_HW;
 -	}
 -
 -	if (skip_sw && !(f->flags & TCA_CLS_FLAGS_IN_HW))
 -		return -EINVAL;
  
 +	if (tc_skip_sw(f->flags))
 +		return err;
  	return 0;
  }
  
  static void fl_hw_update_stats(struct tcf_proto *tp, struct cls_fl_filter *f)
  {
  	struct tc_cls_flower_offload cls_flower = {};
++<<<<<<< HEAD
 +	struct net_device *dev = f->hw_dev;
 +
 +	if (!tc_can_offload(dev))
 +		return;
++=======
+ 	struct net_device *dev = tp->q->dev_queue->dev;
+ 	struct tcf_block *block = tp->chain->block;
++>>>>>>> 208c0f4b5237 (net: sched: use tc_setup_cb_call to call per-block callbacks)
  
  	tc_cls_common_offload_init(&cls_flower.common, tp);
  	cls_flower.command = TC_CLSFLOWER_STATS;
  	cls_flower.cookie = (unsigned long) f;
  	cls_flower.exts = &f->exts;
 +	cls_flower.egress_dev = f->hw_dev != tp->q->dev_queue->dev;
  
++<<<<<<< HEAD
 +	__rh_call_ndo_setup_tc(dev, TC_SETUP_CLSFLOWER, &cls_flower);
++=======
+ 	if (tc_can_offload(dev))
+ 		dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_CLSFLOWER,
+ 					      &cls_flower);
+ 	tc_setup_cb_call(block, &f->exts, TC_SETUP_CLSFLOWER,
+ 			 &cls_flower, false);
++>>>>>>> 208c0f4b5237 (net: sched: use tc_setup_cb_call to call per-block callbacks)
  }
  
  static void __fl_delete(struct tcf_proto *tp, struct cls_fl_filter *f)
* Unmerged path include/net/pkt_cls.h
* Unmerged path net/sched/cls_api.c
* Unmerged path net/sched/cls_flower.c
