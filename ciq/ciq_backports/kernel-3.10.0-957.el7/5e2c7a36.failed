md/raid1: abort delayed writes when device fails.

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [md] raid1: abort delayed writes when device fails (Nigel Croxon) [1494474]
Rebuild_FUZZ: 95.74%
commit-author NeilBrown <neilb@suse.com>
commit 5e2c7a3611977b69ae0531e8fbdeab5dad17925a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/5e2c7a36.failed

When writing to an array with a bitmap enabled, the writes are grouped
in batches which are preceded by an update to the bitmap.

It is quite likely if that a drive develops a problem which is not
media related, that the bitmap write will be the first to report an
error and cause the device to be marked faulty (as the bitmap write is
at the start of a batch).

In this case, there is point submiting the subsequent writes to the
failed device - that just wastes times.

So re-check the Faulty state of a device before submitting a
delayed write.

This requires that we keep the 'rdev', rather than the 'bdev' in the
bio, then swap in the bdev just before final submission.

	Signed-off-by: NeilBrown <neilb@suse.com>
	Signed-off-by: Shaohua Li <shli@fb.com>
(cherry picked from commit 5e2c7a3611977b69ae0531e8fbdeab5dad17925a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/raid1.c
diff --cc drivers/md/raid1.c
index 5904bace89de,aac2a05cf8d1..000000000000
--- a/drivers/md/raid1.c
+++ b/drivers/md/raid1.c
@@@ -831,11 -742,16 +831,21 @@@ static void flush_pending_writes(struc
  
  		while (bio) { /* submit pending writes */
  			struct bio *next = bio->bi_next;
+ 			struct md_rdev *rdev = (void*)bio->bi_bdev;
  			bio->bi_next = NULL;
++<<<<<<< HEAD
 +			if (unlikely((bio->bi_rw & REQ_DISCARD) &&
 +			    !blk_queue_discard(bdev_get_queue(bio->bi_bdev))))
++=======
+ 			bio->bi_bdev = rdev->bdev;
+ 			if (test_bit(Faulty, &rdev->flags)) {
+ 				bio->bi_error = -EIO;
+ 				bio_endio(bio);
+ 			} else if (unlikely((bio_op(bio) == REQ_OP_DISCARD) &&
+ 					    !blk_queue_discard(bdev_get_queue(bio->bi_bdev))))
++>>>>>>> 5e2c7a361197 (md/raid1: abort delayed writes when device fails.)
  				/* Just ignore it */
 -				bio_endio(bio);
 +				bio_endio(bio, 0);
  			else
  				generic_make_request(bio);
  			bio = next;
@@@ -1150,11 -1021,16 +1160,21 @@@ static void raid1_unplug(struct blk_plu
  
  	while (bio) { /* submit pending writes */
  		struct bio *next = bio->bi_next;
+ 		struct md_rdev *rdev = (void*)bio->bi_bdev;
  		bio->bi_next = NULL;
++<<<<<<< HEAD
 +		if (unlikely((bio->bi_rw & REQ_DISCARD) &&
 +		    !blk_queue_discard(bdev_get_queue(bio->bi_bdev))))
++=======
+ 		bio->bi_bdev = rdev->bdev;
+ 		if (test_bit(Faulty, &rdev->flags)) {
+ 			bio->bi_error = -EIO;
+ 			bio_endio(bio);
+ 		} else if (unlikely((bio_op(bio) == REQ_OP_DISCARD) &&
+ 				    !blk_queue_discard(bdev_get_queue(bio->bi_bdev))))
++>>>>>>> 5e2c7a361197 (md/raid1: abort delayed writes when device fails.)
  			/* Just ignore it */
 -			bio_endio(bio);
 +			bio_endio(bio, 0);
  		else
  			generic_make_request(bio);
  		bio = next;
@@@ -1443,16 -1365,11 +1463,16 @@@ static bool raid1_write_request(struct 
  
  		r1_bio->bios[i] = mbio;
  
 -		mbio->bi_iter.bi_sector	= (r1_bio->sector +
 +		mbio->bi_sector	= (r1_bio->sector +
  				   conf->mirrors[i].rdev->data_offset);
- 		mbio->bi_bdev = conf->mirrors[i].rdev->bdev;
+ 		mbio->bi_bdev = (void*)conf->mirrors[i].rdev;
  		mbio->bi_end_io	= raid1_end_write_request;
 -		bio_set_op_attrs(mbio, op, do_flush_fua | do_sync);
 +		mbio->bi_rw =
 +			WRITE | do_fua | do_sync | do_discard | do_same;
 +		if (test_bit(FailFast, &conf->mirrors[i].rdev->flags) &&
 +		    !test_bit(WriteMostly, &conf->mirrors[i].rdev->flags) &&
 +		    conf->raid_disks - mddev->degraded > 1)
 +			mbio->bi_rw |= MD_FAILFAST;
  		mbio->bi_private = r1_bio;
  
  		atomic_inc(&r1_bio->remaining);
* Unmerged path drivers/md/raid1.c
