bpf: fix implicit declaration of bpf_prog_add

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Brenden Blanco <bblanco@plumgrid.com>
commit cc2e0b3fbcdd9667d7b7ecdf36d7b4d3647681d6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/cc2e0b3f.failed

For the ifndef case of CONFIG_BPF_SYSCALL, an inline version of
bpf_prog_add needs to exist otherwise the build breaks on some configs.

 drivers/net/ethernet/mellanox/mlx4/en_netdev.c:2544:10: error: implicit declaration of function 'bpf_prog_add'
       prog = bpf_prog_add(prog, priv->rx_ring_num - 1);

The function is introduced in
59d3656d5bf50 ("bpf: add bpf_prog_add api for bulk prog refcnt")
and first used in
47f1afdba2b87 ("net/mlx4_en: add support for fast rx drop bpf program").

Fixes: 47f1afdba2b87 ("net/mlx4_en: add support for fast rx drop bpf program")
	Reported-by: kbuild test robot <fengguang.wu@intel.com>
	Reported-by: Tariq Toukan <ttoukan.linux@gmail.com>
	Signed-off-by: Brenden Blanco <bblanco@plumgrid.com>
	Acked-by: Alexei Starovoitov <ast@kernel.org>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit cc2e0b3fbcdd9667d7b7ecdf36d7b4d3647681d6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
diff --cc include/linux/bpf.h
index d4c1f9049ad3,36da0749205a..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -97,20 -163,160 +97,165 @@@ struct bpf_prog_type_list 
  	enum bpf_prog_type type;
  };
  
 +void bpf_register_prog_type(struct bpf_prog_type_list *tl);
 +
 +struct bpf_prog;
 +
  struct bpf_prog_aux {
  	atomic_t refcnt;
 -	u32 used_map_cnt;
 -	u32 max_ctx_offset;
 -	const struct bpf_verifier_ops *ops;
 +	bool is_gpl_compatible;
 +	enum bpf_prog_type prog_type;
 +	struct bpf_verifier_ops *ops;
 +	u32 id;
  	struct bpf_map **used_maps;
 +	u32 used_map_cnt;
  	struct bpf_prog *prog;
 -	struct user_struct *user;
 -	union {
 -		struct work_struct work;
 -		struct rcu_head	rcu;
 -	};
 +	struct work_struct work;
  };
  
++<<<<<<< HEAD
++=======
+ struct bpf_array {
+ 	struct bpf_map map;
+ 	u32 elem_size;
+ 	/* 'ownership' of prog_array is claimed by the first program that
+ 	 * is going to use this map or by the first program which FD is stored
+ 	 * in the map to make sure that all callers and callees have the same
+ 	 * prog_type and JITed flag
+ 	 */
+ 	enum bpf_prog_type owner_prog_type;
+ 	bool owner_jited;
+ 	union {
+ 		char value[0] __aligned(8);
+ 		void *ptrs[0] __aligned(8);
+ 		void __percpu *pptrs[0] __aligned(8);
+ 	};
+ };
+ 
+ #define MAX_TAIL_CALL_CNT 32
+ 
+ struct bpf_event_entry {
+ 	struct perf_event *event;
+ 	struct file *perf_file;
+ 	struct file *map_file;
+ 	struct rcu_head rcu;
+ };
+ 
+ u64 bpf_tail_call(u64 ctx, u64 r2, u64 index, u64 r4, u64 r5);
+ u64 bpf_get_stackid(u64 r1, u64 r2, u64 r3, u64 r4, u64 r5);
+ 
+ bool bpf_prog_array_compatible(struct bpf_array *array, const struct bpf_prog *fp);
+ 
+ const struct bpf_func_proto *bpf_get_trace_printk_proto(void);
+ 
+ typedef unsigned long (*bpf_ctx_copy_t)(void *dst, const void *src,
+ 					unsigned long len);
+ 
+ u64 bpf_event_output(struct bpf_map *map, u64 flags, void *meta, u64 meta_size,
+ 		     void *ctx, u64 ctx_size, bpf_ctx_copy_t ctx_copy);
+ 
+ #ifdef CONFIG_BPF_SYSCALL
+ DECLARE_PER_CPU(int, bpf_prog_active);
+ 
+ void bpf_register_prog_type(struct bpf_prog_type_list *tl);
+ void bpf_register_map_type(struct bpf_map_type_list *tl);
+ 
+ struct bpf_prog *bpf_prog_get(u32 ufd);
+ struct bpf_prog *bpf_prog_get_type(u32 ufd, enum bpf_prog_type type);
+ struct bpf_prog *bpf_prog_add(struct bpf_prog *prog, int i);
+ struct bpf_prog *bpf_prog_inc(struct bpf_prog *prog);
+ void bpf_prog_put(struct bpf_prog *prog);
+ 
+ struct bpf_map *bpf_map_get_with_uref(u32 ufd);
+ struct bpf_map *__bpf_map_get(struct fd f);
+ struct bpf_map *bpf_map_inc(struct bpf_map *map, bool uref);
+ void bpf_map_put_with_uref(struct bpf_map *map);
+ void bpf_map_put(struct bpf_map *map);
+ int bpf_map_precharge_memlock(u32 pages);
+ 
+ extern int sysctl_unprivileged_bpf_disabled;
+ 
+ int bpf_map_new_fd(struct bpf_map *map);
+ int bpf_prog_new_fd(struct bpf_prog *prog);
+ 
+ int bpf_obj_pin_user(u32 ufd, const char __user *pathname);
+ int bpf_obj_get_user(const char __user *pathname);
+ 
+ int bpf_percpu_hash_copy(struct bpf_map *map, void *key, void *value);
+ int bpf_percpu_array_copy(struct bpf_map *map, void *key, void *value);
+ int bpf_percpu_hash_update(struct bpf_map *map, void *key, void *value,
+ 			   u64 flags);
+ int bpf_percpu_array_update(struct bpf_map *map, void *key, void *value,
+ 			    u64 flags);
+ 
+ int bpf_stackmap_copy(struct bpf_map *map, void *key, void *value);
+ 
+ int bpf_fd_array_map_update_elem(struct bpf_map *map, struct file *map_file,
+ 				 void *key, void *value, u64 map_flags);
+ void bpf_fd_array_map_clear(struct bpf_map *map);
+ 
+ /* memcpy that is used with 8-byte aligned pointers, power-of-8 size and
+  * forced to use 'long' read/writes to try to atomically copy long counters.
+  * Best-effort only.  No barriers here, since it _will_ race with concurrent
+  * updates from BPF programs. Called from bpf syscall and mostly used with
+  * size 8 or 16 bytes, so ask compiler to inline it.
+  */
+ static inline void bpf_long_memcpy(void *dst, const void *src, u32 size)
+ {
+ 	const long *lsrc = src;
+ 	long *ldst = dst;
+ 
+ 	size /= sizeof(long);
+ 	while (size--)
+ 		*ldst++ = *lsrc++;
+ }
+ 
+ /* verify correctness of eBPF program */
+ int bpf_check(struct bpf_prog **fp, union bpf_attr *attr);
+ #else
+ static inline void bpf_register_prog_type(struct bpf_prog_type_list *tl)
+ {
+ }
+ 
+ static inline struct bpf_prog *bpf_prog_get(u32 ufd)
+ {
+ 	return ERR_PTR(-EOPNOTSUPP);
+ }
+ 
+ static inline struct bpf_prog *bpf_prog_get_type(u32 ufd,
+ 						 enum bpf_prog_type type)
+ {
+ 	return ERR_PTR(-EOPNOTSUPP);
+ }
+ static inline struct bpf_prog *bpf_prog_add(struct bpf_prog *prog, int i)
+ {
+ 	return ERR_PTR(-EOPNOTSUPP);
+ }
+ 
+ static inline void bpf_prog_put(struct bpf_prog *prog)
+ {
+ }
+ #endif /* CONFIG_BPF_SYSCALL */
+ 
+ /* verifier prototypes for helper functions called from eBPF programs */
+ extern const struct bpf_func_proto bpf_map_lookup_elem_proto;
+ extern const struct bpf_func_proto bpf_map_update_elem_proto;
+ extern const struct bpf_func_proto bpf_map_delete_elem_proto;
+ 
+ extern const struct bpf_func_proto bpf_get_prandom_u32_proto;
+ extern const struct bpf_func_proto bpf_get_smp_processor_id_proto;
+ extern const struct bpf_func_proto bpf_tail_call_proto;
+ extern const struct bpf_func_proto bpf_ktime_get_ns_proto;
+ extern const struct bpf_func_proto bpf_get_current_pid_tgid_proto;
+ extern const struct bpf_func_proto bpf_get_current_uid_gid_proto;
+ extern const struct bpf_func_proto bpf_get_current_comm_proto;
+ extern const struct bpf_func_proto bpf_skb_vlan_push_proto;
+ extern const struct bpf_func_proto bpf_skb_vlan_pop_proto;
+ extern const struct bpf_func_proto bpf_get_stackid_proto;
+ 
+ /* Shared helpers among cBPF and eBPF. */
+ void bpf_user_rnd_init_once(void);
+ u64 bpf_user_rnd_u32(u64 r1, u64 r2, u64 r3, u64 r4, u64 r5);
+ 
++>>>>>>> cc2e0b3fbcdd (bpf: fix implicit declaration of bpf_prog_add)
  #endif /* _LINUX_BPF_H */
* Unmerged path include/linux/bpf.h
