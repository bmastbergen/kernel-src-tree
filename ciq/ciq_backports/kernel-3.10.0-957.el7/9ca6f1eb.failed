drm/nouveau/kms/nv50: modify core allocation so the code can be split

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Ben Skeggs <bskeggs@redhat.com>
commit 9ca6f1ebba10240ad02f7c659481899a28220fbc
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/9ca6f1eb.failed

	Signed-off-by: Ben Skeggs <bskeggs@redhat.com>
(cherry picked from commit 9ca6f1ebba10240ad02f7c659481899a28220fbc)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/nouveau/dispnv50/disp.c
diff --cc drivers/gpu/drm/nouveau/dispnv50/disp.c
index a2ea42f947c7,abdf39ed9d26..000000000000
--- a/drivers/gpu/drm/nouveau/dispnv50/disp.c
+++ b/drivers/gpu/drm/nouveau/dispnv50/disp.c
@@@ -561,41 -426,6 +561,44 @@@ nv50_dmac_create(struct nvif_device *de
  }
  
  /******************************************************************************
++<<<<<<< HEAD
 + * Core
 + *****************************************************************************/
 +
 +struct nv50_mast {
 +	struct nv50_dmac base;
 +};
 +
 +static int
 +nv50_core_create(struct nvif_device *device, struct nvif_object *disp,
 +		 u64 syncbuf, struct nv50_mast *core)
 +{
 +	struct nv50_disp_core_channel_dma_v0 args = {
 +		.pushbuf = 0xb0007d00,
 +	};
 +	static const s32 oclass[] = {
 +		GP102_DISP_CORE_CHANNEL_DMA,
 +		GP100_DISP_CORE_CHANNEL_DMA,
 +		GM200_DISP_CORE_CHANNEL_DMA,
 +		GM107_DISP_CORE_CHANNEL_DMA,
 +		GK110_DISP_CORE_CHANNEL_DMA,
 +		GK104_DISP_CORE_CHANNEL_DMA,
 +		GF110_DISP_CORE_CHANNEL_DMA,
 +		GT214_DISP_CORE_CHANNEL_DMA,
 +		GT206_DISP_CORE_CHANNEL_DMA,
 +		GT200_DISP_CORE_CHANNEL_DMA,
 +		G82_DISP_CORE_CHANNEL_DMA,
 +		NV50_DISP_CORE_CHANNEL_DMA,
 +		0
 +	};
 +
 +	return nv50_dmac_create(device, disp, oclass, 0, &args, sizeof(args),
 +				syncbuf, &core->base);
 +}
 +
 +/******************************************************************************
++=======
++>>>>>>> 9ca6f1ebba10 (drm/nouveau/kms/nv50: modify core allocation so the code can be split)
   * Base
   *****************************************************************************/
  
@@@ -665,14 -444,10 +668,15 @@@ struct nv50_head 
  };
  
  #define nv50_head(c) ((struct nv50_head *)nouveau_crtc(c))
- #define nv50_ovly(c) (&nv50_head(c)->ovly)
- #define nv50_oimm(c) (&nv50_head(c)->oimm)
- #define nv50_chan(c) (&(c)->base.base)
- #define nv50_vers(c) nv50_chan(c)->user.oclass
  
  struct nv50_disp {
++<<<<<<< HEAD
 +	struct nvif_object *disp;
 +	struct nv50_mast mast;
++=======
+ 	struct nvif_disp *disp;
+ 	struct nv50_core *core;
++>>>>>>> 9ca6f1ebba10 (drm/nouveau/kms/nv50: modify core allocation so the code can be split)
  
  	struct nouveau_bo *sync;
  
@@@ -1195,25 -1236,60 +1233,73 @@@ nv50_curs = 
  };
  
  static int
 -curs507a_new_(const struct nv50_wimm_func *func, struct nouveau_drm *drm,
 -	      int head, s32 oclass, struct nv50_wndw **pwndw)
 -{
 +nv50_curs_new(struct nouveau_drm *drm, struct nv50_head *head,
 +	      struct nv50_curs **pcurs)
 +{
++<<<<<<< HEAD
 +	static const struct nvif_mclass curses[] = {
 +		{ GK104_DISP_CURSOR, 0 },
 +		{ GF110_DISP_CURSOR, 0 },
 +		{ GT214_DISP_CURSOR, 0 },
 +		{   G82_DISP_CURSOR, 0 },
 +		{  NV50_DISP_CURSOR, 0 },
++=======
+ 	struct nv50_disp_cursor_v0 args = {
+ 		.head = head,
+ 	};
+ 	struct nv50_disp *disp = nv50_disp(drm->dev);
+ 	struct nv50_wndw *wndw;
+ 	int ret;
+ 
+ 	ret = nv50_wndw_new_(&nv50_curs, drm->dev, DRM_PLANE_TYPE_CURSOR,
+ 			     "curs", head, nv50_curs_format, &wndw);
+ 	if (*pwndw = wndw, ret)
+ 		return ret;
+ 
+ 	ret = nvif_object_init(&disp->disp->object, 0, oclass, &args,
+ 			       sizeof(args), &wndw->wimm.base.user);
+ 	if (ret) {
+ 		NV_ERROR(drm, "curs%04x allocation failed: %d\n", oclass, ret);
+ 		return ret;
+ 	}
+ 
+ 	nvif_object_map(&wndw->wimm.base.user, NULL, 0);
+ 	wndw->immd = func;
+ 	wndw->ctxdma.parent = &disp->core->chan.base.user;
+ 	return 0;
+ }
+ 
+ static int
+ curs507a_new(struct nouveau_drm *drm, int head, s32 oclass,
+ 	     struct nv50_wndw **pwndw)
+ {
+ 	return curs507a_new_(&curs507a, drm, head, oclass, pwndw);
+ }
+ 
+ static int
+ nv50_curs_new(struct nouveau_drm *drm, int head, struct nv50_wndw **pwndw)
+ {
+ 	struct {
+ 		s32 oclass;
+ 		int version;
+ 		int (*new)(struct nouveau_drm *, int, s32, struct nv50_wndw **);
+ 	} curses[] = {
+ 		{ GK104_DISP_CURSOR, 0, curs507a_new },
+ 		{ GF110_DISP_CURSOR, 0, curs507a_new },
+ 		{ GT214_DISP_CURSOR, 0, curs507a_new },
+ 		{   G82_DISP_CURSOR, 0, curs507a_new },
+ 		{  NV50_DISP_CURSOR, 0, curs507a_new },
++>>>>>>> 9ca6f1ebba10 (drm/nouveau/kms/nv50: modify core allocation so the code can be split)
  		{}
  	};
 +	struct nv50_disp_cursor_v0 args = {
 +		.head = head->base.index,
 +	};
  	struct nv50_disp *disp = nv50_disp(drm->dev);
 -	int cid;
 +	struct nv50_curs *curs;
 +	int cid, ret;
  
 -	cid = nvif_mclass(&disp->disp->object, curses);
 +	cid = nvif_mclass(disp->disp, curses);
  	if (cid < 0) {
  		NV_ERROR(drm, "No supported cursor immediate class\n");
  		return cid;
@@@ -2042,6 -2161,37 +2128,40 @@@ nv50_head_atomic_check_view(struct nv50
  }
  
  static void
++<<<<<<< HEAD
++=======
+ nv50_head_atomic_check_lut(struct nv50_head *head,
+ 			   struct nv50_head_atom *armh,
+ 			   struct nv50_head_atom *asyh)
+ {
+ 	struct nv50_disp *disp = nv50_disp(head->base.base.dev);
+ 
+ 	/* An I8 surface without an input LUT makes no sense, and
+ 	 * EVO will throw an error if you try.
+ 	 *
+ 	 * Legacy clients actually cause this due to the order in
+ 	 * which they call ioctls, so we will enable the LUT with
+ 	 * whatever contents the buffer already contains to avoid
+ 	 * triggering the error check.
+ 	 */
+ 	if (!asyh->state.gamma_lut && asyh->base.cpp != 1) {
+ 		asyh->lut.handle = 0;
+ 		asyh->clr.ilut = armh->lut.visible;
+ 		return;
+ 	}
+ 
+ 	if (disp->disp->object.oclass < GF110_DISP) {
+ 		asyh->lut.mode = (asyh->base.cpp == 1) ? 0 : 1;
+ 		asyh->set.ilut = true;
+ 	} else {
+ 		asyh->lut.mode = 7;
+ 		asyh->set.ilut = asyh->state.color_mgmt_changed;
+ 	}
+ 	asyh->lut.handle = disp->core->chan.vram.handle;
+ }
+ 
+ static void
++>>>>>>> 9ca6f1ebba10 (drm/nouveau/kms/nv50: modify core allocation so the code can be split)
  nv50_head_atomic_check_mode(struct nv50_head *head, struct nv50_head_atom *asyh)
  {
  	struct drm_display_mode *mode = &asyh->state.adjusted_mode;
@@@ -4346,12 -4495,12 +4522,13 @@@ nv50_display_fini(struct drm_device *de
  int
  nv50_display_init(struct drm_device *dev)
  {
+ 	struct nv50_dmac *core = &nv50_disp(dev)->core->chan;
  	struct drm_encoder *encoder;
  	struct drm_plane *plane;
 +	struct drm_crtc *crtc;
  	u32 *push;
  
- 	push = evo_wait(nv50_mast(dev), 32);
+ 	push = evo_wait(core, 32);
  	if (!push)
  		return -EBUSY;
  
@@@ -4386,7 -4531,7 +4563,11 @@@ nv50_display_destroy(struct drm_device 
  {
  	struct nv50_disp *disp = nv50_disp(dev);
  
++<<<<<<< HEAD
 +	nv50_dmac_destroy(&disp->mast.base, disp->disp);
++=======
+ 	nv50_core_del(&disp->core);
++>>>>>>> 9ca6f1ebba10 (drm/nouveau/kms/nv50: modify core allocation so the code can be split)
  
  	nouveau_bo_unmap(disp->sync);
  	if (disp->sync)
@@@ -4445,8 -4591,7 +4626,12 @@@ nv50_display_create(struct drm_device *
  		goto out;
  
  	/* allocate master evo channel */
++<<<<<<< HEAD
 +	ret = nv50_core_create(device, disp->disp, disp->sync->bo.offset,
 +			      &disp->mast);
++=======
+ 	ret = nv50_core_new(drm, &disp->core);
++>>>>>>> 9ca6f1ebba10 (drm/nouveau/kms/nv50: modify core allocation so the code can be split)
  	if (ret)
  		goto out;
  
* Unmerged path drivers/gpu/drm/nouveau/dispnv50/disp.c
