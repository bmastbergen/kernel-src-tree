s390/ftrace: use expoline for indirect branches

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [s390] ftrace: use expoline for indirect branches (Hendrik Brueckner) [1583564]
Rebuild_FUZZ: 94.38%
commit-author Martin Schwidefsky <schwidefsky@de.ibm.com>
commit 23a4d7fd34856da8218c4cfc23dba7a6ec0a423a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/23a4d7fd.failed

The return from the ftrace_stub, _mcount, ftrace_caller and
return_to_handler functions is done with "br %r14" and "br %r1".
These are indirect branches as well and need to use execute
trampolines for CONFIG_EXPOLINE=y.

The ftrace_caller function is a special case as it returns to the
start of a function and may only use %r0 and %r1. For a pre z10
machine the standard execute trampoline uses a LARL + EX to do
this, but this requires *two* registers in the range %r1..%r15.
To get around this the 'br %r1' located in the lowcore is used,
then the EX instruction does not need an address register.
But the lowcore trick may only be used for pre z14 machines,
with noexec=on the mapping for the first page may not contain
instructions. The solution for that is an ALTERNATIVE in the
expoline THUNK generated by 'GEN_BR_THUNK %r1' to switch to
EXRL, this relies on the fact that a machine that supports
noexec=on has EXRL as well.

	Cc: stable@vger.kernel.org # 4.16
Fixes: f19fbd5ed6 ("s390: introduce execute-trampolines for branches")
	Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
(cherry picked from commit 23a4d7fd34856da8218c4cfc23dba7a6ec0a423a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/s390/include/asm/nospec-insn.h
#	arch/s390/kernel/asm-offsets.c
#	arch/s390/kernel/mcount.S
diff --cc arch/s390/kernel/asm-offsets.c
index d2bdeb537ffe,11aea745a2a6..000000000000
--- a/arch/s390/kernel/asm-offsets.c
+++ b/arch/s390/kernel/asm-offsets.c
@@@ -71,107 -91,124 +71,205 @@@ int main(void
  	/* constants used by the vdso */
  	DEFINE(__CLOCK_REALTIME, CLOCK_REALTIME);
  	DEFINE(__CLOCK_MONOTONIC, CLOCK_MONOTONIC);
 -	DEFINE(__CLOCK_REALTIME_COARSE, CLOCK_REALTIME_COARSE);
 -	DEFINE(__CLOCK_MONOTONIC_COARSE, CLOCK_MONOTONIC_COARSE);
  	DEFINE(__CLOCK_THREAD_CPUTIME_ID, CLOCK_THREAD_CPUTIME_ID);
  	DEFINE(__CLOCK_REALTIME_RES, MONOTONIC_RES_NSEC);
 -	DEFINE(__CLOCK_COARSE_RES, LOW_RES_NSEC);
  	BLANK();
  	/* idle data offsets */
 -	OFFSET(__CLOCK_IDLE_ENTER, s390_idle_data, clock_idle_enter);
 -	OFFSET(__CLOCK_IDLE_EXIT, s390_idle_data, clock_idle_exit);
 -	OFFSET(__TIMER_IDLE_ENTER, s390_idle_data, timer_idle_enter);
 -	OFFSET(__TIMER_IDLE_EXIT, s390_idle_data, timer_idle_exit);
 +	DEFINE(__CLOCK_IDLE_ENTER, offsetof(struct s390_idle_data, clock_idle_enter));
 +	DEFINE(__CLOCK_IDLE_EXIT, offsetof(struct s390_idle_data, clock_idle_exit));
 +	DEFINE(__TIMER_IDLE_ENTER, offsetof(struct s390_idle_data, timer_idle_enter));
 +	DEFINE(__TIMER_IDLE_EXIT, offsetof(struct s390_idle_data, timer_idle_exit));
 +	/* lowcore offsets */
 +	DEFINE(__LC_MCESAD, offsetof(struct _lowcore, mcesad));
 +	DEFINE(__LC_EXT_PARAMS, offsetof(struct _lowcore, ext_params));
 +	DEFINE(__LC_EXT_CPU_ADDR, offsetof(struct _lowcore, ext_cpu_addr));
 +	DEFINE(__LC_EXT_INT_CODE, offsetof(struct _lowcore, ext_int_code));
 +	DEFINE(__LC_SVC_ILC, offsetof(struct _lowcore, svc_ilc));
 +	DEFINE(__LC_SVC_INT_CODE, offsetof(struct _lowcore, svc_code));
 +	DEFINE(__LC_PGM_ILC, offsetof(struct _lowcore, pgm_ilc));
 +	DEFINE(__LC_PGM_INT_CODE, offsetof(struct _lowcore, pgm_code));
 +	DEFINE(__LC_TRANS_EXC_CODE, offsetof(struct _lowcore, trans_exc_code));
 +	DEFINE(__LC_PER_CAUSE, offsetof(struct _lowcore, per_perc_atmid));
 +	DEFINE(__LC_PER_ADDRESS, offsetof(struct _lowcore, per_address));
 +	DEFINE(__LC_PER_PAID, offsetof(struct _lowcore, per_access_id));
 +	DEFINE(__LC_AR_MODE_ID, offsetof(struct _lowcore, ar_access_id));
 +	DEFINE(__LC_SUBCHANNEL_ID, offsetof(struct _lowcore, subchannel_id));
 +	DEFINE(__LC_SUBCHANNEL_NR, offsetof(struct _lowcore, subchannel_nr));
 +	DEFINE(__LC_IO_INT_PARM, offsetof(struct _lowcore, io_int_parm));
 +	DEFINE(__LC_IO_INT_WORD, offsetof(struct _lowcore, io_int_word));
 +	DEFINE(__LC_STFL_FAC_LIST, offsetof(struct _lowcore, stfl_fac_list));
 +	DEFINE(__LC_MCCK_CODE, offsetof(struct _lowcore, mcck_interruption_code));
 +	DEFINE(__LC_RST_OLD_PSW, offsetof(struct _lowcore, restart_old_psw));
 +	DEFINE(__LC_EXT_OLD_PSW, offsetof(struct _lowcore, external_old_psw));
 +	DEFINE(__LC_SVC_OLD_PSW, offsetof(struct _lowcore, svc_old_psw));
 +	DEFINE(__LC_PGM_OLD_PSW, offsetof(struct _lowcore, program_old_psw));
 +	DEFINE(__LC_MCK_OLD_PSW, offsetof(struct _lowcore, mcck_old_psw));
 +	DEFINE(__LC_IO_OLD_PSW, offsetof(struct _lowcore, io_old_psw));
 +	DEFINE(__LC_RST_NEW_PSW, offsetof(struct _lowcore, restart_psw));
 +	DEFINE(__LC_EXT_NEW_PSW, offsetof(struct _lowcore, external_new_psw));
 +	DEFINE(__LC_SVC_NEW_PSW, offsetof(struct _lowcore, svc_new_psw));
 +	DEFINE(__LC_PGM_NEW_PSW, offsetof(struct _lowcore, program_new_psw));
 +	DEFINE(__LC_MCK_NEW_PSW, offsetof(struct _lowcore, mcck_new_psw));
 +	DEFINE(__LC_IO_NEW_PSW, offsetof(struct _lowcore, io_new_psw));
  	BLANK();
++<<<<<<< HEAD
 +	DEFINE(__LC_SAVE_AREA_SYNC, offsetof(struct _lowcore, save_area_sync));
 +	DEFINE(__LC_SAVE_AREA_ASYNC, offsetof(struct _lowcore, save_area_async));
 +	DEFINE(__LC_SAVE_AREA_RESTART, offsetof(struct _lowcore, save_area_restart));
 +	DEFINE(__LC_RETURN_PSW, offsetof(struct _lowcore, return_psw));
 +	DEFINE(__LC_RETURN_MCCK_PSW, offsetof(struct _lowcore, return_mcck_psw));
 +	DEFINE(__LC_SYNC_ENTER_TIMER, offsetof(struct _lowcore, sync_enter_timer));
 +	DEFINE(__LC_ASYNC_ENTER_TIMER, offsetof(struct _lowcore, async_enter_timer));
 +	DEFINE(__LC_MCCK_ENTER_TIMER, offsetof(struct _lowcore, mcck_enter_timer));
 +	DEFINE(__LC_EXIT_TIMER, offsetof(struct _lowcore, exit_timer));
 +	DEFINE(__LC_USER_TIMER, offsetof(struct _lowcore, user_timer));
 +	DEFINE(__LC_SYSTEM_TIMER, offsetof(struct _lowcore, system_timer));
 +	DEFINE(__LC_STEAL_TIMER, offsetof(struct _lowcore, steal_timer));
 +	DEFINE(__LC_LAST_UPDATE_TIMER, offsetof(struct _lowcore, last_update_timer));
 +	DEFINE(__LC_LAST_UPDATE_CLOCK, offsetof(struct _lowcore, last_update_clock));
 +	DEFINE(__LC_CURRENT, offsetof(struct _lowcore, current_task));
 +#ifdef CONFIG_64BIT
 +	DEFINE(__LC_LPP, offsetof(struct _lowcore, lpp));
 +#endif
 +	DEFINE(__LC_CURRENT_PID, offsetof(struct _lowcore, current_pid));
 +	DEFINE(__LC_THREAD_INFO, offsetof(struct _lowcore, thread_info));
 +	DEFINE(__LC_KERNEL_STACK, offsetof(struct _lowcore, kernel_stack));
 +	DEFINE(__LC_ASYNC_STACK, offsetof(struct _lowcore, async_stack));
 +	DEFINE(__LC_PANIC_STACK, offsetof(struct _lowcore, panic_stack));
 +	DEFINE(__LC_RESTART_STACK, offsetof(struct _lowcore, restart_stack));
 +	DEFINE(__LC_RESTART_FN, offsetof(struct _lowcore, restart_fn));
 +	DEFINE(__LC_RESTART_DATA, offsetof(struct _lowcore, restart_data));
 +	DEFINE(__LC_RESTART_SOURCE, offsetof(struct _lowcore, restart_source));
 +	DEFINE(__LC_KERNEL_ASCE, offsetof(struct _lowcore, kernel_asce));
 +	DEFINE(__LC_USER_ASCE, offsetof(struct _lowcore, user_asce));
 +	DEFINE(__LC_INT_CLOCK, offsetof(struct _lowcore, int_clock));
 +	DEFINE(__LC_MCCK_CLOCK, offsetof(struct _lowcore, mcck_clock));
 +	DEFINE(__LC_MACHINE_FLAGS, offsetof(struct _lowcore, machine_flags));
 +	DEFINE(__LC_FTRACE_FUNC, offsetof(struct _lowcore, ftrace_func));
 +	DEFINE(__LC_IRB, offsetof(struct _lowcore, irb));
 +	DEFINE(__LC_DUMP_REIPL, offsetof(struct _lowcore, ipib));
++=======
+ 	/* hardware defined lowcore locations 0x000 - 0x1ff */
+ 	OFFSET(__LC_EXT_PARAMS, lowcore, ext_params);
+ 	OFFSET(__LC_EXT_CPU_ADDR, lowcore, ext_cpu_addr);
+ 	OFFSET(__LC_EXT_INT_CODE, lowcore, ext_int_code);
+ 	OFFSET(__LC_SVC_ILC, lowcore, svc_ilc);
+ 	OFFSET(__LC_SVC_INT_CODE, lowcore, svc_code);
+ 	OFFSET(__LC_PGM_ILC, lowcore, pgm_ilc);
+ 	OFFSET(__LC_PGM_INT_CODE, lowcore, pgm_code);
+ 	OFFSET(__LC_DATA_EXC_CODE, lowcore, data_exc_code);
+ 	OFFSET(__LC_MON_CLASS_NR, lowcore, mon_class_num);
+ 	OFFSET(__LC_PER_CODE, lowcore, per_code);
+ 	OFFSET(__LC_PER_ATMID, lowcore, per_atmid);
+ 	OFFSET(__LC_PER_ADDRESS, lowcore, per_address);
+ 	OFFSET(__LC_EXC_ACCESS_ID, lowcore, exc_access_id);
+ 	OFFSET(__LC_PER_ACCESS_ID, lowcore, per_access_id);
+ 	OFFSET(__LC_OP_ACCESS_ID, lowcore, op_access_id);
+ 	OFFSET(__LC_AR_MODE_ID, lowcore, ar_mode_id);
+ 	OFFSET(__LC_TRANS_EXC_CODE, lowcore, trans_exc_code);
+ 	OFFSET(__LC_MON_CODE, lowcore, monitor_code);
+ 	OFFSET(__LC_SUBCHANNEL_ID, lowcore, subchannel_id);
+ 	OFFSET(__LC_SUBCHANNEL_NR, lowcore, subchannel_nr);
+ 	OFFSET(__LC_IO_INT_PARM, lowcore, io_int_parm);
+ 	OFFSET(__LC_IO_INT_WORD, lowcore, io_int_word);
+ 	OFFSET(__LC_STFL_FAC_LIST, lowcore, stfl_fac_list);
+ 	OFFSET(__LC_STFLE_FAC_LIST, lowcore, stfle_fac_list);
+ 	OFFSET(__LC_MCCK_CODE, lowcore, mcck_interruption_code);
+ 	OFFSET(__LC_EXT_DAMAGE_CODE, lowcore, external_damage_code);
+ 	OFFSET(__LC_MCCK_FAIL_STOR_ADDR, lowcore, failing_storage_address);
+ 	OFFSET(__LC_LAST_BREAK, lowcore, breaking_event_addr);
+ 	OFFSET(__LC_RST_OLD_PSW, lowcore, restart_old_psw);
+ 	OFFSET(__LC_EXT_OLD_PSW, lowcore, external_old_psw);
+ 	OFFSET(__LC_SVC_OLD_PSW, lowcore, svc_old_psw);
+ 	OFFSET(__LC_PGM_OLD_PSW, lowcore, program_old_psw);
+ 	OFFSET(__LC_MCK_OLD_PSW, lowcore, mcck_old_psw);
+ 	OFFSET(__LC_IO_OLD_PSW, lowcore, io_old_psw);
+ 	OFFSET(__LC_RST_NEW_PSW, lowcore, restart_psw);
+ 	OFFSET(__LC_EXT_NEW_PSW, lowcore, external_new_psw);
+ 	OFFSET(__LC_SVC_NEW_PSW, lowcore, svc_new_psw);
+ 	OFFSET(__LC_PGM_NEW_PSW, lowcore, program_new_psw);
+ 	OFFSET(__LC_MCK_NEW_PSW, lowcore, mcck_new_psw);
+ 	OFFSET(__LC_IO_NEW_PSW, lowcore, io_new_psw);
+ 	/* software defined lowcore locations 0x200 - 0xdff*/
+ 	OFFSET(__LC_SAVE_AREA_SYNC, lowcore, save_area_sync);
+ 	OFFSET(__LC_SAVE_AREA_ASYNC, lowcore, save_area_async);
+ 	OFFSET(__LC_SAVE_AREA_RESTART, lowcore, save_area_restart);
+ 	OFFSET(__LC_CPU_FLAGS, lowcore, cpu_flags);
+ 	OFFSET(__LC_RETURN_PSW, lowcore, return_psw);
+ 	OFFSET(__LC_RETURN_MCCK_PSW, lowcore, return_mcck_psw);
+ 	OFFSET(__LC_SYNC_ENTER_TIMER, lowcore, sync_enter_timer);
+ 	OFFSET(__LC_ASYNC_ENTER_TIMER, lowcore, async_enter_timer);
+ 	OFFSET(__LC_MCCK_ENTER_TIMER, lowcore, mcck_enter_timer);
+ 	OFFSET(__LC_EXIT_TIMER, lowcore, exit_timer);
+ 	OFFSET(__LC_USER_TIMER, lowcore, user_timer);
+ 	OFFSET(__LC_SYSTEM_TIMER, lowcore, system_timer);
+ 	OFFSET(__LC_STEAL_TIMER, lowcore, steal_timer);
+ 	OFFSET(__LC_LAST_UPDATE_TIMER, lowcore, last_update_timer);
+ 	OFFSET(__LC_LAST_UPDATE_CLOCK, lowcore, last_update_clock);
+ 	OFFSET(__LC_INT_CLOCK, lowcore, int_clock);
+ 	OFFSET(__LC_MCCK_CLOCK, lowcore, mcck_clock);
+ 	OFFSET(__LC_CLOCK_COMPARATOR, lowcore, clock_comparator);
+ 	OFFSET(__LC_BOOT_CLOCK, lowcore, boot_clock);
+ 	OFFSET(__LC_CURRENT, lowcore, current_task);
+ 	OFFSET(__LC_KERNEL_STACK, lowcore, kernel_stack);
+ 	OFFSET(__LC_ASYNC_STACK, lowcore, async_stack);
+ 	OFFSET(__LC_PANIC_STACK, lowcore, panic_stack);
+ 	OFFSET(__LC_RESTART_STACK, lowcore, restart_stack);
+ 	OFFSET(__LC_RESTART_FN, lowcore, restart_fn);
+ 	OFFSET(__LC_RESTART_DATA, lowcore, restart_data);
+ 	OFFSET(__LC_RESTART_SOURCE, lowcore, restart_source);
+ 	OFFSET(__LC_USER_ASCE, lowcore, user_asce);
+ 	OFFSET(__LC_VDSO_ASCE, lowcore, vdso_asce);
+ 	OFFSET(__LC_LPP, lowcore, lpp);
+ 	OFFSET(__LC_CURRENT_PID, lowcore, current_pid);
+ 	OFFSET(__LC_PERCPU_OFFSET, lowcore, percpu_offset);
+ 	OFFSET(__LC_VDSO_PER_CPU, lowcore, vdso_per_cpu_data);
+ 	OFFSET(__LC_MACHINE_FLAGS, lowcore, machine_flags);
+ 	OFFSET(__LC_PREEMPT_COUNT, lowcore, preempt_count);
+ 	OFFSET(__LC_GMAP, lowcore, gmap);
+ 	OFFSET(__LC_BR_R1, lowcore, br_r1_trampoline);
+ 	/* software defined ABI-relevant lowcore locations 0xe00 - 0xe20 */
+ 	OFFSET(__LC_DUMP_REIPL, lowcore, ipib);
+ 	/* hardware defined lowcore locations 0x1000 - 0x18ff */
+ 	OFFSET(__LC_MCESAD, lowcore, mcesad);
+ 	OFFSET(__LC_EXT_PARAMS2, lowcore, ext_params2);
+ 	OFFSET(__LC_FPREGS_SAVE_AREA, lowcore, floating_pt_save_area);
+ 	OFFSET(__LC_GPREGS_SAVE_AREA, lowcore, gpregs_save_area);
+ 	OFFSET(__LC_PSW_SAVE_AREA, lowcore, psw_save_area);
+ 	OFFSET(__LC_PREFIX_SAVE_AREA, lowcore, prefixreg_save_area);
+ 	OFFSET(__LC_FP_CREG_SAVE_AREA, lowcore, fpt_creg_save_area);
+ 	OFFSET(__LC_TOD_PROGREG_SAVE_AREA, lowcore, tod_progreg_save_area);
+ 	OFFSET(__LC_CPU_TIMER_SAVE_AREA, lowcore, cpu_timer_save_area);
+ 	OFFSET(__LC_CLOCK_COMP_SAVE_AREA, lowcore, clock_comp_save_area);
+ 	OFFSET(__LC_AREGS_SAVE_AREA, lowcore, access_regs_save_area);
+ 	OFFSET(__LC_CREGS_SAVE_AREA, lowcore, cregs_save_area);
+ 	OFFSET(__LC_PGM_TDB, lowcore, pgm_tdb);
++>>>>>>> 23a4d7fd3485 (s390/ftrace: use expoline for indirect branches)
  	BLANK();
 -	/* extended machine check save area */
 -	OFFSET(__MCESA_GS_SAVE_AREA, mcesa, guarded_storage_save_area);
 -	BLANK();
 -	/* gmap/sie offsets */
 -	OFFSET(__GMAP_ASCE, gmap, asce);
 -	OFFSET(__SIE_PROG0C, kvm_s390_sie_block, prog0c);
 -	OFFSET(__SIE_PROG20, kvm_s390_sie_block, prog20);
 -	/* kexec_sha_region */
 -	OFFSET(__KEXEC_SHA_REGION_START, kexec_sha_region, start);
 -	OFFSET(__KEXEC_SHA_REGION_LEN, kexec_sha_region, len);
 -	DEFINE(__KEXEC_SHA_REGION_SIZE, sizeof(struct kexec_sha_region));
 +	DEFINE(__LC_CPU_TIMER_SAVE_AREA, offsetof(struct _lowcore, cpu_timer_save_area));
 +	DEFINE(__LC_CLOCK_COMP_SAVE_AREA, offsetof(struct _lowcore, clock_comp_save_area));
 +	DEFINE(__LC_PSW_SAVE_AREA, offsetof(struct _lowcore, psw_save_area));
 +	DEFINE(__LC_PREFIX_SAVE_AREA, offsetof(struct _lowcore, prefixreg_save_area));
 +	DEFINE(__LC_AREGS_SAVE_AREA, offsetof(struct _lowcore, access_regs_save_area));
 +	DEFINE(__LC_FPREGS_SAVE_AREA, offsetof(struct _lowcore, floating_pt_save_area));
 +	DEFINE(__LC_GPREGS_SAVE_AREA, offsetof(struct _lowcore, gpregs_save_area));
 +	DEFINE(__LC_CREGS_SAVE_AREA, offsetof(struct _lowcore, cregs_save_area));
 +#ifdef CONFIG_32BIT
 +	DEFINE(SAVE_AREA_BASE, offsetof(struct _lowcore, extended_save_area_addr));
 +#else /* CONFIG_32BIT */
 +	DEFINE(__LC_EXT_PARAMS2, offsetof(struct _lowcore, ext_params2));
 +	DEFINE(SAVE_AREA_BASE, offsetof(struct _lowcore, floating_pt_save_area));
 +	DEFINE(__LC_PASTE, offsetof(struct _lowcore, paste));
 +	DEFINE(__LC_FP_CREG_SAVE_AREA, offsetof(struct _lowcore, fpt_creg_save_area));
 +	DEFINE(__LC_LAST_BREAK, offsetof(struct _lowcore, breaking_event_addr));
 +	DEFINE(__LC_PERCPU_OFFSET, offsetof(struct _lowcore, percpu_offset));
 +	DEFINE(__LC_VDSO_PER_CPU, offsetof(struct _lowcore, vdso_per_cpu_data));
 +	DEFINE(__LC_GMAP, offsetof(struct _lowcore, gmap));
 +	DEFINE(__LC_PGM_TDB, offsetof(struct _lowcore, pgm_tdb));
 +	DEFINE(__THREAD_trap_tdb, offsetof(struct task_struct, thread.trap_tdb));
 +	DEFINE(__GMAP_ASCE, offsetof(struct gmap, asce));
 +	DEFINE(__SIE_PROG0C, offsetof(struct kvm_s390_sie_block, prog0c));
 +	DEFINE(__SIE_PROG20, offsetof(struct kvm_s390_sie_block, prog20));
 +#endif /* CONFIG_32BIT */
  	return 0;
  }
diff --cc arch/s390/kernel/mcount.S
index be6dbd9a81a7,27110f3294ed..000000000000
--- a/arch/s390/kernel/mcount.S
+++ b/arch/s390/kernel/mcount.S
@@@ -8,60 -9,82 +8,116 @@@
  #include <linux/linkage.h>
  #include <asm/asm-offsets.h>
  #include <asm/ftrace.h>
++<<<<<<< HEAD
++=======
+ #include <asm/nospec-insn.h>
+ #include <asm/ptrace.h>
+ #include <asm/export.h>
++>>>>>>> 23a4d7fd3485 (s390/ftrace: use expoline for indirect branches)
+ 
+ 	GEN_BR_THUNK %r1
+ 	GEN_BR_THUNK %r14
  
  	.section .kprobes.text, "ax"
  
  ENTRY(ftrace_stub)
- 	br	%r14
+ 	BR_EX	%r14
  
 -#define STACK_FRAME_SIZE  (STACK_FRAME_OVERHEAD + __PT_SIZE)
 -#define STACK_PTREGS	  (STACK_FRAME_OVERHEAD)
 -#define STACK_PTREGS_GPRS (STACK_PTREGS + __PT_GPRS)
 -#define STACK_PTREGS_PSW  (STACK_PTREGS + __PT_PSW)
 -
  ENTRY(_mcount)
- 	br	%r14
+ 	BR_EX	%r14
  
 -EXPORT_SYMBOL(_mcount)
 -
  ENTRY(ftrace_caller)
++<<<<<<< HEAD
 +	stm	%r2,%r5,16(%r15)
 +	bras	%r1,1f
 +0:	.long	ftrace_trace_function
 +1:	st	%r14,56(%r15)
 +	lr	%r0,%r15
 +	ahi	%r15,-96
 +	l	%r3,100(%r15)
 +	la	%r2,0(%r14)
 +	st	%r0,__SF_BACKCHAIN(%r15)
 +	la	%r3,0(%r3)
 +	ahi	%r2,-MCOUNT_INSN_SIZE
 +	l	%r14,0b-0b(%r1)
 +	l	%r14,0(%r14)
 +	basr	%r14,%r14
++=======
+ 	.globl	ftrace_regs_caller
+ 	.set	ftrace_regs_caller,ftrace_caller
+ 	lgr	%r1,%r15
+ #ifndef CC_USING_HOTPATCH
+ 	aghi	%r0,MCOUNT_RETURN_FIXUP
+ #endif
+ 	aghi	%r15,-STACK_FRAME_SIZE
+ 	stg	%r1,__SF_BACKCHAIN(%r15)
+ 	stg	%r1,(STACK_PTREGS_GPRS+15*8)(%r15)
+ 	stg	%r0,(STACK_PTREGS_PSW+8)(%r15)
+ 	stmg	%r2,%r14,(STACK_PTREGS_GPRS+2*8)(%r15)
+ #ifdef CONFIG_HAVE_MARCH_Z196_FEATURES
+ 	aghik	%r2,%r0,-MCOUNT_INSN_SIZE
+ 	lgrl	%r4,function_trace_op
+ 	lgrl	%r1,ftrace_trace_function
+ #else
+ 	lgr	%r2,%r0
+ 	aghi	%r2,-MCOUNT_INSN_SIZE
+ 	larl	%r4,function_trace_op
+ 	lg	%r4,0(%r4)
+ 	larl	%r1,ftrace_trace_function
+ 	lg	%r1,0(%r1)
+ #endif
+ 	lgr	%r3,%r14
+ 	la	%r5,STACK_PTREGS(%r15)
+ 	BASR_EX	%r14,%r1
++>>>>>>> 23a4d7fd3485 (s390/ftrace: use expoline for indirect branches)
  #ifdef CONFIG_FUNCTION_GRAPH_TRACER
 -# The j instruction gets runtime patched to a nop instruction.
 -# See ftrace_enable_ftrace_graph_caller.
 +	l	%r2,100(%r15)
 +	l	%r3,152(%r15)
  ENTRY(ftrace_graph_caller)
 -	j	ftrace_graph_caller_end
 -	lg	%r2,(STACK_PTREGS_GPRS+14*8)(%r15)
 -	lg	%r3,(STACK_PTREGS_PSW+8)(%r15)
 -	brasl	%r14,prepare_ftrace_return
 -	stg	%r2,(STACK_PTREGS_GPRS+14*8)(%r15)
 -ftrace_graph_caller_end:
 -	.globl	ftrace_graph_caller_end
 +# The bras instruction gets runtime patched to call prepare_ftrace_return.
 +# See ftrace_enable_ftrace_graph_caller. The patched instruction is:
 +#	bras	%r14,prepare_ftrace_return
 +	bras	%r14,0f
 +0:	st	%r2,100(%r15)
  #endif
++<<<<<<< HEAD
 +	ahi	%r15,96
 +	l	%r14,56(%r15)
 +	lm	%r2,%r5,16(%r15)
 +	br	%r14
++=======
+ 	lg	%r1,(STACK_PTREGS_PSW+8)(%r15)
+ 	lmg	%r2,%r15,(STACK_PTREGS_GPRS+2*8)(%r15)
+ 	BR_EX	%r1
++>>>>>>> 23a4d7fd3485 (s390/ftrace: use expoline for indirect branches)
  
  #ifdef CONFIG_FUNCTION_GRAPH_TRACER
  
  ENTRY(return_to_handler)
++<<<<<<< HEAD
 +	stm	%r2,%r5,16(%r15)
 +	st	%r14,56(%r15)
 +	lr	%r0,%r15
 +	ahi	%r15,-96
 +	st	%r0,__SF_BACKCHAIN(%r15)
 +	bras	%r1,0f
 +	.long	ftrace_return_to_handler
 +0:	l	%r2,0b-0b(%r1)
 +	basr	%r14,%r2
 +	lr	%r14,%r2
 +	ahi	%r15,96
 +	lm	%r2,%r5,16(%r15)
 +	br	%r14
++=======
+ 	stmg	%r2,%r5,32(%r15)
+ 	lgr	%r1,%r15
+ 	aghi	%r15,-STACK_FRAME_OVERHEAD
+ 	stg	%r1,__SF_BACKCHAIN(%r15)
+ 	brasl	%r14,ftrace_return_to_handler
+ 	aghi	%r15,STACK_FRAME_OVERHEAD
+ 	lgr	%r14,%r2
+ 	lmg	%r2,%r5,32(%r15)
+ 	BR_EX	%r14
++>>>>>>> 23a4d7fd3485 (s390/ftrace: use expoline for indirect branches)
  
  #endif
* Unmerged path arch/s390/include/asm/nospec-insn.h
* Unmerged path arch/s390/include/asm/nospec-insn.h
* Unmerged path arch/s390/kernel/asm-offsets.c
* Unmerged path arch/s390/kernel/mcount.S
