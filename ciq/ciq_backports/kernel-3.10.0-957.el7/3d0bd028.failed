net/sched: Add support for HW offloading for CBS

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [net] sched: Add support for HW offloading for CBS (Ivan Vecera) [1557250]
Rebuild_FUZZ: 95.65%
commit-author Vinicius Costa Gomes <vinicius.gomes@intel.com>
commit 3d0bd028ffb4a4915cb64cfa0d2cee1578cc0321
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/3d0bd028.failed

This adds support for offloading the CBS algorithm to the controller,
if supported. Drivers wanting to support CBS offload must implement
the .ndo_setup_tc callback and handle the TC_SETUP_CBS (introduced
here) type.

	Signed-off-by: Vinicius Costa Gomes <vinicius.gomes@intel.com>
	Tested-by: Henrik Austad <henrik@austad.us>
	Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
(cherry picked from commit 3d0bd028ffb4a4915cb64cfa0d2cee1578cc0321)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/netdevice.h
diff --cc include/linux/netdevice.h
index fe1a249a50cb,5e02f79b2110..000000000000
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@@ -814,170 -775,8 +814,175 @@@ enum tc_setup_type 
  	TC_SETUP_CLSFLOWER,
  	TC_SETUP_CLSMATCHALL,
  	TC_SETUP_CLSBPF,
++<<<<<<< HEAD
 +};
 +
 +/* Forward declaration of tc_to_netdev structure used by __rh_call_ndo_setup_tc
 + * wrapper for out-of-tree drivers compiled against RHEL7.4.
 + */
 +struct tc_to_netdev_rh74;
 +
 +struct tc_cls_u32_offload;
 +
 +struct tc_to_netdev {
 +	unsigned int type;
 +	union {
 +		u8 tc;
 +		struct tc_cls_u32_offload *cls_u32;
 +		struct tc_cls_flower_offload *cls_flower;
 +		struct tc_cls_matchall_offload *cls_mall;
 +		struct tc_cls_bpf_offload *cls_bpf;
 +	};
 +	bool egress_dev;
 +};
 +
 +/* This structure defines the management hooks for network devices.
 + * It is an extension of net_device_ops. Drivers that want to use any of the
 + * fields defined here must initialize net_device_ops->ndo_size to
 + * sizeof(struct net_device_ops).
 + *
 + * void* (*ndo_dfwd_add_station)(struct net_device *pdev,
 + *				 struct net_device *dev)
 + *	Called by upper layer devices to accelerate switching or other
 + *	station functionality into hardware. 'pdev is the lowerdev
 + *	to use for the offload and 'dev' is the net device that will
 + *	back the offload. Returns a pointer to the private structure
 + *	the upper layer will maintain.
 + * void (*ndo_dfwd_del_station)(struct net_device *pdev, void *priv)
 + *	Called by upper layer device to delete the station created
 + *	by 'ndo_dfwd_add_station'. 'pdev' is the net device backing
 + *	the station and priv is the structure returned by the add
 + *	operation.
 + * int (*ndo_set_tx_maxrate)(struct net_device *dev,
 + *			     int queue_index, u32 maxrate);
 + *	Called when a user wants to set a max-rate limitation of specific
 + *	TX queue.
 + * void (*ndo_set_rx_headroom)(struct net_device *dev, int needed_headroom);
 + *	This function is used to specify the headroom that the skb must
 + *	consider when allocation skb during packet reception. Setting
 + *	appropriate rx headroom value allows avoiding skb head copy on
 + *	forward. Setting a negative value reset the rx headroom to the
 + *	default value.
 + * int (*ndo_fdb_dump)(struct sk_buff *skb, struct netlink_callback *cb,
 + *		       struct net_device *dev, struct net_device *filter_dev,
 + *		       int *idx)
 + *	Used to add FDB entries to dump requests. Implementers should add
 + *	entries to skb and update idx with the number of entries.
 + * void (*ndo_change_proto_down)(struct net_device *dev,
 + *				 bool proto_down);
 + *	This function is used to pass protocol port error state information
 + *	to the switch driver. The switch driver can react to the proto_down
 + *      by doing a phys down on the associated switch port.
 + * void (*ndo_udp_tunnel_add)(struct net_device *dev,
 + *			      struct udp_tunnel_info *ti);
 + *	Called by UDP tunnel to notify a driver about the UDP port and socket
 + *	address family that a UDP tunnel is listnening to. It is called only
 + *	when a new port starts listening. The operation is protected by the
 + *	RTNL.
 + *
 + * void (*ndo_udp_tunnel_del)(struct net_device *dev,
 + *			      struct udp_tunnel_info *ti);
 + *	Called by UDP tunnel to notify the driver about a UDP port and socket
 + *	address family that the UDP tunnel is not listening to anymore. The
 + *	operation is protected by the RTNL.
 + *
 + * int (*ndo_set_vf_vlan)(struct net_device *dev, int vf, u16 vlan,
 + *			  u8 qos, __be16 proto);
 + *
 + * bool (*ndo_has_offload_stats)(const struct net_device *dev, int attr_id)
 + *	Return true if this device supports offload stats of this attr_id.
 + *
 + * int (*ndo_get_offload_stats)(int attr_id, const struct net_device *dev,
 + *	void *attr_data)
 + *	Get statistics for offload operations by attr_id. Write it into the
 + *	attr_data pointer.
 + *
 + * int (*ndo_change_mtu)(struct net_device *dev, int new_mtu);
 + *	Called when a user wants to change the Maximum Transfer Unit
 + *	of a device.
 + *	RHEL: This is an entry point for network device drivers that
 + *	      use central MTU range checking provided by network core.
 + *
 + * int (*ndo_setup_tc)(struct net_device *dev, enum tc_setup_type type,
 + *		       void *type_data);
 + *	Called to setup any 'tc' scheduler, classifier or action on @dev.
 + *	This is always called from the stack with the rtnl lock held and netif
 + *	tx queues stopped. This allows the netdevice to perform queue
 + *	management safely.
 + *	RHEL: Note that this callback is not part of kABI and its prototype
 + *	and semantic can be changed across releases.
 + * int (*ndo_xdp)(struct net_device *dev, struct netdev_xdp *xdp);
 + *	This function is used to set or query state related to XDP on the
 + *	netdevice. See definition of enum xdp_netdev_command for details.
 + * int (*ndo_xdp_xmit)(struct net_device *dev, struct xdp_buff *xdp);
 + *	This function is used to submit a XDP packet for transmit on a
 + *	netdevice.
 + * void (*ndo_xdp_flush)(struct net_device *dev);
 + *	This function is used to inform the driver to flush a paticular
 + *	xpd tx queue. Must be called on same CPU as xdp_xmit.
 + */
 +struct net_device_ops_extended {
 +	int			(*ndo_set_vf_trust)(struct net_device *dev,
 +						    int vf, bool setting);
 +	void*			(*ndo_dfwd_add_station)(struct net_device *pdev,
 +							struct net_device *dev);
 +	void			(*ndo_dfwd_del_station)(struct net_device *pdev,
 +							void *priv);
 +	int			(*ndo_set_tx_maxrate)(struct net_device *dev,
 +						      int queue_index,
 +						      u32 maxrate);
 +	void			(*ndo_set_rx_headroom)(struct net_device *dev,
 +						       int needed_headroom);
 +	int			(*ndo_set_vf_guid)(struct net_device *dev,
 +						   int vf, u64 guid,
 +						   int guid_type);
 +	int			(*ndo_fdb_dump_rh73)(struct sk_buff *skb,
 +						struct netlink_callback *cb,
 +						struct net_device *dev,
 +						struct net_device *filter_dev,
 +						int idx);
 +	int			(*ndo_get_phys_port_name)(struct net_device *dev,
 +							  char *name, size_t len);
 +	int			(*ndo_change_proto_down)(struct net_device *dev,
 +							 bool proto_down);
 +	void			(*ndo_udp_tunnel_add)(struct net_device *dev,
 +						      struct udp_tunnel_info *ti);
 +	void			(*ndo_udp_tunnel_del)(struct net_device *dev,
 +						      struct udp_tunnel_info *ti);
 +	int			(*ndo_neigh_construct)(struct net_device *dev,
 +						       struct neighbour *n);
 +	void			(*ndo_neigh_destroy)(struct net_device *dev,
 +						     struct neighbour *n);
 +	int			(*ndo_set_vf_vlan)(struct net_device *dev,
 +						   int vf, u16 vlan, u8 qos,
 +						   __be16 proto);
 +	int			(*ndo_fdb_dump)(struct sk_buff *skb,
 +						struct netlink_callback *cb,
 +						struct net_device *dev,
 +						struct net_device *filter_dev,
 +						int *idx);
 +	bool			(*ndo_has_offload_stats)(const struct net_device *dev, int attr_id);
 +	int			(*ndo_get_offload_stats)(int attr_id,
 +							 const struct net_device *dev,
 +							 void *attr_data);
 +	int			(*ndo_change_mtu)(struct net_device *dev,
 +						  int new_mtu);
 +	/*
 +	 * RHEL: Note that this callback is not part of kABI and its prototype
 +	 * and semantic can be changed across releases.
 +	 */
 +	int			(*ndo_setup_tc_rh)(struct net_device *dev,
 +						   enum tc_setup_type type,
 +						   void *type_data);
 +	int			(*ndo_xdp)(struct net_device *dev,
 +						  struct netdev_xdp *xdp);
 +	int                     (*ndo_xdp_xmit)(struct net_device *dev,
 +						struct xdp_buff *xdp);
 +	void                    (*ndo_xdp_flush)(struct net_device *dev);
++=======
+ 	TC_SETUP_BLOCK,
+ 	TC_SETUP_CBS,
++>>>>>>> 3d0bd028ffb4 (net/sched: Add support for HW offloading for CBS)
  };
  
  /* These structures hold the attributes of xdp state that are being passed
* Unmerged path include/linux/netdevice.h
diff --git a/include/net/pkt_sched.h b/include/net/pkt_sched.h
index 259bc191ba59..7c597b050b36 100644
--- a/include/net/pkt_sched.h
+++ b/include/net/pkt_sched.h
@@ -146,4 +146,13 @@ static inline bool is_classid_clsact_egress(u32 classid)
 	       TC_H_MIN(classid) == TC_H_MIN(TC_H_MIN_EGRESS);
 }
 
+struct tc_cbs_qopt_offload {
+	u8 enable;
+	s32 queue;
+	s32 hicredit;
+	s32 locredit;
+	s32 idleslope;
+	s32 sendslope;
+};
+
 #endif
diff --git a/net/sched/sch_cbs.c b/net/sched/sch_cbs.c
index 0e85133c5653..bdb533b7fb8c 100644
--- a/net/sched/sch_cbs.c
+++ b/net/sched/sch_cbs.c
@@ -68,6 +68,8 @@
 #define BYTES_PER_KBIT (1000LL / 8)
 
 struct cbs_sched_data {
+	bool offload;
+	int queue;
 	s64 port_rate; /* in bytes/s */
 	s64 last; /* timestamp in ns */
 	s64 credits; /* in bytes */
@@ -80,6 +82,11 @@ struct cbs_sched_data {
 	struct sk_buff *(*dequeue)(struct Qdisc *sch);
 };
 
+static int cbs_enqueue_offload(struct sk_buff *skb, struct Qdisc *sch)
+{
+	return qdisc_enqueue_tail(skb, sch);
+}
+
 static int cbs_enqueue_soft(struct sk_buff *skb, struct Qdisc *sch)
 {
 	struct cbs_sched_data *q = qdisc_priv(sch);
@@ -169,6 +176,11 @@ static struct sk_buff *cbs_dequeue_soft(struct Qdisc *sch)
 	return skb;
 }
 
+static struct sk_buff *cbs_dequeue_offload(struct Qdisc *sch)
+{
+	return qdisc_dequeue_head(sch);
+}
+
 static struct sk_buff *cbs_dequeue(struct Qdisc *sch)
 {
 	struct cbs_sched_data *q = qdisc_priv(sch);
@@ -180,14 +192,66 @@ static const struct nla_policy cbs_policy[TCA_CBS_MAX + 1] = {
 	[TCA_CBS_PARMS]	= { .len = sizeof(struct tc_cbs_qopt) },
 };
 
+static void cbs_disable_offload(struct net_device *dev,
+				struct cbs_sched_data *q)
+{
+	struct tc_cbs_qopt_offload cbs = { };
+	const struct net_device_ops *ops;
+	int err;
+
+	if (!q->offload)
+		return;
+
+	q->enqueue = cbs_enqueue_soft;
+	q->dequeue = cbs_dequeue_soft;
+
+	ops = dev->netdev_ops;
+	if (!ops->ndo_setup_tc)
+		return;
+
+	cbs.queue = q->queue;
+	cbs.enable = 0;
+
+	err = ops->ndo_setup_tc(dev, TC_SETUP_CBS, &cbs);
+	if (err < 0)
+		pr_warn("Couldn't disable CBS offload for queue %d\n",
+			cbs.queue);
+}
+
+static int cbs_enable_offload(struct net_device *dev, struct cbs_sched_data *q,
+			      const struct tc_cbs_qopt *opt)
+{
+	const struct net_device_ops *ops = dev->netdev_ops;
+	struct tc_cbs_qopt_offload cbs = { };
+	int err;
+
+	if (!ops->ndo_setup_tc)
+		return -EOPNOTSUPP;
+
+	cbs.queue = q->queue;
+
+	cbs.enable = 1;
+	cbs.hicredit = opt->hicredit;
+	cbs.locredit = opt->locredit;
+	cbs.idleslope = opt->idleslope;
+	cbs.sendslope = opt->sendslope;
+
+	err = ops->ndo_setup_tc(dev, TC_SETUP_CBS, &cbs);
+	if (err < 0)
+		return err;
+
+	q->enqueue = cbs_enqueue_offload;
+	q->dequeue = cbs_dequeue_offload;
+
+	return 0;
+}
+
 static int cbs_change(struct Qdisc *sch, struct nlattr *opt)
 {
 	struct cbs_sched_data *q = qdisc_priv(sch);
 	struct net_device *dev = qdisc_dev(sch);
 	struct nlattr *tb[TCA_CBS_MAX + 1];
-	struct ethtool_link_ksettings ecmd;
 	struct tc_cbs_qopt *qopt;
-	s64 link_speed;
 	int err;
 
 	err = nla_parse_nested(tb, TCA_CBS_MAX, opt, cbs_policy, NULL);
@@ -199,23 +263,30 @@ static int cbs_change(struct Qdisc *sch, struct nlattr *opt)
 
 	qopt = nla_data(tb[TCA_CBS_PARMS]);
 
-	if (qopt->offload)
-		return -EOPNOTSUPP;
+	if (!qopt->offload) {
+		struct ethtool_link_ksettings ecmd;
+		s64 link_speed;
 
-	if (!__ethtool_get_link_ksettings(dev, &ecmd))
-		link_speed = ecmd.base.speed;
-	else
-		link_speed = SPEED_1000;
+		if (!__ethtool_get_link_ksettings(dev, &ecmd))
+			link_speed = ecmd.base.speed;
+		else
+			link_speed = SPEED_1000;
 
-	q->port_rate = link_speed * 1000 * BYTES_PER_KBIT;
+		q->port_rate = link_speed * 1000 * BYTES_PER_KBIT;
 
-	q->enqueue = cbs_enqueue_soft;
-	q->dequeue = cbs_dequeue_soft;
+		cbs_disable_offload(dev, q);
+	} else {
+		err = cbs_enable_offload(dev, q, qopt);
+		if (err < 0)
+			return err;
+	}
 
+	/* Everything went OK, save the parameters used. */
 	q->hicredit = qopt->hicredit;
 	q->locredit = qopt->locredit;
 	q->idleslope = qopt->idleslope * BYTES_PER_KBIT;
 	q->sendslope = qopt->sendslope * BYTES_PER_KBIT;
+	q->offload = qopt->offload;
 
 	return 0;
 }
@@ -223,10 +294,16 @@ static int cbs_change(struct Qdisc *sch, struct nlattr *opt)
 static int cbs_init(struct Qdisc *sch, struct nlattr *opt)
 {
 	struct cbs_sched_data *q = qdisc_priv(sch);
+	struct net_device *dev = qdisc_dev(sch);
 
 	if (!opt)
 		return -EINVAL;
 
+	q->queue = sch->dev_queue - netdev_get_tx_queue(dev, 0);
+
+	q->enqueue = cbs_enqueue_soft;
+	q->dequeue = cbs_dequeue_soft;
+
 	qdisc_watchdog_init(&q->watchdog, sch);
 
 	return cbs_change(sch, opt);
@@ -235,8 +312,11 @@ static int cbs_init(struct Qdisc *sch, struct nlattr *opt)
 static void cbs_destroy(struct Qdisc *sch)
 {
 	struct cbs_sched_data *q = qdisc_priv(sch);
+	struct net_device *dev = qdisc_dev(sch);
 
 	qdisc_watchdog_cancel(&q->watchdog);
+
+	cbs_disable_offload(dev, q);
 }
 
 static int cbs_dump(struct Qdisc *sch, struct sk_buff *skb)
@@ -253,7 +333,7 @@ static int cbs_dump(struct Qdisc *sch, struct sk_buff *skb)
 	opt.locredit = q->locredit;
 	opt.sendslope = div64_s64(q->sendslope, BYTES_PER_KBIT);
 	opt.idleslope = div64_s64(q->idleslope, BYTES_PER_KBIT);
-	opt.offload = 0;
+	opt.offload = q->offload;
 
 	if (nla_put(skb, TCA_CBS_PARMS, sizeof(opt), &opt))
 		goto nla_put_failure;
