nvme-fabrics: fix and refine state checks in __nvmf_check_ready

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Christoph Hellwig <hch@lst.de>
commit 35897b920c8ab5e23331ad429e0aa235528c63ba
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/35897b92.failed

 - make sure we only allow internally generates commands in any non-live
   state
 - only allow connect commands on non-live queues when actually in the
   new or connecting states
 - treat all other non-live, non-dead states the same as a default
   cach-all

This fixes a regression where we could not shutdown a controller
orderly as we didn't allow the internal generated Property Set
command, and also ensures we don't accidentally let a Connect command
through in the wrong state.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: James Smart <james.smart@broadcom.com>
(cherry picked from commit 35897b920c8ab5e23331ad429e0aa235528c63ba)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/fabrics.c
diff --cc drivers/nvme/host/fabrics.c
index a4c054fbefbd,903eb4545e26..000000000000
--- a/drivers/nvme/host/fabrics.c
+++ b/drivers/nvme/host/fabrics.c
@@@ -536,6 -536,56 +536,59 @@@ static struct nvmf_transport_ops *nvmf_
  	return NULL;
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * For something we're not in a state to send to the device the default action
+  * is to busy it and retry it after the controller state is recovered.  However,
+  * anything marked for failfast or nvme multipath is immediately failed.
+  *
+  * Note: commands used to initialize the controller will be marked for failfast.
+  * Note: nvme cli/ioctl commands are marked for failfast.
+  */
+ blk_status_t nvmf_fail_nonready_command(struct request *rq)
+ {
+ 	if (!blk_noretry_request(rq) && !(rq->cmd_flags & REQ_NVME_MPATH))
+ 		return BLK_STS_RESOURCE;
+ 	nvme_req(rq)->status = NVME_SC_ABORT_REQ;
+ 	return BLK_STS_IOERR;
+ }
+ EXPORT_SYMBOL_GPL(nvmf_fail_nonready_command);
+ 
+ bool __nvmf_check_ready(struct nvme_ctrl *ctrl, struct request *rq,
+ 		bool queue_live)
+ {
+ 	struct nvme_request *req = nvme_req(rq);
+ 
+ 	/*
+ 	 * If we are in some state of setup or teardown only allow
+ 	 * internally generated commands.
+ 	 */
+ 	if (!blk_rq_is_passthrough(rq) || (req->flags & NVME_REQ_USERCMD))
+ 		return false;
+ 
+ 	/*
+ 	 * Only allow commands on a live queue, except for the connect command,
+ 	 * which is require to set the queue live in the appropinquate states.
+ 	 */
+ 	switch (ctrl->state) {
+ 	case NVME_CTRL_NEW:
+ 	case NVME_CTRL_CONNECTING:
+ 		if (req->cmd->common.opcode == nvme_fabrics_command &&
+ 		    req->cmd->fabrics.fctype == nvme_fabrics_type_connect)
+ 			return true;
+ 		break;
+ 	default:
+ 		break;
+ 	case NVME_CTRL_DEAD:
+ 		return false;
+ 	}
+ 
+ 	return queue_live;
+ }
+ EXPORT_SYMBOL_GPL(__nvmf_check_ready);
+ 
++>>>>>>> 35897b920c8a (nvme-fabrics: fix and refine state checks in __nvmf_check_ready)
  static const match_table_t opt_tokens = {
  	{ NVMF_OPT_TRANSPORT,		"transport=%s"		},
  	{ NVMF_OPT_TRADDR,		"traddr=%s"		},
* Unmerged path drivers/nvme/host/fabrics.c
