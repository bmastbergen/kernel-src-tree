drm/nouveau/gem: lookup VMAs for buffers referenced by pushbuf ioctl

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Ben Skeggs <bskeggs@redhat.com>
commit 19ca10d82e33bcfe92412c461fc3534ec1e14747
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/19ca10d8.failed

We previously only did this for push buffers, but an upcoming patch will
need to attach fences to all VMAs to resolve another issue.

	Signed-off-by: Ben Skeggs <bskeggs@redhat.com>
(cherry picked from commit 19ca10d82e33bcfe92412c461fc3534ec1e14747)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/nouveau/nouveau_dma.c
diff --cc drivers/gpu/drm/nouveau/nouveau_dma.c
index 2634a1a79888,e0664d28802b..000000000000
--- a/drivers/gpu/drm/nouveau/nouveau_dma.c
+++ b/drivers/gpu/drm/nouveau/nouveau_dma.c
@@@ -79,18 -80,10 +79,20 @@@ READ_GET(struct nouveau_channel *chan, 
  }
  
  void
- nv50_dma_push(struct nouveau_channel *chan, struct nouveau_bo *bo,
- 	      int delta, int length)
+ nv50_dma_push(struct nouveau_channel *chan, u64 offset, int length)
  {
- 	struct nouveau_cli *cli = (void *)chan->user.client;
  	struct nouveau_bo *pb = chan->push.buffer;
++<<<<<<< HEAD
 +	struct nvkm_vma *vma;
  	int ip = (chan->dma.ib_put * 2) + chan->dma.ib_base;
 +	u64 offset;
 +
 +	vma = nouveau_bo_vma_find(bo, cli->vm);
 +	BUG_ON(!vma);
 +	offset = vma->offset + delta;
++=======
++	int ip = (chan->dma.ib_put * 2) + chan->dma.ib_base;
++>>>>>>> 19ca10d82e33 (drm/nouveau/gem: lookup VMAs for buffers referenced by pushbuf ioctl)
  
  	BUG_ON(chan->dma.ib_free < 1);
  
* Unmerged path drivers/gpu/drm/nouveau/nouveau_dma.c
diff --git a/drivers/gpu/drm/nouveau/nouveau_dma.h b/drivers/gpu/drm/nouveau/nouveau_dma.h
index aff3a9d0a1fc..8399bd41b9f7 100644
--- a/drivers/gpu/drm/nouveau/nouveau_dma.h
+++ b/drivers/gpu/drm/nouveau/nouveau_dma.h
@@ -31,8 +31,7 @@
 #include "nouveau_chan.h"
 
 int nouveau_dma_wait(struct nouveau_channel *, int slots, int size);
-void nv50_dma_push(struct nouveau_channel *, struct nouveau_bo *,
-		   int delta, int length);
+void nv50_dma_push(struct nouveau_channel *, u64 addr, int length);
 
 /*
  * There's a hw race condition where you can't jump to your PUT offset,
@@ -151,7 +150,7 @@ FIRE_RING(struct nouveau_channel *chan)
 	chan->accel_done = true;
 
 	if (chan->dma.ib_max) {
-		nv50_dma_push(chan, chan->push.buffer, chan->dma.put << 2,
+		nv50_dma_push(chan, chan->push.addr + (chan->dma.put << 2),
 			      (chan->dma.cur - chan->dma.put) << 2);
 	} else {
 		WRITE_PUT(chan->dma.cur);
diff --git a/drivers/gpu/drm/nouveau/nouveau_gem.c b/drivers/gpu/drm/nouveau/nouveau_gem.c
index 2170534101ca..7ce585b01e80 100644
--- a/drivers/gpu/drm/nouveau/nouveau_gem.c
+++ b/drivers/gpu/drm/nouveau/nouveau_gem.c
@@ -427,7 +427,20 @@ retry:
 			}
 		}
 
-		b->user_priv = (uint64_t)(unsigned long)nvbo;
+		if (cli->vmm.vmm.object.oclass >= NVIF_CLASS_VMM_NV50) {
+			struct nouveau_vmm *vmm = &cli->vmm;
+			struct nouveau_vma *vma = nouveau_vma_find(nvbo, vmm);
+			if (!vma) {
+				NV_PRINTK(err, cli, "vma not found!\n");
+				ret = -EINVAL;
+				break;
+			}
+
+			b->user_priv = (uint64_t)(unsigned long)vma;
+		} else {
+			b->user_priv = (uint64_t)(unsigned long)nvbo;
+		}
+
 		nvbo->reserved_by = file_priv;
 		nvbo->pbbo_index = i;
 		if ((b->valid_domains & NOUVEAU_GEM_DOMAIN_VRAM) &&
@@ -758,10 +771,10 @@ nouveau_gem_ioctl_pushbuf(struct drm_device *dev, void *data,
 		}
 
 		for (i = 0; i < req->nr_push; i++) {
-			struct nouveau_bo *nvbo = (void *)(unsigned long)
+			struct nouveau_vma *vma = (void *)(unsigned long)
 				bo[push[i].bo_index].user_priv;
 
-			nv50_dma_push(chan, nvbo, push[i].offset,
+			nv50_dma_push(chan, vma->addr + push[i].offset,
 				      push[i].length);
 		}
 	} else
