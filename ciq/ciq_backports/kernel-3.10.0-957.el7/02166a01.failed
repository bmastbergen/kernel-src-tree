mmc: block: Tag DRV_OPs with a driver operation type

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [mmc] block: Tag DRV_OPs with a driver operation type (Gopal Tiwari) [1456570]
Rebuild_FUZZ: 94.95%
commit-author Linus Walleij <linus.walleij@linaro.org>
commit 02166a01f8113c6374d6f1512befa9233c837fa0
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/02166a01.failed

We will expand the DRV_OP usage, so we need to know which
operation we're performing. Tag the operations with an
enum:ed type and rename the function so it is clear that
it deals with any command and put a switch statement in
it. Currently only ioctls are supported.

	Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
	Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
(cherry picked from commit 02166a01f8113c6374d6f1512befa9233c837fa0)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/mmc/core/block.c
#	drivers/mmc/core/queue.h
diff --cc drivers/mmc/core/block.c
index 97e814713e97,b24e7f5171c9..000000000000
--- a/drivers/mmc/core/block.c
+++ b/drivers/mmc/core/block.c
@@@ -583,17 -594,21 +583,33 @@@ static int mmc_blk_ioctl_cmd(struct blo
  		goto cmd_done;
  	}
  
++<<<<<<< HEAD
 +	mmc_get_card(card);
 +
 +	ioc_err = __mmc_blk_ioctl_cmd(card, md, idata);
 +
 +	/* Always switch back to main area after RPMB access */
 +	if (md->area_type & MMC_BLK_DATA_AREA_RPMB)
 +		mmc_blk_part_switch(card, dev_get_drvdata(&card->dev));
 +
 +	mmc_put_card(card);
 +
++=======
+ 	/*
+ 	 * Dispatch the ioctl() into the block request queue.
+ 	 */
+ 	mq = &md->queue;
+ 	req = blk_get_request(mq->queue,
+ 		idata->ic.write_flag ? REQ_OP_DRV_OUT : REQ_OP_DRV_IN,
+ 		__GFP_RECLAIM);
+ 	idatas[0] = idata;
+ 	req_to_mmc_queue_req(req)->drv_op = MMC_DRV_OP_IOCTL;
+ 	req_to_mmc_queue_req(req)->idata = idatas;
+ 	req_to_mmc_queue_req(req)->ioc_count = 1;
+ 	blk_execute_rq(mq->queue, NULL, req, 0);
+ 	ioc_err = req_to_mmc_queue_req(req)->ioc_result;
++>>>>>>> 02166a01f811 (mmc: block: Tag DRV_OPs with a driver operation type)
  	err = mmc_blk_ioctl_copy_to_user(ic_ptr, idata);
 -	blk_put_request(req);
  
  cmd_done:
  	mmc_blk_put(md);
@@@ -603,6 -618,43 +619,46 @@@ cmd_err
  	return ioc_err ? ioc_err : err;
  }
  
++<<<<<<< HEAD
++=======
+ /*
+  * The non-block commands come back from the block layer after it queued it and
+  * processed it with all other requests and then they get issued in this
+  * function.
+  */
+ static void mmc_blk_issue_drv_op(struct mmc_queue *mq, struct request *req)
+ {
+ 	struct mmc_queue_req *mq_rq;
+ 	struct mmc_card *card = mq->card;
+ 	struct mmc_blk_data *md = mq->blkdata;
+ 	int ioc_err;
+ 	int i;
+ 
+ 	mq_rq = req_to_mmc_queue_req(req);
+ 
+ 	switch (mq_rq->drv_op) {
+ 	case MMC_DRV_OP_IOCTL:
+ 		for (i = 0; i < mq_rq->ioc_count; i++) {
+ 			ioc_err =
+ 				__mmc_blk_ioctl_cmd(card, md, mq_rq->idata[i]);
+ 			if (ioc_err)
+ 				break;
+ 		}
+ 		mq_rq->ioc_result = ioc_err;
+ 
+ 		/* Always switch back to main area after RPMB access */
+ 		if (md->area_type & MMC_BLK_DATA_AREA_RPMB)
+ 			mmc_blk_part_switch(card, dev_get_drvdata(&card->dev));
+ 
+ 		blk_end_request_all(req, ioc_err);
+ 		break;
+ 	default:
+ 		/* Unknown operation */
+ 		break;
+ 	}
+ }
+ 
++>>>>>>> 02166a01f811 (mmc: block: Tag DRV_OPs with a driver operation type)
  static int mmc_blk_ioctl_multi_cmd(struct block_device *bdev,
  				   struct mmc_ioc_multi_cmd __user *user)
  {
@@@ -653,16 -707,19 +709,31 @@@
  		goto cmd_done;
  	}
  
 +	mmc_get_card(card);
 +
++<<<<<<< HEAD
 +	for (i = 0; i < num_of_cmds && !ioc_err; i++)
 +		ioc_err = __mmc_blk_ioctl_cmd(card, md, idata[i]);
  
 +	/* Always switch back to main area after RPMB access */
 +	if (md->area_type & MMC_BLK_DATA_AREA_RPMB)
 +		mmc_blk_part_switch(card, dev_get_drvdata(&card->dev));
 +
 +	mmc_put_card(card);
++=======
+ 	/*
+ 	 * Dispatch the ioctl()s into the block request queue.
+ 	 */
+ 	mq = &md->queue;
+ 	req = blk_get_request(mq->queue,
+ 		idata[0]->ic.write_flag ? REQ_OP_DRV_OUT : REQ_OP_DRV_IN,
+ 		__GFP_RECLAIM);
+ 	req_to_mmc_queue_req(req)->drv_op = MMC_DRV_OP_IOCTL;
+ 	req_to_mmc_queue_req(req)->idata = idata;
+ 	req_to_mmc_queue_req(req)->ioc_count = num_of_cmds;
+ 	blk_execute_rq(mq->queue, NULL, req, 0);
+ 	ioc_err = req_to_mmc_queue_req(req)->ioc_result;
++>>>>>>> 02166a01f811 (mmc: block: Tag DRV_OPs with a driver operation type)
  
  	/* copy to user if data and response */
  	for (i = 0; i < num_of_cmds && !err; i++)
@@@ -1802,22 -1905,55 +1873,70 @@@ int mmc_blk_issue_rq(struct mmc_queue *
  		goto out;
  	}
  
++<<<<<<< HEAD
 +	mq->flags &= ~MMC_QUEUE_NEW_REQUEST;
 +	if (cmd_flags & REQ_DISCARD) {
 +		/* complete ongoing async transfer before issuing discard */
 +		if (card->host->areq)
 +			mmc_blk_issue_rw_rq(mq, NULL);
 +		if (req->cmd_flags & REQ_SECURE)
 +			ret = mmc_blk_issue_secdiscard_rq(mq, req);
 +		else
 +			ret = mmc_blk_issue_discard_rq(mq, req);
 +	} else if (cmd_flags & REQ_FLUSH) {
 +		/* complete ongoing async transfer before issuing flush */
 +		if (card->host->areq)
 +			mmc_blk_issue_rw_rq(mq, NULL);
 +		ret = mmc_blk_issue_flush(mq, req);
++=======
+ 	if (req) {
+ 		switch (req_op(req)) {
+ 		case REQ_OP_DRV_IN:
+ 		case REQ_OP_DRV_OUT:
+ 			/*
+ 			 * Complete ongoing async transfer before issuing
+ 			 * ioctl()s
+ 			 */
+ 			if (mq->qcnt)
+ 				mmc_blk_issue_rw_rq(mq, NULL);
+ 			mmc_blk_issue_drv_op(mq, req);
+ 			break;
+ 		case REQ_OP_DISCARD:
+ 			/*
+ 			 * Complete ongoing async transfer before issuing
+ 			 * discard.
+ 			 */
+ 			if (mq->qcnt)
+ 				mmc_blk_issue_rw_rq(mq, NULL);
+ 			mmc_blk_issue_discard_rq(mq, req);
+ 			break;
+ 		case REQ_OP_SECURE_ERASE:
+ 			/*
+ 			 * Complete ongoing async transfer before issuing
+ 			 * secure erase.
+ 			 */
+ 			if (mq->qcnt)
+ 				mmc_blk_issue_rw_rq(mq, NULL);
+ 			mmc_blk_issue_secdiscard_rq(mq, req);
+ 			break;
+ 		case REQ_OP_FLUSH:
+ 			/*
+ 			 * Complete ongoing async transfer before issuing
+ 			 * flush.
+ 			 */
+ 			if (mq->qcnt)
+ 				mmc_blk_issue_rw_rq(mq, NULL);
+ 			mmc_blk_issue_flush(mq, req);
+ 			break;
+ 		default:
+ 			/* Normal request, just issue it */
+ 			mmc_blk_issue_rw_rq(mq, req);
+ 			card->host->context_info.is_waiting_last_req = false;
+ 			break;
+ 		};
++>>>>>>> 02166a01f811 (mmc: block: Tag DRV_OPs with a driver operation type)
  	} else {
 -		/* No request, flushing the pipeline with NULL */
 -		mmc_blk_issue_rw_rq(mq, NULL);
 -		card->host->context_info.is_waiting_last_req = false;
 +		ret = mmc_blk_issue_rw_rq(mq, req);
  	}
  
  out:
diff --cc drivers/mmc/core/queue.h
index a61f88199573,1e6062eb3e07..000000000000
--- a/drivers/mmc/core/queue.h
+++ b/drivers/mmc/core/queue.h
@@@ -16,14 -32,25 +16,30 @@@ struct mmc_blk_request 
  	int			retune_retry_done;
  };
  
+ /**
+  * enum mmc_drv_op - enumerates the operations in the mmc_queue_req
+  * @MMC_DRV_OP_IOCTL: ioctl operation
+  */
+ enum mmc_drv_op {
+ 	MMC_DRV_OP_IOCTL,
+ };
+ 
  struct mmc_queue_req {
 +	struct request		*req;
  	struct mmc_blk_request	brq;
  	struct scatterlist	*sg;
  	char			*bounce_buf;
  	struct scatterlist	*bounce_sg;
  	unsigned int		bounce_sg_len;
++<<<<<<< HEAD
 +	struct mmc_async_req	mmc_active;
++=======
+ 	struct mmc_async_req	areq;
+ 	enum mmc_drv_op		drv_op;
+ 	int			ioc_result;
+ 	struct mmc_blk_ioc_data	**idata;
+ 	unsigned int		ioc_count;
++>>>>>>> 02166a01f811 (mmc: block: Tag DRV_OPs with a driver operation type)
  };
  
  struct mmc_queue {
* Unmerged path drivers/mmc/core/block.c
* Unmerged path drivers/mmc/core/queue.h
