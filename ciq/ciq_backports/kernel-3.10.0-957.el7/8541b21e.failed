tcp: call tcp_drop() from tcp_data_queue_ofo()

jira LE-1907
cve CVE-2018-5390
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Eric Dumazet <edumazet@google.com>
commit 8541b21e781a22dce52a74fef0b9bed00404a1cd
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/8541b21e.failed

In order to be able to give better diagnostics and detect
malicious traffic, we need to have better sk->sk_drops tracking.

Fixes: 9f5afeae5152 ("tcp: use an RB tree for ooo receive queue")
	Signed-off-by: Eric Dumazet <edumazet@google.com>
	Acked-by: Soheil Hassas Yeganeh <soheil@google.com>
	Acked-by: Yuchung Cheng <ycheng@google.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 8541b21e781a22dce52a74fef0b9bed00404a1cd)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/ipv4/tcp_input.c
diff --cc net/ipv4/tcp_input.c
index f78fd9207b7a,b062a7692238..000000000000
--- a/net/ipv4/tcp_input.c
+++ b/net/ipv4/tcp_input.c
@@@ -4327,73 -4478,74 +4327,108 @@@ static void tcp_data_queue_ofo(struct s
  		goto end;
  	}
  
 -	/* In the typical case, we are adding an skb to the end of the list.
 -	 * Use of ooo_last_skb avoids the O(Log(N)) rbtree lookup.
 -	 */
 -	if (tcp_try_coalesce(sk, tp->ooo_last_skb,
 -			     skb, &fragstolen)) {
 -coalesce_done:
 -		tcp_grow_window(sk, skb);
 -		kfree_skb_partial(skb, fragstolen);
 -		skb = NULL;
 -		goto add_sack;
 -	}
 -	/* Can avoid an rbtree lookup if we are adding skb after ooo_last_skb */
 -	if (!before(seq, TCP_SKB_CB(tp->ooo_last_skb)->end_seq)) {
 -		parent = &tp->ooo_last_skb->rbnode;
 -		p = &parent->rb_right;
 -		goto insert;
 +	seq = TCP_SKB_CB(skb)->seq;
 +	end_seq = TCP_SKB_CB(skb)->end_seq;
 +
 +	if (seq == TCP_SKB_CB(skb1)->end_seq) {
 +		bool fragstolen;
 +
 +		if (!tcp_try_coalesce(sk, skb1, skb, &fragstolen)) {
 +			__skb_queue_after(&tp->out_of_order_queue, skb1, skb);
 +		} else {
 +			tcp_grow_window(sk, skb);
 +			kfree_skb_partial(skb, fragstolen);
 +			skb = NULL;
 +		}
 +
 +		if (!tp->rx_opt.num_sacks ||
 +		    tp->selective_acks[0].end_seq != seq)
 +			goto add_sack;
 +
 +		/* Common case: data arrive in order after hole. */
 +		tp->selective_acks[0].end_seq = end_seq;
 +		goto end;
  	}
  
 -	/* Find place to insert this segment. Handle overlaps on the way. */
 -	parent = NULL;
 -	while (*p) {
 -		parent = *p;
 -		skb1 = rb_to_skb(parent);
 -		if (before(seq, TCP_SKB_CB(skb1)->seq)) {
 -			p = &parent->rb_left;
 -			continue;
 +	/* Find place to insert this segment. */
 +	while (1) {
 +		if (!after(TCP_SKB_CB(skb1)->seq, seq))
 +			break;
 +		if (skb_queue_is_first(&tp->out_of_order_queue, skb1)) {
 +			skb1 = NULL;
 +			break;
  		}
++<<<<<<< HEAD
 +		skb1 = skb_queue_prev(&tp->out_of_order_queue, skb1);
++=======
+ 		if (before(seq, TCP_SKB_CB(skb1)->end_seq)) {
+ 			if (!after(end_seq, TCP_SKB_CB(skb1)->end_seq)) {
+ 				/* All the bits are present. Drop. */
+ 				NET_INC_STATS(sock_net(sk),
+ 					      LINUX_MIB_TCPOFOMERGE);
+ 				tcp_drop(sk, skb);
+ 				skb = NULL;
+ 				tcp_dsack_set(sk, seq, end_seq);
+ 				goto add_sack;
+ 			}
+ 			if (after(seq, TCP_SKB_CB(skb1)->seq)) {
+ 				/* Partial overlap. */
+ 				tcp_dsack_set(sk, seq, TCP_SKB_CB(skb1)->end_seq);
+ 			} else {
+ 				/* skb's seq == skb1's seq and skb covers skb1.
+ 				 * Replace skb1 with skb.
+ 				 */
+ 				rb_replace_node(&skb1->rbnode, &skb->rbnode,
+ 						&tp->out_of_order_queue);
+ 				tcp_dsack_extend(sk,
+ 						 TCP_SKB_CB(skb1)->seq,
+ 						 TCP_SKB_CB(skb1)->end_seq);
+ 				NET_INC_STATS(sock_net(sk),
+ 					      LINUX_MIB_TCPOFOMERGE);
+ 				tcp_drop(sk, skb1);
+ 				goto merge_right;
+ 			}
+ 		} else if (tcp_try_coalesce(sk, skb1,
+ 					    skb, &fragstolen)) {
+ 			goto coalesce_done;
+ 		}
+ 		p = &parent->rb_right;
++>>>>>>> 8541b21e781a (tcp: call tcp_drop() from tcp_data_queue_ofo())
 +	}
 +
 +	/* Do skb overlap to previous one? */
 +	if (skb1 && before(seq, TCP_SKB_CB(skb1)->end_seq)) {
 +		if (!after(end_seq, TCP_SKB_CB(skb1)->end_seq)) {
 +			/* All the bits are present. Drop. */
 +			NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPOFOMERGE);
 +			__kfree_skb(skb);
 +			skb = NULL;
 +			tcp_dsack_set(sk, seq, end_seq);
 +			goto add_sack;
 +		}
 +		if (after(seq, TCP_SKB_CB(skb1)->seq)) {
 +			/* Partial overlap. */
 +			tcp_dsack_set(sk, seq,
 +				      TCP_SKB_CB(skb1)->end_seq);
 +		} else {
 +			if (skb_queue_is_first(&tp->out_of_order_queue,
 +					       skb1))
 +				skb1 = NULL;
 +			else
 +				skb1 = skb_queue_prev(
 +					&tp->out_of_order_queue,
 +					skb1);
 +		}
  	}
 -insert:
 -	/* Insert segment into RB tree. */
 -	rb_link_node(&skb->rbnode, parent, p);
 -	rb_insert_color(&skb->rbnode, &tp->out_of_order_queue);
 +	if (!skb1)
 +		__skb_queue_head(&tp->out_of_order_queue, skb);
 +	else
 +		__skb_queue_after(&tp->out_of_order_queue, skb1, skb);
 +
 +	/* And clean segments covered by new one as whole. */
 +	while (!skb_queue_is_last(&tp->out_of_order_queue, skb)) {
 +		skb1 = skb_queue_next(&tp->out_of_order_queue, skb);
  
 -merge_right:
 -	/* Remove other segments covered by skb. */
 -	while ((skb1 = skb_rb_next(skb)) != NULL) {
  		if (!after(end_seq, TCP_SKB_CB(skb1)->seq))
  			break;
  		if (before(end_seq, TCP_SKB_CB(skb1)->end_seq)) {
* Unmerged path net/ipv4/tcp_input.c
