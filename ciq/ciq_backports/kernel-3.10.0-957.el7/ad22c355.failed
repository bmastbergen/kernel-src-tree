nvme: remove handling of multiple AEN requests

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [nvme] remove handling of multiple AEN requests (David Milburn) [1519689]
Rebuild_FUZZ: 93.02%
commit-author Keith Busch <keith.busch@intel.com>
commit ad22c355b707a8d8d48e282aadc01c0b0604b2e9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/ad22c355.failed

The driver can handle tracking only one AEN request, so this patch
removes handling for multiple ones.

	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: James Smart  <james.smart@broadcom.com>
	Signed-off-by: Keith Busch <keith.busch@intel.com>
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit ad22c355b707a8d8d48e282aadc01c0b0604b2e9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/core.c
#	drivers/nvme/host/fc.c
#	drivers/nvme/host/nvme.h
#	drivers/nvme/host/pci.c
diff --cc drivers/nvme/host/core.c
index 9225e17bc34a,dedbf12847b6..000000000000
--- a/drivers/nvme/host/core.c
+++ b/drivers/nvme/host/core.c
@@@ -2484,7 -2758,6 +2463,10 @@@ EXPORT_SYMBOL_GPL(nvme_complete_async_e
  
  void nvme_queue_async_events(struct nvme_ctrl *ctrl)
  {
++<<<<<<< HEAD
 +	ctrl->event_limit = NVME_NR_AERS;
++=======
++>>>>>>> ad22c355b707 (nvme: remove handling of multiple AEN requests)
  	queue_work(nvme_wq, &ctrl->async_event_work);
  }
  EXPORT_SYMBOL_GPL(nvme_queue_async_events);
diff --cc drivers/nvme/host/fc.c
index 6e7bb75ba7ba,6eb460b117d6..000000000000
--- a/drivers/nvme/host/fc.c
+++ b/drivers/nvme/host/fc.c
@@@ -2375,18 -2349,47 +2375,21 @@@ nvme_fc_queue_rq(struct blk_mq_hw_ctx *
  	return nvme_fc_start_fcp_op(ctrl, queue, op, data_len, io_dir);
  }
  
 -static struct blk_mq_tags *
 -nvme_fc_tagset(struct nvme_fc_queue *queue)
 -{
 -	if (queue->qnum == 0)
 -		return queue->ctrl->admin_tag_set.tags[queue->qnum];
 -
 -	return queue->ctrl->tag_set.tags[queue->qnum - 1];
 -}
 -
 -static int
 -nvme_fc_poll(struct blk_mq_hw_ctx *hctx, unsigned int tag)
 -
 -{
 -	struct nvme_fc_queue *queue = hctx->driver_data;
 -	struct nvme_fc_ctrl *ctrl = queue->ctrl;
 -	struct request *req;
 -	struct nvme_fc_fcp_op *op;
 -
 -	req = blk_mq_tag_to_rq(nvme_fc_tagset(queue), tag);
 -	if (!req)
 -		return 0;
 -
 -	op = blk_mq_rq_to_pdu(req);
 -
 -	if ((atomic_read(&op->state) == FCPOP_STATE_ACTIVE) &&
 -		 (ctrl->lport->ops->poll_queue))
 -		ctrl->lport->ops->poll_queue(&ctrl->lport->localport,
 -						 queue->lldd_handle);
 -
 -	return ((atomic_read(&op->state) != FCPOP_STATE_ACTIVE));
 -}
 -
  static void
- nvme_fc_submit_async_event(struct nvme_ctrl *arg, int aer_idx)
+ nvme_fc_submit_async_event(struct nvme_ctrl *arg)
  {
  	struct nvme_fc_ctrl *ctrl = to_fc_ctrl(arg);
  	struct nvme_fc_fcp_op *aen_op;
  	unsigned long flags;
  	bool terminating = false;
 -	blk_status_t ret;
 +	int ret;
 +
++<<<<<<< HEAD
 +	if (aer_idx > NVME_FC_NR_AEN_COMMANDS)
 +		return;
  
++=======
++>>>>>>> ad22c355b707 (nvme: remove handling of multiple AEN requests)
  	spin_lock_irqsave(&ctrl->lock, flags);
  	if (ctrl->flags & FCCTRL_TERMIO)
  		terminating = true;
diff --cc drivers/nvme/host/nvme.h
index df4c3bd4f65c,b55c97ecea31..000000000000
--- a/drivers/nvme/host/nvme.h
+++ b/drivers/nvme/host/nvme.h
@@@ -143,8 -159,9 +143,7 @@@ struct nvme_ctrl 
  	u16 oncs;
  	u16 vid;
  	u16 oacs;
 -	u16 nssa;
 -	u16 nr_streams;
  	atomic_t abort_limit;
- 	u8 event_limit;
  	u8 vwc;
  	u32 vs;
  	u32 sgls;
@@@ -218,9 -236,10 +217,14 @@@ struct nvme_ctrl_ops 
  	int (*reg_write32)(struct nvme_ctrl *ctrl, u32 off, u32 val);
  	int (*reg_read64)(struct nvme_ctrl *ctrl, u32 off, u64 *val);
  	void (*free_ctrl)(struct nvme_ctrl *ctrl);
++<<<<<<< HEAD
 +	void (*submit_async_event)(struct nvme_ctrl *ctrl, int aer_idx);
 +	int (*delete_ctrl)(struct nvme_ctrl *ctrl);
++=======
+ 	void (*submit_async_event)(struct nvme_ctrl *ctrl);
+ 	void (*delete_ctrl)(struct nvme_ctrl *ctrl);
++>>>>>>> ad22c355b707 (nvme: remove handling of multiple AEN requests)
  	int (*get_address)(struct nvme_ctrl *ctrl, char *buf, int size);
 -	int (*reinit_request)(void *data, struct request *rq);
  };
  
  static inline bool nvme_ctrl_ready(struct nvme_ctrl *ctrl)
diff --cc drivers/nvme/host/pci.c
index 5c9aed0eea84,429d56f1a19e..000000000000
--- a/drivers/nvme/host/pci.c
+++ b/drivers/nvme/host/pci.c
@@@ -808,7 -1010,40 +808,44 @@@ static irqreturn_t nvme_irq_check(int i
  	return IRQ_NONE;
  }
  
++<<<<<<< HEAD
 +static void nvme_pci_submit_async_event(struct nvme_ctrl *ctrl, int aer_idx)
++=======
+ static int __nvme_poll(struct nvme_queue *nvmeq, unsigned int tag)
+ {
+ 	struct nvme_completion cqe;
+ 	int found = 0, consumed = 0;
+ 
+ 	if (!nvme_cqe_valid(nvmeq, nvmeq->cq_head, nvmeq->cq_phase))
+ 		return 0;
+ 
+ 	spin_lock_irq(&nvmeq->q_lock);
+ 	while (nvme_read_cqe(nvmeq, &cqe)) {
+ 		nvme_handle_cqe(nvmeq, &cqe);
+ 		consumed++;
+ 
+ 		if (tag == cqe.command_id) {
+ 			found = 1;
+ 			break;
+ 		}
+        }
+ 
+ 	if (consumed)
+ 		nvme_ring_cq_doorbell(nvmeq);
+ 	spin_unlock_irq(&nvmeq->q_lock);
+ 
+ 	return found;
+ }
+ 
+ static int nvme_poll(struct blk_mq_hw_ctx *hctx, unsigned int tag)
+ {
+ 	struct nvme_queue *nvmeq = hctx->driver_data;
+ 
+ 	return __nvme_poll(nvmeq, tag);
+ }
+ 
+ static void nvme_pci_submit_async_event(struct nvme_ctrl *ctrl)
++>>>>>>> ad22c355b707 (nvme: remove handling of multiple AEN requests)
  {
  	struct nvme_dev *dev = to_nvme_dev(ctrl);
  	struct nvme_queue *nvmeq = dev->queues[0];
@@@ -816,7 -1051,7 +853,11 @@@
  
  	memset(&c, 0, sizeof(c));
  	c.common.opcode = nvme_admin_async_event;
++<<<<<<< HEAD
 +	c.common.command_id = NVME_AQ_BLKMQ_DEPTH + aer_idx;
++=======
+ 	c.common.command_id = NVME_AQ_BLK_MQ_DEPTH;
++>>>>>>> ad22c355b707 (nvme: remove handling of multiple AEN requests)
  
  	spin_lock_irq(&nvmeq->q_lock);
  	__nvme_submit_cmd(nvmeq, &c);
* Unmerged path drivers/nvme/host/core.c
* Unmerged path drivers/nvme/host/fc.c
* Unmerged path drivers/nvme/host/nvme.h
* Unmerged path drivers/nvme/host/pci.c
diff --git a/drivers/nvme/host/rdma.c b/drivers/nvme/host/rdma.c
index 2e9ce2cbb1eb..6b4af519a442 100644
--- a/drivers/nvme/host/rdma.c
+++ b/drivers/nvme/host/rdma.c
@@ -1158,7 +1158,7 @@ static struct blk_mq_tags *nvme_rdma_tagset(struct nvme_rdma_queue *queue)
 	return queue->ctrl->tag_set.tags[queue_idx - 1];
 }
 
-static void nvme_rdma_submit_async_event(struct nvme_ctrl *arg, int aer_idx)
+static void nvme_rdma_submit_async_event(struct nvme_ctrl *arg)
 {
 	struct nvme_rdma_ctrl *ctrl = to_rdma_ctrl(arg);
 	struct nvme_rdma_queue *queue = &ctrl->queues[0];
@@ -1168,9 +1168,6 @@ static void nvme_rdma_submit_async_event(struct nvme_ctrl *arg, int aer_idx)
 	struct ib_sge sge;
 	int ret;
 
-	if (WARN_ON_ONCE(aer_idx != 0))
-		return;
-
 	ib_dma_sync_single_for_cpu(dev, sqe->dma, sizeof(*cmd), DMA_TO_DEVICE);
 
 	memset(cmd, 0, sizeof(*cmd));
diff --git a/drivers/nvme/target/loop.c b/drivers/nvme/target/loop.c
index 21dcbdab74e4..01481808b7bf 100644
--- a/drivers/nvme/target/loop.c
+++ b/drivers/nvme/target/loop.c
@@ -195,7 +195,7 @@ static int nvme_loop_queue_rq(struct blk_mq_hw_ctx *hctx,
 	return BLK_MQ_RQ_QUEUE_OK;
 }
 
-static void nvme_loop_submit_async_event(struct nvme_ctrl *arg, int aer_idx)
+static void nvme_loop_submit_async_event(struct nvme_ctrl *arg)
 {
 	struct nvme_loop_ctrl *ctrl = to_loop_ctrl(arg);
 	struct nvme_loop_queue *queue = &ctrl->queues[0];
