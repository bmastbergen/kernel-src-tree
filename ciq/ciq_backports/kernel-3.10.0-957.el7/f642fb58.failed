x86/platform/UV: Add adjustable set memory block size function

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [kernel] revert "platform/uv: Add adjustable set memory block size function" (Baoquan He) [1625143]
Rebuild_FUZZ: 89.92%
commit-author mike.travis@hpe.com <mike.travis@hpe.com>
commit f642fb5864a6e3645edce6f85ffe7b44d5e9b990
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/f642fb58.failed

Add a new function to "adjust" the current fixed UV memory block size
of 2GB so it can be changed to a different physical boundary.  This is
out of necessity so arch dependent code can accommodate specific BIOS
requirements which can align these new PMEM modules at less than the
default boundaries.

A "set order" type of function was used to insure that the memory block
size will be a power of two value without requiring a validity check.
64GB was chosen as the upper limit for memory block size values to
accommodate upcoming 4PB systems which have 6 more bits of physical
address space (46 becoming 52).

	Signed-off-by: Mike Travis <mike.travis@hpe.com>
	Reviewed-by: Andrew Banman <andrew.banman@hpe.com>
	Cc: Andrew Morton <akpm@linux-foundation.org>
	Cc: Dimitri Sivanich <dimitri.sivanich@hpe.com>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Russ Anderson <russ.anderson@hpe.com>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: dan.j.williams@intel.com
	Cc: jgross@suse.com
	Cc: kirill.shutemov@linux.intel.com
	Cc: mhocko@suse.com
	Cc: stable@vger.kernel.org
Link: https://lkml.kernel.org/lkml/20180524201711.609546602@stormcage.americas.sgi.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit f642fb5864a6e3645edce6f85ffe7b44d5e9b990)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/mm/init_64.c
diff --cc arch/x86/mm/init_64.c
index 604b28222fe1,20d8bf5fbceb..000000000000
--- a/arch/x86/mm/init_64.c
+++ b/arch/x86/mm/init_64.c
@@@ -1173,79 -1341,51 +1173,99 @@@ int kern_addr_valid(unsigned long addr
  }
  
  /*
 - * Block size is the minimum amount of memory which can be hotplugged or
 - * hotremoved. It must be power of two and must be equal or larger than
 - * MIN_MEMORY_BLOCK_SIZE.
 + * A pseudo VMA to allow ptrace access for the vsyscall page.  This only
 + * covers the 64bit vsyscall page now. 32bit has a real VMA now and does
 + * not need special handling anymore:
   */
 -#define MAX_BLOCK_SIZE (2UL << 30)
 +static struct vm_area_struct gate_vma = {
 +	.vm_start	= VSYSCALL_START,
 +	.vm_end		= VSYSCALL_START + (VSYSCALL_MAPPED_PAGES * PAGE_SIZE),
 +	.vm_page_prot	= PAGE_READONLY_EXEC,
 +	.vm_flags	= VM_READ | VM_EXEC
 +};
 +
 +struct vm_area_struct *get_gate_vma(struct mm_struct *mm)
 +{
 +#ifdef CONFIG_IA32_EMULATION
 +	if (!mm || mm->context.ia32_compat)
 +		return NULL;
 +#endif
 +	return &gate_vma;
 +}
  
 -/* Amount of ram needed to start using large blocks */
 -#define MEM_SIZE_FOR_LARGE_BLOCK (64UL << 30)
 +int in_gate_area(struct mm_struct *mm, unsigned long addr)
 +{
 +	struct vm_area_struct *vma = get_gate_vma(mm);
 +
 +	if (!vma)
 +		return 0;
 +
 +	return (addr >= vma->vm_start) && (addr < vma->vm_end);
 +}
 +
 +/*
 + * Use this when you have no reliable mm, typically from interrupt
 + * context. It is less reliable than using a task's mm and may give
 + * false positives.
 + */
 +int in_gate_area_no_mm(unsigned long addr)
 +{
 +	return (addr >= VSYSCALL_START) && (addr < VSYSCALL_END);
 +}
 +
 +const char *arch_vma_name(struct vm_area_struct *vma)
 +{
 +	if (vma->vm_mm && vma->vm_start == (long)vma->vm_mm->context.vdso)
 +		return "[vdso]";
 +	if (vma == &gate_vma)
 +		return "[vsyscall]";
 +	return NULL;
 +}
  
+ /* Adjustable memory block size */
+ static unsigned long set_memory_block_size;
+ int __init set_memory_block_size_order(unsigned int order)
+ {
+ 	unsigned long size = 1UL << order;
+ 
+ 	if (size > MEM_SIZE_FOR_LARGE_BLOCK || size < MIN_MEMORY_BLOCK_SIZE)
+ 		return -EINVAL;
+ 
+ 	set_memory_block_size = size;
+ 	return 0;
+ }
+ 
  static unsigned long probe_memory_block_size(void)
  {
 -	unsigned long boot_mem_end = max_pfn << PAGE_SHIFT;
 -	unsigned long bz;
 -
 +	/* start from 2g */
 +	unsigned long bz = 1UL<<31;
 +
++<<<<<<< HEAD
 +#ifdef CONFIG_X86_UV
 +	if (is_uv_system()) {
 +		printk(KERN_INFO "UV: memory block size 2GB\n");
 +		return 2UL * 1024 * 1024 * 1024;
 +	}
 +#endif
++=======
+ 	/* If memory block size has been set, then use it */
+ 	bz = set_memory_block_size;
+ 	if (bz)
+ 		goto done;
++>>>>>>> f642fb5864a6 (x86/platform/UV: Add adjustable set memory block size function)
  
 -	/* Use regular block if RAM is smaller than MEM_SIZE_FOR_LARGE_BLOCK */
 -	if (boot_mem_end < MEM_SIZE_FOR_LARGE_BLOCK) {
 -		bz = MIN_MEMORY_BLOCK_SIZE;
 -		goto done;
 -	}
 +	/* less than 64g installed */
 +	if ((max_pfn << PAGE_SHIFT) < (16UL << 32))
 +		return MIN_MEMORY_BLOCK_SIZE;
  
 -	/* Find the largest allowed block size that aligns to memory end */
 -	for (bz = MAX_BLOCK_SIZE; bz > MIN_MEMORY_BLOCK_SIZE; bz >>= 1) {
 -		if (IS_ALIGNED(boot_mem_end, bz))
 +	/* get the tail size */
 +	while (bz > MIN_MEMORY_BLOCK_SIZE) {
 +		if (!((max_pfn << PAGE_SHIFT) & (bz - 1)))
  			break;
 +		bz >>= 1;
  	}
 -done:
 -	pr_info("x86/mm: Memory block size: %ldMB\n", bz >> 20);
 +
 +	printk(KERN_DEBUG "memory block size : %ldMB\n", bz >> 20);
  
  	return bz;
  }
* Unmerged path arch/x86/mm/init_64.c
diff --git a/include/linux/memory.h b/include/linux/memory.h
index 8b8d8d12348e..241d62998b4d 100644
--- a/include/linux/memory.h
+++ b/include/linux/memory.h
@@ -36,6 +36,7 @@ struct memory_block {
 
 int arch_get_memory_phys_device(unsigned long start_pfn);
 unsigned long memory_block_size_bytes(void);
+int set_memory_block_size_order(unsigned int order);
 
 /* These states are exposed to userspace as text strings in sysfs */
 #define	MEM_ONLINE		(1<<0) /* exposed to userspace */
