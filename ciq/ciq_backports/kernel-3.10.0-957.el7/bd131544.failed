x86/asm/memcpy_mcsafe: Add labels for __memcpy_mcsafe() write fault handling

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [x86] asm/memcpy_mcsafe: Add labels for __memcpy_mcsafe() write fault handling (Jeff Moyer) [1608674]
Rebuild_FUZZ: 97.30%
commit-author Dan Williams <dan.j.williams@intel.com>
commit bd131544aa7e318a5735cbcbad46c4a5ee6b9d42
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/bd131544.failed

The memcpy_mcsafe() implementation handles CPU exceptions when reading
from the source address. Before it can be used for user copies it needs
to grow support for handling write faults. In preparation for adding
that exception handling update the labels for the read cache word X case
(.L_cache_rX) and write cache word X case (.L_cache_wX).

	Reported-by: Tony Luck <tony.luck@intel.com>
	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
	Cc: Al Viro <viro@zeniv.linux.org.uk>
	Cc: Andrew Morton <akpm@linux-foundation.org>
	Cc: Andy Lutomirski <luto@amacapital.net>
	Cc: Borislav Petkov <bp@alien8.de>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: hch@lst.de
	Cc: linux-fsdevel@vger.kernel.org
	Cc: linux-nvdimm@lists.01.org
Link: http://lkml.kernel.org/r/152539237606.31796.6719743548991782264.stgit@dwillia2-desk3.amr.corp.intel.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit bd131544aa7e318a5735cbcbad46c4a5ee6b9d42)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/lib/memcpy_64.S
diff --cc arch/x86/lib/memcpy_64.S
index 36b962df086c,5709f3ec22a4..000000000000
--- a/arch/x86/lib/memcpy_64.S
+++ b/arch/x86/lib/memcpy_64.S
@@@ -233,52 -211,22 +234,63 @@@ ENTRY(memcpy_mcsafe_unrolled
  	incq %rsi
  	incq %rdi
  	decl %ecx
- 	jnz .L_copy_leading_bytes
+ 	jnz .L_read_leading_bytes
  
  .L_8byte_aligned:
 +	/* Figure out how many whole cache lines (64-bytes) to copy */
 +	movl %edx, %ecx
 +	andl $63, %edx
 +	shrl $6, %ecx
 +	jz .L_no_whole_cache_lines
 +
 +	/* Loop copying whole cache lines */
 +.L_cache_w0: movq (%rsi), %r8
 +.L_cache_w1: movq 1*8(%rsi), %r9
 +.L_cache_w2: movq 2*8(%rsi), %r10
 +.L_cache_w3: movq 3*8(%rsi), %r11
 +	movq %r8, (%rdi)
 +	movq %r9, 1*8(%rdi)
 +	movq %r10, 2*8(%rdi)
 +	movq %r11, 3*8(%rdi)
 +.L_cache_w4: movq 4*8(%rsi), %r8
 +.L_cache_w5: movq 5*8(%rsi), %r9
 +.L_cache_w6: movq 6*8(%rsi), %r10
 +.L_cache_w7: movq 7*8(%rsi), %r11
 +	movq %r8, 4*8(%rdi)
 +	movq %r9, 5*8(%rdi)
 +	movq %r10, 6*8(%rdi)
 +	movq %r11, 7*8(%rdi)
 +	leaq 64(%rsi), %rsi
 +	leaq 64(%rdi), %rdi
 +	decl %ecx
 +	jnz .L_cache_w0
 +
 +	/* Are there any trailing 8-byte words? */
 +.L_no_whole_cache_lines:
  	movl %edx, %ecx
  	andl $7, %edx
  	shrl $3, %ecx
  	jz .L_no_whole_words
  
++<<<<<<< HEAD
 +	/* Copy trailing words */
 +.L_copy_trailing_words:
 +	movq (%rsi), %r8
 +	mov %r8, (%rdi)
 +	leaq 8(%rsi), %rsi
 +	leaq 8(%rdi), %rdi
 +	decl %ecx
 +	jnz .L_copy_trailing_words
++=======
+ .L_read_words:
+ 	movq (%rsi), %r8
+ .L_write_words:
+ 	movq %r8, (%rdi)
+ 	addq $8, %rsi
+ 	addq $8, %rdi
+ 	decl %ecx
+ 	jnz .L_read_words
++>>>>>>> bd131544aa7e (x86/asm/memcpy_mcsafe: Add labels for __memcpy_mcsafe() write fault handling)
  
  	/* Any trailing bytes? */
  .L_no_whole_words:
@@@ -309,15 -259,7 +322,21 @@@ ENDPROC(memcpy_mcsafe_unrolled
  
  	.previous
  
++<<<<<<< HEAD
 +	_ASM_EXTABLE_FAULT(.L_copy_leading_bytes, .L_memcpy_mcsafe_fail)
 +	_ASM_EXTABLE_FAULT(.L_cache_w0, .L_memcpy_mcsafe_fail)
 +	_ASM_EXTABLE_FAULT(.L_cache_w1, .L_memcpy_mcsafe_fail)
 +	_ASM_EXTABLE_FAULT(.L_cache_w2, .L_memcpy_mcsafe_fail)
 +	_ASM_EXTABLE_FAULT(.L_cache_w3, .L_memcpy_mcsafe_fail)
 +	_ASM_EXTABLE_FAULT(.L_cache_w4, .L_memcpy_mcsafe_fail)
 +	_ASM_EXTABLE_FAULT(.L_cache_w5, .L_memcpy_mcsafe_fail)
 +	_ASM_EXTABLE_FAULT(.L_cache_w6, .L_memcpy_mcsafe_fail)
 +	_ASM_EXTABLE_FAULT(.L_cache_w7, .L_memcpy_mcsafe_fail)
 +	_ASM_EXTABLE_FAULT(.L_copy_trailing_words, .L_memcpy_mcsafe_fail)
 +	_ASM_EXTABLE_FAULT(.L_copy_trailing_bytes, .L_memcpy_mcsafe_fail)
++=======
+ 	_ASM_EXTABLE_FAULT(.L_read_leading_bytes, .L_memcpy_mcsafe_fail)
+ 	_ASM_EXTABLE_FAULT(.L_read_words, .L_memcpy_mcsafe_fail)
+ 	_ASM_EXTABLE_FAULT(.L_read_trailing_bytes, .L_memcpy_mcsafe_fail)
++>>>>>>> bd131544aa7e (x86/asm/memcpy_mcsafe: Add labels for __memcpy_mcsafe() write fault handling)
  #endif
* Unmerged path arch/x86/lib/memcpy_64.S
