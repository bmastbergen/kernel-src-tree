RDMA/umem: Avoid partial declaration of non-static function

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [rdma] umem: Avoid partial declaration of non-static function (Don Dutile) [1549856]
Rebuild_FUZZ: 95.58%
commit-author Leon Romanovsky <leonro@mellanox.com>
commit fec99ededf6be46178d7f571b34dae80fc05f090
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/fec99ede.failed

The RDMA/umem uses generic RB-trees macros to generate various ib_umem
access functions. The generation is performed with INTERVAL_TREE_DEFINE
macro, which allows one of two modes: declare all functions as static or
declare none of the function to be static.

The second mode of operation produces the following sparse errors:
 drivers/infiniband/core/umem_rbtree.c:69:1:
	warning: symbol 'rbt_ib_umem_iter_first' was not declared.
	Should it be static?
 drivers/infiniband/core/umem_rbtree.c:69:1:
	warning: symbol 'rbt_ib_umem_iter_next' was not declared.
	Should it be static?

Code relocation together with declaration of such functions to be
"static" solves the issue.

Because there is no need to have separate file for two functions,
let's consolidate umem_rtree.c and umem_odp.c into one file.

	Signed-off-by: Leon Romanovsky <leonro@mellanox.com>
	Signed-off-by: Doug Ledford <dledford@redhat.com>
(cherry picked from commit fec99ededf6be46178d7f571b34dae80fc05f090)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/Makefile
#	drivers/infiniband/core/umem_rbtree.c
#	include/rdma/ib_umem_odp.h
diff --cc drivers/infiniband/core/Makefile
index 462096e20c22,336ace50b0ab..000000000000
--- a/drivers/infiniband/core/Makefile
+++ b/drivers/infiniband/core/Makefile
@@@ -14,7 -14,8 +14,12 @@@ ib_core-y :=			packer.o ud_header.o ver
  				security.o nldev.o
  
  ib_core-$(CONFIG_INFINIBAND_USER_MEM) += umem.o
++<<<<<<< HEAD
 +ib_core-$(CONFIG_INFINIBAND_ON_DEMAND_PAGING) += umem_odp.o umem_rbtree.o
++=======
+ ib_core-$(CONFIG_INFINIBAND_ON_DEMAND_PAGING) += umem_odp.o
+ ib_core-$(CONFIG_CGROUP_RDMA) += cgroup.o
++>>>>>>> fec99ededf6b (RDMA/umem: Avoid partial declaration of non-static function)
  
  ib_cm-y :=			cm.o
  
diff --cc include/rdma/ib_umem_odp.h
index fb67554aabd6,6a17f856f841..000000000000
--- a/include/rdma/ib_umem_odp.h
+++ b/include/rdma/ib_umem_odp.h
@@@ -111,8 -111,6 +111,11 @@@ int ib_umem_odp_map_dma_pages(struct ib
  void ib_umem_odp_unmap_dma_pages(struct ib_umem *umem, u64 start_offset,
  				 u64 bound);
  
++<<<<<<< HEAD
 +void rbt_ib_umem_insert(struct umem_odp_node *node, struct rb_root *root);
 +void rbt_ib_umem_remove(struct umem_odp_node *node, struct rb_root *root);
++=======
++>>>>>>> fec99ededf6b (RDMA/umem: Avoid partial declaration of non-static function)
  typedef int (*umem_call_back)(struct ib_umem *item, u64 start, u64 end,
  			      void *cookie);
  /*
* Unmerged path drivers/infiniband/core/umem_rbtree.c
* Unmerged path drivers/infiniband/core/Makefile
diff --git a/drivers/infiniband/core/umem_odp.c b/drivers/infiniband/core/umem_odp.c
index 599824eed65c..d9f1a20dde1c 100644
--- a/drivers/infiniband/core/umem_odp.c
+++ b/drivers/infiniband/core/umem_odp.c
@@ -37,11 +37,44 @@
 #include <linux/export.h>
 #include <linux/vmalloc.h>
 #include <linux/hugetlb.h>
+#include <linux/interval_tree_generic.h>
 
 #include <rdma/ib_verbs.h>
 #include <rdma/ib_umem.h>
 #include <rdma/ib_umem_odp.h>
 
+/*
+ * The ib_umem list keeps track of memory regions for which the HW
+ * device request to receive notification when the related memory
+ * mapping is changed.
+ *
+ * ib_umem_lock protects the list.
+ */
+
+static u64 node_start(struct umem_odp_node *n)
+{
+	struct ib_umem_odp *umem_odp =
+			container_of(n, struct ib_umem_odp, interval_tree);
+
+	return ib_umem_start(umem_odp->umem);
+}
+
+/* Note that the representation of the intervals in the interval tree
+ * considers the ending point as contained in the interval, while the
+ * function ib_umem_end returns the first address which is not contained
+ * in the umem.
+ */
+static u64 node_last(struct umem_odp_node *n)
+{
+	struct ib_umem_odp *umem_odp =
+			container_of(n, struct ib_umem_odp, interval_tree);
+
+	return ib_umem_end(umem_odp->umem) - 1;
+}
+
+INTERVAL_TREE_DEFINE(struct umem_odp_node, rb, u64, __subtree_last,
+		     node_start, node_last, static, rbt_ib_umem)
+
 static void ib_umem_notifier_start_account(struct ib_umem *item)
 {
 	mutex_lock(&item->odp_data->umem_mutex);
@@ -749,3 +782,42 @@ void ib_umem_odp_unmap_dma_pages(struct ib_umem *umem, u64 virt,
 	mutex_unlock(&umem->odp_data->umem_mutex);
 }
 EXPORT_SYMBOL(ib_umem_odp_unmap_dma_pages);
+
+/* @last is not a part of the interval. See comment for function
+ * node_last.
+ */
+int rbt_ib_umem_for_each_in_range(struct rb_root_cached *root,
+				  u64 start, u64 last,
+				  umem_call_back cb,
+				  void *cookie)
+{
+	int ret_val = 0;
+	struct umem_odp_node *node, *next;
+	struct ib_umem_odp *umem;
+
+	if (unlikely(start == last))
+		return ret_val;
+
+	for (node = rbt_ib_umem_iter_first(root, start, last - 1);
+			node; node = next) {
+		next = rbt_ib_umem_iter_next(node, start, last - 1);
+		umem = container_of(node, struct ib_umem_odp, interval_tree);
+		ret_val = cb(umem->umem, start, last, cookie) || ret_val;
+	}
+
+	return ret_val;
+}
+EXPORT_SYMBOL(rbt_ib_umem_for_each_in_range);
+
+struct ib_umem_odp *rbt_ib_umem_lookup(struct rb_root_cached *root,
+				       u64 addr, u64 length)
+{
+	struct umem_odp_node *node;
+
+	node = rbt_ib_umem_iter_first(root, addr, addr + length - 1);
+	if (node)
+		return container_of(node, struct ib_umem_odp, interval_tree);
+	return NULL;
+
+}
+EXPORT_SYMBOL(rbt_ib_umem_lookup);
* Unmerged path drivers/infiniband/core/umem_rbtree.c
* Unmerged path include/rdma/ib_umem_odp.h
