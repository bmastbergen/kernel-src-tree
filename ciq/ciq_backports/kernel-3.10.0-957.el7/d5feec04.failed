s390: do not bypass BPENTER for interrupt system calls

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [s390] do not bypass BPENTER for interrupt system calls (Hendrik Brueckner) [1558325]
Rebuild_FUZZ: 94.12%
commit-author Martin Schwidefsky <schwidefsky@de.ibm.com>
commit d5feec04fe578c8dbd9e2e1439afc2f0af761ed4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/d5feec04.failed

The system call path can be interrupted before the switch back to the
standard branch prediction with BPENTER has been done. The critical
section cleanup code skips forward to .Lsysc_do_svc and bypasses the
BPENTER. In this case the kernel and all subsequent code will run with
the limited branch prediction.

Fixes: eacf67eb9b32 ("s390: run user space and KVM guests with modified branch prediction")
	Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
(cherry picked from commit d5feec04fe578c8dbd9e2e1439afc2f0af761ed4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/s390/kernel/entry.S
diff --cc arch/s390/kernel/entry.S
index be8edbeb24eb,73492461c454..000000000000
--- a/arch/s390/kernel/entry.S
+++ b/arch/s390/kernel/entry.S
@@@ -780,141 -1320,199 +780,147 @@@ ENTRY(restart_int_handler
   * Setup a pt_regs so that show_trace can provide a good call trace.
   */
  stack_overflow:
 -	lg	%r15,__LC_PANIC_STACK	# change to panic stack
 +	l	%r15,__LC_PANIC_STACK	# change to panic stack
  	la	%r11,STACK_FRAME_OVERHEAD(%r15)
 -	stmg	%r0,%r7,__PT_R0(%r11)
 -	stmg	%r8,%r9,__PT_PSW(%r11)
 -	mvc	__PT_R8(64,%r11),0(%r14)
 -	stg	%r10,__PT_ORIG_GPR2(%r11) # store last break to orig_gpr2
 -	xc	__SF_BACKCHAIN(8,%r15),__SF_BACKCHAIN(%r15)
 -	lgr	%r2,%r11		# pass pointer to pt_regs
 -	jg	kernel_stack_overflow
 +	stm	%r0,%r7,__PT_R0(%r11)
 +	stm	%r8,%r9,__PT_PSW(%r11)
 +	mvc	__PT_R8(32,%r11),0(%r14)
 +	l	%r1,BASED(1f)
 +	xc	__SF_BACKCHAIN(4,%r15),__SF_BACKCHAIN(%r15)
 +	lr	%r2,%r11		# pass pointer to pt_regs
 +	br	%r1			# branch to kernel_stack_overflow
 +1:	.long	kernel_stack_overflow
  #endif
  
 +cleanup_table:
 +	.long	system_call + 0x80000000
 +	.long	sysc_do_svc + 0x80000000
 +	.long	sysc_tif + 0x80000000
 +	.long	sysc_restore + 0x80000000
 +	.long	sysc_done + 0x80000000
 +	.long	io_tif + 0x80000000
 +	.long	io_restore + 0x80000000
 +	.long	io_done + 0x80000000
 +	.long	psw_idle + 0x80000000
 +	.long	psw_idle_end + 0x80000000
 +
  cleanup_critical:
 -#if IS_ENABLED(CONFIG_KVM)
 -	clg	%r9,BASED(.Lcleanup_table_sie)	# .Lsie_gmap
 -	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table_sie+8)# .Lsie_done
 -	jl	.Lcleanup_sie
 -#endif
 -	clg	%r9,BASED(.Lcleanup_table)	# system_call
 -	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table+8)	# .Lsysc_do_svc
 -	jl	.Lcleanup_system_call
 -	clg	%r9,BASED(.Lcleanup_table+16)	# .Lsysc_tif
 +	cl	%r9,BASED(cleanup_table)	# system_call
  	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table+24)	# .Lsysc_restore
 -	jl	.Lcleanup_sysc_tif
 -	clg	%r9,BASED(.Lcleanup_table+32)	# .Lsysc_done
 -	jl	.Lcleanup_sysc_restore
 -	clg	%r9,BASED(.Lcleanup_table+40)	# .Lio_tif
 +	cl	%r9,BASED(cleanup_table+4)	# sysc_do_svc
 +	jl	cleanup_system_call
 +	cl	%r9,BASED(cleanup_table+8)	# sysc_tif
  	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table+48)	# .Lio_restore
 -	jl	.Lcleanup_io_tif
 -	clg	%r9,BASED(.Lcleanup_table+56)	# .Lio_done
 -	jl	.Lcleanup_io_restore
 -	clg	%r9,BASED(.Lcleanup_table+64)	# psw_idle
 +	cl	%r9,BASED(cleanup_table+12)	# sysc_restore
 +	jl	cleanup_sysc_tif
 +	cl	%r9,BASED(cleanup_table+16)	# sysc_done
 +	jl	cleanup_sysc_restore
 +	cl	%r9,BASED(cleanup_table+20)	# io_tif
  	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table+72)	# .Lpsw_idle_end
 -	jl	.Lcleanup_idle
 -	clg	%r9,BASED(.Lcleanup_table+80)	# save_fpu_regs
 +	cl	%r9,BASED(cleanup_table+24)	# io_restore
 +	jl	cleanup_io_tif
 +	cl	%r9,BASED(cleanup_table+28)	# io_done
 +	jl	cleanup_io_restore
 +	cl	%r9,BASED(cleanup_table+32)	# psw_idle
  	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table+88)	# .Lsave_fpu_regs_end
 -	jl	.Lcleanup_save_fpu_regs
 -	clg	%r9,BASED(.Lcleanup_table+96)	# load_fpu_regs
 -	jl	0f
 -	clg	%r9,BASED(.Lcleanup_table+104)	# .Lload_fpu_regs_end
 -	jl	.Lcleanup_load_fpu_regs
 -0:	BR_R11USE_R14
 -
 -	.align	8
 -.Lcleanup_table:
 -	.quad	system_call
 -	.quad	.Lsysc_do_svc
 -	.quad	.Lsysc_tif
 -	.quad	.Lsysc_restore
 -	.quad	.Lsysc_done
 -	.quad	.Lio_tif
 -	.quad	.Lio_restore
 -	.quad	.Lio_done
 -	.quad	psw_idle
 -	.quad	.Lpsw_idle_end
 -	.quad	save_fpu_regs
 -	.quad	.Lsave_fpu_regs_end
 -	.quad	load_fpu_regs
 -	.quad	.Lload_fpu_regs_end
 -
 -#if IS_ENABLED(CONFIG_KVM)
 -.Lcleanup_table_sie:
 -	.quad	.Lsie_gmap
 -	.quad	.Lsie_done
 -
 -.Lcleanup_sie:
 -	cghi    %r11,__LC_SAVE_AREA_ASYNC 	#Is this in normal interrupt?
 -	je      1f
 -	slg     %r9,BASED(.Lsie_crit_mcck_start)
 -	clg     %r9,BASED(.Lsie_crit_mcck_length)
 -	jh      1f
 -	oi      __LC_CPU_FLAGS+7, _CIF_MCCK_GUEST
 -1:	BPENTER __SF_EMPTY+24(%r15),(_TIF_ISOLATE_BP|_TIF_ISOLATE_BP_GUEST)
 -	lg	%r9,__SF_EMPTY(%r15)		# get control block pointer
 -	ni	__SIE_PROG0C+3(%r9),0xfe	# no longer in SIE
 -	lctlg	%c1,%c1,__LC_USER_ASCE		# load primary asce
 -	larl	%r9,sie_exit			# skip forward to sie_exit
 -	BR_R11USE_R14
 -#endif
 +	cl	%r9,BASED(cleanup_table+36)	# psw_idle_end
 +	jl	cleanup_idle
 +0:	br	%r14
  
 -.Lcleanup_system_call:
 +cleanup_system_call:
  	# check if stpt has been executed
 -	clg	%r9,BASED(.Lcleanup_system_call_insn)
 +	cl	%r9,BASED(cleanup_system_call_insn)
  	jh	0f
  	mvc	__LC_SYNC_ENTER_TIMER(8),__LC_ASYNC_ENTER_TIMER
 -	cghi	%r11,__LC_SAVE_AREA_ASYNC
 +	chi	%r11,__LC_SAVE_AREA_ASYNC
  	je	0f
  	mvc	__LC_SYNC_ENTER_TIMER(8),__LC_MCCK_ENTER_TIMER
 -0:	# check if stmg has been executed
 -	clg	%r9,BASED(.Lcleanup_system_call_insn+8)
 +0:	# check if stm has been executed
 +	cl	%r9,BASED(cleanup_system_call_insn+4)
  	jh	0f
 -	mvc	__LC_SAVE_AREA_SYNC(64),0(%r11)
 -0:	# check if base register setup + TIF bit load has been done
 -	clg	%r9,BASED(.Lcleanup_system_call_insn+16)
 -	jhe	0f
 -	# set up saved register r12 task struct pointer
 -	stg	%r12,32(%r11)
 -	# set up saved register r13 __TASK_thread offset
 -	mvc	40(8,%r11),BASED(.Lcleanup_system_call_const)
 -0:	# check if the user time update has been done
 -	clg	%r9,BASED(.Lcleanup_system_call_insn+24)
 +	mvc	__LC_SAVE_AREA_SYNC(32),0(%r11)
 +0:	# set up saved registers r12, and r13
 +	st	%r12,16(%r11)		# r12 thread-info pointer
 +	st	%r13,20(%r11)		# r13 literal-pool pointer
 +	# check if the user time calculation has been done
 +	cl	%r9,BASED(cleanup_system_call_insn+8)
  	jh	0f
 -	lg	%r15,__LC_EXIT_TIMER
 -	slg	%r15,__LC_SYNC_ENTER_TIMER
 -	alg	%r15,__LC_USER_TIMER
 -	stg	%r15,__LC_USER_TIMER
 -0:	# check if the system time update has been done
 -	clg	%r9,BASED(.Lcleanup_system_call_insn+32)
 +	l	%r10,__LC_EXIT_TIMER
 +	l	%r15,__LC_EXIT_TIMER+4
 +	SUB64	%r10,%r15,__LC_SYNC_ENTER_TIMER
 +	ADD64	%r10,%r15,__LC_USER_TIMER
 +	st	%r10,__LC_USER_TIMER
 +	st	%r15,__LC_USER_TIMER+4
 +0:	# check if the system time calculation has been done
 +	cl	%r9,BASED(cleanup_system_call_insn+12)
  	jh	0f
 -	lg	%r15,__LC_LAST_UPDATE_TIMER
 -	slg	%r15,__LC_EXIT_TIMER
 -	alg	%r15,__LC_SYSTEM_TIMER
 -	stg	%r15,__LC_SYSTEM_TIMER
 +	l	%r10,__LC_LAST_UPDATE_TIMER
 +	l	%r15,__LC_LAST_UPDATE_TIMER+4
 +	SUB64	%r10,%r15,__LC_EXIT_TIMER
 +	ADD64	%r10,%r15,__LC_SYSTEM_TIMER
 +	st	%r10,__LC_SYSTEM_TIMER
 +	st	%r15,__LC_SYSTEM_TIMER+4
  0:	# update accounting time stamp
  	mvc	__LC_LAST_UPDATE_TIMER(8),__LC_SYNC_ENTER_TIMER
++<<<<<<< HEAD
 +	# set up saved register 11
 +	l	%r15,__LC_KERNEL_STACK
++=======
+ 	BPENTER __TI_flags(%r12),_TIF_ISOLATE_BP
+ 	# set up saved register r11
+ 	lg	%r15,__LC_KERNEL_STACK
++>>>>>>> d5feec04fe57 (s390: do not bypass BPENTER for interrupt system calls)
  	la	%r9,STACK_FRAME_OVERHEAD(%r15)
 -	stg	%r9,24(%r11)		# r11 pt_regs pointer
 +	st	%r9,12(%r11)		# r11 pt_regs pointer
  	# fill pt_regs
 -	mvc	__PT_R8(64,%r9),__LC_SAVE_AREA_SYNC
 -	stmg	%r0,%r7,__PT_R0(%r9)
 -	mvc	__PT_PSW(16,%r9),__LC_SVC_OLD_PSW
 +	mvc	__PT_R8(32,%r9),__LC_SAVE_AREA_SYNC
 +	stm	%r0,%r7,__PT_R0(%r9)
 +	mvc	__PT_PSW(8,%r9),__LC_SVC_OLD_PSW
  	mvc	__PT_INT_CODE(4,%r9),__LC_SVC_ILC
 -	xc	__PT_FLAGS(8,%r9),__PT_FLAGS(%r9)
 -	mvi	__PT_FLAGS+7(%r9),_PIF_SYSCALL
 -	# setup saved register r15
 -	stg	%r15,56(%r11)		# r15 stack pointer
 +	# setup saved register 15
 +	st	%r15,28(%r11)		# r15 stack pointer
  	# set new psw address and exit
 -	larl	%r9,.Lsysc_do_svc
 -	BR_R11USE_R14
 -.Lcleanup_system_call_insn:
 -	.quad	system_call
 -	.quad	.Lsysc_stmg
 -	.quad	.Lsysc_per
 -	.quad	.Lsysc_vtime+36
 -	.quad	.Lsysc_vtime+42
 -.Lcleanup_system_call_const:
 -	.quad	__TASK_thread
 -
 -.Lcleanup_sysc_tif:
 -	larl	%r9,.Lsysc_tif
 -	BR_R11USE_R14
 -
 -.Lcleanup_sysc_restore:
 -	# check if stpt has been executed
 -	clg	%r9,BASED(.Lcleanup_sysc_restore_insn)
 -	jh	0f
 -	mvc	__LC_EXIT_TIMER(8),__LC_ASYNC_ENTER_TIMER
 -	cghi	%r11,__LC_SAVE_AREA_ASYNC
 -	je	0f
 -	mvc	__LC_EXIT_TIMER(8),__LC_MCCK_ENTER_TIMER
 -0:	clg	%r9,BASED(.Lcleanup_sysc_restore_insn+8)
 -	je	1f
 -	lg	%r9,24(%r11)		# get saved pointer to pt_regs
 -	mvc	__LC_RETURN_PSW(16),__PT_PSW(%r9)
 -	mvc	0(64,%r11),__PT_R8(%r9)
 -	lmg	%r0,%r7,__PT_R0(%r9)
 -1:	lmg	%r8,%r9,__LC_RETURN_PSW
 -	BR_R11USE_R14
 -.Lcleanup_sysc_restore_insn:
 -	.quad	.Lsysc_exit_timer
 -	.quad	.Lsysc_done - 4
 -
 -.Lcleanup_io_tif:
 -	larl	%r9,.Lio_tif
 -	BR_R11USE_R14
 -
 -.Lcleanup_io_restore:
 -	# check if stpt has been executed
 -	clg	%r9,BASED(.Lcleanup_io_restore_insn)
 -	jh	0f
 -	mvc	__LC_EXIT_TIMER(8),__LC_MCCK_ENTER_TIMER
 -0:	clg	%r9,BASED(.Lcleanup_io_restore_insn+8)
 -	je	1f
 -	lg	%r9,24(%r11)		# get saved r11 pointer to pt_regs
 -	mvc	__LC_RETURN_PSW(16),__PT_PSW(%r9)
 -	mvc	0(64,%r11),__PT_R8(%r9)
 -	lmg	%r0,%r7,__PT_R0(%r9)
 -1:	lmg	%r8,%r9,__LC_RETURN_PSW
 -	BR_R11USE_R14
 -.Lcleanup_io_restore_insn:
 -	.quad	.Lio_exit_timer
 -	.quad	.Lio_done - 4
 -
 -.Lcleanup_idle:
 -	ni	__LC_CPU_FLAGS+7,255-_CIF_ENABLED_WAIT
 +	l	%r9,BASED(cleanup_table+4)	# sysc_do_svc + 0x80000000
 +	br	%r14
 +cleanup_system_call_insn:
 +	.long	system_call + 0x80000000
 +	.long	sysc_stm + 0x80000000
 +	.long	sysc_vtime + 0x80000000 + 36
 +	.long	sysc_vtime + 0x80000000 + 76
 +
 +cleanup_sysc_tif:
 +	l	%r9,BASED(cleanup_table+8)	# sysc_tif + 0x80000000
 +	br	%r14
 +
 +cleanup_sysc_restore:
 +	cl	%r9,BASED(cleanup_sysc_restore_insn)
 +	jhe	0f
 +	l	%r9,12(%r11)		# get saved pointer to pt_regs
 +	mvc	__LC_RETURN_PSW(8),__PT_PSW(%r9)
 +	mvc	0(32,%r11),__PT_R8(%r9)
 +	lm	%r0,%r7,__PT_R0(%r9)
 +0:	lm	%r8,%r9,__LC_RETURN_PSW
 +	br	%r14
 +cleanup_sysc_restore_insn:
 +	.long	sysc_done - 4 + 0x80000000
 +
 +cleanup_io_tif:
 +	l	%r9,BASED(cleanup_table+20)	# io_tif + 0x80000000
 +	br	%r14
 +
 +cleanup_io_restore:
 +	cl	%r9,BASED(cleanup_io_restore_insn)
 +	jhe	0f
 +	l	%r9,12(%r11)		# get saved r11 pointer to pt_regs
 +	mvc	__LC_RETURN_PSW(8),__PT_PSW(%r9)
 +	mvc	0(32,%r11),__PT_R8(%r9)
 +	lm	%r0,%r7,__PT_R0(%r9)
 +0:	lm	%r8,%r9,__LC_RETURN_PSW
 +	br	%r14
 +cleanup_io_restore_insn:
 +	.long	io_done - 4 + 0x80000000
 +
 +cleanup_idle:
  	# copy interrupt clock & cpu timer
  	mvc	__CLOCK_IDLE_EXIT(8,%r2),__LC_INT_CLOCK
  	mvc	__TIMER_IDLE_EXIT(8,%r2),__LC_ASYNC_ENTER_TIMER
* Unmerged path arch/s390/kernel/entry.S
