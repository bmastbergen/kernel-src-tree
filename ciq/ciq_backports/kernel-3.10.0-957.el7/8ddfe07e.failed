mmc: block: Use local var for mqrq_cur

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [mmc] block: Use local var for mqrq_cur (Gopal Tiwari) [1549495]
Rebuild_FUZZ: 92.96%
commit-author Adrian Hunter <adrian.hunter@intel.com>
commit 8ddfe07e18c9c82f7567d3cfbd68d8b59764d015
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/8ddfe07e.failed

A subsequent patch will remove 'mq->mqrq_cur'. Prepare for that by
assigning it to a local variable.

	Signed-off-by: Adrian Hunter <adrian.hunter@intel.com>
	Reviewed-by: Linus Walleij <linus.walleij@linaro.org>
	Signed-off-by: Ulf Hansson <ulf.hansson@linaro.org>
(cherry picked from commit 8ddfe07e18c9c82f7567d3cfbd68d8b59764d015)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/mmc/core/block.c
diff --cc drivers/mmc/core/block.c
index 49dc294d6eb1,d317e5e9b79a..000000000000
--- a/drivers/mmc/core/block.c
+++ b/drivers/mmc/core/block.c
@@@ -1574,46 -1575,80 +1574,87 @@@ static int mmc_blk_cmd_err(struct mmc_b
  		int err;
  
  		err = mmc_sd_num_wr_blocks(card, &blocks);
 -		if (err)
 -			req_pending = old_req_pending;
 -		else
 -			req_pending = blk_end_request(req, 0, blocks << 9);
 +		if (!err) {
 +			ret = blk_end_request(req, 0, blocks << 9);
 +		}
  	} else {
 -		req_pending = blk_end_request(req, 0, brq->data.bytes_xfered);
 +		ret = blk_end_request(req, 0, brq->data.bytes_xfered);
  	}
 -	return req_pending;
 +	return ret;
  }
  
++<<<<<<< HEAD
 +static int mmc_blk_issue_rw_rq(struct mmc_queue *mq, struct request *rqc)
++=======
+ static void mmc_blk_rw_cmd_abort(struct mmc_card *card, struct request *req)
+ {
+ 	if (mmc_card_removed(card))
+ 		req->rq_flags |= RQF_QUIET;
+ 	while (blk_end_request(req, -EIO, blk_rq_cur_bytes(req)));
+ }
+ 
+ /**
+  * mmc_blk_rw_try_restart() - tries to restart the current async request
+  * @mq: the queue with the card and host to restart
+  * @req: a new request that want to be started after the current one
+  */
+ static void mmc_blk_rw_try_restart(struct mmc_queue *mq, struct request *req,
+ 				   struct mmc_queue_req *mqrq)
+ {
+ 	if (!req)
+ 		return;
+ 
+ 	/*
+ 	 * If the card was removed, just cancel everything and return.
+ 	 */
+ 	if (mmc_card_removed(mq->card)) {
+ 		req->rq_flags |= RQF_QUIET;
+ 		blk_end_request_all(req, -EIO);
+ 		return;
+ 	}
+ 	/* Else proceed and try to restart the current async request */
+ 	mmc_blk_rw_rq_prep(mqrq, mq->card, 0, mq);
+ 	mmc_start_areq(mq->card->host, &mqrq->areq, NULL);
+ }
+ 
+ static void mmc_blk_issue_rw_rq(struct mmc_queue *mq, struct request *new_req)
++>>>>>>> 8ddfe07e18c9 (mmc: block: Use local var for mqrq_cur)
  {
  	struct mmc_blk_data *md = mq->blkdata;
  	struct mmc_card *card = md->queue.card;
  	struct mmc_blk_request *brq;
 -	int disable_multi = 0, retry = 0, type, retune_retry_done = 0;
 +	int ret = 1, disable_multi = 0, retry = 0, type, retune_retry_done = 0;
  	enum mmc_blk_status status;
+ 	struct mmc_queue_req *mqrq_cur = mq->mqrq_cur;
  	struct mmc_queue_req *mq_rq;
 -	struct request *old_req;
 +	struct request *req;
  	struct mmc_async_req *new_areq;
  	struct mmc_async_req *old_areq;
 -	bool req_pending = true;
  
 -	if (!new_req && !mq->mqrq_prev->req)
 -		return;
 +	if (!rqc && !mq->mqrq_prev->req)
 +		return 0;
  
  	do {
 -		if (new_req) {
 +		if (rqc) {
  			/*
  			 * When 4KB native sector is enabled, only 8 blocks
  			 * multiple read or write is allowed
  			 */
  			if (mmc_large_sector(card) &&
 -				!IS_ALIGNED(blk_rq_sectors(new_req), 8)) {
 +				!IS_ALIGNED(blk_rq_sectors(rqc), 8)) {
  				pr_err("%s: Transfer size is not 4KB sector size aligned\n",
 -					new_req->rq_disk->disk_name);
 -				mmc_blk_rw_cmd_abort(card, new_req);
 -				return;
 +					rqc->rq_disk->disk_name);
 +				mmc_blk_rw_cmd_abort(card, rqc);
 +				return 0;
  			}
  
++<<<<<<< HEAD
 +			mmc_blk_rw_rq_prep(mq->mqrq_cur, card, 0, mq);
 +			new_areq = &mq->mqrq_cur->mmc_active;
++=======
+ 			mmc_blk_rw_rq_prep(mqrq_cur, card, 0, mq);
+ 			new_areq = &mqrq_cur->areq;
++>>>>>>> 8ddfe07e18c9 (mmc: block: Use local var for mqrq_cur)
  		} else
  			new_areq = NULL;
  
@@@ -1664,11 -1698,17 +1705,25 @@@
  			}
  			break;
  		case MMC_BLK_CMD_ERR:
++<<<<<<< HEAD
 +			ret = mmc_blk_cmd_err(md, card, brq, req, ret);
 +			if (mmc_blk_reset(md, card->host, type))
 +				goto cmd_abort;
 +			if (!ret)
 +				goto start_new_req;
++=======
+ 			req_pending = mmc_blk_rw_cmd_err(md, card, brq, old_req, req_pending);
+ 			if (mmc_blk_reset(md, card->host, type)) {
+ 				if (req_pending)
+ 					mmc_blk_rw_cmd_abort(card, old_req);
+ 				mmc_blk_rw_try_restart(mq, new_req, mqrq_cur);
+ 				return;
+ 			}
+ 			if (!req_pending) {
+ 				mmc_blk_rw_try_restart(mq, new_req, mqrq_cur);
+ 				return;
+ 			}
++>>>>>>> 8ddfe07e18c9 (mmc: block: Use local var for mqrq_cur)
  			break;
  		case MMC_BLK_RETRY:
  			retune_retry_done = brq->retune_retry_done;
@@@ -1678,15 -1718,20 +1733,29 @@@
  		case MMC_BLK_ABORT:
  			if (!mmc_blk_reset(md, card->host, type))
  				break;
++<<<<<<< HEAD
 +			goto cmd_abort;
++=======
+ 			mmc_blk_rw_cmd_abort(card, old_req);
+ 			mmc_blk_rw_try_restart(mq, new_req, mqrq_cur);
+ 			return;
++>>>>>>> 8ddfe07e18c9 (mmc: block: Use local var for mqrq_cur)
  		case MMC_BLK_DATA_ERR: {
  			int err;
  
  			err = mmc_blk_reset(md, card->host, type);
  			if (!err)
  				break;
++<<<<<<< HEAD
 +			if (err == -ENODEV)
 +				goto cmd_abort;
++=======
+ 			if (err == -ENODEV) {
+ 				mmc_blk_rw_cmd_abort(card, old_req);
+ 				mmc_blk_rw_try_restart(mq, new_req, mqrq_cur);
+ 				return;
+ 			}
++>>>>>>> 8ddfe07e18c9 (mmc: block: Use local var for mqrq_cur)
  			/* Fall through */
  		}
  		case MMC_BLK_ECC_ERR:
@@@ -1702,20 -1747,26 +1771,40 @@@
  			 * time, so we only reach here after trying to
  			 * read a single sector.
  			 */
++<<<<<<< HEAD
 +			ret = blk_end_request(req, -EIO,
 +						brq->data.blksz);
 +			if (!ret)
 +				goto start_new_req;
 +			break;
 +		case MMC_BLK_NOMEDIUM:
 +			goto cmd_abort;
 +		default:
 +			pr_err("%s: Unhandled return value (%d)",
 +					req->rq_disk->disk_name, status);
 +			goto cmd_abort;
++=======
+ 			req_pending = blk_end_request(old_req, -EIO,
+ 						      brq->data.blksz);
+ 			if (!req_pending) {
+ 				mmc_blk_rw_try_restart(mq, new_req, mqrq_cur);
+ 				return;
+ 			}
+ 			break;
+ 		case MMC_BLK_NOMEDIUM:
+ 			mmc_blk_rw_cmd_abort(card, old_req);
+ 			mmc_blk_rw_try_restart(mq, new_req, mqrq_cur);
+ 			return;
+ 		default:
+ 			pr_err("%s: Unhandled return value (%d)",
+ 					old_req->rq_disk->disk_name, status);
+ 			mmc_blk_rw_cmd_abort(card, old_req);
+ 			mmc_blk_rw_try_restart(mq, new_req, mqrq_cur);
+ 			return;
++>>>>>>> 8ddfe07e18c9 (mmc: block: Use local var for mqrq_cur)
  		}
  
 -		if (req_pending) {
 +		if (ret) {
  			/*
  			 * In case of a incomplete request
  			 * prepare it again and resend.
* Unmerged path drivers/mmc/core/block.c
