bpf: get rid of pure_initcall dependency to enable jits

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Daniel Borkmann <daniel@iogearbox.net>
commit fa9dd599b4dae841924b022768354cfde9affecb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/fa9dd599.failed

Having a pure_initcall() callback just to permanently enable BPF
JITs under CONFIG_BPF_JIT_ALWAYS_ON is unnecessary and could leave
a small race window in future where JIT is still disabled on boot.
Since we know about the setting at compilation time anyway, just
initialize it properly there. Also consolidate all the individual
bpf_jit_enable variables into a single one and move them under one
location. Moreover, don't allow for setting unspecified garbage
values on them.

	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Acked-by: Alexei Starovoitov <ast@kernel.org>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
(cherry picked from commit fa9dd599b4dae841924b022768354cfde9affecb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm/net/bpf_jit_32.c
#	arch/arm64/net/bpf_jit_comp.c
#	arch/mips/net/bpf_jit.c
#	arch/mips/net/ebpf_jit.c
#	arch/powerpc/net/bpf_jit_comp64.c
#	arch/s390/net/bpf_jit_comp.c
#	arch/sparc/net/bpf_jit_comp_64.c
#	arch/x86/net/bpf_jit_comp.c
#	kernel/bpf/core.c
#	net/core/sysctl_net_core.c
diff --cc arch/arm/net/bpf_jit_32.c
index 09420d09618b,a15e7cdf8754..000000000000
--- a/arch/arm/net/bpf_jit_32.c
+++ b/arch/arm/net/bpf_jit_32.c
@@@ -22,43 -24,90 +22,56 @@@
  
  #include "bpf_jit_32.h"
  
++<<<<<<< HEAD
++=======
+ #define STACK_OFFSET(k)	(k)
+ #define TMP_REG_1	(MAX_BPF_JIT_REG + 0)	/* TEMP Register 1 */
+ #define TMP_REG_2	(MAX_BPF_JIT_REG + 1)	/* TEMP Register 2 */
+ #define TCALL_CNT	(MAX_BPF_JIT_REG + 2)	/* Tail Call Count */
+ 
+ /* Flags used for JIT optimization */
+ #define SEEN_CALL	(1 << 0)
+ 
+ #define FLAG_IMM_OVERFLOW	(1 << 0)
+ 
++>>>>>>> fa9dd599b4da (bpf: get rid of pure_initcall dependency to enable jits)
  /*
 - * Map eBPF registers to ARM 32bit registers or stack scratch space.
 - *
 - * 1. First argument is passed using the arm 32bit registers and rest of the
 - * arguments are passed on stack scratch space.
 - * 2. First callee-saved arugument is mapped to arm 32 bit registers and rest
 - * arguments are mapped to scratch space on stack.
 - * 3. We need two 64 bit temp registers to do complex operations on eBPF
 - * registers.
 - *
 - * As the eBPF registers are all 64 bit registers and arm has only 32 bit
 - * registers, we have to map each eBPF registers with two arm 32 bit regs or
 - * scratch memory space and we have to build eBPF 64 bit register from those.
 + * ABI:
   *
 + * r0	scratch register
 + * r4	BPF register A
 + * r5	BPF register X
 + * r6	pointer to the skb
 + * r7	skb->data
 + * r8	skb_headlen(skb)
   */
 -static const u8 bpf2a32[][2] = {
 -	/* return value from in-kernel function, and exit value from eBPF */
 -	[BPF_REG_0] = {ARM_R1, ARM_R0},
 -	/* arguments from eBPF program to in-kernel function */
 -	[BPF_REG_1] = {ARM_R3, ARM_R2},
 -	/* Stored on stack scratch space */
 -	[BPF_REG_2] = {STACK_OFFSET(0), STACK_OFFSET(4)},
 -	[BPF_REG_3] = {STACK_OFFSET(8), STACK_OFFSET(12)},
 -	[BPF_REG_4] = {STACK_OFFSET(16), STACK_OFFSET(20)},
 -	[BPF_REG_5] = {STACK_OFFSET(24), STACK_OFFSET(28)},
 -	/* callee saved registers that in-kernel function will preserve */
 -	[BPF_REG_6] = {ARM_R5, ARM_R4},
 -	/* Stored on stack scratch space */
 -	[BPF_REG_7] = {STACK_OFFSET(32), STACK_OFFSET(36)},
 -	[BPF_REG_8] = {STACK_OFFSET(40), STACK_OFFSET(44)},
 -	[BPF_REG_9] = {STACK_OFFSET(48), STACK_OFFSET(52)},
 -	/* Read only Frame Pointer to access Stack */
 -	[BPF_REG_FP] = {STACK_OFFSET(56), STACK_OFFSET(60)},
 -	/* Temporary Register for internal BPF JIT, can be used
 -	 * for constant blindings and others.
 -	 */
 -	[TMP_REG_1] = {ARM_R7, ARM_R6},
 -	[TMP_REG_2] = {ARM_R10, ARM_R8},
 -	/* Tail call count. Stored on stack scratch space. */
 -	[TCALL_CNT] = {STACK_OFFSET(64), STACK_OFFSET(68)},
 -	/* temporary register for blinding constants.
 -	 * Stored on stack scratch space.
 -	 */
 -	[BPF_REG_AX] = {STACK_OFFSET(72), STACK_OFFSET(76)},
 -};
  
 -#define	dst_lo	dst[1]
 -#define dst_hi	dst[0]
 -#define src_lo	src[1]
 -#define src_hi	src[0]
 +#define r_scratch	ARM_R0
 +/* r1-r3 are (also) used for the unaligned loads on the non-ARMv7 slowpath */
 +#define r_off		ARM_R1
 +#define r_A		ARM_R4
 +#define r_X		ARM_R5
 +#define r_skb		ARM_R6
 +#define r_skb_data	ARM_R7
 +#define r_skb_hl	ARM_R8
  
 -/*
 - * JIT Context:
 - *
 - * prog			:	bpf_prog
 - * idx			:	index of current last JITed instruction.
 - * prologue_bytes	:	bytes used in prologue.
 - * epilogue_offset	:	offset of epilogue starting.
 - * seen			:	bit mask used for JIT optimization.
 - * offsets		:	array of eBPF instruction offsets in
 - *				JITed code.
 - * target		:	final JITed code.
 - * epilogue_bytes	:	no of bytes used in epilogue.
 - * imm_count		:	no of immediate counts used for global
 - *				variables.
 - * imms			:	array of global variable addresses.
 - */
 +#define SCRATCH_SP_OFFSET	0
 +#define SCRATCH_OFF(k)		(SCRATCH_SP_OFFSET + 4 * (k))
 +
 +#define SEEN_MEM		((1 << BPF_MEMWORDS) - 1)
 +#define SEEN_MEM_WORD(k)	(1 << (k))
 +#define SEEN_X			(1 << BPF_MEMWORDS)
 +#define SEEN_CALL		(1 << (BPF_MEMWORDS + 1))
 +#define SEEN_SKB		(1 << (BPF_MEMWORDS + 2))
 +#define SEEN_DATA		(1 << (BPF_MEMWORDS + 3))
 +
 +#define FLAG_NEED_X_RESET	(1 << 0)
  
  struct jit_ctx {
 -	const struct bpf_prog *prog;
 -	unsigned int idx;
 -	unsigned int prologue_bytes;
 -	unsigned int epilogue_offset;
 +	const struct sk_filter *skf;
 +	unsigned idx;
 +	unsigned prologue_bytes;
 +	int ret0_fp_idx;
  	u32 seen;
  	u32 flags;
  	u32 *offsets;
diff --cc arch/s390/net/bpf_jit_comp.c
index 600b1e5c8c9d,e50188773ff3..000000000000
--- a/arch/s390/net/bpf_jit_comp.c
+++ b/arch/s390/net/bpf_jit_comp.c
@@@ -1,173 -1,430 +1,176 @@@
  /*
   * BPF Jit compiler for s390.
   *
 - * Minimum build requirements:
 - *
 - *  - HAVE_MARCH_Z196_FEATURES: laal, laalg
 - *  - HAVE_MARCH_Z10_FEATURES: msfi, cgrj, clgrj
 - *  - HAVE_MARCH_Z9_109_FEATURES: alfi, llilf, clfi, oilf, nilf
 - *  - PACK_STACK
 - *  - 64BIT
 - *
 - * Copyright IBM Corp. 2012,2015
 + * Copyright IBM Corp. 2012
   *
   * Author(s): Martin Schwidefsky <schwidefsky@de.ibm.com>
 - *	      Michael Holzheu <holzheu@linux.vnet.ibm.com>
   */
 -
 -#define KMSG_COMPONENT "bpf_jit"
 -#define pr_fmt(fmt) KMSG_COMPONENT ": " fmt
 -
 +#include <linux/moduleloader.h>
  #include <linux/netdevice.h>
 +#include <linux/if_vlan.h>
  #include <linux/filter.h>
 -#include <linux/init.h>
 -#include <linux/bpf.h>
  #include <asm/cacheflush.h>
 +#include <asm/facility.h>
  #include <asm/dis.h>
 -#include <asm/set_memory.h>
 -#include "bpf_jit.h"
 -
 -struct bpf_jit {
 -	u32 seen;		/* Flags to remember seen eBPF instructions */
 -	u32 seen_reg[16];	/* Array to remember which registers are used */
 -	u32 *addrs;		/* Array with relative instruction addresses */
 -	u8 *prg_buf;		/* Start of program */
 -	int size;		/* Size of program and literal pool */
 -	int size_prg;		/* Size of program */
 -	int prg;		/* Current position in program */
 -	int lit_start;		/* Start of literal pool */
 -	int lit;		/* Current position in literal pool */
 -	int base_ip;		/* Base address for literal pool */
 -	int ret0_ip;		/* Address of return 0 */
 -	int exit_ip;		/* Address of exit */
 -	int tail_call_start;	/* Tail call start offset */
 -	int labels[1];		/* Labels for local jumps */
 -};
 -
 -#define BPF_SIZE_MAX	0xffff	/* Max size for program (16 bit branches) */
 -
 -#define SEEN_SKB	1	/* skb access */
 -#define SEEN_MEM	2	/* use mem[] for temporary storage */
 -#define SEEN_RET0	4	/* ret0_ip points to a valid return 0 */
 -#define SEEN_LITERAL	8	/* code uses literals */
 -#define SEEN_FUNC	16	/* calls C functions */
 -#define SEEN_TAIL_CALL	32	/* code uses tail calls */
 -#define SEEN_REG_AX	64	/* code uses constant blinding */
 -#define SEEN_STACK	(SEEN_FUNC | SEEN_MEM | SEEN_SKB)
  
++<<<<<<< HEAD
  /*
 - * s390 registers
 + * Conventions:
 + *   %r2 = skb pointer
 + *   %r3 = offset parameter
 + *   %r4 = scratch register / length parameter
 + *   %r5 = BPF A accumulator
 + *   %r8 = return address
 + *   %r9 = save register for skb pointer
 + *   %r10 = skb->data
 + *   %r11 = skb->len - skb->data_len (headlen)
 + *   %r12 = BPF X accumulator
 + *   %r13 = literal pool pointer
 + *   0(%r15) - 63(%r15) scratch memory array with BPF_MEMWORDS
   */
 -#define REG_W0		(MAX_BPF_JIT_REG + 0)	/* Work register 1 (even) */
 -#define REG_W1		(MAX_BPF_JIT_REG + 1)	/* Work register 2 (odd) */
 -#define REG_SKB_DATA	(MAX_BPF_JIT_REG + 2)	/* SKB data register */
 -#define REG_L		(MAX_BPF_JIT_REG + 3)	/* Literal pool register */
 -#define REG_15		(MAX_BPF_JIT_REG + 4)	/* Register 15 */
 -#define REG_0		REG_W0			/* Register 0 */
 -#define REG_1		REG_W1			/* Register 1 */
 -#define REG_2		BPF_REG_1		/* Register 2 */
 -#define REG_14		BPF_REG_0		/* Register 14 */
 -
 -/*
 - * Mapping of BPF registers to s390 registers
 - */
 -static const int reg2hex[] = {
 -	/* Return code */
 -	[BPF_REG_0]	= 14,
 -	/* Function parameters */
 -	[BPF_REG_1]	= 2,
 -	[BPF_REG_2]	= 3,
 -	[BPF_REG_3]	= 4,
 -	[BPF_REG_4]	= 5,
 -	[BPF_REG_5]	= 6,
 -	/* Call saved registers */
 -	[BPF_REG_6]	= 7,
 -	[BPF_REG_7]	= 8,
 -	[BPF_REG_8]	= 9,
 -	[BPF_REG_9]	= 10,
 -	/* BPF stack pointer */
 -	[BPF_REG_FP]	= 13,
 -	/* Register for blinding (shared with REG_SKB_DATA) */
 -	[BPF_REG_AX]	= 12,
 -	/* SKB data pointer */
 -	[REG_SKB_DATA]	= 12,
 -	/* Work registers for s390x backend */
 -	[REG_W0]	= 0,
 -	[REG_W1]	= 1,
 -	[REG_L]		= 11,
 -	[REG_15]	= 15,
 -};
 -
 -static inline u32 reg(u32 dst_reg, u32 src_reg)
 -{
 -	return reg2hex[dst_reg] << 4 | reg2hex[src_reg];
 -}
 -
 -static inline u32 reg_high(u32 reg)
 -{
 -	return reg2hex[reg] << 4;
 -}
 -
 -static inline void reg_set_seen(struct bpf_jit *jit, u32 b1)
 -{
 -	u32 r1 = reg2hex[b1];
 -
 -	if (!jit->seen_reg[r1] && r1 >= 6 && r1 <= 15)
 -		jit->seen_reg[r1] = 1;
 -}
 -
 -#define REG_SET_SEEN(b1)					\
 -({								\
 -	reg_set_seen(jit, b1);					\
 -})
 -
 -#define REG_SEEN(b1) jit->seen_reg[reg2hex[(b1)]]
 +int bpf_jit_enable __read_mostly;
  
  /*
 - * EMIT macros for code generation
 + * assembly code in arch/x86/net/bpf_jit.S
   */
 +extern u8 sk_load_word[], sk_load_half[], sk_load_byte[], sk_load_byte_msh[];
 +extern u8 sk_load_word_ind[], sk_load_half_ind[], sk_load_byte_ind[];
  
 -#define _EMIT2(op)						\
 -({								\
 -	if (jit->prg_buf)					\
 -		*(u16 *) (jit->prg_buf + jit->prg) = op;	\
 -	jit->prg += 2;						\
 -})
 -
 -#define EMIT2(op, b1, b2)					\
 -({								\
 -	_EMIT2(op | reg(b1, b2));				\
 -	REG_SET_SEEN(b1);					\
 -	REG_SET_SEEN(b2);					\
 -})
 -
 -#define _EMIT4(op)						\
 -({								\
 -	if (jit->prg_buf)					\
 -		*(u32 *) (jit->prg_buf + jit->prg) = op;	\
 -	jit->prg += 4;						\
 -})
 -
 -#define EMIT4(op, b1, b2)					\
 -({								\
 -	_EMIT4(op | reg(b1, b2));				\
 -	REG_SET_SEEN(b1);					\
 -	REG_SET_SEEN(b2);					\
 -})
 -
 -#define EMIT4_RRF(op, b1, b2, b3)				\
 -({								\
 -	_EMIT4(op | reg_high(b3) << 8 | reg(b1, b2));		\
 -	REG_SET_SEEN(b1);					\
 -	REG_SET_SEEN(b2);					\
 -	REG_SET_SEEN(b3);					\
 -})
 -
 -#define _EMIT4_DISP(op, disp)					\
 -({								\
 -	unsigned int __disp = (disp) & 0xfff;			\
 -	_EMIT4(op | __disp);					\
 -})
 -
 -#define EMIT4_DISP(op, b1, b2, disp)				\
 -({								\
 -	_EMIT4_DISP(op | reg_high(b1) << 16 |			\
 -		    reg_high(b2) << 8, disp);			\
 -	REG_SET_SEEN(b1);					\
 -	REG_SET_SEEN(b2);					\
 -})
 -
 -#define EMIT4_IMM(op, b1, imm)					\
 -({								\
 -	unsigned int __imm = (imm) & 0xffff;			\
 -	_EMIT4(op | reg_high(b1) << 16 | __imm);		\
 -	REG_SET_SEEN(b1);					\
 -})
 -
 -#define EMIT4_PCREL(op, pcrel)					\
 -({								\
 -	long __pcrel = ((pcrel) >> 1) & 0xffff;			\
 -	_EMIT4(op | __pcrel);					\
 -})
 -
 -#define _EMIT6(op1, op2)					\
 -({								\
 -	if (jit->prg_buf) {					\
 -		*(u32 *) (jit->prg_buf + jit->prg) = op1;	\
 -		*(u16 *) (jit->prg_buf + jit->prg + 4) = op2;	\
 -	}							\
 -	jit->prg += 6;						\
 -})
 -
 -#define _EMIT6_DISP(op1, op2, disp)				\
 -({								\
 -	unsigned int __disp = (disp) & 0xfff;			\
 -	_EMIT6(op1 | __disp, op2);				\
 -})
++=======
++>>>>>>> fa9dd599b4da (bpf: get rid of pure_initcall dependency to enable jits)
 +struct bpf_jit {
 +	unsigned int seen;
 +	u8 *start;
 +	u8 *prg;
 +	u8 *mid;
 +	u8 *lit;
 +	u8 *end;
 +	u8 *base_ip;
 +	u8 *ret0_ip;
 +	u8 *exit_ip;
 +	unsigned int off_load_word;
 +	unsigned int off_load_half;
 +	unsigned int off_load_byte;
 +	unsigned int off_load_bmsh;
 +	unsigned int off_load_iword;
 +	unsigned int off_load_ihalf;
 +	unsigned int off_load_ibyte;
 +};
  
 -#define _EMIT6_DISP_LH(op1, op2, disp)				\
 -({								\
 -	u32 _disp = (u32) disp;					\
 -	unsigned int __disp_h = _disp & 0xff000;		\
 -	unsigned int __disp_l = _disp & 0x00fff;		\
 -	_EMIT6(op1 | __disp_l, op2 | __disp_h >> 4);		\
 +#define BPF_SIZE_MAX	4096	/* Max size for program */
 +
 +#define SEEN_DATAREF	1	/* might call external helpers */
 +#define SEEN_XREG	2	/* ebx is used */
 +#define SEEN_MEM	4	/* use mem[] for temporary storage */
 +#define SEEN_RET0	8	/* pc_ret0 points to a valid return 0 */
 +#define SEEN_LITERAL	16	/* code uses literals */
 +#define SEEN_LOAD_WORD	32	/* code uses sk_load_word */
 +#define SEEN_LOAD_HALF	64	/* code uses sk_load_half */
 +#define SEEN_LOAD_BYTE	128	/* code uses sk_load_byte */
 +#define SEEN_LOAD_BMSH	256	/* code uses sk_load_byte_msh */
 +#define SEEN_LOAD_IWORD	512	/* code uses sk_load_word_ind */
 +#define SEEN_LOAD_IHALF	1024	/* code uses sk_load_half_ind */
 +#define SEEN_LOAD_IBYTE	2048	/* code uses sk_load_byte_ind */
 +
 +#define EMIT2(op)					\
 +({							\
 +	if (jit->prg + 2 <= jit->mid)			\
 +		*(u16 *) jit->prg = op;			\
 +	jit->prg += 2;					\
  })
  
 -#define EMIT6_DISP_LH(op1, op2, b1, b2, b3, disp)		\
 -({								\
 -	_EMIT6_DISP_LH(op1 | reg(b1, b2) << 16 |		\
 -		       reg_high(b3) << 8, op2, disp);		\
 -	REG_SET_SEEN(b1);					\
 -	REG_SET_SEEN(b2);					\
 -	REG_SET_SEEN(b3);					\
 +#define EMIT4(op)					\
 +({							\
 +	if (jit->prg + 4 <= jit->mid)			\
 +		*(u32 *) jit->prg = op;			\
 +	jit->prg += 4;					\
  })
  
 -#define EMIT6_PCREL_LABEL(op1, op2, b1, b2, label, mask)	\
 -({								\
 -	int rel = (jit->labels[label] - jit->prg) >> 1;		\
 -	_EMIT6(op1 | reg(b1, b2) << 16 | (rel & 0xffff),	\
 -	       op2 | mask << 12);				\
 -	REG_SET_SEEN(b1);					\
 -	REG_SET_SEEN(b2);					\
 +#define EMIT4_DISP(op, disp)				\
 +({							\
 +	unsigned int __disp = (disp) & 0xfff;		\
 +	EMIT4(op | __disp);				\
  })
  
 -#define EMIT6_PCREL_IMM_LABEL(op1, op2, b1, imm, label, mask)	\
 -({								\
 -	int rel = (jit->labels[label] - jit->prg) >> 1;		\
 -	_EMIT6(op1 | (reg_high(b1) | mask) << 16 |		\
 -		(rel & 0xffff), op2 | (imm & 0xff) << 8);	\
 -	REG_SET_SEEN(b1);					\
 -	BUILD_BUG_ON(((unsigned long) imm) > 0xff);		\
 +#define EMIT4_IMM(op, imm)				\
 +({							\
 +	unsigned int __imm = (imm) & 0xffff;		\
 +	EMIT4(op | __imm);				\
  })
  
 -#define EMIT6_PCREL(op1, op2, b1, b2, i, off, mask)		\
 -({								\
 -	/* Branch instruction needs 6 bytes */			\
 -	int rel = (addrs[i + off + 1] - (addrs[i + 1] - 6)) / 2;\
 -	_EMIT6(op1 | reg(b1, b2) << 16 | (rel & 0xffff), op2 | mask);	\
 -	REG_SET_SEEN(b1);					\
 -	REG_SET_SEEN(b2);					\
 +#define EMIT4_PCREL(op, pcrel)				\
 +({							\
 +	long __pcrel = ((pcrel) >> 1) & 0xffff;		\
 +	EMIT4(op | __pcrel);				\
  })
  
 -#define _EMIT6_IMM(op, imm)					\
 -({								\
 -	unsigned int __imm = (imm);				\
 -	_EMIT6(op | (__imm >> 16), __imm & 0xffff);		\
 +#define EMIT6(op1, op2)					\
 +({							\
 +	if (jit->prg + 6 <= jit->mid) {			\
 +		*(u32 *) jit->prg = op1;		\
 +		*(u16 *) (jit->prg + 4) = op2;		\
 +	}						\
 +	jit->prg += 6;					\
  })
  
 -#define EMIT6_IMM(op, b1, imm)					\
 -({								\
 -	_EMIT6_IMM(op | reg_high(b1) << 16, imm);		\
 -	REG_SET_SEEN(b1);					\
 +#define EMIT6_DISP(op1, op2, disp)			\
 +({							\
 +	unsigned int __disp = (disp) & 0xfff;		\
 +	EMIT6(op1 | __disp, op2);			\
  })
  
 -#define EMIT_CONST_U32(val)					\
 -({								\
 -	unsigned int ret;					\
 -	ret = jit->lit - jit->base_ip;				\
 -	jit->seen |= SEEN_LITERAL;				\
 -	if (jit->prg_buf)					\
 -		*(u32 *) (jit->prg_buf + jit->lit) = (u32) val;	\
 -	jit->lit += 4;						\
 -	ret;							\
 +#define EMIT6_IMM(op, imm)				\
 +({							\
 +	unsigned int __imm = (imm);			\
 +	EMIT6(op | (__imm >> 16), __imm & 0xffff);	\
  })
  
 -#define EMIT_CONST_U64(val)					\
 -({								\
 -	unsigned int ret;					\
 -	ret = jit->lit - jit->base_ip;				\
 -	jit->seen |= SEEN_LITERAL;				\
 -	if (jit->prg_buf)					\
 -		*(u64 *) (jit->prg_buf + jit->lit) = (u64) val;	\
 -	jit->lit += 8;						\
 -	ret;							\
 +#define EMIT_CONST(val)					\
 +({							\
 +	unsigned int ret;				\
 +	ret = (unsigned int) (jit->lit - jit->base_ip);	\
 +	jit->seen |= SEEN_LITERAL;			\
 +	if (jit->lit + 4 <= jit->end)			\
 +		*(u32 *) jit->lit = val;		\
 +	jit->lit += 4;					\
 +	ret;						\
  })
  
 -#define EMIT_ZERO(b1)						\
 -({								\
 -	/* llgfr %dst,%dst (zero extend to 64 bit) */		\
 -	EMIT4(0xb9160000, b1, b1);				\
 -	REG_SET_SEEN(b1);					\
 +#define EMIT_FN_CONST(bit, fn)				\
 +({							\
 +	unsigned int ret;				\
 +	ret = (unsigned int) (jit->lit - jit->base_ip);	\
 +	if (jit->seen & bit) {				\
 +		jit->seen |= SEEN_LITERAL;		\
 +		if (jit->lit + 8 <= jit->end)		\
 +			*(void **) jit->lit = fn;	\
 +		jit->lit += 8;				\
 +	}						\
 +	ret;						\
  })
  
 -/*
 - * Fill whole space with illegal instructions
 - */
 -static void jit_fill_hole(void *area, unsigned int size)
 -{
 -	memset(area, 0, size);
 -}
 -
 -/*
 - * Save registers from "rs" (register start) to "re" (register end) on stack
 - */
 -static void save_regs(struct bpf_jit *jit, u32 rs, u32 re)
 -{
 -	u32 off = STK_OFF_R6 + (rs - 6) * 8;
 -
 -	if (rs == re)
 -		/* stg %rs,off(%r15) */
 -		_EMIT6(0xe300f000 | rs << 20 | off, 0x0024);
 -	else
 -		/* stmg %rs,%re,off(%r15) */
 -		_EMIT6_DISP(0xeb00f000 | rs << 20 | re << 16, 0x0024, off);
 -}
 -
 -/*
 - * Restore registers from "rs" (register start) to "re" (register end) on stack
 - */
 -static void restore_regs(struct bpf_jit *jit, u32 rs, u32 re, u32 stack_depth)
 -{
 -	u32 off = STK_OFF_R6 + (rs - 6) * 8;
 -
 -	if (jit->seen & SEEN_STACK)
 -		off += STK_OFF + stack_depth;
 -
 -	if (rs == re)
 -		/* lg %rs,off(%r15) */
 -		_EMIT6(0xe300f000 | rs << 20 | off, 0x0004);
 -	else
 -		/* lmg %rs,%re,off(%r15) */
 -		_EMIT6_DISP(0xeb00f000 | rs << 20 | re << 16, 0x0004, off);
 -}
 -
 -/*
 - * Return first seen register (from start)
 - */
 -static int get_start(struct bpf_jit *jit, int start)
 -{
 -	int i;
 -
 -	for (i = start; i <= 15; i++) {
 -		if (jit->seen_reg[i])
 -			return i;
 -	}
 -	return 0;
 -}
 -
 -/*
 - * Return last seen register (from start) (gap >= 2)
 - */
 -static int get_end(struct bpf_jit *jit, int start)
 -{
 -	int i;
 -
 -	for (i = start; i < 15; i++) {
 -		if (!jit->seen_reg[i] && !jit->seen_reg[i + 1])
 -			return i - 1;
 -	}
 -	return jit->seen_reg[15] ? 15 : 14;
 -}
 -
 -#define REGS_SAVE	1
 -#define REGS_RESTORE	0
 -/*
 - * Save and restore clobbered registers (6-15) on stack.
 - * We save/restore registers in chunks with gap >= 2 registers.
 - */
 -static void save_restore_regs(struct bpf_jit *jit, int op, u32 stack_depth)
 -{
 -
 -	int re = 6, rs;
 -
 -	do {
 -		rs = get_start(jit, re);
 -		if (!rs)
 -			break;
 -		re = get_end(jit, rs + 1);
 -		if (op == REGS_SAVE)
 -			save_regs(jit, rs, re);
 -		else
 -			restore_regs(jit, rs, re, stack_depth);
 -		re++;
 -	} while (re <= 15);
 -}
 -
 -/*
 - * For SKB access %b1 contains the SKB pointer. For "bpf_jit.S"
 - * we store the SKB header length on the stack and the SKB data
 - * pointer in REG_SKB_DATA if BPF_REG_AX is not used.
 - */
 -static void emit_load_skb_data_hlen(struct bpf_jit *jit)
 +static void bpf_jit_prologue(struct bpf_jit *jit)
  {
 -	/* Header length: llgf %w1,<len>(%b1) */
 -	EMIT6_DISP_LH(0xe3000000, 0x0016, REG_W1, REG_0, BPF_REG_1,
 -		      offsetof(struct sk_buff, len));
 -	/* s %w1,<data_len>(%b1) */
 -	EMIT4_DISP(0x5b000000, REG_W1, BPF_REG_1,
 -		   offsetof(struct sk_buff, data_len));
 -	/* stg %w1,ST_OFF_HLEN(%r0,%r15) */
 -	EMIT6_DISP_LH(0xe3000000, 0x0024, REG_W1, REG_0, REG_15, STK_OFF_HLEN);
 -	if (!(jit->seen & SEEN_REG_AX))
 -		/* lg %skb_data,data_off(%b1) */
 -		EMIT6_DISP_LH(0xe3000000, 0x0004, REG_SKB_DATA, REG_0,
 -			      BPF_REG_1, offsetof(struct sk_buff, data));
 -}
 +	/* Save registers and create stack frame if necessary */
 +	if (jit->seen & SEEN_DATAREF) {
 +		/* stmg %r8,%r15,88(%r15) */
 +		EMIT6(0xeb8ff058, 0x0024);
 +		/* lgr %r14,%r15 */
 +		EMIT4(0xb90400ef);
 +		/* ahi %r15,<offset> */
 +		EMIT4_IMM(0xa7fa0000, (jit->seen & SEEN_MEM) ? -112 : -80);
 +		/* stg %r14,152(%r15) */
 +		EMIT6(0xe3e0f098, 0x0024);
 +	} else if ((jit->seen & SEEN_XREG) && (jit->seen & SEEN_LITERAL))
 +		/* stmg %r12,%r13,120(%r15) */
 +		EMIT6(0xebcdf078, 0x0024);
 +	else if (jit->seen & SEEN_XREG)
 +		/* stg %r12,120(%r15) */
 +		EMIT6(0xe3c0f078, 0x0024);
 +	else if (jit->seen & SEEN_LITERAL)
 +		/* stg %r13,128(%r15) */
 +		EMIT6(0xe3d0f080, 0x0024);
  
 -/*
 - * Emit function prologue
 - *
 - * Save registers and create stack frame if necessary.
 - * See stack frame layout desription in "bpf_jit.h"!
 - */
 -static void bpf_jit_prologue(struct bpf_jit *jit, u32 stack_depth)
 -{
 -	if (jit->seen & SEEN_TAIL_CALL) {
 -		/* xc STK_OFF_TCCNT(4,%r15),STK_OFF_TCCNT(%r15) */
 -		_EMIT6(0xd703f000 | STK_OFF_TCCNT, 0xf000 | STK_OFF_TCCNT);
 -	} else {
 -		/* j tail_call_start: NOP if no tail calls are used */
 -		EMIT4_PCREL(0xa7f40000, 6);
 -		_EMIT2(0);
 -	}
 -	/* Tail calls have to skip above initialization */
 -	jit->tail_call_start = jit->prg;
 -	/* Save registers */
 -	save_restore_regs(jit, REGS_SAVE, stack_depth);
  	/* Setup literal pool */
  	if (jit->seen & SEEN_LITERAL) {
  		/* basr %r13,0 */
diff --cc arch/x86/net/bpf_jit_comp.c
index 76c7b3a140ad,b881a979efe1..000000000000
--- a/arch/x86/net/bpf_jit_comp.c
+++ b/arch/x86/net/bpf_jit_comp.c
@@@ -12,21 -11,10 +12,24 @@@
  #include <linux/netdevice.h>
  #include <linux/filter.h>
  #include <linux/if_vlan.h>
 -#include <asm/cacheflush.h>
 -#include <asm/set_memory.h>
 -#include <linux/bpf.h>
  
++<<<<<<< HEAD
 +/*
 + * Conventions :
 + *  EAX : BPF A accumulator
 + *  EBX : BPF X accumulator
 + *  RDI : pointer to skb   (first argument given to JIT function)
 + *  RBP : frame pointer (even if CONFIG_FRAME_POINTER=n)
 + *  ECX,EDX,ESI : scratch registers
 + *  r9d : skb->len - skb->data_len (headlen)
 + *  r8  : skb->data
 + * -8(RBP) : saved RBX value
 + * -16(RBP)..-80(RBP) : BPF_MEMWORDS values
 + */
 +int bpf_jit_enable __read_mostly;
 +
++=======
++>>>>>>> fa9dd599b4da (bpf: get rid of pure_initcall dependency to enable jits)
  /*
   * assembly code in arch/x86/net/bpf_jit.S
   */
diff --cc net/core/sysctl_net_core.c
index ca2d9afec36e,6d39b4c01fc6..000000000000
--- a/net/core/sysctl_net_core.c
+++ b/net/core/sysctl_net_core.c
@@@ -24,7 -25,12 +24,16 @@@
  
  static int zero = 0;
  static int one = 1;
++<<<<<<< HEAD
 +static int ushort_max = USHRT_MAX;
++=======
+ static int two __maybe_unused = 2;
+ static int min_sndbuf = SOCK_MIN_SNDBUF;
+ static int min_rcvbuf = SOCK_MIN_RCVBUF;
+ static int max_skb_frags = MAX_SKB_FRAGS;
+ 
+ static int net_msg_warn;	/* Unused, but still a sysctl */
++>>>>>>> fa9dd599b4da (bpf: get rid of pure_initcall dependency to enable jits)
  
  #ifdef CONFIG_RPS
  static int rps_sock_flow_sysctl(struct ctl_table *table, int write,
@@@ -213,8 -326,35 +222,40 @@@ static struct ctl_table net_core_table[
  		.data		= &bpf_jit_enable,
  		.maxlen		= sizeof(int),
  		.mode		= 0644,
++<<<<<<< HEAD
 +		.proc_handler	= proc_dointvec
 +	},
++=======
+ 		.proc_handler	= proc_dointvec_minmax,
+ # ifdef CONFIG_BPF_JIT_ALWAYS_ON
+ 		.extra1		= &one,
+ 		.extra2		= &one,
+ # else
+ 		.extra1		= &zero,
+ 		.extra2		= &two,
+ # endif
+ 	},
+ # ifdef CONFIG_HAVE_EBPF_JIT
+ 	{
+ 		.procname	= "bpf_jit_harden",
+ 		.data		= &bpf_jit_harden,
+ 		.maxlen		= sizeof(int),
+ 		.mode		= 0600,
+ 		.proc_handler	= proc_dointvec_minmax,
+ 		.extra1		= &zero,
+ 		.extra2		= &two,
+ 	},
+ 	{
+ 		.procname	= "bpf_jit_kallsyms",
+ 		.data		= &bpf_jit_kallsyms,
+ 		.maxlen		= sizeof(int),
+ 		.mode		= 0600,
+ 		.proc_handler	= proc_dointvec_minmax,
+ 		.extra1		= &zero,
+ 		.extra2		= &one,
+ 	},
+ # endif
++>>>>>>> fa9dd599b4da (bpf: get rid of pure_initcall dependency to enable jits)
  #endif
  	{
  		.procname	= "netdev_tstamp_prequeue",
* Unmerged path arch/arm64/net/bpf_jit_comp.c
* Unmerged path arch/mips/net/bpf_jit.c
* Unmerged path arch/mips/net/ebpf_jit.c
* Unmerged path arch/powerpc/net/bpf_jit_comp64.c
* Unmerged path arch/sparc/net/bpf_jit_comp_64.c
* Unmerged path kernel/bpf/core.c
* Unmerged path arch/arm/net/bpf_jit_32.c
* Unmerged path arch/arm64/net/bpf_jit_comp.c
* Unmerged path arch/mips/net/bpf_jit.c
* Unmerged path arch/mips/net/ebpf_jit.c
diff --git a/arch/powerpc/net/bpf_jit_comp.c b/arch/powerpc/net/bpf_jit_comp.c
index 3c4d59c26d16..20ef809f5ba6 100644
--- a/arch/powerpc/net/bpf_jit_comp.c
+++ b/arch/powerpc/net/bpf_jit_comp.c
@@ -17,8 +17,6 @@
 
 #include "bpf_jit.h"
 
-int bpf_jit_enable __read_mostly;
-
 static inline void bpf_flush_icache(void *start, void *end)
 {
 	smp_wmb();
* Unmerged path arch/powerpc/net/bpf_jit_comp64.c
* Unmerged path arch/s390/net/bpf_jit_comp.c
diff --git a/arch/sparc/net/bpf_jit_comp.c b/arch/sparc/net/bpf_jit_comp.c
index d32340c1e7af..b9b50b015c1a 100644
--- a/arch/sparc/net/bpf_jit_comp.c
+++ b/arch/sparc/net/bpf_jit_comp.c
@@ -10,8 +10,6 @@
 
 #include "bpf_jit.h"
 
-int bpf_jit_enable __read_mostly;
-
 static inline bool is_simm13(unsigned int value)
 {
 	return value + 0x1000 < 0x2000;
* Unmerged path arch/sparc/net/bpf_jit_comp_64.c
* Unmerged path arch/x86/net/bpf_jit_comp.c
* Unmerged path kernel/bpf/core.c
* Unmerged path net/core/sysctl_net_core.c
