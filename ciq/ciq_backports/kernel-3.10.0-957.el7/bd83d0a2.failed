md/raid5: call bio_endio() directly rather than queueing for later.

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [md] raid5: call bio_endio() directly rather than queueing for later (Nigel Croxon) [1494474]
Rebuild_FUZZ: 96.92%
commit-author NeilBrown <neilb@suse.com>
commit bd83d0a28c68bacba88a3193a1bd6a083bb8d9f5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/bd83d0a2.failed

We currently gather bios that need to be returned into a bio_list
and call bio_endio() on them all together.
The original reason for this was to avoid making the calls while
holding a spinlock.
Locking has changed a lot since then, and that reason is no longer
valid.

So discard return_io() and various return_bi lists, and just call
bio_endio() directly as needed.

	Signed-off-by: NeilBrown <neilb@suse.com>
	Signed-off-by: Shaohua Li <shli@fb.com>
(cherry picked from commit bd83d0a28c68bacba88a3193a1bd6a083bb8d9f5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/md/raid5-log.h
#	drivers/md/raid5.c
diff --cc drivers/md/raid5-log.h
index dccbe0ceaf4b,738930ff5d17..000000000000
--- a/drivers/md/raid5-log.h
+++ b/drivers/md/raid5-log.h
@@@ -10,6 -10,26 +10,29 @@@ extern void r5l_stripe_write_finished(s
  extern int r5l_handle_flush_request(struct r5l_log *log, struct bio *bio);
  extern void r5l_quiesce(struct r5l_log *log, int state);
  extern bool r5l_log_disk_error(struct r5conf *conf);
++<<<<<<< HEAD
++=======
+ extern bool r5c_is_writeback(struct r5l_log *log);
+ extern int
+ r5c_try_caching_write(struct r5conf *conf, struct stripe_head *sh,
+ 		      struct stripe_head_state *s, int disks);
+ extern void
+ r5c_finish_stripe_write_out(struct r5conf *conf, struct stripe_head *sh,
+ 			    struct stripe_head_state *s);
+ extern void r5c_release_extra_page(struct stripe_head *sh);
+ extern void r5c_use_extra_page(struct stripe_head *sh);
+ extern void r5l_wake_reclaim(struct r5l_log *log, sector_t space);
+ extern void r5c_handle_cached_data_endio(struct r5conf *conf,
+ 	struct stripe_head *sh, int disks);
+ extern int r5c_cache_data(struct r5l_log *log, struct stripe_head *sh);
+ extern void r5c_make_stripe_write_out(struct stripe_head *sh);
+ extern void r5c_flush_cache(struct r5conf *conf, int num);
+ extern void r5c_check_stripe_cache_usage(struct r5conf *conf);
+ extern void r5c_check_cached_full_stripe(struct r5conf *conf);
+ extern struct md_sysfs_entry r5c_journal_mode;
+ extern void r5c_update_on_rdev_error(struct mddev *mddev);
+ extern bool r5c_big_stripe_cached(struct r5conf *conf, sector_t sect);
++>>>>>>> bd83d0a28c68 (md/raid5: call bio_endio() directly rather than queueing for later.)
  
  extern struct dma_async_tx_descriptor *
  ops_run_partial_parity(struct stripe_head *sh, struct raid5_percpu *percpu,
diff --cc drivers/md/raid5.c
index b47f960eee74,44c8ceba13fe..000000000000
--- a/drivers/md/raid5.c
+++ b/drivers/md/raid5.c
@@@ -155,17 -158,6 +155,20 @@@ static int raid6_idx_to_slot(int idx, s
  	return slot;
  }
  
++<<<<<<< HEAD
 +static void return_io(struct bio_list *return_bi)
 +{
 +	struct bio *bi;
 +	while ((bi = bio_list_pop(return_bi)) != NULL) {
 +		bi->bi_size = 0;
 +		trace_block_bio_complete(bdev_get_queue(bi->bi_bdev),
 +					 bi, 0);
 +		bio_endio(bi, 0);
 +	}
 +}
 +
++=======
++>>>>>>> bd83d0a28c68 (md/raid5: call bio_endio() directly rather than queueing for later.)
  static void print_raid5_conf (struct r5conf *conf);
  
  static int stripe_operations_active(struct stripe_head *sh)
@@@ -3294,13 -3378,14 +3293,13 @@@ handle_failed_stripe(struct r5conf *con
  		if (test_and_clear_bit(R5_Overlap, &sh->dev[i].flags))
  			wake_up(&conf->wait_for_overlap);
  
 -		while (bi && bi->bi_iter.bi_sector <
 +		while (bi && bi->bi_sector <
  			sh->dev[i].sector + STRIPE_SECTORS) {
  			struct bio *nextbi = r5_next_bio(bi, sh->dev[i].sector);
 -
 -			bi->bi_error = -EIO;
 +			clear_bit(BIO_UPTODATE, &bi->bi_flags);
  			md_write_end(conf->mddev);
  			if (!raid5_dec_bi_active_stripes(bi))
- 				bio_list_add(return_bi, bi);
+ 				bio_endio(bi);
  			bi = nextbi;
  		}
  		if (bitmap_end)
@@@ -3316,13 -3401,14 +3315,13 @@@
  		}
  
  		if (bi) bitmap_end = 1;
 -		while (bi && bi->bi_iter.bi_sector <
 +		while (bi && bi->bi_sector <
  		       sh->dev[i].sector + STRIPE_SECTORS) {
  			struct bio *bi2 = r5_next_bio(bi, sh->dev[i].sector);
 -
 -			bi->bi_error = -EIO;
 +			clear_bit(BIO_UPTODATE, &bi->bi_flags);
  			md_write_end(conf->mddev);
  			if (!raid5_dec_bi_active_stripes(bi))
- 				bio_list_add(return_bi, bi);
+ 				bio_endio(bi);
  			bi = bi2;
  		}
  
@@@ -3345,9 -3431,10 +3344,9 @@@
  			       sh->dev[i].sector + STRIPE_SECTORS) {
  				struct bio *nextbi =
  					r5_next_bio(bi, sh->dev[i].sector);
 -
 -				bi->bi_error = -EIO;
 +				clear_bit(BIO_UPTODATE, &bi->bi_flags);
  				if (!raid5_dec_bi_active_stripes(bi))
- 					bio_list_add(return_bi, bi);
+ 					bio_endio(bi);
  				bi = nextbi;
  			}
  		}
@@@ -4690,11 -4776,11 +4689,16 @@@ static void handle_stripe(struct stripe
  			     && !test_bit(R5_LOCKED, &qdev->flags)
  			     && (test_bit(R5_UPTODATE, &qdev->flags) ||
  				 test_bit(R5_Discard, &qdev->flags))))))
- 		handle_stripe_clean_event(conf, sh, disks, &s.return_bi);
+ 		handle_stripe_clean_event(conf, sh, disks);
  
  	if (s.just_cached)
++<<<<<<< HEAD
 +		r5c_handle_cached_data_endio(conf, sh, disks, &s.return_bi);
 +	r5l_stripe_write_finished(sh);
++=======
+ 		r5c_handle_cached_data_endio(conf, sh, disks);
+ 	log_stripe_write_finished(sh);
++>>>>>>> bd83d0a28c68 (md/raid5: call bio_endio() directly rather than queueing for later.)
  
  	/* Now we might consider reading some blocks, either to check/generate
  	 * parity, or to satisfy requests
diff --git a/drivers/md/raid5-cache.c b/drivers/md/raid5-cache.c
index cf3561d68686..c9db8191ba8f 100644
--- a/drivers/md/raid5-cache.c
+++ b/drivers/md/raid5-cache.c
@@ -238,8 +238,7 @@ static void __r5l_set_io_unit_state(struct r5l_io_unit *io,
 }
 
 static void
-r5c_return_dev_pending_writes(struct r5conf *conf, struct r5dev *dev,
-			      struct bio_list *return_bi)
+r5c_return_dev_pending_writes(struct r5conf *conf, struct r5dev *dev)
 {
 	struct bio *wbi, *wbi2;
 
@@ -249,23 +248,21 @@ r5c_return_dev_pending_writes(struct r5conf *conf, struct r5dev *dev,
 	       dev->sector + STRIPE_SECTORS) {
 		wbi2 = r5_next_bio(wbi, dev->sector);
 		md_write_end(conf->mddev);
-		if (!raid5_dec_bi_active_stripes(wbi)) {
-			bio_list_add(return_bi, wbi);
-		}
+		if (!raid5_dec_bi_active_stripes(wbi))
+			bio_endio(wbi);
 		wbi = wbi2;
 	}
 }
 
 void r5c_handle_cached_data_endio(struct r5conf *conf,
-	  struct stripe_head *sh, int disks, struct bio_list *return_bi)
+				  struct stripe_head *sh, int disks)
 {
 	int i;
 
 	for (i = sh->disks; i--; ) {
 		if (sh->dev[i].written) {
 			set_bit(R5_UPTODATE, &sh->dev[i].flags);
-			r5c_return_dev_pending_writes(conf, &sh->dev[i],
-						      return_bi);
+			r5c_return_dev_pending_writes(conf, &sh->dev[i]);
 			bitmap_endwrite(conf->mddev->bitmap, sh->sector,
 					STRIPE_SECTORS,
 					!test_bit(STRIPE_DEGRADED, &sh->state),
* Unmerged path drivers/md/raid5-log.h
* Unmerged path drivers/md/raid5.c
diff --git a/drivers/md/raid5.h b/drivers/md/raid5.h
index 4c5b46f68dc8..013c625cc33e 100644
--- a/drivers/md/raid5.h
+++ b/drivers/md/raid5.h
@@ -277,7 +277,6 @@ struct stripe_head_state {
 	int dec_preread_active;
 	unsigned long ops_request;
 
-	struct bio_list return_bi;
 	struct md_rdev *blocked_rdev;
 	int handle_bad_blocks;
 	int log_failed;
