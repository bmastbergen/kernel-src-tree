IB/mlx5: Move locks initialization to the corresponding stage

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Mark Bloch <markb@mellanox.com>
commit 3cc297db970762024109f75ce289078f8479a2f8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/3cc297db.failed

Unconditional locks/list and ODP srcu initialization should be done in
the INIT stage. Remove those from the CAPS stage and move them to the
proper stage.

	Signed-off-by: Mark Bloch <markb@mellanox.com>
	Signed-off-by: Leon Romanovsky <leon@kernel.org>
	Signed-off-by: Jason Gunthorpe <jgg@mellanox.com>
(cherry picked from commit 3cc297db970762024109f75ce289078f8479a2f8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/hw/mlx5/main.c
diff --cc drivers/infiniband/hw/mlx5/main.c
index a49372cd35f7,b9e195d154b1..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -4029,25 -4024,19 +4029,37 @@@ mlx5_ib_get_vector_affinity(struct ib_d
  	return mlx5_get_vector_affinity(dev->mdev, comp_vector);
  }
  
 -static void mlx5_ib_stage_init_cleanup(struct mlx5_ib_dev *dev)
 +static void *mlx5_ib_add(struct mlx5_core_dev *mdev)
  {
++<<<<<<< HEAD
 +	struct mlx5_ib_dev *dev;
 +	enum rdma_link_layer ll;
 +	int port_type_cap;
++=======
+ #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+ 	cleanup_srcu_struct(&dev->mr_srcu);
+ #endif
+ 	kfree(dev->port);
+ }
+ 
+ static int mlx5_ib_stage_init_init(struct mlx5_ib_dev *dev)
+ {
+ 	struct mlx5_core_dev *mdev = dev->mdev;
++>>>>>>> 3cc297db9707 (IB/mlx5: Move locks initialization to the corresponding stage)
  	const char *name;
  	int err;
 +	int i;
 +
 +	port_type_cap = MLX5_CAP_GEN(mdev, port_type);
 +	ll = mlx5_port_type_cap_to_rdma_ll(port_type_cap);
 +
 +	printk_once(KERN_INFO "%s", mlx5_version);
 +
 +	dev = (struct mlx5_ib_dev *)ib_alloc_device(sizeof(*dev));
 +	if (!dev)
 +		return NULL;
 +
 +	dev->mdev = mdev;
  
  	dev->port = kcalloc(MLX5_CAP_GEN(mdev, num_ports), sizeof(*dev->port),
  			    GFP_KERNEL);
@@@ -4077,6 -4066,30 +4089,33 @@@
  		dev->mdev->priv.eq_table.num_comp_vectors;
  	dev->ib_dev.dev.parent		= &mdev->pdev->dev;
  
++<<<<<<< HEAD
++=======
+ 	mutex_init(&dev->flow_db.lock);
+ 	mutex_init(&dev->cap_mask_mutex);
+ 	INIT_LIST_HEAD(&dev->qp_list);
+ 	spin_lock_init(&dev->reset_flow_resource_lock);
+ 
+ #ifdef CONFIG_INFINIBAND_ON_DEMAND_PAGING
+ 	err = init_srcu_struct(&dev->mr_srcu);
+ 	if (err)
+ 		goto err_free_port;
+ #endif
+ 
+ 	return 0;
+ 
+ err_free_port:
+ 	kfree(dev->port);
+ 
+ 	return -ENOMEM;
+ }
+ 
+ static int mlx5_ib_stage_caps_init(struct mlx5_ib_dev *dev)
+ {
+ 	struct mlx5_core_dev *mdev = dev->mdev;
+ 	int err;
+ 
++>>>>>>> 3cc297db9707 (IB/mlx5: Move locks initialization to the corresponding stage)
  	dev->ib_dev.uverbs_abi_ver	= MLX5_IB_UVERBS_ABI_VERSION;
  	dev->ib_dev.uverbs_cmd_mask	=
  		(1ull << IB_USER_VERBS_CMD_GET_CONTEXT)		|
@@@ -4204,8 -4208,29 +4243,34 @@@
  			(1ull << IB_USER_VERBS_EX_CMD_CREATE_FLOW) |
  			(1ull << IB_USER_VERBS_EX_CMD_DESTROY_FLOW);
  
++<<<<<<< HEAD
 +	if (mlx5_ib_port_link_layer(&dev->ib_dev, 1) ==
 +	    IB_LINK_LAYER_ETHERNET) {
++=======
+ 	err = init_node_data(dev);
+ 	if (err)
+ 		return err;
+ 
+ 	if ((MLX5_CAP_GEN(dev->mdev, port_type) == MLX5_CAP_PORT_TYPE_ETH) &&
+ 	    MLX5_CAP_GEN(dev->mdev, disable_local_lb))
+ 		mutex_init(&dev->lb_mutex);
+ 
+ 	return 0;
+ }
+ 
+ static int mlx5_ib_stage_roce_init(struct mlx5_ib_dev *dev)
+ {
+ 	struct mlx5_core_dev *mdev = dev->mdev;
+ 	enum rdma_link_layer ll;
+ 	int port_type_cap;
+ 	int err;
+ 
+ 	port_type_cap = MLX5_CAP_GEN(mdev, port_type);
+ 	ll = mlx5_port_type_cap_to_rdma_ll(port_type_cap);
+ 
+ 	if (ll == IB_LINK_LAYER_ETHERNET) {
+ 		dev->ib_dev.get_netdev	= mlx5_ib_get_netdev;
++>>>>>>> 3cc297db9707 (IB/mlx5: Move locks initialization to the corresponding stage)
  		dev->ib_dev.create_wq	 = mlx5_ib_create_wq;
  		dev->ib_dev.modify_wq	 = mlx5_ib_modify_wq;
  		dev->ib_dev.destroy_wq	 = mlx5_ib_destroy_wq;
@@@ -4234,27 -4248,85 +4299,58 @@@
  		dev->roce.last_port_state = IB_PORT_DOWN;
  	}
  
 -	return 0;
 -}
 +	err = create_dev_resources(&dev->devr);
 +	if (err)
 +		goto err_disable_eth;
  
 -static void mlx5_ib_stage_roce_cleanup(struct mlx5_ib_dev *dev)
 -{
 -	struct mlx5_core_dev *mdev = dev->mdev;
 -	enum rdma_link_layer ll;
 -	int port_type_cap;
 +	err = mlx5_ib_odp_init_one(dev);
 +	if (err)
 +		goto err_rsrc;
  
++<<<<<<< HEAD
++=======
+ 	port_type_cap = MLX5_CAP_GEN(mdev, port_type);
+ 	ll = mlx5_port_type_cap_to_rdma_ll(port_type_cap);
+ 
+ 	if (ll == IB_LINK_LAYER_ETHERNET) {
+ 		mlx5_disable_eth(dev);
+ 		mlx5_remove_netdev_notifier(dev);
+ 	}
+ }
+ 
+ static int mlx5_ib_stage_dev_res_init(struct mlx5_ib_dev *dev)
+ {
+ 	return create_dev_resources(&dev->devr);
+ }
+ 
+ static void mlx5_ib_stage_dev_res_cleanup(struct mlx5_ib_dev *dev)
+ {
+ 	destroy_dev_resources(&dev->devr);
+ }
+ 
+ static int mlx5_ib_stage_odp_init(struct mlx5_ib_dev *dev)
+ {
+ 	mlx5_ib_internal_fill_odp_caps(dev);
+ 
+ 	return mlx5_ib_odp_init_one(dev);
+ }
+ 
+ static int mlx5_ib_stage_counters_init(struct mlx5_ib_dev *dev)
+ {
++>>>>>>> 3cc297db9707 (IB/mlx5: Move locks initialization to the corresponding stage)
  	if (MLX5_CAP_GEN(dev->mdev, max_qp_cnt)) {
 -		dev->ib_dev.get_hw_stats	= mlx5_ib_get_hw_stats;
 -		dev->ib_dev.alloc_hw_stats	= mlx5_ib_alloc_hw_stats;
 -
 -		return mlx5_ib_alloc_counters(dev);
 +		err = mlx5_ib_alloc_counters(dev);
 +		if (err)
 +			goto err_odp;
  	}
  
 -	return 0;
 -}
 -
 -static void mlx5_ib_stage_counters_cleanup(struct mlx5_ib_dev *dev)
 -{
 -	if (MLX5_CAP_GEN(dev->mdev, max_qp_cnt))
 -		mlx5_ib_dealloc_counters(dev);
 -}
 -
 -static int mlx5_ib_stage_cong_debugfs_init(struct mlx5_ib_dev *dev)
 -{
 -	return mlx5_ib_init_cong_debugfs(dev);
 -}
 -
 -static void mlx5_ib_stage_cong_debugfs_cleanup(struct mlx5_ib_dev *dev)
 -{
 -	mlx5_ib_cleanup_cong_debugfs(dev);
 -}
 +	err = mlx5_ib_init_cong_debugfs(dev);
 +	if (err)
 +		goto err_cnt;
  
 -static int mlx5_ib_stage_uar_init(struct mlx5_ib_dev *dev)
 -{
  	dev->mdev->priv.uar = mlx5_get_uars_page(dev->mdev);
 -	if (!dev->mdev->priv.uar)
 -		return -ENOMEM;
 -	return 0;
 -}
 -
 -static void mlx5_ib_stage_uar_cleanup(struct mlx5_ib_dev *dev)
 -{
 -	mlx5_put_uars_page(dev->mdev, dev->mdev->priv.uar);
 -}
 -
 -static int mlx5_ib_stage_bfrag_init(struct mlx5_ib_dev *dev)
 -{
 -	int err;
 +	if (IS_ERR(dev->mdev->priv.uar))
 +		goto err_cong;
  
  	err = mlx5_alloc_bfreg(dev->mdev, &dev->bfreg, false, false);
  	if (err)
@@@ -4333,6 -4440,53 +4429,56 @@@ err_dealloc
  	return NULL;
  }
  
++<<<<<<< HEAD
++=======
+ static const struct mlx5_ib_profile pf_profile = {
+ 	STAGE_CREATE(MLX5_IB_STAGE_INIT,
+ 		     mlx5_ib_stage_init_init,
+ 		     mlx5_ib_stage_init_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_CAPS,
+ 		     mlx5_ib_stage_caps_init,
+ 		     NULL),
+ 	STAGE_CREATE(MLX5_IB_STAGE_ROCE,
+ 		     mlx5_ib_stage_roce_init,
+ 		     mlx5_ib_stage_roce_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_DEVICE_RESOURCES,
+ 		     mlx5_ib_stage_dev_res_init,
+ 		     mlx5_ib_stage_dev_res_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_ODP,
+ 		     mlx5_ib_stage_odp_init,
+ 		     NULL),
+ 	STAGE_CREATE(MLX5_IB_STAGE_COUNTERS,
+ 		     mlx5_ib_stage_counters_init,
+ 		     mlx5_ib_stage_counters_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_CONG_DEBUGFS,
+ 		     mlx5_ib_stage_cong_debugfs_init,
+ 		     mlx5_ib_stage_cong_debugfs_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_UAR,
+ 		     mlx5_ib_stage_uar_init,
+ 		     mlx5_ib_stage_uar_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_BFREG,
+ 		     mlx5_ib_stage_bfrag_init,
+ 		     mlx5_ib_stage_bfrag_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_IB_REG,
+ 		     mlx5_ib_stage_ib_reg_init,
+ 		     mlx5_ib_stage_ib_reg_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_UMR_RESOURCES,
+ 		     mlx5_ib_stage_umr_res_init,
+ 		     mlx5_ib_stage_umr_res_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_DELAY_DROP,
+ 		     mlx5_ib_stage_delay_drop_init,
+ 		     mlx5_ib_stage_delay_drop_cleanup),
+ 	STAGE_CREATE(MLX5_IB_STAGE_CLASS_ATTR,
+ 		     mlx5_ib_stage_class_attr_init,
+ 		     NULL),
+ };
+ 
+ static void *mlx5_ib_add(struct mlx5_core_dev *mdev)
+ {
+ 	return __mlx5_ib_add(mdev, &pf_profile);
+ }
+ 
++>>>>>>> 3cc297db9707 (IB/mlx5: Move locks initialization to the corresponding stage)
  static void mlx5_ib_remove(struct mlx5_core_dev *mdev, void *context)
  {
  	struct mlx5_ib_dev *dev = context;
* Unmerged path drivers/infiniband/hw/mlx5/main.c
diff --git a/drivers/infiniband/hw/mlx5/mlx5_ib.h b/drivers/infiniband/hw/mlx5/mlx5_ib.h
index b8241a8e9c27..e3f1a725c61e 100644
--- a/drivers/infiniband/hw/mlx5/mlx5_ib.h
+++ b/drivers/infiniband/hw/mlx5/mlx5_ib.h
@@ -968,7 +968,6 @@ void mlx5_ib_internal_fill_odp_caps(struct mlx5_ib_dev *dev);
 void mlx5_ib_pfault(struct mlx5_core_dev *mdev, void *context,
 		    struct mlx5_pagefault *pfault);
 int mlx5_ib_odp_init_one(struct mlx5_ib_dev *ibdev);
-void mlx5_ib_odp_remove_one(struct mlx5_ib_dev *ibdev);
 int __init mlx5_ib_odp_init(void);
 void mlx5_ib_odp_cleanup(void);
 void mlx5_ib_invalidate_range(struct ib_umem *umem, unsigned long start,
@@ -983,7 +982,6 @@ static inline void mlx5_ib_internal_fill_odp_caps(struct mlx5_ib_dev *dev)
 }
 
 static inline int mlx5_ib_odp_init_one(struct mlx5_ib_dev *ibdev) { return 0; }
-static inline void mlx5_ib_odp_remove_one(struct mlx5_ib_dev *ibdev)	    {}
 static inline int mlx5_ib_odp_init(void) { return 0; }
 static inline void mlx5_ib_odp_cleanup(void)				    {}
 static inline void mlx5_odp_init_mr_cache_entry(struct mlx5_cache_ent *ent) {}
diff --git a/drivers/infiniband/hw/mlx5/odp.c b/drivers/infiniband/hw/mlx5/odp.c
index e2197bdda89c..f1a87a690a4c 100644
--- a/drivers/infiniband/hw/mlx5/odp.c
+++ b/drivers/infiniband/hw/mlx5/odp.c
@@ -1207,10 +1207,6 @@ int mlx5_ib_odp_init_one(struct mlx5_ib_dev *dev)
 {
 	int ret;
 
-	ret = init_srcu_struct(&dev->mr_srcu);
-	if (ret)
-		return ret;
-
 	if (dev->odp_caps.general_caps & IB_ODP_SUPPORT_IMPLICIT) {
 		ret = mlx5_cmd_null_mkey(dev->mdev, &dev->null_mkey);
 		if (ret) {
@@ -1222,11 +1218,6 @@ int mlx5_ib_odp_init_one(struct mlx5_ib_dev *dev)
 	return 0;
 }
 
-void mlx5_ib_odp_remove_one(struct mlx5_ib_dev *dev)
-{
-	cleanup_srcu_struct(&dev->mr_srcu);
-}
-
 int mlx5_ib_odp_init(void)
 {
 	mlx5_imr_ksm_entries = BIT_ULL(get_order(TASK_SIZE) -
