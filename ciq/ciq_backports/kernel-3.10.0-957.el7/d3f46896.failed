s390/entry.S: fix spurious zeroing of r0

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [s390] entry.s: fix spurious zeroing of r0 (Hendrik Brueckner) [1558325]
Rebuild_FUZZ: 93.33%
commit-author Christian Borntraeger <borntraeger@de.ibm.com>
commit d3f468963cd6fd6d2aa5e26aed8b24232096d0e1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/d3f46896.failed

when a system call is interrupted we might call the critical section
cleanup handler that re-does some of the operations. When we are between
.Lsysc_vtime and .Lsysc_do_svc we might also redo the saving of the
problem state registers r0-r7:

.Lcleanup_system_call:
[...]
0:      # update accounting time stamp
        mvc     __LC_LAST_UPDATE_TIMER(8),__LC_SYNC_ENTER_TIMER
        # set up saved register r11
        lg      %r15,__LC_KERNEL_STACK
        la      %r9,STACK_FRAME_OVERHEAD(%r15)
        stg     %r9,24(%r11)            # r11 pt_regs pointer
        # fill pt_regs
        mvc     __PT_R8(64,%r9),__LC_SAVE_AREA_SYNC
--->    stmg    %r0,%r7,__PT_R0(%r9)

The problem is now, that we might have already zeroed out r0.
The fix is to move the zeroing of r0 after sysc_do_svc.

	Reported-by: Farhan Ali <alifm@linux.vnet.ibm.com>
Fixes: 7041d28115e91 ("s390: scrub registers on kernel entry and KVM exit")
	Signed-off-by: Christian Borntraeger <borntraeger@de.ibm.com>
	Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>
(cherry picked from commit d3f468963cd6fd6d2aa5e26aed8b24232096d0e1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/s390/kernel/entry.S
diff --cc arch/s390/kernel/entry.S
index be8edbeb24eb,a5621ea6d123..000000000000
--- a/arch/s390/kernel/entry.S
+++ b/arch/s390/kernel/entry.S
@@@ -206,57 -414,67 +206,74 @@@ __critical_start
  
  ENTRY(system_call)
  	stpt	__LC_SYNC_ENTER_TIMER
 -.Lsysc_stmg:
 -	stmg	%r8,%r15,__LC_SAVE_AREA_SYNC
 +sysc_stm:
 +	stm	%r8,%r15,__LC_SAVE_AREA_SYNC
  	BPOFF
 -	lg	%r12,__LC_CURRENT
 -	lghi	%r13,__TASK_thread
 -	lghi	%r14,_PIF_SYSCALL
 -.Lsysc_per:
 -	lg	%r15,__LC_KERNEL_STACK
 +	l	%r12,__LC_THREAD_INFO
 +	l	%r13,__LC_SVC_NEW_PSW+4
 +sysc_per:
 +	l	%r15,__LC_KERNEL_STACK
  	la	%r11,STACK_FRAME_OVERHEAD(%r15)	# pointer to pt_regs
 -.Lsysc_vtime:
 +sysc_vtime:
  	UPDATE_VTIME %r8,%r9,__LC_SYNC_ENTER_TIMER
++<<<<<<< HEAD
 +	stm	%r0,%r7,__PT_R0(%r11)
 +	mvc	__PT_R8(32,%r11),__LC_SAVE_AREA_SYNC
 +	mvc	__PT_PSW(8,%r11),__LC_SVC_OLD_PSW
 +	mvc	__PT_INT_CODE(4,%r11),__LC_SVC_ILC
 +sysc_do_svc:
 +	oi	__TI_flags+2(%r12),_TIF_SYSCALL>>8
 +	l	%r10,__TI_sysc_table(%r12)	# 31 bit system call table
 +	lh	%r8,__PT_INT_CODE+2(%r11)
 +	sla	%r8,2				# shift and test for svc0
 +	jnz	sysc_nr_ok
++=======
+ 	BPENTER __TI_flags(%r12),_TIF_ISOLATE_BP
+ 	stmg	%r0,%r7,__PT_R0(%r11)
+ 	mvc	__PT_R8(64,%r11),__LC_SAVE_AREA_SYNC
+ 	mvc	__PT_PSW(16,%r11),__LC_SVC_OLD_PSW
+ 	mvc	__PT_INT_CODE(4,%r11),__LC_SVC_ILC
+ 	stg	%r14,__PT_FLAGS(%r11)
+ .Lsysc_do_svc:
+ 	# clear user controlled register to prevent speculative use
+ 	xgr	%r0,%r0
+ 	# load address of system call table
+ 	lg	%r10,__THREAD_sysc_table(%r13,%r12)
+ 	llgh	%r8,__PT_INT_CODE+2(%r11)
+ 	slag	%r8,%r8,2			# shift and test for svc 0
+ 	jnz	.Lsysc_nr_ok
++>>>>>>> d3f468963cd6 (s390/entry.S: fix spurious zeroing of r0)
  	# svc 0: system call number in %r1
 -	llgfr	%r1,%r1				# clear high word in r1
 -	cghi	%r1,NR_syscalls
 -	jnl	.Lsysc_nr_ok
 +	cl	%r1,BASED(.Lnr_syscalls)
 +	jnl	sysc_nr_ok
  	sth	%r1,__PT_INT_CODE+2(%r11)
 -	slag	%r8,%r1,2
 -.Lsysc_nr_ok:
 -	xc	__SF_BACKCHAIN(8,%r15),__SF_BACKCHAIN(%r15)
 -	stg	%r2,__PT_ORIG_GPR2(%r11)
 -	stg	%r7,STACK_FRAME_OVERHEAD(%r15)
 -	lgf	%r9,0(%r8,%r10)			# get system call add.
 -	TSTMSK	__TI_flags(%r12),_TIF_TRACE
 -	jnz	.Lsysc_tracesys
 -	BASR_R14_R9				# call sys_xxxx
 -	stg	%r2,__PT_R2(%r11)		# store return value
 -
 -.Lsysc_return:
 +	lr	%r8,%r1
 +	sla	%r8,2
 +sysc_nr_ok:
 +	xc	__SF_BACKCHAIN(4,%r15),__SF_BACKCHAIN(%r15)
 +	st	%r2,__PT_ORIG_GPR2(%r11)
 +	st	%r7,STACK_FRAME_OVERHEAD(%r15)
 +	l	%r9,0(%r8,%r10)			# get system call addr.
 +	tm	__TI_flags+2(%r12),_TIF_TRACE >> 8
 +	jnz	sysc_tracesys
 +	basr	%r14,%r9			# call sys_xxxx
 +	st	%r2,__PT_R2(%r11)		# store return value
 +
 +sysc_return:
  	LOCKDEP_SYS_EXIT
 -.Lsysc_tif:
 -	TSTMSK	__PT_FLAGS(%r11),_PIF_WORK
 -	jnz	.Lsysc_work
 -	TSTMSK	__TI_flags(%r12),_TIF_WORK
 -	jnz	.Lsysc_work			# check for work
 -	TSTMSK	__LC_CPU_FLAGS,_CIF_WORK
 -	jnz	.Lsysc_work
 -	BPEXIT	__TI_flags(%r12),_TIF_ISOLATE_BP
 -.Lsysc_restore:
 -	lg	%r14,__LC_VDSO_PER_CPU
 -	lmg	%r0,%r10,__PT_R0(%r11)
 -	mvc	__LC_RETURN_PSW(16),__PT_PSW(%r11)
 -.Lsysc_exit_timer:
 +sysc_tif:
 +	tm	__PT_PSW+1(%r11),0x01		# returning to user ?
 +	jno	sysc_restore
 +	tm	__TI_flags+3(%r12),_TIF_WORK_SVC
 +	jnz	sysc_work			# check for work
 +	ni	__TI_flags+2(%r12),255-_TIF_SYSCALL>>8
 +	BPON
 +sysc_restore:
 +	mvc	__LC_RETURN_PSW(8),__PT_PSW(%r11)
  	stpt	__LC_EXIT_TIMER
 -	mvc	__VDSO_ECTG_BASE(16,%r14),__LC_EXIT_TIMER
 -	lmg	%r11,%r15,__PT_R11(%r11)
 -	lpswe	__LC_RETURN_PSW
 -.Lsysc_done:
 +	lm	%r0,%r15,__PT_R0(%r11)
 +	lpsw	__LC_RETURN_PSW
 +sysc_done:
  
  #
  # One of the work bits is on. Find out which one.
* Unmerged path arch/s390/kernel/entry.S
