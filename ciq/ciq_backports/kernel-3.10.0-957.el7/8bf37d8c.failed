seccomp: Move speculation migitation control to arch code

jira LE-1907
cve CVE-2018-3639
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 8bf37d8c067bb7eb8e7c381bdadf9bd89182b6bc
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/8bf37d8c.failed

The migitation control is simpler to implement in architecture code as it
avoids the extra function call to check the mode. Aside of that having an
explicit seccomp enabled mode in the architecture mitigations would require
even more workarounds.

Move it into architecture code and provide a weak function in the seccomp
code. Remove the 'which' argument as this allows the architecture to decide
which mitigations are relevant for seccomp.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
(cherry picked from commit 8bf37d8c067bb7eb8e7c381bdadf9bd89182b6bc)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/bugs.c
#	include/linux/nospec.h
#	kernel/seccomp.c
diff --cc arch/x86/kernel/cpu/bugs.c
index 29b8876b1f95,5dab4c3d26e7..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -199,15 -406,255 +199,235 @@@ static void __init spectre_v2_select_mi
  }
  
  #undef pr_fmt
++<<<<<<< HEAD
++=======
+ #define pr_fmt(fmt)	"Speculative Store Bypass: " fmt
+ 
+ static enum ssb_mitigation ssb_mode __ro_after_init = SPEC_STORE_BYPASS_NONE;
+ 
+ /* The kernel command line selection */
+ enum ssb_mitigation_cmd {
+ 	SPEC_STORE_BYPASS_CMD_NONE,
+ 	SPEC_STORE_BYPASS_CMD_AUTO,
+ 	SPEC_STORE_BYPASS_CMD_ON,
+ 	SPEC_STORE_BYPASS_CMD_PRCTL,
+ };
+ 
+ static const char *ssb_strings[] = {
+ 	[SPEC_STORE_BYPASS_NONE]	= "Vulnerable",
+ 	[SPEC_STORE_BYPASS_DISABLE]	= "Mitigation: Speculative Store Bypass disabled",
+ 	[SPEC_STORE_BYPASS_PRCTL]	= "Mitigation: Speculative Store Bypass disabled via prctl"
+ };
+ 
+ static const struct {
+ 	const char *option;
+ 	enum ssb_mitigation_cmd cmd;
+ } ssb_mitigation_options[] = {
+ 	{ "auto",	SPEC_STORE_BYPASS_CMD_AUTO },  /* Platform decides */
+ 	{ "on",		SPEC_STORE_BYPASS_CMD_ON },    /* Disable Speculative Store Bypass */
+ 	{ "off",	SPEC_STORE_BYPASS_CMD_NONE },  /* Don't touch Speculative Store Bypass */
+ 	{ "prctl",	SPEC_STORE_BYPASS_CMD_PRCTL }, /* Disable Speculative Store Bypass via prctl */
+ };
+ 
+ static enum ssb_mitigation_cmd __init ssb_parse_cmdline(void)
+ {
+ 	enum ssb_mitigation_cmd cmd = SPEC_STORE_BYPASS_CMD_AUTO;
+ 	char arg[20];
+ 	int ret, i;
+ 
+ 	if (cmdline_find_option_bool(boot_command_line, "nospec_store_bypass_disable")) {
+ 		return SPEC_STORE_BYPASS_CMD_NONE;
+ 	} else {
+ 		ret = cmdline_find_option(boot_command_line, "spec_store_bypass_disable",
+ 					  arg, sizeof(arg));
+ 		if (ret < 0)
+ 			return SPEC_STORE_BYPASS_CMD_AUTO;
+ 
+ 		for (i = 0; i < ARRAY_SIZE(ssb_mitigation_options); i++) {
+ 			if (!match_option(arg, ret, ssb_mitigation_options[i].option))
+ 				continue;
+ 
+ 			cmd = ssb_mitigation_options[i].cmd;
+ 			break;
+ 		}
+ 
+ 		if (i >= ARRAY_SIZE(ssb_mitigation_options)) {
+ 			pr_err("unknown option (%s). Switching to AUTO select\n", arg);
+ 			return SPEC_STORE_BYPASS_CMD_AUTO;
+ 		}
+ 	}
+ 
+ 	return cmd;
+ }
+ 
+ static enum ssb_mitigation_cmd __init __ssb_select_mitigation(void)
+ {
+ 	enum ssb_mitigation mode = SPEC_STORE_BYPASS_NONE;
+ 	enum ssb_mitigation_cmd cmd;
+ 
+ 	if (!boot_cpu_has(X86_FEATURE_RDS))
+ 		return mode;
+ 
+ 	cmd = ssb_parse_cmdline();
+ 	if (!boot_cpu_has_bug(X86_BUG_SPEC_STORE_BYPASS) &&
+ 	    (cmd == SPEC_STORE_BYPASS_CMD_NONE ||
+ 	     cmd == SPEC_STORE_BYPASS_CMD_AUTO))
+ 		return mode;
+ 
+ 	switch (cmd) {
+ 	case SPEC_STORE_BYPASS_CMD_AUTO:
+ 		/* Choose prctl as the default mode */
+ 		mode = SPEC_STORE_BYPASS_PRCTL;
+ 		break;
+ 	case SPEC_STORE_BYPASS_CMD_ON:
+ 		mode = SPEC_STORE_BYPASS_DISABLE;
+ 		break;
+ 	case SPEC_STORE_BYPASS_CMD_PRCTL:
+ 		mode = SPEC_STORE_BYPASS_PRCTL;
+ 		break;
+ 	case SPEC_STORE_BYPASS_CMD_NONE:
+ 		break;
+ 	}
+ 
+ 	/*
+ 	 * We have three CPU feature flags that are in play here:
+ 	 *  - X86_BUG_SPEC_STORE_BYPASS - CPU is susceptible.
+ 	 *  - X86_FEATURE_RDS - CPU is able to turn off speculative store bypass
+ 	 *  - X86_FEATURE_SPEC_STORE_BYPASS_DISABLE - engage the mitigation
+ 	 */
+ 	if (mode == SPEC_STORE_BYPASS_DISABLE) {
+ 		setup_force_cpu_cap(X86_FEATURE_SPEC_STORE_BYPASS_DISABLE);
+ 		/*
+ 		 * Intel uses the SPEC CTRL MSR Bit(2) for this, while AMD uses
+ 		 * a completely different MSR and bit dependent on family.
+ 		 */
+ 		switch (boot_cpu_data.x86_vendor) {
+ 		case X86_VENDOR_INTEL:
+ 			x86_spec_ctrl_base |= SPEC_CTRL_RDS;
+ 			x86_spec_ctrl_mask &= ~SPEC_CTRL_RDS;
+ 			x86_spec_ctrl_set(SPEC_CTRL_RDS);
+ 			break;
+ 		case X86_VENDOR_AMD:
+ 			x86_amd_rds_enable();
+ 			break;
+ 		}
+ 	}
+ 
+ 	return mode;
+ }
+ 
+ static void ssb_select_mitigation()
+ {
+ 	ssb_mode = __ssb_select_mitigation();
+ 
+ 	if (boot_cpu_has_bug(X86_BUG_SPEC_STORE_BYPASS))
+ 		pr_info("%s\n", ssb_strings[ssb_mode]);
+ }
+ 
+ #undef pr_fmt
+ 
+ static int ssb_prctl_set(struct task_struct *task, unsigned long ctrl)
+ {
+ 	bool update;
+ 
+ 	if (ssb_mode != SPEC_STORE_BYPASS_PRCTL)
+ 		return -ENXIO;
+ 
+ 	switch (ctrl) {
+ 	case PR_SPEC_ENABLE:
+ 		/* If speculation is force disabled, enable is not allowed */
+ 		if (task_spec_ssb_force_disable(task))
+ 			return -EPERM;
+ 		task_clear_spec_ssb_disable(task);
+ 		update = test_and_clear_tsk_thread_flag(task, TIF_RDS);
+ 		break;
+ 	case PR_SPEC_DISABLE:
+ 		task_set_spec_ssb_disable(task);
+ 		update = !test_and_set_tsk_thread_flag(task, TIF_RDS);
+ 		break;
+ 	case PR_SPEC_FORCE_DISABLE:
+ 		task_set_spec_ssb_disable(task);
+ 		task_set_spec_ssb_force_disable(task);
+ 		update = !test_and_set_tsk_thread_flag(task, TIF_RDS);
+ 		break;
+ 	default:
+ 		return -ERANGE;
+ 	}
+ 
+ 	/*
+ 	 * If being set on non-current task, delay setting the CPU
+ 	 * mitigation until it is next scheduled.
+ 	 */
+ 	if (task == current && update)
+ 		speculative_store_bypass_update();
+ 
+ 	return 0;
+ }
+ 
+ int arch_prctl_spec_ctrl_set(struct task_struct *task, unsigned long which,
+ 			     unsigned long ctrl)
+ {
+ 	switch (which) {
+ 	case PR_SPEC_STORE_BYPASS:
+ 		return ssb_prctl_set(task, ctrl);
+ 	default:
+ 		return -ENODEV;
+ 	}
+ }
+ 
+ #ifdef CONFIG_SECCOMP
+ void arch_seccomp_spec_mitigate(struct task_struct *task)
+ {
+ 	ssb_prctl_set(task, PR_SPEC_FORCE_DISABLE);
+ }
+ #endif
+ 
+ static int ssb_prctl_get(struct task_struct *task)
+ {
+ 	switch (ssb_mode) {
+ 	case SPEC_STORE_BYPASS_DISABLE:
+ 		return PR_SPEC_DISABLE;
+ 	case SPEC_STORE_BYPASS_PRCTL:
+ 		if (task_spec_ssb_force_disable(task))
+ 			return PR_SPEC_PRCTL | PR_SPEC_FORCE_DISABLE;
+ 		if (task_spec_ssb_disable(task))
+ 			return PR_SPEC_PRCTL | PR_SPEC_DISABLE;
+ 		return PR_SPEC_PRCTL | PR_SPEC_ENABLE;
+ 	default:
+ 		if (boot_cpu_has_bug(X86_BUG_SPEC_STORE_BYPASS))
+ 			return PR_SPEC_ENABLE;
+ 		return PR_SPEC_NOT_AFFECTED;
+ 	}
+ }
+ 
+ int arch_prctl_spec_ctrl_get(struct task_struct *task, unsigned long which)
+ {
+ 	switch (which) {
+ 	case PR_SPEC_STORE_BYPASS:
+ 		return ssb_prctl_get(task);
+ 	default:
+ 		return -ENODEV;
+ 	}
+ }
+ 
+ void x86_spec_ctrl_setup_ap(void)
+ {
+ 	if (boot_cpu_has(X86_FEATURE_IBRS))
+ 		x86_spec_ctrl_set(x86_spec_ctrl_base & ~x86_spec_ctrl_mask);
+ 
+ 	if (ssb_mode == SPEC_STORE_BYPASS_DISABLE)
+ 		x86_amd_rds_enable();
+ }
++>>>>>>> 8bf37d8c067b (seccomp: Move speculation migitation control to arch code)
  
  #ifdef CONFIG_SYSFS
 -
 -ssize_t cpu_show_common(struct device *dev, struct device_attribute *attr,
 -			char *buf, unsigned int bug)
 +ssize_t cpu_show_meltdown(struct device *dev,
 +			  struct device_attribute *attr, char *buf)
  {
 -	if (!boot_cpu_has_bug(bug))
 +	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD)
  		return sprintf(buf, "Not affected\n");
 -
 -	switch (bug) {
 -	case X86_BUG_CPU_MELTDOWN:
 -		if (boot_cpu_has(X86_FEATURE_PTI))
 -			return sprintf(buf, "Mitigation: PTI\n");
 -
 -		break;
 -
 -	case X86_BUG_SPECTRE_V1:
 -		return sprintf(buf, "Mitigation: __user pointer sanitization\n");
 -
 -	case X86_BUG_SPECTRE_V2:
 -		return sprintf(buf, "%s%s%s%s\n", spectre_v2_strings[spectre_v2_enabled],
 -			       boot_cpu_has(X86_FEATURE_USE_IBPB) ? ", IBPB" : "",
 -			       boot_cpu_has(X86_FEATURE_USE_IBRS_FW) ? ", IBRS_FW" : "",
 -			       spectre_v2_module_string());
 -
 -	case X86_BUG_SPEC_STORE_BYPASS:
 -		return sprintf(buf, "%s\n", ssb_strings[ssb_mode]);
 -
 -	default:
 -		break;
 -	}
 -
 +	if (kaiser_enabled)
 +		return sprintf(buf, "Mitigation: PTI\n");
  	return sprintf(buf, "Vulnerable\n");
  }
  
diff --cc kernel/seccomp.c
index 42e55449c1a5,e691d9a6c58d..000000000000
--- a/kernel/seccomp.c
+++ b/kernel/seccomp.c
@@@ -236,8 -229,11 +236,13 @@@ static inline bool seccomp_may_assign_m
  	return true;
  }
  
++<<<<<<< HEAD
++=======
+ void __weak arch_seccomp_spec_mitigate(struct task_struct *task) { }
+ 
++>>>>>>> 8bf37d8c067b (seccomp: Move speculation migitation control to arch code)
  static inline void seccomp_assign_mode(struct task_struct *task,
 -				       unsigned long seccomp_mode,
 -				       unsigned long flags)
 +				       unsigned long seccomp_mode)
  {
  	assert_spin_locked(&task->sighand->siglock);
  
@@@ -247,6 -243,9 +252,12 @@@
  	 * filter) is set.
  	 */
  	smp_mb__before_atomic();
++<<<<<<< HEAD
++=======
+ 	/* Assume default seccomp processes want spec flaw mitigation. */
+ 	if ((flags & SECCOMP_FILTER_FLAG_SPEC_ALLOW) == 0)
+ 		arch_seccomp_spec_mitigate(task);
++>>>>>>> 8bf37d8c067b (seccomp: Move speculation migitation control to arch code)
  	set_tsk_thread_flag(task, TIF_SECCOMP);
  }
  
* Unmerged path include/linux/nospec.h
* Unmerged path arch/x86/kernel/cpu/bugs.c
* Unmerged path include/linux/nospec.h
* Unmerged path kernel/seccomp.c
