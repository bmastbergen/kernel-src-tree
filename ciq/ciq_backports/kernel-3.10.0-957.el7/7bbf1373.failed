nospec: Allow getting/setting on non-current task

jira LE-1907
cve CVE-2018-3639
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Kees Cook <keescook@chromium.org>
commit 7bbf1373e228840bb0295a2ca26d548ef37f448e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/7bbf1373.failed

Adjust arch_prctl_get/set_spec_ctrl() to operate on tasks other than
current.

This is needed both for /proc/$pid/status queries and for seccomp (since
thread-syncing can trigger seccomp in non-current threads).

	Signed-off-by: Kees Cook <keescook@chromium.org>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>

(cherry picked from commit 7bbf1373e228840bb0295a2ca26d548ef37f448e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/bugs.c
#	include/linux/nospec.h
#	kernel/sys.c
diff --cc arch/x86/kernel/cpu/bugs.c
index 29b8876b1f95,e3afb610f2ad..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -199,15 -405,233 +199,213 @@@ static void __init spectre_v2_select_mi
  }
  
  #undef pr_fmt
++<<<<<<< HEAD
++=======
+ #define pr_fmt(fmt)	"Speculative Store Bypass: " fmt
+ 
+ static enum ssb_mitigation ssb_mode = SPEC_STORE_BYPASS_NONE;
+ 
+ /* The kernel command line selection */
+ enum ssb_mitigation_cmd {
+ 	SPEC_STORE_BYPASS_CMD_NONE,
+ 	SPEC_STORE_BYPASS_CMD_AUTO,
+ 	SPEC_STORE_BYPASS_CMD_ON,
+ 	SPEC_STORE_BYPASS_CMD_PRCTL,
+ };
+ 
+ static const char *ssb_strings[] = {
+ 	[SPEC_STORE_BYPASS_NONE]	= "Vulnerable",
+ 	[SPEC_STORE_BYPASS_DISABLE]	= "Mitigation: Speculative Store Bypass disabled",
+ 	[SPEC_STORE_BYPASS_PRCTL]	= "Mitigation: Speculative Store Bypass disabled via prctl"
+ };
+ 
+ static const struct {
+ 	const char *option;
+ 	enum ssb_mitigation_cmd cmd;
+ } ssb_mitigation_options[] = {
+ 	{ "auto",	SPEC_STORE_BYPASS_CMD_AUTO },  /* Platform decides */
+ 	{ "on",		SPEC_STORE_BYPASS_CMD_ON },    /* Disable Speculative Store Bypass */
+ 	{ "off",	SPEC_STORE_BYPASS_CMD_NONE },  /* Don't touch Speculative Store Bypass */
+ 	{ "prctl",	SPEC_STORE_BYPASS_CMD_PRCTL }, /* Disable Speculative Store Bypass via prctl */
+ };
+ 
+ static enum ssb_mitigation_cmd __init ssb_parse_cmdline(void)
+ {
+ 	enum ssb_mitigation_cmd cmd = SPEC_STORE_BYPASS_CMD_AUTO;
+ 	char arg[20];
+ 	int ret, i;
+ 
+ 	if (cmdline_find_option_bool(boot_command_line, "nospec_store_bypass_disable")) {
+ 		return SPEC_STORE_BYPASS_CMD_NONE;
+ 	} else {
+ 		ret = cmdline_find_option(boot_command_line, "spec_store_bypass_disable",
+ 					  arg, sizeof(arg));
+ 		if (ret < 0)
+ 			return SPEC_STORE_BYPASS_CMD_AUTO;
+ 
+ 		for (i = 0; i < ARRAY_SIZE(ssb_mitigation_options); i++) {
+ 			if (!match_option(arg, ret, ssb_mitigation_options[i].option))
+ 				continue;
+ 
+ 			cmd = ssb_mitigation_options[i].cmd;
+ 			break;
+ 		}
+ 
+ 		if (i >= ARRAY_SIZE(ssb_mitigation_options)) {
+ 			pr_err("unknown option (%s). Switching to AUTO select\n", arg);
+ 			return SPEC_STORE_BYPASS_CMD_AUTO;
+ 		}
+ 	}
+ 
+ 	return cmd;
+ }
+ 
+ static enum ssb_mitigation_cmd __init __ssb_select_mitigation(void)
+ {
+ 	enum ssb_mitigation mode = SPEC_STORE_BYPASS_NONE;
+ 	enum ssb_mitigation_cmd cmd;
+ 
+ 	if (!boot_cpu_has(X86_FEATURE_RDS))
+ 		return mode;
+ 
+ 	cmd = ssb_parse_cmdline();
+ 	if (!boot_cpu_has_bug(X86_BUG_SPEC_STORE_BYPASS) &&
+ 	    (cmd == SPEC_STORE_BYPASS_CMD_NONE ||
+ 	     cmd == SPEC_STORE_BYPASS_CMD_AUTO))
+ 		return mode;
+ 
+ 	switch (cmd) {
+ 	case SPEC_STORE_BYPASS_CMD_AUTO:
+ 		/* Choose prctl as the default mode */
+ 		mode = SPEC_STORE_BYPASS_PRCTL;
+ 		break;
+ 	case SPEC_STORE_BYPASS_CMD_ON:
+ 		mode = SPEC_STORE_BYPASS_DISABLE;
+ 		break;
+ 	case SPEC_STORE_BYPASS_CMD_PRCTL:
+ 		mode = SPEC_STORE_BYPASS_PRCTL;
+ 		break;
+ 	case SPEC_STORE_BYPASS_CMD_NONE:
+ 		break;
+ 	}
+ 
+ 	/*
+ 	 * We have three CPU feature flags that are in play here:
+ 	 *  - X86_BUG_SPEC_STORE_BYPASS - CPU is susceptible.
+ 	 *  - X86_FEATURE_RDS - CPU is able to turn off speculative store bypass
+ 	 *  - X86_FEATURE_SPEC_STORE_BYPASS_DISABLE - engage the mitigation
+ 	 */
+ 	if (mode == SPEC_STORE_BYPASS_DISABLE) {
+ 		setup_force_cpu_cap(X86_FEATURE_SPEC_STORE_BYPASS_DISABLE);
+ 		/*
+ 		 * Intel uses the SPEC CTRL MSR Bit(2) for this, while AMD uses
+ 		 * a completely different MSR and bit dependent on family.
+ 		 */
+ 		switch (boot_cpu_data.x86_vendor) {
+ 		case X86_VENDOR_INTEL:
+ 			x86_spec_ctrl_base |= SPEC_CTRL_RDS;
+ 			x86_spec_ctrl_mask &= ~SPEC_CTRL_RDS;
+ 			x86_spec_ctrl_set(SPEC_CTRL_RDS);
+ 			break;
+ 		case X86_VENDOR_AMD:
+ 			x86_amd_rds_enable();
+ 			break;
+ 		}
+ 	}
+ 
+ 	return mode;
+ }
+ 
+ static void ssb_select_mitigation()
+ {
+ 	ssb_mode = __ssb_select_mitigation();
+ 
+ 	if (boot_cpu_has_bug(X86_BUG_SPEC_STORE_BYPASS))
+ 		pr_info("%s\n", ssb_strings[ssb_mode]);
+ }
+ 
+ #undef pr_fmt
+ 
+ static int ssb_prctl_set(struct task_struct *task, unsigned long ctrl)
+ {
+ 	bool rds = !!test_tsk_thread_flag(task, TIF_RDS);
+ 
+ 	if (ssb_mode != SPEC_STORE_BYPASS_PRCTL)
+ 		return -ENXIO;
+ 
+ 	if (ctrl == PR_SPEC_ENABLE)
+ 		clear_tsk_thread_flag(task, TIF_RDS);
+ 	else
+ 		set_tsk_thread_flag(task, TIF_RDS);
+ 
+ 	/*
+ 	 * If being set on non-current task, delay setting the CPU
+ 	 * mitigation until it is next scheduled.
+ 	 */
+ 	if (task == current && rds != !!test_tsk_thread_flag(task, TIF_RDS))
+ 		speculative_store_bypass_update();
+ 
+ 	return 0;
+ }
+ 
+ static int ssb_prctl_get(struct task_struct *task)
+ {
+ 	switch (ssb_mode) {
+ 	case SPEC_STORE_BYPASS_DISABLE:
+ 		return PR_SPEC_DISABLE;
+ 	case SPEC_STORE_BYPASS_PRCTL:
+ 		if (test_tsk_thread_flag(task, TIF_RDS))
+ 			return PR_SPEC_PRCTL | PR_SPEC_DISABLE;
+ 		return PR_SPEC_PRCTL | PR_SPEC_ENABLE;
+ 	default:
+ 		if (boot_cpu_has_bug(X86_BUG_SPEC_STORE_BYPASS))
+ 			return PR_SPEC_ENABLE;
+ 		return PR_SPEC_NOT_AFFECTED;
+ 	}
+ }
+ 
+ int arch_prctl_spec_ctrl_set(struct task_struct *task, unsigned long which,
+ 			     unsigned long ctrl)
+ {
+ 	if (ctrl != PR_SPEC_ENABLE && ctrl != PR_SPEC_DISABLE)
+ 		return -ERANGE;
+ 
+ 	switch (which) {
+ 	case PR_SPEC_STORE_BYPASS:
+ 		return ssb_prctl_set(task, ctrl);
+ 	default:
+ 		return -ENODEV;
+ 	}
+ }
+ 
+ int arch_prctl_spec_ctrl_get(struct task_struct *task, unsigned long which)
+ {
+ 	switch (which) {
+ 	case PR_SPEC_STORE_BYPASS:
+ 		return ssb_prctl_get(task);
+ 	default:
+ 		return -ENODEV;
+ 	}
+ }
+ 
+ void x86_spec_ctrl_setup_ap(void)
+ {
+ 	if (boot_cpu_has(X86_FEATURE_IBRS))
+ 		x86_spec_ctrl_set(x86_spec_ctrl_base & ~x86_spec_ctrl_mask);
+ 
+ 	if (ssb_mode == SPEC_STORE_BYPASS_DISABLE)
+ 		x86_amd_rds_enable();
+ }
++>>>>>>> 7bbf1373e228 (nospec: Allow getting/setting on non-current task)
  
  #ifdef CONFIG_SYSFS
 -
 -ssize_t cpu_show_common(struct device *dev, struct device_attribute *attr,
 -			char *buf, unsigned int bug)
 +ssize_t cpu_show_meltdown(struct device *dev,
 +			  struct device_attribute *attr, char *buf)
  {
 -	if (!boot_cpu_has_bug(bug))
 +	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD)
  		return sprintf(buf, "Not affected\n");
 -
 -	switch (bug) {
 -	case X86_BUG_CPU_MELTDOWN:
 -		if (boot_cpu_has(X86_FEATURE_PTI))
 -			return sprintf(buf, "Mitigation: PTI\n");
 -
 -		break;
 -
 -	case X86_BUG_SPECTRE_V1:
 -		return sprintf(buf, "Mitigation: __user pointer sanitization\n");
 -
 -	case X86_BUG_SPECTRE_V2:
 -		return sprintf(buf, "%s%s%s%s\n", spectre_v2_strings[spectre_v2_enabled],
 -			       boot_cpu_has(X86_FEATURE_USE_IBPB) ? ", IBPB" : "",
 -			       boot_cpu_has(X86_FEATURE_USE_IBRS_FW) ? ", IBRS_FW" : "",
 -			       spectre_v2_module_string());
 -
 -	case X86_BUG_SPEC_STORE_BYPASS:
 -		return sprintf(buf, "%s\n", ssb_strings[ssb_mode]);
 -
 -	default:
 -		break;
 -	}
 -
 +	if (kaiser_enabled)
 +		return sprintf(buf, "Mitigation: PTI\n");
  	return sprintf(buf, "Vulnerable\n");
  }
  
diff --cc kernel/sys.c
index 113961cf6711,b0eee418ee0d..000000000000
--- a/kernel/sys.c
+++ b/kernel/sys.c
@@@ -2321,6 -2226,35 +2321,38 @@@ static int prctl_get_tid_address(struc
  }
  #endif
  
++<<<<<<< HEAD
++=======
+ static int propagate_has_child_subreaper(struct task_struct *p, void *data)
+ {
+ 	/*
+ 	 * If task has has_child_subreaper - all its decendants
+ 	 * already have these flag too and new decendants will
+ 	 * inherit it on fork, skip them.
+ 	 *
+ 	 * If we've found child_reaper - skip descendants in
+ 	 * it's subtree as they will never get out pidns.
+ 	 */
+ 	if (p->signal->has_child_subreaper ||
+ 	    is_child_reaper(task_pid(p)))
+ 		return 0;
+ 
+ 	p->signal->has_child_subreaper = 1;
+ 	return 1;
+ }
+ 
+ int __weak arch_prctl_spec_ctrl_get(struct task_struct *t, unsigned long which)
+ {
+ 	return -EINVAL;
+ }
+ 
+ int __weak arch_prctl_spec_ctrl_set(struct task_struct *t, unsigned long which,
+ 				    unsigned long ctrl)
+ {
+ 	return -EINVAL;
+ }
+ 
++>>>>>>> 7bbf1373e228 (nospec: Allow getting/setting on non-current task)
  SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
  		unsigned long, arg4, unsigned long, arg5)
  {
@@@ -2503,8 -2445,34 +2535,33 @@@
  		error = MPX_ENABLE_MANAGEMENT();
  		break;
  	case PR_MPX_DISABLE_MANAGEMENT:
 -		if (arg2 || arg3 || arg4 || arg5)
 -			return -EINVAL;
  		error = MPX_DISABLE_MANAGEMENT();
  		break;
++<<<<<<< HEAD
++=======
+ 	case PR_SET_FP_MODE:
+ 		error = SET_FP_MODE(me, arg2);
+ 		break;
+ 	case PR_GET_FP_MODE:
+ 		error = GET_FP_MODE(me);
+ 		break;
+ 	case PR_SVE_SET_VL:
+ 		error = SVE_SET_VL(arg2);
+ 		break;
+ 	case PR_SVE_GET_VL:
+ 		error = SVE_GET_VL();
+ 		break;
+ 	case PR_GET_SPECULATION_CTRL:
+ 		if (arg3 || arg4 || arg5)
+ 			return -EINVAL;
+ 		error = arch_prctl_spec_ctrl_get(me, arg2);
+ 		break;
+ 	case PR_SET_SPECULATION_CTRL:
+ 		if (arg4 || arg5)
+ 			return -EINVAL;
+ 		error = arch_prctl_spec_ctrl_set(me, arg2, arg3);
+ 		break;
++>>>>>>> 7bbf1373e228 (nospec: Allow getting/setting on non-current task)
  	default:
  		error = -EINVAL;
  		break;
* Unmerged path include/linux/nospec.h
* Unmerged path arch/x86/kernel/cpu/bugs.c
* Unmerged path include/linux/nospec.h
* Unmerged path kernel/sys.c
