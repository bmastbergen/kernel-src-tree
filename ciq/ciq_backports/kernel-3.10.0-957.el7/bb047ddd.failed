net: sched: don't set q pointer for shared blocks

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [net] sched: don't set q pointer for shared blocks (Ivan Vecera) [1584592]
Rebuild_FUZZ: 94.62%
commit-author Jiri Pirko <jiri@mellanox.com>
commit bb047ddd145860ff24820320a21f03cf8c071b22
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/bb047ddd.failed

It is pointless to set block->q for block which are shared among
multiple qdiscs. So remove the assignment in that case. Do a bit of code
reshuffle to make block->index initialized at that point so we can use
tcf_block_shared() helper.

	Reported-by: Cong Wang <xiyou.wangcong@gmail.com>
Fixes: 4861738775d7 ("net: sched: introduce shared filter blocks infrastructure")
	Signed-off-by: Jiri Pirko <jiri@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit bb047ddd145860ff24820320a21f03cf8c071b22)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/sched/cls_api.c
diff --cc net/sched/cls_api.c
index a56916c8abe9,a7dc7271042a..000000000000
--- a/net/sched/cls_api.c
+++ b/net/sched/cls_api.c
@@@ -244,11 -268,307 +244,229 @@@ void tcf_chain_put(struct tcf_chain *ch
  }
  EXPORT_SYMBOL(tcf_chain_put);
  
 -static bool tcf_block_offload_in_use(struct tcf_block *block)
 -{
 -	return block->offloadcnt;
 -}
 -
 -static int tcf_block_offload_cmd(struct tcf_block *block,
 -				 struct net_device *dev,
 -				 struct tcf_block_ext_info *ei,
 -				 enum tc_block_command command)
 -{
 -	struct tc_block_offload bo = {};
 -
 -	bo.command = command;
 -	bo.binder_type = ei->binder_type;
 -	bo.block = block;
 -	return dev->netdev_ops->ndo_setup_tc(dev, TC_SETUP_BLOCK, &bo);
 -}
 -
 -static int tcf_block_offload_bind(struct tcf_block *block, struct Qdisc *q,
 -				  struct tcf_block_ext_info *ei)
 -{
 -	struct net_device *dev = q->dev_queue->dev;
 -	int err;
 -
 -	if (!dev->netdev_ops->ndo_setup_tc)
 -		goto no_offload_dev_inc;
 -
 -	/* If tc offload feature is disabled and the block we try to bind
 -	 * to already has some offloaded filters, forbid to bind.
 -	 */
 -	if (!tc_can_offload(dev) && tcf_block_offload_in_use(block))
 -		return -EOPNOTSUPP;
 -
 -	err = tcf_block_offload_cmd(block, dev, ei, TC_BLOCK_BIND);
 -	if (err == -EOPNOTSUPP)
 -		goto no_offload_dev_inc;
 -	return err;
 -
 -no_offload_dev_inc:
 -	if (tcf_block_offload_in_use(block))
 -		return -EOPNOTSUPP;
 -	block->nooffloaddevcnt++;
 -	return 0;
 -}
 -
 -static void tcf_block_offload_unbind(struct tcf_block *block, struct Qdisc *q,
 -				     struct tcf_block_ext_info *ei)
 -{
 -	struct net_device *dev = q->dev_queue->dev;
 -	int err;
 -
 -	if (!dev->netdev_ops->ndo_setup_tc)
 -		goto no_offload_dev_dec;
 -	err = tcf_block_offload_cmd(block, dev, ei, TC_BLOCK_UNBIND);
 -	if (err == -EOPNOTSUPP)
 -		goto no_offload_dev_dec;
 -	return;
 -
 -no_offload_dev_dec:
 -	WARN_ON(block->nooffloaddevcnt-- == 0);
 -}
 -
 -static int
 -tcf_chain_head_change_cb_add(struct tcf_chain *chain,
 -			     struct tcf_block_ext_info *ei,
 -			     struct netlink_ext_ack *extack)
 -{
 -	struct tcf_filter_chain_list_item *item;
 -
 -	item = kmalloc(sizeof(*item), GFP_KERNEL);
 -	if (!item) {
 -		NL_SET_ERR_MSG(extack, "Memory allocation for head change callback item failed");
 -		return -ENOMEM;
 -	}
 -	item->chain_head_change = ei->chain_head_change;
 -	item->chain_head_change_priv = ei->chain_head_change_priv;
 -	if (chain->filter_chain)
 -		tcf_chain_head_change_item(item, chain->filter_chain);
 -	list_add(&item->list, &chain->filter_chain_list);
 -	return 0;
 -}
 -
  static void
 -tcf_chain_head_change_cb_del(struct tcf_chain *chain,
 -			     struct tcf_block_ext_info *ei)
 +tcf_chain_filter_chain_ptr_set(struct tcf_chain *chain,
 +			       struct tcf_proto __rcu **p_filter_chain)
  {
++<<<<<<< HEAD
 +	chain->p_filter_chain = p_filter_chain;
++=======
+ 	struct tcf_filter_chain_list_item *item;
+ 
+ 	list_for_each_entry(item, &chain->filter_chain_list, list) {
+ 		if ((!ei->chain_head_change && !ei->chain_head_change_priv) ||
+ 		    (item->chain_head_change == ei->chain_head_change &&
+ 		     item->chain_head_change_priv == ei->chain_head_change_priv)) {
+ 			tcf_chain_head_change_item(item, NULL);
+ 			list_del(&item->list);
+ 			kfree(item);
+ 			return;
+ 		}
+ 	}
+ 	WARN_ON(1);
+ }
+ 
+ struct tcf_net {
+ 	struct idr idr;
+ };
+ 
+ static unsigned int tcf_net_id;
+ 
+ static int tcf_block_insert(struct tcf_block *block, struct net *net,
+ 			    struct netlink_ext_ack *extack)
+ {
+ 	struct tcf_net *tn = net_generic(net, tcf_net_id);
+ 
+ 	return idr_alloc_u32(&tn->idr, block, &block->index, block->index,
+ 			     GFP_KERNEL);
+ }
+ 
+ static void tcf_block_remove(struct tcf_block *block, struct net *net)
+ {
+ 	struct tcf_net *tn = net_generic(net, tcf_net_id);
+ 
+ 	idr_remove(&tn->idr, block->index);
+ }
+ 
+ static struct tcf_block *tcf_block_create(struct net *net, struct Qdisc *q,
+ 					  u32 block_index,
+ 					  struct netlink_ext_ack *extack)
+ {
+ 	struct tcf_block *block;
+ 	struct tcf_chain *chain;
+ 	int err;
+ 
+ 	block = kzalloc(sizeof(*block), GFP_KERNEL);
+ 	if (!block) {
+ 		NL_SET_ERR_MSG(extack, "Memory allocation for block failed");
+ 		return ERR_PTR(-ENOMEM);
+ 	}
+ 	INIT_LIST_HEAD(&block->chain_list);
+ 	INIT_LIST_HEAD(&block->cb_list);
+ 	INIT_LIST_HEAD(&block->owner_list);
+ 
+ 	/* Create chain 0 by default, it has to be always present. */
+ 	chain = tcf_chain_create(block, 0);
+ 	if (!chain) {
+ 		NL_SET_ERR_MSG(extack, "Failed to create new tcf chain");
+ 		err = -ENOMEM;
+ 		goto err_chain_create;
+ 	}
+ 	block->refcnt = 1;
+ 	block->net = net;
+ 	block->index = block_index;
+ 
+ 	/* Don't store q pointer for blocks which are shared */
+ 	if (!tcf_block_shared(block))
+ 		block->q = q;
+ 	return block;
+ 
+ err_chain_create:
+ 	kfree(block);
+ 	return ERR_PTR(err);
+ }
+ 
+ static struct tcf_block *tcf_block_lookup(struct net *net, u32 block_index)
+ {
+ 	struct tcf_net *tn = net_generic(net, tcf_net_id);
+ 
+ 	return idr_find(&tn->idr, block_index);
+ }
+ 
+ static struct tcf_chain *tcf_block_chain_zero(struct tcf_block *block)
+ {
+ 	return list_first_entry(&block->chain_list, struct tcf_chain, list);
+ }
+ 
+ struct tcf_block_owner_item {
+ 	struct list_head list;
+ 	struct Qdisc *q;
+ 	enum tcf_block_binder_type binder_type;
+ };
+ 
+ static void
+ tcf_block_owner_netif_keep_dst(struct tcf_block *block,
+ 			       struct Qdisc *q,
+ 			       enum tcf_block_binder_type binder_type)
+ {
+ 	if (block->keep_dst &&
+ 	    binder_type != TCF_BLOCK_BINDER_TYPE_CLSACT_INGRESS &&
+ 	    binder_type != TCF_BLOCK_BINDER_TYPE_CLSACT_EGRESS)
+ 		netif_keep_dst(qdisc_dev(q));
+ }
+ 
+ void tcf_block_netif_keep_dst(struct tcf_block *block)
+ {
+ 	struct tcf_block_owner_item *item;
+ 
+ 	block->keep_dst = true;
+ 	list_for_each_entry(item, &block->owner_list, list)
+ 		tcf_block_owner_netif_keep_dst(block, item->q,
+ 					       item->binder_type);
+ }
+ EXPORT_SYMBOL(tcf_block_netif_keep_dst);
+ 
+ static int tcf_block_owner_add(struct tcf_block *block,
+ 			       struct Qdisc *q,
+ 			       enum tcf_block_binder_type binder_type)
+ {
+ 	struct tcf_block_owner_item *item;
+ 
+ 	item = kmalloc(sizeof(*item), GFP_KERNEL);
+ 	if (!item)
+ 		return -ENOMEM;
+ 	item->q = q;
+ 	item->binder_type = binder_type;
+ 	list_add(&item->list, &block->owner_list);
+ 	return 0;
+ }
+ 
+ static void tcf_block_owner_del(struct tcf_block *block,
+ 				struct Qdisc *q,
+ 				enum tcf_block_binder_type binder_type)
+ {
+ 	struct tcf_block_owner_item *item;
+ 
+ 	list_for_each_entry(item, &block->owner_list, list) {
+ 		if (item->q == q && item->binder_type == binder_type) {
+ 			list_del(&item->list);
+ 			kfree(item);
+ 			return;
+ 		}
+ 	}
+ 	WARN_ON(1);
+ }
+ 
+ int tcf_block_get_ext(struct tcf_block **p_block, struct Qdisc *q,
+ 		      struct tcf_block_ext_info *ei,
+ 		      struct netlink_ext_ack *extack)
+ {
+ 	struct net *net = qdisc_net(q);
+ 	struct tcf_block *block = NULL;
+ 	bool created = false;
+ 	int err;
+ 
+ 	if (ei->block_index) {
+ 		/* block_index not 0 means the shared block is requested */
+ 		block = tcf_block_lookup(net, ei->block_index);
+ 		if (block)
+ 			block->refcnt++;
+ 	}
+ 
+ 	if (!block) {
+ 		block = tcf_block_create(net, q, ei->block_index, extack);
+ 		if (IS_ERR(block))
+ 			return PTR_ERR(block);
+ 		created = true;
+ 		if (tcf_block_shared(block)) {
+ 			err = tcf_block_insert(block, net, extack);
+ 			if (err)
+ 				goto err_block_insert;
+ 		}
+ 	}
+ 
+ 	err = tcf_block_owner_add(block, q, ei->binder_type);
+ 	if (err)
+ 		goto err_block_owner_add;
+ 
+ 	tcf_block_owner_netif_keep_dst(block, q, ei->binder_type);
+ 
+ 	err = tcf_chain_head_change_cb_add(tcf_block_chain_zero(block),
+ 					   ei, extack);
+ 	if (err)
+ 		goto err_chain_head_change_cb_add;
+ 
+ 	err = tcf_block_offload_bind(block, q, ei);
+ 	if (err)
+ 		goto err_block_offload_bind;
+ 
+ 	*p_block = block;
+ 	return 0;
+ 
+ err_block_offload_bind:
+ 	tcf_chain_head_change_cb_del(tcf_block_chain_zero(block), ei);
+ err_chain_head_change_cb_add:
+ 	tcf_block_owner_del(block, q, ei->binder_type);
+ err_block_owner_add:
+ 	if (created) {
+ 		if (tcf_block_shared(block))
+ 			tcf_block_remove(block, net);
+ err_block_insert:
+ 		kfree(tcf_block_chain_zero(block));
+ 		kfree(block);
+ 	} else {
+ 		block->refcnt--;
+ 	}
+ 	return err;
+ }
+ EXPORT_SYMBOL(tcf_block_get_ext);
+ 
+ static void tcf_chain_head_change_dflt(struct tcf_proto *tp_head, void *priv)
+ {
+ 	struct tcf_proto __rcu **p_filter_chain = priv;
+ 
+ 	rcu_assign_pointer(*p_filter_chain, tp_head);
++>>>>>>> bb047ddd1458 (net: sched: don't set q pointer for shared blocks)
  }
  
  int tcf_block_get(struct tcf_block **p_block,
* Unmerged path net/sched/cls_api.c
