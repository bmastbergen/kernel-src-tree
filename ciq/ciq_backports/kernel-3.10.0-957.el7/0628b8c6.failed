memremap: remove to_vmem_altmap

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Christoph Hellwig <hch@lst.de>
commit 0628b8c650718f4dfedfcdc9ed136bf7e394aae7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/0628b8c6.failed

All callers are gone now.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Dan Williams <dan.j.williams@intel.com>
(cherry picked from commit 0628b8c650718f4dfedfcdc9ed136bf7e394aae7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/memremap.h
#	kernel/memremap.c
diff --cc include/linux/memremap.h
index c4c41ebb44e1,3fddcfe57bb0..000000000000
--- a/include/linux/memremap.h
+++ b/include/linux/memremap.h
@@@ -23,18 -26,6 +23,21 @@@ struct vmem_altmap 
  	unsigned long alloc;
  };
  
++<<<<<<< HEAD
 +unsigned long vmem_altmap_offset(struct vmem_altmap *altmap);
 +void vmem_altmap_free(struct vmem_altmap *altmap, unsigned long nr_pfns);
 +
 +#if defined(CONFIG_SPARSEMEM_VMEMMAP) && defined(CONFIG_ZONE_DEVICE)
 +struct vmem_altmap *to_vmem_altmap(unsigned long memmap_start);
 +#else
 +static inline struct vmem_altmap *to_vmem_altmap(unsigned long memmap_start)
 +{
 +	return NULL;
 +}
 +#endif
 +
++=======
++>>>>>>> 0628b8c65071 (memremap: remove to_vmem_altmap)
  /*
   * Specialize ZONE_DEVICE memory into multiple types each having differents
   * usage.
diff --cc kernel/memremap.c
index 00f3d3b53574,b09517439dec..000000000000
--- a/kernel/memremap.c
+++ b/kernel/memremap.c
@@@ -490,31 -476,61 +490,67 @@@ void vmem_altmap_free(struct vmem_altma
  	altmap->alloc -= nr_pfns;
  }
  
++<<<<<<< HEAD
 +#ifdef CONFIG_SPARSEMEM_VMEMMAP
 +struct vmem_altmap *to_vmem_altmap(unsigned long memmap_start)
 +{
 +	/*
 +	 * 'memmap_start' is the virtual address for the first "struct
 +	 * page" in this range of the vmemmap array.  In the case of
 +	 * CONFIG_SPARSE_VMEMMAP a page_to_pfn conversion is simple
 +	 * pointer arithmetic, so we can perform this to_vmem_altmap()
 +	 * conversion without concern for the initialization state of
 +	 * the struct page fields.
 +	 */
 +	struct page *page = (struct page *) memmap_start;
 +	struct dev_pagemap *pgmap;
 +
 +	/*
 +	 * Uncoditionally retrieve a dev_pagemap associated with the
 +	 * given physical address, this is only for use in the
 +	 * arch_{add|remove}_memory() for setting up and tearing down
 +	 * the memmap.
 +	 */
 +	rcu_read_lock();
 +	pgmap = find_dev_pagemap(__pfn_to_phys(page_to_pfn(page)));
 +	rcu_read_unlock();
 +
 +	return pgmap ? pgmap->altmap : NULL;
 +}
 +#endif /* CONFIG_SPARSEMEM_VMEMMAP */
++=======
+ /**
+  * get_dev_pagemap() - take a new live reference on the dev_pagemap for @pfn
+  * @pfn: page frame number to lookup page_map
+  * @pgmap: optional known pgmap that already has a reference
+  *
+  * If @pgmap is non-NULL and covers @pfn it will be returned as-is.  If @pgmap
+  * is non-NULL but does not cover @pfn the reference to it will be released.
+  */
+ struct dev_pagemap *get_dev_pagemap(unsigned long pfn,
+ 		struct dev_pagemap *pgmap)
+ {
+ 	resource_size_t phys = PFN_PHYS(pfn);
+ 
+ 	/*
+ 	 * In the cached case we're already holding a live reference.
+ 	 */
+ 	if (pgmap) {
+ 		const struct resource *res = pgmap ? pgmap->res : NULL;
+ 
+ 		if (res && phys >= res->start && phys <= res->end)
+ 			return pgmap;
+ 		put_dev_pagemap(pgmap);
+ 	}
+ 
+ 	/* fall back to slow path lookup */
+ 	rcu_read_lock();
+ 	pgmap = find_dev_pagemap(phys);
+ 	if (pgmap && !percpu_ref_tryget_live(pgmap->ref))
+ 		pgmap = NULL;
+ 	rcu_read_unlock();
+ 
+ 	return pgmap;
+ }
++>>>>>>> 0628b8c65071 (memremap: remove to_vmem_altmap)
  #endif /* CONFIG_ZONE_DEVICE */
 -
 -#if IS_ENABLED(CONFIG_DEVICE_PRIVATE) ||  IS_ENABLED(CONFIG_DEVICE_PUBLIC)
 -void put_zone_device_private_or_public_page(struct page *page)
 -{
 -	int count = page_ref_dec_return(page);
 -
 -	/*
 -	 * If refcount is 1 then page is freed and refcount is stable as nobody
 -	 * holds a reference on the page.
 -	 */
 -	if (count == 1) {
 -		/* Clear Active bit in case of parallel mark_page_accessed */
 -		__ClearPageActive(page);
 -		__ClearPageWaiters(page);
 -
 -		page->mapping = NULL;
 -		mem_cgroup_uncharge(page);
 -
 -		page->pgmap->page_free(page, page->pgmap->data);
 -	} else if (!count)
 -		__put_page(page);
 -}
 -EXPORT_SYMBOL(put_zone_device_private_or_public_page);
 -#endif /* CONFIG_DEVICE_PRIVATE || CONFIG_DEVICE_PUBLIC */
* Unmerged path include/linux/memremap.h
* Unmerged path kernel/memremap.c
