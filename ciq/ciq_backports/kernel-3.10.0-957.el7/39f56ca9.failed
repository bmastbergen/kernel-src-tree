bpf, x64: fix memleak when not converging on calls

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Daniel Borkmann <daniel@iogearbox.net>
commit 39f56ca945af86112753646316c4c92dcd4acd82
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/39f56ca9.failed

The JIT logic in jit_subprogs() is as follows: for all subprogs we
allocate a bpf_prog_alloc(), populate it (prog->is_func = 1 here),
and pass it to bpf_int_jit_compile(). If a failure occurred during
JIT and prog->jited is not set, then we bail out from attempting to
JIT the whole program, and punt to the interpreter instead. In case
JITing went successful, we fixup BPF call offsets and do another
pass to bpf_int_jit_compile() (extra_pass is true at that point) to
complete JITing calls. Given that requires to pass JIT context around
addrs and jit_data from x86 JIT are freed in the extra_pass in
bpf_int_jit_compile() when calls are involved (if not, they can
be freed immediately). However, if in the original pass, the JIT
image didn't converge then we leak addrs and jit_data since image
itself is NULL, the prog->is_func is set and extra_pass is false
in that case, meaning both will become unreachable and are never
cleaned up, therefore we need to free as well on !image. Only x64
JIT is affected.

Fixes: 1c2a088a6626 ("bpf: x64: add JIT support for multi-function programs")
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Acked-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: David S. Miller <davem@davemloft.net>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
(cherry picked from commit 39f56ca945af86112753646316c4c92dcd4acd82)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/net/bpf_jit_comp.c
diff --cc arch/x86/net/bpf_jit_comp.c
index 76c7b3a140ad,263c8453815e..000000000000
--- a/arch/x86/net/bpf_jit_comp.c
+++ b/arch/x86/net/bpf_jit_comp.c
@@@ -738,31 -1263,35 +738,55 @@@ cond_branch:			f_offset = addrs[i + fil
  	}
  
  	if (bpf_jit_enable > 1)
 -		bpf_jit_dump(prog->len, proglen, pass + 1, image);
 +		bpf_jit_dump(flen, proglen, pass, image);
  
  	if (image) {
++<<<<<<< HEAD
 +		bpf_flush_icache(image, image + proglen);
 +		fp->bpf_func = (void *)image;
++=======
+ 		if (!prog->is_func || extra_pass) {
+ 			bpf_jit_binary_lock_ro(header);
+ 		} else {
+ 			jit_data->addrs = addrs;
+ 			jit_data->ctx = ctx;
+ 			jit_data->proglen = proglen;
+ 			jit_data->image = image;
+ 			jit_data->header = header;
+ 		}
+ 		prog->bpf_func = (void *)image;
+ 		prog->jited = 1;
+ 		prog->jited_len = proglen;
+ 	} else {
+ 		prog = orig_prog;
+ 	}
+ 
+ 	if (!image || !prog->is_func || extra_pass) {
+ out_addrs:
+ 		kfree(addrs);
+ 		kfree(jit_data);
+ 		prog->aux->jit_data = NULL;
++>>>>>>> 39f56ca945af (bpf, x64: fix memleak when not converging on calls)
  	}
  out:
 -	if (tmp_blinded)
 -		bpf_jit_prog_release_other(prog, prog == orig_prog ?
 -					   tmp : orig_prog);
 -	return prog;
 +	kfree(addrs);
 +	return;
 +}
 +
 +static void jit_free_defer(struct work_struct *arg)
 +{
 +	module_free(NULL, arg);
 +}
 +
 +/* run from softirq, we must use a work_struct to call
 + * module_free() from process context
 + */
 +void bpf_jit_free(struct sk_filter *fp)
 +{
 +	if (fp->bpf_func != sk_run_filter) {
 +		struct work_struct *work = (struct work_struct *)fp->bpf_func;
 +
 +		INIT_WORK(work, jit_free_defer);
 +		schedule_work(work);
 +	}
  }
* Unmerged path arch/x86/net/bpf_jit_comp.c
