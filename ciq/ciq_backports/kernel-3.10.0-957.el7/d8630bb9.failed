scsi: qla2xxx: Serialize session deletion by using work_lock

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [scsi] qla2xxx: Serialize session deletion by using work_lock (Himanshu Madhani) [1547714]
Rebuild_FUZZ: 94.74%
commit-author Quinn Tran <quinn.tran@cavium.com>
commit d8630bb95f46ea118dede63bd75533faa64f9612
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/d8630bb9.failed

for session deletion, replace sess_lock with work_lock.
Under certain case sess_lock is not feasiable to acquire.
The lock is needed temporarily to make sure a single
call to schedule of the work element.

	Signed-off-by: Quinn Tran <quinn.tran@cavium.com>
	Signed-off-by: Himanshu Madhani <himanshu.madhani@cavium.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit d8630bb95f46ea118dede63bd75533faa64f9612)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/qla2xxx/qla_gbl.h
#	drivers/scsi/qla2xxx/qla_gs.c
#	drivers/scsi/qla2xxx/qla_init.c
#	drivers/scsi/qla2xxx/qla_mbx.c
#	drivers/scsi/qla2xxx/qla_os.c
#	drivers/scsi/qla2xxx/qla_target.c
diff --cc drivers/scsi/qla2xxx/qla_gbl.h
index b82df4e47b9c,e9295398050c..000000000000
--- a/drivers/scsi/qla2xxx/qla_gbl.h
+++ b/drivers/scsi/qla2xxx/qla_gbl.h
@@@ -854,8 -887,7 +854,12 @@@ void qla24xx_do_nack_work(struct scsi_q
  void qlt_plogi_ack_link(struct scsi_qla_host *, struct qlt_plogi_ack_t *,
  	struct fc_port *, enum qlt_plogi_link_t);
  void qlt_plogi_ack_unref(struct scsi_qla_host *, struct qlt_plogi_ack_t *);
++<<<<<<< HEAD
 +extern void qlt_schedule_sess_for_deletion(struct fc_port *, bool);
 +extern void qlt_schedule_sess_for_deletion_lock(struct fc_port *);
++=======
+ extern void qlt_schedule_sess_for_deletion(struct fc_port *);
++>>>>>>> d8630bb95f46 (scsi: qla2xxx: Serialize session deletion by using work_lock)
  extern struct fc_port *qlt_find_sess_invalidate_other(scsi_qla_host_t *,
  	uint64_t wwn, port_id_t port_id, uint16_t loop_id, struct fc_port **);
  void qla24xx_delete_sess_fn(struct work_struct *);
diff --cc drivers/scsi/qla2xxx/qla_gs.c
index 0dfd63fae4b1,6bfe24eeb402..000000000000
--- a/drivers/scsi/qla2xxx/qla_gs.c
+++ b/drivers/scsi/qla2xxx/qla_gs.c
@@@ -3143,43 -3410,137 +3143,159 @@@ void qla24xx_async_gpnid_done(scsi_qla_
  
  void qla24xx_handle_gpnid_event(scsi_qla_host_t *vha, struct event_arg *ea)
  {
 -	fc_port_t *fcport, *conflict, *t;
 -	u16 data[2];
 +	fc_port_t *fcport;
 +	unsigned long flags;
  
 -	ql_dbg(ql_dbg_disc, vha, 0xffff,
 -	    "%s %d port_id: %06x\n",
 -	    __func__, __LINE__, ea->id.b24);
 +	spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
 +	fcport = qla2x00_find_fcport_by_wwpn(vha, ea->port_name, 1);
 +	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
  
++<<<<<<< HEAD
 +	if (fcport) {
 +		/* cable moved. just plugged in */
 +		fcport->rscn_gen++;
 +		fcport->d_id = ea->id;
 +		fcport->scan_state = QLA_FCPORT_FOUND;
 +		fcport->flags |= FCF_FABRIC_DEVICE;
 +
 +		switch (fcport->disc_state) {
 +		case DSC_DELETED:
 +			ql_dbg(ql_dbg_disc, vha, 0x210d,
 +			    "%s %d %8phC login\n", __func__, __LINE__,
 +			    fcport->port_name);
 +			qla24xx_fcport_handle_login(vha, fcport);
 +			break;
 +		case DSC_DELETE_PEND:
 +			break;
 +		default:
 +			ql_dbg(ql_dbg_disc, vha, 0x2064,
 +			    "%s %d %8phC post del sess\n",
 +			    __func__, __LINE__, fcport->port_name);
 +			qlt_schedule_sess_for_deletion_lock(fcport);
 +			break;
++=======
+ 	if (ea->rc) {
+ 		/* cable is disconnected */
+ 		list_for_each_entry_safe(fcport, t, &vha->vp_fcports, list) {
+ 			if (fcport->d_id.b24 == ea->id.b24) {
+ 				ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 				    "%s %d %8phC DS %d\n",
+ 				    __func__, __LINE__,
+ 				    fcport->port_name,
+ 				    fcport->disc_state);
+ 				fcport->scan_state = QLA_FCPORT_SCAN;
+ 				switch (fcport->disc_state) {
+ 				case DSC_DELETED:
+ 				case DSC_DELETE_PEND:
+ 					break;
+ 				default:
+ 					ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 					    "%s %d %8phC post del sess\n",
+ 					    __func__, __LINE__,
+ 					    fcport->port_name);
+ 					qlt_schedule_sess_for_deletion(fcport);
+ 					break;
+ 				}
+ 			}
++>>>>>>> d8630bb95f46 (scsi: qla2xxx: Serialize session deletion by using work_lock)
  		}
  	} else {
 -		/* cable is connected */
 -		fcport = qla2x00_find_fcport_by_wwpn(vha, ea->port_name, 1);
 -		if (fcport) {
 -			list_for_each_entry_safe(conflict, t, &vha->vp_fcports,
 -			    list) {
 -				if ((conflict->d_id.b24 == ea->id.b24) &&
 -				    (fcport != conflict)) {
 -					/* 2 fcports with conflict Nport ID or
 -					 * an existing fcport is having nport ID
 -					 * conflict with new fcport.
 -					 */
 -
 +		/* create new fcport */
 +		ql_dbg(ql_dbg_disc, vha, 0x2065,
 +		    "%s %d %8phC post new sess\n",
 +		    __func__, __LINE__, ea->port_name);
 +
++<<<<<<< HEAD
 +		qla24xx_post_newsess_work(vha, &ea->id, ea->port_name, NULL);
++=======
+ 					ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 					    "%s %d %8phC DS %d\n",
+ 					    __func__, __LINE__,
+ 					    conflict->port_name,
+ 					    conflict->disc_state);
+ 					conflict->scan_state = QLA_FCPORT_SCAN;
+ 					switch (conflict->disc_state) {
+ 					case DSC_DELETED:
+ 					case DSC_DELETE_PEND:
+ 						break;
+ 					default:
+ 						ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 						    "%s %d %8phC post del sess\n",
+ 						    __func__, __LINE__,
+ 						    conflict->port_name);
+ 						qlt_schedule_sess_for_deletion
+ 							(conflict);
+ 						break;
+ 					}
+ 				}
+ 			}
+ 
+ 			fcport->rscn_gen++;
+ 			fcport->scan_state = QLA_FCPORT_FOUND;
+ 			fcport->flags |= FCF_FABRIC_DEVICE;
+ 			switch (fcport->disc_state) {
+ 			case DSC_LOGIN_COMPLETE:
+ 				/* recheck session is still intact. */
+ 				ql_dbg(ql_dbg_disc, vha, 0x210d,
+ 				    "%s %d %8phC revalidate session with ADISC\n",
+ 				    __func__, __LINE__, fcport->port_name);
+ 				data[0] = data[1] = 0;
+ 				qla2x00_post_async_adisc_work(vha, fcport,
+ 				    data);
+ 				break;
+ 			case DSC_DELETED:
+ 				ql_dbg(ql_dbg_disc, vha, 0x210d,
+ 				    "%s %d %8phC login\n", __func__, __LINE__,
+ 				    fcport->port_name);
+ 				fcport->d_id = ea->id;
+ 				qla24xx_fcport_handle_login(vha, fcport);
+ 				break;
+ 			case DSC_DELETE_PEND:
+ 				fcport->d_id = ea->id;
+ 				break;
+ 			default:
+ 				fcport->d_id = ea->id;
+ 				break;
+ 			}
+ 		} else {
+ 			list_for_each_entry_safe(conflict, t, &vha->vp_fcports,
+ 			    list) {
+ 				if (conflict->d_id.b24 == ea->id.b24) {
+ 					/* 2 fcports with conflict Nport ID or
+ 					 * an existing fcport is having nport ID
+ 					 * conflict with new fcport.
+ 					 */
+ 					ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 					    "%s %d %8phC DS %d\n",
+ 					    __func__, __LINE__,
+ 					    conflict->port_name,
+ 					    conflict->disc_state);
+ 
+ 					conflict->scan_state = QLA_FCPORT_SCAN;
+ 					switch (conflict->disc_state) {
+ 					case DSC_DELETED:
+ 					case DSC_DELETE_PEND:
+ 						break;
+ 					default:
+ 						ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 						    "%s %d %8phC post del sess\n",
+ 						    __func__, __LINE__,
+ 						    conflict->port_name);
+ 						qlt_schedule_sess_for_deletion
+ 							(conflict);
+ 						break;
+ 					}
+ 				}
+ 			}
+ 
+ 			/* create new fcport */
+ 			ql_dbg(ql_dbg_disc, vha, 0x2065,
+ 			    "%s %d %8phC post new sess\n",
+ 			    __func__, __LINE__, ea->port_name);
+ 			qla24xx_post_newsess_work(vha, &ea->id,
+ 			    ea->port_name, NULL, NULL, FC4_TYPE_UNKNOWN);
+ 		}
++>>>>>>> d8630bb95f46 (scsi: qla2xxx: Serialize session deletion by using work_lock)
  	}
  }
  
@@@ -3328,3 -3721,828 +3444,831 @@@ done_free_sp
  done:
  	return rval;
  }
++<<<<<<< HEAD
++=======
+ 
+ void qla24xx_handle_gffid_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+        fc_port_t *fcport = ea->fcport;
+ 
+        qla24xx_post_gnl_work(vha, fcport);
+ }
+ 
+ void qla24xx_async_gffid_sp_done(void *s, int res)
+ {
+        struct srb *sp = s;
+        struct scsi_qla_host *vha = sp->vha;
+        fc_port_t *fcport = sp->fcport;
+        struct ct_sns_rsp *ct_rsp;
+        struct event_arg ea;
+ 
+        ql_dbg(ql_dbg_disc, vha, 0x2133,
+ 	   "Async done-%s res %x ID %x. %8phC\n",
+ 	   sp->name, res, fcport->d_id.b24, fcport->port_name);
+ 
+        fcport->flags &= ~FCF_ASYNC_SENT;
+        ct_rsp = &fcport->ct_desc.ct_sns->p.rsp;
+        /*
+ 	* FC-GS-7, 5.2.3.12 FC-4 Features - format
+ 	* The format of the FC-4 Features object, as defined by the FC-4,
+ 	* Shall be an array of 4-bit values, one for each type code value
+ 	*/
+        if (!res) {
+ 	       if (ct_rsp->rsp.gff_id.fc4_features[GFF_FCP_SCSI_OFFSET] & 0xf) {
+ 		       /* w1 b00:03 */
+ 		       fcport->fc4_type =
+ 			   ct_rsp->rsp.gff_id.fc4_features[GFF_FCP_SCSI_OFFSET];
+ 		       fcport->fc4_type &= 0xf;
+ 	       }
+ 
+ 	       if (ct_rsp->rsp.gff_id.fc4_features[GFF_NVME_OFFSET] & 0xf) {
+ 		       /* w5 [00:03]/28h */
+ 		       fcport->fc4f_nvme =
+ 			   ct_rsp->rsp.gff_id.fc4_features[GFF_NVME_OFFSET];
+ 		       fcport->fc4f_nvme &= 0xf;
+ 	       }
+        }
+ 
+        memset(&ea, 0, sizeof(ea));
+        ea.sp = sp;
+        ea.fcport = sp->fcport;
+        ea.rc = res;
+        ea.event = FCME_GFFID_DONE;
+ 
+        qla2x00_fcport_event_handler(vha, &ea);
+        sp->free(sp);
+ }
+ 
+ /* Get FC4 Feature with Nport ID. */
+ int qla24xx_async_gffid(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online || (fcport->flags & FCF_ASYNC_SENT))
+ 		return rval;
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		return rval;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gffid";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(fcport->ct_desc.ct_sns, GFF_ID_CMD,
+ 	    GFF_ID_RSP_SIZE);
+ 
+ 	ct_req->req.gff_id.port_id[0] = fcport->d_id.b.domain;
+ 	ct_req->req.gff_id.port_id[1] = fcport->d_id.b.area;
+ 	ct_req->req.gff_id.port_id[2] = fcport->d_id.b.al_pa;
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GFF_ID_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GFF_ID_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla24xx_async_gffid_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2132,
+ 	    "Async-%s hdl=%x  %8phC.\n", sp->name,
+ 	    sp->handle, fcport->port_name);
+ 
+ 	return rval;
+ done_free_sp:
+ 	sp->free(sp);
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ /* GPN_FT + GNN_FT*/
+ static int qla2x00_is_a_vp(scsi_qla_host_t *vha, u64 wwn)
+ {
+ 	struct qla_hw_data *ha = vha->hw;
+ 	scsi_qla_host_t *vp;
+ 	unsigned long flags;
+ 	u64 twwn;
+ 	int rc = 0;
+ 
+ 	if (!ha->num_vhosts)
+ 		return 0;
+ 
+ 	spin_lock_irqsave(&ha->vport_slock, flags);
+ 	list_for_each_entry(vp, &ha->vp_list, list) {
+ 		twwn = wwn_to_u64(vp->port_name);
+ 		if (wwn == twwn) {
+ 			rc = 1;
+ 			break;
+ 		}
+ 	}
+ 	spin_unlock_irqrestore(&ha->vport_slock, flags);
+ 
+ 	return rc;
+ }
+ 
+ void qla24xx_async_gnnft_done(scsi_qla_host_t *vha, srb_t *sp)
+ {
+ 	fc_port_t *fcport;
+ 	u32 i, rc;
+ 	bool found;
+ 	u8 fc4type = sp->gen2;
+ 	struct fab_scan_rp *rp;
+ 	unsigned long flags;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s enter\n", __func__);
+ 
+ 	if (sp->gen1 != vha->hw->base_qpair->chip_reset) {
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "%s scan stop due to chip reset %x/%x\n",
+ 		    sp->name, sp->gen1, vha->hw->base_qpair->chip_reset);
+ 		goto out;
+ 	}
+ 
+ 	rc = sp->rc;
+ 	if (rc) {
+ 		vha->scan.scan_retry++;
+ 		if (vha->scan.scan_retry < MAX_SCAN_RETRIES) {
+ 			set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 			set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 			    "Fabric scan failed on all retries.\n");
+ 		}
+ 		goto out;
+ 	}
+ 	vha->scan.scan_retry = 0;
+ 
+ 	list_for_each_entry(fcport, &vha->vp_fcports, list)
+ 		fcport->scan_state = QLA_FCPORT_SCAN;
+ 
+ 	for (i = 0; i < vha->hw->max_fibre_devices; i++) {
+ 		u64 wwn;
+ 
+ 		rp = &vha->scan.l[i];
+ 		found = false;
+ 
+ 		wwn = wwn_to_u64(rp->port_name);
+ 		if (wwn == 0)
+ 			continue;
+ 
+ 		if (!memcmp(rp->port_name, vha->port_name, WWN_SIZE))
+ 			continue;
+ 
+ 		/* Bypass reserved domain fields. */
+ 		if ((rp->id.b.domain & 0xf0) == 0xf0)
+ 			continue;
+ 
+ 		/* Bypass virtual ports of the same host. */
+ 		if (qla2x00_is_a_vp(vha, wwn))
+ 			continue;
+ 
+ 		list_for_each_entry(fcport, &vha->vp_fcports, list) {
+ 			if (memcmp(rp->port_name, fcport->port_name, WWN_SIZE))
+ 				continue;
+ 			fcport->scan_state = QLA_FCPORT_FOUND;
+ 			fcport->d_id.b24 = rp->id.b24;
+ 			found = true;
+ 			/*
+ 			 * If device was not a fabric device before.
+ 			 */
+ 			if ((fcport->flags & FCF_FABRIC_DEVICE) == 0) {
+ 				qla2x00_clear_loop_id(fcport);
+ 				fcport->flags |= FCF_FABRIC_DEVICE;
+ 			}
+ 			break;
+ 		}
+ 
+ 		if (!found) {
+ 			ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 			    "%s %d %8phC post new sess\n",
+ 			    __func__, __LINE__, rp->port_name);
+ 			qla24xx_post_newsess_work(vha, &rp->id, rp->port_name,
+ 			    rp->node_name, NULL, fc4type);
+ 		}
+ 	}
+ 
+ 	/*
+ 	 * Logout all previous fabric dev marked lost, except FCP2 devices.
+ 	 */
+ 	list_for_each_entry(fcport, &vha->vp_fcports, list) {
+ 		if ((fcport->flags & FCF_FABRIC_DEVICE) == 0)
+ 			continue;
+ 
+ 		if (fcport->scan_state != QLA_FCPORT_FOUND) {
+ 			if ((qla_dual_mode_enabled(vha) ||
+ 				qla_ini_mode_enabled(vha)) &&
+ 			    atomic_read(&fcport->state) == FCS_ONLINE) {
+ 				qla2x00_mark_device_lost(vha, fcport,
+ 				    ql2xplogiabsentdevice, 0);
+ 
+ 				if (fcport->loop_id != FC_NO_LOOP_ID &&
+ 				    (fcport->flags & FCF_FCP2_DEVICE) == 0) {
+ 					ql_dbg(ql_dbg_disc, vha, 0x20f0,
+ 					    "%s %d %8phC post del sess\n",
+ 					    __func__, __LINE__,
+ 					    fcport->port_name);
+ 
+ 					qlt_schedule_sess_for_deletion(fcport);
+ 					continue;
+ 				}
+ 			}
+ 		} else
+ 			qla24xx_fcport_handle_login(vha, fcport);
+ 	}
+ 
+ out:
+ 	qla24xx_sp_unmap(vha, sp);
+ 	spin_lock_irqsave(&vha->work_lock, flags);
+ 	vha->scan.scan_flags &= ~SF_SCANNING;
+ 	spin_unlock_irqrestore(&vha->work_lock, flags);
+ }
+ 
+ static void qla2x00_async_gpnft_gnnft_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	struct qla_work_evt *e;
+ 	struct ct_sns_req *ct_req =
+ 		(struct ct_sns_req *)sp->u.iocb_cmd.u.ctarg.req;
+ 	struct ct_sns_gpnft_rsp *ct_rsp =
+ 		(struct ct_sns_gpnft_rsp *)sp->u.iocb_cmd.u.ctarg.rsp;
+ 	struct ct_sns_gpn_ft_data *d = &ct_rsp->entries[0];
+ 	struct fab_scan_rp *rp;
+ 	int i, j, k;
+ 	u16 cmd = be16_to_cpu(ct_req->command);
+ 
+ 	/* gen2 field is holding the fc4type */
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async done-%s res %x FC4Type %x\n",
+ 	    sp->name, res, sp->gen2);
+ 
+ 	if (res) {
+ 		unsigned long flags;
+ 
+ 		sp->free(sp);
+ 		spin_lock_irqsave(&vha->work_lock, flags);
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		vha->scan.scan_retry++;
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 
+ 		if (vha->scan.scan_retry < MAX_SCAN_RETRIES) {
+ 			set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 			set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 			qla2xxx_wake_dpc(vha);
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, sp->vha, 0xffff,
+ 			    "Async done-%s rescan failed on all retries\n",
+ 			    sp->name);
+ 		}
+ 		return;
+ 	}
+ 
+ 	if (!res) {
+ 		port_id_t id;
+ 		u64 wwn;
+ 
+ 		j = 0;
+ 		for (i = 0; i < vha->hw->max_fibre_devices; i++) {
+ 			d  = &ct_rsp->entries[i];
+ 
+ 			id.b.rsvd_1 = 0;
+ 			id.b.domain = d->port_id[0];
+ 			id.b.area   = d->port_id[1];
+ 			id.b.al_pa  = d->port_id[2];
+ 			wwn = wwn_to_u64(d->port_name);
+ 
+ 			if (id.b24 == 0 || wwn == 0)
+ 				continue;
+ 
+ 			if (cmd == GPN_FT_CMD) {
+ 				rp = &vha->scan.l[j];
+ 				rp->id = id;
+ 				memcpy(rp->port_name, d->port_name, 8);
+ 				j++;
+ 			} else {/* GNN_FT_CMD */
+ 				for (k = 0; k < vha->hw->max_fibre_devices;
+ 				    k++) {
+ 					rp = &vha->scan.l[k];
+ 					if (id.b24 == rp->id.b24) {
+ 						memcpy(rp->node_name,
+ 						    d->port_name, 8);
+ 						break;
+ 					}
+ 				}
+ 			}
+ 		}
+ 	}
+ 
+ 	if (cmd == GPN_FT_CMD)
+ 		e = qla2x00_alloc_work(vha, QLA_EVT_GPNFT_DONE);
+ 	else
+ 		e = qla2x00_alloc_work(vha, QLA_EVT_GNNFT_DONE);
+ 	if (!e) {
+ 		/* please ignore kernel warning. Otherwise, we have mem leak. */
+ 		if (sp->u.iocb_cmd.u.ctarg.req) {
+ 			dma_free_coherent(&vha->hw->pdev->dev,
+ 			    sizeof(struct ct_sns_pkt),
+ 			    sp->u.iocb_cmd.u.ctarg.req,
+ 			    sp->u.iocb_cmd.u.ctarg.req_dma);
+ 			sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 		}
+ 		if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 			dma_free_coherent(&vha->hw->pdev->dev,
+ 			    sizeof(struct ct_sns_pkt),
+ 			    sp->u.iocb_cmd.u.ctarg.rsp,
+ 			    sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 			sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 		}
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "Async done-%s unable to alloc work element\n",
+ 		    sp->name);
+ 		sp->free(sp);
+ 		set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 		set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 		return;
+ 	}
+ 
+ 	sp->rc = res;
+ 	e->u.iosb.sp = sp;
+ 
+ 	qla2x00_post_work(vha, e);
+ }
+ 
+ /*
+  * Get WWNN list for fc4_type
+  *
+  * It is assumed the same SRB is re-used from GPNFT to avoid
+  * mem free & re-alloc
+  */
+ static int qla24xx_async_gnnft(scsi_qla_host_t *vha, struct srb *sp,
+     u8 fc4_type)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req *ct_req;
+ 	struct ct_sns_pkt *ct_sns;
+ 
+ 	if (!vha->flags.online) {
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		goto done_free_sp;
+ 	}
+ 
+ 	if (!sp->u.iocb_cmd.u.ctarg.req || !sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		ql_log(ql_log_warn, vha, 0xffff,
+ 		    "%s: req %p rsp %p are not setup\n",
+ 		    __func__, sp->u.iocb_cmd.u.ctarg.req,
+ 		    sp->u.iocb_cmd.u.ctarg.rsp);
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		WARN_ON(1);
+ 		goto done_free_sp;
+ 	}
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gnnft";
+ 	sp->gen1 = vha->hw->base_qpair->chip_reset;
+ 	sp->gen2 = fc4_type;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	memset(sp->u.iocb_cmd.u.ctarg.rsp, 0, sp->u.iocb_cmd.u.ctarg.rsp_size);
+ 	memset(sp->u.iocb_cmd.u.ctarg.req, 0, sp->u.iocb_cmd.u.ctarg.req_size);
+ 
+ 	ct_sns = (struct ct_sns_pkt *)sp->u.iocb_cmd.u.ctarg.req;
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(ct_sns, GNN_FT_CMD,
+ 	    sp->u.iocb_cmd.u.ctarg.rsp_size);
+ 
+ 	/* GPN_FT req */
+ 	ct_req->req.gpn_ft.port_type = fc4_type;
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GNN_FT_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_gpnft_gnnft_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async-%s hdl=%x FC4Type %x.\n", sp->name,
+ 	    sp->handle, ct_req->req.gpn_ft.port_type);
+ 	return rval;
+ 
+ done_free_sp:
+ 	if (sp->u.iocb_cmd.u.ctarg.req) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 		    sizeof(struct ct_sns_pkt),
+ 		    sp->u.iocb_cmd.u.ctarg.req,
+ 		    sp->u.iocb_cmd.u.ctarg.req_dma);
+ 		sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 	}
+ 	if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 		    sizeof(struct ct_sns_pkt),
+ 		    sp->u.iocb_cmd.u.ctarg.rsp,
+ 		    sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 		sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 	}
+ 
+ 	sp->free(sp);
+ 
+ 	return rval;
+ } /* GNNFT */
+ 
+ void qla24xx_async_gpnft_done(scsi_qla_host_t *vha, srb_t *sp)
+ {
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s enter\n", __func__);
+ 	del_timer(&sp->u.iocb_cmd.timer);
+ 	qla24xx_async_gnnft(vha, sp, sp->gen2);
+ }
+ 
+ /* Get WWPN list for certain fc4_type */
+ int qla24xx_async_gpnft(scsi_qla_host_t *vha, u8 fc4_type)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 	struct ct_sns_pkt *ct_sns;
+ 	u32 rspsz;
+ 	unsigned long flags;
+ 
+ 	if (!vha->flags.online)
+ 		return rval;
+ 
+ 	spin_lock_irqsave(&vha->work_lock, flags);
+ 	if (vha->scan.scan_flags & SF_SCANNING) {
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff, "scan active\n");
+ 		return rval;
+ 	}
+ 	vha->scan.scan_flags |= SF_SCANNING;
+ 	spin_unlock_irqrestore(&vha->work_lock, flags);
+ 
+ 	sp = qla2x00_get_sp(vha, NULL, GFP_KERNEL);
+ 	if (!sp) {
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		return rval;
+ 	}
+ 
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gpnft";
+ 	sp->gen1 = vha->hw->base_qpair->chip_reset;
+ 	sp->gen2 = fc4_type;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req = dma_zalloc_coherent(&vha->hw->pdev->dev,
+ 	    sizeof(struct ct_sns_pkt), &sp->u.iocb_cmd.u.ctarg.req_dma,
+ 	    GFP_KERNEL);
+ 	if (!sp->u.iocb_cmd.u.ctarg.req) {
+ 		ql_log(ql_log_warn, vha, 0xffff,
+ 		    "Failed to allocate ct_sns request.\n");
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		goto done_free_sp;
+ 	}
+ 
+ 	rspsz = sizeof(struct ct_sns_gpnft_rsp) +
+ 		((vha->hw->max_fibre_devices - 1) *
+ 		    sizeof(struct ct_sns_gpn_ft_data));
+ 
+ 	sp->u.iocb_cmd.u.ctarg.rsp = dma_zalloc_coherent(&vha->hw->pdev->dev,
+ 	    rspsz, &sp->u.iocb_cmd.u.ctarg.rsp_dma, GFP_KERNEL);
+ 	if (!sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		ql_log(ql_log_warn, vha, 0xffff,
+ 		    "Failed to allocate ct_sns request.\n");
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		goto done_free_sp;
+ 	}
+ 
+ 	memset(vha->scan.l, 0, vha->scan.size);
+ 
+ 	ct_sns = (struct ct_sns_pkt *)sp->u.iocb_cmd.u.ctarg.req;
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(ct_sns, GPN_FT_CMD, rspsz);
+ 
+ 	/* GPN_FT req */
+ 	ct_req->req.gpn_ft.port_type = fc4_type;
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GPN_FT_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = rspsz;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_gpnft_gnnft_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS) {
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		goto done_free_sp;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async-%s hdl=%x FC4Type %x.\n", sp->name,
+ 	    sp->handle, ct_req->req.gpn_ft.port_type);
+ 	return rval;
+ 
+ done_free_sp:
+ 	if (sp->u.iocb_cmd.u.ctarg.req) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 		    sizeof(struct ct_sns_pkt),
+ 		    sp->u.iocb_cmd.u.ctarg.req,
+ 		    sp->u.iocb_cmd.u.ctarg.req_dma);
+ 		sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 	}
+ 	if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 		    sizeof(struct ct_sns_pkt),
+ 		    sp->u.iocb_cmd.u.ctarg.rsp,
+ 		    sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 		sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 	}
+ 
+ 	sp->free(sp);
+ 
+ 	return rval;
+ }
+ 
+ void qla_scan_work_fn(struct work_struct *work)
+ {
+ 	struct fab_scan *s = container_of(to_delayed_work(work),
+ 	    struct fab_scan, scan_work);
+ 	struct scsi_qla_host *vha = container_of(s, struct scsi_qla_host,
+ 	    scan);
+ 	unsigned long flags;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s: schedule loop resync\n", __func__);
+ 	set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 	set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 	qla2xxx_wake_dpc(vha);
+ 	spin_lock_irqsave(&vha->work_lock, flags);
+ 	vha->scan.scan_flags &= ~SF_QUEUED;
+ 	spin_unlock_irqrestore(&vha->work_lock, flags);
+ }
+ 
+ /* GNN_ID */
+ void qla24xx_handle_gnnid_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	qla24xx_post_gnl_work(vha, ea->fcport);
+ }
+ 
+ static void qla2x00_async_gnnid_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	fc_port_t *fcport = sp->fcport;
+ 	u8 *node_name = fcport->ct_desc.ct_sns->p.rsp.rsp.gnn_id.node_name;
+ 	struct event_arg ea;
+ 	u64 wwnn;
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	wwnn = wwn_to_u64(node_name);
+ 	if (wwnn)
+ 		memcpy(fcport->node_name, node_name, WWN_SIZE);
+ 
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.fcport = fcport;
+ 	ea.sp = sp;
+ 	ea.rc = res;
+ 	ea.event = FCME_GNNID_DONE;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x204f,
+ 	    "Async done-%s res %x, WWPN %8phC %8phC\n",
+ 	    sp->name, res, fcport->port_name, fcport->node_name);
+ 
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_gnnid(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online || (fcport->flags & FCF_ASYNC_SENT))
+ 		return rval;
+ 
+ 	fcport->disc_state = DSC_GNN_ID;
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_ATOMIC);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gnnid";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(fcport->ct_desc.ct_sns, GNN_ID_CMD,
+ 	    GNN_ID_RSP_SIZE);
+ 
+ 	/* GNN_ID req */
+ 	ct_req->req.port_id.port_id[0] = fcport->d_id.b.domain;
+ 	ct_req->req.port_id.port_id[1] = fcport->d_id.b.area;
+ 	ct_req->req.port_id.port_id[2] = fcport->d_id.b.al_pa;
+ 
+ 
+ 	/* req & rsp use the same buffer */
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GNN_ID_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GNN_ID_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_gnnid_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async-%s - %8phC hdl=%x loopid=%x portid %06x.\n",
+ 	    sp->name, fcport->port_name,
+ 	    sp->handle, fcport->loop_id, fcport->d_id.b24);
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ done:
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gnnid_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 	int ls;
+ 
+ 	ls = atomic_read(&vha->loop_state);
+ 	if (((ls != LOOP_READY) && (ls != LOOP_UP)) ||
+ 		test_bit(UNLOADING, &vha->dpc_flags))
+ 		return 0;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GNNID);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ /* GPFN_ID */
+ void qla24xx_handle_gfpnid_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	fc_port_t *fcport = ea->fcport;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s %8phC DS %d LS %d rc %d login %d|%d rscn %d|%d fcpcnt %d\n",
+ 	    __func__, fcport->port_name, fcport->disc_state,
+ 	    fcport->fw_login_state, ea->rc, fcport->login_gen, ea->sp->gen2,
+ 	    fcport->rscn_gen, ea->sp->gen1, vha->fcport_count);
+ 
+ 	if (fcport->disc_state == DSC_DELETE_PEND)
+ 		return;
+ 
+ 	if (ea->sp->gen2 != fcport->login_gen) {
+ 		/* target side must have changed it. */
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d3,
+ 		    "%s %8phC generation changed\n",
+ 		    __func__, fcport->port_name);
+ 		return;
+ 	} else if (ea->sp->gen1 != fcport->rscn_gen) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d4, "%s %d %8phC post gidpn\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 		qla24xx_post_gidpn_work(vha, fcport);
+ 		return;
+ 	}
+ 
+ 	qla24xx_post_gpsc_work(vha, fcport);
+ }
+ 
+ static void qla2x00_async_gfpnid_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	fc_port_t *fcport = sp->fcport;
+ 	u8 *fpn = fcport->ct_desc.ct_sns->p.rsp.rsp.gfpn_id.port_name;
+ 	struct event_arg ea;
+ 	u64 wwn;
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	wwn = wwn_to_u64(fpn);
+ 	if (wwn)
+ 		memcpy(fcport->fabric_port_name, fpn, WWN_SIZE);
+ 
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.fcport = fcport;
+ 	ea.sp = sp;
+ 	ea.rc = res;
+ 	ea.event = FCME_GFPNID_DONE;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x204f,
+ 	    "Async done-%s res %x, WWPN %8phC %8phC\n",
+ 	    sp->name, res, fcport->port_name, fcport->fabric_port_name);
+ 
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_gfpnid(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online || (fcport->flags & FCF_ASYNC_SENT))
+ 		return rval;
+ 
+ 	fcport->disc_state = DSC_GFPN_ID;
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_ATOMIC);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gfpnid";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(fcport->ct_desc.ct_sns, GFPN_ID_CMD,
+ 	    GFPN_ID_RSP_SIZE);
+ 
+ 	/* GFPN_ID req */
+ 	ct_req->req.port_id.port_id[0] = fcport->d_id.b.domain;
+ 	ct_req->req.port_id.port_id[1] = fcport->d_id.b.area;
+ 	ct_req->req.port_id.port_id[2] = fcport->d_id.b.al_pa;
+ 
+ 
+ 	/* req & rsp use the same buffer */
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GFPN_ID_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GFPN_ID_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	sp->done = qla2x00_async_gfpnid_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async-%s - %8phC hdl=%x loopid=%x portid %06x.\n",
+ 	    sp->name, fcport->port_name,
+ 	    sp->handle, fcport->loop_id, fcport->d_id.b24);
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ done:
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gfpnid_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 	int ls;
+ 
+ 	ls = atomic_read(&vha->loop_state);
+ 	if (((ls != LOOP_READY) && (ls != LOOP_UP)) ||
+ 		test_bit(UNLOADING, &vha->dpc_flags))
+ 		return 0;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GFPNID);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	return qla2x00_post_work(vha, e);
+ }
++>>>>>>> d8630bb95f46 (scsi: qla2xxx: Serialize session deletion by using work_lock)
diff --cc drivers/scsi/qla2xxx/qla_init.c
index bc98a1a62b13,9c08222e4c8b..000000000000
--- a/drivers/scsi/qla2xxx/qla_init.c
+++ b/drivers/scsi/qla2xxx/qla_init.c
@@@ -822,23 -1046,112 +822,67 @@@ void qla24xx_handle_gpdb_event(scsi_qla
  		/*
  		 * We have an existing session. A late RSCN delivery
  		 * must have triggered the session to be re-validate.
 -		 * Session is still valid.
 +		 * session is still valid.
  		 */
 -		ql_dbg(ql_dbg_disc, vha, 0x20d6,
 -		    "%s %d %8phC session revalidate success\n",
 -		    __func__, __LINE__, ea->fcport->port_name);
 -		 ea->fcport->disc_state = DSC_LOGIN_COMPLETE;
 +		fcport->disc_state = DSC_LOGIN_COMPLETE;
  	}
  	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
++<<<<<<< HEAD
++=======
+ }
+ 
+ static
+ void qla24xx_handle_gpdb_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	fc_port_t *fcport = ea->fcport;
+ 	struct port_database_24xx *pd;
+ 	struct srb *sp = ea->sp;
+ 
+ 	pd = (struct port_database_24xx *)sp->u.iocb_cmd.u.mbx.in;
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20d2,
+ 	    "%s %8phC DS %d LS %d rc %d\n", __func__, fcport->port_name,
+ 	    fcport->disc_state, pd->current_login_state, ea->rc);
+ 
+ 	if (fcport->disc_state == DSC_DELETE_PEND)
+ 		return;
+ 
+ 	switch (pd->current_login_state) {
+ 	case PDS_PRLI_COMPLETE:
+ 		__qla24xx_parse_gpdb(vha, fcport, pd);
+ 		break;
+ 	case PDS_PLOGI_PENDING:
+ 	case PDS_PLOGI_COMPLETE:
+ 	case PDS_PRLI_PENDING:
+ 	case PDS_PRLI2_PENDING:
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d5, "%s %d %8phC relogin needed\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 		set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
+ 		return;
+ 	case PDS_LOGO_PENDING:
+ 	case PDS_PORT_UNAVAILABLE:
+ 	default:
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d5, "%s %d %8phC post del sess\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 		qlt_schedule_sess_for_deletion(fcport);
+ 		return;
+ 	}
+ 	__qla24xx_handle_gpdb_event(vha, ea);
++>>>>>>> d8630bb95f46 (scsi: qla2xxx: Serialize session deletion by using work_lock)
  } /* gpdb event */
  
 -static void qla_chk_n2n_b4_login(struct scsi_qla_host *vha, fc_port_t *fcport)
 -{
 -	u8 login = 0;
 -	int rc;
 -
 -	if (qla_tgt_mode_enabled(vha))
 -		return;
 -
 -	if (qla_dual_mode_enabled(vha)) {
 -		if (N2N_TOPO(vha->hw)) {
 -			u64 mywwn, wwn;
 -
 -			mywwn = wwn_to_u64(vha->port_name);
 -			wwn = wwn_to_u64(fcport->port_name);
 -			if (mywwn > wwn)
 -				login = 1;
 -			else if ((fcport->fw_login_state == DSC_LS_PLOGI_COMP)
 -			    && time_after_eq(jiffies,
 -				    fcport->plogi_nack_done_deadline))
 -				login = 1;
 -		} else {
 -			login = 1;
 -		}
 -	} else {
 -		/* initiator mode */
 -		login = 1;
 -	}
 -
 -	if (login) {
 -		if (fcport->loop_id == FC_NO_LOOP_ID) {
 -			fcport->fw_login_state = DSC_LS_PORT_UNAVAIL;
 -			rc = qla2x00_find_new_loop_id(vha, fcport);
 -			if (rc) {
 -				ql_dbg(ql_dbg_disc, vha, 0x20e6,
 -				    "%s %d %8phC post del sess - out of loopid\n",
 -				    __func__, __LINE__, fcport->port_name);
 -				fcport->scan_state = 0;
 -				qlt_schedule_sess_for_deletion(fcport);
 -				return;
 -			}
 -		}
 -		ql_dbg(ql_dbg_disc, vha, 0x20bf,
 -		    "%s %d %8phC post login\n",
 -		    __func__, __LINE__, fcport->port_name);
 -		qla2x00_post_async_login_work(vha, fcport, NULL);
 -	}
 -}
 -
  int qla24xx_fcport_handle_login(struct scsi_qla_host *vha, fc_port_t *fcport)
  {
 -	u16 data[2];
 -	u64 wwn;
 +	if (fcport->login_retry == 0)
 +		return 0;
 +
 +	if (fcport->scan_state != QLA_FCPORT_FOUND)
 +		return 0;
  
  	ql_dbg(ql_dbg_disc, vha, 0x20d8,
 -	    "%s %8phC DS %d LS %d P %d fl %x confl %p rscn %d|%d login %d retry %d lid %d scan %d\n",
 +	    "%s %8phC DS %d LS %d P %d fl %x confl %p rscn %d|%d login %d|%d retry %d lid %d\n",
  	    __func__, fcport->port_name, fcport->disc_state,
  	    fcport->fw_login_state, fcport->login_pause, fcport->flags,
  	    fcport->conflict, fcport->last_rscn_gen, fcport->rscn_gen,
@@@ -4440,6 -4945,35 +4484,38 @@@ qla2x00_configure_local_loop(scsi_qla_h
  		found_devs++;
  	}
  
++<<<<<<< HEAD
++=======
+ 	list_for_each_entry(fcport, &vha->vp_fcports, list) {
+ 		if (test_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags))
+ 			break;
+ 
+ 		if (fcport->scan_state == QLA_FCPORT_SCAN) {
+ 			if ((qla_dual_mode_enabled(vha) ||
+ 			    qla_ini_mode_enabled(vha)) &&
+ 			    atomic_read(&fcport->state) == FCS_ONLINE) {
+ 				qla2x00_mark_device_lost(vha, fcport,
+ 					ql2xplogiabsentdevice, 0);
+ 				if (fcport->loop_id != FC_NO_LOOP_ID &&
+ 				    (fcport->flags & FCF_FCP2_DEVICE) == 0 &&
+ 				    fcport->port_type != FCT_INITIATOR &&
+ 				    fcport->port_type != FCT_BROADCAST) {
+ 					ql_dbg(ql_dbg_disc, vha, 0x20f0,
+ 					    "%s %d %8phC post del sess\n",
+ 					    __func__, __LINE__,
+ 					    fcport->port_name);
+ 
+ 					qlt_schedule_sess_for_deletion(fcport);
+ 					continue;
+ 				}
+ 			}
+ 		}
+ 
+ 		if (fcport->scan_state == QLA_FCPORT_FOUND)
+ 			qla24xx_fcport_handle_login(vha, fcport);
+ 	}
+ 
++>>>>>>> d8630bb95f46 (scsi: qla2xxx: Serialize session deletion by using work_lock)
  cleanup_allocation:
  	kfree(new_fcport);
  
diff --cc drivers/scsi/qla2xxx/qla_mbx.c
index 4649e83dd88d,7397aeddd96c..000000000000
--- a/drivers/scsi/qla2xxx/qla_mbx.c
+++ b/drivers/scsi/qla2xxx/qla_mbx.c
@@@ -3749,6 -3875,40 +3749,43 @@@ qla24xx_report_id_acquisition(scsi_qla_
  		spin_lock_irqsave(&ha->vport_slock, flags);
  		qlt_update_vp_map(vha, SET_AL_PA);
  		spin_unlock_irqrestore(&ha->vport_slock, flags);
++<<<<<<< HEAD
++=======
+ 
+ 		list_for_each_entry(fcport, &vha->vp_fcports, list) {
+ 			fcport->scan_state = QLA_FCPORT_SCAN;
+ 		}
+ 
+ 		fcport = qla2x00_find_fcport_by_wwpn(vha,
+ 		    rptid_entry->u.f2.port_name, 1);
+ 
+ 		if (fcport) {
+ 			fcport->plogi_nack_done_deadline = jiffies + HZ;
+ 			fcport->scan_state = QLA_FCPORT_FOUND;
+ 			switch (fcport->disc_state) {
+ 			case DSC_DELETED:
+ 				ql_dbg(ql_dbg_disc, vha, 0x210d,
+ 				    "%s %d %8phC login\n",
+ 				    __func__, __LINE__, fcport->port_name);
+ 				qla24xx_fcport_handle_login(vha, fcport);
+ 				break;
+ 			case DSC_DELETE_PEND:
+ 				break;
+ 			default:
+ 				qlt_schedule_sess_for_deletion(fcport);
+ 				break;
+ 			}
+ 		} else {
+ 			id.b.al_pa  = rptid_entry->u.f2.remote_nport_id[0];
+ 			id.b.area   = rptid_entry->u.f2.remote_nport_id[1];
+ 			id.b.domain = rptid_entry->u.f2.remote_nport_id[2];
+ 			qla24xx_post_newsess_work(vha, &id,
+ 			    rptid_entry->u.f2.port_name,
+ 			    rptid_entry->u.f2.node_name,
+ 			    NULL,
+ 			    FC4_TYPE_UNKNOWN);
+ 		}
++>>>>>>> d8630bb95f46 (scsi: qla2xxx: Serialize session deletion by using work_lock)
  	}
  }
  
diff --cc drivers/scsi/qla2xxx/qla_os.c
index 20a870bdd02c,b21878a70f6e..000000000000
--- a/drivers/scsi/qla2xxx/qla_os.c
+++ b/drivers/scsi/qla2xxx/qla_os.c
@@@ -4806,10 -4844,72 +4806,49 @@@ void qla24xx_create_new_sess(struct scs
  	spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
  
  	if (fcport) {
 -		if (N2N_TOPO(vha->hw))
 -			fcport->flags &= ~FCF_FABRIC_DEVICE;
 -
 -		fcport->id_changed = 1;
 -		fcport->scan_state = QLA_FCPORT_FOUND;
 -		memcpy(fcport->node_name, e->u.new_sess.node_name, WWN_SIZE);
 -
 -		if (pla) {
 -			if (pla->iocb.u.isp24.status_subcode == ELS_PRLI) {
 -				u16 wd3_lo;
 -
 -				fcport->fw_login_state = DSC_LS_PRLI_PEND;
 -				fcport->local = 0;
 -				fcport->loop_id =
 -					le16_to_cpu(
 -					    pla->iocb.u.isp24.nport_handle);
 -				fcport->fw_login_state = DSC_LS_PRLI_PEND;
 -				wd3_lo =
 -				    le16_to_cpu(
 -					pla->iocb.u.isp24.u.prli.wd3_lo);
 -
 -				if (wd3_lo & BIT_7)
 -					fcport->conf_compl_supported = 1;
 -
 -				if ((wd3_lo & BIT_4) == 0)
 -					fcport->port_type = FCT_INITIATOR;
 -				else
 -					fcport->port_type = FCT_TARGET;
 -			}
 +		if (pla)
  			qlt_plogi_ack_unref(vha, pla);
++<<<<<<< HEAD
 +		else
 +			qla24xx_async_gnl(vha, fcport);
++=======
+ 		} else {
+ 			spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 			tfcp = qla2x00_find_fcport_by_nportid(vha,
+ 			    &e->u.new_sess.id, 1);
+ 			if (tfcp && (tfcp != fcport)) {
+ 				/*
+ 				 * We have a conflict fcport with same NportID.
+ 				 */
+ 				ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 				    "%s %8phC found conflict b4 add. DS %d LS %d\n",
+ 				    __func__, tfcp->port_name, tfcp->disc_state,
+ 				    tfcp->fw_login_state);
+ 
+ 				switch (tfcp->disc_state) {
+ 				case DSC_DELETED:
+ 					break;
+ 				case DSC_DELETE_PEND:
+ 					fcport->login_pause = 1;
+ 					tfcp->conflict = fcport;
+ 					break;
+ 				default:
+ 					fcport->login_pause = 1;
+ 					tfcp->conflict = fcport;
+ 					qlt_schedule_sess_for_deletion(tfcp);
+ 					break;
+ 				}
+ 			}
+ 			spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 
+ 			wwn = wwn_to_u64(fcport->node_name);
+ 
+ 			if (!wwn)
+ 				qla24xx_async_gnnid(vha, fcport);
+ 			else
+ 				qla24xx_async_gnl(vha, fcport);
+ 		}
++>>>>>>> d8630bb95f46 (scsi: qla2xxx: Serialize session deletion by using work_lock)
  	}
  
  	if (free_fcport) {
diff --cc drivers/scsi/qla2xxx/qla_target.c
index 3c5690bebff9,72b452db26da..000000000000
--- a/drivers/scsi/qla2xxx/qla_target.c
+++ b/drivers/scsi/qla2xxx/qla_target.c
@@@ -1168,10 -1211,10 +1168,11 @@@ static void qla24xx_chk_fcp_state(struc
  }
  
  /* ha->tgt.sess_lock supposed to be held on entry */
 -void qlt_schedule_sess_for_deletion(struct fc_port *sess)
 +void qlt_schedule_sess_for_deletion(struct fc_port *sess,
 +	bool immediate)
  {
  	struct qla_tgt *tgt = sess->tgt;
+ 	unsigned long flags;
  
  	if (sess->disc_state == DSC_DELETE_PEND)
  		return;
@@@ -1202,15 -1254,6 +1210,18 @@@
  	queue_work(sess->vha->hw->wq, &sess->del_work);
  }
  
++<<<<<<< HEAD
 +void qlt_schedule_sess_for_deletion_lock(struct fc_port *sess)
 +{
 +	unsigned long flags;
 +	struct qla_hw_data *ha = sess->vha->hw;
 +	spin_lock_irqsave(&ha->tgt.sess_lock, flags);
 +	qlt_schedule_sess_for_deletion(sess, 1);
 +	spin_unlock_irqrestore(&ha->tgt.sess_lock, flags);
 +}
 +
++=======
++>>>>>>> d8630bb95f46 (scsi: qla2xxx: Serialize session deletion by using work_lock)
  /* ha->tgt.sess_lock supposed to be held on entry */
  static void qlt_clear_tgt_db(struct qla_tgt *tgt)
  {
@@@ -4664,6 -4597,138 +4675,141 @@@ static int abort_cmds_for_s_id(struct s
  	return count;
  }
  
++<<<<<<< HEAD
++=======
+ static int qlt_handle_login(struct scsi_qla_host *vha,
+     struct imm_ntfy_from_isp *iocb)
+ {
+ 	struct fc_port *sess = NULL, *conflict_sess = NULL;
+ 	uint64_t wwn;
+ 	port_id_t port_id;
+ 	uint16_t loop_id, wd3_lo;
+ 	int res = 0;
+ 	struct qlt_plogi_ack_t *pla;
+ 	unsigned long flags;
+ 
+ 	wwn = wwn_to_u64(iocb->u.isp24.port_name);
+ 
+ 	port_id.b.domain = iocb->u.isp24.port_id[2];
+ 	port_id.b.area   = iocb->u.isp24.port_id[1];
+ 	port_id.b.al_pa  = iocb->u.isp24.port_id[0];
+ 	port_id.b.rsvd_1 = 0;
+ 
+ 	loop_id = le16_to_cpu(iocb->u.isp24.nport_handle);
+ 
+ 	/* Mark all stale commands sitting in qla_tgt_wq for deletion */
+ 	abort_cmds_for_s_id(vha, &port_id);
+ 
+ 	if (wwn) {
+ 		spin_lock_irqsave(&vha->hw->tgt.sess_lock, flags);
+ 		sess = qlt_find_sess_invalidate_other(vha, wwn,
+ 		    port_id, loop_id, &conflict_sess);
+ 		spin_unlock_irqrestore(&vha->hw->tgt.sess_lock, flags);
+ 	}
+ 
+ 	if (IS_SW_RESV_ADDR(port_id)) {
+ 		res = 1;
+ 		goto out;
+ 	}
+ 
+ 	pla = qlt_plogi_ack_find_add(vha, &port_id, iocb);
+ 	if (!pla) {
+ 		qlt_send_term_imm_notif(vha, iocb, 1);
+ 		goto out;
+ 	}
+ 
+ 	if (conflict_sess) {
+ 		conflict_sess->login_gen++;
+ 		qlt_plogi_ack_link(vha, pla, conflict_sess,
+ 		    QLT_PLOGI_LINK_CONFLICT);
+ 	}
+ 
+ 	if (!sess) {
+ 		pla->ref_count++;
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "%s %d %8phC post new sess\n",
+ 		    __func__, __LINE__, iocb->u.isp24.port_name);
+ 		if (iocb->u.isp24.status_subcode == ELS_PLOGI)
+ 			qla24xx_post_newsess_work(vha, &port_id,
+ 			    iocb->u.isp24.port_name,
+ 			    iocb->u.isp24.u.plogi.node_name,
+ 			    pla, FC4_TYPE_UNKNOWN);
+ 		else
+ 			qla24xx_post_newsess_work(vha, &port_id,
+ 			    iocb->u.isp24.port_name, NULL,
+ 			    pla, FC4_TYPE_UNKNOWN);
+ 
+ 		goto out;
+ 	}
+ 
+ 	qlt_plogi_ack_link(vha, pla, sess, QLT_PLOGI_LINK_SAME_WWN);
+ 	sess->d_id = port_id;
+ 	sess->login_gen++;
+ 
+ 	if (iocb->u.isp24.status_subcode == ELS_PRLI) {
+ 		sess->fw_login_state = DSC_LS_PRLI_PEND;
+ 		sess->local = 0;
+ 		sess->loop_id = loop_id;
+ 		sess->d_id = port_id;
+ 		sess->fw_login_state = DSC_LS_PRLI_PEND;
+ 		wd3_lo = le16_to_cpu(iocb->u.isp24.u.prli.wd3_lo);
+ 
+ 		if (wd3_lo & BIT_7)
+ 			sess->conf_compl_supported = 1;
+ 
+ 		if ((wd3_lo & BIT_4) == 0)
+ 			sess->port_type = FCT_INITIATOR;
+ 		else
+ 			sess->port_type = FCT_TARGET;
+ 
+ 	} else
+ 		sess->fw_login_state = DSC_LS_PLOGI_PEND;
+ 
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20f9,
+ 	    "%s %d %8phC  DS %d\n",
+ 	    __func__, __LINE__, sess->port_name, sess->disc_state);
+ 
+ 	switch (sess->disc_state) {
+ 	case DSC_DELETED:
+ 		qlt_plogi_ack_unref(vha, pla);
+ 		break;
+ 
+ 	default:
+ 		/*
+ 		 * Under normal circumstances we want to release nport handle
+ 		 * during LOGO process to avoid nport handle leaks inside FW.
+ 		 * The exception is when LOGO is done while another PLOGI with
+ 		 * the same nport handle is waiting as might be the case here.
+ 		 * Note: there is always a possibily of a race where session
+ 		 * deletion has already started for other reasons (e.g. ACL
+ 		 * removal) and now PLOGI arrives:
+ 		 * 1. if PLOGI arrived in FW after nport handle has been freed,
+ 		 *    FW must have assigned this PLOGI a new/same handle and we
+ 		 *    can proceed ACK'ing it as usual when session deletion
+ 		 *    completes.
+ 		 * 2. if PLOGI arrived in FW before LOGO with LCF_FREE_NPORT
+ 		 *    bit reached it, the handle has now been released. We'll
+ 		 *    get an error when we ACK this PLOGI. Nothing will be sent
+ 		 *    back to initiator. Initiator should eventually retry
+ 		 *    PLOGI and situation will correct itself.
+ 		 */
+ 		sess->keep_nport_handle = ((sess->loop_id == loop_id) &&
+ 		    (sess->d_id.b24 == port_id.b24));
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0x20f9,
+ 		    "%s %d %8phC post del sess\n",
+ 		    __func__, __LINE__, sess->port_name);
+ 
+ 
+ 		qlt_schedule_sess_for_deletion(sess);
+ 		break;
+ 	}
+ out:
+ 	return res;
+ }
+ 
++>>>>>>> d8630bb95f46 (scsi: qla2xxx: Serialize session deletion by using work_lock)
  /*
   * ha->hardware_lock supposed to be held on entry. Might drop it, then reaquire
   */
* Unmerged path drivers/scsi/qla2xxx/qla_gbl.h
* Unmerged path drivers/scsi/qla2xxx/qla_gs.c
* Unmerged path drivers/scsi/qla2xxx/qla_init.c
diff --git a/drivers/scsi/qla2xxx/qla_isr.c b/drivers/scsi/qla2xxx/qla_isr.c
index 07f970a66c67..225258040b0d 100644
--- a/drivers/scsi/qla2xxx/qla_isr.c
+++ b/drivers/scsi/qla2xxx/qla_isr.c
@@ -1011,7 +1011,7 @@ skip_rio:
 			if (qla_ini_mode_enabled(vha)) {
 				qla2x00_mark_device_lost(fcport->vha, fcport, 1, 1);
 				fcport->logout_on_delete = 0;
-				qlt_schedule_sess_for_deletion_lock(fcport);
+				qlt_schedule_sess_for_deletion(fcport);
 			}
 			break;
 
@@ -2533,7 +2533,7 @@ check_scsi_status:
 				fcport->logout_on_delete = 0;
 
 			qla2x00_mark_device_lost(fcport->vha, fcport, 1, 1);
-			qlt_schedule_sess_for_deletion_lock(fcport);
+			qlt_schedule_sess_for_deletion(fcport);
 		}
 
 		break;
* Unmerged path drivers/scsi/qla2xxx/qla_mbx.c
* Unmerged path drivers/scsi/qla2xxx/qla_os.c
* Unmerged path drivers/scsi/qla2xxx/qla_target.c
