kyber: fix another domain token wait queue hang

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Omar Sandoval <osandov@fb.com>
commit fcf38cdf332a81b20a59e3ebaea81f6b316bbe0c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/fcf38cdf.failed

Commit 8cf466602028 ("kyber: fix hang on domain token wait queue") fixed
a hang caused by leaving wait entries on the domain token wait queue
after the __sbitmap_queue_get() retry succeeded, making that wait entry
a "dud" which won't in turn wake more entries up. However, we can also
get a dud entry if kyber_get_domain_token() fails once but is then
called again and succeeds. This can happen if the hardware queue is
rerun for some other reason, or, more likely, kyber_dispatch_request()
tries the same domain twice.

The fix is to remove our entry from the wait queue whenever we
successfully get a token. The only complication is that we might be on
one of many wait queues in the struct sbitmap_queue, but that's easily
fixed by remembering which wait queue we were put on.

While we're here, only initialize the wait queue entry once instead of
on every wait, and use spin_lock_irq() instead of spin_lock_irqsave(),
since this is always called from process context with irqs enabled.

	Signed-off-by: Omar Sandoval <osandov@fb.com>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit fcf38cdf332a81b20a59e3ebaea81f6b316bbe0c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/kyber-iosched.c
diff --cc block/kyber-iosched.c
index 236dd17397e2,f95c60774ce8..000000000000
--- a/block/kyber-iosched.c
+++ b/block/kyber-iosched.c
@@@ -99,14 -99,13 +99,24 @@@ struct kyber_hctx_data 
  	struct list_head rqs[KYBER_NUM_DOMAINS];
  	unsigned int cur_domain;
  	unsigned int batching;
++<<<<<<< HEAD
 +	wait_queue_t domain_wait[KYBER_NUM_DOMAINS];
 +	atomic_t wait_index[KYBER_NUM_DOMAINS];
 +};
 +
 +static bool op_is_sync(unsigned int cmd_flags)
 +{
 +	return rw_is_sync(cmd_flags) || (cmd_flags & (REQ_FUA | REQ_FLUSH));
 +}
++=======
+ 	wait_queue_entry_t domain_wait[KYBER_NUM_DOMAINS];
+ 	struct sbq_wait_state *domain_ws[KYBER_NUM_DOMAINS];
+ 	atomic_t wait_index[KYBER_NUM_DOMAINS];
+ };
+ 
+ static int kyber_domain_wake(wait_queue_entry_t *wait, unsigned mode, int flags,
+ 			     void *key);
++>>>>>>> fcf38cdf332a (kyber: fix another domain token wait queue hang)
  
  static int rq_sched_domain(const struct request *rq)
  {
@@@ -392,7 -389,10 +402,14 @@@ static int kyber_init_hctx(struct blk_m
  
  	for (i = 0; i < KYBER_NUM_DOMAINS; i++) {
  		INIT_LIST_HEAD(&khd->rqs[i]);
++<<<<<<< HEAD
 +		INIT_LIST_HEAD(&khd->domain_wait[i].task_list);
++=======
+ 		init_waitqueue_func_entry(&khd->domain_wait[i],
+ 					  kyber_domain_wake);
+ 		khd->domain_wait[i].private = hctx;
+ 		INIT_LIST_HEAD(&khd->domain_wait[i].entry);
++>>>>>>> fcf38cdf332a (kyber: fix another domain token wait queue hang)
  		atomic_set(&khd->wait_index[i], 0);
  	}
  
@@@ -543,11 -537,10 +558,16 @@@ static int kyber_get_domain_token(struc
  	 * run when one becomes available. Note that this is serialized on
  	 * khd->lock, but we still need to be careful about the waker.
  	 */
++<<<<<<< HEAD
 +	if (list_empty_careful(&wait->task_list)) {
 +		init_waitqueue_func_entry(wait, kyber_domain_wake);
 +		wait->private = hctx;
++=======
+ 	if (nr < 0 && list_empty_careful(&wait->entry)) {
++>>>>>>> fcf38cdf332a (kyber: fix another domain token wait queue hang)
  		ws = sbq_wait_ptr(domain_tokens,
  				  &khd->wait_index[sched_domain]);
+ 		khd->domain_ws[sched_domain] = ws;
  		add_wait_queue(&ws->wait, wait);
  
  		/*
* Unmerged path block/kyber-iosched.c
