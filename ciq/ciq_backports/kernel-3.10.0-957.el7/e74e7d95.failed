scsi: qla2xxx: Fix race condition between iocb timeout and initialisation

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
Rebuild_CHGLOG: - [scsi] qla2xxx: Fix race condition between iocb timeout and initialisation (Himanshu Madhani) [1547714]
Rebuild_FUZZ: 95.71%
commit-author Ben Hutchings <ben.hutchings@codethink.co.uk>
commit e74e7d95878d7993cf56c801d55d78f16ea58d1d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/e74e7d95.failed

qla2x00_init_timer() calls add_timer() on the iocb timeout timer, which
means the timeout function pointer and any data that the function depends on
must be initialised beforehand.

Move this initialisation before each call to qla2x00_init_timer().  In some
cases qla2x00_init_timer() initialises a completion structure needed by the
timeout function, so move the call to add_timer() after that.

	Signed-off-by: Ben Hutchings <ben.hutchings@codethink.co.uk>
	Acked-by: Himanshu Madhani <himanshu.madhani@cavium.com>
	Signed-off-by: Martin K. Petersen <martin.petersen@oracle.com>
(cherry picked from commit e74e7d95878d7993cf56c801d55d78f16ea58d1d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/scsi/qla2xxx/qla_gs.c
#	drivers/scsi/qla2xxx/qla_init.c
#	drivers/scsi/qla2xxx/qla_inline.h
#	drivers/scsi/qla2xxx/qla_iocb.c
#	drivers/scsi/qla2xxx/qla_mid.c
diff --cc drivers/scsi/qla2xxx/qla_gs.c
index 985af1dbf875,9e914f9c3ffb..000000000000
--- a/drivers/scsi/qla2xxx/qla_gs.c
+++ b/drivers/scsi/qla2xxx/qla_gs.c
@@@ -3326,3 -3721,974 +3326,977 @@@ done_free_sp
  done:
  	return rval;
  }
++<<<<<<< HEAD
++=======
+ 
+ void qla24xx_handle_gffid_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+        fc_port_t *fcport = ea->fcport;
+ 
+        qla24xx_post_gnl_work(vha, fcport);
+ }
+ 
+ void qla24xx_async_gffid_sp_done(void *s, int res)
+ {
+        struct srb *sp = s;
+        struct scsi_qla_host *vha = sp->vha;
+        fc_port_t *fcport = sp->fcport;
+        struct ct_sns_rsp *ct_rsp;
+        struct event_arg ea;
+ 
+        ql_dbg(ql_dbg_disc, vha, 0x2133,
+ 	   "Async done-%s res %x ID %x. %8phC\n",
+ 	   sp->name, res, fcport->d_id.b24, fcport->port_name);
+ 
+        fcport->flags &= ~FCF_ASYNC_SENT;
+        ct_rsp = &fcport->ct_desc.ct_sns->p.rsp;
+        /*
+ 	* FC-GS-7, 5.2.3.12 FC-4 Features - format
+ 	* The format of the FC-4 Features object, as defined by the FC-4,
+ 	* Shall be an array of 4-bit values, one for each type code value
+ 	*/
+        if (!res) {
+ 	       if (ct_rsp->rsp.gff_id.fc4_features[GFF_FCP_SCSI_OFFSET] & 0xf) {
+ 		       /* w1 b00:03 */
+ 		       fcport->fc4_type =
+ 			   ct_rsp->rsp.gff_id.fc4_features[GFF_FCP_SCSI_OFFSET];
+ 		       fcport->fc4_type &= 0xf;
+ 	       }
+ 
+ 	       if (ct_rsp->rsp.gff_id.fc4_features[GFF_NVME_OFFSET] & 0xf) {
+ 		       /* w5 [00:03]/28h */
+ 		       fcport->fc4f_nvme =
+ 			   ct_rsp->rsp.gff_id.fc4_features[GFF_NVME_OFFSET];
+ 		       fcport->fc4f_nvme &= 0xf;
+ 	       }
+        }
+ 
+        memset(&ea, 0, sizeof(ea));
+        ea.sp = sp;
+        ea.fcport = sp->fcport;
+        ea.rc = res;
+        ea.event = FCME_GFFID_DONE;
+ 
+        qla2x00_fcport_event_handler(vha, &ea);
+        sp->free(sp);
+ }
+ 
+ /* Get FC4 Feature with Nport ID. */
+ int qla24xx_async_gffid(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online || (fcport->flags & FCF_ASYNC_SENT))
+ 		return rval;
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		return rval;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gffid";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(fcport->ct_desc.ct_sns, GFF_ID_CMD,
+ 	    GFF_ID_RSP_SIZE);
+ 
+ 	ct_req->req.gff_id.port_id[0] = fcport->d_id.b.domain;
+ 	ct_req->req.gff_id.port_id[1] = fcport->d_id.b.area;
+ 	ct_req->req.gff_id.port_id[2] = fcport->d_id.b.al_pa;
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GFF_ID_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GFF_ID_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->done = qla24xx_async_gffid_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2132,
+ 	    "Async-%s hdl=%x  %8phC.\n", sp->name,
+ 	    sp->handle, fcport->port_name);
+ 
+ 	return rval;
+ done_free_sp:
+ 	sp->free(sp);
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ /* GPN_FT + GNN_FT*/
+ static int qla2x00_is_a_vp(scsi_qla_host_t *vha, u64 wwn)
+ {
+ 	struct qla_hw_data *ha = vha->hw;
+ 	scsi_qla_host_t *vp;
+ 	unsigned long flags;
+ 	u64 twwn;
+ 	int rc = 0;
+ 
+ 	if (!ha->num_vhosts)
+ 		return 0;
+ 
+ 	spin_lock_irqsave(&ha->vport_slock, flags);
+ 	list_for_each_entry(vp, &ha->vp_list, list) {
+ 		twwn = wwn_to_u64(vp->port_name);
+ 		if (wwn == twwn) {
+ 			rc = 1;
+ 			break;
+ 		}
+ 	}
+ 	spin_unlock_irqrestore(&ha->vport_slock, flags);
+ 
+ 	return rc;
+ }
+ 
+ void qla24xx_async_gnnft_done(scsi_qla_host_t *vha, srb_t *sp)
+ {
+ 	fc_port_t *fcport;
+ 	u32 i, rc;
+ 	bool found;
+ 	struct fab_scan_rp *rp;
+ 	unsigned long flags;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s enter\n", __func__);
+ 
+ 	if (sp->gen1 != vha->hw->base_qpair->chip_reset) {
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "%s scan stop due to chip reset %x/%x\n",
+ 		    sp->name, sp->gen1, vha->hw->base_qpair->chip_reset);
+ 		goto out;
+ 	}
+ 
+ 	rc = sp->rc;
+ 	if (rc) {
+ 		vha->scan.scan_retry++;
+ 		if (vha->scan.scan_retry < MAX_SCAN_RETRIES) {
+ 			set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 			set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 			    "Fabric scan failed on all retries.\n");
+ 		}
+ 		goto out;
+ 	}
+ 	vha->scan.scan_retry = 0;
+ 
+ 	list_for_each_entry(fcport, &vha->vp_fcports, list)
+ 		fcport->scan_state = QLA_FCPORT_SCAN;
+ 
+ 	for (i = 0; i < vha->hw->max_fibre_devices; i++) {
+ 		u64 wwn;
+ 
+ 		rp = &vha->scan.l[i];
+ 		found = false;
+ 
+ 		wwn = wwn_to_u64(rp->port_name);
+ 		if (wwn == 0)
+ 			continue;
+ 
+ 		if (!memcmp(rp->port_name, vha->port_name, WWN_SIZE))
+ 			continue;
+ 
+ 		/* Bypass reserved domain fields. */
+ 		if ((rp->id.b.domain & 0xf0) == 0xf0)
+ 			continue;
+ 
+ 		/* Bypass virtual ports of the same host. */
+ 		if (qla2x00_is_a_vp(vha, wwn))
+ 			continue;
+ 
+ 		list_for_each_entry(fcport, &vha->vp_fcports, list) {
+ 			if (memcmp(rp->port_name, fcport->port_name, WWN_SIZE))
+ 				continue;
+ 			fcport->scan_state = QLA_FCPORT_FOUND;
+ 			fcport->d_id.b24 = rp->id.b24;
+ 			found = true;
+ 			/*
+ 			 * If device was not a fabric device before.
+ 			 */
+ 			if ((fcport->flags & FCF_FABRIC_DEVICE) == 0) {
+ 				qla2x00_clear_loop_id(fcport);
+ 				fcport->flags |= FCF_FABRIC_DEVICE;
+ 			}
+ 			break;
+ 		}
+ 
+ 		if (!found) {
+ 			ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 			    "%s %d %8phC post new sess\n",
+ 			    __func__, __LINE__, rp->port_name);
+ 			qla24xx_post_newsess_work(vha, &rp->id, rp->port_name,
+ 			    rp->node_name, NULL, rp->fc4type);
+ 		}
+ 	}
+ 
+ 	/*
+ 	 * Logout all previous fabric dev marked lost, except FCP2 devices.
+ 	 */
+ 	list_for_each_entry(fcport, &vha->vp_fcports, list) {
+ 		if ((fcport->flags & FCF_FABRIC_DEVICE) == 0)
+ 			continue;
+ 
+ 		if (fcport->scan_state != QLA_FCPORT_FOUND) {
+ 			if ((qla_dual_mode_enabled(vha) ||
+ 				qla_ini_mode_enabled(vha)) &&
+ 			    atomic_read(&fcport->state) == FCS_ONLINE) {
+ 				qla2x00_mark_device_lost(vha, fcport,
+ 				    ql2xplogiabsentdevice, 0);
+ 
+ 				if (fcport->loop_id != FC_NO_LOOP_ID &&
+ 				    (fcport->flags & FCF_FCP2_DEVICE) == 0) {
+ 					ql_dbg(ql_dbg_disc, vha, 0x20f0,
+ 					    "%s %d %8phC post del sess\n",
+ 					    __func__, __LINE__,
+ 					    fcport->port_name);
+ 
+ 					qlt_schedule_sess_for_deletion(fcport);
+ 					continue;
+ 				}
+ 			}
+ 		} else
+ 			qla24xx_fcport_handle_login(vha, fcport);
+ 	}
+ 
+ out:
+ 	qla24xx_sp_unmap(vha, sp);
+ 	spin_lock_irqsave(&vha->work_lock, flags);
+ 	vha->scan.scan_flags &= ~SF_SCANNING;
+ 	spin_unlock_irqrestore(&vha->work_lock, flags);
+ }
+ 
+ static void qla2x00_find_free_fcp_nvme_slot(struct scsi_qla_host *vha,
+ 	struct srb *sp)
+ {
+ 	struct qla_hw_data *ha = vha->hw;
+ 	int num_fibre_dev = ha->max_fibre_devices;
+ 	struct ct_sns_req *ct_req =
+ 		(struct ct_sns_req *)sp->u.iocb_cmd.u.ctarg.req;
+ 	struct ct_sns_gpnft_rsp *ct_rsp =
+ 		(struct ct_sns_gpnft_rsp *)sp->u.iocb_cmd.u.ctarg.rsp;
+ 	struct ct_sns_gpn_ft_data *d;
+ 	struct fab_scan_rp *rp;
+ 	u16 cmd = be16_to_cpu(ct_req->command);
+ 	u8 fc4_type = sp->gen2;
+ 	int i, j, k;
+ 	port_id_t id;
+ 	u8 found;
+ 	u64 wwn;
+ 
+ 	j = 0;
+ 	for (i = 0; i < num_fibre_dev; i++) {
+ 		d  = &ct_rsp->entries[i];
+ 
+ 		id.b.rsvd_1 = 0;
+ 		id.b.domain = d->port_id[0];
+ 		id.b.area   = d->port_id[1];
+ 		id.b.al_pa  = d->port_id[2];
+ 		wwn = wwn_to_u64(d->port_name);
+ 
+ 		if (id.b24 == 0 || wwn == 0)
+ 			continue;
+ 
+ 		if (fc4_type == FC4_TYPE_FCP_SCSI) {
+ 			if (cmd == GPN_FT_CMD) {
+ 				rp = &vha->scan.l[j];
+ 				rp->id = id;
+ 				memcpy(rp->port_name, d->port_name, 8);
+ 				j++;
+ 				rp->fc4type = FS_FC4TYPE_FCP;
+ 			} else {
+ 				for (k = 0; k < num_fibre_dev; k++) {
+ 					rp = &vha->scan.l[k];
+ 					if (id.b24 == rp->id.b24) {
+ 						memcpy(rp->node_name,
+ 						    d->port_name, 8);
+ 						break;
+ 					}
+ 				}
+ 			}
+ 		} else {
+ 			/* Search if the fibre device supports FC4_TYPE_NVME */
+ 			if (cmd == GPN_FT_CMD) {
+ 				found = 0;
+ 
+ 				for (k = 0; k < num_fibre_dev; k++) {
+ 					rp = &vha->scan.l[k];
+ 					if (!memcmp(rp->port_name,
+ 					    d->port_name, 8)) {
+ 						/*
+ 						 * Supports FC-NVMe & FCP
+ 						 */
+ 						rp->fc4type |= FS_FC4TYPE_NVME;
+ 						found = 1;
+ 						break;
+ 					}
+ 				}
+ 
+ 				/* We found new FC-NVMe only port */
+ 				if (!found) {
+ 					for (k = 0; k < num_fibre_dev; k++) {
+ 						rp = &vha->scan.l[k];
+ 						if (wwn_to_u64(rp->port_name)) {
+ 							continue;
+ 						} else {
+ 							rp->id = id;
+ 							memcpy(rp->port_name,
+ 							    d->port_name, 8);
+ 							rp->fc4type =
+ 							    FS_FC4TYPE_NVME;
+ 							break;
+ 						}
+ 					}
+ 				}
+ 			} else {
+ 				for (k = 0; k < num_fibre_dev; k++) {
+ 					rp = &vha->scan.l[k];
+ 					if (id.b24 == rp->id.b24) {
+ 						memcpy(rp->node_name,
+ 						    d->port_name, 8);
+ 						break;
+ 					}
+ 				}
+ 			}
+ 		}
+ 	}
+ }
+ 
+ static void qla2x00_async_gpnft_gnnft_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	struct qla_work_evt *e;
+ 	struct ct_sns_req *ct_req =
+ 		(struct ct_sns_req *)sp->u.iocb_cmd.u.ctarg.req;
+ 	u16 cmd = be16_to_cpu(ct_req->command);
+ 	u8 fc4_type = sp->gen2;
+ 	unsigned long flags;
+ 
+ 	/* gen2 field is holding the fc4type */
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async done-%s res %x FC4Type %x\n",
+ 	    sp->name, res, sp->gen2);
+ 
+ 	if (res) {
+ 		unsigned long flags;
+ 
+ 		sp->free(sp);
+ 		spin_lock_irqsave(&vha->work_lock, flags);
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		vha->scan.scan_retry++;
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 
+ 		if (vha->scan.scan_retry < MAX_SCAN_RETRIES) {
+ 			set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 			set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 			qla2xxx_wake_dpc(vha);
+ 		} else {
+ 			ql_dbg(ql_dbg_disc, sp->vha, 0xffff,
+ 			    "Async done-%s rescan failed on all retries\n",
+ 			    sp->name);
+ 		}
+ 		return;
+ 	}
+ 
+ 	if (!res)
+ 		qla2x00_find_free_fcp_nvme_slot(vha, sp);
+ 
+ 	if ((fc4_type == FC4_TYPE_FCP_SCSI) && vha->flags.nvme_enabled &&
+ 	    cmd == GNN_FT_CMD) {
+ 		del_timer(&sp->u.iocb_cmd.timer);
+ 		spin_lock_irqsave(&vha->work_lock, flags);
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 
+ 		e = qla2x00_alloc_work(vha, QLA_EVT_GPNFT);
+ 		if (!e) {
+ 			/*
+ 			 * please ignore kernel warning. Otherwise,
+ 			 * we have mem leak.
+ 			 */
+ 			if (sp->u.iocb_cmd.u.ctarg.req) {
+ 				dma_free_coherent(&vha->hw->pdev->dev,
+ 				    sizeof(struct ct_sns_pkt),
+ 				    sp->u.iocb_cmd.u.ctarg.req,
+ 				    sp->u.iocb_cmd.u.ctarg.req_dma);
+ 				sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 			}
+ 			if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 				dma_free_coherent(&vha->hw->pdev->dev,
+ 				    sizeof(struct ct_sns_pkt),
+ 				    sp->u.iocb_cmd.u.ctarg.rsp,
+ 				    sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 				sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 			}
+ 
+ 			ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 			    "Async done-%s unable to alloc work element\n",
+ 			    sp->name);
+ 			sp->free(sp);
+ 			set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 			set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 			return;
+ 		}
+ 		e->u.gpnft.fc4_type = FC4_TYPE_NVME;
+ 		sp->rc = res;
+ 		e->u.gpnft.sp = sp;
+ 
+ 		qla2x00_post_work(vha, e);
+ 		return;
+ 	}
+ 
+ 	if (cmd == GPN_FT_CMD)
+ 		e = qla2x00_alloc_work(vha, QLA_EVT_GPNFT_DONE);
+ 	else
+ 		e = qla2x00_alloc_work(vha, QLA_EVT_GNNFT_DONE);
+ 	if (!e) {
+ 		/* please ignore kernel warning. Otherwise, we have mem leak. */
+ 		if (sp->u.iocb_cmd.u.ctarg.req) {
+ 			dma_free_coherent(&vha->hw->pdev->dev,
+ 			    sizeof(struct ct_sns_pkt),
+ 			    sp->u.iocb_cmd.u.ctarg.req,
+ 			    sp->u.iocb_cmd.u.ctarg.req_dma);
+ 			sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 		}
+ 		if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 			dma_free_coherent(&vha->hw->pdev->dev,
+ 			    sizeof(struct ct_sns_pkt),
+ 			    sp->u.iocb_cmd.u.ctarg.rsp,
+ 			    sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 			sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 		}
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "Async done-%s unable to alloc work element\n",
+ 		    sp->name);
+ 		sp->free(sp);
+ 		set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 		set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 		return;
+ 	}
+ 
+ 	sp->rc = res;
+ 	e->u.iosb.sp = sp;
+ 
+ 	qla2x00_post_work(vha, e);
+ }
+ 
+ /*
+  * Get WWNN list for fc4_type
+  *
+  * It is assumed the same SRB is re-used from GPNFT to avoid
+  * mem free & re-alloc
+  */
+ static int qla24xx_async_gnnft(scsi_qla_host_t *vha, struct srb *sp,
+     u8 fc4_type)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req *ct_req;
+ 	struct ct_sns_pkt *ct_sns;
+ 	unsigned long flags;
+ 
+ 	if (!vha->flags.online) {
+ 		spin_lock_irqsave(&vha->work_lock, flags);
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 		goto done_free_sp;
+ 	}
+ 
+ 	if (!sp->u.iocb_cmd.u.ctarg.req || !sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		ql_log(ql_log_warn, vha, 0xffff,
+ 		    "%s: req %p rsp %p are not setup\n",
+ 		    __func__, sp->u.iocb_cmd.u.ctarg.req,
+ 		    sp->u.iocb_cmd.u.ctarg.rsp);
+ 		spin_lock_irqsave(&vha->work_lock, flags);
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 		WARN_ON(1);
+ 		goto done_free_sp;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xfffff,
+ 	    "%s: FC4Type %x, CT-PASSTRHU %s command ctarg rsp size %d, ctarg req size %d\n",
+ 	    __func__, fc4_type, sp->name, sp->u.iocb_cmd.u.ctarg.rsp_size,
+ 	     sp->u.iocb_cmd.u.ctarg.req_size);
+ 
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gnnft";
+ 	sp->gen1 = vha->hw->base_qpair->chip_reset;
+ 	sp->gen2 = fc4_type;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	memset(sp->u.iocb_cmd.u.ctarg.rsp, 0, sp->u.iocb_cmd.u.ctarg.rsp_size);
+ 	memset(sp->u.iocb_cmd.u.ctarg.req, 0, sp->u.iocb_cmd.u.ctarg.req_size);
+ 
+ 	ct_sns = (struct ct_sns_pkt *)sp->u.iocb_cmd.u.ctarg.req;
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(ct_sns, GNN_FT_CMD,
+ 	    sp->u.iocb_cmd.u.ctarg.rsp_size);
+ 
+ 	/* GPN_FT req */
+ 	ct_req->req.gpn_ft.port_type = fc4_type;
+ 
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GNN_FT_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->done = qla2x00_async_gpnft_gnnft_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async-%s hdl=%x FC4Type %x.\n", sp->name,
+ 	    sp->handle, ct_req->req.gpn_ft.port_type);
+ 	return rval;
+ 
+ done_free_sp:
+ 	if (sp->u.iocb_cmd.u.ctarg.req) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 		    sizeof(struct ct_sns_pkt),
+ 		    sp->u.iocb_cmd.u.ctarg.req,
+ 		    sp->u.iocb_cmd.u.ctarg.req_dma);
+ 		sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 	}
+ 	if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 		    sizeof(struct ct_sns_pkt),
+ 		    sp->u.iocb_cmd.u.ctarg.rsp,
+ 		    sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 		sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 	}
+ 
+ 	sp->free(sp);
+ 
+ 	return rval;
+ } /* GNNFT */
+ 
+ void qla24xx_async_gpnft_done(scsi_qla_host_t *vha, srb_t *sp)
+ {
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s enter\n", __func__);
+ 	del_timer(&sp->u.iocb_cmd.timer);
+ 	qla24xx_async_gnnft(vha, sp, sp->gen2);
+ }
+ 
+ /* Get WWPN list for certain fc4_type */
+ int qla24xx_async_gpnft(scsi_qla_host_t *vha, u8 fc4_type, srb_t *sp)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	struct ct_sns_pkt *ct_sns;
+ 	u32 rspsz;
+ 	unsigned long flags;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s enter\n", __func__);
+ 
+ 	if (!vha->flags.online)
+ 		return rval;
+ 
+ 	spin_lock_irqsave(&vha->work_lock, flags);
+ 	if (vha->scan.scan_flags & SF_SCANNING) {
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff, "scan active\n");
+ 		return rval;
+ 	}
+ 	vha->scan.scan_flags |= SF_SCANNING;
+ 	spin_unlock_irqrestore(&vha->work_lock, flags);
+ 
+ 	if (fc4_type == FC4_TYPE_FCP_SCSI) {
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "%s: Performing FCP Scan\n", __func__);
+ 
+ 		if (sp)
+ 			sp->free(sp); /* should not happen */
+ 
+ 		sp = qla2x00_get_sp(vha, NULL, GFP_KERNEL);
+ 		if (!sp) {
+ 			spin_lock_irqsave(&vha->work_lock, flags);
+ 			vha->scan.scan_flags &= ~SF_SCANNING;
+ 			spin_unlock_irqrestore(&vha->work_lock, flags);
+ 			return rval;
+ 		}
+ 
+ 		sp->u.iocb_cmd.u.ctarg.req = dma_zalloc_coherent(
+ 			&vha->hw->pdev->dev, sizeof(struct ct_sns_pkt),
+ 			&sp->u.iocb_cmd.u.ctarg.req_dma, GFP_KERNEL);
+ 		if (!sp->u.iocb_cmd.u.ctarg.req) {
+ 			ql_log(ql_log_warn, vha, 0xffff,
+ 			    "Failed to allocate ct_sns request.\n");
+ 			spin_lock_irqsave(&vha->work_lock, flags);
+ 			vha->scan.scan_flags &= ~SF_SCANNING;
+ 			spin_unlock_irqrestore(&vha->work_lock, flags);
+ 			goto done_free_sp;
+ 		}
+ 		sp->u.iocb_cmd.u.ctarg.req_size = GPN_FT_REQ_SIZE;
+ 
+ 		rspsz = sizeof(struct ct_sns_gpnft_rsp) +
+ 			((vha->hw->max_fibre_devices - 1) *
+ 			    sizeof(struct ct_sns_gpn_ft_data));
+ 
+ 		sp->u.iocb_cmd.u.ctarg.rsp = dma_zalloc_coherent(
+ 			&vha->hw->pdev->dev, rspsz,
+ 			&sp->u.iocb_cmd.u.ctarg.rsp_dma, GFP_KERNEL);
+ 		if (!sp->u.iocb_cmd.u.ctarg.rsp) {
+ 			ql_log(ql_log_warn, vha, 0xffff,
+ 			    "Failed to allocate ct_sns request.\n");
+ 			spin_lock_irqsave(&vha->work_lock, flags);
+ 			vha->scan.scan_flags &= ~SF_SCANNING;
+ 			spin_unlock_irqrestore(&vha->work_lock, flags);
+ 			goto done_free_sp;
+ 		}
+ 		sp->u.iocb_cmd.u.ctarg.rsp_size = rspsz;
+ 
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "%s scan list size %d\n", __func__, vha->scan.size);
+ 
+ 		memset(vha->scan.l, 0, vha->scan.size);
+ 	} else if (!sp) {
+ 		ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 		    "NVME scan did not provide SP\n");
+ 		return rval;
+ 	}
+ 
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gpnft";
+ 	sp->gen1 = vha->hw->base_qpair->chip_reset;
+ 	sp->gen2 = fc4_type;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	rspsz = sizeof(struct ct_sns_gpnft_rsp) +
+ 		((vha->hw->max_fibre_devices - 1) *
+ 		    sizeof(struct ct_sns_gpn_ft_data));
+ 
+ 	ct_sns = (struct ct_sns_pkt *)sp->u.iocb_cmd.u.ctarg.req;
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(ct_sns, GPN_FT_CMD, rspsz);
+ 
+ 	/* GPN_FT req */
+ 	ct_req->req.gpn_ft.port_type = fc4_type;
+ 
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->done = qla2x00_async_gpnft_gnnft_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS) {
+ 		spin_lock_irqsave(&vha->work_lock, flags);
+ 		vha->scan.scan_flags &= ~SF_SCANNING;
+ 		spin_unlock_irqrestore(&vha->work_lock, flags);
+ 		goto done_free_sp;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async-%s hdl=%x FC4Type %x.\n", sp->name,
+ 	    sp->handle, ct_req->req.gpn_ft.port_type);
+ 	return rval;
+ 
+ done_free_sp:
+ 	if (sp->u.iocb_cmd.u.ctarg.req) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 		    sizeof(struct ct_sns_pkt),
+ 		    sp->u.iocb_cmd.u.ctarg.req,
+ 		    sp->u.iocb_cmd.u.ctarg.req_dma);
+ 		sp->u.iocb_cmd.u.ctarg.req = NULL;
+ 	}
+ 	if (sp->u.iocb_cmd.u.ctarg.rsp) {
+ 		dma_free_coherent(&vha->hw->pdev->dev,
+ 		    sizeof(struct ct_sns_pkt),
+ 		    sp->u.iocb_cmd.u.ctarg.rsp,
+ 		    sp->u.iocb_cmd.u.ctarg.rsp_dma);
+ 		sp->u.iocb_cmd.u.ctarg.rsp = NULL;
+ 	}
+ 
+ 	sp->free(sp);
+ 
+ 	return rval;
+ }
+ 
+ void qla_scan_work_fn(struct work_struct *work)
+ {
+ 	struct fab_scan *s = container_of(to_delayed_work(work),
+ 	    struct fab_scan, scan_work);
+ 	struct scsi_qla_host *vha = container_of(s, struct scsi_qla_host,
+ 	    scan);
+ 	unsigned long flags;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s: schedule loop resync\n", __func__);
+ 	set_bit(LOCAL_LOOP_UPDATE, &vha->dpc_flags);
+ 	set_bit(LOOP_RESYNC_NEEDED, &vha->dpc_flags);
+ 	qla2xxx_wake_dpc(vha);
+ 	spin_lock_irqsave(&vha->work_lock, flags);
+ 	vha->scan.scan_flags &= ~SF_QUEUED;
+ 	spin_unlock_irqrestore(&vha->work_lock, flags);
+ }
+ 
+ /* GNN_ID */
+ void qla24xx_handle_gnnid_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	qla24xx_post_gnl_work(vha, ea->fcport);
+ }
+ 
+ static void qla2x00_async_gnnid_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	fc_port_t *fcport = sp->fcport;
+ 	u8 *node_name = fcport->ct_desc.ct_sns->p.rsp.rsp.gnn_id.node_name;
+ 	struct event_arg ea;
+ 	u64 wwnn;
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	wwnn = wwn_to_u64(node_name);
+ 	if (wwnn)
+ 		memcpy(fcport->node_name, node_name, WWN_SIZE);
+ 
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.fcport = fcport;
+ 	ea.sp = sp;
+ 	ea.rc = res;
+ 	ea.event = FCME_GNNID_DONE;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x204f,
+ 	    "Async done-%s res %x, WWPN %8phC %8phC\n",
+ 	    sp->name, res, fcport->port_name, fcport->node_name);
+ 
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_gnnid(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online || (fcport->flags & FCF_ASYNC_SENT))
+ 		return rval;
+ 
+ 	fcport->disc_state = DSC_GNN_ID;
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_ATOMIC);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gnnid";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(fcport->ct_desc.ct_sns, GNN_ID_CMD,
+ 	    GNN_ID_RSP_SIZE);
+ 
+ 	/* GNN_ID req */
+ 	ct_req->req.port_id.port_id[0] = fcport->d_id.b.domain;
+ 	ct_req->req.port_id.port_id[1] = fcport->d_id.b.area;
+ 	ct_req->req.port_id.port_id[2] = fcport->d_id.b.al_pa;
+ 
+ 
+ 	/* req & rsp use the same buffer */
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GNN_ID_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GNN_ID_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->done = qla2x00_async_gnnid_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async-%s - %8phC hdl=%x loopid=%x portid %06x.\n",
+ 	    sp->name, fcport->port_name,
+ 	    sp->handle, fcport->loop_id, fcport->d_id.b24);
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ done:
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gnnid_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 	int ls;
+ 
+ 	ls = atomic_read(&vha->loop_state);
+ 	if (((ls != LOOP_READY) && (ls != LOOP_UP)) ||
+ 		test_bit(UNLOADING, &vha->dpc_flags))
+ 		return 0;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GNNID);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ /* GPFN_ID */
+ void qla24xx_handle_gfpnid_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	fc_port_t *fcport = ea->fcport;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "%s %8phC DS %d LS %d rc %d login %d|%d rscn %d|%d fcpcnt %d\n",
+ 	    __func__, fcport->port_name, fcport->disc_state,
+ 	    fcport->fw_login_state, ea->rc, fcport->login_gen, ea->sp->gen2,
+ 	    fcport->rscn_gen, ea->sp->gen1, vha->fcport_count);
+ 
+ 	if (fcport->disc_state == DSC_DELETE_PEND)
+ 		return;
+ 
+ 	if (ea->sp->gen2 != fcport->login_gen) {
+ 		/* target side must have changed it. */
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d3,
+ 		    "%s %8phC generation changed\n",
+ 		    __func__, fcport->port_name);
+ 		return;
+ 	} else if (ea->sp->gen1 != fcport->rscn_gen) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d4, "%s %d %8phC post gidpn\n",
+ 		    __func__, __LINE__, fcport->port_name);
+ 		qla24xx_post_gidpn_work(vha, fcport);
+ 		return;
+ 	}
+ 
+ 	qla24xx_post_gpsc_work(vha, fcport);
+ }
+ 
+ static void qla2x00_async_gfpnid_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	fc_port_t *fcport = sp->fcport;
+ 	u8 *fpn = fcport->ct_desc.ct_sns->p.rsp.rsp.gfpn_id.port_name;
+ 	struct event_arg ea;
+ 	u64 wwn;
+ 
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	wwn = wwn_to_u64(fpn);
+ 	if (wwn)
+ 		memcpy(fcport->fabric_port_name, fpn, WWN_SIZE);
+ 
+ 	memset(&ea, 0, sizeof(ea));
+ 	ea.fcport = fcport;
+ 	ea.sp = sp;
+ 	ea.rc = res;
+ 	ea.event = FCME_GFPNID_DONE;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x204f,
+ 	    "Async done-%s res %x, WWPN %8phC %8phC\n",
+ 	    sp->name, res, fcport->port_name, fcport->fabric_port_name);
+ 
+ 	qla2x00_fcport_event_handler(vha, &ea);
+ 
+ 	sp->free(sp);
+ }
+ 
+ int qla24xx_async_gfpnid(scsi_qla_host_t *vha, fc_port_t *fcport)
+ {
+ 	int rval = QLA_FUNCTION_FAILED;
+ 	struct ct_sns_req       *ct_req;
+ 	srb_t *sp;
+ 
+ 	if (!vha->flags.online || (fcport->flags & FCF_ASYNC_SENT))
+ 		return rval;
+ 
+ 	fcport->disc_state = DSC_GFPN_ID;
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_ATOMIC);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	sp->type = SRB_CT_PTHRU_CMD;
+ 	sp->name = "gfpnid";
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
+ 
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	/* CT_IU preamble  */
+ 	ct_req = qla2x00_prep_ct_req(fcport->ct_desc.ct_sns, GFPN_ID_CMD,
+ 	    GFPN_ID_RSP_SIZE);
+ 
+ 	/* GFPN_ID req */
+ 	ct_req->req.port_id.port_id[0] = fcport->d_id.b.domain;
+ 	ct_req->req.port_id.port_id[1] = fcport->d_id.b.area;
+ 	ct_req->req.port_id.port_id[2] = fcport->d_id.b.al_pa;
+ 
+ 
+ 	/* req & rsp use the same buffer */
+ 	sp->u.iocb_cmd.u.ctarg.req = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.req_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.rsp = fcport->ct_desc.ct_sns;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_dma = fcport->ct_desc.ct_sns_dma;
+ 	sp->u.iocb_cmd.u.ctarg.req_size = GFPN_ID_REQ_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.rsp_size = GFPN_ID_RSP_SIZE;
+ 	sp->u.iocb_cmd.u.ctarg.nport_handle = NPH_SNS;
+ 
+ 	sp->done = qla2x00_async_gfpnid_sp_done;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0xffff,
+ 	    "Async-%s - %8phC hdl=%x loopid=%x portid %06x.\n",
+ 	    sp->name, fcport->port_name,
+ 	    sp->handle, fcport->loop_id, fcport->d_id.b24);
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ done:
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gfpnid_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 	int ls;
+ 
+ 	ls = atomic_read(&vha->loop_state);
+ 	if (((ls != LOOP_READY) && (ls != LOOP_UP)) ||
+ 		test_bit(UNLOADING, &vha->dpc_flags))
+ 		return 0;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_GFPNID);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 	return qla2x00_post_work(vha, e);
+ }
++>>>>>>> e74e7d95878d (scsi: qla2xxx: Fix race condition between iocb timeout and initialisation)
diff --cc drivers/scsi/qla2xxx/qla_init.c
index f74932ce86ba,8f55dd44adae..000000000000
--- a/drivers/scsi/qla2xxx/qla_init.c
+++ b/drivers/scsi/qla2xxx/qla_init.c
@@@ -193,14 -178,22 +193,21 @@@ qla2x00_async_login(struct scsi_qla_hos
  	fcport->flags |= FCF_ASYNC_SENT;
  	fcport->logout_completed = 0;
  
 -	fcport->disc_state = DSC_LOGIN_PEND;
  	sp->type = SRB_LOGIN_CMD;
  	sp->name = "login";
++<<<<<<< HEAD
 +	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
++=======
+ 	sp->gen1 = fcport->rscn_gen;
+ 	sp->gen2 = fcport->login_gen;
++>>>>>>> e74e7d95878d (scsi: qla2xxx: Fix race condition between iocb timeout and initialisation)
  
  	lio = &sp->u.iocb_cmd;
  	lio->timeout = qla2x00_async_iocb_timeout;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
  	sp->done = qla2x00_async_login_sp_done;
  	lio->u.logio.flags |= SRB_LOGIN_COND_PLOGI;
 -
 -	if (fcport->fc4f_nvme)
 -		lio->u.logio.flags |= SRB_LOGIN_SKIP_PRLI;
 -
  	if (data[1] & QLA_LOGIO_LOGIN_RETRIED)
  		lio->u.logio.flags |= SRB_LOGIN_RETRIED;
  	rval = qla2x00_start_sp(sp);
@@@ -276,6 -270,106 +284,109 @@@ done
  	return rval;
  }
  
++<<<<<<< HEAD
++=======
+ void
+ qla2x00_async_prlo_done(struct scsi_qla_host *vha, fc_port_t *fcport,
+     uint16_t *data)
+ {
+ 	fcport->flags &= ~FCF_ASYNC_ACTIVE;
+ 	/* Don't re-login in target mode */
+ 	if (!fcport->tgt_session)
+ 		qla2x00_mark_device_lost(vha, fcport, 1, 0);
+ 	qlt_logo_completion_handler(fcport, data[0]);
+ }
+ 
+ static void
+ qla2x00_async_prlo_sp_done(void *s, int res)
+ {
+ 	srb_t *sp = (srb_t *)s;
+ 	struct srb_iocb *lio = &sp->u.iocb_cmd;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 
+ 	sp->fcport->flags &= ~FCF_ASYNC_ACTIVE;
+ 	if (!test_bit(UNLOADING, &vha->dpc_flags))
+ 		qla2x00_post_async_prlo_done_work(sp->fcport->vha, sp->fcport,
+ 		    lio->u.logio.data);
+ 	sp->free(sp);
+ }
+ 
+ int
+ qla2x00_async_prlo(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	srb_t *sp;
+ 	struct srb_iocb *lio;
+ 	int rval;
+ 
+ 	rval = QLA_FUNCTION_FAILED;
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	sp->type = SRB_PRLO_CMD;
+ 	sp->name = "prlo";
+ 
+ 	lio = &sp->u.iocb_cmd;
+ 	lio->timeout = qla2x00_async_iocb_timeout;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	sp->done = qla2x00_async_prlo_sp_done;
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS)
+ 		goto done_free_sp;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2070,
+ 	    "Async-prlo - hdl=%x loop-id=%x portid=%02x%02x%02x.\n",
+ 	    sp->handle, fcport->loop_id, fcport->d_id.b.domain,
+ 	    fcport->d_id.b.area, fcport->d_id.b.al_pa);
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ done:
+ 	fcport->flags &= ~FCF_ASYNC_ACTIVE;
+ 	return rval;
+ }
+ 
+ static
+ void qla24xx_handle_adisc_event(scsi_qla_host_t *vha, struct event_arg *ea)
+ {
+ 	struct fc_port *fcport = ea->fcport;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x20d2,
+ 	    "%s %8phC DS %d LS %d rc %d login %d|%d rscn %d|%d lid %d\n",
+ 	    __func__, fcport->port_name, fcport->disc_state,
+ 	    fcport->fw_login_state, ea->rc, fcport->login_gen, ea->sp->gen2,
+ 	    fcport->rscn_gen, ea->sp->gen1, fcport->loop_id);
+ 
+ 	if (ea->data[0] != MBS_COMMAND_COMPLETE) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x2066,
+ 		    "%s %8phC: adisc fail: post delete\n",
+ 		    __func__, ea->fcport->port_name);
+ 		qlt_schedule_sess_for_deletion(ea->fcport);
+ 		return;
+ 	}
+ 
+ 	if (ea->fcport->disc_state == DSC_DELETE_PEND)
+ 		return;
+ 
+ 	if (ea->sp->gen2 != ea->fcport->login_gen) {
+ 		/* target side must have changed it. */
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d3,
+ 		    "%s %8phC generation changed\n",
+ 		    __func__, ea->fcport->port_name);
+ 		return;
+ 	} else if (ea->sp->gen1 != ea->fcport->rscn_gen) {
+ 		ql_dbg(ql_dbg_disc, vha, 0x20d4, "%s %d %8phC post gidpn\n",
+ 		    __func__, __LINE__, ea->fcport->port_name);
+ 		qla24xx_post_gidpn_work(vha, ea->fcport);
+ 		return;
+ 	}
+ 
+ 	__qla24xx_handle_gpdb_event(vha, ea);
+ }
+ 
++>>>>>>> e74e7d95878d (scsi: qla2xxx: Fix race condition between iocb timeout and initialisation)
  static void
  qla2x00_async_adisc_sp_done(void *ptr, int res)
  {
@@@ -675,8 -824,104 +786,109 @@@ gpd_error_out
  	sp->free(sp);
  }
  
++<<<<<<< HEAD
 +static int qla24xx_post_gpdb_work(struct scsi_qla_host *vha, fc_port_t *fcport,
 +    u8 opt)
++=======
+ static int qla24xx_post_prli_work(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	struct qla_work_evt *e;
+ 
+ 	e = qla2x00_alloc_work(vha, QLA_EVT_PRLI);
+ 	if (!e)
+ 		return QLA_FUNCTION_FAILED;
+ 
+ 	e->u.fcport.fcport = fcport;
+ 
+ 	return qla2x00_post_work(vha, e);
+ }
+ 
+ static void
+ qla2x00_async_prli_sp_done(void *ptr, int res)
+ {
+ 	srb_t *sp = ptr;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	struct srb_iocb *lio = &sp->u.iocb_cmd;
+ 	struct event_arg ea;
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x2129,
+ 	    "%s %8phC res %d \n", __func__,
+ 	    sp->fcport->port_name, res);
+ 
+ 	sp->fcport->flags &= ~FCF_ASYNC_SENT;
+ 
+ 	if (!test_bit(UNLOADING, &vha->dpc_flags)) {
+ 		memset(&ea, 0, sizeof(ea));
+ 		ea.event = FCME_PRLI_DONE;
+ 		ea.fcport = sp->fcport;
+ 		ea.data[0] = lio->u.logio.data[0];
+ 		ea.data[1] = lio->u.logio.data[1];
+ 		ea.iop[0] = lio->u.logio.iop[0];
+ 		ea.iop[1] = lio->u.logio.iop[1];
+ 		ea.sp = sp;
+ 
+ 		qla2x00_fcport_event_handler(vha, &ea);
+ 	}
+ 
+ 	sp->free(sp);
+ }
+ 
+ int
+ qla24xx_async_prli(struct scsi_qla_host *vha, fc_port_t *fcport)
+ {
+ 	srb_t *sp;
+ 	struct srb_iocb *lio;
+ 	int rval = QLA_FUNCTION_FAILED;
+ 
+ 	if (!vha->flags.online)
+ 		return rval;
+ 
+ 	if (fcport->fw_login_state == DSC_LS_PLOGI_PEND ||
+ 	    fcport->fw_login_state == DSC_LS_PRLI_PEND)
+ 		return rval;
+ 
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp)
+ 		return rval;
+ 
+ 	fcport->flags |= FCF_ASYNC_SENT;
+ 	fcport->logout_completed = 0;
+ 
+ 	sp->type = SRB_PRLI_CMD;
+ 	sp->name = "prli";
+ 
+ 	lio = &sp->u.iocb_cmd;
+ 	lio->timeout = qla2x00_async_iocb_timeout;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 
+ 	sp->done = qla2x00_async_prli_sp_done;
+ 	lio->u.logio.flags = 0;
+ 
+ 	if  (fcport->fc4f_nvme)
+ 		lio->u.logio.flags |= SRB_LOGIN_NVME_PRLI;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS) {
+ 		fcport->flags |= FCF_LOGIN_NEEDED;
+ 		set_bit(RELOGIN_NEEDED, &vha->dpc_flags);
+ 		goto done_free_sp;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_disc, vha, 0x211b,
+ 	    "Async-prli - %8phC hdl=%x, loopid=%x portid=%06x retries=%d.\n",
+ 	    fcport->port_name, sp->handle, fcport->loop_id,
+ 	    fcport->d_id.b24, fcport->login_retry);
+ 
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ 	fcport->flags &= ~FCF_ASYNC_SENT;
+ 	return rval;
+ }
+ 
+ int qla24xx_post_gpdb_work(struct scsi_qla_host *vha, fc_port_t *fcport, u8 opt)
++>>>>>>> e74e7d95878d (scsi: qla2xxx: Fix race condition between iocb timeout and initialisation)
  {
  	struct qla_work_evt *e;
  
diff --cc drivers/scsi/qla2xxx/qla_inline.h
index 46fe0c121ac1,37ae0f6d8ae5..000000000000
--- a/drivers/scsi/qla2xxx/qla_inline.h
+++ b/drivers/scsi/qla2xxx/qla_inline.h
@@@ -270,12 -270,10 +270,15 @@@ qla2x00_rel_sp(srb_t *sp
  static inline void
  qla2x00_init_timer(srb_t *sp, unsigned long tmo)
  {
 -	timer_setup(&sp->u.iocb_cmd.timer, qla2x00_sp_timeout, 0);
 +	init_timer(&sp->u.iocb_cmd.timer);
  	sp->u.iocb_cmd.timer.expires = jiffies + tmo * HZ;
++<<<<<<< HEAD
 +	sp->u.iocb_cmd.timer.data = (unsigned long)sp;
 +	sp->u.iocb_cmd.timer.function = qla2x00_sp_timeout;
 +	add_timer(&sp->u.iocb_cmd.timer);
++=======
++>>>>>>> e74e7d95878d (scsi: qla2xxx: Fix race condition between iocb timeout and initialisation)
  	sp->free = qla2x00_sp_free;
 -	init_completion(&sp->comp);
  	if (IS_QLAFX00(sp->vha->hw) && (sp->type == SRB_FXIOCB_DCMD))
  		init_completion(&sp->u.iocb_cmd.u.fxiocb.fxiocb_comp);
  	if (sp->type == SRB_ELS_DCMD)
diff --cc drivers/scsi/qla2xxx/qla_iocb.c
index 548e89f3aaa9,a91cca52b5d5..000000000000
--- a/drivers/scsi/qla2xxx/qla_iocb.c
+++ b/drivers/scsi/qla2xxx/qla_iocb.c
@@@ -2565,9 -2568,162 +2565,164 @@@ qla24xx_els_logo_iocb(srb_t *sp, struc
  }
  
  static void
++<<<<<<< HEAD
++=======
+ qla2x00_els_dcmd2_sp_free(void *data)
+ {
+ 	srb_t *sp = data;
+ 	struct srb_iocb *elsio = &sp->u.iocb_cmd;
+ 
+ 	if (elsio->u.els_plogi.els_plogi_pyld)
+ 		dma_free_coherent(&sp->vha->hw->pdev->dev, DMA_POOL_SIZE,
+ 		    elsio->u.els_plogi.els_plogi_pyld,
+ 		    elsio->u.els_plogi.els_plogi_pyld_dma);
+ 
+ 	if (elsio->u.els_plogi.els_resp_pyld)
+ 		dma_free_coherent(&sp->vha->hw->pdev->dev, DMA_POOL_SIZE,
+ 		    elsio->u.els_plogi.els_resp_pyld,
+ 		    elsio->u.els_plogi.els_resp_pyld_dma);
+ 
+ 	del_timer(&elsio->timer);
+ 	qla2x00_rel_sp(sp);
+ }
+ 
+ static void
+ qla2x00_els_dcmd2_iocb_timeout(void *data)
+ {
+ 	srb_t *sp = data;
+ 	fc_port_t *fcport = sp->fcport;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	struct srb_iocb *lio = &sp->u.iocb_cmd;
+ 	unsigned long flags = 0;
+ 	int res;
+ 
+ 	ql_dbg(ql_dbg_io + ql_dbg_disc, vha, 0x3069,
+ 	    "%s hdl=%x ELS Timeout, %8phC portid=%06x\n",
+ 	    sp->name, sp->handle, fcport->port_name, fcport->d_id.b24);
+ 
+ 	/* Abort the exchange */
+ 	spin_lock_irqsave(&ha->hardware_lock, flags);
+ 	res = ha->isp_ops->abort_command(sp);
+ 	ql_dbg(ql_dbg_io, vha, 0x3070,
+ 	    "mbx abort_command %s\n",
+ 	    (res == QLA_SUCCESS) ? "successful" : "failed");
+ 	spin_unlock_irqrestore(&ha->hardware_lock, flags);
+ 
+ 	complete(&lio->u.els_plogi.comp);
+ }
+ 
+ static void
+ qla2x00_els_dcmd2_sp_done(void *ptr, int res)
+ {
+ 	srb_t *sp = ptr;
+ 	fc_port_t *fcport = sp->fcport;
+ 	struct srb_iocb *lio = &sp->u.iocb_cmd;
+ 	struct scsi_qla_host *vha = sp->vha;
+ 
+ 	ql_dbg(ql_dbg_io + ql_dbg_disc, vha, 0x3072,
+ 	    "%s ELS hdl=%x, portid=%06x done %8phC\n",
+ 	    sp->name, sp->handle, fcport->d_id.b24, fcport->port_name);
+ 
+ 	complete(&lio->u.els_plogi.comp);
+ }
+ 
+ int
+ qla24xx_els_dcmd2_iocb(scsi_qla_host_t *vha, int els_opcode,
+ 		       fc_port_t *fcport, port_id_t remote_did)
+ {
+ 	srb_t *sp;
+ 	struct srb_iocb *elsio = NULL;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	int rval = QLA_SUCCESS;
+ 	void	*ptr, *resp_ptr;
+ 	dma_addr_t ptr_dma;
+ 
+ 	/* Alloc SRB structure */
+ 	sp = qla2x00_get_sp(vha, fcport, GFP_KERNEL);
+ 	if (!sp) {
+ 		ql_log(ql_log_info, vha, 0x70e6,
+ 		 "SRB allocation failed\n");
+ 		return -ENOMEM;
+ 	}
+ 
+ 	elsio = &sp->u.iocb_cmd;
+ 	fcport->d_id.b.domain = remote_did.b.domain;
+ 	fcport->d_id.b.area = remote_did.b.area;
+ 	fcport->d_id.b.al_pa = remote_did.b.al_pa;
+ 
+ 	ql_dbg(ql_dbg_io, vha, 0x3073,
+ 	    "Enter: PLOGI portid=%06x\n", fcport->d_id.b24);
+ 
+ 	sp->type = SRB_ELS_DCMD;
+ 	sp->name = "ELS_DCMD";
+ 	sp->fcport = fcport;
+ 
+ 	elsio->timeout = qla2x00_els_dcmd2_iocb_timeout;
+ 	init_completion(&elsio->u.els_plogi.comp);
+ 	qla2x00_init_timer(sp, ELS_DCMD_TIMEOUT);
+ 
+ 	sp->done = qla2x00_els_dcmd2_sp_done;
+ 	sp->free = qla2x00_els_dcmd2_sp_free;
+ 
+ 	ptr = elsio->u.els_plogi.els_plogi_pyld =
+ 	    dma_alloc_coherent(&ha->pdev->dev, DMA_POOL_SIZE,
+ 		&elsio->u.els_plogi.els_plogi_pyld_dma, GFP_KERNEL);
+ 	ptr_dma = elsio->u.els_plogi.els_plogi_pyld_dma;
+ 
+ 	if (!elsio->u.els_plogi.els_plogi_pyld) {
+ 		rval = QLA_FUNCTION_FAILED;
+ 		goto out;
+ 	}
+ 
+ 	resp_ptr = elsio->u.els_plogi.els_resp_pyld =
+ 	    dma_alloc_coherent(&ha->pdev->dev, DMA_POOL_SIZE,
+ 		&elsio->u.els_plogi.els_resp_pyld_dma, GFP_KERNEL);
+ 
+ 	if (!elsio->u.els_plogi.els_resp_pyld) {
+ 		rval = QLA_FUNCTION_FAILED;
+ 		goto out;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_io, vha, 0x3073, "PLOGI %p %p\n", ptr, resp_ptr);
+ 
+ 	memset(ptr, 0, sizeof(struct els_plogi_payload));
+ 	memset(resp_ptr, 0, sizeof(struct els_plogi_payload));
+ 	elsio->u.els_plogi.els_cmd = els_opcode;
+ 	elsio->u.els_plogi.els_plogi_pyld->opcode = els_opcode;
+ 	qla24xx_get_port_login_templ(vha, ptr_dma + 4,
+ 		&elsio->u.els_plogi.els_plogi_pyld->data[0],
+ 		sizeof(struct els_plogi_payload));
+ 
+ 	ql_dbg(ql_dbg_io + ql_dbg_buffer, vha, 0x3073, "PLOGI buffer:\n");
+ 	ql_dump_buffer(ql_dbg_io + ql_dbg_buffer, vha, 0x0109,
+ 	    (uint8_t *)elsio->u.els_plogi.els_plogi_pyld, 0x70);
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS) {
+ 		rval = QLA_FUNCTION_FAILED;
+ 		goto out;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_io, vha, 0x3074,
+ 	    "%s PLOGI sent, hdl=%x, loopid=%x, portid=%06x\n",
+ 	    sp->name, sp->handle, fcport->loop_id, fcport->d_id.b24);
+ 
+ 	wait_for_completion(&elsio->u.els_plogi.comp);
+ 
+ 	if (elsio->u.els_plogi.comp_status != CS_COMPLETE)
+ 		rval = QLA_FUNCTION_FAILED;
+ 
+ out:
+ 	sp->free(sp);
+ 	return rval;
+ }
+ 
+ static void
++>>>>>>> e74e7d95878d (scsi: qla2xxx: Fix race condition between iocb timeout and initialisation)
  qla24xx_els_iocb(srb_t *sp, struct els_entry_24xx *els_iocb)
  {
 -	struct bsg_job *bsg_job = sp->u.bsg_job;
 -	struct fc_bsg_request *bsg_request = bsg_job->request;
 +	struct fc_bsg_job *bsg_job = sp->u.bsg_job;
  
          els_iocb->entry_type = ELS_IOCB_TYPE;
          els_iocb->entry_count = 1;
diff --cc drivers/scsi/qla2xxx/qla_mid.c
index a7dee9b177bf,f6f0a759a7c2..000000000000
--- a/drivers/scsi/qla2xxx/qla_mid.c
+++ b/drivers/scsi/qla2xxx/qla_mid.c
@@@ -894,3 -892,79 +894,82 @@@ que_failed
  failed:
  	return 0;
  }
++<<<<<<< HEAD
++=======
+ 
+ static void qla_ctrlvp_sp_done(void *s, int res)
+ {
+ 	struct srb *sp = s;
+ 
+ 	complete(&sp->comp);
+ 	/* don't free sp here. Let the caller do the free */
+ }
+ 
+ /**
+  * qla24xx_control_vp() - Enable a virtual port for given host
+  * @vha:	adapter block pointer
+  * @cmd:	command type to be sent for enable virtual port
+  *
+  * Return:	qla2xxx local function return status code.
+  */
+ int qla24xx_control_vp(scsi_qla_host_t *vha, int cmd)
+ {
+ 	int rval = QLA_MEMORY_ALLOC_FAILED;
+ 	struct qla_hw_data *ha = vha->hw;
+ 	int	vp_index = vha->vp_idx;
+ 	struct scsi_qla_host *base_vha = pci_get_drvdata(ha->pdev);
+ 	srb_t *sp;
+ 
+ 	ql_dbg(ql_dbg_vport, vha, 0x10c1,
+ 	    "Entered %s cmd %x index %d.\n", __func__, cmd, vp_index);
+ 
+ 	if (vp_index == 0 || vp_index >= ha->max_npiv_vports)
+ 		return QLA_PARAMETER_ERROR;
+ 
+ 	sp = qla2x00_get_sp(base_vha, NULL, GFP_KERNEL);
+ 	if (!sp)
+ 		goto done;
+ 
+ 	sp->type = SRB_CTRL_VP;
+ 	sp->name = "ctrl_vp";
+ 	sp->done = qla_ctrlvp_sp_done;
+ 	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
+ 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+ 	sp->u.iocb_cmd.u.ctrlvp.cmd = cmd;
+ 	sp->u.iocb_cmd.u.ctrlvp.vp_index = vp_index;
+ 
+ 	rval = qla2x00_start_sp(sp);
+ 	if (rval != QLA_SUCCESS) {
+ 		ql_dbg(ql_dbg_async, vha, 0xffff,
+ 		    "%s: %s Failed submission. %x.\n",
+ 		    __func__, sp->name, rval);
+ 		goto done_free_sp;
+ 	}
+ 
+ 	ql_dbg(ql_dbg_vport, vha, 0x113f, "%s hndl %x submitted\n",
+ 	    sp->name, sp->handle);
+ 
+ 	wait_for_completion(&sp->comp);
+ 	rval = sp->rc;
+ 	switch (rval) {
+ 	case QLA_FUNCTION_TIMEOUT:
+ 		ql_dbg(ql_dbg_vport, vha, 0xffff, "%s: %s Timeout. %x.\n",
+ 		    __func__, sp->name, rval);
+ 		break;
+ 	case QLA_SUCCESS:
+ 		ql_dbg(ql_dbg_vport, vha, 0xffff, "%s: %s done.\n",
+ 		    __func__, sp->name);
+ 		goto done_free_sp;
+ 	default:
+ 		ql_dbg(ql_dbg_vport, vha, 0xffff, "%s: %s Failed. %x.\n",
+ 		    __func__, sp->name, rval);
+ 		goto done_free_sp;
+ 	}
+ done:
+ 	return rval;
+ 
+ done_free_sp:
+ 	sp->free(sp);
+ 	return rval;
+ }
++>>>>>>> e74e7d95878d (scsi: qla2xxx: Fix race condition between iocb timeout and initialisation)
* Unmerged path drivers/scsi/qla2xxx/qla_gs.c
* Unmerged path drivers/scsi/qla2xxx/qla_init.c
* Unmerged path drivers/scsi/qla2xxx/qla_inline.h
* Unmerged path drivers/scsi/qla2xxx/qla_iocb.c
diff --git a/drivers/scsi/qla2xxx/qla_mbx.c b/drivers/scsi/qla2xxx/qla_mbx.c
index 5997303a0944..2099c62f5829 100644
--- a/drivers/scsi/qla2xxx/qla_mbx.c
+++ b/drivers/scsi/qla2xxx/qla_mbx.c
@@ -5884,14 +5884,14 @@ int qla24xx_send_mb_cmd(struct scsi_qla_host *vha, mbx_cmd_t *mcp)
 	sp->type = SRB_MB_IOCB;
 	sp->name = mb_to_str(mcp->mb[0]);
 
-	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
-
-	memcpy(sp->u.iocb_cmd.u.mbx.out_mb, mcp->mb, SIZEOF_IOCB_MB_REG);
-
 	c = &sp->u.iocb_cmd;
 	c->timeout = qla2x00_async_iocb_timeout;
 	init_completion(&c->u.mbx.comp);
 
+	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha) + 2);
+
+	memcpy(sp->u.iocb_cmd.u.mbx.out_mb, mcp->mb, SIZEOF_IOCB_MB_REG);
+
 	sp->done = qla2x00_async_mb_sp_done;
 
 	rval = qla2x00_start_sp(sp);
* Unmerged path drivers/scsi/qla2xxx/qla_mid.c
diff --git a/drivers/scsi/qla2xxx/qla_mr.c b/drivers/scsi/qla2xxx/qla_mr.c
index e970f71fc1c1..62c2bd68a475 100644
--- a/drivers/scsi/qla2xxx/qla_mr.c
+++ b/drivers/scsi/qla2xxx/qla_mr.c
@@ -1820,9 +1820,11 @@ qlafx00_fx_disc(scsi_qla_host_t *vha, fc_port_t *fcport, uint16_t fx_type)
 
 	sp->type = SRB_FXIOCB_DCMD;
 	sp->name = "fxdisc";
-	qla2x00_init_timer(sp, FXDISC_TIMEOUT);
 
 	fdisc = &sp->u.iocb_cmd;
+	fdisc->timeout = qla2x00_fxdisc_iocb_timeout;
+	qla2x00_init_timer(sp, FXDISC_TIMEOUT);
+
 	switch (fx_type) {
 	case FXDISC_GET_CONFIG_INFO:
 	fdisc->u.fxiocb.flags =
@@ -1924,7 +1926,6 @@ qlafx00_fx_disc(scsi_qla_host_t *vha, fc_port_t *fcport, uint16_t fx_type)
 			goto done_unmap_req;
 	}
 
-	fdisc->timeout = qla2x00_fxdisc_iocb_timeout;
 	fdisc->u.fxiocb.req_func_type = cpu_to_le16(fx_type);
 	sp->done = qla2x00_fxdisc_sp_done;
 
diff --git a/drivers/scsi/qla2xxx/qla_target.c b/drivers/scsi/qla2xxx/qla_target.c
index 753c5e0953f9..072c80561068 100644
--- a/drivers/scsi/qla2xxx/qla_target.c
+++ b/drivers/scsi/qla2xxx/qla_target.c
@@ -657,10 +657,10 @@ int qla24xx_async_notify_ack(scsi_qla_host_t *vha, fc_port_t *fcport,
 	sp->type = type;
 	sp->name = "nack";
 
+	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
 	qla2x00_init_timer(sp, qla2x00_get_async_timeout(vha)+2);
 
 	sp->u.iocb_cmd.u.nack.ntfy = ntfy;
-	sp->u.iocb_cmd.timeout = qla2x00_async_iocb_timeout;
 	sp->done = qla2x00_async_nack_sp_done;
 
 	rval = qla2x00_start_sp(sp);
