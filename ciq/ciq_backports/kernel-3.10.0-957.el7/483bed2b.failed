bpf: fix htab map destruction when extra reserve is in use

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-957.el7
commit-author Daniel Borkmann <daniel@iogearbox.net>
commit 483bed2b0ddd12ec33fc9407e0c6e1088e77a97c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-957.el7/483bed2b.failed

Commit a6ed3ea65d98 ("bpf: restore behavior of bpf_map_update_elem")
added an extra per-cpu reserve to the hash table map to restore old
behaviour from pre prealloc times. When non-prealloc is in use for a
map, then problem is that once a hash table extra element has been
linked into the hash-table, and the hash table is destroyed due to
refcount dropping to zero, then htab_map_free() -> delete_all_elements()
will walk the whole hash table and drop all elements via htab_elem_free().
The problem is that the element from the extra reserve is first fed
to the wrong backend allocator and eventually freed twice.

Fixes: a6ed3ea65d98 ("bpf: restore behavior of bpf_map_update_elem")
	Reported-by: Dmitry Vyukov <dvyukov@google.com>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Acked-by: Alexei Starovoitov <ast@kernel.org>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 483bed2b0ddd12ec33fc9407e0c6e1088e77a97c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/hashtab.c
* Unmerged path kernel/bpf/hashtab.c
* Unmerged path kernel/bpf/hashtab.c
