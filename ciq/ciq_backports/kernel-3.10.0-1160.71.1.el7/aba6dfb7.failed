mm/mmap.c: rb_parent is not necessary in __vma_link_list()

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1160.71.1.el7
commit-author Wei Yang <richardw.yang@linux.intel.com>
commit aba6dfb75fe15650991442efd137c32fbf2e2b85
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.71.1.el7/aba6dfb7.failed

Now we use rb_parent to get next, while this is not necessary.

When prev is NULL, this means vma should be the first element in the list.
Then next should be current first one (mm->mmap), no matter whether we
have parent or not.

After removing it, the code shows the beauty of symmetry.

Link: http://lkml.kernel.org/r/20190813032656.16625-1-richardw.yang@linux.intel.com
	Signed-off-by: Wei Yang <richardw.yang@linux.intel.com>
	Acked-by: Andrew Morton <akpm@linux-foundation.org>
	Cc: Mel Gorman <mgorman@techsingularity.net>
	Cc: Vlastimil Babka <vbabka@suse.cz>
	Cc: Matthew Wilcox <willy@infradead.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit aba6dfb75fe15650991442efd137c32fbf2e2b85)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/internal.h
diff --cc mm/internal.h
index 6b35e457f4d8,a246c516ade2..000000000000
--- a/mm/internal.h
+++ b/mm/internal.h
@@@ -169,9 -257,41 +169,14 @@@ static inline bool is_cow_mapping(vm_fl
  	return (flags & (VM_SHARED | VM_MAYWRITE)) == VM_MAYWRITE;
  }
  
 -/*
 - * These three helpers classifies VMAs for virtual memory accounting.
 - */
 -
 -/*
 - * Executable code area - executable, not writable, not stack
 - */
 -static inline bool is_exec_mapping(vm_flags_t flags)
 -{
 -	return (flags & (VM_EXEC | VM_WRITE | VM_STACK)) == VM_EXEC;
 -}
 -
 -/*
 - * Stack area - atomatically grows in one direction
 - *
 - * VM_GROWSUP / VM_GROWSDOWN VMAs are always private anonymous:
 - * do_mmap() forbids all other combinations.
 - */
 -static inline bool is_stack_mapping(vm_flags_t flags)
 -{
 -	return (flags & VM_STACK) == VM_STACK;
 -}
 -
 -/*
 - * Data area - private, writable, not stack
 - */
 -static inline bool is_data_mapping(vm_flags_t flags)
 -{
 -	return (flags & (VM_WRITE | VM_SHARED | VM_STACK)) == VM_WRITE;
 -}
 -
  /* mm/util.c */
  void __vma_link_list(struct mm_struct *mm, struct vm_area_struct *vma,
++<<<<<<< HEAD
 +		struct vm_area_struct *prev, struct rb_node *rb_parent);
++=======
+ 		struct vm_area_struct *prev);
+ void __vma_unlink_list(struct mm_struct *mm, struct vm_area_struct *vma);
++>>>>>>> aba6dfb75fe1 (mm/mmap.c: rb_parent is not necessary in __vma_link_list())
  
  #ifdef CONFIG_MMU
  extern long populate_vma_page_range(struct vm_area_struct *vma,
* Unmerged path mm/internal.h
diff --git a/mm/mmap.c b/mm/mmap.c
index 86f8b49aab29..5b9424fc5d35 100644
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -702,7 +702,7 @@ __vma_link(struct mm_struct *mm, struct vm_area_struct *vma,
 	struct vm_area_struct *prev, struct rb_node **rb_link,
 	struct rb_node *rb_parent)
 {
-	__vma_link_list(mm, vma, prev, rb_parent);
+	__vma_link_list(mm, vma, prev);
 	__vma_link_rb(mm, vma, rb_link, rb_parent);
 }
 
diff --git a/mm/nommu.c b/mm/nommu.c
index fadb2e373a06..6e3f38ad7ed8 100644
--- a/mm/nommu.c
+++ b/mm/nommu.c
@@ -795,7 +795,7 @@ static void add_vma_to_mm(struct mm_struct *mm, struct vm_area_struct *vma)
 	if (rb_prev)
 		prev = rb_entry(rb_prev, struct vm_area_struct, vm_rb);
 
-	__vma_link_list(mm, vma, prev, parent);
+	__vma_link_list(mm, vma, prev);
 }
 
 /*
diff --git a/mm/util.c b/mm/util.c
index 92fd5ebfb3cc..13a19ccbce1a 100644
--- a/mm/util.c
+++ b/mm/util.c
@@ -329,7 +329,7 @@ void *memdup_user_nul(const void __user *src, size_t len)
 EXPORT_SYMBOL(memdup_user_nul);
 
 void __vma_link_list(struct mm_struct *mm, struct vm_area_struct *vma,
-		struct vm_area_struct *prev, struct rb_node *rb_parent)
+		struct vm_area_struct *prev)
 {
 	struct vm_area_struct *next;
 
@@ -338,12 +338,8 @@ void __vma_link_list(struct mm_struct *mm, struct vm_area_struct *vma,
 		next = prev->vm_next;
 		prev->vm_next = vma;
 	} else {
+		next = mm->mmap;
 		mm->mmap = vma;
-		if (rb_parent)
-			next = rb_entry(rb_parent,
-					struct vm_area_struct, vm_rb);
-		else
-			next = NULL;
 	}
 	vma->vm_next = next;
 	if (next)
