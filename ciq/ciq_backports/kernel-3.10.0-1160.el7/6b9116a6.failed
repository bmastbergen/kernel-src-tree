mm, dax: check for pmd_none() after split_huge_pmd()

jira LE-1907
cve CVE-2020-10757
Rebuild_History Non-Buildable kernel-3.10.0-1160.el7
commit-author Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
commit 6b9116a652bd9e0e2994505cfaaa5f66deaa2a05
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.el7/6b9116a6.failed

DAX implements split_huge_pmd() by clearing pmd.  This simple approach
reduces memory overhead, as we don't need to deposit page table on huge
page mapping to make split_huge_pmd() never-fail.  PTE table can be
allocated and populated later on page fault from backing store.

But one side effect is that have to check if pmd is pmd_none() after
split_huge_pmd().  In most places we do this already to deal with
parallel MADV_DONTNEED.

But I found two call sites which is not affected by MADV_DONTNEED (due
down_write(mmap_sem)), but need to have the check to work with DAX
properly.

	Signed-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>
	Cc: Dan Williams <dan.j.williams@intel.com>
	Cc: Matthew Wilcox <willy@linux.intel.com>
	Cc: Andrea Arcangeli <aarcange@redhat.com>
	Cc: Ross Zwisler <ross.zwisler@linux.intel.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 6b9116a652bd9e0e2994505cfaaa5f66deaa2a05)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/mprotect.c
#	mm/mremap.c
diff --cc mm/mprotect.c
index f572ea0ac0b4,f7cb3d4d9c2e..000000000000
--- a/mm/mprotect.c
+++ b/mm/mprotect.c
@@@ -159,9 -160,11 +159,17 @@@ static inline unsigned long change_pmd_
  		}
  
  		if (pmd_trans_huge(*pmd) || pmd_devmap(*pmd)) {
++<<<<<<< HEAD
 +			if (next - addr != HPAGE_PMD_SIZE)
 +				split_huge_page_pmd(vma, addr, pmd);
 +			else {
++=======
+ 			if (next - addr != HPAGE_PMD_SIZE) {
+ 				split_huge_pmd(vma, pmd, addr);
+ 				if (pmd_none(*pmd))
+ 					continue;
+ 			} else {
++>>>>>>> 6b9116a652bd (mm, dax: check for pmd_none() after split_huge_pmd())
  				int nr_ptes = change_huge_pmd(vma, pmd, addr,
  						newprot, prot_numa);
  
diff --cc mm/mremap.c
index 793a0391c137,8eeba02fc991..000000000000
--- a/mm/mremap.c
+++ b/mm/mremap.c
@@@ -223,12 -204,14 +223,18 @@@ unsigned long move_page_tables(struct v
  						    old_pmd, new_pmd);
  				if (need_rmap_locks)
  					anon_vma_unlock_write(vma->anon_vma);
 -				if (moved) {
 -					need_flush = true;
 -					continue;
 -				}
  			}
++<<<<<<< HEAD
 +			if (err > 0)
 +				continue;
 +			else if (!err) {
 +				split_huge_page_pmd(vma, old_addr, old_pmd);
 +			}
++=======
+ 			split_huge_pmd(vma, old_pmd, old_addr);
+ 			if (pmd_none(*old_pmd))
+ 				continue;
++>>>>>>> 6b9116a652bd (mm, dax: check for pmd_none() after split_huge_pmd())
  			VM_BUG_ON(pmd_trans_huge(*old_pmd));
  		}
  		if (pmd_none(*new_pmd) && __pte_alloc(new_vma->vm_mm, new_vma,
* Unmerged path mm/mprotect.c
* Unmerged path mm/mremap.c
