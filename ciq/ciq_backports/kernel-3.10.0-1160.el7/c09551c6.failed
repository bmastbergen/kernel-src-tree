net: ipv4: use a dedicated counter for icmp_v4 redirect packets

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1160.el7
Rebuild_CHGLOG: - [net] ipv4: use a dedicated counter for icmp_v4 redirect packets (Paolo Abeni) [1832332]
Rebuild_FUZZ: 95.87%
commit-author Lorenzo Bianconi <lorenzo.bianconi@redhat.com>
commit c09551c6ff7fe16a79a42133bcecba5fc2fc3291
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.el7/c09551c6.failed

According to the algorithm described in the comment block at the
beginning of ip_rt_send_redirect, the host should try to send
'ip_rt_redirect_number' ICMP redirect packets with an exponential
backoff and then stop sending them at all assuming that the destination
ignores redirects.
If the device has previously sent some ICMP error packets that are
rate-limited (e.g TTL expired) and continues to receive traffic,
the redirect packets will never be transmitted. This happens since
peer->rate_tokens will be typically greater than 'ip_rt_redirect_number'
and so it will never be reset even if the redirect silence timeout
(ip_rt_redirect_silence) has elapsed without receiving any packet
requiring redirects.

Fix it by using a dedicated counter for the number of ICMP redirect
packets that has been sent by the host

I have not been able to identify a given commit that introduced the
issue since ip_rt_send_redirect implements the same rate-limiting
algorithm from commit 1da177e4c3f4 ("Linux-2.6.12-rc2")

	Signed-off-by: Lorenzo Bianconi <lorenzo.bianconi@redhat.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit c09551c6ff7fe16a79a42133bcecba5fc2fc3291)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/ipv4/inetpeer.c
diff --cc net/ipv4/inetpeer.c
index 67140efc15fd,be778599bfed..000000000000
--- a/net/ipv4/inetpeer.c
+++ b/net/ipv4/inetpeer.c
@@@ -472,36 -202,33 +472,61 @@@ struct inet_peer *inet_getpeer(struct i
  	/* retry an exact lookup, taking the lock before.
  	 * At least, nodes should be hot in our cache.
  	 */
 -	parent = NULL;
  	write_seqlock_bh(&base->lock);
++<<<<<<< HEAD
 +relookup:
 +	p = lookup(daddr, stack, base);
 +	if (p != peer_avl_empty) {
 +		atomic_inc(&p->refcnt);
 +		write_sequnlock_bh(&base->lock);
 +		return p;
 +	}
 +	if (!gccnt) {
 +		gccnt = inet_peer_gc(base, stack, stackptr);
 +		if (gccnt && create)
 +			goto relookup;
 +	}
 +	p = create ? kmem_cache_alloc(peer_cachep, GFP_ATOMIC) : NULL;
 +	if (p) {
 +		p->daddr = *daddr;
 +		atomic_set(&p->refcnt, 1);
 +		atomic_set(&p->rid, 0);
 +		p->metrics[RTAX_LOCK-1] = INETPEER_METRICS_NEW;
 +		p->rate_tokens = 0;
 +		/* 60*HZ is arbitrary, but chosen enough high so that the first
 +		 * calculation of tokens is at its maximum.
 +		 */
 +		p->rate_last = jiffies - 60*HZ;
 +		INIT_LIST_HEAD(&p->gc_list);
 +
 +		/* Link the node. */
 +		link_to_pool(p, base);
 +		base->total++;
++=======
+ 
+ 	gc_cnt = 0;
+ 	p = lookup(daddr, base, seq, gc_stack, &gc_cnt, &parent, &pp);
+ 	if (!p && create) {
+ 		p = kmem_cache_alloc(peer_cachep, GFP_ATOMIC);
+ 		if (p) {
+ 			p->daddr = *daddr;
+ 			p->dtime = (__u32)jiffies;
+ 			refcount_set(&p->refcnt, 2);
+ 			atomic_set(&p->rid, 0);
+ 			p->metrics[RTAX_LOCK-1] = INETPEER_METRICS_NEW;
+ 			p->rate_tokens = 0;
+ 			p->n_redirects = 0;
+ 			/* 60*HZ is arbitrary, but chosen enough high so that the first
+ 			 * calculation of tokens is at its maximum.
+ 			 */
+ 			p->rate_last = jiffies - 60*HZ;
+ 
+ 			rb_link_node(&p->rb_node, parent, pp);
+ 			rb_insert_color(&p->rb_node, &base->rb_root);
+ 			base->total++;
+ 		}
++>>>>>>> c09551c6ff7f (net: ipv4: use a dedicated counter for icmp_v4 redirect packets)
  	}
 -	if (gc_cnt)
 -		inet_peer_gc(base, gc_stack, gc_cnt);
  	write_sequnlock_bh(&base->lock);
  
  	return p;
diff --git a/include/net/inetpeer.h b/include/net/inetpeer.h
index 1a356cfed24f..a52a7ed64b34 100644
--- a/include/net/inetpeer.h
+++ b/include/net/inetpeer.h
@@ -37,6 +37,7 @@ struct inet_peer {
 
 	u32			metrics[RTAX_MAX];
 	u32			rate_tokens;	/* rate limiting for ICMP */
+	u32			n_redirects;
 	unsigned long		rate_last;
 	union {
 		struct list_head	gc_list;
* Unmerged path net/ipv4/inetpeer.c
diff --git a/net/ipv4/route.c b/net/ipv4/route.c
index 9cf3c3fd762f..9e639c33c0c1 100644
--- a/net/ipv4/route.c
+++ b/net/ipv4/route.c
@@ -900,13 +900,15 @@ void ip_rt_send_redirect(struct sk_buff *skb)
 	/* No redirected packets during ip_rt_redirect_silence;
 	 * reset the algorithm.
 	 */
-	if (time_after(jiffies, peer->rate_last + ip_rt_redirect_silence))
+	if (time_after(jiffies, peer->rate_last + ip_rt_redirect_silence)) {
 		peer->rate_tokens = 0;
+		peer->n_redirects = 0;
+	}
 
 	/* Too many ignored redirects; do not send anything
 	 * set dst.rate_last to the last seen redirected packet.
 	 */
-	if (peer->rate_tokens >= ip_rt_redirect_number) {
+	if (peer->n_redirects >= ip_rt_redirect_number) {
 		peer->rate_last = jiffies;
 		goto out_put_peer;
 	}
@@ -923,6 +925,7 @@ void ip_rt_send_redirect(struct sk_buff *skb)
 		icmp_send(skb, ICMP_REDIRECT, ICMP_REDIR_HOST, gw);
 		peer->rate_last = jiffies;
 		++peer->rate_tokens;
+		++peer->n_redirects;
 #ifdef CONFIG_IP_ROUTE_VERBOSE
 		if (log_martians &&
 		    peer->rate_tokens == ip_rt_redirect_number)
