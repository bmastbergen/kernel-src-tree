x86/speculation: Add Special Register Buffer Data Sampling (SRBDS) mitigation

jira LE-1907
cve CVE-2020-0543
Rebuild_History Non-Buildable kernel-3.10.0-1160.el7
commit-author Mark Gross <mgross@linux.intel.com>
commit 7e5b3c267d256822407a22fdce6afdf9cd13f9fb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.el7/7e5b3c26.failed

SRBDS is an MDS-like speculative side channel that can leak bits from the
random number generator (RNG) across cores and threads. New microcode
serializes the processor access during the execution of RDRAND and
RDSEED. This ensures that the shared buffer is overwritten before it is
released for reuse.

While it is present on all affected CPU models, the microcode mitigation
is not needed on models that enumerate ARCH_CAPABILITIES[MDS_NO] in the
cases where TSX is not supported or has been disabled with TSX_CTRL.

The mitigation is activated by default on affected processors and it
increases latency for RDRAND and RDSEED instructions. Among other
effects this will reduce throughput from /dev/urandom.

* Enable administrator to configure the mitigation off when desired using
  either mitigations=off or srbds=off.

* Export vulnerability status via sysfs

* Rename file-scoped macros to apply for non-whitelist table initializations.

 [ bp: Massage,
   - s/VULNBL_INTEL_STEPPING/VULNBL_INTEL_STEPPINGS/g,
   - do not read arch cap MSR a second time in tsx_fused_off() - just pass it in,
   - flip check in cpu_set_bug_bits() to save an indentation level,
   - reflow comments.
   jpoimboe: s/Mitigated/Mitigation/ in user-visible strings
   tglx: Dropped the fused off magic for now
 ]

	Signed-off-by: Mark Gross <mgross@linux.intel.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Reviewed-by: Tony Luck <tony.luck@intel.com>
	Reviewed-by: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
	Reviewed-by: Josh Poimboeuf <jpoimboe@redhat.com>
	Tested-by: Neelima Krishnan <neelima.krishnan@intel.com>
(cherry picked from commit 7e5b3c267d256822407a22fdce6afdf9cd13f9fb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/kernel-parameters.txt
#	arch/x86/include/asm/cpufeatures.h
#	arch/x86/kernel/cpu/bugs.c
#	arch/x86/kernel/cpu/common.c
#	arch/x86/kernel/cpu/cpu.h
#	drivers/base/cpu.c
diff --cc Documentation/kernel-parameters.txt
index 25318ee68938,f720463bd918..000000000000
--- a/Documentation/kernel-parameters.txt
+++ b/Documentation/kernel-parameters.txt
@@@ -3495,6 -4735,82 +3495,85 @@@ bytes respectively. Such letter suffixe
  	spia_pedr=
  	spia_peddr=
  
++<<<<<<< HEAD:Documentation/kernel-parameters.txt
++=======
+ 	split_lock_detect=
+ 			[X86] Enable split lock detection
+ 
+ 			When enabled (and if hardware support is present), atomic
+ 			instructions that access data across cache line
+ 			boundaries will result in an alignment check exception.
+ 
+ 			off	- not enabled
+ 
+ 			warn	- the kernel will emit rate limited warnings
+ 				  about applications triggering the #AC
+ 				  exception. This mode is the default on CPUs
+ 				  that supports split lock detection.
+ 
+ 			fatal	- the kernel will send SIGBUS to applications
+ 				  that trigger the #AC exception.
+ 
+ 			If an #AC exception is hit in the kernel or in
+ 			firmware (i.e. not while executing in user mode)
+ 			the kernel will oops in either "warn" or "fatal"
+ 			mode.
+ 
+ 	srbds=		[X86,INTEL]
+ 			Control the Special Register Buffer Data Sampling
+ 			(SRBDS) mitigation.
+ 
+ 			Certain CPUs are vulnerable to an MDS-like
+ 			exploit which can leak bits from the random
+ 			number generator.
+ 
+ 			By default, this issue is mitigated by
+ 			microcode.  However, the microcode fix can cause
+ 			the RDRAND and RDSEED instructions to become
+ 			much slower.  Among other effects, this will
+ 			result in reduced throughput from /dev/urandom.
+ 
+ 			The microcode mitigation can be disabled with
+ 			the following option:
+ 
+ 			off:    Disable mitigation and remove
+ 				performance impact to RDRAND and RDSEED
+ 
+ 	srcutree.counter_wrap_check [KNL]
+ 			Specifies how frequently to check for
+ 			grace-period sequence counter wrap for the
+ 			srcu_data structure's ->srcu_gp_seq_needed field.
+ 			The greater the number of bits set in this kernel
+ 			parameter, the less frequently counter wrap will
+ 			be checked for.  Note that the bottom two bits
+ 			are ignored.
+ 
+ 	srcutree.exp_holdoff [KNL]
+ 			Specifies how many nanoseconds must elapse
+ 			since the end of the last SRCU grace period for
+ 			a given srcu_struct until the next normal SRCU
+ 			grace period will be considered for automatic
+ 			expediting.  Set to zero to disable automatic
+ 			expediting.
+ 
+ 	ssbd=		[ARM64,HW]
+ 			Speculative Store Bypass Disable control
+ 
+ 			On CPUs that are vulnerable to the Speculative
+ 			Store Bypass vulnerability and offer a
+ 			firmware based mitigation, this parameter
+ 			indicates how the mitigation should be used:
+ 
+ 			force-on:  Unconditionally enable mitigation for
+ 				   for both kernel and userspace
+ 			force-off: Unconditionally disable mitigation for
+ 				   for both kernel and userspace
+ 			kernel:    Always enable mitigation in the
+ 				   kernel, and offer a prctl interface
+ 				   to allow userspace to register its
+ 				   interest in being mitigated too.
+ 
++>>>>>>> 7e5b3c267d25 (x86/speculation: Add Special Register Buffer Data Sampling (SRBDS) mitigation):Documentation/admin-guide/kernel-parameters.txt
  	stack_guard_gap=	[MM]
  			override the default stack gap protection. The value
  			is in page units and it defines how many pages prior
diff --cc arch/x86/include/asm/cpufeatures.h
index 234458e2ef34,02dabc9e77b0..000000000000
--- a/arch/x86/include/asm/cpufeatures.h
+++ b/arch/x86/include/asm/cpufeatures.h
@@@ -334,6 -355,14 +334,12 @@@
  /* Intel-defined CPU features, CPUID level 0x00000007:0 (EDX), word 18 */
  #define X86_FEATURE_AVX512_4VNNIW	(18*32+ 2) /* AVX-512 Neural Network Instructions */
  #define X86_FEATURE_AVX512_4FMAPS	(18*32+ 3) /* AVX-512 Multiply Accumulation Single precision */
++<<<<<<< HEAD
++=======
+ #define X86_FEATURE_FSRM		(18*32+ 4) /* Fast Short Rep Mov */
+ #define X86_FEATURE_AVX512_VP2INTERSECT (18*32+ 8) /* AVX-512 Intersect for D/Q */
+ #define X86_FEATURE_SRBDS_CTRL		(18*32+ 9) /* "" SRBDS mitigation MSR available */
++>>>>>>> 7e5b3c267d25 (x86/speculation: Add Special Register Buffer Data Sampling (SRBDS) mitigation)
  #define X86_FEATURE_MD_CLEAR		(18*32+10) /* VERW clears CPU buffers */
  #define X86_FEATURE_TSX_FORCE_ABORT	(18*32+13) /* "" TSX_FORCE_ABORT */
  #define X86_FEATURE_PCONFIG		(18*32+18) /* Intel PCONFIG */
diff --cc arch/x86/kernel/cpu/bugs.c
index 4f81e6de3d45,56978cb06149..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -33,20 -36,43 +33,24 @@@
  
  static void __init spectre_v1_select_mitigation(void);
  static void __init spectre_v2_select_mitigation(void);
 -static void __init ssb_select_mitigation(void);
 +static void __init ssb_parse_cmdline(void);
 +void ssb_select_mitigation(void);
  static void __init l1tf_select_mitigation(void);
  static void __init mds_select_mitigation(void);
 -static void __init mds_print_mitigation(void);
  static void __init taa_select_mitigation(void);
++<<<<<<< HEAD
 +extern void spec_ctrl_save_msr(void);
++=======
+ static void __init srbds_select_mitigation(void);
++>>>>>>> 7e5b3c267d25 (x86/speculation: Add Special Register Buffer Data Sampling (SRBDS) mitigation)
  
 -/* The base value of the SPEC_CTRL MSR that always has to be preserved. */
 -u64 x86_spec_ctrl_base;
 -EXPORT_SYMBOL_GPL(x86_spec_ctrl_base);
  static DEFINE_MUTEX(spec_ctrl_mutex);
  
 -/*
 - * The vendor and possibly platform specific bits which can be modified in
 - * x86_spec_ctrl_base.
 - */
 -static u64 __ro_after_init x86_spec_ctrl_mask = SPEC_CTRL_IBRS;
 -
 -/*
 - * AMD specific MSR info for Speculative Store Bypass control.
 - * x86_amd_ls_cfg_ssbd_mask is initialized in identify_boot_cpu().
 - */
 -u64 __ro_after_init x86_amd_ls_cfg_base;
 -u64 __ro_after_init x86_amd_ls_cfg_ssbd_mask;
 -
 -/* Control conditional STIBP in switch_to() */
 -DEFINE_STATIC_KEY_FALSE(switch_to_cond_stibp);
 -/* Control conditional IBPB in switch_mm() */
 -DEFINE_STATIC_KEY_FALSE(switch_mm_cond_ibpb);
 -/* Control unconditional IBPB in switch_mm() */
 -DEFINE_STATIC_KEY_FALSE(switch_mm_always_ibpb);
 -
  /* Control MDS CPU buffer clear before returning to user space */
 -DEFINE_STATIC_KEY_FALSE(mds_user_clear);
 +struct static_key mds_user_clear = STATIC_KEY_INIT_FALSE;
  EXPORT_SYMBOL_GPL(mds_user_clear);
  /* Control MDS CPU buffer clear before idling (halt, mwait) */
 -DEFINE_STATIC_KEY_FALSE(mds_idle_clear);
 +struct static_key mds_idle_clear = STATIC_KEY_INIT_FALSE;
  EXPORT_SYMBOL_GPL(mds_idle_clear);
  
  void __init check_bugs(void)
@@@ -1123,14 -1611,23 +1219,19 @@@ static char *stibp_state(void
  
  static char *ibpb_state(void)
  {
 -	if (boot_cpu_has(X86_FEATURE_IBPB)) {
 -		if (static_key_enabled(&switch_mm_always_ibpb))
 -			return ", IBPB: always-on";
 -		if (static_key_enabled(&switch_mm_cond_ibpb))
 -			return ", IBPB: conditional";
 -		return ", IBPB: disabled";
 -	}
 -	return "";
 +	if (boot_cpu_has(X86_FEATURE_USE_IBPB))
 +		return ", IBPB";
 +	else
 +		return "";
  }
  
+ static ssize_t srbds_show_state(char *buf)
+ {
+ 	return sprintf(buf, "%s\n", srbds_strings[srbds_mitigation]);
+ }
+ 
  static ssize_t cpu_show_common(struct device *dev, struct device_attribute *attr,
 -			       char *buf, unsigned int bug)
 +			char *buf, unsigned int bug)
  {
  	if (!boot_cpu_has_bug(bug))
  		return sprintf(buf, "Not affected\n");
diff --cc arch/x86/kernel/cpu/common.c
index 984a878f5552,8293ee514975..000000000000
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@@ -965,9 -1070,35 +965,34 @@@ static const __initconst struct x86_cpu
  	{}
  };
  
++<<<<<<< HEAD
 +static bool __init cpu_matches(unsigned long which)
++=======
+ #define VULNBL_INTEL_STEPPINGS(model, steppings, issues)		   \
+ 	X86_MATCH_VENDOR_FAM_MODEL_STEPPINGS_FEATURE(INTEL, 6,		   \
+ 					    INTEL_FAM6_##model, steppings, \
+ 					    X86_FEATURE_ANY, issues)
+ 
+ #define SRBDS		BIT(0)
+ 
+ static const struct x86_cpu_id cpu_vuln_blacklist[] __initconst = {
+ 	VULNBL_INTEL_STEPPINGS(IVYBRIDGE,	X86_STEPPING_ANY,		SRBDS),
+ 	VULNBL_INTEL_STEPPINGS(HASWELL,		X86_STEPPING_ANY,		SRBDS),
+ 	VULNBL_INTEL_STEPPINGS(HASWELL_L,	X86_STEPPING_ANY,		SRBDS),
+ 	VULNBL_INTEL_STEPPINGS(HASWELL_G,	X86_STEPPING_ANY,		SRBDS),
+ 	VULNBL_INTEL_STEPPINGS(BROADWELL_G,	X86_STEPPING_ANY,		SRBDS),
+ 	VULNBL_INTEL_STEPPINGS(BROADWELL,	X86_STEPPING_ANY,		SRBDS),
+ 	VULNBL_INTEL_STEPPINGS(SKYLAKE_L,	X86_STEPPING_ANY,		SRBDS),
+ 	VULNBL_INTEL_STEPPINGS(SKYLAKE,		X86_STEPPING_ANY,		SRBDS),
+ 	VULNBL_INTEL_STEPPINGS(KABYLAKE_L,	X86_STEPPINGS(0x0, 0xC),	SRBDS),
+ 	VULNBL_INTEL_STEPPINGS(KABYLAKE,	X86_STEPPINGS(0x0, 0xD),	SRBDS),
+ 	{}
+ };
+ 
+ static bool __init cpu_matches(const struct x86_cpu_id *table, unsigned long which)
++>>>>>>> 7e5b3c267d25 (x86/speculation: Add Special Register Buffer Data Sampling (SRBDS) mitigation)
  {
 -	const struct x86_cpu_id *m = x86_match_cpu(table);
 +	const struct x86_cpu_id *m = x86_match_cpu(cpu_vuln_whitelist);
  
  	return m && !!(m->driver_data & which);
  }
@@@ -1027,7 -1163,16 +1052,20 @@@ static void __init cpu_set_bug_bits(str
  	     (ia32_cap & ARCH_CAP_TSX_CTRL_MSR)))
  		setup_force_cpu_bug(X86_BUG_TAA);
  
++<<<<<<< HEAD
 +	if (cpu_matches(NO_MELTDOWN))
++=======
+ 	/*
+ 	 * SRBDS affects CPUs which support RDRAND or RDSEED and are listed
+ 	 * in the vulnerability blacklist.
+ 	 */
+ 	if ((cpu_has(c, X86_FEATURE_RDRAND) ||
+ 	     cpu_has(c, X86_FEATURE_RDSEED)) &&
+ 	    cpu_matches(cpu_vuln_blacklist, SRBDS))
+ 		    setup_force_cpu_bug(X86_BUG_SRBDS);
+ 
+ 	if (cpu_matches(cpu_vuln_whitelist, NO_MELTDOWN))
++>>>>>>> 7e5b3c267d25 (x86/speculation: Add Special Register Buffer Data Sampling (SRBDS) mitigation)
  		return;
  
  	/* Rogue Data Cache Load? No! */
@@@ -1395,53 -1623,10 +1433,58 @@@ void identify_secondary_cpu(struct cpui
  #endif
  	mtrr_ap_init();
  	validate_apic_and_package_id(c);
++<<<<<<< HEAD
++=======
+ 	x86_spec_ctrl_setup_ap();
+ 	update_srbds_msr();
++>>>>>>> 7e5b3c267d25 (x86/speculation: Add Special Register Buffer Data Sampling (SRBDS) mitigation)
  }
  
 +struct msr_range {
 +	unsigned	min;
 +	unsigned	max;
 +};
 +
 +static const struct msr_range msr_range_array[] = {
 +	{ 0x00000000, 0x00000418},
 +	{ 0xc0000000, 0xc000040b},
 +	{ 0xc0010000, 0xc0010142},
 +	{ 0xc0011000, 0xc001103b},
 +};
 +
 +static void __print_cpu_msr(void)
 +{
 +	unsigned index_min, index_max;
 +	unsigned index;
 +	u64 val;
 +	int i;
 +
 +	for (i = 0; i < ARRAY_SIZE(msr_range_array); i++) {
 +		index_min = msr_range_array[i].min;
 +		index_max = msr_range_array[i].max;
 +
 +		for (index = index_min; index < index_max; index++) {
 +			if (rdmsrl_safe(index, &val))
 +				continue;
 +			printk(KERN_INFO " MSR%08x: %016llx\n", index, val);
 +		}
 +	}
 +}
 +
 +static int show_msr;
 +
 +static __init int setup_show_msr(char *arg)
 +{
 +	int num;
 +
 +	get_option(&arg, &num);
 +
 +	if (num > 0)
 +		show_msr = num;
 +	return 1;
 +}
 +__setup("show_msr=", setup_show_msr);
 +
  static __init int setup_noclflush(char *arg)
  {
  	setup_clear_cpu_cap(X86_FEATURE_CLFLUSH);
diff --cc arch/x86/kernel/cpu/cpu.h
index 6440c7f0fd6e,fb538fccd24c..000000000000
--- a/arch/x86/kernel/cpu/cpu.h
+++ b/arch/x86/kernel/cpu/cpu.h
@@@ -58,9 -61,28 +58,18 @@@ static inline void tsx_init(void) { 
  #endif /* CONFIG_CPU_SUP_INTEL */
  
  extern void get_cpu_cap(struct cpuinfo_x86 *c);
 -extern void get_cpu_address_sizes(struct cpuinfo_x86 *c);
  extern void cpu_detect_cache_sizes(struct cpuinfo_x86 *c);
 -extern void init_scattered_cpuid_features(struct cpuinfo_x86 *c);
 -extern void init_intel_cacheinfo(struct cpuinfo_x86 *c);
 -extern void init_amd_cacheinfo(struct cpuinfo_x86 *c);
 -extern void init_hygon_cacheinfo(struct cpuinfo_x86 *c);
 -
 -extern void detect_num_cpu_cores(struct cpuinfo_x86 *c);
  extern int detect_extended_topology_early(struct cpuinfo_x86 *c);
 -extern int detect_extended_topology(struct cpuinfo_x86 *c);
  extern int detect_ht_early(struct cpuinfo_x86 *c);
++<<<<<<< HEAD
++=======
+ extern void detect_ht(struct cpuinfo_x86 *c);
+ 
+ unsigned int aperfmperf_get_khz(int cpu);
+ 
+ extern void x86_spec_ctrl_setup_ap(void);
+ extern void update_srbds_msr(void);
++>>>>>>> 7e5b3c267d25 (x86/speculation: Add Special Register Buffer Data Sampling (SRBDS) mitigation)
  
  extern u64 x86_read_arch_cap_msr(void);
 -
 -#ifdef CONFIG_IA32_FEAT_CTL
 -void init_ia32_feat_ctl(struct cpuinfo_x86 *c);
 -#endif
 -
  #endif /* ARCH_X86_CPU_H */
diff --cc drivers/base/cpu.c
index fc5bf8545e62,d2136ab9b14a..000000000000
--- a/drivers/base/cpu.c
+++ b/drivers/base/cpu.c
@@@ -445,14 -562,21 +445,32 @@@ ssize_t __weak cpu_show_itlb_multihit(s
  	return sprintf(buf, "Not affected\n");
  }
  
++<<<<<<< HEAD
 +static DEVICE_ATTR(meltdown, 0400, cpu_show_meltdown, NULL);
 +static DEVICE_ATTR(spectre_v1, 0400, cpu_show_spectre_v1, NULL);
 +static DEVICE_ATTR(spectre_v2, 0400, cpu_show_spectre_v2, NULL);
 +static DEVICE_ATTR(spec_store_bypass, 0400, cpu_show_spec_store_bypass, NULL);
 +static DEVICE_ATTR(l1tf, 0400, cpu_show_l1tf, NULL);
 +static DEVICE_ATTR(mds, 0400, cpu_show_mds, NULL);
 +static DEVICE_ATTR(tsx_async_abort, 0400, cpu_show_tsx_async_abort, NULL);
 +static DEVICE_ATTR(itlb_multihit, 0400, cpu_show_itlb_multihit, NULL);
++=======
+ ssize_t __weak cpu_show_srbds(struct device *dev,
+ 			      struct device_attribute *attr, char *buf)
+ {
+ 	return sprintf(buf, "Not affected\n");
+ }
+ 
+ static DEVICE_ATTR(meltdown, 0444, cpu_show_meltdown, NULL);
+ static DEVICE_ATTR(spectre_v1, 0444, cpu_show_spectre_v1, NULL);
+ static DEVICE_ATTR(spectre_v2, 0444, cpu_show_spectre_v2, NULL);
+ static DEVICE_ATTR(spec_store_bypass, 0444, cpu_show_spec_store_bypass, NULL);
+ static DEVICE_ATTR(l1tf, 0444, cpu_show_l1tf, NULL);
+ static DEVICE_ATTR(mds, 0444, cpu_show_mds, NULL);
+ static DEVICE_ATTR(tsx_async_abort, 0444, cpu_show_tsx_async_abort, NULL);
+ static DEVICE_ATTR(itlb_multihit, 0444, cpu_show_itlb_multihit, NULL);
+ static DEVICE_ATTR(srbds, 0444, cpu_show_srbds, NULL);
++>>>>>>> 7e5b3c267d25 (x86/speculation: Add Special Register Buffer Data Sampling (SRBDS) mitigation)
  
  static struct attribute *cpu_root_vulnerabilities_attrs[] = {
  	&dev_attr_meltdown.attr,
diff --git a/Documentation/ABI/testing/sysfs-devices-system-cpu b/Documentation/ABI/testing/sysfs-devices-system-cpu
index 5fa8aa01bd74..56e4cffb9db2 100644
--- a/Documentation/ABI/testing/sysfs-devices-system-cpu
+++ b/Documentation/ABI/testing/sysfs-devices-system-cpu
@@ -277,6 +277,7 @@ What:		/sys/devices/system/cpu/vulnerabilities
 		/sys/devices/system/cpu/vulnerabilities/spec_store_bypass
 		/sys/devices/system/cpu/vulnerabilities/l1tf
 		/sys/devices/system/cpu/vulnerabilities/mds
+		/sys/devices/system/cpu/vulnerabilities/srbds
 		/sys/devices/system/cpu/vulnerabilities/tsx_async_abort
 Date:		January 2018
 Contact:	Linux kernel mailing list <linux-kernel@vger.kernel.org>
* Unmerged path Documentation/kernel-parameters.txt
* Unmerged path arch/x86/include/asm/cpufeatures.h
diff --git a/arch/x86/include/asm/msr-index.h b/arch/x86/include/asm/msr-index.h
index b8eaa265bf9a..15590d20bbe2 100644
--- a/arch/x86/include/asm/msr-index.h
+++ b/arch/x86/include/asm/msr-index.h
@@ -106,6 +106,10 @@
 #define TSX_CTRL_RTM_DISABLE		BIT(0)	/* Disable RTM feature */
 #define TSX_CTRL_CPUID_CLEAR		BIT(1)	/* Disable TSX enumeration */
 
+/* SRBDS support */
+#define MSR_IA32_MCU_OPT_CTRL		0x00000123
+#define RNGDS_MITG_DIS			BIT(0)
+
 #define MSR_IA32_SYSENTER_CS		0x00000174
 #define MSR_IA32_SYSENTER_ESP		0x00000175
 #define MSR_IA32_SYSENTER_EIP		0x00000176
* Unmerged path arch/x86/kernel/cpu/bugs.c
* Unmerged path arch/x86/kernel/cpu/common.c
* Unmerged path arch/x86/kernel/cpu/cpu.h
* Unmerged path drivers/base/cpu.c
