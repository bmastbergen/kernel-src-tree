ext4: change LRU to round-robin in extent status tree shrinker

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1160.el7
commit-author Zheng Liu <wenqing.lz@taobao.com>
commit edaa53cac8fd4b96ed4b8f96c4933158ff2dd337
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.el7/edaa53ca.failed

In this commit we discard the lru algorithm for inodes with extent
status tree because it takes significant effort to maintain a lru list
in extent status tree shrinker and the shrinker can take a long time to
scan this lru list in order to reclaim some objects.

We replace the lru ordering with a simple round-robin.  After that we
never need to keep a lru list.  That means that the list needn't be
sorted if the shrinker can not reclaim any objects in the first round.

	Cc: Andreas Dilger <adilger.kernel@dilger.ca>
	Signed-off-by: Zheng Liu <wenqing.lz@taobao.com>
	Signed-off-by: Jan Kara <jack@suse.cz>
	Signed-off-by: Theodore Ts'o <tytso@mit.edu>
(cherry picked from commit edaa53cac8fd4b96ed4b8f96c4933158ff2dd337)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/ext4/ext4.h
#	fs/ext4/extents_status.c
#	fs/ext4/extents_status.h
#	fs/ext4/super.c
#	include/trace/events/ext4.h
diff --cc fs/ext4/ext4.h
index 8897de79c790,ab6caf55f5bf..000000000000
--- a/fs/ext4/ext4.h
+++ b/fs/ext4/ext4.h
@@@ -953,9 -878,9 +953,15 @@@ struct ext4_inode_info 
  	/* extents status tree */
  	struct ext4_es_tree i_es_tree;
  	rwlock_t i_es_lock;
++<<<<<<< HEAD
 +	struct list_head i_es_lru;
 +	unsigned int i_es_lru_nr;	/* protected by i_es_lock */
 +	unsigned long i_touch_when;	/* jiffies of last accessing */
++=======
+ 	struct list_head i_es_list;
+ 	unsigned int i_es_all_nr;	/* protected by i_es_lock */
+ 	unsigned int i_es_shk_nr;	/* protected by i_es_lock */
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  
  	/* ialloc */
  	ext4_group_t	i_last_alloc_group;
@@@ -1393,10 -1321,11 +1399,18 @@@ struct ext4_sb_info 
  
  	/* Reclaim extents from extent status tree */
  	struct shrinker s_es_shrinker;
++<<<<<<< HEAD
 +	struct list_head s_es_lru;
 +	unsigned long s_es_last_sorted;
 +	struct percpu_counter s_extent_cache_cnt;
 +	spinlock_t s_es_lru_lock ____cacheline_aligned_in_smp;
++=======
+ 	struct list_head s_es_list;
+ 	long s_es_nr_inode;
+ 	struct ext4_es_stats s_es_stats;
+ 	struct mb_cache *s_mb_cache;
+ 	spinlock_t s_es_lock ____cacheline_aligned_in_smp;
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  
  	/* Ratelimit ext4 messages. */
  	struct ratelimit_state s_err_ratelimit_state;
diff --cc fs/ext4/extents_status.c
index 3ef7f932e809,0193ca107396..000000000000
--- a/fs/ext4/extents_status.c
+++ b/fs/ext4/extents_status.c
@@@ -312,20 -344,28 +342,38 @@@ ext4_es_alloc_extent(struct inode *inod
  	 * We don't count delayed extent because we never try to reclaim them
  	 */
  	if (!ext4_es_is_delayed(es)) {
++<<<<<<< HEAD
 +		EXT4_I(inode)->i_es_lru_nr++;
 +		percpu_counter_inc(&EXT4_SB(inode->i_sb)->s_extent_cache_cnt);
++=======
+ 		EXT4_I(inode)->i_es_shk_nr++;
+ 		percpu_counter_inc(&EXT4_SB(inode->i_sb)->
+ 					s_es_stats.es_stats_shk_cnt);
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  	}
  
 -	EXT4_I(inode)->i_es_all_nr++;
 -	percpu_counter_inc(&EXT4_SB(inode->i_sb)->s_es_stats.es_stats_all_cnt);
 -
  	return es;
  }
  
  static void ext4_es_free_extent(struct inode *inode, struct extent_status *es)
  {
++<<<<<<< HEAD
 +	/* Decrease the lru counter when this es is not delayed */
 +	if (!ext4_es_is_delayed(es)) {
 +		BUG_ON(EXT4_I(inode)->i_es_lru_nr == 0);
 +		EXT4_I(inode)->i_es_lru_nr--;
 +		percpu_counter_dec(&EXT4_SB(inode->i_sb)->s_extent_cache_cnt);
++=======
+ 	EXT4_I(inode)->i_es_all_nr--;
+ 	percpu_counter_dec(&EXT4_SB(inode->i_sb)->s_es_stats.es_stats_all_cnt);
+ 
+ 	/* Decrease the shrink counter when this es is not delayed */
+ 	if (!ext4_es_is_delayed(es)) {
+ 		BUG_ON(EXT4_I(inode)->i_es_shk_nr == 0);
+ 		EXT4_I(inode)->i_es_shk_nr--;
+ 		percpu_counter_dec(&EXT4_SB(inode->i_sb)->
+ 					s_es_stats.es_stats_shk_cnt);
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  	}
  
  	kmem_cache_free(ext4_es_cachep, es);
@@@ -916,80 -956,66 +969,105 @@@ int ext4_es_remove_extent(struct inode 
  	return err;
  }
  
- static int ext4_inode_touch_time_cmp(void *priv, struct list_head *a,
- 				     struct list_head *b)
- {
- 	struct ext4_inode_info *eia, *eib;
- 	eia = list_entry(a, struct ext4_inode_info, i_es_lru);
- 	eib = list_entry(b, struct ext4_inode_info, i_es_lru);
- 
- 	if (ext4_test_inode_state(&eia->vfs_inode, EXT4_STATE_EXT_PRECACHED) &&
- 	    !ext4_test_inode_state(&eib->vfs_inode, EXT4_STATE_EXT_PRECACHED))
- 		return 1;
- 	if (!ext4_test_inode_state(&eia->vfs_inode, EXT4_STATE_EXT_PRECACHED) &&
- 	    ext4_test_inode_state(&eib->vfs_inode, EXT4_STATE_EXT_PRECACHED))
- 		return -1;
- 	if (eia->i_touch_when == eib->i_touch_when)
- 		return 0;
- 	if (time_after(eia->i_touch_when, eib->i_touch_when))
- 		return 1;
- 	else
- 		return -1;
- }
- 
- static int __ext4_es_shrink(struct ext4_sb_info *sbi, int nr_to_scan,
- 			    struct ext4_inode_info *locked_ei)
+ static int __es_shrink(struct ext4_sb_info *sbi, int nr_to_scan,
+ 		       struct ext4_inode_info *locked_ei)
  {
  	struct ext4_inode_info *ei;
++<<<<<<< HEAD
 +	struct list_head *cur, *tmp;
 +	LIST_HEAD(skipped);
 +	int ret, nr_shrunk = 0;
 +	int retried = 0, skip_precached = 1, nr_skipped = 0;
 +
 +	spin_lock(&sbi->s_es_lru_lock);
 +
 +retry:
 +	list_for_each_safe(cur, tmp, &sbi->s_es_lru) {
 +		/*
 +		 * If we have already reclaimed all extents from extent
 +		 * status tree, just stop the loop immediately.
 +		 */
 +		if (percpu_counter_read_positive(&sbi->s_extent_cache_cnt) == 0)
 +			break;
 +
 +		ei = list_entry(cur, struct ext4_inode_info, i_es_lru);
++=======
+ 	struct ext4_es_stats *es_stats;
+ 	ktime_t start_time;
+ 	u64 scan_time;
+ 	int nr_to_walk;
+ 	int nr_shrunk = 0;
+ 	int retried = 0, nr_skipped = 0;
+ 
+ 	es_stats = &sbi->s_es_stats;
+ 	start_time = ktime_get();
+ 
+ retry:
+ 	spin_lock(&sbi->s_es_lock);
+ 	nr_to_walk = sbi->s_es_nr_inode;
+ 	while (nr_to_walk-- > 0) {
+ 		int shrunk;
+ 
+ 		if (list_empty(&sbi->s_es_list)) {
+ 			spin_unlock(&sbi->s_es_lock);
+ 			goto out;
+ 		}
+ 		ei = list_first_entry(&sbi->s_es_list, struct ext4_inode_info,
+ 				      i_es_list);
+ 		/* Move the inode to the tail */
+ 		list_move(&ei->i_es_list, sbi->s_es_list.prev);
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  
  		/*
- 		 * Skip the inode that is newer than the last_sorted
- 		 * time.  Normally we try hard to avoid shrinking
- 		 * precached inodes, but we will as a last resort.
+ 		 * Normally we try hard to avoid shrinking precached inodes,
+ 		 * but we will as a last resort.
  		 */
++<<<<<<< HEAD
 +		if ((sbi->s_es_last_sorted < ei->i_touch_when) ||
 +		    (skip_precached && ext4_test_inode_state(&ei->vfs_inode,
 +						EXT4_STATE_EXT_PRECACHED))) {
++=======
+ 		if (!retried && ext4_test_inode_state(&ei->vfs_inode,
+ 						EXT4_STATE_EXT_PRECACHED)) {
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  			nr_skipped++;
- 			list_move_tail(cur, &skipped);
  			continue;
  		}
  
- 		if (ei->i_es_lru_nr == 0 || ei == locked_ei ||
- 		    !write_trylock(&ei->i_es_lock))
+ 		if (ei == locked_ei || !write_trylock(&ei->i_es_lock)) {
+ 			nr_skipped++;
  			continue;
+ 		}
+ 		/*
+ 		 * Now we hold i_es_lock which protects us from inode reclaim
+ 		 * freeing inode under us
+ 		 */
+ 		spin_unlock(&sbi->s_es_lock);
  
++<<<<<<< HEAD
 +		ret = __es_try_to_reclaim_extents(ei, nr_to_scan);
 +		if (ei->i_es_lru_nr == 0)
 +			list_del_init(&ei->i_es_lru);
 +		write_unlock(&ei->i_es_lock);
 +
 +		nr_shrunk += ret;
 +		nr_to_scan -= ret;
 +		if (nr_to_scan == 0)
 +			break;
 +	}
++=======
+ 		shrunk = __es_try_to_reclaim_extents(ei, nr_to_scan);
+ 		write_unlock(&ei->i_es_lock);
  
- 	/* Move the newer inodes into the tail of the LRU list. */
- 	list_splice_tail(&skipped, &sbi->s_es_lru);
- 	INIT_LIST_HEAD(&skipped);
+ 		nr_shrunk += shrunk;
+ 		nr_to_scan -= shrunk;
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
+ 
+ 		if (nr_to_scan == 0)
+ 			goto out;
+ 		spin_lock(&sbi->s_es_lock);
+ 	}
+ 	spin_unlock(&sbi->s_es_lock);
  
  	/*
  	 * If we skipped any inodes, and we weren't able to make any
@@@ -997,88 -1023,203 +1075,245 @@@
  	 */
  	if ((nr_shrunk == 0) && nr_skipped && !retried) {
  		retried++;
++<<<<<<< HEAD
 +		list_sort(NULL, &sbi->s_es_lru, ext4_inode_touch_time_cmp);
 +		sbi->s_es_last_sorted = jiffies;
 +		ei = list_first_entry(&sbi->s_es_lru, struct ext4_inode_info,
 +				      i_es_lru);
 +		/*
 +		 * If there are no non-precached inodes left on the
 +		 * list, start releasing precached extents.
 +		 */
 +		if (ext4_test_inode_state(&ei->vfs_inode,
 +					  EXT4_STATE_EXT_PRECACHED))
 +			skip_precached = 0;
++=======
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  		goto retry;
  	}
  
  	if (locked_ei && nr_shrunk == 0)
  		nr_shrunk = __es_try_to_reclaim_extents(locked_ei, nr_to_scan);
  
++<<<<<<< HEAD
 +	return nr_shrunk;
 +}
 +
 +static int ext4_es_shrink(struct shrinker *shrink, struct shrink_control *sc)
++=======
+ out:
+ 	scan_time = ktime_to_ns(ktime_sub(ktime_get(), start_time));
+ 	if (likely(es_stats->es_stats_scan_time))
+ 		es_stats->es_stats_scan_time = (scan_time +
+ 				es_stats->es_stats_scan_time*3) / 4;
+ 	else
+ 		es_stats->es_stats_scan_time = scan_time;
+ 	if (scan_time > es_stats->es_stats_max_scan_time)
+ 		es_stats->es_stats_max_scan_time = scan_time;
+ 	if (likely(es_stats->es_stats_shrunk))
+ 		es_stats->es_stats_shrunk = (nr_shrunk +
+ 				es_stats->es_stats_shrunk*3) / 4;
+ 	else
+ 		es_stats->es_stats_shrunk = nr_shrunk;
+ 
+ 	trace_ext4_es_shrink(sbi->s_sb, nr_shrunk, scan_time,
+ 			     nr_skipped, retried);
+ 	return nr_shrunk;
+ }
+ 
+ static unsigned long ext4_es_count(struct shrinker *shrink,
+ 				   struct shrink_control *sc)
+ {
+ 	unsigned long nr;
+ 	struct ext4_sb_info *sbi;
+ 
+ 	sbi = container_of(shrink, struct ext4_sb_info, s_es_shrinker);
+ 	nr = percpu_counter_read_positive(&sbi->s_es_stats.es_stats_shk_cnt);
+ 	trace_ext4_es_shrink_count(sbi->s_sb, sc->nr_to_scan, nr);
+ 	return nr;
+ }
+ 
+ static unsigned long ext4_es_scan(struct shrinker *shrink,
+ 				  struct shrink_control *sc)
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  {
  	struct ext4_sb_info *sbi = container_of(shrink,
  					struct ext4_sb_info, s_es_shrinker);
  	int nr_to_scan = sc->nr_to_scan;
  	int ret, nr_shrunk;
  
++<<<<<<< HEAD
 +	ret = percpu_counter_read_positive(&sbi->s_extent_cache_cnt);
 +	trace_ext4_es_shrink_enter(sbi->s_sb, nr_to_scan, ret);
++=======
+ 	ret = percpu_counter_read_positive(&sbi->s_es_stats.es_stats_shk_cnt);
+ 	trace_ext4_es_shrink_scan_enter(sbi->s_sb, nr_to_scan, ret);
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  
  	if (!nr_to_scan)
  		return ret;
  
- 	nr_shrunk = __ext4_es_shrink(sbi, nr_to_scan, NULL);
+ 	nr_shrunk = __es_shrink(sbi, nr_to_scan, NULL);
  
++<<<<<<< HEAD
 +	ret = percpu_counter_read_positive(&sbi->s_extent_cache_cnt);
 +	trace_ext4_es_shrink_exit(sbi->s_sb, nr_shrunk, ret);
++=======
+ 	trace_ext4_es_shrink_scan_exit(sbi->s_sb, nr_shrunk, ret);
+ 	return nr_shrunk;
+ }
+ 
+ static void *ext4_es_seq_shrinker_info_start(struct seq_file *seq, loff_t *pos)
+ {
+ 	return *pos ? NULL : SEQ_START_TOKEN;
+ }
+ 
+ static void *
+ ext4_es_seq_shrinker_info_next(struct seq_file *seq, void *v, loff_t *pos)
+ {
+ 	return NULL;
+ }
+ 
+ static int ext4_es_seq_shrinker_info_show(struct seq_file *seq, void *v)
+ {
+ 	struct ext4_sb_info *sbi = seq->private;
+ 	struct ext4_es_stats *es_stats = &sbi->s_es_stats;
+ 	struct ext4_inode_info *ei, *max = NULL;
+ 	unsigned int inode_cnt = 0;
+ 
+ 	if (v != SEQ_START_TOKEN)
+ 		return 0;
+ 
+ 	/* here we just find an inode that has the max nr. of objects */
+ 	spin_lock(&sbi->s_es_lock);
+ 	list_for_each_entry(ei, &sbi->s_es_list, i_es_list) {
+ 		inode_cnt++;
+ 		if (max && max->i_es_all_nr < ei->i_es_all_nr)
+ 			max = ei;
+ 		else if (!max)
+ 			max = ei;
+ 	}
+ 	spin_unlock(&sbi->s_es_lock);
+ 
+ 	seq_printf(seq, "stats:\n  %lld objects\n  %lld reclaimable objects\n",
+ 		   percpu_counter_sum_positive(&es_stats->es_stats_all_cnt),
+ 		   percpu_counter_sum_positive(&es_stats->es_stats_shk_cnt));
+ 	seq_printf(seq, "  %lu/%lu cache hits/misses\n",
+ 		   es_stats->es_stats_cache_hits,
+ 		   es_stats->es_stats_cache_misses);
+ 	if (inode_cnt)
+ 		seq_printf(seq, "  %d inodes on list\n", inode_cnt);
+ 
+ 	seq_printf(seq, "average:\n  %llu us scan time\n",
+ 	    div_u64(es_stats->es_stats_scan_time, 1000));
+ 	seq_printf(seq, "  %lu shrunk objects\n", es_stats->es_stats_shrunk);
+ 	if (inode_cnt)
+ 		seq_printf(seq,
+ 		    "maximum:\n  %lu inode (%u objects, %u reclaimable)\n"
+ 		    "  %llu us max scan time\n",
+ 		    max->vfs_inode.i_ino, max->i_es_all_nr, max->i_es_shk_nr,
+ 		    div_u64(es_stats->es_stats_max_scan_time, 1000));
+ 
+ 	return 0;
+ }
+ 
+ static void ext4_es_seq_shrinker_info_stop(struct seq_file *seq, void *v)
+ {
+ }
+ 
+ static const struct seq_operations ext4_es_seq_shrinker_info_ops = {
+ 	.start = ext4_es_seq_shrinker_info_start,
+ 	.next  = ext4_es_seq_shrinker_info_next,
+ 	.stop  = ext4_es_seq_shrinker_info_stop,
+ 	.show  = ext4_es_seq_shrinker_info_show,
+ };
+ 
+ static int
+ ext4_es_seq_shrinker_info_open(struct inode *inode, struct file *file)
+ {
+ 	int ret;
+ 
+ 	ret = seq_open(file, &ext4_es_seq_shrinker_info_ops);
+ 	if (!ret) {
+ 		struct seq_file *m = file->private_data;
+ 		m->private = PDE_DATA(inode);
+ 	}
+ 
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  	return ret;
  }
  
 -static int
 -ext4_es_seq_shrinker_info_release(struct inode *inode, struct file *file)
 +void ext4_es_register_shrinker(struct ext4_sb_info *sbi)
  {
++<<<<<<< HEAD
 +	INIT_LIST_HEAD(&sbi->s_es_lru);
 +	spin_lock_init(&sbi->s_es_lru_lock);
 +	sbi->s_es_last_sorted = 0;
 +	sbi->s_es_shrinker.shrink = ext4_es_shrink;
 +	sbi->s_es_shrinker.seeks = DEFAULT_SEEKS;
 +	register_shrinker(&sbi->s_es_shrinker);
++=======
+ 	return seq_release(inode, file);
  }
  
- void ext4_es_unregister_shrinker(struct ext4_sb_info *sbi)
- {
- 	unregister_shrinker(&sbi->s_es_shrinker);
- }
+ static const struct file_operations ext4_es_seq_shrinker_info_fops = {
+ 	.owner		= THIS_MODULE,
+ 	.open		= ext4_es_seq_shrinker_info_open,
+ 	.read		= seq_read,
+ 	.llseek		= seq_lseek,
+ 	.release	= ext4_es_seq_shrinker_info_release,
+ };
  
- void ext4_es_lru_add(struct inode *inode)
+ int ext4_es_register_shrinker(struct ext4_sb_info *sbi)
  {
- 	struct ext4_inode_info *ei = EXT4_I(inode);
- 	struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);
+ 	int err;
+ 
+ 	INIT_LIST_HEAD(&sbi->s_es_list);
+ 	sbi->s_es_nr_inode = 0;
+ 	spin_lock_init(&sbi->s_es_lock);
+ 	sbi->s_es_stats.es_stats_shrunk = 0;
+ 	sbi->s_es_stats.es_stats_cache_hits = 0;
+ 	sbi->s_es_stats.es_stats_cache_misses = 0;
+ 	sbi->s_es_stats.es_stats_scan_time = 0;
+ 	sbi->s_es_stats.es_stats_max_scan_time = 0;
+ 	err = percpu_counter_init(&sbi->s_es_stats.es_stats_all_cnt, 0, GFP_KERNEL);
+ 	if (err)
+ 		return err;
+ 	err = percpu_counter_init(&sbi->s_es_stats.es_stats_shk_cnt, 0, GFP_KERNEL);
+ 	if (err)
+ 		goto err1;
  
- 	ei->i_touch_when = jiffies;
+ 	sbi->s_es_shrinker.scan_objects = ext4_es_scan;
+ 	sbi->s_es_shrinker.count_objects = ext4_es_count;
+ 	sbi->s_es_shrinker.seeks = DEFAULT_SEEKS;
+ 	err = register_shrinker(&sbi->s_es_shrinker);
+ 	if (err)
+ 		goto err2;
  
- 	if (!list_empty(&ei->i_es_lru))
- 		return;
+ 	if (sbi->s_proc)
+ 		proc_create_data("es_shrinker_info", S_IRUGO, sbi->s_proc,
+ 				 &ext4_es_seq_shrinker_info_fops, sbi);
  
- 	spin_lock(&sbi->s_es_lru_lock);
- 	if (list_empty(&ei->i_es_lru))
- 		list_add_tail(&ei->i_es_lru, &sbi->s_es_lru);
- 	spin_unlock(&sbi->s_es_lru_lock);
+ 	return 0;
+ 
+ err2:
+ 	percpu_counter_destroy(&sbi->s_es_stats.es_stats_shk_cnt);
+ err1:
+ 	percpu_counter_destroy(&sbi->s_es_stats.es_stats_all_cnt);
+ 	return err;
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  }
  
- void ext4_es_lru_del(struct inode *inode)
+ void ext4_es_unregister_shrinker(struct ext4_sb_info *sbi)
  {
- 	struct ext4_inode_info *ei = EXT4_I(inode);
- 	struct ext4_sb_info *sbi = EXT4_SB(inode->i_sb);
- 
- 	spin_lock(&sbi->s_es_lru_lock);
- 	if (!list_empty(&ei->i_es_lru))
- 		list_del_init(&ei->i_es_lru);
- 	spin_unlock(&sbi->s_es_lru_lock);
++<<<<<<< HEAD
++=======
+ 	if (sbi->s_proc)
+ 		remove_proc_entry("es_shrinker_info", sbi->s_proc);
+ 	percpu_counter_destroy(&sbi->s_es_stats.es_stats_all_cnt);
+ 	percpu_counter_destroy(&sbi->s_es_stats.es_stats_shk_cnt);
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
+ 	unregister_shrinker(&sbi->s_es_shrinker);
  }
  
  static int __es_try_to_reclaim_extents(struct ext4_inode_info *ei,
diff --cc fs/ext4/extents_status.h
index f1b62a419920,0e6a33e81e5f..000000000000
--- a/fs/ext4/extents_status.h
+++ b/fs/ext4/extents_status.h
@@@ -64,6 -64,16 +64,19 @@@ struct ext4_es_tree 
  	struct extent_status *cache_es;	/* recently accessed extent */
  };
  
++<<<<<<< HEAD
++=======
+ struct ext4_es_stats {
+ 	unsigned long es_stats_shrunk;
+ 	unsigned long es_stats_cache_hits;
+ 	unsigned long es_stats_cache_misses;
+ 	u64 es_stats_scan_time;
+ 	u64 es_stats_max_scan_time;
+ 	struct percpu_counter es_stats_all_cnt;
+ 	struct percpu_counter es_stats_shk_cnt;
+ };
+ 
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  extern int __init ext4_init_es(void);
  extern void ext4_exit_es(void);
  extern void ext4_es_init_tree(struct ext4_es_tree *tree);
@@@ -138,9 -148,9 +151,9 @@@ static inline void ext4_es_store_pblock
  		       (pb & ~ES_MASK));
  }
  
 -extern int ext4_es_register_shrinker(struct ext4_sb_info *sbi);
 +extern void ext4_es_register_shrinker(struct ext4_sb_info *sbi);
  extern void ext4_es_unregister_shrinker(struct ext4_sb_info *sbi);
- extern void ext4_es_lru_add(struct inode *inode);
- extern void ext4_es_lru_del(struct inode *inode);
+ extern void ext4_es_list_add(struct inode *inode);
+ extern void ext4_es_list_del(struct inode *inode);
  
  #endif /* _EXT4_EXTENTS_STATUS_H */
diff --cc fs/ext4/super.c
index 417c0071ce41,32df08e99ca9..000000000000
--- a/fs/ext4/super.c
+++ b/fs/ext4/super.c
@@@ -918,9 -871,9 +918,15 @@@ static struct inode *ext4_alloc_inode(s
  	spin_lock_init(&ei->i_prealloc_lock);
  	ext4_es_init_tree(&ei->i_es_tree);
  	rwlock_init(&ei->i_es_lock);
++<<<<<<< HEAD
 +	INIT_LIST_HEAD(&ei->i_es_lru);
 +	ei->i_es_lru_nr = 0;
 +	ei->i_touch_when = 0;
++=======
+ 	INIT_LIST_HEAD(&ei->i_es_list);
+ 	ei->i_es_all_nr = 0;
+ 	ei->i_es_shk_nr = 0;
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  	ei->i_reserved_data_blocks = 0;
  	ei->i_reserved_meta_blocks = 0;
  	ei->i_allocated_meta_blocks = 0;
diff --cc include/trace/events/ext4.h
index 7b429f35fbff,6cfb841fea7c..000000000000
--- a/include/trace/events/ext4.h
+++ b/include/trace/events/ext4.h
@@@ -2446,6 -2448,34 +2446,37 @@@ TRACE_EVENT(ext4_collapse_range
  		  __entry->offset, __entry->len)
  );
  
++<<<<<<< HEAD
++=======
+ TRACE_EVENT(ext4_es_shrink,
+ 	TP_PROTO(struct super_block *sb, int nr_shrunk, u64 scan_time,
+ 		 int nr_skipped, int retried),
+ 
+ 	TP_ARGS(sb, nr_shrunk, scan_time, nr_skipped, retried),
+ 
+ 	TP_STRUCT__entry(
+ 		__field(	dev_t,		dev		)
+ 		__field(	int,		nr_shrunk	)
+ 		__field(	unsigned long long, scan_time	)
+ 		__field(	int,		nr_skipped	)
+ 		__field(	int,		retried		)
+ 	),
+ 
+ 	TP_fast_assign(
+ 		__entry->dev		= sb->s_dev;
+ 		__entry->nr_shrunk	= nr_shrunk;
+ 		__entry->scan_time	= div_u64(scan_time, 1000);
+ 		__entry->nr_skipped	= nr_skipped;
+ 		__entry->retried	= retried;
+ 	),
+ 
+ 	TP_printk("dev %d,%d nr_shrunk %d, scan_time %llu "
+ 		  "nr_skipped %d retried %d",
+ 		  MAJOR(__entry->dev), MINOR(__entry->dev), __entry->nr_shrunk,
+ 		  __entry->scan_time, __entry->nr_skipped, __entry->retried)
+ );
+ 
++>>>>>>> edaa53cac8fd (ext4: change LRU to round-robin in extent status tree shrinker)
  #endif /* _TRACE_EXT4_H */
  
  /* This part must be outside protection */
* Unmerged path fs/ext4/ext4.h
diff --git a/fs/ext4/extents.c b/fs/ext4/extents.c
index 72233774feed..1b33dbcc3b9e 100644
--- a/fs/ext4/extents.c
+++ b/fs/ext4/extents.c
@@ -4663,7 +4663,7 @@ out2:
 
 	trace_ext4_ext_map_blocks_exit(inode, flags, map,
 				       err ? err : allocated);
-	ext4_es_lru_add(inode);
+	ext4_es_list_add(inode);
 	return err ? err : allocated;
 }
 
@@ -5234,7 +5234,7 @@ int ext4_fiemap(struct inode *inode, struct fiemap_extent_info *fieinfo,
 		error = ext4_fill_fiemap_extents(inode, start_blk,
 						 len_blks, fieinfo);
 	}
-	ext4_es_lru_add(inode);
+	ext4_es_list_add(inode);
 	return error;
 }
 
* Unmerged path fs/ext4/extents_status.c
* Unmerged path fs/ext4/extents_status.h
diff --git a/fs/ext4/inode.c b/fs/ext4/inode.c
index 8274eb8296d4..fbe3a32b9b8e 100644
--- a/fs/ext4/inode.c
+++ b/fs/ext4/inode.c
@@ -494,7 +494,7 @@ int ext4_map_blocks(handle_t *handle, struct inode *inode,
 
 	/* Lookup extent status tree firstly */
 	if (ext4_es_lookup_extent(inode, map->m_lblk, &es)) {
-		ext4_es_lru_add(inode);
+		ext4_es_list_add(inode);
 		if (ext4_es_is_written(&es) || ext4_es_is_unwritten(&es)) {
 			map->m_pblk = ext4_es_pblock(&es) +
 					map->m_lblk - es.es_lblk;
@@ -1487,7 +1487,7 @@ static int ext4_da_map_blocks(struct inode *inode, sector_t iblock,
 
 	/* Lookup extent status tree firstly */
 	if (ext4_es_lookup_extent(inode, iblock, &es)) {
-		ext4_es_lru_add(inode);
+		ext4_es_list_add(inode);
 		if (ext4_es_is_hole(&es)) {
 			retval = 0;
 			down_read(&EXT4_I(inode)->i_data_sem);
diff --git a/fs/ext4/ioctl.c b/fs/ext4/ioctl.c
index fe421e8dcaba..ecd3f7189161 100644
--- a/fs/ext4/ioctl.c
+++ b/fs/ext4/ioctl.c
@@ -79,8 +79,8 @@ static void swap_inode_data(struct inode *inode1, struct inode *inode2)
 	memswap(&ei1->i_disksize, &ei2->i_disksize, sizeof(ei1->i_disksize));
 	ext4_es_remove_extent(inode1, 0, EXT_MAX_BLOCKS);
 	ext4_es_remove_extent(inode2, 0, EXT_MAX_BLOCKS);
-	ext4_es_lru_del(inode1);
-	ext4_es_lru_del(inode2);
+	ext4_es_list_del(inode1);
+	ext4_es_list_del(inode2);
 
 	isize = i_size_read(inode1);
 	i_size_write(inode1, i_size_read(inode2));
* Unmerged path fs/ext4/super.c
* Unmerged path include/trace/events/ext4.h
