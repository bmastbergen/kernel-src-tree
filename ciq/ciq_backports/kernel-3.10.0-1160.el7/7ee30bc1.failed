KVM: x86: deliver KVM IOAPIC scan request to target vCPUs

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-1160.el7
commit-author Nitesh Narayan Lal <nitesh@redhat.com>
commit 7ee30bc132c683d06a6d9e360e39e483e3990708
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.el7/7ee30bc1.failed

In IOAPIC fixed delivery mode instead of flushing the scan
requests to all vCPUs, we should only send the requests to
vCPUs specified within the destination field.

This patch introduces kvm_get_dest_vcpus_mask() API which
retrieves an array of target vCPUs by using
kvm_apic_map_get_dest_lapic() and then based on the
vcpus_idx, it sets the bit in a bitmap. However, if the above
fails kvm_get_dest_vcpus_mask() finds the target vCPUs by
traversing all available vCPUs. Followed by setting the
bits in the bitmap.

If we had different vCPUs in the previous request for the
same redirection table entry then bits corresponding to
these vCPUs are also set. This to done to keep
ioapic_handled_vectors synchronized.

This bitmap is then eventually passed on to
kvm_make_vcpus_request_mask() to generate a masked request
only for the target vCPUs.

This would enable us to reduce the latency overhead on isolated
vCPUs caused by the IPI to process due to KVM_REQ_IOAPIC_SCAN.

	Suggested-by: Marcelo Tosatti <mtosatti@redhat.com>
	Signed-off-by: Nitesh Narayan Lal <nitesh@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 7ee30bc132c683d06a6d9e360e39e483e3990708)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/kvm_host.h
#	arch/x86/kvm/ioapic.c
#	arch/x86/kvm/x86.c
diff --cc arch/x86/include/asm/kvm_host.h
index b6317f3d615e,898ab9eb4dc8..000000000000
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@@ -1433,6 -1586,11 +1433,14 @@@ u64 kvm_read_l1_tsc(struct kvm_vcpu *vc
  unsigned long kvm_get_linear_rip(struct kvm_vcpu *vcpu);
  bool kvm_is_linear_rip(struct kvm_vcpu *vcpu, unsigned long linear_rip);
  
++<<<<<<< HEAD
++=======
+ void kvm_make_mclock_inprogress_request(struct kvm *kvm);
+ void kvm_make_scan_ioapic_request(struct kvm *kvm);
+ void kvm_make_scan_ioapic_request_mask(struct kvm *kvm,
+ 				       unsigned long *vcpu_bitmap);
+ 
++>>>>>>> 7ee30bc132c6 (KVM: x86: deliver KVM IOAPIC scan request to target vCPUs)
  void kvm_arch_async_page_not_present(struct kvm_vcpu *vcpu,
  				     struct kvm_async_pf *work);
  void kvm_arch_async_page_present(struct kvm_vcpu *vcpu,
diff --cc arch/x86/kvm/ioapic.c
index 48c3d0dcf67b,ce30ef23c86b..000000000000
--- a/arch/x86/kvm/ioapic.c
+++ b/arch/x86/kvm/ioapic.c
@@@ -329,7 -324,33 +332,37 @@@ static void ioapic_write_indirect(struc
  		if (e->fields.trig_mode == IOAPIC_LEVEL_TRIG
  		    && ioapic->irr & (1 << index))
  			ioapic_service(ioapic, index, false);
++<<<<<<< HEAD
 +		kvm_vcpu_request_scan_ioapic(ioapic->kvm);
++=======
+ 		if (e->fields.delivery_mode == APIC_DM_FIXED) {
+ 			struct kvm_lapic_irq irq;
+ 
+ 			irq.shorthand = 0;
+ 			irq.vector = e->fields.vector;
+ 			irq.delivery_mode = e->fields.delivery_mode << 8;
+ 			irq.dest_id = e->fields.dest_id;
+ 			irq.dest_mode = e->fields.dest_mode;
+ 			kvm_bitmap_or_dest_vcpus(ioapic->kvm, &irq,
+ 						 &vcpu_bitmap);
+ 			if (old_dest_mode != e->fields.dest_mode ||
+ 			    old_dest_id != e->fields.dest_id) {
+ 				/*
+ 				 * Update vcpu_bitmap with vcpus specified in
+ 				 * the previous request as well. This is done to
+ 				 * keep ioapic_handled_vectors synchronized.
+ 				 */
+ 				irq.dest_id = old_dest_id;
+ 				irq.dest_mode = old_dest_mode;
+ 				kvm_bitmap_or_dest_vcpus(ioapic->kvm, &irq,
+ 							 &vcpu_bitmap);
+ 			}
+ 			kvm_make_scan_ioapic_request_mask(ioapic->kvm,
+ 							  &vcpu_bitmap);
+ 		} else {
+ 			kvm_make_scan_ioapic_request(ioapic->kvm);
+ 		}
++>>>>>>> 7ee30bc132c6 (KVM: x86: deliver KVM IOAPIC scan request to target vCPUs)
  		break;
  	}
  }
diff --cc arch/x86/kvm/x86.c
index 8137675c477b,991dd01ba08b..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -6804,9 -7874,28 +6804,31 @@@ static void process_smi(struct kvm_vcp
  	kvm_make_request(KVM_REQ_EVENT, vcpu);
  }
  
++<<<<<<< HEAD
++=======
+ void kvm_make_scan_ioapic_request_mask(struct kvm *kvm,
+ 				       unsigned long *vcpu_bitmap)
+ {
+ 	cpumask_var_t cpus;
+ 	bool called;
+ 
+ 	zalloc_cpumask_var(&cpus, GFP_ATOMIC);
+ 
+ 	called = kvm_make_vcpus_request_mask(kvm, KVM_REQ_SCAN_IOAPIC,
+ 					     vcpu_bitmap, cpus);
+ 
+ 	free_cpumask_var(cpus);
+ }
+ 
+ void kvm_make_scan_ioapic_request(struct kvm *kvm)
+ {
+ 	kvm_make_all_cpus_request(kvm, KVM_REQ_SCAN_IOAPIC);
+ }
+ 
++>>>>>>> 7ee30bc132c6 (KVM: x86: deliver KVM IOAPIC scan request to target vCPUs)
  static void vcpu_scan_ioapic(struct kvm_vcpu *vcpu)
  {
 -	if (!kvm_apic_present(vcpu))
 +	if (!kvm_apic_hw_enabled(vcpu->arch.apic))
  		return;
  
  	bitmap_zero(vcpu->arch.ioapic_handled_vectors, 256);
* Unmerged path arch/x86/include/asm/kvm_host.h
* Unmerged path arch/x86/kvm/ioapic.c
diff --git a/arch/x86/kvm/lapic.c b/arch/x86/kvm/lapic.c
index 27da7d39f701..dc18ddb7a6d0 100644
--- a/arch/x86/kvm/lapic.c
+++ b/arch/x86/kvm/lapic.c
@@ -1061,6 +1061,50 @@ static int __apic_accept_irq(struct kvm_lapic *apic, int delivery_mode,
 	return result;
 }
 
+/*
+ * This routine identifies the destination vcpus mask meant to receive the
+ * IOAPIC interrupts. It either uses kvm_apic_map_get_dest_lapic() to find
+ * out the destination vcpus array and set the bitmap or it traverses to
+ * each available vcpu to identify the same.
+ */
+void kvm_bitmap_or_dest_vcpus(struct kvm *kvm, struct kvm_lapic_irq *irq,
+			      unsigned long *vcpu_bitmap)
+{
+	struct kvm_lapic **dest_vcpu = NULL;
+	struct kvm_lapic *src = NULL;
+	struct kvm_apic_map *map;
+	struct kvm_vcpu *vcpu;
+	unsigned long bitmap;
+	int i, vcpu_idx;
+	bool ret;
+
+	rcu_read_lock();
+	map = rcu_dereference(kvm->arch.apic_map);
+
+	ret = kvm_apic_map_get_dest_lapic(kvm, &src, irq, map, &dest_vcpu,
+					  &bitmap);
+	if (ret) {
+		for_each_set_bit(i, &bitmap, 16) {
+			if (!dest_vcpu[i])
+				continue;
+			vcpu_idx = dest_vcpu[i]->vcpu->vcpu_idx;
+			__set_bit(vcpu_idx, vcpu_bitmap);
+		}
+	} else {
+		kvm_for_each_vcpu(i, vcpu, kvm) {
+			if (!kvm_apic_present(vcpu))
+				continue;
+			if (!kvm_apic_match_dest(vcpu, NULL,
+						 irq->delivery_mode,
+						 irq->dest_id,
+						 irq->dest_mode))
+				continue;
+			__set_bit(i, vcpu_bitmap);
+		}
+	}
+	rcu_read_unlock();
+}
+
 int kvm_apic_compare_prio(struct kvm_vcpu *vcpu1, struct kvm_vcpu *vcpu2)
 {
 	return vcpu1->arch.apic_arb_prio - vcpu2->arch.apic_arb_prio;
diff --git a/arch/x86/kvm/lapic.h b/arch/x86/kvm/lapic.h
index e666ef59bc8e..2aee1b03fdc8 100644
--- a/arch/x86/kvm/lapic.h
+++ b/arch/x86/kvm/lapic.h
@@ -219,6 +219,9 @@ bool kvm_apic_pending_eoi(struct kvm_vcpu *vcpu, int vector);
 
 void wait_lapic_expire(struct kvm_vcpu *vcpu);
 
+void kvm_bitmap_or_dest_vcpus(struct kvm *kvm, struct kvm_lapic_irq *irq,
+			      unsigned long *vcpu_bitmap);
+
 bool kvm_intr_is_single_vcpu_fast(struct kvm *kvm, struct kvm_lapic_irq *irq,
 			struct kvm_vcpu **dest_vcpu);
 int kvm_vector_to_index(u32 vector, u32 dest_vcpus,
* Unmerged path arch/x86/kvm/x86.c
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index f5e57cdc0fdc..b9d8cf4b07b4 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -701,6 +701,8 @@ void kvm_reload_remote_mmus(struct kvm *kvm);
 void kvm_make_mclock_inprogress_request(struct kvm *kvm);
 void kvm_make_scan_ioapic_request(struct kvm *kvm);
 bool kvm_make_all_cpus_request(struct kvm *kvm, unsigned int req);
+bool kvm_make_cpus_request_mask(struct kvm *kvm, unsigned int req,
+				unsigned long *vcpu_bitmap);
 
 long kvm_arch_dev_ioctl(struct file *filp,
 			unsigned int ioctl, unsigned long arg);
