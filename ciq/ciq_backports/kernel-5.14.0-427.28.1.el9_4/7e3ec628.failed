x86/cpu/amd: Provide a separate accessor for Node ID

jira LE-1907
Rebuild_History Non-Buildable kernel-5.14.0-427.28.1.el9_4
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 7e3ec6286753b404666af9a58d283690302c9321
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-5.14.0-427.28.1.el9_4/7e3ec628.failed

AMD (ab)uses topology_die_id() to store the Node ID information and
topology_max_dies_per_pkg to store the number of nodes per package.

This collides with the proper processor die level enumeration which is
coming on AMD with CPUID 8000_0026, unless there is a correlation between
the two. There is zero documentation about that.

So provide new storage and new accessors which for now still access die_id
and topology_max_die_per_pkg(). Will be mopped up after AMD and HYGON are
converted over.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Tested-by: Juergen Gross <jgross@suse.com>
	Tested-by: Sohil Mehta <sohil.mehta@intel.com>
	Tested-by: Michael Kelley <mhklinux@outlook.com>
	Tested-by: Zhang Rui <rui.zhang@intel.com>
	Tested-by: Wang Wendy <wendy.wang@intel.com>
	Tested-by: K Prateek Nayak <kprateek.nayak@amd.com>
Link: https://lore.kernel.org/r/20240212153624.956116738@linutronix.de

(cherry picked from commit 7e3ec6286753b404666af9a58d283690302c9321)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/processor.h
#	arch/x86/include/asm/topology.h
diff --cc arch/x86/include/asm/processor.h
index d6610dd3b5b6,26a6001ddafd..000000000000
--- a/arch/x86/include/asm/processor.h
+++ b/arch/x86/include/asm/processor.h
@@@ -75,15 -74,40 +75,50 @@@ extern u16 __read_mostly tlb_lld_2m[NR_
  extern u16 __read_mostly tlb_lld_4m[NR_INFO];
  extern u16 __read_mostly tlb_lld_1g[NR_INFO];
  
++<<<<<<< HEAD
 +struct cpuinfo_x86_rh {
++=======
+ /*
+  * CPU type and hardware bug flags. Kept separately for each CPU.
+  */
+ 
+ struct cpuinfo_topology {
+ 	// Real APIC ID read from the local APIC
+ 	u32			apicid;
+ 	// The initial APIC ID provided by CPUID
+ 	u32			initial_apicid;
+ 
+ 	// Physical package ID
+ 	u32			pkg_id;
+ 
+ 	// Physical die ID on AMD, Relative on Intel
+ 	u32			die_id;
+ 
+ 	// Compute unit ID - AMD specific
+ 	u32			cu_id;
+ 
+ 	// Core ID relative to the package
+ 	u32			core_id;
+ 
+ 	// Logical ID mappings
+ 	u32			logical_pkg_id;
+ 	u32			logical_die_id;
+ 
+ 	// AMD Node ID and Nodes per Package info
+ 	u32			amd_node_id;
+ 
+ 	// Cache level topology IDs
+ 	u32			llc_id;
+ 	u32			l2c_id;
++>>>>>>> 7e3ec6286753 (x86/cpu/amd: Provide a separate accessor for Node ID)
  };
  
 +/*
 + *  CPU type and hardware bug flags. Kept separately for each CPU.
 + *  Members of this structure are referenced in head_32.S, so think twice
 + *  before touching them. [mj]
 + */
 +
  struct cpuinfo_x86 {
  	__u8			x86;		/* CPU family */
  	__u8			x86_vendor;	/* CPU vendor */
diff --cc arch/x86/include/asm/topology.h
index 744cd099efee,1fd12e98a283..000000000000
--- a/arch/x86/include/asm/topology.h
+++ b/arch/x86/include/asm/topology.h
@@@ -105,13 -105,34 +105,15 @@@ static inline void setup_node_to_cpumas
  extern const struct cpumask *cpu_coregroup_mask(int cpu);
  extern const struct cpumask *cpu_clustergroup_mask(int cpu);
  
 -#define topology_logical_package_id(cpu)	(cpu_data(cpu).topo.logical_pkg_id)
 -#define topology_physical_package_id(cpu)	(cpu_data(cpu).topo.pkg_id)
 -#define topology_logical_die_id(cpu)		(cpu_data(cpu).topo.logical_die_id)
 -#define topology_die_id(cpu)			(cpu_data(cpu).topo.die_id)
 -#define topology_core_id(cpu)			(cpu_data(cpu).topo.core_id)
 +#define topology_logical_package_id(cpu)	(cpu_data(cpu).logical_proc_id)
 +#define topology_physical_package_id(cpu)	(cpu_data(cpu).phys_proc_id)
 +#define topology_logical_die_id(cpu)		(cpu_data(cpu).logical_die_id)
 +#define topology_die_id(cpu)			(cpu_data(cpu).cpu_die_id)
 +#define topology_core_id(cpu)			(cpu_data(cpu).cpu_core_id)
  #define topology_ppin(cpu)			(cpu_data(cpu).ppin)
  
+ #define topology_amd_node_id(cpu)		(cpu_data(cpu).topo.die_id)
+ 
  extern unsigned int __max_die_per_package;
  
  #ifdef CONFIG_SMP
@@@ -141,8 -162,24 +143,29 @@@ static inline int topology_max_smt_thre
  int topology_update_package_map(unsigned int apicid, unsigned int cpu);
  int topology_update_die_map(unsigned int dieid, unsigned int cpu);
  int topology_phys_to_logical_pkg(unsigned int pkg);
++<<<<<<< HEAD
 +bool topology_is_primary_thread(unsigned int cpu);
 +#else
++=======
+ 
+ static inline unsigned int topology_amd_nodes_per_pkg(void)
+ {
+ 	return __max_die_per_package;
+ }
+ 
+ extern struct cpumask __cpu_primary_thread_mask;
+ #define cpu_primary_thread_mask ((const struct cpumask *)&__cpu_primary_thread_mask)
+ 
+ /**
+  * topology_is_primary_thread - Check whether CPU is the primary SMT thread
+  * @cpu:	CPU to check
+  */
+ static inline bool topology_is_primary_thread(unsigned int cpu)
+ {
+ 	return cpumask_test_cpu(cpu, cpu_primary_thread_mask);
+ }
+ #else /* CONFIG_SMP */
++>>>>>>> 7e3ec6286753 (x86/cpu/amd: Provide a separate accessor for Node ID)
  #define topology_max_packages()			(1)
  static inline int
  topology_update_package_map(unsigned int apicid, unsigned int cpu) { return 0; }
@@@ -152,7 -189,8 +175,12 @@@ static inline int topology_phys_to_logi
  static inline int topology_max_die_per_package(void) { return 1; }
  static inline int topology_max_smt_threads(void) { return 1; }
  static inline bool topology_is_primary_thread(unsigned int cpu) { return true; }
++<<<<<<< HEAD
 +#endif
++=======
+ static inline unsigned int topology_amd_nodes_per_pkg(void) { return 0; };
+ #endif /* !CONFIG_SMP */
++>>>>>>> 7e3ec6286753 (x86/cpu/amd: Provide a separate accessor for Node ID)
  
  static inline void arch_fix_phys_package_id(int num, u32 slot)
  {
diff --git a/arch/x86/events/amd/core.c b/arch/x86/events/amd/core.c
index 4ee6390b45c9..da8b27b03617 100644
--- a/arch/x86/events/amd/core.c
+++ b/arch/x86/events/amd/core.c
@@ -579,7 +579,7 @@ static void amd_pmu_cpu_starting(int cpu)
 	if (!x86_pmu.amd_nb_constraints)
 		return;
 
-	nb_id = topology_die_id(cpu);
+	nb_id = topology_amd_node_id(cpu);
 	WARN_ON_ONCE(nb_id == BAD_APICID);
 
 	for_each_online_cpu(i) {
* Unmerged path arch/x86/include/asm/processor.h
* Unmerged path arch/x86/include/asm/topology.h
diff --git a/arch/x86/kernel/amd_nb.c b/arch/x86/kernel/amd_nb.c
index 43238ac2e845..4a477e27fd8b 100644
--- a/arch/x86/kernel/amd_nb.c
+++ b/arch/x86/kernel/amd_nb.c
@@ -386,7 +386,7 @@ struct resource *amd_get_mmconfig_range(struct resource *res)
 
 int amd_get_subcaches(int cpu)
 {
-	struct pci_dev *link = node_to_amd_nb(topology_die_id(cpu))->link;
+	struct pci_dev *link = node_to_amd_nb(topology_amd_node_id(cpu))->link;
 	unsigned int mask;
 
 	if (!amd_nb_has_feature(AMD_NB_L3_PARTITIONING))
@@ -400,7 +400,7 @@ int amd_get_subcaches(int cpu)
 int amd_set_subcaches(int cpu, unsigned long mask)
 {
 	static unsigned int reset, ban;
-	struct amd_northbridge *nb = node_to_amd_nb(topology_die_id(cpu));
+	struct amd_northbridge *nb = node_to_amd_nb(topology_amd_node_id(cpu));
 	unsigned int reg;
 	int cuid;
 
diff --git a/arch/x86/kernel/cpu/cacheinfo.c b/arch/x86/kernel/cpu/cacheinfo.c
index cac526bd7f24..4ed60c734bb9 100644
--- a/arch/x86/kernel/cpu/cacheinfo.c
+++ b/arch/x86/kernel/cpu/cacheinfo.c
@@ -587,7 +587,7 @@ static void amd_init_l3_cache(struct _cpuid4_info_regs *this_leaf, int index)
 	if (index < 3)
 		return;
 
-	node = topology_die_id(smp_processor_id());
+	node = topology_amd_node_id(smp_processor_id());
 	this_leaf->nb = node_to_amd_nb(node);
 	if (this_leaf->nb && !this_leaf->nb->l3_cache.indices)
 		amd_calc_l3_indices(this_leaf->nb);
diff --git a/arch/x86/kernel/cpu/mce/amd.c b/arch/x86/kernel/cpu/mce/amd.c
index 757775635db5..9324752cca04 100644
--- a/arch/x86/kernel/cpu/mce/amd.c
+++ b/arch/x86/kernel/cpu/mce/amd.c
@@ -1230,7 +1230,7 @@ static int threshold_create_bank(struct threshold_bank **bp, unsigned int cpu,
 		return -ENODEV;
 
 	if (is_shared_bank(bank)) {
-		nb = node_to_amd_nb(topology_die_id(cpu));
+		nb = node_to_amd_nb(topology_amd_node_id(cpu));
 
 		/* threshold descriptor already initialized on this node? */
 		if (nb && nb->bank4) {
@@ -1334,7 +1334,7 @@ static void threshold_remove_bank(struct threshold_bank *bank)
 		 * The last CPU on this node using the shared bank is going
 		 * away, remove that bank now.
 		 */
-		nb = node_to_amd_nb(topology_die_id(smp_processor_id()));
+		nb = node_to_amd_nb(topology_amd_node_id(smp_processor_id()));
 		nb->bank4 = NULL;
 	}
 
diff --git a/arch/x86/kernel/cpu/mce/inject.c b/arch/x86/kernel/cpu/mce/inject.c
index 87c15ab89651..e30fc061adb8 100644
--- a/arch/x86/kernel/cpu/mce/inject.c
+++ b/arch/x86/kernel/cpu/mce/inject.c
@@ -544,8 +544,8 @@ static void do_inject(void)
 	if (boot_cpu_has(X86_FEATURE_AMD_DCM) &&
 	    b == 4 &&
 	    boot_cpu_data.x86 < 0x17) {
-		toggle_nb_mca_mst_cpu(topology_die_id(cpu));
-		cpu = get_nbc_for_node(topology_die_id(cpu));
+		toggle_nb_mca_mst_cpu(topology_amd_node_id(cpu));
+		cpu = get_nbc_for_node(topology_amd_node_id(cpu));
 	}
 
 	cpus_read_lock();
diff --git a/drivers/edac/amd64_edac.c b/drivers/edac/amd64_edac.c
index 32e6576c6309..18442e38ae57 100644
--- a/drivers/edac/amd64_edac.c
+++ b/drivers/edac/amd64_edac.c
@@ -1646,7 +1646,7 @@ static void dct_determine_memory_type(struct amd64_pvt *pvt)
 /* On F10h and later ErrAddr is MC4_ADDR[47:1] */
 static u64 get_error_address(struct amd64_pvt *pvt, struct mce *m)
 {
-	u16 mce_nid = topology_die_id(m->extcpu);
+	u16 mce_nid = topology_amd_node_id(m->extcpu);
 	struct mem_ctl_info *mci;
 	u8 start_bit = 1;
 	u8 end_bit   = 47;
@@ -3183,7 +3183,7 @@ static void get_cpus_on_this_dct_cpumask(struct cpumask *mask, u16 nid)
 	int cpu;
 
 	for_each_online_cpu(cpu)
-		if (topology_die_id(cpu) == nid)
+		if (topology_amd_node_id(cpu) == nid)
 			cpumask_set_cpu(cpu, mask);
 }
 
diff --git a/drivers/edac/mce_amd.c b/drivers/edac/mce_amd.c
index ec8b6c9fedfd..8130c3dc64da 100644
--- a/drivers/edac/mce_amd.c
+++ b/drivers/edac/mce_amd.c
@@ -584,7 +584,7 @@ static void decode_mc3_mce(struct mce *m)
 static void decode_mc4_mce(struct mce *m)
 {
 	unsigned int fam = x86_family(m->cpuid);
-	int node_id = topology_die_id(m->extcpu);
+	int node_id = topology_amd_node_id(m->extcpu);
 	u16 ec = EC(m->status);
 	u8 xec = XEC(m->status, 0x1f);
 	u8 offset = 0;
@@ -746,7 +746,7 @@ static void decode_smca_error(struct mce *m)
 
 	if ((bank_type == SMCA_UMC || bank_type == SMCA_UMC_V2) &&
 	    xec == 0 && decode_dram_ecc)
-		decode_dram_ecc(topology_die_id(m->extcpu), m);
+		decode_dram_ecc(topology_amd_node_id(m->extcpu), m);
 }
 
 static inline void amd_decode_err_code(u16 ec)
