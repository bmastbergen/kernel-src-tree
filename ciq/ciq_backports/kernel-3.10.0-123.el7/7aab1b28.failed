xfs: convert kuid_t to/from uid_t for internal structures

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-123.el7
commit-author Dwight Engen <dwight.engen@oracle.com>
commit 7aab1b28879d2280c9a0e50000e4ae153cfac55a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-123.el7/7aab1b28.failed

Use uint32 from init_user_ns for xfs internal uid/gid
representation in xfs_icdinode, xfs_dqid_t.

	Reviewed-by: Dave Chinner <dchinner@redhat.com>
	Reviewed-by: Gao feng <gaofeng@cn.fujitsu.com>
	Signed-off-by: Dwight Engen <dwight.engen@oracle.com>
	Signed-off-by: Ben Myers <bpm@sgi.com>

(cherry picked from commit 7aab1b28879d2280c9a0e50000e4ae153cfac55a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/xfs_inode.c
#	fs/xfs/xfs_iops.c
#	fs/xfs/xfs_qm.c
#	fs/xfs/xfs_quota.h
#	fs/xfs/xfs_symlink.c
diff --cc fs/xfs/xfs_inode.c
index 7f7be5f98f52,8750cdb6e512..000000000000
--- a/fs/xfs/xfs_inode.c
+++ b/fs/xfs/xfs_inode.c
@@@ -1440,6 -862,583 +1440,586 @@@ xfs_ialloc
  }
  
  /*
++<<<<<<< HEAD
++=======
+  * Allocates a new inode from disk and return a pointer to the
+  * incore copy. This routine will internally commit the current
+  * transaction and allocate a new one if the Space Manager needed
+  * to do an allocation to replenish the inode free-list.
+  *
+  * This routine is designed to be called from xfs_create and
+  * xfs_create_dir.
+  *
+  */
+ int
+ xfs_dir_ialloc(
+ 	xfs_trans_t	**tpp,		/* input: current transaction;
+ 					   output: may be a new transaction. */
+ 	xfs_inode_t	*dp,		/* directory within whose allocate
+ 					   the inode. */
+ 	umode_t		mode,
+ 	xfs_nlink_t	nlink,
+ 	xfs_dev_t	rdev,
+ 	prid_t		prid,		/* project id */
+ 	int		okalloc,	/* ok to allocate new space */
+ 	xfs_inode_t	**ipp,		/* pointer to inode; it will be
+ 					   locked. */
+ 	int		*committed)
+ 
+ {
+ 	xfs_trans_t	*tp;
+ 	xfs_trans_t	*ntp;
+ 	xfs_inode_t	*ip;
+ 	xfs_buf_t	*ialloc_context = NULL;
+ 	int		code;
+ 	void		*dqinfo;
+ 	uint		tflags;
+ 
+ 	tp = *tpp;
+ 	ASSERT(tp->t_flags & XFS_TRANS_PERM_LOG_RES);
+ 
+ 	/*
+ 	 * xfs_ialloc will return a pointer to an incore inode if
+ 	 * the Space Manager has an available inode on the free
+ 	 * list. Otherwise, it will do an allocation and replenish
+ 	 * the freelist.  Since we can only do one allocation per
+ 	 * transaction without deadlocks, we will need to commit the
+ 	 * current transaction and start a new one.  We will then
+ 	 * need to call xfs_ialloc again to get the inode.
+ 	 *
+ 	 * If xfs_ialloc did an allocation to replenish the freelist,
+ 	 * it returns the bp containing the head of the freelist as
+ 	 * ialloc_context. We will hold a lock on it across the
+ 	 * transaction commit so that no other process can steal
+ 	 * the inode(s) that we've just allocated.
+ 	 */
+ 	code = xfs_ialloc(tp, dp, mode, nlink, rdev, prid, okalloc,
+ 			  &ialloc_context, &ip);
+ 
+ 	/*
+ 	 * Return an error if we were unable to allocate a new inode.
+ 	 * This should only happen if we run out of space on disk or
+ 	 * encounter a disk error.
+ 	 */
+ 	if (code) {
+ 		*ipp = NULL;
+ 		return code;
+ 	}
+ 	if (!ialloc_context && !ip) {
+ 		*ipp = NULL;
+ 		return XFS_ERROR(ENOSPC);
+ 	}
+ 
+ 	/*
+ 	 * If the AGI buffer is non-NULL, then we were unable to get an
+ 	 * inode in one operation.  We need to commit the current
+ 	 * transaction and call xfs_ialloc() again.  It is guaranteed
+ 	 * to succeed the second time.
+ 	 */
+ 	if (ialloc_context) {
+ 		struct xfs_trans_res tres;
+ 
+ 		/*
+ 		 * Normally, xfs_trans_commit releases all the locks.
+ 		 * We call bhold to hang on to the ialloc_context across
+ 		 * the commit.  Holding this buffer prevents any other
+ 		 * processes from doing any allocations in this
+ 		 * allocation group.
+ 		 */
+ 		xfs_trans_bhold(tp, ialloc_context);
+ 		/*
+ 		 * Save the log reservation so we can use
+ 		 * them in the next transaction.
+ 		 */
+ 		tres.tr_logres = xfs_trans_get_log_res(tp);
+ 		tres.tr_logcount = xfs_trans_get_log_count(tp);
+ 
+ 		/*
+ 		 * We want the quota changes to be associated with the next
+ 		 * transaction, NOT this one. So, detach the dqinfo from this
+ 		 * and attach it to the next transaction.
+ 		 */
+ 		dqinfo = NULL;
+ 		tflags = 0;
+ 		if (tp->t_dqinfo) {
+ 			dqinfo = (void *)tp->t_dqinfo;
+ 			tp->t_dqinfo = NULL;
+ 			tflags = tp->t_flags & XFS_TRANS_DQ_DIRTY;
+ 			tp->t_flags &= ~(XFS_TRANS_DQ_DIRTY);
+ 		}
+ 
+ 		ntp = xfs_trans_dup(tp);
+ 		code = xfs_trans_commit(tp, 0);
+ 		tp = ntp;
+ 		if (committed != NULL) {
+ 			*committed = 1;
+ 		}
+ 		/*
+ 		 * If we get an error during the commit processing,
+ 		 * release the buffer that is still held and return
+ 		 * to the caller.
+ 		 */
+ 		if (code) {
+ 			xfs_buf_relse(ialloc_context);
+ 			if (dqinfo) {
+ 				tp->t_dqinfo = dqinfo;
+ 				xfs_trans_free_dqinfo(tp);
+ 			}
+ 			*tpp = ntp;
+ 			*ipp = NULL;
+ 			return code;
+ 		}
+ 
+ 		/*
+ 		 * transaction commit worked ok so we can drop the extra ticket
+ 		 * reference that we gained in xfs_trans_dup()
+ 		 */
+ 		xfs_log_ticket_put(tp->t_ticket);
+ 		tres.tr_logflags = XFS_TRANS_PERM_LOG_RES;
+ 		code = xfs_trans_reserve(tp, &tres, 0, 0);
+ 
+ 		/*
+ 		 * Re-attach the quota info that we detached from prev trx.
+ 		 */
+ 		if (dqinfo) {
+ 			tp->t_dqinfo = dqinfo;
+ 			tp->t_flags |= tflags;
+ 		}
+ 
+ 		if (code) {
+ 			xfs_buf_relse(ialloc_context);
+ 			*tpp = ntp;
+ 			*ipp = NULL;
+ 			return code;
+ 		}
+ 		xfs_trans_bjoin(tp, ialloc_context);
+ 
+ 		/*
+ 		 * Call ialloc again. Since we've locked out all
+ 		 * other allocations in this allocation group,
+ 		 * this call should always succeed.
+ 		 */
+ 		code = xfs_ialloc(tp, dp, mode, nlink, rdev, prid,
+ 				  okalloc, &ialloc_context, &ip);
+ 
+ 		/*
+ 		 * If we get an error at this point, return to the caller
+ 		 * so that the current transaction can be aborted.
+ 		 */
+ 		if (code) {
+ 			*tpp = tp;
+ 			*ipp = NULL;
+ 			return code;
+ 		}
+ 		ASSERT(!ialloc_context && ip);
+ 
+ 	} else {
+ 		if (committed != NULL)
+ 			*committed = 0;
+ 	}
+ 
+ 	*ipp = ip;
+ 	*tpp = tp;
+ 
+ 	return 0;
+ }
+ 
+ /*
+  * Decrement the link count on an inode & log the change.
+  * If this causes the link count to go to zero, initiate the
+  * logging activity required to truncate a file.
+  */
+ int				/* error */
+ xfs_droplink(
+ 	xfs_trans_t *tp,
+ 	xfs_inode_t *ip)
+ {
+ 	int	error;
+ 
+ 	xfs_trans_ichgtime(tp, ip, XFS_ICHGTIME_CHG);
+ 
+ 	ASSERT (ip->i_d.di_nlink > 0);
+ 	ip->i_d.di_nlink--;
+ 	drop_nlink(VFS_I(ip));
+ 	xfs_trans_log_inode(tp, ip, XFS_ILOG_CORE);
+ 
+ 	error = 0;
+ 	if (ip->i_d.di_nlink == 0) {
+ 		/*
+ 		 * We're dropping the last link to this file.
+ 		 * Move the on-disk inode to the AGI unlinked list.
+ 		 * From xfs_inactive() we will pull the inode from
+ 		 * the list and free it.
+ 		 */
+ 		error = xfs_iunlink(tp, ip);
+ 	}
+ 	return error;
+ }
+ 
+ /*
+  * This gets called when the inode's version needs to be changed from 1 to 2.
+  * Currently this happens when the nlink field overflows the old 16-bit value
+  * or when chproj is called to change the project for the first time.
+  * As a side effect the superblock version will also get rev'd
+  * to contain the NLINK bit.
+  */
+ void
+ xfs_bump_ino_vers2(
+ 	xfs_trans_t	*tp,
+ 	xfs_inode_t	*ip)
+ {
+ 	xfs_mount_t	*mp;
+ 
+ 	ASSERT(xfs_isilocked(ip, XFS_ILOCK_EXCL));
+ 	ASSERT(ip->i_d.di_version == 1);
+ 
+ 	ip->i_d.di_version = 2;
+ 	ip->i_d.di_onlink = 0;
+ 	memset(&(ip->i_d.di_pad[0]), 0, sizeof(ip->i_d.di_pad));
+ 	mp = tp->t_mountp;
+ 	if (!xfs_sb_version_hasnlink(&mp->m_sb)) {
+ 		spin_lock(&mp->m_sb_lock);
+ 		if (!xfs_sb_version_hasnlink(&mp->m_sb)) {
+ 			xfs_sb_version_addnlink(&mp->m_sb);
+ 			spin_unlock(&mp->m_sb_lock);
+ 			xfs_mod_sb(tp, XFS_SB_VERSIONNUM);
+ 		} else {
+ 			spin_unlock(&mp->m_sb_lock);
+ 		}
+ 	}
+ 	/* Caller must log the inode */
+ }
+ 
+ /*
+  * Increment the link count on an inode & log the change.
+  */
+ int
+ xfs_bumplink(
+ 	xfs_trans_t *tp,
+ 	xfs_inode_t *ip)
+ {
+ 	xfs_trans_ichgtime(tp, ip, XFS_ICHGTIME_CHG);
+ 
+ 	ASSERT(ip->i_d.di_nlink > 0);
+ 	ip->i_d.di_nlink++;
+ 	inc_nlink(VFS_I(ip));
+ 	if ((ip->i_d.di_version == 1) &&
+ 	    (ip->i_d.di_nlink > XFS_MAXLINK_1)) {
+ 		/*
+ 		 * The inode has increased its number of links beyond
+ 		 * what can fit in an old format inode.  It now needs
+ 		 * to be converted to a version 2 inode with a 32 bit
+ 		 * link count.  If this is the first inode in the file
+ 		 * system to do this, then we need to bump the superblock
+ 		 * version number as well.
+ 		 */
+ 		xfs_bump_ino_vers2(tp, ip);
+ 	}
+ 
+ 	xfs_trans_log_inode(tp, ip, XFS_ILOG_CORE);
+ 	return 0;
+ }
+ 
+ int
+ xfs_create(
+ 	xfs_inode_t		*dp,
+ 	struct xfs_name		*name,
+ 	umode_t			mode,
+ 	xfs_dev_t		rdev,
+ 	xfs_inode_t		**ipp)
+ {
+ 	int			is_dir = S_ISDIR(mode);
+ 	struct xfs_mount	*mp = dp->i_mount;
+ 	struct xfs_inode	*ip = NULL;
+ 	struct xfs_trans	*tp = NULL;
+ 	int			error;
+ 	xfs_bmap_free_t		free_list;
+ 	xfs_fsblock_t		first_block;
+ 	bool                    unlock_dp_on_error = false;
+ 	uint			cancel_flags;
+ 	int			committed;
+ 	prid_t			prid;
+ 	struct xfs_dquot	*udqp = NULL;
+ 	struct xfs_dquot	*gdqp = NULL;
+ 	struct xfs_dquot	*pdqp = NULL;
+ 	struct xfs_trans_res	tres;
+ 	uint			resblks;
+ 
+ 	trace_xfs_create(dp, name);
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		return XFS_ERROR(EIO);
+ 
+ 	if (dp->i_d.di_flags & XFS_DIFLAG_PROJINHERIT)
+ 		prid = xfs_get_projid(dp);
+ 	else
+ 		prid = XFS_PROJID_DEFAULT;
+ 
+ 	/*
+ 	 * Make sure that we have allocated dquot(s) on disk.
+ 	 */
+ 	error = xfs_qm_vop_dqalloc(dp, xfs_kuid_to_uid(current_fsuid()),
+ 					xfs_kgid_to_gid(current_fsgid()), prid,
+ 					XFS_QMOPT_QUOTALL | XFS_QMOPT_INHERIT,
+ 					&udqp, &gdqp, &pdqp);
+ 	if (error)
+ 		return error;
+ 
+ 	if (is_dir) {
+ 		rdev = 0;
+ 		resblks = XFS_MKDIR_SPACE_RES(mp, name->len);
+ 		tres.tr_logres = M_RES(mp)->tr_mkdir.tr_logres;
+ 		tres.tr_logcount = XFS_MKDIR_LOG_COUNT;
+ 		tp = xfs_trans_alloc(mp, XFS_TRANS_MKDIR);
+ 	} else {
+ 		resblks = XFS_CREATE_SPACE_RES(mp, name->len);
+ 		tres.tr_logres = M_RES(mp)->tr_create.tr_logres;
+ 		tres.tr_logcount = XFS_CREATE_LOG_COUNT;
+ 		tp = xfs_trans_alloc(mp, XFS_TRANS_CREATE);
+ 	}
+ 
+ 	cancel_flags = XFS_TRANS_RELEASE_LOG_RES;
+ 
+ 	/*
+ 	 * Initially assume that the file does not exist and
+ 	 * reserve the resources for that case.  If that is not
+ 	 * the case we'll drop the one we have and get a more
+ 	 * appropriate transaction later.
+ 	 */
+ 	tres.tr_logflags = XFS_TRANS_PERM_LOG_RES;
+ 	error = xfs_trans_reserve(tp, &tres, resblks, 0);
+ 	if (error == ENOSPC) {
+ 		/* flush outstanding delalloc blocks and retry */
+ 		xfs_flush_inodes(mp);
+ 		error = xfs_trans_reserve(tp, &tres, resblks, 0);
+ 	}
+ 	if (error == ENOSPC) {
+ 		/* No space at all so try a "no-allocation" reservation */
+ 		resblks = 0;
+ 		error = xfs_trans_reserve(tp, &tres, 0, 0);
+ 	}
+ 	if (error) {
+ 		cancel_flags = 0;
+ 		goto out_trans_cancel;
+ 	}
+ 
+ 	xfs_ilock(dp, XFS_ILOCK_EXCL | XFS_ILOCK_PARENT);
+ 	unlock_dp_on_error = true;
+ 
+ 	xfs_bmap_init(&free_list, &first_block);
+ 
+ 	/*
+ 	 * Reserve disk quota and the inode.
+ 	 */
+ 	error = xfs_trans_reserve_quota(tp, mp, udqp, gdqp,
+ 						pdqp, resblks, 1, 0);
+ 	if (error)
+ 		goto out_trans_cancel;
+ 
+ 	error = xfs_dir_canenter(tp, dp, name, resblks);
+ 	if (error)
+ 		goto out_trans_cancel;
+ 
+ 	/*
+ 	 * A newly created regular or special file just has one directory
+ 	 * entry pointing to them, but a directory also the "." entry
+ 	 * pointing to itself.
+ 	 */
+ 	error = xfs_dir_ialloc(&tp, dp, mode, is_dir ? 2 : 1, rdev,
+ 			       prid, resblks > 0, &ip, &committed);
+ 	if (error) {
+ 		if (error == ENOSPC)
+ 			goto out_trans_cancel;
+ 		goto out_trans_abort;
+ 	}
+ 
+ 	/*
+ 	 * Now we join the directory inode to the transaction.  We do not do it
+ 	 * earlier because xfs_dir_ialloc might commit the previous transaction
+ 	 * (and release all the locks).  An error from here on will result in
+ 	 * the transaction cancel unlocking dp so don't do it explicitly in the
+ 	 * error path.
+ 	 */
+ 	xfs_trans_ijoin(tp, dp, XFS_ILOCK_EXCL);
+ 	unlock_dp_on_error = false;
+ 
+ 	error = xfs_dir_createname(tp, dp, name, ip->i_ino,
+ 					&first_block, &free_list, resblks ?
+ 					resblks - XFS_IALLOC_SPACE_RES(mp) : 0);
+ 	if (error) {
+ 		ASSERT(error != ENOSPC);
+ 		goto out_trans_abort;
+ 	}
+ 	xfs_trans_ichgtime(tp, dp, XFS_ICHGTIME_MOD | XFS_ICHGTIME_CHG);
+ 	xfs_trans_log_inode(tp, dp, XFS_ILOG_CORE);
+ 
+ 	if (is_dir) {
+ 		error = xfs_dir_init(tp, ip, dp);
+ 		if (error)
+ 			goto out_bmap_cancel;
+ 
+ 		error = xfs_bumplink(tp, dp);
+ 		if (error)
+ 			goto out_bmap_cancel;
+ 	}
+ 
+ 	/*
+ 	 * If this is a synchronous mount, make sure that the
+ 	 * create transaction goes to disk before returning to
+ 	 * the user.
+ 	 */
+ 	if (mp->m_flags & (XFS_MOUNT_WSYNC|XFS_MOUNT_DIRSYNC))
+ 		xfs_trans_set_sync(tp);
+ 
+ 	/*
+ 	 * Attach the dquot(s) to the inodes and modify them incore.
+ 	 * These ids of the inode couldn't have changed since the new
+ 	 * inode has been locked ever since it was created.
+ 	 */
+ 	xfs_qm_vop_create_dqattach(tp, ip, udqp, gdqp, pdqp);
+ 
+ 	error = xfs_bmap_finish(&tp, &free_list, &committed);
+ 	if (error)
+ 		goto out_bmap_cancel;
+ 
+ 	error = xfs_trans_commit(tp, XFS_TRANS_RELEASE_LOG_RES);
+ 	if (error)
+ 		goto out_release_inode;
+ 
+ 	xfs_qm_dqrele(udqp);
+ 	xfs_qm_dqrele(gdqp);
+ 	xfs_qm_dqrele(pdqp);
+ 
+ 	*ipp = ip;
+ 	return 0;
+ 
+  out_bmap_cancel:
+ 	xfs_bmap_cancel(&free_list);
+  out_trans_abort:
+ 	cancel_flags |= XFS_TRANS_ABORT;
+  out_trans_cancel:
+ 	xfs_trans_cancel(tp, cancel_flags);
+  out_release_inode:
+ 	/*
+ 	 * Wait until after the current transaction is aborted to
+ 	 * release the inode.  This prevents recursive transactions
+ 	 * and deadlocks from xfs_inactive.
+ 	 */
+ 	if (ip)
+ 		IRELE(ip);
+ 
+ 	xfs_qm_dqrele(udqp);
+ 	xfs_qm_dqrele(gdqp);
+ 	xfs_qm_dqrele(pdqp);
+ 
+ 	if (unlock_dp_on_error)
+ 		xfs_iunlock(dp, XFS_ILOCK_EXCL);
+ 	return error;
+ }
+ 
+ int
+ xfs_link(
+ 	xfs_inode_t		*tdp,
+ 	xfs_inode_t		*sip,
+ 	struct xfs_name		*target_name)
+ {
+ 	xfs_mount_t		*mp = tdp->i_mount;
+ 	xfs_trans_t		*tp;
+ 	int			error;
+ 	xfs_bmap_free_t         free_list;
+ 	xfs_fsblock_t           first_block;
+ 	int			cancel_flags;
+ 	int			committed;
+ 	int			resblks;
+ 
+ 	trace_xfs_link(tdp, target_name);
+ 
+ 	ASSERT(!S_ISDIR(sip->i_d.di_mode));
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		return XFS_ERROR(EIO);
+ 
+ 	error = xfs_qm_dqattach(sip, 0);
+ 	if (error)
+ 		goto std_return;
+ 
+ 	error = xfs_qm_dqattach(tdp, 0);
+ 	if (error)
+ 		goto std_return;
+ 
+ 	tp = xfs_trans_alloc(mp, XFS_TRANS_LINK);
+ 	cancel_flags = XFS_TRANS_RELEASE_LOG_RES;
+ 	resblks = XFS_LINK_SPACE_RES(mp, target_name->len);
+ 	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_link, resblks, 0);
+ 	if (error == ENOSPC) {
+ 		resblks = 0;
+ 		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_link, 0, 0);
+ 	}
+ 	if (error) {
+ 		cancel_flags = 0;
+ 		goto error_return;
+ 	}
+ 
+ 	xfs_lock_two_inodes(sip, tdp, XFS_ILOCK_EXCL);
+ 
+ 	xfs_trans_ijoin(tp, sip, XFS_ILOCK_EXCL);
+ 	xfs_trans_ijoin(tp, tdp, XFS_ILOCK_EXCL);
+ 
+ 	/*
+ 	 * If we are using project inheritance, we only allow hard link
+ 	 * creation in our tree when the project IDs are the same; else
+ 	 * the tree quota mechanism could be circumvented.
+ 	 */
+ 	if (unlikely((tdp->i_d.di_flags & XFS_DIFLAG_PROJINHERIT) &&
+ 		     (xfs_get_projid(tdp) != xfs_get_projid(sip)))) {
+ 		error = XFS_ERROR(EXDEV);
+ 		goto error_return;
+ 	}
+ 
+ 	error = xfs_dir_canenter(tp, tdp, target_name, resblks);
+ 	if (error)
+ 		goto error_return;
+ 
+ 	xfs_bmap_init(&free_list, &first_block);
+ 
+ 	error = xfs_dir_createname(tp, tdp, target_name, sip->i_ino,
+ 					&first_block, &free_list, resblks);
+ 	if (error)
+ 		goto abort_return;
+ 	xfs_trans_ichgtime(tp, tdp, XFS_ICHGTIME_MOD | XFS_ICHGTIME_CHG);
+ 	xfs_trans_log_inode(tp, tdp, XFS_ILOG_CORE);
+ 
+ 	error = xfs_bumplink(tp, sip);
+ 	if (error)
+ 		goto abort_return;
+ 
+ 	/*
+ 	 * If this is a synchronous mount, make sure that the
+ 	 * link transaction goes to disk before returning to
+ 	 * the user.
+ 	 */
+ 	if (mp->m_flags & (XFS_MOUNT_WSYNC|XFS_MOUNT_DIRSYNC)) {
+ 		xfs_trans_set_sync(tp);
+ 	}
+ 
+ 	error = xfs_bmap_finish (&tp, &free_list, &committed);
+ 	if (error) {
+ 		xfs_bmap_cancel(&free_list);
+ 		goto abort_return;
+ 	}
+ 
+ 	return xfs_trans_commit(tp, XFS_TRANS_RELEASE_LOG_RES);
+ 
+  abort_return:
+ 	cancel_flags |= XFS_TRANS_ABORT;
+  error_return:
+ 	xfs_trans_cancel(tp, cancel_flags);
+  std_return:
+ 	return error;
+ }
+ 
+ /*
++>>>>>>> 7aab1b28879d (xfs: convert kuid_t to/from uid_t for internal structures)
   * Free up the underlying blocks past new_size.  The new size must be smaller
   * than the current size.  This routine can be used both for the attribute and
   * data fork, and does not modify the inode size, which is left to the caller.
diff --cc fs/xfs/xfs_iops.c
index ca9ecaa81112,6d7e9e2d7651..000000000000
--- a/fs/xfs/xfs_iops.c
+++ b/fs/xfs/xfs_iops.c
@@@ -538,8 -539,10 +538,15 @@@ xfs_setattr_nonsize
  		 */
  		ASSERT(udqp == NULL);
  		ASSERT(gdqp == NULL);
++<<<<<<< HEAD
 +		error = xfs_qm_vop_dqalloc(ip, uid, gid, xfs_get_projid(ip),
 +					 qflags, &udqp, &gdqp);
++=======
+ 		error = xfs_qm_vop_dqalloc(ip, xfs_kuid_to_uid(uid),
+ 					   xfs_kgid_to_gid(gid),
+ 					   xfs_get_projid(ip),
+ 					   qflags, &udqp, &gdqp, NULL);
++>>>>>>> 7aab1b28879d (xfs: convert kuid_t to/from uid_t for internal structures)
  		if (error)
  			return error;
  	}
@@@ -571,11 -574,11 +578,11 @@@
  		 * going to change.
  		 */
  		if (XFS_IS_QUOTA_RUNNING(mp) &&
- 		    ((XFS_IS_UQUOTA_ON(mp) && iuid != uid) ||
- 		     (XFS_IS_GQUOTA_ON(mp) && igid != gid))) {
+ 		    ((XFS_IS_UQUOTA_ON(mp) && !uid_eq(iuid, uid)) ||
+ 		     (XFS_IS_GQUOTA_ON(mp) && !gid_eq(igid, gid)))) {
  			ASSERT(tp);
  			error = xfs_qm_vop_chown_reserve(tp, ip, udqp, gdqp,
 -						NULL, capable(CAP_FOWNER) ?
 +						capable(CAP_FOWNER) ?
  						XFS_QMOPT_FORCE_RES : 0);
  			if (error)	/* out of quota */
  				goto out_trans_cancel;
diff --cc fs/xfs/xfs_qm.c
index b75c9bb6e71e,6218a0aeeeea..000000000000
--- a/fs/xfs/xfs_qm.c
+++ b/fs/xfs/xfs_qm.c
@@@ -1697,7 -1815,7 +1697,11 @@@ xfs_qm_vop_dqalloc
  			 * holding ilock.
  			 */
  			xfs_iunlock(ip, lockflags);
++<<<<<<< HEAD
 +			if ((error = xfs_qm_dqget(mp, NULL, (xfs_dqid_t) uid,
++=======
+ 			error = xfs_qm_dqget(mp, NULL, uid,
++>>>>>>> 7aab1b28879d (xfs: convert kuid_t to/from uid_t for internal structures)
  						 XFS_DQ_USER,
  						 XFS_QMOPT_DQALLOC |
  						 XFS_QMOPT_DOWARN,
@@@ -1723,7 -1842,7 +1727,11 @@@
  	if ((flags & XFS_QMOPT_GQUOTA) && XFS_IS_GQUOTA_ON(mp)) {
  		if (ip->i_d.di_gid != gid) {
  			xfs_iunlock(ip, lockflags);
++<<<<<<< HEAD
 +			if ((error = xfs_qm_dqget(mp, NULL, (xfs_dqid_t)gid,
++=======
+ 			error = xfs_qm_dqget(mp, NULL, gid,
++>>>>>>> 7aab1b28879d (xfs: convert kuid_t to/from uid_t for internal structures)
  						 XFS_DQ_GROUP,
  						 XFS_QMOPT_DQALLOC |
  						 XFS_QMOPT_DOWARN,
@@@ -1842,8 -1976,8 +1850,13 @@@ xfs_qm_vop_chown_reserve
  			XFS_QMOPT_RES_RTBLKS : XFS_QMOPT_RES_REGBLKS;
  
  	if (XFS_IS_UQUOTA_ON(mp) && udqp &&
++<<<<<<< HEAD
 +	    ip->i_d.di_uid != (uid_t)be32_to_cpu(udqp->q_core.d_id)) {
 +		delblksudq = udqp;
++=======
+ 	    ip->i_d.di_uid != be32_to_cpu(udqp->q_core.d_id)) {
+ 		udq_delblks = udqp;
++>>>>>>> 7aab1b28879d (xfs: convert kuid_t to/from uid_t for internal structures)
  		/*
  		 * If there are delayed allocation blocks, then we have to
  		 * unreserve those from the old dquot, and add them to the
diff --cc fs/xfs/xfs_quota.h
index c38068f26c55,66522da04d6e..000000000000
--- a/fs/xfs/xfs_quota.h
+++ b/fs/xfs/xfs_quota.h
@@@ -318,12 -85,13 +318,18 @@@ extern int xfs_trans_reserve_quota_nblk
  		struct xfs_inode *, long, long, uint);
  extern int xfs_trans_reserve_quota_bydquots(struct xfs_trans *,
  		struct xfs_mount *, struct xfs_dquot *,
 -		struct xfs_dquot *, struct xfs_dquot *, long, long, uint);
 +		struct xfs_dquot *, long, long, uint);
  
++<<<<<<< HEAD
 +extern int xfs_qm_vop_dqalloc(struct xfs_inode *, uid_t, gid_t, prid_t, uint,
 +		struct xfs_dquot **, struct xfs_dquot **);
++=======
+ extern int xfs_qm_vop_dqalloc(struct xfs_inode *, xfs_dqid_t, xfs_dqid_t,
+ 		prid_t, uint, struct xfs_dquot **, struct xfs_dquot **,
+ 		struct xfs_dquot **);
++>>>>>>> 7aab1b28879d (xfs: convert kuid_t to/from uid_t for internal structures)
  extern void xfs_qm_vop_create_dqattach(struct xfs_trans *, struct xfs_inode *,
 -		struct xfs_dquot *, struct xfs_dquot *, struct xfs_dquot *);
 +		struct xfs_dquot *, struct xfs_dquot *);
  extern int xfs_qm_vop_rename_dqattach(struct xfs_inode **);
  extern struct xfs_dquot *xfs_qm_vop_chown(struct xfs_trans *,
  		struct xfs_inode *, struct xfs_dquot **, struct xfs_dquot *);
@@@ -341,8 -110,9 +347,14 @@@ extern void xfs_qm_unmount_quotas(struc
  
  #else
  static inline int
++<<<<<<< HEAD
 +xfs_qm_vop_dqalloc(struct xfs_inode *ip, uid_t uid, gid_t gid, prid_t prid,
 +		uint flags, struct xfs_dquot **udqp, struct xfs_dquot **gdqp)
++=======
+ xfs_qm_vop_dqalloc(struct xfs_inode *ip, xfs_dqid_t uid, xfs_dqid_t gid,
+ 		prid_t prid, uint flags, struct xfs_dquot **udqp,
+ 		struct xfs_dquot **gdqp, struct xfs_dquot **pdqp)
++>>>>>>> 7aab1b28879d (xfs: convert kuid_t to/from uid_t for internal structures)
  {
  	*udqp = NULL;
  	*gdqp = NULL;
diff --cc fs/xfs/xfs_symlink.c
index 195a403e1522,2f2a7c005be2..000000000000
--- a/fs/xfs/xfs_symlink.c
+++ b/fs/xfs/xfs_symlink.c
@@@ -384,8 -215,11 +384,16 @@@ xfs_symlink
  	/*
  	 * Make sure that we have allocated dquot(s) on disk.
  	 */
++<<<<<<< HEAD
 +	error = xfs_qm_vop_dqalloc(dp, current_fsuid(), current_fsgid(), prid,
 +			XFS_QMOPT_QUOTALL | XFS_QMOPT_INHERIT, &udqp, &gdqp);
++=======
+ 	error = xfs_qm_vop_dqalloc(dp,
+ 			xfs_kuid_to_uid(current_fsuid()),
+ 			xfs_kgid_to_gid(current_fsgid()), prid,
+ 			XFS_QMOPT_QUOTALL | XFS_QMOPT_INHERIT,
+ 			&udqp, &gdqp, &pdqp);
++>>>>>>> 7aab1b28879d (xfs: convert kuid_t to/from uid_t for internal structures)
  	if (error)
  		goto std_return;
  
* Unmerged path fs/xfs/xfs_inode.c
* Unmerged path fs/xfs/xfs_iops.c
* Unmerged path fs/xfs/xfs_qm.c
* Unmerged path fs/xfs/xfs_quota.h
* Unmerged path fs/xfs/xfs_symlink.c
