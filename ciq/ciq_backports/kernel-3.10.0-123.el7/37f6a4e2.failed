KVM: x86: handle invalid root_hpa everywhere

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-123.el7
Rebuild_CHGLOG: - [virt] kvm: handle invalid root_hpa everywhere (Marcelo Tosatti) [1053143]
Rebuild_FUZZ: 93.98%
commit-author Marcelo Tosatti <mtosatti@redhat.com>
commit 37f6a4e237303549c8676dfe1fd1991ceab512eb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-123.el7/37f6a4e2.failed

Rom Freiman <rom@stratoscale.com> notes other code paths vulnerable to
bug fixed by 989c6b34f6a9480e397b.

	Signed-off-by: Marcelo Tosatti <mtosatti@redhat.com>
(cherry picked from commit 37f6a4e237303549c8676dfe1fd1991ceab512eb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/mmu.c
diff --cc arch/x86/kvm/mmu.c
index 52398974b4cc,e50425d0f5f7..000000000000
--- a/arch/x86/kvm/mmu.c
+++ b/arch/x86/kvm/mmu.c
@@@ -2864,7 -2832,10 +2864,14 @@@ static bool fast_page_fault(struct kvm_
  	bool ret = false;
  	u64 spte = 0ull;
  
++<<<<<<< HEAD
 +	if (!page_fault_can_be_fast(vcpu, error_code))
++=======
+ 	if (!VALID_PAGE(vcpu->arch.mmu.root_hpa))
+ 		return false;
+ 
+ 	if (!page_fault_can_be_fast(error_code))
++>>>>>>> 37f6a4e23730 (KVM: x86: handle invalid root_hpa everywhere)
  		return false;
  
  	walk_shadow_page_lockless_begin(vcpu);
* Unmerged path arch/x86/kvm/mmu.c
diff --git a/arch/x86/kvm/paging_tmpl.h b/arch/x86/kvm/paging_tmpl.h
index 7769699d48a8..6b10d66a1fba 100644
--- a/arch/x86/kvm/paging_tmpl.h
+++ b/arch/x86/kvm/paging_tmpl.h
@@ -423,6 +423,9 @@ static int FNAME(fetch)(struct kvm_vcpu *vcpu, gva_t addr,
 	if (FNAME(gpte_changed)(vcpu, gw, top_level))
 		goto out_gpte_changed;
 
+	if (!VALID_PAGE(vcpu->arch.mmu.root_hpa))
+		goto out_gpte_changed;
+
 	for (shadow_walk_init(&it, vcpu, addr);
 	     shadow_walk_okay(&it) && it.level > gw->level;
 	     shadow_walk_next(&it)) {
@@ -674,6 +677,11 @@ static void FNAME(invlpg)(struct kvm_vcpu *vcpu, gva_t gva)
 	 */
 	mmu_topup_memory_caches(vcpu);
 
+	if (!VALID_PAGE(vcpu->arch.mmu.root_hpa)) {
+		WARN_ON(1);
+		return;
+	}
+
 	spin_lock(&vcpu->kvm->mmu_lock);
 	for_each_shadow_entry(vcpu, gva, iterator) {
 		level = iterator.level;
