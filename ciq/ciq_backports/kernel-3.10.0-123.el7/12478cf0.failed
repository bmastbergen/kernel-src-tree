cpufreq: Make sure frequency transitions are serialized

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-123.el7
Rebuild_CHGLOG: - [cpufreq] make sure frequency transitions are serialized (Myron Stowe) [991615]
Rebuild_FUZZ: 91.09%
commit-author Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
commit 12478cf0c55e5969f740bb38a24b1a0104ae18d8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-123.el7/12478cf0.failed

Whenever we change the frequency of a CPU, we call the PRECHANGE and POSTCHANGE
notifiers. They must be serialized, i.e. PRECHANGE and POSTCHANGE notifiers
should strictly alternate, thereby preventing two different sets of PRECHANGE or
POSTCHANGE notifiers from interleaving arbitrarily.

The following examples illustrate why this is important:

Scenario 1:
-----------
A thread reading the value of cpuinfo_cur_freq, will call
__cpufreq_cpu_get()->cpufreq_out_of_sync()->cpufreq_notify_transition()

The ondemand governor can decide to change the frequency of the CPU at the same
time and hence it can end up sending the notifications via ->target().

If the notifiers are not serialized, the following sequence can occur:
- PRECHANGE Notification for freq A (from cpuinfo_cur_freq)
- PRECHANGE Notification for freq B (from target())
- Freq changed by target() to B
- POSTCHANGE Notification for freq B
- POSTCHANGE Notification for freq A

We can see from the above that the last POSTCHANGE Notification happens for freq
A but the hardware is set to run at freq B.

Where would we break then?: adjust_jiffies() in cpufreq.c & cpufreq_callback()
in arch/arm/kernel/smp.c (which also adjusts the jiffies). All the
loops_per_jiffy calculations will get messed up.

Scenario 2:
-----------
The governor calls __cpufreq_driver_target() to change the frequency. At the
same time, if we change scaling_{min|max}_freq from sysfs, it will end up
calling the governor's CPUFREQ_GOV_LIMITS notification, which will also call
__cpufreq_driver_target(). And hence we end up issuing concurrent calls to
->target().

Typically, platforms have the following logic in their ->target() routines:
(Eg: cpufreq-cpu0, omap, exynos, etc)

A. If new freq is more than old: Increase voltage
B. Change freq
C. If new freq is less than old: decrease voltage

Now, if the two concurrent calls to ->target() are X and Y, where X is trying to
increase the freq and Y is trying to decrease it, we get the following race
condition:

X.A: voltage gets increased for larger freq
Y.A: nothing happens
Y.B: freq gets decreased
Y.C: voltage gets decreased
X.B: freq gets increased
X.C: nothing happens

Thus we can end up setting a freq which is not supported by the voltage we have
set. That will probably make the clock to the CPU unstable and the system might
not work properly anymore.

This patch introduces a set of synchronization primitives to serialize frequency
transitions, which are to be used as shown below:

cpufreq_freq_transition_begin();

//Perform the frequency change

cpufreq_freq_transition_end();

The _begin() call sends the PRECHANGE notification whereas the _end() call sends
the POSTCHANGE notification. Also, all the necessary synchronization is handled
within these calls. In particular, even drivers which set the ASYNC_NOTIFICATION
flag can also use these APIs for performing frequency transitions (ie., you can
call _begin() from one task, and call the corresponding _end() from a different
task).

The actual synchronization underneath is not that complicated:

The key challenge is to allow drivers to begin the transition from one thread
and end it in a completely different thread (this is to enable drivers that do
asynchronous POSTCHANGE notification from bottom-halves, to also use the same
interface).

To achieve this, a 'transition_ongoing' flag, a 'transition_lock' spinlock and a
wait-queue are added per-policy. The flag and the wait-queue are used in
conjunction to create an "uninterrupted flow" from _begin() to _end(). The
spinlock is used to ensure that only one such "flow" is in flight at any given
time. Put together, this provides us all the necessary synchronization.

	Signed-off-by: Srivatsa S. Bhat <srivatsa.bhat@linux.vnet.ibm.com>
	Signed-off-by: Viresh Kumar <viresh.kumar@linaro.org>
	Signed-off-by: Rafael J. Wysocki <rafael.j.wysocki@intel.com>
(cherry picked from commit 12478cf0c55e5969f740bb38a24b1a0104ae18d8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/cpufreq/cpufreq.c
#	include/linux/cpufreq.h
diff --cc drivers/cpufreq/cpufreq.c
index 43cf60832468,d57806a85def..000000000000
--- a/drivers/cpufreq/cpufreq.c
+++ b/drivers/cpufreq/cpufreq.c
@@@ -359,7 -339,55 +359,42 @@@ void cpufreq_notify_transition(struct c
  }
  EXPORT_SYMBOL_GPL(cpufreq_notify_transition);
  
 -/* Do post notifications when there are chances that transition has failed */
 -void cpufreq_notify_post_transition(struct cpufreq_policy *policy,
 -		struct cpufreq_freqs *freqs, int transition_failed)
 -{
 -	cpufreq_notify_transition(policy, freqs, CPUFREQ_POSTCHANGE);
 -	if (!transition_failed)
 -		return;
 -
 -	swap(freqs->old, freqs->new);
 -	cpufreq_notify_transition(policy, freqs, CPUFREQ_PRECHANGE);
 -	cpufreq_notify_transition(policy, freqs, CPUFREQ_POSTCHANGE);
 -}
 -EXPORT_SYMBOL_GPL(cpufreq_notify_post_transition);
  
+ void cpufreq_freq_transition_begin(struct cpufreq_policy *policy,
+ 		struct cpufreq_freqs *freqs)
+ {
+ wait:
+ 	wait_event(policy->transition_wait, !policy->transition_ongoing);
+ 
+ 	spin_lock(&policy->transition_lock);
+ 
+ 	if (unlikely(policy->transition_ongoing)) {
+ 		spin_unlock(&policy->transition_lock);
+ 		goto wait;
+ 	}
+ 
+ 	policy->transition_ongoing = true;
+ 
+ 	spin_unlock(&policy->transition_lock);
+ 
+ 	cpufreq_notify_transition(policy, freqs, CPUFREQ_PRECHANGE);
+ }
+ EXPORT_SYMBOL_GPL(cpufreq_freq_transition_begin);
+ 
+ void cpufreq_freq_transition_end(struct cpufreq_policy *policy,
+ 		struct cpufreq_freqs *freqs, int transition_failed)
+ {
+ 	if (unlikely(WARN_ON(!policy->transition_ongoing)))
+ 		return;
+ 
+ 	cpufreq_notify_post_transition(policy, freqs, transition_failed);
+ 
+ 	policy->transition_ongoing = false;
+ 
+ 	wake_up(&policy->transition_wait);
+ }
+ EXPORT_SYMBOL_GPL(cpufreq_freq_transition_end);
+ 
  
  /*********************************************************************
   *                          SYSFS INTERFACE                          *
@@@ -932,16 -988,99 +967,112 @@@ static int cpufreq_add_policy_cpu(unsig
  }
  #endif
  
++<<<<<<< HEAD
 +/**
 + * cpufreq_add_dev - add a CPU device
 + *
 + * Adds the cpufreq interface for a CPU device.
 + *
 + * The Oracle says: try running cpufreq registration/unregistration concurrently
 + * with with cpu hotplugging and all hell will break loose. Tried to clean this
 + * mess up, but more thorough testing is needed. - Mathieu
 + */
 +static int cpufreq_add_dev(struct device *dev, struct subsys_interface *sif)
++=======
+ static struct cpufreq_policy *cpufreq_policy_restore(unsigned int cpu)
+ {
+ 	struct cpufreq_policy *policy;
+ 	unsigned long flags;
+ 
+ 	read_lock_irqsave(&cpufreq_driver_lock, flags);
+ 
+ 	policy = per_cpu(cpufreq_cpu_data_fallback, cpu);
+ 
+ 	read_unlock_irqrestore(&cpufreq_driver_lock, flags);
+ 
+ 	policy->governor = NULL;
+ 
+ 	return policy;
+ }
+ 
+ static struct cpufreq_policy *cpufreq_policy_alloc(void)
+ {
+ 	struct cpufreq_policy *policy;
+ 
+ 	policy = kzalloc(sizeof(*policy), GFP_KERNEL);
+ 	if (!policy)
+ 		return NULL;
+ 
+ 	if (!alloc_cpumask_var(&policy->cpus, GFP_KERNEL))
+ 		goto err_free_policy;
+ 
+ 	if (!zalloc_cpumask_var(&policy->related_cpus, GFP_KERNEL))
+ 		goto err_free_cpumask;
+ 
+ 	INIT_LIST_HEAD(&policy->policy_list);
+ 	init_rwsem(&policy->rwsem);
+ 	spin_lock_init(&policy->transition_lock);
+ 	init_waitqueue_head(&policy->transition_wait);
+ 
+ 	return policy;
+ 
+ err_free_cpumask:
+ 	free_cpumask_var(policy->cpus);
+ err_free_policy:
+ 	kfree(policy);
+ 
+ 	return NULL;
+ }
+ 
+ static void cpufreq_policy_put_kobj(struct cpufreq_policy *policy)
+ {
+ 	struct kobject *kobj;
+ 	struct completion *cmp;
+ 
+ 	blocking_notifier_call_chain(&cpufreq_policy_notifier_list,
+ 			CPUFREQ_REMOVE_POLICY, policy);
+ 
+ 	down_read(&policy->rwsem);
+ 	kobj = &policy->kobj;
+ 	cmp = &policy->kobj_unregister;
+ 	up_read(&policy->rwsem);
+ 	kobject_put(kobj);
+ 
+ 	/*
+ 	 * We need to make sure that the underlying kobj is
+ 	 * actually not referenced anymore by anybody before we
+ 	 * proceed with unloading.
+ 	 */
+ 	pr_debug("waiting for dropping of refcount\n");
+ 	wait_for_completion(cmp);
+ 	pr_debug("wait complete\n");
+ }
+ 
+ static void cpufreq_policy_free(struct cpufreq_policy *policy)
+ {
+ 	free_cpumask_var(policy->related_cpus);
+ 	free_cpumask_var(policy->cpus);
+ 	kfree(policy);
+ }
+ 
+ static void update_policy_cpu(struct cpufreq_policy *policy, unsigned int cpu)
+ {
+ 	if (WARN_ON(cpu == policy->cpu))
+ 		return;
+ 
+ 	down_write(&policy->rwsem);
+ 
+ 	policy->last_cpu = policy->cpu;
+ 	policy->cpu = cpu;
+ 
+ 	up_write(&policy->rwsem);
+ 
+ 	blocking_notifier_call_chain(&cpufreq_policy_notifier_list,
+ 			CPUFREQ_UPDATE_POLICY_CPU, policy);
+ }
+ 
+ static int __cpufreq_add_dev(struct device *dev, struct subsys_interface *sif)
++>>>>>>> 12478cf0c55e (cpufreq: Make sure frequency transitions are serialized)
  {
  	unsigned int j, cpu = dev->id;
  	int ret = -ENOMEM;
diff --cc include/linux/cpufreq.h
index 125719d41285,e33760268a86..000000000000
--- a/include/linux/cpufreq.h
+++ b/include/linux/cpufreq.h
@@@ -11,58 -11,20 +11,62 @@@
  #ifndef _LINUX_CPUFREQ_H
  #define _LINUX_CPUFREQ_H
  
 -#include <linux/clk.h>
 -#include <linux/cpumask.h>
 -#include <linux/completion.h>
 -#include <linux/kobject.h>
 +#include <asm/cputime.h>
 +#include <linux/mutex.h>
  #include <linux/notifier.h>
++<<<<<<< HEAD
 +#include <linux/threads.h>
 +#include <linux/kobject.h>
++=======
+ #include <linux/spinlock.h>
++>>>>>>> 12478cf0c55e (cpufreq: Make sure frequency transitions are serialized)
  #include <linux/sysfs.h>
 +#include <linux/completion.h>
 +#include <linux/workqueue.h>
 +#include <linux/cpumask.h>
 +#include <asm/div64.h>
 +
 +#define CPUFREQ_NAME_LEN 16
 +/* Print length for names. Extra 1 space for accomodating '\n' in prints */
 +#define CPUFREQ_NAME_PLEN (CPUFREQ_NAME_LEN + 1)
 +
  
  /*********************************************************************
 - *                        CPUFREQ INTERFACE                          *
 + *                     CPUFREQ NOTIFIER INTERFACE                    *
   *********************************************************************/
 -/*
 - * Frequency values here are CPU kHz
 - *
 +
 +#define CPUFREQ_TRANSITION_NOTIFIER	(0)
 +#define CPUFREQ_POLICY_NOTIFIER		(1)
 +
 +#ifdef CONFIG_CPU_FREQ
 +int cpufreq_register_notifier(struct notifier_block *nb, unsigned int list);
 +int cpufreq_unregister_notifier(struct notifier_block *nb, unsigned int list);
 +extern void disable_cpufreq(void);
 +#else		/* CONFIG_CPU_FREQ */
 +static inline int cpufreq_register_notifier(struct notifier_block *nb,
 +						unsigned int list)
 +{
 +	return 0;
 +}
 +static inline int cpufreq_unregister_notifier(struct notifier_block *nb,
 +						unsigned int list)
 +{
 +	return 0;
 +}
 +static inline void disable_cpufreq(void) { }
 +#endif		/* CONFIG_CPU_FREQ */
 +
 +/* if (cpufreq_driver->target) exists, the ->governor decides what frequency
 + * within the limits is used. If (cpufreq_driver->setpolicy> exists, these
 + * two generic policies are available:
 + */
 +
 +#define CPUFREQ_POLICY_POWERSAVE	(1)
 +#define CPUFREQ_POLICY_PERFORMANCE	(2)
 +
 +/* Frequency values here are CPU kHz so that hardware which doesn't run
 + * with some frequencies can complain without having to guess what per
 + * cent / per mille means.
   * Maximum transition latency is in nanoseconds - if it's unknown,
   * CPUFREQ_ETERNAL shall be used.
   */
@@@ -117,17 -86,32 +121,39 @@@ struct cpufreq_policy 
  					 * called, but you're in IRQ context */
  
  	struct cpufreq_real_policy	user_policy;
 -	struct cpufreq_frequency_table	*freq_table;
  
 -	struct list_head        policy_list;
  	struct kobject		kobj;
  	struct completion	kobj_unregister;
++<<<<<<< HEAD
++=======
+ 
+ 	/*
+ 	 * The rules for this semaphore:
+ 	 * - Any routine that wants to read from the policy structure will
+ 	 *   do a down_read on this semaphore.
+ 	 * - Any routine that will write to the policy structure and/or may take away
+ 	 *   the policy altogether (eg. CPU hotplug), will hold this lock in write
+ 	 *   mode before doing so.
+ 	 *
+ 	 * Additional rules:
+ 	 * - Lock should not be held across
+ 	 *     __cpufreq_governor(data, CPUFREQ_GOV_POLICY_EXIT);
+ 	 */
+ 	struct rw_semaphore	rwsem;
+ 
+ 	/* Synchronization for frequency transitions */
+ 	bool			transition_ongoing; /* Tracks transition status */
+ 	spinlock_t		transition_lock;
+ 	wait_queue_head_t	transition_wait;
++>>>>>>> 12478cf0c55e (cpufreq: Make sure frequency transitions are serialized)
  };
  
 +#define CPUFREQ_ADJUST			(0)
 +#define CPUFREQ_INCOMPATIBLE		(1)
 +#define CPUFREQ_NOTIFY			(2)
 +#define CPUFREQ_START			(3)
 +#define CPUFREQ_UPDATE_POLICY_CPU	(4)
 +
  /* Only for ACPI */
  #define CPUFREQ_SHARED_TYPE_NONE (0) /* None */
  #define CPUFREQ_SHARED_TYPE_HW	 (1) /* HW does needed coordination */
@@@ -301,69 -299,58 +327,87 @@@ static inline void cpufreq_verify_withi
  	return;
  }
  
 -static inline void
 -cpufreq_verify_within_cpu_limits(struct cpufreq_policy *policy)
 -{
 -	cpufreq_verify_within_limits(policy, policy->cpuinfo.min_freq,
 -			policy->cpuinfo.max_freq);
 -}
 +struct freq_attr {
 +	struct attribute attr;
 +	ssize_t (*show)(struct cpufreq_policy *, char *);
 +	ssize_t (*store)(struct cpufreq_policy *, const char *, size_t count);
 +};
  
 -#ifdef CONFIG_CPU_FREQ
 -void cpufreq_suspend(void);
 -void cpufreq_resume(void);
 -int cpufreq_generic_suspend(struct cpufreq_policy *policy);
 -#else
 -static inline void cpufreq_suspend(void) {}
 -static inline void cpufreq_resume(void) {}
 -#endif
 +#define cpufreq_freq_attr_ro(_name)		\
 +static struct freq_attr _name =			\
 +__ATTR(_name, 0444, show_##_name, NULL)
  
 -/*********************************************************************
 - *                     CPUFREQ NOTIFIER INTERFACE                    *
 - *********************************************************************/
 +#define cpufreq_freq_attr_ro_perm(_name, _perm)	\
 +static struct freq_attr _name =			\
 +__ATTR(_name, _perm, show_##_name, NULL)
  
 -#define CPUFREQ_TRANSITION_NOTIFIER	(0)
 -#define CPUFREQ_POLICY_NOTIFIER		(1)
 +#define cpufreq_freq_attr_rw(_name)		\
 +static struct freq_attr _name =			\
 +__ATTR(_name, 0644, show_##_name, store_##_name)
  
 -/* Transition notifiers */
 -#define CPUFREQ_PRECHANGE		(0)
 -#define CPUFREQ_POSTCHANGE		(1)
 +struct global_attr {
 +	struct attribute attr;
 +	ssize_t (*show)(struct kobject *kobj,
 +			struct attribute *attr, char *buf);
 +	ssize_t (*store)(struct kobject *a, struct attribute *b,
 +			 const char *c, size_t count);
 +};
  
 -/* Policy Notifiers  */
 -#define CPUFREQ_ADJUST			(0)
 -#define CPUFREQ_INCOMPATIBLE		(1)
 -#define CPUFREQ_NOTIFY			(2)
 -#define CPUFREQ_START			(3)
 -#define CPUFREQ_UPDATE_POLICY_CPU	(4)
 -#define CPUFREQ_CREATE_POLICY		(5)
 -#define CPUFREQ_REMOVE_POLICY		(6)
 +#define define_one_global_ro(_name)		\
 +static struct global_attr _name =		\
 +__ATTR(_name, 0444, show_##_name, NULL)
 +
 +#define define_one_global_rw(_name)		\
 +static struct global_attr _name =		\
 +__ATTR(_name, 0644, show_##_name, store_##_name)
 +
 +struct cpufreq_policy *cpufreq_cpu_get(unsigned int cpu);
 +void cpufreq_cpu_put(struct cpufreq_policy *data);
 +const char *cpufreq_get_current_driver(void);
 +
 +/*********************************************************************
 + *                        CPUFREQ 2.6. INTERFACE                     *
 + *********************************************************************/
 +u64 get_cpu_idle_time(unsigned int cpu, u64 *wall, int io_busy);
 +int cpufreq_get_policy(struct cpufreq_policy *policy, unsigned int cpu);
 +int cpufreq_update_policy(unsigned int cpu);
 +bool have_governor_per_policy(void);
 +struct kobject *get_governor_parent_kobj(struct cpufreq_policy *policy);
 +
 +#ifdef CONFIG_CPU_FREQ
 +/* query the current CPU frequency (in kHz). If zero, cpufreq couldn't detect it */
 +unsigned int cpufreq_get(unsigned int cpu);
 +#else
 +static inline unsigned int cpufreq_get(unsigned int cpu)
 +{
 +	return 0;
 +}
 +#endif
  
 +/* query the last known CPU freq (in kHz). If zero, cpufreq couldn't detect it */
  #ifdef CONFIG_CPU_FREQ
++<<<<<<< HEAD
 +unsigned int cpufreq_quick_get(unsigned int cpu);
 +unsigned int cpufreq_quick_get_max(unsigned int cpu);
 +#else
 +static inline unsigned int cpufreq_quick_get(unsigned int cpu)
++=======
+ int cpufreq_register_notifier(struct notifier_block *nb, unsigned int list);
+ int cpufreq_unregister_notifier(struct notifier_block *nb, unsigned int list);
+ 
+ void cpufreq_notify_transition(struct cpufreq_policy *policy,
+ 		struct cpufreq_freqs *freqs, unsigned int state);
+ void cpufreq_notify_post_transition(struct cpufreq_policy *policy,
+ 		struct cpufreq_freqs *freqs, int transition_failed);
+ void cpufreq_freq_transition_begin(struct cpufreq_policy *policy,
+ 		struct cpufreq_freqs *freqs);
+ void cpufreq_freq_transition_end(struct cpufreq_policy *policy,
+ 		struct cpufreq_freqs *freqs, int transition_failed);
+ 
+ #else /* CONFIG_CPU_FREQ */
+ static inline int cpufreq_register_notifier(struct notifier_block *nb,
+ 						unsigned int list)
++>>>>>>> 12478cf0c55e (cpufreq: Make sure frequency transitions are serialized)
  {
  	return 0;
  }
* Unmerged path drivers/cpufreq/cpufreq.c
* Unmerged path include/linux/cpufreq.h
