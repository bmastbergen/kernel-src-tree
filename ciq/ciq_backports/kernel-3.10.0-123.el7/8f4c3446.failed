lockref: use cmpxchg64 explicitly for lockless updates

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-123.el7
commit-author Will Deacon <will.deacon@arm.com>
commit 8f4c344696b9f9f8471d7f342076ef10ed7f66a5
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-123.el7/8f4c3446.failed

The cmpxchg() function tends not to support 64-bit arguments on 32-bit
architectures.  This could be either due to use of unsigned long
arguments (like on ARM) or lack of instruction support (cmpxchgq on
x86).  However, these architectures may implement a specific cmpxchg64()
function to provide 64-bit cmpxchg support instead.

Since the lockref code requires a 64-bit cmpxchg and relies on the
architecture selecting ARCH_USE_CMPXCHG_LOCKREF, move to using cmpxchg64
instead of cmpxchg and allow 32-bit architectures to make use of the
lockless lockref implementation.

	Cc: Waiman Long <Waiman.Long@hp.com>
	Signed-off-by: Will Deacon <will.deacon@arm.com>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 8f4c344696b9f9f8471d7f342076ef10ed7f66a5)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	lib/lockref.c
diff --cc lib/lockref.c
index 01ba8088f424,677d036cf3c7..000000000000
--- a/lib/lockref.c
+++ b/lib/lockref.c
@@@ -1,6 -1,34 +1,37 @@@
  #include <linux/export.h>
  #include <linux/lockref.h>
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_CMPXCHG_LOCKREF
+ 
+ /*
+  * Note that the "cmpxchg()" reloads the "old" value for the
+  * failure case.
+  */
+ #define CMPXCHG_LOOP(CODE, SUCCESS) do {					\
+ 	struct lockref old;							\
+ 	BUILD_BUG_ON(sizeof(old) != 8);						\
+ 	old.lock_count = ACCESS_ONCE(lockref->lock_count);			\
+ 	while (likely(arch_spin_value_unlocked(old.lock.rlock.raw_lock))) {  	\
+ 		struct lockref new = old, prev = old;				\
+ 		CODE								\
+ 		old.lock_count = cmpxchg64(&lockref->lock_count,		\
+ 					   old.lock_count, new.lock_count);	\
+ 		if (likely(old.lock_count == prev.lock_count)) {		\
+ 			SUCCESS;						\
+ 		}								\
+ 		cpu_relax();							\
+ 	}									\
+ } while (0)
+ 
+ #else
+ 
+ #define CMPXCHG_LOOP(CODE, SUCCESS) do { } while (0)
+ 
+ #endif
+ 
++>>>>>>> 8f4c344696b9 (lockref: use cmpxchg64 explicitly for lockless updates)
  /**
   * lockref_get - Increments reference count unconditionally
   * @lockref: pointer to lockref structure
* Unmerged path lib/lockref.c
