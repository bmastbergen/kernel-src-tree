kernel: provide a __smp_call_function_single stub for !CONFIG_SMP

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-123.el7
Rebuild_CHGLOG: - [kernel] provide a __smp_call_function_single stub for !CONFIG_SMP (Mike Snitzer) [1071014]
Rebuild_FUZZ: 93.44%
commit-author Christoph Hellwig <hch@infradead.org>
commit 40c01e8bd5575e32633192513e09eac7155d6926
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-123.el7/40c01e8b.failed

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Cc: Jan Kara <jack@suse.cz>
	Cc: Jens Axboe <axboe@kernel.dk>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 40c01e8bd5575e32633192513e09eac7155d6926)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/up.c
diff --cc kernel/up.c
index c54c75e9faf7,509403e3fbc6..000000000000
--- a/kernel/up.c
+++ b/kernel/up.c
@@@ -19,3 -21,64 +19,67 @@@ int smp_call_function_single(int cpu, v
  	return 0;
  }
  EXPORT_SYMBOL(smp_call_function_single);
++<<<<<<< HEAD
++=======
+ 
+ void __smp_call_function_single(int cpu, struct call_single_data *csd,
+ 				int wait)
+ {
+ 	unsigned long flags;
+ 
+ 	local_irq_save(flags);
+ 	csd->func(csd->info);
+ 	local_irq_restore(flags);
+ }
+ EXPORT_SYMBOL(__smp_call_function_single);
+ 
+ int on_each_cpu(smp_call_func_t func, void *info, int wait)
+ {
+ 	unsigned long flags;
+ 
+ 	local_irq_save(flags);
+ 	func(info);
+ 	local_irq_restore(flags);
+ 	return 0;
+ }
+ EXPORT_SYMBOL(on_each_cpu);
+ 
+ /*
+  * Note we still need to test the mask even for UP
+  * because we actually can get an empty mask from
+  * code that on SMP might call us without the local
+  * CPU in the mask.
+  */
+ void on_each_cpu_mask(const struct cpumask *mask,
+ 		      smp_call_func_t func, void *info, bool wait)
+ {
+ 	unsigned long flags;
+ 
+ 	if (cpumask_test_cpu(0, mask)) {
+ 		local_irq_save(flags);
+ 		func(info);
+ 		local_irq_restore(flags);
+ 	}
+ }
+ EXPORT_SYMBOL(on_each_cpu_mask);
+ 
+ /*
+  * Preemption is disabled here to make sure the cond_func is called under the
+  * same condtions in UP and SMP.
+  */
+ void on_each_cpu_cond(bool (*cond_func)(int cpu, void *info),
+ 		      smp_call_func_t func, void *info, bool wait,
+ 		      gfp_t gfp_flags)
+ {
+ 	unsigned long flags;
+ 
+ 	preempt_disable();
+ 	if (cond_func(0, info)) {
+ 		local_irq_save(flags);
+ 		func(info);
+ 		local_irq_restore(flags);
+ 	}
+ 	preempt_enable();
+ }
+ EXPORT_SYMBOL(on_each_cpu_cond);
++>>>>>>> 40c01e8bd557 (kernel: provide a __smp_call_function_single stub for !CONFIG_SMP)
* Unmerged path kernel/up.c
