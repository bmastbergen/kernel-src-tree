xfs: refactor xfs_trans_reserve() interface

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-123.el7
commit-author Jie Liu <jeff.liu@oracle.com>
commit 3d3c8b5222b92447bffaa4127ee18c757f32a460
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-123.el7/3d3c8b52.failed

With the new xfs_trans_res structure has been introduced, the log
reservation size, log count as well as log flags are pre-initialized
at mount time.  So it's time to refine xfs_trans_reserve() interface
to be more neat.

Also, introduce a new helper M_RES() to return a pointer to the
mp->m_resv structure to simplify the input.

	Signed-off-by: Jie Liu <jeff.liu@oracle.com>
	Signed-off-by: Dave Chinner <dchinner@redhat.com>
	Reviewed-by: Mark Tinguely <tinguely@sgi.com>
	Signed-off-by: Ben Myers <bpm@sgi.com>

(cherry picked from commit 3d3c8b5222b92447bffaa4127ee18c757f32a460)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/xfs/xfs_bmap_util.c
#	fs/xfs/xfs_inode.c
#	fs/xfs/xfs_ioctl.c
diff --cc fs/xfs/xfs_bmap_util.c
index 8e48ddf1c11c,cc2ab9b776b7..000000000000
--- a/fs/xfs/xfs_bmap_util.c
+++ b/fs/xfs/xfs_bmap_util.c
@@@ -832,3 -835,1192 +833,1195 @@@ next_block
  
  	return error;
  }
++<<<<<<< HEAD
++=======
+ 
+ /*
+  * Test whether it is appropriate to check an inode for and free post EOF
+  * blocks. The 'force' parameter determines whether we should also consider
+  * regular files that are marked preallocated or append-only.
+  */
+ bool
+ xfs_can_free_eofblocks(struct xfs_inode *ip, bool force)
+ {
+ 	/* prealloc/delalloc exists only on regular files */
+ 	if (!S_ISREG(ip->i_d.di_mode))
+ 		return false;
+ 
+ 	/*
+ 	 * Zero sized files with no cached pages and delalloc blocks will not
+ 	 * have speculative prealloc/delalloc blocks to remove.
+ 	 */
+ 	if (VFS_I(ip)->i_size == 0 &&
+ 	    VN_CACHED(VFS_I(ip)) == 0 &&
+ 	    ip->i_delayed_blks == 0)
+ 		return false;
+ 
+ 	/* If we haven't read in the extent list, then don't do it now. */
+ 	if (!(ip->i_df.if_flags & XFS_IFEXTENTS))
+ 		return false;
+ 
+ 	/*
+ 	 * Do not free real preallocated or append-only files unless the file
+ 	 * has delalloc blocks and we are forced to remove them.
+ 	 */
+ 	if (ip->i_d.di_flags & (XFS_DIFLAG_PREALLOC | XFS_DIFLAG_APPEND))
+ 		if (!force || ip->i_delayed_blks == 0)
+ 			return false;
+ 
+ 	return true;
+ }
+ 
+ /*
+  * This is called by xfs_inactive to free any blocks beyond eof
+  * when the link count isn't zero and by xfs_dm_punch_hole() when
+  * punching a hole to EOF.
+  */
+ int
+ xfs_free_eofblocks(
+ 	xfs_mount_t	*mp,
+ 	xfs_inode_t	*ip,
+ 	bool		need_iolock)
+ {
+ 	xfs_trans_t	*tp;
+ 	int		error;
+ 	xfs_fileoff_t	end_fsb;
+ 	xfs_fileoff_t	last_fsb;
+ 	xfs_filblks_t	map_len;
+ 	int		nimaps;
+ 	xfs_bmbt_irec_t	imap;
+ 
+ 	/*
+ 	 * Figure out if there are any blocks beyond the end
+ 	 * of the file.  If not, then there is nothing to do.
+ 	 */
+ 	end_fsb = XFS_B_TO_FSB(mp, (xfs_ufsize_t)XFS_ISIZE(ip));
+ 	last_fsb = XFS_B_TO_FSB(mp, mp->m_super->s_maxbytes);
+ 	if (last_fsb <= end_fsb)
+ 		return 0;
+ 	map_len = last_fsb - end_fsb;
+ 
+ 	nimaps = 1;
+ 	xfs_ilock(ip, XFS_ILOCK_SHARED);
+ 	error = xfs_bmapi_read(ip, end_fsb, map_len, &imap, &nimaps, 0);
+ 	xfs_iunlock(ip, XFS_ILOCK_SHARED);
+ 
+ 	if (!error && (nimaps != 0) &&
+ 	    (imap.br_startblock != HOLESTARTBLOCK ||
+ 	     ip->i_delayed_blks)) {
+ 		/*
+ 		 * Attach the dquots to the inode up front.
+ 		 */
+ 		error = xfs_qm_dqattach(ip, 0);
+ 		if (error)
+ 			return error;
+ 
+ 		/*
+ 		 * There are blocks after the end of file.
+ 		 * Free them up now by truncating the file to
+ 		 * its current size.
+ 		 */
+ 		tp = xfs_trans_alloc(mp, XFS_TRANS_INACTIVE);
+ 
+ 		if (need_iolock) {
+ 			if (!xfs_ilock_nowait(ip, XFS_IOLOCK_EXCL)) {
+ 				xfs_trans_cancel(tp, 0);
+ 				return EAGAIN;
+ 			}
+ 		}
+ 
+ 		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_itruncate, 0, 0);
+ 		if (error) {
+ 			ASSERT(XFS_FORCED_SHUTDOWN(mp));
+ 			xfs_trans_cancel(tp, 0);
+ 			if (need_iolock)
+ 				xfs_iunlock(ip, XFS_IOLOCK_EXCL);
+ 			return error;
+ 		}
+ 
+ 		xfs_ilock(ip, XFS_ILOCK_EXCL);
+ 		xfs_trans_ijoin(tp, ip, 0);
+ 
+ 		/*
+ 		 * Do not update the on-disk file size.  If we update the
+ 		 * on-disk file size and then the system crashes before the
+ 		 * contents of the file are flushed to disk then the files
+ 		 * may be full of holes (ie NULL files bug).
+ 		 */
+ 		error = xfs_itruncate_extents(&tp, ip, XFS_DATA_FORK,
+ 					      XFS_ISIZE(ip));
+ 		if (error) {
+ 			/*
+ 			 * If we get an error at this point we simply don't
+ 			 * bother truncating the file.
+ 			 */
+ 			xfs_trans_cancel(tp,
+ 					 (XFS_TRANS_RELEASE_LOG_RES |
+ 					  XFS_TRANS_ABORT));
+ 		} else {
+ 			error = xfs_trans_commit(tp,
+ 						XFS_TRANS_RELEASE_LOG_RES);
+ 			if (!error)
+ 				xfs_inode_clear_eofblocks_tag(ip);
+ 		}
+ 
+ 		xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 		if (need_iolock)
+ 			xfs_iunlock(ip, XFS_IOLOCK_EXCL);
+ 	}
+ 	return error;
+ }
+ 
+ /*
+  * xfs_alloc_file_space()
+  *      This routine allocates disk space for the given file.
+  *
+  *	If alloc_type == 0, this request is for an ALLOCSP type
+  *	request which will change the file size.  In this case, no
+  *	DMAPI event will be generated by the call.  A TRUNCATE event
+  *	will be generated later by xfs_setattr.
+  *
+  *	If alloc_type != 0, this request is for a RESVSP type
+  *	request, and a DMAPI DM_EVENT_WRITE will be generated if the
+  *	lower block boundary byte address is less than the file's
+  *	length.
+  *
+  * RETURNS:
+  *       0 on success
+  *      errno on error
+  *
+  */
+ STATIC int
+ xfs_alloc_file_space(
+ 	xfs_inode_t		*ip,
+ 	xfs_off_t		offset,
+ 	xfs_off_t		len,
+ 	int			alloc_type,
+ 	int			attr_flags)
+ {
+ 	xfs_mount_t		*mp = ip->i_mount;
+ 	xfs_off_t		count;
+ 	xfs_filblks_t		allocated_fsb;
+ 	xfs_filblks_t		allocatesize_fsb;
+ 	xfs_extlen_t		extsz, temp;
+ 	xfs_fileoff_t		startoffset_fsb;
+ 	xfs_fsblock_t		firstfsb;
+ 	int			nimaps;
+ 	int			quota_flag;
+ 	int			rt;
+ 	xfs_trans_t		*tp;
+ 	xfs_bmbt_irec_t		imaps[1], *imapp;
+ 	xfs_bmap_free_t		free_list;
+ 	uint			qblocks, resblks, resrtextents;
+ 	int			committed;
+ 	int			error;
+ 
+ 	trace_xfs_alloc_file_space(ip);
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		return XFS_ERROR(EIO);
+ 
+ 	error = xfs_qm_dqattach(ip, 0);
+ 	if (error)
+ 		return error;
+ 
+ 	if (len <= 0)
+ 		return XFS_ERROR(EINVAL);
+ 
+ 	rt = XFS_IS_REALTIME_INODE(ip);
+ 	extsz = xfs_get_extsz_hint(ip);
+ 
+ 	count = len;
+ 	imapp = &imaps[0];
+ 	nimaps = 1;
+ 	startoffset_fsb	= XFS_B_TO_FSBT(mp, offset);
+ 	allocatesize_fsb = XFS_B_TO_FSB(mp, count);
+ 
+ 	/*
+ 	 * Allocate file space until done or until there is an error
+ 	 */
+ 	while (allocatesize_fsb && !error) {
+ 		xfs_fileoff_t	s, e;
+ 
+ 		/*
+ 		 * Determine space reservations for data/realtime.
+ 		 */
+ 		if (unlikely(extsz)) {
+ 			s = startoffset_fsb;
+ 			do_div(s, extsz);
+ 			s *= extsz;
+ 			e = startoffset_fsb + allocatesize_fsb;
+ 			if ((temp = do_mod(startoffset_fsb, extsz)))
+ 				e += temp;
+ 			if ((temp = do_mod(e, extsz)))
+ 				e += extsz - temp;
+ 		} else {
+ 			s = 0;
+ 			e = allocatesize_fsb;
+ 		}
+ 
+ 		/*
+ 		 * The transaction reservation is limited to a 32-bit block
+ 		 * count, hence we need to limit the number of blocks we are
+ 		 * trying to reserve to avoid an overflow. We can't allocate
+ 		 * more than @nimaps extents, and an extent is limited on disk
+ 		 * to MAXEXTLEN (21 bits), so use that to enforce the limit.
+ 		 */
+ 		resblks = min_t(xfs_fileoff_t, (e - s), (MAXEXTLEN * nimaps));
+ 		if (unlikely(rt)) {
+ 			resrtextents = qblocks = resblks;
+ 			resrtextents /= mp->m_sb.sb_rextsize;
+ 			resblks = XFS_DIOSTRAT_SPACE_RES(mp, 0);
+ 			quota_flag = XFS_QMOPT_RES_RTBLKS;
+ 		} else {
+ 			resrtextents = 0;
+ 			resblks = qblocks = XFS_DIOSTRAT_SPACE_RES(mp, resblks);
+ 			quota_flag = XFS_QMOPT_RES_REGBLKS;
+ 		}
+ 
+ 		/*
+ 		 * Allocate and setup the transaction.
+ 		 */
+ 		tp = xfs_trans_alloc(mp, XFS_TRANS_DIOSTRAT);
+ 		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_write,
+ 					  resblks, resrtextents);
+ 		/*
+ 		 * Check for running out of space
+ 		 */
+ 		if (error) {
+ 			/*
+ 			 * Free the transaction structure.
+ 			 */
+ 			ASSERT(error == ENOSPC || XFS_FORCED_SHUTDOWN(mp));
+ 			xfs_trans_cancel(tp, 0);
+ 			break;
+ 		}
+ 		xfs_ilock(ip, XFS_ILOCK_EXCL);
+ 		error = xfs_trans_reserve_quota_nblks(tp, ip, qblocks,
+ 						      0, quota_flag);
+ 		if (error)
+ 			goto error1;
+ 
+ 		xfs_trans_ijoin(tp, ip, 0);
+ 
+ 		xfs_bmap_init(&free_list, &firstfsb);
+ 		error = xfs_bmapi_write(tp, ip, startoffset_fsb,
+ 					allocatesize_fsb, alloc_type, &firstfsb,
+ 					0, imapp, &nimaps, &free_list);
+ 		if (error) {
+ 			goto error0;
+ 		}
+ 
+ 		/*
+ 		 * Complete the transaction
+ 		 */
+ 		error = xfs_bmap_finish(&tp, &free_list, &committed);
+ 		if (error) {
+ 			goto error0;
+ 		}
+ 
+ 		error = xfs_trans_commit(tp, XFS_TRANS_RELEASE_LOG_RES);
+ 		xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 		if (error) {
+ 			break;
+ 		}
+ 
+ 		allocated_fsb = imapp->br_blockcount;
+ 
+ 		if (nimaps == 0) {
+ 			error = XFS_ERROR(ENOSPC);
+ 			break;
+ 		}
+ 
+ 		startoffset_fsb += allocated_fsb;
+ 		allocatesize_fsb -= allocated_fsb;
+ 	}
+ 
+ 	return error;
+ 
+ error0:	/* Cancel bmap, unlock inode, unreserve quota blocks, cancel trans */
+ 	xfs_bmap_cancel(&free_list);
+ 	xfs_trans_unreserve_quota_nblks(tp, ip, (long)qblocks, 0, quota_flag);
+ 
+ error1:	/* Just cancel transaction */
+ 	xfs_trans_cancel(tp, XFS_TRANS_RELEASE_LOG_RES | XFS_TRANS_ABORT);
+ 	xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 	return error;
+ }
+ 
+ /*
+  * Zero file bytes between startoff and endoff inclusive.
+  * The iolock is held exclusive and no blocks are buffered.
+  *
+  * This function is used by xfs_free_file_space() to zero
+  * partial blocks when the range to free is not block aligned.
+  * When unreserving space with boundaries that are not block
+  * aligned we round up the start and round down the end
+  * boundaries and then use this function to zero the parts of
+  * the blocks that got dropped during the rounding.
+  */
+ STATIC int
+ xfs_zero_remaining_bytes(
+ 	xfs_inode_t		*ip,
+ 	xfs_off_t		startoff,
+ 	xfs_off_t		endoff)
+ {
+ 	xfs_bmbt_irec_t		imap;
+ 	xfs_fileoff_t		offset_fsb;
+ 	xfs_off_t		lastoffset;
+ 	xfs_off_t		offset;
+ 	xfs_buf_t		*bp;
+ 	xfs_mount_t		*mp = ip->i_mount;
+ 	int			nimap;
+ 	int			error = 0;
+ 
+ 	/*
+ 	 * Avoid doing I/O beyond eof - it's not necessary
+ 	 * since nothing can read beyond eof.  The space will
+ 	 * be zeroed when the file is extended anyway.
+ 	 */
+ 	if (startoff >= XFS_ISIZE(ip))
+ 		return 0;
+ 
+ 	if (endoff > XFS_ISIZE(ip))
+ 		endoff = XFS_ISIZE(ip);
+ 
+ 	bp = xfs_buf_get_uncached(XFS_IS_REALTIME_INODE(ip) ?
+ 					mp->m_rtdev_targp : mp->m_ddev_targp,
+ 				  BTOBB(mp->m_sb.sb_blocksize), 0);
+ 	if (!bp)
+ 		return XFS_ERROR(ENOMEM);
+ 
+ 	xfs_buf_unlock(bp);
+ 
+ 	for (offset = startoff; offset <= endoff; offset = lastoffset + 1) {
+ 		offset_fsb = XFS_B_TO_FSBT(mp, offset);
+ 		nimap = 1;
+ 		error = xfs_bmapi_read(ip, offset_fsb, 1, &imap, &nimap, 0);
+ 		if (error || nimap < 1)
+ 			break;
+ 		ASSERT(imap.br_blockcount >= 1);
+ 		ASSERT(imap.br_startoff == offset_fsb);
+ 		lastoffset = XFS_FSB_TO_B(mp, imap.br_startoff + 1) - 1;
+ 		if (lastoffset > endoff)
+ 			lastoffset = endoff;
+ 		if (imap.br_startblock == HOLESTARTBLOCK)
+ 			continue;
+ 		ASSERT(imap.br_startblock != DELAYSTARTBLOCK);
+ 		if (imap.br_state == XFS_EXT_UNWRITTEN)
+ 			continue;
+ 		XFS_BUF_UNDONE(bp);
+ 		XFS_BUF_UNWRITE(bp);
+ 		XFS_BUF_READ(bp);
+ 		XFS_BUF_SET_ADDR(bp, xfs_fsb_to_db(ip, imap.br_startblock));
+ 		xfsbdstrat(mp, bp);
+ 		error = xfs_buf_iowait(bp);
+ 		if (error) {
+ 			xfs_buf_ioerror_alert(bp,
+ 					"xfs_zero_remaining_bytes(read)");
+ 			break;
+ 		}
+ 		memset(bp->b_addr +
+ 			(offset - XFS_FSB_TO_B(mp, imap.br_startoff)),
+ 		      0, lastoffset - offset + 1);
+ 		XFS_BUF_UNDONE(bp);
+ 		XFS_BUF_UNREAD(bp);
+ 		XFS_BUF_WRITE(bp);
+ 		xfsbdstrat(mp, bp);
+ 		error = xfs_buf_iowait(bp);
+ 		if (error) {
+ 			xfs_buf_ioerror_alert(bp,
+ 					"xfs_zero_remaining_bytes(write)");
+ 			break;
+ 		}
+ 	}
+ 	xfs_buf_free(bp);
+ 	return error;
+ }
+ 
+ /*
+  * xfs_free_file_space()
+  *      This routine frees disk space for the given file.
+  *
+  *	This routine is only called by xfs_change_file_space
+  *	for an UNRESVSP type call.
+  *
+  * RETURNS:
+  *       0 on success
+  *      errno on error
+  *
+  */
+ STATIC int
+ xfs_free_file_space(
+ 	xfs_inode_t		*ip,
+ 	xfs_off_t		offset,
+ 	xfs_off_t		len,
+ 	int			attr_flags)
+ {
+ 	int			committed;
+ 	int			done;
+ 	xfs_fileoff_t		endoffset_fsb;
+ 	int			error;
+ 	xfs_fsblock_t		firstfsb;
+ 	xfs_bmap_free_t		free_list;
+ 	xfs_bmbt_irec_t		imap;
+ 	xfs_off_t		ioffset;
+ 	xfs_extlen_t		mod=0;
+ 	xfs_mount_t		*mp;
+ 	int			nimap;
+ 	uint			resblks;
+ 	xfs_off_t		rounding;
+ 	int			rt;
+ 	xfs_fileoff_t		startoffset_fsb;
+ 	xfs_trans_t		*tp;
+ 	int			need_iolock = 1;
+ 
+ 	mp = ip->i_mount;
+ 
+ 	trace_xfs_free_file_space(ip);
+ 
+ 	error = xfs_qm_dqattach(ip, 0);
+ 	if (error)
+ 		return error;
+ 
+ 	error = 0;
+ 	if (len <= 0)	/* if nothing being freed */
+ 		return error;
+ 	rt = XFS_IS_REALTIME_INODE(ip);
+ 	startoffset_fsb	= XFS_B_TO_FSB(mp, offset);
+ 	endoffset_fsb = XFS_B_TO_FSBT(mp, offset + len);
+ 
+ 	if (attr_flags & XFS_ATTR_NOLOCK)
+ 		need_iolock = 0;
+ 	if (need_iolock) {
+ 		xfs_ilock(ip, XFS_IOLOCK_EXCL);
+ 		/* wait for the completion of any pending DIOs */
+ 		inode_dio_wait(VFS_I(ip));
+ 	}
+ 
+ 	rounding = max_t(xfs_off_t, 1 << mp->m_sb.sb_blocklog, PAGE_CACHE_SIZE);
+ 	ioffset = offset & ~(rounding - 1);
+ 	error = -filemap_write_and_wait_range(VFS_I(ip)->i_mapping,
+ 					      ioffset, -1);
+ 	if (error)
+ 		goto out_unlock_iolock;
+ 	truncate_pagecache_range(VFS_I(ip), ioffset, -1);
+ 
+ 	/*
+ 	 * Need to zero the stuff we're not freeing, on disk.
+ 	 * If it's a realtime file & can't use unwritten extents then we
+ 	 * actually need to zero the extent edges.  Otherwise xfs_bunmapi
+ 	 * will take care of it for us.
+ 	 */
+ 	if (rt && !xfs_sb_version_hasextflgbit(&mp->m_sb)) {
+ 		nimap = 1;
+ 		error = xfs_bmapi_read(ip, startoffset_fsb, 1,
+ 					&imap, &nimap, 0);
+ 		if (error)
+ 			goto out_unlock_iolock;
+ 		ASSERT(nimap == 0 || nimap == 1);
+ 		if (nimap && imap.br_startblock != HOLESTARTBLOCK) {
+ 			xfs_daddr_t	block;
+ 
+ 			ASSERT(imap.br_startblock != DELAYSTARTBLOCK);
+ 			block = imap.br_startblock;
+ 			mod = do_div(block, mp->m_sb.sb_rextsize);
+ 			if (mod)
+ 				startoffset_fsb += mp->m_sb.sb_rextsize - mod;
+ 		}
+ 		nimap = 1;
+ 		error = xfs_bmapi_read(ip, endoffset_fsb - 1, 1,
+ 					&imap, &nimap, 0);
+ 		if (error)
+ 			goto out_unlock_iolock;
+ 		ASSERT(nimap == 0 || nimap == 1);
+ 		if (nimap && imap.br_startblock != HOLESTARTBLOCK) {
+ 			ASSERT(imap.br_startblock != DELAYSTARTBLOCK);
+ 			mod++;
+ 			if (mod && (mod != mp->m_sb.sb_rextsize))
+ 				endoffset_fsb -= mod;
+ 		}
+ 	}
+ 	if ((done = (endoffset_fsb <= startoffset_fsb)))
+ 		/*
+ 		 * One contiguous piece to clear
+ 		 */
+ 		error = xfs_zero_remaining_bytes(ip, offset, offset + len - 1);
+ 	else {
+ 		/*
+ 		 * Some full blocks, possibly two pieces to clear
+ 		 */
+ 		if (offset < XFS_FSB_TO_B(mp, startoffset_fsb))
+ 			error = xfs_zero_remaining_bytes(ip, offset,
+ 				XFS_FSB_TO_B(mp, startoffset_fsb) - 1);
+ 		if (!error &&
+ 		    XFS_FSB_TO_B(mp, endoffset_fsb) < offset + len)
+ 			error = xfs_zero_remaining_bytes(ip,
+ 				XFS_FSB_TO_B(mp, endoffset_fsb),
+ 				offset + len - 1);
+ 	}
+ 
+ 	/*
+ 	 * free file space until done or until there is an error
+ 	 */
+ 	resblks = XFS_DIOSTRAT_SPACE_RES(mp, 0);
+ 	while (!error && !done) {
+ 
+ 		/*
+ 		 * allocate and setup the transaction. Allow this
+ 		 * transaction to dip into the reserve blocks to ensure
+ 		 * the freeing of the space succeeds at ENOSPC.
+ 		 */
+ 		tp = xfs_trans_alloc(mp, XFS_TRANS_DIOSTRAT);
+ 		tp->t_flags |= XFS_TRANS_RESERVE;
+ 		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_write, resblks, 0);
+ 
+ 		/*
+ 		 * check for running out of space
+ 		 */
+ 		if (error) {
+ 			/*
+ 			 * Free the transaction structure.
+ 			 */
+ 			ASSERT(error == ENOSPC || XFS_FORCED_SHUTDOWN(mp));
+ 			xfs_trans_cancel(tp, 0);
+ 			break;
+ 		}
+ 		xfs_ilock(ip, XFS_ILOCK_EXCL);
+ 		error = xfs_trans_reserve_quota(tp, mp,
+ 				ip->i_udquot, ip->i_gdquot, ip->i_pdquot,
+ 				resblks, 0, XFS_QMOPT_RES_REGBLKS);
+ 		if (error)
+ 			goto error1;
+ 
+ 		xfs_trans_ijoin(tp, ip, 0);
+ 
+ 		/*
+ 		 * issue the bunmapi() call to free the blocks
+ 		 */
+ 		xfs_bmap_init(&free_list, &firstfsb);
+ 		error = xfs_bunmapi(tp, ip, startoffset_fsb,
+ 				  endoffset_fsb - startoffset_fsb,
+ 				  0, 2, &firstfsb, &free_list, &done);
+ 		if (error) {
+ 			goto error0;
+ 		}
+ 
+ 		/*
+ 		 * complete the transaction
+ 		 */
+ 		error = xfs_bmap_finish(&tp, &free_list, &committed);
+ 		if (error) {
+ 			goto error0;
+ 		}
+ 
+ 		error = xfs_trans_commit(tp, XFS_TRANS_RELEASE_LOG_RES);
+ 		xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 	}
+ 
+  out_unlock_iolock:
+ 	if (need_iolock)
+ 		xfs_iunlock(ip, XFS_IOLOCK_EXCL);
+ 	return error;
+ 
+  error0:
+ 	xfs_bmap_cancel(&free_list);
+  error1:
+ 	xfs_trans_cancel(tp, XFS_TRANS_RELEASE_LOG_RES | XFS_TRANS_ABORT);
+ 	xfs_iunlock(ip, need_iolock ? (XFS_ILOCK_EXCL | XFS_IOLOCK_EXCL) :
+ 		    XFS_ILOCK_EXCL);
+ 	return error;
+ }
+ 
+ 
+ STATIC int
+ xfs_zero_file_space(
+ 	struct xfs_inode	*ip,
+ 	xfs_off_t		offset,
+ 	xfs_off_t		len,
+ 	int			attr_flags)
+ {
+ 	struct xfs_mount	*mp = ip->i_mount;
+ 	uint			granularity;
+ 	xfs_off_t		start_boundary;
+ 	xfs_off_t		end_boundary;
+ 	int			error;
+ 
+ 	granularity = max_t(uint, 1 << mp->m_sb.sb_blocklog, PAGE_CACHE_SIZE);
+ 
+ 	/*
+ 	 * Round the range of extents we are going to convert inwards.  If the
+ 	 * offset is aligned, then it doesn't get changed so we zero from the
+ 	 * start of the block offset points to.
+ 	 */
+ 	start_boundary = round_up(offset, granularity);
+ 	end_boundary = round_down(offset + len, granularity);
+ 
+ 	ASSERT(start_boundary >= offset);
+ 	ASSERT(end_boundary <= offset + len);
+ 
+ 	if (!(attr_flags & XFS_ATTR_NOLOCK))
+ 		xfs_ilock(ip, XFS_IOLOCK_EXCL);
+ 
+ 	if (start_boundary < end_boundary - 1) {
+ 		/* punch out the page cache over the conversion range */
+ 		truncate_pagecache_range(VFS_I(ip), start_boundary,
+ 					 end_boundary - 1);
+ 		/* convert the blocks */
+ 		error = xfs_alloc_file_space(ip, start_boundary,
+ 					end_boundary - start_boundary - 1,
+ 					XFS_BMAPI_PREALLOC | XFS_BMAPI_CONVERT,
+ 					attr_flags);
+ 		if (error)
+ 			goto out_unlock;
+ 
+ 		/* We've handled the interior of the range, now for the edges */
+ 		if (start_boundary != offset)
+ 			error = xfs_iozero(ip, offset, start_boundary - offset);
+ 		if (error)
+ 			goto out_unlock;
+ 
+ 		if (end_boundary != offset + len)
+ 			error = xfs_iozero(ip, end_boundary,
+ 					   offset + len - end_boundary);
+ 
+ 	} else {
+ 		/*
+ 		 * It's either a sub-granularity range or the range spanned lies
+ 		 * partially across two adjacent blocks.
+ 		 */
+ 		error = xfs_iozero(ip, offset, len);
+ 	}
+ 
+ out_unlock:
+ 	if (!(attr_flags & XFS_ATTR_NOLOCK))
+ 		xfs_iunlock(ip, XFS_IOLOCK_EXCL);
+ 	return error;
+ 
+ }
+ 
+ /*
+  * xfs_change_file_space()
+  *      This routine allocates or frees disk space for the given file.
+  *      The user specified parameters are checked for alignment and size
+  *      limitations.
+  *
+  * RETURNS:
+  *       0 on success
+  *      errno on error
+  *
+  */
+ int
+ xfs_change_file_space(
+ 	xfs_inode_t	*ip,
+ 	int		cmd,
+ 	xfs_flock64_t	*bf,
+ 	xfs_off_t	offset,
+ 	int		attr_flags)
+ {
+ 	xfs_mount_t	*mp = ip->i_mount;
+ 	int		clrprealloc;
+ 	int		error;
+ 	xfs_fsize_t	fsize;
+ 	int		setprealloc;
+ 	xfs_off_t	startoffset;
+ 	xfs_trans_t	*tp;
+ 	struct iattr	iattr;
+ 
+ 	if (!S_ISREG(ip->i_d.di_mode))
+ 		return XFS_ERROR(EINVAL);
+ 
+ 	switch (bf->l_whence) {
+ 	case 0: /*SEEK_SET*/
+ 		break;
+ 	case 1: /*SEEK_CUR*/
+ 		bf->l_start += offset;
+ 		break;
+ 	case 2: /*SEEK_END*/
+ 		bf->l_start += XFS_ISIZE(ip);
+ 		break;
+ 	default:
+ 		return XFS_ERROR(EINVAL);
+ 	}
+ 
+ 	/*
+ 	 * length of <= 0 for resv/unresv/zero is invalid.  length for
+ 	 * alloc/free is ignored completely and we have no idea what userspace
+ 	 * might have set it to, so set it to zero to allow range
+ 	 * checks to pass.
+ 	 */
+ 	switch (cmd) {
+ 	case XFS_IOC_ZERO_RANGE:
+ 	case XFS_IOC_RESVSP:
+ 	case XFS_IOC_RESVSP64:
+ 	case XFS_IOC_UNRESVSP:
+ 	case XFS_IOC_UNRESVSP64:
+ 		if (bf->l_len <= 0)
+ 			return XFS_ERROR(EINVAL);
+ 		break;
+ 	default:
+ 		bf->l_len = 0;
+ 		break;
+ 	}
+ 
+ 	if (bf->l_start < 0 ||
+ 	    bf->l_start > mp->m_super->s_maxbytes ||
+ 	    bf->l_start + bf->l_len < 0 ||
+ 	    bf->l_start + bf->l_len >= mp->m_super->s_maxbytes)
+ 		return XFS_ERROR(EINVAL);
+ 
+ 	bf->l_whence = 0;
+ 
+ 	startoffset = bf->l_start;
+ 	fsize = XFS_ISIZE(ip);
+ 
+ 	setprealloc = clrprealloc = 0;
+ 	switch (cmd) {
+ 	case XFS_IOC_ZERO_RANGE:
+ 		error = xfs_zero_file_space(ip, startoffset, bf->l_len,
+ 						attr_flags);
+ 		if (error)
+ 			return error;
+ 		setprealloc = 1;
+ 		break;
+ 
+ 	case XFS_IOC_RESVSP:
+ 	case XFS_IOC_RESVSP64:
+ 		error = xfs_alloc_file_space(ip, startoffset, bf->l_len,
+ 						XFS_BMAPI_PREALLOC, attr_flags);
+ 		if (error)
+ 			return error;
+ 		setprealloc = 1;
+ 		break;
+ 
+ 	case XFS_IOC_UNRESVSP:
+ 	case XFS_IOC_UNRESVSP64:
+ 		if ((error = xfs_free_file_space(ip, startoffset, bf->l_len,
+ 								attr_flags)))
+ 			return error;
+ 		break;
+ 
+ 	case XFS_IOC_ALLOCSP:
+ 	case XFS_IOC_ALLOCSP64:
+ 	case XFS_IOC_FREESP:
+ 	case XFS_IOC_FREESP64:
+ 		/*
+ 		 * These operations actually do IO when extending the file, but
+ 		 * the allocation is done seperately to the zeroing that is
+ 		 * done. This set of operations need to be serialised against
+ 		 * other IO operations, such as truncate and buffered IO. We
+ 		 * need to take the IOLOCK here to serialise the allocation and
+ 		 * zeroing IO to prevent other IOLOCK holders (e.g. getbmap,
+ 		 * truncate, direct IO) from racing against the transient
+ 		 * allocated but not written state we can have here.
+ 		 */
+ 		xfs_ilock(ip, XFS_IOLOCK_EXCL);
+ 		if (startoffset > fsize) {
+ 			error = xfs_alloc_file_space(ip, fsize,
+ 					startoffset - fsize, 0,
+ 					attr_flags | XFS_ATTR_NOLOCK);
+ 			if (error) {
+ 				xfs_iunlock(ip, XFS_IOLOCK_EXCL);
+ 				break;
+ 			}
+ 		}
+ 
+ 		iattr.ia_valid = ATTR_SIZE;
+ 		iattr.ia_size = startoffset;
+ 
+ 		error = xfs_setattr_size(ip, &iattr,
+ 					 attr_flags | XFS_ATTR_NOLOCK);
+ 		xfs_iunlock(ip, XFS_IOLOCK_EXCL);
+ 
+ 		if (error)
+ 			return error;
+ 
+ 		clrprealloc = 1;
+ 		break;
+ 
+ 	default:
+ 		ASSERT(0);
+ 		return XFS_ERROR(EINVAL);
+ 	}
+ 
+ 	/*
+ 	 * update the inode timestamp, mode, and prealloc flag bits
+ 	 */
+ 	tp = xfs_trans_alloc(mp, XFS_TRANS_WRITEID);
+ 	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_writeid, 0, 0);
+ 	if (error) {
+ 		xfs_trans_cancel(tp, 0);
+ 		return error;
+ 	}
+ 
+ 	xfs_ilock(ip, XFS_ILOCK_EXCL);
+ 	xfs_trans_ijoin(tp, ip, XFS_ILOCK_EXCL);
+ 
+ 	if ((attr_flags & XFS_ATTR_DMI) == 0) {
+ 		ip->i_d.di_mode &= ~S_ISUID;
+ 
+ 		/*
+ 		 * Note that we don't have to worry about mandatory
+ 		 * file locking being disabled here because we only
+ 		 * clear the S_ISGID bit if the Group execute bit is
+ 		 * on, but if it was on then mandatory locking wouldn't
+ 		 * have been enabled.
+ 		 */
+ 		if (ip->i_d.di_mode & S_IXGRP)
+ 			ip->i_d.di_mode &= ~S_ISGID;
+ 
+ 		xfs_trans_ichgtime(tp, ip, XFS_ICHGTIME_MOD | XFS_ICHGTIME_CHG);
+ 	}
+ 	if (setprealloc)
+ 		ip->i_d.di_flags |= XFS_DIFLAG_PREALLOC;
+ 	else if (clrprealloc)
+ 		ip->i_d.di_flags &= ~XFS_DIFLAG_PREALLOC;
+ 
+ 	xfs_trans_log_inode(tp, ip, XFS_ILOG_CORE);
+ 	if (attr_flags & XFS_ATTR_SYNC)
+ 		xfs_trans_set_sync(tp);
+ 	return xfs_trans_commit(tp, 0);
+ }
+ 
+ /*
+  * We need to check that the format of the data fork in the temporary inode is
+  * valid for the target inode before doing the swap. This is not a problem with
+  * attr1 because of the fixed fork offset, but attr2 has a dynamically sized
+  * data fork depending on the space the attribute fork is taking so we can get
+  * invalid formats on the target inode.
+  *
+  * E.g. target has space for 7 extents in extent format, temp inode only has
+  * space for 6.  If we defragment down to 7 extents, then the tmp format is a
+  * btree, but when swapped it needs to be in extent format. Hence we can't just
+  * blindly swap data forks on attr2 filesystems.
+  *
+  * Note that we check the swap in both directions so that we don't end up with
+  * a corrupt temporary inode, either.
+  *
+  * Note that fixing the way xfs_fsr sets up the attribute fork in the source
+  * inode will prevent this situation from occurring, so all we do here is
+  * reject and log the attempt. basically we are putting the responsibility on
+  * userspace to get this right.
+  */
+ static int
+ xfs_swap_extents_check_format(
+ 	xfs_inode_t	*ip,	/* target inode */
+ 	xfs_inode_t	*tip)	/* tmp inode */
+ {
+ 
+ 	/* Should never get a local format */
+ 	if (ip->i_d.di_format == XFS_DINODE_FMT_LOCAL ||
+ 	    tip->i_d.di_format == XFS_DINODE_FMT_LOCAL)
+ 		return EINVAL;
+ 
+ 	/*
+ 	 * if the target inode has less extents that then temporary inode then
+ 	 * why did userspace call us?
+ 	 */
+ 	if (ip->i_d.di_nextents < tip->i_d.di_nextents)
+ 		return EINVAL;
+ 
+ 	/*
+ 	 * if the target inode is in extent form and the temp inode is in btree
+ 	 * form then we will end up with the target inode in the wrong format
+ 	 * as we already know there are less extents in the temp inode.
+ 	 */
+ 	if (ip->i_d.di_format == XFS_DINODE_FMT_EXTENTS &&
+ 	    tip->i_d.di_format == XFS_DINODE_FMT_BTREE)
+ 		return EINVAL;
+ 
+ 	/* Check temp in extent form to max in target */
+ 	if (tip->i_d.di_format == XFS_DINODE_FMT_EXTENTS &&
+ 	    XFS_IFORK_NEXTENTS(tip, XFS_DATA_FORK) >
+ 			XFS_IFORK_MAXEXT(ip, XFS_DATA_FORK))
+ 		return EINVAL;
+ 
+ 	/* Check target in extent form to max in temp */
+ 	if (ip->i_d.di_format == XFS_DINODE_FMT_EXTENTS &&
+ 	    XFS_IFORK_NEXTENTS(ip, XFS_DATA_FORK) >
+ 			XFS_IFORK_MAXEXT(tip, XFS_DATA_FORK))
+ 		return EINVAL;
+ 
+ 	/*
+ 	 * If we are in a btree format, check that the temp root block will fit
+ 	 * in the target and that it has enough extents to be in btree format
+ 	 * in the target.
+ 	 *
+ 	 * Note that we have to be careful to allow btree->extent conversions
+ 	 * (a common defrag case) which will occur when the temp inode is in
+ 	 * extent format...
+ 	 */
+ 	if (tip->i_d.di_format == XFS_DINODE_FMT_BTREE) {
+ 		if (XFS_IFORK_BOFF(ip) &&
+ 		    XFS_BMAP_BMDR_SPACE(tip->i_df.if_broot) > XFS_IFORK_BOFF(ip))
+ 			return EINVAL;
+ 		if (XFS_IFORK_NEXTENTS(tip, XFS_DATA_FORK) <=
+ 		    XFS_IFORK_MAXEXT(ip, XFS_DATA_FORK))
+ 			return EINVAL;
+ 	}
+ 
+ 	/* Reciprocal target->temp btree format checks */
+ 	if (ip->i_d.di_format == XFS_DINODE_FMT_BTREE) {
+ 		if (XFS_IFORK_BOFF(tip) &&
+ 		    XFS_BMAP_BMDR_SPACE(ip->i_df.if_broot) > XFS_IFORK_BOFF(tip))
+ 			return EINVAL;
+ 		if (XFS_IFORK_NEXTENTS(ip, XFS_DATA_FORK) <=
+ 		    XFS_IFORK_MAXEXT(tip, XFS_DATA_FORK))
+ 			return EINVAL;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ int
+ xfs_swap_extents(
+ 	xfs_inode_t	*ip,	/* target inode */
+ 	xfs_inode_t	*tip,	/* tmp inode */
+ 	xfs_swapext_t	*sxp)
+ {
+ 	xfs_mount_t	*mp = ip->i_mount;
+ 	xfs_trans_t	*tp;
+ 	xfs_bstat_t	*sbp = &sxp->sx_stat;
+ 	xfs_ifork_t	*tempifp, *ifp, *tifp;
+ 	int		src_log_flags, target_log_flags;
+ 	int		error = 0;
+ 	int		aforkblks = 0;
+ 	int		taforkblks = 0;
+ 	__uint64_t	tmp;
+ 
+ 	/*
+ 	 * We have no way of updating owner information in the BMBT blocks for
+ 	 * each inode on CRC enabled filesystems, so to avoid corrupting the
+ 	 * this metadata we simply don't allow extent swaps to occur.
+ 	 */
+ 	if (xfs_sb_version_hascrc(&mp->m_sb))
+ 		return XFS_ERROR(EINVAL);
+ 
+ 	tempifp = kmem_alloc(sizeof(xfs_ifork_t), KM_MAYFAIL);
+ 	if (!tempifp) {
+ 		error = XFS_ERROR(ENOMEM);
+ 		goto out;
+ 	}
+ 
+ 	/*
+ 	 * we have to do two separate lock calls here to keep lockdep
+ 	 * happy. If we try to get all the locks in one call, lock will
+ 	 * report false positives when we drop the ILOCK and regain them
+ 	 * below.
+ 	 */
+ 	xfs_lock_two_inodes(ip, tip, XFS_IOLOCK_EXCL);
+ 	xfs_lock_two_inodes(ip, tip, XFS_ILOCK_EXCL);
+ 
+ 	/* Verify that both files have the same format */
+ 	if ((ip->i_d.di_mode & S_IFMT) != (tip->i_d.di_mode & S_IFMT)) {
+ 		error = XFS_ERROR(EINVAL);
+ 		goto out_unlock;
+ 	}
+ 
+ 	/* Verify both files are either real-time or non-realtime */
+ 	if (XFS_IS_REALTIME_INODE(ip) != XFS_IS_REALTIME_INODE(tip)) {
+ 		error = XFS_ERROR(EINVAL);
+ 		goto out_unlock;
+ 	}
+ 
+ 	error = -filemap_write_and_wait(VFS_I(tip)->i_mapping);
+ 	if (error)
+ 		goto out_unlock;
+ 	truncate_pagecache_range(VFS_I(tip), 0, -1);
+ 
+ 	/* Verify O_DIRECT for ftmp */
+ 	if (VN_CACHED(VFS_I(tip)) != 0) {
+ 		error = XFS_ERROR(EINVAL);
+ 		goto out_unlock;
+ 	}
+ 
+ 	/* Verify all data are being swapped */
+ 	if (sxp->sx_offset != 0 ||
+ 	    sxp->sx_length != ip->i_d.di_size ||
+ 	    sxp->sx_length != tip->i_d.di_size) {
+ 		error = XFS_ERROR(EFAULT);
+ 		goto out_unlock;
+ 	}
+ 
+ 	trace_xfs_swap_extent_before(ip, 0);
+ 	trace_xfs_swap_extent_before(tip, 1);
+ 
+ 	/* check inode formats now that data is flushed */
+ 	error = xfs_swap_extents_check_format(ip, tip);
+ 	if (error) {
+ 		xfs_notice(mp,
+ 		    "%s: inode 0x%llx format is incompatible for exchanging.",
+ 				__func__, ip->i_ino);
+ 		goto out_unlock;
+ 	}
+ 
+ 	/*
+ 	 * Compare the current change & modify times with that
+ 	 * passed in.  If they differ, we abort this swap.
+ 	 * This is the mechanism used to ensure the calling
+ 	 * process that the file was not changed out from
+ 	 * under it.
+ 	 */
+ 	if ((sbp->bs_ctime.tv_sec != VFS_I(ip)->i_ctime.tv_sec) ||
+ 	    (sbp->bs_ctime.tv_nsec != VFS_I(ip)->i_ctime.tv_nsec) ||
+ 	    (sbp->bs_mtime.tv_sec != VFS_I(ip)->i_mtime.tv_sec) ||
+ 	    (sbp->bs_mtime.tv_nsec != VFS_I(ip)->i_mtime.tv_nsec)) {
+ 		error = XFS_ERROR(EBUSY);
+ 		goto out_unlock;
+ 	}
+ 
+ 	/* We need to fail if the file is memory mapped.  Once we have tossed
+ 	 * all existing pages, the page fault will have no option
+ 	 * but to go to the filesystem for pages. By making the page fault call
+ 	 * vop_read (or write in the case of autogrow) they block on the iolock
+ 	 * until we have switched the extents.
+ 	 */
+ 	if (VN_MAPPED(VFS_I(ip))) {
+ 		error = XFS_ERROR(EBUSY);
+ 		goto out_unlock;
+ 	}
+ 
+ 	xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 	xfs_iunlock(tip, XFS_ILOCK_EXCL);
+ 
+ 	/*
+ 	 * There is a race condition here since we gave up the
+ 	 * ilock.  However, the data fork will not change since
+ 	 * we have the iolock (locked for truncation too) so we
+ 	 * are safe.  We don't really care if non-io related
+ 	 * fields change.
+ 	 */
+ 	truncate_pagecache_range(VFS_I(ip), 0, -1);
+ 
+ 	tp = xfs_trans_alloc(mp, XFS_TRANS_SWAPEXT);
+ 	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_ichange, 0, 0);
+ 	if (error) {
+ 		xfs_iunlock(ip,  XFS_IOLOCK_EXCL);
+ 		xfs_iunlock(tip, XFS_IOLOCK_EXCL);
+ 		xfs_trans_cancel(tp, 0);
+ 		goto out;
+ 	}
+ 	xfs_lock_two_inodes(ip, tip, XFS_ILOCK_EXCL);
+ 
+ 	/*
+ 	 * Count the number of extended attribute blocks
+ 	 */
+ 	if ( ((XFS_IFORK_Q(ip) != 0) && (ip->i_d.di_anextents > 0)) &&
+ 	     (ip->i_d.di_aformat != XFS_DINODE_FMT_LOCAL)) {
+ 		error = xfs_bmap_count_blocks(tp, ip, XFS_ATTR_FORK, &aforkblks);
+ 		if (error)
+ 			goto out_trans_cancel;
+ 	}
+ 	if ( ((XFS_IFORK_Q(tip) != 0) && (tip->i_d.di_anextents > 0)) &&
+ 	     (tip->i_d.di_aformat != XFS_DINODE_FMT_LOCAL)) {
+ 		error = xfs_bmap_count_blocks(tp, tip, XFS_ATTR_FORK,
+ 			&taforkblks);
+ 		if (error)
+ 			goto out_trans_cancel;
+ 	}
+ 
+ 	/*
+ 	 * Swap the data forks of the inodes
+ 	 */
+ 	ifp = &ip->i_df;
+ 	tifp = &tip->i_df;
+ 	*tempifp = *ifp;	/* struct copy */
+ 	*ifp = *tifp;		/* struct copy */
+ 	*tifp = *tempifp;	/* struct copy */
+ 
+ 	/*
+ 	 * Fix the on-disk inode values
+ 	 */
+ 	tmp = (__uint64_t)ip->i_d.di_nblocks;
+ 	ip->i_d.di_nblocks = tip->i_d.di_nblocks - taforkblks + aforkblks;
+ 	tip->i_d.di_nblocks = tmp + taforkblks - aforkblks;
+ 
+ 	tmp = (__uint64_t) ip->i_d.di_nextents;
+ 	ip->i_d.di_nextents = tip->i_d.di_nextents;
+ 	tip->i_d.di_nextents = tmp;
+ 
+ 	tmp = (__uint64_t) ip->i_d.di_format;
+ 	ip->i_d.di_format = tip->i_d.di_format;
+ 	tip->i_d.di_format = tmp;
+ 
+ 	/*
+ 	 * The extents in the source inode could still contain speculative
+ 	 * preallocation beyond EOF (e.g. the file is open but not modified
+ 	 * while defrag is in progress). In that case, we need to copy over the
+ 	 * number of delalloc blocks the data fork in the source inode is
+ 	 * tracking beyond EOF so that when the fork is truncated away when the
+ 	 * temporary inode is unlinked we don't underrun the i_delayed_blks
+ 	 * counter on that inode.
+ 	 */
+ 	ASSERT(tip->i_delayed_blks == 0);
+ 	tip->i_delayed_blks = ip->i_delayed_blks;
+ 	ip->i_delayed_blks = 0;
+ 
+ 	src_log_flags = XFS_ILOG_CORE;
+ 	switch (ip->i_d.di_format) {
+ 	case XFS_DINODE_FMT_EXTENTS:
+ 		/* If the extents fit in the inode, fix the
+ 		 * pointer.  Otherwise it's already NULL or
+ 		 * pointing to the extent.
+ 		 */
+ 		if (ip->i_d.di_nextents <= XFS_INLINE_EXTS) {
+ 			ifp->if_u1.if_extents =
+ 				ifp->if_u2.if_inline_ext;
+ 		}
+ 		src_log_flags |= XFS_ILOG_DEXT;
+ 		break;
+ 	case XFS_DINODE_FMT_BTREE:
+ 		src_log_flags |= XFS_ILOG_DBROOT;
+ 		break;
+ 	}
+ 
+ 	target_log_flags = XFS_ILOG_CORE;
+ 	switch (tip->i_d.di_format) {
+ 	case XFS_DINODE_FMT_EXTENTS:
+ 		/* If the extents fit in the inode, fix the
+ 		 * pointer.  Otherwise it's already NULL or
+ 		 * pointing to the extent.
+ 		 */
+ 		if (tip->i_d.di_nextents <= XFS_INLINE_EXTS) {
+ 			tifp->if_u1.if_extents =
+ 				tifp->if_u2.if_inline_ext;
+ 		}
+ 		target_log_flags |= XFS_ILOG_DEXT;
+ 		break;
+ 	case XFS_DINODE_FMT_BTREE:
+ 		target_log_flags |= XFS_ILOG_DBROOT;
+ 		break;
+ 	}
+ 
+ 
+ 	xfs_trans_ijoin(tp, ip, XFS_ILOCK_EXCL | XFS_IOLOCK_EXCL);
+ 	xfs_trans_ijoin(tp, tip, XFS_ILOCK_EXCL | XFS_IOLOCK_EXCL);
+ 
+ 	xfs_trans_log_inode(tp, ip,  src_log_flags);
+ 	xfs_trans_log_inode(tp, tip, target_log_flags);
+ 
+ 	/*
+ 	 * If this is a synchronous mount, make sure that the
+ 	 * transaction goes to disk before returning to the user.
+ 	 */
+ 	if (mp->m_flags & XFS_MOUNT_WSYNC)
+ 		xfs_trans_set_sync(tp);
+ 
+ 	error = xfs_trans_commit(tp, 0);
+ 
+ 	trace_xfs_swap_extent_after(ip, 0);
+ 	trace_xfs_swap_extent_after(tip, 1);
+ out:
+ 	kmem_free(tempifp);
+ 	return error;
+ 
+ out_unlock:
+ 	xfs_iunlock(ip,  XFS_ILOCK_EXCL | XFS_IOLOCK_EXCL);
+ 	xfs_iunlock(tip, XFS_ILOCK_EXCL | XFS_IOLOCK_EXCL);
+ 	goto out;
+ 
+ out_trans_cancel:
+ 	xfs_trans_cancel(tp, 0);
+ 	goto out_unlock;
+ }
++>>>>>>> 3d3c8b5222b9 (xfs: refactor xfs_trans_reserve() interface)
diff --cc fs/xfs/xfs_inode.c
index 1029f5670207,2f41a1a2f888..000000000000
--- a/fs/xfs/xfs_inode.c
+++ b/fs/xfs/xfs_inode.c
@@@ -633,6 -862,582 +633,585 @@@ xfs_ialloc
  }
  
  /*
++<<<<<<< HEAD
++=======
+  * Allocates a new inode from disk and return a pointer to the
+  * incore copy. This routine will internally commit the current
+  * transaction and allocate a new one if the Space Manager needed
+  * to do an allocation to replenish the inode free-list.
+  *
+  * This routine is designed to be called from xfs_create and
+  * xfs_create_dir.
+  *
+  */
+ int
+ xfs_dir_ialloc(
+ 	xfs_trans_t	**tpp,		/* input: current transaction;
+ 					   output: may be a new transaction. */
+ 	xfs_inode_t	*dp,		/* directory within whose allocate
+ 					   the inode. */
+ 	umode_t		mode,
+ 	xfs_nlink_t	nlink,
+ 	xfs_dev_t	rdev,
+ 	prid_t		prid,		/* project id */
+ 	int		okalloc,	/* ok to allocate new space */
+ 	xfs_inode_t	**ipp,		/* pointer to inode; it will be
+ 					   locked. */
+ 	int		*committed)
+ 
+ {
+ 	xfs_trans_t	*tp;
+ 	xfs_trans_t	*ntp;
+ 	xfs_inode_t	*ip;
+ 	xfs_buf_t	*ialloc_context = NULL;
+ 	int		code;
+ 	void		*dqinfo;
+ 	uint		tflags;
+ 
+ 	tp = *tpp;
+ 	ASSERT(tp->t_flags & XFS_TRANS_PERM_LOG_RES);
+ 
+ 	/*
+ 	 * xfs_ialloc will return a pointer to an incore inode if
+ 	 * the Space Manager has an available inode on the free
+ 	 * list. Otherwise, it will do an allocation and replenish
+ 	 * the freelist.  Since we can only do one allocation per
+ 	 * transaction without deadlocks, we will need to commit the
+ 	 * current transaction and start a new one.  We will then
+ 	 * need to call xfs_ialloc again to get the inode.
+ 	 *
+ 	 * If xfs_ialloc did an allocation to replenish the freelist,
+ 	 * it returns the bp containing the head of the freelist as
+ 	 * ialloc_context. We will hold a lock on it across the
+ 	 * transaction commit so that no other process can steal
+ 	 * the inode(s) that we've just allocated.
+ 	 */
+ 	code = xfs_ialloc(tp, dp, mode, nlink, rdev, prid, okalloc,
+ 			  &ialloc_context, &ip);
+ 
+ 	/*
+ 	 * Return an error if we were unable to allocate a new inode.
+ 	 * This should only happen if we run out of space on disk or
+ 	 * encounter a disk error.
+ 	 */
+ 	if (code) {
+ 		*ipp = NULL;
+ 		return code;
+ 	}
+ 	if (!ialloc_context && !ip) {
+ 		*ipp = NULL;
+ 		return XFS_ERROR(ENOSPC);
+ 	}
+ 
+ 	/*
+ 	 * If the AGI buffer is non-NULL, then we were unable to get an
+ 	 * inode in one operation.  We need to commit the current
+ 	 * transaction and call xfs_ialloc() again.  It is guaranteed
+ 	 * to succeed the second time.
+ 	 */
+ 	if (ialloc_context) {
+ 		struct xfs_trans_res tres;
+ 
+ 		/*
+ 		 * Normally, xfs_trans_commit releases all the locks.
+ 		 * We call bhold to hang on to the ialloc_context across
+ 		 * the commit.  Holding this buffer prevents any other
+ 		 * processes from doing any allocations in this
+ 		 * allocation group.
+ 		 */
+ 		xfs_trans_bhold(tp, ialloc_context);
+ 		/*
+ 		 * Save the log reservation so we can use
+ 		 * them in the next transaction.
+ 		 */
+ 		tres.tr_logres = xfs_trans_get_log_res(tp);
+ 		tres.tr_logcount = xfs_trans_get_log_count(tp);
+ 
+ 		/*
+ 		 * We want the quota changes to be associated with the next
+ 		 * transaction, NOT this one. So, detach the dqinfo from this
+ 		 * and attach it to the next transaction.
+ 		 */
+ 		dqinfo = NULL;
+ 		tflags = 0;
+ 		if (tp->t_dqinfo) {
+ 			dqinfo = (void *)tp->t_dqinfo;
+ 			tp->t_dqinfo = NULL;
+ 			tflags = tp->t_flags & XFS_TRANS_DQ_DIRTY;
+ 			tp->t_flags &= ~(XFS_TRANS_DQ_DIRTY);
+ 		}
+ 
+ 		ntp = xfs_trans_dup(tp);
+ 		code = xfs_trans_commit(tp, 0);
+ 		tp = ntp;
+ 		if (committed != NULL) {
+ 			*committed = 1;
+ 		}
+ 		/*
+ 		 * If we get an error during the commit processing,
+ 		 * release the buffer that is still held and return
+ 		 * to the caller.
+ 		 */
+ 		if (code) {
+ 			xfs_buf_relse(ialloc_context);
+ 			if (dqinfo) {
+ 				tp->t_dqinfo = dqinfo;
+ 				xfs_trans_free_dqinfo(tp);
+ 			}
+ 			*tpp = ntp;
+ 			*ipp = NULL;
+ 			return code;
+ 		}
+ 
+ 		/*
+ 		 * transaction commit worked ok so we can drop the extra ticket
+ 		 * reference that we gained in xfs_trans_dup()
+ 		 */
+ 		xfs_log_ticket_put(tp->t_ticket);
+ 		tres.tr_logflags = XFS_TRANS_PERM_LOG_RES;
+ 		code = xfs_trans_reserve(tp, &tres, 0, 0);
+ 
+ 		/*
+ 		 * Re-attach the quota info that we detached from prev trx.
+ 		 */
+ 		if (dqinfo) {
+ 			tp->t_dqinfo = dqinfo;
+ 			tp->t_flags |= tflags;
+ 		}
+ 
+ 		if (code) {
+ 			xfs_buf_relse(ialloc_context);
+ 			*tpp = ntp;
+ 			*ipp = NULL;
+ 			return code;
+ 		}
+ 		xfs_trans_bjoin(tp, ialloc_context);
+ 
+ 		/*
+ 		 * Call ialloc again. Since we've locked out all
+ 		 * other allocations in this allocation group,
+ 		 * this call should always succeed.
+ 		 */
+ 		code = xfs_ialloc(tp, dp, mode, nlink, rdev, prid,
+ 				  okalloc, &ialloc_context, &ip);
+ 
+ 		/*
+ 		 * If we get an error at this point, return to the caller
+ 		 * so that the current transaction can be aborted.
+ 		 */
+ 		if (code) {
+ 			*tpp = tp;
+ 			*ipp = NULL;
+ 			return code;
+ 		}
+ 		ASSERT(!ialloc_context && ip);
+ 
+ 	} else {
+ 		if (committed != NULL)
+ 			*committed = 0;
+ 	}
+ 
+ 	*ipp = ip;
+ 	*tpp = tp;
+ 
+ 	return 0;
+ }
+ 
+ /*
+  * Decrement the link count on an inode & log the change.
+  * If this causes the link count to go to zero, initiate the
+  * logging activity required to truncate a file.
+  */
+ int				/* error */
+ xfs_droplink(
+ 	xfs_trans_t *tp,
+ 	xfs_inode_t *ip)
+ {
+ 	int	error;
+ 
+ 	xfs_trans_ichgtime(tp, ip, XFS_ICHGTIME_CHG);
+ 
+ 	ASSERT (ip->i_d.di_nlink > 0);
+ 	ip->i_d.di_nlink--;
+ 	drop_nlink(VFS_I(ip));
+ 	xfs_trans_log_inode(tp, ip, XFS_ILOG_CORE);
+ 
+ 	error = 0;
+ 	if (ip->i_d.di_nlink == 0) {
+ 		/*
+ 		 * We're dropping the last link to this file.
+ 		 * Move the on-disk inode to the AGI unlinked list.
+ 		 * From xfs_inactive() we will pull the inode from
+ 		 * the list and free it.
+ 		 */
+ 		error = xfs_iunlink(tp, ip);
+ 	}
+ 	return error;
+ }
+ 
+ /*
+  * This gets called when the inode's version needs to be changed from 1 to 2.
+  * Currently this happens when the nlink field overflows the old 16-bit value
+  * or when chproj is called to change the project for the first time.
+  * As a side effect the superblock version will also get rev'd
+  * to contain the NLINK bit.
+  */
+ void
+ xfs_bump_ino_vers2(
+ 	xfs_trans_t	*tp,
+ 	xfs_inode_t	*ip)
+ {
+ 	xfs_mount_t	*mp;
+ 
+ 	ASSERT(xfs_isilocked(ip, XFS_ILOCK_EXCL));
+ 	ASSERT(ip->i_d.di_version == 1);
+ 
+ 	ip->i_d.di_version = 2;
+ 	ip->i_d.di_onlink = 0;
+ 	memset(&(ip->i_d.di_pad[0]), 0, sizeof(ip->i_d.di_pad));
+ 	mp = tp->t_mountp;
+ 	if (!xfs_sb_version_hasnlink(&mp->m_sb)) {
+ 		spin_lock(&mp->m_sb_lock);
+ 		if (!xfs_sb_version_hasnlink(&mp->m_sb)) {
+ 			xfs_sb_version_addnlink(&mp->m_sb);
+ 			spin_unlock(&mp->m_sb_lock);
+ 			xfs_mod_sb(tp, XFS_SB_VERSIONNUM);
+ 		} else {
+ 			spin_unlock(&mp->m_sb_lock);
+ 		}
+ 	}
+ 	/* Caller must log the inode */
+ }
+ 
+ /*
+  * Increment the link count on an inode & log the change.
+  */
+ int
+ xfs_bumplink(
+ 	xfs_trans_t *tp,
+ 	xfs_inode_t *ip)
+ {
+ 	xfs_trans_ichgtime(tp, ip, XFS_ICHGTIME_CHG);
+ 
+ 	ASSERT(ip->i_d.di_nlink > 0);
+ 	ip->i_d.di_nlink++;
+ 	inc_nlink(VFS_I(ip));
+ 	if ((ip->i_d.di_version == 1) &&
+ 	    (ip->i_d.di_nlink > XFS_MAXLINK_1)) {
+ 		/*
+ 		 * The inode has increased its number of links beyond
+ 		 * what can fit in an old format inode.  It now needs
+ 		 * to be converted to a version 2 inode with a 32 bit
+ 		 * link count.  If this is the first inode in the file
+ 		 * system to do this, then we need to bump the superblock
+ 		 * version number as well.
+ 		 */
+ 		xfs_bump_ino_vers2(tp, ip);
+ 	}
+ 
+ 	xfs_trans_log_inode(tp, ip, XFS_ILOG_CORE);
+ 	return 0;
+ }
+ 
+ int
+ xfs_create(
+ 	xfs_inode_t		*dp,
+ 	struct xfs_name		*name,
+ 	umode_t			mode,
+ 	xfs_dev_t		rdev,
+ 	xfs_inode_t		**ipp)
+ {
+ 	int			is_dir = S_ISDIR(mode);
+ 	struct xfs_mount	*mp = dp->i_mount;
+ 	struct xfs_inode	*ip = NULL;
+ 	struct xfs_trans	*tp = NULL;
+ 	int			error;
+ 	xfs_bmap_free_t		free_list;
+ 	xfs_fsblock_t		first_block;
+ 	bool                    unlock_dp_on_error = false;
+ 	uint			cancel_flags;
+ 	int			committed;
+ 	prid_t			prid;
+ 	struct xfs_dquot	*udqp = NULL;
+ 	struct xfs_dquot	*gdqp = NULL;
+ 	struct xfs_dquot	*pdqp = NULL;
+ 	struct xfs_trans_res	tres;
+ 	uint			resblks;
+ 
+ 	trace_xfs_create(dp, name);
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		return XFS_ERROR(EIO);
+ 
+ 	if (dp->i_d.di_flags & XFS_DIFLAG_PROJINHERIT)
+ 		prid = xfs_get_projid(dp);
+ 	else
+ 		prid = XFS_PROJID_DEFAULT;
+ 
+ 	/*
+ 	 * Make sure that we have allocated dquot(s) on disk.
+ 	 */
+ 	error = xfs_qm_vop_dqalloc(dp, current_fsuid(), current_fsgid(), prid,
+ 					XFS_QMOPT_QUOTALL | XFS_QMOPT_INHERIT,
+ 					&udqp, &gdqp, &pdqp);
+ 	if (error)
+ 		return error;
+ 
+ 	if (is_dir) {
+ 		rdev = 0;
+ 		resblks = XFS_MKDIR_SPACE_RES(mp, name->len);
+ 		tres.tr_logres = M_RES(mp)->tr_mkdir.tr_logres;
+ 		tres.tr_logcount = XFS_MKDIR_LOG_COUNT;
+ 		tp = xfs_trans_alloc(mp, XFS_TRANS_MKDIR);
+ 	} else {
+ 		resblks = XFS_CREATE_SPACE_RES(mp, name->len);
+ 		tres.tr_logres = M_RES(mp)->tr_create.tr_logres;
+ 		tres.tr_logcount = XFS_CREATE_LOG_COUNT;
+ 		tp = xfs_trans_alloc(mp, XFS_TRANS_CREATE);
+ 	}
+ 
+ 	cancel_flags = XFS_TRANS_RELEASE_LOG_RES;
+ 
+ 	/*
+ 	 * Initially assume that the file does not exist and
+ 	 * reserve the resources for that case.  If that is not
+ 	 * the case we'll drop the one we have and get a more
+ 	 * appropriate transaction later.
+ 	 */
+ 	tres.tr_logflags = XFS_TRANS_PERM_LOG_RES;
+ 	error = xfs_trans_reserve(tp, &tres, resblks, 0);
+ 	if (error == ENOSPC) {
+ 		/* flush outstanding delalloc blocks and retry */
+ 		xfs_flush_inodes(mp);
+ 		error = xfs_trans_reserve(tp, &tres, resblks, 0);
+ 	}
+ 	if (error == ENOSPC) {
+ 		/* No space at all so try a "no-allocation" reservation */
+ 		resblks = 0;
+ 		error = xfs_trans_reserve(tp, &tres, 0, 0);
+ 	}
+ 	if (error) {
+ 		cancel_flags = 0;
+ 		goto out_trans_cancel;
+ 	}
+ 
+ 	xfs_ilock(dp, XFS_ILOCK_EXCL | XFS_ILOCK_PARENT);
+ 	unlock_dp_on_error = true;
+ 
+ 	xfs_bmap_init(&free_list, &first_block);
+ 
+ 	/*
+ 	 * Reserve disk quota and the inode.
+ 	 */
+ 	error = xfs_trans_reserve_quota(tp, mp, udqp, gdqp,
+ 						pdqp, resblks, 1, 0);
+ 	if (error)
+ 		goto out_trans_cancel;
+ 
+ 	error = xfs_dir_canenter(tp, dp, name, resblks);
+ 	if (error)
+ 		goto out_trans_cancel;
+ 
+ 	/*
+ 	 * A newly created regular or special file just has one directory
+ 	 * entry pointing to them, but a directory also the "." entry
+ 	 * pointing to itself.
+ 	 */
+ 	error = xfs_dir_ialloc(&tp, dp, mode, is_dir ? 2 : 1, rdev,
+ 			       prid, resblks > 0, &ip, &committed);
+ 	if (error) {
+ 		if (error == ENOSPC)
+ 			goto out_trans_cancel;
+ 		goto out_trans_abort;
+ 	}
+ 
+ 	/*
+ 	 * Now we join the directory inode to the transaction.  We do not do it
+ 	 * earlier because xfs_dir_ialloc might commit the previous transaction
+ 	 * (and release all the locks).  An error from here on will result in
+ 	 * the transaction cancel unlocking dp so don't do it explicitly in the
+ 	 * error path.
+ 	 */
+ 	xfs_trans_ijoin(tp, dp, XFS_ILOCK_EXCL);
+ 	unlock_dp_on_error = false;
+ 
+ 	error = xfs_dir_createname(tp, dp, name, ip->i_ino,
+ 					&first_block, &free_list, resblks ?
+ 					resblks - XFS_IALLOC_SPACE_RES(mp) : 0);
+ 	if (error) {
+ 		ASSERT(error != ENOSPC);
+ 		goto out_trans_abort;
+ 	}
+ 	xfs_trans_ichgtime(tp, dp, XFS_ICHGTIME_MOD | XFS_ICHGTIME_CHG);
+ 	xfs_trans_log_inode(tp, dp, XFS_ILOG_CORE);
+ 
+ 	if (is_dir) {
+ 		error = xfs_dir_init(tp, ip, dp);
+ 		if (error)
+ 			goto out_bmap_cancel;
+ 
+ 		error = xfs_bumplink(tp, dp);
+ 		if (error)
+ 			goto out_bmap_cancel;
+ 	}
+ 
+ 	/*
+ 	 * If this is a synchronous mount, make sure that the
+ 	 * create transaction goes to disk before returning to
+ 	 * the user.
+ 	 */
+ 	if (mp->m_flags & (XFS_MOUNT_WSYNC|XFS_MOUNT_DIRSYNC))
+ 		xfs_trans_set_sync(tp);
+ 
+ 	/*
+ 	 * Attach the dquot(s) to the inodes and modify them incore.
+ 	 * These ids of the inode couldn't have changed since the new
+ 	 * inode has been locked ever since it was created.
+ 	 */
+ 	xfs_qm_vop_create_dqattach(tp, ip, udqp, gdqp, pdqp);
+ 
+ 	error = xfs_bmap_finish(&tp, &free_list, &committed);
+ 	if (error)
+ 		goto out_bmap_cancel;
+ 
+ 	error = xfs_trans_commit(tp, XFS_TRANS_RELEASE_LOG_RES);
+ 	if (error)
+ 		goto out_release_inode;
+ 
+ 	xfs_qm_dqrele(udqp);
+ 	xfs_qm_dqrele(gdqp);
+ 	xfs_qm_dqrele(pdqp);
+ 
+ 	*ipp = ip;
+ 	return 0;
+ 
+  out_bmap_cancel:
+ 	xfs_bmap_cancel(&free_list);
+  out_trans_abort:
+ 	cancel_flags |= XFS_TRANS_ABORT;
+  out_trans_cancel:
+ 	xfs_trans_cancel(tp, cancel_flags);
+  out_release_inode:
+ 	/*
+ 	 * Wait until after the current transaction is aborted to
+ 	 * release the inode.  This prevents recursive transactions
+ 	 * and deadlocks from xfs_inactive.
+ 	 */
+ 	if (ip)
+ 		IRELE(ip);
+ 
+ 	xfs_qm_dqrele(udqp);
+ 	xfs_qm_dqrele(gdqp);
+ 	xfs_qm_dqrele(pdqp);
+ 
+ 	if (unlock_dp_on_error)
+ 		xfs_iunlock(dp, XFS_ILOCK_EXCL);
+ 	return error;
+ }
+ 
+ int
+ xfs_link(
+ 	xfs_inode_t		*tdp,
+ 	xfs_inode_t		*sip,
+ 	struct xfs_name		*target_name)
+ {
+ 	xfs_mount_t		*mp = tdp->i_mount;
+ 	xfs_trans_t		*tp;
+ 	int			error;
+ 	xfs_bmap_free_t         free_list;
+ 	xfs_fsblock_t           first_block;
+ 	int			cancel_flags;
+ 	int			committed;
+ 	int			resblks;
+ 
+ 	trace_xfs_link(tdp, target_name);
+ 
+ 	ASSERT(!S_ISDIR(sip->i_d.di_mode));
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		return XFS_ERROR(EIO);
+ 
+ 	error = xfs_qm_dqattach(sip, 0);
+ 	if (error)
+ 		goto std_return;
+ 
+ 	error = xfs_qm_dqattach(tdp, 0);
+ 	if (error)
+ 		goto std_return;
+ 
+ 	tp = xfs_trans_alloc(mp, XFS_TRANS_LINK);
+ 	cancel_flags = XFS_TRANS_RELEASE_LOG_RES;
+ 	resblks = XFS_LINK_SPACE_RES(mp, target_name->len);
+ 	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_link, resblks, 0);
+ 	if (error == ENOSPC) {
+ 		resblks = 0;
+ 		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_link, 0, 0);
+ 	}
+ 	if (error) {
+ 		cancel_flags = 0;
+ 		goto error_return;
+ 	}
+ 
+ 	xfs_lock_two_inodes(sip, tdp, XFS_ILOCK_EXCL);
+ 
+ 	xfs_trans_ijoin(tp, sip, XFS_ILOCK_EXCL);
+ 	xfs_trans_ijoin(tp, tdp, XFS_ILOCK_EXCL);
+ 
+ 	/*
+ 	 * If we are using project inheritance, we only allow hard link
+ 	 * creation in our tree when the project IDs are the same; else
+ 	 * the tree quota mechanism could be circumvented.
+ 	 */
+ 	if (unlikely((tdp->i_d.di_flags & XFS_DIFLAG_PROJINHERIT) &&
+ 		     (xfs_get_projid(tdp) != xfs_get_projid(sip)))) {
+ 		error = XFS_ERROR(EXDEV);
+ 		goto error_return;
+ 	}
+ 
+ 	error = xfs_dir_canenter(tp, tdp, target_name, resblks);
+ 	if (error)
+ 		goto error_return;
+ 
+ 	xfs_bmap_init(&free_list, &first_block);
+ 
+ 	error = xfs_dir_createname(tp, tdp, target_name, sip->i_ino,
+ 					&first_block, &free_list, resblks);
+ 	if (error)
+ 		goto abort_return;
+ 	xfs_trans_ichgtime(tp, tdp, XFS_ICHGTIME_MOD | XFS_ICHGTIME_CHG);
+ 	xfs_trans_log_inode(tp, tdp, XFS_ILOG_CORE);
+ 
+ 	error = xfs_bumplink(tp, sip);
+ 	if (error)
+ 		goto abort_return;
+ 
+ 	/*
+ 	 * If this is a synchronous mount, make sure that the
+ 	 * link transaction goes to disk before returning to
+ 	 * the user.
+ 	 */
+ 	if (mp->m_flags & (XFS_MOUNT_WSYNC|XFS_MOUNT_DIRSYNC)) {
+ 		xfs_trans_set_sync(tp);
+ 	}
+ 
+ 	error = xfs_bmap_finish (&tp, &free_list, &committed);
+ 	if (error) {
+ 		xfs_bmap_cancel(&free_list);
+ 		goto abort_return;
+ 	}
+ 
+ 	return xfs_trans_commit(tp, XFS_TRANS_RELEASE_LOG_RES);
+ 
+  abort_return:
+ 	cancel_flags |= XFS_TRANS_ABORT;
+  error_return:
+ 	xfs_trans_cancel(tp, cancel_flags);
+  std_return:
+ 	return error;
+ }
+ 
+ /*
++>>>>>>> 3d3c8b5222b9 (xfs: refactor xfs_trans_reserve() interface)
   * Free up the underlying blocks past new_size.  The new size must be smaller
   * than the current size.  This routine can be used both for the attribute and
   * data fork, and does not modify the inode size, which is left to the caller.
@@@ -771,6 -1573,271 +1347,274 @@@ out_bmap_cancel
  	goto out;
  }
  
++<<<<<<< HEAD
++=======
+ int
+ xfs_release(
+ 	xfs_inode_t	*ip)
+ {
+ 	xfs_mount_t	*mp = ip->i_mount;
+ 	int		error;
+ 
+ 	if (!S_ISREG(ip->i_d.di_mode) || (ip->i_d.di_mode == 0))
+ 		return 0;
+ 
+ 	/* If this is a read-only mount, don't do this (would generate I/O) */
+ 	if (mp->m_flags & XFS_MOUNT_RDONLY)
+ 		return 0;
+ 
+ 	if (!XFS_FORCED_SHUTDOWN(mp)) {
+ 		int truncated;
+ 
+ 		/*
+ 		 * If we are using filestreams, and we have an unlinked
+ 		 * file that we are processing the last close on, then nothing
+ 		 * will be able to reopen and write to this file. Purge this
+ 		 * inode from the filestreams cache so that it doesn't delay
+ 		 * teardown of the inode.
+ 		 */
+ 		if ((ip->i_d.di_nlink == 0) && xfs_inode_is_filestream(ip))
+ 			xfs_filestream_deassociate(ip);
+ 
+ 		/*
+ 		 * If we previously truncated this file and removed old data
+ 		 * in the process, we want to initiate "early" writeout on
+ 		 * the last close.  This is an attempt to combat the notorious
+ 		 * NULL files problem which is particularly noticeable from a
+ 		 * truncate down, buffered (re-)write (delalloc), followed by
+ 		 * a crash.  What we are effectively doing here is
+ 		 * significantly reducing the time window where we'd otherwise
+ 		 * be exposed to that problem.
+ 		 */
+ 		truncated = xfs_iflags_test_and_clear(ip, XFS_ITRUNCATED);
+ 		if (truncated) {
+ 			xfs_iflags_clear(ip, XFS_IDIRTY_RELEASE);
+ 			if (VN_DIRTY(VFS_I(ip)) && ip->i_delayed_blks > 0) {
+ 				error = -filemap_flush(VFS_I(ip)->i_mapping);
+ 				if (error)
+ 					return error;
+ 			}
+ 		}
+ 	}
+ 
+ 	if (ip->i_d.di_nlink == 0)
+ 		return 0;
+ 
+ 	if (xfs_can_free_eofblocks(ip, false)) {
+ 
+ 		/*
+ 		 * If we can't get the iolock just skip truncating the blocks
+ 		 * past EOF because we could deadlock with the mmap_sem
+ 		 * otherwise.  We'll get another chance to drop them once the
+ 		 * last reference to the inode is dropped, so we'll never leak
+ 		 * blocks permanently.
+ 		 *
+ 		 * Further, check if the inode is being opened, written and
+ 		 * closed frequently and we have delayed allocation blocks
+ 		 * outstanding (e.g. streaming writes from the NFS server),
+ 		 * truncating the blocks past EOF will cause fragmentation to
+ 		 * occur.
+ 		 *
+ 		 * In this case don't do the truncation, either, but we have to
+ 		 * be careful how we detect this case. Blocks beyond EOF show
+ 		 * up as i_delayed_blks even when the inode is clean, so we
+ 		 * need to truncate them away first before checking for a dirty
+ 		 * release. Hence on the first dirty close we will still remove
+ 		 * the speculative allocation, but after that we will leave it
+ 		 * in place.
+ 		 */
+ 		if (xfs_iflags_test(ip, XFS_IDIRTY_RELEASE))
+ 			return 0;
+ 
+ 		error = xfs_free_eofblocks(mp, ip, true);
+ 		if (error && error != EAGAIN)
+ 			return error;
+ 
+ 		/* delalloc blocks after truncation means it really is dirty */
+ 		if (ip->i_delayed_blks)
+ 			xfs_iflags_set(ip, XFS_IDIRTY_RELEASE);
+ 	}
+ 	return 0;
+ }
+ 
+ /*
+  * xfs_inactive
+  *
+  * This is called when the vnode reference count for the vnode
+  * goes to zero.  If the file has been unlinked, then it must
+  * now be truncated.  Also, we clear all of the read-ahead state
+  * kept for the inode here since the file is now closed.
+  */
+ int
+ xfs_inactive(
+ 	xfs_inode_t	*ip)
+ {
+ 	xfs_bmap_free_t		free_list;
+ 	xfs_fsblock_t		first_block;
+ 	int			committed;
+ 	struct xfs_trans	*tp;
+ 	struct xfs_mount	*mp;
+ 	struct xfs_trans_res	*resp;
+ 	int			error;
+ 	int			truncate = 0;
+ 
+ 	/*
+ 	 * If the inode is already free, then there can be nothing
+ 	 * to clean up here.
+ 	 */
+ 	if (ip->i_d.di_mode == 0 || is_bad_inode(VFS_I(ip))) {
+ 		ASSERT(ip->i_df.if_real_bytes == 0);
+ 		ASSERT(ip->i_df.if_broot_bytes == 0);
+ 		return VN_INACTIVE_CACHE;
+ 	}
+ 
+ 	mp = ip->i_mount;
+ 
+ 	error = 0;
+ 
+ 	/* If this is a read-only mount, don't do this (would generate I/O) */
+ 	if (mp->m_flags & XFS_MOUNT_RDONLY)
+ 		goto out;
+ 
+ 	if (ip->i_d.di_nlink != 0) {
+ 		/*
+ 		 * force is true because we are evicting an inode from the
+ 		 * cache. Post-eof blocks must be freed, lest we end up with
+ 		 * broken free space accounting.
+ 		 */
+ 		if (xfs_can_free_eofblocks(ip, true)) {
+ 			error = xfs_free_eofblocks(mp, ip, false);
+ 			if (error)
+ 				return VN_INACTIVE_CACHE;
+ 		}
+ 		goto out;
+ 	}
+ 
+ 	if (S_ISREG(ip->i_d.di_mode) &&
+ 	    (ip->i_d.di_size != 0 || XFS_ISIZE(ip) != 0 ||
+ 	     ip->i_d.di_nextents > 0 || ip->i_delayed_blks > 0))
+ 		truncate = 1;
+ 
+ 	error = xfs_qm_dqattach(ip, 0);
+ 	if (error)
+ 		return VN_INACTIVE_CACHE;
+ 
+ 	tp = xfs_trans_alloc(mp, XFS_TRANS_INACTIVE);
+ 	resp = (truncate || S_ISLNK(ip->i_d.di_mode)) ?
+ 		&M_RES(mp)->tr_itruncate : &M_RES(mp)->tr_ifree;
+ 
+ 	error = xfs_trans_reserve(tp, resp, 0, 0);
+ 	if (error) {
+ 		ASSERT(XFS_FORCED_SHUTDOWN(mp));
+ 		xfs_trans_cancel(tp, 0);
+ 		return VN_INACTIVE_CACHE;
+ 	}
+ 
+ 	xfs_ilock(ip, XFS_ILOCK_EXCL);
+ 	xfs_trans_ijoin(tp, ip, 0);
+ 
+ 	if (S_ISLNK(ip->i_d.di_mode)) {
+ 		error = xfs_inactive_symlink(ip, &tp);
+ 		if (error)
+ 			goto out_cancel;
+ 	} else if (truncate) {
+ 		ip->i_d.di_size = 0;
+ 		xfs_trans_log_inode(tp, ip, XFS_ILOG_CORE);
+ 
+ 		error = xfs_itruncate_extents(&tp, ip, XFS_DATA_FORK, 0);
+ 		if (error)
+ 			goto out_cancel;
+ 
+ 		ASSERT(ip->i_d.di_nextents == 0);
+ 	}
+ 
+ 	/*
+ 	 * If there are attributes associated with the file then blow them away
+ 	 * now.  The code calls a routine that recursively deconstructs the
+ 	 * attribute fork.  We need to just commit the current transaction
+ 	 * because we can't use it for xfs_attr_inactive().
+ 	 */
+ 	if (ip->i_d.di_anextents > 0) {
+ 		ASSERT(ip->i_d.di_forkoff != 0);
+ 
+ 		error = xfs_trans_commit(tp, XFS_TRANS_RELEASE_LOG_RES);
+ 		if (error)
+ 			goto out_unlock;
+ 
+ 		xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ 
+ 		error = xfs_attr_inactive(ip);
+ 		if (error)
+ 			goto out;
+ 
+ 		tp = xfs_trans_alloc(mp, XFS_TRANS_INACTIVE);
+ 		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_ifree, 0, 0);
+ 		if (error) {
+ 			xfs_trans_cancel(tp, 0);
+ 			goto out;
+ 		}
+ 
+ 		xfs_ilock(ip, XFS_ILOCK_EXCL);
+ 		xfs_trans_ijoin(tp, ip, 0);
+ 	}
+ 
+ 	if (ip->i_afp)
+ 		xfs_idestroy_fork(ip, XFS_ATTR_FORK);
+ 
+ 	ASSERT(ip->i_d.di_anextents == 0);
+ 
+ 	/*
+ 	 * Free the inode.
+ 	 */
+ 	xfs_bmap_init(&free_list, &first_block);
+ 	error = xfs_ifree(tp, ip, &free_list);
+ 	if (error) {
+ 		/*
+ 		 * If we fail to free the inode, shut down.  The cancel
+ 		 * might do that, we need to make sure.  Otherwise the
+ 		 * inode might be lost for a long time or forever.
+ 		 */
+ 		if (!XFS_FORCED_SHUTDOWN(mp)) {
+ 			xfs_notice(mp, "%s: xfs_ifree returned error %d",
+ 				__func__, error);
+ 			xfs_force_shutdown(mp, SHUTDOWN_META_IO_ERROR);
+ 		}
+ 		xfs_trans_cancel(tp, XFS_TRANS_RELEASE_LOG_RES|XFS_TRANS_ABORT);
+ 	} else {
+ 		/*
+ 		 * Credit the quota account(s). The inode is gone.
+ 		 */
+ 		xfs_trans_mod_dquot_byino(tp, ip, XFS_TRANS_DQ_ICOUNT, -1);
+ 
+ 		/*
+ 		 * Just ignore errors at this point.  There is nothing we can
+ 		 * do except to try to keep going. Make sure it's not a silent
+ 		 * error.
+ 		 */
+ 		error = xfs_bmap_finish(&tp,  &free_list, &committed);
+ 		if (error)
+ 			xfs_notice(mp, "%s: xfs_bmap_finish returned error %d",
+ 				__func__, error);
+ 		error = xfs_trans_commit(tp, XFS_TRANS_RELEASE_LOG_RES);
+ 		if (error)
+ 			xfs_notice(mp, "%s: xfs_trans_commit returned error %d",
+ 				__func__, error);
+ 	}
+ 
+ 	/*
+ 	 * Release the dquots held by inode, if any.
+ 	 */
+ 	xfs_qm_dqdetach(ip);
+ out_unlock:
+ 	xfs_iunlock(ip, XFS_ILOCK_EXCL);
+ out:
+ 	return VN_INACTIVE_CACHE;
+ out_cancel:
+ 	xfs_trans_cancel(tp, XFS_TRANS_RELEASE_LOG_RES | XFS_TRANS_ABORT);
+ 	goto out_unlock;
+ }
+ 
++>>>>>>> 3d3c8b5222b9 (xfs: refactor xfs_trans_reserve() interface)
  /*
   * This is called when the inode's link count goes to 0.
   * We place the on-disk inode on a list in the AGI.  It
@@@ -1302,6 -2369,473 +2146,476 @@@ xfs_iunpin_wait
  		__xfs_iunpin_wait(ip);
  }
  
++<<<<<<< HEAD
++=======
+ int
+ xfs_remove(
+ 	xfs_inode_t             *dp,
+ 	struct xfs_name		*name,
+ 	xfs_inode_t		*ip)
+ {
+ 	xfs_mount_t		*mp = dp->i_mount;
+ 	xfs_trans_t             *tp = NULL;
+ 	int			is_dir = S_ISDIR(ip->i_d.di_mode);
+ 	int                     error = 0;
+ 	xfs_bmap_free_t         free_list;
+ 	xfs_fsblock_t           first_block;
+ 	int			cancel_flags;
+ 	int			committed;
+ 	int			link_zero;
+ 	uint			resblks;
+ 	uint			log_count;
+ 
+ 	trace_xfs_remove(dp, name);
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		return XFS_ERROR(EIO);
+ 
+ 	error = xfs_qm_dqattach(dp, 0);
+ 	if (error)
+ 		goto std_return;
+ 
+ 	error = xfs_qm_dqattach(ip, 0);
+ 	if (error)
+ 		goto std_return;
+ 
+ 	if (is_dir) {
+ 		tp = xfs_trans_alloc(mp, XFS_TRANS_RMDIR);
+ 		log_count = XFS_DEFAULT_LOG_COUNT;
+ 	} else {
+ 		tp = xfs_trans_alloc(mp, XFS_TRANS_REMOVE);
+ 		log_count = XFS_REMOVE_LOG_COUNT;
+ 	}
+ 	cancel_flags = XFS_TRANS_RELEASE_LOG_RES;
+ 
+ 	/*
+ 	 * We try to get the real space reservation first,
+ 	 * allowing for directory btree deletion(s) implying
+ 	 * possible bmap insert(s).  If we can't get the space
+ 	 * reservation then we use 0 instead, and avoid the bmap
+ 	 * btree insert(s) in the directory code by, if the bmap
+ 	 * insert tries to happen, instead trimming the LAST
+ 	 * block from the directory.
+ 	 */
+ 	resblks = XFS_REMOVE_SPACE_RES(mp);
+ 	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_remove, resblks, 0);
+ 	if (error == ENOSPC) {
+ 		resblks = 0;
+ 		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_remove, 0, 0);
+ 	}
+ 	if (error) {
+ 		ASSERT(error != ENOSPC);
+ 		cancel_flags = 0;
+ 		goto out_trans_cancel;
+ 	}
+ 
+ 	xfs_lock_two_inodes(dp, ip, XFS_ILOCK_EXCL);
+ 
+ 	xfs_trans_ijoin(tp, dp, XFS_ILOCK_EXCL);
+ 	xfs_trans_ijoin(tp, ip, XFS_ILOCK_EXCL);
+ 
+ 	/*
+ 	 * If we're removing a directory perform some additional validation.
+ 	 */
+ 	if (is_dir) {
+ 		ASSERT(ip->i_d.di_nlink >= 2);
+ 		if (ip->i_d.di_nlink != 2) {
+ 			error = XFS_ERROR(ENOTEMPTY);
+ 			goto out_trans_cancel;
+ 		}
+ 		if (!xfs_dir_isempty(ip)) {
+ 			error = XFS_ERROR(ENOTEMPTY);
+ 			goto out_trans_cancel;
+ 		}
+ 	}
+ 
+ 	xfs_bmap_init(&free_list, &first_block);
+ 	error = xfs_dir_removename(tp, dp, name, ip->i_ino,
+ 					&first_block, &free_list, resblks);
+ 	if (error) {
+ 		ASSERT(error != ENOENT);
+ 		goto out_bmap_cancel;
+ 	}
+ 	xfs_trans_ichgtime(tp, dp, XFS_ICHGTIME_MOD | XFS_ICHGTIME_CHG);
+ 
+ 	if (is_dir) {
+ 		/*
+ 		 * Drop the link from ip's "..".
+ 		 */
+ 		error = xfs_droplink(tp, dp);
+ 		if (error)
+ 			goto out_bmap_cancel;
+ 
+ 		/*
+ 		 * Drop the "." link from ip to self.
+ 		 */
+ 		error = xfs_droplink(tp, ip);
+ 		if (error)
+ 			goto out_bmap_cancel;
+ 	} else {
+ 		/*
+ 		 * When removing a non-directory we need to log the parent
+ 		 * inode here.  For a directory this is done implicitly
+ 		 * by the xfs_droplink call for the ".." entry.
+ 		 */
+ 		xfs_trans_log_inode(tp, dp, XFS_ILOG_CORE);
+ 	}
+ 
+ 	/*
+ 	 * Drop the link from dp to ip.
+ 	 */
+ 	error = xfs_droplink(tp, ip);
+ 	if (error)
+ 		goto out_bmap_cancel;
+ 
+ 	/*
+ 	 * Determine if this is the last link while
+ 	 * we are in the transaction.
+ 	 */
+ 	link_zero = (ip->i_d.di_nlink == 0);
+ 
+ 	/*
+ 	 * If this is a synchronous mount, make sure that the
+ 	 * remove transaction goes to disk before returning to
+ 	 * the user.
+ 	 */
+ 	if (mp->m_flags & (XFS_MOUNT_WSYNC|XFS_MOUNT_DIRSYNC))
+ 		xfs_trans_set_sync(tp);
+ 
+ 	error = xfs_bmap_finish(&tp, &free_list, &committed);
+ 	if (error)
+ 		goto out_bmap_cancel;
+ 
+ 	error = xfs_trans_commit(tp, XFS_TRANS_RELEASE_LOG_RES);
+ 	if (error)
+ 		goto std_return;
+ 
+ 	/*
+ 	 * If we are using filestreams, kill the stream association.
+ 	 * If the file is still open it may get a new one but that
+ 	 * will get killed on last close in xfs_close() so we don't
+ 	 * have to worry about that.
+ 	 */
+ 	if (!is_dir && link_zero && xfs_inode_is_filestream(ip))
+ 		xfs_filestream_deassociate(ip);
+ 
+ 	return 0;
+ 
+  out_bmap_cancel:
+ 	xfs_bmap_cancel(&free_list);
+ 	cancel_flags |= XFS_TRANS_ABORT;
+  out_trans_cancel:
+ 	xfs_trans_cancel(tp, cancel_flags);
+  std_return:
+ 	return error;
+ }
+ 
+ /*
+  * Enter all inodes for a rename transaction into a sorted array.
+  */
+ STATIC void
+ xfs_sort_for_rename(
+ 	xfs_inode_t	*dp1,	/* in: old (source) directory inode */
+ 	xfs_inode_t	*dp2,	/* in: new (target) directory inode */
+ 	xfs_inode_t	*ip1,	/* in: inode of old entry */
+ 	xfs_inode_t	*ip2,	/* in: inode of new entry, if it
+ 				   already exists, NULL otherwise. */
+ 	xfs_inode_t	**i_tab,/* out: array of inode returned, sorted */
+ 	int		*num_inodes)  /* out: number of inodes in array */
+ {
+ 	xfs_inode_t		*temp;
+ 	int			i, j;
+ 
+ 	/*
+ 	 * i_tab contains a list of pointers to inodes.  We initialize
+ 	 * the table here & we'll sort it.  We will then use it to
+ 	 * order the acquisition of the inode locks.
+ 	 *
+ 	 * Note that the table may contain duplicates.  e.g., dp1 == dp2.
+ 	 */
+ 	i_tab[0] = dp1;
+ 	i_tab[1] = dp2;
+ 	i_tab[2] = ip1;
+ 	if (ip2) {
+ 		*num_inodes = 4;
+ 		i_tab[3] = ip2;
+ 	} else {
+ 		*num_inodes = 3;
+ 		i_tab[3] = NULL;
+ 	}
+ 
+ 	/*
+ 	 * Sort the elements via bubble sort.  (Remember, there are at
+ 	 * most 4 elements to sort, so this is adequate.)
+ 	 */
+ 	for (i = 0; i < *num_inodes; i++) {
+ 		for (j = 1; j < *num_inodes; j++) {
+ 			if (i_tab[j]->i_ino < i_tab[j-1]->i_ino) {
+ 				temp = i_tab[j];
+ 				i_tab[j] = i_tab[j-1];
+ 				i_tab[j-1] = temp;
+ 			}
+ 		}
+ 	}
+ }
+ 
+ /*
+  * xfs_rename
+  */
+ int
+ xfs_rename(
+ 	xfs_inode_t	*src_dp,
+ 	struct xfs_name	*src_name,
+ 	xfs_inode_t	*src_ip,
+ 	xfs_inode_t	*target_dp,
+ 	struct xfs_name	*target_name,
+ 	xfs_inode_t	*target_ip)
+ {
+ 	xfs_trans_t	*tp = NULL;
+ 	xfs_mount_t	*mp = src_dp->i_mount;
+ 	int		new_parent;		/* moving to a new dir */
+ 	int		src_is_directory;	/* src_name is a directory */
+ 	int		error;
+ 	xfs_bmap_free_t free_list;
+ 	xfs_fsblock_t   first_block;
+ 	int		cancel_flags;
+ 	int		committed;
+ 	xfs_inode_t	*inodes[4];
+ 	int		spaceres;
+ 	int		num_inodes;
+ 
+ 	trace_xfs_rename(src_dp, target_dp, src_name, target_name);
+ 
+ 	new_parent = (src_dp != target_dp);
+ 	src_is_directory = S_ISDIR(src_ip->i_d.di_mode);
+ 
+ 	xfs_sort_for_rename(src_dp, target_dp, src_ip, target_ip,
+ 				inodes, &num_inodes);
+ 
+ 	xfs_bmap_init(&free_list, &first_block);
+ 	tp = xfs_trans_alloc(mp, XFS_TRANS_RENAME);
+ 	cancel_flags = XFS_TRANS_RELEASE_LOG_RES;
+ 	spaceres = XFS_RENAME_SPACE_RES(mp, target_name->len);
+ 	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_rename, spaceres, 0);
+ 	if (error == ENOSPC) {
+ 		spaceres = 0;
+ 		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_rename, 0, 0);
+ 	}
+ 	if (error) {
+ 		xfs_trans_cancel(tp, 0);
+ 		goto std_return;
+ 	}
+ 
+ 	/*
+ 	 * Attach the dquots to the inodes
+ 	 */
+ 	error = xfs_qm_vop_rename_dqattach(inodes);
+ 	if (error) {
+ 		xfs_trans_cancel(tp, cancel_flags);
+ 		goto std_return;
+ 	}
+ 
+ 	/*
+ 	 * Lock all the participating inodes. Depending upon whether
+ 	 * the target_name exists in the target directory, and
+ 	 * whether the target directory is the same as the source
+ 	 * directory, we can lock from 2 to 4 inodes.
+ 	 */
+ 	xfs_lock_inodes(inodes, num_inodes, XFS_ILOCK_EXCL);
+ 
+ 	/*
+ 	 * Join all the inodes to the transaction. From this point on,
+ 	 * we can rely on either trans_commit or trans_cancel to unlock
+ 	 * them.
+ 	 */
+ 	xfs_trans_ijoin(tp, src_dp, XFS_ILOCK_EXCL);
+ 	if (new_parent)
+ 		xfs_trans_ijoin(tp, target_dp, XFS_ILOCK_EXCL);
+ 	xfs_trans_ijoin(tp, src_ip, XFS_ILOCK_EXCL);
+ 	if (target_ip)
+ 		xfs_trans_ijoin(tp, target_ip, XFS_ILOCK_EXCL);
+ 
+ 	/*
+ 	 * If we are using project inheritance, we only allow renames
+ 	 * into our tree when the project IDs are the same; else the
+ 	 * tree quota mechanism would be circumvented.
+ 	 */
+ 	if (unlikely((target_dp->i_d.di_flags & XFS_DIFLAG_PROJINHERIT) &&
+ 		     (xfs_get_projid(target_dp) != xfs_get_projid(src_ip)))) {
+ 		error = XFS_ERROR(EXDEV);
+ 		goto error_return;
+ 	}
+ 
+ 	/*
+ 	 * Set up the target.
+ 	 */
+ 	if (target_ip == NULL) {
+ 		/*
+ 		 * If there's no space reservation, check the entry will
+ 		 * fit before actually inserting it.
+ 		 */
+ 		error = xfs_dir_canenter(tp, target_dp, target_name, spaceres);
+ 		if (error)
+ 			goto error_return;
+ 		/*
+ 		 * If target does not exist and the rename crosses
+ 		 * directories, adjust the target directory link count
+ 		 * to account for the ".." reference from the new entry.
+ 		 */
+ 		error = xfs_dir_createname(tp, target_dp, target_name,
+ 						src_ip->i_ino, &first_block,
+ 						&free_list, spaceres);
+ 		if (error == ENOSPC)
+ 			goto error_return;
+ 		if (error)
+ 			goto abort_return;
+ 
+ 		xfs_trans_ichgtime(tp, target_dp,
+ 					XFS_ICHGTIME_MOD | XFS_ICHGTIME_CHG);
+ 
+ 		if (new_parent && src_is_directory) {
+ 			error = xfs_bumplink(tp, target_dp);
+ 			if (error)
+ 				goto abort_return;
+ 		}
+ 	} else { /* target_ip != NULL */
+ 		/*
+ 		 * If target exists and it's a directory, check that both
+ 		 * target and source are directories and that target can be
+ 		 * destroyed, or that neither is a directory.
+ 		 */
+ 		if (S_ISDIR(target_ip->i_d.di_mode)) {
+ 			/*
+ 			 * Make sure target dir is empty.
+ 			 */
+ 			if (!(xfs_dir_isempty(target_ip)) ||
+ 			    (target_ip->i_d.di_nlink > 2)) {
+ 				error = XFS_ERROR(EEXIST);
+ 				goto error_return;
+ 			}
+ 		}
+ 
+ 		/*
+ 		 * Link the source inode under the target name.
+ 		 * If the source inode is a directory and we are moving
+ 		 * it across directories, its ".." entry will be
+ 		 * inconsistent until we replace that down below.
+ 		 *
+ 		 * In case there is already an entry with the same
+ 		 * name at the destination directory, remove it first.
+ 		 */
+ 		error = xfs_dir_replace(tp, target_dp, target_name,
+ 					src_ip->i_ino,
+ 					&first_block, &free_list, spaceres);
+ 		if (error)
+ 			goto abort_return;
+ 
+ 		xfs_trans_ichgtime(tp, target_dp,
+ 					XFS_ICHGTIME_MOD | XFS_ICHGTIME_CHG);
+ 
+ 		/*
+ 		 * Decrement the link count on the target since the target
+ 		 * dir no longer points to it.
+ 		 */
+ 		error = xfs_droplink(tp, target_ip);
+ 		if (error)
+ 			goto abort_return;
+ 
+ 		if (src_is_directory) {
+ 			/*
+ 			 * Drop the link from the old "." entry.
+ 			 */
+ 			error = xfs_droplink(tp, target_ip);
+ 			if (error)
+ 				goto abort_return;
+ 		}
+ 	} /* target_ip != NULL */
+ 
+ 	/*
+ 	 * Remove the source.
+ 	 */
+ 	if (new_parent && src_is_directory) {
+ 		/*
+ 		 * Rewrite the ".." entry to point to the new
+ 		 * directory.
+ 		 */
+ 		error = xfs_dir_replace(tp, src_ip, &xfs_name_dotdot,
+ 					target_dp->i_ino,
+ 					&first_block, &free_list, spaceres);
+ 		ASSERT(error != EEXIST);
+ 		if (error)
+ 			goto abort_return;
+ 	}
+ 
+ 	/*
+ 	 * We always want to hit the ctime on the source inode.
+ 	 *
+ 	 * This isn't strictly required by the standards since the source
+ 	 * inode isn't really being changed, but old unix file systems did
+ 	 * it and some incremental backup programs won't work without it.
+ 	 */
+ 	xfs_trans_ichgtime(tp, src_ip, XFS_ICHGTIME_CHG);
+ 	xfs_trans_log_inode(tp, src_ip, XFS_ILOG_CORE);
+ 
+ 	/*
+ 	 * Adjust the link count on src_dp.  This is necessary when
+ 	 * renaming a directory, either within one parent when
+ 	 * the target existed, or across two parent directories.
+ 	 */
+ 	if (src_is_directory && (new_parent || target_ip != NULL)) {
+ 
+ 		/*
+ 		 * Decrement link count on src_directory since the
+ 		 * entry that's moved no longer points to it.
+ 		 */
+ 		error = xfs_droplink(tp, src_dp);
+ 		if (error)
+ 			goto abort_return;
+ 	}
+ 
+ 	error = xfs_dir_removename(tp, src_dp, src_name, src_ip->i_ino,
+ 					&first_block, &free_list, spaceres);
+ 	if (error)
+ 		goto abort_return;
+ 
+ 	xfs_trans_ichgtime(tp, src_dp, XFS_ICHGTIME_MOD | XFS_ICHGTIME_CHG);
+ 	xfs_trans_log_inode(tp, src_dp, XFS_ILOG_CORE);
+ 	if (new_parent)
+ 		xfs_trans_log_inode(tp, target_dp, XFS_ILOG_CORE);
+ 
+ 	/*
+ 	 * If this is a synchronous mount, make sure that the
+ 	 * rename transaction goes to disk before returning to
+ 	 * the user.
+ 	 */
+ 	if (mp->m_flags & (XFS_MOUNT_WSYNC|XFS_MOUNT_DIRSYNC)) {
+ 		xfs_trans_set_sync(tp);
+ 	}
+ 
+ 	error = xfs_bmap_finish(&tp, &free_list, &committed);
+ 	if (error) {
+ 		xfs_bmap_cancel(&free_list);
+ 		xfs_trans_cancel(tp, (XFS_TRANS_RELEASE_LOG_RES |
+ 				 XFS_TRANS_ABORT));
+ 		goto std_return;
+ 	}
+ 
+ 	/*
+ 	 * trans_commit will unlock src_ip, target_ip & decrement
+ 	 * the vnode references.
+ 	 */
+ 	return xfs_trans_commit(tp, XFS_TRANS_RELEASE_LOG_RES);
+ 
+  abort_return:
+ 	cancel_flags |= XFS_TRANS_ABORT;
+  error_return:
+ 	xfs_bmap_cancel(&free_list);
+ 	xfs_trans_cancel(tp, cancel_flags);
+  std_return:
+ 	return error;
+ }
+ 
++>>>>>>> 3d3c8b5222b9 (xfs: refactor xfs_trans_reserve() interface)
  STATIC int
  xfs_iflush_cluster(
  	xfs_inode_t	*ip,
diff --cc fs/xfs/xfs_ioctl.c
index 06ffaf7b9722,e9c17e2ed6d7..000000000000
--- a/fs/xfs/xfs_ioctl.c
+++ b/fs/xfs/xfs_ioctl.c
@@@ -352,6 -350,40 +352,43 @@@ xfs_readlink_by_handle
  	return error;
  }
  
++<<<<<<< HEAD
++=======
+ int
+ xfs_set_dmattrs(
+ 	xfs_inode_t     *ip,
+ 	u_int		evmask,
+ 	u_int16_t	state)
+ {
+ 	xfs_mount_t	*mp = ip->i_mount;
+ 	xfs_trans_t	*tp;
+ 	int		error;
+ 
+ 	if (!capable(CAP_SYS_ADMIN))
+ 		return XFS_ERROR(EPERM);
+ 
+ 	if (XFS_FORCED_SHUTDOWN(mp))
+ 		return XFS_ERROR(EIO);
+ 
+ 	tp = xfs_trans_alloc(mp, XFS_TRANS_SET_DMATTRS);
+ 	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_ichange, 0, 0);
+ 	if (error) {
+ 		xfs_trans_cancel(tp, 0);
+ 		return error;
+ 	}
+ 	xfs_ilock(ip, XFS_ILOCK_EXCL);
+ 	xfs_trans_ijoin(tp, ip, XFS_ILOCK_EXCL);
+ 
+ 	ip->i_d.di_dmevmask = evmask;
+ 	ip->i_d.di_dmstate  = state;
+ 
+ 	xfs_trans_log_inode(tp, ip, XFS_ILOG_CORE);
+ 	error = xfs_trans_commit(tp, 0);
+ 
+ 	return error;
+ }
+ 
++>>>>>>> 3d3c8b5222b9 (xfs: refactor xfs_trans_reserve() interface)
  STATIC int
  xfs_fssetdm_by_handle(
  	struct file		*parfilp,
diff --git a/fs/xfs/xfs_aops.c b/fs/xfs/xfs_aops.c
index 1bd852dcd7f3..536d393dcc7b 100644
--- a/fs/xfs/xfs_aops.c
+++ b/fs/xfs/xfs_aops.c
@@ -117,7 +117,7 @@ xfs_setfilesize_trans_alloc(
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_FSYNC_TS);
 
-	error = xfs_trans_reserve(tp, 0, XFS_FSYNC_TS_LOG_RES(mp), 0, 0, 0);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_fsyncts, 0, 0);
 	if (error) {
 		xfs_trans_cancel(tp, 0);
 		return error;
diff --git a/fs/xfs/xfs_attr.c b/fs/xfs/xfs_attr.c
index 91acc38f664b..565c5c4b119b 100644
--- a/fs/xfs/xfs_attr.c
+++ b/fs/xfs/xfs_attr.c
@@ -227,13 +227,14 @@ xfs_attr_set_int(
 	int		valuelen,
 	int		flags)
 {
-	xfs_da_args_t	args;
-	xfs_fsblock_t	firstblock;
-	xfs_bmap_free_t flist;
-	int		error, err2, committed;
-	xfs_mount_t	*mp = dp->i_mount;
-	int             rsvd = (flags & ATTR_ROOT) != 0;
-	int		local;
+	xfs_da_args_t		args;
+	xfs_fsblock_t		firstblock;
+	xfs_bmap_free_t		flist;
+	int			error, err2, committed;
+	struct xfs_mount	*mp = dp->i_mount;
+	struct xfs_trans_res	tres;
+	int			rsvd = (flags & ATTR_ROOT) != 0;
+	int			local;
 
 	/*
 	 * Attach the dquots to the inode.
@@ -293,11 +294,11 @@ xfs_attr_set_int(
 	if (rsvd)
 		args.trans->t_flags |= XFS_TRANS_RESERVE;
 
-	error = xfs_trans_reserve(args.trans, args.total,
-				  XFS_ATTRSETM_LOG_RES(mp) +
-				  XFS_ATTRSETRT_LOG_RES(mp) * args.total,
-				  0, XFS_TRANS_PERM_LOG_RES,
-				  XFS_ATTRSET_LOG_COUNT);
+	tres.tr_logres = M_RES(mp)->tr_attrsetm.tr_logres +
+			 M_RES(mp)->tr_attrsetrt.tr_logres * args.total;
+	tres.tr_logcount = XFS_ATTRSET_LOG_COUNT;
+	tres.tr_logflags = XFS_TRANS_PERM_LOG_RES;
+	error = xfs_trans_reserve(args.trans, &tres, args.total, 0);
 	if (error) {
 		xfs_trans_cancel(args.trans, 0);
 		return(error);
@@ -517,11 +518,9 @@ xfs_attr_remove_int(xfs_inode_t *dp, struct xfs_name *name, int flags)
 	if (flags & ATTR_ROOT)
 		args.trans->t_flags |= XFS_TRANS_RESERVE;
 
-	if ((error = xfs_trans_reserve(args.trans,
-				      XFS_ATTRRM_SPACE_RES(mp),
-				      XFS_ATTRRM_LOG_RES(mp),
-				      0, XFS_TRANS_PERM_LOG_RES,
-				      XFS_ATTRRM_LOG_COUNT))) {
+	error = xfs_trans_reserve(args.trans, &M_RES(mp)->tr_attrrm,
+				  XFS_ATTRRM_SPACE_RES(mp), 0);
+	if (error) {
 		xfs_trans_cancel(args.trans, 0);
 		return(error);
 	}
diff --git a/fs/xfs/xfs_attr_inactive.c b/fs/xfs/xfs_attr_inactive.c
index ace95e791311..bb24b07cbedb 100644
--- a/fs/xfs/xfs_attr_inactive.c
+++ b/fs/xfs/xfs_attr_inactive.c
@@ -412,9 +412,8 @@ xfs_attr_inactive(xfs_inode_t *dp)
 	 * the log.
 	 */
 	trans = xfs_trans_alloc(mp, XFS_TRANS_ATTRINVAL);
-	if ((error = xfs_trans_reserve(trans, 0, XFS_ATTRINVAL_LOG_RES(mp), 0,
-				      XFS_TRANS_PERM_LOG_RES,
-				      XFS_ATTRINVAL_LOG_COUNT))) {
+	error = xfs_trans_reserve(trans, &M_RES(mp)->tr_attrinval, 0, 0);
+	if (error) {
 		xfs_trans_cancel(trans, 0);
 		return(error);
 	}
diff --git a/fs/xfs/xfs_bmap.c b/fs/xfs/xfs_bmap.c
index 51e6b204a8c4..e295f38d997c 100644
--- a/fs/xfs/xfs_bmap.c
+++ b/fs/xfs/xfs_bmap.c
@@ -1148,8 +1148,8 @@ xfs_bmap_add_attrfork(
 	blks = XFS_ADDAFORK_SPACE_RES(mp);
 	if (rsvd)
 		tp->t_flags |= XFS_TRANS_RESERVE;
-	if ((error = xfs_trans_reserve(tp, blks, XFS_ADDAFORK_LOG_RES(mp), 0,
-			XFS_TRANS_PERM_LOG_RES, XFS_ADDAFORK_LOG_COUNT)))
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_addafork, blks, 0);
+	if (error)
 		goto error0;
 	xfs_ilock(ip, XFS_ILOCK_EXCL);
 	error = xfs_trans_reserve_quota_nblks(tp, ip, blks, 0, rsvd ?
* Unmerged path fs/xfs/xfs_bmap_util.c
diff --git a/fs/xfs/xfs_dquot.c b/fs/xfs/xfs_dquot.c
index e90e123b0085..251c66632e5e 100644
--- a/fs/xfs/xfs_dquot.c
+++ b/fs/xfs/xfs_dquot.c
@@ -712,10 +712,8 @@ xfs_qm_dqread(
 
 	if (flags & XFS_QMOPT_DQALLOC) {
 		tp = xfs_trans_alloc(mp, XFS_TRANS_QM_DQALLOC);
-		error = xfs_trans_reserve(tp, XFS_QM_DQALLOC_SPACE_RES(mp),
-					  XFS_QM_DQALLOC_LOG_RES(mp), 0,
-					  XFS_TRANS_PERM_LOG_RES,
-					  XFS_WRITE_LOG_COUNT);
+		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_attrsetm,
+					  XFS_QM_DQALLOC_SPACE_RES(mp), 0);
 		if (error)
 			goto error1;
 		cancelflags = XFS_TRANS_RELEASE_LOG_RES;
diff --git a/fs/xfs/xfs_fsops.c b/fs/xfs/xfs_fsops.c
index 614eb0cc3608..e64ee5288b86 100644
--- a/fs/xfs/xfs_fsops.c
+++ b/fs/xfs/xfs_fsops.c
@@ -203,8 +203,9 @@ xfs_growfs_data_private(
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_GROWFS);
 	tp->t_flags |= XFS_TRANS_RESERVE;
-	if ((error = xfs_trans_reserve(tp, XFS_GROWFS_SPACE_RES(mp),
-			XFS_GROWDATA_LOG_RES(mp), 0, 0, 0))) {
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_growdata,
+				  XFS_GROWFS_SPACE_RES(mp), 0);
+	if (error) {
 		xfs_trans_cancel(tp, 0);
 		return error;
 	}
@@ -739,8 +740,7 @@ xfs_fs_log_dummy(
 	int		error;
 
 	tp = _xfs_trans_alloc(mp, XFS_TRANS_DUMMY1, KM_SLEEP);
-	error = xfs_trans_reserve(tp, 0, XFS_SB_LOG_RES(mp), 0, 0,
-				  XFS_DEFAULT_LOG_COUNT);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_sb, 0, 0);
 	if (error) {
 		xfs_trans_cancel(tp, 0);
 		return error;
* Unmerged path fs/xfs/xfs_inode.c
* Unmerged path fs/xfs/xfs_ioctl.c
diff --git a/fs/xfs/xfs_iomap.c b/fs/xfs/xfs_iomap.c
index b04a60f66411..a20e090c3d71 100644
--- a/fs/xfs/xfs_iomap.c
+++ b/fs/xfs/xfs_iomap.c
@@ -189,10 +189,8 @@ xfs_iomap_write_direct(
 	 * Allocate and setup the transaction
 	 */
 	tp = xfs_trans_alloc(mp, XFS_TRANS_DIOSTRAT);
-	error = xfs_trans_reserve(tp, resblks,
-			XFS_WRITE_LOG_RES(mp), resrtextents,
-			XFS_TRANS_PERM_LOG_RES,
-			XFS_WRITE_LOG_COUNT);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_write,
+				  resblks, resrtextents);
 	/*
 	 * Check for running out of space, note: need lock to return
 	 */
@@ -700,10 +698,8 @@ xfs_iomap_write_allocate(
 			tp = xfs_trans_alloc(mp, XFS_TRANS_STRAT_WRITE);
 			tp->t_flags |= XFS_TRANS_RESERVE;
 			nres = XFS_EXTENTADD_SPACE_RES(mp, XFS_DATA_FORK);
-			error = xfs_trans_reserve(tp, nres,
-					XFS_WRITE_LOG_RES(mp),
-					0, XFS_TRANS_PERM_LOG_RES,
-					XFS_WRITE_LOG_COUNT);
+			error = xfs_trans_reserve(tp, &M_RES(mp)->tr_write,
+						  nres, 0);
 			if (error) {
 				xfs_trans_cancel(tp, 0);
 				return XFS_ERROR(error);
@@ -866,10 +862,8 @@ xfs_iomap_write_unwritten(
 		sb_start_intwrite(mp->m_super);
 		tp = _xfs_trans_alloc(mp, XFS_TRANS_STRAT_WRITE, KM_NOFS);
 		tp->t_flags |= XFS_TRANS_RESERVE | XFS_TRANS_FREEZE_PROT;
-		error = xfs_trans_reserve(tp, resblks,
-				XFS_WRITE_LOG_RES(mp), 0,
-				XFS_TRANS_PERM_LOG_RES,
-				XFS_WRITE_LOG_COUNT);
+		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_write,
+					  resblks, 0);
 		if (error) {
 			xfs_trans_cancel(tp, 0);
 			return XFS_ERROR(error);
diff --git a/fs/xfs/xfs_iops.c b/fs/xfs/xfs_iops.c
index 17b70f0ccf8a..54ad80c10389 100644
--- a/fs/xfs/xfs_iops.c
+++ b/fs/xfs/xfs_iops.c
@@ -547,7 +547,7 @@ xfs_setattr_nonsize(
 	}
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_SETATTR_NOT_SIZE);
-	error = xfs_trans_reserve(tp, 0, XFS_ICHANGE_LOG_RES(mp), 0, 0, 0);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_ichange, 0, 0);
 	if (error)
 		goto out_dqrele;
 
@@ -809,9 +809,7 @@ xfs_setattr_size(
 		goto out_unlock;
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_SETATTR_SIZE);
-	error = xfs_trans_reserve(tp, 0, XFS_ITRUNCATE_LOG_RES(mp), 0,
-				 XFS_TRANS_PERM_LOG_RES,
-				 XFS_ITRUNCATE_LOG_COUNT);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_itruncate, 0, 0);
 	if (error)
 		goto out_trans_cancel;
 
@@ -934,7 +932,7 @@ xfs_vn_update_time(
 	trace_xfs_update_time(ip);
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_FSYNC_TS);
-	error = xfs_trans_reserve(tp, 0, XFS_FSYNC_TS_LOG_RES(mp), 0, 0, 0);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_fsyncts, 0, 0);
 	if (error) {
 		xfs_trans_cancel(tp, 0);
 		return -error;
diff --git a/fs/xfs/xfs_log_recover.c b/fs/xfs/xfs_log_recover.c
index 7e480860fa75..25746b846b2b 100644
--- a/fs/xfs/xfs_log_recover.c
+++ b/fs/xfs/xfs_log_recover.c
@@ -3378,7 +3378,7 @@ xlog_recover_process_efi(
 	}
 
 	tp = xfs_trans_alloc(mp, 0);
-	error = xfs_trans_reserve(tp, 0, XFS_ITRUNCATE_LOG_RES(mp), 0, 0, 0);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_itruncate, 0, 0);
 	if (error)
 		goto abort_error;
 	efdp = xfs_trans_get_efd(tp, efip, efip->efi_format.efi_nextents);
@@ -3484,8 +3484,7 @@ xlog_recover_clear_agi_bucket(
 	int		error;
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_CLEAR_AGI_BUCKET);
-	error = xfs_trans_reserve(tp, 0, XFS_CLEAR_AGI_BUCKET_LOG_RES(mp),
-				  0, 0, 0);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_clearagi, 0, 0);
 	if (error)
 		goto out_abort;
 
diff --git a/fs/xfs/xfs_mount.c b/fs/xfs/xfs_mount.c
index 4add3c6cf7b4..ce72b0052cf8 100644
--- a/fs/xfs/xfs_mount.c
+++ b/fs/xfs/xfs_mount.c
@@ -596,8 +596,7 @@ xfs_mount_reset_sbqflags(
 		return 0;
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_QM_SBCHANGE);
-	error = xfs_trans_reserve(tp, 0, XFS_QM_SBCHANGE_LOG_RES(mp),
-				  0, 0, XFS_DEFAULT_LOG_COUNT);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_qm_sbchange, 0, 0);
 	if (error) {
 		xfs_trans_cancel(tp, 0);
 		xfs_alert(mp, "%s: Superblock update failed!", __func__);
@@ -1070,8 +1069,7 @@ xfs_log_sbcount(xfs_mount_t *mp)
 		return 0;
 
 	tp = _xfs_trans_alloc(mp, XFS_TRANS_SB_COUNT, KM_SLEEP);
-	error = xfs_trans_reserve(tp, 0, XFS_SB_LOG_RES(mp), 0, 0,
-				  XFS_DEFAULT_LOG_COUNT);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_sb, 0, 0);
 	if (error) {
 		xfs_trans_cancel(tp, 0);
 		return error;
@@ -1391,8 +1389,7 @@ xfs_mount_log_sb(
 			 XFS_SB_VERSIONNUM));
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_SB_UNIT);
-	error = xfs_trans_reserve(tp, 0, XFS_SB_LOG_RES(mp), 0, 0,
-				  XFS_DEFAULT_LOG_COUNT);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_sb, 0, 0);
 	if (error) {
 		xfs_trans_cancel(tp, 0);
 		return error;
diff --git a/fs/xfs/xfs_qm.c b/fs/xfs/xfs_qm.c
index 92c36ac4bb23..b92583990644 100644
--- a/fs/xfs/xfs_qm.c
+++ b/fs/xfs/xfs_qm.c
@@ -866,11 +866,9 @@ xfs_qm_qino_alloc(
 	}
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_QM_QINOCREATE);
-	if ((error = xfs_trans_reserve(tp,
-				      XFS_QM_QINOCREATE_SPACE_RES(mp),
-				      XFS_CREATE_LOG_RES(mp), 0,
-				      XFS_TRANS_PERM_LOG_RES,
-				      XFS_CREATE_LOG_COUNT))) {
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_create,
+				  XFS_QM_QINOCREATE_SPACE_RES(mp), 0);
+	if (error) {
 		xfs_trans_cancel(tp, 0);
 		return error;
 	}
@@ -1741,8 +1739,7 @@ xfs_qm_write_sb_changes(
 	int		error;
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_QM_SBCHANGE);
-	error = xfs_trans_reserve(tp, 0, XFS_QM_SBCHANGE_LOG_RES(mp),
-				  0, 0, XFS_DEFAULT_LOG_COUNT);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_qm_sbchange, 0, 0);
 	if (error) {
 		xfs_trans_cancel(tp, 0);
 		return error;
diff --git a/fs/xfs/xfs_qm_syscalls.c b/fs/xfs/xfs_qm_syscalls.c
index 18519392c486..2c9e54c4305a 100644
--- a/fs/xfs/xfs_qm_syscalls.c
+++ b/fs/xfs/xfs_qm_syscalls.c
@@ -248,9 +248,7 @@ xfs_qm_scall_trunc_qfile(
 	xfs_ilock(ip, XFS_IOLOCK_EXCL);
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_TRUNCATE_FILE);
-	error = xfs_trans_reserve(tp, 0, XFS_ITRUNCATE_LOG_RES(mp), 0,
-				  XFS_TRANS_PERM_LOG_RES,
-				  XFS_ITRUNCATE_LOG_COUNT);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_itruncate, 0, 0);
 	if (error) {
 		xfs_trans_cancel(tp, 0);
 		xfs_iunlock(ip, XFS_IOLOCK_EXCL);
@@ -541,8 +539,7 @@ xfs_qm_scall_setqlim(
 	xfs_dqunlock(dqp);
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_QM_SETQLIM);
-	error = xfs_trans_reserve(tp, 0, XFS_QM_SETQLIM_LOG_RES(mp),
-				  0, 0, XFS_DEFAULT_LOG_COUNT);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_qm_setqlim, 0, 0);
 	if (error) {
 		xfs_trans_cancel(tp, 0);
 		goto out_rele;
@@ -676,8 +673,7 @@ xfs_qm_log_quotaoff_end(
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_QM_QUOTAOFF_END);
 
-	error = xfs_trans_reserve(tp, 0, XFS_QM_QUOTAOFF_END_LOG_RES(mp),
-				  0, 0, XFS_DEFAULT_LOG_COUNT);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_qm_equotaoff, 0, 0);
 	if (error) {
 		xfs_trans_cancel(tp, 0);
 		return (error);
@@ -710,8 +706,7 @@ xfs_qm_log_quotaoff(
 	uint			oldsbqflag=0;
 
 	tp = xfs_trans_alloc(mp, XFS_TRANS_QM_QUOTAOFF);
-	error = xfs_trans_reserve(tp, 0, XFS_QM_QUOTAOFF_LOG_RES(mp),
-				  0, 0, XFS_DEFAULT_LOG_COUNT);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_qm_quotaoff, 0, 0);
 	if (error)
 		goto error0;
 
diff --git a/fs/xfs/xfs_rtalloc.c b/fs/xfs/xfs_rtalloc.c
index 40794ea3acab..8ecde5a5e35b 100644
--- a/fs/xfs/xfs_rtalloc.c
+++ b/fs/xfs/xfs_rtalloc.c
@@ -102,10 +102,9 @@ xfs_growfs_rt_alloc(
 		/*
 		 * Reserve space & log for one extent added to the file.
 		 */
-		if ((error = xfs_trans_reserve(tp, resblks,
-				XFS_GROWRTALLOC_LOG_RES(mp), 0,
-				XFS_TRANS_PERM_LOG_RES,
-				XFS_DEFAULT_PERM_LOG_COUNT)))
+		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_growdata,
+					  resblks, 0);
+		if (error)
 			goto error_cancel;
 		cancelflags = XFS_TRANS_RELEASE_LOG_RES;
 		/*
@@ -148,8 +147,9 @@ xfs_growfs_rt_alloc(
 			/*
 			 * Reserve log for one block zeroing.
 			 */
-			if ((error = xfs_trans_reserve(tp, 0,
-					XFS_GROWRTZERO_LOG_RES(mp), 0, 0, 0)))
+			error = xfs_trans_reserve(tp, &M_RES(mp)->tr_growrtzero,
+						  0, 0);
+			if (error)
 				goto error_cancel;
 			/*
 			 * Lock the bitmap inode.
@@ -1959,8 +1959,9 @@ xfs_growfs_rt(
 		 * Start a transaction, get the log reservation.
 		 */
 		tp = xfs_trans_alloc(mp, XFS_TRANS_GROWFSRT_FREE);
-		if ((error = xfs_trans_reserve(tp, 0,
-				XFS_GROWRTFREE_LOG_RES(nmp), 0, 0, 0)))
+		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_growrtfree,
+					  0, 0);
+		if (error)
 			goto error_cancel;
 		/*
 		 * Lock out other callers by grabbing the bitmap inode lock.
diff --git a/fs/xfs/xfs_symlink.c b/fs/xfs/xfs_symlink.c
index 05bc2306bf6c..b3bc7374c804 100644
--- a/fs/xfs/xfs_symlink.c
+++ b/fs/xfs/xfs_symlink.c
@@ -231,12 +231,10 @@ xfs_symlink(
 	else
 		fs_blocks = xfs_symlink_blocks(mp, pathlen);
 	resblks = XFS_SYMLINK_SPACE_RES(mp, link_name->len, fs_blocks);
-	error = xfs_trans_reserve(tp, resblks, XFS_SYMLINK_LOG_RES(mp), 0,
-			XFS_TRANS_PERM_LOG_RES, XFS_SYMLINK_LOG_COUNT);
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_symlink, resblks, 0);
 	if (error == ENOSPC && fs_blocks == 0) {
 		resblks = 0;
-		error = xfs_trans_reserve(tp, 0, XFS_SYMLINK_LOG_RES(mp), 0,
-				XFS_TRANS_PERM_LOG_RES, XFS_SYMLINK_LOG_COUNT);
+		error = xfs_trans_reserve(tp, &M_RES(mp)->tr_symlink, 0, 0);
 	}
 	if (error) {
 		cancel_flags = 0;
@@ -539,8 +537,8 @@ xfs_inactive_symlink_rmt(
 	 * Put an itruncate log reservation in the new transaction
 	 * for our caller.
 	 */
-	if ((error = xfs_trans_reserve(tp, 0, XFS_ITRUNCATE_LOG_RES(mp), 0,
-			XFS_TRANS_PERM_LOG_RES, XFS_ITRUNCATE_LOG_COUNT))) {
+	error = xfs_trans_reserve(tp, &M_RES(mp)->tr_itruncate, 0, 0);
+	if (error) {
 		ASSERT(XFS_FORCED_SHUTDOWN(mp));
 		goto error0;
 	}
diff --git a/fs/xfs/xfs_trans.c b/fs/xfs/xfs_trans.c
index e0f93f957c5c..b986400ea728 100644
--- a/fs/xfs/xfs_trans.c
+++ b/fs/xfs/xfs_trans.c
@@ -56,7 +56,7 @@ void
 xfs_trans_init(
 	struct xfs_mount	*mp)
 {
-	xfs_trans_resv_calc(mp, &mp->m_resv);
+	xfs_trans_resv_calc(mp, M_RES(mp));
 }
 
 /*
@@ -180,12 +180,10 @@ xfs_trans_dup(
  */
 int
 xfs_trans_reserve(
-	xfs_trans_t	*tp,
-	uint		blocks,
-	uint		logspace,
-	uint		rtextents,
-	uint		flags,
-	uint		logcount)
+	struct xfs_trans	*tp,
+	struct xfs_trans_res	*resp,
+	uint			blocks,
+	uint			rtextents)
 {
 	int		error = 0;
 	int		rsvd = (tp->t_flags & XFS_TRANS_RESERVE) != 0;
@@ -211,13 +209,15 @@ xfs_trans_reserve(
 	/*
 	 * Reserve the log space needed for this transaction.
 	 */
-	if (logspace > 0) {
+	if (resp->tr_logres > 0) {
 		bool	permanent = false;
 
-		ASSERT(tp->t_log_res == 0 || tp->t_log_res == logspace);
-		ASSERT(tp->t_log_count == 0 || tp->t_log_count == logcount);
+		ASSERT(tp->t_log_res == 0 ||
+		       tp->t_log_res == resp->tr_logres);
+		ASSERT(tp->t_log_count == 0 ||
+		       tp->t_log_count == resp->tr_logcount);
 
-		if (flags & XFS_TRANS_PERM_LOG_RES) {
+		if (resp->tr_logflags & XFS_TRANS_PERM_LOG_RES) {
 			tp->t_flags |= XFS_TRANS_PERM_LOG_RES;
 			permanent = true;
 		} else {
@@ -226,20 +226,21 @@ xfs_trans_reserve(
 		}
 
 		if (tp->t_ticket != NULL) {
-			ASSERT(flags & XFS_TRANS_PERM_LOG_RES);
+			ASSERT(resp->tr_logflags & XFS_TRANS_PERM_LOG_RES);
 			error = xfs_log_regrant(tp->t_mountp, tp->t_ticket);
 		} else {
-			error = xfs_log_reserve(tp->t_mountp, logspace,
-						logcount, &tp->t_ticket,
-						XFS_TRANSACTION, permanent,
-						tp->t_type);
+			error = xfs_log_reserve(tp->t_mountp,
+						resp->tr_logres,
+						resp->tr_logcount,
+						&tp->t_ticket, XFS_TRANSACTION,
+						permanent, tp->t_type);
 		}
 
 		if (error)
 			goto undo_blocks;
 
-		tp->t_log_res = logspace;
-		tp->t_log_count = logcount;
+		tp->t_log_res = resp->tr_logres;
+		tp->t_log_count = resp->tr_logcount;
 	}
 
 	/*
@@ -264,10 +265,10 @@ xfs_trans_reserve(
 	 * reservations which have already been performed.
 	 */
 undo_log:
-	if (logspace > 0) {
+	if (resp->tr_logres > 0) {
 		int		log_flags;
 
-		if (flags & XFS_TRANS_PERM_LOG_RES) {
+		if (resp->tr_logflags & XFS_TRANS_PERM_LOG_RES) {
 			log_flags = XFS_LOG_REL_PERM_RESERV;
 		} else {
 			log_flags = 0;
@@ -1014,7 +1015,7 @@ xfs_trans_roll(
 	struct xfs_inode	*dp)
 {
 	struct xfs_trans	*trans;
-	unsigned int		logres, count;
+	struct xfs_trans_res	tres;
 	int			error;
 
 	/*
@@ -1026,8 +1027,8 @@ xfs_trans_roll(
 	/*
 	 * Copy the critical parameters from one trans to the next.
 	 */
-	logres = trans->t_log_res;
-	count = trans->t_log_count;
+	tres.tr_logres = trans->t_log_res;
+	tres.tr_logcount = trans->t_log_count;
 	*tpp = xfs_trans_dup(trans);
 
 	/*
@@ -1058,8 +1059,8 @@ xfs_trans_roll(
 	 * across this call, or that anything that is locked be logged in
 	 * the prior and the next transactions.
 	 */
-	error = xfs_trans_reserve(trans, 0, logres, 0,
-				  XFS_TRANS_PERM_LOG_RES, count);
+	tres.tr_logflags = XFS_TRANS_PERM_LOG_RES;
+	error = xfs_trans_reserve(trans, &tres, 0, 0);
 	/*
 	 *  Ensure that the inode is in the new transaction and locked.
 	 */
diff --git a/fs/xfs/xfs_trans.h b/fs/xfs/xfs_trans.h
index b5dc61e3e56b..7eb81ccd826d 100644
--- a/fs/xfs/xfs_trans.h
+++ b/fs/xfs/xfs_trans.h
@@ -34,6 +34,7 @@ struct xfs_log_iovec;
 struct xfs_log_item_desc;
 struct xfs_mount;
 struct xfs_trans;
+struct xfs_trans_res;
 struct xfs_dquot_acct;
 struct xfs_busy_extent;
 
@@ -170,7 +171,7 @@ typedef struct xfs_trans {
 xfs_trans_t	*xfs_trans_alloc(struct xfs_mount *, uint);
 xfs_trans_t	*_xfs_trans_alloc(struct xfs_mount *, uint, xfs_km_flags_t);
 xfs_trans_t	*xfs_trans_dup(xfs_trans_t *);
-int		xfs_trans_reserve(xfs_trans_t *, uint, uint, uint,
+int		xfs_trans_reserve(struct xfs_trans *, struct xfs_trans_res *,
 				  uint, uint);
 void		xfs_trans_mod_sb(xfs_trans_t *, uint, int64_t);
 
diff --git a/fs/xfs/xfs_trans_resv.c b/fs/xfs/xfs_trans_resv.c
index e9211add5183..24110f36f729 100644
--- a/fs/xfs/xfs_trans_resv.c
+++ b/fs/xfs/xfs_trans_resv.c
@@ -547,7 +547,8 @@ xfs_calc_attrsetm_reservation(
  * Since the runtime attribute transaction space is dependent on the total
  * blocks needed for the 1st bmap, here we calculate out the space unit for
  * one block so that the caller could figure out the total space according
- * to the attibute extent length in blocks by: ext * XFS_ATTRSETRT_LOG_RES(mp).
+ * to the attibute extent length in blocks by:
+ *	ext * M_RES(mp)->tr_attrsetrt.tr_logres
  */
 STATIC uint
 xfs_calc_attrsetrt_reservation(
@@ -619,14 +620,14 @@ xfs_calc_qm_setqlim_reservation(
 
 /*
  * Allocating quota on disk if needed.
- *	the write transaction log space: XFS_WRITE_LOG_RES(mp)
+ *	the write transaction log space: M_RES(mp)->tr_write.tr_logres
  *	the unit of quota allocation: one system block size
  */
 STATIC uint
 xfs_calc_qm_dqalloc_reservation(
 	struct xfs_mount	*mp)
 {
-	return XFS_WRITE_LOG_RES(mp) +
+	return M_RES(mp)->tr_write.tr_logres +
 		xfs_calc_buf_res(1,
 			XFS_FSB_TO_B(mp, XFS_DQUOT_CLUSTER_SIZE_FSB) - 1);
 }
diff --git a/fs/xfs/xfs_trans_resv.h b/fs/xfs/xfs_trans_resv.h
index b8d5666990fe..140d3f367284 100644
--- a/fs/xfs/xfs_trans_resv.h
+++ b/fs/xfs/xfs_trans_resv.h
@@ -65,6 +65,9 @@ struct xfs_trans_resv {
 	struct xfs_trans_res	tr_fsyncts;	/* update timestamps on fsync */
 };
 
+/* shorthand way of accessing reservation structure */
+#define M_RES(mp)	(&(mp)->m_resv)
+
 /*
  * Per-extent log reservation for the allocation btree changes
  * involved in freeing or allocating an extent.
