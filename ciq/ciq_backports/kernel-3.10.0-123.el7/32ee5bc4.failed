blk-throttle: Account for child group's start time in parent while bio climbs up

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-123.el7
commit-author Vivek Goyal <vgoyal@redhat.com>
commit 32ee5bc4787dfbdb280b4d81a338dcdd55918c1e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-123.el7/32ee5bc4.failed

With the planned proper hierarchy support, a bio will climb up the
tree before actually being dispatched. This makes sure bio is also
subjected to parent's throttling limits, if any.

It might happen that parent is idle and when bio is transferred to
parent, a new slice starts fresh. But that is incorrect as parents
wait time should have started when bio was queued in child group and
causes IOs to be throttled more than configured as they climb the
hierarchy.

Given the fact that we have not written hierarchical algorithm in a
way where child's and parents time slices are synchronized, we
transfer the child's start time to parent if parent was idling.  If
parent was busy doing dispatch of other bios all this while, this is
not an issue.

Child's slice start time is passed to parent. Parent looks at its
last expired slice start time. If child's start time is after parents
old start time, that means parent had been idle and after parent
went idle, child had an IO queued. So use child's start time as
parent start time.

If parent's start time is after child's start time, that means,
when IO got queued in child group, parent was not idle. But later
it dispatched some IO, its slice got trimmed and then it went idle.
After a while child's request got shifted in parent group. In this
case use parent's old start time as new start time as that's the
duration of slice we did not use.

This logic is far from perfect as if there are multiple childs
then first child transferring the bio decides the start time while
a bio might have queued up even earlier in other child, which is
yet to be transferred up to parent. In that case we will lose
time and bandwidth in parent. This patch is just an approximation
to make situation somewhat better.
 
	Signed-off-by: Vivek Goyal <vgoyal@redhat.com>
	Signed-off-by: Tejun Heo <tj@kernel.org>
(cherry picked from commit 32ee5bc4787dfbdb280b4d81a338dcdd55918c1e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-throttle.c
diff --cc block/blk-throttle.c
index e65e45a33372,7477f332c8dc..000000000000
--- a/block/blk-throttle.c
+++ b/block/blk-throttle.c
@@@ -416,12 -623,38 +416,34 @@@ static void throtl_schedule_next_dispat
  
  	update_min_dispatch_time(sq);
  
 -	/* is the next dispatch time in the future? */
 -	if (force || time_after(sq->first_pending_disptime, jiffies)) {
 -		throtl_schedule_pending_timer(sq, sq->first_pending_disptime);
 -		return true;
 -	}
 -
 -	/* tell the caller to continue dispatching */
 -	return false;
 +	if (time_before_eq(sq->first_pending_disptime, jiffies))
 +		throtl_schedule_delayed_work(td, 0);
 +	else
 +		throtl_schedule_delayed_work(td, sq->first_pending_disptime - jiffies);
  }
  
+ static inline void throtl_start_new_slice_with_credit(struct throtl_grp *tg,
+ 		bool rw, unsigned long start)
+ {
+ 	tg->bytes_disp[rw] = 0;
+ 	tg->io_disp[rw] = 0;
+ 
+ 	/*
+ 	 * Previous slice has expired. We must have trimmed it after last
+ 	 * bio dispatch. That means since start of last slice, we never used
+ 	 * that bandwidth. Do try to make use of that bandwidth while giving
+ 	 * credit.
+ 	 */
+ 	if (time_after_eq(start, tg->slice_start[rw]))
+ 		tg->slice_start[rw] = start;
+ 
+ 	tg->slice_end[rw] = jiffies + throtl_slice;
+ 	throtl_log(&tg->service_queue,
+ 		   "[%c] new slice with credit start=%lu end=%lu jiffies=%lu",
+ 		   rw == READ ? 'R' : 'W', tg->slice_start[rw],
+ 		   tg->slice_end[rw], jiffies);
+ }
+ 
  static inline void throtl_start_new_slice(struct throtl_grp *tg, bool rw)
  {
  	tg->bytes_disp[rw] = 0;
@@@ -755,28 -1014,59 +777,62 @@@ static void tg_update_disptime(struct t
  	tg->flags &= ~THROTL_TG_WAS_EMPTY;
  }
  
++<<<<<<< HEAD
 +static void tg_dispatch_one_bio(struct throtl_grp *tg, bool rw,
 +				struct bio_list *bl)
++=======
+ static void start_parent_slice_with_credit(struct throtl_grp *child_tg,
+ 					struct throtl_grp *parent_tg, bool rw)
+ {
+ 	if (throtl_slice_used(parent_tg, rw)) {
+ 		throtl_start_new_slice_with_credit(parent_tg, rw,
+ 				child_tg->slice_start[rw]);
+ 	}
+ 
+ }
+ 
+ static void tg_dispatch_one_bio(struct throtl_grp *tg, bool rw)
++>>>>>>> 32ee5bc4787d (blk-throttle: Account for child group's start time in parent while bio climbs up)
  {
  	struct throtl_service_queue *sq = &tg->service_queue;
 -	struct throtl_service_queue *parent_sq = sq->parent_sq;
 -	struct throtl_grp *parent_tg = sq_to_tg(parent_sq);
 -	struct throtl_grp *tg_to_put = NULL;
  	struct bio *bio;
  
 -	/*
 -	 * @bio is being transferred from @tg to @parent_sq.  Popping a bio
 -	 * from @tg may put its reference and @parent_sq might end up
 -	 * getting released prematurely.  Remember the tg to put and put it
 -	 * after @bio is transferred to @parent_sq.
 -	 */
 -	bio = throtl_pop_queued(&sq->queued[rw], &tg_to_put);
 +	bio = bio_list_pop(&sq->bio_lists[rw]);
  	sq->nr_queued[rw]--;
 +	/* Drop bio reference on blkg */
 +	blkg_put(tg_to_blkg(tg));
 +
 +	BUG_ON(tg->td->nr_queued[rw] <= 0);
 +	tg->td->nr_queued[rw]--;
  
  	throtl_charge_bio(tg, bio);
++<<<<<<< HEAD
 +	bio_list_add(bl, bio);
 +	bio->bi_rw |= REQ_THROTTLED;
++=======
+ 
+ 	/*
+ 	 * If our parent is another tg, we just need to transfer @bio to
+ 	 * the parent using throtl_add_bio_tg().  If our parent is
+ 	 * @td->service_queue, @bio is ready to be issued.  Put it on its
+ 	 * bio_lists[] and decrease total number queued.  The caller is
+ 	 * responsible for issuing these bios.
+ 	 */
+ 	if (parent_tg) {
+ 		throtl_add_bio_tg(bio, &tg->qnode_on_parent[rw], parent_tg);
+ 		start_parent_slice_with_credit(tg, parent_tg, rw);
+ 	} else {
+ 		throtl_qnode_add_bio(bio, &tg->qnode_on_parent[rw],
+ 				     &parent_sq->queued[rw]);
+ 		BUG_ON(tg->td->nr_queued[rw] <= 0);
+ 		tg->td->nr_queued[rw]--;
+ 	}
++>>>>>>> 32ee5bc4787d (blk-throttle: Account for child group's start time in parent while bio climbs up)
  
  	throtl_trim_slice(tg, rw);
 -
 -	if (tg_to_put)
 -		blkg_put(tg_to_blkg(tg_to_put));
  }
  
 -static int throtl_dispatch_tg(struct throtl_grp *tg)
 +static int throtl_dispatch_tg(struct throtl_grp *tg, struct bio_list *bl)
  {
  	struct throtl_service_queue *sq = &tg->service_queue;
  	unsigned int nr_reads = 0, nr_writes = 0;
* Unmerged path block/blk-throttle.c
