net: rename low latency sockets functions to busy poll

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-123.el7
Rebuild_CHGLOG: - [net] busy_poll: rename low latency sockets functions to busy poll (Neil Horman) [958330]
Rebuild_FUZZ: 89.47%
commit-author Eliezer Tamir <eliezer.tamir@linux.intel.com>
commit cbf55001b2ddb814329735641be5d29b08c82b08
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-123.el7/cbf55001.failed

Rename functions in include/net/ll_poll.h to busy wait.
Clarify documentation about expected power use increase.
Rename POLL_LL to POLL_BUSY_LOOP.
Add need_resched() testing to poll/select busy loops.

Note, that in select and poll can_busy_poll is dynamic and is
updated continuously to reflect the existence of supported
sockets with valid queue information.

	Signed-off-by: Eliezer Tamir <eliezer.tamir@linux.intel.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit cbf55001b2ddb814329735641be5d29b08c82b08)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/sysctl/net.txt
#	fs/select.c
#	include/net/ll_poll.h
#	include/uapi/asm-generic/poll.h
#	net/socket.c
diff --cc Documentation/sysctl/net.txt
index 98335b7a5337,7323b88e26be..000000000000
--- a/Documentation/sysctl/net.txt
+++ b/Documentation/sysctl/net.txt
@@@ -50,6 -50,29 +50,32 @@@ The maximum number of packets that kern
  it's a Per-CPU variable.
  Default: 64
  
++<<<<<<< HEAD
++=======
+ low_latency_read
+ ----------------
+ Low latency busy poll timeout for socket reads. (needs CONFIG_NET_LL_RX_POLL)
+ Approximate time in us to busy loop waiting for packets on the device queue.
+ This sets the default value of the SO_LL socket option.
+ Can be set or overridden per socket by setting socket option SO_LL, which is
+ the preferred method of enabling.
+ If you need to enable the feature globally via sysctl, a value of 50 is recommended.
+ Will increase power usage.
+ Default: 0 (off)
+ 
+ low_latency_poll
+ ----------------
+ Low latency busy poll timeout for poll and select. (needs CONFIG_NET_LL_RX_POLL)
+ Approximate time in us to busy loop waiting for events.
+ Recommended value depends on the number of sockets you poll on.
+ For several sockets 50, for several hundreds 100.
+ For more than that you probably want to use epoll.
+ Note that only sockets with SO_LL set will be busy polled, so you want to either
+ selectively set SO_LL on those sockets or set sysctl.net.low_latency_read globally.
+ Will increase power usage.
+ Default: 0 (off)
+ 
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  rmem_default
  ------------
  
diff --cc fs/select.c
index 6b14dc7df3a4,25cac5faf6d6..000000000000
--- a/fs/select.c
+++ b/fs/select.c
@@@ -402,6 -402,9 +402,12 @@@ int do_select(int n, fd_set_bits *fds, 
  	poll_table *wait;
  	int retval, i, timed_out = 0;
  	unsigned long slack = 0;
++<<<<<<< HEAD
++=======
+ 	unsigned int busy_flag = net_busy_loop_on() ? POLL_BUSY_LOOP : 0;
+ 	u64 busy_start = busy_loop_start_time(busy_flag);
+ 	u64 busy_end = busy_loop_end_time();
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  
  	rcu_read_lock();
  	retval = max_select_fd(n, fds);
@@@ -424,6 -427,7 +430,10 @@@
  	retval = 0;
  	for (;;) {
  		unsigned long *rinp, *routp, *rexp, *inp, *outp, *exp;
++<<<<<<< HEAD
++=======
+ 		bool can_busy_loop = false;
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  
  		inp = fds->in; outp = fds->out; exp = fds->ex;
  		rinp = fds->res_in; routp = fds->res_out; rexp = fds->res_ex;
@@@ -451,7 -455,8 +461,12 @@@
  					f_op = f.file->f_op;
  					mask = DEFAULT_POLLMASK;
  					if (f_op && f_op->poll) {
++<<<<<<< HEAD
 +						wait_key_set(wait, in, out, bit);
++=======
+ 						wait_key_set(wait, in, out,
+ 							     bit, busy_flag);
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  						mask = (*f_op->poll)(f.file, wait);
  					}
  					fdput(f);
@@@ -470,6 -475,18 +485,21 @@@
  						retval++;
  						wait->_qproc = NULL;
  					}
++<<<<<<< HEAD
++=======
+ 					/* got something, stop busy polling */
+ 					if (retval) {
+ 						can_busy_loop = false;
+ 						busy_flag = 0;
+ 
+ 					/*
+ 					 * only remember a returned
+ 					 * POLL_BUSY_LOOP if we asked for it
+ 					 */
+ 					} else if (busy_flag & mask)
+ 						can_busy_loop = true;
+ 
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  				}
  			}
  			if (res_in)
@@@ -488,6 -505,11 +518,14 @@@
  			break;
  		}
  
++<<<<<<< HEAD
++=======
+ 		/* only if found POLL_BUSY_LOOP sockets && not out of time */
+ 		if (!need_resched() && can_busy_loop &&
+ 		    busy_loop_range(busy_start, busy_end))
+ 			continue;
+ 
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  		/*
  		 * If this is the first loop and we have a timeout
  		 * given, then we convert to ktime_t and set the to
@@@ -719,7 -741,9 +757,13 @@@ struct poll_list 
   * pwait poll_table will be used by the fd-provided poll handler for waiting,
   * if pwait->_qproc is non-NULL.
   */
++<<<<<<< HEAD
 +static inline unsigned int do_pollfd(struct pollfd *pollfd, poll_table *pwait)
++=======
+ static inline unsigned int do_pollfd(struct pollfd *pollfd, poll_table *pwait,
+ 				     bool *can_busy_poll,
+ 				     unsigned int busy_flag)
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  {
  	unsigned int mask;
  	int fd;
@@@ -733,7 -757,10 +777,14 @@@
  			mask = DEFAULT_POLLMASK;
  			if (f.file->f_op && f.file->f_op->poll) {
  				pwait->_key = pollfd->events|POLLERR|POLLHUP;
++<<<<<<< HEAD
 +				mask = f.file->f_op->poll(f.file, pwait);
++=======
+ 				pwait->_key |= busy_flag;
+ 				mask = f.file->f_op->poll(f.file, pwait);
+ 				if (mask & busy_flag)
+ 					*can_busy_poll = true;
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  			}
  			/* Mask out unneeded events. */
  			mask &= pollfd->events | POLLERR | POLLHUP;
@@@ -752,6 -779,10 +803,13 @@@ static int do_poll(unsigned int nfds,  
  	ktime_t expire, *to = NULL;
  	int timed_out = 0, count = 0;
  	unsigned long slack = 0;
++<<<<<<< HEAD
++=======
+ 	unsigned int busy_flag = net_busy_loop_on() ? POLL_BUSY_LOOP : 0;
+ 	u64 busy_start = busy_loop_start_time(busy_flag);
+ 	u64 busy_end = busy_loop_end_time();
+ 
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  
  	/* Optimise the no-wait case */
  	if (end_time && !end_time->tv_sec && !end_time->tv_nsec) {
@@@ -764,6 -795,7 +822,10 @@@
  
  	for (;;) {
  		struct poll_list *walk;
++<<<<<<< HEAD
++=======
+ 		bool can_busy_loop = false;
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  
  		for (walk = list; walk != NULL; walk = walk->next) {
  			struct pollfd * pfd, * pfd_end;
@@@ -778,9 -810,13 +840,19 @@@
  				 * this. They'll get immediately deregistered
  				 * when we break out and return.
  				 */
++<<<<<<< HEAD
 +				if (do_pollfd(pfd, pt)) {
 +					count++;
 +					pt->_qproc = NULL;
++=======
+ 				if (do_pollfd(pfd, pt, &can_busy_loop,
+ 					      busy_flag)) {
+ 					count++;
+ 					pt->_qproc = NULL;
+ 					/* found something, stop busy polling */
+ 					busy_flag = 0;
+ 					can_busy_loop = false;
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  				}
  			}
  		}
@@@ -797,6 -833,11 +869,14 @@@
  		if (count || timed_out)
  			break;
  
++<<<<<<< HEAD
++=======
+ 		/* only if found POLL_BUSY_LOOP sockets && not out of time */
+ 		if (!need_resched() && can_busy_loop &&
+ 		    busy_loop_range(busy_start, busy_end))
+ 			continue;
+ 
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  		/*
  		 * If this is the first loop and we have a timeout
  		 * given, then we convert to ktime_t and set the to
diff --cc include/uapi/asm-generic/poll.h
index 9ce7f44aebd2,a9694982689f..000000000000
--- a/include/uapi/asm-generic/poll.h
+++ b/include/uapi/asm-generic/poll.h
@@@ -30,6 -30,8 +30,11 @@@
  
  #define POLLFREE	0x4000	/* currently only for epoll */
  
++<<<<<<< HEAD
++=======
+ #define POLL_BUSY_LOOP	0x8000
+ 
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  struct pollfd {
  	int fd;
  	short events;
diff --cc net/socket.c
index 4ca1526db756,45afa648364a..000000000000
--- a/net/socket.c
+++ b/net/socket.c
@@@ -1142,13 -1148,24 +1142,31 @@@ EXPORT_SYMBOL(sock_create_lite)
  /* No kernel lock held - perfect */
  static unsigned int sock_poll(struct file *file, poll_table *wait)
  {
++<<<<<<< HEAD
++=======
+ 	unsigned int busy_flag = 0;
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  	struct socket *sock;
  
  	/*
  	 *      We can't return errors to poll, so it's either yes or no.
  	 */
  	sock = file->private_data;
++<<<<<<< HEAD
 +	return sock->ops->poll(file, sock, wait);
++=======
+ 
+ 	if (sk_can_busy_loop(sock->sk)) {
+ 		/* this socket can poll_ll so tell the system call */
+ 		busy_flag = POLL_BUSY_LOOP;
+ 
+ 		/* once, only if requested by syscall */
+ 		if (wait && (wait->_key & POLL_BUSY_LOOP))
+ 			sk_busy_loop(sock->sk, 1);
+ 	}
+ 
+ 	return busy_flag | sock->ops->poll(file, sock, wait);
++>>>>>>> cbf55001b2dd (net: rename low latency sockets functions to busy poll)
  }
  
  static int sock_mmap(struct file *file, struct vm_area_struct *vma)
* Unmerged path include/net/ll_poll.h
* Unmerged path Documentation/sysctl/net.txt
* Unmerged path fs/select.c
* Unmerged path include/net/ll_poll.h
* Unmerged path include/uapi/asm-generic/poll.h
diff --git a/net/core/datagram.c b/net/core/datagram.c
index 9cbaba98ce4c..6e9ab31e457e 100644
--- a/net/core/datagram.c
+++ b/net/core/datagram.c
@@ -208,7 +208,8 @@ struct sk_buff *__skb_recv_datagram(struct sock *sk, unsigned int flags,
 		}
 		spin_unlock_irqrestore(&queue->lock, cpu_flags);
 
-		if (sk_valid_ll(sk) && sk_poll_ll(sk, flags & MSG_DONTWAIT))
+		if (sk_can_busy_loop(sk) &&
+		    sk_busy_loop(sk, flags & MSG_DONTWAIT))
 			continue;
 
 		/* User doesn't want to wait */
diff --git a/net/ipv4/tcp.c b/net/ipv4/tcp.c
index 93ad54d4858d..5d667dddc7bb 100644
--- a/net/ipv4/tcp.c
+++ b/net/ipv4/tcp.c
@@ -1552,9 +1552,9 @@ int tcp_recvmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg,
 	struct sk_buff *skb;
 	u32 urg_hole = 0;
 
-	if (sk_valid_ll(sk) && skb_queue_empty(&sk->sk_receive_queue)
-	    && (sk->sk_state == TCP_ESTABLISHED))
-		sk_poll_ll(sk, nonblock);
+	if (sk_can_busy_loop(sk) && skb_queue_empty(&sk->sk_receive_queue) &&
+	    (sk->sk_state == TCP_ESTABLISHED))
+		sk_busy_loop(sk, nonblock);
 
 	lock_sock(sk);
 
* Unmerged path net/socket.c
