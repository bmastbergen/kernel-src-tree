lockref: Relax in cmpxchg loop

jira LE-1907
Rebuild_History Non-Buildable kernel-3.10.0-123.el7
commit-author Tony Luck <tony.luck@intel.com>
commit d472d9d98b463dd7a04f2bcdeafe4261686ce6ab
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-123.el7/d472d9d9.failed

While we are likley to succeed and break out of this loop, it isn't
guaranteed.  We should be power and thread friendly if we do have to
go around for a second (or third, or more) attempt.

	Signed-off-by: Tony Luck <tony.luck@intel.com>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit d472d9d98b463dd7a04f2bcdeafe4261686ce6ab)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	lib/lockref.c
diff --cc lib/lockref.c
index a9a4f4e1eff5,9d76f404ce9a..000000000000
--- a/lib/lockref.c
+++ b/lib/lockref.c
@@@ -1,6 -1,34 +1,37 @@@
  #include <linux/export.h>
  #include <linux/lockref.h>
  
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_CMPXCHG_LOCKREF
+ 
+ /*
+  * Note that the "cmpxchg()" reloads the "old" value for the
+  * failure case.
+  */
+ #define CMPXCHG_LOOP(CODE, SUCCESS) do {					\
+ 	struct lockref old;							\
+ 	BUILD_BUG_ON(sizeof(old) != 8);						\
+ 	old.lock_count = ACCESS_ONCE(lockref->lock_count);			\
+ 	while (likely(arch_spin_value_unlocked(old.lock.rlock.raw_lock))) {  	\
+ 		struct lockref new = old, prev = old;				\
+ 		CODE								\
+ 		old.lock_count = cmpxchg(&lockref->lock_count,			\
+ 					 old.lock_count, new.lock_count);	\
+ 		if (likely(old.lock_count == prev.lock_count)) {		\
+ 			SUCCESS;						\
+ 		}								\
+ 		cpu_relax();							\
+ 	}									\
+ } while (0)
+ 
+ #else
+ 
+ #define CMPXCHG_LOOP(CODE, SUCCESS) do { } while (0)
+ 
+ #endif
+ 
++>>>>>>> d472d9d98b46 (lockref: Relax in cmpxchg loop)
  /**
   * lockref_get - Increments reference count unconditionally
   * @lockcnt: pointer to lockref structure
* Unmerged path lib/lockref.c
