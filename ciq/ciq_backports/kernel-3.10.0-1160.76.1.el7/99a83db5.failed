x86/speculation/mmio: Enable CPU Fill buffer clearing on idle

jira LE-1907
cve CVE-2022-21166
cve CVE-2022-21125
cve CVE-2022-21123
Rebuild_History Non-Buildable kernel-3.10.0-1160.76.1.el7
commit-author Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
commit 99a83db5a605137424e1efe29dc0573d6a5b6316
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-3.10.0-1160.76.1.el7/99a83db5.failed

When the CPU is affected by Processor MMIO Stale Data vulnerabilities,
Fill Buffer Stale Data Propagator (FBSDP) can propagate stale data out
of Fill buffer to uncore buffer when CPU goes idle. Stale data can then
be exploited with other variants using MMIO operations.

Mitigate it by clearing the Fill buffer before entering idle state.

	Signed-off-by: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
Co-developed-by: Josh Poimboeuf <jpoimboe@redhat.com>
	Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
	Signed-off-by: Borislav Petkov <bp@suse.de>
(cherry picked from commit 99a83db5a605137424e1efe29dc0573d6a5b6316)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kernel/cpu/bugs.c
diff --cc arch/x86/kernel/cpu/bugs.c
index eed1e0c03c19,56d5dea5e128..000000000000
--- a/arch/x86/kernel/cpu/bugs.c
+++ b/arch/x86/kernel/cpu/bugs.c
@@@ -337,6 -390,151 +337,154 @@@ static int __init tsx_async_abort_parse
  early_param("tsx_async_abort", tsx_async_abort_parse_cmdline);
  
  #undef pr_fmt
++<<<<<<< HEAD
++=======
+ #define pr_fmt(fmt)	"MMIO Stale Data: " fmt
+ 
+ enum mmio_mitigations {
+ 	MMIO_MITIGATION_OFF,
+ 	MMIO_MITIGATION_UCODE_NEEDED,
+ 	MMIO_MITIGATION_VERW,
+ };
+ 
+ /* Default mitigation for Processor MMIO Stale Data vulnerabilities */
+ static enum mmio_mitigations mmio_mitigation __ro_after_init = MMIO_MITIGATION_VERW;
+ static bool mmio_nosmt __ro_after_init = false;
+ 
+ static const char * const mmio_strings[] = {
+ 	[MMIO_MITIGATION_OFF]		= "Vulnerable",
+ 	[MMIO_MITIGATION_UCODE_NEEDED]	= "Vulnerable: Clear CPU buffers attempted, no microcode",
+ 	[MMIO_MITIGATION_VERW]		= "Mitigation: Clear CPU buffers",
+ };
+ 
+ static void __init mmio_select_mitigation(void)
+ {
+ 	u64 ia32_cap;
+ 
+ 	if (!boot_cpu_has_bug(X86_BUG_MMIO_STALE_DATA) ||
+ 	    cpu_mitigations_off()) {
+ 		mmio_mitigation = MMIO_MITIGATION_OFF;
+ 		return;
+ 	}
+ 
+ 	if (mmio_mitigation == MMIO_MITIGATION_OFF)
+ 		return;
+ 
+ 	ia32_cap = x86_read_arch_cap_msr();
+ 
+ 	/*
+ 	 * Enable CPU buffer clear mitigation for host and VMM, if also affected
+ 	 * by MDS or TAA. Otherwise, enable mitigation for VMM only.
+ 	 */
+ 	if (boot_cpu_has_bug(X86_BUG_MDS) || (boot_cpu_has_bug(X86_BUG_TAA) &&
+ 					      boot_cpu_has(X86_FEATURE_RTM)))
+ 		static_branch_enable(&mds_user_clear);
+ 	else
+ 		static_branch_enable(&mmio_stale_data_clear);
+ 
+ 	/*
+ 	 * If Processor-MMIO-Stale-Data bug is present and Fill Buffer data can
+ 	 * be propagated to uncore buffers, clearing the Fill buffers on idle
+ 	 * is required irrespective of SMT state.
+ 	 */
+ 	if (!(ia32_cap & ARCH_CAP_FBSDP_NO))
+ 		static_branch_enable(&mds_idle_clear);
+ 
+ 	/*
+ 	 * Check if the system has the right microcode.
+ 	 *
+ 	 * CPU Fill buffer clear mitigation is enumerated by either an explicit
+ 	 * FB_CLEAR or by the presence of both MD_CLEAR and L1D_FLUSH on MDS
+ 	 * affected systems.
+ 	 */
+ 	if ((ia32_cap & ARCH_CAP_FB_CLEAR) ||
+ 	    (boot_cpu_has(X86_FEATURE_MD_CLEAR) &&
+ 	     boot_cpu_has(X86_FEATURE_FLUSH_L1D) &&
+ 	     !(ia32_cap & ARCH_CAP_MDS_NO)))
+ 		mmio_mitigation = MMIO_MITIGATION_VERW;
+ 	else
+ 		mmio_mitigation = MMIO_MITIGATION_UCODE_NEEDED;
+ 
+ 	if (mmio_nosmt || cpu_mitigations_auto_nosmt())
+ 		cpu_smt_disable(false);
+ }
+ 
+ static int __init mmio_stale_data_parse_cmdline(char *str)
+ {
+ 	if (!boot_cpu_has_bug(X86_BUG_MMIO_STALE_DATA))
+ 		return 0;
+ 
+ 	if (!str)
+ 		return -EINVAL;
+ 
+ 	if (!strcmp(str, "off")) {
+ 		mmio_mitigation = MMIO_MITIGATION_OFF;
+ 	} else if (!strcmp(str, "full")) {
+ 		mmio_mitigation = MMIO_MITIGATION_VERW;
+ 	} else if (!strcmp(str, "full,nosmt")) {
+ 		mmio_mitigation = MMIO_MITIGATION_VERW;
+ 		mmio_nosmt = true;
+ 	}
+ 
+ 	return 0;
+ }
+ early_param("mmio_stale_data", mmio_stale_data_parse_cmdline);
+ 
+ #undef pr_fmt
+ #define pr_fmt(fmt)     "" fmt
+ 
+ static void __init md_clear_update_mitigation(void)
+ {
+ 	if (cpu_mitigations_off())
+ 		return;
+ 
+ 	if (!static_key_enabled(&mds_user_clear))
+ 		goto out;
+ 
+ 	/*
+ 	 * mds_user_clear is now enabled. Update MDS, TAA and MMIO Stale Data
+ 	 * mitigation, if necessary.
+ 	 */
+ 	if (mds_mitigation == MDS_MITIGATION_OFF &&
+ 	    boot_cpu_has_bug(X86_BUG_MDS)) {
+ 		mds_mitigation = MDS_MITIGATION_FULL;
+ 		mds_select_mitigation();
+ 	}
+ 	if (taa_mitigation == TAA_MITIGATION_OFF &&
+ 	    boot_cpu_has_bug(X86_BUG_TAA)) {
+ 		taa_mitigation = TAA_MITIGATION_VERW;
+ 		taa_select_mitigation();
+ 	}
+ 	if (mmio_mitigation == MMIO_MITIGATION_OFF &&
+ 	    boot_cpu_has_bug(X86_BUG_MMIO_STALE_DATA)) {
+ 		mmio_mitigation = MMIO_MITIGATION_VERW;
+ 		mmio_select_mitigation();
+ 	}
+ out:
+ 	if (boot_cpu_has_bug(X86_BUG_MDS))
+ 		pr_info("MDS: %s\n", mds_strings[mds_mitigation]);
+ 	if (boot_cpu_has_bug(X86_BUG_TAA))
+ 		pr_info("TAA: %s\n", taa_strings[taa_mitigation]);
+ 	if (boot_cpu_has_bug(X86_BUG_MMIO_STALE_DATA))
+ 		pr_info("MMIO Stale Data: %s\n", mmio_strings[mmio_mitigation]);
+ }
+ 
+ static void __init md_clear_select_mitigation(void)
+ {
+ 	mds_select_mitigation();
+ 	taa_select_mitigation();
+ 	mmio_select_mitigation();
+ 
+ 	/*
+ 	 * As MDS, TAA and MMIO Stale Data mitigations are inter-related, update
+ 	 * and print their mitigation after MDS, TAA and MMIO Stale Data
+ 	 * mitigation selection is done.
+ 	 */
+ 	md_clear_update_mitigation();
+ }
+ 
+ #undef pr_fmt
++>>>>>>> 99a83db5a605 (x86/speculation/mmio: Enable CPU Fill buffer clearing on idle)
  #define pr_fmt(fmt)	"SRBDS: " fmt
  
  enum srbds_mitigations {
@@@ -679,13 -1243,15 +829,22 @@@ static void update_mds_branch_idle(void
  	 * clearing the buffers on idle just to prevent the Store Buffer
  	 * repartitioning leak would be a window dressing exercise.
  	 */
 -	if (!boot_cpu_has_bug(X86_BUG_MSBDS_ONLY))
 +	if (!boot_cpu_has(X86_BUG_MSBDS_ONLY))
  		return;
  
++<<<<<<< HEAD
 +	if (sched_smt_active() && !static_key_enabled(&mds_idle_clear))
 +		static_key_slow_inc(&mds_idle_clear);
 +	else if (!sched_smt_active() && static_key_enabled(&mds_idle_clear))
 +		static_key_slow_dec(&mds_idle_clear);
++=======
+ 	if (sched_smt_active()) {
+ 		static_branch_enable(&mds_idle_clear);
+ 	} else if (mmio_mitigation == MMIO_MITIGATION_OFF ||
+ 		   (ia32_cap & ARCH_CAP_FBSDP_NO)) {
+ 		static_branch_disable(&mds_idle_clear);
+ 	}
++>>>>>>> 99a83db5a605 (x86/speculation/mmio: Enable CPU Fill buffer clearing on idle)
  }
  
  #define MDS_MSG_SMT "MDS CPU bug present and SMT on, data leak possible. See https://www.kernel.org/doc/html/latest/admin-guide/hw-vuln/mds.html for more details.\n"
* Unmerged path arch/x86/kernel/cpu/bugs.c
