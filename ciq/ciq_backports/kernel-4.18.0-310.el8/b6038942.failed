mm: memcg: add swapcache stat for memcg v2

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Shakeel Butt <shakeelb@google.com>
commit b6038942480e574c697ea1a80019bbe586c1d654
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/b6038942.failed

This patch adds swapcache stat for the cgroup v2.  The swapcache
represents the memory that is accounted against both the memory and the
swap limit of the cgroup.  The main motivation behind exposing the
swapcache stat is for enabling users to gracefully migrate from cgroup
v1's memsw counter to cgroup v2's memory and swap counters.

Cgroup v1's memsw limit allows users to limit the memory+swap usage of a
workload but without control on the exact proportion of memory and swap.
Cgroup v2 provides separate limits for memory and swap which enables more
control on the exact usage of memory and swap individually for the
workload.

With some little subtleties, the v1's memsw limit can be switched with the
sum of the v2's memory and swap limits.  However the alternative for memsw
usage is not yet available in cgroup v2.  Exposing per-cgroup swapcache
stat enables that alternative.  Adding the memory usage and swap usage and
subtracting the swapcache will approximate the memsw usage.  This will
help in the transparent migration of the workloads depending on memsw
usage and limit to v2' memory and swap counters.

The reasons these applications are still interested in this approximate
memsw usage are: (1) these applications are not really interested in two
separate memory and swap usage metrics.  A single usage metric is more
simple to use and reason about for them.

(2) The memsw usage metric hides the underlying system's swap setup from
the applications.  Applications with multiple instances running in a
datacenter with heterogeneous systems (some have swap and some don't) will
keep seeing a consistent view of their usage.

[akpm@linux-foundation.org: fix CONFIG_SWAP=n build]

Link: https://lkml.kernel.org/r/20210108155813.2914586-3-shakeelb@google.com
	Signed-off-by: Shakeel Butt <shakeelb@google.com>
	Acked-by: Michal Hocko <mhocko@suse.com>
	Reviewed-by: Roman Gushchin <guro@fb.com>
	Cc: Johannes Weiner <hannes@cmpxchg.org>
	Cc: Muchun Song <songmuchun@bytedance.com>
	Cc: Yang Shi <shy828301@gmail.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit b6038942480e574c697ea1a80019bbe586c1d654)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/base/node.c
#	include/linux/mmzone.h
#	mm/memcontrol.c
#	mm/migrate.c
#	mm/vmstat.c
diff --cc drivers/base/node.c
index 8633d5d90a7d,f449dbb2c746..000000000000
--- a/drivers/base/node.c
+++ b/drivers/base/node.c
@@@ -369,99 -377,105 +370,132 @@@ static ssize_t node_read_meminfo(struc
  	si_meminfo_node(&i, nid);
  	sreclaimable = node_page_state_pages(pgdat, NR_SLAB_RECLAIMABLE_B);
  	sunreclaimable = node_page_state_pages(pgdat, NR_SLAB_UNRECLAIMABLE_B);
++<<<<<<< HEAD
 +	n = sprintf(buf,
 +		       "Node %d MemTotal:       %8lu kB\n"
 +		       "Node %d MemFree:        %8lu kB\n"
 +		       "Node %d MemUsed:        %8lu kB\n"
 +		       "Node %d Active:         %8lu kB\n"
 +		       "Node %d Inactive:       %8lu kB\n"
 +		       "Node %d Active(anon):   %8lu kB\n"
 +		       "Node %d Inactive(anon): %8lu kB\n"
 +		       "Node %d Active(file):   %8lu kB\n"
 +		       "Node %d Inactive(file): %8lu kB\n"
 +		       "Node %d Unevictable:    %8lu kB\n"
 +		       "Node %d Mlocked:        %8lu kB\n",
 +		       nid, K(i.totalram),
 +		       nid, K(i.freeram),
 +		       nid, K(i.totalram - i.freeram),
 +		       nid, K(node_page_state(pgdat, NR_ACTIVE_ANON) +
 +				node_page_state(pgdat, NR_ACTIVE_FILE)),
 +		       nid, K(node_page_state(pgdat, NR_INACTIVE_ANON) +
 +				node_page_state(pgdat, NR_INACTIVE_FILE)),
 +		       nid, K(node_page_state(pgdat, NR_ACTIVE_ANON)),
 +		       nid, K(node_page_state(pgdat, NR_INACTIVE_ANON)),
 +		       nid, K(node_page_state(pgdat, NR_ACTIVE_FILE)),
 +		       nid, K(node_page_state(pgdat, NR_INACTIVE_FILE)),
 +		       nid, K(node_page_state(pgdat, NR_UNEVICTABLE)),
 +		       nid, K(sum_zone_node_page_state(nid, NR_MLOCK)));
++=======
+ #ifdef CONFIG_SWAP
+ 	swapcached = node_page_state_pages(pgdat, NR_SWAPCACHE);
+ #endif
+ 	len = sysfs_emit_at(buf, len,
+ 			    "Node %d MemTotal:       %8lu kB\n"
+ 			    "Node %d MemFree:        %8lu kB\n"
+ 			    "Node %d MemUsed:        %8lu kB\n"
+ 			    "Node %d SwapCached:     %8lu kB\n"
+ 			    "Node %d Active:         %8lu kB\n"
+ 			    "Node %d Inactive:       %8lu kB\n"
+ 			    "Node %d Active(anon):   %8lu kB\n"
+ 			    "Node %d Inactive(anon): %8lu kB\n"
+ 			    "Node %d Active(file):   %8lu kB\n"
+ 			    "Node %d Inactive(file): %8lu kB\n"
+ 			    "Node %d Unevictable:    %8lu kB\n"
+ 			    "Node %d Mlocked:        %8lu kB\n",
+ 			    nid, K(i.totalram),
+ 			    nid, K(i.freeram),
+ 			    nid, K(i.totalram - i.freeram),
+ 			    nid, K(swapcached),
+ 			    nid, K(node_page_state(pgdat, NR_ACTIVE_ANON) +
+ 				   node_page_state(pgdat, NR_ACTIVE_FILE)),
+ 			    nid, K(node_page_state(pgdat, NR_INACTIVE_ANON) +
+ 				   node_page_state(pgdat, NR_INACTIVE_FILE)),
+ 			    nid, K(node_page_state(pgdat, NR_ACTIVE_ANON)),
+ 			    nid, K(node_page_state(pgdat, NR_INACTIVE_ANON)),
+ 			    nid, K(node_page_state(pgdat, NR_ACTIVE_FILE)),
+ 			    nid, K(node_page_state(pgdat, NR_INACTIVE_FILE)),
+ 			    nid, K(node_page_state(pgdat, NR_UNEVICTABLE)),
+ 			    nid, K(sum_zone_node_page_state(nid, NR_MLOCK)));
++>>>>>>> b6038942480e (mm: memcg: add swapcache stat for memcg v2)
  
  #ifdef CONFIG_HIGHMEM
 -	len += sysfs_emit_at(buf, len,
 -			     "Node %d HighTotal:      %8lu kB\n"
 -			     "Node %d HighFree:       %8lu kB\n"
 -			     "Node %d LowTotal:       %8lu kB\n"
 -			     "Node %d LowFree:        %8lu kB\n",
 -			     nid, K(i.totalhigh),
 -			     nid, K(i.freehigh),
 -			     nid, K(i.totalram - i.totalhigh),
 -			     nid, K(i.freeram - i.freehigh));
 +	n += sprintf(buf + n,
 +		       "Node %d HighTotal:      %8lu kB\n"
 +		       "Node %d HighFree:       %8lu kB\n"
 +		       "Node %d LowTotal:       %8lu kB\n"
 +		       "Node %d LowFree:        %8lu kB\n",
 +		       nid, K(i.totalhigh),
 +		       nid, K(i.freehigh),
 +		       nid, K(i.totalram - i.totalhigh),
 +		       nid, K(i.freeram - i.freehigh));
  #endif
 -	len += sysfs_emit_at(buf, len,
 -			     "Node %d Dirty:          %8lu kB\n"
 -			     "Node %d Writeback:      %8lu kB\n"
 -			     "Node %d FilePages:      %8lu kB\n"
 -			     "Node %d Mapped:         %8lu kB\n"
 -			     "Node %d AnonPages:      %8lu kB\n"
 -			     "Node %d Shmem:          %8lu kB\n"
 -			     "Node %d KernelStack:    %8lu kB\n"
 -#ifdef CONFIG_SHADOW_CALL_STACK
 -			     "Node %d ShadowCallStack:%8lu kB\n"
 -#endif
 -			     "Node %d PageTables:     %8lu kB\n"
 -			     "Node %d NFS_Unstable:   %8lu kB\n"
 -			     "Node %d Bounce:         %8lu kB\n"
 -			     "Node %d WritebackTmp:   %8lu kB\n"
 -			     "Node %d KReclaimable:   %8lu kB\n"
 -			     "Node %d Slab:           %8lu kB\n"
 -			     "Node %d SReclaimable:   %8lu kB\n"
 -			     "Node %d SUnreclaim:     %8lu kB\n"
 +	n += sprintf(buf + n,
 +		       "Node %d Dirty:          %8lu kB\n"
 +		       "Node %d Writeback:      %8lu kB\n"
 +		       "Node %d FilePages:      %8lu kB\n"
 +		       "Node %d Mapped:         %8lu kB\n"
 +		       "Node %d AnonPages:      %8lu kB\n"
 +		       "Node %d Shmem:          %8lu kB\n"
 +		       "Node %d KernelStack:    %8lu kB\n"
 +		       "Node %d PageTables:     %8lu kB\n"
 +		       "Node %d NFS_Unstable:   %8lu kB\n"
 +		       "Node %d Bounce:         %8lu kB\n"
 +		       "Node %d WritebackTmp:   %8lu kB\n"
 +		       "Node %d KReclaimable:   %8lu kB\n"
 +		       "Node %d Slab:           %8lu kB\n"
 +		       "Node %d SReclaimable:   %8lu kB\n"
 +		       "Node %d SUnreclaim:     %8lu kB\n"
  #ifdef CONFIG_TRANSPARENT_HUGEPAGE
 -			     "Node %d AnonHugePages:  %8lu kB\n"
 -			     "Node %d ShmemHugePages: %8lu kB\n"
 -			     "Node %d ShmemPmdMapped: %8lu kB\n"
 -			     "Node %d FileHugePages: %8lu kB\n"
 -			     "Node %d FilePmdMapped: %8lu kB\n"
 -#endif
 -			     ,
 -			     nid, K(node_page_state(pgdat, NR_FILE_DIRTY)),
 -			     nid, K(node_page_state(pgdat, NR_WRITEBACK)),
 -			     nid, K(node_page_state(pgdat, NR_FILE_PAGES)),
 -			     nid, K(node_page_state(pgdat, NR_FILE_MAPPED)),
 -			     nid, K(node_page_state(pgdat, NR_ANON_MAPPED)),
 -			     nid, K(i.sharedram),
 -			     nid, node_page_state(pgdat, NR_KERNEL_STACK_KB),
 -#ifdef CONFIG_SHADOW_CALL_STACK
 -			     nid, node_page_state(pgdat, NR_KERNEL_SCS_KB),
 +		       "Node %d AnonHugePages:  %8lu kB\n"
 +		       "Node %d ShmemHugePages: %8lu kB\n"
 +		       "Node %d ShmemPmdMapped: %8lu kB\n"
 +		       "Node %d FileHugePages: %8lu kB\n"
 +		       "Node %d FilePmdMapped: %8lu kB\n"
  #endif
 -			     nid, K(node_page_state(pgdat, NR_PAGETABLE)),
 -			     nid, 0UL,
 -			     nid, K(sum_zone_node_page_state(nid, NR_BOUNCE)),
 -			     nid, K(node_page_state(pgdat, NR_WRITEBACK_TEMP)),
 -			     nid, K(sreclaimable +
 -				    node_page_state(pgdat, NR_KERNEL_MISC_RECLAIMABLE)),
 -			     nid, K(sreclaimable + sunreclaimable),
 -			     nid, K(sreclaimable),
 -			     nid, K(sunreclaimable)
 +			,
 +		       nid, K(node_page_state(pgdat, NR_FILE_DIRTY)),
 +		       nid, K(node_page_state(pgdat, NR_WRITEBACK)),
 +		       nid, K(node_page_state(pgdat, NR_FILE_PAGES)),
 +		       nid, K(node_page_state(pgdat, NR_FILE_MAPPED)),
 +		       nid, K(node_page_state(pgdat, NR_ANON_MAPPED)),
 +		       nid, K(i.sharedram),
 +		       nid, sum_zone_node_page_state(nid, NR_KERNEL_STACK_KB),
 +		       nid, K(sum_zone_node_page_state(nid, NR_PAGETABLE)),
 +		       nid, 0UL,
 +		       nid, K(sum_zone_node_page_state(nid, NR_BOUNCE)),
 +		       nid, K(node_page_state(pgdat, NR_WRITEBACK_TEMP)),
 +		       nid, K(sreclaimable +
 +			      node_page_state(pgdat, NR_KERNEL_MISC_RECLAIMABLE)),
 +		       nid, K(sreclaimable + sunreclaimable),
 +		       nid, K(sreclaimable),
 +		       nid, K(sunreclaimable)
  #ifdef CONFIG_TRANSPARENT_HUGEPAGE
 -			     ,
 -			     nid, K(node_page_state(pgdat, NR_ANON_THPS)),
 -			     nid, K(node_page_state(pgdat, NR_SHMEM_THPS)),
 -			     nid, K(node_page_state(pgdat, NR_SHMEM_PMDMAPPED)),
 -			     nid, K(node_page_state(pgdat, NR_FILE_THPS)),
 -			     nid, K(node_page_state(pgdat, NR_FILE_PMDMAPPED))
 +		       ,
 +		       nid, K(node_page_state(pgdat, NR_ANON_THPS) *
 +				       HPAGE_PMD_NR),
 +		       nid, K(node_page_state(pgdat, NR_SHMEM_THPS) *
 +				       HPAGE_PMD_NR),
 +		       nid, K(node_page_state(pgdat, NR_SHMEM_PMDMAPPED) *
 +				       HPAGE_PMD_NR),
 +		       nid, K(node_page_state(pgdat, NR_FILE_THPS) *
 +				       HPAGE_PMD_NR),
 +		       nid, K(node_page_state(pgdat, NR_FILE_PMDMAPPED) *
 +				       HPAGE_PMD_NR)
  #endif
 -			    );
 -	len += hugetlb_report_node_meminfo(buf, len, nid);
 -	return len;
 +		       );
 +	n += hugetlb_report_node_meminfo(nid, buf + n);
 +	return n;
  }
  
  #undef K
diff --cc include/linux/mmzone.h
index ae118ed2cb9b,fc99e9241846..000000000000
--- a/include/linux/mmzone.h
+++ b/include/linux/mmzone.h
@@@ -206,9 -198,17 +206,23 @@@ enum node_stat_item 
  	NR_VMSCAN_IMMEDIATE,	/* Prioritise for reclaim when writeback ends */
  	NR_DIRTIED,		/* page dirtyings since bootup */
  	NR_WRITTEN,		/* page writings since bootup */
++<<<<<<< HEAD
 +	RH_KABI_RENAME(NR_INDIRECTLY_RECLAIMABLE_BYTES,
 +		       NR_KERNEL_MISC_RECLAIMABLE),
 +				/* reclaimable non-slab kernel pages */
++=======
+ 	NR_KERNEL_MISC_RECLAIMABLE,	/* reclaimable non-slab kernel pages */
+ 	NR_FOLL_PIN_ACQUIRED,	/* via: pin_user_page(), gup flag: FOLL_PIN */
+ 	NR_FOLL_PIN_RELEASED,	/* pages returned via unpin_user_page() */
+ 	NR_KERNEL_STACK_KB,	/* measured in KiB */
+ #if IS_ENABLED(CONFIG_SHADOW_CALL_STACK)
+ 	NR_KERNEL_SCS_KB,	/* measured in KiB */
+ #endif
+ 	NR_PAGETABLE,		/* used for pagetables */
+ #ifdef CONFIG_SWAP
+ 	NR_SWAPCACHE,
+ #endif
++>>>>>>> b6038942480e (mm: memcg: add swapcache stat for memcg v2)
  	NR_VM_NODE_STAT_ITEMS
  };
  
diff --cc mm/memcontrol.c
index 4d65b541b4a3,58edfb6614b8..000000000000
--- a/mm/memcontrol.c
+++ b/mm/memcontrol.c
@@@ -1468,6 -1505,76 +1468,79 @@@ static bool mem_cgroup_wait_acct_move(s
  	return false;
  }
  
++<<<<<<< HEAD
++=======
+ struct memory_stat {
+ 	const char *name;
+ 	unsigned int idx;
+ };
+ 
+ static const struct memory_stat memory_stats[] = {
+ 	{ "anon",			NR_ANON_MAPPED			},
+ 	{ "file",			NR_FILE_PAGES			},
+ 	{ "kernel_stack",		NR_KERNEL_STACK_KB		},
+ 	{ "pagetables",			NR_PAGETABLE			},
+ 	{ "percpu",			MEMCG_PERCPU_B			},
+ 	{ "sock",			MEMCG_SOCK			},
+ 	{ "shmem",			NR_SHMEM			},
+ 	{ "file_mapped",		NR_FILE_MAPPED			},
+ 	{ "file_dirty",			NR_FILE_DIRTY			},
+ 	{ "file_writeback",		NR_WRITEBACK			},
+ #ifdef CONFIG_SWAP
+ 	{ "swapcached",			NR_SWAPCACHE			},
+ #endif
+ #ifdef CONFIG_TRANSPARENT_HUGEPAGE
+ 	{ "anon_thp",			NR_ANON_THPS			},
+ 	{ "file_thp",			NR_FILE_THPS			},
+ 	{ "shmem_thp",			NR_SHMEM_THPS			},
+ #endif
+ 	{ "inactive_anon",		NR_INACTIVE_ANON		},
+ 	{ "active_anon",		NR_ACTIVE_ANON			},
+ 	{ "inactive_file",		NR_INACTIVE_FILE		},
+ 	{ "active_file",		NR_ACTIVE_FILE			},
+ 	{ "unevictable",		NR_UNEVICTABLE			},
+ 	{ "slab_reclaimable",		NR_SLAB_RECLAIMABLE_B		},
+ 	{ "slab_unreclaimable",		NR_SLAB_UNRECLAIMABLE_B		},
+ 
+ 	/* The memory events */
+ 	{ "workingset_refault_anon",	WORKINGSET_REFAULT_ANON		},
+ 	{ "workingset_refault_file",	WORKINGSET_REFAULT_FILE		},
+ 	{ "workingset_activate_anon",	WORKINGSET_ACTIVATE_ANON	},
+ 	{ "workingset_activate_file",	WORKINGSET_ACTIVATE_FILE	},
+ 	{ "workingset_restore_anon",	WORKINGSET_RESTORE_ANON		},
+ 	{ "workingset_restore_file",	WORKINGSET_RESTORE_FILE		},
+ 	{ "workingset_nodereclaim",	WORKINGSET_NODERECLAIM		},
+ };
+ 
+ /* Translate stat items to the correct unit for memory.stat output */
+ static int memcg_page_state_unit(int item)
+ {
+ 	switch (item) {
+ 	case MEMCG_PERCPU_B:
+ 	case NR_SLAB_RECLAIMABLE_B:
+ 	case NR_SLAB_UNRECLAIMABLE_B:
+ 	case WORKINGSET_REFAULT_ANON:
+ 	case WORKINGSET_REFAULT_FILE:
+ 	case WORKINGSET_ACTIVATE_ANON:
+ 	case WORKINGSET_ACTIVATE_FILE:
+ 	case WORKINGSET_RESTORE_ANON:
+ 	case WORKINGSET_RESTORE_FILE:
+ 	case WORKINGSET_NODERECLAIM:
+ 		return 1;
+ 	case NR_KERNEL_STACK_KB:
+ 		return SZ_1K;
+ 	default:
+ 		return PAGE_SIZE;
+ 	}
+ }
+ 
+ static inline unsigned long memcg_page_state_output(struct mem_cgroup *memcg,
+ 						    int item)
+ {
+ 	return memcg_page_state(memcg, item) * memcg_page_state_unit(item);
+ }
+ 
++>>>>>>> b6038942480e (mm: memcg: add swapcache stat for memcg v2)
  static char *memory_stat_format(struct mem_cgroup *memcg)
  {
  	struct seq_buf s;
diff --cc mm/migrate.c
index 357768f2aa73,62b81d5257aa..000000000000
--- a/mm/migrate.c
+++ b/mm/migrate.c
@@@ -494,17 -494,23 +494,31 @@@ int migrate_page_move_mapping(struct ad
  		old_lruvec = mem_cgroup_lruvec(memcg, oldzone->zone_pgdat);
  		new_lruvec = mem_cgroup_lruvec(memcg, newzone->zone_pgdat);
  
 -		__mod_lruvec_state(old_lruvec, NR_FILE_PAGES, -nr);
 -		__mod_lruvec_state(new_lruvec, NR_FILE_PAGES, nr);
 +		__dec_lruvec_state(old_lruvec, NR_FILE_PAGES);
 +		__inc_lruvec_state(new_lruvec, NR_FILE_PAGES);
  		if (PageSwapBacked(page) && !PageSwapCache(page)) {
 -			__mod_lruvec_state(old_lruvec, NR_SHMEM, -nr);
 -			__mod_lruvec_state(new_lruvec, NR_SHMEM, nr);
 +			__dec_lruvec_state(old_lruvec, NR_SHMEM);
 +			__inc_lruvec_state(new_lruvec, NR_SHMEM);
  		}
++<<<<<<< HEAD
 +		if (dirty && mapping_cap_account_dirty(mapping)) {
 +			__dec_node_state(oldzone->zone_pgdat, NR_FILE_DIRTY);
 +			__dec_zone_state(oldzone, NR_ZONE_WRITE_PENDING);
 +			__inc_node_state(newzone->zone_pgdat, NR_FILE_DIRTY);
 +			__inc_zone_state(newzone, NR_ZONE_WRITE_PENDING);
++=======
+ #ifdef CONFIG_SWAP
+ 		if (PageSwapCache(page)) {
+ 			__mod_lruvec_state(old_lruvec, NR_SWAPCACHE, -nr);
+ 			__mod_lruvec_state(new_lruvec, NR_SWAPCACHE, nr);
+ 		}
+ #endif
+ 		if (dirty && mapping_can_writeback(mapping)) {
+ 			__mod_lruvec_state(old_lruvec, NR_FILE_DIRTY, -nr);
+ 			__mod_zone_page_state(oldzone, NR_ZONE_WRITE_PENDING, -nr);
+ 			__mod_lruvec_state(new_lruvec, NR_FILE_DIRTY, nr);
+ 			__mod_zone_page_state(newzone, NR_ZONE_WRITE_PENDING, nr);
++>>>>>>> b6038942480e (mm: memcg: add swapcache stat for memcg v2)
  		}
  	}
  	local_irq_enable();
diff --cc mm/vmstat.c
index d9662e48d82b,a0e949542204..000000000000
--- a/mm/vmstat.c
+++ b/mm/vmstat.c
@@@ -1209,6 -1208,16 +1209,19 @@@ const char * const vmstat_text[] = 
  	"nr_dirtied",
  	"nr_written",
  	"nr_kernel_misc_reclaimable",
++<<<<<<< HEAD
++=======
+ 	"nr_foll_pin_acquired",
+ 	"nr_foll_pin_released",
+ 	"nr_kernel_stack",
+ #if IS_ENABLED(CONFIG_SHADOW_CALL_STACK)
+ 	"nr_shadow_call_stack",
+ #endif
+ 	"nr_page_table_pages",
+ #ifdef CONFIG_SWAP
+ 	"nr_swapcached",
+ #endif
++>>>>>>> b6038942480e (mm: memcg: add swapcache stat for memcg v2)
  
  	/* enum writeback_stat_item counters */
  	"nr_dirty_threshold",
diff --git a/Documentation/admin-guide/cgroup-v2.rst b/Documentation/admin-guide/cgroup-v2.rst
index bc0fc04d2632..4cf6bb701fbd 100644
--- a/Documentation/admin-guide/cgroup-v2.rst
+++ b/Documentation/admin-guide/cgroup-v2.rst
@@ -1264,6 +1264,10 @@ PAGE_SIZE multiple when read back.
 		Amount of cached filesystem data that was modified and
 		is currently being written back to disk
 
+	  swapcached
+		Amount of swap cached in memory. The swapcache is accounted
+		against both memory and swap usage.
+
 	  anon_thp
 		Amount of memory used in anonymous mappings backed by
 		transparent hugepages
* Unmerged path drivers/base/node.c
* Unmerged path include/linux/mmzone.h
diff --git a/include/linux/swap.h b/include/linux/swap.h
index c9e934b74fab..0c0dfe7baa9c 100644
--- a/include/linux/swap.h
+++ b/include/linux/swap.h
@@ -403,7 +403,11 @@ extern struct address_space *swapper_spaces[];
 #define swap_address_space(entry)			    \
 	(&swapper_spaces[swp_type(entry)][swp_offset(entry) \
 		>> SWAP_ADDRESS_SPACE_SHIFT])
-extern unsigned long total_swapcache_pages(void);
+static inline unsigned long total_swapcache_pages(void)
+{
+	return global_node_page_state(NR_SWAPCACHE);
+}
+
 extern void show_swap_cache_info(void);
 extern int add_to_swap(struct page *page);
 extern void *get_shadow_from_swap_cache(swp_entry_t entry);
* Unmerged path mm/memcontrol.c
* Unmerged path mm/migrate.c
diff --git a/mm/swap_state.c b/mm/swap_state.c
index c32697c97df0..7a4149d984b9 100644
--- a/mm/swap_state.c
+++ b/mm/swap_state.c
@@ -69,32 +69,6 @@ static struct {
 	unsigned long find_total;
 } swap_cache_info;
 
-unsigned long total_swapcache_pages(void)
-{
-	unsigned int i, j, nr;
-	unsigned long ret = 0;
-	struct address_space *spaces;
-	struct swap_info_struct *si;
-
-	for (i = 0; i < MAX_SWAPFILES; i++) {
-		swp_entry_t entry = swp_entry(i, 1);
-
-		/* Avoid get_swap_device() to warn for bad swap entry */
-		if (!swp_swap_info(entry))
-			continue;
-		/* Prevent swapoff to free swapper_spaces */
-		si = get_swap_device(entry);
-		if (!si)
-			continue;
-		nr = nr_swapper_spaces[i];
-		spaces = swapper_spaces[i];
-		for (j = 0; j < nr; j++)
-			ret += spaces[j].nrpages;
-		put_swap_device(si);
-	}
-	return ret;
-}
-
 static atomic_t swapin_readahead_hits = ATOMIC_INIT(4);
 
 void show_swap_cache_info(void)
@@ -164,6 +138,7 @@ int add_to_swap_cache(struct page *page, swp_entry_t entry,
 		address_space->nrexceptional -= nr_shadows;
 		address_space->nrpages += nr;
 		__mod_node_page_state(page_pgdat(page), NR_FILE_PAGES, nr);
+		__mod_lruvec_page_state(page, NR_SWAPCACHE, nr);
 		ADD_CACHE_INFO(add_total, nr);
 unlock:
 		xas_unlock_irq(&xas);
@@ -204,6 +179,7 @@ void __delete_from_swap_cache(struct page *page,
 		address_space->nrexceptional += nr;
 	address_space->nrpages -= nr;
 	__mod_node_page_state(page_pgdat(page), NR_FILE_PAGES, -nr);
+	__mod_lruvec_page_state(page, NR_SWAPCACHE, -nr);
 	ADD_CACHE_INFO(del_total, nr);
 }
 
* Unmerged path mm/vmstat.c
