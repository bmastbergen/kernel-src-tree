KVM: x86/xen: Take srcu lock when accessing kvm_memslots()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Wanpeng Li <wanpengli@tencent.com>
commit 9c1a07442c95f6e64dc8de099e9f35ea73db7852
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/9c1a0744.failed

kvm_memslots() will be called by kvm_write_guest_offset_cached() so we should
take the srcu lock. Let's pull the srcu lock operation from kvm_steal_time_set_preempted()
again to fix xen part.

Fixes: 30b5c851af7 ("KVM: x86/xen: Add support for vCPU runstate information")
	Signed-off-by: Wanpeng Li <wanpengli@tencent.com>
Message-Id: <1619166200-9215-1-git-send-email-wanpengli@tencent.com>
	Reviewed-by: Sean Christopherson <seanjc@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 9c1a07442c95f6e64dc8de099e9f35ea73db7852)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/x86.c
diff --cc arch/x86/kvm/x86.c
index b9d8fad34207,ee0dc58ac3a5..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -4033,18 -4047,22 +4033,35 @@@ static void kvm_steal_time_set_preempte
  void kvm_arch_vcpu_put(struct kvm_vcpu *vcpu)
  {
  	int idx;
++<<<<<<< HEAD
 +
 +	if (vcpu->preempted)
 +		vcpu->arch.preempted_in_kernel = !kvm_x86_ops.get_cpl(vcpu);
++=======
+ 
+ 	if (vcpu->preempted && !vcpu->arch.guest_state_protected)
+ 		vcpu->arch.preempted_in_kernel = !static_call(kvm_x86_get_cpl)(vcpu);
+ 
+ 	/*
+ 	 * Take the srcu lock as memslots will be accessed to check the gfn
+ 	 * cache generation against the memslots generation.
+ 	 */
+ 	idx = srcu_read_lock(&vcpu->kvm->srcu);
+ 	if (kvm_xen_msr_enabled(vcpu->kvm))
+ 		kvm_xen_runstate_set_preempted(vcpu);
+ 	else
+ 		kvm_steal_time_set_preempted(vcpu);
+ 	srcu_read_unlock(&vcpu->kvm->srcu, idx);
++>>>>>>> 9c1a07442c95 (KVM: x86/xen: Take srcu lock when accessing kvm_memslots())
  
 -	static_call(kvm_x86_vcpu_put)(vcpu);
 +	/*
 +	 * kvm_memslots() will be called by
 +	 * kvm_write_guest_offset_cached() so take the srcu lock.
 +	 */
 +	idx = srcu_read_lock(&vcpu->kvm->srcu);
 +	kvm_steal_time_set_preempted(vcpu);
 +	srcu_read_unlock(&vcpu->kvm->srcu, idx);
 +	kvm_x86_ops.vcpu_put(vcpu);
  	vcpu->arch.last_host_tsc = rdtsc();
  	/*
  	 * If userspace has set any breakpoints or watchpoints, dr6 is restored
* Unmerged path arch/x86/kvm/x86.c
