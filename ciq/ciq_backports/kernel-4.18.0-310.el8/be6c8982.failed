mm/memcg: rename mem_cgroup_split_huge_fixup to split_page_memcg and add nr_pages argument

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Zhou Guanghui <zhouguanghui1@huawei.com>
commit be6c8982e4ab9a41907555f601b711a7e2a17d4c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/be6c8982.failed

Rename mem_cgroup_split_huge_fixup to split_page_memcg and explicitly pass
in page number argument.

In this way, the interface name is more common and can be used by
potential users.  In addition, the complete info(memcg and flag) of the
memcg needs to be set to the tail pages.

Link: https://lkml.kernel.org/r/20210304074053.65527-2-zhouguanghui1@huawei.com
	Signed-off-by: Zhou Guanghui <zhouguanghui1@huawei.com>
	Acked-by: Johannes Weiner <hannes@cmpxchg.org>
	Reviewed-by: Zi Yan <ziy@nvidia.com>
	Reviewed-by: Shakeel Butt <shakeelb@google.com>
	Acked-by: Michal Hocko <mhocko@suse.com>
	Cc: Hugh Dickins <hughd@google.com>
	Cc: "Kirill A. Shutemov" <kirill.shutemov@linux.intel.com>
	Cc: Nicholas Piggin <npiggin@gmail.com>
	Cc: Kefeng Wang <wangkefeng.wang@huawei.com>
	Cc: Hanjun Guo <guohanjun@huawei.com>
	Cc: Tianhong Ding <dingtianhong@huawei.com>
	Cc: Weilong Chen <chenweilong@huawei.com>
	Cc: Rui Xiang <rui.xiang@huawei.com>
	Cc: <stable@vger.kernel.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit be6c8982e4ab9a41907555f601b711a7e2a17d4c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/memcontrol.c
diff --cc mm/memcontrol.c
index b2ef364998e2,e064ac0d850a..000000000000
--- a/mm/memcontrol.c
+++ b/mm/memcontrol.c
@@@ -3235,26 -3287,21 +3235,36 @@@ void obj_cgroup_uncharge(struct obj_cgr
  
  #endif /* CONFIG_MEMCG_KMEM */
  
++<<<<<<< HEAD
 +#ifdef CONFIG_TRANSPARENT_HUGEPAGE
 +
 +/*
 + * Because tail pages are not marked as "used", set it. We're under
 + * pgdat->lru_lock and migration entries setup in all page mappings.
++=======
+ /*
+  * Because page_memcg(head) is not set on tails, set it now.
++>>>>>>> be6c8982e4ab (mm/memcg: rename mem_cgroup_split_huge_fixup to split_page_memcg and add nr_pages argument)
   */
- void mem_cgroup_split_huge_fixup(struct page *head)
+ void split_page_memcg(struct page *head, unsigned int nr)
  {
 -	struct mem_cgroup *memcg = page_memcg(head);
 +	struct mem_cgroup *memcg = head->mem_cgroup;
  	int i;
  
- 	if (mem_cgroup_disabled())
+ 	if (mem_cgroup_disabled() || !memcg)
  		return;
  
++<<<<<<< HEAD
 +	for (i = 1; i < HPAGE_PMD_NR; i++) {
 +		css_get(&memcg->css);
 +		head[i].mem_cgroup = memcg;
 +	}
++=======
+ 	for (i = 1; i < nr; i++)
+ 		head[i].memcg_data = head->memcg_data;
+ 	css_get_many(&memcg->css, nr - 1);
++>>>>>>> be6c8982e4ab (mm/memcg: rename mem_cgroup_split_huge_fixup to split_page_memcg and add nr_pages argument)
  }
- #endif /* CONFIG_TRANSPARENT_HUGEPAGE */
  
  #ifdef CONFIG_MEMCG_SWAP
  /**
diff --git a/include/linux/memcontrol.h b/include/linux/memcontrol.h
index 3926e67f2ee6..5b23bb8149fb 100644
--- a/include/linux/memcontrol.h
+++ b/include/linux/memcontrol.h
@@ -962,9 +962,7 @@ static inline void memcg_memory_event_mm(struct mm_struct *mm,
 	rcu_read_unlock();
 }
 
-#ifdef CONFIG_TRANSPARENT_HUGEPAGE
-void mem_cgroup_split_huge_fixup(struct page *head);
-#endif
+void split_page_memcg(struct page *head, unsigned int nr);
 
 #else /* CONFIG_MEMCG */
 
@@ -1275,7 +1273,7 @@ unsigned long mem_cgroup_soft_limit_reclaim(pg_data_t *pgdat, int order,
 	return 0;
 }
 
-static inline void mem_cgroup_split_huge_fixup(struct page *head)
+static inline void split_page_memcg(struct page *head, unsigned int nr)
 {
 }
 
diff --git a/mm/huge_memory.c b/mm/huge_memory.c
index f8f2e337b025..2f3f2da55bd5 100644
--- a/mm/huge_memory.c
+++ b/mm/huge_memory.c
@@ -2350,7 +2350,7 @@ static void __split_huge_page(struct page *page, struct list_head *list,
 	lruvec = mem_cgroup_page_lruvec(head, pgdat);
 
 	/* complete memcg works before add pages to LRU */
-	mem_cgroup_split_huge_fixup(head);
+	split_page_memcg(head, nr);
 
 	if (PageAnon(head) && PageSwapCache(head)) {
 		swp_entry_t entry = { .val = page_private(head) };
* Unmerged path mm/memcontrol.c
