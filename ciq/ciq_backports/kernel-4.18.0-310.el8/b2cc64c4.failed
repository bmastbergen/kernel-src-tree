KVM: Make dirty ring exclusive to dirty bitmap log

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Peter Xu <peterx@redhat.com>
commit b2cc64c4f3829c25b618f23f472a493668d9cb80
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/b2cc64c4.failed

There's no good reason to use both the dirty bitmap logging and the
new dirty ring buffer to track dirty bits.  We should be able to even
support both of them at the same time, but it could complicate things
which could actually help little.  Let's simply make it the rule
before we enable dirty ring on any arch, that we don't allow these two
interfaces to be used together.

The big world switch would be KVM_CAP_DIRTY_LOG_RING capability
enablement.  That's where we'll switch from the default dirty logging
way to the dirty ring way.  As long as kvm->dirty_ring_size is setup
correctly, we'll once and for all switch to the dirty ring buffer mode
for the current virtual machine.

	Signed-off-by: Peter Xu <peterx@redhat.com>
Message-Id: <20201001012224.5818-1-peterx@redhat.com>
[Change errno from EINVAL to ENXIO. - Paolo]
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit b2cc64c4f3829c25b618f23f472a493668d9cb80)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/virt/kvm/api.rst
diff --cc Documentation/virt/kvm/api.rst
index 3ace9a7b536b,70254eaa5229..000000000000
--- a/Documentation/virt/kvm/api.rst
+++ b/Documentation/virt/kvm/api.rst
@@@ -6378,3 -6408,91 +6378,94 @@@ When enabled, KVM will disable paravirt
  guest according to the bits in the KVM_CPUID_FEATURES CPUID leaf
  (0x40000001). Otherwise, a guest may use the paravirtual features
  regardless of what has actually been exposed through the CPUID leaf.
++<<<<<<< HEAD
++=======
+ 
+ 
+ 8.29 KVM_CAP_DIRTY_LOG_RING
+ ---------------------------
+ 
+ :Architectures: x86
+ :Parameters: args[0] - size of the dirty log ring
+ 
+ KVM is capable of tracking dirty memory using ring buffers that are
+ mmaped into userspace; there is one dirty ring per vcpu.
+ 
+ The dirty ring is available to userspace as an array of
+ ``struct kvm_dirty_gfn``.  Each dirty entry it's defined as::
+ 
+   struct kvm_dirty_gfn {
+           __u32 flags;
+           __u32 slot; /* as_id | slot_id */
+           __u64 offset;
+   };
+ 
+ The following values are defined for the flags field to define the
+ current state of the entry::
+ 
+   #define KVM_DIRTY_GFN_F_DIRTY           BIT(0)
+   #define KVM_DIRTY_GFN_F_RESET           BIT(1)
+   #define KVM_DIRTY_GFN_F_MASK            0x3
+ 
+ Userspace should call KVM_ENABLE_CAP ioctl right after KVM_CREATE_VM
+ ioctl to enable this capability for the new guest and set the size of
+ the rings.  Enabling the capability is only allowed before creating any
+ vCPU, and the size of the ring must be a power of two.  The larger the
+ ring buffer, the less likely the ring is full and the VM is forced to
+ exit to userspace. The optimal size depends on the workload, but it is
+ recommended that it be at least 64 KiB (4096 entries).
+ 
+ Just like for dirty page bitmaps, the buffer tracks writes to
+ all user memory regions for which the KVM_MEM_LOG_DIRTY_PAGES flag was
+ set in KVM_SET_USER_MEMORY_REGION.  Once a memory region is registered
+ with the flag set, userspace can start harvesting dirty pages from the
+ ring buffer.
+ 
+ An entry in the ring buffer can be unused (flag bits ``00``),
+ dirty (flag bits ``01``) or harvested (flag bits ``1X``).  The
+ state machine for the entry is as follows::
+ 
+           dirtied         harvested        reset
+      00 -----------> 01 -------------> 1X -------+
+       ^                                          |
+       |                                          |
+       +------------------------------------------+
+ 
+ To harvest the dirty pages, userspace accesses the mmaped ring buffer
+ to read the dirty GFNs.  If the flags has the DIRTY bit set (at this stage
+ the RESET bit must be cleared), then it means this GFN is a dirty GFN.
+ The userspace should harvest this GFN and mark the flags from state
+ ``01b`` to ``1Xb`` (bit 0 will be ignored by KVM, but bit 1 must be set
+ to show that this GFN is harvested and waiting for a reset), and move
+ on to the next GFN.  The userspace should continue to do this until the
+ flags of a GFN have the DIRTY bit cleared, meaning that it has harvested
+ all the dirty GFNs that were available.
+ 
+ It's not necessary for userspace to harvest the all dirty GFNs at once.
+ However it must collect the dirty GFNs in sequence, i.e., the userspace
+ program cannot skip one dirty GFN to collect the one next to it.
+ 
+ After processing one or more entries in the ring buffer, userspace
+ calls the VM ioctl KVM_RESET_DIRTY_RINGS to notify the kernel about
+ it, so that the kernel will reprotect those collected GFNs.
+ Therefore, the ioctl must be called *before* reading the content of
+ the dirty pages.
+ 
+ The dirty ring can get full.  When it happens, the KVM_RUN of the
+ vcpu will return with exit reason KVM_EXIT_DIRTY_LOG_FULL.
+ 
+ The dirty ring interface has a major difference comparing to the
+ KVM_GET_DIRTY_LOG interface in that, when reading the dirty ring from
+ userspace, it's still possible that the kernel has not yet flushed the
+ processor's dirty page buffers into the kernel buffer (with dirty bitmaps, the
+ flushing is done by the KVM_GET_DIRTY_LOG ioctl).  To achieve that, one
+ needs to kick the vcpu out of KVM_RUN using a signal.  The resulting
+ vmexit ensures that all dirty GFNs are flushed to the dirty rings.
+ 
+ NOTE: the capability KVM_CAP_DIRTY_LOG_RING and the corresponding
+ ioctl KVM_RESET_DIRTY_RINGS are mutual exclusive to the existing ioctls
+ KVM_GET_DIRTY_LOG and KVM_CLEAR_DIRTY_LOG.  After enabling
+ KVM_CAP_DIRTY_LOG_RING with an acceptable dirty ring size, the virtual
+ machine will switch to ring-buffer dirty page tracking and further
+ KVM_GET_DIRTY_LOG or KVM_CLEAR_DIRTY_LOG ioctls will fail.
++>>>>>>> b2cc64c4f382 (KVM: Make dirty ring exclusive to dirty bitmap log)
* Unmerged path Documentation/virt/kvm/api.rst
diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index eb2cd93ae4e3..6c74374d9dee 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -1432,6 +1432,10 @@ int kvm_get_dirty_log(struct kvm *kvm, struct kvm_dirty_log *log,
 	unsigned long n;
 	unsigned long any = 0;
 
+	/* Dirty ring tracking is exclusive to dirty log tracking */
+	if (kvm->dirty_ring_size)
+		return -ENXIO;
+
 	*memslot = NULL;
 	*is_dirty = 0;
 
@@ -1493,6 +1497,10 @@ static int kvm_get_dirty_log_protect(struct kvm *kvm, struct kvm_dirty_log *log)
 	unsigned long *dirty_bitmap_buffer;
 	bool flush;
 
+	/* Dirty ring tracking is exclusive to dirty log tracking */
+	if (kvm->dirty_ring_size)
+		return -ENXIO;
+
 	as_id = log->slot >> 16;
 	id = (u16)log->slot;
 	if (as_id >= KVM_ADDRESS_SPACE_NUM || id >= KVM_USER_MEM_SLOTS)
@@ -1601,6 +1609,10 @@ static int kvm_clear_dirty_log_protect(struct kvm *kvm,
 	unsigned long *dirty_bitmap_buffer;
 	bool flush;
 
+	/* Dirty ring tracking is exclusive to dirty log tracking */
+	if (kvm->dirty_ring_size)
+		return -ENXIO;
+
 	as_id = log->slot >> 16;
 	id = (u16)log->slot;
 	if (as_id >= KVM_ADDRESS_SPACE_NUM || id >= KVM_USER_MEM_SLOTS)
