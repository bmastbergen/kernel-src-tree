mm: remove activate_page() from unuse_pte()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Yu Zhao <yuzhao@google.com>
commit cc2828b21c764f901128ca2e7b9f056d0e72104f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/cc2828b2.failed

We don't initially add anon pages to active lruvec after commit
b518154e59aa ("mm/vmscan: protect the workingset on anonymous LRU").
Remove activate_page() from unuse_pte(), which seems to be missed by the
commit.  And make the function static while we are at it.

Before the commit, we called lru_cache_add_active_or_unevictable() to add
new ksm pages to active lruvec.  Therefore, activate_page() wasn't
necessary for them in the first place.

	Signed-off-by: Yu Zhao <yuzhao@google.com>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Reviewed-by: Yang Shi <shy828301@gmail.com>
	Cc: Alexander Duyck <alexander.h.duyck@linux.intel.com>
	Cc: Huang Ying <ying.huang@intel.com>
	Cc: David Hildenbrand <david@redhat.com>
	Cc: Michal Hocko <mhocko@suse.com>
	Cc: Qian Cai <cai@lca.pw>
	Cc: Mel Gorman <mgorman@techsingularity.net>
	Cc: Nicholas Piggin <npiggin@gmail.com>
	Cc: Hugh Dickins <hughd@google.com>
	Cc: Joonsoo Kim <iamjoonsoo.kim@lge.com>
Link: http://lkml.kernel.org/r/20200818184704.3625199-1-yuzhao@google.com
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit cc2828b21c764f901128ca2e7b9f056d0e72104f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/swap.c
diff --cc mm/swap.c
index 787ef21718c2,82ddefda4904..000000000000
--- a/mm/swap.c
+++ b/mm/swap.c
@@@ -367,12 -368,7 +367,16 @@@ static inline void activate_page_drain(
  {
  }
  
++<<<<<<< HEAD
 +static bool need_activate_page_drain(int cpu)
 +{
 +	return false;
 +}
 +
 +void activate_page(struct page *page)
++=======
+ static void activate_page(struct page *page)
++>>>>>>> cc2828b21c76 (mm: remove activate_page() from unuse_pte())
  {
  	pg_data_t *pgdat = page_pgdat(page);
  
diff --git a/include/linux/swap.h b/include/linux/swap.h
index c9e934b74fab..886009e4a6ad 100644
--- a/include/linux/swap.h
+++ b/include/linux/swap.h
@@ -331,7 +331,6 @@ extern void lru_note_cost_page(struct page *);
 extern void lru_cache_add(struct page *);
 extern void lru_add_page_tail(struct page *page, struct page *page_tail,
 			 struct lruvec *lruvec, struct list_head *head);
-extern void activate_page(struct page *);
 extern void mark_page_accessed(struct page *);
 extern void lru_add_drain(void);
 extern void lru_add_drain_cpu(int cpu);
* Unmerged path mm/swap.c
diff --git a/mm/swapfile.c b/mm/swapfile.c
index a81161798ee0..ee137d770a28 100644
--- a/mm/swapfile.c
+++ b/mm/swapfile.c
@@ -1946,11 +1946,6 @@ static int unuse_pte(struct vm_area_struct *vma, pmd_t *pmd,
 		lru_cache_add_inactive_or_unevictable(page, vma);
 	}
 	swap_free(entry);
-	/*
-	 * Move the page to the active list so it is not
-	 * immediately swapped out again after swapon.
-	 */
-	activate_page(page);
 out:
 	pte_unmap_unlock(pte, ptl);
 	if (page != swapcache) {
