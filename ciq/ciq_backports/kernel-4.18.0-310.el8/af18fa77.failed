KVM: nSVM: Track the physical cpu of the vmcb vmrun through the vmcb

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Cathy Avery <cavery@redhat.com>
commit af18fa775d07aeb92d4598df5364a21489aa4141
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/af18fa77.failed

This patch moves the physical cpu tracking from the vcpu
to the vmcb in svm_switch_vmcb. If either vmcb01 or vmcb02
change physical cpus from one vmrun to the next the vmcb's
previous cpu is preserved for comparison with the current
cpu and the vmcb is marked dirty if different. This prevents
the processor from using old cached data for a vmcb that may
have been updated on a prior run on a different processor.

It also moves the physical cpu check from svm_vcpu_load
to pre_svm_run as the check only needs to be done at run.

	Suggested-by: Paolo Bonzini <pbonzini@redhat.com>
	Signed-off-by: Cathy Avery <cavery@redhat.com>
Message-Id: <20210112164313.4204-2-cavery@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit af18fa775d07aeb92d4598df5364a21489aa4141)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/svm/svm.c
#	arch/x86/kvm/svm/svm.h
diff --cc arch/x86/kvm/svm/svm.c
index 05deab5ed2e8,a6b02f6241a7..000000000000
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@@ -1305,6 -1305,28 +1305,31 @@@ static void svm_vcpu_reset(struct kvm_v
  		avic_update_vapic_bar(svm, APIC_DEFAULT_PHYS_BASE);
  }
  
++<<<<<<< HEAD
++=======
+ void svm_switch_vmcb(struct vcpu_svm *svm, struct kvm_vmcb_info *target_vmcb)
+ {
+ 	svm->current_vmcb = target_vmcb;
+ 	svm->vmcb = target_vmcb->ptr;
+ 	svm->vmcb_pa = target_vmcb->pa;
+ 
+ 	/*
+ 	* Workaround: we don't yet track the ASID generation
+ 	* that was active the last time target_vmcb was run.
+ 	*/
+ 
+ 	svm->asid_generation = 0;
+ 
+ 	/*
+ 	* Track the physical CPU the target_vmcb is running on
+ 	* in order to mark the VMCB dirty if the cpu changes at
+ 	* its next vmrun.
+ 	*/
+ 
+ 	svm->current_vmcb->cpu = svm->vcpu.cpu;
+ }
+ 
++>>>>>>> af18fa775d07 (KVM: nSVM: Track the physical cpu of the vmcb vmrun through the vmcb)
  static int svm_create_vcpu(struct kvm_vcpu *vcpu)
  {
  	struct vcpu_svm *svm;
@@@ -1410,6 -1474,32 +1435,35 @@@ static void svm_vcpu_load(struct kvm_vc
  	if (static_cpu_has(X86_FEATURE_RDTSCP))
  		wrmsrl(MSR_TSC_AUX, svm->tsc_aux);
  
++<<<<<<< HEAD
++=======
+ 	svm->guest_state_loaded = true;
+ }
+ 
+ static void svm_prepare_host_switch(struct kvm_vcpu *vcpu)
+ {
+ 	struct vcpu_svm *svm = to_svm(vcpu);
+ 	unsigned int i;
+ 
+ 	if (!svm->guest_state_loaded)
+ 		return;
+ 
+ 	/*
+ 	 * Certain MSRs are restored on VMEXIT (sev-es), or vmload of host save
+ 	 * area (non-sev-es). Restore the ones that weren't.
+ 	 */
+ 	for (i = 0; i < NR_HOST_SAVE_USER_MSRS; i++)
+ 		wrmsrl(host_save_user_msrs[i], svm->host_user_msrs[i]);
+ 
+ 	svm->guest_state_loaded = false;
+ }
+ 
+ static void svm_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
+ {
+ 	struct vcpu_svm *svm = to_svm(vcpu);
+ 	struct svm_cpu_data *sd = per_cpu(svm_data, cpu);
+ 
++>>>>>>> af18fa775d07 (KVM: nSVM: Track the physical cpu of the vmcb vmrun through the vmcb)
  	if (sd->current_vmcb != svm->vmcb) {
  		sd->current_vmcb = svm->vmcb;
  		indirect_branch_prediction_barrier();
diff --cc arch/x86/kvm/svm/svm.h
index de600f536464,a37281097751..000000000000
--- a/arch/x86/kvm/svm/svm.h
+++ b/arch/x86/kvm/svm/svm.h
@@@ -84,8 -81,14 +84,17 @@@ struct kvm_svm 
  
  struct kvm_vcpu;
  
++<<<<<<< HEAD
++=======
+ struct kvm_vmcb_info {
+ 	struct vmcb *ptr;
+ 	unsigned long pa;
+ 	int cpu;
+ };
+ 
++>>>>>>> af18fa775d07 (KVM: nSVM: Track the physical cpu of the vmcb vmrun through the vmcb)
  struct svm_nested_state {
 -	struct kvm_vmcb_info vmcb02;
 +	struct vmcb *hsave;
  	u64 hsave_msr;
  	u64 vm_cr_msr;
  	u64 vmcb12_gpa;
* Unmerged path arch/x86/kvm/svm/svm.c
* Unmerged path arch/x86/kvm/svm/svm.h
