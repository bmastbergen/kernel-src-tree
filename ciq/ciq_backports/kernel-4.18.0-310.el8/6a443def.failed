KVM: SVM: Add KVM_SEV_RECEIVE_FINISH command

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Brijesh Singh <brijesh.singh@amd.com>
commit 6a443def87d2698f4fa2d7b57e7f4e5f0f61671a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/6a443def.failed

The command finalize the guest receiving process and make the SEV guest
ready for the execution.

	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: "H. Peter Anvin" <hpa@zytor.com>
	Cc: Paolo Bonzini <pbonzini@redhat.com>
	Cc: Joerg Roedel <joro@8bytes.org>
	Cc: Borislav Petkov <bp@suse.de>
	Cc: Tom Lendacky <thomas.lendacky@amd.com>
	Cc: x86@kernel.org
	Cc: kvm@vger.kernel.org
	Cc: linux-kernel@vger.kernel.org
	Reviewed-by: Steve Rutherford <srutherford@google.com>
	Signed-off-by: Brijesh Singh <brijesh.singh@amd.com>
	Signed-off-by: Ashish Kalra <ashish.kalra@amd.com>
Message-Id: <d08914dc259644de94e29b51c3b68a13286fc5a3.1618498113.git.ashish.kalra@amd.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 6a443def87d2698f4fa2d7b57e7f4e5f0f61671a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/virt/kvm/amd-memory-encryption.rst
#	arch/x86/kvm/svm/sev.c
diff --cc Documentation/virt/kvm/amd-memory-encryption.rst
index 625ce89c7706,907adfe60090..000000000000
--- a/Documentation/virt/kvm/amd-memory-encryption.rst
+++ b/Documentation/virt/kvm/amd-memory-encryption.rst
@@@ -314,6 -320,112 +314,115 @@@ Returns: 0 on success, -negative on err
                  __u32 session_len;
          };
  
++<<<<<<< HEAD
++=======
+ 12. KVM_SEV_SEND_UPDATE_DATA
+ ----------------------------
+ 
+ The KVM_SEV_SEND_UPDATE_DATA command can be used by the hypervisor to encrypt the
+ outgoing guest memory region with the encryption context creating using
+ KVM_SEV_SEND_START.
+ 
+ If hdr_len or trans_len are zero on entry, the length of the packet header and
+ transport region are written to hdr_len and trans_len respectively, and all
+ other fields are not used.
+ 
+ Parameters (in): struct kvm_sev_send_update_data
+ 
+ Returns: 0 on success, -negative on error
+ 
+ ::
+ 
+         struct kvm_sev_launch_send_update_data {
+                 __u64 hdr_uaddr;        /* userspace address containing the packet header */
+                 __u32 hdr_len;
+ 
+                 __u64 guest_uaddr;      /* the source memory region to be encrypted */
+                 __u32 guest_len;
+ 
+                 __u64 trans_uaddr;      /* the destination memory region  */
+                 __u32 trans_len;
+         };
+ 
+ 13. KVM_SEV_SEND_FINISH
+ ------------------------
+ 
+ After completion of the migration flow, the KVM_SEV_SEND_FINISH command can be
+ issued by the hypervisor to delete the encryption context.
+ 
+ Returns: 0 on success, -negative on error
+ 
+ 14. KVM_SEV_SEND_CANCEL
+ ------------------------
+ 
+ After completion of SEND_START, but before SEND_FINISH, the source VMM can issue the
+ SEND_CANCEL command to stop a migration. This is necessary so that a cancelled
+ migration can restart with a new target later.
+ 
+ Returns: 0 on success, -negative on error
+ 
+ 15. KVM_SEV_RECEIVE_START
+ ------------------------
+ 
+ The KVM_SEV_RECEIVE_START command is used for creating the memory encryption
+ context for an incoming SEV guest. To create the encryption context, the user must
+ provide a guest policy, the platform public Diffie-Hellman (PDH) key and session
+ information.
+ 
+ Parameters: struct  kvm_sev_receive_start (in/out)
+ 
+ Returns: 0 on success, -negative on error
+ 
+ ::
+ 
+         struct kvm_sev_receive_start {
+                 __u32 handle;           /* if zero then firmware creates a new handle */
+                 __u32 policy;           /* guest's policy */
+ 
+                 __u64 pdh_uaddr;        /* userspace address pointing to the PDH key */
+                 __u32 pdh_len;
+ 
+                 __u64 session_uaddr;    /* userspace address which points to the guest session information */
+                 __u32 session_len;
+         };
+ 
+ On success, the 'handle' field contains a new handle and on error, a negative value.
+ 
+ For more details, see SEV spec Section 6.12.
+ 
+ 16. KVM_SEV_RECEIVE_UPDATE_DATA
+ ----------------------------
+ 
+ The KVM_SEV_RECEIVE_UPDATE_DATA command can be used by the hypervisor to copy
+ the incoming buffers into the guest memory region with encryption context
+ created during the KVM_SEV_RECEIVE_START.
+ 
+ Parameters (in): struct kvm_sev_receive_update_data
+ 
+ Returns: 0 on success, -negative on error
+ 
+ ::
+ 
+         struct kvm_sev_launch_receive_update_data {
+                 __u64 hdr_uaddr;        /* userspace address containing the packet header */
+                 __u32 hdr_len;
+ 
+                 __u64 guest_uaddr;      /* the destination guest memory region */
+                 __u32 guest_len;
+ 
+                 __u64 trans_uaddr;      /* the incoming buffer memory region  */
+                 __u32 trans_len;
+         };
+ 
+ 17. KVM_SEV_RECEIVE_FINISH
+ ------------------------
+ 
+ After completion of the migration flow, the KVM_SEV_RECEIVE_FINISH command can be
+ issued by the hypervisor to make the guest ready for execution.
+ 
+ Returns: 0 on success, -negative on error
+ 
++>>>>>>> 6a443def87d2 (KVM: SVM: Add KVM_SEV_RECEIVE_FINISH command)
  References
  ==========
  
diff --cc arch/x86/kvm/svm/sev.c
index fbe9a30eb1a6,3f766da43708..000000000000
--- a/arch/x86/kvm/svm/sev.c
+++ b/arch/x86/kvm/svm/sev.c
@@@ -1221,6 -1237,340 +1221,343 @@@ e_free_session
  	return ret;
  }
  
++<<<<<<< HEAD
++=======
+ /* Userspace wants to query either header or trans length. */
+ static int
+ __sev_send_update_data_query_lengths(struct kvm *kvm, struct kvm_sev_cmd *argp,
+ 				     struct kvm_sev_send_update_data *params)
+ {
+ 	struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
+ 	struct sev_data_send_update_data *data;
+ 	int ret;
+ 
+ 	data = kzalloc(sizeof(*data), GFP_KERNEL_ACCOUNT);
+ 	if (!data)
+ 		return -ENOMEM;
+ 
+ 	data->handle = sev->handle;
+ 	ret = sev_issue_cmd(kvm, SEV_CMD_SEND_UPDATE_DATA, data, &argp->error);
+ 	if (ret < 0)
+ 		goto out;
+ 
+ 	params->hdr_len = data->hdr_len;
+ 	params->trans_len = data->trans_len;
+ 
+ 	if (copy_to_user((void __user *)(uintptr_t)argp->data, params,
+ 			 sizeof(struct kvm_sev_send_update_data)))
+ 		ret = -EFAULT;
+ 
+ out:
+ 	kfree(data);
+ 	return ret;
+ }
+ 
+ static int sev_send_update_data(struct kvm *kvm, struct kvm_sev_cmd *argp)
+ {
+ 	struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
+ 	struct sev_data_send_update_data *data;
+ 	struct kvm_sev_send_update_data params;
+ 	void *hdr, *trans_data;
+ 	struct page **guest_page;
+ 	unsigned long n;
+ 	int ret, offset;
+ 
+ 	if (!sev_guest(kvm))
+ 		return -ENOTTY;
+ 
+ 	if (copy_from_user(&params, (void __user *)(uintptr_t)argp->data,
+ 			sizeof(struct kvm_sev_send_update_data)))
+ 		return -EFAULT;
+ 
+ 	/* userspace wants to query either header or trans length */
+ 	if (!params.trans_len || !params.hdr_len)
+ 		return __sev_send_update_data_query_lengths(kvm, argp, &params);
+ 
+ 	if (!params.trans_uaddr || !params.guest_uaddr ||
+ 	    !params.guest_len || !params.hdr_uaddr)
+ 		return -EINVAL;
+ 
+ 	/* Check if we are crossing the page boundary */
+ 	offset = params.guest_uaddr & (PAGE_SIZE - 1);
+ 	if ((params.guest_len + offset > PAGE_SIZE))
+ 		return -EINVAL;
+ 
+ 	/* Pin guest memory */
+ 	guest_page = sev_pin_memory(kvm, params.guest_uaddr & PAGE_MASK,
+ 				    PAGE_SIZE, &n, 0);
+ 	if (!guest_page)
+ 		return -EFAULT;
+ 
+ 	/* allocate memory for header and transport buffer */
+ 	ret = -ENOMEM;
+ 	hdr = kmalloc(params.hdr_len, GFP_KERNEL_ACCOUNT);
+ 	if (!hdr)
+ 		goto e_unpin;
+ 
+ 	trans_data = kmalloc(params.trans_len, GFP_KERNEL_ACCOUNT);
+ 	if (!trans_data)
+ 		goto e_free_hdr;
+ 
+ 	data = kzalloc(sizeof(*data), GFP_KERNEL);
+ 	if (!data)
+ 		goto e_free_trans_data;
+ 
+ 	data->hdr_address = __psp_pa(hdr);
+ 	data->hdr_len = params.hdr_len;
+ 	data->trans_address = __psp_pa(trans_data);
+ 	data->trans_len = params.trans_len;
+ 
+ 	/* The SEND_UPDATE_DATA command requires C-bit to be always set. */
+ 	data->guest_address = (page_to_pfn(guest_page[0]) << PAGE_SHIFT) +
+ 				offset;
+ 	data->guest_address |= sev_me_mask;
+ 	data->guest_len = params.guest_len;
+ 	data->handle = sev->handle;
+ 
+ 	ret = sev_issue_cmd(kvm, SEV_CMD_SEND_UPDATE_DATA, data, &argp->error);
+ 
+ 	if (ret)
+ 		goto e_free;
+ 
+ 	/* copy transport buffer to user space */
+ 	if (copy_to_user((void __user *)(uintptr_t)params.trans_uaddr,
+ 			 trans_data, params.trans_len)) {
+ 		ret = -EFAULT;
+ 		goto e_free;
+ 	}
+ 
+ 	/* Copy packet header to userspace. */
+ 	ret = copy_to_user((void __user *)(uintptr_t)params.hdr_uaddr, hdr,
+ 				params.hdr_len);
+ 
+ e_free:
+ 	kfree(data);
+ e_free_trans_data:
+ 	kfree(trans_data);
+ e_free_hdr:
+ 	kfree(hdr);
+ e_unpin:
+ 	sev_unpin_memory(kvm, guest_page, n);
+ 
+ 	return ret;
+ }
+ 
+ static int sev_send_finish(struct kvm *kvm, struct kvm_sev_cmd *argp)
+ {
+ 	struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
+ 	struct sev_data_send_finish *data;
+ 	int ret;
+ 
+ 	if (!sev_guest(kvm))
+ 		return -ENOTTY;
+ 
+ 	data = kzalloc(sizeof(*data), GFP_KERNEL);
+ 	if (!data)
+ 		return -ENOMEM;
+ 
+ 	data->handle = sev->handle;
+ 	ret = sev_issue_cmd(kvm, SEV_CMD_SEND_FINISH, data, &argp->error);
+ 
+ 	kfree(data);
+ 	return ret;
+ }
+ 
+ static int sev_send_cancel(struct kvm *kvm, struct kvm_sev_cmd *argp)
+ {
+ 	struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
+ 	struct sev_data_send_cancel *data;
+ 	int ret;
+ 
+ 	if (!sev_guest(kvm))
+ 		return -ENOTTY;
+ 
+ 	data = kzalloc(sizeof(*data), GFP_KERNEL);
+ 	if (!data)
+ 		return -ENOMEM;
+ 
+ 	data->handle = sev->handle;
+ 	ret = sev_issue_cmd(kvm, SEV_CMD_SEND_CANCEL, data, &argp->error);
+ 
+ 	kfree(data);
+ 	return ret;
+ }
+ 
+ static int sev_receive_start(struct kvm *kvm, struct kvm_sev_cmd *argp)
+ {
+ 	struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
+ 	struct sev_data_receive_start *start;
+ 	struct kvm_sev_receive_start params;
+ 	int *error = &argp->error;
+ 	void *session_data;
+ 	void *pdh_data;
+ 	int ret;
+ 
+ 	if (!sev_guest(kvm))
+ 		return -ENOTTY;
+ 
+ 	/* Get parameter from the userspace */
+ 	if (copy_from_user(&params, (void __user *)(uintptr_t)argp->data,
+ 			sizeof(struct kvm_sev_receive_start)))
+ 		return -EFAULT;
+ 
+ 	/* some sanity checks */
+ 	if (!params.pdh_uaddr || !params.pdh_len ||
+ 	    !params.session_uaddr || !params.session_len)
+ 		return -EINVAL;
+ 
+ 	pdh_data = psp_copy_user_blob(params.pdh_uaddr, params.pdh_len);
+ 	if (IS_ERR(pdh_data))
+ 		return PTR_ERR(pdh_data);
+ 
+ 	session_data = psp_copy_user_blob(params.session_uaddr,
+ 			params.session_len);
+ 	if (IS_ERR(session_data)) {
+ 		ret = PTR_ERR(session_data);
+ 		goto e_free_pdh;
+ 	}
+ 
+ 	ret = -ENOMEM;
+ 	start = kzalloc(sizeof(*start), GFP_KERNEL);
+ 	if (!start)
+ 		goto e_free_session;
+ 
+ 	start->handle = params.handle;
+ 	start->policy = params.policy;
+ 	start->pdh_cert_address = __psp_pa(pdh_data);
+ 	start->pdh_cert_len = params.pdh_len;
+ 	start->session_address = __psp_pa(session_data);
+ 	start->session_len = params.session_len;
+ 
+ 	/* create memory encryption context */
+ 	ret = __sev_issue_cmd(argp->sev_fd, SEV_CMD_RECEIVE_START, start,
+ 				error);
+ 	if (ret)
+ 		goto e_free;
+ 
+ 	/* Bind ASID to this guest */
+ 	ret = sev_bind_asid(kvm, start->handle, error);
+ 	if (ret)
+ 		goto e_free;
+ 
+ 	params.handle = start->handle;
+ 	if (copy_to_user((void __user *)(uintptr_t)argp->data,
+ 			 &params, sizeof(struct kvm_sev_receive_start))) {
+ 		ret = -EFAULT;
+ 		sev_unbind_asid(kvm, start->handle);
+ 		goto e_free;
+ 	}
+ 
+ 	sev->handle = start->handle;
+ 	sev->fd = argp->sev_fd;
+ 
+ e_free:
+ 	kfree(start);
+ e_free_session:
+ 	kfree(session_data);
+ e_free_pdh:
+ 	kfree(pdh_data);
+ 
+ 	return ret;
+ }
+ 
+ static int sev_receive_update_data(struct kvm *kvm, struct kvm_sev_cmd *argp)
+ {
+ 	struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
+ 	struct kvm_sev_receive_update_data params;
+ 	struct sev_data_receive_update_data *data;
+ 	void *hdr = NULL, *trans = NULL;
+ 	struct page **guest_page;
+ 	unsigned long n;
+ 	int ret, offset;
+ 
+ 	if (!sev_guest(kvm))
+ 		return -EINVAL;
+ 
+ 	if (copy_from_user(&params, (void __user *)(uintptr_t)argp->data,
+ 			sizeof(struct kvm_sev_receive_update_data)))
+ 		return -EFAULT;
+ 
+ 	if (!params.hdr_uaddr || !params.hdr_len ||
+ 	    !params.guest_uaddr || !params.guest_len ||
+ 	    !params.trans_uaddr || !params.trans_len)
+ 		return -EINVAL;
+ 
+ 	/* Check if we are crossing the page boundary */
+ 	offset = params.guest_uaddr & (PAGE_SIZE - 1);
+ 	if ((params.guest_len + offset > PAGE_SIZE))
+ 		return -EINVAL;
+ 
+ 	hdr = psp_copy_user_blob(params.hdr_uaddr, params.hdr_len);
+ 	if (IS_ERR(hdr))
+ 		return PTR_ERR(hdr);
+ 
+ 	trans = psp_copy_user_blob(params.trans_uaddr, params.trans_len);
+ 	if (IS_ERR(trans)) {
+ 		ret = PTR_ERR(trans);
+ 		goto e_free_hdr;
+ 	}
+ 
+ 	ret = -ENOMEM;
+ 	data = kzalloc(sizeof(*data), GFP_KERNEL);
+ 	if (!data)
+ 		goto e_free_trans;
+ 
+ 	data->hdr_address = __psp_pa(hdr);
+ 	data->hdr_len = params.hdr_len;
+ 	data->trans_address = __psp_pa(trans);
+ 	data->trans_len = params.trans_len;
+ 
+ 	/* Pin guest memory */
+ 	ret = -EFAULT;
+ 	guest_page = sev_pin_memory(kvm, params.guest_uaddr & PAGE_MASK,
+ 				    PAGE_SIZE, &n, 0);
+ 	if (!guest_page)
+ 		goto e_free;
+ 
+ 	/* The RECEIVE_UPDATE_DATA command requires C-bit to be always set. */
+ 	data->guest_address = (page_to_pfn(guest_page[0]) << PAGE_SHIFT) +
+ 				offset;
+ 	data->guest_address |= sev_me_mask;
+ 	data->guest_len = params.guest_len;
+ 	data->handle = sev->handle;
+ 
+ 	ret = sev_issue_cmd(kvm, SEV_CMD_RECEIVE_UPDATE_DATA, data,
+ 				&argp->error);
+ 
+ 	sev_unpin_memory(kvm, guest_page, n);
+ 
+ e_free:
+ 	kfree(data);
+ e_free_trans:
+ 	kfree(trans);
+ e_free_hdr:
+ 	kfree(hdr);
+ 
+ 	return ret;
+ }
+ 
+ static int sev_receive_finish(struct kvm *kvm, struct kvm_sev_cmd *argp)
+ {
+ 	struct kvm_sev_info *sev = &to_kvm_svm(kvm)->sev_info;
+ 	struct sev_data_receive_finish *data;
+ 	int ret;
+ 
+ 	if (!sev_guest(kvm))
+ 		return -ENOTTY;
+ 
+ 	data = kzalloc(sizeof(*data), GFP_KERNEL);
+ 	if (!data)
+ 		return -ENOMEM;
+ 
+ 	data->handle = sev->handle;
+ 	ret = sev_issue_cmd(kvm, SEV_CMD_RECEIVE_FINISH, data, &argp->error);
+ 
+ 	kfree(data);
+ 	return ret;
+ }
+ 
++>>>>>>> 6a443def87d2 (KVM: SVM: Add KVM_SEV_RECEIVE_FINISH command)
  int svm_mem_enc_op(struct kvm *kvm, void __user *argp)
  {
  	struct kvm_sev_cmd sev_cmd;
@@@ -1280,6 -1636,24 +1617,27 @@@
  	case KVM_SEV_SEND_START:
  		r = sev_send_start(kvm, &sev_cmd);
  		break;
++<<<<<<< HEAD
++=======
+ 	case KVM_SEV_SEND_UPDATE_DATA:
+ 		r = sev_send_update_data(kvm, &sev_cmd);
+ 		break;
+ 	case KVM_SEV_SEND_FINISH:
+ 		r = sev_send_finish(kvm, &sev_cmd);
+ 		break;
+ 	case KVM_SEV_SEND_CANCEL:
+ 		r = sev_send_cancel(kvm, &sev_cmd);
+ 		break;
+ 	case KVM_SEV_RECEIVE_START:
+ 		r = sev_receive_start(kvm, &sev_cmd);
+ 		break;
+ 	case KVM_SEV_RECEIVE_UPDATE_DATA:
+ 		r = sev_receive_update_data(kvm, &sev_cmd);
+ 		break;
+ 	case KVM_SEV_RECEIVE_FINISH:
+ 		r = sev_receive_finish(kvm, &sev_cmd);
+ 		break;
++>>>>>>> 6a443def87d2 (KVM: SVM: Add KVM_SEV_RECEIVE_FINISH command)
  	default:
  		r = -EINVAL;
  		goto out;
* Unmerged path Documentation/virt/kvm/amd-memory-encryption.rst
* Unmerged path arch/x86/kvm/svm/sev.c
