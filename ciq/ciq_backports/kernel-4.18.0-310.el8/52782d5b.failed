KVM/SVM: Remove leftover __svm_vcpu_run prototype from svm.c

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Uros Bizjak <ubizjak@gmail.com>
commit 52782d5b63725a6c4bf642557c83507430064110
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/52782d5b.failed

Commit 16809ecdc1e8a moved __svm_vcpu_run the prototype to svm.h,
but forgot to remove the original from svm.c.

Fixes: 16809ecdc1e8a ("KVM: SVM: Provide an updated VMRUN invocation for SEV-ES guests")
	Cc: Tom Lendacky <thomas.lendacky@amd.com>
	Cc: Paolo Bonzini <pbonzini@redhat.com>
	Signed-off-by: Uros Bizjak <ubizjak@gmail.com>
Message-Id: <20201220200339.65115-1-ubizjak@gmail.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 52782d5b63725a6c4bf642557c83507430064110)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/svm/svm.c
diff --cc arch/x86/kvm/svm/svm.c
index 189395610780,6824d611dc5d..000000000000
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@@ -3665,9 -3677,65 +3665,71 @@@ static fastpath_t svm_exit_handlers_fas
  	return EXIT_FASTPATH_NONE;
  }
  
++<<<<<<< HEAD
 +void __svm_vcpu_run(unsigned long vmcb_pa, unsigned long *regs);
 +
 +static fastpath_t svm_vcpu_run(struct kvm_vcpu *vcpu)
++=======
+ static noinstr void svm_vcpu_enter_exit(struct kvm_vcpu *vcpu,
+ 					struct vcpu_svm *svm)
+ {
+ 	/*
+ 	 * VMENTER enables interrupts (host state), but the kernel state is
+ 	 * interrupts disabled when this is invoked. Also tell RCU about
+ 	 * it. This is the same logic as for exit_to_user_mode().
+ 	 *
+ 	 * This ensures that e.g. latency analysis on the host observes
+ 	 * guest mode as interrupt enabled.
+ 	 *
+ 	 * guest_enter_irqoff() informs context tracking about the
+ 	 * transition to guest mode and if enabled adjusts RCU state
+ 	 * accordingly.
+ 	 */
+ 	instrumentation_begin();
+ 	trace_hardirqs_on_prepare();
+ 	lockdep_hardirqs_on_prepare(CALLER_ADDR0);
+ 	instrumentation_end();
+ 
+ 	guest_enter_irqoff();
+ 	lockdep_hardirqs_on(CALLER_ADDR0);
+ 
+ 	if (sev_es_guest(svm->vcpu.kvm)) {
+ 		__svm_sev_es_vcpu_run(svm->vmcb_pa);
+ 	} else {
+ 		__svm_vcpu_run(svm->vmcb_pa, (unsigned long *)&svm->vcpu.arch.regs);
+ 
+ #ifdef CONFIG_X86_64
+ 		native_wrmsrl(MSR_GS_BASE, svm->host.gs_base);
+ #else
+ 		loadsegment(fs, svm->host.fs);
+ #ifndef CONFIG_X86_32_LAZY_GS
+ 		loadsegment(gs, svm->host.gs);
+ #endif
+ #endif
+ 	}
+ 
+ 	/*
+ 	 * VMEXIT disables interrupts (host state), but tracing and lockdep
+ 	 * have them in state 'on' as recorded before entering guest mode.
+ 	 * Same as enter_from_user_mode().
+ 	 *
+ 	 * guest_exit_irqoff() restores host context and reinstates RCU if
+ 	 * enabled and required.
+ 	 *
+ 	 * This needs to be done before the below as native_read_msr()
+ 	 * contains a tracepoint and x86_spec_ctrl_restore_host() calls
+ 	 * into world and some more.
+ 	 */
+ 	lockdep_hardirqs_off(CALLER_ADDR0);
+ 	guest_exit_irqoff();
+ 
+ 	instrumentation_begin();
+ 	trace_hardirqs_off_finish();
+ 	instrumentation_end();
+ }
+ 
+ static __no_kcsan fastpath_t svm_vcpu_run(struct kvm_vcpu *vcpu)
++>>>>>>> 52782d5b6372 (KVM/SVM: Remove leftover __svm_vcpu_run prototype from svm.c)
  {
  	struct vcpu_svm *svm = to_svm(vcpu);
  
* Unmerged path arch/x86/kvm/svm/svm.c
