nvme: query namespace identifiers before adding the namespace

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Christoph Hellwig <hch@lst.de>
commit 8b7c0ff2d46dad4974e84f2363d7e0ddefaf0677
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/8b7c0ff2.failed

Check the namespace identifier list first thing when scanning namespaces.
This keeps the code to query the CSI common between the alloc and validate
path, and helps to structure the code better for multiple command set
support.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Keith Busch <kbusch@kernel.org>
	Reviewed-by: Damien Le Moal <damien.lemoal@wdc.com>
(cherry picked from commit 8b7c0ff2d46dad4974e84f2363d7e0ddefaf0677)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/core.c
diff --cc drivers/nvme/host/core.c
index c9e0d12e2c04,ad18c32b36e7..000000000000
--- a/drivers/nvme/host/core.c
+++ b/drivers/nvme/host/core.c
@@@ -2076,77 -2110,56 +2072,94 @@@ static void nvme_set_chunk_sectors(stru
  	blk_queue_chunk_sectors(ns->queue, iob);
  }
  
 -static int nvme_update_ns_info(struct nvme_ns *ns, struct nvme_id_ns *id)
 +static int __nvme_revalidate_disk(struct gendisk *disk, struct nvme_id_ns *id)
  {
++<<<<<<< HEAD
 +	struct nvme_ns *ns = disk->private_data;
 +	struct nvme_ctrl *ctrl = ns->ctrl;
 +
 +	/*
 +	 * If identify namespace failed, use default 512 byte block size so
 +	 * block layer can use before failing read/write for 0 capacity.
 +	 */
 +	ns->lba_shift = id->lbaf[id->flbas & NVME_NS_FLBAS_LBA_MASK].ds;
 +	if (ns->lba_shift == 0)
 +		ns->lba_shift = 9;
 +
 +	switch (ns->head->ids.csi) {
 +	case NVME_CSI_NVM:
 +		break;
 +	default:
 +		dev_warn(ctrl->device, "unknown csi:%d ns:%d\n",
 +			ns->head->ids.csi, ns->head->ns_id);
 +		return -ENODEV;
 +	}
 +
 +	ns->features = 0;
 +	ns->ms = le16_to_cpu(id->lbaf[id->flbas & NVME_NS_FLBAS_LBA_MASK].ms);
 +	/* the PI implementation requires metadata equal t10 pi tuple size */
 +	if (ns->ms == sizeof(struct t10_pi_tuple))
 +		ns->pi_type = id->dps & NVME_NS_DPS_PI_MASK;
 +	else
 +		ns->pi_type = 0;
 +
 +	if (ns->ms) {
 +		/*
 +		 * For PCIe only the separate metadata pointer is supported,
 +		 * as the block layer supplies metadata in a separate bio_vec
 +		 * chain. For Fabrics, only metadata as part of extended data
 +		 * LBA is supported on the wire per the Fabrics specification,
 +		 * but the HBA/HCA will do the remapping from the separate
 +		 * metadata buffers for us.
 +		 */
 +		if (id->flbas & NVME_NS_FLBAS_META_EXT) {
 +			ns->features |= NVME_NS_EXT_LBAS;
 +			if ((ctrl->ops->flags & NVME_F_FABRICS) &&
 +			    (ctrl->ops->flags & NVME_F_METADATA_SUPPORTED) &&
 +			    ctrl->max_integrity_segments)
 +				ns->features |= NVME_NS_METADATA_SUPPORTED;
 +		} else {
 +			if (WARN_ON_ONCE(ctrl->ops->flags & NVME_F_FABRICS))
 +				return -EINVAL;
 +			if (ctrl->ops->flags & NVME_F_METADATA_SUPPORTED)
 +				ns->features |= NVME_NS_METADATA_SUPPORTED;
 +		}
++=======
+ 	unsigned lbaf = id->flbas & NVME_NS_FLBAS_LBA_MASK;
+ 	int ret;
+ 
+ 	blk_mq_freeze_queue(ns->disk->queue);
+ 	ns->lba_shift = id->lbaf[lbaf].ds;
+ 	nvme_set_queue_limits(ns->ctrl, ns->queue);
+ 
+ 	if (ns->head->ids.csi == NVME_CSI_ZNS) {
+ 		ret = nvme_update_zone_info(ns, lbaf);
+ 		if (ret)
+ 			goto out_unfreeze;
++>>>>>>> 8b7c0ff2d46d (nvme: query namespace identifiers before adding the namespace)
  	}
  
 -	ret = nvme_configure_metadata(ns, id);
 -	if (ret)
 -		goto out_unfreeze;
  	nvme_set_chunk_sectors(ns, id);
 -	nvme_update_disk_info(ns->disk, ns, id);
 -	blk_mq_unfreeze_queue(ns->disk->queue);
 -
 -	if (blk_queue_is_zoned(ns->queue)) {
 -		ret = nvme_revalidate_zones(ns);
 -		if (ret)
 -			return ret;
 -	}
 -
 +	nvme_update_disk_info(disk, ns, id);
  #ifdef CONFIG_NVME_MULTIPATH
  	if (ns->head->disk) {
 -		blk_mq_freeze_queue(ns->head->disk->queue);
  		nvme_update_disk_info(ns->head->disk, ns, id);
 -		blk_stack_limits(&ns->head->disk->queue->limits,
 -				 &ns->queue->limits, 0);
 -		blk_queue_update_readahead(ns->head->disk->queue);
 -		nvme_update_bdev_size(ns->head->disk);
 -		blk_mq_unfreeze_queue(ns->head->disk->queue);
 +		blk_queue_stack_limits(ns->head->disk->queue, ns->queue);
 +		nvme_mpath_update_disk_size(ns->head->disk);
  	}
  #endif
  	return 0;
 -
 -out_unfreeze:
 -	blk_mq_unfreeze_queue(ns->disk->queue);
 -	return ret;
  }
  
++<<<<<<< HEAD
 +static int nvme_revalidate_disk(struct gendisk *disk)
++=======
+ static int nvme_validate_ns(struct nvme_ns *ns, struct nvme_ns_ids *ids)
++>>>>>>> 8b7c0ff2d46d (nvme: query namespace identifiers before adding the namespace)
  {
 +	struct nvme_ns *ns = disk->private_data;
  	struct nvme_ctrl *ctrl = ns->ctrl;
  	struct nvme_id_ns *id;
- 	struct nvme_ns_ids ids;
  	int ret = 0;
  
  	if (test_bit(NVME_NS_DEAD, &ns->flags)) {
@@@ -3883,9 -3839,10 +3883,10 @@@ struct nvme_ns *nvme_find_get_ns(struc
  	up_read(&ctrl->namespaces_rwsem);
  	return ret;
  }
 -EXPORT_SYMBOL_NS_GPL(nvme_find_get_ns, NVME_TARGET_PASSTHRU);
 +EXPORT_SYMBOL_GPL(nvme_find_get_ns);
  
- static void nvme_alloc_ns(struct nvme_ctrl *ctrl, unsigned nsid)
+ static void nvme_alloc_ns(struct nvme_ctrl *ctrl, unsigned nsid,
+ 		struct nvme_ns_ids *ids)
  {
  	struct nvme_ns *ns;
  	struct gendisk *disk;
@@@ -3914,14 -3870,9 +3915,14 @@@
  
  	ns->queue->queuedata = ns;
  	ns->ctrl = ctrl;
 +
  	kref_init(&ns->kref);
 +	ns->lba_shift = 9; /* set to a default value for 512 until disk is validated */
 +
 +	blk_queue_logical_block_size(ns->queue, 1 << ns->lba_shift);
 +	nvme_set_queue_limits(ctrl, ns->queue);
  
- 	ret = nvme_init_ns_head(ns, nsid, id);
+ 	ret = nvme_init_ns_head(ns, nsid, ids, id->nmic & NVME_NS_NMIC_SHARED);
  	if (ret)
  		goto out_free_queue;
  	nvme_set_disk_name(disk_name, ns, ctrl, &flags);
@@@ -4024,15 -3975,41 +4025,48 @@@ static void nvme_ns_remove_by_nsid(stru
  
  static void nvme_validate_or_alloc_ns(struct nvme_ctrl *ctrl, unsigned nsid)
  {
+ 	struct nvme_ns_ids ids = { };
  	struct nvme_ns *ns;
 -	int ret;
  
+ 	if (nvme_identify_ns_descs(ctrl, nsid, &ids))
+ 		return;
+ 
  	ns = nvme_find_get_ns(ctrl, nsid);
  	if (ns) {
++<<<<<<< HEAD
 +		if (revalidate_disk(ns->disk))
 +			nvme_ns_remove(ns);
 +		nvme_put_ns(ns);
 +	} else
 +		nvme_alloc_ns(ctrl, nsid);
++=======
+ 		ret = nvme_validate_ns(ns, &ids);
+ 		revalidate_disk_size(ns->disk, ret == 0);
+ 		if (ret)
+ 			nvme_ns_remove(ns);
+ 		nvme_put_ns(ns);
+ 		return;
+ 	}
+ 
+ 	switch (ids.csi) {
+ 	case NVME_CSI_NVM:
+ 		nvme_alloc_ns(ctrl, nsid, &ids);
+ 		break;
+ 	case NVME_CSI_ZNS:
+ 		if (!IS_ENABLED(CONFIG_BLK_DEV_ZONED)) {
+ 			dev_warn(ctrl->device,
+ 				"nsid %u not supported without CONFIG_BLK_DEV_ZONED\n",
+ 				nsid);
+ 			break;
+ 		}
+ 		nvme_alloc_ns(ctrl, nsid, &ids);
+ 		break;
+ 	default:
+ 		dev_warn(ctrl->device, "unknown csi %u for nsid %u\n",
+ 			ids.csi, nsid);
+ 		break;
+ 	}
++>>>>>>> 8b7c0ff2d46d (nvme: query namespace identifiers before adding the namespace)
  }
  
  static void nvme_remove_invalid_namespaces(struct nvme_ctrl *ctrl,
* Unmerged path drivers/nvme/host/core.c
