nvme: cleanup zone information initialization

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Damien Le Moal <damien.lemoal@wdc.com>
commit 73d90386b559d6f4c3c5db5e6bb1b68aae8fd3e7
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/73d90386.failed

For a zoned namespace, in nvme_update_ns_info(), call
nvme_update_zone_info() after executing nvme_update_disk_info() so that
the namespace queue logical and physical block size limits are set.
This allows setting the namespace queue max_zone_append_sectors limit
in nvme_update_zone_info() instead of nvme_revalidate_zones(),
simplifying this function. Also use blk_queue_set_zoned() to set the
namespace zoned model.

	Signed-off-by: Damien Le Moal <damien.lemoal@wdc.com>
	Reviewed-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Chaitanya Kulkarni <chaitanya.kulkarni@wdc.com>
	Reviewed-by: Johannes Thumshirn <johannes.thumshirn@edc.com>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 73d90386b559d6f4c3c5db5e6bb1b68aae8fd3e7)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/core.c
#	drivers/nvme/host/zns.c
diff --cc drivers/nvme/host/core.c
index 194b5a8804e3,81a1c7f6223f..000000000000
--- a/drivers/nvme/host/core.c
+++ b/drivers/nvme/host/core.c
@@@ -2177,66 -2167,43 +2177,89 @@@ static void nvme_set_chunk_sectors(stru
  	blk_queue_chunk_sectors(ns->queue, iob);
  }
  
 -static int nvme_update_ns_info(struct nvme_ns *ns, struct nvme_id_ns *id)
 +static int __nvme_revalidate_disk(struct gendisk *disk, struct nvme_id_ns *id)
  {
 -	unsigned lbaf = id->flbas & NVME_NS_FLBAS_LBA_MASK;
 -	int ret;
 +	struct nvme_ns *ns = disk->private_data;
 +	struct nvme_ctrl *ctrl = ns->ctrl;
 +
 +	/*
 +	 * If identify namespace failed, use default 512 byte block size so
 +	 * block layer can use before failing read/write for 0 capacity.
 +	 */
 +	ns->lba_shift = id->lbaf[id->flbas & NVME_NS_FLBAS_LBA_MASK].ds;
 +	if (ns->lba_shift == 0)
 +		ns->lba_shift = 9;
 +
++<<<<<<< HEAD
 +	switch (ns->head->ids.csi) {
 +	case NVME_CSI_NVM:
 +		break;
 +	default:
 +		dev_warn(ctrl->device, "unknown csi:%d ns:%d\n",
 +			ns->head->ids.csi, ns->head->ns_id);
 +		return -ENODEV;
 +	}
  
 -	blk_mq_freeze_queue(ns->disk->queue);
 -	ns->lba_shift = id->lbaf[lbaf].ds;
 -	nvme_set_queue_limits(ns->ctrl, ns->queue);
 +	ns->features = 0;
 +	ns->ms = le16_to_cpu(id->lbaf[id->flbas & NVME_NS_FLBAS_LBA_MASK].ms);
 +	/* the PI implementation requires metadata equal t10 pi tuple size */
 +	if (ns->ms == sizeof(struct t10_pi_tuple))
 +		ns->pi_type = id->dps & NVME_NS_DPS_PI_MASK;
 +	else
 +		ns->pi_type = 0;
  
 +	if (ns->ms) {
 +		/*
 +		 * For PCIe only the separate metadata pointer is supported,
 +		 * as the block layer supplies metadata in a separate bio_vec
 +		 * chain. For Fabrics, only metadata as part of extended data
 +		 * LBA is supported on the wire per the Fabrics specification,
 +		 * but the HBA/HCA will do the remapping from the separate
 +		 * metadata buffers for us.
 +		 */
 +		if (id->flbas & NVME_NS_FLBAS_META_EXT) {
 +			ns->features |= NVME_NS_EXT_LBAS;
 +			if ((ctrl->ops->flags & NVME_F_FABRICS) &&
 +			    (ctrl->ops->flags & NVME_F_METADATA_SUPPORTED) &&
 +			    ctrl->max_integrity_segments)
 +				ns->features |= NVME_NS_METADATA_SUPPORTED;
 +		} else {
 +			if (WARN_ON_ONCE(ctrl->ops->flags & NVME_F_FABRICS))
 +				return -EINVAL;
 +			if (ctrl->ops->flags & NVME_F_METADATA_SUPPORTED)
 +				ns->features |= NVME_NS_METADATA_SUPPORTED;
 +		}
 +	}
 +
 +	nvme_set_chunk_sectors(ns, id);
 +	nvme_update_disk_info(disk, ns, id);
++=======
+ 	ret = nvme_configure_metadata(ns, id);
+ 	if (ret)
+ 		goto out_unfreeze;
+ 	nvme_set_chunk_sectors(ns, id);
+ 	nvme_update_disk_info(ns->disk, ns, id);
+ 
+ 	if (ns->head->ids.csi == NVME_CSI_ZNS) {
+ 		ret = nvme_update_zone_info(ns, lbaf);
+ 		if (ret)
+ 			goto out_unfreeze;
+ 	}
+ 
+ 	blk_mq_unfreeze_queue(ns->disk->queue);
+ 
+ 	if (blk_queue_is_zoned(ns->queue)) {
+ 		ret = nvme_revalidate_zones(ns);
+ 		if (ret && !nvme_first_scan(ns->disk))
+ 			return ret;
+ 	}
+ 
++>>>>>>> 73d90386b559 (nvme: cleanup zone information initialization)
  #ifdef CONFIG_NVME_MULTIPATH
  	if (ns->head->disk) {
 -		blk_mq_freeze_queue(ns->head->disk->queue);
  		nvme_update_disk_info(ns->head->disk, ns, id);
 -		blk_stack_limits(&ns->head->disk->queue->limits,
 -				 &ns->queue->limits, 0);
 -		blk_queue_update_readahead(ns->head->disk->queue);
 -		blk_mq_unfreeze_queue(ns->head->disk->queue);
 +		blk_queue_stack_limits(ns->head->disk->queue, ns->queue);
 +		nvme_mpath_update_disk_size(ns->head->disk);
  	}
  #endif
  	return 0;
* Unmerged path drivers/nvme/host/zns.c
* Unmerged path drivers/nvme/host/core.c
* Unmerged path drivers/nvme/host/zns.c
