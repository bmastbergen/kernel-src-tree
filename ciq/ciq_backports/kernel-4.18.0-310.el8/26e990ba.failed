RDMA: Check attr_mask during modify_qp

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Jason Gunthorpe <jgg@nvidia.com>
commit 26e990badde40b2fb824bfa3cb9d4288a79584bc
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/26e990ba.failed

Each driver should check that it can support the provided attr_mask during
modify_qp. IB_USER_VERBS_EX_CMD_MODIFY_QP was being used to block
modify_qp_ex because the driver didn't check RATE_LIMIT.

Link: https://lore.kernel.org/r/6-v1-caa70ba3d1ab+1436e-ucmd_mask_jgg@nvidia.com
	Signed-off-by: Jason Gunthorpe <jgg@nvidia.com>
(cherry picked from commit 26e990badde40b2fb824bfa3cb9d4288a79584bc)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/infiniband/core/device.c
#	drivers/infiniband/hw/hns/hns_roce_hw_v2.c
#	drivers/infiniband/hw/mlx5/main.c
#	drivers/infiniband/hw/mlx5/qp.c
diff --cc drivers/infiniband/core/device.c
index 30a7bf1c3b41,6d2603571771..000000000000
--- a/drivers/infiniband/core/device.c
+++ b/drivers/infiniband/core/device.c
@@@ -601,9 -601,47 +601,53 @@@ struct ib_device *_ib_alloc_device(size
  	init_completion(&device->unreg_completion);
  	INIT_WORK(&device->unregistration_work, ib_unregister_work);
  
++<<<<<<< HEAD
 +	spin_lock_init(&device->cq_pools_lock);
 +	for (i = 0; i < ARRAY_SIZE(device->cq_pools); i++)
 +		INIT_LIST_HEAD(&device->cq_pools[i]);
++=======
+ 	device->uverbs_cmd_mask =
+ 		BIT_ULL(IB_USER_VERBS_CMD_ALLOC_MW) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_ALLOC_PD) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_ATTACH_MCAST) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_CLOSE_XRCD) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_CREATE_COMP_CHANNEL) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_CREATE_CQ) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_CREATE_QP) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_CREATE_SRQ) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_CREATE_XSRQ) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_DEALLOC_MW) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_DEALLOC_PD) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_DEREG_MR) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_DESTROY_CQ) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_DESTROY_QP) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_DESTROY_SRQ) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_DETACH_MCAST) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_GET_CONTEXT) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_MODIFY_QP) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_MODIFY_SRQ) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_OPEN_QP) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_OPEN_XRCD) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_QUERY_DEVICE) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_QUERY_PORT) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_QUERY_QP) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_QUERY_SRQ) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_REG_MR) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_REREG_MR) |
+ 		BIT_ULL(IB_USER_VERBS_CMD_RESIZE_CQ);
+ 
+ 	device->uverbs_ex_cmd_mask =
+ 		BIT_ULL(IB_USER_VERBS_EX_CMD_CREATE_FLOW) |
+ 		BIT_ULL(IB_USER_VERBS_EX_CMD_CREATE_RWQ_IND_TBL) |
+ 		BIT_ULL(IB_USER_VERBS_EX_CMD_CREATE_WQ) |
+ 		BIT_ULL(IB_USER_VERBS_EX_CMD_DESTROY_FLOW) |
+ 		BIT_ULL(IB_USER_VERBS_EX_CMD_DESTROY_RWQ_IND_TBL) |
+ 		BIT_ULL(IB_USER_VERBS_EX_CMD_DESTROY_WQ) |
+ 		BIT_ULL(IB_USER_VERBS_EX_CMD_MODIFY_CQ) |
+ 		BIT_ULL(IB_USER_VERBS_EX_CMD_MODIFY_QP) |
+ 		BIT_ULL(IB_USER_VERBS_EX_CMD_MODIFY_WQ) |
+ 		BIT_ULL(IB_USER_VERBS_EX_CMD_QUERY_DEVICE);
++>>>>>>> 26e990badde4 (RDMA: Check attr_mask during modify_qp)
  
  	return device;
  }
diff --cc drivers/infiniband/hw/hns/hns_roce_hw_v2.c
index b61a836a2647,a0b679254a8e..000000000000
--- a/drivers/infiniband/hw/hns/hns_roce_hw_v2.c
+++ b/drivers/infiniband/hw/hns/hns_roce_hw_v2.c
@@@ -3670,6 -4740,93 +3670,96 @@@ static int hns_roce_v2_modify_qp(struc
  		hr_qp->port = attr->port_num - 1;
  		hr_qp->phy_port = hr_dev->iboe.phy_port[hr_qp->port];
  	}
++<<<<<<< HEAD
++=======
+ }
+ 
+ static int hns_roce_v2_modify_qp(struct ib_qp *ibqp,
+ 				 const struct ib_qp_attr *attr,
+ 				 int attr_mask, enum ib_qp_state cur_state,
+ 				 enum ib_qp_state new_state)
+ {
+ 	struct hns_roce_dev *hr_dev = to_hr_dev(ibqp->device);
+ 	struct hns_roce_qp *hr_qp = to_hr_qp(ibqp);
+ 	struct hns_roce_v2_qp_context ctx[2];
+ 	struct hns_roce_v2_qp_context *context = ctx;
+ 	struct hns_roce_v2_qp_context *qpc_mask = ctx + 1;
+ 	struct ib_device *ibdev = &hr_dev->ib_dev;
+ 	unsigned long sq_flag = 0;
+ 	unsigned long rq_flag = 0;
+ 	int ret;
+ 
+ 	if (attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+ 		return -EOPNOTSUPP;
+ 
+ 	/*
+ 	 * In v2 engine, software pass context and context mask to hardware
+ 	 * when modifying qp. If software need modify some fields in context,
+ 	 * we should set all bits of the relevant fields in context mask to
+ 	 * 0 at the same time, else set them to 0x1.
+ 	 */
+ 	memset(context, 0, hr_dev->caps.qpc_sz);
+ 	memset(qpc_mask, 0xff, hr_dev->caps.qpc_sz);
+ 
+ 	ret = hns_roce_v2_set_abs_fields(ibqp, attr, attr_mask, cur_state,
+ 					 new_state, context, qpc_mask);
+ 	if (ret)
+ 		goto out;
+ 
+ 	/* When QP state is err, SQ and RQ WQE should be flushed */
+ 	if (new_state == IB_QPS_ERR) {
+ 		spin_lock_irqsave(&hr_qp->sq.lock, sq_flag);
+ 		hr_qp->state = IB_QPS_ERR;
+ 		roce_set_field(context->byte_160_sq_ci_pi,
+ 			       V2_QPC_BYTE_160_SQ_PRODUCER_IDX_M,
+ 			       V2_QPC_BYTE_160_SQ_PRODUCER_IDX_S,
+ 			       hr_qp->sq.head);
+ 		roce_set_field(qpc_mask->byte_160_sq_ci_pi,
+ 			       V2_QPC_BYTE_160_SQ_PRODUCER_IDX_M,
+ 			       V2_QPC_BYTE_160_SQ_PRODUCER_IDX_S, 0);
+ 		spin_unlock_irqrestore(&hr_qp->sq.lock, sq_flag);
+ 
+ 		if (!ibqp->srq) {
+ 			spin_lock_irqsave(&hr_qp->rq.lock, rq_flag);
+ 			roce_set_field(context->byte_84_rq_ci_pi,
+ 			       V2_QPC_BYTE_84_RQ_PRODUCER_IDX_M,
+ 			       V2_QPC_BYTE_84_RQ_PRODUCER_IDX_S,
+ 			       hr_qp->rq.head);
+ 			roce_set_field(qpc_mask->byte_84_rq_ci_pi,
+ 			       V2_QPC_BYTE_84_RQ_PRODUCER_IDX_M,
+ 			       V2_QPC_BYTE_84_RQ_PRODUCER_IDX_S, 0);
+ 			spin_unlock_irqrestore(&hr_qp->rq.lock, rq_flag);
+ 		}
+ 	}
+ 
+ 	/* Configure the optional fields */
+ 	ret = hns_roce_v2_set_opt_fields(ibqp, attr, attr_mask, context,
+ 					 qpc_mask);
+ 	if (ret)
+ 		goto out;
+ 
+ 	roce_set_bit(context->byte_108_rx_reqepsn, V2_QPC_BYTE_108_INV_CREDIT_S,
+ 		     ibqp->srq ? 1 : 0);
+ 	roce_set_bit(qpc_mask->byte_108_rx_reqepsn,
+ 		     V2_QPC_BYTE_108_INV_CREDIT_S, 0);
+ 
+ 	/* Every status migrate must change state */
+ 	roce_set_field(context->byte_60_qpst_tempid, V2_QPC_BYTE_60_QP_ST_M,
+ 		       V2_QPC_BYTE_60_QP_ST_S, new_state);
+ 	roce_set_field(qpc_mask->byte_60_qpst_tempid, V2_QPC_BYTE_60_QP_ST_M,
+ 		       V2_QPC_BYTE_60_QP_ST_S, 0);
+ 
+ 	/* SW pass context to HW */
+ 	ret = hns_roce_v2_qp_modify(hr_dev, context, qpc_mask, hr_qp);
+ 	if (ret) {
+ 		ibdev_err(ibdev, "failed to modify QP, ret = %d\n", ret);
+ 		goto out;
+ 	}
+ 
+ 	hr_qp->state = new_state;
+ 
+ 	hns_roce_v2_record_opt_fields(ibqp, attr, attr_mask);
++>>>>>>> 26e990badde4 (RDMA: Check attr_mask during modify_qp)
  
  	if (new_state == IB_QPS_RESET && !ibqp->uobject) {
  		hns_roce_v2_cq_clean(to_hr_cq(ibqp->recv_cq), hr_qp->qpn,
diff --cc drivers/infiniband/hw/mlx5/main.c
index 97d5f414e693,b9a12a1d1c5c..000000000000
--- a/drivers/infiniband/hw/mlx5/main.c
+++ b/drivers/infiniband/hw/mlx5/main.c
@@@ -4150,41 -4139,12 +4150,45 @@@ static int mlx5_ib_stage_caps_init(stru
  	struct mlx5_core_dev *mdev = dev->mdev;
  	int err;
  
 -	dev->ib_dev.uverbs_cmd_mask |=
 +	dev->ib_dev.uverbs_cmd_mask	=
 +		(1ull << IB_USER_VERBS_CMD_GET_CONTEXT)		|
 +		(1ull << IB_USER_VERBS_CMD_QUERY_DEVICE)	|
 +		(1ull << IB_USER_VERBS_CMD_QUERY_PORT)		|
 +		(1ull << IB_USER_VERBS_CMD_ALLOC_PD)		|
 +		(1ull << IB_USER_VERBS_CMD_DEALLOC_PD)		|
  		(1ull << IB_USER_VERBS_CMD_CREATE_AH)		|
 -		(1ull << IB_USER_VERBS_CMD_DESTROY_AH);
 -	dev->ib_dev.uverbs_ex_cmd_mask |=
 +		(1ull << IB_USER_VERBS_CMD_DESTROY_AH)		|
 +		(1ull << IB_USER_VERBS_CMD_REG_MR)		|
 +		(1ull << IB_USER_VERBS_CMD_REREG_MR)		|
 +		(1ull << IB_USER_VERBS_CMD_DEREG_MR)		|
 +		(1ull << IB_USER_VERBS_CMD_CREATE_COMP_CHANNEL)	|
 +		(1ull << IB_USER_VERBS_CMD_CREATE_CQ)		|
 +		(1ull << IB_USER_VERBS_CMD_RESIZE_CQ)		|
 +		(1ull << IB_USER_VERBS_CMD_DESTROY_CQ)		|
 +		(1ull << IB_USER_VERBS_CMD_CREATE_QP)		|
 +		(1ull << IB_USER_VERBS_CMD_MODIFY_QP)		|
 +		(1ull << IB_USER_VERBS_CMD_QUERY_QP)		|
 +		(1ull << IB_USER_VERBS_CMD_DESTROY_QP)		|
 +		(1ull << IB_USER_VERBS_CMD_ATTACH_MCAST)	|
 +		(1ull << IB_USER_VERBS_CMD_DETACH_MCAST)	|
 +		(1ull << IB_USER_VERBS_CMD_CREATE_SRQ)		|
 +		(1ull << IB_USER_VERBS_CMD_MODIFY_SRQ)		|
 +		(1ull << IB_USER_VERBS_CMD_QUERY_SRQ)		|
 +		(1ull << IB_USER_VERBS_CMD_DESTROY_SRQ)		|
 +		(1ull << IB_USER_VERBS_CMD_CREATE_XSRQ)		|
 +		(1ull << IB_USER_VERBS_CMD_OPEN_QP);
 +	dev->ib_dev.uverbs_ex_cmd_mask =
 +		(1ull << IB_USER_VERBS_EX_CMD_QUERY_DEVICE)	|
  		(1ull << IB_USER_VERBS_EX_CMD_CREATE_CQ)	|
++<<<<<<< HEAD
 +		(1ull << IB_USER_VERBS_EX_CMD_CREATE_QP)	|
 +		(1ull << IB_USER_VERBS_EX_CMD_MODIFY_QP)	|
 +		(1ull << IB_USER_VERBS_EX_CMD_MODIFY_CQ)	|
 +		(1ull << IB_USER_VERBS_EX_CMD_CREATE_FLOW)	|
 +		(1ull << IB_USER_VERBS_EX_CMD_DESTROY_FLOW);
++=======
+ 		(1ull << IB_USER_VERBS_EX_CMD_CREATE_QP);
++>>>>>>> 26e990badde4 (RDMA: Check attr_mask during modify_qp)
  
  	if (MLX5_CAP_GEN(mdev, ipoib_enhanced_offloads) &&
  	    IS_ENABLED(CONFIG_MLX5_CORE_IPOIB))
diff --cc drivers/infiniband/hw/mlx5/qp.c
index a6560ec2d863,19361132336c..000000000000
--- a/drivers/infiniband/hw/mlx5/qp.c
+++ b/drivers/infiniband/hw/mlx5/qp.c
@@@ -4235,7 -4247,7 +4235,11 @@@ int mlx5_ib_modify_qp(struct ib_qp *ibq
  	int err = -EINVAL;
  	int port;
  
++<<<<<<< HEAD
 +	if (!mlx5_ib_modify_qp_allowed(dev, qp, ibqp->qp_type))
++=======
+ 	if (attr_mask & ~(IB_QP_ATTR_STANDARD_BITS | IB_QP_RATE_LIMIT))
++>>>>>>> 26e990badde4 (RDMA: Check attr_mask during modify_qp)
  		return -EOPNOTSUPP;
  
  	if (ibqp->rwq_ind_tbl)
* Unmerged path drivers/infiniband/core/device.c
diff --git a/drivers/infiniband/core/uverbs_cmd.c b/drivers/infiniband/core/uverbs_cmd.c
index 5076cac0253f..4a337166af45 100644
--- a/drivers/infiniband/core/uverbs_cmd.c
+++ b/drivers/infiniband/core/uverbs_cmd.c
@@ -1900,8 +1900,7 @@ static int ib_uverbs_modify_qp(struct uverbs_attr_bundle *attrs)
 	if (ret)
 		return ret;
 
-	if (cmd.base.attr_mask &
-	    ~((IB_USER_LEGACY_LAST_QP_ATTR_MASK << 1) - 1))
+	if (cmd.base.attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
 		return -EOPNOTSUPP;
 
 	return modify_qp(attrs, &cmd);
@@ -1923,10 +1922,7 @@ static int ib_uverbs_ex_modify_qp(struct uverbs_attr_bundle *attrs)
 	 * Last bit is reserved for extending the attr_mask by
 	 * using another field.
 	 */
-	BUILD_BUG_ON(IB_USER_LAST_QP_ATTR_MASK == (1ULL << 31));
-
-	if (cmd.base.attr_mask &
-	    ~((IB_USER_LAST_QP_ATTR_MASK << 1) - 1))
+	if (cmd.base.attr_mask & ~(IB_QP_ATTR_STANDARD_BITS | IB_QP_RATE_LIMIT))
 		return -EOPNOTSUPP;
 
 	ret = modify_qp(attrs, &cmd);
diff --git a/drivers/infiniband/hw/bnxt_re/ib_verbs.c b/drivers/infiniband/hw/bnxt_re/ib_verbs.c
index f9705083f078..8879131e07bd 100644
--- a/drivers/infiniband/hw/bnxt_re/ib_verbs.c
+++ b/drivers/infiniband/hw/bnxt_re/ib_verbs.c
@@ -1833,6 +1833,9 @@ int bnxt_re_modify_qp(struct ib_qp *ib_qp, struct ib_qp_attr *qp_attr,
 	unsigned int flags;
 	u8 nw_type;
 
+	if (qp_attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	qp->qplib_qp.modify_flags = 0;
 	if (qp_attr_mask & IB_QP_STATE) {
 		curr_qp_state = __to_ib_qp_state(qp->qplib_qp.cur_qp_state);
diff --git a/drivers/infiniband/hw/cxgb4/qp.c b/drivers/infiniband/hw/cxgb4/qp.c
index 4d7acd7576eb..d07f4aa33576 100644
--- a/drivers/infiniband/hw/cxgb4/qp.c
+++ b/drivers/infiniband/hw/cxgb4/qp.c
@@ -2376,6 +2376,9 @@ int c4iw_ib_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 
 	pr_debug("ib_qp %p\n", ibqp);
 
+	if (attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	/* iwarp does not support the RTR state */
 	if ((attr_mask & IB_QP_STATE) && (attr->qp_state == IB_QPS_RTR))
 		attr_mask &= ~IB_QP_STATE;
diff --git a/drivers/infiniband/hw/efa/efa_verbs.c b/drivers/infiniband/hw/efa/efa_verbs.c
index f5dd28c29cff..ee045cfcc6d4 100644
--- a/drivers/infiniband/hw/efa/efa_verbs.c
+++ b/drivers/infiniband/hw/efa/efa_verbs.c
@@ -917,6 +917,9 @@ int efa_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *qp_attr,
 	enum ib_qp_state new_state;
 	int err;
 
+	if (qp_attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	if (udata->inlen &&
 	    !ib_is_udata_cleared(udata, 0, udata->inlen)) {
 		ibdev_dbg(&dev->ibdev,
diff --git a/drivers/infiniband/hw/hns/hns_roce_hw_v1.c b/drivers/infiniband/hw/hns/hns_roce_hw_v1.c
index 8d4e1d9dfa0c..ac203de04495 100644
--- a/drivers/infiniband/hw/hns/hns_roce_hw_v1.c
+++ b/drivers/infiniband/hw/hns/hns_roce_hw_v1.c
@@ -3326,6 +3326,8 @@ static int hns_roce_v1_modify_qp(struct ib_qp *ibqp,
 				 enum ib_qp_state cur_state,
 				 enum ib_qp_state new_state)
 {
+	if (attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
 
 	if (ibqp->qp_type == IB_QPT_GSI || ibqp->qp_type == IB_QPT_SMI)
 		return hns_roce_v1_m_sqp(ibqp, attr, attr_mask, cur_state,
* Unmerged path drivers/infiniband/hw/hns/hns_roce_hw_v2.c
diff --git a/drivers/infiniband/hw/i40iw/i40iw_verbs.c b/drivers/infiniband/hw/i40iw/i40iw_verbs.c
index f03d9769941c..cf8ce6049945 100644
--- a/drivers/infiniband/hw/i40iw/i40iw_verbs.c
+++ b/drivers/infiniband/hw/i40iw/i40iw_verbs.c
@@ -858,6 +858,9 @@ int i40iw_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 	u32 err;
 	unsigned long flags;
 
+	if (attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	memset(&info, 0, sizeof(info));
 	ctx_info = &iwqp->ctx_info;
 	iwarp_info = &iwqp->iwarp_info;
diff --git a/drivers/infiniband/hw/mlx4/qp.c b/drivers/infiniband/hw/mlx4/qp.c
index 7bf33a449bf7..d78c70fee466 100644
--- a/drivers/infiniband/hw/mlx4/qp.c
+++ b/drivers/infiniband/hw/mlx4/qp.c
@@ -2789,6 +2789,9 @@ int mlx4_ib_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 	struct mlx4_ib_qp *mqp = to_mqp(ibqp);
 	int ret;
 
+	if (attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	ret = _mlx4_ib_modify_qp(ibqp, attr, attr_mask, udata);
 
 	if (mqp->mlx4_ib_qp_type == MLX4_IB_QPT_GSI) {
* Unmerged path drivers/infiniband/hw/mlx5/main.c
* Unmerged path drivers/infiniband/hw/mlx5/qp.c
diff --git a/drivers/infiniband/hw/mthca/mthca_qp.c b/drivers/infiniband/hw/mthca/mthca_qp.c
index d04c245359eb..a22cd17568f1 100644
--- a/drivers/infiniband/hw/mthca/mthca_qp.c
+++ b/drivers/infiniband/hw/mthca/mthca_qp.c
@@ -863,6 +863,9 @@ int mthca_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr, int attr_mask,
 	enum ib_qp_state cur_state, new_state;
 	int err = -EINVAL;
 
+	if (attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	mutex_lock(&qp->mutex);
 	if (attr_mask & IB_QP_CUR_STATE) {
 		cur_state = attr->cur_qp_state;
diff --git a/drivers/infiniband/hw/ocrdma/ocrdma_verbs.c b/drivers/infiniband/hw/ocrdma/ocrdma_verbs.c
index bbeb7234154f..100b2ba0563d 100644
--- a/drivers/infiniband/hw/ocrdma/ocrdma_verbs.c
+++ b/drivers/infiniband/hw/ocrdma/ocrdma_verbs.c
@@ -1404,6 +1404,9 @@ int ocrdma_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 	struct ocrdma_dev *dev;
 	enum ib_qp_state old_qps, new_qps;
 
+	if (attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	qp = get_ocrdma_qp(ibqp);
 	dev = get_ocrdma_dev(ibqp->device);
 
diff --git a/drivers/infiniband/hw/qedr/verbs.c b/drivers/infiniband/hw/qedr/verbs.c
index b1278a5a7205..38f8d3afacab 100644
--- a/drivers/infiniband/hw/qedr/verbs.c
+++ b/drivers/infiniband/hw/qedr/verbs.c
@@ -2451,6 +2451,9 @@ int qedr_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 		 "modify qp: qp %p attr_mask=0x%x, state=%d", qp, attr_mask,
 		 attr->qp_state);
 
+	if (attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	old_qp_state = qedr_get_ibqp_state(qp->state);
 	if (attr_mask & IB_QP_STATE)
 		new_qp_state = attr->qp_state;
diff --git a/drivers/infiniband/hw/usnic/usnic_ib_verbs.c b/drivers/infiniband/hw/usnic/usnic_ib_verbs.c
index b8dca2ea9769..7564d38d69d6 100644
--- a/drivers/infiniband/hw/usnic/usnic_ib_verbs.c
+++ b/drivers/infiniband/hw/usnic/usnic_ib_verbs.c
@@ -578,6 +578,9 @@ int usnic_ib_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 	int status;
 	usnic_dbg("\n");
 
+	if (attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	qp_grp = to_uqp_grp(ibqp);
 
 	mutex_lock(&qp_grp->vf->pf->usdev_lock);
diff --git a/drivers/infiniband/hw/vmw_pvrdma/pvrdma_qp.c b/drivers/infiniband/hw/vmw_pvrdma/pvrdma_qp.c
index af09d9d56c4b..ddbb0a418a71 100644
--- a/drivers/infiniband/hw/vmw_pvrdma/pvrdma_qp.c
+++ b/drivers/infiniband/hw/vmw_pvrdma/pvrdma_qp.c
@@ -544,6 +544,9 @@ int pvrdma_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 	enum ib_qp_state cur_state, next_state;
 	int ret;
 
+	if (attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	/* Sanity checking. Should need lock here */
 	mutex_lock(&qp->mutex);
 	cur_state = (attr_mask & IB_QP_CUR_STATE) ? attr->cur_qp_state :
diff --git a/drivers/infiniband/sw/rdmavt/qp.c b/drivers/infiniband/sw/rdmavt/qp.c
index 332a8ba94b81..55acafccc1e9 100644
--- a/drivers/infiniband/sw/rdmavt/qp.c
+++ b/drivers/infiniband/sw/rdmavt/qp.c
@@ -1469,6 +1469,9 @@ int rvt_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 	int pmtu = 0; /* for gcc warning only */
 	int opa_ah;
 
+	if (attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	spin_lock_irq(&qp->r_lock);
 	spin_lock(&qp->s_hlock);
 	spin_lock(&qp->s_lock);
diff --git a/drivers/infiniband/sw/rxe/rxe_verbs.c b/drivers/infiniband/sw/rxe/rxe_verbs.c
index 6f655b55dded..1889cd06a54d 100644
--- a/drivers/infiniband/sw/rxe/rxe_verbs.c
+++ b/drivers/infiniband/sw/rxe/rxe_verbs.c
@@ -432,6 +432,9 @@ static int rxe_modify_qp(struct ib_qp *ibqp, struct ib_qp_attr *attr,
 	struct rxe_dev *rxe = to_rdev(ibqp->device);
 	struct rxe_qp *qp = to_rqp(ibqp);
 
+	if (mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	err = rxe_qp_chk_attr(rxe, qp, attr, mask);
 	if (err)
 		goto err1;
diff --git a/drivers/infiniband/sw/siw/siw_verbs.c b/drivers/infiniband/sw/siw/siw_verbs.c
index db44999ac086..995e7852f846 100644
--- a/drivers/infiniband/sw/siw/siw_verbs.c
+++ b/drivers/infiniband/sw/siw/siw_verbs.c
@@ -552,6 +552,9 @@ int siw_verbs_modify_qp(struct ib_qp *base_qp, struct ib_qp_attr *attr,
 	if (!attr_mask)
 		return 0;
 
+	if (attr_mask & ~IB_QP_ATTR_STANDARD_BITS)
+		return -EOPNOTSUPP;
+
 	memset(&new_attrs, 0, sizeof(new_attrs));
 
 	if (attr_mask & IB_QP_ACCESS_FLAGS) {
diff --git a/include/rdma/ib_verbs.h b/include/rdma/ib_verbs.h
index a63d25a22e2f..655cd0f98226 100644
--- a/include/rdma/ib_verbs.h
+++ b/include/rdma/ib_verbs.h
@@ -1232,6 +1232,8 @@ enum ib_qp_attr_mask {
 	IB_QP_RESERVED3			= (1<<23),
 	IB_QP_RESERVED4			= (1<<24),
 	IB_QP_RATE_LIMIT		= (1<<25),
+
+	IB_QP_ATTR_STANDARD_BITS = GENMASK(20, 0),
 };
 
 enum ib_qp_state {
diff --git a/include/uapi/rdma/ib_user_verbs.h b/include/uapi/rdma/ib_user_verbs.h
index 456438c18c2c..7ee73a0652f1 100644
--- a/include/uapi/rdma/ib_user_verbs.h
+++ b/include/uapi/rdma/ib_user_verbs.h
@@ -596,20 +596,6 @@ enum {
 	IB_UVERBS_CREATE_QP_SUP_COMP_MASK = IB_UVERBS_CREATE_QP_MASK_IND_TABLE,
 };
 
-enum {
-	/*
-	 * This value is equal to IB_QP_DEST_QPN.
-	 */
-	IB_USER_LEGACY_LAST_QP_ATTR_MASK = 1ULL << 20,
-};
-
-enum {
-	/*
-	 * This value is equal to IB_QP_RATE_LIMIT.
-	 */
-	IB_USER_LAST_QP_ATTR_MASK = 1ULL << 25,
-};
-
 struct ib_uverbs_ex_create_qp {
 	__aligned_u64 user_handle;
 	__u32 pd_handle;
