KVM: x86: hyper-v: Prepare to meet unallocated Hyper-V context

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Vitaly Kuznetsov <vkuznets@redhat.com>
commit f2bc14b69c38b60f201fdf90c08cb2dc8966f331
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/f2bc14b6.failed

Currently, Hyper-V context is part of 'struct kvm_vcpu_arch' and is always
available. As a preparation to allocating it dynamically, check that it is
not NULL at call sites which can normally proceed without it i.e. the
behavior is identical to the situation when Hyper-V emulation is not being
used by the guest.

When Hyper-V context for a particular vCPU is not allocated, we may still
need to get 'vp_index' from there. E.g. in a hypothetical situation when
Hyper-V emulation was enabled on one CPU and wasn't on another, Hyper-V
style send-IPI hypercall may still be used. Luckily, vp_index is always
initialized to kvm_vcpu_get_idx() and can only be changed when Hyper-V
context is present. Introduce kvm_hv_get_vpindex() helper for
simplification.

No functional change intended.

	Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
Message-Id: <20210126134816.1880136-12-vkuznets@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit f2bc14b69c38b60f201fdf90c08cb2dc8966f331)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/hyperv.c
#	arch/x86/kvm/hyperv.h
#	arch/x86/kvm/lapic.c
#	arch/x86/kvm/vmx/vmx.c
#	arch/x86/kvm/x86.c
diff --cc arch/x86/kvm/hyperv.c
index c5f77ef20cbd,10e7ed2aa8fe..000000000000
--- a/arch/x86/kvm/hyperv.c
+++ b/arch/x86/kvm/hyperv.c
@@@ -839,7 -841,12 +840,16 @@@ void kvm_hv_vcpu_uninit(struct kvm_vcp
  
  bool kvm_hv_assist_page_enabled(struct kvm_vcpu *vcpu)
  {
++<<<<<<< HEAD
 +	if (!(vcpu->arch.hyperv.hv_vapic & HV_X64_MSR_VP_ASSIST_PAGE_ENABLE))
++=======
+ 	struct kvm_vcpu_hv *hv_vcpu = to_hv_vcpu(vcpu);
+ 
+ 	if (!hv_vcpu)
+ 		return false;
+ 
+ 	if (!(hv_vcpu->hv_vapic & HV_X64_MSR_VP_ASSIST_PAGE_ENABLE))
++>>>>>>> f2bc14b69c38 (KVM: x86: hyper-v: Prepare to meet unallocated Hyper-V context)
  		return false;
  	return vcpu->arch.pv_eoi.msr_val & KVM_MSR_ENABLED;
  }
diff --cc arch/x86/kvm/hyperv.h
index 69fb2e2ca018,57e53a88f5eb..000000000000
--- a/arch/x86/kvm/hyperv.h
+++ b/arch/x86/kvm/hyperv.h
@@@ -119,7 -126,12 +126,16 @@@ static inline struct kvm_vcpu *stimer_t
  
  static inline bool kvm_hv_has_stimer_pending(struct kvm_vcpu *vcpu)
  {
++<<<<<<< HEAD
 +	return !bitmap_empty(vcpu->arch.hyperv.stimer_pending_bitmap,
++=======
+ 	struct kvm_vcpu_hv *hv_vcpu = to_hv_vcpu(vcpu);
+ 
+ 	if (!hv_vcpu)
+ 		return false;
+ 
+ 	return !bitmap_empty(hv_vcpu->stimer_pending_bitmap,
++>>>>>>> f2bc14b69c38 (KVM: x86: hyper-v: Prepare to meet unallocated Hyper-V context)
  			     HV_SYNIC_STIMER_COUNT);
  }
  
diff --cc arch/x86/kvm/lapic.c
index d5b82ba18e86,45d40bfacb7c..000000000000
--- a/arch/x86/kvm/lapic.c
+++ b/arch/x86/kvm/lapic.c
@@@ -1245,7 -1245,8 +1245,12 @@@ static int apic_set_eoi(struct kvm_lapi
  	apic_clear_isr(vector, apic);
  	apic_update_ppr(apic);
  
++<<<<<<< HEAD
 +	if (test_bit(vector, vcpu_to_synic(apic->vcpu)->vec_bitmap))
++=======
+ 	if (to_hv_vcpu(apic->vcpu) &&
+ 	    test_bit(vector, to_hv_synic(apic->vcpu)->vec_bitmap))
++>>>>>>> f2bc14b69c38 (KVM: x86: hyper-v: Prepare to meet unallocated Hyper-V context)
  		kvm_hv_synic_send_eoi(apic->vcpu, vector);
  
  	kvm_ioapic_send_eoi(apic, vector);
@@@ -2512,7 -2513,7 +2517,11 @@@ int kvm_get_apic_interrupt(struct kvm_v
  	 */
  
  	apic_clear_irr(vector, apic);
++<<<<<<< HEAD
 +	if (test_bit(vector, vcpu_to_synic(vcpu)->auto_eoi_bitmap)) {
++=======
+ 	if (to_hv_vcpu(vcpu) && test_bit(vector, to_hv_synic(vcpu)->auto_eoi_bitmap)) {
++>>>>>>> f2bc14b69c38 (KVM: x86: hyper-v: Prepare to meet unallocated Hyper-V context)
  		/*
  		 * For auto-EOI interrupts, there might be another pending
  		 * interrupt above PPR, so check whether to raise another
diff --cc arch/x86/kvm/vmx/vmx.c
index 0a8eae251871,e0a3a9be654b..000000000000
--- a/arch/x86/kvm/vmx/vmx.c
+++ b/arch/x86/kvm/vmx/vmx.c
@@@ -6736,12 -6809,12 +6736,21 @@@ reenter_guest
  	x86_spec_ctrl_restore_host(vmx->spec_ctrl, 0);
  
  	/* All fields are clean at this point */
++<<<<<<< HEAD
 +	if (static_branch_unlikely(&enable_evmcs))
 +		current_evmcs->hv_clean_fields |=
 +			HV_VMX_ENLIGHTENED_CLEAN_FIELD_ALL;
 +
 +	if (static_branch_unlikely(&enable_evmcs))
 +		current_evmcs->hv_vp_id = vcpu->arch.hyperv.vp_index;
++=======
+ 	if (static_branch_unlikely(&enable_evmcs)) {
+ 		current_evmcs->hv_clean_fields |=
+ 			HV_VMX_ENLIGHTENED_CLEAN_FIELD_ALL;
+ 
+ 		current_evmcs->hv_vp_id = kvm_hv_get_vpindex(vcpu);
+ 	}
++>>>>>>> f2bc14b69c38 (KVM: x86: hyper-v: Prepare to meet unallocated Hyper-V context)
  
  	/* MSR_IA32_DEBUGCTLMSR is zeroed on vmexit. Restore it if needed */
  	if (vmx->host_debugctlmsr)
diff --cc arch/x86/kvm/x86.c
index 5b18614d5081,7caf95dadc93..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -8728,9 -8803,12 +8728,18 @@@ static void vcpu_load_eoi_exitmap(struc
  	if (!kvm_apic_hw_enabled(vcpu->arch.apic))
  		return;
  
++<<<<<<< HEAD
 +	bitmap_or((ulong *)eoi_exit_bitmap, vcpu->arch.ioapic_handled_vectors,
 +		  vcpu_to_synic(vcpu)->vec_bitmap, 256);
 +	kvm_x86_ops.load_eoi_exitmap(vcpu, eoi_exit_bitmap);
++=======
+ 	if (to_hv_vcpu(vcpu))
+ 		bitmap_or((ulong *)eoi_exit_bitmap,
+ 			  vcpu->arch.ioapic_handled_vectors,
+ 			  to_hv_synic(vcpu)->vec_bitmap, 256);
+ 
+ 	static_call(kvm_x86_load_eoi_exitmap)(vcpu, eoi_exit_bitmap);
++>>>>>>> f2bc14b69c38 (KVM: x86: hyper-v: Prepare to meet unallocated Hyper-V context)
  }
  
  void kvm_arch_mmu_notifier_invalidate_range(struct kvm *kvm,
* Unmerged path arch/x86/kvm/hyperv.c
* Unmerged path arch/x86/kvm/hyperv.h
* Unmerged path arch/x86/kvm/lapic.c
* Unmerged path arch/x86/kvm/vmx/vmx.c
* Unmerged path arch/x86/kvm/x86.c
