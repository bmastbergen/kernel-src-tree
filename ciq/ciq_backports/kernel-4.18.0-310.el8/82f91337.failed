KVM: selftests: Add option to overlap vCPU memory access

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Ben Gardon <bgardon@google.com>
commit 82f91337ddde22eaa2e9e0aca248f5e6f336fa91
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/82f91337.failed

Add an option to overlap the ranges of memory each vCPU accesses instead
of partitioning them. This option will increase the probability of
multiple vCPUs faulting on the same page at the same time, and causing
interesting races, if there are bugs in the page fault handler or
elsewhere in the kernel.

	Reviewed-by: Jacob Xu <jacobhxu@google.com>
	Reviewed-by: Makarand Sonare <makarandsonare@google.com>

	Signed-off-by: Ben Gardon <bgardon@google.com>
Message-Id: <20210112214253.463999-6-bgardon@google.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 82f91337ddde22eaa2e9e0aca248f5e6f336fa91)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/testing/selftests/kvm/demand_paging_test.c
#	tools/testing/selftests/kvm/dirty_log_perf_test.c
#	tools/testing/selftests/kvm/include/perf_test_util.h
#	tools/testing/selftests/kvm/lib/perf_test_util.c
diff --cc tools/testing/selftests/kvm/demand_paging_test.c
index 3d96a7bfaff3,e8fda95f8389..000000000000
--- a/tools/testing/selftests/kvm/demand_paging_test.c
+++ b/tools/testing/selftests/kvm/demand_paging_test.c
@@@ -248,9 -247,15 +248,19 @@@ static int setup_demand_paging(struct k
  	return 0;
  }
  
++<<<<<<< HEAD
 +static void run_test(enum vm_guest_mode mode, bool use_uffd,
 +		     useconds_t uffd_delay)
++=======
+ struct test_params {
+ 	bool use_uffd;
+ 	useconds_t uffd_delay;
+ 	bool partition_vcpu_memory_access;
+ };
+ 
+ static void run_test(enum vm_guest_mode mode, void *arg)
++>>>>>>> 82f91337ddde (KVM: selftests: Add option to overlap vCPU memory access)
  {
 -	struct test_params *p = arg;
  	pthread_t *vcpu_threads;
  	pthread_t *uffd_handler_threads = NULL;
  	struct uffd_handler_args *uffd_args = NULL;
@@@ -273,9 -278,10 +283,14 @@@
  	vcpu_threads = malloc(nr_vcpus * sizeof(*vcpu_threads));
  	TEST_ASSERT(vcpu_threads, "Memory allocation failed");
  
++<<<<<<< HEAD
 +	add_vcpus(vm, nr_vcpus, guest_percpu_mem_size);
++=======
+ 	perf_test_setup_vcpus(vm, nr_vcpus, guest_percpu_mem_size,
+ 			      p->partition_vcpu_memory_access);
++>>>>>>> 82f91337ddde (KVM: selftests: Add option to overlap vCPU memory access)
  
 -	if (p->use_uffd) {
 +	if (use_uffd) {
  		uffd_handler_threads =
  			malloc(nr_vcpus * sizeof(*uffd_handler_threads));
  		TEST_ASSERT(uffd_handler_threads, "Memory allocation failed");
@@@ -308,8 -323,8 +332,13 @@@
  			r = setup_demand_paging(vm,
  						&uffd_handler_threads[vcpu_id],
  						pipefds[vcpu_id * 2],
++<<<<<<< HEAD
 +						uffd_delay, &uffd_args[vcpu_id],
 +						vcpu_hva, guest_percpu_mem_size);
++=======
+ 						p->uffd_delay, &uffd_args[vcpu_id],
+ 						vcpu_hva, vcpu_mem_size);
++>>>>>>> 82f91337ddde (KVM: selftests: Add option to overlap vCPU memory access)
  			if (r < 0)
  				exit(-r);
  		}
@@@ -369,31 -383,12 +398,36 @@@
  	}
  }
  
 +struct guest_mode {
 +	bool supported;
 +	bool enabled;
 +};
 +static struct guest_mode guest_modes[NUM_VM_MODES];
 +
 +#define guest_mode_init(mode, supported, enabled) ({ \
 +	guest_modes[mode] = (struct guest_mode){ supported, enabled }; \
 +})
 +
  static void help(char *name)
  {
 +	int i;
 +
  	puts("");
  	printf("usage: %s [-h] [-m mode] [-u] [-d uffd_delay_usec]\n"
++<<<<<<< HEAD
 +	       "          [-b memory] [-v vcpus]\n", name);
 +	printf(" -m: specify the guest mode ID to test\n"
 +	       "     (default: test all supported modes)\n"
 +	       "     This option may be used multiple times.\n"
 +	       "     Guest mode IDs:\n");
 +	for (i = 0; i < NUM_VM_MODES; ++i) {
 +		printf("         %d:    %s%s\n", i, vm_guest_mode_string(i),
 +		       guest_modes[i].supported ? " (supported)" : "");
 +	}
++=======
+ 	       "          [-b memory] [-v vcpus] [-o]\n", name);
+ 	guest_modes_help();
++>>>>>>> 82f91337ddde (KVM: selftests: Add option to overlap vCPU memory access)
  	printf(" -u: use User Fault FD to handle vCPU page\n"
  	       "     faults.\n");
  	printf(" -d: add a delay in usec to the User Fault\n"
@@@ -410,53 -407,24 +446,60 @@@
  int main(int argc, char *argv[])
  {
  	int max_vcpus = kvm_check_cap(KVM_CAP_MAX_VCPUS);
++<<<<<<< HEAD
 +	bool mode_selected = false;
 +	unsigned int mode;
 +	int opt, i;
 +	bool use_uffd = false;
 +	useconds_t uffd_delay = 0;
++=======
+ 	struct test_params p = {
+ 		.partition_vcpu_memory_access = true,
+ 	};
+ 	int opt;
++>>>>>>> 82f91337ddde (KVM: selftests: Add option to overlap vCPU memory access)
  
 -	guest_modes_append_default();
 +#ifdef __x86_64__
 +	guest_mode_init(VM_MODE_PXXV48_4K, true, true);
 +#endif
 +#ifdef __aarch64__
 +	guest_mode_init(VM_MODE_P40V48_4K, true, true);
 +	guest_mode_init(VM_MODE_P40V48_64K, true, true);
 +	{
 +		unsigned int limit = kvm_check_cap(KVM_CAP_ARM_VM_IPA_SIZE);
 +
 +		if (limit >= 52)
 +			guest_mode_init(VM_MODE_P52V48_64K, true, true);
 +		if (limit >= 48) {
 +			guest_mode_init(VM_MODE_P48V48_4K, true, true);
 +			guest_mode_init(VM_MODE_P48V48_64K, true, true);
 +		}
 +	}
 +#endif
 +#ifdef __s390x__
 +	guest_mode_init(VM_MODE_P40V48_4K, true, true);
 +#endif
  
- 	while ((opt = getopt(argc, argv, "hm:ud:b:v:")) != -1) {
+ 	while ((opt = getopt(argc, argv, "hm:ud:b:v:o")) != -1) {
  		switch (opt) {
  		case 'm':
 -			guest_modes_cmdline(optarg);
 +			if (!mode_selected) {
 +				for (i = 0; i < NUM_VM_MODES; ++i)
 +					guest_modes[i].enabled = false;
 +				mode_selected = true;
 +			}
 +			mode = strtoul(optarg, NULL, 10);
 +			TEST_ASSERT(mode < NUM_VM_MODES,
 +				    "Guest mode ID %d too big", mode);
 +			guest_modes[mode].enabled = true;
  			break;
  		case 'u':
 -			p.use_uffd = true;
 +			use_uffd = true;
  			break;
  		case 'd':
 -			p.uffd_delay = strtoul(optarg, NULL, 0);
 -			TEST_ASSERT(p.uffd_delay >= 0, "A negative UFFD delay is not supported.");
 +			uffd_delay = strtoul(optarg, NULL, 0);
 +			TEST_ASSERT(uffd_delay >= 0,
 +				    "A negative UFFD delay is not supported.");
  			break;
  		case 'b':
  			guest_percpu_mem_size = parse_size(optarg);
diff --cc tools/testing/selftests/kvm/include/perf_test_util.h
index e9e0ac1876cf,f406534f0487..000000000000
--- a/tools/testing/selftests/kvm/include/perf_test_util.h
+++ b/tools/testing/selftests/kvm/include/perf_test_util.h
@@@ -54,139 -31,23 +54,148 @@@ struct perf_test_args 
  	uint64_t guest_page_size;
  	int wr_fract;
  
 -	struct perf_test_vcpu_args vcpu_args[KVM_MAX_VCPUS];
 +	struct vcpu_args vcpu_args[MAX_VCPUS];
  };
  
 -extern struct perf_test_args perf_test_args;
 +static struct perf_test_args perf_test_args;
  
  /*
 - * Guest physical memory offset of the testing memory slot.
 - * This will be set to the topmost valid physical address minus
 - * the test memory size.
 + * Continuously write to the first 8 bytes of each page in the
 + * specified region.
   */
 -extern uint64_t guest_test_phys_mem;
 +static void guest_code(uint32_t vcpu_id)
 +{
 +	struct vcpu_args *vcpu_args = &perf_test_args.vcpu_args[vcpu_id];
 +	uint64_t gva;
 +	uint64_t pages;
 +	int i;
 +
++<<<<<<< HEAD
 +	/* Make sure vCPU args data structure is not corrupt. */
 +	GUEST_ASSERT(vcpu_args->vcpu_id == vcpu_id);
 +
 +	gva = vcpu_args->gva;
 +	pages = vcpu_args->pages;
 +
 +	for (i = 0; i < pages; i++) {
 +		uint64_t addr = gva + (i * perf_test_args.guest_page_size);
 +
 +		if (i % perf_test_args.wr_fract == 0)
 +			*(uint64_t *)addr = 0x0123456789ABCDEF;
 +		else
 +			READ_ONCE(*(uint64_t *)addr);
 +	}
 +
 +	GUEST_SYNC(1);
 +}
 +
 +static struct kvm_vm *create_vm(enum vm_guest_mode mode, int vcpus,
 +				uint64_t vcpu_memory_bytes)
 +{
 +	struct kvm_vm *vm;
 +	uint64_t pages = DEFAULT_GUEST_PHY_PAGES;
 +	uint64_t guest_num_pages;
 +
 +	/* Account for a few pages per-vCPU for stacks */
 +	pages += DEFAULT_STACK_PGS * vcpus;
 +
 +	/*
 +	 * Reserve twice the ammount of memory needed to map the test region and
 +	 * the page table / stacks region, at 4k, for page tables. Do the
 +	 * calculation with 4K page size: the smallest of all archs. (e.g., 64K
 +	 * page size guest will need even less memory for page tables).
 +	 */
 +	pages += (2 * pages) / PTES_PER_4K_PT;
 +	pages += ((2 * vcpus * vcpu_memory_bytes) >> PAGE_SHIFT_4K) /
 +		 PTES_PER_4K_PT;
 +	pages = vm_adjust_num_guest_pages(mode, pages);
 +
 +	pr_info("Testing guest mode: %s\n", vm_guest_mode_string(mode));
 +
 +	vm = vm_create(mode, pages, O_RDWR);
 +	kvm_vm_elf_load(vm, program_invocation_name, 0, 0);
 +#ifdef __x86_64__
 +	vm_create_irqchip(vm);
 +#endif
 +
 +	perf_test_args.vm = vm;
 +	perf_test_args.guest_page_size = vm_get_page_size(vm);
 +	perf_test_args.host_page_size = getpagesize();
 +
 +	TEST_ASSERT(vcpu_memory_bytes % perf_test_args.guest_page_size == 0,
 +		    "Guest memory size is not guest page size aligned.");
 +
 +	guest_num_pages = (vcpus * vcpu_memory_bytes) /
 +			  perf_test_args.guest_page_size;
 +	guest_num_pages = vm_adjust_num_guest_pages(mode, guest_num_pages);
 +
 +	/*
 +	 * If there should be more memory in the guest test region than there
 +	 * can be pages in the guest, it will definitely cause problems.
 +	 */
 +	TEST_ASSERT(guest_num_pages < vm_get_max_gfn(vm),
 +		    "Requested more guest memory than address space allows.\n"
 +		    "    guest pages: %lx max gfn: %x vcpus: %d wss: %lx]\n",
 +		    guest_num_pages, vm_get_max_gfn(vm), vcpus,
 +		    vcpu_memory_bytes);
 +
 +	TEST_ASSERT(vcpu_memory_bytes % perf_test_args.host_page_size == 0,
 +		    "Guest memory size is not host page size aligned.");
 +
 +	guest_test_phys_mem = (vm_get_max_gfn(vm) - guest_num_pages) *
 +			      perf_test_args.guest_page_size;
 +	guest_test_phys_mem &= ~(perf_test_args.host_page_size - 1);
 +
 +#ifdef __s390x__
 +	/* Align to 1M (segment size) */
 +	guest_test_phys_mem &= ~((1 << 20) - 1);
 +#endif
 +
 +	pr_info("guest physical test memory offset: 0x%lx\n", guest_test_phys_mem);
 +
 +	/* Add an extra memory slot for testing */
 +	vm_userspace_mem_region_add(vm, VM_MEM_SRC_ANONYMOUS,
 +				    guest_test_phys_mem,
 +				    TEST_MEM_SLOT_INDEX,
 +				    guest_num_pages, 0);
 +
 +	/* Do mapping for the demand paging memory slot */
 +	virt_map(vm, guest_test_virt_mem, guest_test_phys_mem, guest_num_pages, 0);
 +
 +	ucall_init(vm, NULL);
 +
 +	return vm;
 +}
 +
 +static void add_vcpus(struct kvm_vm *vm, int vcpus, uint64_t vcpu_memory_bytes)
 +{
 +	vm_paddr_t vcpu_gpa;
 +	struct vcpu_args *vcpu_args;
 +	int vcpu_id;
 +
 +	for (vcpu_id = 0; vcpu_id < vcpus; vcpu_id++) {
 +		vcpu_args = &perf_test_args.vcpu_args[vcpu_id];
 +
 +		vm_vcpu_add_default(vm, vcpu_id, guest_code);
 +
 +		vcpu_args->vcpu_id = vcpu_id;
 +		vcpu_args->gva = guest_test_virt_mem +
 +				 (vcpu_id * vcpu_memory_bytes);
 +		vcpu_args->pages = vcpu_memory_bytes /
 +				   perf_test_args.guest_page_size;
  
 +		vcpu_gpa = guest_test_phys_mem + (vcpu_id * vcpu_memory_bytes);
 +		pr_debug("Added VCPU %d with test mem gpa [%lx, %lx)\n",
 +			 vcpu_id, vcpu_gpa, vcpu_gpa + vcpu_memory_bytes);
 +	}
 +}
++=======
+ struct kvm_vm *perf_test_create_vm(enum vm_guest_mode mode, int vcpus,
+ 				uint64_t vcpu_memory_bytes);
+ void perf_test_destroy_vm(struct kvm_vm *vm);
+ void perf_test_setup_vcpus(struct kvm_vm *vm, int vcpus,
+ 			   uint64_t vcpu_memory_bytes,
+ 			   bool partition_vcpu_memory_access);
++>>>>>>> 82f91337ddde (KVM: selftests: Add option to overlap vCPU memory access)
  
  #endif /* SELFTEST_KVM_PERF_TEST_UTIL_H */
* Unmerged path tools/testing/selftests/kvm/dirty_log_perf_test.c
* Unmerged path tools/testing/selftests/kvm/lib/perf_test_util.c
* Unmerged path tools/testing/selftests/kvm/demand_paging_test.c
* Unmerged path tools/testing/selftests/kvm/dirty_log_perf_test.c
* Unmerged path tools/testing/selftests/kvm/include/perf_test_util.h
* Unmerged path tools/testing/selftests/kvm/lib/perf_test_util.c
