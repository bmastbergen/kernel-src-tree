KVM: Add documentation for Xen hypercall and shared_info updates

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author David Woodhouse <dwmw@amazon.co.uk>
commit e1f68169a4f89e49f33bf52df29aeb57cb8b1144
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/e1f68169.failed

	Signed-off-by: David Woodhouse <dwmw@amazon.co.uk>
(cherry picked from commit e1f68169a4f89e49f33bf52df29aeb57cb8b1144)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	Documentation/virt/kvm/api.rst
diff --cc Documentation/virt/kvm/api.rst
index 1428ffb1891b,5919e9a94f25..000000000000
--- a/Documentation/virt/kvm/api.rst
+++ b/Documentation/virt/kvm/api.rst
@@@ -6421,3 -6589,116 +6557,119 @@@ When enabled, KVM will disable paravirt
  guest according to the bits in the KVM_CPUID_FEATURES CPUID leaf
  (0x40000001). Otherwise, a guest may use the paravirtual features
  regardless of what has actually been exposed through the CPUID leaf.
++<<<<<<< HEAD
++=======
+ 
+ 8.29 KVM_CAP_DIRTY_LOG_RING
+ ---------------------------
+ 
+ :Architectures: x86
+ :Parameters: args[0] - size of the dirty log ring
+ 
+ KVM is capable of tracking dirty memory using ring buffers that are
+ mmaped into userspace; there is one dirty ring per vcpu.
+ 
+ The dirty ring is available to userspace as an array of
+ ``struct kvm_dirty_gfn``.  Each dirty entry it's defined as::
+ 
+   struct kvm_dirty_gfn {
+           __u32 flags;
+           __u32 slot; /* as_id | slot_id */
+           __u64 offset;
+   };
+ 
+ The following values are defined for the flags field to define the
+ current state of the entry::
+ 
+   #define KVM_DIRTY_GFN_F_DIRTY           BIT(0)
+   #define KVM_DIRTY_GFN_F_RESET           BIT(1)
+   #define KVM_DIRTY_GFN_F_MASK            0x3
+ 
+ Userspace should call KVM_ENABLE_CAP ioctl right after KVM_CREATE_VM
+ ioctl to enable this capability for the new guest and set the size of
+ the rings.  Enabling the capability is only allowed before creating any
+ vCPU, and the size of the ring must be a power of two.  The larger the
+ ring buffer, the less likely the ring is full and the VM is forced to
+ exit to userspace. The optimal size depends on the workload, but it is
+ recommended that it be at least 64 KiB (4096 entries).
+ 
+ Just like for dirty page bitmaps, the buffer tracks writes to
+ all user memory regions for which the KVM_MEM_LOG_DIRTY_PAGES flag was
+ set in KVM_SET_USER_MEMORY_REGION.  Once a memory region is registered
+ with the flag set, userspace can start harvesting dirty pages from the
+ ring buffer.
+ 
+ An entry in the ring buffer can be unused (flag bits ``00``),
+ dirty (flag bits ``01``) or harvested (flag bits ``1X``).  The
+ state machine for the entry is as follows::
+ 
+           dirtied         harvested        reset
+      00 -----------> 01 -------------> 1X -------+
+       ^                                          |
+       |                                          |
+       +------------------------------------------+
+ 
+ To harvest the dirty pages, userspace accesses the mmaped ring buffer
+ to read the dirty GFNs.  If the flags has the DIRTY bit set (at this stage
+ the RESET bit must be cleared), then it means this GFN is a dirty GFN.
+ The userspace should harvest this GFN and mark the flags from state
+ ``01b`` to ``1Xb`` (bit 0 will be ignored by KVM, but bit 1 must be set
+ to show that this GFN is harvested and waiting for a reset), and move
+ on to the next GFN.  The userspace should continue to do this until the
+ flags of a GFN have the DIRTY bit cleared, meaning that it has harvested
+ all the dirty GFNs that were available.
+ 
+ It's not necessary for userspace to harvest the all dirty GFNs at once.
+ However it must collect the dirty GFNs in sequence, i.e., the userspace
+ program cannot skip one dirty GFN to collect the one next to it.
+ 
+ After processing one or more entries in the ring buffer, userspace
+ calls the VM ioctl KVM_RESET_DIRTY_RINGS to notify the kernel about
+ it, so that the kernel will reprotect those collected GFNs.
+ Therefore, the ioctl must be called *before* reading the content of
+ the dirty pages.
+ 
+ The dirty ring can get full.  When it happens, the KVM_RUN of the
+ vcpu will return with exit reason KVM_EXIT_DIRTY_LOG_FULL.
+ 
+ The dirty ring interface has a major difference comparing to the
+ KVM_GET_DIRTY_LOG interface in that, when reading the dirty ring from
+ userspace, it's still possible that the kernel has not yet flushed the
+ processor's dirty page buffers into the kernel buffer (with dirty bitmaps, the
+ flushing is done by the KVM_GET_DIRTY_LOG ioctl).  To achieve that, one
+ needs to kick the vcpu out of KVM_RUN using a signal.  The resulting
+ vmexit ensures that all dirty GFNs are flushed to the dirty rings.
+ 
+ NOTE: the capability KVM_CAP_DIRTY_LOG_RING and the corresponding
+ ioctl KVM_RESET_DIRTY_RINGS are mutual exclusive to the existing ioctls
+ KVM_GET_DIRTY_LOG and KVM_CLEAR_DIRTY_LOG.  After enabling
+ KVM_CAP_DIRTY_LOG_RING with an acceptable dirty ring size, the virtual
+ machine will switch to ring-buffer dirty page tracking and further
+ KVM_GET_DIRTY_LOG or KVM_CLEAR_DIRTY_LOG ioctls will fail.
+ 
+ 8.30 KVM_CAP_XEN_HVM
+ --------------------
+ 
+ :Architectures: x86
+ 
+ This capability indicates the features that Xen supports for hosting Xen
+ PVHVM guests. Valid flags are::
+ 
+   #define KVM_XEN_HVM_CONFIG_HYPERCALL_MSR	(1 << 0)
+   #define KVM_XEN_HVM_CONFIG_INTERCEPT_HCALL	(1 << 1)
+   #define KVM_XEN_HVM_CONFIG_SHARED_INFO	(1 << 2)
+ 
+ The KVM_XEN_HVM_CONFIG_HYPERCALL_MSR flag indicates that the KVM_XEN_HVM_CONFIG
+ ioctl is available, for the guest to set its hypercall page.
+ 
+ If KVM_XEN_HVM_CONFIG_INTERCEPT_HCALL is also set, the same flag may also be
+ provided in the flags to KVM_XEN_HVM_CONFIG, without providing hypercall page
+ contents, to request that KVM generate hypercall page content automatically
+ and also enable interception of guest hypercalls with KVM_EXIT_XEN.
+ 
+ The KVM_XEN_HVM_CONFIG_SHARED_INFO flag indicates the availability of the
+ KVM_XEN_HVM_SET_ATTR, KVM_XEN_HVM_GET_ATTR, KVM_XEN_VCPU_SET_ATTR and
+ KVM_XEN_VCPU_GET_ATTR ioctls, as well as the delivery of exception vectors
+ for event channel upcalls when the evtchn_upcall_pending field of a vcpu's
+ vcpu_info is set.
++>>>>>>> e1f68169a4f8 (KVM: Add documentation for Xen hypercall and shared_info updates)
* Unmerged path Documentation/virt/kvm/api.rst
