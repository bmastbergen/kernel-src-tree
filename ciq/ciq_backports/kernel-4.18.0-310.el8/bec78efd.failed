mm/memcg: remove unused definitions

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Wei Yang <richard.weiyang@gmail.com>
commit bec78efd0061365a76f88e498affd7106b256823
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/bec78efd.failed

Some definitions are left unused, just clean them.

Link: https://lkml.kernel.org/r/20201108003834.12669-1-richard.weiyang@gmail.com
	Signed-off-by: Wei Yang <richard.weiyang@gmail.com>
	Acked-by: Michal Hocko <mhocko@suse.com>
	Reviewed-by: Shakeel Butt <shakeelb@google.com>
	Reviewed-by: Roman Gushchin <guro@fb.com>
	Cc: Johannes Weiner <hannes@cmpxchg.org>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit bec78efd0061365a76f88e498affd7106b256823)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/memcontrol.h
diff --cc include/linux/memcontrol.h
index da9b4f3ccbfd,196441f5dc99..000000000000
--- a/include/linux/memcontrol.h
+++ b/include/linux/memcontrol.h
@@@ -759,37 -913,6 +759,40 @@@ static inline void mod_memcg_state(stru
  	local_irq_restore(flags);
  }
  
++<<<<<<< HEAD
 +/**
 + * mod_memcg_page_state - update page state statistics
 + * @page: the page
 + * @idx: page state item to account
 + * @val: number of pages (positive or negative)
 + *
 + * The @page must be locked or the caller must use lock_page_memcg()
 + * to prevent double accounting when the page is concurrently being
 + * moved to another memcg:
 + *
 + *   lock_page(page) or lock_page_memcg(page)
 + *   if (TestClearPageState(page))
 + *     mod_memcg_page_state(page, state, -1);
 + *   unlock_page(page) or unlock_page_memcg(page)
 + *
 + * Kernel pages are an exception to this, since they'll never move.
 + */
 +static inline void __mod_memcg_page_state(struct page *page,
 +					  int idx, int val)
 +{
 +	if (page->mem_cgroup)
 +		__mod_memcg_state(page->mem_cgroup, idx, val);
 +}
 +
 +static inline void mod_memcg_page_state(struct page *page,
 +					int idx, int val)
 +{
 +	if (page->mem_cgroup)
 +		mod_memcg_state(page->mem_cgroup, idx, val);
 +}
 +
++=======
++>>>>>>> bec78efd0061 (mm/memcg: remove unused definitions)
  static inline unsigned long lruvec_page_state(struct lruvec *lruvec,
  					      enum node_stat_item idx)
  {
@@@ -1300,133 -1426,77 +1291,140 @@@ static inlin
  void count_memcg_event_mm(struct mm_struct *mm, enum vm_event_item idx)
  {
  }
 +#endif /* CONFIG_MEMCG */
  
 -static inline void lruvec_memcg_debug(struct lruvec *lruvec, struct page *page)
++<<<<<<< HEAD
 +/* idx can be of type enum memcg_stat_item or node_stat_item */
 +static inline void __inc_memcg_state(struct mem_cgroup *memcg,
 +				     int idx)
  {
 +	__mod_memcg_state(memcg, idx, 1);
 +}
 +
 +/* idx can be of type enum memcg_stat_item or node_stat_item */
 +static inline void __dec_memcg_state(struct mem_cgroup *memcg,
 +				     int idx)
 +{
 +	__mod_memcg_state(memcg, idx, -1);
 +}
 +
 +/* idx can be of type enum memcg_stat_item or node_stat_item */
 +static inline void __inc_memcg_page_state(struct page *page,
 +					  int idx)
 +{
 +	__mod_memcg_page_state(page, idx, 1);
 +}
 +
 +/* idx can be of type enum memcg_stat_item or node_stat_item */
 +static inline void __dec_memcg_page_state(struct page *page,
 +					  int idx)
 +{
 +	__mod_memcg_page_state(page, idx, -1);
  }
 -#endif /* CONFIG_MEMCG */
  
 +static inline void __inc_lruvec_state(struct lruvec *lruvec,
 +				      enum node_stat_item idx)
++=======
+ static inline void __inc_lruvec_kmem_state(void *p, enum node_stat_item idx)
++>>>>>>> bec78efd0061 (mm/memcg: remove unused definitions)
  {
 -	__mod_lruvec_kmem_state(p, idx, 1);
 +	__mod_lruvec_state(lruvec, idx, 1);
  }
  
 -static inline void __dec_lruvec_kmem_state(void *p, enum node_stat_item idx)
 +static inline void __dec_lruvec_state(struct lruvec *lruvec,
 +				      enum node_stat_item idx)
  {
 -	__mod_lruvec_kmem_state(p, idx, -1);
 +	__mod_lruvec_state(lruvec, idx, -1);
  }
  
 -static inline struct lruvec *parent_lruvec(struct lruvec *lruvec)
 +static inline void __inc_lruvec_page_state(struct page *page,
 +					   enum node_stat_item idx)
  {
 -	struct mem_cgroup *memcg;
 +	__mod_lruvec_page_state(page, idx, 1);
 +}
  
 -	memcg = lruvec_memcg(lruvec);
 -	if (!memcg)
 -		return NULL;
 -	memcg = parent_mem_cgroup(memcg);
 -	if (!memcg)
 -		return NULL;
 -	return mem_cgroup_lruvec(memcg, lruvec_pgdat(lruvec));
 +static inline void __dec_lruvec_page_state(struct page *page,
 +					   enum node_stat_item idx)
 +{
 +	__mod_lruvec_page_state(page, idx, -1);
 +}
 +
 +static inline void __inc_lruvec_slab_state(void *p, enum node_stat_item idx)
 +{
 +	__mod_lruvec_slab_state(p, idx, 1);
  }
  
 -static inline void unlock_page_lruvec(struct lruvec *lruvec)
 +static inline void __dec_lruvec_slab_state(void *p, enum node_stat_item idx)
  {
 -	spin_unlock(&lruvec->lru_lock);
 +	__mod_lruvec_slab_state(p, idx, -1);
  }
  
 -static inline void unlock_page_lruvec_irq(struct lruvec *lruvec)
++<<<<<<< HEAD
 +/* idx can be of type enum memcg_stat_item or node_stat_item */
 +static inline void inc_memcg_state(struct mem_cgroup *memcg,
 +				   int idx)
  {
 -	spin_unlock_irq(&lruvec->lru_lock);
 +	mod_memcg_state(memcg, idx, 1);
  }
  
 -static inline void unlock_page_lruvec_irqrestore(struct lruvec *lruvec,
 -		unsigned long flags)
 +/* idx can be of type enum memcg_stat_item or node_stat_item */
 +static inline void dec_memcg_state(struct mem_cgroup *memcg,
 +				   int idx)
  {
 -	spin_unlock_irqrestore(&lruvec->lru_lock, flags);
 +	mod_memcg_state(memcg, idx, -1);
  }
  
 -/* Don't lock again iff page's lruvec locked */
 -static inline struct lruvec *relock_page_lruvec_irq(struct page *page,
 -		struct lruvec *locked_lruvec)
 +/* idx can be of type enum memcg_stat_item or node_stat_item */
 +static inline void inc_memcg_page_state(struct page *page,
 +					int idx)
  {
 -	if (locked_lruvec) {
 -		if (lruvec_holds_page_lru_lock(page, locked_lruvec))
 -			return locked_lruvec;
 +	mod_memcg_page_state(page, idx, 1);
 +}
  
 -		unlock_page_lruvec_irq(locked_lruvec);
 -	}
 +/* idx can be of type enum memcg_stat_item or node_stat_item */
 +static inline void dec_memcg_page_state(struct page *page,
 +					int idx)
 +{
 +	mod_memcg_page_state(page, idx, -1);
 +}
  
 -	return lock_page_lruvec_irq(page);
 +static inline void inc_lruvec_state(struct lruvec *lruvec,
 +				    enum node_stat_item idx)
 +{
 +	mod_lruvec_state(lruvec, idx, 1);
  }
  
 -/* Don't lock again iff page's lruvec locked */
 -static inline struct lruvec *relock_page_lruvec_irqsave(struct page *page,
 -		struct lruvec *locked_lruvec, unsigned long *flags)
 +static inline void dec_lruvec_state(struct lruvec *lruvec,
 +				    enum node_stat_item idx)
  {
 -	if (locked_lruvec) {
 -		if (lruvec_holds_page_lru_lock(page, locked_lruvec))
 -			return locked_lruvec;
 +	mod_lruvec_state(lruvec, idx, -1);
 +}
  
 -		unlock_page_lruvec_irqrestore(locked_lruvec, *flags);
 -	}
 +static inline void inc_lruvec_page_state(struct page *page,
 +					 enum node_stat_item idx)
 +{
 +	mod_lruvec_page_state(page, idx, 1);
 +}
  
 -	return lock_page_lruvec_irqsave(page, flags);
 +static inline void dec_lruvec_page_state(struct page *page,
 +					 enum node_stat_item idx)
 +{
 +	mod_lruvec_page_state(page, idx, -1);
 +}
 +
++=======
++>>>>>>> bec78efd0061 (mm/memcg: remove unused definitions)
 +static inline struct lruvec *parent_lruvec(struct lruvec *lruvec)
 +{
 +	struct mem_cgroup *memcg;
 +
 +	memcg = lruvec_memcg(lruvec);
 +	if (!memcg)
 +		return NULL;
 +	memcg = parent_mem_cgroup(memcg);
 +	if (!memcg)
 +		return NULL;
 +	return mem_cgroup_lruvec(memcg, lruvec_pgdat(lruvec));
  }
  
  #ifdef CONFIG_CGROUP_WRITEBACK
* Unmerged path include/linux/memcontrol.h
