KVM: nSVM: rename functions and variables according to vmcbXY nomenclature

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Paolo Bonzini <pbonzini@redhat.com>
commit 9e8f0fbfff1a7787658ce1add0625f59c4faf0ef
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/9e8f0fbf.failed

Now that SVM is using a separate vmcb01 and vmcb02 (and also uses the vmcb12
naming) we can give clearer names to functions that write to and read
from those VMCBs.  Likewise, variables and parameters can be renamed
from nested_vmcb to vmcb12.

	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 9e8f0fbfff1a7787658ce1add0625f59c4faf0ef)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/svm/nested.c
#	arch/x86/kvm/svm/svm.h
diff --cc arch/x86/kvm/svm/nested.c
index 93c8c786ad5c,6a523df40bfe..000000000000
--- a/arch/x86/kvm/svm/nested.c
+++ b/arch/x86/kvm/svm/nested.c
@@@ -369,8 -386,19 +369,21 @@@ static int nested_svm_load_cr3(struct k
  	return 0;
  }
  
++<<<<<<< HEAD
 +static void nested_prepare_vmcb_save(struct vcpu_svm *svm, struct vmcb *vmcb12)
++=======
+ void nested_vmcb02_compute_g_pat(struct vcpu_svm *svm)
+ {
+ 	if (!svm->nested.vmcb02.ptr)
+ 		return;
+ 
+ 	/* FIXME: merge g_pat from vmcb01 and vmcb12.  */
+ 	svm->nested.vmcb02.ptr->save.g_pat = svm->vmcb01.ptr->save.g_pat;
+ }
+ 
+ static void nested_vmcb02_prepare_save(struct vcpu_svm *svm, struct vmcb *vmcb12)
++>>>>>>> 9e8f0fbfff1a (KVM: nSVM: rename functions and variables according to vmcbXY nomenclature)
  {
 -	nested_vmcb02_compute_g_pat(svm);
 -
  	/* Load the nested guest state */
  	svm->vmcb->save.es = vmcb12->save.es;
  	svm->vmcb->save.cs = vmcb12->save.cs;
@@@ -451,9 -482,15 +464,21 @@@ int enter_svm_guest_mode(struct vcpu_sv
  
  
  	svm->nested.vmcb12_gpa = vmcb12_gpa;
++<<<<<<< HEAD
 +	load_nested_vmcb_control(svm, &vmcb12->control);
 +	nested_prepare_vmcb_save(svm, vmcb12);
 +	nested_prepare_vmcb_control(svm);
++=======
+ 
+ 	WARN_ON(svm->vmcb == svm->nested.vmcb02.ptr);
+ 
+ 	nested_svm_vmloadsave(svm->vmcb01.ptr, svm->nested.vmcb02.ptr);
+ 	nested_load_control_from_vmcb12(svm, &vmcb12->control);
+ 
+ 	svm_switch_vmcb(svm, &svm->nested.vmcb02);
+ 	nested_vmcb02_prepare_control(svm);
+ 	nested_vmcb02_prepare_save(svm, vmcb12);
++>>>>>>> 9e8f0fbfff1a (KVM: nSVM: rename functions and variables according to vmcbXY nomenclature)
  
  	ret = nested_svm_load_cr3(&svm->vcpu, vmcb12->save.cr3,
  				  nested_npt_enabled(svm));
@@@ -1202,12 -1223,15 +1227,23 @@@ static int svm_set_nested_state(struct 
  	svm->nested.nested_run_pending =
  		!!(kvm_state->flags & KVM_STATE_NESTED_RUN_PENDING);
  
 +	copy_vmcb_control_area(&hsave->control, &svm->vmcb->control);
 +	hsave->save = *save;
 +
  	svm->nested.vmcb12_gpa = kvm_state->hdr.svm.vmcb_pa;
++<<<<<<< HEAD
 +	load_nested_vmcb_control(svm, ctl);
 +	nested_prepare_vmcb_control(svm);
++=======
+ 	if (svm->current_vmcb == &svm->vmcb01)
+ 		svm->nested.vmcb02.ptr->save = svm->vmcb01.ptr->save;
+ 	svm->vmcb01.ptr->save = *save;
+ 	nested_load_control_from_vmcb12(svm, ctl);
+ 
+ 	svm_switch_vmcb(svm, &svm->nested.vmcb02);
+ 
+ 	nested_vmcb02_prepare_control(svm);
++>>>>>>> 9e8f0fbfff1a (KVM: nSVM: rename functions and variables according to vmcbXY nomenclature)
  
  	kvm_make_request(KVM_REQ_GET_NESTED_STATE_PAGES, vcpu);
  	ret = 0;
diff --cc arch/x86/kvm/svm/svm.h
index de600f536464,86f2fbb84307..000000000000
--- a/arch/x86/kvm/svm/svm.h
+++ b/arch/x86/kvm/svm/svm.h
@@@ -416,7 -449,9 +415,13 @@@ int nested_svm_check_permissions(struc
  int nested_svm_check_exception(struct vcpu_svm *svm, unsigned nr,
  			       bool has_error_code, u32 error_code);
  int nested_svm_exit_special(struct vcpu_svm *svm);
++<<<<<<< HEAD
 +void sync_nested_vmcb_control(struct vcpu_svm *svm);
++=======
+ void nested_sync_control_from_vmcb02(struct vcpu_svm *svm);
+ void nested_vmcb02_compute_g_pat(struct vcpu_svm *svm);
+ void svm_switch_vmcb(struct vcpu_svm *svm, struct kvm_vmcb_info *target_vmcb);
++>>>>>>> 9e8f0fbfff1a (KVM: nSVM: rename functions and variables according to vmcbXY nomenclature)
  
  extern struct kvm_x86_nested_ops svm_nested_ops;
  
* Unmerged path arch/x86/kvm/svm/nested.c
diff --git a/arch/x86/kvm/svm/svm.c b/arch/x86/kvm/svm/svm.c
index 05deab5ed2e8..40949bcbb0ac 100644
--- a/arch/x86/kvm/svm/svm.c
+++ b/arch/x86/kvm/svm/svm.c
@@ -2061,7 +2061,7 @@ static int vmmcall_interception(struct vcpu_svm *svm)
 
 static int vmload_interception(struct vcpu_svm *svm)
 {
-	struct vmcb *nested_vmcb;
+	struct vmcb *vmcb12;
 	struct kvm_host_map map;
 	int ret;
 
@@ -2075,11 +2075,11 @@ static int vmload_interception(struct vcpu_svm *svm)
 		return 1;
 	}
 
-	nested_vmcb = map.hva;
+	vmcb12 = map.hva;
 
 	ret = kvm_skip_emulated_instruction(&svm->vcpu);
 
-	nested_svm_vmloadsave(nested_vmcb, svm->vmcb);
+	nested_svm_vmloadsave(vmcb12, svm->vmcb);
 	kvm_vcpu_unmap(&svm->vcpu, &map, true);
 
 	return ret;
@@ -2087,7 +2087,7 @@ static int vmload_interception(struct vcpu_svm *svm)
 
 static int vmsave_interception(struct vcpu_svm *svm)
 {
-	struct vmcb *nested_vmcb;
+	struct vmcb *vmcb12;
 	struct kvm_host_map map;
 	int ret;
 
@@ -2101,11 +2101,11 @@ static int vmsave_interception(struct vcpu_svm *svm)
 		return 1;
 	}
 
-	nested_vmcb = map.hva;
+	vmcb12 = map.hva;
 
 	ret = kvm_skip_emulated_instruction(&svm->vcpu);
 
-	nested_svm_vmloadsave(svm->vmcb, nested_vmcb);
+	nested_svm_vmloadsave(svm->vmcb, vmcb12);
 	kvm_vcpu_unmap(&svm->vcpu, &map, true);
 
 	return ret;
@@ -3781,7 +3781,7 @@ static fastpath_t svm_vcpu_run(struct kvm_vcpu *vcpu)
 
 	svm->next_rip = 0;
 	if (is_guest_mode(&svm->vcpu)) {
-		sync_nested_vmcb_control(svm);
+		nested_sync_control_from_vmcb02(svm);
 		svm->nested.nested_run_pending = 0;
 	}
 
* Unmerged path arch/x86/kvm/svm/svm.h
