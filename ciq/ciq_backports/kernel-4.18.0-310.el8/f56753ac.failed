bdi: replace BDI_CAP_NO_{WRITEBACK,ACCT_DIRTY} with a single flag

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Christoph Hellwig <hch@lst.de>
commit f56753ac2a90810726334df04d735e9f8f5a32d9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/f56753ac.failed

Replace the two negative flags that are always used together with a
single positive flag that indicates the writeback capability instead
of two related non-capabilities.  Also remove the pointless wrappers
to just check the flag.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Reviewed-by: Jan Kara <jack@suse.cz>
	Reviewed-by: Johannes Thumshirn <johannes.thumshirn@wdc.com>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit f56753ac2a90810726334df04d735e9f8f5a32d9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/backing-dev.h
#	mm/backing-dev.c
diff --cc include/linux/backing-dev.h
index 6b3504bf7a42,44df4fcef65c..000000000000
--- a/include/linux/backing-dev.h
+++ b/include/linux/backing-dev.h
@@@ -110,33 -110,14 +110,44 @@@ int bdi_set_max_ratio(struct backing_de
  /*
   * Flags in backing_dev_info::capability
   *
++<<<<<<< HEAD
 + * The first three flags control whether dirty pages will contribute to the
 + * VM's accounting and whether writepages() should be called for dirty pages
 + * (something that would not, for example, be appropriate for ramfs)
 + *
 + * WARNING: these flags are closely related and should not normally be
 + * used separately.  The BDI_CAP_NO_ACCT_AND_WRITEBACK combines these
 + * three flags into a single convenience macro.
 + *
 + * BDI_CAP_NO_ACCT_DIRTY:  Dirty pages shouldn't contribute to accounting
 + * BDI_CAP_NO_WRITEBACK:   Don't write pages back
 + * BDI_CAP_NO_ACCT_WB:     Don't automatically account writeback pages
 + * BDI_CAP_STRICTLIMIT:    Keep number of dirty pages below bdi threshold.
 + *
 + * BDI_CAP_CGROUP_WRITEBACK: Supports cgroup-aware writeback.
 + * BDI_CAP_SYNCHRONOUS_IO: Device is so fast that asynchronous IO would be
 + *			   inefficient.
 + */
 +#define BDI_CAP_NO_ACCT_DIRTY	0x00000001
 +#define BDI_CAP_NO_WRITEBACK	0x00000002
 +#define BDI_CAP_NO_ACCT_WB	0x00000004
 +#define BDI_CAP_STABLE_WRITES	0x00000008
 +#define BDI_CAP_STRICTLIMIT	0x00000010
 +#define BDI_CAP_CGROUP_WRITEBACK 0x00000020
 +#define BDI_CAP_SYNCHRONOUS_IO	0x00000040
 +
 +#define BDI_CAP_NO_ACCT_AND_WRITEBACK \
 +	(BDI_CAP_NO_WRITEBACK | BDI_CAP_NO_ACCT_DIRTY | BDI_CAP_NO_ACCT_WB)
++=======
+  * BDI_CAP_WRITEBACK:		Supports dirty page writeback, and dirty pages
+  *				should contribute to accounting
+  * BDI_CAP_WRITEBACK_ACCT:	Automatically account writeback pages
+  * BDI_CAP_STRICTLIMIT:		Keep number of dirty pages below bdi threshold
+  */
+ #define BDI_CAP_WRITEBACK		(1 << 0)
+ #define BDI_CAP_WRITEBACK_ACCT		(1 << 1)
+ #define BDI_CAP_STRICTLIMIT		(1 << 2)
++>>>>>>> f56753ac2a90 (bdi: replace BDI_CAP_NO_{WRITEBACK,ACCT_DIRTY} with a single flag)
  
  extern struct backing_dev_info noop_backing_dev_info;
  
@@@ -179,41 -156,9 +190,47 @@@ static inline int wb_congested(struct b
  long congestion_wait(int sync, long timeout);
  long wait_iff_congested(int sync, long timeout);
  
++<<<<<<< HEAD
 +static inline bool bdi_cap_synchronous_io(struct backing_dev_info *bdi)
 +{
 +	return bdi->capabilities & BDI_CAP_SYNCHRONOUS_IO;
 +}
 +
 +static inline bool bdi_cap_stable_pages_required(struct backing_dev_info *bdi)
 +{
 +	return bdi->capabilities & BDI_CAP_STABLE_WRITES;
 +}
 +
 +static inline bool bdi_cap_writeback_dirty(struct backing_dev_info *bdi)
 +{
 +	return !(bdi->capabilities & BDI_CAP_NO_WRITEBACK);
 +}
 +
 +static inline bool bdi_cap_account_dirty(struct backing_dev_info *bdi)
 +{
 +	return !(bdi->capabilities & BDI_CAP_NO_ACCT_DIRTY);
 +}
 +
 +static inline bool bdi_cap_account_writeback(struct backing_dev_info *bdi)
 +{
 +	/* Paranoia: BDI_CAP_NO_WRITEBACK implies BDI_CAP_NO_ACCT_WB */
 +	return !(bdi->capabilities & (BDI_CAP_NO_ACCT_WB |
 +				      BDI_CAP_NO_WRITEBACK));
 +}
 +
 +static inline bool mapping_cap_writeback_dirty(struct address_space *mapping)
 +{
 +	return bdi_cap_writeback_dirty(inode_to_bdi(mapping->host));
 +}
 +
 +static inline bool mapping_cap_account_dirty(struct address_space *mapping)
 +{
 +	return bdi_cap_account_dirty(inode_to_bdi(mapping->host));
++=======
+ static inline bool mapping_can_writeback(struct address_space *mapping)
+ {
+ 	return inode_to_bdi(mapping->host)->capabilities & BDI_CAP_WRITEBACK;
++>>>>>>> f56753ac2a90 (bdi: replace BDI_CAP_NO_{WRITEBACK,ACCT_DIRTY} with a single flag)
  }
  
  static inline int bdi_sched_wait(void *word)
@@@ -253,8 -195,7 +270,12 @@@ static inline bool inode_cgwb_enabled(s
  
  	return cgroup_subsys_on_dfl(memory_cgrp_subsys) &&
  		cgroup_subsys_on_dfl(io_cgrp_subsys) &&
++<<<<<<< HEAD
 +		bdi_cap_account_dirty(bdi) &&
 +		(bdi->capabilities & BDI_CAP_CGROUP_WRITEBACK) &&
++=======
+ 		(bdi->capabilities & BDI_CAP_WRITEBACK) &&
++>>>>>>> f56753ac2a90 (bdi: replace BDI_CAP_NO_{WRITEBACK,ACCT_DIRTY} with a single flag)
  		(inode->i_sb->s_iflags & SB_I_CGROUPWB);
  }
  
diff --cc mm/backing-dev.c
index 29a89b31a51a,408d5051d05b..000000000000
--- a/mm/backing-dev.c
+++ b/mm/backing-dev.c
@@@ -14,11 -14,7 +14,15 @@@
  #include <linux/device.h>
  #include <trace/events/writeback.h>
  
++<<<<<<< HEAD
 +static char noop_bdi_dev_name[BDI_DEV_NAME_LEN];
 +struct backing_dev_info noop_backing_dev_info = {
 +	.capabilities	= BDI_CAP_NO_ACCT_AND_WRITEBACK,
 +	.dev_name	= noop_bdi_dev_name,
 +};
++=======
+ struct backing_dev_info noop_backing_dev_info;
++>>>>>>> f56753ac2a90 (bdi: replace BDI_CAP_NO_{WRITEBACK,ACCT_DIRTY} with a single flag)
  EXPORT_SYMBOL_GPL(noop_backing_dev_info);
  
  static struct class *bdi_class;
@@@ -904,6 -743,9 +908,12 @@@ struct backing_dev_info *bdi_alloc(int 
  		kfree(bdi);
  		return NULL;
  	}
++<<<<<<< HEAD
++=======
+ 	bdi->capabilities = BDI_CAP_WRITEBACK | BDI_CAP_WRITEBACK_ACCT;
+ 	bdi->ra_pages = VM_READAHEAD_PAGES;
+ 	bdi->io_pages = VM_READAHEAD_PAGES;
++>>>>>>> f56753ac2a90 (bdi: replace BDI_CAP_NO_{WRITEBACK,ACCT_DIRTY} with a single flag)
  	return bdi;
  }
  EXPORT_SYMBOL(bdi_alloc);
diff --git a/fs/9p/vfs_file.c b/fs/9p/vfs_file.c
index 03c9e325bfbc..78ba3cb54ca6 100644
--- a/fs/9p/vfs_file.c
+++ b/fs/9p/vfs_file.c
@@ -614,7 +614,7 @@ static void v9fs_mmap_vm_close(struct vm_area_struct *vma)
 
 	inode = file_inode(vma->vm_file);
 
-	if (!mapping_cap_writeback_dirty(inode->i_mapping))
+	if (!mapping_can_writeback(inode->i_mapping))
 		wbc.nr_to_write = 0;
 
 	might_sleep();
diff --git a/fs/fs-writeback.c b/fs/fs-writeback.c
index 0607058b7a4f..41586f71def8 100644
--- a/fs/fs-writeback.c
+++ b/fs/fs-writeback.c
@@ -2316,7 +2316,7 @@ void __mark_inode_dirty(struct inode *inode, int flags)
 
 			wb = locked_inode_to_wb_and_lock_list(inode);
 
-			WARN(bdi_cap_writeback_dirty(wb->bdi) &&
+			WARN((wb->bdi->capabilities & BDI_CAP_WRITEBACK) &&
 			     !test_bit(WB_registered, &wb->state),
 			     "bdi-%s not registered\n", bdi_dev_name(wb->bdi));
 
@@ -2341,7 +2341,8 @@ void __mark_inode_dirty(struct inode *inode, int flags)
 			 * to make sure background write-back happens
 			 * later.
 			 */
-			if (bdi_cap_writeback_dirty(wb->bdi) && wakeup_bdi)
+			if (wakeup_bdi &&
+			    (wb->bdi->capabilities & BDI_CAP_WRITEBACK))
 				wb_wakeup_delayed(wb);
 			return;
 		}
@@ -2576,7 +2577,7 @@ int write_inode_now(struct inode *inode, int sync)
 		.range_end = LLONG_MAX,
 	};
 
-	if (!mapping_cap_writeback_dirty(inode->i_mapping))
+	if (!mapping_can_writeback(inode->i_mapping))
 		wbc.nr_to_write = 0;
 
 	might_sleep();
* Unmerged path include/linux/backing-dev.h
* Unmerged path mm/backing-dev.c
diff --git a/mm/filemap.c b/mm/filemap.c
index 68745a9da95a..3b5c69e355a6 100644
--- a/mm/filemap.c
+++ b/mm/filemap.c
@@ -412,7 +412,7 @@ int __filemap_fdatawrite_range(struct address_space *mapping, loff_t start,
 		.range_end = end,
 	};
 
-	if (!mapping_cap_writeback_dirty(mapping) ||
+	if (!mapping_can_writeback(mapping) ||
 	    !mapping_tagged(mapping, PAGECACHE_TAG_DIRTY))
 		return 0;
 
@@ -1671,7 +1671,7 @@ struct page *pagecache_get_page(struct address_space *mapping, pgoff_t offset,
 no_page:
 	if (!page && (fgp_flags & FGP_CREAT)) {
 		int err;
-		if ((fgp_flags & FGP_WRITE) && mapping_cap_account_dirty(mapping))
+		if ((fgp_flags & FGP_WRITE) && mapping_can_writeback(mapping))
 			gfp_mask |= __GFP_WRITE;
 		if (fgp_flags & FGP_NOFS)
 			gfp_mask &= ~__GFP_FS;
diff --git a/mm/memcontrol.c b/mm/memcontrol.c
index e0c5e437cb00..94647ca7e37c 100644
--- a/mm/memcontrol.c
+++ b/mm/memcontrol.c
@@ -5667,7 +5667,7 @@ static int mem_cgroup_move_account(struct page *page,
 		if (PageDirty(page)) {
 			struct address_space *mapping = page_mapping(page);
 
-			if (mapping_cap_account_dirty(mapping)) {
+			if (mapping_can_writeback(mapping)) {
 				__mod_lruvec_state(from_vec, NR_FILE_DIRTY,
 						   -nr_pages);
 				__mod_lruvec_state(to_vec, NR_FILE_DIRTY,
diff --git a/mm/memory-failure.c b/mm/memory-failure.c
index 1eb364eceed0..731a357c408a 100644
--- a/mm/memory-failure.c
+++ b/mm/memory-failure.c
@@ -1033,7 +1033,7 @@ static bool hwpoison_user_mappings(struct page *p, unsigned long pfn,
 	 */
 	mapping = page_mapping(hpage);
 	if (!(flags & MF_MUST_KILL) && !PageDirty(hpage) && mapping &&
-	    mapping_cap_writeback_dirty(mapping)) {
+	    mapping_can_writeback(mapping)) {
 		if (page_mkclean(hpage)) {
 			SetPageDirty(hpage);
 		} else {
diff --git a/mm/migrate.c b/mm/migrate.c
index f9092c22e9d0..b43adb095676 100644
--- a/mm/migrate.c
+++ b/mm/migrate.c
@@ -500,7 +500,7 @@ int migrate_page_move_mapping(struct address_space *mapping,
 			__dec_lruvec_state(old_lruvec, NR_SHMEM);
 			__inc_lruvec_state(new_lruvec, NR_SHMEM);
 		}
-		if (dirty && mapping_cap_account_dirty(mapping)) {
+		if (dirty && mapping_can_writeback(mapping)) {
 			__dec_node_state(oldzone->zone_pgdat, NR_FILE_DIRTY);
 			__dec_zone_state(oldzone, NR_ZONE_WRITE_PENDING);
 			__inc_node_state(newzone->zone_pgdat, NR_FILE_DIRTY);
diff --git a/mm/mmap.c b/mm/mmap.c
index 5a45204b129b..42546874cd79 100644
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -1661,7 +1661,7 @@ int vma_wants_writenotify(struct vm_area_struct *vma, pgprot_t vm_page_prot)
 
 	/* Can the mapping track the dirty pages? */
 	return vma->vm_file && vma->vm_file->f_mapping &&
-		mapping_cap_account_dirty(vma->vm_file->f_mapping);
+		mapping_can_writeback(vma->vm_file->f_mapping);
 }
 
 /*
diff --git a/mm/page-writeback.c b/mm/page-writeback.c
index f52d528bbfa7..5c54215a8941 100644
--- a/mm/page-writeback.c
+++ b/mm/page-writeback.c
@@ -1886,7 +1886,7 @@ void balance_dirty_pages_ratelimited(struct address_space *mapping)
 	int ratelimit;
 	int *p;
 
-	if (!bdi_cap_account_dirty(bdi))
+	if (!(bdi->capabilities & BDI_CAP_WRITEBACK))
 		return;
 
 	if (inode_cgwb_enabled(inode))
@@ -2431,7 +2431,7 @@ void account_page_dirtied(struct page *page, struct address_space *mapping)
 
 	trace_writeback_dirty_page(page, mapping);
 
-	if (mapping_cap_account_dirty(mapping)) {
+	if (mapping_can_writeback(mapping)) {
 		struct bdi_writeback *wb;
 
 		inode_attach_wb(inode, page);
@@ -2459,7 +2459,7 @@ EXPORT_SYMBOL(account_page_dirtied);
 void account_page_cleaned(struct page *page, struct address_space *mapping,
 			  struct bdi_writeback *wb)
 {
-	if (mapping_cap_account_dirty(mapping)) {
+	if (mapping_can_writeback(mapping)) {
 		dec_lruvec_page_state(page, NR_FILE_DIRTY);
 		dec_zone_page_state(page, NR_ZONE_WRITE_PENDING);
 		dec_wb_stat(wb, WB_RECLAIMABLE);
@@ -2522,7 +2522,7 @@ void account_page_redirty(struct page *page)
 {
 	struct address_space *mapping = page->mapping;
 
-	if (mapping && mapping_cap_account_dirty(mapping)) {
+	if (mapping && mapping_can_writeback(mapping)) {
 		struct inode *inode = mapping->host;
 		struct bdi_writeback *wb;
 		struct wb_lock_cookie cookie = {};
@@ -2634,7 +2634,7 @@ void __cancel_dirty_page(struct page *page)
 {
 	struct address_space *mapping = page_mapping(page);
 
-	if (mapping_cap_account_dirty(mapping)) {
+	if (mapping_can_writeback(mapping)) {
 		struct inode *inode = mapping->host;
 		struct bdi_writeback *wb;
 		struct wb_lock_cookie cookie = {};
@@ -2674,7 +2674,7 @@ int clear_page_dirty_for_io(struct page *page)
 
 	BUG_ON(!PageLocked(page));
 
-	if (mapping && mapping_cap_account_dirty(mapping)) {
+	if (mapping && mapping_can_writeback(mapping)) {
 		struct inode *inode = mapping->host;
 		struct bdi_writeback *wb;
 		struct wb_lock_cookie cookie = {};
