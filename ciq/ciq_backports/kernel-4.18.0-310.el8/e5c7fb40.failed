block: move the devcgroup_inode_permission call to blkdev_get

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Christoph Hellwig <hch@lst.de>
commit e5c7fb400227df5c7822a3c59b193d23e849d0ac
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/e5c7fb40.failed

devcgroup_inode_permission is never called for the recusive case, so
move it out into blkdev_get.

	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit e5c7fb400227df5c7822a3c59b193d23e849d0ac)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/block_dev.c
diff --cc fs/block_dev.c
index f19cc879b480,990e97bcbeaf..000000000000
--- a/fs/block_dev.c
+++ b/fs/block_dev.c
@@@ -1545,24 -1448,11 +1545,15 @@@ static int __blkdev_get(struct block_de
  	struct gendisk *disk;
  	int ret;
  	int partno;
++<<<<<<< HEAD
 +	int perm = 0;
 +	bool first_open = false;
- 
- 	if (mode & FMODE_READ)
- 		perm |= MAY_READ;
- 	if (mode & FMODE_WRITE)
- 		perm |= MAY_WRITE;
- 	/*
- 	 * hooks: /n/, see "layering violations".
- 	 */
- 	if (!for_part) {
- 		ret = devcgroup_inode_permission(bdev->bd_inode, perm);
- 		if (ret != 0)
- 			return ret;
- 	}
++=======
+ 	bool first_open = false, unblock_events = true, need_restart;
++>>>>>>> e5c7fb400227 (block: move the devcgroup_inode_permission call to blkdev_get)
  
   restart:
 -	need_restart = false;
 +
  	ret = -ENXIO;
  	disk = bdev_get_gendisk(bdev, &partno);
  	if (!disk)
@@@ -1705,51 -1623,24 +1696,72 @@@
   */
  int blkdev_get(struct block_device *bdev, fmode_t mode, void *holder)
  {
++<<<<<<< HEAD
 +	struct block_device *whole = NULL;
 +	int res;
 +
 +	WARN_ON_ONCE((mode & FMODE_EXCL) && !holder);
 +
 +	if ((mode & FMODE_EXCL) && holder) {
 +		whole = bd_start_claiming(bdev, holder);
 +		if (IS_ERR(whole)) {
 +			bdput(bdev);
 +			return PTR_ERR(whole);
 +		}
 +	}
 +
 +	res = __blkdev_get(bdev, mode, 0);
 +
 +	if (whole) {
 +		struct gendisk *disk = whole->bd_disk;
 +
 +		/* finish claiming */
 +		mutex_lock(&bdev->bd_mutex);
 +		if (!res)
 +			bd_finish_claiming(bdev, whole, holder);
 +		else
 +			bd_abort_claiming(bdev, whole, holder);
 +		/*
 +		 * Block event polling for write claims if requested.  Any
 +		 * write holder makes the write_holder state stick until
 +		 * all are released.  This is good enough and tracking
 +		 * individual writeable reference is too fragile given the
 +		 * way @mode is used in blkdev_get/put().
 +		 */
 +		if (!res && (mode & FMODE_WRITE) && !bdev->bd_write_holder &&
 +		    (disk->flags & GENHD_FL_BLOCK_EVENTS_ON_EXCL_WRITE)) {
 +			bdev->bd_write_holder = true;
 +			disk_block_events(disk);
 +		}
 +
 +		mutex_unlock(&bdev->bd_mutex);
 +		bdput(whole);
 +	}
 +
 +	if (res)
 +		bdput(bdev);
 +
 +	return res;
++=======
+ 	int ret, perm = 0;
+ 
+ 	if (mode & FMODE_READ)
+ 		perm |= MAY_READ;
+ 	if (mode & FMODE_WRITE)
+ 		perm |= MAY_WRITE;
+ 	ret = devcgroup_inode_permission(bdev->bd_inode, perm);
+ 	if (ret)
+ 		goto bdput;
+ 
+ 	ret =__blkdev_get(bdev, mode, holder, 0);
+ 	if (ret)
+ 		goto bdput;
+ 	return 0;
+ 
+ bdput:
+ 	bdput(bdev);
+ 	return ret;
++>>>>>>> e5c7fb400227 (block: move the devcgroup_inode_permission call to blkdev_get)
  }
  EXPORT_SYMBOL(blkdev_get);
  
* Unmerged path fs/block_dev.c
