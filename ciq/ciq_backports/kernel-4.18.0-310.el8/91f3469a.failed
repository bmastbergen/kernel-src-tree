powerpc/perf: Include PMCs as part of per-cpu cpuhw_events struct

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Athira Rajeev <atrajeev@linux.vnet.ibm.com>
commit 91f3469a43fd1fb831649c2a2e684bf5ad4818b2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/91f3469a.failed

To support capturing of PMC's as part of extended registers, the
value of SPR's PMC1 to PMC6 has to be saved in the starting of PMI
interrupt handler. This is needed since we are resetting the
overflown PMC before creating sample and hence directly reading
SPRN_PMCx in 'perf_reg_value' will be capturing the modified value.

To solve this, add a per-cpu array as part of structure cpu_hw_events
and use this array to capture PMC values in the perf interrupt handler.
Patch also re-factor's the interrupt handler code to use this per-cpu
array instead of current local array.

	Signed-off-by: Athira Rajeev <atrajeev@linux.vnet.ibm.com>
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://lore.kernel.org/r/1612335337-1888-2-git-send-email-atrajeev@linux.vnet.ibm.com
(cherry picked from commit 91f3469a43fd1fb831649c2a2e684bf5ad4818b2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/perf/core-book3s.c
diff --cc arch/powerpc/perf/core-book3s.c
index f81dff3aa9d5,72bedd812b60..000000000000
--- a/arch/powerpc/perf/core-book3s.c
+++ b/arch/powerpc/perf/core-book3s.c
@@@ -2278,9 -2267,7 +2281,8 @@@ static void __perf_event_interrupt(stru
  	int i, j;
  	struct cpu_hw_events *cpuhw = this_cpu_ptr(&cpu_hw_events);
  	struct perf_event *event;
- 	unsigned long val[8];
  	int found, active;
 +	int nmi;
  
  	if (cpuhw->n_limited)
  		freeze_limited_counters(cpuhw, mfspr(SPRN_PMC5),
@@@ -2288,21 -2275,9 +2290,21 @@@
  
  	perf_read_regs(regs);
  
 +	/*
 +	 * If perf interrupts hit in a local_irq_disable (soft-masked) region,
 +	 * we consider them as NMIs. This is required to prevent hash faults on
 +	 * user addresses when reading callchains. See the NMI test in
 +	 * do_hash_page.
 +	 */
 +	nmi = perf_intr_is_nmi(regs);
 +	if (nmi)
 +		nmi_enter();
 +	else
 +		irq_enter();
 +
  	/* Read all the PMCs since we'll need them a bunch of times */
  	for (i = 0; i < ppmu->n_counter; ++i)
- 		val[i] = read_pmc(i + 1);
+ 		cpuhw->pmcs[i] = read_pmc(i + 1);
  
  	/* Try to find what caused the IRQ */
  	found = 0;
@@@ -2357,10 -2332,9 +2359,16 @@@
  	 */
  	write_mmcr0(cpuhw, cpuhw->mmcr.mmcr0);
  
++<<<<<<< HEAD
 +	if (nmi)
 +		nmi_exit();
 +	else
 +		irq_exit();
++=======
+ 	/* Clear the cpuhw->pmcs */
+ 	memset(&cpuhw->pmcs, 0, sizeof(cpuhw->pmcs));
+ 
++>>>>>>> 91f3469a43fd (powerpc/perf: Include PMCs as part of per-cpu cpuhw_events struct)
  }
  
  static void perf_event_interrupt(struct pt_regs *regs)
* Unmerged path arch/powerpc/perf/core-book3s.c
