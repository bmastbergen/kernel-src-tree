KVM: x86: hyper-v: Allocate Hyper-V context lazily

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-310.el8
commit-author Vitaly Kuznetsov <vkuznets@redhat.com>
commit fc08b628d7c96d9a6d6bca488c3fa9c92bee6cc8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-310.el8/fc08b628.failed

Hyper-V context is only needed for guests which use Hyper-V emulation in
KVM (e.g. Windows/Hyper-V guests) so we don't actually need to allocate
it in kvm_arch_vcpu_create(), we can postpone the action until Hyper-V
specific MSRs are accessed or SynIC is enabled.

Once allocated, let's keep the context alive for the lifetime of the vCPU
as an attempt to free it would require additional synchronization with
other vCPUs and normally it is not supposed to happen.

Note, Hyper-V style hypercall enablement is done by writing to
HV_X64_MSR_GUEST_OS_ID so we don't need to worry about allocating Hyper-V
context from kvm_hv_hypercall().

	Signed-off-by: Vitaly Kuznetsov <vkuznets@redhat.com>
Message-Id: <20210126134816.1880136-15-vkuznets@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit fc08b628d7c96d9a6d6bca488c3fa9c92bee6cc8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/hyperv.c
#	arch/x86/kvm/hyperv.h
#	arch/x86/kvm/x86.c
diff --cc arch/x86/kvm/hyperv.c
index c5f77ef20cbd,7d2dae92d638..000000000000
--- a/arch/x86/kvm/hyperv.c
+++ b/arch/x86/kvm/hyperv.c
@@@ -833,8 -838,14 +833,11 @@@ void kvm_hv_vcpu_uninit(struct kvm_vcp
  	struct kvm_vcpu_hv *hv_vcpu = to_hv_vcpu(vcpu);
  	int i;
  
+ 	if (!hv_vcpu)
+ 		return;
+ 
  	for (i = 0; i < ARRAY_SIZE(hv_vcpu->stimer); i++)
  		stimer_cleanup(&hv_vcpu->stimer[i]);
 -
 -	kfree(hv_vcpu);
 -	vcpu->arch.hyperv = NULL;
  }
  
  bool kvm_hv_assist_page_enabled(struct kvm_vcpu *vcpu)
@@@ -879,28 -895,41 +882,50 @@@ static void stimer_init(struct kvm_vcpu
  	stimer_prepare_msg(stimer);
  }
  
++<<<<<<< HEAD
 +void kvm_hv_vcpu_init(struct kvm_vcpu *vcpu)
++=======
+ static int kvm_hv_vcpu_init(struct kvm_vcpu *vcpu)
++>>>>>>> fc08b628d7c9 (KVM: x86: hyper-v: Allocate Hyper-V context lazily)
  {
 -	struct kvm_vcpu_hv *hv_vcpu;
 +	struct kvm_vcpu_hv *hv_vcpu = to_hv_vcpu(vcpu);
  	int i;
  
 -	hv_vcpu = kzalloc(sizeof(struct kvm_vcpu_hv), GFP_KERNEL_ACCOUNT);
 -	if (!hv_vcpu)
 -		return -ENOMEM;
 -
 -	vcpu->arch.hyperv = hv_vcpu;
 -	hv_vcpu->vcpu = vcpu;
 -
  	synic_init(&hv_vcpu->synic);
  
  	bitmap_zero(hv_vcpu->stimer_pending_bitmap, HV_SYNIC_STIMER_COUNT);
  	for (i = 0; i < ARRAY_SIZE(hv_vcpu->stimer); i++)
  		stimer_init(&hv_vcpu->stimer[i], i);
++<<<<<<< HEAD
 +}
 +
 +void kvm_hv_vcpu_postcreate(struct kvm_vcpu *vcpu)
 +{
 +	struct kvm_vcpu_hv *hv_vcpu = to_hv_vcpu(vcpu);
++=======
++>>>>>>> fc08b628d7c9 (KVM: x86: hyper-v: Allocate Hyper-V context lazily)
  
  	hv_vcpu->vp_index = kvm_vcpu_get_idx(vcpu);
+ 
+ 	return 0;
  }
  
  int kvm_hv_activate_synic(struct kvm_vcpu *vcpu, bool dont_zero_synic_pages)
  {
++<<<<<<< HEAD
 +	struct kvm_vcpu_hv_synic *synic = vcpu_to_synic(vcpu);
++=======
+ 	struct kvm_vcpu_hv_synic *synic;
+ 	int r;
+ 
+ 	if (!to_hv_vcpu(vcpu)) {
+ 		r = kvm_hv_vcpu_init(vcpu);
+ 		if (r)
+ 			return r;
+ 	}
+ 
+ 	synic = to_hv_synic(vcpu);
++>>>>>>> fc08b628d7c9 (KVM: x86: hyper-v: Allocate Hyper-V context lazily)
  
  	/*
  	 * Hyper-V SynIC auto EOI SINT's are
@@@ -1508,6 -1483,14 +1533,17 @@@ int kvm_hv_set_msr_common(struct kvm_vc
  {
  	struct kvm_hv *hv = to_kvm_hv(vcpu->kvm);
  
++<<<<<<< HEAD
++=======
+ 	if (!host && !vcpu->arch.hyperv_enabled)
+ 		return 1;
+ 
+ 	if (!to_hv_vcpu(vcpu)) {
+ 		if (kvm_hv_vcpu_init(vcpu))
+ 			return 1;
+ 	}
+ 
++>>>>>>> fc08b628d7c9 (KVM: x86: hyper-v: Allocate Hyper-V context lazily)
  	if (kvm_hv_msr_partition_wide(msr)) {
  		int r;
  
@@@ -1523,6 -1506,14 +1559,17 @@@ int kvm_hv_get_msr_common(struct kvm_vc
  {
  	struct kvm_hv *hv = to_kvm_hv(vcpu->kvm);
  
++<<<<<<< HEAD
++=======
+ 	if (!host && !vcpu->arch.hyperv_enabled)
+ 		return 1;
+ 
+ 	if (!to_hv_vcpu(vcpu)) {
+ 		if (kvm_hv_vcpu_init(vcpu))
+ 			return 1;
+ 	}
+ 
++>>>>>>> fc08b628d7c9 (KVM: x86: hyper-v: Allocate Hyper-V context lazily)
  	if (kvm_hv_msr_partition_wide(msr)) {
  		int r;
  
diff --cc arch/x86/kvm/hyperv.h
index 69fb2e2ca018,4e0f886eb2a9..000000000000
--- a/arch/x86/kvm/hyperv.h
+++ b/arch/x86/kvm/hyperv.h
@@@ -94,8 -100,6 +94,11 @@@ int kvm_hv_synic_set_irq(struct kvm *kv
  void kvm_hv_synic_send_eoi(struct kvm_vcpu *vcpu, int vector);
  int kvm_hv_activate_synic(struct kvm_vcpu *vcpu, bool dont_zero_synic_pages);
  
++<<<<<<< HEAD
 +void kvm_hv_vcpu_init(struct kvm_vcpu *vcpu);
 +void kvm_hv_vcpu_postcreate(struct kvm_vcpu *vcpu);
++=======
++>>>>>>> fc08b628d7c9 (KVM: x86: hyper-v: Allocate Hyper-V context lazily)
  void kvm_hv_vcpu_uninit(struct kvm_vcpu *vcpu);
  
  bool kvm_hv_assist_page_enabled(struct kvm_vcpu *vcpu);
diff --cc arch/x86/kvm/x86.c
index 5b18614d5081,3fa140383f5d..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -9957,9 -10083,7 +9957,13 @@@ int kvm_arch_vcpu_create(struct kvm_vcp
  	vcpu->arch.pending_external_vector = -1;
  	vcpu->arch.preempted_in_kernel = false;
  
++<<<<<<< HEAD
 +	kvm_hv_vcpu_init(vcpu);
 +
 +	r = kvm_x86_ops.vcpu_create(vcpu);
++=======
+ 	r = static_call(kvm_x86_vcpu_create)(vcpu);
++>>>>>>> fc08b628d7c9 (KVM: x86: hyper-v: Allocate Hyper-V context lazily)
  	if (r)
  		goto free_guest_fpu;
  
* Unmerged path arch/x86/kvm/hyperv.c
* Unmerged path arch/x86/kvm/hyperv.h
* Unmerged path arch/x86/kvm/x86.c
