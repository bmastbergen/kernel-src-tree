drm/i915/gen12: Flush L3

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Mika Kuoppala <mika.kuoppala@linux.intel.com>
commit 0c7c0c8e6f09e0301e02266a0c83611d721adebb
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/0c7c0c8e.failed

Flush TDL,L3 and EUs

	Signed-off-by: Mika Kuoppala <mika.kuoppala@linux.intel.com>
	Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>
	Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
Link: https://patchwork.freedesktop.org/patch/msgid/20200506144734.29297-3-mika.kuoppala@linux.intel.com
(cherry picked from commit 0c7c0c8e6f09e0301e02266a0c83611d721adebb)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/i915/gt/intel_lrc.c
diff --cc drivers/gpu/drm/i915/gt/intel_lrc.c
index f2865f3cc1d5,e1235d504837..000000000000
--- a/drivers/gpu/drm/i915/gt/intel_lrc.c
+++ b/drivers/gpu/drm/i915/gt/intel_lrc.c
@@@ -2508,6 -4482,131 +2508,134 @@@ static int gen8_emit_flush_render(struc
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static int gen11_emit_flush_render(struct i915_request *request,
+ 				   u32 mode)
+ {
+ 	if (mode & EMIT_FLUSH) {
+ 		u32 *cs;
+ 		u32 flags = 0;
+ 
+ 		flags |= PIPE_CONTROL_CS_STALL;
+ 
+ 		flags |= PIPE_CONTROL_TILE_CACHE_FLUSH;
+ 		flags |= PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH;
+ 		flags |= PIPE_CONTROL_DEPTH_CACHE_FLUSH;
+ 		flags |= PIPE_CONTROL_DC_FLUSH_ENABLE;
+ 		flags |= PIPE_CONTROL_FLUSH_ENABLE;
+ 		flags |= PIPE_CONTROL_QW_WRITE;
+ 		flags |= PIPE_CONTROL_STORE_DATA_INDEX;
+ 
+ 		cs = intel_ring_begin(request, 6);
+ 		if (IS_ERR(cs))
+ 			return PTR_ERR(cs);
+ 
+ 		cs = gen8_emit_pipe_control(cs, flags, LRC_PPHWSP_SCRATCH_ADDR);
+ 		intel_ring_advance(request, cs);
+ 	}
+ 
+ 	if (mode & EMIT_INVALIDATE) {
+ 		u32 *cs;
+ 		u32 flags = 0;
+ 
+ 		flags |= PIPE_CONTROL_CS_STALL;
+ 
+ 		flags |= PIPE_CONTROL_COMMAND_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_TLB_INVALIDATE;
+ 		flags |= PIPE_CONTROL_INSTRUCTION_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_TEXTURE_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_VF_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_CONST_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_STATE_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_QW_WRITE;
+ 		flags |= PIPE_CONTROL_STORE_DATA_INDEX;
+ 
+ 		cs = intel_ring_begin(request, 6);
+ 		if (IS_ERR(cs))
+ 			return PTR_ERR(cs);
+ 
+ 		cs = gen8_emit_pipe_control(cs, flags, LRC_PPHWSP_SCRATCH_ADDR);
+ 		intel_ring_advance(request, cs);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static u32 preparser_disable(bool state)
+ {
+ 	return MI_ARB_CHECK | 1 << 8 | state;
+ }
+ 
+ static int gen12_emit_flush_render(struct i915_request *request,
+ 				   u32 mode)
+ {
+ 	if (mode & EMIT_FLUSH) {
+ 		u32 flags = 0;
+ 		u32 *cs;
+ 
+ 		flags |= PIPE_CONTROL_TILE_CACHE_FLUSH;
+ 		flags |= PIPE_CONTROL_FLUSH_L3;
+ 		flags |= PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH;
+ 		flags |= PIPE_CONTROL_DEPTH_CACHE_FLUSH;
+ 		/* Wa_1409600907:tgl */
+ 		flags |= PIPE_CONTROL_DEPTH_STALL;
+ 		flags |= PIPE_CONTROL_DC_FLUSH_ENABLE;
+ 		flags |= PIPE_CONTROL_FLUSH_ENABLE;
+ 
+ 		flags |= PIPE_CONTROL_STORE_DATA_INDEX;
+ 		flags |= PIPE_CONTROL_QW_WRITE;
+ 
+ 		flags |= PIPE_CONTROL_CS_STALL;
+ 
+ 		cs = intel_ring_begin(request, 6);
+ 		if (IS_ERR(cs))
+ 			return PTR_ERR(cs);
+ 
+ 		cs = gen12_emit_pipe_control(cs,
+ 					     PIPE_CONTROL0_HDC_PIPELINE_FLUSH,
+ 					     flags, LRC_PPHWSP_SCRATCH_ADDR);
+ 		intel_ring_advance(request, cs);
+ 	}
+ 
+ 	if (mode & EMIT_INVALIDATE) {
+ 		u32 flags = 0;
+ 		u32 *cs;
+ 
+ 		flags |= PIPE_CONTROL_COMMAND_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_TLB_INVALIDATE;
+ 		flags |= PIPE_CONTROL_INSTRUCTION_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_TEXTURE_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_VF_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_CONST_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_STATE_CACHE_INVALIDATE;
+ 
+ 		flags |= PIPE_CONTROL_STORE_DATA_INDEX;
+ 		flags |= PIPE_CONTROL_QW_WRITE;
+ 
+ 		flags |= PIPE_CONTROL_CS_STALL;
+ 
+ 		cs = intel_ring_begin(request, 8);
+ 		if (IS_ERR(cs))
+ 			return PTR_ERR(cs);
+ 
+ 		/*
+ 		 * Prevent the pre-parser from skipping past the TLB
+ 		 * invalidate and loading a stale page for the batch
+ 		 * buffer / request payload.
+ 		 */
+ 		*cs++ = preparser_disable(true);
+ 
+ 		cs = gen8_emit_pipe_control(cs, flags, LRC_PPHWSP_SCRATCH_ADDR);
+ 
+ 		*cs++ = preparser_disable(false);
+ 		intel_ring_advance(request, cs);
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 0c7c0c8e6f09 (drm/i915/gen12: Flush L3)
  /*
   * Reserve space for 2 NOOPs at the end of each request to be
   * used as a workaround for not being allowed to do lite
@@@ -2562,23 -4745,29 +2690,42 @@@ static u32 *gen8_emit_fini_breadcrumb_r
  	return gen8_emit_wa_tail(request, cs);
  }
  
 -static u32 *gen12_emit_fini_breadcrumb(struct i915_request *rq, u32 *cs)
 +static int gen8_init_rcs_context(struct i915_request *rq)
  {
 -	return gen12_emit_fini_breadcrumb_tail(rq, emit_xcs_breadcrumb(rq, cs));
 -}
 +	int ret;
  
++<<<<<<< HEAD
 +	ret = intel_engine_emit_ctx_wa(rq);
 +	if (ret)
 +		return ret;
++=======
+ static u32 *
+ gen12_emit_fini_breadcrumb_rcs(struct i915_request *request, u32 *cs)
+ {
+ 	cs = gen12_emit_ggtt_write_rcs(cs,
+ 				       request->fence.seqno,
+ 				       i915_request_active_timeline(request)->hwsp_offset,
+ 				       PIPE_CONTROL0_HDC_PIPELINE_FLUSH,
+ 				       PIPE_CONTROL_CS_STALL |
+ 				       PIPE_CONTROL_TILE_CACHE_FLUSH |
+ 				       PIPE_CONTROL_FLUSH_L3 |
+ 				       PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH |
+ 				       PIPE_CONTROL_DEPTH_CACHE_FLUSH |
+ 				       /* Wa_1409600907:tgl */
+ 				       PIPE_CONTROL_DEPTH_STALL |
+ 				       PIPE_CONTROL_DC_FLUSH_ENABLE |
+ 				       PIPE_CONTROL_FLUSH_ENABLE);
++>>>>>>> 0c7c0c8e6f09 (drm/i915/gen12: Flush L3)
 +
 +	ret = intel_rcs_context_init_mocs(rq);
 +	/*
 +	 * Failing to program the MOCS is non-fatal.The system will not
 +	 * run at peak performance. So generate an error and carry on.
 +	 */
 +	if (ret)
 +		DRM_ERROR("MOCS failed to program: expect performance issues.\n");
  
 -	return gen12_emit_fini_breadcrumb_tail(request, cs);
 +	return i915_gem_render_state_emit(rq);
  }
  
  static void execlists_park(struct intel_engine_cs *engine)
* Unmerged path drivers/gpu/drm/i915/gt/intel_lrc.c
