libbpf: Load btf_vmlinux only once per object.

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
Rebuild_CHGLOG: - [tools] libbpf: Load btf_vmlinux only once per object (Yauheni Kaliuta) [1813372]
Rebuild_FUZZ: 98.90%
commit-author KP Singh <kpsingh@google.com>
commit a6ed02cac690b635dbb938690e795812ce1e14ca
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/a6ed02ca.failed

As more programs (TRACING, STRUCT_OPS, and upcoming LSM) use vmlinux
BTF information, loading the BTF vmlinux information for every program
in an object is sub-optimal. The fix was originally proposed in:

   https://lore.kernel.org/bpf/CAEf4BzZodr3LKJuM7QwD38BiEH02Cc1UbtnGpVkCJ00Mf+V_Qg@mail.gmail.com/

The btf_vmlinux is populated in the object if any of the programs in
the object requires it just before the programs are loaded and freed
after the programs finish loading.

	Reported-by: Andrii Nakryiko <andrii.nakryiko@gmail.com>
	Signed-off-by: KP Singh <kpsingh@google.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Reviewed-by: Brendan Jackman <jackmanb@chromium.org>
	Acked-by: Andrii Nakryiko <andriin@fb.com>
Link: https://lore.kernel.org/bpf/20200117212825.11755-1-kpsingh@chromium.org
(cherry picked from commit a6ed02cac690b635dbb938690e795812ce1e14ca)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/lib/bpf/libbpf.c
diff --cc tools/lib/bpf/libbpf.c
index 6ed9ef84b398,faab96a42141..000000000000
--- a/tools/lib/bpf/libbpf.c
+++ b/tools/lib/bpf/libbpf.c
@@@ -534,6 -607,348 +538,351 @@@ static __u32 get_kernel_version(void
  	return KERNEL_VERSION(major, minor, patch);
  }
  
++<<<<<<< HEAD
++=======
+ static const struct btf_member *
+ find_member_by_offset(const struct btf_type *t, __u32 bit_offset)
+ {
+ 	struct btf_member *m;
+ 	int i;
+ 
+ 	for (i = 0, m = btf_members(t); i < btf_vlen(t); i++, m++) {
+ 		if (btf_member_bit_offset(t, i) == bit_offset)
+ 			return m;
+ 	}
+ 
+ 	return NULL;
+ }
+ 
+ static const struct btf_member *
+ find_member_by_name(const struct btf *btf, const struct btf_type *t,
+ 		    const char *name)
+ {
+ 	struct btf_member *m;
+ 	int i;
+ 
+ 	for (i = 0, m = btf_members(t); i < btf_vlen(t); i++, m++) {
+ 		if (!strcmp(btf__name_by_offset(btf, m->name_off), name))
+ 			return m;
+ 	}
+ 
+ 	return NULL;
+ }
+ 
+ #define STRUCT_OPS_VALUE_PREFIX "bpf_struct_ops_"
+ static int find_btf_by_prefix_kind(const struct btf *btf, const char *prefix,
+ 				   const char *name, __u32 kind);
+ 
+ static int
+ find_struct_ops_kern_types(const struct btf *btf, const char *tname,
+ 			   const struct btf_type **type, __u32 *type_id,
+ 			   const struct btf_type **vtype, __u32 *vtype_id,
+ 			   const struct btf_member **data_member)
+ {
+ 	const struct btf_type *kern_type, *kern_vtype;
+ 	const struct btf_member *kern_data_member;
+ 	__s32 kern_vtype_id, kern_type_id;
+ 	__u32 i;
+ 
+ 	kern_type_id = btf__find_by_name_kind(btf, tname, BTF_KIND_STRUCT);
+ 	if (kern_type_id < 0) {
+ 		pr_warn("struct_ops init_kern: struct %s is not found in kernel BTF\n",
+ 			tname);
+ 		return kern_type_id;
+ 	}
+ 	kern_type = btf__type_by_id(btf, kern_type_id);
+ 
+ 	/* Find the corresponding "map_value" type that will be used
+ 	 * in map_update(BPF_MAP_TYPE_STRUCT_OPS).  For example,
+ 	 * find "struct bpf_struct_ops_tcp_congestion_ops" from the
+ 	 * btf_vmlinux.
+ 	 */
+ 	kern_vtype_id = find_btf_by_prefix_kind(btf, STRUCT_OPS_VALUE_PREFIX,
+ 						tname, BTF_KIND_STRUCT);
+ 	if (kern_vtype_id < 0) {
+ 		pr_warn("struct_ops init_kern: struct %s%s is not found in kernel BTF\n",
+ 			STRUCT_OPS_VALUE_PREFIX, tname);
+ 		return kern_vtype_id;
+ 	}
+ 	kern_vtype = btf__type_by_id(btf, kern_vtype_id);
+ 
+ 	/* Find "struct tcp_congestion_ops" from
+ 	 * struct bpf_struct_ops_tcp_congestion_ops {
+ 	 *	[ ... ]
+ 	 *	struct tcp_congestion_ops data;
+ 	 * }
+ 	 */
+ 	kern_data_member = btf_members(kern_vtype);
+ 	for (i = 0; i < btf_vlen(kern_vtype); i++, kern_data_member++) {
+ 		if (kern_data_member->type == kern_type_id)
+ 			break;
+ 	}
+ 	if (i == btf_vlen(kern_vtype)) {
+ 		pr_warn("struct_ops init_kern: struct %s data is not found in struct %s%s\n",
+ 			tname, STRUCT_OPS_VALUE_PREFIX, tname);
+ 		return -EINVAL;
+ 	}
+ 
+ 	*type = kern_type;
+ 	*type_id = kern_type_id;
+ 	*vtype = kern_vtype;
+ 	*vtype_id = kern_vtype_id;
+ 	*data_member = kern_data_member;
+ 
+ 	return 0;
+ }
+ 
+ static bool bpf_map__is_struct_ops(const struct bpf_map *map)
+ {
+ 	return map->def.type == BPF_MAP_TYPE_STRUCT_OPS;
+ }
+ 
+ /* Init the map's fields that depend on kern_btf */
+ static int bpf_map__init_kern_struct_ops(struct bpf_map *map,
+ 					 const struct btf *btf,
+ 					 const struct btf *kern_btf)
+ {
+ 	const struct btf_member *member, *kern_member, *kern_data_member;
+ 	const struct btf_type *type, *kern_type, *kern_vtype;
+ 	__u32 i, kern_type_id, kern_vtype_id, kern_data_off;
+ 	struct bpf_struct_ops *st_ops;
+ 	void *data, *kern_data;
+ 	const char *tname;
+ 	int err;
+ 
+ 	st_ops = map->st_ops;
+ 	type = st_ops->type;
+ 	tname = st_ops->tname;
+ 	err = find_struct_ops_kern_types(kern_btf, tname,
+ 					 &kern_type, &kern_type_id,
+ 					 &kern_vtype, &kern_vtype_id,
+ 					 &kern_data_member);
+ 	if (err)
+ 		return err;
+ 
+ 	pr_debug("struct_ops init_kern %s: type_id:%u kern_type_id:%u kern_vtype_id:%u\n",
+ 		 map->name, st_ops->type_id, kern_type_id, kern_vtype_id);
+ 
+ 	map->def.value_size = kern_vtype->size;
+ 	map->btf_vmlinux_value_type_id = kern_vtype_id;
+ 
+ 	st_ops->kern_vdata = calloc(1, kern_vtype->size);
+ 	if (!st_ops->kern_vdata)
+ 		return -ENOMEM;
+ 
+ 	data = st_ops->data;
+ 	kern_data_off = kern_data_member->offset / 8;
+ 	kern_data = st_ops->kern_vdata + kern_data_off;
+ 
+ 	member = btf_members(type);
+ 	for (i = 0; i < btf_vlen(type); i++, member++) {
+ 		const struct btf_type *mtype, *kern_mtype;
+ 		__u32 mtype_id, kern_mtype_id;
+ 		void *mdata, *kern_mdata;
+ 		__s64 msize, kern_msize;
+ 		__u32 moff, kern_moff;
+ 		__u32 kern_member_idx;
+ 		const char *mname;
+ 
+ 		mname = btf__name_by_offset(btf, member->name_off);
+ 		kern_member = find_member_by_name(kern_btf, kern_type, mname);
+ 		if (!kern_member) {
+ 			pr_warn("struct_ops init_kern %s: Cannot find member %s in kernel BTF\n",
+ 				map->name, mname);
+ 			return -ENOTSUP;
+ 		}
+ 
+ 		kern_member_idx = kern_member - btf_members(kern_type);
+ 		if (btf_member_bitfield_size(type, i) ||
+ 		    btf_member_bitfield_size(kern_type, kern_member_idx)) {
+ 			pr_warn("struct_ops init_kern %s: bitfield %s is not supported\n",
+ 				map->name, mname);
+ 			return -ENOTSUP;
+ 		}
+ 
+ 		moff = member->offset / 8;
+ 		kern_moff = kern_member->offset / 8;
+ 
+ 		mdata = data + moff;
+ 		kern_mdata = kern_data + kern_moff;
+ 
+ 		mtype = skip_mods_and_typedefs(btf, member->type, &mtype_id);
+ 		kern_mtype = skip_mods_and_typedefs(kern_btf, kern_member->type,
+ 						    &kern_mtype_id);
+ 		if (BTF_INFO_KIND(mtype->info) !=
+ 		    BTF_INFO_KIND(kern_mtype->info)) {
+ 			pr_warn("struct_ops init_kern %s: Unmatched member type %s %u != %u(kernel)\n",
+ 				map->name, mname, BTF_INFO_KIND(mtype->info),
+ 				BTF_INFO_KIND(kern_mtype->info));
+ 			return -ENOTSUP;
+ 		}
+ 
+ 		if (btf_is_ptr(mtype)) {
+ 			struct bpf_program *prog;
+ 
+ 			mtype = skip_mods_and_typedefs(btf, mtype->type, &mtype_id);
+ 			kern_mtype = skip_mods_and_typedefs(kern_btf,
+ 							    kern_mtype->type,
+ 							    &kern_mtype_id);
+ 			if (!btf_is_func_proto(mtype) ||
+ 			    !btf_is_func_proto(kern_mtype)) {
+ 				pr_warn("struct_ops init_kern %s: non func ptr %s is not supported\n",
+ 					map->name, mname);
+ 				return -ENOTSUP;
+ 			}
+ 
+ 			prog = st_ops->progs[i];
+ 			if (!prog) {
+ 				pr_debug("struct_ops init_kern %s: func ptr %s is not set\n",
+ 					 map->name, mname);
+ 				continue;
+ 			}
+ 
+ 			prog->attach_btf_id = kern_type_id;
+ 			prog->expected_attach_type = kern_member_idx;
+ 
+ 			st_ops->kern_func_off[i] = kern_data_off + kern_moff;
+ 
+ 			pr_debug("struct_ops init_kern %s: func ptr %s is set to prog %s from data(+%u) to kern_data(+%u)\n",
+ 				 map->name, mname, prog->name, moff,
+ 				 kern_moff);
+ 
+ 			continue;
+ 		}
+ 
+ 		msize = btf__resolve_size(btf, mtype_id);
+ 		kern_msize = btf__resolve_size(kern_btf, kern_mtype_id);
+ 		if (msize < 0 || kern_msize < 0 || msize != kern_msize) {
+ 			pr_warn("struct_ops init_kern %s: Error in size of member %s: %zd != %zd(kernel)\n",
+ 				map->name, mname, (ssize_t)msize,
+ 				(ssize_t)kern_msize);
+ 			return -ENOTSUP;
+ 		}
+ 
+ 		pr_debug("struct_ops init_kern %s: copy %s %u bytes from data(+%u) to kern_data(+%u)\n",
+ 			 map->name, mname, (unsigned int)msize,
+ 			 moff, kern_moff);
+ 		memcpy(kern_mdata, mdata, msize);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int bpf_object__init_kern_struct_ops_maps(struct bpf_object *obj)
+ {
+ 	struct bpf_map *map;
+ 	size_t i;
+ 	int err;
+ 
+ 	for (i = 0; i < obj->nr_maps; i++) {
+ 		map = &obj->maps[i];
+ 
+ 		if (!bpf_map__is_struct_ops(map))
+ 			continue;
+ 
+ 		err = bpf_map__init_kern_struct_ops(map, obj->btf,
+ 						    obj->btf_vmlinux);
+ 		if (err)
+ 			return err;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int bpf_object__init_struct_ops_maps(struct bpf_object *obj)
+ {
+ 	const struct btf_type *type, *datasec;
+ 	const struct btf_var_secinfo *vsi;
+ 	struct bpf_struct_ops *st_ops;
+ 	const char *tname, *var_name;
+ 	__s32 type_id, datasec_id;
+ 	const struct btf *btf;
+ 	struct bpf_map *map;
+ 	__u32 i;
+ 
+ 	if (obj->efile.st_ops_shndx == -1)
+ 		return 0;
+ 
+ 	btf = obj->btf;
+ 	datasec_id = btf__find_by_name_kind(btf, STRUCT_OPS_SEC,
+ 					    BTF_KIND_DATASEC);
+ 	if (datasec_id < 0) {
+ 		pr_warn("struct_ops init: DATASEC %s not found\n",
+ 			STRUCT_OPS_SEC);
+ 		return -EINVAL;
+ 	}
+ 
+ 	datasec = btf__type_by_id(btf, datasec_id);
+ 	vsi = btf_var_secinfos(datasec);
+ 	for (i = 0; i < btf_vlen(datasec); i++, vsi++) {
+ 		type = btf__type_by_id(obj->btf, vsi->type);
+ 		var_name = btf__name_by_offset(obj->btf, type->name_off);
+ 
+ 		type_id = btf__resolve_type(obj->btf, vsi->type);
+ 		if (type_id < 0) {
+ 			pr_warn("struct_ops init: Cannot resolve var type_id %u in DATASEC %s\n",
+ 				vsi->type, STRUCT_OPS_SEC);
+ 			return -EINVAL;
+ 		}
+ 
+ 		type = btf__type_by_id(obj->btf, type_id);
+ 		tname = btf__name_by_offset(obj->btf, type->name_off);
+ 		if (!tname[0]) {
+ 			pr_warn("struct_ops init: anonymous type is not supported\n");
+ 			return -ENOTSUP;
+ 		}
+ 		if (!btf_is_struct(type)) {
+ 			pr_warn("struct_ops init: %s is not a struct\n", tname);
+ 			return -EINVAL;
+ 		}
+ 
+ 		map = bpf_object__add_map(obj);
+ 		if (IS_ERR(map))
+ 			return PTR_ERR(map);
+ 
+ 		map->sec_idx = obj->efile.st_ops_shndx;
+ 		map->sec_offset = vsi->offset;
+ 		map->name = strdup(var_name);
+ 		if (!map->name)
+ 			return -ENOMEM;
+ 
+ 		map->def.type = BPF_MAP_TYPE_STRUCT_OPS;
+ 		map->def.key_size = sizeof(int);
+ 		map->def.value_size = type->size;
+ 		map->def.max_entries = 1;
+ 
+ 		map->st_ops = calloc(1, sizeof(*map->st_ops));
+ 		if (!map->st_ops)
+ 			return -ENOMEM;
+ 		st_ops = map->st_ops;
+ 		st_ops->data = malloc(type->size);
+ 		st_ops->progs = calloc(btf_vlen(type), sizeof(*st_ops->progs));
+ 		st_ops->kern_func_off = malloc(btf_vlen(type) *
+ 					       sizeof(*st_ops->kern_func_off));
+ 		if (!st_ops->data || !st_ops->progs || !st_ops->kern_func_off)
+ 			return -ENOMEM;
+ 
+ 		if (vsi->offset + type->size > obj->efile.st_ops_data->d_size) {
+ 			pr_warn("struct_ops init: var %s is beyond the end of DATASEC %s\n",
+ 				var_name, STRUCT_OPS_SEC);
+ 			return -EINVAL;
+ 		}
+ 
+ 		memcpy(st_ops->data,
+ 		       obj->efile.st_ops_data->d_buf + vsi->offset,
+ 		       type->size);
+ 		st_ops->tname = tname;
+ 		st_ops->type = type;
+ 		st_ops->type_id = type_id;
+ 
+ 		pr_debug("struct_ops init: struct %s(type_id=%u) %s found at offset %u\n",
+ 			 tname, type_id, var_name, vsi->offset);
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> a6ed02cac690 (libbpf: Load btf_vmlinux only once per object.)
  static struct bpf_object *bpf_object__new(const char *path,
  					  const void *obj_buf,
  					  size_t obj_buf_sz,
@@@ -3889,11 -4912,18 +4273,26 @@@ out
  	return ret;
  }
  
++<<<<<<< HEAD
 +int
 +bpf_program__load(struct bpf_program *prog,
 +		  char *license, __u32 kern_version)
 +{
 +	int err = 0, fd, i;
++=======
+ static int libbpf_find_attach_btf_id(struct bpf_program *prog);
+ 
+ int bpf_program__load(struct bpf_program *prog, char *license, __u32 kern_ver)
+ {
+ 	int err = 0, fd, i, btf_id;
+ 
+ 	if (prog->type == BPF_PROG_TYPE_TRACING) {
+ 		btf_id = libbpf_find_attach_btf_id(prog);
+ 		if (btf_id <= 0)
+ 			return btf_id;
+ 		prog->attach_btf_id = btf_id;
+ 	}
++>>>>>>> a6ed02cac690 (libbpf: Load btf_vmlinux only once per object.)
  
  	if (prog->instances.nr < 0 || !prog->instances.fds) {
  		if (prog->preprocessor) {
@@@ -4165,9 -5293,21 +4564,27 @@@ int bpf_object__load_xattr(struct bpf_o
  
  	obj->loaded = true;
  
++<<<<<<< HEAD
 +	CHECK_ERR(bpf_object__create_maps(obj), err, out);
 +	CHECK_ERR(bpf_object__relocate(obj, attr->target_btf_path), err, out);
 +	CHECK_ERR(bpf_object__load_progs(obj, attr->log_level), err, out);
++=======
+ 	err = bpf_object__probe_caps(obj);
+ 	err = err ? : bpf_object__resolve_externs(obj, obj->kconfig);
+ 	err = err ? : bpf_object__sanitize_and_load_btf(obj);
+ 	err = err ? : bpf_object__sanitize_maps(obj);
+ 	err = err ? : bpf_object__load_vmlinux_btf(obj);
+ 	err = err ? : bpf_object__init_kern_struct_ops_maps(obj);
+ 	err = err ? : bpf_object__create_maps(obj);
+ 	err = err ? : bpf_object__relocate(obj, attr->target_btf_path);
+ 	err = err ? : bpf_object__load_progs(obj, attr->log_level);
+ 
+ 	btf__free(obj->btf_vmlinux);
+ 	obj->btf_vmlinux = NULL;
+ 
+ 	if (err)
+ 		goto out;
++>>>>>>> a6ed02cac690 (libbpf: Load btf_vmlinux only once per object.)
  
  	return 0;
  out:
@@@ -5202,6 -6396,247 +5619,250 @@@ int libbpf_prog_type_by_name(const cha
  	return -ESRCH;
  }
  
++<<<<<<< HEAD
++=======
+ static struct bpf_map *find_struct_ops_map_by_offset(struct bpf_object *obj,
+ 						     size_t offset)
+ {
+ 	struct bpf_map *map;
+ 	size_t i;
+ 
+ 	for (i = 0; i < obj->nr_maps; i++) {
+ 		map = &obj->maps[i];
+ 		if (!bpf_map__is_struct_ops(map))
+ 			continue;
+ 		if (map->sec_offset <= offset &&
+ 		    offset - map->sec_offset < map->def.value_size)
+ 			return map;
+ 	}
+ 
+ 	return NULL;
+ }
+ 
+ /* Collect the reloc from ELF and populate the st_ops->progs[] */
+ static int bpf_object__collect_struct_ops_map_reloc(struct bpf_object *obj,
+ 						    GElf_Shdr *shdr,
+ 						    Elf_Data *data)
+ {
+ 	const struct btf_member *member;
+ 	struct bpf_struct_ops *st_ops;
+ 	struct bpf_program *prog;
+ 	unsigned int shdr_idx;
+ 	const struct btf *btf;
+ 	struct bpf_map *map;
+ 	Elf_Data *symbols;
+ 	unsigned int moff;
+ 	const char *name;
+ 	__u32 member_idx;
+ 	GElf_Sym sym;
+ 	GElf_Rel rel;
+ 	int i, nrels;
+ 
+ 	symbols = obj->efile.symbols;
+ 	btf = obj->btf;
+ 	nrels = shdr->sh_size / shdr->sh_entsize;
+ 	for (i = 0; i < nrels; i++) {
+ 		if (!gelf_getrel(data, i, &rel)) {
+ 			pr_warn("struct_ops reloc: failed to get %d reloc\n", i);
+ 			return -LIBBPF_ERRNO__FORMAT;
+ 		}
+ 
+ 		if (!gelf_getsym(symbols, GELF_R_SYM(rel.r_info), &sym)) {
+ 			pr_warn("struct_ops reloc: symbol %zx not found\n",
+ 				(size_t)GELF_R_SYM(rel.r_info));
+ 			return -LIBBPF_ERRNO__FORMAT;
+ 		}
+ 
+ 		name = elf_strptr(obj->efile.elf, obj->efile.strtabidx,
+ 				  sym.st_name) ? : "<?>";
+ 		map = find_struct_ops_map_by_offset(obj, rel.r_offset);
+ 		if (!map) {
+ 			pr_warn("struct_ops reloc: cannot find map at rel.r_offset %zu\n",
+ 				(size_t)rel.r_offset);
+ 			return -EINVAL;
+ 		}
+ 
+ 		moff = rel.r_offset - map->sec_offset;
+ 		shdr_idx = sym.st_shndx;
+ 		st_ops = map->st_ops;
+ 		pr_debug("struct_ops reloc %s: for %lld value %lld shdr_idx %u rel.r_offset %zu map->sec_offset %zu name %d (\'%s\')\n",
+ 			 map->name,
+ 			 (long long)(rel.r_info >> 32),
+ 			 (long long)sym.st_value,
+ 			 shdr_idx, (size_t)rel.r_offset,
+ 			 map->sec_offset, sym.st_name, name);
+ 
+ 		if (shdr_idx >= SHN_LORESERVE) {
+ 			pr_warn("struct_ops reloc %s: rel.r_offset %zu shdr_idx %u unsupported non-static function\n",
+ 				map->name, (size_t)rel.r_offset, shdr_idx);
+ 			return -LIBBPF_ERRNO__RELOC;
+ 		}
+ 
+ 		member = find_member_by_offset(st_ops->type, moff * 8);
+ 		if (!member) {
+ 			pr_warn("struct_ops reloc %s: cannot find member at moff %u\n",
+ 				map->name, moff);
+ 			return -EINVAL;
+ 		}
+ 		member_idx = member - btf_members(st_ops->type);
+ 		name = btf__name_by_offset(btf, member->name_off);
+ 
+ 		if (!resolve_func_ptr(btf, member->type, NULL)) {
+ 			pr_warn("struct_ops reloc %s: cannot relocate non func ptr %s\n",
+ 				map->name, name);
+ 			return -EINVAL;
+ 		}
+ 
+ 		prog = bpf_object__find_prog_by_idx(obj, shdr_idx);
+ 		if (!prog) {
+ 			pr_warn("struct_ops reloc %s: cannot find prog at shdr_idx %u to relocate func ptr %s\n",
+ 				map->name, shdr_idx, name);
+ 			return -EINVAL;
+ 		}
+ 
+ 		if (prog->type == BPF_PROG_TYPE_UNSPEC) {
+ 			const struct bpf_sec_def *sec_def;
+ 
+ 			sec_def = find_sec_def(prog->section_name);
+ 			if (sec_def &&
+ 			    sec_def->prog_type != BPF_PROG_TYPE_STRUCT_OPS) {
+ 				/* for pr_warn */
+ 				prog->type = sec_def->prog_type;
+ 				goto invalid_prog;
+ 			}
+ 
+ 			prog->type = BPF_PROG_TYPE_STRUCT_OPS;
+ 			prog->attach_btf_id = st_ops->type_id;
+ 			prog->expected_attach_type = member_idx;
+ 		} else if (prog->type != BPF_PROG_TYPE_STRUCT_OPS ||
+ 			   prog->attach_btf_id != st_ops->type_id ||
+ 			   prog->expected_attach_type != member_idx) {
+ 			goto invalid_prog;
+ 		}
+ 		st_ops->progs[member_idx] = prog;
+ 	}
+ 
+ 	return 0;
+ 
+ invalid_prog:
+ 	pr_warn("struct_ops reloc %s: cannot use prog %s in sec %s with type %u attach_btf_id %u expected_attach_type %u for func ptr %s\n",
+ 		map->name, prog->name, prog->section_name, prog->type,
+ 		prog->attach_btf_id, prog->expected_attach_type, name);
+ 	return -EINVAL;
+ }
+ 
+ #define BTF_TRACE_PREFIX "btf_trace_"
+ #define BTF_MAX_NAME_SIZE 128
+ 
+ static int find_btf_by_prefix_kind(const struct btf *btf, const char *prefix,
+ 				   const char *name, __u32 kind)
+ {
+ 	char btf_type_name[BTF_MAX_NAME_SIZE];
+ 	int ret;
+ 
+ 	ret = snprintf(btf_type_name, sizeof(btf_type_name),
+ 		       "%s%s", prefix, name);
+ 	/* snprintf returns the number of characters written excluding the
+ 	 * the terminating null. So, if >= BTF_MAX_NAME_SIZE are written, it
+ 	 * indicates truncation.
+ 	 */
+ 	if (ret < 0 || ret >= sizeof(btf_type_name))
+ 		return -ENAMETOOLONG;
+ 	return btf__find_by_name_kind(btf, btf_type_name, kind);
+ }
+ 
+ static inline int __find_vmlinux_btf_id(struct btf *btf, const char *name,
+ 					enum bpf_attach_type attach_type)
+ {
+ 	int err;
+ 
+ 	if (attach_type == BPF_TRACE_RAW_TP)
+ 		err = find_btf_by_prefix_kind(btf, BTF_TRACE_PREFIX, name,
+ 					      BTF_KIND_TYPEDEF);
+ 	else
+ 		err = btf__find_by_name_kind(btf, name, BTF_KIND_FUNC);
+ 
+ 	return err;
+ }
+ 
+ int libbpf_find_vmlinux_btf_id(const char *name,
+ 			       enum bpf_attach_type attach_type)
+ {
+ 	struct btf *btf;
+ 
+ 	btf = libbpf_find_kernel_btf();
+ 	if (IS_ERR(btf)) {
+ 		pr_warn("vmlinux BTF is not found\n");
+ 		return -EINVAL;
+ 	}
+ 
+ 	return __find_vmlinux_btf_id(btf, name, attach_type);
+ }
+ 
+ static int libbpf_find_prog_btf_id(const char *name, __u32 attach_prog_fd)
+ {
+ 	struct bpf_prog_info_linear *info_linear;
+ 	struct bpf_prog_info *info;
+ 	struct btf *btf = NULL;
+ 	int err = -EINVAL;
+ 
+ 	info_linear = bpf_program__get_prog_info_linear(attach_prog_fd, 0);
+ 	if (IS_ERR_OR_NULL(info_linear)) {
+ 		pr_warn("failed get_prog_info_linear for FD %d\n",
+ 			attach_prog_fd);
+ 		return -EINVAL;
+ 	}
+ 	info = &info_linear->info;
+ 	if (!info->btf_id) {
+ 		pr_warn("The target program doesn't have BTF\n");
+ 		goto out;
+ 	}
+ 	if (btf__get_from_id(info->btf_id, &btf)) {
+ 		pr_warn("Failed to get BTF of the program\n");
+ 		goto out;
+ 	}
+ 	err = btf__find_by_name_kind(btf, name, BTF_KIND_FUNC);
+ 	btf__free(btf);
+ 	if (err <= 0) {
+ 		pr_warn("%s is not found in prog's BTF\n", name);
+ 		goto out;
+ 	}
+ out:
+ 	free(info_linear);
+ 	return err;
+ }
+ 
+ static int libbpf_find_attach_btf_id(struct bpf_program *prog)
+ {
+ 	enum bpf_attach_type attach_type = prog->expected_attach_type;
+ 	__u32 attach_prog_fd = prog->attach_prog_fd;
+ 	const char *name = prog->section_name;
+ 	int i, err;
+ 
+ 	if (!name)
+ 		return -EINVAL;
+ 
+ 	for (i = 0; i < ARRAY_SIZE(section_defs); i++) {
+ 		if (!section_defs[i].is_attach_btf)
+ 			continue;
+ 		if (strncmp(name, section_defs[i].sec, section_defs[i].len))
+ 			continue;
+ 		if (attach_prog_fd)
+ 			err = libbpf_find_prog_btf_id(name + section_defs[i].len,
+ 						      attach_prog_fd);
+ 		else
+ 			err = __find_vmlinux_btf_id(prog->obj->btf_vmlinux,
+ 						    name + section_defs[i].len,
+ 						    attach_type);
+ 		if (err <= 0)
+ 			pr_warn("%s is not found in vmlinux BTF\n", name);
+ 		return err;
+ 	}
+ 	pr_warn("failed to identify btf_id based on ELF section name '%s'\n", name);
+ 	return -ESRCH;
+ }
+ 
++>>>>>>> a6ed02cac690 (libbpf: Load btf_vmlinux only once per object.)
  int libbpf_attach_type_by_name(const char *name,
  			       enum bpf_attach_type *attach_type)
  {
* Unmerged path tools/lib/bpf/libbpf.c
