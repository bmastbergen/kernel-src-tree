io_uring: Fix broken links with offloading

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Pavel Begunkov <asml.silence@gmail.com>
commit fb5ccc98782f654778cb8d96ba8a998304f9a51f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/fb5ccc98.failed

io_sq_thread() processes sqes by 8 without considering links. As a
result, links will be randomely subdivided.

The easiest way to fix it is to call io_get_sqring() inside
io_submit_sqes() as do io_ring_submit().

Downsides:
1. This removes optimisation of not grabbing mm_struct for fixed files
2. It submitting all sqes in one go, without finer-grained sheduling
with cq processing.

	Signed-off-by: Pavel Begunkov <asml.silence@gmail.com>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit fb5ccc98782f654778cb8d96ba8a998304f9a51f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/io_uring.c
diff --cc fs/io_uring.c
index 650dd06affd5,949c82a40d16..000000000000
--- a/fs/io_uring.c
+++ b/fs/io_uring.c
@@@ -700,9 -732,17 +700,17 @@@ static unsigned io_cqring_events(struc
  {
  	/* See comment at the top of this file */
  	smp_rmb();
 -	return READ_ONCE(rings->cq.tail) - READ_ONCE(rings->cq.head);
 +	return READ_ONCE(ring->r.tail) - READ_ONCE(ring->r.head);
  }
  
+ static inline unsigned int io_sqring_entries(struct io_ring_ctx *ctx)
+ {
+ 	struct io_rings *rings = ctx->rings;
+ 
+ 	/* make sure SQ entry isn't read before tail */
+ 	return smp_load_acquire(&rings->sq.tail) - ctx->cached_sq_head;
+ }
+ 
  /*
   * Find and free completed poll iocbs
   */
@@@ -2440,13 -2612,13 +2453,20 @@@ static int io_submit_sqes(struct io_rin
  
  out:
  		if (unlikely(mm_fault)) {
- 			io_cqring_add_event(ctx, sqes[i].sqe->user_data,
+ 			io_cqring_add_event(ctx, s.sqe->user_data,
  						-EFAULT);
  		} else {
++<<<<<<< HEAD
 +			sqes[i].has_user = has_user;
 +			sqes[i].needs_lock = true;
 +			sqes[i].needs_fixed_file = true;
 +			io_submit_sqe(ctx, &sqes[i], statep, &link, true);
++=======
+ 			s.has_user = has_user;
+ 			s.needs_lock = true;
+ 			s.needs_fixed_file = true;
+ 			io_submit_sqe(ctx, &s, statep, &link);
++>>>>>>> fb5ccc98782f (io_uring: Fix broken links with offloading)
  			submitted++;
  		}
  	}
@@@ -2543,22 -2716,11 +2564,11 @@@ static int io_sq_thread(void *data
  			}
  			finish_wait(&ctx->sqo_wait, &wait);
  
 -			ctx->rings->sq_flags &= ~IORING_SQ_NEED_WAKEUP;
 +			ctx->sq_ring->flags &= ~IORING_SQ_NEED_WAKEUP;
  		}
  
- 		i = 0;
- 		all_fixed = true;
- 		do {
- 			if (all_fixed && io_sqe_needs_user(sqes[i].sqe))
- 				all_fixed = false;
- 
- 			i++;
- 			if (i == ARRAY_SIZE(sqes))
- 				break;
- 		} while (io_get_sqring(ctx, &sqes[i]));
- 
  		/* Unless all new commands are FIXED regions, grab mm */
- 		if (!all_fixed && !cur_mm) {
+ 		if (!cur_mm) {
  			mm_fault = !mmget_not_zero(ctx->sqo_mm);
  			if (!mm_fault) {
  				use_mm(ctx->sqo_mm);
* Unmerged path fs/io_uring.c
