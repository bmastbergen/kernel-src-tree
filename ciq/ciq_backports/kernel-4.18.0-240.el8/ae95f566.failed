KVM: X86: TSCDEADLINE MSR emulation fastpath

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Wanpeng Li <wanpengli@tencent.com>
commit ae95f566b3d22ade75c67827f1171594dacc9a03
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/ae95f566.failed

This patch implements a fast path for emulation of writes to the TSCDEADLINE
MSR.  Besides shortcutting various housekeeping tasks in the vCPU loop,
the fast path can also deliver the timer interrupt directly without going
through KVM_REQ_PENDING_TIMER because it runs in vCPU context.

	Tested-by: Haiwei Li <lihaiwei@tencent.com>
	Cc: Haiwei Li <lihaiwei@tencent.com>
	Signed-off-by: Wanpeng Li <wanpengli@tencent.com>
Message-Id: <1588055009-12677-7-git-send-email-wanpengli@tencent.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit ae95f566b3d22ade75c67827f1171594dacc9a03)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/x86.c
diff --cc arch/x86/kvm/x86.c
index d6e03d86e3b9,7fb7c1a8f1a5..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -1606,7 -1608,16 +1606,20 @@@ static int handle_fastpath_set_x2apic_i
  	return 1;
  }
  
++<<<<<<< HEAD
 +enum exit_fastpath_completion handle_fastpath_set_msr_irqoff(struct kvm_vcpu *vcpu)
++=======
+ static int handle_fastpath_set_tscdeadline(struct kvm_vcpu *vcpu, u64 data)
+ {
+ 	if (!kvm_can_use_hv_timer(vcpu))
+ 		return 1;
+ 
+ 	kvm_set_lapic_tscdeadline_msr(vcpu, data);
+ 	return 0;
+ }
+ 
+ fastpath_t handle_fastpath_set_msr_irqoff(struct kvm_vcpu *vcpu)
++>>>>>>> ae95f566b3d2 (KVM: X86: TSCDEADLINE MSR emulation fastpath)
  {
  	u32 msr = kvm_rcx_read(vcpu);
  	u64 data;
@@@ -1615,18 -1626,26 +1628,25 @@@
  	switch (msr) {
  	case APIC_BASE_MSR + (APIC_ICR >> 4):
  		data = kvm_read_edx_eax(vcpu);
 -		if (!handle_fastpath_set_x2apic_icr_irqoff(vcpu, data)) {
 -			kvm_skip_emulated_instruction(vcpu);
 -			ret = EXIT_FASTPATH_EXIT_HANDLED;
 -               }
 +		ret = handle_fastpath_set_x2apic_icr_irqoff(vcpu, data);
  		break;
+ 	case MSR_IA32_TSCDEADLINE:
+ 		data = kvm_read_edx_eax(vcpu);
+ 		if (!handle_fastpath_set_tscdeadline(vcpu, data)) {
+ 			kvm_skip_emulated_instruction(vcpu);
+ 			ret = EXIT_FASTPATH_REENTER_GUEST;
+ 		}
+ 		break;
  	default:
 -		break;
 +		return EXIT_FASTPATH_NONE;
  	}
  
 -	if (ret != EXIT_FASTPATH_NONE)
 +	if (!ret) {
  		trace_kvm_msr_write(msr, data);
 +		return EXIT_FASTPATH_SKIP_EMUL_INS;
 +	}
  
 -	return ret;
 +	return EXIT_FASTPATH_NONE;
  }
  EXPORT_SYMBOL_GPL(handle_fastpath_set_msr_irqoff);
  
diff --git a/arch/x86/kvm/lapic.c b/arch/x86/kvm/lapic.c
index 845cf027dd00..291b66920eca 100644
--- a/arch/x86/kvm/lapic.c
+++ b/arch/x86/kvm/lapic.c
@@ -1589,7 +1589,7 @@ static void kvm_apic_inject_pending_timer_irqs(struct kvm_lapic *apic)
 	}
 }
 
-static void apic_timer_expired(struct kvm_lapic *apic)
+static void apic_timer_expired(struct kvm_lapic *apic, bool from_timer_fn)
 {
 	struct kvm_vcpu *vcpu = apic->vcpu;
 	struct kvm_timer *ktimer = &apic->lapic_timer;
@@ -1600,6 +1600,12 @@ static void apic_timer_expired(struct kvm_lapic *apic)
 	if (apic_lvtt_tscdeadline(apic) || ktimer->hv_timer_in_use)
 		ktimer->expired_tscdeadline = ktimer->tscdeadline;
 
+	if (!from_timer_fn && vcpu->arch.apicv_active) {
+		WARN_ON(kvm_get_running_vcpu() != vcpu);
+		kvm_apic_inject_pending_timer_irqs(apic);
+		return;
+	}
+
 	if (kvm_use_posted_timer_interrupt(apic->vcpu)) {
 		if (apic->lapic_timer.timer_advance_ns)
 			__kvm_wait_lapic_expire(vcpu);
@@ -1639,7 +1645,7 @@ static void start_sw_tscdeadline(struct kvm_lapic *apic)
 		expire = ktime_sub_ns(expire, ktimer->timer_advance_ns);
 		hrtimer_start(&ktimer->timer, expire, HRTIMER_MODE_ABS);
 	} else
-		apic_timer_expired(apic);
+		apic_timer_expired(apic, false);
 
 	local_irq_restore(flags);
 }
@@ -1747,7 +1753,7 @@ static void start_sw_period(struct kvm_lapic *apic)
 
 	if (ktime_after(ktime_get(),
 			apic->lapic_timer.target_expiration)) {
-		apic_timer_expired(apic);
+		apic_timer_expired(apic, false);
 
 		if (apic_lvtt_oneshot(apic))
 			return;
@@ -1809,7 +1815,7 @@ static bool start_hv_timer(struct kvm_lapic *apic)
 		if (atomic_read(&ktimer->pending)) {
 			cancel_hv_timer(apic);
 		} else if (expired) {
-			apic_timer_expired(apic);
+			apic_timer_expired(apic, false);
 			cancel_hv_timer(apic);
 		}
 	}
@@ -1859,7 +1865,7 @@ void kvm_lapic_expired_hv_timer(struct kvm_vcpu *vcpu)
 		goto out;
 	WARN_ON(swait_active(&vcpu->wq));
 	cancel_hv_timer(apic);
-	apic_timer_expired(apic);
+	apic_timer_expired(apic, false);
 
 	if (apic_lvtt_period(apic) && apic->lapic_timer.period) {
 		advance_periodic_target_expiration(apic);
@@ -2365,7 +2371,7 @@ static enum hrtimer_restart apic_timer_fn(struct hrtimer *data)
 	struct kvm_timer *ktimer = container_of(data, struct kvm_timer, timer);
 	struct kvm_lapic *apic = container_of(ktimer, struct kvm_lapic, lapic_timer);
 
-	apic_timer_expired(apic);
+	apic_timer_expired(apic, true);
 
 	if (lapic_is_periodic(apic)) {
 		advance_periodic_target_expiration(apic);
* Unmerged path arch/x86/kvm/x86.c
