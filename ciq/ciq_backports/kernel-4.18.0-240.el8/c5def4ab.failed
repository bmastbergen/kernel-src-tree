io-wq: add support for bounded vs unbunded work

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jens Axboe <axboe@kernel.dk>
commit c5def4ab849494d3c97f6c9fc84b2ddb868fe78c
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/c5def4ab.failed

io_uring supports request types that basically have two different
lifetimes:

1) Bounded completion time. These are requests like disk reads or writes,
   which we know will finish in a finite amount of time.
2) Unbounded completion time. These are generally networked IO, where we
   have no idea how long they will take to complete. Another example is
   POLL commands.

This patch provides support for io-wq to handle these differently, so we
don't starve bounded requests by tying up workers for too long. By default
all work is bounded, unless otherwise specified in the work item.

	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit c5def4ab849494d3c97f6c9fc84b2ddb868fe78c)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/io-wq.c
#	fs/io-wq.h
#	fs/io_uring.c
diff --cc fs/io_uring.c
index fca9cdc96d77,831bea0fbc75..000000000000
--- a/fs/io_uring.c
+++ b/fs/io_uring.c
@@@ -3173,26 -3743,12 +3173,35 @@@ static int io_sq_offload_start(struct i
  		goto err;
  	}
  
++<<<<<<< HEAD
 +	/* Do QD, or 2 * CPUS, whatever is smallest */
 +	ctx->sqo_wq[0] = alloc_workqueue("io_ring-wq",
 +			WQ_UNBOUND | WQ_FREEZABLE,
 +			min(ctx->sq_entries - 1, 2 * num_online_cpus()));
 +	if (!ctx->sqo_wq[0]) {
 +		ret = -ENOMEM;
 +		goto err;
 +	}
 +
 +	/*
 +	 * This is for buffered writes, where we want to limit the parallelism
 +	 * due to file locking in file systems. As "normal" buffered writes
 +	 * should parellelize on writeout quite nicely, limit us to having 2
 +	 * pending. This avoids massive contention on the inode when doing
 +	 * buffered async writes.
 +	 */
 +	ctx->sqo_wq[1] = alloc_workqueue("io_ring-write-wq",
 +						WQ_UNBOUND | WQ_FREEZABLE, 2);
 +	if (!ctx->sqo_wq[1]) {
 +		ret = -ENOMEM;
++=======
+ 	/* Do QD, or 4 * CPUS, whatever is smallest */
+ 	concurrency = min(ctx->sq_entries, 4 * num_online_cpus());
+ 	ctx->io_wq = io_wq_create(concurrency, ctx->sqo_mm, NULL);
+ 	if (IS_ERR(ctx->io_wq)) {
+ 		ret = PTR_ERR(ctx->io_wq);
+ 		ctx->io_wq = NULL;
++>>>>>>> c5def4ab8494 (io-wq: add support for bounded vs unbunded work)
  		goto err;
  	}
  
* Unmerged path fs/io-wq.c
* Unmerged path fs/io-wq.h
* Unmerged path fs/io-wq.c
* Unmerged path fs/io-wq.h
* Unmerged path fs/io_uring.c
