net/mlx5e: CT: Introduce connection tracking

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Paul Blakey <paulb@mellanox.com>
commit 4c3844d9e97e10f0cf024fe7f24dcefa133fe9e2
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/4c3844d9.failed

Add support for offloading tc ct action and ct matches.
We translate the tc filter with CT action the following HW model:

+-------------------+      +--------------------+    +--------------+
+ pre_ct (tc chain) +----->+ CT (nat or no nat) +--->+ post_ct      +----->
+ original match    +  |   + tuple + zone match + |  + fte_id match +  |
+-------------------+  |   +--------------------+ |  +--------------+  |
                       v                          v                    v
                      set chain miss mapping  set mark             original
                      set fte_id              set label            filter
                      set zone                set established      actions
                      set tunnel_id           do nat (if needed)
                      do decap

	Signed-off-by: Paul Blakey <paulb@mellanox.com>
	Reviewed-by: Oz Shlomo <ozsh@mellanox.com>
	Reviewed-by: Roi Dayan <roid@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 4c3844d9e97e10f0cf024fe7f24dcefa133fe9e2)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/Makefile
#	drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
diff --cc drivers/net/ethernet/mellanox/mlx5/core/Makefile
index 8d3b7a3aee92,7408ae380d23..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/Makefile
+++ b/drivers/net/ethernet/mellanox/mlx5/core/Makefile
@@@ -33,8 -34,10 +33,15 @@@ mlx5_core-$(CONFIG_MLX5_EN_ARFS)     +
  mlx5_core-$(CONFIG_MLX5_EN_RXNFC)    += en_fs_ethtool.o
  mlx5_core-$(CONFIG_MLX5_CORE_EN_DCB) += en_dcbnl.o en/port_buffer.o
  mlx5_core-$(CONFIG_MLX5_ESWITCH)     += en_rep.o en_tc.o en/tc_tun.o lib/port_tun.o lag_mp.o \
++<<<<<<< HEAD
 +					lib/geneve.o en/tc_tun_vxlan.o en/tc_tun_gre.o \
 +					en/tc_tun_geneve.o
++=======
+ 					lib/geneve.o en/mapping.o en/tc_tun_vxlan.o en/tc_tun_gre.o \
+ 					en/tc_tun_geneve.o diag/en_tc_tracepoint.o
+ mlx5_core-$(CONFIG_PCI_HYPERV_INTERFACE) += en/hv_vhca_stats.o
+ mlx5_core-$(CONFIG_MLX5_TC_CT)	     += en/tc_ct.o
++>>>>>>> 4c3844d9e97e (net/mlx5e: CT: Introduce connection tracking)
  
  #
  # Core extra
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
index a8f7d6030f73,6a2337900420..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
@@@ -81,6 -82,13 +82,16 @@@ struct mlx5_rep_uplink_priv 
  	struct mutex                unready_flows_lock;
  	struct list_head            unready_flows;
  	struct work_struct          reoffload_flows_work;
++<<<<<<< HEAD
++=======
+ 
+ 	/* maps tun_info to a unique id*/
+ 	struct mapping_ctx *tunnel_mapping;
+ 	/* maps tun_enc_opts to a unique id*/
+ 	struct mapping_ctx *tunnel_enc_opts_mapping;
+ 
+ 	struct mlx5_tc_ct_priv *ct_priv;
++>>>>>>> 4c3844d9e97e (net/mlx5e: CT: Introduce connection tracking)
  };
  
  struct mlx5e_rep_priv {
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index 2e22a8de6513,1f6a30623cb7..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -54,8 -54,14 +54,13 @@@
  #include "fs_core.h"
  #include "en/port.h"
  #include "en/tc_tun.h"
++<<<<<<< HEAD
++=======
+ #include "en/mapping.h"
+ #include "en/tc_ct.h"
++>>>>>>> 4c3844d9e97e (net/mlx5e: CT: Introduce connection tracking)
  #include "lib/devcom.h"
  #include "lib/geneve.h"
 -#include "diag/en_tc_tracepoint.h"
 -
 -#define MLX5_MH_ACT_SZ MLX5_UN_SZ_BYTES(set_action_in_add_action_in_auto)
  
  struct mlx5_nic_flow_attr {
  	u32 action;
@@@ -149,6 -158,110 +155,113 @@@ struct mlx5e_tc_flow_parse_attr 
  #define MLX5E_TC_TABLE_NUM_GROUPS 4
  #define MLX5E_TC_TABLE_MAX_GROUP_SIZE BIT(16)
  
++<<<<<<< HEAD
++=======
+ struct tunnel_match_key {
+ 	struct flow_dissector_key_control enc_control;
+ 	struct flow_dissector_key_keyid enc_key_id;
+ 	struct flow_dissector_key_ports enc_tp;
+ 	struct flow_dissector_key_ip enc_ip;
+ 	union {
+ 		struct flow_dissector_key_ipv4_addrs enc_ipv4;
+ 		struct flow_dissector_key_ipv6_addrs enc_ipv6;
+ 	};
+ 
+ 	int filter_ifindex;
+ };
+ 
+ /* Tunnel_id mapping is TUNNEL_INFO_BITS + ENC_OPTS_BITS.
+  * Upper TUNNEL_INFO_BITS for general tunnel info.
+  * Lower ENC_OPTS_BITS bits for enc_opts.
+  */
+ #define TUNNEL_INFO_BITS 6
+ #define TUNNEL_INFO_BITS_MASK GENMASK(TUNNEL_INFO_BITS - 1, 0)
+ #define ENC_OPTS_BITS 2
+ #define ENC_OPTS_BITS_MASK GENMASK(ENC_OPTS_BITS - 1, 0)
+ #define TUNNEL_ID_BITS (TUNNEL_INFO_BITS + ENC_OPTS_BITS)
+ #define TUNNEL_ID_MASK GENMASK(TUNNEL_ID_BITS - 1, 0)
+ 
+ struct mlx5e_tc_attr_to_reg_mapping mlx5e_tc_attr_to_reg_mappings[] = {
+ 	[CHAIN_TO_REG] = {
+ 		.mfield = MLX5_ACTION_IN_FIELD_METADATA_REG_C_0,
+ 		.moffset = 0,
+ 		.mlen = 2,
+ 	},
+ 	[TUNNEL_TO_REG] = {
+ 		.mfield = MLX5_ACTION_IN_FIELD_METADATA_REG_C_1,
+ 		.moffset = 3,
+ 		.mlen = 1,
+ 		.soffset = MLX5_BYTE_OFF(fte_match_param,
+ 					 misc_parameters_2.metadata_reg_c_1),
+ 	},
+ 	[ZONE_TO_REG] = zone_to_reg_ct,
+ 	[CTSTATE_TO_REG] = ctstate_to_reg_ct,
+ 	[MARK_TO_REG] = mark_to_reg_ct,
+ 	[LABELS_TO_REG] = labels_to_reg_ct,
+ 	[FTEID_TO_REG] = fteid_to_reg_ct,
+ };
+ 
+ static void mlx5e_put_flow_tunnel_id(struct mlx5e_tc_flow *flow);
+ 
+ void
+ mlx5e_tc_match_to_reg_match(struct mlx5_flow_spec *spec,
+ 			    enum mlx5e_tc_attr_to_reg type,
+ 			    u32 data,
+ 			    u32 mask)
+ {
+ 	int soffset = mlx5e_tc_attr_to_reg_mappings[type].soffset;
+ 	int match_len = mlx5e_tc_attr_to_reg_mappings[type].mlen;
+ 	void *headers_c = spec->match_criteria;
+ 	void *headers_v = spec->match_value;
+ 	void *fmask, *fval;
+ 
+ 	fmask = headers_c + soffset;
+ 	fval = headers_v + soffset;
+ 
+ 	mask = cpu_to_be32(mask) >> (32 - (match_len * 8));
+ 	data = cpu_to_be32(data) >> (32 - (match_len * 8));
+ 
+ 	memcpy(fmask, &mask, match_len);
+ 	memcpy(fval, &data, match_len);
+ 
+ 	spec->match_criteria_enable |= MLX5_MATCH_MISC_PARAMETERS_2;
+ }
+ 
+ int
+ mlx5e_tc_match_to_reg_set(struct mlx5_core_dev *mdev,
+ 			  struct mlx5e_tc_mod_hdr_acts *mod_hdr_acts,
+ 			  enum mlx5e_tc_attr_to_reg type,
+ 			  u32 data)
+ {
+ 	int moffset = mlx5e_tc_attr_to_reg_mappings[type].moffset;
+ 	int mfield = mlx5e_tc_attr_to_reg_mappings[type].mfield;
+ 	int mlen = mlx5e_tc_attr_to_reg_mappings[type].mlen;
+ 	char *modact;
+ 	int err;
+ 
+ 	err = alloc_mod_hdr_actions(mdev, MLX5_FLOW_NAMESPACE_FDB,
+ 				    mod_hdr_acts);
+ 	if (err)
+ 		return err;
+ 
+ 	modact = mod_hdr_acts->actions +
+ 		 (mod_hdr_acts->num_actions * MLX5_MH_ACT_SZ);
+ 
+ 	/* Firmware has 5bit length field and 0 means 32bits */
+ 	if (mlen == 4)
+ 		mlen = 0;
+ 
+ 	MLX5_SET(set_action_in, modact, action_type, MLX5_ACTION_TYPE_SET);
+ 	MLX5_SET(set_action_in, modact, field, mfield);
+ 	MLX5_SET(set_action_in, modact, offset, moffset * 8);
+ 	MLX5_SET(set_action_in, modact, length, mlen * 8);
+ 	MLX5_SET(set_action_in, modact, data, data);
+ 	mod_hdr_acts->num_actions++;
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 4c3844d9e97e (net/mlx5e: CT: Introduce connection tracking)
  struct mlx5e_hairpin {
  	struct mlx5_hairpin *pair;
  
@@@ -1657,33 -1780,256 +1779,38 @@@ static void mlx5e_tc_del_flow(struct ml
  	}
  }
  
 -static int flow_has_tc_fwd_action(struct flow_cls_offload *f)
 -{
 -	struct flow_rule *rule = flow_cls_offload_flow_rule(f);
 -	struct flow_action *flow_action = &rule->action;
 -	const struct flow_action_entry *act;
 -	int i;
 -
 -	flow_action_for_each(i, act, flow_action) {
 -		switch (act->id) {
 -		case FLOW_ACTION_GOTO:
 -			return true;
 -		default:
 -			continue;
 -		}
 -	}
 -
 -	return false;
 -}
 -
 -static int
 -enc_opts_is_dont_care_or_full_match(struct mlx5e_priv *priv,
 -				    struct flow_dissector_key_enc_opts *opts,
 -				    struct netlink_ext_ack *extack,
 -				    bool *dont_care)
 -{
 -	struct geneve_opt *opt;
 -	int off = 0;
 -
 -	*dont_care = true;
 -
 -	while (opts->len > off) {
 -		opt = (struct geneve_opt *)&opts->data[off];
 -
 -		if (!(*dont_care) || opt->opt_class || opt->type ||
 -		    memchr_inv(opt->opt_data, 0, opt->length * 4)) {
 -			*dont_care = false;
 -
 -			if (opt->opt_class != U16_MAX ||
 -			    opt->type != U8_MAX ||
 -			    memchr_inv(opt->opt_data, 0xFF,
 -				       opt->length * 4)) {
 -				NL_SET_ERR_MSG(extack,
 -					       "Partial match of tunnel options in chain > 0 isn't supported");
 -				netdev_warn(priv->netdev,
 -					    "Partial match of tunnel options in chain > 0 isn't supported");
 -				return -EOPNOTSUPP;
 -			}
 -		}
 -
 -		off += sizeof(struct geneve_opt) + opt->length * 4;
 -	}
 -
 -	return 0;
 -}
 -
 -#define COPY_DISSECTOR(rule, diss_key, dst)\
 -({ \
 -	struct flow_rule *__rule = (rule);\
 -	typeof(dst) __dst = dst;\
 -\
 -	memcpy(__dst,\
 -	       skb_flow_dissector_target(__rule->match.dissector,\
 -					 diss_key,\
 -					 __rule->match.key),\
 -	       sizeof(*__dst));\
 -})
 -
 -static int mlx5e_get_flow_tunnel_id(struct mlx5e_priv *priv,
 -				    struct mlx5e_tc_flow *flow,
 -				    struct flow_cls_offload *f,
 -				    struct net_device *filter_dev)
 -{
 -	struct flow_rule *rule = flow_cls_offload_flow_rule(f);
 -	struct netlink_ext_ack *extack = f->common.extack;
 -	struct mlx5_esw_flow_attr *attr = flow->esw_attr;
 -	struct mlx5e_tc_mod_hdr_acts *mod_hdr_acts;
 -	struct flow_match_enc_opts enc_opts_match;
 -	struct mlx5_rep_uplink_priv *uplink_priv;
 -	struct mlx5e_rep_priv *uplink_rpriv;
 -	struct tunnel_match_key tunnel_key;
 -	bool enc_opts_is_dont_care = true;
 -	u32 tun_id, enc_opts_id = 0;
 -	struct mlx5_eswitch *esw;
 -	u32 value, mask;
 -	int err;
 -
 -	esw = priv->mdev->priv.eswitch;
 -	uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
 -	uplink_priv = &uplink_rpriv->uplink_priv;
 -
 -	memset(&tunnel_key, 0, sizeof(tunnel_key));
 -	COPY_DISSECTOR(rule, FLOW_DISSECTOR_KEY_ENC_CONTROL,
 -		       &tunnel_key.enc_control);
 -	if (tunnel_key.enc_control.addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS)
 -		COPY_DISSECTOR(rule, FLOW_DISSECTOR_KEY_ENC_IPV4_ADDRS,
 -			       &tunnel_key.enc_ipv4);
 -	else
 -		COPY_DISSECTOR(rule, FLOW_DISSECTOR_KEY_ENC_IPV6_ADDRS,
 -			       &tunnel_key.enc_ipv6);
 -	COPY_DISSECTOR(rule, FLOW_DISSECTOR_KEY_ENC_IP, &tunnel_key.enc_ip);
 -	COPY_DISSECTOR(rule, FLOW_DISSECTOR_KEY_ENC_PORTS,
 -		       &tunnel_key.enc_tp);
 -	COPY_DISSECTOR(rule, FLOW_DISSECTOR_KEY_ENC_KEYID,
 -		       &tunnel_key.enc_key_id);
 -	tunnel_key.filter_ifindex = filter_dev->ifindex;
 -
 -	err = mapping_add(uplink_priv->tunnel_mapping, &tunnel_key, &tun_id);
 -	if (err)
 -		return err;
 -
 -	flow_rule_match_enc_opts(rule, &enc_opts_match);
 -	err = enc_opts_is_dont_care_or_full_match(priv,
 -						  enc_opts_match.mask,
 -						  extack,
 -						  &enc_opts_is_dont_care);
 -	if (err)
 -		goto err_enc_opts;
 -
 -	if (!enc_opts_is_dont_care) {
 -		err = mapping_add(uplink_priv->tunnel_enc_opts_mapping,
 -				  enc_opts_match.key, &enc_opts_id);
 -		if (err)
 -			goto err_enc_opts;
 -	}
 -
 -	value = tun_id << ENC_OPTS_BITS | enc_opts_id;
 -	mask = enc_opts_id ? TUNNEL_ID_MASK :
 -			     (TUNNEL_ID_MASK & ~ENC_OPTS_BITS_MASK);
 -
 -	if (attr->chain) {
 -		mlx5e_tc_match_to_reg_match(&attr->parse_attr->spec,
 -					    TUNNEL_TO_REG, value, mask);
 -	} else {
 -		mod_hdr_acts = &attr->parse_attr->mod_hdr_acts;
 -		err = mlx5e_tc_match_to_reg_set(priv->mdev,
 -						mod_hdr_acts,
 -						TUNNEL_TO_REG, value);
 -		if (err)
 -			goto err_set;
 -
 -		attr->action |= MLX5_FLOW_CONTEXT_ACTION_MOD_HDR;
 -	}
 -
 -	flow->tunnel_id = value;
 -	return 0;
 -
 -err_set:
 -	if (enc_opts_id)
 -		mapping_remove(uplink_priv->tunnel_enc_opts_mapping,
 -			       enc_opts_id);
 -err_enc_opts:
 -	mapping_remove(uplink_priv->tunnel_mapping, tun_id);
 -	return err;
 -}
 -
 -static void mlx5e_put_flow_tunnel_id(struct mlx5e_tc_flow *flow)
 -{
 -	u32 enc_opts_id = flow->tunnel_id & ENC_OPTS_BITS_MASK;
 -	u32 tun_id = flow->tunnel_id >> ENC_OPTS_BITS;
 -	struct mlx5_rep_uplink_priv *uplink_priv;
 -	struct mlx5e_rep_priv *uplink_rpriv;
 -	struct mlx5_eswitch *esw;
 -
 -	esw = flow->priv->mdev->priv.eswitch;
 -	uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
 -	uplink_priv = &uplink_rpriv->uplink_priv;
 -
 -	if (tun_id)
 -		mapping_remove(uplink_priv->tunnel_mapping, tun_id);
 -	if (enc_opts_id)
 -		mapping_remove(uplink_priv->tunnel_enc_opts_mapping,
 -			       enc_opts_id);
 -}
  
+ u32 mlx5e_tc_get_flow_tun_id(struct mlx5e_tc_flow *flow)
+ {
+ 	return flow->tunnel_id;
+ }
+ 
  static int parse_tunnel_attr(struct mlx5e_priv *priv,
 -			     struct mlx5e_tc_flow *flow,
  			     struct mlx5_flow_spec *spec,
  			     struct flow_cls_offload *f,
 -			     struct net_device *filter_dev,
 -			     u8 *match_level,
 -			     bool *match_inner)
 +			     struct net_device *filter_dev, u8 *match_level)
  {
 -	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
  	struct netlink_ext_ack *extack = f->common.extack;
 -	bool needs_mapping, sets_mapping;
  	int err;
  
 -	if (!mlx5e_is_eswitch_flow(flow))
 -		return -EOPNOTSUPP;
 -
 -	needs_mapping = !!flow->esw_attr->chain;
 -	sets_mapping = !flow->esw_attr->chain && flow_has_tc_fwd_action(f);
 -	*match_inner = !needs_mapping;
 -
 -	if ((needs_mapping || sets_mapping) &&
 -	    !mlx5_eswitch_vport_match_metadata_enabled(esw)) {
 -		NL_SET_ERR_MSG(extack,
 -			       "Chains on tunnel devices isn't supported without register metadata support");
 -		netdev_warn(priv->netdev,
 -			    "Chains on tunnel devices isn't supported without register metadata support");
 -		return -EOPNOTSUPP;
 -	}
 -
 -	if (!flow->esw_attr->chain) {
 -		err = mlx5e_tc_tun_parse(filter_dev, priv, spec, f,
 -					 match_level);
 -		if (err) {
 -			NL_SET_ERR_MSG_MOD(extack,
 -					   "Failed to parse tunnel attributes");
 -			netdev_warn(priv->netdev,
 -				    "Failed to parse tunnel attributes");
 -			return err;
 -		}
 -
 -		flow->esw_attr->action |= MLX5_FLOW_CONTEXT_ACTION_DECAP;
 +	err = mlx5e_tc_tun_parse(filter_dev, priv, spec, f, match_level);
 +	if (err) {
 +		NL_SET_ERR_MSG_MOD(extack,
 +				   "failed to parse tunnel attributes");
 +		return err;
  	}
  
 -	if (!needs_mapping && !sets_mapping)
 -		return 0;
 -
 -	return mlx5e_get_flow_tunnel_id(priv, flow, f, filter_dev);
 -}
 -
 -static void *get_match_inner_headers_criteria(struct mlx5_flow_spec *spec)
 -{
 -	return MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 -			    inner_headers);
 -}
 -
 -static void *get_match_inner_headers_value(struct mlx5_flow_spec *spec)
 -{
 -	return MLX5_ADDR_OF(fte_match_param, spec->match_value,
 -			    inner_headers);
 -}
 -
 -static void *get_match_outer_headers_criteria(struct mlx5_flow_spec *spec)
 -{
 -	return MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 -			    outer_headers);
 +	return 0;
  }
  
 -static void *get_match_outer_headers_value(struct mlx5_flow_spec *spec)
 +static void *get_match_headers_criteria(u32 flags,
 +					struct mlx5_flow_spec *spec)
  {
 -	return MLX5_ADDR_OF(fte_match_param, spec->match_value,
 -			    outer_headers);
 +	return (flags & MLX5_FLOW_CONTEXT_ACTION_DECAP) ?
 +		MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 +			     inner_headers) :
 +		MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 +			     outer_headers);
  }
  
  static void *get_match_headers_value(u32 flags,
@@@ -2663,16 -3040,26 +2811,31 @@@ static bool actions_match_supported(str
  				    struct netlink_ext_ack *extack)
  {
  	struct net_device *filter_dev = parse_attr->filter_dev;
++<<<<<<< HEAD
 +	bool drop_action, decap_action, pop_action;
++=======
+ 	bool drop_action, pop_action, ct_flow;
++>>>>>>> 4c3844d9e97e (net/mlx5e: CT: Introduce connection tracking)
  	u32 actions;
  
- 	if (mlx5e_is_eswitch_flow(flow))
+ 	ct_flow = flow_flag_test(flow, CT);
+ 	if (mlx5e_is_eswitch_flow(flow)) {
  		actions = flow->esw_attr->action;
- 	else
+ 
+ 		if (flow->esw_attr->split_count && ct_flow) {
+ 			/* All registers used by ct are cleared when using
+ 			 * split rules.
+ 			 */
+ 			NL_SET_ERR_MSG_MOD(extack,
+ 					   "Can't offload mirroring with action ct");
+ 			return -EOPNOTSUPP;
+ 		}
+ 	} else {
  		actions = flow->nic_attr->action;
+ 	}
  
  	drop_action = actions & MLX5_FLOW_CONTEXT_ACTION_DROP;
 +	decap_action = actions & MLX5_FLOW_CONTEXT_ACTION_DECAP;
  	pop_action = actions & MLX5_FLOW_CONTEXT_ACTION_VLAN_POP;
  
  	if (flow_flag_test(flow, EGRESS) && !drop_action) {
@@@ -3379,28 -3868,24 +3542,38 @@@ static int parse_tc_fdb_actions(struct 
  			attr->split_count = attr->out_count;
  			break;
  		case FLOW_ACTION_TUNNEL_DECAP:
 -			decap = true;
 +			action |= MLX5_FLOW_CONTEXT_ACTION_DECAP;
  			break;
 -		case FLOW_ACTION_GOTO:
 -			err = mlx5_validate_goto_chain(esw, flow, act, action,
 -						       extack);
 -			if (err)
 -				return err;
 +		case FLOW_ACTION_GOTO: {
 +			u32 dest_chain = act->chain_index;
 +			u32 max_chain = mlx5_eswitch_get_chain_range(esw);
  
 +			if (ft_flow) {
 +				NL_SET_ERR_MSG_MOD(extack, "Goto action is not supported");
 +				return -EOPNOTSUPP;
 +			}
 +			if (dest_chain <= attr->chain) {
 +				NL_SET_ERR_MSG(extack, "Goto earlier chain isn't supported");
 +				return -EOPNOTSUPP;
 +			}
 +			if (dest_chain > max_chain) {
 +				NL_SET_ERR_MSG(extack, "Requested destination chain is out of supported range");
 +				return -EOPNOTSUPP;
 +			}
  			action |= MLX5_FLOW_CONTEXT_ACTION_COUNT;
 -			attr->dest_chain = act->chain_index;
 +			attr->dest_chain = dest_chain;
  			break;
++<<<<<<< HEAD
 +			}
++=======
+ 		case FLOW_ACTION_CT:
+ 			err = mlx5_tc_ct_parse_action(priv, attr, act, extack);
+ 			if (err)
+ 				return err;
+ 
+ 			flow_flag_set(flow, CT);
+ 			break;
++>>>>>>> 4c3844d9e97e (net/mlx5e: CT: Introduce connection tracking)
  		default:
  			NL_SET_ERR_MSG_MOD(extack, "The offload action is not supported");
  			return -EOPNOTSUPP;
@@@ -4164,12 -4677,63 +4341,68 @@@ void mlx5e_tc_nic_cleanup(struct mlx5e_
  
  int mlx5e_tc_esw_init(struct rhashtable *tc_ht)
  {
++<<<<<<< HEAD
 +	return rhashtable_init(tc_ht, &tc_ht_params);
++=======
+ 	const size_t sz_enc_opts = sizeof(struct flow_dissector_key_enc_opts);
+ 	struct mlx5_rep_uplink_priv *uplink_priv;
+ 	struct mlx5e_rep_priv *priv;
+ 	struct mapping_ctx *mapping;
+ 	int err;
+ 
+ 	uplink_priv = container_of(tc_ht, struct mlx5_rep_uplink_priv, tc_ht);
+ 	priv = container_of(uplink_priv, struct mlx5e_rep_priv, uplink_priv);
+ 
+ 	err = mlx5_tc_ct_init(uplink_priv);
+ 	if (err)
+ 		goto err_ct;
+ 
+ 	mapping = mapping_create(sizeof(struct tunnel_match_key),
+ 				 TUNNEL_INFO_BITS_MASK, true);
+ 	if (IS_ERR(mapping)) {
+ 		err = PTR_ERR(mapping);
+ 		goto err_tun_mapping;
+ 	}
+ 	uplink_priv->tunnel_mapping = mapping;
+ 
+ 	mapping = mapping_create(sz_enc_opts, ENC_OPTS_BITS_MASK, true);
+ 	if (IS_ERR(mapping)) {
+ 		err = PTR_ERR(mapping);
+ 		goto err_enc_opts_mapping;
+ 	}
+ 	uplink_priv->tunnel_enc_opts_mapping = mapping;
+ 
+ 	err = rhashtable_init(tc_ht, &tc_ht_params);
+ 	if (err)
+ 		goto err_ht_init;
+ 
+ 	return err;
+ 
+ err_ht_init:
+ 	mapping_destroy(uplink_priv->tunnel_enc_opts_mapping);
+ err_enc_opts_mapping:
+ 	mapping_destroy(uplink_priv->tunnel_mapping);
+ err_tun_mapping:
+ 	mlx5_tc_ct_clean(uplink_priv);
+ err_ct:
+ 	netdev_warn(priv->netdev,
+ 		    "Failed to initialize tc (eswitch), err: %d", err);
+ 	return err;
++>>>>>>> 4c3844d9e97e (net/mlx5e: CT: Introduce connection tracking)
  }
  
  void mlx5e_tc_esw_cleanup(struct rhashtable *tc_ht)
  {
 -	struct mlx5_rep_uplink_priv *uplink_priv;
 -
  	rhashtable_free_and_destroy(tc_ht, _mlx5e_tc_del_flow, NULL);
++<<<<<<< HEAD
++=======
+ 
+ 	uplink_priv = container_of(tc_ht, struct mlx5_rep_uplink_priv, tc_ht);
+ 	mapping_destroy(uplink_priv->tunnel_enc_opts_mapping);
+ 	mapping_destroy(uplink_priv->tunnel_mapping);
+ 
+ 	mlx5_tc_ct_clean(uplink_priv);
++>>>>>>> 4c3844d9e97e (net/mlx5e: CT: Introduce connection tracking)
  }
  
  int mlx5e_tc_num_filters(struct mlx5e_priv *priv, unsigned long flags)
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
index 22d5efd4edec,31c9e81b9287..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
@@@ -91,6 -91,26 +91,29 @@@ int mlx5e_tc_num_filters(struct mlx5e_p
  
  void mlx5e_tc_reoffload_flows_work(struct work_struct *work);
  
++<<<<<<< HEAD
++=======
+ enum mlx5e_tc_attr_to_reg {
+ 	CHAIN_TO_REG,
+ 	TUNNEL_TO_REG,
+ 	CTSTATE_TO_REG,
+ 	ZONE_TO_REG,
+ 	MARK_TO_REG,
+ 	LABELS_TO_REG,
+ 	FTEID_TO_REG,
+ };
+ 
+ struct mlx5e_tc_attr_to_reg_mapping {
+ 	int mfield; /* rewrite field */
+ 	int moffset; /* offset of mfield */
+ 	int mlen; /* bytes to rewrite/match */
+ 
+ 	int soffset; /* offset of spec for match */
+ };
+ 
+ extern struct mlx5e_tc_attr_to_reg_mapping mlx5e_tc_attr_to_reg_mappings[];
+ 
++>>>>>>> 4c3844d9e97e (net/mlx5e: CT: Introduce connection tracking)
  bool mlx5e_is_valid_eswitch_fwd_dev(struct mlx5e_priv *priv,
  				    struct net_device *out_dev);
  
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index 9c629f913b96,2e0417dd8ce3..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@@ -42,10 -42,17 +42,11 @@@
  #include <linux/mlx5/vport.h>
  #include <linux/mlx5/fs.h>
  #include "lib/mpfs.h"
+ #include "en/tc_ct.h"
  
 -#define FDB_TC_MAX_CHAIN 3
 -#define FDB_FT_CHAIN (FDB_TC_MAX_CHAIN + 1)
 -#define FDB_TC_SLOW_PATH_CHAIN (FDB_FT_CHAIN + 1)
 -
 -/* The index of the last real chain (FT) + 1 as chain zero is valid as well */
 -#define FDB_NUM_CHAINS (FDB_FT_CHAIN + 1)
 -
 -#define FDB_TC_MAX_PRIO 16
 -#define FDB_TC_LEVELS_PER_PRIO 2
 +#define FDB_MAX_CHAIN 3
 +#define FDB_SLOW_PATH_CHAIN (FDB_MAX_CHAIN + 1)
 +#define FDB_MAX_PRIO 16
  
  #ifdef CONFIG_MLX5_ESWITCH
  
@@@ -404,6 -422,10 +405,13 @@@ struct mlx5_esw_flow_attr 
  	u32	chain;
  	u16	prio;
  	u32	dest_chain;
++<<<<<<< HEAD
++=======
+ 	u32	flags;
+ 	struct mlx5_flow_table *fdb;
+ 	struct mlx5_flow_table *dest_ft;
+ 	struct mlx5_ct_attr ct_attr;
++>>>>>>> 4c3844d9e97e (net/mlx5e: CT: Introduce connection tracking)
  	struct mlx5e_tc_flow_parse_attr *parse_attr;
  };
  
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/Kconfig b/drivers/net/ethernet/mellanox/mlx5/core/Kconfig
index 361c783ec9b5..f43d38a03c99 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/Kconfig
+++ b/drivers/net/ethernet/mellanox/mlx5/core/Kconfig
@@ -77,6 +77,16 @@ config MLX5_ESWITCH
                 Legacy SRIOV mode (L2 mac vlan steering based).
                 Switchdev mode (eswitch offloads).
 
+config MLX5_TC_CT
+	bool "MLX5 TC connection tracking offload support"
+	depends on MLX5_CORE_EN && NET_SWITCHDEV && NF_FLOW_TABLE && NET_ACT_CT && NET_TC_SKB_EXT
+	default y
+	help
+	  Say Y here if you want to support offloading connection tracking rules
+	  via tc ct action.
+
+	  If unsure, set to Y
+
 config MLX5_CORE_EN_DCB
 	bool "Data Center Bridging (DCB) Support"
 	default y
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/Makefile
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.c b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.c
new file mode 100644
index 000000000000..c1130460bb60
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.c
@@ -0,0 +1,541 @@
+// SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB
+/* Copyright (c) 2019 Mellanox Technologies. */
+
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_core.h>
+#include <net/netfilter/nf_conntrack_zones.h>
+#include <net/netfilter/nf_conntrack_labels.h>
+#include <net/netfilter/nf_conntrack_helper.h>
+#include <net/netfilter/nf_conntrack_acct.h>
+#include <uapi/linux/tc_act/tc_pedit.h>
+#include <net/tc_act/tc_ct.h>
+#include <net/flow_offload.h>
+#include <linux/workqueue.h>
+
+#include "en/tc_ct.h"
+#include "en.h"
+#include "en_tc.h"
+#include "en_rep.h"
+#include "eswitch_offloads_chains.h"
+
+#define MLX5_CT_ZONE_BITS (mlx5e_tc_attr_to_reg_mappings[ZONE_TO_REG].mlen * 8)
+#define MLX5_CT_ZONE_MASK GENMASK(MLX5_CT_ZONE_BITS - 1, 0)
+#define MLX5_CT_STATE_ESTABLISHED_BIT BIT(1)
+#define MLX5_CT_STATE_TRK_BIT BIT(2)
+
+#define MLX5_FTE_ID_BITS (mlx5e_tc_attr_to_reg_mappings[FTEID_TO_REG].mlen * 8)
+#define MLX5_FTE_ID_MAX GENMASK(MLX5_FTE_ID_BITS - 1, 0)
+#define MLX5_FTE_ID_MASK MLX5_FTE_ID_MAX
+
+#define ct_dbg(fmt, args...)\
+	netdev_dbg(ct_priv->netdev, "ct_debug: " fmt "\n", ##args)
+
+struct mlx5_tc_ct_priv {
+	struct mlx5_eswitch *esw;
+	const struct net_device *netdev;
+	struct idr fte_ids;
+	struct mlx5_flow_table *ct;
+	struct mlx5_flow_table *ct_nat;
+	struct mlx5_flow_table *post_ct;
+	struct mutex control_lock; /* guards parallel adds/dels */
+};
+
+struct mlx5_ct_flow {
+	struct mlx5_esw_flow_attr pre_ct_attr;
+	struct mlx5_esw_flow_attr post_ct_attr;
+	struct mlx5_flow_handle *pre_ct_rule;
+	struct mlx5_flow_handle *post_ct_rule;
+	u32 fte_id;
+	u32 chain_mapping;
+};
+
+static struct mlx5_tc_ct_priv *
+mlx5_tc_ct_get_ct_priv(struct mlx5e_priv *priv)
+{
+	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
+	struct mlx5_rep_uplink_priv *uplink_priv;
+	struct mlx5e_rep_priv *uplink_rpriv;
+
+	uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
+	uplink_priv = &uplink_rpriv->uplink_priv;
+	return uplink_priv->ct_priv;
+}
+
+int
+mlx5_tc_ct_parse_match(struct mlx5e_priv *priv,
+		       struct mlx5_flow_spec *spec,
+		       struct flow_cls_offload *f,
+		       struct netlink_ext_ack *extack)
+{
+	struct mlx5_tc_ct_priv *ct_priv = mlx5_tc_ct_get_ct_priv(priv);
+	struct flow_dissector_key_ct *mask, *key;
+	bool trk, est, untrk, unest, new, unnew;
+	u32 ctstate = 0, ctstate_mask = 0;
+	u16 ct_state_on, ct_state_off;
+	u16 ct_state, ct_state_mask;
+	struct flow_match_ct match;
+
+	if (!flow_rule_match_key(f->rule, FLOW_DISSECTOR_KEY_CT))
+		return 0;
+
+	if (!ct_priv) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "offload of ct matching isn't available");
+		return -EOPNOTSUPP;
+	}
+
+	flow_rule_match_ct(f->rule, &match);
+
+	key = match.key;
+	mask = match.mask;
+
+	ct_state = key->ct_state;
+	ct_state_mask = mask->ct_state;
+
+	if (ct_state_mask & ~(TCA_FLOWER_KEY_CT_FLAGS_TRACKED |
+			      TCA_FLOWER_KEY_CT_FLAGS_ESTABLISHED |
+			      TCA_FLOWER_KEY_CT_FLAGS_NEW)) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "only ct_state trk, est and new are supported for offload");
+		return -EOPNOTSUPP;
+	}
+
+	if (mask->ct_labels[1] || mask->ct_labels[2] || mask->ct_labels[3]) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "only lower 32bits of ct_labels are supported for offload");
+		return -EOPNOTSUPP;
+	}
+
+	ct_state_on = ct_state & ct_state_mask;
+	ct_state_off = (ct_state & ct_state_mask) ^ ct_state_mask;
+	trk = ct_state_on & TCA_FLOWER_KEY_CT_FLAGS_TRACKED;
+	new = ct_state_on & TCA_FLOWER_KEY_CT_FLAGS_NEW;
+	est = ct_state_on & TCA_FLOWER_KEY_CT_FLAGS_ESTABLISHED;
+	untrk = ct_state_off & TCA_FLOWER_KEY_CT_FLAGS_TRACKED;
+	unnew = ct_state_off & TCA_FLOWER_KEY_CT_FLAGS_NEW;
+	unest = ct_state_off & TCA_FLOWER_KEY_CT_FLAGS_ESTABLISHED;
+
+	ctstate |= trk ? MLX5_CT_STATE_TRK_BIT : 0;
+	ctstate |= est ? MLX5_CT_STATE_ESTABLISHED_BIT : 0;
+	ctstate_mask |= (untrk || trk) ? MLX5_CT_STATE_TRK_BIT : 0;
+	ctstate_mask |= (unest || est) ? MLX5_CT_STATE_ESTABLISHED_BIT : 0;
+
+	if (new) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "matching on ct_state +new isn't supported");
+		return -EOPNOTSUPP;
+	}
+
+	if (mask->ct_zone)
+		mlx5e_tc_match_to_reg_match(spec, ZONE_TO_REG,
+					    key->ct_zone, MLX5_CT_ZONE_MASK);
+	if (ctstate_mask)
+		mlx5e_tc_match_to_reg_match(spec, CTSTATE_TO_REG,
+					    ctstate, ctstate_mask);
+	if (mask->ct_mark)
+		mlx5e_tc_match_to_reg_match(spec, MARK_TO_REG,
+					    key->ct_mark, mask->ct_mark);
+	if (mask->ct_labels[0])
+		mlx5e_tc_match_to_reg_match(spec, LABELS_TO_REG,
+					    key->ct_labels[0],
+					    mask->ct_labels[0]);
+
+	return 0;
+}
+
+int
+mlx5_tc_ct_parse_action(struct mlx5e_priv *priv,
+			struct mlx5_esw_flow_attr *attr,
+			const struct flow_action_entry *act,
+			struct netlink_ext_ack *extack)
+{
+	struct mlx5_tc_ct_priv *ct_priv = mlx5_tc_ct_get_ct_priv(priv);
+
+	if (!ct_priv) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "offload of ct action isn't available");
+		return -EOPNOTSUPP;
+	}
+
+	attr->ct_attr.zone = act->ct.zone;
+	attr->ct_attr.ct_action = act->ct.action;
+
+	return 0;
+}
+
+/* We translate the tc filter with CT action to the following HW model:
+ *
+ * +-------------------+      +--------------------+    +--------------+
+ * + pre_ct (tc chain) +----->+ CT (nat or no nat) +--->+ post_ct      +----->
+ * + original match    +  |   + tuple + zone match + |  + fte_id match +  |
+ * +-------------------+  |   +--------------------+ |  +--------------+  |
+ *                        v                          v                    v
+ *                       set chain miss mapping  set mark             original
+ *                       set fte_id              set label            filter
+ *                       set zone                set established      actions
+ *                       set tunnel_id           do nat (if needed)
+ *                       do decap
+ */
+static int
+__mlx5_tc_ct_flow_offload(struct mlx5e_priv *priv,
+			  struct mlx5e_tc_flow *flow,
+			  struct mlx5_flow_spec *orig_spec,
+			  struct mlx5_esw_flow_attr *attr,
+			  struct mlx5_flow_handle **flow_rule)
+{
+	struct mlx5_tc_ct_priv *ct_priv = mlx5_tc_ct_get_ct_priv(priv);
+	bool nat = attr->ct_attr.ct_action & TCA_CT_ACT_NAT;
+	struct mlx5e_tc_mod_hdr_acts pre_mod_acts = {};
+	struct mlx5_eswitch *esw = ct_priv->esw;
+	struct mlx5_flow_spec post_ct_spec = {};
+	struct mlx5_esw_flow_attr *pre_ct_attr;
+	struct  mlx5_modify_hdr *mod_hdr;
+	struct mlx5_flow_handle *rule;
+	struct mlx5_ct_flow *ct_flow;
+	int chain_mapping = 0, err;
+	u32 fte_id = 1;
+
+	ct_flow = kzalloc(sizeof(*ct_flow), GFP_KERNEL);
+	if (!ct_flow)
+		return -ENOMEM;
+
+	err = idr_alloc_u32(&ct_priv->fte_ids, ct_flow, &fte_id,
+			    MLX5_FTE_ID_MAX, GFP_KERNEL);
+	if (err) {
+		netdev_warn(priv->netdev,
+			    "Failed to allocate fte id, err: %d\n", err);
+		goto err_idr;
+	}
+	ct_flow->fte_id = fte_id;
+
+	/* Base esw attributes of both rules on original rule attribute */
+	pre_ct_attr = &ct_flow->pre_ct_attr;
+	memcpy(pre_ct_attr, attr, sizeof(*attr));
+	memcpy(&ct_flow->post_ct_attr, attr, sizeof(*attr));
+
+	/* Modify the original rule's action to fwd and modify, leave decap */
+	pre_ct_attr->action = attr->action & MLX5_FLOW_CONTEXT_ACTION_DECAP;
+	pre_ct_attr->action |= MLX5_FLOW_CONTEXT_ACTION_FWD_DEST |
+			       MLX5_FLOW_CONTEXT_ACTION_MOD_HDR;
+
+	/* Write chain miss tag for miss in ct table as we
+	 * don't go though all prios of this chain as normal tc rules
+	 * miss.
+	 */
+	err = mlx5_esw_chains_get_chain_mapping(esw, attr->chain,
+						&chain_mapping);
+	if (err) {
+		ct_dbg("Failed to get chain register mapping for chain");
+		goto err_get_chain;
+	}
+	ct_flow->chain_mapping = chain_mapping;
+
+	err = mlx5e_tc_match_to_reg_set(esw->dev, &pre_mod_acts,
+					CHAIN_TO_REG, chain_mapping);
+	if (err) {
+		ct_dbg("Failed to set chain register mapping");
+		goto err_mapping;
+	}
+
+	err = mlx5e_tc_match_to_reg_set(esw->dev, &pre_mod_acts, ZONE_TO_REG,
+					attr->ct_attr.zone &
+					MLX5_CT_ZONE_MASK);
+	if (err) {
+		ct_dbg("Failed to set zone register mapping");
+		goto err_mapping;
+	}
+
+	err = mlx5e_tc_match_to_reg_set(esw->dev, &pre_mod_acts,
+					FTEID_TO_REG, fte_id);
+	if (err) {
+		ct_dbg("Failed to set fte_id register mapping");
+		goto err_mapping;
+	}
+
+	/* If original flow is decap, we do it before going into ct table
+	 * so add a rewrite for the tunnel match_id.
+	 */
+	if ((pre_ct_attr->action & MLX5_FLOW_CONTEXT_ACTION_DECAP) &&
+	    attr->chain == 0) {
+		u32 tun_id = mlx5e_tc_get_flow_tun_id(flow);
+
+		err = mlx5e_tc_match_to_reg_set(esw->dev, &pre_mod_acts,
+						TUNNEL_TO_REG,
+						tun_id);
+		if (err) {
+			ct_dbg("Failed to set tunnel register mapping");
+			goto err_mapping;
+		}
+	}
+
+	mod_hdr = mlx5_modify_header_alloc(esw->dev,
+					   MLX5_FLOW_NAMESPACE_FDB,
+					   pre_mod_acts.num_actions,
+					   pre_mod_acts.actions);
+	if (IS_ERR(mod_hdr)) {
+		err = PTR_ERR(mod_hdr);
+		ct_dbg("Failed to create pre ct mod hdr");
+		goto err_mapping;
+	}
+	pre_ct_attr->modify_hdr = mod_hdr;
+
+	/* Post ct rule matches on fte_id and executes original rule's
+	 * tc rule action
+	 */
+	mlx5e_tc_match_to_reg_match(&post_ct_spec, FTEID_TO_REG,
+				    fte_id, MLX5_FTE_ID_MASK);
+
+	/* Put post_ct rule on post_ct fdb */
+	ct_flow->post_ct_attr.chain = 0;
+	ct_flow->post_ct_attr.prio = 0;
+	ct_flow->post_ct_attr.fdb = ct_priv->post_ct;
+
+	ct_flow->post_ct_attr.inner_match_level = MLX5_MATCH_NONE;
+	ct_flow->post_ct_attr.outer_match_level = MLX5_MATCH_NONE;
+	ct_flow->post_ct_attr.action &= ~(MLX5_FLOW_CONTEXT_ACTION_DECAP);
+	rule = mlx5_eswitch_add_offloaded_rule(esw, &post_ct_spec,
+					       &ct_flow->post_ct_attr);
+	ct_flow->post_ct_rule = rule;
+	if (IS_ERR(ct_flow->post_ct_rule)) {
+		err = PTR_ERR(ct_flow->post_ct_rule);
+		ct_dbg("Failed to add post ct rule");
+		goto err_insert_post_ct;
+	}
+
+	/* Change original rule point to ct table */
+	pre_ct_attr->dest_chain = 0;
+	pre_ct_attr->dest_ft = nat ? ct_priv->ct_nat : ct_priv->ct;
+	ct_flow->pre_ct_rule = mlx5_eswitch_add_offloaded_rule(esw,
+							       orig_spec,
+							       pre_ct_attr);
+	if (IS_ERR(ct_flow->pre_ct_rule)) {
+		err = PTR_ERR(ct_flow->pre_ct_rule);
+		ct_dbg("Failed to add pre ct rule");
+		goto err_insert_orig;
+	}
+
+	attr->ct_attr.ct_flow = ct_flow;
+	*flow_rule = ct_flow->post_ct_rule;
+	dealloc_mod_hdr_actions(&pre_mod_acts);
+
+	return 0;
+
+err_insert_orig:
+	mlx5_eswitch_del_offloaded_rule(ct_priv->esw, ct_flow->post_ct_rule,
+					&ct_flow->post_ct_attr);
+err_insert_post_ct:
+	mlx5_modify_header_dealloc(priv->mdev, pre_ct_attr->modify_hdr);
+err_mapping:
+	dealloc_mod_hdr_actions(&pre_mod_acts);
+	mlx5_esw_chains_put_chain_mapping(esw, ct_flow->chain_mapping);
+err_get_chain:
+	idr_remove(&ct_priv->fte_ids, fte_id);
+err_idr:
+	kfree(ct_flow);
+	netdev_warn(priv->netdev, "Failed to offload ct flow, err %d\n", err);
+	return err;
+}
+
+struct mlx5_flow_handle *
+mlx5_tc_ct_flow_offload(struct mlx5e_priv *priv,
+			struct mlx5e_tc_flow *flow,
+			struct mlx5_flow_spec *spec,
+			struct mlx5_esw_flow_attr *attr)
+{
+	struct mlx5_tc_ct_priv *ct_priv = mlx5_tc_ct_get_ct_priv(priv);
+	struct mlx5_flow_handle *rule;
+	int err;
+
+	if (!ct_priv)
+		return ERR_PTR(-EOPNOTSUPP);
+
+	mutex_lock(&ct_priv->control_lock);
+	err = __mlx5_tc_ct_flow_offload(priv, flow, spec, attr, &rule);
+	mutex_unlock(&ct_priv->control_lock);
+	if (err)
+		return ERR_PTR(err);
+
+	return rule;
+}
+
+static void
+__mlx5_tc_ct_delete_flow(struct mlx5_tc_ct_priv *ct_priv,
+			 struct mlx5_ct_flow *ct_flow)
+{
+	struct mlx5_esw_flow_attr *pre_ct_attr = &ct_flow->pre_ct_attr;
+	struct mlx5_eswitch *esw = ct_priv->esw;
+
+	mlx5_eswitch_del_offloaded_rule(esw, ct_flow->pre_ct_rule,
+					pre_ct_attr);
+	mlx5_modify_header_dealloc(esw->dev, pre_ct_attr->modify_hdr);
+	mlx5_eswitch_del_offloaded_rule(esw, ct_flow->post_ct_rule,
+					&ct_flow->post_ct_attr);
+	mlx5_esw_chains_put_chain_mapping(esw, ct_flow->chain_mapping);
+	idr_remove(&ct_priv->fte_ids, ct_flow->fte_id);
+	kfree(ct_flow);
+}
+
+void
+mlx5_tc_ct_delete_flow(struct mlx5e_priv *priv, struct mlx5e_tc_flow *flow,
+		       struct mlx5_esw_flow_attr *attr)
+{
+	struct mlx5_tc_ct_priv *ct_priv = mlx5_tc_ct_get_ct_priv(priv);
+	struct mlx5_ct_flow *ct_flow = attr->ct_attr.ct_flow;
+
+	/* We are called on error to clean up stuff from parsing
+	 * but we don't have anything for now
+	 */
+	if (!ct_flow)
+		return;
+
+	mutex_lock(&ct_priv->control_lock);
+	__mlx5_tc_ct_delete_flow(ct_priv, ct_flow);
+	mutex_unlock(&ct_priv->control_lock);
+}
+
+static int
+mlx5_tc_ct_init_check_support(struct mlx5_eswitch *esw,
+			      const char **err_msg)
+{
+#if !IS_ENABLED(CONFIG_NET_TC_SKB_EXT)
+	/* cannot restore chain ID on HW miss */
+
+	*err_msg = "tc skb extension missing";
+	return -EOPNOTSUPP;
+#endif
+
+	if (!MLX5_CAP_ESW_FLOWTABLE_FDB(esw->dev, ignore_flow_level)) {
+		*err_msg = "firmware level support is missing";
+		return -EOPNOTSUPP;
+	}
+
+	if (!mlx5_eswitch_vlan_actions_supported(esw->dev, 1)) {
+		/* vlan workaround should be avoided for multi chain rules.
+		 * This is just a sanity check as pop vlan action should
+		 * be supported by any FW that supports ignore_flow_level
+		 */
+
+		*err_msg = "firmware vlan actions support is missing";
+		return -EOPNOTSUPP;
+	}
+
+	if (!MLX5_CAP_ESW_FLOWTABLE(esw->dev,
+				    fdb_modify_header_fwd_to_table)) {
+		/* CT always writes to registers which are mod header actions.
+		 * Therefore, mod header and goto is required
+		 */
+
+		*err_msg = "firmware fwd and modify support is missing";
+		return -EOPNOTSUPP;
+	}
+
+	if (!mlx5_eswitch_reg_c1_loopback_enabled(esw)) {
+		*err_msg = "register loopback isn't supported";
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
+static void
+mlx5_tc_ct_init_err(struct mlx5e_rep_priv *rpriv, const char *msg, int err)
+{
+	if (msg)
+		netdev_warn(rpriv->netdev,
+			    "tc ct offload not supported, %s, err: %d\n",
+			    msg, err);
+	else
+		netdev_warn(rpriv->netdev,
+			    "tc ct offload not supported, err: %d\n",
+			    err);
+}
+
+int
+mlx5_tc_ct_init(struct mlx5_rep_uplink_priv *uplink_priv)
+{
+	struct mlx5_tc_ct_priv *ct_priv;
+	struct mlx5e_rep_priv *rpriv;
+	struct mlx5_eswitch *esw;
+	struct mlx5e_priv *priv;
+	const char *msg;
+	int err;
+
+	rpriv = container_of(uplink_priv, struct mlx5e_rep_priv, uplink_priv);
+	priv = netdev_priv(rpriv->netdev);
+	esw = priv->mdev->priv.eswitch;
+
+	err = mlx5_tc_ct_init_check_support(esw, &msg);
+	if (err) {
+		mlx5_tc_ct_init_err(rpriv, msg, err);
+		goto err_support;
+	}
+
+	ct_priv = kzalloc(sizeof(*ct_priv), GFP_KERNEL);
+	if (!ct_priv) {
+		mlx5_tc_ct_init_err(rpriv, NULL, -ENOMEM);
+		goto err_alloc;
+	}
+
+	ct_priv->esw = esw;
+	ct_priv->netdev = rpriv->netdev;
+	ct_priv->ct = mlx5_esw_chains_create_global_table(esw);
+	if (IS_ERR(ct_priv->ct)) {
+		err = PTR_ERR(ct_priv->ct);
+		mlx5_tc_ct_init_err(rpriv, "failed to create ct table", err);
+		goto err_ct_tbl;
+	}
+
+	ct_priv->ct_nat = mlx5_esw_chains_create_global_table(esw);
+	if (IS_ERR(ct_priv->ct_nat)) {
+		err = PTR_ERR(ct_priv->ct_nat);
+		mlx5_tc_ct_init_err(rpriv, "failed to create ct nat table",
+				    err);
+		goto err_ct_nat_tbl;
+	}
+
+	ct_priv->post_ct = mlx5_esw_chains_create_global_table(esw);
+	if (IS_ERR(ct_priv->post_ct)) {
+		err = PTR_ERR(ct_priv->post_ct);
+		mlx5_tc_ct_init_err(rpriv, "failed to create post ct table",
+				    err);
+		goto err_post_ct_tbl;
+	}
+
+	idr_init(&ct_priv->fte_ids);
+	mutex_init(&ct_priv->control_lock);
+
+	/* Done, set ct_priv to know it initializted */
+	uplink_priv->ct_priv = ct_priv;
+
+	return 0;
+
+err_post_ct_tbl:
+	mlx5_esw_chains_destroy_global_table(esw, ct_priv->ct_nat);
+err_ct_nat_tbl:
+	mlx5_esw_chains_destroy_global_table(esw, ct_priv->ct);
+err_ct_tbl:
+	kfree(ct_priv);
+err_alloc:
+err_support:
+
+	return 0;
+}
+
+void
+mlx5_tc_ct_clean(struct mlx5_rep_uplink_priv *uplink_priv)
+{
+	struct mlx5_tc_ct_priv *ct_priv = uplink_priv->ct_priv;
+
+	if (!ct_priv)
+		return;
+
+	mlx5_esw_chains_destroy_global_table(ct_priv->esw, ct_priv->post_ct);
+	mlx5_esw_chains_destroy_global_table(ct_priv->esw, ct_priv->ct_nat);
+	mlx5_esw_chains_destroy_global_table(ct_priv->esw, ct_priv->ct);
+
+	mutex_destroy(&ct_priv->control_lock);
+	idr_destroy(&ct_priv->fte_ids);
+	kfree(ct_priv);
+
+	uplink_priv->ct_priv = NULL;
+}
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.h b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.h
new file mode 100644
index 000000000000..3a8421671c23
--- /dev/null
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/tc_ct.h
@@ -0,0 +1,140 @@
+/* SPDX-License-Identifier: GPL-2.0 OR Linux-OpenIB */
+/* Copyright (c) 2018 Mellanox Technologies. */
+
+#ifndef __MLX5_EN_TC_CT_H__
+#define __MLX5_EN_TC_CT_H__
+
+#include <net/pkt_cls.h>
+#include <linux/mlx5/fs.h>
+#include <net/tc_act/tc_ct.h>
+
+struct mlx5_esw_flow_attr;
+struct mlx5_rep_uplink_priv;
+struct mlx5e_tc_flow;
+struct mlx5e_priv;
+
+struct mlx5_ct_flow;
+
+struct mlx5_ct_attr {
+	u16 zone;
+	u16 ct_action;
+	struct mlx5_ct_flow *ct_flow;
+};
+
+#define zone_to_reg_ct {\
+	.mfield = MLX5_ACTION_IN_FIELD_METADATA_REG_C_2,\
+	.moffset = 0,\
+	.mlen = 2,\
+	.soffset = MLX5_BYTE_OFF(fte_match_param,\
+				 misc_parameters_2.metadata_reg_c_2) + 2,\
+}
+
+#define ctstate_to_reg_ct {\
+	.mfield = MLX5_ACTION_IN_FIELD_METADATA_REG_C_2,\
+	.moffset = 2,\
+	.mlen = 2,\
+	.soffset = MLX5_BYTE_OFF(fte_match_param,\
+				 misc_parameters_2.metadata_reg_c_2),\
+}
+
+#define mark_to_reg_ct {\
+	.mfield = MLX5_ACTION_IN_FIELD_METADATA_REG_C_3,\
+	.moffset = 0,\
+	.mlen = 4,\
+	.soffset = MLX5_BYTE_OFF(fte_match_param,\
+				 misc_parameters_2.metadata_reg_c_3),\
+}
+
+#define labels_to_reg_ct {\
+	.mfield = MLX5_ACTION_IN_FIELD_METADATA_REG_C_4,\
+	.moffset = 0,\
+	.mlen = 4,\
+	.soffset = MLX5_BYTE_OFF(fte_match_param,\
+				 misc_parameters_2.metadata_reg_c_4),\
+}
+
+#define fteid_to_reg_ct {\
+	.mfield = MLX5_ACTION_IN_FIELD_METADATA_REG_C_5,\
+	.moffset = 0,\
+	.mlen = 4,\
+	.soffset = MLX5_BYTE_OFF(fte_match_param,\
+				 misc_parameters_2.metadata_reg_c_5),\
+}
+
+#if IS_ENABLED(CONFIG_MLX5_TC_CT)
+
+int
+mlx5_tc_ct_init(struct mlx5_rep_uplink_priv *uplink_priv);
+void
+mlx5_tc_ct_clean(struct mlx5_rep_uplink_priv *uplink_priv);
+
+int
+mlx5_tc_ct_parse_match(struct mlx5e_priv *priv,
+		       struct mlx5_flow_spec *spec,
+		       struct flow_cls_offload *f,
+		       struct netlink_ext_ack *extack);
+int
+mlx5_tc_ct_parse_action(struct mlx5e_priv *priv,
+			struct mlx5_esw_flow_attr *attr,
+			const struct flow_action_entry *act,
+			struct netlink_ext_ack *extack);
+
+struct mlx5_flow_handle *
+mlx5_tc_ct_flow_offload(struct mlx5e_priv *priv,
+			struct mlx5e_tc_flow *flow,
+			struct mlx5_flow_spec *spec,
+			struct mlx5_esw_flow_attr *attr);
+void
+mlx5_tc_ct_delete_flow(struct mlx5e_priv *priv,
+		       struct mlx5e_tc_flow *flow,
+		       struct mlx5_esw_flow_attr *attr);
+
+#else /* CONFIG_MLX5_TC_CT */
+
+static inline int
+mlx5_tc_ct_init(struct mlx5_rep_uplink_priv *uplink_priv)
+{
+	return 0;
+}
+
+static inline void
+mlx5_tc_ct_clean(struct mlx5_rep_uplink_priv *uplink_priv)
+{
+}
+
+static inline int
+mlx5_tc_ct_parse_match(struct mlx5e_priv *priv,
+		       struct mlx5_flow_spec *spec,
+		       struct flow_cls_offload *f,
+		       struct netlink_ext_ack *extack)
+{
+	return -EOPNOTSUPP;
+}
+
+static inline int
+mlx5_tc_ct_parse_action(struct mlx5e_priv *priv,
+			struct mlx5_esw_flow_attr *attr,
+			const struct flow_action_entry *act,
+			struct netlink_ext_ack *extack)
+{
+	return -EOPNOTSUPP;
+}
+
+static inline struct mlx5_flow_handle *
+mlx5_tc_ct_flow_offload(struct mlx5e_priv *priv,
+			struct mlx5e_tc_flow *flow,
+			struct mlx5_flow_spec *spec,
+			struct mlx5_esw_flow_attr *attr)
+{
+	return ERR_PTR(-EOPNOTSUPP);
+}
+
+static inline void
+mlx5_tc_ct_delete_flow(struct mlx5e_priv *priv,
+		       struct mlx5e_tc_flow *flow,
+		       struct mlx5_esw_flow_attr *attr)
+{
+}
+
+#endif /* !IS_ENABLED(CONFIG_MLX5_TC_CT) */
+#endif /* __MLX5_EN_TC_CT_H__ */
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_rep.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
