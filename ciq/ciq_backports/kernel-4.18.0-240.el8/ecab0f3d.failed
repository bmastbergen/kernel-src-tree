drm/i915: Track active_pipes in bw_state

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Stanislav Lisovskiy <stanislav.lisovskiy@intel.com>
commit ecab0f3d055d333640bbe2aa5a5141574a65c534
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/ecab0f3d.failed

We need to calculate SAGV mask also in a non-modeset
commit, however currently active_pipes are only calculated
for modesets in global atomic state, thus now we will be
tracking those also in bw_state in order to be able to
properly access global data.

v2: - Removed pre/post plane SAGV updates from modeset(Ville)
    - Now tracking active pipes in intel_can_enable_sagv(Ville)

v3: - lock global state if active_pipes change as well(Ville)

	Signed-off-by: Stanislav Lisovskiy <stanislav.lisovskiy@intel.com>
	Signed-off-by: Ville Syrjälä <ville.syrjala@linux.intel.com>
Link: https://patchwork.freedesktop.org/patch/msgid/20200430195634.7666-1-stanislav.lisovskiy@intel.com
(cherry picked from commit ecab0f3d055d333640bbe2aa5a5141574a65c534)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/i915/display/intel_display.c
#	drivers/gpu/drm/i915/intel_pm.c
diff --cc drivers/gpu/drm/i915/display/intel_display.c
index 5c8c11deb857,268d65e23472..000000000000
--- a/drivers/gpu/drm/i915/display/intel_display.c
+++ b/drivers/gpu/drm/i915/display/intel_display.c
@@@ -13852,30 -15368,24 +13852,36 @@@ static void intel_atomic_commit_tail(st
  		}
  	}
  
 -	intel_commit_modeset_disables(state);
 +	/* FIXME: Eventually get rid of our intel_crtc->config pointer */
 +	for_each_new_crtc_in_state(state, crtc, new_crtc_state, i)
 +		to_intel_crtc(crtc)->config = to_intel_crtc_state(new_crtc_state);
  
 -	/* FIXME: Eventually get rid of our crtc->config pointer */
 -	for_each_new_intel_crtc_in_state(state, crtc, new_crtc_state, i)
 -		crtc->config = new_crtc_state;
 +	if (intel_state->modeset) {
 +		drm_atomic_helper_update_legacy_modeset_state(state->dev, state);
  
 -	if (state->modeset) {
 -		drm_atomic_helper_update_legacy_modeset_state(dev, &state->base);
 +		intel_set_cdclk_pre_plane_update(dev_priv,
 +						 &intel_state->cdclk.actual,
 +						 &dev_priv->cdclk.actual,
 +						 intel_state->cdclk.pipe);
  
 -		intel_set_cdclk_pre_plane_update(state);
 +		/*
 +		 * SKL workaround: bspec recommends we disable the SAGV when we
 +		 * have more then one pipe enabled
 +		 */
 +		if (!intel_can_enable_sagv(state))
 +			intel_disable_sagv(dev_priv);
  
++<<<<<<< HEAD
 +		intel_modeset_verify_disabled(dev, state);
++=======
+ 		intel_modeset_verify_disabled(dev_priv, state);
++>>>>>>> ecab0f3d055d (drm/i915: Track active_pipes in bw_state)
  	}
  
+ 	intel_sagv_pre_plane_update(state);
+ 
  	/* Complete the events for pipes that have now been disabled */
 -	for_each_new_intel_crtc_in_state(state, crtc, new_crtc_state, i) {
 +	for_each_new_crtc_in_state(state, crtc, new_crtc_state, i) {
  		bool modeset = needs_modeset(new_crtc_state);
  
  		/* Complete events for now disable pipes here. */
@@@ -13942,15 -15472,18 +13948,22 @@@
  		intel_modeset_verify_crtc(crtc, state, old_crtc_state, new_crtc_state);
  	}
  
 -	/* Underruns don't always raise interrupts, so check manually */
 -	intel_check_cpu_fifo_underruns(dev_priv);
 -	intel_check_pch_fifo_underruns(dev_priv);
 +	if (intel_state->modeset)
 +		intel_verify_planes(intel_state);
 +
++<<<<<<< HEAD
 +	if (intel_state->modeset && intel_can_enable_sagv(state))
 +		intel_enable_sagv(dev_priv);
  
 +	drm_atomic_helper_commit_hw_done(state);
++=======
+ 	if (state->modeset)
+ 		intel_verify_planes(state);
+ 
+ 	intel_sagv_post_plane_update(state);
++>>>>>>> ecab0f3d055d (drm/i915: Track active_pipes in bw_state)
  
 -	drm_atomic_helper_commit_hw_done(&state->base);
 -
 -	if (state->modeset) {
 +	if (intel_state->modeset) {
  		/* As one of the primary mmio accessors, KMS has a high
  		 * likelihood of triggering bugs in unclaimed access. After we
  		 * finish modesetting, see if an error has been flagged, and if
diff --cc drivers/gpu/drm/i915/intel_pm.c
index 8862271193ca,c26f87427e18..000000000000
--- a/drivers/gpu/drm/i915/intel_pm.c
+++ b/drivers/gpu/drm/i915/intel_pm.c
@@@ -3744,52 -3758,72 +3744,107 @@@ intel_disable_sagv(struct drm_i915_priv
  	return 0;
  }
  
 -void intel_sagv_pre_plane_update(struct intel_atomic_state *state)
 +bool intel_can_enable_sagv(struct drm_atomic_state *state)
  {
++<<<<<<< HEAD
 +	struct drm_device *dev = state->dev;
 +	struct drm_i915_private *dev_priv = to_i915(dev);
 +	struct intel_atomic_state *intel_state = to_intel_atomic_state(state);
 +	struct intel_crtc *crtc;
++=======
+ 	struct drm_i915_private *dev_priv = to_i915(state->base.dev);
+ 	const struct intel_bw_state *new_bw_state;
+ 
+ 	/*
+ 	 * Just return if we can't control SAGV or don't have it.
+ 	 * This is different from situation when we have SAGV but just can't
+ 	 * afford it due to DBuf limitation - in case if SAGV is completely
+ 	 * disabled in a BIOS, we are not even allowed to send a PCode request,
+ 	 * as it will throw an error. So have to check it here.
+ 	 */
+ 	if (!intel_has_sagv(dev_priv))
+ 		return;
+ 
+ 	new_bw_state = intel_atomic_get_new_bw_state(state);
+ 	if (!new_bw_state)
+ 		return;
+ 
+ 	if (!intel_can_enable_sagv(new_bw_state))
+ 		intel_disable_sagv(dev_priv);
+ }
+ 
+ void intel_sagv_post_plane_update(struct intel_atomic_state *state)
+ {
+ 	struct drm_i915_private *dev_priv = to_i915(state->base.dev);
+ 	const struct intel_bw_state *new_bw_state;
+ 
+ 	/*
+ 	 * Just return if we can't control SAGV or don't have it.
+ 	 * This is different from situation when we have SAGV but just can't
+ 	 * afford it due to DBuf limitation - in case if SAGV is completely
+ 	 * disabled in a BIOS, we are not even allowed to send a PCode request,
+ 	 * as it will throw an error. So have to check it here.
+ 	 */
+ 	if (!intel_has_sagv(dev_priv))
+ 		return;
+ 
+ 	new_bw_state = intel_atomic_get_new_bw_state(state);
+ 	if (!new_bw_state)
+ 		return;
+ 
+ 	if (intel_can_enable_sagv(new_bw_state))
+ 		intel_enable_sagv(dev_priv);
+ }
+ 
+ static bool intel_crtc_can_enable_sagv(const struct intel_crtc_state *crtc_state)
+ {
+ 	struct intel_crtc *crtc = to_intel_crtc(crtc_state->uapi.crtc);
+ 	struct drm_i915_private *dev_priv = to_i915(crtc->base.dev);
++>>>>>>> ecab0f3d055d (drm/i915: Track active_pipes in bw_state)
  	struct intel_plane *plane;
 -	const struct intel_plane_state *plane_state;
 +	struct intel_crtc_state *cstate;
 +	enum pipe pipe;
  	int level, latency;
 +	int sagv_block_time_us;
  
  	if (!intel_has_sagv(dev_priv))
  		return false;
  
 -	if (!crtc_state->hw.active)
 +	if (IS_GEN(dev_priv, 9))
 +		sagv_block_time_us = 30;
 +	else if (IS_GEN(dev_priv, 10))
 +		sagv_block_time_us = 20;
 +	else
 +		sagv_block_time_us = 10;
 +
 +	/*
 +	 * If there are no active CRTCs, no additional checks need be performed
 +	 */
 +	if (hweight32(intel_state->active_crtcs) == 0)
  		return true;
  
++<<<<<<< HEAD
 +	/*
 +	 * SKL+ workaround: bspec recommends we disable SAGV when we have
 +	 * more then one pipe enabled
 +	 */
 +	if (hweight32(intel_state->active_crtcs) > 1)
 +		return false;
 +
 +	/* Since we're now guaranteed to only have one active CRTC... */
 +	pipe = ffs(intel_state->active_crtcs) - 1;
 +	crtc = intel_get_crtc_for_pipe(dev_priv, pipe);
 +	cstate = to_intel_crtc_state(crtc->base.state);
 +
 +	if (crtc->base.state->adjusted_mode.flags & DRM_MODE_FLAG_INTERLACE)
++=======
+ 	if (crtc_state->hw.adjusted_mode.flags & DRM_MODE_FLAG_INTERLACE)
++>>>>>>> ecab0f3d055d (drm/i915: Track active_pipes in bw_state)
  		return false;
  
 -	intel_atomic_crtc_state_for_each_plane_state(plane, plane_state, crtc_state) {
 -		const struct skl_plane_wm *wm =
 -			&crtc_state->wm.skl.optimal.planes[plane->id];
 +	for_each_intel_plane_on_crtc(dev, crtc, plane) {
 +		struct skl_plane_wm *wm =
 +			&cstate->wm.skl.optimal.planes[plane->id];
  
  		/* Skip this plane if it's not enabled */
  		if (!wm->wm[0].plane_en)
@@@ -3819,17 -3853,87 +3874,97 @@@
  	return true;
  }
  
++<<<<<<< HEAD
 +static u16 intel_get_ddb_size(struct drm_i915_private *dev_priv,
 +			      const struct intel_crtc_state *cstate,
 +			      const u64 total_data_rate,
 +			      const int num_active,
 +			      struct skl_ddb_allocation *ddb)
++=======
+ bool intel_can_enable_sagv(const struct intel_bw_state *bw_state)
+ {
+ 	if (bw_state->active_pipes && !is_power_of_2(bw_state->active_pipes))
+ 		return false;
+ 
+ 	return bw_state->pipe_sagv_reject == 0;
+ }
+ 
+ static int intel_compute_sagv_mask(struct intel_atomic_state *state)
+ {
+ 	int ret;
+ 	struct intel_crtc *crtc;
+ 	struct intel_crtc_state *new_crtc_state;
+ 	struct intel_bw_state *new_bw_state = NULL;
+ 	const struct intel_bw_state *old_bw_state = NULL;
+ 	int i;
+ 
+ 	for_each_new_intel_crtc_in_state(state, crtc,
+ 					 new_crtc_state, i) {
+ 		new_bw_state = intel_atomic_get_bw_state(state);
+ 		if (IS_ERR(new_bw_state))
+ 			return PTR_ERR(new_bw_state);
+ 
+ 		old_bw_state = intel_atomic_get_old_bw_state(state);
+ 
+ 		if (intel_crtc_can_enable_sagv(new_crtc_state))
+ 			new_bw_state->pipe_sagv_reject &= ~BIT(crtc->pipe);
+ 		else
+ 			new_bw_state->pipe_sagv_reject |= BIT(crtc->pipe);
+ 	}
+ 
+ 	if (!new_bw_state)
+ 		return 0;
+ 
+ 	new_bw_state->active_pipes =
+ 		intel_calc_active_pipes(state, old_bw_state->active_pipes);
+ 	if (new_bw_state->active_pipes != old_bw_state->active_pipes) {
+ 		ret = intel_atomic_lock_global_state(&new_bw_state->base);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	if (intel_can_enable_sagv(new_bw_state) != intel_can_enable_sagv(old_bw_state)) {
+ 		ret = intel_atomic_serialize_global_state(&new_bw_state->base);
+ 		if (ret)
+ 			return ret;
+ 	} else if (new_bw_state->pipe_sagv_reject != old_bw_state->pipe_sagv_reject) {
+ 		ret = intel_atomic_lock_global_state(&new_bw_state->base);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ /*
+  * Calculate initial DBuf slice offset, based on slice size
+  * and mask(i.e if slice size is 1024 and second slice is enabled
+  * offset would be 1024)
+  */
+ static unsigned int
+ icl_get_first_dbuf_slice_offset(u32 dbuf_slice_mask,
+ 				u32 slice_size,
+ 				u32 ddb_size)
+ {
+ 	unsigned int offset = 0;
+ 
+ 	if (!dbuf_slice_mask)
+ 		return 0;
+ 
+ 	offset = (ffs(dbuf_slice_mask) - 1) * slice_size;
+ 
+ 	WARN_ON(offset >= ddb_size);
+ 	return offset;
+ }
+ 
+ static u16 intel_get_ddb_size(struct drm_i915_private *dev_priv)
++>>>>>>> ecab0f3d055d (drm/i915: Track active_pipes in bw_state)
  {
 +	const struct drm_display_mode *adjusted_mode;
 +	u64 total_data_bw;
  	u16 ddb_size = INTEL_INFO(dev_priv)->ddb_size;
  
 -	drm_WARN_ON(&dev_priv->drm, ddb_size == 0);
 +	WARN_ON(ddb_size == 0);
  
  	if (INTEL_GEN(dev_priv) < 11)
  		return ddb_size - 4; /* 4 blocks for bypass path allocation */
@@@ -5673,6 -5869,22 +5808,25 @@@ skl_compute_wm(struct intel_atomic_stat
  	if (ret)
  		return ret;
  
++<<<<<<< HEAD
++=======
+ 	ret = intel_compute_sagv_mask(state);
+ 	if (ret)
+ 		return ret;
+ 
+ 	/*
+ 	 * skl_compute_ddb() will have adjusted the final watermarks
+ 	 * based on how much ddb is available. Now we can actually
+ 	 * check if the final watermarks changed.
+ 	 */
+ 	for_each_oldnew_intel_crtc_in_state(state, crtc, old_crtc_state,
+ 					    new_crtc_state, i) {
+ 		ret = skl_wm_add_affected_planes(state, crtc);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
++>>>>>>> ecab0f3d055d (drm/i915: Track active_pipes in bw_state)
  	skl_print_wm_changes(state);
  
  	return 0;
diff --git a/drivers/gpu/drm/i915/display/intel_bw.h b/drivers/gpu/drm/i915/display/intel_bw.h
index e9d9c6d63bc3..982dcfcd468e 100644
--- a/drivers/gpu/drm/i915/display/intel_bw.h
+++ b/drivers/gpu/drm/i915/display/intel_bw.h
@@ -20,6 +20,9 @@ struct intel_bw_state {
 
 	unsigned int data_rate[I915_MAX_PIPES];
 	u8 num_active_planes[I915_MAX_PIPES];
+
+	/* bitmask of active pipes */
+	u8 active_pipes;
 };
 
 #define to_intel_bw_state(x) container_of((x), struct intel_bw_state, base)
* Unmerged path drivers/gpu/drm/i915/display/intel_display.c
* Unmerged path drivers/gpu/drm/i915/intel_pm.c
