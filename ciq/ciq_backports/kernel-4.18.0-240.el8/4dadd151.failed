net/smc: enqueue local LLC messages

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Karsten Graul <kgraul@linux.ibm.com>
commit 4dadd151b26589fd0520feb97c93ee981b393a99
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/4dadd151.failed

As SMC server, when a second link was deleted, trigger the setup of an
asymmetric link. Do this by enqueueing a local ADD_LINK message which
is processed by the LLC layer as if it were received from peer. Do the
same when a new IB port became active and a new link could be created.
smc_llc_srv_add_link_local() enqueues a local ADD_LINK message.
And smc_llc_srv_delete_link_local() is used the same way to enqueue a
local DELETE_LINK message. This is used when an IB port is no longer
active.

	Signed-off-by: Karsten Graul <kgraul@linux.ibm.com>
	Reviewed-by: Ursula Braun <ubraun@linux.ibm.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 4dadd151b26589fd0520feb97c93ee981b393a99)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/smc/smc_core.c
#	net/smc/smc_llc.c
#	net/smc/smc_llc.h
diff --cc net/smc/smc_core.c
index cf74dd642f9a,32a6cadc5c1f..000000000000
--- a/net/smc/smc_core.c
+++ b/net/smc/smc_core.c
@@@ -943,6 -930,80 +943,83 @@@ void smcr_port_add(struct smc_ib_devic
  	}
  }
  
++<<<<<<< HEAD
++=======
+ /* link is down - switch connections to alternate link,
+  * must be called under lgr->llc_conf_mutex lock
+  */
+ static void smcr_link_down(struct smc_link *lnk)
+ {
+ 	struct smc_link_group *lgr = lnk->lgr;
+ 	struct smc_link *to_lnk;
+ 	int del_link_id;
+ 
+ 	if (!lgr || lnk->state == SMC_LNK_UNUSED || list_empty(&lgr->list))
+ 		return;
+ 
+ 	smc_ib_modify_qp_reset(lnk);
+ 	to_lnk = NULL;
+ 	/* tbd: call to_lnk = smc_switch_conns(lgr, lnk, true); */
+ 	if (!to_lnk) { /* no backup link available */
+ 		smcr_link_clear(lnk);
+ 		return;
+ 	}
+ 	lgr->type = SMC_LGR_SINGLE;
+ 	del_link_id = lnk->link_id;
+ 
+ 	if (lgr->role == SMC_SERV) {
+ 		/* trigger local delete link processing */
+ 		smc_llc_srv_delete_link_local(to_lnk, del_link_id);
+ 	} else {
+ 		if (lgr->llc_flow_lcl.type != SMC_LLC_FLOW_NONE) {
+ 			/* another llc task is ongoing */
+ 			mutex_unlock(&lgr->llc_conf_mutex);
+ 			wait_event_interruptible_timeout(lgr->llc_waiter,
+ 				(lgr->llc_flow_lcl.type == SMC_LLC_FLOW_NONE),
+ 				SMC_LLC_WAIT_TIME);
+ 			mutex_lock(&lgr->llc_conf_mutex);
+ 		}
+ 		smc_llc_send_delete_link(to_lnk, del_link_id, SMC_LLC_REQ, true,
+ 					 SMC_LLC_DEL_LOST_PATH);
+ 	}
+ }
+ 
+ /* must be called under lgr->llc_conf_mutex lock */
+ void smcr_link_down_cond(struct smc_link *lnk)
+ {
+ 	if (smc_link_downing(&lnk->state))
+ 		smcr_link_down(lnk);
+ }
+ 
+ /* will get the lgr->llc_conf_mutex lock */
+ void smcr_link_down_cond_sched(struct smc_link *lnk)
+ {
+ 	if (smc_link_downing(&lnk->state))
+ 		schedule_work(&lnk->link_down_wrk);
+ }
+ 
+ void smcr_port_err(struct smc_ib_device *smcibdev, u8 ibport)
+ {
+ 	struct smc_link_group *lgr, *n;
+ 	int i;
+ 
+ 	list_for_each_entry_safe(lgr, n, &smc_lgr_list.list, list) {
+ 		if (strncmp(smcibdev->pnetid[ibport - 1], lgr->pnet_id,
+ 			    SMC_MAX_PNETID_LEN))
+ 			continue; /* lgr is not affected */
+ 		if (list_empty(&lgr->list))
+ 			continue;
+ 		for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) {
+ 			struct smc_link *lnk = &lgr->lnk[i];
+ 
+ 			if (smc_link_usable(lnk) &&
+ 			    lnk->smcibdev == smcibdev && lnk->ibport == ibport)
+ 				smcr_link_down_cond_sched(lnk);
+ 		}
+ 	}
+ }
+ 
++>>>>>>> 4dadd151b265 (net/smc: enqueue local LLC messages)
  static void smc_link_up_work(struct work_struct *work)
  {
  	struct smc_ib_up_work *ib_work = container_of(work,
diff --cc net/smc/smc_llc.c
index 4119cdb6b6bf,7675ccd6f3c3..000000000000
--- a/net/smc/smc_llc.c
+++ b/net/smc/smc_llc.c
@@@ -134,6 -153,162 +134,165 @@@ union smc_llc_msg 
  
  #define SMC_LLC_FLAG_RESP		0x80
  
++<<<<<<< HEAD
++=======
+ struct smc_llc_qentry {
+ 	struct list_head list;
+ 	struct smc_link *link;
+ 	union smc_llc_msg msg;
+ };
+ 
+ static void smc_llc_enqueue(struct smc_link *link, union smc_llc_msg *llc);
+ 
+ struct smc_llc_qentry *smc_llc_flow_qentry_clr(struct smc_llc_flow *flow)
+ {
+ 	struct smc_llc_qentry *qentry = flow->qentry;
+ 
+ 	flow->qentry = NULL;
+ 	return qentry;
+ }
+ 
+ void smc_llc_flow_qentry_del(struct smc_llc_flow *flow)
+ {
+ 	struct smc_llc_qentry *qentry;
+ 
+ 	if (flow->qentry) {
+ 		qentry = flow->qentry;
+ 		flow->qentry = NULL;
+ 		kfree(qentry);
+ 	}
+ }
+ 
+ static inline void smc_llc_flow_qentry_set(struct smc_llc_flow *flow,
+ 					   struct smc_llc_qentry *qentry)
+ {
+ 	flow->qentry = qentry;
+ }
+ 
+ /* try to start a new llc flow, initiated by an incoming llc msg */
+ static bool smc_llc_flow_start(struct smc_llc_flow *flow,
+ 			       struct smc_llc_qentry *qentry)
+ {
+ 	struct smc_link_group *lgr = qentry->link->lgr;
+ 
+ 	spin_lock_bh(&lgr->llc_flow_lock);
+ 	if (flow->type) {
+ 		/* a flow is already active */
+ 		if ((qentry->msg.raw.hdr.common.type == SMC_LLC_ADD_LINK ||
+ 		     qentry->msg.raw.hdr.common.type == SMC_LLC_DELETE_LINK) &&
+ 		    !lgr->delayed_event) {
+ 			lgr->delayed_event = qentry;
+ 		} else {
+ 			/* forget this llc request */
+ 			kfree(qentry);
+ 		}
+ 		spin_unlock_bh(&lgr->llc_flow_lock);
+ 		return false;
+ 	}
+ 	switch (qentry->msg.raw.hdr.common.type) {
+ 	case SMC_LLC_ADD_LINK:
+ 		flow->type = SMC_LLC_FLOW_ADD_LINK;
+ 		break;
+ 	case SMC_LLC_DELETE_LINK:
+ 		flow->type = SMC_LLC_FLOW_DEL_LINK;
+ 		break;
+ 	case SMC_LLC_CONFIRM_RKEY:
+ 	case SMC_LLC_DELETE_RKEY:
+ 		flow->type = SMC_LLC_FLOW_RKEY;
+ 		break;
+ 	default:
+ 		flow->type = SMC_LLC_FLOW_NONE;
+ 	}
+ 	if (qentry == lgr->delayed_event)
+ 		lgr->delayed_event = NULL;
+ 	spin_unlock_bh(&lgr->llc_flow_lock);
+ 	smc_llc_flow_qentry_set(flow, qentry);
+ 	return true;
+ }
+ 
+ /* start a new local llc flow, wait till current flow finished */
+ int smc_llc_flow_initiate(struct smc_link_group *lgr,
+ 			  enum smc_llc_flowtype type)
+ {
+ 	enum smc_llc_flowtype allowed_remote = SMC_LLC_FLOW_NONE;
+ 	int rc;
+ 
+ 	/* all flows except confirm_rkey and delete_rkey are exclusive,
+ 	 * confirm/delete rkey flows can run concurrently (local and remote)
+ 	 */
+ 	if (type == SMC_LLC_FLOW_RKEY)
+ 		allowed_remote = SMC_LLC_FLOW_RKEY;
+ again:
+ 	if (list_empty(&lgr->list))
+ 		return -ENODEV;
+ 	spin_lock_bh(&lgr->llc_flow_lock);
+ 	if (lgr->llc_flow_lcl.type == SMC_LLC_FLOW_NONE &&
+ 	    (lgr->llc_flow_rmt.type == SMC_LLC_FLOW_NONE ||
+ 	     lgr->llc_flow_rmt.type == allowed_remote)) {
+ 		lgr->llc_flow_lcl.type = type;
+ 		spin_unlock_bh(&lgr->llc_flow_lock);
+ 		return 0;
+ 	}
+ 	spin_unlock_bh(&lgr->llc_flow_lock);
+ 	rc = wait_event_interruptible_timeout(lgr->llc_waiter,
+ 			(lgr->llc_flow_lcl.type == SMC_LLC_FLOW_NONE &&
+ 			 (lgr->llc_flow_rmt.type == SMC_LLC_FLOW_NONE ||
+ 			  lgr->llc_flow_rmt.type == allowed_remote)),
+ 			SMC_LLC_WAIT_TIME);
+ 	if (!rc)
+ 		return -ETIMEDOUT;
+ 	goto again;
+ }
+ 
+ /* finish the current llc flow */
+ void smc_llc_flow_stop(struct smc_link_group *lgr, struct smc_llc_flow *flow)
+ {
+ 	spin_lock_bh(&lgr->llc_flow_lock);
+ 	memset(flow, 0, sizeof(*flow));
+ 	flow->type = SMC_LLC_FLOW_NONE;
+ 	spin_unlock_bh(&lgr->llc_flow_lock);
+ 	if (!list_empty(&lgr->list) && lgr->delayed_event &&
+ 	    flow == &lgr->llc_flow_lcl)
+ 		schedule_work(&lgr->llc_event_work);
+ 	else
+ 		wake_up_interruptible(&lgr->llc_waiter);
+ }
+ 
+ /* lnk is optional and used for early wakeup when link goes down, useful in
+  * cases where we wait for a response on the link after we sent a request
+  */
+ struct smc_llc_qentry *smc_llc_wait(struct smc_link_group *lgr,
+ 				    struct smc_link *lnk,
+ 				    int time_out, u8 exp_msg)
+ {
+ 	struct smc_llc_flow *flow = &lgr->llc_flow_lcl;
+ 
+ 	wait_event_interruptible_timeout(lgr->llc_waiter,
+ 					 (flow->qentry ||
+ 					  (lnk && !smc_link_usable(lnk)) ||
+ 					  list_empty(&lgr->list)),
+ 					 time_out);
+ 	if (!flow->qentry ||
+ 	    (lnk && !smc_link_usable(lnk)) || list_empty(&lgr->list)) {
+ 		smc_llc_flow_qentry_del(flow);
+ 		goto out;
+ 	}
+ 	if (exp_msg && flow->qentry->msg.raw.hdr.common.type != exp_msg) {
+ 		if (exp_msg == SMC_LLC_ADD_LINK &&
+ 		    flow->qentry->msg.raw.hdr.common.type ==
+ 		    SMC_LLC_DELETE_LINK) {
+ 			/* flow_start will delay the unexpected msg */
+ 			smc_llc_flow_start(&lgr->llc_flow_lcl,
+ 					   smc_llc_flow_qentry_clr(flow));
+ 			return NULL;
+ 		}
+ 		smc_llc_flow_qentry_del(flow);
+ 	}
+ out:
+ 	return flow->qentry;
+ }
+ 
++>>>>>>> 4dadd151b265 (net/smc: enqueue local LLC messages)
  /********************************** send *************************************/
  
  struct smc_llc_tx_pend {
@@@ -398,137 -781,572 +557,581 @@@ static int smc_llc_send_message(struct 
  	return 0;
  }
  
 -static void smc_llc_save_add_link_info(struct smc_link *link,
 -				       struct smc_llc_msg_add_link *add_llc)
 -{
 -	link->peer_qpn = ntoh24(add_llc->sender_qp_num);
 -	memcpy(link->peer_gid, add_llc->sender_gid, SMC_GID_SIZE);
 -	memcpy(link->peer_mac, add_llc->sender_mac, ETH_ALEN);
 -	link->peer_psn = ntoh24(add_llc->initial_psn);
 -	link->peer_mtu = add_llc->qp_mtu;
 -}
 +/********************************* receive ***********************************/
  
 -/* as an SMC client, process an add link request */
 -int smc_llc_cli_add_link(struct smc_link *link, struct smc_llc_qentry *qentry)
 +static void smc_llc_rx_confirm_link(struct smc_link *link,
 +				    struct smc_llc_msg_confirm_link *llc)
  {
 -	struct smc_llc_msg_add_link *llc = &qentry->msg.add_link;
 -	enum smc_lgr_type lgr_new_t = SMC_LGR_SYMMETRIC;
  	struct smc_link_group *lgr = smc_get_lgr(link);
 -	struct smc_link *lnk_new = NULL;
 -	struct smc_init_info ini;
 -	int lnk_idx, rc = 0;
 +	int conf_rc;
  
++<<<<<<< HEAD
 +	/* RMBE eyecatchers are not supported */
 +	if (llc->hd.flags & SMC_LLC_FLAG_NO_RMBE_EYEC)
 +		conf_rc = 0;
++=======
+ 	ini.vlan_id = lgr->vlan_id;
+ 	smc_pnet_find_alt_roce(lgr, &ini, link->smcibdev);
+ 	if (!memcmp(llc->sender_gid, link->peer_gid, SMC_GID_SIZE) &&
+ 	    !memcmp(llc->sender_mac, link->peer_mac, ETH_ALEN)) {
+ 		if (!ini.ib_dev)
+ 			goto out_reject;
+ 		lgr_new_t = SMC_LGR_ASYMMETRIC_PEER;
+ 	}
+ 	if (!ini.ib_dev) {
+ 		lgr_new_t = SMC_LGR_ASYMMETRIC_LOCAL;
+ 		ini.ib_dev = link->smcibdev;
+ 		ini.ib_port = link->ibport;
+ 	}
+ 	lnk_idx = smc_llc_alloc_alt_link(lgr, lgr_new_t);
+ 	if (lnk_idx < 0)
+ 		goto out_reject;
+ 	lnk_new = &lgr->lnk[lnk_idx];
+ 	rc = smcr_link_init(lgr, lnk_new, lnk_idx, &ini);
+ 	if (rc)
+ 		goto out_reject;
+ 	smc_llc_save_add_link_info(lnk_new, llc);
+ 	lnk_new->link_id = llc->link_num;
+ 
+ 	rc = smc_ib_ready_link(lnk_new);
+ 	if (rc)
+ 		goto out_clear_lnk;
+ 
+ 	rc = smcr_buf_map_lgr(lnk_new);
+ 	if (rc)
+ 		goto out_clear_lnk;
+ 
+ 	rc = smc_llc_send_add_link(link,
+ 				   lnk_new->smcibdev->mac[ini.ib_port - 1],
+ 				   lnk_new->gid, lnk_new, SMC_LLC_RESP);
+ 	if (rc)
+ 		goto out_clear_lnk;
+ 	rc = smc_llc_cli_rkey_exchange(link, lnk_new);
+ 	if (rc) {
+ 		rc = 0;
+ 		goto out_clear_lnk;
+ 	}
+ 	rc = smc_llc_cli_conf_link(link, &ini, lnk_new, lgr_new_t);
+ 	if (!rc)
+ 		goto out;
+ out_clear_lnk:
+ 	smcr_link_clear(lnk_new);
+ out_reject:
+ 	smc_llc_cli_add_link_reject(qentry);
+ out:
+ 	kfree(qentry);
+ 	return rc;
+ }
+ 
+ static void smc_llc_process_cli_add_link(struct smc_link_group *lgr)
+ {
+ 	struct smc_llc_qentry *qentry;
+ 
+ 	qentry = smc_llc_flow_qentry_clr(&lgr->llc_flow_lcl);
+ 
+ 	mutex_lock(&lgr->llc_conf_mutex);
+ 	smc_llc_cli_add_link(qentry->link, qentry);
+ 	mutex_unlock(&lgr->llc_conf_mutex);
+ }
+ 
+ static int smc_llc_active_link_count(struct smc_link_group *lgr)
+ {
+ 	int i, link_count = 0;
+ 
+ 	for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) {
+ 		if (!smc_link_usable(&lgr->lnk[i]))
+ 			continue;
+ 		link_count++;
+ 	}
+ 	return link_count;
+ }
+ 
+ /* find the asymmetric link when 3 links are established  */
+ static struct smc_link *smc_llc_find_asym_link(struct smc_link_group *lgr)
+ {
+ 	int asym_idx = -ENOENT;
+ 	int i, j, k;
+ 	bool found;
+ 
+ 	/* determine asymmetric link */
+ 	found = false;
+ 	for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) {
+ 		for (j = i + 1; j < SMC_LINKS_PER_LGR_MAX; j++) {
+ 			if (!smc_link_usable(&lgr->lnk[i]) ||
+ 			    !smc_link_usable(&lgr->lnk[j]))
+ 				continue;
+ 			if (!memcmp(lgr->lnk[i].gid, lgr->lnk[j].gid,
+ 				    SMC_GID_SIZE)) {
+ 				found = true;	/* asym_lnk is i or j */
+ 				break;
+ 			}
+ 		}
+ 		if (found)
+ 			break;
+ 	}
+ 	if (!found)
+ 		goto out; /* no asymmetric link */
+ 	for (k = 0; k < SMC_LINKS_PER_LGR_MAX; k++) {
+ 		if (!smc_link_usable(&lgr->lnk[k]))
+ 			continue;
+ 		if (k != i &&
+ 		    !memcmp(lgr->lnk[i].peer_gid, lgr->lnk[k].peer_gid,
+ 			    SMC_GID_SIZE)) {
+ 			asym_idx = i;
+ 			break;
+ 		}
+ 		if (k != j &&
+ 		    !memcmp(lgr->lnk[j].peer_gid, lgr->lnk[k].peer_gid,
+ 			    SMC_GID_SIZE)) {
+ 			asym_idx = j;
+ 			break;
+ 		}
+ 	}
+ out:
+ 	return (asym_idx < 0) ? NULL : &lgr->lnk[asym_idx];
+ }
+ 
+ static void smc_llc_delete_asym_link(struct smc_link_group *lgr)
+ {
+ 	struct smc_link *lnk_new = NULL, *lnk_asym;
+ 	struct smc_llc_qentry *qentry;
+ 	int rc;
+ 
+ 	lnk_asym = smc_llc_find_asym_link(lgr);
+ 	if (!lnk_asym)
+ 		return; /* no asymmetric link */
+ 	if (!smc_link_downing(&lnk_asym->state))
+ 		return;
+ 	/* tbd: lnk_new = smc_switch_conns(lgr, lnk_asym, false); */
+ 	smc_wr_tx_wait_no_pending_sends(lnk_asym);
+ 	if (!lnk_new)
+ 		goto out_free;
+ 	/* change flow type from ADD_LINK into DEL_LINK */
+ 	lgr->llc_flow_lcl.type = SMC_LLC_FLOW_DEL_LINK;
+ 	rc = smc_llc_send_delete_link(lnk_new, lnk_asym->link_id, SMC_LLC_REQ,
+ 				      true, SMC_LLC_DEL_NO_ASYM_NEEDED);
+ 	if (rc) {
+ 		smcr_link_down_cond(lnk_new);
+ 		goto out_free;
+ 	}
+ 	qentry = smc_llc_wait(lgr, lnk_new, SMC_LLC_WAIT_TIME,
+ 			      SMC_LLC_DELETE_LINK);
+ 	if (!qentry) {
+ 		smcr_link_down_cond(lnk_new);
+ 		goto out_free;
+ 	}
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ out_free:
+ 	smcr_link_clear(lnk_asym);
+ }
+ 
+ static int smc_llc_srv_rkey_exchange(struct smc_link *link,
+ 				     struct smc_link *link_new)
+ {
+ 	struct smc_llc_msg_add_link_cont *addc_llc;
+ 	struct smc_link_group *lgr = link->lgr;
+ 	u8 max, num_rkeys_send, num_rkeys_recv;
+ 	struct smc_llc_qentry *qentry = NULL;
+ 	struct smc_buf_desc *buf_pos;
+ 	int buf_lst;
+ 	int rc = 0;
+ 	int i;
+ 
+ 	mutex_lock(&lgr->rmbs_lock);
+ 	num_rkeys_send = lgr->conns_num;
+ 	buf_pos = smc_llc_get_first_rmb(lgr, &buf_lst);
+ 	do {
+ 		smc_llc_add_link_cont(link, link_new, &num_rkeys_send,
+ 				      &buf_lst, &buf_pos);
+ 		qentry = smc_llc_wait(lgr, link, SMC_LLC_WAIT_TIME,
+ 				      SMC_LLC_ADD_LINK_CONT);
+ 		if (!qentry) {
+ 			rc = -ETIMEDOUT;
+ 			goto out;
+ 		}
+ 		addc_llc = &qentry->msg.add_link_cont;
+ 		num_rkeys_recv = addc_llc->num_rkeys;
+ 		max = min_t(u8, num_rkeys_recv, SMC_LLC_RKEYS_PER_CONT_MSG);
+ 		for (i = 0; i < max; i++) {
+ 			smc_rtoken_set(lgr, link->link_idx, link_new->link_idx,
+ 				       addc_llc->rt[i].rmb_key,
+ 				       addc_llc->rt[i].rmb_vaddr_new,
+ 				       addc_llc->rt[i].rmb_key_new);
+ 			num_rkeys_recv--;
+ 		}
+ 		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 	} while (num_rkeys_send || num_rkeys_recv);
+ out:
+ 	mutex_unlock(&lgr->rmbs_lock);
+ 	return rc;
+ }
+ 
+ static int smc_llc_srv_conf_link(struct smc_link *link,
+ 				 struct smc_link *link_new,
+ 				 enum smc_lgr_type lgr_new_t)
+ {
+ 	struct smc_link_group *lgr = link->lgr;
+ 	struct smc_llc_qentry *qentry = NULL;
+ 	int rc;
+ 
+ 	/* send CONFIRM LINK request over the RoCE fabric */
+ 	rc = smc_llc_send_confirm_link(link_new, SMC_LLC_REQ);
+ 	if (rc)
+ 		return -ENOLINK;
+ 	/* receive CONFIRM LINK response over the RoCE fabric */
+ 	qentry = smc_llc_wait(lgr, link, SMC_LLC_WAIT_FIRST_TIME,
+ 			      SMC_LLC_CONFIRM_LINK);
+ 	if (!qentry) {
+ 		/* send DELETE LINK */
+ 		smc_llc_send_delete_link(link, link_new->link_id, SMC_LLC_REQ,
+ 					 false, SMC_LLC_DEL_LOST_PATH);
+ 		return -ENOLINK;
+ 	}
+ 	smc_llc_link_active(link_new);
+ 	lgr->type = lgr_new_t;
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 	return 0;
+ }
+ 
+ int smc_llc_srv_add_link(struct smc_link *link)
+ {
+ 	enum smc_lgr_type lgr_new_t = SMC_LGR_SYMMETRIC;
+ 	struct smc_link_group *lgr = link->lgr;
+ 	struct smc_llc_msg_add_link *add_llc;
+ 	struct smc_llc_qentry *qentry = NULL;
+ 	struct smc_link *link_new;
+ 	struct smc_init_info ini;
+ 	int lnk_idx, rc = 0;
+ 
+ 	/* ignore client add link recommendation, start new flow */
+ 	ini.vlan_id = lgr->vlan_id;
+ 	smc_pnet_find_alt_roce(lgr, &ini, link->smcibdev);
+ 	if (!ini.ib_dev) {
+ 		lgr_new_t = SMC_LGR_ASYMMETRIC_LOCAL;
+ 		ini.ib_dev = link->smcibdev;
+ 		ini.ib_port = link->ibport;
+ 	}
+ 	lnk_idx = smc_llc_alloc_alt_link(lgr, lgr_new_t);
+ 	if (lnk_idx < 0)
+ 		return 0;
+ 
+ 	rc = smcr_link_init(lgr, &lgr->lnk[lnk_idx], lnk_idx, &ini);
+ 	if (rc)
+ 		return rc;
+ 	link_new = &lgr->lnk[lnk_idx];
+ 	rc = smc_llc_send_add_link(link,
+ 				   link_new->smcibdev->mac[ini.ib_port - 1],
+ 				   link_new->gid, link_new, SMC_LLC_REQ);
+ 	if (rc)
+ 		goto out_err;
+ 	/* receive ADD LINK response over the RoCE fabric */
+ 	qentry = smc_llc_wait(lgr, link, SMC_LLC_WAIT_TIME, SMC_LLC_ADD_LINK);
+ 	if (!qentry) {
+ 		rc = -ETIMEDOUT;
+ 		goto out_err;
+ 	}
+ 	add_llc = &qentry->msg.add_link;
+ 	if (add_llc->hd.flags & SMC_LLC_FLAG_ADD_LNK_REJ) {
+ 		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 		rc = -ENOLINK;
+ 		goto out_err;
+ 	}
+ 	if (lgr->type == SMC_LGR_SINGLE &&
+ 	    (!memcmp(add_llc->sender_gid, link->peer_gid, SMC_GID_SIZE) &&
+ 	     !memcmp(add_llc->sender_mac, link->peer_mac, ETH_ALEN))) {
+ 		lgr_new_t = SMC_LGR_ASYMMETRIC_PEER;
+ 	}
+ 	smc_llc_save_add_link_info(link_new, add_llc);
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 
+ 	rc = smc_ib_ready_link(link_new);
+ 	if (rc)
+ 		goto out_err;
+ 	rc = smcr_buf_map_lgr(link_new);
+ 	if (rc)
+ 		goto out_err;
+ 	rc = smcr_buf_reg_lgr(link_new);
+ 	if (rc)
+ 		goto out_err;
+ 	rc = smc_llc_srv_rkey_exchange(link, link_new);
+ 	if (rc)
+ 		goto out_err;
+ 	rc = smc_llc_srv_conf_link(link, link_new, lgr_new_t);
+ 	if (rc)
+ 		goto out_err;
+ 	return 0;
+ out_err:
+ 	smcr_link_clear(link_new);
+ 	return rc;
+ }
+ 
+ static void smc_llc_process_srv_add_link(struct smc_link_group *lgr)
+ {
+ 	struct smc_link *link = lgr->llc_flow_lcl.qentry->link;
+ 	int rc;
+ 
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 
+ 	mutex_lock(&lgr->llc_conf_mutex);
+ 	rc = smc_llc_srv_add_link(link);
+ 	if (!rc && lgr->type == SMC_LGR_SYMMETRIC) {
+ 		/* delete any asymmetric link */
+ 		smc_llc_delete_asym_link(lgr);
+ 	}
+ 	mutex_unlock(&lgr->llc_conf_mutex);
+ }
+ 
+ /* enqueue a local add_link req to trigger a new add_link flow, only as SERV */
+ void smc_llc_srv_add_link_local(struct smc_link *link)
+ {
+ 	struct smc_llc_msg_add_link add_llc = {0};
+ 
+ 	add_llc.hd.length = sizeof(add_llc);
+ 	add_llc.hd.common.type = SMC_LLC_ADD_LINK;
+ 	/* no dev and port needed, we as server ignore client data anyway */
+ 	smc_llc_enqueue(link, (union smc_llc_msg *)&add_llc);
+ }
+ 
+ /* worker to process an add link message */
+ static void smc_llc_add_link_work(struct work_struct *work)
+ {
+ 	struct smc_link_group *lgr = container_of(work, struct smc_link_group,
+ 						  llc_add_link_work);
+ 
+ 	if (list_empty(&lgr->list)) {
+ 		/* link group is terminating */
+ 		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 		goto out;
+ 	}
+ 
+ 	if (lgr->role == SMC_CLNT)
+ 		smc_llc_process_cli_add_link(lgr);
++>>>>>>> 4dadd151b265 (net/smc: enqueue local LLC messages)
  	else
 -		smc_llc_process_srv_add_link(lgr);
 -out:
 -	smc_llc_flow_stop(lgr, &lgr->llc_flow_lcl);
 -}
 -
 +		conf_rc = ENOTSUPP;
 +
++<<<<<<< HEAD
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (lgr->role == SMC_SERV &&
 +		    link->state == SMC_LNK_ACTIVATING) {
 +			link->llc_confirm_resp_rc = conf_rc;
 +			complete(&link->llc_confirm_resp);
 +		}
 +	} else {
 +		if (lgr->role == SMC_CLNT &&
 +		    link->state == SMC_LNK_ACTIVATING) {
 +			link->llc_confirm_rc = conf_rc;
 +			link->link_id = llc->link_num;
 +			complete(&link->llc_confirm);
++=======
+ /* enqueue a local del_link msg to trigger a new del_link flow,
+  * called only for role SMC_SERV
+  */
+ void smc_llc_srv_delete_link_local(struct smc_link *link, u8 del_link_id)
+ {
+ 	struct smc_llc_msg_del_link del_llc = {0};
+ 
+ 	del_llc.hd.length = sizeof(del_llc);
+ 	del_llc.hd.common.type = SMC_LLC_DELETE_LINK;
+ 	del_llc.link_num = del_link_id;
+ 	del_llc.reason = htonl(SMC_LLC_DEL_LOST_PATH);
+ 	del_llc.hd.flags |= SMC_LLC_FLAG_DEL_LINK_ORDERLY;
+ 	smc_llc_enqueue(link, (union smc_llc_msg *)&del_llc);
+ }
+ 
+ static void smc_llc_process_cli_delete_link(struct smc_link_group *lgr)
+ {
+ 	struct smc_link *lnk_del = NULL, *lnk_asym, *lnk;
+ 	struct smc_llc_msg_del_link *del_llc;
+ 	struct smc_llc_qentry *qentry;
+ 	int active_links;
+ 	int lnk_idx;
+ 
+ 	qentry = smc_llc_flow_qentry_clr(&lgr->llc_flow_lcl);
+ 	lnk = qentry->link;
+ 	del_llc = &qentry->msg.delete_link;
+ 
+ 	if (del_llc->hd.flags & SMC_LLC_FLAG_DEL_LINK_ALL) {
+ 		smc_lgr_terminate_sched(lgr);
+ 		goto out;
+ 	}
+ 	mutex_lock(&lgr->llc_conf_mutex);
+ 	/* delete single link */
+ 	for (lnk_idx = 0; lnk_idx < SMC_LINKS_PER_LGR_MAX; lnk_idx++) {
+ 		if (lgr->lnk[lnk_idx].link_id != del_llc->link_num)
+ 			continue;
+ 		lnk_del = &lgr->lnk[lnk_idx];
+ 		break;
+ 	}
+ 	del_llc->hd.flags |= SMC_LLC_FLAG_RESP;
+ 	if (!lnk_del) {
+ 		/* link was not found */
+ 		del_llc->reason = htonl(SMC_LLC_DEL_NOLNK);
+ 		smc_llc_send_message(lnk, &qentry->msg);
+ 		goto out_unlock;
+ 	}
+ 	lnk_asym = smc_llc_find_asym_link(lgr);
+ 
+ 	del_llc->reason = 0;
+ 	smc_llc_send_message(lnk, &qentry->msg); /* response */
+ 
+ 	if (smc_link_downing(&lnk_del->state)) {
+ 		/* tbd: call smc_switch_conns(lgr, lnk_del, false); */
+ 		smc_wr_tx_wait_no_pending_sends(lnk_del);
+ 	}
+ 	smcr_link_clear(lnk_del);
+ 
+ 	active_links = smc_llc_active_link_count(lgr);
+ 	if (lnk_del == lnk_asym) {
+ 		/* expected deletion of asym link, don't change lgr state */
+ 	} else if (active_links == 1) {
+ 		lgr->type = SMC_LGR_SINGLE;
+ 	} else if (!active_links) {
+ 		lgr->type = SMC_LGR_NONE;
+ 		smc_lgr_terminate_sched(lgr);
+ 	}
+ out_unlock:
+ 	mutex_unlock(&lgr->llc_conf_mutex);
+ out:
+ 	kfree(qentry);
+ }
+ 
+ static void smc_llc_process_srv_delete_link(struct smc_link_group *lgr)
+ {
+ 	struct smc_llc_msg_del_link *del_llc;
+ 	struct smc_link *lnk, *lnk_del;
+ 	struct smc_llc_qentry *qentry;
+ 	int active_links;
+ 	int i;
+ 
+ 	mutex_lock(&lgr->llc_conf_mutex);
+ 	qentry = smc_llc_flow_qentry_clr(&lgr->llc_flow_lcl);
+ 	lnk = qentry->link;
+ 	del_llc = &qentry->msg.delete_link;
+ 
+ 	if (qentry->msg.delete_link.hd.flags & SMC_LLC_FLAG_DEL_LINK_ALL) {
+ 		/* delete entire lgr */
+ 		smc_lgr_terminate_sched(lgr);
+ 		goto out;
+ 	}
+ 	/* delete single link */
+ 	lnk_del = NULL;
+ 	for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) {
+ 		if (lgr->lnk[i].link_id == del_llc->link_num) {
+ 			lnk_del = &lgr->lnk[i];
+ 			break;
++>>>>>>> 4dadd151b265 (net/smc: enqueue local LLC messages)
  		}
  	}
 -	if (!lnk_del)
 -		goto out; /* asymmetric link already deleted */
 +}
  
 -	if (smc_link_downing(&lnk_del->state)) {
 -		/* tbd: call smc_switch_conns(lgr, lnk_del, false); */
 -		smc_wr_tx_wait_no_pending_sends(lnk_del);
 -	}
 -	if (!list_empty(&lgr->list)) {
 -		/* qentry is either a request from peer (send it back to
 -		 * initiate the DELETE_LINK processing), or a locally
 -		 * enqueued DELETE_LINK request (forward it)
 -		 */
 -		if (!smc_llc_send_message(lnk, &qentry->msg)) {
 -			struct smc_llc_msg_del_link *del_llc_resp;
 -			struct smc_llc_qentry *qentry2;
 -
 -			qentry2 = smc_llc_wait(lgr, lnk, SMC_LLC_WAIT_TIME,
 -					       SMC_LLC_DELETE_LINK);
 -			if (!qentry2) {
 -			} else {
 -				del_llc_resp = &qentry2->msg.delete_link;
 -				smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
 -			}
 +static void smc_llc_rx_add_link(struct smc_link *link,
 +				struct smc_llc_msg_add_link *llc)
 +{
 +	struct smc_link_group *lgr = smc_get_lgr(link);
 +
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (link->state == SMC_LNK_ACTIVATING)
 +			complete(&link->llc_add_resp);
 +	} else {
 +		if (link->state == SMC_LNK_ACTIVATING) {
 +			complete(&link->llc_add);
 +			return;
 +		}
 +
 +		if (lgr->role == SMC_SERV) {
 +			smc_llc_prep_add_link(llc, link,
 +					link->smcibdev->mac[link->ibport - 1],
 +					link->gid, SMC_LLC_REQ);
 +
 +		} else {
 +			smc_llc_prep_add_link(llc, link,
 +					link->smcibdev->mac[link->ibport - 1],
 +					link->gid, SMC_LLC_RESP);
  		}
 +		smc_llc_send_message(link, llc, sizeof(*llc));
  	}
 -	smcr_link_clear(lnk_del);
 +}
  
 -	active_links = smc_llc_active_link_count(lgr);
 -	if (active_links == 1) {
 -		lgr->type = SMC_LGR_SINGLE;
 -	} else if (!active_links) {
 -		lgr->type = SMC_LGR_NONE;
 +static void smc_llc_rx_delete_link(struct smc_link *link,
 +				   struct smc_llc_msg_del_link *llc)
 +{
 +	struct smc_link_group *lgr = smc_get_lgr(link);
 +
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (lgr->role == SMC_SERV)
 +			smc_lgr_schedule_free_work_fast(lgr);
 +	} else {
 +		smc_lgr_forget(lgr);
 +		smc_llc_link_deleting(link);
 +		if (lgr->role == SMC_SERV) {
 +			/* client asks to delete this link, send request */
 +			smc_llc_prep_delete_link(llc, link, SMC_LLC_REQ, true);
 +		} else {
 +			/* server requests to delete this link, send response */
 +			smc_llc_prep_delete_link(llc, link, SMC_LLC_RESP, true);
 +		}
 +		smc_llc_send_message(link, llc, sizeof(*llc));
  		smc_lgr_terminate_sched(lgr);
  	}
 +}
  
++<<<<<<< HEAD
 +static void smc_llc_rx_test_link(struct smc_link *link,
 +				 struct smc_llc_msg_test_link *llc)
 +{
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (link->state == SMC_LNK_ACTIVE)
 +			complete(&link->llc_testlink_resp);
 +	} else {
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
++=======
+ 	if (lgr->type == SMC_LGR_SINGLE && !list_empty(&lgr->list)) {
+ 		/* trigger setup of asymm alt link */
+ 		smc_llc_srv_add_link_local(lnk);
++>>>>>>> 4dadd151b265 (net/smc: enqueue local LLC messages)
  	}
 -out:
 -	mutex_unlock(&lgr->llc_conf_mutex);
 -	kfree(qentry);
  }
  
 -static void smc_llc_delete_link_work(struct work_struct *work)
 +static void smc_llc_rx_confirm_rkey(struct smc_link *link,
 +				    struct smc_llc_msg_confirm_rkey *llc)
  {
 -	struct smc_link_group *lgr = container_of(work, struct smc_link_group,
 -						  llc_del_link_work);
 +	int rc;
  
 -	if (list_empty(&lgr->list)) {
 -		/* link group is terminating */
 -		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
 -		goto out;
 -	}
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		link->llc_confirm_rkey_rc = llc->hd.flags &
 +					    SMC_LLC_FLAG_RKEY_NEG;
 +		complete(&link->llc_confirm_rkey);
 +	} else {
 +		rc = smc_rtoken_add(link,
 +				    llc->rtoken[0].rmb_vaddr,
 +				    llc->rtoken[0].rmb_key);
  
 -	if (lgr->role == SMC_CLNT)
 -		smc_llc_process_cli_delete_link(lgr);
 -	else
 -		smc_llc_process_srv_delete_link(lgr);
 -out:
 -	smc_llc_flow_stop(lgr, &lgr->llc_flow_lcl);
 +		/* ignore rtokens for other links, we have only one link */
 +
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		if (rc < 0)
 +			llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +	}
  }
  
 -/* process a confirm_rkey request from peer, remote flow */
 -static void smc_llc_rmt_conf_rkey(struct smc_link_group *lgr)
 +static void smc_llc_rx_confirm_rkey_cont(struct smc_link *link,
 +				      struct smc_llc_msg_confirm_rkey_cont *llc)
  {
 -	struct smc_llc_msg_confirm_rkey *llc;
 -	struct smc_llc_qentry *qentry;
 -	struct smc_link *link;
 -	int num_entries;
 -	int rk_idx;
 -	int i;
 -
 -	qentry = lgr->llc_flow_rmt.qentry;
 -	llc = &qentry->msg.confirm_rkey;
 -	link = qentry->link;
 -
 -	num_entries = llc->rtoken[0].num_rkeys;
 -	/* first rkey entry is for receiving link */
 -	rk_idx = smc_rtoken_add(link,
 -				llc->rtoken[0].rmb_vaddr,
 -				llc->rtoken[0].rmb_key);
 -	if (rk_idx < 0)
 -		goto out_err;
 -
 -	for (i = 1; i <= min_t(u8, num_entries, SMC_LLC_RKEYS_PER_MSG - 1); i++)
 -		smc_rtoken_set2(lgr, rk_idx, llc->rtoken[i].link_id,
 -				llc->rtoken[i].rmb_vaddr,
 -				llc->rtoken[i].rmb_key);
 -	/* max links is 3 so there is no need to support conf_rkey_cont msgs */
 -	goto out;
 -out_err:
 -	llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 -	llc->hd.flags |= SMC_LLC_FLAG_RKEY_RETRY;
 -out:
 -	llc->hd.flags |= SMC_LLC_FLAG_RESP;
 -	smc_llc_send_message(link, &qentry->msg);
 -	smc_llc_flow_qentry_del(&lgr->llc_flow_rmt);
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		/* unused as long as we don't send this type of msg */
 +	} else {
 +		/* ignore rtokens for other links, we have only one link */
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +	}
  }
  
 -/* process a delete_rkey request from peer, remote flow */
 -static void smc_llc_rmt_delete_rkey(struct smc_link_group *lgr)
 +static void smc_llc_rx_delete_rkey(struct smc_link *link,
 +				   struct smc_llc_msg_delete_rkey *llc)
  {
 -	struct smc_llc_msg_delete_rkey *llc;
 -	struct smc_llc_qentry *qentry;
 -	struct smc_link *link;
  	u8 err_mask = 0;
  	int i, max;
  
diff --cc net/smc/smc_llc.h
index 461c0c3ef76e,c335fc5f363c..000000000000
--- a/net/smc/smc_llc.h
+++ b/net/smc/smc_llc.h
@@@ -39,18 -64,34 +39,43 @@@ enum smc_llc_msg_type 
  int smc_llc_send_confirm_link(struct smc_link *lnk,
  			      enum smc_llc_reqresp reqresp);
  int smc_llc_send_add_link(struct smc_link *link, u8 mac[], u8 gid[],
 -			  struct smc_link *link_new,
  			  enum smc_llc_reqresp reqresp);
++<<<<<<< HEAD
 +int smc_llc_send_delete_link(struct smc_link *link,
 +			     enum smc_llc_reqresp reqresp, bool orderly);
++=======
+ int smc_llc_send_delete_link(struct smc_link *link, u8 link_del_id,
+ 			     enum smc_llc_reqresp reqresp, bool orderly,
+ 			     u32 reason);
+ void smc_llc_srv_delete_link_local(struct smc_link *link, u8 del_link_id);
+ void smc_llc_lgr_init(struct smc_link_group *lgr, struct smc_sock *smc);
+ void smc_llc_lgr_clear(struct smc_link_group *lgr);
++>>>>>>> 4dadd151b265 (net/smc: enqueue local LLC messages)
  int smc_llc_link_init(struct smc_link *link);
 -void smc_llc_link_active(struct smc_link *link);
 +void smc_llc_link_active(struct smc_link *link, int testlink_time);
 +void smc_llc_link_deleting(struct smc_link *link);
 +void smc_llc_link_inactive(struct smc_link *link);
  void smc_llc_link_clear(struct smc_link *link);
 -int smc_llc_do_confirm_rkey(struct smc_link *send_link,
 +int smc_llc_do_confirm_rkey(struct smc_link *link,
  			    struct smc_buf_desc *rmb_desc);
 -int smc_llc_do_delete_rkey(struct smc_link_group *lgr,
 +int smc_llc_do_delete_rkey(struct smc_link *link,
  			   struct smc_buf_desc *rmb_desc);
++<<<<<<< HEAD
++=======
+ int smc_llc_flow_initiate(struct smc_link_group *lgr,
+ 			  enum smc_llc_flowtype type);
+ void smc_llc_flow_stop(struct smc_link_group *lgr, struct smc_llc_flow *flow);
+ int smc_llc_eval_conf_link(struct smc_llc_qentry *qentry,
+ 			   enum smc_llc_reqresp type);
+ struct smc_llc_qentry *smc_llc_wait(struct smc_link_group *lgr,
+ 				    struct smc_link *lnk,
+ 				    int time_out, u8 exp_msg);
+ struct smc_llc_qentry *smc_llc_flow_qentry_clr(struct smc_llc_flow *flow);
+ void smc_llc_flow_qentry_del(struct smc_llc_flow *flow);
+ int smc_llc_cli_add_link(struct smc_link *link, struct smc_llc_qentry *qentry);
+ int smc_llc_srv_add_link(struct smc_link *link);
+ void smc_llc_srv_add_link_local(struct smc_link *link);
++>>>>>>> 4dadd151b265 (net/smc: enqueue local LLC messages)
  int smc_llc_init(void) __init;
  
  #endif /* SMC_LLC_H */
* Unmerged path net/smc/smc_core.c
* Unmerged path net/smc/smc_llc.c
* Unmerged path net/smc/smc_llc.h
