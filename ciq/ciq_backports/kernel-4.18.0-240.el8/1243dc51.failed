cgroup/cpuset: Convert cpuset_mutex to percpu_rwsem

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Juri Lelli <juri.lelli@redhat.com>
commit 1243dc518c9da467da6635313a2dbb41b8ffc275
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/1243dc51.failed

Holding cpuset_mutex means that cpusets are stable (only the holder can
make changes) and this is required for fixing a synchronization issue
between cpusets and scheduler core.  However, grabbing cpuset_mutex from
setscheduler() hotpath (as implemented in a later patch) is a no-go, as
it would create a bottleneck for tasks concurrently calling
setscheduler().

Convert cpuset_mutex to be a percpu_rwsem (cpuset_rwsem), so that
setscheduler() will then be able to read lock it and avoid concurrency
issues.

	Tested-by: Dietmar Eggemann <dietmar.eggemann@arm.com>
	Signed-off-by: Juri Lelli <juri.lelli@redhat.com>
	Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
	Cc: Linus Torvalds <torvalds@linux-foundation.org>
	Cc: Peter Zijlstra <peterz@infradead.org>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: bristot@redhat.com
	Cc: claudio@evidence.eu.com
	Cc: lizefan@huawei.com
	Cc: longman@redhat.com
	Cc: luca.abeni@santannapisa.it
	Cc: mathieu.poirier@linaro.org
	Cc: rostedt@goodmis.org
	Cc: tj@kernel.org
	Cc: tommaso.cucinotta@santannapisa.it
Link: https://lkml.kernel.org/r/20190719140000.31694-6-juri.lelli@redhat.com
	Signed-off-by: Ingo Molnar <mingo@kernel.org>
(cherry picked from commit 1243dc518c9da467da6635313a2dbb41b8ffc275)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/cgroup/cpuset.c
diff --cc kernel/cgroup/cpuset.c
index 6f44b6b04fcb,e1a8d168c5e9..000000000000
--- a/kernel/cgroup/cpuset.c
+++ b/kernel/cgroup/cpuset.c
@@@ -919,6 -895,67 +919,70 @@@ done
  	return ndoms;
  }
  
++<<<<<<< HEAD
++=======
+ static void update_tasks_root_domain(struct cpuset *cs)
+ {
+ 	struct css_task_iter it;
+ 	struct task_struct *task;
+ 
+ 	css_task_iter_start(&cs->css, 0, &it);
+ 
+ 	while ((task = css_task_iter_next(&it)))
+ 		dl_add_task_root_domain(task);
+ 
+ 	css_task_iter_end(&it);
+ }
+ 
+ static void rebuild_root_domains(void)
+ {
+ 	struct cpuset *cs = NULL;
+ 	struct cgroup_subsys_state *pos_css;
+ 
+ 	percpu_rwsem_assert_held(&cpuset_rwsem);
+ 	lockdep_assert_cpus_held();
+ 	lockdep_assert_held(&sched_domains_mutex);
+ 
+ 	cgroup_enable_task_cg_lists();
+ 
+ 	rcu_read_lock();
+ 
+ 	/*
+ 	 * Clear default root domain DL accounting, it will be computed again
+ 	 * if a task belongs to it.
+ 	 */
+ 	dl_clear_root_domain(&def_root_domain);
+ 
+ 	cpuset_for_each_descendant_pre(cs, pos_css, &top_cpuset) {
+ 
+ 		if (cpumask_empty(cs->effective_cpus)) {
+ 			pos_css = css_rightmost_descendant(pos_css);
+ 			continue;
+ 		}
+ 
+ 		css_get(&cs->css);
+ 
+ 		rcu_read_unlock();
+ 
+ 		update_tasks_root_domain(cs);
+ 
+ 		rcu_read_lock();
+ 		css_put(&cs->css);
+ 	}
+ 	rcu_read_unlock();
+ }
+ 
+ static void
+ partition_and_rebuild_sched_domains(int ndoms_new, cpumask_var_t doms_new[],
+ 				    struct sched_domain_attr *dattr_new)
+ {
+ 	mutex_lock(&sched_domains_mutex);
+ 	partition_sched_domains_locked(ndoms_new, doms_new, dattr_new);
+ 	rebuild_root_domains();
+ 	mutex_unlock(&sched_domains_mutex);
+ }
+ 
++>>>>>>> 1243dc518c9d (cgroup/cpuset: Convert cpuset_mutex to percpu_rwsem)
  /*
   * Rebuild scheduler domains.
   *
@@@ -2830,7 -2867,7 +2894,11 @@@ struct cgroup_subsys cpuset_cgrp_subsy
  
  int __init cpuset_init(void)
  {
++<<<<<<< HEAD
 +	int err = 0;
++=======
+ 	BUG_ON(percpu_init_rwsem(&cpuset_rwsem));
++>>>>>>> 1243dc518c9d (cgroup/cpuset: Convert cpuset_mutex to percpu_rwsem)
  
  	BUG_ON(!alloc_cpumask_var(&top_cpuset.cpus_allowed, GFP_KERNEL));
  	BUG_ON(!alloc_cpumask_var(&top_cpuset.effective_cpus, GFP_KERNEL));
* Unmerged path kernel/cgroup/cpuset.c
