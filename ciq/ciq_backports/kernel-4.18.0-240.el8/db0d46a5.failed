arm64: Rename WORKAROUND_1319367 to SPECULATIVE_AT_NVHE

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
Rebuild_CHGLOG: - [arm64] Rename WORKAROUND_1319367 to SPECULATIVE_AT_NVHE (Gavin Shan) [1814009]
Rebuild_FUZZ: 93.20%
commit-author Steven Price <steven.price@arm.com>
commit db0d46a58d34c7cd9d5ece98daf4b8afe3d770f8
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/db0d46a5.failed

To match SPECULATIVE_AT_VHE let's also have a generic name for the NVHE
variant.

	Acked-by: Marc Zyngier <maz@kernel.org>
	Reviewed-by: Suzuki K Poulose <suzuki.poulose@arm.com>
	Signed-off-by: Steven Price <steven.price@arm.com>
	Signed-off-by: Will Deacon <will@kernel.org>
(cherry picked from commit db0d46a58d34c7cd9d5ece98daf4b8afe3d770f8)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/Kconfig
#	arch/arm64/include/asm/cpucaps.h
#	arch/arm64/kernel/cpu_errata.c
diff --cc arch/arm64/Kconfig
index d9a7ce52dbae,d102ebd56c79..000000000000
--- a/arch/arm64/Kconfig
+++ b/arch/arm64/Kconfig
@@@ -538,6 -546,20 +538,23 @@@ config ARM64_ERRATUM_128680
  	  invalidated has been observed by other observers. The
  	  workaround repeats the TLBI+DSB operation.
  
++<<<<<<< HEAD
++=======
+ config ARM64_WORKAROUND_SPECULATIVE_AT_NVHE
+ 	bool
+ 
+ config ARM64_ERRATUM_1319367
+ 	bool "Cortex-A57/A72: Speculative AT instruction using out-of-context translation regime could cause subsequent request to generate an incorrect translation"
+ 	default y
+ 	select ARM64_WORKAROUND_SPECULATIVE_AT_NVHE
+ 	help
+ 	  This option adds work arounds for ARM Cortex-A57 erratum 1319537
+ 	  and A72 erratum 1319367
+ 
+ 	  Cortex-A57 and A72 cores could end-up with corrupted TLBs by
+ 	  speculating an AT instruction during a guest context switch.
+ 
++>>>>>>> db0d46a58d34 (arm64: Rename WORKAROUND_1319367 to SPECULATIVE_AT_NVHE)
  	  If unsure, say Y.
  
  config ARM64_ERRATUM_1463225
diff --cc arch/arm64/include/asm/cpucaps.h
index 5ca3d91a67b5,3d1aa1b02093..000000000000
--- a/arch/arm64/include/asm/cpucaps.h
+++ b/arch/arm64/include/asm/cpucaps.h
@@@ -60,11 -49,14 +60,18 @@@
  #define ARM64_HAS_ADDRESS_AUTH_IMP_DEF		39
  #define ARM64_HAS_GENERIC_AUTH_ARCH		40
  #define ARM64_HAS_GENERIC_AUTH_IMP_DEF		41
 -#define ARM64_HAS_IRQ_PRIO_MASKING		42
 -#define ARM64_HAS_DCPODP			43
 +#define ARM64_WORKAROUND_CAVIUM_TX2_219_TVM	42
 +#define ARM64_WORKAROUND_CAVIUM_TX2_219_PRFM	43
  #define ARM64_WORKAROUND_1463225		44
++<<<<<<< HEAD
 +#define ARM64_WORKAROUND_1542419		45
++=======
+ #define ARM64_WORKAROUND_CAVIUM_TX2_219_TVM	45
+ #define ARM64_WORKAROUND_CAVIUM_TX2_219_PRFM	46
+ #define ARM64_WORKAROUND_1542419		47
+ #define ARM64_WORKAROUND_SPECULATIVE_AT_NVHE	48
++>>>>>>> db0d46a58d34 (arm64: Rename WORKAROUND_1319367 to SPECULATIVE_AT_NVHE)
  
 -#define ARM64_NCAPS				49
 +#define ARM64_NCAPS				46
  
  #endif /* __ASM_CPUCAPS_H */
diff --cc arch/arm64/kernel/cpu_errata.c
index 9de4d99cff30,0332fca5564a..000000000000
--- a/arch/arm64/kernel/cpu_errata.c
+++ b/arch/arm64/kernel/cpu_errata.c
@@@ -919,6 -931,13 +919,16 @@@ const struct arm64_cpu_capabilities arm
  		.cpu_enable = cpu_enable_trap_ctr_access,
  	},
  #endif
++<<<<<<< HEAD
++=======
+ #ifdef CONFIG_ARM64_ERRATUM_1319367
+ 	{
+ 		.desc = "ARM erratum 1319367",
+ 		.capability = ARM64_WORKAROUND_SPECULATIVE_AT_NVHE,
+ 		ERRATA_MIDR_RANGE_LIST(ca57_a72),
+ 	},
+ #endif
++>>>>>>> db0d46a58d34 (arm64: Rename WORKAROUND_1319367 to SPECULATIVE_AT_NVHE)
  	{
  	}
  };
* Unmerged path arch/arm64/Kconfig
* Unmerged path arch/arm64/include/asm/cpucaps.h
* Unmerged path arch/arm64/kernel/cpu_errata.c
diff --git a/arch/arm64/kvm/hyp/switch.c b/arch/arm64/kvm/hyp/switch.c
index b617da7815ad..9975399ff705 100644
--- a/arch/arm64/kvm/hyp/switch.c
+++ b/arch/arm64/kvm/hyp/switch.c
@@ -137,7 +137,7 @@ static void __hyp_text __activate_traps_nvhe(struct kvm_vcpu *vcpu)
 
 	write_sysreg(val, cptr_el2);
 
-	if (cpus_have_const_cap(ARM64_WORKAROUND_1319367)) {
+	if (cpus_have_const_cap(ARM64_WORKAROUND_SPECULATIVE_AT_NVHE)) {
 		struct kvm_cpu_context *ctxt = &vcpu->arch.ctxt;
 
 		isb();
@@ -191,7 +191,7 @@ static void __hyp_text __deactivate_traps_nvhe(void)
 {
 	u64 mdcr_el2 = read_sysreg(mdcr_el2);
 
-	if (cpus_have_const_cap(ARM64_WORKAROUND_1319367)) {
+	if (cpus_have_const_cap(ARM64_WORKAROUND_SPECULATIVE_AT_NVHE)) {
 		u64 val;
 
 		/*
diff --git a/arch/arm64/kvm/hyp/sysreg-sr.c b/arch/arm64/kvm/hyp/sysreg-sr.c
index 87375c4164c2..9f51dc3ba86a 100644
--- a/arch/arm64/kvm/hyp/sysreg-sr.c
+++ b/arch/arm64/kvm/hyp/sysreg-sr.c
@@ -129,7 +129,7 @@ static void __hyp_text __sysreg_restore_el1_state(struct kvm_cpu_context *ctxt)
 	write_sysreg(ctxt->sys_regs[MPIDR_EL1],		vmpidr_el2);
 	write_sysreg(ctxt->sys_regs[CSSELR_EL1],	csselr_el1);
 
-	if (!cpus_have_const_cap(ARM64_WORKAROUND_1319367)) {
+	if (!cpus_have_const_cap(ARM64_WORKAROUND_SPECULATIVE_AT_NVHE)) {
 		write_sysreg_el1(ctxt->sys_regs[SCTLR_EL1],	SYS_SCTLR);
 		write_sysreg_el1(ctxt->sys_regs[TCR_EL1],	SYS_TCR);
 	} else	if (!ctxt->__hyp_running_vcpu) {
@@ -160,7 +160,7 @@ static void __hyp_text __sysreg_restore_el1_state(struct kvm_cpu_context *ctxt)
 	write_sysreg(ctxt->sys_regs[PAR_EL1],		par_el1);
 	write_sysreg(ctxt->sys_regs[TPIDR_EL1],		tpidr_el1);
 
-	if (cpus_have_const_cap(ARM64_WORKAROUND_1319367) &&
+	if (cpus_have_const_cap(ARM64_WORKAROUND_SPECULATIVE_AT_NVHE) &&
 	    ctxt->__hyp_running_vcpu) {
 		/*
 		 * Must only be done for host registers, hence the context
diff --git a/arch/arm64/kvm/hyp/tlb.c b/arch/arm64/kvm/hyp/tlb.c
index e566bc96cab0..ed4c42ab6289 100644
--- a/arch/arm64/kvm/hyp/tlb.c
+++ b/arch/arm64/kvm/hyp/tlb.c
@@ -74,7 +74,7 @@ static void __hyp_text __tlb_switch_to_guest_vhe(struct kvm *kvm,
 static void __hyp_text __tlb_switch_to_guest_nvhe(struct kvm *kvm,
 						  struct tlb_inv_context *cxt)
 {
-	if (cpus_have_const_cap(ARM64_WORKAROUND_1319367)) {
+	if (cpus_have_const_cap(ARM64_WORKAROUND_SPECULATIVE_AT_NVHE)) {
 		u64 val;
 
 		/*
@@ -128,7 +128,7 @@ static void __hyp_text __tlb_switch_to_host_nvhe(struct kvm *kvm,
 {
 	write_sysreg(0, vttbr_el2);
 
-	if (cpus_have_const_cap(ARM64_WORKAROUND_1319367)) {
+	if (cpus_have_const_cap(ARM64_WORKAROUND_SPECULATIVE_AT_NVHE)) {
 		/* Ensure write of the host VMID */
 		isb();
 		/* Restore the host's TCR_EL1 */
