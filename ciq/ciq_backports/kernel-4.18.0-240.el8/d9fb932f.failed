net/mlx5e: Fix an IS_ERR() vs NULL check

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Dan Carpenter <dan.carpenter@oracle.com>
commit d9fb932fde217b15eab2111605b05a05b47ea593
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/d9fb932f.failed

The esw_vport_tbl_get() function returns error pointers on error.

Fixes: 96e326878fa5 ("net/mlx5e: Eswitch, Use per vport tables for mirroring")
	Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit d9fb932fde217b15eab2111605b05a05b47ea593)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
index a042a52084fa,3bed4f0f2f3d..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@@ -47,12 -48,183 +47,190 @@@
   * one for multicast.
   */
  #define MLX5_ESW_MISS_FLOWS (2)
 +
 +#define fdb_prio_table(esw, chain, prio, level) \
 +	(esw)->fdb_table.offloads.fdb_prio[(chain)][(prio)][(level)]
 +
  #define UPLINK_REP_INDEX 0
  
++<<<<<<< HEAD
++=======
+ /* Per vport tables */
+ 
+ #define MLX5_ESW_VPORT_TABLE_SIZE 128
+ 
+ /* This struct is used as a key to the hash table and we need it to be packed
+  * so hash result is consistent
+  */
+ struct mlx5_vport_key {
+ 	u32 chain;
+ 	u16 prio;
+ 	u16 vport;
+ 	u16 vhca_id;
+ } __packed;
+ 
+ struct mlx5_vport_table {
+ 	struct hlist_node hlist;
+ 	struct mlx5_flow_table *fdb;
+ 	u32 num_rules;
+ 	struct mlx5_vport_key key;
+ };
+ 
+ #define MLX5_ESW_VPORT_TBL_NUM_GROUPS  4
+ 
+ static struct mlx5_flow_table *
+ esw_vport_tbl_create(struct mlx5_eswitch *esw, struct mlx5_flow_namespace *ns)
+ {
+ 	struct mlx5_flow_table_attr ft_attr = {};
+ 	struct mlx5_flow_table *fdb;
+ 
+ 	ft_attr.autogroup.max_num_groups = MLX5_ESW_VPORT_TBL_NUM_GROUPS;
+ 	ft_attr.max_fte = MLX5_ESW_VPORT_TABLE_SIZE;
+ 	ft_attr.prio = FDB_PER_VPORT;
+ 	fdb = mlx5_create_auto_grouped_flow_table(ns, &ft_attr);
+ 	if (IS_ERR(fdb)) {
+ 		esw_warn(esw->dev, "Failed to create per vport FDB Table err %ld\n",
+ 			 PTR_ERR(fdb));
+ 	}
+ 
+ 	return fdb;
+ }
+ 
+ static u32 flow_attr_to_vport_key(struct mlx5_eswitch *esw,
+ 				  struct mlx5_esw_flow_attr *attr,
+ 				  struct mlx5_vport_key *key)
+ {
+ 	key->vport = attr->in_rep->vport;
+ 	key->chain = attr->chain;
+ 	key->prio = attr->prio;
+ 	key->vhca_id = MLX5_CAP_GEN(esw->dev, vhca_id);
+ 	return jhash(key, sizeof(*key), 0);
+ }
+ 
+ /* caller must hold vports.lock */
+ static struct mlx5_vport_table *
+ esw_vport_tbl_lookup(struct mlx5_eswitch *esw, struct mlx5_vport_key *skey, u32 key)
+ {
+ 	struct mlx5_vport_table *e;
+ 
+ 	hash_for_each_possible(esw->fdb_table.offloads.vports.table, e, hlist, key)
+ 		if (!memcmp(&e->key, skey, sizeof(*skey)))
+ 			return e;
+ 
+ 	return NULL;
+ }
+ 
+ static void
+ esw_vport_tbl_put(struct mlx5_eswitch *esw, struct mlx5_esw_flow_attr *attr)
+ {
+ 	struct mlx5_vport_table *e;
+ 	struct mlx5_vport_key key;
+ 	u32 hkey;
+ 
+ 	mutex_lock(&esw->fdb_table.offloads.vports.lock);
+ 	hkey = flow_attr_to_vport_key(esw, attr, &key);
+ 	e = esw_vport_tbl_lookup(esw, &key, hkey);
+ 	if (!e || --e->num_rules)
+ 		goto out;
+ 
+ 	hash_del(&e->hlist);
+ 	mlx5_destroy_flow_table(e->fdb);
+ 	kfree(e);
+ out:
+ 	mutex_unlock(&esw->fdb_table.offloads.vports.lock);
+ }
+ 
+ static struct mlx5_flow_table *
+ esw_vport_tbl_get(struct mlx5_eswitch *esw, struct mlx5_esw_flow_attr *attr)
+ {
+ 	struct mlx5_core_dev *dev = esw->dev;
+ 	struct mlx5_flow_namespace *ns;
+ 	struct mlx5_flow_table *fdb;
+ 	struct mlx5_vport_table *e;
+ 	struct mlx5_vport_key skey;
+ 	u32 hkey;
+ 
+ 	mutex_lock(&esw->fdb_table.offloads.vports.lock);
+ 	hkey = flow_attr_to_vport_key(esw, attr, &skey);
+ 	e = esw_vport_tbl_lookup(esw, &skey, hkey);
+ 	if (e) {
+ 		e->num_rules++;
+ 		goto out;
+ 	}
+ 
+ 	e = kzalloc(sizeof(*e), GFP_KERNEL);
+ 	if (!e) {
+ 		fdb = ERR_PTR(-ENOMEM);
+ 		goto err_alloc;
+ 	}
+ 
+ 	ns = mlx5_get_flow_namespace(dev, MLX5_FLOW_NAMESPACE_FDB);
+ 	if (!ns) {
+ 		esw_warn(dev, "Failed to get FDB namespace\n");
+ 		fdb = ERR_PTR(-ENOENT);
+ 		goto err_ns;
+ 	}
+ 
+ 	fdb = esw_vport_tbl_create(esw, ns);
+ 	if (IS_ERR(fdb))
+ 		goto err_ns;
+ 
+ 	e->fdb = fdb;
+ 	e->num_rules = 1;
+ 	e->key = skey;
+ 	hash_add(esw->fdb_table.offloads.vports.table, &e->hlist, hkey);
+ out:
+ 	mutex_unlock(&esw->fdb_table.offloads.vports.lock);
+ 	return e->fdb;
+ 
+ err_ns:
+ 	kfree(e);
+ err_alloc:
+ 	mutex_unlock(&esw->fdb_table.offloads.vports.lock);
+ 	return fdb;
+ }
+ 
+ int mlx5_esw_vport_tbl_get(struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_esw_flow_attr attr = {};
+ 	struct mlx5_eswitch_rep rep = {};
+ 	struct mlx5_flow_table *fdb;
+ 	struct mlx5_vport *vport;
+ 	int i;
+ 
+ 	attr.prio = 1;
+ 	attr.in_rep = &rep;
+ 	mlx5_esw_for_all_vports(esw, i, vport) {
+ 		attr.in_rep->vport = vport->vport;
+ 		fdb = esw_vport_tbl_get(esw, &attr);
+ 		if (IS_ERR(fdb))
+ 			goto out;
+ 	}
+ 	return 0;
+ 
+ out:
+ 	mlx5_esw_vport_tbl_put(esw);
+ 	return PTR_ERR(fdb);
+ }
+ 
+ void mlx5_esw_vport_tbl_put(struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_esw_flow_attr attr = {};
+ 	struct mlx5_eswitch_rep rep = {};
+ 	struct mlx5_vport *vport;
+ 	int i;
+ 
+ 	attr.prio = 1;
+ 	attr.in_rep = &rep;
+ 	mlx5_esw_for_all_vports(esw, i, vport) {
+ 		attr.in_rep->vport = vport->vport;
+ 		esw_vport_tbl_put(esw, &attr);
+ 	}
+ }
+ 
+ /* End: Per vport tables */
+ 
++>>>>>>> d9fb932fde21 (net/mlx5e: Fix an IS_ERR() vs NULL check)
  static struct mlx5_eswitch_rep *mlx5_eswitch_get_rep(struct mlx5_eswitch *esw,
  						     u16 vport_num)
  {
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
