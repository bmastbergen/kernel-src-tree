bpf: Compare BTF types of functions arguments with actual types

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Alexei Starovoitov <ast@kernel.org>
commit 8c1b6e69dcc1e11bd24111e3734dd740aaf3fda1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/8c1b6e69.failed

Make the verifier check that BTF types of function arguments match actual types
passed into top-level BPF program and into BPF-to-BPF calls. If types match
such BPF programs and sub-programs will have full support of BPF trampoline. If
types mismatch the trampoline has to be conservative. It has to save/restore
five program arguments and assume 64-bit scalars.

	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Acked-by: Song Liu <songliubraving@fb.com>
	Acked-by: Andrii Nakryiko <andriin@fb.com>
Link: https://lore.kernel.org/bpf/20191114185720.1641606-17-ast@kernel.org
(cherry picked from commit 8c1b6e69dcc1e11bd24111e3734dd740aaf3fda1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/bpf.h
#	kernel/bpf/btf.c
diff --cc include/linux/bpf.h
index a5585413dfbe,c70bf04726b4..000000000000
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@@ -389,6 -386,104 +389,107 @@@ struct bpf_prog_stats 
  	struct u64_stats_sync syncp;
  } __aligned(2 * sizeof(u64));
  
++<<<<<<< HEAD
++=======
+ struct btf_func_model {
+ 	u8 ret_size;
+ 	u8 nr_args;
+ 	u8 arg_size[MAX_BPF_FUNC_ARGS];
+ };
+ 
+ /* Restore arguments before returning from trampoline to let original function
+  * continue executing. This flag is used for fentry progs when there are no
+  * fexit progs.
+  */
+ #define BPF_TRAMP_F_RESTORE_REGS	BIT(0)
+ /* Call original function after fentry progs, but before fexit progs.
+  * Makes sense for fentry/fexit, normal calls and indirect calls.
+  */
+ #define BPF_TRAMP_F_CALL_ORIG		BIT(1)
+ /* Skip current frame and return to parent.  Makes sense for fentry/fexit
+  * programs only. Should not be used with normal calls and indirect calls.
+  */
+ #define BPF_TRAMP_F_SKIP_FRAME		BIT(2)
+ 
+ /* Different use cases for BPF trampoline:
+  * 1. replace nop at the function entry (kprobe equivalent)
+  *    flags = BPF_TRAMP_F_RESTORE_REGS
+  *    fentry = a set of programs to run before returning from trampoline
+  *
+  * 2. replace nop at the function entry (kprobe + kretprobe equivalent)
+  *    flags = BPF_TRAMP_F_CALL_ORIG | BPF_TRAMP_F_SKIP_FRAME
+  *    orig_call = fentry_ip + MCOUNT_INSN_SIZE
+  *    fentry = a set of program to run before calling original function
+  *    fexit = a set of program to run after original function
+  *
+  * 3. replace direct call instruction anywhere in the function body
+  *    or assign a function pointer for indirect call (like tcp_congestion_ops->cong_avoid)
+  *    With flags = 0
+  *      fentry = a set of programs to run before returning from trampoline
+  *    With flags = BPF_TRAMP_F_CALL_ORIG
+  *      orig_call = original callback addr or direct function addr
+  *      fentry = a set of program to run before calling original function
+  *      fexit = a set of program to run after original function
+  */
+ int arch_prepare_bpf_trampoline(void *image, struct btf_func_model *m, u32 flags,
+ 				struct bpf_prog **fentry_progs, int fentry_cnt,
+ 				struct bpf_prog **fexit_progs, int fexit_cnt,
+ 				void *orig_call);
+ /* these two functions are called from generated trampoline */
+ u64 notrace __bpf_prog_enter(void);
+ void notrace __bpf_prog_exit(struct bpf_prog *prog, u64 start);
+ 
+ enum bpf_tramp_prog_type {
+ 	BPF_TRAMP_FENTRY,
+ 	BPF_TRAMP_FEXIT,
+ 	BPF_TRAMP_MAX
+ };
+ 
+ struct bpf_trampoline {
+ 	/* hlist for trampoline_table */
+ 	struct hlist_node hlist;
+ 	/* serializes access to fields of this trampoline */
+ 	struct mutex mutex;
+ 	refcount_t refcnt;
+ 	u64 key;
+ 	struct {
+ 		struct btf_func_model model;
+ 		void *addr;
+ 	} func;
+ 	/* list of BPF programs using this trampoline */
+ 	struct hlist_head progs_hlist[BPF_TRAMP_MAX];
+ 	/* Number of attached programs. A counter per kind. */
+ 	int progs_cnt[BPF_TRAMP_MAX];
+ 	/* Executable image of trampoline */
+ 	void *image;
+ 	u64 selector;
+ };
+ #ifdef CONFIG_BPF_JIT
+ struct bpf_trampoline *bpf_trampoline_lookup(u64 key);
+ int bpf_trampoline_link_prog(struct bpf_prog *prog);
+ int bpf_trampoline_unlink_prog(struct bpf_prog *prog);
+ void bpf_trampoline_put(struct bpf_trampoline *tr);
+ #else
+ static inline struct bpf_trampoline *bpf_trampoline_lookup(u64 key)
+ {
+ 	return NULL;
+ }
+ static inline int bpf_trampoline_link_prog(struct bpf_prog *prog)
+ {
+ 	return -ENOTSUPP;
+ }
+ static inline int bpf_trampoline_unlink_prog(struct bpf_prog *prog)
+ {
+ 	return -ENOTSUPP;
+ }
+ static inline void bpf_trampoline_put(struct bpf_trampoline *tr) {}
+ #endif
+ 
+ struct bpf_func_info_aux {
+ 	bool unreliable;
+ };
+ 
++>>>>>>> 8c1b6e69dcc1 (bpf: Compare BTF types of functions arguments with actual types)
  struct bpf_prog_aux {
  	atomic_t refcnt;
  	u32 used_map_cnt;
@@@ -399,9 -493,19 +500,21 @@@
  	u32 stack_depth;
  	u32 id;
  	u32 func_cnt; /* used by non-func prog as the number of func progs */
 -	u32 func_idx; /* 0 for non-func prog, the index in func array for func prog */
 -	u32 attach_btf_id; /* in-kernel BTF type id to attach to */
 -	bool verifier_zext; /* Zero extensions has been inserted by verifier. */
 +	RH_KABI_BROKEN_INSERT(u32 func_idx) /* 0 for non-func prog, the index in func array for func prog */
 +	RH_KABI_BROKEN_INSERT(bool verifier_zext) /* Zero extensions has been inserted by verifier. */
  	bool offload_requested;
++<<<<<<< HEAD
++=======
+ 	bool attach_btf_trace; /* true if attaching to BTF-enabled raw tp */
+ 	bool func_proto_unreliable;
+ 	enum bpf_tramp_prog_type trampoline_prog_type;
+ 	struct bpf_trampoline *trampoline;
+ 	struct hlist_node tramp_hlist;
+ 	/* BTF_KIND_FUNC_PROTO for valid attach_btf_id */
+ 	const struct btf_type *attach_func_proto;
+ 	/* function name for valid attach_btf_id */
+ 	const char *attach_func_name;
++>>>>>>> 8c1b6e69dcc1 (bpf: Compare BTF types of functions arguments with actual types)
  	struct bpf_prog **func;
  	void *jit_data; /* JIT specific data. arch dependent */
  	struct latch_tree_node ksym_tnode;
@@@ -417,9 -521,9 +530,10 @@@
  	void *security;
  #endif
  	struct bpf_prog_offload *offload;
 +	RH_KABI_BROKEN_INSERT_BLOCK(
  	struct btf *btf;
  	struct bpf_func_info *func_info;
+ 	struct bpf_func_info_aux *func_info_aux;
  	/* bpf_line_info loaded from userspace.  linfo->insn_off
  	 * has the xlated insn offset.
  	 * Both the main and sub prog share the same linfo.
@@@ -784,7 -887,17 +898,9 @@@ int btf_struct_access(struct bpf_verifi
  		      const struct btf_type *t, int off, int size,
  		      enum bpf_access_type atype,
  		      u32 *next_btf_id);
 -int btf_resolve_helper_id(struct bpf_verifier_log *log,
 -			  const struct bpf_func_proto *fn, int);
 -
 -int btf_distill_func_proto(struct bpf_verifier_log *log,
 -			   struct btf *btf,
 -			   const struct btf_type *func_proto,
 -			   const char *func_name,
 -			   struct btf_func_model *m);
  
+ int btf_check_func_arg_match(struct bpf_verifier_env *env, int subprog);
+ 
  #else /* !CONFIG_BPF_SYSCALL */
  static inline struct bpf_prog *bpf_prog_get(u32 ufd)
  {
diff --cc kernel/bpf/btf.c
index dc1f2324f36a,4620267b186e..000000000000
--- a/kernel/bpf/btf.c
+++ b/kernel/bpf/btf.c
@@@ -3763,6 -3829,244 +3763,247 @@@ again
  	return -EINVAL;
  }
  
++<<<<<<< HEAD
++=======
+ static int __btf_resolve_helper_id(struct bpf_verifier_log *log, void *fn,
+ 				   int arg)
+ {
+ 	char fnname[KSYM_SYMBOL_LEN + 4] = "btf_";
+ 	const struct btf_param *args;
+ 	const struct btf_type *t;
+ 	const char *tname, *sym;
+ 	u32 btf_id, i;
+ 
+ 	if (IS_ERR(btf_vmlinux)) {
+ 		bpf_log(log, "btf_vmlinux is malformed\n");
+ 		return -EINVAL;
+ 	}
+ 
+ 	sym = kallsyms_lookup((long)fn, NULL, NULL, NULL, fnname + 4);
+ 	if (!sym) {
+ 		bpf_log(log, "kernel doesn't have kallsyms\n");
+ 		return -EFAULT;
+ 	}
+ 
+ 	for (i = 1; i <= btf_vmlinux->nr_types; i++) {
+ 		t = btf_type_by_id(btf_vmlinux, i);
+ 		if (BTF_INFO_KIND(t->info) != BTF_KIND_TYPEDEF)
+ 			continue;
+ 		tname = __btf_name_by_offset(btf_vmlinux, t->name_off);
+ 		if (!strcmp(tname, fnname))
+ 			break;
+ 	}
+ 	if (i > btf_vmlinux->nr_types) {
+ 		bpf_log(log, "helper %s type is not found\n", fnname);
+ 		return -ENOENT;
+ 	}
+ 
+ 	t = btf_type_by_id(btf_vmlinux, t->type);
+ 	if (!btf_type_is_ptr(t))
+ 		return -EFAULT;
+ 	t = btf_type_by_id(btf_vmlinux, t->type);
+ 	if (!btf_type_is_func_proto(t))
+ 		return -EFAULT;
+ 
+ 	args = (const struct btf_param *)(t + 1);
+ 	if (arg >= btf_type_vlen(t)) {
+ 		bpf_log(log, "bpf helper %s doesn't have %d-th argument\n",
+ 			fnname, arg);
+ 		return -EINVAL;
+ 	}
+ 
+ 	t = btf_type_by_id(btf_vmlinux, args[arg].type);
+ 	if (!btf_type_is_ptr(t) || !t->type) {
+ 		/* anything but the pointer to struct is a helper config bug */
+ 		bpf_log(log, "ARG_PTR_TO_BTF is misconfigured\n");
+ 		return -EFAULT;
+ 	}
+ 	btf_id = t->type;
+ 	t = btf_type_by_id(btf_vmlinux, t->type);
+ 	/* skip modifiers */
+ 	while (btf_type_is_modifier(t)) {
+ 		btf_id = t->type;
+ 		t = btf_type_by_id(btf_vmlinux, t->type);
+ 	}
+ 	if (!btf_type_is_struct(t)) {
+ 		bpf_log(log, "ARG_PTR_TO_BTF is not a struct\n");
+ 		return -EFAULT;
+ 	}
+ 	bpf_log(log, "helper %s arg%d has btf_id %d struct %s\n", fnname + 4,
+ 		arg, btf_id, __btf_name_by_offset(btf_vmlinux, t->name_off));
+ 	return btf_id;
+ }
+ 
+ int btf_resolve_helper_id(struct bpf_verifier_log *log,
+ 			  const struct bpf_func_proto *fn, int arg)
+ {
+ 	int *btf_id = &fn->btf_id[arg];
+ 	int ret;
+ 
+ 	if (fn->arg_type[arg] != ARG_PTR_TO_BTF_ID)
+ 		return -EINVAL;
+ 
+ 	ret = READ_ONCE(*btf_id);
+ 	if (ret)
+ 		return ret;
+ 	/* ok to race the search. The result is the same */
+ 	ret = __btf_resolve_helper_id(log, fn->func, arg);
+ 	if (!ret) {
+ 		/* Function argument cannot be type 'void' */
+ 		bpf_log(log, "BTF resolution bug\n");
+ 		return -EFAULT;
+ 	}
+ 	WRITE_ONCE(*btf_id, ret);
+ 	return ret;
+ }
+ 
+ static int __get_type_size(struct btf *btf, u32 btf_id,
+ 			   const struct btf_type **bad_type)
+ {
+ 	const struct btf_type *t;
+ 
+ 	if (!btf_id)
+ 		/* void */
+ 		return 0;
+ 	t = btf_type_by_id(btf, btf_id);
+ 	while (t && btf_type_is_modifier(t))
+ 		t = btf_type_by_id(btf, t->type);
+ 	if (!t)
+ 		return -EINVAL;
+ 	if (btf_type_is_ptr(t))
+ 		/* kernel size of pointer. Not BPF's size of pointer*/
+ 		return sizeof(void *);
+ 	if (btf_type_is_int(t) || btf_type_is_enum(t))
+ 		return t->size;
+ 	*bad_type = t;
+ 	return -EINVAL;
+ }
+ 
+ int btf_distill_func_proto(struct bpf_verifier_log *log,
+ 			   struct btf *btf,
+ 			   const struct btf_type *func,
+ 			   const char *tname,
+ 			   struct btf_func_model *m)
+ {
+ 	const struct btf_param *args;
+ 	const struct btf_type *t;
+ 	u32 i, nargs;
+ 	int ret;
+ 
+ 	args = (const struct btf_param *)(func + 1);
+ 	nargs = btf_type_vlen(func);
+ 	if (nargs >= MAX_BPF_FUNC_ARGS) {
+ 		bpf_log(log,
+ 			"The function %s has %d arguments. Too many.\n",
+ 			tname, nargs);
+ 		return -EINVAL;
+ 	}
+ 	ret = __get_type_size(btf, func->type, &t);
+ 	if (ret < 0) {
+ 		bpf_log(log,
+ 			"The function %s return type %s is unsupported.\n",
+ 			tname, btf_kind_str[BTF_INFO_KIND(t->info)]);
+ 		return -EINVAL;
+ 	}
+ 	m->ret_size = ret;
+ 
+ 	for (i = 0; i < nargs; i++) {
+ 		ret = __get_type_size(btf, args[i].type, &t);
+ 		if (ret < 0) {
+ 			bpf_log(log,
+ 				"The function %s arg%d type %s is unsupported.\n",
+ 				tname, i, btf_kind_str[BTF_INFO_KIND(t->info)]);
+ 			return -EINVAL;
+ 		}
+ 		m->arg_size[i] = ret;
+ 	}
+ 	m->nr_args = nargs;
+ 	return 0;
+ }
+ 
+ int btf_check_func_arg_match(struct bpf_verifier_env *env, int subprog)
+ {
+ 	struct bpf_verifier_state *st = env->cur_state;
+ 	struct bpf_func_state *func = st->frame[st->curframe];
+ 	struct bpf_reg_state *reg = func->regs;
+ 	struct bpf_verifier_log *log = &env->log;
+ 	struct bpf_prog *prog = env->prog;
+ 	struct btf *btf = prog->aux->btf;
+ 	const struct btf_param *args;
+ 	const struct btf_type *t;
+ 	u32 i, nargs, btf_id;
+ 	const char *tname;
+ 
+ 	if (!prog->aux->func_info)
+ 		return 0;
+ 
+ 	btf_id = prog->aux->func_info[subprog].type_id;
+ 	if (!btf_id)
+ 		return 0;
+ 
+ 	if (prog->aux->func_info_aux[subprog].unreliable)
+ 		return 0;
+ 
+ 	t = btf_type_by_id(btf, btf_id);
+ 	if (!t || !btf_type_is_func(t)) {
+ 		bpf_log(log, "BTF of subprog %d doesn't point to KIND_FUNC\n",
+ 			subprog);
+ 		return -EINVAL;
+ 	}
+ 	tname = btf_name_by_offset(btf, t->name_off);
+ 
+ 	t = btf_type_by_id(btf, t->type);
+ 	if (!t || !btf_type_is_func_proto(t)) {
+ 		bpf_log(log, "Invalid type of func %s\n", tname);
+ 		return -EINVAL;
+ 	}
+ 	args = (const struct btf_param *)(t + 1);
+ 	nargs = btf_type_vlen(t);
+ 	if (nargs > 5) {
+ 		bpf_log(log, "Function %s has %d > 5 args\n", tname, nargs);
+ 		goto out;
+ 	}
+ 	/* check that BTF function arguments match actual types that the
+ 	 * verifier sees.
+ 	 */
+ 	for (i = 0; i < nargs; i++) {
+ 		t = btf_type_by_id(btf, args[i].type);
+ 		while (btf_type_is_modifier(t))
+ 			t = btf_type_by_id(btf, t->type);
+ 		if (btf_type_is_int(t) || btf_type_is_enum(t)) {
+ 			if (reg[i + 1].type == SCALAR_VALUE)
+ 				continue;
+ 			bpf_log(log, "R%d is not a scalar\n", i + 1);
+ 			goto out;
+ 		}
+ 		if (btf_type_is_ptr(t)) {
+ 			if (reg[i + 1].type == SCALAR_VALUE) {
+ 				bpf_log(log, "R%d is not a pointer\n", i + 1);
+ 				goto out;
+ 			}
+ 			/* If program is passing PTR_TO_CTX into subprogram
+ 			 * check that BTF type matches.
+ 			 */
+ 			if (reg[i + 1].type == PTR_TO_CTX &&
+ 			    !btf_get_prog_ctx_type(log, btf, t, prog->type))
+ 				goto out;
+ 			/* All other pointers are ok */
+ 			continue;
+ 		}
+ 		bpf_log(log, "Unrecognized argument type %s\n",
+ 			btf_kind_str[BTF_INFO_KIND(t->info)]);
+ 		goto out;
+ 	}
+ 	return 0;
+ out:
+ 	/* LLVM optimizations can remove arguments from static functions. */
+ 	bpf_log(log,
+ 		"Type info disagrees with actual arguments due to compiler optimizations\n");
+ 	prog->aux->func_info_aux[subprog].unreliable = true;
+ 	return 0;
+ }
+ 
++>>>>>>> 8c1b6e69dcc1 (bpf: Compare BTF types of functions arguments with actual types)
  void btf_type_seq_show(const struct btf *btf, u32 type_id, void *obj,
  		       struct seq_file *m)
  {
* Unmerged path include/linux/bpf.h
diff --git a/include/linux/bpf_verifier.h b/include/linux/bpf_verifier.h
index 353e710aed31..177a9d2a804a 100644
--- a/include/linux/bpf_verifier.h
+++ b/include/linux/bpf_verifier.h
@@ -346,6 +346,7 @@ static inline bool bpf_verifier_log_needed(const struct bpf_verifier_log *log)
 #define BPF_MAX_SUBPROGS 256
 
 struct bpf_subprog_info {
+	/* 'start' has to be the first field otherwise find_subprog() won't work */
 	u32 start; /* insn idx of function entry point */
 	u32 linfo_idx; /* The idx to the main_prog->aux->linfo */
 	u16 stack_depth; /* max. stack depth used by this function */
* Unmerged path kernel/bpf/btf.c
diff --git a/kernel/bpf/syscall.c b/kernel/bpf/syscall.c
index dd68cbc967e7..0974b2ec8f2e 100644
--- a/kernel/bpf/syscall.c
+++ b/kernel/bpf/syscall.c
@@ -1389,6 +1389,7 @@ static void __bpf_prog_put_rcu(struct rcu_head *rcu)
 	struct bpf_prog_aux *aux = container_of(rcu, struct bpf_prog_aux, rcu);
 
 	kvfree(aux->func_info);
+	kfree(aux->func_info_aux);
 	free_used_maps(aux);
 	bpf_prog_uncharge_memlock(aux->prog);
 	security_bpf_prog_free(aux);
diff --git a/kernel/bpf/verifier.c b/kernel/bpf/verifier.c
index ba15160eab20..6044f7ad08ab 100644
--- a/kernel/bpf/verifier.c
+++ b/kernel/bpf/verifier.c
@@ -3958,6 +3958,9 @@ static int check_func_call(struct bpf_verifier_env *env, struct bpf_insn *insn,
 	/* only increment it after check_reg_arg() finished */
 	state->curframe++;
 
+	if (btf_check_func_arg_match(env, subprog))
+		return -EINVAL;
+
 	/* and go analyze first insn of the callee */
 	*insn_idx = target_insn;
 
@@ -6571,6 +6574,7 @@ static int check_btf_func(struct bpf_verifier_env *env,
 	u32 i, nfuncs, urec_size, min_size;
 	u32 krec_size = sizeof(struct bpf_func_info);
 	struct bpf_func_info *krecord;
+	struct bpf_func_info_aux *info_aux = NULL;
 	const struct btf_type *type;
 	struct bpf_prog *prog;
 	const struct btf *btf;
@@ -6604,6 +6608,9 @@ static int check_btf_func(struct bpf_verifier_env *env,
 	krecord = kvcalloc(nfuncs, krec_size, GFP_KERNEL | __GFP_NOWARN);
 	if (!krecord)
 		return -ENOMEM;
+	info_aux = kcalloc(nfuncs, sizeof(*info_aux), GFP_KERNEL | __GFP_NOWARN);
+	if (!info_aux)
+		goto err_free;
 
 	for (i = 0; i < nfuncs; i++) {
 		ret = bpf_check_uarg_tail_zero(urecord, krec_size, urec_size);
@@ -6655,29 +6662,31 @@ static int check_btf_func(struct bpf_verifier_env *env,
 			ret = -EINVAL;
 			goto err_free;
 		}
-
 		prev_offset = krecord[i].insn_off;
 		urecord += urec_size;
 	}
 
 	prog->aux->func_info = krecord;
 	prog->aux->func_info_cnt = nfuncs;
+	prog->aux->func_info_aux = info_aux;
 	return 0;
 
 err_free:
 	kvfree(krecord);
+	kfree(info_aux);
 	return ret;
 }
 
 static void adjust_btf_func(struct bpf_verifier_env *env)
 {
+	struct bpf_prog_aux *aux = env->prog->aux;
 	int i;
 
-	if (!env->prog->aux->func_info)
+	if (!aux->func_info)
 		return;
 
 	for (i = 0; i < env->subprog_cnt; i++)
-		env->prog->aux->func_info[i].insn_off = env->subprog_info[i].start;
+		aux->func_info[i].insn_off = env->subprog_info[i].start;
 }
 
 #define MIN_BPF_LINEINFO_SIZE	(offsetof(struct bpf_line_info, line_col) + \
@@ -7658,6 +7667,9 @@ static int do_check(struct bpf_verifier_env *env)
 			0 /* frameno */,
 			0 /* subprogno, zero == main subprog */);
 
+	if (btf_check_func_arg_match(env, 0))
+		return -EINVAL;
+
 	for (;;) {
 		struct bpf_insn *insn;
 		u8 class;
