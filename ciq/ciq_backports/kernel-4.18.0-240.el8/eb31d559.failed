memblock: remove _virt from APIs returning virtual address

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Mike Rapoport <rppt@linux.vnet.ibm.com>
commit eb31d559f1e8390195372cd51cfb198da8bc84b9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/eb31d559.failed

The conversion is done using

sed -i 's@memblock_virt_alloc@memblock_alloc@g' \
	$(git grep -l memblock_virt_alloc)

Link: http://lkml.kernel.org/r/1536927045-23536-8-git-send-email-rppt@linux.vnet.ibm.com
	Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Chris Zankel <chris@zankel.net>
	Cc: "David S. Miller" <davem@davemloft.net>
	Cc: Geert Uytterhoeven <geert@linux-m68k.org>
	Cc: Greentime Hu <green.hu@gmail.com>
	Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
	Cc: Guan Xuetao <gxt@pku.edu.cn>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
	Cc: Jonas Bonn <jonas@southpole.se>
	Cc: Jonathan Corbet <corbet@lwn.net>
	Cc: Ley Foon Tan <lftan@altera.com>
	Cc: Mark Salter <msalter@redhat.com>
	Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
	Cc: Matt Turner <mattst88@gmail.com>
	Cc: Michael Ellerman <mpe@ellerman.id.au>
	Cc: Michal Hocko <mhocko@suse.com>
	Cc: Michal Simek <monstr@monstr.eu>
	Cc: Palmer Dabbelt <palmer@sifive.com>
	Cc: Paul Burton <paul.burton@mips.com>
	Cc: Richard Kuo <rkuo@codeaurora.org>
	Cc: Richard Weinberger <richard@nod.at>
	Cc: Rich Felker <dalias@libc.org>
	Cc: Russell King <linux@armlinux.org.uk>
	Cc: Serge Semin <fancer.lancer@gmail.com>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Tony Luck <tony.luck@intel.com>
	Cc: Vineet Gupta <vgupta@synopsys.com>
	Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit eb31d559f1e8390195372cd51cfb198da8bc84b9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm/mach-omap2/omap_hwmod.c
#	arch/mips/kernel/setup.c
#	arch/s390/kernel/setup.c
#	kernel/dma/swiotlb.c
#	mm/memblock.c
#	mm/percpu.c
#	mm/sparse.c
diff --cc arch/arm/mach-omap2/omap_hwmod.c
index 2ceffd85dd3d,1f9b34a7eccd..000000000000
--- a/arch/arm/mach-omap2/omap_hwmod.c
+++ b/arch/arm/mach-omap2/omap_hwmod.c
@@@ -724,23 -724,34 +724,46 @@@ static int __init _setup_clkctrl_provid
  	const __be32 *addrp;
  	struct clkctrl_provider *provider;
  	u64 size;
 -	int i;
  
- 	provider = memblock_virt_alloc(sizeof(*provider), 0);
+ 	provider = memblock_alloc(sizeof(*provider), 0);
  	if (!provider)
  		return -ENOMEM;
  
 +	addrp = of_get_address(np, 0, &size, NULL);
 +	provider->addr = (u32)of_translate_address(np, addrp);
 +	addrp = of_get_address(np->parent, 0, NULL, NULL);
 +	provider->offset = provider->addr -
 +			   (u32)of_translate_address(np->parent, addrp);
 +	provider->addr &= ~0xff;
 +	provider->size = size | 0xff;
  	provider->node = np;
  
++<<<<<<< HEAD
 +	pr_debug("%s: %s: %x...%x [+%x]\n", __func__, np->parent->name,
 +		 provider->addr, provider->addr + provider->size,
 +		 provider->offset);
++=======
+ 	provider->num_addrs =
+ 		of_property_count_elems_of_size(np, "reg", sizeof(u32)) / 2;
+ 
+ 	provider->addr =
+ 		memblock_alloc(sizeof(void *) * provider->num_addrs, 0);
+ 	if (!provider->addr)
+ 		return -ENOMEM;
+ 
+ 	provider->size =
+ 		memblock_alloc(sizeof(u32) * provider->num_addrs, 0);
+ 	if (!provider->size)
+ 		return -ENOMEM;
+ 
+ 	for (i = 0; i < provider->num_addrs; i++) {
+ 		addrp = of_get_address(np, i, &size, NULL);
+ 		provider->addr[i] = (u32)of_translate_address(np, addrp);
+ 		provider->size[i] = size;
+ 		pr_debug("%s: %pOF: %x...%x\n", __func__, np, provider->addr[i],
+ 			 provider->addr[i] + provider->size[i]);
+ 	}
++>>>>>>> eb31d559f1e8 (memblock: remove _virt from APIs returning virtual address)
  
  	list_add(&provider->link, &clkctrl_providers);
  
diff --cc arch/mips/kernel/setup.c
index 2c96c0c68116,0c997645e8f0..000000000000
--- a/arch/mips/kernel/setup.c
+++ b/arch/mips/kernel/setup.c
@@@ -897,6 -854,16 +897,19 @@@ static void __init arch_mem_init(char *
  	early_init_fdt_scan_reserved_mem();
  
  	bootmem_init();
++<<<<<<< HEAD
++=======
+ 
+ 	/*
+ 	 * Prevent memblock from allocating high memory.
+ 	 * This cannot be done before max_low_pfn is detected, so up
+ 	 * to this point is possible to only reserve physical memory
+ 	 * with memblock_reserve; memblock_alloc* can be used
+ 	 * only after this point
+ 	 */
+ 	memblock_set_current_limit(PFN_PHYS(max_low_pfn));
+ 
++>>>>>>> eb31d559f1e8 (memblock: remove _virt from APIs returning virtual address)
  #ifdef CONFIG_PROC_VMCORE
  	if (setup_elfcorehdr && setup_elfcorehdr_size) {
  		printk(KERN_INFO "kdump reserved memory at %lx-%lx\n",
diff --cc arch/s390/kernel/setup.c
index d5516ab24db2,781c1053a773..000000000000
--- a/arch/s390/kernel/setup.c
+++ b/arch/s390/kernel/setup.c
@@@ -322,15 -378,17 +322,15 @@@ static void __init setup_lowcore_dat_of
  	 * Setup lowcore for boot cpu
  	 */
  	BUILD_BUG_ON(sizeof(struct lowcore) != LC_PAGES * PAGE_SIZE);
- 	lc = memblock_virt_alloc_low(sizeof(*lc), sizeof(*lc));
+ 	lc = memblock_alloc_low(sizeof(*lc), sizeof(*lc));
  	lc->restart_psw.mask = PSW_KERNEL_BITS;
  	lc->restart_psw.addr = (unsigned long) restart_int_handler;
 -	lc->external_new_psw.mask = PSW_KERNEL_BITS |
 -		PSW_MASK_DAT | PSW_MASK_MCHECK;
 +	lc->external_new_psw.mask = PSW_KERNEL_BITS | PSW_MASK_MCHECK;
  	lc->external_new_psw.addr = (unsigned long) ext_int_handler;
  	lc->svc_new_psw.mask = PSW_KERNEL_BITS |
 -		PSW_MASK_DAT | PSW_MASK_IO | PSW_MASK_EXT | PSW_MASK_MCHECK;
 +		PSW_MASK_IO | PSW_MASK_EXT | PSW_MASK_MCHECK;
  	lc->svc_new_psw.addr = (unsigned long) system_call;
 -	lc->program_new_psw.mask = PSW_KERNEL_BITS |
 -		PSW_MASK_DAT | PSW_MASK_MCHECK;
 +	lc->program_new_psw.mask = PSW_KERNEL_BITS | PSW_MASK_MCHECK;
  	lc->program_new_psw.addr = (unsigned long) pgm_check_handler;
  	lc->mcck_new_psw.mask = PSW_KERNEL_BITS;
  	lc->mcck_new_psw.addr = (unsigned long) mcck_int_handler;
@@@ -365,8 -418,12 +365,17 @@@
  	lc->last_update_timer = S390_lowcore.last_update_timer;
  	lc->last_update_clock = S390_lowcore.last_update_clock;
  
++<<<<<<< HEAD
 +	restart_stack = memblock_virt_alloc(ASYNC_SIZE, ASYNC_SIZE);
 +	restart_stack += ASYNC_SIZE;
++=======
+ 	/*
+ 	 * Allocate the global restart stack which is the same for
+ 	 * all CPUs in cast *one* of them does a PSW restart.
+ 	 */
+ 	restart_stack = memblock_alloc(THREAD_SIZE, THREAD_SIZE);
+ 	restart_stack += STACK_INIT_OFFSET;
++>>>>>>> eb31d559f1e8 (memblock: remove _virt from APIs returning virtual address)
  
  	/*
  	 * Set up PSW restart to call ipl.c:do_restart(). Copy the relevant
diff --cc kernel/dma/swiotlb.c
index 772e6f52f9c5,801da67e957b..000000000000
--- a/kernel/dma/swiotlb.c
+++ b/kernel/dma/swiotlb.c
@@@ -212,18 -204,12 +212,27 @@@ int __init swiotlb_init_with_tbl(char *
  	 * to find contiguous free memory regions of size up to IO_TLB_SEGSIZE
  	 * between io_tlb_start and io_tlb_end.
  	 */
++<<<<<<< HEAD
 +	alloc_size = PAGE_ALIGN(io_tlb_nslabs * sizeof(int));
 +	io_tlb_list = memblock_virt_alloc(alloc_size, PAGE_SIZE);
 +	if (!io_tlb_list)
 +		panic("%s: Failed to allocate %lu bytes align=0x%lx\n",
 +		      __func__, alloc_size, PAGE_SIZE);
 +
 +	alloc_size = PAGE_ALIGN(io_tlb_nslabs * sizeof(phys_addr_t));
 +	io_tlb_orig_addr = memblock_virt_alloc(alloc_size, PAGE_SIZE);
 +	if (!io_tlb_orig_addr)
 +		panic("%s: Failed to allocate %lu bytes align=0x%lx\n",
 +		      __func__, alloc_size, PAGE_SIZE);
 +
++=======
+ 	io_tlb_list = memblock_alloc(
+ 				PAGE_ALIGN(io_tlb_nslabs * sizeof(int)),
+ 				PAGE_SIZE);
+ 	io_tlb_orig_addr = memblock_alloc(
+ 				PAGE_ALIGN(io_tlb_nslabs * sizeof(phys_addr_t)),
+ 				PAGE_SIZE);
++>>>>>>> eb31d559f1e8 (memblock: remove _virt from APIs returning virtual address)
  	for (i = 0; i < io_tlb_nslabs; i++) {
  		io_tlb_list[i] = IO_TLB_SEGSIZE - OFFSET(i, IO_TLB_SEGSIZE);
  		io_tlb_orig_addr[i] = INVALID_PHYS_ADDR;
diff --cc mm/memblock.c
index d424b555c60f,58340de3ebc6..000000000000
--- a/mm/memblock.c
+++ b/mm/memblock.c
@@@ -1319,9 -1318,8 +1319,9 @@@ phys_addr_t __init memblock_phys_alloc_
  	return memblock_alloc_base(size, align, MEMBLOCK_ALLOC_ACCESSIBLE);
  }
  
 +#if defined(CONFIG_NO_BOOTMEM)
  /**
-  * memblock_virt_alloc_internal - allocate boot memory block
+  * memblock_alloc_internal - allocate boot memory block
   * @size: size of memory block to be allocated in bytes
   * @align: alignment of the region and block's size
   * @min_addr: the lower bound of the memory region to allocate (phys address)
@@@ -1441,11 -1437,11 +1441,11 @@@ void * __init memblock_alloc_try_nid_ra
  {
  	void *ptr;
  
 -	memblock_dbg("%s: %llu bytes align=0x%llx nid=%d from=%pa max_addr=%pa %pF\n",
 -		     __func__, (u64)size, (u64)align, nid, &min_addr,
 -		     &max_addr, (void *)_RET_IP_);
 +	memblock_dbg("%s: %llu bytes align=0x%llx nid=%d from=0x%llx max_addr=0x%llx %pF\n",
 +		     __func__, (u64)size, (u64)align, nid, (u64)min_addr,
 +		     (u64)max_addr, (void *)_RET_IP_);
  
- 	ptr = memblock_virt_alloc_internal(size, align,
+ 	ptr = memblock_alloc_internal(size, align,
  					   min_addr, max_addr, nid);
  	if (ptr && size > 0)
  		page_init_poison(ptr, size);
@@@ -1477,11 -1473,11 +1477,11 @@@ void * __init memblock_alloc_try_nid_no
  {
  	void *ptr;
  
 -	memblock_dbg("%s: %llu bytes align=0x%llx nid=%d from=%pa max_addr=%pa %pF\n",
 -		     __func__, (u64)size, (u64)align, nid, &min_addr,
 -		     &max_addr, (void *)_RET_IP_);
 +	memblock_dbg("%s: %llu bytes align=0x%llx nid=%d from=0x%llx max_addr=0x%llx %pF\n",
 +		     __func__, (u64)size, (u64)align, nid, (u64)min_addr,
 +		     (u64)max_addr, (void *)_RET_IP_);
  
- 	ptr = memblock_virt_alloc_internal(size, align,
+ 	ptr = memblock_alloc_internal(size, align,
  					   min_addr, max_addr, nid);
  	if (ptr)
  		memset(ptr, 0, size);
@@@ -1513,10 -1509,10 +1513,17 @@@ void * __init memblock_alloc_try_nid
  {
  	void *ptr;
  
++<<<<<<< HEAD
 +	memblock_dbg("%s: %llu bytes align=0x%llx nid=%d from=0x%llx max_addr=0x%llx %pF\n",
 +		     __func__, (u64)size, (u64)align, nid, (u64)min_addr,
 +		     (u64)max_addr, (void *)_RET_IP_);
 +	ptr = memblock_virt_alloc_internal(size, align,
++=======
+ 	memblock_dbg("%s: %llu bytes align=0x%llx nid=%d from=%pa max_addr=%pa %pF\n",
+ 		     __func__, (u64)size, (u64)align, nid, &min_addr,
+ 		     &max_addr, (void *)_RET_IP_);
+ 	ptr = memblock_alloc_internal(size, align,
++>>>>>>> eb31d559f1e8 (memblock: remove _virt from APIs returning virtual address)
  					   min_addr, max_addr, nid);
  	if (ptr) {
  		memset(ptr, 0, size);
diff --cc mm/percpu.c
index 2dcd250ad0b7,3050c1d37d37..000000000000
--- a/mm/percpu.c
+++ b/mm/percpu.c
@@@ -1328,12 -1101,9 +1328,18 @@@ static struct pcpu_chunk * __init pcpu_
  	region_size = ALIGN(start_offset + map_size, lcm_align);
  
  	/* allocate chunk */
++<<<<<<< HEAD
 +	alloc_size = sizeof(struct pcpu_chunk) +
 +		BITS_TO_LONGS(region_size >> PAGE_SHIFT);
 +	chunk = memblock_virt_alloc(alloc_size, 0);
 +	if (!chunk)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
++=======
+ 	chunk = memblock_alloc(sizeof(struct pcpu_chunk) +
+ 				    BITS_TO_LONGS(region_size >> PAGE_SHIFT),
+ 				    0);
++>>>>>>> eb31d559f1e8 (memblock: remove _virt from APIs returning virtual address)
  
  	INIT_LIST_HEAD(&chunk->list);
  
@@@ -1344,25 -1114,12 +1350,34 @@@
  	chunk->nr_pages = region_size >> PAGE_SHIFT;
  	region_bits = pcpu_chunk_map_bits(chunk);
  
++<<<<<<< HEAD
 +	alloc_size = BITS_TO_LONGS(region_bits) * sizeof(chunk->alloc_map[0]);
 +	chunk->alloc_map = memblock_virt_alloc(alloc_size, 0);
 +	if (!chunk->alloc_map)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
 +
 +	alloc_size =
 +		BITS_TO_LONGS(region_bits + 1) * sizeof(chunk->bound_map[0]);
 +	chunk->bound_map = memblock_virt_alloc(alloc_size, 0);
 +	if (!chunk->bound_map)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
 +
 +	alloc_size = pcpu_chunk_nr_blocks(chunk) * sizeof(chunk->md_blocks[0]);
 +	chunk->md_blocks = memblock_virt_alloc(alloc_size, 0);
 +	if (!chunk->md_blocks)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
 +
++=======
+ 	chunk->alloc_map = memblock_alloc(BITS_TO_LONGS(region_bits) *
+ 					       sizeof(chunk->alloc_map[0]), 0);
+ 	chunk->bound_map = memblock_alloc(BITS_TO_LONGS(region_bits + 1) *
+ 					       sizeof(chunk->bound_map[0]), 0);
+ 	chunk->md_blocks = memblock_alloc(pcpu_chunk_nr_blocks(chunk) *
+ 					       sizeof(chunk->md_blocks[0]), 0);
++>>>>>>> eb31d559f1e8 (memblock: remove _virt from APIs returning virtual address)
  	pcpu_init_md_blocks(chunk);
  
  	/* manage populated page bitmap */
@@@ -2318,29 -2075,12 +2333,38 @@@ int __init pcpu_setup_first_chunk(cons
  	PCPU_SETUP_BUG_ON(pcpu_verify_alloc_info(ai) < 0);
  
  	/* process group information and build config tables accordingly */
++<<<<<<< HEAD
 +	alloc_size = ai->nr_groups * sizeof(group_offsets[0]);
 +	group_offsets = memblock_virt_alloc(alloc_size, 0);
 +	if (!group_offsets)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
 +
 +	alloc_size = ai->nr_groups * sizeof(group_sizes[0]);
 +	group_sizes = memblock_virt_alloc(alloc_size, 0);
 +	if (!group_sizes)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
 +
 +	alloc_size = nr_cpu_ids * sizeof(unit_map[0]);
 +	unit_map = memblock_virt_alloc(alloc_size, 0);
 +	if (!unit_map)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
 +
 +	alloc_size = nr_cpu_ids * sizeof(unit_off[0]);
 +	unit_off = memblock_virt_alloc(alloc_size, 0);
 +	if (!unit_off)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      alloc_size);
++=======
+ 	group_offsets = memblock_alloc(ai->nr_groups *
+ 					     sizeof(group_offsets[0]), 0);
+ 	group_sizes = memblock_alloc(ai->nr_groups *
+ 					   sizeof(group_sizes[0]), 0);
+ 	unit_map = memblock_alloc(nr_cpu_ids * sizeof(unit_map[0]), 0);
+ 	unit_off = memblock_alloc(nr_cpu_ids * sizeof(unit_off[0]), 0);
++>>>>>>> eb31d559f1e8 (memblock: remove _virt from APIs returning virtual address)
  
  	for (cpu = 0; cpu < nr_cpu_ids; cpu++)
  		unit_map[cpu] = UINT_MAX;
@@@ -2404,11 -2144,8 +2428,16 @@@
  	 * empty chunks.
  	 */
  	pcpu_nr_slots = __pcpu_size_to_slot(pcpu_unit_size) + 2;
++<<<<<<< HEAD
 +	pcpu_slot = memblock_virt_alloc(pcpu_nr_slots * sizeof(pcpu_slot[0]),
 +				   0);
 +	if (!pcpu_slot)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      pcpu_nr_slots * sizeof(pcpu_slot[0]));
++=======
+ 	pcpu_slot = memblock_alloc(
+ 			pcpu_nr_slots * sizeof(pcpu_slot[0]), 0);
++>>>>>>> eb31d559f1e8 (memblock: remove _virt from APIs returning virtual address)
  	for (i = 0; i < pcpu_nr_slots; i++)
  		INIT_LIST_HEAD(&pcpu_slot[i]);
  
@@@ -2862,10 -2599,7 +2891,14 @@@ int __init pcpu_page_first_chunk(size_
  	/* unaligned allocations can't be freed, round up to page size */
  	pages_size = PFN_ALIGN(unit_pages * num_possible_cpus() *
  			       sizeof(pages[0]));
++<<<<<<< HEAD
 +	pages = memblock_virt_alloc(pages_size, 0);
 +	if (!pages)
 +		panic("%s: Failed to allocate %zu bytes\n", __func__,
 +		      pages_size);
++=======
+ 	pages = memblock_alloc(pages_size, 0);
++>>>>>>> eb31d559f1e8 (memblock: remove _virt from APIs returning virtual address)
  
  	/* allocate pages */
  	j = 0;
diff --cc mm/sparse.c
index 743faed13a8f,cb900dda7fd2..000000000000
--- a/mm/sparse.c
+++ b/mm/sparse.c
@@@ -346,10 -306,10 +346,14 @@@ sparse_early_usemaps_alloc_pgdat_sectio
  	limit = goal + (1UL << PA_SECTION_SHIFT);
  	nid = early_pfn_to_nid(goal >> PAGE_SHIFT);
  again:
++<<<<<<< HEAD
 +	usage = memblock_virt_alloc_try_nid_nopanic(size,
++=======
+ 	p = memblock_alloc_try_nid_nopanic(size,
++>>>>>>> eb31d559f1e8 (memblock: remove _virt from APIs returning virtual address)
  						SMP_CACHE_BYTES, goal, limit,
  						nid);
 -	if (!p && limit) {
 +	if (!usage && limit) {
  		limit = 0;
  		goto again;
  	}
@@@ -403,11 -362,10 +407,11 @@@ static struct mem_section_usage * __ini
  sparse_early_usemaps_alloc_pgdat_section(struct pglist_data *pgdat,
  					 unsigned long size)
  {
- 	return memblock_virt_alloc_node_nopanic(size, pgdat->node_id);
+ 	return memblock_alloc_node_nopanic(size, pgdat->node_id);
  }
  
 -static void __init check_usemap_section_nr(int nid, unsigned long *usemap)
 +static void __init check_usemap_section_nr(int nid,
 +		struct mem_section_usage *usage)
  {
  }
  #endif /* CONFIG_MEMORY_HOTREMOVE */
diff --git a/arch/arm/kernel/setup.c b/arch/arm/kernel/setup.c
index 35ca494c028c..14b274c57edb 100644
--- a/arch/arm/kernel/setup.c
+++ b/arch/arm/kernel/setup.c
@@ -857,7 +857,7 @@ static void __init request_standard_resources(const struct machine_desc *mdesc)
 		 */
 		boot_alias_start = phys_to_idmap(start);
 		if (arm_has_idmap_alias() && boot_alias_start != IDMAP_INVALID_ADDR) {
-			res = memblock_virt_alloc(sizeof(*res), 0);
+			res = memblock_alloc(sizeof(*res), 0);
 			res->name = "System RAM (boot alias)";
 			res->start = boot_alias_start;
 			res->end = phys_to_idmap(end);
@@ -865,7 +865,7 @@ static void __init request_standard_resources(const struct machine_desc *mdesc)
 			request_resource(&iomem_resource, res);
 		}
 
-		res = memblock_virt_alloc(sizeof(*res), 0);
+		res = memblock_alloc(sizeof(*res), 0);
 		res->name  = "System RAM";
 		res->start = start;
 		res->end = end;
* Unmerged path arch/arm/mach-omap2/omap_hwmod.c
diff --git a/arch/arm64/mm/kasan_init.c b/arch/arm64/mm/kasan_init.c
index af7fdd95f378..835acb31839d 100644
--- a/arch/arm64/mm/kasan_init.c
+++ b/arch/arm64/mm/kasan_init.c
@@ -38,7 +38,7 @@ static pgd_t tmp_pg_dir[PTRS_PER_PGD] __initdata __aligned(PGD_SIZE);
 
 static phys_addr_t __init kasan_alloc_zeroed_page(int node)
 {
-	void *p = memblock_virt_alloc_try_nid(PAGE_SIZE, PAGE_SIZE,
+	void *p = memblock_alloc_try_nid(PAGE_SIZE, PAGE_SIZE,
 					      __pa(MAX_DMA_ADDRESS),
 					      MEMBLOCK_ALLOC_KASAN, node);
 	return __pa(p);
diff --git a/arch/arm64/mm/numa.c b/arch/arm64/mm/numa.c
index 5faf7fa7845e..d25d5bf9adc0 100644
--- a/arch/arm64/mm/numa.c
+++ b/arch/arm64/mm/numa.c
@@ -168,7 +168,7 @@ static void * __init pcpu_fc_alloc(unsigned int cpu, size_t size,
 {
 	int nid = early_cpu_to_node(cpu);
 
-	return  memblock_virt_alloc_try_nid(size, align,
+	return  memblock_alloc_try_nid(size, align,
 			__pa(MAX_DMA_ADDRESS), MEMBLOCK_ALLOC_ACCESSIBLE, nid);
 }
 
* Unmerged path arch/mips/kernel/setup.c
diff --git a/arch/powerpc/kernel/pci_32.c b/arch/powerpc/kernel/pci_32.c
index d63b488d34d7..2fb4781dd134 100644
--- a/arch/powerpc/kernel/pci_32.c
+++ b/arch/powerpc/kernel/pci_32.c
@@ -204,7 +204,7 @@ pci_create_OF_bus_map(void)
 	struct property* of_prop;
 	struct device_node *dn;
 
-	of_prop = memblock_virt_alloc(sizeof(struct property) + 256, 0);
+	of_prop = memblock_alloc(sizeof(struct property) + 256, 0);
 	dn = of_find_node_by_path("/");
 	if (dn) {
 		memset(of_prop, -1, sizeof(struct property) + 256);
diff --git a/arch/powerpc/lib/alloc.c b/arch/powerpc/lib/alloc.c
index 06796dec01ea..bf87d6e13369 100644
--- a/arch/powerpc/lib/alloc.c
+++ b/arch/powerpc/lib/alloc.c
@@ -14,7 +14,7 @@ void * __ref zalloc_maybe_bootmem(size_t size, gfp_t mask)
 	if (slab_is_available())
 		p = kzalloc(size, mask);
 	else {
-		p = memblock_virt_alloc(size, 0);
+		p = memblock_alloc(size, 0);
 	}
 	return p;
 }
diff --git a/arch/powerpc/mm/mmu_context_nohash.c b/arch/powerpc/mm/mmu_context_nohash.c
index e50c3c7c2401..31c35ef06af6 100644
--- a/arch/powerpc/mm/mmu_context_nohash.c
+++ b/arch/powerpc/mm/mmu_context_nohash.c
@@ -461,10 +461,10 @@ void __init mmu_context_init(void)
 	/*
 	 * Allocate the maps used by context management
 	 */
-	context_map = memblock_virt_alloc(CTX_MAP_SIZE, 0);
-	context_mm = memblock_virt_alloc(sizeof(void *) * (LAST_CONTEXT + 1), 0);
+	context_map = memblock_alloc(CTX_MAP_SIZE, 0);
+	context_mm = memblock_alloc(sizeof(void *) * (LAST_CONTEXT + 1), 0);
 #ifdef CONFIG_SMP
-	stale_map[boot_cpuid] = memblock_virt_alloc(CTX_MAP_SIZE, 0);
+	stale_map[boot_cpuid] = memblock_alloc(CTX_MAP_SIZE, 0);
 
 	cpuhp_setup_state_nocalls(CPUHP_POWERPC_MMU_CTX_PREPARE,
 				  "powerpc/mmu/ctx:prepare",
diff --git a/arch/powerpc/platforms/powermac/nvram.c b/arch/powerpc/platforms/powermac/nvram.c
index 60b03a1703d1..f45b369177a4 100644
--- a/arch/powerpc/platforms/powermac/nvram.c
+++ b/arch/powerpc/platforms/powermac/nvram.c
@@ -513,7 +513,7 @@ static int __init core99_nvram_setup(struct device_node *dp, unsigned long addr)
 		printk(KERN_ERR "nvram: no address\n");
 		return -EINVAL;
 	}
-	nvram_image = memblock_virt_alloc(NVRAM_SIZE, 0);
+	nvram_image = memblock_alloc(NVRAM_SIZE, 0);
 	nvram_data = ioremap(addr, NVRAM_SIZE*2);
 	nvram_naddrs = 1; /* Make sure we get the correct case */
 
diff --git a/arch/powerpc/platforms/powernv/pci-ioda.c b/arch/powerpc/platforms/powernv/pci-ioda.c
index efb558ad5aa1..1abe813cbbb2 100644
--- a/arch/powerpc/platforms/powernv/pci-ioda.c
+++ b/arch/powerpc/platforms/powernv/pci-ioda.c
@@ -3776,7 +3776,7 @@ static void __init pnv_pci_init_ioda_phb(struct device_node *np,
 	phb_id = be64_to_cpup(prop64);
 	pr_debug("  PHB-ID  : 0x%016llx\n", phb_id);
 
-	phb = memblock_virt_alloc(sizeof(*phb), 0);
+	phb = memblock_alloc(sizeof(*phb), 0);
 
 	/* Allocate PCI controller */
 	phb->hose = hose = pcibios_alloc_controller(np);
@@ -3822,7 +3822,7 @@ static void __init pnv_pci_init_ioda_phb(struct device_node *np,
 	else
 		phb->diag_data_size = PNV_PCI_DIAG_BUF_SIZE;
 
-	phb->diag_data = memblock_virt_alloc(phb->diag_data_size, 0);
+	phb->diag_data = memblock_alloc(phb->diag_data_size, 0);
 
 	/* Parse 32-bit and IO ranges (if any) */
 	pci_process_bridge_OF_ranges(hose, np, !hose->global_number);
@@ -3881,7 +3881,7 @@ static void __init pnv_pci_init_ioda_phb(struct device_node *np,
 	}
 	pemap_off = size;
 	size += phb->ioda.total_pe_num * sizeof(struct pnv_ioda_pe);
-	aux = memblock_virt_alloc(size, 0);
+	aux = memblock_alloc(size, 0);
 	phb->ioda.pe_alloc = aux;
 	phb->ioda.m64_segmap = aux + m64map_off;
 	phb->ioda.m32_segmap = aux + m32map_off;
diff --git a/arch/powerpc/platforms/ps3/setup.c b/arch/powerpc/platforms/ps3/setup.c
index 77a37520068d..12519857a33c 100644
--- a/arch/powerpc/platforms/ps3/setup.c
+++ b/arch/powerpc/platforms/ps3/setup.c
@@ -126,7 +126,7 @@ static void __init prealloc(struct ps3_prealloc *p)
 	if (!p->size)
 		return;
 
-	p->address = memblock_virt_alloc(p->size, p->align);
+	p->address = memblock_alloc(p->size, p->align);
 
 	printk(KERN_INFO "%s: %lu bytes at %p\n", p->name, p->size,
 	       p->address);
diff --git a/arch/powerpc/sysdev/msi_bitmap.c b/arch/powerpc/sysdev/msi_bitmap.c
index 6243a7e537d0..78c45ecd2951 100644
--- a/arch/powerpc/sysdev/msi_bitmap.c
+++ b/arch/powerpc/sysdev/msi_bitmap.c
@@ -128,7 +128,7 @@ int __ref msi_bitmap_alloc(struct msi_bitmap *bmp, unsigned int irq_count,
 	if (bmp->bitmap_from_slab)
 		bmp->bitmap = kzalloc(size, GFP_KERNEL);
 	else {
-		bmp->bitmap = memblock_virt_alloc(size, 0);
+		bmp->bitmap = memblock_alloc(size, 0);
 		/* the bitmap won't be freed from memblock allocator */
 		kmemleak_not_leak(bmp->bitmap);
 	}
* Unmerged path arch/s390/kernel/setup.c
diff --git a/arch/s390/kernel/smp.c b/arch/s390/kernel/smp.c
index 79ac23d3301b..dca9e7714a77 100644
--- a/arch/s390/kernel/smp.c
+++ b/arch/s390/kernel/smp.c
@@ -757,7 +757,7 @@ void __init smp_detect_cpus(void)
 	u16 address;
 
 	/* Get CPU information */
-	info = memblock_virt_alloc(sizeof(*info), 8);
+	info = memblock_alloc(sizeof(*info), 8);
 	smp_get_core_info(info, 1);
 	/* Find boot CPU type */
 	if (sclp.has_core_type) {
diff --git a/arch/s390/kernel/topology.c b/arch/s390/kernel/topology.c
index 4b6e0397f66d..b70ba5c07dba 100644
--- a/arch/s390/kernel/topology.c
+++ b/arch/s390/kernel/topology.c
@@ -519,7 +519,7 @@ static void __init alloc_masks(struct sysinfo_15_1_x *info,
 		nr_masks *= info->mag[TOPOLOGY_NR_MAG - offset - 1 - i];
 	nr_masks = max(nr_masks, 1);
 	for (i = 0; i < nr_masks; i++) {
-		mask->next = memblock_virt_alloc(sizeof(*mask->next), 8);
+		mask->next = memblock_alloc(sizeof(*mask->next), 8);
 		mask = mask->next;
 	}
 }
@@ -537,7 +537,7 @@ void __init topology_init_early(void)
 	}
 	if (!MACHINE_HAS_TOPOLOGY)
 		goto out;
-	tl_info = memblock_virt_alloc(PAGE_SIZE, PAGE_SIZE);
+	tl_info = memblock_alloc(PAGE_SIZE, PAGE_SIZE);
 	info = tl_info;
 	store_topology(info);
 	pr_info("The CPU configuration topology of the machine is: %d %d %d %d %d %d / %d\n",
diff --git a/arch/s390/numa/mode_emu.c b/arch/s390/numa/mode_emu.c
index 83b222c57609..5a381fc8e958 100644
--- a/arch/s390/numa/mode_emu.c
+++ b/arch/s390/numa/mode_emu.c
@@ -313,7 +313,7 @@ static void __ref create_core_to_node_map(void)
 {
 	int i;
 
-	emu_cores = memblock_virt_alloc(sizeof(*emu_cores), 8);
+	emu_cores = memblock_alloc(sizeof(*emu_cores), 8);
 	for (i = 0; i < ARRAY_SIZE(emu_cores->to_node_id); i++)
 		emu_cores->to_node_id[i] = NODE_ID_FREE;
 }
diff --git a/arch/s390/numa/toptree.c b/arch/s390/numa/toptree.c
index 21d1e8a1546d..7f61cc3fd4d1 100644
--- a/arch/s390/numa/toptree.c
+++ b/arch/s390/numa/toptree.c
@@ -34,7 +34,7 @@ struct toptree __ref *toptree_alloc(int level, int id)
 	if (slab_is_available())
 		res = kzalloc(sizeof(*res), GFP_KERNEL);
 	else
-		res = memblock_virt_alloc(sizeof(*res), 8);
+		res = memblock_alloc(sizeof(*res), 8);
 	if (!res)
 		return res;
 
diff --git a/arch/x86/mm/kasan_init_64.c b/arch/x86/mm/kasan_init_64.c
index e3e77527f8df..77b857cb036f 100644
--- a/arch/x86/mm/kasan_init_64.c
+++ b/arch/x86/mm/kasan_init_64.c
@@ -28,10 +28,10 @@ static p4d_t tmp_p4d_table[MAX_PTRS_PER_P4D] __initdata __aligned(PAGE_SIZE);
 static __init void *early_alloc(size_t size, int nid, bool panic)
 {
 	if (panic)
-		return memblock_virt_alloc_try_nid(size, size,
+		return memblock_alloc_try_nid(size, size,
 			__pa(MAX_DMA_ADDRESS), BOOTMEM_ALLOC_ACCESSIBLE, nid);
 	else
-		return memblock_virt_alloc_try_nid_nopanic(size, size,
+		return memblock_alloc_try_nid_nopanic(size, size,
 			__pa(MAX_DMA_ADDRESS), BOOTMEM_ALLOC_ACCESSIBLE, nid);
 }
 
diff --git a/arch/xtensa/mm/kasan_init.c b/arch/xtensa/mm/kasan_init.c
index 6b532b6bd785..1a30a258ccd0 100644
--- a/arch/xtensa/mm/kasan_init.c
+++ b/arch/xtensa/mm/kasan_init.c
@@ -43,7 +43,7 @@ static void __init populate(void *start, void *end)
 	unsigned long vaddr = (unsigned long)start;
 	pgd_t *pgd = pgd_offset_k(vaddr);
 	pmd_t *pmd = pmd_offset(pgd, vaddr);
-	pte_t *pte = memblock_virt_alloc(n_pages * sizeof(pte_t), PAGE_SIZE);
+	pte_t *pte = memblock_alloc(n_pages * sizeof(pte_t), PAGE_SIZE);
 
 	pr_debug("%s: %p - %p\n", __func__, start, end);
 
diff --git a/drivers/clk/ti/clk.c b/drivers/clk/ti/clk.c
index 7d22e1af2247..5c54d3734daf 100644
--- a/drivers/clk/ti/clk.c
+++ b/drivers/clk/ti/clk.c
@@ -342,7 +342,7 @@ void __init omap2_clk_legacy_provider_init(int index, void __iomem *mem)
 {
 	struct clk_iomap *io;
 
-	io = memblock_virt_alloc(sizeof(*io), 0);
+	io = memblock_alloc(sizeof(*io), 0);
 
 	io->mem = mem;
 
diff --git a/drivers/firmware/memmap.c b/drivers/firmware/memmap.c
index 5de3ed29282c..03cead6d5f97 100644
--- a/drivers/firmware/memmap.c
+++ b/drivers/firmware/memmap.c
@@ -333,7 +333,7 @@ int __init firmware_map_add_early(u64 start, u64 end, const char *type)
 {
 	struct firmware_map_entry *entry;
 
-	entry = memblock_virt_alloc(sizeof(struct firmware_map_entry), 0);
+	entry = memblock_alloc(sizeof(struct firmware_map_entry), 0);
 	if (WARN_ON(!entry))
 		return -ENOMEM;
 
diff --git a/drivers/of/fdt.c b/drivers/of/fdt.c
index 6da20b9688f7..829efaf56dc8 100644
--- a/drivers/of/fdt.c
+++ b/drivers/of/fdt.c
@@ -1206,7 +1206,7 @@ int __init __weak early_init_dt_reserve_memory_arch(phys_addr_t base,
 
 static void * __init early_init_dt_alloc_memory_arch(u64 size, u64 align)
 {
-	return memblock_virt_alloc(size, align);
+	return memblock_alloc(size, align);
 }
 
 bool __init early_init_dt_verify(void *params)
diff --git a/drivers/of/unittest.c b/drivers/of/unittest.c
index 722537e14848..3a8bffa0747b 100644
--- a/drivers/of/unittest.c
+++ b/drivers/of/unittest.c
@@ -2178,7 +2178,7 @@ static struct device_node *overlay_base_root;
 
 static void * __init dt_alloc_memory(u64 size, u64 align)
 {
-	return memblock_virt_alloc(size, align);
+	return memblock_alloc(size, align);
 }
 
 /*
diff --git a/include/linux/bootmem.h b/include/linux/bootmem.h
index 42515195d7d8..19f2f104512d 100644
--- a/include/linux/bootmem.h
+++ b/include/linux/bootmem.h
@@ -172,78 +172,78 @@ extern void *__alloc_bootmem_low_node(pg_data_t *pgdat,
 #define BOOTMEM_ALLOC_ANYWHERE		(~(phys_addr_t)0)
 
 /* FIXME: Move to memblock.h at a point where we remove nobootmem.c */
-void *memblock_virt_alloc_try_nid_raw(phys_addr_t size, phys_addr_t align,
+void *memblock_alloc_try_nid_raw(phys_addr_t size, phys_addr_t align,
 				      phys_addr_t min_addr,
 				      phys_addr_t max_addr, int nid);
-void *memblock_virt_alloc_try_nid_nopanic(phys_addr_t size,
+void *memblock_alloc_try_nid_nopanic(phys_addr_t size,
 		phys_addr_t align, phys_addr_t min_addr,
 		phys_addr_t max_addr, int nid);
-void *memblock_virt_alloc_try_nid(phys_addr_t size, phys_addr_t align,
+void *memblock_alloc_try_nid(phys_addr_t size, phys_addr_t align,
 		phys_addr_t min_addr, phys_addr_t max_addr, int nid);
 void __memblock_free_early(phys_addr_t base, phys_addr_t size);
 void __memblock_free_late(phys_addr_t base, phys_addr_t size);
 
-static inline void * __init memblock_virt_alloc(
+static inline void * __init memblock_alloc(
 					phys_addr_t size,  phys_addr_t align)
 {
-	return memblock_virt_alloc_try_nid(size, align, BOOTMEM_LOW_LIMIT,
+	return memblock_alloc_try_nid(size, align, BOOTMEM_LOW_LIMIT,
 					    BOOTMEM_ALLOC_ACCESSIBLE,
 					    NUMA_NO_NODE);
 }
 
-static inline void * __init memblock_virt_alloc_raw(
+static inline void * __init memblock_alloc_raw(
 					phys_addr_t size,  phys_addr_t align)
 {
-	return memblock_virt_alloc_try_nid_raw(size, align, BOOTMEM_LOW_LIMIT,
+	return memblock_alloc_try_nid_raw(size, align, BOOTMEM_LOW_LIMIT,
 					    BOOTMEM_ALLOC_ACCESSIBLE,
 					    NUMA_NO_NODE);
 }
 
-static inline void * __init memblock_virt_alloc_nopanic(
+static inline void * __init memblock_alloc_nopanic(
 					phys_addr_t size, phys_addr_t align)
 {
-	return memblock_virt_alloc_try_nid_nopanic(size, align,
+	return memblock_alloc_try_nid_nopanic(size, align,
 						    BOOTMEM_LOW_LIMIT,
 						    BOOTMEM_ALLOC_ACCESSIBLE,
 						    NUMA_NO_NODE);
 }
 
-static inline void * __init memblock_virt_alloc_low(
+static inline void * __init memblock_alloc_low(
 					phys_addr_t size, phys_addr_t align)
 {
-	return memblock_virt_alloc_try_nid(size, align,
+	return memblock_alloc_try_nid(size, align,
 						   BOOTMEM_LOW_LIMIT,
 						   ARCH_LOW_ADDRESS_LIMIT,
 						   NUMA_NO_NODE);
 }
-static inline void * __init memblock_virt_alloc_low_nopanic(
+static inline void * __init memblock_alloc_low_nopanic(
 					phys_addr_t size, phys_addr_t align)
 {
-	return memblock_virt_alloc_try_nid_nopanic(size, align,
+	return memblock_alloc_try_nid_nopanic(size, align,
 						   BOOTMEM_LOW_LIMIT,
 						   ARCH_LOW_ADDRESS_LIMIT,
 						   NUMA_NO_NODE);
 }
 
-static inline void * __init memblock_virt_alloc_from_nopanic(
+static inline void * __init memblock_alloc_from_nopanic(
 		phys_addr_t size, phys_addr_t align, phys_addr_t min_addr)
 {
-	return memblock_virt_alloc_try_nid_nopanic(size, align, min_addr,
+	return memblock_alloc_try_nid_nopanic(size, align, min_addr,
 						    BOOTMEM_ALLOC_ACCESSIBLE,
 						    NUMA_NO_NODE);
 }
 
-static inline void * __init memblock_virt_alloc_node(
+static inline void * __init memblock_alloc_node(
 						phys_addr_t size, int nid)
 {
-	return memblock_virt_alloc_try_nid(size, 0, BOOTMEM_LOW_LIMIT,
+	return memblock_alloc_try_nid(size, 0, BOOTMEM_LOW_LIMIT,
 					    BOOTMEM_ALLOC_ACCESSIBLE, nid);
 }
 
-static inline void * __init memblock_virt_alloc_node_nopanic(
+static inline void * __init memblock_alloc_node_nopanic(
 						phys_addr_t size, int nid)
 {
-	return memblock_virt_alloc_try_nid_nopanic(size, 0, BOOTMEM_LOW_LIMIT,
+	return memblock_alloc_try_nid_nopanic(size, 0, BOOTMEM_LOW_LIMIT,
 						    BOOTMEM_ALLOC_ACCESSIBLE,
 						    nid);
 }
diff --git a/init/main.c b/init/main.c
index 0b1da34b3bf4..2eb00eeaba7a 100644
--- a/init/main.c
+++ b/init/main.c
@@ -376,10 +376,10 @@ static inline void smp_prepare_cpus(unsigned int maxcpus) { }
 static void __init setup_command_line(char *command_line)
 {
 	saved_command_line =
-		memblock_virt_alloc(strlen(boot_command_line) + 1, 0);
+		memblock_alloc(strlen(boot_command_line) + 1, 0);
 	initcall_command_line =
-		memblock_virt_alloc(strlen(boot_command_line) + 1, 0);
-	static_command_line = memblock_virt_alloc(strlen(command_line) + 1, 0);
+		memblock_alloc(strlen(boot_command_line) + 1, 0);
+	static_command_line = memblock_alloc(strlen(command_line) + 1, 0);
 	strcpy(saved_command_line, boot_command_line);
 	strcpy(static_command_line, command_line);
 }
* Unmerged path kernel/dma/swiotlb.c
diff --git a/kernel/power/snapshot.c b/kernel/power/snapshot.c
index c6550dbba7e2..b7df4a3fdf66 100644
--- a/kernel/power/snapshot.c
+++ b/kernel/power/snapshot.c
@@ -963,7 +963,7 @@ void __init __register_nosave_region(unsigned long start_pfn,
 		BUG_ON(!region);
 	} else {
 		/* This allocation cannot fail */
-		region = memblock_virt_alloc(sizeof(struct nosave_region), 0);
+		region = memblock_alloc(sizeof(struct nosave_region), 0);
 	}
 	region->start_pfn = start_pfn;
 	region->end_pfn = end_pfn;
diff --git a/kernel/printk/printk.c b/kernel/printk/printk.c
index 61ec36698a8d..41f09687a730 100644
--- a/kernel/printk/printk.c
+++ b/kernel/printk/printk.c
@@ -1154,9 +1154,9 @@ void __init setup_log_buf(int early)
 
 	if (early) {
 		new_log_buf =
-			memblock_virt_alloc(new_log_buf_len, LOG_ALIGN);
+			memblock_alloc(new_log_buf_len, LOG_ALIGN);
 	} else {
-		new_log_buf = memblock_virt_alloc_nopanic(new_log_buf_len,
+		new_log_buf = memblock_alloc_nopanic(new_log_buf_len,
 							  LOG_ALIGN);
 	}
 
diff --git a/lib/cpumask.c b/lib/cpumask.c
index beca6244671a..1405cb22e6bc 100644
--- a/lib/cpumask.c
+++ b/lib/cpumask.c
@@ -163,7 +163,7 @@ EXPORT_SYMBOL(zalloc_cpumask_var);
  */
 void __init alloc_bootmem_cpumask_var(cpumask_var_t *mask)
 {
-	*mask = memblock_virt_alloc(cpumask_size(), 0);
+	*mask = memblock_alloc(cpumask_size(), 0);
 }
 
 /**
diff --git a/mm/hugetlb.c b/mm/hugetlb.c
index 449fb9efecb9..48e58a2686b7 100644
--- a/mm/hugetlb.c
+++ b/mm/hugetlb.c
@@ -2160,7 +2160,7 @@ int __alloc_bootmem_huge_page(struct hstate *h)
 	for_each_node_mask_to_alloc(h, nr_nodes, node, &node_states[N_MEMORY]) {
 		void *addr;
 
-		addr = memblock_virt_alloc_try_nid_raw(
+		addr = memblock_alloc_try_nid_raw(
 				huge_page_size(h), huge_page_size(h),
 				0, BOOTMEM_ALLOC_ACCESSIBLE, node);
 		if (addr) {
diff --git a/mm/kasan/kasan_init.c b/mm/kasan/kasan_init.c
index 7a2a2f13f86f..24d734bdff6b 100644
--- a/mm/kasan/kasan_init.c
+++ b/mm/kasan/kasan_init.c
@@ -83,7 +83,7 @@ static inline bool kasan_zero_page_entry(pte_t pte)
 
 static __init void *early_alloc(size_t size, int node)
 {
-	return memblock_virt_alloc_try_nid(size, size, __pa(MAX_DMA_ADDRESS),
+	return memblock_alloc_try_nid(size, size, __pa(MAX_DMA_ADDRESS),
 					BOOTMEM_ALLOC_ACCESSIBLE, node);
 }
 
* Unmerged path mm/memblock.c
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 9fb621db90ec..c085ef188b1b 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -6249,7 +6249,7 @@ static void __init setup_usemap(struct pglist_data *pgdat,
 	zone->pageblock_flags = NULL;
 	if (usemapsize)
 		zone->pageblock_flags =
-			memblock_virt_alloc_node_nopanic(usemapsize,
+			memblock_alloc_node_nopanic(usemapsize,
 							 pgdat->node_id);
 }
 #else
@@ -6434,7 +6434,7 @@ static void __ref alloc_node_mem_map(struct pglist_data *pgdat)
 		end = pgdat_end_pfn(pgdat);
 		end = ALIGN(end, MAX_ORDER_NR_PAGES);
 		size =  (end - start) * sizeof(struct page);
-		map = memblock_virt_alloc_node_nopanic(size, pgdat->node_id);
+		map = memblock_alloc_node_nopanic(size, pgdat->node_id);
 		pgdat->node_mem_map = map + offset;
 	}
 	pr_debug("%s: node %d, pgdat %08lx, node_mem_map %08lx\n",
@@ -7696,9 +7696,9 @@ void *__init alloc_large_system_hash(const char *tablename,
 		size = bucketsize << log2qty;
 		if (flags & HASH_EARLY) {
 			if (flags & HASH_ZERO)
-				table = memblock_virt_alloc_nopanic(size, 0);
+				table = memblock_alloc_nopanic(size, 0);
 			else
-				table = memblock_virt_alloc_raw(size, 0);
+				table = memblock_alloc_raw(size, 0);
 		} else if (hashdist) {
 			table = __vmalloc(size, gfp_flags, PAGE_KERNEL);
 		} else {
diff --git a/mm/page_ext.c b/mm/page_ext.c
index 5295ef331165..6aa72f9d986a 100644
--- a/mm/page_ext.c
+++ b/mm/page_ext.c
@@ -161,7 +161,7 @@ static int __init alloc_node_page_ext(int nid)
 
 	table_size = get_entry_size() * nr_pages;
 
-	base = memblock_virt_alloc_try_nid_nopanic(
+	base = memblock_alloc_try_nid_nopanic(
 			table_size, PAGE_SIZE, __pa(MAX_DMA_ADDRESS),
 			BOOTMEM_ALLOC_ACCESSIBLE, nid);
 	if (!base)
* Unmerged path mm/percpu.c
diff --git a/mm/sparse-vmemmap.c b/mm/sparse-vmemmap.c
index 560f92e52b56..714fc8bd4e8f 100644
--- a/mm/sparse-vmemmap.c
+++ b/mm/sparse-vmemmap.c
@@ -42,7 +42,7 @@ static void * __ref __earlyonly_bootmem_alloc(int node,
 				unsigned long align,
 				unsigned long goal)
 {
-	return memblock_virt_alloc_try_nid_raw(size, align, goal,
+	return memblock_alloc_try_nid_raw(size, align, goal,
 					       BOOTMEM_ALLOC_ACCESSIBLE, node);
 }
 
* Unmerged path mm/sparse.c
