crypto: chelsio - Use multiple txq/rxq per tfm to process the requests

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Ayush Sawal <ayush.sawal@chelsio.com>
commit 567be3a5d2270fb1971212f704240d6235a2c060
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/567be3a5.failed

This patch enables chcr to use multiple txq/rxq per tfm
to process the crypto requests. The txq/rxq are selected based
on  cpu core-id.

	Signed-off-by: Ayush Sawal <ayush.sawal@chelsio.com>
	Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
(cherry picked from commit 567be3a5d2270fb1971212f704240d6235a2c060)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/crypto/chelsio/chcr_algo.c
#	drivers/crypto/chelsio/chcr_crypto.h
diff --cc drivers/crypto/chelsio/chcr_algo.c
index 8d9f707b07ea,8952732c0b7d..000000000000
--- a/drivers/crypto/chelsio/chcr_algo.c
+++ b/drivers/crypto/chelsio/chcr_algo.c
@@@ -757,8 -808,9 +808,14 @@@ static inline void create_wreq(struct c
   */
  static struct sk_buff *create_cipher_wr(struct cipher_wr_param *wrparam)
  {
++<<<<<<< HEAD
 +	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(wrparam->req);
 +	struct ablk_ctx *ablkctx = ABLK_CTX(c_ctx(tfm));
++=======
+ 	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(wrparam->req);
+ 	struct chcr_context *ctx = c_ctx(tfm);
+ 	struct ablk_ctx *ablkctx = ABLK_CTX(ctx);
++>>>>>>> 567be3a5d227 (crypto: chelsio - Use multiple txq/rxq per tfm to process the requests)
  	struct sk_buff *skb = NULL;
  	struct chcr_wr *chcr_req;
  	struct cpl_rx_phys_dsgl *phys_cpl;
@@@ -1115,8 -1164,8 +1173,13 @@@ static int chcr_handle_cipher_resp(stru
  	struct ablk_ctx *ablkctx = ABLK_CTX(c_ctx(tfm));
  	struct sk_buff *skb;
  	struct cpl_fw6_pld *fw6_pld = (struct cpl_fw6_pld *)input;
++<<<<<<< HEAD
 +	struct chcr_blkcipher_req_ctx *reqctx = ablkcipher_request_ctx(req);
 +	struct  cipher_wr_param wrparam;
++=======
+ 	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
+ 	struct cipher_wr_param wrparam;
++>>>>>>> 567be3a5d227 (crypto: chelsio - Use multiple txq/rxq per tfm to process the requests)
  	struct chcr_dev *dev = c_ctx(tfm)->dev;
  	int bytes;
  
@@@ -1158,10 -1207,10 +1221,10 @@@
  		goto complete;
  	}
  
 -	if (get_cryptoalg_subtype(tfm) ==
 +	if (get_cryptoalg_subtype(crypto_ablkcipher_tfm(tfm)) ==
  	    CRYPTO_ALG_SUB_TYPE_CTR)
  		bytes = adjust_ctr_overflow(reqctx->iv, bytes);
- 	wrparam.qid = u_ctx->lldi.rxq_ids[c_ctx(tfm)->rx_qidx];
+ 	wrparam.qid = u_ctx->lldi.rxq_ids[reqctx->rxqidx];
  	wrparam.req = req;
  	wrparam.bytes = bytes;
  	skb = create_cipher_wr(&wrparam);
@@@ -1295,13 -1356,21 +1358,25 @@@ error
  	return err;
  }
  
 -static int chcr_aes_encrypt(struct skcipher_request *req)
 +static int chcr_aes_encrypt(struct ablkcipher_request *req)
  {
++<<<<<<< HEAD
 +	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
++=======
+ 	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
+ 	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
++>>>>>>> 567be3a5d227 (crypto: chelsio - Use multiple txq/rxq per tfm to process the requests)
  	struct chcr_dev *dev = c_ctx(tfm)->dev;
  	struct sk_buff *skb = NULL;
- 	int err, isfull = 0;
+ 	int err;
  	struct uld_ctx *u_ctx = ULD_CTX(c_ctx(tfm));
+ 	struct chcr_context *ctx = c_ctx(tfm);
+ 	unsigned int cpu;
+ 
+ 	cpu = get_cpu();
+ 	reqctx->txqidx = cpu % ctx->ntxq;
+ 	reqctx->rxqidx = cpu % ctx->nrxq;
+ 	put_cpu();
  
  	err = chcr_inc_wrcount(dev);
  	if (err)
@@@ -1320,17 -1387,24 +1393,32 @@@
  	if (err || !skb)
  		return  err;
  	skb->dev = u_ctx->lldi.ports[0];
- 	set_wr_txq(skb, CPL_PRIORITY_DATA, c_ctx(tfm)->tx_qidx);
+ 	set_wr_txq(skb, CPL_PRIORITY_DATA, reqctx->txqidx);
  	chcr_send_wr(skb);
++<<<<<<< HEAD
 +	return isfull ? -EBUSY : -EINPROGRESS;
++=======
+ 	if (get_cryptoalg_subtype(tfm) ==
+ 		CRYPTO_ALG_SUB_TYPE_CBC && req->base.flags ==
+ 			CRYPTO_TFM_REQ_MAY_SLEEP ) {
+ 			reqctx->partial_req = 1;
+ 			wait_for_completion(&ctx->cbc_aes_aio_done);
+         }
+ 	return -EINPROGRESS;
++>>>>>>> 567be3a5d227 (crypto: chelsio - Use multiple txq/rxq per tfm to process the requests)
  error:
  	chcr_dec_wrcount(dev);
  	return err;
  }
  
 -static int chcr_aes_decrypt(struct skcipher_request *req)
 +static int chcr_aes_decrypt(struct ablkcipher_request *req)
  {
++<<<<<<< HEAD
 +	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
++=======
+ 	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(req);
+ 	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
++>>>>>>> 567be3a5d227 (crypto: chelsio - Use multiple txq/rxq per tfm to process the requests)
  	struct uld_ctx *u_ctx = ULD_CTX(c_ctx(tfm));
  	struct chcr_dev *dev = c_ctx(tfm)->dev;
  	struct sk_buff *skb = NULL;
@@@ -2587,10 -2665,10 +2692,10 @@@ void chcr_add_aead_dst_ent(struct aead_
  	temp = req->assoclen + req->cryptlen +
  		(reqctx->op ? -authsize : authsize);
  	dsgl_walk_add_sg(&dsgl_walk, req->dst, temp, 0);
- 	dsgl_walk_end(&dsgl_walk, qid, ctx->pci_chan_id);
+ 	dsgl_walk_end(&dsgl_walk, qid, rx_channel_id);
  }
  
 -void chcr_add_cipher_src_ent(struct skcipher_request *req,
 +void chcr_add_cipher_src_ent(struct ablkcipher_request *req,
  			     void *ulptx,
  			     struct  cipher_wr_param *wrparam)
  {
@@@ -2618,10 -2696,11 +2723,11 @@@ void chcr_add_cipher_dst_ent(struct abl
  			     struct  cipher_wr_param *wrparam,
  			     unsigned short qid)
  {
 -	struct chcr_skcipher_req_ctx *reqctx = skcipher_request_ctx(req);
 -	struct crypto_skcipher *tfm = crypto_skcipher_reqtfm(wrparam->req);
 +	struct chcr_blkcipher_req_ctx *reqctx = ablkcipher_request_ctx(req);
 +	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(wrparam->req);
  	struct chcr_context *ctx = c_ctx(tfm);
  	struct dsgl_walk dsgl_walk;
+ 	unsigned int rx_channel_id = reqctx->rxqidx / ctx->rxq_perchan;
  
  	dsgl_walk_init(&dsgl_walk, phys_cpl);
  	dsgl_walk_add_sg(&dsgl_walk, reqctx->dstsg, wrparam->bytes,
diff --cc drivers/crypto/chelsio/chcr_crypto.h
index e231e8b36624,542bebae001f..000000000000
--- a/drivers/crypto/chelsio/chcr_crypto.h
+++ b/drivers/crypto/chelsio/chcr_crypto.h
@@@ -251,10 -252,11 +253,18 @@@ struct __crypto_ctx 
  
  struct chcr_context {
  	struct chcr_dev *dev;
++<<<<<<< HEAD
 +	unsigned char tx_qidx;
 +	unsigned char rx_qidx;
 +	unsigned char tx_chan_id;
 +	unsigned char pci_chan_id;
++=======
+ 	unsigned char rxq_perchan;
+ 	unsigned char txq_perchan;
+ 	unsigned int  ntxq;
+ 	unsigned int  nrxq;
+ 	struct completion cbc_aes_aio_done;
++>>>>>>> 567be3a5d227 (crypto: chelsio - Use multiple txq/rxq per tfm to process the requests)
  	struct __crypto_ctx crypto_ctx[0];
  };
  
* Unmerged path drivers/crypto/chelsio/chcr_algo.c
diff --git a/drivers/crypto/chelsio/chcr_core.h b/drivers/crypto/chelsio/chcr_core.h
index b41ef1abfe74..e51c138b0a51 100644
--- a/drivers/crypto/chelsio/chcr_core.h
+++ b/drivers/crypto/chelsio/chcr_core.h
@@ -148,7 +148,6 @@ struct chcr_dev {
 	int wqretry;
 	struct delayed_work detach_work;
 	struct completion detach_comp;
-	unsigned char tx_channel_id;
 };
 
 struct uld_ctx {
* Unmerged path drivers/crypto/chelsio/chcr_crypto.h
