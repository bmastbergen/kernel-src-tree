drm/i915/gen12: Fix HDC pipeline flush

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Mika Kuoppala <mika.kuoppala@linux.intel.com>
commit 32d7171ee2ae6e19c63b826904cf62d3d5a7f6fa
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/32d7171e.failed

HDC pipeline flush is bit on the first dword of
the PIPE_CONTROL, not the second. Make it so.

v2: function naming (Chris)

	Signed-off-by: Mika Kuoppala <mika.kuoppala@linux.intel.com>
	Reviewed-by: Chris Wilson <chris@chris-wilson.co.uk>
	Signed-off-by: Chris Wilson <chris@chris-wilson.co.uk>
Link: https://patchwork.freedesktop.org/patch/msgid/20200506144734.29297-2-mika.kuoppala@linux.intel.com
(cherry picked from commit 32d7171ee2ae6e19c63b826904cf62d3d5a7f6fa)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/gpu/drm/i915/gt/intel_gpu_commands.h
#	drivers/gpu/drm/i915/gt/intel_lrc.c
diff --cc drivers/gpu/drm/i915/gt/intel_gpu_commands.h
index eec31e36aca7,534e435f20bc..000000000000
--- a/drivers/gpu/drm/i915/gt/intel_gpu_commands.h
+++ b/drivers/gpu/drm/i915/gt/intel_gpu_commands.h
@@@ -215,6 -237,7 +215,10 @@@
  #define   PIPE_CONTROL_INSTRUCTION_CACHE_INVALIDATE	(1<<11) /* MBZ on ILK */
  #define   PIPE_CONTROL_TEXTURE_CACHE_INVALIDATE		(1<<10) /* GM45+ only */
  #define   PIPE_CONTROL_INDIRECT_STATE_DISABLE		(1<<9)
++<<<<<<< HEAD
++=======
+ #define   PIPE_CONTROL0_HDC_PIPELINE_FLUSH		REG_BIT(9)  /* gen12 */
++>>>>>>> 32d7171ee2ae (drm/i915/gen12: Fix HDC pipeline flush)
  #define   PIPE_CONTROL_NOTIFY				(1<<8)
  #define   PIPE_CONTROL_FLUSH_ENABLE			(1<<7) /* gen7+ */
  #define   PIPE_CONTROL_DC_FLUSH_ENABLE			(1<<5)
diff --cc drivers/gpu/drm/i915/gt/intel_lrc.c
index f2865f3cc1d5,78f879ed4aa7..000000000000
--- a/drivers/gpu/drm/i915/gt/intel_lrc.c
+++ b/drivers/gpu/drm/i915/gt/intel_lrc.c
@@@ -2508,6 -4482,130 +2508,133 @@@ static int gen8_emit_flush_render(struc
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static int gen11_emit_flush_render(struct i915_request *request,
+ 				   u32 mode)
+ {
+ 	if (mode & EMIT_FLUSH) {
+ 		u32 *cs;
+ 		u32 flags = 0;
+ 
+ 		flags |= PIPE_CONTROL_CS_STALL;
+ 
+ 		flags |= PIPE_CONTROL_TILE_CACHE_FLUSH;
+ 		flags |= PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH;
+ 		flags |= PIPE_CONTROL_DEPTH_CACHE_FLUSH;
+ 		flags |= PIPE_CONTROL_DC_FLUSH_ENABLE;
+ 		flags |= PIPE_CONTROL_FLUSH_ENABLE;
+ 		flags |= PIPE_CONTROL_QW_WRITE;
+ 		flags |= PIPE_CONTROL_STORE_DATA_INDEX;
+ 
+ 		cs = intel_ring_begin(request, 6);
+ 		if (IS_ERR(cs))
+ 			return PTR_ERR(cs);
+ 
+ 		cs = gen8_emit_pipe_control(cs, flags, LRC_PPHWSP_SCRATCH_ADDR);
+ 		intel_ring_advance(request, cs);
+ 	}
+ 
+ 	if (mode & EMIT_INVALIDATE) {
+ 		u32 *cs;
+ 		u32 flags = 0;
+ 
+ 		flags |= PIPE_CONTROL_CS_STALL;
+ 
+ 		flags |= PIPE_CONTROL_COMMAND_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_TLB_INVALIDATE;
+ 		flags |= PIPE_CONTROL_INSTRUCTION_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_TEXTURE_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_VF_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_CONST_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_STATE_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_QW_WRITE;
+ 		flags |= PIPE_CONTROL_STORE_DATA_INDEX;
+ 
+ 		cs = intel_ring_begin(request, 6);
+ 		if (IS_ERR(cs))
+ 			return PTR_ERR(cs);
+ 
+ 		cs = gen8_emit_pipe_control(cs, flags, LRC_PPHWSP_SCRATCH_ADDR);
+ 		intel_ring_advance(request, cs);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static u32 preparser_disable(bool state)
+ {
+ 	return MI_ARB_CHECK | 1 << 8 | state;
+ }
+ 
+ static int gen12_emit_flush_render(struct i915_request *request,
+ 				   u32 mode)
+ {
+ 	if (mode & EMIT_FLUSH) {
+ 		u32 flags = 0;
+ 		u32 *cs;
+ 
+ 		flags |= PIPE_CONTROL_TILE_CACHE_FLUSH;
+ 		flags |= PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH;
+ 		flags |= PIPE_CONTROL_DEPTH_CACHE_FLUSH;
+ 		/* Wa_1409600907:tgl */
+ 		flags |= PIPE_CONTROL_DEPTH_STALL;
+ 		flags |= PIPE_CONTROL_DC_FLUSH_ENABLE;
+ 		flags |= PIPE_CONTROL_FLUSH_ENABLE;
+ 
+ 		flags |= PIPE_CONTROL_STORE_DATA_INDEX;
+ 		flags |= PIPE_CONTROL_QW_WRITE;
+ 
+ 		flags |= PIPE_CONTROL_CS_STALL;
+ 
+ 		cs = intel_ring_begin(request, 6);
+ 		if (IS_ERR(cs))
+ 			return PTR_ERR(cs);
+ 
+ 		cs = gen12_emit_pipe_control(cs,
+ 					     PIPE_CONTROL0_HDC_PIPELINE_FLUSH,
+ 					     flags, LRC_PPHWSP_SCRATCH_ADDR);
+ 		intel_ring_advance(request, cs);
+ 	}
+ 
+ 	if (mode & EMIT_INVALIDATE) {
+ 		u32 flags = 0;
+ 		u32 *cs;
+ 
+ 		flags |= PIPE_CONTROL_COMMAND_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_TLB_INVALIDATE;
+ 		flags |= PIPE_CONTROL_INSTRUCTION_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_TEXTURE_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_VF_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_CONST_CACHE_INVALIDATE;
+ 		flags |= PIPE_CONTROL_STATE_CACHE_INVALIDATE;
+ 
+ 		flags |= PIPE_CONTROL_STORE_DATA_INDEX;
+ 		flags |= PIPE_CONTROL_QW_WRITE;
+ 
+ 		flags |= PIPE_CONTROL_CS_STALL;
+ 
+ 		cs = intel_ring_begin(request, 8);
+ 		if (IS_ERR(cs))
+ 			return PTR_ERR(cs);
+ 
+ 		/*
+ 		 * Prevent the pre-parser from skipping past the TLB
+ 		 * invalidate and loading a stale page for the batch
+ 		 * buffer / request payload.
+ 		 */
+ 		*cs++ = preparser_disable(true);
+ 
+ 		cs = gen8_emit_pipe_control(cs, flags, LRC_PPHWSP_SCRATCH_ADDR);
+ 
+ 		*cs++ = preparser_disable(false);
+ 		intel_ring_advance(request, cs);
+ 	}
+ 
+ 	return 0;
+ }
+ 
++>>>>>>> 32d7171ee2ae (drm/i915/gen12: Fix HDC pipeline flush)
  /*
   * Reserve space for 2 NOOPs at the end of each request to be
   * used as a workaround for not being allowed to do lite
@@@ -2562,23 -4744,28 +2689,41 @@@ static u32 *gen8_emit_fini_breadcrumb_r
  	return gen8_emit_wa_tail(request, cs);
  }
  
 -static u32 *gen12_emit_fini_breadcrumb(struct i915_request *rq, u32 *cs)
 +static int gen8_init_rcs_context(struct i915_request *rq)
  {
 -	return gen12_emit_fini_breadcrumb_tail(rq, emit_xcs_breadcrumb(rq, cs));
 -}
 +	int ret;
  
++<<<<<<< HEAD
 +	ret = intel_engine_emit_ctx_wa(rq);
 +	if (ret)
 +		return ret;
++=======
+ static u32 *
+ gen12_emit_fini_breadcrumb_rcs(struct i915_request *request, u32 *cs)
+ {
+ 	cs = gen12_emit_ggtt_write_rcs(cs,
+ 				       request->fence.seqno,
+ 				       i915_request_active_timeline(request)->hwsp_offset,
+ 				       PIPE_CONTROL0_HDC_PIPELINE_FLUSH,
+ 				       PIPE_CONTROL_CS_STALL |
+ 				       PIPE_CONTROL_TILE_CACHE_FLUSH |
+ 				       PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH |
+ 				       PIPE_CONTROL_DEPTH_CACHE_FLUSH |
+ 				       /* Wa_1409600907:tgl */
+ 				       PIPE_CONTROL_DEPTH_STALL |
+ 				       PIPE_CONTROL_DC_FLUSH_ENABLE |
+ 				       PIPE_CONTROL_FLUSH_ENABLE);
++>>>>>>> 32d7171ee2ae (drm/i915/gen12: Fix HDC pipeline flush)
 +
 +	ret = intel_rcs_context_init_mocs(rq);
 +	/*
 +	 * Failing to program the MOCS is non-fatal.The system will not
 +	 * run at peak performance. So generate an error and carry on.
 +	 */
 +	if (ret)
 +		DRM_ERROR("MOCS failed to program: expect performance issues.\n");
  
 -	return gen12_emit_fini_breadcrumb_tail(request, cs);
 +	return i915_gem_render_state_emit(rq);
  }
  
  static void execlists_park(struct intel_engine_cs *engine)
diff --git a/drivers/gpu/drm/i915/gt/intel_engine.h b/drivers/gpu/drm/i915/gt/intel_engine.h
index 2f1c6871ee95..739e9555c560 100644
--- a/drivers/gpu/drm/i915/gt/intel_engine.h
+++ b/drivers/gpu/drm/i915/gt/intel_engine.h
@@ -408,19 +408,29 @@ void intel_engine_fini_breadcrumbs(struct intel_engine_cs *engine);
 void intel_engine_print_breadcrumbs(struct intel_engine_cs *engine,
 				    struct drm_printer *p);
 
-static inline u32 *gen8_emit_pipe_control(u32 *batch, u32 flags, u32 offset)
+static inline u32 *__gen8_emit_pipe_control(u32 *batch, u32 flags0, u32 flags1, u32 offset)
 {
 	memset(batch, 0, 6 * sizeof(u32));
 
-	batch[0] = GFX_OP_PIPE_CONTROL(6);
-	batch[1] = flags;
+	batch[0] = GFX_OP_PIPE_CONTROL(6) | flags0;
+	batch[1] = flags1;
 	batch[2] = offset;
 
 	return batch + 6;
 }
 
+static inline u32 *gen8_emit_pipe_control(u32 *batch, u32 flags, u32 offset)
+{
+	return __gen8_emit_pipe_control(batch, 0, flags, offset);
+}
+
+static inline u32 *gen12_emit_pipe_control(u32 *batch, u32 flags0, u32 flags1, u32 offset)
+{
+	return __gen8_emit_pipe_control(batch, flags0, flags1, offset);
+}
+
 static inline u32 *
-gen8_emit_ggtt_write_rcs(u32 *cs, u32 value, u32 gtt_offset, u32 flags)
+__gen8_emit_ggtt_write_rcs(u32 *cs, u32 value, u32 gtt_offset, u32 flags0, u32 flags1)
 {
 	/* We're using qword write, offset should be aligned to 8 bytes. */
 	GEM_BUG_ON(!IS_ALIGNED(gtt_offset, 8));
@@ -429,8 +439,8 @@ gen8_emit_ggtt_write_rcs(u32 *cs, u32 value, u32 gtt_offset, u32 flags)
 	 * need a prior CS_STALL, which is emitted by the flush
 	 * following the batch.
 	 */
-	*cs++ = GFX_OP_PIPE_CONTROL(6);
-	*cs++ = flags | PIPE_CONTROL_QW_WRITE | PIPE_CONTROL_GLOBAL_GTT_IVB;
+	*cs++ = GFX_OP_PIPE_CONTROL(6) | flags0;
+	*cs++ = flags1 | PIPE_CONTROL_QW_WRITE | PIPE_CONTROL_GLOBAL_GTT_IVB;
 	*cs++ = gtt_offset;
 	*cs++ = 0;
 	*cs++ = value;
@@ -440,6 +450,18 @@ gen8_emit_ggtt_write_rcs(u32 *cs, u32 value, u32 gtt_offset, u32 flags)
 	return cs;
 }
 
+static inline u32*
+gen8_emit_ggtt_write_rcs(u32 *cs, u32 value, u32 gtt_offset, u32 flags)
+{
+	return __gen8_emit_ggtt_write_rcs(cs, value, gtt_offset, 0, flags);
+}
+
+static inline u32*
+gen12_emit_ggtt_write_rcs(u32 *cs, u32 value, u32 gtt_offset, u32 flags0, u32 flags1)
+{
+	return __gen8_emit_ggtt_write_rcs(cs, value, gtt_offset, flags0, flags1);
+}
+
 static inline u32 *
 gen8_emit_ggtt_write(u32 *cs, u32 value, u32 gtt_offset, u32 flags)
 {
* Unmerged path drivers/gpu/drm/i915/gt/intel_gpu_commands.h
* Unmerged path drivers/gpu/drm/i915/gt/intel_lrc.c
