memblock: replace free_bootmem{_node} with memblock_free

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Mike Rapoport <rppt@linux.vnet.ibm.com>
commit 2013288f723887837d2f1cebef5fcf663b2319de
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/2013288f.failed

The free_bootmem and free_bootmem_node are merely wrappers for
memblock_free. Replace their usage with a call to memblock_free using the
following semantic patch:

@@
expression e1, e2, e3;
@@
(
- free_bootmem(e1, e2)
+ memblock_free(e1, e2)
|
- free_bootmem_node(e1, e2, e3)
+ memblock_free(e2, e3)
)

Link: http://lkml.kernel.org/r/1536927045-23536-24-git-send-email-rppt@linux.vnet.ibm.com
	Signed-off-by: Mike Rapoport <rppt@linux.vnet.ibm.com>
	Acked-by: Michal Hocko <mhocko@suse.com>
	Cc: Catalin Marinas <catalin.marinas@arm.com>
	Cc: Chris Zankel <chris@zankel.net>
	Cc: "David S. Miller" <davem@davemloft.net>
	Cc: Geert Uytterhoeven <geert@linux-m68k.org>
	Cc: Greentime Hu <green.hu@gmail.com>
	Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
	Cc: Guan Xuetao <gxt@pku.edu.cn>
	Cc: Ingo Molnar <mingo@redhat.com>
	Cc: "James E.J. Bottomley" <jejb@parisc-linux.org>
	Cc: Jonas Bonn <jonas@southpole.se>
	Cc: Jonathan Corbet <corbet@lwn.net>
	Cc: Ley Foon Tan <lftan@altera.com>
	Cc: Mark Salter <msalter@redhat.com>
	Cc: Martin Schwidefsky <schwidefsky@de.ibm.com>
	Cc: Matt Turner <mattst88@gmail.com>
	Cc: Michael Ellerman <mpe@ellerman.id.au>
	Cc: Michal Simek <monstr@monstr.eu>
	Cc: Palmer Dabbelt <palmer@sifive.com>
	Cc: Paul Burton <paul.burton@mips.com>
	Cc: Richard Kuo <rkuo@codeaurora.org>
	Cc: Richard Weinberger <richard@nod.at>
	Cc: Rich Felker <dalias@libc.org>
	Cc: Russell King <linux@armlinux.org.uk>
	Cc: Serge Semin <fancer.lancer@gmail.com>
	Cc: Thomas Gleixner <tglx@linutronix.de>
	Cc: Tony Luck <tony.luck@intel.com>
	Cc: Vineet Gupta <vgupta@synopsys.com>
	Cc: Yoshinori Sato <ysato@users.sourceforge.jp>
	Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
	Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
(cherry picked from commit 2013288f723887837d2f1cebef5fcf663b2319de)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	mm/nobootmem.c
diff --cc mm/nobootmem.c
index 439af3b765a7,85e1822ce918..000000000000
--- a/mm/nobootmem.c
+++ b/mm/nobootmem.c
@@@ -189,257 -150,3 +189,260 @@@ unsigned long __init free_all_bootmem(v
  
  	return pages;
  }
++<<<<<<< HEAD
 +
 +/**
 + * free_bootmem_node - mark a page range as usable
 + * @pgdat: node the range resides on
 + * @physaddr: starting physical address of the range
 + * @size: size of the range in bytes
 + *
 + * Partial pages will be considered reserved and left as they are.
 + *
 + * The range must reside completely on the specified node.
 + */
 +void __init free_bootmem_node(pg_data_t *pgdat, unsigned long physaddr,
 +			      unsigned long size)
 +{
 +	memblock_free(physaddr, size);
 +}
 +
 +/**
 + * free_bootmem - mark a page range as usable
 + * @addr: starting physical address of the range
 + * @size: size of the range in bytes
 + *
 + * Partial pages will be considered reserved and left as they are.
 + *
 + * The range must be contiguous but may span node boundaries.
 + */
 +void __init free_bootmem(unsigned long addr, unsigned long size)
 +{
 +	memblock_free(addr, size);
 +}
 +
 +static void * __init ___alloc_bootmem_nopanic(unsigned long size,
 +					unsigned long align,
 +					unsigned long goal,
 +					unsigned long limit)
 +{
 +	void *ptr;
 +
 +	if (WARN_ON_ONCE(slab_is_available()))
 +		return kzalloc(size, GFP_NOWAIT);
 +
 +restart:
 +
 +	ptr = __alloc_memory_core_early(NUMA_NO_NODE, size, align, goal, limit);
 +
 +	if (ptr)
 +		return ptr;
 +
 +	if (goal != 0) {
 +		goal = 0;
 +		goto restart;
 +	}
 +
 +	return NULL;
 +}
 +
 +/**
 + * __alloc_bootmem_nopanic - allocate boot memory without panicking
 + * @size: size of the request in bytes
 + * @align: alignment of the region
 + * @goal: preferred starting address of the region
 + *
 + * The goal is dropped if it can not be satisfied and the allocation will
 + * fall back to memory below @goal.
 + *
 + * Allocation may happen on any node in the system.
 + *
 + * Return: address of the allocated region or %NULL on failure.
 + */
 +void * __init __alloc_bootmem_nopanic(unsigned long size, unsigned long align,
 +					unsigned long goal)
 +{
 +	unsigned long limit = -1UL;
 +
 +	return ___alloc_bootmem_nopanic(size, align, goal, limit);
 +}
 +
 +static void * __init ___alloc_bootmem(unsigned long size, unsigned long align,
 +					unsigned long goal, unsigned long limit)
 +{
 +	void *mem = ___alloc_bootmem_nopanic(size, align, goal, limit);
 +
 +	if (mem)
 +		return mem;
 +	/*
 +	 * Whoops, we cannot satisfy the allocation request.
 +	 */
 +	pr_alert("bootmem alloc of %lu bytes failed!\n", size);
 +	panic("Out of memory");
 +	return NULL;
 +}
 +
 +/**
 + * __alloc_bootmem - allocate boot memory
 + * @size: size of the request in bytes
 + * @align: alignment of the region
 + * @goal: preferred starting address of the region
 + *
 + * The goal is dropped if it can not be satisfied and the allocation will
 + * fall back to memory below @goal.
 + *
 + * Allocation may happen on any node in the system.
 + *
 + * The function panics if the request can not be satisfied.
 + *
 + * Return: address of the allocated region.
 + */
 +void * __init __alloc_bootmem(unsigned long size, unsigned long align,
 +			      unsigned long goal)
 +{
 +	unsigned long limit = -1UL;
 +
 +	return ___alloc_bootmem(size, align, goal, limit);
 +}
 +
 +void * __init ___alloc_bootmem_node_nopanic(pg_data_t *pgdat,
 +						   unsigned long size,
 +						   unsigned long align,
 +						   unsigned long goal,
 +						   unsigned long limit)
 +{
 +	void *ptr;
 +
 +again:
 +	ptr = __alloc_memory_core_early(pgdat->node_id, size, align,
 +					goal, limit);
 +	if (ptr)
 +		return ptr;
 +
 +	ptr = __alloc_memory_core_early(NUMA_NO_NODE, size, align,
 +					goal, limit);
 +	if (ptr)
 +		return ptr;
 +
 +	if (goal) {
 +		goal = 0;
 +		goto again;
 +	}
 +
 +	return NULL;
 +}
 +
 +void * __init __alloc_bootmem_node_nopanic(pg_data_t *pgdat, unsigned long size,
 +				   unsigned long align, unsigned long goal)
 +{
 +	if (WARN_ON_ONCE(slab_is_available()))
 +		return kzalloc_node(size, GFP_NOWAIT, pgdat->node_id);
 +
 +	return ___alloc_bootmem_node_nopanic(pgdat, size, align, goal, 0);
 +}
 +
 +static void * __init ___alloc_bootmem_node(pg_data_t *pgdat, unsigned long size,
 +				    unsigned long align, unsigned long goal,
 +				    unsigned long limit)
 +{
 +	void *ptr;
 +
 +	ptr = ___alloc_bootmem_node_nopanic(pgdat, size, align, goal, limit);
 +	if (ptr)
 +		return ptr;
 +
 +	pr_alert("bootmem alloc of %lu bytes failed!\n", size);
 +	panic("Out of memory");
 +	return NULL;
 +}
 +
 +/**
 + * __alloc_bootmem_node - allocate boot memory from a specific node
 + * @pgdat: node to allocate from
 + * @size: size of the request in bytes
 + * @align: alignment of the region
 + * @goal: preferred starting address of the region
 + *
 + * The goal is dropped if it can not be satisfied and the allocation will
 + * fall back to memory below @goal.
 + *
 + * Allocation may fall back to any node in the system if the specified node
 + * can not hold the requested memory.
 + *
 + * The function panics if the request can not be satisfied.
 + *
 + * Return: address of the allocated region.
 + */
 +void * __init __alloc_bootmem_node(pg_data_t *pgdat, unsigned long size,
 +				   unsigned long align, unsigned long goal)
 +{
 +	if (WARN_ON_ONCE(slab_is_available()))
 +		return kzalloc_node(size, GFP_NOWAIT, pgdat->node_id);
 +
 +	return ___alloc_bootmem_node(pgdat, size, align, goal, 0);
 +}
 +
 +void * __init __alloc_bootmem_node_high(pg_data_t *pgdat, unsigned long size,
 +				   unsigned long align, unsigned long goal)
 +{
 +	return __alloc_bootmem_node(pgdat, size, align, goal);
 +}
 +
 +
 +/**
 + * __alloc_bootmem_low - allocate low boot memory
 + * @size: size of the request in bytes
 + * @align: alignment of the region
 + * @goal: preferred starting address of the region
 + *
 + * The goal is dropped if it can not be satisfied and the allocation will
 + * fall back to memory below @goal.
 + *
 + * Allocation may happen on any node in the system.
 + *
 + * The function panics if the request can not be satisfied.
 + *
 + * Return: address of the allocated region.
 + */
 +void * __init __alloc_bootmem_low(unsigned long size, unsigned long align,
 +				  unsigned long goal)
 +{
 +	return ___alloc_bootmem(size, align, goal, ARCH_LOW_ADDRESS_LIMIT);
 +}
 +
 +void * __init __alloc_bootmem_low_nopanic(unsigned long size,
 +					  unsigned long align,
 +					  unsigned long goal)
 +{
 +	return ___alloc_bootmem_nopanic(size, align, goal,
 +					ARCH_LOW_ADDRESS_LIMIT);
 +}
 +
 +/**
 + * __alloc_bootmem_low_node - allocate low boot memory from a specific node
 + * @pgdat: node to allocate from
 + * @size: size of the request in bytes
 + * @align: alignment of the region
 + * @goal: preferred starting address of the region
 + *
 + * The goal is dropped if it can not be satisfied and the allocation will
 + * fall back to memory below @goal.
 + *
 + * Allocation may fall back to any node in the system if the specified node
 + * can not hold the requested memory.
 + *
 + * The function panics if the request can not be satisfied.
 + *
 + * Return: address of the allocated region.
 + */
 +void * __init __alloc_bootmem_low_node(pg_data_t *pgdat, unsigned long size,
 +				       unsigned long align, unsigned long goal)
 +{
 +	if (WARN_ON_ONCE(slab_is_available()))
 +		return kzalloc_node(size, GFP_NOWAIT, pgdat->node_id);
 +
 +	return ___alloc_bootmem_node(pgdat, size, align, goal,
 +				     ARCH_LOW_ADDRESS_LIMIT);
 +}
++=======
++>>>>>>> 2013288f7238 (memblock: replace free_bootmem{_node} with memblock_free)
diff --git a/arch/alpha/kernel/core_irongate.c b/arch/alpha/kernel/core_irongate.c
index aec757250e07..c7596ae06af7 100644
--- a/arch/alpha/kernel/core_irongate.c
+++ b/arch/alpha/kernel/core_irongate.c
@@ -233,8 +233,7 @@ albacore_init_arch(void)
 			unsigned long size;
 
 			size = initrd_end - initrd_start;
-			free_bootmem_node(NODE_DATA(0), __pa(initrd_start),
-					  PAGE_ALIGN(size));
+			memblock_free(__pa(initrd_start), PAGE_ALIGN(size));
 			if (!move_initrd(pci_mem))
 				printk("irongate_init_arch: initrd too big "
 				       "(%ldK)\ndisabling initrd\n",
diff --git a/arch/arm64/mm/init.c b/arch/arm64/mm/init.c
index dd320984ebff..95c59f1a9aef 100644
--- a/arch/arm64/mm/init.c
+++ b/arch/arm64/mm/init.c
@@ -544,7 +544,7 @@ static inline void free_memmap(unsigned long start_pfn, unsigned long end_pfn)
 	 * memmap array.
 	 */
 	if (pg < pgend)
-		free_bootmem(pg, pgend - pg);
+		memblock_free(pg, pgend - pg);
 }
 
 /*
diff --git a/arch/mips/kernel/setup.c b/arch/mips/kernel/setup.c
index 2c96c0c68116..e3b28b7af388 100644
--- a/arch/mips/kernel/setup.c
+++ b/arch/mips/kernel/setup.c
@@ -611,7 +611,7 @@ static void __init bootmem_init(void)
 		extern void show_kernel_relocation(const char *level);
 
 		offset = __pa_symbol(_text) - __pa_symbol(VMLINUX_LOAD_ADDRESS);
-		free_bootmem(__pa_symbol(VMLINUX_LOAD_ADDRESS), offset);
+		memblock_free(__pa_symbol(VMLINUX_LOAD_ADDRESS), offset);
 
 #if defined(CONFIG_DEBUG_KERNEL) && defined(CONFIG_DEBUG_INFO)
 		/*
diff --git a/arch/powerpc/kernel/setup_64.c b/arch/powerpc/kernel/setup_64.c
index d9cafc1c5e09..68d73204c601 100644
--- a/arch/powerpc/kernel/setup_64.c
+++ b/arch/powerpc/kernel/setup_64.c
@@ -768,7 +768,7 @@ static void * __init pcpu_fc_alloc(unsigned int cpu, size_t size, size_t align)
 
 static void __init pcpu_fc_free(void *ptr, size_t size)
 {
-	free_bootmem(__pa(ptr), size);
+	memblock_free(__pa(ptr), size);
 }
 
 static int pcpu_cpu_distance(unsigned int from, unsigned int to)
diff --git a/arch/sparc/kernel/smp_64.c b/arch/sparc/kernel/smp_64.c
index d3ea1f3c06a0..0427244fed98 100644
--- a/arch/sparc/kernel/smp_64.c
+++ b/arch/sparc/kernel/smp_64.c
@@ -1607,7 +1607,7 @@ static void * __init pcpu_alloc_bootmem(unsigned int cpu, size_t size,
 
 static void __init pcpu_free_bootmem(void *ptr, size_t size)
 {
-	free_bootmem(__pa(ptr), size);
+	memblock_free(__pa(ptr), size);
 }
 
 static int __init pcpu_cpu_distance(unsigned int from, unsigned int to)
diff --git a/arch/um/kernel/mem.c b/arch/um/kernel/mem.c
index 185f6bb79269..3555c139389c 100644
--- a/arch/um/kernel/mem.c
+++ b/arch/um/kernel/mem.c
@@ -6,6 +6,7 @@
 #include <linux/stddef.h>
 #include <linux/module.h>
 #include <linux/bootmem.h>
+#include <linux/memblock.h>
 #include <linux/highmem.h>
 #include <linux/mm.h>
 #include <linux/swap.h>
@@ -46,7 +47,7 @@ void __init mem_init(void)
 	 */
 	brk_end = (unsigned long) UML_ROUND_UP(sbrk(0));
 	map_memory(brk_end, __pa(brk_end), uml_reserved - brk_end, 1, 1, 0);
-	free_bootmem(__pa(brk_end), uml_reserved - brk_end);
+	memblock_free(__pa(brk_end), uml_reserved - brk_end);
 	uml_reserved = brk_end;
 
 	/* this will put all low memory onto the freelists */
diff --git a/arch/unicore32/mm/init.c b/arch/unicore32/mm/init.c
index f4950fbfe574..36b14f655f10 100644
--- a/arch/unicore32/mm/init.c
+++ b/arch/unicore32/mm/init.c
@@ -293,7 +293,7 @@ free_memmap(unsigned long start_pfn, unsigned long end_pfn)
 	 * free the section of the memmap array.
 	 */
 	if (pg < pgend)
-		free_bootmem(pg, pgend - pg);
+		memblock_free(pg, pgend - pg);
 }
 
 /*
diff --git a/arch/x86/kernel/setup_percpu.c b/arch/x86/kernel/setup_percpu.c
index 67d48e26a8f2..fdb955c54726 100644
--- a/arch/x86/kernel/setup_percpu.c
+++ b/arch/x86/kernel/setup_percpu.c
@@ -5,6 +5,7 @@
 #include <linux/export.h>
 #include <linux/init.h>
 #include <linux/bootmem.h>
+#include <linux/memblock.h>
 #include <linux/percpu.h>
 #include <linux/kexec.h>
 #include <linux/crash_dump.h>
@@ -135,7 +136,7 @@ static void * __init pcpu_fc_alloc(unsigned int cpu, size_t size, size_t align)
 
 static void __init pcpu_fc_free(void *ptr, size_t size)
 {
-	free_bootmem(__pa(ptr), size);
+	memblock_free(__pa(ptr), size);
 }
 
 static int __init pcpu_cpu_distance(unsigned int from, unsigned int to)
diff --git a/arch/x86/kernel/tce_64.c b/arch/x86/kernel/tce_64.c
index 54c9b5a696b1..75730ce01f8d 100644
--- a/arch/x86/kernel/tce_64.c
+++ b/arch/x86/kernel/tce_64.c
@@ -31,6 +31,7 @@
 #include <linux/pci.h>
 #include <linux/dma-mapping.h>
 #include <linux/bootmem.h>
+#include <linux/memblock.h>
 #include <asm/tce.h>
 #include <asm/calgary.h>
 #include <asm/proto.h>
@@ -186,5 +187,5 @@ void __init free_tce_table(void *tbl)
 	size = table_size_to_number_of_entries(specified_table_size);
 	size *= TCE_ENTRY_SIZE;
 
-	free_bootmem(__pa(tbl), size);
+	memblock_free(__pa(tbl), size);
 }
diff --git a/arch/x86/xen/p2m.c b/arch/x86/xen/p2m.c
index 68c0f14c780b..3cedc0b310fa 100644
--- a/arch/x86/xen/p2m.c
+++ b/arch/x86/xen/p2m.c
@@ -66,6 +66,7 @@
 #include <linux/sched.h>
 #include <linux/seq_file.h>
 #include <linux/bootmem.h>
+#include <linux/memblock.h>
 #include <linux/slab.h>
 #include <linux/vmalloc.h>
 
@@ -188,7 +189,7 @@ static void * __ref alloc_p2m_page(void)
 static void __ref free_p2m_page(void *p)
 {
 	if (unlikely(!slab_is_available())) {
-		free_bootmem((unsigned long)p, PAGE_SIZE);
+		memblock_free((unsigned long)p, PAGE_SIZE);
 		return;
 	}
 
diff --git a/drivers/macintosh/smu.c b/drivers/macintosh/smu.c
index e8ae2e54151c..2f63739ea03a 100644
--- a/drivers/macintosh/smu.c
+++ b/drivers/macintosh/smu.c
@@ -569,7 +569,7 @@ int __init smu_init (void)
 fail_db_node:
 	of_node_put(smu->db_node);
 fail_bootmem:
-	free_bootmem(__pa(smu), sizeof(struct smu_device));
+	memblock_free(__pa(smu), sizeof(struct smu_device));
 	smu = NULL;
 fail_np:
 	of_node_put(np);
diff --git a/drivers/usb/early/xhci-dbc.c b/drivers/usb/early/xhci-dbc.c
index e4e89a0b797f..a5db4259dabe 100644
--- a/drivers/usb/early/xhci-dbc.c
+++ b/drivers/usb/early/xhci-dbc.c
@@ -13,6 +13,7 @@
 #include <linux/pci_regs.h>
 #include <linux/pci_ids.h>
 #include <linux/bootmem.h>
+#include <linux/memblock.h>
 #include <linux/io.h>
 #include <asm/pci-direct.h>
 #include <asm/fixmap.h>
@@ -191,7 +192,7 @@ static void __init xdbc_free_ring(struct xdbc_ring *ring)
 	if (!seg)
 		return;
 
-	free_bootmem(seg->dma, PAGE_SIZE);
+	memblock_free(seg->dma, PAGE_SIZE);
 	ring->segment = NULL;
 }
 
@@ -671,10 +672,10 @@ int __init early_xdbc_setup_hardware(void)
 		xdbc_free_ring(&xdbc.in_ring);
 
 		if (xdbc.table_dma)
-			free_bootmem(xdbc.table_dma, PAGE_SIZE);
+			memblock_free(xdbc.table_dma, PAGE_SIZE);
 
 		if (xdbc.out_dma)
-			free_bootmem(xdbc.out_dma, PAGE_SIZE);
+			memblock_free(xdbc.out_dma, PAGE_SIZE);
 
 		xdbc.table_base = NULL;
 		xdbc.out_buf = NULL;
@@ -996,8 +997,8 @@ static int __init xdbc_init(void)
 	xdbc_free_ring(&xdbc.evt_ring);
 	xdbc_free_ring(&xdbc.out_ring);
 	xdbc_free_ring(&xdbc.in_ring);
-	free_bootmem(xdbc.table_dma, PAGE_SIZE);
-	free_bootmem(xdbc.out_dma, PAGE_SIZE);
+	memblock_free(xdbc.table_dma, PAGE_SIZE);
+	memblock_free(xdbc.out_dma, PAGE_SIZE);
 	writel(0, &xdbc.xdbc_reg->control);
 	early_iounmap(xdbc.xhci_base, xdbc.xhci_length);
 
diff --git a/drivers/xen/swiotlb-xen.c b/drivers/xen/swiotlb-xen.c
index e7364ba1862a..80da7cb64852 100644
--- a/drivers/xen/swiotlb-xen.c
+++ b/drivers/xen/swiotlb-xen.c
@@ -36,6 +36,7 @@
 #define pr_fmt(fmt) "xen:" KBUILD_MODNAME ": " fmt
 
 #include <linux/bootmem.h>
+#include <linux/memblock.h>
 #include <linux/dma-direct.h>
 #include <linux/export.h>
 #include <xen/swiotlb-xen.h>
@@ -246,7 +247,8 @@ int __ref xen_swiotlb_init(int verbose, bool early)
 			       xen_io_tlb_nslabs);
 	if (rc) {
 		if (early)
-			free_bootmem(__pa(xen_io_tlb_start), PAGE_ALIGN(bytes));
+			memblock_free(__pa(xen_io_tlb_start),
+				      PAGE_ALIGN(bytes));
 		else {
 			free_pages((unsigned long)xen_io_tlb_start, order);
 			xen_io_tlb_start = NULL;
diff --git a/include/linux/bootmem.h b/include/linux/bootmem.h
index 42515195d7d8..bf262c24e5c9 100644
--- a/include/linux/bootmem.h
+++ b/include/linux/bootmem.h
@@ -66,10 +66,6 @@ extern unsigned long free_all_bootmem(void);
 extern void reset_node_managed_pages(pg_data_t *pgdat);
 extern void reset_all_zones_managed_pages(void);
 
-extern void free_bootmem_node(pg_data_t *pgdat,
-			      unsigned long addr,
-			      unsigned long size);
-extern void free_bootmem(unsigned long physaddr, unsigned long size);
 extern void free_bootmem_late(unsigned long physaddr, unsigned long size);
 
 /*
* Unmerged path mm/nobootmem.c
