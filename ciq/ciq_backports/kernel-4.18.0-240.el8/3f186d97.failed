futex: Add mutex around futex exit

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Thomas Gleixner <tglx@linutronix.de>
commit 3f186d974826847a07bc7964d79ec4eded475ad9
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/3f186d97.failed

The mutex will be used in subsequent changes to replace the busy looping of
a waiter when the futex owner is currently executing the exit cleanup to
prevent a potential live lock.

	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Reviewed-by: Ingo Molnar <mingo@kernel.org>
	Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Link: https://lkml.kernel.org/r/20191106224556.845798895@linutronix.de


(cherry picked from commit 3f186d974826847a07bc7964d79ec4eded475ad9)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	include/linux/futex.h
#	include/linux/sched.h
#	kernel/futex.c
diff --cc include/linux/futex.h
index 821ae502d3d8,5cc3fed27d4c..000000000000
--- a/include/linux/futex.h
+++ b/include/linux/futex.h
@@@ -51,7 -50,27 +51,31 @@@ union futex_key 
  #define FUTEX_KEY_INIT (union futex_key) { .both = { .ptr = NULL } }
  
  #ifdef CONFIG_FUTEX
++<<<<<<< HEAD
 +extern void exit_robust_list(struct task_struct *curr);
++=======
+ enum {
+ 	FUTEX_STATE_OK,
+ 	FUTEX_STATE_EXITING,
+ 	FUTEX_STATE_DEAD,
+ };
+ 
+ static inline void futex_init_task(struct task_struct *tsk)
+ {
+ 	tsk->robust_list = NULL;
+ #ifdef CONFIG_COMPAT
+ 	tsk->compat_robust_list = NULL;
+ #endif
+ 	INIT_LIST_HEAD(&tsk->pi_state_list);
+ 	tsk->pi_state_cache = NULL;
+ 	tsk->futex_state = FUTEX_STATE_OK;
+ 	mutex_init(&tsk->futex_exit_mutex);
+ }
+ 
+ void futex_exit_recursive(struct task_struct *tsk);
+ void futex_exit_release(struct task_struct *tsk);
+ void futex_exec_release(struct task_struct *tsk);
++>>>>>>> 3f186d974826 (futex: Add mutex around futex exit)
  
  long do_futex(u32 __user *uaddr, int op, u32 val, ktime_t *timeout,
  	      u32 __user *uaddr2, u32 val2, u32 val3);
diff --cc include/linux/sched.h
index 2d5a017b4e63,1ebe540f8a08..000000000000
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@@ -1033,6 -1053,8 +1033,11 @@@ struct task_struct 
  #endif
  	struct list_head		pi_state_list;
  	struct futex_pi_state		*pi_state_cache;
++<<<<<<< HEAD
++=======
+ 	struct mutex			futex_exit_mutex;
+ 	unsigned int			futex_state;
++>>>>>>> 3f186d974826 (futex: Add mutex around futex exit)
  #endif
  #ifdef CONFIG_PERF_EVENTS
  	struct perf_event_context	*perf_event_ctxp[perf_nr_task_contexts];
diff --cc kernel/futex.c
index ec3cc9521f31,46a81e611065..000000000000
--- a/kernel/futex.c
+++ b/kernel/futex.c
@@@ -3608,9 -3655,118 +3608,122 @@@ void exit_robust_list(struct task_struc
  		cond_resched();
  	}
  
 -	if (pending) {
 +	if (pending)
  		handle_futex_death((void __user *)pending + futex_offset,
++<<<<<<< HEAD
 +				   curr, pip);
++=======
+ 				   curr, pip, HANDLE_DEATH_PENDING);
+ 	}
+ }
+ 
+ static void futex_cleanup(struct task_struct *tsk)
+ {
+ 	if (unlikely(tsk->robust_list)) {
+ 		exit_robust_list(tsk);
+ 		tsk->robust_list = NULL;
+ 	}
+ 
+ #ifdef CONFIG_COMPAT
+ 	if (unlikely(tsk->compat_robust_list)) {
+ 		compat_exit_robust_list(tsk);
+ 		tsk->compat_robust_list = NULL;
+ 	}
+ #endif
+ 
+ 	if (unlikely(!list_empty(&tsk->pi_state_list)))
+ 		exit_pi_state_list(tsk);
+ }
+ 
+ /**
+  * futex_exit_recursive - Set the tasks futex state to FUTEX_STATE_DEAD
+  * @tsk:	task to set the state on
+  *
+  * Set the futex exit state of the task lockless. The futex waiter code
+  * observes that state when a task is exiting and loops until the task has
+  * actually finished the futex cleanup. The worst case for this is that the
+  * waiter runs through the wait loop until the state becomes visible.
+  *
+  * This is called from the recursive fault handling path in do_exit().
+  *
+  * This is best effort. Either the futex exit code has run already or
+  * not. If the OWNER_DIED bit has been set on the futex then the waiter can
+  * take it over. If not, the problem is pushed back to user space. If the
+  * futex exit code did not run yet, then an already queued waiter might
+  * block forever, but there is nothing which can be done about that.
+  */
+ void futex_exit_recursive(struct task_struct *tsk)
+ {
+ 	/* If the state is FUTEX_STATE_EXITING then futex_exit_mutex is held */
+ 	if (tsk->futex_state == FUTEX_STATE_EXITING)
+ 		mutex_unlock(&tsk->futex_exit_mutex);
+ 	tsk->futex_state = FUTEX_STATE_DEAD;
+ }
+ 
+ static void futex_cleanup_begin(struct task_struct *tsk)
+ {
+ 	/*
+ 	 * Prevent various race issues against a concurrent incoming waiter
+ 	 * including live locks by forcing the waiter to block on
+ 	 * tsk->futex_exit_mutex when it observes FUTEX_STATE_EXITING in
+ 	 * attach_to_pi_owner().
+ 	 */
+ 	mutex_lock(&tsk->futex_exit_mutex);
+ 
+ 	/*
+ 	 * Switch the state to FUTEX_STATE_EXITING under tsk->pi_lock.
+ 	 *
+ 	 * This ensures that all subsequent checks of tsk->futex_state in
+ 	 * attach_to_pi_owner() must observe FUTEX_STATE_EXITING with
+ 	 * tsk->pi_lock held.
+ 	 *
+ 	 * It guarantees also that a pi_state which was queued right before
+ 	 * the state change under tsk->pi_lock by a concurrent waiter must
+ 	 * be observed in exit_pi_state_list().
+ 	 */
+ 	raw_spin_lock_irq(&tsk->pi_lock);
+ 	tsk->futex_state = FUTEX_STATE_EXITING;
+ 	raw_spin_unlock_irq(&tsk->pi_lock);
+ }
+ 
+ static void futex_cleanup_end(struct task_struct *tsk, int state)
+ {
+ 	/*
+ 	 * Lockless store. The only side effect is that an observer might
+ 	 * take another loop until it becomes visible.
+ 	 */
+ 	tsk->futex_state = state;
+ 	/*
+ 	 * Drop the exit protection. This unblocks waiters which observed
+ 	 * FUTEX_STATE_EXITING to reevaluate the state.
+ 	 */
+ 	mutex_unlock(&tsk->futex_exit_mutex);
+ }
+ 
+ void futex_exec_release(struct task_struct *tsk)
+ {
+ 	/*
+ 	 * The state handling is done for consistency, but in the case of
+ 	 * exec() there is no way to prevent futher damage as the PID stays
+ 	 * the same. But for the unlikely and arguably buggy case that a
+ 	 * futex is held on exec(), this provides at least as much state
+ 	 * consistency protection which is possible.
+ 	 */
+ 	futex_cleanup_begin(tsk);
+ 	futex_cleanup(tsk);
+ 	/*
+ 	 * Reset the state to FUTEX_STATE_OK. The task is alive and about
+ 	 * exec a new binary.
+ 	 */
+ 	futex_cleanup_end(tsk, FUTEX_STATE_OK);
+ }
+ 
+ void futex_exit_release(struct task_struct *tsk)
+ {
+ 	futex_cleanup_begin(tsk);
+ 	futex_cleanup(tsk);
+ 	futex_cleanup_end(tsk, FUTEX_STATE_DEAD);
++>>>>>>> 3f186d974826 (futex: Add mutex around futex exit)
  }
  
  long do_futex(u32 __user *uaddr, int op, u32 val, ktime_t *timeout,
* Unmerged path include/linux/futex.h
* Unmerged path include/linux/sched.h
* Unmerged path kernel/futex.c
