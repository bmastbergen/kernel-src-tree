block/rq_qos: implement rq_qos_ops->queue_depth_changed()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Tejun Heo <tj@kernel.org>
commit 9677a3e01f838622d2efc9a3ccb97090a2c3156a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/9677a3e0.failed

wbt already gets queue depth changed notification through
wbt_set_queue_depth().  Generalize it into
rq_qos_ops->queue_depth_changed() so that other rq_qos policies can
easily hook into the events too.

	Signed-off-by: Tejun Heo <tj@kernel.org>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 9677a3e01f838622d2efc9a3ccb97090a2c3156a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-rq-qos.h
diff --cc block/blk-rq-qos.h
index 3c85f26d3846,e15b6907b76d..000000000000
--- a/block/blk-rq-qos.h
+++ b/block/blk-rq-qos.h
@@@ -134,7 -137,9 +135,8 @@@ void __rq_qos_issue(struct rq_qos *rqos
  void __rq_qos_requeue(struct rq_qos *rqos, struct request *rq);
  void __rq_qos_throttle(struct rq_qos *rqos, struct bio *bio);
  void __rq_qos_track(struct rq_qos *rqos, struct request *rq, struct bio *bio);
 -void __rq_qos_merge(struct rq_qos *rqos, struct request *rq, struct bio *bio);
  void __rq_qos_done_bio(struct rq_qos *rqos, struct bio *bio);
+ void __rq_qos_queue_depth_changed(struct rq_qos *rqos);
  
  static inline void rq_qos_cleanup(struct request_queue *q, struct bio *bio)
  {
@@@ -179,6 -189,19 +181,22 @@@ static inline void rq_qos_track(struct 
  		__rq_qos_track(q->rq_qos, rq, bio);
  }
  
++<<<<<<< HEAD
++=======
+ static inline void rq_qos_merge(struct request_queue *q, struct request *rq,
+ 				struct bio *bio)
+ {
+ 	if (q->rq_qos)
+ 		__rq_qos_merge(q->rq_qos, rq, bio);
+ }
+ 
+ static inline void rq_qos_queue_depth_changed(struct request_queue *q)
+ {
+ 	if (q->rq_qos)
+ 		__rq_qos_queue_depth_changed(q->rq_qos);
+ }
+ 
++>>>>>>> 9677a3e01f83 (block/rq_qos: implement rq_qos_ops->queue_depth_changed())
  void rq_qos_exit(struct request_queue *);
  
  #endif
diff --git a/block/blk-rq-qos.c b/block/blk-rq-qos.c
index 7f70f6906a57..b042c3af7bb9 100644
--- a/block/blk-rq-qos.c
+++ b/block/blk-rq-qos.c
@@ -90,6 +90,15 @@ void __rq_qos_done_bio(struct rq_qos *rqos, struct bio *bio)
 	} while (rqos);
 }
 
+void __rq_qos_queue_depth_changed(struct rq_qos *rqos)
+{
+	do {
+		if (rqos->ops->queue_depth_changed)
+			rqos->ops->queue_depth_changed(rqos);
+		rqos = rqos->next;
+	} while (rqos);
+}
+
 /*
  * Return true, if we can't increase the depth further by scaling
  */
* Unmerged path block/blk-rq-qos.h
diff --git a/block/blk-settings.c b/block/blk-settings.c
index 2c39a3c7924a..4e76ff58dfaf 100644
--- a/block/blk-settings.c
+++ b/block/blk-settings.c
@@ -811,7 +811,7 @@ EXPORT_SYMBOL(blk_queue_update_dma_alignment);
 void blk_set_queue_depth(struct request_queue *q, unsigned int depth)
 {
 	q->queue_depth = depth;
-	wbt_set_queue_depth(q, depth);
+	rq_qos_queue_depth_changed(q);
 }
 EXPORT_SYMBOL(blk_set_queue_depth);
 
diff --git a/block/blk-wbt.c b/block/blk-wbt.c
index aef954ae649c..3fa980620817 100644
--- a/block/blk-wbt.c
+++ b/block/blk-wbt.c
@@ -628,15 +628,6 @@ void wbt_requeue(struct rq_qos *rqos, struct request *rq)
 	}
 }
 
-void wbt_set_queue_depth(struct request_queue *q, unsigned int depth)
-{
-	struct rq_qos *rqos = wbt_rq_qos(q);
-	if (rqos) {
-		RQWB(rqos)->rq_depth.queue_depth = depth;
-		__wbt_update_limits(RQWB(rqos));
-	}
-}
-
 void wbt_set_write_cache(struct request_queue *q, bool write_cache_on)
 {
 	struct rq_qos *rqos = wbt_rq_qos(q);
@@ -688,6 +679,12 @@ static int wbt_data_dir(const struct request *rq)
 	return -1;
 }
 
+static void wbt_queue_depth_changed(struct rq_qos *rqos)
+{
+	RQWB(rqos)->rq_depth.queue_depth = blk_queue_depth(rqos->q);
+	__wbt_update_limits(RQWB(rqos));
+}
+
 static void wbt_exit(struct rq_qos *rqos)
 {
 	struct rq_wb *rwb = RQWB(rqos);
@@ -722,6 +719,7 @@ static struct rq_qos_ops wbt_rqos_ops = {
 	.requeue = wbt_requeue,
 	.done = wbt_done,
 	.cleanup = wbt_cleanup,
+	.queue_depth_changed = wbt_queue_depth_changed,
 	.exit = wbt_exit,
 };
 
@@ -761,7 +759,7 @@ int wbt_init(struct request_queue *q)
 
 	rwb->min_lat_nsec = wbt_default_latency_nsec(q);
 
-	wbt_set_queue_depth(q, blk_queue_depth(q));
+	wbt_queue_depth_changed(&rwb->rqos);
 	wbt_set_write_cache(q, test_bit(QUEUE_FLAG_WC, &q->queue_flags));
 
 	return 0;
diff --git a/block/blk-wbt.h b/block/blk-wbt.h
index f47218d5b3b2..8e4e37660971 100644
--- a/block/blk-wbt.h
+++ b/block/blk-wbt.h
@@ -95,7 +95,6 @@ void wbt_enable_default(struct request_queue *);
 u64 wbt_get_min_lat(struct request_queue *q);
 void wbt_set_min_lat(struct request_queue *q, u64 val);
 
-void wbt_set_queue_depth(struct request_queue *, unsigned int);
 void wbt_set_write_cache(struct request_queue *, bool);
 
 u64 wbt_default_latency_nsec(struct request_queue *);
@@ -118,9 +117,6 @@ static inline void wbt_disable_default(struct request_queue *q)
 static inline void wbt_enable_default(struct request_queue *q)
 {
 }
-static inline void wbt_set_queue_depth(struct request_queue *q, unsigned int depth)
-{
-}
 static inline void wbt_set_write_cache(struct request_queue *q, bool wc)
 {
 }
