nvme-pci: align io queue count with allocted nvme_queue in nvme_probe

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Weiping Zhang <zhangweiping@didiglobal.com>
commit 2a5bcfdd41d68559567cec3c124a75e093506cc1
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/2a5bcfdd.failed

Since commit 147b27e4bd08 ("nvme-pci: allocate device queues storage
space at probe"), nvme_alloc_queue does not alloc the nvme queues
itself anymore.

If the write/poll_queues module parameters are changed at runtime to
values larger than the number of allocated queues in nvme_probe,
nvme_alloc_queue will access unallocated memory.

Add a new nr_allocated_queues member to struct nvme_dev to record how
many queues were alloctated in nvme_probe to avoid using more than the
allocated queues after a reset following a change to the
write/poll_queues module parameters.

Also add nr_write_queues and nr_poll_queues members to allow refreshing
the number of write and poll queues based on a change to the module
parameters when resetting the controller.

Fixes: 147b27e4bd08 ("nvme-pci: allocate device queues storage space at probe")
	Signed-off-by: Weiping Zhang <zhangweiping@didiglobal.com>
	Reviewed-by: Keith Busch <kbusch@kernel.org>
	Reviewed-by: Max Gurtovoy <maxg@mellanox.com>
[hch: add nvme_max_io_queues, update the commit message]
	Signed-off-by: Christoph Hellwig <hch@lst.de>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 2a5bcfdd41d68559567cec3c124a75e093506cc1)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/nvme/host/pci.c
diff --cc drivers/nvme/host/pci.c
index 2bab31a7d130,b0978ac554d5..000000000000
--- a/drivers/nvme/host/pci.c
+++ b/drivers/nvme/host/pci.c
@@@ -204,25 -206,14 +207,14 @@@ struct nvme_iod 
  	int npages;		/* In the PRP list. 0 means small pool in use */
  	int nents;		/* Used in scatterlist */
  	dma_addr_t first_dma;
 -	unsigned int dma_len;	/* length of single DMA segment mapping */
 -	dma_addr_t meta_dma;
 +	struct scatterlist meta_sg; /* metadata requires single contiguous buffer */
  	struct scatterlist *sg;
 +	struct scatterlist inline_sg[0];
  };
  
- static unsigned int max_io_queues(void)
+ static inline unsigned int nvme_dbbuf_size(struct nvme_dev *dev)
  {
- 	return num_possible_cpus() + write_queues + poll_queues;
- }
- 
- static unsigned int max_queue_count(void)
- {
- 	/* IO queues + admin queue */
- 	return 1 + max_io_queues();
- }
- 
- static inline unsigned int nvme_dbbuf_size(u32 stride)
- {
- 	return (max_queue_count() * 8 * stride);
+ 	return dev->nr_allocated_queues * 8 * dev->db_stride;
  }
  
  static int nvme_dbbuf_dma_alloc(struct nvme_dev *dev)
@@@ -2070,10 -2057,27 +2067,31 @@@ static int nvme_setup_io_queues(struct 
  {
  	struct nvme_queue *adminq = &dev->queues[0];
  	struct pci_dev *pdev = to_pci_dev(dev->dev);
- 	int result, nr_io_queues;
+ 	unsigned int nr_io_queues;
  	unsigned long size;
+ 	int result;
  
++<<<<<<< HEAD
 +	nr_io_queues = max_io_queues();
++=======
+ 	/*
+ 	 * Sample the module parameters once at reset time so that we have
+ 	 * stable values to work with.
+ 	 */
+ 	dev->nr_write_queues = write_queues;
+ 	dev->nr_poll_queues = poll_queues;
+ 
+ 	/*
+ 	 * If tags are shared with admin queue (Apple bug), then
+ 	 * make sure we only use one IO queue.
+ 	 */
+ 	if (dev->ctrl.quirks & NVME_QUIRK_SHARED_TAGS)
+ 		nr_io_queues = 1;
+ 	else
+ 		nr_io_queues = min(nvme_max_io_queues(dev),
+ 				   dev->nr_allocated_queues - 1);
+ 
++>>>>>>> 2a5bcfdd41d6 (nvme-pci: align io queue count with allocted nvme_queue in nvme_probe)
  	result = nvme_set_queue_count(&dev->ctrl, &nr_io_queues);
  	if (result < 0)
  		return result;
* Unmerged path drivers/nvme/host/pci.c
