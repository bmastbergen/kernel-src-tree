ice: Improve clarity of prints and variables

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Brett Creeley <brett.creeley@intel.com>
commit 46c276cebfb47ec43e17bb0e147f18d0f3e57a28
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/46c276ce.failed

Currently when the device runs out of MSI-X interrupts a cryptic and
unhelpful message is printed. This will cause confusion when hitting this
case. Fix this by clearing up the error message for both SR-IOV and non
SR-IOV use cases.

Also, make a few minor changes to increase clarity of variables.
1. Change per VF MSI-X and queue pair variables in the PF structure.
2. Use ICE_NONQ_VECS_VF when determining pf->num_msix_per_vf instead of
the magic number "1". This vector is reserved for the OICR.

All of the resource tracking functions were moved to avoid adding
any forward declaration function prototypes.

	Signed-off-by: Brett Creeley <brett.creeley@intel.com>
	Signed-off-by: Tony Nguyen <anthony.l.nguyen@intel.com>
	Tested-by: Andrew Bowers <andrewx.bowers@intel.com>
	Signed-off-by: Jeff Kirsher <jeffrey.t.kirsher@intel.com>
(cherry picked from commit 46c276cebfb47ec43e17bb0e147f18d0f3e57a28)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/intel/ice/ice.h
#	drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
diff --cc drivers/net/ethernet/intel/ice/ice.h
index cb10abb14e11,aed3ff31e064..000000000000
--- a/drivers/net/ethernet/intel/ice/ice.h
+++ b/drivers/net/ethernet/intel/ice/ice.h
@@@ -361,8 -362,10 +361,15 @@@ struct ice_pf 
  	struct ice_vf *vf;
  	int num_alloc_vfs;		/* actual number of VFs allocated */
  	u16 num_vfs_supported;		/* num VFs supported for this PF */
++<<<<<<< HEAD
 +	u16 num_vf_qps;			/* num queue pairs per VF */
 +	u16 num_vf_msix;		/* num vectors per VF */
++=======
+ 	u16 num_qps_per_vf;
+ 	u16 num_msix_per_vf;
+ 	/* used to ratelimit the MDD event logging */
+ 	unsigned long last_printed_mdd_jiffies;
++>>>>>>> 46c276cebfb4 (ice: Improve clarity of prints and variables)
  	DECLARE_BITMAP(state, __ICE_STATE_NBITS);
  	DECLARE_BITMAP(flags, ICE_PF_FLAGS_NBITS);
  	unsigned long *avail_txqs;	/* bitmap to track PF Tx queue usage */
diff --cc drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
index 7d83855b0913,e0277b49439f..000000000000
--- a/drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
+++ b/drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
@@@ -170,7 -170,12 +170,16 @@@ static void ice_free_vf_res(struct ice_
  		vf->num_mac = 0;
  	}
  
++<<<<<<< HEAD
 +	last_vector_idx = vf->first_vector_idx + pf->num_vf_msix - 1;
++=======
+ 	last_vector_idx = vf->first_vector_idx + pf->num_msix_per_vf - 1;
+ 
+ 	/* clear VF MDD event information */
+ 	memset(&vf->mdd_tx_events, 0, sizeof(vf->mdd_tx_events));
+ 	memset(&vf->mdd_rx_events, 0, sizeof(vf->mdd_rx_events));
+ 
++>>>>>>> 46c276cebfb4 (ice: Improve clarity of prints and variables)
  	/* Disable interrupts so that VF starts in a known state */
  	for (i = vf->first_vector_idx; i <= last_vector_idx; i++) {
  		wr32(&pf->hw, GLINT_DYN_CTL(i), GLINT_DYN_CTL_CLEARPBA_M);
@@@ -599,7 -596,7 +608,11 @@@ static int ice_alloc_vf_res(struct ice_
  	 */
  	tx_rx_queue_left = min_t(int, ice_get_avail_txq_count(pf),
  				 ice_get_avail_rxq_count(pf));
++<<<<<<< HEAD
 +	tx_rx_queue_left += ICE_DFLT_QS_PER_VF;
++=======
+ 	tx_rx_queue_left += pf->num_qps_per_vf;
++>>>>>>> 46c276cebfb4 (ice: Improve clarity of prints and variables)
  	if (vf->num_req_qs && vf->num_req_qs <= tx_rx_queue_left &&
  	    vf->num_req_qs != vf->num_vf_qs)
  		vf->num_vf_qs = vf->num_req_qs;
@@@ -842,83 -824,83 +855,137 @@@ static int ice_sriov_set_msix_res(struc
  }
  
  /**
 - * ice_set_per_vf_res - check if vectors and queues are available
 + * ice_check_avail_res - check if vectors and queues are available
   * @pf: pointer to the PF structure
   *
 - * First, determine HW interrupts from common pool. If we allocate fewer VFs, we
 - * get more vectors and can enable more queues per VF. Note that this does not
 - * grab any vectors from the SW pool already allocated. Also note, that all
 - * vector counts include one for each VF's miscellaneous interrupt vector
 - * (i.e. OICR).
 - *
 - * Minimum VFs - 2 vectors, 1 queue pair
 - * Small VFs - 5 vectors, 4 queue pairs
 - * Medium VFs - 17 vectors, 16 queue pairs
 - *
 - * Second, determine number of queue pairs per VF by starting with a pre-defined
 - * maximum each VF supports. If this is not possible, then we adjust based on
 - * queue pairs available on the device.
 - *
 - * Lastly, set queue and MSI-X VF variables tracked by the PF so it can be used
 - * by each VF during VF initialization and reset.
 + * This function is where we calculate actual number of resources for VF VSIs,
 + * we don't reserve ahead of time during probe. Returns success if vectors and
 + * queues resources are available, otherwise returns error code
   */
 -static int ice_set_per_vf_res(struct ice_pf *pf)
 +static int ice_check_avail_res(struct ice_pf *pf)
  {
  	int max_valid_res_idx = ice_get_max_valid_res_idx(pf->irq_tracker);
++<<<<<<< HEAD
 +	u16 num_msix, num_txq, num_rxq, num_avail_msix;
 +	struct device *dev = ice_pf_to_dev(pf);
++=======
+ 	int msix_avail_per_vf, msix_avail_for_sriov;
+ 	struct device *dev = ice_pf_to_dev(pf);
+ 	u16 num_msix_per_vf, num_txq, num_rxq;
++>>>>>>> 46c276cebfb4 (ice: Improve clarity of prints and variables)
  
  	if (!pf->num_alloc_vfs || max_valid_res_idx < 0)
  		return -EINVAL;
  
++<<<<<<< HEAD
 +	/* add 1 to max_valid_res_idx to account for it being 0-based */
 +	num_avail_msix = pf->hw.func_caps.common_cap.num_msix_vectors -
 +		(max_valid_res_idx + 1);
 +
 +	/* Grab from HW interrupts common pool
 +	 * Note: By the time the user decides it needs more vectors in a VF
 +	 * its already too late since one must decide this prior to creating the
 +	 * VF interface. So the best we can do is take a guess as to what the
 +	 * user might want.
 +	 *
 +	 * We have two policies for vector allocation:
 +	 * 1. if num_alloc_vfs is from 1 to 16, then we consider this as small
 +	 * number of NFV VFs used for NFV appliances, since this is a special
 +	 * case, we try to assign maximum vectors per VF (65) as much as
 +	 * possible, based on determine_resources algorithm.
 +	 * 2. if num_alloc_vfs is from 17 to 256, then its large number of
 +	 * regular VFs which are not used for any special purpose. Hence try to
 +	 * grab default interrupt vectors (5 as supported by AVF driver).
 +	 */
 +	if (pf->num_alloc_vfs <= 16) {
 +		num_msix = ice_determine_res(pf, num_avail_msix,
 +					     ICE_MAX_INTR_PER_VF,
 +					     ICE_MIN_INTR_PER_VF);
 +	} else if (pf->num_alloc_vfs <= ICE_MAX_VF_COUNT) {
 +		num_msix = ice_determine_res(pf, num_avail_msix,
 +					     ICE_DFLT_INTR_PER_VF,
 +					     ICE_MIN_INTR_PER_VF);
 +	} else {
 +		dev_err(dev, "Number of VFs %d exceeds max VF count %d\n",
 +			pf->num_alloc_vfs, ICE_MAX_VF_COUNT);
++=======
+ 	/* determine MSI-X resources per VF */
+ 	msix_avail_for_sriov = pf->hw.func_caps.common_cap.num_msix_vectors -
+ 		pf->irq_tracker->num_entries;
+ 	msix_avail_per_vf = msix_avail_for_sriov / pf->num_alloc_vfs;
+ 	if (msix_avail_per_vf >= ICE_NUM_VF_MSIX_MED) {
+ 		num_msix_per_vf = ICE_NUM_VF_MSIX_MED;
+ 	} else if (msix_avail_per_vf >= ICE_NUM_VF_MSIX_SMALL) {
+ 		num_msix_per_vf = ICE_NUM_VF_MSIX_SMALL;
+ 	} else if (msix_avail_per_vf >= ICE_MIN_INTR_PER_VF) {
+ 		num_msix_per_vf = ICE_MIN_INTR_PER_VF;
+ 	} else {
+ 		dev_err(dev, "Only %d MSI-X interrupts available for SR-IOV. Not enough to support minimum of %d MSI-X interrupts per VF for %d VFs\n",
+ 			msix_avail_for_sriov, ICE_MIN_INTR_PER_VF,
+ 			pf->num_alloc_vfs);
++>>>>>>> 46c276cebfb4 (ice: Improve clarity of prints and variables)
  		return -EIO;
  	}
  
 -	/* determine queue resources per VF */
 +	if (!num_msix)
 +		return -EIO;
 +
 +	/* Grab from the common pool
 +	 * start by requesting Default queues (4 as supported by AVF driver),
 +	 * Note that, the main difference between queues and vectors is, latter
 +	 * can only be reserved at init time but queues can be requested by VF
 +	 * at runtime through Virtchnl, that is the reason we start by reserving
 +	 * few queues.
 +	 */
  	num_txq = ice_determine_res(pf, ice_get_avail_txq_count(pf),
++<<<<<<< HEAD
 +				    ICE_DFLT_QS_PER_VF, ICE_MIN_QS_PER_VF);
 +
 +	num_rxq = ice_determine_res(pf, ice_get_avail_rxq_count(pf),
 +				    ICE_DFLT_QS_PER_VF, ICE_MIN_QS_PER_VF);
 +
 +	if (!num_txq || !num_rxq)
++=======
+ 				    min_t(u16,
+ 					  num_msix_per_vf - ICE_NONQ_VECS_VF,
+ 					  ICE_MAX_RSS_QS_PER_VF),
+ 				    ICE_MIN_QS_PER_VF);
+ 
+ 	num_rxq = ice_determine_res(pf, ice_get_avail_rxq_count(pf),
+ 				    min_t(u16,
+ 					  num_msix_per_vf - ICE_NONQ_VECS_VF,
+ 					  ICE_MAX_RSS_QS_PER_VF),
+ 				    ICE_MIN_QS_PER_VF);
+ 
+ 	if (!num_txq || !num_rxq) {
+ 		dev_err(dev, "Not enough queues to support minimum of %d queue pairs per VF for %d VFs\n",
+ 			ICE_MIN_QS_PER_VF, pf->num_alloc_vfs);
++>>>>>>> 46c276cebfb4 (ice: Improve clarity of prints and variables)
  		return -EIO;
 -	}
  
++<<<<<<< HEAD
 +	if (ice_sriov_set_msix_res(pf, num_msix * pf->num_alloc_vfs))
++=======
+ 	if (ice_sriov_set_msix_res(pf, num_msix_per_vf * pf->num_alloc_vfs)) {
+ 		dev_err(dev, "Unable to set MSI-X resources for %d VFs\n",
+ 			pf->num_alloc_vfs);
++>>>>>>> 46c276cebfb4 (ice: Improve clarity of prints and variables)
  		return -EINVAL;
 -	}
  
++<<<<<<< HEAD
 +	/* since AVF driver works with only queue pairs which means, it expects
 +	 * to have equal number of Rx and Tx queues, so take the minimum of
 +	 * available Tx or Rx queues
 +	 */
 +	pf->num_vf_qps = min_t(int, num_txq, num_rxq);
 +	pf->num_vf_msix = num_msix;
++=======
+ 	/* only allow equal Tx/Rx queue count (i.e. queue pairs) */
+ 	pf->num_qps_per_vf = min_t(int, num_txq, num_rxq);
+ 	pf->num_msix_per_vf = num_msix_per_vf;
+ 	dev_info(dev, "Enabling %d VFs with %d vectors and %d queues per VF\n",
+ 		 pf->num_alloc_vfs, pf->num_msix_per_vf, pf->num_qps_per_vf);
++>>>>>>> 46c276cebfb4 (ice: Improve clarity of prints and variables)
  
  	return 0;
  }
@@@ -2259,8 -2391,8 +2326,13 @@@ static int ice_vc_cfg_irq_map_msg(struc
  	 * there is actually at least a single VF queue vector mapped
  	 */
  	if (!test_bit(ICE_VF_STATE_ACTIVE, vf->vf_states) ||
++<<<<<<< HEAD
 +	    pf->num_vf_msix < num_q_vectors_mapped ||
 +	    !irqmap_info->num_vectors) {
++=======
+ 	    pf->num_msix_per_vf < num_q_vectors_mapped ||
+ 	    !num_q_vectors_mapped) {
++>>>>>>> 46c276cebfb4 (ice: Improve clarity of prints and variables)
  		v_ret = VIRTCHNL_STATUS_ERR_PARAM;
  		goto error_param;
  	}
@@@ -2281,7 -2413,7 +2353,11 @@@
  		/* vector_id is always 0-based for each VF, and can never be
  		 * larger than or equal to the max allowed interrupts per VF
  		 */
++<<<<<<< HEAD
 +		if (!(vector_id < ICE_MAX_INTR_PER_VF) ||
++=======
+ 		if (!(vector_id < pf->num_msix_per_vf) ||
++>>>>>>> 46c276cebfb4 (ice: Improve clarity of prints and variables)
  		    !ice_vc_isvalid_vsi_id(vf, vsi_id) ||
  		    (!vector_id && (map->rxq_map || map->txq_map))) {
  			v_ret = VIRTCHNL_STATUS_ERR_PARAM;
* Unmerged path drivers/net/ethernet/intel/ice/ice.h
diff --git a/drivers/net/ethernet/intel/ice/ice_lib.c b/drivers/net/ethernet/intel/ice/ice_lib.c
index 1bb9095c40d0..a58807f8ea3b 100644
--- a/drivers/net/ethernet/intel/ice/ice_lib.c
+++ b/drivers/net/ethernet/intel/ice/ice_lib.c
@@ -178,12 +178,12 @@ static void ice_vsi_set_num_qs(struct ice_vsi *vsi, u16 vf_id)
 		vf = &pf->vf[vsi->vf_id];
 		vsi->alloc_txq = vf->num_vf_qs;
 		vsi->alloc_rxq = vf->num_vf_qs;
-		/* pf->num_vf_msix includes (VF miscellaneous vector +
+		/* pf->num_msix_per_vf includes (VF miscellaneous vector +
 		 * data queue interrupts). Since vsi->num_q_vectors is number
 		 * of queues vectors, subtract 1 (ICE_NONQ_VECS_VF) from the
 		 * original vector count
 		 */
-		vsi->num_q_vectors = pf->num_vf_msix - ICE_NONQ_VECS_VF;
+		vsi->num_q_vectors = pf->num_msix_per_vf - ICE_NONQ_VECS_VF;
 		break;
 	case ICE_VSI_LB:
 		vsi->alloc_txq = 1;
@@ -907,6 +907,109 @@ static int ice_vsi_init(struct ice_vsi *vsi, bool init_vsi)
 	return ret;
 }
 
+/**
+ * ice_free_res - free a block of resources
+ * @res: pointer to the resource
+ * @index: starting index previously returned by ice_get_res
+ * @id: identifier to track owner
+ *
+ * Returns number of resources freed
+ */
+int ice_free_res(struct ice_res_tracker *res, u16 index, u16 id)
+{
+	int count = 0;
+	int i;
+
+	if (!res || index >= res->end)
+		return -EINVAL;
+
+	id |= ICE_RES_VALID_BIT;
+	for (i = index; i < res->end && res->list[i] == id; i++) {
+		res->list[i] = 0;
+		count++;
+	}
+
+	return count;
+}
+
+/**
+ * ice_search_res - Search the tracker for a block of resources
+ * @res: pointer to the resource
+ * @needed: size of the block needed
+ * @id: identifier to track owner
+ *
+ * Returns the base item index of the block, or -ENOMEM for error
+ */
+static int ice_search_res(struct ice_res_tracker *res, u16 needed, u16 id)
+{
+	int start = 0, end = 0;
+
+	if (needed > res->end)
+		return -ENOMEM;
+
+	id |= ICE_RES_VALID_BIT;
+
+	do {
+		/* skip already allocated entries */
+		if (res->list[end++] & ICE_RES_VALID_BIT) {
+			start = end;
+			if ((start + needed) > res->end)
+				break;
+		}
+
+		if (end == (start + needed)) {
+			int i = start;
+
+			/* there was enough, so assign it to the requestor */
+			while (i != end)
+				res->list[i++] = id;
+
+			return start;
+		}
+	} while (end < res->end);
+
+	return -ENOMEM;
+}
+
+/**
+ * ice_get_free_res_count - Get free count from a resource tracker
+ * @res: Resource tracker instance
+ */
+static u16 ice_get_free_res_count(struct ice_res_tracker *res)
+{
+	u16 i, count = 0;
+
+	for (i = 0; i < res->end; i++)
+		if (!(res->list[i] & ICE_RES_VALID_BIT))
+			count++;
+
+	return count;
+}
+
+/**
+ * ice_get_res - get a block of resources
+ * @pf: board private structure
+ * @res: pointer to the resource
+ * @needed: size of the block needed
+ * @id: identifier to track owner
+ *
+ * Returns the base item index of the block, or negative for error
+ */
+int
+ice_get_res(struct ice_pf *pf, struct ice_res_tracker *res, u16 needed, u16 id)
+{
+	if (!res || !pf)
+		return -EINVAL;
+
+	if (!needed || needed > res->num_entries || id >= ICE_RES_VALID_BIT) {
+		dev_err(ice_pf_to_dev(pf), "param err: needed=%d, num_entries = %d id=0x%04x\n",
+			needed, res->num_entries, id);
+		return -EINVAL;
+	}
+
+	return ice_search_res(res, needed, id);
+}
+
 /**
  * ice_vsi_setup_vector_base - Set up the base vector for the given VSI
  * @vsi: ptr to the VSI
@@ -939,8 +1042,9 @@ static int ice_vsi_setup_vector_base(struct ice_vsi *vsi)
 	vsi->base_vector = ice_get_res(pf, pf->irq_tracker, num_q_vectors,
 				       vsi->idx);
 	if (vsi->base_vector < 0) {
-		dev_err(dev, "Failed to get tracking for %d vectors for VSI %d, err=%d\n",
-			num_q_vectors, vsi->vsi_num, vsi->base_vector);
+		dev_err(dev, "%d MSI-X interrupts available. %s %d failed to get %d MSI-X vectors\n",
+			ice_get_free_res_count(pf->irq_tracker),
+			ice_vsi_type_str(vsi->type), vsi->idx, num_q_vectors);
 		return -ENOENT;
 	}
 	pf->num_avail_sw_msix -= num_q_vectors;
@@ -2345,94 +2449,6 @@ void ice_dis_vsi(struct ice_vsi *vsi, bool locked)
 	}
 }
 
-/**
- * ice_free_res - free a block of resources
- * @res: pointer to the resource
- * @index: starting index previously returned by ice_get_res
- * @id: identifier to track owner
- *
- * Returns number of resources freed
- */
-int ice_free_res(struct ice_res_tracker *res, u16 index, u16 id)
-{
-	int count = 0;
-	int i;
-
-	if (!res || index >= res->end)
-		return -EINVAL;
-
-	id |= ICE_RES_VALID_BIT;
-	for (i = index; i < res->end && res->list[i] == id; i++) {
-		res->list[i] = 0;
-		count++;
-	}
-
-	return count;
-}
-
-/**
- * ice_search_res - Search the tracker for a block of resources
- * @res: pointer to the resource
- * @needed: size of the block needed
- * @id: identifier to track owner
- *
- * Returns the base item index of the block, or -ENOMEM for error
- */
-static int ice_search_res(struct ice_res_tracker *res, u16 needed, u16 id)
-{
-	int start = 0, end = 0;
-
-	if (needed > res->end)
-		return -ENOMEM;
-
-	id |= ICE_RES_VALID_BIT;
-
-	do {
-		/* skip already allocated entries */
-		if (res->list[end++] & ICE_RES_VALID_BIT) {
-			start = end;
-			if ((start + needed) > res->end)
-				break;
-		}
-
-		if (end == (start + needed)) {
-			int i = start;
-
-			/* there was enough, so assign it to the requestor */
-			while (i != end)
-				res->list[i++] = id;
-
-			return start;
-		}
-	} while (end < res->end);
-
-	return -ENOMEM;
-}
-
-/**
- * ice_get_res - get a block of resources
- * @pf: board private structure
- * @res: pointer to the resource
- * @needed: size of the block needed
- * @id: identifier to track owner
- *
- * Returns the base item index of the block, or negative for error
- */
-int
-ice_get_res(struct ice_pf *pf, struct ice_res_tracker *res, u16 needed, u16 id)
-{
-	if (!res || !pf)
-		return -EINVAL;
-
-	if (!needed || needed > res->num_entries || id >= ICE_RES_VALID_BIT) {
-		dev_err(ice_pf_to_dev(pf), "param err: needed=%d, num_entries = %d id=0x%04x\n",
-			needed, res->num_entries, id);
-		return -EINVAL;
-	}
-
-	return ice_search_res(res, needed, id);
-}
-
 /**
  * ice_vsi_dis_irq - Mask off queue interrupt generation on the VSI
  * @vsi: the VSI being un-configured
* Unmerged path drivers/net/ethernet/intel/ice/ice_virtchnl_pf.c
