net/mlx5: E-Switch, Get reg_c0 value on CQE

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Paul Blakey <paulb@mellanox.com>
commit 11b717d6152699623fb1133759f9b8f235935a51
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/11b717d6.failed

On RX side create a restore table in OFFLOADS namespace.
This table will match on all values for reg_c0 we will use,
and set it to the flow_tag. This flow tag can then be read on the CQE.

As there is no copy action from reg c0 to flow tag, instead we have to
set the flow tag explictily. We add an API so callers can add all the used
reg_c0 values (tags) and for each of those we add a restore rule.

This will be used in a following patch to save the miss chain mapping
tag on reg_c0 and from it restore the tc chain on the skb.

	Signed-off-by: Paul Blakey <paulb@mellanox.com>
	Reviewed-by: Roi Dayan <roid@mellanox.com>
	Reviewed-by: Oz Shlomo <ozsh@mellanox.com>
	Reviewed-by: Mark Bloch <markb@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 11b717d6152699623fb1133759f9b8f235935a51)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
#	drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
index 9c629f913b96,a94d91cdc758..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
@@@ -609,6 -619,18 +612,21 @@@ mlx5_eswitch_enable_pf_vf_vports(struc
  				 enum mlx5_eswitch_vport_event enabled_events);
  void mlx5_eswitch_disable_pf_vf_vports(struct mlx5_eswitch *esw);
  
++<<<<<<< HEAD
++=======
+ int
+ esw_vport_create_offloads_acl_tables(struct mlx5_eswitch *esw,
+ 				     struct mlx5_vport *vport);
+ void
+ esw_vport_destroy_offloads_acl_tables(struct mlx5_eswitch *esw,
+ 				      struct mlx5_vport *vport);
+ 
+ struct mlx5_flow_handle *
+ esw_add_restore_rule(struct mlx5_eswitch *esw, u32 tag);
+ u32
+ esw_get_max_restore_tag(struct mlx5_eswitch *esw);
+ 
++>>>>>>> 11b717d61526 (net/mlx5: E-Switch, Get reg_c0 value on CQE)
  #else  /* CONFIG_MLX5_ESWITCH */
  /* eswitch API stubs */
  static inline int  mlx5_eswitch_init(struct mlx5_core_dev *dev) { return 0; }
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
index 1f7d3f1673cb,81c2cbf0c308..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@@ -854,173 -838,52 +854,222 @@@ out
  	return err;
  }
  
++<<<<<<< HEAD
 +#define ESW_OFFLOADS_NUM_GROUPS  4
 +
 +/* Firmware currently has 4 pool of 4 sizes that it supports (ESW_POOLS),
 + * and a virtual memory region of 16M (ESW_SIZE), this region is duplicated
 + * for each flow table pool. We can allocate up to 16M of each pool,
 + * and we keep track of how much we used via put/get_sz_to_pool.
 + * Firmware doesn't report any of this for now.
 + * ESW_POOL is expected to be sorted from large to small
 + */
 +#define ESW_SIZE (16 * 1024 * 1024)
 +const unsigned int ESW_POOLS[4] = { 4 * 1024 * 1024, 1 * 1024 * 1024,
 +				    64 * 1024, 128 };
 +
 +static int
 +get_sz_from_pool(struct mlx5_eswitch *esw)
 +{
 +	int sz = 0, i;
 +
 +	for (i = 0; i < ARRAY_SIZE(ESW_POOLS); i++) {
 +		if (esw->fdb_table.offloads.fdb_left[i]) {
 +			--esw->fdb_table.offloads.fdb_left[i];
 +			sz = ESW_POOLS[i];
 +			break;
 +		}
 +	}
 +
 +	return sz;
 +}
 +
 +static void
 +put_sz_to_pool(struct mlx5_eswitch *esw, int sz)
 +{
 +	int i;
 +
 +	for (i = 0; i < ARRAY_SIZE(ESW_POOLS); i++) {
 +		if (sz >= ESW_POOLS[i]) {
 +			++esw->fdb_table.offloads.fdb_left[i];
 +			break;
 +		}
 +	}
 +}
 +
 +static struct mlx5_flow_table *
 +create_next_size_table(struct mlx5_eswitch *esw,
 +		       struct mlx5_flow_namespace *ns,
 +		       u16 table_prio,
 +		       int level,
 +		       u32 flags)
 +{
 +	struct mlx5_flow_table_attr ft_attr = {};
 +	struct mlx5_flow_table *fdb;
 +	int sz;
 +
 +	sz = get_sz_from_pool(esw);
 +	if (!sz)
 +		return ERR_PTR(-ENOSPC);
 +
 +	ft_attr.max_fte = sz;
 +	ft_attr.prio = table_prio;
 +	ft_attr.level = level;
 +	ft_attr.flags = flags;
 +	ft_attr.autogroup.max_num_groups = ESW_OFFLOADS_NUM_GROUPS;
 +	fdb = mlx5_create_auto_grouped_flow_table(ns, &ft_attr);
 +	if (IS_ERR(fdb)) {
 +		esw_warn(esw->dev, "Failed to create FDB Table err %d (table prio: %d, level: %d, size: %d)\n",
 +			 (int)PTR_ERR(fdb), table_prio, level, sz);
 +		put_sz_to_pool(esw, sz);
 +	}
 +
 +	return fdb;
 +}
 +
 +static struct mlx5_flow_table *
 +esw_get_prio_table(struct mlx5_eswitch *esw, u32 chain, u16 prio, int level)
 +{
 +	struct mlx5_core_dev *dev = esw->dev;
 +	struct mlx5_flow_table *fdb = NULL;
 +	struct mlx5_flow_namespace *ns;
 +	int table_prio, l = 0;
 +	u32 flags = 0;
 +
 +	if (chain == FDB_SLOW_PATH_CHAIN)
 +		return esw->fdb_table.offloads.slow_fdb;
 +
 +	mutex_lock(&esw->fdb_table.offloads.fdb_prio_lock);
 +
 +	fdb = fdb_prio_table(esw, chain, prio, level).fdb;
 +	if (fdb) {
 +		/* take ref on earlier levels as well */
 +		while (level >= 0)
 +			fdb_prio_table(esw, chain, prio, level--).num_rules++;
 +		mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
 +		return fdb;
 +	}
 +
 +	ns = mlx5_get_fdb_sub_ns(dev, chain);
 +	if (!ns) {
 +		esw_warn(dev, "Failed to get FDB sub namespace\n");
 +		mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
 +		return ERR_PTR(-EOPNOTSUPP);
 +	}
 +
 +	if (esw->offloads.encap != DEVLINK_ESWITCH_ENCAP_MODE_NONE)
 +		flags |= (MLX5_FLOW_TABLE_TUNNEL_EN_REFORMAT |
 +			  MLX5_FLOW_TABLE_TUNNEL_EN_DECAP);
 +
 +	table_prio = (chain * FDB_MAX_PRIO) + prio - 1;
 +
 +	/* create earlier levels for correct fs_core lookup when
 +	 * connecting tables
 +	 */
 +	for (l = 0; l <= level; l++) {
 +		if (fdb_prio_table(esw, chain, prio, l).fdb) {
 +			fdb_prio_table(esw, chain, prio, l).num_rules++;
 +			continue;
 +		}
 +
 +		fdb = create_next_size_table(esw, ns, table_prio, l, flags);
 +		if (IS_ERR(fdb)) {
 +			l--;
 +			goto err_create_fdb;
 +		}
 +
 +		fdb_prio_table(esw, chain, prio, l).fdb = fdb;
 +		fdb_prio_table(esw, chain, prio, l).num_rules = 1;
 +	}
 +
 +	mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
 +	return fdb;
 +
 +err_create_fdb:
 +	mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
 +	if (l >= 0)
 +		esw_put_prio_table(esw, chain, prio, l);
 +
 +	return fdb;
 +}
 +
 +static void
 +esw_put_prio_table(struct mlx5_eswitch *esw, u32 chain, u16 prio, int level)
 +{
 +	int l;
 +
 +	if (chain == FDB_SLOW_PATH_CHAIN)
 +		return;
 +
 +	mutex_lock(&esw->fdb_table.offloads.fdb_prio_lock);
 +
 +	for (l = level; l >= 0; l--) {
 +		if (--(fdb_prio_table(esw, chain, prio, l).num_rules) > 0)
 +			continue;
 +
 +		put_sz_to_pool(esw, fdb_prio_table(esw, chain, prio, l).fdb->max_fte);
 +		mlx5_destroy_flow_table(fdb_prio_table(esw, chain, prio, l).fdb);
 +		fdb_prio_table(esw, chain, prio, l).fdb = NULL;
 +	}
 +
 +	mutex_unlock(&esw->fdb_table.offloads.fdb_prio_lock);
 +}
 +
 +static void esw_destroy_offloads_fast_fdb_tables(struct mlx5_eswitch *esw)
 +{
 +	/* If lazy creation isn't supported, deref the fast path tables */
 +	if (!(esw->fdb_table.flags & ESW_FDB_CHAINS_AND_PRIOS_SUPPORTED)) {
 +		esw_put_prio_table(esw, 0, 1, 1);
 +		esw_put_prio_table(esw, 0, 1, 0);
 +	}
++=======
+ struct mlx5_flow_handle *
+ esw_add_restore_rule(struct mlx5_eswitch *esw, u32 tag)
+ {
+ 	struct mlx5_flow_act flow_act = { .flags = FLOW_ACT_NO_APPEND, };
+ 	struct mlx5_flow_table *ft = esw->offloads.ft_offloads_restore;
+ 	struct mlx5_flow_context *flow_context;
+ 	struct mlx5_flow_handle *flow_rule;
+ 	struct mlx5_flow_destination dest;
+ 	struct mlx5_flow_spec *spec;
+ 	void *misc;
+ 
+ 	spec = kzalloc(sizeof(*spec), GFP_KERNEL);
+ 	if (!spec)
+ 		return ERR_PTR(-ENOMEM);
+ 
+ 	misc = MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
+ 			    misc_parameters_2);
+ 	MLX5_SET(fte_match_set_misc2, misc, metadata_reg_c_0,
+ 		 ESW_CHAIN_TAG_METADATA_MASK);
+ 	misc = MLX5_ADDR_OF(fte_match_param, spec->match_value,
+ 			    misc_parameters_2);
+ 	MLX5_SET(fte_match_set_misc2, misc, metadata_reg_c_0, tag);
+ 	spec->match_criteria_enable = MLX5_MATCH_MISC_PARAMETERS_2;
+ 	flow_act.action = MLX5_FLOW_CONTEXT_ACTION_FWD_DEST;
+ 
+ 	flow_context = &spec->flow_context;
+ 	flow_context->flags |= FLOW_CONTEXT_HAS_TAG;
+ 	flow_context->flow_tag = tag;
+ 	dest.type = MLX5_FLOW_DESTINATION_TYPE_FLOW_TABLE;
+ 	dest.ft = esw->offloads.ft_offloads;
+ 
+ 	flow_rule = mlx5_add_flow_rules(ft, spec, &flow_act, &dest, 1);
+ 	kfree(spec);
+ 
+ 	if (IS_ERR(flow_rule))
+ 		esw_warn(esw->dev,
+ 			 "Failed to create restore rule for tag: %d, err(%d)\n",
+ 			 tag, (int)PTR_ERR(flow_rule));
+ 
+ 	return flow_rule;
+ }
+ 
+ u32
+ esw_get_max_restore_tag(struct mlx5_eswitch *esw)
+ {
+ 	return ESW_CHAIN_TAG_METADATA_MASK;
++>>>>>>> 11b717d61526 (net/mlx5: E-Switch, Get reg_c0 value on CQE)
  }
  
  #define MAX_PF_SQ 256
@@@ -2066,13 -2066,13 +2195,17 @@@ static int esw_offloads_steering_init(s
  	return 0;
  
  create_fg_err:
- 	esw_destroy_offloads_table(esw);
- 
- create_ft_err:
  	esw_destroy_offloads_fdb_tables(esw);
- 
  create_fdb_err:
++<<<<<<< HEAD
 +	esw_destroy_offloads_acl_tables(esw);
++=======
+ 	esw_destroy_restore_table(esw);
+ create_restore_err:
+ 	esw_destroy_offloads_table(esw);
+ create_offloads_err:
+ 	esw_destroy_uplink_offloads_acl_tables(esw);
++>>>>>>> 11b717d61526 (net/mlx5: E-Switch, Get reg_c0 value on CQE)
  
  	return err;
  }
@@@ -2080,9 -2080,10 +2213,14 @@@
  static void esw_offloads_steering_cleanup(struct mlx5_eswitch *esw)
  {
  	esw_destroy_vport_rx_group(esw);
- 	esw_destroy_offloads_table(esw);
  	esw_destroy_offloads_fdb_tables(esw);
++<<<<<<< HEAD
 +	esw_destroy_offloads_acl_tables(esw);
++=======
+ 	esw_destroy_restore_table(esw);
+ 	esw_destroy_offloads_table(esw);
+ 	esw_destroy_uplink_offloads_acl_tables(esw);
++>>>>>>> 11b717d61526 (net/mlx5: E-Switch, Get reg_c0 value on CQE)
  }
  
  static void
diff --cc drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
index 19446018a6ee,2660ffabb09f..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
@@@ -109,9 -110,9 +109,15 @@@
  #define ANCHOR_NUM_PRIOS 1
  #define ANCHOR_MIN_LEVEL (BY_PASS_MIN_LEVEL + 1)
  
++<<<<<<< HEAD
 +#define OFFLOADS_MAX_FT 2
 +#define OFFLOADS_NUM_PRIOS 1
 +#define OFFLOADS_MIN_LEVEL (ANCHOR_MIN_LEVEL + 1)
++=======
+ #define OFFLOADS_MAX_FT 1
+ #define OFFLOADS_NUM_PRIOS 2
+ #define OFFLOADS_MIN_LEVEL (ANCHOR_MIN_LEVEL + OFFLOADS_NUM_PRIOS)
++>>>>>>> 11b717d61526 (net/mlx5: E-Switch, Get reg_c0 value on CQE)
  
  #define LAG_PRIO_NUM_LEVELS 1
  #define LAG_NUM_PRIOS 1
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch.h
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/fs_core.c
diff --git a/include/linux/mlx5/eswitch.h b/include/linux/mlx5/eswitch.h
index dd1333f29f6e..61705e74a5bb 100644
--- a/include/linux/mlx5/eswitch.h
+++ b/include/linux/mlx5/eswitch.h
@@ -84,6 +84,8 @@ bool mlx5_eswitch_vport_match_metadata_enabled(const struct mlx5_eswitch *esw);
 #define ESW_SOURCE_PORT_METADATA_BITS (ESW_VHCA_ID_BITS + ESW_VPORT_BITS)
 #define ESW_SOURCE_PORT_METADATA_OFFSET (32 - ESW_SOURCE_PORT_METADATA_BITS)
 #define ESW_CHAIN_TAG_METADATA_BITS (32 - ESW_SOURCE_PORT_METADATA_BITS)
+#define ESW_CHAIN_TAG_METADATA_MASK GENMASK(ESW_CHAIN_TAG_METADATA_BITS - 1,\
+					    0)
 
 static inline u32 mlx5_eswitch_get_vport_metadata_mask(void)
 {
