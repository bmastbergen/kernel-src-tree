net/mlx5e: en_tc: Rely just on register loopback for tunnel restoration

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Paul Blakey <paulb@mellanox.com>
commit 636bb96852398548bfc797dc29a2a6d4f95fc693
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/636bb968.failed

Register loopback which is needed for tunnel restoration, is now always
enabled if supported and not just with metadata enabled, check for
that instead.

	Signed-off-by: Paul Blakey <paulb@mellanox.com>
	Reviewed-by: Oz Shlomo <ozsh@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit 636bb96852398548bfc797dc29a2a6d4f95fc693)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index d358fdb49b84,a2ff7df67b46..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@@ -1658,33 -1785,256 +1658,50 @@@ static void mlx5e_tc_del_flow(struct ml
  	}
  }
  
 -static int flow_has_tc_fwd_action(struct flow_cls_offload *f)
 -{
 -	struct flow_rule *rule = flow_cls_offload_flow_rule(f);
 -	struct flow_action *flow_action = &rule->action;
 -	const struct flow_action_entry *act;
 -	int i;
 -
 -	flow_action_for_each(i, act, flow_action) {
 -		switch (act->id) {
 -		case FLOW_ACTION_GOTO:
 -			return true;
 -		default:
 -			continue;
 -		}
 -	}
 -
 -	return false;
 -}
 -
 -static int
 -enc_opts_is_dont_care_or_full_match(struct mlx5e_priv *priv,
 -				    struct flow_dissector_key_enc_opts *opts,
 -				    struct netlink_ext_ack *extack,
 -				    bool *dont_care)
 -{
 -	struct geneve_opt *opt;
 -	int off = 0;
 -
 -	*dont_care = true;
 -
 -	while (opts->len > off) {
 -		opt = (struct geneve_opt *)&opts->data[off];
 -
 -		if (!(*dont_care) || opt->opt_class || opt->type ||
 -		    memchr_inv(opt->opt_data, 0, opt->length * 4)) {
 -			*dont_care = false;
 -
 -			if (opt->opt_class != U16_MAX ||
 -			    opt->type != U8_MAX ||
 -			    memchr_inv(opt->opt_data, 0xFF,
 -				       opt->length * 4)) {
 -				NL_SET_ERR_MSG(extack,
 -					       "Partial match of tunnel options in chain > 0 isn't supported");
 -				netdev_warn(priv->netdev,
 -					    "Partial match of tunnel options in chain > 0 isn't supported");
 -				return -EOPNOTSUPP;
 -			}
 -		}
 -
 -		off += sizeof(struct geneve_opt) + opt->length * 4;
 -	}
 -
 -	return 0;
 -}
 -
 -#define COPY_DISSECTOR(rule, diss_key, dst)\
 -({ \
 -	struct flow_rule *__rule = (rule);\
 -	typeof(dst) __dst = dst;\
 -\
 -	memcpy(__dst,\
 -	       skb_flow_dissector_target(__rule->match.dissector,\
 -					 diss_key,\
 -					 __rule->match.key),\
 -	       sizeof(*__dst));\
 -})
 -
 -static int mlx5e_get_flow_tunnel_id(struct mlx5e_priv *priv,
 -				    struct mlx5e_tc_flow *flow,
 -				    struct flow_cls_offload *f,
 -				    struct net_device *filter_dev)
 -{
 -	struct flow_rule *rule = flow_cls_offload_flow_rule(f);
 -	struct netlink_ext_ack *extack = f->common.extack;
 -	struct mlx5_esw_flow_attr *attr = flow->esw_attr;
 -	struct mlx5e_tc_mod_hdr_acts *mod_hdr_acts;
 -	struct flow_match_enc_opts enc_opts_match;
 -	struct mlx5_rep_uplink_priv *uplink_priv;
 -	struct mlx5e_rep_priv *uplink_rpriv;
 -	struct tunnel_match_key tunnel_key;
 -	bool enc_opts_is_dont_care = true;
 -	u32 tun_id, enc_opts_id = 0;
 -	struct mlx5_eswitch *esw;
 -	u32 value, mask;
 -	int err;
 -
 -	esw = priv->mdev->priv.eswitch;
 -	uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
 -	uplink_priv = &uplink_rpriv->uplink_priv;
 -
 -	memset(&tunnel_key, 0, sizeof(tunnel_key));
 -	COPY_DISSECTOR(rule, FLOW_DISSECTOR_KEY_ENC_CONTROL,
 -		       &tunnel_key.enc_control);
 -	if (tunnel_key.enc_control.addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS)
 -		COPY_DISSECTOR(rule, FLOW_DISSECTOR_KEY_ENC_IPV4_ADDRS,
 -			       &tunnel_key.enc_ipv4);
 -	else
 -		COPY_DISSECTOR(rule, FLOW_DISSECTOR_KEY_ENC_IPV6_ADDRS,
 -			       &tunnel_key.enc_ipv6);
 -	COPY_DISSECTOR(rule, FLOW_DISSECTOR_KEY_ENC_IP, &tunnel_key.enc_ip);
 -	COPY_DISSECTOR(rule, FLOW_DISSECTOR_KEY_ENC_PORTS,
 -		       &tunnel_key.enc_tp);
 -	COPY_DISSECTOR(rule, FLOW_DISSECTOR_KEY_ENC_KEYID,
 -		       &tunnel_key.enc_key_id);
 -	tunnel_key.filter_ifindex = filter_dev->ifindex;
 -
 -	err = mapping_add(uplink_priv->tunnel_mapping, &tunnel_key, &tun_id);
 -	if (err)
 -		return err;
 -
 -	flow_rule_match_enc_opts(rule, &enc_opts_match);
 -	err = enc_opts_is_dont_care_or_full_match(priv,
 -						  enc_opts_match.mask,
 -						  extack,
 -						  &enc_opts_is_dont_care);
 -	if (err)
 -		goto err_enc_opts;
 -
 -	if (!enc_opts_is_dont_care) {
 -		err = mapping_add(uplink_priv->tunnel_enc_opts_mapping,
 -				  enc_opts_match.key, &enc_opts_id);
 -		if (err)
 -			goto err_enc_opts;
 -	}
 -
 -	value = tun_id << ENC_OPTS_BITS | enc_opts_id;
 -	mask = enc_opts_id ? TUNNEL_ID_MASK :
 -			     (TUNNEL_ID_MASK & ~ENC_OPTS_BITS_MASK);
 -
 -	if (attr->chain) {
 -		mlx5e_tc_match_to_reg_match(&attr->parse_attr->spec,
 -					    TUNNEL_TO_REG, value, mask);
 -	} else {
 -		mod_hdr_acts = &attr->parse_attr->mod_hdr_acts;
 -		err = mlx5e_tc_match_to_reg_set(priv->mdev,
 -						mod_hdr_acts,
 -						TUNNEL_TO_REG, value);
 -		if (err)
 -			goto err_set;
 -
 -		attr->action |= MLX5_FLOW_CONTEXT_ACTION_MOD_HDR;
 -	}
 -
 -	flow->tunnel_id = value;
 -	return 0;
 -
 -err_set:
 -	if (enc_opts_id)
 -		mapping_remove(uplink_priv->tunnel_enc_opts_mapping,
 -			       enc_opts_id);
 -err_enc_opts:
 -	mapping_remove(uplink_priv->tunnel_mapping, tun_id);
 -	return err;
 -}
 -
 -static void mlx5e_put_flow_tunnel_id(struct mlx5e_tc_flow *flow)
 -{
 -	u32 enc_opts_id = flow->tunnel_id & ENC_OPTS_BITS_MASK;
 -	u32 tun_id = flow->tunnel_id >> ENC_OPTS_BITS;
 -	struct mlx5_rep_uplink_priv *uplink_priv;
 -	struct mlx5e_rep_priv *uplink_rpriv;
 -	struct mlx5_eswitch *esw;
 -
 -	esw = flow->priv->mdev->priv.eswitch;
 -	uplink_rpriv = mlx5_eswitch_get_uplink_priv(esw, REP_ETH);
 -	uplink_priv = &uplink_rpriv->uplink_priv;
 -
 -	if (tun_id)
 -		mapping_remove(uplink_priv->tunnel_mapping, tun_id);
 -	if (enc_opts_id)
 -		mapping_remove(uplink_priv->tunnel_enc_opts_mapping,
 -			       enc_opts_id);
 -}
 -
 -u32 mlx5e_tc_get_flow_tun_id(struct mlx5e_tc_flow *flow)
 -{
 -	return flow->tunnel_id;
 -}
  
  static int parse_tunnel_attr(struct mlx5e_priv *priv,
 -			     struct mlx5e_tc_flow *flow,
  			     struct mlx5_flow_spec *spec,
  			     struct flow_cls_offload *f,
 -			     struct net_device *filter_dev,
 -			     u8 *match_level,
 -			     bool *match_inner)
 +			     struct net_device *filter_dev, u8 *match_level)
  {
 -	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
  	struct netlink_ext_ack *extack = f->common.extack;
 -	bool needs_mapping, sets_mapping;
  	int err;
  
++<<<<<<< HEAD
 +	err = mlx5e_tc_tun_parse(filter_dev, priv, spec, f, match_level);
 +	if (err) {
 +		NL_SET_ERR_MSG_MOD(extack,
 +				   "failed to parse tunnel attributes");
 +		return err;
++=======
+ 	if (!mlx5e_is_eswitch_flow(flow))
+ 		return -EOPNOTSUPP;
+ 
+ 	needs_mapping = !!flow->esw_attr->chain;
+ 	sets_mapping = !flow->esw_attr->chain && flow_has_tc_fwd_action(f);
+ 	*match_inner = !needs_mapping;
+ 
+ 	if ((needs_mapping || sets_mapping) &&
+ 	    !mlx5_eswitch_reg_c1_loopback_enabled(esw)) {
+ 		NL_SET_ERR_MSG(extack,
+ 			       "Chains on tunnel devices isn't supported without register loopback support");
+ 		netdev_warn(priv->netdev,
+ 			    "Chains on tunnel devices isn't supported without register loopback support");
+ 		return -EOPNOTSUPP;
++>>>>>>> 636bb9685239 (net/mlx5e: en_tc: Rely just on register loopback for tunnel restoration)
  	}
  
 -	if (!flow->esw_attr->chain) {
 -		err = mlx5e_tc_tun_parse(filter_dev, priv, spec, f,
 -					 match_level);
 -		if (err) {
 -			NL_SET_ERR_MSG_MOD(extack,
 -					   "Failed to parse tunnel attributes");
 -			netdev_warn(priv->netdev,
 -				    "Failed to parse tunnel attributes");
 -			return err;
 -		}
 -
 -		flow->esw_attr->action |= MLX5_FLOW_CONTEXT_ACTION_DECAP;
 -	}
 -
 -	if (!needs_mapping && !sets_mapping)
 -		return 0;
 -
 -	return mlx5e_get_flow_tunnel_id(priv, flow, f, filter_dev);
 -}
 -
 -static void *get_match_inner_headers_criteria(struct mlx5_flow_spec *spec)
 -{
 -	return MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 -			    inner_headers);
 -}
 -
 -static void *get_match_inner_headers_value(struct mlx5_flow_spec *spec)
 -{
 -	return MLX5_ADDR_OF(fte_match_param, spec->match_value,
 -			    inner_headers);
 -}
 -
 -static void *get_match_outer_headers_criteria(struct mlx5_flow_spec *spec)
 -{
 -	return MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 -			    outer_headers);
 +	return 0;
  }
  
 -static void *get_match_outer_headers_value(struct mlx5_flow_spec *spec)
 +static void *get_match_headers_criteria(u32 flags,
 +					struct mlx5_flow_spec *spec)
  {
 -	return MLX5_ADDR_OF(fte_match_param, spec->match_value,
 -			    outer_headers);
 +	return (flags & MLX5_FLOW_CONTEXT_ACTION_DECAP) ?
 +		MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 +			     inner_headers) :
 +		MLX5_ADDR_OF(fte_match_param, spec->match_criteria,
 +			     outer_headers);
  }
  
  static void *get_match_headers_value(u32 flags,
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
