io_uring: mark requests that we can do poll async in io_op_defs

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jens Axboe <axboe@kernel.dk>
commit 8a72758c51f8a5501a0e01ea95069630edb9ca07
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/8a72758c.failed

Add a pollin/pollout field to the request table, and have commands that
we can safely poll for properly marked.

	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 8a72758c51f8a5501a0e01ea95069630edb9ca07)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/io_uring.c
diff --cc fs/io_uring.c
index 7842c6de7135,0d973de75127..000000000000
--- a/fs/io_uring.c
+++ b/fs/io_uring.c
@@@ -366,8 -610,195 +366,200 @@@ struct io_submit_state 
  	unsigned int		ios_left;
  };
  
++<<<<<<< HEAD
 +static void io_sq_wq_submit_work(struct work_struct *work);
 +static void __io_free_req(struct io_kiocb *req);
++=======
+ struct io_op_def {
+ 	/* needs req->io allocated for deferral/async */
+ 	unsigned		async_ctx : 1;
+ 	/* needs current->mm setup, does mm access */
+ 	unsigned		needs_mm : 1;
+ 	/* needs req->file assigned */
+ 	unsigned		needs_file : 1;
+ 	/* needs req->file assigned IFF fd is >= 0 */
+ 	unsigned		fd_non_neg : 1;
+ 	/* hash wq insertion if file is a regular file */
+ 	unsigned		hash_reg_file : 1;
+ 	/* unbound wq insertion if file is a non-regular file */
+ 	unsigned		unbound_nonreg_file : 1;
+ 	/* opcode is not supported by this kernel */
+ 	unsigned		not_supported : 1;
+ 	/* needs file table */
+ 	unsigned		file_table : 1;
+ 	/* needs ->fs */
+ 	unsigned		needs_fs : 1;
+ 	/* set if opcode supports polled "wait" */
+ 	unsigned		pollin : 1;
+ 	unsigned		pollout : 1;
+ };
+ 
+ static const struct io_op_def io_op_defs[] = {
+ 	[IORING_OP_NOP] = {},
+ 	[IORING_OP_READV] = {
+ 		.async_ctx		= 1,
+ 		.needs_mm		= 1,
+ 		.needs_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 		.pollin			= 1,
+ 	},
+ 	[IORING_OP_WRITEV] = {
+ 		.async_ctx		= 1,
+ 		.needs_mm		= 1,
+ 		.needs_file		= 1,
+ 		.hash_reg_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 		.pollout		= 1,
+ 	},
+ 	[IORING_OP_FSYNC] = {
+ 		.needs_file		= 1,
+ 	},
+ 	[IORING_OP_READ_FIXED] = {
+ 		.needs_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 		.pollin			= 1,
+ 	},
+ 	[IORING_OP_WRITE_FIXED] = {
+ 		.needs_file		= 1,
+ 		.hash_reg_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 		.pollout		= 1,
+ 	},
+ 	[IORING_OP_POLL_ADD] = {
+ 		.needs_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 	},
+ 	[IORING_OP_POLL_REMOVE] = {},
+ 	[IORING_OP_SYNC_FILE_RANGE] = {
+ 		.needs_file		= 1,
+ 	},
+ 	[IORING_OP_SENDMSG] = {
+ 		.async_ctx		= 1,
+ 		.needs_mm		= 1,
+ 		.needs_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 		.needs_fs		= 1,
+ 		.pollout		= 1,
+ 	},
+ 	[IORING_OP_RECVMSG] = {
+ 		.async_ctx		= 1,
+ 		.needs_mm		= 1,
+ 		.needs_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 		.needs_fs		= 1,
+ 		.pollin			= 1,
+ 	},
+ 	[IORING_OP_TIMEOUT] = {
+ 		.async_ctx		= 1,
+ 		.needs_mm		= 1,
+ 	},
+ 	[IORING_OP_TIMEOUT_REMOVE] = {},
+ 	[IORING_OP_ACCEPT] = {
+ 		.needs_mm		= 1,
+ 		.needs_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 		.file_table		= 1,
+ 		.pollin			= 1,
+ 	},
+ 	[IORING_OP_ASYNC_CANCEL] = {},
+ 	[IORING_OP_LINK_TIMEOUT] = {
+ 		.async_ctx		= 1,
+ 		.needs_mm		= 1,
+ 	},
+ 	[IORING_OP_CONNECT] = {
+ 		.async_ctx		= 1,
+ 		.needs_mm		= 1,
+ 		.needs_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 		.pollout		= 1,
+ 	},
+ 	[IORING_OP_FALLOCATE] = {
+ 		.needs_file		= 1,
+ 	},
+ 	[IORING_OP_OPENAT] = {
+ 		.needs_file		= 1,
+ 		.fd_non_neg		= 1,
+ 		.file_table		= 1,
+ 		.needs_fs		= 1,
+ 	},
+ 	[IORING_OP_CLOSE] = {
+ 		.needs_file		= 1,
+ 		.file_table		= 1,
+ 	},
+ 	[IORING_OP_FILES_UPDATE] = {
+ 		.needs_mm		= 1,
+ 		.file_table		= 1,
+ 	},
+ 	[IORING_OP_STATX] = {
+ 		.needs_mm		= 1,
+ 		.needs_file		= 1,
+ 		.fd_non_neg		= 1,
+ 		.needs_fs		= 1,
+ 	},
+ 	[IORING_OP_READ] = {
+ 		.needs_mm		= 1,
+ 		.needs_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 		.pollin			= 1,
+ 	},
+ 	[IORING_OP_WRITE] = {
+ 		.needs_mm		= 1,
+ 		.needs_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 		.pollout		= 1,
+ 	},
+ 	[IORING_OP_FADVISE] = {
+ 		.needs_file		= 1,
+ 	},
+ 	[IORING_OP_MADVISE] = {
+ 		.needs_mm		= 1,
+ 	},
+ 	[IORING_OP_SEND] = {
+ 		.needs_mm		= 1,
+ 		.needs_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 		.pollout		= 1,
+ 	},
+ 	[IORING_OP_RECV] = {
+ 		.needs_mm		= 1,
+ 		.needs_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 		.pollin			= 1,
+ 	},
+ 	[IORING_OP_OPENAT2] = {
+ 		.needs_file		= 1,
+ 		.fd_non_neg		= 1,
+ 		.file_table		= 1,
+ 		.needs_fs		= 1,
+ 	},
+ 	[IORING_OP_EPOLL_CTL] = {
+ 		.unbound_nonreg_file	= 1,
+ 		.file_table		= 1,
+ 	},
+ 	[IORING_OP_SPLICE] = {
+ 		.needs_file		= 1,
+ 		.hash_reg_file		= 1,
+ 		.unbound_nonreg_file	= 1,
+ 	}
+ };
+ 
+ static void io_wq_submit_work(struct io_wq_work **workptr);
+ static void io_cqring_fill_event(struct io_kiocb *req, long res);
+ static void io_put_req(struct io_kiocb *req);
+ static void __io_double_put_req(struct io_kiocb *req);
+ static struct io_kiocb *io_prep_linked_timeout(struct io_kiocb *req);
+ static void io_queue_linked_timeout(struct io_kiocb *req);
+ static int __io_sqe_files_update(struct io_ring_ctx *ctx,
+ 				 struct io_uring_files_update *ip,
+ 				 unsigned nr_args);
+ static int io_grab_files(struct io_kiocb *req);
+ static void io_ring_file_ref_flush(struct fixed_file_data *data);
+ static void io_cleanup_req(struct io_kiocb *req);
+ static int io_file_get(struct io_submit_state *state, struct io_kiocb *req,
+ 		       int fd, struct file **out_file, bool fixed);
+ static void __io_queue_sqe(struct io_kiocb *req,
+ 			   const struct io_uring_sqe *sqe);
++>>>>>>> 8a72758c51f8 (io_uring: mark requests that we can do poll async in io_op_defs)
  
  static struct kmem_cache *req_cachep;
  
* Unmerged path fs/io_uring.c
