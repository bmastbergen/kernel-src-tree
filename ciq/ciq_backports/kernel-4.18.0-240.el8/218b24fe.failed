net/smc: adapt SMC remote DELETE_RKEY processing to use the LLC flow

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Karsten Graul <kgraul@linux.ibm.com>
commit 218b24fe381238941a06496eaf221a22c5935267
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/218b24fe.failed

Use the LLC flow framework for the processing of DELETE_RKEY messages
that were received from the peer.

	Signed-off-by: Karsten Graul <kgraul@linux.ibm.com>
	Reviewed-by: Ursula Braun <ubraun@linux.ibm.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 218b24fe381238941a06496eaf221a22c5935267)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/smc/smc_llc.c
diff --cc net/smc/smc_llc.c
index 4119cdb6b6bf,e458207bde9e..000000000000
--- a/net/smc/smc_llc.c
+++ b/net/smc/smc_llc.c
@@@ -461,133 -551,269 +461,239 @@@ static void smc_llc_rx_delete_link(stru
  {
  	struct smc_link_group *lgr = smc_get_lgr(link);
  
 -	smc_lgr_forget(lgr);
 -	smc_llc_link_deleting(link);
 -	if (lgr->role == SMC_SERV) {
 -		/* client asks to delete this link, send request */
 -		smc_llc_prep_delete_link(llc, link, SMC_LLC_REQ, true);
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (lgr->role == SMC_SERV)
 +			smc_lgr_schedule_free_work_fast(lgr);
  	} else {
 -		/* server requests to delete this link, send response */
 -		smc_llc_prep_delete_link(llc, link, SMC_LLC_RESP, true);
 +		smc_lgr_forget(lgr);
 +		smc_llc_link_deleting(link);
 +		if (lgr->role == SMC_SERV) {
 +			/* client asks to delete this link, send request */
 +			smc_llc_prep_delete_link(llc, link, SMC_LLC_REQ, true);
 +		} else {
 +			/* server requests to delete this link, send response */
 +			smc_llc_prep_delete_link(llc, link, SMC_LLC_RESP, true);
 +		}
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +		smc_lgr_terminate_sched(lgr);
  	}
 -	smc_llc_send_message(link, llc);
 -	smc_lgr_terminate_sched(lgr);
  }
  
 -/* process a confirm_rkey request from peer, remote flow */
 -static void smc_llc_rmt_conf_rkey(struct smc_link_group *lgr)
 +static void smc_llc_rx_test_link(struct smc_link *link,
 +				 struct smc_llc_msg_test_link *llc)
  {
 -	struct smc_llc_msg_confirm_rkey *llc;
 -	struct smc_llc_qentry *qentry;
 -	struct smc_link *link;
 -	int num_entries;
 -	int rk_idx;
 -	int i;
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (link->state == SMC_LNK_ACTIVE)
 +			complete(&link->llc_testlink_resp);
 +	} else {
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +	}
 +}
  
 -	qentry = lgr->llc_flow_rmt.qentry;
 -	llc = &qentry->msg.confirm_rkey;
 -	link = qentry->link;
 +static void smc_llc_rx_confirm_rkey(struct smc_link *link,
 +				    struct smc_llc_msg_confirm_rkey *llc)
 +{
 +	int rc;
  
 -	num_entries = llc->rtoken[0].num_rkeys;
 -	/* first rkey entry is for receiving link */
 -	rk_idx = smc_rtoken_add(link,
 -				llc->rtoken[0].rmb_vaddr,
 -				llc->rtoken[0].rmb_key);
 -	if (rk_idx < 0)
 -		goto out_err;
 -
 -	for (i = 1; i <= min_t(u8, num_entries, SMC_LLC_RKEYS_PER_MSG - 1); i++)
 -		smc_rtoken_set2(lgr, rk_idx, llc->rtoken[i].link_id,
 -				llc->rtoken[i].rmb_vaddr,
 -				llc->rtoken[i].rmb_key);
 -	/* max links is 3 so there is no need to support conf_rkey_cont msgs */
 -	goto out;
 -out_err:
 -	llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 -	llc->hd.flags |= SMC_LLC_FLAG_RKEY_RETRY;
 -out:
 -	llc->hd.flags |= SMC_LLC_FLAG_RESP;
 -	smc_llc_send_message(link, &qentry->msg);
 -	smc_llc_flow_qentry_del(&lgr->llc_flow_rmt);
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		link->llc_confirm_rkey_rc = llc->hd.flags &
 +					    SMC_LLC_FLAG_RKEY_NEG;
 +		complete(&link->llc_confirm_rkey);
 +	} else {
 +		rc = smc_rtoken_add(link,
 +				    llc->rtoken[0].rmb_vaddr,
 +				    llc->rtoken[0].rmb_key);
 +
 +		/* ignore rtokens for other links, we have only one link */
 +
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		if (rc < 0)
 +			llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +	}
  }
  
++<<<<<<< HEAD
 +static void smc_llc_rx_confirm_rkey_cont(struct smc_link *link,
 +				      struct smc_llc_msg_confirm_rkey_cont *llc)
 +{
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		/* unused as long as we don't send this type of msg */
 +	} else {
 +		/* ignore rtokens for other links, we have only one link */
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +	}
 +}
 +
 +static void smc_llc_rx_delete_rkey(struct smc_link *link,
 +				   struct smc_llc_msg_delete_rkey *llc)
++=======
+ /* process a delete_rkey request from peer, remote flow */
+ static void smc_llc_rmt_delete_rkey(struct smc_link_group *lgr)
++>>>>>>> 218b24fe3812 (net/smc: adapt SMC remote DELETE_RKEY processing to use the LLC flow)
  {
+ 	struct smc_llc_msg_delete_rkey *llc;
+ 	struct smc_llc_qentry *qentry;
+ 	struct smc_link *link;
  	u8 err_mask = 0;
  	int i, max;
  
++<<<<<<< HEAD
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		link->llc_delete_rkey_rc = llc->hd.flags &
 +					    SMC_LLC_FLAG_RKEY_NEG;
 +		complete(&link->llc_delete_rkey);
 +	} else {
 +		max = min_t(u8, llc->num_rkeys, SMC_LLC_DEL_RKEY_MAX);
 +		for (i = 0; i < max; i++) {
 +			if (smc_rtoken_delete(link, llc->rkey[i]))
 +				err_mask |= 1 << (SMC_LLC_DEL_RKEY_MAX - 1 - i);
++=======
+ 	qentry = lgr->llc_flow_rmt.qentry;
+ 	llc = &qentry->msg.delete_rkey;
+ 	link = qentry->link;
+ 
+ 	max = min_t(u8, llc->num_rkeys, SMC_LLC_DEL_RKEY_MAX);
+ 	for (i = 0; i < max; i++) {
+ 		if (smc_rtoken_delete(link, llc->rkey[i]))
+ 			err_mask |= 1 << (SMC_LLC_DEL_RKEY_MAX - 1 - i);
+ 	}
+ 	if (err_mask) {
+ 		llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
+ 		llc->err_mask = err_mask;
+ 	}
+ 	llc->hd.flags |= SMC_LLC_FLAG_RESP;
+ 	smc_llc_send_message(link, &qentry->msg);
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_rmt);
+ }
+ 
+ static void smc_llc_rx_confirm_rkey_cont(struct smc_link *link,
+ 				      struct smc_llc_msg_confirm_rkey_cont *llc)
+ {
+ 	/* ignore rtokens for other links, we have only one link */
+ 	llc->hd.flags |= SMC_LLC_FLAG_RESP;
+ 	smc_llc_send_message(link, llc);
+ }
+ 
+ /* flush the llc event queue */
+ static void smc_llc_event_flush(struct smc_link_group *lgr)
+ {
+ 	struct smc_llc_qentry *qentry, *q;
+ 
+ 	spin_lock_bh(&lgr->llc_event_q_lock);
+ 	list_for_each_entry_safe(qentry, q, &lgr->llc_event_q, list) {
+ 		list_del_init(&qentry->list);
+ 		kfree(qentry);
+ 	}
+ 	spin_unlock_bh(&lgr->llc_event_q_lock);
+ }
+ 
+ static void smc_llc_event_handler(struct smc_llc_qentry *qentry)
+ {
+ 	union smc_llc_msg *llc = &qentry->msg;
+ 	struct smc_link *link = qentry->link;
+ 	struct smc_link_group *lgr = link->lgr;
+ 
+ 	if (!smc_link_usable(link))
+ 		goto out;
+ 
+ 	switch (llc->raw.hdr.common.type) {
+ 	case SMC_LLC_TEST_LINK:
+ 		llc->test_link.hd.flags |= SMC_LLC_FLAG_RESP;
+ 		smc_llc_send_message(link, llc);
+ 		break;
+ 	case SMC_LLC_ADD_LINK:
+ 		if (list_empty(&lgr->list))
+ 			goto out;	/* lgr is terminating */
+ 		if (lgr->role == SMC_CLNT) {
+ 			if (lgr->llc_flow_lcl.type == SMC_LLC_FLOW_ADD_LINK) {
+ 				/* a flow is waiting for this message */
+ 				smc_llc_flow_qentry_set(&lgr->llc_flow_lcl,
+ 							qentry);
+ 				wake_up_interruptible(&lgr->llc_waiter);
+ 			} else if (smc_llc_flow_start(&lgr->llc_flow_lcl,
+ 						      qentry)) {
+ 				/* tbd: schedule_work(&lgr->llc_add_link_work); */
+ 			}
+ 		} else if (smc_llc_flow_start(&lgr->llc_flow_lcl, qentry)) {
+ 			/* as smc server, handle client suggestion */
+ 			/* tbd: schedule_work(&lgr->llc_add_link_work); */
++>>>>>>> 218b24fe3812 (net/smc: adapt SMC remote DELETE_RKEY processing to use the LLC flow)
  		}
 -		return;
 -	case SMC_LLC_CONFIRM_LINK:
 -		if (lgr->llc_flow_lcl.type != SMC_LLC_FLOW_NONE) {
 -			/* a flow is waiting for this message */
 -			smc_llc_flow_qentry_set(&lgr->llc_flow_lcl, qentry);
 -			wake_up_interruptible(&lgr->llc_waiter);
 -			return;
 +
 +		if (err_mask) {
 +			llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 +			llc->err_mask = err_mask;
  		}
++<<<<<<< HEAD
 +
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
++=======
+ 		break;
+ 	case SMC_LLC_DELETE_LINK:
+ 		smc_llc_rx_delete_link(link, &llc->delete_link);
+ 		break;
+ 	case SMC_LLC_CONFIRM_RKEY:
+ 		/* new request from remote, assign to remote flow */
+ 		if (smc_llc_flow_start(&lgr->llc_flow_rmt, qentry)) {
+ 			/* process here, does not wait for more llc msgs */
+ 			smc_llc_rmt_conf_rkey(lgr);
+ 			smc_llc_flow_stop(lgr, &lgr->llc_flow_rmt);
+ 		}
+ 		return;
+ 	case SMC_LLC_CONFIRM_RKEY_CONT:
+ 		smc_llc_rx_confirm_rkey_cont(link, &llc->confirm_rkey_cont);
+ 		break;
+ 	case SMC_LLC_DELETE_RKEY:
+ 		/* new request from remote, assign to remote flow */
+ 		if (smc_llc_flow_start(&lgr->llc_flow_rmt, qentry)) {
+ 			/* process here, does not wait for more llc msgs */
+ 			smc_llc_rmt_delete_rkey(lgr);
+ 			smc_llc_flow_stop(lgr, &lgr->llc_flow_rmt);
+ 		}
+ 		return;
++>>>>>>> 218b24fe3812 (net/smc: adapt SMC remote DELETE_RKEY processing to use the LLC flow)
  	}
 -out:
 -	kfree(qentry);
  }
  
 -/* worker to process llc messages on the event queue */
 -static void smc_llc_event_work(struct work_struct *work)
 +static void smc_llc_rx_handler(struct ib_wc *wc, void *buf)
  {
 -	struct smc_link_group *lgr = container_of(work, struct smc_link_group,
 -						  llc_event_work);
 -	struct smc_llc_qentry *qentry;
 -
 -	if (!lgr->llc_flow_lcl.type && lgr->delayed_event) {
 -		if (smc_link_usable(lgr->delayed_event->link)) {
 -			smc_llc_event_handler(lgr->delayed_event);
 -		} else {
 -			qentry = lgr->delayed_event;
 -			lgr->delayed_event = NULL;
 -			kfree(qentry);
 -		}
 -	}
 -
 -again:
 -	spin_lock_bh(&lgr->llc_event_q_lock);
 -	if (!list_empty(&lgr->llc_event_q)) {
 -		qentry = list_first_entry(&lgr->llc_event_q,
 -					  struct smc_llc_qentry, list);
 -		list_del_init(&qentry->list);
 -		spin_unlock_bh(&lgr->llc_event_q_lock);
 -		smc_llc_event_handler(qentry);
 -		goto again;
 -	}
 -	spin_unlock_bh(&lgr->llc_event_q_lock);
 -}
 +	struct smc_link *link = (struct smc_link *)wc->qp->qp_context;
 +	union smc_llc_msg *llc = buf;
  
 -/* process llc responses in tasklet context */
 -static void smc_llc_rx_response(struct smc_link *link,
 -				struct smc_llc_qentry *qentry)
 -{
 -	u8 llc_type = qentry->msg.raw.hdr.common.type;
 +	if (wc->byte_len < sizeof(*llc))
 +		return; /* short message */
 +	if (llc->raw.hdr.length != sizeof(*llc))
 +		return; /* invalid message */
 +	if (link->state == SMC_LNK_INACTIVE)
 +		return; /* link not active, drop msg */
  
 -	switch (llc_type) {
 +	switch (llc->raw.hdr.common.type) {
  	case SMC_LLC_TEST_LINK:
 -		if (link->state == SMC_LNK_ACTIVE)
 -			complete(&link->llc_testlink_resp);
 +		smc_llc_rx_test_link(link, &llc->test_link);
  		break;
 -	case SMC_LLC_ADD_LINK:
  	case SMC_LLC_CONFIRM_LINK:
 -	case SMC_LLC_CONFIRM_RKEY:
 -	case SMC_LLC_DELETE_RKEY:
 -		/* assign responses to the local flow, we requested them */
 -		smc_llc_flow_qentry_set(&link->lgr->llc_flow_lcl, qentry);
 -		wake_up_interruptible(&link->lgr->llc_waiter);
 -		return;
 +		smc_llc_rx_confirm_link(link, &llc->confirm_link);
 +		break;
 +	case SMC_LLC_ADD_LINK:
 +		smc_llc_rx_add_link(link, &llc->add_link);
 +		break;
  	case SMC_LLC_DELETE_LINK:
 -		if (link->lgr->role == SMC_SERV)
 -			smc_lgr_schedule_free_work_fast(link->lgr);
 +		smc_llc_rx_delete_link(link, &llc->delete_link);
 +		break;
 +	case SMC_LLC_CONFIRM_RKEY:
 +		smc_llc_rx_confirm_rkey(link, &llc->confirm_rkey);
  		break;
  	case SMC_LLC_CONFIRM_RKEY_CONT:
 -		/* unused as long as we don't send this type of msg */
 +		smc_llc_rx_confirm_rkey_cont(link, &llc->confirm_rkey_cont);
 +		break;
 +	case SMC_LLC_DELETE_RKEY:
 +		smc_llc_rx_delete_rkey(link, &llc->delete_rkey);
  		break;
  	}
 -	kfree(qentry);
 -}
 -
 -static void smc_llc_enqueue(struct smc_link *link, union smc_llc_msg *llc)
 -{
 -	struct smc_link_group *lgr = link->lgr;
 -	struct smc_llc_qentry *qentry;
 -	unsigned long flags;
 -
 -	qentry = kmalloc(sizeof(*qentry), GFP_ATOMIC);
 -	if (!qentry)
 -		return;
 -	qentry->link = link;
 -	INIT_LIST_HEAD(&qentry->list);
 -	memcpy(&qentry->msg, llc, sizeof(union smc_llc_msg));
 -
 -	/* process responses immediately */
 -	if (llc->raw.hdr.flags & SMC_LLC_FLAG_RESP) {
 -		smc_llc_rx_response(link, qentry);
 -		return;
 -	}
 -
 -	/* add requests to event queue */
 -	spin_lock_irqsave(&lgr->llc_event_q_lock, flags);
 -	list_add_tail(&qentry->list, &lgr->llc_event_q);
 -	spin_unlock_irqrestore(&lgr->llc_event_q_lock, flags);
 -	schedule_work(&link->lgr->llc_event_work);
 -}
 -
 -/* copy received msg and add it to the event queue */
 -static void smc_llc_rx_handler(struct ib_wc *wc, void *buf)
 -{
 -	struct smc_link *link = (struct smc_link *)wc->qp->qp_context;
 -	union smc_llc_msg *llc = buf;
 -
 -	if (wc->byte_len < sizeof(*llc))
 -		return; /* short message */
 -	if (llc->raw.hdr.length != sizeof(*llc))
 -		return; /* invalid message */
 -
 -	smc_llc_enqueue(link, llc);
  }
  
  /***************************** worker, utils *********************************/
* Unmerged path net/smc/smc_llc.c
