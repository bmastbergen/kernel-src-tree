KVM: Add kvm_arch_vcpu_precreate() to handle pre-allocation issues

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Sean Christopherson <sean.j.christopherson@intel.com>
commit 897cc38eaab96d006ab17edd0f50a2f432f584cf
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/897cc38e.failed

Add a pre-allocation arch hook to handle checks that are currently done
by arch specific code prior to allocating the vCPU object.  This paves
the way for moving the allocation to common KVM code.

	Acked-by: Christoffer Dall <christoffer.dall@arm.com>
	Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
	Reviewed-by: Cornelia Huck <cohuck@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 897cc38eaab96d006ab17edd0f50a2f432f584cf)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/kvm/x86.c
diff --cc arch/x86/kvm/x86.c
index fd0e26bb25de,661e3c40529f..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -9148,29 -9170,39 +9148,45 @@@ static void fx_init(struct kvm_vcpu *vc
  	vcpu->arch.cr0 |= X86_CR0_ET;
  }
  
++<<<<<<< HEAD
 +void kvm_arch_vcpu_free(struct kvm_vcpu *vcpu)
 +{
 +	void *wbinvd_dirty_mask = vcpu->arch.wbinvd_dirty_mask;
 +
 +	kvmclock_reset(vcpu);
 +
 +	kvm_x86_ops->vcpu_free(vcpu);
 +	free_cpumask_var(wbinvd_dirty_mask);
++=======
+ int kvm_arch_vcpu_precreate(struct kvm *kvm, unsigned int id)
+ {
+ 	if (kvm_check_tsc_unstable() && atomic_read(&kvm->online_vcpus) != 0)
+ 		pr_warn_once("kvm: SMP vm created on host with unstable TSC; "
+ 			     "guest TSC will not be reliable\n");
+ 
+ 	return 0;
++>>>>>>> 897cc38eaab9 (KVM: Add kvm_arch_vcpu_precreate() to handle pre-allocation issues)
  }
  
  struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm,
  						unsigned int id)
  {
  	struct kvm_vcpu *vcpu;
 -	int r;
  
++<<<<<<< HEAD
 +	if (kvm_check_tsc_unstable() && atomic_read(&kvm->online_vcpus) != 0)
 +		printk_once(KERN_WARNING
 +		"kvm: SMP vm created on host with unstable TSC; "
 +		"guest TSC will not be reliable\n");
 +
 +	vcpu = kvm_x86_ops->vcpu_create(kvm, id);
++=======
+ 	vcpu = kmem_cache_zalloc(kvm_vcpu_cache, GFP_KERNEL_ACCOUNT);
+ 	if (!vcpu)
+ 		return ERR_PTR(-ENOMEM);
++>>>>>>> 897cc38eaab9 (KVM: Add kvm_arch_vcpu_precreate() to handle pre-allocation issues)
  
 -	r = kvm_vcpu_init(vcpu, kvm, id);
 -	if (r)
 -		goto free_vcpu;
 -
 -	r = kvm_x86_ops->vcpu_create(vcpu);
 -	if (r)
 -		goto uninit_vcpu;
  	return vcpu;
 -
 -uninit_vcpu:
 -	kvm_vcpu_uninit(vcpu);
 -free_vcpu:
 -	kmem_cache_free(kvm_vcpu_cache, vcpu);
 -	return ERR_PTR(r);
  }
  
  int kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu)
diff --git a/arch/mips/kvm/mips.c b/arch/mips/kvm/mips.c
index 6d4b49925bf8..3b89b3f58223 100644
--- a/arch/mips/kvm/mips.c
+++ b/arch/mips/kvm/mips.c
@@ -280,6 +280,11 @@ static inline void dump_handler(const char *symbol, void *start, void *end)
 	pr_debug("\tEND(%s)\n", symbol);
 }
 
+int kvm_arch_vcpu_precreate(struct kvm *kvm, unsigned int id)
+{
+	return 0;
+}
+
 struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm, unsigned int id)
 {
 	int err, size;
diff --git a/arch/powerpc/kvm/powerpc.c b/arch/powerpc/kvm/powerpc.c
index 124aecce15bf..e96d4229525c 100644
--- a/arch/powerpc/kvm/powerpc.c
+++ b/arch/powerpc/kvm/powerpc.c
@@ -728,6 +728,11 @@ void kvm_arch_flush_shadow_memslot(struct kvm *kvm,
 	kvmppc_core_flush_memslot(kvm, slot);
 }
 
+int kvm_arch_vcpu_precreate(struct kvm *kvm, unsigned int id)
+{
+	return 0;
+}
+
 struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm, unsigned int id)
 {
 	struct kvm_vcpu *vcpu;
diff --git a/arch/s390/kvm/kvm-s390.c b/arch/s390/kvm/kvm-s390.c
index f6db0f1bc867..e58d2545f0e2 100644
--- a/arch/s390/kvm/kvm-s390.c
+++ b/arch/s390/kvm/kvm-s390.c
@@ -3038,15 +3038,19 @@ int kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu)
 	return rc;
 }
 
+int kvm_arch_vcpu_precreate(struct kvm *kvm, unsigned int id)
+{
+	if (!kvm_is_ucontrol(kvm) && !sca_can_add_vcpu(kvm, id))
+		return -EINVAL;
+	return 0;
+}
+
 struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm,
 				      unsigned int id)
 {
 	struct kvm_vcpu *vcpu;
 	struct sie_page *sie_page;
-	int rc = -EINVAL;
-
-	if (!kvm_is_ucontrol(kvm) && !sca_can_add_vcpu(kvm, id))
-		goto out;
+	int rc;
 
 	rc = -ENOMEM;
 
* Unmerged path arch/x86/kvm/x86.c
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index 76c481d92694..9fa4c1c4a8ce 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -877,6 +877,7 @@ void kvm_arch_sched_in(struct kvm_vcpu *vcpu, int cpu);
 
 void kvm_arch_vcpu_load(struct kvm_vcpu *vcpu, int cpu);
 void kvm_arch_vcpu_put(struct kvm_vcpu *vcpu);
+int kvm_arch_vcpu_precreate(struct kvm *kvm, unsigned int id);
 struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm, unsigned int id);
 int kvm_arch_vcpu_setup(struct kvm_vcpu *vcpu);
 void kvm_arch_vcpu_postcreate(struct kvm_vcpu *vcpu);
diff --git a/virt/kvm/arm/arm.c b/virt/kvm/arm/arm.c
index f41a18f358a9..4b9d09241d10 100644
--- a/virt/kvm/arm/arm.c
+++ b/virt/kvm/arm/arm.c
@@ -265,21 +265,22 @@ void kvm_arch_free_vm(struct kvm *kvm)
 		vfree(kvm);
 }
 
+int kvm_arch_vcpu_precreate(struct kvm *kvm, unsigned int id)
+{
+	if (irqchip_in_kernel(kvm) && vgic_initialized(kvm))
+		return -EBUSY;
+
+	if (id >= kvm->arch.max_vcpus)
+		return -EINVAL;
+
+	return 0;
+}
+
 struct kvm_vcpu *kvm_arch_vcpu_create(struct kvm *kvm, unsigned int id)
 {
 	int err;
 	struct kvm_vcpu *vcpu;
 
-	if (irqchip_in_kernel(kvm) && vgic_initialized(kvm)) {
-		err = -EBUSY;
-		goto out;
-	}
-
-	if (id >= kvm->arch.max_vcpus) {
-		err = -EINVAL;
-		goto out;
-	}
-
 	vcpu = kmem_cache_zalloc(kvm_vcpu_cache, GFP_KERNEL);
 	if (!vcpu) {
 		err = -ENOMEM;
diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index c6256c9afce6..5b6bad91d51a 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -2730,6 +2730,10 @@ static int kvm_vm_ioctl_create_vcpu(struct kvm *kvm, u32 id)
 	kvm->created_vcpus++;
 	mutex_unlock(&kvm->lock);
 
+	r = kvm_arch_vcpu_precreate(kvm, id);
+	if (r)
+		goto vcpu_decrement;
+
 	vcpu = kvm_arch_vcpu_create(kvm, id);
 	if (IS_ERR(vcpu)) {
 		r = PTR_ERR(vcpu);
