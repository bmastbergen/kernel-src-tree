x86: Fix kernel-doc atomic.h warnings

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Randy Dunlap <rdunlap@infradead.org>
commit 4331f4d5ada5684fc77fa16e3f6177f077c9e6ec
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/4331f4d5.failed

Fix kernel-doc warnings in arch/x86/include/asm/atomic.h that are caused by
having a #define macro between the kernel-doc notation and the function
name.  Fixed by moving the #define macro to after the function
implementation.

Make the same change for atomic64_{32,64}.h for consistency even though
there were no kernel-doc warnings found in these header files, but there
would be if they were used in generation of documentation.

Fixes these kernel-doc warnings:

../arch/x86/include/asm/atomic.h:84: warning: Excess function parameter 'i' description in 'arch_atomic_sub_and_test'
../arch/x86/include/asm/atomic.h:84: warning: Excess function parameter 'v' description in 'arch_atomic_sub_and_test'
../arch/x86/include/asm/atomic.h:96: warning: Excess function parameter 'v' description in 'arch_atomic_inc'
../arch/x86/include/asm/atomic.h:109: warning: Excess function parameter 'v' description in 'arch_atomic_dec'
../arch/x86/include/asm/atomic.h:124: warning: Excess function parameter 'v' description in 'arch_atomic_dec_and_test'
../arch/x86/include/asm/atomic.h:138: warning: Excess function parameter 'v' description in 'arch_atomic_inc_and_test'
../arch/x86/include/asm/atomic.h:153: warning: Excess function parameter 'i' description in 'arch_atomic_add_negative'
../arch/x86/include/asm/atomic.h:153: warning: Excess function parameter 'v' description in 'arch_atomic_add_negative'

Fixes: 18cc1814d4e7 ("atomics/treewide: Make test ops optional")
	Signed-off-by: Randy Dunlap <rdunlap@infradead.org>
	Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
	Cc: Mark Rutland <mark.rutland@arm.com>
Link: https://lkml.kernel.org/r/0a1e678d-c8c5-b32c-2640-ed4e94d399d2@infradead.org


(cherry picked from commit 4331f4d5ada5684fc77fa16e3f6177f077c9e6ec)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/x86/include/asm/atomic64_32.h
diff --cc arch/x86/include/asm/atomic64_32.h
index 92212bf0484f,6a5b0ec460da..000000000000
--- a/arch/x86/include/asm/atomic64_32.h
+++ b/arch/x86/include/asm/atomic64_32.h
@@@ -234,47 -223,8 +235,48 @@@ static inline void arch_atomic64_dec(at
  	__alternative_atomic64(dec, dec_return, /* no output */,
  			       "S" (v) : "memory", "eax", "ecx", "edx");
  }
+ #define arch_atomic64_dec arch_atomic64_dec
  
 +/**
 + * arch_atomic64_dec_and_test - decrement and test
 + * @v: pointer to type atomic64_t
 + *
 + * Atomically decrements @v by 1 and
 + * returns true if the result is 0, or false for all other
 + * cases.
 + */
 +static inline int arch_atomic64_dec_and_test(atomic64_t *v)
 +{
 +	return arch_atomic64_dec_return(v) == 0;
 +}
 +
 +/**
 + * atomic64_inc_and_test - increment and test
 + * @v: pointer to type atomic64_t
 + *
 + * Atomically increments @v by 1
 + * and returns true if the result is zero, or false for all
 + * other cases.
 + */
 +static inline int arch_atomic64_inc_and_test(atomic64_t *v)
 +{
 +	return arch_atomic64_inc_return(v) == 0;
 +}
 +
 +/**
 + * arch_atomic64_add_negative - add and test if negative
 + * @i: integer value to add
 + * @v: pointer to type atomic64_t
 + *
 + * Atomically adds @i to @v and returns true
 + * if the result is negative, or false when
 + * result is greater than or equal to zero.
 + */
 +static inline int arch_atomic64_add_negative(long long i, atomic64_t *v)
 +{
 +	return arch_atomic64_add_return(i, v) < 0;
 +}
 +
  /**
   * arch_atomic64_add_unless - add unless the number is a given value
   * @v: pointer of type atomic64_t
@@@ -295,7 -245,6 +297,10 @@@ static inline int arch_atomic64_add_unl
  	return (int)a;
  }
  
++<<<<<<< HEAD
 +
++=======
++>>>>>>> 4331f4d5ada5 (x86: Fix kernel-doc atomic.h warnings)
  static inline int arch_atomic64_inc_not_zero(atomic64_t *v)
  {
  	int r;
diff --git a/arch/x86/include/asm/atomic.h b/arch/x86/include/asm/atomic.h
index 7cf580771c57..1739b08fdca4 100644
--- a/arch/x86/include/asm/atomic.h
+++ b/arch/x86/include/asm/atomic.h
@@ -84,6 +84,7 @@ static __always_inline bool arch_atomic_sub_and_test(int i, atomic_t *v)
 {
 	return GEN_BINARY_RMWcc(LOCK_PREFIX "subl", v->counter, e, "er", i);
 }
+#define arch_atomic_sub_and_test arch_atomic_sub_and_test
 
 /**
  * arch_atomic_inc - increment atomic variable
@@ -96,6 +97,7 @@ static __always_inline void arch_atomic_inc(atomic_t *v)
 	asm volatile(LOCK_PREFIX "incl %0"
 		     : "+m" (v->counter) :: "memory");
 }
+#define arch_atomic_inc arch_atomic_inc
 
 /**
  * arch_atomic_dec - decrement atomic variable
@@ -108,6 +110,7 @@ static __always_inline void arch_atomic_dec(atomic_t *v)
 	asm volatile(LOCK_PREFIX "decl %0"
 		     : "+m" (v->counter) :: "memory");
 }
+#define arch_atomic_dec arch_atomic_dec
 
 /**
  * arch_atomic_dec_and_test - decrement and test
@@ -121,6 +124,7 @@ static __always_inline bool arch_atomic_dec_and_test(atomic_t *v)
 {
 	return GEN_UNARY_RMWcc(LOCK_PREFIX "decl", v->counter, e);
 }
+#define arch_atomic_dec_and_test arch_atomic_dec_and_test
 
 /**
  * arch_atomic_inc_and_test - increment and test
@@ -134,6 +138,7 @@ static __always_inline bool arch_atomic_inc_and_test(atomic_t *v)
 {
 	return GEN_UNARY_RMWcc(LOCK_PREFIX "incl", v->counter, e);
 }
+#define arch_atomic_inc_and_test arch_atomic_inc_and_test
 
 /**
  * arch_atomic_add_negative - add and test if negative
@@ -148,6 +153,7 @@ static __always_inline bool arch_atomic_add_negative(int i, atomic_t *v)
 {
 	return GEN_BINARY_RMWcc(LOCK_PREFIX "addl", v->counter, s, "er", i);
 }
+#define arch_atomic_add_negative arch_atomic_add_negative
 
 /**
  * arch_atomic_add_return - add integer and return
* Unmerged path arch/x86/include/asm/atomic64_32.h
diff --git a/arch/x86/include/asm/atomic64_64.h b/arch/x86/include/asm/atomic64_64.h
index c99f33271b13..651fb85035a6 100644
--- a/arch/x86/include/asm/atomic64_64.h
+++ b/arch/x86/include/asm/atomic64_64.h
@@ -75,6 +75,7 @@ static inline bool arch_atomic64_sub_and_test(long i, atomic64_t *v)
 {
 	return GEN_BINARY_RMWcc(LOCK_PREFIX "subq", v->counter, e, "er", i);
 }
+#define arch_atomic64_sub_and_test arch_atomic64_sub_and_test
 
 /**
  * arch_atomic64_inc - increment atomic64 variable
@@ -88,6 +89,7 @@ static __always_inline void arch_atomic64_inc(atomic64_t *v)
 		     : "=m" (v->counter)
 		     : "m" (v->counter) : "memory");
 }
+#define arch_atomic64_inc arch_atomic64_inc
 
 /**
  * arch_atomic64_dec - decrement atomic64 variable
@@ -101,6 +103,7 @@ static __always_inline void arch_atomic64_dec(atomic64_t *v)
 		     : "=m" (v->counter)
 		     : "m" (v->counter) : "memory");
 }
+#define arch_atomic64_dec arch_atomic64_dec
 
 /**
  * arch_atomic64_dec_and_test - decrement and test
@@ -114,6 +117,7 @@ static inline bool arch_atomic64_dec_and_test(atomic64_t *v)
 {
 	return GEN_UNARY_RMWcc(LOCK_PREFIX "decq", v->counter, e);
 }
+#define arch_atomic64_dec_and_test arch_atomic64_dec_and_test
 
 /**
  * arch_atomic64_inc_and_test - increment and test
@@ -127,6 +131,7 @@ static inline bool arch_atomic64_inc_and_test(atomic64_t *v)
 {
 	return GEN_UNARY_RMWcc(LOCK_PREFIX "incq", v->counter, e);
 }
+#define arch_atomic64_inc_and_test arch_atomic64_inc_and_test
 
 /**
  * arch_atomic64_add_negative - add and test if negative
@@ -141,6 +146,7 @@ static inline bool arch_atomic64_add_negative(long i, atomic64_t *v)
 {
 	return GEN_BINARY_RMWcc(LOCK_PREFIX "addq", v->counter, s, "er", i);
 }
+#define arch_atomic64_add_negative arch_atomic64_add_negative
 
 /**
  * arch_atomic64_add_return - add and return
