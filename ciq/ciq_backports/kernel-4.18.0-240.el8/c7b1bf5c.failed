blk-mq: Document the functions that iterate over requests

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Bart Van Assche <bvanassche@acm.org>
commit c7b1bf5cca76a31845a7d9e58cec7ff8f1cb0d4d
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/c7b1bf5c.failed

Make it easier to understand the purpose of the functions that iterate
over requests by documenting their purpose. Fix several minor spelling
and grammer mistakes in comments in these functions.

	Signed-off-by: Bart Van Assche <bvanassche@acm.org>
	Reviewed-by: Johannes Thumshirn <jthumshirn@suse.de>
	Cc: Christoph Hellwig <hch@lst.de>
	Cc: Ming Lei <ming.lei@redhat.com>
	Cc: Jianchao Wang <jianchao.w.wang@oracle.com>
	Cc: Hannes Reinecke <hare@suse.com>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit c7b1bf5cca76a31845a7d9e58cec7ff8f1cb0d4d)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	block/blk-mq-tag.c
diff --cc block/blk-mq-tag.c
index 61571c1b674d,40d1667bceac..000000000000
--- a/block/blk-mq-tag.c
+++ b/block/blk-mq-tag.c
@@@ -217,10 -232,10 +217,10 @@@ static bool bt_iter(struct sbitmap *bit
  
  	/*
  	 * We can hit rq == NULL here, because the tagging functions
- 	 * test and set the bit before assining ->rqs[].
+ 	 * test and set the bit before assigning ->rqs[].
  	 */
  	if (rq && rq->q == hctx->queue)
 -		iter_data->fn(hctx, rq, iter_data->data, reserved);
 +		return iter_data->fn(hctx, rq, iter_data->data, reserved);
  	return true;
  }
  
@@@ -299,37 -357,20 +342,54 @@@ void blk_mq_tagset_busy_iter(struct blk
  }
  EXPORT_SYMBOL(blk_mq_tagset_busy_iter);
  
++<<<<<<< HEAD
 +static bool blk_mq_tagset_count_completed_rqs(struct request *rq,
 +		void *data, bool reserved)
 +{
 +	unsigned *count = data;
 +
 +	if (blk_mq_request_completed(rq))
 +		(*count)++;
 +	return true;
 +}
 +
 +/**
 + * blk_mq_tagset_wait_completed_request - wait until all completed req's
 + * complete funtion is run
 + * @tagset:	Tag set to drain completed request
 + *
 + * Note: This function has to be run after all IO queues are shutdown
 + */
 +void blk_mq_tagset_wait_completed_request(struct blk_mq_tag_set *tagset)
 +{
 +	while (true) {
 +		unsigned count = 0;
 +
 +		blk_mq_tagset_busy_iter(tagset,
 +				blk_mq_tagset_count_completed_rqs, &count);
 +		if (!count)
 +			break;
 +		msleep(5);
 +	}
 +}
 +EXPORT_SYMBOL(blk_mq_tagset_wait_completed_request);
 +
++=======
+ /**
+  * blk_mq_queue_tag_busy_iter - iterate over all requests with a driver tag
+  * @q:		Request queue to examine.
+  * @fn:		Pointer to the function that will be called for each request
+  *		on @q. @fn will be called as follows: @fn(hctx, rq, @priv,
+  *		reserved) where rq is a pointer to a request and hctx points
+  *		to the hardware queue associated with the request. 'reserved'
+  *		indicates whether or not @rq is a reserved request.
+  * @priv:	Will be passed as third argument to @fn.
+  *
+  * Note: if @q->tag_set is shared with other request queues then @fn will be
+  * called for all requests on all queues that share that tag set and not only
+  * for requests associated with @q.
+  */
++>>>>>>> c7b1bf5cca76 (blk-mq: Document the functions that iterate over requests)
  void blk_mq_queue_tag_busy_iter(struct request_queue *q, busy_iter_fn *fn,
  		void *priv)
  {
@@@ -337,12 -378,17 +397,20 @@@
  	int i;
  
  	/*
++<<<<<<< HEAD
 +	 * __blk_mq_update_nr_hw_queues will update the nr_hw_queues and
 +	 * queue_hw_ctx after freeze the queue, so we use q_usage_counter
 +	 * to avoid race with it.
++=======
+ 	 * __blk_mq_update_nr_hw_queues() updates nr_hw_queues and queue_hw_ctx
+ 	 * while the queue is frozen. So we can use q_usage_counter to avoid
+ 	 * racing with it. __blk_mq_update_nr_hw_queues() uses
+ 	 * synchronize_rcu() to ensure this function left the critical section
+ 	 * below.
++>>>>>>> c7b1bf5cca76 (blk-mq: Document the functions that iterate over requests)
  	 */
 -	rcu_read_lock();
 -	if (percpu_ref_is_zero(&q->q_usage_counter)) {
 -		rcu_read_unlock();
 +	if (!percpu_ref_tryget(&q->q_usage_counter))
  		return;
 -	}
  
  	queue_for_each_hw_ctx(q, hctx, i) {
  		struct blk_mq_tags *tags = hctx->tags;
* Unmerged path block/blk-mq-tag.c
