eventfd: track eventfd_signal() recursion depth

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jens Axboe <axboe@kernel.dk>
commit b5e683d5cab8cd433b06ae178621f083cabd4f63
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/b5e683d5.failed

eventfd use cases from aio and io_uring can deadlock due to circular
or resursive calling, when eventfd_signal() tries to grab the waitqueue
lock. On top of that, it's also possible to construct notification
chains that are deep enough that we could blow the stack.

Add a percpu counter that tracks the percpu recursion depth, warn if we
exceed it. The counter is also exposed so that users of eventfd_signal()
can do the right thing if it's non-zero in the context where it is
called.

	Cc: stable@vger.kernel.org # 4.19+
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit b5e683d5cab8cd433b06ae178621f083cabd4f63)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/eventfd.c
diff --cc fs/eventfd.c
index 08d3bd602f73,78e41c7c3d05..000000000000
--- a/fs/eventfd.c
+++ b/fs/eventfd.c
@@@ -21,6 -22,11 +21,14 @@@
  #include <linux/eventfd.h>
  #include <linux/proc_fs.h>
  #include <linux/seq_file.h>
++<<<<<<< HEAD
++=======
+ #include <linux/idr.h>
+ 
+ DEFINE_PER_CPU(int, eventfd_wake_count);
+ 
+ static DEFINE_IDA(eventfd_ida);
++>>>>>>> b5e683d5cab8 (eventfd: track eventfd_signal() recursion depth)
  
  struct eventfd_ctx {
  	struct kref kref;
* Unmerged path fs/eventfd.c
diff --git a/include/linux/eventfd.h b/include/linux/eventfd.h
index ffcc7724ca21..dc4fd8a6644d 100644
--- a/include/linux/eventfd.h
+++ b/include/linux/eventfd.h
@@ -12,6 +12,8 @@
 #include <linux/fcntl.h>
 #include <linux/wait.h>
 #include <linux/err.h>
+#include <linux/percpu-defs.h>
+#include <linux/percpu.h>
 
 /*
  * CAREFUL: Check include/uapi/asm-generic/fcntl.h when defining
@@ -40,6 +42,13 @@ __u64 eventfd_signal(struct eventfd_ctx *ctx, __u64 n);
 int eventfd_ctx_remove_wait_queue(struct eventfd_ctx *ctx, wait_queue_entry_t *wait,
 				  __u64 *cnt);
 
+DECLARE_PER_CPU(int, eventfd_wake_count);
+
+static inline bool eventfd_signal_count(void)
+{
+	return this_cpu_read(eventfd_wake_count);
+}
+
 #else /* CONFIG_EVENTFD */
 
 /*
@@ -68,6 +77,11 @@ static inline int eventfd_ctx_remove_wait_queue(struct eventfd_ctx *ctx,
 	return -ENOSYS;
 }
 
+static inline bool eventfd_signal_count(void)
+{
+	return false;
+}
+
 #endif
 
 #endif /* _LINUX_EVENTFD_H */
