io_wq: add get/put_work handlers to io_wq_create()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jens Axboe <axboe@kernel.dk>
commit 7d7230652e7c788ef908536fd79f4cca077f269f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/7d723065.failed

For cancellation, we need to ensure that the work item stays valid for
as long as ->cur_work is valid. Right now we can't safely dereference
the work item even under the wqe->lock, because while the ->cur_work
pointer will remain valid, the work could be completing and be freed
in parallel.

Only invoke ->get/put_work() on items we know that the caller queued
themselves. Add IO_WQ_WORK_INTERNAL for io-wq to use, which is needed
when we're queueing a flush item, for instance.

	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit 7d7230652e7c788ef908536fd79f4cca077f269f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/io-wq.c
#	fs/io-wq.h
#	fs/io_uring.c
diff --cc fs/io_uring.c
index fca9cdc96d77,e1a3b8b667e0..000000000000
--- a/fs/io_uring.c
+++ b/fs/io_uring.c
@@@ -3173,26 -3883,13 +3187,36 @@@ static int io_sq_offload_start(struct i
  		goto err;
  	}
  
++<<<<<<< HEAD
 +	/* Do QD, or 2 * CPUS, whatever is smallest */
 +	ctx->sqo_wq[0] = alloc_workqueue("io_ring-wq",
 +			WQ_UNBOUND | WQ_FREEZABLE,
 +			min(ctx->sq_entries - 1, 2 * num_online_cpus()));
 +	if (!ctx->sqo_wq[0]) {
 +		ret = -ENOMEM;
 +		goto err;
 +	}
 +
 +	/*
 +	 * This is for buffered writes, where we want to limit the parallelism
 +	 * due to file locking in file systems. As "normal" buffered writes
 +	 * should parellelize on writeout quite nicely, limit us to having 2
 +	 * pending. This avoids massive contention on the inode when doing
 +	 * buffered async writes.
 +	 */
 +	ctx->sqo_wq[1] = alloc_workqueue("io_ring-write-wq",
 +						WQ_UNBOUND | WQ_FREEZABLE, 2);
 +	if (!ctx->sqo_wq[1]) {
 +		ret = -ENOMEM;
++=======
+ 	/* Do QD, or 4 * CPUS, whatever is smallest */
+ 	concurrency = min(ctx->sq_entries, 4 * num_online_cpus());
+ 	ctx->io_wq = io_wq_create(concurrency, ctx->sqo_mm, ctx->user,
+ 					io_get_work, io_put_work);
+ 	if (IS_ERR(ctx->io_wq)) {
+ 		ret = PTR_ERR(ctx->io_wq);
+ 		ctx->io_wq = NULL;
++>>>>>>> 7d7230652e7c (io_wq: add get/put_work handlers to io_wq_create())
  		goto err;
  	}
  
* Unmerged path fs/io-wq.c
* Unmerged path fs/io-wq.h
* Unmerged path fs/io-wq.c
* Unmerged path fs/io-wq.h
* Unmerged path fs/io_uring.c
