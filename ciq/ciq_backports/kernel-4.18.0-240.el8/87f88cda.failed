net/smc: rkey processing for a new link as SMC client

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Karsten Graul <kgraul@linux.ibm.com>
commit 87f88cda2128a72d79d4cc700729488af1081a06
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/87f88cda.failed

Part of the SMC client new link establishment process is the exchange of
rkeys for all used buffers.
Add new LLC message type ADD_LINK_CONTINUE which is used to exchange
rkeys of all current RMB buffers. Add functions to iterate over all
used RMB buffers of the link group, and implement the ADD_LINK_CONTINUE
processing.

	Signed-off-by: Karsten Graul <kgraul@linux.ibm.com>
	Reviewed-by: Ursula Braun <ubraun@linux.ibm.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 87f88cda2128a72d79d4cc700729488af1081a06)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/smc/smc_llc.c
diff --cc net/smc/smc_llc.c
index 4119cdb6b6bf,a06b618f172e..000000000000
--- a/net/smc/smc_llc.c
+++ b/net/smc/smc_llc.c
@@@ -400,60 -560,259 +418,285 @@@ static int smc_llc_send_message(struct 
  
  /********************************* receive ***********************************/
  
 -static int smc_llc_alloc_alt_link(struct smc_link_group *lgr,
 -				  enum smc_lgr_type lgr_new_t)
 +static void smc_llc_rx_confirm_link(struct smc_link *link,
 +				    struct smc_llc_msg_confirm_link *llc)
  {
++<<<<<<< HEAD
++=======
+ 	int i;
+ 
+ 	if (lgr->type == SMC_LGR_SYMMETRIC ||
+ 	    (lgr->type != SMC_LGR_SINGLE &&
+ 	     (lgr_new_t == SMC_LGR_ASYMMETRIC_LOCAL ||
+ 	      lgr_new_t == SMC_LGR_ASYMMETRIC_PEER)))
+ 		return -EMLINK;
+ 
+ 	if (lgr_new_t == SMC_LGR_ASYMMETRIC_LOCAL ||
+ 	    lgr_new_t == SMC_LGR_ASYMMETRIC_PEER) {
+ 		for (i = SMC_LINKS_PER_LGR_MAX - 1; i >= 0; i--)
+ 			if (lgr->lnk[i].state == SMC_LNK_UNUSED)
+ 				return i;
+ 	} else {
+ 		for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++)
+ 			if (lgr->lnk[i].state == SMC_LNK_UNUSED)
+ 				return i;
+ 	}
+ 	return -EMLINK;
+ }
+ 
+ /* return first buffer from any of the next buf lists */
+ static struct smc_buf_desc *_smc_llc_get_next_rmb(struct smc_link_group *lgr,
+ 						  int *buf_lst)
+ {
+ 	struct smc_buf_desc *buf_pos;
+ 
+ 	while (*buf_lst < SMC_RMBE_SIZES) {
+ 		buf_pos = list_first_entry_or_null(&lgr->rmbs[*buf_lst],
+ 						   struct smc_buf_desc, list);
+ 		if (buf_pos)
+ 			return buf_pos;
+ 		(*buf_lst)++;
+ 	}
+ 	return NULL;
+ }
+ 
+ /* return next rmb from buffer lists */
+ static struct smc_buf_desc *smc_llc_get_next_rmb(struct smc_link_group *lgr,
+ 						 int *buf_lst,
+ 						 struct smc_buf_desc *buf_pos)
+ {
+ 	struct smc_buf_desc *buf_next;
+ 
+ 	if (!buf_pos || list_is_last(&buf_pos->list, &lgr->rmbs[*buf_lst])) {
+ 		(*buf_lst)++;
+ 		return _smc_llc_get_next_rmb(lgr, buf_lst);
+ 	}
+ 	buf_next = list_next_entry(buf_pos, list);
+ 	return buf_next;
+ }
+ 
+ static struct smc_buf_desc *smc_llc_get_first_rmb(struct smc_link_group *lgr,
+ 						  int *buf_lst)
+ {
+ 	*buf_lst = 0;
+ 	return smc_llc_get_next_rmb(lgr, buf_lst, NULL);
+ }
+ 
+ /* send one add_link_continue msg */
+ static int smc_llc_add_link_cont(struct smc_link *link,
+ 				 struct smc_link *link_new, u8 *num_rkeys_todo,
+ 				 int *buf_lst, struct smc_buf_desc **buf_pos)
+ {
+ 	struct smc_llc_msg_add_link_cont *addc_llc;
+ 	struct smc_link_group *lgr = link->lgr;
+ 	int prim_lnk_idx, lnk_idx, i, rc;
+ 	struct smc_wr_tx_pend_priv *pend;
+ 	struct smc_wr_buf *wr_buf;
+ 	struct smc_buf_desc *rmb;
+ 	u8 n;
+ 
+ 	rc = smc_llc_add_pending_send(link, &wr_buf, &pend);
+ 	if (rc)
+ 		return rc;
+ 	addc_llc = (struct smc_llc_msg_add_link_cont *)wr_buf;
+ 	memset(addc_llc, 0, sizeof(*addc_llc));
+ 
+ 	prim_lnk_idx = link->link_idx;
+ 	lnk_idx = link_new->link_idx;
+ 	addc_llc->link_num = link_new->link_id;
+ 	addc_llc->num_rkeys = *num_rkeys_todo;
+ 	n = *num_rkeys_todo;
+ 	for (i = 0; i < min_t(u8, n, SMC_LLC_RKEYS_PER_CONT_MSG); i++) {
+ 		if (!*buf_pos) {
+ 			addc_llc->num_rkeys = addc_llc->num_rkeys -
+ 					      *num_rkeys_todo;
+ 			*num_rkeys_todo = 0;
+ 			break;
+ 		}
+ 		rmb = *buf_pos;
+ 
+ 		addc_llc->rt[i].rmb_key = htonl(rmb->mr_rx[prim_lnk_idx]->rkey);
+ 		addc_llc->rt[i].rmb_key_new = htonl(rmb->mr_rx[lnk_idx]->rkey);
+ 		addc_llc->rt[i].rmb_vaddr_new =
+ 			cpu_to_be64((u64)sg_dma_address(rmb->sgt[lnk_idx].sgl));
+ 
+ 		(*num_rkeys_todo)--;
+ 		*buf_pos = smc_llc_get_next_rmb(lgr, buf_lst, *buf_pos);
+ 		while (*buf_pos && !(*buf_pos)->used)
+ 			*buf_pos = smc_llc_get_next_rmb(lgr, buf_lst, *buf_pos);
+ 	}
+ 	addc_llc->hd.common.type = SMC_LLC_ADD_LINK_CONT;
+ 	addc_llc->hd.length = sizeof(struct smc_llc_msg_add_link_cont);
+ 	if (lgr->role == SMC_CLNT)
+ 		addc_llc->hd.flags |= SMC_LLC_FLAG_RESP;
+ 	return smc_wr_tx_send(link, pend);
+ }
+ 
+ static int smc_llc_cli_rkey_exchange(struct smc_link *link,
+ 				     struct smc_link *link_new)
+ {
+ 	struct smc_llc_msg_add_link_cont *addc_llc;
+ 	struct smc_link_group *lgr = link->lgr;
+ 	u8 max, num_rkeys_send, num_rkeys_recv;
+ 	struct smc_llc_qentry *qentry;
+ 	struct smc_buf_desc *buf_pos;
+ 	int buf_lst;
+ 	int rc = 0;
+ 	int i;
+ 
+ 	mutex_lock(&lgr->rmbs_lock);
+ 	num_rkeys_send = lgr->conns_num;
+ 	buf_pos = smc_llc_get_first_rmb(lgr, &buf_lst);
+ 	do {
+ 		qentry = smc_llc_wait(lgr, NULL, SMC_LLC_WAIT_TIME,
+ 				      SMC_LLC_ADD_LINK_CONT);
+ 		if (!qentry) {
+ 			rc = -ETIMEDOUT;
+ 			break;
+ 		}
+ 		addc_llc = &qentry->msg.add_link_cont;
+ 		num_rkeys_recv = addc_llc->num_rkeys;
+ 		max = min_t(u8, num_rkeys_recv, SMC_LLC_RKEYS_PER_CONT_MSG);
+ 		for (i = 0; i < max; i++) {
+ 			smc_rtoken_set(lgr, link->link_idx, link_new->link_idx,
+ 				       addc_llc->rt[i].rmb_key,
+ 				       addc_llc->rt[i].rmb_vaddr_new,
+ 				       addc_llc->rt[i].rmb_key_new);
+ 			num_rkeys_recv--;
+ 		}
+ 		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 		rc = smc_llc_add_link_cont(link, link_new, &num_rkeys_send,
+ 					   &buf_lst, &buf_pos);
+ 		if (rc)
+ 			break;
+ 	} while (num_rkeys_send || num_rkeys_recv);
+ 
+ 	mutex_unlock(&lgr->rmbs_lock);
+ 	return rc;
+ }
+ 
+ /* prepare and send an add link reject response */
+ static int smc_llc_cli_add_link_reject(struct smc_llc_qentry *qentry)
+ {
+ 	qentry->msg.raw.hdr.flags |= SMC_LLC_FLAG_RESP;
+ 	qentry->msg.raw.hdr.flags |= SMC_LLC_FLAG_ADD_LNK_REJ;
+ 	qentry->msg.raw.hdr.add_link_rej_rsn = SMC_LLC_REJ_RSN_NO_ALT_PATH;
+ 	return smc_llc_send_message(qentry->link, &qentry->msg);
+ }
+ 
+ static void smc_llc_save_add_link_info(struct smc_link *link,
+ 				       struct smc_llc_msg_add_link *add_llc)
+ {
+ 	link->peer_qpn = ntoh24(add_llc->sender_qp_num);
+ 	memcpy(link->peer_gid, add_llc->sender_gid, SMC_GID_SIZE);
+ 	memcpy(link->peer_mac, add_llc->sender_mac, ETH_ALEN);
+ 	link->peer_psn = ntoh24(add_llc->initial_psn);
+ 	link->peer_mtu = add_llc->qp_mtu;
+ }
+ 
+ /* as an SMC client, process an add link request */
+ int smc_llc_cli_add_link(struct smc_link *link, struct smc_llc_qentry *qentry)
+ {
+ 	struct smc_llc_msg_add_link *llc = &qentry->msg.add_link;
+ 	enum smc_lgr_type lgr_new_t = SMC_LGR_SYMMETRIC;
++>>>>>>> 87f88cda2128 (net/smc: rkey processing for a new link as SMC client)
  	struct smc_link_group *lgr = smc_get_lgr(link);
 -	struct smc_link *lnk_new = NULL;
 -	struct smc_init_info ini;
 -	int lnk_idx, rc = 0;
 -
 -	ini.vlan_id = lgr->vlan_id;
 -	smc_pnet_find_alt_roce(lgr, &ini, link->smcibdev);
 -	if (!memcmp(llc->sender_gid, link->peer_gid, SMC_GID_SIZE) &&
 -	    !memcmp(llc->sender_mac, link->peer_mac, ETH_ALEN)) {
 -		if (!ini.ib_dev)
 -			goto out_reject;
 -		lgr_new_t = SMC_LGR_ASYMMETRIC_PEER;
 +	int conf_rc;
 +
 +	/* RMBE eyecatchers are not supported */
 +	if (llc->hd.flags & SMC_LLC_FLAG_NO_RMBE_EYEC)
 +		conf_rc = 0;
 +	else
 +		conf_rc = ENOTSUPP;
 +
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (lgr->role == SMC_SERV &&
 +		    link->state == SMC_LNK_ACTIVATING) {
 +			link->llc_confirm_resp_rc = conf_rc;
 +			complete(&link->llc_confirm_resp);
 +		}
 +	} else {
 +		if (lgr->role == SMC_CLNT &&
 +		    link->state == SMC_LNK_ACTIVATING) {
 +			link->llc_confirm_rc = conf_rc;
 +			link->link_id = llc->link_num;
 +			complete(&link->llc_confirm);
 +		}
  	}
++<<<<<<< HEAD
++=======
+ 	if (!ini.ib_dev) {
+ 		lgr_new_t = SMC_LGR_ASYMMETRIC_LOCAL;
+ 		ini.ib_dev = link->smcibdev;
+ 		ini.ib_port = link->ibport;
+ 	}
+ 	lnk_idx = smc_llc_alloc_alt_link(lgr, lgr_new_t);
+ 	if (lnk_idx < 0)
+ 		goto out_reject;
+ 	lnk_new = &lgr->lnk[lnk_idx];
+ 	rc = smcr_link_init(lgr, lnk_new, lnk_idx, &ini);
+ 	if (rc)
+ 		goto out_reject;
+ 	smc_llc_save_add_link_info(lnk_new, llc);
+ 	lnk_new->link_id = llc->link_num;
+ 
+ 	rc = smc_ib_ready_link(lnk_new);
+ 	if (rc)
+ 		goto out_clear_lnk;
+ 
+ 	rc = smcr_buf_map_lgr(lnk_new);
+ 	if (rc)
+ 		goto out_clear_lnk;
+ 
+ 	rc = smc_llc_send_add_link(link,
+ 				   lnk_new->smcibdev->mac[ini.ib_port - 1],
+ 				   lnk_new->gid, lnk_new, SMC_LLC_RESP);
+ 	if (rc)
+ 		goto out_clear_lnk;
+ 	rc = smc_llc_cli_rkey_exchange(link, lnk_new);
+ 	if (rc) {
+ 		rc = 0;
+ 		goto out_clear_lnk;
+ 	}
+ 	/* tbd: rc = smc_llc_cli_conf_link(link, &ini, lnk_new, lgr_new_t); */
+ 	if (!rc)
+ 		goto out;
+ out_clear_lnk:
+ 	smcr_link_clear(lnk_new);
+ out_reject:
+ 	smc_llc_cli_add_link_reject(qentry);
+ out:
+ 	kfree(qentry);
+ 	return rc;
++>>>>>>> 87f88cda2128 (net/smc: rkey processing for a new link as SMC client)
  }
  
 -/* worker to process an add link message */
 -static void smc_llc_add_link_work(struct work_struct *work)
 +static void smc_llc_rx_add_link(struct smc_link *link,
 +				struct smc_llc_msg_add_link *llc)
  {
 -	struct smc_link_group *lgr = container_of(work, struct smc_link_group,
 -						  llc_add_link_work);
 +	struct smc_link_group *lgr = smc_get_lgr(link);
  
 -	if (list_empty(&lgr->list)) {
 -		/* link group is terminating */
 -		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
 -		goto out;
 -	}
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (link->state == SMC_LNK_ACTIVATING)
 +			complete(&link->llc_add_resp);
 +	} else {
 +		if (link->state == SMC_LNK_ACTIVATING) {
 +			complete(&link->llc_add);
 +			return;
 +		}
  
 -	/* tbd: call smc_llc_process_cli_add_link(lgr); */
 -	/* tbd: call smc_llc_process_srv_add_link(lgr); */
 -out:
 -	smc_llc_flow_stop(lgr, &lgr->llc_flow_lcl);
 +		if (lgr->role == SMC_SERV) {
 +			smc_llc_prep_add_link(llc, link,
 +					link->smcibdev->mac[link->ibport - 1],
 +					link->gid, SMC_LLC_REQ);
 +
 +		} else {
 +			smc_llc_prep_add_link(llc, link,
 +					link->smcibdev->mac[link->ibport - 1],
 +					link->gid, SMC_LLC_RESP);
 +		}
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +	}
  }
  
  static void smc_llc_rx_delete_link(struct smc_link *link,
@@@ -461,98 -820,254 +704,200 @@@
  {
  	struct smc_link_group *lgr = smc_get_lgr(link);
  
 -	smc_lgr_forget(lgr);
 -	if (lgr->role == SMC_SERV) {
 -		/* client asks to delete this link, send request */
 -		smc_llc_send_delete_link(link, 0, SMC_LLC_REQ, true,
 -					 SMC_LLC_DEL_PROG_INIT_TERM);
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (lgr->role == SMC_SERV)
 +			smc_lgr_schedule_free_work_fast(lgr);
  	} else {
 -		/* server requests to delete this link, send response */
 -		smc_llc_send_delete_link(link, 0, SMC_LLC_RESP, true,
 -					 SMC_LLC_DEL_PROG_INIT_TERM);
 +		smc_lgr_forget(lgr);
 +		smc_llc_link_deleting(link);
 +		if (lgr->role == SMC_SERV) {
 +			/* client asks to delete this link, send request */
 +			smc_llc_prep_delete_link(llc, link, SMC_LLC_REQ, true);
 +		} else {
 +			/* server requests to delete this link, send response */
 +			smc_llc_prep_delete_link(llc, link, SMC_LLC_RESP, true);
 +		}
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +		smc_lgr_terminate_sched(lgr);
  	}
 -	smcr_link_down_cond(link);
  }
  
 -/* process a confirm_rkey request from peer, remote flow */
 -static void smc_llc_rmt_conf_rkey(struct smc_link_group *lgr)
 +static void smc_llc_rx_test_link(struct smc_link *link,
 +				 struct smc_llc_msg_test_link *llc)
  {
 -	struct smc_llc_msg_confirm_rkey *llc;
 -	struct smc_llc_qentry *qentry;
 -	struct smc_link *link;
 -	int num_entries;
 -	int rk_idx;
 -	int i;
 -
 -	qentry = lgr->llc_flow_rmt.qentry;
 -	llc = &qentry->msg.confirm_rkey;
 -	link = qentry->link;
 -
 -	num_entries = llc->rtoken[0].num_rkeys;
 -	/* first rkey entry is for receiving link */
 -	rk_idx = smc_rtoken_add(link,
 -				llc->rtoken[0].rmb_vaddr,
 -				llc->rtoken[0].rmb_key);
 -	if (rk_idx < 0)
 -		goto out_err;
 -
 -	for (i = 1; i <= min_t(u8, num_entries, SMC_LLC_RKEYS_PER_MSG - 1); i++)
 -		smc_rtoken_set2(lgr, rk_idx, llc->rtoken[i].link_id,
 -				llc->rtoken[i].rmb_vaddr,
 -				llc->rtoken[i].rmb_key);
 -	/* max links is 3 so there is no need to support conf_rkey_cont msgs */
 -	goto out;
 -out_err:
 -	llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 -	llc->hd.flags |= SMC_LLC_FLAG_RKEY_RETRY;
 -out:
 -	llc->hd.flags |= SMC_LLC_FLAG_RESP;
 -	smc_llc_send_message(link, &qentry->msg);
 -	smc_llc_flow_qentry_del(&lgr->llc_flow_rmt);
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (link->state == SMC_LNK_ACTIVE)
 +			complete(&link->llc_testlink_resp);
 +	} else {
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +	}
  }
  
 -/* process a delete_rkey request from peer, remote flow */
 -static void smc_llc_rmt_delete_rkey(struct smc_link_group *lgr)
 +static void smc_llc_rx_confirm_rkey(struct smc_link *link,
 +				    struct smc_llc_msg_confirm_rkey *llc)
  {
 -	struct smc_llc_msg_delete_rkey *llc;
 -	struct smc_llc_qentry *qentry;
 -	struct smc_link *link;
 -	u8 err_mask = 0;
 -	int i, max;
 +	int rc;
  
 -	qentry = lgr->llc_flow_rmt.qentry;
 -	llc = &qentry->msg.delete_rkey;
 -	link = qentry->link;
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		link->llc_confirm_rkey_rc = llc->hd.flags &
 +					    SMC_LLC_FLAG_RKEY_NEG;
 +		complete(&link->llc_confirm_rkey);
 +	} else {
 +		rc = smc_rtoken_add(link,
 +				    llc->rtoken[0].rmb_vaddr,
 +				    llc->rtoken[0].rmb_key);
  
 -	max = min_t(u8, llc->num_rkeys, SMC_LLC_DEL_RKEY_MAX);
 -	for (i = 0; i < max; i++) {
 -		if (smc_rtoken_delete(link, llc->rkey[i]))
 -			err_mask |= 1 << (SMC_LLC_DEL_RKEY_MAX - 1 - i);
 -	}
 -	if (err_mask) {
 -		llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 -		llc->err_mask = err_mask;
 +		/* ignore rtokens for other links, we have only one link */
 +
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		if (rc < 0)
 +			llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
  	}
 -	llc->hd.flags |= SMC_LLC_FLAG_RESP;
 -	smc_llc_send_message(link, &qentry->msg);
 -	smc_llc_flow_qentry_del(&lgr->llc_flow_rmt);
  }
  
 -/* flush the llc event queue */
 -static void smc_llc_event_flush(struct smc_link_group *lgr)
 +static void smc_llc_rx_confirm_rkey_cont(struct smc_link *link,
 +				      struct smc_llc_msg_confirm_rkey_cont *llc)
  {
 -	struct smc_llc_qentry *qentry, *q;
 -
 -	spin_lock_bh(&lgr->llc_event_q_lock);
 -	list_for_each_entry_safe(qentry, q, &lgr->llc_event_q, list) {
 -		list_del_init(&qentry->list);
 -		kfree(qentry);
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		/* unused as long as we don't send this type of msg */
 +	} else {
 +		/* ignore rtokens for other links, we have only one link */
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
  	}
 -	spin_unlock_bh(&lgr->llc_event_q_lock);
  }
  
 -static void smc_llc_event_handler(struct smc_llc_qentry *qentry)
 +static void smc_llc_rx_delete_rkey(struct smc_link *link,
 +				   struct smc_llc_msg_delete_rkey *llc)
  {
 -	union smc_llc_msg *llc = &qentry->msg;
 -	struct smc_link *link = qentry->link;
 -	struct smc_link_group *lgr = link->lgr;
 -
 -	if (!smc_link_usable(link))
 -		goto out;
 +	u8 err_mask = 0;
 +	int i, max;
  
 -	switch (llc->raw.hdr.common.type) {
 -	case SMC_LLC_TEST_LINK:
 -		llc->test_link.hd.flags |= SMC_LLC_FLAG_RESP;
 -		smc_llc_send_message(link, llc);
 -		break;
 -	case SMC_LLC_ADD_LINK:
 -		if (list_empty(&lgr->list))
 -			goto out;	/* lgr is terminating */
 -		if (lgr->role == SMC_CLNT) {
 -			if (lgr->llc_flow_lcl.type == SMC_LLC_FLOW_ADD_LINK) {
 -				/* a flow is waiting for this message */
 -				smc_llc_flow_qentry_set(&lgr->llc_flow_lcl,
 -							qentry);
 -				wake_up_interruptible(&lgr->llc_waiter);
 -			} else if (smc_llc_flow_start(&lgr->llc_flow_lcl,
 -						      qentry)) {
 -				schedule_work(&lgr->llc_add_link_work);
 -			}
 -		} else if (smc_llc_flow_start(&lgr->llc_flow_lcl, qentry)) {
 -			/* as smc server, handle client suggestion */
 -			schedule_work(&lgr->llc_add_link_work);
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		link->llc_delete_rkey_rc = llc->hd.flags &
 +					    SMC_LLC_FLAG_RKEY_NEG;
 +		complete(&link->llc_delete_rkey);
 +	} else {
 +		max = min_t(u8, llc->num_rkeys, SMC_LLC_DEL_RKEY_MAX);
 +		for (i = 0; i < max; i++) {
 +			if (smc_rtoken_delete(link, llc->rkey[i]))
 +				err_mask |= 1 << (SMC_LLC_DEL_RKEY_MAX - 1 - i);
  		}
++<<<<<<< HEAD
 +
 +		if (err_mask) {
 +			llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 +			llc->err_mask = err_mask;
++=======
+ 		return;
+ 	case SMC_LLC_CONFIRM_LINK:
+ 	case SMC_LLC_ADD_LINK_CONT:
+ 		if (lgr->llc_flow_lcl.type != SMC_LLC_FLOW_NONE) {
+ 			/* a flow is waiting for this message */
+ 			smc_llc_flow_qentry_set(&lgr->llc_flow_lcl, qentry);
+ 			wake_up_interruptible(&lgr->llc_waiter);
+ 			return;
++>>>>>>> 87f88cda2128 (net/smc: rkey processing for a new link as SMC client)
  		}
 -		break;
 -	case SMC_LLC_DELETE_LINK:
 -		smc_llc_rx_delete_link(link, &llc->delete_link);
 -		break;
 -	case SMC_LLC_CONFIRM_RKEY:
 -		/* new request from remote, assign to remote flow */
 -		if (smc_llc_flow_start(&lgr->llc_flow_rmt, qentry)) {
 -			/* process here, does not wait for more llc msgs */
 -			smc_llc_rmt_conf_rkey(lgr);
 -			smc_llc_flow_stop(lgr, &lgr->llc_flow_rmt);
 -		}
 -		return;
 -	case SMC_LLC_CONFIRM_RKEY_CONT:
 -		/* not used because max links is 3, and 3 rkeys fit into
 -		 * one CONFIRM_RKEY message
 -		 */
 -		break;
 -	case SMC_LLC_DELETE_RKEY:
 -		/* new request from remote, assign to remote flow */
 -		if (smc_llc_flow_start(&lgr->llc_flow_rmt, qentry)) {
 -			/* process here, does not wait for more llc msgs */
 -			smc_llc_rmt_delete_rkey(lgr);
 -			smc_llc_flow_stop(lgr, &lgr->llc_flow_rmt);
 -		}
 -		return;
 +
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
  	}
 -out:
 -	kfree(qentry);
  }
  
++<<<<<<< HEAD
++=======
+ /* worker to process llc messages on the event queue */
+ static void smc_llc_event_work(struct work_struct *work)
+ {
+ 	struct smc_link_group *lgr = container_of(work, struct smc_link_group,
+ 						  llc_event_work);
+ 	struct smc_llc_qentry *qentry;
+ 
+ 	if (!lgr->llc_flow_lcl.type && lgr->delayed_event) {
+ 		if (smc_link_usable(lgr->delayed_event->link)) {
+ 			smc_llc_event_handler(lgr->delayed_event);
+ 		} else {
+ 			qentry = lgr->delayed_event;
+ 			lgr->delayed_event = NULL;
+ 			kfree(qentry);
+ 		}
+ 	}
+ 
+ again:
+ 	spin_lock_bh(&lgr->llc_event_q_lock);
+ 	if (!list_empty(&lgr->llc_event_q)) {
+ 		qentry = list_first_entry(&lgr->llc_event_q,
+ 					  struct smc_llc_qentry, list);
+ 		list_del_init(&qentry->list);
+ 		spin_unlock_bh(&lgr->llc_event_q_lock);
+ 		smc_llc_event_handler(qentry);
+ 		goto again;
+ 	}
+ 	spin_unlock_bh(&lgr->llc_event_q_lock);
+ }
+ 
+ /* process llc responses in tasklet context */
+ static void smc_llc_rx_response(struct smc_link *link,
+ 				struct smc_llc_qentry *qentry)
+ {
+ 	u8 llc_type = qentry->msg.raw.hdr.common.type;
+ 
+ 	switch (llc_type) {
+ 	case SMC_LLC_TEST_LINK:
+ 		if (link->state == SMC_LNK_ACTIVE)
+ 			complete(&link->llc_testlink_resp);
+ 		break;
+ 	case SMC_LLC_ADD_LINK:
+ 	case SMC_LLC_CONFIRM_LINK:
+ 	case SMC_LLC_ADD_LINK_CONT:
+ 	case SMC_LLC_CONFIRM_RKEY:
+ 	case SMC_LLC_DELETE_RKEY:
+ 		/* assign responses to the local flow, we requested them */
+ 		smc_llc_flow_qentry_set(&link->lgr->llc_flow_lcl, qentry);
+ 		wake_up_interruptible(&link->lgr->llc_waiter);
+ 		return;
+ 	case SMC_LLC_DELETE_LINK:
+ 		if (link->lgr->role == SMC_SERV)
+ 			smc_lgr_schedule_free_work_fast(link->lgr);
+ 		break;
+ 	case SMC_LLC_CONFIRM_RKEY_CONT:
+ 		/* not used because max links is 3 */
+ 		break;
+ 	}
+ 	kfree(qentry);
+ }
+ 
+ static void smc_llc_enqueue(struct smc_link *link, union smc_llc_msg *llc)
+ {
+ 	struct smc_link_group *lgr = link->lgr;
+ 	struct smc_llc_qentry *qentry;
+ 	unsigned long flags;
+ 
+ 	qentry = kmalloc(sizeof(*qentry), GFP_ATOMIC);
+ 	if (!qentry)
+ 		return;
+ 	qentry->link = link;
+ 	INIT_LIST_HEAD(&qentry->list);
+ 	memcpy(&qentry->msg, llc, sizeof(union smc_llc_msg));
+ 
+ 	/* process responses immediately */
+ 	if (llc->raw.hdr.flags & SMC_LLC_FLAG_RESP) {
+ 		smc_llc_rx_response(link, qentry);
+ 		return;
+ 	}
+ 
+ 	/* add requests to event queue */
+ 	spin_lock_irqsave(&lgr->llc_event_q_lock, flags);
+ 	list_add_tail(&qentry->list, &lgr->llc_event_q);
+ 	spin_unlock_irqrestore(&lgr->llc_event_q_lock, flags);
+ 	schedule_work(&link->lgr->llc_event_work);
+ }
+ 
+ /* copy received msg and add it to the event queue */
++>>>>>>> 87f88cda2128 (net/smc: rkey processing for a new link as SMC client)
  static void smc_llc_rx_handler(struct ib_wc *wc, void *buf)
  {
  	struct smc_link *link = (struct smc_link *)wc->qp->qp_context;
* Unmerged path net/smc/smc_llc.c
diff --git a/net/smc/smc_llc.h b/net/smc/smc_llc.h
index 461c0c3ef76e..03f7c52f6176 100644
--- a/net/smc/smc_llc.h
+++ b/net/smc/smc_llc.h
@@ -28,6 +28,7 @@ enum smc_llc_reqresp {
 enum smc_llc_msg_type {
 	SMC_LLC_CONFIRM_LINK		= 0x01,
 	SMC_LLC_ADD_LINK		= 0x02,
+	SMC_LLC_ADD_LINK_CONT		= 0x03,
 	SMC_LLC_DELETE_LINK		= 0x04,
 	SMC_LLC_CONFIRM_RKEY		= 0x06,
 	SMC_LLC_TEST_LINK		= 0x07,
