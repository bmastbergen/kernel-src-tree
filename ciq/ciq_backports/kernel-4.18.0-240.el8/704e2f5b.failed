perf stat: Use affinity for enabling/disabling events

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Andi Kleen <ak@linux.intel.com>
commit 704e2f5b700da4c912635cf161c3e982737eb89e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/704e2f5b.failed

Restructure event enabling/disabling to use affinity, which
minimizes the number of IPIs needed.

Before on a large test case with 94 CPUs:

  % time     seconds  usecs/call     calls    errors syscall
  ------ ----------- ----------- --------- --------- ----------------
   54.65    1.899986          22     84812       660 ioctl

after:

   39.21    0.930451          10     84796       644 ioctl

	Signed-off-by: Andi Kleen <ak@linux.intel.com>
	Acked-by: Jiri Olsa <jolsa@kernel.org>
Link: http://lore.kernel.org/lkml/20191121001522.180827-13-andi@firstfloor.org
	Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
(cherry picked from commit 704e2f5b700da4c912635cf161c3e982737eb89e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	tools/perf/util/evlist.c
diff --cc tools/perf/util/evlist.c
index 29a998d183ce,1548237b6558..000000000000
--- a/tools/perf/util/evlist.c
+++ b/tools/perf/util/evlist.c
@@@ -338,36 -334,102 +338,120 @@@ int perf_evlist__add_newtp(struct perf_
  	return 0;
  }
  
 -static int perf_evlist__nr_threads(struct evlist *evlist,
 -				   struct evsel *evsel)
 +static int perf_evlist__nr_threads(struct perf_evlist *evlist,
 +				   struct perf_evsel *evsel)
  {
 -	if (evsel->core.system_wide)
 +	if (evsel->system_wide)
  		return 1;
  	else
 -		return perf_thread_map__nr(evlist->core.threads);
 +		return thread_map__nr(evlist->threads);
  }
  
 -void evlist__cpu_iter_start(struct evlist *evlist)
 +void perf_evlist__disable(struct perf_evlist *evlist)
  {
++<<<<<<< HEAD
 +	struct perf_evsel *pos;
++=======
+ 	struct evsel *pos;
  
+ 	/*
+ 	 * Reset the per evsel cpu_iter. This is needed because
+ 	 * each evsel's cpumap may have a different index space,
+ 	 * and some operations need the index to modify
+ 	 * the FD xyarray (e.g. open, close)
+ 	 */
+ 	evlist__for_each_entry(evlist, pos)
+ 		pos->cpu_iter = 0;
+ }
+ 
+ bool evsel__cpu_iter_skip_no_inc(struct evsel *ev, int cpu)
+ {
+ 	if (ev->cpu_iter >= ev->core.cpus->nr)
+ 		return true;
+ 	if (cpu >= 0 && ev->core.cpus->map[ev->cpu_iter] != cpu)
+ 		return true;
+ 	return false;
+ }
+ 
+ bool evsel__cpu_iter_skip(struct evsel *ev, int cpu)
+ {
+ 	if (!evsel__cpu_iter_skip_no_inc(ev, cpu)) {
+ 		ev->cpu_iter++;
+ 		return false;
+ 	}
+ 	return true;
+ }
+ 
+ void evlist__disable(struct evlist *evlist)
+ {
+ 	struct evsel *pos;
+ 	struct affinity affinity;
+ 	int cpu, i;
++>>>>>>> 704e2f5b700d (perf stat: Use affinity for enabling/disabling events)
+ 
+ 	if (affinity__setup(&affinity) < 0)
+ 		return;
+ 
+ 	evlist__for_each_cpu(evlist, i, cpu) {
+ 		affinity__set(&affinity, cpu);
+ 
+ 		evlist__for_each_entry(evlist, pos) {
+ 			if (evsel__cpu_iter_skip(pos, cpu))
+ 				continue;
+ 			if (pos->disabled || !perf_evsel__is_group_leader(pos) || !pos->core.fd)
+ 				continue;
+ 			evsel__disable_cpu(pos, pos->cpu_iter - 1);
+ 		}
+ 	}
+ 	affinity__cleanup(&affinity);
  	evlist__for_each_entry(evlist, pos) {
++<<<<<<< HEAD
 +		if (pos->disabled || !perf_evsel__is_group_leader(pos) || !pos->fd)
 +			continue;
 +		perf_evsel__disable(pos);
++=======
+ 		if (!perf_evsel__is_group_leader(pos) || !pos->core.fd)
+ 			continue;
+ 		pos->disabled = true;
++>>>>>>> 704e2f5b700d (perf stat: Use affinity for enabling/disabling events)
  	}
  
  	evlist->enabled = false;
  }
  
 -void evlist__enable(struct evlist *evlist)
 +void perf_evlist__enable(struct perf_evlist *evlist)
  {
++<<<<<<< HEAD
 +	struct perf_evsel *pos;
++=======
+ 	struct evsel *pos;
+ 	struct affinity affinity;
+ 	int cpu, i;
++>>>>>>> 704e2f5b700d (perf stat: Use affinity for enabling/disabling events)
+ 
+ 	if (affinity__setup(&affinity) < 0)
+ 		return;
  
+ 	evlist__for_each_cpu(evlist, i, cpu) {
+ 		affinity__set(&affinity, cpu);
+ 
+ 		evlist__for_each_entry(evlist, pos) {
+ 			if (evsel__cpu_iter_skip(pos, cpu))
+ 				continue;
+ 			if (!perf_evsel__is_group_leader(pos) || !pos->core.fd)
+ 				continue;
+ 			evsel__enable_cpu(pos, pos->cpu_iter - 1);
+ 		}
+ 	}
+ 	affinity__cleanup(&affinity);
  	evlist__for_each_entry(evlist, pos) {
 -		if (!perf_evsel__is_group_leader(pos) || !pos->core.fd)
 +		if (!perf_evsel__is_group_leader(pos) || !pos->fd)
  			continue;
++<<<<<<< HEAD
 +		perf_evsel__enable(pos);
++=======
+ 		pos->disabled = false;
++>>>>>>> 704e2f5b700d (perf stat: Use affinity for enabling/disabling events)
  	}
  
  	evlist->enabled = true;
* Unmerged path tools/perf/util/evlist.c
