KVM: Move vcpu->run page allocation out of kvm_vcpu_init()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Sean Christopherson <sean.j.christopherson@intel.com>
commit 8bd826d629d6ff4a4e647079db15d64d06346004
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/8bd826d6.failed

Open code the allocation and freeing of the vcpu->run page in
kvm_vm_ioctl_create_vcpu() and kvm_vcpu_destroy() respectively.  Doing
so allows kvm_vcpu_init() to be a pure init function and eliminates
kvm_vcpu_uninit() entirely.

	Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
	Reviewed-by: Cornelia Huck <cohuck@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit 8bd826d629d6ff4a4e647079db15d64d06346004)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	virt/kvm/kvm_main.c
diff --cc virt/kvm/kvm_main.c
index c6256c9afce6,d21cf86176f0..000000000000
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@@ -324,11 -321,8 +324,16 @@@ void kvm_reload_remote_mmus(struct kvm 
  	kvm_make_all_cpus_request(kvm, KVM_REQ_MMU_RELOAD);
  }
  
++<<<<<<< HEAD
 +int kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id)
 +{
 +	struct page *page;
 +	int r;
 +
++=======
+ static void kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id)
+ {
++>>>>>>> 8bd826d629d6 (KVM: Move vcpu->run page allocation out of kvm_vcpu_init())
  	mutex_init(&vcpu->mutex);
  	vcpu->cpu = -1;
  	vcpu->kvm = kvm;
@@@ -340,42 -334,28 +345,55 @@@
  	vcpu->pre_pcpu = -1;
  	INIT_LIST_HEAD(&vcpu->blocked_vcpu_list);
  
++<<<<<<< HEAD
 +	page = alloc_page(GFP_KERNEL | __GFP_ZERO);
 +	if (!page) {
 +		r = -ENOMEM;
 +		goto fail;
 +	}
 +	vcpu->run = page_address(page);
 +
++=======
++>>>>>>> 8bd826d629d6 (KVM: Move vcpu->run page allocation out of kvm_vcpu_init())
  	kvm_vcpu_set_in_spin_loop(vcpu, false);
  	kvm_vcpu_set_dy_eligible(vcpu, false);
  	vcpu->preempted = false;
  	vcpu->ready = false;
++<<<<<<< HEAD
 +
 +	r = kvm_arch_vcpu_init(vcpu);
 +	if (r < 0)
 +		goto fail_free_run;
 +	return 0;
 +
 +fail_free_run:
 +	free_page((unsigned long)vcpu->run);
 +fail:
 +	return r;
++=======
+ 	preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);
++>>>>>>> 8bd826d629d6 (KVM: Move vcpu->run page allocation out of kvm_vcpu_init())
  }
 +EXPORT_SYMBOL_GPL(kvm_vcpu_init);
  
 -void kvm_vcpu_destroy(struct kvm_vcpu *vcpu)
 +void kvm_vcpu_uninit(struct kvm_vcpu *vcpu)
  {
 -	kvm_arch_vcpu_destroy(vcpu);
 -
  	/*
 -	 * No need for rcu_read_lock as VCPU_RUN is the only place that changes
 -	 * the vcpu->pid pointer, and at destruction time all file descriptors
 -	 * are already gone.
 +	 * no need for rcu_read_lock as VCPU_RUN is the only place that
 +	 * will change the vcpu->pid pointer and on uninit all file
 +	 * descriptors are already gone.
  	 */
  	put_pid(rcu_dereference_protected(vcpu->pid, 1));
++<<<<<<< HEAD
 +	kvm_arch_vcpu_uninit(vcpu);
 +	free_page((unsigned long)vcpu->run);
++=======
+ 
+ 	free_page((unsigned long)vcpu->run);
+ 	kmem_cache_free(kvm_vcpu_cache, vcpu);
++>>>>>>> 8bd826d629d6 (KVM: Move vcpu->run page allocation out of kvm_vcpu_init())
  }
 -EXPORT_SYMBOL_GPL(kvm_vcpu_destroy);
 +EXPORT_SYMBOL_GPL(kvm_vcpu_uninit);
  
  #if defined(CONFIG_MMU_NOTIFIER) && defined(KVM_ARCH_WANT_MMU_NOTIFIER)
  static inline struct kvm *mmu_notifier_to_kvm(struct mmu_notifier *mn)
@@@ -2736,11 -2721,18 +2755,26 @@@ static int kvm_vm_ioctl_create_vcpu(str
  		goto vcpu_decrement;
  	}
  
++<<<<<<< HEAD
 +	preempt_notifier_init(&vcpu->preempt_notifier, &kvm_preempt_ops);
++=======
+ 	page = alloc_page(GFP_KERNEL | __GFP_ZERO);
+ 	if (!page) {
+ 		r = -ENOMEM;
+ 		goto vcpu_free;
+ 	}
+ 	vcpu->run = page_address(page);
+ 
+ 	kvm_vcpu_init(vcpu, kvm, id);
++>>>>>>> 8bd826d629d6 (KVM: Move vcpu->run page allocation out of kvm_vcpu_init())
  
 -	r = kvm_arch_vcpu_create(vcpu);
 +	r = kvm_arch_vcpu_setup(vcpu);
  	if (r)
++<<<<<<< HEAD
 +		goto vcpu_destroy;
++=======
+ 		goto vcpu_free_run_page;
++>>>>>>> 8bd826d629d6 (KVM: Move vcpu->run page allocation out of kvm_vcpu_init())
  
  	kvm_create_vcpu_debugfs(vcpu);
  
@@@ -2777,8 -2769,11 +2811,15 @@@
  unlock_vcpu_destroy:
  	mutex_unlock(&kvm->lock);
  	debugfs_remove_recursive(vcpu->debugfs_dentry);
 +vcpu_destroy:
  	kvm_arch_vcpu_destroy(vcpu);
++<<<<<<< HEAD
++=======
+ vcpu_free_run_page:
+ 	free_page((unsigned long)vcpu->run);
+ vcpu_free:
+ 	kmem_cache_free(kvm_vcpu_cache, vcpu);
++>>>>>>> 8bd826d629d6 (KVM: Move vcpu->run page allocation out of kvm_vcpu_init())
  vcpu_decrement:
  	mutex_lock(&kvm->lock);
  	kvm->created_vcpus--;
* Unmerged path virt/kvm/kvm_main.c
