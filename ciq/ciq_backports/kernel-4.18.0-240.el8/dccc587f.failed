io_uring: remove obsolete @mm_fault

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Pavel Begunkov <asml.silence@gmail.com>
commit dccc587f6c07ccc734588226fdf62f685558e89f
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/dccc587f.failed

If io_submit_sqes() can't grab an mm, it fails and exits right away.
There is no need to track the fact of the failure. Remove @mm_fault.

	Signed-off-by: Pavel Begunkov <asml.silence@gmail.com>
	Signed-off-by: Jens Axboe <axboe@kernel.dk>
(cherry picked from commit dccc587f6c07ccc734588226fdf62f685558e89f)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	fs/io_uring.c
diff --cc fs/io_uring.c
index 2afa3b27779e,81532479c857..000000000000
--- a/fs/io_uring.c
+++ b/fs/io_uring.c
@@@ -2439,54 -5817,82 +2439,90 @@@ static int io_submit_sqes(struct io_rin
  {
  	struct io_submit_state state, *statep = NULL;
  	struct io_kiocb *link = NULL;
 +	struct io_kiocb *shadow_req = NULL;
 +	bool prev_was_link = false;
  	int i, submitted = 0;
++<<<<<<< HEAD
++=======
+ 
+ 	/* if we have a backlog and couldn't flush it all, return BUSY */
+ 	if (test_bit(0, &ctx->sq_check_overflow)) {
+ 		if (!list_empty(&ctx->cq_overflow_list) &&
+ 		    !io_cqring_overflow_flush(ctx, false))
+ 			return -EBUSY;
+ 	}
+ 
+ 	/* make sure SQ entry isn't read before tail */
+ 	nr = min3(nr, ctx->sq_entries, io_sqring_entries(ctx));
+ 
+ 	if (!percpu_ref_tryget_many(&ctx->refs, nr))
+ 		return -EAGAIN;
++>>>>>>> dccc587f6c07 (io_uring: remove obsolete @mm_fault)
  
  	if (nr > IO_PLUG_THRESHOLD) {
  		io_submit_state_start(&state, nr);
  		statep = &state;
  	}
  
 -	ctx->ring_fd = ring_fd;
 -	ctx->ring_file = ring_file;
 -
  	for (i = 0; i < nr; i++) {
 -		const struct io_uring_sqe *sqe;
 -		struct io_kiocb *req;
 -		int err;
 -
 -		sqe = io_get_sqe(ctx);
 -		if (unlikely(!sqe)) {
 -			io_consume_sqe(ctx);
 -			break;
 -		}
 -		req = io_alloc_req(ctx, statep);
 -		if (unlikely(!req)) {
 -			if (!submitted)
 -				submitted = -EAGAIN;
 -			break;
 +		/*
 +		 * If previous wasn't linked and we have a linked command,
 +		 * that's the end of the chain. Submit the previous link.
 +		 */
 +		if (!prev_was_link && link) {
 +			io_queue_link_head(ctx, link, &link->submit, shadow_req,
 +						true);
 +			link = NULL;
 +			shadow_req = NULL;
  		}
 -
 +		prev_was_link = (sqes[i].sqe->flags & IOSQE_IO_LINK) != 0;
 +
++<<<<<<< HEAD
 +		if (link && (sqes[i].sqe->flags & IOSQE_IO_DRAIN)) {
 +			if (!shadow_req) {
 +				shadow_req = io_get_req(ctx, NULL);
 +				if (unlikely(!shadow_req))
 +					goto out;
 +				shadow_req->flags |= (REQ_F_IO_DRAIN | REQ_F_SHADOW_DRAIN);
 +				refcount_dec(&shadow_req->refs);
++=======
+ 		io_init_req(ctx, req, sqe);
+ 		io_consume_sqe(ctx);
+ 		/* will complete beyond this point, count as submitted */
+ 		submitted++;
+ 
+ 		if (unlikely(req->opcode >= IORING_OP_LAST)) {
+ 			err = -EINVAL;
+ fail_req:
+ 			io_cqring_add_event(req, err);
+ 			io_double_put_req(req);
+ 			break;
+ 		}
+ 
+ 		if (io_op_defs[req->opcode].needs_mm && !*mm) {
+ 			if (unlikely(!mmget_not_zero(ctx->sqo_mm))) {
+ 				err = -EFAULT;
+ 				goto fail_req;
++>>>>>>> dccc587f6c07 (io_uring: remove obsolete @mm_fault)
  			}
 -			use_mm(ctx->sqo_mm);
 -			*mm = ctx->sqo_mm;
 +			shadow_req->sequence = sqes[i].sequence;
  		}
  
 -		req->needs_fixed_file = async;
 -		trace_io_uring_submit_sqe(ctx, req->opcode, req->user_data,
 -						true, async);
 -		if (!io_submit_sqe(req, sqe, statep, &link))
 -			break;
 +out:
 +		if (unlikely(mm_fault)) {
 +			io_cqring_add_event(ctx, sqes[i].sqe->user_data,
 +						-EFAULT);
 +		} else {
 +			sqes[i].has_user = has_user;
 +			sqes[i].needs_lock = true;
 +			sqes[i].needs_fixed_file = true;
 +			io_submit_sqe(ctx, &sqes[i], statep, &link, true);
 +			submitted++;
 +		}
  	}
  
 -	if (unlikely(submitted != nr)) {
 -		int ref_used = (submitted == -EAGAIN) ? 0 : submitted;
 -
 -		percpu_ref_put_many(&ctx->refs, nr - ref_used);
 -	}
  	if (link)
 -		io_queue_link_head(link);
 +		io_queue_link_head(ctx, link, &link->submit, shadow_req, true);
  	if (statep)
  		io_submit_state_end(&state);
  
* Unmerged path fs/io_uring.c
