flow_offload: check for basic action hw stats type

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Jiri Pirko <jiri@mellanox.com>
commit 319a1d19471ec49b8a91a7f6a3fe2c4535e5c279
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/319a1d19.failed

Introduce flow_action_basic_hw_stats_types_check() helper and use it
in drivers. That sanitizes the drivers which do not have support
for action HW stats types.

	Signed-off-by: Jiri Pirko <jiri@mellanox.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit 319a1d19471ec49b8a91a7f6a3fe2c4535e5c279)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.c
#	drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.h
#	drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_matchall.c
#	drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.c
#	drivers/net/ethernet/mscc/ocelot_flower.c
#	drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
diff --cc drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.c
index e447976bdd3e,cc46277e98de..000000000000
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.c
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.c
@@@ -544,17 -543,20 +544,30 @@@ static bool valid_pedit_action(struct n
  	return true;
  }
  
++<<<<<<< HEAD
 +static int cxgb4_validate_flow_actions(struct net_device *dev,
 +				       struct flow_cls_offload *cls)
++=======
+ int cxgb4_validate_flow_actions(struct net_device *dev,
+ 				struct flow_action *actions,
+ 				struct netlink_ext_ack *extack)
++>>>>>>> 319a1d19471e (flow_offload: check for basic action hw stats type)
  {
 +	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
  	struct flow_action_entry *act;
  	bool act_redir = false;
  	bool act_pedit = false;
  	bool act_vlan = false;
  	int i;
  
++<<<<<<< HEAD
 +	flow_action_for_each(i, act, &rule->action) {
++=======
+ 	if (!flow_action_basic_hw_stats_types_check(actions, extack))
+ 		return -EOPNOTSUPP;
+ 
+ 	flow_action_for_each(i, act, actions) {
++>>>>>>> 319a1d19471e (flow_offload: check for basic action hw stats type)
  		switch (act->id) {
  		case FLOW_ACTION_ACCEPT:
  		case FLOW_ACTION_DROP:
@@@ -640,10 -644,9 +653,14 @@@ int cxgb4_tc_flower_replace(struct net_
  	struct ch_tc_flower_entry *ch_flower;
  	struct ch_filter_specification *fs;
  	struct filter_ctx ctx;
 -	int fidx, ret;
 +	int fidx;
 +	int ret;
  
++<<<<<<< HEAD
 +	if (cxgb4_validate_flow_actions(dev, cls))
++=======
+ 	if (cxgb4_validate_flow_actions(dev, &rule->action, extack))
++>>>>>>> 319a1d19471e (flow_offload: check for basic action hw stats type)
  		return -EOPNOTSUPP;
  
  	if (cxgb4_validate_flow_match(dev, cls))
diff --cc drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.h
index eb4c95248baf,0a30c96b81ff..000000000000
--- a/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.h
+++ b/drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.h
@@@ -108,6 -108,13 +108,16 @@@ struct ch_tc_pedit_fields 
  #define PEDIT_TCP_SPORT_DPORT		0x0
  #define PEDIT_UDP_SPORT_DPORT		0x0
  
++<<<<<<< HEAD
++=======
+ void cxgb4_process_flow_actions(struct net_device *in,
+ 				struct flow_action *actions,
+ 				struct ch_filter_specification *fs);
+ int cxgb4_validate_flow_actions(struct net_device *dev,
+ 				struct flow_action *actions,
+ 				struct netlink_ext_ack *extack);
+ 
++>>>>>>> 319a1d19471e (flow_offload: check for basic action hw stats type)
  int cxgb4_tc_flower_replace(struct net_device *dev,
  			    struct flow_cls_offload *cls);
  int cxgb4_tc_flower_destroy(struct net_device *dev,
diff --cc drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.c
index 8581d5b17dd5,0a0c6ec2336c..000000000000
--- a/drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.c
+++ b/drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.c
@@@ -107,7 -1074,398 +107,402 @@@ void mvpp2_cls_oversize_rxq_set(struct 
  	mvpp2_write(port->priv, MVPP2_CLS_SWFWD_PCTRL_REG, val);
  }
  
++<<<<<<< HEAD
 +void mvpp22_init_rss(struct mvpp2_port *port)
++=======
+ static int mvpp2_port_c2_tcam_rule_add(struct mvpp2_port *port,
+ 				       struct mvpp2_rfs_rule *rule)
+ {
+ 	struct flow_action_entry *act;
+ 	struct mvpp2_cls_c2_entry c2;
+ 	u8 qh, ql, pmap;
+ 	int index, ctx;
+ 
+ 	if (!flow_action_basic_hw_stats_types_check(&rule->flow->action, NULL))
+ 		return -EOPNOTSUPP;
+ 
+ 	memset(&c2, 0, sizeof(c2));
+ 
+ 	index = mvpp2_cls_c2_port_flow_index(port, rule->loc);
+ 	if (index < 0)
+ 		return -EINVAL;
+ 	c2.index = index;
+ 
+ 	act = &rule->flow->action.entries[0];
+ 
+ 	rule->c2_index = c2.index;
+ 
+ 	c2.tcam[3] = (rule->c2_tcam & 0xffff) |
+ 		     ((rule->c2_tcam_mask & 0xffff) << 16);
+ 	c2.tcam[2] = ((rule->c2_tcam >> 16) & 0xffff) |
+ 		     (((rule->c2_tcam_mask >> 16) & 0xffff) << 16);
+ 	c2.tcam[1] = ((rule->c2_tcam >> 32) & 0xffff) |
+ 		     (((rule->c2_tcam_mask >> 32) & 0xffff) << 16);
+ 	c2.tcam[0] = ((rule->c2_tcam >> 48) & 0xffff) |
+ 		     (((rule->c2_tcam_mask >> 48) & 0xffff) << 16);
+ 
+ 	pmap = BIT(port->id);
+ 	c2.tcam[4] = MVPP22_CLS_C2_PORT_ID(pmap);
+ 	c2.tcam[4] |= MVPP22_CLS_C2_TCAM_EN(MVPP22_CLS_C2_PORT_ID(pmap));
+ 
+ 	/* Match on Lookup Type */
+ 	c2.tcam[4] |= MVPP22_CLS_C2_TCAM_EN(MVPP22_CLS_C2_LU_TYPE(MVPP2_CLS_LU_TYPE_MASK));
+ 	c2.tcam[4] |= MVPP22_CLS_C2_LU_TYPE(rule->loc);
+ 
+ 	if (act->id == FLOW_ACTION_DROP) {
+ 		c2.act = MVPP22_CLS_C2_ACT_COLOR(MVPP22_C2_COL_RED_LOCK);
+ 	} else {
+ 		/* We want to keep the default color derived from the Header
+ 		 * Parser drop entries, for VLAN and MAC filtering. This will
+ 		 * assign a default color of Green or Red, and we want matches
+ 		 * with a non-drop action to keep that color.
+ 		 */
+ 		c2.act = MVPP22_CLS_C2_ACT_COLOR(MVPP22_C2_COL_NO_UPD_LOCK);
+ 
+ 		/* Update RSS status after matching this entry */
+ 		if (act->queue.ctx)
+ 			c2.attr[2] |= MVPP22_CLS_C2_ATTR2_RSS_EN;
+ 
+ 		/* Always lock the RSS_EN decision. We might have high prio
+ 		 * rules steering to an RXQ, and a lower one steering to RSS,
+ 		 * we don't want the low prio RSS rule overwriting this flag.
+ 		 */
+ 		c2.act = MVPP22_CLS_C2_ACT_RSS_EN(MVPP22_C2_UPD_LOCK);
+ 
+ 		/* Mark packet as "forwarded to software", needed for RSS */
+ 		c2.act |= MVPP22_CLS_C2_ACT_FWD(MVPP22_C2_FWD_SW_LOCK);
+ 
+ 		c2.act |= MVPP22_CLS_C2_ACT_QHIGH(MVPP22_C2_UPD_LOCK) |
+ 			   MVPP22_CLS_C2_ACT_QLOW(MVPP22_C2_UPD_LOCK);
+ 
+ 		if (act->queue.ctx) {
+ 			/* Get the global ctx number */
+ 			ctx = mvpp22_rss_ctx(port, act->queue.ctx);
+ 			if (ctx < 0)
+ 				return -EINVAL;
+ 
+ 			qh = (ctx >> 3) & MVPP22_CLS_C2_ATTR0_QHIGH_MASK;
+ 			ql = ctx & MVPP22_CLS_C2_ATTR0_QLOW_MASK;
+ 		} else {
+ 			qh = ((act->queue.index + port->first_rxq) >> 3) &
+ 			      MVPP22_CLS_C2_ATTR0_QHIGH_MASK;
+ 			ql = (act->queue.index + port->first_rxq) &
+ 			      MVPP22_CLS_C2_ATTR0_QLOW_MASK;
+ 		}
+ 
+ 		c2.attr[0] = MVPP22_CLS_C2_ATTR0_QHIGH(qh) |
+ 			      MVPP22_CLS_C2_ATTR0_QLOW(ql);
+ 	}
+ 
+ 	c2.valid = true;
+ 
+ 	mvpp2_cls_c2_write(port->priv, &c2);
+ 
+ 	return 0;
+ }
+ 
+ static int mvpp2_port_c2_rfs_rule_insert(struct mvpp2_port *port,
+ 					 struct mvpp2_rfs_rule *rule)
+ {
+ 	return mvpp2_port_c2_tcam_rule_add(port, rule);
+ }
+ 
+ static int mvpp2_port_cls_rfs_rule_remove(struct mvpp2_port *port,
+ 					  struct mvpp2_rfs_rule *rule)
+ {
+ 	const struct mvpp2_cls_flow *flow;
+ 	struct mvpp2_cls_flow_entry fe;
+ 	int index, i;
+ 
+ 	for_each_cls_flow_id_containing_type(i, rule->flow_type) {
+ 		flow = mvpp2_cls_flow_get(i);
+ 		if (!flow)
+ 			return 0;
+ 
+ 		index = MVPP2_CLS_FLT_C2_RFS(port->id, flow->flow_id, rule->loc);
+ 
+ 		mvpp2_cls_flow_read(port->priv, index, &fe);
+ 		mvpp2_cls_flow_port_remove(&fe, BIT(port->id));
+ 		mvpp2_cls_flow_write(port->priv, &fe);
+ 	}
+ 
+ 	if (rule->c2_index >= 0)
+ 		mvpp22_port_c2_lookup_disable(port, rule->c2_index);
+ 
+ 	return 0;
+ }
+ 
+ static int mvpp2_port_flt_rfs_rule_insert(struct mvpp2_port *port,
+ 					  struct mvpp2_rfs_rule *rule)
+ {
+ 	const struct mvpp2_cls_flow *flow;
+ 	struct mvpp2 *priv = port->priv;
+ 	struct mvpp2_cls_flow_entry fe;
+ 	int index, ret, i;
+ 
+ 	if (rule->engine != MVPP22_CLS_ENGINE_C2)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = mvpp2_port_c2_rfs_rule_insert(port, rule);
+ 	if (ret)
+ 		return ret;
+ 
+ 	for_each_cls_flow_id_containing_type(i, rule->flow_type) {
+ 		flow = mvpp2_cls_flow_get(i);
+ 		if (!flow)
+ 			return 0;
+ 
+ 		if ((rule->hek_fields & flow->supported_hash_opts) != rule->hek_fields)
+ 			continue;
+ 
+ 		index = MVPP2_CLS_FLT_C2_RFS(port->id, flow->flow_id, rule->loc);
+ 
+ 		mvpp2_cls_flow_read(priv, index, &fe);
+ 		mvpp2_cls_flow_eng_set(&fe, rule->engine);
+ 		mvpp2_cls_flow_port_id_sel(&fe, true);
+ 		mvpp2_flow_set_hek_fields(&fe, rule->hek_fields);
+ 		mvpp2_cls_flow_lu_type_set(&fe, rule->loc);
+ 		mvpp2_cls_flow_port_add(&fe, 0xf);
+ 
+ 		mvpp2_cls_flow_write(priv, &fe);
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int mvpp2_cls_c2_build_match(struct mvpp2_rfs_rule *rule)
+ {
+ 	struct flow_rule *flow = rule->flow;
+ 	int offs = 0;
+ 
+ 	/* The order of insertion in C2 tcam must match the order in which
+ 	 * the fields are found in the header
+ 	 */
+ 	if (flow_rule_match_key(flow, FLOW_DISSECTOR_KEY_VLAN)) {
+ 		struct flow_match_vlan match;
+ 
+ 		flow_rule_match_vlan(flow, &match);
+ 		if (match.mask->vlan_id) {
+ 			rule->hek_fields |= MVPP22_CLS_HEK_OPT_VLAN;
+ 
+ 			rule->c2_tcam |= ((u64)match.key->vlan_id) << offs;
+ 			rule->c2_tcam_mask |= ((u64)match.mask->vlan_id) << offs;
+ 
+ 			/* Don't update the offset yet */
+ 		}
+ 
+ 		if (match.mask->vlan_priority) {
+ 			rule->hek_fields |= MVPP22_CLS_HEK_OPT_VLAN_PRI;
+ 
+ 			/* VLAN pri is always at offset 13 relative to the
+ 			 * current offset
+ 			 */
+ 			rule->c2_tcam |= ((u64)match.key->vlan_priority) <<
+ 				(offs + 13);
+ 			rule->c2_tcam_mask |= ((u64)match.mask->vlan_priority) <<
+ 				(offs + 13);
+ 		}
+ 
+ 		if (match.mask->vlan_dei)
+ 			return -EOPNOTSUPP;
+ 
+ 		/* vlan id and prio always seem to take a full 16-bit slot in
+ 		 * the Header Extracted Key.
+ 		 */
+ 		offs += 16;
+ 	}
+ 
+ 	if (flow_rule_match_key(flow, FLOW_DISSECTOR_KEY_PORTS)) {
+ 		struct flow_match_ports match;
+ 
+ 		flow_rule_match_ports(flow, &match);
+ 		if (match.mask->src) {
+ 			rule->hek_fields |= MVPP22_CLS_HEK_OPT_L4SIP;
+ 
+ 			rule->c2_tcam |= ((u64)ntohs(match.key->src)) << offs;
+ 			rule->c2_tcam_mask |= ((u64)ntohs(match.mask->src)) << offs;
+ 			offs += mvpp2_cls_hek_field_size(MVPP22_CLS_HEK_OPT_L4SIP);
+ 		}
+ 
+ 		if (match.mask->dst) {
+ 			rule->hek_fields |= MVPP22_CLS_HEK_OPT_L4DIP;
+ 
+ 			rule->c2_tcam |= ((u64)ntohs(match.key->dst)) << offs;
+ 			rule->c2_tcam_mask |= ((u64)ntohs(match.mask->dst)) << offs;
+ 			offs += mvpp2_cls_hek_field_size(MVPP22_CLS_HEK_OPT_L4DIP);
+ 		}
+ 	}
+ 
+ 	if (hweight16(rule->hek_fields) > MVPP2_FLOW_N_FIELDS)
+ 		return -EOPNOTSUPP;
+ 
+ 	return 0;
+ }
+ 
+ static int mvpp2_cls_rfs_parse_rule(struct mvpp2_rfs_rule *rule)
+ {
+ 	struct flow_rule *flow = rule->flow;
+ 	struct flow_action_entry *act;
+ 
+ 	if (!flow_action_basic_hw_stats_types_check(&rule->flow->action, NULL))
+ 		return -EOPNOTSUPP;
+ 
+ 	act = &flow->action.entries[0];
+ 	if (act->id != FLOW_ACTION_QUEUE && act->id != FLOW_ACTION_DROP)
+ 		return -EOPNOTSUPP;
+ 
+ 	/* When both an RSS context and an queue index are set, the index
+ 	 * is considered as an offset to be added to the indirection table
+ 	 * entries. We don't support this, so reject this rule.
+ 	 */
+ 	if (act->queue.ctx && act->queue.index)
+ 		return -EOPNOTSUPP;
+ 
+ 	/* For now, only use the C2 engine which has a HEK size limited to 64
+ 	 * bits for TCAM matching.
+ 	 */
+ 	rule->engine = MVPP22_CLS_ENGINE_C2;
+ 
+ 	if (mvpp2_cls_c2_build_match(rule))
+ 		return -EINVAL;
+ 
+ 	return 0;
+ }
+ 
+ int mvpp2_ethtool_cls_rule_get(struct mvpp2_port *port,
+ 			       struct ethtool_rxnfc *rxnfc)
+ {
+ 	struct mvpp2_ethtool_fs *efs;
+ 
+ 	if (rxnfc->fs.location >= MVPP2_N_RFS_ENTRIES_PER_FLOW)
+ 		return -EINVAL;
+ 
+ 	efs = port->rfs_rules[rxnfc->fs.location];
+ 	if (!efs)
+ 		return -ENOENT;
+ 
+ 	memcpy(rxnfc, &efs->rxnfc, sizeof(efs->rxnfc));
+ 
+ 	return 0;
+ }
+ 
+ int mvpp2_ethtool_cls_rule_ins(struct mvpp2_port *port,
+ 			       struct ethtool_rxnfc *info)
+ {
+ 	struct ethtool_rx_flow_spec_input input = {};
+ 	struct ethtool_rx_flow_rule *ethtool_rule;
+ 	struct mvpp2_ethtool_fs *efs, *old_efs;
+ 	int ret = 0;
+ 
+ 	if (info->fs.location >= MVPP2_N_RFS_ENTRIES_PER_FLOW)
+ 		return -EINVAL;
+ 
+ 	efs = kzalloc(sizeof(*efs), GFP_KERNEL);
+ 	if (!efs)
+ 		return -ENOMEM;
+ 
+ 	input.fs = &info->fs;
+ 
+ 	/* We need to manually set the rss_ctx, since this info isn't present
+ 	 * in info->fs
+ 	 */
+ 	if (info->fs.flow_type & FLOW_RSS)
+ 		input.rss_ctx = info->rss_context;
+ 
+ 	ethtool_rule = ethtool_rx_flow_rule_create(&input);
+ 	if (IS_ERR(ethtool_rule)) {
+ 		ret = PTR_ERR(ethtool_rule);
+ 		goto clean_rule;
+ 	}
+ 
+ 	efs->rule.flow = ethtool_rule->rule;
+ 	efs->rule.flow_type = mvpp2_cls_ethtool_flow_to_type(info->fs.flow_type);
+ 	if (efs->rule.flow_type < 0) {
+ 		ret = efs->rule.flow_type;
+ 		goto clean_rule;
+ 	}
+ 
+ 	ret = mvpp2_cls_rfs_parse_rule(&efs->rule);
+ 	if (ret)
+ 		goto clean_eth_rule;
+ 
+ 	efs->rule.loc = info->fs.location;
+ 
+ 	/* Replace an already existing rule */
+ 	if (port->rfs_rules[efs->rule.loc]) {
+ 		old_efs = port->rfs_rules[efs->rule.loc];
+ 		ret = mvpp2_port_cls_rfs_rule_remove(port, &old_efs->rule);
+ 		if (ret)
+ 			goto clean_eth_rule;
+ 		kfree(old_efs);
+ 		port->n_rfs_rules--;
+ 	}
+ 
+ 	ret = mvpp2_port_flt_rfs_rule_insert(port, &efs->rule);
+ 	if (ret)
+ 		goto clean_eth_rule;
+ 
+ 	ethtool_rx_flow_rule_destroy(ethtool_rule);
+ 	efs->rule.flow = NULL;
+ 
+ 	memcpy(&efs->rxnfc, info, sizeof(*info));
+ 	port->rfs_rules[efs->rule.loc] = efs;
+ 	port->n_rfs_rules++;
+ 
+ 	return ret;
+ 
+ clean_eth_rule:
+ 	ethtool_rx_flow_rule_destroy(ethtool_rule);
+ clean_rule:
+ 	kfree(efs);
+ 	return ret;
+ }
+ 
+ int mvpp2_ethtool_cls_rule_del(struct mvpp2_port *port,
+ 			       struct ethtool_rxnfc *info)
+ {
+ 	struct mvpp2_ethtool_fs *efs;
+ 	int ret;
+ 
+ 	efs = port->rfs_rules[info->fs.location];
+ 	if (!efs)
+ 		return -EINVAL;
+ 
+ 	/* Remove the rule from the engines. */
+ 	ret = mvpp2_port_cls_rfs_rule_remove(port, &efs->rule);
+ 	if (ret)
+ 		return ret;
+ 
+ 	port->n_rfs_rules--;
+ 	port->rfs_rules[info->fs.location] = NULL;
+ 	kfree(efs);
+ 
+ 	return 0;
+ }
+ 
+ static inline u32 mvpp22_rxfh_indir(struct mvpp2_port *port, u32 rxq)
+ {
+ 	int nrxqs, cpu, cpus = num_possible_cpus();
+ 
+ 	/* Number of RXQs per CPU */
+ 	nrxqs = port->nrxqs / cpus;
+ 
+ 	/* CPU that will handle this rx queue */
+ 	cpu = rxq / nrxqs;
+ 
+ 	if (!cpu_online(cpu))
+ 		return port->first_rxq;
+ 
+ 	/* Indirection to better distribute the paquets on the CPUs when
+ 	 * configuring the RSS queues.
+ 	 */
+ 	return port->first_rxq + ((rxq * nrxqs + rxq / cpus) % port->nrxqs);
+ }
+ 
+ static void mvpp22_rss_fill_table(struct mvpp2_port *port,
+ 				  struct mvpp2_rss_table *table,
+ 				  u32 rss_ctx)
++>>>>>>> 319a1d19471e (flow_offload: check for basic action hw stats type)
  {
  	struct mvpp2 *priv = port->priv;
  	int i;
diff --cc drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
index 225c833b2291,a0e6118444b0..000000000000
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
@@@ -288,6 -306,456 +288,459 @@@ static int tc_init(struct stmmac_priv *
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ static int tc_setup_cbs(struct stmmac_priv *priv,
+ 			struct tc_cbs_qopt_offload *qopt)
+ {
+ 	u32 tx_queues_count = priv->plat->tx_queues_to_use;
+ 	u32 queue = qopt->queue;
+ 	u32 ptr, speed_div;
+ 	u32 mode_to_use;
+ 	u64 value;
+ 	int ret;
+ 
+ 	/* Queue 0 is not AVB capable */
+ 	if (queue <= 0 || queue >= tx_queues_count)
+ 		return -EINVAL;
+ 	if (!priv->dma_cap.av)
+ 		return -EOPNOTSUPP;
+ 
+ 	mode_to_use = priv->plat->tx_queues_cfg[queue].mode_to_use;
+ 	if (mode_to_use == MTL_QUEUE_DCB && qopt->enable) {
+ 		ret = stmmac_dma_qmode(priv, priv->ioaddr, queue, MTL_QUEUE_AVB);
+ 		if (ret)
+ 			return ret;
+ 
+ 		priv->plat->tx_queues_cfg[queue].mode_to_use = MTL_QUEUE_AVB;
+ 	} else if (!qopt->enable) {
+ 		return stmmac_dma_qmode(priv, priv->ioaddr, queue, MTL_QUEUE_DCB);
+ 	}
+ 
+ 	/* Port Transmit Rate and Speed Divider */
+ 	ptr = (priv->speed == SPEED_100) ? 4 : 8;
+ 	speed_div = (priv->speed == SPEED_100) ? 100000 : 1000000;
+ 
+ 	/* Final adjustments for HW */
+ 	value = div_s64(qopt->idleslope * 1024ll * ptr, speed_div);
+ 	priv->plat->tx_queues_cfg[queue].idle_slope = value & GENMASK(31, 0);
+ 
+ 	value = div_s64(-qopt->sendslope * 1024ll * ptr, speed_div);
+ 	priv->plat->tx_queues_cfg[queue].send_slope = value & GENMASK(31, 0);
+ 
+ 	value = qopt->hicredit * 1024ll * 8;
+ 	priv->plat->tx_queues_cfg[queue].high_credit = value & GENMASK(31, 0);
+ 
+ 	value = qopt->locredit * 1024ll * 8;
+ 	priv->plat->tx_queues_cfg[queue].low_credit = value & GENMASK(31, 0);
+ 
+ 	ret = stmmac_config_cbs(priv, priv->hw,
+ 				priv->plat->tx_queues_cfg[queue].send_slope,
+ 				priv->plat->tx_queues_cfg[queue].idle_slope,
+ 				priv->plat->tx_queues_cfg[queue].high_credit,
+ 				priv->plat->tx_queues_cfg[queue].low_credit,
+ 				queue);
+ 	if (ret)
+ 		return ret;
+ 
+ 	dev_info(priv->device, "CBS queue %d: send %d, idle %d, hi %d, lo %d\n",
+ 			queue, qopt->sendslope, qopt->idleslope,
+ 			qopt->hicredit, qopt->locredit);
+ 	return 0;
+ }
+ 
+ static int tc_parse_flow_actions(struct stmmac_priv *priv,
+ 				 struct flow_action *action,
+ 				 struct stmmac_flow_entry *entry,
+ 				 struct netlink_ext_ack *extack)
+ {
+ 	struct flow_action_entry *act;
+ 	int i;
+ 
+ 	if (!flow_action_has_entries(action))
+ 		return -EINVAL;
+ 
+ 	if (!flow_action_basic_hw_stats_types_check(action, extack))
+ 		return -EOPNOTSUPP;
+ 
+ 	flow_action_for_each(i, act, action) {
+ 		switch (act->id) {
+ 		case FLOW_ACTION_DROP:
+ 			entry->action |= STMMAC_FLOW_ACTION_DROP;
+ 			return 0;
+ 		default:
+ 			break;
+ 		}
+ 	}
+ 
+ 	/* Nothing to do, maybe inverse filter ? */
+ 	return 0;
+ }
+ 
+ static int tc_add_basic_flow(struct stmmac_priv *priv,
+ 			     struct flow_cls_offload *cls,
+ 			     struct stmmac_flow_entry *entry)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
+ 	struct flow_dissector *dissector = rule->match.dissector;
+ 	struct flow_match_basic match;
+ 
+ 	/* Nothing to do here */
+ 	if (!dissector_uses_key(dissector, FLOW_DISSECTOR_KEY_BASIC))
+ 		return -EINVAL;
+ 
+ 	flow_rule_match_basic(rule, &match);
+ 	entry->ip_proto = match.key->ip_proto;
+ 	return 0;
+ }
+ 
+ static int tc_add_ip4_flow(struct stmmac_priv *priv,
+ 			   struct flow_cls_offload *cls,
+ 			   struct stmmac_flow_entry *entry)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
+ 	struct flow_dissector *dissector = rule->match.dissector;
+ 	bool inv = entry->action & STMMAC_FLOW_ACTION_DROP;
+ 	struct flow_match_ipv4_addrs match;
+ 	u32 hw_match;
+ 	int ret;
+ 
+ 	/* Nothing to do here */
+ 	if (!dissector_uses_key(dissector, FLOW_DISSECTOR_KEY_IPV4_ADDRS))
+ 		return -EINVAL;
+ 
+ 	flow_rule_match_ipv4_addrs(rule, &match);
+ 	hw_match = ntohl(match.key->src) & ntohl(match.mask->src);
+ 	if (hw_match) {
+ 		ret = stmmac_config_l3_filter(priv, priv->hw, entry->idx, true,
+ 					      false, true, inv, hw_match);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	hw_match = ntohl(match.key->dst) & ntohl(match.mask->dst);
+ 	if (hw_match) {
+ 		ret = stmmac_config_l3_filter(priv, priv->hw, entry->idx, true,
+ 					      false, false, inv, hw_match);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	return 0;
+ }
+ 
+ static int tc_add_ports_flow(struct stmmac_priv *priv,
+ 			     struct flow_cls_offload *cls,
+ 			     struct stmmac_flow_entry *entry)
+ {
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
+ 	struct flow_dissector *dissector = rule->match.dissector;
+ 	bool inv = entry->action & STMMAC_FLOW_ACTION_DROP;
+ 	struct flow_match_ports match;
+ 	u32 hw_match;
+ 	bool is_udp;
+ 	int ret;
+ 
+ 	/* Nothing to do here */
+ 	if (!dissector_uses_key(dissector, FLOW_DISSECTOR_KEY_PORTS))
+ 		return -EINVAL;
+ 
+ 	switch (entry->ip_proto) {
+ 	case IPPROTO_TCP:
+ 		is_udp = false;
+ 		break;
+ 	case IPPROTO_UDP:
+ 		is_udp = true;
+ 		break;
+ 	default:
+ 		return -EINVAL;
+ 	}
+ 
+ 	flow_rule_match_ports(rule, &match);
+ 
+ 	hw_match = ntohs(match.key->src) & ntohs(match.mask->src);
+ 	if (hw_match) {
+ 		ret = stmmac_config_l4_filter(priv, priv->hw, entry->idx, true,
+ 					      is_udp, true, inv, hw_match);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	hw_match = ntohs(match.key->dst) & ntohs(match.mask->dst);
+ 	if (hw_match) {
+ 		ret = stmmac_config_l4_filter(priv, priv->hw, entry->idx, true,
+ 					      is_udp, false, inv, hw_match);
+ 		if (ret)
+ 			return ret;
+ 	}
+ 
+ 	entry->is_l4 = true;
+ 	return 0;
+ }
+ 
+ static struct stmmac_flow_entry *tc_find_flow(struct stmmac_priv *priv,
+ 					      struct flow_cls_offload *cls,
+ 					      bool get_free)
+ {
+ 	int i;
+ 
+ 	for (i = 0; i < priv->flow_entries_max; i++) {
+ 		struct stmmac_flow_entry *entry = &priv->flow_entries[i];
+ 
+ 		if (entry->cookie == cls->cookie)
+ 			return entry;
+ 		if (get_free && (entry->in_use == false))
+ 			return entry;
+ 	}
+ 
+ 	return NULL;
+ }
+ 
+ static struct {
+ 	int (*fn)(struct stmmac_priv *priv, struct flow_cls_offload *cls,
+ 		  struct stmmac_flow_entry *entry);
+ } tc_flow_parsers[] = {
+ 	{ .fn = tc_add_basic_flow },
+ 	{ .fn = tc_add_ip4_flow },
+ 	{ .fn = tc_add_ports_flow },
+ };
+ 
+ static int tc_add_flow(struct stmmac_priv *priv,
+ 		       struct flow_cls_offload *cls)
+ {
+ 	struct stmmac_flow_entry *entry = tc_find_flow(priv, cls, false);
+ 	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
+ 	int i, ret;
+ 
+ 	if (!entry) {
+ 		entry = tc_find_flow(priv, cls, true);
+ 		if (!entry)
+ 			return -ENOENT;
+ 	}
+ 
+ 	ret = tc_parse_flow_actions(priv, &rule->action, entry,
+ 				    cls->common.extack);
+ 	if (ret)
+ 		return ret;
+ 
+ 	for (i = 0; i < ARRAY_SIZE(tc_flow_parsers); i++) {
+ 		ret = tc_flow_parsers[i].fn(priv, cls, entry);
+ 		if (!ret) {
+ 			entry->in_use = true;
+ 			continue;
+ 		}
+ 	}
+ 
+ 	if (!entry->in_use)
+ 		return -EINVAL;
+ 
+ 	entry->cookie = cls->cookie;
+ 	return 0;
+ }
+ 
+ static int tc_del_flow(struct stmmac_priv *priv,
+ 		       struct flow_cls_offload *cls)
+ {
+ 	struct stmmac_flow_entry *entry = tc_find_flow(priv, cls, false);
+ 	int ret;
+ 
+ 	if (!entry || !entry->in_use)
+ 		return -ENOENT;
+ 
+ 	if (entry->is_l4) {
+ 		ret = stmmac_config_l4_filter(priv, priv->hw, entry->idx, false,
+ 					      false, false, false, 0);
+ 	} else {
+ 		ret = stmmac_config_l3_filter(priv, priv->hw, entry->idx, false,
+ 					      false, false, false, 0);
+ 	}
+ 
+ 	entry->in_use = false;
+ 	entry->cookie = 0;
+ 	entry->is_l4 = false;
+ 	return ret;
+ }
+ 
+ static int tc_setup_cls(struct stmmac_priv *priv,
+ 			struct flow_cls_offload *cls)
+ {
+ 	int ret = 0;
+ 
+ 	/* When RSS is enabled, the filtering will be bypassed */
+ 	if (priv->rss.enable)
+ 		return -EBUSY;
+ 
+ 	switch (cls->command) {
+ 	case FLOW_CLS_REPLACE:
+ 		ret = tc_add_flow(priv, cls);
+ 		break;
+ 	case FLOW_CLS_DESTROY:
+ 		ret = tc_del_flow(priv, cls);
+ 		break;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	return ret;
+ }
+ 
+ static int tc_setup_taprio(struct stmmac_priv *priv,
+ 			   struct tc_taprio_qopt_offload *qopt)
+ {
+ 	u32 size, wid = priv->dma_cap.estwid, dep = priv->dma_cap.estdep;
+ 	struct plat_stmmacenet_data *plat = priv->plat;
+ 	struct timespec64 time;
+ 	bool fpe = false;
+ 	int i, ret = 0;
+ 	u64 ctr;
+ 
+ 	if (!priv->dma_cap.estsel)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (wid) {
+ 	case 0x1:
+ 		wid = 16;
+ 		break;
+ 	case 0x2:
+ 		wid = 20;
+ 		break;
+ 	case 0x3:
+ 		wid = 24;
+ 		break;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	switch (dep) {
+ 	case 0x1:
+ 		dep = 64;
+ 		break;
+ 	case 0x2:
+ 		dep = 128;
+ 		break;
+ 	case 0x3:
+ 		dep = 256;
+ 		break;
+ 	case 0x4:
+ 		dep = 512;
+ 		break;
+ 	case 0x5:
+ 		dep = 1024;
+ 		break;
+ 	default:
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	if (!qopt->enable)
+ 		goto disable;
+ 	if (qopt->num_entries >= dep)
+ 		return -EINVAL;
+ 	if (!qopt->base_time)
+ 		return -ERANGE;
+ 	if (!qopt->cycle_time)
+ 		return -ERANGE;
+ 
+ 	if (!plat->est) {
+ 		plat->est = devm_kzalloc(priv->device, sizeof(*plat->est),
+ 					 GFP_KERNEL);
+ 		if (!plat->est)
+ 			return -ENOMEM;
+ 	} else {
+ 		memset(plat->est, 0, sizeof(*plat->est));
+ 	}
+ 
+ 	size = qopt->num_entries;
+ 
+ 	priv->plat->est->gcl_size = size;
+ 	priv->plat->est->enable = qopt->enable;
+ 
+ 	for (i = 0; i < size; i++) {
+ 		s64 delta_ns = qopt->entries[i].interval;
+ 		u32 gates = qopt->entries[i].gate_mask;
+ 
+ 		if (delta_ns > GENMASK(wid, 0))
+ 			return -ERANGE;
+ 		if (gates > GENMASK(31 - wid, 0))
+ 			return -ERANGE;
+ 
+ 		switch (qopt->entries[i].command) {
+ 		case TC_TAPRIO_CMD_SET_GATES:
+ 			if (fpe)
+ 				return -EINVAL;
+ 			break;
+ 		case TC_TAPRIO_CMD_SET_AND_HOLD:
+ 			gates |= BIT(0);
+ 			fpe = true;
+ 			break;
+ 		case TC_TAPRIO_CMD_SET_AND_RELEASE:
+ 			gates &= ~BIT(0);
+ 			fpe = true;
+ 			break;
+ 		default:
+ 			return -EOPNOTSUPP;
+ 		}
+ 
+ 		priv->plat->est->gcl[i] = delta_ns | (gates << wid);
+ 	}
+ 
+ 	/* Adjust for real system time */
+ 	time = ktime_to_timespec64(qopt->base_time);
+ 	priv->plat->est->btr[0] = (u32)time.tv_nsec;
+ 	priv->plat->est->btr[1] = (u32)time.tv_sec;
+ 
+ 	ctr = qopt->cycle_time;
+ 	priv->plat->est->ctr[0] = do_div(ctr, NSEC_PER_SEC);
+ 	priv->plat->est->ctr[1] = (u32)ctr;
+ 
+ 	if (fpe && !priv->dma_cap.fpesel)
+ 		return -EOPNOTSUPP;
+ 
+ 	ret = stmmac_fpe_configure(priv, priv->ioaddr,
+ 				   priv->plat->tx_queues_to_use,
+ 				   priv->plat->rx_queues_to_use, fpe);
+ 	if (ret && fpe) {
+ 		netdev_err(priv->dev, "failed to enable Frame Preemption\n");
+ 		return ret;
+ 	}
+ 
+ 	ret = stmmac_est_configure(priv, priv->ioaddr, priv->plat->est,
+ 				   priv->plat->clk_ptp_rate);
+ 	if (ret) {
+ 		netdev_err(priv->dev, "failed to configure EST\n");
+ 		goto disable;
+ 	}
+ 
+ 	netdev_info(priv->dev, "configured EST\n");
+ 	return 0;
+ 
+ disable:
+ 	priv->plat->est->enable = false;
+ 	stmmac_est_configure(priv, priv->ioaddr, priv->plat->est,
+ 			     priv->plat->clk_ptp_rate);
+ 	return ret;
+ }
+ 
+ static int tc_setup_etf(struct stmmac_priv *priv,
+ 			struct tc_etf_qopt_offload *qopt)
+ {
+ 	if (!priv->dma_cap.tbssel)
+ 		return -EOPNOTSUPP;
+ 	if (qopt->queue >= priv->plat->tx_queues_to_use)
+ 		return -EINVAL;
+ 	if (!(priv->tx_queue[qopt->queue].tbs & STMMAC_TBS_AVAIL))
+ 		return -EINVAL;
+ 
+ 	if (qopt->enable)
+ 		priv->tx_queue[qopt->queue].tbs |= STMMAC_TBS_EN;
+ 	else
+ 		priv->tx_queue[qopt->queue].tbs &= ~STMMAC_TBS_EN;
+ 
+ 	netdev_info(priv->dev, "%s ETF for Queue %d\n",
+ 		    qopt->enable ? "enabled" : "disabled", qopt->queue);
+ 	return 0;
+ }
+ 
++>>>>>>> 319a1d19471e (flow_offload: check for basic action hw stats type)
  const struct stmmac_tc_ops dwmac510_tc_ops = {
  	.init = tc_init,
  	.setup_cls_u32 = tc_setup_cls_u32,
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_matchall.c
* Unmerged path drivers/net/ethernet/mscc/ocelot_flower.c
diff --git a/drivers/net/ethernet/broadcom/bnxt/bnxt_tc.c b/drivers/net/ethernet/broadcom/bnxt/bnxt_tc.c
index 51891cbb4dc4..a8a4523acfd2 100644
--- a/drivers/net/ethernet/broadcom/bnxt/bnxt_tc.c
+++ b/drivers/net/ethernet/broadcom/bnxt/bnxt_tc.c
@@ -114,7 +114,8 @@ static int bnxt_tc_parse_tunnel_set(struct bnxt *bp,
 
 static int bnxt_tc_parse_actions(struct bnxt *bp,
 				 struct bnxt_tc_actions *actions,
-				 struct flow_action *flow_action)
+				 struct flow_action *flow_action,
+				 struct netlink_ext_ack *extack)
 {
 	struct flow_action_entry *act;
 	int i, rc;
@@ -124,6 +125,9 @@ static int bnxt_tc_parse_actions(struct bnxt *bp,
 		return -EINVAL;
 	}
 
+	if (!flow_action_basic_hw_stats_types_check(flow_action, extack))
+		return -EOPNOTSUPP;
+
 	flow_action_for_each(i, act, flow_action) {
 		switch (act->id) {
 		case FLOW_ACTION_DROP:
@@ -301,7 +305,8 @@ static int bnxt_tc_parse_flow(struct bnxt *bp,
 		flow->tun_mask.tp_src = match.mask->src;
 	}
 
-	return bnxt_tc_parse_actions(bp, &flow->actions, &rule->action);
+	return bnxt_tc_parse_actions(bp, &flow->actions, &rule->action,
+				     tc_flow_cmd->common.extack);
 }
 
 static int bnxt_hwrm_cfa_flow_free(struct bnxt *bp,
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.c
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_flower.h
* Unmerged path drivers/net/ethernet/chelsio/cxgb4/cxgb4_tc_matchall.c
* Unmerged path drivers/net/ethernet/marvell/mvpp2/mvpp2_cls.c
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
index 123069223147..bb2d27aeb4a3 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@ -2865,6 +2865,9 @@ static int parse_tc_nic_actions(struct mlx5e_priv *priv,
 	if (!flow_action_has_entries(flow_action))
 		return -EINVAL;
 
+	if (!flow_action_basic_hw_stats_types_check(flow_action, extack))
+		return -EOPNOTSUPP;
+
 	attr->flow_tag = MLX5_FS_DEFAULT_FLOW_TAG;
 
 	flow_action_for_each(i, act, flow_action) {
@@ -3270,6 +3273,9 @@ static int parse_tc_fdb_actions(struct mlx5e_priv *priv,
 	if (!flow_action_has_entries(flow_action))
 		return -EINVAL;
 
+	if (!flow_action_basic_hw_stats_types_check(flow_action, extack))
+		return -EOPNOTSUPP;
+
 	flow_action_for_each(i, act, flow_action) {
 		switch (act->id) {
 		case FLOW_ACTION_DROP:
@@ -4056,6 +4062,9 @@ static int scan_tc_matchall_fdb_actions(struct mlx5e_priv *priv,
 		return -EOPNOTSUPP;
 	}
 
+	if (!flow_action_basic_hw_stats_types_check(flow_action, extack))
+		return -EOPNOTSUPP;
+
 	flow_action_for_each(i, act, flow_action) {
 		switch (act->id) {
 		case FLOW_ACTION_POLICE:
* Unmerged path drivers/net/ethernet/mscc/ocelot_flower.c
diff --git a/drivers/net/ethernet/netronome/nfp/flower/action.c b/drivers/net/ethernet/netronome/nfp/flower/action.c
index 1b019fdfcd97..ec87afef1061 100644
--- a/drivers/net/ethernet/netronome/nfp/flower/action.c
+++ b/drivers/net/ethernet/netronome/nfp/flower/action.c
@@ -1178,6 +1178,10 @@ int nfp_flower_compile_action(struct nfp_app *app,
 	bool pkt_host = false;
 	u32 csum_updated = 0;
 
+	if (!flow_action_basic_hw_stats_types_check(&flow->rule->action,
+						    extack))
+		return -EOPNOTSUPP;
+
 	memset(nfp_flow->action_data, 0, NFP_FL_MAX_A_SIZ);
 	nfp_flow->meta.act_len = 0;
 	tun_type = NFP_FL_TUNNEL_NONE;
diff --git a/drivers/net/ethernet/qlogic/qede/qede_filter.c b/drivers/net/ethernet/qlogic/qede/qede_filter.c
index c8bdbf057d5a..31c75bd05faa 100644
--- a/drivers/net/ethernet/qlogic/qede/qede_filter.c
+++ b/drivers/net/ethernet/qlogic/qede/qede_filter.c
@@ -1746,7 +1746,8 @@ int qede_get_arfs_filter_count(struct qede_dev *edev)
 }
 
 static int qede_parse_actions(struct qede_dev *edev,
-			      struct flow_action *flow_action)
+			      struct flow_action *flow_action,
+			      struct netlink_ext_ack *extack)
 {
 	const struct flow_action_entry *act;
 	int i;
@@ -1756,6 +1757,9 @@ static int qede_parse_actions(struct qede_dev *edev,
 		return -EINVAL;
 	}
 
+	if (!flow_action_basic_hw_stats_types_check(flow_action, extack))
+		return -EOPNOTSUPP;
+
 	flow_action_for_each(i, act, flow_action) {
 		switch (act->id) {
 		case FLOW_ACTION_DROP:
@@ -1970,7 +1974,7 @@ int qede_add_tc_flower_fltr(struct qede_dev *edev, __be16 proto,
 	}
 
 	/* parse tc actions and get the vf_id */
-	if (qede_parse_actions(edev, &f->rule->action))
+	if (qede_parse_actions(edev, &f->rule->action, f->common.extack))
 		goto unlock;
 
 	if (qede_flow_find_fltr(edev, &t)) {
@@ -2038,7 +2042,7 @@ static int qede_flow_spec_validate(struct qede_dev *edev,
 		return -EINVAL;
 	}
 
-	if (qede_parse_actions(edev, flow_action))
+	if (qede_parse_actions(edev, flow_action, NULL))
 		return -EINVAL;
 
 	return 0;
* Unmerged path drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
diff --git a/include/net/flow_offload.h b/include/net/flow_offload.h
index 1dc851f1a884..3aac04fe43e5 100644
--- a/include/net/flow_offload.h
+++ b/include/net/flow_offload.h
@@ -3,6 +3,7 @@
 
 #include <linux/kernel.h>
 #include <linux/list.h>
+#include <linux/netlink.h>
 #include <net/flow_dissector.h>
 #include <linux/rhashtable.h>
 
@@ -251,6 +252,66 @@ static inline bool flow_offload_has_one_action(const struct flow_action *action)
 	return action->num_entries == 1;
 }
 
+static inline bool
+flow_action_mixed_hw_stats_types_check(const struct flow_action *action,
+				       struct netlink_ext_ack *extack)
+{
+	const struct flow_action_entry *action_entry;
+	u8 uninitialized_var(last_hw_stats_type);
+	int i;
+
+	if (flow_offload_has_one_action(action))
+		return true;
+
+	for (i = 0; i < action->num_entries; i++) {
+		action_entry = &action->entries[i];
+		if (i && action_entry->hw_stats_type != last_hw_stats_type) {
+			NL_SET_ERR_MSG_MOD(extack, "Mixing HW stats types for actions is not supported");
+			return false;
+		}
+		last_hw_stats_type = action_entry->hw_stats_type;
+	}
+	return true;
+}
+
+static inline const struct flow_action_entry *
+flow_action_first_entry_get(const struct flow_action *action)
+{
+	WARN_ON(!flow_action_has_entries(action));
+	return &action->entries[0];
+}
+
+static inline bool
+flow_action_hw_stats_types_check(const struct flow_action *action,
+				 struct netlink_ext_ack *extack,
+				 u8 allowed_hw_stats_type)
+{
+	const struct flow_action_entry *action_entry;
+
+	if (!flow_action_has_entries(action))
+		return true;
+	if (!flow_action_mixed_hw_stats_types_check(action, extack))
+		return false;
+	action_entry = flow_action_first_entry_get(action);
+	if (allowed_hw_stats_type == 0 &&
+	    action_entry->hw_stats_type != FLOW_ACTION_HW_STATS_TYPE_ANY) {
+		NL_SET_ERR_MSG_MOD(extack, "Driver supports only default HW stats type \"any\"");
+		return false;
+	} else if (allowed_hw_stats_type != 0 &&
+		   action_entry->hw_stats_type != allowed_hw_stats_type) {
+		NL_SET_ERR_MSG_MOD(extack, "Driver does not support selected HW stats type");
+		return false;
+	}
+	return true;
+}
+
+static inline bool
+flow_action_basic_hw_stats_types_check(const struct flow_action *action,
+				       struct netlink_ext_ack *extack)
+{
+	return flow_action_hw_stats_types_check(action, extack, 0);
+}
+
 #define flow_action_for_each(__i, __act, __actions)			\
         for (__i = 0, __act = &(__actions)->entries[0]; __i < (__actions)->num_entries; __act = &(__actions)->entries[++__i])
 
diff --git a/net/dsa/slave.c b/net/dsa/slave.c
index fb4f949cd420..74b64b99de6c 100644
--- a/net/dsa/slave.c
+++ b/net/dsa/slave.c
@@ -778,6 +778,10 @@ static int dsa_slave_add_cls_matchall(struct net_device *dev,
 	if (!flow_offload_has_one_action(&cls->rule->action))
 		return err;
 
+	if (!flow_action_basic_hw_stats_types_check(&cls->rule->action,
+						    cls->common.extack))
+		return err;
+
 	act = &cls->rule->action.entries[0];
 
 	if (act->id == FLOW_ACTION_MIRRED && protocol == htons(ETH_P_ALL)) {
