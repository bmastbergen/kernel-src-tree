powerpc/xive: Define xive_native_alloc_irq_on_chip()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Haren Myneni <haren@linux.ibm.com>
commit 8d0ea29db5aefd0d94fa4b6ca6124c68998f3c6a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/8d0ea29d.failed

This function allocates IRQ on a specific chip. VAS needs per chip
IRQ allocation and will have IRQ handler per VAS instance.

	Signed-off-by: Haren Myneni <haren@linux.ibm.com>
	Reviewed-by: CÃ©dric Le Goater <clg@kaod.org>
	Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
Link: https://lore.kernel.org/r/1587016720.2275.1047.camel@hbabu-laptop
(cherry picked from commit 8d0ea29db5aefd0d94fa4b6ca6124c68998f3c6a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/powerpc/include/asm/xive.h
diff --cc arch/powerpc/include/asm/xive.h
index eb2fdba95d54,d08ea11b271c..000000000000
--- a/arch/powerpc/include/asm/xive.h
+++ b/arch/powerpc/include/asm/xive.h
@@@ -83,57 -89,61 +85,83 @@@ extern bool __xive_enabled
  
  static inline bool xive_enabled(void) { return __xive_enabled; }
  
 -bool xive_spapr_init(void);
 -bool xive_native_init(void);
 -void xive_smp_probe(void);
 -int  xive_smp_prepare_cpu(unsigned int cpu);
 -void xive_smp_setup_cpu(void);
 -void xive_smp_disable_cpu(void);
 -void xive_teardown_cpu(void);
 -void xive_shutdown(void);
 -void xive_flush_interrupt(void);
 +extern bool xive_spapr_init(void);
 +extern bool xive_native_init(void);
 +extern void xive_smp_probe(void);
 +extern int  xive_smp_prepare_cpu(unsigned int cpu);
 +extern void xive_smp_setup_cpu(void);
 +extern void xive_smp_disable_cpu(void);
 +extern void xive_teardown_cpu(void);
 +extern void xive_kexec_teardown_cpu(int secondary);
 +extern void xive_shutdown(void);
 +extern void xive_flush_interrupt(void);
  
  /* xmon hook */
 -void xmon_xive_do_dump(int cpu);
 -int xmon_xive_get_irq_config(u32 hw_irq, struct irq_data *d);
 +extern void xmon_xive_do_dump(int cpu);
 +extern int xmon_xive_get_irq_config(u32 hw_irq, struct irq_data *d);
  
  /* APIs used by KVM */
++<<<<<<< HEAD
 +extern u32 xive_native_default_eq_shift(void);
 +extern u32 xive_native_alloc_vp_block(u32 max_vcpus);
 +extern void xive_native_free_vp_block(u32 vp_base);
 +extern int xive_native_populate_irq_data(u32 hw_irq,
 +					 struct xive_irq_data *data);
 +extern void xive_cleanup_irq_data(struct xive_irq_data *xd);
 +extern u32 xive_native_alloc_irq(void);
 +extern void xive_native_free_irq(u32 irq);
 +extern int xive_native_configure_irq(u32 hw_irq, u32 target, u8 prio, u32 sw_irq);
++=======
+ u32 xive_native_default_eq_shift(void);
+ u32 xive_native_alloc_vp_block(u32 max_vcpus);
+ void xive_native_free_vp_block(u32 vp_base);
+ int xive_native_populate_irq_data(u32 hw_irq,
+ 				  struct xive_irq_data *data);
+ void xive_cleanup_irq_data(struct xive_irq_data *xd);
+ void xive_native_free_irq(u32 irq);
+ int xive_native_configure_irq(u32 hw_irq, u32 target, u8 prio, u32 sw_irq);
 -
 -int xive_native_configure_queue(u32 vp_id, struct xive_q *q, u8 prio,
 -				__be32 *qpage, u32 order, bool can_escalate);
 -void xive_native_disable_queue(u32 vp_id, struct xive_q *q, u8 prio);
 -
 -void xive_native_sync_source(u32 hw_irq);
 -void xive_native_sync_queue(u32 hw_irq);
 -bool is_xive_irq(struct irq_chip *chip);
 -int xive_native_enable_vp(u32 vp_id, bool single_escalation);
 -int xive_native_disable_vp(u32 vp_id);
 -int xive_native_get_vp_info(u32 vp_id, u32 *out_cam_id, u32 *out_chip_id);
 -bool xive_native_has_single_escalation(void);
 -
 -int xive_native_get_queue_info(u32 vp_id, uint32_t prio,
 -			       u64 *out_qpage,
 -			       u64 *out_qsize,
 -			       u64 *out_qeoi_page,
 -			       u32 *out_escalate_irq,
 -			       u64 *out_qflags);
 -
++>>>>>>> 8d0ea29db5ae (powerpc/xive: Define xive_native_alloc_irq_on_chip())
 +
 +extern int xive_native_configure_queue(u32 vp_id, struct xive_q *q, u8 prio,
 +				       __be32 *qpage, u32 order, bool can_escalate);
 +extern void xive_native_disable_queue(u32 vp_id, struct xive_q *q, u8 prio);
 +
 +extern void xive_native_sync_source(u32 hw_irq);
 +extern void xive_native_sync_queue(u32 hw_irq);
 +extern bool is_xive_irq(struct irq_chip *chip);
 +extern int xive_native_enable_vp(u32 vp_id, bool single_escalation);
 +extern int xive_native_disable_vp(u32 vp_id);
 +extern int xive_native_get_vp_info(u32 vp_id, u32 *out_cam_id, u32 *out_chip_id);
 +extern bool xive_native_has_single_escalation(void);
 +
 +extern int xive_native_get_queue_info(u32 vp_id, uint32_t prio,
 +				      u64 *out_qpage,
 +				      u64 *out_qsize,
 +				      u64 *out_qeoi_page,
 +				      u32 *out_escalate_irq,
 +				      u64 *out_qflags);
 +
++<<<<<<< HEAD
 +extern int xive_native_get_queue_state(u32 vp_id, uint32_t prio, u32 *qtoggle,
 +				       u32 *qindex);
 +extern int xive_native_set_queue_state(u32 vp_id, uint32_t prio, u32 qtoggle,
 +				       u32 qindex);
 +extern int xive_native_get_vp_state(u32 vp_id, u64 *out_state);
 +extern bool xive_native_has_queue_state_support(void);
++=======
+ int xive_native_get_queue_state(u32 vp_id, uint32_t prio, u32 *qtoggle,
+ 				u32 *qindex);
+ int xive_native_set_queue_state(u32 vp_id, uint32_t prio, u32 qtoggle,
+ 				u32 qindex);
+ int xive_native_get_vp_state(u32 vp_id, u64 *out_state);
+ bool xive_native_has_queue_state_support(void);
+ extern u32 xive_native_alloc_irq_on_chip(u32 chip_id);
+ 
+ static inline u32 xive_native_alloc_irq(void)
+ {
+ 	return xive_native_alloc_irq_on_chip(OPAL_XIVE_ANY_CHIP);
+ }
++>>>>>>> 8d0ea29db5ae (powerpc/xive: Define xive_native_alloc_irq_on_chip())
  
  #else
  
* Unmerged path arch/powerpc/include/asm/xive.h
diff --git a/arch/powerpc/sysdev/xive/native.c b/arch/powerpc/sysdev/xive/native.c
index 7d5dd9328278..9ce7272a179b 100644
--- a/arch/powerpc/sysdev/xive/native.c
+++ b/arch/powerpc/sysdev/xive/native.c
@@ -281,12 +281,12 @@ static int xive_native_get_ipi(unsigned int cpu, struct xive_cpu *xc)
 }
 #endif /* CONFIG_SMP */
 
-u32 xive_native_alloc_irq(void)
+u32 xive_native_alloc_irq_on_chip(u32 chip_id)
 {
 	s64 rc;
 
 	for (;;) {
-		rc = opal_xive_allocate_irq(OPAL_XIVE_ANY_CHIP);
+		rc = opal_xive_allocate_irq(chip_id);
 		if (rc != OPAL_BUSY)
 			break;
 		msleep(1);
@@ -295,7 +295,7 @@ u32 xive_native_alloc_irq(void)
 		return 0;
 	return rc;
 }
-EXPORT_SYMBOL_GPL(xive_native_alloc_irq);
+EXPORT_SYMBOL_GPL(xive_native_alloc_irq_on_chip);
 
 void xive_native_free_irq(u32 irq)
 {
