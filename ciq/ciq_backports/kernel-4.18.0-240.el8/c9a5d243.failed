net/smc: delete an asymmetric link as SMC server

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Karsten Graul <kgraul@linux.ibm.com>
commit c9a5d243035161f06175a7c6d487c9860e0f179a
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/c9a5d243.failed

When a link group moved from asymmetric to symmetric state then the
dangling asymmetric link can be deleted. Add smc_llc_find_asym_link() to
find the respective link and add smc_llc_delete_asym_link() to delete
it.

	Signed-off-by: Karsten Graul <kgraul@linux.ibm.com>
	Reviewed-by: Ursula Braun <ubraun@linux.ibm.com>
	Signed-off-by: David S. Miller <davem@davemloft.net>
(cherry picked from commit c9a5d243035161f06175a7c6d487c9860e0f179a)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	net/smc/smc_llc.c
diff --cc net/smc/smc_llc.c
index 4119cdb6b6bf,9d102c912be9..000000000000
--- a/net/smc/smc_llc.c
+++ b/net/smc/smc_llc.c
@@@ -398,161 -779,598 +398,477 @@@ static int smc_llc_send_message(struct 
  	return 0;
  }
  
 -static void smc_llc_save_add_link_info(struct smc_link *link,
 -				       struct smc_llc_msg_add_link *add_llc)
 -{
 -	link->peer_qpn = ntoh24(add_llc->sender_qp_num);
 -	memcpy(link->peer_gid, add_llc->sender_gid, SMC_GID_SIZE);
 -	memcpy(link->peer_mac, add_llc->sender_mac, ETH_ALEN);
 -	link->peer_psn = ntoh24(add_llc->initial_psn);
 -	link->peer_mtu = add_llc->qp_mtu;
 -}
 +/********************************* receive ***********************************/
  
 -/* as an SMC client, process an add link request */
 -int smc_llc_cli_add_link(struct smc_link *link, struct smc_llc_qentry *qentry)
 +static void smc_llc_rx_confirm_link(struct smc_link *link,
 +				    struct smc_llc_msg_confirm_link *llc)
  {
 -	struct smc_llc_msg_add_link *llc = &qentry->msg.add_link;
 -	enum smc_lgr_type lgr_new_t = SMC_LGR_SYMMETRIC;
  	struct smc_link_group *lgr = smc_get_lgr(link);
 -	struct smc_link *lnk_new = NULL;
 -	struct smc_init_info ini;
 -	int lnk_idx, rc = 0;
 +	int conf_rc;
  
++<<<<<<< HEAD
 +	/* RMBE eyecatchers are not supported */
 +	if (llc->hd.flags & SMC_LLC_FLAG_NO_RMBE_EYEC)
 +		conf_rc = 0;
++=======
+ 	ini.vlan_id = lgr->vlan_id;
+ 	smc_pnet_find_alt_roce(lgr, &ini, link->smcibdev);
+ 	if (!memcmp(llc->sender_gid, link->peer_gid, SMC_GID_SIZE) &&
+ 	    !memcmp(llc->sender_mac, link->peer_mac, ETH_ALEN)) {
+ 		if (!ini.ib_dev)
+ 			goto out_reject;
+ 		lgr_new_t = SMC_LGR_ASYMMETRIC_PEER;
+ 	}
+ 	if (!ini.ib_dev) {
+ 		lgr_new_t = SMC_LGR_ASYMMETRIC_LOCAL;
+ 		ini.ib_dev = link->smcibdev;
+ 		ini.ib_port = link->ibport;
+ 	}
+ 	lnk_idx = smc_llc_alloc_alt_link(lgr, lgr_new_t);
+ 	if (lnk_idx < 0)
+ 		goto out_reject;
+ 	lnk_new = &lgr->lnk[lnk_idx];
+ 	rc = smcr_link_init(lgr, lnk_new, lnk_idx, &ini);
+ 	if (rc)
+ 		goto out_reject;
+ 	smc_llc_save_add_link_info(lnk_new, llc);
+ 	lnk_new->link_id = llc->link_num;
+ 
+ 	rc = smc_ib_ready_link(lnk_new);
+ 	if (rc)
+ 		goto out_clear_lnk;
+ 
+ 	rc = smcr_buf_map_lgr(lnk_new);
+ 	if (rc)
+ 		goto out_clear_lnk;
+ 
+ 	rc = smc_llc_send_add_link(link,
+ 				   lnk_new->smcibdev->mac[ini.ib_port - 1],
+ 				   lnk_new->gid, lnk_new, SMC_LLC_RESP);
+ 	if (rc)
+ 		goto out_clear_lnk;
+ 	rc = smc_llc_cli_rkey_exchange(link, lnk_new);
+ 	if (rc) {
+ 		rc = 0;
+ 		goto out_clear_lnk;
+ 	}
+ 	rc = smc_llc_cli_conf_link(link, &ini, lnk_new, lgr_new_t);
+ 	if (!rc)
+ 		goto out;
+ out_clear_lnk:
+ 	smcr_link_clear(lnk_new);
+ out_reject:
+ 	smc_llc_cli_add_link_reject(qentry);
+ out:
+ 	kfree(qentry);
+ 	return rc;
+ }
+ 
+ static void smc_llc_process_cli_add_link(struct smc_link_group *lgr)
+ {
+ 	struct smc_llc_qentry *qentry;
+ 
+ 	qentry = smc_llc_flow_qentry_clr(&lgr->llc_flow_lcl);
+ 
+ 	mutex_lock(&lgr->llc_conf_mutex);
+ 	smc_llc_cli_add_link(qentry->link, qentry);
+ 	mutex_unlock(&lgr->llc_conf_mutex);
+ }
+ 
+ /* find the asymmetric link when 3 links are established  */
+ static struct smc_link *smc_llc_find_asym_link(struct smc_link_group *lgr)
+ {
+ 	int asym_idx = -ENOENT;
+ 	int i, j, k;
+ 	bool found;
+ 
+ 	/* determine asymmetric link */
+ 	found = false;
+ 	for (i = 0; i < SMC_LINKS_PER_LGR_MAX; i++) {
+ 		for (j = i + 1; j < SMC_LINKS_PER_LGR_MAX; j++) {
+ 			if (!smc_link_usable(&lgr->lnk[i]) ||
+ 			    !smc_link_usable(&lgr->lnk[j]))
+ 				continue;
+ 			if (!memcmp(lgr->lnk[i].gid, lgr->lnk[j].gid,
+ 				    SMC_GID_SIZE)) {
+ 				found = true;	/* asym_lnk is i or j */
+ 				break;
+ 			}
+ 		}
+ 		if (found)
+ 			break;
+ 	}
+ 	if (!found)
+ 		goto out; /* no asymmetric link */
+ 	for (k = 0; k < SMC_LINKS_PER_LGR_MAX; k++) {
+ 		if (!smc_link_usable(&lgr->lnk[k]))
+ 			continue;
+ 		if (k != i &&
+ 		    !memcmp(lgr->lnk[i].peer_gid, lgr->lnk[k].peer_gid,
+ 			    SMC_GID_SIZE)) {
+ 			asym_idx = i;
+ 			break;
+ 		}
+ 		if (k != j &&
+ 		    !memcmp(lgr->lnk[j].peer_gid, lgr->lnk[k].peer_gid,
+ 			    SMC_GID_SIZE)) {
+ 			asym_idx = j;
+ 			break;
+ 		}
+ 	}
+ out:
+ 	return (asym_idx < 0) ? NULL : &lgr->lnk[asym_idx];
+ }
+ 
+ static void smc_llc_delete_asym_link(struct smc_link_group *lgr)
+ {
+ 	struct smc_link *lnk_new = NULL, *lnk_asym;
+ 	struct smc_llc_qentry *qentry;
+ 	int rc;
+ 
+ 	lnk_asym = smc_llc_find_asym_link(lgr);
+ 	if (!lnk_asym)
+ 		return; /* no asymmetric link */
+ 	if (!smc_link_downing(&lnk_asym->state))
+ 		return;
+ 	/* tbd: lnk_new = smc_switch_conns(lgr, lnk_asym, false); */
+ 	smc_wr_tx_wait_no_pending_sends(lnk_asym);
+ 	if (!lnk_new)
+ 		goto out_free;
+ 	/* change flow type from ADD_LINK into DEL_LINK */
+ 	lgr->llc_flow_lcl.type = SMC_LLC_FLOW_DEL_LINK;
+ 	rc = smc_llc_send_delete_link(lnk_new, lnk_asym->link_id, SMC_LLC_REQ,
+ 				      true, SMC_LLC_DEL_NO_ASYM_NEEDED);
+ 	if (rc) {
+ 		smcr_link_down_cond(lnk_new);
+ 		goto out_free;
+ 	}
+ 	qentry = smc_llc_wait(lgr, lnk_new, SMC_LLC_WAIT_TIME,
+ 			      SMC_LLC_DELETE_LINK);
+ 	if (!qentry) {
+ 		smcr_link_down_cond(lnk_new);
+ 		goto out_free;
+ 	}
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ out_free:
+ 	smcr_link_clear(lnk_asym);
+ }
+ 
+ static int smc_llc_srv_rkey_exchange(struct smc_link *link,
+ 				     struct smc_link *link_new)
+ {
+ 	struct smc_llc_msg_add_link_cont *addc_llc;
+ 	struct smc_link_group *lgr = link->lgr;
+ 	u8 max, num_rkeys_send, num_rkeys_recv;
+ 	struct smc_llc_qentry *qentry = NULL;
+ 	struct smc_buf_desc *buf_pos;
+ 	int buf_lst;
+ 	int rc = 0;
+ 	int i;
+ 
+ 	mutex_lock(&lgr->rmbs_lock);
+ 	num_rkeys_send = lgr->conns_num;
+ 	buf_pos = smc_llc_get_first_rmb(lgr, &buf_lst);
+ 	do {
+ 		smc_llc_add_link_cont(link, link_new, &num_rkeys_send,
+ 				      &buf_lst, &buf_pos);
+ 		qentry = smc_llc_wait(lgr, link, SMC_LLC_WAIT_TIME,
+ 				      SMC_LLC_ADD_LINK_CONT);
+ 		if (!qentry) {
+ 			rc = -ETIMEDOUT;
+ 			goto out;
+ 		}
+ 		addc_llc = &qentry->msg.add_link_cont;
+ 		num_rkeys_recv = addc_llc->num_rkeys;
+ 		max = min_t(u8, num_rkeys_recv, SMC_LLC_RKEYS_PER_CONT_MSG);
+ 		for (i = 0; i < max; i++) {
+ 			smc_rtoken_set(lgr, link->link_idx, link_new->link_idx,
+ 				       addc_llc->rt[i].rmb_key,
+ 				       addc_llc->rt[i].rmb_vaddr_new,
+ 				       addc_llc->rt[i].rmb_key_new);
+ 			num_rkeys_recv--;
+ 		}
+ 		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 	} while (num_rkeys_send || num_rkeys_recv);
+ out:
+ 	mutex_unlock(&lgr->rmbs_lock);
+ 	return rc;
+ }
+ 
+ static int smc_llc_srv_conf_link(struct smc_link *link,
+ 				 struct smc_link *link_new,
+ 				 enum smc_lgr_type lgr_new_t)
+ {
+ 	struct smc_link_group *lgr = link->lgr;
+ 	struct smc_llc_qentry *qentry = NULL;
+ 	int rc;
+ 
+ 	/* send CONFIRM LINK request over the RoCE fabric */
+ 	rc = smc_llc_send_confirm_link(link_new, SMC_LLC_REQ);
+ 	if (rc)
+ 		return -ENOLINK;
+ 	/* receive CONFIRM LINK response over the RoCE fabric */
+ 	qentry = smc_llc_wait(lgr, link, SMC_LLC_WAIT_FIRST_TIME,
+ 			      SMC_LLC_CONFIRM_LINK);
+ 	if (!qentry) {
+ 		/* send DELETE LINK */
+ 		smc_llc_send_delete_link(link, link_new->link_id, SMC_LLC_REQ,
+ 					 false, SMC_LLC_DEL_LOST_PATH);
+ 		return -ENOLINK;
+ 	}
+ 	smc_llc_link_active(link_new);
+ 	lgr->type = lgr_new_t;
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 	return 0;
+ }
+ 
+ int smc_llc_srv_add_link(struct smc_link *link)
+ {
+ 	enum smc_lgr_type lgr_new_t = SMC_LGR_SYMMETRIC;
+ 	struct smc_link_group *lgr = link->lgr;
+ 	struct smc_llc_msg_add_link *add_llc;
+ 	struct smc_llc_qentry *qentry = NULL;
+ 	struct smc_link *link_new;
+ 	struct smc_init_info ini;
+ 	int lnk_idx, rc = 0;
+ 
+ 	/* ignore client add link recommendation, start new flow */
+ 	ini.vlan_id = lgr->vlan_id;
+ 	smc_pnet_find_alt_roce(lgr, &ini, link->smcibdev);
+ 	if (!ini.ib_dev) {
+ 		lgr_new_t = SMC_LGR_ASYMMETRIC_LOCAL;
+ 		ini.ib_dev = link->smcibdev;
+ 		ini.ib_port = link->ibport;
+ 	}
+ 	lnk_idx = smc_llc_alloc_alt_link(lgr, lgr_new_t);
+ 	if (lnk_idx < 0)
+ 		return 0;
+ 
+ 	rc = smcr_link_init(lgr, &lgr->lnk[lnk_idx], lnk_idx, &ini);
+ 	if (rc)
+ 		return rc;
+ 	link_new = &lgr->lnk[lnk_idx];
+ 	rc = smc_llc_send_add_link(link,
+ 				   link_new->smcibdev->mac[ini.ib_port - 1],
+ 				   link_new->gid, link_new, SMC_LLC_REQ);
+ 	if (rc)
+ 		goto out_err;
+ 	/* receive ADD LINK response over the RoCE fabric */
+ 	qentry = smc_llc_wait(lgr, link, SMC_LLC_WAIT_TIME, SMC_LLC_ADD_LINK);
+ 	if (!qentry) {
+ 		rc = -ETIMEDOUT;
+ 		goto out_err;
+ 	}
+ 	add_llc = &qentry->msg.add_link;
+ 	if (add_llc->hd.flags & SMC_LLC_FLAG_ADD_LNK_REJ) {
+ 		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 		rc = -ENOLINK;
+ 		goto out_err;
+ 	}
+ 	if (lgr->type == SMC_LGR_SINGLE &&
+ 	    (!memcmp(add_llc->sender_gid, link->peer_gid, SMC_GID_SIZE) &&
+ 	     !memcmp(add_llc->sender_mac, link->peer_mac, ETH_ALEN))) {
+ 		lgr_new_t = SMC_LGR_ASYMMETRIC_PEER;
+ 	}
+ 	smc_llc_save_add_link_info(link_new, add_llc);
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 
+ 	rc = smc_ib_ready_link(link_new);
+ 	if (rc)
+ 		goto out_err;
+ 	rc = smcr_buf_map_lgr(link_new);
+ 	if (rc)
+ 		goto out_err;
+ 	rc = smcr_buf_reg_lgr(link_new);
+ 	if (rc)
+ 		goto out_err;
+ 	rc = smc_llc_srv_rkey_exchange(link, link_new);
+ 	if (rc)
+ 		goto out_err;
+ 	rc = smc_llc_srv_conf_link(link, link_new, lgr_new_t);
+ 	if (rc)
+ 		goto out_err;
+ 	return 0;
+ out_err:
+ 	smcr_link_clear(link_new);
+ 	return rc;
+ }
+ 
+ static void smc_llc_process_srv_add_link(struct smc_link_group *lgr)
+ {
+ 	struct smc_link *link = lgr->llc_flow_lcl.qentry->link;
+ 	int rc;
+ 
+ 	smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 
+ 	mutex_lock(&lgr->llc_conf_mutex);
+ 	rc = smc_llc_srv_add_link(link);
+ 	if (!rc && lgr->type == SMC_LGR_SYMMETRIC) {
+ 		/* delete any asymmetric link */
+ 		smc_llc_delete_asym_link(lgr);
+ 	}
+ 	mutex_unlock(&lgr->llc_conf_mutex);
+ }
+ 
+ /* worker to process an add link message */
+ static void smc_llc_add_link_work(struct work_struct *work)
+ {
+ 	struct smc_link_group *lgr = container_of(work, struct smc_link_group,
+ 						  llc_add_link_work);
+ 
+ 	if (list_empty(&lgr->list)) {
+ 		/* link group is terminating */
+ 		smc_llc_flow_qentry_del(&lgr->llc_flow_lcl);
+ 		goto out;
+ 	}
+ 
+ 	if (lgr->role == SMC_CLNT)
+ 		smc_llc_process_cli_add_link(lgr);
++>>>>>>> c9a5d2430351 (net/smc: delete an asymmetric link as SMC server)
  	else
 -		smc_llc_process_srv_add_link(lgr);
 -out:
 -	smc_llc_flow_stop(lgr, &lgr->llc_flow_lcl);
 -}
 +		conf_rc = ENOTSUPP;
  
 -static void smc_llc_rx_delete_link(struct smc_link *link,
 -				   struct smc_llc_msg_del_link *llc)
 -{
 -	struct smc_link_group *lgr = smc_get_lgr(link);
 -
 -	smc_lgr_forget(lgr);
 -	if (lgr->role == SMC_SERV) {
 -		/* client asks to delete this link, send request */
 -		smc_llc_send_delete_link(link, 0, SMC_LLC_REQ, true,
 -					 SMC_LLC_DEL_PROG_INIT_TERM);
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (lgr->role == SMC_SERV &&
 +		    link->state == SMC_LNK_ACTIVATING) {
 +			link->llc_confirm_resp_rc = conf_rc;
 +			complete(&link->llc_confirm_resp);
 +		}
  	} else {
 -		/* server requests to delete this link, send response */
 -		smc_llc_send_delete_link(link, 0, SMC_LLC_RESP, true,
 -					 SMC_LLC_DEL_PROG_INIT_TERM);
 +		if (lgr->role == SMC_CLNT &&
 +		    link->state == SMC_LNK_ACTIVATING) {
 +			link->llc_confirm_rc = conf_rc;
 +			link->link_id = llc->link_num;
 +			complete(&link->llc_confirm);
 +		}
  	}
 -	smcr_link_down_cond(link);
  }
  
 -/* process a confirm_rkey request from peer, remote flow */
 -static void smc_llc_rmt_conf_rkey(struct smc_link_group *lgr)
 +static void smc_llc_rx_add_link(struct smc_link *link,
 +				struct smc_llc_msg_add_link *llc)
  {
 -	struct smc_llc_msg_confirm_rkey *llc;
 -	struct smc_llc_qentry *qentry;
 -	struct smc_link *link;
 -	int num_entries;
 -	int rk_idx;
 -	int i;
 -
 -	qentry = lgr->llc_flow_rmt.qentry;
 -	llc = &qentry->msg.confirm_rkey;
 -	link = qentry->link;
 -
 -	num_entries = llc->rtoken[0].num_rkeys;
 -	/* first rkey entry is for receiving link */
 -	rk_idx = smc_rtoken_add(link,
 -				llc->rtoken[0].rmb_vaddr,
 -				llc->rtoken[0].rmb_key);
 -	if (rk_idx < 0)
 -		goto out_err;
 -
 -	for (i = 1; i <= min_t(u8, num_entries, SMC_LLC_RKEYS_PER_MSG - 1); i++)
 -		smc_rtoken_set2(lgr, rk_idx, llc->rtoken[i].link_id,
 -				llc->rtoken[i].rmb_vaddr,
 -				llc->rtoken[i].rmb_key);
 -	/* max links is 3 so there is no need to support conf_rkey_cont msgs */
 -	goto out;
 -out_err:
 -	llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 -	llc->hd.flags |= SMC_LLC_FLAG_RKEY_RETRY;
 -out:
 -	llc->hd.flags |= SMC_LLC_FLAG_RESP;
 -	smc_llc_send_message(link, &qentry->msg);
 -	smc_llc_flow_qentry_del(&lgr->llc_flow_rmt);
 -}
 +	struct smc_link_group *lgr = smc_get_lgr(link);
  
 -/* process a delete_rkey request from peer, remote flow */
 -static void smc_llc_rmt_delete_rkey(struct smc_link_group *lgr)
 -{
 -	struct smc_llc_msg_delete_rkey *llc;
 -	struct smc_llc_qentry *qentry;
 -	struct smc_link *link;
 -	u8 err_mask = 0;
 -	int i, max;
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (link->state == SMC_LNK_ACTIVATING)
 +			complete(&link->llc_add_resp);
 +	} else {
 +		if (link->state == SMC_LNK_ACTIVATING) {
 +			complete(&link->llc_add);
 +			return;
 +		}
  
 -	qentry = lgr->llc_flow_rmt.qentry;
 -	llc = &qentry->msg.delete_rkey;
 -	link = qentry->link;
 +		if (lgr->role == SMC_SERV) {
 +			smc_llc_prep_add_link(llc, link,
 +					link->smcibdev->mac[link->ibport - 1],
 +					link->gid, SMC_LLC_REQ);
  
 -	max = min_t(u8, llc->num_rkeys, SMC_LLC_DEL_RKEY_MAX);
 -	for (i = 0; i < max; i++) {
 -		if (smc_rtoken_delete(link, llc->rkey[i]))
 -			err_mask |= 1 << (SMC_LLC_DEL_RKEY_MAX - 1 - i);
 -	}
 -	if (err_mask) {
 -		llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 -		llc->err_mask = err_mask;
 +		} else {
 +			smc_llc_prep_add_link(llc, link,
 +					link->smcibdev->mac[link->ibport - 1],
 +					link->gid, SMC_LLC_RESP);
 +		}
 +		smc_llc_send_message(link, llc, sizeof(*llc));
  	}
 -	llc->hd.flags |= SMC_LLC_FLAG_RESP;
 -	smc_llc_send_message(link, &qentry->msg);
 -	smc_llc_flow_qentry_del(&lgr->llc_flow_rmt);
  }
  
 -/* flush the llc event queue */
 -static void smc_llc_event_flush(struct smc_link_group *lgr)
 +static void smc_llc_rx_delete_link(struct smc_link *link,
 +				   struct smc_llc_msg_del_link *llc)
  {
 -	struct smc_llc_qentry *qentry, *q;
 +	struct smc_link_group *lgr = smc_get_lgr(link);
  
 -	spin_lock_bh(&lgr->llc_event_q_lock);
 -	list_for_each_entry_safe(qentry, q, &lgr->llc_event_q, list) {
 -		list_del_init(&qentry->list);
 -		kfree(qentry);
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (lgr->role == SMC_SERV)
 +			smc_lgr_schedule_free_work_fast(lgr);
 +	} else {
 +		smc_lgr_forget(lgr);
 +		smc_llc_link_deleting(link);
 +		if (lgr->role == SMC_SERV) {
 +			/* client asks to delete this link, send request */
 +			smc_llc_prep_delete_link(llc, link, SMC_LLC_REQ, true);
 +		} else {
 +			/* server requests to delete this link, send response */
 +			smc_llc_prep_delete_link(llc, link, SMC_LLC_RESP, true);
 +		}
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +		smc_lgr_terminate_sched(lgr);
  	}
 -	spin_unlock_bh(&lgr->llc_event_q_lock);
  }
  
 -static void smc_llc_event_handler(struct smc_llc_qentry *qentry)
 +static void smc_llc_rx_test_link(struct smc_link *link,
 +				 struct smc_llc_msg_test_link *llc)
  {
 -	union smc_llc_msg *llc = &qentry->msg;
 -	struct smc_link *link = qentry->link;
 -	struct smc_link_group *lgr = link->lgr;
 -
 -	if (!smc_link_usable(link))
 -		goto out;
 -
 -	switch (llc->raw.hdr.common.type) {
 -	case SMC_LLC_TEST_LINK:
 -		llc->test_link.hd.flags |= SMC_LLC_FLAG_RESP;
 -		smc_llc_send_message(link, llc);
 -		break;
 -	case SMC_LLC_ADD_LINK:
 -		if (list_empty(&lgr->list))
 -			goto out;	/* lgr is terminating */
 -		if (lgr->role == SMC_CLNT) {
 -			if (lgr->llc_flow_lcl.type == SMC_LLC_FLOW_ADD_LINK) {
 -				/* a flow is waiting for this message */
 -				smc_llc_flow_qentry_set(&lgr->llc_flow_lcl,
 -							qentry);
 -				wake_up_interruptible(&lgr->llc_waiter);
 -			} else if (smc_llc_flow_start(&lgr->llc_flow_lcl,
 -						      qentry)) {
 -				schedule_work(&lgr->llc_add_link_work);
 -			}
 -		} else if (smc_llc_flow_start(&lgr->llc_flow_lcl, qentry)) {
 -			/* as smc server, handle client suggestion */
 -			schedule_work(&lgr->llc_add_link_work);
 -		}
 -		return;
 -	case SMC_LLC_CONFIRM_LINK:
 -	case SMC_LLC_ADD_LINK_CONT:
 -		if (lgr->llc_flow_lcl.type != SMC_LLC_FLOW_NONE) {
 -			/* a flow is waiting for this message */
 -			smc_llc_flow_qentry_set(&lgr->llc_flow_lcl, qentry);
 -			wake_up_interruptible(&lgr->llc_waiter);
 -			return;
 -		}
 -		break;
 -	case SMC_LLC_DELETE_LINK:
 -		smc_llc_rx_delete_link(link, &llc->delete_link);
 -		break;
 -	case SMC_LLC_CONFIRM_RKEY:
 -		/* new request from remote, assign to remote flow */
 -		if (smc_llc_flow_start(&lgr->llc_flow_rmt, qentry)) {
 -			/* process here, does not wait for more llc msgs */
 -			smc_llc_rmt_conf_rkey(lgr);
 -			smc_llc_flow_stop(lgr, &lgr->llc_flow_rmt);
 -		}
 -		return;
 -	case SMC_LLC_CONFIRM_RKEY_CONT:
 -		/* not used because max links is 3, and 3 rkeys fit into
 -		 * one CONFIRM_RKEY message
 -		 */
 -		break;
 -	case SMC_LLC_DELETE_RKEY:
 -		/* new request from remote, assign to remote flow */
 -		if (smc_llc_flow_start(&lgr->llc_flow_rmt, qentry)) {
 -			/* process here, does not wait for more llc msgs */
 -			smc_llc_rmt_delete_rkey(lgr);
 -			smc_llc_flow_stop(lgr, &lgr->llc_flow_rmt);
 -		}
 -		return;
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		if (link->state == SMC_LNK_ACTIVE)
 +			complete(&link->llc_testlink_resp);
 +	} else {
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
  	}
 -out:
 -	kfree(qentry);
  }
  
 -/* worker to process llc messages on the event queue */
 -static void smc_llc_event_work(struct work_struct *work)
 +static void smc_llc_rx_confirm_rkey(struct smc_link *link,
 +				    struct smc_llc_msg_confirm_rkey *llc)
  {
 -	struct smc_link_group *lgr = container_of(work, struct smc_link_group,
 -						  llc_event_work);
 -	struct smc_llc_qentry *qentry;
 +	int rc;
  
 -	if (!lgr->llc_flow_lcl.type && lgr->delayed_event) {
 -		if (smc_link_usable(lgr->delayed_event->link)) {
 -			smc_llc_event_handler(lgr->delayed_event);
 -		} else {
 -			qentry = lgr->delayed_event;
 -			lgr->delayed_event = NULL;
 -			kfree(qentry);
 -		}
 -	}
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		link->llc_confirm_rkey_rc = llc->hd.flags &
 +					    SMC_LLC_FLAG_RKEY_NEG;
 +		complete(&link->llc_confirm_rkey);
 +	} else {
 +		rc = smc_rtoken_add(link,
 +				    llc->rtoken[0].rmb_vaddr,
 +				    llc->rtoken[0].rmb_key);
  
 -again:
 -	spin_lock_bh(&lgr->llc_event_q_lock);
 -	if (!list_empty(&lgr->llc_event_q)) {
 -		qentry = list_first_entry(&lgr->llc_event_q,
 -					  struct smc_llc_qentry, list);
 -		list_del_init(&qentry->list);
 -		spin_unlock_bh(&lgr->llc_event_q_lock);
 -		smc_llc_event_handler(qentry);
 -		goto again;
 +		/* ignore rtokens for other links, we have only one link */
 +
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		if (rc < 0)
 +			llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
  	}
 -	spin_unlock_bh(&lgr->llc_event_q_lock);
  }
  
 -/* process llc responses in tasklet context */
 -static void smc_llc_rx_response(struct smc_link *link,
 -				struct smc_llc_qentry *qentry)
 +static void smc_llc_rx_confirm_rkey_cont(struct smc_link *link,
 +				      struct smc_llc_msg_confirm_rkey_cont *llc)
  {
 -	u8 llc_type = qentry->msg.raw.hdr.common.type;
 -
 -	switch (llc_type) {
 -	case SMC_LLC_TEST_LINK:
 -		if (link->state == SMC_LNK_ACTIVE)
 -			complete(&link->llc_testlink_resp);
 -		break;
 -	case SMC_LLC_ADD_LINK:
 -	case SMC_LLC_CONFIRM_LINK:
 -	case SMC_LLC_ADD_LINK_CONT:
 -	case SMC_LLC_CONFIRM_RKEY:
 -	case SMC_LLC_DELETE_RKEY:
 -		/* assign responses to the local flow, we requested them */
 -		smc_llc_flow_qentry_set(&link->lgr->llc_flow_lcl, qentry);
 -		wake_up_interruptible(&link->lgr->llc_waiter);
 -		return;
 -	case SMC_LLC_DELETE_LINK:
 -		if (link->lgr->role == SMC_SERV)
 -			smc_lgr_schedule_free_work_fast(link->lgr);
 -		break;
 -	case SMC_LLC_CONFIRM_RKEY_CONT:
 -		/* not used because max links is 3 */
 -		break;
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		/* unused as long as we don't send this type of msg */
 +	} else {
 +		/* ignore rtokens for other links, we have only one link */
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
  	}
 -	kfree(qentry);
  }
  
 -static void smc_llc_enqueue(struct smc_link *link, union smc_llc_msg *llc)
 +static void smc_llc_rx_delete_rkey(struct smc_link *link,
 +				   struct smc_llc_msg_delete_rkey *llc)
  {
 -	struct smc_link_group *lgr = link->lgr;
 -	struct smc_llc_qentry *qentry;
 -	unsigned long flags;
 +	u8 err_mask = 0;
 +	int i, max;
  
 -	qentry = kmalloc(sizeof(*qentry), GFP_ATOMIC);
 -	if (!qentry)
 -		return;
 -	qentry->link = link;
 -	INIT_LIST_HEAD(&qentry->list);
 -	memcpy(&qentry->msg, llc, sizeof(union smc_llc_msg));
 +	if (llc->hd.flags & SMC_LLC_FLAG_RESP) {
 +		link->llc_delete_rkey_rc = llc->hd.flags &
 +					    SMC_LLC_FLAG_RKEY_NEG;
 +		complete(&link->llc_delete_rkey);
 +	} else {
 +		max = min_t(u8, llc->num_rkeys, SMC_LLC_DEL_RKEY_MAX);
 +		for (i = 0; i < max; i++) {
 +			if (smc_rtoken_delete(link, llc->rkey[i]))
 +				err_mask |= 1 << (SMC_LLC_DEL_RKEY_MAX - 1 - i);
 +		}
  
 -	/* process responses immediately */
 -	if (llc->raw.hdr.flags & SMC_LLC_FLAG_RESP) {
 -		smc_llc_rx_response(link, qentry);
 -		return;
 -	}
 +		if (err_mask) {
 +			llc->hd.flags |= SMC_LLC_FLAG_RKEY_NEG;
 +			llc->err_mask = err_mask;
 +		}
  
 -	/* add requests to event queue */
 -	spin_lock_irqsave(&lgr->llc_event_q_lock, flags);
 -	list_add_tail(&qentry->list, &lgr->llc_event_q);
 -	spin_unlock_irqrestore(&lgr->llc_event_q_lock, flags);
 -	schedule_work(&link->lgr->llc_event_work);
 +		llc->hd.flags |= SMC_LLC_FLAG_RESP;
 +		smc_llc_send_message(link, llc, sizeof(*llc));
 +	}
  }
  
 -/* copy received msg and add it to the event queue */
  static void smc_llc_rx_handler(struct ib_wc *wc, void *buf)
  {
  	struct smc_link *link = (struct smc_link *)wc->qp->qp_context;
* Unmerged path net/smc/smc_llc.c
diff --git a/net/smc/smc_wr.c b/net/smc/smc_wr.c
index 337ee52ad3d3..18993ed60b9d 100644
--- a/net/smc/smc_wr.c
+++ b/net/smc/smc_wr.c
@@ -61,7 +61,7 @@ static inline bool smc_wr_is_tx_pend(struct smc_link *link)
 }
 
 /* wait till all pending tx work requests on the given link are completed */
-static inline int smc_wr_tx_wait_no_pending_sends(struct smc_link *link)
+int smc_wr_tx_wait_no_pending_sends(struct smc_link *link)
 {
 	if (wait_event_timeout(link->wr_tx_wait, !smc_wr_is_tx_pend(link),
 			       SMC_WR_TX_WAIT_PENDING_TIME))
diff --git a/net/smc/smc_wr.h b/net/smc/smc_wr.h
index 3ac99c898418..f7eaeb3391f3 100644
--- a/net/smc/smc_wr.h
+++ b/net/smc/smc_wr.h
@@ -106,6 +106,7 @@ void smc_wr_tx_dismiss_slots(struct smc_link *lnk, u8 wr_rx_hdr_type,
 			     smc_wr_tx_filter filter,
 			     smc_wr_tx_dismisser dismisser,
 			     unsigned long data);
+int smc_wr_tx_wait_no_pending_sends(struct smc_link *link);
 
 int smc_wr_rx_register_handler(struct smc_wr_rx_handler *handler);
 int smc_wr_rx_post_init(struct smc_link *link);
