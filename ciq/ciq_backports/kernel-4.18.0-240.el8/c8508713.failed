net/mlx5: E-Switch, free flow_group_in after creating the restore table

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Roi Dayan <roid@mellanox.com>
commit c8508713c71c21f5a16469dcc75ffb4381fbfeb4
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/c8508713.failed

We allocate a temporary memory but forget to free it.

Fixes: 11b717d61526 ("net/mlx5: E-Switch, Get reg_c0 value on CQE")
	Signed-off-by: Roi Dayan <roid@mellanox.com>
	Reviewed-by: Paul Blakey <paulb@mellanox.com>
	Signed-off-by: Saeed Mahameed <saeedm@mellanox.com>
(cherry picked from commit c8508713c71c21f5a16469dcc75ffb4381fbfeb4)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
diff --cc drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
index 1f7d3f1673cb,088fb51123e2..000000000000
--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@@ -1370,6 -1438,148 +1370,151 @@@ out
  	return flow_rule;
  }
  
++<<<<<<< HEAD
++=======
+ 
+ static int mlx5_eswitch_inline_mode_get(const struct mlx5_eswitch *esw, u8 *mode)
+ {
+ 	u8 prev_mlx5_mode, mlx5_mode = MLX5_INLINE_MODE_L2;
+ 	struct mlx5_core_dev *dev = esw->dev;
+ 	int vport;
+ 
+ 	if (!MLX5_CAP_GEN(dev, vport_group_manager))
+ 		return -EOPNOTSUPP;
+ 
+ 	if (esw->mode == MLX5_ESWITCH_NONE)
+ 		return -EOPNOTSUPP;
+ 
+ 	switch (MLX5_CAP_ETH(dev, wqe_inline_mode)) {
+ 	case MLX5_CAP_INLINE_MODE_NOT_REQUIRED:
+ 		mlx5_mode = MLX5_INLINE_MODE_NONE;
+ 		goto out;
+ 	case MLX5_CAP_INLINE_MODE_L2:
+ 		mlx5_mode = MLX5_INLINE_MODE_L2;
+ 		goto out;
+ 	case MLX5_CAP_INLINE_MODE_VPORT_CONTEXT:
+ 		goto query_vports;
+ 	}
+ 
+ query_vports:
+ 	mlx5_query_nic_vport_min_inline(dev, esw->first_host_vport, &prev_mlx5_mode);
+ 	mlx5_esw_for_each_host_func_vport(esw, vport, esw->esw_funcs.num_vfs) {
+ 		mlx5_query_nic_vport_min_inline(dev, vport, &mlx5_mode);
+ 		if (prev_mlx5_mode != mlx5_mode)
+ 			return -EINVAL;
+ 		prev_mlx5_mode = mlx5_mode;
+ 	}
+ 
+ out:
+ 	*mode = mlx5_mode;
+ 	return 0;
+ }       
+ 
+ static void esw_destroy_restore_table(struct mlx5_eswitch *esw)
+ {
+ 	struct mlx5_esw_offload *offloads = &esw->offloads;
+ 
+ 	if (!mlx5_eswitch_reg_c1_loopback_supported(esw))
+ 		return;
+ 
+ 	mlx5_modify_header_dealloc(esw->dev, offloads->restore_copy_hdr_id);
+ 	mlx5_destroy_flow_group(offloads->restore_group);
+ 	mlx5_destroy_flow_table(offloads->ft_offloads_restore);
+ }
+ 
+ static int esw_create_restore_table(struct mlx5_eswitch *esw)
+ {
+ 	u8 modact[MLX5_UN_SZ_BYTES(set_action_in_add_action_in_auto)] = {};
+ 	int inlen = MLX5_ST_SZ_BYTES(create_flow_group_in);
+ 	struct mlx5_flow_table_attr ft_attr = {};
+ 	struct mlx5_core_dev *dev = esw->dev;
+ 	struct mlx5_flow_namespace *ns;
+ 	struct mlx5_modify_hdr *mod_hdr;
+ 	void *match_criteria, *misc;
+ 	struct mlx5_flow_table *ft;
+ 	struct mlx5_flow_group *g;
+ 	u32 *flow_group_in;
+ 	int err = 0;
+ 
+ 	if (!mlx5_eswitch_reg_c1_loopback_supported(esw))
+ 		return 0;
+ 
+ 	ns = mlx5_get_flow_namespace(dev, MLX5_FLOW_NAMESPACE_OFFLOADS);
+ 	if (!ns) {
+ 		esw_warn(esw->dev, "Failed to get offloads flow namespace\n");
+ 		return -EOPNOTSUPP;
+ 	}
+ 
+ 	flow_group_in = kvzalloc(inlen, GFP_KERNEL);
+ 	if (!flow_group_in) {
+ 		err = -ENOMEM;
+ 		goto out_free;
+ 	}
+ 
+ 	ft_attr.max_fte = 1 << ESW_CHAIN_TAG_METADATA_BITS;
+ 	ft = mlx5_create_flow_table(ns, &ft_attr);
+ 	if (IS_ERR(ft)) {
+ 		err = PTR_ERR(ft);
+ 		esw_warn(esw->dev, "Failed to create restore table, err %d\n",
+ 			 err);
+ 		goto out_free;
+ 	}
+ 
+ 	memset(flow_group_in, 0, inlen);
+ 	match_criteria = MLX5_ADDR_OF(create_flow_group_in, flow_group_in,
+ 				      match_criteria);
+ 	misc = MLX5_ADDR_OF(fte_match_param, match_criteria,
+ 			    misc_parameters_2);
+ 
+ 	MLX5_SET(fte_match_set_misc2, misc, metadata_reg_c_0,
+ 		 ESW_CHAIN_TAG_METADATA_MASK);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, start_flow_index, 0);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, end_flow_index,
+ 		 ft_attr.max_fte - 1);
+ 	MLX5_SET(create_flow_group_in, flow_group_in, match_criteria_enable,
+ 		 MLX5_MATCH_MISC_PARAMETERS_2);
+ 	g = mlx5_create_flow_group(ft, flow_group_in);
+ 	if (IS_ERR(g)) {
+ 		err = PTR_ERR(g);
+ 		esw_warn(dev, "Failed to create restore flow group, err: %d\n",
+ 			 err);
+ 		goto err_group;
+ 	}
+ 
+ 	MLX5_SET(copy_action_in, modact, action_type, MLX5_ACTION_TYPE_COPY);
+ 	MLX5_SET(copy_action_in, modact, src_field,
+ 		 MLX5_ACTION_IN_FIELD_METADATA_REG_C_1);
+ 	MLX5_SET(copy_action_in, modact, dst_field,
+ 		 MLX5_ACTION_IN_FIELD_METADATA_REG_B);
+ 	mod_hdr = mlx5_modify_header_alloc(esw->dev,
+ 					   MLX5_FLOW_NAMESPACE_KERNEL, 1,
+ 					   modact);
+ 	if (IS_ERR(mod_hdr)) {
+ 		esw_warn(dev, "Failed to create restore mod header, err: %d\n",
+ 			 err);
+ 		err = PTR_ERR(mod_hdr);
+ 		goto err_mod_hdr;
+ 	}
+ 
+ 	esw->offloads.ft_offloads_restore = ft;
+ 	esw->offloads.restore_group = g;
+ 	esw->offloads.restore_copy_hdr_id = mod_hdr;
+ 
+ 	kvfree(flow_group_in);
+ 
+ 	return 0;
+ 
+ err_mod_hdr:
+ 	mlx5_destroy_flow_group(g);
+ err_group:
+ 	mlx5_destroy_flow_table(ft);
+ out_free:
+ 	kvfree(flow_group_in);
+ 
+ 	return err;
+ }
+ 
++>>>>>>> c8508713c71c (net/mlx5: E-Switch, free flow_group_in after creating the restore table)
  static int esw_offloads_start(struct mlx5_eswitch *esw,
  			      struct netlink_ext_ack *extack)
  {
* Unmerged path drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
