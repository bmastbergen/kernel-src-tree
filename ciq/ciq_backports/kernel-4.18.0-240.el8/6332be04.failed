bpf: Move bpf_free_used_maps into sleepable section

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Daniel Borkmann <daniel@iogearbox.net>
commit 6332be04c039a72fca32ed0a4265bac58d606bb6
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/6332be04.failed

We later on are going to need a sleepable context as opposed to plain
RCU callback in order to untrack programs we need to poke at runtime
and tracking as well as image update is performed under mutex.

	Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: Andrii Nakryiko <andriin@fb.com>
Link: https://lore.kernel.org/bpf/09823b1d5262876e9b83a8e75df04cf0467357a4.1574452833.git.daniel@iogearbox.net
(cherry picked from commit 6332be04c039a72fca32ed0a4265bac58d606bb6)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/syscall.c
diff --cc kernel/bpf/syscall.c
index dd68cbc967e7,373778da8489..000000000000
--- a/kernel/bpf/syscall.c
+++ b/kernel/bpf/syscall.c
@@@ -1248,54 -1302,6 +1248,57 @@@ static int find_prog_type(enum bpf_prog
  	return 0;
  }
  
++<<<<<<< HEAD
 +/* drop refcnt on maps used by eBPF program and free auxilary data */
 +static void free_used_maps(struct bpf_prog_aux *aux)
 +{
 +	enum bpf_cgroup_storage_type stype;
 +	int i;
 +
 +	for_each_cgroup_storage_type(stype) {
 +		if (!aux->cgroup_storage[stype])
 +			continue;
 +		bpf_cgroup_storage_release(aux, aux->cgroup_storage[stype]);
 +	}
 +
 +	for (i = 0; i < aux->used_map_cnt; i++)
 +		bpf_map_put(aux->used_maps[i]);
 +
 +	kfree(aux->used_maps);
 +}
 +
 +enum bpf_audit {
 +	BPF_AUDIT_LOAD,
 +	BPF_AUDIT_UNLOAD,
 +	BPF_AUDIT_MAX,
 +};
 +
 +static const char * const bpf_audit_str[BPF_AUDIT_MAX] = {
 +	[BPF_AUDIT_LOAD]   = "LOAD",
 +	[BPF_AUDIT_UNLOAD] = "UNLOAD",
 +};
 +
 +static void bpf_audit_prog(const struct bpf_prog *prog, unsigned int op)
 +{
 +	struct audit_context *ctx = NULL;
 +	struct audit_buffer *ab;
 +
 +	if (WARN_ON_ONCE(op >= BPF_AUDIT_MAX))
 +		return;
 +	if (audit_enabled == AUDIT_OFF)
 +		return;
 +	if (op == BPF_AUDIT_LOAD)
 +		ctx = audit_context();
 +	ab = audit_log_start(ctx, GFP_ATOMIC, AUDIT_BPF);
 +	if (unlikely(!ab))
 +		return;
 +	audit_log_format(ab, "prog-id=%u op=%s",
 +			 prog->aux->id, bpf_audit_str[op]);
 +	audit_log_end(ab);
 +}
 +
++=======
++>>>>>>> 6332be04c039 (bpf: Move bpf_free_used_maps into sleepable section)
  int __bpf_prog_charge(struct user_struct *user, u32 pages)
  {
  	unsigned long memlock_limit = rlimit(RLIMIT_MEMLOCK) >> PAGE_SHIFT;
@@@ -1389,7 -1395,7 +1392,11 @@@ static void __bpf_prog_put_rcu(struct r
  	struct bpf_prog_aux *aux = container_of(rcu, struct bpf_prog_aux, rcu);
  
  	kvfree(aux->func_info);
++<<<<<<< HEAD
 +	free_used_maps(aux);
++=======
+ 	kfree(aux->func_info_aux);
++>>>>>>> 6332be04c039 (bpf: Move bpf_free_used_maps into sleepable section)
  	bpf_prog_uncharge_memlock(aux->prog);
  	security_bpf_prog_free(aux);
  	bpf_prog_free(aux->prog);
diff --git a/include/linux/bpf.h b/include/linux/bpf.h
index a5585413dfbe..23e9782d8349 100644
--- a/include/linux/bpf.h
+++ b/include/linux/bpf.h
@@ -909,6 +909,10 @@ static inline int bpf_prog_test_run_flow_dissector(struct bpf_prog *prog,
 {
 	return -ENOTSUPP;
 }
+
+static inline void bpf_map_put(struct bpf_map *map)
+{
+}
 #endif /* CONFIG_BPF_SYSCALL */
 
 static inline struct bpf_prog *bpf_prog_get_type(u32 ufd,
diff --git a/kernel/bpf/core.c b/kernel/bpf/core.c
index bb9fdedbeefb..14be694925fe 100644
--- a/kernel/bpf/core.c
+++ b/kernel/bpf/core.c
@@ -2009,12 +2009,35 @@ int bpf_prog_array_copy_info(struct bpf_prog_array *array,
 								     : 0;
 }
 
+static void bpf_free_cgroup_storage(struct bpf_prog_aux *aux)
+{
+	enum bpf_cgroup_storage_type stype;
+
+	for_each_cgroup_storage_type(stype) {
+		if (!aux->cgroup_storage[stype])
+			continue;
+		bpf_cgroup_storage_release(aux->prog,
+					   aux->cgroup_storage[stype]);
+	}
+}
+
+static void bpf_free_used_maps(struct bpf_prog_aux *aux)
+{
+	int i;
+
+	bpf_free_cgroup_storage(aux);
+	for (i = 0; i < aux->used_map_cnt; i++)
+		bpf_map_put(aux->used_maps[i]);
+	kfree(aux->used_maps);
+}
+
 static void bpf_prog_free_deferred(struct work_struct *work)
 {
 	struct bpf_prog_aux *aux;
 	int i;
 
 	aux = container_of(work, struct bpf_prog_aux, work);
+	bpf_free_used_maps(aux);
 	if (bpf_prog_is_dev_bound(aux))
 		bpf_prog_offload_destroy(aux->prog);
 #ifdef CONFIG_PERF_EVENTS
* Unmerged path kernel/bpf/syscall.c
