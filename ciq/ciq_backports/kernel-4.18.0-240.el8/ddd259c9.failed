KVM: Drop kvm_arch_vcpu_init() and kvm_arch_vcpu_uninit()

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Sean Christopherson <sean.j.christopherson@intel.com>
commit ddd259c9aaba08244dba8877687ee856f79c4f45
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/ddd259c9.failed

Remove kvm_arch_vcpu_init() and kvm_arch_vcpu_uninit() now that all
arch specific implementations are nops.

	Acked-by: Christoffer Dall <christoffer.dall@arm.com>
	Signed-off-by: Sean Christopherson <sean.j.christopherson@intel.com>
	Reviewed-by: Cornelia Huck <cohuck@redhat.com>
	Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
(cherry picked from commit ddd259c9aaba08244dba8877687ee856f79c4f45)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	arch/arm64/include/asm/kvm_host.h
#	arch/arm64/kvm/reset.c
#	arch/mips/kvm/mips.c
#	arch/powerpc/kvm/powerpc.c
#	arch/x86/kvm/x86.c
#	virt/kvm/arm/arm.c
diff --cc arch/arm64/include/asm/kvm_host.h
index 4ee1459d6b92,8ab62944e514..000000000000
--- a/arch/arm64/include/asm/kvm_host.h
+++ b/arch/arm64/include/asm/kvm_host.h
@@@ -62,7 -53,7 +62,11 @@@ int kvm_arm_init_sve(void)
  
  int __attribute_const__ kvm_target_cpu(void);
  int kvm_reset_vcpu(struct kvm_vcpu *vcpu);
++<<<<<<< HEAD
 +void kvm_arch_vcpu_uninit(struct kvm_vcpu *vcpu);
++=======
+ void kvm_arm_vcpu_destroy(struct kvm_vcpu *vcpu);
++>>>>>>> ddd259c9aaba (KVM: Drop kvm_arch_vcpu_init() and kvm_arch_vcpu_uninit())
  int kvm_arch_vm_ioctl_check_extension(struct kvm *kvm, long ext);
  void __extended_idmap_trampoline(phys_addr_t boot_pgd, phys_addr_t idmap_start);
  
diff --cc arch/arm64/kvm/reset.c
index 7eec78935627,30b7ea680f66..000000000000
--- a/arch/arm64/kvm/reset.c
+++ b/arch/arm64/kvm/reset.c
@@@ -210,7 -204,7 +210,11 @@@ bool kvm_arm_vcpu_is_finalized(struct k
  	return true;
  }
  
++<<<<<<< HEAD
 +void kvm_arch_vcpu_uninit(struct kvm_vcpu *vcpu)
++=======
+ void kvm_arm_vcpu_destroy(struct kvm_vcpu *vcpu)
++>>>>>>> ddd259c9aaba (KVM: Drop kvm_arch_vcpu_init() and kvm_arch_vcpu_uninit())
  {
  	kfree(vcpu->arch.sve_state);
  }
diff --cc arch/mips/kvm/mips.c
index 6d4b49925bf8,2606f3f02b54..000000000000
--- a/arch/mips/kvm/mips.c
+++ b/arch/mips/kvm/mips.c
@@@ -1233,25 -1230,6 +1233,28 @@@ static enum hrtimer_restart kvm_mips_co
  	return kvm_mips_count_timeout(vcpu);
  }
  
++<<<<<<< HEAD
 +int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)
 +{
 +	int err;
 +
 +	err = kvm_mips_callbacks->vcpu_init(vcpu);
 +	if (err)
 +		return err;
 +
 +	hrtimer_init(&vcpu->arch.comparecount_timer, CLOCK_MONOTONIC,
 +		     HRTIMER_MODE_REL);
 +	vcpu->arch.comparecount_timer.function = kvm_mips_comparecount_wakeup;
 +	return 0;
 +}
 +
 +void kvm_arch_vcpu_uninit(struct kvm_vcpu *vcpu)
 +{
 +	kvm_mips_callbacks->vcpu_uninit(vcpu);
 +}
 +
++=======
++>>>>>>> ddd259c9aaba (KVM: Drop kvm_arch_vcpu_init() and kvm_arch_vcpu_uninit())
  int kvm_arch_vcpu_ioctl_translate(struct kvm_vcpu *vcpu,
  				  struct kvm_translation *tr)
  {
diff --cc arch/powerpc/kvm/powerpc.c
index 124aecce15bf,1af96fb5dc6f..000000000000
--- a/arch/powerpc/kvm/powerpc.c
+++ b/arch/powerpc/kvm/powerpc.c
@@@ -794,37 -801,6 +794,40 @@@ int kvm_cpu_has_pending_timer(struct kv
  	return kvmppc_core_pending_dec(vcpu);
  }
  
++<<<<<<< HEAD
 +static enum hrtimer_restart kvmppc_decrementer_wakeup(struct hrtimer *timer)
 +{
 +	struct kvm_vcpu *vcpu;
 +
 +	vcpu = container_of(timer, struct kvm_vcpu, arch.dec_timer);
 +	kvmppc_decrementer_func(vcpu);
 +
 +	return HRTIMER_NORESTART;
 +}
 +
 +int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)
 +{
 +	int ret;
 +
 +	hrtimer_init(&vcpu->arch.dec_timer, CLOCK_REALTIME, HRTIMER_MODE_ABS);
 +	vcpu->arch.dec_timer.function = kvmppc_decrementer_wakeup;
 +	vcpu->arch.dec_expires = get_tb();
 +
 +#ifdef CONFIG_KVM_EXIT_TIMING
 +	mutex_init(&vcpu->arch.exit_timing_lock);
 +#endif
 +	ret = kvmppc_subarch_vcpu_init(vcpu);
 +	return ret;
 +}
 +
 +void kvm_arch_vcpu_uninit(struct kvm_vcpu *vcpu)
 +{
 +	kvmppc_mmu_destroy(vcpu);
 +	kvmppc_subarch_vcpu_uninit(vcpu);
 +}
 +
++=======
++>>>>>>> ddd259c9aaba (KVM: Drop kvm_arch_vcpu_init() and kvm_arch_vcpu_uninit())
  void kvm_arch_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
  {
  #ifdef CONFIG_BOOKE
diff --cc arch/x86/kvm/x86.c
index fd0e26bb25de,985066e1bda5..000000000000
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@@ -9461,98 -9575,6 +9461,101 @@@ bool kvm_vcpu_is_bsp(struct kvm_vcpu *v
  struct static_key kvm_no_apic_vcpu __read_mostly;
  EXPORT_SYMBOL_GPL(kvm_no_apic_vcpu);
  
++<<<<<<< HEAD
 +int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)
 +{
 +	struct page *page;
 +	int r;
 +
 +	vcpu->arch.emulate_ctxt.ops = &emulate_ops;
 +	if (!irqchip_in_kernel(vcpu->kvm) || kvm_vcpu_is_reset_bsp(vcpu))
 +		vcpu->arch.mp_state = KVM_MP_STATE_RUNNABLE;
 +	else
 +		vcpu->arch.mp_state = KVM_MP_STATE_UNINITIALIZED;
 +
 +	page = alloc_page(GFP_KERNEL | __GFP_ZERO);
 +	if (!page) {
 +		r = -ENOMEM;
 +		goto fail;
 +	}
 +	vcpu->arch.pio_data = page_address(page);
 +
 +	kvm_set_tsc_khz(vcpu, max_tsc_khz);
 +
 +	r = kvm_mmu_create(vcpu);
 +	if (r < 0)
 +		goto fail_free_pio_data;
 +
 +	if (irqchip_in_kernel(vcpu->kvm)) {
 +		vcpu->arch.apicv_active = kvm_x86_ops->get_enable_apicv(vcpu->kvm);
 +		r = kvm_create_lapic(vcpu, lapic_timer_advance_ns);
 +		if (r < 0)
 +			goto fail_mmu_destroy;
 +	} else
 +		static_key_slow_inc(&kvm_no_apic_vcpu);
 +
 +	vcpu->arch.mce_banks = kzalloc(KVM_MAX_MCE_BANKS * sizeof(u64) * 4,
 +				       GFP_KERNEL_ACCOUNT);
 +	if (!vcpu->arch.mce_banks) {
 +		r = -ENOMEM;
 +		goto fail_free_lapic;
 +	}
 +	vcpu->arch.mcg_cap = KVM_MAX_MCE_BANKS;
 +
 +	if (!zalloc_cpumask_var(&vcpu->arch.wbinvd_dirty_mask,
 +				GFP_KERNEL_ACCOUNT)) {
 +		r = -ENOMEM;
 +		goto fail_free_mce_banks;
 +	}
 +
 +	fx_init(vcpu);
 +
 +	vcpu->arch.guest_xstate_size = XSAVE_HDR_SIZE + XSAVE_HDR_OFFSET;
 +
 +	vcpu->arch.maxphyaddr = cpuid_query_maxphyaddr(vcpu);
 +
 +	vcpu->arch.pat = MSR_IA32_CR_PAT_DEFAULT;
 +
 +	kvm_async_pf_hash_reset(vcpu);
 +	kvm_pmu_init(vcpu);
 +
 +	vcpu->arch.pending_external_vector = -1;
 +	vcpu->arch.preempted_in_kernel = false;
 +
 +	kvm_hv_vcpu_init(vcpu);
 +
 +	return 0;
 +
 +fail_free_mce_banks:
 +	kfree(vcpu->arch.mce_banks);
 +fail_free_lapic:
 +	kvm_free_lapic(vcpu);
 +fail_mmu_destroy:
 +	kvm_mmu_destroy(vcpu);
 +fail_free_pio_data:
 +	free_page((unsigned long)vcpu->arch.pio_data);
 +fail:
 +	return r;
 +}
 +
 +void kvm_arch_vcpu_uninit(struct kvm_vcpu *vcpu)
 +{
 +	int idx;
 +
 +	kvm_hv_vcpu_uninit(vcpu);
 +	kvm_pmu_destroy(vcpu);
 +	kfree(vcpu->arch.mce_banks);
 +	kvm_free_lapic(vcpu);
 +	idx = srcu_read_lock(&vcpu->kvm->srcu);
 +	kvm_mmu_destroy(vcpu);
 +	srcu_read_unlock(&vcpu->kvm->srcu, idx);
 +	free_page((unsigned long)vcpu->arch.pio_data);
 +	if (!lapic_in_kernel(vcpu))
 +		static_key_slow_dec(&kvm_no_apic_vcpu);
 +}
 +
++=======
++>>>>>>> ddd259c9aaba (KVM: Drop kvm_arch_vcpu_init() and kvm_arch_vcpu_uninit())
  void kvm_arch_sched_in(struct kvm_vcpu *vcpu, int cpu)
  {
  	struct kvm_pmu *pmu = vcpu_to_pmu(vcpu);
diff --cc virt/kvm/arm/arm.c
index f41a18f358a9,1cfc108eca1e..000000000000
--- a/virt/kvm/arm/arm.c
+++ b/virt/kvm/arm/arm.c
@@@ -349,22 -360,6 +349,25 @@@ void kvm_arch_vcpu_unblocking(struct kv
  	preempt_enable();
  }
  
++<<<<<<< HEAD
 +int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)
 +{
 +	/* Force users to call KVM_ARM_VCPU_INIT */
 +	vcpu->arch.target = -1;
 +	bitmap_zero(vcpu->arch.features, KVM_VCPU_MAX_FEATURES);
 +
 +	/* Set up the timer */
 +	kvm_timer_vcpu_init(vcpu);
 +
 +	kvm_pmu_vcpu_init(vcpu);
 +
 +	kvm_arm_reset_debug_ptr(vcpu);
 +
 +	return kvm_vgic_vcpu_init(vcpu);
 +}
 +
++=======
++>>>>>>> ddd259c9aaba (KVM: Drop kvm_arch_vcpu_init() and kvm_arch_vcpu_uninit())
  void kvm_arch_vcpu_load(struct kvm_vcpu *vcpu, int cpu)
  {
  	int *last_ran;
diff --git a/arch/arm/include/asm/kvm_host.h b/arch/arm/include/asm/kvm_host.h
index 425ec46ee61b..425740605a96 100644
--- a/arch/arm/include/asm/kvm_host.h
+++ b/arch/arm/include/asm/kvm_host.h
@@ -317,7 +317,6 @@ struct kvm_vcpu *kvm_mpidr_to_vcpu(struct kvm *kvm, unsigned long mpidr);
 static inline bool kvm_arch_requires_vhe(void) { return false; }
 static inline void kvm_arch_hardware_unsetup(void) {}
 static inline void kvm_arch_sync_events(struct kvm *kvm) {}
-static inline void kvm_arch_vcpu_uninit(struct kvm_vcpu *vcpu) {}
 static inline void kvm_arch_sched_in(struct kvm_vcpu *vcpu, int cpu) {}
 static inline void kvm_arch_vcpu_block_finish(struct kvm_vcpu *vcpu) {}
 
* Unmerged path arch/arm64/include/asm/kvm_host.h
* Unmerged path arch/arm64/kvm/reset.c
* Unmerged path arch/mips/kvm/mips.c
* Unmerged path arch/powerpc/kvm/powerpc.c
diff --git a/arch/s390/include/asm/kvm_host.h b/arch/s390/include/asm/kvm_host.h
index abe60268335d..e0a542fd5559 100644
--- a/arch/s390/include/asm/kvm_host.h
+++ b/arch/s390/include/asm/kvm_host.h
@@ -913,7 +913,6 @@ extern int kvm_s390_gisc_unregister(struct kvm *kvm, u32 gisc);
 
 static inline void kvm_arch_hardware_disable(void) {}
 static inline void kvm_arch_sync_events(struct kvm *kvm) {}
-static inline void kvm_arch_vcpu_uninit(struct kvm_vcpu *vcpu) {}
 static inline void kvm_arch_sched_in(struct kvm_vcpu *vcpu, int cpu) {}
 static inline void kvm_arch_free_memslot(struct kvm *kvm,
 		struct kvm_memory_slot *free, struct kvm_memory_slot *dont) {}
diff --git a/arch/s390/kvm/kvm-s390.c b/arch/s390/kvm/kvm-s390.c
index d6b727e2f0a2..80d5ee28b5ee 100644
--- a/arch/s390/kvm/kvm-s390.c
+++ b/arch/s390/kvm/kvm-s390.c
@@ -2706,11 +2706,6 @@ static int sca_can_add_vcpu(struct kvm *kvm, unsigned int id)
 	return rc == 0 && id < KVM_S390_ESCA_CPU_SLOTS;
 }
 
-int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)
-{
-	return 0;
-}
-
 /* needs disabled preemption to protect from TOD sync and vcpu_load/put */
 static void __start_cpu_timer_accounting(struct kvm_vcpu *vcpu)
 {
* Unmerged path arch/x86/kvm/x86.c
diff --git a/include/linux/kvm_host.h b/include/linux/kvm_host.h
index 76c481d92694..6ac3c19578ce 100644
--- a/include/linux/kvm_host.h
+++ b/include/linux/kvm_host.h
@@ -870,9 +870,6 @@ int kvm_arch_vcpu_ioctl_run(struct kvm_vcpu *vcpu, struct kvm_run *kvm_run);
 int kvm_arch_init(void *opaque);
 void kvm_arch_exit(void);
 
-int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu);
-void kvm_arch_vcpu_uninit(struct kvm_vcpu *vcpu);
-
 void kvm_arch_sched_in(struct kvm_vcpu *vcpu, int cpu);
 
 void kvm_arch_vcpu_load(struct kvm_vcpu *vcpu, int cpu);
* Unmerged path virt/kvm/arm/arm.c
diff --git a/virt/kvm/kvm_main.c b/virt/kvm/kvm_main.c
index c6256c9afce6..10fece14f1a2 100644
--- a/virt/kvm/kvm_main.c
+++ b/virt/kvm/kvm_main.c
@@ -327,7 +327,6 @@ void kvm_reload_remote_mmus(struct kvm *kvm)
 int kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id)
 {
 	struct page *page;
-	int r;
 
 	mutex_init(&vcpu->mutex);
 	vcpu->cpu = -1;
@@ -341,10 +340,8 @@ int kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id)
 	INIT_LIST_HEAD(&vcpu->blocked_vcpu_list);
 
 	page = alloc_page(GFP_KERNEL | __GFP_ZERO);
-	if (!page) {
-		r = -ENOMEM;
-		goto fail;
-	}
+	if (!page)
+		return -ENOMEM;
 	vcpu->run = page_address(page);
 
 	kvm_vcpu_set_in_spin_loop(vcpu, false);
@@ -352,15 +349,7 @@ int kvm_vcpu_init(struct kvm_vcpu *vcpu, struct kvm *kvm, unsigned id)
 	vcpu->preempted = false;
 	vcpu->ready = false;
 
-	r = kvm_arch_vcpu_init(vcpu);
-	if (r < 0)
-		goto fail_free_run;
 	return 0;
-
-fail_free_run:
-	free_page((unsigned long)vcpu->run);
-fail:
-	return r;
 }
 EXPORT_SYMBOL_GPL(kvm_vcpu_init);
 
@@ -372,7 +361,6 @@ void kvm_vcpu_uninit(struct kvm_vcpu *vcpu)
 	 * descriptors are already gone.
 	 */
 	put_pid(rcu_dereference_protected(vcpu->pid, 1));
-	kvm_arch_vcpu_uninit(vcpu);
 	free_page((unsigned long)vcpu->run);
 }
 EXPORT_SYMBOL_GPL(kvm_vcpu_uninit);
