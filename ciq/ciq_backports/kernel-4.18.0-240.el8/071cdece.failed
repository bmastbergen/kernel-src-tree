xdp: Fix cleanup on map free for devmap_hash map type

jira LE-1907
Rebuild_History Non-Buildable kernel-4.18.0-240.el8
commit-author Toke Høiland-Jørgensen <toke@redhat.com>
commit 071cdecec57fb5d5df78e6a12114ad7bccea5b0e
Empty-Commit: Cherry-Pick Conflicts during history rebuild.
Will be included in final tarball splat. Ref for failed cherry-pick at:
ciq/ciq_backports/kernel-4.18.0-240.el8/071cdece.failed

Tetsuo pointed out that it was not only the device unregister hook that was
broken for devmap_hash types, it was also cleanup on map free. So better
fix this as well.

While we're at it, there's no reason to allocate the netdev_map array for
DEVMAP_HASH, so skip that and adjust the cost accordingly.

Fixes: 6f9d451ab1a3 ("xdp: Add devmap_hash map type for looking up devices by hashed index")
	Reported-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>
	Signed-off-by: Toke Høiland-Jørgensen <toke@redhat.com>
	Signed-off-by: Alexei Starovoitov <ast@kernel.org>
	Acked-by: John Fastabend <john.fastabend@gmail.com>
Link: https://lore.kernel.org/bpf/20191121133612.430414-1-toke@redhat.com
(cherry picked from commit 071cdecec57fb5d5df78e6a12114ad7bccea5b0e)
	Signed-off-by: Jonathan Maple <jmaple@ciq.com>

# Conflicts:
#	kernel/bpf/devmap.c
diff --cc kernel/bpf/devmap.c
index cfc445b29247,3d3d61b5985b..000000000000
--- a/kernel/bpf/devmap.c
+++ b/kernel/bpf/devmap.c
@@@ -75,14 -74,39 +75,36 @@@ struct bpf_dtab_netdev 
  
  struct bpf_dtab {
  	struct bpf_map map;
- 	struct bpf_dtab_netdev **netdev_map;
+ 	struct bpf_dtab_netdev **netdev_map; /* DEVMAP type only */
  	struct list_head __percpu *flush_list;
  	struct list_head list;
 -
 -	/* these are only used for DEVMAP_HASH type maps */
 -	struct hlist_head *dev_index_head;
 -	spinlock_t index_lock;
 -	unsigned int items;
 -	u32 n_buckets;
  };
  
  static DEFINE_SPINLOCK(dev_map_lock);
  static LIST_HEAD(dev_map_list);
  
++<<<<<<< HEAD
++=======
+ static struct hlist_head *dev_map_create_hash(unsigned int entries)
+ {
+ 	int i;
+ 	struct hlist_head *hash;
+ 
+ 	hash = kmalloc_array(entries, sizeof(*hash), GFP_KERNEL);
+ 	if (hash != NULL)
+ 		for (i = 0; i < entries; i++)
+ 			INIT_HLIST_HEAD(&hash[i]);
+ 
+ 	return hash;
+ }
+ 
+ static inline struct hlist_head *dev_map_index_hash(struct bpf_dtab *dtab,
+ 						    int idx)
+ {
+ 	return &dtab->dev_index_head[idx & (dtab->n_buckets - 1)];
+ }
+ 
++>>>>>>> 071cdecec57f (xdp: Fix cleanup on map free for devmap_hash map type)
  static int dev_map_init_map(struct bpf_dtab *dtab, union bpf_attr *attr)
  {
  	int err, cpu;
@@@ -102,9 -126,18 +124,21 @@@
  	bpf_map_init_from_attr(&dtab->map, attr);
  
  	/* make sure page count doesn't overflow */
- 	cost = (u64) dtab->map.max_entries * sizeof(struct bpf_dtab_netdev *);
- 	cost += sizeof(struct list_head) * num_possible_cpus();
+ 	cost = (u64) sizeof(struct list_head) * num_possible_cpus();
+ 
++<<<<<<< HEAD
++=======
+ 	if (attr->map_type == BPF_MAP_TYPE_DEVMAP_HASH) {
+ 		dtab->n_buckets = roundup_pow_of_two(dtab->map.max_entries);
+ 
+ 		if (!dtab->n_buckets) /* Overflow check */
+ 			return -EINVAL;
+ 		cost += (u64) sizeof(struct hlist_head) * dtab->n_buckets;
+ 	} else {
+ 		cost += (u64) dtab->map.max_entries * sizeof(struct bpf_dtab_netdev *);
+ 	}
  
++>>>>>>> 071cdecec57f (xdp: Fix cleanup on map free for devmap_hash map type)
  	/* if map size is larger than memlock limit, reject it */
  	err = bpf_map_charge_init(&dtab->map.memory, cost);
  	if (err)
@@@ -117,11 -150,19 +151,27 @@@
  	for_each_possible_cpu(cpu)
  		INIT_LIST_HEAD(per_cpu_ptr(dtab->flush_list, cpu));
  
++<<<<<<< HEAD
 +	dtab->netdev_map = bpf_map_area_alloc(dtab->map.max_entries *
 +					      sizeof(struct bpf_dtab_netdev *),
 +					      dtab->map.numa_node);
 +	if (!dtab->netdev_map)
 +		goto free_percpu;
++=======
+ 	if (attr->map_type == BPF_MAP_TYPE_DEVMAP_HASH) {
+ 		dtab->dev_index_head = dev_map_create_hash(dtab->n_buckets);
+ 		if (!dtab->dev_index_head)
+ 			goto free_percpu;
+ 
+ 		spin_lock_init(&dtab->index_lock);
+ 	} else {
+ 		dtab->netdev_map = bpf_map_area_alloc(dtab->map.max_entries *
+ 						      sizeof(struct bpf_dtab_netdev *),
+ 						      dtab->map.numa_node);
+ 		if (!dtab->netdev_map)
+ 			goto free_percpu;
+ 	}
++>>>>>>> 071cdecec57f (xdp: Fix cleanup on map free for devmap_hash map type)
  
  	return 0;
  
@@@ -205,7 -267,6 +276,10 @@@ static void dev_map_free(struct bpf_ma
  	}
  
  	free_percpu(dtab->flush_list);
++<<<<<<< HEAD
 +	bpf_map_area_free(dtab->netdev_map);
++=======
++>>>>>>> 071cdecec57f (xdp: Fix cleanup on map free for devmap_hash map type)
  	kfree(dtab);
  }
  
@@@ -226,6 -287,64 +300,67 @@@ static int dev_map_get_next_key(struct 
  	return 0;
  }
  
++<<<<<<< HEAD
++=======
+ struct bpf_dtab_netdev *__dev_map_hash_lookup_elem(struct bpf_map *map, u32 key)
+ {
+ 	struct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);
+ 	struct hlist_head *head = dev_map_index_hash(dtab, key);
+ 	struct bpf_dtab_netdev *dev;
+ 
+ 	hlist_for_each_entry_rcu(dev, head, index_hlist)
+ 		if (dev->idx == key)
+ 			return dev;
+ 
+ 	return NULL;
+ }
+ 
+ static int dev_map_hash_get_next_key(struct bpf_map *map, void *key,
+ 				    void *next_key)
+ {
+ 	struct bpf_dtab *dtab = container_of(map, struct bpf_dtab, map);
+ 	u32 idx, *next = next_key;
+ 	struct bpf_dtab_netdev *dev, *next_dev;
+ 	struct hlist_head *head;
+ 	int i = 0;
+ 
+ 	if (!key)
+ 		goto find_first;
+ 
+ 	idx = *(u32 *)key;
+ 
+ 	dev = __dev_map_hash_lookup_elem(map, idx);
+ 	if (!dev)
+ 		goto find_first;
+ 
+ 	next_dev = hlist_entry_safe(rcu_dereference_raw(hlist_next_rcu(&dev->index_hlist)),
+ 				    struct bpf_dtab_netdev, index_hlist);
+ 
+ 	if (next_dev) {
+ 		*next = next_dev->idx;
+ 		return 0;
+ 	}
+ 
+ 	i = idx & (dtab->n_buckets - 1);
+ 	i++;
+ 
+  find_first:
+ 	for (; i < dtab->n_buckets; i++) {
+ 		head = dev_map_index_hash(dtab, i);
+ 
+ 		next_dev = hlist_entry_safe(rcu_dereference_raw(hlist_first_rcu(head)),
+ 					    struct bpf_dtab_netdev,
+ 					    index_hlist);
+ 		if (next_dev) {
+ 			*next = next_dev->idx;
+ 			return 0;
+ 		}
+ 	}
+ 
+ 	return -ENOENT;
+ }
+ 
++>>>>>>> 071cdecec57f (xdp: Fix cleanup on map free for devmap_hash map type)
  static int bq_xmit_all(struct xdp_bulk_queue *bq, u32 flags,
  		       bool in_napi_ctx)
  {
* Unmerged path kernel/bpf/devmap.c
